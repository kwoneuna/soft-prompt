Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'clipart', 'product']
Target     ['real_world']
# classes  65
# train_x  7,877
# val      3,354
# test     4,357
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/246] time 0.118 (0.155) data 0.000 (0.017) loss 1.9608 (1.8417) teacher_loss 1.6060 (1.4869) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0001 (-0.0001) acc 59.3750 (60.7812) kd_loss 0.3549 (0.3549) lr 1.0000e-05 eta 0:31:45
epoch [1/50] batch [40/246] time 0.141 (0.133) data 0.000 (0.009) loss 1.4022 (1.7621) teacher_loss 1.0205 (1.4159) loss_zs_kd 0.0001 (0.0000) loss_oracle -0.0000 (-0.0001) acc 75.0000 (62.9688) kd_loss 0.3818 (0.3462) lr 1.0000e-05 eta 0:27:07
epoch [1/50] batch [60/246] time 0.098 (0.125) data 0.000 (0.006) loss 1.4299 (1.7535) teacher_loss 1.1300 (1.4168) loss_zs_kd 0.0003 (0.0001) loss_oracle -0.0000 (-0.0001) acc 78.1250 (63.3854) kd_loss 0.2999 (0.3368) lr 1.0000e-05 eta 0:25:33
epoch [1/50] batch [80/246] time 0.100 (0.120) data 0.000 (0.004) loss 2.3232 (1.7489) teacher_loss 1.9281 (1.4095) loss_zs_kd 0.0006 (0.0002) loss_oracle 0.0001 (-0.0001) acc 50.0000 (63.5156) kd_loss 0.3951 (0.3394) lr 1.0000e-05 eta 0:24:23
epoch [1/50] batch [100/246] time 0.105 (0.116) data 0.000 (0.004) loss 1.8604 (1.7317) teacher_loss 1.4568 (1.3918) loss_zs_kd 0.0011 (0.0002) loss_oracle 0.0001 (-0.0000) acc 59.3750 (63.8438) kd_loss 0.4035 (0.3399) lr 1.0000e-05 eta 0:23:39
epoch [1/50] batch [120/246] time 0.105 (0.114) data 0.000 (0.003) loss 1.7260 (1.7348) teacher_loss 1.5071 (1.3924) loss_zs_kd 0.0012 (0.0003) loss_oracle 0.0000 (-0.0000) acc 59.3750 (64.0104) kd_loss 0.2189 (0.3424) lr 1.0000e-05 eta 0:23:04
epoch [1/50] batch [140/246] time 0.099 (0.112) data 0.001 (0.003) loss 2.0892 (1.7348) teacher_loss 1.7413 (1.3918) loss_zs_kd 0.0007 (0.0005) loss_oracle 0.0002 (-0.0000) acc 53.1250 (64.0848) kd_loss 0.3478 (0.3430) lr 1.0000e-05 eta 0:22:43
epoch [1/50] batch [160/246] time 0.103 (0.112) data 0.000 (0.002) loss 2.1481 (1.7545) teacher_loss 1.6008 (1.4027) loss_zs_kd 0.0012 (0.0006) loss_oracle -0.0000 (-0.0000) acc 65.6250 (63.5938) kd_loss 0.5474 (0.3518) lr 1.0000e-05 eta 0:22:36
epoch [1/50] batch [180/246] time 0.099 (0.112) data 0.000 (0.002) loss 2.0490 (1.7504) teacher_loss 1.6119 (1.3963) loss_zs_kd 0.0018 (0.0007) loss_oracle 0.0000 (0.0000) acc 56.2500 (63.9583) kd_loss 0.4371 (0.3542) lr 1.0000e-05 eta 0:22:34
epoch [1/50] batch [200/246] time 0.100 (0.111) data 0.000 (0.002) loss 2.4131 (1.7529) teacher_loss 2.1251 (1.3970) loss_zs_kd 0.0058 (0.0010) loss_oracle 0.0003 (0.0000) acc 40.6250 (63.8281) kd_loss 0.2878 (0.3558) lr 1.0000e-05 eta 0:22:26
epoch [1/50] batch [220/246] time 0.105 (0.111) data 0.000 (0.002) loss 1.5331 (1.7552) teacher_loss 1.2712 (1.3973) loss_zs_kd 0.0043 (0.0012) loss_oracle 0.0001 (0.0000) acc 71.8750 (64.0199) kd_loss 0.2619 (0.3579) lr 1.0000e-05 eta 0:22:19
epoch [1/50] batch [240/246] time 0.102 (0.111) data 0.000 (0.002) loss 2.0512 (1.7568) teacher_loss 1.5810 (1.3959) loss_zs_kd 0.0032 (0.0014) loss_oracle 0.0001 (0.0000) acc 59.3750 (63.9583) kd_loss 0.4702 (0.3609) lr 1.0000e-05 eta 0:22:13
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,684
* accuracy: 80.0%
* error: 20.0%
* macro_f1: 78.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,897
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 87.9%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      80.0%, epoch: 1 *******
******* Domain r best val test acc: 89.4%, epoch: 1 *******
******* Domain r best test acc:     89.4%, epoch: 1 *******
epoch [2/50] batch [20/246] time 0.121 (0.114) data 0.000 (0.014) loss 2.3762 (1.9834) teacher_loss 1.6503 (1.4379) loss_zs_kd 0.1657 (0.0932) loss_oracle 0.3082 (0.1345) acc 68.7500 (64.0625) kd_loss 0.5718 (0.4782) lr 2.0000e-03 eta 0:22:54
epoch [2/50] batch [40/246] time 0.099 (0.113) data 0.000 (0.007) loss 2.1992 (2.0209) teacher_loss 1.5080 (1.3711) loss_zs_kd 0.1605 (0.1320) loss_oracle 0.2168 (0.2051) acc 59.3750 (65.4688) kd_loss 0.5828 (0.5473) lr 2.0000e-03 eta 0:22:42
epoch [2/50] batch [60/246] time 0.094 (0.107) data 0.000 (0.005) loss 2.1765 (2.0389) teacher_loss 1.2267 (1.2948) loss_zs_kd 0.3060 (0.1589) loss_oracle 0.5023 (0.2911) acc 68.7500 (67.1354) kd_loss 0.6986 (0.5986) lr 2.0000e-03 eta 0:21:26
epoch [2/50] batch [80/246] time 0.089 (0.104) data 0.000 (0.004) loss 2.1364 (2.0591) teacher_loss 1.1959 (1.2586) loss_zs_kd 0.2905 (0.1817) loss_oracle 0.5000 (0.3461) acc 68.7500 (68.1250) kd_loss 0.6905 (0.6275) lr 2.0000e-03 eta 0:20:45
epoch [2/50] batch [100/246] time 0.086 (0.102) data 0.000 (0.003) loss 1.8656 (2.0916) teacher_loss 1.0237 (1.2521) loss_zs_kd 0.1824 (0.1944) loss_oracle 0.4399 (0.3804) acc 71.8750 (67.9062) kd_loss 0.6220 (0.6493) lr 2.0000e-03 eta 0:20:18
epoch [2/50] batch [120/246] time 0.092 (0.101) data 0.000 (0.003) loss 2.4641 (2.1311) teacher_loss 1.0523 (1.2412) loss_zs_kd 0.1659 (0.2019) loss_oracle 0.8565 (0.4248) acc 71.8750 (68.3073) kd_loss 0.9836 (0.6775) lr 2.0000e-03 eta 0:20:03
epoch [2/50] batch [140/246] time 0.084 (0.100) data 0.000 (0.002) loss 2.5484 (2.1836) teacher_loss 1.2880 (1.2323) loss_zs_kd 0.1609 (0.2067) loss_oracle 0.7640 (0.4790) acc 71.8750 (68.1920) kd_loss 0.8784 (0.7118) lr 2.0000e-03 eta 0:19:48
epoch [2/50] batch [160/246] time 0.096 (0.099) data 0.000 (0.002) loss 2.3594 (2.2256) teacher_loss 0.9452 (1.2226) loss_zs_kd 0.2212 (0.2110) loss_oracle 0.8671 (0.5268) acc 68.7500 (68.4180) kd_loss 0.9807 (0.7396) lr 2.0000e-03 eta 0:19:36
epoch [2/50] batch [180/246] time 0.098 (0.098) data 0.000 (0.002) loss 2.0700 (2.2440) teacher_loss 1.1929 (1.2142) loss_zs_kd 0.2634 (0.2157) loss_oracle 0.5515 (0.5517) acc 75.0000 (68.7153) kd_loss 0.6014 (0.7539) lr 2.0000e-03 eta 0:19:28
epoch [2/50] batch [200/246] time 0.091 (0.098) data 0.000 (0.002) loss 2.5400 (2.2496) teacher_loss 1.5401 (1.2177) loss_zs_kd 0.2056 (0.2197) loss_oracle 0.5691 (0.5537) acc 56.2500 (68.6406) kd_loss 0.7153 (0.7550) lr 2.0000e-03 eta 0:19:20
epoch [2/50] batch [220/246] time 0.100 (0.098) data 0.000 (0.001) loss 2.2978 (2.2452) teacher_loss 1.2111 (1.2121) loss_zs_kd 0.2948 (0.2226) loss_oracle 0.5614 (0.5558) acc 65.6250 (68.7642) kd_loss 0.8060 (0.7552) lr 2.0000e-03 eta 0:19:19
epoch [2/50] batch [240/246] time 0.085 (0.097) data 0.000 (0.001) loss 2.2765 (2.2454) teacher_loss 1.2716 (1.2153) loss_zs_kd 0.4302 (0.2276) loss_oracle 0.5257 (0.5530) acc 68.7500 (68.7500) kd_loss 0.7420 (0.7536) lr 2.0000e-03 eta 0:19:09
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,812
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.6%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.8%, epoch: 2 *******
******* Domain r best val test acc: 90.8%, epoch: 2 *******
******* Domain r best test acc:     90.8%, epoch: 2 *******
epoch [3/50] batch [20/246] time 0.100 (0.110) data 0.000 (0.014) loss 2.5021 (2.3079) teacher_loss 1.3861 (1.1669) loss_zs_kd 0.2220 (0.2882) loss_oracle 0.6025 (0.6581) acc 65.6250 (70.3125) kd_loss 0.8148 (0.8119) lr 1.9980e-03 eta 0:21:42
epoch [3/50] batch [40/246] time 0.150 (0.109) data 0.001 (0.007) loss 1.6418 (2.2319) teacher_loss 0.7039 (1.1703) loss_zs_kd 0.1796 (0.2846) loss_oracle 0.4766 (0.5865) acc 87.5000 (70.4688) kd_loss 0.6996 (0.7684) lr 1.9980e-03 eta 0:21:24
epoch [3/50] batch [60/246] time 0.117 (0.108) data 0.000 (0.005) loss 2.6931 (2.2058) teacher_loss 1.7189 (1.1768) loss_zs_kd 0.2615 (0.2798) loss_oracle 0.4890 (0.5518) acc 53.1250 (69.3229) kd_loss 0.7297 (0.7532) lr 1.9980e-03 eta 0:21:10
epoch [3/50] batch [80/246] time 0.101 (0.107) data 0.000 (0.004) loss 2.7648 (2.1927) teacher_loss 1.8553 (1.1927) loss_zs_kd 0.2864 (0.2807) loss_oracle 0.3708 (0.5253) acc 62.5000 (69.3359) kd_loss 0.7241 (0.7374) lr 1.9980e-03 eta 0:20:54
epoch [3/50] batch [100/246] time 0.127 (0.108) data 0.000 (0.003) loss 1.9060 (2.1694) teacher_loss 1.0096 (1.1923) loss_zs_kd 0.1811 (0.2817) loss_oracle 0.4845 (0.5018) acc 68.7500 (69.1562) kd_loss 0.6541 (0.7262) lr 1.9980e-03 eta 0:21:10
epoch [3/50] batch [120/246] time 0.118 (0.111) data 0.000 (0.003) loss 2.2351 (2.1758) teacher_loss 1.1041 (1.1819) loss_zs_kd 0.1843 (0.2798) loss_oracle 0.6215 (0.5183) acc 68.7500 (69.4531) kd_loss 0.8202 (0.7348) lr 1.9980e-03 eta 0:21:37
epoch [3/50] batch [140/246] time 0.132 (0.113) data 0.001 (0.002) loss 2.5620 (2.1904) teacher_loss 1.6241 (1.1861) loss_zs_kd 0.2607 (0.2802) loss_oracle 0.4974 (0.5292) acc 53.1250 (69.1518) kd_loss 0.6892 (0.7397) lr 1.9980e-03 eta 0:22:01
epoch [3/50] batch [160/246] time 0.130 (0.115) data 0.000 (0.002) loss 1.9966 (2.1780) teacher_loss 1.0466 (1.1867) loss_zs_kd 0.2652 (0.2789) loss_oracle 0.4793 (0.5199) acc 71.8750 (69.2773) kd_loss 0.7104 (0.7313) lr 1.9980e-03 eta 0:22:16
epoch [3/50] batch [180/246] time 0.103 (0.115) data 0.000 (0.002) loss 2.1570 (2.1643) teacher_loss 1.2240 (1.1784) loss_zs_kd 0.2775 (0.2784) loss_oracle 0.4582 (0.5184) acc 71.8750 (69.3924) kd_loss 0.7039 (0.7268) lr 1.9980e-03 eta 0:22:15
epoch [3/50] batch [200/246] time 0.096 (0.114) data 0.000 (0.002) loss 1.9671 (2.1528) teacher_loss 1.0936 (1.1756) loss_zs_kd 0.2279 (0.2788) loss_oracle 0.4628 (0.5127) acc 78.1250 (69.3906) kd_loss 0.6421 (0.7208) lr 1.9980e-03 eta 0:22:02
epoch [3/50] batch [220/246] time 0.089 (0.112) data 0.000 (0.002) loss 1.9642 (2.1513) teacher_loss 0.8948 (1.1772) loss_zs_kd 0.2480 (0.2796) loss_oracle 0.5217 (0.5094) acc 75.0000 (69.2614) kd_loss 0.8086 (0.7194) lr 1.9980e-03 eta 0:21:39
epoch [3/50] batch [240/246] time 0.085 (0.110) data 0.000 (0.001) loss 1.5261 (2.1331) teacher_loss 0.7909 (1.1708) loss_zs_kd 0.2176 (0.2799) loss_oracle 0.3949 (0.5020) acc 78.1250 (69.4401) kd_loss 0.5377 (0.7113) lr 1.9980e-03 eta 0:21:15
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,830
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.5%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,953
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      84.4%, epoch: 3 *******
******* Domain r best val test acc: 90.7%, epoch: 3 *******
******* Domain r best test acc:     90.8%, epoch: 2 *******
epoch [4/50] batch [20/246] time 0.098 (0.112) data 0.000 (0.015) loss 1.9503 (2.0336) teacher_loss 1.0335 (1.1017) loss_zs_kd 0.2046 (0.2822) loss_oracle 0.4696 (0.4676) acc 71.8750 (72.0312) kd_loss 0.6820 (0.6980) lr 1.9921e-03 eta 0:21:34
epoch [4/50] batch [40/246] time 0.119 (0.116) data 0.000 (0.008) loss 2.2606 (1.9973) teacher_loss 1.1461 (1.0716) loss_zs_kd 0.2625 (0.2745) loss_oracle 0.5748 (0.4730) acc 68.7500 (73.1250) kd_loss 0.8271 (0.6891) lr 1.9921e-03 eta 0:22:18
epoch [4/50] batch [60/246] time 0.131 (0.118) data 0.001 (0.005) loss 2.2521 (2.0315) teacher_loss 1.2907 (1.0853) loss_zs_kd 0.2847 (0.2830) loss_oracle 0.4646 (0.4883) acc 68.7500 (72.2917) kd_loss 0.7291 (0.7021) lr 1.9921e-03 eta 0:22:41
epoch [4/50] batch [80/246] time 0.123 (0.120) data 0.000 (0.004) loss 1.7677 (2.0328) teacher_loss 0.7541 (1.0802) loss_zs_kd 0.2141 (0.2865) loss_oracle 0.5281 (0.4951) acc 81.2500 (72.1094) kd_loss 0.7495 (0.7050) lr 1.9921e-03 eta 0:22:56
epoch [4/50] batch [100/246] time 0.123 (0.121) data 0.000 (0.003) loss 2.1736 (2.0477) teacher_loss 1.0776 (1.0851) loss_zs_kd 0.2529 (0.2895) loss_oracle 0.5620 (0.5032) acc 65.6250 (71.3125) kd_loss 0.8149 (0.7110) lr 1.9921e-03 eta 0:23:05
epoch [4/50] batch [120/246] time 0.123 (0.122) data 0.000 (0.003) loss 2.4824 (2.0690) teacher_loss 1.5013 (1.0928) loss_zs_kd 0.2978 (0.2925) loss_oracle 0.4958 (0.5093) acc 59.3750 (70.7552) kd_loss 0.7333 (0.7216) lr 1.9921e-03 eta 0:23:11
epoch [4/50] batch [140/246] time 0.130 (0.122) data 0.000 (0.002) loss 1.9168 (2.0545) teacher_loss 1.0212 (1.0797) loss_zs_kd 0.3163 (0.2919) loss_oracle 0.4799 (0.5105) acc 71.8750 (71.0045) kd_loss 0.6556 (0.7195) lr 1.9921e-03 eta 0:23:17
epoch [4/50] batch [160/246] time 0.104 (0.121) data 0.000 (0.002) loss 2.0590 (2.0696) teacher_loss 1.0779 (1.0951) loss_zs_kd 0.3699 (0.3026) loss_oracle 0.5155 (0.5126) acc 62.5000 (70.7617) kd_loss 0.7233 (0.7182) lr 1.9921e-03 eta 0:23:04
epoch [4/50] batch [180/246] time 0.121 (0.122) data 0.000 (0.002) loss 1.7364 (2.0707) teacher_loss 0.8476 (1.1018) loss_zs_kd 0.2081 (0.3044) loss_oracle 0.3799 (0.5047) acc 75.0000 (70.5556) kd_loss 0.6989 (0.7165) lr 1.9921e-03 eta 0:23:04
epoch [4/50] batch [200/246] time 0.102 (0.122) data 0.000 (0.002) loss 2.3988 (2.0660) teacher_loss 1.4760 (1.1052) loss_zs_kd 0.3999 (0.3056) loss_oracle 0.4356 (0.4980) acc 71.8750 (70.5469) kd_loss 0.7050 (0.7118) lr 1.9921e-03 eta 0:23:03
epoch [4/50] batch [220/246] time 0.120 (0.121) data 0.000 (0.002) loss 1.7640 (2.0549) teacher_loss 0.6619 (1.0971) loss_zs_kd 0.3421 (0.3065) loss_oracle 0.5011 (0.4963) acc 81.2500 (70.7102) kd_loss 0.8515 (0.7097) lr 1.9921e-03 eta 0:22:56
epoch [4/50] batch [240/246] time 0.106 (0.121) data 0.000 (0.002) loss 2.1622 (2.0563) teacher_loss 1.1434 (1.1026) loss_zs_kd 0.2243 (0.3092) loss_oracle 0.4936 (0.4951) acc 78.1250 (70.6120) kd_loss 0.7720 (0.7061) lr 1.9921e-03 eta 0:22:50
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,829
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,950
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.5%
******* Domain r best val acc:      84.4%, epoch: 3 *******
******* Domain r best val test acc: 90.7%, epoch: 3 *******
******* Domain r best test acc:     90.8%, epoch: 2 *******
epoch [5/50] batch [20/246] time 0.122 (0.129) data 0.000 (0.014) loss 1.9737 (1.9515) teacher_loss 1.1010 (1.1062) loss_zs_kd 0.2695 (0.2876) loss_oracle 0.3700 (0.4269) acc 75.0000 (72.5000) kd_loss 0.6877 (0.6319) lr 1.9823e-03 eta 0:24:18
epoch [5/50] batch [40/246] time 0.113 (0.128) data 0.000 (0.007) loss 2.4006 (1.9256) teacher_loss 1.6003 (1.1059) loss_zs_kd 0.3882 (0.2824) loss_oracle 0.3488 (0.3909) acc 59.3750 (72.4219) kd_loss 0.6260 (0.6243) lr 1.9823e-03 eta 0:24:00
epoch [5/50] batch [60/246] time 0.122 (0.124) data 0.001 (0.005) loss 1.8839 (1.9444) teacher_loss 0.8566 (1.1043) loss_zs_kd 0.2429 (0.2881) loss_oracle 0.4918 (0.3958) acc 78.1250 (71.6667) kd_loss 0.7814 (0.6423) lr 1.9823e-03 eta 0:23:19
epoch [5/50] batch [80/246] time 0.124 (0.124) data 0.000 (0.004) loss 1.7729 (1.9748) teacher_loss 0.9458 (1.1119) loss_zs_kd 0.2561 (0.2888) loss_oracle 0.4667 (0.4097) acc 68.7500 (71.3281) kd_loss 0.5937 (0.6581) lr 1.9823e-03 eta 0:23:16
epoch [5/50] batch [100/246] time 0.130 (0.125) data 0.000 (0.003) loss 1.8454 (1.9799) teacher_loss 0.9463 (1.1103) loss_zs_kd 0.4941 (0.2978) loss_oracle 0.4198 (0.4164) acc 75.0000 (71.0938) kd_loss 0.6892 (0.6615) lr 1.9823e-03 eta 0:23:26
epoch [5/50] batch [120/246] time 0.124 (0.126) data 0.000 (0.003) loss 1.6362 (1.9859) teacher_loss 0.8078 (1.1266) loss_zs_kd 0.3237 (0.3061) loss_oracle 0.3978 (0.4112) acc 81.2500 (70.7552) kd_loss 0.6296 (0.6536) lr 1.9823e-03 eta 0:23:28
epoch [5/50] batch [140/246] time 0.113 (0.126) data 0.000 (0.002) loss 2.2144 (1.9836) teacher_loss 1.5500 (1.1286) loss_zs_kd 0.3714 (0.3064) loss_oracle 0.3758 (0.4075) acc 59.3750 (70.7143) kd_loss 0.4765 (0.6513) lr 1.9823e-03 eta 0:23:26
epoch [5/50] batch [160/246] time 0.128 (0.125) data 0.000 (0.002) loss 2.1770 (1.9851) teacher_loss 1.3232 (1.1317) loss_zs_kd 0.3026 (0.3100) loss_oracle 0.3649 (0.4038) acc 65.6250 (70.5078) kd_loss 0.6714 (0.6516) lr 1.9823e-03 eta 0:23:15
epoch [5/50] batch [180/246] time 0.128 (0.125) data 0.001 (0.002) loss 1.8643 (1.9772) teacher_loss 1.0835 (1.1266) loss_zs_kd 0.3496 (0.3118) loss_oracle 0.3362 (0.3978) acc 75.0000 (70.5382) kd_loss 0.6128 (0.6517) lr 1.9823e-03 eta 0:23:14
epoch [5/50] batch [200/246] time 0.131 (0.125) data 0.001 (0.002) loss 1.9414 (1.9782) teacher_loss 0.9967 (1.1297) loss_zs_kd 0.3736 (0.3153) loss_oracle 0.3705 (0.3924) acc 71.8750 (70.3906) kd_loss 0.7595 (0.6523) lr 1.9823e-03 eta 0:23:14
epoch [5/50] batch [220/246] time 0.125 (0.126) data 0.000 (0.002) loss 2.3068 (1.9708) teacher_loss 1.4101 (1.1224) loss_zs_kd 0.2780 (0.3162) loss_oracle 0.3072 (0.3875) acc 65.6250 (70.5540) kd_loss 0.7430 (0.6547) lr 1.9823e-03 eta 0:23:13
epoch [5/50] batch [240/246] time 0.107 (0.125) data 0.000 (0.002) loss 2.0072 (1.9695) teacher_loss 1.1391 (1.1211) loss_zs_kd 0.2711 (0.3168) loss_oracle 0.3530 (0.3852) acc 71.8750 (70.5729) kd_loss 0.6916 (0.6558) lr 1.9823e-03 eta 0:23:05
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,834
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.6%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,953
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      84.5%, epoch: 5 *******
******* Domain r best val test acc: 90.7%, epoch: 5 *******
******* Domain r best test acc:     90.8%, epoch: 2 *******
epoch [6/50] batch [20/246] time 0.098 (0.112) data 0.000 (0.014) loss 2.0138 (2.0566) teacher_loss 1.0365 (1.1433) loss_zs_kd 0.3261 (0.3545) loss_oracle 0.3563 (0.3963) acc 78.1250 (72.8125) kd_loss 0.7991 (0.7152) lr 1.9686e-03 eta 0:20:36
epoch [6/50] batch [40/246] time 0.091 (0.105) data 0.000 (0.007) loss 2.2866 (1.9695) teacher_loss 1.3895 (1.1100) loss_zs_kd 0.3323 (0.3344) loss_oracle 0.3081 (0.3539) acc 62.5000 (72.0312) kd_loss 0.7431 (0.6825) lr 1.9686e-03 eta 0:19:18
epoch [6/50] batch [60/246] time 0.097 (0.102) data 0.000 (0.005) loss 1.9208 (1.9308) teacher_loss 1.1426 (1.0886) loss_zs_kd 0.2613 (0.3345) loss_oracle 0.3022 (0.3365) acc 71.8750 (72.1875) kd_loss 0.6272 (0.6740) lr 1.9686e-03 eta 0:18:44
epoch [6/50] batch [80/246] time 0.102 (0.100) data 0.000 (0.004) loss 1.8855 (1.9368) teacher_loss 1.0845 (1.0983) loss_zs_kd 0.2528 (0.3292) loss_oracle 0.3068 (0.3363) acc 81.2500 (71.7188) kd_loss 0.6475 (0.6703) lr 1.9686e-03 eta 0:18:23
epoch [6/50] batch [100/246] time 0.096 (0.099) data 0.000 (0.003) loss 2.1330 (1.9143) teacher_loss 1.3621 (1.0888) loss_zs_kd 0.3216 (0.3324) loss_oracle 0.2328 (0.3257) acc 59.3750 (71.9062) kd_loss 0.6546 (0.6626) lr 1.9686e-03 eta 0:18:11
epoch [6/50] batch [120/246] time 0.094 (0.099) data 0.000 (0.003) loss 1.5480 (1.8752) teacher_loss 0.8657 (1.0704) loss_zs_kd 0.3918 (0.3379) loss_oracle 0.2885 (0.3147) acc 75.0000 (72.5260) kd_loss 0.5381 (0.6475) lr 1.9686e-03 eta 0:18:02
epoch [6/50] batch [140/246] time 0.088 (0.098) data 0.000 (0.002) loss 1.8053 (1.8642) teacher_loss 1.0019 (1.0738) loss_zs_kd 0.2645 (0.3348) loss_oracle 0.3455 (0.3131) acc 71.8750 (72.4107) kd_loss 0.6306 (0.6338) lr 1.9686e-03 eta 0:17:53
epoch [6/50] batch [160/246] time 0.093 (0.098) data 0.000 (0.002) loss 1.7752 (1.8843) teacher_loss 1.0313 (1.0936) loss_zs_kd 0.3202 (0.3393) loss_oracle 0.3746 (0.3224) acc 71.8750 (72.0312) kd_loss 0.5566 (0.6295) lr 1.9686e-03 eta 0:17:50
epoch [6/50] batch [180/246] time 0.107 (0.098) data 0.000 (0.002) loss 2.3671 (1.8842) teacher_loss 1.4268 (1.0907) loss_zs_kd 0.3975 (0.3422) loss_oracle 0.4408 (0.3303) acc 65.6250 (72.0833) kd_loss 0.7199 (0.6284) lr 1.9686e-03 eta 0:17:46
epoch [6/50] batch [200/246] time 0.102 (0.098) data 0.000 (0.002) loss 1.6170 (1.8835) teacher_loss 0.9024 (1.0845) loss_zs_kd 0.2340 (0.3415) loss_oracle 0.3542 (0.3362) acc 75.0000 (72.2031) kd_loss 0.5374 (0.6309) lr 1.9686e-03 eta 0:17:45
epoch [6/50] batch [220/246] time 0.101 (0.098) data 0.000 (0.001) loss 2.1892 (1.8943) teacher_loss 1.2674 (1.0855) loss_zs_kd 0.4159 (0.3402) loss_oracle 0.3635 (0.3440) acc 68.7500 (72.0170) kd_loss 0.7401 (0.6368) lr 1.9686e-03 eta 0:17:45
epoch [6/50] batch [240/246] time 0.087 (0.098) data 0.000 (0.001) loss 1.9804 (1.9019) teacher_loss 1.0079 (1.0844) loss_zs_kd 0.2016 (0.3362) loss_oracle 0.3412 (0.3483) acc 71.8750 (71.9141) kd_loss 0.8020 (0.6433) lr 1.9686e-03 eta 0:17:40
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,830
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.6%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.5%, epoch: 5 *******
******* Domain r best val test acc: 90.7%, epoch: 5 *******
******* Domain r best test acc:     90.8%, epoch: 6 *******
epoch [7/50] batch [20/246] time 0.105 (0.131) data 0.000 (0.020) loss 2.2883 (2.0636) teacher_loss 1.4594 (1.2073) loss_zs_kd 0.3071 (0.3061) loss_oracle 0.2562 (0.3375) acc 56.2500 (66.2500) kd_loss 0.7008 (0.6875) lr 1.9511e-03 eta 0:23:36
epoch [7/50] batch [40/246] time 0.105 (0.118) data 0.001 (0.010) loss 1.5335 (1.9506) teacher_loss 0.6614 (1.1088) loss_zs_kd 0.2525 (0.3134) loss_oracle 0.3361 (0.3481) acc 78.1250 (70.0000) kd_loss 0.7040 (0.6677) lr 1.9511e-03 eta 0:21:07
epoch [7/50] batch [60/246] time 0.104 (0.113) data 0.001 (0.007) loss 1.4481 (1.8968) teacher_loss 0.5291 (1.0908) loss_zs_kd 0.3040 (0.3279) loss_oracle 0.2719 (0.3324) acc 90.6250 (70.7812) kd_loss 0.7831 (0.6398) lr 1.9511e-03 eta 0:20:16
epoch [7/50] batch [80/246] time 0.105 (0.110) data 0.000 (0.005) loss 1.7084 (1.9033) teacher_loss 0.9122 (1.0976) loss_zs_kd 0.2925 (0.3358) loss_oracle 0.2986 (0.3306) acc 75.0000 (70.4297) kd_loss 0.6469 (0.6404) lr 1.9511e-03 eta 0:19:44
epoch [7/50] batch [100/246] time 0.119 (0.109) data 0.000 (0.004) loss 1.6656 (1.8989) teacher_loss 0.8680 (1.0961) loss_zs_kd 0.3251 (0.3388) loss_oracle 0.2719 (0.3255) acc 81.2500 (70.6875) kd_loss 0.6616 (0.6400) lr 1.9511e-03 eta 0:19:23
epoch [7/50] batch [120/246] time 0.112 (0.108) data 0.000 (0.004) loss 1.4068 (1.8810) teacher_loss 0.6400 (1.0718) loss_zs_kd 0.3739 (0.3353) loss_oracle 0.2991 (0.3241) acc 84.3750 (71.5365) kd_loss 0.6173 (0.6471) lr 1.9511e-03 eta 0:19:12
epoch [7/50] batch [140/246] time 0.113 (0.107) data 0.001 (0.003) loss 1.3707 (1.8800) teacher_loss 0.4654 (1.0686) loss_zs_kd 0.1755 (0.3357) loss_oracle 0.3647 (0.3243) acc 90.6250 (71.7188) kd_loss 0.7229 (0.6493) lr 1.9511e-03 eta 0:19:05
epoch [7/50] batch [160/246] time 0.105 (0.107) data 0.000 (0.003) loss 2.1334 (1.9039) teacher_loss 1.3088 (1.0827) loss_zs_kd 0.5020 (0.3398) loss_oracle 0.3300 (0.3267) acc 65.6250 (71.4258) kd_loss 0.6596 (0.6578) lr 1.9511e-03 eta 0:19:00
epoch [7/50] batch [180/246] time 0.124 (0.107) data 0.000 (0.003) loss 2.2125 (1.9137) teacher_loss 1.2730 (1.0858) loss_zs_kd 0.3997 (0.3398) loss_oracle 0.3545 (0.3305) acc 65.6250 (71.2847) kd_loss 0.7622 (0.6626) lr 1.9511e-03 eta 0:19:01
epoch [7/50] batch [200/246] time 0.103 (0.107) data 0.000 (0.002) loss 1.7815 (1.9135) teacher_loss 0.9329 (1.0839) loss_zs_kd 0.4126 (0.3388) loss_oracle 0.3475 (0.3292) acc 84.3750 (71.4062) kd_loss 0.6748 (0.6650) lr 1.9511e-03 eta 0:19:01
epoch [7/50] batch [220/246] time 0.099 (0.108) data 0.001 (0.002) loss 2.3133 (1.9067) teacher_loss 1.4649 (1.0822) loss_zs_kd 0.3529 (0.3385) loss_oracle 0.2504 (0.3225) acc 62.5000 (71.3494) kd_loss 0.7232 (0.6633) lr 1.9511e-03 eta 0:19:01
epoch [7/50] batch [240/246] time 0.104 (0.107) data 0.000 (0.002) loss 1.6891 (1.9024) teacher_loss 0.7372 (1.0775) loss_zs_kd 0.3305 (0.3399) loss_oracle 0.3711 (0.3207) acc 84.3750 (71.4323) kd_loss 0.7663 (0.6645) lr 1.9511e-03 eta 0:18:51
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,840
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,960
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.7%, epoch: 7 *******
******* Domain r best val test acc: 90.9%, epoch: 7 *******
******* Domain r best test acc:     90.9%, epoch: 7 *******
epoch [8/50] batch [20/246] time 0.104 (0.129) data 0.000 (0.022) loss 1.6953 (1.9017) teacher_loss 1.0737 (1.0715) loss_zs_kd 0.4479 (0.3558) loss_oracle 0.2938 (0.3187) acc 71.8750 (71.0938) kd_loss 0.4748 (0.6709) lr 1.9298e-03 eta 0:22:37
epoch [8/50] batch [40/246] time 0.089 (0.113) data 0.000 (0.011) loss 2.1160 (1.9260) teacher_loss 1.2090 (1.0999) loss_zs_kd 0.3435 (0.3546) loss_oracle 0.4220 (0.3192) acc 68.7500 (71.4062) kd_loss 0.6960 (0.6665) lr 1.9298e-03 eta 0:19:45
epoch [8/50] batch [60/246] time 0.103 (0.107) data 0.000 (0.007) loss 2.0820 (1.8950) teacher_loss 1.3103 (1.0818) loss_zs_kd 0.4495 (0.3532) loss_oracle 0.2068 (0.3094) acc 62.5000 (71.8750) kd_loss 0.6683 (0.6585) lr 1.9298e-03 eta 0:18:46
epoch [8/50] batch [80/246] time 0.095 (0.104) data 0.000 (0.006) loss 1.2741 (1.8668) teacher_loss 0.6333 (1.0760) loss_zs_kd 0.2018 (0.3520) loss_oracle 0.1906 (0.2940) acc 84.3750 (72.3047) kd_loss 0.5455 (0.6439) lr 1.9298e-03 eta 0:18:14
epoch [8/50] batch [100/246] time 0.105 (0.103) data 0.000 (0.004) loss 1.7910 (1.8759) teacher_loss 1.0464 (1.0928) loss_zs_kd 0.4950 (0.3499) loss_oracle 0.2440 (0.2881) acc 75.0000 (71.6562) kd_loss 0.6225 (0.6391) lr 1.9298e-03 eta 0:18:03
epoch [8/50] batch [120/246] time 0.109 (0.103) data 0.000 (0.004) loss 2.1697 (1.8573) teacher_loss 1.4298 (1.0806) loss_zs_kd 0.3770 (0.3523) loss_oracle 0.3578 (0.2883) acc 65.6250 (72.1094) kd_loss 0.5610 (0.6326) lr 1.9298e-03 eta 0:18:01
epoch [8/50] batch [140/246] time 0.108 (0.104) data 0.000 (0.003) loss 1.8196 (1.8679) teacher_loss 1.0586 (1.0915) loss_zs_kd 0.2764 (0.3545) loss_oracle 0.3541 (0.2943) acc 65.6250 (71.9196) kd_loss 0.5839 (0.6292) lr 1.9298e-03 eta 0:18:01
epoch [8/50] batch [160/246] time 0.101 (0.103) data 0.000 (0.003) loss 2.1514 (1.8680) teacher_loss 1.3417 (1.0927) loss_zs_kd 0.4269 (0.3555) loss_oracle 0.2719 (0.2933) acc 68.7500 (71.8945) kd_loss 0.6738 (0.6287) lr 1.9298e-03 eta 0:17:56
epoch [8/50] batch [180/246] time 0.103 (0.103) data 0.000 (0.003) loss 2.1085 (1.8581) teacher_loss 1.3372 (1.0853) loss_zs_kd 0.3866 (0.3533) loss_oracle 0.2979 (0.2914) acc 62.5000 (71.9618) kd_loss 0.6223 (0.6271) lr 1.9298e-03 eta 0:17:53
epoch [8/50] batch [200/246] time 0.099 (0.103) data 0.000 (0.002) loss 1.7607 (1.8585) teacher_loss 1.0207 (1.0882) loss_zs_kd 0.3343 (0.3520) loss_oracle 0.3207 (0.2887) acc 71.8750 (71.7969) kd_loss 0.5797 (0.6259) lr 1.9298e-03 eta 0:17:48
epoch [8/50] batch [220/246] time 0.097 (0.103) data 0.000 (0.002) loss 2.1058 (1.8614) teacher_loss 1.0937 (1.0894) loss_zs_kd 0.2565 (0.3553) loss_oracle 0.3517 (0.2907) acc 78.1250 (71.7045) kd_loss 0.8362 (0.6267) lr 1.9298e-03 eta 0:17:45
epoch [8/50] batch [240/246] time 0.107 (0.103) data 0.000 (0.002) loss 1.5543 (1.8612) teacher_loss 0.8310 (1.0890) loss_zs_kd 0.4312 (0.3576) loss_oracle 0.2569 (0.2904) acc 78.1250 (71.5495) kd_loss 0.5949 (0.6270) lr 1.9298e-03 eta 0:17:45
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,846
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      84.9%, epoch: 8 *******
******* Domain r best val test acc: 90.7%, epoch: 8 *******
******* Domain r best test acc:     90.9%, epoch: 7 *******
epoch [9/50] batch [20/246] time 0.088 (0.114) data 0.000 (0.014) loss 1.5012 (1.9040) teacher_loss 0.7359 (1.1026) loss_zs_kd 0.4428 (0.3679) loss_oracle 0.2108 (0.2550) acc 78.1250 (71.5625) kd_loss 0.6599 (0.6739) lr 1.9048e-03 eta 0:19:36
epoch [9/50] batch [40/246] time 0.094 (0.104) data 0.000 (0.007) loss 1.9646 (1.9263) teacher_loss 1.2789 (1.1143) loss_zs_kd 0.3024 (0.3704) loss_oracle 0.2851 (0.2644) acc 71.8750 (71.2500) kd_loss 0.5432 (0.6798) lr 1.9048e-03 eta 0:17:47
epoch [9/50] batch [60/246] time 0.096 (0.101) data 0.000 (0.005) loss 1.9409 (1.9116) teacher_loss 1.2547 (1.1193) loss_zs_kd 0.4672 (0.3781) loss_oracle 0.2121 (0.2629) acc 75.0000 (71.4583) kd_loss 0.5801 (0.6608) lr 1.9048e-03 eta 0:17:18
epoch [9/50] batch [80/246] time 0.099 (0.100) data 0.000 (0.004) loss 1.7745 (1.9087) teacher_loss 1.1302 (1.1194) loss_zs_kd 0.4136 (0.3723) loss_oracle 0.1992 (0.2614) acc 62.5000 (71.4844) kd_loss 0.5447 (0.6586) lr 1.9048e-03 eta 0:17:05
epoch [9/50] batch [100/246] time 0.092 (0.099) data 0.000 (0.003) loss 1.5381 (1.8795) teacher_loss 0.8111 (1.0938) loss_zs_kd 0.2754 (0.3628) loss_oracle 0.3162 (0.2596) acc 75.0000 (71.8125) kd_loss 0.5689 (0.6558) lr 1.9048e-03 eta 0:16:54
epoch [9/50] batch [120/246] time 0.099 (0.099) data 0.001 (0.003) loss 2.1221 (1.9135) teacher_loss 1.1102 (1.1218) loss_zs_kd 0.2616 (0.3654) loss_oracle 0.2636 (0.2617) acc 65.6250 (70.8854) kd_loss 0.8801 (0.6609) lr 1.9048e-03 eta 0:16:50
epoch [9/50] batch [140/246] time 0.100 (0.099) data 0.000 (0.002) loss 2.2372 (1.9253) teacher_loss 1.3509 (1.1285) loss_zs_kd 0.3128 (0.3646) loss_oracle 0.3180 (0.2664) acc 65.6250 (70.6027) kd_loss 0.7273 (0.6636) lr 1.9048e-03 eta 0:16:47
epoch [9/50] batch [160/246] time 0.097 (0.099) data 0.000 (0.002) loss 1.9634 (1.9294) teacher_loss 1.0293 (1.1259) loss_zs_kd 0.3220 (0.3603) loss_oracle 0.2901 (0.2719) acc 75.0000 (70.5664) kd_loss 0.7890 (0.6675) lr 1.9048e-03 eta 0:16:43
epoch [9/50] batch [180/246] time 0.093 (0.098) data 0.000 (0.002) loss 1.9427 (1.9221) teacher_loss 1.0345 (1.1187) loss_zs_kd 0.3256 (0.3605) loss_oracle 0.3798 (0.2754) acc 68.7500 (70.7465) kd_loss 0.7183 (0.6657) lr 1.9048e-03 eta 0:16:39
epoch [9/50] batch [200/246] time 0.093 (0.098) data 0.000 (0.002) loss 1.7921 (1.9195) teacher_loss 1.0961 (1.1173) loss_zs_kd 0.3799 (0.3597) loss_oracle 0.3031 (0.2796) acc 65.6250 (70.8281) kd_loss 0.5444 (0.6624) lr 1.9048e-03 eta 0:16:35
epoch [9/50] batch [220/246] time 0.099 (0.098) data 0.000 (0.001) loss 1.9533 (1.9138) teacher_loss 0.9580 (1.1126) loss_zs_kd 0.3762 (0.3626) loss_oracle 0.3541 (0.2839) acc 78.1250 (70.9801) kd_loss 0.8183 (0.6592) lr 1.9048e-03 eta 0:16:32
epoch [9/50] batch [240/246] time 0.089 (0.098) data 0.000 (0.001) loss 1.7760 (1.9168) teacher_loss 0.9923 (1.1141) loss_zs_kd 0.3531 (0.3639) loss_oracle 0.2462 (0.2864) acc 71.8750 (70.8724) kd_loss 0.6607 (0.6595) lr 1.9048e-03 eta 0:16:25
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,849
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,950
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.5%
******* Domain r best val acc:      84.9%, epoch: 9 *******
******* Domain r best val test acc: 90.7%, epoch: 9 *******
******* Domain r best test acc:     90.9%, epoch: 7 *******
epoch [10/50] batch [20/246] time 0.096 (0.114) data 0.000 (0.013) loss 1.5761 (1.9179) teacher_loss 0.9276 (1.1210) loss_zs_kd 0.2764 (0.3857) loss_oracle 0.2519 (0.2986) acc 75.0000 (71.2500) kd_loss 0.5225 (0.6476) lr 1.8763e-03 eta 0:19:07
epoch [10/50] batch [40/246] time 0.098 (0.105) data 0.000 (0.007) loss 2.1209 (1.9025) teacher_loss 1.3878 (1.1044) loss_zs_kd 0.3058 (0.3708) loss_oracle 0.2865 (0.3029) acc 68.7500 (70.9375) kd_loss 0.5898 (0.6466) lr 1.8763e-03 eta 0:17:38
epoch [10/50] batch [60/246] time 0.105 (0.102) data 0.001 (0.004) loss 1.5473 (1.8805) teacher_loss 0.8429 (1.0697) loss_zs_kd 0.3243 (0.3725) loss_oracle 0.2955 (0.3059) acc 75.0000 (71.4583) kd_loss 0.5566 (0.6578) lr 1.8763e-03 eta 0:17:05
epoch [10/50] batch [80/246] time 0.097 (0.101) data 0.000 (0.003) loss 2.0722 (1.8798) teacher_loss 1.2426 (1.0659) loss_zs_kd 0.5139 (0.3689) loss_oracle 0.3731 (0.3059) acc 56.2500 (71.6406) kd_loss 0.6431 (0.6609) lr 1.8763e-03 eta 0:16:50
epoch [10/50] batch [100/246] time 0.092 (0.100) data 0.000 (0.003) loss 2.2516 (1.9002) teacher_loss 1.3863 (1.0746) loss_zs_kd 0.3379 (0.3685) loss_oracle 0.2263 (0.3062) acc 71.8750 (71.5625) kd_loss 0.7521 (0.6725) lr 1.8763e-03 eta 0:16:41
epoch [10/50] batch [120/246] time 0.092 (0.099) data 0.000 (0.002) loss 2.7180 (1.9286) teacher_loss 1.8480 (1.0953) loss_zs_kd 0.3341 (0.3702) loss_oracle 0.2932 (0.3059) acc 65.6250 (71.4323) kd_loss 0.7233 (0.6803) lr 1.8763e-03 eta 0:16:31
epoch [10/50] batch [140/246] time 0.099 (0.099) data 0.000 (0.002) loss 1.7629 (1.9562) teacher_loss 0.7077 (1.1013) loss_zs_kd 0.3379 (0.3685) loss_oracle 0.4709 (0.3196) acc 78.1250 (70.9821) kd_loss 0.8198 (0.6951) lr 1.8763e-03 eta 0:16:25
epoch [10/50] batch [160/246] time 0.092 (0.099) data 0.000 (0.002) loss 2.2856 (1.9676) teacher_loss 1.2616 (1.1005) loss_zs_kd 0.3926 (0.3684) loss_oracle 0.4716 (0.3323) acc 65.6250 (71.0547) kd_loss 0.7882 (0.7010) lr 1.8763e-03 eta 0:16:21
epoch [10/50] batch [180/246] time 0.101 (0.099) data 0.000 (0.002) loss 1.7572 (1.9744) teacher_loss 0.9272 (1.1044) loss_zs_kd 0.2318 (0.3711) loss_oracle 0.3333 (0.3365) acc 71.8750 (71.0938) kd_loss 0.6634 (0.7018) lr 1.8763e-03 eta 0:16:21
epoch [10/50] batch [200/246] time 0.105 (0.099) data 0.000 (0.002) loss 1.6780 (1.9715) teacher_loss 1.0074 (1.1021) loss_zs_kd 0.3630 (0.3707) loss_oracle 0.3256 (0.3383) acc 75.0000 (71.2812) kd_loss 0.5079 (0.7003) lr 1.8763e-03 eta 0:16:21
epoch [10/50] batch [220/246] time 0.116 (0.100) data 0.001 (0.001) loss 2.1966 (1.9588) teacher_loss 1.3973 (1.0958) loss_zs_kd 0.6076 (0.3703) loss_oracle 0.2571 (0.3356) acc 59.3750 (71.4489) kd_loss 0.6708 (0.6952) lr 1.8763e-03 eta 0:16:25
epoch [10/50] batch [240/246] time 0.109 (0.100) data 0.000 (0.001) loss 1.4925 (1.9560) teacher_loss 0.6622 (1.0938) loss_zs_kd 0.3495 (0.3715) loss_oracle 0.4097 (0.3384) acc 78.1250 (71.4583) kd_loss 0.6255 (0.6931) lr 1.8763e-03 eta 0:16:27
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,859
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.2%, epoch: 10 *******
******* Domain r best val test acc: 90.8%, epoch: 10 *******
******* Domain r best test acc:     90.9%, epoch: 7 *******
epoch [11/50] batch [20/246] time 0.091 (0.109) data 0.000 (0.013) loss 1.6920 (2.0063) teacher_loss 0.6800 (1.0706) loss_zs_kd 0.7140 (0.4031) loss_oracle 0.3428 (0.4047) acc 87.5000 (72.6562) kd_loss 0.8406 (0.7334) lr 1.8443e-03 eta 0:17:54
epoch [11/50] batch [40/246] time 0.106 (0.104) data 0.000 (0.007) loss 1.8409 (1.9431) teacher_loss 1.1103 (1.0499) loss_zs_kd 0.4492 (0.3959) loss_oracle 0.3400 (0.3837) acc 71.8750 (72.6562) kd_loss 0.5606 (0.7014) lr 1.8443e-03 eta 0:16:59
epoch [11/50] batch [60/246] time 0.091 (0.103) data 0.000 (0.005) loss 2.1117 (1.9624) teacher_loss 0.9966 (1.0410) loss_zs_kd 0.4948 (0.4091) loss_oracle 0.5041 (0.3954) acc 75.0000 (72.4479) kd_loss 0.8631 (0.7236) lr 1.8443e-03 eta 0:16:50
epoch [11/50] batch [80/246] time 0.105 (0.103) data 0.000 (0.004) loss 1.8765 (1.9753) teacher_loss 0.9413 (1.0379) loss_zs_kd 0.4358 (0.4134) loss_oracle 0.4732 (0.4096) acc 81.2500 (72.5000) kd_loss 0.6986 (0.7326) lr 1.8443e-03 eta 0:16:47
epoch [11/50] batch [100/246] time 0.108 (0.104) data 0.000 (0.003) loss 2.2280 (1.9957) teacher_loss 1.1086 (1.0480) loss_zs_kd 0.4087 (0.4238) loss_oracle 0.6208 (0.4239) acc 71.8750 (72.5000) kd_loss 0.8090 (0.7357) lr 1.8443e-03 eta 0:16:48
epoch [11/50] batch [120/246] time 0.109 (0.104) data 0.000 (0.002) loss 1.5476 (1.9819) teacher_loss 0.6929 (1.0304) loss_zs_kd 0.3342 (0.4217) loss_oracle 0.4100 (0.4324) acc 81.2500 (73.0208) kd_loss 0.6497 (0.7353) lr 1.8443e-03 eta 0:16:51
epoch [11/50] batch [140/246] time 0.101 (0.104) data 0.000 (0.002) loss 1.8995 (1.9879) teacher_loss 0.9529 (1.0366) loss_zs_kd 0.3883 (0.4220) loss_oracle 0.3644 (0.4246) acc 81.2500 (72.8571) kd_loss 0.7644 (0.7391) lr 1.8443e-03 eta 0:16:46
epoch [11/50] batch [160/246] time 0.104 (0.104) data 0.001 (0.002) loss 2.2829 (1.9997) teacher_loss 1.2330 (1.0388) loss_zs_kd 0.3874 (0.4193) loss_oracle 0.4835 (0.4253) acc 68.7500 (72.7734) kd_loss 0.8082 (0.7483) lr 1.8443e-03 eta 0:16:43
epoch [11/50] batch [180/246] time 0.099 (0.104) data 0.001 (0.002) loss 1.8839 (1.9919) teacher_loss 0.8568 (1.0296) loss_zs_kd 0.3114 (0.4151) loss_oracle 0.4295 (0.4299) acc 75.0000 (72.9688) kd_loss 0.8123 (0.7473) lr 1.8443e-03 eta 0:16:40
epoch [11/50] batch [200/246] time 0.097 (0.103) data 0.000 (0.002) loss 1.9138 (1.9903) teacher_loss 1.0147 (1.0341) loss_zs_kd 0.2674 (0.4107) loss_oracle 0.4013 (0.4301) acc 68.7500 (72.9375) kd_loss 0.6985 (0.7411) lr 1.8443e-03 eta 0:16:35
epoch [11/50] batch [220/246] time 0.099 (0.103) data 0.000 (0.001) loss 1.8089 (1.9760) teacher_loss 0.9737 (1.0252) loss_zs_kd 0.3941 (0.4079) loss_oracle 0.3970 (0.4296) acc 71.8750 (73.0966) kd_loss 0.6367 (0.7360) lr 1.8443e-03 eta 0:16:27
epoch [11/50] batch [240/246] time 0.087 (0.102) data 0.000 (0.001) loss 2.0511 (1.9824) teacher_loss 0.8632 (1.0324) loss_zs_kd 0.3631 (0.4090) loss_oracle 0.4935 (0.4296) acc 78.1250 (72.9297) kd_loss 0.9411 (0.7351) lr 1.8443e-03 eta 0:16:16
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,866
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.5%, epoch: 11 *******
******* Domain r best val test acc: 90.8%, epoch: 11 *******
******* Domain r best test acc:     90.9%, epoch: 7 *******
epoch [12/50] batch [20/246] time 0.094 (0.111) data 0.000 (0.014) loss 1.7922 (1.8630) teacher_loss 0.9210 (1.0073) loss_zs_kd 0.3148 (0.4158) loss_oracle 0.3868 (0.4142) acc 68.7500 (73.5938) kd_loss 0.6778 (0.6487) lr 1.8090e-03 eta 0:17:45
epoch [12/50] batch [40/246] time 0.091 (0.104) data 0.000 (0.007) loss 2.5231 (1.9096) teacher_loss 1.6956 (1.0408) loss_zs_kd 0.4474 (0.4232) loss_oracle 0.2989 (0.4090) acc 50.0000 (72.2656) kd_loss 0.6780 (0.6643) lr 1.8090e-03 eta 0:16:31
epoch [12/50] batch [60/246] time 0.100 (0.101) data 0.000 (0.005) loss 2.3003 (1.9456) teacher_loss 1.4100 (1.0503) loss_zs_kd 0.4262 (0.4270) loss_oracle 0.3728 (0.4085) acc 62.5000 (71.9792) kd_loss 0.7039 (0.6910) lr 1.8090e-03 eta 0:15:59
epoch [12/50] batch [80/246] time 0.094 (0.100) data 0.001 (0.004) loss 1.9923 (1.9618) teacher_loss 0.9607 (1.0564) loss_zs_kd 0.3661 (0.4212) loss_oracle 0.5005 (0.4153) acc 68.7500 (72.0703) kd_loss 0.7814 (0.6977) lr 1.8090e-03 eta 0:15:48
epoch [12/50] batch [100/246] time 0.099 (0.099) data 0.000 (0.003) loss 2.1546 (1.9396) teacher_loss 1.3158 (1.0319) loss_zs_kd 0.4848 (0.4183) loss_oracle 0.3066 (0.4161) acc 65.6250 (72.7500) kd_loss 0.6855 (0.6997) lr 1.8090e-03 eta 0:15:40
epoch [12/50] batch [120/246] time 0.100 (0.099) data 0.000 (0.003) loss 1.4678 (1.9199) teacher_loss 0.7177 (1.0207) loss_zs_kd 0.3024 (0.4176) loss_oracle 0.3636 (0.4095) acc 84.3750 (73.0208) kd_loss 0.5684 (0.6945) lr 1.8090e-03 eta 0:15:35
epoch [12/50] batch [140/246] time 0.090 (0.099) data 0.000 (0.002) loss 2.0168 (1.9256) teacher_loss 1.3341 (1.0303) loss_zs_kd 0.3220 (0.4127) loss_oracle 0.3822 (0.4078) acc 75.0000 (73.1250) kd_loss 0.4916 (0.6914) lr 1.8090e-03 eta 0:15:32
epoch [12/50] batch [160/246] time 0.092 (0.098) data 0.000 (0.002) loss 2.2960 (1.9398) teacher_loss 1.3206 (1.0397) loss_zs_kd 0.4175 (0.4108) loss_oracle 0.3985 (0.4064) acc 65.6250 (72.5977) kd_loss 0.7762 (0.6970) lr 1.8090e-03 eta 0:15:27
epoch [12/50] batch [180/246] time 0.099 (0.098) data 0.000 (0.002) loss 1.6726 (1.9423) teacher_loss 0.8333 (1.0454) loss_zs_kd 0.3924 (0.4126) loss_oracle 0.3993 (0.4040) acc 81.2500 (72.5347) kd_loss 0.6396 (0.6949) lr 1.8090e-03 eta 0:15:23
epoch [12/50] batch [200/246] time 0.090 (0.098) data 0.000 (0.002) loss 1.9271 (1.9308) teacher_loss 0.9241 (1.0374) loss_zs_kd 0.6630 (0.4147) loss_oracle 0.2877 (0.4011) acc 78.1250 (72.6875) kd_loss 0.8592 (0.6929) lr 1.8090e-03 eta 0:15:20
epoch [12/50] batch [220/246] time 0.101 (0.098) data 0.000 (0.001) loss 1.6505 (1.9325) teacher_loss 0.8167 (1.0403) loss_zs_kd 0.4332 (0.4157) loss_oracle 0.4619 (0.3999) acc 84.3750 (72.4716) kd_loss 0.6029 (0.6922) lr 1.8090e-03 eta 0:15:16
epoch [12/50] batch [240/246] time 0.087 (0.097) data 0.000 (0.001) loss 1.8659 (1.9423) teacher_loss 0.9360 (1.0472) loss_zs_kd 0.3688 (0.4199) loss_oracle 0.4436 (0.4037) acc 75.0000 (72.1615) kd_loss 0.7080 (0.6932) lr 1.8090e-03 eta 0:15:10
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,853
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,950
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      85.5%, epoch: 11 *******
******* Domain r best val test acc: 90.8%, epoch: 11 *******
******* Domain r best test acc:     90.9%, epoch: 7 *******
epoch [13/50] batch [20/246] time 0.088 (0.117) data 0.000 (0.015) loss 2.0570 (1.9910) teacher_loss 0.9908 (1.0095) loss_zs_kd 0.4654 (0.4480) loss_oracle 0.4317 (0.4426) acc 75.0000 (73.4375) kd_loss 0.8503 (0.7602) lr 1.7705e-03 eta 0:18:08
epoch [13/50] batch [40/246] time 0.099 (0.106) data 0.000 (0.007) loss 2.1903 (1.9952) teacher_loss 1.0883 (1.0195) loss_zs_kd 0.3674 (0.4222) loss_oracle 0.5224 (0.4469) acc 78.1250 (73.6719) kd_loss 0.8408 (0.7523) lr 1.7705e-03 eta 0:16:22
epoch [13/50] batch [60/246] time 0.093 (0.102) data 0.000 (0.005) loss 2.1793 (1.9830) teacher_loss 1.3176 (1.0230) loss_zs_kd 0.4109 (0.4189) loss_oracle 0.3684 (0.4375) acc 62.5000 (73.8542) kd_loss 0.6775 (0.7412) lr 1.7705e-03 eta 0:15:49
epoch [13/50] batch [80/246] time 0.096 (0.100) data 0.000 (0.004) loss 1.6404 (1.9662) teacher_loss 0.8759 (1.0259) loss_zs_kd 0.4586 (0.4214) loss_oracle 0.3394 (0.4168) acc 81.2500 (73.5547) kd_loss 0.5947 (0.7318) lr 1.7705e-03 eta 0:15:31
epoch [13/50] batch [100/246] time 0.098 (0.100) data 0.000 (0.003) loss 1.4251 (1.9387) teacher_loss 0.7144 (1.0257) loss_zs_kd 0.5697 (0.4262) loss_oracle 0.2948 (0.3997) acc 84.3750 (73.3125) kd_loss 0.5632 (0.7131) lr 1.7705e-03 eta 0:15:20
epoch [13/50] batch [120/246] time 0.096 (0.099) data 0.000 (0.003) loss 1.5144 (1.9162) teacher_loss 0.5829 (1.0134) loss_zs_kd 0.3958 (0.4267) loss_oracle 0.4585 (0.3930) acc 81.2500 (73.6979) kd_loss 0.7022 (0.7063) lr 1.7705e-03 eta 0:15:11
epoch [13/50] batch [140/246] time 0.100 (0.099) data 0.000 (0.002) loss 2.1175 (1.9232) teacher_loss 1.0847 (1.0212) loss_zs_kd 0.3591 (0.4285) loss_oracle 0.3603 (0.3903) acc 75.0000 (73.3482) kd_loss 0.8526 (0.7068) lr 1.7705e-03 eta 0:15:07
epoch [13/50] batch [160/246] time 0.097 (0.099) data 0.000 (0.002) loss 2.4018 (1.9282) teacher_loss 1.4895 (1.0331) loss_zs_kd 0.6158 (0.4319) loss_oracle 0.4498 (0.3884) acc 53.1250 (72.9297) kd_loss 0.6874 (0.7008) lr 1.7705e-03 eta 0:15:08
epoch [13/50] batch [180/246] time 0.103 (0.099) data 0.001 (0.002) loss 2.4440 (1.9263) teacher_loss 1.7667 (1.0329) loss_zs_kd 0.3800 (0.4319) loss_oracle 0.3703 (0.3864) acc 56.2500 (72.8993) kd_loss 0.4922 (0.7001) lr 1.7705e-03 eta 0:15:08
epoch [13/50] batch [200/246] time 0.112 (0.099) data 0.000 (0.002) loss 2.2144 (1.9326) teacher_loss 1.2095 (1.0370) loss_zs_kd 0.5327 (0.4349) loss_oracle 0.5184 (0.3858) acc 71.8750 (72.9375) kd_loss 0.7457 (0.7027) lr 1.7705e-03 eta 0:15:09
epoch [13/50] batch [220/246] time 0.108 (0.100) data 0.000 (0.002) loss 1.9263 (1.9179) teacher_loss 0.7822 (1.0245) loss_zs_kd 0.4344 (0.4320) loss_oracle 0.4540 (0.3838) acc 84.3750 (73.1676) kd_loss 0.9171 (0.7015) lr 1.7705e-03 eta 0:15:10
epoch [13/50] batch [240/246] time 0.108 (0.100) data 0.000 (0.001) loss 1.7805 (1.9119) teacher_loss 0.9568 (1.0218) loss_zs_kd 0.4583 (0.4293) loss_oracle 0.3633 (0.3812) acc 81.2500 (73.3464) kd_loss 0.6421 (0.6995) lr 1.7705e-03 eta 0:15:11
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,858
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 11 *******
******* Domain r best val test acc: 90.8%, epoch: 11 *******
******* Domain r best test acc:     90.9%, epoch: 7 *******
epoch [14/50] batch [20/246] time 0.097 (0.135) data 0.000 (0.017) loss 1.7246 (1.9855) teacher_loss 0.6281 (1.0719) loss_zs_kd 0.2729 (0.4071) loss_oracle 0.4301 (0.4008) acc 78.1250 (70.3125) kd_loss 0.8814 (0.7132) lr 1.7290e-03 eta 0:20:27
epoch [14/50] batch [40/246] time 0.100 (0.120) data 0.000 (0.008) loss 2.4777 (1.9100) teacher_loss 1.5451 (1.0063) loss_zs_kd 0.3891 (0.3987) loss_oracle 0.4534 (0.3999) acc 68.7500 (73.5938) kd_loss 0.7059 (0.7038) lr 1.7290e-03 eta 0:18:03
epoch [14/50] batch [60/246] time 0.107 (0.114) data 0.001 (0.006) loss 2.3096 (1.9582) teacher_loss 1.6427 (1.0480) loss_zs_kd 0.6235 (0.4068) loss_oracle 0.3359 (0.4072) acc 62.5000 (72.5521) kd_loss 0.4989 (0.7067) lr 1.7290e-03 eta 0:17:11
epoch [14/50] batch [80/246] time 0.103 (0.111) data 0.000 (0.004) loss 1.6335 (1.9404) teacher_loss 0.8143 (1.0355) loss_zs_kd 0.3953 (0.4091) loss_oracle 0.3944 (0.4031) acc 75.0000 (72.6562) kd_loss 0.6221 (0.7034) lr 1.7290e-03 eta 0:16:43
epoch [14/50] batch [100/246] time 0.108 (0.110) data 0.000 (0.004) loss 1.7152 (1.9402) teacher_loss 0.9254 (1.0432) loss_zs_kd 0.5824 (0.4146) loss_oracle 0.3113 (0.3970) acc 71.8750 (72.3438) kd_loss 0.6341 (0.6986) lr 1.7290e-03 eta 0:16:31
epoch [14/50] batch [120/246] time 0.101 (0.108) data 0.000 (0.003) loss 1.8219 (1.9374) teacher_loss 0.7921 (1.0469) loss_zs_kd 0.4930 (0.4123) loss_oracle 0.4543 (0.3954) acc 75.0000 (72.3438) kd_loss 0.8027 (0.6928) lr 1.7290e-03 eta 0:16:12
epoch [14/50] batch [140/246] time 0.093 (0.107) data 0.000 (0.003) loss 2.3880 (1.9412) teacher_loss 1.5037 (1.0506) loss_zs_kd 0.4387 (0.4121) loss_oracle 0.3834 (0.3952) acc 62.5000 (72.2991) kd_loss 0.6925 (0.6930) lr 1.7290e-03 eta 0:15:55
epoch [14/50] batch [160/246] time 0.095 (0.105) data 0.000 (0.002) loss 1.8846 (1.9335) teacher_loss 0.9816 (1.0478) loss_zs_kd 0.3815 (0.4118) loss_oracle 0.3889 (0.3924) acc 75.0000 (72.4414) kd_loss 0.7086 (0.6896) lr 1.7290e-03 eta 0:15:40
epoch [14/50] batch [180/246] time 0.095 (0.104) data 0.000 (0.002) loss 2.2934 (1.9197) teacher_loss 1.4773 (1.0399) loss_zs_kd 0.4618 (0.4136) loss_oracle 0.4667 (0.3894) acc 68.7500 (72.7431) kd_loss 0.5827 (0.6851) lr 1.7290e-03 eta 0:15:30
epoch [14/50] batch [200/246] time 0.099 (0.104) data 0.000 (0.002) loss 2.0594 (1.9177) teacher_loss 1.0651 (1.0417) loss_zs_kd 0.5009 (0.4155) loss_oracle 0.3699 (0.3885) acc 71.8750 (72.6719) kd_loss 0.8093 (0.6817) lr 1.7290e-03 eta 0:15:21
epoch [14/50] batch [220/246] time 0.092 (0.103) data 0.000 (0.002) loss 1.8722 (1.9146) teacher_loss 0.9503 (1.0341) loss_zs_kd 0.5287 (0.4176) loss_oracle 0.3316 (0.3897) acc 81.2500 (72.9261) kd_loss 0.7562 (0.6857) lr 1.7290e-03 eta 0:15:12
epoch [14/50] batch [240/246] time 0.089 (0.102) data 0.001 (0.002) loss 1.8965 (1.9124) teacher_loss 0.9163 (1.0276) loss_zs_kd 0.5104 (0.4191) loss_oracle 0.3550 (0.3916) acc 75.0000 (73.1771) kd_loss 0.8027 (0.6891) lr 1.7290e-03 eta 0:15:01
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,859
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,951
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      85.5%, epoch: 11 *******
******* Domain r best val test acc: 90.8%, epoch: 11 *******
******* Domain r best test acc:     90.9%, epoch: 7 *******
epoch [15/50] batch [20/246] time 0.100 (0.150) data 0.000 (0.016) loss 2.1751 (1.9495) teacher_loss 1.0653 (1.0477) loss_zs_kd 0.3863 (0.4380) loss_oracle 0.4784 (0.4205) acc 75.0000 (72.9688) kd_loss 0.8707 (0.6916) lr 1.6845e-03 eta 0:22:06
epoch [15/50] batch [40/246] time 0.119 (0.134) data 0.000 (0.008) loss 1.8953 (1.9503) teacher_loss 0.9983 (1.0378) loss_zs_kd 0.4640 (0.4295) loss_oracle 0.3836 (0.4297) acc 75.0000 (72.7344) kd_loss 0.7052 (0.6977) lr 1.6845e-03 eta 0:19:37
epoch [15/50] batch [60/246] time 0.102 (0.124) data 0.000 (0.006) loss 1.6048 (1.9209) teacher_loss 0.6859 (1.0303) loss_zs_kd 0.4528 (0.4361) loss_oracle 0.4300 (0.4154) acc 84.3750 (73.1250) kd_loss 0.7039 (0.6829) lr 1.6845e-03 eta 0:18:11
epoch [15/50] batch [80/246] time 0.099 (0.119) data 0.000 (0.004) loss 1.8625 (1.9050) teacher_loss 0.7752 (1.0102) loss_zs_kd 0.4514 (0.4442) loss_oracle 0.3895 (0.4124) acc 75.0000 (73.5547) kd_loss 0.8925 (0.6886) lr 1.6845e-03 eta 0:17:21
epoch [15/50] batch [100/246] time 0.098 (0.115) data 0.000 (0.003) loss 1.7502 (1.9122) teacher_loss 0.8384 (1.0061) loss_zs_kd 0.4121 (0.4458) loss_oracle 0.4144 (0.4192) acc 81.2500 (73.6875) kd_loss 0.7046 (0.6965) lr 1.6845e-03 eta 0:16:46
epoch [15/50] batch [120/246] time 0.099 (0.112) data 0.000 (0.003) loss 2.4227 (1.9177) teacher_loss 1.4058 (1.0084) loss_zs_kd 0.3358 (0.4477) loss_oracle 0.4067 (0.4256) acc 62.5000 (73.7760) kd_loss 0.8136 (0.6964) lr 1.6845e-03 eta 0:16:22
epoch [15/50] batch [140/246] time 0.098 (0.111) data 0.000 (0.003) loss 2.0457 (1.9343) teacher_loss 1.1845 (1.0186) loss_zs_kd 0.4442 (0.4490) loss_oracle 0.3301 (0.4279) acc 68.7500 (73.3929) kd_loss 0.6961 (0.7018) lr 1.6845e-03 eta 0:16:05
epoch [15/50] batch [160/246] time 0.106 (0.109) data 0.001 (0.002) loss 2.2363 (1.9484) teacher_loss 1.3018 (1.0287) loss_zs_kd 0.4786 (0.4456) loss_oracle 0.4334 (0.4265) acc 62.5000 (73.3008) kd_loss 0.7178 (0.7064) lr 1.6845e-03 eta 0:15:51
epoch [15/50] batch [180/246] time 0.095 (0.108) data 0.000 (0.002) loss 2.4256 (1.9437) teacher_loss 1.4423 (1.0164) loss_zs_kd 0.5123 (0.4413) loss_oracle 0.4488 (0.4280) acc 59.3750 (73.5417) kd_loss 0.7588 (0.7134) lr 1.6845e-03 eta 0:15:39
epoch [15/50] batch [200/246] time 0.101 (0.108) data 0.000 (0.002) loss 1.6984 (1.9509) teacher_loss 0.8082 (1.0210) loss_zs_kd 0.3796 (0.4393) loss_oracle 0.3564 (0.4286) acc 75.0000 (73.3594) kd_loss 0.7120 (0.7157) lr 1.6845e-03 eta 0:15:31
epoch [15/50] batch [220/246] time 0.097 (0.107) data 0.000 (0.002) loss 2.3928 (1.9556) teacher_loss 1.5820 (1.0232) loss_zs_kd 0.4791 (0.4396) loss_oracle 0.3518 (0.4303) acc 62.5000 (73.2670) kd_loss 0.6349 (0.7173) lr 1.6845e-03 eta 0:15:23
epoch [15/50] batch [240/246] time 0.108 (0.107) data 0.000 (0.002) loss 1.8448 (1.9612) teacher_loss 0.8755 (1.0277) loss_zs_kd 0.3948 (0.4404) loss_oracle 0.4564 (0.4307) acc 75.0000 (73.2031) kd_loss 0.7410 (0.7181) lr 1.6845e-03 eta 0:15:19
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,868
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.7%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.5%, epoch: 15 *******
******* Domain r best val test acc: 90.8%, epoch: 15 *******
******* Domain r best test acc:     90.9%, epoch: 7 *******
epoch [16/50] batch [20/246] time 0.102 (0.134) data 0.000 (0.014) loss 1.5903 (2.0226) teacher_loss 0.4916 (1.0284) loss_zs_kd 0.5083 (0.4348) loss_oracle 0.4583 (0.4639) acc 90.6250 (72.3438) kd_loss 0.8695 (0.7622) lr 1.6374e-03 eta 0:19:08
epoch [16/50] batch [40/246] time 0.099 (0.117) data 0.000 (0.007) loss 1.7390 (2.0062) teacher_loss 0.7800 (1.0300) loss_zs_kd 0.5547 (0.4358) loss_oracle 0.4241 (0.4569) acc 81.2500 (72.5781) kd_loss 0.7470 (0.7477) lr 1.6374e-03 eta 0:16:39
epoch [16/50] batch [60/246] time 0.102 (0.112) data 0.000 (0.005) loss 2.3187 (2.0113) teacher_loss 1.5541 (1.0560) loss_zs_kd 0.4463 (0.4450) loss_oracle 0.4089 (0.4518) acc 59.3750 (72.1875) kd_loss 0.5602 (0.7294) lr 1.6374e-03 eta 0:15:57
epoch [16/50] batch [80/246] time 0.102 (0.110) data 0.000 (0.004) loss 2.1859 (2.0279) teacher_loss 1.2747 (1.0768) loss_zs_kd 0.5444 (0.4425) loss_oracle 0.3416 (0.4470) acc 65.6250 (71.6016) kd_loss 0.7404 (0.7276) lr 1.6374e-03 eta 0:15:35
epoch [16/50] batch [100/246] time 0.100 (0.108) data 0.000 (0.003) loss 1.7398 (2.0029) teacher_loss 0.8782 (1.0597) loss_zs_kd 0.6145 (0.4446) loss_oracle 0.3875 (0.4416) acc 75.0000 (72.2812) kd_loss 0.6678 (0.7224) lr 1.6374e-03 eta 0:15:17
epoch [16/50] batch [120/246] time 0.096 (0.106) data 0.000 (0.003) loss 1.7514 (1.9840) teacher_loss 0.7696 (1.0499) loss_zs_kd 0.5024 (0.4491) loss_oracle 0.4189 (0.4348) acc 71.8750 (72.5781) kd_loss 0.7723 (0.7167) lr 1.6374e-03 eta 0:15:04
epoch [16/50] batch [140/246] time 0.098 (0.106) data 0.000 (0.002) loss 1.7607 (1.9854) teacher_loss 0.8771 (1.0518) loss_zs_kd 0.3615 (0.4486) loss_oracle 0.3571 (0.4316) acc 78.1250 (72.6116) kd_loss 0.7051 (0.7178) lr 1.6374e-03 eta 0:14:54
epoch [16/50] batch [160/246] time 0.095 (0.105) data 0.000 (0.002) loss 2.6238 (1.9790) teacher_loss 1.6020 (1.0480) loss_zs_kd 0.4719 (0.4475) loss_oracle 0.4792 (0.4316) acc 59.3750 (72.5195) kd_loss 0.7822 (0.7152) lr 1.6374e-03 eta 0:14:46
epoch [16/50] batch [180/246] time 0.099 (0.104) data 0.000 (0.002) loss 2.0891 (1.9745) teacher_loss 1.0550 (1.0382) loss_zs_kd 0.4009 (0.4466) loss_oracle 0.4578 (0.4342) acc 75.0000 (72.9514) kd_loss 0.8052 (0.7192) lr 1.6374e-03 eta 0:14:35
epoch [16/50] batch [200/246] time 0.101 (0.103) data 0.000 (0.002) loss 1.7612 (1.9808) teacher_loss 0.7152 (1.0423) loss_zs_kd 0.4756 (0.4508) loss_oracle 0.4486 (0.4370) acc 84.3750 (73.0000) kd_loss 0.8217 (0.7200) lr 1.6374e-03 eta 0:14:27
epoch [16/50] batch [220/246] time 0.100 (0.103) data 0.000 (0.002) loss 2.0346 (1.9779) teacher_loss 1.0773 (1.0349) loss_zs_kd 0.4482 (0.4514) loss_oracle 0.4871 (0.4414) acc 78.1250 (73.1960) kd_loss 0.7138 (0.7223) lr 1.6374e-03 eta 0:14:22
epoch [16/50] batch [240/246] time 0.106 (0.103) data 0.000 (0.001) loss 2.1438 (1.9752) teacher_loss 1.1495 (1.0326) loss_zs_kd 0.3570 (0.4512) loss_oracle 0.4709 (0.4394) acc 71.8750 (73.2292) kd_loss 0.7589 (0.7229) lr 1.6374e-03 eta 0:14:20
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,881
* accuracy: 85.9%
* error: 14.1%
* macro_f1: 85.0%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,948
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      85.9%, epoch: 16 *******
******* Domain r best val test acc: 90.6%, epoch: 16 *******
******* Domain r best test acc:     90.9%, epoch: 7 *******
epoch [17/50] batch [20/246] time 0.094 (0.128) data 0.000 (0.014) loss 1.7427 (1.9010) teacher_loss 0.8512 (1.0415) loss_zs_kd 0.2378 (0.4482) loss_oracle 0.4262 (0.4070) acc 71.8750 (72.9688) kd_loss 0.6784 (0.6560) lr 1.5878e-03 eta 0:17:50
epoch [17/50] batch [40/246] time 0.090 (0.112) data 0.000 (0.007) loss 1.5288 (1.8981) teacher_loss 0.6340 (1.0206) loss_zs_kd 0.3170 (0.4465) loss_oracle 0.4044 (0.3985) acc 75.0000 (72.8125) kd_loss 0.6927 (0.6783) lr 1.5878e-03 eta 0:15:30
epoch [17/50] batch [60/246] time 0.093 (0.107) data 0.000 (0.005) loss 1.6180 (1.8806) teacher_loss 0.6982 (1.0067) loss_zs_kd 0.5792 (0.4468) loss_oracle 0.3706 (0.3964) acc 84.3750 (73.3854) kd_loss 0.7344 (0.6757) lr 1.5878e-03 eta 0:14:44
epoch [17/50] batch [80/246] time 0.099 (0.105) data 0.000 (0.004) loss 1.6644 (1.9007) teacher_loss 0.8816 (1.0249) loss_zs_kd 0.3731 (0.4419) loss_oracle 0.3676 (0.3895) acc 78.1250 (72.8906) kd_loss 0.5989 (0.6810) lr 1.5878e-03 eta 0:14:33
epoch [17/50] batch [100/246] time 0.103 (0.104) data 0.000 (0.003) loss 1.9524 (1.9099) teacher_loss 1.0605 (1.0201) loss_zs_kd 0.4315 (0.4507) loss_oracle 0.4587 (0.4002) acc 68.7500 (73.0938) kd_loss 0.6627 (0.6897) lr 1.5878e-03 eta 0:14:19
epoch [17/50] batch [120/246] time 0.097 (0.104) data 0.000 (0.003) loss 1.4331 (1.9097) teacher_loss 0.6699 (1.0092) loss_zs_kd 0.5710 (0.4560) loss_oracle 0.3995 (0.4075) acc 84.3750 (73.4896) kd_loss 0.5634 (0.6967) lr 1.5878e-03 eta 0:14:14
epoch [17/50] batch [140/246] time 0.102 (0.103) data 0.000 (0.002) loss 1.9798 (1.9113) teacher_loss 1.0095 (1.0117) loss_zs_kd 0.4087 (0.4608) loss_oracle 0.3719 (0.4062) acc 75.0000 (73.5491) kd_loss 0.7844 (0.6965) lr 1.5878e-03 eta 0:14:10
epoch [17/50] batch [160/246] time 0.099 (0.103) data 0.000 (0.002) loss 1.6561 (1.9145) teacher_loss 0.6566 (1.0111) loss_zs_kd 0.4729 (0.4620) loss_oracle 0.4392 (0.4105) acc 75.0000 (73.6719) kd_loss 0.7799 (0.6981) lr 1.5878e-03 eta 0:14:09
epoch [17/50] batch [180/246] time 0.102 (0.103) data 0.000 (0.002) loss 2.4331 (1.9234) teacher_loss 1.4744 (1.0133) loss_zs_kd 0.5279 (0.4662) loss_oracle 0.5378 (0.4171) acc 62.5000 (73.7326) kd_loss 0.6897 (0.7015) lr 1.5878e-03 eta 0:14:05
epoch [17/50] batch [200/246] time 0.102 (0.103) data 0.000 (0.002) loss 1.7768 (1.9291) teacher_loss 0.8569 (1.0108) loss_zs_kd 0.3167 (0.4658) loss_oracle 0.4592 (0.4261) acc 81.2500 (73.8281) kd_loss 0.6903 (0.7053) lr 1.5878e-03 eta 0:14:01
epoch [17/50] batch [220/246] time 0.095 (0.103) data 0.000 (0.002) loss 1.7953 (1.9440) teacher_loss 0.8684 (1.0153) loss_zs_kd 0.5657 (0.4685) loss_oracle 0.4623 (0.4346) acc 78.1250 (73.7926) kd_loss 0.6957 (0.7114) lr 1.5878e-03 eta 0:13:56
epoch [17/50] batch [240/246] time 0.085 (0.102) data 0.000 (0.001) loss 1.8226 (1.9408) teacher_loss 0.7906 (1.0078) loss_zs_kd 0.4868 (0.4727) loss_oracle 0.4367 (0.4380) acc 81.2500 (73.9453) kd_loss 0.8136 (0.7140) lr 1.5878e-03 eta 0:13:46
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,866
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,960
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.9%, epoch: 16 *******
******* Domain r best val test acc: 90.6%, epoch: 16 *******
******* Domain r best test acc:     90.9%, epoch: 7 *******
epoch [18/50] batch [20/246] time 0.098 (0.117) data 0.000 (0.015) loss 1.5921 (2.0036) teacher_loss 0.7508 (1.0316) loss_zs_kd 0.5696 (0.4994) loss_oracle 0.3903 (0.4648) acc 78.1250 (74.0625) kd_loss 0.6462 (0.7395) lr 1.5358e-03 eta 0:15:47
epoch [18/50] batch [40/246] time 0.102 (0.113) data 0.000 (0.008) loss 2.1200 (2.0054) teacher_loss 1.0425 (1.0438) loss_zs_kd 0.4405 (0.4760) loss_oracle 0.5336 (0.4605) acc 71.8750 (72.7344) kd_loss 0.8107 (0.7313) lr 1.5358e-03 eta 0:15:15
epoch [18/50] batch [60/246] time 0.098 (0.108) data 0.000 (0.005) loss 1.9020 (1.9460) teacher_loss 0.9500 (0.9976) loss_zs_kd 0.4614 (0.4861) loss_oracle 0.4653 (0.4588) acc 71.8750 (74.1667) kd_loss 0.7193 (0.7190) lr 1.5358e-03 eta 0:14:29
epoch [18/50] batch [80/246] time 0.097 (0.105) data 0.000 (0.004) loss 2.1285 (1.9697) teacher_loss 1.1455 (1.0140) loss_zs_kd 0.4545 (0.4806) loss_oracle 0.4864 (0.4609) acc 75.0000 (73.7891) kd_loss 0.7398 (0.7253) lr 1.5358e-03 eta 0:14:01
epoch [18/50] batch [100/246] time 0.095 (0.103) data 0.000 (0.003) loss 2.2693 (1.9623) teacher_loss 1.2602 (1.0123) loss_zs_kd 0.3724 (0.4727) loss_oracle 0.4634 (0.4594) acc 65.6250 (73.4375) kd_loss 0.7774 (0.7203) lr 1.5358e-03 eta 0:13:44
epoch [18/50] batch [120/246] time 0.095 (0.102) data 0.000 (0.003) loss 2.4146 (1.9769) teacher_loss 1.4197 (1.0268) loss_zs_kd 0.4573 (0.4730) loss_oracle 0.4847 (0.4590) acc 68.7500 (73.2552) kd_loss 0.7526 (0.7206) lr 1.5358e-03 eta 0:13:35
epoch [18/50] batch [140/246] time 0.092 (0.101) data 0.000 (0.002) loss 1.5101 (1.9618) teacher_loss 0.6419 (1.0214) loss_zs_kd 0.4422 (0.4720) loss_oracle 0.4542 (0.4555) acc 81.2500 (73.3259) kd_loss 0.6410 (0.7126) lr 1.5358e-03 eta 0:13:25
epoch [18/50] batch [160/246] time 0.093 (0.100) data 0.000 (0.002) loss 1.2652 (1.9508) teacher_loss 0.4630 (1.0144) loss_zs_kd 0.3995 (0.4692) loss_oracle 0.3923 (0.4516) acc 90.6250 (73.4766) kd_loss 0.6060 (0.7106) lr 1.5358e-03 eta 0:13:17
epoch [18/50] batch [180/246] time 0.100 (0.100) data 0.000 (0.002) loss 1.4842 (1.9512) teacher_loss 0.6733 (1.0170) loss_zs_kd 0.3401 (0.4648) loss_oracle 0.4868 (0.4540) acc 81.2500 (73.2986) kd_loss 0.5675 (0.7072) lr 1.5358e-03 eta 0:13:12
epoch [18/50] batch [200/246] time 0.096 (0.099) data 0.000 (0.002) loss 1.8634 (1.9537) teacher_loss 1.0207 (1.0190) loss_zs_kd 0.5181 (0.4661) loss_oracle 0.4328 (0.4557) acc 75.0000 (73.1562) kd_loss 0.6263 (0.7068) lr 1.5358e-03 eta 0:13:07
epoch [18/50] batch [220/246] time 0.096 (0.099) data 0.000 (0.002) loss 1.7245 (1.9585) teacher_loss 0.7955 (1.0228) loss_zs_kd 0.2808 (0.4654) loss_oracle 0.4293 (0.4542) acc 81.2500 (73.1534) kd_loss 0.7143 (0.7086) lr 1.5358e-03 eta 0:13:02
epoch [18/50] batch [240/246] time 0.088 (0.099) data 0.000 (0.001) loss 1.6385 (1.9663) teacher_loss 0.6697 (1.0294) loss_zs_kd 0.5986 (0.4666) loss_oracle 0.4518 (0.4545) acc 78.1250 (72.9167) kd_loss 0.7428 (0.7097) lr 1.5358e-03 eta 0:12:56
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,872
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,960
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.9%, epoch: 16 *******
******* Domain r best val test acc: 90.6%, epoch: 16 *******
******* Domain r best test acc:     90.9%, epoch: 7 *******
epoch [19/50] batch [20/246] time 0.105 (0.117) data 0.000 (0.014) loss 1.7002 (1.9004) teacher_loss 0.8091 (0.9670) loss_zs_kd 0.4052 (0.4479) loss_oracle 0.4456 (0.4363) acc 75.0000 (75.9375) kd_loss 0.6683 (0.7153) lr 1.4818e-03 eta 0:15:17
epoch [19/50] batch [40/246] time 0.091 (0.106) data 0.000 (0.007) loss 1.8288 (1.9172) teacher_loss 0.9228 (0.9822) loss_zs_kd 0.3792 (0.4400) loss_oracle 0.4112 (0.4405) acc 75.0000 (74.4531) kd_loss 0.7004 (0.7147) lr 1.4818e-03 eta 0:13:51
epoch [19/50] batch [60/246] time 0.096 (0.108) data 0.000 (0.005) loss 1.9921 (1.9002) teacher_loss 1.0007 (0.9898) loss_zs_kd 0.3003 (0.4408) loss_oracle 0.3841 (0.4323) acc 75.0000 (74.1146) kd_loss 0.7994 (0.6942) lr 1.4818e-03 eta 0:14:01
epoch [19/50] batch [80/246] time 0.096 (0.105) data 0.000 (0.004) loss 1.9806 (1.8918) teacher_loss 1.1383 (0.9855) loss_zs_kd 0.5763 (0.4532) loss_oracle 0.3880 (0.4307) acc 62.5000 (74.1016) kd_loss 0.6483 (0.6910) lr 1.4818e-03 eta 0:13:38
epoch [19/50] batch [100/246] time 0.088 (0.104) data 0.000 (0.003) loss 1.9114 (1.8916) teacher_loss 0.9080 (0.9909) loss_zs_kd 0.4818 (0.4516) loss_oracle 0.4248 (0.4261) acc 71.8750 (73.6562) kd_loss 0.7910 (0.6876) lr 1.4818e-03 eta 0:13:26
epoch [19/50] batch [120/246] time 0.098 (0.103) data 0.000 (0.003) loss 1.7112 (1.8952) teacher_loss 0.9527 (0.9977) loss_zs_kd 0.5234 (0.4621) loss_oracle 0.4444 (0.4258) acc 71.8750 (73.4115) kd_loss 0.5364 (0.6846) lr 1.4818e-03 eta 0:13:18
epoch [19/50] batch [140/246] time 0.101 (0.103) data 0.000 (0.002) loss 1.9206 (1.9052) teacher_loss 1.0004 (1.0128) loss_zs_kd 0.4773 (0.4640) loss_oracle 0.4702 (0.4200) acc 71.8750 (73.1696) kd_loss 0.6851 (0.6824) lr 1.4818e-03 eta 0:13:13
epoch [19/50] batch [160/246] time 0.102 (0.102) data 0.000 (0.002) loss 1.6196 (1.9039) teacher_loss 0.7475 (1.0077) loss_zs_kd 0.4840 (0.4621) loss_oracle 0.4310 (0.4207) acc 81.2500 (73.3789) kd_loss 0.6566 (0.6858) lr 1.4818e-03 eta 0:13:09
epoch [19/50] batch [180/246] time 0.099 (0.102) data 0.000 (0.002) loss 2.1414 (1.9068) teacher_loss 0.9555 (1.0123) loss_zs_kd 0.6924 (0.4607) loss_oracle 0.5512 (0.4196) acc 78.1250 (73.2639) kd_loss 0.9103 (0.6847) lr 1.4818e-03 eta 0:13:07
epoch [19/50] batch [200/246] time 0.103 (0.102) data 0.000 (0.002) loss 1.8900 (1.9062) teacher_loss 0.9666 (1.0115) loss_zs_kd 0.3720 (0.4589) loss_oracle 0.4640 (0.4216) acc 75.0000 (73.2969) kd_loss 0.6913 (0.6839) lr 1.4818e-03 eta 0:13:05
epoch [19/50] batch [220/246] time 0.097 (0.102) data 0.000 (0.002) loss 1.7405 (1.9142) teacher_loss 0.8167 (1.0188) loss_zs_kd 0.4795 (0.4603) loss_oracle 0.4224 (0.4241) acc 81.2500 (73.2102) kd_loss 0.7126 (0.6834) lr 1.4818e-03 eta 0:13:02
epoch [19/50] batch [240/246] time 0.108 (0.102) data 0.000 (0.001) loss 1.6623 (1.9148) teacher_loss 0.9076 (1.0204) loss_zs_kd 0.5359 (0.4637) loss_oracle 0.4262 (0.4243) acc 71.8750 (73.1250) kd_loss 0.5416 (0.6823) lr 1.4818e-03 eta 0:13:01
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,876
* accuracy: 85.7%
* error: 14.3%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,964
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.0%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      85.9%, epoch: 16 *******
******* Domain r best val test acc: 90.6%, epoch: 16 *******
******* Domain r best test acc:     91.0%, epoch: 19 *******
epoch [20/50] batch [20/246] time 0.119 (0.129) data 0.001 (0.014) loss 2.0207 (1.9300) teacher_loss 1.1241 (1.0472) loss_zs_kd 0.5371 (0.5067) loss_oracle 0.4701 (0.4217) acc 75.0000 (72.9688) kd_loss 0.6615 (0.6720) lr 1.4258e-03 eta 0:16:21
epoch [20/50] batch [40/246] time 0.110 (0.118) data 0.000 (0.007) loss 1.6871 (1.9257) teacher_loss 0.7617 (1.0270) loss_zs_kd 0.5844 (0.4829) loss_oracle 0.4636 (0.4286) acc 84.3750 (73.9844) kd_loss 0.6936 (0.6845) lr 1.4258e-03 eta 0:14:57
epoch [20/50] batch [60/246] time 0.112 (0.118) data 0.000 (0.005) loss 1.8715 (1.9277) teacher_loss 0.9886 (1.0334) loss_zs_kd 0.6063 (0.4772) loss_oracle 0.3968 (0.4314) acc 75.0000 (73.0208) kd_loss 0.6845 (0.6786) lr 1.4258e-03 eta 0:14:50
epoch [20/50] batch [80/246] time 0.109 (0.113) data 0.000 (0.004) loss 1.9720 (1.9289) teacher_loss 0.9270 (1.0297) loss_zs_kd 0.5720 (0.4778) loss_oracle 0.4687 (0.4324) acc 81.2500 (73.1250) kd_loss 0.8107 (0.6830) lr 1.4258e-03 eta 0:14:13
epoch [20/50] batch [100/246] time 0.109 (0.111) data 0.000 (0.003) loss 1.4320 (1.9320) teacher_loss 0.6148 (1.0320) loss_zs_kd 0.5045 (0.4754) loss_oracle 0.3666 (0.4336) acc 87.5000 (73.2500) kd_loss 0.6339 (0.6833) lr 1.4258e-03 eta 0:13:52
epoch [20/50] batch [120/246] time 0.108 (0.109) data 0.000 (0.003) loss 2.0123 (1.9142) teacher_loss 1.0446 (1.0120) loss_zs_kd 0.6776 (0.4798) loss_oracle 0.4435 (0.4339) acc 75.0000 (73.8542) kd_loss 0.7460 (0.6853) lr 1.4258e-03 eta 0:13:41
epoch [20/50] batch [140/246] time 0.113 (0.109) data 0.000 (0.002) loss 1.8853 (1.9027) teacher_loss 1.0170 (1.0051) loss_zs_kd 0.4123 (0.4807) loss_oracle 0.3705 (0.4316) acc 75.0000 (74.0625) kd_loss 0.6831 (0.6818) lr 1.4258e-03 eta 0:13:33
epoch [20/50] batch [160/246] time 0.099 (0.108) data 0.000 (0.002) loss 1.4720 (1.9038) teacher_loss 0.6024 (1.0020) loss_zs_kd 0.4016 (0.4825) loss_oracle 0.4272 (0.4317) acc 81.2500 (74.0039) kd_loss 0.6560 (0.6860) lr 1.4258e-03 eta 0:13:23
epoch [20/50] batch [180/246] time 0.094 (0.107) data 0.000 (0.002) loss 1.8503 (1.8919) teacher_loss 0.7694 (0.9893) loss_zs_kd 0.5121 (0.4800) loss_oracle 0.4638 (0.4316) acc 71.8750 (74.2535) kd_loss 0.8490 (0.6868) lr 1.4258e-03 eta 0:13:15
epoch [20/50] batch [200/246] time 0.094 (0.106) data 0.001 (0.002) loss 1.9479 (1.8954) teacher_loss 0.9839 (0.9918) loss_zs_kd 0.5967 (0.4826) loss_oracle 0.4515 (0.4324) acc 68.7500 (74.1875) kd_loss 0.7382 (0.6874) lr 1.4258e-03 eta 0:13:08
epoch [20/50] batch [220/246] time 0.098 (0.106) data 0.001 (0.002) loss 2.5071 (1.9034) teacher_loss 1.4477 (0.9938) loss_zs_kd 0.4605 (0.4818) loss_oracle 0.5226 (0.4349) acc 65.6250 (73.8494) kd_loss 0.7981 (0.6921) lr 1.4258e-03 eta 0:13:01
epoch [20/50] batch [240/246] time 0.108 (0.105) data 0.000 (0.001) loss 1.8322 (1.9072) teacher_loss 1.0941 (0.9972) loss_zs_kd 0.4303 (0.4832) loss_oracle 0.3547 (0.4365) acc 71.8750 (73.9062) kd_loss 0.5608 (0.6917) lr 1.4258e-03 eta 0:12:57
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,879
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      85.9%, epoch: 16 *******
******* Domain r best val test acc: 90.6%, epoch: 16 *******
******* Domain r best test acc:     91.0%, epoch: 19 *******
epoch [21/50] batch [20/246] time 0.084 (0.118) data 0.000 (0.013) loss 1.4024 (1.8615) teacher_loss 0.5494 (0.9655) loss_zs_kd 0.3378 (0.5188) loss_oracle 0.3745 (0.4391) acc 81.2500 (73.1250) kd_loss 0.6657 (0.6765) lr 1.3681e-03 eta 0:14:31
epoch [21/50] batch [40/246] time 0.106 (0.107) data 0.000 (0.007) loss 1.8786 (1.9068) teacher_loss 0.8867 (1.0051) loss_zs_kd 0.5879 (0.4988) loss_oracle 0.4755 (0.4410) acc 75.0000 (73.2812) kd_loss 0.7541 (0.6812) lr 1.3681e-03 eta 0:13:03
epoch [21/50] batch [60/246] time 0.122 (0.112) data 0.001 (0.005) loss 1.7066 (1.8916) teacher_loss 0.9935 (1.0033) loss_zs_kd 0.6273 (0.5047) loss_oracle 0.3279 (0.4265) acc 81.2500 (74.1667) kd_loss 0.5491 (0.6751) lr 1.3681e-03 eta 0:13:38
epoch [21/50] batch [80/246] time 0.085 (0.110) data 0.000 (0.004) loss 2.0657 (1.8775) teacher_loss 1.3006 (0.9924) loss_zs_kd 0.4507 (0.4994) loss_oracle 0.3920 (0.4263) acc 68.7500 (74.6094) kd_loss 0.5691 (0.6719) lr 1.3681e-03 eta 0:13:20
epoch [21/50] batch [100/246] time 0.107 (0.105) data 0.001 (0.003) loss 2.0013 (1.8777) teacher_loss 1.0971 (0.9953) loss_zs_kd 0.4454 (0.5008) loss_oracle 0.4217 (0.4215) acc 71.8750 (74.6250) kd_loss 0.6934 (0.6717) lr 1.3681e-03 eta 0:12:46
epoch [21/50] batch [120/246] time 0.102 (0.106) data 0.000 (0.002) loss 1.4189 (1.8870) teacher_loss 0.6422 (1.0078) loss_zs_kd 0.4427 (0.5016) loss_oracle 0.3240 (0.4187) acc 84.3750 (74.2708) kd_loss 0.6146 (0.6699) lr 1.3681e-03 eta 0:12:46
epoch [21/50] batch [140/246] time 0.095 (0.105) data 0.000 (0.002) loss 1.7490 (1.8889) teacher_loss 0.7764 (1.0079) loss_zs_kd 0.4932 (0.5004) loss_oracle 0.4325 (0.4208) acc 81.2500 (74.2857) kd_loss 0.7563 (0.6706) lr 1.3681e-03 eta 0:12:40
epoch [21/50] batch [160/246] time 0.090 (0.104) data 0.000 (0.002) loss 1.6614 (1.8915) teacher_loss 0.6609 (1.0062) loss_zs_kd 0.5360 (0.4987) loss_oracle 0.4806 (0.4226) acc 84.3750 (74.1602) kd_loss 0.7603 (0.6740) lr 1.3681e-03 eta 0:12:31
epoch [21/50] batch [180/246] time 0.086 (0.103) data 0.000 (0.002) loss 1.8805 (1.9070) teacher_loss 1.1258 (1.0204) loss_zs_kd 0.5872 (0.4970) loss_oracle 0.4194 (0.4222) acc 71.8750 (73.7153) kd_loss 0.5450 (0.6756) lr 1.3681e-03 eta 0:12:18
epoch [21/50] batch [200/246] time 0.083 (0.101) data 0.000 (0.002) loss 1.8983 (1.9061) teacher_loss 0.9716 (1.0168) loss_zs_kd 0.5950 (0.4932) loss_oracle 0.4851 (0.4241) acc 68.7500 (73.7812) kd_loss 0.6841 (0.6772) lr 1.3681e-03 eta 0:12:08
epoch [21/50] batch [220/246] time 0.100 (0.101) data 0.000 (0.001) loss 1.7129 (1.9102) teacher_loss 0.7440 (1.0177) loss_zs_kd 0.4743 (0.4909) loss_oracle 0.4922 (0.4268) acc 78.1250 (73.8920) kd_loss 0.7228 (0.6791) lr 1.3681e-03 eta 0:12:01
epoch [21/50] batch [240/246] time 0.092 (0.100) data 0.000 (0.001) loss 1.8094 (1.9092) teacher_loss 0.9303 (1.0177) loss_zs_kd 0.4971 (0.4898) loss_oracle 0.4467 (0.4273) acc 75.0000 (73.8411) kd_loss 0.6558 (0.6778) lr 1.3681e-03 eta 0:11:54
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,867
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,948
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      85.9%, epoch: 16 *******
******* Domain r best val test acc: 90.6%, epoch: 16 *******
******* Domain r best test acc:     91.0%, epoch: 19 *******
epoch [22/50] batch [20/246] time 0.102 (0.119) data 0.000 (0.016) loss 1.5992 (1.8356) teacher_loss 0.7325 (0.9403) loss_zs_kd 0.4571 (0.5128) loss_oracle 0.3653 (0.4404) acc 84.3750 (73.9062) kd_loss 0.6840 (0.6750) lr 1.3090e-03 eta 0:14:05
epoch [22/50] batch [40/246] time 0.092 (0.105) data 0.000 (0.008) loss 2.0654 (1.9226) teacher_loss 1.2451 (1.0174) loss_zs_kd 0.5620 (0.5249) loss_oracle 0.4469 (0.4496) acc 75.0000 (72.6562) kd_loss 0.5969 (0.6805) lr 1.3090e-03 eta 0:12:28
epoch [22/50] batch [60/246] time 0.086 (0.100) data 0.000 (0.005) loss 1.7733 (1.9103) teacher_loss 0.8341 (1.0032) loss_zs_kd 0.5125 (0.5293) loss_oracle 0.5439 (0.4496) acc 87.5000 (72.7604) kd_loss 0.6672 (0.6824) lr 1.3090e-03 eta 0:11:47
epoch [22/50] batch [80/246] time 0.099 (0.102) data 0.000 (0.004) loss 2.2728 (1.9176) teacher_loss 1.3845 (1.0000) loss_zs_kd 0.6054 (0.5245) loss_oracle 0.4270 (0.4578) acc 56.2500 (73.0859) kd_loss 0.6748 (0.6886) lr 1.3090e-03 eta 0:12:01
epoch [22/50] batch [100/246] time 0.085 (0.100) data 0.000 (0.003) loss 1.5115 (1.9004) teacher_loss 0.5431 (0.9832) loss_zs_kd 0.4054 (0.5123) loss_oracle 0.4804 (0.4539) acc 90.6250 (73.4375) kd_loss 0.7282 (0.6902) lr 1.3090e-03 eta 0:11:42
epoch [22/50] batch [120/246] time 0.093 (0.098) data 0.000 (0.003) loss 1.8769 (1.8937) teacher_loss 0.9381 (0.9797) loss_zs_kd 0.4896 (0.5052) loss_oracle 0.4262 (0.4498) acc 75.0000 (73.8281) kd_loss 0.7256 (0.6891) lr 1.3090e-03 eta 0:11:30
epoch [22/50] batch [140/246] time 0.094 (0.098) data 0.000 (0.002) loss 1.7117 (1.8885) teacher_loss 0.9388 (0.9808) loss_zs_kd 0.5380 (0.5032) loss_oracle 0.3975 (0.4465) acc 84.3750 (73.8170) kd_loss 0.5742 (0.6844) lr 1.3090e-03 eta 0:11:22
epoch [22/50] batch [160/246] time 0.096 (0.097) data 0.000 (0.002) loss 1.5137 (1.8873) teacher_loss 0.5617 (0.9788) loss_zs_kd 0.3776 (0.4934) loss_oracle 0.5085 (0.4474) acc 84.3750 (74.0625) kd_loss 0.6977 (0.6847) lr 1.3090e-03 eta 0:11:15
epoch [22/50] batch [180/246] time 0.083 (0.096) data 0.000 (0.002) loss 2.2701 (1.8951) teacher_loss 1.3013 (0.9839) loss_zs_kd 0.5896 (0.4946) loss_oracle 0.5092 (0.4476) acc 59.3750 (73.8542) kd_loss 0.7142 (0.6874) lr 1.3090e-03 eta 0:11:08
epoch [22/50] batch [200/246] time 0.099 (0.096) data 0.000 (0.002) loss 1.7187 (1.8942) teacher_loss 0.9799 (0.9852) loss_zs_kd 0.6585 (0.4958) loss_oracle 0.4001 (0.4481) acc 71.8750 (73.7188) kd_loss 0.5388 (0.6850) lr 1.3090e-03 eta 0:11:03
epoch [22/50] batch [220/246] time 0.088 (0.095) data 0.000 (0.002) loss 2.0574 (1.8980) teacher_loss 1.2100 (0.9899) loss_zs_kd 0.6132 (0.4953) loss_oracle 0.4350 (0.4467) acc 71.8750 (73.5938) kd_loss 0.6299 (0.6847) lr 1.3090e-03 eta 0:10:58
epoch [22/50] batch [240/246] time 0.089 (0.095) data 0.000 (0.002) loss 1.5489 (1.9033) teacher_loss 0.6816 (0.9934) loss_zs_kd 0.4603 (0.4971) loss_oracle 0.5194 (0.4495) acc 84.3750 (73.6328) kd_loss 0.6076 (0.6851) lr 1.3090e-03 eta 0:10:54
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,880
* accuracy: 85.9%
* error: 14.1%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,940
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.4%
******* Domain r best val acc:      85.9%, epoch: 16 *******
******* Domain r best val test acc: 90.6%, epoch: 16 *******
******* Domain r best test acc:     91.0%, epoch: 19 *******
epoch [23/50] batch [20/246] time 0.088 (0.099) data 0.001 (0.012) loss 1.9206 (1.9504) teacher_loss 0.9747 (0.9807) loss_zs_kd 0.3822 (0.4994) loss_oracle 0.4701 (0.4859) acc 68.7500 (74.0625) kd_loss 0.7108 (0.7268) lr 1.2487e-03 eta 0:11:19
epoch [23/50] batch [40/246] time 0.098 (0.098) data 0.000 (0.006) loss 2.0458 (1.9610) teacher_loss 1.2515 (1.0263) loss_zs_kd 0.5007 (0.5036) loss_oracle 0.3430 (0.4605) acc 65.6250 (72.6562) kd_loss 0.6228 (0.7045) lr 1.2487e-03 eta 0:11:09
epoch [23/50] batch [60/246] time 0.119 (0.097) data 0.001 (0.004) loss 1.8940 (1.9386) teacher_loss 0.9945 (1.0070) loss_zs_kd 0.6624 (0.5185) loss_oracle 0.4201 (0.4563) acc 68.7500 (73.4375) kd_loss 0.6894 (0.7034) lr 1.2487e-03 eta 0:11:02
epoch [23/50] batch [80/246] time 0.110 (0.101) data 0.000 (0.003) loss 1.6864 (1.9547) teacher_loss 0.7802 (1.0260) loss_zs_kd 0.5582 (0.5098) loss_oracle 0.4499 (0.4534) acc 78.1250 (72.5000) kd_loss 0.6813 (0.7020) lr 1.2487e-03 eta 0:11:25
epoch [23/50] batch [100/246] time 0.121 (0.102) data 0.001 (0.003) loss 2.0163 (1.9412) teacher_loss 1.0386 (1.0110) loss_zs_kd 0.5806 (0.5085) loss_oracle 0.4579 (0.4557) acc 75.0000 (72.8438) kd_loss 0.7488 (0.7024) lr 1.2487e-03 eta 0:11:29
epoch [23/50] batch [120/246] time 0.107 (0.102) data 0.001 (0.002) loss 1.6772 (1.9239) teacher_loss 0.8275 (0.9913) loss_zs_kd 0.4619 (0.5060) loss_oracle 0.4020 (0.4551) acc 75.0000 (73.3594) kd_loss 0.6486 (0.7050) lr 1.2487e-03 eta 0:11:33
epoch [23/50] batch [140/246] time 0.108 (0.103) data 0.000 (0.002) loss 1.6510 (1.9193) teacher_loss 0.7453 (0.9921) loss_zs_kd 0.4021 (0.5067) loss_oracle 0.5045 (0.4543) acc 84.3750 (73.5491) kd_loss 0.6534 (0.7000) lr 1.2487e-03 eta 0:11:32
epoch [23/50] batch [160/246] time 0.089 (0.101) data 0.000 (0.002) loss 2.1125 (1.9213) teacher_loss 1.2109 (0.9930) loss_zs_kd 0.3868 (0.5014) loss_oracle 0.4120 (0.4532) acc 68.7500 (73.5352) kd_loss 0.6956 (0.7017) lr 1.2487e-03 eta 0:11:22
epoch [23/50] batch [180/246] time 0.101 (0.101) data 0.000 (0.002) loss 1.7610 (1.9112) teacher_loss 0.8211 (0.9835) loss_zs_kd 0.5431 (0.4999) loss_oracle 0.4551 (0.4552) acc 75.0000 (73.6111) kd_loss 0.7123 (0.7001) lr 1.2487e-03 eta 0:11:19
epoch [23/50] batch [200/246] time 0.103 (0.102) data 0.001 (0.002) loss 2.1728 (1.9105) teacher_loss 1.3217 (0.9812) loss_zs_kd 0.4730 (0.4981) loss_oracle 0.3856 (0.4567) acc 62.5000 (73.7344) kd_loss 0.6583 (0.7009) lr 1.2487e-03 eta 0:11:22
epoch [23/50] batch [220/246] time 0.112 (0.103) data 0.000 (0.001) loss 1.9013 (1.9108) teacher_loss 0.9940 (0.9819) loss_zs_kd 0.4807 (0.4990) loss_oracle 0.4367 (0.4582) acc 75.0000 (73.6364) kd_loss 0.6889 (0.6998) lr 1.2487e-03 eta 0:11:25
epoch [23/50] batch [240/246] time 0.105 (0.103) data 0.000 (0.001) loss 1.5982 (1.9133) teacher_loss 0.6901 (0.9837) loss_zs_kd 0.3579 (0.5005) loss_oracle 0.4722 (0.4592) acc 78.1250 (73.6458) kd_loss 0.6720 (0.7000) lr 1.2487e-03 eta 0:11:25
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,876
* accuracy: 85.7%
* error: 14.3%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.0%
******* Domain r best val acc:      85.9%, epoch: 16 *******
******* Domain r best val test acc: 90.6%, epoch: 16 *******
******* Domain r best test acc:     91.0%, epoch: 19 *******
epoch [24/50] batch [20/246] time 0.098 (0.124) data 0.000 (0.014) loss 2.0081 (1.9570) teacher_loss 1.0568 (0.9530) loss_zs_kd 0.4783 (0.5436) loss_oracle 0.4690 (0.5034) acc 75.0000 (74.8438) kd_loss 0.7168 (0.7523) lr 1.1874e-03 eta 0:13:41
epoch [24/50] batch [40/246] time 0.092 (0.113) data 0.000 (0.007) loss 2.0276 (1.9697) teacher_loss 1.1193 (0.9944) loss_zs_kd 0.7269 (0.5373) loss_oracle 0.4222 (0.4909) acc 68.7500 (73.7500) kd_loss 0.6973 (0.7298) lr 1.1874e-03 eta 0:12:24
epoch [24/50] batch [60/246] time 0.098 (0.108) data 0.001 (0.005) loss 2.0983 (1.9500) teacher_loss 1.1455 (0.9748) loss_zs_kd 0.4253 (0.5264) loss_oracle 0.5310 (0.4950) acc 71.8750 (74.0625) kd_loss 0.6872 (0.7277) lr 1.1874e-03 eta 0:11:51
epoch [24/50] batch [80/246] time 0.101 (0.106) data 0.000 (0.004) loss 1.7392 (1.9588) teacher_loss 0.9050 (1.0029) loss_zs_kd 0.6514 (0.5369) loss_oracle 0.4959 (0.4880) acc 84.3750 (73.2422) kd_loss 0.5863 (0.7120) lr 1.1874e-03 eta 0:11:35
epoch [24/50] batch [100/246] time 0.135 (0.106) data 0.001 (0.003) loss 2.0588 (1.9558) teacher_loss 1.1996 (1.0128) loss_zs_kd 0.4419 (0.5328) loss_oracle 0.4326 (0.4827) acc 75.0000 (73.2812) kd_loss 0.6429 (0.7016) lr 1.1874e-03 eta 0:11:35
epoch [24/50] batch [120/246] time 0.099 (0.105) data 0.000 (0.003) loss 1.7726 (1.9204) teacher_loss 0.9043 (0.9856) loss_zs_kd 0.5713 (0.5297) loss_oracle 0.4533 (0.4789) acc 78.1250 (73.7500) kd_loss 0.6417 (0.6953) lr 1.1874e-03 eta 0:11:26
epoch [24/50] batch [140/246] time 0.099 (0.104) data 0.000 (0.002) loss 1.7859 (1.9258) teacher_loss 0.8816 (0.9868) loss_zs_kd 0.4862 (0.5218) loss_oracle 0.4128 (0.4754) acc 81.2500 (73.7277) kd_loss 0.6980 (0.7013) lr 1.1874e-03 eta 0:11:17
epoch [24/50] batch [160/246] time 0.096 (0.103) data 0.000 (0.002) loss 1.9414 (1.9289) teacher_loss 0.9517 (0.9912) loss_zs_kd 0.6739 (0.5174) loss_oracle 0.4391 (0.4714) acc 75.0000 (73.5938) kd_loss 0.7701 (0.7019) lr 1.1874e-03 eta 0:11:09
epoch [24/50] batch [180/246] time 0.099 (0.103) data 0.000 (0.002) loss 2.3513 (1.9242) teacher_loss 1.4413 (0.9916) loss_zs_kd 0.6554 (0.5168) loss_oracle 0.4459 (0.4670) acc 68.7500 (73.6111) kd_loss 0.6871 (0.6990) lr 1.1874e-03 eta 0:11:02
epoch [24/50] batch [200/246] time 0.100 (0.102) data 0.000 (0.002) loss 2.1078 (1.9399) teacher_loss 1.3196 (1.0053) loss_zs_kd 0.5517 (0.5129) loss_oracle 0.3919 (0.4651) acc 62.5000 (73.1406) kd_loss 0.5922 (0.7020) lr 1.1874e-03 eta 0:10:55
epoch [24/50] batch [220/246] time 0.095 (0.101) data 0.000 (0.002) loss 2.2760 (1.9329) teacher_loss 1.2989 (1.0049) loss_zs_kd 0.4871 (0.5107) loss_oracle 0.4375 (0.4602) acc 62.5000 (73.0824) kd_loss 0.7583 (0.6978) lr 1.1874e-03 eta 0:10:49
epoch [24/50] batch [240/246] time 0.088 (0.100) data 0.000 (0.001) loss 1.8991 (1.9297) teacher_loss 1.0059 (1.0012) loss_zs_kd 0.4571 (0.5114) loss_oracle 0.4439 (0.4609) acc 68.7500 (73.1641) kd_loss 0.6713 (0.6980) lr 1.1874e-03 eta 0:10:42
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,884
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 85.2%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      86.0%, epoch: 24 *******
******* Domain r best val test acc: 90.7%, epoch: 24 *******
******* Domain r best test acc:     91.0%, epoch: 19 *******
epoch [25/50] batch [20/246] time 0.090 (0.113) data 0.000 (0.015) loss 1.7058 (1.8847) teacher_loss 0.7790 (0.9785) loss_zs_kd 0.5895 (0.5143) loss_oracle 0.4522 (0.4398) acc 78.1250 (74.3750) kd_loss 0.7008 (0.6862) lr 1.1253e-03 eta 0:12:02
epoch [25/50] batch [40/246] time 0.096 (0.103) data 0.000 (0.008) loss 1.7633 (1.8281) teacher_loss 0.8913 (0.9273) loss_zs_kd 0.4499 (0.5018) loss_oracle 0.4396 (0.4489) acc 68.7500 (74.8438) kd_loss 0.6522 (0.6763) lr 1.1253e-03 eta 0:10:57
epoch [25/50] batch [60/246] time 0.096 (0.101) data 0.000 (0.005) loss 2.5874 (1.8744) teacher_loss 1.5957 (0.9622) loss_zs_kd 0.5822 (0.4980) loss_oracle 0.4133 (0.4540) acc 53.1250 (74.0625) kd_loss 0.7851 (0.6851) lr 1.1253e-03 eta 0:10:40
epoch [25/50] batch [80/246] time 0.099 (0.100) data 0.000 (0.004) loss 1.6328 (1.8794) teacher_loss 0.7786 (0.9624) loss_zs_kd 0.4371 (0.4990) loss_oracle 0.4589 (0.4511) acc 75.0000 (73.6719) kd_loss 0.6247 (0.6914) lr 1.1253e-03 eta 0:10:31
epoch [25/50] batch [100/246] time 0.093 (0.099) data 0.000 (0.003) loss 1.6650 (1.8893) teacher_loss 0.7980 (0.9747) loss_zs_kd 0.4458 (0.5008) loss_oracle 0.4583 (0.4481) acc 84.3750 (73.8438) kd_loss 0.6378 (0.6905) lr 1.1253e-03 eta 0:10:24
epoch [25/50] batch [120/246] time 0.092 (0.101) data 0.000 (0.003) loss 2.0434 (1.9002) teacher_loss 1.0336 (0.9915) loss_zs_kd 0.5144 (0.5053) loss_oracle 0.4114 (0.4432) acc 81.2500 (73.3073) kd_loss 0.8041 (0.6871) lr 1.1253e-03 eta 0:10:32
epoch [25/50] batch [140/246] time 0.090 (0.100) data 0.000 (0.002) loss 1.9623 (1.9033) teacher_loss 0.9546 (0.9901) loss_zs_kd 0.4924 (0.5034) loss_oracle 0.4930 (0.4436) acc 78.1250 (73.4598) kd_loss 0.7612 (0.6914) lr 1.1253e-03 eta 0:10:24
epoch [25/50] batch [160/246] time 0.099 (0.099) data 0.000 (0.002) loss 2.0351 (1.9147) teacher_loss 1.2351 (0.9992) loss_zs_kd 0.4799 (0.5011) loss_oracle 0.4069 (0.4485) acc 71.8750 (73.2812) kd_loss 0.5965 (0.6912) lr 1.1253e-03 eta 0:10:20
epoch [25/50] batch [180/246] time 0.097 (0.099) data 0.000 (0.002) loss 1.6770 (1.9138) teacher_loss 0.8951 (0.9995) loss_zs_kd 0.4014 (0.5013) loss_oracle 0.4336 (0.4510) acc 78.1250 (73.3507) kd_loss 0.5651 (0.6888) lr 1.1253e-03 eta 0:10:16
epoch [25/50] batch [200/246] time 0.101 (0.099) data 0.000 (0.002) loss 1.7536 (1.9135) teacher_loss 0.7385 (0.9935) loss_zs_kd 0.5816 (0.5005) loss_oracle 0.5556 (0.4546) acc 87.5000 (73.6562) kd_loss 0.7373 (0.6927) lr 1.1253e-03 eta 0:10:12
epoch [25/50] batch [220/246] time 0.095 (0.099) data 0.000 (0.002) loss 1.8508 (1.9111) teacher_loss 0.9873 (0.9870) loss_zs_kd 0.4998 (0.4988) loss_oracle 0.4496 (0.4594) acc 71.8750 (73.9915) kd_loss 0.6386 (0.6944) lr 1.1253e-03 eta 0:10:08
epoch [25/50] batch [240/246] time 0.088 (0.098) data 0.000 (0.001) loss 1.8825 (1.9144) teacher_loss 0.8624 (0.9905) loss_zs_kd 0.5008 (0.5009) loss_oracle 0.5028 (0.4594) acc 78.1250 (73.8672) kd_loss 0.7686 (0.6941) lr 1.1253e-03 eta 0:10:03
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,876
* accuracy: 85.7%
* error: 14.3%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      86.0%, epoch: 24 *******
******* Domain r best val test acc: 90.7%, epoch: 24 *******
******* Domain r best test acc:     91.0%, epoch: 19 *******
epoch [26/50] batch [20/246] time 0.099 (0.114) data 0.000 (0.012) loss 1.7702 (1.8805) teacher_loss 0.7959 (0.9770) loss_zs_kd 0.5788 (0.5300) loss_oracle 0.4605 (0.4339) acc 78.1250 (74.5312) kd_loss 0.7441 (0.6866) lr 1.0628e-03 eta 0:11:39
epoch [26/50] batch [40/246] time 0.104 (0.106) data 0.000 (0.006) loss 1.9083 (1.8105) teacher_loss 0.9638 (0.9100) loss_zs_kd 0.5099 (0.5327) loss_oracle 0.4207 (0.4338) acc 78.1250 (76.0156) kd_loss 0.7342 (0.6836) lr 1.0628e-03 eta 0:10:45
epoch [26/50] batch [60/246] time 0.102 (0.103) data 0.000 (0.004) loss 1.9397 (1.8108) teacher_loss 0.9028 (0.9117) loss_zs_kd 0.5278 (0.5429) loss_oracle 0.3841 (0.4298) acc 65.6250 (75.5729) kd_loss 0.8448 (0.6842) lr 1.0628e-03 eta 0:10:29
epoch [26/50] batch [80/246] time 0.093 (0.102) data 0.000 (0.003) loss 2.0010 (1.8214) teacher_loss 1.0304 (0.9353) loss_zs_kd 0.4148 (0.5399) loss_oracle 0.4206 (0.4224) acc 71.8750 (74.8828) kd_loss 0.7603 (0.6749) lr 1.0628e-03 eta 0:10:17
epoch [26/50] batch [100/246] time 0.098 (0.101) data 0.000 (0.002) loss 2.4133 (1.8456) teacher_loss 1.2242 (0.9559) loss_zs_kd 0.6907 (0.5489) loss_oracle 0.5966 (0.4269) acc 75.0000 (74.3750) kd_loss 0.8907 (0.6763) lr 1.0628e-03 eta 0:10:10
epoch [26/50] batch [120/246] time 0.103 (0.101) data 0.000 (0.002) loss 2.4360 (1.8762) teacher_loss 1.3819 (0.9827) loss_zs_kd 0.6131 (0.5512) loss_oracle 0.4856 (0.4328) acc 62.5000 (73.9062) kd_loss 0.8112 (0.6771) lr 1.0628e-03 eta 0:10:06
epoch [26/50] batch [140/246] time 0.103 (0.102) data 0.000 (0.002) loss 1.7022 (1.8901) teacher_loss 0.8717 (0.9932) loss_zs_kd 0.4301 (0.5467) loss_oracle 0.4054 (0.4366) acc 75.0000 (73.4375) kd_loss 0.6278 (0.6786) lr 1.0628e-03 eta 0:10:14
epoch [26/50] batch [160/246] time 0.104 (0.101) data 0.001 (0.002) loss 1.8745 (1.8867) teacher_loss 0.9320 (0.9909) loss_zs_kd 0.6346 (0.5393) loss_oracle 0.4519 (0.4388) acc 68.7500 (73.4766) kd_loss 0.7166 (0.6764) lr 1.0628e-03 eta 0:10:06
epoch [26/50] batch [180/246] time 0.096 (0.101) data 0.000 (0.002) loss 2.0142 (1.8787) teacher_loss 1.0144 (0.9817) loss_zs_kd 0.5629 (0.5380) loss_oracle 0.4802 (0.4389) acc 71.8750 (73.8021) kd_loss 0.7596 (0.6776) lr 1.0628e-03 eta 0:10:01
epoch [26/50] batch [200/246] time 0.098 (0.100) data 0.000 (0.001) loss 1.6887 (1.8775) teacher_loss 0.6039 (0.9756) loss_zs_kd 0.5075 (0.5311) loss_oracle 0.5518 (0.4398) acc 87.5000 (74.1875) kd_loss 0.8089 (0.6820) lr 1.0628e-03 eta 0:09:56
epoch [26/50] batch [220/246] time 0.098 (0.100) data 0.000 (0.001) loss 2.3260 (1.8920) teacher_loss 1.5448 (0.9937) loss_zs_kd 0.6362 (0.5299) loss_oracle 0.3374 (0.4361) acc 62.5000 (73.7642) kd_loss 0.6124 (0.6803) lr 1.0628e-03 eta 0:09:53
epoch [26/50] batch [240/246] time 0.088 (0.100) data 0.000 (0.001) loss 1.7536 (1.8919) teacher_loss 0.8992 (0.9947) loss_zs_kd 0.3719 (0.5283) loss_oracle 0.4183 (0.4337) acc 75.0000 (73.6719) kd_loss 0.6452 (0.6804) lr 1.0628e-03 eta 0:09:48
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,881
* accuracy: 85.9%
* error: 14.1%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,951
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      86.0%, epoch: 24 *******
******* Domain r best val test acc: 90.7%, epoch: 24 *******
******* Domain r best test acc:     91.0%, epoch: 19 *******
epoch [27/50] batch [20/246] time 0.102 (0.126) data 0.000 (0.016) loss 1.4549 (1.8452) teacher_loss 0.6098 (0.9510) loss_zs_kd 0.4339 (0.4890) loss_oracle 0.4073 (0.4182) acc 81.2500 (75.1562) kd_loss 0.6415 (0.6851) lr 1.0000e-03 eta 0:12:20
epoch [27/50] batch [40/246] time 0.106 (0.114) data 0.001 (0.008) loss 1.5480 (1.8493) teacher_loss 0.6192 (0.9414) loss_zs_kd 0.4601 (0.4934) loss_oracle 0.3840 (0.4306) acc 84.3750 (75.4688) kd_loss 0.7368 (0.6926) lr 1.0000e-03 eta 0:11:10
epoch [27/50] batch [60/246] time 0.101 (0.109) data 0.001 (0.006) loss 1.7281 (1.8560) teacher_loss 0.8595 (0.9617) loss_zs_kd 0.6686 (0.5107) loss_oracle 0.4822 (0.4313) acc 75.0000 (75.1562) kd_loss 0.6275 (0.6787) lr 1.0000e-03 eta 0:10:39
epoch [27/50] batch [80/246] time 0.093 (0.106) data 0.000 (0.004) loss 1.6942 (1.8839) teacher_loss 0.8955 (0.9877) loss_zs_kd 0.4675 (0.5137) loss_oracle 0.4973 (0.4361) acc 71.8750 (74.1406) kd_loss 0.5500 (0.6781) lr 1.0000e-03 eta 0:10:19
epoch [27/50] batch [100/246] time 0.108 (0.105) data 0.000 (0.003) loss 2.0706 (1.8832) teacher_loss 1.0211 (0.9779) loss_zs_kd 0.6252 (0.5152) loss_oracle 0.5100 (0.4424) acc 71.8750 (74.2812) kd_loss 0.7946 (0.6841) lr 1.0000e-03 eta 0:10:08
epoch [27/50] batch [120/246] time 0.105 (0.104) data 0.000 (0.003) loss 1.7404 (1.8890) teacher_loss 0.9683 (0.9875) loss_zs_kd 0.5117 (0.5134) loss_oracle 0.3674 (0.4424) acc 71.8750 (73.9062) kd_loss 0.5883 (0.6803) lr 1.0000e-03 eta 0:10:02
epoch [27/50] batch [140/246] time 0.102 (0.106) data 0.000 (0.003) loss 1.8099 (1.8819) teacher_loss 0.9103 (0.9854) loss_zs_kd 0.3660 (0.5164) loss_oracle 0.4148 (0.4376) acc 75.0000 (73.7277) kd_loss 0.6922 (0.6777) lr 1.0000e-03 eta 0:10:11
epoch [27/50] batch [160/246] time 0.092 (0.105) data 0.000 (0.002) loss 1.9338 (1.8667) teacher_loss 1.0594 (0.9692) loss_zs_kd 0.5409 (0.5164) loss_oracle 0.4640 (0.4380) acc 71.8750 (74.2383) kd_loss 0.6425 (0.6785) lr 1.0000e-03 eta 0:10:04
epoch [27/50] batch [180/246] time 0.110 (0.104) data 0.000 (0.002) loss 2.0342 (1.8661) teacher_loss 1.1711 (0.9695) loss_zs_kd 0.4110 (0.5178) loss_oracle 0.3916 (0.4364) acc 68.7500 (74.2882) kd_loss 0.6672 (0.6783) lr 1.0000e-03 eta 0:09:58
epoch [27/50] batch [200/246] time 0.112 (0.104) data 0.000 (0.002) loss 1.6192 (1.8665) teacher_loss 0.7699 (0.9678) loss_zs_kd 0.7095 (0.5212) loss_oracle 0.4504 (0.4380) acc 71.8750 (74.3594) kd_loss 0.6242 (0.6796) lr 1.0000e-03 eta 0:09:54
epoch [27/50] batch [220/246] time 0.100 (0.104) data 0.000 (0.002) loss 1.7822 (1.8652) teacher_loss 0.8316 (0.9665) loss_zs_kd 0.6129 (0.5233) loss_oracle 0.4610 (0.4390) acc 78.1250 (74.4602) kd_loss 0.7200 (0.6792) lr 1.0000e-03 eta 0:09:52
epoch [27/50] batch [240/246] time 0.106 (0.104) data 0.000 (0.002) loss 1.4567 (1.8666) teacher_loss 0.5319 (0.9660) loss_zs_kd 0.5978 (0.5261) loss_oracle 0.4602 (0.4404) acc 87.5000 (74.4531) kd_loss 0.6947 (0.6804) lr 1.0000e-03 eta 0:09:50
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,885
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 85.2%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,969
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.1%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      86.0%, epoch: 27 *******
******* Domain r best val test acc: 91.1%, epoch: 27 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [28/50] batch [20/246] time 0.101 (0.115) data 0.000 (0.015) loss 1.7810 (1.8668) teacher_loss 0.8703 (0.9564) loss_zs_kd 0.6057 (0.5294) loss_oracle 0.4560 (0.4461) acc 75.0000 (72.8125) kd_loss 0.6827 (0.6873) lr 9.3721e-04 eta 0:10:49
epoch [28/50] batch [40/246] time 0.109 (0.109) data 0.000 (0.007) loss 1.7826 (1.8832) teacher_loss 0.7689 (0.9522) loss_zs_kd 0.5454 (0.5500) loss_oracle 0.5044 (0.4523) acc 84.3750 (74.1406) kd_loss 0.7615 (0.7048) lr 9.3721e-04 eta 0:10:10
epoch [28/50] batch [60/246] time 0.105 (0.107) data 0.001 (0.005) loss 1.9037 (1.8879) teacher_loss 0.9555 (0.9560) loss_zs_kd 0.4030 (0.5346) loss_oracle 0.4779 (0.4532) acc 75.0000 (74.7917) kd_loss 0.7093 (0.7053) lr 9.3721e-04 eta 0:09:59
epoch [28/50] batch [80/246] time 0.097 (0.106) data 0.000 (0.004) loss 2.3950 (1.8996) teacher_loss 1.4982 (0.9723) loss_zs_kd 0.5952 (0.5252) loss_oracle 0.4079 (0.4583) acc 62.5000 (74.2578) kd_loss 0.6929 (0.6982) lr 9.3721e-04 eta 0:09:49
epoch [28/50] batch [100/246] time 0.108 (0.105) data 0.000 (0.003) loss 1.7907 (1.8880) teacher_loss 0.8308 (0.9602) loss_zs_kd 0.5224 (0.5246) loss_oracle 0.4947 (0.4600) acc 78.1250 (74.5625) kd_loss 0.7125 (0.6978) lr 9.3721e-04 eta 0:09:45
epoch [28/50] batch [120/246] time 0.101 (0.105) data 0.000 (0.003) loss 1.8522 (1.8973) teacher_loss 0.7604 (0.9759) loss_zs_kd 0.5035 (0.5273) loss_oracle 0.5472 (0.4588) acc 81.2500 (74.2708) kd_loss 0.8181 (0.6920) lr 9.3721e-04 eta 0:09:42
epoch [28/50] batch [140/246] time 0.103 (0.106) data 0.001 (0.002) loss 1.6612 (1.8935) teacher_loss 0.7368 (0.9712) loss_zs_kd 0.4600 (0.5258) loss_oracle 0.4099 (0.4551) acc 81.2500 (74.5536) kd_loss 0.7195 (0.6948) lr 9.3721e-04 eta 0:09:47
epoch [28/50] batch [160/246] time 0.105 (0.106) data 0.001 (0.002) loss 2.0075 (1.8894) teacher_loss 1.1789 (0.9706) loss_zs_kd 0.5816 (0.5278) loss_oracle 0.4806 (0.4518) acc 71.8750 (74.3945) kd_loss 0.5883 (0.6929) lr 9.3721e-04 eta 0:09:43
epoch [28/50] batch [180/246] time 0.095 (0.106) data 0.000 (0.002) loss 1.7665 (1.8951) teacher_loss 1.0068 (0.9757) loss_zs_kd 0.5705 (0.5282) loss_oracle 0.3795 (0.4514) acc 78.1250 (74.2535) kd_loss 0.5699 (0.6938) lr 9.3721e-04 eta 0:09:39
epoch [28/50] batch [200/246] time 0.101 (0.105) data 0.000 (0.002) loss 1.8451 (1.8862) teacher_loss 0.9834 (0.9725) loss_zs_kd 0.6331 (0.5275) loss_oracle 0.4329 (0.4472) acc 65.6250 (74.3750) kd_loss 0.6453 (0.6901) lr 9.3721e-04 eta 0:09:33
epoch [28/50] batch [220/246] time 0.094 (0.104) data 0.000 (0.002) loss 1.7710 (1.8863) teacher_loss 0.8742 (0.9738) loss_zs_kd 0.5173 (0.5291) loss_oracle 0.3925 (0.4444) acc 71.8750 (74.3892) kd_loss 0.7006 (0.6903) lr 9.3721e-04 eta 0:09:27
epoch [28/50] batch [240/246] time 0.087 (0.103) data 0.000 (0.001) loss 1.9033 (1.8922) teacher_loss 0.9093 (0.9812) loss_zs_kd 0.3517 (0.5316) loss_oracle 0.3501 (0.4420) acc 71.8750 (74.1016) kd_loss 0.8189 (0.6900) lr 9.3721e-04 eta 0:09:20
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,877
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,950
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      86.0%, epoch: 27 *******
******* Domain r best val test acc: 91.1%, epoch: 27 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [29/50] batch [20/246] time 0.102 (0.121) data 0.000 (0.013) loss 1.8248 (1.9213) teacher_loss 0.8881 (1.0102) loss_zs_kd 0.5395 (0.5427) loss_oracle 0.4808 (0.4466) acc 75.0000 (74.3750) kd_loss 0.6963 (0.6878) lr 8.7467e-04 eta 0:10:52
epoch [29/50] batch [40/246] time 0.093 (0.108) data 0.000 (0.007) loss 1.7427 (1.8582) teacher_loss 0.7993 (0.9437) loss_zs_kd 0.6859 (0.5423) loss_oracle 0.5364 (0.4533) acc 81.2500 (75.2344) kd_loss 0.6751 (0.6879) lr 8.7467e-04 eta 0:09:42
epoch [29/50] batch [60/246] time 0.093 (0.104) data 0.000 (0.005) loss 2.4396 (1.8547) teacher_loss 1.6662 (0.9582) loss_zs_kd 0.5248 (0.5453) loss_oracle 0.3682 (0.4458) acc 53.1250 (74.6875) kd_loss 0.5893 (0.6735) lr 8.7467e-04 eta 0:09:14
epoch [29/50] batch [80/246] time 0.102 (0.102) data 0.000 (0.003) loss 1.5646 (1.8565) teacher_loss 0.5800 (0.9658) loss_zs_kd 0.4333 (0.5325) loss_oracle 0.4798 (0.4430) acc 78.1250 (74.3750) kd_loss 0.7447 (0.6692) lr 8.7467e-04 eta 0:09:03
epoch [29/50] batch [100/246] time 0.100 (0.101) data 0.000 (0.003) loss 2.0050 (1.8740) teacher_loss 1.1194 (0.9791) loss_zs_kd 0.3417 (0.5299) loss_oracle 0.4679 (0.4437) acc 68.7500 (74.1250) kd_loss 0.6516 (0.6730) lr 8.7467e-04 eta 0:08:54
epoch [29/50] batch [120/246] time 0.095 (0.100) data 0.000 (0.002) loss 1.8204 (1.8764) teacher_loss 0.9089 (0.9715) loss_zs_kd 0.7230 (0.5286) loss_oracle 0.4505 (0.4502) acc 78.1250 (74.3750) kd_loss 0.6863 (0.6798) lr 8.7467e-04 eta 0:08:47
epoch [29/50] batch [140/246] time 0.123 (0.100) data 0.000 (0.002) loss 2.2869 (1.8739) teacher_loss 1.3350 (0.9674) loss_zs_kd 0.5313 (0.5273) loss_oracle 0.5199 (0.4537) acc 59.3750 (74.5089) kd_loss 0.6919 (0.6797) lr 8.7467e-04 eta 0:08:47
epoch [29/50] batch [160/246] time 0.104 (0.101) data 0.000 (0.002) loss 1.6245 (1.8766) teacher_loss 0.7586 (0.9687) loss_zs_kd 0.4377 (0.5264) loss_oracle 0.4381 (0.4541) acc 84.3750 (74.6680) kd_loss 0.6468 (0.6808) lr 8.7467e-04 eta 0:08:51
epoch [29/50] batch [180/246] time 0.114 (0.101) data 0.000 (0.002) loss 2.6422 (1.8859) teacher_loss 1.5855 (0.9789) loss_zs_kd 0.5470 (0.5259) loss_oracle 0.5427 (0.4523) acc 68.7500 (74.5139) kd_loss 0.7853 (0.6809) lr 8.7467e-04 eta 0:08:50
epoch [29/50] batch [200/246] time 0.108 (0.102) data 0.000 (0.002) loss 1.5800 (1.8758) teacher_loss 0.7110 (0.9712) loss_zs_kd 0.6376 (0.5232) loss_oracle 0.3754 (0.4499) acc 78.1250 (74.6094) kd_loss 0.6812 (0.6796) lr 8.7467e-04 eta 0:08:49
epoch [29/50] batch [220/246] time 0.099 (0.102) data 0.000 (0.001) loss 1.9226 (1.8749) teacher_loss 0.9474 (0.9707) loss_zs_kd 0.5297 (0.5232) loss_oracle 0.4442 (0.4485) acc 75.0000 (74.5597) kd_loss 0.7531 (0.6799) lr 8.7467e-04 eta 0:08:47
epoch [29/50] batch [240/246] time 0.106 (0.102) data 0.000 (0.001) loss 1.7533 (1.8630) teacher_loss 0.8026 (0.9593) loss_zs_kd 0.3367 (0.5204) loss_oracle 0.4290 (0.4471) acc 78.1250 (74.8958) kd_loss 0.7363 (0.6802) lr 8.7467e-04 eta 0:08:48
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,879
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,944
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.5%
******* Domain r best val acc:      86.0%, epoch: 27 *******
******* Domain r best val test acc: 91.1%, epoch: 27 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [30/50] batch [20/246] time 0.111 (0.124) data 0.000 (0.015) loss 1.6555 (1.9024) teacher_loss 0.7534 (0.9956) loss_zs_kd 0.6372 (0.5965) loss_oracle 0.4528 (0.4377) acc 84.3750 (74.6875) kd_loss 0.6757 (0.6879) lr 8.1262e-04 eta 0:10:40
epoch [30/50] batch [40/246] time 0.112 (0.115) data 0.000 (0.008) loss 1.5090 (1.8759) teacher_loss 0.6929 (0.9490) loss_zs_kd 0.5172 (0.5625) loss_oracle 0.4358 (0.4533) acc 78.1250 (74.5312) kd_loss 0.5982 (0.7002) lr 8.1262e-04 eta 0:09:48
epoch [30/50] batch [60/246] time 0.101 (0.113) data 0.001 (0.005) loss 1.9409 (1.8891) teacher_loss 1.0159 (0.9678) loss_zs_kd 0.6940 (0.5637) loss_oracle 0.3956 (0.4530) acc 68.7500 (73.8021) kd_loss 0.7272 (0.6947) lr 8.1262e-04 eta 0:09:34
epoch [30/50] batch [80/246] time 0.114 (0.111) data 0.000 (0.004) loss 1.6225 (1.8842) teacher_loss 0.6951 (0.9640) loss_zs_kd 0.6781 (0.5613) loss_oracle 0.4814 (0.4534) acc 81.2500 (73.7891) kd_loss 0.6867 (0.6936) lr 8.1262e-04 eta 0:09:23
epoch [30/50] batch [100/246] time 0.109 (0.110) data 0.000 (0.003) loss 1.5827 (1.8894) teacher_loss 0.5766 (0.9749) loss_zs_kd 0.4795 (0.5595) loss_oracle 0.4800 (0.4509) acc 87.5000 (73.9062) kd_loss 0.7661 (0.6891) lr 8.1262e-04 eta 0:09:17
epoch [30/50] batch [120/246] time 0.114 (0.109) data 0.001 (0.003) loss 1.7009 (1.9102) teacher_loss 0.8081 (0.9998) loss_zs_kd 0.4828 (0.5597) loss_oracle 0.4663 (0.4476) acc 81.2500 (73.2031) kd_loss 0.6596 (0.6866) lr 8.1262e-04 eta 0:09:12
epoch [30/50] batch [140/246] time 0.093 (0.110) data 0.000 (0.002) loss 1.7712 (1.9031) teacher_loss 0.7141 (0.9927) loss_zs_kd 0.7867 (0.5582) loss_oracle 0.4751 (0.4468) acc 90.6250 (73.4598) kd_loss 0.8196 (0.6870) lr 8.1262e-04 eta 0:09:12
epoch [30/50] batch [160/246] time 0.094 (0.108) data 0.000 (0.002) loss 1.7558 (1.9018) teacher_loss 0.9180 (0.9936) loss_zs_kd 0.3409 (0.5509) loss_oracle 0.3879 (0.4449) acc 65.6250 (73.4961) kd_loss 0.6438 (0.6857) lr 8.1262e-04 eta 0:08:59
epoch [30/50] batch [180/246] time 0.086 (0.106) data 0.000 (0.002) loss 1.3008 (1.8996) teacher_loss 0.4990 (0.9924) loss_zs_kd 0.2880 (0.5462) loss_oracle 0.3800 (0.4439) acc 84.3750 (73.6979) kd_loss 0.6118 (0.6852) lr 8.1262e-04 eta 0:08:48
epoch [30/50] batch [200/246] time 0.096 (0.105) data 0.000 (0.002) loss 1.9245 (1.8957) teacher_loss 0.9758 (0.9870) loss_zs_kd 0.5548 (0.5458) loss_oracle 0.4354 (0.4430) acc 68.7500 (73.8281) kd_loss 0.7310 (0.6872) lr 8.1262e-04 eta 0:08:40
epoch [30/50] batch [220/246] time 0.086 (0.104) data 0.000 (0.002) loss 2.0989 (1.8985) teacher_loss 1.2095 (0.9906) loss_zs_kd 0.4356 (0.5409) loss_oracle 0.4161 (0.4411) acc 68.7500 (73.7642) kd_loss 0.6814 (0.6873) lr 8.1262e-04 eta 0:08:32
epoch [30/50] batch [240/246] time 0.091 (0.103) data 0.000 (0.001) loss 1.2359 (1.8953) teacher_loss 0.4363 (0.9869) loss_zs_kd 0.4861 (0.5390) loss_oracle 0.4304 (0.4399) acc 87.5000 (73.8281) kd_loss 0.5844 (0.6884) lr 8.1262e-04 eta 0:08:25
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,873
* accuracy: 85.7%
* error: 14.3%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,948
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      86.0%, epoch: 27 *******
******* Domain r best val test acc: 91.1%, epoch: 27 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [31/50] batch [20/246] time 0.104 (0.120) data 0.001 (0.015) loss 1.6415 (1.7885) teacher_loss 0.6666 (0.8812) loss_zs_kd 0.5169 (0.5336) loss_oracle 0.4939 (0.4366) acc 81.2500 (75.9375) kd_loss 0.7280 (0.6891) lr 7.5131e-04 eta 0:09:49
epoch [31/50] batch [40/246] time 0.103 (0.111) data 0.000 (0.008) loss 1.9896 (1.8558) teacher_loss 1.1290 (0.9541) loss_zs_kd 0.3809 (0.5347) loss_oracle 0.4895 (0.4351) acc 71.8750 (74.5312) kd_loss 0.6158 (0.6842) lr 7.5131e-04 eta 0:09:03
epoch [31/50] batch [60/246] time 0.103 (0.109) data 0.001 (0.005) loss 1.8529 (1.8759) teacher_loss 0.9576 (0.9745) loss_zs_kd 0.7395 (0.5379) loss_oracle 0.4457 (0.4386) acc 75.0000 (74.2188) kd_loss 0.6724 (0.6821) lr 7.5131e-04 eta 0:08:47
epoch [31/50] batch [80/246] time 0.100 (0.107) data 0.000 (0.004) loss 1.3002 (1.8721) teacher_loss 0.5056 (0.9639) loss_zs_kd 0.5722 (0.5373) loss_oracle 0.4299 (0.4447) acc 87.5000 (74.3750) kd_loss 0.5796 (0.6859) lr 7.5131e-04 eta 0:08:36
epoch [31/50] batch [100/246] time 0.100 (0.104) data 0.000 (0.003) loss 1.5802 (1.8757) teacher_loss 0.7170 (0.9639) loss_zs_kd 0.5534 (0.5462) loss_oracle 0.4568 (0.4482) acc 84.3750 (74.4062) kd_loss 0.6348 (0.6877) lr 7.5131e-04 eta 0:08:23
epoch [31/50] batch [120/246] time 0.103 (0.104) data 0.000 (0.003) loss 1.8995 (1.8873) teacher_loss 0.9811 (0.9754) loss_zs_kd 0.4362 (0.5474) loss_oracle 0.5241 (0.4494) acc 65.6250 (73.9323) kd_loss 0.6564 (0.6872) lr 7.5131e-04 eta 0:08:19
epoch [31/50] batch [140/246] time 0.101 (0.104) data 0.000 (0.002) loss 2.1603 (1.8965) teacher_loss 1.2092 (0.9833) loss_zs_kd 0.7607 (0.5503) loss_oracle 0.4572 (0.4505) acc 71.8750 (73.8393) kd_loss 0.7224 (0.6879) lr 7.5131e-04 eta 0:08:15
epoch [31/50] batch [160/246] time 0.104 (0.106) data 0.001 (0.002) loss 1.5792 (1.8828) teacher_loss 0.6521 (0.9682) loss_zs_kd 0.7539 (0.5544) loss_oracle 0.4685 (0.4521) acc 84.3750 (74.1211) kd_loss 0.6929 (0.6886) lr 7.5131e-04 eta 0:08:23
epoch [31/50] batch [180/246] time 0.101 (0.105) data 0.001 (0.002) loss 2.0875 (1.8764) teacher_loss 1.2309 (0.9616) loss_zs_kd 0.3909 (0.5533) loss_oracle 0.4365 (0.4524) acc 71.8750 (74.2708) kd_loss 0.6384 (0.6886) lr 7.5131e-04 eta 0:08:18
epoch [31/50] batch [200/246] time 0.100 (0.105) data 0.001 (0.002) loss 2.0116 (1.8785) teacher_loss 1.0192 (0.9636) loss_zs_kd 0.4970 (0.5516) loss_oracle 0.4600 (0.4527) acc 75.0000 (74.2812) kd_loss 0.7624 (0.6886) lr 7.5131e-04 eta 0:08:14
epoch [31/50] batch [220/246] time 0.097 (0.105) data 0.000 (0.002) loss 1.7713 (1.8834) teacher_loss 0.8486 (0.9704) loss_zs_kd 0.7065 (0.5490) loss_oracle 0.3792 (0.4499) acc 75.0000 (74.2614) kd_loss 0.7331 (0.6881) lr 7.5131e-04 eta 0:08:14
epoch [31/50] batch [240/246] time 0.107 (0.105) data 0.000 (0.002) loss 1.9052 (1.8799) teacher_loss 1.0417 (0.9713) loss_zs_kd 0.4253 (0.5459) loss_oracle 0.3987 (0.4475) acc 65.6250 (74.1797) kd_loss 0.6642 (0.6849) lr 7.5131e-04 eta 0:08:12
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,891
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 85.4%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      86.2%, epoch: 31 *******
******* Domain r best val test acc: 90.7%, epoch: 31 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [32/50] batch [20/246] time 0.095 (0.110) data 0.000 (0.013) loss 1.4960 (1.8425) teacher_loss 0.6003 (0.9358) loss_zs_kd 0.5388 (0.5308) loss_oracle 0.4596 (0.4499) acc 84.3750 (75.3125) kd_loss 0.6659 (0.6817) lr 6.9098e-04 eta 0:08:33
epoch [32/50] batch [40/246] time 0.089 (0.102) data 0.000 (0.007) loss 1.5398 (1.8926) teacher_loss 0.6864 (0.9870) loss_zs_kd 0.4808 (0.5339) loss_oracle 0.3946 (0.4527) acc 78.1250 (74.1406) kd_loss 0.6561 (0.6792) lr 6.9098e-04 eta 0:07:51
epoch [32/50] batch [60/246] time 0.095 (0.099) data 0.000 (0.005) loss 1.9824 (1.8945) teacher_loss 1.0423 (1.0029) loss_zs_kd 0.3938 (0.5322) loss_oracle 0.4136 (0.4437) acc 68.7500 (73.0208) kd_loss 0.7333 (0.6698) lr 6.9098e-04 eta 0:07:37
epoch [32/50] batch [80/246] time 0.083 (0.097) data 0.000 (0.003) loss 1.6449 (1.8599) teacher_loss 0.8519 (0.9810) loss_zs_kd 0.5387 (0.5371) loss_oracle 0.3569 (0.4379) acc 81.2500 (74.1016) kd_loss 0.6146 (0.6600) lr 6.9098e-04 eta 0:07:27
epoch [32/50] batch [100/246] time 0.093 (0.097) data 0.000 (0.003) loss 1.9544 (1.8847) teacher_loss 0.9774 (0.9997) loss_zs_kd 0.4990 (0.5342) loss_oracle 0.4965 (0.4345) acc 75.0000 (73.4062) kd_loss 0.7288 (0.6677) lr 6.9098e-04 eta 0:07:23
epoch [32/50] batch [120/246] time 0.084 (0.097) data 0.000 (0.002) loss 1.5487 (1.8816) teacher_loss 0.6298 (0.9955) loss_zs_kd 0.4665 (0.5366) loss_oracle 0.4669 (0.4349) acc 84.3750 (73.6458) kd_loss 0.6855 (0.6686) lr 6.9098e-04 eta 0:07:20
epoch [32/50] batch [140/246] time 0.093 (0.096) data 0.000 (0.002) loss 1.9519 (1.8766) teacher_loss 1.2953 (0.9864) loss_zs_kd 0.5596 (0.5347) loss_oracle 0.3621 (0.4375) acc 68.7500 (74.0179) kd_loss 0.4755 (0.6714) lr 6.9098e-04 eta 0:07:17
epoch [32/50] batch [160/246] time 0.085 (0.097) data 0.000 (0.002) loss 1.7310 (1.8865) teacher_loss 0.9090 (0.9943) loss_zs_kd 0.4084 (0.5327) loss_oracle 0.3494 (0.4353) acc 78.1250 (73.9062) kd_loss 0.6474 (0.6745) lr 6.9098e-04 eta 0:07:19
epoch [32/50] batch [180/246] time 0.103 (0.097) data 0.000 (0.002) loss 1.7728 (1.8772) teacher_loss 0.9296 (0.9866) loss_zs_kd 0.5765 (0.5311) loss_oracle 0.4018 (0.4326) acc 78.1250 (74.3403) kd_loss 0.6423 (0.6743) lr 6.9098e-04 eta 0:07:13
epoch [32/50] batch [200/246] time 0.085 (0.096) data 0.000 (0.001) loss 1.9638 (1.8786) teacher_loss 1.0731 (0.9872) loss_zs_kd 0.6872 (0.5331) loss_oracle 0.5111 (0.4338) acc 71.8750 (74.4219) kd_loss 0.6351 (0.6744) lr 6.9098e-04 eta 0:07:10
epoch [32/50] batch [220/246] time 0.093 (0.096) data 0.000 (0.001) loss 1.7921 (1.8675) teacher_loss 0.8820 (0.9758) loss_zs_kd 0.7094 (0.5343) loss_oracle 0.4944 (0.4347) acc 71.8750 (74.6591) kd_loss 0.6629 (0.6744) lr 6.9098e-04 eta 0:07:06
epoch [32/50] batch [240/246] time 0.088 (0.096) data 0.000 (0.001) loss 1.6032 (1.8737) teacher_loss 0.7405 (0.9809) loss_zs_kd 0.3746 (0.5324) loss_oracle 0.4414 (0.4363) acc 84.3750 (74.3229) kd_loss 0.6420 (0.6747) lr 6.9098e-04 eta 0:07:03
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,893
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.4%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,949
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      86.3%, epoch: 32 *******
******* Domain r best val test acc: 90.6%, epoch: 32 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [33/50] batch [20/246] time 0.094 (0.118) data 0.000 (0.013) loss 2.1617 (1.8803) teacher_loss 1.2666 (0.9538) loss_zs_kd 0.4525 (0.5125) loss_oracle 0.4122 (0.4589) acc 65.6250 (74.3750) kd_loss 0.6890 (0.6971) lr 6.3188e-04 eta 0:08:41
epoch [33/50] batch [40/246] time 0.101 (0.108) data 0.000 (0.007) loss 1.6289 (1.9099) teacher_loss 0.6017 (0.9790) loss_zs_kd 0.4472 (0.5340) loss_oracle 0.5433 (0.4680) acc 81.2500 (73.5938) kd_loss 0.7555 (0.6969) lr 6.3188e-04 eta 0:07:53
epoch [33/50] batch [60/246] time 0.098 (0.104) data 0.000 (0.005) loss 2.1818 (1.9010) teacher_loss 1.1788 (0.9660) loss_zs_kd 0.6087 (0.5465) loss_oracle 0.4956 (0.4713) acc 75.0000 (74.1667) kd_loss 0.7552 (0.6994) lr 6.3188e-04 eta 0:07:35
epoch [33/50] batch [80/246] time 0.096 (0.102) data 0.000 (0.003) loss 1.5696 (1.8840) teacher_loss 0.6353 (0.9592) loss_zs_kd 0.6478 (0.5435) loss_oracle 0.3714 (0.4640) acc 78.1250 (74.2188) kd_loss 0.7487 (0.6928) lr 6.3188e-04 eta 0:07:24
epoch [33/50] batch [100/246] time 0.099 (0.102) data 0.000 (0.003) loss 1.6844 (1.8718) teacher_loss 0.8021 (0.9492) loss_zs_kd 0.7534 (0.5485) loss_oracle 0.4167 (0.4586) acc 75.0000 (74.6562) kd_loss 0.6740 (0.6933) lr 6.3188e-04 eta 0:07:19
epoch [33/50] batch [120/246] time 0.099 (0.102) data 0.001 (0.002) loss 2.4932 (1.8751) teacher_loss 1.5306 (0.9518) loss_zs_kd 0.5640 (0.5466) loss_oracle 0.5383 (0.4571) acc 68.7500 (74.6094) kd_loss 0.6935 (0.6948) lr 6.3188e-04 eta 0:07:17
epoch [33/50] batch [140/246] time 0.105 (0.102) data 0.000 (0.002) loss 1.9907 (1.8774) teacher_loss 1.1527 (0.9582) loss_zs_kd 0.6293 (0.5485) loss_oracle 0.4437 (0.4556) acc 62.5000 (74.3080) kd_loss 0.6162 (0.6914) lr 6.3188e-04 eta 0:07:16
epoch [33/50] batch [160/246] time 0.098 (0.104) data 0.000 (0.002) loss 1.7842 (1.8569) teacher_loss 0.9367 (0.9414) loss_zs_kd 0.6582 (0.5487) loss_oracle 0.4382 (0.4552) acc 68.7500 (74.7461) kd_loss 0.6285 (0.6879) lr 6.3188e-04 eta 0:07:22
epoch [33/50] batch [180/246] time 0.099 (0.104) data 0.000 (0.002) loss 2.1005 (1.8647) teacher_loss 1.1685 (0.9502) loss_zs_kd 0.5929 (0.5464) loss_oracle 0.4700 (0.4547) acc 75.0000 (74.6701) kd_loss 0.6969 (0.6871) lr 6.3188e-04 eta 0:07:19
epoch [33/50] batch [200/246] time 0.100 (0.103) data 0.000 (0.002) loss 1.8450 (1.8695) teacher_loss 0.8720 (0.9570) loss_zs_kd 0.4256 (0.5440) loss_oracle 0.5130 (0.4533) acc 78.1250 (74.5625) kd_loss 0.7165 (0.6858) lr 6.3188e-04 eta 0:07:16
epoch [33/50] batch [220/246] time 0.109 (0.103) data 0.001 (0.001) loss 2.1607 (1.8673) teacher_loss 1.2159 (0.9557) loss_zs_kd 0.5653 (0.5413) loss_oracle 0.4100 (0.4525) acc 68.7500 (74.4602) kd_loss 0.7398 (0.6853) lr 6.3188e-04 eta 0:07:13
epoch [33/50] batch [240/246] time 0.106 (0.103) data 0.000 (0.001) loss 1.8469 (1.8582) teacher_loss 0.9208 (0.9474) loss_zs_kd 0.7730 (0.5458) loss_oracle 0.4499 (0.4521) acc 78.1250 (74.7266) kd_loss 0.7012 (0.6848) lr 6.3188e-04 eta 0:07:11
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,895
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.6%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,933
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.2%
******* Domain r best val acc:      86.3%, epoch: 33 *******
******* Domain r best val test acc: 90.3%, epoch: 33 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [34/50] batch [20/246] time 0.099 (0.123) data 0.000 (0.015) loss 1.4405 (1.7529) teacher_loss 0.6050 (0.8631) loss_zs_kd 0.4958 (0.5649) loss_oracle 0.4202 (0.4420) acc 84.3750 (76.8750) kd_loss 0.6253 (0.6688) lr 5.7422e-04 eta 0:08:30
epoch [34/50] batch [40/246] time 0.096 (0.113) data 0.000 (0.007) loss 1.9807 (1.8524) teacher_loss 1.0212 (0.9385) loss_zs_kd 0.5601 (0.5735) loss_oracle 0.5036 (0.4532) acc 78.1250 (75.2344) kd_loss 0.7077 (0.6873) lr 5.7422e-04 eta 0:07:47
epoch [34/50] batch [60/246] time 0.101 (0.109) data 0.000 (0.005) loss 1.3951 (1.8168) teacher_loss 0.5825 (0.9021) loss_zs_kd 0.5539 (0.5602) loss_oracle 0.3802 (0.4571) acc 90.6250 (75.9375) kd_loss 0.6226 (0.6861) lr 5.7422e-04 eta 0:07:29
epoch [34/50] batch [80/246] time 0.102 (0.106) data 0.000 (0.004) loss 1.7560 (1.8300) teacher_loss 0.9336 (0.9219) loss_zs_kd 0.4893 (0.5492) loss_oracle 0.4020 (0.4557) acc 71.8750 (75.5078) kd_loss 0.6214 (0.6803) lr 5.7422e-04 eta 0:07:16
epoch [34/50] batch [100/246] time 0.098 (0.105) data 0.000 (0.003) loss 2.1121 (1.8410) teacher_loss 1.2076 (0.9342) loss_zs_kd 0.6145 (0.5599) loss_oracle 0.4531 (0.4543) acc 68.7500 (75.1562) kd_loss 0.6780 (0.6796) lr 5.7422e-04 eta 0:07:09
epoch [34/50] batch [120/246] time 0.108 (0.105) data 0.000 (0.003) loss 1.8273 (1.8278) teacher_loss 0.8728 (0.9173) loss_zs_kd 0.4142 (0.5482) loss_oracle 0.4655 (0.4552) acc 75.0000 (75.7031) kd_loss 0.7217 (0.6829) lr 5.7422e-04 eta 0:07:05
epoch [34/50] batch [140/246] time 0.098 (0.105) data 0.000 (0.002) loss 1.9027 (1.8371) teacher_loss 0.9086 (0.9294) loss_zs_kd 0.5456 (0.5524) loss_oracle 0.4022 (0.4542) acc 78.1250 (75.7589) kd_loss 0.7929 (0.6806) lr 5.7422e-04 eta 0:07:03
epoch [34/50] batch [160/246] time 0.102 (0.106) data 0.000 (0.002) loss 1.4024 (1.8364) teacher_loss 0.6036 (0.9306) loss_zs_kd 0.5867 (0.5567) loss_oracle 0.4780 (0.4543) acc 78.1250 (75.9375) kd_loss 0.5598 (0.6787) lr 5.7422e-04 eta 0:07:06
epoch [34/50] batch [180/246] time 0.096 (0.106) data 0.000 (0.002) loss 1.5028 (1.8368) teacher_loss 0.6346 (0.9313) loss_zs_kd 0.4656 (0.5563) loss_oracle 0.4166 (0.4544) acc 78.1250 (75.8333) kd_loss 0.6599 (0.6783) lr 5.7422e-04 eta 0:07:03
epoch [34/50] batch [200/246] time 0.106 (0.106) data 0.000 (0.002) loss 1.5775 (1.8465) teacher_loss 0.8292 (0.9413) loss_zs_kd 0.4216 (0.5601) loss_oracle 0.4602 (0.4531) acc 78.1250 (75.7031) kd_loss 0.5182 (0.6786) lr 5.7422e-04 eta 0:07:00
epoch [34/50] batch [220/246] time 0.101 (0.105) data 0.000 (0.002) loss 2.0749 (1.8475) teacher_loss 1.0348 (0.9418) loss_zs_kd 0.3851 (0.5584) loss_oracle 0.5719 (0.4532) acc 71.8750 (75.6392) kd_loss 0.7541 (0.6791) lr 5.7422e-04 eta 0:06:57
epoch [34/50] batch [240/246] time 0.105 (0.105) data 0.000 (0.001) loss 2.1005 (1.8496) teacher_loss 1.1549 (0.9439) loss_zs_kd 0.5671 (0.5575) loss_oracle 0.4019 (0.4515) acc 62.5000 (75.5078) kd_loss 0.7447 (0.6799) lr 5.7422e-04 eta 0:06:54
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,902
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 85.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,949
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      86.5%, epoch: 34 *******
******* Domain r best val test acc: 90.6%, epoch: 34 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [35/50] batch [20/246] time 0.107 (0.120) data 0.000 (0.013) loss 1.8885 (1.7345) teacher_loss 1.0946 (0.8852) loss_zs_kd 0.5713 (0.5430) loss_oracle 0.3852 (0.4303) acc 62.5000 (77.5000) kd_loss 0.6014 (0.6342) lr 5.1825e-04 eta 0:07:50
epoch [35/50] batch [40/246] time 0.093 (0.109) data 0.000 (0.007) loss 2.0024 (1.8108) teacher_loss 1.1500 (0.9282) loss_zs_kd 0.6219 (0.5590) loss_oracle 0.4601 (0.4444) acc 68.7500 (76.2500) kd_loss 0.6223 (0.6604) lr 5.1825e-04 eta 0:07:06
epoch [35/50] batch [60/246] time 0.099 (0.107) data 0.001 (0.005) loss 1.6886 (1.8094) teacher_loss 0.7541 (0.9206) loss_zs_kd 0.6517 (0.5725) loss_oracle 0.4091 (0.4413) acc 71.8750 (76.4062) kd_loss 0.7299 (0.6681) lr 5.1825e-04 eta 0:06:54
epoch [35/50] batch [80/246] time 0.100 (0.106) data 0.000 (0.004) loss 2.8675 (1.8244) teacher_loss 1.8579 (0.9292) loss_zs_kd 0.6248 (0.5704) loss_oracle 0.5021 (0.4447) acc 56.2500 (76.1328) kd_loss 0.7586 (0.6729) lr 5.1825e-04 eta 0:06:47
epoch [35/50] batch [100/246] time 0.099 (0.105) data 0.000 (0.003) loss 2.1176 (1.8233) teacher_loss 1.1805 (0.9326) loss_zs_kd 0.5132 (0.5684) loss_oracle 0.5012 (0.4422) acc 68.7500 (76.1250) kd_loss 0.6865 (0.6696) lr 5.1825e-04 eta 0:06:40
epoch [35/50] batch [120/246] time 0.092 (0.103) data 0.000 (0.002) loss 1.7688 (1.8295) teacher_loss 0.8176 (0.9341) loss_zs_kd 0.4585 (0.5718) loss_oracle 0.4986 (0.4465) acc 78.1250 (76.1719) kd_loss 0.7019 (0.6721) lr 5.1825e-04 eta 0:06:32
epoch [35/50] batch [140/246] time 0.096 (0.101) data 0.000 (0.002) loss 1.7003 (1.8362) teacher_loss 0.9166 (0.9393) loss_zs_kd 0.4949 (0.5667) loss_oracle 0.4093 (0.4456) acc 75.0000 (75.8259) kd_loss 0.5791 (0.6741) lr 5.1825e-04 eta 0:06:24
epoch [35/50] batch [160/246] time 0.101 (0.102) data 0.000 (0.002) loss 1.4062 (1.8432) teacher_loss 0.4705 (0.9422) loss_zs_kd 0.5062 (0.5660) loss_oracle 0.4573 (0.4462) acc 81.2500 (75.6250) kd_loss 0.7070 (0.6779) lr 5.1825e-04 eta 0:06:26
epoch [35/50] batch [180/246] time 0.098 (0.102) data 0.000 (0.002) loss 2.3082 (1.8443) teacher_loss 1.3989 (0.9415) loss_zs_kd 0.5392 (0.5650) loss_oracle 0.4341 (0.4473) acc 68.7500 (75.5729) kd_loss 0.6923 (0.6791) lr 5.1825e-04 eta 0:06:22
epoch [35/50] batch [200/246] time 0.091 (0.101) data 0.000 (0.002) loss 1.8042 (1.8489) teacher_loss 0.8159 (0.9431) loss_zs_kd 0.5950 (0.5626) loss_oracle 0.4908 (0.4492) acc 78.1250 (75.4688) kd_loss 0.7429 (0.6812) lr 5.1825e-04 eta 0:06:16
epoch [35/50] batch [220/246] time 0.095 (0.100) data 0.000 (0.001) loss 1.9519 (1.8525) teacher_loss 1.0893 (0.9471) loss_zs_kd 0.5921 (0.5587) loss_oracle 0.4959 (0.4495) acc 68.7500 (75.3267) kd_loss 0.6147 (0.6806) lr 5.1825e-04 eta 0:06:12
epoch [35/50] batch [240/246] time 0.089 (0.100) data 0.000 (0.001) loss 1.6370 (1.8586) teacher_loss 0.8187 (0.9484) loss_zs_kd 0.6106 (0.5602) loss_oracle 0.4901 (0.4528) acc 78.1250 (75.2083) kd_loss 0.5732 (0.6838) lr 5.1825e-04 eta 0:06:07
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,904
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 85.9%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,949
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [36/50] batch [20/246] time 0.096 (0.108) data 0.000 (0.013) loss 2.1755 (1.9297) teacher_loss 1.1099 (1.0058) loss_zs_kd 0.7188 (0.5252) loss_oracle 0.5383 (0.4505) acc 62.5000 (73.4375) kd_loss 0.7964 (0.6987) lr 4.6417e-04 eta 0:06:37
epoch [36/50] batch [40/246] time 0.086 (0.099) data 0.000 (0.007) loss 2.3698 (1.8849) teacher_loss 1.4560 (0.9635) loss_zs_kd 0.5575 (0.5512) loss_oracle 0.4241 (0.4532) acc 59.3750 (74.4531) kd_loss 0.7017 (0.6948) lr 4.6417e-04 eta 0:06:02
epoch [36/50] batch [60/246] time 0.092 (0.099) data 0.000 (0.004) loss 1.8263 (1.8864) teacher_loss 0.7761 (0.9660) loss_zs_kd 0.6260 (0.5624) loss_oracle 0.5945 (0.4549) acc 75.0000 (74.3229) kd_loss 0.7529 (0.6930) lr 4.6417e-04 eta 0:05:58
epoch [36/50] batch [80/246] time 0.086 (0.096) data 0.000 (0.003) loss 1.9050 (1.9118) teacher_loss 0.9850 (0.9936) loss_zs_kd 0.4563 (0.5726) loss_oracle 0.5264 (0.4554) acc 68.7500 (73.5938) kd_loss 0.6568 (0.6905) lr 4.6417e-04 eta 0:05:48
epoch [36/50] batch [100/246] time 0.093 (0.095) data 0.000 (0.003) loss 2.3604 (1.9045) teacher_loss 1.3024 (0.9837) loss_zs_kd 0.6497 (0.5765) loss_oracle 0.4498 (0.4571) acc 59.3750 (73.6562) kd_loss 0.8332 (0.6923) lr 4.6417e-04 eta 0:05:41
epoch [36/50] batch [120/246] time 0.096 (0.095) data 0.000 (0.002) loss 1.6630 (1.8947) teacher_loss 0.6672 (0.9750) loss_zs_kd 0.5295 (0.5783) loss_oracle 0.5424 (0.4568) acc 87.5000 (74.0625) kd_loss 0.7245 (0.6913) lr 4.6417e-04 eta 0:05:37
epoch [36/50] batch [140/246] time 0.091 (0.095) data 0.000 (0.002) loss 1.9954 (1.8934) teacher_loss 1.1467 (0.9753) loss_zs_kd 0.3597 (0.5730) loss_oracle 0.4607 (0.4559) acc 68.7500 (74.0402) kd_loss 0.6184 (0.6902) lr 4.6417e-04 eta 0:05:37
epoch [36/50] batch [160/246] time 0.098 (0.095) data 0.000 (0.002) loss 1.3293 (1.8764) teacher_loss 0.4531 (0.9576) loss_zs_kd 0.6377 (0.5661) loss_oracle 0.4210 (0.4571) acc 87.5000 (74.4531) kd_loss 0.6657 (0.6903) lr 4.6417e-04 eta 0:05:36
epoch [36/50] batch [180/246] time 0.100 (0.097) data 0.000 (0.002) loss 1.7725 (1.8656) teacher_loss 0.7861 (0.9509) loss_zs_kd 0.4727 (0.5674) loss_oracle 0.4736 (0.4567) acc 78.1250 (74.7049) kd_loss 0.7496 (0.6863) lr 4.6417e-04 eta 0:05:42
epoch [36/50] batch [200/246] time 0.087 (0.098) data 0.000 (0.001) loss 1.9411 (1.8707) teacher_loss 1.0925 (0.9567) loss_zs_kd 0.5796 (0.5667) loss_oracle 0.4649 (0.4568) acc 62.5000 (74.4688) kd_loss 0.6162 (0.6856) lr 4.6417e-04 eta 0:05:40
epoch [36/50] batch [220/246] time 0.103 (0.097) data 0.000 (0.001) loss 1.1183 (1.8635) teacher_loss 0.4368 (0.9507) loss_zs_kd 0.4043 (0.5653) loss_oracle 0.3971 (0.4569) acc 84.3750 (74.7301) kd_loss 0.4829 (0.6843) lr 4.6417e-04 eta 0:05:36
epoch [36/50] batch [240/246] time 0.084 (0.096) data 0.000 (0.001) loss 2.1071 (1.8555) teacher_loss 1.0280 (0.9403) loss_zs_kd 0.7026 (0.5656) loss_oracle 0.4738 (0.4582) acc 71.8750 (75.0000) kd_loss 0.8422 (0.6861) lr 4.6417e-04 eta 0:05:32
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,893
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [37/50] batch [20/246] time 0.103 (0.115) data 0.000 (0.013) loss 2.0570 (1.8978) teacher_loss 1.1765 (1.0038) loss_zs_kd 0.4209 (0.5613) loss_oracle 0.5243 (0.4459) acc 71.8750 (75.1562) kd_loss 0.6183 (0.6711) lr 4.1221e-04 eta 0:06:33
epoch [37/50] batch [40/246] time 0.101 (0.105) data 0.000 (0.007) loss 2.3705 (1.8769) teacher_loss 1.3624 (0.9747) loss_zs_kd 0.3681 (0.5491) loss_oracle 0.4818 (0.4475) acc 68.7500 (75.2344) kd_loss 0.7672 (0.6784) lr 4.1221e-04 eta 0:05:56
epoch [37/50] batch [60/246] time 0.093 (0.103) data 0.000 (0.004) loss 1.6482 (1.8834) teacher_loss 0.5883 (0.9657) loss_zs_kd 0.5793 (0.5514) loss_oracle 0.5066 (0.4507) acc 84.3750 (75.6771) kd_loss 0.8066 (0.6923) lr 4.1221e-04 eta 0:05:47
epoch [37/50] batch [80/246] time 0.101 (0.101) data 0.000 (0.003) loss 1.6378 (1.8752) teacher_loss 0.7740 (0.9538) loss_zs_kd 0.6089 (0.5482) loss_oracle 0.4347 (0.4549) acc 81.2500 (75.8203) kd_loss 0.6464 (0.6939) lr 4.1221e-04 eta 0:05:40
epoch [37/50] batch [100/246] time 0.096 (0.101) data 0.000 (0.003) loss 2.5479 (1.8719) teacher_loss 1.5891 (0.9514) loss_zs_kd 0.4578 (0.5485) loss_oracle 0.4725 (0.4557) acc 68.7500 (75.6875) kd_loss 0.7226 (0.6926) lr 4.1221e-04 eta 0:05:37
epoch [37/50] batch [120/246] time 0.100 (0.100) data 0.000 (0.002) loss 2.1065 (1.8795) teacher_loss 1.0976 (0.9562) loss_zs_kd 0.5763 (0.5533) loss_oracle 0.3997 (0.4575) acc 68.7500 (75.4948) kd_loss 0.8090 (0.6945) lr 4.1221e-04 eta 0:05:31
epoch [37/50] batch [140/246] time 0.096 (0.100) data 0.000 (0.002) loss 1.4389 (1.8809) teacher_loss 0.5075 (0.9594) loss_zs_kd 0.6664 (0.5533) loss_oracle 0.4238 (0.4570) acc 84.3750 (75.3348) kd_loss 0.7195 (0.6930) lr 4.1221e-04 eta 0:05:28
epoch [37/50] batch [160/246] time 0.102 (0.099) data 0.000 (0.002) loss 1.9002 (1.8700) teacher_loss 1.0630 (0.9509) loss_zs_kd 0.5968 (0.5513) loss_oracle 0.4502 (0.4572) acc 78.1250 (75.5078) kd_loss 0.6121 (0.6905) lr 4.1221e-04 eta 0:05:25
epoch [37/50] batch [180/246] time 0.093 (0.099) data 0.000 (0.002) loss 1.7675 (1.8638) teacher_loss 0.9393 (0.9503) loss_zs_kd 0.4743 (0.5469) loss_oracle 0.4575 (0.4543) acc 71.8750 (75.4340) kd_loss 0.5995 (0.6864) lr 4.1221e-04 eta 0:05:22
epoch [37/50] batch [200/246] time 0.098 (0.100) data 0.000 (0.001) loss 1.8278 (1.8653) teacher_loss 0.8591 (0.9498) loss_zs_kd 0.4120 (0.5480) loss_oracle 0.5455 (0.4555) acc 71.8750 (75.3125) kd_loss 0.6960 (0.6877) lr 4.1221e-04 eta 0:05:23
epoch [37/50] batch [220/246] time 0.104 (0.100) data 0.000 (0.001) loss 2.2721 (1.8644) teacher_loss 1.4793 (0.9514) loss_zs_kd 0.6244 (0.5469) loss_oracle 0.4304 (0.4545) acc 62.5000 (75.2841) kd_loss 0.5775 (0.6857) lr 4.1221e-04 eta 0:05:22
epoch [37/50] batch [240/246] time 0.106 (0.101) data 0.000 (0.001) loss 1.7611 (1.8608) teacher_loss 0.8373 (0.9499) loss_zs_kd 0.4658 (0.5481) loss_oracle 0.4077 (0.4532) acc 75.0000 (75.2344) kd_loss 0.7200 (0.6843) lr 4.1221e-04 eta 0:05:22
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,891
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [38/50] batch [20/246] time 0.094 (0.109) data 0.000 (0.013) loss 1.8856 (1.9464) teacher_loss 0.9737 (1.0330) loss_zs_kd 0.4568 (0.5759) loss_oracle 0.4809 (0.4433) acc 75.0000 (72.8125) kd_loss 0.6714 (0.6917) lr 3.6258e-04 eta 0:05:46
epoch [38/50] batch [40/246] time 0.083 (0.101) data 0.000 (0.007) loss 1.7290 (1.9390) teacher_loss 0.7105 (1.0229) loss_zs_kd 0.6295 (0.5815) loss_oracle 0.4506 (0.4470) acc 78.1250 (72.8906) kd_loss 0.7933 (0.6927) lr 3.6258e-04 eta 0:05:17
epoch [38/50] batch [60/246] time 0.093 (0.097) data 0.000 (0.004) loss 2.0486 (1.9012) teacher_loss 1.2033 (0.9925) loss_zs_kd 0.4605 (0.5767) loss_oracle 0.4049 (0.4478) acc 71.8750 (74.0104) kd_loss 0.6429 (0.6848) lr 3.6258e-04 eta 0:05:05
epoch [38/50] batch [80/246] time 0.084 (0.096) data 0.000 (0.003) loss 2.2947 (1.8890) teacher_loss 1.3279 (0.9828) loss_zs_kd 0.5530 (0.5702) loss_oracle 0.5117 (0.4443) acc 65.6250 (74.1016) kd_loss 0.7109 (0.6840) lr 3.6258e-04 eta 0:04:58
epoch [38/50] batch [100/246] time 0.098 (0.095) data 0.000 (0.003) loss 2.3165 (1.8869) teacher_loss 1.4998 (0.9833) loss_zs_kd 0.5107 (0.5658) loss_oracle 0.4172 (0.4417) acc 65.6250 (74.3125) kd_loss 0.6081 (0.6828) lr 3.6258e-04 eta 0:04:55
epoch [38/50] batch [120/246] time 0.094 (0.096) data 0.000 (0.002) loss 1.5921 (1.8860) teacher_loss 0.7053 (0.9833) loss_zs_kd 0.5194 (0.5569) loss_oracle 0.4109 (0.4420) acc 81.2500 (74.2448) kd_loss 0.6814 (0.6817) lr 3.6258e-04 eta 0:04:54
epoch [38/50] batch [140/246] time 0.098 (0.096) data 0.000 (0.002) loss 1.5297 (1.8679) teacher_loss 0.5584 (0.9684) loss_zs_kd 0.4166 (0.5553) loss_oracle 0.4652 (0.4411) acc 78.1250 (74.4866) kd_loss 0.7387 (0.6790) lr 3.6258e-04 eta 0:04:54
epoch [38/50] batch [160/246] time 0.107 (0.097) data 0.000 (0.002) loss 1.7262 (1.8804) teacher_loss 0.7390 (0.9733) loss_zs_kd 0.5523 (0.5536) loss_oracle 0.5383 (0.4445) acc 78.1250 (74.3750) kd_loss 0.7181 (0.6849) lr 3.6258e-04 eta 0:04:53
epoch [38/50] batch [180/246] time 0.090 (0.097) data 0.000 (0.002) loss 1.7744 (1.8782) teacher_loss 0.8171 (0.9671) loss_zs_kd 0.6089 (0.5590) loss_oracle 0.4520 (0.4456) acc 87.5000 (74.7222) kd_loss 0.7313 (0.6883) lr 3.6258e-04 eta 0:04:51
epoch [38/50] batch [200/246] time 0.102 (0.097) data 0.000 (0.001) loss 1.8800 (1.8712) teacher_loss 0.9027 (0.9603) loss_zs_kd 0.6521 (0.5581) loss_oracle 0.5057 (0.4446) acc 78.1250 (75.0000) kd_loss 0.7244 (0.6885) lr 3.6258e-04 eta 0:04:49
epoch [38/50] batch [220/246] time 0.110 (0.098) data 0.000 (0.001) loss 1.6027 (1.8679) teacher_loss 0.7883 (0.9574) loss_zs_kd 0.4750 (0.5562) loss_oracle 0.3809 (0.4444) acc 81.2500 (75.0852) kd_loss 0.6239 (0.6883) lr 3.6258e-04 eta 0:04:50
epoch [38/50] batch [240/246] time 0.089 (0.098) data 0.000 (0.001) loss 2.1161 (1.8659) teacher_loss 1.1773 (0.9561) loss_zs_kd 0.6559 (0.5585) loss_oracle 0.5009 (0.4450) acc 65.6250 (75.0391) kd_loss 0.6884 (0.6873) lr 3.6258e-04 eta 0:04:48
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,892
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,941
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.4%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [39/50] batch [20/246] time 0.087 (0.118) data 0.000 (0.014) loss 1.5522 (1.8254) teacher_loss 0.6163 (0.9045) loss_zs_kd 0.3598 (0.5650) loss_oracle 0.4769 (0.4559) acc 90.6250 (77.6562) kd_loss 0.6975 (0.6929) lr 3.1545e-04 eta 0:05:46
epoch [39/50] batch [40/246] time 0.096 (0.106) data 0.000 (0.007) loss 1.3631 (1.8244) teacher_loss 0.5381 (0.9142) loss_zs_kd 0.4751 (0.5662) loss_oracle 0.4337 (0.4548) acc 84.3750 (77.3438) kd_loss 0.6083 (0.6828) lr 3.1545e-04 eta 0:05:08
epoch [39/50] batch [60/246] time 0.090 (0.103) data 0.000 (0.005) loss 1.5227 (1.8145) teacher_loss 0.7451 (0.9169) loss_zs_kd 0.5178 (0.5597) loss_oracle 0.3964 (0.4469) acc 78.1250 (76.4583) kd_loss 0.5795 (0.6741) lr 3.1545e-04 eta 0:04:56
epoch [39/50] batch [80/246] time 0.090 (0.101) data 0.000 (0.004) loss 2.2208 (1.8241) teacher_loss 1.2428 (0.9206) loss_zs_kd 0.4306 (0.5562) loss_oracle 0.5344 (0.4479) acc 75.0000 (76.4844) kd_loss 0.7109 (0.6796) lr 3.1545e-04 eta 0:04:50
epoch [39/50] batch [100/246] time 0.094 (0.101) data 0.000 (0.003) loss 1.7438 (1.8404) teacher_loss 0.8452 (0.9295) loss_zs_kd 0.6886 (0.5662) loss_oracle 0.4392 (0.4519) acc 81.2500 (76.0625) kd_loss 0.6790 (0.6849) lr 3.1545e-04 eta 0:04:46
epoch [39/50] batch [120/246] time 0.099 (0.100) data 0.000 (0.002) loss 1.6144 (1.8390) teacher_loss 0.9181 (0.9262) loss_zs_kd 0.5154 (0.5781) loss_oracle 0.3609 (0.4559) acc 78.1250 (76.1979) kd_loss 0.5158 (0.6849) lr 3.1545e-04 eta 0:04:43
epoch [39/50] batch [140/246] time 0.093 (0.100) data 0.000 (0.002) loss 2.2083 (1.8580) teacher_loss 1.3655 (0.9464) loss_zs_kd 0.6595 (0.5872) loss_oracle 0.3891 (0.4541) acc 65.6250 (75.6473) kd_loss 0.6483 (0.6845) lr 3.1545e-04 eta 0:04:40
epoch [39/50] batch [160/246] time 0.099 (0.100) data 0.000 (0.002) loss 2.0626 (1.8663) teacher_loss 0.9197 (0.9513) loss_zs_kd 0.5342 (0.5874) loss_oracle 0.5294 (0.4552) acc 75.0000 (75.2734) kd_loss 0.8782 (0.6874) lr 3.1545e-04 eta 0:04:38
epoch [39/50] batch [180/246] time 0.098 (0.100) data 0.000 (0.002) loss 1.5877 (1.8592) teacher_loss 0.7505 (0.9442) loss_zs_kd 0.6346 (0.5833) loss_oracle 0.4014 (0.4552) acc 81.2500 (75.4340) kd_loss 0.6365 (0.6873) lr 3.1545e-04 eta 0:04:36
epoch [39/50] batch [200/246] time 0.096 (0.100) data 0.000 (0.002) loss 1.7892 (1.8626) teacher_loss 0.9514 (0.9455) loss_zs_kd 0.7078 (0.5849) loss_oracle 0.3731 (0.4543) acc 68.7500 (75.3594) kd_loss 0.6513 (0.6899) lr 3.1545e-04 eta 0:04:34
epoch [39/50] batch [220/246] time 0.122 (0.100) data 0.000 (0.001) loss 2.1417 (1.8731) teacher_loss 1.1836 (0.9536) loss_zs_kd 0.5256 (0.5819) loss_oracle 0.4566 (0.4558) acc 68.7500 (75.2415) kd_loss 0.7299 (0.6916) lr 3.1545e-04 eta 0:04:32
epoch [39/50] batch [240/246] time 0.088 (0.099) data 0.000 (0.001) loss 1.5453 (1.8709) teacher_loss 0.7305 (0.9537) loss_zs_kd 0.5398 (0.5798) loss_oracle 0.4590 (0.4559) acc 78.1250 (75.2344) kd_loss 0.5854 (0.6892) lr 3.1545e-04 eta 0:04:29
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,885
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,953
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [40/50] batch [20/246] time 0.098 (0.117) data 0.000 (0.015) loss 1.1226 (1.9064) teacher_loss 0.4124 (0.9980) loss_zs_kd 0.6944 (0.6122) loss_oracle 0.3630 (0.4573) acc 84.3750 (72.8125) kd_loss 0.5287 (0.6797) lr 2.7103e-04 eta 0:05:15
epoch [40/50] batch [40/246] time 0.098 (0.108) data 0.000 (0.008) loss 2.0374 (1.8767) teacher_loss 1.2632 (0.9614) loss_zs_kd 0.6290 (0.6089) loss_oracle 0.3965 (0.4616) acc 68.7500 (74.3750) kd_loss 0.5759 (0.6845) lr 2.7103e-04 eta 0:04:47
epoch [40/50] batch [60/246] time 0.095 (0.104) data 0.001 (0.005) loss 1.5389 (1.8694) teacher_loss 0.6015 (0.9570) loss_zs_kd 0.7439 (0.6012) loss_oracle 0.4335 (0.4603) acc 84.3750 (74.3750) kd_loss 0.7207 (0.6822) lr 2.7103e-04 eta 0:04:35
epoch [40/50] batch [80/246] time 0.095 (0.103) data 0.000 (0.004) loss 1.9612 (1.8673) teacher_loss 0.9773 (0.9497) loss_zs_kd 0.6338 (0.5919) loss_oracle 0.4505 (0.4586) acc 71.8750 (74.6875) kd_loss 0.7586 (0.6883) lr 2.7103e-04 eta 0:04:29
epoch [40/50] batch [100/246] time 0.099 (0.101) data 0.000 (0.003) loss 1.7356 (1.8436) teacher_loss 0.8623 (0.9282) loss_zs_kd 0.6367 (0.5902) loss_oracle 0.4050 (0.4557) acc 75.0000 (75.2500) kd_loss 0.6707 (0.6875) lr 2.7103e-04 eta 0:04:24
epoch [40/50] batch [120/246] time 0.103 (0.101) data 0.000 (0.003) loss 1.8845 (1.8309) teacher_loss 1.0034 (0.9157) loss_zs_kd 0.5406 (0.5805) loss_oracle 0.5146 (0.4529) acc 75.0000 (75.6510) kd_loss 0.6237 (0.6888) lr 2.7103e-04 eta 0:04:21
epoch [40/50] batch [140/246] time 0.096 (0.101) data 0.001 (0.002) loss 2.3116 (1.8198) teacher_loss 1.2677 (0.8999) loss_zs_kd 0.5239 (0.5703) loss_oracle 0.4584 (0.4543) acc 59.3750 (75.9821) kd_loss 0.8147 (0.6928) lr 2.7103e-04 eta 0:04:17
epoch [40/50] batch [160/246] time 0.099 (0.100) data 0.000 (0.002) loss 2.0301 (1.8288) teacher_loss 0.9594 (0.9107) loss_zs_kd 0.7455 (0.5727) loss_oracle 0.5296 (0.4552) acc 75.0000 (75.8398) kd_loss 0.8059 (0.6905) lr 2.7103e-04 eta 0:04:15
epoch [40/50] batch [180/246] time 0.099 (0.100) data 0.000 (0.002) loss 1.7482 (1.8343) teacher_loss 0.7686 (0.9163) loss_zs_kd 0.9390 (0.5768) loss_oracle 0.3794 (0.4534) acc 68.7500 (75.7292) kd_loss 0.7899 (0.6912) lr 2.7103e-04 eta 0:04:12
epoch [40/50] batch [200/246] time 0.096 (0.100) data 0.000 (0.002) loss 1.6801 (1.8329) teacher_loss 0.8751 (0.9189) loss_zs_kd 0.5530 (0.5751) loss_oracle 0.3973 (0.4514) acc 78.1250 (75.8281) kd_loss 0.6063 (0.6883) lr 2.7103e-04 eta 0:04:10
epoch [40/50] batch [220/246] time 0.091 (0.099) data 0.000 (0.002) loss 1.8152 (1.8324) teacher_loss 1.0846 (0.9200) loss_zs_kd 0.7279 (0.5770) loss_oracle 0.4275 (0.4523) acc 71.8750 (75.7812) kd_loss 0.5168 (0.6863) lr 2.7103e-04 eta 0:04:06
epoch [40/50] batch [240/246] time 0.088 (0.099) data 0.000 (0.002) loss 2.3719 (1.8368) teacher_loss 1.2892 (0.9251) loss_zs_kd 0.5636 (0.5773) loss_oracle 0.4931 (0.4511) acc 68.7500 (75.7292) kd_loss 0.8362 (0.6862) lr 2.7103e-04 eta 0:04:04
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,894
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,946
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.5%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [41/50] batch [20/246] time 0.093 (0.109) data 0.000 (0.013) loss 2.2146 (1.8101) teacher_loss 1.2066 (0.8954) loss_zs_kd 0.7288 (0.5613) loss_oracle 0.4536 (0.4472) acc 65.6250 (75.0000) kd_loss 0.7812 (0.6911) lr 2.2949e-04 eta 0:04:25
epoch [41/50] batch [40/246] time 0.098 (0.102) data 0.000 (0.007) loss 2.3703 (1.8354) teacher_loss 1.4849 (0.9330) loss_zs_kd 0.7518 (0.5724) loss_oracle 0.4578 (0.4508) acc 62.5000 (75.9375) kd_loss 0.6566 (0.6770) lr 2.2949e-04 eta 0:04:07
epoch [41/50] batch [60/246] time 0.098 (0.099) data 0.000 (0.005) loss 1.6954 (1.8158) teacher_loss 0.7924 (0.9060) loss_zs_kd 0.5157 (0.5501) loss_oracle 0.4391 (0.4501) acc 78.1250 (75.7812) kd_loss 0.6834 (0.6848) lr 2.2949e-04 eta 0:03:57
epoch [41/50] batch [80/246] time 0.103 (0.100) data 0.000 (0.003) loss 1.5612 (1.8144) teacher_loss 0.7651 (0.9006) loss_zs_kd 0.6337 (0.5514) loss_oracle 0.4050 (0.4527) acc 81.2500 (75.8203) kd_loss 0.5936 (0.6874) lr 2.2949e-04 eta 0:03:57
epoch [41/50] batch [100/246] time 0.100 (0.100) data 0.000 (0.003) loss 1.4923 (1.8295) teacher_loss 0.7006 (0.9226) loss_zs_kd 0.4396 (0.5586) loss_oracle 0.3707 (0.4483) acc 75.0000 (75.4062) kd_loss 0.6063 (0.6827) lr 2.2949e-04 eta 0:03:56
epoch [41/50] batch [120/246] time 0.112 (0.101) data 0.000 (0.002) loss 1.7646 (1.8436) teacher_loss 0.9223 (0.9345) loss_zs_kd 0.6144 (0.5632) loss_oracle 0.4527 (0.4509) acc 75.0000 (75.0781) kd_loss 0.6159 (0.6836) lr 2.2949e-04 eta 0:03:56
epoch [41/50] batch [140/246] time 0.095 (0.102) data 0.000 (0.002) loss 1.8258 (1.8403) teacher_loss 0.8765 (0.9313) loss_zs_kd 0.5546 (0.5641) loss_oracle 0.4057 (0.4498) acc 75.0000 (75.4464) kd_loss 0.7464 (0.6841) lr 2.2949e-04 eta 0:03:56
epoch [41/50] batch [160/246] time 0.100 (0.102) data 0.000 (0.002) loss 2.0137 (1.8338) teacher_loss 1.0375 (0.9252) loss_zs_kd 0.7369 (0.5646) loss_oracle 0.4686 (0.4493) acc 71.8750 (75.5859) kd_loss 0.7419 (0.6840) lr 2.2949e-04 eta 0:03:54
epoch [41/50] batch [180/246] time 0.100 (0.102) data 0.000 (0.002) loss 1.6380 (1.8420) teacher_loss 0.7201 (0.9318) loss_zs_kd 0.6466 (0.5692) loss_oracle 0.5017 (0.4498) acc 78.1250 (75.3472) kd_loss 0.6670 (0.6853) lr 2.2949e-04 eta 0:03:53
epoch [41/50] batch [200/246] time 0.104 (0.102) data 0.000 (0.002) loss 1.8591 (1.8412) teacher_loss 1.0703 (0.9283) loss_zs_kd 0.5980 (0.5700) loss_oracle 0.4252 (0.4501) acc 75.0000 (75.3906) kd_loss 0.5762 (0.6879) lr 2.2949e-04 eta 0:03:51
epoch [41/50] batch [220/246] time 0.100 (0.103) data 0.000 (0.001) loss 2.0007 (1.8357) teacher_loss 1.2544 (0.9247) loss_zs_kd 0.5392 (0.5715) loss_oracle 0.3807 (0.4494) acc 68.7500 (75.4688) kd_loss 0.5560 (0.6864) lr 2.2949e-04 eta 0:03:49
epoch [41/50] batch [240/246] time 0.107 (0.103) data 0.000 (0.001) loss 1.7383 (1.8393) teacher_loss 0.8788 (0.9281) loss_zs_kd 0.6081 (0.5736) loss_oracle 0.4461 (0.4489) acc 81.2500 (75.4036) kd_loss 0.6365 (0.6868) lr 2.2949e-04 eta 0:03:48
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,891
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,951
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [42/50] batch [20/246] time 0.081 (0.113) data 0.000 (0.015) loss 1.4502 (1.8016) teacher_loss 0.4359 (0.8854) loss_zs_kd 0.4615 (0.5631) loss_oracle 0.4675 (0.4473) acc 90.6250 (77.5000) kd_loss 0.7805 (0.6925) lr 1.9098e-04 eta 0:04:08
epoch [42/50] batch [40/246] time 0.095 (0.101) data 0.000 (0.008) loss 1.8229 (1.7971) teacher_loss 0.8437 (0.8831) loss_zs_kd 0.8171 (0.5776) loss_oracle 0.4591 (0.4530) acc 75.0000 (76.7969) kd_loss 0.7497 (0.6875) lr 1.9098e-04 eta 0:03:40
epoch [42/50] batch [60/246] time 0.092 (0.099) data 0.000 (0.005) loss 2.3037 (1.8126) teacher_loss 1.4125 (0.8961) loss_zs_kd 0.5561 (0.5680) loss_oracle 0.4363 (0.4537) acc 65.6250 (76.3021) kd_loss 0.6730 (0.6897) lr 1.9098e-04 eta 0:03:33
epoch [42/50] batch [80/246] time 0.086 (0.097) data 0.000 (0.004) loss 1.7657 (1.8388) teacher_loss 0.9408 (0.9208) loss_zs_kd 0.5186 (0.5834) loss_oracle 0.4289 (0.4534) acc 71.8750 (75.3906) kd_loss 0.6104 (0.6913) lr 1.9098e-04 eta 0:03:28
epoch [42/50] batch [100/246] time 0.091 (0.096) data 0.000 (0.003) loss 2.1280 (1.8324) teacher_loss 1.1121 (0.9193) loss_zs_kd 0.6617 (0.5832) loss_oracle 0.4605 (0.4534) acc 68.7500 (75.5000) kd_loss 0.7857 (0.6864) lr 1.9098e-04 eta 0:03:22
epoch [42/50] batch [120/246] time 0.087 (0.095) data 0.000 (0.003) loss 2.4086 (1.8295) teacher_loss 1.5290 (0.9176) loss_zs_kd 0.5510 (0.5881) loss_oracle 0.4938 (0.4526) acc 62.5000 (75.4688) kd_loss 0.6327 (0.6856) lr 1.9098e-04 eta 0:03:18
epoch [42/50] batch [140/246] time 0.099 (0.097) data 0.000 (0.002) loss 1.5839 (1.8383) teacher_loss 0.5264 (0.9263) loss_zs_kd 0.5347 (0.5858) loss_oracle 0.5144 (0.4507) acc 87.5000 (75.5804) kd_loss 0.8003 (0.6867) lr 1.9098e-04 eta 0:03:20
epoch [42/50] batch [160/246] time 0.101 (0.098) data 0.001 (0.002) loss 1.8765 (1.8410) teacher_loss 0.9512 (0.9293) loss_zs_kd 0.5697 (0.5863) loss_oracle 0.4698 (0.4508) acc 75.0000 (75.6055) kd_loss 0.6904 (0.6863) lr 1.9098e-04 eta 0:03:21
epoch [42/50] batch [180/246] time 0.094 (0.098) data 0.000 (0.002) loss 1.6893 (1.8450) teacher_loss 0.8203 (0.9309) loss_zs_kd 0.5344 (0.5901) loss_oracle 0.4628 (0.4504) acc 81.2500 (75.3993) kd_loss 0.6376 (0.6889) lr 1.9098e-04 eta 0:03:19
epoch [42/50] batch [200/246] time 0.101 (0.098) data 0.000 (0.002) loss 2.0877 (1.8505) teacher_loss 0.9764 (0.9358) loss_zs_kd 0.7381 (0.5902) loss_oracle 0.5362 (0.4506) acc 68.7500 (75.3906) kd_loss 0.8432 (0.6894) lr 1.9098e-04 eta 0:03:16
epoch [42/50] batch [220/246] time 0.101 (0.098) data 0.000 (0.002) loss 1.4209 (1.8429) teacher_loss 0.6532 (0.9309) loss_zs_kd 0.4838 (0.5915) loss_oracle 0.4049 (0.4485) acc 81.2500 (75.5256) kd_loss 0.5652 (0.6877) lr 1.9098e-04 eta 0:03:14
epoch [42/50] batch [240/246] time 0.087 (0.097) data 0.000 (0.001) loss 1.7841 (1.8401) teacher_loss 0.7897 (0.9294) loss_zs_kd 0.5347 (0.5888) loss_oracle 0.5236 (0.4493) acc 78.1250 (75.5990) kd_loss 0.7327 (0.6861) lr 1.9098e-04 eta 0:03:11
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,896
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,948
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [43/50] batch [20/246] time 0.096 (0.119) data 0.000 (0.015) loss 1.4664 (1.8844) teacher_loss 0.6041 (0.9433) loss_zs_kd 0.5223 (0.6214) loss_oracle 0.4388 (0.4695) acc 84.3750 (74.2188) kd_loss 0.6428 (0.7063) lr 1.5567e-04 eta 0:03:51
epoch [43/50] batch [40/246] time 0.098 (0.109) data 0.000 (0.008) loss 1.9741 (1.8033) teacher_loss 1.1134 (0.8854) loss_zs_kd 0.5242 (0.5941) loss_oracle 0.4943 (0.4603) acc 71.8750 (75.6250) kd_loss 0.6135 (0.6878) lr 1.5567e-04 eta 0:03:29
epoch [43/50] batch [60/246] time 0.097 (0.107) data 0.000 (0.005) loss 2.6873 (1.8637) teacher_loss 1.8376 (0.9510) loss_zs_kd 0.6914 (0.5972) loss_oracle 0.4100 (0.4501) acc 56.2500 (74.2708) kd_loss 0.6446 (0.6876) lr 1.5567e-04 eta 0:03:23
epoch [43/50] batch [80/246] time 0.095 (0.104) data 0.000 (0.004) loss 1.5769 (1.8386) teacher_loss 0.6904 (0.9302) loss_zs_kd 0.6244 (0.5832) loss_oracle 0.4346 (0.4460) acc 84.3750 (74.6484) kd_loss 0.6692 (0.6854) lr 1.5567e-04 eta 0:03:16
epoch [43/50] batch [100/246] time 0.097 (0.103) data 0.000 (0.003) loss 2.0496 (1.8628) teacher_loss 1.2705 (0.9551) loss_zs_kd 0.7765 (0.5813) loss_oracle 0.3499 (0.4451) acc 71.8750 (74.3125) kd_loss 0.6041 (0.6851) lr 1.5567e-04 eta 0:03:12
epoch [43/50] batch [120/246] time 0.097 (0.102) data 0.000 (0.003) loss 1.4886 (1.8426) teacher_loss 0.5580 (0.9391) loss_zs_kd 0.4947 (0.5717) loss_oracle 0.4803 (0.4423) acc 87.5000 (74.8958) kd_loss 0.6904 (0.6823) lr 1.5567e-04 eta 0:03:09
epoch [43/50] batch [140/246] time 0.094 (0.101) data 0.000 (0.002) loss 1.9194 (1.8454) teacher_loss 0.9563 (0.9419) loss_zs_kd 0.5719 (0.5749) loss_oracle 0.5249 (0.4431) acc 68.7500 (74.8438) kd_loss 0.7007 (0.6819) lr 1.5567e-04 eta 0:03:05
epoch [43/50] batch [160/246] time 0.104 (0.101) data 0.000 (0.002) loss 1.9177 (1.8419) teacher_loss 1.0792 (0.9369) loss_zs_kd 0.7269 (0.5759) loss_oracle 0.5051 (0.4459) acc 75.0000 (75.0195) kd_loss 0.5859 (0.6820) lr 1.5567e-04 eta 0:03:02
epoch [43/50] batch [180/246] time 0.090 (0.101) data 0.000 (0.002) loss 1.5620 (1.8405) teacher_loss 0.6150 (0.9348) loss_zs_kd 0.5230 (0.5773) loss_oracle 0.4874 (0.4453) acc 84.3750 (75.1215) kd_loss 0.7033 (0.6830) lr 1.5567e-04 eta 0:02:59
epoch [43/50] batch [200/246] time 0.103 (0.100) data 0.000 (0.002) loss 1.6202 (1.8408) teacher_loss 0.6755 (0.9360) loss_zs_kd 0.4660 (0.5758) loss_oracle 0.4190 (0.4446) acc 81.2500 (75.1562) kd_loss 0.7352 (0.6825) lr 1.5567e-04 eta 0:02:56
epoch [43/50] batch [220/246] time 0.096 (0.100) data 0.000 (0.002) loss 1.6342 (1.8368) teacher_loss 0.8371 (0.9332) loss_zs_kd 0.3982 (0.5766) loss_oracle 0.4275 (0.4436) acc 81.2500 (75.2273) kd_loss 0.5834 (0.6819) lr 1.5567e-04 eta 0:02:54
epoch [43/50] batch [240/246] time 0.088 (0.099) data 0.000 (0.001) loss 2.3153 (1.8373) teacher_loss 1.3491 (0.9339) loss_zs_kd 0.5142 (0.5792) loss_oracle 0.4768 (0.4440) acc 62.5000 (75.1693) kd_loss 0.7279 (0.6814) lr 1.5567e-04 eta 0:02:51
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,897
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,950
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [44/50] batch [20/246] time 0.096 (0.108) data 0.000 (0.013) loss 1.6964 (1.8270) teacher_loss 0.8211 (0.9180) loss_zs_kd 0.5912 (0.5952) loss_oracle 0.4434 (0.4545) acc 71.8750 (75.1562) kd_loss 0.6536 (0.6817) lr 1.2369e-04 eta 0:03:04
epoch [44/50] batch [40/246] time 0.085 (0.100) data 0.000 (0.007) loss 1.9271 (1.8535) teacher_loss 0.8185 (0.9260) loss_zs_kd 0.6421 (0.5750) loss_oracle 0.5670 (0.4618) acc 81.2500 (75.7031) kd_loss 0.8251 (0.6966) lr 1.2369e-04 eta 0:02:48
epoch [44/50] batch [60/246] time 0.109 (0.099) data 0.001 (0.005) loss 1.8178 (1.8576) teacher_loss 0.9175 (0.9331) loss_zs_kd 0.4398 (0.5790) loss_oracle 0.4578 (0.4597) acc 71.8750 (75.2083) kd_loss 0.6714 (0.6946) lr 1.2369e-04 eta 0:02:45
epoch [44/50] batch [80/246] time 0.094 (0.099) data 0.000 (0.003) loss 1.5535 (1.8503) teacher_loss 0.7282 (0.9252) loss_zs_kd 0.7093 (0.5903) loss_oracle 0.4541 (0.4629) acc 81.2500 (75.1562) kd_loss 0.5983 (0.6937) lr 1.2369e-04 eta 0:02:42
epoch [44/50] batch [100/246] time 0.092 (0.099) data 0.000 (0.003) loss 1.7292 (1.8432) teacher_loss 1.0207 (0.9264) loss_zs_kd 0.6934 (0.5943) loss_oracle 0.3436 (0.4584) acc 78.1250 (75.2500) kd_loss 0.5367 (0.6876) lr 1.2369e-04 eta 0:02:40
epoch [44/50] batch [120/246] time 0.094 (0.098) data 0.000 (0.002) loss 1.8008 (1.8387) teacher_loss 0.8063 (0.9244) loss_zs_kd 0.5639 (0.5936) loss_oracle 0.4178 (0.4555) acc 78.1250 (75.2344) kd_loss 0.7856 (0.6866) lr 1.2369e-04 eta 0:02:37
epoch [44/50] batch [140/246] time 0.099 (0.098) data 0.001 (0.002) loss 1.4412 (1.8266) teacher_loss 0.6179 (0.9124) loss_zs_kd 0.5065 (0.5880) loss_oracle 0.4244 (0.4538) acc 78.1250 (75.4241) kd_loss 0.6112 (0.6872) lr 1.2369e-04 eta 0:02:34
epoch [44/50] batch [160/246] time 0.093 (0.098) data 0.000 (0.002) loss 1.7912 (1.8321) teacher_loss 0.8624 (0.9202) loss_zs_kd 0.8010 (0.5889) loss_oracle 0.4976 (0.4515) acc 84.3750 (75.5273) kd_loss 0.6800 (0.6862) lr 1.2369e-04 eta 0:02:32
epoch [44/50] batch [180/246] time 0.105 (0.098) data 0.001 (0.002) loss 1.7324 (1.8290) teacher_loss 0.8903 (0.9187) loss_zs_kd 0.4880 (0.5879) loss_oracle 0.4794 (0.4507) acc 71.8750 (75.4861) kd_loss 0.6025 (0.6850) lr 1.2369e-04 eta 0:02:30
epoch [44/50] batch [200/246] time 0.095 (0.098) data 0.000 (0.002) loss 1.9285 (1.8274) teacher_loss 1.0096 (0.9138) loss_zs_kd 0.4839 (0.5843) loss_oracle 0.4316 (0.4535) acc 71.8750 (75.4844) kd_loss 0.7031 (0.6868) lr 1.2369e-04 eta 0:02:28
epoch [44/50] batch [220/246] time 0.097 (0.097) data 0.000 (0.001) loss 1.9623 (1.8232) teacher_loss 1.0729 (0.9116) loss_zs_kd 0.3004 (0.5783) loss_oracle 0.4244 (0.4512) acc 71.8750 (75.6534) kd_loss 0.6772 (0.6859) lr 1.2369e-04 eta 0:02:26
epoch [44/50] batch [240/246] time 0.088 (0.097) data 0.000 (0.001) loss 1.6603 (1.8251) teacher_loss 0.6955 (0.9147) loss_zs_kd 0.4902 (0.5770) loss_oracle 0.4929 (0.4526) acc 84.3750 (75.6120) kd_loss 0.7185 (0.6841) lr 1.2369e-04 eta 0:02:23
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,895
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [45/50] batch [20/246] time 0.106 (0.119) data 0.000 (0.015) loss 1.6566 (1.9238) teacher_loss 0.7416 (1.0008) loss_zs_kd 0.5974 (0.5705) loss_oracle 0.4405 (0.4467) acc 78.1250 (74.0625) kd_loss 0.6947 (0.6996) lr 9.5173e-05 eta 0:02:53
epoch [45/50] batch [40/246] time 0.095 (0.109) data 0.000 (0.007) loss 2.5308 (1.8542) teacher_loss 1.6640 (0.9351) loss_zs_kd 0.5109 (0.5819) loss_oracle 0.4343 (0.4484) acc 62.5000 (75.7812) kd_loss 0.6496 (0.6948) lr 9.5173e-05 eta 0:02:35
epoch [45/50] batch [60/246] time 0.106 (0.106) data 0.000 (0.005) loss 2.1414 (1.8392) teacher_loss 1.0647 (0.9229) loss_zs_kd 0.7916 (0.5873) loss_oracle 0.6062 (0.4516) acc 78.1250 (76.1979) kd_loss 0.7736 (0.6905) lr 9.5173e-05 eta 0:02:29
epoch [45/50] batch [80/246] time 0.101 (0.104) data 0.000 (0.004) loss 1.6805 (1.8619) teacher_loss 0.6709 (0.9489) loss_zs_kd 0.6046 (0.5886) loss_oracle 0.4530 (0.4503) acc 84.3750 (75.3125) kd_loss 0.7831 (0.6878) lr 9.5173e-05 eta 0:02:24
epoch [45/50] batch [100/246] time 0.102 (0.103) data 0.000 (0.003) loss 1.8007 (1.8556) teacher_loss 0.8663 (0.9358) loss_zs_kd 0.7559 (0.5913) loss_oracle 0.4431 (0.4527) acc 75.0000 (75.6562) kd_loss 0.7129 (0.6935) lr 9.5173e-05 eta 0:02:22
epoch [45/50] batch [120/246] time 0.099 (0.103) data 0.000 (0.003) loss 1.9431 (1.8474) teacher_loss 0.9917 (0.9300) loss_zs_kd 0.4952 (0.5841) loss_oracle 0.4087 (0.4522) acc 65.6250 (75.7292) kd_loss 0.7471 (0.6913) lr 9.5173e-05 eta 0:02:20
epoch [45/50] batch [140/246] time 0.111 (0.103) data 0.000 (0.002) loss 1.5112 (1.8402) teacher_loss 0.6639 (0.9288) loss_zs_kd 0.4984 (0.5830) loss_oracle 0.3646 (0.4498) acc 78.1250 (75.7366) kd_loss 0.6650 (0.6865) lr 9.5173e-05 eta 0:02:18
epoch [45/50] batch [160/246] time 0.099 (0.103) data 0.000 (0.002) loss 2.0970 (1.8399) teacher_loss 1.2545 (0.9291) loss_zs_kd 0.5858 (0.5822) loss_oracle 0.4432 (0.4500) acc 68.7500 (75.7812) kd_loss 0.6209 (0.6857) lr 9.5173e-05 eta 0:02:15
epoch [45/50] batch [180/246] time 0.100 (0.103) data 0.000 (0.002) loss 2.0807 (1.8414) teacher_loss 1.2736 (0.9335) loss_zs_kd 0.5715 (0.5795) loss_oracle 0.3844 (0.4493) acc 68.7500 (75.6250) kd_loss 0.6149 (0.6833) lr 9.5173e-05 eta 0:02:13
epoch [45/50] batch [200/246] time 0.101 (0.103) data 0.000 (0.002) loss 1.7913 (1.8426) teacher_loss 0.8031 (0.9328) loss_zs_kd 0.5953 (0.5776) loss_oracle 0.4165 (0.4504) acc 81.2500 (75.6094) kd_loss 0.7799 (0.6846) lr 9.5173e-05 eta 0:02:11
epoch [45/50] batch [220/246] time 0.101 (0.103) data 0.000 (0.002) loss 2.2562 (1.8430) teacher_loss 1.1434 (0.9314) loss_zs_kd 0.5710 (0.5764) loss_oracle 0.5373 (0.4498) acc 68.7500 (75.5256) kd_loss 0.8442 (0.6866) lr 9.5173e-05 eta 0:02:09
epoch [45/50] batch [240/246] time 0.108 (0.103) data 0.000 (0.001) loss 2.0326 (1.8408) teacher_loss 1.1107 (0.9300) loss_zs_kd 0.4922 (0.5772) loss_oracle 0.4984 (0.4504) acc 78.1250 (75.6510) kd_loss 0.6727 (0.6856) lr 9.5173e-05 eta 0:02:07
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,899
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,953
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [46/50] batch [20/246] time 0.129 (0.141) data 0.000 (0.017) loss 1.6202 (1.9138) teacher_loss 0.8361 (1.0224) loss_zs_kd 0.5989 (0.5876) loss_oracle 0.4446 (0.4421) acc 78.1250 (73.9062) kd_loss 0.5619 (0.6703) lr 7.0224e-05 eta 0:02:50
epoch [46/50] batch [40/246] time 0.127 (0.134) data 0.000 (0.009) loss 1.5978 (1.9053) teacher_loss 0.7589 (1.0033) loss_zs_kd 0.5944 (0.5800) loss_oracle 0.4548 (0.4469) acc 81.2500 (73.9062) kd_loss 0.6115 (0.6785) lr 7.0224e-05 eta 0:02:39
epoch [46/50] batch [60/246] time 0.100 (0.126) data 0.001 (0.006) loss 1.6342 (1.8958) teacher_loss 0.6587 (0.9904) loss_zs_kd 0.8144 (0.5767) loss_oracle 0.5189 (0.4464) acc 84.3750 (74.1146) kd_loss 0.7161 (0.6821) lr 7.0224e-05 eta 0:02:27
epoch [46/50] batch [80/246] time 0.132 (0.123) data 0.000 (0.004) loss 1.8840 (1.8915) teacher_loss 1.0443 (0.9869) loss_zs_kd 0.5656 (0.5904) loss_oracle 0.4266 (0.4453) acc 71.8750 (74.3359) kd_loss 0.6264 (0.6819) lr 7.0224e-05 eta 0:02:21
epoch [46/50] batch [100/246] time 0.117 (0.122) data 0.000 (0.004) loss 1.4916 (1.8867) teacher_loss 0.6239 (0.9805) loss_zs_kd 0.6322 (0.5958) loss_oracle 0.4472 (0.4461) acc 78.1250 (74.1875) kd_loss 0.6441 (0.6831) lr 7.0224e-05 eta 0:02:18
epoch [46/50] batch [120/246] time 0.110 (0.122) data 0.000 (0.003) loss 1.6289 (1.8724) teacher_loss 0.5039 (0.9654) loss_zs_kd 0.4207 (0.5910) loss_oracle 0.6030 (0.4464) acc 84.3750 (74.4010) kd_loss 0.8234 (0.6838) lr 7.0224e-05 eta 0:02:15
epoch [46/50] batch [140/246] time 0.125 (0.123) data 0.000 (0.003) loss 1.2506 (1.8442) teacher_loss 0.3841 (0.9386) loss_zs_kd 0.7723 (0.5790) loss_oracle 0.3934 (0.4433) acc 90.6250 (75.2679) kd_loss 0.6698 (0.6840) lr 7.0224e-05 eta 0:02:14
epoch [46/50] batch [160/246] time 0.108 (0.123) data 0.000 (0.002) loss 2.2574 (1.8403) teacher_loss 1.1993 (0.9314) loss_zs_kd 0.7281 (0.5838) loss_oracle 0.5156 (0.4445) acc 71.8750 (75.3906) kd_loss 0.8002 (0.6866) lr 7.0224e-05 eta 0:02:11
epoch [46/50] batch [180/246] time 0.133 (0.123) data 0.000 (0.002) loss 1.8885 (1.8355) teacher_loss 0.8544 (0.9273) loss_zs_kd 0.5240 (0.5852) loss_oracle 0.4827 (0.4450) acc 75.0000 (75.4861) kd_loss 0.7928 (0.6857) lr 7.0224e-05 eta 0:02:09
epoch [46/50] batch [200/246] time 0.095 (0.121) data 0.000 (0.002) loss 2.1910 (1.8434) teacher_loss 1.2294 (0.9345) loss_zs_kd 0.8062 (0.5877) loss_oracle 0.4501 (0.4443) acc 71.8750 (75.3594) kd_loss 0.7365 (0.6868) lr 7.0224e-05 eta 0:02:04
epoch [46/50] batch [220/246] time 0.098 (0.119) data 0.000 (0.002) loss 2.1392 (1.8370) teacher_loss 1.1532 (0.9292) loss_zs_kd 0.5157 (0.5883) loss_oracle 0.4322 (0.4436) acc 68.7500 (75.6676) kd_loss 0.7699 (0.6860) lr 7.0224e-05 eta 0:01:59
epoch [46/50] batch [240/246] time 0.109 (0.117) data 0.000 (0.002) loss 1.6245 (1.8352) teacher_loss 0.7141 (0.9303) loss_zs_kd 0.5882 (0.5883) loss_oracle 0.5369 (0.4440) acc 84.3750 (75.7292) kd_loss 0.6420 (0.6829) lr 7.0224e-05 eta 0:01:56
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,900
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 85.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [47/50] batch [20/246] time 0.092 (0.113) data 0.000 (0.014) loss 1.9753 (1.7956) teacher_loss 1.1168 (0.8823) loss_zs_kd 0.4839 (0.5874) loss_oracle 0.4618 (0.4490) acc 71.8750 (75.4688) kd_loss 0.6276 (0.6888) lr 4.8943e-05 eta 0:01:48
epoch [47/50] batch [40/246] time 0.085 (0.102) data 0.000 (0.007) loss 1.7518 (1.8113) teacher_loss 0.8127 (0.9061) loss_zs_kd 0.7527 (0.5975) loss_oracle 0.4771 (0.4485) acc 71.8750 (75.0781) kd_loss 0.7005 (0.6810) lr 4.8943e-05 eta 0:01:36
epoch [47/50] batch [60/246] time 0.098 (0.098) data 0.000 (0.005) loss 1.2749 (1.8093) teacher_loss 0.4314 (0.9095) loss_zs_kd 0.5923 (0.5950) loss_oracle 0.4611 (0.4472) acc 90.6250 (75.3125) kd_loss 0.6130 (0.6762) lr 4.8943e-05 eta 0:01:30
epoch [47/50] batch [80/246] time 0.096 (0.097) data 0.000 (0.004) loss 1.5074 (1.7930) teacher_loss 0.5815 (0.8920) loss_zs_kd 0.3676 (0.5886) loss_oracle 0.4736 (0.4438) acc 81.2500 (75.7031) kd_loss 0.6891 (0.6791) lr 4.8943e-05 eta 0:01:27
epoch [47/50] batch [100/246] time 0.092 (0.096) data 0.000 (0.003) loss 1.7668 (1.8004) teacher_loss 0.8292 (0.8959) loss_zs_kd 0.9149 (0.5886) loss_oracle 0.5081 (0.4475) acc 75.0000 (75.7500) kd_loss 0.6835 (0.6807) lr 4.8943e-05 eta 0:01:24
epoch [47/50] batch [120/246] time 0.084 (0.095) data 0.000 (0.003) loss 1.7328 (1.8160) teacher_loss 0.8846 (0.9141) loss_zs_kd 0.4824 (0.5933) loss_oracle 0.3962 (0.4473) acc 75.0000 (75.3125) kd_loss 0.6501 (0.6783) lr 4.8943e-05 eta 0:01:22
epoch [47/50] batch [140/246] time 0.091 (0.095) data 0.000 (0.002) loss 1.7667 (1.8128) teacher_loss 0.7355 (0.9081) loss_zs_kd 0.5841 (0.5939) loss_oracle 0.5028 (0.4483) acc 78.1250 (75.7366) kd_loss 0.7797 (0.6805) lr 4.8943e-05 eta 0:01:19
epoch [47/50] batch [160/246] time 0.093 (0.094) data 0.000 (0.002) loss 1.5319 (1.8121) teacher_loss 0.6567 (0.9073) loss_zs_kd 0.4437 (0.5937) loss_oracle 0.4812 (0.4468) acc 81.2500 (75.9570) kd_loss 0.6346 (0.6813) lr 4.8943e-05 eta 0:01:17
epoch [47/50] batch [180/246] time 0.095 (0.094) data 0.000 (0.002) loss 1.4491 (1.8114) teacher_loss 0.6050 (0.9080) loss_zs_kd 0.5938 (0.5898) loss_oracle 0.3868 (0.4466) acc 78.1250 (75.9028) kd_loss 0.6507 (0.6800) lr 4.8943e-05 eta 0:01:15
epoch [47/50] batch [200/246] time 0.093 (0.094) data 0.000 (0.002) loss 1.7497 (1.8088) teacher_loss 0.7313 (0.9046) loss_zs_kd 0.4896 (0.5842) loss_oracle 0.5115 (0.4462) acc 78.1250 (75.9219) kd_loss 0.7626 (0.6811) lr 4.8943e-05 eta 0:01:13
epoch [47/50] batch [220/246] time 0.096 (0.094) data 0.000 (0.001) loss 1.5130 (1.8166) teacher_loss 0.5614 (0.9148) loss_zs_kd 0.5127 (0.5842) loss_oracle 0.4151 (0.4448) acc 90.6250 (75.7812) kd_loss 0.7441 (0.6794) lr 4.8943e-05 eta 0:01:12
epoch [47/50] batch [240/246] time 0.087 (0.094) data 0.000 (0.001) loss 2.1053 (1.8211) teacher_loss 1.1763 (0.9201) loss_zs_kd 0.6257 (0.5864) loss_oracle 0.5013 (0.4448) acc 68.7500 (75.6120) kd_loss 0.6783 (0.6786) lr 4.8943e-05 eta 0:01:09
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,897
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [48/50] batch [20/246] time 0.087 (0.110) data 0.000 (0.014) loss 1.4660 (1.7743) teacher_loss 0.5313 (0.8694) loss_zs_kd 0.5540 (0.5971) loss_oracle 0.4412 (0.4353) acc 87.5000 (77.6562) kd_loss 0.7142 (0.6873) lr 3.1417e-05 eta 0:01:19
epoch [48/50] batch [40/246] time 0.098 (0.102) data 0.000 (0.007) loss 1.7537 (1.7617) teacher_loss 0.8290 (0.8543) loss_zs_kd 0.6042 (0.5957) loss_oracle 0.4095 (0.4410) acc 75.0000 (76.8750) kd_loss 0.7200 (0.6869) lr 3.1417e-05 eta 0:01:11
epoch [48/50] batch [60/246] time 0.084 (0.099) data 0.001 (0.005) loss 2.0697 (1.7529) teacher_loss 1.0167 (0.8385) loss_zs_kd 0.6834 (0.5847) loss_oracle 0.4693 (0.4419) acc 68.7500 (77.5521) kd_loss 0.8183 (0.6934) lr 3.1417e-05 eta 0:01:06
epoch [48/50] batch [80/246] time 0.092 (0.097) data 0.000 (0.004) loss 1.8968 (1.7755) teacher_loss 0.9329 (0.8696) loss_zs_kd 0.5827 (0.5854) loss_oracle 0.5010 (0.4426) acc 75.0000 (76.3672) kd_loss 0.7134 (0.6847) lr 3.1417e-05 eta 0:01:04
epoch [48/50] batch [100/246] time 0.086 (0.096) data 0.000 (0.003) loss 2.0568 (1.7924) teacher_loss 1.1682 (0.8813) loss_zs_kd 0.6840 (0.5852) loss_oracle 0.3771 (0.4431) acc 71.8750 (76.0938) kd_loss 0.7001 (0.6895) lr 3.1417e-05 eta 0:01:01
epoch [48/50] batch [120/246] time 0.093 (0.095) data 0.000 (0.002) loss 2.0795 (1.8156) teacher_loss 1.1212 (0.9015) loss_zs_kd 0.4549 (0.5903) loss_oracle 0.4705 (0.4477) acc 65.6250 (75.6510) kd_loss 0.7231 (0.6902) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [140/246] time 0.099 (0.095) data 0.000 (0.002) loss 2.1211 (1.8201) teacher_loss 1.2259 (0.9104) loss_zs_kd 0.5192 (0.5912) loss_oracle 0.4313 (0.4474) acc 68.7500 (75.4911) kd_loss 0.6795 (0.6860) lr 3.1417e-05 eta 0:00:57
epoch [48/50] batch [160/246] time 0.094 (0.096) data 0.000 (0.002) loss 1.5292 (1.8360) teacher_loss 0.5909 (0.9263) loss_zs_kd 0.5477 (0.5900) loss_oracle 0.5325 (0.4470) acc 84.3750 (75.2734) kd_loss 0.6721 (0.6862) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [180/246] time 0.096 (0.096) data 0.000 (0.002) loss 2.3443 (1.8307) teacher_loss 1.3771 (0.9234) loss_zs_kd 0.5104 (0.5846) loss_oracle 0.4620 (0.4459) acc 59.3750 (75.3299) kd_loss 0.7362 (0.6844) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [200/246] time 0.097 (0.096) data 0.000 (0.002) loss 1.9294 (1.8425) teacher_loss 1.1176 (0.9346) loss_zs_kd 0.5112 (0.5849) loss_oracle 0.4022 (0.4454) acc 71.8750 (75.0938) kd_loss 0.6107 (0.6852) lr 3.1417e-05 eta 0:00:51
epoch [48/50] batch [220/246] time 0.097 (0.096) data 0.000 (0.001) loss 1.8029 (1.8475) teacher_loss 0.9127 (0.9393) loss_zs_kd 0.6541 (0.5875) loss_oracle 0.4642 (0.4458) acc 81.2500 (75.0568) kd_loss 0.6581 (0.6852) lr 3.1417e-05 eta 0:00:49
epoch [48/50] batch [240/246] time 0.087 (0.095) data 0.000 (0.001) loss 2.5479 (1.8549) teacher_loss 1.5057 (0.9450) loss_zs_kd 0.5856 (0.5874) loss_oracle 0.5033 (0.4456) acc 75.0000 (74.9609) kd_loss 0.7905 (0.6871) lr 3.1417e-05 eta 0:00:47
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,896
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [49/50] batch [20/246] time 0.097 (0.127) data 0.000 (0.015) loss 1.8811 (1.8151) teacher_loss 1.0464 (0.9098) loss_zs_kd 0.5532 (0.5921) loss_oracle 0.4446 (0.4462) acc 75.0000 (77.6562) kd_loss 0.6124 (0.6821) lr 1.7713e-05 eta 0:01:00
epoch [49/50] batch [40/246] time 0.095 (0.113) data 0.000 (0.008) loss 1.6540 (1.7799) teacher_loss 0.7178 (0.8640) loss_zs_kd 0.6291 (0.5867) loss_oracle 0.5177 (0.4533) acc 78.1250 (77.9688) kd_loss 0.6773 (0.6893) lr 1.7713e-05 eta 0:00:51
epoch [49/50] batch [60/246] time 0.103 (0.109) data 0.001 (0.005) loss 1.5314 (1.8093) teacher_loss 0.6446 (0.9011) loss_zs_kd 0.8963 (0.5845) loss_oracle 0.4645 (0.4471) acc 87.5000 (76.5104) kd_loss 0.6546 (0.6847) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [80/246] time 0.098 (0.107) data 0.001 (0.004) loss 2.0271 (1.8078) teacher_loss 1.0020 (0.9007) loss_zs_kd 0.6122 (0.5769) loss_oracle 0.4236 (0.4465) acc 78.1250 (76.7188) kd_loss 0.8133 (0.6839) lr 1.7713e-05 eta 0:00:44
epoch [49/50] batch [100/246] time 0.098 (0.106) data 0.000 (0.003) loss 1.9153 (1.8429) teacher_loss 1.0629 (0.9355) loss_zs_kd 0.6734 (0.5740) loss_oracle 0.4753 (0.4493) acc 68.7500 (75.5938) kd_loss 0.6148 (0.6827) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [120/246] time 0.102 (0.106) data 0.000 (0.003) loss 1.5052 (1.8384) teacher_loss 0.5291 (0.9294) loss_zs_kd 0.6314 (0.5658) loss_oracle 0.5355 (0.4493) acc 87.5000 (75.8073) kd_loss 0.7084 (0.6843) lr 1.7713e-05 eta 0:00:39
epoch [49/50] batch [140/246] time 0.101 (0.105) data 0.000 (0.002) loss 2.2107 (1.8340) teacher_loss 1.2476 (0.9256) loss_zs_kd 0.5338 (0.5679) loss_oracle 0.4286 (0.4500) acc 68.7500 (75.8929) kd_loss 0.7489 (0.6834) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [160/246] time 0.099 (0.104) data 0.000 (0.002) loss 2.0995 (1.8312) teacher_loss 1.3408 (0.9245) loss_zs_kd 0.7461 (0.5751) loss_oracle 0.3835 (0.4480) acc 62.5000 (76.0547) kd_loss 0.5670 (0.6826) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [180/246] time 0.112 (0.104) data 0.000 (0.002) loss 1.7146 (1.8289) teacher_loss 0.7348 (0.9231) loss_zs_kd 0.6201 (0.5775) loss_oracle 0.5238 (0.4482) acc 78.1250 (76.0243) kd_loss 0.7179 (0.6817) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [200/246] time 0.102 (0.104) data 0.000 (0.002) loss 2.4236 (1.8390) teacher_loss 1.5930 (0.9327) loss_zs_kd 0.6260 (0.5804) loss_oracle 0.4284 (0.4499) acc 59.3750 (75.7344) kd_loss 0.6164 (0.6814) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [220/246] time 0.097 (0.104) data 0.000 (0.002) loss 1.7184 (1.8329) teacher_loss 0.7497 (0.9273) loss_zs_kd 0.7881 (0.5833) loss_oracle 0.5172 (0.4498) acc 81.2500 (75.8949) kd_loss 0.7101 (0.6808) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [240/246] time 0.108 (0.104) data 0.000 (0.001) loss 1.8927 (1.8274) teacher_loss 0.9172 (0.9198) loss_zs_kd 0.5442 (0.5821) loss_oracle 0.5239 (0.4499) acc 71.8750 (75.9245) kd_loss 0.7136 (0.6826) lr 1.7713e-05 eta 0:00:26
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,896
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,953
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
epoch [50/50] batch [20/246] time 0.096 (0.126) data 0.000 (0.015) loss 1.8339 (1.7715) teacher_loss 1.0196 (0.8609) loss_zs_kd 0.7108 (0.5954) loss_oracle 0.4302 (0.4505) acc 68.7500 (76.7188) kd_loss 0.5992 (0.6854) lr 7.8853e-06 eta 0:00:28
epoch [50/50] batch [40/246] time 0.103 (0.111) data 0.000 (0.007) loss 1.9534 (1.7781) teacher_loss 1.0191 (0.8651) loss_zs_kd 0.5255 (0.5836) loss_oracle 0.5148 (0.4516) acc 81.2500 (76.6406) kd_loss 0.6768 (0.6872) lr 7.8853e-06 eta 0:00:22
epoch [50/50] batch [60/246] time 0.094 (0.107) data 0.001 (0.005) loss 2.3982 (1.8096) teacher_loss 1.3961 (0.8981) loss_zs_kd 0.7756 (0.5921) loss_oracle 0.4369 (0.4489) acc 65.6250 (76.5104) kd_loss 0.7837 (0.6870) lr 7.8853e-06 eta 0:00:19
epoch [50/50] batch [80/246] time 0.092 (0.106) data 0.000 (0.004) loss 1.8893 (1.8331) teacher_loss 0.9737 (0.9194) loss_zs_kd 0.4720 (0.5872) loss_oracle 0.4928 (0.4556) acc 71.8750 (75.8984) kd_loss 0.6692 (0.6858) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [100/246] time 0.097 (0.105) data 0.000 (0.003) loss 2.7541 (1.8510) teacher_loss 1.7502 (0.9397) loss_zs_kd 0.6474 (0.5866) loss_oracle 0.4570 (0.4535) acc 71.8750 (75.6250) kd_loss 0.7754 (0.6846) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [120/246] time 0.102 (0.105) data 0.000 (0.003) loss 1.5262 (1.8354) teacher_loss 0.6061 (0.9365) loss_zs_kd 0.6756 (0.5937) loss_oracle 0.4599 (0.4490) acc 78.1250 (75.6250) kd_loss 0.6902 (0.6744) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [140/246] time 0.097 (0.104) data 0.000 (0.002) loss 1.7722 (1.8311) teacher_loss 0.8089 (0.9281) loss_zs_kd 0.5755 (0.5869) loss_oracle 0.4001 (0.4509) acc 78.1250 (75.8036) kd_loss 0.7632 (0.6775) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [160/246] time 0.092 (0.103) data 0.000 (0.002) loss 1.7084 (1.8366) teacher_loss 0.7785 (0.9326) loss_zs_kd 0.5045 (0.5856) loss_oracle 0.4565 (0.4513) acc 81.2500 (75.7227) kd_loss 0.7017 (0.6784) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [180/246] time 0.091 (0.102) data 0.000 (0.002) loss 1.7161 (1.8264) teacher_loss 0.9350 (0.9249) loss_zs_kd 0.6602 (0.5865) loss_oracle 0.3628 (0.4500) acc 78.1250 (75.8681) kd_loss 0.5997 (0.6764) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [200/246] time 0.101 (0.102) data 0.000 (0.002) loss 1.8505 (1.8258) teacher_loss 0.9331 (0.9214) loss_zs_kd 0.5469 (0.5838) loss_oracle 0.4679 (0.4503) acc 78.1250 (76.1406) kd_loss 0.6835 (0.6793) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [220/246] time 0.099 (0.101) data 0.000 (0.002) loss 2.0921 (1.8394) teacher_loss 1.3712 (0.9352) loss_zs_kd 0.5840 (0.5862) loss_oracle 0.4276 (0.4502) acc 65.6250 (75.7528) kd_loss 0.5072 (0.6791) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [240/246] time 0.087 (0.100) data 0.000 (0.001) loss 1.9559 (1.8440) teacher_loss 1.0913 (0.9383) loss_zs_kd 0.6226 (0.5838) loss_oracle 0.3938 (0.4497) acc 68.7500 (75.5078) kd_loss 0.6676 (0.6808) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,897
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      86.6%, epoch: 35 *******
******* Domain r best val test acc: 90.6%, epoch: 35 *******
******* Domain r best test acc:     91.1%, epoch: 27 *******
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:27:03

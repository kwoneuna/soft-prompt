Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------------
Dataset    SPG_OfficeHome
Source     ['clipart', 'product', 'real_world']
Target     ['art']
# classes  65
# train_x  9,222
# val      3,939
# test     2,427
---------  ------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/288] time 0.101 (0.156) data 0.000 (0.022) loss 1.4443 (1.5893) teacher_loss 1.1101 (1.2381) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0001 (-0.0001) acc 71.8750 (68.5938) kd_loss 0.3342 (0.3512) lr 1.0000e-05 eta 0:37:28
epoch [1/50] batch [40/288] time 0.095 (0.130) data 0.000 (0.011) loss 1.6059 (1.6020) teacher_loss 1.2156 (1.2593) loss_zs_kd 0.0002 (0.0001) loss_oracle -0.0001 (-0.0001) acc 65.6250 (68.3594) kd_loss 0.3903 (0.3428) lr 1.0000e-05 eta 0:31:13
epoch [1/50] batch [60/288] time 0.099 (0.121) data 0.000 (0.008) loss 1.6988 (1.6234) teacher_loss 1.4267 (1.2662) loss_zs_kd 0.0007 (0.0001) loss_oracle 0.0002 (-0.0000) acc 59.3750 (67.7083) kd_loss 0.2719 (0.3572) lr 1.0000e-05 eta 0:28:58
epoch [1/50] batch [80/288] time 0.115 (0.118) data 0.000 (0.006) loss 1.5902 (1.6447) teacher_loss 1.2552 (1.2701) loss_zs_kd 0.0009 (0.0002) loss_oracle 0.0000 (-0.0000) acc 62.5000 (67.4219) kd_loss 0.3350 (0.3746) lr 1.0000e-05 eta 0:28:09
epoch [1/50] batch [100/288] time 0.097 (0.116) data 0.000 (0.005) loss 1.4800 (1.6126) teacher_loss 1.0898 (1.2424) loss_zs_kd 0.0006 (0.0003) loss_oracle 0.0000 (-0.0000) acc 62.5000 (68.1250) kd_loss 0.3901 (0.3702) lr 1.0000e-05 eta 0:27:41
epoch [1/50] batch [120/288] time 0.087 (0.113) data 0.000 (0.004) loss 1.4387 (1.6102) teacher_loss 1.0321 (1.2362) loss_zs_kd 0.0008 (0.0004) loss_oracle 0.0001 (-0.0000) acc 75.0000 (68.1771) kd_loss 0.4065 (0.3740) lr 1.0000e-05 eta 0:26:47
epoch [1/50] batch [140/288] time 0.083 (0.109) data 0.000 (0.003) loss 1.9072 (1.6008) teacher_loss 1.4843 (1.2222) loss_zs_kd 0.0012 (0.0005) loss_oracle 0.0001 (0.0000) acc 56.2500 (68.3036) kd_loss 0.4228 (0.3786) lr 1.0000e-05 eta 0:26:01
epoch [1/50] batch [160/288] time 0.098 (0.108) data 0.000 (0.003) loss 1.2077 (1.5955) teacher_loss 1.0575 (1.2196) loss_zs_kd 0.0020 (0.0007) loss_oracle 0.0001 (0.0000) acc 71.8750 (68.6328) kd_loss 0.1501 (0.3759) lr 1.0000e-05 eta 0:25:37
epoch [1/50] batch [180/288] time 0.102 (0.107) data 0.000 (0.003) loss 1.3087 (1.5963) teacher_loss 0.9927 (1.2231) loss_zs_kd 0.0027 (0.0008) loss_oracle 0.0001 (0.0000) acc 71.8750 (68.4549) kd_loss 0.3160 (0.3732) lr 1.0000e-05 eta 0:25:18
epoch [1/50] batch [200/288] time 0.091 (0.106) data 0.000 (0.002) loss 1.7901 (1.5921) teacher_loss 1.3384 (1.2198) loss_zs_kd 0.0023 (0.0009) loss_oracle 0.0001 (0.0000) acc 62.5000 (68.3438) kd_loss 0.4517 (0.3722) lr 1.0000e-05 eta 0:25:01
epoch [1/50] batch [220/288] time 0.102 (0.105) data 0.000 (0.002) loss 1.4825 (1.5850) teacher_loss 1.4136 (1.2153) loss_zs_kd 0.0027 (0.0011) loss_oracle 0.0000 (0.0000) acc 68.7500 (68.6222) kd_loss 0.0688 (0.3696) lr 1.0000e-05 eta 0:24:44
epoch [1/50] batch [240/288] time 0.103 (0.104) data 0.000 (0.002) loss 1.3227 (1.5805) teacher_loss 0.9842 (1.2128) loss_zs_kd 0.0013 (0.0013) loss_oracle 0.0000 (0.0000) acc 81.2500 (68.8932) kd_loss 0.3384 (0.3676) lr 1.0000e-05 eta 0:24:27
epoch [1/50] batch [260/288] time 0.085 (0.103) data 0.000 (0.002) loss 1.8037 (1.5857) teacher_loss 1.2970 (1.2182) loss_zs_kd 0.0063 (0.0014) loss_oracle 0.0000 (0.0000) acc 71.8750 (68.7620) kd_loss 0.5067 (0.3675) lr 1.0000e-05 eta 0:24:16
epoch [1/50] batch [280/288] time 0.085 (0.103) data 0.000 (0.002) loss 1.7362 (1.5853) teacher_loss 1.5180 (1.2181) loss_zs_kd 0.0063 (0.0017) loss_oracle 0.0000 (0.0000) acc 65.6250 (68.8170) kd_loss 0.2182 (0.3672) lr 1.0000e-05 eta 0:24:15
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,268
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 82.0%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,966
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 76.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      83.0%, epoch: 1 *******
******* Domain a best val test acc: 81.0%, epoch: 1 *******
******* Domain a best test acc:     81.0%, epoch: 1 *******
epoch [2/50] batch [20/288] time 0.101 (0.121) data 0.000 (0.019) loss 1.6199 (1.7249) teacher_loss 0.9845 (1.1874) loss_zs_kd 0.1409 (0.1157) loss_oracle 0.2359 (0.1090) acc 71.8750 (68.4375) kd_loss 0.5174 (0.4830) lr 2.0000e-03 eta 0:28:22
epoch [2/50] batch [40/288] time 0.082 (0.106) data 0.000 (0.010) loss 1.2817 (1.6983) teacher_loss 0.7053 (1.1164) loss_zs_kd 0.1750 (0.1586) loss_oracle 0.1783 (0.1527) acc 84.3750 (71.0156) kd_loss 0.4872 (0.5055) lr 2.0000e-03 eta 0:24:52
epoch [2/50] batch [60/288] time 0.101 (0.106) data 0.000 (0.006) loss 2.0963 (1.7204) teacher_loss 1.4334 (1.1150) loss_zs_kd 0.2314 (0.1745) loss_oracle 0.2183 (0.1711) acc 65.6250 (71.6146) kd_loss 0.5538 (0.5197) lr 2.0000e-03 eta 0:24:48
epoch [2/50] batch [80/288] time 0.109 (0.106) data 0.000 (0.005) loss 1.6300 (1.7308) teacher_loss 0.7927 (1.0939) loss_zs_kd 0.2204 (0.1843) loss_oracle 0.3245 (0.1956) acc 75.0000 (71.9531) kd_loss 0.6750 (0.5391) lr 2.0000e-03 eta 0:24:50
epoch [2/50] batch [100/288] time 0.096 (0.105) data 0.000 (0.004) loss 2.0943 (1.7490) teacher_loss 1.4293 (1.0891) loss_zs_kd 0.2453 (0.1991) loss_oracle 0.3040 (0.2182) acc 65.6250 (71.9375) kd_loss 0.5131 (0.5508) lr 2.0000e-03 eta 0:24:32
epoch [2/50] batch [120/288] time 0.090 (0.104) data 0.000 (0.003) loss 2.0505 (1.7748) teacher_loss 1.0576 (1.0840) loss_zs_kd 0.1464 (0.2069) loss_oracle 0.4825 (0.2478) acc 71.8750 (71.9531) kd_loss 0.7517 (0.5669) lr 2.0000e-03 eta 0:24:17
epoch [2/50] batch [140/288] time 0.098 (0.104) data 0.000 (0.003) loss 2.1003 (1.8296) teacher_loss 1.1564 (1.0853) loss_zs_kd 0.3078 (0.2102) loss_oracle 0.5695 (0.2965) acc 75.0000 (72.0312) kd_loss 0.6592 (0.5961) lr 2.0000e-03 eta 0:24:06
epoch [2/50] batch [160/288] time 0.112 (0.103) data 0.000 (0.003) loss 1.7782 (1.8489) teacher_loss 1.0919 (1.0864) loss_zs_kd 0.4248 (0.2131) loss_oracle 0.2897 (0.3108) acc 71.8750 (72.0898) kd_loss 0.5416 (0.6071) lr 2.0000e-03 eta 0:23:59
epoch [2/50] batch [180/288] time 0.093 (0.103) data 0.000 (0.002) loss 1.7116 (1.8433) teacher_loss 0.9661 (1.0800) loss_zs_kd 0.2502 (0.2179) loss_oracle 0.2689 (0.3113) acc 78.1250 (72.1875) kd_loss 0.6110 (0.6076) lr 2.0000e-03 eta 0:24:00
epoch [2/50] batch [200/288] time 0.114 (0.103) data 0.001 (0.002) loss 2.4933 (1.8360) teacher_loss 1.7378 (1.0800) loss_zs_kd 0.3345 (0.2246) loss_oracle 0.2079 (0.3060) acc 56.2500 (71.9062) kd_loss 0.6515 (0.6030) lr 2.0000e-03 eta 0:23:50
epoch [2/50] batch [220/288] time 0.123 (0.104) data 0.001 (0.002) loss 1.9011 (1.8236) teacher_loss 1.1335 (1.0686) loss_zs_kd 0.3126 (0.2286) loss_oracle 0.2914 (0.3059) acc 75.0000 (72.1449) kd_loss 0.6220 (0.6021) lr 2.0000e-03 eta 0:24:01
epoch [2/50] batch [240/288] time 0.107 (0.106) data 0.000 (0.002) loss 2.2728 (1.8300) teacher_loss 1.2078 (1.0644) loss_zs_kd 0.2629 (0.2326) loss_oracle 0.6314 (0.3155) acc 68.7500 (72.3307) kd_loss 0.7494 (0.6078) lr 2.0000e-03 eta 0:24:35
epoch [2/50] batch [260/288] time 0.098 (0.106) data 0.000 (0.002) loss 1.9441 (1.8517) teacher_loss 1.0178 (1.0612) loss_zs_kd 0.3693 (0.2354) loss_oracle 0.4248 (0.3379) acc 75.0000 (72.3317) kd_loss 0.7139 (0.6216) lr 2.0000e-03 eta 0:24:25
epoch [2/50] batch [280/288] time 0.103 (0.106) data 0.000 (0.002) loss 1.8207 (1.8613) teacher_loss 0.7987 (1.0574) loss_zs_kd 0.3065 (0.2369) loss_oracle 0.5266 (0.3507) acc 68.7500 (72.3214) kd_loss 0.7587 (0.6286) lr 2.0000e-03 eta 0:24:19
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,393
* accuracy: 86.1%
* error: 13.9%
* macro_f1: 85.5%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,022
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 79.7%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.1%, epoch: 2 *******
******* Domain a best val test acc: 83.3%, epoch: 2 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [3/50] batch [20/288] time 0.134 (0.139) data 0.001 (0.015) loss 2.3812 (2.0999) teacher_loss 1.4118 (1.0400) loss_zs_kd 0.3456 (0.2748) loss_oracle 0.5848 (0.5904) acc 50.0000 (71.4062) kd_loss 0.6770 (0.7647) lr 1.9980e-03 eta 0:32:02
epoch [3/50] batch [40/288] time 0.107 (0.129) data 0.000 (0.008) loss 1.8927 (2.0013) teacher_loss 0.7621 (0.9781) loss_zs_kd 0.1850 (0.2639) loss_oracle 0.6006 (0.5606) acc 84.3750 (73.5156) kd_loss 0.8302 (0.7429) lr 1.9980e-03 eta 0:29:43
epoch [3/50] batch [60/288] time 0.112 (0.122) data 0.001 (0.005) loss 2.2060 (2.1068) teacher_loss 1.0146 (1.0386) loss_zs_kd 0.1732 (0.2585) loss_oracle 0.7241 (0.5982) acc 75.0000 (72.3958) kd_loss 0.8294 (0.7691) lr 1.9980e-03 eta 0:27:56
epoch [3/50] batch [80/288] time 0.101 (0.116) data 0.000 (0.004) loss 2.0740 (2.1495) teacher_loss 0.9910 (1.0404) loss_zs_kd 0.2378 (0.2506) loss_oracle 0.6577 (0.6359) acc 71.8750 (72.2656) kd_loss 0.7542 (0.7911) lr 1.9980e-03 eta 0:26:40
epoch [3/50] batch [100/288] time 0.106 (0.113) data 0.000 (0.003) loss 2.0026 (2.1527) teacher_loss 1.0509 (1.0452) loss_zs_kd 0.2189 (0.2505) loss_oracle 0.5208 (0.6316) acc 71.8750 (72.3125) kd_loss 0.6914 (0.7916) lr 1.9980e-03 eta 0:25:45
epoch [3/50] batch [120/288] time 0.091 (0.111) data 0.000 (0.003) loss 1.7048 (2.1167) teacher_loss 0.7325 (1.0310) loss_zs_kd 0.2569 (0.2534) loss_oracle 0.4905 (0.6135) acc 81.2500 (72.7344) kd_loss 0.7271 (0.7789) lr 1.9980e-03 eta 0:25:15
epoch [3/50] batch [140/288] time 0.101 (0.109) data 0.000 (0.002) loss 1.9408 (2.0987) teacher_loss 1.0365 (1.0283) loss_zs_kd 0.2010 (0.2531) loss_oracle 0.4975 (0.6008) acc 75.0000 (72.7009) kd_loss 0.6555 (0.7701) lr 1.9980e-03 eta 0:24:49
epoch [3/50] batch [160/288] time 0.100 (0.108) data 0.000 (0.002) loss 2.4154 (2.0845) teacher_loss 1.5501 (1.0305) loss_zs_kd 0.3152 (0.2592) loss_oracle 0.4762 (0.5861) acc 62.5000 (72.6367) kd_loss 0.6272 (0.7610) lr 1.9980e-03 eta 0:24:33
epoch [3/50] batch [180/288] time 0.136 (0.107) data 0.000 (0.002) loss 1.9821 (2.0657) teacher_loss 1.1412 (1.0287) loss_zs_kd 0.2828 (0.2606) loss_oracle 0.4202 (0.5688) acc 71.8750 (72.7951) kd_loss 0.6308 (0.7526) lr 1.9980e-03 eta 0:24:21
epoch [3/50] batch [200/288] time 0.101 (0.108) data 0.000 (0.002) loss 1.9220 (2.0481) teacher_loss 0.9305 (1.0236) loss_zs_kd 0.2558 (0.2624) loss_oracle 0.5133 (0.5556) acc 84.3750 (72.9219) kd_loss 0.7348 (0.7468) lr 1.9980e-03 eta 0:24:26
epoch [3/50] batch [220/288] time 0.113 (0.107) data 0.000 (0.002) loss 1.8930 (2.0509) teacher_loss 0.8390 (1.0340) loss_zs_kd 0.3868 (0.2686) loss_oracle 0.5287 (0.5495) acc 71.8750 (72.7841) kd_loss 0.7897 (0.7421) lr 1.9980e-03 eta 0:24:22
epoch [3/50] batch [240/288] time 0.114 (0.107) data 0.000 (0.001) loss 2.2536 (2.0423) teacher_loss 1.4457 (1.0393) loss_zs_kd 0.2310 (0.2693) loss_oracle 0.3374 (0.5377) acc 62.5000 (72.6693) kd_loss 0.6392 (0.7342) lr 1.9980e-03 eta 0:24:10
epoch [3/50] batch [260/288] time 0.110 (0.107) data 0.000 (0.001) loss 1.4746 (2.0269) teacher_loss 0.6102 (1.0336) loss_zs_kd 0.2876 (0.2689) loss_oracle 0.4932 (0.5312) acc 84.3750 (72.7404) kd_loss 0.6178 (0.7277) lr 1.9980e-03 eta 0:24:10
epoch [3/50] batch [280/288] time 0.107 (0.107) data 0.000 (0.001) loss 1.9363 (2.0150) teacher_loss 1.0126 (1.0280) loss_zs_kd 0.5205 (0.2737) loss_oracle 0.4745 (0.5256) acc 65.6250 (72.8906) kd_loss 0.6864 (0.7242) lr 1.9980e-03 eta 0:24:04
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,406
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 85.7%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,017
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.5%
******* Domain a best val acc:      86.5%, epoch: 3 *******
******* Domain a best val test acc: 83.1%, epoch: 3 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [4/50] batch [20/288] time 0.125 (0.126) data 0.000 (0.014) loss 1.6783 (1.8532) teacher_loss 0.7502 (0.9446) loss_zs_kd 0.2816 (0.2872) loss_oracle 0.5104 (0.4801) acc 84.3750 (74.3750) kd_loss 0.6728 (0.6685) lr 1.9921e-03 eta 0:28:20
epoch [4/50] batch [40/288] time 0.101 (0.116) data 0.000 (0.007) loss 1.7541 (1.8626) teacher_loss 1.0118 (0.9738) loss_zs_kd 0.4270 (0.2884) loss_oracle 0.3925 (0.4651) acc 71.8750 (74.2969) kd_loss 0.5461 (0.6562) lr 1.9921e-03 eta 0:26:11
epoch [4/50] batch [60/288] time 0.101 (0.112) data 0.001 (0.005) loss 2.2222 (1.8393) teacher_loss 1.3220 (0.9685) loss_zs_kd 0.2916 (0.2851) loss_oracle 0.4370 (0.4446) acc 59.3750 (74.3750) kd_loss 0.6817 (0.6486) lr 1.9921e-03 eta 0:25:12
epoch [4/50] batch [80/288] time 0.108 (0.110) data 0.000 (0.004) loss 2.2120 (1.8599) teacher_loss 1.3858 (0.9881) loss_zs_kd 0.2752 (0.2837) loss_oracle 0.4737 (0.4426) acc 68.7500 (74.1406) kd_loss 0.5894 (0.6504) lr 1.9921e-03 eta 0:24:33
epoch [4/50] batch [100/288] time 0.100 (0.108) data 0.000 (0.003) loss 1.6540 (1.8710) teacher_loss 0.8646 (1.0061) loss_zs_kd 0.2158 (0.2770) loss_oracle 0.3540 (0.4338) acc 81.2500 (73.8438) kd_loss 0.6123 (0.6480) lr 1.9921e-03 eta 0:24:15
epoch [4/50] batch [120/288] time 0.099 (0.107) data 0.000 (0.003) loss 1.8481 (1.8674) teacher_loss 0.9226 (1.0144) loss_zs_kd 0.2615 (0.2738) loss_oracle 0.3508 (0.4200) acc 71.8750 (73.4115) kd_loss 0.7500 (0.6430) lr 1.9921e-03 eta 0:23:58
epoch [4/50] batch [140/288] time 0.149 (0.107) data 0.001 (0.002) loss 1.6421 (1.8675) teacher_loss 0.7049 (1.0196) loss_zs_kd 0.2541 (0.2720) loss_oracle 0.3318 (0.4078) acc 84.3750 (73.2143) kd_loss 0.7713 (0.6440) lr 1.9921e-03 eta 0:23:53
epoch [4/50] batch [160/288] time 0.108 (0.107) data 0.000 (0.002) loss 1.9319 (1.8490) teacher_loss 1.1933 (1.0102) loss_zs_kd 0.2754 (0.2732) loss_oracle 0.3737 (0.4010) acc 71.8750 (73.4375) kd_loss 0.5517 (0.6383) lr 1.9921e-03 eta 0:23:57
epoch [4/50] batch [180/288] time 0.103 (0.107) data 0.000 (0.002) loss 2.1710 (1.8435) teacher_loss 1.3883 (1.0076) loss_zs_kd 0.3823 (0.2747) loss_oracle 0.3236 (0.3990) acc 56.2500 (73.4896) kd_loss 0.6209 (0.6364) lr 1.9921e-03 eta 0:23:47
epoch [4/50] batch [200/288] time 0.102 (0.106) data 0.000 (0.002) loss 1.9441 (1.8382) teacher_loss 1.0608 (1.0061) loss_zs_kd 0.2635 (0.2800) loss_oracle 0.3563 (0.3954) acc 65.6250 (73.5625) kd_loss 0.7051 (0.6343) lr 1.9921e-03 eta 0:23:37
epoch [4/50] batch [220/288] time 0.099 (0.106) data 0.000 (0.002) loss 1.9684 (1.8356) teacher_loss 1.1400 (1.0048) loss_zs_kd 0.3243 (0.2842) loss_oracle 0.3648 (0.3956) acc 65.6250 (73.3949) kd_loss 0.6460 (0.6330) lr 1.9921e-03 eta 0:23:30
epoch [4/50] batch [240/288] time 0.103 (0.106) data 0.000 (0.001) loss 2.0821 (1.8304) teacher_loss 1.2207 (1.0034) loss_zs_kd 0.2515 (0.2846) loss_oracle 0.3409 (0.3929) acc 75.0000 (73.5547) kd_loss 0.6909 (0.6306) lr 1.9921e-03 eta 0:23:23
epoch [4/50] batch [260/288] time 0.098 (0.105) data 0.000 (0.001) loss 1.6752 (1.8373) teacher_loss 0.8411 (1.0079) loss_zs_kd 0.3182 (0.2853) loss_oracle 0.4347 (0.3960) acc 68.7500 (73.3654) kd_loss 0.6167 (0.6314) lr 1.9921e-03 eta 0:23:19
epoch [4/50] batch [280/288] time 0.110 (0.105) data 0.000 (0.001) loss 1.7136 (1.8389) teacher_loss 0.7686 (1.0043) loss_zs_kd 0.2019 (0.2849) loss_oracle 0.4640 (0.4007) acc 78.1250 (73.5379) kd_loss 0.7129 (0.6342) lr 1.9921e-03 eta 0:23:15
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,422
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.2%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,016
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.7%
******* Domain a best val acc:      86.9%, epoch: 4 *******
******* Domain a best val test acc: 83.1%, epoch: 4 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [5/50] batch [20/288] time 0.092 (0.113) data 0.000 (0.014) loss 2.2501 (1.9964) teacher_loss 1.4457 (1.1355) loss_zs_kd 0.2797 (0.2833) loss_oracle 0.3064 (0.3834) acc 68.7500 (70.0000) kd_loss 0.6512 (0.6692) lr 1.9823e-03 eta 0:24:57
epoch [5/50] batch [40/288] time 0.091 (0.104) data 0.000 (0.007) loss 1.1936 (1.8315) teacher_loss 0.4579 (1.0274) loss_zs_kd 0.3796 (0.2861) loss_oracle 0.2559 (0.3386) acc 90.6250 (72.5781) kd_loss 0.6078 (0.6348) lr 1.9823e-03 eta 0:22:48
epoch [5/50] batch [60/288] time 0.102 (0.101) data 0.000 (0.005) loss 1.7201 (1.7752) teacher_loss 1.1579 (0.9967) loss_zs_kd 0.2140 (0.2830) loss_oracle 0.2791 (0.3136) acc 62.5000 (73.8021) kd_loss 0.4226 (0.6217) lr 1.9823e-03 eta 0:22:17
epoch [5/50] batch [80/288] time 0.095 (0.100) data 0.000 (0.004) loss 2.0959 (1.7434) teacher_loss 1.4338 (0.9787) loss_zs_kd 0.2501 (0.2925) loss_oracle 0.2955 (0.3116) acc 71.8750 (74.1797) kd_loss 0.5143 (0.6089) lr 1.9823e-03 eta 0:22:02
epoch [5/50] batch [100/288] time 0.094 (0.099) data 0.001 (0.003) loss 1.4473 (1.7565) teacher_loss 0.5702 (0.9887) loss_zs_kd 0.3175 (0.2957) loss_oracle 0.4219 (0.3189) acc 84.3750 (73.6562) kd_loss 0.6662 (0.6083) lr 1.9823e-03 eta 0:21:48
epoch [5/50] batch [120/288] time 0.108 (0.102) data 0.001 (0.002) loss 1.8201 (1.7525) teacher_loss 0.9575 (0.9780) loss_zs_kd 0.4194 (0.2979) loss_oracle 0.4676 (0.3281) acc 71.8750 (73.8542) kd_loss 0.6287 (0.6105) lr 1.9823e-03 eta 0:22:17
epoch [5/50] batch [140/288] time 0.106 (0.102) data 0.000 (0.002) loss 1.6967 (1.7731) teacher_loss 1.0349 (0.9832) loss_zs_kd 0.2559 (0.3023) loss_oracle 0.3419 (0.3376) acc 75.0000 (73.8393) kd_loss 0.4908 (0.6212) lr 1.9823e-03 eta 0:22:15
epoch [5/50] batch [160/288] time 0.097 (0.102) data 0.000 (0.002) loss 2.1728 (1.7786) teacher_loss 1.1809 (0.9848) loss_zs_kd 0.2699 (0.3031) loss_oracle 0.4593 (0.3409) acc 68.7500 (73.6719) kd_loss 0.7622 (0.6234) lr 1.9823e-03 eta 0:22:09
epoch [5/50] batch [180/288] time 0.102 (0.101) data 0.000 (0.002) loss 1.7015 (1.7913) teacher_loss 0.9359 (0.9925) loss_zs_kd 0.2728 (0.3063) loss_oracle 0.3458 (0.3470) acc 75.0000 (73.4549) kd_loss 0.5927 (0.6252) lr 1.9823e-03 eta 0:22:03
epoch [5/50] batch [200/288] time 0.094 (0.101) data 0.000 (0.002) loss 1.7864 (1.7956) teacher_loss 0.9556 (0.9973) loss_zs_kd 0.3273 (0.3051) loss_oracle 0.4532 (0.3505) acc 81.2500 (73.6094) kd_loss 0.6041 (0.6230) lr 1.9823e-03 eta 0:21:57
epoch [5/50] batch [220/288] time 0.102 (0.101) data 0.001 (0.001) loss 2.1719 (1.8017) teacher_loss 1.2199 (1.0020) loss_zs_kd 0.2988 (0.3049) loss_oracle 0.4072 (0.3566) acc 75.0000 (73.3381) kd_loss 0.7485 (0.6214) lr 1.9823e-03 eta 0:21:53
epoch [5/50] batch [240/288] time 0.091 (0.100) data 0.000 (0.001) loss 1.5635 (1.7992) teacher_loss 0.7554 (0.9991) loss_zs_kd 0.2480 (0.3050) loss_oracle 0.3635 (0.3593) acc 81.2500 (73.3203) kd_loss 0.6264 (0.6204) lr 1.9823e-03 eta 0:21:46
epoch [5/50] batch [260/288] time 0.109 (0.100) data 0.000 (0.001) loss 1.9644 (1.7963) teacher_loss 1.0800 (0.9956) loss_zs_kd 0.1974 (0.3043) loss_oracle 0.3794 (0.3604) acc 68.7500 (73.3654) kd_loss 0.6947 (0.6205) lr 1.9823e-03 eta 0:21:43
epoch [5/50] batch [280/288] time 0.089 (0.100) data 0.000 (0.001) loss 1.6583 (1.7906) teacher_loss 0.7413 (0.9867) loss_zs_kd 0.2986 (0.3030) loss_oracle 0.4131 (0.3633) acc 84.3750 (73.5938) kd_loss 0.7105 (0.6223) lr 1.9823e-03 eta 0:21:36
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,433
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.4%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.9%
******* Domain a best val acc:      87.2%, epoch: 5 *******
******* Domain a best val test acc: 83.1%, epoch: 5 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [6/50] batch [20/288] time 0.091 (0.112) data 0.000 (0.014) loss 2.0026 (1.7516) teacher_loss 1.0733 (0.8833) loss_zs_kd 0.2132 (0.2725) loss_oracle 0.3732 (0.3955) acc 68.7500 (73.2812) kd_loss 0.7427 (0.6705) lr 1.9686e-03 eta 0:24:08
epoch [6/50] batch [40/288] time 0.099 (0.104) data 0.000 (0.007) loss 1.7947 (1.8050) teacher_loss 0.9894 (0.9451) loss_zs_kd 0.3096 (0.2899) loss_oracle 0.3700 (0.3928) acc 71.8750 (72.6562) kd_loss 0.6203 (0.6634) lr 1.9686e-03 eta 0:22:19
epoch [6/50] batch [60/288] time 0.095 (0.101) data 0.000 (0.005) loss 1.8413 (1.7759) teacher_loss 1.0063 (0.9306) loss_zs_kd 0.3434 (0.2968) loss_oracle 0.3849 (0.3910) acc 65.6250 (73.3333) kd_loss 0.6426 (0.6498) lr 1.9686e-03 eta 0:21:47
epoch [6/50] batch [80/288] time 0.099 (0.100) data 0.000 (0.004) loss 1.6310 (1.7637) teacher_loss 0.9617 (0.9367) loss_zs_kd 0.3586 (0.3076) loss_oracle 0.3168 (0.3808) acc 68.7500 (73.3203) kd_loss 0.5109 (0.6365) lr 1.9686e-03 eta 0:21:27
epoch [6/50] batch [100/288] time 0.090 (0.102) data 0.000 (0.003) loss 2.1625 (1.7741) teacher_loss 1.1646 (0.9492) loss_zs_kd 0.3667 (0.3091) loss_oracle 0.4132 (0.3749) acc 62.5000 (73.5312) kd_loss 0.7913 (0.6375) lr 1.9686e-03 eta 0:21:52
epoch [6/50] batch [120/288] time 0.094 (0.101) data 0.000 (0.003) loss 1.8256 (1.7740) teacher_loss 1.0895 (0.9450) loss_zs_kd 0.4499 (0.3122) loss_oracle 0.3414 (0.3788) acc 68.7500 (73.6979) kd_loss 0.5654 (0.6396) lr 1.9686e-03 eta 0:21:38
epoch [6/50] batch [140/288] time 0.093 (0.100) data 0.000 (0.002) loss 1.5971 (1.7724) teacher_loss 0.8404 (0.9480) loss_zs_kd 0.2127 (0.3145) loss_oracle 0.3516 (0.3784) acc 78.1250 (73.6384) kd_loss 0.5809 (0.6352) lr 1.9686e-03 eta 0:21:28
epoch [6/50] batch [160/288] time 0.091 (0.100) data 0.000 (0.002) loss 1.3270 (1.7739) teacher_loss 0.5603 (0.9475) loss_zs_kd 0.3940 (0.3202) loss_oracle 0.3540 (0.3763) acc 78.1250 (73.6133) kd_loss 0.5898 (0.6383) lr 1.9686e-03 eta 0:21:19
epoch [6/50] batch [180/288] time 0.099 (0.100) data 0.000 (0.002) loss 1.5639 (1.7691) teacher_loss 0.7231 (0.9490) loss_zs_kd 0.4582 (0.3242) loss_oracle 0.3519 (0.3720) acc 81.2500 (73.7847) kd_loss 0.6649 (0.6341) lr 1.9686e-03 eta 0:21:12
epoch [6/50] batch [200/288] time 0.095 (0.099) data 0.000 (0.002) loss 1.5601 (1.7724) teacher_loss 0.9365 (0.9565) loss_zs_kd 0.3046 (0.3242) loss_oracle 0.3414 (0.3710) acc 71.8750 (73.7344) kd_loss 0.4530 (0.6304) lr 1.9686e-03 eta 0:21:04
epoch [6/50] batch [220/288] time 0.092 (0.099) data 0.000 (0.001) loss 1.9302 (1.7762) teacher_loss 1.0951 (0.9608) loss_zs_kd 0.4220 (0.3260) loss_oracle 0.3589 (0.3691) acc 71.8750 (73.7074) kd_loss 0.6556 (0.6309) lr 1.9686e-03 eta 0:20:59
epoch [6/50] batch [240/288] time 0.097 (0.099) data 0.000 (0.001) loss 1.5705 (1.7777) teacher_loss 0.8866 (0.9650) loss_zs_kd 0.1913 (0.3256) loss_oracle 0.3878 (0.3660) acc 75.0000 (73.5026) kd_loss 0.4900 (0.6297) lr 1.9686e-03 eta 0:20:54
epoch [6/50] batch [260/288] time 0.094 (0.098) data 0.001 (0.001) loss 2.0105 (1.7831) teacher_loss 1.1919 (0.9677) loss_zs_kd 0.2791 (0.3286) loss_oracle 0.3493 (0.3635) acc 68.7500 (73.4495) kd_loss 0.6440 (0.6336) lr 1.9686e-03 eta 0:20:50
epoch [6/50] batch [280/288] time 0.089 (0.098) data 0.000 (0.001) loss 1.9756 (1.7795) teacher_loss 1.2247 (0.9685) loss_zs_kd 0.4734 (0.3317) loss_oracle 0.3300 (0.3617) acc 78.1250 (73.6272) kd_loss 0.5859 (0.6302) lr 1.9686e-03 eta 0:20:44
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,414
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 86.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,009
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 79.2%
******* Domain a best val acc:      87.2%, epoch: 5 *******
******* Domain a best val test acc: 83.1%, epoch: 5 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [7/50] batch [20/288] time 0.107 (0.124) data 0.000 (0.014) loss 2.0557 (1.7554) teacher_loss 1.1791 (1.0074) loss_zs_kd 0.3103 (0.3200) loss_oracle 0.3087 (0.2972) acc 68.7500 (74.5312) kd_loss 0.7222 (0.5995) lr 1.9511e-03 eta 0:26:06
epoch [7/50] batch [40/288] time 0.105 (0.114) data 0.000 (0.007) loss 1.6489 (1.7190) teacher_loss 0.7183 (0.9576) loss_zs_kd 0.2957 (0.3167) loss_oracle 0.3522 (0.2968) acc 81.2500 (75.0000) kd_loss 0.7545 (0.6129) lr 1.9511e-03 eta 0:24:02
epoch [7/50] batch [60/288] time 0.110 (0.110) data 0.001 (0.005) loss 1.8224 (1.6967) teacher_loss 1.1542 (0.9286) loss_zs_kd 0.3928 (0.3194) loss_oracle 0.2816 (0.2969) acc 68.7500 (74.9479) kd_loss 0.5274 (0.6196) lr 1.9511e-03 eta 0:23:01
epoch [7/50] batch [80/288] time 0.122 (0.111) data 0.000 (0.004) loss 1.6431 (1.6965) teacher_loss 0.8807 (0.9269) loss_zs_kd 0.3690 (0.3228) loss_oracle 0.3038 (0.2971) acc 81.2500 (75.0781) kd_loss 0.6106 (0.6210) lr 1.9511e-03 eta 0:23:12
epoch [7/50] batch [100/288] time 0.122 (0.112) data 0.001 (0.003) loss 1.3704 (1.7054) teacher_loss 0.5648 (0.9248) loss_zs_kd 0.3203 (0.3236) loss_oracle 0.2965 (0.2970) acc 87.5000 (75.1875) kd_loss 0.6573 (0.6322) lr 1.9511e-03 eta 0:23:28
epoch [7/50] batch [120/288] time 0.122 (0.114) data 0.001 (0.003) loss 2.4029 (1.7161) teacher_loss 1.4742 (0.9265) loss_zs_kd 0.3291 (0.3236) loss_oracle 0.4024 (0.2994) acc 68.7500 (75.2344) kd_loss 0.7275 (0.6399) lr 1.9511e-03 eta 0:23:54
epoch [7/50] batch [140/288] time 0.123 (0.116) data 0.000 (0.002) loss 1.9345 (1.7274) teacher_loss 1.0865 (0.9368) loss_zs_kd 0.3001 (0.3251) loss_oracle 0.3273 (0.3059) acc 68.7500 (75.1339) kd_loss 0.6844 (0.6376) lr 1.9511e-03 eta 0:24:12
epoch [7/50] batch [160/288] time 0.122 (0.117) data 0.000 (0.002) loss 1.8701 (1.7520) teacher_loss 1.0217 (0.9529) loss_zs_kd 0.3234 (0.3241) loss_oracle 0.3779 (0.3126) acc 71.8750 (74.6875) kd_loss 0.6595 (0.6428) lr 1.9511e-03 eta 0:24:23
epoch [7/50] batch [180/288] time 0.096 (0.117) data 0.000 (0.002) loss 1.6506 (1.7599) teacher_loss 1.0114 (0.9604) loss_zs_kd 0.3143 (0.3250) loss_oracle 0.2772 (0.3142) acc 75.0000 (74.6181) kd_loss 0.5006 (0.6424) lr 1.9511e-03 eta 0:24:27
epoch [7/50] batch [200/288] time 0.096 (0.116) data 0.000 (0.002) loss 1.3479 (1.7468) teacher_loss 0.6248 (0.9498) loss_zs_kd 0.3578 (0.3271) loss_oracle 0.3101 (0.3137) acc 78.1250 (74.9219) kd_loss 0.5680 (0.6402) lr 1.9511e-03 eta 0:24:02
epoch [7/50] batch [220/288] time 0.097 (0.114) data 0.001 (0.002) loss 2.0324 (1.7469) teacher_loss 1.2797 (0.9525) loss_zs_kd 0.3383 (0.3276) loss_oracle 0.3288 (0.3132) acc 68.7500 (74.8295) kd_loss 0.5884 (0.6378) lr 1.9511e-03 eta 0:23:44
epoch [7/50] batch [240/288] time 0.096 (0.113) data 0.000 (0.001) loss 2.1942 (1.7519) teacher_loss 1.3615 (0.9600) loss_zs_kd 0.3280 (0.3273) loss_oracle 0.3132 (0.3119) acc 62.5000 (74.7656) kd_loss 0.6760 (0.6359) lr 1.9511e-03 eta 0:23:25
epoch [7/50] batch [260/288] time 0.098 (0.112) data 0.000 (0.001) loss 1.7706 (1.7561) teacher_loss 0.9880 (0.9615) loss_zs_kd 0.2552 (0.3254) loss_oracle 0.3183 (0.3124) acc 75.0000 (74.6514) kd_loss 0.6234 (0.6384) lr 1.9511e-03 eta 0:23:14
epoch [7/50] batch [280/288] time 0.105 (0.112) data 0.000 (0.001) loss 1.4060 (1.7540) teacher_loss 0.5971 (0.9573) loss_zs_kd 0.2759 (0.3226) loss_oracle 0.2897 (0.3129) acc 81.2500 (74.8103) kd_loss 0.6641 (0.6403) lr 1.9511e-03 eta 0:23:02
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,437
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.6%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,012
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.3%
******* Domain a best val acc:      87.3%, epoch: 7 *******
******* Domain a best val test acc: 82.9%, epoch: 7 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [8/50] batch [20/288] time 0.153 (0.137) data 0.000 (0.018) loss 1.7451 (1.7771) teacher_loss 0.8885 (0.9418) loss_zs_kd 0.4489 (0.3248) loss_oracle 0.3315 (0.3361) acc 78.1250 (74.3750) kd_loss 0.6909 (0.6673) lr 1.9298e-03 eta 0:28:17
epoch [8/50] batch [40/288] time 0.105 (0.133) data 0.000 (0.009) loss 1.5199 (1.7370) teacher_loss 0.7863 (0.9273) loss_zs_kd 0.3470 (0.3159) loss_oracle 0.3102 (0.3242) acc 81.2500 (74.5312) kd_loss 0.5785 (0.6475) lr 1.9298e-03 eta 0:27:22
epoch [8/50] batch [60/288] time 0.116 (0.127) data 0.000 (0.006) loss 2.4158 (1.7161) teacher_loss 1.4958 (0.9163) loss_zs_kd 0.2086 (0.3127) loss_oracle 0.3083 (0.3167) acc 62.5000 (74.6875) kd_loss 0.7659 (0.6415) lr 1.9298e-03 eta 0:26:09
epoch [8/50] batch [80/288] time 0.096 (0.121) data 0.000 (0.005) loss 1.8547 (1.6886) teacher_loss 1.0355 (0.9096) loss_zs_kd 0.2203 (0.3175) loss_oracle 0.3071 (0.3168) acc 65.6250 (75.0000) kd_loss 0.6656 (0.6207) lr 1.9298e-03 eta 0:24:47
epoch [8/50] batch [100/288] time 0.104 (0.118) data 0.000 (0.004) loss 1.4563 (1.6902) teacher_loss 0.7360 (0.9141) loss_zs_kd 0.4638 (0.3227) loss_oracle 0.3205 (0.3176) acc 87.5000 (75.0000) kd_loss 0.5601 (0.6173) lr 1.9298e-03 eta 0:24:05
epoch [8/50] batch [120/288] time 0.098 (0.115) data 0.000 (0.003) loss 1.7057 (1.6672) teacher_loss 0.7936 (0.9044) loss_zs_kd 0.3743 (0.3299) loss_oracle 0.3309 (0.3094) acc 78.1250 (75.2344) kd_loss 0.7466 (0.6082) lr 1.9298e-03 eta 0:23:33
epoch [8/50] batch [140/288] time 0.116 (0.113) data 0.000 (0.003) loss 1.5310 (1.6718) teacher_loss 0.9264 (0.9125) loss_zs_kd 0.4315 (0.3338) loss_oracle 0.3238 (0.3077) acc 71.8750 (75.0670) kd_loss 0.4427 (0.6055) lr 1.9298e-03 eta 0:23:07
epoch [8/50] batch [160/288] time 0.110 (0.112) data 0.000 (0.003) loss 1.8042 (1.6913) teacher_loss 1.1322 (0.9342) loss_zs_kd 0.3735 (0.3355) loss_oracle 0.3187 (0.3092) acc 71.8750 (74.5703) kd_loss 0.5127 (0.6026) lr 1.9298e-03 eta 0:22:53
epoch [8/50] batch [180/288] time 0.104 (0.111) data 0.000 (0.002) loss 2.0267 (1.6941) teacher_loss 1.2766 (0.9356) loss_zs_kd 0.2800 (0.3351) loss_oracle 0.3628 (0.3131) acc 71.8750 (74.5660) kd_loss 0.5687 (0.6020) lr 1.9298e-03 eta 0:22:39
epoch [8/50] batch [200/288] time 0.094 (0.110) data 0.000 (0.002) loss 1.9442 (1.6965) teacher_loss 1.2348 (0.9398) loss_zs_kd 0.2981 (0.3361) loss_oracle 0.3640 (0.3144) acc 71.8750 (74.5156) kd_loss 0.5274 (0.5996) lr 1.9298e-03 eta 0:22:22
epoch [8/50] batch [220/288] time 0.103 (0.109) data 0.000 (0.002) loss 1.3050 (1.6914) teacher_loss 0.6786 (0.9376) loss_zs_kd 0.2990 (0.3346) loss_oracle 0.3129 (0.3136) acc 84.3750 (74.6449) kd_loss 0.4699 (0.5970) lr 1.9298e-03 eta 0:22:06
epoch [8/50] batch [240/288] time 0.097 (0.108) data 0.000 (0.002) loss 1.6638 (1.6950) teacher_loss 0.9305 (0.9426) loss_zs_kd 0.3746 (0.3360) loss_oracle 0.3959 (0.3143) acc 75.0000 (74.4531) kd_loss 0.5354 (0.5953) lr 1.9298e-03 eta 0:21:54
epoch [8/50] batch [260/288] time 0.106 (0.107) data 0.000 (0.002) loss 1.6149 (1.6969) teacher_loss 0.8123 (0.9428) loss_zs_kd 0.4626 (0.3352) loss_oracle 0.4044 (0.3176) acc 78.1250 (74.5793) kd_loss 0.6004 (0.5953) lr 1.9298e-03 eta 0:21:42
epoch [8/50] batch [280/288] time 0.091 (0.107) data 0.000 (0.002) loss 2.2310 (1.7076) teacher_loss 1.4972 (0.9513) loss_zs_kd 0.4038 (0.3328) loss_oracle 0.3240 (0.3207) acc 56.2500 (74.3862) kd_loss 0.5717 (0.5959) lr 1.9298e-03 eta 0:21:29
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,433
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,004
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 79.3%
******* Domain a best val acc:      87.3%, epoch: 7 *******
******* Domain a best val test acc: 82.9%, epoch: 7 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [9/50] batch [20/288] time 0.101 (0.117) data 0.000 (0.015) loss 1.7723 (1.6992) teacher_loss 1.1133 (0.9574) loss_zs_kd 0.3315 (0.3486) loss_oracle 0.3585 (0.3336) acc 71.8750 (75.6250) kd_loss 0.4797 (0.5750) lr 1.9048e-03 eta 0:23:34
epoch [9/50] batch [40/288] time 0.092 (0.106) data 0.000 (0.007) loss 1.3289 (1.6776) teacher_loss 0.5922 (0.9059) loss_zs_kd 0.2573 (0.3385) loss_oracle 0.3567 (0.3451) acc 87.5000 (76.6406) kd_loss 0.5584 (0.5991) lr 1.9048e-03 eta 0:21:20
epoch [9/50] batch [60/288] time 0.100 (0.101) data 0.000 (0.005) loss 1.6301 (1.6813) teacher_loss 0.9805 (0.9063) loss_zs_kd 0.3326 (0.3439) loss_oracle 0.3241 (0.3448) acc 78.1250 (76.1979) kd_loss 0.4876 (0.6026) lr 1.9048e-03 eta 0:20:21
epoch [9/50] batch [80/288] time 0.088 (0.100) data 0.000 (0.004) loss 1.5496 (1.7124) teacher_loss 0.7951 (0.9436) loss_zs_kd 0.3473 (0.3546) loss_oracle 0.3132 (0.3418) acc 84.3750 (75.1953) kd_loss 0.5979 (0.5978) lr 1.9048e-03 eta 0:19:58
epoch [9/50] batch [100/288] time 0.099 (0.099) data 0.000 (0.003) loss 1.5433 (1.7102) teacher_loss 0.6624 (0.9431) loss_zs_kd 0.2924 (0.3506) loss_oracle 0.3837 (0.3431) acc 81.2500 (75.0938) kd_loss 0.6891 (0.5955) lr 1.9048e-03 eta 0:19:46
epoch [9/50] batch [120/288] time 0.093 (0.099) data 0.000 (0.003) loss 1.5539 (1.7149) teacher_loss 0.9024 (0.9524) loss_zs_kd 0.4084 (0.3508) loss_oracle 0.2706 (0.3413) acc 78.1250 (74.6875) kd_loss 0.5162 (0.5918) lr 1.9048e-03 eta 0:19:50
epoch [9/50] batch [140/288] time 0.094 (0.099) data 0.000 (0.002) loss 1.5888 (1.7197) teacher_loss 0.9580 (0.9605) loss_zs_kd 0.1894 (0.3518) loss_oracle 0.2591 (0.3377) acc 75.0000 (74.6429) kd_loss 0.5012 (0.5903) lr 1.9048e-03 eta 0:19:45
epoch [9/50] batch [160/288] time 0.093 (0.099) data 0.000 (0.002) loss 1.5994 (1.7170) teacher_loss 0.7160 (0.9542) loss_zs_kd 0.4177 (0.3580) loss_oracle 0.3073 (0.3366) acc 87.5000 (74.6680) kd_loss 0.7298 (0.5945) lr 1.9048e-03 eta 0:19:40
epoch [9/50] batch [180/288] time 0.096 (0.099) data 0.000 (0.002) loss 2.2841 (1.7156) teacher_loss 1.5958 (0.9570) loss_zs_kd 0.4038 (0.3557) loss_oracle 0.3266 (0.3338) acc 68.7500 (74.7396) kd_loss 0.5251 (0.5917) lr 1.9048e-03 eta 0:19:36
epoch [9/50] batch [200/288] time 0.088 (0.098) data 0.000 (0.002) loss 1.9502 (1.7199) teacher_loss 1.3426 (0.9671) loss_zs_kd 0.3498 (0.3562) loss_oracle 0.3172 (0.3291) acc 71.8750 (74.5781) kd_loss 0.4490 (0.5883) lr 1.9048e-03 eta 0:19:30
epoch [9/50] batch [220/288] time 0.099 (0.098) data 0.000 (0.001) loss 1.5777 (1.7219) teacher_loss 0.6874 (0.9686) loss_zs_kd 0.4140 (0.3541) loss_oracle 0.3892 (0.3296) acc 81.2500 (74.5170) kd_loss 0.6957 (0.5885) lr 1.9048e-03 eta 0:19:25
epoch [9/50] batch [240/288] time 0.108 (0.098) data 0.001 (0.001) loss 1.5360 (1.7221) teacher_loss 0.8696 (0.9660) loss_zs_kd 0.5649 (0.3534) loss_oracle 0.3368 (0.3309) acc 78.1250 (74.6094) kd_loss 0.4979 (0.5906) lr 1.9048e-03 eta 0:19:25
epoch [9/50] batch [260/288] time 0.105 (0.098) data 0.000 (0.001) loss 1.5126 (1.7217) teacher_loss 0.9240 (0.9679) loss_zs_kd 0.3049 (0.3532) loss_oracle 0.2236 (0.3278) acc 68.7500 (74.5553) kd_loss 0.4768 (0.5899) lr 1.9048e-03 eta 0:19:25
epoch [9/50] batch [280/288] time 0.087 (0.098) data 0.000 (0.001) loss 1.6481 (1.7161) teacher_loss 0.9521 (0.9609) loss_zs_kd 0.2017 (0.3536) loss_oracle 0.2834 (0.3253) acc 71.8750 (74.6540) kd_loss 0.5542 (0.5926) lr 1.9048e-03 eta 0:19:19
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,441
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,000
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 79.2%
******* Domain a best val acc:      87.4%, epoch: 9 *******
******* Domain a best val test acc: 82.4%, epoch: 9 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [10/50] batch [20/288] time 0.096 (0.106) data 0.000 (0.013) loss 1.6916 (1.7456) teacher_loss 0.7848 (0.9921) loss_zs_kd 0.2599 (0.3347) loss_oracle 0.2756 (0.2856) acc 78.1250 (75.1562) kd_loss 0.7689 (0.6107) lr 1.8763e-03 eta 0:20:50
epoch [10/50] batch [40/288] time 0.098 (0.101) data 0.000 (0.006) loss 1.8857 (1.6960) teacher_loss 1.0979 (0.9357) loss_zs_kd 0.3905 (0.3412) loss_oracle 0.3038 (0.2862) acc 65.6250 (75.6250) kd_loss 0.6359 (0.6172) lr 1.8763e-03 eta 0:19:46
epoch [10/50] batch [60/288] time 0.096 (0.099) data 0.000 (0.004) loss 1.6564 (1.6763) teacher_loss 0.8837 (0.9085) loss_zs_kd 0.2769 (0.3397) loss_oracle 0.2974 (0.2887) acc 75.0000 (76.2500) kd_loss 0.6240 (0.6235) lr 1.8763e-03 eta 0:19:28
epoch [10/50] batch [80/288] time 0.098 (0.099) data 0.000 (0.003) loss 1.8471 (1.7049) teacher_loss 1.0763 (0.9318) loss_zs_kd 0.2188 (0.3496) loss_oracle 0.3271 (0.2985) acc 78.1250 (75.6250) kd_loss 0.6072 (0.6239) lr 1.8763e-03 eta 0:19:21
epoch [10/50] batch [100/288] time 0.092 (0.099) data 0.000 (0.003) loss 2.0642 (1.6906) teacher_loss 1.2520 (0.9204) loss_zs_kd 0.3565 (0.3442) loss_oracle 0.3005 (0.3002) acc 71.8750 (75.6875) kd_loss 0.6620 (0.6201) lr 1.8763e-03 eta 0:19:14
epoch [10/50] batch [120/288] time 0.105 (0.099) data 0.000 (0.002) loss 1.6603 (1.6870) teacher_loss 0.8591 (0.9187) loss_zs_kd 0.2938 (0.3445) loss_oracle 0.2960 (0.3009) acc 78.1250 (75.4948) kd_loss 0.6532 (0.6179) lr 1.8763e-03 eta 0:19:13
epoch [10/50] batch [140/288] time 0.098 (0.099) data 0.000 (0.002) loss 1.9247 (1.6950) teacher_loss 1.2302 (0.9324) loss_zs_kd 0.2996 (0.3483) loss_oracle 0.1999 (0.2950) acc 68.7500 (75.4018) kd_loss 0.5946 (0.6151) lr 1.8763e-03 eta 0:19:09
epoch [10/50] batch [160/288] time 0.098 (0.099) data 0.000 (0.002) loss 1.1139 (1.6921) teacher_loss 0.5968 (0.9313) loss_zs_kd 0.3039 (0.3458) loss_oracle 0.2483 (0.2916) acc 90.6250 (75.5273) kd_loss 0.3929 (0.6150) lr 1.8763e-03 eta 0:19:07
epoch [10/50] batch [180/288] time 0.090 (0.098) data 0.000 (0.002) loss 1.8907 (1.7060) teacher_loss 1.0776 (0.9421) loss_zs_kd 0.2666 (0.3450) loss_oracle 0.2909 (0.2906) acc 75.0000 (75.2778) kd_loss 0.6676 (0.6186) lr 1.8763e-03 eta 0:19:03
epoch [10/50] batch [200/288] time 0.098 (0.098) data 0.000 (0.001) loss 2.2662 (1.7197) teacher_loss 1.2411 (0.9503) loss_zs_kd 0.2731 (0.3427) loss_oracle 0.2434 (0.2905) acc 68.7500 (74.9531) kd_loss 0.9034 (0.6241) lr 1.8763e-03 eta 0:18:57
epoch [10/50] batch [220/288] time 0.092 (0.098) data 0.000 (0.001) loss 1.6441 (1.7218) teacher_loss 1.0672 (0.9503) loss_zs_kd 0.3276 (0.3409) loss_oracle 0.2327 (0.2903) acc 68.7500 (75.0426) kd_loss 0.4606 (0.6264) lr 1.8763e-03 eta 0:18:51
epoch [10/50] batch [240/288] time 0.102 (0.098) data 0.000 (0.001) loss 1.5115 (1.7281) teacher_loss 0.8049 (0.9526) loss_zs_kd 0.4425 (0.3417) loss_oracle 0.3208 (0.2905) acc 71.8750 (74.9219) kd_loss 0.5462 (0.6303) lr 1.8763e-03 eta 0:18:49
epoch [10/50] batch [260/288] time 0.100 (0.097) data 0.001 (0.001) loss 1.5582 (1.7277) teacher_loss 1.0379 (0.9513) loss_zs_kd 0.3190 (0.3441) loss_oracle 0.3144 (0.2922) acc 71.8750 (74.8798) kd_loss 0.3631 (0.6303) lr 1.8763e-03 eta 0:18:45
epoch [10/50] batch [280/288] time 0.087 (0.097) data 0.000 (0.001) loss 2.4626 (1.7360) teacher_loss 1.5512 (0.9590) loss_zs_kd 0.4747 (0.3470) loss_oracle 0.3559 (0.2933) acc 65.6250 (74.6875) kd_loss 0.7335 (0.6303) lr 1.8763e-03 eta 0:18:42
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,434
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,989
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 78.4%
******* Domain a best val acc:      87.4%, epoch: 9 *******
******* Domain a best val test acc: 82.4%, epoch: 9 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [11/50] batch [20/288] time 0.096 (0.116) data 0.000 (0.014) loss 2.3128 (1.7293) teacher_loss 1.5283 (0.9792) loss_zs_kd 0.3288 (0.3669) loss_oracle 0.3056 (0.3013) acc 59.3750 (73.7500) kd_loss 0.6316 (0.5995) lr 1.8443e-03 eta 0:22:17
epoch [11/50] batch [40/288] time 0.096 (0.107) data 0.000 (0.007) loss 1.9918 (1.7524) teacher_loss 1.1757 (0.9720) loss_zs_kd 0.3691 (0.3627) loss_oracle 0.3374 (0.3057) acc 65.6250 (72.6562) kd_loss 0.6474 (0.6276) lr 1.8443e-03 eta 0:20:25
epoch [11/50] batch [60/288] time 0.101 (0.103) data 0.000 (0.005) loss 1.4236 (1.7425) teacher_loss 0.7861 (0.9644) loss_zs_kd 0.4006 (0.3573) loss_oracle 0.3416 (0.3076) acc 81.2500 (72.8125) kd_loss 0.4668 (0.6242) lr 1.8443e-03 eta 0:19:38
epoch [11/50] batch [80/288] time 0.084 (0.101) data 0.000 (0.004) loss 1.9505 (1.7322) teacher_loss 1.0642 (0.9448) loss_zs_kd 0.2167 (0.3497) loss_oracle 0.3045 (0.3097) acc 71.8750 (73.5938) kd_loss 0.7341 (0.6325) lr 1.8443e-03 eta 0:19:17
epoch [11/50] batch [100/288] time 0.096 (0.100) data 0.000 (0.003) loss 1.8998 (1.7222) teacher_loss 1.1373 (0.9273) loss_zs_kd 0.4407 (0.3489) loss_oracle 0.3473 (0.3160) acc 71.8750 (74.2188) kd_loss 0.5889 (0.6369) lr 1.8443e-03 eta 0:18:59
epoch [11/50] batch [120/288] time 0.096 (0.099) data 0.000 (0.002) loss 2.2443 (1.7354) teacher_loss 1.3721 (0.9295) loss_zs_kd 0.2864 (0.3469) loss_oracle 0.3955 (0.3230) acc 62.5000 (74.4010) kd_loss 0.6744 (0.6444) lr 1.8443e-03 eta 0:18:49
epoch [11/50] batch [140/288] time 0.102 (0.098) data 0.000 (0.002) loss 1.6767 (1.7360) teacher_loss 0.8686 (0.9320) loss_zs_kd 0.2662 (0.3458) loss_oracle 0.3362 (0.3263) acc 81.2500 (74.4866) kd_loss 0.6400 (0.6408) lr 1.8443e-03 eta 0:18:39
epoch [11/50] batch [160/288] time 0.099 (0.098) data 0.000 (0.002) loss 2.0530 (1.7468) teacher_loss 1.3254 (0.9447) loss_zs_kd 0.2914 (0.3447) loss_oracle 0.2872 (0.3240) acc 65.6250 (74.2969) kd_loss 0.5841 (0.6400) lr 1.8443e-03 eta 0:18:35
epoch [11/50] batch [180/288] time 0.101 (0.098) data 0.000 (0.002) loss 1.7698 (1.7470) teacher_loss 0.9750 (0.9433) loss_zs_kd 0.3585 (0.3439) loss_oracle 0.2933 (0.3253) acc 78.1250 (74.3924) kd_loss 0.6482 (0.6410) lr 1.8443e-03 eta 0:18:31
epoch [11/50] batch [200/288] time 0.096 (0.098) data 0.000 (0.002) loss 1.7362 (1.7430) teacher_loss 1.0486 (0.9394) loss_zs_kd 0.4352 (0.3412) loss_oracle 0.2562 (0.3230) acc 78.1250 (74.6406) kd_loss 0.5596 (0.6421) lr 1.8443e-03 eta 0:18:27
epoch [11/50] batch [220/288] time 0.095 (0.098) data 0.000 (0.001) loss 1.8212 (1.7468) teacher_loss 1.0268 (0.9395) loss_zs_kd 0.3286 (0.3461) loss_oracle 0.2906 (0.3202) acc 84.3750 (74.7017) kd_loss 0.6490 (0.6472) lr 1.8443e-03 eta 0:18:23
epoch [11/50] batch [240/288] time 0.090 (0.097) data 0.000 (0.001) loss 1.8253 (1.7443) teacher_loss 0.9243 (0.9368) loss_zs_kd 0.2964 (0.3473) loss_oracle 0.2531 (0.3175) acc 71.8750 (74.8047) kd_loss 0.7745 (0.6488) lr 1.8443e-03 eta 0:18:19
epoch [11/50] batch [260/288] time 0.092 (0.097) data 0.000 (0.001) loss 1.4858 (1.7414) teacher_loss 0.8693 (0.9370) loss_zs_kd 0.3077 (0.3472) loss_oracle 0.2726 (0.3154) acc 75.0000 (74.8317) kd_loss 0.4801 (0.6468) lr 1.8443e-03 eta 0:18:17
epoch [11/50] batch [280/288] time 0.089 (0.097) data 0.000 (0.001) loss 1.2391 (1.7298) teacher_loss 0.5968 (0.9299) loss_zs_kd 0.2276 (0.3459) loss_oracle 0.2536 (0.3119) acc 81.2500 (74.9888) kd_loss 0.5156 (0.6439) lr 1.8443e-03 eta 0:18:12
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,438
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,991
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 78.6%
******* Domain a best val acc:      87.4%, epoch: 9 *******
******* Domain a best val test acc: 82.4%, epoch: 9 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [12/50] batch [20/288] time 0.101 (0.122) data 0.000 (0.017) loss 1.4309 (1.7145) teacher_loss 0.8353 (0.9440) loss_zs_kd 0.2732 (0.3645) loss_oracle 0.2865 (0.2977) acc 84.3750 (75.6250) kd_loss 0.4523 (0.6216) lr 1.8090e-03 eta 0:22:47
epoch [12/50] batch [40/288] time 0.102 (0.112) data 0.000 (0.009) loss 1.8749 (1.7037) teacher_loss 0.9993 (0.9064) loss_zs_kd 0.2391 (0.3664) loss_oracle 0.2832 (0.3083) acc 78.1250 (75.8594) kd_loss 0.7340 (0.6431) lr 1.8090e-03 eta 0:20:57
epoch [12/50] batch [60/288] time 0.099 (0.109) data 0.001 (0.006) loss 1.8812 (1.7323) teacher_loss 1.2050 (0.9372) loss_zs_kd 0.3556 (0.3621) loss_oracle 0.3179 (0.3038) acc 68.7500 (74.7396) kd_loss 0.5173 (0.6431) lr 1.8090e-03 eta 0:20:16
epoch [12/50] batch [80/288] time 0.102 (0.107) data 0.000 (0.004) loss 2.8590 (1.7342) teacher_loss 2.0207 (0.9487) loss_zs_kd 0.4303 (0.3634) loss_oracle 0.2987 (0.3021) acc 53.1250 (75.0391) kd_loss 0.6890 (0.6345) lr 1.8090e-03 eta 0:19:53
epoch [12/50] batch [100/288] time 0.097 (0.106) data 0.000 (0.004) loss 1.7852 (1.7092) teacher_loss 1.0468 (0.9329) loss_zs_kd 0.3468 (0.3545) loss_oracle 0.2955 (0.2961) acc 68.7500 (75.1250) kd_loss 0.5907 (0.6282) lr 1.8090e-03 eta 0:19:35
epoch [12/50] batch [120/288] time 0.098 (0.104) data 0.000 (0.003) loss 2.0714 (1.7013) teacher_loss 1.1586 (0.9294) loss_zs_kd 0.3499 (0.3505) loss_oracle 0.3032 (0.2919) acc 75.0000 (75.5208) kd_loss 0.7612 (0.6260) lr 1.8090e-03 eta 0:19:18
epoch [12/50] batch [140/288] time 0.097 (0.103) data 0.000 (0.003) loss 1.1731 (1.7028) teacher_loss 0.4721 (0.9321) loss_zs_kd 0.3277 (0.3542) loss_oracle 0.2629 (0.2909) acc 90.6250 (75.6027) kd_loss 0.5696 (0.6253) lr 1.8090e-03 eta 0:19:04
epoch [12/50] batch [160/288] time 0.093 (0.102) data 0.000 (0.002) loss 1.8000 (1.7053) teacher_loss 1.0058 (0.9300) loss_zs_kd 0.4761 (0.3578) loss_oracle 0.3314 (0.2943) acc 78.1250 (75.3906) kd_loss 0.6285 (0.6281) lr 1.8090e-03 eta 0:18:52
epoch [12/50] batch [180/288] time 0.105 (0.102) data 0.000 (0.002) loss 1.6869 (1.7257) teacher_loss 0.8823 (0.9456) loss_zs_kd 0.4392 (0.3590) loss_oracle 0.3581 (0.3005) acc 81.2500 (74.8090) kd_loss 0.6256 (0.6299) lr 1.8090e-03 eta 0:18:47
epoch [12/50] batch [200/288] time 0.089 (0.102) data 0.000 (0.002) loss 1.9893 (1.7344) teacher_loss 1.0269 (0.9480) loss_zs_kd 0.4018 (0.3590) loss_oracle 0.3198 (0.3036) acc 71.8750 (74.8125) kd_loss 0.8025 (0.6346) lr 1.8090e-03 eta 0:18:41
epoch [12/50] batch [220/288] time 0.099 (0.101) data 0.000 (0.002) loss 1.4760 (1.7322) teacher_loss 0.6812 (0.9428) loss_zs_kd 0.4967 (0.3637) loss_oracle 0.2194 (0.3035) acc 75.0000 (75.0000) kd_loss 0.6850 (0.6377) lr 1.8090e-03 eta 0:18:33
epoch [12/50] batch [240/288] time 0.101 (0.101) data 0.000 (0.002) loss 1.9504 (1.7340) teacher_loss 1.2433 (0.9441) loss_zs_kd 0.4447 (0.3649) loss_oracle 0.3595 (0.3039) acc 68.7500 (75.0000) kd_loss 0.5273 (0.6380) lr 1.8090e-03 eta 0:18:29
epoch [12/50] batch [260/288] time 0.100 (0.101) data 0.000 (0.002) loss 1.7311 (1.7334) teacher_loss 0.6809 (0.9413) loss_zs_kd 0.4484 (0.3648) loss_oracle 0.3674 (0.3036) acc 84.3750 (75.0601) kd_loss 0.8666 (0.6403) lr 1.8090e-03 eta 0:18:25
epoch [12/50] batch [280/288] time 0.116 (0.101) data 0.000 (0.001) loss 1.8042 (1.7320) teacher_loss 0.8846 (0.9398) loss_zs_kd 0.3028 (0.3638) loss_oracle 0.2830 (0.3043) acc 78.1250 (75.2567) kd_loss 0.7781 (0.6401) lr 1.8090e-03 eta 0:18:21
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,442
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.7%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,004
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 79.3%
******* Domain a best val acc:      87.4%, epoch: 12 *******
******* Domain a best val test acc: 82.6%, epoch: 12 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [13/50] batch [20/288] time 0.107 (0.123) data 0.000 (0.014) loss 1.4308 (1.6691) teacher_loss 0.6657 (0.8857) loss_zs_kd 0.4076 (0.3811) loss_oracle 0.2971 (0.3124) acc 78.1250 (75.6250) kd_loss 0.6165 (0.6272) lr 1.7705e-03 eta 0:22:22
epoch [13/50] batch [40/288] time 0.102 (0.112) data 0.000 (0.007) loss 1.3781 (1.7477) teacher_loss 0.6757 (0.9588) loss_zs_kd 0.5721 (0.3959) loss_oracle 0.3190 (0.3157) acc 84.3750 (73.9844) kd_loss 0.5429 (0.6310) lr 1.7705e-03 eta 0:20:22
epoch [13/50] batch [60/288] time 0.084 (0.107) data 0.000 (0.005) loss 2.4069 (1.8127) teacher_loss 1.4087 (1.0086) loss_zs_kd 0.4927 (0.3943) loss_oracle 0.2944 (0.3130) acc 65.6250 (73.0208) kd_loss 0.8510 (0.6476) lr 1.7705e-03 eta 0:19:20
epoch [13/50] batch [80/288] time 0.100 (0.104) data 0.000 (0.004) loss 1.9250 (1.7808) teacher_loss 1.2158 (0.9837) loss_zs_kd 0.4843 (0.3960) loss_oracle 0.3418 (0.3110) acc 68.7500 (73.5156) kd_loss 0.5384 (0.6417) lr 1.7705e-03 eta 0:18:49
epoch [13/50] batch [100/288] time 0.097 (0.103) data 0.000 (0.003) loss 1.4661 (1.7629) teacher_loss 0.6365 (0.9525) loss_zs_kd 0.1854 (0.3897) loss_oracle 0.3146 (0.3138) acc 84.3750 (74.4062) kd_loss 0.6724 (0.6535) lr 1.7705e-03 eta 0:18:34
epoch [13/50] batch [120/288] time 0.092 (0.102) data 0.000 (0.003) loss 1.9772 (1.7598) teacher_loss 0.9824 (0.9468) loss_zs_kd 0.3843 (0.3913) loss_oracle 0.3612 (0.3139) acc 75.0000 (74.8958) kd_loss 0.8143 (0.6561) lr 1.7705e-03 eta 0:18:21
epoch [13/50] batch [140/288] time 0.100 (0.101) data 0.000 (0.002) loss 1.7041 (1.7716) teacher_loss 0.8447 (0.9607) loss_zs_kd 0.3371 (0.3859) loss_oracle 0.3167 (0.3112) acc 78.1250 (74.5759) kd_loss 0.7011 (0.6553) lr 1.7705e-03 eta 0:18:13
epoch [13/50] batch [160/288] time 0.092 (0.100) data 0.000 (0.002) loss 1.8789 (1.7581) teacher_loss 1.0678 (0.9482) loss_zs_kd 0.2644 (0.3800) loss_oracle 0.3270 (0.3084) acc 75.0000 (74.8828) kd_loss 0.6476 (0.6557) lr 1.7705e-03 eta 0:18:02
epoch [13/50] batch [180/288] time 0.097 (0.100) data 0.000 (0.002) loss 1.3326 (1.7617) teacher_loss 0.6255 (0.9555) loss_zs_kd 0.2152 (0.3803) loss_oracle 0.3163 (0.3081) acc 81.2500 (74.6701) kd_loss 0.5490 (0.6521) lr 1.7705e-03 eta 0:17:55
epoch [13/50] batch [200/288] time 0.101 (0.100) data 0.000 (0.002) loss 2.2830 (1.7530) teacher_loss 1.4174 (0.9515) loss_zs_kd 0.3020 (0.3834) loss_oracle 0.3281 (0.3073) acc 62.5000 (74.7812) kd_loss 0.7016 (0.6478) lr 1.7705e-03 eta 0:17:50
epoch [13/50] batch [220/288] time 0.090 (0.099) data 0.000 (0.001) loss 1.7047 (1.7435) teacher_loss 0.7100 (0.9460) loss_zs_kd 0.6057 (0.3861) loss_oracle 0.3229 (0.3071) acc 84.3750 (74.8011) kd_loss 0.8332 (0.6439) lr 1.7705e-03 eta 0:17:46
epoch [13/50] batch [240/288] time 0.092 (0.099) data 0.000 (0.001) loss 1.8400 (1.7401) teacher_loss 1.0715 (0.9420) loss_zs_kd 0.3750 (0.3839) loss_oracle 0.3531 (0.3084) acc 75.0000 (74.8047) kd_loss 0.5920 (0.6439) lr 1.7705e-03 eta 0:17:40
epoch [13/50] batch [260/288] time 0.094 (0.099) data 0.000 (0.001) loss 1.6627 (1.7263) teacher_loss 0.9245 (0.9300) loss_zs_kd 0.3549 (0.3812) loss_oracle 0.3086 (0.3079) acc 78.1250 (75.0721) kd_loss 0.5839 (0.6423) lr 1.7705e-03 eta 0:17:36
epoch [13/50] batch [280/288] time 0.109 (0.100) data 0.000 (0.001) loss 1.3723 (1.7237) teacher_loss 0.6425 (0.9305) loss_zs_kd 0.3358 (0.3810) loss_oracle 0.2958 (0.3074) acc 84.3750 (75.1339) kd_loss 0.5819 (0.6395) lr 1.7705e-03 eta 0:17:42
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,426
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 86.4%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,989
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 78.2%
******* Domain a best val acc:      87.4%, epoch: 12 *******
******* Domain a best val test acc: 82.6%, epoch: 12 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [14/50] batch [20/288] time 0.103 (0.118) data 0.000 (0.014) loss 1.6446 (1.6999) teacher_loss 0.9918 (0.9560) loss_zs_kd 0.3531 (0.3601) loss_oracle 0.2832 (0.2690) acc 75.0000 (76.5625) kd_loss 0.5112 (0.6095) lr 1.7290e-03 eta 0:20:53
epoch [14/50] batch [40/288] time 0.111 (0.109) data 0.000 (0.007) loss 1.4680 (1.6668) teacher_loss 0.6961 (0.9152) loss_zs_kd 0.4306 (0.3609) loss_oracle 0.2563 (0.2697) acc 81.2500 (76.5625) kd_loss 0.6437 (0.6167) lr 1.7290e-03 eta 0:19:20
epoch [14/50] batch [60/288] time 0.100 (0.107) data 0.000 (0.005) loss 1.5858 (1.6461) teacher_loss 0.8851 (0.8906) loss_zs_kd 0.3233 (0.3738) loss_oracle 0.2831 (0.2689) acc 71.8750 (76.7708) kd_loss 0.5592 (0.6211) lr 1.7290e-03 eta 0:18:50
epoch [14/50] batch [80/288] time 0.097 (0.105) data 0.000 (0.004) loss 2.0662 (1.6757) teacher_loss 1.1224 (0.9148) loss_zs_kd 0.3412 (0.3861) loss_oracle 0.3375 (0.2686) acc 75.0000 (76.1328) kd_loss 0.7750 (0.6266) lr 1.7290e-03 eta 0:18:33
epoch [14/50] batch [100/288] time 0.104 (0.105) data 0.000 (0.003) loss 1.9272 (1.6903) teacher_loss 1.1233 (0.9137) loss_zs_kd 0.3761 (0.3955) loss_oracle 0.3510 (0.2818) acc 75.0000 (75.9688) kd_loss 0.6284 (0.6357) lr 1.7290e-03 eta 0:18:30
epoch [14/50] batch [120/288] time 0.094 (0.104) data 0.000 (0.003) loss 1.4312 (1.7117) teacher_loss 0.7312 (0.9265) loss_zs_kd 0.3762 (0.3914) loss_oracle 0.3490 (0.2928) acc 84.3750 (75.5469) kd_loss 0.5255 (0.6388) lr 1.7290e-03 eta 0:18:15
epoch [14/50] batch [140/288] time 0.100 (0.103) data 0.000 (0.002) loss 1.4343 (1.7197) teacher_loss 0.7025 (0.9373) loss_zs_kd 0.3488 (0.3892) loss_oracle 0.3374 (0.2958) acc 81.2500 (75.5357) kd_loss 0.5631 (0.6345) lr 1.7290e-03 eta 0:18:03
epoch [14/50] batch [160/288] time 0.097 (0.103) data 0.000 (0.002) loss 1.3948 (1.7157) teacher_loss 0.6447 (0.9263) loss_zs_kd 0.3558 (0.3872) loss_oracle 0.3474 (0.3034) acc 81.2500 (75.8203) kd_loss 0.5764 (0.6377) lr 1.7290e-03 eta 0:18:02
epoch [14/50] batch [180/288] time 0.093 (0.102) data 0.000 (0.002) loss 1.2300 (1.7073) teacher_loss 0.6081 (0.9179) loss_zs_kd 0.2529 (0.3838) loss_oracle 0.3374 (0.3063) acc 84.3750 (75.9375) kd_loss 0.4532 (0.6363) lr 1.7290e-03 eta 0:17:52
epoch [14/50] batch [200/288] time 0.094 (0.102) data 0.000 (0.002) loss 1.9736 (1.7092) teacher_loss 1.0503 (0.9233) loss_zs_kd 0.4086 (0.3830) loss_oracle 0.2840 (0.3077) acc 62.5000 (75.6875) kd_loss 0.7814 (0.6321) lr 1.7290e-03 eta 0:17:47
epoch [14/50] batch [220/288] time 0.093 (0.102) data 0.000 (0.001) loss 1.0642 (1.7014) teacher_loss 0.3247 (0.9162) loss_zs_kd 0.2738 (0.3827) loss_oracle 0.3189 (0.3088) acc 93.7500 (75.8239) kd_loss 0.5800 (0.6308) lr 1.7290e-03 eta 0:17:42
epoch [14/50] batch [240/288] time 0.138 (0.102) data 0.000 (0.001) loss 1.6671 (1.6929) teacher_loss 0.8202 (0.9093) loss_zs_kd 0.4046 (0.3839) loss_oracle 0.3258 (0.3072) acc 78.1250 (75.9635) kd_loss 0.6840 (0.6300) lr 1.7290e-03 eta 0:17:40
epoch [14/50] batch [260/288] time 0.093 (0.102) data 0.000 (0.001) loss 1.9450 (1.6908) teacher_loss 1.2026 (0.9090) loss_zs_kd 0.4220 (0.3859) loss_oracle 0.3133 (0.3067) acc 75.0000 (76.0457) kd_loss 0.5857 (0.6284) lr 1.7290e-03 eta 0:17:40
epoch [14/50] batch [280/288] time 0.085 (0.101) data 0.000 (0.001) loss 1.2754 (1.6897) teacher_loss 0.5279 (0.9079) loss_zs_kd 0.2915 (0.3856) loss_oracle 0.3490 (0.3084) acc 81.2500 (76.0268) kd_loss 0.5730 (0.6276) lr 1.7290e-03 eta 0:17:32
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,428
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 86.4%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,000
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 78.9%
******* Domain a best val acc:      87.4%, epoch: 12 *******
******* Domain a best val test acc: 82.6%, epoch: 12 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [15/50] batch [20/288] time 0.091 (0.115) data 0.000 (0.015) loss 1.8433 (1.6900) teacher_loss 1.0516 (0.9192) loss_zs_kd 0.2601 (0.3736) loss_oracle 0.3293 (0.3173) acc 81.2500 (76.5625) kd_loss 0.6270 (0.6122) lr 1.6845e-03 eta 0:19:46
epoch [15/50] batch [40/288] time 0.092 (0.105) data 0.000 (0.007) loss 1.9692 (1.7492) teacher_loss 1.0331 (0.9772) loss_zs_kd 0.3131 (0.3683) loss_oracle 0.3499 (0.3309) acc 78.1250 (75.0781) kd_loss 0.7612 (0.6065) lr 1.6845e-03 eta 0:18:07
epoch [15/50] batch [60/288] time 0.094 (0.102) data 0.000 (0.005) loss 1.4353 (1.6957) teacher_loss 0.6462 (0.9275) loss_zs_kd 0.3026 (0.3690) loss_oracle 0.2998 (0.3265) acc 75.0000 (75.8854) kd_loss 0.6392 (0.6050) lr 1.6845e-03 eta 0:17:33
epoch [15/50] batch [80/288] time 0.090 (0.100) data 0.000 (0.004) loss 1.7974 (1.6662) teacher_loss 1.0271 (0.8967) loss_zs_kd 0.3394 (0.3659) loss_oracle 0.2750 (0.3203) acc 78.1250 (76.5234) kd_loss 0.6327 (0.6093) lr 1.6845e-03 eta 0:17:08
epoch [15/50] batch [100/288] time 0.092 (0.098) data 0.000 (0.003) loss 1.6655 (1.6541) teacher_loss 0.8135 (0.8823) loss_zs_kd 0.2839 (0.3714) loss_oracle 0.3004 (0.3183) acc 81.2500 (76.5938) kd_loss 0.7018 (0.6127) lr 1.6845e-03 eta 0:16:50
epoch [15/50] batch [120/288] time 0.092 (0.097) data 0.000 (0.003) loss 1.9011 (1.6644) teacher_loss 1.1870 (0.8884) loss_zs_kd 0.4888 (0.3714) loss_oracle 0.2976 (0.3200) acc 71.8750 (76.4323) kd_loss 0.5652 (0.6160) lr 1.6845e-03 eta 0:16:37
epoch [15/50] batch [140/288] time 0.095 (0.097) data 0.000 (0.002) loss 1.5662 (1.6710) teacher_loss 0.9612 (0.8976) loss_zs_kd 0.3232 (0.3744) loss_oracle 0.2633 (0.3160) acc 71.8750 (76.2723) kd_loss 0.4734 (0.6154) lr 1.6845e-03 eta 0:16:34
epoch [15/50] batch [160/288] time 0.098 (0.097) data 0.000 (0.002) loss 1.8701 (1.6703) teacher_loss 1.0429 (0.9003) loss_zs_kd 0.2406 (0.3790) loss_oracle 0.3207 (0.3134) acc 75.0000 (76.1914) kd_loss 0.6668 (0.6132) lr 1.6845e-03 eta 0:16:31
epoch [15/50] batch [180/288] time 0.092 (0.097) data 0.000 (0.002) loss 2.1132 (1.6778) teacher_loss 1.3715 (0.9102) loss_zs_kd 0.4359 (0.3799) loss_oracle 0.3139 (0.3099) acc 71.8750 (75.8333) kd_loss 0.5848 (0.6127) lr 1.6845e-03 eta 0:16:28
epoch [15/50] batch [200/288] time 0.093 (0.097) data 0.000 (0.002) loss 1.4048 (1.6837) teacher_loss 0.6722 (0.9171) loss_zs_kd 0.5200 (0.3836) loss_oracle 0.3247 (0.3082) acc 84.3750 (75.8125) kd_loss 0.5703 (0.6126) lr 1.6845e-03 eta 0:16:25
epoch [15/50] batch [220/288] time 0.103 (0.097) data 0.000 (0.002) loss 1.8005 (1.6814) teacher_loss 1.0754 (0.9160) loss_zs_kd 0.3664 (0.3852) loss_oracle 0.2719 (0.3054) acc 71.8750 (75.7955) kd_loss 0.5892 (0.6128) lr 1.6845e-03 eta 0:16:21
epoch [15/50] batch [240/288] time 0.101 (0.098) data 0.000 (0.001) loss 1.6593 (1.6773) teacher_loss 0.7784 (0.9110) loss_zs_kd 0.6713 (0.3877) loss_oracle 0.2916 (0.3044) acc 68.7500 (75.9375) kd_loss 0.7352 (0.6141) lr 1.6845e-03 eta 0:16:29
epoch [15/50] batch [260/288] time 0.093 (0.098) data 0.000 (0.001) loss 1.6418 (1.6819) teacher_loss 0.9929 (0.9138) loss_zs_kd 0.2783 (0.3890) loss_oracle 0.2983 (0.3040) acc 81.2500 (75.8534) kd_loss 0.4997 (0.6161) lr 1.6845e-03 eta 0:16:25
epoch [15/50] batch [280/288] time 0.090 (0.097) data 0.000 (0.001) loss 1.6504 (1.6799) teacher_loss 0.9389 (0.9114) loss_zs_kd 0.3292 (0.3867) loss_oracle 0.3414 (0.3025) acc 71.8750 (75.7589) kd_loss 0.5408 (0.6173) lr 1.6845e-03 eta 0:16:20
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,441
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,989
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 78.2%
******* Domain a best val acc:      87.4%, epoch: 12 *******
******* Domain a best val test acc: 82.6%, epoch: 12 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [16/50] batch [20/288] time 0.091 (0.115) data 0.000 (0.012) loss 2.2163 (1.6962) teacher_loss 1.1991 (0.9352) loss_zs_kd 0.4362 (0.3861) loss_oracle 0.3558 (0.2852) acc 71.8750 (75.1562) kd_loss 0.8393 (0.6184) lr 1.6374e-03 eta 0:19:13
epoch [16/50] batch [40/288] time 0.101 (0.106) data 0.000 (0.006) loss 1.9407 (1.6785) teacher_loss 1.0550 (0.9067) loss_zs_kd 0.4012 (0.3980) loss_oracle 0.3569 (0.2858) acc 71.8750 (75.3906) kd_loss 0.7072 (0.6288) lr 1.6374e-03 eta 0:17:46
epoch [16/50] batch [60/288] time 0.094 (0.104) data 0.000 (0.004) loss 2.1940 (1.6675) teacher_loss 1.0713 (0.9009) loss_zs_kd 0.6012 (0.3974) loss_oracle 0.3371 (0.2849) acc 78.1250 (75.7292) kd_loss 0.9541 (0.6241) lr 1.6374e-03 eta 0:17:19
epoch [16/50] batch [80/288] time 0.105 (0.102) data 0.000 (0.003) loss 2.1115 (1.6665) teacher_loss 1.3130 (0.9007) loss_zs_kd 0.3866 (0.3947) loss_oracle 0.2479 (0.2846) acc 62.5000 (75.8984) kd_loss 0.6745 (0.6235) lr 1.6374e-03 eta 0:17:00
epoch [16/50] batch [100/288] time 0.097 (0.102) data 0.000 (0.003) loss 1.6146 (1.6758) teacher_loss 0.8955 (0.9137) loss_zs_kd 0.4332 (0.3985) loss_oracle 0.3471 (0.2853) acc 75.0000 (75.3125) kd_loss 0.5455 (0.6195) lr 1.6374e-03 eta 0:17:00
epoch [16/50] batch [120/288] time 0.103 (0.102) data 0.000 (0.002) loss 1.4085 (1.6739) teacher_loss 0.7280 (0.9084) loss_zs_kd 0.4350 (0.3919) loss_oracle 0.2572 (0.2876) acc 81.2500 (75.4427) kd_loss 0.5519 (0.6218) lr 1.6374e-03 eta 0:17:00
epoch [16/50] batch [140/288] time 0.100 (0.103) data 0.000 (0.002) loss 1.6950 (1.6520) teacher_loss 0.9477 (0.8894) loss_zs_kd 0.3440 (0.3911) loss_oracle 0.2889 (0.2910) acc 75.0000 (75.7812) kd_loss 0.6029 (0.6171) lr 1.6374e-03 eta 0:17:01
epoch [16/50] batch [160/288] time 0.101 (0.103) data 0.000 (0.002) loss 1.7592 (1.6476) teacher_loss 1.0205 (0.8860) loss_zs_kd 0.3263 (0.3954) loss_oracle 0.2863 (0.2925) acc 78.1250 (76.0742) kd_loss 0.5956 (0.6154) lr 1.6374e-03 eta 0:17:00
epoch [16/50] batch [180/288] time 0.109 (0.103) data 0.000 (0.002) loss 1.4245 (1.6531) teacher_loss 0.7204 (0.8986) loss_zs_kd 0.2915 (0.3967) loss_oracle 0.2671 (0.2923) acc 78.1250 (76.0069) kd_loss 0.5706 (0.6084) lr 1.6374e-03 eta 0:17:01
epoch [16/50] batch [200/288] time 0.100 (0.103) data 0.000 (0.001) loss 1.6024 (1.6595) teacher_loss 0.8049 (0.9037) loss_zs_kd 0.4531 (0.3954) loss_oracle 0.3162 (0.2935) acc 81.2500 (75.8125) kd_loss 0.6394 (0.6091) lr 1.6374e-03 eta 0:16:58
epoch [16/50] batch [220/288] time 0.119 (0.105) data 0.000 (0.001) loss 1.4666 (1.6667) teacher_loss 0.6597 (0.9018) loss_zs_kd 0.3738 (0.3951) loss_oracle 0.4053 (0.2965) acc 78.1250 (75.7102) kd_loss 0.6043 (0.6166) lr 1.6374e-03 eta 0:17:11
epoch [16/50] batch [240/288] time 0.101 (0.105) data 0.000 (0.001) loss 1.4538 (1.6620) teacher_loss 0.7749 (0.8950) loss_zs_kd 0.4825 (0.3956) loss_oracle 0.2572 (0.2960) acc 75.0000 (75.8984) kd_loss 0.5503 (0.6190) lr 1.6374e-03 eta 0:17:09
epoch [16/50] batch [260/288] time 0.114 (0.104) data 0.000 (0.001) loss 1.6262 (1.6684) teacher_loss 0.8933 (0.9009) loss_zs_kd 0.3352 (0.3961) loss_oracle 0.2687 (0.2952) acc 81.2500 (75.7332) kd_loss 0.5985 (0.6199) lr 1.6374e-03 eta 0:17:05
epoch [16/50] batch [280/288] time 0.107 (0.104) data 0.000 (0.001) loss 2.2473 (1.6794) teacher_loss 1.5042 (0.9099) loss_zs_kd 0.4197 (0.3968) loss_oracle 0.2553 (0.2955) acc 59.3750 (75.5915) kd_loss 0.6155 (0.6218) lr 1.6374e-03 eta 0:17:02
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,434
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,996
* accuracy: 82.2%
* error: 17.8%
* macro_f1: 79.1%
******* Domain a best val acc:      87.4%, epoch: 12 *******
******* Domain a best val test acc: 82.6%, epoch: 12 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [17/50] batch [20/288] time 0.113 (0.129) data 0.000 (0.020) loss 2.0718 (1.6047) teacher_loss 1.3321 (0.7815) loss_zs_kd 0.3453 (0.3595) loss_oracle 0.2971 (0.3211) acc 81.2500 (80.7812) kd_loss 0.5911 (0.6627) lr 1.5878e-03 eta 0:20:56
epoch [17/50] batch [40/288] time 0.101 (0.116) data 0.000 (0.010) loss 1.4705 (1.6889) teacher_loss 0.8019 (0.8746) loss_zs_kd 0.4425 (0.3753) loss_oracle 0.3061 (0.3194) acc 71.8750 (78.4375) kd_loss 0.5156 (0.6546) lr 1.5878e-03 eta 0:18:47
epoch [17/50] batch [60/288] time 0.096 (0.111) data 0.000 (0.007) loss 2.4576 (1.7107) teacher_loss 1.5242 (0.8930) loss_zs_kd 0.3675 (0.3816) loss_oracle 0.2854 (0.3174) acc 59.3750 (77.7083) kd_loss 0.7907 (0.6590) lr 1.5878e-03 eta 0:18:03
epoch [17/50] batch [80/288] time 0.102 (0.109) data 0.000 (0.005) loss 1.5841 (1.6972) teacher_loss 0.7492 (0.8862) loss_zs_kd 0.4076 (0.3832) loss_oracle 0.2789 (0.3133) acc 81.2500 (77.5000) kd_loss 0.6955 (0.6543) lr 1.5878e-03 eta 0:17:39
epoch [17/50] batch [100/288] time 0.098 (0.108) data 0.000 (0.004) loss 1.7240 (1.6834) teacher_loss 1.0204 (0.8848) loss_zs_kd 0.3298 (0.3817) loss_oracle 0.2897 (0.3086) acc 65.6250 (77.2188) kd_loss 0.5587 (0.6444) lr 1.5878e-03 eta 0:17:24
epoch [17/50] batch [120/288] time 0.103 (0.107) data 0.000 (0.004) loss 1.7429 (1.6860) teacher_loss 1.0576 (0.8909) loss_zs_kd 0.2492 (0.3815) loss_oracle 0.3316 (0.3072) acc 78.1250 (76.9010) kd_loss 0.5195 (0.6416) lr 1.5878e-03 eta 0:17:12
epoch [17/50] batch [140/288] time 0.111 (0.106) data 0.001 (0.003) loss 1.9696 (1.7011) teacher_loss 1.1364 (0.9122) loss_zs_kd 0.3762 (0.3858) loss_oracle 0.3539 (0.3076) acc 68.7500 (76.2500) kd_loss 0.6562 (0.6350) lr 1.5878e-03 eta 0:17:03
epoch [17/50] batch [160/288] time 0.103 (0.106) data 0.000 (0.003) loss 1.6983 (1.6958) teacher_loss 0.9399 (0.9121) loss_zs_kd 0.3478 (0.3868) loss_oracle 0.2780 (0.3079) acc 68.7500 (76.3086) kd_loss 0.6194 (0.6298) lr 1.5878e-03 eta 0:16:56
epoch [17/50] batch [180/288] time 0.093 (0.105) data 0.000 (0.002) loss 1.5163 (1.6871) teacher_loss 0.7106 (0.9039) loss_zs_kd 0.3143 (0.3827) loss_oracle 0.2559 (0.3077) acc 84.3750 (76.5104) kd_loss 0.6777 (0.6294) lr 1.5878e-03 eta 0:16:53
epoch [17/50] batch [200/288] time 0.101 (0.105) data 0.000 (0.002) loss 1.5933 (1.6877) teacher_loss 0.8533 (0.9010) loss_zs_kd 0.3155 (0.3822) loss_oracle 0.2911 (0.3076) acc 75.0000 (76.5312) kd_loss 0.5945 (0.6329) lr 1.5878e-03 eta 0:16:42
epoch [17/50] batch [220/288] time 0.093 (0.104) data 0.000 (0.002) loss 1.4193 (1.6926) teacher_loss 0.6766 (0.8985) loss_zs_kd 0.2458 (0.3859) loss_oracle 0.3047 (0.3091) acc 87.5000 (76.6193) kd_loss 0.5903 (0.6395) lr 1.5878e-03 eta 0:16:32
epoch [17/50] batch [240/288] time 0.097 (0.103) data 0.000 (0.002) loss 1.4118 (1.6894) teacher_loss 0.7781 (0.8944) loss_zs_kd 0.3862 (0.3866) loss_oracle 0.2677 (0.3096) acc 81.2500 (76.7188) kd_loss 0.4999 (0.6402) lr 1.5878e-03 eta 0:16:25
epoch [17/50] batch [260/288] time 0.095 (0.103) data 0.000 (0.002) loss 2.2114 (1.6922) teacher_loss 1.2425 (0.8950) loss_zs_kd 0.3876 (0.3897) loss_oracle 0.3331 (0.3101) acc 71.8750 (76.6106) kd_loss 0.8024 (0.6422) lr 1.5878e-03 eta 0:16:19
epoch [17/50] batch [280/288] time 0.089 (0.102) data 0.000 (0.002) loss 2.0252 (1.6961) teacher_loss 1.0804 (0.8942) loss_zs_kd 0.5284 (0.3923) loss_oracle 0.3725 (0.3104) acc 71.8750 (76.5960) kd_loss 0.7586 (0.6467) lr 1.5878e-03 eta 0:16:10
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,432
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,007
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 79.3%
******* Domain a best val acc:      87.4%, epoch: 12 *******
******* Domain a best val test acc: 82.6%, epoch: 12 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [18/50] batch [20/288] time 0.096 (0.116) data 0.001 (0.014) loss 2.2267 (1.7140) teacher_loss 1.1421 (0.8735) loss_zs_kd 0.3919 (0.4136) loss_oracle 0.3481 (0.3246) acc 68.7500 (76.5625) kd_loss 0.9105 (0.6782) lr 1.5358e-03 eta 0:18:21
epoch [18/50] batch [40/288] time 0.095 (0.106) data 0.000 (0.007) loss 2.2148 (1.7533) teacher_loss 1.3987 (0.9143) loss_zs_kd 0.5885 (0.4171) loss_oracle 0.3697 (0.3184) acc 65.6250 (74.9219) kd_loss 0.6313 (0.6799) lr 1.5358e-03 eta 0:16:41
epoch [18/50] batch [60/288] time 0.096 (0.103) data 0.000 (0.005) loss 1.4117 (1.7584) teacher_loss 0.5873 (0.9204) loss_zs_kd 0.4555 (0.4070) loss_oracle 0.3312 (0.3156) acc 75.0000 (74.5833) kd_loss 0.6589 (0.6802) lr 1.5358e-03 eta 0:16:08
epoch [18/50] batch [80/288] time 0.105 (0.103) data 0.000 (0.004) loss 2.8904 (1.7661) teacher_loss 1.8369 (0.9413) loss_zs_kd 0.5669 (0.4084) loss_oracle 0.4246 (0.3192) acc 56.2500 (74.6094) kd_loss 0.8413 (0.6652) lr 1.5358e-03 eta 0:16:06
epoch [18/50] batch [100/288] time 0.098 (0.103) data 0.000 (0.003) loss 1.7733 (1.7622) teacher_loss 0.8452 (0.9292) loss_zs_kd 0.2705 (0.4053) loss_oracle 0.3355 (0.3266) acc 84.3750 (75.0312) kd_loss 0.7603 (0.6698) lr 1.5358e-03 eta 0:16:04
epoch [18/50] batch [120/288] time 0.102 (0.103) data 0.000 (0.003) loss 1.7603 (1.7484) teacher_loss 1.1028 (0.9155) loss_zs_kd 0.3755 (0.4033) loss_oracle 0.3360 (0.3294) acc 75.0000 (75.4427) kd_loss 0.4895 (0.6683) lr 1.5358e-03 eta 0:16:02
epoch [18/50] batch [140/288] time 0.109 (0.103) data 0.000 (0.002) loss 1.7215 (1.7527) teacher_loss 1.0339 (0.9227) loss_zs_kd 0.3831 (0.4049) loss_oracle 0.3087 (0.3301) acc 71.8750 (75.3348) kd_loss 0.5333 (0.6649) lr 1.5358e-03 eta 0:16:00
epoch [18/50] batch [160/288] time 0.096 (0.104) data 0.000 (0.002) loss 1.7207 (1.7470) teacher_loss 0.9054 (0.9159) loss_zs_kd 0.5564 (0.4084) loss_oracle 0.3143 (0.3313) acc 68.7500 (75.5273) kd_loss 0.6582 (0.6655) lr 1.5358e-03 eta 0:16:13
epoch [18/50] batch [180/288] time 0.100 (0.104) data 0.000 (0.002) loss 1.5440 (1.7368) teacher_loss 0.7338 (0.9083) loss_zs_kd 0.5453 (0.4134) loss_oracle 0.3177 (0.3310) acc 71.8750 (75.8333) kd_loss 0.6514 (0.6630) lr 1.5358e-03 eta 0:16:08
epoch [18/50] batch [200/288] time 0.100 (0.104) data 0.000 (0.002) loss 1.9390 (1.7317) teacher_loss 1.3023 (0.9028) loss_zs_kd 0.4411 (0.4120) loss_oracle 0.2989 (0.3311) acc 65.6250 (75.7812) kd_loss 0.4873 (0.6633) lr 1.5358e-03 eta 0:16:05
epoch [18/50] batch [220/288] time 0.091 (0.103) data 0.000 (0.002) loss 2.2538 (1.7358) teacher_loss 1.3415 (0.9057) loss_zs_kd 0.3472 (0.4120) loss_oracle 0.4015 (0.3317) acc 68.7500 (75.6818) kd_loss 0.7115 (0.6643) lr 1.5358e-03 eta 0:15:56
epoch [18/50] batch [240/288] time 0.103 (0.103) data 0.000 (0.001) loss 1.4318 (1.7411) teacher_loss 0.7394 (0.9097) loss_zs_kd 0.3780 (0.4115) loss_oracle 0.3231 (0.3330) acc 81.2500 (75.5469) kd_loss 0.5309 (0.6649) lr 1.5358e-03 eta 0:15:50
epoch [18/50] batch [260/288] time 0.094 (0.102) data 0.000 (0.001) loss 1.9134 (1.7410) teacher_loss 0.9839 (0.9097) loss_zs_kd 0.2206 (0.4084) loss_oracle 0.4239 (0.3348) acc 84.3750 (75.6851) kd_loss 0.7175 (0.6639) lr 1.5358e-03 eta 0:15:44
epoch [18/50] batch [280/288] time 0.088 (0.102) data 0.000 (0.001) loss 1.9159 (1.7446) teacher_loss 1.0976 (0.9140) loss_zs_kd 0.5542 (0.4078) loss_oracle 0.3320 (0.3351) acc 68.7500 (75.5915) kd_loss 0.6523 (0.6631) lr 1.5358e-03 eta 0:15:36
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,440
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,000
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 78.9%
******* Domain a best val acc:      87.4%, epoch: 12 *******
******* Domain a best val test acc: 82.6%, epoch: 12 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [19/50] batch [20/288] time 0.090 (0.114) data 0.000 (0.014) loss 1.6731 (1.6708) teacher_loss 0.8438 (0.8343) loss_zs_kd 0.3139 (0.3806) loss_oracle 0.2724 (0.3345) acc 75.0000 (78.2812) kd_loss 0.6931 (0.6692) lr 1.4818e-03 eta 0:17:26
epoch [19/50] batch [40/288] time 0.097 (0.106) data 0.000 (0.007) loss 1.8285 (1.7392) teacher_loss 1.0122 (0.9100) loss_zs_kd 0.3996 (0.3856) loss_oracle 0.2819 (0.3288) acc 65.6250 (75.2344) kd_loss 0.6754 (0.6648) lr 1.4818e-03 eta 0:16:10
epoch [19/50] batch [60/288] time 0.095 (0.103) data 0.000 (0.005) loss 2.0700 (1.7749) teacher_loss 1.2432 (0.9530) loss_zs_kd 0.4820 (0.3973) loss_oracle 0.2375 (0.3217) acc 68.7500 (74.3229) kd_loss 0.7080 (0.6610) lr 1.4818e-03 eta 0:15:42
epoch [19/50] batch [80/288] time 0.096 (0.101) data 0.000 (0.004) loss 1.7585 (1.7251) teacher_loss 0.8452 (0.9088) loss_zs_kd 0.3451 (0.3967) loss_oracle 0.3709 (0.3184) acc 68.7500 (75.0391) kd_loss 0.7278 (0.6571) lr 1.4818e-03 eta 0:15:27
epoch [19/50] batch [100/288] time 0.099 (0.100) data 0.000 (0.003) loss 1.7323 (1.7206) teacher_loss 1.0461 (0.9089) loss_zs_kd 0.3206 (0.3983) loss_oracle 0.3417 (0.3188) acc 71.8750 (75.0938) kd_loss 0.5154 (0.6523) lr 1.4818e-03 eta 0:15:14
epoch [19/50] batch [120/288] time 0.096 (0.100) data 0.000 (0.002) loss 2.2143 (1.7226) teacher_loss 1.4120 (0.9093) loss_zs_kd 0.3716 (0.3989) loss_oracle 0.3788 (0.3207) acc 65.6250 (75.1823) kd_loss 0.6130 (0.6529) lr 1.4818e-03 eta 0:15:08
epoch [19/50] batch [140/288] time 0.103 (0.102) data 0.000 (0.002) loss 2.0589 (1.7304) teacher_loss 1.2076 (0.9112) loss_zs_kd 0.3160 (0.3984) loss_oracle 0.2960 (0.3230) acc 75.0000 (75.3571) kd_loss 0.7033 (0.6577) lr 1.4818e-03 eta 0:15:27
epoch [19/50] batch [160/288] time 0.102 (0.103) data 0.000 (0.002) loss 1.5411 (1.7317) teacher_loss 0.8411 (0.9100) loss_zs_kd 0.3783 (0.3916) loss_oracle 0.2691 (0.3235) acc 75.0000 (75.2930) kd_loss 0.5654 (0.6599) lr 1.4818e-03 eta 0:15:30
epoch [19/50] batch [180/288] time 0.126 (0.104) data 0.001 (0.002) loss 1.8866 (1.7320) teacher_loss 1.0039 (0.9092) loss_zs_kd 0.3602 (0.3912) loss_oracle 0.2861 (0.3237) acc 71.8750 (75.3125) kd_loss 0.7396 (0.6609) lr 1.4818e-03 eta 0:15:35
epoch [19/50] batch [200/288] time 0.100 (0.104) data 0.000 (0.002) loss 1.2307 (1.7226) teacher_loss 0.5222 (0.9014) loss_zs_kd 0.4805 (0.3910) loss_oracle 0.3247 (0.3245) acc 87.5000 (75.4219) kd_loss 0.5462 (0.6590) lr 1.4818e-03 eta 0:15:35
epoch [19/50] batch [220/288] time 0.107 (0.104) data 0.000 (0.001) loss 1.6564 (1.7311) teacher_loss 0.9085 (0.9092) loss_zs_kd 0.5257 (0.3978) loss_oracle 0.3589 (0.3251) acc 81.2500 (75.4688) kd_loss 0.5685 (0.6594) lr 1.4818e-03 eta 0:15:35
epoch [19/50] batch [240/288] time 0.104 (0.104) data 0.000 (0.001) loss 1.6627 (1.7300) teacher_loss 0.7016 (0.9077) loss_zs_kd 0.6398 (0.4007) loss_oracle 0.3563 (0.3238) acc 81.2500 (75.4818) kd_loss 0.7829 (0.6604) lr 1.4818e-03 eta 0:15:33
epoch [19/50] batch [260/288] time 0.098 (0.104) data 0.000 (0.001) loss 1.8740 (1.7297) teacher_loss 0.9390 (0.9034) loss_zs_kd 0.3976 (0.4018) loss_oracle 0.3707 (0.3258) acc 75.0000 (75.5288) kd_loss 0.7497 (0.6634) lr 1.4818e-03 eta 0:15:30
epoch [19/50] batch [280/288] time 0.108 (0.104) data 0.001 (0.001) loss 2.3336 (1.7357) teacher_loss 1.4828 (0.9050) loss_zs_kd 0.5268 (0.4025) loss_oracle 0.3457 (0.3292) acc 62.5000 (75.5469) kd_loss 0.6780 (0.6661) lr 1.4818e-03 eta 0:15:30
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,448
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 87.0%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,988
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 78.4%
******* Domain a best val acc:      87.5%, epoch: 19 *******
******* Domain a best val test acc: 81.9%, epoch: 19 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [20/50] batch [20/288] time 0.094 (0.127) data 0.000 (0.018) loss 2.2820 (1.7604) teacher_loss 1.3291 (0.8862) loss_zs_kd 0.4432 (0.4236) loss_oracle 0.3240 (0.3778) acc 62.5000 (74.8438) kd_loss 0.7908 (0.6853) lr 1.4258e-03 eta 0:18:54
epoch [20/50] batch [40/288] time 0.101 (0.116) data 0.000 (0.009) loss 1.6218 (1.7354) teacher_loss 0.8283 (0.8725) loss_zs_kd 0.6465 (0.4366) loss_oracle 0.3327 (0.3701) acc 78.1250 (75.4688) kd_loss 0.6271 (0.6779) lr 1.4258e-03 eta 0:17:07
epoch [20/50] batch [60/288] time 0.103 (0.111) data 0.000 (0.006) loss 1.6153 (1.7527) teacher_loss 0.8418 (0.8793) loss_zs_kd 0.2614 (0.4272) loss_oracle 0.3191 (0.3617) acc 78.1250 (75.5729) kd_loss 0.6140 (0.6925) lr 1.4258e-03 eta 0:16:26
epoch [20/50] batch [80/288] time 0.102 (0.109) data 0.000 (0.005) loss 1.5440 (1.7397) teacher_loss 0.6852 (0.8792) loss_zs_kd 0.3469 (0.4215) loss_oracle 0.3867 (0.3512) acc 84.3750 (75.9375) kd_loss 0.6655 (0.6849) lr 1.4258e-03 eta 0:16:04
epoch [20/50] batch [100/288] time 0.101 (0.110) data 0.000 (0.004) loss 1.7753 (1.7347) teacher_loss 1.0853 (0.8761) loss_zs_kd 0.3553 (0.4163) loss_oracle 0.3259 (0.3477) acc 65.6250 (75.9062) kd_loss 0.5271 (0.6848) lr 1.4258e-03 eta 0:16:15
epoch [20/50] batch [120/288] time 0.102 (0.109) data 0.000 (0.003) loss 1.3839 (1.7548) teacher_loss 0.4454 (0.8936) loss_zs_kd 0.2278 (0.4150) loss_oracle 0.3166 (0.3513) acc 90.6250 (75.7292) kd_loss 0.7802 (0.6856) lr 1.4258e-03 eta 0:16:01
epoch [20/50] batch [140/288] time 0.096 (0.108) data 0.000 (0.003) loss 1.5664 (1.7543) teacher_loss 0.7860 (0.8955) loss_zs_kd 0.3567 (0.4171) loss_oracle 0.3325 (0.3514) acc 78.1250 (75.6696) kd_loss 0.6142 (0.6831) lr 1.4258e-03 eta 0:15:47
epoch [20/50] batch [160/288] time 0.102 (0.107) data 0.000 (0.003) loss 1.7079 (1.7433) teacher_loss 0.9314 (0.8914) loss_zs_kd 0.3238 (0.4153) loss_oracle 0.3823 (0.3515) acc 75.0000 (75.8789) kd_loss 0.5853 (0.6762) lr 1.4258e-03 eta 0:15:35
epoch [20/50] batch [180/288] time 0.097 (0.106) data 0.000 (0.002) loss 1.5781 (1.7373) teacher_loss 0.7488 (0.8842) loss_zs_kd 0.3478 (0.4158) loss_oracle 0.4037 (0.3547) acc 75.0000 (75.9896) kd_loss 0.6274 (0.6757) lr 1.4258e-03 eta 0:15:30
epoch [20/50] batch [200/288] time 0.099 (0.106) data 0.000 (0.002) loss 2.0923 (1.7352) teacher_loss 1.3478 (0.8852) loss_zs_kd 0.6149 (0.4155) loss_oracle 0.3179 (0.3550) acc 62.5000 (76.0156) kd_loss 0.5855 (0.6725) lr 1.4258e-03 eta 0:15:24
epoch [20/50] batch [220/288] time 0.113 (0.106) data 0.000 (0.002) loss 1.6414 (1.7271) teacher_loss 0.8595 (0.8742) loss_zs_kd 0.4114 (0.4163) loss_oracle 0.3777 (0.3570) acc 75.0000 (76.2216) kd_loss 0.5930 (0.6744) lr 1.4258e-03 eta 0:15:18
epoch [20/50] batch [240/288] time 0.099 (0.105) data 0.000 (0.002) loss 1.9713 (1.7297) teacher_loss 1.0753 (0.8727) loss_zs_kd 0.3806 (0.4178) loss_oracle 0.3362 (0.3581) acc 65.6250 (76.2370) kd_loss 0.7279 (0.6780) lr 1.4258e-03 eta 0:15:13
epoch [20/50] batch [260/288] time 0.102 (0.105) data 0.000 (0.002) loss 2.1008 (1.7256) teacher_loss 1.2335 (0.8696) loss_zs_kd 0.3033 (0.4178) loss_oracle 0.3487 (0.3588) acc 68.7500 (76.2740) kd_loss 0.6929 (0.6766) lr 1.4258e-03 eta 0:15:09
epoch [20/50] batch [280/288] time 0.108 (0.105) data 0.000 (0.002) loss 1.3907 (1.7274) teacher_loss 0.6118 (0.8684) loss_zs_kd 0.3518 (0.4156) loss_oracle 0.3034 (0.3599) acc 90.6250 (76.3170) kd_loss 0.6272 (0.6791) lr 1.4258e-03 eta 0:15:05
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,448
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,990
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 78.6%
******* Domain a best val acc:      87.5%, epoch: 19 *******
******* Domain a best val test acc: 81.9%, epoch: 19 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [21/50] batch [20/288] time 0.110 (0.125) data 0.000 (0.019) loss 1.3102 (1.6662) teacher_loss 0.4220 (0.8268) loss_zs_kd 0.3951 (0.4442) loss_oracle 0.3552 (0.3475) acc 84.3750 (77.3438) kd_loss 0.7106 (0.6656) lr 1.3681e-03 eta 0:18:01
epoch [21/50] batch [40/288] time 0.093 (0.114) data 0.000 (0.009) loss 1.3912 (1.6834) teacher_loss 0.4775 (0.8315) loss_zs_kd 0.4319 (0.4258) loss_oracle 0.3683 (0.3561) acc 81.2500 (76.7188) kd_loss 0.7296 (0.6737) lr 1.3681e-03 eta 0:16:17
epoch [21/50] batch [60/288] time 0.157 (0.109) data 0.000 (0.006) loss 1.5179 (1.6868) teacher_loss 0.7612 (0.8510) loss_zs_kd 0.4274 (0.4166) loss_oracle 0.3357 (0.3530) acc 81.2500 (76.4062) kd_loss 0.5888 (0.6593) lr 1.3681e-03 eta 0:15:39
epoch [21/50] batch [80/288] time 0.090 (0.109) data 0.000 (0.005) loss 1.4448 (1.7084) teacher_loss 0.5140 (0.8761) loss_zs_kd 0.2802 (0.4108) loss_oracle 0.3509 (0.3492) acc 90.6250 (76.2109) kd_loss 0.7554 (0.6577) lr 1.3681e-03 eta 0:15:36
epoch [21/50] batch [100/288] time 0.116 (0.108) data 0.000 (0.004) loss 1.7461 (1.6937) teacher_loss 0.8530 (0.8614) loss_zs_kd 0.2960 (0.4130) loss_oracle 0.3751 (0.3505) acc 78.1250 (76.6875) kd_loss 0.7055 (0.6571) lr 1.3681e-03 eta 0:15:19
epoch [21/50] batch [120/288] time 0.099 (0.107) data 0.000 (0.003) loss 1.7348 (1.6996) teacher_loss 0.6726 (0.8636) loss_zs_kd 0.3010 (0.4165) loss_oracle 0.3625 (0.3516) acc 87.5000 (76.6667) kd_loss 0.8810 (0.6602) lr 1.3681e-03 eta 0:15:08
epoch [21/50] batch [140/288] time 0.102 (0.106) data 0.000 (0.003) loss 1.6913 (1.7160) teacher_loss 0.8146 (0.8762) loss_zs_kd 0.4457 (0.4163) loss_oracle 0.3441 (0.3529) acc 78.1250 (76.4509) kd_loss 0.7047 (0.6633) lr 1.3681e-03 eta 0:15:02
epoch [21/50] batch [160/288] time 0.104 (0.106) data 0.000 (0.002) loss 1.6218 (1.7381) teacher_loss 0.7412 (0.8929) loss_zs_kd 0.4335 (0.4241) loss_oracle 0.4420 (0.3557) acc 81.2500 (76.1133) kd_loss 0.6596 (0.6674) lr 1.3681e-03 eta 0:14:55
epoch [21/50] batch [180/288] time 0.099 (0.105) data 0.000 (0.002) loss 2.1511 (1.7487) teacher_loss 1.1733 (0.8993) loss_zs_kd 0.3258 (0.4273) loss_oracle 0.3482 (0.3567) acc 68.7500 (75.6771) kd_loss 0.8037 (0.6711) lr 1.3681e-03 eta 0:14:50
epoch [21/50] batch [200/288] time 0.096 (0.105) data 0.000 (0.002) loss 2.2814 (1.7471) teacher_loss 1.2209 (0.8947) loss_zs_kd 0.3185 (0.4248) loss_oracle 0.3517 (0.3555) acc 68.7500 (75.8438) kd_loss 0.8846 (0.6746) lr 1.3681e-03 eta 0:14:45
epoch [21/50] batch [220/288] time 0.097 (0.104) data 0.000 (0.002) loss 1.6222 (1.7503) teacher_loss 0.8171 (0.8950) loss_zs_kd 0.3224 (0.4237) loss_oracle 0.3773 (0.3549) acc 81.2500 (75.7528) kd_loss 0.6165 (0.6779) lr 1.3681e-03 eta 0:14:39
epoch [21/50] batch [240/288] time 0.100 (0.104) data 0.000 (0.002) loss 1.7362 (1.7591) teacher_loss 0.9404 (0.9062) loss_zs_kd 0.5079 (0.4212) loss_oracle 0.3685 (0.3547) acc 81.2500 (75.6771) kd_loss 0.6116 (0.6756) lr 1.3681e-03 eta 0:14:32
epoch [21/50] batch [260/288] time 0.099 (0.103) data 0.000 (0.002) loss 1.6731 (1.7522) teacher_loss 0.8026 (0.9029) loss_zs_kd 0.3757 (0.4213) loss_oracle 0.3265 (0.3541) acc 78.1250 (75.7332) kd_loss 0.7072 (0.6722) lr 1.3681e-03 eta 0:14:25
epoch [21/50] batch [280/288] time 0.088 (0.103) data 0.000 (0.001) loss 1.7293 (1.7519) teacher_loss 0.8327 (0.9013) loss_zs_kd 0.3622 (0.4203) loss_oracle 0.3296 (0.3539) acc 81.2500 (75.7478) kd_loss 0.7318 (0.6736) lr 1.3681e-03 eta 0:14:18
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,438
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,991
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 78.6%
******* Domain a best val acc:      87.5%, epoch: 19 *******
******* Domain a best val test acc: 81.9%, epoch: 19 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [22/50] batch [20/288] time 0.091 (0.115) data 0.000 (0.014) loss 2.1769 (1.7130) teacher_loss 1.2709 (0.8723) loss_zs_kd 0.4543 (0.4300) loss_oracle 0.2963 (0.3191) acc 62.5000 (74.8438) kd_loss 0.7579 (0.6811) lr 1.3090e-03 eta 0:15:54
epoch [22/50] batch [40/288] time 0.167 (0.114) data 0.000 (0.007) loss 1.5976 (1.6835) teacher_loss 0.8832 (0.8691) loss_zs_kd 0.3381 (0.4180) loss_oracle 0.2996 (0.3173) acc 84.3750 (75.5469) kd_loss 0.5647 (0.6558) lr 1.3090e-03 eta 0:15:44
epoch [22/50] batch [60/288] time 0.099 (0.108) data 0.000 (0.005) loss 1.5363 (1.6939) teacher_loss 0.6238 (0.8910) loss_zs_kd 0.4988 (0.4208) loss_oracle 0.3544 (0.3201) acc 78.1250 (75.1042) kd_loss 0.7352 (0.6429) lr 1.3090e-03 eta 0:14:56
epoch [22/50] batch [80/288] time 0.098 (0.105) data 0.000 (0.004) loss 2.2450 (1.6900) teacher_loss 1.3081 (0.8800) loss_zs_kd 0.4593 (0.4267) loss_oracle 0.3248 (0.3242) acc 65.6250 (75.5078) kd_loss 0.7744 (0.6479) lr 1.3090e-03 eta 0:14:32
epoch [22/50] batch [100/288] time 0.101 (0.104) data 0.000 (0.003) loss 1.3566 (1.6988) teacher_loss 0.5425 (0.8774) loss_zs_kd 0.2834 (0.4176) loss_oracle 0.3684 (0.3270) acc 87.5000 (75.7812) kd_loss 0.6298 (0.6580) lr 1.3090e-03 eta 0:14:16
epoch [22/50] batch [120/288] time 0.097 (0.103) data 0.000 (0.002) loss 1.6710 (1.7014) teacher_loss 0.8174 (0.8786) loss_zs_kd 0.5211 (0.4242) loss_oracle 0.3726 (0.3285) acc 78.1250 (75.8594) kd_loss 0.6674 (0.6586) lr 1.3090e-03 eta 0:14:04
epoch [22/50] batch [140/288] time 0.098 (0.102) data 0.000 (0.002) loss 1.7571 (1.6971) teacher_loss 0.9135 (0.8737) loss_zs_kd 0.4657 (0.4182) loss_oracle 0.3584 (0.3300) acc 78.1250 (76.0491) kd_loss 0.6644 (0.6584) lr 1.3090e-03 eta 0:13:54
epoch [22/50] batch [160/288] time 0.093 (0.101) data 0.000 (0.002) loss 1.2889 (1.7137) teacher_loss 0.6267 (0.8848) loss_zs_kd 0.2862 (0.4171) loss_oracle 0.3200 (0.3313) acc 87.5000 (75.9766) kd_loss 0.5022 (0.6633) lr 1.3090e-03 eta 0:13:49
epoch [22/50] batch [180/288] time 0.101 (0.101) data 0.000 (0.002) loss 1.7179 (1.7145) teacher_loss 0.8544 (0.8806) loss_zs_kd 0.2349 (0.4159) loss_oracle 0.3432 (0.3343) acc 81.2500 (76.1806) kd_loss 0.6919 (0.6668) lr 1.3090e-03 eta 0:13:44
epoch [22/50] batch [200/288] time 0.091 (0.100) data 0.000 (0.002) loss 1.7495 (1.7180) teacher_loss 0.8652 (0.8836) loss_zs_kd 0.4139 (0.4149) loss_oracle 0.3434 (0.3352) acc 87.5000 (76.2031) kd_loss 0.7126 (0.6668) lr 1.3090e-03 eta 0:13:37
epoch [22/50] batch [220/288] time 0.095 (0.100) data 0.000 (0.001) loss 1.1632 (1.7204) teacher_loss 0.4893 (0.8842) loss_zs_kd 0.4279 (0.4181) loss_oracle 0.3328 (0.3359) acc 87.5000 (75.9659) kd_loss 0.5076 (0.6683) lr 1.3090e-03 eta 0:13:32
epoch [22/50] batch [240/288] time 0.105 (0.100) data 0.000 (0.001) loss 1.7293 (1.7227) teacher_loss 0.9544 (0.8891) loss_zs_kd 0.4437 (0.4181) loss_oracle 0.2844 (0.3343) acc 68.7500 (75.8333) kd_loss 0.6327 (0.6665) lr 1.3090e-03 eta 0:13:28
epoch [22/50] batch [260/288] time 0.099 (0.100) data 0.000 (0.001) loss 1.8170 (1.7236) teacher_loss 0.8250 (0.8913) loss_zs_kd 0.3973 (0.4155) loss_oracle 0.3648 (0.3344) acc 78.1250 (75.7692) kd_loss 0.8096 (0.6651) lr 1.3090e-03 eta 0:13:25
epoch [22/50] batch [280/288] time 0.090 (0.099) data 0.000 (0.001) loss 1.2747 (1.7284) teacher_loss 0.5644 (0.8946) loss_zs_kd 0.4115 (0.4160) loss_oracle 0.3337 (0.3337) acc 87.5000 (75.7366) kd_loss 0.5434 (0.6669) lr 1.3090e-03 eta 0:13:20
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,441
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,985
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 78.2%
******* Domain a best val acc:      87.5%, epoch: 19 *******
******* Domain a best val test acc: 81.9%, epoch: 19 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [23/50] batch [20/288] time 0.112 (0.121) data 0.000 (0.015) loss 1.6690 (1.6532) teacher_loss 0.9979 (0.8548) loss_zs_kd 0.3771 (0.3931) loss_oracle 0.2966 (0.3403) acc 78.1250 (77.1875) kd_loss 0.5227 (0.6282) lr 1.2487e-03 eta 0:16:15
epoch [23/50] batch [40/288] time 0.101 (0.120) data 0.000 (0.008) loss 1.4096 (1.6521) teacher_loss 0.7824 (0.8523) loss_zs_kd 0.3685 (0.3961) loss_oracle 0.3037 (0.3370) acc 81.2500 (77.5000) kd_loss 0.4753 (0.6313) lr 1.2487e-03 eta 0:16:05
epoch [23/50] batch [60/288] time 0.115 (0.115) data 0.000 (0.005) loss 2.1401 (1.6768) teacher_loss 1.2059 (0.8804) loss_zs_kd 0.5044 (0.4031) loss_oracle 0.3515 (0.3361) acc 62.5000 (76.9792) kd_loss 0.7584 (0.6283) lr 1.2487e-03 eta 0:15:21
epoch [23/50] batch [80/288] time 0.097 (0.112) data 0.000 (0.004) loss 1.8570 (1.6652) teacher_loss 1.0978 (0.8697) loss_zs_kd 0.4138 (0.4041) loss_oracle 0.3499 (0.3365) acc 68.7500 (77.1484) kd_loss 0.5843 (0.6273) lr 1.2487e-03 eta 0:14:53
epoch [23/50] batch [100/288] time 0.103 (0.109) data 0.000 (0.003) loss 1.5851 (1.6588) teacher_loss 0.7391 (0.8622) loss_zs_kd 0.4790 (0.4085) loss_oracle 0.3364 (0.3356) acc 78.1250 (77.1562) kd_loss 0.6777 (0.6288) lr 1.2487e-03 eta 0:14:31
epoch [23/50] batch [120/288] time 0.100 (0.108) data 0.000 (0.003) loss 1.3118 (1.6741) teacher_loss 0.4890 (0.8687) loss_zs_kd 0.4617 (0.4132) loss_oracle 0.3607 (0.3381) acc 84.3750 (77.1875) kd_loss 0.6424 (0.6364) lr 1.2487e-03 eta 0:14:16
epoch [23/50] batch [140/288] time 0.101 (0.106) data 0.000 (0.002) loss 1.2617 (1.6687) teacher_loss 0.7549 (0.8646) loss_zs_kd 0.3210 (0.4092) loss_oracle 0.3085 (0.3365) acc 78.1250 (77.0312) kd_loss 0.3526 (0.6359) lr 1.2487e-03 eta 0:14:03
epoch [23/50] batch [160/288] time 0.096 (0.105) data 0.000 (0.002) loss 1.9865 (1.6790) teacher_loss 1.0810 (0.8764) loss_zs_kd 0.3942 (0.4081) loss_oracle 0.3649 (0.3334) acc 75.0000 (76.5625) kd_loss 0.7230 (0.6359) lr 1.2487e-03 eta 0:13:52
epoch [23/50] batch [180/288] time 0.104 (0.104) data 0.000 (0.002) loss 1.5416 (1.6798) teacher_loss 0.7168 (0.8741) loss_zs_kd 0.2432 (0.4070) loss_oracle 0.3620 (0.3325) acc 84.3750 (76.5625) kd_loss 0.6438 (0.6395) lr 1.2487e-03 eta 0:13:43
epoch [23/50] batch [200/288] time 0.094 (0.104) data 0.000 (0.002) loss 1.6249 (1.6845) teacher_loss 0.8065 (0.8724) loss_zs_kd 0.4342 (0.4074) loss_oracle 0.2592 (0.3318) acc 75.0000 (76.7812) kd_loss 0.6888 (0.6463) lr 1.2487e-03 eta 0:13:37
epoch [23/50] batch [220/288] time 0.107 (0.103) data 0.000 (0.002) loss 2.0473 (1.6962) teacher_loss 1.1922 (0.8768) loss_zs_kd 0.3507 (0.4073) loss_oracle 0.3214 (0.3329) acc 71.8750 (76.5199) kd_loss 0.6944 (0.6529) lr 1.2487e-03 eta 0:13:30
epoch [23/50] batch [240/288] time 0.097 (0.103) data 0.000 (0.001) loss 1.7042 (1.7054) teacher_loss 0.8549 (0.8857) loss_zs_kd 0.4456 (0.4035) loss_oracle 0.3546 (0.3325) acc 75.0000 (76.3672) kd_loss 0.6720 (0.6535) lr 1.2487e-03 eta 0:13:24
epoch [23/50] batch [260/288] time 0.102 (0.102) data 0.000 (0.001) loss 1.4129 (1.7178) teacher_loss 0.6330 (0.8923) loss_zs_kd 0.3854 (0.4044) loss_oracle 0.3338 (0.3330) acc 84.3750 (76.1779) kd_loss 0.6130 (0.6590) lr 1.2487e-03 eta 0:13:18
epoch [23/50] batch [280/288] time 0.088 (0.102) data 0.000 (0.001) loss 1.8577 (1.7138) teacher_loss 0.9109 (0.8869) loss_zs_kd 0.4134 (0.4041) loss_oracle 0.2997 (0.3335) acc 71.8750 (76.4174) kd_loss 0.7970 (0.6601) lr 1.2487e-03 eta 0:13:12
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,447
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,987
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 78.5%
******* Domain a best val acc:      87.5%, epoch: 19 *******
******* Domain a best val test acc: 81.9%, epoch: 19 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [24/50] batch [20/288] time 0.109 (0.143) data 0.000 (0.016) loss 1.7205 (1.6958) teacher_loss 1.0671 (0.8585) loss_zs_kd 0.3378 (0.3789) loss_oracle 0.3001 (0.3223) acc 78.1250 (77.5000) kd_loss 0.5034 (0.6761) lr 1.1874e-03 eta 0:18:27
epoch [24/50] batch [40/288] time 0.094 (0.121) data 0.000 (0.008) loss 1.5482 (1.7316) teacher_loss 0.8816 (0.8995) loss_zs_kd 0.4890 (0.3870) loss_oracle 0.3118 (0.3267) acc 75.0000 (76.3281) kd_loss 0.5106 (0.6688) lr 1.1874e-03 eta 0:15:33
epoch [24/50] batch [60/288] time 0.101 (0.113) data 0.000 (0.006) loss 1.6907 (1.7276) teacher_loss 0.8116 (0.9119) loss_zs_kd 0.3579 (0.3982) loss_oracle 0.3595 (0.3237) acc 81.2500 (76.0417) kd_loss 0.6993 (0.6539) lr 1.1874e-03 eta 0:14:32
epoch [24/50] batch [80/288] time 0.097 (0.109) data 0.000 (0.004) loss 1.5379 (1.7021) teacher_loss 0.7577 (0.8871) loss_zs_kd 0.5053 (0.3965) loss_oracle 0.3952 (0.3241) acc 87.5000 (76.5625) kd_loss 0.5827 (0.6529) lr 1.1874e-03 eta 0:13:56
epoch [24/50] batch [100/288] time 0.095 (0.106) data 0.000 (0.003) loss 1.3675 (1.7048) teacher_loss 0.7220 (0.8907) loss_zs_kd 0.4881 (0.3932) loss_oracle 0.2919 (0.3243) acc 84.3750 (76.5312) kd_loss 0.4996 (0.6519) lr 1.1874e-03 eta 0:13:37
epoch [24/50] batch [120/288] time 0.098 (0.104) data 0.000 (0.003) loss 1.7100 (1.6866) teacher_loss 0.8763 (0.8759) loss_zs_kd 0.2991 (0.3942) loss_oracle 0.3433 (0.3272) acc 78.1250 (76.6667) kd_loss 0.6621 (0.6471) lr 1.1874e-03 eta 0:13:19
epoch [24/50] batch [140/288] time 0.094 (0.103) data 0.000 (0.003) loss 1.7877 (1.6891) teacher_loss 0.8543 (0.8719) loss_zs_kd 0.3285 (0.3959) loss_oracle 0.3635 (0.3334) acc 78.1250 (76.8304) kd_loss 0.7517 (0.6505) lr 1.1874e-03 eta 0:13:08
epoch [24/50] batch [160/288] time 0.097 (0.102) data 0.000 (0.002) loss 1.8562 (1.6921) teacher_loss 1.0031 (0.8767) loss_zs_kd 0.3897 (0.4045) loss_oracle 0.3654 (0.3346) acc 78.1250 (76.8359) kd_loss 0.6705 (0.6481) lr 1.1874e-03 eta 0:12:59
epoch [24/50] batch [180/288] time 0.100 (0.102) data 0.000 (0.002) loss 1.6522 (1.7045) teacher_loss 0.7650 (0.8883) loss_zs_kd 0.3588 (0.4053) loss_oracle 0.3572 (0.3352) acc 75.0000 (76.4410) kd_loss 0.7086 (0.6486) lr 1.1874e-03 eta 0:12:52
epoch [24/50] batch [200/288] time 0.086 (0.101) data 0.000 (0.002) loss 1.8074 (1.7101) teacher_loss 0.9145 (0.8914) loss_zs_kd 0.4336 (0.4077) loss_oracle 0.2648 (0.3346) acc 71.8750 (76.3281) kd_loss 0.7605 (0.6513) lr 1.1874e-03 eta 0:12:47
epoch [24/50] batch [220/288] time 0.097 (0.101) data 0.000 (0.002) loss 1.4795 (1.7053) teacher_loss 0.7351 (0.8900) loss_zs_kd 0.4384 (0.4082) loss_oracle 0.2913 (0.3346) acc 78.1250 (76.3494) kd_loss 0.5987 (0.6480) lr 1.1874e-03 eta 0:12:40
epoch [24/50] batch [240/288] time 0.100 (0.100) data 0.000 (0.002) loss 1.5269 (1.7015) teacher_loss 0.7263 (0.8900) loss_zs_kd 0.4124 (0.4082) loss_oracle 0.2425 (0.3331) acc 84.3750 (76.4583) kd_loss 0.6793 (0.6450) lr 1.1874e-03 eta 0:12:35
epoch [24/50] batch [260/288] time 0.097 (0.100) data 0.000 (0.001) loss 1.3448 (1.7014) teacher_loss 0.6489 (0.8937) loss_zs_kd 0.4616 (0.4083) loss_oracle 0.2747 (0.3306) acc 81.2500 (76.2740) kd_loss 0.5585 (0.6424) lr 1.1874e-03 eta 0:12:31
epoch [24/50] batch [280/288] time 0.109 (0.100) data 0.000 (0.001) loss 1.4624 (1.7008) teacher_loss 0.8038 (0.8971) loss_zs_kd 0.3848 (0.4109) loss_oracle 0.2988 (0.3287) acc 81.2500 (76.2612) kd_loss 0.5091 (0.6393) lr 1.1874e-03 eta 0:12:30
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,453
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 87.1%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,987
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 78.7%
******* Domain a best val acc:      87.7%, epoch: 24 *******
******* Domain a best val test acc: 81.9%, epoch: 24 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [25/50] batch [20/288] time 0.102 (0.126) data 0.000 (0.017) loss 2.0116 (1.6056) teacher_loss 1.1928 (0.8872) loss_zs_kd 0.4554 (0.4216) loss_oracle 0.3410 (0.2919) acc 65.6250 (77.5000) kd_loss 0.6484 (0.5725) lr 1.1253e-03 eta 0:15:39
epoch [25/50] batch [40/288] time 0.097 (0.116) data 0.000 (0.009) loss 1.3916 (1.6402) teacher_loss 0.5804 (0.8965) loss_zs_kd 0.3477 (0.4210) loss_oracle 0.3186 (0.2911) acc 87.5000 (76.5625) kd_loss 0.6519 (0.5981) lr 1.1253e-03 eta 0:14:21
epoch [25/50] batch [60/288] time 0.107 (0.113) data 0.000 (0.006) loss 2.0663 (1.6635) teacher_loss 1.2529 (0.9080) loss_zs_kd 0.4006 (0.4180) loss_oracle 0.4060 (0.3016) acc 65.6250 (75.8854) kd_loss 0.6104 (0.6047) lr 1.1253e-03 eta 0:13:56
epoch [25/50] batch [80/288] time 0.098 (0.111) data 0.000 (0.005) loss 1.5754 (1.6632) teacher_loss 0.9828 (0.9008) loss_zs_kd 0.5579 (0.4202) loss_oracle 0.2899 (0.3075) acc 71.8750 (76.2891) kd_loss 0.4476 (0.6087) lr 1.1253e-03 eta 0:13:42
epoch [25/50] batch [100/288] time 0.101 (0.109) data 0.000 (0.004) loss 1.4499 (1.6666) teacher_loss 0.7094 (0.8931) loss_zs_kd 0.4790 (0.4314) loss_oracle 0.3165 (0.3127) acc 75.0000 (76.6250) kd_loss 0.5823 (0.6171) lr 1.1253e-03 eta 0:13:27
epoch [25/50] batch [120/288] time 0.102 (0.108) data 0.001 (0.003) loss 2.0508 (1.6732) teacher_loss 1.0991 (0.8870) loss_zs_kd 0.3931 (0.4248) loss_oracle 0.3323 (0.3175) acc 68.7500 (76.4062) kd_loss 0.7855 (0.6274) lr 1.1253e-03 eta 0:13:18
epoch [25/50] batch [140/288] time 0.130 (0.108) data 0.001 (0.003) loss 0.9402 (1.6782) teacher_loss 0.2855 (0.8844) loss_zs_kd 0.2961 (0.4244) loss_oracle 0.2411 (0.3221) acc 90.6250 (76.3839) kd_loss 0.5342 (0.6327) lr 1.1253e-03 eta 0:13:11
epoch [25/50] batch [160/288] time 0.102 (0.108) data 0.000 (0.002) loss 1.6101 (1.6839) teacher_loss 0.7810 (0.8785) loss_zs_kd 0.3571 (0.4200) loss_oracle 0.3240 (0.3250) acc 84.3750 (76.4648) kd_loss 0.6671 (0.6429) lr 1.1253e-03 eta 0:13:10
epoch [25/50] batch [180/288] time 0.122 (0.108) data 0.000 (0.002) loss 1.9792 (1.6953) teacher_loss 1.0691 (0.8856) loss_zs_kd 0.3838 (0.4196) loss_oracle 0.3898 (0.3271) acc 75.0000 (76.4062) kd_loss 0.7152 (0.6462) lr 1.1253e-03 eta 0:13:08
epoch [25/50] batch [200/288] time 0.100 (0.108) data 0.000 (0.002) loss 1.2607 (1.6922) teacher_loss 0.4733 (0.8808) loss_zs_kd 0.4897 (0.4201) loss_oracle 0.3475 (0.3289) acc 87.5000 (76.5312) kd_loss 0.6137 (0.6469) lr 1.1253e-03 eta 0:13:09
epoch [25/50] batch [220/288] time 0.125 (0.108) data 0.001 (0.002) loss 1.7264 (1.6896) teacher_loss 0.7160 (0.8724) loss_zs_kd 0.4628 (0.4193) loss_oracle 0.3360 (0.3315) acc 81.2500 (76.7472) kd_loss 0.8424 (0.6515) lr 1.1253e-03 eta 0:13:08
epoch [25/50] batch [240/288] time 0.103 (0.108) data 0.000 (0.002) loss 2.1143 (1.6935) teacher_loss 1.3849 (0.8755) loss_zs_kd 0.4613 (0.4183) loss_oracle 0.3159 (0.3330) acc 65.6250 (76.6667) kd_loss 0.5714 (0.6515) lr 1.1253e-03 eta 0:13:06
epoch [25/50] batch [260/288] time 0.092 (0.108) data 0.000 (0.002) loss 1.4759 (1.6950) teacher_loss 0.7621 (0.8749) loss_zs_kd 0.3956 (0.4203) loss_oracle 0.3107 (0.3335) acc 81.2500 (76.6947) kd_loss 0.5585 (0.6534) lr 1.1253e-03 eta 0:13:00
epoch [25/50] batch [280/288] time 0.109 (0.108) data 0.000 (0.002) loss 1.6101 (1.6960) teacher_loss 0.9434 (0.8752) loss_zs_kd 0.2682 (0.4191) loss_oracle 0.3557 (0.3336) acc 75.0000 (76.7634) kd_loss 0.4889 (0.6540) lr 1.1253e-03 eta 0:12:56
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,454
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 87.2%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,005
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 79.4%
******* Domain a best val acc:      87.7%, epoch: 25 *******
******* Domain a best val test acc: 82.6%, epoch: 25 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [26/50] batch [20/288] time 0.114 (0.119) data 0.000 (0.014) loss 1.3998 (1.5281) teacher_loss 0.6218 (0.7317) loss_zs_kd 0.2980 (0.4174) loss_oracle 0.3307 (0.3557) acc 87.5000 (80.6250) kd_loss 0.6126 (0.6185) lr 1.0628e-03 eta 0:14:15
epoch [26/50] batch [40/288] time 0.105 (0.111) data 0.000 (0.007) loss 1.8031 (1.6080) teacher_loss 0.9668 (0.8071) loss_zs_kd 0.2318 (0.4207) loss_oracle 0.3044 (0.3541) acc 75.0000 (77.8125) kd_loss 0.6841 (0.6238) lr 1.0628e-03 eta 0:13:13
epoch [26/50] batch [60/288] time 0.102 (0.107) data 0.000 (0.005) loss 1.5772 (1.6450) teacher_loss 0.8871 (0.8252) loss_zs_kd 0.4246 (0.4299) loss_oracle 0.3196 (0.3674) acc 62.5000 (77.7604) kd_loss 0.5303 (0.6361) lr 1.0628e-03 eta 0:12:47
epoch [26/50] batch [80/288] time 0.100 (0.106) data 0.000 (0.004) loss 2.1767 (1.6651) teacher_loss 1.4399 (0.8390) loss_zs_kd 0.4365 (0.4300) loss_oracle 0.3306 (0.3674) acc 71.8750 (77.5781) kd_loss 0.5715 (0.6425) lr 1.0628e-03 eta 0:12:33
epoch [26/50] batch [100/288] time 0.103 (0.106) data 0.000 (0.003) loss 1.2968 (1.6829) teacher_loss 0.5638 (0.8528) loss_zs_kd 0.3837 (0.4281) loss_oracle 0.3775 (0.3711) acc 90.6250 (77.0312) kd_loss 0.5443 (0.6446) lr 1.0628e-03 eta 0:12:32
epoch [26/50] batch [120/288] time 0.124 (0.107) data 0.000 (0.002) loss 1.8240 (1.6945) teacher_loss 0.9572 (0.8593) loss_zs_kd 0.5952 (0.4264) loss_oracle 0.3904 (0.3732) acc 71.8750 (76.7969) kd_loss 0.6716 (0.6486) lr 1.0628e-03 eta 0:12:36
epoch [26/50] batch [140/288] time 0.102 (0.108) data 0.000 (0.002) loss 1.8069 (1.6911) teacher_loss 0.9156 (0.8532) loss_zs_kd 0.3953 (0.4258) loss_oracle 0.4301 (0.3704) acc 71.8750 (76.7857) kd_loss 0.6763 (0.6526) lr 1.0628e-03 eta 0:12:43
epoch [26/50] batch [160/288] time 0.106 (0.109) data 0.001 (0.002) loss 1.8315 (1.6879) teacher_loss 1.0453 (0.8554) loss_zs_kd 0.5152 (0.4276) loss_oracle 0.3510 (0.3705) acc 65.6250 (76.8164) kd_loss 0.6107 (0.6472) lr 1.0628e-03 eta 0:12:44
epoch [26/50] batch [180/288] time 0.098 (0.109) data 0.000 (0.002) loss 1.4334 (1.6917) teacher_loss 0.6682 (0.8565) loss_zs_kd 0.3197 (0.4260) loss_oracle 0.3497 (0.3693) acc 81.2500 (76.7188) kd_loss 0.5903 (0.6505) lr 1.0628e-03 eta 0:12:41
epoch [26/50] batch [200/288] time 0.101 (0.108) data 0.000 (0.002) loss 1.7729 (1.6935) teacher_loss 0.8897 (0.8572) loss_zs_kd 0.3712 (0.4263) loss_oracle 0.3883 (0.3680) acc 81.2500 (76.6875) kd_loss 0.6890 (0.6524) lr 1.0628e-03 eta 0:12:34
epoch [26/50] batch [220/288] time 0.099 (0.107) data 0.000 (0.001) loss 1.1910 (1.7022) teacher_loss 0.3432 (0.8617) loss_zs_kd 0.3150 (0.4264) loss_oracle 0.3601 (0.3670) acc 93.7500 (76.6335) kd_loss 0.6678 (0.6570) lr 1.0628e-03 eta 0:12:30
epoch [26/50] batch [240/288] time 0.098 (0.107) data 0.000 (0.001) loss 1.7896 (1.7097) teacher_loss 0.8592 (0.8659) loss_zs_kd 0.4687 (0.4280) loss_oracle 0.3385 (0.3662) acc 78.1250 (76.4453) kd_loss 0.7611 (0.6606) lr 1.0628e-03 eta 0:12:22
epoch [26/50] batch [260/288] time 0.104 (0.108) data 0.000 (0.001) loss 1.6209 (1.7198) teacher_loss 0.7403 (0.8711) loss_zs_kd 0.5919 (0.4340) loss_oracle 0.3804 (0.3670) acc 81.2500 (76.3582) kd_loss 0.6905 (0.6652) lr 1.0628e-03 eta 0:12:28
epoch [26/50] batch [280/288] time 0.107 (0.108) data 0.001 (0.001) loss 1.9144 (1.7257) teacher_loss 0.9115 (0.8738) loss_zs_kd 0.4964 (0.4375) loss_oracle 0.3387 (0.3670) acc 68.7500 (76.3504) kd_loss 0.8336 (0.6684) lr 1.0628e-03 eta 0:12:27
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,453
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,993
* accuracy: 82.1%
* error: 17.9%
* macro_f1: 78.5%
******* Domain a best val acc:      87.7%, epoch: 25 *******
******* Domain a best val test acc: 82.6%, epoch: 25 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [27/50] batch [20/288] time 0.098 (0.117) data 0.000 (0.014) loss 1.0828 (1.6312) teacher_loss 0.5624 (0.8136) loss_zs_kd 0.4802 (0.4778) loss_oracle 0.3327 (0.3497) acc 84.3750 (78.7500) kd_loss 0.3541 (0.6428) lr 1.0000e-03 eta 0:13:26
epoch [27/50] batch [40/288] time 0.106 (0.112) data 0.000 (0.007) loss 1.3226 (1.7065) teacher_loss 0.4097 (0.8758) loss_zs_kd 0.2938 (0.4475) loss_oracle 0.3844 (0.3634) acc 90.6250 (76.9531) kd_loss 0.7208 (0.6489) lr 1.0000e-03 eta 0:12:49
epoch [27/50] batch [60/288] time 0.103 (0.110) data 0.000 (0.005) loss 2.0445 (1.7022) teacher_loss 1.1788 (0.8608) loss_zs_kd 0.6934 (0.4526) loss_oracle 0.4056 (0.3734) acc 65.6250 (77.1354) kd_loss 0.6628 (0.6547) lr 1.0000e-03 eta 0:12:35
epoch [27/50] batch [80/288] time 0.105 (0.109) data 0.000 (0.004) loss 1.6558 (1.7139) teacher_loss 0.6268 (0.8579) loss_zs_kd 0.4365 (0.4404) loss_oracle 0.3649 (0.3761) acc 87.5000 (76.7188) kd_loss 0.8466 (0.6679) lr 1.0000e-03 eta 0:12:25
epoch [27/50] batch [100/288] time 0.097 (0.108) data 0.000 (0.003) loss 1.6870 (1.7192) teacher_loss 0.7126 (0.8651) loss_zs_kd 0.5489 (0.4413) loss_oracle 0.4090 (0.3733) acc 81.2500 (76.4688) kd_loss 0.7700 (0.6675) lr 1.0000e-03 eta 0:12:18
epoch [27/50] batch [120/288] time 0.107 (0.108) data 0.000 (0.003) loss 1.4225 (1.6930) teacher_loss 0.6402 (0.8432) loss_zs_kd 0.3647 (0.4378) loss_oracle 0.4194 (0.3722) acc 84.3750 (77.2917) kd_loss 0.5725 (0.6637) lr 1.0000e-03 eta 0:12:12
epoch [27/50] batch [140/288] time 0.108 (0.107) data 0.000 (0.002) loss 1.6277 (1.7012) teacher_loss 0.8501 (0.8528) loss_zs_kd 0.5957 (0.4426) loss_oracle 0.3413 (0.3708) acc 78.1250 (77.3214) kd_loss 0.6070 (0.6630) lr 1.0000e-03 eta 0:12:06
epoch [27/50] batch [160/288] time 0.100 (0.106) data 0.000 (0.002) loss 1.9670 (1.7004) teacher_loss 0.9608 (0.8481) loss_zs_kd 0.4713 (0.4438) loss_oracle 0.3392 (0.3672) acc 65.6250 (77.4219) kd_loss 0.8366 (0.6687) lr 1.0000e-03 eta 0:11:58
epoch [27/50] batch [180/288] time 0.097 (0.106) data 0.001 (0.002) loss 1.5329 (1.7021) teacher_loss 0.7639 (0.8516) loss_zs_kd 0.4815 (0.4427) loss_oracle 0.3480 (0.3638) acc 68.7500 (77.1354) kd_loss 0.5949 (0.6686) lr 1.0000e-03 eta 0:11:52
epoch [27/50] batch [200/288] time 0.100 (0.105) data 0.000 (0.002) loss 1.8409 (1.6969) teacher_loss 0.9598 (0.8466) loss_zs_kd 0.3596 (0.4419) loss_oracle 0.3532 (0.3630) acc 71.8750 (77.1250) kd_loss 0.7046 (0.6688) lr 1.0000e-03 eta 0:11:46
epoch [27/50] batch [220/288] time 0.175 (0.106) data 0.000 (0.002) loss 1.5867 (1.6924) teacher_loss 0.8634 (0.8450) loss_zs_kd 0.7624 (0.4411) loss_oracle 0.3285 (0.3610) acc 75.0000 (77.1449) kd_loss 0.5591 (0.6669) lr 1.0000e-03 eta 0:11:50
epoch [27/50] batch [240/288] time 0.116 (0.106) data 0.000 (0.001) loss 1.2390 (1.7059) teacher_loss 0.4972 (0.8579) loss_zs_kd 0.3117 (0.4409) loss_oracle 0.3867 (0.3591) acc 84.3750 (76.7318) kd_loss 0.5485 (0.6684) lr 1.0000e-03 eta 0:11:49
epoch [27/50] batch [260/288] time 0.099 (0.107) data 0.000 (0.001) loss 1.4439 (1.7056) teacher_loss 0.6013 (0.8582) loss_zs_kd 0.4000 (0.4413) loss_oracle 0.4306 (0.3586) acc 81.2500 (76.7067) kd_loss 0.6272 (0.6680) lr 1.0000e-03 eta 0:11:48
epoch [27/50] batch [280/288] time 0.108 (0.107) data 0.000 (0.001) loss 2.0286 (1.7061) teacher_loss 1.2980 (0.8603) loss_zs_kd 0.5947 (0.4417) loss_oracle 0.2618 (0.3577) acc 56.2500 (76.6518) kd_loss 0.5997 (0.6670) lr 1.0000e-03 eta 0:11:46
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,442
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,984
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 78.4%
******* Domain a best val acc:      87.7%, epoch: 25 *******
******* Domain a best val test acc: 82.6%, epoch: 25 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [28/50] batch [20/288] time 0.093 (0.115) data 0.000 (0.016) loss 1.3939 (1.7420) teacher_loss 0.6870 (0.8573) loss_zs_kd 0.4200 (0.4651) loss_oracle 0.3527 (0.3754) acc 78.1250 (76.0938) kd_loss 0.5305 (0.6971) lr 9.3721e-04 eta 0:12:40
epoch [28/50] batch [40/288] time 0.089 (0.103) data 0.000 (0.008) loss 1.2910 (1.7250) teacher_loss 0.5035 (0.8686) loss_zs_kd 0.3888 (0.4325) loss_oracle 0.3252 (0.3630) acc 87.5000 (75.7812) kd_loss 0.6249 (0.6749) lr 9.3721e-04 eta 0:11:16
epoch [28/50] batch [60/288] time 0.100 (0.101) data 0.001 (0.005) loss 1.5588 (1.7294) teacher_loss 0.7440 (0.8808) loss_zs_kd 0.5485 (0.4439) loss_oracle 0.2831 (0.3573) acc 75.0000 (75.3646) kd_loss 0.6733 (0.6700) lr 9.3721e-04 eta 0:11:02
epoch [28/50] batch [80/288] time 0.097 (0.100) data 0.000 (0.004) loss 1.6497 (1.7406) teacher_loss 0.8881 (0.8907) loss_zs_kd 0.4004 (0.4441) loss_oracle 0.3432 (0.3601) acc 68.7500 (75.2734) kd_loss 0.5900 (0.6699) lr 9.3721e-04 eta 0:10:56
epoch [28/50] batch [100/288] time 0.102 (0.100) data 0.000 (0.003) loss 1.5653 (1.7421) teacher_loss 0.7576 (0.8863) loss_zs_kd 0.3429 (0.4446) loss_oracle 0.3182 (0.3629) acc 81.2500 (75.5000) kd_loss 0.6486 (0.6743) lr 9.3721e-04 eta 0:10:53
epoch [28/50] batch [120/288] time 0.098 (0.101) data 0.000 (0.003) loss 1.6303 (1.7204) teacher_loss 0.8146 (0.8727) loss_zs_kd 0.3728 (0.4390) loss_oracle 0.3505 (0.3602) acc 81.2500 (75.9896) kd_loss 0.6405 (0.6676) lr 9.3721e-04 eta 0:10:55
epoch [28/50] batch [140/288] time 0.114 (0.102) data 0.000 (0.002) loss 1.1025 (1.7041) teacher_loss 0.3697 (0.8643) loss_zs_kd 0.3383 (0.4390) loss_oracle 0.3696 (0.3574) acc 90.6250 (76.1830) kd_loss 0.5480 (0.6610) lr 9.3721e-04 eta 0:10:59
epoch [28/50] batch [160/288] time 0.102 (0.102) data 0.000 (0.002) loss 1.7959 (1.6853) teacher_loss 1.1123 (0.8525) loss_zs_kd 0.4193 (0.4345) loss_oracle 0.3115 (0.3552) acc 65.6250 (76.5234) kd_loss 0.5279 (0.6552) lr 9.3721e-04 eta 0:10:59
epoch [28/50] batch [180/288] time 0.112 (0.102) data 0.000 (0.002) loss 1.3971 (1.6749) teacher_loss 0.6667 (0.8444) loss_zs_kd 0.6196 (0.4364) loss_oracle 0.2993 (0.3556) acc 81.2500 (76.9444) kd_loss 0.5807 (0.6527) lr 9.3721e-04 eta 0:11:00
epoch [28/50] batch [200/288] time 0.092 (0.104) data 0.000 (0.002) loss 1.9146 (1.6842) teacher_loss 1.1351 (0.8535) loss_zs_kd 0.5778 (0.4405) loss_oracle 0.3551 (0.3569) acc 68.7500 (76.8594) kd_loss 0.6020 (0.6522) lr 9.3721e-04 eta 0:11:04
epoch [28/50] batch [220/288] time 0.112 (0.104) data 0.000 (0.002) loss 1.8073 (1.6846) teacher_loss 1.0244 (0.8534) loss_zs_kd 0.3719 (0.4404) loss_oracle 0.3662 (0.3582) acc 75.0000 (76.8182) kd_loss 0.5998 (0.6521) lr 9.3721e-04 eta 0:11:02
epoch [28/50] batch [240/288] time 0.094 (0.104) data 0.000 (0.002) loss 1.1810 (1.6893) teacher_loss 0.3693 (0.8541) loss_zs_kd 0.4582 (0.4428) loss_oracle 0.4145 (0.3618) acc 87.5000 (76.7188) kd_loss 0.6044 (0.6544) lr 9.3721e-04 eta 0:11:03
epoch [28/50] batch [260/288] time 0.096 (0.104) data 0.000 (0.001) loss 1.5607 (1.6918) teacher_loss 0.7199 (0.8553) loss_zs_kd 0.4016 (0.4431) loss_oracle 0.3574 (0.3637) acc 81.2500 (76.7909) kd_loss 0.6621 (0.6546) lr 9.3721e-04 eta 0:11:02
epoch [28/50] batch [280/288] time 0.084 (0.103) data 0.000 (0.001) loss 1.5138 (1.6926) teacher_loss 0.6766 (0.8533) loss_zs_kd 0.4317 (0.4442) loss_oracle 0.3685 (0.3659) acc 81.2500 (76.9196) kd_loss 0.6529 (0.6563) lr 9.3721e-04 eta 0:10:54
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,442
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,996
* accuracy: 82.2%
* error: 17.8%
* macro_f1: 79.0%
******* Domain a best val acc:      87.7%, epoch: 25 *******
******* Domain a best val test acc: 82.6%, epoch: 25 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [29/50] batch [20/288] time 0.086 (0.112) data 0.000 (0.015) loss 1.7024 (1.6145) teacher_loss 0.6301 (0.7477) loss_zs_kd 0.5999 (0.4509) loss_oracle 0.4169 (0.3800) acc 78.1250 (79.2188) kd_loss 0.8639 (0.6768) lr 8.7467e-04 eta 0:11:44
epoch [29/50] batch [40/288] time 0.085 (0.101) data 0.000 (0.008) loss 1.6379 (1.7249) teacher_loss 0.8798 (0.8541) loss_zs_kd 0.3882 (0.4435) loss_oracle 0.3820 (0.3852) acc 81.2500 (76.8750) kd_loss 0.5670 (0.6782) lr 8.7467e-04 eta 0:10:32
epoch [29/50] batch [60/288] time 0.090 (0.097) data 0.000 (0.005) loss 2.5651 (1.7525) teacher_loss 1.7008 (0.8882) loss_zs_kd 0.5176 (0.4407) loss_oracle 0.4183 (0.3804) acc 59.3750 (76.3021) kd_loss 0.6552 (0.6742) lr 8.7467e-04 eta 0:10:10
epoch [29/50] batch [80/288] time 0.108 (0.097) data 0.001 (0.004) loss 1.3681 (1.7452) teacher_loss 0.6143 (0.8813) loss_zs_kd 0.5131 (0.4609) loss_oracle 0.3170 (0.3750) acc 87.5000 (76.3672) kd_loss 0.5953 (0.6764) lr 8.7467e-04 eta 0:10:09
epoch [29/50] batch [100/288] time 0.104 (0.098) data 0.000 (0.003) loss 2.1747 (1.7610) teacher_loss 1.3454 (0.9001) loss_zs_kd 0.4090 (0.4653) loss_oracle 0.3425 (0.3721) acc 71.8750 (76.3750) kd_loss 0.6581 (0.6748) lr 8.7467e-04 eta 0:10:10
epoch [29/50] batch [120/288] time 0.087 (0.098) data 0.000 (0.003) loss 1.6276 (1.7408) teacher_loss 0.7734 (0.8825) loss_zs_kd 0.3161 (0.4587) loss_oracle 0.3223 (0.3671) acc 78.1250 (76.9010) kd_loss 0.6931 (0.6747) lr 8.7467e-04 eta 0:10:06
epoch [29/50] batch [140/288] time 0.102 (0.097) data 0.000 (0.002) loss 1.9932 (1.7292) teacher_loss 0.9708 (0.8704) loss_zs_kd 0.2841 (0.4503) loss_oracle 0.4142 (0.3677) acc 68.7500 (76.8750) kd_loss 0.8152 (0.6750) lr 8.7467e-04 eta 0:10:02
epoch [29/50] batch [160/288] time 0.100 (0.097) data 0.000 (0.002) loss 1.5035 (1.7288) teacher_loss 0.6477 (0.8695) loss_zs_kd 0.4947 (0.4528) loss_oracle 0.3758 (0.3684) acc 81.2500 (76.8555) kd_loss 0.6678 (0.6751) lr 8.7467e-04 eta 0:10:00
epoch [29/50] batch [180/288] time 0.104 (0.099) data 0.000 (0.002) loss 1.9055 (1.7361) teacher_loss 1.0945 (0.8771) loss_zs_kd 0.5228 (0.4544) loss_oracle 0.3734 (0.3702) acc 68.7500 (76.6493) kd_loss 0.6244 (0.6738) lr 8.7467e-04 eta 0:10:09
epoch [29/50] batch [200/288] time 0.097 (0.099) data 0.000 (0.002) loss 2.0620 (1.7332) teacher_loss 1.1355 (0.8731) loss_zs_kd 0.4200 (0.4526) loss_oracle 0.3336 (0.3695) acc 68.7500 (76.7812) kd_loss 0.7598 (0.6753) lr 8.7467e-04 eta 0:10:07
epoch [29/50] batch [220/288] time 0.093 (0.099) data 0.000 (0.002) loss 1.9960 (1.7436) teacher_loss 0.8966 (0.8775) loss_zs_kd 0.4293 (0.4486) loss_oracle 0.3821 (0.3702) acc 71.8750 (76.6903) kd_loss 0.9083 (0.6810) lr 8.7467e-04 eta 0:10:03
epoch [29/50] batch [240/288] time 0.099 (0.098) data 0.000 (0.001) loss 1.5948 (1.7449) teacher_loss 0.7527 (0.8762) loss_zs_kd 0.3491 (0.4463) loss_oracle 0.3712 (0.3716) acc 81.2500 (76.5495) kd_loss 0.6565 (0.6829) lr 8.7467e-04 eta 0:09:58
epoch [29/50] batch [260/288] time 0.095 (0.098) data 0.000 (0.001) loss 1.4413 (1.7424) teacher_loss 0.6432 (0.8761) loss_zs_kd 0.5558 (0.4480) loss_oracle 0.3879 (0.3720) acc 75.0000 (76.5505) kd_loss 0.6041 (0.6803) lr 8.7467e-04 eta 0:09:55
epoch [29/50] batch [280/288] time 0.106 (0.098) data 0.000 (0.001) loss 2.2734 (1.7427) teacher_loss 1.4456 (0.8782) loss_zs_kd 0.4239 (0.4493) loss_oracle 0.3393 (0.3710) acc 56.2500 (76.4621) kd_loss 0.6581 (0.6790) lr 8.7467e-04 eta 0:09:55
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,452
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,995
* accuracy: 82.2%
* error: 17.8%
* macro_f1: 78.7%
******* Domain a best val acc:      87.7%, epoch: 25 *******
******* Domain a best val test acc: 82.6%, epoch: 25 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [30/50] batch [20/288] time 0.096 (0.116) data 0.000 (0.013) loss 1.3985 (1.6702) teacher_loss 0.5550 (0.8278) loss_zs_kd 0.4591 (0.4348) loss_oracle 0.3574 (0.3513) acc 81.2500 (76.2500) kd_loss 0.6648 (0.6667) lr 8.1262e-04 eta 0:11:38
epoch [30/50] batch [40/288] time 0.096 (0.108) data 0.000 (0.007) loss 1.7344 (1.6307) teacher_loss 0.8694 (0.7736) loss_zs_kd 0.3152 (0.4329) loss_oracle 0.3786 (0.3618) acc 71.8750 (77.5781) kd_loss 0.6757 (0.6762) lr 8.1262e-04 eta 0:10:46
epoch [30/50] batch [60/288] time 0.093 (0.105) data 0.000 (0.005) loss 1.8702 (1.6847) teacher_loss 0.9413 (0.8119) loss_zs_kd 0.7027 (0.4490) loss_oracle 0.4274 (0.3684) acc 68.7500 (77.4479) kd_loss 0.7152 (0.6886) lr 8.1262e-04 eta 0:10:29
epoch [30/50] batch [80/288] time 0.098 (0.104) data 0.000 (0.004) loss 1.7248 (1.7124) teacher_loss 0.8066 (0.8375) loss_zs_kd 0.3946 (0.4496) loss_oracle 0.3622 (0.3697) acc 81.2500 (77.1094) kd_loss 0.7371 (0.6901) lr 8.1262e-04 eta 0:10:20
epoch [30/50] batch [100/288] time 0.098 (0.103) data 0.000 (0.003) loss 1.3722 (1.7413) teacher_loss 0.5177 (0.8620) loss_zs_kd 0.4332 (0.4452) loss_oracle 0.3105 (0.3656) acc 93.7500 (76.6562) kd_loss 0.6993 (0.6965) lr 8.1262e-04 eta 0:10:14
epoch [30/50] batch [120/288] time 0.101 (0.104) data 0.000 (0.002) loss 1.6625 (1.7484) teacher_loss 0.8255 (0.8716) loss_zs_kd 0.3497 (0.4449) loss_oracle 0.3703 (0.3651) acc 75.0000 (76.3542) kd_loss 0.6520 (0.6942) lr 8.1262e-04 eta 0:10:13
epoch [30/50] batch [140/288] time 0.096 (0.106) data 0.000 (0.002) loss 1.7362 (1.7579) teacher_loss 1.1276 (0.8851) loss_zs_kd 0.2739 (0.4482) loss_oracle 0.2859 (0.3646) acc 62.5000 (76.2946) kd_loss 0.4656 (0.6905) lr 8.1262e-04 eta 0:10:23
epoch [30/50] batch [160/288] time 0.104 (0.105) data 0.000 (0.002) loss 1.4367 (1.7496) teacher_loss 0.5349 (0.8798) loss_zs_kd 0.4368 (0.4491) loss_oracle 0.4164 (0.3638) acc 87.5000 (76.5820) kd_loss 0.6936 (0.6879) lr 8.1262e-04 eta 0:10:18
epoch [30/50] batch [180/288] time 0.101 (0.105) data 0.000 (0.002) loss 1.7228 (1.7532) teacher_loss 1.0474 (0.8889) loss_zs_kd 0.4716 (0.4467) loss_oracle 0.2840 (0.3609) acc 75.0000 (76.3194) kd_loss 0.5334 (0.6839) lr 8.1262e-04 eta 0:10:14
epoch [30/50] batch [200/288] time 0.102 (0.105) data 0.000 (0.002) loss 1.9013 (1.7484) teacher_loss 1.1325 (0.8858) loss_zs_kd 0.4814 (0.4455) loss_oracle 0.3924 (0.3597) acc 62.5000 (76.3594) kd_loss 0.5726 (0.6828) lr 8.1262e-04 eta 0:10:11
epoch [30/50] batch [220/288] time 0.109 (0.105) data 0.000 (0.001) loss 1.9855 (1.7468) teacher_loss 0.9946 (0.8861) loss_zs_kd 0.4489 (0.4454) loss_oracle 0.3875 (0.3599) acc 68.7500 (76.3068) kd_loss 0.7971 (0.6808) lr 8.1262e-04 eta 0:10:09
epoch [30/50] batch [240/288] time 0.097 (0.105) data 0.000 (0.001) loss 1.3270 (1.7445) teacher_loss 0.5261 (0.8883) loss_zs_kd 0.3388 (0.4433) loss_oracle 0.4000 (0.3581) acc 90.6250 (76.2240) kd_loss 0.6009 (0.6771) lr 8.1262e-04 eta 0:10:07
epoch [30/50] batch [260/288] time 0.106 (0.104) data 0.000 (0.001) loss 1.5339 (1.7510) teacher_loss 0.5685 (0.8943) loss_zs_kd 0.3988 (0.4431) loss_oracle 0.3552 (0.3587) acc 87.5000 (76.0697) kd_loss 0.7878 (0.6775) lr 8.1262e-04 eta 0:10:04
epoch [30/50] batch [280/288] time 0.107 (0.104) data 0.000 (0.001) loss 1.4247 (1.7416) teacher_loss 0.5571 (0.8848) loss_zs_kd 0.3827 (0.4421) loss_oracle 0.3621 (0.3578) acc 84.3750 (76.4732) kd_loss 0.6866 (0.6779) lr 8.1262e-04 eta 0:10:02
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,461
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 87.3%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,993
* accuracy: 82.1%
* error: 17.9%
* macro_f1: 78.6%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [31/50] batch [20/288] time 0.107 (0.116) data 0.000 (0.015) loss 1.0681 (1.6275) teacher_loss 0.4010 (0.8067) loss_zs_kd 0.3345 (0.4721) loss_oracle 0.2697 (0.3389) acc 90.6250 (78.5938) kd_loss 0.5322 (0.6513) lr 7.5131e-04 eta 0:11:08
epoch [31/50] batch [40/288] time 0.105 (0.112) data 0.000 (0.008) loss 1.5256 (1.6818) teacher_loss 0.6594 (0.8525) loss_zs_kd 0.4339 (0.4508) loss_oracle 0.4801 (0.3433) acc 87.5000 (77.2656) kd_loss 0.6261 (0.6577) lr 7.5131e-04 eta 0:10:39
epoch [31/50] batch [60/288] time 0.108 (0.109) data 0.000 (0.005) loss 1.7054 (1.6957) teacher_loss 0.8903 (0.8684) loss_zs_kd 0.4742 (0.4430) loss_oracle 0.3208 (0.3407) acc 75.0000 (76.3021) kd_loss 0.6546 (0.6570) lr 7.5131e-04 eta 0:10:23
epoch [31/50] batch [80/288] time 0.100 (0.107) data 0.000 (0.004) loss 1.8247 (1.6926) teacher_loss 0.7890 (0.8512) loss_zs_kd 0.3623 (0.4504) loss_oracle 0.4178 (0.3450) acc 81.2500 (76.7969) kd_loss 0.8267 (0.6689) lr 7.5131e-04 eta 0:10:08
epoch [31/50] batch [100/288] time 0.166 (0.109) data 0.000 (0.003) loss 1.8704 (1.6824) teacher_loss 0.9271 (0.8394) loss_zs_kd 0.6898 (0.4514) loss_oracle 0.3594 (0.3449) acc 71.8750 (77.2500) kd_loss 0.7635 (0.6705) lr 7.5131e-04 eta 0:10:15
epoch [31/50] batch [120/288] time 0.104 (0.107) data 0.000 (0.003) loss 1.3374 (1.6988) teacher_loss 0.4669 (0.8442) loss_zs_kd 0.3470 (0.4577) loss_oracle 0.2976 (0.3450) acc 90.6250 (77.3958) kd_loss 0.7217 (0.6822) lr 7.5131e-04 eta 0:10:06
epoch [31/50] batch [140/288] time 0.095 (0.106) data 0.000 (0.002) loss 1.1594 (1.6945) teacher_loss 0.5361 (0.8424) loss_zs_kd 0.5475 (0.4582) loss_oracle 0.3131 (0.3446) acc 84.3750 (77.5446) kd_loss 0.4668 (0.6797) lr 7.5131e-04 eta 0:09:58
epoch [31/50] batch [160/288] time 0.101 (0.106) data 0.000 (0.002) loss 1.7282 (1.7076) teacher_loss 0.6381 (0.8496) loss_zs_kd 0.4707 (0.4601) loss_oracle 0.3757 (0.3460) acc 81.2500 (77.2656) kd_loss 0.9022 (0.6850) lr 7.5131e-04 eta 0:09:52
epoch [31/50] batch [180/288] time 0.096 (0.105) data 0.000 (0.002) loss 1.9413 (1.7137) teacher_loss 1.1895 (0.8558) loss_zs_kd 0.4544 (0.4562) loss_oracle 0.2926 (0.3459) acc 71.8750 (76.9965) kd_loss 0.6055 (0.6850) lr 7.5131e-04 eta 0:09:47
epoch [31/50] batch [200/288] time 0.099 (0.105) data 0.000 (0.002) loss 1.5502 (1.7152) teacher_loss 0.7979 (0.8576) loss_zs_kd 0.3992 (0.4575) loss_oracle 0.3401 (0.3466) acc 84.3750 (77.1406) kd_loss 0.5823 (0.6844) lr 7.5131e-04 eta 0:09:44
epoch [31/50] batch [220/288] time 0.100 (0.105) data 0.000 (0.002) loss 1.8808 (1.7195) teacher_loss 0.8878 (0.8623) loss_zs_kd 0.5187 (0.4566) loss_oracle 0.3714 (0.3473) acc 75.0000 (77.0312) kd_loss 0.8073 (0.6836) lr 7.5131e-04 eta 0:09:43
epoch [31/50] batch [240/288] time 0.105 (0.106) data 0.000 (0.002) loss 1.7528 (1.7163) teacher_loss 0.8859 (0.8597) loss_zs_kd 0.4220 (0.4572) loss_oracle 0.3263 (0.3477) acc 75.0000 (76.9401) kd_loss 0.7038 (0.6828) lr 7.5131e-04 eta 0:09:45
epoch [31/50] batch [260/288] time 0.108 (0.107) data 0.000 (0.001) loss 1.4060 (1.7172) teacher_loss 0.5129 (0.8628) loss_zs_kd 0.2780 (0.4543) loss_oracle 0.3651 (0.3472) acc 87.5000 (76.8510) kd_loss 0.7106 (0.6809) lr 7.5131e-04 eta 0:09:49
epoch [31/50] batch [280/288] time 0.090 (0.107) data 0.000 (0.001) loss 1.6567 (1.7093) teacher_loss 0.6940 (0.8558) loss_zs_kd 0.3504 (0.4518) loss_oracle 0.4164 (0.3488) acc 84.3750 (77.1987) kd_loss 0.7545 (0.6792) lr 7.5131e-04 eta 0:09:43
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,455
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,989
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 78.6%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [32/50] batch [20/288] time 0.100 (0.105) data 0.000 (0.012) loss 1.6880 (1.7368) teacher_loss 0.8744 (0.8635) loss_zs_kd 0.3374 (0.4391) loss_oracle 0.3502 (0.3638) acc 81.2500 (78.1250) kd_loss 0.6385 (0.6914) lr 6.9098e-04 eta 0:09:32
epoch [32/50] batch [40/288] time 0.099 (0.099) data 0.000 (0.006) loss 1.1691 (1.7358) teacher_loss 0.4426 (0.8800) loss_zs_kd 0.2800 (0.4609) loss_oracle 0.3671 (0.3598) acc 90.6250 (77.8906) kd_loss 0.5429 (0.6759) lr 6.9098e-04 eta 0:08:58
epoch [32/50] batch [60/288] time 0.087 (0.097) data 0.000 (0.004) loss 1.4251 (1.7537) teacher_loss 0.7188 (0.8881) loss_zs_kd 0.5438 (0.4677) loss_oracle 0.3457 (0.3661) acc 81.2500 (76.7708) kd_loss 0.5334 (0.6826) lr 6.9098e-04 eta 0:08:45
epoch [32/50] batch [80/288] time 0.104 (0.100) data 0.000 (0.003) loss 2.1981 (1.7247) teacher_loss 1.3611 (0.8644) loss_zs_kd 0.3473 (0.4649) loss_oracle 0.3874 (0.3683) acc 62.5000 (77.4609) kd_loss 0.6432 (0.6761) lr 6.9098e-04 eta 0:08:58
epoch [32/50] batch [100/288] time 0.084 (0.099) data 0.000 (0.003) loss 1.2780 (1.7213) teacher_loss 0.3896 (0.8621) loss_zs_kd 0.4419 (0.4585) loss_oracle 0.3855 (0.3670) acc 90.6250 (77.5625) kd_loss 0.6956 (0.6757) lr 6.9098e-04 eta 0:08:49
epoch [32/50] batch [120/288] time 0.097 (0.098) data 0.000 (0.002) loss 1.2018 (1.7105) teacher_loss 0.4335 (0.8545) loss_zs_kd 0.3500 (0.4604) loss_oracle 0.3609 (0.3685) acc 87.5000 (77.6042) kd_loss 0.5878 (0.6718) lr 6.9098e-04 eta 0:08:43
epoch [32/50] batch [140/288] time 0.089 (0.097) data 0.000 (0.002) loss 1.6657 (1.7164) teacher_loss 0.8111 (0.8553) loss_zs_kd 0.6076 (0.4599) loss_oracle 0.4239 (0.3704) acc 81.2500 (77.4330) kd_loss 0.6427 (0.6759) lr 6.9098e-04 eta 0:08:36
epoch [32/50] batch [160/288] time 0.096 (0.097) data 0.000 (0.002) loss 1.3701 (1.7182) teacher_loss 0.5360 (0.8539) loss_zs_kd 0.4768 (0.4582) loss_oracle 0.4326 (0.3726) acc 87.5000 (77.4609) kd_loss 0.6177 (0.6779) lr 6.9098e-04 eta 0:08:33
epoch [32/50] batch [180/288] time 0.099 (0.097) data 0.000 (0.002) loss 1.5508 (1.7351) teacher_loss 0.7295 (0.8695) loss_zs_kd 0.4769 (0.4584) loss_oracle 0.4073 (0.3728) acc 75.0000 (77.0139) kd_loss 0.6177 (0.6792) lr 6.9098e-04 eta 0:08:30
epoch [32/50] batch [200/288] time 0.095 (0.097) data 0.000 (0.001) loss 1.7570 (1.7338) teacher_loss 0.8345 (0.8654) loss_zs_kd 0.4628 (0.4568) loss_oracle 0.3504 (0.3746) acc 81.2500 (77.0312) kd_loss 0.7473 (0.6812) lr 6.9098e-04 eta 0:08:30
epoch [32/50] batch [220/288] time 0.094 (0.097) data 0.000 (0.001) loss 1.5932 (1.7348) teacher_loss 0.6510 (0.8697) loss_zs_kd 0.3657 (0.4547) loss_oracle 0.3516 (0.3738) acc 81.2500 (76.8750) kd_loss 0.7664 (0.6781) lr 6.9098e-04 eta 0:08:29
epoch [32/50] batch [240/288] time 0.099 (0.097) data 0.000 (0.001) loss 1.6771 (1.7223) teacher_loss 0.9736 (0.8621) loss_zs_kd 0.3328 (0.4522) loss_oracle 0.3296 (0.3724) acc 78.1250 (77.2135) kd_loss 0.5388 (0.6739) lr 6.9098e-04 eta 0:08:29
epoch [32/50] batch [260/288] time 0.102 (0.098) data 0.000 (0.001) loss 1.6359 (1.7255) teacher_loss 0.8328 (0.8685) loss_zs_kd 0.2979 (0.4518) loss_oracle 0.3701 (0.3705) acc 78.1250 (77.0673) kd_loss 0.6180 (0.6717) lr 6.9098e-04 eta 0:08:29
epoch [32/50] batch [280/288] time 0.108 (0.098) data 0.000 (0.001) loss 1.2848 (1.7192) teacher_loss 0.6256 (0.8659) loss_zs_kd 0.3553 (0.4512) loss_oracle 0.3580 (0.3694) acc 81.2500 (77.0647) kd_loss 0.4802 (0.6687) lr 6.9098e-04 eta 0:08:29
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,453
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,989
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 78.4%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [33/50] batch [20/288] time 0.102 (0.116) data 0.000 (0.013) loss 1.5867 (1.7510) teacher_loss 0.9547 (0.9003) loss_zs_kd 0.4832 (0.4747) loss_oracle 0.3284 (0.3679) acc 75.0000 (77.5000) kd_loss 0.4677 (0.6668) lr 6.3188e-04 eta 0:09:59
epoch [33/50] batch [40/288] time 0.132 (0.116) data 0.000 (0.007) loss 1.6907 (1.7869) teacher_loss 0.9158 (0.9117) loss_zs_kd 0.4778 (0.4680) loss_oracle 0.3076 (0.3671) acc 81.2500 (76.6406) kd_loss 0.6212 (0.6916) lr 6.3188e-04 eta 0:09:55
epoch [33/50] batch [60/288] time 0.108 (0.117) data 0.000 (0.005) loss 1.8804 (1.7805) teacher_loss 0.9923 (0.8970) loss_zs_kd 0.5498 (0.4694) loss_oracle 0.2974 (0.3693) acc 65.6250 (76.6667) kd_loss 0.7393 (0.6989) lr 6.3188e-04 eta 0:10:01
epoch [33/50] batch [80/288] time 0.114 (0.116) data 0.001 (0.004) loss 1.6962 (1.7724) teacher_loss 0.7425 (0.8957) loss_zs_kd 0.3560 (0.4623) loss_oracle 0.3561 (0.3670) acc 81.2500 (76.5234) kd_loss 0.7757 (0.6933) lr 6.3188e-04 eta 0:09:51
epoch [33/50] batch [100/288] time 0.093 (0.112) data 0.000 (0.003) loss 1.7552 (1.7441) teacher_loss 0.8544 (0.8753) loss_zs_kd 0.4551 (0.4695) loss_oracle 0.3799 (0.3655) acc 78.1250 (76.9062) kd_loss 0.7108 (0.6860) lr 6.3188e-04 eta 0:09:27
epoch [33/50] batch [120/288] time 0.096 (0.109) data 0.000 (0.002) loss 2.4443 (1.7431) teacher_loss 1.5537 (0.8740) loss_zs_kd 0.4673 (0.4697) loss_oracle 0.3841 (0.3658) acc 59.3750 (77.0052) kd_loss 0.6985 (0.6862) lr 6.3188e-04 eta 0:09:13
epoch [33/50] batch [140/288] time 0.100 (0.108) data 0.000 (0.002) loss 1.6336 (1.7429) teacher_loss 0.8914 (0.8756) loss_zs_kd 0.5085 (0.4710) loss_oracle 0.4083 (0.3636) acc 75.0000 (76.7857) kd_loss 0.5380 (0.6856) lr 6.3188e-04 eta 0:09:04
epoch [33/50] batch [160/288] time 0.104 (0.107) data 0.000 (0.002) loss 1.8404 (1.7386) teacher_loss 0.9695 (0.8690) loss_zs_kd 0.6005 (0.4680) loss_oracle 0.3646 (0.3628) acc 71.8750 (76.9727) kd_loss 0.6886 (0.6882) lr 6.3188e-04 eta 0:08:57
epoch [33/50] batch [180/288] time 0.097 (0.106) data 0.000 (0.002) loss 1.7441 (1.7438) teacher_loss 0.8845 (0.8716) loss_zs_kd 0.4952 (0.4671) loss_oracle 0.3722 (0.3623) acc 78.1250 (76.9965) kd_loss 0.6735 (0.6911) lr 6.3188e-04 eta 0:08:52
epoch [33/50] batch [200/288] time 0.097 (0.106) data 0.000 (0.002) loss 1.7152 (1.7347) teacher_loss 0.8940 (0.8657) loss_zs_kd 0.3294 (0.4645) loss_oracle 0.3313 (0.3612) acc 78.1250 (77.1250) kd_loss 0.6556 (0.6884) lr 6.3188e-04 eta 0:08:45
epoch [33/50] batch [220/288] time 0.097 (0.105) data 0.000 (0.001) loss 1.8681 (1.7310) teacher_loss 1.1055 (0.8636) loss_zs_kd 0.1934 (0.4645) loss_oracle 0.3688 (0.3619) acc 75.0000 (77.1307) kd_loss 0.5782 (0.6865) lr 6.3188e-04 eta 0:08:39
epoch [33/50] batch [240/288] time 0.107 (0.104) data 0.000 (0.001) loss 1.4363 (1.7175) teacher_loss 0.6754 (0.8545) loss_zs_kd 0.3781 (0.4654) loss_oracle 0.3960 (0.3619) acc 81.2500 (77.3438) kd_loss 0.5629 (0.6820) lr 6.3188e-04 eta 0:08:35
epoch [33/50] batch [260/288] time 0.095 (0.104) data 0.000 (0.001) loss 1.6035 (1.7193) teacher_loss 0.8954 (0.8610) loss_zs_kd 0.2998 (0.4651) loss_oracle 0.3396 (0.3619) acc 81.2500 (77.1755) kd_loss 0.5383 (0.6773) lr 6.3188e-04 eta 0:08:32
epoch [33/50] batch [280/288] time 0.086 (0.104) data 0.000 (0.001) loss 1.4503 (1.7158) teacher_loss 0.8247 (0.8627) loss_zs_kd 0.3372 (0.4648) loss_oracle 0.2939 (0.3595) acc 78.1250 (77.1094) kd_loss 0.4786 (0.6733) lr 6.3188e-04 eta 0:08:27
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,449
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,987
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 78.4%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [34/50] batch [20/288] time 0.099 (0.113) data 0.000 (0.013) loss 1.8193 (1.5933) teacher_loss 1.0537 (0.7926) loss_zs_kd 0.4352 (0.4425) loss_oracle 0.3585 (0.3376) acc 75.0000 (77.6562) kd_loss 0.5864 (0.6319) lr 5.7422e-04 eta 0:09:11
epoch [34/50] batch [40/288] time 0.095 (0.112) data 0.000 (0.007) loss 1.5983 (1.6155) teacher_loss 0.7824 (0.8233) loss_zs_kd 0.3281 (0.4409) loss_oracle 0.3289 (0.3464) acc 81.2500 (77.6562) kd_loss 0.6514 (0.6190) lr 5.7422e-04 eta 0:09:05
epoch [34/50] batch [60/288] time 0.096 (0.107) data 0.000 (0.005) loss 1.6368 (1.6277) teacher_loss 0.7348 (0.8348) loss_zs_kd 0.3143 (0.4464) loss_oracle 0.3955 (0.3474) acc 81.2500 (77.6042) kd_loss 0.7043 (0.6192) lr 5.7422e-04 eta 0:08:38
epoch [34/50] batch [80/288] time 0.102 (0.105) data 0.000 (0.004) loss 1.5316 (1.6297) teacher_loss 0.7849 (0.8341) loss_zs_kd 0.5008 (0.4473) loss_oracle 0.3429 (0.3507) acc 81.2500 (77.7734) kd_loss 0.5752 (0.6203) lr 5.7422e-04 eta 0:08:24
epoch [34/50] batch [100/288] time 0.096 (0.103) data 0.000 (0.003) loss 1.7505 (1.6303) teacher_loss 0.9487 (0.8202) loss_zs_kd 0.5630 (0.4458) loss_oracle 0.3775 (0.3544) acc 78.1250 (78.1250) kd_loss 0.6131 (0.6329) lr 5.7422e-04 eta 0:08:14
epoch [34/50] batch [120/288] time 0.098 (0.102) data 0.000 (0.002) loss 1.7606 (1.6526) teacher_loss 0.8386 (0.8356) loss_zs_kd 0.3667 (0.4425) loss_oracle 0.3232 (0.3558) acc 68.7500 (77.5000) kd_loss 0.7604 (0.6391) lr 5.7422e-04 eta 0:08:08
epoch [34/50] batch [140/288] time 0.094 (0.102) data 0.000 (0.002) loss 1.8274 (1.6520) teacher_loss 0.9226 (0.8307) loss_zs_kd 0.4686 (0.4447) loss_oracle 0.3057 (0.3573) acc 75.0000 (77.6786) kd_loss 0.7520 (0.6426) lr 5.7422e-04 eta 0:08:04
epoch [34/50] batch [160/288] time 0.101 (0.101) data 0.001 (0.002) loss 1.0063 (1.6530) teacher_loss 0.5337 (0.8283) loss_zs_kd 0.4834 (0.4507) loss_oracle 0.2850 (0.3583) acc 84.3750 (77.7344) kd_loss 0.3301 (0.6455) lr 5.7422e-04 eta 0:07:59
epoch [34/50] batch [180/288] time 0.095 (0.101) data 0.000 (0.002) loss 1.5128 (1.6625) teacher_loss 0.7034 (0.8385) loss_zs_kd 0.4465 (0.4556) loss_oracle 0.3360 (0.3586) acc 81.2500 (77.3264) kd_loss 0.6414 (0.6447) lr 5.7422e-04 eta 0:07:54
epoch [34/50] batch [200/288] time 0.091 (0.100) data 0.000 (0.002) loss 2.5164 (1.6830) teacher_loss 1.5298 (0.8542) loss_zs_kd 0.5081 (0.4556) loss_oracle 0.3612 (0.3596) acc 62.5000 (77.0000) kd_loss 0.8060 (0.6491) lr 5.7422e-04 eta 0:07:49
epoch [34/50] batch [220/288] time 0.100 (0.100) data 0.000 (0.001) loss 1.8680 (1.6878) teacher_loss 0.9523 (0.8550) loss_zs_kd 0.3868 (0.4573) loss_oracle 0.4028 (0.3617) acc 75.0000 (77.1023) kd_loss 0.7143 (0.6520) lr 5.7422e-04 eta 0:07:45
epoch [34/50] batch [240/288] time 0.091 (0.099) data 0.000 (0.001) loss 1.9790 (1.6930) teacher_loss 0.9759 (0.8562) loss_zs_kd 0.5114 (0.4591) loss_oracle 0.3538 (0.3630) acc 59.3750 (76.9922) kd_loss 0.8261 (0.6553) lr 5.7422e-04 eta 0:07:42
epoch [34/50] batch [260/288] time 0.094 (0.099) data 0.000 (0.001) loss 1.5358 (1.6929) teacher_loss 0.6734 (0.8535) loss_zs_kd 0.4942 (0.4581) loss_oracle 0.4171 (0.3647) acc 90.6250 (77.1154) kd_loss 0.6539 (0.6570) lr 5.7422e-04 eta 0:07:40
epoch [34/50] batch [280/288] time 0.084 (0.099) data 0.000 (0.001) loss 1.8735 (1.6896) teacher_loss 0.9709 (0.8502) loss_zs_kd 0.5782 (0.4563) loss_oracle 0.3560 (0.3649) acc 71.8750 (77.1429) kd_loss 0.7247 (0.6569) lr 5.7422e-04 eta 0:07:36
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,455
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,986
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 78.5%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [35/50] batch [20/288] time 0.094 (0.135) data 0.000 (0.018) loss 1.8380 (1.7229) teacher_loss 1.1397 (0.8992) loss_zs_kd 0.4405 (0.4752) loss_oracle 0.3502 (0.3685) acc 75.0000 (76.0938) kd_loss 0.5233 (0.6395) lr 5.1825e-04 eta 0:10:17
epoch [35/50] batch [40/288] time 0.098 (0.116) data 0.000 (0.009) loss 1.7821 (1.7709) teacher_loss 0.8901 (0.9335) loss_zs_kd 0.3794 (0.4817) loss_oracle 0.4371 (0.3699) acc 75.0000 (74.3750) kd_loss 0.6734 (0.6524) lr 5.1825e-04 eta 0:08:48
epoch [35/50] batch [60/288] time 0.094 (0.110) data 0.000 (0.006) loss 2.2924 (1.7713) teacher_loss 1.4170 (0.9156) loss_zs_kd 0.3807 (0.4665) loss_oracle 0.3817 (0.3762) acc 68.7500 (74.8438) kd_loss 0.6845 (0.6676) lr 5.1825e-04 eta 0:08:18
epoch [35/50] batch [80/288] time 0.093 (0.107) data 0.000 (0.005) loss 1.6415 (1.7664) teacher_loss 0.7842 (0.9168) loss_zs_kd 0.5154 (0.4619) loss_oracle 0.3355 (0.3779) acc 81.2500 (74.9219) kd_loss 0.6895 (0.6607) lr 5.1825e-04 eta 0:08:03
epoch [35/50] batch [100/288] time 0.097 (0.105) data 0.000 (0.004) loss 1.8684 (1.7669) teacher_loss 1.0148 (0.9132) loss_zs_kd 0.4138 (0.4620) loss_oracle 0.4472 (0.3835) acc 75.0000 (75.2188) kd_loss 0.6301 (0.6619) lr 5.1825e-04 eta 0:07:51
epoch [35/50] batch [120/288] time 0.097 (0.103) data 0.000 (0.003) loss 1.4190 (1.7532) teacher_loss 0.5973 (0.8980) loss_zs_kd 0.5832 (0.4628) loss_oracle 0.3703 (0.3850) acc 81.2500 (75.5469) kd_loss 0.6366 (0.6628) lr 5.1825e-04 eta 0:07:42
epoch [35/50] batch [140/288] time 0.096 (0.102) data 0.000 (0.003) loss 1.4020 (1.7567) teacher_loss 0.4508 (0.8955) loss_zs_kd 0.2296 (0.4596) loss_oracle 0.3941 (0.3874) acc 87.5000 (75.8036) kd_loss 0.7542 (0.6675) lr 5.1825e-04 eta 0:07:37
epoch [35/50] batch [160/288] time 0.100 (0.102) data 0.000 (0.002) loss 1.6432 (1.7516) teacher_loss 0.7506 (0.8893) loss_zs_kd 0.4518 (0.4592) loss_oracle 0.4354 (0.3888) acc 75.0000 (76.0156) kd_loss 0.6750 (0.6679) lr 5.1825e-04 eta 0:07:32
epoch [35/50] batch [180/288] time 0.097 (0.101) data 0.000 (0.002) loss 1.4092 (1.7398) teacher_loss 0.6254 (0.8728) loss_zs_kd 0.3001 (0.4557) loss_oracle 0.3297 (0.3877) acc 78.1250 (76.3542) kd_loss 0.6189 (0.6732) lr 5.1825e-04 eta 0:07:27
epoch [35/50] batch [200/288] time 0.098 (0.101) data 0.000 (0.002) loss 1.1482 (1.7336) teacher_loss 0.4524 (0.8691) loss_zs_kd 0.4537 (0.4585) loss_oracle 0.3448 (0.3856) acc 87.5000 (76.5625) kd_loss 0.5234 (0.6718) lr 5.1825e-04 eta 0:07:23
epoch [35/50] batch [220/288] time 0.091 (0.100) data 0.000 (0.002) loss 1.4697 (1.7253) teacher_loss 0.5829 (0.8653) loss_zs_kd 0.3072 (0.4575) loss_oracle 0.3496 (0.3835) acc 84.3750 (76.5909) kd_loss 0.7119 (0.6682) lr 5.1825e-04 eta 0:07:20
epoch [35/50] batch [240/288] time 0.105 (0.100) data 0.000 (0.002) loss 1.4066 (1.7177) teacher_loss 0.3827 (0.8590) loss_zs_kd 0.5322 (0.4574) loss_oracle 0.4029 (0.3836) acc 87.5000 (76.6927) kd_loss 0.8224 (0.6669) lr 5.1825e-04 eta 0:07:17
epoch [35/50] batch [260/288] time 0.096 (0.100) data 0.000 (0.002) loss 1.4238 (1.7064) teacher_loss 0.6200 (0.8474) loss_zs_kd 0.3805 (0.4574) loss_oracle 0.3785 (0.3837) acc 78.1250 (76.9111) kd_loss 0.6145 (0.6672) lr 5.1825e-04 eta 0:07:14
epoch [35/50] batch [280/288] time 0.088 (0.099) data 0.000 (0.002) loss 1.7141 (1.7097) teacher_loss 0.9193 (0.8507) loss_zs_kd 0.4131 (0.4608) loss_oracle 0.4171 (0.3834) acc 81.2500 (76.8192) kd_loss 0.5863 (0.6674) lr 5.1825e-04 eta 0:07:10
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,453
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,992
* accuracy: 82.1%
* error: 17.9%
* macro_f1: 78.6%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [36/50] batch [20/288] time 0.084 (0.122) data 0.000 (0.023) loss 2.1186 (1.6947) teacher_loss 1.1853 (0.8069) loss_zs_kd 0.4407 (0.4687) loss_oracle 0.3602 (0.3785) acc 75.0000 (78.5938) kd_loss 0.7532 (0.6985) lr 4.6417e-04 eta 0:08:44
epoch [36/50] batch [40/288] time 0.093 (0.106) data 0.000 (0.012) loss 1.5260 (1.7417) teacher_loss 0.7658 (0.8517) loss_zs_kd 0.4197 (0.4874) loss_oracle 0.3982 (0.3828) acc 84.3750 (77.1094) kd_loss 0.5611 (0.6987) lr 4.6417e-04 eta 0:07:31
epoch [36/50] batch [60/288] time 0.086 (0.101) data 0.000 (0.008) loss 1.5380 (1.7350) teacher_loss 0.5104 (0.8533) loss_zs_kd 0.6347 (0.4881) loss_oracle 0.4863 (0.3850) acc 90.6250 (77.0833) kd_loss 0.7845 (0.6892) lr 4.6417e-04 eta 0:07:08
epoch [36/50] batch [80/288] time 0.097 (0.098) data 0.000 (0.006) loss 1.6796 (1.7127) teacher_loss 0.7473 (0.8331) loss_zs_kd 0.4466 (0.4788) loss_oracle 0.3612 (0.3856) acc 78.1250 (77.7344) kd_loss 0.7516 (0.6868) lr 4.6417e-04 eta 0:06:54
epoch [36/50] batch [100/288] time 0.106 (0.098) data 0.000 (0.005) loss 2.0001 (1.6924) teacher_loss 1.1083 (0.8104) loss_zs_kd 0.3681 (0.4777) loss_oracle 0.4345 (0.3847) acc 78.1250 (78.3125) kd_loss 0.6746 (0.6897) lr 4.6417e-04 eta 0:06:53
epoch [36/50] batch [120/288] time 0.120 (0.099) data 0.000 (0.004) loss 1.3346 (1.6989) teacher_loss 0.5308 (0.8159) loss_zs_kd 0.3894 (0.4702) loss_oracle 0.3671 (0.3854) acc 87.5000 (78.0990) kd_loss 0.6203 (0.6903) lr 4.6417e-04 eta 0:06:57
epoch [36/50] batch [140/288] time 0.117 (0.100) data 0.000 (0.004) loss 1.5901 (1.7028) teacher_loss 0.8304 (0.8218) loss_zs_kd 0.4263 (0.4682) loss_oracle 0.4088 (0.3856) acc 75.0000 (77.9464) kd_loss 0.5552 (0.6882) lr 4.6417e-04 eta 0:06:59
epoch [36/50] batch [160/288] time 0.140 (0.102) data 0.000 (0.003) loss 1.5242 (1.6950) teacher_loss 0.6900 (0.8131) loss_zs_kd 0.3862 (0.4718) loss_oracle 0.3722 (0.3861) acc 81.2500 (78.1445) kd_loss 0.6481 (0.6888) lr 4.6417e-04 eta 0:07:03
epoch [36/50] batch [180/288] time 0.123 (0.103) data 0.001 (0.003) loss 2.1239 (1.7051) teacher_loss 1.1959 (0.8210) loss_zs_kd 0.4223 (0.4725) loss_oracle 0.3792 (0.3866) acc 68.7500 (78.1424) kd_loss 0.7385 (0.6908) lr 4.6417e-04 eta 0:07:06
epoch [36/50] batch [200/288] time 0.138 (0.104) data 0.000 (0.003) loss 1.8103 (1.7151) teacher_loss 1.0216 (0.8316) loss_zs_kd 0.3894 (0.4719) loss_oracle 0.3708 (0.3845) acc 68.7500 (78.0156) kd_loss 0.6034 (0.6912) lr 4.6417e-04 eta 0:07:09
epoch [36/50] batch [220/288] time 0.111 (0.105) data 0.001 (0.002) loss 1.7645 (1.7075) teacher_loss 0.8579 (0.8272) loss_zs_kd 0.5064 (0.4706) loss_oracle 0.3578 (0.3826) acc 71.8750 (78.0540) kd_loss 0.7277 (0.6891) lr 4.6417e-04 eta 0:07:12
epoch [36/50] batch [240/288] time 0.101 (0.105) data 0.000 (0.002) loss 1.5891 (1.7038) teacher_loss 0.6930 (0.8233) loss_zs_kd 0.4009 (0.4697) loss_oracle 0.3006 (0.3819) acc 75.0000 (78.0729) kd_loss 0.7458 (0.6895) lr 4.6417e-04 eta 0:07:10
epoch [36/50] batch [260/288] time 0.097 (0.105) data 0.000 (0.002) loss 1.5021 (1.6979) teacher_loss 0.5351 (0.8201) loss_zs_kd 0.4664 (0.4673) loss_oracle 0.3678 (0.3816) acc 87.5000 (78.0288) kd_loss 0.7830 (0.6869) lr 4.6417e-04 eta 0:07:06
epoch [36/50] batch [280/288] time 0.105 (0.105) data 0.000 (0.002) loss 1.8499 (1.7016) teacher_loss 0.8206 (0.8237) loss_zs_kd 0.3983 (0.4709) loss_oracle 0.4011 (0.3819) acc 81.2500 (77.9018) kd_loss 0.8288 (0.6870) lr 4.6417e-04 eta 0:07:03
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,449
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,983
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 78.2%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [37/50] batch [20/288] time 0.121 (0.137) data 0.000 (0.017) loss 1.7386 (1.7317) teacher_loss 0.8367 (0.8456) loss_zs_kd 0.4327 (0.5167) loss_oracle 0.3434 (0.3947) acc 71.8750 (78.1250) kd_loss 0.7302 (0.6887) lr 4.1221e-04 eta 0:09:09
epoch [37/50] batch [40/288] time 0.112 (0.125) data 0.000 (0.009) loss 1.7371 (1.7461) teacher_loss 0.8817 (0.8698) loss_zs_kd 0.5362 (0.4876) loss_oracle 0.3823 (0.3844) acc 71.8750 (77.1094) kd_loss 0.6643 (0.6841) lr 4.1221e-04 eta 0:08:17
epoch [37/50] batch [60/288] time 0.095 (0.118) data 0.000 (0.006) loss 1.7077 (1.7331) teacher_loss 0.6794 (0.8570) loss_zs_kd 0.4766 (0.4687) loss_oracle 0.4349 (0.3855) acc 84.3750 (77.1875) kd_loss 0.8108 (0.6833) lr 4.1221e-04 eta 0:07:48
epoch [37/50] batch [80/288] time 0.111 (0.115) data 0.000 (0.005) loss 1.3719 (1.7296) teacher_loss 0.5642 (0.8474) loss_zs_kd 0.3399 (0.4733) loss_oracle 0.4098 (0.3866) acc 87.5000 (77.5000) kd_loss 0.6028 (0.6890) lr 4.1221e-04 eta 0:07:33
epoch [37/50] batch [100/288] time 0.107 (0.112) data 0.000 (0.004) loss 1.5449 (1.7127) teacher_loss 0.7667 (0.8316) loss_zs_kd 0.4099 (0.4745) loss_oracle 0.3253 (0.3852) acc 81.2500 (77.9688) kd_loss 0.6155 (0.6884) lr 4.1221e-04 eta 0:07:21
epoch [37/50] batch [120/288] time 0.100 (0.110) data 0.000 (0.003) loss 2.0858 (1.7323) teacher_loss 1.1785 (0.8467) loss_zs_kd 0.3599 (0.4805) loss_oracle 0.4123 (0.3839) acc 68.7500 (77.3958) kd_loss 0.7012 (0.6936) lr 4.1221e-04 eta 0:07:11
epoch [37/50] batch [140/288] time 0.106 (0.109) data 0.000 (0.003) loss 1.9067 (1.7341) teacher_loss 0.9022 (0.8476) loss_zs_kd 0.3727 (0.4817) loss_oracle 0.3282 (0.3806) acc 78.1250 (77.2321) kd_loss 0.8404 (0.6962) lr 4.1221e-04 eta 0:07:05
epoch [37/50] batch [160/288] time 0.098 (0.109) data 0.000 (0.002) loss 1.8041 (1.7296) teacher_loss 0.8040 (0.8433) loss_zs_kd 0.4428 (0.4856) loss_oracle 0.4397 (0.3821) acc 78.1250 (77.3438) kd_loss 0.7803 (0.6952) lr 4.1221e-04 eta 0:07:00
epoch [37/50] batch [180/288] time 0.100 (0.108) data 0.000 (0.002) loss 1.7720 (1.7211) teacher_loss 0.7586 (0.8319) loss_zs_kd 0.4746 (0.4828) loss_oracle 0.4694 (0.3833) acc 78.1250 (77.6910) kd_loss 0.7787 (0.6976) lr 4.1221e-04 eta 0:06:56
epoch [37/50] batch [200/288] time 0.104 (0.108) data 0.000 (0.002) loss 1.7056 (1.7289) teacher_loss 0.8502 (0.8368) loss_zs_kd 0.4373 (0.4843) loss_oracle 0.3464 (0.3835) acc 78.1250 (77.7812) kd_loss 0.6823 (0.7004) lr 4.1221e-04 eta 0:06:52
epoch [37/50] batch [220/288] time 0.100 (0.107) data 0.000 (0.002) loss 1.8118 (1.7325) teacher_loss 0.9896 (0.8399) loss_zs_kd 0.5819 (0.4824) loss_oracle 0.3520 (0.3849) acc 71.8750 (77.6562) kd_loss 0.6462 (0.7002) lr 4.1221e-04 eta 0:06:49
epoch [37/50] batch [240/288] time 0.104 (0.107) data 0.000 (0.002) loss 1.3700 (1.7323) teacher_loss 0.5864 (0.8400) loss_zs_kd 0.4898 (0.4820) loss_oracle 0.3942 (0.3851) acc 84.3750 (77.5781) kd_loss 0.5865 (0.6996) lr 4.1221e-04 eta 0:06:46
epoch [37/50] batch [260/288] time 0.097 (0.107) data 0.000 (0.002) loss 1.9457 (1.7355) teacher_loss 1.0714 (0.8438) loss_zs_kd 0.5507 (0.4822) loss_oracle 0.3579 (0.3852) acc 78.1250 (77.4760) kd_loss 0.6954 (0.6991) lr 4.1221e-04 eta 0:06:43
epoch [37/50] batch [280/288] time 0.123 (0.107) data 0.000 (0.001) loss 1.5743 (1.7317) teacher_loss 0.6211 (0.8388) loss_zs_kd 0.4950 (0.4844) loss_oracle 0.3883 (0.3850) acc 84.3750 (77.5781) kd_loss 0.7590 (0.7004) lr 4.1221e-04 eta 0:06:42
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,455
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,979
* accuracy: 81.5%
* error: 18.5%
* macro_f1: 77.9%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [38/50] batch [20/288] time 0.113 (0.140) data 0.000 (0.018) loss 1.8525 (1.8324) teacher_loss 1.1104 (0.9253) loss_zs_kd 0.3370 (0.5099) loss_oracle 0.3234 (0.3770) acc 65.6250 (75.0000) kd_loss 0.5804 (0.7186) lr 3.6258e-04 eta 0:08:40
epoch [38/50] batch [40/288] time 0.120 (0.128) data 0.000 (0.009) loss 1.0053 (1.7206) teacher_loss 0.2065 (0.8306) loss_zs_kd 0.7127 (0.5008) loss_oracle 0.3254 (0.3715) acc 93.7500 (77.5781) kd_loss 0.6361 (0.7042) lr 3.6258e-04 eta 0:07:52
epoch [38/50] batch [60/288] time 0.106 (0.121) data 0.000 (0.006) loss 1.4613 (1.7229) teacher_loss 0.6423 (0.8321) loss_zs_kd 0.4973 (0.4989) loss_oracle 0.4052 (0.3726) acc 78.1250 (77.5521) kd_loss 0.6165 (0.7045) lr 3.6258e-04 eta 0:07:24
epoch [38/50] batch [80/288] time 0.097 (0.116) data 0.000 (0.005) loss 1.8661 (1.7353) teacher_loss 1.0374 (0.8435) loss_zs_kd 0.3445 (0.4945) loss_oracle 0.3418 (0.3738) acc 75.0000 (77.2656) kd_loss 0.6578 (0.7049) lr 3.6258e-04 eta 0:07:06
epoch [38/50] batch [100/288] time 0.093 (0.113) data 0.000 (0.004) loss 1.6680 (1.7543) teacher_loss 0.7851 (0.8565) loss_zs_kd 0.4250 (0.4911) loss_oracle 0.3588 (0.3785) acc 84.3750 (77.0938) kd_loss 0.7034 (0.7086) lr 3.6258e-04 eta 0:06:52
epoch [38/50] batch [120/288] time 0.106 (0.112) data 0.000 (0.003) loss 2.1377 (1.7612) teacher_loss 1.3672 (0.8625) loss_zs_kd 0.4924 (0.4883) loss_oracle 0.3710 (0.3787) acc 68.7500 (76.8750) kd_loss 0.5851 (0.7094) lr 3.6258e-04 eta 0:06:44
epoch [38/50] batch [140/288] time 0.102 (0.111) data 0.000 (0.003) loss 1.6798 (1.7696) teacher_loss 0.8205 (0.8696) loss_zs_kd 0.4783 (0.4912) loss_oracle 0.3475 (0.3780) acc 81.2500 (76.6295) kd_loss 0.6855 (0.7109) lr 3.6258e-04 eta 0:06:38
epoch [38/50] batch [160/288] time 0.098 (0.109) data 0.000 (0.002) loss 1.5530 (1.7748) teacher_loss 0.5770 (0.8772) loss_zs_kd 0.3705 (0.4969) loss_oracle 0.4130 (0.3780) acc 87.5000 (76.3477) kd_loss 0.7695 (0.7086) lr 3.6258e-04 eta 0:06:31
epoch [38/50] batch [180/288] time 0.098 (0.109) data 0.000 (0.002) loss 1.8704 (1.7834) teacher_loss 0.8658 (0.8869) loss_zs_kd 0.6802 (0.5040) loss_oracle 0.3425 (0.3782) acc 81.2500 (76.1632) kd_loss 0.8333 (0.7074) lr 3.6258e-04 eta 0:06:28
epoch [38/50] batch [200/288] time 0.092 (0.109) data 0.001 (0.002) loss 1.6044 (1.7720) teacher_loss 0.6708 (0.8755) loss_zs_kd 0.3584 (0.5003) loss_oracle 0.3371 (0.3789) acc 71.8750 (76.5000) kd_loss 0.7651 (0.7071) lr 3.6258e-04 eta 0:06:25
epoch [38/50] batch [220/288] time 0.097 (0.108) data 0.000 (0.002) loss 1.5437 (1.7708) teacher_loss 0.5527 (0.8737) loss_zs_kd 0.4683 (0.4978) loss_oracle 0.3593 (0.3786) acc 84.3750 (76.5625) kd_loss 0.8113 (0.7078) lr 3.6258e-04 eta 0:06:22
epoch [38/50] batch [240/288] time 0.099 (0.109) data 0.000 (0.002) loss 1.3546 (1.7704) teacher_loss 0.3713 (0.8721) loss_zs_kd 0.4031 (0.4979) loss_oracle 0.3858 (0.3792) acc 90.6250 (76.6146) kd_loss 0.7904 (0.7088) lr 3.6258e-04 eta 0:06:21
epoch [38/50] batch [260/288] time 0.097 (0.109) data 0.000 (0.002) loss 1.7359 (1.7722) teacher_loss 0.8478 (0.8697) loss_zs_kd 0.3393 (0.4944) loss_oracle 0.3562 (0.3806) acc 84.3750 (76.7067) kd_loss 0.7100 (0.7121) lr 3.6258e-04 eta 0:06:18
epoch [38/50] batch [280/288] time 0.101 (0.108) data 0.000 (0.002) loss 1.4642 (1.7663) teacher_loss 0.5027 (0.8647) loss_zs_kd 0.4603 (0.4916) loss_oracle 0.3904 (0.3808) acc 84.3750 (76.8080) kd_loss 0.7663 (0.7113) lr 3.6258e-04 eta 0:06:15
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,452
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,980
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 77.9%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [39/50] batch [20/288] time 0.095 (0.112) data 0.001 (0.014) loss 1.7183 (1.7497) teacher_loss 0.8256 (0.8172) loss_zs_kd 0.3873 (0.4544) loss_oracle 0.4398 (0.3979) acc 81.2500 (77.0312) kd_loss 0.6727 (0.7335) lr 3.1545e-04 eta 0:06:23
epoch [39/50] batch [40/288] time 0.099 (0.105) data 0.000 (0.007) loss 1.8086 (1.7431) teacher_loss 0.9865 (0.8398) loss_zs_kd 0.5815 (0.4776) loss_oracle 0.3584 (0.3911) acc 71.8750 (76.7969) kd_loss 0.6429 (0.7077) lr 3.1545e-04 eta 0:05:57
epoch [39/50] batch [60/288] time 0.093 (0.102) data 0.000 (0.005) loss 1.6829 (1.7302) teacher_loss 0.7883 (0.8389) loss_zs_kd 0.3474 (0.4738) loss_oracle 0.4224 (0.3862) acc 81.2500 (76.7188) kd_loss 0.6834 (0.6982) lr 3.1545e-04 eta 0:05:47
epoch [39/50] batch [80/288] time 0.097 (0.101) data 0.000 (0.004) loss 1.9443 (1.7173) teacher_loss 1.1805 (0.8385) loss_zs_kd 0.4173 (0.4699) loss_oracle 0.3529 (0.3797) acc 71.8750 (77.0703) kd_loss 0.5874 (0.6889) lr 3.1545e-04 eta 0:05:42
epoch [39/50] batch [100/288] time 0.098 (0.101) data 0.000 (0.003) loss 1.6302 (1.7191) teacher_loss 0.9918 (0.8497) loss_zs_kd 0.4920 (0.4727) loss_oracle 0.3454 (0.3745) acc 78.1250 (76.8125) kd_loss 0.4657 (0.6822) lr 3.1545e-04 eta 0:05:37
epoch [39/50] batch [120/288] time 0.100 (0.100) data 0.000 (0.002) loss 1.5436 (1.7232) teacher_loss 0.6534 (0.8538) loss_zs_kd 0.3772 (0.4718) loss_oracle 0.3506 (0.3738) acc 84.3750 (76.7188) kd_loss 0.7148 (0.6825) lr 3.1545e-04 eta 0:05:33
epoch [39/50] batch [140/288] time 0.097 (0.100) data 0.000 (0.002) loss 1.8667 (1.7152) teacher_loss 1.0396 (0.8520) loss_zs_kd 0.5483 (0.4809) loss_oracle 0.3718 (0.3742) acc 56.2500 (76.6964) kd_loss 0.6412 (0.6761) lr 3.1545e-04 eta 0:05:30
epoch [39/50] batch [160/288] time 0.092 (0.099) data 0.000 (0.002) loss 1.8793 (1.7055) teacher_loss 1.0335 (0.8495) loss_zs_kd 0.5237 (0.4816) loss_oracle 0.3373 (0.3733) acc 75.0000 (77.0312) kd_loss 0.6772 (0.6694) lr 3.1545e-04 eta 0:05:26
epoch [39/50] batch [180/288] time 0.105 (0.099) data 0.000 (0.002) loss 1.3711 (1.6979) teacher_loss 0.6447 (0.8436) loss_zs_kd 0.4952 (0.4773) loss_oracle 0.3598 (0.3710) acc 81.2500 (76.9965) kd_loss 0.5465 (0.6688) lr 3.1545e-04 eta 0:05:24
epoch [39/50] batch [200/288] time 0.099 (0.099) data 0.000 (0.002) loss 1.7010 (1.7077) teacher_loss 0.7583 (0.8515) loss_zs_kd 0.5068 (0.4786) loss_oracle 0.3925 (0.3705) acc 81.2500 (76.7188) kd_loss 0.7465 (0.6709) lr 3.1545e-04 eta 0:05:21
epoch [39/50] batch [220/288] time 0.098 (0.100) data 0.000 (0.001) loss 1.9740 (1.7057) teacher_loss 1.0991 (0.8509) loss_zs_kd 0.4638 (0.4770) loss_oracle 0.4326 (0.3720) acc 75.0000 (76.8750) kd_loss 0.6587 (0.6688) lr 3.1545e-04 eta 0:05:23
epoch [39/50] batch [240/288] time 0.101 (0.100) data 0.001 (0.001) loss 1.7372 (1.7073) teacher_loss 0.7796 (0.8520) loss_zs_kd 0.5939 (0.4823) loss_oracle 0.3543 (0.3717) acc 71.8750 (76.7448) kd_loss 0.7804 (0.6694) lr 3.1545e-04 eta 0:05:20
epoch [39/50] batch [260/288] time 0.093 (0.100) data 0.000 (0.001) loss 1.2267 (1.7057) teacher_loss 0.4042 (0.8500) loss_zs_kd 0.3675 (0.4803) loss_oracle 0.3627 (0.3720) acc 90.6250 (76.7067) kd_loss 0.6412 (0.6697) lr 3.1545e-04 eta 0:05:18
epoch [39/50] batch [280/288] time 0.114 (0.099) data 0.000 (0.001) loss 1.6018 (1.7023) teacher_loss 0.7833 (0.8471) loss_zs_kd 0.3802 (0.4802) loss_oracle 0.3371 (0.3714) acc 78.1250 (76.8080) kd_loss 0.6499 (0.6695) lr 3.1545e-04 eta 0:05:15
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,453
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,987
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 78.4%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [40/50] batch [20/288] time 0.114 (0.125) data 0.000 (0.019) loss 1.7846 (1.7320) teacher_loss 0.7916 (0.8343) loss_zs_kd 0.4223 (0.4574) loss_oracle 0.4005 (0.3748) acc 81.2500 (76.5625) kd_loss 0.7927 (0.7102) lr 2.7103e-04 eta 0:06:33
epoch [40/50] batch [40/288] time 0.100 (0.114) data 0.001 (0.010) loss 2.2693 (1.7589) teacher_loss 1.1852 (0.8691) loss_zs_kd 0.6665 (0.4865) loss_oracle 0.3875 (0.3774) acc 68.7500 (76.0156) kd_loss 0.8904 (0.7011) lr 2.7103e-04 eta 0:05:57
epoch [40/50] batch [60/288] time 0.103 (0.110) data 0.001 (0.007) loss 1.7001 (1.7354) teacher_loss 0.7174 (0.8535) loss_zs_kd 0.4660 (0.4767) loss_oracle 0.3554 (0.3765) acc 81.2500 (76.6146) kd_loss 0.8050 (0.6936) lr 2.7103e-04 eta 0:05:43
epoch [40/50] batch [80/288] time 0.100 (0.108) data 0.000 (0.005) loss 1.9065 (1.7384) teacher_loss 1.0299 (0.8577) loss_zs_kd 0.5006 (0.4822) loss_oracle 0.3715 (0.3809) acc 71.8750 (76.6406) kd_loss 0.6909 (0.6902) lr 2.7103e-04 eta 0:05:34
epoch [40/50] batch [100/288] time 0.128 (0.108) data 0.000 (0.004) loss 1.5230 (1.7376) teacher_loss 0.7340 (0.8625) loss_zs_kd 0.4329 (0.4784) loss_oracle 0.3603 (0.3799) acc 78.1250 (76.5625) kd_loss 0.6089 (0.6852) lr 2.7103e-04 eta 0:05:31
epoch [40/50] batch [120/288] time 0.095 (0.107) data 0.000 (0.003) loss 1.8406 (1.7341) teacher_loss 0.8904 (0.8594) loss_zs_kd 0.5679 (0.4811) loss_oracle 0.4191 (0.3803) acc 78.1250 (76.6146) kd_loss 0.7406 (0.6845) lr 2.7103e-04 eta 0:05:27
epoch [40/50] batch [140/288] time 0.107 (0.106) data 0.000 (0.003) loss 1.8899 (1.7381) teacher_loss 0.9993 (0.8624) loss_zs_kd 0.4173 (0.4804) loss_oracle 0.3795 (0.3797) acc 71.8750 (76.6518) kd_loss 0.7009 (0.6859) lr 2.7103e-04 eta 0:05:21
epoch [40/50] batch [160/288] time 0.090 (0.105) data 0.000 (0.003) loss 2.0560 (1.7312) teacher_loss 1.2447 (0.8610) loss_zs_kd 0.5775 (0.4837) loss_oracle 0.3858 (0.3798) acc 78.1250 (76.7969) kd_loss 0.6184 (0.6803) lr 2.7103e-04 eta 0:05:16
epoch [40/50] batch [180/288] time 0.095 (0.104) data 0.000 (0.002) loss 1.5824 (1.7442) teacher_loss 0.6469 (0.8690) loss_zs_kd 0.4773 (0.4848) loss_oracle 0.3651 (0.3810) acc 84.3750 (76.7361) kd_loss 0.7530 (0.6847) lr 2.7103e-04 eta 0:05:11
epoch [40/50] batch [200/288] time 0.103 (0.105) data 0.000 (0.002) loss 1.7506 (1.7375) teacher_loss 0.8061 (0.8618) loss_zs_kd 0.6490 (0.4824) loss_oracle 0.3571 (0.3817) acc 65.6250 (76.8438) kd_loss 0.7659 (0.6849) lr 2.7103e-04 eta 0:05:10
epoch [40/50] batch [220/288] time 0.101 (0.104) data 0.000 (0.002) loss 1.7282 (1.7334) teacher_loss 0.8566 (0.8614) loss_zs_kd 0.2766 (0.4832) loss_oracle 0.3471 (0.3819) acc 78.1250 (76.9034) kd_loss 0.6981 (0.6811) lr 2.7103e-04 eta 0:05:06
epoch [40/50] batch [240/288] time 0.103 (0.103) data 0.000 (0.002) loss 1.3112 (1.7241) teacher_loss 0.5055 (0.8529) loss_zs_kd 0.5390 (0.4814) loss_oracle 0.3117 (0.3818) acc 87.5000 (77.1615) kd_loss 0.6499 (0.6802) lr 2.7103e-04 eta 0:05:02
epoch [40/50] batch [260/288] time 0.096 (0.103) data 0.000 (0.002) loss 1.9852 (1.7184) teacher_loss 1.0067 (0.8480) loss_zs_kd 0.5895 (0.4840) loss_oracle 0.3866 (0.3808) acc 65.6250 (77.1995) kd_loss 0.7852 (0.6799) lr 2.7103e-04 eta 0:04:59
epoch [40/50] batch [280/288] time 0.088 (0.102) data 0.000 (0.002) loss 1.8876 (1.7185) teacher_loss 0.9552 (0.8456) loss_zs_kd 0.6049 (0.4829) loss_oracle 0.3804 (0.3801) acc 81.2500 (77.2433) kd_loss 0.7423 (0.6828) lr 2.7103e-04 eta 0:04:55
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,453
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,986
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 78.2%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [41/50] batch [20/288] time 0.108 (0.114) data 0.000 (0.014) loss 1.4817 (1.6922) teacher_loss 0.6116 (0.8189) loss_zs_kd 0.5124 (0.5325) loss_oracle 0.3351 (0.3613) acc 81.2500 (77.5000) kd_loss 0.7025 (0.6927) lr 2.2949e-04 eta 0:05:26
epoch [41/50] batch [40/288] time 0.097 (0.106) data 0.000 (0.007) loss 1.7375 (1.7084) teacher_loss 0.6916 (0.8420) loss_zs_kd 0.5265 (0.4897) loss_oracle 0.3537 (0.3685) acc 75.0000 (77.1094) kd_loss 0.8691 (0.6822) lr 2.2949e-04 eta 0:05:00
epoch [41/50] batch [60/288] time 0.097 (0.103) data 0.000 (0.005) loss 1.8547 (1.7229) teacher_loss 1.1840 (0.8578) loss_zs_kd 0.5017 (0.4755) loss_oracle 0.3631 (0.3716) acc 68.7500 (76.6667) kd_loss 0.4892 (0.6793) lr 2.2949e-04 eta 0:04:51
epoch [41/50] batch [80/288] time 0.104 (0.102) data 0.000 (0.004) loss 1.2179 (1.7249) teacher_loss 0.4428 (0.8577) loss_zs_kd 0.3821 (0.4702) loss_oracle 0.3804 (0.3713) acc 84.3750 (77.0703) kd_loss 0.5849 (0.6816) lr 2.2949e-04 eta 0:04:46
epoch [41/50] batch [100/288] time 0.097 (0.101) data 0.000 (0.003) loss 2.4811 (1.7354) teacher_loss 1.2970 (0.8604) loss_zs_kd 0.6019 (0.4794) loss_oracle 0.4143 (0.3769) acc 65.6250 (76.7812) kd_loss 0.9769 (0.6866) lr 2.2949e-04 eta 0:04:41
epoch [41/50] batch [120/288] time 0.100 (0.100) data 0.000 (0.002) loss 1.9869 (1.7285) teacher_loss 1.1349 (0.8561) loss_zs_kd 0.6571 (0.4807) loss_oracle 0.3842 (0.3776) acc 68.7500 (76.8750) kd_loss 0.6600 (0.6836) lr 2.2949e-04 eta 0:04:36
epoch [41/50] batch [140/288] time 0.101 (0.100) data 0.000 (0.002) loss 1.9289 (1.7285) teacher_loss 1.1477 (0.8506) loss_zs_kd 0.3935 (0.4802) loss_oracle 0.3554 (0.3784) acc 68.7500 (77.0759) kd_loss 0.6035 (0.6886) lr 2.2949e-04 eta 0:04:33
epoch [41/50] batch [160/288] time 0.094 (0.099) data 0.000 (0.002) loss 1.6262 (1.7192) teacher_loss 0.6313 (0.8394) loss_zs_kd 0.2837 (0.4786) loss_oracle 0.4444 (0.3795) acc 84.3750 (77.4414) kd_loss 0.7726 (0.6901) lr 2.2949e-04 eta 0:04:30
epoch [41/50] batch [180/288] time 0.099 (0.100) data 0.000 (0.002) loss 2.6020 (1.7213) teacher_loss 1.6695 (0.8398) loss_zs_kd 0.8646 (0.4826) loss_oracle 0.4236 (0.3800) acc 62.5000 (77.4132) kd_loss 0.7207 (0.6915) lr 2.2949e-04 eta 0:04:30
epoch [41/50] batch [200/288] time 0.098 (0.100) data 0.000 (0.002) loss 1.8979 (1.7252) teacher_loss 0.9334 (0.8403) loss_zs_kd 0.4648 (0.4853) loss_oracle 0.4164 (0.3823) acc 75.0000 (77.3750) kd_loss 0.7563 (0.6938) lr 2.2949e-04 eta 0:04:28
epoch [41/50] batch [220/288] time 0.099 (0.100) data 0.000 (0.001) loss 1.6494 (1.7241) teacher_loss 0.8860 (0.8383) loss_zs_kd 0.6136 (0.4890) loss_oracle 0.3415 (0.3826) acc 81.2500 (77.4432) kd_loss 0.5926 (0.6945) lr 2.2949e-04 eta 0:04:26
epoch [41/50] batch [240/288] time 0.098 (0.100) data 0.000 (0.001) loss 1.7004 (1.7220) teacher_loss 0.8488 (0.8401) loss_zs_kd 0.6314 (0.4853) loss_oracle 0.3755 (0.3813) acc 81.2500 (77.4089) kd_loss 0.6639 (0.6912) lr 2.2949e-04 eta 0:04:24
epoch [41/50] batch [260/288] time 0.095 (0.100) data 0.000 (0.001) loss 2.1442 (1.7221) teacher_loss 1.3805 (0.8425) loss_zs_kd 0.5024 (0.4857) loss_oracle 0.3867 (0.3799) acc 62.5000 (77.3438) kd_loss 0.5703 (0.6897) lr 2.2949e-04 eta 0:04:22
epoch [41/50] batch [280/288] time 0.106 (0.100) data 0.000 (0.001) loss 1.8363 (1.7175) teacher_loss 0.8002 (0.8419) loss_zs_kd 0.4802 (0.4850) loss_oracle 0.4364 (0.3788) acc 81.2500 (77.4107) kd_loss 0.8179 (0.6862) lr 2.2949e-04 eta 0:04:20
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,457
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,989
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 78.3%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [42/50] batch [20/288] time 0.108 (0.121) data 0.000 (0.013) loss 1.5943 (1.6163) teacher_loss 0.7808 (0.8111) loss_zs_kd 0.3827 (0.4524) loss_oracle 0.3418 (0.3645) acc 75.0000 (78.5938) kd_loss 0.6426 (0.6229) lr 1.9098e-04 eta 0:05:10
epoch [42/50] batch [40/288] time 0.101 (0.112) data 0.000 (0.006) loss 1.7013 (1.6492) teacher_loss 0.8061 (0.8308) loss_zs_kd 0.4105 (0.4639) loss_oracle 0.4016 (0.3732) acc 81.2500 (78.6719) kd_loss 0.6944 (0.6317) lr 1.9098e-04 eta 0:04:45
epoch [42/50] batch [60/288] time 0.099 (0.108) data 0.001 (0.004) loss 2.0372 (1.6855) teacher_loss 1.2036 (0.8527) loss_zs_kd 0.4659 (0.4863) loss_oracle 0.3427 (0.3739) acc 71.8750 (77.8646) kd_loss 0.6622 (0.6459) lr 1.9098e-04 eta 0:04:34
epoch [42/50] batch [80/288] time 0.099 (0.107) data 0.000 (0.003) loss 1.4973 (1.6855) teacher_loss 0.5556 (0.8384) loss_zs_kd 0.5427 (0.4863) loss_oracle 0.3766 (0.3721) acc 84.3750 (77.6172) kd_loss 0.7535 (0.6610) lr 1.9098e-04 eta 0:04:28
epoch [42/50] batch [100/288] time 0.111 (0.106) data 0.000 (0.003) loss 1.6474 (1.6990) teacher_loss 0.8270 (0.8515) loss_zs_kd 0.5127 (0.4885) loss_oracle 0.3385 (0.3729) acc 78.1250 (77.3750) kd_loss 0.6512 (0.6611) lr 1.9098e-04 eta 0:04:25
epoch [42/50] batch [120/288] time 0.097 (0.106) data 0.000 (0.002) loss 1.5767 (1.6797) teacher_loss 0.5260 (0.8277) loss_zs_kd 0.4996 (0.4806) loss_oracle 0.4278 (0.3709) acc 81.2500 (77.9427) kd_loss 0.8367 (0.6665) lr 1.9098e-04 eta 0:04:21
epoch [42/50] batch [140/288] time 0.130 (0.106) data 0.000 (0.002) loss 2.0152 (1.6827) teacher_loss 1.0934 (0.8285) loss_zs_kd 0.4938 (0.4856) loss_oracle 0.3279 (0.3716) acc 65.6250 (77.7455) kd_loss 0.7578 (0.6683) lr 1.9098e-04 eta 0:04:20
epoch [42/50] batch [160/288] time 0.093 (0.106) data 0.000 (0.002) loss 1.8271 (1.6851) teacher_loss 1.0114 (0.8296) loss_zs_kd 0.5465 (0.4890) loss_oracle 0.3397 (0.3699) acc 71.8750 (77.6953) kd_loss 0.6458 (0.6705) lr 1.9098e-04 eta 0:04:16
epoch [42/50] batch [180/288] time 0.101 (0.105) data 0.000 (0.002) loss 1.6528 (1.6816) teacher_loss 0.8860 (0.8263) loss_zs_kd 0.6707 (0.4913) loss_oracle 0.3571 (0.3701) acc 78.1250 (77.7951) kd_loss 0.5882 (0.6703) lr 1.9098e-04 eta 0:04:12
epoch [42/50] batch [200/288] time 0.093 (0.104) data 0.000 (0.002) loss 1.9281 (1.6846) teacher_loss 0.8827 (0.8278) loss_zs_kd 0.3848 (0.4907) loss_oracle 0.3568 (0.3701) acc 75.0000 (77.8438) kd_loss 0.8670 (0.6718) lr 1.9098e-04 eta 0:04:08
epoch [42/50] batch [220/288] time 0.095 (0.103) data 0.000 (0.001) loss 1.5370 (1.6889) teacher_loss 0.9238 (0.8330) loss_zs_kd 0.4175 (0.4909) loss_oracle 0.3472 (0.3692) acc 81.2500 (77.7273) kd_loss 0.4396 (0.6713) lr 1.9098e-04 eta 0:04:04
epoch [42/50] batch [240/288] time 0.106 (0.102) data 0.000 (0.001) loss 1.6833 (1.6895) teacher_loss 0.8772 (0.8321) loss_zs_kd 0.4635 (0.4879) loss_oracle 0.3669 (0.3699) acc 81.2500 (77.8125) kd_loss 0.6227 (0.6724) lr 1.9098e-04 eta 0:04:01
epoch [42/50] batch [260/288] time 0.100 (0.102) data 0.001 (0.001) loss 2.1613 (1.7001) teacher_loss 1.1283 (0.8387) loss_zs_kd 0.5915 (0.4882) loss_oracle 0.4128 (0.3707) acc 71.8750 (77.6562) kd_loss 0.8267 (0.6760) lr 1.9098e-04 eta 0:03:58
epoch [42/50] batch [280/288] time 0.106 (0.102) data 0.000 (0.001) loss 1.7848 (1.6978) teacher_loss 0.7323 (0.8348) loss_zs_kd 0.3558 (0.4854) loss_oracle 0.3448 (0.3707) acc 78.1250 (77.7121) kd_loss 0.8801 (0.6777) lr 1.9098e-04 eta 0:03:56
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,457
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,991
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 78.6%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [43/50] batch [20/288] time 0.107 (0.134) data 0.000 (0.019) loss 2.0122 (1.7927) teacher_loss 1.0267 (0.8801) loss_zs_kd 0.4945 (0.4971) loss_oracle 0.3896 (0.3690) acc 75.0000 (76.5625) kd_loss 0.7906 (0.7281) lr 1.5567e-04 eta 0:05:05
epoch [43/50] batch [40/288] time 0.096 (0.122) data 0.000 (0.010) loss 1.8921 (1.7527) teacher_loss 0.9969 (0.8789) loss_zs_kd 0.4848 (0.4912) loss_oracle 0.3642 (0.3713) acc 75.0000 (76.4062) kd_loss 0.7131 (0.6881) lr 1.5567e-04 eta 0:04:35
epoch [43/50] batch [60/288] time 0.096 (0.115) data 0.000 (0.007) loss 2.5503 (1.7808) teacher_loss 1.6316 (0.8995) loss_zs_kd 0.5452 (0.5007) loss_oracle 0.3217 (0.3707) acc 62.5000 (75.8333) kd_loss 0.7579 (0.6959) lr 1.5567e-04 eta 0:04:17
epoch [43/50] batch [80/288] time 0.098 (0.111) data 0.000 (0.005) loss 1.3034 (1.7413) teacher_loss 0.4654 (0.8545) loss_zs_kd 0.2382 (0.4788) loss_oracle 0.3464 (0.3700) acc 87.5000 (77.1484) kd_loss 0.6648 (0.7017) lr 1.5567e-04 eta 0:04:07
epoch [43/50] batch [100/288] time 0.112 (0.109) data 0.000 (0.004) loss 1.6836 (1.7453) teacher_loss 1.1375 (0.8584) loss_zs_kd 0.6089 (0.4730) loss_oracle 0.3079 (0.3726) acc 65.6250 (76.9062) kd_loss 0.3922 (0.7006) lr 1.5567e-04 eta 0:04:01
epoch [43/50] batch [120/288] time 0.098 (0.110) data 0.000 (0.003) loss 1.5474 (1.7376) teacher_loss 0.6776 (0.8553) loss_zs_kd 0.3743 (0.4796) loss_oracle 0.3847 (0.3740) acc 81.2500 (77.0052) kd_loss 0.6774 (0.6953) lr 1.5567e-04 eta 0:04:00
epoch [43/50] batch [140/288] time 0.101 (0.109) data 0.000 (0.003) loss 1.2792 (1.7312) teacher_loss 0.6034 (0.8532) loss_zs_kd 0.5060 (0.4828) loss_oracle 0.3525 (0.3750) acc 87.5000 (76.9866) kd_loss 0.4995 (0.6905) lr 1.5567e-04 eta 0:03:55
epoch [43/50] batch [160/288] time 0.100 (0.108) data 0.000 (0.003) loss 1.7704 (1.7230) teacher_loss 0.9447 (0.8483) loss_zs_kd 0.4185 (0.4842) loss_oracle 0.3798 (0.3746) acc 75.0000 (77.1484) kd_loss 0.6359 (0.6874) lr 1.5567e-04 eta 0:03:50
epoch [43/50] batch [180/288] time 0.104 (0.107) data 0.000 (0.002) loss 1.4359 (1.7138) teacher_loss 0.7065 (0.8406) loss_zs_kd 0.3724 (0.4801) loss_oracle 0.3175 (0.3740) acc 84.3750 (77.3264) kd_loss 0.5706 (0.6862) lr 1.5567e-04 eta 0:03:46
epoch [43/50] batch [200/288] time 0.098 (0.106) data 0.000 (0.002) loss 1.4072 (1.7136) teacher_loss 0.7110 (0.8443) loss_zs_kd 0.5311 (0.4802) loss_oracle 0.3634 (0.3742) acc 84.3750 (77.2031) kd_loss 0.5145 (0.6823) lr 1.5567e-04 eta 0:03:42
epoch [43/50] batch [220/288] time 0.097 (0.105) data 0.000 (0.002) loss 1.6299 (1.7129) teacher_loss 0.8455 (0.8437) loss_zs_kd 0.5902 (0.4807) loss_oracle 0.3669 (0.3734) acc 78.1250 (77.3295) kd_loss 0.6010 (0.6826) lr 1.5567e-04 eta 0:03:38
epoch [43/50] batch [240/288] time 0.094 (0.104) data 0.000 (0.002) loss 1.5089 (1.7059) teacher_loss 0.6936 (0.8373) loss_zs_kd 0.7140 (0.4799) loss_oracle 0.4294 (0.3737) acc 90.6250 (77.3958) kd_loss 0.6006 (0.6818) lr 1.5567e-04 eta 0:03:35
epoch [43/50] batch [260/288] time 0.092 (0.104) data 0.000 (0.002) loss 1.7589 (1.7023) teacher_loss 0.7600 (0.8366) loss_zs_kd 0.5560 (0.4810) loss_oracle 0.4024 (0.3731) acc 81.2500 (77.4399) kd_loss 0.7976 (0.6792) lr 1.5567e-04 eta 0:03:31
epoch [43/50] batch [280/288] time 0.089 (0.103) data 0.000 (0.002) loss 1.9065 (1.7056) teacher_loss 0.8968 (0.8390) loss_zs_kd 0.4625 (0.4814) loss_oracle 0.3807 (0.3735) acc 84.3750 (77.4665) kd_loss 0.8194 (0.6798) lr 1.5567e-04 eta 0:03:27
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,460
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,987
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 78.4%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [44/50] batch [20/288] time 0.108 (0.124) data 0.000 (0.017) loss 1.8508 (1.7020) teacher_loss 1.0934 (0.8475) loss_zs_kd 0.4391 (0.4802) loss_oracle 0.3916 (0.3820) acc 68.7500 (77.8125) kd_loss 0.5615 (0.6636) lr 1.2369e-04 eta 0:04:07
epoch [44/50] batch [40/288] time 0.110 (0.114) data 0.000 (0.009) loss 1.6243 (1.7388) teacher_loss 0.5934 (0.8833) loss_zs_kd 0.4142 (0.4803) loss_oracle 0.3955 (0.3722) acc 81.2500 (76.7188) kd_loss 0.8331 (0.6694) lr 1.2369e-04 eta 0:03:46
epoch [44/50] batch [60/288] time 0.115 (0.111) data 0.000 (0.006) loss 1.5209 (1.7147) teacher_loss 0.6737 (0.8642) loss_zs_kd 0.3200 (0.4907) loss_oracle 0.3848 (0.3746) acc 84.3750 (77.2396) kd_loss 0.6548 (0.6631) lr 1.2369e-04 eta 0:03:37
epoch [44/50] batch [80/288] time 0.092 (0.108) data 0.000 (0.004) loss 1.8837 (1.7063) teacher_loss 0.9668 (0.8569) loss_zs_kd 0.6454 (0.4891) loss_oracle 0.4389 (0.3738) acc 75.0000 (76.8359) kd_loss 0.6975 (0.6624) lr 1.2369e-04 eta 0:03:29
epoch [44/50] batch [100/288] time 0.099 (0.108) data 0.000 (0.004) loss 1.7596 (1.7015) teacher_loss 0.8948 (0.8515) loss_zs_kd 0.4431 (0.4872) loss_oracle 0.4158 (0.3749) acc 71.8750 (76.9688) kd_loss 0.6569 (0.6626) lr 1.2369e-04 eta 0:03:26
epoch [44/50] batch [120/288] time 0.110 (0.107) data 0.000 (0.003) loss 1.8341 (1.6997) teacher_loss 0.9059 (0.8437) loss_zs_kd 0.5804 (0.4827) loss_oracle 0.4025 (0.3768) acc 68.7500 (77.2396) kd_loss 0.7270 (0.6676) lr 1.2369e-04 eta 0:03:22
epoch [44/50] batch [140/288] time 0.103 (0.106) data 0.000 (0.003) loss 1.8751 (1.7058) teacher_loss 0.8712 (0.8446) loss_zs_kd 0.5146 (0.4832) loss_oracle 0.3756 (0.3762) acc 75.0000 (77.2768) kd_loss 0.8161 (0.6731) lr 1.2369e-04 eta 0:03:19
epoch [44/50] batch [160/288] time 0.094 (0.105) data 0.000 (0.002) loss 1.8533 (1.7093) teacher_loss 1.0172 (0.8520) loss_zs_kd 0.5144 (0.4873) loss_oracle 0.3603 (0.3746) acc 71.8750 (77.1094) kd_loss 0.6559 (0.6701) lr 1.2369e-04 eta 0:03:15
epoch [44/50] batch [180/288] time 0.093 (0.104) data 0.000 (0.002) loss 1.7008 (1.7168) teacher_loss 0.6078 (0.8575) loss_zs_kd 0.4297 (0.4877) loss_oracle 0.4134 (0.3753) acc 81.2500 (77.0660) kd_loss 0.8863 (0.6716) lr 1.2369e-04 eta 0:03:11
epoch [44/50] batch [200/288] time 0.094 (0.104) data 0.000 (0.002) loss 1.4811 (1.7176) teacher_loss 0.6100 (0.8541) loss_zs_kd 0.4677 (0.4921) loss_oracle 0.4360 (0.3755) acc 81.2500 (77.1250) kd_loss 0.6531 (0.6757) lr 1.2369e-04 eta 0:03:08
epoch [44/50] batch [220/288] time 0.107 (0.103) data 0.000 (0.002) loss 1.9975 (1.7183) teacher_loss 0.9905 (0.8550) loss_zs_kd 0.4880 (0.4915) loss_oracle 0.4139 (0.3756) acc 78.1250 (77.0312) kd_loss 0.8000 (0.6755) lr 1.2369e-04 eta 0:03:05
epoch [44/50] batch [240/288] time 0.097 (0.103) data 0.000 (0.002) loss 1.7590 (1.7282) teacher_loss 0.9097 (0.8658) loss_zs_kd 0.5037 (0.4915) loss_oracle 0.3533 (0.3759) acc 78.1250 (76.7839) kd_loss 0.6727 (0.6745) lr 1.2369e-04 eta 0:03:02
epoch [44/50] batch [260/288] time 0.107 (0.102) data 0.001 (0.002) loss 2.3127 (1.7262) teacher_loss 1.3897 (0.8641) loss_zs_kd 0.4284 (0.4891) loss_oracle 0.3317 (0.3754) acc 68.7500 (76.6827) kd_loss 0.7571 (0.6744) lr 1.2369e-04 eta 0:02:59
epoch [44/50] batch [280/288] time 0.088 (0.102) data 0.000 (0.001) loss 2.0787 (1.7237) teacher_loss 1.1807 (0.8620) loss_zs_kd 0.3826 (0.4899) loss_oracle 0.3744 (0.3756) acc 65.6250 (76.6406) kd_loss 0.7107 (0.6738) lr 1.2369e-04 eta 0:02:56
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,459
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,990
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 78.6%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [45/50] batch [20/288] time 0.101 (0.117) data 0.000 (0.015) loss 2.0330 (1.7193) teacher_loss 1.1567 (0.8539) loss_zs_kd 0.3453 (0.4914) loss_oracle 0.3500 (0.3768) acc 62.5000 (77.0312) kd_loss 0.7013 (0.6770) lr 9.5173e-05 eta 0:03:19
epoch [45/50] batch [40/288] time 0.096 (0.107) data 0.000 (0.008) loss 1.4483 (1.6688) teacher_loss 0.5936 (0.7908) loss_zs_kd 0.2525 (0.4851) loss_oracle 0.3882 (0.3818) acc 71.8750 (78.1250) kd_loss 0.6606 (0.6871) lr 9.5173e-05 eta 0:02:59
epoch [45/50] batch [60/288] time 0.095 (0.103) data 0.000 (0.005) loss 1.3889 (1.6659) teacher_loss 0.4203 (0.7998) loss_zs_kd 0.4948 (0.4735) loss_oracle 0.3974 (0.3783) acc 90.6250 (78.2812) kd_loss 0.7699 (0.6770) lr 9.5173e-05 eta 0:02:51
epoch [45/50] batch [80/288] time 0.094 (0.105) data 0.000 (0.004) loss 1.3299 (1.6649) teacher_loss 0.6150 (0.8087) loss_zs_kd 0.3469 (0.4668) loss_oracle 0.3690 (0.3780) acc 84.3750 (77.8906) kd_loss 0.5305 (0.6672) lr 9.5173e-05 eta 0:02:53
epoch [45/50] batch [100/288] time 0.097 (0.104) data 0.000 (0.003) loss 2.2480 (1.6603) teacher_loss 1.3914 (0.8077) loss_zs_kd 0.4759 (0.4679) loss_oracle 0.3076 (0.3741) acc 62.5000 (78.0000) kd_loss 0.7029 (0.6656) lr 9.5173e-05 eta 0:02:48
epoch [45/50] batch [120/288] time 0.095 (0.103) data 0.000 (0.003) loss 1.4699 (1.6734) teacher_loss 0.7094 (0.8168) loss_zs_kd 0.4150 (0.4736) loss_oracle 0.3514 (0.3738) acc 87.5000 (77.7865) kd_loss 0.5849 (0.6697) lr 9.5173e-05 eta 0:02:44
epoch [45/50] batch [140/288] time 0.095 (0.102) data 0.000 (0.002) loss 1.0548 (1.6733) teacher_loss 0.1995 (0.8186) loss_zs_kd 0.4744 (0.4745) loss_oracle 0.2854 (0.3719) acc 93.7500 (77.8125) kd_loss 0.7126 (0.6688) lr 9.5173e-05 eta 0:02:41
epoch [45/50] batch [160/288] time 0.091 (0.101) data 0.000 (0.002) loss 1.6386 (1.6767) teacher_loss 0.7997 (0.8199) loss_zs_kd 0.5215 (0.4773) loss_oracle 0.4020 (0.3726) acc 84.3750 (77.7539) kd_loss 0.6378 (0.6705) lr 9.5173e-05 eta 0:02:38
epoch [45/50] batch [180/288] time 0.092 (0.101) data 0.000 (0.002) loss 1.6934 (1.6782) teacher_loss 0.8444 (0.8222) loss_zs_kd 0.6395 (0.4792) loss_oracle 0.3631 (0.3731) acc 81.2500 (77.5347) kd_loss 0.6674 (0.6695) lr 9.5173e-05 eta 0:02:35
epoch [45/50] batch [200/288] time 0.099 (0.100) data 0.000 (0.002) loss 1.5159 (1.6828) teacher_loss 0.5136 (0.8260) loss_zs_kd 0.3631 (0.4796) loss_oracle 0.3741 (0.3713) acc 87.5000 (77.6406) kd_loss 0.8153 (0.6711) lr 9.5173e-05 eta 0:02:33
epoch [45/50] batch [220/288] time 0.093 (0.100) data 0.000 (0.002) loss 1.5580 (1.6802) teacher_loss 0.6270 (0.8222) loss_zs_kd 0.5903 (0.4797) loss_oracle 0.3618 (0.3706) acc 81.2500 (77.7557) kd_loss 0.7500 (0.6727) lr 9.5173e-05 eta 0:02:31
epoch [45/50] batch [240/288] time 0.099 (0.100) data 0.000 (0.001) loss 1.5689 (1.6754) teacher_loss 0.7119 (0.8132) loss_zs_kd 0.4311 (0.4778) loss_oracle 0.3385 (0.3716) acc 78.1250 (78.1641) kd_loss 0.6878 (0.6764) lr 9.5173e-05 eta 0:02:28
epoch [45/50] batch [260/288] time 0.099 (0.099) data 0.000 (0.001) loss 1.6389 (1.6747) teacher_loss 0.9963 (0.8117) loss_zs_kd 0.6589 (0.4799) loss_oracle 0.3247 (0.3718) acc 71.8750 (78.2212) kd_loss 0.4802 (0.6771) lr 9.5173e-05 eta 0:02:26
epoch [45/50] batch [280/288] time 0.090 (0.099) data 0.000 (0.001) loss 1.6708 (1.6887) teacher_loss 0.8381 (0.8212) loss_zs_kd 0.5734 (0.4818) loss_oracle 0.3812 (0.3729) acc 81.2500 (77.9353) kd_loss 0.6421 (0.6811) lr 9.5173e-05 eta 0:02:23
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,459
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,989
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 78.5%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [46/50] batch [20/288] time 0.103 (0.124) data 0.001 (0.015) loss 1.4564 (1.6946) teacher_loss 0.6931 (0.8282) loss_zs_kd 0.4313 (0.4628) loss_oracle 0.3875 (0.3643) acc 84.3750 (77.8125) kd_loss 0.5695 (0.6843) lr 7.0224e-05 eta 0:02:56
epoch [46/50] batch [40/288] time 0.104 (0.114) data 0.000 (0.008) loss 1.8106 (1.7324) teacher_loss 1.1665 (0.8615) loss_zs_kd 0.4972 (0.4895) loss_oracle 0.3466 (0.3723) acc 68.7500 (77.6562) kd_loss 0.4708 (0.6848) lr 7.0224e-05 eta 0:02:39
epoch [46/50] batch [60/288] time 0.111 (0.115) data 0.000 (0.005) loss 1.6903 (1.7393) teacher_loss 0.7202 (0.8625) loss_zs_kd 0.4773 (0.5069) loss_oracle 0.3517 (0.3672) acc 81.2500 (76.7188) kd_loss 0.7942 (0.6931) lr 7.0224e-05 eta 0:02:39
epoch [46/50] batch [80/288] time 0.101 (0.113) data 0.000 (0.004) loss 1.6254 (1.7290) teacher_loss 0.7797 (0.8437) loss_zs_kd 0.3879 (0.4929) loss_oracle 0.4206 (0.3694) acc 81.2500 (77.0703) kd_loss 0.6354 (0.7006) lr 7.0224e-05 eta 0:02:33
epoch [46/50] batch [100/288] time 0.111 (0.111) data 0.000 (0.003) loss 1.4964 (1.7087) teacher_loss 0.6781 (0.8348) loss_zs_kd 0.5703 (0.4909) loss_oracle 0.3485 (0.3690) acc 84.3750 (77.3750) kd_loss 0.6440 (0.6894) lr 7.0224e-05 eta 0:02:28
epoch [46/50] batch [120/288] time 0.097 (0.109) data 0.000 (0.003) loss 1.2598 (1.7052) teacher_loss 0.4307 (0.8364) loss_zs_kd 0.4870 (0.4932) loss_oracle 0.3816 (0.3661) acc 87.5000 (77.2656) kd_loss 0.6382 (0.6858) lr 7.0224e-05 eta 0:02:24
epoch [46/50] batch [140/288] time 0.100 (0.108) data 0.000 (0.002) loss 1.6418 (1.7110) teacher_loss 0.8276 (0.8397) loss_zs_kd 0.4762 (0.4896) loss_oracle 0.3495 (0.3677) acc 75.0000 (77.2768) kd_loss 0.6394 (0.6874) lr 7.0224e-05 eta 0:02:20
epoch [46/50] batch [160/288] time 0.109 (0.108) data 0.000 (0.002) loss 1.5884 (1.7055) teacher_loss 0.7042 (0.8350) loss_zs_kd 0.6037 (0.4887) loss_oracle 0.4214 (0.3683) acc 81.2500 (77.3047) kd_loss 0.6735 (0.6864) lr 7.0224e-05 eta 0:02:17
epoch [46/50] batch [180/288] time 0.101 (0.107) data 0.000 (0.002) loss 1.6386 (1.7201) teacher_loss 0.9012 (0.8435) loss_zs_kd 0.5645 (0.4893) loss_oracle 0.3463 (0.3699) acc 78.1250 (77.1875) kd_loss 0.5642 (0.6916) lr 7.0224e-05 eta 0:02:14
epoch [46/50] batch [200/288] time 0.101 (0.107) data 0.000 (0.002) loss 1.9903 (1.7280) teacher_loss 1.1167 (0.8520) loss_zs_kd 0.3040 (0.4876) loss_oracle 0.3358 (0.3697) acc 71.8750 (76.9531) kd_loss 0.7057 (0.6912) lr 7.0224e-05 eta 0:02:12
epoch [46/50] batch [220/288] time 0.102 (0.106) data 0.000 (0.002) loss 1.7862 (1.7287) teacher_loss 0.8019 (0.8521) loss_zs_kd 0.3695 (0.4849) loss_oracle 0.3488 (0.3696) acc 75.0000 (76.8892) kd_loss 0.8098 (0.6917) lr 7.0224e-05 eta 0:02:09
epoch [46/50] batch [240/288] time 0.100 (0.106) data 0.000 (0.002) loss 1.7441 (1.7287) teacher_loss 0.7312 (0.8513) loss_zs_kd 0.5060 (0.4873) loss_oracle 0.3611 (0.3702) acc 78.1250 (76.8490) kd_loss 0.8323 (0.6923) lr 7.0224e-05 eta 0:02:06
epoch [46/50] batch [260/288] time 0.098 (0.106) data 0.000 (0.001) loss 1.6386 (1.7248) teacher_loss 0.7288 (0.8476) loss_zs_kd 0.3513 (0.4878) loss_oracle 0.3796 (0.3711) acc 84.3750 (76.8750) kd_loss 0.7200 (0.6916) lr 7.0224e-05 eta 0:02:04
epoch [46/50] batch [280/288] time 0.106 (0.105) data 0.000 (0.001) loss 2.1233 (1.7263) teacher_loss 1.1657 (0.8479) loss_zs_kd 0.4731 (0.4888) loss_oracle 0.3161 (0.3712) acc 65.6250 (76.9754) kd_loss 0.7995 (0.6928) lr 7.0224e-05 eta 0:02:02
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,459
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,986
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 78.4%
******* Domain a best val acc:      87.9%, epoch: 30 *******
******* Domain a best val test acc: 82.1%, epoch: 30 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [47/50] batch [20/288] time 0.106 (0.127) data 0.000 (0.020) loss 2.0185 (1.7277) teacher_loss 1.0774 (0.8649) loss_zs_kd 0.4385 (0.4898) loss_oracle 0.3620 (0.3631) acc 71.8750 (77.3438) kd_loss 0.7601 (0.6813) lr 4.8943e-05 eta 0:02:24
epoch [47/50] batch [40/288] time 0.099 (0.121) data 0.000 (0.010) loss 1.9319 (1.7321) teacher_loss 1.0670 (0.8565) loss_zs_kd 0.4105 (0.4639) loss_oracle 0.3632 (0.3686) acc 75.0000 (77.0312) kd_loss 0.6833 (0.6913) lr 4.8943e-05 eta 0:02:14
epoch [47/50] batch [60/288] time 0.108 (0.115) data 0.000 (0.007) loss 2.4483 (1.7301) teacher_loss 1.6298 (0.8633) loss_zs_kd 0.4228 (0.4631) loss_oracle 0.3901 (0.3694) acc 68.7500 (77.0833) kd_loss 0.6235 (0.6821) lr 4.8943e-05 eta 0:02:05
epoch [47/50] batch [80/288] time 0.098 (0.112) data 0.000 (0.005) loss 1.8584 (1.7275) teacher_loss 0.8846 (0.8551) loss_zs_kd 0.3880 (0.4735) loss_oracle 0.3551 (0.3719) acc 71.8750 (77.1484) kd_loss 0.7963 (0.6865) lr 4.8943e-05 eta 0:02:00
epoch [47/50] batch [100/288] time 0.101 (0.110) data 0.000 (0.004) loss 1.6149 (1.7066) teacher_loss 0.5560 (0.8423) loss_zs_kd 0.3459 (0.4767) loss_oracle 0.4212 (0.3707) acc 81.2500 (77.0938) kd_loss 0.8484 (0.6789) lr 4.8943e-05 eta 0:01:55
epoch [47/50] batch [120/288] time 0.097 (0.109) data 0.000 (0.004) loss 1.9028 (1.6940) teacher_loss 1.1851 (0.8304) loss_zs_kd 0.3584 (0.4789) loss_oracle 0.3307 (0.3704) acc 68.7500 (77.2396) kd_loss 0.5524 (0.6784) lr 4.8943e-05 eta 0:01:52
epoch [47/50] batch [140/288] time 0.100 (0.108) data 0.000 (0.003) loss 1.6202 (1.7012) teacher_loss 0.7002 (0.8354) loss_zs_kd 0.7167 (0.4848) loss_oracle 0.4024 (0.3691) acc 75.0000 (77.0536) kd_loss 0.7188 (0.6813) lr 4.8943e-05 eta 0:01:49
epoch [47/50] batch [160/288] time 0.096 (0.107) data 0.000 (0.003) loss 1.8234 (1.7097) teacher_loss 0.8373 (0.8413) loss_zs_kd 0.7868 (0.4897) loss_oracle 0.3639 (0.3700) acc 75.0000 (76.8750) kd_loss 0.8042 (0.6834) lr 4.8943e-05 eta 0:01:45
epoch [47/50] batch [180/288] time 0.100 (0.106) data 0.000 (0.002) loss 1.7098 (1.7140) teacher_loss 0.7932 (0.8424) loss_zs_kd 0.4184 (0.4911) loss_oracle 0.3608 (0.3694) acc 71.8750 (76.6667) kd_loss 0.7363 (0.6869) lr 4.8943e-05 eta 0:01:43
epoch [47/50] batch [200/288] time 0.111 (0.106) data 0.000 (0.002) loss 1.0813 (1.7212) teacher_loss 0.3089 (0.8440) loss_zs_kd 0.3531 (0.4868) loss_oracle 0.3874 (0.3694) acc 84.3750 (76.6875) kd_loss 0.5787 (0.6925) lr 4.8943e-05 eta 0:01:40
epoch [47/50] batch [220/288] time 0.098 (0.105) data 0.000 (0.002) loss 1.6050 (1.7248) teacher_loss 0.6773 (0.8480) loss_zs_kd 0.4384 (0.4880) loss_oracle 0.3591 (0.3694) acc 75.0000 (76.6477) kd_loss 0.7481 (0.6922) lr 4.8943e-05 eta 0:01:38
epoch [47/50] batch [240/288] time 0.100 (0.105) data 0.000 (0.002) loss 1.4215 (1.7218) teacher_loss 0.5738 (0.8459) loss_zs_kd 0.4035 (0.4877) loss_oracle 0.3671 (0.3698) acc 87.5000 (76.8099) kd_loss 0.6642 (0.6910) lr 4.8943e-05 eta 0:01:35
epoch [47/50] batch [260/288] time 0.098 (0.105) data 0.000 (0.002) loss 2.1569 (1.7213) teacher_loss 1.2110 (0.8457) loss_zs_kd 0.6680 (0.4888) loss_oracle 0.4186 (0.3706) acc 68.7500 (76.8389) kd_loss 0.7365 (0.6903) lr 4.8943e-05 eta 0:01:33
epoch [47/50] batch [280/288] time 0.086 (0.104) data 0.000 (0.002) loss 1.2849 (1.7239) teacher_loss 0.3661 (0.8482) loss_zs_kd 0.4396 (0.4900) loss_oracle 0.3892 (0.3707) acc 90.6250 (76.8638) kd_loss 0.7242 (0.6903) lr 4.8943e-05 eta 0:01:30
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,462
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 87.4%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,986
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 78.4%
******* Domain a best val acc:      87.9%, epoch: 47 *******
******* Domain a best val test acc: 81.8%, epoch: 47 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [48/50] batch [20/288] time 0.091 (0.114) data 0.000 (0.014) loss 1.6615 (1.7734) teacher_loss 0.8734 (0.9342) loss_zs_kd 0.4766 (0.5145) loss_oracle 0.3543 (0.3732) acc 68.7500 (73.7500) kd_loss 0.6110 (0.6526) lr 3.1417e-05 eta 0:01:36
epoch [48/50] batch [40/288] time 0.092 (0.104) data 0.000 (0.007) loss 2.3069 (1.7604) teacher_loss 1.2170 (0.8955) loss_zs_kd 0.5335 (0.4971) loss_oracle 0.4557 (0.3745) acc 75.0000 (75.5469) kd_loss 0.8620 (0.6776) lr 3.1417e-05 eta 0:01:25
epoch [48/50] batch [60/288] time 0.096 (0.102) data 0.000 (0.005) loss 1.7428 (1.7216) teacher_loss 0.8901 (0.8632) loss_zs_kd 0.4301 (0.5149) loss_oracle 0.3123 (0.3744) acc 75.0000 (76.3542) kd_loss 0.6966 (0.6713) lr 3.1417e-05 eta 0:01:21
epoch [48/50] batch [80/288] time 0.099 (0.100) data 0.000 (0.004) loss 1.9450 (1.7262) teacher_loss 1.0877 (0.8648) loss_zs_kd 0.4714 (0.5044) loss_oracle 0.3625 (0.3730) acc 75.0000 (76.0156) kd_loss 0.6761 (0.6749) lr 3.1417e-05 eta 0:01:18
epoch [48/50] batch [100/288] time 0.095 (0.100) data 0.000 (0.003) loss 1.5886 (1.7163) teacher_loss 0.7972 (0.8535) loss_zs_kd 0.3643 (0.4968) loss_oracle 0.3090 (0.3724) acc 78.1250 (76.6562) kd_loss 0.6369 (0.6766) lr 3.1417e-05 eta 0:01:16
epoch [48/50] batch [120/288] time 0.100 (0.099) data 0.000 (0.002) loss 1.7756 (1.7246) teacher_loss 0.9171 (0.8536) loss_zs_kd 0.6532 (0.4935) loss_oracle 0.3139 (0.3738) acc 78.1250 (76.5625) kd_loss 0.7016 (0.6841) lr 3.1417e-05 eta 0:01:13
epoch [48/50] batch [140/288] time 0.096 (0.099) data 0.000 (0.002) loss 1.7323 (1.7288) teacher_loss 0.7493 (0.8548) loss_zs_kd 0.5880 (0.4930) loss_oracle 0.3947 (0.3734) acc 78.1250 (76.6518) kd_loss 0.7857 (0.6873) lr 3.1417e-05 eta 0:01:11
epoch [48/50] batch [160/288] time 0.105 (0.099) data 0.000 (0.002) loss 1.8051 (1.7325) teacher_loss 0.8390 (0.8609) loss_zs_kd 0.4092 (0.4956) loss_oracle 0.3762 (0.3719) acc 65.6250 (76.2305) kd_loss 0.7781 (0.6856) lr 3.1417e-05 eta 0:01:09
epoch [48/50] batch [180/288] time 0.099 (0.099) data 0.000 (0.002) loss 1.6156 (1.7215) teacher_loss 0.7195 (0.8499) loss_zs_kd 0.5085 (0.4991) loss_oracle 0.3586 (0.3719) acc 84.3750 (76.6667) kd_loss 0.7169 (0.6857) lr 3.1417e-05 eta 0:01:07
epoch [48/50] batch [200/288] time 0.090 (0.099) data 0.000 (0.002) loss 1.5894 (1.7207) teacher_loss 0.6404 (0.8480) loss_zs_kd 0.5230 (0.4993) loss_oracle 0.3589 (0.3727) acc 87.5000 (76.8750) kd_loss 0.7695 (0.6864) lr 3.1417e-05 eta 0:01:05
epoch [48/50] batch [220/288] time 0.097 (0.099) data 0.000 (0.001) loss 1.4894 (1.7157) teacher_loss 0.7350 (0.8450) loss_zs_kd 0.5468 (0.4992) loss_oracle 0.3385 (0.3722) acc 78.1250 (77.0739) kd_loss 0.5851 (0.6846) lr 3.1417e-05 eta 0:01:03
epoch [48/50] batch [240/288] time 0.092 (0.099) data 0.000 (0.001) loss 1.7252 (1.7181) teacher_loss 0.8678 (0.8456) loss_zs_kd 0.4659 (0.5006) loss_oracle 0.4063 (0.3722) acc 81.2500 (77.0573) kd_loss 0.6543 (0.6864) lr 3.1417e-05 eta 0:01:01
epoch [48/50] batch [260/288] time 0.100 (0.099) data 0.000 (0.001) loss 1.8746 (1.7158) teacher_loss 0.9590 (0.8431) loss_zs_kd 0.4574 (0.4981) loss_oracle 0.3579 (0.3720) acc 71.8750 (77.0793) kd_loss 0.7367 (0.6867) lr 3.1417e-05 eta 0:00:59
epoch [48/50] batch [280/288] time 0.087 (0.098) data 0.000 (0.001) loss 1.6410 (1.7141) teacher_loss 0.7677 (0.8406) loss_zs_kd 0.5386 (0.4987) loss_oracle 0.3648 (0.3725) acc 84.3750 (77.1652) kd_loss 0.6909 (0.6873) lr 3.1417e-05 eta 0:00:57
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,460
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,988
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 78.5%
******* Domain a best val acc:      87.9%, epoch: 47 *******
******* Domain a best val test acc: 81.8%, epoch: 47 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [49/50] batch [20/288] time 0.095 (0.112) data 0.000 (0.014) loss 1.6603 (1.6375) teacher_loss 0.8361 (0.7724) loss_zs_kd 0.4892 (0.4894) loss_oracle 0.3504 (0.3691) acc 75.0000 (79.0625) kd_loss 0.6490 (0.6806) lr 1.7713e-05 eta 0:01:02
epoch [49/50] batch [40/288] time 0.092 (0.103) data 0.000 (0.007) loss 2.1150 (1.6502) teacher_loss 1.1425 (0.8053) loss_zs_kd 0.5304 (0.4905) loss_oracle 0.3325 (0.3618) acc 68.7500 (78.2031) kd_loss 0.8063 (0.6640) lr 1.7713e-05 eta 0:00:55
epoch [49/50] batch [60/288] time 0.099 (0.100) data 0.000 (0.005) loss 1.4199 (1.6546) teacher_loss 0.4788 (0.7995) loss_zs_kd 0.3937 (0.4961) loss_oracle 0.4284 (0.3667) acc 84.3750 (78.5417) kd_loss 0.7269 (0.6718) lr 1.7713e-05 eta 0:00:51
epoch [49/50] batch [80/288] time 0.097 (0.099) data 0.000 (0.004) loss 1.7235 (1.6493) teacher_loss 0.9095 (0.7909) loss_zs_kd 0.4982 (0.4939) loss_oracle 0.3712 (0.3689) acc 78.1250 (79.3359) kd_loss 0.6284 (0.6739) lr 1.7713e-05 eta 0:00:49
epoch [49/50] batch [100/288] time 0.092 (0.099) data 0.000 (0.003) loss 1.3948 (1.6560) teacher_loss 0.5704 (0.8047) loss_zs_kd 0.4303 (0.4997) loss_oracle 0.3493 (0.3672) acc 84.3750 (79.0938) kd_loss 0.6497 (0.6677) lr 1.7713e-05 eta 0:00:46
epoch [49/50] batch [120/288] time 0.094 (0.098) data 0.000 (0.002) loss 2.0042 (1.6673) teacher_loss 1.0827 (0.8130) loss_zs_kd 0.4294 (0.4951) loss_oracle 0.3703 (0.3683) acc 84.3750 (78.8021) kd_loss 0.7364 (0.6702) lr 1.7713e-05 eta 0:00:44
epoch [49/50] batch [140/288] time 0.097 (0.098) data 0.000 (0.002) loss 2.0461 (1.6723) teacher_loss 1.1217 (0.8127) loss_zs_kd 0.5807 (0.4984) loss_oracle 0.4110 (0.3711) acc 71.8750 (78.8170) kd_loss 0.7189 (0.6741) lr 1.7713e-05 eta 0:00:42
epoch [49/50] batch [160/288] time 0.094 (0.098) data 0.000 (0.002) loss 1.4623 (1.6713) teacher_loss 0.7114 (0.8099) loss_zs_kd 0.4876 (0.4938) loss_oracle 0.3471 (0.3697) acc 84.3750 (78.9258) kd_loss 0.5774 (0.6765) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [180/288] time 0.098 (0.098) data 0.000 (0.002) loss 1.6078 (1.6646) teacher_loss 0.8729 (0.8039) loss_zs_kd 0.6740 (0.4908) loss_oracle 0.3146 (0.3712) acc 78.1250 (79.0278) kd_loss 0.5777 (0.6750) lr 1.7713e-05 eta 0:00:38
epoch [49/50] batch [200/288] time 0.098 (0.098) data 0.000 (0.002) loss 2.1046 (1.6816) teacher_loss 1.3239 (0.8184) loss_zs_kd 0.4425 (0.4905) loss_oracle 0.4213 (0.3718) acc 68.7500 (78.7031) kd_loss 0.5700 (0.6773) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [220/288] time 0.094 (0.098) data 0.000 (0.001) loss 1.7906 (1.6876) teacher_loss 1.0278 (0.8239) loss_zs_kd 0.5202 (0.4915) loss_oracle 0.3232 (0.3709) acc 65.6250 (78.5795) kd_loss 0.6012 (0.6782) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [240/288] time 0.091 (0.098) data 0.000 (0.001) loss 1.5952 (1.6886) teacher_loss 0.6085 (0.8231) loss_zs_kd 0.4663 (0.4900) loss_oracle 0.3509 (0.3710) acc 84.3750 (78.4245) kd_loss 0.8112 (0.6799) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [260/288] time 0.102 (0.098) data 0.000 (0.001) loss 1.6651 (1.6839) teacher_loss 0.9423 (0.8163) loss_zs_kd 0.5600 (0.4875) loss_oracle 0.3032 (0.3719) acc 84.3750 (78.7019) kd_loss 0.5711 (0.6816) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [280/288] time 0.087 (0.098) data 0.000 (0.001) loss 1.4429 (1.6781) teacher_loss 0.5223 (0.8122) loss_zs_kd 0.3490 (0.4857) loss_oracle 0.2988 (0.3709) acc 90.6250 (78.7165) kd_loss 0.7711 (0.6804) lr 1.7713e-05 eta 0:00:28
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,459
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,987
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 78.5%
******* Domain a best val acc:      87.9%, epoch: 47 *******
******* Domain a best val test acc: 81.8%, epoch: 47 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
epoch [50/50] batch [20/288] time 0.101 (0.122) data 0.000 (0.016) loss 2.0008 (1.5923) teacher_loss 1.1062 (0.7353) loss_zs_kd 0.3666 (0.5041) loss_oracle 0.3623 (0.3653) acc 75.0000 (78.9062) kd_loss 0.7134 (0.6743) lr 7.8853e-06 eta 0:00:32
epoch [50/50] batch [40/288] time 0.096 (0.111) data 0.000 (0.008) loss 1.6044 (1.6692) teacher_loss 0.8241 (0.8122) loss_zs_kd 0.6347 (0.5048) loss_oracle 0.2542 (0.3605) acc 78.1250 (77.5000) kd_loss 0.6533 (0.6768) lr 7.8853e-06 eta 0:00:27
epoch [50/50] batch [60/288] time 0.099 (0.108) data 0.000 (0.006) loss 1.4411 (1.6743) teacher_loss 0.7160 (0.8163) loss_zs_kd 0.4512 (0.4815) loss_oracle 0.3674 (0.3612) acc 81.2500 (77.7083) kd_loss 0.5413 (0.6773) lr 7.8853e-06 eta 0:00:24
epoch [50/50] batch [80/288] time 0.094 (0.106) data 0.000 (0.004) loss 1.5753 (1.6756) teacher_loss 0.5926 (0.8192) loss_zs_kd 0.4395 (0.4855) loss_oracle 0.4120 (0.3653) acc 78.1250 (77.5000) kd_loss 0.7767 (0.6737) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [100/288] time 0.105 (0.105) data 0.000 (0.003) loss 1.8291 (1.6938) teacher_loss 1.0135 (0.8393) loss_zs_kd 0.5061 (0.4889) loss_oracle 0.3797 (0.3673) acc 84.3750 (77.0625) kd_loss 0.6257 (0.6708) lr 7.8853e-06 eta 0:00:19
epoch [50/50] batch [120/288] time 0.099 (0.104) data 0.000 (0.003) loss 1.7932 (1.6963) teacher_loss 0.7626 (0.8398) loss_zs_kd 0.4504 (0.4847) loss_oracle 0.4390 (0.3689) acc 78.1250 (77.1354) kd_loss 0.8111 (0.6721) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [140/288] time 0.106 (0.104) data 0.001 (0.003) loss 1.6999 (1.6962) teacher_loss 0.9156 (0.8311) loss_zs_kd 0.5836 (0.4933) loss_oracle 0.4189 (0.3704) acc 75.0000 (77.5000) kd_loss 0.5749 (0.6799) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [160/288] time 0.101 (0.104) data 0.000 (0.002) loss 1.8193 (1.6843) teacher_loss 0.7941 (0.8221) loss_zs_kd 0.3547 (0.4896) loss_oracle 0.3898 (0.3697) acc 75.0000 (77.7539) kd_loss 0.8303 (0.6773) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [180/288] time 0.094 (0.104) data 0.000 (0.002) loss 1.8002 (1.6984) teacher_loss 0.7792 (0.8363) loss_zs_kd 0.5680 (0.4917) loss_oracle 0.4165 (0.3705) acc 81.2500 (77.6042) kd_loss 0.8128 (0.6768) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [200/288] time 0.099 (0.103) data 0.000 (0.002) loss 1.9155 (1.7074) teacher_loss 0.9392 (0.8402) loss_zs_kd 0.3760 (0.4923) loss_oracle 0.3895 (0.3721) acc 65.6250 (77.5938) kd_loss 0.7816 (0.6812) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [220/288] time 0.097 (0.103) data 0.000 (0.002) loss 1.2823 (1.7079) teacher_loss 0.5971 (0.8393) loss_zs_kd 0.3719 (0.4939) loss_oracle 0.3385 (0.3719) acc 78.1250 (77.6847) kd_loss 0.5159 (0.6827) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [240/288] time 0.096 (0.102) data 0.000 (0.002) loss 1.6459 (1.7196) teacher_loss 0.6780 (0.8471) loss_zs_kd 0.4036 (0.4924) loss_oracle 0.3768 (0.3725) acc 81.2500 (77.5781) kd_loss 0.7795 (0.6863) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [260/288] time 0.093 (0.102) data 0.000 (0.001) loss 1.3625 (1.7241) teacher_loss 0.5764 (0.8535) loss_zs_kd 0.4121 (0.4938) loss_oracle 0.3567 (0.3719) acc 75.0000 (77.3197) kd_loss 0.6078 (0.6846) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [280/288] time 0.084 (0.101) data 0.000 (0.001) loss 2.2322 (1.7224) teacher_loss 1.2105 (0.8511) loss_zs_kd 0.5082 (0.4943) loss_oracle 0.3805 (0.3712) acc 71.8750 (77.5000) kd_loss 0.8315 (0.6858) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,459
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,986
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 78.4%
******* Domain a best val acc:      87.9%, epoch: 47 *******
******* Domain a best val test acc: 81.8%, epoch: 47 *******
******* Domain a best test acc:     83.3%, epoch: 2 *******
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:29:44

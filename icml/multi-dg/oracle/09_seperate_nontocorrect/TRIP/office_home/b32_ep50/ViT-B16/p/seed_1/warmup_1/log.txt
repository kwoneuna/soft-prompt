Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'clipart', 'real_world']
Target     ['product']
# classes  65
# train_x  7,815
# val      3,334
# test     4,439
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/244] time 0.109 (0.153) data 0.000 (0.017) loss 1.7508 (1.7747) teacher_loss 1.4292 (1.4244) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0000 (-0.0001) acc 62.5000 (65.0000) kd_loss 0.3216 (0.3504) lr 1.0000e-05 eta 0:30:59
epoch [1/50] batch [40/244] time 0.106 (0.130) data 0.000 (0.008) loss 1.8478 (1.7461) teacher_loss 1.4990 (1.3941) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0000 (-0.0001) acc 56.2500 (65.2344) kd_loss 0.3488 (0.3521) lr 1.0000e-05 eta 0:26:23
epoch [1/50] batch [60/244] time 0.099 (0.122) data 0.000 (0.006) loss 1.6690 (1.7821) teacher_loss 1.3179 (1.4276) loss_zs_kd 0.0001 (0.0001) loss_oracle -0.0001 (-0.0001) acc 65.6250 (63.9583) kd_loss 0.3512 (0.3545) lr 1.0000e-05 eta 0:24:46
epoch [1/50] batch [80/244] time 0.101 (0.117) data 0.000 (0.004) loss 2.0262 (1.7863) teacher_loss 1.5626 (1.4335) loss_zs_kd 0.0003 (0.0001) loss_oracle -0.0001 (-0.0001) acc 59.3750 (63.9453) kd_loss 0.4637 (0.3529) lr 1.0000e-05 eta 0:23:43
epoch [1/50] batch [100/244] time 0.104 (0.114) data 0.000 (0.004) loss 1.8564 (1.7625) teacher_loss 1.5563 (1.4141) loss_zs_kd 0.0006 (0.0002) loss_oracle 0.0000 (-0.0001) acc 62.5000 (64.1562) kd_loss 0.3000 (0.3484) lr 1.0000e-05 eta 0:23:03
epoch [1/50] batch [120/244] time 0.099 (0.112) data 0.000 (0.003) loss 1.1369 (1.7453) teacher_loss 0.9579 (1.3998) loss_zs_kd 0.0006 (0.0002) loss_oracle 0.0001 (-0.0000) acc 75.0000 (64.5312) kd_loss 0.1790 (0.3455) lr 1.0000e-05 eta 0:22:36
epoch [1/50] batch [140/244] time 0.096 (0.111) data 0.000 (0.003) loss 1.3743 (1.7294) teacher_loss 1.0922 (1.3811) loss_zs_kd 0.0008 (0.0004) loss_oracle -0.0000 (-0.0000) acc 75.0000 (64.9777) kd_loss 0.2822 (0.3483) lr 1.0000e-05 eta 0:22:13
epoch [1/50] batch [160/244] time 0.104 (0.110) data 0.000 (0.002) loss 1.8989 (1.7241) teacher_loss 1.4830 (1.3727) loss_zs_kd 0.0017 (0.0005) loss_oracle -0.0001 (-0.0000) acc 56.2500 (65.1172) kd_loss 0.4160 (0.3514) lr 1.0000e-05 eta 0:22:01
epoch [1/50] batch [180/244] time 0.100 (0.109) data 0.000 (0.002) loss 1.3255 (1.7207) teacher_loss 0.9822 (1.3719) loss_zs_kd 0.0012 (0.0006) loss_oracle -0.0001 (-0.0000) acc 81.2500 (65.1562) kd_loss 0.3434 (0.3488) lr 1.0000e-05 eta 0:21:47
epoch [1/50] batch [200/244] time 0.104 (0.108) data 0.000 (0.002) loss 1.7375 (1.7239) teacher_loss 1.4845 (1.3711) loss_zs_kd 0.0015 (0.0008) loss_oracle -0.0000 (-0.0000) acc 62.5000 (65.2031) kd_loss 0.2530 (0.3528) lr 1.0000e-05 eta 0:21:36
epoch [1/50] batch [220/244] time 0.091 (0.107) data 0.000 (0.002) loss 1.5063 (1.7234) teacher_loss 1.2207 (1.3676) loss_zs_kd 0.0077 (0.0009) loss_oracle 0.0000 (-0.0000) acc 68.7500 (65.2273) kd_loss 0.2855 (0.3558) lr 1.0000e-05 eta 0:21:25
epoch [1/50] batch [240/244] time 0.173 (0.107) data 0.001 (0.002) loss 1.6512 (1.7196) teacher_loss 1.3134 (1.3640) loss_zs_kd 0.0020 (0.0011) loss_oracle -0.0000 (-0.0000) acc 75.0000 (65.4167) kd_loss 0.3378 (0.3556) lr 1.0000e-05 eta 0:21:23
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,681
* accuracy: 80.4%
* error: 19.6%
* macro_f1: 78.9%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,947
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 88.0%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      80.4%, epoch: 1 *******
******* Domain p best val test acc: 88.9%, epoch: 1 *******
******* Domain p best test acc:     88.9%, epoch: 1 *******
epoch [2/50] batch [20/244] time 0.104 (0.122) data 0.000 (0.016) loss 1.7741 (1.9011) teacher_loss 1.0428 (1.3701) loss_zs_kd 0.1569 (0.1276) loss_oracle 0.3665 (0.1200) acc 75.0000 (64.0625) kd_loss 0.5480 (0.4710) lr 2.0000e-03 eta 0:24:18
epoch [2/50] batch [40/244] time 0.085 (0.110) data 0.000 (0.008) loss 1.9025 (1.9091) teacher_loss 1.1019 (1.2978) loss_zs_kd 0.1483 (0.1557) loss_oracle 0.2098 (0.1823) acc 71.8750 (66.4844) kd_loss 0.6957 (0.5201) lr 2.0000e-03 eta 0:21:51
epoch [2/50] batch [60/244] time 0.102 (0.105) data 0.001 (0.005) loss 1.9257 (1.9741) teacher_loss 1.2752 (1.3223) loss_zs_kd 0.2031 (0.1655) loss_oracle 0.2659 (0.2095) acc 68.7500 (66.0938) kd_loss 0.5176 (0.5471) lr 2.0000e-03 eta 0:20:45
epoch [2/50] batch [80/244] time 0.108 (0.103) data 0.001 (0.004) loss 1.8576 (1.9570) teacher_loss 1.1298 (1.2695) loss_zs_kd 0.2122 (0.1741) loss_oracle 0.3250 (0.2493) acc 62.5000 (67.4219) kd_loss 0.5653 (0.5629) lr 2.0000e-03 eta 0:20:21
epoch [2/50] batch [100/244] time 0.092 (0.101) data 0.000 (0.003) loss 1.7644 (1.9710) teacher_loss 0.8671 (1.2580) loss_zs_kd 0.1411 (0.1793) loss_oracle 0.4068 (0.2702) acc 78.1250 (67.7812) kd_loss 0.6938 (0.5779) lr 2.0000e-03 eta 0:20:00
epoch [2/50] batch [120/244] time 0.102 (0.100) data 0.000 (0.003) loss 2.2391 (1.9522) teacher_loss 1.4841 (1.2332) loss_zs_kd 0.2047 (0.1803) loss_oracle 0.2516 (0.2685) acc 71.8750 (68.5938) kd_loss 0.6292 (0.5847) lr 2.0000e-03 eta 0:19:47
epoch [2/50] batch [140/244] time 0.086 (0.099) data 0.000 (0.002) loss 1.9010 (1.9409) teacher_loss 1.0263 (1.2241) loss_zs_kd 0.2171 (0.1876) loss_oracle 0.4146 (0.2696) acc 71.8750 (68.8839) kd_loss 0.6674 (0.5820) lr 2.0000e-03 eta 0:19:28
epoch [2/50] batch [160/244] time 0.100 (0.098) data 0.000 (0.002) loss 1.8902 (1.9608) teacher_loss 1.1484 (1.2278) loss_zs_kd 0.1820 (0.1900) loss_oracle 0.3172 (0.2835) acc 68.7500 (68.6328) kd_loss 0.5832 (0.5912) lr 2.0000e-03 eta 0:19:14
epoch [2/50] batch [180/244] time 0.084 (0.097) data 0.000 (0.002) loss 1.8078 (1.9510) teacher_loss 0.8893 (1.2107) loss_zs_kd 0.2002 (0.1933) loss_oracle 0.4274 (0.2932) acc 75.0000 (69.0104) kd_loss 0.7047 (0.5937) lr 2.0000e-03 eta 0:19:05
epoch [2/50] batch [200/244] time 0.104 (0.097) data 0.000 (0.002) loss 2.4154 (1.9782) teacher_loss 1.4810 (1.2227) loss_zs_kd 0.1878 (0.2075) loss_oracle 0.4495 (0.3088) acc 62.5000 (68.6719) kd_loss 0.7097 (0.6011) lr 2.0000e-03 eta 0:18:57
epoch [2/50] batch [220/244] time 0.090 (0.097) data 0.000 (0.002) loss 1.9316 (1.9834) teacher_loss 1.0886 (1.2176) loss_zs_kd 0.2881 (0.2091) loss_oracle 0.3712 (0.3161) acc 75.0000 (68.7216) kd_loss 0.6574 (0.6077) lr 2.0000e-03 eta 0:18:55
epoch [2/50] batch [240/244] time 0.086 (0.096) data 0.000 (0.001) loss 2.2029 (1.9893) teacher_loss 1.3557 (1.2146) loss_zs_kd 0.3062 (0.2113) loss_oracle 0.4479 (0.3254) acc 65.6250 (68.6068) kd_loss 0.6233 (0.6120) lr 2.0000e-03 eta 0:18:47
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,780
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 82.1%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,040
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.6%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.4%, epoch: 2 *******
******* Domain p best val test acc: 91.0%, epoch: 2 *******
******* Domain p best test acc:     91.0%, epoch: 2 *******
epoch [3/50] batch [20/244] time 0.101 (0.115) data 0.000 (0.013) loss 2.1145 (2.1038) teacher_loss 1.2183 (1.1723) loss_zs_kd 0.2866 (0.2897) loss_oracle 0.4654 (0.4609) acc 65.6250 (69.2188) kd_loss 0.6635 (0.7010) lr 1.9980e-03 eta 0:22:20
epoch [3/50] batch [40/244] time 0.085 (0.106) data 0.000 (0.007) loss 1.5321 (2.0986) teacher_loss 0.6994 (1.1909) loss_zs_kd 0.2673 (0.2678) loss_oracle 0.2991 (0.4372) acc 75.0000 (68.5156) kd_loss 0.6831 (0.6891) lr 1.9980e-03 eta 0:20:34
epoch [3/50] batch [60/244] time 0.094 (0.104) data 0.000 (0.005) loss 1.4811 (2.0156) teacher_loss 0.7183 (1.1601) loss_zs_kd 0.2381 (0.2534) loss_oracle 0.2592 (0.3873) acc 84.3750 (69.3750) kd_loss 0.6333 (0.6619) lr 1.9980e-03 eta 0:20:06
epoch [3/50] batch [80/244] time 0.093 (0.102) data 0.000 (0.004) loss 2.4454 (2.0294) teacher_loss 1.4882 (1.2015) loss_zs_kd 0.1822 (0.2561) loss_oracle 0.3257 (0.3636) acc 65.6250 (68.8672) kd_loss 0.7943 (0.6461) lr 1.9980e-03 eta 0:19:46
epoch [3/50] batch [100/244] time 0.092 (0.101) data 0.000 (0.003) loss 2.3584 (1.9979) teacher_loss 1.6531 (1.1895) loss_zs_kd 0.3777 (0.2522) loss_oracle 0.3225 (0.3486) acc 59.3750 (69.1875) kd_loss 0.5440 (0.6341) lr 1.9980e-03 eta 0:19:31
epoch [3/50] batch [120/244] time 0.097 (0.100) data 0.000 (0.002) loss 1.6554 (1.9886) teacher_loss 0.8257 (1.1866) loss_zs_kd 0.3060 (0.2553) loss_oracle 0.2681 (0.3409) acc 75.0000 (68.9062) kd_loss 0.6956 (0.6315) lr 1.9980e-03 eta 0:19:19
epoch [3/50] batch [140/244] time 0.091 (0.099) data 0.000 (0.002) loss 2.1930 (1.9747) teacher_loss 1.2433 (1.1762) loss_zs_kd 0.2555 (0.2544) loss_oracle 0.2597 (0.3353) acc 78.1250 (69.3080) kd_loss 0.8199 (0.6309) lr 1.9980e-03 eta 0:19:11
epoch [3/50] batch [160/244] time 0.100 (0.099) data 0.000 (0.002) loss 2.1777 (1.9818) teacher_loss 1.2054 (1.1863) loss_zs_kd 0.2413 (0.2549) loss_oracle 0.4124 (0.3323) acc 65.6250 (69.1406) kd_loss 0.7661 (0.6294) lr 1.9980e-03 eta 0:19:09
epoch [3/50] batch [180/244] time 0.093 (0.099) data 0.000 (0.002) loss 1.8183 (1.9775) teacher_loss 0.8494 (1.1782) loss_zs_kd 0.2598 (0.2528) loss_oracle 0.3956 (0.3385) acc 68.7500 (69.4444) kd_loss 0.7711 (0.6301) lr 1.9980e-03 eta 0:19:03
epoch [3/50] batch [200/244] time 0.107 (0.100) data 0.000 (0.002) loss 2.1916 (1.9783) teacher_loss 1.2574 (1.1736) loss_zs_kd 0.2604 (0.2528) loss_oracle 0.4582 (0.3466) acc 68.7500 (69.5000) kd_loss 0.7050 (0.6315) lr 1.9980e-03 eta 0:19:07
epoch [3/50] batch [220/244] time 0.103 (0.100) data 0.000 (0.001) loss 2.0626 (1.9911) teacher_loss 1.2385 (1.1766) loss_zs_kd 0.3117 (0.2554) loss_oracle 0.4517 (0.3582) acc 71.8750 (69.3608) kd_loss 0.5982 (0.6354) lr 1.9980e-03 eta 0:19:08
epoch [3/50] batch [240/244] time 0.110 (0.100) data 0.000 (0.001) loss 1.3098 (1.9861) teacher_loss 0.7890 (1.1725) loss_zs_kd 0.1635 (0.2557) loss_oracle 0.2681 (0.3589) acc 78.1250 (69.3750) kd_loss 0.3868 (0.6341) lr 1.9980e-03 eta 0:19:10
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,800
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 82.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.0%, epoch: 3 *******
******* Domain p best val test acc: 90.9%, epoch: 3 *******
******* Domain p best test acc:     91.0%, epoch: 2 *******
epoch [4/50] batch [20/244] time 0.099 (0.123) data 0.000 (0.018) loss 2.1453 (1.9380) teacher_loss 1.3818 (1.1736) loss_zs_kd 0.2133 (0.2770) loss_oracle 0.2756 (0.3275) acc 62.5000 (68.9062) kd_loss 0.6257 (0.6006) lr 1.9921e-03 eta 0:23:23
epoch [4/50] batch [40/244] time 0.098 (0.112) data 0.000 (0.009) loss 1.5797 (1.9177) teacher_loss 0.7501 (1.1359) loss_zs_kd 0.2746 (0.2642) loss_oracle 0.3120 (0.3269) acc 81.2500 (69.5312) kd_loss 0.6735 (0.6184) lr 1.9921e-03 eta 0:21:19
epoch [4/50] batch [60/244] time 0.106 (0.108) data 0.001 (0.006) loss 2.3252 (1.9149) teacher_loss 1.3677 (1.1202) loss_zs_kd 0.3478 (0.2664) loss_oracle 0.4422 (0.3398) acc 59.3750 (70.4167) kd_loss 0.7364 (0.6249) lr 1.9921e-03 eta 0:20:36
epoch [4/50] batch [80/244] time 0.107 (0.108) data 0.000 (0.005) loss 2.7085 (1.9586) teacher_loss 1.7653 (1.1220) loss_zs_kd 0.3555 (0.2742) loss_oracle 0.4330 (0.3799) acc 53.1250 (70.8203) kd_loss 0.7266 (0.6466) lr 1.9921e-03 eta 0:20:28
epoch [4/50] batch [100/244] time 0.102 (0.108) data 0.000 (0.004) loss 2.3384 (2.0082) teacher_loss 1.3191 (1.1470) loss_zs_kd 0.2957 (0.2806) loss_oracle 0.4685 (0.3988) acc 71.8750 (69.9688) kd_loss 0.7851 (0.6618) lr 1.9921e-03 eta 0:20:24
epoch [4/50] batch [120/244] time 0.111 (0.107) data 0.001 (0.003) loss 1.9311 (2.0334) teacher_loss 1.0607 (1.1546) loss_zs_kd 0.2646 (0.2866) loss_oracle 0.3741 (0.4141) acc 75.0000 (69.9740) kd_loss 0.6834 (0.6717) lr 1.9921e-03 eta 0:20:19
epoch [4/50] batch [140/244] time 0.102 (0.107) data 0.000 (0.003) loss 1.5431 (2.0247) teacher_loss 0.8117 (1.1400) loss_zs_kd 0.2441 (0.2877) loss_oracle 0.3482 (0.4212) acc 78.1250 (70.5134) kd_loss 0.5572 (0.6740) lr 1.9921e-03 eta 0:20:16
epoch [4/50] batch [160/244] time 0.100 (0.106) data 0.000 (0.003) loss 1.9835 (2.0313) teacher_loss 0.9695 (1.1415) loss_zs_kd 0.2612 (0.2890) loss_oracle 0.4936 (0.4273) acc 68.7500 (70.1758) kd_loss 0.7673 (0.6761) lr 1.9921e-03 eta 0:20:03
epoch [4/50] batch [180/244] time 0.099 (0.106) data 0.000 (0.002) loss 1.5330 (2.0262) teacher_loss 0.6152 (1.1267) loss_zs_kd 0.3120 (0.2907) loss_oracle 0.4868 (0.4352) acc 81.2500 (70.5729) kd_loss 0.6744 (0.6818) lr 1.9921e-03 eta 0:19:55
epoch [4/50] batch [200/244] time 0.097 (0.106) data 0.000 (0.002) loss 2.1930 (2.0257) teacher_loss 1.2566 (1.1256) loss_zs_kd 0.3038 (0.2918) loss_oracle 0.4768 (0.4379) acc 75.0000 (70.5000) kd_loss 0.6981 (0.6811) lr 1.9921e-03 eta 0:19:49
epoch [4/50] batch [220/244] time 0.104 (0.105) data 0.000 (0.002) loss 2.5907 (2.0138) teacher_loss 1.7362 (1.1153) loss_zs_kd 0.3685 (0.2935) loss_oracle 0.4585 (0.4369) acc 59.3750 (70.6108) kd_loss 0.6253 (0.6800) lr 1.9921e-03 eta 0:19:43
epoch [4/50] batch [240/244] time 0.106 (0.105) data 0.000 (0.002) loss 2.4112 (2.0137) teacher_loss 1.3937 (1.1155) loss_zs_kd 0.2449 (0.2955) loss_oracle 0.4522 (0.4376) acc 68.7500 (70.5859) kd_loss 0.7914 (0.6794) lr 1.9921e-03 eta 0:19:40
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,806
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.1%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,038
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.2%, epoch: 4 *******
******* Domain p best val test acc: 91.0%, epoch: 4 *******
******* Domain p best test acc:     91.0%, epoch: 2 *******
epoch [5/50] batch [20/244] time 0.105 (0.122) data 0.000 (0.014) loss 2.4696 (2.1817) teacher_loss 1.4673 (1.1564) loss_zs_kd 0.2282 (0.3108) loss_oracle 0.5389 (0.5582) acc 65.6250 (67.9688) kd_loss 0.7328 (0.7462) lr 1.9823e-03 eta 0:22:50
epoch [5/50] batch [40/244] time 0.101 (0.113) data 0.000 (0.007) loss 2.0609 (2.0829) teacher_loss 1.0780 (1.0727) loss_zs_kd 0.2823 (0.3062) loss_oracle 0.4890 (0.5438) acc 68.7500 (70.6250) kd_loss 0.7383 (0.7383) lr 1.9823e-03 eta 0:21:05
epoch [5/50] batch [60/244] time 0.100 (0.109) data 0.000 (0.005) loss 1.8796 (2.0621) teacher_loss 0.9952 (1.0755) loss_zs_kd 0.3528 (0.3078) loss_oracle 0.4168 (0.5252) acc 71.8750 (70.0521) kd_loss 0.6760 (0.7240) lr 1.9823e-03 eta 0:20:22
epoch [5/50] batch [80/244] time 0.110 (0.108) data 0.000 (0.004) loss 2.1441 (2.0365) teacher_loss 1.3050 (1.0704) loss_zs_kd 0.3560 (0.3191) loss_oracle 0.4755 (0.5034) acc 71.8750 (71.2891) kd_loss 0.6013 (0.7144) lr 1.9823e-03 eta 0:20:08
epoch [5/50] batch [100/244] time 0.112 (0.108) data 0.000 (0.003) loss 2.3857 (2.0354) teacher_loss 1.5558 (1.0758) loss_zs_kd 0.3020 (0.3222) loss_oracle 0.4553 (0.4960) acc 65.6250 (71.4375) kd_loss 0.6022 (0.7117) lr 1.9823e-03 eta 0:19:56
epoch [5/50] batch [120/244] time 0.117 (0.107) data 0.001 (0.003) loss 1.8987 (2.0556) teacher_loss 0.9243 (1.0909) loss_zs_kd 0.3894 (0.3251) loss_oracle 0.5382 (0.4980) acc 78.1250 (70.8333) kd_loss 0.7054 (0.7156) lr 1.9823e-03 eta 0:19:47
epoch [5/50] batch [140/244] time 0.102 (0.106) data 0.000 (0.002) loss 2.2662 (2.0591) teacher_loss 1.2581 (1.0923) loss_zs_kd 0.3428 (0.3261) loss_oracle 0.5261 (0.5011) acc 56.2500 (70.7589) kd_loss 0.7451 (0.7162) lr 1.9823e-03 eta 0:19:34
epoch [5/50] batch [160/244] time 0.093 (0.105) data 0.000 (0.002) loss 1.8244 (2.0599) teacher_loss 0.8984 (1.1022) loss_zs_kd 0.2926 (0.3215) loss_oracle 0.4196 (0.4955) acc 78.1250 (70.5469) kd_loss 0.7162 (0.7099) lr 1.9823e-03 eta 0:19:20
epoch [5/50] batch [180/244] time 0.093 (0.104) data 0.000 (0.002) loss 2.3402 (2.0627) teacher_loss 1.4263 (1.1065) loss_zs_kd 0.4239 (0.3189) loss_oracle 0.4439 (0.4894) acc 68.7500 (70.6771) kd_loss 0.6920 (0.7115) lr 1.9823e-03 eta 0:19:10
epoch [5/50] batch [200/244] time 0.098 (0.103) data 0.000 (0.002) loss 2.2414 (2.0562) teacher_loss 1.1914 (1.1052) loss_zs_kd 0.2650 (0.3168) loss_oracle 0.3668 (0.4804) acc 75.0000 (70.5469) kd_loss 0.8666 (0.7108) lr 1.9823e-03 eta 0:19:00
epoch [5/50] batch [220/244] time 0.098 (0.103) data 0.000 (0.002) loss 2.1956 (2.0443) teacher_loss 1.3831 (1.1035) loss_zs_kd 0.4550 (0.3175) loss_oracle 0.3579 (0.4697) acc 59.3750 (70.6392) kd_loss 0.6336 (0.7059) lr 1.9823e-03 eta 0:18:51
epoch [5/50] batch [240/244] time 0.090 (0.102) data 0.000 (0.001) loss 2.2508 (2.0289) teacher_loss 1.3095 (1.1003) loss_zs_kd 0.5062 (0.3152) loss_oracle 0.4562 (0.4608) acc 68.7500 (70.7943) kd_loss 0.7132 (0.6982) lr 1.9823e-03 eta 0:18:42
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,820
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.4%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.6%, epoch: 5 *******
******* Domain p best val test acc: 90.9%, epoch: 5 *******
******* Domain p best test acc:     91.0%, epoch: 2 *******
epoch [6/50] batch [20/244] time 0.102 (0.118) data 0.000 (0.015) loss 2.0881 (1.9131) teacher_loss 1.2278 (1.0603) loss_zs_kd 0.3060 (0.3005) loss_oracle 0.4208 (0.3571) acc 75.0000 (73.2812) kd_loss 0.6499 (0.6742) lr 1.9686e-03 eta 0:21:30
epoch [6/50] batch [40/244] time 0.095 (0.106) data 0.000 (0.007) loss 2.1293 (1.9703) teacher_loss 1.2298 (1.0960) loss_zs_kd 0.2956 (0.3166) loss_oracle 0.3663 (0.3784) acc 65.6250 (72.1094) kd_loss 0.7163 (0.6851) lr 1.9686e-03 eta 0:19:21
epoch [6/50] batch [60/244] time 0.096 (0.103) data 0.000 (0.005) loss 2.2072 (1.9769) teacher_loss 1.4202 (1.1007) loss_zs_kd 0.4681 (0.3136) loss_oracle 0.4222 (0.3914) acc 62.5000 (72.2396) kd_loss 0.5760 (0.6804) lr 1.9686e-03 eta 0:18:49
epoch [6/50] batch [80/244] time 0.101 (0.102) data 0.000 (0.004) loss 1.7770 (1.9701) teacher_loss 1.0250 (1.1022) loss_zs_kd 0.2853 (0.3143) loss_oracle 0.3034 (0.3907) acc 65.6250 (71.2500) kd_loss 0.6003 (0.6725) lr 1.9686e-03 eta 0:18:32
epoch [6/50] batch [100/244] time 0.101 (0.102) data 0.000 (0.003) loss 2.2116 (1.9469) teacher_loss 1.3782 (1.0959) loss_zs_kd 0.3806 (0.3164) loss_oracle 0.3641 (0.3843) acc 56.2500 (71.3438) kd_loss 0.6514 (0.6589) lr 1.9686e-03 eta 0:18:26
epoch [6/50] batch [120/244] time 0.098 (0.101) data 0.000 (0.003) loss 2.0250 (1.9584) teacher_loss 1.1672 (1.1009) loss_zs_kd 0.4665 (0.3187) loss_oracle 0.4428 (0.3919) acc 59.3750 (71.1458) kd_loss 0.6363 (0.6615) lr 1.9686e-03 eta 0:18:17
epoch [6/50] batch [140/244] time 0.101 (0.101) data 0.000 (0.002) loss 2.1713 (1.9799) teacher_loss 1.3559 (1.1114) loss_zs_kd 0.3191 (0.3284) loss_oracle 0.4613 (0.4061) acc 65.6250 (70.8259) kd_loss 0.5848 (0.6654) lr 1.9686e-03 eta 0:18:11
epoch [6/50] batch [160/244] time 0.094 (0.100) data 0.000 (0.002) loss 1.7898 (1.9861) teacher_loss 0.8040 (1.1104) loss_zs_kd 0.3680 (0.3313) loss_oracle 0.4638 (0.4152) acc 71.8750 (70.8008) kd_loss 0.7538 (0.6681) lr 1.9686e-03 eta 0:18:06
epoch [6/50] batch [180/244] time 0.092 (0.100) data 0.000 (0.002) loss 1.8289 (1.9874) teacher_loss 0.9550 (1.1095) loss_zs_kd 0.4423 (0.3359) loss_oracle 0.4409 (0.4218) acc 78.1250 (70.7986) kd_loss 0.6534 (0.6669) lr 1.9686e-03 eta 0:18:00
epoch [6/50] batch [200/244] time 0.095 (0.100) data 0.000 (0.002) loss 1.8426 (1.9838) teacher_loss 1.0659 (1.1114) loss_zs_kd 0.5124 (0.3434) loss_oracle 0.3713 (0.4195) acc 75.0000 (70.7031) kd_loss 0.5911 (0.6626) lr 1.9686e-03 eta 0:17:53
epoch [6/50] batch [220/244] time 0.091 (0.099) data 0.000 (0.002) loss 2.1844 (1.9805) teacher_loss 1.3575 (1.1138) loss_zs_kd 0.3891 (0.3465) loss_oracle 0.4181 (0.4172) acc 68.7500 (70.5114) kd_loss 0.6178 (0.6581) lr 1.9686e-03 eta 0:17:46
epoch [6/50] batch [240/244] time 0.082 (0.098) data 0.000 (0.001) loss 2.0894 (1.9724) teacher_loss 1.2211 (1.1074) loss_zs_kd 0.3274 (0.3468) loss_oracle 0.4008 (0.4167) acc 62.5000 (70.7682) kd_loss 0.6679 (0.6567) lr 1.9686e-03 eta 0:17:35
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,796
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 82.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,021
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.9%
******* Domain p best val acc:      84.6%, epoch: 5 *******
******* Domain p best val test acc: 90.9%, epoch: 5 *******
******* Domain p best test acc:     91.0%, epoch: 2 *******
epoch [7/50] batch [20/244] time 0.110 (0.123) data 0.000 (0.014) loss 1.8712 (2.0290) teacher_loss 0.9842 (1.1813) loss_zs_kd 0.3512 (0.3674) loss_oracle 0.4848 (0.4427) acc 75.0000 (69.0625) kd_loss 0.6446 (0.6263) lr 1.9511e-03 eta 0:21:55
epoch [7/50] batch [40/244] time 0.089 (0.109) data 0.000 (0.007) loss 1.8000 (1.9741) teacher_loss 0.8815 (1.1136) loss_zs_kd 0.4268 (0.3596) loss_oracle 0.4441 (0.4376) acc 71.8750 (70.4688) kd_loss 0.6965 (0.6417) lr 1.9511e-03 eta 0:19:29
epoch [7/50] batch [60/244] time 0.102 (0.105) data 0.000 (0.005) loss 1.6317 (2.0076) teacher_loss 0.7668 (1.1265) loss_zs_kd 0.2656 (0.3567) loss_oracle 0.4046 (0.4333) acc 75.0000 (69.7396) kd_loss 0.6627 (0.6644) lr 1.9511e-03 eta 0:18:43
epoch [7/50] batch [80/244] time 0.102 (0.104) data 0.000 (0.004) loss 1.8999 (1.9897) teacher_loss 1.0156 (1.1126) loss_zs_kd 0.4947 (0.3591) loss_oracle 0.4942 (0.4331) acc 75.0000 (70.1953) kd_loss 0.6372 (0.6605) lr 1.9511e-03 eta 0:18:31
epoch [7/50] batch [100/244] time 0.093 (0.103) data 0.000 (0.003) loss 2.3021 (1.9865) teacher_loss 1.2948 (1.0994) loss_zs_kd 0.5369 (0.3706) loss_oracle 0.5014 (0.4398) acc 65.6250 (70.3438) kd_loss 0.7566 (0.6672) lr 1.9511e-03 eta 0:18:16
epoch [7/50] batch [120/244] time 0.100 (0.102) data 0.000 (0.003) loss 1.8653 (2.0004) teacher_loss 1.1446 (1.1068) loss_zs_kd 0.3078 (0.3737) loss_oracle 0.4365 (0.4482) acc 71.8750 (70.5469) kd_loss 0.5024 (0.6696) lr 1.9511e-03 eta 0:18:05
epoch [7/50] batch [140/244] time 0.095 (0.102) data 0.000 (0.002) loss 1.5295 (1.9956) teacher_loss 0.7361 (1.0993) loss_zs_kd 0.3589 (0.3677) loss_oracle 0.3993 (0.4487) acc 71.8750 (70.7143) kd_loss 0.5937 (0.6719) lr 1.9511e-03 eta 0:17:58
epoch [7/50] batch [160/244] time 0.095 (0.101) data 0.000 (0.002) loss 2.4526 (1.9961) teacher_loss 1.6305 (1.1005) loss_zs_kd 0.4270 (0.3621) loss_oracle 0.3549 (0.4477) acc 56.2500 (70.7227) kd_loss 0.6447 (0.6717) lr 1.9511e-03 eta 0:17:50
epoch [7/50] batch [180/244] time 0.092 (0.101) data 0.000 (0.002) loss 1.8242 (2.0001) teacher_loss 0.9137 (1.1040) loss_zs_kd 0.4277 (0.3613) loss_oracle 0.4874 (0.4474) acc 78.1250 (70.7639) kd_loss 0.6668 (0.6723) lr 1.9511e-03 eta 0:17:45
epoch [7/50] batch [200/244] time 0.097 (0.101) data 0.000 (0.002) loss 1.6348 (1.9897) teacher_loss 0.8531 (1.0987) loss_zs_kd 0.3139 (0.3587) loss_oracle 0.4413 (0.4416) acc 71.8750 (71.0625) kd_loss 0.5610 (0.6702) lr 1.9511e-03 eta 0:17:40
epoch [7/50] batch [220/244] time 0.098 (0.100) data 0.000 (0.001) loss 2.1734 (1.9975) teacher_loss 1.1743 (1.1029) loss_zs_kd 0.3992 (0.3599) loss_oracle 0.4782 (0.4411) acc 68.7500 (70.9517) kd_loss 0.7600 (0.6740) lr 1.9511e-03 eta 0:17:36
epoch [7/50] batch [240/244] time 0.088 (0.100) data 0.000 (0.001) loss 1.6631 (1.9913) teacher_loss 0.8750 (1.0981) loss_zs_kd 0.4598 (0.3563) loss_oracle 0.4289 (0.4412) acc 75.0000 (71.1589) kd_loss 0.5736 (0.6726) lr 1.9511e-03 eta 0:17:28
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,818
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.4%
******* Domain p best val acc:      84.6%, epoch: 5 *******
******* Domain p best val test acc: 90.9%, epoch: 5 *******
******* Domain p best test acc:     91.0%, epoch: 2 *******
epoch [8/50] batch [20/244] time 0.086 (0.114) data 0.000 (0.018) loss 2.2083 (2.0959) teacher_loss 1.2271 (1.1676) loss_zs_kd 0.2600 (0.3300) loss_oracle 0.3929 (0.4506) acc 71.8750 (68.9062) kd_loss 0.7847 (0.7030) lr 1.9298e-03 eta 0:19:54
epoch [8/50] batch [40/244] time 0.094 (0.103) data 0.000 (0.009) loss 2.0768 (2.0569) teacher_loss 1.0709 (1.1133) loss_zs_kd 0.3408 (0.3375) loss_oracle 0.4595 (0.4494) acc 71.8750 (70.3125) kd_loss 0.7761 (0.7189) lr 1.9298e-03 eta 0:18:01
epoch [8/50] batch [60/244] time 0.102 (0.100) data 0.001 (0.006) loss 1.8296 (2.0346) teacher_loss 0.9537 (1.0969) loss_zs_kd 0.3366 (0.3301) loss_oracle 0.3318 (0.4381) acc 81.2500 (70.7292) kd_loss 0.7099 (0.7186) lr 1.9298e-03 eta 0:17:27
epoch [8/50] batch [80/244] time 0.096 (0.098) data 0.000 (0.005) loss 2.0512 (2.0007) teacher_loss 1.1546 (1.0792) loss_zs_kd 0.5044 (0.3336) loss_oracle 0.4040 (0.4272) acc 75.0000 (71.0938) kd_loss 0.6946 (0.7079) lr 1.9298e-03 eta 0:17:05
epoch [8/50] batch [100/244] time 0.099 (0.099) data 0.000 (0.004) loss 1.8334 (1.9952) teacher_loss 0.9278 (1.0844) loss_zs_kd 0.3268 (0.3391) loss_oracle 0.3801 (0.4229) acc 71.8750 (71.1250) kd_loss 0.7156 (0.6993) lr 1.9298e-03 eta 0:17:05
epoch [8/50] batch [120/244] time 0.097 (0.099) data 0.000 (0.003) loss 2.0509 (1.9848) teacher_loss 1.0633 (1.0803) loss_zs_kd 0.3097 (0.3457) loss_oracle 0.4416 (0.4155) acc 71.8750 (71.1198) kd_loss 0.7668 (0.6968) lr 1.9298e-03 eta 0:17:09
epoch [8/50] batch [140/244] time 0.099 (0.100) data 0.000 (0.003) loss 2.3379 (2.0031) teacher_loss 1.5138 (1.1021) loss_zs_kd 0.3923 (0.3438) loss_oracle 0.3695 (0.4129) acc 68.7500 (70.7812) kd_loss 0.6393 (0.6945) lr 1.9298e-03 eta 0:17:11
epoch [8/50] batch [160/244] time 0.107 (0.100) data 0.000 (0.003) loss 2.1289 (1.9907) teacher_loss 1.3128 (1.0907) loss_zs_kd 0.3791 (0.3416) loss_oracle 0.3792 (0.4080) acc 65.6250 (71.0938) kd_loss 0.6265 (0.6960) lr 1.9298e-03 eta 0:17:14
epoch [8/50] batch [180/244] time 0.110 (0.100) data 0.001 (0.002) loss 1.9690 (1.9820) teacher_loss 0.9271 (1.0870) loss_zs_kd 0.4628 (0.3411) loss_oracle 0.4112 (0.4006) acc 75.0000 (71.3021) kd_loss 0.8363 (0.6947) lr 1.9298e-03 eta 0:17:15
epoch [8/50] batch [200/244] time 0.099 (0.101) data 0.000 (0.002) loss 1.9302 (1.9789) teacher_loss 1.0212 (1.0862) loss_zs_kd 0.2615 (0.3389) loss_oracle 0.3790 (0.3922) acc 75.0000 (71.6250) kd_loss 0.7196 (0.6966) lr 1.9298e-03 eta 0:17:16
epoch [8/50] batch [220/244] time 0.110 (0.101) data 0.000 (0.002) loss 2.0228 (1.9750) teacher_loss 1.0616 (1.0841) loss_zs_kd 0.2964 (0.3394) loss_oracle 0.4103 (0.3886) acc 68.7500 (71.5483) kd_loss 0.7560 (0.6966) lr 1.9298e-03 eta 0:17:13
epoch [8/50] batch [240/244] time 0.104 (0.101) data 0.000 (0.002) loss 2.2851 (1.9819) teacher_loss 1.3611 (1.0904) loss_zs_kd 0.3450 (0.3399) loss_oracle 0.4097 (0.3851) acc 65.6250 (71.4453) kd_loss 0.7192 (0.6990) lr 1.9298e-03 eta 0:17:13
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,814
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,031
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.1%
******* Domain p best val acc:      84.6%, epoch: 5 *******
******* Domain p best val test acc: 90.9%, epoch: 5 *******
******* Domain p best test acc:     91.0%, epoch: 2 *******
epoch [9/50] batch [20/244] time 0.089 (0.117) data 0.000 (0.018) loss 2.3917 (2.0967) teacher_loss 1.5046 (1.2238) loss_zs_kd 0.3204 (0.3514) loss_oracle 0.3186 (0.3442) acc 62.5000 (69.6875) kd_loss 0.7277 (0.7007) lr 1.9048e-03 eta 0:19:53
epoch [9/50] batch [40/244] time 0.084 (0.104) data 0.000 (0.009) loss 1.8549 (2.0086) teacher_loss 1.1154 (1.1369) loss_zs_kd 0.2575 (0.3225) loss_oracle 0.3267 (0.3372) acc 71.8750 (71.7969) kd_loss 0.5761 (0.7031) lr 1.9048e-03 eta 0:17:46
epoch [9/50] batch [60/244] time 0.102 (0.101) data 0.000 (0.006) loss 2.7181 (1.9928) teacher_loss 1.6664 (1.1163) loss_zs_kd 0.4525 (0.3333) loss_oracle 0.4188 (0.3438) acc 68.7500 (71.8750) kd_loss 0.8423 (0.7045) lr 1.9048e-03 eta 0:17:05
epoch [9/50] batch [80/244] time 0.084 (0.098) data 0.000 (0.005) loss 2.5036 (2.0165) teacher_loss 1.5285 (1.1228) loss_zs_kd 0.2403 (0.3453) loss_oracle 0.4325 (0.3538) acc 59.3750 (71.2500) kd_loss 0.7588 (0.7168) lr 1.9048e-03 eta 0:16:37
epoch [9/50] batch [100/244] time 0.095 (0.097) data 0.000 (0.004) loss 1.7814 (2.0250) teacher_loss 0.8982 (1.1174) loss_zs_kd 0.2701 (0.3403) loss_oracle 0.3954 (0.3625) acc 71.8750 (71.5312) kd_loss 0.6854 (0.7263) lr 1.9048e-03 eta 0:16:21
epoch [9/50] batch [120/244] time 0.092 (0.097) data 0.000 (0.003) loss 2.2436 (2.0282) teacher_loss 1.4275 (1.1186) loss_zs_kd 0.2779 (0.3402) loss_oracle 0.4481 (0.3715) acc 62.5000 (71.3021) kd_loss 0.5920 (0.7239) lr 1.9048e-03 eta 0:16:21
epoch [9/50] batch [140/244] time 0.089 (0.096) data 0.001 (0.003) loss 1.8535 (2.0368) teacher_loss 0.9627 (1.1258) loss_zs_kd 0.2180 (0.3415) loss_oracle 0.3651 (0.3764) acc 71.8750 (71.0491) kd_loss 0.7082 (0.7229) lr 1.9048e-03 eta 0:16:09
epoch [9/50] batch [160/244] time 0.090 (0.095) data 0.000 (0.003) loss 1.3282 (2.0217) teacher_loss 0.5634 (1.1116) loss_zs_kd 0.3289 (0.3432) loss_oracle 0.3628 (0.3796) acc 90.6250 (71.3281) kd_loss 0.5835 (0.7204) lr 1.9048e-03 eta 0:16:02
epoch [9/50] batch [180/244] time 0.101 (0.095) data 0.000 (0.002) loss 1.7852 (2.0116) teacher_loss 1.0505 (1.1046) loss_zs_kd 0.4162 (0.3445) loss_oracle 0.2730 (0.3777) acc 78.1250 (71.2674) kd_loss 0.5982 (0.7181) lr 1.9048e-03 eta 0:15:57
epoch [9/50] batch [200/244] time 0.085 (0.095) data 0.000 (0.002) loss 2.0701 (2.0068) teacher_loss 1.1363 (1.1025) loss_zs_kd 0.3067 (0.3489) loss_oracle 0.2968 (0.3751) acc 65.6250 (71.3750) kd_loss 0.7855 (0.7167) lr 1.9048e-03 eta 0:15:50
epoch [9/50] batch [220/244] time 0.096 (0.094) data 0.000 (0.002) loss 2.2931 (2.0052) teacher_loss 1.3621 (1.1016) loss_zs_kd 0.4927 (0.3506) loss_oracle 0.3604 (0.3732) acc 78.1250 (71.4062) kd_loss 0.7508 (0.7170) lr 1.9048e-03 eta 0:15:45
epoch [9/50] batch [240/244] time 0.084 (0.094) data 0.000 (0.002) loss 2.3219 (2.0063) teacher_loss 1.3767 (1.1007) loss_zs_kd 0.4119 (0.3521) loss_oracle 0.4428 (0.3723) acc 75.0000 (71.4714) kd_loss 0.7238 (0.7194) lr 1.9048e-03 eta 0:15:38
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,819
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.6%, epoch: 5 *******
******* Domain p best val test acc: 90.9%, epoch: 5 *******
******* Domain p best test acc:     91.0%, epoch: 2 *******
epoch [10/50] batch [20/244] time 0.092 (0.113) data 0.000 (0.012) loss 1.6837 (1.9881) teacher_loss 0.9447 (1.0487) loss_zs_kd 0.2911 (0.3236) loss_oracle 0.3359 (0.3757) acc 68.7500 (71.5625) kd_loss 0.5711 (0.7516) lr 1.8763e-03 eta 0:18:48
epoch [10/50] batch [40/244] time 0.087 (0.115) data 0.000 (0.006) loss 1.8878 (1.9403) teacher_loss 0.8585 (1.0455) loss_zs_kd 0.4093 (0.3427) loss_oracle 0.4087 (0.3623) acc 87.5000 (72.8125) kd_loss 0.8250 (0.7137) lr 1.8763e-03 eta 0:19:10
epoch [10/50] batch [60/244] time 0.104 (0.109) data 0.000 (0.004) loss 1.7576 (1.9548) teacher_loss 1.1378 (1.0546) loss_zs_kd 0.3048 (0.3392) loss_oracle 0.3076 (0.3655) acc 68.7500 (72.3958) kd_loss 0.4660 (0.7175) lr 1.8763e-03 eta 0:18:06
epoch [10/50] batch [80/244] time 0.095 (0.106) data 0.000 (0.003) loss 2.1713 (1.9833) teacher_loss 1.1487 (1.0707) loss_zs_kd 0.2931 (0.3380) loss_oracle 0.3922 (0.3687) acc 65.6250 (71.9141) kd_loss 0.8265 (0.7282) lr 1.8763e-03 eta 0:17:35
epoch [10/50] batch [100/244] time 0.085 (0.105) data 0.000 (0.003) loss 2.1551 (1.9954) teacher_loss 1.0884 (1.0785) loss_zs_kd 0.3752 (0.3417) loss_oracle 0.4550 (0.3732) acc 65.6250 (71.6250) kd_loss 0.8393 (0.7303) lr 1.8763e-03 eta 0:17:16
epoch [10/50] batch [120/244] time 0.100 (0.104) data 0.000 (0.002) loss 2.3035 (2.0084) teacher_loss 1.3496 (1.0836) loss_zs_kd 0.3249 (0.3505) loss_oracle 0.3913 (0.3818) acc 65.6250 (71.4844) kd_loss 0.7583 (0.7339) lr 1.8763e-03 eta 0:17:03
epoch [10/50] batch [140/244] time 0.086 (0.103) data 0.000 (0.002) loss 1.8650 (2.0131) teacher_loss 1.0235 (1.0844) loss_zs_kd 0.3033 (0.3550) loss_oracle 0.3713 (0.3874) acc 68.7500 (71.1161) kd_loss 0.6558 (0.7349) lr 1.8763e-03 eta 0:16:52
epoch [10/50] batch [160/244] time 0.094 (0.102) data 0.000 (0.002) loss 1.6483 (2.0014) teacher_loss 0.8553 (1.0718) loss_zs_kd 0.2064 (0.3523) loss_oracle 0.3812 (0.3880) acc 75.0000 (71.5820) kd_loss 0.6024 (0.7356) lr 1.8763e-03 eta 0:16:43
epoch [10/50] batch [180/244] time 0.098 (0.101) data 0.000 (0.002) loss 2.0910 (2.0047) teacher_loss 1.2620 (1.0698) loss_zs_kd 0.3872 (0.3550) loss_oracle 0.2937 (0.3920) acc 68.7500 (71.7882) kd_loss 0.6821 (0.7390) lr 1.8763e-03 eta 0:16:35
epoch [10/50] batch [200/244] time 0.099 (0.101) data 0.000 (0.001) loss 1.8798 (2.0115) teacher_loss 1.0837 (1.0820) loss_zs_kd 0.3295 (0.3601) loss_oracle 0.3962 (0.3925) acc 65.6250 (71.5312) kd_loss 0.5980 (0.7333) lr 1.8763e-03 eta 0:16:31
epoch [10/50] batch [220/244] time 0.096 (0.101) data 0.000 (0.001) loss 2.1686 (2.0202) teacher_loss 1.1224 (1.0897) loss_zs_kd 0.3946 (0.3580) loss_oracle 0.4131 (0.3923) acc 62.5000 (71.3068) kd_loss 0.8396 (0.7343) lr 1.8763e-03 eta 0:16:23
epoch [10/50] batch [240/244] time 0.085 (0.100) data 0.000 (0.001) loss 2.3227 (2.0250) teacher_loss 1.3886 (1.0931) loss_zs_kd 0.3963 (0.3572) loss_oracle 0.4056 (0.3906) acc 62.5000 (71.1719) kd_loss 0.7313 (0.7366) lr 1.8763e-03 eta 0:16:13
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,829
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.7%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,060
* accuracy: 91.5%
* error: 8.5%
* macro_f1: 91.0%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 91.5%, epoch: 10 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [11/50] batch [20/244] time 0.108 (0.114) data 0.000 (0.013) loss 1.3857 (1.9130) teacher_loss 0.8108 (1.0485) loss_zs_kd 0.2317 (0.3181) loss_oracle 0.2477 (0.3392) acc 75.0000 (71.5625) kd_loss 0.4510 (0.6949) lr 1.8443e-03 eta 0:18:33
epoch [11/50] batch [40/244] time 0.102 (0.106) data 0.000 (0.007) loss 1.9612 (1.9380) teacher_loss 0.9908 (1.0503) loss_zs_kd 0.3662 (0.3418) loss_oracle 0.4067 (0.3549) acc 78.1250 (71.9531) kd_loss 0.7671 (0.7103) lr 1.8443e-03 eta 0:17:08
epoch [11/50] batch [60/244] time 0.100 (0.109) data 0.000 (0.005) loss 1.7007 (1.9597) teacher_loss 0.8448 (1.0602) loss_zs_kd 0.4140 (0.3577) loss_oracle 0.3570 (0.3675) acc 71.8750 (71.5625) kd_loss 0.6773 (0.7158) lr 1.8443e-03 eta 0:17:41
epoch [11/50] batch [80/244] time 0.103 (0.108) data 0.000 (0.004) loss 1.9617 (1.9734) teacher_loss 1.1233 (1.0592) loss_zs_kd 0.3709 (0.3594) loss_oracle 0.3253 (0.3732) acc 71.8750 (71.8359) kd_loss 0.6758 (0.7276) lr 1.8443e-03 eta 0:17:22
epoch [11/50] batch [100/244] time 0.108 (0.107) data 0.000 (0.003) loss 2.1157 (1.9731) teacher_loss 1.0230 (1.0466) loss_zs_kd 0.4730 (0.3656) loss_oracle 0.4819 (0.3865) acc 68.7500 (72.0000) kd_loss 0.8518 (0.7333) lr 1.8443e-03 eta 0:17:09
epoch [11/50] batch [120/244] time 0.111 (0.106) data 0.000 (0.002) loss 2.1326 (1.9951) teacher_loss 1.0165 (1.0554) loss_zs_kd 0.3179 (0.3773) loss_oracle 0.5006 (0.3933) acc 71.8750 (72.1094) kd_loss 0.8657 (0.7430) lr 1.8443e-03 eta 0:17:03
epoch [11/50] batch [140/244] time 0.100 (0.106) data 0.000 (0.002) loss 1.6716 (2.0086) teacher_loss 0.5493 (1.0625) loss_zs_kd 0.2057 (0.3771) loss_oracle 0.3675 (0.3969) acc 84.3750 (71.9643) kd_loss 0.9385 (0.7476) lr 1.8443e-03 eta 0:16:55
epoch [11/50] batch [160/244] time 0.101 (0.105) data 0.000 (0.002) loss 2.0471 (2.0202) teacher_loss 1.0175 (1.0706) loss_zs_kd 0.4691 (0.3789) loss_oracle 0.4169 (0.3973) acc 78.1250 (72.0117) kd_loss 0.8212 (0.7509) lr 1.8443e-03 eta 0:16:49
epoch [11/50] batch [180/244] time 0.095 (0.104) data 0.000 (0.002) loss 2.0210 (2.0118) teacher_loss 1.0320 (1.0654) loss_zs_kd 0.3522 (0.3772) loss_oracle 0.4205 (0.3989) acc 71.8750 (72.0486) kd_loss 0.7787 (0.7469) lr 1.8443e-03 eta 0:16:39
epoch [11/50] batch [200/244] time 0.101 (0.103) data 0.000 (0.002) loss 1.8996 (2.0056) teacher_loss 1.1516 (1.0630) loss_zs_kd 0.2342 (0.3766) loss_oracle 0.3108 (0.3986) acc 75.0000 (72.0781) kd_loss 0.5926 (0.7433) lr 1.8443e-03 eta 0:16:29
epoch [11/50] batch [220/244] time 0.095 (0.103) data 0.000 (0.001) loss 1.5199 (1.9922) teacher_loss 0.4969 (1.0514) loss_zs_kd 0.3086 (0.3740) loss_oracle 0.3622 (0.3962) acc 93.7500 (72.4432) kd_loss 0.8419 (0.7428) lr 1.8443e-03 eta 0:16:21
epoch [11/50] batch [240/244] time 0.088 (0.102) data 0.000 (0.001) loss 1.9054 (1.9950) teacher_loss 0.8905 (1.0515) loss_zs_kd 0.3687 (0.3729) loss_oracle 0.3430 (0.3955) acc 75.0000 (72.4089) kd_loss 0.8434 (0.7458) lr 1.8443e-03 eta 0:16:11
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,824
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,055
* accuracy: 91.3%
* error: 8.7%
* macro_f1: 91.0%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 91.5%, epoch: 10 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [12/50] batch [20/244] time 0.091 (0.113) data 0.000 (0.014) loss 2.1164 (1.8693) teacher_loss 1.0845 (0.9598) loss_zs_kd 0.5015 (0.3793) loss_oracle 0.4148 (0.3810) acc 68.7500 (74.0625) kd_loss 0.8245 (0.7190) lr 1.8090e-03 eta 0:17:55
epoch [12/50] batch [40/244] time 0.090 (0.104) data 0.000 (0.007) loss 2.0726 (1.9146) teacher_loss 0.9876 (0.9939) loss_zs_kd 0.3430 (0.3802) loss_oracle 0.3443 (0.3857) acc 65.6250 (73.5938) kd_loss 0.9129 (0.7278) lr 1.8090e-03 eta 0:16:29
epoch [12/50] batch [60/244] time 0.095 (0.106) data 0.000 (0.005) loss 2.2210 (1.9784) teacher_loss 1.0539 (1.0275) loss_zs_kd 0.2598 (0.3713) loss_oracle 0.4689 (0.3974) acc 68.7500 (73.0729) kd_loss 0.9326 (0.7522) lr 1.8090e-03 eta 0:16:41
epoch [12/50] batch [80/244] time 0.097 (0.103) data 0.000 (0.004) loss 1.6307 (1.9977) teacher_loss 0.8040 (1.0489) loss_zs_kd 0.2770 (0.3682) loss_oracle 0.4144 (0.3988) acc 78.1250 (72.8516) kd_loss 0.6195 (0.7494) lr 1.8090e-03 eta 0:16:15
epoch [12/50] batch [100/244] time 0.095 (0.103) data 0.000 (0.003) loss 2.2314 (2.0002) teacher_loss 1.1829 (1.0507) loss_zs_kd 0.3839 (0.3675) loss_oracle 0.3971 (0.3962) acc 68.7500 (72.5625) kd_loss 0.8499 (0.7513) lr 1.8090e-03 eta 0:16:05
epoch [12/50] batch [120/244] time 0.095 (0.102) data 0.000 (0.002) loss 1.9452 (2.0032) teacher_loss 0.9161 (1.0561) loss_zs_kd 0.5415 (0.3666) loss_oracle 0.4685 (0.3931) acc 75.0000 (72.6823) kd_loss 0.7949 (0.7505) lr 1.8090e-03 eta 0:15:54
epoch [12/50] batch [140/244] time 0.096 (0.101) data 0.000 (0.002) loss 2.2536 (2.0205) teacher_loss 1.3300 (1.0701) loss_zs_kd 0.3837 (0.3715) loss_oracle 0.3580 (0.3924) acc 65.6250 (72.2991) kd_loss 0.7446 (0.7542) lr 1.8090e-03 eta 0:15:46
epoch [12/50] batch [160/244] time 0.095 (0.100) data 0.000 (0.002) loss 2.1574 (2.0143) teacher_loss 1.1706 (1.0607) loss_zs_kd 0.3416 (0.3710) loss_oracle 0.4483 (0.3962) acc 59.3750 (72.2656) kd_loss 0.7627 (0.7555) lr 1.8090e-03 eta 0:15:39
epoch [12/50] batch [180/244] time 0.096 (0.100) data 0.000 (0.002) loss 1.9476 (2.0199) teacher_loss 1.1956 (1.0651) loss_zs_kd 0.5622 (0.3750) loss_oracle 0.3434 (0.4000) acc 68.7500 (72.2049) kd_loss 0.5803 (0.7548) lr 1.8090e-03 eta 0:15:31
epoch [12/50] batch [200/244] time 0.099 (0.099) data 0.000 (0.002) loss 2.1981 (2.0139) teacher_loss 1.1426 (1.0612) loss_zs_kd 0.5324 (0.3757) loss_oracle 0.4417 (0.4012) acc 62.5000 (72.2969) kd_loss 0.8347 (0.7521) lr 1.8090e-03 eta 0:15:26
epoch [12/50] batch [220/244] time 0.092 (0.099) data 0.000 (0.001) loss 2.1658 (2.0176) teacher_loss 1.2151 (1.0643) loss_zs_kd 0.3233 (0.3760) loss_oracle 0.3854 (0.4025) acc 65.6250 (72.1875) kd_loss 0.7580 (0.7521) lr 1.8090e-03 eta 0:15:22
epoch [12/50] batch [240/244] time 0.089 (0.099) data 0.000 (0.001) loss 1.7737 (2.0114) teacher_loss 0.8213 (1.0581) loss_zs_kd 0.2683 (0.3764) loss_oracle 0.4205 (0.4049) acc 75.0000 (72.2917) kd_loss 0.7421 (0.7509) lr 1.8090e-03 eta 0:15:15
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,828
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 91.5%, epoch: 10 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [13/50] batch [20/244] time 0.097 (0.120) data 0.000 (0.015) loss 1.5079 (1.9178) teacher_loss 0.6449 (0.9710) loss_zs_kd 0.3647 (0.3647) loss_oracle 0.3689 (0.4290) acc 87.5000 (75.4688) kd_loss 0.6785 (0.7322) lr 1.7705e-03 eta 0:18:27
epoch [13/50] batch [40/244] time 0.100 (0.111) data 0.000 (0.007) loss 1.9978 (1.9210) teacher_loss 1.0309 (1.0033) loss_zs_kd 0.4420 (0.3720) loss_oracle 0.3466 (0.4166) acc 75.0000 (73.8281) kd_loss 0.7936 (0.7093) lr 1.7705e-03 eta 0:17:05
epoch [13/50] batch [60/244] time 0.103 (0.108) data 0.001 (0.005) loss 1.8233 (1.9459) teacher_loss 0.9492 (1.0259) loss_zs_kd 0.4447 (0.3732) loss_oracle 0.4549 (0.4174) acc 75.0000 (73.6979) kd_loss 0.6467 (0.7113) lr 1.7705e-03 eta 0:16:38
epoch [13/50] batch [80/244] time 0.111 (0.109) data 0.000 (0.004) loss 2.4696 (1.9815) teacher_loss 1.5848 (1.0603) loss_zs_kd 0.3618 (0.3732) loss_oracle 0.4150 (0.4172) acc 50.0000 (72.5781) kd_loss 0.6773 (0.7126) lr 1.7705e-03 eta 0:16:44
epoch [13/50] batch [100/244] time 0.102 (0.108) data 0.000 (0.003) loss 2.4062 (1.9900) teacher_loss 1.4693 (1.0668) loss_zs_kd 0.3453 (0.3713) loss_oracle 0.4690 (0.4111) acc 56.2500 (72.0625) kd_loss 0.7024 (0.7176) lr 1.7705e-03 eta 0:16:30
epoch [13/50] batch [120/244] time 0.103 (0.107) data 0.000 (0.003) loss 2.0870 (1.9899) teacher_loss 1.2116 (1.0620) loss_zs_kd 0.3431 (0.3666) loss_oracle 0.4084 (0.4079) acc 68.7500 (72.1354) kd_loss 0.6712 (0.7239) lr 1.7705e-03 eta 0:16:20
epoch [13/50] batch [140/244] time 0.103 (0.106) data 0.000 (0.002) loss 2.4598 (1.9997) teacher_loss 1.5165 (1.0730) loss_zs_kd 0.4589 (0.3711) loss_oracle 0.4270 (0.4040) acc 62.5000 (72.0089) kd_loss 0.7297 (0.7247) lr 1.7705e-03 eta 0:16:11
epoch [13/50] batch [160/244] time 0.103 (0.106) data 0.000 (0.002) loss 2.5274 (1.9912) teacher_loss 1.5602 (1.0661) loss_zs_kd 0.3557 (0.3685) loss_oracle 0.4794 (0.3993) acc 62.5000 (72.1289) kd_loss 0.7275 (0.7254) lr 1.7705e-03 eta 0:16:02
epoch [13/50] batch [180/244] time 0.101 (0.105) data 0.000 (0.002) loss 2.2719 (1.9974) teacher_loss 1.1749 (1.0688) loss_zs_kd 0.4353 (0.3698) loss_oracle 0.3790 (0.4003) acc 78.1250 (72.1007) kd_loss 0.9074 (0.7285) lr 1.7705e-03 eta 0:15:58
epoch [13/50] batch [200/244] time 0.113 (0.105) data 0.000 (0.002) loss 1.9365 (2.0004) teacher_loss 1.0974 (1.0698) loss_zs_kd 0.3834 (0.3709) loss_oracle 0.3569 (0.4019) acc 68.7500 (72.0156) kd_loss 0.6607 (0.7297) lr 1.7705e-03 eta 0:15:53
epoch [13/50] batch [220/244] time 0.097 (0.105) data 0.000 (0.002) loss 1.7228 (1.9950) teacher_loss 0.5935 (1.0616) loss_zs_kd 0.4563 (0.3714) loss_oracle 0.4595 (0.4020) acc 81.2500 (72.2727) kd_loss 0.8996 (0.7324) lr 1.7705e-03 eta 0:15:51
epoch [13/50] batch [240/244] time 0.108 (0.105) data 0.000 (0.001) loss 2.2195 (1.9949) teacher_loss 1.2649 (1.0577) loss_zs_kd 0.4490 (0.3723) loss_oracle 0.4003 (0.4046) acc 71.8750 (72.3958) kd_loss 0.7545 (0.7350) lr 1.7705e-03 eta 0:15:49
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,817
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 91.5%, epoch: 10 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [14/50] batch [20/244] time 0.101 (0.124) data 0.000 (0.017) loss 1.9719 (1.9845) teacher_loss 0.9841 (1.0447) loss_zs_kd 0.4739 (0.3771) loss_oracle 0.3601 (0.4084) acc 75.0000 (70.6250) kd_loss 0.8077 (0.7357) lr 1.7290e-03 eta 0:18:38
epoch [14/50] batch [40/244] time 0.099 (0.119) data 0.000 (0.009) loss 1.9045 (1.9747) teacher_loss 0.9112 (1.0505) loss_zs_kd 0.3541 (0.3875) loss_oracle 0.4628 (0.3971) acc 78.1250 (71.3281) kd_loss 0.7619 (0.7257) lr 1.7290e-03 eta 0:17:52
epoch [14/50] batch [60/244] time 0.091 (0.116) data 0.000 (0.006) loss 2.0785 (2.0022) teacher_loss 1.0817 (1.0489) loss_zs_kd 0.2912 (0.3816) loss_oracle 0.3640 (0.3996) acc 78.1250 (71.5625) kd_loss 0.8147 (0.7535) lr 1.7290e-03 eta 0:17:15
epoch [14/50] batch [80/244] time 0.099 (0.113) data 0.000 (0.005) loss 1.9771 (1.9948) teacher_loss 0.9726 (1.0217) loss_zs_kd 0.3468 (0.3836) loss_oracle 0.4036 (0.4024) acc 78.1250 (72.5000) kd_loss 0.8027 (0.7719) lr 1.7290e-03 eta 0:16:52
epoch [14/50] batch [100/244] time 0.119 (0.113) data 0.000 (0.004) loss 2.1658 (1.9777) teacher_loss 1.2089 (1.0126) loss_zs_kd 0.3029 (0.3781) loss_oracle 0.3306 (0.3991) acc 71.8750 (73.0625) kd_loss 0.7915 (0.7656) lr 1.7290e-03 eta 0:16:48
epoch [14/50] batch [120/244] time 0.096 (0.113) data 0.000 (0.003) loss 2.0017 (1.9614) teacher_loss 0.9572 (0.9991) loss_zs_kd 0.2763 (0.3748) loss_oracle 0.4414 (0.3979) acc 78.1250 (73.3073) kd_loss 0.8237 (0.7633) lr 1.7290e-03 eta 0:16:42
epoch [14/50] batch [140/244] time 0.110 (0.112) data 0.000 (0.003) loss 2.2457 (1.9700) teacher_loss 1.3067 (1.0052) loss_zs_kd 0.4208 (0.3776) loss_oracle 0.3935 (0.4004) acc 71.8750 (72.9688) kd_loss 0.7423 (0.7646) lr 1.7290e-03 eta 0:16:32
epoch [14/50] batch [160/244] time 0.100 (0.111) data 0.000 (0.002) loss 2.2154 (1.9737) teacher_loss 1.1447 (1.0094) loss_zs_kd 0.5072 (0.3834) loss_oracle 0.4310 (0.4006) acc 75.0000 (73.0859) kd_loss 0.8552 (0.7640) lr 1.7290e-03 eta 0:16:22
epoch [14/50] batch [180/244] time 0.122 (0.111) data 0.000 (0.002) loss 2.2020 (1.9588) teacher_loss 1.1860 (1.0001) loss_zs_kd 0.2586 (0.3819) loss_oracle 0.4719 (0.4015) acc 71.8750 (73.2639) kd_loss 0.7800 (0.7580) lr 1.7290e-03 eta 0:16:18
epoch [14/50] batch [200/244] time 0.111 (0.111) data 0.000 (0.002) loss 1.7790 (1.9573) teacher_loss 0.8984 (1.0027) loss_zs_kd 0.3246 (0.3789) loss_oracle 0.2990 (0.4007) acc 75.0000 (73.2500) kd_loss 0.7311 (0.7542) lr 1.7290e-03 eta 0:16:15
epoch [14/50] batch [220/244] time 0.117 (0.111) data 0.000 (0.002) loss 1.5957 (1.9485) teacher_loss 0.6098 (0.9966) loss_zs_kd 0.3939 (0.3796) loss_oracle 0.4056 (0.3992) acc 81.2500 (73.4659) kd_loss 0.7831 (0.7523) lr 1.7290e-03 eta 0:16:18
epoch [14/50] batch [240/244] time 0.108 (0.111) data 0.000 (0.002) loss 2.1202 (1.9636) teacher_loss 1.0977 (1.0074) loss_zs_kd 0.4052 (0.3784) loss_oracle 0.4146 (0.4015) acc 71.8750 (73.1901) kd_loss 0.8153 (0.7554) lr 1.7290e-03 eta 0:16:13
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,826
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 91.5%, epoch: 10 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [15/50] batch [20/244] time 0.092 (0.111) data 0.000 (0.014) loss 1.5878 (2.0152) teacher_loss 0.6658 (1.0331) loss_zs_kd 0.2670 (0.3594) loss_oracle 0.3487 (0.4015) acc 84.3750 (73.2812) kd_loss 0.7476 (0.7814) lr 1.6845e-03 eta 0:16:12
epoch [15/50] batch [40/244] time 0.099 (0.104) data 0.000 (0.007) loss 1.7206 (2.0313) teacher_loss 0.6939 (1.0569) loss_zs_kd 0.3080 (0.3764) loss_oracle 0.4183 (0.4013) acc 84.3750 (72.1875) kd_loss 0.8175 (0.7738) lr 1.6845e-03 eta 0:15:08
epoch [15/50] batch [60/244] time 0.099 (0.105) data 0.000 (0.005) loss 1.6685 (2.0127) teacher_loss 0.5498 (1.0426) loss_zs_kd 0.3726 (0.3813) loss_oracle 0.4088 (0.4020) acc 84.3750 (72.2917) kd_loss 0.9142 (0.7691) lr 1.6845e-03 eta 0:15:16
epoch [15/50] batch [80/244] time 0.105 (0.103) data 0.000 (0.004) loss 2.3620 (1.9953) teacher_loss 1.4126 (1.0414) loss_zs_kd 0.3658 (0.3826) loss_oracle 0.3829 (0.3927) acc 68.7500 (72.3828) kd_loss 0.7580 (0.7576) lr 1.6845e-03 eta 0:14:56
epoch [15/50] batch [100/244] time 0.096 (0.102) data 0.000 (0.003) loss 2.1206 (1.9770) teacher_loss 1.2582 (1.0280) loss_zs_kd 0.4504 (0.3849) loss_oracle 0.3149 (0.3859) acc 65.6250 (72.5938) kd_loss 0.7050 (0.7561) lr 1.6845e-03 eta 0:14:44
epoch [15/50] batch [120/244] time 0.106 (0.101) data 0.000 (0.003) loss 1.7651 (1.9576) teacher_loss 0.9105 (1.0202) loss_zs_kd 0.3770 (0.3835) loss_oracle 0.3683 (0.3819) acc 62.5000 (72.4740) kd_loss 0.6704 (0.7465) lr 1.6845e-03 eta 0:14:35
epoch [15/50] batch [140/244] time 0.091 (0.100) data 0.000 (0.002) loss 1.8661 (1.9689) teacher_loss 0.6723 (1.0228) loss_zs_kd 0.5120 (0.3859) loss_oracle 0.3674 (0.3843) acc 84.3750 (72.6786) kd_loss 1.0101 (0.7539) lr 1.6845e-03 eta 0:14:26
epoch [15/50] batch [160/244] time 0.092 (0.100) data 0.000 (0.002) loss 1.6445 (1.9704) teacher_loss 0.8779 (1.0256) loss_zs_kd 0.3890 (0.3861) loss_oracle 0.4044 (0.3847) acc 81.2500 (72.8516) kd_loss 0.5644 (0.7524) lr 1.6845e-03 eta 0:14:20
epoch [15/50] batch [180/244] time 0.094 (0.099) data 0.000 (0.002) loss 1.5913 (1.9602) teacher_loss 0.5831 (1.0208) loss_zs_kd 0.3780 (0.3866) loss_oracle 0.3641 (0.3847) acc 87.5000 (72.9861) kd_loss 0.8262 (0.7470) lr 1.6845e-03 eta 0:14:15
epoch [15/50] batch [200/244] time 0.092 (0.099) data 0.000 (0.002) loss 1.5482 (1.9544) teacher_loss 0.7677 (1.0189) loss_zs_kd 0.4252 (0.3876) loss_oracle 0.3131 (0.3854) acc 81.2500 (73.1094) kd_loss 0.6240 (0.7428) lr 1.6845e-03 eta 0:14:08
epoch [15/50] batch [220/244] time 0.102 (0.098) data 0.000 (0.001) loss 1.8758 (1.9603) teacher_loss 0.9088 (1.0266) loss_zs_kd 0.4081 (0.3876) loss_oracle 0.4228 (0.3879) acc 84.3750 (73.1108) kd_loss 0.7557 (0.7398) lr 1.6845e-03 eta 0:14:02
epoch [15/50] batch [240/244] time 0.085 (0.098) data 0.000 (0.001) loss 2.0437 (1.9693) teacher_loss 0.8973 (1.0319) loss_zs_kd 0.5709 (0.3888) loss_oracle 0.3333 (0.3901) acc 71.8750 (73.0208) kd_loss 0.9797 (0.7424) lr 1.6845e-03 eta 0:13:56
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,832
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.3%
******* Domain p best val acc:      84.9%, epoch: 15 *******
******* Domain p best val test acc: 90.9%, epoch: 15 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [16/50] batch [20/244] time 0.088 (0.110) data 0.000 (0.015) loss 1.6209 (2.0210) teacher_loss 0.5724 (1.0708) loss_zs_kd 0.4479 (0.4014) loss_oracle 0.4473 (0.3872) acc 78.1250 (72.0312) kd_loss 0.8248 (0.7566) lr 1.6374e-03 eta 0:15:36
epoch [16/50] batch [40/244] time 0.099 (0.101) data 0.000 (0.007) loss 1.5311 (1.9972) teacher_loss 0.5973 (1.0661) loss_zs_kd 0.3219 (0.4046) loss_oracle 0.3093 (0.3842) acc 81.2500 (73.0469) kd_loss 0.7792 (0.7390) lr 1.6374e-03 eta 0:14:21
epoch [16/50] batch [60/244] time 0.095 (0.099) data 0.000 (0.005) loss 1.8622 (1.9979) teacher_loss 0.9029 (1.0574) loss_zs_kd 0.4190 (0.4026) loss_oracle 0.4034 (0.3921) acc 71.8750 (72.6042) kd_loss 0.7576 (0.7444) lr 1.6374e-03 eta 0:14:01
epoch [16/50] batch [80/244] time 0.152 (0.101) data 0.000 (0.004) loss 1.8317 (2.0143) teacher_loss 0.9973 (1.0682) loss_zs_kd 0.5107 (0.4028) loss_oracle 0.4091 (0.3924) acc 68.7500 (72.5781) kd_loss 0.6299 (0.7499) lr 1.6374e-03 eta 0:14:14
epoch [16/50] batch [100/244] time 0.108 (0.100) data 0.000 (0.003) loss 1.7505 (2.0035) teacher_loss 0.8765 (1.0684) loss_zs_kd 0.4294 (0.4023) loss_oracle 0.3653 (0.3890) acc 78.1250 (72.6562) kd_loss 0.6914 (0.7405) lr 1.6374e-03 eta 0:14:05
epoch [16/50] batch [120/244] time 0.091 (0.100) data 0.000 (0.003) loss 2.5617 (2.0014) teacher_loss 1.5616 (1.0665) loss_zs_kd 0.3050 (0.4011) loss_oracle 0.3334 (0.3878) acc 59.3750 (72.6302) kd_loss 0.8334 (0.7410) lr 1.6374e-03 eta 0:13:57
epoch [16/50] batch [140/244] time 0.095 (0.099) data 0.000 (0.002) loss 1.4507 (1.9781) teacher_loss 0.6769 (1.0536) loss_zs_kd 0.3516 (0.3996) loss_oracle 0.3020 (0.3838) acc 84.3750 (72.9464) kd_loss 0.6228 (0.7326) lr 1.6374e-03 eta 0:13:52
epoch [16/50] batch [160/244] time 0.101 (0.099) data 0.000 (0.002) loss 1.4839 (1.9601) teacher_loss 0.7071 (1.0421) loss_zs_kd 0.2749 (0.3941) loss_oracle 0.2957 (0.3792) acc 84.3750 (73.1445) kd_loss 0.6290 (0.7284) lr 1.6374e-03 eta 0:13:49
epoch [16/50] batch [180/244] time 0.100 (0.099) data 0.000 (0.002) loss 1.5973 (1.9528) teacher_loss 0.8645 (1.0411) loss_zs_kd 0.4127 (0.3943) loss_oracle 0.3538 (0.3763) acc 71.8750 (73.1424) kd_loss 0.5559 (0.7235) lr 1.6374e-03 eta 0:13:47
epoch [16/50] batch [200/244] time 0.094 (0.099) data 0.000 (0.002) loss 2.1679 (1.9567) teacher_loss 1.0993 (1.0479) loss_zs_kd 0.3979 (0.3918) loss_oracle 0.4205 (0.3747) acc 68.7500 (73.0000) kd_loss 0.8584 (0.7215) lr 1.6374e-03 eta 0:13:45
epoch [16/50] batch [220/244] time 0.102 (0.099) data 0.000 (0.002) loss 2.6054 (1.9529) teacher_loss 1.3839 (1.0416) loss_zs_kd 0.6668 (0.3928) loss_oracle 0.4973 (0.3781) acc 68.7500 (73.3665) kd_loss 0.9728 (0.7222) lr 1.6374e-03 eta 0:13:41
epoch [16/50] batch [240/244] time 0.109 (0.099) data 0.000 (0.001) loss 1.5668 (1.9583) teacher_loss 0.5903 (1.0415) loss_zs_kd 0.3407 (0.3938) loss_oracle 0.4510 (0.3821) acc 84.3750 (73.4115) kd_loss 0.7510 (0.7257) lr 1.6374e-03 eta 0:13:43
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,824
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,032
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.2%
******* Domain p best val acc:      84.9%, epoch: 15 *******
******* Domain p best val test acc: 90.9%, epoch: 15 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [17/50] batch [20/244] time 0.093 (0.114) data 0.000 (0.016) loss 2.1708 (2.1219) teacher_loss 1.1198 (1.0906) loss_zs_kd 0.3241 (0.3993) loss_oracle 0.4555 (0.4278) acc 71.8750 (71.2500) kd_loss 0.8232 (0.8174) lr 1.5878e-03 eta 0:15:41
epoch [17/50] batch [40/244] time 0.097 (0.105) data 0.000 (0.008) loss 1.9717 (2.1084) teacher_loss 1.1972 (1.0991) loss_zs_kd 0.3145 (0.4008) loss_oracle 0.3226 (0.4258) acc 68.7500 (71.5625) kd_loss 0.6132 (0.7964) lr 1.5878e-03 eta 0:14:29
epoch [17/50] batch [60/244] time 0.093 (0.102) data 0.000 (0.005) loss 2.1793 (2.0704) teacher_loss 1.1600 (1.0601) loss_zs_kd 0.3782 (0.3984) loss_oracle 0.4391 (0.4246) acc 65.6250 (71.8750) kd_loss 0.7997 (0.7980) lr 1.5878e-03 eta 0:14:03
epoch [17/50] batch [80/244] time 0.093 (0.101) data 0.000 (0.004) loss 1.7315 (2.0688) teacher_loss 0.7209 (1.0671) loss_zs_kd 0.3507 (0.3927) loss_oracle 0.4165 (0.4256) acc 78.1250 (71.6406) kd_loss 0.8024 (0.7889) lr 1.5878e-03 eta 0:13:51
epoch [17/50] batch [100/244] time 0.095 (0.102) data 0.000 (0.003) loss 1.6643 (2.0503) teacher_loss 0.7992 (1.0540) loss_zs_kd 0.3992 (0.3923) loss_oracle 0.3750 (0.4258) acc 75.0000 (72.1250) kd_loss 0.6776 (0.7834) lr 1.5878e-03 eta 0:13:58
epoch [17/50] batch [120/244] time 0.094 (0.102) data 0.000 (0.003) loss 1.9466 (2.0452) teacher_loss 0.9587 (1.0471) loss_zs_kd 0.4351 (0.3988) loss_oracle 0.4709 (0.4296) acc 75.0000 (72.6042) kd_loss 0.7525 (0.7833) lr 1.5878e-03 eta 0:13:52
epoch [17/50] batch [140/244] time 0.095 (0.101) data 0.000 (0.002) loss 1.7816 (2.0416) teacher_loss 0.8827 (1.0422) loss_zs_kd 0.3223 (0.4032) loss_oracle 0.4437 (0.4319) acc 71.8750 (72.4330) kd_loss 0.6770 (0.7834) lr 1.5878e-03 eta 0:13:44
epoch [17/50] batch [160/244] time 0.092 (0.101) data 0.000 (0.002) loss 1.9144 (2.0445) teacher_loss 0.9738 (1.0438) loss_zs_kd 0.4371 (0.4033) loss_oracle 0.3611 (0.4303) acc 71.8750 (72.4609) kd_loss 0.7600 (0.7856) lr 1.5878e-03 eta 0:13:37
epoch [17/50] batch [180/244] time 0.096 (0.100) data 0.000 (0.002) loss 1.7591 (2.0380) teacher_loss 0.5462 (1.0369) loss_zs_kd 0.3884 (0.4079) loss_oracle 0.4435 (0.4282) acc 81.2500 (72.6389) kd_loss 0.9912 (0.7870) lr 1.5878e-03 eta 0:13:34
epoch [17/50] batch [200/244] time 0.102 (0.101) data 0.000 (0.002) loss 1.7471 (2.0520) teacher_loss 0.7510 (1.0477) loss_zs_kd 0.3367 (0.4064) loss_oracle 0.3911 (0.4270) acc 75.0000 (72.3594) kd_loss 0.8005 (0.7908) lr 1.5878e-03 eta 0:13:33
epoch [17/50] batch [220/244] time 0.099 (0.101) data 0.000 (0.002) loss 1.8858 (2.0449) teacher_loss 0.8595 (1.0432) loss_zs_kd 0.4117 (0.4071) loss_oracle 0.3841 (0.4236) acc 68.7500 (72.5994) kd_loss 0.8342 (0.7898) lr 1.5878e-03 eta 0:13:32
epoch [17/50] batch [240/244] time 0.107 (0.101) data 0.000 (0.002) loss 2.1492 (2.0434) teacher_loss 1.0355 (1.0436) loss_zs_kd 0.3874 (0.4085) loss_oracle 0.4673 (0.4229) acc 71.8750 (72.7474) kd_loss 0.8801 (0.7884) lr 1.5878e-03 eta 0:13:34
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,832
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,038
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.9%, epoch: 15 *******
******* Domain p best val test acc: 90.9%, epoch: 15 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [18/50] batch [20/244] time 0.093 (0.117) data 0.000 (0.013) loss 2.0195 (2.0003) teacher_loss 1.0646 (1.0051) loss_zs_kd 0.3127 (0.4298) loss_oracle 0.3127 (0.4029) acc 71.8750 (72.0312) kd_loss 0.7985 (0.7937) lr 1.5358e-03 eta 0:15:36
epoch [18/50] batch [40/244] time 0.103 (0.107) data 0.000 (0.007) loss 2.0021 (2.0429) teacher_loss 1.1105 (1.0465) loss_zs_kd 0.4077 (0.4151) loss_oracle 0.3660 (0.4133) acc 65.6250 (71.6406) kd_loss 0.7086 (0.7897) lr 1.5358e-03 eta 0:14:17
epoch [18/50] batch [60/244] time 0.103 (0.106) data 0.000 (0.005) loss 1.9363 (2.0452) teacher_loss 1.1220 (1.0451) loss_zs_kd 0.3293 (0.4078) loss_oracle 0.3516 (0.4112) acc 81.2500 (72.3438) kd_loss 0.6385 (0.7945) lr 1.5358e-03 eta 0:14:04
epoch [18/50] batch [80/244] time 0.103 (0.104) data 0.000 (0.004) loss 1.7945 (2.0546) teacher_loss 0.9851 (1.0670) loss_zs_kd 0.3695 (0.4099) loss_oracle 0.3890 (0.4104) acc 81.2500 (72.1094) kd_loss 0.6149 (0.7824) lr 1.5358e-03 eta 0:13:49
epoch [18/50] batch [100/244] time 0.099 (0.106) data 0.000 (0.003) loss 2.5016 (2.0439) teacher_loss 1.4748 (1.0677) loss_zs_kd 0.4543 (0.4091) loss_oracle 0.3491 (0.4054) acc 62.5000 (72.1250) kd_loss 0.8523 (0.7735) lr 1.5358e-03 eta 0:14:00
epoch [18/50] batch [120/244] time 0.094 (0.104) data 0.000 (0.002) loss 2.5623 (2.0442) teacher_loss 1.6025 (1.0762) loss_zs_kd 0.3693 (0.4117) loss_oracle 0.4114 (0.4038) acc 59.3750 (71.8490) kd_loss 0.7541 (0.7661) lr 1.5358e-03 eta 0:13:46
epoch [18/50] batch [140/244] time 0.094 (0.103) data 0.000 (0.002) loss 1.8127 (2.0311) teacher_loss 0.7356 (1.0644) loss_zs_kd 0.2803 (0.4088) loss_oracle 0.3687 (0.4007) acc 68.7500 (72.1875) kd_loss 0.8928 (0.7663) lr 1.5358e-03 eta 0:13:34
epoch [18/50] batch [160/244] time 0.095 (0.102) data 0.000 (0.002) loss 2.0150 (2.0220) teacher_loss 1.2082 (1.0594) loss_zs_kd 0.4734 (0.4089) loss_oracle 0.3853 (0.4006) acc 59.3750 (72.0703) kd_loss 0.6141 (0.7623) lr 1.5358e-03 eta 0:13:24
epoch [18/50] batch [180/244] time 0.101 (0.101) data 0.000 (0.002) loss 1.4835 (2.0251) teacher_loss 0.5351 (1.0577) loss_zs_kd 0.2330 (0.4070) loss_oracle 0.4185 (0.4030) acc 81.2500 (72.1181) kd_loss 0.7391 (0.7659) lr 1.5358e-03 eta 0:13:15
epoch [18/50] batch [200/244] time 0.101 (0.101) data 0.000 (0.002) loss 1.5909 (2.0084) teacher_loss 0.9177 (1.0461) loss_zs_kd 0.3955 (0.4041) loss_oracle 0.3062 (0.4014) acc 75.0000 (72.4844) kd_loss 0.5201 (0.7615) lr 1.5358e-03 eta 0:13:09
epoch [18/50] batch [220/244] time 0.091 (0.100) data 0.000 (0.001) loss 1.9007 (2.0030) teacher_loss 0.9666 (1.0413) loss_zs_kd 0.4984 (0.4055) loss_oracle 0.3771 (0.3999) acc 75.0000 (72.5852) kd_loss 0.7455 (0.7617) lr 1.5358e-03 eta 0:13:01
epoch [18/50] batch [240/244] time 0.086 (0.099) data 0.000 (0.001) loss 2.0263 (2.0066) teacher_loss 1.1073 (1.0430) loss_zs_kd 0.4504 (0.4079) loss_oracle 0.3875 (0.3990) acc 71.8750 (72.5260) kd_loss 0.7253 (0.7641) lr 1.5358e-03 eta 0:12:52
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,842
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.2%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,042
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.4%
******* Domain p best val acc:      85.2%, epoch: 18 *******
******* Domain p best val test acc: 91.1%, epoch: 18 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [19/50] batch [20/244] time 0.094 (0.117) data 0.000 (0.015) loss 1.7361 (2.0417) teacher_loss 0.8474 (1.0885) loss_zs_kd 0.3563 (0.4054) loss_oracle 0.3655 (0.3992) acc 75.0000 (69.6875) kd_loss 0.7060 (0.7536) lr 1.4818e-03 eta 0:15:10
epoch [19/50] batch [40/244] time 0.109 (0.107) data 0.000 (0.008) loss 1.8318 (2.0406) teacher_loss 1.0666 (1.0806) loss_zs_kd 0.4615 (0.4105) loss_oracle 0.3472 (0.4010) acc 75.0000 (70.1562) kd_loss 0.5916 (0.7595) lr 1.4818e-03 eta 0:13:48
epoch [19/50] batch [60/244] time 0.099 (0.105) data 0.000 (0.005) loss 1.4382 (2.0613) teacher_loss 0.6475 (1.0948) loss_zs_kd 0.3086 (0.4159) loss_oracle 0.3603 (0.3972) acc 84.3750 (70.0000) kd_loss 0.6105 (0.7679) lr 1.4818e-03 eta 0:13:35
epoch [19/50] batch [80/244] time 0.099 (0.105) data 0.000 (0.004) loss 2.1548 (2.0316) teacher_loss 1.2957 (1.0735) loss_zs_kd 0.4074 (0.4180) loss_oracle 0.3745 (0.3971) acc 59.3750 (70.5859) kd_loss 0.6718 (0.7596) lr 1.4818e-03 eta 0:13:29
epoch [19/50] batch [100/244] time 0.097 (0.104) data 0.000 (0.003) loss 2.3703 (2.0294) teacher_loss 1.4090 (1.0716) loss_zs_kd 0.4755 (0.4091) loss_oracle 0.3582 (0.3958) acc 59.3750 (70.6250) kd_loss 0.7823 (0.7599) lr 1.4818e-03 eta 0:13:23
epoch [19/50] batch [120/244] time 0.098 (0.106) data 0.000 (0.003) loss 2.4994 (2.0350) teacher_loss 1.3785 (1.0762) loss_zs_kd 0.4392 (0.4087) loss_oracle 0.4750 (0.3971) acc 62.5000 (70.5990) kd_loss 0.8834 (0.7603) lr 1.4818e-03 eta 0:13:38
epoch [19/50] batch [140/244] time 0.104 (0.105) data 0.000 (0.002) loss 1.9317 (2.0181) teacher_loss 1.0752 (1.0637) loss_zs_kd 0.4724 (0.4084) loss_oracle 0.4294 (0.3944) acc 78.1250 (71.2723) kd_loss 0.6418 (0.7572) lr 1.4818e-03 eta 0:13:24
epoch [19/50] batch [160/244] time 0.093 (0.104) data 0.000 (0.002) loss 2.0376 (2.0140) teacher_loss 0.9825 (1.0580) loss_zs_kd 0.4323 (0.4117) loss_oracle 0.4089 (0.3941) acc 75.0000 (71.6016) kd_loss 0.8506 (0.7590) lr 1.4818e-03 eta 0:13:17
epoch [19/50] batch [180/244] time 0.108 (0.103) data 0.000 (0.002) loss 1.7830 (2.0079) teacher_loss 0.7503 (1.0508) loss_zs_kd 0.5089 (0.4150) loss_oracle 0.3936 (0.3930) acc 81.2500 (71.7882) kd_loss 0.8360 (0.7606) lr 1.4818e-03 eta 0:13:08
epoch [19/50] batch [200/244] time 0.097 (0.103) data 0.000 (0.002) loss 1.8897 (1.9900) teacher_loss 0.8430 (1.0337) loss_zs_kd 0.5430 (0.4206) loss_oracle 0.4427 (0.3914) acc 75.0000 (72.2344) kd_loss 0.8253 (0.7607) lr 1.4818e-03 eta 0:13:05
epoch [19/50] batch [220/244] time 0.099 (0.103) data 0.000 (0.002) loss 2.1695 (1.9942) teacher_loss 1.0985 (1.0373) loss_zs_kd 0.2597 (0.4204) loss_oracle 0.3341 (0.3887) acc 71.8750 (72.3153) kd_loss 0.9039 (0.7626) lr 1.4818e-03 eta 0:12:58
epoch [19/50] batch [240/244] time 0.090 (0.102) data 0.000 (0.001) loss 1.8548 (1.9794) teacher_loss 1.0491 (1.0265) loss_zs_kd 0.4355 (0.4199) loss_oracle 0.3774 (0.3891) acc 75.0000 (72.5521) kd_loss 0.6171 (0.7584) lr 1.4818e-03 eta 0:12:49
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,838
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.4%
******* Domain p best val acc:      85.2%, epoch: 18 *******
******* Domain p best val test acc: 91.1%, epoch: 18 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [20/50] batch [20/244] time 0.098 (0.115) data 0.000 (0.017) loss 1.9341 (1.9786) teacher_loss 1.0487 (0.9956) loss_zs_kd 0.4243 (0.4228) loss_oracle 0.4559 (0.4025) acc 75.0000 (73.9062) kd_loss 0.6575 (0.7818) lr 1.4258e-03 eta 0:14:31
epoch [20/50] batch [40/244] time 0.096 (0.108) data 0.000 (0.009) loss 1.9726 (2.0008) teacher_loss 0.9017 (0.9929) loss_zs_kd 0.3009 (0.4189) loss_oracle 0.4058 (0.4113) acc 78.1250 (73.8281) kd_loss 0.8680 (0.8023) lr 1.4258e-03 eta 0:13:32
epoch [20/50] batch [60/244] time 0.105 (0.108) data 0.001 (0.006) loss 2.0140 (1.9859) teacher_loss 0.9303 (0.9847) loss_zs_kd 0.5213 (0.4243) loss_oracle 0.5022 (0.4208) acc 71.8750 (73.5938) kd_loss 0.8326 (0.7908) lr 1.4258e-03 eta 0:13:26
epoch [20/50] batch [80/244] time 0.097 (0.106) data 0.000 (0.004) loss 1.9079 (1.9672) teacher_loss 0.9642 (0.9828) loss_zs_kd 0.4373 (0.4226) loss_oracle 0.4337 (0.4169) acc 68.7500 (73.7109) kd_loss 0.7269 (0.7759) lr 1.4258e-03 eta 0:13:16
epoch [20/50] batch [100/244] time 0.093 (0.105) data 0.000 (0.004) loss 2.1963 (1.9904) teacher_loss 1.3351 (1.0144) loss_zs_kd 0.3707 (0.4222) loss_oracle 0.3542 (0.4129) acc 75.0000 (72.9062) kd_loss 0.6842 (0.7695) lr 1.4258e-03 eta 0:13:01
epoch [20/50] batch [120/244] time 0.112 (0.107) data 0.000 (0.003) loss 1.9996 (1.9906) teacher_loss 1.0064 (1.0190) loss_zs_kd 0.4212 (0.4268) loss_oracle 0.3169 (0.4107) acc 71.8750 (73.0729) kd_loss 0.8347 (0.7663) lr 1.4258e-03 eta 0:13:13
epoch [20/50] batch [140/244] time 0.097 (0.106) data 0.000 (0.003) loss 2.1750 (2.0028) teacher_loss 1.3050 (1.0244) loss_zs_kd 0.3962 (0.4255) loss_oracle 0.4170 (0.4163) acc 62.5000 (72.9018) kd_loss 0.6615 (0.7703) lr 1.4258e-03 eta 0:13:06
epoch [20/50] batch [160/244] time 0.094 (0.105) data 0.000 (0.002) loss 1.4069 (1.9992) teacher_loss 0.5796 (1.0229) loss_zs_kd 0.2341 (0.4192) loss_oracle 0.4391 (0.4173) acc 81.2500 (72.9492) kd_loss 0.6077 (0.7676) lr 1.4258e-03 eta 0:13:00
epoch [20/50] batch [180/244] time 0.101 (0.105) data 0.001 (0.002) loss 2.2299 (1.9885) teacher_loss 1.2427 (1.0154) loss_zs_kd 0.5443 (0.4141) loss_oracle 0.3549 (0.4151) acc 71.8750 (73.1250) kd_loss 0.8097 (0.7656) lr 1.4258e-03 eta 0:12:54
epoch [20/50] batch [200/244] time 0.096 (0.104) data 0.000 (0.002) loss 1.6033 (1.9886) teacher_loss 0.6086 (1.0188) loss_zs_kd 0.4037 (0.4166) loss_oracle 0.4098 (0.4144) acc 78.1250 (72.7812) kd_loss 0.7898 (0.7626) lr 1.4258e-03 eta 0:12:47
epoch [20/50] batch [220/244] time 0.102 (0.104) data 0.000 (0.002) loss 1.8682 (1.9814) teacher_loss 0.9736 (1.0131) loss_zs_kd 0.5427 (0.4181) loss_oracle 0.4256 (0.4121) acc 75.0000 (72.8551) kd_loss 0.6818 (0.7623) lr 1.4258e-03 eta 0:12:40
epoch [20/50] batch [240/244] time 0.085 (0.103) data 0.000 (0.002) loss 1.8617 (1.9823) teacher_loss 0.8455 (1.0119) loss_zs_kd 0.3646 (0.4187) loss_oracle 0.3391 (0.4115) acc 78.1250 (72.9167) kd_loss 0.8466 (0.7647) lr 1.4258e-03 eta 0:12:31
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,833
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,030
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
******* Domain p best val acc:      85.2%, epoch: 18 *******
******* Domain p best val test acc: 91.1%, epoch: 18 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [21/50] batch [20/244] time 0.103 (0.134) data 0.000 (0.018) loss 1.7644 (1.9533) teacher_loss 0.7039 (0.9786) loss_zs_kd 0.3502 (0.4210) loss_oracle 0.3898 (0.4157) acc 84.3750 (75.0000) kd_loss 0.8656 (0.7668) lr 1.3681e-03 eta 0:16:20
epoch [21/50] batch [40/244] time 0.108 (0.120) data 0.001 (0.009) loss 1.4196 (1.9399) teacher_loss 0.5194 (0.9688) loss_zs_kd 0.4628 (0.4324) loss_oracle 0.4554 (0.4244) acc 84.3750 (74.5312) kd_loss 0.6725 (0.7589) lr 1.3681e-03 eta 0:14:30
epoch [21/50] batch [60/244] time 0.099 (0.115) data 0.000 (0.006) loss 1.7542 (1.9740) teacher_loss 0.8360 (1.0031) loss_zs_kd 0.3444 (0.4322) loss_oracle 0.4642 (0.4297) acc 68.7500 (73.1250) kd_loss 0.6861 (0.7560) lr 1.3681e-03 eta 0:13:52
epoch [21/50] batch [80/244] time 0.100 (0.111) data 0.000 (0.005) loss 1.7750 (1.9970) teacher_loss 0.7825 (1.0131) loss_zs_kd 0.6538 (0.4439) loss_oracle 0.4820 (0.4359) acc 71.8750 (72.7734) kd_loss 0.7515 (0.7659) lr 1.3681e-03 eta 0:13:25
epoch [21/50] batch [100/244] time 0.106 (0.109) data 0.000 (0.004) loss 1.6980 (2.0122) teacher_loss 0.8117 (1.0302) loss_zs_kd 0.4301 (0.4470) loss_oracle 0.4125 (0.4288) acc 78.1250 (72.3750) kd_loss 0.6800 (0.7676) lr 1.3681e-03 eta 0:13:04
epoch [21/50] batch [120/244] time 0.096 (0.109) data 0.000 (0.003) loss 1.7864 (2.0136) teacher_loss 0.7062 (1.0379) loss_zs_kd 0.4330 (0.4475) loss_oracle 0.3662 (0.4211) acc 84.3750 (72.2656) kd_loss 0.8971 (0.7651) lr 1.3681e-03 eta 0:13:04
epoch [21/50] batch [140/244] time 0.099 (0.108) data 0.000 (0.003) loss 2.4154 (2.0109) teacher_loss 1.3082 (1.0397) loss_zs_kd 0.4956 (0.4491) loss_oracle 0.4870 (0.4164) acc 56.2500 (72.3214) kd_loss 0.8636 (0.7630) lr 1.3681e-03 eta 0:12:54
epoch [21/50] batch [160/244] time 0.100 (0.107) data 0.000 (0.002) loss 2.4586 (2.0082) teacher_loss 1.3144 (1.0364) loss_zs_kd 0.4125 (0.4488) loss_oracle 0.3380 (0.4138) acc 68.7500 (72.4609) kd_loss 0.9752 (0.7649) lr 1.3681e-03 eta 0:12:48
epoch [21/50] batch [180/244] time 0.111 (0.107) data 0.000 (0.002) loss 1.7116 (1.9966) teacher_loss 0.5811 (1.0253) loss_zs_kd 0.3341 (0.4445) loss_oracle 0.4586 (0.4129) acc 81.2500 (72.7778) kd_loss 0.9012 (0.7649) lr 1.3681e-03 eta 0:12:41
epoch [21/50] batch [200/244] time 0.096 (0.106) data 0.000 (0.002) loss 1.7313 (1.9956) teacher_loss 0.7841 (1.0227) loss_zs_kd 0.5207 (0.4415) loss_oracle 0.3897 (0.4111) acc 68.7500 (72.6406) kd_loss 0.7523 (0.7673) lr 1.3681e-03 eta 0:12:35
epoch [21/50] batch [220/244] time 0.109 (0.106) data 0.000 (0.002) loss 2.0093 (1.9982) teacher_loss 1.0890 (1.0246) loss_zs_kd 0.4745 (0.4412) loss_oracle 0.3862 (0.4108) acc 68.7500 (72.6136) kd_loss 0.7272 (0.7682) lr 1.3681e-03 eta 0:12:30
epoch [21/50] batch [240/244] time 0.107 (0.105) data 0.000 (0.002) loss 1.8984 (2.0105) teacher_loss 0.9591 (1.0352) loss_zs_kd 0.4752 (0.4406) loss_oracle 0.3777 (0.4113) acc 71.8750 (72.4479) kd_loss 0.7505 (0.7697) lr 1.3681e-03 eta 0:12:26
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,835
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,021
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 90.1%
******* Domain p best val acc:      85.2%, epoch: 18 *******
******* Domain p best val test acc: 91.1%, epoch: 18 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [22/50] batch [20/244] time 0.122 (0.122) data 0.001 (0.015) loss 1.9723 (1.9948) teacher_loss 1.0159 (1.0351) loss_zs_kd 0.3891 (0.4341) loss_oracle 0.4026 (0.4177) acc 78.1250 (71.5625) kd_loss 0.7551 (0.7508) lr 1.3090e-03 eta 0:14:22
epoch [22/50] batch [40/244] time 0.096 (0.115) data 0.000 (0.008) loss 1.5561 (2.0126) teacher_loss 0.6152 (1.0515) loss_zs_kd 0.3166 (0.4292) loss_oracle 0.3693 (0.4055) acc 75.0000 (71.0938) kd_loss 0.7563 (0.7584) lr 1.3090e-03 eta 0:13:30
epoch [22/50] batch [60/244] time 0.110 (0.111) data 0.000 (0.005) loss 2.0371 (1.9573) teacher_loss 0.9011 (1.0106) loss_zs_kd 0.4297 (0.4399) loss_oracle 0.4568 (0.4079) acc 81.2500 (72.3438) kd_loss 0.9076 (0.7428) lr 1.3090e-03 eta 0:12:58
epoch [22/50] batch [80/244] time 0.096 (0.108) data 0.000 (0.004) loss 2.5240 (1.9605) teacher_loss 1.5561 (1.0089) loss_zs_kd 0.5450 (0.4455) loss_oracle 0.3977 (0.4080) acc 65.6250 (72.6953) kd_loss 0.7690 (0.7477) lr 1.3090e-03 eta 0:12:38
epoch [22/50] batch [100/244] time 0.113 (0.108) data 0.000 (0.003) loss 2.0313 (1.9518) teacher_loss 0.7979 (0.9892) loss_zs_kd 0.4868 (0.4450) loss_oracle 0.4921 (0.4180) acc 75.0000 (73.4062) kd_loss 0.9874 (0.7536) lr 1.3090e-03 eta 0:12:31
epoch [22/50] batch [120/244] time 0.106 (0.109) data 0.000 (0.003) loss 2.0070 (1.9553) teacher_loss 0.8426 (0.9822) loss_zs_kd 0.4137 (0.4502) loss_oracle 0.5028 (0.4247) acc 78.1250 (73.5677) kd_loss 0.9131 (0.7608) lr 1.3090e-03 eta 0:12:36
epoch [22/50] batch [140/244] time 0.107 (0.108) data 0.000 (0.002) loss 2.5238 (1.9565) teacher_loss 1.4259 (0.9840) loss_zs_kd 0.4643 (0.4452) loss_oracle 0.4617 (0.4276) acc 56.2500 (73.4375) kd_loss 0.8671 (0.7587) lr 1.3090e-03 eta 0:12:28
epoch [22/50] batch [160/244] time 0.108 (0.107) data 0.001 (0.002) loss 2.1453 (1.9738) teacher_loss 0.9935 (0.9967) loss_zs_kd 0.6070 (0.4514) loss_oracle 0.5279 (0.4278) acc 75.0000 (73.4180) kd_loss 0.8879 (0.7632) lr 1.3090e-03 eta 0:12:22
epoch [22/50] batch [180/244] time 0.110 (0.107) data 0.000 (0.002) loss 2.1314 (1.9815) teacher_loss 1.2559 (1.0016) loss_zs_kd 0.4649 (0.4473) loss_oracle 0.3839 (0.4264) acc 59.3750 (73.5417) kd_loss 0.6835 (0.7667) lr 1.3090e-03 eta 0:12:17
epoch [22/50] batch [200/244] time 0.093 (0.106) data 0.000 (0.002) loss 1.9250 (1.9822) teacher_loss 0.9771 (0.9983) loss_zs_kd 0.3376 (0.4502) loss_oracle 0.3920 (0.4273) acc 71.8750 (73.6250) kd_loss 0.7519 (0.7702) lr 1.3090e-03 eta 0:12:11
epoch [22/50] batch [220/244] time 0.107 (0.106) data 0.001 (0.002) loss 1.6630 (1.9816) teacher_loss 0.6094 (0.9940) loss_zs_kd 0.4518 (0.4482) loss_oracle 0.4473 (0.4285) acc 78.1250 (73.6790) kd_loss 0.8300 (0.7734) lr 1.3090e-03 eta 0:12:05
epoch [22/50] batch [240/244] time 0.107 (0.106) data 0.000 (0.002) loss 2.1349 (1.9983) teacher_loss 1.1009 (1.0063) loss_zs_kd 0.4728 (0.4495) loss_oracle 0.4398 (0.4311) acc 78.1250 (73.2552) kd_loss 0.8141 (0.7765) lr 1.3090e-03 eta 0:12:01
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,834
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.8%
******* Domain p best val acc:      85.2%, epoch: 18 *******
******* Domain p best val test acc: 91.1%, epoch: 18 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [23/50] batch [20/244] time 0.084 (0.112) data 0.000 (0.015) loss 1.7747 (2.0489) teacher_loss 0.9295 (1.0318) loss_zs_kd 0.3521 (0.4422) loss_oracle 0.3687 (0.4540) acc 75.0000 (71.2500) kd_loss 0.6608 (0.7901) lr 1.2487e-03 eta 0:12:43
epoch [23/50] batch [40/244] time 0.100 (0.102) data 0.000 (0.007) loss 1.9196 (2.0372) teacher_loss 0.9801 (1.0337) loss_zs_kd 0.4901 (0.4480) loss_oracle 0.5092 (0.4472) acc 71.8750 (72.2656) kd_loss 0.6849 (0.7800) lr 1.2487e-03 eta 0:11:35
epoch [23/50] batch [60/244] time 0.093 (0.099) data 0.001 (0.005) loss 2.0148 (2.0369) teacher_loss 0.9221 (1.0337) loss_zs_kd 0.5022 (0.4556) loss_oracle 0.4192 (0.4453) acc 75.0000 (72.8646) kd_loss 0.8831 (0.7805) lr 1.2487e-03 eta 0:11:09
epoch [23/50] batch [80/244] time 0.096 (0.099) data 0.000 (0.004) loss 1.8224 (2.0130) teacher_loss 0.8926 (1.0125) loss_zs_kd 0.3934 (0.4542) loss_oracle 0.3706 (0.4435) acc 71.8750 (73.3984) kd_loss 0.7444 (0.7788) lr 1.2487e-03 eta 0:11:06
epoch [23/50] batch [100/244] time 0.092 (0.099) data 0.000 (0.003) loss 2.2502 (1.9971) teacher_loss 1.2887 (1.0042) loss_zs_kd 0.3906 (0.4530) loss_oracle 0.4210 (0.4387) acc 59.3750 (73.3750) kd_loss 0.7510 (0.7736) lr 1.2487e-03 eta 0:11:05
epoch [23/50] batch [120/244] time 0.098 (0.101) data 0.000 (0.003) loss 2.1304 (1.9901) teacher_loss 1.1934 (1.0019) loss_zs_kd 0.3721 (0.4543) loss_oracle 0.4896 (0.4323) acc 68.7500 (73.4115) kd_loss 0.6922 (0.7721) lr 1.2487e-03 eta 0:11:17
epoch [23/50] batch [140/244] time 0.095 (0.100) data 0.000 (0.002) loss 1.8355 (1.9954) teacher_loss 0.9677 (1.0075) loss_zs_kd 0.3884 (0.4556) loss_oracle 0.4047 (0.4297) acc 84.3750 (73.2589) kd_loss 0.6654 (0.7731) lr 1.2487e-03 eta 0:11:11
epoch [23/50] batch [160/244] time 0.099 (0.100) data 0.000 (0.002) loss 2.3009 (2.0003) teacher_loss 1.3088 (1.0114) loss_zs_kd 0.4289 (0.4534) loss_oracle 0.4194 (0.4299) acc 62.5000 (73.1055) kd_loss 0.7824 (0.7739) lr 1.2487e-03 eta 0:11:07
epoch [23/50] batch [180/244] time 0.099 (0.100) data 0.000 (0.002) loss 1.8854 (2.0080) teacher_loss 0.8921 (1.0126) loss_zs_kd 0.3413 (0.4546) loss_oracle 0.4681 (0.4333) acc 78.1250 (73.1424) kd_loss 0.7593 (0.7788) lr 1.2487e-03 eta 0:11:04
epoch [23/50] batch [200/244] time 0.098 (0.100) data 0.001 (0.002) loss 1.8714 (1.9962) teacher_loss 0.7624 (1.0015) loss_zs_kd 0.5518 (0.4516) loss_oracle 0.4852 (0.4331) acc 78.1250 (73.2344) kd_loss 0.8663 (0.7781) lr 1.2487e-03 eta 0:11:03
epoch [23/50] batch [220/244] time 0.103 (0.100) data 0.000 (0.002) loss 2.0426 (2.0006) teacher_loss 1.2457 (1.0056) loss_zs_kd 0.5348 (0.4540) loss_oracle 0.4427 (0.4335) acc 65.6250 (73.0682) kd_loss 0.5756 (0.7783) lr 1.2487e-03 eta 0:11:03
epoch [23/50] batch [240/244] time 0.089 (0.100) data 0.000 (0.001) loss 1.5654 (2.0058) teacher_loss 0.6447 (1.0068) loss_zs_kd 0.4620 (0.4557) loss_oracle 0.4318 (0.4359) acc 90.6250 (73.0990) kd_loss 0.7048 (0.7810) lr 1.2487e-03 eta 0:11:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,840
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,042
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.5%
******* Domain p best val acc:      85.2%, epoch: 18 *******
******* Domain p best val test acc: 91.1%, epoch: 18 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [24/50] batch [20/244] time 0.102 (0.122) data 0.000 (0.017) loss 2.0164 (1.9547) teacher_loss 1.0754 (0.9400) loss_zs_kd 0.4849 (0.4437) loss_oracle 0.4393 (0.4376) acc 75.0000 (73.4375) kd_loss 0.7214 (0.7958) lr 1.1874e-03 eta 0:13:24
epoch [24/50] batch [40/244] time 0.097 (0.110) data 0.000 (0.009) loss 2.6248 (2.0252) teacher_loss 1.6279 (1.0265) loss_zs_kd 0.4384 (0.4409) loss_oracle 0.4860 (0.4473) acc 53.1250 (72.7344) kd_loss 0.7539 (0.7751) lr 1.1874e-03 eta 0:12:01
epoch [24/50] batch [60/244] time 0.099 (0.108) data 0.000 (0.006) loss 2.2833 (2.0554) teacher_loss 1.3081 (1.0544) loss_zs_kd 0.5821 (0.4518) loss_oracle 0.4759 (0.4526) acc 65.6250 (72.1875) kd_loss 0.7373 (0.7748) lr 1.1874e-03 eta 0:11:43
epoch [24/50] batch [80/244] time 0.094 (0.106) data 0.000 (0.004) loss 1.9476 (2.0481) teacher_loss 1.0288 (1.0470) loss_zs_kd 0.3833 (0.4630) loss_oracle 0.3854 (0.4517) acc 65.6250 (72.4609) kd_loss 0.7262 (0.7753) lr 1.1874e-03 eta 0:11:27
epoch [24/50] batch [100/244] time 0.099 (0.104) data 0.000 (0.004) loss 1.8659 (2.0208) teacher_loss 0.8555 (1.0216) loss_zs_kd 0.4714 (0.4563) loss_oracle 0.3817 (0.4485) acc 71.8750 (72.9062) kd_loss 0.8195 (0.7750) lr 1.1874e-03 eta 0:11:14
epoch [24/50] batch [120/244] time 0.149 (0.103) data 0.000 (0.003) loss 2.3431 (2.0239) teacher_loss 1.2411 (1.0256) loss_zs_kd 0.4665 (0.4513) loss_oracle 0.5107 (0.4493) acc 65.6250 (73.0469) kd_loss 0.8467 (0.7736) lr 1.1874e-03 eta 0:11:08
epoch [24/50] batch [140/244] time 0.102 (0.104) data 0.000 (0.003) loss 1.8692 (2.0324) teacher_loss 0.7723 (1.0269) loss_zs_kd 0.4087 (0.4502) loss_oracle 0.4836 (0.4547) acc 81.2500 (73.1696) kd_loss 0.8551 (0.7781) lr 1.1874e-03 eta 0:11:09
epoch [24/50] batch [160/244] time 0.100 (0.103) data 0.000 (0.002) loss 1.9960 (2.0096) teacher_loss 0.9317 (1.0094) loss_zs_kd 0.5554 (0.4459) loss_oracle 0.4519 (0.4507) acc 75.0000 (73.4766) kd_loss 0.8384 (0.7748) lr 1.1874e-03 eta 0:11:01
epoch [24/50] batch [180/244] time 0.100 (0.102) data 0.000 (0.002) loss 1.8986 (2.0179) teacher_loss 1.0532 (1.0227) loss_zs_kd 0.4640 (0.4417) loss_oracle 0.4674 (0.4473) acc 65.6250 (72.9514) kd_loss 0.6116 (0.7716) lr 1.1874e-03 eta 0:10:55
epoch [24/50] batch [200/244] time 0.099 (0.102) data 0.000 (0.002) loss 1.8807 (2.0087) teacher_loss 1.0031 (1.0123) loss_zs_kd 0.3916 (0.4413) loss_oracle 0.4198 (0.4449) acc 75.0000 (73.0938) kd_loss 0.6677 (0.7740) lr 1.1874e-03 eta 0:10:49
epoch [24/50] batch [220/244] time 0.092 (0.101) data 0.000 (0.002) loss 2.3635 (1.9947) teacher_loss 1.3565 (1.0009) loss_zs_kd 0.5032 (0.4405) loss_oracle 0.4443 (0.4425) acc 65.6250 (73.3665) kd_loss 0.7848 (0.7725) lr 1.1874e-03 eta 0:10:43
epoch [24/50] batch [240/244] time 0.088 (0.100) data 0.000 (0.002) loss 2.2680 (1.9975) teacher_loss 1.2614 (1.0013) loss_zs_kd 0.4676 (0.4415) loss_oracle 0.4283 (0.4427) acc 68.7500 (73.2552) kd_loss 0.7925 (0.7748) lr 1.1874e-03 eta 0:10:36
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,844
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.3%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.3%, epoch: 24 *******
******* Domain p best val test acc: 91.0%, epoch: 24 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [25/50] batch [20/244] time 0.091 (0.114) data 0.000 (0.014) loss 1.6526 (1.9700) teacher_loss 0.6945 (1.0230) loss_zs_kd 0.3865 (0.4088) loss_oracle 0.4552 (0.4183) acc 84.3750 (73.4375) kd_loss 0.7306 (0.7378) lr 1.1253e-03 eta 0:12:02
epoch [25/50] batch [40/244] time 0.096 (0.103) data 0.000 (0.007) loss 1.8585 (1.9831) teacher_loss 0.8135 (1.0008) loss_zs_kd 0.4493 (0.4019) loss_oracle 0.3863 (0.4215) acc 65.6250 (73.0469) kd_loss 0.8518 (0.7715) lr 1.1253e-03 eta 0:10:50
epoch [25/50] batch [60/244] time 0.099 (0.103) data 0.000 (0.005) loss 1.9587 (1.9642) teacher_loss 0.7957 (0.9799) loss_zs_kd 0.4313 (0.4123) loss_oracle 0.4445 (0.4253) acc 84.3750 (73.9062) kd_loss 0.9408 (0.7716) lr 1.1253e-03 eta 0:10:46
epoch [25/50] batch [80/244] time 0.112 (0.103) data 0.000 (0.004) loss 1.9858 (1.9916) teacher_loss 0.9026 (0.9992) loss_zs_kd 0.6777 (0.4357) loss_oracle 0.4475 (0.4281) acc 71.8750 (73.2422) kd_loss 0.8595 (0.7783) lr 1.1253e-03 eta 0:10:46
epoch [25/50] batch [100/244] time 0.103 (0.103) data 0.000 (0.003) loss 1.8964 (1.9906) teacher_loss 1.0146 (1.0005) loss_zs_kd 0.3661 (0.4484) loss_oracle 0.4604 (0.4300) acc 71.8750 (73.1875) kd_loss 0.6516 (0.7751) lr 1.1253e-03 eta 0:10:40
epoch [25/50] batch [120/244] time 0.102 (0.102) data 0.000 (0.003) loss 2.4906 (1.9866) teacher_loss 1.4334 (0.9972) loss_zs_kd 0.3831 (0.4526) loss_oracle 0.4648 (0.4306) acc 65.6250 (73.4115) kd_loss 0.8248 (0.7741) lr 1.1253e-03 eta 0:10:36
epoch [25/50] batch [140/244] time 0.098 (0.104) data 0.000 (0.002) loss 2.1136 (1.9953) teacher_loss 1.0668 (1.0054) loss_zs_kd 0.5748 (0.4564) loss_oracle 0.4140 (0.4328) acc 71.8750 (73.3482) kd_loss 0.8399 (0.7734) lr 1.1253e-03 eta 0:10:44
epoch [25/50] batch [160/244] time 0.096 (0.103) data 0.000 (0.002) loss 2.0770 (2.0018) teacher_loss 1.0506 (1.0084) loss_zs_kd 0.4912 (0.4569) loss_oracle 0.4398 (0.4324) acc 71.8750 (73.3789) kd_loss 0.8065 (0.7772) lr 1.1253e-03 eta 0:10:38
epoch [25/50] batch [180/244] time 0.100 (0.103) data 0.000 (0.002) loss 2.4748 (1.9992) teacher_loss 1.3875 (1.0058) loss_zs_kd 0.4096 (0.4551) loss_oracle 0.4679 (0.4336) acc 65.6250 (73.3681) kd_loss 0.8533 (0.7766) lr 1.1253e-03 eta 0:10:35
epoch [25/50] batch [200/244] time 0.099 (0.103) data 0.000 (0.002) loss 1.9436 (2.0049) teacher_loss 0.8158 (1.0090) loss_zs_kd 0.5912 (0.4535) loss_oracle 0.5134 (0.4340) acc 81.2500 (73.3594) kd_loss 0.8711 (0.7789) lr 1.1253e-03 eta 0:10:33
epoch [25/50] batch [220/244] time 0.099 (0.103) data 0.000 (0.002) loss 1.7283 (2.0026) teacher_loss 0.7981 (1.0078) loss_zs_kd 0.5831 (0.4520) loss_oracle 0.3615 (0.4336) acc 81.2500 (73.3523) kd_loss 0.7495 (0.7781) lr 1.1253e-03 eta 0:10:32
epoch [25/50] batch [240/244] time 0.112 (0.103) data 0.000 (0.001) loss 1.6014 (1.9995) teacher_loss 0.8597 (1.0068) loss_zs_kd 0.3979 (0.4531) loss_oracle 0.4102 (0.4337) acc 78.1250 (73.3464) kd_loss 0.5366 (0.7758) lr 1.1253e-03 eta 0:10:31
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,849
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      85.5%, epoch: 25 *******
******* Domain p best val test acc: 90.9%, epoch: 25 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [26/50] batch [20/244] time 0.104 (0.119) data 0.001 (0.015) loss 1.7878 (1.8828) teacher_loss 0.8119 (0.9411) loss_zs_kd 0.4394 (0.4580) loss_oracle 0.4164 (0.4348) acc 78.1250 (74.3750) kd_loss 0.7677 (0.7243) lr 1.0628e-03 eta 0:12:03
epoch [26/50] batch [40/244] time 0.096 (0.108) data 0.000 (0.008) loss 2.1852 (1.8835) teacher_loss 1.1282 (0.9040) loss_zs_kd 0.3941 (0.4675) loss_oracle 0.4214 (0.4374) acc 71.8750 (75.1562) kd_loss 0.8463 (0.7607) lr 1.0628e-03 eta 0:10:57
epoch [26/50] batch [60/244] time 0.102 (0.105) data 0.000 (0.005) loss 1.5925 (1.9207) teacher_loss 0.6715 (0.9412) loss_zs_kd 0.4221 (0.4590) loss_oracle 0.4307 (0.4375) acc 87.5000 (74.5833) kd_loss 0.7057 (0.7608) lr 1.0628e-03 eta 0:10:35
epoch [26/50] batch [80/244] time 0.104 (0.103) data 0.000 (0.004) loss 1.8983 (1.9390) teacher_loss 0.9148 (0.9530) loss_zs_kd 0.4256 (0.4588) loss_oracle 0.4672 (0.4389) acc 75.0000 (74.3750) kd_loss 0.7499 (0.7665) lr 1.0628e-03 eta 0:10:20
epoch [26/50] batch [100/244] time 0.096 (0.102) data 0.000 (0.003) loss 2.3589 (1.9353) teacher_loss 1.2755 (0.9598) loss_zs_kd 0.4669 (0.4598) loss_oracle 0.4228 (0.4314) acc 59.3750 (74.3750) kd_loss 0.8720 (0.7598) lr 1.0628e-03 eta 0:10:14
epoch [26/50] batch [120/244] time 0.093 (0.101) data 0.000 (0.003) loss 1.9874 (1.9479) teacher_loss 0.8764 (0.9659) loss_zs_kd 0.4849 (0.4561) loss_oracle 0.4101 (0.4315) acc 71.8750 (73.9323) kd_loss 0.9060 (0.7663) lr 1.0628e-03 eta 0:10:06
epoch [26/50] batch [140/244] time 0.102 (0.103) data 0.000 (0.002) loss 2.3498 (1.9629) teacher_loss 1.4053 (0.9790) loss_zs_kd 0.3691 (0.4554) loss_oracle 0.4243 (0.4319) acc 68.7500 (73.9732) kd_loss 0.7324 (0.7680) lr 1.0628e-03 eta 0:10:11
epoch [26/50] batch [160/244] time 0.099 (0.102) data 0.000 (0.002) loss 2.0041 (1.9743) teacher_loss 1.1654 (0.9901) loss_zs_kd 0.4868 (0.4571) loss_oracle 0.4417 (0.4326) acc 65.6250 (73.7500) kd_loss 0.6178 (0.7679) lr 1.0628e-03 eta 0:10:07
epoch [26/50] batch [180/244] time 0.104 (0.102) data 0.000 (0.002) loss 1.6552 (1.9642) teacher_loss 0.5941 (0.9788) loss_zs_kd 0.5440 (0.4548) loss_oracle 0.4693 (0.4324) acc 78.1250 (74.1319) kd_loss 0.8264 (0.7693) lr 1.0628e-03 eta 0:10:02
epoch [26/50] batch [200/244] time 0.094 (0.102) data 0.000 (0.002) loss 1.5018 (1.9670) teacher_loss 0.6114 (0.9838) loss_zs_kd 0.4443 (0.4556) loss_oracle 0.4765 (0.4312) acc 87.5000 (74.0469) kd_loss 0.6521 (0.7676) lr 1.0628e-03 eta 0:09:58
epoch [26/50] batch [220/244] time 0.099 (0.101) data 0.000 (0.002) loss 1.9864 (1.9757) teacher_loss 1.0143 (0.9931) loss_zs_kd 0.4063 (0.4558) loss_oracle 0.3858 (0.4287) acc 75.0000 (73.8636) kd_loss 0.7792 (0.7682) lr 1.0628e-03 eta 0:09:54
epoch [26/50] batch [240/244] time 0.088 (0.100) data 0.000 (0.001) loss 2.0794 (1.9795) teacher_loss 0.9305 (0.9959) loss_zs_kd 0.2460 (0.4536) loss_oracle 0.4971 (0.4292) acc 75.0000 (73.8411) kd_loss 0.9003 (0.7690) lr 1.0628e-03 eta 0:09:48
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,840
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,048
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.8%
******* Domain p best val acc:      85.5%, epoch: 25 *******
******* Domain p best val test acc: 90.9%, epoch: 25 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [27/50] batch [20/244] time 0.116 (0.130) data 0.000 (0.018) loss 1.9256 (1.9192) teacher_loss 0.9686 (0.9234) loss_zs_kd 0.5086 (0.4261) loss_oracle 0.4315 (0.4306) acc 68.7500 (75.9375) kd_loss 0.7412 (0.7805) lr 1.0000e-03 eta 0:12:41
epoch [27/50] batch [40/244] time 0.098 (0.119) data 0.000 (0.009) loss 1.4748 (1.9467) teacher_loss 0.5616 (0.9360) loss_zs_kd 0.3395 (0.4418) loss_oracle 0.4059 (0.4348) acc 84.3750 (76.0938) kd_loss 0.7103 (0.7933) lr 1.0000e-03 eta 0:11:29
epoch [27/50] batch [60/244] time 0.096 (0.112) data 0.000 (0.006) loss 2.1275 (1.9722) teacher_loss 1.0722 (0.9696) loss_zs_kd 0.4565 (0.4554) loss_oracle 0.4157 (0.4264) acc 68.7500 (74.6875) kd_loss 0.8474 (0.7894) lr 1.0000e-03 eta 0:10:49
epoch [27/50] batch [80/244] time 0.102 (0.109) data 0.000 (0.005) loss 1.9849 (1.9692) teacher_loss 1.0942 (0.9790) loss_zs_kd 0.5290 (0.4655) loss_oracle 0.4529 (0.4271) acc 75.0000 (74.3750) kd_loss 0.6643 (0.7767) lr 1.0000e-03 eta 0:10:27
epoch [27/50] batch [100/244] time 0.094 (0.107) data 0.000 (0.004) loss 1.7354 (1.9465) teacher_loss 0.7987 (0.9658) loss_zs_kd 0.4335 (0.4745) loss_oracle 0.4853 (0.4276) acc 81.2500 (74.6562) kd_loss 0.6941 (0.7670) lr 1.0000e-03 eta 0:10:13
epoch [27/50] batch [120/244] time 0.097 (0.105) data 0.000 (0.003) loss 1.6030 (1.9502) teacher_loss 0.4818 (0.9655) loss_zs_kd 0.5359 (0.4800) loss_oracle 0.5354 (0.4343) acc 87.5000 (74.5312) kd_loss 0.8534 (0.7676) lr 1.0000e-03 eta 0:10:03
epoch [27/50] batch [140/244] time 0.103 (0.104) data 0.000 (0.003) loss 1.7625 (1.9367) teacher_loss 0.7793 (0.9563) loss_zs_kd 0.3895 (0.4793) loss_oracle 0.4768 (0.4348) acc 75.0000 (74.6875) kd_loss 0.7448 (0.7630) lr 1.0000e-03 eta 0:09:55
epoch [27/50] batch [160/244] time 0.111 (0.105) data 0.000 (0.003) loss 1.7763 (1.9276) teacher_loss 0.8245 (0.9502) loss_zs_kd 0.4837 (0.4804) loss_oracle 0.3486 (0.4359) acc 75.0000 (74.9023) kd_loss 0.7775 (0.7594) lr 1.0000e-03 eta 0:09:59
epoch [27/50] batch [180/244] time 0.107 (0.105) data 0.000 (0.002) loss 1.9247 (1.9304) teacher_loss 0.9238 (0.9521) loss_zs_kd 0.4781 (0.4796) loss_oracle 0.4359 (0.4346) acc 75.0000 (75.0521) kd_loss 0.7830 (0.7611) lr 1.0000e-03 eta 0:09:56
epoch [27/50] batch [200/244] time 0.103 (0.105) data 0.000 (0.002) loss 2.0362 (1.9379) teacher_loss 1.0521 (0.9591) loss_zs_kd 0.4625 (0.4774) loss_oracle 0.4455 (0.4344) acc 78.1250 (74.7656) kd_loss 0.7614 (0.7617) lr 1.0000e-03 eta 0:09:53
epoch [27/50] batch [220/244] time 0.104 (0.105) data 0.001 (0.002) loss 1.8204 (1.9351) teacher_loss 0.8716 (0.9552) loss_zs_kd 0.5201 (0.4775) loss_oracle 0.4438 (0.4357) acc 78.1250 (74.8153) kd_loss 0.7269 (0.7621) lr 1.0000e-03 eta 0:09:51
epoch [27/50] batch [240/244] time 0.105 (0.105) data 0.000 (0.002) loss 2.1532 (1.9391) teacher_loss 1.1932 (0.9598) loss_zs_kd 0.3757 (0.4741) loss_oracle 0.3218 (0.4353) acc 75.0000 (74.7917) kd_loss 0.7991 (0.7617) lr 1.0000e-03 eta 0:09:48
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,832
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,056
* accuracy: 91.4%
* error: 8.6%
* macro_f1: 90.9%
******* Domain p best val acc:      85.5%, epoch: 25 *******
******* Domain p best val test acc: 90.9%, epoch: 25 *******
******* Domain p best test acc:     91.5%, epoch: 10 *******
epoch [28/50] batch [20/244] time 0.105 (0.127) data 0.000 (0.018) loss 2.2983 (1.9350) teacher_loss 1.0608 (0.9367) loss_zs_kd 0.5333 (0.4441) loss_oracle 0.4463 (0.4211) acc 75.0000 (75.4688) kd_loss 1.0144 (0.7877) lr 9.3721e-04 eta 0:11:50
epoch [28/50] batch [40/244] time 0.097 (0.114) data 0.000 (0.009) loss 2.2009 (1.9551) teacher_loss 1.0499 (0.9709) loss_zs_kd 0.5290 (0.4781) loss_oracle 0.5551 (0.4306) acc 75.0000 (74.0625) kd_loss 0.8734 (0.7689) lr 9.3721e-04 eta 0:10:35
epoch [28/50] batch [60/244] time 0.114 (0.110) data 0.000 (0.006) loss 2.0880 (1.9445) teacher_loss 1.0665 (0.9677) loss_zs_kd 0.4668 (0.4709) loss_oracle 0.4328 (0.4294) acc 75.0000 (74.3750) kd_loss 0.8050 (0.7621) lr 9.3721e-04 eta 0:10:10
epoch [28/50] batch [80/244] time 0.097 (0.107) data 0.000 (0.005) loss 2.2952 (1.9880) teacher_loss 1.2417 (1.0024) loss_zs_kd 0.6428 (0.4744) loss_oracle 0.4675 (0.4367) acc 68.7500 (73.5547) kd_loss 0.8197 (0.7673) lr 9.3721e-04 eta 0:09:53
epoch [28/50] batch [100/244] time 0.105 (0.106) data 0.000 (0.004) loss 2.1620 (1.9906) teacher_loss 1.2245 (1.0038) loss_zs_kd 0.5021 (0.4758) loss_oracle 0.4161 (0.4398) acc 71.8750 (73.2500) kd_loss 0.7295 (0.7670) lr 9.3721e-04 eta 0:09:43
epoch [28/50] batch [120/244] time 0.100 (0.105) data 0.000 (0.003) loss 1.9539 (1.9916) teacher_loss 1.0028 (1.0052) loss_zs_kd 0.4342 (0.4790) loss_oracle 0.4513 (0.4408) acc 75.0000 (73.3333) kd_loss 0.7255 (0.7660) lr 9.3721e-04 eta 0:09:35
epoch [28/50] batch [140/244] time 0.102 (0.104) data 0.000 (0.003) loss 2.2793 (1.9807) teacher_loss 1.1504 (0.9949) loss_zs_kd 0.4915 (0.4774) loss_oracle 0.4806 (0.4388) acc 59.3750 (73.4821) kd_loss 0.8886 (0.7664) lr 9.3721e-04 eta 0:09:28
epoch [28/50] batch [160/244] time 0.099 (0.105) data 0.000 (0.002) loss 2.2250 (1.9725) teacher_loss 1.2315 (0.9909) loss_zs_kd 0.7085 (0.4782) loss_oracle 0.5430 (0.4375) acc 59.3750 (73.4375) kd_loss 0.7220 (0.7629) lr 9.3721e-04 eta 0:09:30
epoch [28/50] batch [180/244] time 0.102 (0.104) data 0.000 (0.002) loss 1.8173 (1.9673) teacher_loss 0.8120 (0.9837) loss_zs_kd 0.4723 (0.4760) loss_oracle 0.4244 (0.4394) acc 84.3750 (73.7500) kd_loss 0.7931 (0.7640) lr 9.3721e-04 eta 0:09:25
epoch [28/50] batch [200/244] time 0.090 (0.103) data 0.000 (0.002) loss 1.7726 (1.9532) teacher_loss 0.8075 (0.9751) loss_zs_kd 0.5723 (0.4748) loss_oracle 0.4550 (0.4374) acc 75.0000 (73.9375) kd_loss 0.7376 (0.7594) lr 9.3721e-04 eta 0:09:19
epoch [28/50] batch [220/244] time 0.101 (0.103) data 0.000 (0.002) loss 1.7520 (1.9434) teacher_loss 0.7136 (0.9676) loss_zs_kd 0.4926 (0.4714) loss_oracle 0.4483 (0.4350) acc 81.2500 (74.1335) kd_loss 0.8143 (0.7583) lr 9.3721e-04 eta 0:09:14
epoch [28/50] batch [240/244] time 0.108 (0.103) data 0.000 (0.002) loss 1.8702 (1.9433) teacher_loss 0.9738 (0.9661) loss_zs_kd 0.3265 (0.4689) loss_oracle 0.4076 (0.4335) acc 75.0000 (74.1667) kd_loss 0.6925 (0.7604) lr 9.3721e-04 eta 0:09:12
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,838
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,062
* accuracy: 91.5%
* error: 8.5%
* macro_f1: 91.1%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      85.5%, epoch: 25 *******
******* Domain p best val test acc: 90.9%, epoch: 25 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [29/50] batch [20/244] time 0.095 (0.106) data 0.000 (0.014) loss 1.6988 (1.9217) teacher_loss 0.7969 (0.9467) loss_zs_kd 0.4350 (0.4667) loss_oracle 0.3755 (0.4268) acc 78.1250 (75.7812) kd_loss 0.7141 (0.7616) lr 8.7467e-04 eta 0:09:27
epoch [29/50] batch [40/244] time 0.085 (0.099) data 0.000 (0.007) loss 1.9973 (1.9587) teacher_loss 1.1389 (0.9820) loss_zs_kd 0.4088 (0.4723) loss_oracle 0.3629 (0.4254) acc 68.7500 (74.1406) kd_loss 0.6770 (0.7640) lr 8.7467e-04 eta 0:08:49
epoch [29/50] batch [60/244] time 0.099 (0.097) data 0.000 (0.005) loss 2.1531 (1.9665) teacher_loss 1.2523 (0.9951) loss_zs_kd 0.3928 (0.4569) loss_oracle 0.3907 (0.4212) acc 71.8750 (73.4896) kd_loss 0.7055 (0.7608) lr 8.7467e-04 eta 0:08:34
epoch [29/50] batch [80/244] time 0.084 (0.096) data 0.000 (0.004) loss 1.3615 (1.9665) teacher_loss 0.4400 (0.9994) loss_zs_kd 0.4831 (0.4606) loss_oracle 0.3579 (0.4133) acc 87.5000 (73.5547) kd_loss 0.7425 (0.7604) lr 8.7467e-04 eta 0:08:26
epoch [29/50] batch [100/244] time 0.095 (0.095) data 0.000 (0.003) loss 2.0736 (1.9696) teacher_loss 1.0261 (1.0131) loss_zs_kd 0.3593 (0.4648) loss_oracle 0.4290 (0.4122) acc 78.1250 (73.1562) kd_loss 0.8330 (0.7504) lr 8.7467e-04 eta 0:08:21
epoch [29/50] batch [120/244] time 0.084 (0.094) data 0.000 (0.002) loss 2.1035 (1.9647) teacher_loss 1.1340 (1.0103) loss_zs_kd 0.5727 (0.4670) loss_oracle 0.4344 (0.4134) acc 68.7500 (73.3854) kd_loss 0.7523 (0.7476) lr 8.7467e-04 eta 0:08:14
epoch [29/50] batch [140/244] time 0.099 (0.094) data 0.000 (0.002) loss 2.5305 (1.9654) teacher_loss 1.6921 (1.0135) loss_zs_kd 0.6744 (0.4676) loss_oracle 0.4551 (0.4122) acc 59.3750 (73.3259) kd_loss 0.6109 (0.7457) lr 8.7467e-04 eta 0:08:11
epoch [29/50] batch [160/244] time 0.085 (0.094) data 0.000 (0.002) loss 1.6269 (1.9499) teacher_loss 0.7404 (1.0028) loss_zs_kd 0.5299 (0.4666) loss_oracle 0.5006 (0.4130) acc 81.2500 (73.5352) kd_loss 0.6361 (0.7406) lr 8.7467e-04 eta 0:08:08
epoch [29/50] batch [180/244] time 0.097 (0.095) data 0.000 (0.002) loss 2.6318 (1.9618) teacher_loss 1.7120 (1.0128) loss_zs_kd 0.3955 (0.4636) loss_oracle 0.4722 (0.4155) acc 56.2500 (73.4201) kd_loss 0.6837 (0.7413) lr 8.7467e-04 eta 0:08:13
epoch [29/50] batch [200/244] time 0.086 (0.095) data 0.000 (0.002) loss 2.0936 (1.9593) teacher_loss 1.2574 (1.0068) loss_zs_kd 0.5189 (0.4630) loss_oracle 0.4246 (0.4193) acc 65.6250 (73.4219) kd_loss 0.6239 (0.7428) lr 8.7467e-04 eta 0:08:10
epoch [29/50] batch [220/244] time 0.093 (0.095) data 0.000 (0.001) loss 1.6579 (1.9591) teacher_loss 0.6230 (1.0020) loss_zs_kd 0.3754 (0.4618) loss_oracle 0.4487 (0.4251) acc 84.3750 (73.5938) kd_loss 0.8105 (0.7445) lr 8.7467e-04 eta 0:08:07
epoch [29/50] batch [240/244] time 0.085 (0.094) data 0.000 (0.001) loss 1.7274 (1.9530) teacher_loss 0.6588 (0.9935) loss_zs_kd 0.3616 (0.4621) loss_oracle 0.5081 (0.4271) acc 87.5000 (73.7630) kd_loss 0.8146 (0.7460) lr 8.7467e-04 eta 0:08:04
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,846
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,045
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      85.5%, epoch: 25 *******
******* Domain p best val test acc: 90.9%, epoch: 25 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [30/50] batch [20/244] time 0.123 (0.138) data 0.000 (0.018) loss 1.5953 (1.8843) teacher_loss 0.6264 (0.9406) loss_zs_kd 0.3775 (0.4362) loss_oracle 0.4474 (0.4310) acc 81.2500 (75.3125) kd_loss 0.7451 (0.7282) lr 8.1262e-04 eta 0:11:46
epoch [30/50] batch [40/244] time 0.117 (0.125) data 0.000 (0.009) loss 1.6470 (1.9108) teacher_loss 0.6878 (0.9452) loss_zs_kd 0.4061 (0.4422) loss_oracle 0.4690 (0.4366) acc 78.1250 (75.3906) kd_loss 0.7247 (0.7473) lr 8.1262e-04 eta 0:10:34
epoch [30/50] batch [60/244] time 0.103 (0.118) data 0.000 (0.006) loss 1.8135 (1.9323) teacher_loss 0.7645 (0.9660) loss_zs_kd 0.5208 (0.4489) loss_oracle 0.4831 (0.4341) acc 75.0000 (74.4792) kd_loss 0.8075 (0.7492) lr 8.1262e-04 eta 0:09:55
epoch [30/50] batch [80/244] time 0.099 (0.114) data 0.000 (0.005) loss 1.6575 (1.9406) teacher_loss 0.7469 (0.9714) loss_zs_kd 0.5107 (0.4494) loss_oracle 0.3927 (0.4378) acc 71.8750 (74.2578) kd_loss 0.7142 (0.7503) lr 8.1262e-04 eta 0:09:34
epoch [30/50] batch [100/244] time 0.101 (0.112) data 0.000 (0.004) loss 1.4780 (1.9464) teacher_loss 0.6330 (0.9796) loss_zs_kd 0.3775 (0.4623) loss_oracle 0.3711 (0.4367) acc 87.5000 (74.2188) kd_loss 0.6594 (0.7484) lr 8.1262e-04 eta 0:09:22
epoch [30/50] batch [120/244] time 0.103 (0.110) data 0.000 (0.003) loss 1.7367 (1.9404) teacher_loss 0.8947 (0.9728) loss_zs_kd 0.4007 (0.4649) loss_oracle 0.4140 (0.4362) acc 78.1250 (74.3229) kd_loss 0.6350 (0.7495) lr 8.1262e-04 eta 0:09:11
epoch [30/50] batch [140/244] time 0.100 (0.109) data 0.001 (0.003) loss 1.6086 (1.9275) teacher_loss 0.6170 (0.9558) loss_zs_kd 0.6942 (0.4667) loss_oracle 0.4521 (0.4332) acc 81.2500 (74.7321) kd_loss 0.7655 (0.7551) lr 8.1262e-04 eta 0:09:03
epoch [30/50] batch [160/244] time 0.101 (0.108) data 0.000 (0.002) loss 1.5566 (1.9285) teacher_loss 0.6571 (0.9605) loss_zs_kd 0.4997 (0.4733) loss_oracle 0.4656 (0.4328) acc 78.1250 (74.5508) kd_loss 0.6666 (0.7516) lr 8.1262e-04 eta 0:08:55
epoch [30/50] batch [180/244] time 0.098 (0.109) data 0.000 (0.002) loss 2.1561 (1.9299) teacher_loss 1.0116 (0.9612) loss_zs_kd 0.5908 (0.4753) loss_oracle 0.4587 (0.4327) acc 81.2500 (74.5486) kd_loss 0.9151 (0.7524) lr 8.1262e-04 eta 0:08:57
epoch [30/50] batch [200/244] time 0.111 (0.108) data 0.000 (0.002) loss 1.8644 (1.9301) teacher_loss 0.8083 (0.9597) loss_zs_kd 0.4344 (0.4760) loss_oracle 0.4719 (0.4342) acc 75.0000 (74.4844) kd_loss 0.8202 (0.7533) lr 8.1262e-04 eta 0:08:53
epoch [30/50] batch [220/244] time 0.099 (0.108) data 0.000 (0.002) loss 1.9830 (1.9381) teacher_loss 0.9565 (0.9670) loss_zs_kd 0.4871 (0.4781) loss_oracle 0.4374 (0.4343) acc 71.8750 (74.3324) kd_loss 0.8079 (0.7539) lr 8.1262e-04 eta 0:08:49
epoch [30/50] batch [240/244] time 0.108 (0.108) data 0.000 (0.002) loss 1.8978 (1.9498) teacher_loss 0.9095 (0.9770) loss_zs_kd 0.4598 (0.4765) loss_oracle 0.4686 (0.4337) acc 68.7500 (73.9714) kd_loss 0.7540 (0.7559) lr 8.1262e-04 eta 0:08:45
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,849
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,048
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.7%
******* Domain p best val acc:      85.5%, epoch: 25 *******
******* Domain p best val test acc: 90.9%, epoch: 25 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [31/50] batch [20/244] time 0.116 (0.116) data 0.001 (0.014) loss 1.6080 (1.9806) teacher_loss 0.6276 (0.9580) loss_zs_kd 0.4852 (0.4522) loss_oracle 0.4594 (0.4315) acc 78.1250 (72.8125) kd_loss 0.7506 (0.8068) lr 7.5131e-04 eta 0:09:25
epoch [31/50] batch [40/244] time 0.100 (0.111) data 0.000 (0.007) loss 1.9076 (1.9668) teacher_loss 0.9773 (0.9621) loss_zs_kd 0.4759 (0.4658) loss_oracle 0.4368 (0.4255) acc 78.1250 (73.4375) kd_loss 0.7120 (0.7920) lr 7.5131e-04 eta 0:08:56
epoch [31/50] batch [60/244] time 0.100 (0.108) data 0.001 (0.005) loss 2.2990 (1.9827) teacher_loss 1.3519 (0.9936) loss_zs_kd 0.4577 (0.4612) loss_oracle 0.4689 (0.4318) acc 65.6250 (73.1250) kd_loss 0.7126 (0.7731) lr 7.5131e-04 eta 0:08:40
epoch [31/50] batch [80/244] time 0.099 (0.107) data 0.000 (0.004) loss 2.3025 (1.9523) teacher_loss 1.2742 (0.9604) loss_zs_kd 0.4611 (0.4658) loss_oracle 0.4800 (0.4347) acc 71.8750 (74.4141) kd_loss 0.7883 (0.7746) lr 7.5131e-04 eta 0:08:31
epoch [31/50] batch [100/244] time 0.110 (0.106) data 0.001 (0.003) loss 2.0294 (1.9283) teacher_loss 1.0839 (0.9444) loss_zs_kd 0.6362 (0.4713) loss_oracle 0.4843 (0.4316) acc 65.6250 (74.5000) kd_loss 0.7033 (0.7681) lr 7.5131e-04 eta 0:08:26
epoch [31/50] batch [120/244] time 0.098 (0.105) data 0.001 (0.003) loss 2.1629 (1.9475) teacher_loss 1.1225 (0.9619) loss_zs_kd 0.7858 (0.4786) loss_oracle 0.4536 (0.4331) acc 71.8750 (73.8281) kd_loss 0.8135 (0.7691) lr 7.5131e-04 eta 0:08:20
epoch [31/50] batch [140/244] time 0.103 (0.105) data 0.000 (0.002) loss 1.6394 (1.9635) teacher_loss 0.6293 (0.9739) loss_zs_kd 0.4522 (0.4793) loss_oracle 0.4303 (0.4368) acc 87.5000 (73.7277) kd_loss 0.7949 (0.7712) lr 7.5131e-04 eta 0:08:17
epoch [31/50] batch [160/244] time 0.104 (0.105) data 0.000 (0.002) loss 2.0277 (1.9521) teacher_loss 1.0504 (0.9591) loss_zs_kd 0.4520 (0.4774) loss_oracle 0.4942 (0.4394) acc 78.1250 (74.1797) kd_loss 0.7303 (0.7734) lr 7.5131e-04 eta 0:08:14
epoch [31/50] batch [180/244] time 0.097 (0.106) data 0.000 (0.002) loss 1.7446 (1.9471) teacher_loss 0.7027 (0.9534) loss_zs_kd 0.4542 (0.4767) loss_oracle 0.4102 (0.4402) acc 87.5000 (74.5312) kd_loss 0.8368 (0.7735) lr 7.5131e-04 eta 0:08:17
epoch [31/50] batch [200/244] time 0.096 (0.105) data 0.000 (0.002) loss 2.5750 (1.9506) teacher_loss 1.4316 (0.9578) loss_zs_kd 0.6031 (0.4789) loss_oracle 0.4480 (0.4417) acc 65.6250 (74.2656) kd_loss 0.9193 (0.7720) lr 7.5131e-04 eta 0:08:13
epoch [31/50] batch [220/244] time 0.100 (0.105) data 0.000 (0.002) loss 1.9295 (1.9547) teacher_loss 0.9293 (0.9625) loss_zs_kd 0.4165 (0.4779) loss_oracle 0.4398 (0.4409) acc 65.6250 (73.9915) kd_loss 0.7802 (0.7718) lr 7.5131e-04 eta 0:08:10
epoch [31/50] batch [240/244] time 0.107 (0.105) data 0.000 (0.001) loss 1.7635 (1.9553) teacher_loss 0.7114 (0.9637) loss_zs_kd 0.5140 (0.4795) loss_oracle 0.5063 (0.4415) acc 78.1250 (73.9974) kd_loss 0.7989 (0.7708) lr 7.5131e-04 eta 0:08:08
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,854
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 84.6%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.5%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [32/50] batch [20/244] time 0.109 (0.116) data 0.000 (0.012) loss 2.2687 (1.9413) teacher_loss 1.2653 (0.9159) loss_zs_kd 0.4331 (0.4720) loss_oracle 0.4678 (0.4626) acc 65.6250 (76.0938) kd_loss 0.7695 (0.7941) lr 6.9098e-04 eta 0:08:54
epoch [32/50] batch [40/244] time 0.100 (0.108) data 0.000 (0.006) loss 2.2253 (1.9568) teacher_loss 0.9929 (0.9284) loss_zs_kd 0.4340 (0.4719) loss_oracle 0.4178 (0.4682) acc 75.0000 (75.3906) kd_loss 1.0235 (0.7943) lr 6.9098e-04 eta 0:08:18
epoch [32/50] batch [60/244] time 0.102 (0.106) data 0.000 (0.004) loss 2.0666 (1.9818) teacher_loss 1.0287 (0.9580) loss_zs_kd 0.6730 (0.4875) loss_oracle 0.4356 (0.4657) acc 71.8750 (74.7917) kd_loss 0.8202 (0.7910) lr 6.9098e-04 eta 0:08:05
epoch [32/50] batch [80/244] time 0.100 (0.105) data 0.000 (0.003) loss 1.7779 (1.9761) teacher_loss 0.8576 (0.9562) loss_zs_kd 0.5202 (0.4851) loss_oracle 0.4376 (0.4659) acc 78.1250 (74.6484) kd_loss 0.7015 (0.7870) lr 6.9098e-04 eta 0:07:59
epoch [32/50] batch [100/244] time 0.097 (0.104) data 0.000 (0.003) loss 2.4193 (1.9959) teacher_loss 1.2479 (0.9815) loss_zs_kd 0.5484 (0.4933) loss_oracle 0.3454 (0.4609) acc 68.7500 (74.0938) kd_loss 0.9987 (0.7839) lr 6.9098e-04 eta 0:07:53
epoch [32/50] batch [120/244] time 0.097 (0.103) data 0.000 (0.002) loss 1.4734 (1.9983) teacher_loss 0.6097 (0.9923) loss_zs_kd 0.6331 (0.4898) loss_oracle 0.4003 (0.4516) acc 81.2500 (73.8281) kd_loss 0.6635 (0.7802) lr 6.9098e-04 eta 0:07:46
epoch [32/50] batch [140/244] time 0.102 (0.102) data 0.000 (0.002) loss 1.7341 (1.9742) teacher_loss 0.8620 (0.9766) loss_zs_kd 0.5358 (0.4879) loss_oracle 0.3525 (0.4491) acc 75.0000 (74.1295) kd_loss 0.6958 (0.7730) lr 6.9098e-04 eta 0:07:40
epoch [32/50] batch [160/244] time 0.103 (0.103) data 0.000 (0.002) loss 2.0121 (1.9726) teacher_loss 1.0158 (0.9735) loss_zs_kd 0.5720 (0.4855) loss_oracle 0.4434 (0.4486) acc 78.1250 (74.3750) kd_loss 0.7747 (0.7748) lr 6.9098e-04 eta 0:07:39
epoch [32/50] batch [180/244] time 0.113 (0.104) data 0.000 (0.002) loss 1.4821 (1.9816) teacher_loss 0.6851 (0.9826) loss_zs_kd 0.6066 (0.4805) loss_oracle 0.4065 (0.4485) acc 87.5000 (74.0972) kd_loss 0.5937 (0.7748) lr 6.9098e-04 eta 0:07:42
epoch [32/50] batch [200/244] time 0.111 (0.104) data 0.000 (0.001) loss 1.9298 (1.9770) teacher_loss 1.0364 (0.9866) loss_zs_kd 0.3833 (0.4820) loss_oracle 0.4363 (0.4456) acc 65.6250 (73.9375) kd_loss 0.6752 (0.7676) lr 6.9098e-04 eta 0:07:40
epoch [32/50] batch [220/244] time 0.103 (0.104) data 0.000 (0.001) loss 2.4539 (1.9798) teacher_loss 1.4427 (0.9910) loss_zs_kd 0.6029 (0.4784) loss_oracle 0.4476 (0.4438) acc 62.5000 (73.7642) kd_loss 0.7873 (0.7669) lr 6.9098e-04 eta 0:07:38
epoch [32/50] batch [240/244] time 0.108 (0.104) data 0.000 (0.001) loss 1.8878 (1.9859) teacher_loss 0.8323 (0.9972) loss_zs_kd 0.3964 (0.4754) loss_oracle 0.3639 (0.4433) acc 75.0000 (73.6328) kd_loss 0.8736 (0.7671) lr 6.9098e-04 eta 0:07:36
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,847
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,051
* accuracy: 91.3%
* error: 8.7%
* macro_f1: 90.8%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [33/50] batch [20/244] time 0.096 (0.116) data 0.000 (0.015) loss 1.8518 (1.9981) teacher_loss 1.0692 (1.0003) loss_zs_kd 0.3475 (0.4487) loss_oracle 0.3588 (0.4378) acc 75.0000 (73.9062) kd_loss 0.6032 (0.7789) lr 6.3188e-04 eta 0:08:27
epoch [33/50] batch [40/244] time 0.095 (0.105) data 0.000 (0.007) loss 1.6999 (1.9383) teacher_loss 0.7007 (0.9461) loss_zs_kd 0.4710 (0.4514) loss_oracle 0.4144 (0.4294) acc 87.5000 (75.2344) kd_loss 0.7920 (0.7774) lr 6.3188e-04 eta 0:07:38
epoch [33/50] batch [60/244] time 0.094 (0.104) data 0.000 (0.005) loss 2.8910 (1.9390) teacher_loss 1.8398 (0.9647) loss_zs_kd 0.5352 (0.4578) loss_oracle 0.5077 (0.4307) acc 56.2500 (74.5833) kd_loss 0.7973 (0.7590) lr 6.3188e-04 eta 0:07:28
epoch [33/50] batch [80/244] time 0.098 (0.102) data 0.000 (0.004) loss 1.9434 (1.9656) teacher_loss 0.9822 (0.9875) loss_zs_kd 0.5112 (0.4692) loss_oracle 0.4427 (0.4327) acc 71.8750 (73.8281) kd_loss 0.7398 (0.7618) lr 6.3188e-04 eta 0:07:19
epoch [33/50] batch [100/244] time 0.094 (0.101) data 0.000 (0.003) loss 1.6275 (1.9546) teacher_loss 0.7381 (0.9763) loss_zs_kd 0.5266 (0.4657) loss_oracle 0.3987 (0.4356) acc 81.2500 (74.0312) kd_loss 0.6900 (0.7604) lr 6.3188e-04 eta 0:07:11
epoch [33/50] batch [120/244] time 0.106 (0.100) data 0.000 (0.003) loss 2.0110 (1.9574) teacher_loss 1.0082 (0.9747) loss_zs_kd 0.5416 (0.4735) loss_oracle 0.5573 (0.4393) acc 71.8750 (74.1146) kd_loss 0.7241 (0.7631) lr 6.3188e-04 eta 0:07:07
epoch [33/50] batch [140/244] time 0.099 (0.099) data 0.000 (0.002) loss 1.9389 (1.9577) teacher_loss 0.9971 (0.9743) loss_zs_kd 0.4078 (0.4740) loss_oracle 0.3607 (0.4412) acc 68.7500 (74.2411) kd_loss 0.7614 (0.7628) lr 6.3188e-04 eta 0:07:02
epoch [33/50] batch [160/244] time 0.100 (0.099) data 0.000 (0.002) loss 1.3952 (1.9459) teacher_loss 0.4531 (0.9655) loss_zs_kd 0.6501 (0.4781) loss_oracle 0.4593 (0.4414) acc 84.3750 (74.4922) kd_loss 0.7125 (0.7597) lr 6.3188e-04 eta 0:06:59
epoch [33/50] batch [180/244] time 0.130 (0.100) data 0.000 (0.002) loss 2.3779 (1.9472) teacher_loss 1.4653 (0.9702) loss_zs_kd 0.5046 (0.4762) loss_oracle 0.3027 (0.4401) acc 68.7500 (74.3576) kd_loss 0.7613 (0.7570) lr 6.3188e-04 eta 0:06:59
epoch [33/50] batch [200/244] time 0.092 (0.100) data 0.000 (0.002) loss 2.0257 (1.9541) teacher_loss 0.8541 (0.9774) loss_zs_kd 0.4476 (0.4785) loss_oracle 0.5028 (0.4392) acc 71.8750 (74.0000) kd_loss 0.9202 (0.7571) lr 6.3188e-04 eta 0:06:57
epoch [33/50] batch [220/244] time 0.094 (0.099) data 0.000 (0.002) loss 2.1980 (1.9564) teacher_loss 1.0937 (0.9782) loss_zs_kd 0.4845 (0.4802) loss_oracle 0.4276 (0.4386) acc 65.6250 (73.8778) kd_loss 0.8904 (0.7590) lr 6.3188e-04 eta 0:06:55
epoch [33/50] batch [240/244] time 0.086 (0.099) data 0.000 (0.001) loss 1.3606 (1.9505) teacher_loss 0.4629 (0.9734) loss_zs_kd 0.4675 (0.4825) loss_oracle 0.3993 (0.4385) acc 78.1250 (73.8411) kd_loss 0.6980 (0.7578) lr 6.3188e-04 eta 0:06:50
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,836
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,040
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [34/50] batch [20/244] time 0.105 (0.120) data 0.000 (0.015) loss 1.7801 (1.9543) teacher_loss 0.8715 (0.9760) loss_zs_kd 0.4654 (0.4786) loss_oracle 0.3824 (0.4415) acc 75.0000 (73.1250) kd_loss 0.7174 (0.7575) lr 5.7422e-04 eta 0:08:16
epoch [34/50] batch [40/244] time 0.105 (0.110) data 0.000 (0.008) loss 2.3153 (1.9009) teacher_loss 1.3277 (0.9373) loss_zs_kd 0.4861 (0.4855) loss_oracle 0.4062 (0.4336) acc 65.6250 (73.9844) kd_loss 0.7845 (0.7468) lr 5.7422e-04 eta 0:07:30
epoch [34/50] batch [60/244] time 0.098 (0.106) data 0.000 (0.005) loss 2.1999 (1.8921) teacher_loss 1.1722 (0.9343) loss_zs_kd 0.5549 (0.4879) loss_oracle 0.4732 (0.4328) acc 65.6250 (73.6979) kd_loss 0.7911 (0.7414) lr 5.7422e-04 eta 0:07:12
epoch [34/50] batch [80/244] time 0.097 (0.103) data 0.000 (0.004) loss 2.2088 (1.8804) teacher_loss 1.3116 (0.9270) loss_zs_kd 0.4925 (0.4933) loss_oracle 0.5358 (0.4329) acc 65.6250 (74.0234) kd_loss 0.6292 (0.7369) lr 5.7422e-04 eta 0:07:00
epoch [34/50] batch [100/244] time 0.094 (0.102) data 0.000 (0.003) loss 1.7794 (1.9013) teacher_loss 0.8451 (0.9453) loss_zs_kd 0.5001 (0.4908) loss_oracle 0.4240 (0.4312) acc 81.2500 (73.6562) kd_loss 0.7223 (0.7404) lr 5.7422e-04 eta 0:06:52
epoch [34/50] batch [120/244] time 0.095 (0.101) data 0.000 (0.003) loss 1.7695 (1.9006) teacher_loss 0.6513 (0.9472) loss_zs_kd 0.4722 (0.4875) loss_oracle 0.5220 (0.4313) acc 81.2500 (73.7760) kd_loss 0.8572 (0.7378) lr 5.7422e-04 eta 0:06:46
epoch [34/50] batch [140/244] time 0.099 (0.101) data 0.001 (0.002) loss 1.5186 (1.8961) teacher_loss 0.7331 (0.9380) loss_zs_kd 0.4241 (0.4832) loss_oracle 0.3642 (0.4321) acc 81.2500 (74.2857) kd_loss 0.6034 (0.7421) lr 5.7422e-04 eta 0:06:43
epoch [34/50] batch [160/244] time 0.096 (0.100) data 0.000 (0.002) loss 1.9016 (1.8968) teacher_loss 1.0994 (0.9387) loss_zs_kd 0.4887 (0.4888) loss_oracle 0.3702 (0.4320) acc 68.7500 (74.4727) kd_loss 0.6171 (0.7421) lr 5.7422e-04 eta 0:06:39
epoch [34/50] batch [180/244] time 0.096 (0.100) data 0.000 (0.002) loss 2.1057 (1.9059) teacher_loss 1.2777 (0.9507) loss_zs_kd 0.5150 (0.4902) loss_oracle 0.3993 (0.4318) acc 65.6250 (74.0451) kd_loss 0.6283 (0.7393) lr 5.7422e-04 eta 0:06:35
epoch [34/50] batch [200/244] time 0.090 (0.100) data 0.000 (0.002) loss 1.9005 (1.9050) teacher_loss 0.8992 (0.9495) loss_zs_kd 0.4654 (0.4885) loss_oracle 0.4131 (0.4319) acc 78.1250 (74.0312) kd_loss 0.7947 (0.7395) lr 5.7422e-04 eta 0:06:36
epoch [34/50] batch [220/244] time 0.096 (0.100) data 0.000 (0.002) loss 2.0373 (1.9002) teacher_loss 0.9862 (0.9465) loss_zs_kd 0.3427 (0.4874) loss_oracle 0.4199 (0.4311) acc 75.0000 (74.1903) kd_loss 0.8412 (0.7382) lr 5.7422e-04 eta 0:06:34
epoch [34/50] batch [240/244] time 0.086 (0.100) data 0.000 (0.001) loss 1.5356 (1.8946) teacher_loss 0.7988 (0.9414) loss_zs_kd 0.5964 (0.4878) loss_oracle 0.3693 (0.4309) acc 81.2500 (74.3490) kd_loss 0.5522 (0.7378) lr 5.7422e-04 eta 0:06:30
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,848
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,047
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.7%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [35/50] batch [20/244] time 0.096 (0.113) data 0.000 (0.013) loss 1.8755 (1.9215) teacher_loss 0.9809 (0.9870) loss_zs_kd 0.4370 (0.4914) loss_oracle 0.4854 (0.4238) acc 71.8750 (74.8438) kd_loss 0.6520 (0.7226) lr 5.1825e-04 eta 0:07:20
epoch [35/50] batch [40/244] time 0.088 (0.104) data 0.000 (0.007) loss 1.8383 (1.9562) teacher_loss 0.9406 (1.0022) loss_zs_kd 0.3640 (0.4960) loss_oracle 0.3234 (0.4195) acc 71.8750 (74.0625) kd_loss 0.7360 (0.7443) lr 5.1825e-04 eta 0:06:41
epoch [35/50] batch [60/244] time 0.101 (0.101) data 0.000 (0.005) loss 1.8873 (1.9494) teacher_loss 0.8680 (0.9913) loss_zs_kd 0.4171 (0.4927) loss_oracle 0.4337 (0.4240) acc 78.1250 (74.0104) kd_loss 0.8024 (0.7461) lr 5.1825e-04 eta 0:06:29
epoch [35/50] batch [80/244] time 0.094 (0.100) data 0.000 (0.003) loss 1.7294 (1.9468) teacher_loss 0.6249 (0.9837) loss_zs_kd 0.5930 (0.5015) loss_oracle 0.4874 (0.4266) acc 84.3750 (74.2188) kd_loss 0.8609 (0.7498) lr 5.1825e-04 eta 0:06:23
epoch [35/50] batch [100/244] time 0.094 (0.099) data 0.000 (0.003) loss 1.4925 (1.9432) teacher_loss 0.7221 (0.9780) loss_zs_kd 0.5246 (0.5093) loss_oracle 0.4350 (0.4287) acc 81.2500 (74.5938) kd_loss 0.5528 (0.7508) lr 5.1825e-04 eta 0:06:17
epoch [35/50] batch [120/244] time 0.083 (0.098) data 0.000 (0.002) loss 2.0012 (1.9328) teacher_loss 0.9415 (0.9650) loss_zs_kd 0.3409 (0.5111) loss_oracle 0.4427 (0.4265) acc 84.3750 (74.7396) kd_loss 0.8384 (0.7545) lr 5.1825e-04 eta 0:06:12
epoch [35/50] batch [140/244] time 0.091 (0.097) data 0.000 (0.002) loss 1.9726 (1.9223) teacher_loss 0.8745 (0.9540) loss_zs_kd 0.5021 (0.5080) loss_oracle 0.4400 (0.4291) acc 81.2500 (74.9554) kd_loss 0.8782 (0.7538) lr 5.1825e-04 eta 0:06:06
epoch [35/50] batch [160/244] time 0.087 (0.097) data 0.001 (0.002) loss 2.3541 (1.9252) teacher_loss 1.2815 (0.9524) loss_zs_kd 0.6889 (0.5119) loss_oracle 0.4502 (0.4318) acc 59.3750 (74.8828) kd_loss 0.8475 (0.7569) lr 5.1825e-04 eta 0:06:01
epoch [35/50] batch [180/244] time 0.093 (0.096) data 0.000 (0.002) loss 2.1592 (1.9320) teacher_loss 1.3261 (0.9649) loss_zs_kd 0.5030 (0.5083) loss_oracle 0.4313 (0.4321) acc 68.7500 (74.5660) kd_loss 0.6175 (0.7511) lr 5.1825e-04 eta 0:05:58
epoch [35/50] batch [200/244] time 0.087 (0.096) data 0.000 (0.002) loss 1.6314 (1.9435) teacher_loss 0.5910 (0.9729) loss_zs_kd 0.4358 (0.5070) loss_oracle 0.4404 (0.4340) acc 78.1250 (74.2500) kd_loss 0.8202 (0.7536) lr 5.1825e-04 eta 0:05:54
epoch [35/50] batch [220/244] time 0.118 (0.097) data 0.000 (0.001) loss 2.0868 (1.9433) teacher_loss 1.0936 (0.9714) loss_zs_kd 0.4481 (0.5080) loss_oracle 0.4649 (0.4358) acc 71.8750 (74.3608) kd_loss 0.7608 (0.7540) lr 5.1825e-04 eta 0:05:55
epoch [35/50] batch [240/244] time 0.085 (0.096) data 0.000 (0.001) loss 1.8933 (1.9540) teacher_loss 0.8894 (0.9794) loss_zs_kd 0.3791 (0.5061) loss_oracle 0.4416 (0.4355) acc 71.8750 (74.0755) kd_loss 0.7831 (0.7568) lr 5.1825e-04 eta 0:05:52
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,850
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [36/50] batch [20/244] time 0.095 (0.116) data 0.000 (0.013) loss 2.3473 (2.1153) teacher_loss 1.2239 (1.1445) loss_zs_kd 0.5286 (0.5205) loss_oracle 0.4488 (0.4349) acc 68.7500 (70.0000) kd_loss 0.8990 (0.7533) lr 4.6417e-04 eta 0:07:03
epoch [36/50] batch [40/244] time 0.106 (0.107) data 0.000 (0.007) loss 2.2233 (2.0257) teacher_loss 1.2430 (1.0535) loss_zs_kd 0.5481 (0.5228) loss_oracle 0.4551 (0.4314) acc 59.3750 (72.1875) kd_loss 0.7527 (0.7565) lr 4.6417e-04 eta 0:06:28
epoch [36/50] batch [60/244] time 0.086 (0.103) data 0.000 (0.004) loss 1.8745 (1.9978) teacher_loss 0.7221 (1.0260) loss_zs_kd 0.3687 (0.5044) loss_oracle 0.4633 (0.4345) acc 78.1250 (72.8125) kd_loss 0.9208 (0.7547) lr 4.6417e-04 eta 0:06:10
epoch [36/50] batch [80/244] time 0.096 (0.100) data 0.000 (0.003) loss 1.9714 (1.9765) teacher_loss 1.0645 (1.0057) loss_zs_kd 0.6462 (0.4953) loss_oracle 0.3391 (0.4341) acc 75.0000 (73.3203) kd_loss 0.7373 (0.7538) lr 4.6417e-04 eta 0:05:58
epoch [36/50] batch [100/244] time 0.084 (0.099) data 0.000 (0.003) loss 1.5804 (1.9583) teacher_loss 0.7972 (0.9881) loss_zs_kd 0.6464 (0.5052) loss_oracle 0.3602 (0.4352) acc 78.1250 (73.8750) kd_loss 0.6031 (0.7526) lr 4.6417e-04 eta 0:05:50
epoch [36/50] batch [120/244] time 0.095 (0.098) data 0.000 (0.002) loss 1.5640 (1.9631) teacher_loss 0.7538 (0.9959) loss_zs_kd 0.4012 (0.5111) loss_oracle 0.4359 (0.4356) acc 78.1250 (73.8802) kd_loss 0.5922 (0.7494) lr 4.6417e-04 eta 0:05:46
epoch [36/50] batch [140/244] time 0.092 (0.098) data 0.000 (0.002) loss 1.7198 (1.9625) teacher_loss 0.8615 (0.9926) loss_zs_kd 0.5768 (0.5085) loss_oracle 0.3601 (0.4371) acc 75.0000 (74.1071) kd_loss 0.6783 (0.7513) lr 4.6417e-04 eta 0:05:43
epoch [36/50] batch [160/244] time 0.094 (0.098) data 0.000 (0.002) loss 1.9288 (1.9732) teacher_loss 0.8891 (0.9981) loss_zs_kd 0.6127 (0.5064) loss_oracle 0.4921 (0.4385) acc 81.2500 (74.1797) kd_loss 0.7937 (0.7559) lr 4.6417e-04 eta 0:05:41
epoch [36/50] batch [180/244] time 0.095 (0.098) data 0.000 (0.002) loss 1.7815 (1.9690) teacher_loss 0.7148 (0.9928) loss_zs_kd 0.4891 (0.5047) loss_oracle 0.4546 (0.4374) acc 78.1250 (74.1667) kd_loss 0.8394 (0.7575) lr 4.6417e-04 eta 0:05:39
epoch [36/50] batch [200/244] time 0.095 (0.097) data 0.000 (0.001) loss 2.0869 (1.9711) teacher_loss 1.0174 (0.9891) loss_zs_kd 0.5284 (0.5047) loss_oracle 0.4831 (0.4364) acc 68.7500 (74.1562) kd_loss 0.8280 (0.7638) lr 4.6417e-04 eta 0:05:36
epoch [36/50] batch [220/244] time 0.102 (0.097) data 0.000 (0.001) loss 2.1463 (1.9679) teacher_loss 0.9502 (0.9847) loss_zs_kd 0.7750 (0.5032) loss_oracle 0.5902 (0.4366) acc 68.7500 (74.2614) kd_loss 0.9010 (0.7649) lr 4.6417e-04 eta 0:05:34
epoch [36/50] batch [240/244] time 0.088 (0.097) data 0.000 (0.001) loss 2.1052 (1.9610) teacher_loss 1.1283 (0.9770) loss_zs_kd 0.3344 (0.5015) loss_oracle 0.4580 (0.4383) acc 59.3750 (74.4792) kd_loss 0.7479 (0.7648) lr 4.6417e-04 eta 0:05:31
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,851
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [37/50] batch [20/244] time 0.104 (0.123) data 0.000 (0.017) loss 1.4053 (1.9449) teacher_loss 0.5180 (0.9756) loss_zs_kd 0.3044 (0.4724) loss_oracle 0.4320 (0.4394) acc 87.5000 (75.6250) kd_loss 0.6713 (0.7496) lr 4.1221e-04 eta 0:06:57
epoch [37/50] batch [40/244] time 0.108 (0.111) data 0.000 (0.009) loss 1.8562 (1.9926) teacher_loss 0.8777 (0.9861) loss_zs_kd 0.4847 (0.4745) loss_oracle 0.4392 (0.4526) acc 78.1250 (74.5312) kd_loss 0.7588 (0.7801) lr 4.1221e-04 eta 0:06:13
epoch [37/50] batch [60/244] time 0.099 (0.107) data 0.000 (0.006) loss 1.8210 (1.9978) teacher_loss 0.7987 (0.9887) loss_zs_kd 0.4695 (0.4881) loss_oracle 0.5126 (0.4578) acc 84.3750 (74.2188) kd_loss 0.7660 (0.7802) lr 4.1221e-04 eta 0:05:57
epoch [37/50] batch [80/244] time 0.098 (0.104) data 0.000 (0.005) loss 2.1171 (1.9939) teacher_loss 1.1110 (0.9945) loss_zs_kd 0.5567 (0.4795) loss_oracle 0.4618 (0.4543) acc 71.8750 (74.1797) kd_loss 0.7752 (0.7722) lr 4.1221e-04 eta 0:05:47
epoch [37/50] batch [100/244] time 0.093 (0.103) data 0.000 (0.004) loss 1.5636 (2.0046) teacher_loss 0.7319 (1.0091) loss_zs_kd 0.5398 (0.4895) loss_oracle 0.4225 (0.4550) acc 84.3750 (73.4375) kd_loss 0.6205 (0.7680) lr 4.1221e-04 eta 0:05:39
epoch [37/50] batch [120/244] time 0.092 (0.102) data 0.000 (0.003) loss 1.7551 (1.9914) teacher_loss 0.8429 (0.9991) loss_zs_kd 0.5725 (0.5004) loss_oracle 0.3714 (0.4563) acc 78.1250 (73.6458) kd_loss 0.7264 (0.7641) lr 4.1221e-04 eta 0:05:35
epoch [37/50] batch [140/244] time 0.098 (0.101) data 0.000 (0.003) loss 2.0915 (1.9983) teacher_loss 1.1257 (1.0021) loss_zs_kd 0.6160 (0.5015) loss_oracle 0.4496 (0.4544) acc 75.0000 (73.7946) kd_loss 0.7410 (0.7690) lr 4.1221e-04 eta 0:05:30
epoch [37/50] batch [160/244] time 0.096 (0.100) data 0.000 (0.002) loss 2.3904 (1.9940) teacher_loss 1.4175 (0.9982) loss_zs_kd 0.3790 (0.5032) loss_oracle 0.4129 (0.4541) acc 71.8750 (74.1992) kd_loss 0.7664 (0.7687) lr 4.1221e-04 eta 0:05:26
epoch [37/50] batch [180/244] time 0.097 (0.100) data 0.000 (0.002) loss 2.7254 (1.9937) teacher_loss 1.5047 (0.9925) loss_zs_kd 0.5555 (0.5035) loss_oracle 0.4770 (0.4551) acc 62.5000 (74.4792) kd_loss 0.9822 (0.7736) lr 4.1221e-04 eta 0:05:23
epoch [37/50] batch [200/244] time 0.091 (0.100) data 0.000 (0.002) loss 1.8151 (1.9849) teacher_loss 0.6909 (0.9853) loss_zs_kd 0.6309 (0.5024) loss_oracle 0.5301 (0.4564) acc 78.1250 (74.4844) kd_loss 0.8591 (0.7714) lr 4.1221e-04 eta 0:05:20
epoch [37/50] batch [220/244] time 0.094 (0.099) data 0.000 (0.002) loss 1.9641 (1.9859) teacher_loss 1.0305 (0.9878) loss_zs_kd 0.4737 (0.5013) loss_oracle 0.4719 (0.4567) acc 68.7500 (74.4886) kd_loss 0.6977 (0.7698) lr 4.1221e-04 eta 0:05:17
epoch [37/50] batch [240/244] time 0.085 (0.099) data 0.000 (0.002) loss 2.2798 (1.9865) teacher_loss 1.2238 (0.9883) loss_zs_kd 0.4269 (0.5010) loss_oracle 0.4650 (0.4558) acc 68.7500 (74.4010) kd_loss 0.8235 (0.7704) lr 4.1221e-04 eta 0:05:14
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,842
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.5%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [38/50] batch [20/244] time 0.114 (0.129) data 0.000 (0.015) loss 2.3431 (2.0334) teacher_loss 1.2798 (1.0179) loss_zs_kd 0.4040 (0.4825) loss_oracle 0.3878 (0.4640) acc 71.8750 (73.9062) kd_loss 0.8694 (0.7835) lr 3.6258e-04 eta 0:06:45
epoch [38/50] batch [40/244] time 0.112 (0.118) data 0.001 (0.008) loss 1.9775 (1.9262) teacher_loss 1.0263 (0.9491) loss_zs_kd 0.4079 (0.4650) loss_oracle 0.4792 (0.4416) acc 71.8750 (75.5469) kd_loss 0.7116 (0.7563) lr 3.6258e-04 eta 0:06:09
epoch [38/50] batch [60/244] time 0.114 (0.114) data 0.000 (0.005) loss 2.2877 (1.9096) teacher_loss 1.2914 (0.9317) loss_zs_kd 0.3846 (0.4628) loss_oracle 0.4830 (0.4421) acc 59.3750 (75.8333) kd_loss 0.7548 (0.7568) lr 3.6258e-04 eta 0:05:55
epoch [38/50] batch [80/244] time 0.103 (0.111) data 0.000 (0.004) loss 2.3905 (1.9345) teacher_loss 1.2706 (0.9467) loss_zs_kd 0.5183 (0.4775) loss_oracle 0.5305 (0.4450) acc 65.6250 (75.1172) kd_loss 0.8546 (0.7653) lr 3.6258e-04 eta 0:05:44
epoch [38/50] batch [100/244] time 0.112 (0.110) data 0.000 (0.003) loss 2.6571 (1.9461) teacher_loss 1.6320 (0.9543) loss_zs_kd 0.5202 (0.4809) loss_oracle 0.5075 (0.4476) acc 46.8750 (74.8125) kd_loss 0.7714 (0.7681) lr 3.6258e-04 eta 0:05:38
epoch [38/50] batch [120/244] time 0.098 (0.109) data 0.000 (0.003) loss 1.6329 (1.9492) teacher_loss 0.7067 (0.9604) loss_zs_kd 0.4431 (0.4803) loss_oracle 0.4096 (0.4493) acc 84.3750 (74.6354) kd_loss 0.7214 (0.7641) lr 3.6258e-04 eta 0:05:32
epoch [38/50] batch [140/244] time 0.109 (0.108) data 0.001 (0.002) loss 2.1529 (1.9588) teacher_loss 1.0122 (0.9659) loss_zs_kd 0.4455 (0.4809) loss_oracle 0.3982 (0.4493) acc 68.7500 (74.3304) kd_loss 0.9416 (0.7682) lr 3.6258e-04 eta 0:05:28
epoch [38/50] batch [160/244] time 0.104 (0.108) data 0.000 (0.002) loss 1.8090 (1.9554) teacher_loss 0.8517 (0.9645) loss_zs_kd 0.4561 (0.4852) loss_oracle 0.5091 (0.4482) acc 78.1250 (74.4336) kd_loss 0.7027 (0.7668) lr 3.6258e-04 eta 0:05:25
epoch [38/50] batch [180/244] time 0.104 (0.107) data 0.000 (0.002) loss 1.9833 (1.9581) teacher_loss 1.1179 (0.9695) loss_zs_kd 0.6193 (0.4848) loss_oracle 0.4274 (0.4481) acc 65.6250 (74.3576) kd_loss 0.6517 (0.7646) lr 3.6258e-04 eta 0:05:21
epoch [38/50] batch [200/244] time 0.100 (0.107) data 0.000 (0.002) loss 1.9478 (1.9671) teacher_loss 0.9452 (0.9751) loss_zs_kd 0.3978 (0.4877) loss_oracle 0.4306 (0.4489) acc 78.1250 (74.2969) kd_loss 0.7873 (0.7676) lr 3.6258e-04 eta 0:05:17
epoch [38/50] batch [220/244] time 0.103 (0.106) data 0.000 (0.002) loss 1.6733 (1.9657) teacher_loss 0.7759 (0.9779) loss_zs_kd 0.3843 (0.4882) loss_oracle 0.4380 (0.4497) acc 81.2500 (74.2045) kd_loss 0.6785 (0.7629) lr 3.6258e-04 eta 0:05:14
epoch [38/50] batch [240/244] time 0.108 (0.106) data 0.000 (0.002) loss 2.2368 (1.9635) teacher_loss 1.1043 (0.9742) loss_zs_kd 0.6106 (0.4900) loss_oracle 0.4447 (0.4498) acc 65.6250 (74.2839) kd_loss 0.9101 (0.7644) lr 3.6258e-04 eta 0:05:11
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,843
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [39/50] batch [20/244] time 0.099 (0.116) data 0.000 (0.015) loss 2.5657 (2.0169) teacher_loss 1.5198 (1.0310) loss_zs_kd 0.5477 (0.4645) loss_oracle 0.4842 (0.4195) acc 65.6250 (75.6250) kd_loss 0.8038 (0.7762) lr 3.1545e-04 eta 0:05:36
epoch [39/50] batch [40/244] time 0.095 (0.105) data 0.000 (0.007) loss 2.0019 (1.9468) teacher_loss 1.1736 (0.9787) loss_zs_kd 0.4809 (0.4898) loss_oracle 0.4679 (0.4271) acc 65.6250 (74.8438) kd_loss 0.5944 (0.7546) lr 3.1545e-04 eta 0:05:03
epoch [39/50] batch [60/244] time 0.093 (0.102) data 0.000 (0.005) loss 1.5079 (1.9338) teacher_loss 0.6834 (0.9595) loss_zs_kd 0.5475 (0.4975) loss_oracle 0.3833 (0.4377) acc 87.5000 (75.1562) kd_loss 0.6328 (0.7555) lr 3.1545e-04 eta 0:04:52
epoch [39/50] batch [80/244] time 0.096 (0.101) data 0.000 (0.004) loss 2.1259 (1.9498) teacher_loss 1.0327 (0.9692) loss_zs_kd 0.3793 (0.4923) loss_oracle 0.4025 (0.4374) acc 68.7500 (75.1953) kd_loss 0.8919 (0.7619) lr 3.1545e-04 eta 0:04:46
epoch [39/50] batch [100/244] time 0.094 (0.100) data 0.000 (0.003) loss 1.7165 (1.9327) teacher_loss 0.8934 (0.9558) loss_zs_kd 0.5189 (0.4941) loss_oracle 0.5282 (0.4404) acc 68.7500 (75.0938) kd_loss 0.5590 (0.7567) lr 3.1545e-04 eta 0:04:41
epoch [39/50] batch [120/244] time 0.099 (0.099) data 0.000 (0.003) loss 1.7003 (1.9373) teacher_loss 0.6576 (0.9592) loss_zs_kd 0.6029 (0.4978) loss_oracle 0.4141 (0.4414) acc 84.3750 (74.8177) kd_loss 0.8357 (0.7574) lr 3.1545e-04 eta 0:04:37
epoch [39/50] batch [140/244] time 0.099 (0.099) data 0.000 (0.002) loss 2.0378 (1.9295) teacher_loss 1.0577 (0.9556) loss_zs_kd 0.4447 (0.5033) loss_oracle 0.4530 (0.4392) acc 71.8750 (74.8661) kd_loss 0.7536 (0.7543) lr 3.1545e-04 eta 0:04:35
epoch [39/50] batch [160/244] time 0.101 (0.099) data 0.000 (0.002) loss 2.2345 (1.9470) teacher_loss 1.1733 (0.9694) loss_zs_kd 0.5913 (0.5016) loss_oracle 0.4819 (0.4404) acc 71.8750 (74.7656) kd_loss 0.8203 (0.7574) lr 3.1545e-04 eta 0:04:33
epoch [39/50] batch [180/244] time 0.097 (0.099) data 0.000 (0.002) loss 1.7117 (1.9506) teacher_loss 0.6767 (0.9765) loss_zs_kd 0.3633 (0.5027) loss_oracle 0.4122 (0.4384) acc 81.2500 (74.5833) kd_loss 0.8289 (0.7549) lr 3.1545e-04 eta 0:04:31
epoch [39/50] batch [200/244] time 0.098 (0.099) data 0.000 (0.002) loss 2.0731 (1.9499) teacher_loss 0.9634 (0.9779) loss_zs_kd 0.4078 (0.5014) loss_oracle 0.5828 (0.4389) acc 71.8750 (74.4375) kd_loss 0.8183 (0.7526) lr 3.1545e-04 eta 0:04:29
epoch [39/50] batch [220/244] time 0.097 (0.099) data 0.000 (0.002) loss 2.5559 (1.9566) teacher_loss 1.6149 (0.9825) loss_zs_kd 0.3846 (0.4995) loss_oracle 0.3927 (0.4408) acc 59.3750 (74.1903) kd_loss 0.7446 (0.7537) lr 3.1545e-04 eta 0:04:27
epoch [39/50] batch [240/244] time 0.089 (0.098) data 0.000 (0.001) loss 1.7698 (1.9575) teacher_loss 0.8392 (0.9831) loss_zs_kd 0.4596 (0.4994) loss_oracle 0.4976 (0.4405) acc 78.1250 (74.1797) kd_loss 0.6819 (0.7542) lr 3.1545e-04 eta 0:04:24
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,851
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [40/50] batch [20/244] time 0.101 (0.112) data 0.000 (0.015) loss 1.9000 (1.9926) teacher_loss 0.7790 (1.0015) loss_zs_kd 0.5614 (0.4896) loss_oracle 0.4861 (0.4569) acc 75.0000 (71.7188) kd_loss 0.8779 (0.7627) lr 2.7103e-04 eta 0:04:59
epoch [40/50] batch [40/244] time 0.087 (0.102) data 0.000 (0.007) loss 1.9123 (1.9862) teacher_loss 0.9032 (0.9936) loss_zs_kd 0.5087 (0.5047) loss_oracle 0.4798 (0.4540) acc 81.2500 (72.0312) kd_loss 0.7692 (0.7656) lr 2.7103e-04 eta 0:04:29
epoch [40/50] batch [60/244] time 0.102 (0.099) data 0.000 (0.005) loss 2.0556 (1.9807) teacher_loss 1.0118 (0.9933) loss_zs_kd 0.2940 (0.5071) loss_oracle 0.4775 (0.4522) acc 71.8750 (73.2292) kd_loss 0.8051 (0.7613) lr 2.7103e-04 eta 0:04:19
epoch [40/50] batch [80/244] time 0.103 (0.098) data 0.000 (0.004) loss 1.7368 (1.9840) teacher_loss 0.9112 (1.0016) loss_zs_kd 0.3846 (0.5200) loss_oracle 0.3866 (0.4483) acc 75.0000 (72.8516) kd_loss 0.6323 (0.7583) lr 2.7103e-04 eta 0:04:16
epoch [40/50] batch [100/244] time 0.094 (0.098) data 0.000 (0.003) loss 1.7558 (1.9566) teacher_loss 0.6333 (0.9784) loss_zs_kd 0.5301 (0.5148) loss_oracle 0.5033 (0.4445) acc 81.2500 (73.7500) kd_loss 0.8709 (0.7559) lr 2.7103e-04 eta 0:04:12
epoch [40/50] batch [120/244] time 0.094 (0.098) data 0.000 (0.003) loss 1.7873 (1.9518) teacher_loss 0.8941 (0.9739) loss_zs_kd 0.3097 (0.5067) loss_oracle 0.4289 (0.4445) acc 78.1250 (73.8542) kd_loss 0.6787 (0.7556) lr 2.7103e-04 eta 0:04:11
epoch [40/50] batch [140/244] time 0.098 (0.098) data 0.000 (0.002) loss 1.6045 (1.9432) teacher_loss 0.6419 (0.9666) loss_zs_kd 0.3849 (0.5116) loss_oracle 0.4432 (0.4441) acc 81.2500 (73.9509) kd_loss 0.7411 (0.7545) lr 2.7103e-04 eta 0:04:08
epoch [40/50] batch [160/244] time 0.099 (0.097) data 0.000 (0.002) loss 2.0701 (1.9364) teacher_loss 1.0589 (0.9546) loss_zs_kd 0.6067 (0.5122) loss_oracle 0.4345 (0.4466) acc 84.3750 (74.2383) kd_loss 0.7938 (0.7584) lr 2.7103e-04 eta 0:04:05
epoch [40/50] batch [180/244] time 0.102 (0.097) data 0.000 (0.002) loss 1.7175 (1.9379) teacher_loss 0.7570 (0.9573) loss_zs_kd 0.5991 (0.5184) loss_oracle 0.4034 (0.4454) acc 81.2500 (74.0625) kd_loss 0.7588 (0.7579) lr 2.7103e-04 eta 0:04:03
epoch [40/50] batch [200/244] time 0.099 (0.097) data 0.000 (0.002) loss 1.3693 (1.9371) teacher_loss 0.4407 (0.9555) loss_zs_kd 0.5283 (0.5152) loss_oracle 0.3720 (0.4456) acc 90.6250 (74.0312) kd_loss 0.7426 (0.7588) lr 2.7103e-04 eta 0:04:01
epoch [40/50] batch [220/244] time 0.096 (0.097) data 0.000 (0.002) loss 1.5318 (1.9243) teacher_loss 0.6546 (0.9427) loss_zs_kd 0.3895 (0.5130) loss_oracle 0.3698 (0.4459) acc 81.2500 (74.4318) kd_loss 0.6923 (0.7586) lr 2.7103e-04 eta 0:03:59
epoch [40/50] batch [240/244] time 0.088 (0.097) data 0.000 (0.001) loss 1.7101 (1.9213) teacher_loss 0.8220 (0.9398) loss_zs_kd 0.4597 (0.5129) loss_oracle 0.4498 (0.4467) acc 81.2500 (74.5573) kd_loss 0.6631 (0.7581) lr 2.7103e-04 eta 0:03:55
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,850
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,046
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [41/50] batch [20/244] time 0.108 (0.129) data 0.000 (0.016) loss 1.9084 (1.9359) teacher_loss 0.8475 (0.9273) loss_zs_kd 0.4310 (0.5184) loss_oracle 0.4425 (0.4645) acc 78.1250 (75.3125) kd_loss 0.8396 (0.7763) lr 2.2949e-04 eta 0:05:11
epoch [41/50] batch [40/244] time 0.103 (0.119) data 0.000 (0.008) loss 1.8298 (1.8982) teacher_loss 0.8119 (0.9105) loss_zs_kd 0.4120 (0.5123) loss_oracle 0.5130 (0.4600) acc 78.1250 (75.9375) kd_loss 0.7614 (0.7577) lr 2.2949e-04 eta 0:04:45
epoch [41/50] batch [60/244] time 0.101 (0.114) data 0.000 (0.005) loss 1.5346 (1.9128) teacher_loss 0.7089 (0.9246) loss_zs_kd 0.4182 (0.5066) loss_oracle 0.3925 (0.4587) acc 78.1250 (75.4167) kd_loss 0.6295 (0.7588) lr 2.2949e-04 eta 0:04:30
epoch [41/50] batch [80/244] time 0.101 (0.111) data 0.000 (0.004) loss 1.6161 (1.9165) teacher_loss 0.6957 (0.9230) loss_zs_kd 0.6867 (0.5191) loss_oracle 0.4088 (0.4620) acc 78.1250 (75.5078) kd_loss 0.7160 (0.7625) lr 2.2949e-04 eta 0:04:22
epoch [41/50] batch [100/244] time 0.101 (0.109) data 0.000 (0.003) loss 1.7780 (1.9207) teacher_loss 0.6976 (0.9253) loss_zs_kd 0.5371 (0.5336) loss_oracle 0.4127 (0.4594) acc 84.3750 (75.4688) kd_loss 0.8740 (0.7657) lr 2.2949e-04 eta 0:04:15
epoch [41/50] batch [120/244] time 0.105 (0.108) data 0.001 (0.003) loss 1.4818 (1.9225) teacher_loss 0.4094 (0.9247) loss_zs_kd 0.5055 (0.5320) loss_oracle 0.4699 (0.4627) acc 93.7500 (75.4688) kd_loss 0.8375 (0.7664) lr 2.2949e-04 eta 0:04:10
epoch [41/50] batch [140/244] time 0.092 (0.107) data 0.000 (0.002) loss 2.2226 (1.9192) teacher_loss 1.1658 (0.9167) loss_zs_kd 0.6688 (0.5282) loss_oracle 0.4123 (0.4630) acc 68.7500 (75.8259) kd_loss 0.8507 (0.7710) lr 2.2949e-04 eta 0:04:05
epoch [41/50] batch [160/244] time 0.101 (0.106) data 0.000 (0.002) loss 1.4050 (1.9149) teacher_loss 0.4067 (0.9156) loss_zs_kd 0.5590 (0.5257) loss_oracle 0.4557 (0.4597) acc 93.7500 (76.0156) kd_loss 0.7705 (0.7694) lr 2.2949e-04 eta 0:04:00
epoch [41/50] batch [180/244] time 0.092 (0.105) data 0.000 (0.002) loss 1.8615 (1.9224) teacher_loss 0.8902 (0.9215) loss_zs_kd 0.6186 (0.5294) loss_oracle 0.4254 (0.4595) acc 71.8750 (75.7292) kd_loss 0.7586 (0.7711) lr 2.2949e-04 eta 0:03:56
epoch [41/50] batch [200/244] time 0.103 (0.104) data 0.000 (0.002) loss 1.9380 (1.9193) teacher_loss 0.9248 (0.9203) loss_zs_kd 0.4030 (0.5254) loss_oracle 0.4966 (0.4594) acc 78.1250 (75.7656) kd_loss 0.7649 (0.7693) lr 2.2949e-04 eta 0:03:53
epoch [41/50] batch [220/244] time 0.102 (0.104) data 0.000 (0.002) loss 2.2272 (1.9187) teacher_loss 1.2653 (0.9203) loss_zs_kd 0.5018 (0.5230) loss_oracle 0.4365 (0.4593) acc 68.7500 (75.7670) kd_loss 0.7437 (0.7687) lr 2.2949e-04 eta 0:03:50
epoch [41/50] batch [240/244] time 0.107 (0.104) data 0.000 (0.002) loss 1.9996 (1.9194) teacher_loss 0.9317 (0.9209) loss_zs_kd 0.5700 (0.5226) loss_oracle 0.4214 (0.4602) acc 65.6250 (75.7161) kd_loss 0.8572 (0.7684) lr 2.2949e-04 eta 0:03:49
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,851
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [42/50] batch [20/244] time 0.093 (0.107) data 0.000 (0.013) loss 1.5404 (1.9292) teacher_loss 0.6918 (0.9293) loss_zs_kd 0.4825 (0.4714) loss_oracle 0.4360 (0.4537) acc 81.2500 (75.4688) kd_loss 0.6306 (0.7730) lr 1.9098e-04 eta 0:03:52
epoch [42/50] batch [40/244] time 0.084 (0.099) data 0.000 (0.006) loss 2.0385 (1.9418) teacher_loss 1.0027 (0.9394) loss_zs_kd 0.5006 (0.4944) loss_oracle 0.5907 (0.4657) acc 71.8750 (74.6094) kd_loss 0.7404 (0.7696) lr 1.9098e-04 eta 0:03:33
epoch [42/50] batch [60/244] time 0.098 (0.096) data 0.000 (0.004) loss 1.7462 (1.9294) teacher_loss 0.7522 (0.9274) loss_zs_kd 0.6140 (0.5079) loss_oracle 0.4071 (0.4655) acc 84.3750 (74.8438) kd_loss 0.7905 (0.7692) lr 1.9098e-04 eta 0:03:25
epoch [42/50] batch [80/244] time 0.096 (0.095) data 0.000 (0.003) loss 2.0341 (1.9365) teacher_loss 1.2477 (0.9359) loss_zs_kd 0.4748 (0.5082) loss_oracle 0.3682 (0.4657) acc 78.1250 (75.1562) kd_loss 0.6023 (0.7677) lr 1.9098e-04 eta 0:03:21
epoch [42/50] batch [100/244] time 0.099 (0.095) data 0.000 (0.003) loss 2.3645 (1.9305) teacher_loss 1.4435 (0.9316) loss_zs_kd 0.4564 (0.4992) loss_oracle 0.4554 (0.4641) acc 62.5000 (75.1562) kd_loss 0.6933 (0.7668) lr 1.9098e-04 eta 0:03:19
epoch [42/50] batch [120/244] time 0.101 (0.095) data 0.000 (0.002) loss 2.1936 (1.9428) teacher_loss 1.1401 (0.9441) loss_zs_kd 0.5097 (0.5068) loss_oracle 0.4538 (0.4654) acc 71.8750 (74.6615) kd_loss 0.8266 (0.7660) lr 1.9098e-04 eta 0:03:17
epoch [42/50] batch [140/244] time 0.092 (0.095) data 0.000 (0.002) loss 1.6384 (1.9362) teacher_loss 0.5644 (0.9381) loss_zs_kd 0.3688 (0.5044) loss_oracle 0.4726 (0.4631) acc 84.3750 (74.9107) kd_loss 0.8377 (0.7665) lr 1.9098e-04 eta 0:03:15
epoch [42/50] batch [160/244] time 0.090 (0.094) data 0.000 (0.002) loss 1.7578 (1.9306) teacher_loss 0.9022 (0.9361) loss_zs_kd 0.4971 (0.5123) loss_oracle 0.4152 (0.4626) acc 84.3750 (75.1172) kd_loss 0.6481 (0.7633) lr 1.9098e-04 eta 0:03:12
epoch [42/50] batch [180/244] time 0.095 (0.094) data 0.000 (0.002) loss 2.3898 (1.9305) teacher_loss 1.1970 (0.9327) loss_zs_kd 0.5873 (0.5164) loss_oracle 0.5129 (0.4634) acc 78.1250 (75.4340) kd_loss 0.9363 (0.7661) lr 1.9098e-04 eta 0:03:09
epoch [42/50] batch [200/244] time 0.083 (0.094) data 0.000 (0.001) loss 1.6574 (1.9292) teacher_loss 0.6530 (0.9321) loss_zs_kd 0.4438 (0.5141) loss_oracle 0.4733 (0.4621) acc 81.2500 (75.4219) kd_loss 0.7677 (0.7660) lr 1.9098e-04 eta 0:03:06
epoch [42/50] batch [220/244] time 0.116 (0.094) data 0.000 (0.001) loss 1.8690 (1.9314) teacher_loss 0.9936 (0.9345) loss_zs_kd 0.4640 (0.5113) loss_oracle 0.4639 (0.4610) acc 81.2500 (75.4261) kd_loss 0.6435 (0.7664) lr 1.9098e-04 eta 0:03:06
epoch [42/50] batch [240/244] time 0.085 (0.094) data 0.000 (0.001) loss 1.5289 (1.9370) teacher_loss 0.5807 (0.9423) loss_zs_kd 0.5333 (0.5143) loss_oracle 0.4728 (0.4596) acc 81.2500 (75.2214) kd_loss 0.7118 (0.7649) lr 1.9098e-04 eta 0:03:03
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,846
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [43/50] batch [20/244] time 0.128 (0.118) data 0.000 (0.014) loss 1.5577 (1.8686) teacher_loss 0.7178 (0.8701) loss_zs_kd 0.5621 (0.5441) loss_oracle 0.3751 (0.4579) acc 81.2500 (76.2500) kd_loss 0.6524 (0.7696) lr 1.5567e-04 eta 0:03:47
epoch [43/50] batch [40/244] time 0.106 (0.116) data 0.000 (0.007) loss 1.6506 (1.8970) teacher_loss 0.6926 (0.8937) loss_zs_kd 0.4525 (0.5430) loss_oracle 0.4078 (0.4687) acc 78.1250 (75.6250) kd_loss 0.7541 (0.7690) lr 1.5567e-04 eta 0:03:41
epoch [43/50] batch [60/244] time 0.105 (0.113) data 0.000 (0.005) loss 1.9375 (1.8887) teacher_loss 0.9908 (0.8987) loss_zs_kd 0.4356 (0.5487) loss_oracle 0.4350 (0.4633) acc 68.7500 (76.2500) kd_loss 0.7291 (0.7583) lr 1.5567e-04 eta 0:03:32
epoch [43/50] batch [80/244] time 0.115 (0.110) data 0.000 (0.004) loss 1.7145 (1.9148) teacher_loss 0.5464 (0.9112) loss_zs_kd 0.4420 (0.5414) loss_oracle 0.5242 (0.4671) acc 81.2500 (75.8984) kd_loss 0.9060 (0.7701) lr 1.5567e-04 eta 0:03:25
epoch [43/50] batch [100/244] time 0.104 (0.109) data 0.000 (0.003) loss 1.9838 (1.9118) teacher_loss 0.9067 (0.9180) loss_zs_kd 0.5737 (0.5342) loss_oracle 0.5246 (0.4646) acc 71.8750 (75.4688) kd_loss 0.8148 (0.7615) lr 1.5567e-04 eta 0:03:21
epoch [43/50] batch [120/244] time 0.093 (0.107) data 0.000 (0.003) loss 2.1102 (1.9305) teacher_loss 1.0362 (0.9347) loss_zs_kd 0.7999 (0.5272) loss_oracle 0.4926 (0.4622) acc 68.7500 (75.2865) kd_loss 0.8277 (0.7646) lr 1.5567e-04 eta 0:03:16
epoch [43/50] batch [140/244] time 0.108 (0.106) data 0.000 (0.002) loss 1.8140 (1.9287) teacher_loss 0.7458 (0.9360) loss_zs_kd 0.5450 (0.5285) loss_oracle 0.5777 (0.4606) acc 87.5000 (75.3125) kd_loss 0.7794 (0.7624) lr 1.5567e-04 eta 0:03:12
epoch [43/50] batch [160/244] time 0.118 (0.106) data 0.001 (0.002) loss 1.6625 (1.9327) teacher_loss 0.6953 (0.9372) loss_zs_kd 0.3342 (0.5210) loss_oracle 0.3903 (0.4614) acc 75.0000 (75.2930) kd_loss 0.7721 (0.7648) lr 1.5567e-04 eta 0:03:10
epoch [43/50] batch [180/244] time 0.127 (0.107) data 0.001 (0.002) loss 1.6489 (1.9281) teacher_loss 0.7717 (0.9358) loss_zs_kd 0.5821 (0.5197) loss_oracle 0.5083 (0.4593) acc 68.7500 (75.3472) kd_loss 0.6231 (0.7627) lr 1.5567e-04 eta 0:03:09
epoch [43/50] batch [200/244] time 0.119 (0.108) data 0.000 (0.002) loss 2.4541 (1.9318) teacher_loss 1.4492 (0.9394) loss_zs_kd 0.4920 (0.5177) loss_oracle 0.4171 (0.4578) acc 59.3750 (75.1094) kd_loss 0.7963 (0.7634) lr 1.5567e-04 eta 0:03:08
epoch [43/50] batch [220/244] time 0.116 (0.108) data 0.000 (0.002) loss 1.6723 (1.9417) teacher_loss 0.7233 (0.9479) loss_zs_kd 0.5364 (0.5202) loss_oracle 0.4699 (0.4587) acc 78.1250 (74.9290) kd_loss 0.7141 (0.7645) lr 1.5567e-04 eta 0:03:07
epoch [43/50] batch [240/244] time 0.107 (0.108) data 0.000 (0.001) loss 2.3275 (1.9400) teacher_loss 1.2374 (0.9469) loss_zs_kd 0.6482 (0.5179) loss_oracle 0.4939 (0.4571) acc 62.5000 (74.7917) kd_loss 0.8432 (0.7645) lr 1.5567e-04 eta 0:03:05
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,851
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,045
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [44/50] batch [20/244] time 0.108 (0.124) data 0.000 (0.013) loss 2.1670 (1.9432) teacher_loss 1.1041 (0.9349) loss_zs_kd 0.7564 (0.5133) loss_oracle 0.5086 (0.4581) acc 62.5000 (74.0625) kd_loss 0.8085 (0.7793) lr 1.2369e-04 eta 0:03:28
epoch [44/50] batch [40/244] time 0.102 (0.116) data 0.000 (0.007) loss 2.0715 (1.8847) teacher_loss 1.0023 (0.8949) loss_zs_kd 0.5511 (0.5136) loss_oracle 0.4657 (0.4452) acc 71.8750 (75.8594) kd_loss 0.8364 (0.7673) lr 1.2369e-04 eta 0:03:14
epoch [44/50] batch [60/244] time 0.097 (0.110) data 0.000 (0.005) loss 1.5915 (1.8783) teacher_loss 0.7218 (0.8841) loss_zs_kd 0.5237 (0.5039) loss_oracle 0.4440 (0.4458) acc 87.5000 (76.0417) kd_loss 0.6477 (0.7713) lr 1.2369e-04 eta 0:03:01
epoch [44/50] batch [80/244] time 0.093 (0.107) data 0.000 (0.003) loss 2.1888 (1.8898) teacher_loss 1.1802 (0.8967) loss_zs_kd 0.4445 (0.4979) loss_oracle 0.4520 (0.4459) acc 68.7500 (75.7031) kd_loss 0.7826 (0.7701) lr 1.2369e-04 eta 0:02:54
epoch [44/50] batch [100/244] time 0.096 (0.105) data 0.000 (0.003) loss 2.1250 (1.8989) teacher_loss 1.0259 (0.9060) loss_zs_kd 0.4235 (0.4972) loss_oracle 0.3889 (0.4449) acc 81.2500 (75.8750) kd_loss 0.9047 (0.7705) lr 1.2369e-04 eta 0:02:48
epoch [44/50] batch [120/244] time 0.099 (0.103) data 0.000 (0.002) loss 1.9496 (1.9174) teacher_loss 1.0079 (0.9267) loss_zs_kd 0.4769 (0.5016) loss_oracle 0.4502 (0.4467) acc 71.8750 (75.3906) kd_loss 0.7166 (0.7674) lr 1.2369e-04 eta 0:02:44
epoch [44/50] batch [140/244] time 0.103 (0.102) data 0.000 (0.002) loss 2.0691 (1.9297) teacher_loss 1.0209 (0.9352) loss_zs_kd 0.3845 (0.5045) loss_oracle 0.4033 (0.4466) acc 71.8750 (75.2679) kd_loss 0.8465 (0.7712) lr 1.2369e-04 eta 0:02:40
epoch [44/50] batch [160/244] time 0.093 (0.102) data 0.000 (0.002) loss 1.8571 (1.9336) teacher_loss 0.7352 (0.9397) loss_zs_kd 0.9242 (0.5067) loss_oracle 0.4705 (0.4471) acc 81.2500 (75.0586) kd_loss 0.8867 (0.7704) lr 1.2369e-04 eta 0:02:37
epoch [44/50] batch [180/244] time 0.098 (0.101) data 0.000 (0.002) loss 2.1388 (1.9405) teacher_loss 1.1766 (0.9414) loss_zs_kd 0.5598 (0.5164) loss_oracle 0.4901 (0.4505) acc 68.7500 (74.9653) kd_loss 0.7172 (0.7738) lr 1.2369e-04 eta 0:02:34
epoch [44/50] batch [200/244] time 0.097 (0.101) data 0.000 (0.001) loss 1.9697 (1.9383) teacher_loss 1.1447 (0.9442) loss_zs_kd 0.4675 (0.5151) loss_oracle 0.4490 (0.4511) acc 71.8750 (74.8750) kd_loss 0.6005 (0.7686) lr 1.2369e-04 eta 0:02:32
epoch [44/50] batch [220/244] time 0.109 (0.101) data 0.000 (0.001) loss 2.5959 (1.9377) teacher_loss 1.5193 (0.9468) loss_zs_kd 0.5951 (0.5170) loss_oracle 0.5153 (0.4514) acc 65.6250 (74.9290) kd_loss 0.8190 (0.7652) lr 1.2369e-04 eta 0:02:30
epoch [44/50] batch [240/244] time 0.101 (0.101) data 0.000 (0.001) loss 2.1201 (1.9377) teacher_loss 0.9562 (0.9466) loss_zs_kd 0.6472 (0.5186) loss_oracle 0.4856 (0.4520) acc 71.8750 (74.9089) kd_loss 0.9211 (0.7651) lr 1.2369e-04 eta 0:02:28
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,849
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [45/50] batch [20/244] time 0.103 (0.117) data 0.000 (0.013) loss 1.6387 (1.9464) teacher_loss 0.7347 (0.9521) loss_zs_kd 0.4783 (0.5167) loss_oracle 0.4439 (0.4583) acc 81.2500 (72.8125) kd_loss 0.6820 (0.7652) lr 9.5173e-05 eta 0:02:48
epoch [45/50] batch [40/244] time 0.157 (0.111) data 0.000 (0.007) loss 1.9969 (1.9251) teacher_loss 1.0280 (0.9215) loss_zs_kd 0.4220 (0.5165) loss_oracle 0.4562 (0.4610) acc 75.0000 (73.4375) kd_loss 0.7408 (0.7731) lr 9.5173e-05 eta 0:02:37
epoch [45/50] batch [60/244] time 0.104 (0.110) data 0.000 (0.005) loss 2.5097 (1.9312) teacher_loss 1.3527 (0.9354) loss_zs_kd 0.4371 (0.5156) loss_oracle 0.5272 (0.4632) acc 62.5000 (73.5417) kd_loss 0.8934 (0.7642) lr 9.5173e-05 eta 0:02:34
epoch [45/50] batch [80/244] time 0.094 (0.107) data 0.001 (0.004) loss 1.5634 (1.9492) teacher_loss 0.5637 (0.9547) loss_zs_kd 0.3899 (0.5108) loss_oracle 0.4447 (0.4615) acc 87.5000 (73.4375) kd_loss 0.7774 (0.7637) lr 9.5173e-05 eta 0:02:27
epoch [45/50] batch [100/244] time 0.099 (0.105) data 0.000 (0.003) loss 2.0837 (1.9607) teacher_loss 1.1210 (0.9648) loss_zs_kd 0.6406 (0.5123) loss_oracle 0.3931 (0.4642) acc 71.8750 (73.6562) kd_loss 0.7662 (0.7637) lr 9.5173e-05 eta 0:02:22
epoch [45/50] batch [120/244] time 0.100 (0.103) data 0.000 (0.002) loss 1.7168 (1.9436) teacher_loss 0.5825 (0.9496) loss_zs_kd 0.5546 (0.5152) loss_oracle 0.5238 (0.4611) acc 78.1250 (74.3490) kd_loss 0.8724 (0.7635) lr 9.5173e-05 eta 0:02:19
epoch [45/50] batch [140/244] time 0.095 (0.103) data 0.001 (0.002) loss 1.5620 (1.9550) teacher_loss 0.5272 (0.9604) loss_zs_kd 0.5418 (0.5187) loss_oracle 0.3752 (0.4616) acc 90.6250 (74.0179) kd_loss 0.8472 (0.7637) lr 9.5173e-05 eta 0:02:15
epoch [45/50] batch [160/244] time 0.096 (0.102) data 0.000 (0.002) loss 1.9449 (1.9532) teacher_loss 0.8176 (0.9579) loss_zs_kd 0.3874 (0.5181) loss_oracle 0.5608 (0.4630) acc 81.2500 (74.2383) kd_loss 0.8469 (0.7638) lr 9.5173e-05 eta 0:02:13
epoch [45/50] batch [180/244] time 0.099 (0.102) data 0.000 (0.002) loss 2.2124 (1.9562) teacher_loss 1.1373 (0.9648) loss_zs_kd 0.5298 (0.5172) loss_oracle 0.5286 (0.4604) acc 75.0000 (74.3576) kd_loss 0.8108 (0.7612) lr 9.5173e-05 eta 0:02:11
epoch [45/50] batch [200/244] time 0.105 (0.102) data 0.000 (0.002) loss 1.6463 (1.9474) teacher_loss 0.6760 (0.9575) loss_zs_kd 0.4859 (0.5157) loss_oracle 0.3964 (0.4583) acc 78.1250 (74.5000) kd_loss 0.7721 (0.7608) lr 9.5173e-05 eta 0:02:09
epoch [45/50] batch [220/244] time 0.096 (0.102) data 0.000 (0.001) loss 2.0219 (1.9492) teacher_loss 0.8618 (0.9550) loss_zs_kd 0.6521 (0.5144) loss_oracle 0.5225 (0.4577) acc 71.8750 (74.3892) kd_loss 0.8988 (0.7653) lr 9.5173e-05 eta 0:02:07
epoch [45/50] batch [240/244] time 0.114 (0.103) data 0.000 (0.001) loss 2.0927 (1.9508) teacher_loss 1.0522 (0.9529) loss_zs_kd 0.5785 (0.5173) loss_oracle 0.3864 (0.4567) acc 71.8750 (74.5182) kd_loss 0.8473 (0.7696) lr 9.5173e-05 eta 0:02:05
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,851
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [46/50] batch [20/244] time 0.102 (0.127) data 0.000 (0.015) loss 1.9827 (1.9168) teacher_loss 1.0912 (0.9301) loss_zs_kd 0.6276 (0.4959) loss_oracle 0.4627 (0.4605) acc 75.0000 (75.4688) kd_loss 0.6601 (0.7565) lr 7.0224e-05 eta 0:02:32
epoch [46/50] batch [40/244] time 0.100 (0.115) data 0.000 (0.008) loss 1.7242 (1.9508) teacher_loss 0.7574 (0.9593) loss_zs_kd 0.4844 (0.5120) loss_oracle 0.4504 (0.4594) acc 84.3750 (75.0000) kd_loss 0.7417 (0.7618) lr 7.0224e-05 eta 0:02:15
epoch [46/50] batch [60/244] time 0.100 (0.115) data 0.000 (0.005) loss 1.7832 (1.9507) teacher_loss 0.7040 (0.9469) loss_zs_kd 0.4939 (0.5262) loss_oracle 0.4421 (0.4575) acc 81.2500 (74.8958) kd_loss 0.8582 (0.7751) lr 7.0224e-05 eta 0:02:12
epoch [46/50] batch [80/244] time 0.106 (0.111) data 0.000 (0.004) loss 2.0279 (1.9448) teacher_loss 1.2320 (0.9493) loss_zs_kd 0.4717 (0.5209) loss_oracle 0.3733 (0.4532) acc 68.7500 (74.7656) kd_loss 0.6093 (0.7690) lr 7.0224e-05 eta 0:02:06
epoch [46/50] batch [100/244] time 0.103 (0.109) data 0.000 (0.003) loss 1.9625 (1.9337) teacher_loss 1.0123 (0.9343) loss_zs_kd 0.5653 (0.5182) loss_oracle 0.4353 (0.4515) acc 75.0000 (75.2500) kd_loss 0.7325 (0.7736) lr 7.0224e-05 eta 0:02:02
epoch [46/50] batch [120/244] time 0.101 (0.108) data 0.001 (0.003) loss 1.6736 (1.9372) teacher_loss 0.7239 (0.9403) loss_zs_kd 0.4111 (0.5192) loss_oracle 0.3901 (0.4498) acc 84.3750 (75.1302) kd_loss 0.7547 (0.7720) lr 7.0224e-05 eta 0:01:59
epoch [46/50] batch [140/244] time 0.100 (0.107) data 0.000 (0.002) loss 1.5536 (1.9298) teacher_loss 0.4956 (0.9342) loss_zs_kd 0.3792 (0.5178) loss_oracle 0.5021 (0.4499) acc 84.3750 (75.0446) kd_loss 0.8069 (0.7707) lr 7.0224e-05 eta 0:01:56
epoch [46/50] batch [160/244] time 0.102 (0.107) data 0.000 (0.002) loss 2.1082 (1.9210) teacher_loss 1.0854 (0.9264) loss_zs_kd 0.4345 (0.5138) loss_oracle 0.4022 (0.4494) acc 68.7500 (75.1367) kd_loss 0.8217 (0.7699) lr 7.0224e-05 eta 0:01:53
epoch [46/50] batch [180/244] time 0.101 (0.106) data 0.000 (0.002) loss 2.2159 (1.9220) teacher_loss 1.3218 (0.9257) loss_zs_kd 0.4507 (0.5143) loss_oracle 0.4706 (0.4515) acc 62.5000 (74.9826) kd_loss 0.6587 (0.7705) lr 7.0224e-05 eta 0:01:50
epoch [46/50] batch [200/244] time 0.115 (0.106) data 0.001 (0.002) loss 2.7514 (1.9368) teacher_loss 1.7134 (0.9383) loss_zs_kd 0.7335 (0.5179) loss_oracle 0.4940 (0.4527) acc 50.0000 (74.5312) kd_loss 0.7910 (0.7722) lr 7.0224e-05 eta 0:01:47
epoch [46/50] batch [220/244] time 0.100 (0.106) data 0.000 (0.002) loss 1.9271 (1.9402) teacher_loss 0.8304 (0.9418) loss_zs_kd 0.4836 (0.5204) loss_oracle 0.4849 (0.4540) acc 78.1250 (74.5597) kd_loss 0.8543 (0.7714) lr 7.0224e-05 eta 0:01:45
epoch [46/50] batch [240/244] time 0.106 (0.105) data 0.000 (0.001) loss 1.7638 (1.9481) teacher_loss 0.7197 (0.9493) loss_zs_kd 0.5670 (0.5234) loss_oracle 0.4735 (0.4534) acc 75.0000 (74.3750) kd_loss 0.8074 (0.7721) lr 7.0224e-05 eta 0:01:43
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,854
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [47/50] batch [20/244] time 0.101 (0.122) data 0.000 (0.014) loss 1.5724 (1.8515) teacher_loss 0.8267 (0.8744) loss_zs_kd 0.5238 (0.5031) loss_oracle 0.3891 (0.4534) acc 71.8750 (76.2500) kd_loss 0.5511 (0.7504) lr 4.8943e-05 eta 0:01:56
epoch [47/50] batch [40/244] time 0.103 (0.112) data 0.001 (0.007) loss 1.5128 (1.8414) teacher_loss 0.5495 (0.8802) loss_zs_kd 0.4241 (0.5027) loss_oracle 0.3879 (0.4464) acc 84.3750 (76.2500) kd_loss 0.7693 (0.7380) lr 4.8943e-05 eta 0:01:44
epoch [47/50] batch [60/244] time 0.106 (0.112) data 0.000 (0.005) loss 1.6656 (1.9066) teacher_loss 0.7089 (0.9400) loss_zs_kd 0.7976 (0.5123) loss_oracle 0.4635 (0.4462) acc 84.3750 (75.1042) kd_loss 0.7250 (0.7434) lr 4.8943e-05 eta 0:01:42
epoch [47/50] batch [80/244] time 0.094 (0.108) data 0.000 (0.004) loss 1.9870 (1.9184) teacher_loss 0.8693 (0.9381) loss_zs_kd 0.5095 (0.5097) loss_oracle 0.4470 (0.4526) acc 71.8750 (75.3906) kd_loss 0.8941 (0.7540) lr 4.8943e-05 eta 0:01:37
epoch [47/50] batch [100/244] time 0.092 (0.106) data 0.000 (0.003) loss 2.4011 (1.9224) teacher_loss 1.4720 (0.9501) loss_zs_kd 0.6803 (0.5045) loss_oracle 0.4723 (0.4481) acc 71.8750 (75.0312) kd_loss 0.6929 (0.7483) lr 4.8943e-05 eta 0:01:33
epoch [47/50] batch [120/244] time 0.095 (0.105) data 0.000 (0.002) loss 2.0574 (1.9146) teacher_loss 1.0806 (0.9387) loss_zs_kd 0.4557 (0.5041) loss_oracle 0.4340 (0.4497) acc 71.8750 (75.2083) kd_loss 0.7599 (0.7511) lr 4.8943e-05 eta 0:01:29
epoch [47/50] batch [140/244] time 0.094 (0.105) data 0.000 (0.002) loss 2.0419 (1.9248) teacher_loss 1.1609 (0.9440) loss_zs_kd 0.6901 (0.5065) loss_oracle 0.4680 (0.4519) acc 71.8750 (75.0000) kd_loss 0.6470 (0.7548) lr 4.8943e-05 eta 0:01:27
epoch [47/50] batch [160/244] time 0.091 (0.104) data 0.000 (0.002) loss 1.9504 (1.9371) teacher_loss 0.8557 (0.9476) loss_zs_kd 0.3502 (0.5013) loss_oracle 0.4253 (0.4506) acc 87.5000 (75.1562) kd_loss 0.8821 (0.7643) lr 4.8943e-05 eta 0:01:24
epoch [47/50] batch [180/244] time 0.097 (0.103) data 0.000 (0.002) loss 1.8516 (1.9292) teacher_loss 0.8059 (0.9355) loss_zs_kd 0.7588 (0.5025) loss_oracle 0.5272 (0.4520) acc 75.0000 (75.4340) kd_loss 0.7821 (0.7677) lr 4.8943e-05 eta 0:01:21
epoch [47/50] batch [200/244] time 0.098 (0.102) data 0.000 (0.002) loss 1.9647 (1.9281) teacher_loss 0.9111 (0.9335) loss_zs_kd 0.5212 (0.5060) loss_oracle 0.4772 (0.4537) acc 78.1250 (75.4531) kd_loss 0.8150 (0.7678) lr 4.8943e-05 eta 0:01:19
epoch [47/50] batch [220/244] time 0.103 (0.102) data 0.000 (0.001) loss 2.2132 (1.9369) teacher_loss 1.2798 (0.9457) loss_zs_kd 0.6870 (0.5086) loss_oracle 0.4233 (0.4538) acc 68.7500 (75.1278) kd_loss 0.7218 (0.7643) lr 4.8943e-05 eta 0:01:17
epoch [47/50] batch [240/244] time 0.093 (0.102) data 0.000 (0.001) loss 1.8755 (1.9224) teacher_loss 0.9196 (0.9341) loss_zs_kd 0.6981 (0.5115) loss_oracle 0.4714 (0.4535) acc 81.2500 (75.3385) kd_loss 0.7202 (0.7616) lr 4.8943e-05 eta 0:01:15
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,854
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,045
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [48/50] batch [20/244] time 0.099 (0.119) data 0.000 (0.016) loss 1.5822 (1.9834) teacher_loss 0.6192 (1.0035) loss_zs_kd 0.8024 (0.5608) loss_oracle 0.4587 (0.4490) acc 78.1250 (71.4062) kd_loss 0.7336 (0.7554) lr 3.1417e-05 eta 0:01:24
epoch [48/50] batch [40/244] time 0.102 (0.108) data 0.000 (0.008) loss 1.9421 (1.9655) teacher_loss 0.9581 (0.9669) loss_zs_kd 0.2846 (0.5414) loss_oracle 0.4348 (0.4559) acc 65.6250 (72.9688) kd_loss 0.7666 (0.7707) lr 3.1417e-05 eta 0:01:14
epoch [48/50] batch [60/244] time 0.102 (0.109) data 0.001 (0.005) loss 1.8638 (1.9678) teacher_loss 0.9147 (0.9734) loss_zs_kd 0.5067 (0.5253) loss_oracle 0.4286 (0.4552) acc 81.2500 (73.2292) kd_loss 0.7348 (0.7668) lr 3.1417e-05 eta 0:01:13
epoch [48/50] batch [80/244] time 0.093 (0.106) data 0.000 (0.004) loss 1.9351 (1.9725) teacher_loss 1.0075 (0.9773) loss_zs_kd 0.5900 (0.5229) loss_oracle 0.3366 (0.4534) acc 71.8750 (73.2422) kd_loss 0.7593 (0.7686) lr 3.1417e-05 eta 0:01:09
epoch [48/50] batch [100/244] time 0.096 (0.104) data 0.000 (0.003) loss 1.7586 (1.9570) teacher_loss 0.9051 (0.9627) loss_zs_kd 0.4778 (0.5204) loss_oracle 0.4630 (0.4538) acc 75.0000 (73.4688) kd_loss 0.6220 (0.7674) lr 3.1417e-05 eta 0:01:05
epoch [48/50] batch [120/244] time 0.100 (0.103) data 0.000 (0.003) loss 1.5420 (1.9560) teacher_loss 0.7028 (0.9664) loss_zs_kd 0.5109 (0.5186) loss_oracle 0.3995 (0.4526) acc 78.1250 (73.4635) kd_loss 0.6395 (0.7633) lr 3.1417e-05 eta 0:01:03
epoch [48/50] batch [140/244] time 0.093 (0.102) data 0.000 (0.002) loss 2.0943 (1.9624) teacher_loss 1.0203 (0.9720) loss_zs_kd 0.6316 (0.5252) loss_oracle 0.4610 (0.4531) acc 75.0000 (73.5268) kd_loss 0.8434 (0.7639) lr 3.1417e-05 eta 0:01:00
epoch [48/50] batch [160/244] time 0.110 (0.102) data 0.000 (0.002) loss 2.3727 (1.9522) teacher_loss 1.3498 (0.9635) loss_zs_kd 0.3713 (0.5191) loss_oracle 0.4853 (0.4516) acc 68.7500 (73.9453) kd_loss 0.7803 (0.7629) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [180/244] time 0.097 (0.101) data 0.000 (0.002) loss 1.7237 (1.9450) teacher_loss 0.7828 (0.9565) loss_zs_kd 0.4733 (0.5238) loss_oracle 0.5225 (0.4538) acc 81.2500 (74.1319) kd_loss 0.6797 (0.7617) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [200/244] time 0.101 (0.101) data 0.000 (0.002) loss 1.9373 (1.9536) teacher_loss 0.8469 (0.9648) loss_zs_kd 0.6937 (0.5256) loss_oracle 0.4978 (0.4540) acc 78.1250 (74.0781) kd_loss 0.8415 (0.7618) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [220/244] time 0.100 (0.101) data 0.000 (0.002) loss 2.0648 (1.9590) teacher_loss 1.0934 (0.9690) loss_zs_kd 0.4336 (0.5228) loss_oracle 0.4261 (0.4544) acc 71.8750 (73.9773) kd_loss 0.7583 (0.7628) lr 3.1417e-05 eta 0:00:51
epoch [48/50] batch [240/244] time 0.089 (0.100) data 0.000 (0.001) loss 1.7139 (1.9458) teacher_loss 0.8534 (0.9577) loss_zs_kd 0.4478 (0.5237) loss_oracle 0.4139 (0.4535) acc 71.8750 (74.2448) kd_loss 0.6535 (0.7614) lr 3.1417e-05 eta 0:00:49
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,853
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [49/50] batch [20/244] time 0.090 (0.111) data 0.000 (0.014) loss 1.7584 (1.9109) teacher_loss 0.7749 (0.9202) loss_zs_kd 0.4909 (0.5524) loss_oracle 0.4932 (0.4624) acc 75.0000 (77.0312) kd_loss 0.7369 (0.7595) lr 1.7713e-05 eta 0:00:51
epoch [49/50] batch [40/244] time 0.096 (0.104) data 0.000 (0.007) loss 1.9390 (1.8955) teacher_loss 0.9363 (0.9069) loss_zs_kd 0.5471 (0.5226) loss_oracle 0.4124 (0.4634) acc 75.0000 (76.7969) kd_loss 0.7964 (0.7569) lr 1.7713e-05 eta 0:00:46
epoch [49/50] batch [60/244] time 0.099 (0.101) data 0.001 (0.005) loss 1.4918 (1.9052) teacher_loss 0.6175 (0.9151) loss_zs_kd 0.6846 (0.5200) loss_oracle 0.4398 (0.4614) acc 81.2500 (76.1979) kd_loss 0.6544 (0.7594) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [80/244] time 0.138 (0.101) data 0.000 (0.004) loss 1.4239 (1.9159) teacher_loss 0.5804 (0.9204) loss_zs_kd 0.4756 (0.5254) loss_oracle 0.4395 (0.4587) acc 87.5000 (75.8984) kd_loss 0.6237 (0.7662) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [100/244] time 0.099 (0.102) data 0.000 (0.003) loss 1.8620 (1.9388) teacher_loss 0.7182 (0.9418) loss_zs_kd 0.5140 (0.5241) loss_oracle 0.5297 (0.4548) acc 78.1250 (75.2500) kd_loss 0.8790 (0.7696) lr 1.7713e-05 eta 0:00:39
epoch [49/50] batch [120/244] time 0.093 (0.101) data 0.000 (0.003) loss 1.9251 (1.9153) teacher_loss 0.7838 (0.9206) loss_zs_kd 0.5872 (0.5198) loss_oracle 0.3902 (0.4512) acc 81.2500 (75.6250) kd_loss 0.9462 (0.7691) lr 1.7713e-05 eta 0:00:37
epoch [49/50] batch [140/244] time 0.102 (0.100) data 0.000 (0.002) loss 1.8184 (1.8901) teacher_loss 1.1029 (0.9031) loss_zs_kd 0.5448 (0.5213) loss_oracle 0.3862 (0.4506) acc 65.6250 (76.1830) kd_loss 0.5223 (0.7617) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [160/244] time 0.093 (0.100) data 0.000 (0.002) loss 1.7852 (1.9037) teacher_loss 0.8659 (0.9155) loss_zs_kd 0.4158 (0.5182) loss_oracle 0.4245 (0.4505) acc 84.3750 (76.0938) kd_loss 0.7070 (0.7630) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [180/244] time 0.097 (0.099) data 0.001 (0.002) loss 1.7073 (1.9056) teacher_loss 0.8266 (0.9111) loss_zs_kd 0.5734 (0.5157) loss_oracle 0.4652 (0.4518) acc 78.1250 (76.1285) kd_loss 0.6481 (0.7687) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [200/244] time 0.091 (0.099) data 0.000 (0.002) loss 1.8715 (1.9125) teacher_loss 0.8441 (0.9214) loss_zs_kd 0.3831 (0.5142) loss_oracle 0.4171 (0.4524) acc 68.7500 (75.9062) kd_loss 0.8189 (0.7649) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [220/244] time 0.096 (0.099) data 0.000 (0.001) loss 2.7763 (1.9216) teacher_loss 1.8286 (0.9304) loss_zs_kd 0.5125 (0.5134) loss_oracle 0.4624 (0.4530) acc 56.2500 (75.7244) kd_loss 0.7164 (0.7647) lr 1.7713e-05 eta 0:00:26
epoch [49/50] batch [240/244] time 0.086 (0.098) data 0.000 (0.001) loss 2.0355 (1.9224) teacher_loss 1.0703 (0.9309) loss_zs_kd 0.4320 (0.5119) loss_oracle 0.5066 (0.4529) acc 65.6250 (75.6510) kd_loss 0.7119 (0.7650) lr 1.7713e-05 eta 0:00:24
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,853
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
epoch [50/50] batch [20/244] time 0.101 (0.120) data 0.000 (0.014) loss 1.9368 (1.9495) teacher_loss 1.0079 (0.9458) loss_zs_kd 0.5106 (0.5219) loss_oracle 0.4831 (0.4417) acc 68.7500 (73.4375) kd_loss 0.6873 (0.7828) lr 7.8853e-06 eta 0:00:26
epoch [50/50] batch [40/244] time 0.094 (0.107) data 0.000 (0.007) loss 2.0520 (1.9552) teacher_loss 1.0516 (0.9407) loss_zs_kd 0.5228 (0.5135) loss_oracle 0.4404 (0.4493) acc 71.8750 (74.3750) kd_loss 0.7803 (0.7898) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [60/244] time 0.094 (0.103) data 0.001 (0.005) loss 1.4043 (1.9096) teacher_loss 0.3879 (0.9023) loss_zs_kd 0.3390 (0.5195) loss_oracle 0.4133 (0.4566) acc 90.6250 (75.6250) kd_loss 0.8098 (0.7790) lr 7.8853e-06 eta 0:00:19
epoch [50/50] batch [80/244] time 0.098 (0.101) data 0.000 (0.004) loss 2.0239 (1.8970) teacher_loss 1.0671 (0.8976) loss_zs_kd 0.4265 (0.5100) loss_oracle 0.4632 (0.4548) acc 68.7500 (76.0156) kd_loss 0.7252 (0.7719) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [100/244] time 0.125 (0.100) data 0.000 (0.003) loss 2.2940 (1.9163) teacher_loss 1.2137 (0.9186) loss_zs_kd 0.4689 (0.5081) loss_oracle 0.4868 (0.4582) acc 65.6250 (75.4062) kd_loss 0.8369 (0.7686) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [120/244] time 0.100 (0.102) data 0.000 (0.003) loss 1.9974 (1.9070) teacher_loss 0.8868 (0.9124) loss_zs_kd 0.6252 (0.5078) loss_oracle 0.4972 (0.4556) acc 68.7500 (75.6771) kd_loss 0.8620 (0.7668) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [140/244] time 0.100 (0.101) data 0.000 (0.002) loss 1.7164 (1.9155) teacher_loss 0.7805 (0.9188) loss_zs_kd 0.3992 (0.5088) loss_oracle 0.3729 (0.4564) acc 78.1250 (75.3571) kd_loss 0.7494 (0.7685) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [160/244] time 0.091 (0.100) data 0.000 (0.002) loss 1.5164 (1.9042) teacher_loss 0.5798 (0.9119) loss_zs_kd 0.4192 (0.5118) loss_oracle 0.2894 (0.4556) acc 87.5000 (75.4102) kd_loss 0.7919 (0.7645) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [180/244] time 0.097 (0.100) data 0.000 (0.002) loss 2.1731 (1.9092) teacher_loss 1.2456 (0.9192) loss_zs_kd 0.4568 (0.5185) loss_oracle 0.4216 (0.4556) acc 65.6250 (75.3646) kd_loss 0.7168 (0.7623) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [200/244] time 0.102 (0.099) data 0.000 (0.002) loss 1.6093 (1.9126) teacher_loss 0.8189 (0.9211) loss_zs_kd 0.8114 (0.5184) loss_oracle 0.3722 (0.4554) acc 84.3750 (75.2031) kd_loss 0.6043 (0.7637) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [220/244] time 0.103 (0.099) data 0.000 (0.002) loss 2.3010 (1.9114) teacher_loss 1.3436 (0.9179) loss_zs_kd 0.6769 (0.5191) loss_oracle 0.4298 (0.4571) acc 59.3750 (75.2699) kd_loss 0.7425 (0.7649) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [240/244] time 0.086 (0.099) data 0.000 (0.001) loss 1.7545 (1.9240) teacher_loss 0.6851 (0.9280) loss_zs_kd 0.3674 (0.5214) loss_oracle 0.4471 (0.4568) acc 81.2500 (75.0391) kd_loss 0.8458 (0.7676) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,852
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.6%, epoch: 31 *******
******* Domain p best val test acc: 91.1%, epoch: 31 *******
******* Domain p best test acc:     91.5%, epoch: 28 *******
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:26:41

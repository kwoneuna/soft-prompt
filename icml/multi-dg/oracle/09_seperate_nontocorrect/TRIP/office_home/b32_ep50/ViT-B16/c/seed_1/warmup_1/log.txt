Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'product', 'real_world']
Target     ['clipart']
# classes  65
# train_x  7,870
# val      3,353
# test     4,365
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/245] time 0.099 (0.158) data 0.000 (0.016) loss 1.0807 (1.3242) teacher_loss 0.8491 (0.9444) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0001 (-0.0001) acc 75.0000 (76.5625) kd_loss 0.2317 (0.3799) lr 1.0000e-05 eta 0:32:16
epoch [1/50] batch [40/245] time 0.107 (0.130) data 0.001 (0.008) loss 1.1128 (1.3181) teacher_loss 0.8594 (0.9404) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0000 (-0.0001) acc 75.0000 (75.3906) kd_loss 0.2534 (0.3778) lr 1.0000e-05 eta 0:26:23
epoch [1/50] batch [60/245] time 0.103 (0.121) data 0.000 (0.006) loss 1.3521 (1.3189) teacher_loss 0.9571 (0.9520) loss_zs_kd 0.0004 (0.0001) loss_oracle -0.0000 (-0.0001) acc 75.0000 (75.2083) kd_loss 0.3950 (0.3669) lr 1.0000e-05 eta 0:24:31
epoch [1/50] batch [80/245] time 0.107 (0.116) data 0.000 (0.004) loss 1.5122 (1.3368) teacher_loss 1.1435 (0.9671) loss_zs_kd 0.0003 (0.0001) loss_oracle -0.0000 (-0.0001) acc 71.8750 (74.9609) kd_loss 0.3686 (0.3697) lr 1.0000e-05 eta 0:23:35
epoch [1/50] batch [100/245] time 0.103 (0.114) data 0.000 (0.004) loss 0.9829 (1.3035) teacher_loss 0.7693 (0.9381) loss_zs_kd 0.0009 (0.0002) loss_oracle -0.0000 (-0.0000) acc 81.2500 (75.5625) kd_loss 0.2136 (0.3654) lr 1.0000e-05 eta 0:23:04
epoch [1/50] batch [120/245] time 0.105 (0.112) data 0.000 (0.003) loss 1.1564 (1.2861) teacher_loss 0.8096 (0.9247) loss_zs_kd 0.0006 (0.0004) loss_oracle -0.0000 (-0.0000) acc 75.0000 (75.5990) kd_loss 0.3469 (0.3613) lr 1.0000e-05 eta 0:22:32
epoch [1/50] batch [140/245] time 0.106 (0.110) data 0.000 (0.003) loss 0.6771 (1.2770) teacher_loss 0.3281 (0.9151) loss_zs_kd 0.0007 (0.0005) loss_oracle 0.0001 (-0.0000) acc 93.7500 (75.6473) kd_loss 0.3489 (0.3619) lr 1.0000e-05 eta 0:22:16
epoch [1/50] batch [160/245] time 0.158 (0.110) data 0.000 (0.002) loss 1.3384 (1.2797) teacher_loss 0.9887 (0.9121) loss_zs_kd 0.0018 (0.0007) loss_oracle 0.0004 (0.0000) acc 71.8750 (75.6250) kd_loss 0.3495 (0.3676) lr 1.0000e-05 eta 0:22:07
epoch [1/50] batch [180/245] time 0.101 (0.109) data 0.000 (0.002) loss 1.0656 (1.2742) teacher_loss 0.5482 (0.9069) loss_zs_kd 0.0019 (0.0008) loss_oracle 0.0002 (0.0000) acc 84.3750 (75.5035) kd_loss 0.5173 (0.3673) lr 1.0000e-05 eta 0:21:54
epoch [1/50] batch [200/245] time 0.096 (0.108) data 0.000 (0.002) loss 0.7874 (1.2767) teacher_loss 0.5808 (0.9123) loss_zs_kd 0.0009 (0.0009) loss_oracle 0.0002 (0.0001) acc 84.3750 (75.3438) kd_loss 0.2064 (0.3644) lr 1.0000e-05 eta 0:21:39
epoch [1/50] batch [220/245] time 0.096 (0.107) data 0.000 (0.002) loss 1.7136 (1.2637) teacher_loss 1.4100 (0.9044) loss_zs_kd 0.0048 (0.0010) loss_oracle 0.0006 (0.0001) acc 56.2500 (75.5540) kd_loss 0.3033 (0.3593) lr 1.0000e-05 eta 0:21:26
epoch [1/50] batch [240/245] time 0.099 (0.106) data 0.000 (0.002) loss 1.1253 (1.2650) teacher_loss 0.8903 (0.9054) loss_zs_kd 0.0017 (0.0012) loss_oracle 0.0003 (0.0001) acc 75.0000 (75.4818) kd_loss 0.2349 (0.3596) lr 1.0000e-05 eta 0:21:15
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 2,926
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 85.9%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,081
* accuracy: 70.6%
* error: 29.4%
* macro_f1: 69.2%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      87.3%, epoch: 1 *******
******* Domain c best val test acc: 70.6%, epoch: 1 *******
******* Domain c best test acc:     70.6%, epoch: 1 *******
epoch [2/50] batch [20/245] time 0.087 (0.105) data 0.001 (0.015) loss 1.5636 (1.4110) teacher_loss 0.8689 (0.8805) loss_zs_kd 0.1451 (0.1099) loss_oracle 0.1798 (0.0981) acc 75.0000 (75.4688) kd_loss 0.6048 (0.4815) lr 2.0000e-03 eta 0:20:54
epoch [2/50] batch [40/245] time 0.093 (0.099) data 0.000 (0.008) loss 1.7534 (1.5022) teacher_loss 1.0432 (0.8476) loss_zs_kd 0.1439 (0.1553) loss_oracle 0.3236 (0.2201) acc 68.7500 (76.5625) kd_loss 0.5484 (0.5445) lr 2.0000e-03 eta 0:19:42
epoch [2/50] batch [60/245] time 0.092 (0.098) data 0.000 (0.005) loss 1.6065 (1.5359) teacher_loss 0.7127 (0.8304) loss_zs_kd 0.2183 (0.1755) loss_oracle 0.4201 (0.2693) acc 78.1250 (77.2917) kd_loss 0.6837 (0.5708) lr 2.0000e-03 eta 0:19:33
epoch [2/50] batch [80/245] time 0.092 (0.097) data 0.000 (0.004) loss 1.5490 (1.5495) teacher_loss 0.5823 (0.8235) loss_zs_kd 0.1617 (0.1832) loss_oracle 0.4260 (0.2826) acc 84.3750 (77.6562) kd_loss 0.7537 (0.5848) lr 2.0000e-03 eta 0:19:22
epoch [2/50] batch [100/245] time 0.096 (0.098) data 0.000 (0.003) loss 1.1695 (1.5385) teacher_loss 0.5400 (0.7957) loss_zs_kd 0.2533 (0.1884) loss_oracle 0.2887 (0.3030) acc 84.3750 (78.4688) kd_loss 0.4852 (0.5913) lr 2.0000e-03 eta 0:19:22
epoch [2/50] batch [120/245] time 0.096 (0.098) data 0.000 (0.003) loss 1.5887 (1.5599) teacher_loss 0.7881 (0.8091) loss_zs_kd 0.2046 (0.1899) loss_oracle 0.3634 (0.3070) acc 75.0000 (78.2292) kd_loss 0.6188 (0.5973) lr 2.0000e-03 eta 0:19:19
epoch [2/50] batch [140/245] time 0.091 (0.097) data 0.000 (0.002) loss 1.9520 (1.5639) teacher_loss 1.0091 (0.7959) loss_zs_kd 0.2381 (0.1901) loss_oracle 0.4327 (0.3217) acc 68.7500 (78.3705) kd_loss 0.7266 (0.6072) lr 2.0000e-03 eta 0:19:13
epoch [2/50] batch [160/245] time 0.094 (0.097) data 0.000 (0.002) loss 2.2646 (1.5855) teacher_loss 1.3168 (0.7964) loss_zs_kd 0.1844 (0.1923) loss_oracle 0.4311 (0.3403) acc 71.8750 (78.6133) kd_loss 0.7323 (0.6190) lr 2.0000e-03 eta 0:19:06
epoch [2/50] batch [180/245] time 0.092 (0.098) data 0.000 (0.002) loss 2.0356 (1.6028) teacher_loss 1.1640 (0.7971) loss_zs_kd 0.1969 (0.1957) loss_oracle 0.4592 (0.3548) acc 71.8750 (78.7847) kd_loss 0.6420 (0.6283) lr 2.0000e-03 eta 0:19:15
epoch [2/50] batch [200/245] time 0.093 (0.098) data 0.000 (0.002) loss 1.8955 (1.6158) teacher_loss 0.7751 (0.7970) loss_zs_kd 0.2203 (0.1982) loss_oracle 0.6012 (0.3665) acc 78.1250 (78.7344) kd_loss 0.8198 (0.6355) lr 2.0000e-03 eta 0:19:11
epoch [2/50] batch [220/245] time 0.100 (0.097) data 0.000 (0.002) loss 1.9165 (1.6430) teacher_loss 0.6379 (0.7975) loss_zs_kd 0.3921 (0.2031) loss_oracle 0.7528 (0.3903) acc 78.1250 (78.6222) kd_loss 0.9022 (0.6504) lr 2.0000e-03 eta 0:19:05
epoch [2/50] batch [240/245] time 0.084 (0.097) data 0.000 (0.001) loss 1.6274 (1.6533) teacher_loss 0.5888 (0.7880) loss_zs_kd 0.3077 (0.2076) loss_oracle 0.5293 (0.4085) acc 84.3750 (78.7500) kd_loss 0.7739 (0.6611) lr 2.0000e-03 eta 0:18:57
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,013
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 88.9%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,171
* accuracy: 72.6%
* error: 27.4%
* macro_f1: 71.3%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      89.9%, epoch: 2 *******
******* Domain c best val test acc: 72.6%, epoch: 2 *******
******* Domain c best test acc:     72.6%, epoch: 2 *******
epoch [3/50] batch [20/245] time 0.094 (0.111) data 0.001 (0.014) loss 1.4453 (1.6922) teacher_loss 0.4479 (0.6578) loss_zs_kd 0.2348 (0.2494) loss_oracle 0.5122 (0.5819) acc 93.7500 (82.6562) kd_loss 0.7414 (0.7434) lr 1.9980e-03 eta 0:21:45
epoch [3/50] batch [40/245] time 0.094 (0.103) data 0.000 (0.007) loss 1.3299 (1.7117) teacher_loss 0.5593 (0.7245) loss_zs_kd 0.1351 (0.2352) loss_oracle 0.3446 (0.5349) acc 78.1250 (80.6250) kd_loss 0.5983 (0.7197) lr 1.9980e-03 eta 0:20:08
epoch [3/50] batch [60/245] time 0.097 (0.100) data 0.001 (0.005) loss 1.7945 (1.6203) teacher_loss 1.0216 (0.7222) loss_zs_kd 0.2008 (0.2265) loss_oracle 0.2593 (0.4489) acc 75.0000 (80.6771) kd_loss 0.6432 (0.6737) lr 1.9980e-03 eta 0:19:34
epoch [3/50] batch [80/245] time 0.096 (0.099) data 0.000 (0.004) loss 1.2965 (1.5839) teacher_loss 0.5732 (0.7241) loss_zs_kd 0.3370 (0.2261) loss_oracle 0.4118 (0.4149) acc 81.2500 (80.6250) kd_loss 0.5175 (0.6524) lr 1.9980e-03 eta 0:19:12
epoch [3/50] batch [100/245] time 0.098 (0.098) data 0.000 (0.003) loss 1.5166 (1.5711) teacher_loss 0.8216 (0.7325) loss_zs_kd 0.2792 (0.2357) loss_oracle 0.3570 (0.3981) acc 81.2500 (80.1562) kd_loss 0.5165 (0.6395) lr 1.9980e-03 eta 0:18:59
epoch [3/50] batch [120/245] time 0.088 (0.097) data 0.000 (0.003) loss 1.2017 (1.5668) teacher_loss 0.2638 (0.7214) loss_zs_kd 0.1826 (0.2358) loss_oracle 0.4742 (0.4052) acc 93.7500 (80.3646) kd_loss 0.7008 (0.6428) lr 1.9980e-03 eta 0:18:52
epoch [3/50] batch [140/245] time 0.101 (0.097) data 0.000 (0.002) loss 1.7216 (1.5947) teacher_loss 0.6565 (0.7319) loss_zs_kd 0.2588 (0.2374) loss_oracle 0.5961 (0.4256) acc 78.1250 (80.2009) kd_loss 0.7670 (0.6500) lr 1.9980e-03 eta 0:18:46
epoch [3/50] batch [160/245] time 0.095 (0.097) data 0.000 (0.002) loss 1.3536 (1.6106) teacher_loss 0.4666 (0.7307) loss_zs_kd 0.2534 (0.2337) loss_oracle 0.4736 (0.4422) acc 87.5000 (80.2148) kd_loss 0.6502 (0.6588) lr 1.9980e-03 eta 0:18:40
epoch [3/50] batch [180/245] time 0.091 (0.096) data 0.000 (0.002) loss 1.4948 (1.6137) teacher_loss 0.6321 (0.7324) loss_zs_kd 0.1359 (0.2333) loss_oracle 0.3351 (0.4388) acc 75.0000 (80.0347) kd_loss 0.6952 (0.6619) lr 1.9980e-03 eta 0:18:33
epoch [3/50] batch [200/245] time 0.092 (0.098) data 0.000 (0.002) loss 1.6070 (1.6074) teacher_loss 0.7935 (0.7348) loss_zs_kd 0.3331 (0.2330) loss_oracle 0.3749 (0.4300) acc 81.2500 (79.9531) kd_loss 0.6260 (0.6576) lr 1.9980e-03 eta 0:18:49
epoch [3/50] batch [220/245] time 0.100 (0.097) data 0.000 (0.002) loss 1.5340 (1.6006) teacher_loss 0.9078 (0.7369) loss_zs_kd 0.3189 (0.2382) loss_oracle 0.1882 (0.4190) acc 75.0000 (79.9290) kd_loss 0.5321 (0.6542) lr 1.9980e-03 eta 0:18:45
epoch [3/50] batch [240/245] time 0.084 (0.097) data 0.000 (0.001) loss 0.8615 (1.5877) teacher_loss 0.2112 (0.7367) loss_zs_kd 0.4372 (0.2427) loss_oracle 0.2413 (0.4085) acc 93.7500 (80.0911) kd_loss 0.5296 (0.6467) lr 1.9980e-03 eta 0:18:35
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,019
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.2%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,215
* accuracy: 73.7%
* error: 26.3%
* macro_f1: 72.4%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      90.0%, epoch: 3 *******
******* Domain c best val test acc: 73.7%, epoch: 3 *******
******* Domain c best test acc:     73.7%, epoch: 3 *******
epoch [4/50] batch [20/245] time 0.089 (0.120) data 0.000 (0.017) loss 1.6446 (1.5664) teacher_loss 0.9334 (0.7698) loss_zs_kd 0.4024 (0.2869) loss_oracle 0.2642 (0.3541) acc 71.8750 (79.2188) kd_loss 0.5791 (0.6195) lr 1.9921e-03 eta 0:23:02
epoch [4/50] batch [40/245] time 0.096 (0.108) data 0.000 (0.009) loss 1.5504 (1.5392) teacher_loss 0.8497 (0.7639) loss_zs_kd 0.3191 (0.2839) loss_oracle 0.3002 (0.3296) acc 81.2500 (78.9062) kd_loss 0.5506 (0.6104) lr 1.9921e-03 eta 0:20:36
epoch [4/50] batch [60/245] time 0.090 (0.103) data 0.000 (0.006) loss 1.0657 (1.4857) teacher_loss 0.5007 (0.7380) loss_zs_kd 0.4315 (0.2686) loss_oracle 0.2214 (0.3174) acc 90.6250 (79.5833) kd_loss 0.4543 (0.5891) lr 1.9921e-03 eta 0:19:34
epoch [4/50] batch [80/245] time 0.093 (0.101) data 0.000 (0.004) loss 1.3614 (1.4900) teacher_loss 0.6191 (0.7496) loss_zs_kd 0.2053 (0.2635) loss_oracle 0.3146 (0.3128) acc 78.1250 (78.8672) kd_loss 0.5850 (0.5840) lr 1.9921e-03 eta 0:19:11
epoch [4/50] batch [100/245] time 0.091 (0.100) data 0.000 (0.004) loss 1.2661 (1.4790) teacher_loss 0.6808 (0.7400) loss_zs_kd 0.2876 (0.2635) loss_oracle 0.2484 (0.3144) acc 84.3750 (79.5312) kd_loss 0.4611 (0.5818) lr 1.9921e-03 eta 0:19:02
epoch [4/50] batch [120/245] time 0.102 (0.100) data 0.001 (0.003) loss 1.6314 (1.4810) teacher_loss 0.9628 (0.7489) loss_zs_kd 0.2648 (0.2629) loss_oracle 0.2698 (0.3095) acc 71.8750 (79.3229) kd_loss 0.5337 (0.5773) lr 1.9921e-03 eta 0:18:54
epoch [4/50] batch [140/245] time 0.110 (0.100) data 0.000 (0.003) loss 1.4731 (1.4774) teacher_loss 0.6099 (0.7479) loss_zs_kd 0.2840 (0.2629) loss_oracle 0.2719 (0.3061) acc 84.3750 (79.4866) kd_loss 0.7273 (0.5765) lr 1.9921e-03 eta 0:18:55
epoch [4/50] batch [160/245] time 0.085 (0.100) data 0.000 (0.002) loss 1.1074 (1.4698) teacher_loss 0.4080 (0.7439) loss_zs_kd 0.2019 (0.2629) loss_oracle 0.2533 (0.3004) acc 90.6250 (79.7266) kd_loss 0.5728 (0.5757) lr 1.9921e-03 eta 0:18:56
epoch [4/50] batch [180/245] time 0.092 (0.100) data 0.000 (0.002) loss 0.9963 (1.4551) teacher_loss 0.3310 (0.7346) loss_zs_kd 0.1887 (0.2609) loss_oracle 0.2211 (0.2970) acc 96.8750 (80.0174) kd_loss 0.5547 (0.5720) lr 1.9921e-03 eta 0:18:52
epoch [4/50] batch [200/245] time 0.149 (0.101) data 0.000 (0.002) loss 1.2577 (1.4505) teacher_loss 0.5414 (0.7303) loss_zs_kd 0.2674 (0.2626) loss_oracle 0.2785 (0.2969) acc 81.2500 (80.0625) kd_loss 0.5771 (0.5718) lr 1.9921e-03 eta 0:19:00
epoch [4/50] batch [220/245] time 0.093 (0.101) data 0.000 (0.002) loss 1.3035 (1.4545) teacher_loss 0.5032 (0.7325) loss_zs_kd 0.3178 (0.2613) loss_oracle 0.3214 (0.3007) acc 84.3750 (79.9858) kd_loss 0.6396 (0.5716) lr 1.9921e-03 eta 0:19:01
epoch [4/50] batch [240/245] time 0.082 (0.100) data 0.000 (0.002) loss 1.7976 (1.4601) teacher_loss 1.0630 (0.7373) loss_zs_kd 0.2297 (0.2612) loss_oracle 0.3124 (0.3006) acc 68.7500 (79.8177) kd_loss 0.5785 (0.5725) lr 1.9921e-03 eta 0:18:47
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,041
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,227
* accuracy: 73.9%
* error: 26.1%
* macro_f1: 72.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      90.7%, epoch: 4 *******
******* Domain c best val test acc: 73.9%, epoch: 4 *******
******* Domain c best test acc:     73.9%, epoch: 4 *******
epoch [5/50] batch [20/245] time 0.094 (0.117) data 0.000 (0.013) loss 1.7579 (1.4630) teacher_loss 1.1130 (0.8084) loss_zs_kd 0.3404 (0.2617) loss_oracle 0.2505 (0.2331) acc 71.8750 (77.8125) kd_loss 0.5196 (0.5380) lr 1.9823e-03 eta 0:21:56
epoch [5/50] batch [40/245] time 0.107 (0.109) data 0.000 (0.007) loss 1.6269 (1.4887) teacher_loss 0.8715 (0.7839) loss_zs_kd 0.2596 (0.2710) loss_oracle 0.3329 (0.2817) acc 78.1250 (78.3594) kd_loss 0.5890 (0.5639) lr 1.9823e-03 eta 0:20:29
epoch [5/50] batch [60/245] time 0.098 (0.106) data 0.001 (0.005) loss 1.5053 (1.5053) teacher_loss 0.7812 (0.7709) loss_zs_kd 0.1508 (0.2627) loss_oracle 0.3585 (0.3101) acc 75.0000 (79.0625) kd_loss 0.5448 (0.5793) lr 1.9823e-03 eta 0:19:51
epoch [5/50] batch [80/245] time 0.112 (0.106) data 0.000 (0.004) loss 1.2655 (1.5073) teacher_loss 0.6283 (0.7608) loss_zs_kd 0.3619 (0.2681) loss_oracle 0.2720 (0.3187) acc 84.3750 (79.3750) kd_loss 0.5012 (0.5872) lr 1.9823e-03 eta 0:19:41
epoch [5/50] batch [100/245] time 0.112 (0.108) data 0.000 (0.003) loss 0.9234 (1.4869) teacher_loss 0.2869 (0.7393) loss_zs_kd 0.2583 (0.2680) loss_oracle 0.3015 (0.3204) acc 87.5000 (79.6250) kd_loss 0.4858 (0.5874) lr 1.9823e-03 eta 0:20:09
epoch [5/50] batch [120/245] time 0.121 (0.110) data 0.001 (0.002) loss 1.3658 (1.4818) teacher_loss 0.6090 (0.7378) loss_zs_kd 0.2966 (0.2695) loss_oracle 0.2606 (0.3174) acc 81.2500 (79.4531) kd_loss 0.6265 (0.5853) lr 1.9823e-03 eta 0:20:28
epoch [5/50] batch [140/245] time 0.103 (0.111) data 0.000 (0.002) loss 1.3562 (1.4741) teacher_loss 0.5228 (0.7287) loss_zs_kd 0.2675 (0.2643) loss_oracle 0.4120 (0.3233) acc 81.2500 (79.6205) kd_loss 0.6273 (0.5838) lr 1.9823e-03 eta 0:20:33
epoch [5/50] batch [160/245] time 0.118 (0.111) data 0.001 (0.002) loss 1.3573 (1.4719) teacher_loss 0.6041 (0.7257) loss_zs_kd 0.2631 (0.2634) loss_oracle 0.3099 (0.3241) acc 84.3750 (79.7852) kd_loss 0.5982 (0.5841) lr 1.9823e-03 eta 0:20:35
epoch [5/50] batch [180/245] time 0.110 (0.111) data 0.000 (0.002) loss 1.5690 (1.4831) teacher_loss 0.6865 (0.7329) loss_zs_kd 0.4718 (0.2649) loss_oracle 0.4644 (0.3293) acc 84.3750 (79.4965) kd_loss 0.6503 (0.5856) lr 1.9823e-03 eta 0:20:30
epoch [5/50] batch [200/245] time 0.118 (0.112) data 0.001 (0.002) loss 1.4619 (1.4857) teacher_loss 0.6806 (0.7334) loss_zs_kd 0.2576 (0.2667) loss_oracle 0.5150 (0.3353) acc 75.0000 (79.5312) kd_loss 0.5238 (0.5846) lr 1.9823e-03 eta 0:20:39
epoch [5/50] batch [220/245] time 0.108 (0.111) data 0.000 (0.002) loss 2.0152 (1.4965) teacher_loss 1.1204 (0.7347) loss_zs_kd 0.2340 (0.2657) loss_oracle 0.5014 (0.3453) acc 71.8750 (79.6165) kd_loss 0.6442 (0.5891) lr 1.9823e-03 eta 0:20:30
epoch [5/50] batch [240/245] time 0.110 (0.111) data 0.000 (0.001) loss 1.7073 (1.5069) teacher_loss 1.0259 (0.7381) loss_zs_kd 0.3016 (0.2655) loss_oracle 0.3625 (0.3517) acc 62.5000 (79.4271) kd_loss 0.5002 (0.5930) lr 1.9823e-03 eta 0:20:21
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,047
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.0%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,245
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 73.1%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      90.9%, epoch: 5 *******
******* Domain c best val test acc: 74.3%, epoch: 5 *******
******* Domain c best test acc:     74.3%, epoch: 5 *******
epoch [6/50] batch [20/245] time 0.130 (0.141) data 0.000 (0.015) loss 1.5987 (1.5420) teacher_loss 0.7639 (0.6721) loss_zs_kd 0.2151 (0.2617) loss_oracle 0.4792 (0.4489) acc 78.1250 (81.8750) kd_loss 0.5952 (0.6454) lr 1.9686e-03 eta 0:25:52
epoch [6/50] batch [40/245] time 0.125 (0.128) data 0.000 (0.008) loss 1.8816 (1.5761) teacher_loss 1.0029 (0.6982) loss_zs_kd 0.2367 (0.2478) loss_oracle 0.3318 (0.4329) acc 68.7500 (80.2344) kd_loss 0.7128 (0.6614) lr 1.9686e-03 eta 0:23:31
epoch [6/50] batch [60/245] time 0.115 (0.122) data 0.000 (0.005) loss 1.5735 (1.5417) teacher_loss 0.7904 (0.6989) loss_zs_kd 0.2959 (0.2522) loss_oracle 0.3259 (0.3969) acc 75.0000 (80.1562) kd_loss 0.6201 (0.6444) lr 1.9686e-03 eta 0:22:20
epoch [6/50] batch [80/245] time 0.122 (0.118) data 0.000 (0.004) loss 1.1522 (1.5048) teacher_loss 0.5643 (0.6947) loss_zs_kd 0.2689 (0.2576) loss_oracle 0.3053 (0.3730) acc 75.0000 (80.4297) kd_loss 0.4352 (0.6236) lr 1.9686e-03 eta 0:21:34
epoch [6/50] batch [100/245] time 0.105 (0.115) data 0.001 (0.003) loss 1.9957 (1.4841) teacher_loss 1.2264 (0.6832) loss_zs_kd 0.3213 (0.2585) loss_oracle 0.3943 (0.3689) acc 65.6250 (81.1562) kd_loss 0.5721 (0.6165) lr 1.9686e-03 eta 0:20:58
epoch [6/50] batch [120/245] time 0.104 (0.113) data 0.000 (0.003) loss 1.5613 (1.4563) teacher_loss 0.9129 (0.6758) loss_zs_kd 0.3888 (0.2659) loss_oracle 0.2710 (0.3559) acc 71.8750 (81.3021) kd_loss 0.5128 (0.6026) lr 1.9686e-03 eta 0:20:31
epoch [6/50] batch [140/245] time 0.100 (0.112) data 0.000 (0.002) loss 1.5334 (1.4526) teacher_loss 0.9317 (0.6822) loss_zs_kd 0.2747 (0.2687) loss_oracle 0.2697 (0.3439) acc 75.0000 (81.1161) kd_loss 0.4668 (0.5984) lr 1.9686e-03 eta 0:20:13
epoch [6/50] batch [160/245] time 0.100 (0.110) data 0.000 (0.002) loss 1.3522 (1.4459) teacher_loss 0.4993 (0.6839) loss_zs_kd 0.2676 (0.2709) loss_oracle 0.2810 (0.3345) acc 87.5000 (80.8203) kd_loss 0.7124 (0.5948) lr 1.9686e-03 eta 0:19:58
epoch [6/50] batch [180/245] time 0.098 (0.110) data 0.001 (0.002) loss 1.4612 (1.4474) teacher_loss 0.5608 (0.6815) loss_zs_kd 0.2697 (0.2744) loss_oracle 0.3793 (0.3346) acc 87.5000 (80.9028) kd_loss 0.7107 (0.5985) lr 1.9686e-03 eta 0:19:58
epoch [6/50] batch [200/245] time 0.100 (0.109) data 0.000 (0.002) loss 0.9632 (1.4457) teacher_loss 0.2827 (0.6840) loss_zs_kd 0.3038 (0.2740) loss_oracle 0.2980 (0.3321) acc 96.8750 (80.9844) kd_loss 0.5314 (0.5957) lr 1.9686e-03 eta 0:19:43
epoch [6/50] batch [220/245] time 0.098 (0.108) data 0.000 (0.002) loss 1.3858 (1.4544) teacher_loss 0.6930 (0.6945) loss_zs_kd 0.2253 (0.2761) loss_oracle 0.3552 (0.3318) acc 84.3750 (80.6960) kd_loss 0.5152 (0.5940) lr 1.9686e-03 eta 0:19:31
epoch [6/50] batch [240/245] time 0.097 (0.107) data 0.000 (0.001) loss 1.3948 (1.4490) teacher_loss 0.6084 (0.6864) loss_zs_kd 0.2708 (0.2749) loss_oracle 0.3545 (0.3352) acc 78.1250 (80.7031) kd_loss 0.6091 (0.5949) lr 1.9686e-03 eta 0:19:15
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,042
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.9%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,224
* accuracy: 73.9%
* error: 26.1%
* macro_f1: 72.6%
******* Domain c best val acc:      90.9%, epoch: 5 *******
******* Domain c best val test acc: 74.3%, epoch: 5 *******
******* Domain c best test acc:     74.3%, epoch: 5 *******
epoch [7/50] batch [20/245] time 0.101 (0.121) data 0.000 (0.014) loss 1.8151 (1.5111) teacher_loss 1.1084 (0.7753) loss_zs_kd 0.2513 (0.2625) loss_oracle 0.3433 (0.3430) acc 68.7500 (80.0000) kd_loss 0.5351 (0.5643) lr 1.9511e-03 eta 0:21:39
epoch [7/50] batch [40/245] time 0.095 (0.113) data 0.000 (0.007) loss 1.1930 (1.4893) teacher_loss 0.3944 (0.7367) loss_zs_kd 0.2657 (0.2945) loss_oracle 0.3345 (0.3486) acc 87.5000 (80.4688) kd_loss 0.6313 (0.5783) lr 1.9511e-03 eta 0:20:14
epoch [7/50] batch [60/245] time 0.103 (0.109) data 0.000 (0.005) loss 1.6033 (1.4730) teacher_loss 0.8403 (0.7154) loss_zs_kd 0.2875 (0.2973) loss_oracle 0.3817 (0.3527) acc 75.0000 (81.0938) kd_loss 0.5722 (0.5812) lr 1.9511e-03 eta 0:19:27
epoch [7/50] batch [80/245] time 0.094 (0.107) data 0.000 (0.004) loss 1.5562 (1.4592) teacher_loss 0.7618 (0.7065) loss_zs_kd 0.2544 (0.2920) loss_oracle 0.3138 (0.3440) acc 81.2500 (81.1719) kd_loss 0.6375 (0.5807) lr 1.9511e-03 eta 0:18:59
epoch [7/50] batch [100/245] time 0.100 (0.105) data 0.000 (0.003) loss 1.4189 (1.4610) teacher_loss 0.6880 (0.7112) loss_zs_kd 0.2256 (0.2974) loss_oracle 0.3345 (0.3380) acc 81.2500 (81.2500) kd_loss 0.5637 (0.5808) lr 1.9511e-03 eta 0:18:42
epoch [7/50] batch [120/245] time 0.105 (0.104) data 0.000 (0.003) loss 1.3987 (1.4619) teacher_loss 0.6490 (0.7103) loss_zs_kd 0.2380 (0.2984) loss_oracle 0.3362 (0.3380) acc 81.2500 (81.1979) kd_loss 0.5816 (0.5826) lr 1.9511e-03 eta 0:18:29
epoch [7/50] batch [140/245] time 0.098 (0.104) data 0.000 (0.002) loss 1.5100 (1.4687) teacher_loss 0.7426 (0.7159) loss_zs_kd 0.1965 (0.2990) loss_oracle 0.2908 (0.3373) acc 87.5000 (80.8705) kd_loss 0.6221 (0.5841) lr 1.9511e-03 eta 0:18:21
epoch [7/50] batch [160/245] time 0.102 (0.103) data 0.000 (0.002) loss 1.4273 (1.4739) teacher_loss 0.7049 (0.7236) loss_zs_kd 0.2624 (0.2972) loss_oracle 0.3447 (0.3346) acc 84.3750 (80.7031) kd_loss 0.5501 (0.5830) lr 1.9511e-03 eta 0:18:16
epoch [7/50] batch [180/245] time 0.128 (0.104) data 0.000 (0.002) loss 1.2313 (1.4687) teacher_loss 0.4742 (0.7192) loss_zs_kd 0.4106 (0.2958) loss_oracle 0.2980 (0.3340) acc 81.2500 (80.7118) kd_loss 0.6081 (0.5825) lr 1.9511e-03 eta 0:18:20
epoch [7/50] batch [200/245] time 0.103 (0.104) data 0.000 (0.002) loss 1.5421 (1.4616) teacher_loss 0.7765 (0.7111) loss_zs_kd 0.1791 (0.2930) loss_oracle 0.3079 (0.3319) acc 81.2500 (80.9062) kd_loss 0.6116 (0.5845) lr 1.9511e-03 eta 0:18:17
epoch [7/50] batch [220/245] time 0.105 (0.103) data 0.000 (0.002) loss 1.1782 (1.4559) teacher_loss 0.6439 (0.7077) loss_zs_kd 0.2452 (0.2922) loss_oracle 0.3068 (0.3295) acc 84.3750 (81.0085) kd_loss 0.3809 (0.5834) lr 1.9511e-03 eta 0:18:10
epoch [7/50] batch [240/245] time 0.088 (0.103) data 0.000 (0.001) loss 0.9729 (1.4448) teacher_loss 0.2812 (0.6974) loss_zs_kd 0.2036 (0.2894) loss_oracle 0.3860 (0.3315) acc 90.6250 (81.2500) kd_loss 0.4987 (0.5816) lr 1.9511e-03 eta 0:18:00
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,049
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.0%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,238
* accuracy: 74.2%
* error: 25.8%
* macro_f1: 73.0%
******* Domain c best val acc:      90.9%, epoch: 7 *******
******* Domain c best val test acc: 74.2%, epoch: 7 *******
******* Domain c best test acc:     74.3%, epoch: 5 *******
epoch [8/50] batch [20/245] time 0.095 (0.111) data 0.000 (0.014) loss 1.8742 (1.5609) teacher_loss 1.0529 (0.7561) loss_zs_kd 0.2374 (0.3030) loss_oracle 0.3549 (0.3877) acc 65.6250 (79.5312) kd_loss 0.6439 (0.6109) lr 1.9298e-03 eta 0:19:22
epoch [8/50] batch [40/245] time 0.093 (0.103) data 0.000 (0.007) loss 1.1719 (1.4904) teacher_loss 0.4403 (0.7098) loss_zs_kd 0.1534 (0.2922) loss_oracle 0.3571 (0.3848) acc 84.3750 (80.2344) kd_loss 0.5530 (0.5882) lr 1.9298e-03 eta 0:18:02
epoch [8/50] batch [60/245] time 0.095 (0.101) data 0.000 (0.005) loss 1.5410 (1.4493) teacher_loss 0.8584 (0.6975) loss_zs_kd 0.2272 (0.2866) loss_oracle 0.2554 (0.3619) acc 78.1250 (80.8333) kd_loss 0.5549 (0.5708) lr 1.9298e-03 eta 0:17:37
epoch [8/50] batch [80/245] time 0.096 (0.100) data 0.000 (0.004) loss 0.9067 (1.4402) teacher_loss 0.3496 (0.7126) loss_zs_kd 0.2305 (0.2848) loss_oracle 0.2991 (0.3505) acc 93.7500 (80.6641) kd_loss 0.4076 (0.5524) lr 1.9298e-03 eta 0:17:23
epoch [8/50] batch [100/245] time 0.093 (0.100) data 0.000 (0.003) loss 1.4423 (1.4387) teacher_loss 0.7809 (0.7192) loss_zs_kd 0.4175 (0.2798) loss_oracle 0.3254 (0.3457) acc 75.0000 (80.4062) kd_loss 0.4987 (0.5467) lr 1.9298e-03 eta 0:17:19
epoch [8/50] batch [120/245] time 0.099 (0.099) data 0.000 (0.002) loss 1.2627 (1.4181) teacher_loss 0.5387 (0.7020) loss_zs_kd 0.3814 (0.2782) loss_oracle 0.3319 (0.3399) acc 81.2500 (80.7552) kd_loss 0.5580 (0.5461) lr 1.9298e-03 eta 0:17:15
epoch [8/50] batch [140/245] time 0.096 (0.099) data 0.000 (0.002) loss 1.2564 (1.4107) teacher_loss 0.4928 (0.6959) loss_zs_kd 0.2023 (0.2749) loss_oracle 0.3598 (0.3394) acc 87.5000 (81.0491) kd_loss 0.5837 (0.5452) lr 1.9298e-03 eta 0:17:09
epoch [8/50] batch [160/245] time 0.094 (0.099) data 0.000 (0.002) loss 1.6844 (1.4174) teacher_loss 1.0079 (0.7011) loss_zs_kd 0.1825 (0.2783) loss_oracle 0.3500 (0.3408) acc 81.2500 (80.9375) kd_loss 0.5015 (0.5459) lr 1.9298e-03 eta 0:17:08
epoch [8/50] batch [180/245] time 0.095 (0.099) data 0.000 (0.002) loss 1.1442 (1.4073) teacher_loss 0.4594 (0.6953) loss_zs_kd 0.2291 (0.2806) loss_oracle 0.3623 (0.3398) acc 87.5000 (81.0243) kd_loss 0.5036 (0.5421) lr 1.9298e-03 eta 0:17:03
epoch [8/50] batch [200/245] time 0.094 (0.100) data 0.000 (0.002) loss 1.5989 (1.4050) teacher_loss 0.9716 (0.6955) loss_zs_kd 0.2563 (0.2816) loss_oracle 0.2592 (0.3367) acc 68.7500 (81.1094) kd_loss 0.4977 (0.5412) lr 1.9298e-03 eta 0:17:14
epoch [8/50] batch [220/245] time 0.113 (0.100) data 0.000 (0.001) loss 1.2773 (1.3979) teacher_loss 0.6158 (0.6914) loss_zs_kd 0.4405 (0.2846) loss_oracle 0.3188 (0.3344) acc 84.3750 (81.1790) kd_loss 0.5021 (0.5394) lr 1.9298e-03 eta 0:17:12
epoch [8/50] batch [240/245] time 0.087 (0.100) data 0.000 (0.001) loss 1.2669 (1.4019) teacher_loss 0.5547 (0.6940) loss_zs_kd 0.2967 (0.2851) loss_oracle 0.3339 (0.3358) acc 84.3750 (81.0677) kd_loss 0.5452 (0.5399) lr 1.9298e-03 eta 0:17:04
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,045
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,228
* accuracy: 74.0%
* error: 26.0%
* macro_f1: 72.7%
******* Domain c best val acc:      90.9%, epoch: 7 *******
******* Domain c best val test acc: 74.2%, epoch: 7 *******
******* Domain c best test acc:     74.3%, epoch: 5 *******
epoch [9/50] batch [20/245] time 0.097 (0.123) data 0.000 (0.016) loss 1.6409 (1.3527) teacher_loss 0.8724 (0.6431) loss_zs_kd 0.3149 (0.2968) loss_oracle 0.3452 (0.3568) acc 78.1250 (83.1250) kd_loss 0.5959 (0.5312) lr 1.9048e-03 eta 0:20:59
epoch [9/50] batch [40/245] time 0.093 (0.108) data 0.000 (0.008) loss 1.2081 (1.3563) teacher_loss 0.4181 (0.6289) loss_zs_kd 0.3276 (0.3038) loss_oracle 0.3433 (0.3614) acc 84.3750 (82.5000) kd_loss 0.6184 (0.5467) lr 1.9048e-03 eta 0:18:22
epoch [9/50] batch [60/245] time 0.086 (0.104) data 0.000 (0.006) loss 2.1547 (1.4080) teacher_loss 1.3561 (0.6810) loss_zs_kd 0.2948 (0.3089) loss_oracle 0.3079 (0.3551) acc 68.7500 (81.3542) kd_loss 0.6446 (0.5495) lr 1.9048e-03 eta 0:17:41
epoch [9/50] batch [80/245] time 0.096 (0.102) data 0.000 (0.004) loss 1.4842 (1.4217) teacher_loss 0.6865 (0.6998) loss_zs_kd 0.2672 (0.3080) loss_oracle 0.3381 (0.3480) acc 81.2500 (81.4062) kd_loss 0.6286 (0.5479) lr 1.9048e-03 eta 0:17:22
epoch [9/50] batch [100/245] time 0.097 (0.101) data 0.000 (0.003) loss 0.6978 (1.4213) teacher_loss 0.1022 (0.7027) loss_zs_kd 0.2063 (0.3084) loss_oracle 0.3359 (0.3465) acc 100.0000 (81.1562) kd_loss 0.4277 (0.5453) lr 1.9048e-03 eta 0:17:12
epoch [9/50] batch [120/245] time 0.094 (0.100) data 0.000 (0.003) loss 1.1773 (1.4231) teacher_loss 0.4624 (0.7024) loss_zs_kd 0.3136 (0.3016) loss_oracle 0.2624 (0.3452) acc 87.5000 (81.0417) kd_loss 0.5837 (0.5481) lr 1.9048e-03 eta 0:17:00
epoch [9/50] batch [140/245] time 0.102 (0.100) data 0.001 (0.003) loss 0.9671 (1.4248) teacher_loss 0.2920 (0.7093) loss_zs_kd 0.1484 (0.2986) loss_oracle 0.2952 (0.3407) acc 87.5000 (80.8036) kd_loss 0.5275 (0.5452) lr 1.9048e-03 eta 0:16:57
epoch [9/50] batch [160/245] time 0.096 (0.100) data 0.000 (0.002) loss 1.1970 (1.4283) teacher_loss 0.4998 (0.7083) loss_zs_kd 0.3885 (0.2997) loss_oracle 0.3940 (0.3461) acc 81.2500 (80.7422) kd_loss 0.5001 (0.5470) lr 1.9048e-03 eta 0:16:53
epoch [9/50] batch [180/245] time 0.109 (0.100) data 0.000 (0.002) loss 1.9647 (1.4281) teacher_loss 1.1497 (0.7032) loss_zs_kd 0.4340 (0.3015) loss_oracle 0.4179 (0.3511) acc 59.3750 (80.6771) kd_loss 0.6061 (0.5493) lr 1.9048e-03 eta 0:16:52
epoch [9/50] batch [200/245] time 0.099 (0.100) data 0.000 (0.002) loss 1.3602 (1.4223) teacher_loss 0.7225 (0.7009) loss_zs_kd 0.1743 (0.3010) loss_oracle 0.3295 (0.3518) acc 81.2500 (80.8594) kd_loss 0.4730 (0.5455) lr 1.9048e-03 eta 0:16:53
epoch [9/50] batch [220/245] time 0.102 (0.102) data 0.000 (0.002) loss 1.7363 (1.4235) teacher_loss 0.9211 (0.7014) loss_zs_kd 0.3113 (0.2999) loss_oracle 0.4368 (0.3547) acc 78.1250 (80.8097) kd_loss 0.5969 (0.5448) lr 1.9048e-03 eta 0:17:07
epoch [9/50] batch [240/245] time 0.109 (0.102) data 0.001 (0.002) loss 1.5963 (1.4233) teacher_loss 0.8448 (0.6988) loss_zs_kd 0.3261 (0.3034) loss_oracle 0.3562 (0.3577) acc 75.0000 (80.8854) kd_loss 0.5734 (0.5457) lr 1.9048e-03 eta 0:17:09
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,058
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.4%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,219
* accuracy: 73.7%
* error: 26.3%
* macro_f1: 72.5%
******* Domain c best val acc:      91.2%, epoch: 9 *******
******* Domain c best val test acc: 73.7%, epoch: 9 *******
******* Domain c best test acc:     74.3%, epoch: 5 *******
epoch [10/50] batch [20/245] time 0.096 (0.128) data 0.000 (0.017) loss 1.5787 (1.4364) teacher_loss 0.7538 (0.6949) loss_zs_kd 0.3287 (0.3187) loss_oracle 0.4007 (0.3588) acc 78.1250 (80.7812) kd_loss 0.6246 (0.5621) lr 1.8763e-03 eta 0:21:24
epoch [10/50] batch [40/245] time 0.114 (0.117) data 0.000 (0.009) loss 0.8936 (1.3973) teacher_loss 0.2273 (0.6801) loss_zs_kd 0.2357 (0.3047) loss_oracle 0.3335 (0.3505) acc 93.7500 (81.5625) kd_loss 0.4996 (0.5421) lr 1.8763e-03 eta 0:19:35
epoch [10/50] batch [60/245] time 0.101 (0.113) data 0.000 (0.006) loss 1.5441 (1.3708) teacher_loss 0.8098 (0.6623) loss_zs_kd 0.2515 (0.3094) loss_oracle 0.3897 (0.3496) acc 87.5000 (82.1354) kd_loss 0.5395 (0.5336) lr 1.8763e-03 eta 0:18:52
epoch [10/50] batch [80/245] time 0.113 (0.112) data 0.000 (0.004) loss 1.1357 (1.3665) teacher_loss 0.5927 (0.6650) loss_zs_kd 0.3998 (0.3115) loss_oracle 0.3157 (0.3480) acc 81.2500 (82.1094) kd_loss 0.3852 (0.5275) lr 1.8763e-03 eta 0:18:31
epoch [10/50] batch [100/245] time 0.104 (0.110) data 0.001 (0.004) loss 1.5824 (1.3963) teacher_loss 0.8894 (0.6942) loss_zs_kd 0.4359 (0.3138) loss_oracle 0.3601 (0.3485) acc 75.0000 (81.1875) kd_loss 0.5129 (0.5278) lr 1.8763e-03 eta 0:18:11
epoch [10/50] batch [120/245] time 0.109 (0.109) data 0.000 (0.003) loss 1.4969 (1.3955) teacher_loss 0.6451 (0.6891) loss_zs_kd 0.2788 (0.3104) loss_oracle 0.4199 (0.3515) acc 81.2500 (81.2500) kd_loss 0.6418 (0.5307) lr 1.8763e-03 eta 0:18:01
epoch [10/50] batch [140/245] time 0.099 (0.108) data 0.000 (0.003) loss 1.4733 (1.3974) teacher_loss 0.7275 (0.6899) loss_zs_kd 0.4157 (0.3124) loss_oracle 0.3264 (0.3530) acc 75.0000 (81.3393) kd_loss 0.5826 (0.5310) lr 1.8763e-03 eta 0:17:48
epoch [10/50] batch [160/245] time 0.108 (0.107) data 0.000 (0.002) loss 1.4992 (1.3981) teacher_loss 0.8675 (0.6928) loss_zs_kd 0.3481 (0.3114) loss_oracle 0.3078 (0.3511) acc 71.8750 (81.1523) kd_loss 0.4777 (0.5298) lr 1.8763e-03 eta 0:17:40
epoch [10/50] batch [180/245] time 0.108 (0.107) data 0.000 (0.002) loss 1.5751 (1.3967) teacher_loss 0.7773 (0.6911) loss_zs_kd 0.3838 (0.3159) loss_oracle 0.3638 (0.3505) acc 81.2500 (81.2326) kd_loss 0.6159 (0.5303) lr 1.8763e-03 eta 0:17:39
epoch [10/50] batch [200/245] time 0.174 (0.110) data 0.001 (0.002) loss 1.3490 (1.3969) teacher_loss 0.5125 (0.6900) loss_zs_kd 0.2883 (0.3171) loss_oracle 0.3362 (0.3491) acc 84.3750 (81.2969) kd_loss 0.6685 (0.5323) lr 1.8763e-03 eta 0:17:59
epoch [10/50] batch [220/245] time 0.110 (0.110) data 0.000 (0.002) loss 1.0964 (1.3897) teacher_loss 0.3838 (0.6818) loss_zs_kd 0.3167 (0.3179) loss_oracle 0.3718 (0.3484) acc 90.6250 (81.5767) kd_loss 0.5266 (0.5337) lr 1.8763e-03 eta 0:18:01
epoch [10/50] batch [240/245] time 0.110 (0.110) data 0.001 (0.002) loss 1.4138 (1.3963) teacher_loss 0.6700 (0.6812) loss_zs_kd 0.3413 (0.3209) loss_oracle 0.3938 (0.3532) acc 87.5000 (81.6016) kd_loss 0.5469 (0.5385) lr 1.8763e-03 eta 0:17:55
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,053
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.2%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,223
* accuracy: 73.8%
* error: 26.2%
* macro_f1: 72.6%
******* Domain c best val acc:      91.2%, epoch: 9 *******
******* Domain c best val test acc: 73.7%, epoch: 9 *******
******* Domain c best test acc:     74.3%, epoch: 5 *******
epoch [11/50] batch [20/245] time 0.097 (0.119) data 0.000 (0.016) loss 1.7028 (1.4211) teacher_loss 0.9103 (0.6378) loss_zs_kd 0.4317 (0.3254) loss_oracle 0.4114 (0.4047) acc 78.1250 (82.5000) kd_loss 0.5868 (0.5810) lr 1.8443e-03 eta 0:19:24
epoch [11/50] batch [40/245] time 0.103 (0.108) data 0.000 (0.008) loss 1.5568 (1.4542) teacher_loss 0.8680 (0.6728) loss_zs_kd 0.3115 (0.3168) loss_oracle 0.3831 (0.4080) acc 75.0000 (80.7812) kd_loss 0.4972 (0.5775) lr 1.8443e-03 eta 0:17:35
epoch [11/50] batch [60/245] time 0.094 (0.105) data 0.001 (0.005) loss 1.4483 (1.4012) teacher_loss 0.7067 (0.6389) loss_zs_kd 0.2190 (0.3092) loss_oracle 0.3700 (0.3928) acc 75.0000 (81.7708) kd_loss 0.5566 (0.5659) lr 1.8443e-03 eta 0:17:01
epoch [11/50] batch [80/245] time 0.086 (0.102) data 0.000 (0.004) loss 1.6489 (1.4093) teacher_loss 0.9093 (0.6557) loss_zs_kd 0.3620 (0.3155) loss_oracle 0.3625 (0.3843) acc 78.1250 (81.0547) kd_loss 0.5583 (0.5614) lr 1.8443e-03 eta 0:16:32
epoch [11/50] batch [100/245] time 0.094 (0.101) data 0.000 (0.003) loss 1.5772 (1.3934) teacher_loss 0.9437 (0.6606) loss_zs_kd 0.2915 (0.3176) loss_oracle 0.2578 (0.3692) acc 71.8750 (81.1875) kd_loss 0.5046 (0.5482) lr 1.8443e-03 eta 0:16:15
epoch [11/50] batch [120/245] time 0.104 (0.100) data 0.000 (0.003) loss 1.4394 (1.3654) teacher_loss 0.7249 (0.6489) loss_zs_kd 0.3246 (0.3159) loss_oracle 0.3122 (0.3514) acc 78.1250 (81.5885) kd_loss 0.5584 (0.5408) lr 1.8443e-03 eta 0:16:08
epoch [11/50] batch [140/245] time 0.098 (0.099) data 0.000 (0.002) loss 1.2053 (1.3703) teacher_loss 0.5398 (0.6609) loss_zs_kd 0.2059 (0.3123) loss_oracle 0.3178 (0.3398) acc 81.2500 (81.1607) kd_loss 0.5066 (0.5396) lr 1.8443e-03 eta 0:15:59
epoch [11/50] batch [160/245] time 0.099 (0.099) data 0.000 (0.002) loss 1.4755 (1.3773) teacher_loss 0.7463 (0.6714) loss_zs_kd 0.2872 (0.3148) loss_oracle 0.3541 (0.3390) acc 75.0000 (81.0156) kd_loss 0.5522 (0.5364) lr 1.8443e-03 eta 0:15:53
epoch [11/50] batch [180/245] time 0.089 (0.098) data 0.000 (0.002) loss 1.7264 (1.3837) teacher_loss 0.8491 (0.6718) loss_zs_kd 0.2307 (0.3100) loss_oracle 0.4159 (0.3443) acc 71.8750 (81.1979) kd_loss 0.6693 (0.5397) lr 1.8443e-03 eta 0:15:45
epoch [11/50] batch [200/245] time 0.099 (0.098) data 0.000 (0.002) loss 1.2160 (1.3856) teacher_loss 0.4760 (0.6689) loss_zs_kd 0.2382 (0.3066) loss_oracle 0.3929 (0.3495) acc 81.2500 (81.2188) kd_loss 0.5435 (0.5419) lr 1.8443e-03 eta 0:15:39
epoch [11/50] batch [220/245] time 0.101 (0.099) data 0.000 (0.002) loss 1.2614 (1.3920) teacher_loss 0.4242 (0.6687) loss_zs_kd 0.3417 (0.3046) loss_oracle 0.3829 (0.3551) acc 81.2500 (81.1790) kd_loss 0.6458 (0.5457) lr 1.8443e-03 eta 0:15:48
epoch [11/50] batch [240/245] time 0.085 (0.098) data 0.000 (0.002) loss 1.1513 (1.3957) teacher_loss 0.4502 (0.6737) loss_zs_kd 0.1455 (0.3033) loss_oracle 0.3481 (0.3560) acc 90.6250 (81.1068) kd_loss 0.5271 (0.5440) lr 1.8443e-03 eta 0:15:40
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,048
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.1%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,246
* accuracy: 74.4%
* error: 25.6%
* macro_f1: 73.0%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      91.2%, epoch: 9 *******
******* Domain c best val test acc: 73.7%, epoch: 9 *******
******* Domain c best test acc:     74.4%, epoch: 11 *******
epoch [12/50] batch [20/245] time 0.097 (0.117) data 0.000 (0.014) loss 1.6992 (1.4476) teacher_loss 0.9787 (0.7194) loss_zs_kd 0.2170 (0.2577) loss_oracle 0.3764 (0.3704) acc 75.0000 (80.3125) kd_loss 0.5323 (0.5431) lr 1.8090e-03 eta 0:18:34
epoch [12/50] batch [40/245] time 0.098 (0.110) data 0.000 (0.007) loss 1.4640 (1.4194) teacher_loss 0.6805 (0.7000) loss_zs_kd 0.3328 (0.2737) loss_oracle 0.3431 (0.3618) acc 81.2500 (80.9375) kd_loss 0.6119 (0.5386) lr 1.8090e-03 eta 0:17:23
epoch [12/50] batch [60/245] time 0.094 (0.107) data 0.000 (0.005) loss 1.3542 (1.4184) teacher_loss 0.6315 (0.6912) loss_zs_kd 0.2505 (0.2724) loss_oracle 0.4105 (0.3611) acc 78.1250 (80.9896) kd_loss 0.5175 (0.5466) lr 1.8090e-03 eta 0:16:53
epoch [12/50] batch [80/245] time 0.098 (0.105) data 0.000 (0.004) loss 1.7974 (1.4367) teacher_loss 0.9244 (0.7001) loss_zs_kd 0.3618 (0.2872) loss_oracle 0.3472 (0.3676) acc 68.7500 (80.6641) kd_loss 0.6993 (0.5527) lr 1.8090e-03 eta 0:16:31
epoch [12/50] batch [100/245] time 0.096 (0.104) data 0.000 (0.003) loss 1.8261 (1.4402) teacher_loss 0.9478 (0.6955) loss_zs_kd 0.3212 (0.2915) loss_oracle 0.4086 (0.3684) acc 75.0000 (80.6875) kd_loss 0.6740 (0.5605) lr 1.8090e-03 eta 0:16:23
epoch [12/50] batch [120/245] time 0.094 (0.104) data 0.000 (0.003) loss 1.2157 (1.4519) teacher_loss 0.4661 (0.6972) loss_zs_kd 0.3053 (0.2965) loss_oracle 0.3326 (0.3708) acc 87.5000 (80.6771) kd_loss 0.5832 (0.5693) lr 1.8090e-03 eta 0:16:16
epoch [12/50] batch [140/245] time 0.096 (0.103) data 0.000 (0.002) loss 1.7918 (1.4410) teacher_loss 1.1802 (0.6939) loss_zs_kd 0.2201 (0.3003) loss_oracle 0.3381 (0.3698) acc 75.0000 (80.7143) kd_loss 0.4425 (0.5622) lr 1.8090e-03 eta 0:16:08
epoch [12/50] batch [160/245] time 0.098 (0.103) data 0.000 (0.002) loss 1.1463 (1.4316) teacher_loss 0.4575 (0.6869) loss_zs_kd 0.2778 (0.3026) loss_oracle 0.3839 (0.3693) acc 90.6250 (81.0938) kd_loss 0.4968 (0.5600) lr 1.8090e-03 eta 0:16:03
epoch [12/50] batch [180/245] time 0.092 (0.102) data 0.000 (0.002) loss 1.2110 (1.4271) teacher_loss 0.4081 (0.6889) loss_zs_kd 0.2681 (0.3076) loss_oracle 0.3435 (0.3680) acc 90.6250 (80.9896) kd_loss 0.6312 (0.5542) lr 1.8090e-03 eta 0:15:56
epoch [12/50] batch [200/245] time 0.100 (0.102) data 0.000 (0.002) loss 1.6006 (1.4250) teacher_loss 0.8231 (0.6916) loss_zs_kd 0.3319 (0.3103) loss_oracle 0.3311 (0.3657) acc 78.1250 (80.8125) kd_loss 0.6119 (0.5506) lr 1.8090e-03 eta 0:15:49
epoch [12/50] batch [220/245] time 0.100 (0.102) data 0.000 (0.002) loss 1.1092 (1.4211) teacher_loss 0.5149 (0.6911) loss_zs_kd 0.3799 (0.3157) loss_oracle 0.3301 (0.3638) acc 84.3750 (80.8665) kd_loss 0.4292 (0.5481) lr 1.8090e-03 eta 0:15:54
epoch [12/50] batch [240/245] time 0.106 (0.102) data 0.000 (0.001) loss 1.5194 (1.4205) teacher_loss 0.7134 (0.6898) loss_zs_kd 0.3234 (0.3180) loss_oracle 0.3529 (0.3636) acc 81.2500 (80.9115) kd_loss 0.6296 (0.5489) lr 1.8090e-03 eta 0:15:52
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,051
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.2%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,226
* accuracy: 73.9%
* error: 26.1%
* macro_f1: 72.5%
******* Domain c best val acc:      91.2%, epoch: 9 *******
******* Domain c best val test acc: 73.7%, epoch: 9 *******
******* Domain c best test acc:     74.4%, epoch: 11 *******
epoch [13/50] batch [20/245] time 0.099 (0.127) data 0.000 (0.019) loss 1.5487 (1.5085) teacher_loss 0.7640 (0.7616) loss_zs_kd 0.4726 (0.3536) loss_oracle 0.4041 (0.3778) acc 81.2500 (78.1250) kd_loss 0.5827 (0.5580) lr 1.7705e-03 eta 0:19:39
epoch [13/50] batch [40/245] time 0.096 (0.115) data 0.000 (0.010) loss 1.3020 (1.4626) teacher_loss 0.5753 (0.7392) loss_zs_kd 0.3026 (0.3389) loss_oracle 0.3708 (0.3676) acc 90.6250 (79.4531) kd_loss 0.5413 (0.5396) lr 1.7705e-03 eta 0:17:47
epoch [13/50] batch [60/245] time 0.099 (0.111) data 0.001 (0.006) loss 1.7102 (1.4557) teacher_loss 0.9440 (0.7230) loss_zs_kd 0.3230 (0.3393) loss_oracle 0.3544 (0.3702) acc 78.1250 (80.3646) kd_loss 0.5890 (0.5475) lr 1.7705e-03 eta 0:17:03
epoch [13/50] batch [80/245] time 0.096 (0.109) data 0.000 (0.005) loss 1.7498 (1.4627) teacher_loss 0.7993 (0.7149) loss_zs_kd 0.3103 (0.3323) loss_oracle 0.4534 (0.3763) acc 81.2500 (80.4688) kd_loss 0.7238 (0.5596) lr 1.7705e-03 eta 0:16:41
epoch [13/50] batch [100/245] time 0.101 (0.107) data 0.000 (0.004) loss 1.2504 (1.4642) teacher_loss 0.5387 (0.7087) loss_zs_kd 0.2521 (0.3302) loss_oracle 0.3376 (0.3803) acc 81.2500 (80.5312) kd_loss 0.5429 (0.5654) lr 1.7705e-03 eta 0:16:25
epoch [13/50] batch [120/245] time 0.101 (0.106) data 0.000 (0.003) loss 1.2053 (1.4469) teacher_loss 0.4832 (0.6947) loss_zs_kd 0.4030 (0.3286) loss_oracle 0.3597 (0.3771) acc 84.3750 (81.0417) kd_loss 0.5422 (0.5636) lr 1.7705e-03 eta 0:16:16
epoch [13/50] batch [140/245] time 0.108 (0.106) data 0.000 (0.003) loss 1.6375 (1.4425) teacher_loss 0.8632 (0.6889) loss_zs_kd 0.4054 (0.3322) loss_oracle 0.3718 (0.3762) acc 68.7500 (80.9821) kd_loss 0.5883 (0.5656) lr 1.7705e-03 eta 0:16:07
epoch [13/50] batch [160/245] time 0.101 (0.105) data 0.000 (0.003) loss 1.2610 (1.4471) teacher_loss 0.6141 (0.6924) loss_zs_kd 0.3635 (0.3346) loss_oracle 0.3963 (0.3755) acc 84.3750 (80.8398) kd_loss 0.4487 (0.5669) lr 1.7705e-03 eta 0:16:03
epoch [13/50] batch [180/245] time 0.095 (0.105) data 0.000 (0.002) loss 1.7206 (1.4494) teacher_loss 1.0033 (0.6967) loss_zs_kd 0.3615 (0.3338) loss_oracle 0.3492 (0.3748) acc 65.6250 (80.6771) kd_loss 0.5427 (0.5653) lr 1.7705e-03 eta 0:15:54
epoch [13/50] batch [200/245] time 0.099 (0.104) data 0.000 (0.002) loss 1.3364 (1.4373) teacher_loss 0.7136 (0.6930) loss_zs_kd 0.3722 (0.3305) loss_oracle 0.2947 (0.3718) acc 84.3750 (80.8594) kd_loss 0.4755 (0.5584) lr 1.7705e-03 eta 0:15:48
epoch [13/50] batch [220/245] time 0.101 (0.105) data 0.000 (0.002) loss 1.2714 (1.4260) teacher_loss 0.6879 (0.6922) loss_zs_kd 0.3406 (0.3295) loss_oracle 0.3491 (0.3672) acc 81.2500 (80.8097) kd_loss 0.4089 (0.5502) lr 1.7705e-03 eta 0:15:54
epoch [13/50] batch [240/245] time 0.106 (0.105) data 0.000 (0.002) loss 1.7763 (1.4198) teacher_loss 1.0084 (0.6905) loss_zs_kd 0.4158 (0.3269) loss_oracle 0.3978 (0.3660) acc 71.8750 (80.8203) kd_loss 0.5690 (0.5463) lr 1.7705e-03 eta 0:15:51
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,053
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.2%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,227
* accuracy: 73.9%
* error: 26.1%
* macro_f1: 72.7%
******* Domain c best val acc:      91.2%, epoch: 9 *******
******* Domain c best val test acc: 73.7%, epoch: 9 *******
******* Domain c best test acc:     74.4%, epoch: 11 *******
epoch [14/50] batch [20/245] time 0.096 (0.128) data 0.000 (0.016) loss 1.2968 (1.3217) teacher_loss 0.7147 (0.6763) loss_zs_kd 0.3361 (0.3420) loss_oracle 0.3494 (0.3434) acc 78.1250 (80.7812) kd_loss 0.4075 (0.4737) lr 1.7290e-03 eta 0:19:17
epoch [14/50] batch [40/245] time 0.098 (0.114) data 0.000 (0.008) loss 1.0897 (1.3002) teacher_loss 0.3464 (0.6276) loss_zs_kd 0.1724 (0.3354) loss_oracle 0.3937 (0.3571) acc 90.6250 (81.7969) kd_loss 0.5464 (0.4941) lr 1.7290e-03 eta 0:17:12
epoch [14/50] batch [60/245] time 0.109 (0.109) data 0.001 (0.006) loss 1.7048 (1.3179) teacher_loss 1.0080 (0.6318) loss_zs_kd 0.2227 (0.3448) loss_oracle 0.3768 (0.3628) acc 71.8750 (82.2396) kd_loss 0.5084 (0.5046) lr 1.7290e-03 eta 0:16:22
epoch [14/50] batch [80/245] time 0.096 (0.106) data 0.000 (0.004) loss 1.6854 (1.3527) teacher_loss 0.9581 (0.6612) loss_zs_kd 0.4030 (0.3528) loss_oracle 0.3735 (0.3622) acc 68.7500 (82.0312) kd_loss 0.5406 (0.5104) lr 1.7290e-03 eta 0:15:56
epoch [14/50] batch [100/245] time 0.100 (0.105) data 0.000 (0.003) loss 1.5082 (1.3482) teacher_loss 0.7609 (0.6523) loss_zs_kd 0.3519 (0.3574) loss_oracle 0.3573 (0.3617) acc 68.7500 (82.5938) kd_loss 0.5687 (0.5151) lr 1.7290e-03 eta 0:15:45
epoch [14/50] batch [120/245] time 0.092 (0.104) data 0.000 (0.003) loss 1.3709 (1.3452) teacher_loss 0.6740 (0.6462) loss_zs_kd 0.3037 (0.3517) loss_oracle 0.3512 (0.3593) acc 84.3750 (82.6302) kd_loss 0.5213 (0.5193) lr 1.7290e-03 eta 0:15:34
epoch [14/50] batch [140/245] time 0.099 (0.104) data 0.000 (0.003) loss 1.2287 (1.3503) teacher_loss 0.5786 (0.6506) loss_zs_kd 0.4041 (0.3503) loss_oracle 0.3335 (0.3574) acc 81.2500 (82.5446) kd_loss 0.4834 (0.5210) lr 1.7290e-03 eta 0:15:26
epoch [14/50] batch [160/245] time 0.098 (0.104) data 0.000 (0.002) loss 1.5119 (1.3542) teacher_loss 0.8376 (0.6589) loss_zs_kd 0.4547 (0.3497) loss_oracle 0.3295 (0.3552) acc 78.1250 (82.3633) kd_loss 0.5096 (0.5177) lr 1.7290e-03 eta 0:15:23
epoch [14/50] batch [180/245] time 0.108 (0.103) data 0.000 (0.002) loss 1.4464 (1.3591) teacher_loss 0.8108 (0.6636) loss_zs_kd 0.3283 (0.3530) loss_oracle 0.3182 (0.3554) acc 75.0000 (82.2049) kd_loss 0.4765 (0.5178) lr 1.7290e-03 eta 0:15:19
epoch [14/50] batch [200/245] time 0.104 (0.103) data 0.000 (0.002) loss 1.8569 (1.3675) teacher_loss 1.1778 (0.6694) loss_zs_kd 0.4005 (0.3534) loss_oracle 0.3997 (0.3559) acc 75.0000 (82.0312) kd_loss 0.4792 (0.5202) lr 1.7290e-03 eta 0:15:17
epoch [14/50] batch [220/245] time 0.106 (0.105) data 0.000 (0.002) loss 1.4273 (1.3689) teacher_loss 0.7650 (0.6702) loss_zs_kd 0.2592 (0.3526) loss_oracle 0.3178 (0.3556) acc 78.1250 (81.8608) kd_loss 0.5034 (0.5209) lr 1.7290e-03 eta 0:15:24
epoch [14/50] batch [240/245] time 0.110 (0.105) data 0.000 (0.002) loss 1.2067 (1.3664) teacher_loss 0.4822 (0.6691) loss_zs_kd 0.3108 (0.3525) loss_oracle 0.3737 (0.3549) acc 84.3750 (81.9010) kd_loss 0.5377 (0.5199) lr 1.7290e-03 eta 0:15:23
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,051
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.1%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,240
* accuracy: 74.2%
* error: 25.8%
* macro_f1: 72.9%
******* Domain c best val acc:      91.2%, epoch: 9 *******
******* Domain c best val test acc: 73.7%, epoch: 9 *******
******* Domain c best test acc:     74.4%, epoch: 11 *******
epoch [15/50] batch [20/245] time 0.127 (0.136) data 0.000 (0.018) loss 1.5274 (1.3679) teacher_loss 0.8948 (0.6860) loss_zs_kd 0.3265 (0.3507) loss_oracle 0.3442 (0.3626) acc 81.2500 (82.3438) kd_loss 0.4605 (0.5007) lr 1.6845e-03 eta 0:19:57
epoch [15/50] batch [40/245] time 0.106 (0.123) data 0.000 (0.009) loss 1.2109 (1.3596) teacher_loss 0.6237 (0.6684) loss_zs_kd 0.3106 (0.3685) loss_oracle 0.2981 (0.3535) acc 84.3750 (81.9531) kd_loss 0.4381 (0.5145) lr 1.6845e-03 eta 0:17:59
epoch [15/50] batch [60/245] time 0.116 (0.118) data 0.001 (0.006) loss 1.4879 (1.3478) teacher_loss 0.7370 (0.6623) loss_zs_kd 0.3777 (0.3717) loss_oracle 0.3030 (0.3468) acc 81.2500 (81.4583) kd_loss 0.5994 (0.5121) lr 1.6845e-03 eta 0:17:15
epoch [15/50] batch [80/245] time 0.097 (0.115) data 0.000 (0.005) loss 1.4523 (1.3407) teacher_loss 0.7279 (0.6545) loss_zs_kd 0.4019 (0.3737) loss_oracle 0.3441 (0.3425) acc 87.5000 (81.6406) kd_loss 0.5524 (0.5149) lr 1.6845e-03 eta 0:16:45
epoch [15/50] batch [100/245] time 0.100 (0.113) data 0.000 (0.004) loss 1.1310 (1.3186) teacher_loss 0.4391 (0.6363) loss_zs_kd 0.6318 (0.3678) loss_oracle 0.3166 (0.3378) acc 90.6250 (81.9688) kd_loss 0.5336 (0.5134) lr 1.6845e-03 eta 0:16:22
epoch [15/50] batch [120/245] time 0.100 (0.111) data 0.000 (0.003) loss 1.7350 (1.3252) teacher_loss 1.0178 (0.6417) loss_zs_kd 0.3136 (0.3672) loss_oracle 0.3461 (0.3353) acc 71.8750 (81.8490) kd_loss 0.5442 (0.5159) lr 1.6845e-03 eta 0:16:04
epoch [15/50] batch [140/245] time 0.113 (0.110) data 0.000 (0.003) loss 1.6510 (1.3163) teacher_loss 0.9419 (0.6344) loss_zs_kd 0.3749 (0.3604) loss_oracle 0.3335 (0.3320) acc 75.0000 (82.2768) kd_loss 0.5423 (0.5159) lr 1.6845e-03 eta 0:15:55
epoch [15/50] batch [160/245] time 0.113 (0.110) data 0.000 (0.002) loss 1.9043 (1.3290) teacher_loss 1.1025 (0.6394) loss_zs_kd 0.3133 (0.3569) loss_oracle 0.3517 (0.3347) acc 65.6250 (81.9531) kd_loss 0.6260 (0.5223) lr 1.6845e-03 eta 0:15:52
epoch [15/50] batch [180/245] time 0.103 (0.110) data 0.000 (0.002) loss 1.5255 (1.3220) teacher_loss 0.8673 (0.6338) loss_zs_kd 0.3573 (0.3508) loss_oracle 0.2955 (0.3322) acc 75.0000 (82.2049) kd_loss 0.5105 (0.5220) lr 1.6845e-03 eta 0:15:49
epoch [15/50] batch [200/245] time 0.097 (0.109) data 0.000 (0.002) loss 1.0775 (1.3275) teacher_loss 0.3513 (0.6392) loss_zs_kd 0.4425 (0.3509) loss_oracle 0.2821 (0.3282) acc 84.3750 (82.0625) kd_loss 0.5851 (0.5242) lr 1.6845e-03 eta 0:15:43
epoch [15/50] batch [220/245] time 0.110 (0.111) data 0.000 (0.002) loss 1.2676 (1.3262) teacher_loss 0.5224 (0.6367) loss_zs_kd 0.3163 (0.3486) loss_oracle 0.4018 (0.3290) acc 84.3750 (82.2159) kd_loss 0.5443 (0.5250) lr 1.6845e-03 eta 0:15:50
epoch [15/50] batch [240/245] time 0.109 (0.110) data 0.000 (0.002) loss 1.2477 (1.3269) teacher_loss 0.6199 (0.6325) loss_zs_kd 0.2541 (0.3489) loss_oracle 0.3580 (0.3316) acc 84.3750 (82.2656) kd_loss 0.4488 (0.5286) lr 1.6845e-03 eta 0:15:45
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,051
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.1%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,236
* accuracy: 74.1%
* error: 25.9%
* macro_f1: 73.0%
******* Domain c best val acc:      91.2%, epoch: 9 *******
******* Domain c best val test acc: 73.7%, epoch: 9 *******
******* Domain c best test acc:     74.4%, epoch: 11 *******
epoch [16/50] batch [20/245] time 0.099 (0.130) data 0.000 (0.020) loss 1.6113 (1.3760) teacher_loss 0.7792 (0.6378) loss_zs_kd 0.2809 (0.3582) loss_oracle 0.3375 (0.3607) acc 78.1250 (82.0312) kd_loss 0.6633 (0.5579) lr 1.6374e-03 eta 0:18:34
epoch [16/50] batch [40/245] time 0.094 (0.116) data 0.000 (0.010) loss 1.2718 (1.3803) teacher_loss 0.6761 (0.6553) loss_zs_kd 0.3120 (0.3485) loss_oracle 0.3979 (0.3484) acc 84.3750 (82.1094) kd_loss 0.3967 (0.5508) lr 1.6374e-03 eta 0:16:29
epoch [16/50] batch [60/245] time 0.098 (0.111) data 0.000 (0.007) loss 1.7456 (1.4054) teacher_loss 0.8514 (0.6627) loss_zs_kd 0.2975 (0.3485) loss_oracle 0.4639 (0.3544) acc 71.8750 (81.5625) kd_loss 0.6623 (0.5655) lr 1.6374e-03 eta 0:15:41
epoch [16/50] batch [80/245] time 0.092 (0.107) data 0.000 (0.005) loss 1.6697 (1.4279) teacher_loss 0.9099 (0.6640) loss_zs_kd 0.4563 (0.3582) loss_oracle 0.3682 (0.3598) acc 71.8750 (81.2500) kd_loss 0.5757 (0.5839) lr 1.6374e-03 eta 0:15:12
epoch [16/50] batch [100/245] time 0.105 (0.105) data 0.000 (0.004) loss 1.2076 (1.4297) teacher_loss 0.4336 (0.6745) loss_zs_kd 0.2048 (0.3524) loss_oracle 0.3234 (0.3529) acc 93.7500 (81.3750) kd_loss 0.6123 (0.5787) lr 1.6374e-03 eta 0:14:52
epoch [16/50] batch [120/245] time 0.095 (0.104) data 0.000 (0.003) loss 1.2659 (1.4276) teacher_loss 0.4504 (0.6848) loss_zs_kd 0.3719 (0.3506) loss_oracle 0.3534 (0.3438) acc 87.5000 (81.0677) kd_loss 0.6388 (0.5709) lr 1.6374e-03 eta 0:14:35
epoch [16/50] batch [140/245] time 0.100 (0.102) data 0.000 (0.003) loss 1.5701 (1.4259) teacher_loss 0.8185 (0.6898) loss_zs_kd 0.2848 (0.3465) loss_oracle 0.3466 (0.3372) acc 71.8750 (81.1830) kd_loss 0.5783 (0.5675) lr 1.6374e-03 eta 0:14:23
epoch [16/50] batch [160/245] time 0.093 (0.102) data 0.000 (0.003) loss 1.6208 (1.4133) teacher_loss 0.9800 (0.6784) loss_zs_kd 0.2901 (0.3395) loss_oracle 0.3120 (0.3352) acc 71.8750 (81.3672) kd_loss 0.4848 (0.5673) lr 1.6374e-03 eta 0:14:17
epoch [16/50] batch [180/245] time 0.096 (0.101) data 0.000 (0.002) loss 1.5142 (1.4104) teacher_loss 0.7907 (0.6791) loss_zs_kd 0.2502 (0.3406) loss_oracle 0.3100 (0.3338) acc 84.3750 (81.3715) kd_loss 0.5685 (0.5645) lr 1.6374e-03 eta 0:14:08
epoch [16/50] batch [200/245] time 0.095 (0.101) data 0.000 (0.002) loss 1.6078 (1.4069) teacher_loss 0.8723 (0.6743) loss_zs_kd 0.2788 (0.3382) loss_oracle 0.3341 (0.3327) acc 75.0000 (81.5469) kd_loss 0.5684 (0.5663) lr 1.6374e-03 eta 0:14:04
epoch [16/50] batch [220/245] time 0.095 (0.102) data 0.000 (0.002) loss 1.5345 (1.4074) teacher_loss 0.8489 (0.6746) loss_zs_kd 0.4069 (0.3363) loss_oracle 0.3119 (0.3322) acc 84.3750 (81.5625) kd_loss 0.5296 (0.5666) lr 1.6374e-03 eta 0:14:09
epoch [16/50] batch [240/245] time 0.087 (0.101) data 0.000 (0.002) loss 1.1818 (1.4034) teacher_loss 0.4040 (0.6660) loss_zs_kd 0.2768 (0.3359) loss_oracle 0.3972 (0.3348) acc 93.7500 (81.7839) kd_loss 0.5792 (0.5700) lr 1.6374e-03 eta 0:14:02
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,064
* accuracy: 91.4%
* error: 8.6%
* macro_f1: 90.6%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,251
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.3%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      91.4%, epoch: 16 *******
******* Domain c best val test acc: 74.5%, epoch: 16 *******
******* Domain c best test acc:     74.5%, epoch: 16 *******
epoch [17/50] batch [20/245] time 0.103 (0.118) data 0.000 (0.016) loss 1.3170 (1.4092) teacher_loss 0.6071 (0.6625) loss_zs_kd 0.4187 (0.3480) loss_oracle 0.4007 (0.3558) acc 81.2500 (80.6250) kd_loss 0.5095 (0.5688) lr 1.5878e-03 eta 0:16:21
epoch [17/50] batch [40/245] time 0.094 (0.107) data 0.000 (0.008) loss 1.2388 (1.4028) teacher_loss 0.4471 (0.6519) loss_zs_kd 0.3686 (0.3668) loss_oracle 0.3404 (0.3628) acc 87.5000 (81.7188) kd_loss 0.6215 (0.5695) lr 1.5878e-03 eta 0:14:49
epoch [17/50] batch [60/245] time 0.094 (0.104) data 0.000 (0.005) loss 1.1923 (1.3956) teacher_loss 0.4584 (0.6446) loss_zs_kd 0.3262 (0.3576) loss_oracle 0.3029 (0.3557) acc 87.5000 (82.1875) kd_loss 0.5825 (0.5731) lr 1.5878e-03 eta 0:14:20
epoch [17/50] batch [80/245] time 0.099 (0.102) data 0.000 (0.004) loss 1.0748 (1.3864) teacher_loss 0.4146 (0.6474) loss_zs_kd 0.3600 (0.3570) loss_oracle 0.2649 (0.3483) acc 87.5000 (82.1484) kd_loss 0.5278 (0.5649) lr 1.5878e-03 eta 0:14:03
epoch [17/50] batch [100/245] time 0.107 (0.101) data 0.000 (0.003) loss 1.1445 (1.3641) teacher_loss 0.4743 (0.6398) loss_zs_kd 0.3913 (0.3604) loss_oracle 0.2690 (0.3386) acc 87.5000 (82.2500) kd_loss 0.5357 (0.5550) lr 1.5878e-03 eta 0:13:52
epoch [17/50] batch [120/245] time 0.097 (0.101) data 0.000 (0.003) loss 1.2167 (1.3563) teacher_loss 0.4827 (0.6390) loss_zs_kd 0.4240 (0.3619) loss_oracle 0.3542 (0.3329) acc 84.3750 (82.2656) kd_loss 0.5570 (0.5508) lr 1.5878e-03 eta 0:13:45
epoch [17/50] batch [140/245] time 0.094 (0.100) data 0.000 (0.002) loss 1.2222 (1.3595) teacher_loss 0.5120 (0.6448) loss_zs_kd 0.2980 (0.3656) loss_oracle 0.3521 (0.3318) acc 84.3750 (81.9196) kd_loss 0.5342 (0.5488) lr 1.5878e-03 eta 0:13:37
epoch [17/50] batch [160/245] time 0.099 (0.100) data 0.000 (0.002) loss 1.5612 (1.3477) teacher_loss 0.8288 (0.6353) loss_zs_kd 0.2781 (0.3656) loss_oracle 0.3085 (0.3317) acc 78.1250 (82.1680) kd_loss 0.5781 (0.5466) lr 1.5878e-03 eta 0:13:33
epoch [17/50] batch [180/245] time 0.096 (0.099) data 0.000 (0.002) loss 1.7638 (1.3447) teacher_loss 0.9383 (0.6302) loss_zs_kd 0.3160 (0.3644) loss_oracle 0.3266 (0.3313) acc 78.1250 (82.3090) kd_loss 0.6622 (0.5488) lr 1.5878e-03 eta 0:13:29
epoch [17/50] batch [200/245] time 0.099 (0.099) data 0.000 (0.002) loss 1.4215 (1.3405) teacher_loss 0.7194 (0.6305) loss_zs_kd 0.2109 (0.3630) loss_oracle 0.3017 (0.3300) acc 87.5000 (82.2656) kd_loss 0.5513 (0.5450) lr 1.5878e-03 eta 0:13:26
epoch [17/50] batch [220/245] time 0.128 (0.100) data 0.000 (0.002) loss 0.9843 (1.3384) teacher_loss 0.4243 (0.6340) loss_zs_kd 0.3736 (0.3643) loss_oracle 0.3257 (0.3283) acc 84.3750 (82.2443) kd_loss 0.3971 (0.5403) lr 1.5878e-03 eta 0:13:27
epoch [17/50] batch [240/245] time 0.090 (0.099) data 0.000 (0.002) loss 1.0316 (1.3313) teacher_loss 0.4724 (0.6334) loss_zs_kd 0.3033 (0.3619) loss_oracle 0.2833 (0.3251) acc 84.3750 (82.2526) kd_loss 0.4175 (0.5354) lr 1.5878e-03 eta 0:13:23
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,055
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.3%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,235
* accuracy: 74.1%
* error: 25.9%
* macro_f1: 72.9%
******* Domain c best val acc:      91.4%, epoch: 16 *******
******* Domain c best val test acc: 74.5%, epoch: 16 *******
******* Domain c best test acc:     74.5%, epoch: 16 *******
epoch [18/50] batch [20/245] time 0.101 (0.119) data 0.000 (0.015) loss 1.0376 (1.3372) teacher_loss 0.3979 (0.6501) loss_zs_kd 0.4462 (0.3479) loss_oracle 0.3400 (0.3160) acc 87.5000 (82.0312) kd_loss 0.4697 (0.5291) lr 1.5358e-03 eta 0:15:57
epoch [18/50] batch [40/245] time 0.095 (0.108) data 0.000 (0.008) loss 1.4028 (1.3752) teacher_loss 0.7435 (0.6919) loss_zs_kd 0.3598 (0.3492) loss_oracle 0.3249 (0.3226) acc 84.3750 (81.1719) kd_loss 0.4969 (0.5220) lr 1.5358e-03 eta 0:14:28
epoch [18/50] batch [60/245] time 0.094 (0.104) data 0.001 (0.005) loss 1.2015 (1.3355) teacher_loss 0.4477 (0.6478) loss_zs_kd 0.3482 (0.3459) loss_oracle 0.3179 (0.3222) acc 84.3750 (82.4479) kd_loss 0.5949 (0.5266) lr 1.5358e-03 eta 0:13:55
epoch [18/50] batch [80/245] time 0.095 (0.102) data 0.000 (0.004) loss 1.2713 (1.3669) teacher_loss 0.5086 (0.6769) loss_zs_kd 0.3160 (0.3510) loss_oracle 0.4074 (0.3271) acc 84.3750 (81.7578) kd_loss 0.5590 (0.5264) lr 1.5358e-03 eta 0:13:35
epoch [18/50] batch [100/245] time 0.093 (0.101) data 0.000 (0.003) loss 1.3850 (1.3477) teacher_loss 0.7155 (0.6524) loss_zs_kd 0.2296 (0.3455) loss_oracle 0.3485 (0.3318) acc 81.2500 (82.3125) kd_loss 0.4953 (0.5293) lr 1.5358e-03 eta 0:13:22
epoch [18/50] batch [120/245] time 0.099 (0.100) data 0.000 (0.003) loss 1.2488 (1.3533) teacher_loss 0.6055 (0.6581) loss_zs_kd 0.3416 (0.3465) loss_oracle 0.3153 (0.3281) acc 78.1250 (82.1615) kd_loss 0.4856 (0.5312) lr 1.5358e-03 eta 0:13:14
epoch [18/50] batch [140/245] time 0.094 (0.099) data 0.000 (0.002) loss 1.4087 (1.3523) teacher_loss 0.7779 (0.6548) loss_zs_kd 0.3888 (0.3507) loss_oracle 0.3296 (0.3266) acc 78.1250 (82.2321) kd_loss 0.4660 (0.5341) lr 1.5358e-03 eta 0:13:08
epoch [18/50] batch [160/245] time 0.096 (0.099) data 0.000 (0.002) loss 1.6347 (1.3555) teacher_loss 0.8671 (0.6564) loss_zs_kd 0.2576 (0.3537) loss_oracle 0.3800 (0.3284) acc 75.0000 (82.0508) kd_loss 0.5776 (0.5349) lr 1.5358e-03 eta 0:13:04
epoch [18/50] batch [180/245] time 0.099 (0.099) data 0.000 (0.002) loss 1.6585 (1.3646) teacher_loss 0.8556 (0.6619) loss_zs_kd 0.3065 (0.3574) loss_oracle 0.3345 (0.3310) acc 78.1250 (81.7708) kd_loss 0.6357 (0.5373) lr 1.5358e-03 eta 0:13:01
epoch [18/50] batch [200/245] time 0.094 (0.099) data 0.000 (0.002) loss 1.9252 (1.3624) teacher_loss 1.1207 (0.6592) loss_zs_kd 0.4114 (0.3591) loss_oracle 0.3192 (0.3292) acc 68.7500 (81.6875) kd_loss 0.6449 (0.5386) lr 1.5358e-03 eta 0:12:58
epoch [18/50] batch [220/245] time 0.096 (0.098) data 0.000 (0.002) loss 1.4068 (1.3618) teacher_loss 0.6720 (0.6578) loss_zs_kd 0.4789 (0.3626) loss_oracle 0.3156 (0.3276) acc 87.5000 (81.8608) kd_loss 0.5770 (0.5402) lr 1.5358e-03 eta 0:12:53
epoch [18/50] batch [240/245] time 0.085 (0.099) data 0.000 (0.001) loss 1.1440 (1.3603) teacher_loss 0.4863 (0.6596) loss_zs_kd 0.3068 (0.3620) loss_oracle 0.3344 (0.3261) acc 90.6250 (81.7969) kd_loss 0.4905 (0.5377) lr 1.5358e-03 eta 0:12:54
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,064
* accuracy: 91.4%
* error: 8.6%
* macro_f1: 90.6%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,254
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.1%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      91.4%, epoch: 16 *******
******* Domain c best val test acc: 74.5%, epoch: 16 *******
******* Domain c best test acc:     74.5%, epoch: 18 *******
epoch [19/50] batch [20/245] time 0.099 (0.127) data 0.000 (0.018) loss 1.7173 (1.4311) teacher_loss 0.7758 (0.6694) loss_zs_kd 0.3597 (0.3386) loss_oracle 0.3425 (0.3311) acc 75.0000 (81.4062) kd_loss 0.7702 (0.5962) lr 1.4818e-03 eta 0:16:29
epoch [19/50] batch [40/245] time 0.103 (0.114) data 0.000 (0.009) loss 1.1273 (1.4016) teacher_loss 0.4196 (0.6396) loss_zs_kd 0.5203 (0.3379) loss_oracle 0.2979 (0.3344) acc 90.6250 (82.5000) kd_loss 0.5588 (0.5949) lr 1.4818e-03 eta 0:14:45
epoch [19/50] batch [60/245] time 0.100 (0.110) data 0.001 (0.006) loss 1.6875 (1.4019) teacher_loss 1.0039 (0.6611) loss_zs_kd 0.3652 (0.3461) loss_oracle 0.3044 (0.3228) acc 68.7500 (81.3021) kd_loss 0.5314 (0.5793) lr 1.4818e-03 eta 0:14:16
epoch [19/50] batch [80/245] time 0.101 (0.109) data 0.000 (0.005) loss 1.0068 (1.3588) teacher_loss 0.3852 (0.6371) loss_zs_kd 0.2525 (0.3418) loss_oracle 0.2696 (0.3195) acc 81.2500 (82.1484) kd_loss 0.4868 (0.5619) lr 1.4818e-03 eta 0:14:07
epoch [19/50] batch [100/245] time 0.101 (0.108) data 0.000 (0.004) loss 1.3946 (1.3520) teacher_loss 0.7327 (0.6381) loss_zs_kd 0.3772 (0.3426) loss_oracle 0.3007 (0.3173) acc 75.0000 (82.3438) kd_loss 0.5116 (0.5552) lr 1.4818e-03 eta 0:13:57
epoch [19/50] batch [120/245] time 0.112 (0.107) data 0.000 (0.003) loss 1.7517 (1.3479) teacher_loss 1.0015 (0.6340) loss_zs_kd 0.3713 (0.3456) loss_oracle 0.3191 (0.3153) acc 71.8750 (82.3958) kd_loss 0.5907 (0.5562) lr 1.4818e-03 eta 0:13:49
epoch [19/50] batch [140/245] time 0.110 (0.107) data 0.000 (0.003) loss 1.3333 (1.3364) teacher_loss 0.6484 (0.6214) loss_zs_kd 0.3258 (0.3473) loss_oracle 0.3046 (0.3170) acc 75.0000 (82.7679) kd_loss 0.5327 (0.5565) lr 1.4818e-03 eta 0:13:43
epoch [19/50] batch [160/245] time 0.100 (0.106) data 0.000 (0.003) loss 1.2785 (1.3413) teacher_loss 0.5755 (0.6271) loss_zs_kd 0.4093 (0.3521) loss_oracle 0.3174 (0.3192) acc 81.2500 (82.5586) kd_loss 0.5443 (0.5547) lr 1.4818e-03 eta 0:13:37
epoch [19/50] batch [180/245] time 0.093 (0.106) data 0.000 (0.002) loss 1.5301 (1.3576) teacher_loss 0.7379 (0.6386) loss_zs_kd 0.3835 (0.3531) loss_oracle 0.3074 (0.3214) acc 75.0000 (82.2743) kd_loss 0.6385 (0.5583) lr 1.4818e-03 eta 0:13:29
epoch [19/50] batch [200/245] time 0.100 (0.105) data 0.000 (0.002) loss 1.3666 (1.3706) teacher_loss 0.6011 (0.6511) loss_zs_kd 0.2412 (0.3563) loss_oracle 0.3911 (0.3236) acc 84.3750 (81.8594) kd_loss 0.5700 (0.5577) lr 1.4818e-03 eta 0:13:23
epoch [19/50] batch [220/245] time 0.098 (0.105) data 0.000 (0.002) loss 1.6219 (1.3785) teacher_loss 0.7202 (0.6590) loss_zs_kd 0.3009 (0.3612) loss_oracle 0.3095 (0.3250) acc 75.0000 (81.6051) kd_loss 0.7469 (0.5570) lr 1.4818e-03 eta 0:13:19
epoch [19/50] batch [240/245] time 0.084 (0.104) data 0.000 (0.002) loss 1.4721 (1.3720) teacher_loss 0.6777 (0.6549) loss_zs_kd 0.3266 (0.3579) loss_oracle 0.3656 (0.3254) acc 81.2500 (81.6667) kd_loss 0.6117 (0.5544) lr 1.4818e-03 eta 0:13:13
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,070
* accuracy: 91.6%
* error: 8.4%
* macro_f1: 90.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,252
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.2%
******* Domain c best val acc:      91.6%, epoch: 19 *******
******* Domain c best val test acc: 74.5%, epoch: 19 *******
******* Domain c best test acc:     74.5%, epoch: 18 *******
epoch [20/50] batch [20/245] time 0.094 (0.116) data 0.000 (0.015) loss 1.2524 (1.2644) teacher_loss 0.4985 (0.5745) loss_zs_kd 0.3321 (0.3273) loss_oracle 0.3150 (0.3096) acc 84.3750 (83.1250) kd_loss 0.5965 (0.5351) lr 1.4258e-03 eta 0:14:38
epoch [20/50] batch [40/245] time 0.095 (0.105) data 0.000 (0.008) loss 1.6237 (1.2801) teacher_loss 0.8482 (0.5882) loss_zs_kd 0.3507 (0.3510) loss_oracle 0.3794 (0.3164) acc 78.1250 (82.5000) kd_loss 0.5859 (0.5337) lr 1.4258e-03 eta 0:13:17
epoch [20/50] batch [60/245] time 0.095 (0.102) data 0.001 (0.005) loss 1.3100 (1.3122) teacher_loss 0.5044 (0.6087) loss_zs_kd 0.3259 (0.3635) loss_oracle 0.3285 (0.3214) acc 87.5000 (82.5000) kd_loss 0.6413 (0.5428) lr 1.4258e-03 eta 0:12:49
epoch [20/50] batch [80/245] time 0.093 (0.100) data 0.000 (0.004) loss 1.2769 (1.3082) teacher_loss 0.4740 (0.6026) loss_zs_kd 0.4142 (0.3674) loss_oracle 0.3765 (0.3243) acc 84.3750 (83.0469) kd_loss 0.6147 (0.5434) lr 1.4258e-03 eta 0:12:31
epoch [20/50] batch [100/245] time 0.091 (0.100) data 0.000 (0.003) loss 1.5544 (1.3060) teacher_loss 0.7832 (0.6024) loss_zs_kd 0.3030 (0.3702) loss_oracle 0.2620 (0.3240) acc 78.1250 (83.0625) kd_loss 0.6402 (0.5416) lr 1.4258e-03 eta 0:12:26
epoch [20/50] batch [120/245] time 0.101 (0.099) data 0.000 (0.003) loss 0.9491 (1.3118) teacher_loss 0.1856 (0.6039) loss_zs_kd 0.4550 (0.3692) loss_oracle 0.3688 (0.3237) acc 96.8750 (82.9427) kd_loss 0.5791 (0.5460) lr 1.4258e-03 eta 0:12:20
epoch [20/50] batch [140/245] time 0.093 (0.099) data 0.000 (0.002) loss 1.5917 (1.3128) teacher_loss 0.9107 (0.6072) loss_zs_kd 0.5063 (0.3718) loss_oracle 0.3490 (0.3243) acc 75.0000 (82.7455) kd_loss 0.5065 (0.5434) lr 1.4258e-03 eta 0:12:15
epoch [20/50] batch [160/245] time 0.093 (0.099) data 0.000 (0.002) loss 0.9635 (1.3162) teacher_loss 0.2614 (0.6136) loss_zs_kd 0.3894 (0.3722) loss_oracle 0.3146 (0.3264) acc 90.6250 (82.5977) kd_loss 0.5449 (0.5395) lr 1.4258e-03 eta 0:12:14
epoch [20/50] batch [180/245] time 0.100 (0.099) data 0.000 (0.002) loss 1.5114 (1.3110) teacher_loss 0.7650 (0.6101) loss_zs_kd 0.5806 (0.3713) loss_oracle 0.3362 (0.3272) acc 81.2500 (82.7604) kd_loss 0.5783 (0.5373) lr 1.4258e-03 eta 0:12:12
epoch [20/50] batch [200/245] time 0.105 (0.099) data 0.001 (0.002) loss 1.3990 (1.3142) teacher_loss 0.7101 (0.6145) loss_zs_kd 0.2742 (0.3712) loss_oracle 0.3306 (0.3270) acc 84.3750 (82.6719) kd_loss 0.5236 (0.5362) lr 1.4258e-03 eta 0:12:09
epoch [20/50] batch [220/245] time 0.106 (0.099) data 0.000 (0.002) loss 1.4386 (1.3227) teacher_loss 0.7258 (0.6225) loss_zs_kd 0.2863 (0.3686) loss_oracle 0.3464 (0.3262) acc 81.2500 (82.4290) kd_loss 0.5395 (0.5371) lr 1.4258e-03 eta 0:12:06
epoch [20/50] batch [240/245] time 0.088 (0.098) data 0.000 (0.001) loss 1.2528 (1.3319) teacher_loss 0.5334 (0.6305) loss_zs_kd 0.4825 (0.3673) loss_oracle 0.3599 (0.3254) acc 81.2500 (82.2786) kd_loss 0.5394 (0.5387) lr 1.4258e-03 eta 0:12:00
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,065
* accuracy: 91.4%
* error: 8.6%
* macro_f1: 90.7%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,250
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.2%
******* Domain c best val acc:      91.6%, epoch: 19 *******
******* Domain c best val test acc: 74.5%, epoch: 19 *******
******* Domain c best test acc:     74.5%, epoch: 18 *******
epoch [21/50] batch [20/245] time 0.107 (0.127) data 0.000 (0.019) loss 1.4813 (1.3065) teacher_loss 0.8287 (0.6251) loss_zs_kd 0.6680 (0.3726) loss_oracle 0.3264 (0.3068) acc 75.0000 (83.9062) kd_loss 0.4894 (0.5280) lr 1.3681e-03 eta 0:15:27
epoch [21/50] batch [40/245] time 0.099 (0.113) data 0.000 (0.010) loss 1.6203 (1.2910) teacher_loss 0.8469 (0.6170) loss_zs_kd 0.3911 (0.3761) loss_oracle 0.3507 (0.3094) acc 78.1250 (83.4375) kd_loss 0.5980 (0.5193) lr 1.3681e-03 eta 0:13:44
epoch [21/50] batch [60/245] time 0.102 (0.109) data 0.001 (0.007) loss 1.1495 (1.3196) teacher_loss 0.4644 (0.6414) loss_zs_kd 0.3031 (0.3756) loss_oracle 0.3126 (0.3151) acc 84.3750 (82.9688) kd_loss 0.5289 (0.5207) lr 1.3681e-03 eta 0:13:16
epoch [21/50] batch [80/245] time 0.098 (0.107) data 0.000 (0.005) loss 1.0959 (1.3227) teacher_loss 0.4196 (0.6435) loss_zs_kd 0.4762 (0.3739) loss_oracle 0.2881 (0.3169) acc 84.3750 (82.6953) kd_loss 0.5322 (0.5208) lr 1.3681e-03 eta 0:12:57
epoch [21/50] batch [100/245] time 0.100 (0.106) data 0.000 (0.004) loss 1.2091 (1.3172) teacher_loss 0.5675 (0.6401) loss_zs_kd 0.3746 (0.3751) loss_oracle 0.3002 (0.3163) acc 81.2500 (82.9062) kd_loss 0.4915 (0.5190) lr 1.3681e-03 eta 0:12:47
epoch [21/50] batch [120/245] time 0.102 (0.105) data 0.000 (0.003) loss 1.2884 (1.3292) teacher_loss 0.5636 (0.6479) loss_zs_kd 0.5946 (0.3785) loss_oracle 0.3866 (0.3168) acc 87.5000 (82.5000) kd_loss 0.5314 (0.5230) lr 1.3681e-03 eta 0:12:38
epoch [21/50] batch [140/245] time 0.101 (0.104) data 0.000 (0.003) loss 1.5735 (1.3276) teacher_loss 0.7311 (0.6427) loss_zs_kd 0.3125 (0.3749) loss_oracle 0.3089 (0.3140) acc 75.0000 (82.4777) kd_loss 0.6879 (0.5279) lr 1.3681e-03 eta 0:12:32
epoch [21/50] batch [160/245] time 0.103 (0.104) data 0.000 (0.003) loss 1.0022 (1.3258) teacher_loss 0.4161 (0.6391) loss_zs_kd 0.2840 (0.3741) loss_oracle 0.3049 (0.3126) acc 90.6250 (82.6562) kd_loss 0.4337 (0.5304) lr 1.3681e-03 eta 0:12:28
epoch [21/50] batch [180/245] time 0.107 (0.104) data 0.000 (0.002) loss 1.4359 (1.3395) teacher_loss 0.7955 (0.6471) loss_zs_kd 0.3719 (0.3749) loss_oracle 0.2991 (0.3150) acc 78.1250 (82.3438) kd_loss 0.4909 (0.5349) lr 1.3681e-03 eta 0:12:24
epoch [21/50] batch [200/245] time 0.103 (0.104) data 0.000 (0.002) loss 1.0793 (1.3392) teacher_loss 0.3366 (0.6432) loss_zs_kd 0.5263 (0.3781) loss_oracle 0.3775 (0.3168) acc 90.6250 (82.4062) kd_loss 0.5539 (0.5376) lr 1.3681e-03 eta 0:12:21
epoch [21/50] batch [220/245] time 0.108 (0.103) data 0.000 (0.002) loss 1.1788 (1.3493) teacher_loss 0.4711 (0.6474) loss_zs_kd 0.3675 (0.3770) loss_oracle 0.3400 (0.3206) acc 87.5000 (82.2727) kd_loss 0.5377 (0.5416) lr 1.3681e-03 eta 0:12:16
epoch [21/50] batch [240/245] time 0.105 (0.103) data 0.000 (0.002) loss 1.4897 (1.3558) teacher_loss 0.5423 (0.6501) loss_zs_kd 0.3382 (0.3773) loss_oracle 0.4055 (0.3225) acc 84.3750 (82.2526) kd_loss 0.7447 (0.5444) lr 1.3681e-03 eta 0:12:15
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,065
* accuracy: 91.4%
* error: 8.6%
* macro_f1: 90.6%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,260
* accuracy: 74.7%
* error: 25.3%
* macro_f1: 73.4%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      91.6%, epoch: 19 *******
******* Domain c best val test acc: 74.5%, epoch: 19 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [22/50] batch [20/245] time 0.090 (0.114) data 0.000 (0.015) loss 1.3045 (1.3039) teacher_loss 0.3587 (0.5648) loss_zs_kd 0.1945 (0.3768) loss_oracle 0.3354 (0.3319) acc 87.5000 (84.2188) kd_loss 0.7781 (0.5732) lr 1.3090e-03 eta 0:13:29
epoch [22/50] batch [40/245] time 0.103 (0.106) data 0.000 (0.007) loss 0.9023 (1.3124) teacher_loss 0.1447 (0.5778) loss_zs_kd 0.4059 (0.3742) loss_oracle 0.3810 (0.3255) acc 96.8750 (83.5156) kd_loss 0.5671 (0.5719) lr 1.3090e-03 eta 0:12:31
epoch [22/50] batch [60/245] time 0.095 (0.102) data 0.000 (0.005) loss 0.9958 (1.3114) teacher_loss 0.3188 (0.5897) loss_zs_kd 0.3414 (0.3711) loss_oracle 0.2576 (0.3245) acc 84.3750 (82.8646) kd_loss 0.5482 (0.5595) lr 1.3090e-03 eta 0:11:58
epoch [22/50] batch [80/245] time 0.104 (0.099) data 0.000 (0.004) loss 1.5660 (1.3363) teacher_loss 0.8707 (0.6097) loss_zs_kd 0.2726 (0.3758) loss_oracle 0.2659 (0.3240) acc 75.0000 (82.1484) kd_loss 0.5624 (0.5646) lr 1.3090e-03 eta 0:11:38
epoch [22/50] batch [100/245] time 0.093 (0.098) data 0.000 (0.003) loss 1.3325 (1.3401) teacher_loss 0.4934 (0.6102) loss_zs_kd 0.2756 (0.3679) loss_oracle 0.3577 (0.3219) acc 87.5000 (82.0312) kd_loss 0.6602 (0.5689) lr 1.3090e-03 eta 0:11:29
epoch [22/50] batch [120/245] time 0.099 (0.099) data 0.000 (0.003) loss 1.0519 (1.3584) teacher_loss 0.4865 (0.6313) loss_zs_kd 0.5228 (0.3713) loss_oracle 0.2745 (0.3247) acc 84.3750 (81.8229) kd_loss 0.4281 (0.5647) lr 1.3090e-03 eta 0:11:30
epoch [22/50] batch [140/245] time 0.098 (0.098) data 0.000 (0.002) loss 1.3188 (1.3492) teacher_loss 0.6498 (0.6240) loss_zs_kd 0.3847 (0.3711) loss_oracle 0.3347 (0.3234) acc 84.3750 (82.0759) kd_loss 0.5017 (0.5635) lr 1.3090e-03 eta 0:11:23
epoch [22/50] batch [160/245] time 0.097 (0.098) data 0.000 (0.002) loss 1.2975 (1.3523) teacher_loss 0.4622 (0.6267) loss_zs_kd 0.4216 (0.3749) loss_oracle 0.3676 (0.3244) acc 87.5000 (82.1289) kd_loss 0.6515 (0.5634) lr 1.3090e-03 eta 0:11:21
epoch [22/50] batch [180/245] time 0.096 (0.098) data 0.000 (0.002) loss 1.1117 (1.3444) teacher_loss 0.3952 (0.6154) loss_zs_kd 0.3405 (0.3742) loss_oracle 0.3114 (0.3277) acc 90.6250 (82.4826) kd_loss 0.5608 (0.5651) lr 1.3090e-03 eta 0:11:17
epoch [22/50] batch [200/245] time 0.100 (0.098) data 0.000 (0.002) loss 1.4134 (1.3495) teacher_loss 0.5540 (0.6151) loss_zs_kd 0.3345 (0.3738) loss_oracle 0.3604 (0.3309) acc 78.1250 (82.5625) kd_loss 0.6791 (0.5689) lr 1.3090e-03 eta 0:11:15
epoch [22/50] batch [220/245] time 0.093 (0.098) data 0.000 (0.002) loss 1.1690 (1.3622) teacher_loss 0.5099 (0.6272) loss_zs_kd 0.4017 (0.3739) loss_oracle 0.3579 (0.3337) acc 84.3750 (82.1733) kd_loss 0.4802 (0.5682) lr 1.3090e-03 eta 0:11:11
epoch [22/50] batch [240/245] time 0.086 (0.097) data 0.000 (0.001) loss 1.2328 (1.3734) teacher_loss 0.6264 (0.6369) loss_zs_kd 0.5365 (0.3734) loss_oracle 0.3181 (0.3358) acc 78.1250 (81.9271) kd_loss 0.4474 (0.5686) lr 1.3090e-03 eta 0:11:06
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,061
* accuracy: 91.3%
* error: 8.7%
* macro_f1: 90.5%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,228
* accuracy: 74.0%
* error: 26.0%
* macro_f1: 72.7%
******* Domain c best val acc:      91.6%, epoch: 19 *******
******* Domain c best val test acc: 74.5%, epoch: 19 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [23/50] batch [20/245] time 0.099 (0.109) data 0.001 (0.012) loss 1.0728 (1.4044) teacher_loss 0.3693 (0.6732) loss_zs_kd 0.4616 (0.4058) loss_oracle 0.3585 (0.3427) acc 90.6250 (81.5625) kd_loss 0.5243 (0.5599) lr 1.2487e-03 eta 0:12:23
epoch [23/50] batch [40/245] time 0.101 (0.103) data 0.000 (0.006) loss 1.1900 (1.3551) teacher_loss 0.4150 (0.6347) loss_zs_kd 0.2834 (0.3830) loss_oracle 0.3355 (0.3399) acc 90.6250 (82.2656) kd_loss 0.6073 (0.5504) lr 1.2487e-03 eta 0:11:43
epoch [23/50] batch [60/245] time 0.103 (0.102) data 0.000 (0.004) loss 1.8913 (1.3826) teacher_loss 1.1939 (0.6564) loss_zs_kd 0.3663 (0.3779) loss_oracle 0.3993 (0.3472) acc 62.5000 (81.4062) kd_loss 0.4977 (0.5526) lr 1.2487e-03 eta 0:11:32
epoch [23/50] batch [80/245] time 0.103 (0.102) data 0.000 (0.003) loss 1.7357 (1.3881) teacher_loss 1.0363 (0.6629) loss_zs_kd 0.2153 (0.3853) loss_oracle 0.3149 (0.3479) acc 75.0000 (81.0938) kd_loss 0.5419 (0.5512) lr 1.2487e-03 eta 0:11:28
epoch [23/50] batch [100/245] time 0.096 (0.101) data 0.000 (0.003) loss 1.3230 (1.3860) teacher_loss 0.6178 (0.6565) loss_zs_kd 0.4278 (0.3899) loss_oracle 0.3603 (0.3511) acc 81.2500 (81.4062) kd_loss 0.5250 (0.5540) lr 1.2487e-03 eta 0:11:21
epoch [23/50] batch [120/245] time 0.101 (0.100) data 0.000 (0.002) loss 1.3534 (1.3796) teacher_loss 0.5839 (0.6538) loss_zs_kd 0.4405 (0.3884) loss_oracle 0.3418 (0.3500) acc 87.5000 (81.8490) kd_loss 0.5987 (0.5508) lr 1.2487e-03 eta 0:11:16
epoch [23/50] batch [140/245] time 0.093 (0.100) data 0.000 (0.002) loss 1.1754 (1.3795) teacher_loss 0.2045 (0.6515) loss_zs_kd 0.3956 (0.3875) loss_oracle 0.4137 (0.3507) acc 90.6250 (81.8750) kd_loss 0.7641 (0.5526) lr 1.2487e-03 eta 0:11:10
epoch [23/50] batch [160/245] time 0.097 (0.099) data 0.000 (0.002) loss 1.2332 (1.3925) teacher_loss 0.4234 (0.6618) loss_zs_kd 0.3770 (0.3873) loss_oracle 0.4401 (0.3529) acc 93.7500 (81.6016) kd_loss 0.5898 (0.5543) lr 1.2487e-03 eta 0:11:06
epoch [23/50] batch [180/245] time 0.092 (0.099) data 0.000 (0.002) loss 1.2752 (1.3884) teacher_loss 0.6091 (0.6564) loss_zs_kd 0.4499 (0.3867) loss_oracle 0.3355 (0.3548) acc 84.3750 (81.8229) kd_loss 0.4983 (0.5546) lr 1.2487e-03 eta 0:11:01
epoch [23/50] batch [200/245] time 0.102 (0.099) data 0.000 (0.001) loss 1.6513 (1.3823) teacher_loss 0.9077 (0.6499) loss_zs_kd 0.3543 (0.3867) loss_oracle 0.3917 (0.3565) acc 71.8750 (81.9531) kd_loss 0.5478 (0.5541) lr 1.2487e-03 eta 0:10:58
epoch [23/50] batch [220/245] time 0.093 (0.099) data 0.000 (0.001) loss 1.7732 (1.3906) teacher_loss 1.0715 (0.6560) loss_zs_kd 0.6188 (0.3895) loss_oracle 0.3625 (0.3577) acc 75.0000 (81.8608) kd_loss 0.5205 (0.5558) lr 1.2487e-03 eta 0:10:54
epoch [23/50] batch [240/245] time 0.091 (0.098) data 0.000 (0.001) loss 1.4482 (1.3838) teacher_loss 0.8731 (0.6507) loss_zs_kd 0.4110 (0.3876) loss_oracle 0.3534 (0.3587) acc 75.0000 (81.9010) kd_loss 0.3984 (0.5538) lr 1.2487e-03 eta 0:10:51
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,056
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.3%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,239
* accuracy: 74.2%
* error: 25.8%
* macro_f1: 73.1%
******* Domain c best val acc:      91.6%, epoch: 19 *******
******* Domain c best val test acc: 74.5%, epoch: 19 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [24/50] batch [20/245] time 0.095 (0.115) data 0.000 (0.014) loss 1.1319 (1.4857) teacher_loss 0.3776 (0.6914) loss_zs_kd 0.2458 (0.3755) loss_oracle 0.2543 (0.3634) acc 90.6250 (81.0938) kd_loss 0.6272 (0.6126) lr 1.1874e-03 eta 0:12:36
epoch [24/50] batch [40/245] time 0.101 (0.106) data 0.000 (0.007) loss 1.6503 (1.4610) teacher_loss 0.9234 (0.6761) loss_zs_kd 0.4827 (0.3797) loss_oracle 0.3750 (0.3647) acc 81.2500 (81.3281) kd_loss 0.5394 (0.6026) lr 1.1874e-03 eta 0:11:35
epoch [24/50] batch [60/245] time 0.099 (0.103) data 0.000 (0.005) loss 1.0948 (1.4520) teacher_loss 0.3961 (0.6591) loss_zs_kd 0.3489 (0.3805) loss_oracle 0.3071 (0.3726) acc 84.3750 (81.8229) kd_loss 0.5452 (0.6067) lr 1.1874e-03 eta 0:11:13
epoch [24/50] batch [80/245] time 0.099 (0.101) data 0.001 (0.004) loss 1.4204 (1.4267) teacher_loss 0.7213 (0.6431) loss_zs_kd 0.4578 (0.3798) loss_oracle 0.3399 (0.3689) acc 75.0000 (81.9141) kd_loss 0.5291 (0.5992) lr 1.1874e-03 eta 0:11:01
epoch [24/50] batch [100/245] time 0.097 (0.100) data 0.000 (0.003) loss 1.0990 (1.4066) teacher_loss 0.4830 (0.6374) loss_zs_kd 0.3065 (0.3763) loss_oracle 0.2767 (0.3631) acc 93.7500 (82.1875) kd_loss 0.4776 (0.5876) lr 1.1874e-03 eta 0:10:53
epoch [24/50] batch [120/245] time 0.103 (0.101) data 0.000 (0.003) loss 1.4470 (1.3835) teacher_loss 0.7829 (0.6283) loss_zs_kd 0.4308 (0.3774) loss_oracle 0.3794 (0.3603) acc 75.0000 (82.3177) kd_loss 0.4743 (0.5750) lr 1.1874e-03 eta 0:10:55
epoch [24/50] batch [140/245] time 0.112 (0.101) data 0.000 (0.002) loss 1.6368 (1.3719) teacher_loss 0.9420 (0.6255) loss_zs_kd 0.3493 (0.3852) loss_oracle 0.3982 (0.3586) acc 75.0000 (82.4777) kd_loss 0.4956 (0.5671) lr 1.1874e-03 eta 0:10:57
epoch [24/50] batch [160/245] time 0.091 (0.101) data 0.000 (0.002) loss 1.5235 (1.3699) teacher_loss 0.7010 (0.6261) loss_zs_kd 0.4321 (0.3867) loss_oracle 0.3716 (0.3592) acc 81.2500 (82.5195) kd_loss 0.6367 (0.5642) lr 1.1874e-03 eta 0:10:53
epoch [24/50] batch [180/245] time 0.098 (0.101) data 0.000 (0.002) loss 1.2620 (1.3691) teacher_loss 0.5231 (0.6268) loss_zs_kd 0.4179 (0.3890) loss_oracle 0.3511 (0.3601) acc 84.3750 (82.6562) kd_loss 0.5633 (0.5622) lr 1.1874e-03 eta 0:10:48
epoch [24/50] batch [200/245] time 0.094 (0.100) data 0.000 (0.002) loss 1.6249 (1.3771) teacher_loss 0.7536 (0.6353) loss_zs_kd 0.2424 (0.3888) loss_oracle 0.3837 (0.3612) acc 81.2500 (82.3438) kd_loss 0.6794 (0.5612) lr 1.1874e-03 eta 0:10:44
epoch [24/50] batch [220/245] time 0.100 (0.100) data 0.000 (0.001) loss 1.2034 (1.3744) teacher_loss 0.4808 (0.6342) loss_zs_kd 0.3627 (0.3909) loss_oracle 0.3603 (0.3608) acc 90.6250 (82.4432) kd_loss 0.5425 (0.5599) lr 1.1874e-03 eta 0:10:41
epoch [24/50] batch [240/245] time 0.090 (0.100) data 0.000 (0.001) loss 1.3250 (1.3703) teacher_loss 0.7509 (0.6347) loss_zs_kd 0.3007 (0.3879) loss_oracle 0.3015 (0.3576) acc 81.2500 (82.3958) kd_loss 0.4233 (0.5568) lr 1.1874e-03 eta 0:10:36
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,077
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 91.0%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,246
* accuracy: 74.4%
* error: 25.6%
* macro_f1: 73.1%
******* Domain c best val acc:      91.8%, epoch: 24 *******
******* Domain c best val test acc: 74.4%, epoch: 24 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [25/50] batch [20/245] time 0.105 (0.119) data 0.001 (0.014) loss 1.4415 (1.3839) teacher_loss 0.7611 (0.6555) loss_zs_kd 0.3360 (0.3853) loss_oracle 0.2974 (0.3237) acc 78.1250 (83.1250) kd_loss 0.5317 (0.5665) lr 1.1253e-03 eta 0:12:33
epoch [25/50] batch [40/245] time 0.103 (0.110) data 0.000 (0.007) loss 1.0677 (1.3894) teacher_loss 0.3703 (0.6396) loss_zs_kd 0.4059 (0.3916) loss_oracle 0.3319 (0.3342) acc 81.2500 (82.6562) kd_loss 0.5314 (0.5827) lr 1.1253e-03 eta 0:11:34
epoch [25/50] batch [60/245] time 0.096 (0.106) data 0.000 (0.005) loss 1.6057 (1.3935) teacher_loss 0.7555 (0.6467) loss_zs_kd 0.3758 (0.3853) loss_oracle 0.4212 (0.3388) acc 81.2500 (82.1875) kd_loss 0.6396 (0.5774) lr 1.1253e-03 eta 0:11:06
epoch [25/50] batch [80/245] time 0.103 (0.104) data 0.000 (0.004) loss 1.3508 (1.4143) teacher_loss 0.6538 (0.6637) loss_zs_kd 0.4669 (0.3879) loss_oracle 0.3395 (0.3446) acc 81.2500 (81.3672) kd_loss 0.5272 (0.5784) lr 1.1253e-03 eta 0:10:52
epoch [25/50] batch [100/245] time 0.103 (0.102) data 0.001 (0.003) loss 1.0446 (1.4081) teacher_loss 0.3637 (0.6572) loss_zs_kd 0.4559 (0.3939) loss_oracle 0.3152 (0.3463) acc 93.7500 (81.6562) kd_loss 0.5234 (0.5777) lr 1.1253e-03 eta 0:10:42
epoch [25/50] batch [120/245] time 0.101 (0.102) data 0.000 (0.003) loss 1.5312 (1.3975) teacher_loss 0.8869 (0.6527) loss_zs_kd 0.3355 (0.3926) loss_oracle 0.3352 (0.3450) acc 81.2500 (81.7969) kd_loss 0.4768 (0.5723) lr 1.1253e-03 eta 0:10:36
epoch [25/50] batch [140/245] time 0.094 (0.101) data 0.000 (0.002) loss 1.4428 (1.3829) teacher_loss 0.7841 (0.6428) loss_zs_kd 0.3858 (0.3914) loss_oracle 0.3306 (0.3415) acc 81.2500 (82.1652) kd_loss 0.4935 (0.5694) lr 1.1253e-03 eta 0:10:30
epoch [25/50] batch [160/245] time 0.102 (0.101) data 0.000 (0.002) loss 1.4055 (1.3795) teacher_loss 0.7466 (0.6405) loss_zs_kd 0.4111 (0.3856) loss_oracle 0.3146 (0.3399) acc 71.8750 (82.2852) kd_loss 0.5016 (0.5690) lr 1.1253e-03 eta 0:10:25
epoch [25/50] batch [180/245] time 0.101 (0.101) data 0.000 (0.002) loss 0.9184 (1.3849) teacher_loss 0.0956 (0.6417) loss_zs_kd 0.3694 (0.3833) loss_oracle 0.3377 (0.3402) acc 100.0000 (82.2396) kd_loss 0.6540 (0.5732) lr 1.1253e-03 eta 0:10:22
epoch [25/50] batch [200/245] time 0.103 (0.100) data 0.000 (0.002) loss 1.2201 (1.3820) teacher_loss 0.4034 (0.6396) loss_zs_kd 0.4391 (0.3826) loss_oracle 0.3558 (0.3384) acc 87.5000 (82.2812) kd_loss 0.6388 (0.5732) lr 1.1253e-03 eta 0:10:19
epoch [25/50] batch [220/245] time 0.100 (0.100) data 0.000 (0.001) loss 1.1585 (1.3801) teacher_loss 0.3842 (0.6368) loss_zs_kd 0.4141 (0.3820) loss_oracle 0.3124 (0.3377) acc 90.6250 (82.3864) kd_loss 0.6181 (0.5744) lr 1.1253e-03 eta 0:10:16
epoch [25/50] batch [240/245] time 0.091 (0.100) data 0.000 (0.001) loss 1.4931 (1.3822) teacher_loss 0.4088 (0.6347) loss_zs_kd 0.3370 (0.3797) loss_oracle 0.3599 (0.3380) acc 90.6250 (82.3307) kd_loss 0.9044 (0.5786) lr 1.1253e-03 eta 0:10:10
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,078
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 91.0%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,253
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.2%
******* Domain c best val acc:      91.8%, epoch: 25 *******
******* Domain c best val test acc: 74.5%, epoch: 25 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [26/50] batch [20/245] time 0.100 (0.133) data 0.000 (0.014) loss 1.5469 (1.3830) teacher_loss 0.7826 (0.6043) loss_zs_kd 0.3695 (0.4187) loss_oracle 0.3702 (0.3681) acc 78.1250 (82.3438) kd_loss 0.5792 (0.5946) lr 1.0628e-03 eta 0:13:33
epoch [26/50] batch [40/245] time 0.102 (0.119) data 0.000 (0.007) loss 1.7833 (1.4104) teacher_loss 0.9182 (0.6190) loss_zs_kd 0.3842 (0.4022) loss_oracle 0.3710 (0.3702) acc 75.0000 (82.8125) kd_loss 0.6796 (0.6063) lr 1.0628e-03 eta 0:12:01
epoch [26/50] batch [60/245] time 0.103 (0.114) data 0.000 (0.005) loss 1.2224 (1.4230) teacher_loss 0.3837 (0.6363) loss_zs_kd 0.2382 (0.4033) loss_oracle 0.3758 (0.3710) acc 90.6250 (81.8229) kd_loss 0.6508 (0.6013) lr 1.0628e-03 eta 0:11:31
epoch [26/50] batch [80/245] time 0.100 (0.111) data 0.000 (0.004) loss 1.5069 (1.4357) teacher_loss 0.6322 (0.6518) loss_zs_kd 0.5243 (0.4058) loss_oracle 0.3827 (0.3703) acc 78.1250 (81.7578) kd_loss 0.6834 (0.5988) lr 1.0628e-03 eta 0:11:12
epoch [26/50] batch [100/245] time 0.101 (0.109) data 0.000 (0.003) loss 1.1394 (1.4408) teacher_loss 0.5212 (0.6670) loss_zs_kd 0.4043 (0.4120) loss_oracle 0.3207 (0.3657) acc 84.3750 (81.1562) kd_loss 0.4578 (0.5910) lr 1.0628e-03 eta 0:10:59
epoch [26/50] batch [120/245] time 0.104 (0.108) data 0.000 (0.002) loss 1.3871 (1.4295) teacher_loss 0.6611 (0.6632) loss_zs_kd 0.4052 (0.4064) loss_oracle 0.3181 (0.3613) acc 81.2500 (81.3802) kd_loss 0.5669 (0.5857) lr 1.0628e-03 eta 0:10:49
epoch [26/50] batch [140/245] time 0.112 (0.107) data 0.000 (0.002) loss 1.2137 (1.4283) teacher_loss 0.5522 (0.6629) loss_zs_kd 0.4012 (0.4034) loss_oracle 0.2931 (0.3570) acc 87.5000 (81.2500) kd_loss 0.5150 (0.5869) lr 1.0628e-03 eta 0:10:42
epoch [26/50] batch [160/245] time 0.108 (0.107) data 0.000 (0.002) loss 1.8010 (1.4186) teacher_loss 1.0600 (0.6586) loss_zs_kd 0.3136 (0.3986) loss_oracle 0.3246 (0.3529) acc 68.7500 (81.2305) kd_loss 0.5787 (0.5835) lr 1.0628e-03 eta 0:10:37
epoch [26/50] batch [180/245] time 0.099 (0.106) data 0.000 (0.002) loss 1.4965 (1.4129) teacher_loss 0.6882 (0.6537) loss_zs_kd 0.3467 (0.3929) loss_oracle 0.3211 (0.3469) acc 87.5000 (81.4583) kd_loss 0.6477 (0.5858) lr 1.0628e-03 eta 0:10:32
epoch [26/50] batch [200/245] time 0.099 (0.105) data 0.000 (0.002) loss 1.1367 (1.4045) teacher_loss 0.4964 (0.6458) loss_zs_kd 0.2763 (0.3880) loss_oracle 0.3128 (0.3433) acc 84.3750 (81.5156) kd_loss 0.4839 (0.5870) lr 1.0628e-03 eta 0:10:24
epoch [26/50] batch [220/245] time 0.094 (0.105) data 0.000 (0.001) loss 1.2676 (1.4010) teacher_loss 0.5104 (0.6435) loss_zs_kd 0.4882 (0.3916) loss_oracle 0.3056 (0.3421) acc 93.7500 (81.6619) kd_loss 0.6044 (0.5865) lr 1.0628e-03 eta 0:10:18
epoch [26/50] batch [240/245] time 0.090 (0.104) data 0.000 (0.001) loss 0.9057 (1.3966) teacher_loss 0.2959 (0.6430) loss_zs_kd 0.2580 (0.3905) loss_oracle 0.3527 (0.3428) acc 90.6250 (81.6406) kd_loss 0.4335 (0.5821) lr 1.0628e-03 eta 0:10:10
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,080
* accuracy: 91.9%
* error: 8.1%
* macro_f1: 91.1%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,239
* accuracy: 74.2%
* error: 25.8%
* macro_f1: 72.9%
******* Domain c best val acc:      91.9%, epoch: 26 *******
******* Domain c best val test acc: 74.2%, epoch: 26 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [27/50] batch [20/245] time 0.110 (0.136) data 0.000 (0.014) loss 1.0495 (1.3360) teacher_loss 0.4187 (0.5754) loss_zs_kd 0.2628 (0.3575) loss_oracle 0.2848 (0.3442) acc 90.6250 (84.0625) kd_loss 0.4884 (0.5885) lr 1.0000e-03 eta 0:13:14
epoch [27/50] batch [40/245] time 0.119 (0.121) data 0.000 (0.007) loss 1.1351 (1.3897) teacher_loss 0.4995 (0.6247) loss_zs_kd 0.3424 (0.3702) loss_oracle 0.3054 (0.3452) acc 84.3750 (82.3438) kd_loss 0.4829 (0.5924) lr 1.0000e-03 eta 0:11:45
epoch [27/50] batch [60/245] time 0.112 (0.116) data 0.001 (0.005) loss 1.5343 (1.4096) teacher_loss 0.7519 (0.6464) loss_zs_kd 0.4055 (0.3620) loss_oracle 0.3546 (0.3475) acc 78.1250 (82.1354) kd_loss 0.6051 (0.5894) lr 1.0000e-03 eta 0:11:13
epoch [27/50] batch [80/245] time 0.102 (0.113) data 0.000 (0.004) loss 1.5431 (1.4132) teacher_loss 0.8179 (0.6475) loss_zs_kd 0.4794 (0.3677) loss_oracle 0.3473 (0.3500) acc 75.0000 (82.0312) kd_loss 0.5516 (0.5907) lr 1.0000e-03 eta 0:10:55
epoch [27/50] batch [100/245] time 0.108 (0.111) data 0.000 (0.003) loss 1.5516 (1.4234) teacher_loss 0.7540 (0.6538) loss_zs_kd 0.5806 (0.3706) loss_oracle 0.3487 (0.3524) acc 71.8750 (81.7812) kd_loss 0.6233 (0.5934) lr 1.0000e-03 eta 0:10:43
epoch [27/50] batch [120/245] time 0.096 (0.110) data 0.000 (0.003) loss 1.2723 (1.4231) teacher_loss 0.4398 (0.6509) loss_zs_kd 0.2855 (0.3741) loss_oracle 0.3536 (0.3541) acc 90.6250 (81.7969) kd_loss 0.6557 (0.5952) lr 1.0000e-03 eta 0:10:31
epoch [27/50] batch [140/245] time 0.102 (0.108) data 0.000 (0.002) loss 0.9061 (1.4138) teacher_loss 0.2966 (0.6463) loss_zs_kd 0.3451 (0.3790) loss_oracle 0.3490 (0.3541) acc 93.7500 (82.0312) kd_loss 0.4350 (0.5904) lr 1.0000e-03 eta 0:10:22
epoch [27/50] batch [160/245] time 0.096 (0.108) data 0.000 (0.002) loss 1.3601 (1.4053) teacher_loss 0.6421 (0.6380) loss_zs_kd 0.4547 (0.3750) loss_oracle 0.3265 (0.3549) acc 84.3750 (82.2461) kd_loss 0.5548 (0.5898) lr 1.0000e-03 eta 0:10:15
epoch [27/50] batch [180/245] time 0.104 (0.106) data 0.000 (0.002) loss 1.1188 (1.3901) teacher_loss 0.3854 (0.6250) loss_zs_kd 0.3537 (0.3778) loss_oracle 0.3504 (0.3574) acc 87.5000 (82.6736) kd_loss 0.5582 (0.5864) lr 1.0000e-03 eta 0:10:06
epoch [27/50] batch [200/245] time 0.095 (0.105) data 0.000 (0.002) loss 1.3284 (1.3820) teacher_loss 0.5087 (0.6201) loss_zs_kd 0.4079 (0.3779) loss_oracle 0.3738 (0.3573) acc 81.2500 (82.7812) kd_loss 0.6329 (0.5832) lr 1.0000e-03 eta 0:09:59
epoch [27/50] batch [220/245] time 0.100 (0.105) data 0.000 (0.001) loss 1.4315 (1.3725) teacher_loss 0.7149 (0.6115) loss_zs_kd 0.3896 (0.3787) loss_oracle 0.3351 (0.3572) acc 75.0000 (82.7557) kd_loss 0.5490 (0.5824) lr 1.0000e-03 eta 0:09:53
epoch [27/50] batch [240/245] time 0.087 (0.104) data 0.000 (0.001) loss 1.5486 (1.3751) teacher_loss 0.6757 (0.6123) loss_zs_kd 0.3887 (0.3841) loss_oracle 0.3413 (0.3567) acc 75.0000 (82.7995) kd_loss 0.7022 (0.5845) lr 1.0000e-03 eta 0:09:44
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,072
* accuracy: 91.6%
* error: 8.4%
* macro_f1: 90.8%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,229
* accuracy: 74.0%
* error: 26.0%
* macro_f1: 72.8%
******* Domain c best val acc:      91.9%, epoch: 26 *******
******* Domain c best val test acc: 74.2%, epoch: 26 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [28/50] batch [20/245] time 0.154 (0.114) data 0.000 (0.014) loss 1.5947 (1.3535) teacher_loss 0.7485 (0.5893) loss_zs_kd 0.3598 (0.4115) loss_oracle 0.3193 (0.3471) acc 78.1250 (81.5625) kd_loss 0.6865 (0.5907) lr 9.3721e-04 eta 0:10:40
epoch [28/50] batch [40/245] time 0.096 (0.108) data 0.000 (0.007) loss 1.0835 (1.3146) teacher_loss 0.4516 (0.5582) loss_zs_kd 0.5971 (0.3966) loss_oracle 0.3363 (0.3434) acc 90.6250 (83.0469) kd_loss 0.4638 (0.5846) lr 9.3721e-04 eta 0:10:03
epoch [28/50] batch [60/245] time 0.095 (0.103) data 0.000 (0.005) loss 1.5971 (1.3246) teacher_loss 0.9840 (0.5830) loss_zs_kd 0.5449 (0.4026) loss_oracle 0.3056 (0.3420) acc 75.0000 (82.9688) kd_loss 0.4603 (0.5706) lr 9.3721e-04 eta 0:09:36
epoch [28/50] batch [80/245] time 0.091 (0.100) data 0.000 (0.004) loss 1.5337 (1.3493) teacher_loss 0.8440 (0.6028) loss_zs_kd 0.3708 (0.3906) loss_oracle 0.3490 (0.3391) acc 75.0000 (82.6953) kd_loss 0.5152 (0.5769) lr 9.3721e-04 eta 0:09:18
epoch [28/50] batch [100/245] time 0.090 (0.099) data 0.001 (0.003) loss 1.8334 (1.3625) teacher_loss 1.0694 (0.6119) loss_zs_kd 0.4765 (0.3912) loss_oracle 0.3611 (0.3397) acc 71.8750 (82.6250) kd_loss 0.5835 (0.5808) lr 9.3721e-04 eta 0:09:06
epoch [28/50] batch [120/245] time 0.099 (0.098) data 0.000 (0.002) loss 1.2368 (1.3800) teacher_loss 0.5290 (0.6238) loss_zs_kd 0.3411 (0.4006) loss_oracle 0.2753 (0.3379) acc 87.5000 (82.5000) kd_loss 0.5702 (0.5872) lr 9.3721e-04 eta 0:08:59
epoch [28/50] batch [140/245] time 0.084 (0.097) data 0.000 (0.002) loss 1.1062 (1.3665) teacher_loss 0.4124 (0.6150) loss_zs_kd 0.4210 (0.4001) loss_oracle 0.3003 (0.3362) acc 93.7500 (82.7455) kd_loss 0.5437 (0.5834) lr 9.3721e-04 eta 0:08:52
epoch [28/50] batch [160/245] time 0.097 (0.096) data 0.000 (0.002) loss 1.5915 (1.3705) teacher_loss 0.7983 (0.6211) loss_zs_kd 0.3766 (0.4036) loss_oracle 0.3840 (0.3358) acc 78.1250 (82.5391) kd_loss 0.6012 (0.5816) lr 9.3721e-04 eta 0:08:46
epoch [28/50] batch [180/245] time 0.103 (0.096) data 0.000 (0.002) loss 1.0948 (1.3654) teacher_loss 0.3865 (0.6199) loss_zs_kd 0.2473 (0.3999) loss_oracle 0.3399 (0.3345) acc 84.3750 (82.6389) kd_loss 0.5383 (0.5782) lr 9.3721e-04 eta 0:08:43
epoch [28/50] batch [200/245] time 0.099 (0.096) data 0.000 (0.002) loss 1.5024 (1.3684) teacher_loss 0.7352 (0.6250) loss_zs_kd 0.3493 (0.3965) loss_oracle 0.3295 (0.3340) acc 78.1250 (82.5156) kd_loss 0.6025 (0.5763) lr 9.3721e-04 eta 0:08:42
epoch [28/50] batch [220/245] time 0.093 (0.096) data 0.000 (0.001) loss 1.0113 (1.3635) teacher_loss 0.3720 (0.6241) loss_zs_kd 0.3227 (0.3995) loss_oracle 0.3312 (0.3340) acc 90.6250 (82.5710) kd_loss 0.4737 (0.5724) lr 9.3721e-04 eta 0:08:42
epoch [28/50] batch [240/245] time 0.085 (0.096) data 0.000 (0.001) loss 1.1248 (1.3575) teacher_loss 0.2490 (0.6182) loss_zs_kd 0.4084 (0.3965) loss_oracle 0.3942 (0.3347) acc 93.7500 (82.7083) kd_loss 0.6787 (0.5719) lr 9.3721e-04 eta 0:08:39
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,069
* accuracy: 91.5%
* error: 8.5%
* macro_f1: 90.8%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,247
* accuracy: 74.4%
* error: 25.6%
* macro_f1: 73.1%
******* Domain c best val acc:      91.9%, epoch: 26 *******
******* Domain c best val test acc: 74.2%, epoch: 26 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [29/50] batch [20/245] time 0.111 (0.121) data 0.000 (0.013) loss 1.5500 (1.3732) teacher_loss 0.8164 (0.6155) loss_zs_kd 0.6086 (0.3916) loss_oracle 0.3321 (0.3387) acc 75.0000 (82.6562) kd_loss 0.5676 (0.5884) lr 8.7467e-04 eta 0:10:49
epoch [29/50] batch [40/245] time 0.147 (0.118) data 0.000 (0.007) loss 1.1574 (1.4270) teacher_loss 0.3788 (0.6803) loss_zs_kd 0.3359 (0.3814) loss_oracle 0.3536 (0.3359) acc 87.5000 (81.0938) kd_loss 0.6018 (0.5788) lr 8.7467e-04 eta 0:10:32
epoch [29/50] batch [60/245] time 0.112 (0.115) data 0.001 (0.005) loss 1.3026 (1.3940) teacher_loss 0.5697 (0.6548) loss_zs_kd 0.4178 (0.3728) loss_oracle 0.3263 (0.3332) acc 87.5000 (81.5625) kd_loss 0.5698 (0.5726) lr 8.7467e-04 eta 0:10:11
epoch [29/50] batch [80/245] time 0.101 (0.112) data 0.000 (0.003) loss 1.2727 (1.3779) teacher_loss 0.4370 (0.6392) loss_zs_kd 0.3683 (0.3722) loss_oracle 0.3358 (0.3324) acc 90.6250 (82.1875) kd_loss 0.6677 (0.5725) lr 8.7467e-04 eta 0:09:53
epoch [29/50] batch [100/245] time 0.101 (0.109) data 0.000 (0.003) loss 1.5704 (1.3682) teacher_loss 0.8167 (0.6302) loss_zs_kd 0.3842 (0.3739) loss_oracle 0.3746 (0.3324) acc 84.3750 (82.5000) kd_loss 0.5664 (0.5718) lr 8.7467e-04 eta 0:09:36
epoch [29/50] batch [120/245] time 0.109 (0.108) data 0.000 (0.002) loss 1.8577 (1.3645) teacher_loss 1.1405 (0.6287) loss_zs_kd 0.3802 (0.3833) loss_oracle 0.3147 (0.3334) acc 71.8750 (82.4219) kd_loss 0.5599 (0.5692) lr 8.7467e-04 eta 0:09:28
epoch [29/50] batch [140/245] time 0.098 (0.107) data 0.000 (0.002) loss 1.8128 (1.3676) teacher_loss 0.9879 (0.6338) loss_zs_kd 0.6222 (0.3832) loss_oracle 0.3434 (0.3337) acc 71.8750 (82.2321) kd_loss 0.6532 (0.5670) lr 8.7467e-04 eta 0:09:19
epoch [29/50] batch [160/245] time 0.094 (0.105) data 0.000 (0.002) loss 1.2609 (1.3708) teacher_loss 0.4683 (0.6322) loss_zs_kd 0.3244 (0.3809) loss_oracle 0.2756 (0.3343) acc 84.3750 (82.2656) kd_loss 0.6547 (0.5715) lr 8.7467e-04 eta 0:09:11
epoch [29/50] batch [180/245] time 0.105 (0.104) data 0.000 (0.002) loss 1.1968 (1.3796) teacher_loss 0.4618 (0.6413) loss_zs_kd 0.4636 (0.3826) loss_oracle 0.3576 (0.3334) acc 87.5000 (82.1528) kd_loss 0.5562 (0.5716) lr 8.7467e-04 eta 0:09:03
epoch [29/50] batch [200/245] time 0.095 (0.104) data 0.000 (0.002) loss 1.4764 (1.3773) teacher_loss 0.7587 (0.6411) loss_zs_kd 0.3656 (0.3804) loss_oracle 0.3084 (0.3313) acc 78.1250 (82.1406) kd_loss 0.5634 (0.5705) lr 8.7467e-04 eta 0:08:59
epoch [29/50] batch [220/245] time 0.092 (0.104) data 0.000 (0.001) loss 1.2638 (1.3734) teacher_loss 0.5845 (0.6394) loss_zs_kd 0.3842 (0.3818) loss_oracle 0.3736 (0.3316) acc 78.1250 (82.1449) kd_loss 0.4925 (0.5682) lr 8.7467e-04 eta 0:08:55
epoch [29/50] batch [240/245] time 0.089 (0.102) data 0.000 (0.001) loss 0.9270 (1.3669) teacher_loss 0.2915 (0.6365) loss_zs_kd 0.2584 (0.3824) loss_oracle 0.3140 (0.3309) acc 93.7500 (82.0964) kd_loss 0.4784 (0.5650) lr 8.7467e-04 eta 0:08:47
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,072
* accuracy: 91.6%
* error: 8.4%
* macro_f1: 90.8%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,240
* accuracy: 74.2%
* error: 25.8%
* macro_f1: 72.9%
******* Domain c best val acc:      91.9%, epoch: 26 *******
******* Domain c best val test acc: 74.2%, epoch: 26 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [30/50] batch [20/245] time 0.108 (0.124) data 0.000 (0.018) loss 1.1319 (1.2700) teacher_loss 0.4545 (0.5879) loss_zs_kd 0.4101 (0.3600) loss_oracle 0.3346 (0.3332) acc 81.2500 (82.3438) kd_loss 0.5102 (0.5155) lr 8.1262e-04 eta 0:10:36
epoch [30/50] batch [40/245] time 0.103 (0.115) data 0.000 (0.009) loss 1.0164 (1.2773) teacher_loss 0.3112 (0.5670) loss_zs_kd 0.3525 (0.3828) loss_oracle 0.3445 (0.3372) acc 90.6250 (83.1250) kd_loss 0.5329 (0.5417) lr 8.1262e-04 eta 0:09:45
epoch [30/50] batch [60/245] time 0.100 (0.115) data 0.001 (0.006) loss 1.2935 (1.3025) teacher_loss 0.5971 (0.5860) loss_zs_kd 0.3902 (0.3871) loss_oracle 0.3046 (0.3394) acc 84.3750 (82.6562) kd_loss 0.5442 (0.5468) lr 8.1262e-04 eta 0:09:46
epoch [30/50] batch [80/245] time 0.098 (0.112) data 0.000 (0.005) loss 1.1894 (1.3119) teacher_loss 0.4559 (0.5925) loss_zs_kd 0.2765 (0.3932) loss_oracle 0.3258 (0.3379) acc 81.2500 (82.6953) kd_loss 0.5705 (0.5504) lr 8.1262e-04 eta 0:09:27
epoch [30/50] batch [100/245] time 0.103 (0.110) data 0.000 (0.004) loss 1.3455 (1.3254) teacher_loss 0.5461 (0.6060) loss_zs_kd 0.3415 (0.4001) loss_oracle 0.3366 (0.3391) acc 81.2500 (82.4688) kd_loss 0.6311 (0.5498) lr 8.1262e-04 eta 0:09:14
epoch [30/50] batch [120/245] time 0.103 (0.109) data 0.000 (0.003) loss 1.3967 (1.3355) teacher_loss 0.5703 (0.6075) loss_zs_kd 0.4313 (0.4010) loss_oracle 0.3224 (0.3373) acc 81.2500 (82.6042) kd_loss 0.6652 (0.5593) lr 8.1262e-04 eta 0:09:07
epoch [30/50] batch [140/245] time 0.110 (0.108) data 0.001 (0.003) loss 1.3553 (1.3450) teacher_loss 0.5476 (0.6133) loss_zs_kd 0.4671 (0.4039) loss_oracle 0.2705 (0.3381) acc 84.3750 (82.4330) kd_loss 0.6725 (0.5626) lr 8.1262e-04 eta 0:09:01
epoch [30/50] batch [160/245] time 0.109 (0.108) data 0.000 (0.002) loss 0.9817 (1.3411) teacher_loss 0.2804 (0.6068) loss_zs_kd 0.4154 (0.4027) loss_oracle 0.2993 (0.3384) acc 93.7500 (82.6953) kd_loss 0.5517 (0.5651) lr 8.1262e-04 eta 0:08:56
epoch [30/50] batch [180/245] time 0.099 (0.107) data 0.000 (0.002) loss 1.1652 (1.3351) teacher_loss 0.5549 (0.6046) loss_zs_kd 0.3918 (0.4018) loss_oracle 0.2642 (0.3373) acc 84.3750 (82.8299) kd_loss 0.4781 (0.5618) lr 8.1262e-04 eta 0:08:50
epoch [30/50] batch [200/245] time 0.099 (0.106) data 0.001 (0.002) loss 1.3597 (1.3405) teacher_loss 0.7331 (0.6137) loss_zs_kd 0.4517 (0.4027) loss_oracle 0.3273 (0.3379) acc 84.3750 (82.5938) kd_loss 0.4629 (0.5579) lr 8.1262e-04 eta 0:08:46
epoch [30/50] batch [220/245] time 0.100 (0.106) data 0.000 (0.002) loss 1.7807 (1.3490) teacher_loss 1.0798 (0.6201) loss_zs_kd 0.5133 (0.4025) loss_oracle 0.3513 (0.3398) acc 71.8750 (82.3722) kd_loss 0.5253 (0.5590) lr 8.1262e-04 eta 0:08:42
epoch [30/50] batch [240/245] time 0.109 (0.106) data 0.000 (0.002) loss 1.2748 (1.3510) teacher_loss 0.4054 (0.6217) loss_zs_kd 0.5362 (0.4035) loss_oracle 0.4334 (0.3421) acc 90.6250 (82.4609) kd_loss 0.6528 (0.5583) lr 8.1262e-04 eta 0:08:39
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,075
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,236
* accuracy: 74.1%
* error: 25.9%
* macro_f1: 72.9%
******* Domain c best val acc:      91.9%, epoch: 26 *******
******* Domain c best val test acc: 74.2%, epoch: 26 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [31/50] batch [20/245] time 0.099 (0.123) data 0.001 (0.016) loss 1.2334 (1.3667) teacher_loss 0.4905 (0.5584) loss_zs_kd 0.4480 (0.4008) loss_oracle 0.3462 (0.3532) acc 84.3750 (84.2188) kd_loss 0.5698 (0.6318) lr 7.5131e-04 eta 0:10:02
epoch [31/50] batch [40/245] time 0.105 (0.114) data 0.000 (0.008) loss 1.6475 (1.4074) teacher_loss 0.7322 (0.6045) loss_zs_kd 0.5195 (0.4102) loss_oracle 0.3994 (0.3627) acc 75.0000 (83.5156) kd_loss 0.7155 (0.6216) lr 7.5131e-04 eta 0:09:14
epoch [31/50] batch [60/245] time 0.111 (0.115) data 0.000 (0.006) loss 1.6145 (1.4083) teacher_loss 0.8101 (0.6011) loss_zs_kd 0.5420 (0.4014) loss_oracle 0.3930 (0.3637) acc 81.2500 (83.4896) kd_loss 0.6078 (0.6253) lr 7.5131e-04 eta 0:09:15
epoch [31/50] batch [80/245] time 0.101 (0.113) data 0.000 (0.004) loss 1.4108 (1.3727) teacher_loss 0.6595 (0.5845) loss_zs_kd 0.2616 (0.3935) loss_oracle 0.3239 (0.3591) acc 81.2500 (83.7891) kd_loss 0.5894 (0.6087) lr 7.5131e-04 eta 0:09:02
epoch [31/50] batch [100/245] time 0.104 (0.111) data 0.000 (0.003) loss 1.1751 (1.3861) teacher_loss 0.4682 (0.6056) loss_zs_kd 0.2076 (0.3880) loss_oracle 0.3314 (0.3589) acc 87.5000 (83.1562) kd_loss 0.5412 (0.6010) lr 7.5131e-04 eta 0:08:52
epoch [31/50] batch [120/245] time 0.100 (0.110) data 0.000 (0.003) loss 1.0390 (1.3852) teacher_loss 0.2614 (0.6104) loss_zs_kd 0.3011 (0.3905) loss_oracle 0.3505 (0.3589) acc 93.7500 (82.9948) kd_loss 0.6024 (0.5954) lr 7.5131e-04 eta 0:08:44
epoch [31/50] batch [140/245] time 0.098 (0.109) data 0.000 (0.002) loss 1.2211 (1.3812) teacher_loss 0.3538 (0.6110) loss_zs_kd 0.2952 (0.3883) loss_oracle 0.3520 (0.3585) acc 90.6250 (83.1696) kd_loss 0.6913 (0.5910) lr 7.5131e-04 eta 0:08:37
epoch [31/50] batch [160/245] time 0.093 (0.107) data 0.000 (0.002) loss 1.6899 (1.3854) teacher_loss 0.8041 (0.6117) loss_zs_kd 0.5956 (0.3888) loss_oracle 0.3357 (0.3571) acc 81.2500 (82.9297) kd_loss 0.7179 (0.5952) lr 7.5131e-04 eta 0:08:29
epoch [31/50] batch [180/245] time 0.096 (0.106) data 0.000 (0.002) loss 1.6467 (1.3842) teacher_loss 0.8987 (0.6111) loss_zs_kd 0.4762 (0.3883) loss_oracle 0.3398 (0.3557) acc 65.6250 (83.0035) kd_loss 0.5781 (0.5953) lr 7.5131e-04 eta 0:08:20
epoch [31/50] batch [200/245] time 0.097 (0.105) data 0.000 (0.002) loss 1.5864 (1.3863) teacher_loss 0.7862 (0.6179) loss_zs_kd 0.3820 (0.3920) loss_oracle 0.3850 (0.3545) acc 81.2500 (82.8750) kd_loss 0.6077 (0.5911) lr 7.5131e-04 eta 0:08:13
epoch [31/50] batch [220/245] time 0.099 (0.104) data 0.000 (0.002) loss 1.6061 (1.3875) teacher_loss 0.8854 (0.6224) loss_zs_kd 0.5573 (0.3967) loss_oracle 0.3259 (0.3541) acc 78.1250 (82.8693) kd_loss 0.5577 (0.5881) lr 7.5131e-04 eta 0:08:07
epoch [31/50] batch [240/245] time 0.089 (0.103) data 0.000 (0.002) loss 1.3736 (1.3827) teacher_loss 0.6843 (0.6182) loss_zs_kd 0.3225 (0.3951) loss_oracle 0.3082 (0.3532) acc 81.2500 (82.9948) kd_loss 0.5352 (0.5879) lr 7.5131e-04 eta 0:08:00
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,074
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 90.9%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,249
* accuracy: 74.4%
* error: 25.6%
* macro_f1: 73.2%
******* Domain c best val acc:      91.9%, epoch: 26 *******
******* Domain c best val test acc: 74.2%, epoch: 26 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [32/50] batch [20/245] time 0.092 (0.120) data 0.000 (0.016) loss 1.0701 (1.2652) teacher_loss 0.2984 (0.5236) loss_zs_kd 0.2999 (0.4134) loss_oracle 0.3698 (0.3455) acc 90.6250 (84.8438) kd_loss 0.5868 (0.5688) lr 6.9098e-04 eta 0:09:14
epoch [32/50] batch [40/245] time 0.102 (0.109) data 0.000 (0.008) loss 1.3244 (1.2923) teacher_loss 0.5803 (0.5701) loss_zs_kd 0.4442 (0.3995) loss_oracle 0.3625 (0.3497) acc 81.2500 (83.5938) kd_loss 0.5629 (0.5473) lr 6.9098e-04 eta 0:08:23
epoch [32/50] batch [60/245] time 0.094 (0.108) data 0.001 (0.005) loss 1.0332 (1.3090) teacher_loss 0.2914 (0.5786) loss_zs_kd 0.4156 (0.3976) loss_oracle 0.3965 (0.3482) acc 90.6250 (83.1250) kd_loss 0.5435 (0.5563) lr 6.9098e-04 eta 0:08:16
epoch [32/50] batch [80/245] time 0.097 (0.105) data 0.000 (0.004) loss 1.2421 (1.3151) teacher_loss 0.4560 (0.5785) loss_zs_kd 0.3550 (0.3981) loss_oracle 0.3657 (0.3486) acc 81.2500 (82.8906) kd_loss 0.6032 (0.5623) lr 6.9098e-04 eta 0:07:59
epoch [32/50] batch [100/245] time 0.097 (0.103) data 0.000 (0.003) loss 1.8842 (1.3417) teacher_loss 1.0656 (0.6012) loss_zs_kd 0.3081 (0.4004) loss_oracle 0.3183 (0.3485) acc 68.7500 (82.2188) kd_loss 0.6594 (0.5663) lr 6.9098e-04 eta 0:07:48
epoch [32/50] batch [120/245] time 0.094 (0.102) data 0.000 (0.003) loss 0.9019 (1.3444) teacher_loss 0.2146 (0.6086) loss_zs_kd 0.2954 (0.4057) loss_oracle 0.3331 (0.3466) acc 96.8750 (82.3698) kd_loss 0.5208 (0.5624) lr 6.9098e-04 eta 0:07:41
epoch [32/50] batch [140/245] time 0.092 (0.101) data 0.000 (0.002) loss 1.4468 (1.3364) teacher_loss 0.6574 (0.6020) loss_zs_kd 0.3259 (0.4034) loss_oracle 0.3851 (0.3473) acc 84.3750 (82.7009) kd_loss 0.5968 (0.5608) lr 6.9098e-04 eta 0:07:36
epoch [32/50] batch [160/245] time 0.096 (0.100) data 0.000 (0.002) loss 1.0891 (1.3307) teacher_loss 0.3823 (0.5952) loss_zs_kd 0.4269 (0.4022) loss_oracle 0.3439 (0.3497) acc 90.6250 (82.7734) kd_loss 0.5349 (0.5606) lr 6.9098e-04 eta 0:07:31
epoch [32/50] batch [180/245] time 0.099 (0.100) data 0.000 (0.002) loss 1.3685 (1.3399) teacher_loss 0.4676 (0.6068) loss_zs_kd 0.2433 (0.4058) loss_oracle 0.4182 (0.3492) acc 87.5000 (82.6389) kd_loss 0.6918 (0.5585) lr 6.9098e-04 eta 0:07:27
epoch [32/50] batch [200/245] time 0.094 (0.100) data 0.001 (0.002) loss 1.4159 (1.3426) teacher_loss 0.6817 (0.6089) loss_zs_kd 0.3268 (0.4079) loss_oracle 0.3620 (0.3490) acc 84.3750 (82.6875) kd_loss 0.5532 (0.5592) lr 6.9098e-04 eta 0:07:23
epoch [32/50] batch [220/245] time 0.100 (0.099) data 0.000 (0.002) loss 1.3984 (1.3514) teacher_loss 0.7363 (0.6204) loss_zs_kd 0.3808 (0.4064) loss_oracle 0.3137 (0.3489) acc 75.0000 (82.3011) kd_loss 0.5053 (0.5566) lr 6.9098e-04 eta 0:07:20
epoch [32/50] batch [240/245] time 0.087 (0.099) data 0.000 (0.001) loss 1.3362 (1.3521) teacher_loss 0.6501 (0.6230) loss_zs_kd 0.4472 (0.4082) loss_oracle 0.3598 (0.3488) acc 84.3750 (82.3047) kd_loss 0.5062 (0.5547) lr 6.9098e-04 eta 0:07:15
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,075
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,243
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 73.1%
******* Domain c best val acc:      91.9%, epoch: 26 *******
******* Domain c best val test acc: 74.2%, epoch: 26 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [33/50] batch [20/245] time 0.095 (0.108) data 0.000 (0.012) loss 0.9826 (1.3918) teacher_loss 0.2234 (0.6622) loss_zs_kd 0.3926 (0.4139) loss_oracle 0.3513 (0.3605) acc 93.7500 (82.0312) kd_loss 0.5836 (0.5494) lr 6.3188e-04 eta 0:07:53
epoch [33/50] batch [40/245] time 0.092 (0.101) data 0.000 (0.006) loss 1.2824 (1.3773) teacher_loss 0.6089 (0.6380) loss_zs_kd 0.3118 (0.4228) loss_oracle 0.3188 (0.3588) acc 84.3750 (82.2656) kd_loss 0.5141 (0.5599) lr 6.3188e-04 eta 0:07:21
epoch [33/50] batch [60/245] time 0.099 (0.099) data 0.000 (0.004) loss 1.8937 (1.4032) teacher_loss 0.9945 (0.6602) loss_zs_kd 0.5294 (0.4237) loss_oracle 0.4049 (0.3620) acc 71.8750 (81.5625) kd_loss 0.6967 (0.5620) lr 6.3188e-04 eta 0:07:12
epoch [33/50] batch [80/245] time 0.100 (0.102) data 0.000 (0.003) loss 1.3994 (1.3879) teacher_loss 0.5695 (0.6554) loss_zs_kd 0.3117 (0.4125) loss_oracle 0.3198 (0.3597) acc 84.3750 (81.4844) kd_loss 0.6701 (0.5526) lr 6.3188e-04 eta 0:07:20
epoch [33/50] batch [100/245] time 0.092 (0.101) data 0.000 (0.003) loss 1.1194 (1.3788) teacher_loss 0.3942 (0.6477) loss_zs_kd 0.3231 (0.4080) loss_oracle 0.3022 (0.3561) acc 90.6250 (81.8125) kd_loss 0.5741 (0.5531) lr 6.3188e-04 eta 0:07:14
epoch [33/50] batch [120/245] time 0.100 (0.100) data 0.000 (0.002) loss 1.3796 (1.3630) teacher_loss 0.6402 (0.6347) loss_zs_kd 0.3061 (0.4030) loss_oracle 0.4123 (0.3552) acc 78.1250 (82.3177) kd_loss 0.5333 (0.5507) lr 6.3188e-04 eta 0:07:09
epoch [33/50] batch [140/245] time 0.097 (0.100) data 0.000 (0.002) loss 0.9673 (1.3593) teacher_loss 0.3069 (0.6373) loss_zs_kd 0.2804 (0.4032) loss_oracle 0.3186 (0.3531) acc 90.6250 (82.0312) kd_loss 0.5011 (0.5454) lr 6.3188e-04 eta 0:07:06
epoch [33/50] batch [160/245] time 0.092 (0.100) data 0.000 (0.002) loss 0.9972 (1.3416) teacher_loss 0.2859 (0.6234) loss_zs_kd 0.3122 (0.4036) loss_oracle 0.3617 (0.3515) acc 93.7500 (82.4805) kd_loss 0.5305 (0.5425) lr 6.3188e-04 eta 0:07:03
epoch [33/50] batch [180/245] time 0.096 (0.100) data 0.000 (0.002) loss 1.4946 (1.3489) teacher_loss 0.7833 (0.6315) loss_zs_kd 0.4554 (0.4054) loss_oracle 0.3444 (0.3513) acc 84.3750 (82.3785) kd_loss 0.5390 (0.5419) lr 6.3188e-04 eta 0:07:00
epoch [33/50] batch [200/245] time 0.099 (0.099) data 0.000 (0.001) loss 1.2301 (1.3438) teacher_loss 0.5694 (0.6267) loss_zs_kd 0.3513 (0.4031) loss_oracle 0.3788 (0.3507) acc 81.2500 (82.5312) kd_loss 0.4713 (0.5418) lr 6.3188e-04 eta 0:06:58
epoch [33/50] batch [220/245] time 0.098 (0.099) data 0.000 (0.001) loss 1.5302 (1.3400) teacher_loss 0.8044 (0.6245) loss_zs_kd 0.3283 (0.4042) loss_oracle 0.2998 (0.3487) acc 75.0000 (82.6562) kd_loss 0.5759 (0.5412) lr 6.3188e-04 eta 0:06:56
epoch [33/50] batch [240/245] time 0.090 (0.099) data 0.000 (0.001) loss 1.0662 (1.3373) teacher_loss 0.3002 (0.6223) loss_zs_kd 0.2626 (0.4035) loss_oracle 0.3595 (0.3479) acc 90.6250 (82.7995) kd_loss 0.5862 (0.5411) lr 6.3188e-04 eta 0:06:52
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,069
* accuracy: 91.5%
* error: 8.5%
* macro_f1: 90.8%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,237
* accuracy: 74.2%
* error: 25.8%
* macro_f1: 73.0%
******* Domain c best val acc:      91.9%, epoch: 26 *******
******* Domain c best val test acc: 74.2%, epoch: 26 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [34/50] batch [20/245] time 0.092 (0.115) data 0.000 (0.015) loss 1.4108 (1.4028) teacher_loss 0.5420 (0.6548) loss_zs_kd 0.2623 (0.4278) loss_oracle 0.4405 (0.3547) acc 90.6250 (82.9688) kd_loss 0.6486 (0.5707) lr 5.7422e-04 eta 0:07:58
epoch [34/50] batch [40/245] time 0.095 (0.105) data 0.000 (0.007) loss 1.7590 (1.3969) teacher_loss 1.0896 (0.6699) loss_zs_kd 0.2577 (0.4341) loss_oracle 0.3403 (0.3560) acc 71.8750 (82.0312) kd_loss 0.4992 (0.5490) lr 5.7422e-04 eta 0:07:14
epoch [34/50] batch [60/245] time 0.095 (0.102) data 0.000 (0.005) loss 1.2598 (1.3720) teacher_loss 0.5029 (0.6391) loss_zs_kd 0.3263 (0.4204) loss_oracle 0.3266 (0.3551) acc 84.3750 (82.0833) kd_loss 0.5936 (0.5553) lr 5.7422e-04 eta 0:06:58
epoch [34/50] batch [80/245] time 0.093 (0.100) data 0.000 (0.004) loss 1.2986 (1.3573) teacher_loss 0.5163 (0.6214) loss_zs_kd 0.3527 (0.4215) loss_oracle 0.3787 (0.3534) acc 90.6250 (82.8906) kd_loss 0.5930 (0.5592) lr 5.7422e-04 eta 0:06:50
epoch [34/50] batch [100/245] time 0.096 (0.102) data 0.000 (0.003) loss 1.2378 (1.3460) teacher_loss 0.5734 (0.6084) loss_zs_kd 0.3275 (0.4162) loss_oracle 0.3731 (0.3529) acc 90.6250 (83.1250) kd_loss 0.4779 (0.5611) lr 5.7422e-04 eta 0:06:54
epoch [34/50] batch [120/245] time 0.092 (0.101) data 0.000 (0.003) loss 1.3809 (1.3557) teacher_loss 0.6806 (0.6170) loss_zs_kd 0.3551 (0.4104) loss_oracle 0.3373 (0.3525) acc 81.2500 (82.9167) kd_loss 0.5317 (0.5624) lr 5.7422e-04 eta 0:06:48
epoch [34/50] batch [140/245] time 0.091 (0.100) data 0.000 (0.002) loss 1.2906 (1.3496) teacher_loss 0.5716 (0.6151) loss_zs_kd 0.4211 (0.4109) loss_oracle 0.3423 (0.3534) acc 87.5000 (82.8348) kd_loss 0.5478 (0.5578) lr 5.7422e-04 eta 0:06:42
epoch [34/50] batch [160/245] time 0.099 (0.100) data 0.000 (0.002) loss 1.1659 (1.3450) teacher_loss 0.4455 (0.6133) loss_zs_kd 0.3451 (0.4072) loss_oracle 0.3712 (0.3543) acc 81.2500 (82.6758) kd_loss 0.5349 (0.5545) lr 5.7422e-04 eta 0:06:38
epoch [34/50] batch [180/245] time 0.101 (0.099) data 0.000 (0.002) loss 1.3376 (1.3461) teacher_loss 0.5529 (0.6164) loss_zs_kd 0.2754 (0.4072) loss_oracle 0.3851 (0.3542) acc 84.3750 (82.7083) kd_loss 0.5922 (0.5526) lr 5.7422e-04 eta 0:06:34
epoch [34/50] batch [200/245] time 0.100 (0.099) data 0.000 (0.002) loss 1.1768 (1.3431) teacher_loss 0.5107 (0.6157) loss_zs_kd 0.3878 (0.4059) loss_oracle 0.3095 (0.3544) acc 90.6250 (82.7500) kd_loss 0.5114 (0.5502) lr 5.7422e-04 eta 0:06:31
epoch [34/50] batch [220/245] time 0.093 (0.099) data 0.000 (0.002) loss 1.4068 (1.3395) teacher_loss 0.7203 (0.6134) loss_zs_kd 0.4487 (0.4075) loss_oracle 0.3609 (0.3549) acc 75.0000 (82.8267) kd_loss 0.5061 (0.5487) lr 5.7422e-04 eta 0:06:28
epoch [34/50] batch [240/245] time 0.088 (0.098) data 0.000 (0.001) loss 1.5586 (1.3444) teacher_loss 0.7931 (0.6193) loss_zs_kd 0.5237 (0.4126) loss_oracle 0.4173 (0.3554) acc 75.0000 (82.7604) kd_loss 0.5568 (0.5474) lr 5.7422e-04 eta 0:06:24
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,069
* accuracy: 91.5%
* error: 8.5%
* macro_f1: 90.7%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,253
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.3%
******* Domain c best val acc:      91.9%, epoch: 26 *******
******* Domain c best val test acc: 74.2%, epoch: 26 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [35/50] batch [20/245] time 0.094 (0.109) data 0.000 (0.013) loss 1.1613 (1.3480) teacher_loss 0.3848 (0.6262) loss_zs_kd 0.3114 (0.4189) loss_oracle 0.4016 (0.3706) acc 90.6250 (83.9062) kd_loss 0.5757 (0.5365) lr 5.1825e-04 eta 0:07:03
epoch [35/50] batch [40/245] time 0.093 (0.100) data 0.000 (0.007) loss 1.3588 (1.3474) teacher_loss 0.6677 (0.6340) loss_zs_kd 0.3636 (0.4168) loss_oracle 0.3647 (0.3723) acc 81.2500 (82.1875) kd_loss 0.5088 (0.5272) lr 5.1825e-04 eta 0:06:29
epoch [35/50] batch [60/245] time 0.085 (0.097) data 0.000 (0.005) loss 1.3612 (1.3440) teacher_loss 0.6097 (0.6263) loss_zs_kd 0.3980 (0.4236) loss_oracle 0.3186 (0.3712) acc 81.2500 (82.2917) kd_loss 0.5922 (0.5321) lr 5.1825e-04 eta 0:06:15
epoch [35/50] batch [80/245] time 0.097 (0.096) data 0.000 (0.003) loss 1.3647 (1.3449) teacher_loss 0.6391 (0.6270) loss_zs_kd 0.5276 (0.4167) loss_oracle 0.3968 (0.3711) acc 90.6250 (82.2266) kd_loss 0.5272 (0.5323) lr 5.1825e-04 eta 0:06:10
epoch [35/50] batch [100/245] time 0.090 (0.096) data 0.000 (0.003) loss 1.4044 (1.3658) teacher_loss 0.7095 (0.6428) loss_zs_kd 0.2458 (0.4173) loss_oracle 0.3776 (0.3705) acc 81.2500 (81.7812) kd_loss 0.5061 (0.5377) lr 5.1825e-04 eta 0:06:05
epoch [35/50] batch [120/245] time 0.132 (0.097) data 0.001 (0.002) loss 1.2684 (1.3635) teacher_loss 0.4846 (0.6371) loss_zs_kd 0.4678 (0.4195) loss_oracle 0.3569 (0.3716) acc 87.5000 (81.8490) kd_loss 0.6053 (0.5406) lr 5.1825e-04 eta 0:06:09
epoch [35/50] batch [140/245] time 0.098 (0.096) data 0.000 (0.002) loss 0.9232 (1.3736) teacher_loss 0.2661 (0.6442) loss_zs_kd 0.3109 (0.4233) loss_oracle 0.3828 (0.3716) acc 93.7500 (81.7411) kd_loss 0.4657 (0.5436) lr 5.1825e-04 eta 0:06:04
epoch [35/50] batch [160/245] time 0.094 (0.096) data 0.000 (0.002) loss 1.5219 (1.3700) teacher_loss 0.5679 (0.6354) loss_zs_kd 0.3731 (0.4202) loss_oracle 0.3917 (0.3720) acc 81.2500 (82.0312) kd_loss 0.7582 (0.5486) lr 5.1825e-04 eta 0:06:00
epoch [35/50] batch [180/245] time 0.089 (0.096) data 0.000 (0.002) loss 1.5560 (1.3660) teacher_loss 0.8070 (0.6282) loss_zs_kd 0.5281 (0.4187) loss_oracle 0.3604 (0.3733) acc 71.8750 (82.1181) kd_loss 0.5688 (0.5511) lr 5.1825e-04 eta 0:05:57
epoch [35/50] batch [200/245] time 0.097 (0.095) data 0.000 (0.002) loss 1.6512 (1.3680) teacher_loss 0.8859 (0.6306) loss_zs_kd 0.2611 (0.4199) loss_oracle 0.3611 (0.3732) acc 75.0000 (82.1875) kd_loss 0.5847 (0.5508) lr 5.1825e-04 eta 0:05:54
epoch [35/50] batch [220/245] time 0.088 (0.095) data 0.000 (0.001) loss 1.1601 (1.3573) teacher_loss 0.4621 (0.6222) loss_zs_kd 0.3680 (0.4201) loss_oracle 0.3794 (0.3737) acc 87.5000 (82.3438) kd_loss 0.5082 (0.5483) lr 5.1825e-04 eta 0:05:51
epoch [35/50] batch [240/245] time 0.087 (0.095) data 0.000 (0.001) loss 0.9146 (1.3578) teacher_loss 0.2336 (0.6220) loss_zs_kd 0.3755 (0.4223) loss_oracle 0.3719 (0.3746) acc 93.7500 (82.3568) kd_loss 0.4950 (0.5485) lr 5.1825e-04 eta 0:05:48
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,074
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 90.9%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,243
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 73.0%
******* Domain c best val acc:      91.9%, epoch: 26 *******
******* Domain c best val test acc: 74.2%, epoch: 26 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [36/50] batch [20/245] time 0.098 (0.116) data 0.000 (0.014) loss 1.3073 (1.3535) teacher_loss 0.5641 (0.6066) loss_zs_kd 0.4646 (0.4596) loss_oracle 0.3698 (0.3845) acc 87.5000 (82.6562) kd_loss 0.5583 (0.5547) lr 4.6417e-04 eta 0:07:05
epoch [36/50] batch [40/245] time 0.092 (0.106) data 0.000 (0.007) loss 1.2450 (1.3574) teacher_loss 0.5509 (0.6166) loss_zs_kd 0.3233 (0.4335) loss_oracle 0.3435 (0.3763) acc 90.6250 (82.2656) kd_loss 0.5223 (0.5526) lr 4.6417e-04 eta 0:06:26
epoch [36/50] batch [60/245] time 0.096 (0.102) data 0.000 (0.005) loss 1.2108 (1.3477) teacher_loss 0.4529 (0.6126) loss_zs_kd 0.3287 (0.4154) loss_oracle 0.3998 (0.3756) acc 87.5000 (82.3958) kd_loss 0.5580 (0.5473) lr 4.6417e-04 eta 0:06:10
epoch [36/50] batch [80/245] time 0.090 (0.101) data 0.000 (0.004) loss 0.9809 (1.3327) teacher_loss 0.2639 (0.5991) loss_zs_kd 0.4132 (0.4148) loss_oracle 0.3868 (0.3759) acc 93.7500 (82.7344) kd_loss 0.5236 (0.5456) lr 4.6417e-04 eta 0:06:02
epoch [36/50] batch [100/245] time 0.095 (0.100) data 0.000 (0.003) loss 1.2480 (1.3341) teacher_loss 0.5852 (0.6039) loss_zs_kd 0.5993 (0.4099) loss_oracle 0.3375 (0.3734) acc 87.5000 (82.6875) kd_loss 0.4940 (0.5434) lr 4.6417e-04 eta 0:05:58
epoch [36/50] batch [120/245] time 0.093 (0.099) data 0.000 (0.003) loss 1.1972 (1.3386) teacher_loss 0.4535 (0.6055) loss_zs_kd 0.4616 (0.4102) loss_oracle 0.3384 (0.3716) acc 90.6250 (82.6823) kd_loss 0.5746 (0.5473) lr 4.6417e-04 eta 0:05:53
epoch [36/50] batch [140/245] time 0.091 (0.099) data 0.000 (0.002) loss 1.6210 (1.3523) teacher_loss 0.7503 (0.6159) loss_zs_kd 0.4594 (0.4116) loss_oracle 0.3624 (0.3721) acc 65.6250 (82.5000) kd_loss 0.6895 (0.5503) lr 4.6417e-04 eta 0:05:48
epoch [36/50] batch [160/245] time 0.103 (0.100) data 0.000 (0.002) loss 1.0901 (1.3463) teacher_loss 0.3576 (0.6112) loss_zs_kd 0.2334 (0.4099) loss_oracle 0.3348 (0.3707) acc 93.7500 (82.8125) kd_loss 0.5651 (0.5497) lr 4.6417e-04 eta 0:05:52
epoch [36/50] batch [180/245] time 0.098 (0.100) data 0.000 (0.002) loss 1.1081 (1.3432) teacher_loss 0.4052 (0.6104) loss_zs_kd 0.2700 (0.4075) loss_oracle 0.3631 (0.3705) acc 87.5000 (82.8819) kd_loss 0.5213 (0.5475) lr 4.6417e-04 eta 0:05:49
epoch [36/50] batch [200/245] time 0.098 (0.100) data 0.000 (0.002) loss 1.0723 (1.3372) teacher_loss 0.4385 (0.6054) loss_zs_kd 0.5093 (0.4107) loss_oracle 0.3590 (0.3710) acc 87.5000 (83.0000) kd_loss 0.4543 (0.5463) lr 4.6417e-04 eta 0:05:47
epoch [36/50] batch [220/245] time 0.098 (0.100) data 0.000 (0.001) loss 1.3771 (1.3325) teacher_loss 0.5613 (0.5994) loss_zs_kd 0.3431 (0.4156) loss_oracle 0.3210 (0.3706) acc 84.3750 (83.2812) kd_loss 0.6552 (0.5478) lr 4.6417e-04 eta 0:05:44
epoch [36/50] batch [240/245] time 0.087 (0.099) data 0.000 (0.001) loss 1.7560 (1.3326) teacher_loss 0.9092 (0.5990) loss_zs_kd 0.3053 (0.4162) loss_oracle 0.3804 (0.3700) acc 71.8750 (83.2161) kd_loss 0.6566 (0.5486) lr 4.6417e-04 eta 0:05:39
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,069
* accuracy: 91.5%
* error: 8.5%
* macro_f1: 90.7%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,249
* accuracy: 74.4%
* error: 25.6%
* macro_f1: 73.2%
******* Domain c best val acc:      91.9%, epoch: 26 *******
******* Domain c best val test acc: 74.2%, epoch: 26 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [37/50] batch [20/245] time 0.092 (0.111) data 0.000 (0.013) loss 1.7236 (1.3278) teacher_loss 0.8429 (0.6033) loss_zs_kd 0.4429 (0.4186) loss_oracle 0.4261 (0.3664) acc 68.7500 (83.4375) kd_loss 0.6677 (0.5412) lr 4.1221e-04 eta 0:06:18
epoch [37/50] batch [40/245] time 0.105 (0.105) data 0.000 (0.006) loss 1.3384 (1.3257) teacher_loss 0.5954 (0.5910) loss_zs_kd 0.4158 (0.4430) loss_oracle 0.3737 (0.3674) acc 84.3750 (83.3594) kd_loss 0.5562 (0.5510) lr 4.1221e-04 eta 0:05:55
epoch [37/50] batch [60/245] time 0.093 (0.102) data 0.000 (0.004) loss 1.0973 (1.3635) teacher_loss 0.3746 (0.6237) loss_zs_kd 0.3496 (0.4266) loss_oracle 0.3513 (0.3709) acc 90.6250 (82.5000) kd_loss 0.5471 (0.5544) lr 4.1221e-04 eta 0:05:42
epoch [37/50] batch [80/245] time 0.097 (0.101) data 0.000 (0.003) loss 1.1265 (1.3677) teacher_loss 0.4543 (0.6224) loss_zs_kd 0.4446 (0.4288) loss_oracle 0.3354 (0.3724) acc 87.5000 (82.7344) kd_loss 0.5045 (0.5591) lr 4.1221e-04 eta 0:05:37
epoch [37/50] batch [100/245] time 0.103 (0.100) data 0.000 (0.003) loss 1.6787 (1.3662) teacher_loss 0.8880 (0.6193) loss_zs_kd 0.5593 (0.4297) loss_oracle 0.4035 (0.3741) acc 75.0000 (82.5625) kd_loss 0.5889 (0.5599) lr 4.1221e-04 eta 0:05:31
epoch [37/50] batch [120/245] time 0.091 (0.099) data 0.000 (0.002) loss 1.4817 (1.3736) teacher_loss 0.7576 (0.6262) loss_zs_kd 0.3453 (0.4313) loss_oracle 0.3477 (0.3744) acc 75.0000 (82.3438) kd_loss 0.5503 (0.5603) lr 4.1221e-04 eta 0:05:27
epoch [37/50] batch [140/245] time 0.091 (0.099) data 0.000 (0.002) loss 1.4349 (1.3754) teacher_loss 0.5829 (0.6274) loss_zs_kd 0.2976 (0.4252) loss_oracle 0.3707 (0.3755) acc 78.1250 (82.3884) kd_loss 0.6666 (0.5603) lr 4.1221e-04 eta 0:05:24
epoch [37/50] batch [160/245] time 0.093 (0.098) data 0.000 (0.002) loss 1.7851 (1.3789) teacher_loss 0.9189 (0.6336) loss_zs_kd 0.4489 (0.4271) loss_oracle 0.4104 (0.3741) acc 71.8750 (82.1680) kd_loss 0.6610 (0.5583) lr 4.1221e-04 eta 0:05:20
epoch [37/50] batch [180/245] time 0.101 (0.099) data 0.000 (0.002) loss 1.3900 (1.3761) teacher_loss 0.6339 (0.6265) loss_zs_kd 0.4283 (0.4237) loss_oracle 0.3522 (0.3748) acc 81.2500 (82.4306) kd_loss 0.5800 (0.5622) lr 4.1221e-04 eta 0:05:23
epoch [37/50] batch [200/245] time 0.092 (0.099) data 0.000 (0.001) loss 1.3796 (1.3770) teacher_loss 0.6491 (0.6296) loss_zs_kd 0.4351 (0.4245) loss_oracle 0.3558 (0.3744) acc 81.2500 (82.4062) kd_loss 0.5525 (0.5601) lr 4.1221e-04 eta 0:05:20
epoch [37/50] batch [220/245] time 0.100 (0.099) data 0.000 (0.001) loss 1.3751 (1.3756) teacher_loss 0.6308 (0.6291) loss_zs_kd 0.3622 (0.4224) loss_oracle 0.3622 (0.3747) acc 81.2500 (82.3438) kd_loss 0.5631 (0.5592) lr 4.1221e-04 eta 0:05:17
epoch [37/50] batch [240/245] time 0.111 (0.099) data 0.000 (0.001) loss 1.2772 (1.3704) teacher_loss 0.4853 (0.6233) loss_zs_kd 0.5017 (0.4227) loss_oracle 0.3686 (0.3749) acc 87.5000 (82.5521) kd_loss 0.6077 (0.5597) lr 4.1221e-04 eta 0:05:14
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,081
* accuracy: 91.9%
* error: 8.1%
* macro_f1: 91.1%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,239
* accuracy: 74.2%
* error: 25.8%
* macro_f1: 73.0%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [38/50] batch [20/245] time 0.103 (0.124) data 0.000 (0.016) loss 1.3478 (1.3597) teacher_loss 0.5403 (0.6220) loss_zs_kd 0.4526 (0.4389) loss_oracle 0.3411 (0.3697) acc 81.2500 (82.1875) kd_loss 0.6369 (0.5529) lr 3.6258e-04 eta 0:06:33
epoch [38/50] batch [40/245] time 0.084 (0.109) data 0.000 (0.008) loss 1.1504 (1.3449) teacher_loss 0.3947 (0.6021) loss_zs_kd 0.5395 (0.4264) loss_oracle 0.3321 (0.3667) acc 90.6250 (83.5938) kd_loss 0.5897 (0.5594) lr 3.6258e-04 eta 0:05:41
epoch [38/50] batch [60/245] time 0.093 (0.103) data 0.000 (0.006) loss 1.4888 (1.3637) teacher_loss 0.7632 (0.6209) loss_zs_kd 0.4560 (0.4212) loss_oracle 0.4124 (0.3716) acc 84.3750 (83.0208) kd_loss 0.5194 (0.5570) lr 3.6258e-04 eta 0:05:22
epoch [38/50] batch [80/245] time 0.083 (0.100) data 0.000 (0.004) loss 1.2255 (1.3651) teacher_loss 0.4342 (0.6240) loss_zs_kd 0.3900 (0.4133) loss_oracle 0.3343 (0.3737) acc 81.2500 (83.1641) kd_loss 0.6242 (0.5543) lr 3.6258e-04 eta 0:05:09
epoch [38/50] batch [100/245] time 0.094 (0.098) data 0.000 (0.003) loss 1.6350 (1.3756) teacher_loss 0.7571 (0.6381) loss_zs_kd 0.4483 (0.4132) loss_oracle 0.3663 (0.3714) acc 78.1250 (82.6562) kd_loss 0.6947 (0.5517) lr 3.6258e-04 eta 0:05:03
epoch [38/50] batch [120/245] time 0.086 (0.097) data 0.000 (0.003) loss 1.4367 (1.3735) teacher_loss 0.6823 (0.6291) loss_zs_kd 0.3903 (0.4130) loss_oracle 0.3688 (0.3728) acc 81.2500 (82.9948) kd_loss 0.5701 (0.5580) lr 3.6258e-04 eta 0:04:57
epoch [38/50] batch [140/245] time 0.090 (0.096) data 0.000 (0.003) loss 1.7559 (1.3691) teacher_loss 0.8116 (0.6253) loss_zs_kd 0.5763 (0.4138) loss_oracle 0.4269 (0.3749) acc 78.1250 (82.9688) kd_loss 0.7309 (0.5564) lr 3.6258e-04 eta 0:04:53
epoch [38/50] batch [160/245] time 0.089 (0.096) data 0.000 (0.002) loss 1.4404 (1.3728) teacher_loss 0.7185 (0.6268) loss_zs_kd 0.5281 (0.4151) loss_oracle 0.3896 (0.3750) acc 81.2500 (82.7734) kd_loss 0.5270 (0.5585) lr 3.6258e-04 eta 0:04:49
epoch [38/50] batch [180/245] time 0.091 (0.095) data 0.000 (0.002) loss 1.5898 (1.3689) teacher_loss 0.6831 (0.6217) loss_zs_kd 0.3143 (0.4138) loss_oracle 0.4166 (0.3769) acc 84.3750 (82.8993) kd_loss 0.6984 (0.5587) lr 3.6258e-04 eta 0:04:46
epoch [38/50] batch [200/245] time 0.099 (0.096) data 0.000 (0.002) loss 1.3190 (1.3712) teacher_loss 0.5688 (0.6237) loss_zs_kd 0.6704 (0.4127) loss_oracle 0.3991 (0.3761) acc 81.2500 (82.7969) kd_loss 0.5506 (0.5594) lr 3.6258e-04 eta 0:04:46
epoch [38/50] batch [220/245] time 0.091 (0.096) data 0.000 (0.002) loss 1.9542 (1.3782) teacher_loss 1.1777 (0.6322) loss_zs_kd 0.4361 (0.4130) loss_oracle 0.4036 (0.3759) acc 75.0000 (82.7273) kd_loss 0.5747 (0.5581) lr 3.6258e-04 eta 0:04:44
epoch [38/50] batch [240/245] time 0.085 (0.095) data 0.000 (0.002) loss 1.1016 (1.3751) teacher_loss 0.4134 (0.6290) loss_zs_kd 0.2829 (0.4117) loss_oracle 0.3416 (0.3738) acc 90.6250 (82.7865) kd_loss 0.5175 (0.5592) lr 3.6258e-04 eta 0:04:40
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,071
* accuracy: 91.6%
* error: 8.4%
* macro_f1: 90.8%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,245
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 73.2%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [39/50] batch [20/245] time 0.121 (0.136) data 0.000 (0.021) loss 1.1162 (1.2888) teacher_loss 0.2957 (0.5305) loss_zs_kd 0.3930 (0.3943) loss_oracle 0.3452 (0.3665) acc 90.6250 (85.9375) kd_loss 0.6479 (0.5751) lr 3.1545e-04 eta 0:06:38
epoch [39/50] batch [40/245] time 0.109 (0.123) data 0.001 (0.011) loss 1.5466 (1.3503) teacher_loss 0.6737 (0.5909) loss_zs_kd 0.3198 (0.4072) loss_oracle 0.3715 (0.3681) acc 84.3750 (84.4531) kd_loss 0.6872 (0.5754) lr 3.1545e-04 eta 0:05:55
epoch [39/50] batch [60/245] time 0.101 (0.116) data 0.000 (0.007) loss 1.7078 (1.3347) teacher_loss 0.9138 (0.5780) loss_zs_kd 0.4119 (0.4090) loss_oracle 0.4092 (0.3683) acc 71.8750 (84.0104) kd_loss 0.5894 (0.5726) lr 3.1545e-04 eta 0:05:32
epoch [39/50] batch [80/245] time 0.098 (0.112) data 0.001 (0.005) loss 1.0780 (1.3585) teacher_loss 0.4341 (0.6120) loss_zs_kd 0.2132 (0.4105) loss_oracle 0.3719 (0.3669) acc 87.5000 (83.1641) kd_loss 0.4579 (0.5631) lr 3.1545e-04 eta 0:05:19
epoch [39/50] batch [100/245] time 0.101 (0.110) data 0.000 (0.004) loss 1.0982 (1.3772) teacher_loss 0.3195 (0.6272) loss_zs_kd 0.4644 (0.4116) loss_oracle 0.4000 (0.3705) acc 93.7500 (82.9688) kd_loss 0.5786 (0.5647) lr 3.1545e-04 eta 0:05:12
epoch [39/50] batch [120/245] time 0.096 (0.109) data 0.000 (0.004) loss 1.2082 (1.3768) teacher_loss 0.3364 (0.6244) loss_zs_kd 0.3143 (0.4096) loss_oracle 0.3604 (0.3708) acc 90.6250 (82.9167) kd_loss 0.6917 (0.5670) lr 3.1545e-04 eta 0:05:07
epoch [39/50] batch [140/245] time 0.109 (0.108) data 0.000 (0.003) loss 1.6920 (1.3772) teacher_loss 0.9934 (0.6270) loss_zs_kd 0.4083 (0.4117) loss_oracle 0.3910 (0.3703) acc 68.7500 (82.4330) kd_loss 0.5030 (0.5650) lr 3.1545e-04 eta 0:05:02
epoch [39/50] batch [160/245] time 0.097 (0.107) data 0.000 (0.003) loss 1.3812 (1.3718) teacher_loss 0.6512 (0.6217) loss_zs_kd 0.2668 (0.4134) loss_oracle 0.3717 (0.3690) acc 81.2500 (82.5781) kd_loss 0.5442 (0.5656) lr 3.1545e-04 eta 0:04:56
epoch [39/50] batch [180/245] time 0.095 (0.105) data 0.000 (0.003) loss 0.9795 (1.3779) teacher_loss 0.1707 (0.6275) loss_zs_kd 0.3128 (0.4128) loss_oracle 0.3491 (0.3671) acc 93.7500 (82.6389) kd_loss 0.6343 (0.5668) lr 3.1545e-04 eta 0:04:51
epoch [39/50] batch [200/245] time 0.092 (0.106) data 0.000 (0.002) loss 1.2588 (1.3940) teacher_loss 0.5214 (0.6447) loss_zs_kd 0.5180 (0.4161) loss_oracle 0.3339 (0.3642) acc 87.5000 (82.2188) kd_loss 0.5705 (0.5672) lr 3.1545e-04 eta 0:04:50
epoch [39/50] batch [220/245] time 0.099 (0.105) data 0.000 (0.002) loss 1.2175 (1.3853) teacher_loss 0.4318 (0.6361) loss_zs_kd 0.4703 (0.4146) loss_oracle 0.3463 (0.3636) acc 87.5000 (82.4432) kd_loss 0.6126 (0.5674) lr 3.1545e-04 eta 0:04:46
epoch [39/50] batch [240/245] time 0.090 (0.104) data 0.000 (0.002) loss 1.1096 (1.3895) teacher_loss 0.4206 (0.6410) loss_zs_kd 0.3322 (0.4129) loss_oracle 0.3027 (0.3634) acc 84.3750 (82.3828) kd_loss 0.5376 (0.5668) lr 3.1545e-04 eta 0:04:41
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,076
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,240
* accuracy: 74.2%
* error: 25.8%
* macro_f1: 73.1%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [40/50] batch [20/245] time 0.098 (0.116) data 0.000 (0.015) loss 1.4160 (1.3531) teacher_loss 0.5910 (0.6182) loss_zs_kd 0.5882 (0.3641) loss_oracle 0.3574 (0.3611) acc 84.3750 (82.0312) kd_loss 0.6463 (0.5543) lr 2.7103e-04 eta 0:05:09
epoch [40/50] batch [40/245] time 0.095 (0.107) data 0.000 (0.007) loss 1.3100 (1.3265) teacher_loss 0.5421 (0.5853) loss_zs_kd 0.3779 (0.3946) loss_oracle 0.3509 (0.3624) acc 84.3750 (82.8906) kd_loss 0.5924 (0.5600) lr 2.7103e-04 eta 0:04:42
epoch [40/50] batch [60/245] time 0.097 (0.103) data 0.000 (0.005) loss 1.4876 (1.3670) teacher_loss 0.7534 (0.6280) loss_zs_kd 0.5349 (0.4033) loss_oracle 0.3083 (0.3602) acc 90.6250 (81.7708) kd_loss 0.5801 (0.5590) lr 2.7103e-04 eta 0:04:31
epoch [40/50] batch [80/245] time 0.099 (0.102) data 0.000 (0.004) loss 0.9367 (1.3422) teacher_loss 0.1872 (0.6071) loss_zs_kd 0.4891 (0.4029) loss_oracle 0.3472 (0.3585) acc 96.8750 (82.8125) kd_loss 0.5759 (0.5558) lr 2.7103e-04 eta 0:04:25
epoch [40/50] batch [100/245] time 0.097 (0.101) data 0.000 (0.003) loss 1.3534 (1.3434) teacher_loss 0.6163 (0.6105) loss_zs_kd 0.2924 (0.4096) loss_oracle 0.3506 (0.3595) acc 84.3750 (82.5938) kd_loss 0.5619 (0.5531) lr 2.7103e-04 eta 0:04:23
epoch [40/50] batch [120/245] time 0.100 (0.101) data 0.000 (0.003) loss 1.3800 (1.3554) teacher_loss 0.5811 (0.6153) loss_zs_kd 0.4406 (0.4124) loss_oracle 0.3547 (0.3599) acc 87.5000 (82.6042) kd_loss 0.6216 (0.5602) lr 2.7103e-04 eta 0:04:20
epoch [40/50] batch [140/245] time 0.092 (0.100) data 0.000 (0.002) loss 1.2884 (1.3577) teacher_loss 0.5475 (0.6156) loss_zs_kd 0.4196 (0.4175) loss_oracle 0.3908 (0.3610) acc 84.3750 (82.7009) kd_loss 0.5455 (0.5616) lr 2.7103e-04 eta 0:04:16
epoch [40/50] batch [160/245] time 0.091 (0.100) data 0.000 (0.002) loss 1.6393 (1.3639) teacher_loss 0.8320 (0.6244) loss_zs_kd 0.3966 (0.4139) loss_oracle 0.3875 (0.3613) acc 68.7500 (82.3047) kd_loss 0.6136 (0.5589) lr 2.7103e-04 eta 0:04:12
epoch [40/50] batch [180/245] time 0.094 (0.099) data 0.000 (0.002) loss 1.2010 (1.3676) teacher_loss 0.5189 (0.6268) loss_zs_kd 0.2701 (0.4138) loss_oracle 0.3907 (0.3627) acc 87.5000 (82.1354) kd_loss 0.4867 (0.5594) lr 2.7103e-04 eta 0:04:09
epoch [40/50] batch [200/245] time 0.085 (0.099) data 0.000 (0.002) loss 1.2921 (1.3797) teacher_loss 0.5451 (0.6386) loss_zs_kd 0.2639 (0.4153) loss_oracle 0.3896 (0.3633) acc 81.2500 (81.7969) kd_loss 0.5522 (0.5595) lr 2.7103e-04 eta 0:04:06
epoch [40/50] batch [220/245] time 0.098 (0.099) data 0.000 (0.002) loss 1.3895 (1.3730) teacher_loss 0.5569 (0.6321) loss_zs_kd 0.3766 (0.4124) loss_oracle 0.3263 (0.3633) acc 84.3750 (81.8892) kd_loss 0.6694 (0.5592) lr 2.7103e-04 eta 0:04:05
epoch [40/50] batch [240/245] time 0.108 (0.100) data 0.000 (0.001) loss 1.1055 (1.3709) teacher_loss 0.3996 (0.6303) loss_zs_kd 0.7003 (0.4160) loss_oracle 0.3280 (0.3638) acc 90.6250 (81.9531) kd_loss 0.5419 (0.5587) lr 2.7103e-04 eta 0:04:04
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,079
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 91.1%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,243
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 73.2%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [41/50] batch [20/245] time 0.100 (0.111) data 0.000 (0.013) loss 1.7256 (1.3590) teacher_loss 1.0082 (0.6137) loss_zs_kd 0.4595 (0.4543) loss_oracle 0.3574 (0.3586) acc 78.1250 (83.2812) kd_loss 0.5388 (0.5660) lr 2.2949e-04 eta 0:04:30
epoch [41/50] batch [40/245] time 0.090 (0.102) data 0.000 (0.006) loss 1.7455 (1.3784) teacher_loss 0.8666 (0.6307) loss_zs_kd 0.5076 (0.4348) loss_oracle 0.3790 (0.3630) acc 75.0000 (82.5781) kd_loss 0.6894 (0.5662) lr 2.2949e-04 eta 0:04:05
epoch [41/50] batch [60/245] time 0.103 (0.100) data 0.000 (0.004) loss 1.3093 (1.3838) teacher_loss 0.5474 (0.6415) loss_zs_kd 0.3077 (0.4187) loss_oracle 0.3601 (0.3636) acc 78.1250 (82.1354) kd_loss 0.5818 (0.5605) lr 2.2949e-04 eta 0:03:58
epoch [41/50] batch [80/245] time 0.094 (0.098) data 0.000 (0.003) loss 1.0947 (1.3740) teacher_loss 0.4250 (0.6363) loss_zs_kd 0.3312 (0.4214) loss_oracle 0.3312 (0.3639) acc 84.3750 (82.1875) kd_loss 0.5040 (0.5557) lr 2.2949e-04 eta 0:03:51
epoch [41/50] batch [100/245] time 0.100 (0.097) data 0.000 (0.003) loss 1.5987 (1.3734) teacher_loss 0.6503 (0.6328) loss_zs_kd 0.3012 (0.4270) loss_oracle 0.4019 (0.3655) acc 78.1250 (82.1875) kd_loss 0.7475 (0.5577) lr 2.2949e-04 eta 0:03:48
epoch [41/50] batch [120/245] time 0.106 (0.097) data 0.000 (0.002) loss 2.2214 (1.3635) teacher_loss 1.4175 (0.6244) loss_zs_kd 0.6403 (0.4300) loss_oracle 0.4041 (0.3632) acc 56.2500 (82.4219) kd_loss 0.6019 (0.5575) lr 2.2949e-04 eta 0:03:46
epoch [41/50] batch [140/245] time 0.097 (0.098) data 0.000 (0.002) loss 1.1913 (1.3548) teacher_loss 0.3898 (0.6149) loss_zs_kd 0.3250 (0.4273) loss_oracle 0.3450 (0.3607) acc 90.6250 (82.7009) kd_loss 0.6289 (0.5596) lr 2.2949e-04 eta 0:03:45
epoch [41/50] batch [160/245] time 0.100 (0.097) data 0.000 (0.002) loss 1.0257 (1.3559) teacher_loss 0.4170 (0.6147) loss_zs_kd 0.4281 (0.4299) loss_oracle 0.3483 (0.3599) acc 81.2500 (82.7344) kd_loss 0.4346 (0.5613) lr 2.2949e-04 eta 0:03:42
epoch [41/50] batch [180/245] time 0.102 (0.097) data 0.000 (0.002) loss 1.0831 (1.3528) teacher_loss 0.3629 (0.6112) loss_zs_kd 0.3646 (0.4269) loss_oracle 0.3310 (0.3584) acc 90.6250 (82.8472) kd_loss 0.5547 (0.5624) lr 2.2949e-04 eta 0:03:41
epoch [41/50] batch [200/245] time 0.095 (0.097) data 0.000 (0.001) loss 0.9483 (1.3467) teacher_loss 0.3285 (0.6051) loss_zs_kd 0.5419 (0.4265) loss_oracle 0.3470 (0.3578) acc 90.6250 (83.0469) kd_loss 0.4463 (0.5628) lr 2.2949e-04 eta 0:03:39
epoch [41/50] batch [220/245] time 0.099 (0.097) data 0.000 (0.001) loss 1.4466 (1.3420) teacher_loss 0.6307 (0.6005) loss_zs_kd 0.5017 (0.4274) loss_oracle 0.3647 (0.3572) acc 84.3750 (83.1108) kd_loss 0.6336 (0.5629) lr 2.2949e-04 eta 0:03:37
epoch [41/50] batch [240/245] time 0.106 (0.098) data 0.000 (0.001) loss 1.0201 (1.3500) teacher_loss 0.3338 (0.6079) loss_zs_kd 0.2942 (0.4280) loss_oracle 0.3536 (0.3587) acc 90.6250 (82.8516) kd_loss 0.5095 (0.5628) lr 2.2949e-04 eta 0:03:37
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,079
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 91.1%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,259
* accuracy: 74.7%
* error: 25.3%
* macro_f1: 73.4%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [42/50] batch [20/245] time 0.114 (0.123) data 0.000 (0.017) loss 1.1082 (1.3452) teacher_loss 0.3891 (0.5889) loss_zs_kd 0.3598 (0.4122) loss_oracle 0.3587 (0.3635) acc 84.3750 (83.7500) kd_loss 0.5398 (0.5745) lr 1.9098e-04 eta 0:04:29
epoch [42/50] batch [40/245] time 0.110 (0.112) data 0.000 (0.008) loss 1.3939 (1.3924) teacher_loss 0.5819 (0.6387) loss_zs_kd 0.4183 (0.4291) loss_oracle 0.3109 (0.3593) acc 84.3750 (82.8906) kd_loss 0.6566 (0.5741) lr 1.9098e-04 eta 0:04:02
epoch [42/50] batch [60/245] time 0.102 (0.109) data 0.001 (0.006) loss 1.0310 (1.3712) teacher_loss 0.4093 (0.6218) loss_zs_kd 0.3104 (0.4240) loss_oracle 0.3687 (0.3575) acc 93.7500 (83.3333) kd_loss 0.4373 (0.5706) lr 1.9098e-04 eta 0:03:54
epoch [42/50] batch [80/245] time 0.113 (0.108) data 0.000 (0.004) loss 1.3175 (1.3506) teacher_loss 0.5415 (0.6069) loss_zs_kd 0.3904 (0.4255) loss_oracle 0.3906 (0.3560) acc 78.1250 (83.3594) kd_loss 0.5807 (0.5657) lr 1.9098e-04 eta 0:03:49
epoch [42/50] batch [100/245] time 0.109 (0.107) data 0.000 (0.004) loss 1.5161 (1.3592) teacher_loss 0.7545 (0.6129) loss_zs_kd 0.4801 (0.4278) loss_oracle 0.3727 (0.3570) acc 75.0000 (82.8438) kd_loss 0.5753 (0.5677) lr 1.9098e-04 eta 0:03:44
epoch [42/50] batch [120/245] time 0.104 (0.106) data 0.000 (0.003) loss 2.0742 (1.3447) teacher_loss 1.2468 (0.6043) loss_zs_kd 0.5638 (0.4270) loss_oracle 0.3695 (0.3567) acc 59.3750 (82.9688) kd_loss 0.6427 (0.5620) lr 1.9098e-04 eta 0:03:41
epoch [42/50] batch [140/245] time 0.107 (0.106) data 0.000 (0.003) loss 1.3740 (1.3477) teacher_loss 0.6202 (0.6039) loss_zs_kd 0.4046 (0.4201) loss_oracle 0.3725 (0.3569) acc 84.3750 (83.0804) kd_loss 0.5676 (0.5654) lr 1.9098e-04 eta 0:03:38
epoch [42/50] batch [160/245] time 0.110 (0.105) data 0.000 (0.002) loss 1.3824 (1.3559) teacher_loss 0.6198 (0.6126) loss_zs_kd 0.4651 (0.4203) loss_oracle 0.3951 (0.3572) acc 81.2500 (82.7539) kd_loss 0.5651 (0.5648) lr 1.9098e-04 eta 0:03:35
epoch [42/50] batch [180/245] time 0.102 (0.105) data 0.000 (0.002) loss 1.5127 (1.3605) teacher_loss 0.6914 (0.6141) loss_zs_kd 0.4244 (0.4200) loss_oracle 0.3653 (0.3567) acc 84.3750 (82.7083) kd_loss 0.6386 (0.5680) lr 1.9098e-04 eta 0:03:32
epoch [42/50] batch [200/245] time 0.103 (0.105) data 0.000 (0.002) loss 0.8603 (1.3607) teacher_loss 0.1457 (0.6142) loss_zs_kd 0.3077 (0.4159) loss_oracle 0.2950 (0.3563) acc 93.7500 (82.7188) kd_loss 0.5671 (0.5684) lr 1.9098e-04 eta 0:03:29
epoch [42/50] batch [220/245] time 0.108 (0.104) data 0.000 (0.002) loss 0.9761 (1.3567) teacher_loss 0.2063 (0.6142) loss_zs_kd 0.3752 (0.4172) loss_oracle 0.3561 (0.3558) acc 96.8750 (82.7557) kd_loss 0.5917 (0.5646) lr 1.9098e-04 eta 0:03:27
epoch [42/50] batch [240/245] time 0.111 (0.106) data 0.000 (0.002) loss 1.3487 (1.3608) teacher_loss 0.6719 (0.6187) loss_zs_kd 0.3469 (0.4194) loss_oracle 0.3747 (0.3553) acc 84.3750 (82.5781) kd_loss 0.4894 (0.5645) lr 1.9098e-04 eta 0:03:27
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,079
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 91.1%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,259
* accuracy: 74.7%
* error: 25.3%
* macro_f1: 73.4%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [43/50] batch [20/245] time 0.103 (0.123) data 0.000 (0.018) loss 1.2281 (1.3617) teacher_loss 0.4168 (0.6077) loss_zs_kd 0.2814 (0.4375) loss_oracle 0.3353 (0.3518) acc 90.6250 (82.0312) kd_loss 0.6436 (0.5781) lr 1.5567e-04 eta 0:03:59
epoch [43/50] batch [40/245] time 0.115 (0.113) data 0.000 (0.009) loss 1.7125 (1.3279) teacher_loss 0.9811 (0.5874) loss_zs_kd 0.4743 (0.4340) loss_oracle 0.3477 (0.3537) acc 71.8750 (83.2812) kd_loss 0.5575 (0.5636) lr 1.5567e-04 eta 0:03:36
epoch [43/50] batch [60/245] time 0.106 (0.109) data 0.001 (0.006) loss 2.1677 (1.3683) teacher_loss 1.4187 (0.6214) loss_zs_kd 0.4778 (0.4311) loss_oracle 0.3587 (0.3546) acc 65.6250 (82.6562) kd_loss 0.5696 (0.5695) lr 1.5567e-04 eta 0:03:27
epoch [43/50] batch [80/245] time 0.103 (0.108) data 0.000 (0.005) loss 1.3231 (1.3774) teacher_loss 0.5461 (0.6314) loss_zs_kd 0.3749 (0.4302) loss_oracle 0.3833 (0.3539) acc 78.1250 (82.5000) kd_loss 0.5854 (0.5691) lr 1.5567e-04 eta 0:03:22
epoch [43/50] batch [100/245] time 0.107 (0.107) data 0.000 (0.004) loss 1.1577 (1.3834) teacher_loss 0.3679 (0.6312) loss_zs_kd 0.2905 (0.4297) loss_oracle 0.3511 (0.3559) acc 90.6250 (82.5000) kd_loss 0.6142 (0.5743) lr 1.5567e-04 eta 0:03:19
epoch [43/50] batch [120/245] time 0.103 (0.107) data 0.001 (0.003) loss 1.2193 (1.3719) teacher_loss 0.5529 (0.6254) loss_zs_kd 0.6873 (0.4303) loss_oracle 0.3092 (0.3563) acc 84.3750 (82.7865) kd_loss 0.5118 (0.5684) lr 1.5567e-04 eta 0:03:16
epoch [43/50] batch [140/245] time 0.112 (0.106) data 0.000 (0.003) loss 1.3894 (1.3613) teacher_loss 0.5610 (0.6171) loss_zs_kd 0.5075 (0.4183) loss_oracle 0.3486 (0.3557) acc 84.3750 (83.0804) kd_loss 0.6542 (0.5664) lr 1.5567e-04 eta 0:03:12
epoch [43/50] batch [160/245] time 0.098 (0.106) data 0.000 (0.003) loss 1.0986 (1.3527) teacher_loss 0.3277 (0.6098) loss_zs_kd 0.3486 (0.4200) loss_oracle 0.3326 (0.3570) acc 87.5000 (83.2031) kd_loss 0.6046 (0.5644) lr 1.5567e-04 eta 0:03:09
epoch [43/50] batch [180/245] time 0.110 (0.105) data 0.000 (0.002) loss 1.4929 (1.3567) teacher_loss 0.6911 (0.6137) loss_zs_kd 0.2995 (0.4194) loss_oracle 0.3951 (0.3582) acc 78.1250 (83.0382) kd_loss 0.6043 (0.5639) lr 1.5567e-04 eta 0:03:07
epoch [43/50] batch [200/245] time 0.100 (0.105) data 0.000 (0.002) loss 1.0149 (1.3605) teacher_loss 0.2366 (0.6195) loss_zs_kd 0.6663 (0.4167) loss_oracle 0.3495 (0.3581) acc 96.8750 (82.9531) kd_loss 0.6036 (0.5619) lr 1.5567e-04 eta 0:03:05
epoch [43/50] batch [220/245] time 0.103 (0.105) data 0.000 (0.002) loss 1.5311 (1.3586) teacher_loss 0.7758 (0.6144) loss_zs_kd 0.5142 (0.4150) loss_oracle 0.3897 (0.3596) acc 75.0000 (83.0540) kd_loss 0.5604 (0.5643) lr 1.5567e-04 eta 0:03:03
epoch [43/50] batch [240/245] time 0.108 (0.106) data 0.000 (0.002) loss 1.1116 (1.3567) teacher_loss 0.4350 (0.6124) loss_zs_kd 0.3642 (0.4154) loss_oracle 0.3473 (0.3586) acc 84.3750 (82.9948) kd_loss 0.5029 (0.5649) lr 1.5567e-04 eta 0:03:03
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,073
* accuracy: 91.6%
* error: 8.4%
* macro_f1: 90.9%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,244
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 73.2%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [44/50] batch [20/245] time 0.107 (0.124) data 0.000 (0.017) loss 2.0435 (1.4284) teacher_loss 1.3265 (0.6618) loss_zs_kd 0.4921 (0.4392) loss_oracle 0.4120 (0.3725) acc 62.5000 (81.7188) kd_loss 0.5110 (0.5803) lr 1.2369e-04 eta 0:03:30
epoch [44/50] batch [40/245] time 0.101 (0.114) data 0.000 (0.009) loss 1.2306 (1.3980) teacher_loss 0.4638 (0.6297) loss_zs_kd 0.4541 (0.4276) loss_oracle 0.3570 (0.3602) acc 87.5000 (82.9688) kd_loss 0.5884 (0.5882) lr 1.2369e-04 eta 0:03:10
epoch [44/50] batch [60/245] time 0.101 (0.110) data 0.000 (0.006) loss 1.9123 (1.3651) teacher_loss 1.0445 (0.5992) loss_zs_kd 0.3360 (0.4217) loss_oracle 0.3693 (0.3598) acc 75.0000 (83.8542) kd_loss 0.6832 (0.5860) lr 1.2369e-04 eta 0:03:01
epoch [44/50] batch [80/245] time 0.097 (0.107) data 0.000 (0.004) loss 1.4169 (1.3503) teacher_loss 0.7838 (0.5984) loss_zs_kd 0.3144 (0.4141) loss_oracle 0.3284 (0.3579) acc 75.0000 (83.4375) kd_loss 0.4688 (0.5730) lr 1.2369e-04 eta 0:02:55
epoch [44/50] batch [100/245] time 0.107 (0.106) data 0.000 (0.004) loss 1.2023 (1.3345) teacher_loss 0.5826 (0.5954) loss_zs_kd 0.4608 (0.4229) loss_oracle 0.3006 (0.3551) acc 81.2500 (83.4062) kd_loss 0.4694 (0.5616) lr 1.2369e-04 eta 0:02:50
epoch [44/50] batch [120/245] time 0.098 (0.104) data 0.000 (0.003) loss 1.1616 (1.3469) teacher_loss 0.4694 (0.6049) loss_zs_kd 0.2414 (0.4256) loss_oracle 0.3278 (0.3564) acc 84.3750 (83.2292) kd_loss 0.5283 (0.5639) lr 1.2369e-04 eta 0:02:46
epoch [44/50] batch [140/245] time 0.103 (0.104) data 0.000 (0.003) loss 1.2866 (1.3381) teacher_loss 0.6147 (0.5966) loss_zs_kd 0.3722 (0.4288) loss_oracle 0.3078 (0.3573) acc 84.3750 (83.6830) kd_loss 0.5180 (0.5628) lr 1.2369e-04 eta 0:02:43
epoch [44/50] batch [160/245] time 0.103 (0.104) data 0.000 (0.002) loss 0.9323 (1.3302) teacher_loss 0.2396 (0.5920) loss_zs_kd 0.3998 (0.4238) loss_oracle 0.3752 (0.3573) acc 90.6250 (83.7305) kd_loss 0.5050 (0.5596) lr 1.2369e-04 eta 0:02:41
epoch [44/50] batch [180/245] time 0.100 (0.103) data 0.000 (0.002) loss 1.1883 (1.3402) teacher_loss 0.3704 (0.5983) loss_zs_kd 0.4782 (0.4244) loss_oracle 0.3267 (0.3579) acc 90.6250 (83.4375) kd_loss 0.6545 (0.5630) lr 1.2369e-04 eta 0:02:38
epoch [44/50] batch [200/245] time 0.097 (0.103) data 0.000 (0.002) loss 1.2292 (1.3417) teacher_loss 0.5909 (0.6022) loss_zs_kd 0.5681 (0.4249) loss_oracle 0.3292 (0.3572) acc 87.5000 (83.3906) kd_loss 0.4737 (0.5609) lr 1.2369e-04 eta 0:02:35
epoch [44/50] batch [220/245] time 0.103 (0.103) data 0.000 (0.002) loss 1.3258 (1.3431) teacher_loss 0.6090 (0.6052) loss_zs_kd 0.4191 (0.4254) loss_oracle 0.3547 (0.3571) acc 78.1250 (83.2955) kd_loss 0.5395 (0.5593) lr 1.2369e-04 eta 0:02:33
epoch [44/50] batch [240/245] time 0.084 (0.102) data 0.000 (0.002) loss 1.3487 (1.3460) teacher_loss 0.6958 (0.6086) loss_zs_kd 0.3329 (0.4252) loss_oracle 0.3186 (0.3572) acc 78.1250 (83.2682) kd_loss 0.4936 (0.5588) lr 1.2369e-04 eta 0:02:31
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,076
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,254
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.4%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [45/50] batch [20/245] time 0.096 (0.117) data 0.000 (0.014) loss 1.3718 (1.3446) teacher_loss 0.6172 (0.6136) loss_zs_kd 0.3458 (0.4083) loss_oracle 0.3482 (0.3564) acc 84.3750 (85.1562) kd_loss 0.5805 (0.5528) lr 9.5173e-05 eta 0:02:50
epoch [45/50] batch [40/245] time 0.099 (0.108) data 0.000 (0.007) loss 1.2993 (1.3285) teacher_loss 0.4443 (0.5792) loss_zs_kd 0.4249 (0.4133) loss_oracle 0.3995 (0.3498) acc 93.7500 (85.1562) kd_loss 0.6553 (0.5744) lr 9.5173e-05 eta 0:02:33
epoch [45/50] batch [60/245] time 0.096 (0.104) data 0.000 (0.005) loss 1.1823 (1.3378) teacher_loss 0.4136 (0.5944) loss_zs_kd 0.3066 (0.4182) loss_oracle 0.3386 (0.3522) acc 90.6250 (84.4271) kd_loss 0.5995 (0.5673) lr 9.5173e-05 eta 0:02:26
epoch [45/50] batch [80/245] time 0.107 (0.103) data 0.000 (0.004) loss 1.1700 (1.3397) teacher_loss 0.4877 (0.5965) loss_zs_kd 0.5371 (0.4135) loss_oracle 0.3426 (0.3506) acc 87.5000 (84.1016) kd_loss 0.5110 (0.5679) lr 9.5173e-05 eta 0:02:22
epoch [45/50] batch [100/245] time 0.101 (0.102) data 0.000 (0.003) loss 1.6908 (1.3461) teacher_loss 0.9352 (0.5950) loss_zs_kd 0.4510 (0.4112) loss_oracle 0.3630 (0.3544) acc 75.0000 (84.0312) kd_loss 0.5740 (0.5739) lr 9.5173e-05 eta 0:02:20
epoch [45/50] batch [120/245] time 0.112 (0.103) data 0.000 (0.002) loss 1.3423 (1.3562) teacher_loss 0.5841 (0.5971) loss_zs_kd 0.6094 (0.4200) loss_oracle 0.3866 (0.3569) acc 81.2500 (83.4896) kd_loss 0.5650 (0.5807) lr 9.5173e-05 eta 0:02:19
epoch [45/50] batch [140/245] time 0.099 (0.103) data 0.000 (0.002) loss 1.2714 (1.3596) teacher_loss 0.4826 (0.6011) loss_zs_kd 0.3688 (0.4222) loss_oracle 0.3292 (0.3578) acc 81.2500 (83.4152) kd_loss 0.6241 (0.5795) lr 9.5173e-05 eta 0:02:17
epoch [45/50] batch [160/245] time 0.109 (0.104) data 0.000 (0.002) loss 1.5391 (1.3626) teacher_loss 0.7278 (0.6073) loss_zs_kd 0.5975 (0.4242) loss_oracle 0.3798 (0.3581) acc 78.1250 (83.0664) kd_loss 0.6214 (0.5763) lr 9.5173e-05 eta 0:02:15
epoch [45/50] batch [180/245] time 0.100 (0.103) data 0.000 (0.002) loss 1.2918 (1.3629) teacher_loss 0.6218 (0.6114) loss_zs_kd 0.3713 (0.4267) loss_oracle 0.3659 (0.3584) acc 84.3750 (82.9688) kd_loss 0.4870 (0.5723) lr 9.5173e-05 eta 0:02:12
epoch [45/50] batch [200/245] time 0.092 (0.102) data 0.000 (0.002) loss 1.2948 (1.3557) teacher_loss 0.4819 (0.6096) loss_zs_kd 0.4550 (0.4257) loss_oracle 0.3756 (0.3571) acc 90.6250 (82.9531) kd_loss 0.6251 (0.5676) lr 9.5173e-05 eta 0:02:09
epoch [45/50] batch [220/245] time 0.101 (0.102) data 0.001 (0.001) loss 1.0674 (1.3521) teacher_loss 0.4237 (0.6084) loss_zs_kd 0.2988 (0.4226) loss_oracle 0.3668 (0.3566) acc 84.3750 (83.0824) kd_loss 0.4603 (0.5654) lr 9.5173e-05 eta 0:02:07
epoch [45/50] batch [240/245] time 0.126 (0.102) data 0.000 (0.001) loss 1.3599 (1.3529) teacher_loss 0.6917 (0.6105) loss_zs_kd 0.3986 (0.4222) loss_oracle 0.3298 (0.3562) acc 78.1250 (82.9688) kd_loss 0.5034 (0.5643) lr 9.5173e-05 eta 0:02:05
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,078
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,250
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.2%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [46/50] batch [20/245] time 0.117 (0.126) data 0.000 (0.020) loss 1.7863 (1.4789) teacher_loss 1.0146 (0.7319) loss_zs_kd 0.5050 (0.4119) loss_oracle 0.3656 (0.3555) acc 65.6250 (80.3125) kd_loss 0.5889 (0.5693) lr 7.0224e-05 eta 0:02:31
epoch [46/50] batch [40/245] time 0.087 (0.109) data 0.000 (0.010) loss 1.4593 (1.4035) teacher_loss 0.7087 (0.6552) loss_zs_kd 0.3094 (0.4167) loss_oracle 0.3122 (0.3565) acc 81.2500 (81.6406) kd_loss 0.5944 (0.5701) lr 7.0224e-05 eta 0:02:09
epoch [46/50] batch [60/245] time 0.097 (0.104) data 0.000 (0.007) loss 0.8643 (1.3734) teacher_loss 0.1583 (0.6233) loss_zs_kd 0.3071 (0.4097) loss_oracle 0.3825 (0.3570) acc 96.8750 (82.6042) kd_loss 0.5147 (0.5716) lr 7.0224e-05 eta 0:02:01
epoch [46/50] batch [80/245] time 0.095 (0.101) data 0.000 (0.005) loss 1.3782 (1.3686) teacher_loss 0.6067 (0.6182) loss_zs_kd 0.3886 (0.4182) loss_oracle 0.3840 (0.3558) acc 84.3750 (82.7344) kd_loss 0.5795 (0.5725) lr 7.0224e-05 eta 0:01:56
epoch [46/50] batch [100/245] time 0.102 (0.102) data 0.000 (0.004) loss 1.2671 (1.3669) teacher_loss 0.3846 (0.6161) loss_zs_kd 0.5711 (0.4267) loss_oracle 0.3785 (0.3550) acc 84.3750 (82.6562) kd_loss 0.6932 (0.5732) lr 7.0224e-05 eta 0:01:54
epoch [46/50] batch [120/245] time 0.099 (0.102) data 0.000 (0.003) loss 1.1406 (1.3764) teacher_loss 0.4191 (0.6300) loss_zs_kd 0.2538 (0.4268) loss_oracle 0.3303 (0.3540) acc 90.6250 (82.3958) kd_loss 0.5564 (0.5693) lr 7.0224e-05 eta 0:01:53
epoch [46/50] batch [140/245] time 0.102 (0.102) data 0.000 (0.003) loss 1.1844 (1.3694) teacher_loss 0.4445 (0.6235) loss_zs_kd 0.4031 (0.4271) loss_oracle 0.3447 (0.3534) acc 87.5000 (82.3661) kd_loss 0.5676 (0.5693) lr 7.0224e-05 eta 0:01:51
epoch [46/50] batch [160/245] time 0.096 (0.102) data 0.000 (0.003) loss 1.2540 (1.3520) teacher_loss 0.4622 (0.6082) loss_zs_kd 0.4168 (0.4242) loss_oracle 0.3805 (0.3539) acc 87.5000 (82.8125) kd_loss 0.6015 (0.5668) lr 7.0224e-05 eta 0:01:48
epoch [46/50] batch [180/245] time 0.094 (0.102) data 0.000 (0.002) loss 1.5128 (1.3557) teacher_loss 0.6679 (0.6121) loss_zs_kd 0.5643 (0.4257) loss_oracle 0.3777 (0.3539) acc 81.2500 (82.6736) kd_loss 0.6560 (0.5666) lr 7.0224e-05 eta 0:01:46
epoch [46/50] batch [200/245] time 0.102 (0.102) data 0.000 (0.002) loss 1.3765 (1.3632) teacher_loss 0.6792 (0.6187) loss_zs_kd 0.4430 (0.4239) loss_oracle 0.3993 (0.3548) acc 81.2500 (82.5156) kd_loss 0.4976 (0.5672) lr 7.0224e-05 eta 0:01:44
epoch [46/50] batch [220/245] time 0.096 (0.102) data 0.000 (0.002) loss 1.3031 (1.3582) teacher_loss 0.4524 (0.6146) loss_zs_kd 0.4931 (0.4264) loss_oracle 0.3890 (0.3555) acc 87.5000 (82.5852) kd_loss 0.6562 (0.5658) lr 7.0224e-05 eta 0:01:42
epoch [46/50] batch [240/245] time 0.108 (0.102) data 0.000 (0.002) loss 1.1240 (1.3604) teacher_loss 0.2916 (0.6171) loss_zs_kd 0.4577 (0.4274) loss_oracle 0.3668 (0.3556) acc 93.7500 (82.5260) kd_loss 0.6490 (0.5655) lr 7.0224e-05 eta 0:01:40
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,075
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,248
* accuracy: 74.4%
* error: 25.6%
* macro_f1: 73.3%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [47/50] batch [20/245] time 0.104 (0.124) data 0.000 (0.019) loss 1.1690 (1.2959) teacher_loss 0.4648 (0.5454) loss_zs_kd 0.4452 (0.4001) loss_oracle 0.3144 (0.3539) acc 84.3750 (83.7500) kd_loss 0.5469 (0.5735) lr 4.8943e-05 eta 0:01:59
epoch [47/50] batch [40/245] time 0.103 (0.113) data 0.000 (0.009) loss 0.9507 (1.3451) teacher_loss 0.2685 (0.5979) loss_zs_kd 0.4047 (0.3998) loss_oracle 0.3610 (0.3543) acc 90.6250 (83.5938) kd_loss 0.5017 (0.5701) lr 4.8943e-05 eta 0:01:45
epoch [47/50] batch [60/245] time 0.092 (0.107) data 0.000 (0.006) loss 1.1238 (1.3532) teacher_loss 0.4295 (0.6047) loss_zs_kd 0.3066 (0.4067) loss_oracle 0.3521 (0.3592) acc 87.5000 (83.7500) kd_loss 0.5182 (0.5689) lr 4.8943e-05 eta 0:01:38
epoch [47/50] batch [80/245] time 0.104 (0.105) data 0.000 (0.005) loss 1.5909 (1.3389) teacher_loss 0.8991 (0.5949) loss_zs_kd 0.4358 (0.4154) loss_oracle 0.3697 (0.3594) acc 78.1250 (83.8672) kd_loss 0.5069 (0.5644) lr 4.8943e-05 eta 0:01:34
epoch [47/50] batch [100/245] time 0.093 (0.103) data 0.000 (0.004) loss 1.8121 (1.3417) teacher_loss 0.9986 (0.5971) loss_zs_kd 0.5703 (0.4221) loss_oracle 0.3509 (0.3578) acc 68.7500 (83.3750) kd_loss 0.6380 (0.5658) lr 4.8943e-05 eta 0:01:30
epoch [47/50] batch [120/245] time 0.096 (0.102) data 0.000 (0.003) loss 1.3435 (1.3334) teacher_loss 0.4804 (0.5925) loss_zs_kd 0.4775 (0.4204) loss_oracle 0.3906 (0.3575) acc 84.3750 (83.3854) kd_loss 0.6678 (0.5622) lr 4.8943e-05 eta 0:01:27
epoch [47/50] batch [140/245] time 0.098 (0.102) data 0.000 (0.003) loss 1.2501 (1.3404) teacher_loss 0.6647 (0.5973) loss_zs_kd 0.3977 (0.4242) loss_oracle 0.3372 (0.3573) acc 84.3750 (83.1473) kd_loss 0.4168 (0.5644) lr 4.8943e-05 eta 0:01:25
epoch [47/50] batch [160/245] time 0.101 (0.101) data 0.000 (0.003) loss 1.0512 (1.3381) teacher_loss 0.3741 (0.5938) loss_zs_kd 0.5158 (0.4252) loss_oracle 0.3548 (0.3580) acc 87.5000 (83.1055) kd_loss 0.4997 (0.5653) lr 4.8943e-05 eta 0:01:23
epoch [47/50] batch [180/245] time 0.098 (0.101) data 0.000 (0.002) loss 1.3220 (1.3348) teacher_loss 0.5190 (0.5880) loss_zs_kd 0.3764 (0.4199) loss_oracle 0.3422 (0.3587) acc 81.2500 (83.3160) kd_loss 0.6318 (0.5675) lr 4.8943e-05 eta 0:01:20
epoch [47/50] batch [200/245] time 0.102 (0.101) data 0.000 (0.002) loss 1.1291 (1.3362) teacher_loss 0.5033 (0.5898) loss_zs_kd 0.4704 (0.4193) loss_oracle 0.2720 (0.3589) acc 87.5000 (83.2812) kd_loss 0.4898 (0.5670) lr 4.8943e-05 eta 0:01:18
epoch [47/50] batch [220/245] time 0.092 (0.101) data 0.000 (0.002) loss 1.1511 (1.3388) teacher_loss 0.3827 (0.5940) loss_zs_kd 0.5716 (0.4197) loss_oracle 0.3780 (0.3591) acc 90.6250 (83.1250) kd_loss 0.5795 (0.5653) lr 4.8943e-05 eta 0:01:16
epoch [47/50] batch [240/245] time 0.086 (0.100) data 0.000 (0.002) loss 1.1686 (1.3471) teacher_loss 0.5789 (0.6018) loss_zs_kd 0.4836 (0.4174) loss_oracle 0.3665 (0.3590) acc 81.2500 (82.8646) kd_loss 0.4065 (0.5658) lr 4.8943e-05 eta 0:01:14
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,076
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,243
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 73.2%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [48/50] batch [20/245] time 0.104 (0.109) data 0.000 (0.014) loss 1.0178 (1.3555) teacher_loss 0.4129 (0.6132) loss_zs_kd 0.4852 (0.4152) loss_oracle 0.3485 (0.3571) acc 90.6250 (81.5625) kd_loss 0.4307 (0.5638) lr 3.1417e-05 eta 0:01:17
epoch [48/50] batch [40/245] time 0.096 (0.101) data 0.000 (0.007) loss 1.3255 (1.3326) teacher_loss 0.5565 (0.5952) loss_zs_kd 0.3381 (0.4298) loss_oracle 0.3633 (0.3578) acc 87.5000 (82.5781) kd_loss 0.5873 (0.5585) lr 3.1417e-05 eta 0:01:10
epoch [48/50] batch [60/245] time 0.095 (0.100) data 0.000 (0.005) loss 1.3920 (1.3202) teacher_loss 0.5238 (0.5805) loss_zs_kd 0.3915 (0.4115) loss_oracle 0.4034 (0.3598) acc 84.3750 (83.0729) kd_loss 0.6664 (0.5598) lr 3.1417e-05 eta 0:01:07
epoch [48/50] batch [80/245] time 0.100 (0.100) data 0.000 (0.004) loss 1.7174 (1.3294) teacher_loss 0.9737 (0.5923) loss_zs_kd 0.4544 (0.4199) loss_oracle 0.3161 (0.3588) acc 68.7500 (82.7344) kd_loss 0.5857 (0.5577) lr 3.1417e-05 eta 0:01:05
epoch [48/50] batch [100/245] time 0.103 (0.099) data 0.000 (0.003) loss 1.7509 (1.3294) teacher_loss 1.0940 (0.5903) loss_zs_kd 0.5108 (0.4186) loss_oracle 0.3369 (0.3583) acc 68.7500 (82.9062) kd_loss 0.4885 (0.5599) lr 3.1417e-05 eta 0:01:02
epoch [48/50] batch [120/245] time 0.092 (0.099) data 0.000 (0.002) loss 1.6122 (1.3456) teacher_loss 0.8522 (0.6021) loss_zs_kd 0.3876 (0.4196) loss_oracle 0.3538 (0.3608) acc 81.2500 (82.9688) kd_loss 0.5831 (0.5631) lr 3.1417e-05 eta 0:01:00
epoch [48/50] batch [140/245] time 0.100 (0.098) data 0.000 (0.002) loss 1.5379 (1.3527) teacher_loss 0.8217 (0.6040) loss_zs_kd 0.5239 (0.4211) loss_oracle 0.3550 (0.3599) acc 78.1250 (82.9464) kd_loss 0.5388 (0.5688) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [160/245] time 0.094 (0.098) data 0.001 (0.002) loss 1.4695 (1.3520) teacher_loss 0.6353 (0.6030) loss_zs_kd 0.5547 (0.4231) loss_oracle 0.4195 (0.3611) acc 78.1250 (82.9297) kd_loss 0.6246 (0.5684) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [180/245] time 0.094 (0.098) data 0.000 (0.002) loss 1.0723 (1.3541) teacher_loss 0.3261 (0.6039) loss_zs_kd 0.4055 (0.4217) loss_oracle 0.3627 (0.3617) acc 90.6250 (82.8993) kd_loss 0.5649 (0.5694) lr 3.1417e-05 eta 0:00:54
epoch [48/50] batch [200/245] time 0.092 (0.098) data 0.000 (0.002) loss 1.2597 (1.3580) teacher_loss 0.5255 (0.6057) loss_zs_kd 0.7144 (0.4248) loss_oracle 0.3918 (0.3616) acc 81.2500 (82.9219) kd_loss 0.5383 (0.5715) lr 3.1417e-05 eta 0:00:52
epoch [48/50] batch [220/245] time 0.091 (0.097) data 0.000 (0.001) loss 1.2532 (1.3588) teacher_loss 0.4448 (0.6039) loss_zs_kd 0.4451 (0.4249) loss_oracle 0.3252 (0.3626) acc 84.3750 (82.8835) kd_loss 0.6458 (0.5736) lr 3.1417e-05 eta 0:00:50
epoch [48/50] batch [240/245] time 0.088 (0.097) data 0.000 (0.001) loss 1.6244 (1.3690) teacher_loss 0.8488 (0.6162) loss_zs_kd 0.5054 (0.4258) loss_oracle 0.3556 (0.3621) acc 71.8750 (82.5781) kd_loss 0.5978 (0.5717) lr 3.1417e-05 eta 0:00:47
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,077
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,245
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 73.2%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [49/50] batch [20/245] time 0.096 (0.119) data 0.000 (0.015) loss 1.8611 (1.3546) teacher_loss 1.1113 (0.6301) loss_zs_kd 0.4860 (0.4267) loss_oracle 0.3540 (0.3540) acc 65.6250 (82.5000) kd_loss 0.5728 (0.5475) lr 1.7713e-05 eta 0:00:55
epoch [49/50] batch [40/245] time 0.093 (0.109) data 0.000 (0.008) loss 1.5052 (1.3456) teacher_loss 0.6602 (0.6017) loss_zs_kd 0.3874 (0.4218) loss_oracle 0.3987 (0.3559) acc 84.3750 (82.6562) kd_loss 0.6457 (0.5659) lr 1.7713e-05 eta 0:00:49
epoch [49/50] batch [60/245] time 0.093 (0.104) data 0.000 (0.005) loss 1.8108 (1.3440) teacher_loss 1.0271 (0.5939) loss_zs_kd 0.4989 (0.4127) loss_oracle 0.3724 (0.3605) acc 62.5000 (82.8646) kd_loss 0.5974 (0.5698) lr 1.7713e-05 eta 0:00:44
epoch [49/50] batch [80/245] time 0.094 (0.101) data 0.000 (0.004) loss 1.5890 (1.3335) teacher_loss 0.6423 (0.5851) loss_zs_kd 0.3967 (0.4060) loss_oracle 0.3846 (0.3594) acc 75.0000 (83.0078) kd_loss 0.7544 (0.5687) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [100/245] time 0.093 (0.101) data 0.000 (0.003) loss 1.3915 (1.3568) teacher_loss 0.6989 (0.6065) loss_zs_kd 0.3811 (0.4153) loss_oracle 0.3627 (0.3615) acc 81.2500 (82.5938) kd_loss 0.5113 (0.5696) lr 1.7713e-05 eta 0:00:39
epoch [49/50] batch [120/245] time 0.092 (0.100) data 0.000 (0.003) loss 1.3039 (1.3468) teacher_loss 0.4840 (0.5969) loss_zs_kd 0.4285 (0.4164) loss_oracle 0.3638 (0.3618) acc 84.3750 (82.7865) kd_loss 0.6380 (0.5689) lr 1.7713e-05 eta 0:00:37
epoch [49/50] batch [140/245] time 0.099 (0.100) data 0.000 (0.002) loss 1.5819 (1.3419) teacher_loss 0.8263 (0.5942) loss_zs_kd 0.4324 (0.4178) loss_oracle 0.3516 (0.3601) acc 84.3750 (82.9018) kd_loss 0.5797 (0.5676) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [160/245] time 0.099 (0.099) data 0.000 (0.002) loss 1.3086 (1.3479) teacher_loss 0.5810 (0.5991) loss_zs_kd 0.3170 (0.4183) loss_oracle 0.3710 (0.3596) acc 90.6250 (82.6758) kd_loss 0.5420 (0.5690) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [180/245] time 0.097 (0.099) data 0.000 (0.002) loss 1.3857 (1.3460) teacher_loss 0.5362 (0.5955) loss_zs_kd 0.4452 (0.4156) loss_oracle 0.4140 (0.3599) acc 87.5000 (82.8819) kd_loss 0.6425 (0.5706) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [200/245] time 0.098 (0.099) data 0.000 (0.002) loss 1.4605 (1.3475) teacher_loss 0.6166 (0.5958) loss_zs_kd 0.6269 (0.4157) loss_oracle 0.3281 (0.3597) acc 84.3750 (83.0625) kd_loss 0.6799 (0.5718) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [220/245] time 0.099 (0.099) data 0.000 (0.002) loss 1.4333 (1.3518) teacher_loss 0.6210 (0.5992) loss_zs_kd 0.4257 (0.4163) loss_oracle 0.3474 (0.3599) acc 84.3750 (82.9830) kd_loss 0.6385 (0.5726) lr 1.7713e-05 eta 0:00:26
epoch [49/50] batch [240/245] time 0.105 (0.100) data 0.000 (0.001) loss 1.6897 (1.3552) teacher_loss 0.9238 (0.6030) loss_zs_kd 0.4402 (0.4205) loss_oracle 0.3664 (0.3605) acc 75.0000 (82.8776) kd_loss 0.5828 (0.5718) lr 1.7713e-05 eta 0:00:24
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,078
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,247
* accuracy: 74.4%
* error: 25.6%
* macro_f1: 73.2%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
epoch [50/50] batch [20/245] time 0.106 (0.118) data 0.000 (0.013) loss 1.6348 (1.3503) teacher_loss 0.9602 (0.6040) loss_zs_kd 0.4941 (0.4195) loss_oracle 0.3586 (0.3549) acc 78.1250 (82.8125) kd_loss 0.4954 (0.5689) lr 7.8853e-06 eta 0:00:26
epoch [50/50] batch [40/245] time 0.091 (0.110) data 0.000 (0.007) loss 1.3406 (1.3227) teacher_loss 0.6166 (0.5730) loss_zs_kd 0.4729 (0.4179) loss_oracle 0.4017 (0.3602) acc 84.3750 (83.9844) kd_loss 0.5231 (0.5696) lr 7.8853e-06 eta 0:00:22
epoch [50/50] batch [60/245] time 0.099 (0.106) data 0.000 (0.005) loss 1.4390 (1.3313) teacher_loss 0.4931 (0.5737) loss_zs_kd 0.6659 (0.4114) loss_oracle 0.3916 (0.3588) acc 87.5000 (83.6979) kd_loss 0.7500 (0.5782) lr 7.8853e-06 eta 0:00:19
epoch [50/50] batch [80/245] time 0.112 (0.106) data 0.000 (0.003) loss 1.0719 (1.3340) teacher_loss 0.4270 (0.5830) loss_zs_kd 0.3942 (0.4095) loss_oracle 0.3648 (0.3604) acc 84.3750 (83.3594) kd_loss 0.4626 (0.5708) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [100/245] time 0.102 (0.105) data 0.000 (0.003) loss 1.4675 (1.3180) teacher_loss 0.6380 (0.5664) loss_zs_kd 0.4875 (0.4134) loss_oracle 0.3489 (0.3586) acc 81.2500 (83.8438) kd_loss 0.6551 (0.5723) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [120/245] time 0.099 (0.104) data 0.000 (0.002) loss 1.0423 (1.3135) teacher_loss 0.3407 (0.5648) loss_zs_kd 0.3042 (0.4143) loss_oracle 0.3234 (0.3596) acc 90.6250 (83.9062) kd_loss 0.5399 (0.5690) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [140/245] time 0.094 (0.104) data 0.000 (0.002) loss 1.9040 (1.3194) teacher_loss 1.1022 (0.5716) loss_zs_kd 0.4170 (0.4095) loss_oracle 0.4006 (0.3605) acc 75.0000 (83.6607) kd_loss 0.6015 (0.5676) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [160/245] time 0.092 (0.103) data 0.000 (0.002) loss 1.4059 (1.3224) teacher_loss 0.6519 (0.5724) loss_zs_kd 0.4745 (0.4127) loss_oracle 0.3570 (0.3607) acc 81.2500 (83.5156) kd_loss 0.5755 (0.5696) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [180/245] time 0.097 (0.102) data 0.000 (0.002) loss 1.5795 (1.3276) teacher_loss 0.8970 (0.5795) loss_zs_kd 0.5742 (0.4161) loss_oracle 0.3633 (0.3609) acc 78.1250 (83.2986) kd_loss 0.5009 (0.5676) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [200/245] time 0.095 (0.102) data 0.000 (0.002) loss 1.4009 (1.3314) teacher_loss 0.5875 (0.5811) loss_zs_kd 0.3733 (0.4151) loss_oracle 0.3754 (0.3627) acc 87.5000 (83.4688) kd_loss 0.6257 (0.5690) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [220/245] time 0.092 (0.101) data 0.000 (0.001) loss 1.3348 (1.3330) teacher_loss 0.5794 (0.5849) loss_zs_kd 0.4282 (0.4135) loss_oracle 0.3760 (0.3625) acc 84.3750 (83.4375) kd_loss 0.5674 (0.5668) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [240/245] time 0.089 (0.100) data 0.000 (0.001) loss 1.2676 (1.3403) teacher_loss 0.5470 (0.5937) loss_zs_kd 0.3906 (0.4129) loss_oracle 0.3101 (0.3624) acc 81.2500 (83.1901) kd_loss 0.5655 (0.5654) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,077
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,244
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 73.2%
******* Domain c best val acc:      91.9%, epoch: 37 *******
******* Domain c best val test acc: 74.2%, epoch: 37 *******
******* Domain c best test acc:     74.7%, epoch: 21 *******
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:26:45

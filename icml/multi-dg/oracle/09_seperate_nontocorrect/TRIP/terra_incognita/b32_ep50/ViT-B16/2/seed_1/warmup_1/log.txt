Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_100', 'location_43', 'location_46']
Target     ['location_38']
# classes  10
# train_x  10,216
# val      4,378
# test     9,736
---------  ----------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/319] time 0.057 (0.124) data 0.000 (0.030) loss 2.7638 (3.5112) teacher_loss 1.2528 (2.0152) loss_zs_kd 0.0002 (0.0001) loss_oracle 1.0965 (1.0988) acc 59.3750 (37.0312) kd_loss 0.9628 (0.9466) lr 1.0000e-05 eta 0:32:58
epoch [1/50] batch [40/319] time 0.083 (0.098) data 0.000 (0.015) loss 3.0297 (3.3891) teacher_loss 1.5746 (1.9121) loss_zs_kd 0.0015 (0.0003) loss_oracle 1.0972 (1.0973) acc 56.2500 (39.7656) kd_loss 0.9064 (0.9283) lr 1.0000e-05 eta 0:25:54
epoch [1/50] batch [60/319] time 0.086 (0.093) data 0.001 (0.010) loss 3.6686 (3.4224) teacher_loss 2.1716 (1.9404) loss_zs_kd 0.0026 (0.0008) loss_oracle 1.0957 (1.0968) acc 31.2500 (39.2188) kd_loss 0.9491 (0.9336) lr 1.0000e-05 eta 0:24:35
epoch [1/50] batch [80/319] time 0.071 (0.091) data 0.000 (0.008) loss 3.4408 (3.4022) teacher_loss 1.9702 (1.9215) loss_zs_kd 0.0041 (0.0015) loss_oracle 1.0942 (1.0964) acc 43.7500 (38.8672) kd_loss 0.9235 (0.9324) lr 1.0000e-05 eta 0:24:03
epoch [1/50] batch [100/319] time 0.088 (0.089) data 0.000 (0.006) loss 3.7233 (3.3612) teacher_loss 2.1710 (1.8828) loss_zs_kd 0.0083 (0.0025) loss_oracle 1.0950 (1.0961) acc 25.0000 (39.5312) kd_loss 1.0049 (0.9303) lr 1.0000e-05 eta 0:23:22
epoch [1/50] batch [120/319] time 0.077 (0.087) data 0.000 (0.005) loss 3.2834 (3.3575) teacher_loss 1.8661 (1.8809) loss_zs_kd 0.0065 (0.0035) loss_oracle 1.0951 (1.0959) acc 40.6250 (39.6615) kd_loss 0.8698 (0.9287) lr 1.0000e-05 eta 0:22:57
epoch [1/50] batch [140/319] time 0.077 (0.085) data 0.000 (0.004) loss 3.4166 (3.3552) teacher_loss 2.0505 (1.8808) loss_zs_kd 0.0103 (0.0045) loss_oracle 1.0968 (1.0958) acc 37.5000 (39.5982) kd_loss 0.8176 (0.9264) lr 1.0000e-05 eta 0:22:31
epoch [1/50] batch [160/319] time 0.071 (0.085) data 0.000 (0.004) loss 3.2795 (3.3494) teacher_loss 1.8241 (1.8768) loss_zs_kd 0.0138 (0.0058) loss_oracle 1.0961 (1.0960) acc 34.3750 (39.7266) kd_loss 0.9074 (0.9246) lr 1.0000e-05 eta 0:22:28
epoch [1/50] batch [180/319] time 0.078 (0.085) data 0.000 (0.004) loss 3.5709 (3.3445) teacher_loss 2.1712 (1.8734) loss_zs_kd 0.0238 (0.0073) loss_oracle 1.0957 (1.0960) acc 28.1250 (39.6354) kd_loss 0.8519 (0.9231) lr 1.0000e-05 eta 0:22:18
epoch [1/50] batch [200/319] time 0.078 (0.085) data 0.000 (0.003) loss 3.5135 (3.3398) teacher_loss 1.9913 (1.8687) loss_zs_kd 0.0248 (0.0089) loss_oracle 1.0942 (1.0959) acc 31.2500 (39.6250) kd_loss 0.9751 (0.9231) lr 1.0000e-05 eta 0:22:11
epoch [1/50] batch [220/319] time 0.078 (0.085) data 0.000 (0.003) loss 3.2041 (3.3457) teacher_loss 1.7087 (1.8743) loss_zs_kd 0.0326 (0.0108) loss_oracle 1.0968 (1.0958) acc 43.7500 (39.2188) kd_loss 0.9469 (0.9235) lr 1.0000e-05 eta 0:22:09
epoch [1/50] batch [240/319] time 0.083 (0.084) data 0.000 (0.003) loss 3.3783 (3.3543) teacher_loss 1.9297 (1.8808) loss_zs_kd 0.0452 (0.0128) loss_oracle 1.0994 (1.0961) acc 28.1250 (38.9062) kd_loss 0.8988 (0.9254) lr 1.0000e-05 eta 0:22:03
epoch [1/50] batch [260/319] time 0.084 (0.084) data 0.000 (0.003) loss 3.4220 (3.3516) teacher_loss 1.9806 (1.8779) loss_zs_kd 0.0415 (0.0149) loss_oracle 1.0977 (1.0965) acc 40.6250 (38.8582) kd_loss 0.8926 (0.9255) lr 1.0000e-05 eta 0:21:53
epoch [1/50] batch [280/319] time 0.078 (0.083) data 0.000 (0.002) loss 3.5968 (3.3478) teacher_loss 2.0918 (1.8740) loss_zs_kd 0.0606 (0.0172) loss_oracle 1.0941 (1.0964) acc 31.2500 (38.9174) kd_loss 0.9579 (0.9256) lr 1.0000e-05 eta 0:21:43
epoch [1/50] batch [300/319] time 0.088 (0.083) data 0.000 (0.002) loss 3.7371 (3.3434) teacher_loss 2.2817 (1.8698) loss_zs_kd 0.0592 (0.0197) loss_oracle 1.0947 (1.0963) acc 31.2500 (38.9062) kd_loss 0.9081 (0.9255) lr 1.0000e-05 eta 0:21:33
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,775
* accuracy: 40.5%
* error: 59.5%
* macro_f1: 26.1%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 3,209
* accuracy: 33.0%
* error: 67.0%
* macro_f1: 14.2%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 33.0%, epoch: 1 *******
******* Domain 2 best test acc:     33.0%, epoch: 1 *******
epoch [2/50] batch [20/319] time 0.080 (0.117) data 0.000 (0.030) loss 3.1545 (3.2105) teacher_loss 1.5941 (1.6725) loss_zs_kd 0.6244 (0.4990) loss_oracle 1.0908 (1.0962) acc 46.8750 (40.1562) kd_loss 1.0150 (0.9899) lr 2.0000e-03 eta 0:30:21
epoch [2/50] batch [40/319] time 0.083 (0.100) data 0.000 (0.015) loss 3.4377 (3.1843) teacher_loss 1.8791 (1.6267) loss_zs_kd 0.4792 (0.6267) loss_oracle 1.0694 (1.0881) acc 28.1250 (43.0469) kd_loss 1.0239 (1.0135) lr 2.0000e-03 eta 0:25:55
epoch [2/50] batch [60/319] time 0.068 (0.098) data 0.000 (0.010) loss 3.0567 (3.1391) teacher_loss 1.4907 (1.5795) loss_zs_kd 0.3677 (0.5531) loss_oracle 1.0530 (1.0785) acc 46.8750 (44.1146) kd_loss 1.0394 (1.0203) lr 2.0000e-03 eta 0:25:19
epoch [2/50] batch [80/319] time 0.094 (0.094) data 0.000 (0.008) loss 2.9394 (3.1083) teacher_loss 1.4039 (1.5474) loss_zs_kd 0.4397 (0.4996) loss_oracle 1.0482 (1.0735) acc 50.0000 (45.5469) kd_loss 1.0115 (1.0242) lr 2.0000e-03 eta 0:24:22
epoch [2/50] batch [100/319] time 0.098 (0.092) data 0.001 (0.006) loss 3.0702 (3.1000) teacher_loss 1.5053 (1.5340) loss_zs_kd 0.3950 (0.4825) loss_oracle 1.0433 (1.0662) acc 43.7500 (45.5625) kd_loss 1.0433 (1.0329) lr 2.0000e-03 eta 0:23:54
epoch [2/50] batch [120/319] time 0.076 (0.091) data 0.000 (0.005) loss 2.6525 (3.0782) teacher_loss 1.0762 (1.5135) loss_zs_kd 0.3804 (0.4770) loss_oracle 1.0468 (1.0642) acc 68.7500 (45.4167) kd_loss 1.0529 (1.0326) lr 2.0000e-03 eta 0:23:28
epoch [2/50] batch [140/319] time 0.078 (0.089) data 0.000 (0.005) loss 3.1177 (3.0630) teacher_loss 1.5408 (1.4995) loss_zs_kd 0.5189 (0.4757) loss_oracle 1.0550 (1.0619) acc 37.5000 (45.5134) kd_loss 1.0494 (1.0326) lr 2.0000e-03 eta 0:23:01
epoch [2/50] batch [160/319] time 0.077 (0.088) data 0.000 (0.004) loss 2.9308 (3.0428) teacher_loss 1.3376 (1.4779) loss_zs_kd 0.4631 (0.4842) loss_oracle 1.0616 (1.0610) acc 50.0000 (46.1719) kd_loss 1.0624 (1.0344) lr 2.0000e-03 eta 0:22:36
epoch [2/50] batch [180/319] time 0.081 (0.086) data 0.000 (0.004) loss 3.0596 (3.0349) teacher_loss 1.4945 (1.4709) loss_zs_kd 0.6379 (0.5004) loss_oracle 1.0547 (1.0606) acc 43.7500 (46.3715) kd_loss 1.0377 (1.0337) lr 2.0000e-03 eta 0:22:15
epoch [2/50] batch [200/319] time 0.081 (0.086) data 0.000 (0.003) loss 2.8956 (3.0254) teacher_loss 1.3736 (1.4652) loss_zs_kd 0.6674 (0.5202) loss_oracle 1.0371 (1.0589) acc 46.8750 (46.4062) kd_loss 1.0035 (1.0308) lr 2.0000e-03 eta 0:22:03
epoch [2/50] batch [220/319] time 0.072 (0.085) data 0.000 (0.003) loss 3.1520 (3.0107) teacher_loss 1.6519 (1.4562) loss_zs_kd 0.3932 (0.5216) loss_oracle 1.0236 (1.0564) acc 31.2500 (46.4062) kd_loss 0.9883 (1.0263) lr 2.0000e-03 eta 0:21:52
epoch [2/50] batch [240/319] time 0.088 (0.085) data 0.000 (0.003) loss 2.4746 (2.9889) teacher_loss 0.9756 (1.4395) loss_zs_kd 0.4891 (0.5131) loss_oracle 1.0213 (1.0535) acc 62.5000 (46.8880) kd_loss 0.9883 (1.0227) lr 2.0000e-03 eta 0:21:45
epoch [2/50] batch [260/319] time 0.073 (0.085) data 0.000 (0.003) loss 2.7646 (2.9599) teacher_loss 1.2935 (1.4174) loss_zs_kd 0.4363 (0.5144) loss_oracle 1.0045 (1.0497) acc 40.6250 (47.5481) kd_loss 0.9688 (1.0176) lr 2.0000e-03 eta 0:21:40
epoch [2/50] batch [280/319] time 0.084 (0.084) data 0.000 (0.002) loss 2.8066 (2.9467) teacher_loss 1.3513 (1.4105) loss_zs_kd 0.4167 (0.5123) loss_oracle 1.0100 (1.0469) acc 40.6250 (47.7455) kd_loss 0.9503 (1.0128) lr 2.0000e-03 eta 0:21:35
epoch [2/50] batch [300/319] time 0.073 (0.084) data 0.000 (0.002) loss 2.5436 (2.9358) teacher_loss 1.1027 (1.4058) loss_zs_kd 0.4758 (0.5136) loss_oracle 1.0124 (1.0445) acc 53.1250 (47.9792) kd_loss 0.9346 (1.0078) lr 2.0000e-03 eta 0:21:32
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,120
* accuracy: 48.4%
* error: 51.6%
* macro_f1: 36.3%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,486
* accuracy: 46.1%
* error: 53.9%
* macro_f1: 17.7%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      48.4%, epoch: 2 *******
******* Domain 2 best val test acc: 46.1%, epoch: 2 *******
******* Domain 2 best test acc:     46.1%, epoch: 2 *******
epoch [3/50] batch [20/319] time 0.080 (0.113) data 0.000 (0.031) loss 2.4115 (2.6234) teacher_loss 1.0089 (1.1996) loss_zs_kd 0.4173 (0.5066) loss_oracle 1.0100 (1.0125) acc 53.1250 (54.8438) kd_loss 0.8976 (0.9175) lr 1.9980e-03 eta 0:28:49
epoch [3/50] batch [40/319] time 0.079 (0.099) data 0.000 (0.016) loss 2.5258 (2.6431) teacher_loss 1.1386 (1.2312) loss_zs_kd 0.5511 (0.5177) loss_oracle 0.9818 (0.9988) acc 75.0000 (52.6562) kd_loss 0.8963 (0.9125) lr 1.9980e-03 eta 0:25:05
epoch [3/50] batch [60/319] time 0.092 (0.094) data 0.001 (0.011) loss 2.3759 (2.6240) teacher_loss 1.0183 (1.2170) loss_zs_kd 0.5972 (0.5319) loss_oracle 0.9428 (0.9983) acc 62.5000 (53.4375) kd_loss 0.8862 (0.9078) lr 1.9980e-03 eta 0:23:57
epoch [3/50] batch [80/319] time 0.084 (0.092) data 0.000 (0.008) loss 2.4373 (2.6231) teacher_loss 1.0648 (1.2203) loss_zs_kd 0.4949 (0.5477) loss_oracle 0.9342 (0.9912) acc 59.3750 (52.8125) kd_loss 0.9054 (0.9072) lr 1.9980e-03 eta 0:23:14
epoch [3/50] batch [100/319] time 0.089 (0.090) data 0.000 (0.006) loss 2.5208 (2.6241) teacher_loss 1.1631 (1.2232) loss_zs_kd 0.5140 (0.5394) loss_oracle 0.9887 (0.9891) acc 62.5000 (53.7188) kd_loss 0.8634 (0.9064) lr 1.9980e-03 eta 0:22:49
epoch [3/50] batch [120/319] time 0.081 (0.091) data 0.000 (0.005) loss 2.8805 (2.6295) teacher_loss 1.4155 (1.2221) loss_zs_kd 0.5278 (0.5376) loss_oracle 1.0215 (0.9912) acc 46.8750 (53.6979) kd_loss 0.9542 (0.9118) lr 1.9980e-03 eta 0:23:05
epoch [3/50] batch [140/319] time 0.082 (0.090) data 0.000 (0.005) loss 2.3634 (2.6223) teacher_loss 0.9843 (1.2162) loss_zs_kd 0.5412 (0.5402) loss_oracle 0.9590 (0.9903) acc 62.5000 (54.2411) kd_loss 0.8996 (0.9109) lr 1.9980e-03 eta 0:22:46
epoch [3/50] batch [160/319] time 0.082 (0.089) data 0.000 (0.004) loss 2.4474 (2.6084) teacher_loss 1.0907 (1.2056) loss_zs_kd 0.6872 (0.5506) loss_oracle 0.9473 (0.9888) acc 62.5000 (54.6484) kd_loss 0.8831 (0.9085) lr 1.9980e-03 eta 0:22:34
epoch [3/50] batch [180/319] time 0.078 (0.089) data 0.000 (0.004) loss 2.7584 (2.6102) teacher_loss 1.3458 (1.2072) loss_zs_kd 0.4451 (0.5584) loss_oracle 0.9962 (0.9918) acc 43.7500 (54.7049) kd_loss 0.9144 (0.9071) lr 1.9980e-03 eta 0:22:21
epoch [3/50] batch [200/319] time 0.076 (0.088) data 0.000 (0.003) loss 2.6124 (2.6010) teacher_loss 1.2523 (1.2038) loss_zs_kd 0.6085 (0.5541) loss_oracle 0.9396 (0.9862) acc 56.2500 (55.0000) kd_loss 0.8903 (0.9041) lr 1.9980e-03 eta 0:22:12
epoch [3/50] batch [220/319] time 0.080 (0.088) data 0.000 (0.003) loss 2.4708 (2.5926) teacher_loss 1.0375 (1.1981) loss_zs_kd 0.5229 (0.5610) loss_oracle 0.9752 (0.9819) acc 65.6250 (55.2415) kd_loss 0.9457 (0.9036) lr 1.9980e-03 eta 0:22:02
epoch [3/50] batch [240/319] time 0.089 (0.088) data 0.000 (0.003) loss 2.6633 (2.5835) teacher_loss 1.2734 (1.1913) loss_zs_kd 0.7482 (0.5682) loss_oracle 0.9486 (0.9782) acc 50.0000 (55.5729) kd_loss 0.9156 (0.9031) lr 1.9980e-03 eta 0:21:59
epoch [3/50] batch [260/319] time 0.084 (0.087) data 0.000 (0.003) loss 2.5562 (2.5855) teacher_loss 1.1891 (1.1940) loss_zs_kd 0.6348 (0.5755) loss_oracle 0.9539 (0.9750) acc 59.3750 (55.5409) kd_loss 0.8901 (0.9040) lr 1.9980e-03 eta 0:21:54
epoch [3/50] batch [280/319] time 0.087 (0.087) data 0.000 (0.003) loss 2.3635 (2.5759) teacher_loss 1.0264 (1.1880) loss_zs_kd 0.7511 (0.5862) loss_oracle 0.9002 (0.9697) acc 65.6250 (55.7366) kd_loss 0.8870 (0.9031) lr 1.9980e-03 eta 0:21:49
epoch [3/50] batch [300/319] time 0.090 (0.087) data 0.000 (0.002) loss 2.2648 (2.5696) teacher_loss 0.8957 (1.1851) loss_zs_kd 0.8643 (0.6008) loss_oracle 0.8965 (0.9633) acc 62.5000 (56.0312) kd_loss 0.9209 (0.9028) lr 1.9980e-03 eta 0:21:44
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,166
* accuracy: 49.5%
* error: 50.5%
* macro_f1: 38.6%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,168
* accuracy: 53.1%
* error: 46.9%
* macro_f1: 21.0%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      49.5%, epoch: 3 *******
******* Domain 2 best val test acc: 53.1%, epoch: 3 *******
******* Domain 2 best test acc:     53.1%, epoch: 3 *******
epoch [4/50] batch [20/319] time 0.082 (0.120) data 0.000 (0.033) loss 2.4480 (2.4251) teacher_loss 1.1251 (1.1037) loss_zs_kd 0.9057 (0.8968) loss_oracle 0.9257 (0.9097) acc 59.3750 (59.2188) kd_loss 0.8601 (0.8665) lr 1.9921e-03 eta 0:29:55
epoch [4/50] batch [40/319] time 0.078 (0.104) data 0.000 (0.016) loss 2.5145 (2.4329) teacher_loss 1.1174 (1.0986) loss_zs_kd 0.7519 (0.9202) loss_oracle 0.9135 (0.9117) acc 53.1250 (58.2031) kd_loss 0.9403 (0.8785) lr 1.9921e-03 eta 0:25:48
epoch [4/50] batch [60/319] time 0.078 (0.097) data 0.000 (0.011) loss 2.5124 (2.4177) teacher_loss 1.1650 (1.0896) loss_zs_kd 0.9526 (0.8840) loss_oracle 0.8919 (0.9080) acc 62.5000 (59.6875) kd_loss 0.9015 (0.8741) lr 1.9921e-03 eta 0:24:05
epoch [4/50] batch [80/319] time 0.087 (0.094) data 0.000 (0.008) loss 2.6204 (2.4216) teacher_loss 1.3068 (1.1003) loss_zs_kd 0.7487 (0.8621) loss_oracle 0.9653 (0.9075) acc 53.1250 (59.6094) kd_loss 0.8310 (0.8675) lr 1.9921e-03 eta 0:23:18
epoch [4/50] batch [100/319] time 0.083 (0.092) data 0.000 (0.007) loss 2.6893 (2.4158) teacher_loss 1.3597 (1.0979) loss_zs_kd 0.8047 (0.8476) loss_oracle 0.9452 (0.9096) acc 68.7500 (59.5312) kd_loss 0.8570 (0.8631) lr 1.9921e-03 eta 0:22:47
epoch [4/50] batch [120/319] time 0.082 (0.091) data 0.000 (0.006) loss 2.4587 (2.4157) teacher_loss 1.1958 (1.1003) loss_zs_kd 0.7336 (0.8360) loss_oracle 0.8506 (0.9078) acc 56.2500 (59.6615) kd_loss 0.8377 (0.8615) lr 1.9921e-03 eta 0:22:31
epoch [4/50] batch [140/319] time 0.090 (0.090) data 0.000 (0.005) loss 2.7180 (2.4217) teacher_loss 1.4310 (1.1053) loss_zs_kd 1.0365 (0.8423) loss_oracle 0.8480 (0.9032) acc 46.8750 (59.5536) kd_loss 0.8630 (0.8648) lr 1.9921e-03 eta 0:22:17
epoch [4/50] batch [160/319] time 0.088 (0.090) data 0.000 (0.004) loss 2.9955 (2.4310) teacher_loss 1.5602 (1.1100) loss_zs_kd 0.9891 (0.8481) loss_oracle 0.8986 (0.8995) acc 50.0000 (59.6875) kd_loss 0.9860 (0.8712) lr 1.9921e-03 eta 0:22:09
epoch [4/50] batch [180/319] time 0.084 (0.089) data 0.000 (0.004) loss 2.5312 (2.4451) teacher_loss 1.1589 (1.1158) loss_zs_kd 0.7348 (0.8506) loss_oracle 0.9172 (0.9006) acc 65.6250 (59.4444) kd_loss 0.9137 (0.8790) lr 1.9921e-03 eta 0:21:57
epoch [4/50] batch [200/319] time 0.082 (0.088) data 0.000 (0.004) loss 2.4050 (2.4529) teacher_loss 1.0796 (1.1222) loss_zs_kd 0.7518 (0.8441) loss_oracle 0.8687 (0.9018) acc 65.6250 (59.2969) kd_loss 0.8911 (0.8799) lr 1.9921e-03 eta 0:21:48
epoch [4/50] batch [220/319] time 0.085 (0.088) data 0.000 (0.003) loss 2.5231 (2.4501) teacher_loss 1.2412 (1.1204) loss_zs_kd 0.8722 (0.8401) loss_oracle 0.9126 (0.9005) acc 53.1250 (59.5312) kd_loss 0.8256 (0.8795) lr 1.9921e-03 eta 0:21:40
epoch [4/50] batch [240/319] time 0.080 (0.088) data 0.000 (0.003) loss 2.4899 (2.4529) teacher_loss 1.2614 (1.1240) loss_zs_kd 0.8114 (0.8386) loss_oracle 0.9100 (0.9012) acc 53.1250 (59.5182) kd_loss 0.7734 (0.8783) lr 1.9921e-03 eta 0:21:34
epoch [4/50] batch [260/319] time 0.081 (0.087) data 0.000 (0.003) loss 2.5828 (2.4523) teacher_loss 1.2866 (1.1269) loss_zs_kd 0.9639 (0.8396) loss_oracle 0.9174 (0.9012) acc 43.7500 (59.4712) kd_loss 0.8375 (0.8748) lr 1.9921e-03 eta 0:21:23
epoch [4/50] batch [280/319] time 0.080 (0.088) data 0.000 (0.003) loss 2.3157 (2.4462) teacher_loss 1.0981 (1.1250) loss_zs_kd 0.8178 (0.8392) loss_oracle 0.8715 (0.9006) acc 59.3750 (59.5871) kd_loss 0.7818 (0.8710) lr 1.9921e-03 eta 0:21:41
epoch [4/50] batch [300/319] time 0.081 (0.088) data 0.000 (0.002) loss 2.1892 (2.4412) teacher_loss 0.8976 (1.1218) loss_zs_kd 0.9963 (0.8392) loss_oracle 0.8434 (0.8989) acc 68.7500 (59.6042) kd_loss 0.8699 (0.8699) lr 1.9921e-03 eta 0:21:33
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,286
* accuracy: 52.2%
* error: 47.8%
* macro_f1: 41.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,173
* accuracy: 53.1%
* error: 46.9%
* macro_f1: 19.3%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      52.2%, epoch: 4 *******
******* Domain 2 best val test acc: 53.1%, epoch: 4 *******
******* Domain 2 best test acc:     53.1%, epoch: 4 *******
epoch [5/50] batch [20/319] time 0.093 (0.114) data 0.000 (0.030) loss 2.3745 (2.3726) teacher_loss 1.1239 (1.1006) loss_zs_kd 0.8057 (0.8886) loss_oracle 0.8107 (0.8522) acc 59.3750 (56.7188) kd_loss 0.8453 (0.8459) lr 1.9823e-03 eta 0:27:46
epoch [5/50] batch [40/319] time 0.078 (0.100) data 0.000 (0.015) loss 2.1061 (2.3751) teacher_loss 0.7861 (1.1145) loss_zs_kd 0.9112 (0.9206) loss_oracle 0.8739 (0.8518) acc 71.8750 (57.9688) kd_loss 0.8831 (0.8347) lr 1.9823e-03 eta 0:24:26
epoch [5/50] batch [60/319] time 0.070 (0.092) data 0.001 (0.010) loss 2.2348 (2.3903) teacher_loss 0.9940 (1.1260) loss_zs_kd 0.9991 (0.8988) loss_oracle 0.8814 (0.8566) acc 62.5000 (57.8125) kd_loss 0.8001 (0.8359) lr 1.9823e-03 eta 0:22:27
epoch [5/50] batch [80/319] time 0.078 (0.092) data 0.000 (0.008) loss 2.0201 (2.3670) teacher_loss 0.7618 (1.1154) loss_zs_kd 0.7968 (0.8969) loss_oracle 0.8604 (0.8504) acc 81.2500 (58.7891) kd_loss 0.8281 (0.8264) lr 1.9823e-03 eta 0:22:29
epoch [5/50] batch [100/319] time 0.080 (0.091) data 0.000 (0.006) loss 2.4503 (2.3516) teacher_loss 1.1273 (1.1023) loss_zs_kd 0.9688 (0.9092) loss_oracle 0.8688 (0.8486) acc 56.2500 (59.4062) kd_loss 0.8886 (0.8249) lr 1.9823e-03 eta 0:22:06
epoch [5/50] batch [120/319] time 0.079 (0.090) data 0.000 (0.005) loss 2.4377 (2.3670) teacher_loss 1.1232 (1.1141) loss_zs_kd 0.7293 (0.8946) loss_oracle 0.8570 (0.8520) acc 56.2500 (59.0104) kd_loss 0.8860 (0.8269) lr 1.9823e-03 eta 0:21:47
epoch [5/50] batch [140/319] time 0.061 (0.088) data 0.000 (0.005) loss 2.7598 (2.3715) teacher_loss 1.4051 (1.1113) loss_zs_kd 0.8207 (0.8903) loss_oracle 0.8772 (0.8535) acc 43.7500 (59.2411) kd_loss 0.9161 (0.8334) lr 1.9823e-03 eta 0:21:17
epoch [5/50] batch [160/319] time 0.078 (0.087) data 0.000 (0.004) loss 2.7401 (2.3930) teacher_loss 1.2800 (1.1156) loss_zs_kd 0.7655 (0.8818) loss_oracle 0.8483 (0.8575) acc 56.2500 (58.8086) kd_loss 1.0359 (0.8487) lr 1.9823e-03 eta 0:21:02
epoch [5/50] batch [180/319] time 0.093 (0.087) data 0.000 (0.004) loss 2.3916 (2.4121) teacher_loss 0.9638 (1.1184) loss_zs_kd 0.9505 (0.8782) loss_oracle 0.8929 (0.8599) acc 68.7500 (58.4549) kd_loss 0.9813 (0.8637) lr 1.9823e-03 eta 0:20:58
epoch [5/50] batch [200/319] time 0.087 (0.087) data 0.000 (0.003) loss 2.4847 (2.4200) teacher_loss 1.0838 (1.1212) loss_zs_kd 0.9333 (0.8712) loss_oracle 0.9290 (0.8624) acc 62.5000 (58.3281) kd_loss 0.9364 (0.8677) lr 1.9823e-03 eta 0:20:52
epoch [5/50] batch [220/319] time 0.076 (0.086) data 0.000 (0.003) loss 2.3804 (2.4346) teacher_loss 0.9894 (1.1266) loss_zs_kd 0.8029 (0.8621) loss_oracle 0.9231 (0.8669) acc 62.5000 (57.9403) kd_loss 0.9294 (0.8745) lr 1.9823e-03 eta 0:20:43
epoch [5/50] batch [240/319] time 0.096 (0.086) data 0.000 (0.003) loss 2.4541 (2.4481) teacher_loss 1.0768 (1.1322) loss_zs_kd 0.6923 (0.8582) loss_oracle 0.9345 (0.8713) acc 50.0000 (57.5911) kd_loss 0.9100 (0.8803) lr 1.9823e-03 eta 0:20:35
epoch [5/50] batch [260/319] time 0.081 (0.085) data 0.000 (0.003) loss 2.7507 (2.4537) teacher_loss 1.4198 (1.1342) loss_zs_kd 0.9696 (0.8588) loss_oracle 0.8863 (0.8749) acc 40.6250 (57.4159) kd_loss 0.8878 (0.8821) lr 1.9823e-03 eta 0:20:25
epoch [5/50] batch [280/319] time 0.080 (0.085) data 0.000 (0.002) loss 2.1527 (2.4560) teacher_loss 0.7771 (1.1350) loss_zs_kd 0.5607 (0.8544) loss_oracle 0.8980 (0.8764) acc 78.1250 (57.4107) kd_loss 0.9266 (0.8828) lr 1.9823e-03 eta 0:20:23
epoch [5/50] batch [300/319] time 0.075 (0.085) data 0.000 (0.002) loss 2.5341 (2.4550) teacher_loss 1.2678 (1.1365) loss_zs_kd 0.7188 (0.8478) loss_oracle 0.8731 (0.8766) acc 56.2500 (57.5417) kd_loss 0.8298 (0.8802) lr 1.9823e-03 eta 0:20:22
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,682
* accuracy: 61.3%
* error: 38.7%
* macro_f1: 52.1%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,630
* accuracy: 47.6%
* error: 52.4%
* macro_f1: 21.1%
******* Domain 2 best val acc:      61.3%, epoch: 5 *******
******* Domain 2 best val test acc: 47.6%, epoch: 5 *******
******* Domain 2 best test acc:     53.1%, epoch: 4 *******
epoch [6/50] batch [20/319] time 0.098 (0.093) data 0.000 (0.024) loss 2.5097 (2.3920) teacher_loss 1.1871 (1.0992) loss_zs_kd 0.8320 (0.7728) loss_oracle 0.8761 (0.8714) acc 46.8750 (62.1875) kd_loss 0.8845 (0.8571) lr 1.9686e-03 eta 0:22:18
epoch [6/50] batch [40/319] time 0.087 (0.088) data 0.000 (0.012) loss 2.3486 (2.3404) teacher_loss 1.0845 (1.0538) loss_zs_kd 0.7921 (0.7877) loss_oracle 0.8699 (0.8744) acc 68.7500 (64.8438) kd_loss 0.8291 (0.8494) lr 1.9686e-03 eta 0:20:55
epoch [6/50] batch [60/319] time 0.082 (0.088) data 0.001 (0.008) loss 2.5061 (2.3686) teacher_loss 1.2121 (1.0869) loss_zs_kd 0.7803 (0.7775) loss_oracle 0.8758 (0.8728) acc 50.0000 (61.5104) kd_loss 0.8560 (0.8452) lr 1.9686e-03 eta 0:20:59
epoch [6/50] batch [80/319] time 0.087 (0.087) data 0.000 (0.006) loss 2.4844 (2.3783) teacher_loss 1.1973 (1.0981) loss_zs_kd 0.7880 (0.7742) loss_oracle 0.8842 (0.8732) acc 56.2500 (59.9219) kd_loss 0.8450 (0.8436) lr 1.9686e-03 eta 0:20:44
epoch [6/50] batch [100/319] time 0.075 (0.086) data 0.000 (0.005) loss 2.3190 (2.3956) teacher_loss 1.0144 (1.1156) loss_zs_kd 0.8184 (0.7638) loss_oracle 0.9020 (0.8748) acc 59.3750 (59.0000) kd_loss 0.8536 (0.8426) lr 1.9686e-03 eta 0:20:32
epoch [6/50] batch [120/319] time 0.064 (0.083) data 0.000 (0.004) loss 2.3671 (2.3959) teacher_loss 1.0565 (1.1115) loss_zs_kd 0.9541 (0.7755) loss_oracle 0.8983 (0.8779) acc 46.8750 (59.3490) kd_loss 0.8614 (0.8455) lr 1.9686e-03 eta 0:19:39
epoch [6/50] batch [140/319] time 0.071 (0.080) data 0.000 (0.004) loss 2.5644 (2.3930) teacher_loss 1.3222 (1.1088) loss_zs_kd 0.7956 (0.7854) loss_oracle 0.8914 (0.8800) acc 59.3750 (59.5982) kd_loss 0.7965 (0.8442) lr 1.9686e-03 eta 0:19:01
epoch [6/50] batch [160/319] time 0.062 (0.078) data 0.000 (0.003) loss 2.4105 (2.3860) teacher_loss 1.0852 (1.1014) loss_zs_kd 0.7594 (0.7986) loss_oracle 0.8862 (0.8810) acc 65.6250 (59.9609) kd_loss 0.8822 (0.8440) lr 1.9686e-03 eta 0:18:32
epoch [6/50] batch [180/319] time 0.064 (0.077) data 0.000 (0.003) loss 2.5791 (2.3930) teacher_loss 1.3273 (1.1085) loss_zs_kd 0.8176 (0.8000) loss_oracle 0.8882 (0.8814) acc 46.8750 (59.3924) kd_loss 0.8078 (0.8438) lr 1.9686e-03 eta 0:18:07
epoch [6/50] batch [200/319] time 0.082 (0.076) data 0.000 (0.003) loss 2.3335 (2.3870) teacher_loss 1.0670 (1.1039) loss_zs_kd 0.7285 (0.7917) loss_oracle 0.8763 (0.8813) acc 62.5000 (59.5000) kd_loss 0.8283 (0.8424) lr 1.9686e-03 eta 0:17:53
epoch [6/50] batch [220/319] time 0.077 (0.076) data 0.000 (0.002) loss 2.3399 (2.3879) teacher_loss 1.0074 (1.1044) loss_zs_kd 0.8321 (0.7995) loss_oracle 0.8814 (0.8814) acc 62.5000 (59.4318) kd_loss 0.8919 (0.8428) lr 1.9686e-03 eta 0:18:00
epoch [6/50] batch [240/319] time 0.071 (0.077) data 0.000 (0.002) loss 2.6939 (2.3944) teacher_loss 1.4383 (1.1117) loss_zs_kd 0.7641 (0.7973) loss_oracle 0.8736 (0.8812) acc 37.5000 (59.0365) kd_loss 0.8189 (0.8422) lr 1.9686e-03 eta 0:18:05
epoch [6/50] batch [260/319] time 0.086 (0.077) data 0.000 (0.002) loss 2.2151 (2.3930) teacher_loss 0.8988 (1.1104) loss_zs_kd 0.7988 (0.7923) loss_oracle 0.8803 (0.8809) acc 68.7500 (59.0625) kd_loss 0.8762 (0.8421) lr 1.9686e-03 eta 0:18:11
epoch [6/50] batch [280/319] time 0.077 (0.079) data 0.000 (0.002) loss 2.3475 (2.3937) teacher_loss 1.0645 (1.1113) loss_zs_kd 0.7006 (0.7905) loss_oracle 0.8785 (0.8807) acc 56.2500 (59.1183) kd_loss 0.8437 (0.8420) lr 1.9686e-03 eta 0:18:32
epoch [6/50] batch [300/319] time 0.082 (0.079) data 0.000 (0.002) loss 2.2828 (2.3915) teacher_loss 1.0006 (1.1099) loss_zs_kd 0.8069 (0.7850) loss_oracle 0.8764 (0.8805) acc 68.7500 (59.2292) kd_loss 0.8440 (0.8413) lr 1.9686e-03 eta 0:18:32
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,678
* accuracy: 61.2%
* error: 38.8%
* macro_f1: 53.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,031
* accuracy: 51.7%
* error: 48.3%
* macro_f1: 22.2%
******* Domain 2 best val acc:      61.3%, epoch: 5 *******
******* Domain 2 best val test acc: 47.6%, epoch: 5 *******
******* Domain 2 best test acc:     53.1%, epoch: 4 *******
epoch [7/50] batch [20/319] time 0.073 (0.116) data 0.000 (0.032) loss 1.9871 (2.3243) teacher_loss 0.7209 (1.0672) loss_zs_kd 0.7846 (0.7698) loss_oracle 0.8784 (0.8770) acc 68.7500 (62.0312) kd_loss 0.8270 (0.8186) lr 1.9511e-03 eta 0:27:08
epoch [7/50] batch [40/319] time 0.083 (0.099) data 0.000 (0.016) loss 2.6470 (2.3613) teacher_loss 1.3597 (1.1057) loss_zs_kd 0.8105 (0.7677) loss_oracle 0.8739 (0.8766) acc 56.2500 (59.4531) kd_loss 0.8504 (0.8173) lr 1.9511e-03 eta 0:23:03
epoch [7/50] batch [60/319] time 0.070 (0.097) data 0.001 (0.011) loss 2.2656 (2.3227) teacher_loss 0.9606 (1.0644) loss_zs_kd 0.8591 (0.7812) loss_oracle 0.8747 (0.8760) acc 68.7500 (60.9896) kd_loss 0.8676 (0.8203) lr 1.9511e-03 eta 0:22:40
epoch [7/50] batch [80/319] time 0.080 (0.093) data 0.000 (0.008) loss 2.2980 (2.3248) teacher_loss 1.0678 (1.0666) loss_zs_kd 0.7475 (0.7861) loss_oracle 0.8747 (0.8755) acc 68.7500 (61.9141) kd_loss 0.7928 (0.8204) lr 1.9511e-03 eta 0:21:42
epoch [7/50] batch [100/319] time 0.088 (0.091) data 0.000 (0.007) loss 2.3331 (2.3315) teacher_loss 1.0699 (1.0714) loss_zs_kd 0.7605 (0.7868) loss_oracle 0.8735 (0.8754) acc 65.6250 (61.3438) kd_loss 0.8264 (0.8223) lr 1.9511e-03 eta 0:21:12
epoch [7/50] batch [120/319] time 0.088 (0.090) data 0.000 (0.006) loss 2.6829 (2.3215) teacher_loss 1.4285 (1.0614) loss_zs_kd 0.8192 (0.7945) loss_oracle 0.8753 (0.8755) acc 53.1250 (61.7188) kd_loss 0.8168 (0.8224) lr 1.9511e-03 eta 0:20:46
epoch [7/50] batch [140/319] time 0.079 (0.088) data 0.000 (0.005) loss 2.3395 (2.3240) teacher_loss 1.0737 (1.0627) loss_zs_kd 0.7229 (0.7916) loss_oracle 0.8750 (0.8755) acc 56.2500 (61.7634) kd_loss 0.8282 (0.8235) lr 1.9511e-03 eta 0:20:27
epoch [7/50] batch [160/319] time 0.086 (0.087) data 0.000 (0.004) loss 2.1949 (2.3296) teacher_loss 0.9341 (1.0678) loss_zs_kd 0.7225 (0.7885) loss_oracle 0.8750 (0.8754) acc 59.3750 (61.4258) kd_loss 0.8233 (0.8241) lr 1.9511e-03 eta 0:20:11
epoch [7/50] batch [180/319] time 0.078 (0.087) data 0.000 (0.004) loss 2.3391 (2.3394) teacher_loss 1.0446 (1.0784) loss_zs_kd 0.8733 (0.7953) loss_oracle 0.8744 (0.8753) acc 59.3750 (60.5556) kd_loss 0.8572 (0.8234) lr 1.9511e-03 eta 0:20:01
epoch [7/50] batch [200/319] time 0.075 (0.086) data 0.000 (0.003) loss 2.6947 (2.3358) teacher_loss 1.3976 (1.0734) loss_zs_kd 0.9987 (0.7994) loss_oracle 0.8752 (0.8753) acc 62.5000 (60.6406) kd_loss 0.8595 (0.8247) lr 1.9511e-03 eta 0:19:52
epoch [7/50] batch [220/319] time 0.081 (0.086) data 0.000 (0.003) loss 2.4771 (2.3291) teacher_loss 1.1962 (1.0656) loss_zs_kd 0.9627 (0.8087) loss_oracle 0.8748 (0.8753) acc 56.2500 (60.8807) kd_loss 0.8435 (0.8258) lr 1.9511e-03 eta 0:19:46
epoch [7/50] batch [240/319] time 0.088 (0.086) data 0.000 (0.003) loss 2.5583 (2.3294) teacher_loss 1.3008 (1.0659) loss_zs_kd 0.8685 (0.8207) loss_oracle 0.8738 (0.8752) acc 53.1250 (60.6901) kd_loss 0.8206 (0.8259) lr 1.9511e-03 eta 0:19:45
epoch [7/50] batch [260/319] time 0.076 (0.085) data 0.000 (0.003) loss 2.2591 (2.3324) teacher_loss 0.9911 (1.0699) loss_zs_kd 0.7461 (0.8169) loss_oracle 0.8745 (0.8751) acc 65.6250 (60.4567) kd_loss 0.8307 (0.8249) lr 1.9511e-03 eta 0:19:37
epoch [7/50] batch [280/319] time 0.081 (0.085) data 0.000 (0.003) loss 2.2410 (2.3338) teacher_loss 0.9861 (1.0720) loss_zs_kd 0.9522 (0.8155) loss_oracle 0.8742 (0.8751) acc 59.3750 (60.4464) kd_loss 0.8179 (0.8242) lr 1.9511e-03 eta 0:19:26
epoch [7/50] batch [300/319] time 0.075 (0.084) data 0.000 (0.002) loss 2.2767 (2.3323) teacher_loss 1.0246 (1.0713) loss_zs_kd 0.8720 (0.8128) loss_oracle 0.8749 (0.8750) acc 62.5000 (60.4479) kd_loss 0.8147 (0.8234) lr 1.9511e-03 eta 0:19:18
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,748
* accuracy: 62.8%
* error: 37.2%
* macro_f1: 54.3%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,959
* accuracy: 50.9%
* error: 49.1%
* macro_f1: 21.2%
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     53.1%, epoch: 4 *******
epoch [8/50] batch [20/319] time 0.089 (0.117) data 0.000 (0.031) loss 2.5010 (2.4083) teacher_loss 1.1942 (1.1386) loss_zs_kd 0.7658 (0.7232) loss_oracle 0.8737 (0.8735) acc 53.1250 (55.7812) kd_loss 0.8700 (0.8330) lr 1.9298e-03 eta 0:26:40
epoch [8/50] batch [40/319] time 0.073 (0.099) data 0.000 (0.016) loss 2.0722 (2.3575) teacher_loss 0.8232 (1.0881) loss_zs_kd 0.8730 (0.7930) loss_oracle 0.8709 (0.8729) acc 68.7500 (57.6562) kd_loss 0.8135 (0.8330) lr 1.9298e-03 eta 0:22:38
epoch [8/50] batch [60/319] time 0.081 (0.093) data 0.000 (0.011) loss 2.2994 (2.3433) teacher_loss 1.0489 (1.0774) loss_zs_kd 0.7718 (0.7940) loss_oracle 0.8721 (0.8725) acc 59.3750 (59.4271) kd_loss 0.8144 (0.8297) lr 1.9298e-03 eta 0:21:15
epoch [8/50] batch [80/319] time 0.074 (0.089) data 0.000 (0.008) loss 2.3079 (2.3265) teacher_loss 1.0532 (1.0645) loss_zs_kd 0.6618 (0.7801) loss_oracle 0.8718 (0.8724) acc 65.6250 (60.1562) kd_loss 0.8188 (0.8257) lr 1.9298e-03 eta 0:20:20
epoch [8/50] batch [100/319] time 0.068 (0.086) data 0.000 (0.006) loss 2.1377 (2.3330) teacher_loss 0.9066 (1.0755) loss_zs_kd 0.8122 (0.7800) loss_oracle 0.8725 (0.8726) acc 71.8750 (60.0000) kd_loss 0.7948 (0.8212) lr 1.9298e-03 eta 0:19:30
epoch [8/50] batch [120/319] time 0.077 (0.084) data 0.000 (0.005) loss 2.5606 (2.3288) teacher_loss 1.2938 (1.0714) loss_zs_kd 0.9034 (0.7789) loss_oracle 0.8739 (0.8725) acc 50.0000 (59.9219) kd_loss 0.8299 (0.8212) lr 1.9298e-03 eta 0:19:04
epoch [8/50] batch [140/319] time 0.076 (0.083) data 0.000 (0.005) loss 2.3604 (2.3362) teacher_loss 1.1233 (1.0807) loss_zs_kd 0.9831 (0.7739) loss_oracle 0.8724 (0.8725) acc 56.2500 (59.5759) kd_loss 0.8009 (0.8193) lr 1.9298e-03 eta 0:18:49
epoch [8/50] batch [160/319] time 0.075 (0.082) data 0.000 (0.004) loss 2.5010 (2.3366) teacher_loss 1.1670 (1.0841) loss_zs_kd 0.6883 (0.7736) loss_oracle 0.8731 (0.8727) acc 53.1250 (59.3945) kd_loss 0.8975 (0.8161) lr 1.9298e-03 eta 0:18:37
epoch [8/50] batch [180/319] time 0.079 (0.081) data 0.000 (0.004) loss 2.4937 (2.3359) teacher_loss 1.3403 (1.0853) loss_zs_kd 0.7406 (0.7835) loss_oracle 0.8754 (0.8728) acc 53.1250 (59.5312) kd_loss 0.7157 (0.8141) lr 1.9298e-03 eta 0:18:23
epoch [8/50] batch [200/319] time 0.072 (0.081) data 0.000 (0.003) loss 2.2160 (2.3306) teacher_loss 1.0084 (1.0808) loss_zs_kd 1.0248 (0.7896) loss_oracle 0.8714 (0.8728) acc 59.3750 (59.6250) kd_loss 0.7719 (0.8134) lr 1.9298e-03 eta 0:18:15
epoch [8/50] batch [220/319] time 0.076 (0.081) data 0.000 (0.003) loss 2.1145 (2.3281) teacher_loss 0.8761 (1.0778) loss_zs_kd 0.8812 (0.7929) loss_oracle 0.8722 (0.8727) acc 68.7500 (60.0000) kd_loss 0.8024 (0.8139) lr 1.9298e-03 eta 0:18:07
epoch [8/50] batch [240/319] time 0.067 (0.082) data 0.000 (0.003) loss 2.6580 (2.3189) teacher_loss 1.4073 (1.0696) loss_zs_kd 0.8195 (0.7970) loss_oracle 0.8726 (0.8726) acc 59.3750 (60.4167) kd_loss 0.8143 (0.8130) lr 1.9298e-03 eta 0:18:24
epoch [8/50] batch [260/319] time 0.079 (0.082) data 0.000 (0.003) loss 2.5705 (2.3152) teacher_loss 1.3033 (1.0660) loss_zs_kd 0.8667 (0.8012) loss_oracle 0.8736 (0.8726) acc 53.1250 (60.9135) kd_loss 0.8304 (0.8129) lr 1.9298e-03 eta 0:18:18
epoch [8/50] batch [280/319] time 0.081 (0.082) data 0.000 (0.002) loss 2.5944 (2.3106) teacher_loss 1.3489 (1.0611) loss_zs_kd 0.7603 (0.8024) loss_oracle 0.8708 (0.8725) acc 50.0000 (60.9933) kd_loss 0.8101 (0.8132) lr 1.9298e-03 eta 0:18:17
epoch [8/50] batch [300/319] time 0.082 (0.082) data 0.000 (0.002) loss 2.5729 (2.3174) teacher_loss 1.3162 (1.0673) loss_zs_kd 0.7211 (0.8050) loss_oracle 0.8724 (0.8725) acc 53.1250 (60.7188) kd_loss 0.8205 (0.8139) lr 1.9298e-03 eta 0:18:14
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,533
* accuracy: 57.9%
* error: 42.1%
* macro_f1: 51.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,358
* accuracy: 55.0%
* error: 45.0%
* macro_f1: 21.7%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     55.0%, epoch: 8 *******
epoch [9/50] batch [20/319] time 0.062 (0.127) data 0.000 (0.033) loss 2.1349 (2.2225) teacher_loss 0.8763 (0.9659) loss_zs_kd 0.9097 (0.9453) loss_oracle 0.8704 (0.8703) acc 65.6250 (62.9688) kd_loss 0.8234 (0.8215) lr 1.9048e-03 eta 0:28:22
epoch [9/50] batch [40/319] time 0.081 (0.102) data 0.000 (0.017) loss 2.1318 (2.2326) teacher_loss 0.9000 (0.9780) loss_zs_kd 0.9440 (0.9358) loss_oracle 0.8678 (0.8699) acc 59.3750 (63.7500) kd_loss 0.7980 (0.8197) lr 1.9048e-03 eta 0:22:36
epoch [9/50] batch [60/319] time 0.081 (0.094) data 0.000 (0.011) loss 2.4279 (2.2651) teacher_loss 1.1586 (1.0100) loss_zs_kd 0.8408 (0.9055) loss_oracle 0.8710 (0.8697) acc 46.8750 (62.3438) kd_loss 0.8338 (0.8203) lr 1.9048e-03 eta 0:20:57
epoch [9/50] batch [80/319] time 0.080 (0.091) data 0.000 (0.009) loss 2.3327 (2.2756) teacher_loss 1.0777 (1.0232) loss_zs_kd 0.8345 (0.9094) loss_oracle 0.8682 (0.8697) acc 68.7500 (62.7734) kd_loss 0.8209 (0.8176) lr 1.9048e-03 eta 0:20:15
epoch [9/50] batch [100/319] time 0.079 (0.089) data 0.000 (0.007) loss 2.3760 (2.2806) teacher_loss 1.1636 (1.0291) loss_zs_kd 0.6662 (0.8808) loss_oracle 0.8749 (0.8702) acc 59.3750 (62.9375) kd_loss 0.7749 (0.8164) lr 1.9048e-03 eta 0:19:39
epoch [9/50] batch [120/319] time 0.075 (0.087) data 0.000 (0.006) loss 2.3506 (2.2920) teacher_loss 1.0511 (1.0432) loss_zs_kd 0.6312 (0.8549) loss_oracle 0.8775 (0.8707) acc 75.0000 (62.5781) kd_loss 0.8608 (0.8135) lr 1.9048e-03 eta 0:19:13
epoch [9/50] batch [140/319] time 0.085 (0.086) data 0.000 (0.005) loss 2.8062 (2.3047) teacher_loss 1.5493 (1.0592) loss_zs_kd 0.7318 (0.8397) loss_oracle 0.8730 (0.8711) acc 40.6250 (61.4062) kd_loss 0.8204 (0.8100) lr 1.9048e-03 eta 0:18:59
epoch [9/50] batch [160/319] time 0.075 (0.085) data 0.000 (0.004) loss 2.3358 (2.3012) teacher_loss 1.0582 (1.0553) loss_zs_kd 0.8212 (0.8329) loss_oracle 0.8719 (0.8714) acc 62.5000 (61.6406) kd_loss 0.8417 (0.8102) lr 1.9048e-03 eta 0:18:45
epoch [9/50] batch [180/319] time 0.080 (0.084) data 0.000 (0.004) loss 2.0206 (2.2913) teacher_loss 0.7908 (1.0454) loss_zs_kd 0.9951 (0.8379) loss_oracle 0.8661 (0.8715) acc 78.1250 (62.0139) kd_loss 0.7968 (0.8102) lr 1.9048e-03 eta 0:18:34
epoch [9/50] batch [200/319] time 0.064 (0.083) data 0.000 (0.004) loss 2.1951 (2.2900) teacher_loss 0.9317 (1.0441) loss_zs_kd 0.8174 (0.8459) loss_oracle 0.8707 (0.8713) acc 68.7500 (62.0312) kd_loss 0.8281 (0.8102) lr 1.9048e-03 eta 0:18:14
epoch [9/50] batch [220/319] time 0.083 (0.083) data 0.000 (0.003) loss 2.0981 (2.2840) teacher_loss 0.8207 (1.0369) loss_zs_kd 0.8386 (0.8470) loss_oracle 0.8652 (0.8713) acc 71.8750 (62.3722) kd_loss 0.8449 (0.8115) lr 1.9048e-03 eta 0:18:10
epoch [9/50] batch [240/319] time 0.090 (0.082) data 0.001 (0.003) loss 2.3276 (2.2864) teacher_loss 1.0927 (1.0388) loss_zs_kd 1.1154 (0.8542) loss_oracle 0.8667 (0.8710) acc 62.5000 (62.4870) kd_loss 0.8016 (0.8120) lr 1.9048e-03 eta 0:18:05
epoch [9/50] batch [260/319] time 0.079 (0.082) data 0.000 (0.003) loss 2.3164 (2.2865) teacher_loss 1.0616 (1.0387) loss_zs_kd 0.8300 (0.8617) loss_oracle 0.8711 (0.8709) acc 59.3750 (62.2716) kd_loss 0.8192 (0.8124) lr 1.9048e-03 eta 0:18:01
epoch [9/50] batch [280/319] time 0.077 (0.082) data 0.000 (0.003) loss 2.2211 (2.2933) teacher_loss 0.9525 (1.0454) loss_zs_kd 1.0350 (0.8664) loss_oracle 0.8653 (0.8707) acc 62.5000 (61.8973) kd_loss 0.8359 (0.8125) lr 1.9048e-03 eta 0:17:58
epoch [9/50] batch [300/319] time 0.078 (0.082) data 0.000 (0.003) loss 2.3562 (2.2933) teacher_loss 1.1391 (1.0451) loss_zs_kd 0.8319 (0.8683) loss_oracle 0.8680 (0.8707) acc 59.3750 (61.9271) kd_loss 0.7832 (0.8128) lr 1.9048e-03 eta 0:17:55
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,694
* accuracy: 61.5%
* error: 38.5%
* macro_f1: 52.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,465
* accuracy: 56.1%
* error: 43.9%
* macro_f1: 21.9%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     56.1%, epoch: 9 *******
epoch [10/50] batch [20/319] time 0.107 (0.117) data 0.000 (0.029) loss 2.4526 (2.3622) teacher_loss 1.2424 (1.1096) loss_zs_kd 0.7892 (0.7713) loss_oracle 0.8724 (0.8722) acc 62.5000 (60.4688) kd_loss 0.7740 (0.8165) lr 1.8763e-03 eta 0:25:32
epoch [10/50] batch [40/319] time 0.074 (0.097) data 0.000 (0.015) loss 2.4841 (2.3545) teacher_loss 1.2012 (1.0988) loss_zs_kd 0.6572 (0.7355) loss_oracle 0.8715 (0.8714) acc 59.3750 (58.5938) kd_loss 0.8471 (0.8200) lr 1.8763e-03 eta 0:21:06
epoch [10/50] batch [60/319] time 0.084 (0.091) data 0.000 (0.010) loss 2.5980 (2.3411) teacher_loss 1.3976 (1.0868) loss_zs_kd 0.6413 (0.7128) loss_oracle 0.8723 (0.8715) acc 53.1250 (59.2708) kd_loss 0.7643 (0.8185) lr 1.8763e-03 eta 0:19:50
epoch [10/50] batch [80/319] time 0.087 (0.090) data 0.001 (0.007) loss 1.9885 (2.3408) teacher_loss 0.7960 (1.0909) loss_zs_kd 0.6324 (0.6958) loss_oracle 0.8712 (0.8719) acc 71.8750 (58.9062) kd_loss 0.7569 (0.8139) lr 1.8763e-03 eta 0:19:23
epoch [10/50] batch [100/319] time 0.084 (0.088) data 0.000 (0.006) loss 2.1083 (2.3511) teacher_loss 0.8475 (1.1019) loss_zs_kd 0.5477 (0.6901) loss_oracle 0.8699 (0.8721) acc 71.8750 (58.5938) kd_loss 0.8259 (0.8132) lr 1.8763e-03 eta 0:19:00
epoch [10/50] batch [120/319] time 0.085 (0.087) data 0.001 (0.005) loss 2.3512 (2.3482) teacher_loss 1.0824 (1.0988) loss_zs_kd 0.6524 (0.6868) loss_oracle 0.8745 (0.8721) acc 59.3750 (59.0104) kd_loss 0.8314 (0.8133) lr 1.8763e-03 eta 0:18:50
epoch [10/50] batch [140/319] time 0.088 (0.087) data 0.000 (0.004) loss 2.2310 (2.3355) teacher_loss 1.0332 (1.0883) loss_zs_kd 0.6274 (0.6842) loss_oracle 0.8741 (0.8720) acc 56.2500 (59.6875) kd_loss 0.7608 (0.8112) lr 1.8763e-03 eta 0:18:45
epoch [10/50] batch [160/319] time 0.082 (0.086) data 0.000 (0.004) loss 2.2933 (2.3310) teacher_loss 1.0955 (1.0844) loss_zs_kd 0.8477 (0.6881) loss_oracle 0.8715 (0.8720) acc 56.2500 (59.9805) kd_loss 0.7620 (0.8106) lr 1.8763e-03 eta 0:18:36
epoch [10/50] batch [180/319] time 0.093 (0.086) data 0.000 (0.003) loss 2.3251 (2.3387) teacher_loss 1.1080 (1.0921) loss_zs_kd 0.5626 (0.6946) loss_oracle 0.8671 (0.8718) acc 71.8750 (59.9132) kd_loss 0.7836 (0.8107) lr 1.8763e-03 eta 0:18:32
epoch [10/50] batch [200/319] time 0.073 (0.087) data 0.000 (0.003) loss 2.0276 (2.3365) teacher_loss 0.8089 (1.0914) loss_zs_kd 0.6309 (0.6872) loss_oracle 0.8705 (0.8717) acc 71.8750 (59.7812) kd_loss 0.7834 (0.8093) lr 1.8763e-03 eta 0:18:41
epoch [10/50] batch [220/319] time 0.071 (0.086) data 0.000 (0.003) loss 2.0940 (2.3344) teacher_loss 0.8452 (1.0884) loss_zs_kd 0.7725 (0.6926) loss_oracle 0.8705 (0.8716) acc 75.0000 (59.9716) kd_loss 0.8136 (0.8102) lr 1.8763e-03 eta 0:18:26
epoch [10/50] batch [240/319] time 0.080 (0.086) data 0.000 (0.003) loss 2.4038 (2.3364) teacher_loss 1.1483 (1.0901) loss_zs_kd 0.8743 (0.7043) loss_oracle 0.8714 (0.8714) acc 62.5000 (59.9349) kd_loss 0.8199 (0.8106) lr 1.8763e-03 eta 0:18:21
epoch [10/50] batch [260/319] time 0.073 (0.085) data 0.000 (0.002) loss 2.3567 (2.3323) teacher_loss 1.0875 (1.0862) loss_zs_kd 1.0108 (0.7140) loss_oracle 0.8670 (0.8713) acc 62.5000 (60.0240) kd_loss 0.8357 (0.8105) lr 1.8763e-03 eta 0:18:11
epoch [10/50] batch [280/319] time 0.084 (0.085) data 0.000 (0.002) loss 2.2127 (2.3244) teacher_loss 0.9977 (1.0780) loss_zs_kd 0.8689 (0.7262) loss_oracle 0.8704 (0.8711) acc 59.3750 (60.2455) kd_loss 0.7799 (0.8109) lr 1.8763e-03 eta 0:18:05
epoch [10/50] batch [300/319] time 0.077 (0.085) data 0.000 (0.002) loss 2.2712 (2.3230) teacher_loss 1.0569 (1.0768) loss_zs_kd 0.7962 (0.7339) loss_oracle 0.8710 (0.8710) acc 59.3750 (60.3958) kd_loss 0.7788 (0.8107) lr 1.8763e-03 eta 0:18:03
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,661
* accuracy: 60.8%
* error: 39.2%
* macro_f1: 53.3%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,304
* accuracy: 54.5%
* error: 45.5%
* macro_f1: 21.4%
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     56.1%, epoch: 9 *******
epoch [11/50] batch [20/319] time 0.084 (0.115) data 0.000 (0.030) loss 2.2319 (2.1922) teacher_loss 0.9503 (0.9485) loss_zs_kd 0.7923 (0.7705) loss_oracle 0.8695 (0.8697) acc 65.6250 (66.7188) kd_loss 0.8468 (0.8089) lr 1.8443e-03 eta 0:24:30
epoch [11/50] batch [40/319] time 0.084 (0.101) data 0.000 (0.015) loss 2.0575 (2.2178) teacher_loss 0.7890 (0.9675) loss_zs_kd 0.8103 (0.8239) loss_oracle 0.8694 (0.8691) acc 71.8750 (64.8438) kd_loss 0.8338 (0.8158) lr 1.8443e-03 eta 0:21:21
epoch [11/50] batch [60/319] time 0.088 (0.095) data 0.001 (0.010) loss 2.4379 (2.2223) teacher_loss 1.1454 (0.9704) loss_zs_kd 1.0204 (0.8359) loss_oracle 0.8687 (0.8688) acc 65.6250 (65.5208) kd_loss 0.8582 (0.8175) lr 1.8443e-03 eta 0:20:08
epoch [11/50] batch [80/319] time 0.076 (0.092) data 0.000 (0.008) loss 2.4937 (2.2258) teacher_loss 1.2638 (0.9717) loss_zs_kd 1.0546 (0.8498) loss_oracle 0.8644 (0.8684) acc 59.3750 (65.5078) kd_loss 0.7977 (0.8199) lr 1.8443e-03 eta 0:19:22
epoch [11/50] batch [100/319] time 0.064 (0.087) data 0.000 (0.006) loss 2.2575 (2.2344) teacher_loss 0.9851 (0.9796) loss_zs_kd 0.8260 (0.8621) loss_oracle 0.8631 (0.8680) acc 62.5000 (65.3750) kd_loss 0.8409 (0.8208) lr 1.8443e-03 eta 0:18:18
epoch [11/50] batch [120/319] time 0.105 (0.085) data 0.000 (0.005) loss 2.2164 (2.2379) teacher_loss 0.9936 (0.9839) loss_zs_kd 0.8787 (0.8684) loss_oracle 0.8671 (0.8678) acc 62.5000 (65.3125) kd_loss 0.7892 (0.8201) lr 1.8443e-03 eta 0:17:59
epoch [11/50] batch [140/319] time 0.088 (0.086) data 0.000 (0.005) loss 2.5938 (2.2333) teacher_loss 1.3143 (0.9807) loss_zs_kd 1.0507 (0.8681) loss_oracle 0.8699 (0.8676) acc 46.8750 (65.5357) kd_loss 0.8445 (0.8188) lr 1.8443e-03 eta 0:18:01
epoch [11/50] batch [160/319] time 0.075 (0.085) data 0.000 (0.004) loss 1.9012 (2.2399) teacher_loss 0.6819 (0.9886) loss_zs_kd 0.6796 (0.8603) loss_oracle 0.8652 (0.8677) acc 75.0000 (65.4688) kd_loss 0.7867 (0.8174) lr 1.8443e-03 eta 0:17:45
epoch [11/50] batch [180/319] time 0.079 (0.084) data 0.000 (0.004) loss 2.2614 (2.2441) teacher_loss 1.0414 (0.9923) loss_zs_kd 0.5964 (0.8393) loss_oracle 0.8641 (0.8676) acc 56.2500 (65.3299) kd_loss 0.7880 (0.8180) lr 1.8443e-03 eta 0:17:37
epoch [11/50] batch [200/319] time 0.071 (0.084) data 0.000 (0.003) loss 2.2109 (2.2428) teacher_loss 0.9131 (0.9901) loss_zs_kd 0.7492 (0.8274) loss_oracle 0.8689 (0.8675) acc 65.6250 (65.2969) kd_loss 0.8633 (0.8190) lr 1.8443e-03 eta 0:17:30
epoch [11/50] batch [220/319] time 0.072 (0.082) data 0.000 (0.003) loss 2.4001 (2.2408) teacher_loss 1.1399 (0.9890) loss_zs_kd 0.6470 (0.8120) loss_oracle 0.8669 (0.8675) acc 65.6250 (65.3693) kd_loss 0.8268 (0.8181) lr 1.8443e-03 eta 0:17:07
epoch [11/50] batch [240/319] time 0.073 (0.081) data 0.000 (0.003) loss 2.1672 (2.2366) teacher_loss 0.9770 (0.9863) loss_zs_kd 0.5776 (0.7980) loss_oracle 0.8699 (0.8676) acc 68.7500 (65.3255) kd_loss 0.7553 (0.8165) lr 1.8443e-03 eta 0:16:56
epoch [11/50] batch [260/319] time 0.084 (0.081) data 0.000 (0.003) loss 1.9673 (2.2367) teacher_loss 0.7060 (0.9868) loss_zs_kd 0.8514 (0.7925) loss_oracle 0.8667 (0.8676) acc 81.2500 (65.2043) kd_loss 0.8279 (0.8161) lr 1.8443e-03 eta 0:16:55
epoch [11/50] batch [280/319] time 0.087 (0.081) data 0.000 (0.002) loss 2.4068 (2.2351) teacher_loss 1.1105 (0.9844) loss_zs_kd 0.6785 (0.7871) loss_oracle 0.8679 (0.8675) acc 53.1250 (65.2567) kd_loss 0.8623 (0.8169) lr 1.8443e-03 eta 0:16:55
epoch [11/50] batch [300/319] time 0.081 (0.081) data 0.000 (0.002) loss 2.7757 (2.2393) teacher_loss 1.5257 (0.9881) loss_zs_kd 0.7739 (0.7847) loss_oracle 0.8642 (0.8674) acc 46.8750 (65.1979) kd_loss 0.8180 (0.8175) lr 1.8443e-03 eta 0:16:51
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,640
* accuracy: 60.3%
* error: 39.7%
* macro_f1: 51.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,344
* accuracy: 54.9%
* error: 45.1%
* macro_f1: 22.1%
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     56.1%, epoch: 9 *******
epoch [12/50] batch [20/319] time 0.088 (0.119) data 0.000 (0.031) loss 2.2354 (2.2486) teacher_loss 0.9339 (0.9864) loss_zs_kd 0.6423 (0.8288) loss_oracle 0.8685 (0.8675) acc 65.6250 (66.5625) kd_loss 0.8672 (0.8284) lr 1.8090e-03 eta 0:24:38
epoch [12/50] batch [40/319] time 0.090 (0.097) data 0.000 (0.016) loss 1.9302 (2.2490) teacher_loss 0.6798 (0.9892) loss_zs_kd 0.6882 (0.7410) loss_oracle 0.8662 (0.8681) acc 71.8750 (66.0156) kd_loss 0.8173 (0.8257) lr 1.8090e-03 eta 0:20:00
epoch [12/50] batch [60/319] time 0.056 (0.090) data 0.001 (0.011) loss 2.4329 (2.2748) teacher_loss 1.1555 (1.0216) loss_zs_kd 0.5603 (0.7273) loss_oracle 0.8705 (0.8684) acc 53.1250 (64.4792) kd_loss 0.8422 (0.8189) lr 1.8090e-03 eta 0:18:31
epoch [12/50] batch [80/319] time 0.069 (0.083) data 0.000 (0.008) loss 2.1728 (2.2680) teacher_loss 0.8964 (1.0162) loss_zs_kd 0.5676 (0.7128) loss_oracle 0.8672 (0.8683) acc 71.8750 (64.8828) kd_loss 0.8428 (0.8176) lr 1.8090e-03 eta 0:17:07
epoch [12/50] batch [100/319] time 0.059 (0.082) data 0.000 (0.006) loss 2.1687 (2.2746) teacher_loss 0.8993 (1.0249) loss_zs_kd 0.7097 (0.6977) loss_oracle 0.8701 (0.8683) acc 65.6250 (64.5312) kd_loss 0.8343 (0.8155) lr 1.8090e-03 eta 0:16:56
epoch [12/50] batch [120/319] time 0.067 (0.080) data 0.000 (0.005) loss 2.2426 (2.2797) teacher_loss 1.0198 (1.0300) loss_zs_kd 0.7039 (0.6953) loss_oracle 0.8670 (0.8683) acc 59.3750 (64.4531) kd_loss 0.7894 (0.8155) lr 1.8090e-03 eta 0:16:30
epoch [12/50] batch [140/319] time 0.063 (0.080) data 0.000 (0.005) loss 2.5287 (2.2727) teacher_loss 1.2394 (1.0243) loss_zs_kd 0.8678 (0.7096) loss_oracle 0.8673 (0.8682) acc 65.6250 (64.6429) kd_loss 0.8556 (0.8143) lr 1.8090e-03 eta 0:16:18
epoch [12/50] batch [160/319] time 0.084 (0.078) data 0.000 (0.004) loss 2.3320 (2.2732) teacher_loss 1.1010 (1.0242) loss_zs_kd 0.8324 (0.7173) loss_oracle 0.8663 (0.8682) acc 56.2500 (64.4922) kd_loss 0.7978 (0.8149) lr 1.8090e-03 eta 0:16:03
epoch [12/50] batch [180/319] time 0.080 (0.079) data 0.000 (0.004) loss 2.1970 (2.2732) teacher_loss 0.9529 (1.0245) loss_zs_kd 0.7626 (0.7276) loss_oracle 0.8707 (0.8682) acc 62.5000 (64.3056) kd_loss 0.8088 (0.8147) lr 1.8090e-03 eta 0:16:06
epoch [12/50] batch [200/319] time 0.078 (0.081) data 0.000 (0.003) loss 2.3831 (2.2733) teacher_loss 1.1275 (1.0234) loss_zs_kd 0.8056 (0.7341) loss_oracle 0.8686 (0.8681) acc 50.0000 (64.0000) kd_loss 0.8213 (0.8158) lr 1.8090e-03 eta 0:16:27
epoch [12/50] batch [220/319] time 0.083 (0.081) data 0.000 (0.003) loss 2.0765 (2.2673) teacher_loss 0.8301 (1.0176) loss_zs_kd 0.7382 (0.7536) loss_oracle 0.8679 (0.8681) acc 62.5000 (64.0909) kd_loss 0.8125 (0.8157) lr 1.8090e-03 eta 0:16:27
epoch [12/50] batch [240/319] time 0.085 (0.081) data 0.000 (0.003) loss 2.1534 (2.2651) teacher_loss 0.8459 (1.0156) loss_zs_kd 0.8934 (0.7570) loss_oracle 0.8722 (0.8682) acc 75.0000 (63.7370) kd_loss 0.8714 (0.8155) lr 1.8090e-03 eta 0:16:25
epoch [12/50] batch [260/319] time 0.085 (0.081) data 0.000 (0.003) loss 2.1255 (2.2623) teacher_loss 0.8892 (1.0127) loss_zs_kd 0.6145 (0.7521) loss_oracle 0.8683 (0.8682) acc 75.0000 (63.7861) kd_loss 0.8021 (0.8155) lr 1.8090e-03 eta 0:16:27
epoch [12/50] batch [280/319] time 0.079 (0.081) data 0.000 (0.002) loss 2.0176 (2.2632) teacher_loss 0.7786 (1.0131) loss_zs_kd 0.6244 (0.7460) loss_oracle 0.8688 (0.8683) acc 65.6250 (63.7165) kd_loss 0.8046 (0.8160) lr 1.8090e-03 eta 0:16:24
epoch [12/50] batch [300/319] time 0.081 (0.081) data 0.000 (0.002) loss 2.3897 (2.2609) teacher_loss 1.0865 (1.0107) loss_zs_kd 0.6595 (0.7453) loss_oracle 0.8717 (0.8684) acc 53.1250 (63.7604) kd_loss 0.8673 (0.8160) lr 1.8090e-03 eta 0:16:26
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,684
* accuracy: 61.3%
* error: 38.7%
* macro_f1: 53.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,276
* accuracy: 54.2%
* error: 45.8%
* macro_f1: 21.9%
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     56.1%, epoch: 9 *******
epoch [13/50] batch [20/319] time 0.079 (0.120) data 0.000 (0.032) loss 2.2411 (2.2998) teacher_loss 0.9949 (1.0572) loss_zs_kd 0.9378 (0.8225) loss_oracle 0.8669 (0.8692) acc 62.5000 (62.6562) kd_loss 0.8128 (0.8080) lr 1.7705e-03 eta 0:24:06
epoch [13/50] batch [40/319] time 0.087 (0.100) data 0.000 (0.016) loss 2.6227 (2.2564) teacher_loss 1.3430 (1.0134) loss_zs_kd 0.8605 (0.8177) loss_oracle 0.8690 (0.8688) acc 53.1250 (63.3594) kd_loss 0.8452 (0.8086) lr 1.7705e-03 eta 0:20:07
epoch [13/50] batch [60/319] time 0.086 (0.094) data 0.000 (0.011) loss 2.8147 (2.2818) teacher_loss 1.5708 (1.0379) loss_zs_kd 0.7915 (0.8129) loss_oracle 0.8694 (0.8684) acc 46.8750 (61.9792) kd_loss 0.8092 (0.8097) lr 1.7705e-03 eta 0:18:51
epoch [13/50] batch [80/319] time 0.095 (0.092) data 0.000 (0.008) loss 2.0403 (2.3025) teacher_loss 0.7881 (1.0553) loss_zs_kd 0.6233 (0.7878) loss_oracle 0.8706 (0.8684) acc 65.6250 (61.0156) kd_loss 0.8169 (0.8130) lr 1.7705e-03 eta 0:18:28
epoch [13/50] batch [100/319] time 0.085 (0.091) data 0.000 (0.007) loss 2.3511 (2.2978) teacher_loss 1.1000 (1.0495) loss_zs_kd 0.7854 (0.7870) loss_oracle 0.8693 (0.8682) acc 53.1250 (60.9688) kd_loss 0.8164 (0.8142) lr 1.7705e-03 eta 0:18:16
epoch [13/50] batch [120/319] time 0.086 (0.090) data 0.000 (0.006) loss 2.3093 (2.2894) teacher_loss 1.0333 (1.0415) loss_zs_kd 0.7140 (0.7925) loss_oracle 0.8668 (0.8679) acc 59.3750 (61.1979) kd_loss 0.8426 (0.8139) lr 1.7705e-03 eta 0:18:01
epoch [13/50] batch [140/319] time 0.087 (0.089) data 0.000 (0.005) loss 2.5629 (2.2874) teacher_loss 1.2889 (1.0394) loss_zs_kd 0.7955 (0.7883) loss_oracle 0.8667 (0.8679) acc 53.1250 (61.5848) kd_loss 0.8406 (0.8140) lr 1.7705e-03 eta 0:17:50
epoch [13/50] batch [160/319] time 0.076 (0.089) data 0.000 (0.004) loss 2.3403 (2.2779) teacher_loss 1.0862 (1.0300) loss_zs_kd 0.9163 (0.7885) loss_oracle 0.8672 (0.8679) acc 59.3750 (61.8750) kd_loss 0.8205 (0.8139) lr 1.7705e-03 eta 0:17:38
epoch [13/50] batch [180/319] time 0.086 (0.088) data 0.000 (0.004) loss 2.1843 (2.2749) teacher_loss 0.9516 (1.0267) loss_zs_kd 0.8975 (0.8002) loss_oracle 0.8684 (0.8678) acc 75.0000 (62.4132) kd_loss 0.7985 (0.8143) lr 1.7705e-03 eta 0:17:29
epoch [13/50] batch [200/319] time 0.084 (0.087) data 0.000 (0.003) loss 2.3148 (2.2718) teacher_loss 1.0653 (1.0234) loss_zs_kd 0.7812 (0.8040) loss_oracle 0.8686 (0.8679) acc 68.7500 (62.7188) kd_loss 0.8152 (0.8145) lr 1.7705e-03 eta 0:17:23
epoch [13/50] batch [220/319] time 0.080 (0.087) data 0.000 (0.003) loss 2.2532 (2.2618) teacher_loss 0.9979 (1.0127) loss_zs_kd 1.0023 (0.8080) loss_oracle 0.8670 (0.8679) acc 71.8750 (63.2386) kd_loss 0.8218 (0.8152) lr 1.7705e-03 eta 0:17:14
epoch [13/50] batch [240/319] time 0.097 (0.087) data 0.000 (0.003) loss 2.0865 (2.2570) teacher_loss 0.7954 (1.0067) loss_zs_kd 0.9835 (0.8170) loss_oracle 0.8656 (0.8678) acc 68.7500 (63.5547) kd_loss 0.8583 (0.8163) lr 1.7705e-03 eta 0:17:09
epoch [13/50] batch [260/319] time 0.082 (0.086) data 0.000 (0.003) loss 2.2499 (2.2506) teacher_loss 0.9679 (0.9986) loss_zs_kd 0.8991 (0.8280) loss_oracle 0.8660 (0.8678) acc 62.5000 (64.0385) kd_loss 0.8491 (0.8182) lr 1.7705e-03 eta 0:17:04
epoch [13/50] batch [280/319] time 0.081 (0.086) data 0.000 (0.003) loss 2.1485 (2.2464) teacher_loss 0.8920 (0.9927) loss_zs_kd 0.9367 (0.8283) loss_oracle 0.8668 (0.8677) acc 65.6250 (64.2188) kd_loss 0.8231 (0.8199) lr 1.7705e-03 eta 0:16:56
epoch [13/50] batch [300/319] time 0.080 (0.085) data 0.000 (0.002) loss 2.2595 (2.2424) teacher_loss 0.9966 (0.9875) loss_zs_kd 0.7865 (0.8271) loss_oracle 0.8672 (0.8676) acc 68.7500 (64.5208) kd_loss 0.8293 (0.8210) lr 1.7705e-03 eta 0:16:50
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,620
* accuracy: 59.8%
* error: 40.2%
* macro_f1: 51.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,472
* accuracy: 56.2%
* error: 43.8%
* macro_f1: 22.2%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [14/50] batch [20/319] time 0.088 (0.121) data 0.000 (0.031) loss 2.1535 (2.2202) teacher_loss 0.8518 (0.9474) loss_zs_kd 1.0608 (0.8502) loss_oracle 0.8658 (0.8664) acc 78.1250 (67.6562) kd_loss 0.8687 (0.8396) lr 1.7290e-03 eta 0:23:50
epoch [14/50] batch [40/319] time 0.075 (0.101) data 0.000 (0.016) loss 2.5192 (2.1902) teacher_loss 1.2038 (0.9240) loss_zs_kd 0.9033 (0.9495) loss_oracle 0.8644 (0.8658) acc 59.3750 (68.5938) kd_loss 0.8832 (0.8334) lr 1.7290e-03 eta 0:19:48
epoch [14/50] batch [60/319] time 0.091 (0.095) data 0.000 (0.011) loss 2.1320 (2.2188) teacher_loss 0.8810 (0.9557) loss_zs_kd 1.2810 (0.9743) loss_oracle 0.8663 (0.8657) acc 68.7500 (66.5104) kd_loss 0.8179 (0.8303) lr 1.7290e-03 eta 0:18:35
epoch [14/50] batch [80/319] time 0.082 (0.092) data 0.000 (0.008) loss 2.3461 (2.2326) teacher_loss 1.0540 (0.9693) loss_zs_kd 0.9889 (0.9577) loss_oracle 0.8668 (0.8657) acc 56.2500 (64.7266) kd_loss 0.8587 (0.8304) lr 1.7290e-03 eta 0:18:00
epoch [14/50] batch [100/319] time 0.090 (0.091) data 0.000 (0.007) loss 1.8853 (2.2416) teacher_loss 0.6227 (0.9781) loss_zs_kd 0.9711 (0.9622) loss_oracle 0.8635 (0.8654) acc 81.2500 (64.2812) kd_loss 0.8309 (0.8308) lr 1.7290e-03 eta 0:17:42
epoch [14/50] batch [120/319] time 0.084 (0.090) data 0.000 (0.005) loss 2.1383 (2.2479) teacher_loss 0.8774 (0.9841) loss_zs_kd 1.0632 (0.9694) loss_oracle 0.8639 (0.8652) acc 65.6250 (63.9062) kd_loss 0.8290 (0.8313) lr 1.7290e-03 eta 0:17:28
epoch [14/50] batch [140/319] time 0.092 (0.089) data 0.000 (0.005) loss 2.5518 (2.2562) teacher_loss 1.3024 (0.9935) loss_zs_kd 0.8578 (0.9635) loss_oracle 0.8663 (0.8652) acc 56.2500 (63.3482) kd_loss 0.8162 (0.8301) lr 1.7290e-03 eta 0:17:18
epoch [14/50] batch [160/319] time 0.078 (0.090) data 0.000 (0.004) loss 2.3097 (2.2680) teacher_loss 1.0609 (1.0048) loss_zs_kd 0.7890 (0.9487) loss_oracle 0.8668 (0.8653) acc 65.6250 (62.6953) kd_loss 0.8153 (0.8305) lr 1.7290e-03 eta 0:17:30
epoch [14/50] batch [180/319] time 0.081 (0.089) data 0.000 (0.004) loss 2.2442 (2.2661) teacher_loss 0.9796 (1.0025) loss_zs_kd 0.8335 (0.9404) loss_oracle 0.8647 (0.8652) acc 68.7500 (62.7431) kd_loss 0.8322 (0.8311) lr 1.7290e-03 eta 0:17:17
epoch [14/50] batch [200/319] time 0.086 (0.088) data 0.000 (0.003) loss 2.1195 (2.2622) teacher_loss 0.8784 (0.9971) loss_zs_kd 0.8978 (0.9381) loss_oracle 0.8637 (0.8650) acc 68.7500 (63.0312) kd_loss 0.8093 (0.8325) lr 1.7290e-03 eta 0:17:06
epoch [14/50] batch [220/319] time 0.077 (0.088) data 0.000 (0.003) loss 2.2257 (2.2639) teacher_loss 0.9629 (0.9995) loss_zs_kd 0.8293 (0.9341) loss_oracle 0.8665 (0.8650) acc 68.7500 (62.8977) kd_loss 0.8296 (0.8319) lr 1.7290e-03 eta 0:17:00
epoch [14/50] batch [240/319] time 0.087 (0.088) data 0.000 (0.003) loss 2.2118 (2.2648) teacher_loss 0.9697 (1.0005) loss_zs_kd 0.8851 (0.9262) loss_oracle 0.8677 (0.8650) acc 68.7500 (62.8776) kd_loss 0.8083 (0.8317) lr 1.7290e-03 eta 0:16:52
epoch [14/50] batch [260/319] time 0.083 (0.087) data 0.000 (0.003) loss 2.1038 (2.2630) teacher_loss 0.8518 (0.9998) loss_zs_kd 0.7210 (0.9168) loss_oracle 0.8675 (0.8651) acc 75.0000 (63.0048) kd_loss 0.8183 (0.8307) lr 1.7290e-03 eta 0:16:49
epoch [14/50] batch [280/319] time 0.088 (0.087) data 0.000 (0.003) loss 2.0968 (2.2580) teacher_loss 0.8492 (0.9959) loss_zs_kd 0.8705 (0.9161) loss_oracle 0.8654 (0.8652) acc 59.3750 (63.1585) kd_loss 0.8149 (0.8295) lr 1.7290e-03 eta 0:16:45
epoch [14/50] batch [300/319] time 0.064 (0.087) data 0.000 (0.002) loss 2.3129 (2.2562) teacher_loss 1.0524 (0.9939) loss_zs_kd 0.9021 (0.9131) loss_oracle 0.8659 (0.8652) acc 56.2500 (63.3229) kd_loss 0.8275 (0.8297) lr 1.7290e-03 eta 0:16:35
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,547
* accuracy: 58.2%
* error: 41.8%
* macro_f1: 51.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,205
* accuracy: 53.5%
* error: 46.5%
* macro_f1: 21.5%
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [15/50] batch [20/319] time 0.077 (0.111) data 0.000 (0.025) loss 2.7353 (2.3313) teacher_loss 1.4462 (1.0678) loss_zs_kd 0.8566 (0.9323) loss_oracle 0.8659 (0.8652) acc 56.2500 (60.9375) kd_loss 0.8562 (0.8309) lr 1.6845e-03 eta 0:21:12
epoch [15/50] batch [40/319] time 0.079 (0.094) data 0.000 (0.013) loss 1.9595 (2.2690) teacher_loss 0.7409 (1.0140) loss_zs_kd 0.8543 (0.9245) loss_oracle 0.8645 (0.8656) acc 71.8750 (62.1094) kd_loss 0.7863 (0.8221) lr 1.6845e-03 eta 0:17:52
epoch [15/50] batch [60/319] time 0.077 (0.090) data 0.000 (0.009) loss 2.2033 (2.2597) teacher_loss 0.9864 (0.9998) loss_zs_kd 1.0513 (0.9348) loss_oracle 0.8657 (0.8658) acc 65.6250 (63.1771) kd_loss 0.7840 (0.8270) lr 1.6845e-03 eta 0:17:05
epoch [15/50] batch [80/319] time 0.078 (0.086) data 0.000 (0.006) loss 2.1386 (2.2620) teacher_loss 0.9212 (1.0015) loss_zs_kd 0.9332 (0.9563) loss_oracle 0.8648 (0.8660) acc 68.7500 (63.2031) kd_loss 0.7850 (0.8275) lr 1.6845e-03 eta 0:16:22
epoch [15/50] batch [100/319] time 0.078 (0.085) data 0.000 (0.005) loss 2.1506 (2.2466) teacher_loss 0.8755 (0.9865) loss_zs_kd 0.7576 (0.9481) loss_oracle 0.8692 (0.8663) acc 68.7500 (64.6250) kd_loss 0.8405 (0.8270) lr 1.6845e-03 eta 0:16:06
epoch [15/50] batch [120/319] time 0.082 (0.085) data 0.000 (0.004) loss 1.9806 (2.2403) teacher_loss 0.7140 (0.9798) loss_zs_kd 0.9823 (0.9408) loss_oracle 0.8644 (0.8664) acc 78.1250 (65.2865) kd_loss 0.8344 (0.8273) lr 1.6845e-03 eta 0:16:01
epoch [15/50] batch [140/319] time 0.084 (0.085) data 0.000 (0.004) loss 2.3124 (2.2288) teacher_loss 1.0053 (0.9686) loss_zs_kd 1.2575 (0.9440) loss_oracle 0.8683 (0.8666) acc 56.2500 (65.7589) kd_loss 0.8729 (0.8269) lr 1.6845e-03 eta 0:15:58
epoch [15/50] batch [160/319] time 0.079 (0.085) data 0.000 (0.003) loss 2.1392 (2.2181) teacher_loss 0.8611 (0.9580) loss_zs_kd 1.0388 (0.9690) loss_oracle 0.8633 (0.8666) acc 78.1250 (66.2500) kd_loss 0.8465 (0.8268) lr 1.6845e-03 eta 0:15:58
epoch [15/50] batch [180/319] time 0.085 (0.085) data 0.000 (0.003) loss 2.0568 (2.2050) teacher_loss 0.8256 (0.9451) loss_zs_kd 0.8177 (0.9692) loss_oracle 0.8666 (0.8665) acc 71.8750 (66.5278) kd_loss 0.7979 (0.8267) lr 1.6845e-03 eta 0:15:57
epoch [15/50] batch [200/319] time 0.083 (0.084) data 0.000 (0.003) loss 2.5012 (2.2176) teacher_loss 1.2533 (0.9572) loss_zs_kd 0.8349 (0.9691) loss_oracle 0.8675 (0.8667) acc 53.1250 (66.0781) kd_loss 0.8141 (0.8270) lr 1.6845e-03 eta 0:15:49
epoch [15/50] batch [220/319] time 0.080 (0.084) data 0.000 (0.003) loss 2.3834 (2.2259) teacher_loss 1.1722 (0.9669) loss_zs_kd 0.8062 (0.9572) loss_oracle 0.8656 (0.8668) acc 62.5000 (65.6818) kd_loss 0.7785 (0.8256) lr 1.6845e-03 eta 0:15:45
epoch [15/50] batch [240/319] time 0.079 (0.084) data 0.000 (0.002) loss 2.0332 (2.2254) teacher_loss 0.8246 (0.9681) loss_zs_kd 0.8290 (0.9416) loss_oracle 0.8711 (0.8671) acc 68.7500 (65.5339) kd_loss 0.7730 (0.8237) lr 1.6845e-03 eta 0:15:42
epoch [15/50] batch [260/319] time 0.086 (0.084) data 0.000 (0.002) loss 2.3317 (2.2340) teacher_loss 1.0860 (0.9781) loss_zs_kd 0.7309 (0.9334) loss_oracle 0.8678 (0.8672) acc 46.8750 (65.0000) kd_loss 0.8118 (0.8222) lr 1.6845e-03 eta 0:15:41
epoch [15/50] batch [280/319] time 0.083 (0.084) data 0.000 (0.002) loss 2.0679 (2.2408) teacher_loss 0.8311 (0.9857) loss_zs_kd 0.8250 (0.9244) loss_oracle 0.8673 (0.8672) acc 68.7500 (64.8214) kd_loss 0.8032 (0.8216) lr 1.6845e-03 eta 0:15:40
epoch [15/50] batch [300/319] time 0.081 (0.084) data 0.000 (0.002) loss 2.4665 (2.2419) teacher_loss 1.2494 (0.9863) loss_zs_kd 0.7649 (0.9144) loss_oracle 0.8671 (0.8672) acc 50.0000 (64.6979) kd_loss 0.7835 (0.8220) lr 1.6845e-03 eta 0:15:38
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,700
* accuracy: 61.7%
* error: 38.3%
* macro_f1: 53.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,835
* accuracy: 49.7%
* error: 50.3%
* macro_f1: 21.4%
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [16/50] batch [20/319] time 0.072 (0.119) data 0.000 (0.031) loss 2.0546 (2.2023) teacher_loss 0.8192 (0.9526) loss_zs_kd 0.7711 (0.8153) loss_oracle 0.8676 (0.8681) acc 68.7500 (66.5625) kd_loss 0.8016 (0.8157) lr 1.6374e-03 eta 0:22:03
epoch [16/50] batch [40/319] time 0.075 (0.098) data 0.000 (0.016) loss 2.3735 (2.2082) teacher_loss 1.1242 (0.9500) loss_zs_kd 0.6723 (0.8300) loss_oracle 0.8697 (0.8680) acc 62.5000 (66.3281) kd_loss 0.8144 (0.8242) lr 1.6374e-03 eta 0:18:11
epoch [16/50] batch [60/319] time 0.085 (0.091) data 0.000 (0.010) loss 1.9999 (2.1936) teacher_loss 0.7415 (0.9320) loss_zs_kd 1.0115 (0.8441) loss_oracle 0.8642 (0.8678) acc 71.8750 (67.0833) kd_loss 0.8263 (0.8277) lr 1.6374e-03 eta 0:16:54
epoch [16/50] batch [80/319] time 0.070 (0.088) data 0.000 (0.008) loss 2.2082 (2.2011) teacher_loss 0.9625 (0.9404) loss_zs_kd 0.8899 (0.8553) loss_oracle 0.8675 (0.8676) acc 68.7500 (67.3828) kd_loss 0.8119 (0.8269) lr 1.6374e-03 eta 0:16:13
epoch [16/50] batch [100/319] time 0.101 (0.086) data 0.001 (0.006) loss 2.3750 (2.2173) teacher_loss 1.1282 (0.9560) loss_zs_kd 0.6698 (0.8542) loss_oracle 0.8673 (0.8676) acc 62.5000 (66.5312) kd_loss 0.8131 (0.8275) lr 1.6374e-03 eta 0:15:56
epoch [16/50] batch [120/319] time 0.081 (0.086) data 0.000 (0.005) loss 2.1684 (2.2137) teacher_loss 0.8991 (0.9529) loss_zs_kd 0.9715 (0.8524) loss_oracle 0.8679 (0.8676) acc 62.5000 (66.5625) kd_loss 0.8354 (0.8270) lr 1.6374e-03 eta 0:15:47
epoch [16/50] batch [140/319] time 0.159 (0.087) data 0.001 (0.005) loss 2.0432 (2.2265) teacher_loss 0.7993 (0.9655) loss_zs_kd 0.8972 (0.8552) loss_oracle 0.8660 (0.8676) acc 81.2500 (66.1830) kd_loss 0.8108 (0.8272) lr 1.6374e-03 eta 0:15:54
epoch [16/50] batch [160/319] time 0.076 (0.086) data 0.000 (0.004) loss 1.9843 (2.2356) teacher_loss 0.7315 (0.9745) loss_zs_kd 0.9092 (0.8587) loss_oracle 0.8665 (0.8676) acc 78.1250 (65.7227) kd_loss 0.8196 (0.8274) lr 1.6374e-03 eta 0:15:49
epoch [16/50] batch [180/319] time 0.071 (0.086) data 0.000 (0.004) loss 2.1319 (2.2337) teacher_loss 0.8137 (0.9735) loss_zs_kd 0.7137 (0.8557) loss_oracle 0.8680 (0.8674) acc 68.7500 (65.7465) kd_loss 0.8842 (0.8265) lr 1.6374e-03 eta 0:15:39
epoch [16/50] batch [200/319] time 0.080 (0.085) data 0.000 (0.003) loss 2.1711 (2.2330) teacher_loss 0.9175 (0.9726) loss_zs_kd 0.8524 (0.8542) loss_oracle 0.8651 (0.8674) acc 81.2500 (65.7188) kd_loss 0.8211 (0.8267) lr 1.6374e-03 eta 0:15:28
epoch [16/50] batch [220/319] time 0.112 (0.084) data 0.000 (0.003) loss 2.2028 (2.2299) teacher_loss 0.9215 (0.9695) loss_zs_kd 0.8534 (0.8654) loss_oracle 0.8632 (0.8673) acc 62.5000 (65.9659) kd_loss 0.8498 (0.8268) lr 1.6374e-03 eta 0:15:24
epoch [16/50] batch [240/319] time 0.090 (0.085) data 0.000 (0.003) loss 2.1074 (2.2304) teacher_loss 0.8920 (0.9704) loss_zs_kd 1.1441 (0.8740) loss_oracle 0.8674 (0.8673) acc 68.7500 (65.8854) kd_loss 0.7818 (0.8264) lr 1.6374e-03 eta 0:15:24
epoch [16/50] batch [260/319] time 0.081 (0.084) data 0.000 (0.003) loss 1.9124 (2.2319) teacher_loss 0.6822 (0.9717) loss_zs_kd 0.7902 (0.8676) loss_oracle 0.8668 (0.8672) acc 71.8750 (65.8774) kd_loss 0.7968 (0.8266) lr 1.6374e-03 eta 0:15:18
epoch [16/50] batch [280/319] time 0.085 (0.084) data 0.000 (0.002) loss 2.5548 (2.2315) teacher_loss 1.2937 (0.9706) loss_zs_kd 0.9445 (0.8699) loss_oracle 0.8651 (0.8671) acc 50.0000 (66.0603) kd_loss 0.8285 (0.8274) lr 1.6374e-03 eta 0:15:16
epoch [16/50] batch [300/319] time 0.081 (0.084) data 0.000 (0.002) loss 2.1745 (2.2258) teacher_loss 0.8832 (0.9643) loss_zs_kd 0.7992 (0.8726) loss_oracle 0.8649 (0.8670) acc 68.7500 (66.2708) kd_loss 0.8588 (0.8280) lr 1.6374e-03 eta 0:15:12
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,617
* accuracy: 59.8%
* error: 40.2%
* macro_f1: 51.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,813
* accuracy: 49.4%
* error: 50.6%
* macro_f1: 21.0%
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [17/50] batch [20/319] time 0.081 (0.122) data 0.000 (0.031) loss 2.0254 (2.0704) teacher_loss 0.7447 (0.8071) loss_zs_kd 1.3036 (0.8284) loss_oracle 0.8655 (0.8654) acc 78.1250 (74.5312) kd_loss 0.8479 (0.8305) lr 1.5878e-03 eta 0:22:00
epoch [17/50] batch [40/319] time 0.085 (0.101) data 0.000 (0.016) loss 2.0491 (2.1158) teacher_loss 0.8264 (0.8461) loss_zs_kd 1.0400 (0.9046) loss_oracle 0.8653 (0.8652) acc 71.8750 (72.5781) kd_loss 0.7900 (0.8371) lr 1.5878e-03 eta 0:18:13
epoch [17/50] batch [60/319] time 0.082 (0.095) data 0.000 (0.010) loss 2.4741 (2.1194) teacher_loss 1.2030 (0.8525) loss_zs_kd 0.7541 (0.9061) loss_oracle 0.8645 (0.8652) acc 62.5000 (72.1354) kd_loss 0.8389 (0.8343) lr 1.5878e-03 eta 0:17:02
epoch [17/50] batch [80/319] time 0.080 (0.092) data 0.000 (0.008) loss 2.0561 (2.1101) teacher_loss 0.8288 (0.8452) loss_zs_kd 1.0312 (0.8897) loss_oracle 0.8661 (0.8653) acc 71.8750 (72.2656) kd_loss 0.7943 (0.8322) lr 1.5878e-03 eta 0:16:25
epoch [17/50] batch [100/319] time 0.074 (0.089) data 0.000 (0.006) loss 1.9942 (2.1128) teacher_loss 0.7546 (0.8464) loss_zs_kd 1.1157 (0.8862) loss_oracle 0.8667 (0.8655) acc 78.1250 (72.1250) kd_loss 0.8062 (0.8336) lr 1.5878e-03 eta 0:15:56
epoch [17/50] batch [120/319] time 0.078 (0.088) data 0.000 (0.005) loss 2.3162 (2.1250) teacher_loss 1.0125 (0.8596) loss_zs_kd 1.2203 (0.9065) loss_oracle 0.8662 (0.8654) acc 62.5000 (71.7188) kd_loss 0.8706 (0.8327) lr 1.5878e-03 eta 0:15:38
epoch [17/50] batch [140/319] time 0.085 (0.087) data 0.000 (0.005) loss 2.4097 (2.1406) teacher_loss 1.1604 (0.8759) loss_zs_kd 0.9958 (0.9192) loss_oracle 0.8644 (0.8653) acc 59.3750 (70.9821) kd_loss 0.8171 (0.8320) lr 1.5878e-03 eta 0:15:29
epoch [17/50] batch [160/319] time 0.080 (0.086) data 0.000 (0.004) loss 1.9430 (2.1465) teacher_loss 0.6421 (0.8814) loss_zs_kd 0.8229 (0.9162) loss_oracle 0.8661 (0.8653) acc 81.2500 (70.6445) kd_loss 0.8678 (0.8325) lr 1.5878e-03 eta 0:15:15
epoch [17/50] batch [180/319] time 0.083 (0.086) data 0.000 (0.004) loss 1.8920 (2.1438) teacher_loss 0.5903 (0.8795) loss_zs_kd 1.1170 (0.9133) loss_oracle 0.8637 (0.8653) acc 84.3750 (70.7986) kd_loss 0.8698 (0.8317) lr 1.5878e-03 eta 0:15:12
epoch [17/50] batch [200/319] time 0.078 (0.085) data 0.000 (0.003) loss 1.9838 (2.1494) teacher_loss 0.7192 (0.8839) loss_zs_kd 0.9444 (0.9156) loss_oracle 0.8656 (0.8653) acc 78.1250 (70.6875) kd_loss 0.8318 (0.8328) lr 1.5878e-03 eta 0:15:04
epoch [17/50] batch [220/319] time 0.085 (0.085) data 0.000 (0.003) loss 2.1495 (2.1608) teacher_loss 0.9047 (0.8957) loss_zs_kd 1.0660 (0.9111) loss_oracle 0.8646 (0.8653) acc 62.5000 (70.0426) kd_loss 0.8125 (0.8325) lr 1.5878e-03 eta 0:14:58
epoch [17/50] batch [240/319] time 0.076 (0.084) data 0.000 (0.003) loss 2.3856 (2.1588) teacher_loss 1.1240 (0.8940) loss_zs_kd 1.0468 (0.9074) loss_oracle 0.8648 (0.8653) acc 62.5000 (70.1562) kd_loss 0.8292 (0.8321) lr 1.5878e-03 eta 0:14:55
epoch [17/50] batch [260/319] time 0.088 (0.084) data 0.000 (0.003) loss 2.1062 (2.1582) teacher_loss 0.7863 (0.8924) loss_zs_kd 1.0392 (0.9099) loss_oracle 0.8652 (0.8652) acc 75.0000 (70.0721) kd_loss 0.8873 (0.8332) lr 1.5878e-03 eta 0:14:49
epoch [17/50] batch [280/319] time 0.072 (0.084) data 0.000 (0.002) loss 1.7842 (2.1574) teacher_loss 0.5386 (0.8911) loss_zs_kd 0.9997 (0.9096) loss_oracle 0.8644 (0.8652) acc 78.1250 (70.0335) kd_loss 0.8134 (0.8337) lr 1.5878e-03 eta 0:14:45
epoch [17/50] batch [300/319] time 0.083 (0.084) data 0.000 (0.002) loss 2.3382 (2.1577) teacher_loss 1.0483 (0.8916) loss_zs_kd 1.1100 (0.9146) loss_oracle 0.8658 (0.8652) acc 65.6250 (69.9688) kd_loss 0.8571 (0.8335) lr 1.5878e-03 eta 0:14:41
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,713
* accuracy: 62.0%
* error: 38.0%
* macro_f1: 52.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,284
* accuracy: 54.3%
* error: 45.7%
* macro_f1: 21.3%
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [18/50] batch [20/319] time 0.073 (0.116) data 0.000 (0.032) loss 2.0683 (2.1448) teacher_loss 0.8180 (0.8904) loss_zs_kd 0.9894 (1.0278) loss_oracle 0.8651 (0.8650) acc 68.7500 (68.2812) kd_loss 0.8178 (0.8218) lr 1.5358e-03 eta 0:20:13
epoch [18/50] batch [40/319] time 0.077 (0.098) data 0.000 (0.016) loss 2.0733 (2.1451) teacher_loss 0.8777 (0.8882) loss_zs_kd 0.9504 (1.0266) loss_oracle 0.8647 (0.8651) acc 65.6250 (70.1562) kd_loss 0.7633 (0.8244) lr 1.5358e-03 eta 0:17:12
epoch [18/50] batch [60/319] time 0.081 (0.091) data 0.001 (0.011) loss 2.0679 (2.1331) teacher_loss 0.8377 (0.8751) loss_zs_kd 0.9190 (0.9797) loss_oracle 0.8656 (0.8652) acc 68.7500 (70.6771) kd_loss 0.7973 (0.8254) lr 1.5358e-03 eta 0:15:51
epoch [18/50] batch [80/319] time 0.085 (0.089) data 0.000 (0.008) loss 1.8675 (2.1379) teacher_loss 0.6315 (0.8779) loss_zs_kd 0.9354 (0.9623) loss_oracle 0.8665 (0.8652) acc 78.1250 (70.4297) kd_loss 0.8028 (0.8274) lr 1.5358e-03 eta 0:15:24
epoch [18/50] batch [100/319] time 0.078 (0.087) data 0.001 (0.007) loss 1.8140 (2.1320) teacher_loss 0.5472 (0.8686) loss_zs_kd 0.9683 (0.9603) loss_oracle 0.8623 (0.8653) acc 84.3750 (70.9062) kd_loss 0.8357 (0.8308) lr 1.5358e-03 eta 0:15:02
epoch [18/50] batch [120/319] time 0.089 (0.085) data 0.000 (0.006) loss 2.0082 (2.1395) teacher_loss 0.7560 (0.8784) loss_zs_kd 1.2157 (0.9507) loss_oracle 0.8670 (0.8653) acc 71.8750 (70.8073) kd_loss 0.8187 (0.8284) lr 1.5358e-03 eta 0:14:46
epoch [18/50] batch [140/319] time 0.077 (0.087) data 0.000 (0.005) loss 2.0948 (2.1365) teacher_loss 0.8330 (0.8758) loss_zs_kd 0.9471 (0.9368) loss_oracle 0.8643 (0.8652) acc 75.0000 (71.1830) kd_loss 0.8296 (0.8281) lr 1.5358e-03 eta 0:15:04
epoch [18/50] batch [160/319] time 0.087 (0.086) data 0.000 (0.004) loss 2.2923 (2.1482) teacher_loss 1.0350 (0.8869) loss_zs_kd 0.7969 (0.9190) loss_oracle 0.8653 (0.8653) acc 65.6250 (70.8594) kd_loss 0.8247 (0.8286) lr 1.5358e-03 eta 0:14:52
epoch [18/50] batch [180/319] time 0.078 (0.085) data 0.000 (0.004) loss 2.2899 (2.1462) teacher_loss 1.0050 (0.8854) loss_zs_kd 0.8921 (0.9094) loss_oracle 0.8657 (0.8653) acc 59.3750 (70.7639) kd_loss 0.8521 (0.8282) lr 1.5358e-03 eta 0:14:41
epoch [18/50] batch [200/319] time 0.081 (0.085) data 0.000 (0.003) loss 2.3321 (2.1503) teacher_loss 1.0438 (0.8889) loss_zs_kd 0.8371 (0.9040) loss_oracle 0.8663 (0.8653) acc 62.5000 (70.4375) kd_loss 0.8551 (0.8287) lr 1.5358e-03 eta 0:14:33
epoch [18/50] batch [220/319] time 0.094 (0.084) data 0.000 (0.003) loss 2.1676 (2.1492) teacher_loss 0.9449 (0.8884) loss_zs_kd 0.8797 (0.8991) loss_oracle 0.8653 (0.8653) acc 56.2500 (70.2983) kd_loss 0.7901 (0.8282) lr 1.5358e-03 eta 0:14:27
epoch [18/50] batch [240/319] time 0.085 (0.084) data 0.000 (0.003) loss 1.9542 (2.1456) teacher_loss 0.6868 (0.8844) loss_zs_kd 0.9364 (0.9050) loss_oracle 0.8648 (0.8653) acc 71.8750 (70.3776) kd_loss 0.8350 (0.8285) lr 1.5358e-03 eta 0:14:21
epoch [18/50] batch [260/319] time 0.075 (0.084) data 0.000 (0.003) loss 2.3317 (2.1427) teacher_loss 1.0467 (0.8817) loss_zs_kd 1.1342 (0.9158) loss_oracle 0.8656 (0.8652) acc 56.2500 (70.3726) kd_loss 0.8522 (0.8284) lr 1.5358e-03 eta 0:14:19
epoch [18/50] batch [280/319] time 0.088 (0.083) data 0.000 (0.003) loss 2.3493 (2.1489) teacher_loss 1.1161 (0.8880) loss_zs_kd 0.8284 (0.9200) loss_oracle 0.8663 (0.8652) acc 56.2500 (70.1562) kd_loss 0.8000 (0.8283) lr 1.5358e-03 eta 0:14:13
epoch [18/50] batch [300/319] time 0.072 (0.083) data 0.000 (0.002) loss 1.9398 (2.1530) teacher_loss 0.6721 (0.8932) loss_zs_kd 0.9574 (0.9156) loss_oracle 0.8658 (0.8653) acc 78.1250 (69.9792) kd_loss 0.8348 (0.8271) lr 1.5358e-03 eta 0:14:08
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,728
* accuracy: 62.3%
* error: 37.7%
* macro_f1: 54.0%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,826
* accuracy: 49.6%
* error: 50.4%
* macro_f1: 21.5%
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [19/50] batch [20/319] time 0.075 (0.119) data 0.000 (0.030) loss 2.0877 (2.1567) teacher_loss 0.8888 (0.9004) loss_zs_kd 0.8688 (0.8147) loss_oracle 0.8637 (0.8656) acc 65.6250 (68.1250) kd_loss 0.7671 (0.8236) lr 1.4818e-03 eta 0:20:11
epoch [19/50] batch [40/319] time 0.088 (0.099) data 0.000 (0.015) loss 2.0894 (2.1801) teacher_loss 0.8650 (0.9249) loss_zs_kd 0.7650 (0.8175) loss_oracle 0.8658 (0.8653) acc 71.8750 (68.1250) kd_loss 0.7914 (0.8226) lr 1.4818e-03 eta 0:16:50
epoch [19/50] batch [60/319] time 0.080 (0.094) data 0.000 (0.010) loss 2.1673 (2.1812) teacher_loss 0.9712 (0.9257) loss_zs_kd 0.5739 (0.8130) loss_oracle 0.8656 (0.8655) acc 62.5000 (67.2396) kd_loss 0.7633 (0.8227) lr 1.4818e-03 eta 0:15:49
epoch [19/50] batch [80/319] time 0.088 (0.092) data 0.000 (0.008) loss 2.3509 (2.1946) teacher_loss 1.1535 (0.9407) loss_zs_kd 0.8144 (0.7923) loss_oracle 0.8658 (0.8655) acc 53.1250 (66.6406) kd_loss 0.7644 (0.8212) lr 1.4818e-03 eta 0:15:28
epoch [19/50] batch [100/319] time 0.083 (0.090) data 0.000 (0.006) loss 2.0983 (2.2004) teacher_loss 0.8480 (0.9462) loss_zs_kd 0.8217 (0.7923) loss_oracle 0.8656 (0.8655) acc 75.0000 (66.3438) kd_loss 0.8175 (0.8214) lr 1.4818e-03 eta 0:15:10
epoch [19/50] batch [120/319] time 0.080 (0.089) data 0.000 (0.005) loss 2.2861 (2.1987) teacher_loss 1.0377 (0.9451) loss_zs_kd 0.6586 (0.7901) loss_oracle 0.8666 (0.8656) acc 62.5000 (66.5625) kd_loss 0.8151 (0.8209) lr 1.4818e-03 eta 0:14:59
epoch [19/50] batch [140/319] time 0.080 (0.088) data 0.000 (0.005) loss 2.1326 (2.1993) teacher_loss 0.8560 (0.9457) loss_zs_kd 0.9063 (0.8002) loss_oracle 0.8661 (0.8656) acc 56.2500 (66.6964) kd_loss 0.8435 (0.8208) lr 1.4818e-03 eta 0:14:47
epoch [19/50] batch [160/319] time 0.086 (0.088) data 0.000 (0.004) loss 2.2964 (2.1966) teacher_loss 1.0351 (0.9432) loss_zs_kd 0.7069 (0.8020) loss_oracle 0.8662 (0.8656) acc 62.5000 (66.5234) kd_loss 0.8282 (0.8205) lr 1.4818e-03 eta 0:14:42
epoch [19/50] batch [180/319] time 0.084 (0.087) data 0.000 (0.004) loss 2.1333 (2.1918) teacher_loss 0.8440 (0.9381) loss_zs_kd 0.8121 (0.7967) loss_oracle 0.8642 (0.8656) acc 71.8750 (66.8750) kd_loss 0.8573 (0.8209) lr 1.4818e-03 eta 0:14:33
epoch [19/50] batch [200/319] time 0.081 (0.087) data 0.000 (0.003) loss 2.1356 (2.1890) teacher_loss 0.8865 (0.9351) loss_zs_kd 0.8111 (0.8075) loss_oracle 0.8664 (0.8656) acc 68.7500 (67.1406) kd_loss 0.8159 (0.8211) lr 1.4818e-03 eta 0:14:30
epoch [19/50] batch [220/319] time 0.085 (0.087) data 0.000 (0.003) loss 2.3131 (2.1835) teacher_loss 1.0107 (0.9292) loss_zs_kd 0.7183 (0.8119) loss_oracle 0.8659 (0.8656) acc 65.6250 (67.3438) kd_loss 0.8695 (0.8215) lr 1.4818e-03 eta 0:14:26
epoch [19/50] batch [240/319] time 0.083 (0.087) data 0.000 (0.003) loss 2.3217 (2.1878) teacher_loss 1.0769 (0.9333) loss_zs_kd 0.7644 (0.8117) loss_oracle 0.8648 (0.8656) acc 65.6250 (67.2005) kd_loss 0.8124 (0.8217) lr 1.4818e-03 eta 0:14:24
epoch [19/50] batch [260/319] time 0.078 (0.086) data 0.000 (0.003) loss 2.5233 (2.1932) teacher_loss 1.2725 (0.9388) loss_zs_kd 0.6506 (0.8143) loss_oracle 0.8656 (0.8655) acc 59.3750 (66.9471) kd_loss 0.8180 (0.8216) lr 1.4818e-03 eta 0:14:20
epoch [19/50] batch [280/319] time 0.085 (0.086) data 0.000 (0.002) loss 2.0197 (2.1923) teacher_loss 0.7826 (0.9386) loss_zs_kd 0.8335 (0.8149) loss_oracle 0.8662 (0.8656) acc 68.7500 (67.0312) kd_loss 0.8039 (0.8209) lr 1.4818e-03 eta 0:14:14
epoch [19/50] batch [300/319] time 0.081 (0.086) data 0.000 (0.002) loss 2.0866 (2.1899) teacher_loss 0.8824 (0.9369) loss_zs_kd 0.9463 (0.8246) loss_oracle 0.8642 (0.8655) acc 75.0000 (67.0625) kd_loss 0.7721 (0.8202) lr 1.4818e-03 eta 0:14:11
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,719
* accuracy: 62.1%
* error: 37.9%
* macro_f1: 54.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,123
* accuracy: 52.6%
* error: 47.4%
* macro_f1: 22.0%
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [20/50] batch [20/319] time 0.095 (0.116) data 0.000 (0.027) loss 2.0544 (2.1363) teacher_loss 0.7914 (0.8727) loss_zs_kd 0.9687 (1.0113) loss_oracle 0.8656 (0.8646) acc 75.0000 (69.6875) kd_loss 0.8302 (0.8313) lr 1.4258e-03 eta 0:19:02
epoch [20/50] batch [40/319] time 0.071 (0.095) data 0.000 (0.013) loss 2.0995 (2.1392) teacher_loss 0.7880 (0.8778) loss_zs_kd 0.8646 (0.9921) loss_oracle 0.8655 (0.8647) acc 75.0000 (69.3750) kd_loss 0.8788 (0.8290) lr 1.4258e-03 eta 0:15:38
epoch [20/50] batch [60/319] time 0.074 (0.090) data 0.000 (0.009) loss 1.8249 (2.1844) teacher_loss 0.6410 (0.9262) loss_zs_kd 0.7091 (0.9598) loss_oracle 0.8649 (0.8650) acc 75.0000 (68.1250) kd_loss 0.7514 (0.8256) lr 1.4258e-03 eta 0:14:40
epoch [20/50] batch [80/319] time 0.081 (0.088) data 0.000 (0.007) loss 2.1411 (2.1955) teacher_loss 0.8829 (0.9374) loss_zs_kd 1.0740 (0.9636) loss_oracle 0.8662 (0.8652) acc 62.5000 (67.6172) kd_loss 0.8251 (0.8256) lr 1.4258e-03 eta 0:14:20
epoch [20/50] batch [100/319] time 0.087 (0.087) data 0.000 (0.006) loss 2.0859 (2.2016) teacher_loss 0.8765 (0.9464) loss_zs_kd 0.9178 (0.9607) loss_oracle 0.8650 (0.8653) acc 75.0000 (67.0938) kd_loss 0.7769 (0.8226) lr 1.4258e-03 eta 0:14:07
epoch [20/50] batch [120/319] time 0.108 (0.086) data 0.000 (0.005) loss 2.0276 (2.1962) teacher_loss 0.8094 (0.9444) loss_zs_kd 0.8793 (0.9559) loss_oracle 0.8657 (0.8654) acc 78.1250 (66.9531) kd_loss 0.7854 (0.8191) lr 1.4258e-03 eta 0:14:01
epoch [20/50] batch [140/319] time 0.077 (0.088) data 0.000 (0.004) loss 2.1241 (2.1930) teacher_loss 0.8700 (0.9403) loss_zs_kd 0.8815 (0.9600) loss_oracle 0.8643 (0.8653) acc 65.6250 (66.9643) kd_loss 0.8219 (0.8200) lr 1.4258e-03 eta 0:14:16
epoch [20/50] batch [160/319] time 0.101 (0.087) data 0.000 (0.004) loss 2.0474 (2.1886) teacher_loss 0.7943 (0.9356) loss_zs_kd 0.9773 (0.9528) loss_oracle 0.8649 (0.8653) acc 71.8750 (67.2656) kd_loss 0.8207 (0.8204) lr 1.4258e-03 eta 0:14:08
epoch [20/50] batch [180/319] time 0.081 (0.086) data 0.000 (0.003) loss 2.3954 (2.1947) teacher_loss 1.0818 (0.9415) loss_zs_kd 0.7848 (0.9334) loss_oracle 0.8665 (0.8653) acc 50.0000 (66.8576) kd_loss 0.8803 (0.8206) lr 1.4258e-03 eta 0:13:51
epoch [20/50] batch [200/319] time 0.071 (0.085) data 0.000 (0.003) loss 2.4090 (2.1974) teacher_loss 1.1935 (0.9441) loss_zs_kd 1.1248 (0.9202) loss_oracle 0.8655 (0.8653) acc 56.2500 (66.8438) kd_loss 0.7827 (0.8206) lr 1.4258e-03 eta 0:13:41
epoch [20/50] batch [220/319] time 0.077 (0.084) data 0.000 (0.003) loss 2.3223 (2.1978) teacher_loss 1.0611 (0.9450) loss_zs_kd 0.8875 (0.9158) loss_oracle 0.8657 (0.8652) acc 68.7500 (66.7898) kd_loss 0.8284 (0.8203) lr 1.4258e-03 eta 0:13:33
epoch [20/50] batch [240/319] time 0.084 (0.084) data 0.000 (0.002) loss 2.3077 (2.2046) teacher_loss 1.0842 (0.9526) loss_zs_kd 0.8007 (0.9070) loss_oracle 0.8651 (0.8653) acc 56.2500 (66.4193) kd_loss 0.7909 (0.8194) lr 1.4258e-03 eta 0:13:32
epoch [20/50] batch [260/319] time 0.081 (0.084) data 0.000 (0.002) loss 2.1916 (2.2086) teacher_loss 0.9323 (0.9566) loss_zs_kd 0.6950 (0.8963) loss_oracle 0.8650 (0.8653) acc 65.6250 (66.2139) kd_loss 0.8268 (0.8193) lr 1.4258e-03 eta 0:13:30
epoch [20/50] batch [280/319] time 0.086 (0.084) data 0.000 (0.002) loss 2.2956 (2.2144) teacher_loss 1.0378 (0.9626) loss_zs_kd 0.8757 (0.8875) loss_oracle 0.8650 (0.8653) acc 75.0000 (65.9933) kd_loss 0.8252 (0.8191) lr 1.4258e-03 eta 0:13:28
epoch [20/50] batch [300/319] time 0.082 (0.084) data 0.000 (0.002) loss 2.1831 (2.2190) teacher_loss 0.9718 (0.9677) loss_zs_kd 1.0895 (0.8823) loss_oracle 0.8656 (0.8653) acc 71.8750 (65.7292) kd_loss 0.7785 (0.8186) lr 1.4258e-03 eta 0:13:26
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,590
* accuracy: 59.2%
* error: 40.8%
* macro_f1: 52.9%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,045
* accuracy: 51.8%
* error: 48.2%
* macro_f1: 22.6%
******* Domain 2 best val acc:      62.8%, epoch: 7 *******
******* Domain 2 best val test acc: 50.9%, epoch: 7 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [21/50] batch [20/319] time 0.062 (0.111) data 0.000 (0.029) loss 2.1650 (2.2082) teacher_loss 0.9215 (0.9468) loss_zs_kd 1.0124 (0.8998) loss_oracle 0.8659 (0.8653) acc 65.6250 (64.6875) kd_loss 0.8106 (0.8288) lr 1.3681e-03 eta 0:17:38
epoch [21/50] batch [40/319] time 0.070 (0.092) data 0.000 (0.014) loss 2.2516 (2.2387) teacher_loss 1.0326 (0.9848) loss_zs_kd 0.6447 (0.8598) loss_oracle 0.8651 (0.8653) acc 56.2500 (63.9844) kd_loss 0.7865 (0.8213) lr 1.3681e-03 eta 0:14:35
epoch [21/50] batch [60/319] time 0.073 (0.087) data 0.000 (0.010) loss 2.0721 (2.2439) teacher_loss 0.8148 (0.9887) loss_zs_kd 1.0251 (0.8619) loss_oracle 0.8657 (0.8653) acc 68.7500 (63.9583) kd_loss 0.8245 (0.8226) lr 1.3681e-03 eta 0:13:42
epoch [21/50] batch [80/319] time 0.079 (0.084) data 0.000 (0.007) loss 2.0329 (2.2503) teacher_loss 0.7822 (0.9960) loss_zs_kd 0.7315 (0.8429) loss_oracle 0.8645 (0.8653) acc 71.8750 (63.3594) kd_loss 0.8184 (0.8216) lr 1.3681e-03 eta 0:13:17
epoch [21/50] batch [100/319] time 0.079 (0.084) data 0.000 (0.006) loss 2.0742 (2.2562) teacher_loss 0.8103 (1.0023) loss_zs_kd 0.6950 (0.8282) loss_oracle 0.8650 (0.8653) acc 68.7500 (63.2812) kd_loss 0.8314 (0.8213) lr 1.3681e-03 eta 0:13:14
epoch [21/50] batch [120/319] time 0.073 (0.083) data 0.000 (0.005) loss 2.0914 (2.2441) teacher_loss 0.8470 (0.9901) loss_zs_kd 0.7837 (0.8215) loss_oracle 0.8655 (0.8652) acc 62.5000 (64.0365) kd_loss 0.8116 (0.8214) lr 1.3681e-03 eta 0:13:00
epoch [21/50] batch [140/319] time 0.078 (0.082) data 0.000 (0.004) loss 2.2751 (2.2401) teacher_loss 1.0316 (0.9878) loss_zs_kd 0.9013 (0.8192) loss_oracle 0.8651 (0.8652) acc 62.5000 (63.9955) kd_loss 0.8110 (0.8197) lr 1.3681e-03 eta 0:12:57
epoch [21/50] batch [160/319] time 0.080 (0.083) data 0.000 (0.004) loss 2.0631 (2.2414) teacher_loss 0.8934 (0.9904) loss_zs_kd 0.9526 (0.8124) loss_oracle 0.8642 (0.8652) acc 78.1250 (64.1797) kd_loss 0.7376 (0.8185) lr 1.3681e-03 eta 0:12:59
epoch [21/50] batch [180/319] time 0.077 (0.082) data 0.000 (0.003) loss 2.2673 (2.2325) teacher_loss 1.0021 (0.9810) loss_zs_kd 0.8234 (0.8116) loss_oracle 0.8650 (0.8651) acc 65.6250 (64.6181) kd_loss 0.8327 (0.8190) lr 1.3681e-03 eta 0:12:54
epoch [21/50] batch [200/319] time 0.078 (0.082) data 0.000 (0.003) loss 2.4868 (2.2291) teacher_loss 1.2561 (0.9767) loss_zs_kd 0.8785 (0.8162) loss_oracle 0.8652 (0.8651) acc 62.5000 (64.9844) kd_loss 0.7981 (0.8199) lr 1.3681e-03 eta 0:12:49
epoch [21/50] batch [220/319] time 0.081 (0.082) data 0.000 (0.003) loss 2.0450 (2.2221) teacher_loss 0.8040 (0.9689) loss_zs_kd 0.8002 (0.8272) loss_oracle 0.8641 (0.8650) acc 75.0000 (65.3977) kd_loss 0.8089 (0.8207) lr 1.3681e-03 eta 0:12:47
epoch [21/50] batch [240/319] time 0.086 (0.082) data 0.001 (0.003) loss 2.1206 (2.2171) teacher_loss 0.8119 (0.9633) loss_zs_kd 0.8806 (0.8287) loss_oracle 0.8639 (0.8650) acc 65.6250 (65.7812) kd_loss 0.8768 (0.8214) lr 1.3681e-03 eta 0:12:45
epoch [21/50] batch [260/319] time 0.079 (0.082) data 0.000 (0.002) loss 2.2152 (2.2217) teacher_loss 0.9923 (0.9676) loss_zs_kd 0.8739 (0.8287) loss_oracle 0.8651 (0.8649) acc 71.8750 (65.6370) kd_loss 0.7903 (0.8216) lr 1.3681e-03 eta 0:12:41
epoch [21/50] batch [280/319] time 0.086 (0.082) data 0.000 (0.002) loss 2.1370 (2.2235) teacher_loss 0.8563 (0.9682) loss_zs_kd 0.6735 (0.8240) loss_oracle 0.8652 (0.8649) acc 68.7500 (65.5915) kd_loss 0.8481 (0.8229) lr 1.3681e-03 eta 0:12:40
epoch [21/50] batch [300/319] time 0.080 (0.082) data 0.000 (0.002) loss 1.9366 (2.2169) teacher_loss 0.6444 (0.9605) loss_zs_kd 0.8250 (0.8191) loss_oracle 0.8640 (0.8649) acc 81.2500 (65.9896) kd_loss 0.8603 (0.8240) lr 1.3681e-03 eta 0:12:39
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,755
* accuracy: 62.9%
* error: 37.1%
* macro_f1: 54.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,775
* accuracy: 49.0%
* error: 51.0%
* macro_f1: 21.1%
******* Domain 2 best val acc:      62.9%, epoch: 21 *******
******* Domain 2 best val test acc: 49.0%, epoch: 21 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [22/50] batch [20/319] time 0.086 (0.107) data 0.000 (0.025) loss 2.1599 (2.1379) teacher_loss 0.8574 (0.8762) loss_zs_kd 1.0344 (0.8911) loss_oracle 0.8639 (0.8645) acc 68.7500 (71.5625) kd_loss 0.8705 (0.8294) lr 1.3090e-03 eta 0:16:28
epoch [22/50] batch [40/319] time 0.072 (0.094) data 0.000 (0.013) loss 2.2631 (2.1364) teacher_loss 0.9826 (0.8784) loss_zs_kd 0.9041 (0.8488) loss_oracle 0.8647 (0.8645) acc 59.3750 (70.5469) kd_loss 0.8482 (0.8259) lr 1.3090e-03 eta 0:14:24
epoch [22/50] batch [60/319] time 0.079 (0.089) data 0.000 (0.009) loss 1.9758 (2.1604) teacher_loss 0.7336 (0.8978) loss_zs_kd 0.8589 (0.8307) loss_oracle 0.8649 (0.8645) acc 75.0000 (69.1667) kd_loss 0.8097 (0.8304) lr 1.3090e-03 eta 0:13:42
epoch [22/50] batch [80/319] time 0.086 (0.088) data 0.000 (0.007) loss 2.5018 (2.1594) teacher_loss 1.2070 (0.8974) loss_zs_kd 0.9678 (0.8451) loss_oracle 0.8642 (0.8645) acc 62.5000 (68.7891) kd_loss 0.8627 (0.8298) lr 1.3090e-03 eta 0:13:22
epoch [22/50] batch [100/319] time 0.082 (0.086) data 0.000 (0.005) loss 2.0482 (2.1638) teacher_loss 0.7413 (0.9008) loss_zs_kd 0.7889 (0.8562) loss_oracle 0.8650 (0.8645) acc 71.8750 (68.3438) kd_loss 0.8744 (0.8307) lr 1.3090e-03 eta 0:13:08
epoch [22/50] batch [120/319] time 0.084 (0.087) data 0.000 (0.004) loss 2.5032 (2.1579) teacher_loss 1.1963 (0.8929) loss_zs_kd 1.0435 (0.8632) loss_oracle 0.8644 (0.8645) acc 56.2500 (68.6979) kd_loss 0.8747 (0.8328) lr 1.3090e-03 eta 0:13:15
epoch [22/50] batch [140/319] time 0.074 (0.086) data 0.000 (0.004) loss 2.2119 (2.1620) teacher_loss 0.9644 (0.8919) loss_zs_kd 0.8688 (0.9028) loss_oracle 0.8645 (0.8645) acc 62.5000 (68.7946) kd_loss 0.8153 (0.8379) lr 1.3090e-03 eta 0:13:06
epoch [22/50] batch [160/319] time 0.086 (0.085) data 0.000 (0.003) loss 2.2961 (2.1665) teacher_loss 1.0850 (0.8911) loss_zs_kd 0.7160 (0.9067) loss_oracle 0.8638 (0.8645) acc 62.5000 (69.0625) kd_loss 0.7792 (0.8432) lr 1.3090e-03 eta 0:12:56
epoch [22/50] batch [180/319] time 0.087 (0.085) data 0.000 (0.003) loss 2.5025 (2.1566) teacher_loss 1.2022 (0.8825) loss_zs_kd 0.9322 (0.9092) loss_oracle 0.8640 (0.8645) acc 50.0000 (69.3576) kd_loss 0.8683 (0.8419) lr 1.3090e-03 eta 0:12:53
epoch [22/50] batch [200/319] time 0.069 (0.084) data 0.000 (0.003) loss 2.1515 (2.1556) teacher_loss 0.9025 (0.8836) loss_zs_kd 0.7911 (0.8999) loss_oracle 0.8642 (0.8644) acc 75.0000 (69.5469) kd_loss 0.8169 (0.8398) lr 1.3090e-03 eta 0:12:42
epoch [22/50] batch [220/319] time 0.070 (0.083) data 0.000 (0.003) loss 2.2046 (2.1595) teacher_loss 0.9534 (0.8873) loss_zs_kd 0.7610 (0.8958) loss_oracle 0.8637 (0.8644) acc 59.3750 (69.2756) kd_loss 0.8193 (0.8400) lr 1.3090e-03 eta 0:12:30
epoch [22/50] batch [240/319] time 0.069 (0.082) data 0.000 (0.002) loss 2.2532 (2.1546) teacher_loss 1.0134 (0.8824) loss_zs_kd 0.9825 (0.8972) loss_oracle 0.8647 (0.8644) acc 71.8750 (69.4661) kd_loss 0.8074 (0.8400) lr 1.3090e-03 eta 0:12:19
epoch [22/50] batch [260/319] time 0.065 (0.082) data 0.000 (0.002) loss 2.3739 (2.1635) teacher_loss 1.1474 (0.8918) loss_zs_kd 0.7809 (0.8979) loss_oracle 0.8640 (0.8644) acc 53.1250 (69.1947) kd_loss 0.7944 (0.8395) lr 1.3090e-03 eta 0:12:13
epoch [22/50] batch [280/319] time 0.060 (0.080) data 0.000 (0.002) loss 1.7968 (2.1642) teacher_loss 0.5810 (0.8935) loss_zs_kd 0.7281 (0.8916) loss_oracle 0.8645 (0.8644) acc 84.3750 (69.1406) kd_loss 0.7836 (0.8385) lr 1.3090e-03 eta 0:11:59
epoch [22/50] batch [300/319] time 0.079 (0.079) data 0.000 (0.002) loss 2.1859 (2.1679) teacher_loss 0.9164 (0.8985) loss_zs_kd 1.0051 (0.8890) loss_oracle 0.8639 (0.8644) acc 71.8750 (69.0729) kd_loss 0.8375 (0.8372) lr 1.3090e-03 eta 0:11:51
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,675
* accuracy: 61.1%
* error: 38.9%
* macro_f1: 53.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,203
* accuracy: 43.2%
* error: 56.8%
* macro_f1: 21.9%
******* Domain 2 best val acc:      62.9%, epoch: 21 *******
******* Domain 2 best val test acc: 49.0%, epoch: 21 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [23/50] batch [20/319] time 0.083 (0.118) data 0.000 (0.031) loss 2.4653 (2.2245) teacher_loss 1.1819 (0.9655) loss_zs_kd 0.7586 (0.8159) loss_oracle 0.8640 (0.8644) acc 53.1250 (67.0312) kd_loss 0.8515 (0.8268) lr 1.2487e-03 eta 0:17:32
epoch [23/50] batch [40/319] time 0.075 (0.098) data 0.000 (0.015) loss 2.0906 (2.2247) teacher_loss 0.8570 (0.9703) loss_zs_kd 0.9725 (0.7916) loss_oracle 0.8644 (0.8644) acc 65.6250 (65.9375) kd_loss 0.8013 (0.8222) lr 1.2487e-03 eta 0:14:33
epoch [23/50] batch [60/319] time 0.083 (0.093) data 0.000 (0.010) loss 2.1580 (2.1886) teacher_loss 0.9553 (0.9309) loss_zs_kd 0.9185 (0.8165) loss_oracle 0.8640 (0.8643) acc 68.7500 (68.3333) kd_loss 0.7707 (0.8256) lr 1.2487e-03 eta 0:13:46
epoch [23/50] batch [80/319] time 0.079 (0.090) data 0.000 (0.008) loss 2.0316 (2.1943) teacher_loss 0.8702 (0.9385) loss_zs_kd 0.8225 (0.8169) loss_oracle 0.8644 (0.8643) acc 65.6250 (67.2656) kd_loss 0.7291 (0.8236) lr 1.2487e-03 eta 0:13:12
epoch [23/50] batch [100/319] time 0.083 (0.088) data 0.000 (0.006) loss 1.9921 (2.1997) teacher_loss 0.8249 (0.9447) loss_zs_kd 0.9752 (0.8105) loss_oracle 0.8641 (0.8643) acc 78.1250 (67.1562) kd_loss 0.7351 (0.8228) lr 1.2487e-03 eta 0:12:56
epoch [23/50] batch [120/319] time 0.084 (0.087) data 0.000 (0.005) loss 2.2077 (2.1992) teacher_loss 0.9824 (0.9426) loss_zs_kd 0.7819 (0.8059) loss_oracle 0.8639 (0.8643) acc 56.2500 (67.0052) kd_loss 0.7934 (0.8244) lr 1.2487e-03 eta 0:12:49
epoch [23/50] batch [140/319] time 0.089 (0.087) data 0.001 (0.005) loss 2.0035 (2.1948) teacher_loss 0.7540 (0.9386) loss_zs_kd 0.6849 (0.8049) loss_oracle 0.8641 (0.8643) acc 78.1250 (67.1875) kd_loss 0.8174 (0.8240) lr 1.2487e-03 eta 0:12:43
epoch [23/50] batch [160/319] time 0.084 (0.087) data 0.000 (0.004) loss 2.1107 (2.1892) teacher_loss 0.8450 (0.9299) loss_zs_kd 0.8257 (0.8172) loss_oracle 0.8643 (0.8643) acc 68.7500 (67.4805) kd_loss 0.8336 (0.8272) lr 1.2487e-03 eta 0:12:39
epoch [23/50] batch [180/319] time 0.088 (0.086) data 0.000 (0.004) loss 2.3181 (2.1871) teacher_loss 1.0854 (0.9280) loss_zs_kd 0.7518 (0.8222) loss_oracle 0.8644 (0.8643) acc 59.3750 (67.5347) kd_loss 0.8005 (0.8269) lr 1.2487e-03 eta 0:12:31
epoch [23/50] batch [200/319] time 0.065 (0.084) data 0.000 (0.003) loss 1.7147 (2.1852) teacher_loss 0.4725 (0.9260) loss_zs_kd 0.6352 (0.8214) loss_oracle 0.8635 (0.8643) acc 87.5000 (67.7188) kd_loss 0.8105 (0.8271) lr 1.2487e-03 eta 0:12:17
epoch [23/50] batch [220/319] time 0.086 (0.084) data 0.001 (0.003) loss 2.4657 (2.1864) teacher_loss 1.2002 (0.9255) loss_zs_kd 0.8631 (0.8254) loss_oracle 0.8644 (0.8643) acc 62.5000 (67.6705) kd_loss 0.8333 (0.8288) lr 1.2487e-03 eta 0:12:12
epoch [23/50] batch [240/319] time 0.077 (0.084) data 0.000 (0.003) loss 2.1301 (2.1904) teacher_loss 0.9074 (0.9305) loss_zs_kd 0.7757 (0.8218) loss_oracle 0.8641 (0.8643) acc 71.8750 (67.5781) kd_loss 0.7907 (0.8278) lr 1.2487e-03 eta 0:12:09
epoch [23/50] batch [260/319] time 0.090 (0.084) data 0.000 (0.003) loss 2.2955 (2.1933) teacher_loss 1.0100 (0.9332) loss_zs_kd 0.8489 (0.8231) loss_oracle 0.8640 (0.8642) acc 68.7500 (67.4399) kd_loss 0.8534 (0.8280) lr 1.2487e-03 eta 0:12:04
epoch [23/50] batch [280/319] time 0.074 (0.083) data 0.000 (0.002) loss 1.9471 (2.1928) teacher_loss 0.6523 (0.9326) loss_zs_kd 0.9929 (0.8241) loss_oracle 0.8641 (0.8642) acc 81.2500 (67.4219) kd_loss 0.8627 (0.8281) lr 1.2487e-03 eta 0:12:00
epoch [23/50] batch [300/319] time 0.079 (0.083) data 0.000 (0.002) loss 2.3072 (2.1915) teacher_loss 1.0455 (0.9310) loss_zs_kd 0.9950 (0.8261) loss_oracle 0.8636 (0.8642) acc 68.7500 (67.5000) kd_loss 0.8298 (0.8284) lr 1.2487e-03 eta 0:11:57
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,773
* accuracy: 63.3%
* error: 36.7%
* macro_f1: 56.2%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,089
* accuracy: 52.3%
* error: 47.7%
* macro_f1: 22.5%
******* Domain 2 best val acc:      63.3%, epoch: 23 *******
******* Domain 2 best val test acc: 52.3%, epoch: 23 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [24/50] batch [20/319] time 0.083 (0.122) data 0.000 (0.031) loss 1.9274 (2.1493) teacher_loss 0.6335 (0.8689) loss_zs_kd 1.0003 (0.9178) loss_oracle 0.8638 (0.8640) acc 75.0000 (70.1562) kd_loss 0.8621 (0.8484) lr 1.1874e-03 eta 0:17:28
epoch [24/50] batch [40/319] time 0.080 (0.102) data 0.000 (0.016) loss 2.6953 (2.1726) teacher_loss 1.4165 (0.8967) loss_zs_kd 0.8321 (0.9164) loss_oracle 0.8639 (0.8639) acc 50.0000 (68.6719) kd_loss 0.8469 (0.8439) lr 1.1874e-03 eta 0:14:38
epoch [24/50] batch [60/319] time 0.069 (0.096) data 0.001 (0.011) loss 2.1723 (2.2091) teacher_loss 0.8800 (0.9382) loss_zs_kd 0.9737 (0.8847) loss_oracle 0.8644 (0.8640) acc 65.6250 (67.4479) kd_loss 0.8601 (0.8389) lr 1.1874e-03 eta 0:13:40
epoch [24/50] batch [80/319] time 0.082 (0.091) data 0.000 (0.008) loss 2.1867 (2.2022) teacher_loss 0.9777 (0.9351) loss_zs_kd 0.9087 (0.8655) loss_oracle 0.8641 (0.8640) acc 71.8750 (67.3828) kd_loss 0.7769 (0.8350) lr 1.1874e-03 eta 0:12:59
epoch [24/50] batch [100/319] time 0.080 (0.090) data 0.000 (0.006) loss 2.5635 (2.2058) teacher_loss 1.3140 (0.9402) loss_zs_kd 0.8801 (0.8495) loss_oracle 0.8643 (0.8640) acc 53.1250 (67.1875) kd_loss 0.8174 (0.8336) lr 1.1874e-03 eta 0:12:47
epoch [24/50] batch [120/319] time 0.087 (0.091) data 0.000 (0.005) loss 2.2155 (2.2165) teacher_loss 0.9674 (0.9533) loss_zs_kd 0.7497 (0.8431) loss_oracle 0.8644 (0.8640) acc 62.5000 (66.5625) kd_loss 0.8160 (0.8312) lr 1.1874e-03 eta 0:12:52
epoch [24/50] batch [140/319] time 0.080 (0.090) data 0.000 (0.005) loss 2.1162 (2.2118) teacher_loss 0.8782 (0.9493) loss_zs_kd 0.9445 (0.8322) loss_oracle 0.8638 (0.8640) acc 71.8750 (66.7411) kd_loss 0.8060 (0.8305) lr 1.1874e-03 eta 0:12:40
epoch [24/50] batch [160/319] time 0.082 (0.089) data 0.000 (0.004) loss 2.1304 (2.2041) teacher_loss 0.8737 (0.9430) loss_zs_kd 0.6544 (0.8291) loss_oracle 0.8640 (0.8640) acc 78.1250 (66.9727) kd_loss 0.8247 (0.8291) lr 1.1874e-03 eta 0:12:29
epoch [24/50] batch [180/319] time 0.079 (0.088) data 0.000 (0.004) loss 2.3297 (2.2050) teacher_loss 1.1424 (0.9456) loss_zs_kd 0.7478 (0.8355) loss_oracle 0.8641 (0.8640) acc 62.5000 (66.9618) kd_loss 0.7553 (0.8273) lr 1.1874e-03 eta 0:12:24
epoch [24/50] batch [200/319] time 0.079 (0.088) data 0.000 (0.003) loss 2.0989 (2.2001) teacher_loss 0.8559 (0.9410) loss_zs_kd 0.7972 (0.8304) loss_oracle 0.8640 (0.8640) acc 68.7500 (67.0000) kd_loss 0.8110 (0.8271) lr 1.1874e-03 eta 0:12:17
epoch [24/50] batch [220/319] time 0.084 (0.087) data 0.000 (0.003) loss 2.4470 (2.1970) teacher_loss 1.1256 (0.9376) loss_zs_kd 0.9095 (0.8300) loss_oracle 0.8635 (0.8640) acc 65.6250 (67.3011) kd_loss 0.8896 (0.8274) lr 1.1874e-03 eta 0:12:11
epoch [24/50] batch [240/319] time 0.086 (0.087) data 0.000 (0.003) loss 2.4816 (2.1944) teacher_loss 1.1846 (0.9345) loss_zs_kd 0.8922 (0.8276) loss_oracle 0.8640 (0.8640) acc 59.3750 (67.3438) kd_loss 0.8650 (0.8279) lr 1.1874e-03 eta 0:12:07
epoch [24/50] batch [260/319] time 0.078 (0.087) data 0.000 (0.003) loss 2.4017 (2.1936) teacher_loss 1.1394 (0.9330) loss_zs_kd 0.6466 (0.8267) loss_oracle 0.8640 (0.8640) acc 59.3750 (67.4880) kd_loss 0.8303 (0.8285) lr 1.1874e-03 eta 0:12:03
epoch [24/50] batch [280/319] time 0.083 (0.086) data 0.000 (0.002) loss 2.3962 (2.1923) teacher_loss 1.1016 (0.9315) loss_zs_kd 0.6869 (0.8289) loss_oracle 0.8639 (0.8640) acc 56.2500 (67.5781) kd_loss 0.8627 (0.8289) lr 1.1874e-03 eta 0:11:57
epoch [24/50] batch [300/319] time 0.068 (0.085) data 0.000 (0.002) loss 2.0780 (2.1915) teacher_loss 0.7711 (0.9314) loss_zs_kd 0.9811 (0.8277) loss_oracle 0.8638 (0.8640) acc 71.8750 (67.6562) kd_loss 0.8750 (0.8281) lr 1.1874e-03 eta 0:11:47
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,785
* accuracy: 63.6%
* error: 36.4%
* macro_f1: 55.3%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,193
* accuracy: 53.3%
* error: 46.7%
* macro_f1: 22.5%
******* Domain 2 best val acc:      63.6%, epoch: 24 *******
******* Domain 2 best val test acc: 53.3%, epoch: 24 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [25/50] batch [20/319] time 0.081 (0.099) data 0.000 (0.024) loss 2.2191 (2.1826) teacher_loss 0.9676 (0.9185) loss_zs_kd 0.8364 (0.8481) loss_oracle 0.8637 (0.8638) acc 59.3750 (68.9062) kd_loss 0.8196 (0.8322) lr 1.1253e-03 eta 0:13:41
epoch [25/50] batch [40/319] time 0.080 (0.090) data 0.000 (0.012) loss 2.3645 (2.2176) teacher_loss 1.1216 (0.9629) loss_zs_kd 0.6445 (0.8035) loss_oracle 0.8641 (0.8639) acc 53.1250 (66.4844) kd_loss 0.8109 (0.8228) lr 1.1253e-03 eta 0:12:20
epoch [25/50] batch [60/319] time 0.081 (0.088) data 0.000 (0.008) loss 2.5700 (2.2168) teacher_loss 1.2818 (0.9623) loss_zs_kd 0.9400 (0.7832) loss_oracle 0.8636 (0.8638) acc 56.2500 (66.1458) kd_loss 0.8563 (0.8226) lr 1.1253e-03 eta 0:12:02
epoch [25/50] batch [80/319] time 0.083 (0.085) data 0.000 (0.006) loss 2.2019 (2.2306) teacher_loss 0.9994 (0.9760) loss_zs_kd 0.7842 (0.7885) loss_oracle 0.8641 (0.8638) acc 62.5000 (65.5469) kd_loss 0.7704 (0.8228) lr 1.1253e-03 eta 0:11:40
epoch [25/50] batch [100/319] time 0.073 (0.084) data 0.000 (0.005) loss 2.4978 (2.2375) teacher_loss 1.2580 (0.9812) loss_zs_kd 0.7640 (0.7965) loss_oracle 0.8639 (0.8638) acc 56.2500 (64.7188) kd_loss 0.8079 (0.8244) lr 1.1253e-03 eta 0:11:26
epoch [25/50] batch [120/319] time 0.088 (0.083) data 0.000 (0.004) loss 2.1342 (2.2406) teacher_loss 0.8973 (0.9869) loss_zs_kd 1.0110 (0.7947) loss_oracle 0.8637 (0.8638) acc 71.8750 (64.6094) kd_loss 0.8050 (0.8217) lr 1.1253e-03 eta 0:11:20
epoch [25/50] batch [140/319] time 0.086 (0.083) data 0.001 (0.004) loss 2.1092 (2.2347) teacher_loss 0.7792 (0.9811) loss_zs_kd 0.9541 (0.7963) loss_oracle 0.8641 (0.8638) acc 75.0000 (64.6652) kd_loss 0.8980 (0.8217) lr 1.1253e-03 eta 0:11:17
epoch [25/50] batch [160/319] time 0.083 (0.083) data 0.000 (0.003) loss 2.0690 (2.2315) teacher_loss 0.7910 (0.9763) loss_zs_kd 0.9427 (0.7996) loss_oracle 0.8637 (0.8638) acc 78.1250 (65.2148) kd_loss 0.8462 (0.8232) lr 1.1253e-03 eta 0:11:13
epoch [25/50] batch [180/319] time 0.085 (0.082) data 0.000 (0.003) loss 2.0918 (2.2201) teacher_loss 0.8419 (0.9663) loss_zs_kd 0.7508 (0.8087) loss_oracle 0.8638 (0.8638) acc 62.5000 (65.8507) kd_loss 0.8180 (0.8218) lr 1.1253e-03 eta 0:11:08
epoch [25/50] batch [200/319] time 0.084 (0.082) data 0.000 (0.003) loss 2.2260 (2.2121) teacher_loss 1.0112 (0.9576) loss_zs_kd 0.9104 (0.8228) loss_oracle 0.8636 (0.8638) acc 68.7500 (66.3125) kd_loss 0.7830 (0.8226) lr 1.1253e-03 eta 0:11:07
epoch [25/50] batch [220/319] time 0.082 (0.083) data 0.000 (0.002) loss 2.1027 (2.2128) teacher_loss 0.8621 (0.9574) loss_zs_kd 0.9989 (0.8316) loss_oracle 0.8640 (0.8638) acc 71.8750 (66.4347) kd_loss 0.8086 (0.8235) lr 1.1253e-03 eta 0:11:06
epoch [25/50] batch [240/319] time 0.077 (0.082) data 0.000 (0.002) loss 2.3420 (2.2045) teacher_loss 1.0797 (0.9473) loss_zs_kd 0.9890 (0.8390) loss_oracle 0.8642 (0.8638) acc 59.3750 (66.8099) kd_loss 0.8302 (0.8253) lr 1.1253e-03 eta 0:11:04
epoch [25/50] batch [260/319] time 0.081 (0.082) data 0.000 (0.002) loss 2.0657 (2.2043) teacher_loss 0.8132 (0.9464) loss_zs_kd 0.9841 (0.8481) loss_oracle 0.8642 (0.8638) acc 71.8750 (66.7067) kd_loss 0.8204 (0.8260) lr 1.1253e-03 eta 0:11:01
epoch [25/50] batch [280/319] time 0.082 (0.082) data 0.000 (0.002) loss 2.1833 (2.2003) teacher_loss 0.9595 (0.9412) loss_zs_kd 0.7987 (0.8487) loss_oracle 0.8642 (0.8638) acc 59.3750 (66.9085) kd_loss 0.7917 (0.8271) lr 1.1253e-03 eta 0:10:56
epoch [25/50] batch [300/319] time 0.074 (0.083) data 0.000 (0.002) loss 2.1475 (2.1982) teacher_loss 0.9745 (0.9397) loss_zs_kd 0.8179 (0.8509) loss_oracle 0.8638 (0.8638) acc 68.7500 (66.8438) kd_loss 0.7411 (0.8265) lr 1.1253e-03 eta 0:11:06
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,742
* accuracy: 62.6%
* error: 37.4%
* macro_f1: 54.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,194
* accuracy: 53.3%
* error: 46.7%
* macro_f1: 23.4%
******* Domain 2 best val acc:      63.6%, epoch: 24 *******
******* Domain 2 best val test acc: 53.3%, epoch: 24 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [26/50] batch [20/319] time 0.077 (0.103) data 0.000 (0.027) loss 2.1579 (2.2363) teacher_loss 0.9113 (0.9759) loss_zs_kd 0.6356 (0.8372) loss_oracle 0.8641 (0.8639) acc 62.5000 (64.6875) kd_loss 0.8145 (0.8284) lr 1.0628e-03 eta 0:13:39
epoch [26/50] batch [40/319] time 0.078 (0.090) data 0.000 (0.014) loss 2.1884 (2.2157) teacher_loss 0.9213 (0.9521) loss_zs_kd 0.9346 (0.8254) loss_oracle 0.8637 (0.8640) acc 62.5000 (65.9375) kd_loss 0.8352 (0.8316) lr 1.0628e-03 eta 0:11:56
epoch [26/50] batch [60/319] time 0.085 (0.088) data 0.000 (0.009) loss 2.2123 (2.1843) teacher_loss 0.9370 (0.9216) loss_zs_kd 0.7741 (0.8454) loss_oracle 0.8639 (0.8639) acc 59.3750 (67.1354) kd_loss 0.8434 (0.8308) lr 1.0628e-03 eta 0:11:37
epoch [26/50] batch [80/319] time 0.089 (0.088) data 0.000 (0.007) loss 2.1637 (2.1865) teacher_loss 0.9124 (0.9227) loss_zs_kd 1.1463 (0.8653) loss_oracle 0.8637 (0.8639) acc 71.8750 (67.3828) kd_loss 0.8194 (0.8319) lr 1.0628e-03 eta 0:11:30
epoch [26/50] batch [100/319] time 0.112 (0.089) data 0.000 (0.006) loss 2.2153 (2.1883) teacher_loss 0.9716 (0.9230) loss_zs_kd 0.7770 (0.8769) loss_oracle 0.8638 (0.8639) acc 62.5000 (67.5625) kd_loss 0.8118 (0.8333) lr 1.0628e-03 eta 0:11:39
epoch [26/50] batch [120/319] time 0.066 (0.087) data 0.000 (0.005) loss 2.1248 (2.1751) teacher_loss 0.8397 (0.9060) loss_zs_kd 0.9354 (0.8831) loss_oracle 0.8634 (0.8638) acc 68.7500 (68.0990) kd_loss 0.8535 (0.8371) lr 1.0628e-03 eta 0:11:21
epoch [26/50] batch [140/319] time 0.090 (0.085) data 0.000 (0.004) loss 2.2761 (2.1739) teacher_loss 0.9892 (0.9041) loss_zs_kd 0.8980 (0.8852) loss_oracle 0.8637 (0.8638) acc 59.3750 (68.2812) kd_loss 0.8551 (0.8379) lr 1.0628e-03 eta 0:11:02
epoch [26/50] batch [160/319] time 0.085 (0.085) data 0.000 (0.004) loss 2.0373 (2.1694) teacher_loss 0.7641 (0.9003) loss_zs_kd 0.8146 (0.8833) loss_oracle 0.8639 (0.8638) acc 71.8750 (68.6133) kd_loss 0.8412 (0.8372) lr 1.0628e-03 eta 0:11:00
epoch [26/50] batch [180/319] time 0.088 (0.085) data 0.000 (0.003) loss 1.9547 (2.1681) teacher_loss 0.7085 (0.8988) loss_zs_kd 0.8823 (0.8836) loss_oracle 0.8633 (0.8638) acc 71.8750 (68.6979) kd_loss 0.8146 (0.8374) lr 1.0628e-03 eta 0:10:58
epoch [26/50] batch [200/319] time 0.084 (0.085) data 0.000 (0.003) loss 2.4263 (2.1713) teacher_loss 1.1865 (0.9033) loss_zs_kd 0.7618 (0.8792) loss_oracle 0.8638 (0.8638) acc 59.3750 (68.3438) kd_loss 0.8078 (0.8361) lr 1.0628e-03 eta 0:10:58
epoch [26/50] batch [220/319] time 0.082 (0.085) data 0.000 (0.003) loss 1.8501 (2.1729) teacher_loss 0.7246 (0.9068) loss_zs_kd 0.6605 (0.8757) loss_oracle 0.8635 (0.8638) acc 68.7500 (68.1108) kd_loss 0.6937 (0.8342) lr 1.0628e-03 eta 0:10:58
epoch [26/50] batch [240/319] time 0.084 (0.085) data 0.000 (0.003) loss 2.0960 (2.1751) teacher_loss 0.8519 (0.9102) loss_zs_kd 0.8676 (0.8706) loss_oracle 0.8637 (0.8638) acc 62.5000 (67.9557) kd_loss 0.8122 (0.8330) lr 1.0628e-03 eta 0:10:54
epoch [26/50] batch [260/319] time 0.087 (0.084) data 0.000 (0.002) loss 2.1817 (2.1727) teacher_loss 0.8951 (0.9074) loss_zs_kd 0.7344 (0.8698) loss_oracle 0.8635 (0.8638) acc 65.6250 (67.9928) kd_loss 0.8548 (0.8335) lr 1.0628e-03 eta 0:10:50
epoch [26/50] batch [280/319] time 0.082 (0.084) data 0.000 (0.002) loss 2.1542 (2.1753) teacher_loss 0.8961 (0.9106) loss_zs_kd 0.7539 (0.8690) loss_oracle 0.8635 (0.8638) acc 65.6250 (67.9353) kd_loss 0.8264 (0.8328) lr 1.0628e-03 eta 0:10:47
epoch [26/50] batch [300/319] time 0.075 (0.084) data 0.000 (0.002) loss 2.6788 (2.1813) teacher_loss 1.3898 (0.9161) loss_zs_kd 0.8680 (0.8641) loss_oracle 0.8639 (0.8638) acc 46.8750 (67.7083) kd_loss 0.8571 (0.8333) lr 1.0628e-03 eta 0:10:43
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,799
* accuracy: 63.9%
* error: 36.1%
* macro_f1: 55.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,058
* accuracy: 52.0%
* error: 48.0%
* macro_f1: 22.8%
******* Domain 2 best val acc:      63.9%, epoch: 26 *******
******* Domain 2 best val test acc: 52.0%, epoch: 26 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [27/50] batch [20/319] time 0.067 (0.110) data 0.000 (0.026) loss 1.9663 (2.1829) teacher_loss 0.6807 (0.9138) loss_zs_kd 0.6180 (0.8319) loss_oracle 0.8636 (0.8636) acc 78.1250 (67.3438) kd_loss 0.8538 (0.8373) lr 1.0000e-03 eta 0:13:58
epoch [27/50] batch [40/319] time 0.074 (0.094) data 0.000 (0.013) loss 1.8488 (2.1683) teacher_loss 0.6313 (0.9112) loss_zs_kd 1.0735 (0.8536) loss_oracle 0.8636 (0.8637) acc 78.1250 (67.8125) kd_loss 0.7857 (0.8252) lr 1.0000e-03 eta 0:11:54
epoch [27/50] batch [60/319] time 0.079 (0.088) data 0.000 (0.009) loss 2.0039 (2.1434) teacher_loss 0.7151 (0.8867) loss_zs_kd 1.0288 (0.8409) loss_oracle 0.8635 (0.8636) acc 78.1250 (68.6979) kd_loss 0.8571 (0.8249) lr 1.0000e-03 eta 0:11:09
epoch [27/50] batch [80/319] time 0.084 (0.085) data 0.000 (0.007) loss 2.3552 (2.1490) teacher_loss 1.0741 (0.8922) loss_zs_kd 0.8539 (0.8357) loss_oracle 0.8638 (0.8636) acc 56.2500 (68.5156) kd_loss 0.8493 (0.8250) lr 1.0000e-03 eta 0:10:47
epoch [27/50] batch [100/319] time 0.093 (0.084) data 0.000 (0.005) loss 2.0947 (2.1482) teacher_loss 0.7882 (0.8945) loss_zs_kd 0.9158 (0.8430) loss_oracle 0.8636 (0.8637) acc 68.7500 (68.3750) kd_loss 0.8747 (0.8219) lr 1.0000e-03 eta 0:10:34
epoch [27/50] batch [120/319] time 0.089 (0.083) data 0.000 (0.004) loss 2.1150 (2.1525) teacher_loss 0.8307 (0.8992) loss_zs_kd 1.0067 (0.8617) loss_oracle 0.8636 (0.8637) acc 65.6250 (68.3594) kd_loss 0.8525 (0.8215) lr 1.0000e-03 eta 0:10:29
epoch [27/50] batch [140/319] time 0.092 (0.083) data 0.000 (0.004) loss 2.0684 (2.1532) teacher_loss 0.8372 (0.9004) loss_zs_kd 0.9767 (0.8695) loss_oracle 0.8636 (0.8637) acc 71.8750 (68.5045) kd_loss 0.7994 (0.8210) lr 1.0000e-03 eta 0:10:22
epoch [27/50] batch [160/319] time 0.076 (0.083) data 0.000 (0.003) loss 1.9999 (2.1486) teacher_loss 0.7648 (0.8944) loss_zs_kd 0.9791 (0.8875) loss_oracle 0.8635 (0.8636) acc 75.0000 (68.7500) kd_loss 0.8033 (0.8224) lr 1.0000e-03 eta 0:10:18
epoch [27/50] batch [180/319] time 0.081 (0.083) data 0.000 (0.003) loss 1.9979 (2.1533) teacher_loss 0.7391 (0.8977) loss_zs_kd 0.8730 (0.8914) loss_oracle 0.8637 (0.8636) acc 71.8750 (68.5069) kd_loss 0.8270 (0.8238) lr 1.0000e-03 eta 0:10:17
epoch [27/50] batch [200/319] time 0.084 (0.083) data 0.000 (0.003) loss 2.0118 (2.1536) teacher_loss 0.7285 (0.8976) loss_zs_kd 1.1714 (0.8995) loss_oracle 0.8635 (0.8636) acc 78.1250 (68.5156) kd_loss 0.8515 (0.8242) lr 1.0000e-03 eta 0:10:17
epoch [27/50] batch [220/319] time 0.075 (0.082) data 0.000 (0.003) loss 2.1829 (2.1490) teacher_loss 0.9112 (0.8900) loss_zs_kd 0.9468 (0.9053) loss_oracle 0.8636 (0.8636) acc 62.5000 (69.0341) kd_loss 0.8399 (0.8271) lr 1.0000e-03 eta 0:10:13
epoch [27/50] batch [240/319] time 0.082 (0.083) data 0.000 (0.002) loss 2.2972 (2.1532) teacher_loss 0.9835 (0.8934) loss_zs_kd 0.7855 (0.9081) loss_oracle 0.8637 (0.8636) acc 65.6250 (69.1146) kd_loss 0.8819 (0.8280) lr 1.0000e-03 eta 0:10:12
epoch [27/50] batch [260/319] time 0.083 (0.083) data 0.000 (0.002) loss 1.9799 (2.1500) teacher_loss 0.7002 (0.8900) loss_zs_kd 0.9986 (0.9058) loss_oracle 0.8637 (0.8636) acc 75.0000 (69.2788) kd_loss 0.8478 (0.8282) lr 1.0000e-03 eta 0:10:12
epoch [27/50] batch [280/319] time 0.137 (0.084) data 0.000 (0.002) loss 2.4263 (2.1547) teacher_loss 1.1398 (0.8943) loss_zs_kd 1.0401 (0.9046) loss_oracle 0.8635 (0.8636) acc 56.2500 (69.2188) kd_loss 0.8548 (0.8286) lr 1.0000e-03 eta 0:10:16
epoch [27/50] batch [300/319] time 0.088 (0.084) data 0.000 (0.002) loss 2.4272 (2.1516) teacher_loss 1.1568 (0.8907) loss_zs_kd 1.0521 (0.9000) loss_oracle 0.8636 (0.8636) acc 56.2500 (69.3646) kd_loss 0.8386 (0.8291) lr 1.0000e-03 eta 0:10:17
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,775
* accuracy: 63.4%
* error: 36.6%
* macro_f1: 55.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,066
* accuracy: 52.0%
* error: 48.0%
* macro_f1: 23.5%
******* Domain 2 best val acc:      63.9%, epoch: 26 *******
******* Domain 2 best val test acc: 52.0%, epoch: 26 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [28/50] batch [20/319] time 0.073 (0.110) data 0.000 (0.026) loss 2.0406 (2.0998) teacher_loss 0.7484 (0.8252) loss_zs_kd 1.0200 (0.9180) loss_oracle 0.8633 (0.8635) acc 78.1250 (70.3125) kd_loss 0.8605 (0.8429) lr 9.3721e-04 eta 0:13:26
epoch [28/50] batch [40/319] time 0.078 (0.095) data 0.000 (0.013) loss 2.3479 (2.1214) teacher_loss 1.0115 (0.8449) loss_zs_kd 1.0428 (0.8979) loss_oracle 0.8634 (0.8635) acc 56.2500 (70.3906) kd_loss 0.9048 (0.8448) lr 9.3721e-04 eta 0:11:34
epoch [28/50] batch [60/319] time 0.082 (0.090) data 0.000 (0.009) loss 2.0077 (2.1465) teacher_loss 0.7513 (0.8721) loss_zs_kd 0.9415 (0.9155) loss_oracle 0.8635 (0.8635) acc 78.1250 (69.8958) kd_loss 0.8246 (0.8427) lr 9.3721e-04 eta 0:10:56
epoch [28/50] batch [80/319] time 0.085 (0.091) data 0.001 (0.007) loss 2.1491 (2.1278) teacher_loss 0.8725 (0.8515) loss_zs_kd 0.8954 (0.9186) loss_oracle 0.8636 (0.8635) acc 68.7500 (69.9609) kd_loss 0.8448 (0.8446) lr 9.3721e-04 eta 0:10:59
epoch [28/50] batch [100/319] time 0.090 (0.089) data 0.000 (0.005) loss 2.1490 (2.1260) teacher_loss 0.8941 (0.8510) loss_zs_kd 1.0807 (0.9430) loss_oracle 0.8635 (0.8635) acc 71.8750 (70.3125) kd_loss 0.8232 (0.8432) lr 9.3721e-04 eta 0:10:41
epoch [28/50] batch [120/319] time 0.081 (0.087) data 0.000 (0.005) loss 2.0293 (2.1239) teacher_loss 0.7881 (0.8500) loss_zs_kd 1.0666 (0.9454) loss_oracle 0.8638 (0.8635) acc 75.0000 (70.5729) kd_loss 0.8093 (0.8422) lr 9.3721e-04 eta 0:10:27
epoch [28/50] batch [140/319] time 0.083 (0.086) data 0.000 (0.004) loss 2.0781 (2.1287) teacher_loss 0.8572 (0.8563) loss_zs_kd 0.9837 (0.9416) loss_oracle 0.8636 (0.8635) acc 71.8750 (70.5357) kd_loss 0.7891 (0.8406) lr 9.3721e-04 eta 0:10:15
epoch [28/50] batch [160/319] time 0.086 (0.085) data 0.000 (0.003) loss 1.8555 (2.1233) teacher_loss 0.5883 (0.8521) loss_zs_kd 1.1328 (0.9310) loss_oracle 0.8634 (0.8635) acc 81.2500 (70.8594) kd_loss 0.8355 (0.8394) lr 9.3721e-04 eta 0:10:07
epoch [28/50] batch [180/319] time 0.085 (0.084) data 0.000 (0.003) loss 1.9976 (2.1144) teacher_loss 0.7310 (0.8442) loss_zs_kd 0.9124 (0.9287) loss_oracle 0.8634 (0.8635) acc 81.2500 (71.2674) kd_loss 0.8349 (0.8385) lr 9.3721e-04 eta 0:09:58
epoch [28/50] batch [200/319] time 0.083 (0.083) data 0.000 (0.003) loss 2.1683 (2.1203) teacher_loss 0.9210 (0.8491) loss_zs_kd 0.9188 (0.9298) loss_oracle 0.8637 (0.8635) acc 65.6250 (71.2500) kd_loss 0.8154 (0.8394) lr 9.3721e-04 eta 0:09:55
epoch [28/50] batch [220/319] time 0.089 (0.083) data 0.000 (0.003) loss 2.4669 (2.1259) teacher_loss 1.1399 (0.8540) loss_zs_kd 0.8519 (0.9324) loss_oracle 0.8634 (0.8635) acc 53.1250 (71.1364) kd_loss 0.8952 (0.8402) lr 9.3721e-04 eta 0:09:53
epoch [28/50] batch [240/319] time 0.076 (0.083) data 0.000 (0.002) loss 2.0680 (2.1246) teacher_loss 0.7923 (0.8534) loss_zs_kd 1.0178 (0.9396) loss_oracle 0.8636 (0.8635) acc 78.1250 (71.0547) kd_loss 0.8439 (0.8395) lr 9.3721e-04 eta 0:09:51
epoch [28/50] batch [260/319] time 0.084 (0.083) data 0.000 (0.002) loss 2.0079 (2.1189) teacher_loss 0.6722 (0.8487) loss_zs_kd 1.1099 (0.9432) loss_oracle 0.8634 (0.8635) acc 78.1250 (71.3101) kd_loss 0.9041 (0.8385) lr 9.3721e-04 eta 0:09:47
epoch [28/50] batch [280/319] time 0.091 (0.083) data 0.000 (0.002) loss 2.0061 (2.1185) teacher_loss 0.7218 (0.8485) loss_zs_kd 0.9732 (0.9471) loss_oracle 0.8635 (0.8635) acc 75.0000 (71.2612) kd_loss 0.8525 (0.8382) lr 9.3721e-04 eta 0:09:45
epoch [28/50] batch [300/319] time 0.082 (0.083) data 0.000 (0.002) loss 2.2395 (2.1191) teacher_loss 0.9792 (0.8499) loss_zs_kd 0.8388 (0.9488) loss_oracle 0.8635 (0.8635) acc 65.6250 (71.2812) kd_loss 0.8286 (0.8375) lr 9.3721e-04 eta 0:09:44
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,713
* accuracy: 62.0%
* error: 38.0%
* macro_f1: 54.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,411
* accuracy: 45.3%
* error: 54.7%
* macro_f1: 21.7%
******* Domain 2 best val acc:      63.9%, epoch: 26 *******
******* Domain 2 best val test acc: 52.0%, epoch: 26 *******
******* Domain 2 best test acc:     56.2%, epoch: 13 *******
epoch [29/50] batch [20/319] time 0.084 (0.117) data 0.000 (0.031) loss 2.2319 (2.1539) teacher_loss 0.9621 (0.8925) loss_zs_kd 0.7998 (0.8166) loss_oracle 0.8637 (0.8635) acc 62.5000 (69.3750) kd_loss 0.8380 (0.8296) lr 8.7467e-04 eta 0:13:38
epoch [29/50] batch [40/319] time 0.080 (0.100) data 0.000 (0.016) loss 2.0486 (2.1195) teacher_loss 0.7964 (0.8596) loss_zs_kd 0.8787 (0.8440) loss_oracle 0.8635 (0.8635) acc 78.1250 (70.7812) kd_loss 0.8204 (0.8282) lr 8.7467e-04 eta 0:11:41
epoch [29/50] batch [60/319] time 0.089 (0.095) data 0.000 (0.011) loss 1.9000 (2.1257) teacher_loss 0.6244 (0.8607) loss_zs_kd 0.9226 (0.8695) loss_oracle 0.8634 (0.8635) acc 78.1250 (70.7292) kd_loss 0.8439 (0.8333) lr 8.7467e-04 eta 0:11:01
epoch [29/50] batch [80/319] time 0.079 (0.091) data 0.000 (0.008) loss 2.0513 (2.1226) teacher_loss 0.7783 (0.8588) loss_zs_kd 1.0525 (0.8925) loss_oracle 0.8634 (0.8635) acc 78.1250 (71.2500) kd_loss 0.8413 (0.8321) lr 8.7467e-04 eta 0:10:31
epoch [29/50] batch [100/319] time 0.078 (0.088) data 0.000 (0.006) loss 2.2241 (2.1232) teacher_loss 1.0034 (0.8573) loss_zs_kd 1.2095 (0.9049) loss_oracle 0.8634 (0.8635) acc 62.5000 (71.2500) kd_loss 0.7890 (0.8342) lr 8.7467e-04 eta 0:10:09
epoch [29/50] batch [120/319] time 0.086 (0.088) data 0.000 (0.005) loss 2.0218 (2.1197) teacher_loss 0.7540 (0.8546) loss_zs_kd 0.8492 (0.9100) loss_oracle 0.8632 (0.8635) acc 75.0000 (71.6667) kd_loss 0.8363 (0.8334) lr 8.7467e-04 eta 0:10:03
epoch [29/50] batch [140/319] time 0.076 (0.087) data 0.000 (0.005) loss 2.3834 (2.1250) teacher_loss 1.1138 (0.8594) loss_zs_kd 1.1125 (0.9148) loss_oracle 0.8634 (0.8634) acc 53.1250 (71.4286) kd_loss 0.8380 (0.8339) lr 8.7467e-04 eta 0:09:57
epoch [29/50] batch [160/319] time 0.086 (0.086) data 0.000 (0.004) loss 2.5679 (2.1358) teacher_loss 1.3050 (0.8717) loss_zs_kd 0.7825 (0.9166) loss_oracle 0.8633 (0.8634) acc 56.2500 (70.8984) kd_loss 0.8313 (0.8324) lr 8.7467e-04 eta 0:09:50
epoch [29/50] batch [180/319] time 0.056 (0.085) data 0.000 (0.004) loss 2.2521 (2.1430) teacher_loss 0.9418 (0.8799) loss_zs_kd 0.6158 (0.9124) loss_oracle 0.8634 (0.8634) acc 59.3750 (70.3299) kd_loss 0.8786 (0.8314) lr 8.7467e-04 eta 0:09:43
epoch [29/50] batch [200/319] time 0.083 (0.085) data 0.000 (0.003) loss 2.1510 (2.1522) teacher_loss 0.8843 (0.8893) loss_zs_kd 0.9483 (0.9066) loss_oracle 0.8634 (0.8634) acc 68.7500 (70.1094) kd_loss 0.8350 (0.8311) lr 8.7467e-04 eta 0:09:39
epoch [29/50] batch [220/319] time 0.074 (0.085) data 0.000 (0.003) loss 2.5094 (2.1510) teacher_loss 1.3006 (0.8885) loss_zs_kd 0.7743 (0.8967) loss_oracle 0.8635 (0.8634) acc 50.0000 (69.9290) kd_loss 0.7770 (0.8308) lr 8.7467e-04 eta 0:09:35
epoch [29/50] batch [240/319] time 0.077 (0.084) data 0.000 (0.003) loss 2.2224 (2.1516) teacher_loss 1.0112 (0.8891) loss_zs_kd 1.0746 (0.9062) loss_oracle 0.8633 (0.8634) acc 62.5000 (70.0781) kd_loss 0.7796 (0.8308) lr 8.7467e-04 eta 0:09:30
epoch [29/50] batch [260/319] time 0.086 (0.084) data 0.000 (0.003) loss 2.0998 (2.1566) teacher_loss 0.8596 (0.8936) loss_zs_kd 1.1223 (0.9155) loss_oracle 0.8632 (0.8634) acc 68.7500 (69.8918) kd_loss 0.8087 (0.8312) lr 8.7467e-04 eta 0:09:27
epoch [29/50] batch [280/319] time 0.073 (0.085) data 0.000 (0.002) loss 2.1475 (2.1567) teacher_loss 0.8595 (0.8949) loss_zs_kd 1.0771 (0.9246) loss_oracle 0.8635 (0.8634) acc 78.1250 (69.7991) kd_loss 0.8562 (0.8301) lr 8.7467e-04 eta 0:09:31
epoch [29/50] batch [300/319] time 0.081 (0.084) data 0.000 (0.002) loss 2.3359 (2.1594) teacher_loss 1.1502 (0.8983) loss_zs_kd 1.0112 (0.9297) loss_oracle 0.8634 (0.8634) acc 59.3750 (69.6458) kd_loss 0.7540 (0.8294) lr 8.7467e-04 eta 0:09:27
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,759
* accuracy: 63.0%
* error: 37.0%
* macro_f1: 55.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,532
* accuracy: 56.8%
* error: 43.2%
* macro_f1: 23.7%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      63.9%, epoch: 26 *******
******* Domain 2 best val test acc: 52.0%, epoch: 26 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [30/50] batch [20/319] time 0.083 (0.109) data 0.000 (0.030) loss 1.8809 (2.1819) teacher_loss 0.5961 (0.9023) loss_zs_kd 1.0200 (0.9754) loss_oracle 0.8634 (0.8634) acc 78.1250 (69.0625) kd_loss 0.8531 (0.8479) lr 8.1262e-04 eta 0:12:06
epoch [30/50] batch [40/319] time 0.089 (0.095) data 0.000 (0.015) loss 1.8967 (2.1957) teacher_loss 0.5795 (0.9116) loss_zs_kd 0.9557 (1.0155) loss_oracle 0.8634 (0.8634) acc 81.2500 (68.8281) kd_loss 0.8855 (0.8524) lr 8.1262e-04 eta 0:10:31
epoch [30/50] batch [60/319] time 0.182 (0.095) data 0.001 (0.010) loss 2.0939 (2.1947) teacher_loss 0.7981 (0.9134) loss_zs_kd 1.0295 (1.0122) loss_oracle 0.8633 (0.8634) acc 71.8750 (69.0104) kd_loss 0.8642 (0.8497) lr 8.1262e-04 eta 0:10:29
epoch [30/50] batch [80/319] time 0.077 (0.091) data 0.000 (0.008) loss 2.2602 (2.1931) teacher_loss 1.0015 (0.9156) loss_zs_kd 0.8061 (1.0084) loss_oracle 0.8635 (0.8634) acc 68.7500 (69.0625) kd_loss 0.8270 (0.8458) lr 8.1262e-04 eta 0:10:00
epoch [30/50] batch [100/319] time 0.078 (0.089) data 0.000 (0.006) loss 2.1703 (2.1942) teacher_loss 0.8947 (0.9205) loss_zs_kd 1.0205 (0.9951) loss_oracle 0.8634 (0.8634) acc 65.6250 (69.0312) kd_loss 0.8439 (0.8421) lr 8.1262e-04 eta 0:09:45
epoch [30/50] batch [120/319] time 0.079 (0.087) data 0.000 (0.005) loss 2.3229 (2.1993) teacher_loss 0.9941 (0.9259) loss_zs_kd 0.9420 (0.9835) loss_oracle 0.8634 (0.8634) acc 62.5000 (68.5156) kd_loss 0.8972 (0.8417) lr 8.1262e-04 eta 0:09:34
epoch [30/50] batch [140/319] time 0.086 (0.086) data 0.000 (0.004) loss 1.9269 (2.1869) teacher_loss 0.6828 (0.9162) loss_zs_kd 0.8476 (0.9704) loss_oracle 0.8634 (0.8634) acc 78.1250 (68.8616) kd_loss 0.8124 (0.8390) lr 8.1262e-04 eta 0:09:25
epoch [30/50] batch [160/319] time 0.097 (0.086) data 0.001 (0.004) loss 1.9816 (2.1837) teacher_loss 0.7298 (0.9157) loss_zs_kd 0.6182 (0.9534) loss_oracle 0.8633 (0.8634) acc 71.8750 (68.5156) kd_loss 0.8201 (0.8364) lr 8.1262e-04 eta 0:09:21
epoch [30/50] batch [180/319] time 0.080 (0.085) data 0.000 (0.004) loss 2.1489 (2.1828) teacher_loss 0.8749 (0.9130) loss_zs_kd 0.9460 (0.9448) loss_oracle 0.8633 (0.8634) acc 59.3750 (68.2812) kd_loss 0.8423 (0.8381) lr 8.1262e-04 eta 0:09:15
epoch [30/50] batch [200/319] time 0.086 (0.085) data 0.000 (0.003) loss 2.3153 (2.1771) teacher_loss 0.9728 (0.9068) loss_zs_kd 0.9653 (0.9473) loss_oracle 0.8634 (0.8634) acc 71.8750 (68.6406) kd_loss 0.9108 (0.8387) lr 8.1262e-04 eta 0:09:11
epoch [30/50] batch [220/319] time 0.068 (0.084) data 0.000 (0.003) loss 2.2297 (2.1753) teacher_loss 0.8839 (0.9043) loss_zs_kd 1.0021 (0.9564) loss_oracle 0.8633 (0.8634) acc 75.0000 (69.0057) kd_loss 0.9142 (0.8392) lr 8.1262e-04 eta 0:09:07
epoch [30/50] batch [240/319] time 0.086 (0.084) data 0.000 (0.003) loss 2.2726 (2.1826) teacher_loss 0.9558 (0.9114) loss_zs_kd 0.9130 (0.9566) loss_oracle 0.8633 (0.8634) acc 71.8750 (68.8021) kd_loss 0.8851 (0.8396) lr 8.1262e-04 eta 0:09:04
epoch [30/50] batch [260/319] time 0.083 (0.084) data 0.000 (0.003) loss 2.1802 (2.1814) teacher_loss 0.9552 (0.9119) loss_zs_kd 0.8127 (0.9499) loss_oracle 0.8634 (0.8634) acc 59.3750 (68.6418) kd_loss 0.7933 (0.8378) lr 8.1262e-04 eta 0:09:01
epoch [30/50] batch [280/319] time 0.074 (0.084) data 0.000 (0.002) loss 2.1872 (2.1788) teacher_loss 0.9253 (0.9097) loss_zs_kd 0.8096 (0.9463) loss_oracle 0.8633 (0.8634) acc 68.7500 (68.6496) kd_loss 0.8302 (0.8374) lr 8.1262e-04 eta 0:08:58
epoch [30/50] batch [300/319] time 0.083 (0.084) data 0.000 (0.002) loss 2.5063 (2.1789) teacher_loss 1.1997 (0.9094) loss_zs_kd 0.8892 (0.9431) loss_oracle 0.8635 (0.8634) acc 59.3750 (68.6771) kd_loss 0.8749 (0.8378) lr 8.1262e-04 eta 0:08:57
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,821
* accuracy: 64.4%
* error: 35.6%
* macro_f1: 56.3%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,348
* accuracy: 54.9%
* error: 45.1%
* macro_f1: 23.5%
******* Domain 2 best val acc:      64.4%, epoch: 30 *******
******* Domain 2 best val test acc: 54.9%, epoch: 30 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [31/50] batch [20/319] time 0.082 (0.108) data 0.000 (0.032) loss 1.9878 (2.0682) teacher_loss 0.7404 (0.8082) loss_zs_kd 1.1202 (0.9442) loss_oracle 0.8632 (0.8634) acc 71.8750 (72.0312) kd_loss 0.8158 (0.8283) lr 7.5131e-04 eta 0:11:24
epoch [31/50] batch [40/319] time 0.089 (0.092) data 0.000 (0.016) loss 2.0162 (2.0924) teacher_loss 0.8088 (0.8300) loss_zs_kd 0.8659 (0.9707) loss_oracle 0.8634 (0.8633) acc 71.8750 (71.0156) kd_loss 0.7757 (0.8308) lr 7.5131e-04 eta 0:09:46
epoch [31/50] batch [60/319] time 0.081 (0.089) data 0.000 (0.011) loss 2.1973 (2.1313) teacher_loss 0.9201 (0.8715) loss_zs_kd 0.9413 (0.9599) loss_oracle 0.8635 (0.8634) acc 68.7500 (69.6875) kd_loss 0.8454 (0.8280) lr 7.5131e-04 eta 0:09:19
epoch [31/50] batch [80/319] time 0.089 (0.096) data 0.000 (0.008) loss 2.1488 (2.1404) teacher_loss 0.9311 (0.8800) loss_zs_kd 0.8567 (0.9506) loss_oracle 0.8634 (0.8634) acc 56.2500 (68.8672) kd_loss 0.7860 (0.8287) lr 7.5131e-04 eta 0:10:02
epoch [31/50] batch [100/319] time 0.083 (0.099) data 0.000 (0.007) loss 2.1769 (2.1337) teacher_loss 0.9212 (0.8742) loss_zs_kd 1.1462 (0.9509) loss_oracle 0.8634 (0.8634) acc 71.8750 (69.2500) kd_loss 0.8240 (0.8279) lr 7.5131e-04 eta 0:10:20
epoch [31/50] batch [120/319] time 0.142 (0.107) data 0.000 (0.005) loss 1.9521 (2.1466) teacher_loss 0.6804 (0.8839) loss_zs_kd 0.8642 (0.9431) loss_oracle 0.8634 (0.8634) acc 78.1250 (69.2188) kd_loss 0.8400 (0.8310) lr 7.5131e-04 eta 0:11:09
epoch [31/50] batch [140/319] time 0.154 (0.113) data 0.000 (0.005) loss 2.0233 (2.1544) teacher_loss 0.7604 (0.8909) loss_zs_kd 1.0934 (0.9441) loss_oracle 0.8634 (0.8634) acc 75.0000 (68.9509) kd_loss 0.8312 (0.8318) lr 7.5131e-04 eta 0:11:46
epoch [31/50] batch [160/319] time 0.149 (0.118) data 0.000 (0.004) loss 2.4677 (2.1587) teacher_loss 1.1417 (0.8947) loss_zs_kd 1.0848 (0.9557) loss_oracle 0.8634 (0.8634) acc 56.2500 (68.5352) kd_loss 0.8943 (0.8323) lr 7.5131e-04 eta 0:12:12
epoch [31/50] batch [180/319] time 0.111 (0.120) data 0.000 (0.004) loss 2.4395 (2.1633) teacher_loss 1.1545 (0.8993) loss_zs_kd 0.9582 (0.9607) loss_oracle 0.8632 (0.8634) acc 59.3750 (68.3854) kd_loss 0.8534 (0.8323) lr 7.5131e-04 eta 0:12:25
epoch [31/50] batch [200/319] time 0.091 (0.120) data 0.000 (0.003) loss 2.0295 (2.1641) teacher_loss 0.8021 (0.8998) loss_zs_kd 0.9707 (0.9680) loss_oracle 0.8634 (0.8634) acc 71.8750 (68.3438) kd_loss 0.7957 (0.8326) lr 7.5131e-04 eta 0:12:21
epoch [31/50] batch [220/319] time 0.095 (0.121) data 0.000 (0.003) loss 2.0518 (2.1660) teacher_loss 0.7681 (0.9018) loss_zs_kd 1.1572 (0.9693) loss_oracle 0.8632 (0.8634) acc 71.8750 (68.2528) kd_loss 0.8520 (0.8325) lr 7.5131e-04 eta 0:12:28
epoch [31/50] batch [240/319] time 0.144 (0.124) data 0.000 (0.003) loss 2.1433 (2.1642) teacher_loss 0.8911 (0.9018) loss_zs_kd 0.6847 (0.9649) loss_oracle 0.8634 (0.8634) acc 68.7500 (68.2161) kd_loss 0.8205 (0.8308) lr 7.5131e-04 eta 0:12:38
epoch [31/50] batch [260/319] time 0.151 (0.126) data 0.000 (0.003) loss 2.1925 (2.1604) teacher_loss 0.9333 (0.8974) loss_zs_kd 1.0939 (0.9647) loss_oracle 0.8634 (0.8634) acc 65.6250 (68.4375) kd_loss 0.8274 (0.8312) lr 7.5131e-04 eta 0:12:49
epoch [31/50] batch [280/319] time 0.118 (0.126) data 0.000 (0.003) loss 2.2435 (2.1654) teacher_loss 0.9588 (0.9021) loss_zs_kd 1.0823 (0.9659) loss_oracle 0.8633 (0.8634) acc 62.5000 (68.2031) kd_loss 0.8530 (0.8316) lr 7.5131e-04 eta 0:12:48
epoch [31/50] batch [300/319] time 0.105 (0.125) data 0.000 (0.002) loss 1.7946 (2.1669) teacher_loss 0.5490 (0.9044) loss_zs_kd 0.9339 (0.9663) loss_oracle 0.8633 (0.8633) acc 78.1250 (68.1667) kd_loss 0.8140 (0.8307) lr 7.5131e-04 eta 0:12:38
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,734
* accuracy: 62.4%
* error: 37.6%
* macro_f1: 54.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,370
* accuracy: 55.2%
* error: 44.8%
* macro_f1: 22.6%
******* Domain 2 best val acc:      64.4%, epoch: 30 *******
******* Domain 2 best val test acc: 54.9%, epoch: 30 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [32/50] batch [20/319] time 0.103 (0.145) data 0.000 (0.026) loss 2.3070 (2.1837) teacher_loss 1.0334 (0.9253) loss_zs_kd 1.2290 (0.9959) loss_oracle 0.8634 (0.8633) acc 59.3750 (66.7188) kd_loss 0.8419 (0.8268) lr 6.9098e-04 eta 0:14:38
epoch [32/50] batch [40/319] time 0.116 (0.126) data 0.000 (0.013) loss 2.2976 (2.1687) teacher_loss 1.0331 (0.9115) loss_zs_kd 0.8430 (0.9637) loss_oracle 0.8633 (0.8633) acc 62.5000 (68.1250) kd_loss 0.8328 (0.8255) lr 6.9098e-04 eta 0:12:40
epoch [32/50] batch [60/319] time 0.078 (0.115) data 0.000 (0.009) loss 2.0216 (2.1546) teacher_loss 0.7142 (0.8903) loss_zs_kd 0.8899 (0.9888) loss_oracle 0.8633 (0.8633) acc 87.5000 (69.5312) kd_loss 0.8758 (0.8326) lr 6.9098e-04 eta 0:11:31
epoch [32/50] batch [80/319] time 0.078 (0.110) data 0.000 (0.007) loss 1.9750 (2.1567) teacher_loss 0.6681 (0.8905) loss_zs_kd 1.0665 (0.9935) loss_oracle 0.8633 (0.8633) acc 78.1250 (69.4141) kd_loss 0.8753 (0.8346) lr 6.9098e-04 eta 0:10:59
epoch [32/50] batch [100/319] time 0.078 (0.107) data 0.000 (0.005) loss 2.0023 (2.1676) teacher_loss 0.7301 (0.9007) loss_zs_kd 0.8542 (0.9844) loss_oracle 0.8633 (0.8633) acc 81.2500 (69.0625) kd_loss 0.8406 (0.8352) lr 6.9098e-04 eta 0:10:39
epoch [32/50] batch [120/319] time 0.089 (0.105) data 0.000 (0.005) loss 1.9656 (2.1567) teacher_loss 0.7399 (0.8885) loss_zs_kd 1.0331 (0.9680) loss_oracle 0.8632 (0.8633) acc 75.0000 (69.4271) kd_loss 0.7941 (0.8365) lr 6.9098e-04 eta 0:10:25
epoch [32/50] batch [140/319] time 0.119 (0.106) data 0.000 (0.004) loss 2.1509 (2.1522) teacher_loss 0.8445 (0.8849) loss_zs_kd 1.1297 (0.9605) loss_oracle 0.8633 (0.8633) acc 71.8750 (69.6205) kd_loss 0.8749 (0.8356) lr 6.9098e-04 eta 0:10:27
epoch [32/50] batch [160/319] time 0.145 (0.105) data 0.000 (0.003) loss 2.4086 (2.1563) teacher_loss 1.1009 (0.8893) loss_zs_kd 0.8548 (0.9599) loss_oracle 0.8632 (0.8633) acc 68.7500 (69.4922) kd_loss 0.8761 (0.8354) lr 6.9098e-04 eta 0:10:22
epoch [32/50] batch [180/319] time 0.097 (0.106) data 0.000 (0.003) loss 2.4062 (2.1556) teacher_loss 1.1279 (0.8892) loss_zs_kd 0.7746 (0.9589) loss_oracle 0.8633 (0.8633) acc 56.2500 (69.4618) kd_loss 0.8466 (0.8348) lr 6.9098e-04 eta 0:10:25
epoch [32/50] batch [200/319] time 0.118 (0.106) data 0.000 (0.003) loss 2.1381 (2.1578) teacher_loss 0.8859 (0.8926) loss_zs_kd 0.8271 (0.9568) loss_oracle 0.8632 (0.8633) acc 65.6250 (69.0938) kd_loss 0.8206 (0.8335) lr 6.9098e-04 eta 0:10:19
epoch [32/50] batch [220/319] time 0.097 (0.107) data 0.001 (0.003) loss 2.2048 (2.1586) teacher_loss 0.9486 (0.8937) loss_zs_kd 0.7310 (0.9473) loss_oracle 0.8633 (0.8633) acc 71.8750 (68.8352) kd_loss 0.8245 (0.8332) lr 6.9098e-04 eta 0:10:23
epoch [32/50] batch [240/319] time 0.094 (0.107) data 0.000 (0.002) loss 2.0530 (2.1642) teacher_loss 0.8001 (0.8999) loss_zs_kd 0.7712 (0.9377) loss_oracle 0.8633 (0.8633) acc 71.8750 (68.6328) kd_loss 0.8213 (0.8326) lr 6.9098e-04 eta 0:10:24
epoch [32/50] batch [260/319] time 0.146 (0.111) data 0.000 (0.002) loss 2.1367 (2.1724) teacher_loss 0.9027 (0.9081) loss_zs_kd 0.9615 (0.9339) loss_oracle 0.8633 (0.8633) acc 68.7500 (68.2933) kd_loss 0.8024 (0.8327) lr 6.9098e-04 eta 0:10:42
epoch [32/50] batch [280/319] time 0.184 (0.113) data 0.000 (0.002) loss 2.3663 (2.1803) teacher_loss 1.0909 (0.9164) loss_zs_kd 0.8167 (0.9296) loss_oracle 0.8633 (0.8633) acc 65.6250 (67.8460) kd_loss 0.8437 (0.8322) lr 6.9098e-04 eta 0:10:50
epoch [32/50] batch [300/319] time 0.092 (0.112) data 0.000 (0.002) loss 2.1449 (2.1798) teacher_loss 0.8544 (0.9167) loss_zs_kd 0.7525 (0.9326) loss_oracle 0.8633 (0.8633) acc 68.7500 (67.6354) kd_loss 0.8589 (0.8314) lr 6.9098e-04 eta 0:10:46
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,804
* accuracy: 64.0%
* error: 36.0%
* macro_f1: 56.3%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,793
* accuracy: 49.2%
* error: 50.8%
* macro_f1: 22.4%
******* Domain 2 best val acc:      64.4%, epoch: 30 *******
******* Domain 2 best val test acc: 54.9%, epoch: 30 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [33/50] batch [20/319] time 0.111 (0.144) data 0.000 (0.024) loss 2.4944 (2.2498) teacher_loss 1.2198 (1.0042) loss_zs_kd 0.9210 (0.9299) loss_oracle 0.8632 (0.8633) acc 50.0000 (62.6562) kd_loss 0.8430 (0.8140) lr 6.3188e-04 eta 0:13:42
epoch [33/50] batch [40/319] time 0.080 (0.126) data 0.000 (0.012) loss 2.1646 (2.2440) teacher_loss 0.8547 (0.9906) loss_zs_kd 0.9386 (0.9064) loss_oracle 0.8633 (0.8633) acc 68.7500 (63.2031) kd_loss 0.8783 (0.8218) lr 6.3188e-04 eta 0:11:58
epoch [33/50] batch [60/319] time 0.151 (0.127) data 0.000 (0.008) loss 1.7167 (2.2381) teacher_loss 0.4697 (0.9834) loss_zs_kd 0.6869 (0.8920) loss_oracle 0.8633 (0.8633) acc 87.5000 (64.3750) kd_loss 0.8154 (0.8230) lr 6.3188e-04 eta 0:12:03
epoch [33/50] batch [80/319] time 0.099 (0.119) data 0.000 (0.006) loss 2.1096 (2.2175) teacher_loss 0.8516 (0.9641) loss_zs_kd 1.0129 (0.8924) loss_oracle 0.8632 (0.8633) acc 65.6250 (65.6250) kd_loss 0.8264 (0.8218) lr 6.3188e-04 eta 0:11:14
epoch [33/50] batch [100/319] time 0.122 (0.122) data 0.000 (0.005) loss 2.2599 (2.2113) teacher_loss 1.0515 (0.9588) loss_zs_kd 0.8067 (0.8861) loss_oracle 0.8632 (0.8633) acc 59.3750 (66.0625) kd_loss 0.7768 (0.8208) lr 6.3188e-04 eta 0:11:25
epoch [33/50] batch [120/319] time 0.136 (0.120) data 0.000 (0.004) loss 2.4632 (2.2077) teacher_loss 1.1815 (0.9561) loss_zs_kd 0.8574 (0.8786) loss_oracle 0.8633 (0.8633) acc 65.6250 (66.0677) kd_loss 0.8500 (0.8199) lr 6.3188e-04 eta 0:11:17
epoch [33/50] batch [140/319] time 0.101 (0.116) data 0.000 (0.004) loss 2.1236 (2.2084) teacher_loss 0.9032 (0.9552) loss_zs_kd 1.0594 (0.8781) loss_oracle 0.8632 (0.8633) acc 65.6250 (65.9375) kd_loss 0.7888 (0.8216) lr 6.3188e-04 eta 0:10:50
epoch [33/50] batch [160/319] time 0.069 (0.122) data 0.000 (0.003) loss 1.8132 (2.2090) teacher_loss 0.5601 (0.9567) loss_zs_kd 0.7757 (0.8826) loss_oracle 0.8633 (0.8633) acc 84.3750 (65.9180) kd_loss 0.8215 (0.8207) lr 6.3188e-04 eta 0:11:22
epoch [33/50] batch [180/319] time 0.183 (0.123) data 0.000 (0.003) loss 2.4277 (2.2246) teacher_loss 1.1511 (0.9711) loss_zs_kd 1.3369 (0.8755) loss_oracle 0.8633 (0.8633) acc 68.7500 (65.5729) kd_loss 0.8450 (0.8219) lr 6.3188e-04 eta 0:11:22
epoch [33/50] batch [200/319] time 0.063 (0.125) data 0.000 (0.003) loss 2.0973 (2.2230) teacher_loss 0.8104 (0.9690) loss_zs_kd 1.2945 (0.8778) loss_oracle 0.8633 (0.8633) acc 75.0000 (65.4531) kd_loss 0.8553 (0.8224) lr 6.3188e-04 eta 0:11:33
epoch [33/50] batch [220/319] time 0.100 (0.124) data 0.000 (0.002) loss 1.9231 (2.2170) teacher_loss 0.6813 (0.9650) loss_zs_kd 0.7518 (0.8710) loss_oracle 0.8632 (0.8633) acc 75.0000 (65.5398) kd_loss 0.8102 (0.8203) lr 6.3188e-04 eta 0:11:22
epoch [33/50] batch [240/319] time 0.109 (0.123) data 0.000 (0.002) loss 2.1899 (2.2171) teacher_loss 0.9411 (0.9645) loss_zs_kd 0.9428 (0.8672) loss_oracle 0.8633 (0.8633) acc 65.6250 (65.5078) kd_loss 0.8171 (0.8210) lr 6.3188e-04 eta 0:11:15
epoch [33/50] batch [260/319] time 0.139 (0.122) data 0.000 (0.002) loss 2.2614 (2.2225) teacher_loss 1.0447 (0.9706) loss_zs_kd 0.7004 (0.8613) loss_oracle 0.8632 (0.8633) acc 65.6250 (65.1082) kd_loss 0.7852 (0.8203) lr 6.3188e-04 eta 0:11:06
epoch [33/50] batch [280/319] time 0.096 (0.121) data 0.000 (0.002) loss 1.9605 (2.2192) teacher_loss 0.6808 (0.9684) loss_zs_kd 0.7877 (0.8580) loss_oracle 0.8632 (0.8633) acc 78.1250 (65.1004) kd_loss 0.8482 (0.8192) lr 6.3188e-04 eta 0:11:00
epoch [33/50] batch [300/319] time 0.136 (0.120) data 0.000 (0.002) loss 1.9105 (2.2207) teacher_loss 0.6749 (0.9698) loss_zs_kd 0.7202 (0.8543) loss_oracle 0.8632 (0.8633) acc 75.0000 (65.0312) kd_loss 0.8041 (0.8192) lr 6.3188e-04 eta 0:10:54
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,840
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 56.9%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,894
* accuracy: 50.3%
* error: 49.7%
* macro_f1: 23.0%
******* Domain 2 best val acc:      64.9%, epoch: 33 *******
******* Domain 2 best val test acc: 50.3%, epoch: 33 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [34/50] batch [20/319] time 0.190 (0.160) data 0.000 (0.024) loss 2.5736 (2.2419) teacher_loss 1.3618 (1.0052) loss_zs_kd 0.7640 (0.7971) loss_oracle 0.8632 (0.8632) acc 56.2500 (62.8125) kd_loss 0.7802 (0.8050) lr 5.7422e-04 eta 0:14:25
epoch [34/50] batch [40/319] time 0.084 (0.157) data 0.000 (0.012) loss 2.0869 (2.2326) teacher_loss 0.8381 (0.9913) loss_zs_kd 0.6532 (0.8191) loss_oracle 0.8633 (0.8632) acc 62.5000 (63.4375) kd_loss 0.8171 (0.8097) lr 5.7422e-04 eta 0:14:05
epoch [34/50] batch [60/319] time 0.169 (0.157) data 0.000 (0.008) loss 2.2896 (2.2036) teacher_loss 1.0684 (0.9607) loss_zs_kd 0.7674 (0.8315) loss_oracle 0.8632 (0.8632) acc 56.2500 (64.8438) kd_loss 0.7896 (0.8113) lr 5.7422e-04 eta 0:14:01
epoch [34/50] batch [80/319] time 0.135 (0.148) data 0.000 (0.006) loss 2.3450 (2.1965) teacher_loss 1.0973 (0.9546) loss_zs_kd 0.9050 (0.8222) loss_oracle 0.8632 (0.8632) acc 62.5000 (64.9609) kd_loss 0.8160 (0.8104) lr 5.7422e-04 eta 0:13:10
epoch [34/50] batch [100/319] time 0.105 (0.138) data 0.000 (0.005) loss 2.2490 (2.2109) teacher_loss 1.0206 (0.9686) loss_zs_kd 0.7955 (0.8341) loss_oracle 0.8632 (0.8632) acc 68.7500 (64.3125) kd_loss 0.7968 (0.8107) lr 5.7422e-04 eta 0:12:15
epoch [34/50] batch [120/319] time 0.141 (0.135) data 0.000 (0.004) loss 2.2472 (2.2041) teacher_loss 1.0205 (0.9614) loss_zs_kd 0.8385 (0.8334) loss_oracle 0.8632 (0.8632) acc 65.6250 (64.6615) kd_loss 0.7951 (0.8111) lr 5.7422e-04 eta 0:11:56
epoch [34/50] batch [140/319] time 0.143 (0.135) data 0.000 (0.004) loss 2.4114 (2.2122) teacher_loss 1.1557 (0.9682) loss_zs_kd 0.8120 (0.8375) loss_oracle 0.8632 (0.8632) acc 59.3750 (64.4643) kd_loss 0.8241 (0.8124) lr 5.7422e-04 eta 0:11:55
epoch [34/50] batch [160/319] time 0.143 (0.137) data 0.000 (0.003) loss 2.2778 (2.2138) teacher_loss 1.0315 (0.9706) loss_zs_kd 0.9083 (0.8451) loss_oracle 0.8632 (0.8632) acc 59.3750 (64.5508) kd_loss 0.8147 (0.8116) lr 5.7422e-04 eta 0:12:03
epoch [34/50] batch [180/319] time 0.157 (0.138) data 0.000 (0.003) loss 2.2141 (2.2195) teacher_loss 0.8925 (0.9750) loss_zs_kd 1.1225 (0.8551) loss_oracle 0.8632 (0.8632) acc 78.1250 (64.4965) kd_loss 0.8900 (0.8128) lr 5.7422e-04 eta 0:12:03
epoch [34/50] batch [200/319] time 0.150 (0.139) data 0.000 (0.003) loss 2.1257 (2.2311) teacher_loss 0.9207 (0.9857) loss_zs_kd 0.6922 (0.8503) loss_oracle 0.8632 (0.8632) acc 65.6250 (64.2500) kd_loss 0.7734 (0.8138) lr 5.7422e-04 eta 0:12:07
epoch [34/50] batch [220/319] time 0.133 (0.136) data 0.000 (0.002) loss 2.1258 (2.2302) teacher_loss 0.8110 (0.9843) loss_zs_kd 0.8813 (0.8509) loss_oracle 0.8632 (0.8632) acc 71.8750 (64.2330) kd_loss 0.8832 (0.8143) lr 5.7422e-04 eta 0:11:48
epoch [34/50] batch [240/319] time 0.142 (0.133) data 0.000 (0.002) loss 2.3709 (2.2303) teacher_loss 1.1796 (0.9834) loss_zs_kd 0.9629 (0.8497) loss_oracle 0.8632 (0.8632) acc 62.5000 (64.3620) kd_loss 0.7597 (0.8152) lr 5.7422e-04 eta 0:11:31
epoch [34/50] batch [260/319] time 0.164 (0.133) data 0.000 (0.002) loss 1.8641 (2.2241) teacher_loss 0.6361 (0.9765) loss_zs_kd 0.7700 (0.8476) loss_oracle 0.8632 (0.8632) acc 87.5000 (64.7596) kd_loss 0.7964 (0.8160) lr 5.7422e-04 eta 0:11:24
epoch [34/50] batch [280/319] time 0.089 (0.131) data 0.000 (0.002) loss 2.0239 (2.2196) teacher_loss 0.7022 (0.9707) loss_zs_kd 1.0216 (0.8504) loss_oracle 0.8632 (0.8632) acc 81.2500 (65.0112) kd_loss 0.8901 (0.8174) lr 5.7422e-04 eta 0:11:15
epoch [34/50] batch [300/319] time 0.158 (0.130) data 0.000 (0.002) loss 2.2056 (2.2211) teacher_loss 0.9631 (0.9710) loss_zs_kd 1.0364 (0.8547) loss_oracle 0.8632 (0.8632) acc 71.8750 (65.1042) kd_loss 0.8110 (0.8185) lr 5.7422e-04 eta 0:11:05
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,811
* accuracy: 64.2%
* error: 35.8%
* macro_f1: 56.3%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,729
* accuracy: 48.6%
* error: 51.4%
* macro_f1: 21.9%
******* Domain 2 best val acc:      64.9%, epoch: 33 *******
******* Domain 2 best val test acc: 50.3%, epoch: 33 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [35/50] batch [20/319] time 0.133 (0.149) data 0.000 (0.028) loss 2.2879 (2.2188) teacher_loss 1.0271 (0.9693) loss_zs_kd 0.8472 (0.8383) loss_oracle 0.8632 (0.8632) acc 50.0000 (64.0625) kd_loss 0.8293 (0.8179) lr 5.1825e-04 eta 0:12:35
epoch [35/50] batch [40/319] time 0.100 (0.128) data 0.000 (0.014) loss 2.1485 (2.2034) teacher_loss 0.9052 (0.9513) loss_zs_kd 0.9134 (0.8474) loss_oracle 0.8632 (0.8632) acc 68.7500 (65.8594) kd_loss 0.8117 (0.8205) lr 5.1825e-04 eta 0:10:49
epoch [35/50] batch [60/319] time 0.092 (0.122) data 0.000 (0.009) loss 2.2886 (2.2240) teacher_loss 1.0015 (0.9691) loss_zs_kd 0.8258 (0.8362) loss_oracle 0.8632 (0.8632) acc 65.6250 (64.6354) kd_loss 0.8554 (0.8233) lr 5.1825e-04 eta 0:10:16
epoch [35/50] batch [80/319] time 0.091 (0.119) data 0.000 (0.007) loss 2.2337 (2.2134) teacher_loss 1.0002 (0.9581) loss_zs_kd 0.8246 (0.8419) loss_oracle 0.8631 (0.8632) acc 75.0000 (65.5859) kd_loss 0.8020 (0.8238) lr 5.1825e-04 eta 0:09:59
epoch [35/50] batch [100/319] time 0.127 (0.118) data 0.000 (0.006) loss 2.3247 (2.2001) teacher_loss 1.0671 (0.9428) loss_zs_kd 0.9840 (0.8424) loss_oracle 0.8631 (0.8632) acc 62.5000 (66.1562) kd_loss 0.8260 (0.8257) lr 5.1825e-04 eta 0:09:51
epoch [35/50] batch [120/319] time 0.155 (0.119) data 0.000 (0.005) loss 2.2968 (2.1992) teacher_loss 1.1089 (0.9439) loss_zs_kd 0.9816 (0.8433) loss_oracle 0.8631 (0.8632) acc 65.6250 (66.0938) kd_loss 0.7563 (0.8237) lr 5.1825e-04 eta 0:09:54
epoch [35/50] batch [140/319] time 0.095 (0.118) data 0.000 (0.004) loss 2.0762 (2.1934) teacher_loss 0.7425 (0.9370) loss_zs_kd 0.8226 (0.8447) loss_oracle 0.8631 (0.8632) acc 75.0000 (66.4509) kd_loss 0.9021 (0.8248) lr 5.1825e-04 eta 0:09:47
epoch [35/50] batch [160/319] time 0.132 (0.115) data 0.000 (0.004) loss 2.3260 (2.1925) teacher_loss 1.1024 (0.9360) loss_zs_kd 0.9353 (0.8521) loss_oracle 0.8631 (0.8632) acc 62.5000 (66.4844) kd_loss 0.7921 (0.8249) lr 5.1825e-04 eta 0:09:30
epoch [35/50] batch [180/319] time 0.093 (0.115) data 0.000 (0.003) loss 2.2797 (2.2022) teacher_loss 1.0123 (0.9460) loss_zs_kd 0.7473 (0.8541) loss_oracle 0.8631 (0.8632) acc 65.6250 (65.9201) kd_loss 0.8358 (0.8246) lr 5.1825e-04 eta 0:09:25
epoch [35/50] batch [200/319] time 0.082 (0.114) data 0.000 (0.003) loss 2.2307 (2.2108) teacher_loss 0.9781 (0.9551) loss_zs_kd 0.6221 (0.8542) loss_oracle 0.8631 (0.8632) acc 59.3750 (65.6094) kd_loss 0.8210 (0.8241) lr 5.1825e-04 eta 0:09:19
epoch [35/50] batch [220/319] time 0.081 (0.113) data 0.000 (0.003) loss 2.5413 (2.2017) teacher_loss 1.3141 (0.9465) loss_zs_kd 0.8037 (0.8551) loss_oracle 0.8631 (0.8632) acc 56.2500 (65.9801) kd_loss 0.7957 (0.8237) lr 5.1825e-04 eta 0:09:12
epoch [35/50] batch [240/319] time 0.078 (0.112) data 0.000 (0.002) loss 2.0810 (2.2030) teacher_loss 0.7736 (0.9476) loss_zs_kd 0.8582 (0.8559) loss_oracle 0.8631 (0.8632) acc 68.7500 (66.0026) kd_loss 0.8758 (0.8239) lr 5.1825e-04 eta 0:09:05
epoch [35/50] batch [260/319] time 0.104 (0.111) data 0.000 (0.002) loss 1.8787 (2.1955) teacher_loss 0.6039 (0.9402) loss_zs_kd 0.9086 (0.8586) loss_oracle 0.8631 (0.8632) acc 81.2500 (66.2260) kd_loss 0.8432 (0.8237) lr 5.1825e-04 eta 0:08:58
epoch [35/50] batch [280/319] time 0.138 (0.111) data 0.000 (0.002) loss 2.3122 (2.1970) teacher_loss 0.9355 (0.9404) loss_zs_kd 1.0526 (0.8688) loss_oracle 0.8631 (0.8632) acc 71.8750 (66.3504) kd_loss 0.9451 (0.8250) lr 5.1825e-04 eta 0:08:55
epoch [35/50] batch [300/319] time 0.090 (0.111) data 0.000 (0.002) loss 1.9787 (2.1928) teacher_loss 0.7441 (0.9365) loss_zs_kd 0.8935 (0.8753) loss_oracle 0.8631 (0.8631) acc 68.7500 (66.5104) kd_loss 0.8030 (0.8247) lr 5.1825e-04 eta 0:08:52
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,846
* accuracy: 65.0%
* error: 35.0%
* macro_f1: 57.8%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,224
* accuracy: 53.7%
* error: 46.3%
* macro_f1: 23.4%
******* Domain 2 best val acc:      65.0%, epoch: 35 *******
******* Domain 2 best val test acc: 53.7%, epoch: 35 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [36/50] batch [20/319] time 0.151 (0.172) data 0.000 (0.027) loss 2.2111 (2.2276) teacher_loss 0.9707 (0.9605) loss_zs_kd 0.6765 (0.9261) loss_oracle 0.8631 (0.8631) acc 62.5000 (65.9375) kd_loss 0.8089 (0.8355) lr 4.6417e-04 eta 0:13:38
epoch [36/50] batch [40/319] time 0.165 (0.161) data 0.000 (0.014) loss 2.1833 (2.2399) teacher_loss 0.9108 (0.9716) loss_zs_kd 0.8849 (0.9224) loss_oracle 0.8631 (0.8631) acc 65.6250 (65.4688) kd_loss 0.8410 (0.8367) lr 4.6417e-04 eta 0:12:45
epoch [36/50] batch [60/319] time 0.152 (0.158) data 0.000 (0.009) loss 2.1239 (2.2141) teacher_loss 0.8797 (0.9544) loss_zs_kd 1.2220 (0.9152) loss_oracle 0.8631 (0.8631) acc 65.6250 (66.0938) kd_loss 0.8126 (0.8281) lr 4.6417e-04 eta 0:12:26
epoch [36/50] batch [80/319] time 0.151 (0.157) data 0.000 (0.007) loss 2.2392 (2.2238) teacher_loss 0.9846 (0.9639) loss_zs_kd 0.9603 (0.8979) loss_oracle 0.8631 (0.8631) acc 68.7500 (65.8594) kd_loss 0.8231 (0.8283) lr 4.6417e-04 eta 0:12:17
epoch [36/50] batch [100/319] time 0.152 (0.156) data 0.001 (0.006) loss 2.0618 (2.2092) teacher_loss 0.7663 (0.9517) loss_zs_kd 1.0910 (0.8882) loss_oracle 0.8631 (0.8631) acc 75.0000 (66.0938) kd_loss 0.8639 (0.8259) lr 4.6417e-04 eta 0:12:09
epoch [36/50] batch [120/319] time 0.153 (0.154) data 0.000 (0.005) loss 2.1628 (2.2053) teacher_loss 0.9086 (0.9480) loss_zs_kd 0.9135 (0.8859) loss_oracle 0.8631 (0.8631) acc 62.5000 (66.3021) kd_loss 0.8227 (0.8257) lr 4.6417e-04 eta 0:11:57
epoch [36/50] batch [140/319] time 0.165 (0.152) data 0.000 (0.004) loss 2.2547 (2.1990) teacher_loss 0.9829 (0.9412) loss_zs_kd 0.7529 (0.8909) loss_oracle 0.8631 (0.8631) acc 62.5000 (66.5848) kd_loss 0.8403 (0.8263) lr 4.6417e-04 eta 0:11:46
epoch [36/50] batch [160/319] time 0.089 (0.151) data 0.000 (0.004) loss 2.2451 (2.1931) teacher_loss 0.9759 (0.9346) loss_zs_kd 0.7560 (0.8971) loss_oracle 0.8631 (0.8631) acc 62.5000 (67.0312) kd_loss 0.8377 (0.8270) lr 4.6417e-04 eta 0:11:38
epoch [36/50] batch [180/319] time 0.191 (0.156) data 0.000 (0.003) loss 2.3594 (2.1872) teacher_loss 1.0599 (0.9280) loss_zs_kd 0.9788 (0.8957) loss_oracle 0.8631 (0.8631) acc 56.2500 (67.0833) kd_loss 0.8680 (0.8276) lr 4.6417e-04 eta 0:11:56
epoch [36/50] batch [200/319] time 0.093 (0.151) data 0.000 (0.003) loss 2.0862 (2.1856) teacher_loss 0.8364 (0.9250) loss_zs_kd 0.8109 (0.8971) loss_oracle 0.8631 (0.8631) acc 71.8750 (67.1406) kd_loss 0.8183 (0.8291) lr 4.6417e-04 eta 0:11:33
epoch [36/50] batch [220/319] time 0.105 (0.148) data 0.000 (0.003) loss 2.2102 (2.1846) teacher_loss 0.9449 (0.9235) loss_zs_kd 1.0670 (0.9066) loss_oracle 0.8631 (0.8631) acc 68.7500 (67.0881) kd_loss 0.8338 (0.8295) lr 4.6417e-04 eta 0:11:16
epoch [36/50] batch [240/319] time 0.089 (0.146) data 0.000 (0.003) loss 2.1268 (2.1850) teacher_loss 0.8597 (0.9242) loss_zs_kd 1.1582 (0.9148) loss_oracle 0.8632 (0.8631) acc 62.5000 (67.1875) kd_loss 0.8356 (0.8292) lr 4.6417e-04 eta 0:11:02
epoch [36/50] batch [260/319] time 0.148 (0.146) data 0.000 (0.002) loss 2.2937 (2.1843) teacher_loss 1.0408 (0.9244) loss_zs_kd 0.6780 (0.9149) loss_oracle 0.8631 (0.8631) acc 65.6250 (67.1394) kd_loss 0.8213 (0.8284) lr 4.6417e-04 eta 0:10:58
epoch [36/50] batch [280/319] time 0.114 (0.144) data 0.000 (0.002) loss 2.2472 (2.1808) teacher_loss 0.9951 (0.9212) loss_zs_kd 0.8202 (0.9120) loss_oracle 0.8631 (0.8631) acc 71.8750 (67.2321) kd_loss 0.8205 (0.8280) lr 4.6417e-04 eta 0:10:46
epoch [36/50] batch [300/319] time 0.134 (0.142) data 0.000 (0.002) loss 2.3865 (2.1821) teacher_loss 1.0797 (0.9216) loss_zs_kd 0.9479 (0.9150) loss_oracle 0.8631 (0.8631) acc 56.2500 (67.3542) kd_loss 0.8752 (0.8290) lr 4.6417e-04 eta 0:10:35
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,822
* accuracy: 64.5%
* error: 35.5%
* macro_f1: 57.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,009
* accuracy: 51.4%
* error: 48.6%
* macro_f1: 24.7%
******* Domain 2 best val acc:      65.0%, epoch: 35 *******
******* Domain 2 best val test acc: 53.7%, epoch: 35 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [37/50] batch [20/319] time 0.190 (0.187) data 0.000 (0.030) loss 2.1991 (2.1159) teacher_loss 0.8969 (0.8571) loss_zs_kd 1.2290 (0.9227) loss_oracle 0.8632 (0.8631) acc 68.7500 (70.7812) kd_loss 0.8706 (0.8272) lr 4.1221e-04 eta 0:13:50
epoch [37/50] batch [40/319] time 0.089 (0.157) data 0.000 (0.015) loss 2.3607 (2.1102) teacher_loss 1.0432 (0.8466) loss_zs_kd 0.8179 (0.9107) loss_oracle 0.8631 (0.8631) acc 71.8750 (71.3281) kd_loss 0.8860 (0.8320) lr 4.1221e-04 eta 0:11:34
epoch [37/50] batch [60/319] time 0.138 (0.140) data 0.000 (0.010) loss 1.9927 (2.1341) teacher_loss 0.7258 (0.8706) loss_zs_kd 1.2427 (0.9178) loss_oracle 0.8631 (0.8631) acc 81.2500 (70.1042) kd_loss 0.8354 (0.8319) lr 4.1221e-04 eta 0:10:16
epoch [37/50] batch [80/319] time 0.079 (0.129) data 0.000 (0.008) loss 2.2172 (2.1507) teacher_loss 0.8925 (0.8856) loss_zs_kd 0.9484 (0.9336) loss_oracle 0.8631 (0.8631) acc 65.6250 (69.9219) kd_loss 0.8932 (0.8336) lr 4.1221e-04 eta 0:09:27
epoch [37/50] batch [100/319] time 0.090 (0.124) data 0.000 (0.006) loss 2.2052 (2.1484) teacher_loss 0.9596 (0.8782) loss_zs_kd 0.9317 (0.9387) loss_oracle 0.8630 (0.8631) acc 71.8750 (70.1250) kd_loss 0.8142 (0.8387) lr 4.1221e-04 eta 0:08:59
epoch [37/50] batch [120/319] time 0.103 (0.120) data 0.000 (0.005) loss 2.3202 (2.1540) teacher_loss 0.9926 (0.8806) loss_zs_kd 1.0315 (0.9463) loss_oracle 0.8631 (0.8631) acc 71.8750 (70.3906) kd_loss 0.8961 (0.8419) lr 4.1221e-04 eta 0:08:40
epoch [37/50] batch [140/319] time 0.133 (0.117) data 0.000 (0.005) loss 1.9056 (2.1538) teacher_loss 0.6227 (0.8786) loss_zs_kd 1.0557 (0.9586) loss_oracle 0.8631 (0.8631) acc 81.2500 (70.3571) kd_loss 0.8513 (0.8436) lr 4.1221e-04 eta 0:08:27
epoch [37/50] batch [160/319] time 0.138 (0.117) data 0.000 (0.004) loss 2.3056 (2.1591) teacher_loss 1.0580 (0.8838) loss_zs_kd 1.0336 (0.9621) loss_oracle 0.8631 (0.8631) acc 53.1250 (70.0391) kd_loss 0.8161 (0.8437) lr 4.1221e-04 eta 0:08:22
epoch [37/50] batch [180/319] time 0.085 (0.115) data 0.000 (0.004) loss 2.1070 (2.1598) teacher_loss 0.8462 (0.8834) loss_zs_kd 1.2921 (0.9671) loss_oracle 0.8631 (0.8631) acc 65.6250 (70.1562) kd_loss 0.8292 (0.8448) lr 4.1221e-04 eta 0:08:11
epoch [37/50] batch [200/319] time 0.090 (0.114) data 0.000 (0.003) loss 2.0494 (2.1563) teacher_loss 0.7976 (0.8806) loss_zs_kd 0.9769 (0.9652) loss_oracle 0.8631 (0.8631) acc 81.2500 (70.3750) kd_loss 0.8202 (0.8442) lr 4.1221e-04 eta 0:08:07
epoch [37/50] batch [220/319] time 0.105 (0.113) data 0.000 (0.003) loss 2.3590 (2.1486) teacher_loss 1.0681 (0.8743) loss_zs_kd 0.8973 (0.9580) loss_oracle 0.8631 (0.8631) acc 68.7500 (70.8381) kd_loss 0.8594 (0.8428) lr 4.1221e-04 eta 0:07:58
epoch [37/50] batch [240/319] time 0.088 (0.112) data 0.000 (0.003) loss 2.1285 (2.1453) teacher_loss 0.8426 (0.8720) loss_zs_kd 0.8595 (0.9521) loss_oracle 0.8631 (0.8631) acc 68.7500 (70.6510) kd_loss 0.8543 (0.8417) lr 4.1221e-04 eta 0:07:53
epoch [37/50] batch [260/319] time 0.141 (0.112) data 0.000 (0.003) loss 2.2102 (2.1544) teacher_loss 0.9758 (0.8824) loss_zs_kd 0.8294 (0.9459) loss_oracle 0.8631 (0.8631) acc 65.6250 (70.0240) kd_loss 0.8029 (0.8405) lr 4.1221e-04 eta 0:07:50
epoch [37/50] batch [280/319] time 0.135 (0.112) data 0.000 (0.002) loss 2.1054 (2.1549) teacher_loss 0.8642 (0.8837) loss_zs_kd 0.7877 (0.9440) loss_oracle 0.8631 (0.8631) acc 68.7500 (69.9330) kd_loss 0.8097 (0.8397) lr 4.1221e-04 eta 0:07:46
epoch [37/50] batch [300/319] time 0.115 (0.112) data 0.000 (0.002) loss 1.9499 (2.1517) teacher_loss 0.6520 (0.8807) loss_zs_kd 0.9699 (0.9439) loss_oracle 0.8631 (0.8631) acc 71.8750 (70.0833) kd_loss 0.8664 (0.8395) lr 4.1221e-04 eta 0:07:44
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,777
* accuracy: 63.4%
* error: 36.6%
* macro_f1: 56.3%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,518
* accuracy: 46.4%
* error: 53.6%
* macro_f1: 22.6%
******* Domain 2 best val acc:      65.0%, epoch: 35 *******
******* Domain 2 best val test acc: 53.7%, epoch: 35 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [38/50] batch [20/319] time 0.085 (0.126) data 0.000 (0.025) loss 2.1537 (2.2046) teacher_loss 0.8855 (0.9284) loss_zs_kd 1.0759 (0.8780) loss_oracle 0.8631 (0.8631) acc 71.8750 (69.2188) kd_loss 0.8366 (0.8447) lr 3.6258e-04 eta 0:08:40
epoch [38/50] batch [40/319] time 0.110 (0.114) data 0.000 (0.013) loss 2.2399 (2.1867) teacher_loss 0.9680 (0.9159) loss_zs_kd 0.6934 (0.8766) loss_oracle 0.8631 (0.8631) acc 65.6250 (69.0625) kd_loss 0.8403 (0.8392) lr 3.6258e-04 eta 0:07:48
epoch [38/50] batch [60/319] time 0.107 (0.108) data 0.000 (0.009) loss 2.4691 (2.2049) teacher_loss 1.2120 (0.9374) loss_zs_kd 1.0257 (0.8745) loss_oracle 0.8631 (0.8631) acc 68.7500 (69.0104) kd_loss 0.8256 (0.8360) lr 3.6258e-04 eta 0:07:22
epoch [38/50] batch [80/319] time 0.104 (0.105) data 0.000 (0.006) loss 2.2400 (2.1918) teacher_loss 0.9793 (0.9236) loss_zs_kd 1.1750 (0.8832) loss_oracle 0.8631 (0.8631) acc 62.5000 (68.9453) kd_loss 0.8292 (0.8367) lr 3.6258e-04 eta 0:07:06
epoch [38/50] batch [100/319] time 0.077 (0.104) data 0.000 (0.005) loss 2.0560 (2.1800) teacher_loss 0.8193 (0.9131) loss_zs_kd 1.0998 (0.8987) loss_oracle 0.8631 (0.8631) acc 71.8750 (69.2188) kd_loss 0.8051 (0.8353) lr 3.6258e-04 eta 0:07:02
epoch [38/50] batch [120/319] time 0.150 (0.106) data 0.000 (0.004) loss 2.1387 (2.1743) teacher_loss 0.8529 (0.9079) loss_zs_kd 0.9606 (0.8970) loss_oracle 0.8630 (0.8631) acc 68.7500 (69.2448) kd_loss 0.8543 (0.8349) lr 3.6258e-04 eta 0:07:06
epoch [38/50] batch [140/319] time 0.095 (0.107) data 0.000 (0.004) loss 2.2486 (2.1809) teacher_loss 1.0716 (0.9164) loss_zs_kd 0.9508 (0.9003) loss_oracle 0.8630 (0.8631) acc 68.7500 (68.9286) kd_loss 0.7454 (0.8329) lr 3.6258e-04 eta 0:07:09
epoch [38/50] batch [160/319] time 0.153 (0.107) data 0.000 (0.003) loss 2.0205 (2.1776) teacher_loss 0.7220 (0.9142) loss_zs_kd 0.7188 (0.8970) loss_oracle 0.8630 (0.8631) acc 75.0000 (69.0625) kd_loss 0.8670 (0.8319) lr 3.6258e-04 eta 0:07:08
epoch [38/50] batch [180/319] time 0.078 (0.110) data 0.000 (0.003) loss 2.2139 (2.1807) teacher_loss 0.8938 (0.9152) loss_zs_kd 0.9466 (0.8956) loss_oracle 0.8631 (0.8631) acc 65.6250 (68.7674) kd_loss 0.8886 (0.8340) lr 3.6258e-04 eta 0:07:15
epoch [38/50] batch [200/319] time 0.083 (0.109) data 0.000 (0.003) loss 2.1712 (2.1790) teacher_loss 0.9126 (0.9129) loss_zs_kd 0.9586 (0.9033) loss_oracle 0.8631 (0.8631) acc 62.5000 (68.6562) kd_loss 0.8271 (0.8346) lr 3.6258e-04 eta 0:07:12
epoch [38/50] batch [220/319] time 0.144 (0.110) data 0.000 (0.002) loss 2.3442 (2.1753) teacher_loss 1.1016 (0.9101) loss_zs_kd 0.8141 (0.9065) loss_oracle 0.8631 (0.8631) acc 68.7500 (68.7500) kd_loss 0.8111 (0.8337) lr 3.6258e-04 eta 0:07:10
epoch [38/50] batch [240/319] time 0.125 (0.110) data 0.000 (0.002) loss 1.9533 (2.1691) teacher_loss 0.6859 (0.9036) loss_zs_kd 0.7374 (0.9101) loss_oracle 0.8631 (0.8631) acc 78.1250 (68.9583) kd_loss 0.8358 (0.8340) lr 3.6258e-04 eta 0:07:11
epoch [38/50] batch [260/319] time 0.102 (0.111) data 0.000 (0.002) loss 2.4817 (2.1689) teacher_loss 1.2020 (0.9041) loss_zs_kd 1.1590 (0.9118) loss_oracle 0.8630 (0.8631) acc 68.7500 (68.9062) kd_loss 0.8482 (0.8333) lr 3.6258e-04 eta 0:07:10
epoch [38/50] batch [280/319] time 0.077 (0.110) data 0.000 (0.002) loss 1.9508 (2.1652) teacher_loss 0.6721 (0.8997) loss_zs_kd 0.9250 (0.9132) loss_oracle 0.8630 (0.8631) acc 75.0000 (69.0960) kd_loss 0.8472 (0.8339) lr 3.6258e-04 eta 0:07:06
epoch [38/50] batch [300/319] time 0.095 (0.110) data 0.000 (0.002) loss 2.4490 (2.1684) teacher_loss 1.1602 (0.9016) loss_zs_kd 1.0054 (0.9160) loss_oracle 0.8630 (0.8631) acc 65.6250 (69.0625) kd_loss 0.8573 (0.8353) lr 3.6258e-04 eta 0:07:03
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,842
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 57.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,219
* accuracy: 53.6%
* error: 46.4%
* macro_f1: 23.7%
******* Domain 2 best val acc:      65.0%, epoch: 35 *******
******* Domain 2 best val test acc: 53.7%, epoch: 35 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [39/50] batch [20/319] time 0.153 (0.156) data 0.000 (0.033) loss 2.1177 (2.1549) teacher_loss 0.8729 (0.8789) loss_zs_kd 0.9794 (0.9183) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.5312) kd_loss 0.8132 (0.8444) lr 3.1545e-04 eta 0:09:55
epoch [39/50] batch [40/319] time 0.156 (0.145) data 0.000 (0.017) loss 2.3868 (2.1554) teacher_loss 1.1206 (0.8787) loss_zs_kd 0.8968 (0.9390) loss_oracle 0.8631 (0.8630) acc 56.2500 (68.9062) kd_loss 0.8347 (0.8452) lr 3.1545e-04 eta 0:09:10
epoch [39/50] batch [60/319] time 0.154 (0.139) data 0.000 (0.011) loss 1.9907 (2.1483) teacher_loss 0.7566 (0.8725) loss_zs_kd 0.7695 (0.9326) loss_oracle 0.8631 (0.8631) acc 71.8750 (69.1667) kd_loss 0.8026 (0.8443) lr 3.1545e-04 eta 0:08:41
epoch [39/50] batch [80/319] time 0.100 (0.139) data 0.000 (0.008) loss 2.2149 (2.1567) teacher_loss 0.9143 (0.8845) loss_zs_kd 1.1404 (0.9353) loss_oracle 0.8630 (0.8630) acc 65.6250 (68.6719) kd_loss 0.8691 (0.8407) lr 3.1545e-04 eta 0:08:39
epoch [39/50] batch [100/319] time 0.145 (0.141) data 0.000 (0.007) loss 2.5574 (2.1618) teacher_loss 1.3079 (0.8923) loss_zs_kd 0.8475 (0.9186) loss_oracle 0.8630 (0.8630) acc 59.3750 (68.5312) kd_loss 0.8180 (0.8380) lr 3.1545e-04 eta 0:08:47
epoch [39/50] batch [120/319] time 0.147 (0.143) data 0.000 (0.006) loss 2.3874 (2.1548) teacher_loss 1.1383 (0.8840) loss_zs_kd 0.6388 (0.9076) loss_oracle 0.8630 (0.8630) acc 59.3750 (68.8542) kd_loss 0.8177 (0.8392) lr 3.1545e-04 eta 0:08:50
epoch [39/50] batch [140/319] time 0.151 (0.144) data 0.000 (0.005) loss 1.9971 (2.1551) teacher_loss 0.6749 (0.8816) loss_zs_kd 1.1848 (0.9105) loss_oracle 0.8630 (0.8630) acc 81.2500 (69.1964) kd_loss 0.8907 (0.8420) lr 3.1545e-04 eta 0:08:52
epoch [39/50] batch [160/319] time 0.078 (0.142) data 0.000 (0.004) loss 2.0376 (2.1494) teacher_loss 0.7415 (0.8755) loss_zs_kd 1.1554 (0.9125) loss_oracle 0.8631 (0.8630) acc 71.8750 (69.2188) kd_loss 0.8646 (0.8424) lr 3.1545e-04 eta 0:08:39
epoch [39/50] batch [180/319] time 0.139 (0.137) data 0.000 (0.004) loss 1.9898 (2.1506) teacher_loss 0.7046 (0.8759) loss_zs_kd 0.9367 (0.9134) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.3403) kd_loss 0.8537 (0.8432) lr 3.1545e-04 eta 0:08:20
epoch [39/50] batch [200/319] time 0.149 (0.135) data 0.000 (0.004) loss 1.9139 (2.1456) teacher_loss 0.5891 (0.8717) loss_zs_kd 0.8064 (0.9153) loss_oracle 0.8630 (0.8630) acc 84.3750 (69.3125) kd_loss 0.8933 (0.8423) lr 3.1545e-04 eta 0:08:09
epoch [39/50] batch [220/319] time 0.191 (0.134) data 0.000 (0.003) loss 2.1196 (2.1448) teacher_loss 0.7668 (0.8699) loss_zs_kd 1.0915 (0.9236) loss_oracle 0.8631 (0.8630) acc 78.1250 (69.5028) kd_loss 0.9213 (0.8434) lr 3.1545e-04 eta 0:08:02
epoch [39/50] batch [240/319] time 0.070 (0.135) data 0.000 (0.003) loss 2.3780 (2.1499) teacher_loss 1.0711 (0.8749) loss_zs_kd 1.0471 (0.9317) loss_oracle 0.8630 (0.8630) acc 62.5000 (69.3490) kd_loss 0.8753 (0.8435) lr 3.1545e-04 eta 0:08:04
epoch [39/50] batch [260/319] time 0.184 (0.137) data 0.000 (0.003) loss 2.0726 (2.1515) teacher_loss 0.8341 (0.8760) loss_zs_kd 0.9563 (0.9362) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.4111) kd_loss 0.8070 (0.8439) lr 3.1545e-04 eta 0:08:09
epoch [39/50] batch [280/319] time 0.149 (0.136) data 0.000 (0.003) loss 2.4491 (2.1515) teacher_loss 1.1857 (0.8759) loss_zs_kd 0.9717 (0.9398) loss_oracle 0.8630 (0.8630) acc 56.2500 (69.4085) kd_loss 0.8319 (0.8441) lr 3.1545e-04 eta 0:08:03
epoch [39/50] batch [300/319] time 0.080 (0.135) data 0.000 (0.002) loss 2.1829 (2.1540) teacher_loss 0.9258 (0.8783) loss_zs_kd 1.3764 (0.9476) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.4167) kd_loss 0.8256 (0.8441) lr 3.1545e-04 eta 0:07:54
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,821
* accuracy: 64.4%
* error: 35.6%
* macro_f1: 56.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,010
* accuracy: 51.5%
* error: 48.5%
* macro_f1: 22.5%
******* Domain 2 best val acc:      65.0%, epoch: 35 *******
******* Domain 2 best val test acc: 53.7%, epoch: 35 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [40/50] batch [20/319] time 0.157 (0.176) data 0.000 (0.025) loss 2.2130 (2.1143) teacher_loss 0.8893 (0.8355) loss_zs_kd 0.7697 (0.9281) loss_oracle 0.8630 (0.8630) acc 75.0000 (71.8750) kd_loss 0.8922 (0.8473) lr 2.7103e-04 eta 0:10:13
epoch [40/50] batch [40/319] time 0.184 (0.160) data 0.000 (0.013) loss 2.1039 (2.1526) teacher_loss 0.7775 (0.8676) loss_zs_kd 0.8192 (0.9493) loss_oracle 0.8631 (0.8630) acc 84.3750 (71.4844) kd_loss 0.8948 (0.8535) lr 2.7103e-04 eta 0:09:14
epoch [40/50] batch [60/319] time 0.192 (0.160) data 0.001 (0.009) loss 2.1595 (2.1575) teacher_loss 0.8517 (0.8719) loss_zs_kd 0.9114 (0.9638) loss_oracle 0.8630 (0.8630) acc 71.8750 (71.2500) kd_loss 0.8763 (0.8541) lr 2.7103e-04 eta 0:09:11
epoch [40/50] batch [80/319] time 0.064 (0.164) data 0.000 (0.007) loss 1.9765 (2.1290) teacher_loss 0.7278 (0.8444) loss_zs_kd 0.8821 (0.9721) loss_oracle 0.8630 (0.8630) acc 78.1250 (71.4844) kd_loss 0.8172 (0.8531) lr 2.7103e-04 eta 0:09:21
epoch [40/50] batch [100/319] time 0.143 (0.152) data 0.000 (0.005) loss 2.1930 (2.1306) teacher_loss 0.9093 (0.8484) loss_zs_kd 0.7033 (0.9627) loss_oracle 0.8631 (0.8630) acc 68.7500 (71.0625) kd_loss 0.8522 (0.8507) lr 2.7103e-04 eta 0:08:36
epoch [40/50] batch [120/319] time 0.135 (0.146) data 0.000 (0.004) loss 1.8977 (2.1255) teacher_loss 0.5849 (0.8430) loss_zs_kd 1.1512 (0.9690) loss_oracle 0.8630 (0.8630) acc 84.3750 (71.2500) kd_loss 0.8813 (0.8510) lr 2.7103e-04 eta 0:08:14
epoch [40/50] batch [140/319] time 0.115 (0.142) data 0.000 (0.004) loss 2.2447 (2.1332) teacher_loss 0.9055 (0.8511) loss_zs_kd 0.9590 (0.9661) loss_oracle 0.8630 (0.8630) acc 65.6250 (71.0045) kd_loss 0.9077 (0.8506) lr 2.7103e-04 eta 0:07:58
epoch [40/50] batch [160/319] time 0.100 (0.136) data 0.000 (0.003) loss 2.1734 (2.1314) teacher_loss 0.8768 (0.8483) loss_zs_kd 0.9700 (0.9734) loss_oracle 0.8630 (0.8630) acc 68.7500 (71.1523) kd_loss 0.8650 (0.8516) lr 2.7103e-04 eta 0:07:36
epoch [40/50] batch [180/319] time 0.090 (0.133) data 0.000 (0.003) loss 2.4117 (2.1345) teacher_loss 1.1120 (0.8505) loss_zs_kd 0.8755 (0.9725) loss_oracle 0.8630 (0.8630) acc 59.3750 (71.0938) kd_loss 0.8682 (0.8525) lr 2.7103e-04 eta 0:07:23
epoch [40/50] batch [200/319] time 0.115 (0.133) data 0.000 (0.003) loss 2.0383 (2.1474) teacher_loss 0.7869 (0.8619) loss_zs_kd 0.8344 (0.9670) loss_oracle 0.8630 (0.8630) acc 65.6250 (70.6250) kd_loss 0.8200 (0.8540) lr 2.7103e-04 eta 0:07:20
epoch [40/50] batch [220/319] time 0.144 (0.132) data 0.000 (0.003) loss 2.2412 (2.1513) teacher_loss 0.9108 (0.8654) loss_zs_kd 1.0763 (0.9654) loss_oracle 0.8631 (0.8630) acc 62.5000 (70.3409) kd_loss 0.8989 (0.8544) lr 2.7103e-04 eta 0:07:15
epoch [40/50] batch [240/319] time 0.126 (0.131) data 0.000 (0.002) loss 2.3855 (2.1532) teacher_loss 1.0966 (0.8663) loss_zs_kd 0.8835 (0.9652) loss_oracle 0.8630 (0.8630) acc 62.5000 (70.2214) kd_loss 0.8574 (0.8554) lr 2.7103e-04 eta 0:07:07
epoch [40/50] batch [260/319] time 0.145 (0.131) data 0.000 (0.002) loss 2.1209 (2.1549) teacher_loss 0.8963 (0.8684) loss_zs_kd 1.0815 (0.9660) loss_oracle 0.8630 (0.8630) acc 65.6250 (70.0721) kd_loss 0.7931 (0.8551) lr 2.7103e-04 eta 0:07:05
epoch [40/50] batch [280/319] time 0.099 (0.129) data 0.000 (0.002) loss 2.2370 (2.1602) teacher_loss 0.9491 (0.8730) loss_zs_kd 0.7500 (0.9617) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.8772) kd_loss 0.8564 (0.8557) lr 2.7103e-04 eta 0:06:56
epoch [40/50] batch [300/319] time 0.141 (0.129) data 0.000 (0.002) loss 2.4062 (2.1642) teacher_loss 1.1306 (0.8764) loss_zs_kd 0.8547 (0.9598) loss_oracle 0.8631 (0.8630) acc 65.6250 (69.7500) kd_loss 0.8441 (0.8562) lr 2.7103e-04 eta 0:06:53
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,823
* accuracy: 64.5%
* error: 35.5%
* macro_f1: 56.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,189
* accuracy: 53.3%
* error: 46.7%
* macro_f1: 23.0%
******* Domain 2 best val acc:      65.0%, epoch: 35 *******
******* Domain 2 best val test acc: 53.7%, epoch: 35 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [41/50] batch [20/319] time 0.156 (0.138) data 0.000 (0.033) loss 2.0970 (2.1450) teacher_loss 0.8693 (0.8528) loss_zs_kd 1.1017 (0.9969) loss_oracle 0.8630 (0.8630) acc 59.3750 (70.9375) kd_loss 0.7962 (0.8607) lr 2.2949e-04 eta 0:07:17
epoch [41/50] batch [40/319] time 0.092 (0.124) data 0.000 (0.016) loss 2.2308 (2.1467) teacher_loss 1.0141 (0.8597) loss_zs_kd 1.3126 (0.9865) loss_oracle 0.8630 (0.8630) acc 71.8750 (70.2344) kd_loss 0.7851 (0.8555) lr 2.2949e-04 eta 0:06:31
epoch [41/50] batch [60/319] time 0.087 (0.114) data 0.000 (0.011) loss 2.2274 (2.1589) teacher_loss 0.9031 (0.8681) loss_zs_kd 0.9250 (0.9818) loss_oracle 0.8630 (0.8630) acc 68.7500 (70.1042) kd_loss 0.8928 (0.8593) lr 2.2949e-04 eta 0:05:56
epoch [41/50] batch [80/319] time 0.138 (0.109) data 0.000 (0.008) loss 1.9904 (2.1572) teacher_loss 0.7087 (0.8641) loss_zs_kd 1.1647 (0.9987) loss_oracle 0.8630 (0.8630) acc 75.0000 (70.1562) kd_loss 0.8502 (0.8615) lr 2.2949e-04 eta 0:05:39
epoch [41/50] batch [100/319] time 0.085 (0.111) data 0.000 (0.007) loss 2.0891 (2.1590) teacher_loss 0.7671 (0.8661) loss_zs_kd 0.9927 (1.0014) loss_oracle 0.8630 (0.8630) acc 75.0000 (70.0000) kd_loss 0.8905 (0.8614) lr 2.2949e-04 eta 0:05:41
epoch [41/50] batch [120/319] time 0.084 (0.111) data 0.000 (0.006) loss 1.8615 (2.1665) teacher_loss 0.5735 (0.8724) loss_zs_kd 0.8626 (1.0014) loss_oracle 0.8630 (0.8630) acc 75.0000 (69.6875) kd_loss 0.8566 (0.8625) lr 2.2949e-04 eta 0:05:41
epoch [41/50] batch [140/319] time 0.101 (0.112) data 0.000 (0.005) loss 1.9047 (2.1629) teacher_loss 0.6349 (0.8695) loss_zs_kd 0.9562 (0.9981) loss_oracle 0.8630 (0.8630) acc 81.2500 (70.2009) kd_loss 0.8383 (0.8619) lr 2.2949e-04 eta 0:05:40
epoch [41/50] batch [160/319] time 0.157 (0.112) data 0.000 (0.004) loss 2.1634 (2.1647) teacher_loss 0.8802 (0.8750) loss_zs_kd 0.8720 (0.9928) loss_oracle 0.8630 (0.8630) acc 68.7500 (70.0195) kd_loss 0.8517 (0.8582) lr 2.2949e-04 eta 0:05:40
epoch [41/50] batch [180/319] time 0.139 (0.116) data 0.000 (0.004) loss 1.9290 (2.1621) teacher_loss 0.6698 (0.8729) loss_zs_kd 0.9848 (0.9910) loss_oracle 0.8631 (0.8630) acc 78.1250 (70.1389) kd_loss 0.8276 (0.8577) lr 2.2949e-04 eta 0:05:48
epoch [41/50] batch [200/319] time 0.142 (0.117) data 0.000 (0.003) loss 1.9744 (2.1568) teacher_loss 0.6781 (0.8681) loss_zs_kd 0.9480 (0.9850) loss_oracle 0.8630 (0.8630) acc 78.1250 (70.4375) kd_loss 0.8648 (0.8572) lr 2.2949e-04 eta 0:05:50
epoch [41/50] batch [220/319] time 0.145 (0.120) data 0.000 (0.003) loss 2.1967 (2.1549) teacher_loss 0.8906 (0.8663) loss_zs_kd 0.9416 (0.9854) loss_oracle 0.8630 (0.8630) acc 56.2500 (70.2841) kd_loss 0.8747 (0.8572) lr 2.2949e-04 eta 0:05:57
epoch [41/50] batch [240/319] time 0.086 (0.121) data 0.000 (0.003) loss 2.1014 (2.1559) teacher_loss 0.8574 (0.8683) loss_zs_kd 0.7771 (0.9841) loss_oracle 0.8630 (0.8630) acc 65.6250 (70.1823) kd_loss 0.8125 (0.8560) lr 2.2949e-04 eta 0:05:58
epoch [41/50] batch [260/319] time 0.110 (0.120) data 0.000 (0.003) loss 2.2151 (2.1579) teacher_loss 0.9503 (0.8715) loss_zs_kd 0.9650 (0.9782) loss_oracle 0.8630 (0.8630) acc 65.6250 (69.8798) kd_loss 0.8333 (0.8549) lr 2.2949e-04 eta 0:05:52
epoch [41/50] batch [280/319] time 0.153 (0.122) data 0.000 (0.003) loss 2.1489 (2.1613) teacher_loss 0.8868 (0.8749) loss_zs_kd 0.9025 (0.9786) loss_oracle 0.8631 (0.8630) acc 78.1250 (69.6429) kd_loss 0.8305 (0.8548) lr 2.2949e-04 eta 0:05:56
epoch [41/50] batch [300/319] time 0.128 (0.122) data 0.000 (0.002) loss 2.2638 (2.1592) teacher_loss 0.9536 (0.8737) loss_zs_kd 0.8306 (0.9749) loss_oracle 0.8630 (0.8630) acc 75.0000 (69.7083) kd_loss 0.8787 (0.8540) lr 2.2949e-04 eta 0:05:52
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,853
* accuracy: 65.2%
* error: 34.8%
* macro_f1: 56.4%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,010
* accuracy: 51.5%
* error: 48.5%
* macro_f1: 22.5%
******* Domain 2 best val acc:      65.2%, epoch: 41 *******
******* Domain 2 best val test acc: 51.5%, epoch: 41 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [42/50] batch [20/319] time 0.154 (0.172) data 0.000 (0.032) loss 2.2358 (2.1927) teacher_loss 0.9367 (0.9023) loss_zs_kd 1.2131 (0.8962) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.5312) kd_loss 0.8676 (0.8589) lr 1.9098e-04 eta 0:08:11
epoch [42/50] batch [40/319] time 0.150 (0.161) data 0.000 (0.016) loss 1.8103 (2.1885) teacher_loss 0.5593 (0.9040) loss_zs_kd 0.8637 (0.9116) loss_oracle 0.8630 (0.8630) acc 81.2500 (69.6875) kd_loss 0.8195 (0.8529) lr 1.9098e-04 eta 0:07:36
epoch [42/50] batch [60/319] time 0.150 (0.158) data 0.000 (0.011) loss 2.2251 (2.1904) teacher_loss 0.9387 (0.9105) loss_zs_kd 0.8884 (0.9162) loss_oracle 0.8630 (0.8630) acc 59.3750 (69.2708) kd_loss 0.8549 (0.8484) lr 1.9098e-04 eta 0:07:22
epoch [42/50] batch [80/319] time 0.157 (0.156) data 0.000 (0.008) loss 2.1472 (2.1816) teacher_loss 0.8718 (0.9033) loss_zs_kd 0.8642 (0.9223) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.1406) kd_loss 0.8439 (0.8468) lr 1.9098e-04 eta 0:07:15
epoch [42/50] batch [100/319] time 0.153 (0.155) data 0.000 (0.007) loss 2.7228 (2.1905) teacher_loss 1.3739 (0.9120) loss_zs_kd 1.0566 (0.9256) loss_oracle 0.8630 (0.8630) acc 46.8750 (68.7812) kd_loss 0.9174 (0.8470) lr 1.9098e-04 eta 0:07:10
epoch [42/50] batch [120/319] time 0.150 (0.154) data 0.000 (0.006) loss 2.2356 (2.1758) teacher_loss 0.9448 (0.8980) loss_zs_kd 0.9907 (0.9379) loss_oracle 0.8630 (0.8630) acc 65.6250 (69.2969) kd_loss 0.8593 (0.8463) lr 1.9098e-04 eta 0:07:05
epoch [42/50] batch [140/319] time 0.090 (0.150) data 0.000 (0.005) loss 1.7507 (2.1795) teacher_loss 0.5148 (0.9044) loss_zs_kd 1.0624 (0.9425) loss_oracle 0.8630 (0.8630) acc 87.5000 (68.9955) kd_loss 0.8044 (0.8436) lr 1.9098e-04 eta 0:06:49
epoch [42/50] batch [160/319] time 0.196 (0.146) data 0.000 (0.004) loss 2.5540 (2.1795) teacher_loss 1.2517 (0.9033) loss_zs_kd 1.1535 (0.9425) loss_oracle 0.8630 (0.8630) acc 59.3750 (69.1211) kd_loss 0.8708 (0.8447) lr 1.9098e-04 eta 0:06:36
epoch [42/50] batch [180/319] time 0.188 (0.147) data 0.000 (0.004) loss 2.0932 (2.1771) teacher_loss 0.8877 (0.9014) loss_zs_kd 1.0235 (0.9529) loss_oracle 0.8630 (0.8630) acc 65.6250 (69.2188) kd_loss 0.7740 (0.8441) lr 1.9098e-04 eta 0:06:35
epoch [42/50] batch [200/319] time 0.066 (0.149) data 0.000 (0.003) loss 2.1067 (2.1728) teacher_loss 0.8454 (0.8967) loss_zs_kd 0.9062 (0.9561) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.2031) kd_loss 0.8298 (0.8446) lr 1.9098e-04 eta 0:06:37
epoch [42/50] batch [220/319] time 0.084 (0.145) data 0.000 (0.003) loss 2.2960 (2.1637) teacher_loss 0.9909 (0.8883) loss_zs_kd 0.7927 (0.9616) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.3466) kd_loss 0.8736 (0.8439) lr 1.9098e-04 eta 0:06:23
epoch [42/50] batch [240/319] time 0.125 (0.142) data 0.000 (0.003) loss 2.4037 (2.1609) teacher_loss 1.1196 (0.8866) loss_zs_kd 0.9731 (0.9627) loss_oracle 0.8630 (0.8630) acc 59.3750 (69.3099) kd_loss 0.8526 (0.8427) lr 1.9098e-04 eta 0:06:12
epoch [42/50] batch [260/319] time 0.106 (0.139) data 0.000 (0.003) loss 2.2959 (2.1566) teacher_loss 1.0065 (0.8827) loss_zs_kd 1.0498 (0.9603) loss_oracle 0.8630 (0.8630) acc 59.3750 (69.4351) kd_loss 0.8579 (0.8424) lr 1.9098e-04 eta 0:06:03
epoch [42/50] batch [280/319] time 0.142 (0.137) data 0.000 (0.003) loss 2.3200 (2.1560) teacher_loss 1.0343 (0.8819) loss_zs_kd 0.8169 (0.9635) loss_oracle 0.8630 (0.8630) acc 65.6250 (69.5424) kd_loss 0.8541 (0.8426) lr 1.9098e-04 eta 0:05:55
epoch [42/50] batch [300/319] time 0.104 (0.136) data 0.000 (0.002) loss 2.1708 (2.1589) teacher_loss 0.8489 (0.8854) loss_zs_kd 1.1027 (0.9679) loss_oracle 0.8630 (0.8630) acc 75.0000 (69.3125) kd_loss 0.8904 (0.8420) lr 1.9098e-04 eta 0:05:49
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,836
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 56.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,047
* accuracy: 51.8%
* error: 48.2%
* macro_f1: 22.6%
******* Domain 2 best val acc:      65.2%, epoch: 41 *******
******* Domain 2 best val test acc: 51.5%, epoch: 41 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [43/50] batch [20/319] time 0.194 (0.153) data 0.000 (0.029) loss 2.0072 (2.1005) teacher_loss 0.7342 (0.8392) loss_zs_kd 1.2453 (0.9795) loss_oracle 0.8630 (0.8630) acc 75.0000 (71.4062) kd_loss 0.8415 (0.8298) lr 1.5567e-04 eta 0:06:26
epoch [43/50] batch [40/319] time 0.071 (0.147) data 0.000 (0.015) loss 2.4444 (2.1430) teacher_loss 1.2191 (0.8760) loss_zs_kd 0.8987 (0.9542) loss_oracle 0.8630 (0.8630) acc 56.2500 (69.5312) kd_loss 0.7937 (0.8355) lr 1.5567e-04 eta 0:06:10
epoch [43/50] batch [60/319] time 0.180 (0.147) data 0.000 (0.010) loss 2.4646 (2.1452) teacher_loss 1.2153 (0.8750) loss_zs_kd 0.9343 (0.9525) loss_oracle 0.8630 (0.8630) acc 50.0000 (69.4271) kd_loss 0.8179 (0.8387) lr 1.5567e-04 eta 0:06:06
epoch [43/50] batch [80/319] time 0.089 (0.141) data 0.000 (0.007) loss 2.0413 (2.1439) teacher_loss 0.7118 (0.8762) loss_zs_kd 1.1106 (0.9515) loss_oracle 0.8630 (0.8630) acc 81.2500 (69.8047) kd_loss 0.8980 (0.8363) lr 1.5567e-04 eta 0:05:49
epoch [43/50] batch [100/319] time 0.081 (0.135) data 0.000 (0.006) loss 1.8799 (2.1345) teacher_loss 0.6299 (0.8690) loss_zs_kd 0.8710 (0.9437) loss_oracle 0.8630 (0.8630) acc 81.2500 (70.0312) kd_loss 0.8185 (0.8340) lr 1.5567e-04 eta 0:05:31
epoch [43/50] batch [120/319] time 0.131 (0.129) data 0.000 (0.005) loss 2.1039 (2.1397) teacher_loss 0.8591 (0.8717) loss_zs_kd 0.9313 (0.9372) loss_oracle 0.8630 (0.8630) acc 59.3750 (69.7917) kd_loss 0.8133 (0.8365) lr 1.5567e-04 eta 0:05:14
epoch [43/50] batch [140/319] time 0.162 (0.130) data 0.000 (0.004) loss 2.3135 (2.1416) teacher_loss 1.0119 (0.8741) loss_zs_kd 0.8122 (0.9447) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.4420) kd_loss 0.8701 (0.8360) lr 1.5567e-04 eta 0:05:13
epoch [43/50] batch [160/319] time 0.156 (0.133) data 0.000 (0.004) loss 2.0842 (2.1370) teacher_loss 0.8171 (0.8699) loss_zs_kd 0.9361 (0.9475) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.7656) kd_loss 0.8356 (0.8356) lr 1.5567e-04 eta 0:05:17
epoch [43/50] batch [180/319] time 0.160 (0.135) data 0.000 (0.003) loss 2.1098 (2.1452) teacher_loss 0.8475 (0.8784) loss_zs_kd 0.8536 (0.9477) loss_oracle 0.8630 (0.8630) acc 78.1250 (69.6875) kd_loss 0.8309 (0.8353) lr 1.5567e-04 eta 0:05:20
epoch [43/50] batch [200/319] time 0.141 (0.134) data 0.000 (0.003) loss 2.1814 (2.1491) teacher_loss 0.9246 (0.8810) loss_zs_kd 0.8635 (0.9500) loss_oracle 0.8630 (0.8630) acc 62.5000 (69.6250) kd_loss 0.8253 (0.8367) lr 1.5567e-04 eta 0:05:15
epoch [43/50] batch [220/319] time 0.158 (0.133) data 0.000 (0.003) loss 2.5762 (2.1557) teacher_loss 1.2859 (0.8881) loss_zs_kd 1.0259 (0.9435) loss_oracle 0.8630 (0.8630) acc 50.0000 (69.3466) kd_loss 0.8587 (0.8360) lr 1.5567e-04 eta 0:05:09
epoch [43/50] batch [240/319] time 0.143 (0.134) data 0.000 (0.003) loss 2.1662 (2.1567) teacher_loss 0.8782 (0.8887) loss_zs_kd 1.1339 (0.9438) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.2318) kd_loss 0.8565 (0.8365) lr 1.5567e-04 eta 0:05:10
epoch [43/50] batch [260/319] time 0.144 (0.136) data 0.000 (0.002) loss 2.0840 (2.1569) teacher_loss 0.7918 (0.8881) loss_zs_kd 1.1132 (0.9456) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.2428) kd_loss 0.8607 (0.8372) lr 1.5567e-04 eta 0:05:11
epoch [43/50] batch [280/319] time 0.144 (0.137) data 0.000 (0.002) loss 2.0198 (2.1514) teacher_loss 0.7127 (0.8834) loss_zs_kd 1.0211 (0.9455) loss_oracle 0.8631 (0.8630) acc 78.1250 (69.4308) kd_loss 0.8755 (0.8365) lr 1.5567e-04 eta 0:05:11
epoch [43/50] batch [300/319] time 0.084 (0.137) data 0.000 (0.002) loss 2.1720 (2.1497) teacher_loss 0.9191 (0.8824) loss_zs_kd 0.6973 (0.9464) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.4688) kd_loss 0.8214 (0.8358) lr 1.5567e-04 eta 0:05:07
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,837
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 56.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,149
* accuracy: 52.9%
* error: 47.1%
* macro_f1: 22.6%
******* Domain 2 best val acc:      65.2%, epoch: 41 *******
******* Domain 2 best val test acc: 51.5%, epoch: 41 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [44/50] batch [20/319] time 0.101 (0.152) data 0.000 (0.027) loss 2.4771 (2.1606) teacher_loss 1.2321 (0.8956) loss_zs_kd 0.9211 (0.9627) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.8438) kd_loss 0.8135 (0.8335) lr 1.2369e-04 eta 0:05:36
epoch [44/50] batch [40/319] time 0.100 (0.129) data 0.000 (0.014) loss 2.5563 (2.1765) teacher_loss 1.2556 (0.9180) loss_zs_kd 0.7740 (0.9529) loss_oracle 0.8630 (0.8630) acc 56.2500 (69.0625) kd_loss 0.8692 (0.8270) lr 1.2369e-04 eta 0:04:43
epoch [44/50] batch [60/319] time 0.099 (0.116) data 0.001 (0.009) loss 1.7897 (2.1600) teacher_loss 0.5144 (0.8989) loss_zs_kd 1.0475 (0.9442) loss_oracle 0.8630 (0.8630) acc 84.3750 (69.2188) kd_loss 0.8438 (0.8296) lr 1.2369e-04 eta 0:04:12
epoch [44/50] batch [80/319] time 0.126 (0.114) data 0.000 (0.007) loss 2.0010 (2.1483) teacher_loss 0.8602 (0.8866) loss_zs_kd 1.1396 (0.9450) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.2969) kd_loss 0.7092 (0.8302) lr 1.2369e-04 eta 0:04:05
epoch [44/50] batch [100/319] time 0.090 (0.111) data 0.000 (0.006) loss 2.2538 (2.1492) teacher_loss 0.9664 (0.8861) loss_zs_kd 0.8422 (0.9506) loss_oracle 0.8630 (0.8630) acc 59.3750 (69.3125) kd_loss 0.8559 (0.8315) lr 1.2369e-04 eta 0:03:56
epoch [44/50] batch [120/319] time 0.140 (0.109) data 0.000 (0.005) loss 2.3739 (2.1666) teacher_loss 1.1361 (0.9007) loss_zs_kd 0.9202 (0.9372) loss_oracle 0.8630 (0.8630) acc 62.5000 (68.5417) kd_loss 0.8062 (0.8344) lr 1.2369e-04 eta 0:03:50
epoch [44/50] batch [140/319] time 0.084 (0.109) data 0.000 (0.004) loss 2.3597 (2.1737) teacher_loss 1.1224 (0.9071) loss_zs_kd 0.9261 (0.9256) loss_oracle 0.8630 (0.8630) acc 65.6250 (68.1696) kd_loss 0.8059 (0.8351) lr 1.2369e-04 eta 0:03:48
epoch [44/50] batch [160/319] time 0.088 (0.108) data 0.000 (0.004) loss 2.2983 (2.1781) teacher_loss 1.0196 (0.9108) loss_zs_kd 0.7778 (0.9273) loss_oracle 0.8630 (0.8630) acc 62.5000 (68.1445) kd_loss 0.8472 (0.8358) lr 1.2369e-04 eta 0:03:44
epoch [44/50] batch [180/319] time 0.117 (0.107) data 0.000 (0.003) loss 2.4622 (2.1806) teacher_loss 1.1647 (0.9137) loss_zs_kd 0.7362 (0.9260) loss_oracle 0.8630 (0.8630) acc 59.3750 (67.8472) kd_loss 0.8660 (0.8354) lr 1.2369e-04 eta 0:03:39
epoch [44/50] batch [200/319] time 0.068 (0.107) data 0.000 (0.003) loss 1.8498 (2.1787) teacher_loss 0.5312 (0.9101) loss_zs_kd 0.7624 (0.9295) loss_oracle 0.8630 (0.8630) acc 78.1250 (68.0938) kd_loss 0.8871 (0.8371) lr 1.2369e-04 eta 0:03:37
epoch [44/50] batch [220/319] time 0.090 (0.106) data 0.000 (0.003) loss 1.9838 (2.1750) teacher_loss 0.7119 (0.9063) loss_zs_kd 0.9999 (0.9343) loss_oracle 0.8630 (0.8630) acc 75.0000 (68.1534) kd_loss 0.8404 (0.8372) lr 1.2369e-04 eta 0:03:33
epoch [44/50] batch [240/319] time 0.144 (0.107) data 0.000 (0.002) loss 2.3679 (2.1715) teacher_loss 1.0981 (0.9030) loss_zs_kd 1.2211 (0.9375) loss_oracle 0.8630 (0.8630) acc 65.6250 (68.2812) kd_loss 0.8383 (0.8371) lr 1.2369e-04 eta 0:03:33
epoch [44/50] batch [260/319] time 0.080 (0.106) data 0.000 (0.002) loss 2.2234 (2.1706) teacher_loss 0.9898 (0.9021) loss_zs_kd 0.8828 (0.9365) loss_oracle 0.8630 (0.8630) acc 59.3750 (68.3053) kd_loss 0.8021 (0.8370) lr 1.2369e-04 eta 0:03:29
epoch [44/50] batch [280/319] time 0.105 (0.105) data 0.000 (0.002) loss 2.3013 (2.1695) teacher_loss 1.0312 (0.9008) loss_zs_kd 0.8864 (0.9346) loss_oracle 0.8630 (0.8630) acc 56.2500 (68.4487) kd_loss 0.8387 (0.8372) lr 1.2369e-04 eta 0:03:25
epoch [44/50] batch [300/319] time 0.163 (0.106) data 0.000 (0.002) loss 2.1463 (2.1683) teacher_loss 0.9476 (0.8993) loss_zs_kd 0.8925 (0.9345) loss_oracle 0.8630 (0.8630) acc 65.6250 (68.5000) kd_loss 0.7672 (0.8375) lr 1.2369e-04 eta 0:03:24
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,847
* accuracy: 65.0%
* error: 35.0%
* macro_f1: 56.9%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,050
* accuracy: 51.9%
* error: 48.1%
* macro_f1: 22.6%
******* Domain 2 best val acc:      65.2%, epoch: 41 *******
******* Domain 2 best val test acc: 51.5%, epoch: 41 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [45/50] batch [20/319] time 0.141 (0.153) data 0.000 (0.023) loss 1.8934 (2.1007) teacher_loss 0.6830 (0.8319) loss_zs_kd 0.6320 (0.9189) loss_oracle 0.8630 (0.8630) acc 78.1250 (70.0000) kd_loss 0.7789 (0.8373) lr 9.5173e-05 eta 0:04:49
epoch [45/50] batch [40/319] time 0.108 (0.133) data 0.000 (0.012) loss 2.2355 (2.1401) teacher_loss 0.9458 (0.8723) loss_zs_kd 0.8636 (0.9167) loss_oracle 0.8630 (0.8630) acc 75.0000 (70.1562) kd_loss 0.8583 (0.8363) lr 9.5173e-05 eta 0:04:08
epoch [45/50] batch [60/319] time 0.140 (0.128) data 0.001 (0.008) loss 2.0612 (2.1573) teacher_loss 0.7614 (0.8836) loss_zs_kd 1.0739 (0.9408) loss_oracle 0.8630 (0.8630) acc 81.2500 (70.1562) kd_loss 0.8683 (0.8422) lr 9.5173e-05 eta 0:03:57
epoch [45/50] batch [80/319] time 0.107 (0.124) data 0.000 (0.006) loss 2.1889 (2.1491) teacher_loss 0.9131 (0.8737) loss_zs_kd 1.0804 (0.9392) loss_oracle 0.8630 (0.8630) acc 59.3750 (70.1562) kd_loss 0.8443 (0.8439) lr 9.5173e-05 eta 0:03:47
epoch [45/50] batch [100/319] time 0.148 (0.124) data 0.000 (0.005) loss 2.3303 (2.1536) teacher_loss 0.9490 (0.8755) loss_zs_kd 0.8135 (0.9402) loss_oracle 0.8630 (0.8630) acc 68.7500 (70.0625) kd_loss 0.9498 (0.8466) lr 9.5173e-05 eta 0:03:44
epoch [45/50] batch [120/319] time 0.159 (0.127) data 0.000 (0.004) loss 2.1033 (2.1527) teacher_loss 0.9135 (0.8745) loss_zs_kd 0.7549 (0.9333) loss_oracle 0.8630 (0.8630) acc 65.6250 (69.8958) kd_loss 0.7583 (0.8467) lr 9.5173e-05 eta 0:03:47
epoch [45/50] batch [140/319] time 0.152 (0.130) data 0.000 (0.004) loss 2.1806 (2.1443) teacher_loss 0.8160 (0.8643) loss_zs_kd 0.9254 (0.9388) loss_oracle 0.8630 (0.8630) acc 75.0000 (70.2902) kd_loss 0.9330 (0.8485) lr 9.5173e-05 eta 0:03:51
epoch [45/50] batch [160/319] time 0.136 (0.132) data 0.000 (0.003) loss 2.1086 (2.1367) teacher_loss 0.8572 (0.8574) loss_zs_kd 0.8055 (0.9355) loss_oracle 0.8630 (0.8630) acc 65.6250 (70.2734) kd_loss 0.8199 (0.8477) lr 9.5173e-05 eta 0:03:51
epoch [45/50] batch [180/319] time 0.073 (0.133) data 0.001 (0.003) loss 1.9960 (2.1352) teacher_loss 0.7718 (0.8550) loss_zs_kd 1.0087 (0.9418) loss_oracle 0.8629 (0.8630) acc 78.1250 (70.4514) kd_loss 0.7927 (0.8487) lr 9.5173e-05 eta 0:03:50
epoch [45/50] batch [200/319] time 0.189 (0.136) data 0.000 (0.003) loss 2.0898 (2.1365) teacher_loss 0.8205 (0.8567) loss_zs_kd 0.8178 (0.9340) loss_oracle 0.8629 (0.8630) acc 68.7500 (70.4219) kd_loss 0.8379 (0.8483) lr 9.5173e-05 eta 0:03:52
epoch [45/50] batch [220/319] time 0.198 (0.134) data 0.000 (0.002) loss 1.8672 (2.1378) teacher_loss 0.5574 (0.8582) loss_zs_kd 0.7706 (0.9330) loss_oracle 0.8630 (0.8630) acc 78.1250 (70.4261) kd_loss 0.8783 (0.8480) lr 9.5173e-05 eta 0:03:47
epoch [45/50] batch [240/319] time 0.114 (0.138) data 0.001 (0.002) loss 2.1850 (2.1336) teacher_loss 0.8698 (0.8546) loss_zs_kd 1.1396 (0.9341) loss_oracle 0.8629 (0.8630) acc 65.6250 (70.4297) kd_loss 0.8838 (0.8475) lr 9.5173e-05 eta 0:03:50
epoch [45/50] batch [260/319] time 0.141 (0.138) data 0.000 (0.002) loss 2.1929 (2.1451) teacher_loss 0.9373 (0.8666) loss_zs_kd 0.9696 (0.9333) loss_oracle 0.8630 (0.8630) acc 59.3750 (69.9760) kd_loss 0.8241 (0.8471) lr 9.5173e-05 eta 0:03:48
epoch [45/50] batch [280/319] time 0.160 (0.139) data 0.000 (0.002) loss 1.9873 (2.1500) teacher_loss 0.6959 (0.8731) loss_zs_kd 1.1232 (0.9339) loss_oracle 0.8630 (0.8630) acc 75.0000 (69.8549) kd_loss 0.8598 (0.8454) lr 9.5173e-05 eta 0:03:46
epoch [45/50] batch [300/319] time 0.160 (0.140) data 0.000 (0.002) loss 2.0696 (2.1483) teacher_loss 0.8115 (0.8720) loss_zs_kd 0.7907 (0.9347) loss_oracle 0.8630 (0.8630) acc 81.2500 (69.9271) kd_loss 0.8265 (0.8448) lr 9.5173e-05 eta 0:03:45
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,868
* accuracy: 65.5%
* error: 34.5%
* macro_f1: 57.5%
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,109
* accuracy: 52.5%
* error: 47.5%
* macro_f1: 22.5%
******* Domain 2 best val acc:      65.5%, epoch: 45 *******
******* Domain 2 best val test acc: 52.5%, epoch: 45 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [46/50] batch [20/319] time 0.194 (0.188) data 0.000 (0.033) loss 2.1677 (2.1046) teacher_loss 0.9118 (0.8415) loss_zs_kd 0.9137 (0.9627) loss_oracle 0.8630 (0.8630) acc 68.7500 (71.5625) kd_loss 0.8244 (0.8316) lr 7.0224e-05 eta 0:04:56
epoch [46/50] batch [40/319] time 0.227 (0.165) data 0.000 (0.016) loss 2.3557 (2.1257) teacher_loss 1.0522 (0.8516) loss_zs_kd 0.9262 (0.9535) loss_oracle 0.8630 (0.8630) acc 59.3750 (70.3125) kd_loss 0.8720 (0.8427) lr 7.0224e-05 eta 0:04:15
epoch [46/50] batch [60/319] time 0.105 (0.163) data 0.000 (0.011) loss 2.1178 (2.1208) teacher_loss 0.8239 (0.8431) loss_zs_kd 1.0042 (0.9710) loss_oracle 0.8630 (0.8630) acc 75.0000 (70.4167) kd_loss 0.8625 (0.8462) lr 7.0224e-05 eta 0:04:10
epoch [46/50] batch [80/319] time 0.140 (0.158) data 0.000 (0.008) loss 2.0041 (2.1222) teacher_loss 0.7744 (0.8447) loss_zs_kd 0.8120 (0.9767) loss_oracle 0.8630 (0.8630) acc 75.0000 (70.7422) kd_loss 0.7983 (0.8460) lr 7.0224e-05 eta 0:03:58
epoch [46/50] batch [100/319] time 0.138 (0.156) data 0.000 (0.007) loss 1.7875 (2.1236) teacher_loss 0.5367 (0.8436) loss_zs_kd 0.8417 (0.9765) loss_oracle 0.8629 (0.8630) acc 84.3750 (70.5938) kd_loss 0.8193 (0.8485) lr 7.0224e-05 eta 0:03:53
epoch [46/50] batch [120/319] time 0.146 (0.156) data 0.001 (0.006) loss 2.1346 (2.1227) teacher_loss 0.8141 (0.8454) loss_zs_kd 0.9927 (0.9685) loss_oracle 0.8630 (0.8630) acc 71.8750 (70.5990) kd_loss 0.8890 (0.8458) lr 7.0224e-05 eta 0:03:49
epoch [46/50] batch [140/319] time 0.153 (0.155) data 0.000 (0.005) loss 2.1144 (2.1304) teacher_loss 0.8508 (0.8530) loss_zs_kd 0.7187 (0.9641) loss_oracle 0.8630 (0.8630) acc 75.0000 (70.4911) kd_loss 0.8322 (0.8458) lr 7.0224e-05 eta 0:03:45
epoch [46/50] batch [160/319] time 0.144 (0.154) data 0.000 (0.004) loss 1.9147 (2.1257) teacher_loss 0.6136 (0.8471) loss_zs_kd 0.8043 (0.9635) loss_oracle 0.8630 (0.8630) acc 84.3750 (70.7812) kd_loss 0.8696 (0.8471) lr 7.0224e-05 eta 0:03:41
epoch [46/50] batch [180/319] time 0.071 (0.150) data 0.000 (0.004) loss 2.2145 (2.1346) teacher_loss 0.9250 (0.8560) loss_zs_kd 0.8103 (0.9639) loss_oracle 0.8630 (0.8630) acc 65.6250 (70.3819) kd_loss 0.8581 (0.8471) lr 7.0224e-05 eta 0:03:32
epoch [46/50] batch [200/319] time 0.084 (0.145) data 0.000 (0.004) loss 2.1558 (2.1360) teacher_loss 0.9172 (0.8569) loss_zs_kd 0.8565 (0.9658) loss_oracle 0.8629 (0.8630) acc 65.6250 (70.3594) kd_loss 0.8070 (0.8475) lr 7.0224e-05 eta 0:03:21
epoch [46/50] batch [220/319] time 0.081 (0.142) data 0.000 (0.003) loss 2.3775 (2.1430) teacher_loss 1.1171 (0.8646) loss_zs_kd 0.9659 (0.9614) loss_oracle 0.8630 (0.8630) acc 62.5000 (70.0000) kd_loss 0.8289 (0.8469) lr 7.0224e-05 eta 0:03:14
epoch [46/50] batch [240/319] time 0.151 (0.143) data 0.000 (0.003) loss 1.9526 (2.1456) teacher_loss 0.7480 (0.8660) loss_zs_kd 0.8356 (0.9603) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.9479) kd_loss 0.7731 (0.8482) lr 7.0224e-05 eta 0:03:13
epoch [46/50] batch [260/319] time 0.150 (0.142) data 0.000 (0.003) loss 2.2243 (2.1450) teacher_loss 0.8742 (0.8665) loss_zs_kd 1.0164 (0.9596) loss_oracle 0.8630 (0.8630) acc 71.8750 (70.0361) kd_loss 0.9186 (0.8470) lr 7.0224e-05 eta 0:03:09
epoch [46/50] batch [280/319] time 0.084 (0.140) data 0.000 (0.003) loss 2.2549 (2.1477) teacher_loss 0.9935 (0.8705) loss_zs_kd 0.7928 (0.9584) loss_oracle 0.8630 (0.8630) acc 59.3750 (69.8438) kd_loss 0.8299 (0.8456) lr 7.0224e-05 eta 0:03:03
epoch [46/50] batch [300/319] time 0.160 (0.139) data 0.000 (0.002) loss 2.0646 (2.1452) teacher_loss 0.8153 (0.8685) loss_zs_kd 1.0010 (0.9571) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.8333) kd_loss 0.8178 (0.8452) lr 7.0224e-05 eta 0:02:59
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,866
* accuracy: 65.5%
* error: 34.5%
* macro_f1: 57.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,099
* accuracy: 52.4%
* error: 47.6%
* macro_f1: 22.7%
******* Domain 2 best val acc:      65.5%, epoch: 45 *******
******* Domain 2 best val test acc: 52.5%, epoch: 45 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [47/50] batch [20/319] time 0.141 (0.164) data 0.000 (0.023) loss 2.0684 (2.2081) teacher_loss 0.8218 (0.9360) loss_zs_kd 0.9041 (0.9310) loss_oracle 0.8630 (0.8630) acc 75.0000 (69.3750) kd_loss 0.8151 (0.8405) lr 4.8943e-05 eta 0:03:25
epoch [47/50] batch [40/319] time 0.146 (0.158) data 0.000 (0.012) loss 2.0965 (2.1821) teacher_loss 0.8061 (0.9091) loss_zs_kd 0.8920 (0.9258) loss_oracle 0.8630 (0.8630) acc 65.6250 (68.9062) kd_loss 0.8590 (0.8415) lr 4.8943e-05 eta 0:03:15
epoch [47/50] batch [60/319] time 0.157 (0.157) data 0.000 (0.008) loss 2.3653 (2.1637) teacher_loss 0.9686 (0.8893) loss_zs_kd 1.1673 (0.9517) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.6875) kd_loss 0.9651 (0.8428) lr 4.8943e-05 eta 0:03:10
epoch [47/50] batch [80/319] time 0.148 (0.156) data 0.000 (0.006) loss 2.1725 (2.1597) teacher_loss 0.9954 (0.8869) loss_zs_kd 0.7408 (0.9370) loss_oracle 0.8629 (0.8630) acc 56.2500 (69.2188) kd_loss 0.7456 (0.8413) lr 4.8943e-05 eta 0:03:06
epoch [47/50] batch [100/319] time 0.084 (0.151) data 0.000 (0.005) loss 1.8712 (2.1643) teacher_loss 0.6249 (0.8916) loss_zs_kd 0.9535 (0.9395) loss_oracle 0.8630 (0.8630) acc 81.2500 (68.8438) kd_loss 0.8149 (0.8412) lr 4.8943e-05 eta 0:02:57
epoch [47/50] batch [120/319] time 0.136 (0.144) data 0.000 (0.004) loss 1.9388 (2.1504) teacher_loss 0.6474 (0.8752) loss_zs_kd 0.7887 (0.9451) loss_oracle 0.8630 (0.8630) acc 78.1250 (69.2708) kd_loss 0.8599 (0.8437) lr 4.8943e-05 eta 0:02:45
epoch [47/50] batch [140/319] time 0.082 (0.139) data 0.000 (0.003) loss 2.3614 (2.1407) teacher_loss 1.1231 (0.8663) loss_zs_kd 1.0507 (0.9455) loss_oracle 0.8630 (0.8630) acc 56.2500 (69.6875) kd_loss 0.8068 (0.8429) lr 4.8943e-05 eta 0:02:37
epoch [47/50] batch [160/319] time 0.135 (0.136) data 0.000 (0.003) loss 2.1132 (2.1368) teacher_loss 0.8596 (0.8628) loss_zs_kd 0.6966 (0.9475) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.9023) kd_loss 0.8220 (0.8425) lr 4.8943e-05 eta 0:02:31
epoch [47/50] batch [180/319] time 0.092 (0.134) data 0.000 (0.003) loss 2.0537 (2.1390) teacher_loss 0.7885 (0.8630) loss_zs_kd 1.0260 (0.9508) loss_oracle 0.8630 (0.8630) acc 59.3750 (69.7569) kd_loss 0.8337 (0.8444) lr 4.8943e-05 eta 0:02:26
epoch [47/50] batch [200/319] time 0.145 (0.134) data 0.000 (0.002) loss 2.2744 (2.1345) teacher_loss 1.0019 (0.8590) loss_zs_kd 1.1334 (0.9464) loss_oracle 0.8631 (0.8630) acc 65.6250 (69.9062) kd_loss 0.8409 (0.8440) lr 4.8943e-05 eta 0:02:24
epoch [47/50] batch [220/319] time 0.117 (0.136) data 0.000 (0.002) loss 1.9117 (2.1339) teacher_loss 0.6453 (0.8583) loss_zs_kd 0.8596 (0.9511) loss_oracle 0.8630 (0.8630) acc 78.1250 (69.9290) kd_loss 0.8349 (0.8441) lr 4.8943e-05 eta 0:02:23
epoch [47/50] batch [240/319] time 0.193 (0.139) data 0.000 (0.002) loss 1.9839 (2.1393) teacher_loss 0.6742 (0.8638) loss_zs_kd 0.8813 (0.9516) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.7005) kd_loss 0.8782 (0.8440) lr 4.8943e-05 eta 0:02:23
epoch [47/50] batch [260/319] time 0.191 (0.139) data 0.000 (0.002) loss 2.3806 (2.1432) teacher_loss 1.1141 (0.8678) loss_zs_kd 0.8166 (0.9506) loss_oracle 0.8629 (0.8630) acc 59.3750 (69.6154) kd_loss 0.8351 (0.8440) lr 4.8943e-05 eta 0:02:21
epoch [47/50] batch [280/319] time 0.101 (0.139) data 0.000 (0.002) loss 2.4133 (2.1418) teacher_loss 1.1113 (0.8677) loss_zs_kd 0.7653 (0.9514) loss_oracle 0.8630 (0.8630) acc 62.5000 (69.5089) kd_loss 0.8706 (0.8427) lr 4.8943e-05 eta 0:02:18
epoch [47/50] batch [300/319] time 0.140 (0.139) data 0.000 (0.002) loss 2.0204 (2.1434) teacher_loss 0.6754 (0.8696) loss_zs_kd 0.8985 (0.9518) loss_oracle 0.8631 (0.8630) acc 78.1250 (69.4896) kd_loss 0.9135 (0.8423) lr 4.8943e-05 eta 0:02:15
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,861
* accuracy: 65.3%
* error: 34.7%
* macro_f1: 57.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,082
* accuracy: 52.2%
* error: 47.8%
* macro_f1: 22.7%
******* Domain 2 best val acc:      65.5%, epoch: 45 *******
******* Domain 2 best val test acc: 52.5%, epoch: 45 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [48/50] batch [20/319] time 0.089 (0.170) data 0.000 (0.025) loss 2.0816 (2.1980) teacher_loss 0.9374 (0.9417) loss_zs_kd 0.7683 (0.9395) loss_oracle 0.8630 (0.8630) acc 68.7500 (67.0312) kd_loss 0.7126 (0.8248) lr 3.1417e-05 eta 0:02:38
epoch [48/50] batch [40/319] time 0.134 (0.143) data 0.001 (0.013) loss 1.9402 (2.1810) teacher_loss 0.7188 (0.9147) loss_zs_kd 0.9127 (0.9479) loss_oracle 0.8630 (0.8630) acc 75.0000 (67.7344) kd_loss 0.7899 (0.8348) lr 3.1417e-05 eta 0:02:11
epoch [48/50] batch [60/319] time 0.137 (0.133) data 0.001 (0.009) loss 2.1993 (2.1694) teacher_loss 0.9475 (0.9008) loss_zs_kd 0.6999 (0.9485) loss_oracle 0.8630 (0.8630) acc 75.0000 (68.5417) kd_loss 0.8203 (0.8371) lr 3.1417e-05 eta 0:01:59
epoch [48/50] batch [80/319] time 0.216 (0.128) data 0.000 (0.007) loss 2.0948 (2.1472) teacher_loss 0.8753 (0.8756) loss_zs_kd 0.8648 (0.9531) loss_oracle 0.8630 (0.8630) acc 75.0000 (69.5703) kd_loss 0.7880 (0.8401) lr 3.1417e-05 eta 0:01:52
epoch [48/50] batch [100/319] time 0.070 (0.132) data 0.000 (0.005) loss 2.1535 (2.1424) teacher_loss 0.8186 (0.8703) loss_zs_kd 0.8331 (0.9571) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.5000) kd_loss 0.9034 (0.8406) lr 3.1417e-05 eta 0:01:53
epoch [48/50] batch [120/319] time 0.189 (0.140) data 0.000 (0.004) loss 2.2377 (2.1379) teacher_loss 0.9216 (0.8633) loss_zs_kd 0.8247 (0.9544) loss_oracle 0.8630 (0.8630) acc 65.6250 (69.8177) kd_loss 0.8846 (0.8432) lr 3.1417e-05 eta 0:01:57
epoch [48/50] batch [140/319] time 0.087 (0.136) data 0.000 (0.004) loss 2.2529 (2.1397) teacher_loss 0.9405 (0.8627) loss_zs_kd 0.8781 (0.9554) loss_oracle 0.8630 (0.8630) acc 71.8750 (70.0223) kd_loss 0.8809 (0.8456) lr 3.1417e-05 eta 0:01:51
epoch [48/50] batch [160/319] time 0.108 (0.132) data 0.000 (0.003) loss 1.9006 (2.1348) teacher_loss 0.6298 (0.8576) loss_zs_kd 1.1613 (0.9521) loss_oracle 0.8631 (0.8630) acc 84.3750 (70.3906) kd_loss 0.8393 (0.8457) lr 3.1417e-05 eta 0:01:45
epoch [48/50] batch [180/319] time 0.098 (0.130) data 0.000 (0.003) loss 2.1345 (2.1387) teacher_loss 0.8999 (0.8627) loss_zs_kd 1.0123 (0.9478) loss_oracle 0.8630 (0.8630) acc 68.7500 (70.1389) kd_loss 0.8031 (0.8446) lr 3.1417e-05 eta 0:01:41
epoch [48/50] batch [200/319] time 0.092 (0.130) data 0.000 (0.003) loss 2.4289 (2.1457) teacher_loss 1.1514 (0.8688) loss_zs_kd 0.8192 (0.9525) loss_oracle 0.8629 (0.8630) acc 62.5000 (69.8281) kd_loss 0.8460 (0.8455) lr 3.1417e-05 eta 0:01:38
epoch [48/50] batch [220/319] time 0.116 (0.128) data 0.000 (0.003) loss 2.0053 (2.1456) teacher_loss 0.7665 (0.8685) loss_zs_kd 0.7925 (0.9520) loss_oracle 0.8629 (0.8630) acc 78.1250 (69.8295) kd_loss 0.8074 (0.8456) lr 3.1417e-05 eta 0:01:34
epoch [48/50] batch [240/319] time 0.143 (0.128) data 0.000 (0.002) loss 2.3621 (2.1495) teacher_loss 1.1222 (0.8725) loss_zs_kd 0.9773 (0.9503) loss_oracle 0.8630 (0.8630) acc 65.6250 (69.6615) kd_loss 0.8084 (0.8455) lr 3.1417e-05 eta 0:01:31
epoch [48/50] batch [260/319] time 0.106 (0.125) data 0.000 (0.002) loss 2.3490 (2.1468) teacher_loss 1.0367 (0.8689) loss_zs_kd 1.2414 (0.9528) loss_oracle 0.8630 (0.8630) acc 62.5000 (69.6514) kd_loss 0.8808 (0.8464) lr 3.1417e-05 eta 0:01:27
epoch [48/50] batch [280/319] time 0.079 (0.124) data 0.000 (0.002) loss 2.4718 (2.1428) teacher_loss 1.2690 (0.8662) loss_zs_kd 0.9982 (0.9485) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.9554) kd_loss 0.7713 (0.8451) lr 3.1417e-05 eta 0:01:24
epoch [48/50] batch [300/319] time 0.115 (0.123) data 0.000 (0.002) loss 2.1280 (2.1435) teacher_loss 0.8550 (0.8679) loss_zs_kd 0.9221 (0.9454) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.8646) kd_loss 0.8416 (0.8441) lr 3.1417e-05 eta 0:01:20
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,855
* accuracy: 65.2%
* error: 34.8%
* macro_f1: 57.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,084
* accuracy: 52.2%
* error: 47.8%
* macro_f1: 22.7%
******* Domain 2 best val acc:      65.5%, epoch: 45 *******
******* Domain 2 best val test acc: 52.5%, epoch: 45 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [49/50] batch [20/319] time 0.122 (0.180) data 0.000 (0.027) loss 2.0683 (2.0962) teacher_loss 0.7795 (0.8390) loss_zs_kd 0.9041 (0.9646) loss_oracle 0.8630 (0.8630) acc 75.0000 (71.5625) kd_loss 0.8573 (0.8257) lr 1.7713e-05 eta 0:01:51
epoch [49/50] batch [40/319] time 0.149 (0.150) data 0.000 (0.014) loss 2.3650 (2.1376) teacher_loss 1.1071 (0.8757) loss_zs_kd 0.9171 (0.9552) loss_oracle 0.8630 (0.8630) acc 62.5000 (70.0000) kd_loss 0.8264 (0.8305) lr 1.7713e-05 eta 0:01:29
epoch [49/50] batch [60/319] time 0.156 (0.151) data 0.000 (0.009) loss 1.9012 (2.1448) teacher_loss 0.6032 (0.8777) loss_zs_kd 0.7727 (0.9511) loss_oracle 0.8630 (0.8630) acc 75.0000 (70.1562) kd_loss 0.8666 (0.8356) lr 1.7713e-05 eta 0:01:27
epoch [49/50] batch [80/319] time 0.116 (0.146) data 0.000 (0.007) loss 2.2580 (2.1588) teacher_loss 0.9913 (0.8862) loss_zs_kd 1.0004 (0.9384) loss_oracle 0.8630 (0.8630) acc 65.6250 (69.8828) kd_loss 0.8352 (0.8411) lr 1.7713e-05 eta 0:01:21
epoch [49/50] batch [100/319] time 0.133 (0.139) data 0.000 (0.006) loss 2.0603 (2.1396) teacher_loss 0.8481 (0.8659) loss_zs_kd 1.1048 (0.9350) loss_oracle 0.8630 (0.8630) acc 65.6250 (70.2500) kd_loss 0.7807 (0.8422) lr 1.7713e-05 eta 0:01:14
epoch [49/50] batch [120/319] time 0.143 (0.134) data 0.000 (0.005) loss 1.9193 (2.1530) teacher_loss 0.6409 (0.8775) loss_zs_kd 1.0618 (0.9334) loss_oracle 0.8630 (0.8630) acc 75.0000 (69.6094) kd_loss 0.8469 (0.8440) lr 1.7713e-05 eta 0:01:09
epoch [49/50] batch [140/319] time 0.117 (0.131) data 0.000 (0.004) loss 2.0272 (2.1479) teacher_loss 0.7482 (0.8731) loss_zs_kd 0.8439 (0.9374) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.8214) kd_loss 0.8474 (0.8433) lr 1.7713e-05 eta 0:01:05
epoch [49/50] batch [160/319] time 0.135 (0.128) data 0.000 (0.004) loss 1.8434 (2.1487) teacher_loss 0.5859 (0.8752) loss_zs_kd 0.8758 (0.9415) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.4141) kd_loss 0.8261 (0.8419) lr 1.7713e-05 eta 0:01:01
epoch [49/50] batch [180/319] time 0.097 (0.126) data 0.000 (0.003) loss 2.1565 (2.1590) teacher_loss 0.8355 (0.8860) loss_zs_kd 0.8144 (0.9428) loss_oracle 0.8630 (0.8630) acc 71.8750 (68.9236) kd_loss 0.8896 (0.8416) lr 1.7713e-05 eta 0:00:57
epoch [49/50] batch [200/319] time 0.100 (0.124) data 0.000 (0.003) loss 2.0185 (2.1604) teacher_loss 0.6863 (0.8884) loss_zs_kd 1.0759 (0.9463) loss_oracle 0.8630 (0.8630) acc 75.0000 (68.8750) kd_loss 0.9008 (0.8405) lr 1.7713e-05 eta 0:00:54
epoch [49/50] batch [220/319] time 0.145 (0.122) data 0.000 (0.003) loss 2.2862 (2.1594) teacher_loss 1.0035 (0.8866) loss_zs_kd 0.9120 (0.9470) loss_oracle 0.8629 (0.8630) acc 53.1250 (68.9062) kd_loss 0.8513 (0.8413) lr 1.7713e-05 eta 0:00:51
epoch [49/50] batch [240/319] time 0.139 (0.122) data 0.000 (0.002) loss 2.0553 (2.1648) teacher_loss 0.7899 (0.8910) loss_zs_kd 1.0198 (0.9489) loss_oracle 0.8629 (0.8630) acc 59.3750 (68.8281) kd_loss 0.8339 (0.8423) lr 1.7713e-05 eta 0:00:48
epoch [49/50] batch [260/319] time 0.132 (0.120) data 0.000 (0.002) loss 2.0320 (2.1630) teacher_loss 0.7806 (0.8889) loss_zs_kd 0.9876 (0.9477) loss_oracle 0.8630 (0.8630) acc 75.0000 (68.9784) kd_loss 0.8200 (0.8427) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [280/319] time 0.144 (0.120) data 0.000 (0.002) loss 1.9028 (2.1631) teacher_loss 0.5350 (0.8892) loss_zs_kd 0.9182 (0.9464) loss_oracle 0.8630 (0.8630) acc 84.3750 (68.9509) kd_loss 0.9363 (0.8424) lr 1.7713e-05 eta 0:00:42
epoch [49/50] batch [300/319] time 0.156 (0.121) data 0.000 (0.002) loss 2.0061 (2.1551) teacher_loss 0.7705 (0.8812) loss_zs_kd 1.0495 (0.9497) loss_oracle 0.8630 (0.8630) acc 71.8750 (69.3646) kd_loss 0.8041 (0.8425) lr 1.7713e-05 eta 0:00:41
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,858
* accuracy: 65.3%
* error: 34.7%
* macro_f1: 57.3%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,086
* accuracy: 52.2%
* error: 47.8%
* macro_f1: 22.6%
******* Domain 2 best val acc:      65.5%, epoch: 45 *******
******* Domain 2 best val test acc: 52.5%, epoch: 45 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
epoch [50/50] batch [20/319] time 0.100 (0.139) data 0.000 (0.023) loss 1.9329 (2.2124) teacher_loss 0.6190 (0.9300) loss_zs_kd 0.9499 (0.9456) loss_oracle 0.8630 (0.8630) acc 75.0000 (66.5625) kd_loss 0.8824 (0.8509) lr 7.8853e-06 eta 0:00:41
epoch [50/50] batch [40/319] time 0.102 (0.124) data 0.000 (0.012) loss 2.2325 (2.1718) teacher_loss 0.9544 (0.8991) loss_zs_kd 1.3246 (0.9480) loss_oracle 0.8630 (0.8630) acc 62.5000 (67.8906) kd_loss 0.8466 (0.8411) lr 7.8853e-06 eta 0:00:34
epoch [50/50] batch [60/319] time 0.100 (0.113) data 0.000 (0.008) loss 2.0948 (2.1734) teacher_loss 0.8480 (0.8958) loss_zs_kd 0.9298 (0.9531) loss_oracle 0.8629 (0.8630) acc 71.8750 (67.9688) kd_loss 0.8154 (0.8461) lr 7.8853e-06 eta 0:00:29
epoch [50/50] batch [80/319] time 0.076 (0.108) data 0.000 (0.006) loss 2.0065 (2.1578) teacher_loss 0.7465 (0.8770) loss_zs_kd 0.7929 (0.9464) loss_oracle 0.8630 (0.8630) acc 75.0000 (69.2188) kd_loss 0.8284 (0.8493) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [100/319] time 0.128 (0.106) data 0.000 (0.005) loss 2.3672 (2.1678) teacher_loss 1.0522 (0.8898) loss_zs_kd 0.8336 (0.9414) loss_oracle 0.8630 (0.8630) acc 68.7500 (68.9375) kd_loss 0.8835 (0.8466) lr 7.8853e-06 eta 0:00:23
epoch [50/50] batch [120/319] time 0.138 (0.105) data 0.000 (0.004) loss 2.2452 (2.1601) teacher_loss 0.9912 (0.8832) loss_zs_kd 0.7456 (0.9346) loss_oracle 0.8629 (0.8630) acc 59.3750 (69.1667) kd_loss 0.8226 (0.8454) lr 7.8853e-06 eta 0:00:20
epoch [50/50] batch [140/319] time 0.082 (0.105) data 0.000 (0.003) loss 2.0354 (2.1590) teacher_loss 0.6719 (0.8804) loss_zs_kd 0.9461 (0.9356) loss_oracle 0.8630 (0.8630) acc 81.2500 (69.1518) kd_loss 0.9321 (0.8471) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [160/319] time 0.112 (0.105) data 0.000 (0.003) loss 2.1997 (2.1643) teacher_loss 0.9508 (0.8876) loss_zs_kd 0.7837 (0.9423) loss_oracle 0.8630 (0.8630) acc 65.6250 (68.6914) kd_loss 0.8174 (0.8452) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [180/319] time 0.089 (0.107) data 0.000 (0.003) loss 2.0517 (2.1619) teacher_loss 0.7262 (0.8849) loss_zs_kd 1.1514 (0.9454) loss_oracle 0.8631 (0.8630) acc 75.0000 (68.9583) kd_loss 0.8939 (0.8456) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [200/319] time 0.094 (0.107) data 0.000 (0.002) loss 2.0345 (2.1664) teacher_loss 0.7673 (0.8882) loss_zs_kd 0.9540 (0.9463) loss_oracle 0.8630 (0.8630) acc 75.0000 (68.9219) kd_loss 0.8357 (0.8466) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [220/319] time 0.100 (0.109) data 0.000 (0.002) loss 2.0570 (2.1602) teacher_loss 0.8157 (0.8834) loss_zs_kd 0.9913 (0.9470) loss_oracle 0.8630 (0.8630) acc 68.7500 (69.1903) kd_loss 0.8097 (0.8453) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [240/319] time 0.084 (0.109) data 0.000 (0.002) loss 2.2964 (2.1517) teacher_loss 0.9436 (0.8756) loss_zs_kd 0.7358 (0.9434) loss_oracle 0.8629 (0.8630) acc 65.6250 (69.2969) kd_loss 0.9214 (0.8446) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [260/319] time 0.085 (0.109) data 0.000 (0.002) loss 1.9649 (2.1542) teacher_loss 0.6861 (0.8785) loss_zs_kd 1.0644 (0.9445) loss_oracle 0.8630 (0.8630) acc 75.0000 (69.1707) kd_loss 0.8473 (0.8442) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [280/319] time 0.074 (0.108) data 0.000 (0.002) loss 2.8065 (2.1512) teacher_loss 1.4936 (0.8761) loss_zs_kd 0.8484 (0.9427) loss_oracle 0.8630 (0.8630) acc 53.1250 (69.2634) kd_loss 0.8815 (0.8436) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [300/319] time 0.189 (0.111) data 0.000 (0.002) loss 2.1621 (2.1464) teacher_loss 0.9190 (0.8710) loss_zs_kd 1.0599 (0.9431) loss_oracle 0.8631 (0.8630) acc 65.6250 (69.4688) kd_loss 0.8115 (0.8439) lr 7.8853e-06 eta 0:00:02
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,858
* accuracy: 65.3%
* error: 34.7%
* macro_f1: 57.3%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,094
* accuracy: 52.3%
* error: 47.7%
* macro_f1: 22.6%
******* Domain 2 best val acc:      65.5%, epoch: 45 *******
******* Domain 2 best val test acc: 52.5%, epoch: 45 *******
******* Domain 2 best test acc:     56.8%, epoch: 29 *******
Checkpoint saved to icml/multi-dg/oracle/09_seperate_nontocorrect/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:46:19

Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------------
Dataset    SPG_OfficeHome
Source     ['clipart', 'product', 'real_world']
Target     ['art']
# classes  65
# train_x  9,222
# val      3,939
# test     2,427
---------  ------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/288] time 0.122 (0.170) data 0.001 (0.024) loss 1.1131 (1.2412) ce_loss 1.1104 (1.2377) teacher_loss 1.1106 (1.2380) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0024 (0.0032) acc 71.8750 (68.5938) kd_loss 0.0098 (0.0128) lr 1.0000e-05 eta 0:40:49
epoch [1/50] batch [40/288] time 0.124 (0.145) data 0.001 (0.012) loss 1.2211 (1.2627) ce_loss 1.2178 (1.2591) teacher_loss 1.2169 (1.2594) loss_zs_kd 0.0002 (0.0000) loss_oracle 0.0041 (0.0032) acc 65.6250 (68.3594) kd_loss 0.0168 (0.0129) lr 1.0000e-05 eta 0:34:40
epoch [1/50] batch [60/288] time 0.121 (0.135) data 0.001 (0.008) loss 1.4317 (1.2693) ce_loss 1.4297 (1.2662) teacher_loss 1.4293 (1.2662) loss_zs_kd 0.0006 (0.0001) loss_oracle 0.0021 (0.0031) acc 59.3750 (67.7083) kd_loss 0.0076 (0.0122) lr 1.0000e-05 eta 0:32:15
epoch [1/50] batch [80/288] time 0.113 (0.128) data 0.000 (0.006) loss 1.2609 (1.2732) ce_loss 1.2568 (1.2702) teacher_loss 1.2564 (1.2702) loss_zs_kd 0.0008 (0.0002) loss_oracle 0.0040 (0.0029) acc 62.5000 (67.5000) kd_loss 0.0158 (0.0115) lr 1.0000e-05 eta 0:30:37
epoch [1/50] batch [100/288] time 0.108 (0.124) data 0.001 (0.005) loss 1.0931 (1.2453) ce_loss 1.0908 (1.2426) teacher_loss 1.0902 (1.2425) loss_zs_kd 0.0006 (0.0003) loss_oracle 0.0027 (0.0027) acc 62.5000 (68.1875) kd_loss 0.0101 (0.0106) lr 1.0000e-05 eta 0:29:35
epoch [1/50] batch [120/288] time 0.099 (0.121) data 0.000 (0.004) loss 1.0351 (1.2390) ce_loss 1.0352 (1.2365) teacher_loss 1.0328 (1.2363) loss_zs_kd 0.0007 (0.0004) loss_oracle 0.0020 (0.0025) acc 75.0000 (68.2292) kd_loss 0.0066 (0.0097) lr 1.0000e-05 eta 0:28:47
epoch [1/50] batch [140/288] time 0.109 (0.119) data 0.000 (0.004) loss 1.4882 (1.2250) ce_loss 1.4883 (1.2225) teacher_loss 1.4858 (1.2224) loss_zs_kd 0.0010 (0.0005) loss_oracle 0.0019 (0.0023) acc 56.2500 (68.3259) kd_loss 0.0050 (0.0090) lr 1.0000e-05 eta 0:28:17
epoch [1/50] batch [160/288] time 0.099 (0.117) data 0.000 (0.003) loss 1.0588 (1.2224) ce_loss 1.0557 (1.2201) teacher_loss 1.0571 (1.2199) loss_zs_kd 0.0019 (0.0006) loss_oracle 0.0008 (0.0022) acc 71.8750 (68.6523) kd_loss 0.0024 (0.0084) lr 1.0000e-05 eta 0:27:46
epoch [1/50] batch [180/288] time 0.109 (0.116) data 0.000 (0.003) loss 0.9960 (1.2259) ce_loss 0.9927 (1.2236) teacher_loss 0.9940 (1.2234) loss_zs_kd 0.0023 (0.0007) loss_oracle 0.0009 (0.0021) acc 71.8750 (68.4549) kd_loss 0.0026 (0.0079) lr 1.0000e-05 eta 0:27:22
epoch [1/50] batch [200/288] time 0.099 (0.115) data 0.000 (0.003) loss 1.3383 (1.2226) ce_loss 1.3359 (1.2203) teacher_loss 1.3366 (1.2202) loss_zs_kd 0.0019 (0.0008) loss_oracle 0.0007 (0.0020) acc 62.5000 (68.3438) kd_loss 0.0027 (0.0075) lr 1.0000e-05 eta 0:27:07
epoch [1/50] batch [220/288] time 0.107 (0.114) data 0.000 (0.003) loss 1.4186 (1.2183) ce_loss 1.4170 (1.2160) teacher_loss 1.4166 (1.2159) loss_zs_kd 0.0022 (0.0010) loss_oracle 0.0010 (0.0019) acc 65.6250 (68.6080) kd_loss 0.0028 (0.0070) lr 1.0000e-05 eta 0:26:53
epoch [1/50] batch [240/288] time 0.104 (0.113) data 0.000 (0.002) loss 0.9870 (1.2159) ce_loss 0.9849 (1.2136) teacher_loss 0.9854 (1.2135) loss_zs_kd 0.0010 (0.0011) loss_oracle 0.0011 (0.0018) acc 81.2500 (68.8672) kd_loss 0.0038 (0.0067) lr 1.0000e-05 eta 0:26:45
epoch [1/50] batch [260/288] time 0.101 (0.113) data 0.000 (0.002) loss 1.3075 (1.2215) ce_loss 1.3037 (1.2192) teacher_loss 1.3039 (1.2191) loss_zs_kd 0.0053 (0.0012) loss_oracle 0.0009 (0.0018) acc 71.8750 (68.7139) kd_loss 0.0023 (0.0064) lr 1.0000e-05 eta 0:26:34
epoch [1/50] batch [280/288] time 0.107 (0.112) data 0.000 (0.002) loss 1.5232 (1.2214) ce_loss 1.5205 (1.2191) teacher_loss 1.5197 (1.2190) loss_zs_kd 0.0051 (0.0014) loss_oracle 0.0009 (0.0017) acc 62.5000 (68.7612) kd_loss 0.0027 (0.0061) lr 1.0000e-05 eta 0:26:23
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,267
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 82.0%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,966
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 76.8%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      82.9%, epoch: 1 *******
******* Domain a best val test acc: 81.0%, epoch: 1 *******
******* Domain a best test acc:     81.0%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/ana
epoch [2/50] batch [20/288] time 0.110 (0.118) data 0.000 (0.014) loss 1.1004 (1.2416) ce_loss 1.0439 (1.1907) teacher_loss 1.0466 (1.1914) loss_zs_kd 0.0995 (0.0957) loss_oracle 0.0041 (0.0024) acc 65.6250 (68.5938) kd_loss 0.0024 (0.0020) lr 2.0000e-03 eta 0:27:42
epoch [2/50] batch [40/288] time 0.108 (0.112) data 0.000 (0.007) loss 0.7524 (1.1862) ce_loss 0.6978 (1.1242) teacher_loss 0.6992 (1.1259) loss_zs_kd 0.0873 (0.1099) loss_oracle 0.0096 (0.0054) acc 81.2500 (70.0781) kd_loss 0.0014 (0.0019) lr 2.0000e-03 eta 0:26:16
epoch [2/50] batch [60/288] time 0.106 (0.109) data 0.000 (0.005) loss 1.3701 (1.1893) ce_loss 1.3125 (1.1277) teacher_loss 1.3139 (1.1295) loss_zs_kd 0.0952 (0.1077) loss_oracle 0.0087 (0.0060) acc 68.7500 (70.4688) kd_loss 0.0034 (0.0022) lr 2.0000e-03 eta 0:25:38
epoch [2/50] batch [80/288] time 0.110 (0.108) data 0.000 (0.004) loss 0.8990 (1.1741) ce_loss 0.8481 (1.1137) teacher_loss 0.8507 (1.1155) loss_zs_kd 0.0830 (0.1035) loss_oracle 0.0068 (0.0069) acc 71.8750 (71.1328) kd_loss 0.0026 (0.0024) lr 2.0000e-03 eta 0:25:20
epoch [2/50] batch [100/288] time 0.093 (0.107) data 0.000 (0.003) loss 1.5397 (1.1725) ce_loss 1.4941 (1.1131) teacher_loss 1.4958 (1.1148) loss_zs_kd 0.0759 (0.1019) loss_oracle 0.0060 (0.0068) acc 59.3750 (71.1562) kd_loss 0.0030 (0.0025) lr 2.0000e-03 eta 0:24:54
epoch [2/50] batch [120/288] time 0.095 (0.105) data 0.000 (0.003) loss 1.1599 (1.1680) ce_loss 1.1221 (1.1089) teacher_loss 1.1239 (1.1105) loss_zs_kd 0.0606 (0.1015) loss_oracle 0.0057 (0.0067) acc 71.8750 (71.0417) kd_loss 0.0026 (0.0026) lr 2.0000e-03 eta 0:24:33
epoch [2/50] batch [140/288] time 0.114 (0.105) data 0.000 (0.002) loss 1.2990 (1.1709) ce_loss 1.2178 (1.1125) teacher_loss 1.2209 (1.1141) loss_zs_kd 0.1323 (0.0995) loss_oracle 0.0119 (0.0070) acc 68.7500 (70.8929) kd_loss 0.0043 (0.0027) lr 2.0000e-03 eta 0:24:27
epoch [2/50] batch [160/288] time 0.102 (0.106) data 0.001 (0.002) loss 1.1931 (1.1711) ce_loss 1.1074 (1.1126) teacher_loss 1.1083 (1.1143) loss_zs_kd 0.1569 (0.0987) loss_oracle 0.0064 (0.0075) acc 68.7500 (70.7812) kd_loss 0.0039 (0.0029) lr 2.0000e-03 eta 0:24:36
epoch [2/50] batch [180/288] time 0.089 (0.105) data 0.000 (0.002) loss 1.0653 (1.1657) ce_loss 1.0000 (1.1070) teacher_loss 1.0041 (1.1087) loss_zs_kd 0.1073 (0.0990) loss_oracle 0.0076 (0.0075) acc 78.1250 (70.9201) kd_loss 0.0046 (0.0030) lr 2.0000e-03 eta 0:24:22
epoch [2/50] batch [200/288] time 0.103 (0.104) data 0.000 (0.002) loss 1.8191 (1.1684) ce_loss 1.7197 (1.1082) teacher_loss 1.7224 (1.1098) loss_zs_kd 0.1647 (0.1019) loss_oracle 0.0144 (0.0076) acc 59.3750 (70.8125) kd_loss 0.0072 (0.0032) lr 2.0000e-03 eta 0:24:10
epoch [2/50] batch [220/288] time 0.088 (0.103) data 0.000 (0.001) loss 1.2065 (1.1579) ce_loss 1.1338 (1.0970) teacher_loss 1.1352 (1.0986) loss_zs_kd 0.1174 (0.1026) loss_oracle 0.0125 (0.0081) acc 71.8750 (71.0938) kd_loss 0.0050 (0.0034) lr 2.0000e-03 eta 0:23:54
epoch [2/50] batch [240/288] time 0.100 (0.103) data 0.000 (0.001) loss 1.4501 (1.1539) ce_loss 1.3936 (1.0929) teacher_loss 1.3947 (1.0944) loss_zs_kd 0.0919 (0.1024) loss_oracle 0.0095 (0.0082) acc 65.6250 (71.1458) kd_loss 0.0052 (0.0036) lr 2.0000e-03 eta 0:23:45
epoch [2/50] batch [260/288] time 0.103 (0.103) data 0.000 (0.001) loss 1.1758 (1.1502) ce_loss 1.0586 (1.0885) teacher_loss 1.0595 (1.0900) loss_zs_kd 0.1888 (0.1028) loss_oracle 0.0219 (0.0088) acc 78.1250 (71.2260) kd_loss 0.0065 (0.0038) lr 2.0000e-03 eta 0:23:43
epoch [2/50] batch [280/288] time 0.105 (0.103) data 0.000 (0.001) loss 0.8735 (1.1464) ce_loss 0.8032 (1.0840) teacher_loss 0.8023 (1.0856) loss_zs_kd 0.1140 (0.1032) loss_oracle 0.0143 (0.0092) acc 75.0000 (71.2946) kd_loss 0.0064 (0.0040) lr 2.0000e-03 eta 0:23:44
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,381
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 85.2%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.5%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      85.8%, epoch: 2 *******
******* Domain a best val test acc: 83.2%, epoch: 2 *******
******* Domain a best test acc:     83.2%, epoch: 2 *******
epoch [3/50] batch [20/288] time 0.107 (0.125) data 0.000 (0.018) loss 1.5637 (1.1552) ce_loss 1.4824 (1.0777) teacher_loss 1.4835 (1.0789) loss_zs_kd 0.1294 (0.1159) loss_oracle 0.0154 (0.0184) acc 53.1250 (71.2500) kd_loss 0.0075 (0.0071) lr 1.9980e-03 eta 0:28:45
epoch [3/50] batch [40/288] time 0.105 (0.116) data 0.002 (0.009) loss 0.9294 (1.0842) ce_loss 0.8677 (1.0031) teacher_loss 0.8708 (1.0051) loss_zs_kd 0.0680 (0.1073) loss_oracle 0.0246 (0.0255) acc 78.1250 (73.3594) kd_loss 0.0111 (0.0078) lr 1.9980e-03 eta 0:26:39
epoch [3/50] batch [60/288] time 0.102 (0.112) data 0.000 (0.006) loss 0.9971 (1.1314) ce_loss 0.9263 (1.0502) teacher_loss 0.9261 (1.0518) loss_zs_kd 0.0875 (0.1078) loss_oracle 0.0273 (0.0257) acc 75.0000 (72.1875) kd_loss 0.0145 (0.0088) lr 1.9980e-03 eta 0:25:43
epoch [3/50] batch [80/288] time 0.102 (0.110) data 0.000 (0.005) loss 1.1150 (1.1359) ce_loss 1.0166 (1.0514) teacher_loss 1.0180 (1.0533) loss_zs_kd 0.1032 (0.1084) loss_oracle 0.0454 (0.0284) acc 71.8750 (71.9141) kd_loss 0.0127 (0.0096) lr 1.9980e-03 eta 0:25:05
epoch [3/50] batch [100/288] time 0.099 (0.108) data 0.001 (0.004) loss 1.0553 (1.1512) ce_loss 0.9468 (1.0629) teacher_loss 0.9430 (1.0645) loss_zs_kd 0.0864 (0.1079) loss_oracle 0.0691 (0.0327) acc 75.0000 (71.7188) kd_loss 0.0208 (0.0111) lr 1.9980e-03 eta 0:24:40
epoch [3/50] batch [120/288] time 0.110 (0.107) data 0.000 (0.003) loss 0.8333 (1.1490) ce_loss 0.6826 (1.0510) teacher_loss 0.6849 (1.0524) loss_zs_kd 0.1217 (0.1120) loss_oracle 0.0875 (0.0407) acc 81.2500 (72.1615) kd_loss 0.0262 (0.0134) lr 1.9980e-03 eta 0:24:29
epoch [3/50] batch [140/288] time 0.102 (0.107) data 0.000 (0.003) loss 1.0878 (1.1490) ce_loss 0.9932 (1.0469) teacher_loss 0.9905 (1.0480) loss_zs_kd 0.0712 (0.1120) loss_oracle 0.0617 (0.0450) acc 75.0000 (72.0759) kd_loss 0.0326 (0.0161) lr 1.9980e-03 eta 0:24:21
epoch [3/50] batch [160/288] time 0.102 (0.106) data 0.000 (0.003) loss 1.6668 (1.1538) ce_loss 1.5479 (1.0513) teacher_loss 1.5470 (1.0525) loss_zs_kd 0.1367 (0.1136) loss_oracle 0.0514 (0.0445) acc 59.3750 (71.8945) kd_loss 0.0410 (0.0182) lr 1.9980e-03 eta 0:24:09
epoch [3/50] batch [180/288] time 0.103 (0.106) data 0.000 (0.002) loss 1.2296 (1.1532) ce_loss 1.1182 (1.0515) teacher_loss 1.1220 (1.0527) loss_zs_kd 0.1110 (0.1125) loss_oracle 0.0521 (0.0443) acc 71.8750 (71.9444) kd_loss 0.0332 (0.0196) lr 1.9980e-03 eta 0:24:02
epoch [3/50] batch [200/288] time 0.102 (0.105) data 0.000 (0.002) loss 1.1568 (1.1528) ce_loss 1.0215 (1.0492) teacher_loss 1.0240 (1.0501) loss_zs_kd 0.0920 (0.1125) loss_oracle 0.0868 (0.0465) acc 75.0000 (72.1094) kd_loss 0.0435 (0.0211) lr 1.9980e-03 eta 0:23:56
epoch [3/50] batch [220/288] time 0.102 (0.105) data 0.000 (0.002) loss 0.9268 (1.1661) ce_loss 0.8247 (1.0589) teacher_loss 0.8305 (1.0597) loss_zs_kd 0.1139 (0.1145) loss_oracle 0.0394 (0.0492) acc 75.0000 (71.8892) kd_loss 0.0330 (0.0230) lr 1.9980e-03 eta 0:23:52
epoch [3/50] batch [240/288] time 0.103 (0.105) data 0.000 (0.002) loss 1.4231 (1.1706) ce_loss 1.3037 (1.0627) teacher_loss 1.3064 (1.0635) loss_zs_kd 0.0846 (0.1141) loss_oracle 0.0744 (0.0502) acc 65.6250 (71.8620) kd_loss 0.0500 (0.0245) lr 1.9980e-03 eta 0:23:49
epoch [3/50] batch [260/288] time 0.102 (0.105) data 0.000 (0.002) loss 0.7825 (1.1659) ce_loss 0.6553 (1.0579) teacher_loss 0.6405 (1.0585) loss_zs_kd 0.1118 (0.1137) loss_oracle 0.0860 (0.0506) acc 87.5000 (71.9952) kd_loss 0.0465 (0.0258) lr 1.9980e-03 eta 0:23:49
epoch [3/50] batch [280/288] time 0.107 (0.105) data 0.000 (0.002) loss 1.2927 (1.1655) ce_loss 1.0967 (1.0540) teacher_loss 1.0887 (1.0545) loss_zs_kd 0.1961 (0.1149) loss_oracle 0.1059 (0.0535) acc 68.7500 (72.1205) kd_loss 0.0590 (0.0272) lr 1.9980e-03 eta 0:23:46
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,386
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 85.2%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,014
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 79.5%
******* Domain a best val acc:      86.0%, epoch: 3 *******
******* Domain a best val test acc: 83.0%, epoch: 3 *******
******* Domain a best test acc:     83.2%, epoch: 2 *******
epoch [4/50] batch [20/288] time 0.094 (0.113) data 0.000 (0.013) loss 0.9764 (1.1099) ce_loss 0.8696 (0.9846) teacher_loss 0.8651 (0.9812) loss_zs_kd 0.0864 (0.1092) loss_oracle 0.0682 (0.0741) acc 84.3750 (73.5938) kd_loss 0.0366 (0.0455) lr 1.9921e-03 eta 0:25:23
epoch [4/50] batch [40/288] time 0.106 (0.105) data 0.000 (0.007) loss 1.2493 (1.1254) ce_loss 1.1113 (1.0003) teacher_loss 1.1033 (0.9993) loss_zs_kd 0.1912 (0.1135) loss_oracle 0.0505 (0.0695) acc 68.7500 (73.4375) kd_loss 0.0435 (0.0438) lr 1.9921e-03 eta 0:23:36
epoch [4/50] batch [60/288] time 0.104 (0.105) data 0.001 (0.005) loss 1.2686 (1.1090) ce_loss 1.1865 (0.9922) teacher_loss 1.1923 (0.9919) loss_zs_kd 0.0899 (0.1116) loss_oracle 0.0313 (0.0613) acc 68.7500 (73.5938) kd_loss 0.0232 (0.0421) lr 1.9921e-03 eta 0:23:34
epoch [4/50] batch [80/288] time 0.102 (0.104) data 0.000 (0.003) loss 1.5345 (1.1256) ce_loss 1.4326 (1.0124) teacher_loss 1.4340 (1.0123) loss_zs_kd 0.0979 (0.1097) loss_oracle 0.0515 (0.0585) acc 65.6250 (73.3594) kd_loss 0.0346 (0.0409) lr 1.9921e-03 eta 0:23:14
epoch [4/50] batch [100/288] time 0.116 (0.104) data 0.000 (0.003) loss 1.0437 (1.1438) ce_loss 0.9453 (1.0339) teacher_loss 0.9417 (1.0337) loss_zs_kd 0.0845 (0.1065) loss_oracle 0.0598 (0.0569) acc 78.1250 (72.7500) kd_loss 0.0365 (0.0394) lr 1.9921e-03 eta 0:23:18
epoch [4/50] batch [120/288] time 0.099 (0.104) data 0.001 (0.002) loss 1.0588 (1.1519) ce_loss 0.9341 (1.0425) teacher_loss 0.9395 (1.0421) loss_zs_kd 0.1095 (0.1056) loss_oracle 0.0646 (0.0570) acc 78.1250 (72.5260) kd_loss 0.0295 (0.0384) lr 1.9921e-03 eta 0:23:14
epoch [4/50] batch [140/288] time 0.103 (0.104) data 0.000 (0.002) loss 0.8953 (1.1594) ce_loss 0.8096 (1.0490) teacher_loss 0.8109 (1.0486) loss_zs_kd 0.0948 (0.1067) loss_oracle 0.0370 (0.0574) acc 81.2500 (72.2768) kd_loss 0.0298 (0.0381) lr 1.9921e-03 eta 0:23:12
epoch [4/50] batch [160/288] time 0.092 (0.104) data 0.000 (0.002) loss 1.3131 (1.1506) ce_loss 1.2246 (1.0420) teacher_loss 1.2203 (1.0413) loss_zs_kd 0.1138 (0.1087) loss_oracle 0.0359 (0.0549) acc 68.7500 (72.3633) kd_loss 0.0304 (0.0374) lr 1.9921e-03 eta 0:23:09
epoch [4/50] batch [180/288] time 0.108 (0.103) data 0.000 (0.002) loss 1.5060 (1.1468) ce_loss 1.3906 (1.0395) teacher_loss 1.3809 (1.0387) loss_zs_kd 0.1516 (0.1096) loss_oracle 0.0492 (0.0534) acc 62.5000 (72.3090) kd_loss 0.0250 (0.0365) lr 1.9921e-03 eta 0:23:00
epoch [4/50] batch [200/288] time 0.094 (0.103) data 0.000 (0.002) loss 1.2429 (1.1455) ce_loss 1.1357 (1.0366) teacher_loss 1.1320 (1.0358) loss_zs_kd 0.1096 (0.1123) loss_oracle 0.0561 (0.0535) acc 71.8750 (72.5469) kd_loss 0.0280 (0.0359) lr 1.9921e-03 eta 0:22:50
epoch [4/50] batch [220/288] time 0.101 (0.102) data 0.000 (0.001) loss 1.2872 (1.1481) ce_loss 1.1807 (1.0376) teacher_loss 1.1784 (1.0365) loss_zs_kd 0.0953 (0.1135) loss_oracle 0.0612 (0.0548) acc 71.8750 (72.4006) kd_loss 0.0348 (0.0358) lr 1.9921e-03 eta 0:22:41
epoch [4/50] batch [240/288] time 0.091 (0.102) data 0.000 (0.001) loss 1.3422 (1.1459) ce_loss 1.2188 (1.0352) teacher_loss 1.2079 (1.0343) loss_zs_kd 0.1185 (0.1131) loss_oracle 0.0751 (0.0551) acc 68.7500 (72.5521) kd_loss 0.0313 (0.0352) lr 1.9921e-03 eta 0:22:32
epoch [4/50] batch [260/288] time 0.099 (0.101) data 0.000 (0.001) loss 0.9578 (1.1520) ce_loss 0.8228 (1.0397) teacher_loss 0.8197 (1.0387) loss_zs_kd 0.1224 (0.1137) loss_oracle 0.0769 (0.0564) acc 71.8750 (72.4038) kd_loss 0.0415 (0.0352) lr 1.9921e-03 eta 0:22:26
epoch [4/50] batch [280/288] time 0.089 (0.101) data 0.000 (0.001) loss 0.8231 (1.1477) ce_loss 0.7188 (1.0350) teacher_loss 0.7238 (1.0340) loss_zs_kd 0.0950 (0.1129) loss_oracle 0.0518 (0.0572) acc 81.2500 (72.6339) kd_loss 0.0258 (0.0350) lr 1.9921e-03 eta 0:22:17
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,406
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 85.8%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 79.6%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.5%, epoch: 4 *******
******* Domain a best val test acc: 83.3%, epoch: 4 *******
******* Domain a best test acc:     83.3%, epoch: 4 *******
epoch [5/50] batch [20/288] time 0.102 (0.119) data 0.000 (0.014) loss 1.5428 (1.3121) ce_loss 1.4111 (1.1753) teacher_loss 1.4221 (1.1748) loss_zs_kd 0.1275 (0.1418) loss_oracle 0.0570 (0.0664) acc 71.8750 (70.4688) kd_loss 0.0342 (0.0376) lr 1.9823e-03 eta 0:26:18
epoch [5/50] batch [40/288] time 0.109 (0.111) data 0.000 (0.007) loss 0.6609 (1.2029) ce_loss 0.4993 (1.0687) teacher_loss 0.5029 (1.0669) loss_zs_kd 0.1739 (0.1340) loss_oracle 0.0710 (0.0690) acc 90.6250 (72.3438) kd_loss 0.0342 (0.0379) lr 1.9823e-03 eta 0:24:30
epoch [5/50] batch [60/288] time 0.099 (0.108) data 0.000 (0.005) loss 1.2859 (1.1692) ce_loss 1.1748 (1.0371) teacher_loss 1.1718 (1.0350) loss_zs_kd 0.0820 (0.1259) loss_oracle 0.0731 (0.0713) acc 62.5000 (73.1771) kd_loss 0.0430 (0.0382) lr 1.9823e-03 eta 0:23:50
epoch [5/50] batch [80/288] time 0.110 (0.108) data 0.000 (0.004) loss 1.5008 (1.1495) ce_loss 1.4062 (1.0189) teacher_loss 1.4017 (1.0159) loss_zs_kd 0.1060 (0.1268) loss_oracle 0.0461 (0.0702) acc 75.0000 (73.3203) kd_loss 0.0279 (0.0382) lr 1.9823e-03 eta 0:23:47
epoch [5/50] batch [100/288] time 0.101 (0.107) data 0.000 (0.003) loss 0.8037 (1.1570) ce_loss 0.6816 (1.0284) teacher_loss 0.6711 (1.0253) loss_zs_kd 0.1187 (0.1265) loss_oracle 0.0733 (0.0684) acc 81.2500 (73.1562) kd_loss 0.0355 (0.0380) lr 1.9823e-03 eta 0:23:32
epoch [5/50] batch [120/288] time 0.112 (0.107) data 0.001 (0.003) loss 1.1966 (1.1470) ce_loss 1.0420 (1.0199) teacher_loss 1.0345 (1.0166) loss_zs_kd 0.1478 (0.1233) loss_oracle 0.0882 (0.0687) acc 75.0000 (73.3333) kd_loss 0.0509 (0.0379) lr 1.9823e-03 eta 0:23:21
epoch [5/50] batch [140/288] time 0.101 (0.107) data 0.000 (0.002) loss 1.1722 (1.1472) ce_loss 1.0732 (1.0243) teacher_loss 1.0728 (1.0206) loss_zs_kd 0.1092 (0.1204) loss_oracle 0.0448 (0.0664) acc 65.6250 (73.3482) kd_loss 0.0353 (0.0371) lr 1.9823e-03 eta 0:23:18
epoch [5/50] batch [160/288] time 0.103 (0.106) data 0.000 (0.002) loss 1.3999 (1.1481) ce_loss 1.2891 (1.0275) teacher_loss 1.2839 (1.0238) loss_zs_kd 0.1070 (0.1196) loss_oracle 0.0626 (0.0645) acc 65.6250 (73.0469) kd_loss 0.0364 (0.0364) lr 1.9823e-03 eta 0:23:12
epoch [5/50] batch [180/288] time 0.097 (0.106) data 0.000 (0.002) loss 1.0686 (1.1527) ce_loss 0.9761 (1.0331) teacher_loss 0.9649 (1.0296) loss_zs_kd 0.1013 (0.1197) loss_oracle 0.0530 (0.0632) acc 71.8750 (72.8646) kd_loss 0.0325 (0.0359) lr 1.9823e-03 eta 0:23:04
epoch [5/50] batch [200/288] time 0.105 (0.106) data 0.000 (0.002) loss 1.0952 (1.1536) ce_loss 0.9966 (1.0357) teacher_loss 0.9876 (1.0324) loss_zs_kd 0.0977 (0.1185) loss_oracle 0.0588 (0.0620) acc 78.1250 (72.8750) kd_loss 0.0283 (0.0352) lr 1.9823e-03 eta 0:23:02
epoch [5/50] batch [220/288] time 0.097 (0.106) data 0.000 (0.002) loss 1.3330 (1.1571) ce_loss 1.2188 (1.0391) teacher_loss 1.2220 (1.0361) loss_zs_kd 0.1153 (0.1183) loss_oracle 0.0534 (0.0618) acc 75.0000 (72.5994) kd_loss 0.0234 (0.0343) lr 1.9823e-03 eta 0:22:57
epoch [5/50] batch [240/288] time 0.112 (0.106) data 0.000 (0.001) loss 0.9595 (1.1570) ce_loss 0.8447 (1.0375) teacher_loss 0.8348 (1.0345) loss_zs_kd 0.0990 (0.1177) loss_oracle 0.0751 (0.0636) acc 81.2500 (72.5781) kd_loss 0.0354 (0.0341) lr 1.9823e-03 eta 0:22:54
epoch [5/50] batch [260/288] time 0.102 (0.106) data 0.001 (0.001) loss 1.2017 (1.1521) ce_loss 1.1191 (1.0324) teacher_loss 1.1192 (1.0292) loss_zs_kd 0.0742 (0.1172) loss_oracle 0.0453 (0.0643) acc 68.7500 (72.6442) kd_loss 0.0272 (0.0343) lr 1.9823e-03 eta 0:22:52
epoch [5/50] batch [280/288] time 0.107 (0.106) data 0.000 (0.001) loss 0.8541 (1.1430) ce_loss 0.7368 (1.0233) teacher_loss 0.7089 (1.0199) loss_zs_kd 0.1345 (0.1166) loss_oracle 0.0780 (0.0647) acc 81.2500 (72.8237) kd_loss 0.0361 (0.0344) lr 1.9823e-03 eta 0:22:50
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,402
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.7%
******* Domain a best val acc:      86.5%, epoch: 4 *******
******* Domain a best val test acc: 83.3%, epoch: 4 *******
******* Domain a best test acc:     83.3%, epoch: 4 *******
epoch [6/50] batch [20/288] time 0.090 (0.109) data 0.000 (0.014) loss 1.2069 (1.0367) ce_loss 1.1084 (0.9239) teacher_loss 1.1094 (0.9178) loss_zs_kd 0.0839 (0.1029) loss_oracle 0.0556 (0.0675) acc 71.8750 (73.4375) kd_loss 0.0308 (0.0354) lr 1.9686e-03 eta 0:23:29
epoch [6/50] batch [40/288] time 0.095 (0.104) data 0.000 (0.007) loss 1.0861 (1.0960) ce_loss 0.9414 (0.9778) teacher_loss 0.9431 (0.9729) loss_zs_kd 0.1193 (0.1077) loss_oracle 0.0834 (0.0692) acc 75.0000 (72.8906) kd_loss 0.0379 (0.0361) lr 1.9686e-03 eta 0:22:19
epoch [6/50] batch [60/288] time 0.092 (0.101) data 0.000 (0.005) loss 1.2155 (1.0885) ce_loss 1.0576 (0.9654) teacher_loss 1.0535 (0.9615) loss_zs_kd 0.1479 (0.1078) loss_oracle 0.0881 (0.0731) acc 65.6250 (73.1771) kd_loss 0.0416 (0.0363) lr 1.9686e-03 eta 0:21:45
epoch [6/50] batch [80/288] time 0.092 (0.100) data 0.000 (0.004) loss 1.1593 (1.1003) ce_loss 1.0254 (0.9723) teacher_loss 1.0071 (0.9686) loss_zs_kd 0.1249 (0.1098) loss_oracle 0.0897 (0.0768) acc 71.8750 (73.1641) kd_loss 0.0408 (0.0373) lr 1.9686e-03 eta 0:21:29
epoch [6/50] batch [100/288] time 0.099 (0.101) data 0.000 (0.003) loss 1.4415 (1.1257) ce_loss 1.2920 (0.9932) teacher_loss 1.2739 (0.9891) loss_zs_kd 0.1316 (0.1088) loss_oracle 0.1018 (0.0822) acc 65.6250 (73.1562) kd_loss 0.0461 (0.0386) lr 1.9686e-03 eta 0:21:34
epoch [6/50] batch [120/288] time 0.095 (0.100) data 0.000 (0.003) loss 1.2856 (1.1217) ce_loss 1.1416 (0.9859) teacher_loss 1.1344 (0.9824) loss_zs_kd 0.1454 (0.1092) loss_oracle 0.0785 (0.0847) acc 71.8750 (73.5417) kd_loss 0.0435 (0.0398) lr 1.9686e-03 eta 0:21:26
epoch [6/50] batch [140/288] time 0.093 (0.100) data 0.000 (0.002) loss 0.8978 (1.1197) ce_loss 0.8013 (0.9854) teacher_loss 0.7982 (0.9818) loss_zs_kd 0.0793 (0.1098) loss_oracle 0.0599 (0.0830) acc 87.5000 (73.5491) kd_loss 0.0488 (0.0405) lr 1.9686e-03 eta 0:21:17
epoch [6/50] batch [160/288] time 0.107 (0.100) data 0.000 (0.002) loss 0.8456 (1.1206) ce_loss 0.7188 (0.9874) teacher_loss 0.7191 (0.9837) loss_zs_kd 0.1327 (0.1139) loss_oracle 0.0601 (0.0799) acc 75.0000 (73.4766) kd_loss 0.0361 (0.0406) lr 1.9686e-03 eta 0:21:22
epoch [6/50] batch [180/288] time 0.106 (0.101) data 0.001 (0.002) loss 0.9072 (1.1224) ce_loss 0.7671 (0.9907) teacher_loss 0.7516 (0.9867) loss_zs_kd 0.1702 (0.1158) loss_oracle 0.0705 (0.0778) acc 81.2500 (73.5069) kd_loss 0.0434 (0.0405) lr 1.9686e-03 eta 0:21:25
epoch [6/50] batch [200/288] time 0.092 (0.101) data 0.000 (0.002) loss 1.1385 (1.1237) ce_loss 1.0332 (0.9944) teacher_loss 1.0189 (0.9905) loss_zs_kd 0.1061 (0.1159) loss_oracle 0.0666 (0.0752) acc 68.7500 (73.3906) kd_loss 0.0522 (0.0401) lr 1.9686e-03 eta 0:21:24
epoch [6/50] batch [220/288] time 0.098 (0.100) data 0.000 (0.002) loss 1.3235 (1.1254) ce_loss 1.1973 (0.9979) teacher_loss 1.1959 (0.9940) loss_zs_kd 0.1423 (0.1163) loss_oracle 0.0564 (0.0732) acc 71.8750 (73.3807) kd_loss 0.0300 (0.0393) lr 1.9686e-03 eta 0:21:19
epoch [6/50] batch [240/288] time 0.117 (0.101) data 0.000 (0.001) loss 1.0849 (1.1296) ce_loss 0.9912 (1.0028) teacher_loss 0.9884 (0.9989) loss_zs_kd 0.0683 (0.1160) loss_oracle 0.0624 (0.0726) acc 75.0000 (73.2161) kd_loss 0.0408 (0.0389) lr 1.9686e-03 eta 0:21:23
epoch [6/50] batch [260/288] time 0.101 (0.101) data 0.000 (0.001) loss 1.3552 (1.1313) ce_loss 1.2539 (1.0059) teacher_loss 1.2462 (1.0020) loss_zs_kd 0.1002 (0.1168) loss_oracle 0.0588 (0.0709) acc 68.7500 (73.1490) kd_loss 0.0338 (0.0382) lr 1.9686e-03 eta 0:21:24
epoch [6/50] batch [280/288] time 0.108 (0.101) data 0.000 (0.001) loss 1.3729 (1.1308) ce_loss 1.2070 (1.0054) teacher_loss 1.2066 (1.0018) loss_zs_kd 0.1694 (0.1171) loss_oracle 0.0816 (0.0704) acc 71.8750 (73.2812) kd_loss 0.0297 (0.0375) lr 1.9686e-03 eta 0:21:23
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,401
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,032
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 80.4%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.5%, epoch: 4 *******
******* Domain a best val test acc: 83.3%, epoch: 4 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [7/50] batch [20/288] time 0.090 (0.120) data 0.000 (0.018) loss 1.3023 (1.1657) ce_loss 1.1934 (1.0450) teacher_loss 1.1835 (1.0427) loss_zs_kd 0.1037 (0.1131) loss_oracle 0.0670 (0.0665) acc 71.8750 (74.2188) kd_loss 0.0266 (0.0279) lr 1.9511e-03 eta 0:25:15
epoch [7/50] batch [40/288] time 0.099 (0.107) data 0.000 (0.009) loss 0.7972 (1.1060) ce_loss 0.6909 (0.9858) teacher_loss 0.6809 (0.9836) loss_zs_kd 0.1163 (0.1168) loss_oracle 0.0582 (0.0641) acc 87.5000 (75.1562) kd_loss 0.0259 (0.0281) lr 1.9511e-03 eta 0:22:37
epoch [7/50] batch [60/288] time 0.099 (0.104) data 0.001 (0.006) loss 1.2940 (1.0846) ce_loss 1.1875 (0.9683) teacher_loss 1.1923 (0.9657) loss_zs_kd 0.1181 (0.1194) loss_oracle 0.0426 (0.0592) acc 68.7500 (74.9479) kd_loss 0.0265 (0.0277) lr 1.9511e-03 eta 0:21:54
epoch [7/50] batch [80/288] time 0.091 (0.102) data 0.000 (0.005) loss 1.0150 (1.0850) ce_loss 0.8994 (0.9693) teacher_loss 0.8888 (0.9668) loss_zs_kd 0.1279 (0.1229) loss_oracle 0.0623 (0.0567) acc 75.0000 (74.8047) kd_loss 0.0375 (0.0278) lr 1.9511e-03 eta 0:21:27
epoch [7/50] batch [100/288] time 0.099 (0.101) data 0.000 (0.004) loss 0.7231 (1.0827) ce_loss 0.6196 (0.9682) teacher_loss 0.6215 (0.9658) loss_zs_kd 0.0907 (0.1227) loss_oracle 0.0562 (0.0555) acc 84.3750 (74.4062) kd_loss 0.0338 (0.0279) lr 1.9511e-03 eta 0:21:07
epoch [7/50] batch [120/288] time 0.093 (0.100) data 0.000 (0.003) loss 1.3853 (1.0788) ce_loss 1.2568 (0.9652) teacher_loss 1.2515 (0.9625) loss_zs_kd 0.1154 (0.1212) loss_oracle 0.0761 (0.0557) acc 75.0000 (74.2708) kd_loss 0.0363 (0.0277) lr 1.9511e-03 eta 0:20:53
epoch [7/50] batch [140/288] time 0.093 (0.099) data 0.000 (0.003) loss 1.1494 (1.0895) ce_loss 1.0615 (0.9765) teacher_loss 1.0592 (0.9734) loss_zs_kd 0.1067 (0.1212) loss_oracle 0.0368 (0.0555) acc 71.8750 (73.8393) kd_loss 0.0204 (0.0275) lr 1.9511e-03 eta 0:20:42
epoch [7/50] batch [160/288] time 0.094 (0.099) data 0.000 (0.002) loss 1.1046 (1.1062) ce_loss 0.9937 (0.9935) teacher_loss 0.9906 (0.9902) loss_zs_kd 0.1181 (0.1208) loss_oracle 0.0549 (0.0556) acc 75.0000 (73.4375) kd_loss 0.0280 (0.0274) lr 1.9511e-03 eta 0:20:32
epoch [7/50] batch [180/288] time 0.102 (0.098) data 0.000 (0.002) loss 1.1728 (1.1111) ce_loss 1.0693 (0.9990) teacher_loss 1.0483 (0.9958) loss_zs_kd 0.1312 (0.1208) loss_oracle 0.0589 (0.0549) acc 78.1250 (73.4549) kd_loss 0.0327 (0.0271) lr 1.9511e-03 eta 0:20:28
epoch [7/50] batch [200/288] time 0.097 (0.098) data 0.000 (0.002) loss 0.8198 (1.1041) ce_loss 0.7036 (0.9919) teacher_loss 0.7089 (0.9888) loss_zs_kd 0.1444 (0.1214) loss_oracle 0.0387 (0.0546) acc 68.7500 (73.5312) kd_loss 0.0129 (0.0267) lr 1.9511e-03 eta 0:20:22
epoch [7/50] batch [220/288] time 0.102 (0.098) data 0.000 (0.002) loss 1.3543 (1.1044) ce_loss 1.2412 (0.9930) teacher_loss 1.2479 (0.9899) loss_zs_kd 0.1229 (0.1212) loss_oracle 0.0450 (0.0540) acc 68.7500 (73.3807) kd_loss 0.0236 (0.0264) lr 1.9511e-03 eta 0:20:20
epoch [7/50] batch [240/288] time 0.091 (0.098) data 0.000 (0.002) loss 1.5563 (1.1107) ce_loss 1.4375 (0.9991) teacher_loss 1.4288 (0.9961) loss_zs_kd 0.1142 (0.1212) loss_oracle 0.0705 (0.0540) acc 59.3750 (73.2943) kd_loss 0.0286 (0.0263) lr 1.9511e-03 eta 0:20:16
epoch [7/50] batch [260/288] time 0.096 (0.098) data 0.001 (0.002) loss 1.0881 (1.1133) ce_loss 0.9434 (1.0012) teacher_loss 0.9385 (0.9984) loss_zs_kd 0.1067 (0.1203) loss_oracle 0.0962 (0.0548) acc 75.0000 (73.1971) kd_loss 0.0409 (0.0263) lr 1.9511e-03 eta 0:20:14
epoch [7/50] batch [280/288] time 0.086 (0.098) data 0.000 (0.001) loss 0.7984 (1.1086) ce_loss 0.7085 (0.9966) teacher_loss 0.7156 (0.9939) loss_zs_kd 0.0949 (0.1193) loss_oracle 0.0353 (0.0550) acc 78.1250 (73.4152) kd_loss 0.0169 (0.0264) lr 1.9511e-03 eta 0:20:08
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,405
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,029
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.3%
******* Domain a best val acc:      86.5%, epoch: 4 *******
******* Domain a best val test acc: 83.3%, epoch: 4 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [8/50] batch [20/288] time 0.085 (0.125) data 0.000 (0.014) loss 1.0357 (1.0936) ce_loss 0.8911 (0.9885) teacher_loss 0.8737 (0.9829) loss_zs_kd 0.1901 (0.1226) loss_oracle 0.0669 (0.0493) acc 84.3750 (74.0625) kd_loss 0.0455 (0.0288) lr 1.9298e-03 eta 0:25:49
epoch [8/50] batch [40/288] time 0.096 (0.109) data 0.000 (0.007) loss 0.9836 (1.0831) ce_loss 0.8594 (0.9764) teacher_loss 0.8573 (0.9725) loss_zs_kd 0.1494 (0.1187) loss_oracle 0.0516 (0.0513) acc 78.1250 (73.4375) kd_loss 0.0241 (0.0273) lr 1.9298e-03 eta 0:22:20
epoch [8/50] batch [60/288] time 0.092 (0.104) data 0.000 (0.005) loss 1.6255 (1.0664) ce_loss 1.5635 (0.9577) teacher_loss 1.5499 (0.9544) loss_zs_kd 0.0752 (0.1198) loss_oracle 0.0380 (0.0520) acc 59.3750 (74.0104) kd_loss 0.0228 (0.0276) lr 1.9298e-03 eta 0:21:27
epoch [8/50] batch [80/288] time 0.112 (0.102) data 0.000 (0.004) loss 1.1936 (1.0597) ce_loss 1.0996 (0.9513) teacher_loss 1.0887 (0.9476) loss_zs_kd 0.0961 (0.1213) loss_oracle 0.0569 (0.0514) acc 68.7500 (74.2578) kd_loss 0.0285 (0.0276) lr 1.9298e-03 eta 0:21:00
epoch [8/50] batch [100/288] time 0.099 (0.102) data 0.000 (0.003) loss 0.9047 (1.0670) ce_loss 0.7617 (0.9586) teacher_loss 0.7570 (0.9554) loss_zs_kd 0.1838 (0.1236) loss_oracle 0.0559 (0.0499) acc 84.3750 (74.2812) kd_loss 0.0323 (0.0268) lr 1.9298e-03 eta 0:20:50
epoch [8/50] batch [120/288] time 0.113 (0.101) data 0.000 (0.003) loss 1.0215 (1.0580) ce_loss 0.9092 (0.9496) teacher_loss 0.9141 (0.9470) loss_zs_kd 0.1404 (0.1260) loss_oracle 0.0372 (0.0481) acc 75.0000 (74.4531) kd_loss 0.0196 (0.0264) lr 1.9298e-03 eta 0:20:43
epoch [8/50] batch [140/288] time 0.099 (0.101) data 0.000 (0.002) loss 1.0796 (1.0695) ce_loss 0.9272 (0.9611) teacher_loss 0.9306 (0.9589) loss_zs_kd 0.1815 (0.1264) loss_oracle 0.0582 (0.0474) acc 68.7500 (74.1071) kd_loss 0.0334 (0.0261) lr 1.9298e-03 eta 0:20:36
epoch [8/50] batch [160/288] time 0.103 (0.101) data 0.000 (0.002) loss 1.2639 (1.0867) ce_loss 1.1504 (0.9789) teacher_loss 1.1494 (0.9765) loss_zs_kd 0.1274 (0.1251) loss_oracle 0.0508 (0.0476) acc 65.6250 (73.6914) kd_loss 0.0246 (0.0260) lr 1.9298e-03 eta 0:20:30
epoch [8/50] batch [180/288] time 0.095 (0.100) data 0.000 (0.002) loss 1.5074 (1.0870) ce_loss 1.3965 (0.9798) teacher_loss 1.3977 (0.9776) loss_zs_kd 0.0978 (0.1233) loss_oracle 0.0608 (0.0477) acc 68.7500 (73.6285) kd_loss 0.0229 (0.0259) lr 1.9298e-03 eta 0:20:22
epoch [8/50] batch [200/288] time 0.102 (0.100) data 0.000 (0.002) loss 1.3610 (1.0900) ce_loss 1.2617 (0.9826) teacher_loss 1.2567 (0.9802) loss_zs_kd 0.1149 (0.1234) loss_oracle 0.0469 (0.0481) acc 65.6250 (73.4844) kd_loss 0.0263 (0.0258) lr 1.9298e-03 eta 0:20:19
epoch [8/50] batch [220/288] time 0.097 (0.100) data 0.000 (0.001) loss 0.8236 (1.0859) ce_loss 0.7188 (0.9782) teacher_loss 0.7188 (0.9759) loss_zs_kd 0.1011 (0.1233) loss_oracle 0.0542 (0.0483) acc 84.3750 (73.6222) kd_loss 0.0223 (0.0255) lr 1.9298e-03 eta 0:20:16
epoch [8/50] batch [240/288] time 0.111 (0.100) data 0.000 (0.001) loss 1.0649 (1.0899) ce_loss 0.9307 (0.9816) teacher_loss 0.9203 (0.9793) loss_zs_kd 0.1628 (0.1239) loss_oracle 0.0632 (0.0487) acc 75.0000 (73.4635) kd_loss 0.0308 (0.0253) lr 1.9298e-03 eta 0:20:17
epoch [8/50] batch [260/288] time 0.095 (0.100) data 0.000 (0.001) loss 1.0697 (1.0901) ce_loss 0.9204 (0.9820) teacher_loss 0.9247 (0.9797) loss_zs_kd 0.1652 (0.1232) loss_oracle 0.0624 (0.0487) acc 78.1250 (73.5697) kd_loss 0.0278 (0.0251) lr 1.9298e-03 eta 0:20:15
epoch [8/50] batch [280/288] time 0.087 (0.100) data 0.000 (0.001) loss 1.5732 (1.0966) ce_loss 1.4609 (0.9887) teacher_loss 1.4493 (0.9863) loss_zs_kd 0.1289 (0.1227) loss_oracle 0.0594 (0.0490) acc 59.3750 (73.4263) kd_loss 0.0265 (0.0251) lr 1.9298e-03 eta 0:20:08
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,411
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 86.0%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,029
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.2%
******* Domain a best val acc:      86.6%, epoch: 8 *******
******* Domain a best val test acc: 83.6%, epoch: 8 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [9/50] batch [20/288] time 0.112 (0.125) data 0.000 (0.016) loss 1.1710 (1.1149) ce_loss 1.0693 (1.0087) teacher_loss 1.0655 (1.0086) loss_zs_kd 0.1110 (0.1173) loss_oracle 0.0500 (0.0476) acc 71.8750 (72.3438) kd_loss 0.0267 (0.0242) lr 1.9048e-03 eta 0:25:08
epoch [9/50] batch [40/288] time 0.115 (0.116) data 0.000 (0.008) loss 0.7032 (1.0588) ce_loss 0.6333 (0.9537) teacher_loss 0.6201 (0.9517) loss_zs_kd 0.0666 (0.1174) loss_oracle 0.0498 (0.0483) acc 81.2500 (74.2969) kd_loss 0.0217 (0.0238) lr 1.9048e-03 eta 0:23:14
epoch [9/50] batch [60/288] time 0.099 (0.111) data 0.001 (0.006) loss 1.2054 (1.0653) ce_loss 1.1055 (0.9584) teacher_loss 1.1107 (0.9571) loss_zs_kd 0.1118 (0.1188) loss_oracle 0.0388 (0.0488) acc 65.6250 (74.1667) kd_loss 0.0231 (0.0236) lr 1.9048e-03 eta 0:22:20
epoch [9/50] batch [80/288] time 0.100 (0.110) data 0.000 (0.004) loss 0.9135 (1.0956) ce_loss 0.7930 (0.9849) teacher_loss 0.7981 (0.9842) loss_zs_kd 0.1220 (0.1244) loss_oracle 0.0544 (0.0492) acc 87.5000 (73.7109) kd_loss 0.0241 (0.0235) lr 1.9048e-03 eta 0:21:56
epoch [9/50] batch [100/288] time 0.101 (0.108) data 0.000 (0.003) loss 0.8473 (1.0975) ce_loss 0.7451 (0.9872) teacher_loss 0.7454 (0.9863) loss_zs_kd 0.1251 (0.1231) loss_oracle 0.0394 (0.0497) acc 71.8750 (73.8438) kd_loss 0.0234 (0.0237) lr 1.9048e-03 eta 0:21:35
epoch [9/50] batch [120/288] time 0.106 (0.107) data 0.000 (0.003) loss 1.1520 (1.1099) ce_loss 1.0391 (0.9994) teacher_loss 1.0421 (0.9983) loss_zs_kd 0.1132 (0.1237) loss_oracle 0.0533 (0.0497) acc 68.7500 (73.3333) kd_loss 0.0252 (0.0237) lr 1.9048e-03 eta 0:21:18
epoch [9/50] batch [140/288] time 0.100 (0.106) data 0.000 (0.003) loss 1.0060 (1.1149) ce_loss 0.9478 (1.0054) teacher_loss 0.9480 (1.0044) loss_zs_kd 0.0697 (0.1247) loss_oracle 0.0231 (0.0481) acc 71.8750 (73.5268) kd_loss 0.0173 (0.0237) lr 1.9048e-03 eta 0:21:02
epoch [9/50] batch [160/288] time 0.097 (0.104) data 0.000 (0.002) loss 0.8829 (1.1093) ce_loss 0.7632 (0.9986) teacher_loss 0.7673 (0.9974) loss_zs_kd 0.1420 (0.1282) loss_oracle 0.0446 (0.0478) acc 81.2500 (73.5156) kd_loss 0.0190 (0.0241) lr 1.9048e-03 eta 0:20:45
epoch [9/50] batch [180/288] time 0.092 (0.103) data 0.000 (0.002) loss 1.7456 (1.1106) ce_loss 1.6494 (1.0010) teacher_loss 1.6295 (0.9995) loss_zs_kd 0.1445 (0.1267) loss_oracle 0.0439 (0.0477) acc 68.7500 (73.5069) kd_loss 0.0304 (0.0242) lr 1.9048e-03 eta 0:20:31
epoch [9/50] batch [200/288] time 0.095 (0.103) data 0.000 (0.002) loss 1.3377 (1.1184) ce_loss 1.2393 (1.0093) teacher_loss 1.2266 (1.0076) loss_zs_kd 0.1198 (0.1265) loss_oracle 0.0513 (0.0476) acc 68.7500 (73.2344) kd_loss 0.0205 (0.0246) lr 1.9048e-03 eta 0:20:22
epoch [9/50] batch [220/288] time 0.097 (0.102) data 0.000 (0.002) loss 0.8172 (1.1188) ce_loss 0.6582 (1.0093) teacher_loss 0.6625 (1.0074) loss_zs_kd 0.1644 (0.1259) loss_oracle 0.0726 (0.0484) acc 81.2500 (73.1960) kd_loss 0.0289 (0.0248) lr 1.9048e-03 eta 0:20:13
epoch [9/50] batch [240/288] time 0.099 (0.102) data 0.000 (0.002) loss 1.2334 (1.1176) ce_loss 1.0830 (1.0074) teacher_loss 1.0796 (1.0054) loss_zs_kd 0.1814 (0.1251) loss_oracle 0.0632 (0.0496) acc 71.8750 (73.2161) kd_loss 0.0251 (0.0248) lr 1.9048e-03 eta 0:20:05
epoch [9/50] batch [260/288] time 0.100 (0.101) data 0.000 (0.001) loss 0.9937 (1.1211) ce_loss 0.8867 (1.0106) teacher_loss 0.8891 (1.0084) loss_zs_kd 0.0945 (0.1247) loss_oracle 0.0573 (0.0503) acc 71.8750 (73.0529) kd_loss 0.0246 (0.0249) lr 1.9048e-03 eta 0:19:57
epoch [9/50] batch [280/288] time 0.087 (0.101) data 0.000 (0.001) loss 0.9809 (1.1149) ce_loss 0.9155 (1.0040) teacher_loss 0.9103 (1.0014) loss_zs_kd 0.0694 (0.1248) loss_oracle 0.0359 (0.0511) acc 75.0000 (73.1027) kd_loss 0.0236 (0.0254) lr 1.9048e-03 eta 0:19:48
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,414
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 86.1%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.8%
******* Domain a best val acc:      86.7%, epoch: 9 *******
******* Domain a best val test acc: 83.2%, epoch: 9 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [10/50] batch [20/288] time 0.094 (0.104) data 0.000 (0.011) loss 0.8534 (1.1301) ce_loss 0.7705 (1.0187) teacher_loss 0.7727 (1.0166) loss_zs_kd 0.0739 (0.1196) loss_oracle 0.0438 (0.0537) acc 78.1250 (74.2188) kd_loss 0.0219 (0.0280) lr 1.8763e-03 eta 0:20:25
epoch [10/50] batch [40/288] time 0.104 (0.100) data 0.000 (0.005) loss 1.3098 (1.0867) ce_loss 1.1641 (0.9729) teacher_loss 1.1645 (0.9690) loss_zs_kd 0.1654 (0.1246) loss_oracle 0.0626 (0.0554) acc 68.7500 (75.7812) kd_loss 0.0356 (0.0294) lr 1.8763e-03 eta 0:19:36
epoch [10/50] batch [60/288] time 0.099 (0.099) data 0.000 (0.004) loss 0.9535 (1.0537) ce_loss 0.8574 (0.9427) teacher_loss 0.8596 (0.9385) loss_zs_kd 0.0957 (0.1230) loss_oracle 0.0460 (0.0536) acc 81.2500 (75.8854) kd_loss 0.0226 (0.0297) lr 1.8763e-03 eta 0:19:23
epoch [10/50] batch [80/288] time 0.090 (0.098) data 0.000 (0.003) loss 1.2240 (1.0816) ce_loss 1.1211 (0.9684) teacher_loss 1.1205 (0.9636) loss_zs_kd 0.1063 (0.1257) loss_oracle 0.0503 (0.0551) acc 78.1250 (74.8828) kd_loss 0.0218 (0.0296) lr 1.8763e-03 eta 0:19:09
epoch [10/50] batch [100/288] time 0.107 (0.098) data 0.000 (0.002) loss 1.3828 (1.0687) ce_loss 1.2734 (0.9574) teacher_loss 1.2719 (0.9535) loss_zs_kd 0.1253 (0.1236) loss_oracle 0.0481 (0.0534) acc 71.8750 (75.0312) kd_loss 0.0315 (0.0290) lr 1.8763e-03 eta 0:19:07
epoch [10/50] batch [120/288] time 0.095 (0.099) data 0.000 (0.002) loss 0.9664 (1.0672) ce_loss 0.8594 (0.9554) teacher_loss 0.8600 (0.9519) loss_zs_kd 0.1192 (0.1233) loss_oracle 0.0468 (0.0537) acc 81.2500 (75.1042) kd_loss 0.0227 (0.0288) lr 1.8763e-03 eta 0:19:13
epoch [10/50] batch [140/288] time 0.102 (0.099) data 0.001 (0.002) loss 1.3927 (1.0853) ce_loss 1.2676 (0.9727) teacher_loss 1.2643 (0.9692) loss_zs_kd 0.1174 (0.1245) loss_oracle 0.0696 (0.0538) acc 68.7500 (74.7098) kd_loss 0.0342 (0.0286) lr 1.8763e-03 eta 0:19:18
epoch [10/50] batch [160/288] time 0.099 (0.100) data 0.000 (0.002) loss 0.7881 (1.0859) ce_loss 0.6748 (0.9718) teacher_loss 0.6745 (0.9686) loss_zs_kd 0.0898 (0.1235) loss_oracle 0.0687 (0.0556) acc 84.3750 (74.6289) kd_loss 0.0345 (0.0290) lr 1.8763e-03 eta 0:19:22
epoch [10/50] batch [180/288] time 0.101 (0.100) data 0.000 (0.001) loss 1.1789 (1.0974) ce_loss 1.0859 (0.9823) teacher_loss 1.0874 (0.9793) loss_zs_kd 0.0957 (0.1236) loss_oracle 0.0436 (0.0564) acc 75.0000 (74.2882) kd_loss 0.0319 (0.0290) lr 1.8763e-03 eta 0:19:23
epoch [10/50] batch [200/288] time 0.103 (0.100) data 0.001 (0.001) loss 1.3870 (1.1035) ce_loss 1.2959 (0.9892) teacher_loss 1.2889 (0.9861) loss_zs_kd 0.0992 (0.1228) loss_oracle 0.0485 (0.0560) acc 65.6250 (74.1562) kd_loss 0.0298 (0.0290) lr 1.8763e-03 eta 0:19:25
epoch [10/50] batch [220/288] time 0.102 (0.101) data 0.000 (0.001) loss 1.1748 (1.1034) ce_loss 1.0703 (0.9903) teacher_loss 1.0610 (0.9873) loss_zs_kd 0.1381 (0.1224) loss_oracle 0.0448 (0.0549) acc 68.7500 (74.1761) kd_loss 0.0273 (0.0287) lr 1.8763e-03 eta 0:19:26
epoch [10/50] batch [240/288] time 0.113 (0.101) data 0.000 (0.001) loss 1.0211 (1.1053) ce_loss 0.8921 (0.9930) teacher_loss 0.8937 (0.9899) loss_zs_kd 0.1521 (0.1229) loss_oracle 0.0514 (0.0539) acc 78.1250 (74.0495) kd_loss 0.0222 (0.0286) lr 1.8763e-03 eta 0:19:28
epoch [10/50] batch [260/288] time 0.113 (0.101) data 0.000 (0.001) loss 1.2000 (1.1051) ce_loss 1.0723 (0.9927) teacher_loss 1.0751 (0.9895) loss_zs_kd 0.1253 (0.1241) loss_oracle 0.0622 (0.0535) acc 75.0000 (73.9183) kd_loss 0.0329 (0.0286) lr 1.8763e-03 eta 0:19:28
epoch [10/50] batch [280/288] time 0.105 (0.101) data 0.000 (0.001) loss 1.6016 (1.1139) ce_loss 1.4307 (1.0011) teacher_loss 1.4437 (0.9981) loss_zs_kd 0.1972 (0.1254) loss_oracle 0.0594 (0.0531) acc 65.6250 (73.6830) kd_loss 0.0309 (0.0286) lr 1.8763e-03 eta 0:19:29
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,423
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.2%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,019
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.8%
******* Domain a best val acc:      86.9%, epoch: 10 *******
******* Domain a best val test acc: 83.2%, epoch: 10 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [11/50] batch [20/288] time 0.098 (0.127) data 0.001 (0.016) loss 1.6220 (1.1305) ce_loss 1.5176 (1.0150) teacher_loss 1.5168 (1.0157) loss_zs_kd 0.1085 (0.1313) loss_oracle 0.0510 (0.0491) acc 62.5000 (72.8125) kd_loss 0.0262 (0.0289) lr 1.8443e-03 eta 0:24:15
epoch [11/50] batch [40/288] time 0.109 (0.115) data 0.000 (0.008) loss 1.2557 (1.1282) ce_loss 1.1367 (1.0120) teacher_loss 1.1402 (1.0106) loss_zs_kd 0.1556 (0.1315) loss_oracle 0.0377 (0.0519) acc 71.8750 (72.3438) kd_loss 0.0250 (0.0322) lr 1.8443e-03 eta 0:22:02
epoch [11/50] batch [60/288] time 0.101 (0.112) data 0.000 (0.006) loss 0.9205 (1.1222) ce_loss 0.8066 (1.0086) teacher_loss 0.8094 (1.0070) loss_zs_kd 0.1418 (0.1290) loss_oracle 0.0402 (0.0507) acc 78.1250 (72.8125) kd_loss 0.0263 (0.0318) lr 1.8443e-03 eta 0:21:22
epoch [11/50] batch [80/288] time 0.112 (0.110) data 0.001 (0.004) loss 1.1657 (1.0973) ce_loss 1.0859 (0.9867) teacher_loss 1.0930 (0.9839) loss_zs_kd 0.0906 (0.1273) loss_oracle 0.0274 (0.0498) acc 65.6250 (73.4375) kd_loss 0.0278 (0.0326) lr 1.8443e-03 eta 0:21:00
epoch [11/50] batch [100/288] time 0.102 (0.109) data 0.000 (0.004) loss 1.3196 (1.0824) ce_loss 1.1924 (0.9723) teacher_loss 1.1797 (0.9693) loss_zs_kd 0.1498 (0.1270) loss_oracle 0.0650 (0.0496) acc 68.7500 (73.7500) kd_loss 0.0453 (0.0327) lr 1.8443e-03 eta 0:20:47
epoch [11/50] batch [120/288] time 0.102 (0.109) data 0.000 (0.003) loss 1.6321 (1.0847) ce_loss 1.5283 (0.9743) teacher_loss 1.5284 (0.9718) loss_zs_kd 0.1074 (0.1273) loss_oracle 0.0501 (0.0493) acc 53.1250 (73.6198) kd_loss 0.0302 (0.0320) lr 1.8443e-03 eta 0:20:40
epoch [11/50] batch [140/288] time 0.106 (0.108) data 0.000 (0.003) loss 0.9329 (1.0869) ce_loss 0.8433 (0.9762) teacher_loss 0.8387 (0.9736) loss_zs_kd 0.0834 (0.1262) loss_oracle 0.0525 (0.0502) acc 81.2500 (73.5045) kd_loss 0.0293 (0.0316) lr 1.8443e-03 eta 0:20:30
epoch [11/50] batch [160/288] time 0.104 (0.107) data 0.001 (0.002) loss 1.3400 (1.1001) ce_loss 1.2324 (0.9902) teacher_loss 1.2334 (0.9873) loss_zs_kd 0.1132 (0.1255) loss_oracle 0.0499 (0.0501) acc 65.6250 (73.0859) kd_loss 0.0331 (0.0313) lr 1.8443e-03 eta 0:20:18
epoch [11/50] batch [180/288] time 0.112 (0.107) data 0.000 (0.002) loss 1.1530 (1.0954) ce_loss 1.0352 (0.9859) teacher_loss 1.0381 (0.9830) loss_zs_kd 0.1377 (0.1259) loss_oracle 0.0461 (0.0495) acc 78.1250 (73.1597) kd_loss 0.0243 (0.0311) lr 1.8443e-03 eta 0:20:10
epoch [11/50] batch [200/288] time 0.098 (0.106) data 0.000 (0.002) loss 1.2278 (1.0916) ce_loss 1.0830 (0.9825) teacher_loss 1.0838 (0.9800) loss_zs_kd 0.1903 (0.1255) loss_oracle 0.0488 (0.0488) acc 78.1250 (73.2344) kd_loss 0.0297 (0.0307) lr 1.8443e-03 eta 0:20:04
epoch [11/50] batch [220/288] time 0.110 (0.106) data 0.000 (0.002) loss 1.0706 (1.0917) ce_loss 0.9590 (0.9815) teacher_loss 0.9463 (0.9790) loss_zs_kd 0.1425 (0.1279) loss_oracle 0.0530 (0.0487) acc 81.2500 (73.3239) kd_loss 0.0334 (0.0306) lr 1.8443e-03 eta 0:19:58
epoch [11/50] batch [240/288] time 0.109 (0.106) data 0.000 (0.002) loss 1.0988 (1.0890) ce_loss 1.0068 (0.9790) teacher_loss 1.0071 (0.9766) loss_zs_kd 0.1004 (0.1279) loss_oracle 0.0415 (0.0484) acc 71.8750 (73.4635) kd_loss 0.0237 (0.0302) lr 1.8443e-03 eta 0:19:56
epoch [11/50] batch [260/288] time 0.099 (0.106) data 0.000 (0.002) loss 1.0295 (1.0902) ce_loss 0.9517 (0.9806) teacher_loss 0.9285 (0.9779) loss_zs_kd 0.0993 (0.1275) loss_oracle 0.0514 (0.0485) acc 75.0000 (73.3534) kd_loss 0.0300 (0.0300) lr 1.8443e-03 eta 0:19:48
epoch [11/50] batch [280/288] time 0.088 (0.105) data 0.000 (0.001) loss 0.8291 (1.0833) ce_loss 0.7549 (0.9737) teacher_loss 0.7451 (0.9711) loss_zs_kd 0.0915 (0.1270) loss_oracle 0.0383 (0.0487) acc 81.2500 (73.5938) kd_loss 0.0296 (0.0299) lr 1.8443e-03 eta 0:19:36
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,421
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.2%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,025
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.1%
******* Domain a best val acc:      86.9%, epoch: 10 *******
******* Domain a best val test acc: 83.2%, epoch: 10 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [12/50] batch [20/288] time 0.117 (0.125) data 0.000 (0.012) loss 1.0786 (1.1016) ce_loss 0.9785 (0.9933) teacher_loss 0.9778 (0.9887) loss_zs_kd 0.0852 (0.1348) loss_oracle 0.0582 (0.0456) acc 81.2500 (73.5938) kd_loss 0.0381 (0.0274) lr 1.8090e-03 eta 0:23:25
epoch [12/50] batch [40/288] time 0.110 (0.116) data 0.000 (0.006) loss 1.1234 (1.0784) ce_loss 1.0342 (0.9687) teacher_loss 1.0429 (0.9654) loss_zs_kd 0.0801 (0.1315) loss_oracle 0.0405 (0.0472) acc 75.0000 (73.6719) kd_loss 0.0162 (0.0267) lr 1.8090e-03 eta 0:21:40
epoch [12/50] batch [60/288] time 0.114 (0.112) data 0.001 (0.004) loss 1.3276 (1.1013) ce_loss 1.2256 (0.9915) teacher_loss 1.2211 (0.9892) loss_zs_kd 0.1263 (0.1307) loss_oracle 0.0433 (0.0468) acc 68.7500 (73.3854) kd_loss 0.0320 (0.0263) lr 1.8090e-03 eta 0:20:55
epoch [12/50] batch [80/288] time 0.109 (0.110) data 0.000 (0.003) loss 2.0883 (1.1078) ce_loss 1.9844 (0.9985) teacher_loss 1.9716 (0.9957) loss_zs_kd 0.1535 (0.1324) loss_oracle 0.0399 (0.0458) acc 56.2500 (73.6328) kd_loss 0.0272 (0.0266) lr 1.8090e-03 eta 0:20:28
epoch [12/50] batch [100/288] time 0.105 (0.109) data 0.000 (0.003) loss 1.1741 (1.0871) ce_loss 1.0742 (0.9804) teacher_loss 1.0651 (0.9780) loss_zs_kd 0.1256 (0.1294) loss_oracle 0.0462 (0.0444) acc 59.3750 (73.7812) kd_loss 0.0382 (0.0269) lr 1.8090e-03 eta 0:20:08
epoch [12/50] batch [120/288] time 0.102 (0.108) data 0.000 (0.002) loss 1.2615 (1.0791) ce_loss 1.1455 (0.9729) teacher_loss 1.1421 (0.9703) loss_zs_kd 0.1361 (0.1292) loss_oracle 0.0514 (0.0443) acc 68.7500 (74.1667) kd_loss 0.0254 (0.0270) lr 1.8090e-03 eta 0:19:56
epoch [12/50] batch [140/288] time 0.112 (0.108) data 0.000 (0.002) loss 0.5908 (1.0850) ce_loss 0.4824 (0.9773) teacher_loss 0.4823 (0.9746) loss_zs_kd 0.1110 (0.1313) loss_oracle 0.0530 (0.0447) acc 90.6250 (74.1964) kd_loss 0.0285 (0.0273) lr 1.8090e-03 eta 0:19:53
epoch [12/50] batch [160/288] time 0.098 (0.107) data 0.000 (0.002) loss 1.1091 (1.0847) ce_loss 0.9668 (0.9756) teacher_loss 0.9674 (0.9730) loss_zs_kd 0.1779 (0.1325) loss_oracle 0.0528 (0.0455) acc 71.8750 (74.0430) kd_loss 0.0357 (0.0273) lr 1.8090e-03 eta 0:19:46
epoch [12/50] batch [180/288] time 0.105 (0.107) data 0.000 (0.002) loss 0.9648 (1.0993) ce_loss 0.8354 (0.9898) teacher_loss 0.8457 (0.9875) loss_zs_kd 0.1653 (0.1330) loss_oracle 0.0364 (0.0453) acc 81.2500 (73.5938) kd_loss 0.0163 (0.0272) lr 1.8090e-03 eta 0:19:44
epoch [12/50] batch [200/288] time 0.112 (0.107) data 0.000 (0.001) loss 1.2546 (1.1014) ce_loss 1.1514 (0.9922) teacher_loss 1.1483 (0.9898) loss_zs_kd 0.1264 (0.1321) loss_oracle 0.0431 (0.0456) acc 71.8750 (73.7188) kd_loss 0.0307 (0.0274) lr 1.8090e-03 eta 0:19:42
epoch [12/50] batch [220/288] time 0.097 (0.107) data 0.000 (0.001) loss 0.8500 (1.0984) ce_loss 0.7148 (0.9887) teacher_loss 0.7201 (0.9866) loss_zs_kd 0.1879 (0.1328) loss_oracle 0.0360 (0.0454) acc 75.0000 (73.8068) kd_loss 0.0201 (0.0275) lr 1.8090e-03 eta 0:19:43
epoch [12/50] batch [240/288] time 0.102 (0.107) data 0.000 (0.001) loss 1.4979 (1.1019) ce_loss 1.3789 (0.9923) teacher_loss 1.3692 (0.9904) loss_zs_kd 0.1535 (0.1326) loss_oracle 0.0519 (0.0452) acc 59.3750 (73.7760) kd_loss 0.0279 (0.0277) lr 1.8090e-03 eta 0:19:41
epoch [12/50] batch [260/288] time 0.110 (0.107) data 0.000 (0.001) loss 0.9324 (1.0980) ce_loss 0.7993 (0.9889) teacher_loss 0.7946 (0.9869) loss_zs_kd 0.1525 (0.1317) loss_oracle 0.0615 (0.0453) acc 84.3750 (73.8221) kd_loss 0.0409 (0.0279) lr 1.8090e-03 eta 0:19:37
epoch [12/50] batch [280/288] time 0.102 (0.107) data 0.000 (0.001) loss 0.9819 (1.0966) ce_loss 0.8994 (0.9876) teacher_loss 0.8950 (0.9855) loss_zs_kd 0.0931 (0.1312) loss_oracle 0.0403 (0.0455) acc 78.1250 (73.8839) kd_loss 0.0366 (0.0282) lr 1.8090e-03 eta 0:19:35
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,408
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 86.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 79.8%
******* Domain a best val acc:      86.9%, epoch: 10 *******
******* Domain a best val test acc: 83.2%, epoch: 10 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [13/50] batch [20/288] time 0.118 (0.126) data 0.000 (0.013) loss 0.9036 (1.0577) ce_loss 0.7695 (0.9447) teacher_loss 0.7767 (0.9425) loss_zs_kd 0.1605 (0.1374) loss_oracle 0.0467 (0.0465) acc 78.1250 (73.9062) kd_loss 0.0363 (0.0345) lr 1.7705e-03 eta 0:22:51

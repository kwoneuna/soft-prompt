Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'pascal', 'sun']
Target     ['labelme']
# classes  5
# train_x  5,651
# val      2,422
# test     2,656
---------  ----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/13_entropybaseweight_mixlogits/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/176] time 0.070 (0.122) data 0.000 (0.020) loss 1.2760 (1.3978) teacher_loss 0.3723 (0.5075) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.9036 (0.8903) acc 81.2500 (80.6250) alaph_mean 0.0686 (0.0742) alpha_min 0.0000 (0.0000) alpha_max 0.5000 (0.4565) lr 1.0000e-05 eta 0:17:49
epoch [1/50] batch [40/176] time 0.076 (0.097) data 0.000 (0.010) loss 1.4364 (1.4066) teacher_loss 0.5273 (0.5271) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.9090 (0.8795) acc 81.2500 (80.6250) alaph_mean 0.0699 (0.0788) alpha_min 0.0000 (0.0000) alpha_max 0.4532 (0.4522) lr 1.0000e-05 eta 0:14:13
epoch [1/50] batch [60/176] time 0.062 (0.089) data 0.001 (0.007) loss 1.4176 (1.4120) teacher_loss 0.5234 (0.5304) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.8940 (0.8816) acc 78.1250 (81.0938) alaph_mean 0.0720 (0.0778) alpha_min 0.0000 (0.0000) alpha_max 0.4220 (0.4521) lr 1.0000e-05 eta 0:12:54
epoch [1/50] batch [80/176] time 0.061 (0.083) data 0.000 (0.005) loss 1.3577 (1.4100) teacher_loss 0.4551 (0.5280) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.9025 (0.8820) acc 87.5000 (81.5234) alaph_mean 0.0684 (0.0779) alpha_min 0.0000 (0.0000) alpha_max 0.3913 (0.4528) lr 1.0000e-05 eta 0:12:01
epoch [1/50] batch [100/176] time 0.080 (0.082) data 0.000 (0.004) loss 1.2177 (1.4008) teacher_loss 0.3635 (0.5197) loss_zs_kd 0.0005 (0.0002) loss_oracle 0.8539 (0.8811) acc 87.5000 (81.9375) alaph_mean 0.0952 (0.0784) alpha_min 0.0000 (0.0000) alpha_max 0.5002 (0.4540) lr 1.0000e-05 eta 0:11:53
epoch [1/50] batch [120/176] time 0.083 (0.082) data 0.000 (0.003) loss 1.1352 (1.4000) teacher_loss 0.2437 (0.5181) loss_zs_kd 0.0006 (0.0002) loss_oracle 0.8913 (0.8818) acc 93.7500 (81.9792) alaph_mean 0.0735 (0.0777) alpha_min 0.0000 (0.0000) alpha_max 0.4999 (0.4517) lr 1.0000e-05 eta 0:11:54
epoch [1/50] batch [140/176] time 0.080 (0.083) data 0.000 (0.003) loss 1.5698 (1.4085) teacher_loss 0.6528 (0.5294) loss_zs_kd 0.0008 (0.0003) loss_oracle 0.9166 (0.8790) acc 78.1250 (81.5848) alaph_mean 0.0641 (0.0790) alpha_min 0.0000 (0.0000) alpha_max 0.4106 (0.4558) lr 1.0000e-05 eta 0:11:55
epoch [1/50] batch [160/176] time 0.086 (0.083) data 0.000 (0.003) loss 1.2349 (1.4083) teacher_loss 0.3223 (0.5279) loss_zs_kd 0.0005 (0.0004) loss_oracle 0.9124 (0.8803) acc 87.5000 (81.4258) alaph_mean 0.0598 (0.0785) alpha_min 0.0000 (0.0000) alpha_max 0.3772 (0.4548) lr 1.0000e-05 eta 0:11:58
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,070
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 87.8%
Checkpoint saved to icml/multi-dg/oracle/13_entropybaseweight_mixlogits/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,832
* accuracy: 69.0%
* error: 31.0%
* macro_f1: 61.7%
Checkpoint saved to icml/multi-dg/oracle/13_entropybaseweight_mixlogits/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain l best val acc:      85.5%, epoch: 1 *******
******* Domain l best val test acc: 69.0%, epoch: 1 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [2/50] batch [20/176] time 0.080 (0.096) data 0.000 (0.013) loss 1.5972 (1.4715) teacher_loss 0.5962 (0.5247) loss_zs_kd 0.0958 (0.0647) loss_oracle 0.9531 (0.9145) acc 75.0000 (80.9375) alaph_mean 0.0790 (0.0767) alpha_min 0.0000 (0.0000) alpha_max 0.5047 (0.4872) lr 2.0000e-03 eta 0:13:42
epoch [2/50] batch [40/176] time 0.079 (0.089) data 0.000 (0.007) loss 1.4025 (1.4462) teacher_loss 0.3901 (0.4900) loss_zs_kd 0.1025 (0.0704) loss_oracle 0.9611 (0.9210) acc 81.2500 (82.7344) alaph_mean 0.0483 (0.0781) alpha_min -0.0000 (0.0000) alpha_max 0.3225 (0.4972) lr 2.0000e-03 eta 0:12:43
epoch [2/50] batch [60/176] time 0.090 (0.087) data 0.000 (0.005) loss 1.3027 (1.4326) teacher_loss 0.2932 (0.4672) loss_zs_kd 0.0916 (0.0791) loss_oracle 0.9637 (0.9258) acc 87.5000 (83.4375) alaph_mean 0.0654 (0.0750) alpha_min 0.0000 (0.0000) alpha_max 0.5014 (0.4876) lr 2.0000e-03 eta 0:12:25
epoch [2/50] batch [80/176] time 0.149 (0.088) data 0.001 (0.004) loss 1.7073 (1.4409) teacher_loss 0.6255 (0.4600) loss_zs_kd 0.0837 (0.0819) loss_oracle 1.0400 (0.9400) acc 81.2500 (83.8672) alaph_mean 0.0281 (0.0707) alpha_min 0.0000 (0.0000) alpha_max 0.5680 (0.4891) lr 2.0000e-03 eta 0:12:30
epoch [2/50] batch [100/176] time 0.085 (0.089) data 0.000 (0.003) loss 1.9184 (1.4415) teacher_loss 0.8228 (0.4578) loss_zs_kd 0.0967 (0.0831) loss_oracle 1.0473 (0.9421) acc 78.1250 (84.0938) alaph_mean 0.0319 (0.0719) alpha_min 0.0000 (0.0000) alpha_max 0.4868 (0.4993) lr 2.0000e-03 eta 0:12:36
epoch [2/50] batch [120/176] time 0.084 (0.088) data 0.000 (0.002) loss 1.3714 (1.4407) teacher_loss 0.3577 (0.4513) loss_zs_kd 0.1047 (0.0835) loss_oracle 0.9614 (0.9476) acc 84.3750 (84.1146) alaph_mean 0.0719 (0.0720) alpha_min 0.0000 (0.0000) alpha_max 0.5356 (0.5193) lr 2.0000e-03 eta 0:12:29
epoch [2/50] batch [140/176] time 0.087 (0.088) data 0.000 (0.002) loss 1.3865 (1.4333) teacher_loss 0.3564 (0.4433) loss_zs_kd 0.0706 (0.0860) loss_oracle 0.9948 (0.9470) acc 87.5000 (84.4420) alaph_mean 0.0398 (0.0729) alpha_min 0.0000 (0.0000) alpha_max 0.4056 (0.5230) lr 2.0000e-03 eta 0:12:26
epoch [2/50] batch [160/176] time 0.092 (0.088) data 0.001 (0.002) loss 1.1008 (1.4275) teacher_loss 0.2686 (0.4386) loss_zs_kd 0.0340 (0.0848) loss_oracle 0.8153 (0.9465) acc 93.7500 (84.6289) alaph_mean 0.1319 (0.0719) alpha_min 0.0000 (0.0000) alpha_max 0.5667 (0.5177) lr 2.0000e-03 eta 0:12:22
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,167
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 91.4%
Checkpoint saved to icml/multi-dg/oracle/13_entropybaseweight_mixlogits/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,752
* accuracy: 66.0%
* error: 34.0%
* macro_f1: 60.7%
******* Domain l best val acc:      89.5%, epoch: 2 *******
******* Domain l best val test acc: 66.0%, epoch: 2 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [3/50] batch [20/176] time 0.076 (0.098) data 0.000 (0.017) loss 1.6727 (1.4231) teacher_loss 0.7104 (0.4233) loss_zs_kd 0.1188 (0.0737) loss_oracle 0.9028 (0.9630) acc 75.0000 (84.0625) alaph_mean 0.0803 (0.0563) alpha_min 0.0000 (0.0000) alpha_max 0.4992 (0.5384) lr 1.9980e-03 eta 0:13:48
epoch [3/50] batch [40/176] time 0.085 (0.090) data 0.000 (0.009) loss 1.2428 (1.4035) teacher_loss 0.2622 (0.4172) loss_zs_kd 0.0966 (0.0760) loss_oracle 0.9323 (0.9483) acc 87.5000 (84.2188) alaph_mean 0.0834 (0.0623) alpha_min 0.0000 (0.0000) alpha_max 0.6641 (0.5250) lr 1.9980e-03 eta 0:12:39
epoch [3/50] batch [60/176] time 0.078 (0.087) data 0.000 (0.006) loss 1.5082 (1.3762) teacher_loss 0.5259 (0.3942) loss_zs_kd 0.0811 (0.0812) loss_oracle 0.9418 (0.9414) acc 84.3750 (85.3125) alaph_mean 0.0646 (0.0683) alpha_min -0.0000 (0.0000) alpha_max 0.4960 (0.5368) lr 1.9980e-03 eta 0:12:10
epoch [3/50] batch [80/176] time 0.076 (0.084) data 0.000 (0.005) loss 1.1980 (1.3627) teacher_loss 0.1824 (0.3831) loss_zs_kd 0.0627 (0.0799) loss_oracle 0.9843 (0.9397) acc 90.6250 (85.8203) alaph_mean 0.0364 (0.0687) alpha_min 0.0000 (0.0000) alpha_max 0.3359 (0.5350) lr 1.9980e-03 eta 0:11:45
epoch [3/50] batch [100/176] time 0.079 (0.083) data 0.000 (0.004) loss 1.2554 (1.3607) teacher_loss 0.2808 (0.3867) loss_zs_kd 0.1087 (0.0813) loss_oracle 0.9203 (0.9333) acc 93.7500 (85.8750) alaph_mean 0.0672 (0.0712) alpha_min 0.0000 (0.0000) alpha_max 0.4376 (0.5337) lr 1.9980e-03 eta 0:11:32
epoch [3/50] batch [120/176] time 0.082 (0.082) data 0.000 (0.003) loss 1.3301 (1.3605) teacher_loss 0.2727 (0.3828) loss_zs_kd 0.1192 (0.0813) loss_oracle 0.9978 (0.9371) acc 87.5000 (85.9635) alaph_mean 0.0665 (0.0701) alpha_min 0.0000 (0.0000) alpha_max 0.8710 (0.5365) lr 1.9980e-03 eta 0:11:26
epoch [3/50] batch [140/176] time 0.084 (0.082) data 0.000 (0.003) loss 1.2081 (1.3600) teacher_loss 0.2766 (0.3792) loss_zs_kd 0.1134 (0.0841) loss_oracle 0.8748 (0.9387) acc 87.5000 (86.1607) alaph_mean 0.1032 (0.0696) alpha_min 0.0000 (0.0000) alpha_max 0.5720 (0.5310) lr 1.9980e-03 eta 0:11:20
epoch [3/50] batch [160/176] time 0.087 (0.082) data 0.000 (0.002) loss 1.2956 (1.3601) teacher_loss 0.2881 (0.3812) loss_zs_kd 0.0949 (0.0857) loss_oracle 0.9600 (0.9361) acc 90.6250 (86.3086) alaph_mean 0.0412 (0.0708) alpha_min 0.0000 (0.0000) alpha_max 0.4247 (0.5382) lr 1.9980e-03 eta 0:11:16
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,172
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.5%
Checkpoint saved to icml/multi-dg/oracle/13_entropybaseweight_mixlogits/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,721
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 59.8%
******* Domain l best val acc:      89.7%, epoch: 3 *******
******* Domain l best val test acc: 64.8%, epoch: 3 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [4/50] batch [20/176] time 0.088 (0.118) data 0.000 (0.014) loss 1.3052 (1.3729) teacher_loss 0.3088 (0.3970) loss_zs_kd 0.0813 (0.0892) loss_oracle 0.9557 (0.9313) acc 93.7500 (85.9375) alaph_mean 0.0599 (0.0645) alpha_min 0.0000 (0.0000) alpha_max 0.5993 (0.4907) lr 1.9921e-03 eta 0:16:13
epoch [4/50] batch [40/176] time 0.092 (0.102) data 0.000 (0.007) loss 1.2482 (1.3515) teacher_loss 0.3335 (0.3794) loss_zs_kd 0.0670 (0.0799) loss_oracle 0.8813 (0.9321) acc 87.5000 (86.1719) alaph_mean 0.0878 (0.0666) alpha_min 0.0000 (0.0000) alpha_max 0.4877 (0.5180) lr 1.9921e-03 eta 0:13:58
epoch [4/50] batch [60/176] time 0.088 (0.096) data 0.001 (0.005) loss 1.3805 (1.3555) teacher_loss 0.3936 (0.3829) loss_zs_kd 0.0738 (0.0787) loss_oracle 0.9501 (0.9332) acc 75.0000 (85.9896) alaph_mean 0.0732 (0.0691) alpha_min 0.0000 (0.0000) alpha_max 0.7185 (0.5334) lr 1.9921e-03 eta 0:13:11
epoch [4/50] batch [80/176] time 0.091 (0.094) data 0.000 (0.004) loss 1.4181 (1.3516) teacher_loss 0.4214 (0.3812) loss_zs_kd 0.1154 (0.0798) loss_oracle 0.9390 (0.9304) acc 78.1250 (86.0938) alaph_mean 0.0673 (0.0717) alpha_min 0.0000 (0.0000) alpha_max 0.5056 (0.5363) lr 1.9921e-03 eta 0:12:52
epoch [4/50] batch [100/176] time 0.096 (0.095) data 0.000 (0.003) loss 1.1470 (1.3498) teacher_loss 0.1899 (0.3845) loss_zs_kd 0.0622 (0.0798) loss_oracle 0.9259 (0.9254) acc 93.7500 (85.9688) alaph_mean 0.0622 (0.0739) alpha_min 0.0000 (0.0000) alpha_max 0.4187 (0.5349) lr 1.9921e-03 eta 0:12:56
epoch [4/50] batch [120/176] time 0.085 (0.094) data 0.000 (0.003) loss 1.1227 (1.3572) teacher_loss 0.1672 (0.3899) loss_zs_kd 0.0899 (0.0835) loss_oracle 0.9105 (0.9255) acc 93.7500 (85.8854) alaph_mean 0.0747 (0.0727) alpha_min 0.0000 (0.0000) alpha_max 0.5401 (0.5331) lr 1.9921e-03 eta 0:12:43
epoch [4/50] batch [140/176] time 0.087 (0.093) data 0.000 (0.002) loss 1.5430 (1.3585) teacher_loss 0.6182 (0.3911) loss_zs_kd 0.1095 (0.0866) loss_oracle 0.8701 (0.9241) acc 81.2500 (85.8929) alaph_mean 0.0948 (0.0724) alpha_min 0.0000 (0.0000) alpha_max 0.4999 (0.5319) lr 1.9921e-03 eta 0:12:32
epoch [4/50] batch [160/176] time 0.094 (0.092) data 0.000 (0.002) loss 1.1591 (1.3533) teacher_loss 0.2524 (0.3871) loss_zs_kd 0.0960 (0.0867) loss_oracle 0.8587 (0.9228) acc 93.7500 (86.2500) alaph_mean 0.1100 (0.0728) alpha_min 0.0000 (0.0000) alpha_max 0.5787 (0.5329) lr 1.9921e-03 eta 0:12:26
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,184
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.0%
Checkpoint saved to icml/multi-dg/oracle/13_entropybaseweight_mixlogits/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,762
* accuracy: 66.3%
* error: 33.7%
* macro_f1: 60.1%
******* Domain l best val acc:      90.2%, epoch: 4 *******
******* Domain l best val test acc: 66.3%, epoch: 4 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [5/50] batch [20/176] time 0.072 (0.101) data 0.000 (0.018) loss 1.1953 (1.3116) teacher_loss 0.2654 (0.3516) loss_zs_kd 0.1003 (0.0989) loss_oracle 0.8797 (0.9105) acc 87.5000 (86.4062) alaph_mean 0.0855 (0.0712) alpha_min 0.0000 (0.0000) alpha_max 0.5605 (0.5224) lr 1.9823e-03 eta 0:13:36
epoch [5/50] batch [40/176] time 0.077 (0.090) data 0.000 (0.009) loss 1.3137 (1.3169) teacher_loss 0.3618 (0.3654) loss_zs_kd 0.0878 (0.0935) loss_oracle 0.9080 (0.9047) acc 90.6250 (87.1094) alaph_mean 0.0611 (0.0757) alpha_min 0.0000 (0.0000) alpha_max 0.5020 (0.5238) lr 1.9823e-03 eta 0:12:04
epoch [5/50] batch [60/176] time 0.081 (0.086) data 0.000 (0.006) loss 1.1029 (1.2946) teacher_loss 0.1898 (0.3476) loss_zs_kd 0.0644 (0.0871) loss_oracle 0.8808 (0.9035) acc 96.8750 (88.3854) alaph_mean 0.0789 (0.0735) alpha_min 0.0000 (0.0000) alpha_max 0.4687 (0.5086) lr 1.9823e-03 eta 0:11:30
epoch [5/50] batch [80/176] time 0.087 (0.085) data 0.000 (0.005) loss 1.3164 (1.3137) teacher_loss 0.3904 (0.3679) loss_zs_kd 0.0923 (0.0877) loss_oracle 0.8799 (0.9020) acc 84.3750 (87.5781) alaph_mean 0.0798 (0.0746) alpha_min 0.0000 (0.0000) alpha_max 0.5194 (0.5137) lr 1.9823e-03 eta 0:11:21
epoch [5/50] batch [100/176] time 0.088 (0.085) data 0.001 (0.004) loss 1.2495 (1.3181) teacher_loss 0.3250 (0.3723) loss_zs_kd 0.0731 (0.0874) loss_oracle 0.8880 (0.9021) acc 90.6250 (87.4688) alaph_mean 0.0747 (0.0742) alpha_min 0.0000 (0.0000) alpha_max 0.5548 (0.5123) lr 1.9823e-03 eta 0:11:20
epoch [5/50] batch [120/176] time 0.091 (0.085) data 0.000 (0.003) loss 1.3140 (1.3232) teacher_loss 0.3752 (0.3787) loss_zs_kd 0.0753 (0.0870) loss_oracle 0.9011 (0.9010) acc 84.3750 (87.0833) alaph_mean 0.0617 (0.0731) alpha_min 0.0000 (0.0000) alpha_max 0.4979 (0.5122) lr 1.9823e-03 eta 0:11:18
epoch [5/50] batch [140/176] time 0.083 (0.085) data 0.000 (0.003) loss 1.1466 (1.3258) teacher_loss 0.1699 (0.3788) loss_zs_kd 0.0705 (0.0868) loss_oracle 0.9414 (0.9036) acc 100.0000 (87.0312) alaph_mean 0.0592 (0.0714) alpha_min 0.0000 (0.0000) alpha_max 0.6998 (0.5164) lr 1.9823e-03 eta 0:11:15
epoch [5/50] batch [160/176] time 0.083 (0.087) data 0.000 (0.002) loss 1.2150 (1.3277) teacher_loss 0.2263 (0.3806) loss_zs_kd 0.0897 (0.0869) loss_oracle 0.9439 (0.9036) acc 90.6250 (86.7188) alaph_mean 0.0622 (0.0724) alpha_min -0.0000 (0.0000) alpha_max 0.6820 (0.5195) lr 1.9823e-03 eta 0:11:31
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,178
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,748
* accuracy: 65.8%
* error: 34.2%
* macro_f1: 60.6%
******* Domain l best val acc:      90.2%, epoch: 4 *******
******* Domain l best val test acc: 66.3%, epoch: 4 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [6/50] batch [20/176] time 0.085 (0.103) data 0.000 (0.012) loss 1.0727 (1.3035) teacher_loss 0.1866 (0.3393) loss_zs_kd 0.0910 (0.0873) loss_oracle 0.8406 (0.9206) acc 93.7500 (87.8125) alaph_mean 0.0856 (0.0715) alpha_min 0.0000 (0.0000) alpha_max 0.4779 (0.5383) lr 1.9686e-03 eta 0:13:29
epoch [6/50] batch [40/176] time 0.083 (0.091) data 0.000 (0.006) loss 1.2048 (1.3214) teacher_loss 0.3804 (0.3634) loss_zs_kd 0.0651 (0.0960) loss_oracle 0.7919 (0.9100) acc 81.2500 (87.5000) alaph_mean 0.1118 (0.0753) alpha_min 0.0000 (0.0000) alpha_max 0.4492 (0.5262) lr 1.9686e-03 eta 0:11:59
epoch [6/50] batch [60/176] time 0.076 (0.088) data 0.001 (0.004) loss 1.1920 (1.3280) teacher_loss 0.2174 (0.3721) loss_zs_kd 0.0843 (0.0951) loss_oracle 0.9324 (0.9084) acc 96.8750 (87.1354) alaph_mean 0.0642 (0.0744) alpha_min 0.0000 (0.0000) alpha_max 0.4872 (0.5258) lr 1.9686e-03 eta 0:11:34
epoch [6/50] batch [80/176] time 0.083 (0.087) data 0.000 (0.003) loss 1.0503 (1.3148) teacher_loss 0.2085 (0.3619) loss_zs_kd 0.0655 (0.0957) loss_oracle 0.8090 (0.9050) acc 93.7500 (87.7734) alaph_mean 0.1157 (0.0746) alpha_min 0.0000 (0.0000) alpha_max 0.6817 (0.5220) lr 1.9686e-03 eta 0:11:25
epoch [6/50] batch [100/176] time 0.099 (0.087) data 0.000 (0.003) loss 1.4059 (1.3235) teacher_loss 0.4490 (0.3699) loss_zs_kd 0.1075 (0.0945) loss_oracle 0.9032 (0.9063) acc 84.3750 (87.5000) alaph_mean 0.0472 (0.0719) alpha_min 0.0000 (0.0000) alpha_max 0.4974 (0.5172) lr 1.9686e-03 eta 0:11:20
epoch [6/50] batch [120/176] time 0.094 (0.087) data 0.000 (0.002) loss 1.4425 (1.3241) teacher_loss 0.4663 (0.3704) loss_zs_kd 0.0798 (0.0953) loss_oracle 0.9363 (0.9061) acc 81.2500 (87.2396) alaph_mean 0.0419 (0.0696) alpha_min 0.0000 (0.0000) alpha_max 0.5008 (0.5151) lr 1.9686e-03 eta 0:11:18
epoch [6/50] batch [140/176] time 0.082 (0.087) data 0.000 (0.002) loss 1.3992 (1.3198) teacher_loss 0.4221 (0.3685) loss_zs_kd 0.0993 (0.0950) loss_oracle 0.9274 (0.9039) acc 75.0000 (87.1652) alaph_mean 0.0448 (0.0686) alpha_min 0.0000 (0.0000) alpha_max 0.4003 (0.5158) lr 1.9686e-03 eta 0:11:14
epoch [6/50] batch [160/176] time 0.091 (0.086) data 0.001 (0.002) loss 1.3565 (1.3198) teacher_loss 0.4521 (0.3687) loss_zs_kd 0.1327 (0.0952) loss_oracle 0.8380 (0.9035) acc 78.1250 (87.0117) alaph_mean 0.0817 (0.0677) alpha_min 0.0000 (0.0000) alpha_max 0.4997 (0.5135) lr 1.9686e-03 eta 0:11:09
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,174
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,718
* accuracy: 64.7%
* error: 35.3%
* macro_f1: 58.9%
******* Domain l best val acc:      90.2%, epoch: 4 *******
******* Domain l best val test acc: 66.3%, epoch: 4 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [7/50] batch [20/176] time 0.080 (0.095) data 0.000 (0.017) loss 1.3542 (1.2897) teacher_loss 0.4402 (0.3438) loss_zs_kd 0.0833 (0.0900) loss_oracle 0.8724 (0.9009) acc 87.5000 (88.5938) alaph_mean 0.0804 (0.0693) alpha_min 0.0000 (0.0000) alpha_max 0.4995 (0.5395) lr 1.9511e-03 eta 0:12:16
epoch [7/50] batch [40/176] time 0.071 (0.082) data 0.000 (0.009) loss 1.3215 (1.2819) teacher_loss 0.2952 (0.3425) loss_zs_kd 0.1023 (0.0875) loss_oracle 0.9752 (0.8956) acc 87.5000 (87.9688) alaph_mean 0.0463 (0.0715) alpha_min 0.0000 (0.0000) alpha_max 0.6465 (0.5359) lr 1.9511e-03 eta 0:10:30
epoch [7/50] batch [60/176] time 0.079 (0.080) data 0.001 (0.006) loss 1.1894 (1.3078) teacher_loss 0.3096 (0.3768) loss_zs_kd 0.0707 (0.0887) loss_oracle 0.8445 (0.8866) acc 87.5000 (86.9792) alaph_mean 0.0542 (0.0682) alpha_min 0.0000 (0.0000) alpha_max 0.5001 (0.5236) lr 1.9511e-03 eta 0:10:12
epoch [7/50] batch [80/176] time 0.122 (0.079) data 0.000 (0.005) loss 1.0458 (1.3081) teacher_loss 0.1371 (0.3789) loss_zs_kd 0.0876 (0.0881) loss_oracle 0.8649 (0.8851) acc 96.8750 (86.4453) alaph_mean 0.0701 (0.0650) alpha_min -0.0000 (0.0000) alpha_max 0.4155 (0.5171) lr 1.9511e-03 eta 0:10:03
epoch [7/50] batch [100/176] time 0.068 (0.080) data 0.000 (0.004) loss 1.3991 (1.3035) teacher_loss 0.4531 (0.3719) loss_zs_kd 0.1018 (0.0898) loss_oracle 0.8950 (0.8867) acc 81.2500 (86.8750) alaph_mean 0.0536 (0.0626) alpha_min 0.0000 (0.0000) alpha_max 0.4993 (0.5083) lr 1.9511e-03 eta 0:10:12
epoch [7/50] batch [120/176] time 0.093 (0.080) data 0.000 (0.003) loss 1.4892 (1.3041) teacher_loss 0.6157 (0.3739) loss_zs_kd 0.0483 (0.0882) loss_oracle 0.8494 (0.8861) acc 81.2500 (86.8750) alaph_mean 0.0794 (0.0612) alpha_min 0.0000 (0.0000) alpha_max 0.5686 (0.5047) lr 1.9511e-03 eta 0:10:13
epoch [7/50] batch [140/176] time 0.078 (0.081) data 0.000 (0.003) loss 1.4585 (1.3065) teacher_loss 0.5039 (0.3770) loss_zs_kd 0.0721 (0.0873) loss_oracle 0.9185 (0.8858) acc 84.3750 (86.7188) alaph_mean 0.0394 (0.0598) alpha_min 0.0000 (0.0000) alpha_max 0.5015 (0.5000) lr 1.9511e-03 eta 0:10:12
epoch [7/50] batch [160/176] time 0.079 (0.081) data 0.000 (0.002) loss 1.5106 (1.3039) teacher_loss 0.5645 (0.3769) loss_zs_kd 0.0750 (0.0875) loss_oracle 0.9086 (0.8832) acc 81.2500 (86.5820) alaph_mean 0.0448 (0.0607) alpha_min -0.0000 (0.0000) alpha_max 0.5155 (0.5019) lr 1.9511e-03 eta 0:10:10
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,178
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,724
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 59.1%
******* Domain l best val acc:      90.2%, epoch: 4 *******
******* Domain l best val test acc: 66.3%, epoch: 4 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [8/50] batch [20/176] time 0.080 (0.098) data 0.000 (0.013) loss 1.0108 (1.2487) teacher_loss 0.1923 (0.3327) loss_zs_kd 0.0754 (0.0951) loss_oracle 0.7808 (0.8684) acc 96.8750 (88.7500) alaph_mean 0.1127 (0.0677) alpha_min 0.0000 (0.0000) alpha_max 0.6170 (0.5315) lr 1.9298e-03 eta 0:12:21
epoch [8/50] batch [40/176] time 0.083 (0.091) data 0.000 (0.007) loss 1.2064 (1.2864) teacher_loss 0.3149 (0.3573) loss_zs_kd 0.0634 (0.0912) loss_oracle 0.8597 (0.8835) acc 90.6250 (87.7344) alaph_mean 0.0721 (0.0656) alpha_min 0.0000 (0.0000) alpha_max 0.4021 (0.5145) lr 1.9298e-03 eta 0:11:22
epoch [8/50] batch [60/176] time 0.091 (0.088) data 0.001 (0.005) loss 1.2881 (1.2811) teacher_loss 0.3599 (0.3656) loss_zs_kd 0.0974 (0.0882) loss_oracle 0.8796 (0.8713) acc 90.6250 (87.3438) alaph_mean 0.0508 (0.0682) alpha_min 0.0000 (0.0000) alpha_max 0.4319 (0.5125) lr 1.9298e-03 eta 0:11:01
epoch [8/50] batch [80/176] time 0.085 (0.088) data 0.000 (0.004) loss 1.2431 (1.2779) teacher_loss 0.3000 (0.3656) loss_zs_kd 0.0621 (0.0884) loss_oracle 0.9120 (0.8681) acc 90.6250 (87.5391) alaph_mean 0.0486 (0.0695) alpha_min 0.0000 (0.0000) alpha_max 0.3468 (0.5105) lr 1.9298e-03 eta 0:10:55
epoch [8/50] batch [100/176] time 0.085 (0.087) data 0.000 (0.003) loss 1.2617 (1.2811) teacher_loss 0.3269 (0.3671) loss_zs_kd 0.0672 (0.0873) loss_oracle 0.9012 (0.8703) acc 84.3750 (87.4062) alaph_mean 0.0412 (0.0695) alpha_min 0.0000 (0.0000) alpha_max 0.3203 (0.5074) lr 1.9298e-03 eta 0:10:52
epoch [8/50] batch [120/176] time 0.084 (0.087) data 0.000 (0.002) loss 1.3468 (1.2869) teacher_loss 0.4912 (0.3693) loss_zs_kd 0.1042 (0.0864) loss_oracle 0.8035 (0.8743) acc 75.0000 (87.1875) alaph_mean 0.0966 (0.0676) alpha_min 0.0000 (0.0000) alpha_max 0.5154 (0.4969) lr 1.9298e-03 eta 0:10:46
epoch [8/50] batch [140/176] time 0.091 (0.086) data 0.000 (0.002) loss 1.3103 (1.2865) teacher_loss 0.3481 (0.3699) loss_zs_kd 0.0627 (0.0859) loss_oracle 0.9308 (0.8736) acc 81.2500 (87.0759) alaph_mean 0.0441 (0.0670) alpha_min 0.0000 (0.0000) alpha_max 0.4608 (0.4996) lr 1.9298e-03 eta 0:10:42
epoch [8/50] batch [160/176] time 0.088 (0.086) data 0.000 (0.002) loss 1.2922 (1.2876) teacher_loss 0.3633 (0.3716) loss_zs_kd 0.1059 (0.0868) loss_oracle 0.8759 (0.8726) acc 87.5000 (87.0898) alaph_mean 0.0543 (0.0674) alpha_min 0.0000 (0.0000) alpha_max 0.4936 (0.5009) lr 1.9298e-03 eta 0:10:37
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,173
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,663
* accuracy: 62.6%
* error: 37.4%
* macro_f1: 58.0%
******* Domain l best val acc:      90.2%, epoch: 4 *******
******* Domain l best val test acc: 66.3%, epoch: 4 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [9/50] batch [20/176] time 0.073 (0.115) data 0.000 (0.014) loss 1.2269 (1.2676) teacher_loss 0.3733 (0.3810) loss_zs_kd 0.1004 (0.0797) loss_oracle 0.8034 (0.8468) acc 87.5000 (85.7812) alaph_mean 0.0936 (0.0670) alpha_min 0.0000 (0.0000) alpha_max 0.5426 (0.5431) lr 1.9048e-03 eta 0:14:04
epoch [9/50] batch [40/176] time 0.079 (0.097) data 0.000 (0.007) loss 1.5190 (1.2968) teacher_loss 0.6226 (0.4079) loss_zs_kd 0.0745 (0.0767) loss_oracle 0.8592 (0.8506) acc 71.8750 (84.9219) alaph_mean 0.0665 (0.0660) alpha_min 0.0000 (0.0000) alpha_max 0.6172 (0.5302) lr 1.9048e-03 eta 0:11:56
epoch [9/50] batch [60/176] time 0.084 (0.092) data 0.001 (0.005) loss 1.1505 (1.2797) teacher_loss 0.3110 (0.3894) loss_zs_kd 0.0758 (0.0806) loss_oracle 0.8016 (0.8500) acc 87.5000 (85.9375) alaph_mean 0.0974 (0.0684) alpha_min -0.0000 (0.0000) alpha_max 0.5837 (0.5306) lr 1.9048e-03 eta 0:11:13
epoch [9/50] batch [80/176] time 0.078 (0.089) data 0.000 (0.004) loss 1.2646 (1.2888) teacher_loss 0.3530 (0.3894) loss_zs_kd 0.1365 (0.0829) loss_oracle 0.8434 (0.8580) acc 84.3750 (86.4062) alaph_mean 0.0896 (0.0704) alpha_min 0.0000 (0.0000) alpha_max 0.5634 (0.5252) lr 1.9048e-03 eta 0:10:53
epoch [9/50] batch [100/176] time 0.080 (0.088) data 0.000 (0.003) loss 1.1530 (1.2906) teacher_loss 0.2729 (0.3868) loss_zs_kd 0.0911 (0.0835) loss_oracle 0.8345 (0.8621) acc 93.7500 (86.8750) alaph_mean 0.1048 (0.0723) alpha_min 0.0000 (0.0000) alpha_max 0.6711 (0.5275) lr 1.9048e-03 eta 0:10:42
epoch [9/50] batch [120/176] time 0.070 (0.087) data 0.000 (0.002) loss 1.5096 (1.2965) teacher_loss 0.6641 (0.3922) loss_zs_kd 0.1010 (0.0847) loss_oracle 0.7950 (0.8620) acc 78.1250 (86.5365) alaph_mean 0.0983 (0.0714) alpha_min 0.0000 (0.0000) alpha_max 0.5866 (0.5338) lr 1.9048e-03 eta 0:10:29
epoch [9/50] batch [140/176] time 0.091 (0.085) data 0.000 (0.002) loss 1.1806 (1.2944) teacher_loss 0.2439 (0.3859) loss_zs_kd 0.0843 (0.0839) loss_oracle 0.8946 (0.8666) acc 96.8750 (86.8304) alaph_mean 0.0829 (0.0705) alpha_min 0.0000 (0.0000) alpha_max 0.4715 (0.5340) lr 1.9048e-03 eta 0:10:18
epoch [9/50] batch [160/176] time 0.088 (0.085) data 0.000 (0.002) loss 1.4649 (1.3002) teacher_loss 0.4380 (0.3885) loss_zs_kd 0.0673 (0.0839) loss_oracle 0.9932 (0.8698) acc 87.5000 (86.5820) alaph_mean 0.0592 (0.0714) alpha_min 0.0000 (0.0000) alpha_max 0.8801 (0.5424) lr 1.9048e-03 eta 0:10:16
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,183
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,670
* accuracy: 62.9%
* error: 37.1%
* macro_f1: 58.1%
******* Domain l best val acc:      90.2%, epoch: 4 *******
******* Domain l best val test acc: 66.3%, epoch: 4 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [10/50] batch [20/176] time 0.069 (0.096) data 0.000 (0.018) loss 1.4836 (1.3447) teacher_loss 0.4651 (0.3917) loss_zs_kd 0.0897 (0.0889) loss_oracle 0.9736 (0.9086) acc 81.2500 (85.0000) alaph_mean 0.0497 (0.0631) alpha_min 0.0000 (0.0000) alpha_max 0.4106 (0.4718) lr 1.8763e-03 eta 0:11:29
epoch [10/50] batch [40/176] time 0.080 (0.084) data 0.000 (0.009) loss 1.1725 (1.2944) teacher_loss 0.3269 (0.3566) loss_zs_kd 0.0734 (0.0947) loss_oracle 0.8089 (0.8904) acc 84.3750 (86.7188) alaph_mean 0.0969 (0.0700) alpha_min 0.0000 (0.0000) alpha_max 0.5375 (0.4882) lr 1.8763e-03 eta 0:10:03
epoch [10/50] batch [60/176] time 0.073 (0.082) data 0.000 (0.006) loss 1.4306 (1.2971) teacher_loss 0.3611 (0.3641) loss_zs_kd 0.1327 (0.0959) loss_oracle 1.0032 (0.8851) acc 90.6250 (86.6146) alaph_mean 0.0335 (0.0724) alpha_min 0.0000 (0.0000) alpha_max 0.4996 (0.5013) lr 1.8763e-03 eta 0:09:49
epoch [10/50] batch [80/176] time 0.078 (0.081) data 0.000 (0.005) loss 1.3006 (1.2859) teacher_loss 0.4319 (0.3656) loss_zs_kd 0.0756 (0.0943) loss_oracle 0.8309 (0.8732) acc 84.3750 (86.7578) alaph_mean 0.0777 (0.0716) alpha_min 0.0000 (0.0000) alpha_max 0.6072 (0.5160) lr 1.8763e-03 eta 0:09:36
epoch [10/50] batch [100/176] time 0.070 (0.079) data 0.000 (0.004) loss 1.2820 (1.2850) teacher_loss 0.4802 (0.3767) loss_zs_kd 0.1126 (0.0930) loss_oracle 0.7455 (0.8618) acc 84.3750 (86.5312) alaph_mean 0.1165 (0.0708) alpha_min 0.0000 (0.0000) alpha_max 0.7611 (0.5152) lr 1.8763e-03 eta 0:09:21
epoch [10/50] batch [120/176] time 0.082 (0.079) data 0.000 (0.003) loss 1.4300 (1.2806) teacher_loss 0.5898 (0.3750) loss_zs_kd 0.0723 (0.0905) loss_oracle 0.8040 (0.8604) acc 81.2500 (86.3802) alaph_mean 0.0568 (0.0683) alpha_min -0.0000 (0.0000) alpha_max 0.4507 (0.5180) lr 1.8763e-03 eta 0:09:19
epoch [10/50] batch [140/176] time 0.064 (0.078) data 0.000 (0.003) loss 1.2068 (1.2787) teacher_loss 0.3672 (0.3776) loss_zs_kd 0.0742 (0.0902) loss_oracle 0.8025 (0.8560) acc 87.5000 (86.2723) alaph_mean 0.0675 (0.0671) alpha_min 0.0000 (0.0000) alpha_max 0.5483 (0.5172) lr 1.8763e-03 eta 0:09:11
epoch [10/50] batch [160/176] time 0.082 (0.077) data 0.000 (0.003) loss 1.0780 (1.2750) teacher_loss 0.2749 (0.3761) loss_zs_kd 0.0586 (0.0891) loss_oracle 0.7737 (0.8543) acc 93.7500 (86.2891) alaph_mean 0.1131 (0.0665) alpha_min -0.0000 (0.0000) alpha_max 0.5950 (0.5170) lr 1.8763e-03 eta 0:09:05
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,182
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,676
* accuracy: 63.1%
* error: 36.9%
* macro_f1: 58.2%
******* Domain l best val acc:      90.2%, epoch: 4 *******
******* Domain l best val test acc: 66.3%, epoch: 4 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [11/50] batch [20/176] time 0.082 (0.095) data 0.000 (0.014) loss 1.2512 (1.3118) teacher_loss 0.4219 (0.4015) loss_zs_kd 0.1263 (0.1044) loss_oracle 0.7662 (0.8581) acc 93.7500 (85.7812) alaph_mean 0.0875 (0.0622) alpha_min 0.0000 (0.0000) alpha_max 0.5022 (0.4901) lr 1.8443e-03 eta 0:11:05
epoch [11/50] batch [40/176] time 0.079 (0.088) data 0.000 (0.007) loss 1.3291 (1.2694) teacher_loss 0.4744 (0.3794) loss_zs_kd 0.0822 (0.0921) loss_oracle 0.8137 (0.8439) acc 84.3750 (87.1875) alaph_mean 0.0999 (0.0611) alpha_min 0.0000 (0.0000) alpha_max 0.8981 (0.5132) lr 1.8443e-03 eta 0:10:15
epoch [11/50] batch [60/176] time 0.083 (0.086) data 0.001 (0.005) loss 1.2541 (1.2742) teacher_loss 0.4578 (0.3857) loss_zs_kd 0.1405 (0.0916) loss_oracle 0.7261 (0.8427) acc 84.3750 (87.0312) alaph_mean 0.1378 (0.0626) alpha_min 0.0000 (0.0000) alpha_max 0.5801 (0.5150) lr 1.8443e-03 eta 0:10:03
epoch [11/50] batch [80/176] time 0.079 (0.085) data 0.000 (0.004) loss 1.4942 (1.2916) teacher_loss 0.5474 (0.3917) loss_zs_kd 0.0778 (0.0885) loss_oracle 0.9079 (0.8556) acc 84.3750 (86.7188) alaph_mean 0.0804 (0.0655) alpha_min 0.0000 (0.0000) alpha_max 0.5107 (0.5162) lr 1.8443e-03 eta 0:09:49
epoch [11/50] batch [100/176] time 0.080 (0.084) data 0.000 (0.003) loss 1.4259 (1.2845) teacher_loss 0.4250 (0.3760) loss_zs_kd 0.0607 (0.0870) loss_oracle 0.9705 (0.8650) acc 84.3750 (87.3750) alaph_mean 0.0489 (0.0665) alpha_min 0.0000 (0.0000) alpha_max 0.4561 (0.5188) lr 1.8443e-03 eta 0:09:42
epoch [11/50] batch [120/176] time 0.079 (0.084) data 0.000 (0.003) loss 1.0828 (1.2858) teacher_loss 0.2091 (0.3751) loss_zs_kd 0.0822 (0.0874) loss_oracle 0.8326 (0.8670) acc 90.6250 (87.1875) alaph_mean 0.0644 (0.0670) alpha_min 0.0000 (0.0000) alpha_max 0.4980 (0.5175) lr 1.8443e-03 eta 0:09:44
epoch [11/50] batch [140/176] time 0.083 (0.084) data 0.000 (0.002) loss 1.3709 (1.2853) teacher_loss 0.4683 (0.3779) loss_zs_kd 0.0865 (0.0870) loss_oracle 0.8594 (0.8638) acc 87.5000 (87.0759) alaph_mean 0.0803 (0.0668) alpha_min 0.0000 (0.0000) alpha_max 0.8373 (0.5268) lr 1.8443e-03 eta 0:09:39
epoch [11/50] batch [160/176] time 0.081 (0.084) data 0.000 (0.002) loss 1.1207 (1.2870) teacher_loss 0.2795 (0.3838) loss_zs_kd 0.0912 (0.0865) loss_oracle 0.7956 (0.8600) acc 87.5000 (86.7773) alaph_mean 0.1060 (0.0657) alpha_min 0.0000 (0.0000) alpha_max 0.9011 (0.5312) lr 1.8443e-03 eta 0:09:38
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,186
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.1%
Checkpoint saved to icml/multi-dg/oracle/13_entropybaseweight_mixlogits/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,777
* accuracy: 66.9%
* error: 33.1%
* macro_f1: 60.2%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 66.9%, epoch: 11 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [12/50] batch [20/176] time 0.086 (0.098) data 0.000 (0.014) loss 1.1730 (1.2669) teacher_loss 0.2603 (0.3737) loss_zs_kd 0.0665 (0.0862) loss_oracle 0.8795 (0.8500) acc 96.8750 (85.7812) alaph_mean 0.0522 (0.0707) alpha_min 0.0000 (0.0000) alpha_max 0.4346 (0.5012) lr 1.8090e-03 eta 0:11:10
epoch [12/50] batch [40/176] time 0.091 (0.090) data 0.000 (0.007) loss 1.3841 (1.2588) teacher_loss 0.4746 (0.3716) loss_zs_kd 0.0555 (0.0848) loss_oracle 0.8818 (0.8448) acc 84.3750 (86.3281) alaph_mean 0.0394 (0.0723) alpha_min -0.0000 (0.0000) alpha_max 0.4715 (0.5210) lr 1.8090e-03 eta 0:10:15
epoch [12/50] batch [60/176] time 0.088 (0.087) data 0.001 (0.005) loss 1.3888 (1.2509) teacher_loss 0.5181 (0.3664) loss_zs_kd 0.1055 (0.0891) loss_oracle 0.8180 (0.8399) acc 75.0000 (86.5104) alaph_mean 0.0783 (0.0737) alpha_min 0.0000 (0.0000) alpha_max 0.6427 (0.5460) lr 1.8090e-03 eta 0:09:52
epoch [12/50] batch [80/176] time 0.088 (0.086) data 0.000 (0.004) loss 1.1272 (1.2428) teacher_loss 0.2788 (0.3623) loss_zs_kd 0.0928 (0.0878) loss_oracle 0.8020 (0.8366) acc 87.5000 (86.8750) alaph_mean 0.0865 (0.0744) alpha_min 0.0000 (0.0000) alpha_max 0.4746 (0.5501) lr 1.8090e-03 eta 0:09:42
epoch [12/50] batch [100/176] time 0.073 (0.084) data 0.000 (0.003) loss 1.1662 (1.2489) teacher_loss 0.2382 (0.3646) loss_zs_kd 0.0505 (0.0880) loss_oracle 0.9028 (0.8403) acc 90.6250 (86.7188) alaph_mean 0.0716 (0.0744) alpha_min 0.0000 (0.0000) alpha_max 0.6538 (0.5602) lr 1.8090e-03 eta 0:09:29
epoch [12/50] batch [120/176] time 0.060 (0.082) data 0.000 (0.003) loss 1.1216 (1.2520) teacher_loss 0.2419 (0.3622) loss_zs_kd 0.0486 (0.0871) loss_oracle 0.8554 (0.8462) acc 96.8750 (86.9010) alaph_mean 0.0926 (0.0731) alpha_min 0.0000 (0.0000) alpha_max 0.5202 (0.5559) lr 1.8090e-03 eta 0:09:16
epoch [12/50] batch [140/176] time 0.080 (0.084) data 0.000 (0.002) loss 1.5030 (1.2565) teacher_loss 0.5581 (0.3625) loss_zs_kd 0.0706 (0.0874) loss_oracle 0.9096 (0.8503) acc 81.2500 (86.9866) alaph_mean 0.0573 (0.0724) alpha_min 0.0000 (0.0000) alpha_max 0.4859 (0.5482) lr 1.8090e-03 eta 0:09:23
epoch [12/50] batch [160/176] time 0.061 (0.083) data 0.000 (0.002) loss 1.2247 (1.2583) teacher_loss 0.3567 (0.3642) loss_zs_kd 0.0793 (0.0874) loss_oracle 0.8284 (0.8505) acc 84.3750 (86.9727) alaph_mean 0.0928 (0.0734) alpha_min 0.0000 (0.0000) alpha_max 0.8095 (0.5516) lr 1.8090e-03 eta 0:09:15
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,180
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,655
* accuracy: 62.3%
* error: 37.7%
* macro_f1: 57.7%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 66.9%, epoch: 11 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [13/50] batch [20/176] time 0.085 (0.099) data 0.000 (0.015) loss 1.5927 (1.3058) teacher_loss 0.5479 (0.3961) loss_zs_kd 0.0664 (0.0848) loss_oracle 1.0117 (0.8672) acc 78.1250 (85.4688) alaph_mean 0.0193 (0.0706) alpha_min 0.0000 (0.0000) alpha_max 0.3725 (0.5408) lr 1.7705e-03 eta 0:10:59
epoch [13/50] batch [40/176] time 0.088 (0.092) data 0.000 (0.008) loss 1.2543 (1.2695) teacher_loss 0.3523 (0.3772) loss_zs_kd 0.0749 (0.0845) loss_oracle 0.8645 (0.8500) acc 81.2500 (86.1719) alaph_mean 0.0773 (0.0780) alpha_min 0.0000 (0.0000) alpha_max 0.4339 (0.5535) lr 1.7705e-03 eta 0:10:12
epoch [13/50] batch [60/176] time 0.087 (0.090) data 0.000 (0.005) loss 1.1801 (1.2643) teacher_loss 0.2534 (0.3715) loss_zs_kd 0.0695 (0.0849) loss_oracle 0.8920 (0.8504) acc 93.7500 (86.4062) alaph_mean 0.0559 (0.0777) alpha_min 0.0000 (0.0000) alpha_max 0.5013 (0.5403) lr 1.7705e-03 eta 0:09:54
epoch [13/50] batch [80/176] time 0.087 (0.088) data 0.001 (0.004) loss 1.1682 (1.2775) teacher_loss 0.2800 (0.3879) loss_zs_kd 0.0830 (0.0865) loss_oracle 0.8466 (0.8463) acc 93.7500 (86.1719) alaph_mean 0.0880 (0.0786) alpha_min 0.0000 (0.0000) alpha_max 0.5009 (0.5384) lr 1.7705e-03 eta 0:09:43
epoch [13/50] batch [100/176] time 0.084 (0.088) data 0.000 (0.003) loss 1.0625 (1.2713) teacher_loss 0.1353 (0.3813) loss_zs_kd 0.0973 (0.0878) loss_oracle 0.8786 (0.8461) acc 93.7500 (86.3750) alaph_mean 0.0431 (0.0756) alpha_min 0.0000 (0.0000) alpha_max 0.4087 (0.5265) lr 1.7705e-03 eta 0:09:40
epoch [13/50] batch [120/176] time 0.084 (0.088) data 0.000 (0.003) loss 1.1808 (1.2615) teacher_loss 0.3669 (0.3746) loss_zs_kd 0.0691 (0.0871) loss_oracle 0.7793 (0.8434) acc 81.2500 (86.6406) alaph_mean 0.0484 (0.0721) alpha_min 0.0000 (0.0000) alpha_max 0.4043 (0.5271) lr 1.7705e-03 eta 0:09:35
epoch [13/50] batch [140/176] time 0.095 (0.087) data 0.000 (0.002) loss 1.1612 (1.2590) teacher_loss 0.3542 (0.3750) loss_zs_kd 0.0798 (0.0883) loss_oracle 0.7671 (0.8398) acc 84.3750 (86.7188) alaph_mean 0.0739 (0.0703) alpha_min 0.0000 (0.0000) alpha_max 0.5000 (0.5250) lr 1.7705e-03 eta 0:09:30
epoch [13/50] batch [160/176] time 0.080 (0.087) data 0.000 (0.002) loss 1.2231 (1.2460) teacher_loss 0.3770 (0.3670) loss_zs_kd 0.0746 (0.0887) loss_oracle 0.8089 (0.8346) acc 87.5000 (87.0312) alaph_mean 0.0507 (0.0704) alpha_min 0.0000 (0.0000) alpha_max 0.5704 (0.5365) lr 1.7705e-03 eta 0:09:27
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,184
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,730
* accuracy: 65.1%
* error: 34.9%
* macro_f1: 59.2%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 66.9%, epoch: 11 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [14/50] batch [20/176] time 0.100 (0.097) data 0.001 (0.013) loss 1.1886 (1.2129) teacher_loss 0.3445 (0.3525) loss_zs_kd 0.0886 (0.0990) loss_oracle 0.7998 (0.8109) acc 93.7500 (88.5938) alaph_mean 0.0721 (0.0690) alpha_min 0.0000 (0.0000) alpha_max 0.7723 (0.5514) lr 1.7290e-03 eta 0:10:27
epoch [14/50] batch [40/176] time 0.080 (0.090) data 0.000 (0.006) loss 1.0716 (1.2228) teacher_loss 0.3267 (0.3671) loss_zs_kd 0.1220 (0.0964) loss_oracle 0.6839 (0.8075) acc 87.5000 (87.3438) alaph_mean 0.0972 (0.0626) alpha_min 0.0000 (0.0000) alpha_max 0.8379 (0.5374) lr 1.7290e-03 eta 0:09:39
epoch [14/50] batch [60/176] time 0.089 (0.085) data 0.001 (0.004) loss 1.2897 (1.2240) teacher_loss 0.5015 (0.3718) loss_zs_kd 0.1126 (0.0908) loss_oracle 0.7319 (0.8068) acc 78.1250 (87.5000) alaph_mean 0.0536 (0.0646) alpha_min 0.0000 (0.0000) alpha_max 0.4828 (0.5450) lr 1.7290e-03 eta 0:09:08
epoch [14/50] batch [80/176] time 0.061 (0.088) data 0.000 (0.003) loss 1.3872 (1.2364) teacher_loss 0.4626 (0.3863) loss_zs_kd 0.0795 (0.0865) loss_oracle 0.8849 (0.8069) acc 87.5000 (87.0703) alaph_mean 0.0592 (0.0692) alpha_min 0.0000 (0.0000) alpha_max 0.7091 (0.5639) lr 1.7290e-03 eta 0:09:24
epoch [14/50] batch [100/176] time 0.088 (0.085) data 0.000 (0.003) loss 1.0494 (1.2325) teacher_loss 0.1621 (0.3790) loss_zs_kd 0.1083 (0.0860) loss_oracle 0.8331 (0.8105) acc 96.8750 (87.2188) alaph_mean 0.0637 (0.0688) alpha_min 0.0000 (0.0000) alpha_max 0.4150 (0.5582) lr 1.7290e-03 eta 0:09:03
epoch [14/50] batch [120/176] time 0.063 (0.083) data 0.000 (0.002) loss 1.1235 (1.2414) teacher_loss 0.2380 (0.3782) loss_zs_kd 0.0712 (0.0865) loss_oracle 0.8499 (0.8200) acc 93.7500 (87.0312) alaph_mean 0.0645 (0.0679) alpha_min 0.0000 (0.0000) alpha_max 0.6494 (0.5534) lr 1.7290e-03 eta 0:08:53
epoch [14/50] batch [140/176] time 0.073 (0.082) data 0.000 (0.002) loss 1.1339 (1.2388) teacher_loss 0.1742 (0.3763) loss_zs_kd 0.0834 (0.0872) loss_oracle 0.9180 (0.8189) acc 96.8750 (87.0982) alaph_mean 0.0416 (0.0699) alpha_min 0.0000 (0.0000) alpha_max 0.4944 (0.5548) lr 1.7290e-03 eta 0:08:42
epoch [14/50] batch [160/176] time 0.071 (0.081) data 0.000 (0.002) loss 1.2014 (1.2454) teacher_loss 0.2668 (0.3769) loss_zs_kd 0.0752 (0.0870) loss_oracle 0.8970 (0.8250) acc 90.6250 (87.1094) alaph_mean 0.0816 (0.0707) alpha_min 0.0000 (0.0000) alpha_max 0.7999 (0.5645) lr 1.7290e-03 eta 0:08:32
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,181
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,678
* accuracy: 63.2%
* error: 36.8%
* macro_f1: 58.6%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 66.9%, epoch: 11 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [15/50] batch [20/176] time 0.080 (0.103) data 0.000 (0.018) loss 1.3767 (1.2642) teacher_loss 0.3965 (0.3817) loss_zs_kd 0.0907 (0.0870) loss_oracle 0.9348 (0.8390) acc 84.3750 (86.7188) alaph_mean 0.0541 (0.0845) alpha_min 0.0000 (0.0000) alpha_max 0.7492 (0.5867) lr 1.6845e-03 eta 0:10:51
epoch [15/50] batch [40/176] time 0.078 (0.092) data 0.000 (0.009) loss 1.1345 (1.2369) teacher_loss 0.3447 (0.3642) loss_zs_kd 0.1480 (0.0877) loss_oracle 0.7158 (0.8288) acc 87.5000 (86.9531) alaph_mean 0.1193 (0.0805) alpha_min 0.0000 (0.0000) alpha_max 0.6251 (0.5718) lr 1.6845e-03 eta 0:09:41
epoch [15/50] batch [60/176] time 0.082 (0.089) data 0.000 (0.006) loss 1.0522 (1.2303) teacher_loss 0.2864 (0.3629) loss_zs_kd 0.0710 (0.0874) loss_oracle 0.7303 (0.8237) acc 90.6250 (86.7708) alaph_mean 0.1219 (0.0847) alpha_min 0.0000 (0.0000) alpha_max 0.5537 (0.5863) lr 1.6845e-03 eta 0:09:21
epoch [15/50] batch [80/176] time 0.086 (0.088) data 0.000 (0.005) loss 1.1624 (1.2245) teacher_loss 0.3706 (0.3660) loss_zs_kd 0.0628 (0.0913) loss_oracle 0.7604 (0.8128) acc 87.5000 (86.6406) alaph_mean 0.0435 (0.0851) alpha_min 0.0000 (0.0000) alpha_max 0.4073 (0.5958) lr 1.6845e-03 eta 0:09:12
epoch [15/50] batch [100/176] time 0.079 (0.088) data 0.000 (0.004) loss 1.2070 (1.2242) teacher_loss 0.3816 (0.3638) loss_zs_kd 0.0972 (0.0932) loss_oracle 0.7768 (0.8139) acc 87.5000 (86.9062) alaph_mean 0.1099 (0.0811) alpha_min 0.0000 (0.0000) alpha_max 0.6710 (0.5957) lr 1.6845e-03 eta 0:09:08
epoch [15/50] batch [120/176] time 0.082 (0.087) data 0.000 (0.003) loss 1.1947 (1.2313) teacher_loss 0.2810 (0.3623) loss_zs_kd 0.1195 (0.0925) loss_oracle 0.8539 (0.8227) acc 90.6250 (86.9271) alaph_mean 0.0855 (0.0790) alpha_min 0.0000 (0.0000) alpha_max 0.5727 (0.5881) lr 1.6845e-03 eta 0:09:03
epoch [15/50] batch [140/176] time 0.089 (0.087) data 0.000 (0.003) loss 1.1881 (1.2323) teacher_loss 0.3120 (0.3610) loss_zs_kd 0.0627 (0.0908) loss_oracle 0.8447 (0.8259) acc 87.5000 (86.9643) alaph_mean 0.1221 (0.0789) alpha_min 0.0000 (0.0000) alpha_max 0.8524 (0.5834) lr 1.6845e-03 eta 0:09:00
epoch [15/50] batch [160/176] time 0.086 (0.087) data 0.000 (0.003) loss 1.4511 (1.2358) teacher_loss 0.4458 (0.3617) loss_zs_kd 0.0776 (0.0894) loss_oracle 0.9665 (0.8294) acc 78.1250 (86.9922) alaph_mean 0.0326 (0.0793) alpha_min 0.0000 (0.0000) alpha_max 0.4448 (0.5868) lr 1.6845e-03 eta 0:08:58
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.8%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,698
* accuracy: 63.9%
* error: 36.1%
* macro_f1: 58.6%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 66.9%, epoch: 11 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [16/50] batch [20/176] time 0.083 (0.106) data 0.000 (0.023) loss 1.6174 (1.2635) teacher_loss 0.7373 (0.3852) loss_zs_kd 0.1011 (0.0869) loss_oracle 0.8295 (0.8349) acc 68.7500 (85.7812) alaph_mean 0.0992 (0.0746) alpha_min 0.0000 (0.0000) alpha_max 0.8877 (0.6313) lr 1.6374e-03 eta 0:10:53
epoch [16/50] batch [40/176] time 0.081 (0.097) data 0.000 (0.012) loss 1.1116 (1.2350) teacher_loss 0.3706 (0.3690) loss_zs_kd 0.0992 (0.0855) loss_oracle 0.6915 (0.8233) acc 93.7500 (86.7188) alaph_mean 0.1330 (0.0758) alpha_min 0.0000 (0.0000) alpha_max 0.5032 (0.6078) lr 1.6374e-03 eta 0:09:55
epoch [16/50] batch [60/176] time 0.082 (0.093) data 0.001 (0.008) loss 1.1228 (1.2402) teacher_loss 0.2546 (0.3751) loss_zs_kd 0.0759 (0.0853) loss_oracle 0.8302 (0.8224) acc 93.7500 (86.8229) alaph_mean 0.0391 (0.0770) alpha_min 0.0000 (0.0000) alpha_max 0.4187 (0.6124) lr 1.6374e-03 eta 0:09:25
epoch [16/50] batch [80/176] time 0.080 (0.090) data 0.000 (0.006) loss 1.4075 (1.2463) teacher_loss 0.5464 (0.3800) loss_zs_kd 0.0749 (0.0878) loss_oracle 0.8236 (0.8224) acc 81.2500 (86.7578) alaph_mean 0.0730 (0.0760) alpha_min 0.0000 (0.0000) alpha_max 0.7933 (0.6347) lr 1.6374e-03 eta 0:09:08
epoch [16/50] batch [100/176] time 0.082 (0.089) data 0.000 (0.005) loss 1.1333 (1.2416) teacher_loss 0.3513 (0.3789) loss_zs_kd 0.0410 (0.0866) loss_oracle 0.7615 (0.8194) acc 90.6250 (86.7188) alaph_mean 0.1261 (0.0783) alpha_min 0.0000 (0.0000) alpha_max 0.5321 (0.6276) lr 1.6374e-03 eta 0:08:59
epoch [16/50] batch [120/176] time 0.090 (0.088) data 0.000 (0.004) loss 1.1989 (1.2449) teacher_loss 0.3015 (0.3779) loss_zs_kd 0.1006 (0.0851) loss_oracle 0.8470 (0.8245) acc 87.5000 (86.4583) alaph_mean 0.0431 (0.0789) alpha_min 0.0000 (0.0000) alpha_max 0.4441 (0.6205) lr 1.6374e-03 eta 0:08:52
epoch [16/50] batch [140/176] time 0.087 (0.088) data 0.000 (0.004) loss 1.3167 (1.2401) teacher_loss 0.3440 (0.3685) loss_zs_kd 0.0844 (0.0836) loss_oracle 0.9305 (0.8299) acc 87.5000 (86.9643) alaph_mean 0.0224 (0.0772) alpha_min 0.0000 (0.0000) alpha_max 0.4489 (0.6098) lr 1.6374e-03 eta 0:08:48
epoch [16/50] batch [160/176] time 0.099 (0.088) data 0.000 (0.003) loss 1.1578 (1.2392) teacher_loss 0.3499 (0.3682) loss_zs_kd 0.0619 (0.0834) loss_oracle 0.7770 (0.8294) acc 87.5000 (87.0312) alaph_mean 0.1246 (0.0781) alpha_min 0.0000 (0.0000) alpha_max 0.7240 (0.6119) lr 1.6374e-03 eta 0:08:45
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,181
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,690
* accuracy: 63.6%
* error: 36.4%
* macro_f1: 58.4%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 66.9%, epoch: 11 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [17/50] batch [20/176] time 0.082 (0.101) data 0.000 (0.018) loss 1.2056 (1.2989) teacher_loss 0.2957 (0.4059) loss_zs_kd 0.0930 (0.0823) loss_oracle 0.8635 (0.8518) acc 93.7500 (86.0938) alaph_mean 0.1505 (0.0993) alpha_min 0.0000 (0.0000) alpha_max 0.6421 (0.6464) lr 1.5878e-03 eta 0:10:01
epoch [17/50] batch [40/176] time 0.083 (0.092) data 0.000 (0.009) loss 0.9978 (1.2944) teacher_loss 0.1887 (0.3820) loss_zs_kd 0.0779 (0.0806) loss_oracle 0.7702 (0.8720) acc 96.8750 (87.2656) alaph_mean 0.1014 (0.0921) alpha_min 0.0000 (0.0000) alpha_max 0.6160 (0.6347) lr 1.5878e-03 eta 0:09:05
epoch [17/50] batch [60/176] time 0.089 (0.089) data 0.001 (0.006) loss 1.2487 (1.3040) teacher_loss 0.3848 (0.3815) loss_zs_kd 0.0619 (0.0848) loss_oracle 0.8329 (0.8802) acc 87.5000 (87.4479) alaph_mean 0.1266 (0.0892) alpha_min 0.0000 (0.0000) alpha_max 0.6533 (0.6181) lr 1.5878e-03 eta 0:08:47
epoch [17/50] batch [80/176] time 0.084 (0.089) data 0.000 (0.005) loss 1.2296 (1.3049) teacher_loss 0.2959 (0.3809) loss_zs_kd 0.1093 (0.0871) loss_oracle 0.8790 (0.8804) acc 87.5000 (87.3438) alaph_mean 0.1034 (0.0899) alpha_min 0.0000 (0.0000) alpha_max 0.6766 (0.6217) lr 1.5878e-03 eta 0:08:45
epoch [17/50] batch [100/176] time 0.091 (0.089) data 0.000 (0.004) loss 1.2745 (1.3163) teacher_loss 0.2883 (0.3840) loss_zs_kd 0.0955 (0.0881) loss_oracle 0.9384 (0.8882) acc 93.7500 (87.4688) alaph_mean 0.0378 (0.0858) alpha_min 0.0000 (0.0000) alpha_max 0.3799 (0.6159) lr 1.5878e-03 eta 0:08:41
epoch [17/50] batch [120/176] time 0.085 (0.088) data 0.000 (0.003) loss 1.2477 (1.3129) teacher_loss 0.3140 (0.3841) loss_zs_kd 0.0888 (0.0871) loss_oracle 0.8893 (0.8853) acc 90.6250 (87.3438) alaph_mean 0.0457 (0.0848) alpha_min -0.0000 (0.0000) alpha_max 0.4368 (0.6085) lr 1.5878e-03 eta 0:08:36
epoch [17/50] batch [140/176] time 0.098 (0.088) data 0.000 (0.003) loss 1.2715 (1.2980) teacher_loss 0.4121 (0.3811) loss_zs_kd 0.1160 (0.0868) loss_oracle 0.8013 (0.8735) acc 84.3750 (87.2545) alaph_mean 0.0658 (0.0845) alpha_min 0.0000 (0.0000) alpha_max 0.6340 (0.6111) lr 1.5878e-03 eta 0:08:34
epoch [17/50] batch [160/176] time 0.086 (0.090) data 0.000 (0.002) loss 1.2944 (1.2868) teacher_loss 0.3269 (0.3756) loss_zs_kd 0.0852 (0.0865) loss_oracle 0.9249 (0.8680) acc 87.5000 (87.2461) alaph_mean 0.0617 (0.0839) alpha_min 0.0000 (0.0000) alpha_max 0.7105 (0.6104) lr 1.5878e-03 eta 0:08:44
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,186
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,705
* accuracy: 64.2%
* error: 35.8%
* macro_f1: 58.7%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 66.9%, epoch: 11 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [18/50] batch [20/176] time 0.066 (0.092) data 0.000 (0.017) loss 1.1957 (1.2849) teacher_loss 0.2937 (0.3509) loss_zs_kd 0.0956 (0.0927) loss_oracle 0.8542 (0.8877) acc 93.7500 (88.1250) alaph_mean 0.1068 (0.0746) alpha_min 0.0000 (0.0000) alpha_max 0.7395 (0.5477) lr 1.5358e-03 eta 0:08:50
epoch [18/50] batch [40/176] time 0.080 (0.082) data 0.000 (0.009) loss 1.4900 (1.2598) teacher_loss 0.4841 (0.3376) loss_zs_kd 0.1125 (0.0973) loss_oracle 0.9496 (0.8735) acc 78.1250 (88.7500) alaph_mean 0.0492 (0.0795) alpha_min 0.0000 (0.0000) alpha_max 0.6653 (0.5765) lr 1.5358e-03 eta 0:07:53
epoch [18/50] batch [60/176] time 0.070 (0.079) data 0.001 (0.006) loss 1.2318 (1.2712) teacher_loss 0.2671 (0.3687) loss_zs_kd 0.1292 (0.0977) loss_oracle 0.9001 (0.8536) acc 90.6250 (86.9792) alaph_mean 0.0473 (0.0796) alpha_min -0.0000 (0.0000) alpha_max 0.5666 (0.5793) lr 1.5358e-03 eta 0:07:31
epoch [18/50] batch [80/176] time 0.077 (0.077) data 0.000 (0.004) loss 1.1726 (1.2720) teacher_loss 0.2903 (0.3771) loss_zs_kd 0.0548 (0.0939) loss_oracle 0.8549 (0.8479) acc 93.7500 (86.8359) alaph_mean 0.0573 (0.0808) alpha_min 0.0000 (0.0000) alpha_max 0.5450 (0.5963) lr 1.5358e-03 eta 0:07:20
epoch [18/50] batch [100/176] time 0.074 (0.076) data 0.000 (0.004) loss 1.1370 (1.2609) teacher_loss 0.3232 (0.3746) loss_zs_kd 0.1019 (0.0927) loss_oracle 0.7628 (0.8399) acc 87.5000 (86.9375) alaph_mean 0.0619 (0.0808) alpha_min 0.0000 (0.0000) alpha_max 0.4531 (0.5924) lr 1.5358e-03 eta 0:07:13
epoch [18/50] batch [120/176] time 0.075 (0.075) data 0.000 (0.003) loss 1.2354 (1.2530) teacher_loss 0.4167 (0.3712) loss_zs_kd 0.0743 (0.0919) loss_oracle 0.7815 (0.8359) acc 90.6250 (87.2135) alaph_mean 0.0934 (0.0814) alpha_min 0.0000 (0.0000) alpha_max 0.5856 (0.5983) lr 1.5358e-03 eta 0:07:08
epoch [18/50] batch [140/176] time 0.063 (0.075) data 0.000 (0.003) loss 1.1784 (1.2520) teacher_loss 0.2267 (0.3660) loss_zs_kd 0.0799 (0.0893) loss_oracle 0.9118 (0.8414) acc 93.7500 (87.4554) alaph_mean 0.0688 (0.0821) alpha_min 0.0000 (0.0000) alpha_max 0.6609 (0.6108) lr 1.5358e-03 eta 0:07:07
epoch [18/50] batch [160/176] time 0.073 (0.075) data 0.000 (0.002) loss 1.3712 (1.2558) teacher_loss 0.4177 (0.3676) loss_zs_kd 0.0978 (0.0892) loss_oracle 0.9046 (0.8436) acc 78.1250 (87.5391) alaph_mean 0.0832 (0.0849) alpha_min 0.0000 (0.0000) alpha_max 0.6137 (0.6124) lr 1.5358e-03 eta 0:07:01
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,190
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.2%
Checkpoint saved to icml/multi-dg/oracle/13_entropybaseweight_mixlogits/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,745
* accuracy: 65.7%
* error: 34.3%
* macro_f1: 59.8%
******* Domain l best val acc:      90.4%, epoch: 18 *******
******* Domain l best val test acc: 65.7%, epoch: 18 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [19/50] batch [20/176] time 0.082 (0.100) data 0.000 (0.014) loss 1.6076 (1.3017) teacher_loss 0.6479 (0.3861) loss_zs_kd 0.0943 (0.0880) loss_oracle 0.9125 (0.8716) acc 75.0000 (86.0938) alaph_mean 0.0557 (0.0702) alpha_min 0.0000 (0.0000) alpha_max 0.5244 (0.5736) lr 1.4818e-03 eta 0:09:22
epoch [19/50] batch [40/176] time 0.080 (0.092) data 0.000 (0.007) loss 1.1700 (1.3054) teacher_loss 0.2070 (0.3894) loss_zs_kd 0.0855 (0.0912) loss_oracle 0.9203 (0.8704) acc 93.7500 (86.3281) alaph_mean 0.0823 (0.0753) alpha_min 0.0000 (0.0000) alpha_max 0.5731 (0.6021) lr 1.4818e-03 eta 0:08:32
epoch [19/50] batch [60/176] time 0.088 (0.089) data 0.001 (0.005) loss 1.2365 (1.3091) teacher_loss 0.3066 (0.3900) loss_zs_kd 0.0809 (0.0879) loss_oracle 0.8894 (0.8751) acc 90.6250 (85.8333) alaph_mean 0.0925 (0.0767) alpha_min 0.0000 (0.0000) alpha_max 0.5000 (0.5903) lr 1.4818e-03 eta 0:08:14
epoch [19/50] batch [80/176] time 0.084 (0.088) data 0.000 (0.004) loss 1.1512 (1.3012) teacher_loss 0.2966 (0.3773) loss_zs_kd 0.0685 (0.0884) loss_oracle 0.8204 (0.8797) acc 87.5000 (86.6016) alaph_mean 0.1226 (0.0783) alpha_min 0.0000 (0.0000) alpha_max 0.6793 (0.5916) lr 1.4818e-03 eta 0:08:06
epoch [19/50] batch [100/176] time 0.080 (0.091) data 0.000 (0.003) loss 1.3126 (1.2994) teacher_loss 0.4800 (0.3759) loss_zs_kd 0.0724 (0.0893) loss_oracle 0.7964 (0.8789) acc 81.2500 (86.6250) alaph_mean 0.1074 (0.0778) alpha_min 0.0000 (0.0000) alpha_max 0.6291 (0.5900) lr 1.4818e-03 eta 0:08:21
epoch [19/50] batch [120/176] time 0.082 (0.090) data 0.000 (0.003) loss 1.2545 (1.2981) teacher_loss 0.4495 (0.3730) loss_zs_kd 0.0993 (0.0903) loss_oracle 0.7554 (0.8799) acc 81.2500 (86.8750) alaph_mean 0.1022 (0.0770) alpha_min 0.0000 (0.0000) alpha_max 0.6757 (0.5816) lr 1.4818e-03 eta 0:08:14
epoch [19/50] batch [140/176] time 0.082 (0.089) data 0.000 (0.002) loss 1.2268 (1.2870) teacher_loss 0.3027 (0.3686) loss_zs_kd 0.0969 (0.0916) loss_oracle 0.8756 (0.8726) acc 93.7500 (87.0089) alaph_mean 0.0723 (0.0790) alpha_min 0.0000 (0.0000) alpha_max 0.6677 (0.5804) lr 1.4818e-03 eta 0:08:08
epoch [19/50] batch [160/176] time 0.080 (0.089) data 0.000 (0.002) loss 1.3647 (1.2795) teacher_loss 0.4673 (0.3614) loss_zs_kd 0.1036 (0.0920) loss_oracle 0.8456 (0.8721) acc 84.3750 (87.3047) alaph_mean 0.0670 (0.0798) alpha_min -0.0000 (0.0000) alpha_max 0.6327 (0.5803) lr 1.4818e-03 eta 0:08:05
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,191
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 92.2%
Checkpoint saved to icml/multi-dg/oracle/13_entropybaseweight_mixlogits/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,672
* accuracy: 63.0%
* error: 37.0%
* macro_f1: 58.7%
******* Domain l best val acc:      90.5%, epoch: 19 *******
******* Domain l best val test acc: 63.0%, epoch: 19 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [20/50] batch [20/176] time 0.073 (0.094) data 0.000 (0.016) loss 1.2804 (1.2589) teacher_loss 0.3538 (0.3554) loss_zs_kd 0.1052 (0.0885) loss_oracle 0.8740 (0.8593) acc 84.3750 (88.2812) alaph_mean 0.0295 (0.0585) alpha_min 0.0000 (0.0000) alpha_max 0.4990 (0.5179) lr 1.4258e-03 eta 0:08:28
epoch [20/50] batch [40/176] time 0.065 (0.080) data 0.000 (0.008) loss 1.0627 (1.2301) teacher_loss 0.1783 (0.3436) loss_zs_kd 0.0647 (0.0895) loss_oracle 0.8520 (0.8418) acc 93.7500 (88.5156) alaph_mean 0.0662 (0.0692) alpha_min 0.0000 (0.0000) alpha_max 0.4975 (0.5491) lr 1.4258e-03 eta 0:07:15
epoch [20/50] batch [60/176] time 0.062 (0.076) data 0.000 (0.006) loss 1.3218 (1.2447) teacher_loss 0.3584 (0.3482) loss_zs_kd 0.0884 (0.0945) loss_oracle 0.9192 (0.8492) acc 87.5000 (88.0729) alaph_mean 0.0668 (0.0711) alpha_min 0.0000 (0.0000) alpha_max 0.4141 (0.5451) lr 1.4258e-03 eta 0:06:50
epoch [20/50] batch [80/176] time 0.082 (0.076) data 0.000 (0.004) loss 1.3325 (1.2629) teacher_loss 0.3718 (0.3552) loss_zs_kd 0.0818 (0.0943) loss_oracle 0.9198 (0.8606) acc 87.5000 (87.9297) alaph_mean 0.0516 (0.0757) alpha_min 0.0000 (0.0000) alpha_max 0.4132 (0.5568) lr 1.4258e-03 eta 0:06:48
epoch [20/50] batch [100/176] time 0.060 (0.076) data 0.000 (0.003) loss 1.2525 (1.2680) teacher_loss 0.3875 (0.3591) loss_zs_kd 0.0590 (0.0915) loss_oracle 0.8356 (0.8632) acc 87.5000 (87.8750) alaph_mean 0.0925 (0.0785) alpha_min 0.0000 (0.0000) alpha_max 0.8289 (0.5611) lr 1.4258e-03 eta 0:06:48
epoch [20/50] batch [120/176] time 0.081 (0.076) data 0.000 (0.003) loss 1.3632 (1.2775) teacher_loss 0.3870 (0.3606) loss_zs_kd 0.1297 (0.0929) loss_oracle 0.9114 (0.8704) acc 84.3750 (87.6042) alaph_mean 0.0696 (0.0792) alpha_min -0.0000 (0.0000) alpha_max 0.7653 (0.5544) lr 1.4258e-03 eta 0:06:43
epoch [20/50] batch [140/176] time 0.058 (0.075) data 0.000 (0.003) loss 1.4059 (1.2801) teacher_loss 0.4014 (0.3593) loss_zs_kd 0.1524 (0.0930) loss_oracle 0.9283 (0.8744) acc 84.3750 (87.5000) alaph_mean 0.0963 (0.0805) alpha_min 0.0000 (0.0000) alpha_max 0.6898 (0.5556) lr 1.4258e-03 eta 0:06:40
epoch [20/50] batch [160/176] time 0.073 (0.074) data 0.000 (0.002) loss 1.2213 (1.2872) teacher_loss 0.2612 (0.3613) loss_zs_kd 0.0832 (0.0936) loss_oracle 0.9185 (0.8791) acc 93.7500 (87.5195) alaph_mean 0.0642 (0.0809) alpha_min 0.0000 (0.0000) alpha_max 0.7041 (0.5591) lr 1.4258e-03 eta 0:06:34
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,185
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,713
* accuracy: 64.5%
* error: 35.5%
* macro_f1: 58.8%
******* Domain l best val acc:      90.5%, epoch: 19 *******
******* Domain l best val test acc: 63.0%, epoch: 19 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [21/50] batch [20/176] time 0.077 (0.095) data 0.000 (0.014) loss 1.0691 (1.2813) teacher_loss 0.2007 (0.3642) loss_zs_kd 0.0814 (0.0961) loss_oracle 0.8277 (0.8690) acc 90.6250 (87.3438) alaph_mean 0.0934 (0.0778) alpha_min 0.0000 (0.0000) alpha_max 0.5776 (0.5808) lr 1.3681e-03 eta 0:08:20
epoch [21/50] batch [40/176] time 0.069 (0.100) data 0.000 (0.007) loss 1.2036 (1.2884) teacher_loss 0.2012 (0.3495) loss_zs_kd 0.0712 (0.0911) loss_oracle 0.9668 (0.8933) acc 93.7500 (87.8906) alaph_mean 0.0612 (0.0743) alpha_min 0.0000 (0.0000) alpha_max 0.5775 (0.5649) lr 1.3681e-03 eta 0:08:44
epoch [21/50] batch [60/176] time 0.083 (0.093) data 0.001 (0.005) loss 1.3184 (1.3132) teacher_loss 0.3389 (0.3585) loss_zs_kd 0.1323 (0.0921) loss_oracle 0.9134 (0.9086) acc 96.8750 (87.8646) alaph_mean 0.0674 (0.0733) alpha_min 0.0000 (0.0000) alpha_max 0.5025 (0.5599) lr 1.3681e-03 eta 0:08:05
epoch [21/50] batch [80/176] time 0.083 (0.091) data 0.000 (0.004) loss 1.3246 (1.3206) teacher_loss 0.3870 (0.3644) loss_zs_kd 0.0989 (0.0919) loss_oracle 0.8882 (0.9103) acc 96.8750 (87.5781) alaph_mean 0.0782 (0.0741) alpha_min 0.0000 (0.0000) alpha_max 0.4865 (0.5544) lr 1.3681e-03 eta 0:07:50
epoch [21/50] batch [100/176] time 0.082 (0.088) data 0.000 (0.003) loss 1.1511 (1.3197) teacher_loss 0.2556 (0.3683) loss_zs_kd 0.1202 (0.0907) loss_oracle 0.8354 (0.9060) acc 96.8750 (87.2500) alaph_mean 0.0886 (0.0751) alpha_min 0.0000 (0.0000) alpha_max 0.6670 (0.5588) lr 1.3681e-03 eta 0:07:35
epoch [21/50] batch [120/176] time 0.085 (0.087) data 0.000 (0.003) loss 1.3014 (1.3251) teacher_loss 0.5083 (0.3776) loss_zs_kd 0.0592 (0.0892) loss_oracle 0.7635 (0.9029) acc 81.2500 (86.8490) alaph_mean 0.1489 (0.0757) alpha_min 0.0000 (0.0000) alpha_max 0.4690 (0.5571) lr 1.3681e-03 eta 0:07:27
epoch [21/50] batch [140/176] time 0.082 (0.086) data 0.000 (0.002) loss 1.0954 (1.3122) teacher_loss 0.2186 (0.3722) loss_zs_kd 0.0763 (0.0892) loss_oracle 0.8386 (0.8953) acc 93.7500 (87.1429) alaph_mean 0.0833 (0.0773) alpha_min 0.0000 (0.0000) alpha_max 0.5059 (0.5614) lr 1.3681e-03 eta 0:07:20
epoch [21/50] batch [160/176] time 0.080 (0.085) data 0.000 (0.002) loss 1.2934 (1.3146) teacher_loss 0.3022 (0.3725) loss_zs_kd 0.0870 (0.0881) loss_oracle 0.9476 (0.8980) acc 90.6250 (87.0117) alaph_mean 0.0460 (0.0764) alpha_min 0.0000 (0.0000) alpha_max 0.4232 (0.5533) lr 1.3681e-03 eta 0:07:16
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,187
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,704
* accuracy: 64.2%
* error: 35.8%
* macro_f1: 58.9%
******* Domain l best val acc:      90.5%, epoch: 19 *******
******* Domain l best val test acc: 63.0%, epoch: 19 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [22/50] batch [20/176] time 0.076 (0.095) data 0.000 (0.015) loss 1.3202 (1.3078) teacher_loss 0.3804 (0.3733) loss_zs_kd 0.0646 (0.0939) loss_oracle 0.9075 (0.8876) acc 84.3750 (85.9375) alaph_mean 0.0644 (0.0831) alpha_min 0.0000 (0.0000) alpha_max 0.6549 (0.6132) lr 1.3090e-03 eta 0:08:03
epoch [22/50] batch [40/176] time 0.077 (0.088) data 0.000 (0.007) loss 1.1966 (1.2782) teacher_loss 0.4460 (0.3707) loss_zs_kd 0.0566 (0.0898) loss_oracle 0.7223 (0.8626) acc 84.3750 (87.0312) alaph_mean 0.0843 (0.0879) alpha_min 0.0000 (0.0000) alpha_max 0.4561 (0.6318) lr 1.3090e-03 eta 0:07:23
epoch [22/50] batch [60/176] time 0.081 (0.085) data 0.001 (0.005) loss 1.2043 (1.2719) teacher_loss 0.2820 (0.3678) loss_zs_kd 0.1034 (0.0879) loss_oracle 0.8706 (0.8602) acc 87.5000 (87.2396) alaph_mean 0.0692 (0.0878) alpha_min 0.0000 (0.0000) alpha_max 0.5000 (0.6361) lr 1.3090e-03 eta 0:07:10
epoch [22/50] batch [80/176] time 0.078 (0.084) data 0.000 (0.004) loss 1.3538 (1.2772) teacher_loss 0.3276 (0.3646) loss_zs_kd 0.0804 (0.0890) loss_oracle 0.9860 (0.8681) acc 90.6250 (87.3828) alaph_mean 0.0886 (0.0892) alpha_min 0.0000 (0.0000) alpha_max 0.7377 (0.6409) lr 1.3090e-03 eta 0:07:04
epoch [22/50] batch [100/176] time 0.087 (0.086) data 0.000 (0.003) loss 1.3471 (1.2900) teacher_loss 0.3298 (0.3700) loss_zs_kd 0.0875 (0.0892) loss_oracle 0.9735 (0.8754) acc 93.7500 (87.2500) alaph_mean 0.0964 (0.0920) alpha_min 0.0000 (0.0000) alpha_max 0.5099 (0.6423) lr 1.3090e-03 eta 0:07:08
epoch [22/50] batch [120/176] time 0.081 (0.086) data 0.000 (0.003) loss 1.6076 (1.2942) teacher_loss 0.6719 (0.3703) loss_zs_kd 0.1249 (0.0899) loss_oracle 0.8732 (0.8789) acc 81.2500 (87.1615) alaph_mean 0.0997 (0.0903) alpha_min -0.0000 (0.0000) alpha_max 0.7350 (0.6349) lr 1.3090e-03 eta 0:07:07
epoch [22/50] batch [140/176] time 0.089 (0.085) data 0.000 (0.002) loss 1.1946 (1.2891) teacher_loss 0.2482 (0.3656) loss_zs_kd 0.0948 (0.0891) loss_oracle 0.8991 (0.8789) acc 87.5000 (87.2768) alaph_mean 0.0710 (0.0889) alpha_min 0.0000 (0.0000) alpha_max 0.8582 (0.6332) lr 1.3090e-03 eta 0:07:03
epoch [22/50] batch [160/176] time 0.092 (0.085) data 0.000 (0.002) loss 1.3768 (1.2927) teacher_loss 0.4219 (0.3689) loss_zs_kd 0.0806 (0.0882) loss_oracle 0.9146 (0.8798) acc 81.2500 (87.1680) alaph_mean 0.0711 (0.0870) alpha_min 0.0000 (0.0000) alpha_max 0.5002 (0.6265) lr 1.3090e-03 eta 0:07:01
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,184
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,748
* accuracy: 65.8%
* error: 34.2%
* macro_f1: 59.6%
******* Domain l best val acc:      90.5%, epoch: 19 *******
******* Domain l best val test acc: 63.0%, epoch: 19 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [23/50] batch [20/176] time 0.081 (0.095) data 0.000 (0.013) loss 1.4318 (1.3400) teacher_loss 0.3743 (0.3956) loss_zs_kd 0.0764 (0.0787) loss_oracle 1.0193 (0.9051) acc 90.6250 (86.0938) alaph_mean 0.0420 (0.0765) alpha_min 0.0000 (0.0000) alpha_max 0.3764 (0.5515) lr 1.2487e-03 eta 0:07:44
epoch [23/50] batch [40/176] time 0.059 (0.086) data 0.000 (0.007) loss 1.2597 (1.3317) teacher_loss 0.3865 (0.3745) loss_zs_kd 0.0866 (0.0839) loss_oracle 0.8299 (0.9153) acc 81.2500 (87.0312) alaph_mean 0.1110 (0.0836) alpha_min 0.0000 (0.0000) alpha_max 0.5772 (0.5739) lr 1.2487e-03 eta 0:06:59
epoch [23/50] batch [60/176] time 0.075 (0.080) data 0.001 (0.004) loss 1.2495 (1.3390) teacher_loss 0.4216 (0.3802) loss_zs_kd 0.0657 (0.0864) loss_oracle 0.7951 (0.9156) acc 78.1250 (86.8750) alaph_mean 0.1151 (0.0860) alpha_min 0.0000 (0.0000) alpha_max 0.8166 (0.5658) lr 1.2487e-03 eta 0:06:30
epoch [23/50] batch [80/176] time 0.090 (0.079) data 0.000 (0.003) loss 1.5098 (1.3420) teacher_loss 0.4810 (0.3815) loss_zs_kd 0.0743 (0.0872) loss_oracle 0.9917 (0.9170) acc 84.3750 (86.7578) alaph_mean 0.0421 (0.0849) alpha_min 0.0000 (0.0000) alpha_max 0.4782 (0.5687) lr 1.2487e-03 eta 0:06:25
epoch [23/50] batch [100/176] time 0.082 (0.080) data 0.000 (0.003) loss 1.5881 (1.3300) teacher_loss 0.5103 (0.3734) loss_zs_kd 0.1082 (0.0881) loss_oracle 1.0238 (0.9126) acc 81.2500 (86.8438) alaph_mean 0.0163 (0.0860) alpha_min 0.0000 (0.0000) alpha_max 0.2284 (0.5654) lr 1.2487e-03 eta 0:06:24
epoch [23/50] batch [120/176] time 0.059 (0.079) data 0.000 (0.002) loss 1.0475 (1.3276) teacher_loss 0.1783 (0.3732) loss_zs_kd 0.0636 (0.0888) loss_oracle 0.8374 (0.9100) acc 93.7500 (86.9010) alaph_mean 0.1058 (0.0843) alpha_min 0.0000 (0.0000) alpha_max 0.8282 (0.5691) lr 1.2487e-03 eta 0:06:20
epoch [23/50] batch [140/176] time 0.083 (0.079) data 0.000 (0.002) loss 1.2550 (1.3204) teacher_loss 0.2974 (0.3750) loss_zs_kd 0.1025 (0.0891) loss_oracle 0.9064 (0.9009) acc 90.6250 (86.8304) alaph_mean 0.0914 (0.0868) alpha_min 0.0000 (0.0000) alpha_max 0.4587 (0.5728) lr 1.2487e-03 eta 0:06:16
epoch [23/50] batch [160/176] time 0.082 (0.079) data 0.000 (0.002) loss 1.3546 (1.3133) teacher_loss 0.3044 (0.3690) loss_zs_kd 0.0971 (0.0886) loss_oracle 1.0016 (0.8999) acc 93.7500 (87.1484) alaph_mean 0.0553 (0.0857) alpha_min 0.0000 (0.0000) alpha_max 0.4175 (0.5692) lr 1.2487e-03 eta 0:06:16
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,186
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,659
* accuracy: 62.5%
* error: 37.5%
* macro_f1: 58.0%
******* Domain l best val acc:      90.5%, epoch: 19 *******
******* Domain l best val test acc: 63.0%, epoch: 19 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [24/50] batch [20/176] time 0.072 (0.083) data 0.001 (0.012) loss 1.2914 (1.2837) teacher_loss 0.3396 (0.3460) loss_zs_kd 0.1241 (0.1056) loss_oracle 0.8898 (0.8848) acc 87.5000 (88.1250) alaph_mean 0.0700 (0.0835) alpha_min 0.0000 (0.0000) alpha_max 0.5379 (0.5603) lr 1.1874e-03 eta 0:06:32
epoch [24/50] batch [40/176] time 0.081 (0.078) data 0.000 (0.006) loss 1.1371 (1.2595) teacher_loss 0.2607 (0.3383) loss_zs_kd 0.0902 (0.0950) loss_oracle 0.8312 (0.8737) acc 93.7500 (88.0469) alaph_mean 0.1294 (0.0871) alpha_min 0.0000 (0.0000) alpha_max 0.8806 (0.5985) lr 1.1874e-03 eta 0:06:07
epoch [24/50] batch [60/176] time 0.062 (0.075) data 0.001 (0.004) loss 1.1905 (1.2760) teacher_loss 0.3396 (0.3611) loss_zs_kd 0.0821 (0.0963) loss_oracle 0.8099 (0.8668) acc 87.5000 (87.5521) alaph_mean 0.0576 (0.0875) alpha_min 0.0000 (0.0000) alpha_max 0.5299 (0.5857) lr 1.1874e-03 eta 0:05:53
epoch [24/50] batch [80/176] time 0.082 (0.075) data 0.000 (0.003) loss 1.2528 (1.2772) teacher_loss 0.3103 (0.3613) loss_zs_kd 0.0516 (0.0941) loss_oracle 0.9167 (0.8689) acc 87.5000 (87.5000) alaph_mean 0.0791 (0.0865) alpha_min 0.0000 (0.0000) alpha_max 0.6122 (0.5942) lr 1.1874e-03 eta 0:05:49
epoch [24/50] batch [100/176] time 0.059 (0.073) data 0.000 (0.003) loss 1.1237 (1.2771) teacher_loss 0.1708 (0.3582) loss_zs_kd 0.0542 (0.0941) loss_oracle 0.9259 (0.8718) acc 96.8750 (87.9062) alaph_mean 0.0906 (0.0890) alpha_min 0.0000 (0.0000) alpha_max 0.6626 (0.6048) lr 1.1874e-03 eta 0:05:40
epoch [24/50] batch [120/176] time 0.076 (0.072) data 0.000 (0.002) loss 1.1889 (1.2792) teacher_loss 0.2754 (0.3578) loss_zs_kd 0.0671 (0.0931) loss_oracle 0.8799 (0.8749) acc 87.5000 (87.7083) alaph_mean 0.1262 (0.0892) alpha_min 0.0000 (0.0000) alpha_max 0.7357 (0.6020) lr 1.1874e-03 eta 0:05:33
epoch [24/50] batch [140/176] time 0.065 (0.072) data 0.000 (0.002) loss 1.3404 (1.2800) teacher_loss 0.2959 (0.3535) loss_zs_kd 0.0914 (0.0925) loss_oracle 0.9989 (0.8803) acc 90.6250 (87.8125) alaph_mean 0.0684 (0.0891) alpha_min 0.0000 (0.0000) alpha_max 0.5359 (0.6091) lr 1.1874e-03 eta 0:05:31
epoch [24/50] batch [160/176] time 0.084 (0.073) data 0.000 (0.002) loss 1.5162 (1.2920) teacher_loss 0.4802 (0.3596) loss_zs_kd 0.0722 (0.0940) loss_oracle 0.9999 (0.8854) acc 84.3750 (87.5391) alaph_mean 0.0784 (0.0889) alpha_min 0.0000 (0.0000) alpha_max 0.7258 (0.6084) lr 1.1874e-03 eta 0:05:35
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,189
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,688
* accuracy: 63.6%
* error: 36.4%
* macro_f1: 58.9%
******* Domain l best val acc:      90.5%, epoch: 19 *******
******* Domain l best val test acc: 63.0%, epoch: 19 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [25/50] batch [20/176] time 0.080 (0.098) data 0.000 (0.015) loss 1.2536 (1.2967) teacher_loss 0.3452 (0.3554) loss_zs_kd 0.1073 (0.0890) loss_oracle 0.8547 (0.8967) acc 84.3750 (86.7188) alaph_mean 0.0622 (0.0836) alpha_min 0.0000 (0.0000) alpha_max 0.4086 (0.5618) lr 1.1253e-03 eta 0:07:25
epoch [25/50] batch [40/176] time 0.099 (0.089) data 0.000 (0.008) loss 1.2118 (1.2747) teacher_loss 0.3237 (0.3529) loss_zs_kd 0.0918 (0.0891) loss_oracle 0.8422 (0.8773) acc 87.5000 (87.5000) alaph_mean 0.1164 (0.0801) alpha_min 0.0000 (0.0000) alpha_max 0.5739 (0.5548) lr 1.1253e-03 eta 0:06:45
epoch [25/50] batch [60/176] time 0.080 (0.086) data 0.000 (0.005) loss 1.2548 (1.2668) teacher_loss 0.3840 (0.3472) loss_zs_kd 0.0898 (0.0910) loss_oracle 0.8259 (0.8742) acc 90.6250 (88.1250) alaph_mean 0.1322 (0.0830) alpha_min 0.0000 (0.0000) alpha_max 0.8908 (0.5718) lr 1.1253e-03 eta 0:06:27
epoch [25/50] batch [80/176] time 0.068 (0.085) data 0.000 (0.004) loss 1.1646 (1.2736) teacher_loss 0.2737 (0.3456) loss_zs_kd 0.0933 (0.0932) loss_oracle 0.8442 (0.8814) acc 87.5000 (88.2422) alaph_mean 0.1372 (0.0826) alpha_min 0.0000 (0.0000) alpha_max 0.7843 (0.5703) lr 1.1253e-03 eta 0:06:20
epoch [25/50] batch [100/176] time 0.073 (0.083) data 0.000 (0.003) loss 1.3135 (1.2829) teacher_loss 0.3816 (0.3542) loss_zs_kd 0.0729 (0.0931) loss_oracle 0.8955 (0.8821) acc 84.3750 (87.6875) alaph_mean 0.1074 (0.0854) alpha_min 0.0000 (0.0000) alpha_max 0.8422 (0.5895) lr 1.1253e-03 eta 0:06:12
epoch [25/50] batch [120/176] time 0.069 (0.083) data 0.000 (0.003) loss 1.4085 (1.2959) teacher_loss 0.5879 (0.3632) loss_zs_kd 0.0623 (0.0924) loss_oracle 0.7894 (0.8865) acc 78.1250 (87.5000) alaph_mean 0.1422 (0.0839) alpha_min 0.0000 (0.0000) alpha_max 0.8023 (0.5877) lr 1.1253e-03 eta 0:06:08
epoch [25/50] batch [140/176] time 0.078 (0.083) data 0.000 (0.002) loss 1.2560 (1.2971) teacher_loss 0.2418 (0.3667) loss_zs_kd 0.0541 (0.0927) loss_oracle 0.9871 (0.8840) acc 87.5000 (87.3438) alaph_mean 0.0777 (0.0854) alpha_min 0.0000 (0.0000) alpha_max 0.8078 (0.5960) lr 1.1253e-03 eta 0:06:09
epoch [25/50] batch [160/176] time 0.092 (0.084) data 0.000 (0.002) loss 1.3249 (1.2901) teacher_loss 0.4480 (0.3660) loss_zs_kd 0.0794 (0.0938) loss_oracle 0.8372 (0.8772) acc 84.3750 (87.2852) alaph_mean 0.0759 (0.0859) alpha_min 0.0000 (0.0000) alpha_max 0.5747 (0.6007) lr 1.1253e-03 eta 0:06:11
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,195
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 92.4%
Checkpoint saved to icml/multi-dg/oracle/13_entropybaseweight_mixlogits/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,693
* accuracy: 63.7%
* error: 36.3%
* macro_f1: 58.4%
******* Domain l best val acc:      90.6%, epoch: 25 *******
******* Domain l best val test acc: 63.7%, epoch: 25 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [26/50] batch [20/176] time 0.082 (0.104) data 0.000 (0.017) loss 1.2791 (1.2395) teacher_loss 0.4722 (0.3444) loss_zs_kd 0.0805 (0.0989) loss_oracle 0.7667 (0.8457) acc 87.5000 (90.3125) alaph_mean 0.1252 (0.0819) alpha_min 0.0000 (0.0000) alpha_max 0.5622 (0.6045) lr 1.0628e-03 eta 0:07:35
epoch [26/50] batch [40/176] time 0.085 (0.093) data 0.000 (0.009) loss 1.5524 (1.2863) teacher_loss 0.5376 (0.3821) loss_zs_kd 0.0933 (0.0945) loss_oracle 0.9681 (0.8570) acc 78.1250 (88.2031) alaph_mean 0.0556 (0.0840) alpha_min 0.0000 (0.0000) alpha_max 0.6031 (0.6166) lr 1.0628e-03 eta 0:06:46
epoch [26/50] batch [60/176] time 0.097 (0.090) data 0.002 (0.006) loss 1.1217 (1.2741) teacher_loss 0.3481 (0.3772) loss_zs_kd 0.0791 (0.0936) loss_oracle 0.7340 (0.8502) acc 84.3750 (87.7083) alaph_mean 0.1176 (0.0831) alpha_min -0.0000 (0.0000) alpha_max 0.7253 (0.6275) lr 1.0628e-03 eta 0:06:32
epoch [26/50] batch [80/176] time 0.078 (0.090) data 0.000 (0.005) loss 1.2134 (1.2738) teacher_loss 0.3054 (0.3772) loss_zs_kd 0.1059 (0.0962) loss_oracle 0.8550 (0.8484) acc 87.5000 (87.3438) alaph_mean 0.0359 (0.0845) alpha_min -0.0000 (0.0000) alpha_max 0.4027 (0.6168) lr 1.0628e-03 eta 0:06:28
epoch [26/50] batch [100/176] time 0.080 (0.093) data 0.000 (0.004) loss 1.2349 (1.2795) teacher_loss 0.2827 (0.3816) loss_zs_kd 0.1465 (0.0953) loss_oracle 0.8789 (0.8503) acc 84.3750 (86.8750) alaph_mean 0.0631 (0.0849) alpha_min 0.0000 (0.0000) alpha_max 0.4989 (0.6124) lr 1.0628e-03 eta 0:06:39
epoch [26/50] batch [120/176] time 0.092 (0.091) data 0.000 (0.003) loss 1.1383 (1.2694) teacher_loss 0.2101 (0.3754) loss_zs_kd 0.0637 (0.0926) loss_oracle 0.8964 (0.8477) acc 96.8750 (87.3177) alaph_mean 0.0441 (0.0825) alpha_min 0.0000 (0.0000) alpha_max 0.4998 (0.6026) lr 1.0628e-03 eta 0:06:30
epoch [26/50] batch [140/176] time 0.095 (0.091) data 0.000 (0.003) loss 1.2863 (1.2647) teacher_loss 0.3982 (0.3713) loss_zs_kd 0.1245 (0.0918) loss_oracle 0.8259 (0.8475) acc 81.2500 (87.3884) alaph_mean 0.0851 (0.0806) alpha_min 0.0000 (0.0000) alpha_max 0.7059 (0.5864) lr 1.0628e-03 eta 0:06:25
epoch [26/50] batch [160/176] time 0.086 (0.090) data 0.000 (0.003) loss 1.0778 (1.2588) teacher_loss 0.2015 (0.3671) loss_zs_kd 0.0668 (0.0909) loss_oracle 0.8428 (0.8462) acc 93.7500 (87.4609) alaph_mean 0.0541 (0.0815) alpha_min 0.0000 (0.0000) alpha_max 0.6737 (0.5934) lr 1.0628e-03 eta 0:06:21
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,190
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,690
* accuracy: 63.6%
* error: 36.4%
* macro_f1: 59.1%
******* Domain l best val acc:      90.6%, epoch: 25 *******
******* Domain l best val test acc: 63.7%, epoch: 25 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [27/50] batch [20/176] time 0.083 (0.096) data 0.000 (0.013) loss 1.0468 (1.2449) teacher_loss 0.1805 (0.3354) loss_zs_kd 0.1146 (0.0938) loss_oracle 0.8089 (0.8626) acc 93.7500 (88.5938) alaph_mean 0.0903 (0.0697) alpha_min 0.0000 (0.0000) alpha_max 0.7042 (0.5537) lr 1.0000e-03 eta 0:06:43
epoch [27/50] batch [40/176] time 0.077 (0.088) data 0.000 (0.007) loss 0.9588 (1.2053) teacher_loss 0.1038 (0.3244) loss_zs_kd 0.0529 (0.0921) loss_oracle 0.8286 (0.8349) acc 93.7500 (88.4375) alaph_mean 0.0559 (0.0756) alpha_min -0.0000 (0.0000) alpha_max 0.3827 (0.5590) lr 1.0000e-03 eta 0:06:09
epoch [27/50] batch [60/176] time 0.078 (0.085) data 0.001 (0.005) loss 1.1751 (1.2270) teacher_loss 0.3105 (0.3448) loss_zs_kd 0.1325 (0.0928) loss_oracle 0.7983 (0.8358) acc 87.5000 (87.9688) alaph_mean 0.0811 (0.0746) alpha_min 0.0000 (0.0000) alpha_max 0.8452 (0.5563) lr 1.0000e-03 eta 0:05:53
epoch [27/50] batch [80/176] time 0.082 (0.084) data 0.000 (0.004) loss 1.2228 (1.2330) teacher_loss 0.2744 (0.3454) loss_zs_kd 0.1324 (0.0952) loss_oracle 0.8822 (0.8400) acc 93.7500 (88.1250) alaph_mean 0.0684 (0.0740) alpha_min -0.0000 (0.0000) alpha_max 0.7958 (0.5649) lr 1.0000e-03 eta 0:05:47
epoch [27/50] batch [100/176] time 0.088 (0.083) data 0.000 (0.003) loss 1.1822 (1.2356) teacher_loss 0.2954 (0.3464) loss_zs_kd 0.0823 (0.0946) loss_oracle 0.8456 (0.8419) acc 90.6250 (88.0938) alaph_mean 0.0633 (0.0752) alpha_min 0.0000 (0.0000) alpha_max 0.4953 (0.5814) lr 1.0000e-03 eta 0:05:44
epoch [27/50] batch [120/176] time 0.081 (0.083) data 0.000 (0.002) loss 1.1602 (1.2395) teacher_loss 0.3325 (0.3476) loss_zs_kd 0.1275 (0.0948) loss_oracle 0.7639 (0.8445) acc 90.6250 (88.0208) alaph_mean 0.1036 (0.0754) alpha_min 0.0000 (0.0000) alpha_max 0.5473 (0.5831) lr 1.0000e-03 eta 0:05:40
epoch [27/50] batch [140/176] time 0.086 (0.083) data 0.001 (0.002) loss 1.0435 (1.2457) teacher_loss 0.2549 (0.3555) loss_zs_kd 0.0579 (0.0929) loss_oracle 0.7596 (0.8437) acc 90.6250 (87.5000) alaph_mean 0.1191 (0.0774) alpha_min 0.0000 (0.0000) alpha_max 0.5655 (0.5814) lr 1.0000e-03 eta 0:05:37
epoch [27/50] batch [160/176] time 0.079 (0.083) data 0.000 (0.002) loss 1.4070 (1.2535) teacher_loss 0.5312 (0.3618) loss_zs_kd 0.0960 (0.0927) loss_oracle 0.8277 (0.8454) acc 90.6250 (87.2070) alaph_mean 0.0899 (0.0780) alpha_min 0.0000 (0.0000) alpha_max 0.5520 (0.5791) lr 1.0000e-03 eta 0:05:36
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,195
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 92.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,675
* accuracy: 63.1%
* error: 36.9%
* macro_f1: 58.0%
******* Domain l best val acc:      90.6%, epoch: 25 *******
******* Domain l best val test acc: 63.7%, epoch: 25 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [28/50] batch [20/176] time 0.106 (0.111) data 0.001 (0.015) loss 1.1294 (1.2642) teacher_loss 0.2737 (0.3386) loss_zs_kd 0.0895 (0.0868) loss_oracle 0.8110 (0.8822) acc 90.6250 (89.0625) alaph_mean 0.1049 (0.0871) alpha_min 0.0000 (0.0000) alpha_max 0.7002 (0.6446) lr 9.3721e-04 eta 0:07:28
epoch [28/50] batch [40/176] time 0.089 (0.099) data 0.000 (0.008) loss 1.0786 (1.2554) teacher_loss 0.2075 (0.3489) loss_zs_kd 0.0745 (0.0888) loss_oracle 0.8338 (0.8620) acc 93.7500 (87.8906) alaph_mean 0.0565 (0.0801) alpha_min 0.0000 (0.0000) alpha_max 0.4472 (0.6082) lr 9.3721e-04 eta 0:06:38
epoch [28/50] batch [60/176] time 0.085 (0.095) data 0.001 (0.005) loss 1.3469 (1.2564) teacher_loss 0.5518 (0.3567) loss_zs_kd 0.0891 (0.0886) loss_oracle 0.7506 (0.8554) acc 84.3750 (87.3438) alaph_mean 0.1098 (0.0799) alpha_min 0.0000 (0.0000) alpha_max 0.6601 (0.6036) lr 9.3721e-04 eta 0:06:17
epoch [28/50] batch [80/176] time 0.082 (0.092) data 0.000 (0.004) loss 1.0543 (1.2533) teacher_loss 0.2581 (0.3557) loss_zs_kd 0.0719 (0.0885) loss_oracle 0.7603 (0.8533) acc 87.5000 (86.9531) alaph_mean 0.0791 (0.0813) alpha_min 0.0000 (0.0000) alpha_max 0.7831 (0.6092) lr 9.3721e-04 eta 0:06:05
epoch [28/50] batch [100/176] time 0.088 (0.091) data 0.000 (0.003) loss 1.0952 (1.2508) teacher_loss 0.1774 (0.3552) loss_zs_kd 0.0918 (0.0891) loss_oracle 0.8719 (0.8511) acc 93.7500 (87.2188) alaph_mean 0.0410 (0.0831) alpha_min 0.0000 (0.0000) alpha_max 0.3982 (0.6146) lr 9.3721e-04 eta 0:05:57
epoch [28/50] batch [120/176] time 0.084 (0.090) data 0.000 (0.003) loss 1.3735 (1.2528) teacher_loss 0.4490 (0.3583) loss_zs_kd 0.0970 (0.0908) loss_oracle 0.8760 (0.8492) acc 90.6250 (87.2396) alaph_mean 0.0721 (0.0837) alpha_min 0.0000 (0.0000) alpha_max 0.4997 (0.6143) lr 9.3721e-04 eta 0:05:51
epoch [28/50] batch [140/176] time 0.085 (0.089) data 0.000 (0.002) loss 1.2838 (1.2508) teacher_loss 0.3428 (0.3559) loss_zs_kd 0.1153 (0.0906) loss_oracle 0.8834 (0.8496) acc 87.5000 (87.2991) alaph_mean 0.0266 (0.0818) alpha_min 0.0000 (0.0000) alpha_max 0.3687 (0.6050) lr 9.3721e-04 eta 0:05:47
epoch [28/50] batch [160/176] time 0.089 (0.088) data 0.000 (0.002) loss 1.1988 (1.2509) teacher_loss 0.2935 (0.3579) loss_zs_kd 0.0726 (0.0900) loss_oracle 0.8690 (0.8481) acc 84.3750 (87.3438) alaph_mean 0.0843 (0.0826) alpha_min 0.0000 (0.0000) alpha_max 0.7963 (0.6056) lr 9.3721e-04 eta 0:05:43
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,201
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 92.6%
Checkpoint saved to icml/multi-dg/oracle/13_entropybaseweight_mixlogits/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,717
* accuracy: 64.6%
* error: 35.4%
* macro_f1: 58.9%
******* Domain l best val acc:      90.9%, epoch: 28 *******
******* Domain l best val test acc: 64.6%, epoch: 28 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [29/50] batch [20/176] time 0.077 (0.096) data 0.000 (0.012) loss 1.4186 (1.3009) teacher_loss 0.3960 (0.3742) loss_zs_kd 0.1025 (0.0913) loss_oracle 0.9713 (0.8810) acc 90.6250 (86.8750) alaph_mean 0.0409 (0.0909) alpha_min 0.0000 (0.0000) alpha_max 0.4635 (0.6020) lr 8.7467e-04 eta 0:06:08
epoch [29/50] batch [40/176] time 0.092 (0.091) data 0.000 (0.006) loss 1.1403 (1.2886) teacher_loss 0.3225 (0.3707) loss_zs_kd 0.0834 (0.0909) loss_oracle 0.7761 (0.8724) acc 90.6250 (86.8750) alaph_mean 0.1237 (0.0827) alpha_min 0.0000 (0.0000) alpha_max 0.7307 (0.5818) lr 8.7467e-04 eta 0:05:48
epoch [29/50] batch [60/176] time 0.081 (0.089) data 0.001 (0.004) loss 1.4388 (1.2741) teacher_loss 0.5977 (0.3716) loss_zs_kd 0.1293 (0.0918) loss_oracle 0.7765 (0.8565) acc 81.2500 (87.0312) alaph_mean 0.0978 (0.0820) alpha_min 0.0000 (0.0000) alpha_max 0.5826 (0.5729) lr 8.7467e-04 eta 0:05:39

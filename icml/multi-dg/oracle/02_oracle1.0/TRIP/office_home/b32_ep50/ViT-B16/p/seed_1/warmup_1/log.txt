Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'clipart', 'real_world']
Target     ['product']
# classes  65
# train_x  7,815
# val      3,334
# test     4,439
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/244] time 0.128 (0.149) data 0.000 (0.020) loss 1.4285 (1.4244) ce_loss 1.4297 (1.4243) teacher_loss 1.4285 (1.4243) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0000 (0.0000) acc 62.5000 (65.0000) kd_loss 0.0126 (0.0098) lr 1.0000e-05 eta 0:30:15
epoch [1/50] batch [40/244] time 0.123 (0.135) data 0.001 (0.010) loss 1.4993 (1.3940) ce_loss 1.4980 (1.3939) teacher_loss 1.4992 (1.3940) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0000 (0.0000) acc 56.2500 (65.2344) kd_loss 0.0079 (0.0101) lr 1.0000e-05 eta 0:27:23
epoch [1/50] batch [60/244] time 0.121 (0.129) data 0.001 (0.007) loss 1.3183 (1.4278) ce_loss 1.3184 (1.4277) teacher_loss 1.3182 (1.4277) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0000 (0.0000) acc 65.6250 (64.0104) kd_loss 0.0049 (0.0093) lr 1.0000e-05 eta 0:26:04
epoch [1/50] batch [80/244] time 0.104 (0.123) data 0.000 (0.005) loss 1.5648 (1.4338) ce_loss 1.5654 (1.4337) teacher_loss 1.5646 (1.4337) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0001 (0.0000) acc 59.3750 (63.9844) kd_loss 0.0043 (0.0085) lr 1.0000e-05 eta 0:24:51
epoch [1/50] batch [100/244] time 0.123 (0.120) data 0.000 (0.004) loss 1.5558 (1.4145) ce_loss 1.5557 (1.4144) teacher_loss 1.5554 (1.4144) loss_zs_kd 0.0006 (0.0002) loss_oracle 0.0001 (0.0000) acc 62.5000 (64.1875) kd_loss 0.0071 (0.0077) lr 1.0000e-05 eta 0:24:14
epoch [1/50] batch [120/244] time 0.098 (0.118) data 0.000 (0.004) loss 0.9570 (1.4002) ce_loss 0.9565 (1.4001) teacher_loss 0.9567 (1.4001) loss_zs_kd 0.0005 (0.0002) loss_oracle 0.0000 (0.0000) acc 75.0000 (64.5573) kd_loss 0.0039 (0.0071) lr 1.0000e-05 eta 0:23:41
epoch [1/50] batch [140/244] time 0.108 (0.115) data 0.000 (0.003) loss 1.0918 (1.3817) ce_loss 1.0908 (1.3815) teacher_loss 1.0914 (1.3815) loss_zs_kd 0.0007 (0.0003) loss_oracle 0.0001 (0.0001) acc 75.0000 (65.0000) kd_loss 0.0040 (0.0065) lr 1.0000e-05 eta 0:23:09
epoch [1/50] batch [160/244] time 0.095 (0.114) data 0.000 (0.003) loss 1.4824 (1.3733) ce_loss 1.4814 (1.3731) teacher_loss 1.4815 (1.3731) loss_zs_kd 0.0016 (0.0004) loss_oracle 0.0001 (0.0001) acc 56.2500 (65.1367) kd_loss 0.0029 (0.0060) lr 1.0000e-05 eta 0:22:47
epoch [1/50] batch [180/244] time 0.101 (0.112) data 0.000 (0.002) loss 0.9843 (1.3728) ce_loss 0.9834 (1.3725) teacher_loss 0.9837 (1.3725) loss_zs_kd 0.0010 (0.0005) loss_oracle 0.0001 (0.0001) acc 81.2500 (65.1910) kd_loss 0.0041 (0.0057) lr 1.0000e-05 eta 0:22:28
epoch [1/50] batch [200/244] time 0.096 (0.111) data 0.000 (0.002) loss 1.4856 (1.3721) ce_loss 1.4844 (1.3717) teacher_loss 1.4848 (1.3717) loss_zs_kd 0.0013 (0.0007) loss_oracle 0.0001 (0.0001) acc 62.5000 (65.2344) kd_loss 0.0041 (0.0054) lr 1.0000e-05 eta 0:22:13
epoch [1/50] batch [220/244] time 0.100 (0.110) data 0.000 (0.002) loss 1.2259 (1.3688) ce_loss 1.2227 (1.3683) teacher_loss 1.2226 (1.3683) loss_zs_kd 0.0063 (0.0008) loss_oracle 0.0001 (0.0001) acc 68.7500 (65.2557) kd_loss 0.0021 (0.0052) lr 1.0000e-05 eta 0:21:59
epoch [1/50] batch [240/244] time 0.103 (0.110) data 0.000 (0.002) loss 1.3146 (1.3654) ce_loss 1.3135 (1.3649) teacher_loss 1.3137 (1.3649) loss_zs_kd 0.0016 (0.0009) loss_oracle 0.0001 (0.0001) acc 75.0000 (65.4557) kd_loss 0.0042 (0.0050) lr 1.0000e-05 eta 0:21:49
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,673
* accuracy: 80.2%
* error: 19.8%
* macro_f1: 78.6%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,943
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 87.9%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      80.2%, epoch: 1 *******
******* Domain p best val test acc: 88.8%, epoch: 1 *******
******* Domain p best test acc:     88.8%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/ana
epoch [2/50] batch [20/244] time 0.097 (0.131) data 0.000 (0.026) loss 1.0438 (1.4239) ce_loss 1.0000 (1.3729) teacher_loss 0.9998 (1.3729) loss_zs_kd 0.0726 (0.0918) loss_oracle 0.0077 (0.0051) acc 75.0000 (63.9062) kd_loss 0.0021 (0.0027) lr 2.0000e-03 eta 0:26:01
epoch [2/50] batch [40/244] time 0.097 (0.115) data 0.000 (0.013) loss 1.1430 (1.3531) ce_loss 1.0977 (1.3022) teacher_loss 1.0983 (1.3024) loss_zs_kd 0.0525 (0.0838) loss_oracle 0.0184 (0.0088) acc 71.8750 (66.4844) kd_loss 0.0017 (0.0026) lr 2.0000e-03 eta 0:22:54
epoch [2/50] batch [60/244] time 0.095 (0.109) data 0.000 (0.009) loss 1.5096 (1.4131) ce_loss 1.3818 (1.3359) teacher_loss 1.3835 (1.3363) loss_zs_kd 0.0845 (0.0805) loss_oracle 0.0839 (0.0366) acc 62.5000 (65.3125) kd_loss 0.0075 (0.0030) lr 2.0000e-03 eta 0:21:39
epoch [2/50] batch [80/244] time 0.091 (0.107) data 0.000 (0.007) loss 1.1427 (1.3633) ce_loss 1.0791 (1.2845) teacher_loss 1.0795 (1.2851) loss_zs_kd 0.1017 (0.0839) loss_oracle 0.0123 (0.0362) acc 68.7500 (66.2500) kd_loss 0.0046 (0.0036) lr 2.0000e-03 eta 0:21:09
epoch [2/50] batch [100/244] time 0.100 (0.105) data 0.000 (0.005) loss 0.9581 (1.3454) ce_loss 0.9136 (1.2708) teacher_loss 0.9137 (1.2714) loss_zs_kd 0.0626 (0.0850) loss_oracle 0.0131 (0.0315) acc 71.8750 (66.8750) kd_loss 0.0033 (0.0039) lr 2.0000e-03 eta 0:20:49
epoch [2/50] batch [120/244] time 0.102 (0.105) data 0.000 (0.004) loss 1.7284 (1.3205) ce_loss 1.6768 (1.2501) teacher_loss 1.6759 (1.2507) loss_zs_kd 0.0753 (0.0830) loss_oracle 0.0149 (0.0283) acc 62.5000 (67.6823) kd_loss 0.0060 (0.0041) lr 2.0000e-03 eta 0:20:39
epoch [2/50] batch [140/244] time 0.097 (0.104) data 0.000 (0.004) loss 1.0539 (1.3135) ce_loss 0.9824 (1.2438) teacher_loss 0.9833 (1.2444) loss_zs_kd 0.0975 (0.0854) loss_oracle 0.0218 (0.0264) acc 75.0000 (67.9688) kd_loss 0.0058 (0.0043) lr 2.0000e-03 eta 0:20:31
epoch [2/50] batch [160/244] time 0.099 (0.104) data 0.000 (0.003) loss 1.2442 (1.3192) ce_loss 1.1787 (1.2501) teacher_loss 1.1791 (1.2507) loss_zs_kd 0.0626 (0.0855) loss_oracle 0.0337 (0.0258) acc 68.7500 (67.7930) kd_loss 0.0055 (0.0044) lr 2.0000e-03 eta 0:20:23
epoch [2/50] batch [180/244] time 0.100 (0.103) data 0.000 (0.003) loss 1.1592 (1.3061) ce_loss 1.0723 (1.2363) teacher_loss 1.0729 (1.2369) loss_zs_kd 0.0825 (0.0860) loss_oracle 0.0451 (0.0261) acc 71.8750 (68.0903) kd_loss 0.0047 (0.0046) lr 2.0000e-03 eta 0:20:17
epoch [2/50] batch [200/244] time 0.100 (0.103) data 0.001 (0.003) loss 1.4456 (1.3177) ce_loss 1.3828 (1.2452) teacher_loss 1.3816 (1.2459) loss_zs_kd 0.0689 (0.0889) loss_oracle 0.0296 (0.0274) acc 65.6250 (67.7969) kd_loss 0.0073 (0.0047) lr 2.0000e-03 eta 0:20:13
epoch [2/50] batch [220/244] time 0.108 (0.103) data 0.000 (0.003) loss 1.1782 (1.3126) ce_loss 1.0771 (1.2399) teacher_loss 1.0772 (1.2407) loss_zs_kd 0.1359 (0.0893) loss_oracle 0.0331 (0.0272) acc 75.0000 (67.8267) kd_loss 0.0055 (0.0047) lr 2.0000e-03 eta 0:20:08
epoch [2/50] batch [240/244] time 0.105 (0.103) data 0.000 (0.002) loss 1.5155 (1.3121) ce_loss 1.4131 (1.2388) teacher_loss 1.4126 (1.2396) loss_zs_kd 0.1641 (0.0905) loss_oracle 0.0208 (0.0273) acc 65.6250 (67.6693) kd_loss 0.0055 (0.0048) lr 2.0000e-03 eta 0:20:06
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,783
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.4%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,031
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.2%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.5%, epoch: 2 *******
******* Domain p best val test acc: 90.8%, epoch: 2 *******
******* Domain p best test acc:     90.8%, epoch: 2 *******
epoch [3/50] batch [20/244] time 0.106 (0.119) data 0.000 (0.020) loss 1.3030 (1.2979) ce_loss 1.1953 (1.2039) teacher_loss 1.1980 (1.2044) loss_zs_kd 0.1410 (0.1320) loss_oracle 0.0345 (0.0274) acc 65.6250 (69.5312) kd_loss 0.0104 (0.0071) lr 1.9980e-03 eta 0:23:11
epoch [3/50] batch [40/244] time 0.089 (0.109) data 0.000 (0.010) loss 0.8593 (1.2932) ce_loss 0.7852 (1.2103) teacher_loss 0.7866 (1.2105) loss_zs_kd 0.0969 (0.1125) loss_oracle 0.0243 (0.0264) acc 68.7500 (69.3750) kd_loss 0.0064 (0.0070) lr 1.9980e-03 eta 0:21:12
epoch [3/50] batch [60/244] time 0.084 (0.102) data 0.000 (0.007) loss 0.7452 (1.2564) ce_loss 0.6719 (1.1796) teacher_loss 0.6724 (1.1800) loss_zs_kd 0.1021 (0.1051) loss_oracle 0.0218 (0.0240) acc 84.3750 (69.6875) kd_loss 0.0052 (0.0072) lr 1.9980e-03 eta 0:19:43
epoch [3/50] batch [80/244] time 0.090 (0.099) data 0.000 (0.005) loss 1.5845 (1.2994) ce_loss 1.5273 (1.2206) teacher_loss 1.5292 (1.2207) loss_zs_kd 0.0693 (0.1089) loss_oracle 0.0207 (0.0243) acc 65.6250 (68.6328) kd_loss 0.0059 (0.0074) lr 1.9980e-03 eta 0:19:07
epoch [3/50] batch [100/244] time 0.088 (0.097) data 0.000 (0.004) loss 1.7444 (1.2872) ce_loss 1.6445 (1.2100) teacher_loss 1.6429 (1.2101) loss_zs_kd 0.1524 (0.1059) loss_oracle 0.0253 (0.0241) acc 56.2500 (69.0000) kd_loss 0.0105 (0.0075) lr 1.9980e-03 eta 0:18:45
epoch [3/50] batch [120/244] time 0.089 (0.096) data 0.000 (0.003) loss 0.9396 (1.2865) ce_loss 0.8198 (1.2093) teacher_loss 0.8210 (1.2094) loss_zs_kd 0.1614 (0.1069) loss_oracle 0.0379 (0.0236) acc 75.0000 (68.8542) kd_loss 0.0091 (0.0077) lr 1.9980e-03 eta 0:18:29
epoch [3/50] batch [140/244] time 0.084 (0.095) data 0.000 (0.003) loss 1.3574 (1.2766) ce_loss 1.2676 (1.1978) teacher_loss 1.2655 (1.1981) loss_zs_kd 0.1184 (0.1091) loss_oracle 0.0326 (0.0240) acc 68.7500 (69.1518) kd_loss 0.0089 (0.0077) lr 1.9980e-03 eta 0:18:14
epoch [3/50] batch [160/244] time 0.092 (0.094) data 0.000 (0.003) loss 1.2701 (1.2878) ce_loss 1.1865 (1.2090) teacher_loss 1.1872 (1.2094) loss_zs_kd 0.0813 (0.1075) loss_oracle 0.0423 (0.0247) acc 68.7500 (68.9062) kd_loss 0.0080 (0.0077) lr 1.9980e-03 eta 0:18:05
epoch [3/50] batch [180/244] time 0.084 (0.093) data 0.000 (0.002) loss 1.0026 (1.2811) ce_loss 0.9023 (1.2018) teacher_loss 0.9027 (1.2022) loss_zs_kd 0.1141 (0.1068) loss_oracle 0.0429 (0.0254) acc 75.0000 (69.1493) kd_loss 0.0093 (0.0077) lr 1.9980e-03 eta 0:17:57
epoch [3/50] batch [200/244] time 0.097 (0.093) data 0.000 (0.002) loss 1.4559 (1.2812) ce_loss 1.3574 (1.1998) teacher_loss 1.3460 (1.2003) loss_zs_kd 0.1184 (0.1080) loss_oracle 0.0508 (0.0270) acc 62.5000 (69.1094) kd_loss 0.0135 (0.0077) lr 1.9980e-03 eta 0:17:50
epoch [3/50] batch [220/244] time 0.098 (0.093) data 0.000 (0.002) loss 1.3915 (1.2868) ce_loss 1.3125 (1.2039) teacher_loss 1.3131 (1.2044) loss_zs_kd 0.1268 (0.1087) loss_oracle 0.0151 (0.0281) acc 75.0000 (69.1761) kd_loss 0.0074 (0.0078) lr 1.9980e-03 eta 0:17:51
epoch [3/50] batch [240/244] time 0.104 (0.094) data 0.000 (0.002) loss 0.9357 (1.2836) ce_loss 0.8843 (1.2008) teacher_loss 0.8840 (1.2012) loss_zs_kd 0.0712 (0.1091) loss_oracle 0.0161 (0.0278) acc 71.8750 (69.2578) kd_loss 0.0055 (0.0079) lr 1.9980e-03 eta 0:17:55
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,783
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.3%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.5%, epoch: 2 *******
******* Domain p best val test acc: 90.8%, epoch: 2 *******
******* Domain p best test acc:     90.9%, epoch: 3 *******
epoch [4/50] batch [20/244] time 0.097 (0.119) data 0.000 (0.016) loss 1.6178 (1.3075) ce_loss 1.5479 (1.2210) teacher_loss 1.5428 (1.2216) loss_zs_kd 0.0899 (0.1209) loss_oracle 0.0301 (0.0254) acc 59.3750 (67.1875) kd_loss 0.0117 (0.0093) lr 1.9921e-03 eta 0:22:38
epoch [4/50] batch [40/244] time 0.109 (0.110) data 0.000 (0.008) loss 0.8613 (1.2696) ce_loss 0.7715 (1.1870) teacher_loss 0.7744 (1.1879) loss_zs_kd 0.1349 (0.1129) loss_oracle 0.0195 (0.0252) acc 84.3750 (68.4375) kd_loss 0.0068 (0.0088) lr 1.9921e-03 eta 0:20:55
epoch [4/50] batch [60/244] time 0.099 (0.107) data 0.000 (0.005) loss 1.5262 (1.2479) ce_loss 1.4219 (1.1620) teacher_loss 1.4214 (1.1630) loss_zs_kd 0.1269 (0.1139) loss_oracle 0.0414 (0.0279) acc 56.2500 (69.4271) kd_loss 0.0116 (0.0091) lr 1.9921e-03 eta 0:20:24
epoch [4/50] batch [80/244] time 0.090 (0.104) data 0.000 (0.004) loss 1.9559 (1.2529) ce_loss 1.8457 (1.1640) teacher_loss 1.8401 (1.1646) loss_zs_kd 0.1616 (0.1187) loss_oracle 0.0350 (0.0290) acc 46.8750 (69.5312) kd_loss 0.0125 (0.0092) lr 1.9921e-03 eta 0:19:47
epoch [4/50] batch [100/244] time 0.095 (0.103) data 0.000 (0.003) loss 1.4334 (1.2764) ce_loss 1.3477 (1.1859) teacher_loss 1.3497 (1.1863) loss_zs_kd 0.1069 (0.1214) loss_oracle 0.0302 (0.0294) acc 65.6250 (68.9375) kd_loss 0.0067 (0.0091) lr 1.9921e-03 eta 0:19:29
epoch [4/50] batch [120/244] time 0.084 (0.102) data 0.000 (0.003) loss 1.0961 (1.2886) ce_loss 0.9980 (1.1973) teacher_loss 1.0038 (1.1976) loss_zs_kd 0.1029 (0.1212) loss_oracle 0.0409 (0.0304) acc 81.2500 (68.9844) kd_loss 0.0073 (0.0090) lr 1.9921e-03 eta 0:19:13
epoch [4/50] batch [140/244] time 0.089 (0.100) data 0.000 (0.002) loss 0.9325 (1.2735) ce_loss 0.8413 (1.1828) teacher_loss 0.8445 (1.1830) loss_zs_kd 0.1018 (0.1200) loss_oracle 0.0371 (0.0305) acc 78.1250 (69.3080) kd_loss 0.0107 (0.0089) lr 1.9921e-03 eta 0:18:53
epoch [4/50] batch [160/244] time 0.096 (0.100) data 0.000 (0.002) loss 1.0832 (1.2778) ce_loss 0.9971 (1.1853) teacher_loss 0.9954 (1.1855) loss_zs_kd 0.0989 (0.1217) loss_oracle 0.0383 (0.0315) acc 71.8750 (68.9062) kd_loss 0.0082 (0.0089) lr 1.9921e-03 eta 0:18:47
epoch [4/50] batch [180/244] time 0.100 (0.100) data 0.000 (0.002) loss 0.7521 (1.2626) ce_loss 0.6782 (1.1701) teacher_loss 0.6783 (1.1702) loss_zs_kd 0.1047 (0.1211) loss_oracle 0.0215 (0.0318) acc 81.2500 (69.5312) kd_loss 0.0078 (0.0089) lr 1.9921e-03 eta 0:18:44
epoch [4/50] batch [200/244] time 0.094 (0.100) data 0.000 (0.002) loss 1.4321 (1.2600) ce_loss 1.3535 (1.1675) teacher_loss 1.3501 (1.1676) loss_zs_kd 0.0959 (0.1207) loss_oracle 0.0341 (0.0321) acc 71.8750 (69.4844) kd_loss 0.0092 (0.0088) lr 1.9921e-03 eta 0:18:42
epoch [4/50] batch [220/244] time 0.149 (0.100) data 0.000 (0.002) loss 1.8932 (1.2527) ce_loss 1.7959 (1.1587) teacher_loss 1.7929 (1.1588) loss_zs_kd 0.1068 (0.1212) loss_oracle 0.0469 (0.0333) acc 59.3750 (69.6449) kd_loss 0.0112 (0.0088) lr 1.9921e-03 eta 0:18:47
epoch [4/50] batch [240/244] time 0.101 (0.101) data 0.000 (0.002) loss 1.4865 (1.2517) ce_loss 1.4092 (1.1578) teacher_loss 1.4008 (1.1579) loss_zs_kd 0.0886 (0.1205) loss_oracle 0.0414 (0.0335) acc 59.3750 (69.6875) kd_loss 0.0090 (0.0087) lr 1.9921e-03 eta 0:18:54
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,794
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.7%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.3%
******* Domain p best val acc:      83.8%, epoch: 4 *******
******* Domain p best val test acc: 90.9%, epoch: 4 *******
******* Domain p best test acc:     90.9%, epoch: 3 *******
epoch [5/50] batch [20/244] time 0.105 (0.122) data 0.000 (0.014) loss 1.4754 (1.3221) ce_loss 1.3965 (1.2104) teacher_loss 1.3947 (1.2117) loss_zs_kd 0.0881 (0.1350) loss_oracle 0.0366 (0.0430) acc 62.5000 (67.0312) kd_loss 0.0098 (0.0090) lr 1.9823e-03 eta 0:22:42
epoch [5/50] batch [40/244] time 0.103 (0.108) data 0.000 (0.007) loss 1.1826 (1.2213) ce_loss 1.0635 (1.1175) teacher_loss 1.0673 (1.1185) loss_zs_kd 0.1344 (0.1260) loss_oracle 0.0481 (0.0398) acc 71.8750 (70.0781) kd_loss 0.0082 (0.0091) lr 1.9823e-03 eta 0:20:13
epoch [5/50] batch [60/244] time 0.103 (0.105) data 0.000 (0.005) loss 1.1863 (1.2239) ce_loss 1.0762 (1.1179) teacher_loss 1.0771 (1.1188) loss_zs_kd 0.1392 (0.1240) loss_oracle 0.0396 (0.0431) acc 68.7500 (69.7396) kd_loss 0.0103 (0.0092) lr 1.9823e-03 eta 0:19:34
epoch [5/50] batch [80/244] time 0.096 (0.104) data 0.000 (0.004) loss 1.4642 (1.2226) ce_loss 1.3604 (1.1163) teacher_loss 1.3589 (1.1171) loss_zs_kd 0.1355 (0.1278) loss_oracle 0.0375 (0.0416) acc 65.6250 (70.7031) kd_loss 0.0096 (0.0093) lr 1.9823e-03 eta 0:19:18
epoch [5/50] batch [100/244] time 0.104 (0.103) data 0.000 (0.003) loss 1.6478 (1.2272) ce_loss 1.5684 (1.1232) teacher_loss 1.5672 (1.1238) loss_zs_kd 0.0911 (0.1264) loss_oracle 0.0350 (0.0401) acc 65.6250 (70.4062) kd_loss 0.0102 (0.0095) lr 1.9823e-03 eta 0:19:07
epoch [5/50] batch [120/244] time 0.106 (0.103) data 0.000 (0.002) loss 1.1601 (1.2436) ce_loss 1.0625 (1.1395) teacher_loss 1.0594 (1.1399) loss_zs_kd 0.1246 (0.1272) loss_oracle 0.0384 (0.0401) acc 75.0000 (69.9219) kd_loss 0.0115 (0.0097) lr 1.9823e-03 eta 0:19:00
epoch [5/50] batch [140/244] time 0.095 (0.102) data 0.000 (0.002) loss 1.3703 (1.2408) ce_loss 1.2734 (1.1378) teacher_loss 1.2641 (1.1380) loss_zs_kd 0.1238 (0.1266) loss_oracle 0.0443 (0.0395) acc 62.5000 (70.0446) kd_loss 0.0170 (0.0098) lr 1.9823e-03 eta 0:18:53
epoch [5/50] batch [160/244] time 0.096 (0.102) data 0.000 (0.002) loss 1.0707 (1.2498) ce_loss 0.9609 (1.1484) teacher_loss 0.9615 (1.1485) loss_zs_kd 0.1071 (0.1242) loss_oracle 0.0557 (0.0391) acc 78.1250 (69.6484) kd_loss 0.0106 (0.0098) lr 1.9823e-03 eta 0:18:50
epoch [5/50] batch [180/244] time 0.096 (0.102) data 0.000 (0.002) loss 1.5785 (1.2503) ce_loss 1.4365 (1.1479) teacher_loss 1.4365 (1.1479) loss_zs_kd 0.1679 (0.1234) loss_oracle 0.0580 (0.0407) acc 68.7500 (69.8611) kd_loss 0.0117 (0.0099) lr 1.9823e-03 eta 0:18:44
epoch [5/50] batch [200/244] time 0.104 (0.102) data 0.000 (0.002) loss 1.2389 (1.2489) ce_loss 1.1514 (1.1468) teacher_loss 1.1552 (1.1468) loss_zs_kd 0.1069 (0.1231) loss_oracle 0.0303 (0.0406) acc 75.0000 (69.8594) kd_loss 0.0085 (0.0099) lr 1.9823e-03 eta 0:18:40
epoch [5/50] batch [220/244] time 0.097 (0.102) data 0.000 (0.002) loss 1.5861 (1.2499) ce_loss 1.4326 (1.1475) teacher_loss 1.4286 (1.1474) loss_zs_kd 0.2315 (0.1243) loss_oracle 0.0418 (0.0403) acc 56.2500 (69.9006) kd_loss 0.0132 (0.0099) lr 1.9823e-03 eta 0:18:37
epoch [5/50] batch [240/244] time 0.086 (0.101) data 0.000 (0.001) loss 1.5866 (1.2483) ce_loss 1.4277 (1.1464) teacher_loss 1.4244 (1.1463) loss_zs_kd 0.2372 (0.1241) loss_oracle 0.0437 (0.0399) acc 68.7500 (70.0000) kd_loss 0.0116 (0.0100) lr 1.9823e-03 eta 0:18:27
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,793
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,048
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.7%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.8%, epoch: 4 *******
******* Domain p best val test acc: 90.9%, epoch: 4 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [6/50] batch [20/244] time 0.096 (0.107) data 0.000 (0.012) loss 1.3969 (1.2067) ce_loss 1.3076 (1.1062) teacher_loss 1.3037 (1.1057) loss_zs_kd 0.1140 (0.1235) loss_oracle 0.0362 (0.0392) acc 71.8750 (70.9375) kd_loss 0.0096 (0.0100) lr 1.9686e-03 eta 0:19:29
epoch [6/50] batch [40/244] time 0.090 (0.100) data 0.000 (0.006) loss 1.4215 (1.2449) ce_loss 1.3193 (1.1404) teacher_loss 1.3242 (1.1403) loss_zs_kd 0.1097 (0.1268) loss_oracle 0.0424 (0.0412) acc 68.7500 (70.4688) kd_loss 0.0075 (0.0101) lr 1.9686e-03 eta 0:18:15
epoch [6/50] batch [60/244] time 0.090 (0.097) data 0.000 (0.004) loss 1.5243 (1.2484) ce_loss 1.3799 (1.1453) teacher_loss 1.3781 (1.1451) loss_zs_kd 0.1803 (0.1230) loss_oracle 0.0560 (0.0418) acc 65.6250 (70.6250) kd_loss 0.0110 (0.0101) lr 1.9686e-03 eta 0:17:44
epoch [6/50] batch [80/244] time 0.089 (0.097) data 0.000 (0.003) loss 1.1319 (1.2513) ce_loss 1.0234 (1.1458) teacher_loss 1.0248 (1.1456) loss_zs_kd 0.1146 (0.1220) loss_oracle 0.0498 (0.0447) acc 71.8750 (70.2734) kd_loss 0.0081 (0.0103) lr 1.9686e-03 eta 0:17:33
epoch [6/50] batch [100/244] time 0.091 (0.096) data 0.000 (0.003) loss 1.5778 (1.2479) ce_loss 1.4717 (1.1429) teacher_loss 1.4672 (1.1428) loss_zs_kd 0.1235 (0.1201) loss_oracle 0.0489 (0.0450) acc 53.1250 (70.1562) kd_loss 0.0147 (0.0104) lr 1.9686e-03 eta 0:17:26
epoch [6/50] batch [120/244] time 0.091 (0.096) data 0.000 (0.002) loss 1.3750 (1.2505) ce_loss 1.2461 (1.1457) teacher_loss 1.2473 (1.1457) loss_zs_kd 0.1525 (0.1201) loss_oracle 0.0514 (0.0447) acc 62.5000 (70.1042) kd_loss 0.0118 (0.0102) lr 1.9686e-03 eta 0:17:19
epoch [6/50] batch [140/244] time 0.099 (0.096) data 0.000 (0.002) loss 1.5811 (1.2661) ce_loss 1.4766 (1.1575) teacher_loss 1.4761 (1.1576) loss_zs_kd 0.1076 (0.1238) loss_oracle 0.0512 (0.0466) acc 62.5000 (69.8214) kd_loss 0.0095 (0.0103) lr 1.9686e-03 eta 0:17:17
epoch [6/50] batch [160/244] time 0.094 (0.095) data 0.000 (0.002) loss 0.9325 (1.2671) ce_loss 0.8008 (1.1568) teacher_loss 0.8017 (1.1570) loss_zs_kd 0.1490 (0.1250) loss_oracle 0.0563 (0.0476) acc 75.0000 (69.8047) kd_loss 0.0119 (0.0104) lr 1.9686e-03 eta 0:17:12
epoch [6/50] batch [180/244] time 0.095 (0.096) data 0.000 (0.001) loss 1.0550 (1.2684) ce_loss 0.9121 (1.1566) teacher_loss 0.9117 (1.1568) loss_zs_kd 0.1718 (0.1265) loss_oracle 0.0573 (0.0484) acc 75.0000 (69.8958) kd_loss 0.0123 (0.0105) lr 1.9686e-03 eta 0:17:12
epoch [6/50] batch [200/244] time 0.097 (0.096) data 0.000 (0.001) loss 1.3428 (1.2701) ce_loss 1.2217 (1.1581) teacher_loss 1.2193 (1.1582) loss_zs_kd 0.1663 (0.1267) loss_oracle 0.0403 (0.0485) acc 71.8750 (69.8125) kd_loss 0.0110 (0.0106) lr 1.9686e-03 eta 0:17:11
epoch [6/50] batch [220/244] time 0.100 (0.096) data 0.000 (0.001) loss 1.3771 (1.2727) ce_loss 1.2568 (1.1614) teacher_loss 1.2493 (1.1615) loss_zs_kd 0.1381 (0.1275) loss_oracle 0.0588 (0.0475) acc 68.7500 (69.7017) kd_loss 0.0149 (0.0107) lr 1.9686e-03 eta 0:17:09
epoch [6/50] batch [240/244] time 0.086 (0.095) data 0.000 (0.001) loss 1.4359 (1.2662) ce_loss 1.3301 (1.1552) teacher_loss 1.3273 (1.1553) loss_zs_kd 0.1322 (0.1265) loss_oracle 0.0425 (0.0476) acc 56.2500 (69.7656) kd_loss 0.0143 (0.0108) lr 1.9686e-03 eta 0:17:02
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,798
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,032
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
******* Domain p best val acc:      83.9%, epoch: 6 *******
******* Domain p best val test acc: 90.8%, epoch: 6 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [7/50] batch [20/244] time 0.110 (0.117) data 0.000 (0.013) loss 1.2079 (1.3632) ce_loss 1.0957 (1.2436) teacher_loss 1.0971 (1.2435) loss_zs_kd 0.1182 (0.1236) loss_oracle 0.0517 (0.0579) acc 68.7500 (66.2500) kd_loss 0.0091 (0.0119) lr 1.9511e-03 eta 0:20:54
epoch [7/50] batch [40/244] time 0.106 (0.109) data 0.000 (0.007) loss 1.0427 (1.2926) ce_loss 0.9321 (1.1748) teacher_loss 0.9296 (1.1749) loss_zs_kd 0.1211 (0.1215) loss_oracle 0.0526 (0.0570) acc 75.0000 (68.5156) kd_loss 0.0134 (0.0113) lr 1.9511e-03 eta 0:19:22
epoch [7/50] batch [60/244] time 0.111 (0.106) data 0.000 (0.005) loss 0.9282 (1.3058) ce_loss 0.8174 (1.1847) teacher_loss 0.8147 (1.1851) loss_zs_kd 0.0944 (0.1204) loss_oracle 0.0663 (0.0605) acc 75.0000 (67.6042) kd_loss 0.0152 (0.0118) lr 1.9511e-03 eta 0:18:47
epoch [7/50] batch [80/244] time 0.110 (0.105) data 0.000 (0.004) loss 1.2846 (1.2895) ce_loss 1.0996 (1.1690) teacher_loss 1.1001 (1.1698) loss_zs_kd 0.2412 (0.1240) loss_oracle 0.0639 (0.0577) acc 68.7500 (68.1641) kd_loss 0.0128 (0.0119) lr 1.9511e-03 eta 0:18:39
epoch [7/50] batch [100/244] time 0.097 (0.104) data 0.000 (0.003) loss 1.5833 (1.2769) ce_loss 1.4121 (1.1593) teacher_loss 1.4165 (1.1599) loss_zs_kd 0.2230 (0.1252) loss_oracle 0.0553 (0.0544) acc 62.5000 (68.7812) kd_loss 0.0193 (0.0120) lr 1.9511e-03 eta 0:18:25
epoch [7/50] batch [120/244] time 0.112 (0.104) data 0.000 (0.002) loss 1.2689 (1.2811) ce_loss 1.1797 (1.1638) teacher_loss 1.1810 (1.1643) loss_zs_kd 0.1012 (0.1263) loss_oracle 0.0372 (0.0537) acc 65.6250 (68.9844) kd_loss 0.0104 (0.0123) lr 1.9511e-03 eta 0:18:21
epoch [7/50] batch [140/244] time 0.103 (0.103) data 0.000 (0.002) loss 0.8932 (1.2690) ce_loss 0.7402 (1.1521) teacher_loss 0.7441 (1.1523) loss_zs_kd 0.1574 (0.1263) loss_oracle 0.0704 (0.0536) acc 78.1250 (69.3080) kd_loss 0.0183 (0.0126) lr 1.9511e-03 eta 0:18:15
epoch [7/50] batch [160/244] time 0.098 (0.103) data 0.000 (0.002) loss 1.7561 (1.2706) ce_loss 1.6191 (1.1544) teacher_loss 1.6178 (1.1546) loss_zs_kd 0.1765 (0.1265) loss_oracle 0.0501 (0.0527) acc 62.5000 (69.3555) kd_loss 0.0109 (0.0126) lr 1.9511e-03 eta 0:18:13
epoch [7/50] batch [180/244] time 0.100 (0.103) data 0.000 (0.002) loss 1.1314 (1.2772) ce_loss 1.0010 (1.1599) teacher_loss 0.9989 (1.1601) loss_zs_kd 0.1551 (0.1284) loss_oracle 0.0549 (0.0529) acc 75.0000 (69.2882) kd_loss 0.0175 (0.0126) lr 1.9511e-03 eta 0:18:09
epoch [7/50] batch [200/244] time 0.100 (0.103) data 0.000 (0.002) loss 1.1138 (1.2724) ce_loss 1.0088 (1.1529) teacher_loss 1.0106 (1.1531) loss_zs_kd 0.1237 (0.1296) loss_oracle 0.0413 (0.0544) acc 68.7500 (69.5781) kd_loss 0.0165 (0.0129) lr 1.9511e-03 eta 0:18:04
epoch [7/50] batch [220/244] time 0.098 (0.103) data 0.000 (0.001) loss 1.3434 (1.2779) ce_loss 1.2129 (1.1575) teacher_loss 1.2176 (1.1577) loss_zs_kd 0.1541 (0.1312) loss_oracle 0.0488 (0.0545) acc 75.0000 (69.5028) kd_loss 0.0098 (0.0131) lr 1.9511e-03 eta 0:18:00
epoch [7/50] batch [240/244] time 0.108 (0.103) data 0.000 (0.001) loss 1.0972 (1.2680) ce_loss 0.9468 (1.1488) teacher_loss 0.9476 (1.1490) loss_zs_kd 0.1797 (0.1298) loss_oracle 0.0598 (0.0541) acc 78.1250 (69.8177) kd_loss 0.0174 (0.0132) lr 1.9511e-03 eta 0:17:58
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,785
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,024
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.1%
******* Domain p best val acc:      83.9%, epoch: 6 *******
******* Domain p best val test acc: 90.8%, epoch: 6 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [8/50] batch [20/244] time 0.095 (0.107) data 0.000 (0.011) loss 1.4268 (1.3566) ce_loss 1.2939 (1.2293) teacher_loss 1.2969 (1.2297) loss_zs_kd 0.1208 (0.1250) loss_oracle 0.0695 (0.0644) acc 65.6250 (66.2500) kd_loss 0.0127 (0.0147) lr 1.9298e-03 eta 0:18:37
epoch [8/50] batch [40/244] time 0.091 (0.100) data 0.000 (0.006) loss 1.1715 (1.2912) ce_loss 1.0381 (1.1518) teacher_loss 1.0371 (1.1519) loss_zs_kd 0.1373 (0.1368) loss_oracle 0.0658 (0.0709) acc 71.8750 (68.8281) kd_loss 0.0110 (0.0145) lr 1.9298e-03 eta 0:17:24
epoch [8/50] batch [60/244] time 0.102 (0.099) data 0.000 (0.004) loss 1.1342 (1.2772) ce_loss 0.9922 (1.1429) teacher_loss 0.9967 (1.1428) loss_zs_kd 0.1489 (0.1344) loss_oracle 0.0631 (0.0673) acc 78.1250 (69.3229) kd_loss 0.0157 (0.0145) lr 1.9298e-03 eta 0:17:07
epoch [8/50] batch [80/244] time 0.093 (0.097) data 0.000 (0.003) loss 1.3931 (1.2625) ce_loss 1.2207 (1.1324) teacher_loss 1.2204 (1.1325) loss_zs_kd 0.1997 (0.1367) loss_oracle 0.0729 (0.0616) acc 68.7500 (69.4922) kd_loss 0.0212 (0.0143) lr 1.9298e-03 eta 0:16:54
epoch [8/50] batch [100/244] time 0.094 (0.097) data 0.000 (0.002) loss 1.0632 (1.2734) ce_loss 0.9604 (1.1445) teacher_loss 0.9617 (1.1445) loss_zs_kd 0.1074 (0.1371) loss_oracle 0.0479 (0.0603) acc 75.0000 (69.0000) kd_loss 0.0098 (0.0141) lr 1.9298e-03 eta 0:16:46
epoch [8/50] batch [120/244] time 0.093 (0.096) data 0.000 (0.002) loss 1.0983 (1.2609) ce_loss 1.0088 (1.1349) teacher_loss 1.0090 (1.1349) loss_zs_kd 0.1151 (0.1381) loss_oracle 0.0318 (0.0569) acc 75.0000 (69.3750) kd_loss 0.0136 (0.0139) lr 1.9298e-03 eta 0:16:40
epoch [8/50] batch [140/244] time 0.095 (0.096) data 0.000 (0.002) loss 1.6213 (1.2735) ce_loss 1.4844 (1.1510) teacher_loss 1.4829 (1.1509) loss_zs_kd 0.1435 (0.1366) loss_oracle 0.0666 (0.0543) acc 65.6250 (69.3080) kd_loss 0.0195 (0.0141) lr 1.9298e-03 eta 0:16:36
epoch [8/50] batch [160/244] time 0.093 (0.096) data 0.000 (0.002) loss 1.5120 (1.2631) ce_loss 1.3838 (1.1424) teacher_loss 1.3800 (1.1423) loss_zs_kd 0.1494 (0.1362) loss_oracle 0.0573 (0.0527) acc 65.6250 (69.6289) kd_loss 0.0133 (0.0139) lr 1.9298e-03 eta 0:16:31
epoch [8/50] batch [180/244] time 0.091 (0.096) data 0.000 (0.001) loss 1.0823 (1.2571) ce_loss 0.9414 (1.1376) teacher_loss 0.9383 (1.1374) loss_zs_kd 0.1815 (0.1353) loss_oracle 0.0532 (0.0521) acc 78.1250 (69.8958) kd_loss 0.0136 (0.0138) lr 1.9298e-03 eta 0:16:28
epoch [8/50] batch [200/244] time 0.108 (0.096) data 0.001 (0.001) loss 1.2704 (1.2577) ce_loss 1.1865 (1.1400) teacher_loss 1.1885 (1.1396) loss_zs_kd 0.0963 (0.1336) loss_oracle 0.0338 (0.0513) acc 75.0000 (70.1562) kd_loss 0.0112 (0.0137) lr 1.9298e-03 eta 0:16:30
epoch [8/50] batch [220/244] time 0.099 (0.096) data 0.000 (0.001) loss 1.2492 (1.2547) ce_loss 1.1504 (1.1382) teacher_loss 1.1458 (1.1379) loss_zs_kd 0.1147 (0.1328) loss_oracle 0.0460 (0.0504) acc 62.5000 (70.0852) kd_loss 0.0126 (0.0137) lr 1.9298e-03 eta 0:16:28
epoch [8/50] batch [240/244] time 0.088 (0.096) data 0.000 (0.001) loss 1.4712 (1.2586) ce_loss 1.3477 (1.1421) teacher_loss 1.3448 (1.1419) loss_zs_kd 0.1326 (0.1324) loss_oracle 0.0601 (0.0505) acc 65.6250 (70.0260) kd_loss 0.0095 (0.0136) lr 1.9298e-03 eta 0:16:21
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,801
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.0%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.0%, epoch: 8 *******
******* Domain p best val test acc: 90.9%, epoch: 8 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [9/50] batch [20/244] time 0.095 (0.113) data 0.000 (0.013) loss 1.5787 (1.4299) ce_loss 1.4375 (1.2741) teacher_loss 1.4316 (1.2730) loss_zs_kd 0.1182 (0.1441) loss_oracle 0.0880 (0.0849) acc 62.5000 (68.9062) kd_loss 0.0122 (0.0137) lr 1.9048e-03 eta 0:19:12
epoch [9/50] batch [40/244] time 0.098 (0.103) data 0.000 (0.006) loss 1.3410 (1.3261) ce_loss 1.2539 (1.1832) teacher_loss 1.2552 (1.1830) loss_zs_kd 0.0793 (0.1296) loss_oracle 0.0461 (0.0783) acc 62.5000 (70.3125) kd_loss 0.0130 (0.0138) lr 1.9048e-03 eta 0:17:32
epoch [9/50] batch [60/244] time 0.096 (0.101) data 0.001 (0.004) loss 1.8127 (1.3135) ce_loss 1.6699 (1.1739) teacher_loss 1.6662 (1.1740) loss_zs_kd 0.1602 (0.1339) loss_oracle 0.0663 (0.0725) acc 59.3750 (70.3125) kd_loss 0.0129 (0.0133) lr 1.9048e-03 eta 0:17:08
epoch [9/50] batch [80/244] time 0.090 (0.100) data 0.000 (0.003) loss 1.7602 (1.3271) ce_loss 1.6182 (1.1810) teacher_loss 1.6142 (1.1808) loss_zs_kd 0.0932 (0.1372) loss_oracle 0.0994 (0.0777) acc 59.3750 (69.7656) kd_loss 0.0140 (0.0137) lr 1.9048e-03 eta 0:16:53
epoch [9/50] batch [100/244] time 0.093 (0.099) data 0.000 (0.003) loss 1.0885 (1.3176) ce_loss 0.9565 (1.1680) teacher_loss 0.9549 (1.1679) loss_zs_kd 0.1113 (0.1357) loss_oracle 0.0779 (0.0818) acc 65.6250 (69.8125) kd_loss 0.0144 (0.0143) lr 1.9048e-03 eta 0:16:43
epoch [9/50] batch [120/244] time 0.099 (0.098) data 0.000 (0.002) loss 1.6818 (1.3189) ce_loss 1.5566 (1.1693) teacher_loss 1.5510 (1.1693) loss_zs_kd 0.1000 (0.1357) loss_oracle 0.0808 (0.0818) acc 59.3750 (69.6615) kd_loss 0.0150 (0.0145) lr 1.9048e-03 eta 0:16:35
epoch [9/50] batch [140/244] time 0.091 (0.098) data 0.000 (0.002) loss 1.0903 (1.3276) ce_loss 0.9912 (1.1798) teacher_loss 0.9942 (1.1794) loss_zs_kd 0.0813 (0.1351) loss_oracle 0.0554 (0.0806) acc 71.8750 (69.2411) kd_loss 0.0108 (0.0151) lr 1.9048e-03 eta 0:16:30
epoch [9/50] batch [160/244] time 0.092 (0.098) data 0.000 (0.002) loss 0.8271 (1.3141) ce_loss 0.6890 (1.1667) teacher_loss 0.6893 (1.1662) loss_zs_kd 0.1190 (0.1362) loss_oracle 0.0783 (0.0798) acc 78.1250 (69.6289) kd_loss 0.0124 (0.0152) lr 1.9048e-03 eta 0:16:27
epoch [9/50] batch [180/244] time 0.099 (0.098) data 0.000 (0.002) loss 1.4123 (1.3076) ce_loss 1.2402 (1.1602) teacher_loss 1.2378 (1.1596) loss_zs_kd 0.1690 (0.1365) loss_oracle 0.0900 (0.0797) acc 68.7500 (69.5312) kd_loss 0.0182 (0.0155) lr 1.9048e-03 eta 0:16:27
epoch [9/50] batch [200/244] time 0.092 (0.098) data 0.000 (0.001) loss 1.3542 (1.3087) ce_loss 1.2139 (1.1589) teacher_loss 1.2187 (1.1585) loss_zs_kd 0.1131 (0.1383) loss_oracle 0.0790 (0.0810) acc 65.6250 (69.5625) kd_loss 0.0193 (0.0158) lr 1.9048e-03 eta 0:16:25
epoch [9/50] batch [220/244] time 0.102 (0.098) data 0.000 (0.001) loss 1.5984 (1.3081) ce_loss 1.4219 (1.1576) teacher_loss 1.4192 (1.1572) loss_zs_kd 0.1845 (0.1382) loss_oracle 0.0870 (0.0817) acc 71.8750 (69.6449) kd_loss 0.0165 (0.0160) lr 1.9048e-03 eta 0:16:25
epoch [9/50] batch [240/244] time 0.085 (0.098) data 0.000 (0.001) loss 1.5771 (1.3059) ce_loss 1.4316 (1.1543) teacher_loss 1.4348 (1.1540) loss_zs_kd 0.1687 (0.1391) loss_oracle 0.0579 (0.0824) acc 65.6250 (69.8047) kd_loss 0.0128 (0.0161) lr 1.9048e-03 eta 0:16:17
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,793
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,028
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.3%
******* Domain p best val acc:      84.0%, epoch: 8 *******
******* Domain p best val test acc: 90.9%, epoch: 8 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [10/50] batch [20/244] time 0.105 (0.115) data 0.000 (0.016) loss 1.1312 (1.2036) ce_loss 1.0186 (1.0787) teacher_loss 1.0184 (1.0792) loss_zs_kd 0.1083 (0.1249) loss_oracle 0.0587 (0.0620) acc 65.6250 (71.0938) kd_loss 0.0177 (0.0166) lr 1.8763e-03 eta 0:19:03
epoch [10/50] batch [40/244] time 0.095 (0.105) data 0.000 (0.008) loss 1.1677 (1.2201) ce_loss 1.0068 (1.0867) teacher_loss 1.0054 (1.0867) loss_zs_kd 0.1757 (0.1382) loss_oracle 0.0745 (0.0643) acc 81.2500 (71.0938) kd_loss 0.0202 (0.0174) lr 1.8763e-03 eta 0:17:30
epoch [10/50] batch [60/244] time 0.092 (0.102) data 0.001 (0.005) loss 1.3063 (1.2310) ce_loss 1.1748 (1.0965) teacher_loss 1.1776 (1.0968) loss_zs_kd 0.1141 (0.1359) loss_oracle 0.0716 (0.0663) acc 71.8750 (70.8333) kd_loss 0.0165 (0.0169) lr 1.8763e-03 eta 0:16:53
epoch [10/50] batch [80/244] time 0.092 (0.100) data 0.000 (0.004) loss 1.2803 (1.2585) ce_loss 1.1309 (1.1194) teacher_loss 1.1292 (1.1194) loss_zs_kd 0.1050 (0.1331) loss_oracle 0.0985 (0.0726) acc 65.6250 (70.1953) kd_loss 0.0155 (0.0170) lr 1.8763e-03 eta 0:16:35
epoch [10/50] batch [100/244] time 0.117 (0.100) data 0.000 (0.003) loss 1.3812 (1.2718) ce_loss 1.2373 (1.1301) teacher_loss 1.2367 (1.1301) loss_zs_kd 0.1513 (0.1357) loss_oracle 0.0688 (0.0739) acc 62.5000 (70.0312) kd_loss 0.0187 (0.0169) lr 1.8763e-03 eta 0:16:32
epoch [10/50] batch [120/244] time 0.115 (0.102) data 0.000 (0.003) loss 1.5509 (1.2833) ce_loss 1.4277 (1.1377) teacher_loss 1.4238 (1.1380) loss_zs_kd 0.1269 (0.1395) loss_oracle 0.0637 (0.0756) acc 65.6250 (69.8438) kd_loss 0.0125 (0.0170) lr 1.8763e-03 eta 0:16:45
epoch [10/50] batch [140/244] time 0.109 (0.103) data 0.000 (0.002) loss 1.1641 (1.2861) ce_loss 1.0449 (1.1421) teacher_loss 1.0456 (1.1422) loss_zs_kd 0.1071 (0.1407) loss_oracle 0.0650 (0.0736) acc 71.8750 (69.6429) kd_loss 0.0234 (0.0172) lr 1.8763e-03 eta 0:16:53
epoch [10/50] batch [160/244] time 0.103 (0.103) data 0.000 (0.002) loss 0.9733 (1.2719) ce_loss 0.8779 (1.1282) teacher_loss 0.8734 (1.1283) loss_zs_kd 0.0714 (0.1404) loss_oracle 0.0641 (0.0733) acc 75.0000 (70.0977) kd_loss 0.0143 (0.0170) lr 1.8763e-03 eta 0:16:54
epoch [10/50] batch [180/244] time 0.115 (0.104) data 0.000 (0.002) loss 1.4140 (1.2680) ce_loss 1.2803 (1.1250) teacher_loss 1.2786 (1.1250) loss_zs_kd 0.1208 (0.1400) loss_oracle 0.0750 (0.0730) acc 75.0000 (70.2604) kd_loss 0.0162 (0.0169) lr 1.8763e-03 eta 0:16:57
epoch [10/50] batch [200/244] time 0.116 (0.104) data 0.000 (0.002) loss 1.3012 (1.2808) ce_loss 1.1738 (1.1379) teacher_loss 1.1719 (1.1378) loss_zs_kd 0.1238 (0.1405) loss_oracle 0.0674 (0.0727) acc 65.6250 (69.9375) kd_loss 0.0127 (0.0167) lr 1.8763e-03 eta 0:17:01
epoch [10/50] batch [220/244] time 0.106 (0.104) data 0.000 (0.002) loss 1.1805 (1.2885) ce_loss 1.0020 (1.1461) teacher_loss 0.9995 (1.1458) loss_zs_kd 0.1939 (0.1403) loss_oracle 0.0840 (0.0726) acc 81.2500 (69.9006) kd_loss 0.0166 (0.0168) lr 1.8763e-03 eta 0:17:01
epoch [10/50] batch [240/244] time 0.103 (0.105) data 0.000 (0.001) loss 1.7000 (1.2912) ce_loss 1.5391 (1.1487) teacher_loss 1.5414 (1.1485) loss_zs_kd 0.1769 (0.1409) loss_oracle 0.0702 (0.0723) acc 59.3750 (69.7786) kd_loss 0.0110 (0.0166) lr 1.8763e-03 eta 0:17:05
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,804
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.0%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,048
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.7%
******* Domain p best val acc:      84.1%, epoch: 10 *******
******* Domain p best val test acc: 91.2%, epoch: 10 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [11/50] batch [20/244] time 0.098 (0.118) data 0.000 (0.012) loss 0.9085 (1.2528) ce_loss 0.8042 (1.1244) teacher_loss 0.8069 (1.1246) loss_zs_kd 0.0990 (0.1274) loss_oracle 0.0521 (0.0645) acc 75.0000 (71.0938) kd_loss 0.0155 (0.0166) lr 1.8443e-03 eta 0:19:06
epoch [11/50] batch [40/244] time 0.102 (0.108) data 0.000 (0.006) loss 1.2918 (1.2618) ce_loss 1.1338 (1.1260) teacher_loss 1.1305 (1.1256) loss_zs_kd 0.1280 (0.1317) loss_oracle 0.0974 (0.0703) acc 75.0000 (70.7031) kd_loss 0.0146 (0.0164) lr 1.8443e-03 eta 0:17:31
epoch [11/50] batch [60/244] time 0.096 (0.105) data 0.000 (0.004) loss 1.0604 (1.2650) ce_loss 0.9580 (1.1285) teacher_loss 0.9594 (1.1283) loss_zs_kd 0.1156 (0.1350) loss_oracle 0.0432 (0.0692) acc 75.0000 (70.7812) kd_loss 0.0099 (0.0163) lr 1.8443e-03 eta 0:16:59
epoch [11/50] batch [80/244] time 0.094 (0.103) data 0.000 (0.003) loss 1.1867 (1.2571) ce_loss 1.0840 (1.1240) teacher_loss 1.0831 (1.1235) loss_zs_kd 0.1210 (0.1341) loss_oracle 0.0431 (0.0666) acc 68.7500 (70.7812) kd_loss 0.0088 (0.0161) lr 1.8443e-03 eta 0:16:40
epoch [11/50] batch [100/244] time 0.091 (0.102) data 0.000 (0.003) loss 1.2361 (1.2415) ce_loss 1.0596 (1.1065) teacher_loss 1.0632 (1.1059) loss_zs_kd 0.1443 (0.1344) loss_oracle 0.1008 (0.0684) acc 71.8750 (70.7500) kd_loss 0.0234 (0.0163) lr 1.8443e-03 eta 0:16:21
epoch [11/50] batch [120/244] time 0.088 (0.100) data 0.000 (0.002) loss 1.0836 (1.2557) ce_loss 0.9678 (1.1193) teacher_loss 0.9737 (1.1189) loss_zs_kd 0.0932 (0.1369) loss_oracle 0.0633 (0.0684) acc 78.1250 (70.7031) kd_loss 0.0132 (0.0162) lr 1.8443e-03 eta 0:16:02
epoch [11/50] batch [140/244] time 0.096 (0.099) data 0.000 (0.002) loss 0.6622 (1.2581) ce_loss 0.5752 (1.1238) teacher_loss 0.5780 (1.1237) loss_zs_kd 0.0722 (0.1346) loss_oracle 0.0481 (0.0672) acc 84.3750 (70.6027) kd_loss 0.0111 (0.0160) lr 1.8443e-03 eta 0:15:52
epoch [11/50] batch [160/244] time 0.092 (0.099) data 0.000 (0.002) loss 1.2084 (1.2664) ce_loss 1.0605 (1.1338) teacher_loss 1.0570 (1.1333) loss_zs_kd 0.1704 (0.1348) loss_oracle 0.0663 (0.0657) acc 75.0000 (70.4297) kd_loss 0.0228 (0.0161) lr 1.8443e-03 eta 0:15:46
epoch [11/50] batch [180/244] time 0.093 (0.098) data 0.000 (0.002) loss 1.1870 (1.2616) ce_loss 1.0576 (1.1283) teacher_loss 1.0611 (1.1277) loss_zs_kd 0.1134 (0.1347) loss_oracle 0.0692 (0.0665) acc 75.0000 (70.4340) kd_loss 0.0108 (0.0161) lr 1.8443e-03 eta 0:15:40
epoch [11/50] batch [200/244] time 0.094 (0.098) data 0.000 (0.001) loss 1.3529 (1.2605) ce_loss 1.2412 (1.1273) teacher_loss 1.2381 (1.1266) loss_zs_kd 0.0754 (0.1345) loss_oracle 0.0771 (0.0667) acc 68.7500 (70.4062) kd_loss 0.0159 (0.0161) lr 1.8443e-03 eta 0:15:35
epoch [11/50] batch [220/244] time 0.097 (0.098) data 0.000 (0.001) loss 0.7529 (1.2485) ce_loss 0.5874 (1.1141) teacher_loss 0.5878 (1.1134) loss_zs_kd 0.0948 (0.1341) loss_oracle 0.1177 (0.0680) acc 90.6250 (70.8523) kd_loss 0.0191 (0.0160) lr 1.8443e-03 eta 0:15:31
epoch [11/50] batch [240/244] time 0.084 (0.097) data 0.000 (0.001) loss 1.0082 (1.2500) ce_loss 0.8589 (1.1149) teacher_loss 0.8613 (1.1142) loss_zs_kd 0.1622 (0.1340) loss_oracle 0.0658 (0.0688) acc 75.0000 (70.8724) kd_loss 0.0139 (0.0160) lr 1.8443e-03 eta 0:15:23
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,806
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.1%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.2%, epoch: 11 *******
******* Domain p best val test acc: 91.1%, epoch: 11 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [12/50] batch [20/244] time 0.083 (0.112) data 0.000 (0.011) loss 1.4315 (1.2078) ce_loss 1.2334 (1.0465) teacher_loss 1.2360 (1.0456) loss_zs_kd 0.1956 (0.1443) loss_oracle 0.0977 (0.0900) acc 65.6250 (72.0312) kd_loss 0.0224 (0.0175) lr 1.8090e-03 eta 0:17:44
epoch [12/50] batch [40/244] time 0.103 (0.103) data 0.000 (0.006) loss 1.1156 (1.2333) ce_loss 0.9858 (1.0731) teacher_loss 0.9895 (1.0740) loss_zs_kd 0.1384 (0.1472) loss_oracle 0.0569 (0.0858) acc 78.1250 (71.9531) kd_loss 0.0153 (0.0166) lr 1.8090e-03 eta 0:16:18
epoch [12/50] batch [60/244] time 0.089 (0.101) data 0.000 (0.004) loss 1.1830 (1.2479) ce_loss 1.0635 (1.0980) teacher_loss 1.0635 (1.0984) loss_zs_kd 0.0953 (0.1433) loss_oracle 0.0718 (0.0779) acc 68.7500 (71.8750) kd_loss 0.0153 (0.0163) lr 1.8090e-03 eta 0:15:53
epoch [12/50] batch [80/244] time 0.102 (0.100) data 0.000 (0.003) loss 1.0001 (1.2663) ce_loss 0.8755 (1.1179) teacher_loss 0.8739 (1.1184) loss_zs_kd 0.1170 (0.1448) loss_oracle 0.0678 (0.0755) acc 78.1250 (71.2109) kd_loss 0.0179 (0.0160) lr 1.8090e-03 eta 0:15:41
epoch [12/50] batch [100/244] time 0.088 (0.099) data 0.000 (0.002) loss 1.3829 (1.2628) ce_loss 1.2617 (1.1157) teacher_loss 1.2599 (1.1160) loss_zs_kd 0.1470 (0.1451) loss_oracle 0.0495 (0.0742) acc 62.5000 (70.7812) kd_loss 0.0159 (0.0162) lr 1.8090e-03 eta 0:15:27
epoch [12/50] batch [120/244] time 0.098 (0.098) data 0.000 (0.002) loss 1.1601 (1.2646) ce_loss 0.9673 (1.1175) teacher_loss 0.9702 (1.1178) loss_zs_kd 0.2157 (0.1443) loss_oracle 0.0821 (0.0747) acc 71.8750 (70.6250) kd_loss 0.0183 (0.0162) lr 1.8090e-03 eta 0:15:19
epoch [12/50] batch [140/244] time 0.098 (0.098) data 0.001 (0.002) loss 1.6533 (1.2838) ce_loss 1.4678 (1.1332) teacher_loss 1.4675 (1.1335) loss_zs_kd 0.1442 (0.1459) loss_oracle 0.1137 (0.0773) acc 56.2500 (70.2009) kd_loss 0.0229 (0.0162) lr 1.8090e-03 eta 0:15:14
epoch [12/50] batch [160/244] time 0.094 (0.097) data 0.000 (0.002) loss 1.3992 (1.2761) ce_loss 1.2744 (1.1253) teacher_loss 1.2757 (1.1257) loss_zs_kd 0.1402 (0.1451) loss_oracle 0.0534 (0.0778) acc 65.6250 (70.3516) kd_loss 0.0127 (0.0164) lr 1.8090e-03 eta 0:15:11
epoch [12/50] batch [180/244] time 0.094 (0.097) data 0.000 (0.001) loss 1.4894 (1.2775) ce_loss 1.3057 (1.1287) teacher_loss 1.3036 (1.1289) loss_zs_kd 0.2250 (0.1457) loss_oracle 0.0733 (0.0757) acc 68.7500 (70.4167) kd_loss 0.0186 (0.0165) lr 1.8090e-03 eta 0:15:06
epoch [12/50] batch [200/244] time 0.093 (0.097) data 0.000 (0.001) loss 1.3714 (1.2696) ce_loss 1.2295 (1.1228) teacher_loss 1.2271 (1.1228) loss_zs_kd 0.1614 (0.1453) loss_oracle 0.0636 (0.0742) acc 62.5000 (70.5312) kd_loss 0.0215 (0.0167) lr 1.8090e-03 eta 0:15:02
epoch [12/50] batch [220/244] time 0.093 (0.097) data 0.000 (0.001) loss 1.4580 (1.2701) ce_loss 1.3408 (1.1235) teacher_loss 1.3382 (1.1236) loss_zs_kd 0.1091 (0.1462) loss_oracle 0.0653 (0.0734) acc 65.6250 (70.4972) kd_loss 0.0139 (0.0165) lr 1.8090e-03 eta 0:14:59
epoch [12/50] batch [240/244] time 0.085 (0.096) data 0.000 (0.001) loss 1.0291 (1.2648) ce_loss 0.9111 (1.1182) teacher_loss 0.9066 (1.1183) loss_zs_kd 0.1073 (0.1460) loss_oracle 0.0688 (0.0735) acc 78.1250 (70.6120) kd_loss 0.0140 (0.0165) lr 1.8090e-03 eta 0:14:51
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,794
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.2%, epoch: 11 *******
******* Domain p best val test acc: 91.1%, epoch: 11 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [13/50] batch [20/244] time 0.089 (0.108) data 0.000 (0.013) loss 0.8651 (1.1829) ce_loss 0.7056 (1.0389) teacher_loss 0.7079 (1.0387) loss_zs_kd 0.1322 (0.1348) loss_oracle 0.0911 (0.0769) acc 84.3750 (71.8750) kd_loss 0.0148 (0.0176) lr 1.7705e-03 eta 0:16:39
epoch [13/50] batch [40/244] time 0.091 (0.100) data 0.000 (0.007) loss 1.1368 (1.2167) ce_loss 0.9844 (1.0714) teacher_loss 0.9861 (1.0706) loss_zs_kd 0.1562 (0.1381) loss_oracle 0.0726 (0.0770) acc 81.2500 (71.0156) kd_loss 0.0177 (0.0182) lr 1.7705e-03 eta 0:15:18
epoch [13/50] batch [60/244] time 0.098 (0.097) data 0.001 (0.005) loss 1.1532 (1.2294) ce_loss 1.0303 (1.0895) teacher_loss 1.0309 (1.0890) loss_zs_kd 0.1758 (0.1384) loss_oracle 0.0343 (0.0713) acc 75.0000 (70.8854) kd_loss 0.0162 (0.0182) lr 1.7705e-03 eta 0:14:55
epoch [13/50] batch [80/244] time 0.097 (0.097) data 0.000 (0.003) loss 1.8638 (1.2599) ce_loss 1.6777 (1.1184) teacher_loss 1.6778 (1.1178) loss_zs_kd 0.1536 (0.1415) loss_oracle 0.1092 (0.0714) acc 53.1250 (70.3516) kd_loss 0.0200 (0.0182) lr 1.7705e-03 eta 0:14:47
epoch [13/50] batch [100/244] time 0.100 (0.096) data 0.000 (0.003) loss 1.6718 (1.2679) ce_loss 1.5625 (1.1240) teacher_loss 1.5653 (1.1235) loss_zs_kd 0.1044 (0.1422) loss_oracle 0.0543 (0.0733) acc 59.3750 (70.2812) kd_loss 0.0122 (0.0181) lr 1.7705e-03 eta 0:14:40
epoch [13/50] batch [120/244] time 0.108 (0.097) data 0.000 (0.002) loss 1.3840 (1.2635) ce_loss 1.2363 (1.1211) teacher_loss 1.2329 (1.1206) loss_zs_kd 0.1366 (0.1402) loss_oracle 0.0828 (0.0728) acc 68.7500 (70.5990) kd_loss 0.0239 (0.0184) lr 1.7705e-03 eta 0:14:43
epoch [13/50] batch [140/244] time 0.104 (0.097) data 0.000 (0.002) loss 1.7143 (1.2772) ce_loss 1.5303 (1.1321) teacher_loss 1.5298 (1.1316) loss_zs_kd 0.1843 (0.1430) loss_oracle 0.0924 (0.0741) acc 65.6250 (70.5804) kd_loss 0.0219 (0.0184) lr 1.7705e-03 eta 0:14:49
epoch [13/50] batch [160/244] time 0.099 (0.098) data 0.000 (0.002) loss 1.6893 (1.2681) ce_loss 1.5107 (1.1217) teacher_loss 1.5065 (1.1214) loss_zs_kd 0.1349 (0.1403) loss_oracle 0.1154 (0.0766) acc 65.6250 (70.7422) kd_loss 0.0204 (0.0185) lr 1.7705e-03 eta 0:14:50
epoch [13/50] batch [180/244] time 0.093 (0.098) data 0.000 (0.002) loss 1.3573 (1.2736) ce_loss 1.2080 (1.1262) teacher_loss 1.2075 (1.1257) loss_zs_kd 0.1708 (0.1404) loss_oracle 0.0644 (0.0777) acc 78.1250 (70.6250) kd_loss 0.0195 (0.0184) lr 1.7705e-03 eta 0:14:50
epoch [13/50] batch [200/244] time 0.096 (0.098) data 0.000 (0.002) loss 1.2444 (1.2747) ce_loss 1.1152 (1.1289) teacher_loss 1.1138 (1.1286) loss_zs_kd 0.1367 (0.1395) loss_oracle 0.0623 (0.0763) acc 71.8750 (70.5156) kd_loss 0.0226 (0.0185) lr 1.7705e-03 eta 0:14:48
epoch [13/50] batch [220/244] time 0.098 (0.098) data 0.000 (0.001) loss 0.7575 (1.2642) ce_loss 0.5811 (1.1203) teacher_loss 0.5827 (1.1200) loss_zs_kd 0.2078 (0.1391) loss_oracle 0.0709 (0.0747) acc 87.5000 (70.8097) kd_loss 0.0198 (0.0186) lr 1.7705e-03 eta 0:14:47
epoch [13/50] batch [240/244] time 0.104 (0.098) data 0.000 (0.001) loss 1.4385 (1.2593) ce_loss 1.3115 (1.1176) teacher_loss 1.3115 (1.1171) loss_zs_kd 0.1454 (0.1389) loss_oracle 0.0543 (0.0727) acc 68.7500 (70.8594) kd_loss 0.0202 (0.0186) lr 1.7705e-03 eta 0:14:48
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,800
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 82.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,035
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.2%, epoch: 11 *******
******* Domain p best val test acc: 91.1%, epoch: 11 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [14/50] batch [20/244] time 0.100 (0.112) data 0.000 (0.014) loss 1.1394 (1.2431) ce_loss 0.9790 (1.0996) teacher_loss 0.9848 (1.0987) loss_zs_kd 0.1609 (0.1533) loss_oracle 0.0742 (0.0678) acc 71.8750 (70.0000) kd_loss 0.0181 (0.0203) lr 1.7290e-03 eta 0:16:49
epoch [14/50] batch [40/244] time 0.090 (0.103) data 0.000 (0.007) loss 1.1067 (1.2497) ce_loss 0.9482 (1.1064) teacher_loss 0.9535 (1.1043) loss_zs_kd 0.1490 (0.1545) loss_oracle 0.0787 (0.0682) acc 71.8750 (70.3906) kd_loss 0.0189 (0.0206) lr 1.7290e-03 eta 0:15:28
epoch [14/50] batch [60/244] time 0.097 (0.102) data 0.000 (0.005) loss 1.2027 (1.2452) ce_loss 1.0645 (1.0992) teacher_loss 1.0616 (1.0971) loss_zs_kd 0.1167 (0.1546) loss_oracle 0.0827 (0.0708) acc 81.2500 (70.7292) kd_loss 0.0260 (0.0205) lr 1.7290e-03 eta 0:15:13
epoch [14/50] batch [80/244] time 0.100 (0.102) data 0.000 (0.004) loss 1.0821 (1.2197) ce_loss 0.9692 (1.0738) teacher_loss 0.9709 (1.0723) loss_zs_kd 0.1211 (0.1549) loss_oracle 0.0506 (0.0700) acc 75.0000 (71.4453) kd_loss 0.0173 (0.0199) lr 1.7290e-03 eta 0:15:08
epoch [14/50] batch [100/244] time 0.099 (0.101) data 0.000 (0.003) loss 1.3676 (1.2092) ce_loss 1.2461 (1.0662) teacher_loss 1.2448 (1.0645) loss_zs_kd 0.1122 (0.1515) loss_oracle 0.0666 (0.0689) acc 68.7500 (71.8750) kd_loss 0.0164 (0.0201) lr 1.7290e-03 eta 0:15:04
epoch [14/50] batch [120/244] time 0.105 (0.101) data 0.000 (0.003) loss 1.0494 (1.1958) ce_loss 0.9248 (1.0534) teacher_loss 0.9308 (1.0520) loss_zs_kd 0.0955 (0.1492) loss_oracle 0.0708 (0.0693) acc 81.2500 (72.1354) kd_loss 0.0146 (0.0202) lr 1.7290e-03 eta 0:15:00
epoch [14/50] batch [140/244] time 0.096 (0.101) data 0.000 (0.002) loss 1.5486 (1.2053) ce_loss 1.4023 (1.0626) teacher_loss 1.3989 (1.0611) loss_zs_kd 0.1440 (0.1488) loss_oracle 0.0777 (0.0698) acc 62.5000 (71.9196) kd_loss 0.0206 (0.0203) lr 1.7290e-03 eta 0:14:54
epoch [14/50] batch [160/244] time 0.095 (0.100) data 0.000 (0.002) loss 1.3923 (1.2108) ce_loss 1.2607 (1.0693) teacher_loss 1.2618 (1.0678) loss_zs_kd 0.1615 (0.1487) loss_oracle 0.0497 (0.0686) acc 75.0000 (71.8359) kd_loss 0.0208 (0.0203) lr 1.7290e-03 eta 0:14:45
epoch [14/50] batch [180/244] time 0.098 (0.099) data 0.000 (0.002) loss 1.3116 (1.2005) ce_loss 1.1963 (1.0606) teacher_loss 1.1932 (1.0593) loss_zs_kd 0.0880 (0.1465) loss_oracle 0.0744 (0.0679) acc 68.7500 (72.0312) kd_loss 0.0217 (0.0201) lr 1.7290e-03 eta 0:14:39
epoch [14/50] batch [200/244] time 0.099 (0.099) data 0.000 (0.002) loss 1.1100 (1.2024) ce_loss 0.9819 (1.0627) teacher_loss 0.9795 (1.0615) loss_zs_kd 0.1310 (0.1454) loss_oracle 0.0651 (0.0682) acc 71.8750 (71.9219) kd_loss 0.0222 (0.0202) lr 1.7290e-03 eta 0:14:32
epoch [14/50] batch [220/244] time 0.083 (0.098) data 0.000 (0.002) loss 0.8665 (1.1953) ce_loss 0.7119 (1.0564) teacher_loss 0.6984 (1.0552) loss_zs_kd 0.1381 (0.1460) loss_oracle 0.0990 (0.0672) acc 84.3750 (72.1449) kd_loss 0.0274 (0.0203) lr 1.7290e-03 eta 0:14:25
epoch [14/50] batch [240/244] time 0.084 (0.097) data 0.000 (0.001) loss 1.3033 (1.2043) ce_loss 1.1709 (1.0675) teacher_loss 1.1705 (1.0662) loss_zs_kd 0.1654 (0.1446) loss_oracle 0.0502 (0.0657) acc 68.7500 (71.8359) kd_loss 0.0140 (0.0204) lr 1.7290e-03 eta 0:14:15
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,805
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,035
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.2%, epoch: 11 *******
******* Domain p best val test acc: 91.1%, epoch: 11 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [15/50] batch [20/244] time 0.100 (0.113) data 0.000 (0.014) loss 0.8969 (1.2102) ce_loss 0.7915 (1.0799) teacher_loss 0.7928 (1.0781) loss_zs_kd 0.1030 (0.1300) loss_oracle 0.0525 (0.0671) acc 81.2500 (72.0312) kd_loss 0.0193 (0.0223) lr 1.6845e-03 eta 0:16:26
epoch [15/50] batch [40/244] time 0.101 (0.104) data 0.000 (0.007) loss 0.9440 (1.2593) ce_loss 0.8081 (1.1133) teacher_loss 0.8070 (1.1121) loss_zs_kd 0.1160 (0.1385) loss_oracle 0.0790 (0.0780) acc 75.0000 (70.3906) kd_loss 0.0314 (0.0226) lr 1.6845e-03 eta 0:15:10
epoch [15/50] batch [60/244] time 0.098 (0.101) data 0.000 (0.005) loss 0.7241 (1.2504) ce_loss 0.5825 (1.1027) teacher_loss 0.5882 (1.1016) loss_zs_kd 0.1585 (0.1406) loss_oracle 0.0567 (0.0785) acc 81.2500 (70.8333) kd_loss 0.0205 (0.0238) lr 1.6845e-03 eta 0:14:41
epoch [15/50] batch [80/244] time 0.092 (0.099) data 0.000 (0.004) loss 1.5287 (1.2449) ce_loss 1.3887 (1.1002) teacher_loss 1.3811 (1.0986) loss_zs_kd 0.1282 (0.1408) loss_oracle 0.0835 (0.0760) acc 71.8750 (70.7812) kd_loss 0.0276 (0.0246) lr 1.6845e-03 eta 0:14:25
epoch [15/50] batch [100/244] time 0.096 (0.099) data 0.000 (0.003) loss 1.4361 (1.2294) ce_loss 1.2637 (1.0867) teacher_loss 1.2680 (1.0857) loss_zs_kd 0.2069 (0.1434) loss_oracle 0.0647 (0.0720) acc 59.3750 (71.1250) kd_loss 0.0231 (0.0244) lr 1.6845e-03 eta 0:14:18
epoch [15/50] batch [120/244] time 0.093 (0.098) data 0.000 (0.002) loss 1.1360 (1.2208) ce_loss 0.9756 (1.0785) teacher_loss 0.9655 (1.0776) loss_zs_kd 0.1448 (0.1439) loss_oracle 0.0981 (0.0713) acc 59.3750 (71.1198) kd_loss 0.0265 (0.0241) lr 1.6845e-03 eta 0:14:11
epoch [15/50] batch [140/244] time 0.093 (0.098) data 0.000 (0.002) loss 0.9078 (1.2251) ce_loss 0.7310 (1.0818) teacher_loss 0.7302 (1.0807) loss_zs_kd 0.1862 (0.1445) loss_oracle 0.0845 (0.0722) acc 84.3750 (71.1830) kd_loss 0.0226 (0.0238) lr 1.6845e-03 eta 0:14:06
epoch [15/50] batch [160/244] time 0.094 (0.098) data 0.000 (0.002) loss 1.1006 (1.2327) ce_loss 0.9531 (1.0887) teacher_loss 0.9532 (1.0875) loss_zs_kd 0.1519 (0.1447) loss_oracle 0.0715 (0.0729) acc 78.1250 (71.1719) kd_loss 0.0221 (0.0236) lr 1.6845e-03 eta 0:14:03
epoch [15/50] batch [180/244] time 0.090 (0.097) data 0.000 (0.002) loss 0.8157 (1.2250) ce_loss 0.6855 (1.0813) teacher_loss 0.6881 (1.0803) loss_zs_kd 0.1319 (0.1455) loss_oracle 0.0616 (0.0720) acc 81.2500 (71.3368) kd_loss 0.0167 (0.0234) lr 1.6845e-03 eta 0:13:56
epoch [15/50] batch [200/244] time 0.091 (0.097) data 0.000 (0.002) loss 0.8960 (1.2200) ce_loss 0.7646 (1.0778) teacher_loss 0.7663 (1.0768) loss_zs_kd 0.1846 (0.1459) loss_oracle 0.0375 (0.0703) acc 84.3750 (71.5625) kd_loss 0.0225 (0.0235) lr 1.6845e-03 eta 0:13:49
epoch [15/50] batch [220/244] time 0.091 (0.096) data 0.000 (0.001) loss 1.0940 (1.2264) ce_loss 0.9844 (1.0869) teacher_loss 0.9820 (1.0858) loss_zs_kd 0.1314 (0.1449) loss_oracle 0.0463 (0.0682) acc 84.3750 (71.4205) kd_loss 0.0303 (0.0238) lr 1.6845e-03 eta 0:13:42
epoch [15/50] batch [240/244] time 0.085 (0.096) data 0.000 (0.001) loss 1.1705 (1.2302) ce_loss 0.9819 (1.0920) teacher_loss 0.9772 (1.0909) loss_zs_kd 0.2690 (0.1454) loss_oracle 0.0588 (0.0666) acc 71.8750 (71.2630) kd_loss 0.0347 (0.0240) lr 1.6845e-03 eta 0:13:36
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,817
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.4%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,027
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.1%
******* Domain p best val acc:      84.5%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [16/50] batch [20/244] time 0.099 (0.115) data 0.000 (0.012) loss 0.8881 (1.2664) ce_loss 0.7422 (1.1309) teacher_loss 0.7399 (1.1313) loss_zs_kd 0.1653 (0.1561) loss_oracle 0.0655 (0.0571) acc 75.0000 (69.6875) kd_loss 0.0244 (0.0250) lr 1.6374e-03 eta 0:16:22
epoch [16/50] batch [40/244] time 0.096 (0.106) data 0.000 (0.006) loss 0.8417 (1.2734) ce_loss 0.7139 (1.1294) teacher_loss 0.7133 (1.1293) loss_zs_kd 0.1059 (0.1579) loss_oracle 0.0755 (0.0652) acc 84.3750 (70.6250) kd_loss 0.0274 (0.0248) lr 1.6374e-03 eta 0:15:02
epoch [16/50] batch [60/244] time 0.097 (0.103) data 0.001 (0.004) loss 1.0582 (1.2681) ce_loss 0.8916 (1.1200) teacher_loss 0.8940 (1.1199) loss_zs_kd 0.1698 (0.1574) loss_oracle 0.0793 (0.0695) acc 68.7500 (70.1042) kd_loss 0.0177 (0.0245) lr 1.6374e-03 eta 0:14:35
epoch [16/50] batch [80/244] time 0.097 (0.101) data 0.000 (0.003) loss 1.2257 (1.2795) ce_loss 1.0576 (1.1348) teacher_loss 1.0635 (1.1348) loss_zs_kd 0.2060 (0.1539) loss_oracle 0.0592 (0.0678) acc 65.6250 (70.1562) kd_loss 0.0247 (0.0238) lr 1.6374e-03 eta 0:14:13
epoch [16/50] batch [100/244] time 0.093 (0.100) data 0.000 (0.003) loss 1.0782 (1.2777) ce_loss 0.9253 (1.1339) teacher_loss 0.9296 (1.1337) loss_zs_kd 0.1419 (0.1503) loss_oracle 0.0776 (0.0689) acc 75.0000 (70.1875) kd_loss 0.0186 (0.0235) lr 1.6374e-03 eta 0:14:00
epoch [16/50] batch [120/244] time 0.096 (0.100) data 0.000 (0.002) loss 1.7077 (1.2810) ce_loss 1.5645 (1.1343) teacher_loss 1.5592 (1.1338) loss_zs_kd 0.1141 (0.1474) loss_oracle 0.0914 (0.0734) acc 65.6250 (70.1302) kd_loss 0.0212 (0.0235) lr 1.6374e-03 eta 0:13:58
epoch [16/50] batch [140/244] time 0.102 (0.100) data 0.000 (0.002) loss 0.8111 (1.2676) ce_loss 0.6519 (1.1184) teacher_loss 0.6541 (1.1181) loss_zs_kd 0.1507 (0.1476) loss_oracle 0.0817 (0.0757) acc 84.3750 (70.4911) kd_loss 0.0300 (0.0237) lr 1.6374e-03 eta 0:13:56
epoch [16/50] batch [160/244] time 0.098 (0.100) data 0.000 (0.002) loss 0.7578 (1.2527) ce_loss 0.6372 (1.1056) teacher_loss 0.6395 (1.1054) loss_zs_kd 0.1237 (0.1461) loss_oracle 0.0565 (0.0743) acc 84.3750 (70.7617) kd_loss 0.0261 (0.0238) lr 1.6374e-03 eta 0:13:54
epoch [16/50] batch [180/244] time 0.101 (0.100) data 0.000 (0.002) loss 0.9988 (1.2510) ce_loss 0.8491 (1.1045) teacher_loss 0.8486 (1.1040) loss_zs_kd 0.1655 (0.1459) loss_oracle 0.0675 (0.0740) acc 81.2500 (70.7639) kd_loss 0.0310 (0.0239) lr 1.6374e-03 eta 0:13:54
epoch [16/50] batch [200/244] time 0.096 (0.100) data 0.000 (0.001) loss 1.4045 (1.2588) ce_loss 1.2275 (1.1114) teacher_loss 1.2206 (1.1111) loss_zs_kd 0.1718 (0.1446) loss_oracle 0.0980 (0.0754) acc 71.8750 (70.6719) kd_loss 0.0297 (0.0241) lr 1.6374e-03 eta 0:13:51
epoch [16/50] batch [220/244] time 0.094 (0.100) data 0.000 (0.001) loss 1.8660 (1.2547) ce_loss 1.6729 (1.1070) teacher_loss 1.6628 (1.1065) loss_zs_kd 0.2312 (0.1444) loss_oracle 0.0877 (0.0760) acc 50.0000 (70.7386) kd_loss 0.0301 (0.0243) lr 1.6374e-03 eta 0:13:49
epoch [16/50] batch [240/244] time 0.091 (0.100) data 0.000 (0.001) loss 0.7698 (1.2545) ce_loss 0.6533 (1.1070) teacher_loss 0.6537 (1.1063) loss_zs_kd 0.1078 (0.1445) loss_oracle 0.0622 (0.0759) acc 84.3750 (70.6380) kd_loss 0.0286 (0.0247) lr 1.6374e-03 eta 0:13:46
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,815
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.5%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [17/50] batch [20/244] time 0.100 (0.115) data 0.000 (0.013) loss 1.2929 (1.2750) ce_loss 1.1641 (1.1452) teacher_loss 1.1680 (1.1430) loss_zs_kd 0.1114 (0.1412) loss_oracle 0.0693 (0.0614) acc 68.7500 (68.5938) kd_loss 0.0246 (0.0300) lr 1.5878e-03 eta 0:15:53
epoch [17/50] batch [40/244] time 0.109 (0.108) data 0.000 (0.007) loss 1.3036 (1.2879) ce_loss 1.1953 (1.1600) teacher_loss 1.1867 (1.1581) loss_zs_kd 0.1104 (0.1410) loss_oracle 0.0617 (0.0593) acc 62.5000 (68.1250) kd_loss 0.0316 (0.0295) lr 1.5878e-03 eta 0:14:54
epoch [17/50] batch [60/244] time 0.102 (0.106) data 0.001 (0.005) loss 1.5418 (1.2563) ce_loss 1.4121 (1.1269) teacher_loss 1.4126 (1.1252) loss_zs_kd 0.1459 (0.1407) loss_oracle 0.0562 (0.0608) acc 59.3750 (69.0104) kd_loss 0.0231 (0.0281) lr 1.5878e-03 eta 0:14:34
epoch [17/50] batch [80/244] time 0.089 (0.103) data 0.000 (0.004) loss 0.8665 (1.2697) ce_loss 0.7178 (1.1371) teacher_loss 0.7145 (1.1354) loss_zs_kd 0.1391 (0.1403) loss_oracle 0.0824 (0.0642) acc 81.2500 (69.0625) kd_loss 0.0381 (0.0281) lr 1.5878e-03 eta 0:14:07
epoch [17/50] batch [100/244] time 0.103 (0.102) data 0.000 (0.003) loss 1.0434 (1.2536) ce_loss 0.8872 (1.1196) teacher_loss 0.8890 (1.1178) loss_zs_kd 0.1509 (0.1413) loss_oracle 0.0789 (0.0652) acc 71.8750 (69.6875) kd_loss 0.0301 (0.0281) lr 1.5878e-03 eta 0:13:54
epoch [17/50] batch [120/244] time 0.092 (0.101) data 0.000 (0.002) loss 1.0471 (1.2502) ce_loss 0.9009 (1.1141) teacher_loss 0.9045 (1.1125) loss_zs_kd 0.1689 (0.1439) loss_oracle 0.0582 (0.0657) acc 75.0000 (70.1823) kd_loss 0.0264 (0.0284) lr 1.5878e-03 eta 0:13:43
epoch [17/50] batch [140/244] time 0.098 (0.100) data 0.000 (0.002) loss 1.0557 (1.2480) ce_loss 0.9536 (1.1106) teacher_loss 0.9538 (1.1090) loss_zs_kd 0.0903 (0.1454) loss_oracle 0.0567 (0.0663) acc 68.7500 (70.1562) kd_loss 0.0300 (0.0288) lr 1.5878e-03 eta 0:13:36
epoch [17/50] batch [160/244] time 0.110 (0.100) data 0.000 (0.002) loss 1.1050 (1.2488) ce_loss 0.9517 (1.1120) teacher_loss 0.9569 (1.1102) loss_zs_kd 0.1697 (0.1447) loss_oracle 0.0633 (0.0663) acc 81.2500 (70.2148) kd_loss 0.0339 (0.0293) lr 1.5878e-03 eta 0:13:33
epoch [17/50] batch [180/244] time 0.100 (0.100) data 0.000 (0.002) loss 0.8546 (1.2453) ce_loss 0.6572 (1.1057) teacher_loss 0.6579 (1.1041) loss_zs_kd 0.1550 (0.1466) loss_oracle 0.1192 (0.0678) acc 78.1250 (70.3819) kd_loss 0.0322 (0.0295) lr 1.5878e-03 eta 0:13:33
epoch [17/50] batch [200/244] time 0.099 (0.100) data 0.000 (0.002) loss 0.9410 (1.2568) ce_loss 0.8213 (1.1161) teacher_loss 0.8209 (1.1145) loss_zs_kd 0.1037 (0.1461) loss_oracle 0.0683 (0.0692) acc 68.7500 (70.2344) kd_loss 0.0192 (0.0294) lr 1.5878e-03 eta 0:13:32
epoch [17/50] batch [220/244] time 0.098 (0.100) data 0.000 (0.001) loss 1.1060 (1.2532) ce_loss 0.9844 (1.1133) teacher_loss 0.9888 (1.1119) loss_zs_kd 0.1245 (0.1457) loss_oracle 0.0550 (0.0684) acc 65.6250 (70.4830) kd_loss 0.0342 (0.0292) lr 1.5878e-03 eta 0:13:30
epoch [17/50] batch [240/244] time 0.106 (0.101) data 0.000 (0.001) loss 1.0112 (1.2516) ce_loss 0.8711 (1.1124) teacher_loss 0.8709 (1.1110) loss_zs_kd 0.1542 (0.1454) loss_oracle 0.0632 (0.0679) acc 78.1250 (70.5859) kd_loss 0.0270 (0.0291) lr 1.5878e-03 eta 0:13:31
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,808
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.3%
******* Domain p best val acc:      84.5%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [18/50] batch [20/244] time 0.093 (0.112) data 0.000 (0.013) loss 1.3443 (1.2144) ce_loss 1.2158 (1.0831) teacher_loss 1.2086 (1.0825) loss_zs_kd 0.1261 (0.1432) loss_oracle 0.0727 (0.0603) acc 71.8750 (70.9375) kd_loss 0.0271 (0.0278) lr 1.5358e-03 eta 0:15:01
epoch [18/50] batch [40/244] time 0.101 (0.103) data 0.000 (0.007) loss 1.2676 (1.2363) ce_loss 1.1270 (1.1084) teacher_loss 1.1254 (1.1076) loss_zs_kd 0.1339 (0.1385) loss_oracle 0.0752 (0.0595) acc 65.6250 (70.7812) kd_loss 0.0248 (0.0282) lr 1.5358e-03 eta 0:13:45
epoch [18/50] batch [60/244] time 0.093 (0.100) data 0.001 (0.005) loss 1.2116 (1.2386) ce_loss 1.0967 (1.1105) teacher_loss 1.0960 (1.1089) loss_zs_kd 0.1282 (0.1373) loss_oracle 0.0515 (0.0610) acc 75.0000 (71.1458) kd_loss 0.0271 (0.0286) lr 1.5358e-03 eta 0:13:22
epoch [18/50] batch [80/244] time 0.092 (0.099) data 0.000 (0.003) loss 1.1307 (1.2671) ce_loss 0.9985 (1.1372) teacher_loss 1.0008 (1.1358) loss_zs_kd 0.1413 (0.1413) loss_oracle 0.0593 (0.0607) acc 78.1250 (70.4688) kd_loss 0.0234 (0.0282) lr 1.5358e-03 eta 0:13:07
epoch [18/50] batch [100/244] time 0.095 (0.098) data 0.000 (0.003) loss 1.7299 (1.2733) ce_loss 1.5566 (1.1406) teacher_loss 1.5556 (1.1392) loss_zs_kd 0.1890 (0.1437) loss_oracle 0.0798 (0.0623) acc 62.5000 (70.0000) kd_loss 0.0396 (0.0281) lr 1.5358e-03 eta 0:12:58
epoch [18/50] batch [120/244] time 0.101 (0.098) data 0.000 (0.002) loss 1.7116 (1.2816) ce_loss 1.5762 (1.1453) teacher_loss 1.5783 (1.1439) loss_zs_kd 0.1400 (0.1461) loss_oracle 0.0634 (0.0647) acc 59.3750 (69.9219) kd_loss 0.0246 (0.0283) lr 1.5358e-03 eta 0:12:55
epoch [18/50] batch [140/244] time 0.091 (0.097) data 0.000 (0.002) loss 0.8415 (1.2700) ce_loss 0.7524 (1.1348) teacher_loss 0.7556 (1.1336) loss_zs_kd 0.0869 (0.1461) loss_oracle 0.0425 (0.0633) acc 71.8750 (70.1562) kd_loss 0.0246 (0.0283) lr 1.5358e-03 eta 0:12:46
epoch [18/50] batch [160/244] time 0.104 (0.097) data 0.000 (0.002) loss 1.3107 (1.2701) ce_loss 1.1396 (1.1332) teacher_loss 1.1433 (1.1323) loss_zs_kd 0.2202 (0.1465) loss_oracle 0.0573 (0.0645) acc 78.1250 (70.2148) kd_loss 0.0262 (0.0282) lr 1.5358e-03 eta 0:12:41
epoch [18/50] batch [180/244] time 0.099 (0.096) data 0.000 (0.002) loss 0.6248 (1.2690) ce_loss 0.5122 (1.1310) teacher_loss 0.5105 (1.1302) loss_zs_kd 0.0791 (0.1455) loss_oracle 0.0747 (0.0661) acc 84.3750 (70.2604) kd_loss 0.0310 (0.0285) lr 1.5358e-03 eta 0:12:38
epoch [18/50] batch [200/244] time 0.093 (0.096) data 0.000 (0.001) loss 1.1173 (1.2578) ce_loss 0.9673 (1.1193) teacher_loss 0.9704 (1.1183) loss_zs_kd 0.1626 (0.1451) loss_oracle 0.0655 (0.0669) acc 75.0000 (70.6719) kd_loss 0.0271 (0.0286) lr 1.5358e-03 eta 0:12:34
epoch [18/50] batch [220/244] time 0.098 (0.096) data 0.000 (0.001) loss 1.2267 (1.2518) ce_loss 1.1006 (1.1138) teacher_loss 1.0898 (1.1125) loss_zs_kd 0.1583 (0.1450) loss_oracle 0.0578 (0.0667) acc 71.8750 (70.7812) kd_loss 0.0330 (0.0288) lr 1.5358e-03 eta 0:12:31
epoch [18/50] batch [240/244] time 0.087 (0.096) data 0.000 (0.001) loss 1.2631 (1.2541) ce_loss 1.1191 (1.1162) teacher_loss 1.1168 (1.1150) loss_zs_kd 0.1599 (0.1453) loss_oracle 0.0664 (0.0664) acc 59.3750 (70.7552) kd_loss 0.0214 (0.0287) lr 1.5358e-03 eta 0:12:26
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,814
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,022
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 90.0%
******* Domain p best val acc:      84.5%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [19/50] batch [20/244] time 0.101 (0.113) data 0.000 (0.014) loss 1.0760 (1.2964) ce_loss 0.9292 (1.1557) teacher_loss 0.9277 (1.1534) loss_zs_kd 0.1247 (0.1408) loss_oracle 0.0859 (0.0725) acc 75.0000 (69.3750) kd_loss 0.0288 (0.0260) lr 1.4818e-03 eta 0:14:40
epoch [19/50] batch [40/244] time 0.096 (0.104) data 0.001 (0.007) loss 1.3908 (1.2937) ce_loss 1.2109 (1.1370) teacher_loss 1.2041 (1.1351) loss_zs_kd 0.1869 (0.1499) loss_oracle 0.0932 (0.0836) acc 78.1250 (69.9219) kd_loss 0.0337 (0.0278) lr 1.4818e-03 eta 0:13:29
epoch [19/50] batch [60/244] time 0.094 (0.101) data 0.000 (0.005) loss 0.7657 (1.3158) ce_loss 0.6406 (1.1536) teacher_loss 0.6409 (1.1520) loss_zs_kd 0.0990 (0.1550) loss_oracle 0.0753 (0.0863) acc 84.3750 (69.4271) kd_loss 0.0390 (0.0297) lr 1.4818e-03 eta 0:13:01
epoch [19/50] batch [80/244] time 0.096 (0.101) data 0.000 (0.004) loss 1.3540 (1.2935) ce_loss 1.2314 (1.1355) teacher_loss 1.2292 (1.1337) loss_zs_kd 0.1189 (0.1531) loss_oracle 0.0653 (0.0833) acc 59.3750 (69.6484) kd_loss 0.0273 (0.0310) lr 1.4818e-03 eta 0:12:56
epoch [19/50] batch [100/244] time 0.098 (0.100) data 0.000 (0.003) loss 1.6991 (1.2847) ce_loss 1.5293 (1.1326) teacher_loss 1.5300 (1.1311) loss_zs_kd 0.1996 (0.1481) loss_oracle 0.0692 (0.0795) acc 59.3750 (69.8438) kd_loss 0.0336 (0.0314) lr 1.4818e-03 eta 0:12:53
epoch [19/50] batch [120/244] time 0.099 (0.100) data 0.000 (0.003) loss 1.5590 (1.2893) ce_loss 1.3574 (1.1376) teacher_loss 1.3501 (1.1360) loss_zs_kd 0.1734 (0.1470) loss_oracle 0.1222 (0.0799) acc 65.6250 (69.5573) kd_loss 0.0500 (0.0318) lr 1.4818e-03 eta 0:12:51
epoch [19/50] batch [140/244] time 0.111 (0.100) data 0.000 (0.002) loss 1.3835 (1.2809) ce_loss 1.2246 (1.1304) teacher_loss 1.2201 (1.1288) loss_zs_kd 0.1747 (0.1455) loss_oracle 0.0760 (0.0793) acc 68.7500 (69.9107) kd_loss 0.0271 (0.0322) lr 1.4818e-03 eta 0:12:49
epoch [19/50] batch [160/244] time 0.097 (0.100) data 0.000 (0.002) loss 1.1785 (1.2772) ce_loss 1.0537 (1.1282) teacher_loss 1.0589 (1.1268) loss_zs_kd 0.1481 (0.1457) loss_oracle 0.0456 (0.0775) acc 78.1250 (70.0000) kd_loss 0.0191 (0.0320) lr 1.4818e-03 eta 0:12:47
epoch [19/50] batch [180/244] time 0.111 (0.100) data 0.000 (0.002) loss 0.9338 (1.2730) ce_loss 0.7793 (1.1243) teacher_loss 0.7708 (1.1229) loss_zs_kd 0.1537 (0.1464) loss_oracle 0.0862 (0.0769) acc 84.3750 (70.1562) kd_loss 0.0405 (0.0322) lr 1.4818e-03 eta 0:12:44
epoch [19/50] batch [200/244] time 0.092 (0.100) data 0.000 (0.002) loss 1.1070 (1.2545) ce_loss 0.9580 (1.1069) teacher_loss 0.9381 (1.1053) loss_zs_kd 0.1944 (0.1472) loss_oracle 0.0718 (0.0755) acc 68.7500 (70.5938) kd_loss 0.0438 (0.0323) lr 1.4818e-03 eta 0:12:42
epoch [19/50] batch [220/244] time 0.104 (0.100) data 0.000 (0.001) loss 1.2066 (1.2538) ce_loss 1.1113 (1.1078) teacher_loss 1.1067 (1.1062) loss_zs_kd 0.0946 (0.1466) loss_oracle 0.0527 (0.0743) acc 75.0000 (70.7102) kd_loss 0.0224 (0.0322) lr 1.4818e-03 eta 0:12:40
epoch [19/50] batch [240/244] time 0.105 (0.100) data 0.001 (0.001) loss 1.3543 (1.2423) ce_loss 1.2334 (1.0981) teacher_loss 1.2285 (1.0967) loss_zs_kd 0.1593 (0.1458) loss_oracle 0.0461 (0.0727) acc 71.8750 (70.8724) kd_loss 0.0376 (0.0321) lr 1.4818e-03 eta 0:12:38
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,814
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,038
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.4%
******* Domain p best val acc:      84.5%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [20/50] batch [20/244] time 0.104 (0.128) data 0.000 (0.021) loss 1.2867 (1.2149) ce_loss 1.1729 (1.0811) teacher_loss 1.1695 (1.0799) loss_zs_kd 0.1444 (0.1466) loss_oracle 0.0450 (0.0617) acc 62.5000 (71.7188) kd_loss 0.0282 (0.0317) lr 1.4258e-03 eta 0:16:06
epoch [20/50] batch [40/244] time 0.102 (0.116) data 0.000 (0.011) loss 1.2093 (1.2184) ce_loss 1.0801 (1.0837) teacher_loss 1.0778 (1.0833) loss_zs_kd 0.1030 (0.1439) loss_oracle 0.0800 (0.0632) acc 81.2500 (72.5000) kd_loss 0.0352 (0.0286) lr 1.4258e-03 eta 0:14:30
epoch [20/50] batch [60/244] time 0.097 (0.110) data 0.001 (0.007) loss 1.3095 (1.2193) ce_loss 1.1484 (1.0780) teacher_loss 1.1484 (1.0774) loss_zs_kd 0.1514 (0.1417) loss_oracle 0.0854 (0.0710) acc 68.7500 (72.3958) kd_loss 0.0304 (0.0273) lr 1.4258e-03 eta 0:13:45
epoch [20/50] batch [80/244] time 0.101 (0.109) data 0.000 (0.006) loss 1.2021 (1.2193) ce_loss 1.0635 (1.0751) teacher_loss 1.0555 (1.0744) loss_zs_kd 0.1420 (0.1425) loss_oracle 0.0756 (0.0737) acc 65.6250 (72.5000) kd_loss 0.0295 (0.0269) lr 1.4258e-03 eta 0:13:38
epoch [20/50] batch [100/244] time 0.097 (0.108) data 0.000 (0.004) loss 1.4786 (1.2518) ce_loss 1.3535 (1.1049) teacher_loss 1.3466 (1.1041) loss_zs_kd 0.1074 (0.1435) loss_oracle 0.0783 (0.0759) acc 71.8750 (71.5312) kd_loss 0.0239 (0.0263) lr 1.4258e-03 eta 0:13:22
epoch [20/50] batch [120/244] time 0.093 (0.107) data 0.000 (0.004) loss 1.1281 (1.2590) ce_loss 0.9888 (1.1123) teacher_loss 0.9871 (1.1116) loss_zs_kd 0.1476 (0.1449) loss_oracle 0.0672 (0.0749) acc 78.1250 (71.5885) kd_loss 0.0290 (0.0260) lr 1.4258e-03 eta 0:13:16
epoch [20/50] batch [140/244] time 0.118 (0.107) data 0.001 (0.003) loss 1.5866 (1.2627) ce_loss 1.4570 (1.1155) teacher_loss 1.4458 (1.1147) loss_zs_kd 0.1105 (0.1451) loss_oracle 0.0855 (0.0755) acc 59.3750 (71.4509) kd_loss 0.0211 (0.0261) lr 1.4258e-03 eta 0:13:17
epoch [20/50] batch [160/244] time 0.096 (0.107) data 0.000 (0.003) loss 0.8138 (1.2566) ce_loss 0.6963 (1.1114) teacher_loss 0.7003 (1.1106) loss_zs_kd 0.0690 (0.1428) loss_oracle 0.0790 (0.0746) acc 84.3750 (71.4648) kd_loss 0.0291 (0.0262) lr 1.4258e-03 eta 0:13:12
epoch [20/50] batch [180/244] time 0.112 (0.107) data 0.000 (0.003) loss 1.4047 (1.2469) ce_loss 1.2168 (1.1028) teacher_loss 1.2199 (1.1020) loss_zs_kd 0.1900 (0.1415) loss_oracle 0.0898 (0.0741) acc 65.6250 (71.4583) kd_loss 0.0291 (0.0260) lr 1.4258e-03 eta 0:13:09
epoch [20/50] batch [200/244] time 0.099 (0.107) data 0.000 (0.002) loss 0.8044 (1.2497) ce_loss 0.6582 (1.1046) teacher_loss 0.6545 (1.1036) loss_zs_kd 0.1463 (0.1428) loss_oracle 0.0768 (0.0747) acc 78.1250 (71.2656) kd_loss 0.0301 (0.0262) lr 1.4258e-03 eta 0:13:04
epoch [20/50] batch [220/244] time 0.101 (0.106) data 0.000 (0.002) loss 1.2385 (1.2440) ce_loss 1.0518 (1.0983) teacher_loss 1.0495 (1.0972) loss_zs_kd 0.2333 (0.1440) loss_oracle 0.0723 (0.0748) acc 78.1250 (71.4489) kd_loss 0.0212 (0.0261) lr 1.4258e-03 eta 0:12:59
epoch [20/50] batch [240/244] time 0.102 (0.106) data 0.000 (0.002) loss 0.9213 (1.2431) ce_loss 0.7871 (1.0970) teacher_loss 0.7885 (1.0957) loss_zs_kd 0.1229 (0.1443) loss_oracle 0.0713 (0.0752) acc 78.1250 (71.3672) kd_loss 0.0179 (0.0258) lr 1.4258e-03 eta 0:12:54
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,815
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,035
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.5%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [21/50] batch [20/244] time 0.099 (0.123) data 0.000 (0.017) loss 0.8731 (1.1888) ce_loss 0.7319 (1.0433) teacher_loss 0.7312 (1.0436) loss_zs_kd 0.1265 (0.1474) loss_oracle 0.0786 (0.0715) acc 78.1250 (71.4062) kd_loss 0.0188 (0.0213) lr 1.3681e-03 eta 0:14:58
epoch [21/50] batch [40/244] time 0.098 (0.113) data 0.000 (0.009) loss 0.8617 (1.1948) ce_loss 0.7080 (1.0502) teacher_loss 0.7115 (1.0505) loss_zs_kd 0.1791 (0.1489) loss_oracle 0.0606 (0.0699) acc 81.2500 (71.4062) kd_loss 0.0187 (0.0215) lr 1.3681e-03 eta 0:13:42
epoch [21/50] batch [60/244] time 0.103 (0.112) data 0.001 (0.006) loss 1.0109 (1.2250) ce_loss 0.8945 (1.0814) teacher_loss 0.8922 (1.0810) loss_zs_kd 0.1062 (0.1475) loss_oracle 0.0656 (0.0702) acc 71.8750 (70.6771) kd_loss 0.0250 (0.0224) lr 1.3681e-03 eta 0:13:31
epoch [21/50] batch [80/244] time 0.098 (0.110) data 0.000 (0.005) loss 1.0228 (1.2429) ce_loss 0.8394 (1.0980) teacher_loss 0.8459 (1.0975) loss_zs_kd 0.2176 (0.1498) loss_oracle 0.0681 (0.0704) acc 81.2500 (70.5469) kd_loss 0.0233 (0.0233) lr 1.3681e-03 eta 0:13:15
epoch [21/50] batch [100/244] time 0.094 (0.108) data 0.000 (0.004) loss 0.9532 (1.2551) ce_loss 0.7949 (1.1101) teacher_loss 0.8014 (1.1098) loss_zs_kd 0.1596 (0.1515) loss_oracle 0.0720 (0.0695) acc 75.0000 (70.2188) kd_loss 0.0240 (0.0234) lr 1.3681e-03 eta 0:13:00
epoch [21/50] batch [120/244] time 0.104 (0.107) data 0.000 (0.003) loss 1.0701 (1.2610) ce_loss 0.9224 (1.1181) teacher_loss 0.9236 (1.1178) loss_zs_kd 0.1307 (0.1499) loss_oracle 0.0811 (0.0683) acc 75.0000 (70.2083) kd_loss 0.0217 (0.0239) lr 1.3681e-03 eta 0:12:49
epoch [21/50] batch [140/244] time 0.105 (0.106) data 0.000 (0.003) loss 1.4425 (1.2652) ce_loss 1.2998 (1.1231) teacher_loss 1.2953 (1.1226) loss_zs_kd 0.1562 (0.1496) loss_oracle 0.0691 (0.0678) acc 65.6250 (70.2902) kd_loss 0.0331 (0.0246) lr 1.3681e-03 eta 0:12:43
epoch [21/50] batch [160/244] time 0.103 (0.105) data 0.000 (0.002) loss 1.6121 (1.2615) ce_loss 1.4775 (1.1180) teacher_loss 1.4712 (1.1172) loss_zs_kd 0.1081 (0.1497) loss_oracle 0.0869 (0.0694) acc 62.5000 (70.5664) kd_loss 0.0332 (0.0251) lr 1.3681e-03 eta 0:12:34
epoch [21/50] batch [180/244] time 0.095 (0.104) data 0.000 (0.002) loss 0.8253 (1.2488) ce_loss 0.7124 (1.1061) teacher_loss 0.7123 (1.1053) loss_zs_kd 0.1181 (0.1493) loss_oracle 0.0540 (0.0689) acc 81.2500 (70.9549) kd_loss 0.0380 (0.0254) lr 1.3681e-03 eta 0:12:24
epoch [21/50] batch [200/244] time 0.093 (0.103) data 0.000 (0.002) loss 1.1502 (1.2457) ce_loss 0.9805 (1.1037) teacher_loss 0.9838 (1.1027) loss_zs_kd 0.1919 (0.1485) loss_oracle 0.0703 (0.0687) acc 71.8750 (70.9844) kd_loss 0.0340 (0.0258) lr 1.3681e-03 eta 0:12:15
epoch [21/50] batch [220/244] time 0.107 (0.103) data 0.000 (0.002) loss 1.2313 (1.2468) ce_loss 1.0801 (1.1049) teacher_loss 1.0879 (1.1038) loss_zs_kd 0.1923 (0.1483) loss_oracle 0.0473 (0.0688) acc 75.0000 (70.8949) kd_loss 0.0297 (0.0264) lr 1.3681e-03 eta 0:12:10
epoch [21/50] batch [240/244] time 0.104 (0.103) data 0.000 (0.002) loss 1.2074 (1.2561) ce_loss 1.0400 (1.1140) teacher_loss 1.0360 (1.1129) loss_zs_kd 0.1801 (0.1488) loss_oracle 0.0813 (0.0689) acc 71.8750 (70.8594) kd_loss 0.0298 (0.0264) lr 1.3681e-03 eta 0:12:05
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,819
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.5%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,030
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
******* Domain p best val acc:      84.6%, epoch: 21 *******
******* Domain p best val test acc: 90.8%, epoch: 21 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [22/50] batch [20/244] time 0.090 (0.113) data 0.000 (0.015) loss 1.2174 (1.2354) ce_loss 1.0840 (1.0931) teacher_loss 1.0852 (1.0917) loss_zs_kd 0.1421 (0.1512) loss_oracle 0.0612 (0.0681) acc 75.0000 (70.9375) kd_loss 0.0219 (0.0281) lr 1.3090e-03 eta 0:13:16
epoch [22/50] batch [40/244] time 0.091 (0.103) data 0.000 (0.008) loss 0.8780 (1.2553) ce_loss 0.7656 (1.1117) teacher_loss 0.7571 (1.1101) loss_zs_kd 0.1239 (0.1505) loss_oracle 0.0590 (0.0699) acc 71.8750 (70.4688) kd_loss 0.0326 (0.0291) lr 1.3090e-03 eta 0:12:04
epoch [22/50] batch [60/244] time 0.099 (0.100) data 0.000 (0.005) loss 0.9921 (1.2268) ce_loss 0.8560 (1.0836) teacher_loss 0.8588 (1.0819) loss_zs_kd 0.1375 (0.1534) loss_oracle 0.0645 (0.0682) acc 81.2500 (71.0938) kd_loss 0.0274 (0.0292) lr 1.3090e-03 eta 0:11:44
epoch [22/50] batch [80/244] time 0.090 (0.099) data 0.000 (0.004) loss 1.8769 (1.2262) ce_loss 1.7568 (1.0847) teacher_loss 1.7495 (1.0829) loss_zs_kd 0.1563 (0.1535) loss_oracle 0.0492 (0.0666) acc 50.0000 (71.4062) kd_loss 0.0281 (0.0296) lr 1.3090e-03 eta 0:11:29
epoch [22/50] batch [100/244] time 0.095 (0.098) data 0.000 (0.003) loss 0.9603 (1.2062) ce_loss 0.8159 (1.0646) teacher_loss 0.8107 (1.0628) loss_zs_kd 0.1474 (0.1517) loss_oracle 0.0758 (0.0676) acc 71.8750 (72.0000) kd_loss 0.0282 (0.0297) lr 1.3090e-03 eta 0:11:23
epoch [22/50] batch [120/244] time 0.096 (0.097) data 0.000 (0.003) loss 1.0057 (1.2009) ce_loss 0.8726 (1.0573) teacher_loss 0.8633 (1.0553) loss_zs_kd 0.1379 (0.1534) loss_oracle 0.0734 (0.0688) acc 78.1250 (72.0833) kd_loss 0.0301 (0.0301) lr 1.3090e-03 eta 0:11:18
epoch [22/50] batch [140/244] time 0.092 (0.097) data 0.000 (0.002) loss 1.6584 (1.2062) ce_loss 1.5293 (1.0636) teacher_loss 1.5251 (1.0616) loss_zs_kd 0.1576 (0.1519) loss_oracle 0.0545 (0.0686) acc 53.1250 (71.6071) kd_loss 0.0253 (0.0299) lr 1.3090e-03 eta 0:11:15
epoch [22/50] batch [160/244] time 0.099 (0.097) data 0.000 (0.002) loss 1.2232 (1.2203) ce_loss 1.0850 (1.0776) teacher_loss 1.0886 (1.0758) loss_zs_kd 0.1485 (0.1538) loss_oracle 0.0603 (0.0676) acc 78.1250 (71.3867) kd_loss 0.0245 (0.0299) lr 1.3090e-03 eta 0:11:12
epoch [22/50] batch [180/244] time 0.091 (0.097) data 0.000 (0.002) loss 1.4340 (1.2226) ce_loss 1.2891 (1.0800) teacher_loss 1.2875 (1.0784) loss_zs_kd 0.1466 (0.1522) loss_oracle 0.0732 (0.0680) acc 56.2500 (71.3542) kd_loss 0.0239 (0.0296) lr 1.3090e-03 eta 0:11:09
epoch [22/50] batch [200/244] time 0.095 (0.097) data 0.000 (0.002) loss 1.1831 (1.2204) ce_loss 1.0459 (1.0750) teacher_loss 1.0459 (1.0734) loss_zs_kd 0.1279 (0.1547) loss_oracle 0.0733 (0.0697) acc 78.1250 (71.5156) kd_loss 0.0266 (0.0296) lr 1.3090e-03 eta 0:11:05
epoch [22/50] batch [220/244] time 0.099 (0.097) data 0.000 (0.002) loss 0.9285 (1.2175) ce_loss 0.7642 (1.0719) teacher_loss 0.7672 (1.0704) loss_zs_kd 0.1624 (0.1543) loss_oracle 0.0801 (0.0700) acc 81.2500 (71.7188) kd_loss 0.0317 (0.0296) lr 1.3090e-03 eta 0:11:02
epoch [22/50] batch [240/244] time 0.089 (0.096) data 0.000 (0.001) loss 1.4559 (1.2309) ce_loss 1.2520 (1.0835) teacher_loss 1.2415 (1.0819) loss_zs_kd 0.1934 (0.1551) loss_oracle 0.1177 (0.0714) acc 71.8750 (71.3672) kd_loss 0.0440 (0.0299) lr 1.3090e-03 eta 0:10:56
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,029
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.2%
******* Domain p best val acc:      84.6%, epoch: 22 *******
******* Domain p best val test acc: 90.8%, epoch: 22 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [23/50] batch [20/244] time 0.098 (0.117) data 0.000 (0.014) loss 1.2242 (1.2988) ce_loss 1.1152 (1.1485) teacher_loss 1.1069 (1.1457) loss_zs_kd 0.1118 (0.1503) loss_oracle 0.0614 (0.0779) acc 68.7500 (70.0000) kd_loss 0.0430 (0.0349) lr 1.2487e-03 eta 0:13:20
epoch [23/50] batch [40/244] time 0.102 (0.109) data 0.000 (0.007) loss 1.2439 (1.2795) ce_loss 1.0752 (1.1337) teacher_loss 1.0750 (1.1319) loss_zs_kd 0.1815 (0.1511) loss_oracle 0.0781 (0.0722) acc 65.6250 (70.1562) kd_loss 0.0315 (0.0346) lr 1.2487e-03 eta 0:12:18
epoch [23/50] batch [60/244] time 0.102 (0.105) data 0.001 (0.005) loss 1.2488 (1.2759) ce_loss 1.0957 (1.1256) teacher_loss 1.0955 (1.1242) loss_zs_kd 0.1821 (0.1550) loss_oracle 0.0622 (0.0742) acc 71.8750 (70.7812) kd_loss 0.0277 (0.0348) lr 1.2487e-03 eta 0:11:54
epoch [23/50] batch [80/244] time 0.096 (0.104) data 0.000 (0.004) loss 1.0659 (1.2486) ce_loss 0.9277 (1.0988) teacher_loss 0.9341 (1.0974) loss_zs_kd 0.1642 (0.1540) loss_oracle 0.0497 (0.0742) acc 68.7500 (71.4062) kd_loss 0.0319 (0.0350) lr 1.2487e-03 eta 0:11:43
epoch [23/50] batch [100/244] time 0.098 (0.103) data 0.000 (0.003) loss 1.4942 (1.2353) ce_loss 1.3779 (1.0870) teacher_loss 1.3710 (1.0853) loss_zs_kd 0.1390 (0.1540) loss_oracle 0.0537 (0.0730) acc 62.5000 (71.4375) kd_loss 0.0352 (0.0352) lr 1.2487e-03 eta 0:11:32
epoch [23/50] batch [120/244] time 0.095 (0.102) data 0.000 (0.003) loss 1.3939 (1.2324) ce_loss 1.2188 (1.0848) teacher_loss 1.2257 (1.0832) loss_zs_kd 0.1425 (0.1539) loss_oracle 0.0970 (0.0722) acc 68.7500 (71.4323) kd_loss 0.0309 (0.0350) lr 1.2487e-03 eta 0:11:21
epoch [23/50] batch [140/244] time 0.092 (0.101) data 0.000 (0.002) loss 1.1732 (1.2346) ce_loss 1.0596 (1.0865) teacher_loss 1.0625 (1.0852) loss_zs_kd 0.1093 (0.1538) loss_oracle 0.0559 (0.0725) acc 81.2500 (71.3170) kd_loss 0.0323 (0.0352) lr 1.2487e-03 eta 0:11:13
epoch [23/50] batch [160/244] time 0.092 (0.100) data 0.000 (0.002) loss 1.4760 (1.2337) ce_loss 1.2949 (1.0862) teacher_loss 1.2928 (1.0847) loss_zs_kd 0.1638 (0.1532) loss_oracle 0.1013 (0.0724) acc 59.3750 (71.1523) kd_loss 0.0421 (0.0351) lr 1.2487e-03 eta 0:11:06
epoch [23/50] batch [180/244] time 0.098 (0.099) data 0.000 (0.002) loss 1.0888 (1.2337) ce_loss 0.9556 (1.0862) teacher_loss 0.9551 (1.0848) loss_zs_kd 0.1128 (0.1527) loss_oracle 0.0773 (0.0726) acc 75.0000 (71.1979) kd_loss 0.0269 (0.0349) lr 1.2487e-03 eta 0:10:59
epoch [23/50] batch [200/244] time 0.098 (0.099) data 0.001 (0.002) loss 0.8694 (1.2233) ce_loss 0.7310 (1.0763) teacher_loss 0.7309 (1.0748) loss_zs_kd 0.1656 (0.1521) loss_oracle 0.0557 (0.0725) acc 78.1250 (71.2969) kd_loss 0.0339 (0.0346) lr 1.2487e-03 eta 0:10:56
epoch [23/50] batch [220/244] time 0.099 (0.099) data 0.000 (0.001) loss 1.4979 (1.2277) ce_loss 1.3428 (1.0808) teacher_loss 1.3504 (1.0794) loss_zs_kd 0.1856 (0.1529) loss_oracle 0.0548 (0.0719) acc 65.6250 (71.1080) kd_loss 0.0274 (0.0342) lr 1.2487e-03 eta 0:10:54
epoch [23/50] batch [240/244] time 0.110 (0.099) data 0.000 (0.001) loss 0.8301 (1.2302) ce_loss 0.6924 (1.0834) teacher_loss 0.6906 (1.0822) loss_zs_kd 0.1553 (0.1541) loss_oracle 0.0618 (0.0709) acc 87.5000 (71.1589) kd_loss 0.0292 (0.0340) lr 1.2487e-03 eta 0:10:54
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,817
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,032
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.4%
******* Domain p best val acc:      84.6%, epoch: 22 *******
******* Domain p best val test acc: 90.8%, epoch: 22 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [24/50] batch [20/244] time 0.092 (0.113) data 0.000 (0.012) loss 1.4229 (1.1630) ce_loss 1.3125 (1.0363) teacher_loss 1.2995 (1.0335) loss_zs_kd 0.1538 (0.1503) loss_oracle 0.0465 (0.0544) acc 65.6250 (72.3438) kd_loss 0.0361 (0.0326) lr 1.1874e-03 eta 0:12:21
epoch [24/50] batch [40/244] time 0.092 (0.103) data 0.000 (0.006) loss 1.8884 (1.2615) ce_loss 1.7314 (1.1292) teacher_loss 1.7195 (1.1263) loss_zs_kd 0.1360 (0.1471) loss_oracle 0.1009 (0.0617) acc 50.0000 (69.9219) kd_loss 0.0336 (0.0331) lr 1.1874e-03 eta 0:11:16
epoch [24/50] batch [60/244] time 0.098 (0.101) data 0.001 (0.004) loss 1.6380 (1.2844) ce_loss 1.4756 (1.1449) teacher_loss 1.4785 (1.1422) loss_zs_kd 0.1710 (0.1519) loss_oracle 0.0740 (0.0663) acc 62.5000 (69.6875) kd_loss 0.0357 (0.0328) lr 1.1874e-03 eta 0:10:56
epoch [24/50] batch [80/244] time 0.094 (0.099) data 0.000 (0.003) loss 1.2443 (1.2805) ce_loss 1.1436 (1.1372) teacher_loss 1.1430 (1.1351) loss_zs_kd 0.1200 (0.1552) loss_oracle 0.0413 (0.0678) acc 65.6250 (69.8047) kd_loss 0.0312 (0.0331) lr 1.1874e-03 eta 0:10:42
epoch [24/50] batch [100/244] time 0.095 (0.098) data 0.000 (0.003) loss 1.1256 (1.2517) ce_loss 0.9663 (1.1086) teacher_loss 0.9689 (1.1064) loss_zs_kd 0.1561 (0.1547) loss_oracle 0.0787 (0.0680) acc 75.0000 (70.5000) kd_loss 0.0324 (0.0335) lr 1.1874e-03 eta 0:10:37
epoch [24/50] batch [120/244] time 0.098 (0.098) data 0.000 (0.002) loss 1.4199 (1.2554) ce_loss 1.2754 (1.1132) teacher_loss 1.2749 (1.1110) loss_zs_kd 0.1515 (0.1525) loss_oracle 0.0693 (0.0681) acc 68.7500 (70.6510) kd_loss 0.0408 (0.0336) lr 1.1874e-03 eta 0:10:33
epoch [24/50] batch [140/244] time 0.098 (0.098) data 0.000 (0.002) loss 0.9470 (1.2567) ce_loss 0.8159 (1.1139) teacher_loss 0.8029 (1.1117) loss_zs_kd 0.1521 (0.1521) loss_oracle 0.0681 (0.0689) acc 84.3750 (70.6920) kd_loss 0.0334 (0.0336) lr 1.1874e-03 eta 0:10:35
epoch [24/50] batch [160/244] time 0.093 (0.098) data 0.000 (0.002) loss 1.2931 (1.2382) ce_loss 1.1514 (1.0958) teacher_loss 1.1515 (1.0936) loss_zs_kd 0.1737 (0.1512) loss_oracle 0.0547 (0.0691) acc 65.6250 (70.8008) kd_loss 0.0287 (0.0338) lr 1.1874e-03 eta 0:10:32
epoch [24/50] batch [180/244] time 0.097 (0.098) data 0.000 (0.002) loss 1.3381 (1.2469) ce_loss 1.1660 (1.1055) teacher_loss 1.1722 (1.1034) loss_zs_kd 0.1986 (0.1499) loss_oracle 0.0666 (0.0685) acc 62.5000 (70.5208) kd_loss 0.0284 (0.0335) lr 1.1874e-03 eta 0:10:28
epoch [24/50] batch [200/244] time 0.092 (0.098) data 0.000 (0.001) loss 1.1956 (1.2377) ce_loss 1.0664 (1.0950) teacher_loss 1.0680 (1.0933) loss_zs_kd 0.1528 (0.1516) loss_oracle 0.0512 (0.0687) acc 78.1250 (70.8281) kd_loss 0.0251 (0.0334) lr 1.1874e-03 eta 0:10:26
epoch [24/50] batch [220/244] time 0.101 (0.098) data 0.000 (0.001) loss 1.5069 (1.2269) ce_loss 1.3633 (1.0830) teacher_loss 1.3592 (1.0814) loss_zs_kd 0.1733 (0.1528) loss_oracle 0.0610 (0.0691) acc 62.5000 (71.0938) kd_loss 0.0318 (0.0335) lr 1.1874e-03 eta 0:10:23
epoch [24/50] batch [240/244] time 0.086 (0.097) data 0.000 (0.001) loss 1.4449 (1.2283) ce_loss 1.2812 (1.0842) teacher_loss 1.2826 (1.0828) loss_zs_kd 0.1619 (0.1531) loss_oracle 0.0813 (0.0690) acc 62.5000 (71.1198) kd_loss 0.0384 (0.0336) lr 1.1874e-03 eta 0:10:17
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,826
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.7%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,045
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [25/50] batch [20/244] time 0.107 (0.125) data 0.000 (0.015) loss 1.0365 (1.2176) ce_loss 0.8696 (1.0738) teacher_loss 0.8611 (1.0727) loss_zs_kd 0.1359 (0.1344) loss_oracle 0.1074 (0.0776) acc 71.8750 (70.7812) kd_loss 0.0385 (0.0395) lr 1.1253e-03 eta 0:13:07
epoch [25/50] batch [40/244] time 0.118 (0.118) data 0.001 (0.008) loss 1.0889 (1.2072) ce_loss 0.9541 (1.0673) teacher_loss 0.9410 (1.0672) loss_zs_kd 0.1507 (0.1363) loss_oracle 0.0725 (0.0718) acc 71.8750 (70.8594) kd_loss 0.0432 (0.0385) lr 1.1253e-03 eta 0:12:22
epoch [25/50] batch [60/244] time 0.107 (0.113) data 0.001 (0.005) loss 1.0663 (1.1931) ce_loss 0.9307 (1.0489) teacher_loss 0.9365 (1.0487) loss_zs_kd 0.1487 (0.1417) loss_oracle 0.0555 (0.0736) acc 78.1250 (72.1875) kd_loss 0.0386 (0.0394) lr 1.1253e-03 eta 0:11:49
epoch [25/50] batch [80/244] time 0.092 (0.112) data 0.000 (0.004) loss 1.0642 (1.2212) ce_loss 0.8799 (1.0728) teacher_loss 0.8853 (1.0728) loss_zs_kd 0.2521 (0.1497) loss_oracle 0.0528 (0.0735) acc 81.2500 (71.8750) kd_loss 0.0426 (0.0395) lr 1.1253e-03 eta 0:11:40
epoch [25/50] batch [100/244] time 0.098 (0.109) data 0.000 (0.003) loss 1.4340 (1.2288) ce_loss 1.2783 (1.0754) teacher_loss 1.2716 (1.0753) loss_zs_kd 0.1378 (0.1570) loss_oracle 0.0935 (0.0750) acc 65.6250 (71.8438) kd_loss 0.0451 (0.0400) lr 1.1253e-03 eta 0:11:22
epoch [25/50] batch [120/244] time 0.096 (0.108) data 0.000 (0.003) loss 1.6279 (1.2293) ce_loss 1.4980 (1.0721) teacher_loss 1.4988 (1.0721) loss_zs_kd 0.1259 (0.1598) loss_oracle 0.0662 (0.0774) acc 59.3750 (71.6667) kd_loss 0.0496 (0.0413) lr 1.1253e-03 eta 0:11:11
epoch [25/50] batch [140/244] time 0.094 (0.107) data 0.000 (0.002) loss 1.2967 (1.2402) ce_loss 1.1289 (1.0826) teacher_loss 1.1247 (1.0824) loss_zs_kd 0.1899 (0.1588) loss_oracle 0.0771 (0.0784) acc 68.7500 (71.4286) kd_loss 0.0514 (0.0418) lr 1.1253e-03 eta 0:11:02
epoch [25/50] batch [160/244] time 0.097 (0.106) data 0.000 (0.002) loss 1.4082 (1.2421) ce_loss 1.2617 (1.0862) teacher_loss 1.2467 (1.0856) loss_zs_kd 0.1628 (0.1575) loss_oracle 0.0801 (0.0778) acc 71.8750 (71.4844) kd_loss 0.0506 (0.0426) lr 1.1253e-03 eta 0:10:52
epoch [25/50] batch [180/244] time 0.099 (0.104) data 0.000 (0.002) loss 1.4977 (1.2399) ce_loss 1.3604 (1.0841) teacher_loss 1.3690 (1.0833) loss_zs_kd 0.1299 (0.1568) loss_oracle 0.0638 (0.0783) acc 62.5000 (71.4410) kd_loss 0.0353 (0.0432) lr 1.1253e-03 eta 0:10:43
epoch [25/50] batch [200/244] time 0.096 (0.104) data 0.000 (0.002) loss 1.1437 (1.2428) ce_loss 0.9805 (1.0877) teacher_loss 0.9769 (1.0868) loss_zs_kd 0.2002 (0.1562) loss_oracle 0.0666 (0.0778) acc 78.1250 (71.4844) kd_loss 0.0633 (0.0433) lr 1.1253e-03 eta 0:10:36
epoch [25/50] batch [220/244] time 0.098 (0.103) data 0.000 (0.002) loss 0.8559 (1.2396) ce_loss 0.6929 (1.0859) teacher_loss 0.6863 (1.0851) loss_zs_kd 0.2093 (0.1550) loss_oracle 0.0650 (0.0770) acc 75.0000 (71.4062) kd_loss 0.0531 (0.0433) lr 1.1253e-03 eta 0:10:33
epoch [25/50] batch [240/244] time 0.105 (0.103) data 0.000 (0.002) loss 1.0908 (1.2400) ce_loss 0.9307 (1.0867) teacher_loss 0.9305 (1.0857) loss_zs_kd 0.1352 (0.1558) loss_oracle 0.0928 (0.0764) acc 78.1250 (71.4974) kd_loss 0.0441 (0.0436) lr 1.1253e-03 eta 0:10:29
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,819
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,030
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [26/50] batch [20/244] time 0.134 (0.138) data 0.000 (0.013) loss 1.0970 (1.1910) ce_loss 0.9160 (1.0396) teacher_loss 0.9125 (1.0316) loss_zs_kd 0.1544 (0.1570) loss_oracle 0.1073 (0.0808) acc 75.0000 (71.7188) kd_loss 0.0542 (0.0499) lr 1.0628e-03 eta 0:13:59
epoch [26/50] batch [40/244] time 0.131 (0.134) data 0.000 (0.007) loss 1.3468 (1.1664) ce_loss 1.2041 (1.0064) teacher_loss 1.2026 (1.0015) loss_zs_kd 0.1318 (0.1633) loss_oracle 0.0784 (0.0833) acc 65.6250 (72.5000) kd_loss 0.0427 (0.0463) lr 1.0628e-03 eta 0:13:34
epoch [26/50] batch [60/244] time 0.129 (0.133) data 0.001 (0.005) loss 0.9158 (1.2060) ce_loss 0.7441 (1.0434) teacher_loss 0.7503 (1.0394) loss_zs_kd 0.1356 (0.1579) loss_oracle 0.0976 (0.0877) acc 84.3750 (71.6667) kd_loss 0.0318 (0.0463) lr 1.0628e-03 eta 0:13:23
epoch [26/50] batch [80/244] time 0.127 (0.132) data 0.000 (0.004) loss 1.1007 (1.2183) ce_loss 0.9146 (1.0524) teacher_loss 0.9206 (1.0485) loss_zs_kd 0.1591 (0.1579) loss_oracle 0.1006 (0.0908) acc 81.2500 (71.5625) kd_loss 0.0444 (0.0468) lr 1.0628e-03 eta 0:13:17
epoch [26/50] batch [100/244] time 0.102 (0.128) data 0.000 (0.003) loss 1.4395 (1.2179) ce_loss 1.3125 (1.0541) teacher_loss 1.3102 (1.0503) loss_zs_kd 0.1350 (0.1572) loss_oracle 0.0618 (0.0890) acc 62.5000 (71.4375) kd_loss 0.0453 (0.0468) lr 1.0628e-03 eta 0:12:48
epoch [26/50] batch [120/244] time 0.109 (0.124) data 0.000 (0.003) loss 1.0608 (1.2184) ce_loss 0.8994 (1.0581) teacher_loss 0.8941 (1.0544) loss_zs_kd 0.1603 (0.1552) loss_oracle 0.0866 (0.0864) acc 71.8750 (71.4062) kd_loss 0.0514 (0.0466) lr 1.0628e-03 eta 0:12:19
epoch [26/50] batch [140/244] time 0.101 (0.121) data 0.001 (0.002) loss 1.6794 (1.2311) ce_loss 1.5391 (1.0725) teacher_loss 1.5390 (1.0692) loss_zs_kd 0.1129 (0.1547) loss_oracle 0.0839 (0.0846) acc 65.6250 (71.3616) kd_loss 0.0418 (0.0462) lr 1.0628e-03 eta 0:12:00
epoch [26/50] batch [160/244] time 0.103 (0.119) data 0.000 (0.002) loss 1.5529 (1.2407) ce_loss 1.3984 (1.0825) teacher_loss 1.3902 (1.0788) loss_zs_kd 0.1767 (0.1557) loss_oracle 0.0743 (0.0840) acc 65.6250 (71.1719) kd_loss 0.0513 (0.0466) lr 1.0628e-03 eta 0:11:44
epoch [26/50] batch [180/244] time 0.102 (0.117) data 0.000 (0.002) loss 0.9745 (1.2268) ce_loss 0.7495 (1.0686) teacher_loss 0.7462 (1.0653) loss_zs_kd 0.2255 (0.1549) loss_oracle 0.1155 (0.0840) acc 78.1250 (71.4757) kd_loss 0.0503 (0.0464) lr 1.0628e-03 eta 0:11:31
epoch [26/50] batch [200/244] time 0.098 (0.115) data 0.000 (0.002) loss 0.9115 (1.2297) ce_loss 0.7710 (1.0716) teacher_loss 0.7694 (1.0682) loss_zs_kd 0.1452 (0.1546) loss_oracle 0.0696 (0.0842) acc 84.3750 (71.4844) kd_loss 0.0460 (0.0463) lr 1.0628e-03 eta 0:11:19
epoch [26/50] batch [220/244] time 0.102 (0.114) data 0.000 (0.002) loss 1.1369 (1.2377) ce_loss 1.0322 (1.0796) teacher_loss 1.0223 (1.0764) loss_zs_kd 0.1164 (0.1547) loss_oracle 0.0564 (0.0840) acc 75.0000 (71.2784) kd_loss 0.0450 (0.0461) lr 1.0628e-03 eta 0:11:09
epoch [26/50] batch [240/244] time 0.111 (0.113) data 0.000 (0.001) loss 1.0533 (1.2383) ce_loss 0.9507 (1.0807) teacher_loss 0.9402 (1.0772) loss_zs_kd 0.0827 (0.1539) loss_oracle 0.0718 (0.0841) acc 75.0000 (71.2630) kd_loss 0.0367 (0.0459) lr 1.0628e-03 eta 0:11:03
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,826
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.6%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [27/50] batch [20/244] time 0.108 (0.121) data 0.000 (0.014) loss 1.2330 (1.1466) ce_loss 1.0732 (0.9981) teacher_loss 1.0666 (0.9942) loss_zs_kd 0.1561 (0.1485) loss_oracle 0.0884 (0.0783) acc 65.6250 (72.5000) kd_loss 0.0426 (0.0420) lr 1.0000e-03 eta 0:11:48
epoch [27/50] batch [40/244] time 0.106 (0.115) data 0.000 (0.007) loss 0.8606 (1.1794) ce_loss 0.7256 (1.0287) teacher_loss 0.7213 (1.0263) loss_zs_kd 0.1076 (0.1534) loss_oracle 0.0855 (0.0764) acc 75.0000 (73.3594) kd_loss 0.0400 (0.0417) lr 1.0000e-03 eta 0:11:06
epoch [27/50] batch [60/244] time 0.109 (0.112) data 0.000 (0.005) loss 1.3643 (1.2154) ce_loss 1.2041 (1.0625) teacher_loss 1.2098 (1.0600) loss_zs_kd 0.1521 (0.1565) loss_oracle 0.0784 (0.0771) acc 71.8750 (72.3958) kd_loss 0.0359 (0.0412) lr 1.0000e-03 eta 0:10:50
epoch [27/50] batch [80/244] time 0.093 (0.109) data 0.000 (0.004) loss 1.7016 (1.2320) ce_loss 1.5244 (1.0754) teacher_loss 1.5056 (1.0725) loss_zs_kd 0.1598 (0.1592) loss_oracle 0.1161 (0.0799) acc 56.2500 (71.8359) kd_loss 0.0400 (0.0410) lr 1.0000e-03 eta 0:10:30
epoch [27/50] batch [100/244] time 0.096 (0.107) data 0.000 (0.003) loss 1.1321 (1.2242) ce_loss 0.9653 (1.0642) teacher_loss 0.9703 (1.0618) loss_zs_kd 0.1499 (0.1623) loss_oracle 0.0868 (0.0813) acc 71.8750 (72.3438) kd_loss 0.0306 (0.0407) lr 1.0000e-03 eta 0:10:15
epoch [27/50] batch [120/244] time 0.102 (0.105) data 0.000 (0.003) loss 0.7970 (1.2247) ce_loss 0.6436 (1.0647) teacher_loss 0.6480 (1.0622) loss_zs_kd 0.1709 (0.1641) loss_oracle 0.0636 (0.0805) acc 87.5000 (72.1615) kd_loss 0.0322 (0.0402) lr 1.0000e-03 eta 0:10:02
epoch [27/50] batch [140/244] time 0.101 (0.104) data 0.000 (0.002) loss 1.0087 (1.2116) ce_loss 0.8271 (1.0527) teacher_loss 0.8347 (1.0506) loss_zs_kd 0.1432 (0.1618) loss_oracle 0.1024 (0.0801) acc 75.0000 (72.3661) kd_loss 0.0367 (0.0398) lr 1.0000e-03 eta 0:09:53
epoch [27/50] batch [160/244] time 0.091 (0.103) data 0.000 (0.002) loss 1.1699 (1.2057) ce_loss 1.0156 (1.0458) teacher_loss 0.9874 (1.0432) loss_zs_kd 0.1576 (0.1626) loss_oracle 0.1038 (0.0812) acc 68.7500 (72.3828) kd_loss 0.0526 (0.0402) lr 1.0000e-03 eta 0:09:46
epoch [27/50] batch [180/244] time 0.105 (0.102) data 0.000 (0.002) loss 1.1319 (1.2038) ce_loss 0.9980 (1.0457) teacher_loss 0.9968 (1.0434) loss_zs_kd 0.1527 (0.1615) loss_oracle 0.0587 (0.0796) acc 71.8750 (72.5868) kd_loss 0.0424 (0.0400) lr 1.0000e-03 eta 0:09:41
epoch [27/50] batch [200/244] time 0.105 (0.102) data 0.000 (0.002) loss 1.5009 (1.2083) ce_loss 1.3516 (1.0520) teacher_loss 1.3458 (1.0497) loss_zs_kd 0.1433 (0.1601) loss_oracle 0.0834 (0.0786) acc 62.5000 (72.4688) kd_loss 0.0330 (0.0398) lr 1.0000e-03 eta 0:09:38
epoch [27/50] batch [220/244] time 0.136 (0.104) data 0.000 (0.001) loss 1.1732 (1.2042) ce_loss 1.0010 (1.0479) teacher_loss 1.0002 (1.0458) loss_zs_kd 0.1563 (0.1603) loss_oracle 0.0949 (0.0783) acc 68.7500 (72.6278) kd_loss 0.0455 (0.0398) lr 1.0000e-03 eta 0:09:45
epoch [27/50] batch [240/244] time 0.111 (0.105) data 0.000 (0.001) loss 1.2368 (1.2080) ce_loss 1.1104 (1.0520) teacher_loss 1.1121 (1.0498) loss_zs_kd 0.1362 (0.1587) loss_oracle 0.0566 (0.0789) acc 75.0000 (72.5260) kd_loss 0.0290 (0.0400) lr 1.0000e-03 eta 0:09:51
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,832
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,045
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.1%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [28/50] batch [20/244] time 0.099 (0.123) data 0.000 (0.015) loss 1.4499 (1.1926) ce_loss 1.2383 (1.0241) teacher_loss 1.2360 (1.0237) loss_zs_kd 0.2107 (0.1576) loss_oracle 0.1085 (0.0901) acc 71.8750 (73.5938) kd_loss 0.0395 (0.0379) lr 9.3721e-04 eta 0:11:27
epoch [28/50] batch [40/244] time 0.095 (0.108) data 0.000 (0.008) loss 1.3797 (1.2334) ce_loss 1.1855 (1.0668) teacher_loss 1.1849 (1.0658) loss_zs_kd 0.1934 (0.1599) loss_oracle 0.0981 (0.0876) acc 68.7500 (72.0312) kd_loss 0.0331 (0.0384) lr 9.3721e-04 eta 0:10:00
epoch [28/50] batch [60/244] time 0.100 (0.105) data 0.000 (0.005) loss 1.3273 (1.2174) ce_loss 1.1670 (1.0576) teacher_loss 1.1664 (1.0560) loss_zs_kd 0.1706 (0.1565) loss_oracle 0.0757 (0.0831) acc 68.7500 (72.1354) kd_loss 0.0355 (0.0381) lr 9.3721e-04 eta 0:09:40
epoch [28/50] batch [80/244] time 0.102 (0.102) data 0.000 (0.004) loss 1.6598 (1.2463) ce_loss 1.4941 (1.0905) teacher_loss 1.4853 (1.0888) loss_zs_kd 0.1895 (0.1564) loss_oracle 0.0797 (0.0793) acc 68.7500 (71.5234) kd_loss 0.0435 (0.0375) lr 9.3721e-04 eta 0:09:26
epoch [28/50] batch [100/244] time 0.095 (0.101) data 0.000 (0.003) loss 1.4204 (1.2441) ce_loss 1.2842 (1.0877) teacher_loss 1.2780 (1.0860) loss_zs_kd 0.1593 (0.1568) loss_oracle 0.0628 (0.0797) acc 59.3750 (71.6875) kd_loss 0.0382 (0.0370) lr 9.3721e-04 eta 0:09:14
epoch [28/50] batch [120/244] time 0.095 (0.100) data 0.000 (0.003) loss 1.2020 (1.2532) ce_loss 1.0234 (1.0946) teacher_loss 1.0178 (1.0933) loss_zs_kd 0.1616 (0.1592) loss_oracle 0.1034 (0.0804) acc 81.2500 (71.4323) kd_loss 0.0360 (0.0365) lr 9.3721e-04 eta 0:09:07
epoch [28/50] batch [140/244] time 0.096 (0.100) data 0.000 (0.002) loss 1.4184 (1.2414) ce_loss 1.2695 (1.0819) teacher_loss 1.2613 (1.0803) loss_zs_kd 0.1587 (0.1590) loss_oracle 0.0778 (0.0816) acc 65.6250 (71.7857) kd_loss 0.0337 (0.0364) lr 9.3721e-04 eta 0:09:05
epoch [28/50] batch [160/244] time 0.098 (0.099) data 0.000 (0.002) loss 1.4922 (1.2353) ce_loss 1.2783 (1.0765) teacher_loss 1.2706 (1.0747) loss_zs_kd 0.2521 (0.1596) loss_oracle 0.0955 (0.0807) acc 59.3750 (71.9531) kd_loss 0.0416 (0.0364) lr 9.3721e-04 eta 0:09:00
epoch [28/50] batch [180/244] time 0.098 (0.099) data 0.000 (0.002) loss 0.9711 (1.2255) ce_loss 0.8105 (1.0682) teacher_loss 0.8223 (1.0663) loss_zs_kd 0.1732 (0.1584) loss_oracle 0.0622 (0.0800) acc 81.2500 (72.1701) kd_loss 0.0318 (0.0364) lr 9.3721e-04 eta 0:08:56
epoch [28/50] batch [200/244] time 0.091 (0.098) data 0.000 (0.002) loss 1.2003 (1.2165) ce_loss 1.0010 (1.0595) teacher_loss 0.9955 (1.0578) loss_zs_kd 0.1987 (0.1583) loss_oracle 0.1055 (0.0796) acc 68.7500 (72.2500) kd_loss 0.0450 (0.0364) lr 9.3721e-04 eta 0:08:52
epoch [28/50] batch [220/244] time 0.098 (0.098) data 0.000 (0.002) loss 1.0323 (1.2101) ce_loss 0.8662 (1.0532) teacher_loss 0.8638 (1.0517) loss_zs_kd 0.1899 (0.1588) loss_oracle 0.0735 (0.0791) acc 81.2500 (72.4006) kd_loss 0.0430 (0.0365) lr 9.3721e-04 eta 0:08:48
epoch [28/50] batch [240/244] time 0.085 (0.098) data 0.000 (0.001) loss 1.1880 (1.2080) ce_loss 1.0410 (1.0508) teacher_loss 1.0412 (1.0492) loss_zs_kd 0.1194 (0.1590) loss_oracle 0.0871 (0.0792) acc 71.8750 (72.4089) kd_loss 0.0382 (0.0368) lr 9.3721e-04 eta 0:08:44
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,033
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.1%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [29/50] batch [20/244] time 0.090 (0.108) data 0.000 (0.013) loss 0.9946 (1.1871) ce_loss 0.8525 (1.0352) teacher_loss 0.8498 (1.0322) loss_zs_kd 0.1452 (0.1603) loss_oracle 0.0721 (0.0747) acc 78.1250 (74.2188) kd_loss 0.0343 (0.0421) lr 8.7467e-04 eta 0:09:38
epoch [29/50] batch [40/244] time 0.092 (0.099) data 0.000 (0.007) loss 1.4958 (1.2309) ce_loss 1.3242 (1.0728) teacher_loss 1.3305 (1.0697) loss_zs_kd 0.1384 (0.1608) loss_oracle 0.0961 (0.0809) acc 62.5000 (72.1094) kd_loss 0.0419 (0.0422) lr 8.7467e-04 eta 0:08:49
epoch [29/50] batch [60/244] time 0.088 (0.096) data 0.000 (0.005) loss 1.6333 (1.2363) ce_loss 1.4551 (1.0766) teacher_loss 1.4549 (1.0743) loss_zs_kd 0.1394 (0.1541) loss_oracle 0.1087 (0.0849) acc 62.5000 (71.7708) kd_loss 0.0385 (0.0401) lr 8.7467e-04 eta 0:08:30
epoch [29/50] batch [80/244] time 0.098 (0.096) data 0.000 (0.003) loss 0.5918 (1.2422) ce_loss 0.4529 (1.0822) teacher_loss 0.4527 (1.0792) loss_zs_kd 0.1446 (0.1541) loss_oracle 0.0668 (0.0860) acc 93.7500 (71.7969) kd_loss 0.0336 (0.0392) lr 8.7467e-04 eta 0:08:29
epoch [29/50] batch [100/244] time 0.097 (0.097) data 0.000 (0.003) loss 1.3641 (1.2540) ce_loss 1.2480 (1.0943) teacher_loss 1.2459 (1.0916) loss_zs_kd 0.0960 (0.1563) loss_oracle 0.0702 (0.0843) acc 68.7500 (71.3438) kd_loss 0.0341 (0.0382) lr 8.7467e-04 eta 0:08:30
epoch [29/50] batch [120/244] time 0.099 (0.097) data 0.000 (0.002) loss 1.3567 (1.2628) ce_loss 1.1699 (1.1035) teacher_loss 1.1795 (1.1007) loss_zs_kd 0.2093 (0.1585) loss_oracle 0.0726 (0.0829) acc 68.7500 (71.0938) kd_loss 0.0268 (0.0375) lr 8.7467e-04 eta 0:08:29
epoch [29/50] batch [140/244] time 0.113 (0.097) data 0.000 (0.002) loss 2.0258 (1.2591) ce_loss 1.8721 (1.1007) teacher_loss 1.8750 (1.0980) loss_zs_kd 0.1908 (0.1589) loss_oracle 0.0553 (0.0817) acc 53.1250 (70.9821) kd_loss 0.0271 (0.0368) lr 8.7467e-04 eta 0:08:27
epoch [29/50] batch [160/244] time 0.097 (0.097) data 0.000 (0.002) loss 1.1872 (1.2495) ce_loss 1.0117 (1.0920) teacher_loss 1.0099 (1.0892) loss_zs_kd 0.1900 (0.1586) loss_oracle 0.0823 (0.0811) acc 75.0000 (71.2500) kd_loss 0.0342 (0.0364) lr 8.7467e-04 eta 0:08:27
epoch [29/50] batch [180/244] time 0.109 (0.098) data 0.000 (0.002) loss 1.9557 (1.2589) ce_loss 1.8232 (1.1026) teacher_loss 1.8257 (1.0999) loss_zs_kd 0.1518 (0.1578) loss_oracle 0.0540 (0.0802) acc 56.2500 (71.1979) kd_loss 0.0287 (0.0359) lr 8.7467e-04 eta 0:08:26
epoch [29/50] batch [200/244] time 0.104 (0.098) data 0.000 (0.002) loss 1.3541 (1.2525) ce_loss 1.1621 (1.0957) teacher_loss 1.1543 (1.0928) loss_zs_kd 0.1874 (0.1585) loss_oracle 0.1060 (0.0805) acc 65.6250 (71.2812) kd_loss 0.0424 (0.0362) lr 8.7467e-04 eta 0:08:26
epoch [29/50] batch [220/244] time 0.105 (0.098) data 0.000 (0.001) loss 0.8492 (1.2501) ce_loss 0.7158 (1.0931) teacher_loss 0.7235 (1.0903) loss_zs_kd 0.1353 (0.1585) loss_oracle 0.0580 (0.0805) acc 84.3750 (71.3636) kd_loss 0.0258 (0.0360) lr 8.7467e-04 eta 0:08:24
epoch [29/50] batch [240/244] time 0.094 (0.097) data 0.000 (0.001) loss 0.7872 (1.2407) ce_loss 0.6323 (1.0832) teacher_loss 0.6195 (1.0801) loss_zs_kd 0.1297 (0.1583) loss_oracle 0.1028 (0.0814) acc 87.5000 (71.5885) kd_loss 0.0498 (0.0364) lr 8.7467e-04 eta 0:08:19
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,825
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.1%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [30/50] batch [20/244] time 0.130 (0.144) data 0.001 (0.020) loss 0.9715 (1.1756) ce_loss 0.8081 (1.0095) teacher_loss 0.8066 (1.0069) loss_zs_kd 0.1160 (0.1514) loss_oracle 0.1069 (0.0930) acc 75.0000 (74.0625) kd_loss 0.0534 (0.0408) lr 8.1262e-04 eta 0:12:15
epoch [30/50] batch [40/244] time 0.103 (0.128) data 0.001 (0.010) loss 0.9169 (1.1769) ce_loss 0.7642 (1.0161) teacher_loss 0.7650 (1.0134) loss_zs_kd 0.1229 (0.1477) loss_oracle 0.0904 (0.0897) acc 81.2500 (73.6719) kd_loss 0.0434 (0.0423) lr 8.1262e-04 eta 0:10:50
epoch [30/50] batch [60/244] time 0.102 (0.119) data 0.000 (0.007) loss 0.9692 (1.2007) ce_loss 0.8262 (1.0435) teacher_loss 0.8217 (1.0404) loss_zs_kd 0.1713 (0.1493) loss_oracle 0.0618 (0.0857) acc 84.3750 (72.6562) kd_loss 0.0493 (0.0429) lr 8.1262e-04 eta 0:10:04
epoch [30/50] batch [80/244] time 0.101 (0.115) data 0.001 (0.005) loss 0.9587 (1.2110) ce_loss 0.7871 (1.0556) teacher_loss 0.7830 (1.0527) loss_zs_kd 0.1751 (0.1494) loss_oracle 0.0881 (0.0836) acc 75.0000 (72.2266) kd_loss 0.0506 (0.0426) lr 8.1262e-04 eta 0:09:40
epoch [30/50] batch [100/244] time 0.104 (0.112) data 0.000 (0.004) loss 0.7430 (1.2291) ce_loss 0.5825 (1.0708) teacher_loss 0.5855 (1.0676) loss_zs_kd 0.1335 (0.1521) loss_oracle 0.0907 (0.0854) acc 87.5000 (71.7812) kd_loss 0.0460 (0.0427) lr 8.1262e-04 eta 0:09:25
epoch [30/50] batch [120/244] time 0.103 (0.110) data 0.000 (0.004) loss 1.1207 (1.2259) ce_loss 0.9736 (1.0659) teacher_loss 0.9752 (1.0628) loss_zs_kd 0.1294 (0.1532) loss_oracle 0.0808 (0.0865) acc 71.8750 (71.6667) kd_loss 0.0442 (0.0428) lr 8.1262e-04 eta 0:09:11
epoch [30/50] batch [140/244] time 0.099 (0.109) data 0.000 (0.003) loss 0.9856 (1.2091) ce_loss 0.7637 (1.0481) teacher_loss 0.7585 (1.0451) loss_zs_kd 0.2405 (0.1548) loss_oracle 0.1068 (0.0866) acc 78.1250 (72.1652) kd_loss 0.0459 (0.0430) lr 8.1262e-04 eta 0:09:01
epoch [30/50] batch [160/244] time 0.103 (0.107) data 0.000 (0.003) loss 0.8594 (1.2155) ce_loss 0.7104 (1.0547) teacher_loss 0.7094 (1.0518) loss_zs_kd 0.1795 (0.1576) loss_oracle 0.0603 (0.0850) acc 71.8750 (71.9336) kd_loss 0.0369 (0.0431) lr 8.1262e-04 eta 0:08:53
epoch [30/50] batch [180/244] time 0.101 (0.107) data 0.000 (0.003) loss 1.2059 (1.2116) ce_loss 1.0469 (1.0522) teacher_loss 1.0379 (1.0493) loss_zs_kd 0.1664 (0.1576) loss_oracle 0.0848 (0.0835) acc 71.8750 (72.0660) kd_loss 0.0535 (0.0435) lr 8.1262e-04 eta 0:08:46
epoch [30/50] batch [200/244] time 0.095 (0.106) data 0.000 (0.002) loss 1.0435 (1.2098) ce_loss 0.8696 (1.0504) teacher_loss 0.8554 (1.0476) loss_zs_kd 0.1459 (0.1584) loss_oracle 0.1151 (0.0830) acc 71.8750 (72.0781) kd_loss 0.0600 (0.0438) lr 8.1262e-04 eta 0:08:41
epoch [30/50] batch [220/244] time 0.099 (0.105) data 0.000 (0.002) loss 1.2480 (1.2152) ce_loss 1.0840 (1.0561) teacher_loss 1.0816 (1.0533) loss_zs_kd 0.1646 (0.1595) loss_oracle 0.0841 (0.0821) acc 68.7500 (71.9034) kd_loss 0.0548 (0.0439) lr 8.1262e-04 eta 0:08:37
epoch [30/50] batch [240/244] time 0.103 (0.105) data 0.000 (0.002) loss 1.0554 (1.2211) ce_loss 0.9180 (1.0631) teacher_loss 0.9076 (1.0605) loss_zs_kd 0.1452 (0.1582) loss_oracle 0.0752 (0.0815) acc 68.7500 (71.7448) kd_loss 0.0531 (0.0439) lr 8.1262e-04 eta 0:08:33
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,038
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.4%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.1%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [31/50] batch [20/244] time 0.099 (0.119) data 0.000 (0.014) loss 0.8376 (1.1668) ce_loss 0.6641 (1.0246) teacher_loss 0.6649 (1.0209) loss_zs_kd 0.1794 (0.1467) loss_oracle 0.0830 (0.0726) acc 78.1250 (71.2500) kd_loss 0.0458 (0.0453) lr 7.5131e-04 eta 0:09:37
epoch [31/50] batch [40/244] time 0.103 (0.110) data 0.000 (0.007) loss 1.1813 (1.1827) ce_loss 1.0400 (1.0318) teacher_loss 1.0411 (1.0293) loss_zs_kd 0.1623 (0.1606) loss_oracle 0.0590 (0.0731) acc 71.8750 (71.3281) kd_loss 0.0354 (0.0440) lr 7.5131e-04 eta 0:08:50
epoch [31/50] batch [60/244] time 0.097 (0.108) data 0.000 (0.005) loss 1.5972 (1.2227) ce_loss 1.4365 (1.0702) teacher_loss 1.4330 (1.0679) loss_zs_kd 0.1679 (0.1597) loss_oracle 0.0803 (0.0749) acc 62.5000 (70.6250) kd_loss 0.0340 (0.0435) lr 7.5131e-04 eta 0:08:39
epoch [31/50] batch [80/244] time 0.099 (0.106) data 0.000 (0.004) loss 1.3840 (1.1991) ce_loss 1.2432 (1.0439) teacher_loss 1.2385 (1.0416) loss_zs_kd 0.1629 (0.1592) loss_oracle 0.0641 (0.0778) acc 65.6250 (71.7578) kd_loss 0.0317 (0.0437) lr 7.5131e-04 eta 0:08:30
epoch [31/50] batch [100/244] time 0.093 (0.105) data 0.000 (0.003) loss 1.3823 (1.1791) ce_loss 1.2012 (1.0251) teacher_loss 1.2012 (1.0228) loss_zs_kd 0.2267 (0.1597) loss_oracle 0.0678 (0.0765) acc 68.7500 (72.1875) kd_loss 0.0503 (0.0443) lr 7.5131e-04 eta 0:08:22
epoch [31/50] batch [120/244] time 0.095 (0.104) data 0.000 (0.003) loss 1.4292 (1.2033) ce_loss 1.1650 (1.0473) teacher_loss 1.1560 (1.0446) loss_zs_kd 0.3114 (0.1617) loss_oracle 0.1175 (0.0778) acc 65.6250 (71.6406) kd_loss 0.0506 (0.0448) lr 7.5131e-04 eta 0:08:12
epoch [31/50] batch [140/244] time 0.099 (0.102) data 0.000 (0.002) loss 0.8831 (1.2162) ce_loss 0.7012 (1.0601) teacher_loss 0.7071 (1.0576) loss_zs_kd 0.1698 (0.1611) loss_oracle 0.0910 (0.0781) acc 84.3750 (71.6071) kd_loss 0.0448 (0.0447) lr 7.5131e-04 eta 0:08:05
epoch [31/50] batch [160/244] time 0.102 (0.102) data 0.001 (0.002) loss 1.2201 (1.2050) ce_loss 1.0771 (1.0488) teacher_loss 1.0821 (1.0461) loss_zs_kd 0.1499 (0.1599) loss_oracle 0.0631 (0.0790) acc 75.0000 (71.9922) kd_loss 0.0391 (0.0452) lr 7.5131e-04 eta 0:08:01
epoch [31/50] batch [180/244] time 0.101 (0.102) data 0.000 (0.002) loss 0.9837 (1.1997) ce_loss 0.8086 (1.0428) teacher_loss 0.8126 (1.0401) loss_zs_kd 0.1517 (0.1608) loss_oracle 0.0952 (0.0792) acc 78.1250 (72.2396) kd_loss 0.0458 (0.0453) lr 7.5131e-04 eta 0:07:58
epoch [31/50] batch [200/244] time 0.098 (0.102) data 0.000 (0.002) loss 1.5147 (1.2069) ce_loss 1.3418 (1.0505) teacher_loss 1.3380 (1.0475) loss_zs_kd 0.2041 (0.1604) loss_oracle 0.0746 (0.0792) acc 71.8750 (71.9688) kd_loss 0.0448 (0.0454) lr 7.5131e-04 eta 0:07:55
epoch [31/50] batch [220/244] time 0.096 (0.101) data 0.000 (0.002) loss 1.0372 (1.2111) ce_loss 0.9185 (1.0556) teacher_loss 0.9207 (1.0528) loss_zs_kd 0.1179 (0.1595) loss_oracle 0.0575 (0.0785) acc 68.7500 (71.8892) kd_loss 0.0414 (0.0453) lr 7.5131e-04 eta 0:07:51
epoch [31/50] batch [240/244] time 0.085 (0.100) data 0.000 (0.001) loss 0.9727 (1.2132) ce_loss 0.8247 (1.0571) teacher_loss 0.8183 (1.0545) loss_zs_kd 0.1614 (0.1604) loss_oracle 0.0737 (0.0785) acc 84.3750 (71.9792) kd_loss 0.0512 (0.0453) lr 7.5131e-04 eta 0:07:44
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,827
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,045
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.1%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [32/50] batch [20/244] time 0.096 (0.111) data 0.000 (0.014) loss 1.5852 (1.1906) ce_loss 1.4375 (1.0170) teacher_loss 1.4409 (1.0173) loss_zs_kd 0.1599 (0.1644) loss_oracle 0.0644 (0.0911) acc 62.5000 (72.8125) kd_loss 0.0465 (0.0460) lr 6.9098e-04 eta 0:08:33
epoch [32/50] batch [40/244] time 0.095 (0.103) data 0.000 (0.007) loss 1.2040 (1.2002) ce_loss 1.0557 (1.0372) teacher_loss 1.0555 (1.0371) loss_zs_kd 0.1523 (0.1604) loss_oracle 0.0723 (0.0829) acc 75.0000 (73.1250) kd_loss 0.0453 (0.0449) lr 6.9098e-04 eta 0:07:53
epoch [32/50] batch [60/244] time 0.093 (0.100) data 0.000 (0.005) loss 1.2405 (1.2183) ce_loss 1.0488 (1.0563) teacher_loss 1.0553 (1.0554) loss_zs_kd 0.2282 (0.1671) loss_oracle 0.0711 (0.0794) acc 75.0000 (72.9167) kd_loss 0.0472 (0.0463) lr 6.9098e-04 eta 0:07:36
epoch [32/50] batch [80/244] time 0.090 (0.098) data 0.000 (0.004) loss 1.0304 (1.2126) ce_loss 0.8364 (1.0496) teacher_loss 0.8357 (1.0481) loss_zs_kd 0.2176 (0.1685) loss_oracle 0.0858 (0.0803) acc 84.3750 (72.6562) kd_loss 0.0515 (0.0475) lr 6.9098e-04 eta 0:07:28
epoch [32/50] batch [100/244] time 0.090 (0.098) data 0.000 (0.003) loss 1.3266 (1.2388) ce_loss 1.1709 (1.0755) teacher_loss 1.1670 (1.0735) loss_zs_kd 0.1891 (0.1698) loss_oracle 0.0650 (0.0804) acc 68.7500 (72.0938) kd_loss 0.0518 (0.0475) lr 6.9098e-04 eta 0:07:22
epoch [32/50] batch [120/244] time 0.098 (0.098) data 0.000 (0.002) loss 0.9207 (1.2419) ce_loss 0.7485 (1.0815) teacher_loss 0.7446 (1.0793) loss_zs_kd 0.2054 (0.1673) loss_oracle 0.0734 (0.0790) acc 78.1250 (71.9792) kd_loss 0.0466 (0.0480) lr 6.9098e-04 eta 0:07:21
epoch [32/50] batch [140/244] time 0.092 (0.098) data 0.000 (0.002) loss 1.3408 (1.2276) ce_loss 1.1973 (1.0681) teacher_loss 1.1858 (1.0651) loss_zs_kd 0.1850 (0.1664) loss_oracle 0.0625 (0.0792) acc 59.3750 (72.2991) kd_loss 0.0575 (0.0488) lr 6.9098e-04 eta 0:07:19
epoch [32/50] batch [160/244] time 0.098 (0.098) data 0.000 (0.002) loss 1.1805 (1.2222) ce_loss 0.9609 (1.0626) teacher_loss 0.9689 (1.0597) loss_zs_kd 0.1977 (0.1655) loss_oracle 0.1128 (0.0798) acc 81.2500 (72.5781) kd_loss 0.0559 (0.0489) lr 6.9098e-04 eta 0:07:16
epoch [32/50] batch [180/244] time 0.104 (0.098) data 0.000 (0.002) loss 0.8864 (1.2292) ce_loss 0.6758 (1.0714) teacher_loss 0.6812 (1.0683) loss_zs_kd 0.2413 (0.1630) loss_oracle 0.0845 (0.0793) acc 90.6250 (72.4132) kd_loss 0.0538 (0.0488) lr 6.9098e-04 eta 0:07:14
epoch [32/50] batch [200/244] time 0.101 (0.098) data 0.000 (0.002) loss 1.2881 (1.2352) ce_loss 1.1523 (1.0774) teacher_loss 1.1457 (1.0743) loss_zs_kd 0.1286 (0.1627) loss_oracle 0.0780 (0.0795) acc 65.6250 (72.2656) kd_loss 0.0368 (0.0488) lr 6.9098e-04 eta 0:07:13
epoch [32/50] batch [220/244] time 0.090 (0.098) data 0.000 (0.001) loss 1.5114 (1.2352) ce_loss 1.3340 (1.0782) teacher_loss 1.3263 (1.0753) loss_zs_kd 0.1889 (0.1613) loss_oracle 0.0906 (0.0793) acc 59.3750 (71.9886) kd_loss 0.0467 (0.0486) lr 6.9098e-04 eta 0:07:10
epoch [32/50] batch [240/244] time 0.084 (0.097) data 0.000 (0.001) loss 0.9542 (1.2420) ce_loss 0.7988 (1.0847) teacher_loss 0.8032 (1.0817) loss_zs_kd 0.1305 (0.1603) loss_oracle 0.0857 (0.0801) acc 75.0000 (71.8099) kd_loss 0.0484 (0.0488) lr 6.9098e-04 eta 0:07:06
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,825
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,038
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.4%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.1%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [33/50] batch [20/244] time 0.093 (0.115) data 0.000 (0.013) loss 1.2132 (1.2312) ce_loss 1.0791 (1.0678) teacher_loss 1.0764 (1.0623) loss_zs_kd 0.1219 (0.1540) loss_oracle 0.0758 (0.0920) acc 81.2500 (72.6562) kd_loss 0.0508 (0.0539) lr 6.3188e-04 eta 0:08:24
epoch [33/50] batch [40/244] time 0.096 (0.105) data 0.000 (0.007) loss 1.0114 (1.1853) ce_loss 0.8569 (1.0235) teacher_loss 0.8529 (1.0188) loss_zs_kd 0.1338 (0.1535) loss_oracle 0.0916 (0.0898) acc 78.1250 (74.1406) kd_loss 0.0453 (0.0518) lr 6.3188e-04 eta 0:07:36
epoch [33/50] batch [60/244] time 0.102 (0.102) data 0.000 (0.005) loss 2.0698 (1.2201) ce_loss 1.9023 (1.0603) teacher_loss 1.8878 (1.0554) loss_zs_kd 0.1844 (0.1549) loss_oracle 0.0898 (0.0873) acc 50.0000 (72.3438) kd_loss 0.0542 (0.0515) lr 6.3188e-04 eta 0:07:20
epoch [33/50] batch [80/244] time 0.097 (0.100) data 0.000 (0.004) loss 1.1502 (1.2443) ce_loss 0.9922 (1.0836) teacher_loss 0.9904 (1.0793) loss_zs_kd 0.1967 (0.1591) loss_oracle 0.0615 (0.0854) acc 75.0000 (71.7578) kd_loss 0.0464 (0.0509) lr 6.3188e-04 eta 0:07:12
epoch [33/50] batch [100/244] time 0.100 (0.100) data 0.000 (0.003) loss 1.0769 (1.2267) ce_loss 0.9004 (1.0668) teacher_loss 0.9012 (1.0631) loss_zs_kd 0.1657 (0.1566) loss_oracle 0.0929 (0.0853) acc 71.8750 (72.2500) kd_loss 0.0451 (0.0501) lr 6.3188e-04 eta 0:07:10
epoch [33/50] batch [120/244] time 0.102 (0.100) data 0.000 (0.002) loss 1.4526 (1.2311) ce_loss 1.2422 (1.0701) teacher_loss 1.2483 (1.0659) loss_zs_kd 0.2106 (0.1586) loss_oracle 0.0990 (0.0859) acc 62.5000 (72.2135) kd_loss 0.0351 (0.0498) lr 6.3188e-04 eta 0:07:08
epoch [33/50] batch [140/244] time 0.100 (0.100) data 0.000 (0.002) loss 1.1706 (1.2285) ce_loss 1.0352 (1.0671) teacher_loss 1.0196 (1.0633) loss_zs_kd 0.1351 (0.1587) loss_oracle 0.0835 (0.0859) acc 68.7500 (72.5000) kd_loss 0.0521 (0.0493) lr 6.3188e-04 eta 0:07:03
epoch [33/50] batch [160/244] time 0.094 (0.099) data 0.000 (0.002) loss 0.8171 (1.2205) ce_loss 0.6382 (1.0592) teacher_loss 0.6422 (1.0556) loss_zs_kd 0.1940 (0.1600) loss_oracle 0.0779 (0.0849) acc 87.5000 (72.7148) kd_loss 0.0415 (0.0492) lr 6.3188e-04 eta 0:06:59
epoch [33/50] batch [180/244] time 0.097 (0.099) data 0.000 (0.002) loss 1.6221 (1.2267) ce_loss 1.4658 (1.0660) teacher_loss 1.4639 (1.0624) loss_zs_kd 0.1695 (0.1589) loss_oracle 0.0734 (0.0848) acc 68.7500 (72.4479) kd_loss 0.0571 (0.0491) lr 6.3188e-04 eta 0:06:57
epoch [33/50] batch [200/244] time 0.096 (0.099) data 0.000 (0.002) loss 0.8861 (1.2327) ce_loss 0.7446 (1.0725) teacher_loss 0.7454 (1.0687) loss_zs_kd 0.1435 (0.1590) loss_oracle 0.0690 (0.0845) acc 81.2500 (72.2969) kd_loss 0.0350 (0.0489) lr 6.3188e-04 eta 0:06:54
epoch [33/50] batch [220/244] time 0.094 (0.098) data 0.000 (0.001) loss 1.3664 (1.2339) ce_loss 1.1924 (1.0738) teacher_loss 1.1962 (1.0701) loss_zs_kd 0.1686 (0.1596) loss_oracle 0.0860 (0.0841) acc 65.6250 (72.1449) kd_loss 0.0508 (0.0486) lr 6.3188e-04 eta 0:06:50
epoch [33/50] batch [240/244] time 0.088 (0.098) data 0.000 (0.001) loss 0.7572 (1.2326) ce_loss 0.6201 (1.0715) teacher_loss 0.6151 (1.0678) loss_zs_kd 0.1447 (0.1604) loss_oracle 0.0697 (0.0846) acc 75.0000 (72.0703) kd_loss 0.0406 (0.0484) lr 6.3188e-04 eta 0:06:46
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,832
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,035
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.1%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [34/50] batch [20/244] time 0.092 (0.112) data 0.000 (0.014) loss 1.0507 (1.2515) ce_loss 0.8818 (1.0846) teacher_loss 0.8845 (1.0834) loss_zs_kd 0.1596 (0.1611) loss_oracle 0.0864 (0.0875) acc 78.1250 (72.8125) kd_loss 0.0386 (0.0433) lr 5.7422e-04 eta 0:07:41
epoch [34/50] batch [40/244] time 0.091 (0.102) data 0.000 (0.007) loss 1.6805 (1.2242) ce_loss 1.5225 (1.0585) teacher_loss 1.5071 (1.0555) loss_zs_kd 0.1688 (0.1668) loss_oracle 0.0890 (0.0853) acc 65.6250 (72.4219) kd_loss 0.0593 (0.0460) lr 5.7422e-04 eta 0:07:00
epoch [34/50] batch [60/244] time 0.082 (0.098) data 0.000 (0.005) loss 1.4368 (1.2093) ce_loss 1.2666 (1.0464) teacher_loss 1.2661 (1.0434) loss_zs_kd 0.1850 (0.1630) loss_oracle 0.0781 (0.0844) acc 65.6250 (72.7604) kd_loss 0.0541 (0.0471) lr 5.7422e-04 eta 0:06:39
epoch [34/50] batch [80/244] time 0.102 (0.096) data 0.000 (0.004) loss 1.5073 (1.1950) ce_loss 1.3320 (1.0332) teacher_loss 1.3374 (1.0300) loss_zs_kd 0.1725 (0.1633) loss_oracle 0.0836 (0.0833) acc 68.7500 (72.9297) kd_loss 0.0466 (0.0469) lr 5.7422e-04 eta 0:06:29
epoch [34/50] batch [100/244] time 0.091 (0.094) data 0.000 (0.003) loss 1.1507 (1.2050) ce_loss 0.9639 (1.0423) teacher_loss 0.9696 (1.0395) loss_zs_kd 0.1824 (0.1629) loss_oracle 0.0900 (0.0840) acc 78.1250 (72.7188) kd_loss 0.0440 (0.0466) lr 5.7422e-04 eta 0:06:22
epoch [34/50] batch [120/244] time 0.095 (0.094) data 0.001 (0.002) loss 0.8718 (1.2048) ce_loss 0.6953 (1.0420) teacher_loss 0.6789 (1.0390) loss_zs_kd 0.1551 (0.1609) loss_oracle 0.1154 (0.0853) acc 81.2500 (72.5260) kd_loss 0.0656 (0.0467) lr 5.7422e-04 eta 0:06:19
epoch [34/50] batch [140/244] time 0.095 (0.095) data 0.000 (0.002) loss 0.9187 (1.1961) ce_loss 0.7725 (1.0344) teacher_loss 0.7785 (1.0315) loss_zs_kd 0.1560 (0.1590) loss_oracle 0.0622 (0.0851) acc 78.1250 (72.5000) kd_loss 0.0419 (0.0470) lr 5.7422e-04 eta 0:06:18
epoch [34/50] batch [160/244] time 0.097 (0.095) data 0.000 (0.002) loss 1.3509 (1.2003) ce_loss 1.1855 (1.0370) teacher_loss 1.1816 (1.0338) loss_zs_kd 0.1552 (0.1608) loss_oracle 0.0917 (0.0861) acc 65.6250 (72.5586) kd_loss 0.0592 (0.0474) lr 5.7422e-04 eta 0:06:18
epoch [34/50] batch [180/244] time 0.112 (0.096) data 0.000 (0.002) loss 1.4591 (1.2102) ce_loss 1.3008 (1.0484) teacher_loss 1.2987 (1.0445) loss_zs_kd 0.1672 (0.1611) loss_oracle 0.0767 (0.0851) acc 71.8750 (72.2049) kd_loss 0.0495 (0.0477) lr 5.7422e-04 eta 0:06:19
epoch [34/50] batch [200/244] time 0.098 (0.096) data 0.000 (0.002) loss 1.2147 (1.2061) ce_loss 1.0430 (1.0451) teacher_loss 1.0349 (1.0411) loss_zs_kd 0.1603 (0.1602) loss_oracle 0.0996 (0.0849) acc 68.7500 (72.2969) kd_loss 0.0534 (0.0480) lr 5.7422e-04 eta 0:06:20
epoch [34/50] batch [220/244] time 0.097 (0.097) data 0.000 (0.001) loss 1.2245 (1.2038) ce_loss 1.1162 (1.0437) teacher_loss 1.1170 (1.0397) loss_zs_kd 0.1014 (0.1597) loss_oracle 0.0568 (0.0843) acc 71.8750 (72.5142) kd_loss 0.0492 (0.0479) lr 5.7422e-04 eta 0:06:19
epoch [34/50] batch [240/244] time 0.106 (0.097) data 0.000 (0.001) loss 1.0759 (1.2015) ce_loss 0.8882 (1.0416) teacher_loss 0.8843 (1.0377) loss_zs_kd 0.2123 (0.1598) loss_oracle 0.0854 (0.0839) acc 81.2500 (72.5911) kd_loss 0.0503 (0.0479) lr 5.7422e-04 eta 0:06:19
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,836
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.6%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [35/50] batch [20/244] time 0.098 (0.110) data 0.000 (0.013) loss 1.1884 (1.2341) ce_loss 1.0391 (1.0748) teacher_loss 1.0263 (1.0722) loss_zs_kd 0.1553 (0.1661) loss_oracle 0.0844 (0.0789) acc 68.7500 (70.3125) kd_loss 0.0424 (0.0488) lr 5.1825e-04 eta 0:07:08
epoch [35/50] batch [40/244] time 0.091 (0.103) data 0.000 (0.007) loss 1.2306 (1.2599) ce_loss 1.0840 (1.1002) teacher_loss 1.0809 (1.0949) loss_zs_kd 0.1258 (0.1654) loss_oracle 0.0868 (0.0823) acc 68.7500 (70.1562) kd_loss 0.0523 (0.0521) lr 5.1825e-04 eta 0:06:38
epoch [35/50] batch [60/244] time 0.096 (0.101) data 0.000 (0.005) loss 0.9822 (1.2421) ce_loss 0.8472 (1.0805) teacher_loss 0.8517 (1.0757) loss_zs_kd 0.1257 (0.1649) loss_oracle 0.0676 (0.0840) acc 78.1250 (70.4167) kd_loss 0.0490 (0.0526) lr 5.1825e-04 eta 0:06:29
epoch [35/50] batch [80/244] time 0.096 (0.101) data 0.000 (0.004) loss 1.1127 (1.2407) ce_loss 0.9380 (1.0772) teacher_loss 0.9236 (1.0725) loss_zs_kd 0.1706 (0.1668) loss_oracle 0.1038 (0.0848) acc 75.0000 (70.4297) kd_loss 0.0589 (0.0535) lr 5.1825e-04 eta 0:06:24
epoch [35/50] batch [100/244] time 0.093 (0.100) data 0.000 (0.003) loss 0.9721 (1.2301) ce_loss 0.8159 (1.0648) teacher_loss 0.8204 (1.0605) loss_zs_kd 0.1450 (0.1695) loss_oracle 0.0792 (0.0848) acc 75.0000 (71.1562) kd_loss 0.0566 (0.0542) lr 5.1825e-04 eta 0:06:21
epoch [35/50] batch [120/244] time 0.102 (0.099) data 0.001 (0.002) loss 1.1642 (1.2205) ce_loss 1.0254 (1.0561) teacher_loss 1.0205 (1.0519) loss_zs_kd 0.1048 (0.1684) loss_oracle 0.0913 (0.0844) acc 81.2500 (71.5885) kd_loss 0.0617 (0.0547) lr 5.1825e-04 eta 0:06:15
epoch [35/50] batch [140/244] time 0.096 (0.099) data 0.000 (0.002) loss 1.0642 (1.2078) ce_loss 0.9058 (1.0446) teacher_loss 0.9096 (1.0408) loss_zs_kd 0.1679 (0.1662) loss_oracle 0.0707 (0.0839) acc 81.2500 (71.9196) kd_loss 0.0618 (0.0550) lr 5.1825e-04 eta 0:06:12
epoch [35/50] batch [160/244] time 0.109 (0.099) data 0.000 (0.002) loss 1.5749 (1.2094) ce_loss 1.3848 (1.0461) teacher_loss 1.3767 (1.0423) loss_zs_kd 0.1922 (0.1672) loss_oracle 0.1022 (0.0835) acc 53.1250 (71.8945) kd_loss 0.0744 (0.0554) lr 5.1825e-04 eta 0:06:09
epoch [35/50] batch [180/244] time 0.086 (0.098) data 0.000 (0.002) loss 1.5734 (1.2212) ce_loss 1.4102 (1.0603) teacher_loss 1.3896 (1.0564) loss_zs_kd 0.1468 (0.1648) loss_oracle 0.1103 (0.0825) acc 53.1250 (71.5799) kd_loss 0.0710 (0.0560) lr 5.1825e-04 eta 0:06:06
epoch [35/50] batch [200/244] time 0.102 (0.098) data 0.000 (0.002) loss 0.7624 (1.2294) ce_loss 0.6025 (1.0691) teacher_loss 0.5871 (1.0645) loss_zs_kd 0.1674 (0.1637) loss_oracle 0.0916 (0.0830) acc 90.6250 (71.3281) kd_loss 0.0636 (0.0568) lr 5.1825e-04 eta 0:06:03
epoch [35/50] batch [220/244] time 0.094 (0.098) data 0.000 (0.001) loss 1.3365 (1.2313) ce_loss 1.1602 (1.0705) teacher_loss 1.1581 (1.0660) loss_zs_kd 0.1650 (0.1641) loss_oracle 0.0959 (0.0833) acc 68.7500 (71.3352) kd_loss 0.0564 (0.0570) lr 5.1825e-04 eta 0:06:00
epoch [35/50] batch [240/244] time 0.084 (0.097) data 0.000 (0.001) loss 1.0547 (1.2394) ce_loss 0.9453 (1.0788) teacher_loss 0.9397 (1.0743) loss_zs_kd 0.1023 (0.1633) loss_oracle 0.0639 (0.0834) acc 75.0000 (71.2109) kd_loss 0.0557 (0.0571) lr 5.1825e-04 eta 0:05:56
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,833
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [36/50] batch [20/244] time 0.129 (0.140) data 0.001 (0.013) loss 1.5828 (1.4132) ce_loss 1.4375 (1.2450) teacher_loss 1.4297 (1.2408) loss_zs_kd 0.1458 (0.1682) loss_oracle 0.0802 (0.0883) acc 59.3750 (66.4062) kd_loss 0.0612 (0.0583) lr 4.6417e-04 eta 0:08:28
epoch [36/50] batch [40/244] time 0.130 (0.135) data 0.000 (0.007) loss 1.3876 (1.3296) ce_loss 1.2363 (1.1603) teacher_loss 1.2367 (1.1571) loss_zs_kd 0.1861 (0.1684) loss_oracle 0.0579 (0.0882) acc 62.5000 (68.9062) kd_loss 0.0497 (0.0597) lr 4.6417e-04 eta 0:08:09
epoch [36/50] batch [60/244] time 0.125 (0.134) data 0.000 (0.005) loss 0.8392 (1.2933) ce_loss 0.6855 (1.1285) teacher_loss 0.6780 (1.1253) loss_zs_kd 0.1169 (0.1613) loss_oracle 0.1027 (0.0873) acc 84.3750 (70.0521) kd_loss 0.0633 (0.0595) lr 4.6417e-04 eta 0:08:01
epoch [36/50] batch [80/244] time 0.134 (0.133) data 0.001 (0.004) loss 1.1660 (1.2649) ce_loss 0.9419 (1.1029) teacher_loss 0.9490 (1.0997) loss_zs_kd 0.2349 (0.1582) loss_oracle 0.0996 (0.0860) acc 78.1250 (70.3906) kd_loss 0.0546 (0.0584) lr 4.6417e-04 eta 0:07:55
epoch [36/50] batch [100/244] time 0.129 (0.132) data 0.001 (0.003) loss 1.1670 (1.2469) ce_loss 0.9707 (1.0830) teacher_loss 0.9716 (1.0795) loss_zs_kd 0.2301 (0.1605) loss_oracle 0.0804 (0.0871) acc 71.8750 (70.9375) kd_loss 0.0613 (0.0585) lr 4.6417e-04 eta 0:07:51
epoch [36/50] batch [120/244] time 0.135 (0.132) data 0.000 (0.003) loss 1.0938 (1.2499) ce_loss 0.9888 (1.0842) teacher_loss 0.9845 (1.0807) loss_zs_kd 0.1238 (0.1628) loss_oracle 0.0474 (0.0877) acc 68.7500 (71.2240) kd_loss 0.0476 (0.0587) lr 4.6417e-04 eta 0:07:47
epoch [36/50] batch [140/244] time 0.100 (0.128) data 0.000 (0.002) loss 1.0355 (1.2420) ce_loss 0.8896 (1.0781) teacher_loss 0.8978 (1.0751) loss_zs_kd 0.1764 (0.1626) loss_oracle 0.0494 (0.0856) acc 75.0000 (71.4062) kd_loss 0.0790 (0.0585) lr 4.6417e-04 eta 0:07:31
epoch [36/50] batch [160/244] time 0.099 (0.125) data 0.000 (0.002) loss 1.1487 (1.2461) ce_loss 0.9751 (1.0838) teacher_loss 0.9729 (1.0809) loss_zs_kd 0.2144 (0.1622) loss_oracle 0.0686 (0.0841) acc 71.8750 (71.4453) kd_loss 0.0593 (0.0588) lr 4.6417e-04 eta 0:07:17
epoch [36/50] batch [180/244] time 0.103 (0.122) data 0.000 (0.002) loss 1.0327 (1.2411) ce_loss 0.8848 (1.0791) teacher_loss 0.8908 (1.0761) loss_zs_kd 0.1510 (0.1614) loss_oracle 0.0663 (0.0843) acc 71.8750 (71.4757) kd_loss 0.0557 (0.0599) lr 4.6417e-04 eta 0:07:06
epoch [36/50] batch [200/244] time 0.130 (0.123) data 0.000 (0.002) loss 1.3319 (1.2382) ce_loss 1.1660 (1.0766) teacher_loss 1.1523 (1.0736) loss_zs_kd 0.1887 (0.1616) loss_oracle 0.0852 (0.0839) acc 65.6250 (71.5625) kd_loss 0.0726 (0.0605) lr 4.6417e-04 eta 0:07:05
epoch [36/50] batch [220/244] time 0.128 (0.124) data 0.000 (0.002) loss 1.4417 (1.2337) ce_loss 1.2188 (1.0722) teacher_loss 1.2141 (1.0692) loss_zs_kd 0.2593 (0.1614) loss_oracle 0.0979 (0.0838) acc 59.3750 (71.7045) kd_loss 0.0510 (0.0607) lr 4.6417e-04 eta 0:07:05
epoch [36/50] batch [240/244] time 0.112 (0.123) data 0.000 (0.001) loss 1.2301 (1.2259) ce_loss 1.1260 (1.0648) teacher_loss 1.1221 (1.0618) loss_zs_kd 0.0986 (0.1607) loss_oracle 0.0587 (0.0837) acc 59.3750 (71.7839) kd_loss 0.0524 (0.0606) lr 4.6417e-04 eta 0:07:01
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,831
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [37/50] batch [20/244] time 0.100 (0.120) data 0.000 (0.018) loss 0.6218 (1.2331) ce_loss 0.4800 (1.0708) teacher_loss 0.4818 (1.0675) loss_zs_kd 0.0987 (0.1528) loss_oracle 0.0907 (0.0891) acc 93.7500 (72.5000) kd_loss 0.0613 (0.0580) lr 4.1221e-04 eta 0:06:48
epoch [37/50] batch [40/244] time 0.099 (0.111) data 0.000 (0.009) loss 1.2264 (1.2291) ce_loss 1.0537 (1.0662) teacher_loss 1.0565 (1.0623) loss_zs_kd 0.1317 (0.1492) loss_oracle 0.1041 (0.0921) acc 71.8750 (72.0312) kd_loss 0.0479 (0.0565) lr 4.1221e-04 eta 0:06:13
epoch [37/50] batch [60/244] time 0.103 (0.108) data 0.001 (0.006) loss 1.2859 (1.2475) ce_loss 1.0938 (1.0827) teacher_loss 1.0681 (1.0775) loss_zs_kd 0.1705 (0.1554) loss_oracle 0.1326 (0.0923) acc 75.0000 (71.7188) kd_loss 0.0509 (0.0552) lr 4.1221e-04 eta 0:06:02
epoch [37/50] batch [80/244] time 0.107 (0.107) data 0.000 (0.005) loss 1.3670 (1.2624) ce_loss 1.1572 (1.0974) teacher_loss 1.1601 (1.0922) loss_zs_kd 0.1873 (0.1543) loss_oracle 0.1133 (0.0930) acc 68.7500 (71.2109) kd_loss 0.0439 (0.0534) lr 4.1221e-04 eta 0:05:55
epoch [37/50] batch [100/244] time 0.100 (0.106) data 0.000 (0.004) loss 1.0772 (1.2717) ce_loss 0.9277 (1.1031) teacher_loss 0.9248 (1.0982) loss_zs_kd 0.1660 (0.1589) loss_oracle 0.0694 (0.0940) acc 75.0000 (70.6250) kd_loss 0.0410 (0.0527) lr 4.1221e-04 eta 0:05:51
epoch [37/50] batch [120/244] time 0.106 (0.106) data 0.000 (0.003) loss 1.0407 (1.2676) ce_loss 0.8589 (1.0977) teacher_loss 0.8637 (1.0934) loss_zs_kd 0.1850 (0.1632) loss_oracle 0.0845 (0.0926) acc 75.0000 (71.0938) kd_loss 0.0474 (0.0516) lr 4.1221e-04 eta 0:05:48
epoch [37/50] batch [140/244] time 0.099 (0.105) data 0.000 (0.003) loss 1.4766 (1.2709) ce_loss 1.2969 (1.1009) teacher_loss 1.3005 (1.0970) loss_zs_kd 0.1760 (0.1644) loss_oracle 0.0881 (0.0916) acc 65.6250 (71.1830) kd_loss 0.0454 (0.0516) lr 4.1221e-04 eta 0:05:44
epoch [37/50] batch [160/244] time 0.130 (0.105) data 0.000 (0.002) loss 1.4452 (1.2635) ce_loss 1.3027 (1.0936) teacher_loss 1.2950 (1.0897) loss_zs_kd 0.1318 (0.1648) loss_oracle 0.0843 (0.0914) acc 65.6250 (71.5039) kd_loss 0.0561 (0.0518) lr 4.1221e-04 eta 0:05:42
epoch [37/50] batch [180/244] time 0.120 (0.108) data 0.000 (0.002) loss 1.6938 (1.2562) ce_loss 1.5332 (1.0869) teacher_loss 1.5263 (1.0832) loss_zs_kd 0.1652 (0.1640) loss_oracle 0.0849 (0.0910) acc 59.3750 (71.6493) kd_loss 0.0745 (0.0522) lr 4.1221e-04 eta 0:05:49
epoch [37/50] batch [200/244] time 0.131 (0.110) data 0.000 (0.002) loss 1.0952 (1.2520) ce_loss 0.9072 (1.0829) teacher_loss 0.9082 (1.0793) loss_zs_kd 0.1995 (0.1637) loss_oracle 0.0873 (0.0909) acc 75.0000 (71.6875) kd_loss 0.0617 (0.0526) lr 4.1221e-04 eta 0:05:55
epoch [37/50] batch [220/244] time 0.127 (0.112) data 0.000 (0.002) loss 1.3403 (1.2519) ce_loss 1.2002 (1.0826) teacher_loss 1.1898 (1.0789) loss_zs_kd 0.1464 (0.1637) loss_oracle 0.0773 (0.0911) acc 62.5000 (71.7045) kd_loss 0.0524 (0.0526) lr 4.1221e-04 eta 0:05:59
epoch [37/50] batch [240/244] time 0.112 (0.113) data 0.000 (0.002) loss 1.4730 (1.2527) ce_loss 1.3311 (1.0842) teacher_loss 1.3248 (1.0805) loss_zs_kd 0.1218 (0.1638) loss_oracle 0.0872 (0.0903) acc 62.5000 (71.6406) kd_loss 0.0564 (0.0529) lr 4.1221e-04 eta 0:05:59
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,826
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,033
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [38/50] batch [20/244] time 0.094 (0.112) data 0.000 (0.013) loss 1.5293 (1.2862) ce_loss 1.3789 (1.1294) teacher_loss 1.3771 (1.1246) loss_zs_kd 0.1206 (0.1558) loss_oracle 0.0919 (0.0836) acc 71.8750 (69.2188) kd_loss 0.0710 (0.0574) lr 3.6258e-04 eta 0:05:51
epoch [38/50] batch [40/244] time 0.093 (0.103) data 0.000 (0.006) loss 1.3516 (1.2029) ce_loss 1.2031 (1.0500) teacher_loss 1.1847 (1.0460) loss_zs_kd 0.1596 (0.1505) loss_oracle 0.0871 (0.0817) acc 71.8750 (71.5625) kd_loss 0.0638 (0.0570) lr 3.6258e-04 eta 0:05:21
epoch [38/50] batch [60/244] time 0.113 (0.103) data 0.001 (0.004) loss 1.4512 (1.1848) ce_loss 1.3184 (1.0309) teacher_loss 1.3173 (1.0273) loss_zs_kd 0.1182 (0.1502) loss_oracle 0.0748 (0.0824) acc 59.3750 (72.7083) kd_loss 0.0571 (0.0582) lr 3.6258e-04 eta 0:05:20
epoch [38/50] batch [80/244] time 0.110 (0.104) data 0.000 (0.003) loss 1.6594 (1.2133) ce_loss 1.4766 (1.0562) teacher_loss 1.4723 (1.0526) loss_zs_kd 0.1793 (0.1547) loss_oracle 0.0974 (0.0833) acc 59.3750 (72.1875) kd_loss 0.0645 (0.0588) lr 3.6258e-04 eta 0:05:20
epoch [38/50] batch [100/244] time 0.102 (0.104) data 0.000 (0.003) loss 1.8993 (1.2181) ce_loss 1.7354 (1.0584) teacher_loss 1.7305 (1.0548) loss_zs_kd 0.1706 (0.1578) loss_oracle 0.0835 (0.0844) acc 40.6250 (71.8750) kd_loss 0.0690 (0.0589) lr 3.6258e-04 eta 0:05:18
epoch [38/50] batch [120/244] time 0.098 (0.104) data 0.000 (0.002) loss 0.9650 (1.2227) ce_loss 0.8179 (1.0635) teacher_loss 0.8192 (1.0599) loss_zs_kd 0.1646 (0.1562) loss_oracle 0.0635 (0.0847) acc 81.2500 (71.9271) kd_loss 0.0723 (0.0593) lr 3.6258e-04 eta 0:05:16
epoch [38/50] batch [140/244] time 0.095 (0.103) data 0.000 (0.002) loss 1.3183 (1.2255) ce_loss 1.1709 (1.0656) teacher_loss 1.1594 (1.0612) loss_zs_kd 0.1403 (0.1566) loss_oracle 0.0887 (0.0859) acc 68.7500 (72.0089) kd_loss 0.0721 (0.0594) lr 3.6258e-04 eta 0:05:13
epoch [38/50] batch [160/244] time 0.098 (0.103) data 0.000 (0.002) loss 1.1573 (1.2242) ce_loss 1.0176 (1.0631) teacher_loss 1.0195 (1.0591) loss_zs_kd 0.1496 (0.1584) loss_oracle 0.0630 (0.0858) acc 75.0000 (72.0312) kd_loss 0.0431 (0.0589) lr 3.6258e-04 eta 0:05:11
epoch [38/50] batch [180/244] time 0.091 (0.103) data 0.000 (0.002) loss 1.3857 (1.2297) ce_loss 1.2012 (1.0687) teacher_loss 1.1972 (1.0646) loss_zs_kd 0.1797 (0.1589) loss_oracle 0.0986 (0.0856) acc 62.5000 (71.8229) kd_loss 0.0542 (0.0586) lr 3.6258e-04 eta 0:05:07
epoch [38/50] batch [200/244] time 0.099 (0.103) data 0.001 (0.002) loss 1.0645 (1.2330) ce_loss 0.9336 (1.0713) teacher_loss 0.9370 (1.0672) loss_zs_kd 0.1308 (0.1607) loss_oracle 0.0621 (0.0854) acc 78.1250 (71.8750) kd_loss 0.0565 (0.0584) lr 3.6258e-04 eta 0:05:05
epoch [38/50] batch [220/244] time 0.098 (0.103) data 0.000 (0.001) loss 0.9614 (1.2383) ce_loss 0.7852 (1.0761) teacher_loss 0.7908 (1.0716) loss_zs_kd 0.1386 (0.1617) loss_oracle 0.1014 (0.0859) acc 81.2500 (71.8182) kd_loss 0.0602 (0.0585) lr 3.6258e-04 eta 0:05:03
epoch [38/50] batch [240/244] time 0.102 (0.103) data 0.000 (0.001) loss 1.3770 (1.2347) ce_loss 1.1729 (1.0722) teacher_loss 1.1815 (1.0679) loss_zs_kd 0.1945 (0.1621) loss_oracle 0.0982 (0.0857) acc 65.6250 (71.9922) kd_loss 0.0445 (0.0584) lr 3.6258e-04 eta 0:05:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,831
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [39/50] batch [20/244] time 0.113 (0.125) data 0.000 (0.014) loss 1.7112 (1.2602) ce_loss 1.5205 (1.1025) teacher_loss 1.5297 (1.0981) loss_zs_kd 0.1689 (0.1546) loss_oracle 0.0970 (0.0848) acc 59.3750 (73.1250) kd_loss 0.0613 (0.0618) lr 3.1545e-04 eta 0:06:03
epoch [39/50] batch [40/244] time 0.104 (0.116) data 0.000 (0.007) loss 1.4254 (1.2431) ce_loss 1.2803 (1.0788) teacher_loss 1.2762 (1.0754) loss_zs_kd 0.1472 (0.1629) loss_oracle 0.0756 (0.0863) acc 65.6250 (72.0312) kd_loss 0.0553 (0.0609) lr 3.1545e-04 eta 0:05:35
epoch [39/50] batch [60/244] time 0.111 (0.113) data 0.001 (0.005) loss 0.9665 (1.2242) ce_loss 0.8120 (1.0575) teacher_loss 0.7987 (1.0532) loss_zs_kd 0.1549 (0.1676) loss_oracle 0.0904 (0.0872) acc 84.3750 (72.2396) kd_loss 0.0739 (0.0617) lr 3.1545e-04 eta 0:05:23
epoch [39/50] batch [80/244] time 0.107 (0.111) data 0.000 (0.004) loss 1.2782 (1.2338) ce_loss 1.1328 (1.0706) teacher_loss 1.1319 (1.0658) loss_zs_kd 0.1282 (0.1641) loss_oracle 0.0822 (0.0860) acc 68.7500 (72.1484) kd_loss 0.0678 (0.0621) lr 3.1545e-04 eta 0:05:16
epoch [39/50] batch [100/244] time 0.107 (0.111) data 0.000 (0.003) loss 1.2806 (1.2238) ce_loss 1.0957 (1.0586) teacher_loss 1.0964 (1.0541) loss_zs_kd 0.1477 (0.1646) loss_oracle 0.1104 (0.0874) acc 65.6250 (72.0000) kd_loss 0.0663 (0.0622) lr 3.1545e-04 eta 0:05:12
epoch [39/50] batch [120/244] time 0.104 (0.110) data 0.000 (0.002) loss 1.0198 (1.2271) ce_loss 0.8535 (1.0608) teacher_loss 0.8459 (1.0560) loss_zs_kd 0.1996 (0.1666) loss_oracle 0.0741 (0.0878) acc 78.1250 (71.9010) kd_loss 0.0720 (0.0629) lr 3.1545e-04 eta 0:05:08
epoch [39/50] batch [140/244] time 0.130 (0.110) data 0.000 (0.002) loss 1.3890 (1.2273) ce_loss 1.2500 (1.0605) teacher_loss 1.2499 (1.0560) loss_zs_kd 0.1421 (0.1684) loss_oracle 0.0680 (0.0871) acc 62.5000 (71.8080) kd_loss 0.0536 (0.0627) lr 3.1545e-04 eta 0:05:05
epoch [39/50] batch [160/244] time 0.132 (0.112) data 0.000 (0.002) loss 1.3099 (1.2387) ce_loss 1.1396 (1.0721) teacher_loss 1.1281 (1.0674) loss_zs_kd 0.2187 (0.1678) loss_oracle 0.0725 (0.0874) acc 65.6250 (71.6602) kd_loss 0.0716 (0.0630) lr 3.1545e-04 eta 0:05:10
epoch [39/50] batch [180/244] time 0.135 (0.114) data 0.001 (0.002) loss 0.8544 (1.2404) ce_loss 0.7090 (1.0731) teacher_loss 0.7175 (1.0685) loss_zs_kd 0.1423 (0.1683) loss_oracle 0.0658 (0.0877) acc 75.0000 (71.5451) kd_loss 0.0646 (0.0632) lr 3.1545e-04 eta 0:05:14
epoch [39/50] batch [200/244] time 0.127 (0.116) data 0.000 (0.002) loss 1.3080 (1.2425) ce_loss 1.1553 (1.0760) teacher_loss 1.1615 (1.0714) loss_zs_kd 0.1447 (0.1680) loss_oracle 0.0742 (0.0871) acc 75.0000 (71.5469) kd_loss 0.0573 (0.0635) lr 3.1545e-04 eta 0:05:16
epoch [39/50] batch [220/244] time 0.133 (0.117) data 0.001 (0.001) loss 1.9241 (1.2480) ce_loss 1.7852 (1.0823) teacher_loss 1.7842 (1.0774) loss_zs_kd 0.1111 (0.1667) loss_oracle 0.0843 (0.0872) acc 53.1250 (71.4062) kd_loss 0.0606 (0.0638) lr 3.1545e-04 eta 0:05:17
epoch [39/50] batch [240/244] time 0.104 (0.117) data 0.000 (0.001) loss 1.1493 (1.2481) ce_loss 1.0117 (1.0820) teacher_loss 1.0094 (1.0771) loss_zs_kd 0.1400 (0.1663) loss_oracle 0.0699 (0.0878) acc 68.7500 (71.3672) kd_loss 0.0580 (0.0644) lr 3.1545e-04 eta 0:05:14
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,833
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,035
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [40/50] batch [20/244] time 0.095 (0.120) data 0.000 (0.015) loss 1.1314 (1.2738) ce_loss 0.9668 (1.1069) teacher_loss 0.9626 (1.1011) loss_zs_kd 0.1893 (0.1640) loss_oracle 0.0742 (0.0907) acc 78.1250 (70.4688) kd_loss 0.0520 (0.0707) lr 2.7103e-04 eta 0:05:19
epoch [40/50] batch [40/244] time 0.102 (0.111) data 0.000 (0.007) loss 1.2064 (1.2652) ce_loss 1.0293 (1.0968) teacher_loss 1.0370 (1.0921) loss_zs_kd 0.1871 (0.1672) loss_oracle 0.0759 (0.0895) acc 78.1250 (71.4844) kd_loss 0.0417 (0.0685) lr 2.7103e-04 eta 0:04:53
epoch [40/50] batch [60/244] time 0.099 (0.108) data 0.001 (0.005) loss 1.1486 (1.2550) ce_loss 1.0137 (1.0857) teacher_loss 1.0062 (1.0818) loss_zs_kd 0.1058 (0.1703) loss_oracle 0.0895 (0.0880) acc 68.7500 (72.0833) kd_loss 0.0554 (0.0681) lr 2.7103e-04 eta 0:04:42
epoch [40/50] batch [80/244] time 0.100 (0.106) data 0.000 (0.004) loss 1.1263 (1.2783) ce_loss 0.9707 (1.1006) teacher_loss 0.9746 (1.0960) loss_zs_kd 0.1200 (0.1772) loss_oracle 0.0918 (0.0936) acc 78.1250 (71.6016) kd_loss 0.0666 (0.0686) lr 2.7103e-04 eta 0:04:35
epoch [40/50] batch [100/244] time 0.098 (0.105) data 0.000 (0.003) loss 0.9511 (1.2565) ce_loss 0.7637 (1.0782) teacher_loss 0.7536 (1.0736) loss_zs_kd 0.1508 (0.1759) loss_oracle 0.1221 (0.0949) acc 75.0000 (72.0938) kd_loss 0.0726 (0.0688) lr 2.7103e-04 eta 0:04:30
epoch [40/50] batch [120/244] time 0.100 (0.104) data 0.000 (0.003) loss 1.0955 (1.2523) ce_loss 0.9673 (1.0763) teacher_loss 0.9489 (1.0718) loss_zs_kd 0.0981 (0.1726) loss_oracle 0.0976 (0.0942) acc 78.1250 (72.1094) kd_loss 0.0780 (0.0691) lr 2.7103e-04 eta 0:04:26
epoch [40/50] batch [140/244] time 0.099 (0.104) data 0.000 (0.002) loss 0.8048 (1.2445) ce_loss 0.6479 (1.0687) teacher_loss 0.6510 (1.0639) loss_zs_kd 0.1194 (0.1739) loss_oracle 0.0941 (0.0936) acc 84.3750 (72.3214) kd_loss 0.0740 (0.0694) lr 2.7103e-04 eta 0:04:23
epoch [40/50] batch [160/244] time 0.096 (0.103) data 0.000 (0.002) loss 1.3766 (1.2320) ce_loss 1.2080 (1.0577) teacher_loss 1.2070 (1.0532) loss_zs_kd 0.1774 (0.1722) loss_oracle 0.0808 (0.0926) acc 81.2500 (72.5977) kd_loss 0.0583 (0.0693) lr 2.7103e-04 eta 0:04:20
epoch [40/50] batch [180/244] time 0.096 (0.103) data 0.000 (0.002) loss 1.0367 (1.2392) ce_loss 0.8784 (1.0654) teacher_loss 0.8738 (1.0608) loss_zs_kd 0.1880 (0.1727) loss_oracle 0.0689 (0.0920) acc 71.8750 (72.4132) kd_loss 0.0700 (0.0692) lr 2.7103e-04 eta 0:04:17
epoch [40/50] batch [200/244] time 0.096 (0.103) data 0.000 (0.002) loss 0.7200 (1.2378) ce_loss 0.5361 (1.0654) teacher_loss 0.5324 (1.0607) loss_zs_kd 0.2243 (0.1710) loss_oracle 0.0755 (0.0917) acc 90.6250 (72.3281) kd_loss 0.0770 (0.0691) lr 2.7103e-04 eta 0:04:14
epoch [40/50] batch [220/244] time 0.107 (0.102) data 0.000 (0.002) loss 0.9023 (1.2258) ce_loss 0.7705 (1.0544) teacher_loss 0.7697 (1.0498) loss_zs_kd 0.1230 (0.1706) loss_oracle 0.0711 (0.0907) acc 75.0000 (72.6136) kd_loss 0.0606 (0.0689) lr 2.7103e-04 eta 0:04:12
epoch [40/50] batch [240/244] time 0.085 (0.102) data 0.000 (0.001) loss 1.0897 (1.2222) ce_loss 0.9067 (1.0511) teacher_loss 0.8877 (1.0466) loss_zs_kd 0.1770 (0.1704) loss_oracle 0.1136 (0.0903) acc 78.1250 (72.6823) kd_loss 0.0721 (0.0686) lr 2.7103e-04 eta 0:04:08
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,832
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,040
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [41/50] batch [20/244] time 0.116 (0.121) data 0.001 (0.014) loss 0.9577 (1.1938) ce_loss 0.8198 (1.0241) teacher_loss 0.8135 (1.0185) loss_zs_kd 0.1380 (0.1748) loss_oracle 0.0751 (0.0879) acc 78.1250 (72.5000) kd_loss 0.0738 (0.0686) lr 2.2949e-04 eta 0:04:53
epoch [41/50] batch [40/244] time 0.110 (0.113) data 0.001 (0.007) loss 1.0766 (1.1845) ce_loss 0.9136 (1.0133) teacher_loss 0.9132 (1.0077) loss_zs_kd 0.1533 (0.1741) loss_oracle 0.0868 (0.0898) acc 81.2500 (73.9062) kd_loss 0.0766 (0.0688) lr 2.2949e-04 eta 0:04:32
epoch [41/50] batch [60/244] time 0.111 (0.109) data 0.001 (0.005) loss 0.8960 (1.1949) ce_loss 0.7554 (1.0263) teacher_loss 0.7550 (1.0211) loss_zs_kd 0.1200 (0.1703) loss_oracle 0.0809 (0.0886) acc 75.0000 (72.8646) kd_loss 0.0541 (0.0698) lr 2.2949e-04 eta 0:04:20
epoch [41/50] batch [80/244] time 0.097 (0.107) data 0.000 (0.004) loss 1.1138 (1.1975) ce_loss 0.9204 (1.0275) teacher_loss 0.9119 (1.0224) loss_zs_kd 0.2210 (0.1729) loss_oracle 0.0914 (0.0886) acc 68.7500 (72.5781) kd_loss 0.0897 (0.0717) lr 2.2949e-04 eta 0:04:12
epoch [41/50] batch [100/244] time 0.095 (0.106) data 0.000 (0.003) loss 0.9254 (1.2077) ce_loss 0.7661 (1.0358) teacher_loss 0.7564 (1.0310) loss_zs_kd 0.1546 (0.1758) loss_oracle 0.0917 (0.0888) acc 78.1250 (72.2812) kd_loss 0.0669 (0.0717) lr 2.2949e-04 eta 0:04:06
epoch [41/50] batch [120/244] time 0.099 (0.105) data 0.001 (0.003) loss 0.7229 (1.2043) ce_loss 0.5303 (1.0328) teacher_loss 0.5246 (1.0277) loss_zs_kd 0.1585 (0.1754) loss_oracle 0.1190 (0.0889) acc 87.5000 (72.2917) kd_loss 0.0855 (0.0728) lr 2.2949e-04 eta 0:04:03
epoch [41/50] batch [140/244] time 0.099 (0.104) data 0.000 (0.002) loss 1.4130 (1.1936) ce_loss 1.2363 (1.0226) teacher_loss 1.2346 (1.0177) loss_zs_kd 0.1852 (0.1730) loss_oracle 0.0858 (0.0894) acc 68.7500 (72.7232) kd_loss 0.0766 (0.0729) lr 2.2949e-04 eta 0:04:00
epoch [41/50] batch [160/244] time 0.099 (0.104) data 0.000 (0.002) loss 0.6585 (1.1895) ce_loss 0.4788 (1.0196) teacher_loss 0.4812 (1.0152) loss_zs_kd 0.1710 (0.1717) loss_oracle 0.0918 (0.0884) acc 87.5000 (72.9688) kd_loss 0.0585 (0.0724) lr 2.2949e-04 eta 0:03:57
epoch [41/50] batch [180/244] time 0.102 (0.104) data 0.000 (0.002) loss 1.0651 (1.1924) ce_loss 0.9033 (1.0235) teacher_loss 0.9041 (1.0189) loss_zs_kd 0.1796 (0.1722) loss_oracle 0.0712 (0.0875) acc 71.8750 (72.8472) kd_loss 0.0574 (0.0722) lr 2.2949e-04 eta 0:03:54
epoch [41/50] batch [200/244] time 0.100 (0.104) data 0.000 (0.002) loss 1.1297 (1.1908) ce_loss 1.0039 (1.0223) teacher_loss 0.9994 (1.0176) loss_zs_kd 0.1283 (0.1713) loss_oracle 0.0661 (0.0876) acc 81.2500 (72.9531) kd_loss 0.0692 (0.0719) lr 2.2949e-04 eta 0:03:52
epoch [41/50] batch [220/244] time 0.102 (0.104) data 0.000 (0.001) loss 1.4602 (1.1901) ce_loss 1.2764 (1.0221) teacher_loss 1.2679 (1.0174) loss_zs_kd 0.1951 (0.1702) loss_oracle 0.0948 (0.0875) acc 65.6250 (73.0966) kd_loss 0.0767 (0.0712) lr 2.2949e-04 eta 0:03:50
epoch [41/50] batch [240/244] time 0.100 (0.103) data 0.000 (0.001) loss 1.2885 (1.1913) ce_loss 1.1016 (1.0234) teacher_loss 1.0927 (1.0188) loss_zs_kd 0.2000 (0.1701) loss_oracle 0.0958 (0.0875) acc 71.8750 (73.0990) kd_loss 0.0795 (0.0710) lr 2.2949e-04 eta 0:03:47
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,831
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [42/50] batch [20/244] time 0.133 (0.127) data 0.000 (0.013) loss 1.0578 (1.2008) ce_loss 0.9014 (1.0481) teacher_loss 0.9081 (1.0432) loss_zs_kd 0.1668 (0.1501) loss_oracle 0.0663 (0.0825) acc 78.1250 (71.7188) kd_loss 0.0667 (0.0717) lr 1.9098e-04 eta 0:04:36
epoch [42/50] batch [40/244] time 0.131 (0.128) data 0.001 (0.007) loss 1.2463 (1.2110) ce_loss 1.1084 (1.0518) teacher_loss 1.0994 (1.0469) loss_zs_kd 0.1534 (0.1603) loss_oracle 0.0702 (0.0839) acc 68.7500 (71.6406) kd_loss 0.0741 (0.0708) lr 1.9098e-04 eta 0:04:36
epoch [42/50] batch [60/244] time 0.121 (0.128) data 0.001 (0.005) loss 1.0037 (1.2154) ce_loss 0.8042 (1.0511) teacher_loss 0.7948 (1.0448) loss_zs_kd 0.2213 (0.1675) loss_oracle 0.0982 (0.0868) acc 84.3750 (71.8229) kd_loss 0.0833 (0.0716) lr 1.9098e-04 eta 0:04:34
epoch [42/50] batch [80/244] time 0.123 (0.127) data 0.000 (0.004) loss 1.3001 (1.2254) ce_loss 1.1367 (1.0591) teacher_loss 1.1333 (1.0523) loss_zs_kd 0.1590 (0.1681) loss_oracle 0.0873 (0.0891) acc 78.1250 (72.1484) kd_loss 0.0980 (0.0727) lr 1.9098e-04 eta 0:04:29
epoch [42/50] batch [100/244] time 0.132 (0.127) data 0.002 (0.003) loss 1.7102 (1.2175) ce_loss 1.5615 (1.0540) teacher_loss 1.5519 (1.0478) loss_zs_kd 0.1639 (0.1640) loss_oracle 0.0763 (0.0876) acc 59.3750 (72.2500) kd_loss 0.0642 (0.0709) lr 1.9098e-04 eta 0:04:25
epoch [42/50] batch [120/244] time 0.121 (0.127) data 0.000 (0.002) loss 1.2692 (1.2276) ce_loss 1.1436 (1.0629) teacher_loss 1.1437 (1.0565) loss_zs_kd 0.1510 (0.1670) loss_oracle 0.0501 (0.0876) acc 68.7500 (72.0312) kd_loss 0.0704 (0.0705) lr 1.9098e-04 eta 0:04:22
epoch [42/50] batch [140/244] time 0.116 (0.126) data 0.000 (0.002) loss 0.6277 (1.2194) ce_loss 0.4976 (1.0557) teacher_loss 0.4922 (1.0495) loss_zs_kd 0.1232 (0.1655) loss_oracle 0.0739 (0.0872) acc 87.5000 (72.3214) kd_loss 0.0636 (0.0708) lr 1.9098e-04 eta 0:04:19
epoch [42/50] batch [160/244] time 0.131 (0.126) data 0.001 (0.002) loss 1.1338 (1.2213) ce_loss 0.9604 (1.0553) teacher_loss 0.9684 (1.0492) loss_zs_kd 0.1949 (0.1678) loss_oracle 0.0679 (0.0882) acc 78.1250 (72.4609) kd_loss 0.0686 (0.0714) lr 1.9098e-04 eta 0:04:16
epoch [42/50] batch [180/244] time 0.120 (0.126) data 0.000 (0.002) loss 1.3174 (1.2154) ce_loss 1.1445 (1.0489) teacher_loss 1.1474 (1.0431) loss_zs_kd 0.1720 (0.1683) loss_oracle 0.0841 (0.0881) acc 71.8750 (72.7083) kd_loss 0.0619 (0.0709) lr 1.9098e-04 eta 0:04:13
epoch [42/50] batch [200/244] time 0.121 (0.125) data 0.000 (0.002) loss 1.0088 (1.2090) ce_loss 0.8936 (1.0430) teacher_loss 0.8883 (1.0375) loss_zs_kd 0.1156 (0.1667) loss_oracle 0.0628 (0.0881) acc 78.1250 (72.8750) kd_loss 0.0629 (0.0710) lr 1.9098e-04 eta 0:04:10
epoch [42/50] batch [220/244] time 0.105 (0.124) data 0.000 (0.002) loss 1.3286 (1.2104) ce_loss 1.1582 (1.0448) teacher_loss 1.1570 (1.0396) loss_zs_kd 0.1876 (0.1655) loss_oracle 0.0777 (0.0881) acc 78.1250 (72.8551) kd_loss 0.0733 (0.0712) lr 1.9098e-04 eta 0:04:05
epoch [42/50] batch [240/244] time 0.104 (0.123) data 0.000 (0.001) loss 0.9277 (1.2189) ce_loss 0.7300 (1.0533) teacher_loss 0.7407 (1.0478) loss_zs_kd 0.2067 (0.1663) loss_oracle 0.0837 (0.0879) acc 81.2500 (72.6823) kd_loss 0.0582 (0.0712) lr 1.9098e-04 eta 0:04:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,830
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [43/50] batch [20/244] time 0.107 (0.131) data 0.000 (0.016) loss 1.1013 (1.1406) ce_loss 0.9653 (0.9702) teacher_loss 0.9545 (0.9653) loss_zs_kd 0.1500 (0.1748) loss_oracle 0.0719 (0.0879) acc 71.8750 (74.8438) kd_loss 0.0747 (0.0726) lr 1.5567e-04 eta 0:04:13
epoch [43/50] batch [40/244] time 0.100 (0.116) data 0.001 (0.008) loss 0.8586 (1.1980) ce_loss 0.6943 (1.0236) teacher_loss 0.6847 (1.0190) loss_zs_kd 0.1655 (0.1761) loss_oracle 0.0911 (0.0909) acc 81.2500 (72.9688) kd_loss 0.0837 (0.0723) lr 1.5567e-04 eta 0:03:41
epoch [43/50] batch [60/244] time 0.097 (0.110) data 0.001 (0.006) loss 1.2283 (1.2047) ce_loss 1.0850 (1.0291) teacher_loss 1.0769 (1.0251) loss_zs_kd 0.1398 (0.1771) loss_oracle 0.0815 (0.0910) acc 65.6250 (73.2292) kd_loss 0.0851 (0.0726) lr 1.5567e-04 eta 0:03:27
epoch [43/50] batch [80/244] time 0.102 (0.106) data 0.000 (0.004) loss 0.9020 (1.2177) ce_loss 0.7300 (1.0444) teacher_loss 0.7210 (1.0397) loss_zs_kd 0.1507 (0.1747) loss_oracle 0.1056 (0.0906) acc 75.0000 (72.6562) kd_loss 0.0763 (0.0732) lr 1.5567e-04 eta 0:03:18
epoch [43/50] batch [100/244] time 0.103 (0.105) data 0.000 (0.003) loss 1.2537 (1.2133) ce_loss 1.0840 (1.0414) teacher_loss 1.0895 (1.0373) loss_zs_kd 0.1602 (0.1719) loss_oracle 0.0841 (0.0901) acc 68.7500 (72.5312) kd_loss 0.0948 (0.0737) lr 1.5567e-04 eta 0:03:14
epoch [43/50] batch [120/244] time 0.103 (0.104) data 0.000 (0.003) loss 1.3554 (1.2230) ce_loss 1.1426 (1.0538) teacher_loss 1.1308 (1.0494) loss_zs_kd 0.2860 (0.1695) loss_oracle 0.0816 (0.0889) acc 68.7500 (72.2135) kd_loss 0.0731 (0.0738) lr 1.5567e-04 eta 0:03:10
epoch [43/50] batch [140/244] time 0.091 (0.103) data 0.000 (0.002) loss 1.1833 (1.2180) ce_loss 1.0059 (1.0493) teacher_loss 1.0071 (1.0452) loss_zs_kd 0.1748 (0.1709) loss_oracle 0.0888 (0.0874) acc 75.0000 (72.3214) kd_loss 0.0700 (0.0726) lr 1.5567e-04 eta 0:03:06
epoch [43/50] batch [160/244] time 0.091 (0.102) data 0.000 (0.002) loss 0.8334 (1.2120) ce_loss 0.7378 (1.0456) teacher_loss 0.7332 (1.0416) loss_zs_kd 0.0995 (0.1674) loss_oracle 0.0505 (0.0867) acc 75.0000 (72.4805) kd_loss 0.0625 (0.0719) lr 1.5567e-04 eta 0:03:02
epoch [43/50] batch [180/244] time 0.088 (0.101) data 0.000 (0.002) loss 1.0939 (1.2126) ce_loss 0.9116 (1.0461) teacher_loss 0.9053 (1.0418) loss_zs_kd 0.1961 (0.1675) loss_oracle 0.0905 (0.0870) acc 65.6250 (72.5347) kd_loss 0.0660 (0.0715) lr 1.5567e-04 eta 0:02:58
epoch [43/50] batch [200/244] time 0.087 (0.100) data 0.000 (0.002) loss 1.4498 (1.2147) ce_loss 1.2744 (1.0485) teacher_loss 1.2550 (1.0439) loss_zs_kd 0.1484 (0.1663) loss_oracle 0.1206 (0.0876) acc 56.2500 (72.2969) kd_loss 0.0653 (0.0714) lr 1.5567e-04 eta 0:02:54
epoch [43/50] batch [220/244] time 0.091 (0.099) data 0.000 (0.002) loss 1.0632 (1.2208) ce_loss 0.8706 (1.0548) teacher_loss 0.8860 (1.0500) loss_zs_kd 0.1756 (0.1671) loss_oracle 0.0894 (0.0872) acc 78.1250 (72.0597) kd_loss 0.0635 (0.0710) lr 1.5567e-04 eta 0:02:51
epoch [43/50] batch [240/244] time 0.085 (0.098) data 0.000 (0.002) loss 1.6351 (1.2207) ce_loss 1.4785 (1.0553) teacher_loss 1.4696 (1.0507) loss_zs_kd 0.1781 (0.1660) loss_oracle 0.0764 (0.0870) acc 56.2500 (71.9401) kd_loss 0.0725 (0.0701) lr 1.5567e-04 eta 0:02:48
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,832
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,040
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [44/50] batch [20/244] time 0.081 (0.108) data 0.000 (0.014) loss 1.5571 (1.2368) ce_loss 1.3359 (1.0685) teacher_loss 1.3387 (1.0649) loss_zs_kd 0.2517 (0.1687) loss_oracle 0.0926 (0.0876) acc 59.3750 (71.5625) kd_loss 0.0645 (0.0671) lr 1.2369e-04 eta 0:03:01
epoch [44/50] batch [40/244] time 0.087 (0.097) data 0.000 (0.007) loss 1.3192 (1.1793) ce_loss 1.1484 (1.0089) teacher_loss 1.1391 (1.0046) loss_zs_kd 0.1869 (0.1679) loss_oracle 0.0867 (0.0908) acc 71.8750 (73.9062) kd_loss 0.0714 (0.0672) lr 1.2369e-04 eta 0:02:42
epoch [44/50] batch [60/244] time 0.096 (0.097) data 0.000 (0.005) loss 1.1244 (1.1610) ce_loss 0.9497 (0.9936) teacher_loss 0.9473 (0.9891) loss_zs_kd 0.1528 (0.1639) loss_oracle 0.1007 (0.0899) acc 81.2500 (74.3750) kd_loss 0.0548 (0.0666) lr 1.2369e-04 eta 0:02:39
epoch [44/50] batch [80/244] time 0.095 (0.096) data 0.000 (0.004) loss 1.4475 (1.1698) ce_loss 1.2734 (1.0045) teacher_loss 1.2750 (1.0001) loss_zs_kd 0.1492 (0.1627) loss_oracle 0.0980 (0.0883) acc 68.7500 (74.0625) kd_loss 0.0708 (0.0665) lr 1.2369e-04 eta 0:02:36
epoch [44/50] batch [100/244] time 0.091 (0.096) data 0.000 (0.003) loss 1.2057 (1.1771) ce_loss 1.0576 (1.0136) teacher_loss 1.0588 (1.0096) loss_zs_kd 0.1306 (0.1610) loss_oracle 0.0816 (0.0870) acc 84.3750 (73.4688) kd_loss 0.0559 (0.0656) lr 1.2369e-04 eta 0:02:34
epoch [44/50] batch [120/244] time 0.097 (0.095) data 0.000 (0.002) loss 1.3060 (1.1963) ce_loss 1.1484 (1.0321) teacher_loss 1.1425 (1.0279) loss_zs_kd 0.1376 (0.1622) loss_oracle 0.0947 (0.0873) acc 65.6250 (72.9167) kd_loss 0.0614 (0.0653) lr 1.2369e-04 eta 0:02:31
epoch [44/50] batch [140/244] time 0.081 (0.094) data 0.000 (0.002) loss 1.1178 (1.2053) ce_loss 0.9727 (1.0406) teacher_loss 0.9807 (1.0360) loss_zs_kd 0.1414 (0.1638) loss_oracle 0.0665 (0.0874) acc 75.0000 (72.6562) kd_loss 0.0473 (0.0653) lr 1.2369e-04 eta 0:02:27
epoch [44/50] batch [160/244] time 0.088 (0.094) data 0.000 (0.002) loss 1.1642 (1.2098) ce_loss 0.9282 (1.0448) teacher_loss 0.9251 (1.0402) loss_zs_kd 0.2460 (0.1643) loss_oracle 0.1162 (0.0875) acc 78.1250 (72.4609) kd_loss 0.0742 (0.0653) lr 1.2369e-04 eta 0:02:24
epoch [44/50] batch [180/244] time 0.085 (0.093) data 0.000 (0.002) loss 1.6118 (1.2185) ce_loss 1.4443 (1.0501) teacher_loss 1.4372 (1.0456) loss_zs_kd 0.1767 (0.1681) loss_oracle 0.0862 (0.0889) acc 53.1250 (72.3438) kd_loss 0.0831 (0.0660) lr 1.2369e-04 eta 0:02:22
epoch [44/50] batch [200/244] time 0.095 (0.093) data 0.000 (0.002) loss 1.4182 (1.2212) ce_loss 1.2539 (1.0527) teacher_loss 1.2663 (1.0486) loss_zs_kd 0.1560 (0.1681) loss_oracle 0.0739 (0.0885) acc 71.8750 (72.3281) kd_loss 0.0692 (0.0660) lr 1.2369e-04 eta 0:02:19
epoch [44/50] batch [220/244] time 0.082 (0.092) data 0.000 (0.001) loss 1.7273 (1.2256) ce_loss 1.5391 (1.0567) teacher_loss 1.5182 (1.0523) loss_zs_kd 0.1847 (0.1684) loss_oracle 0.1168 (0.0891) acc 68.7500 (72.2443) kd_loss 0.0824 (0.0663) lr 1.2369e-04 eta 0:02:17
epoch [44/50] batch [240/244] time 0.087 (0.092) data 0.000 (0.001) loss 1.3464 (1.2242) ce_loss 1.1426 (1.0547) teacher_loss 1.1490 (1.0506) loss_zs_kd 0.2045 (0.1692) loss_oracle 0.0951 (0.0890) acc 65.6250 (72.1615) kd_loss 0.0548 (0.0665) lr 1.2369e-04 eta 0:02:15
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,840
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.2%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [45/50] batch [20/244] time 0.092 (0.111) data 0.000 (0.013) loss 1.0464 (1.2215) ce_loss 0.8877 (1.0504) teacher_loss 0.8757 (1.0470) loss_zs_kd 0.1514 (0.1710) loss_oracle 0.0950 (0.0890) acc 78.1250 (71.8750) kd_loss 0.0846 (0.0731) lr 9.5173e-05 eta 0:02:40
epoch [45/50] batch [40/244] time 0.089 (0.102) data 0.000 (0.007) loss 1.2972 (1.1826) ce_loss 1.1768 (1.0147) teacher_loss 1.1717 (1.0120) loss_zs_kd 0.1150 (0.1698) loss_oracle 0.0680 (0.0857) acc 62.5000 (72.6562) kd_loss 0.0710 (0.0718) lr 9.5173e-05 eta 0:02:25
epoch [45/50] batch [60/244] time 0.094 (0.099) data 0.001 (0.005) loss 1.5036 (1.2017) ce_loss 1.3496 (1.0316) teacher_loss 1.3454 (1.0281) loss_zs_kd 0.1560 (0.1707) loss_oracle 0.0802 (0.0882) acc 65.6250 (72.2396) kd_loss 0.0727 (0.0708) lr 9.5173e-05 eta 0:02:18
epoch [45/50] batch [80/244] time 0.092 (0.097) data 0.000 (0.003) loss 0.9005 (1.2191) ce_loss 0.7324 (1.0515) teacher_loss 0.7339 (1.0473) loss_zs_kd 0.1500 (0.1683) loss_oracle 0.0915 (0.0877) acc 84.3750 (71.9531) kd_loss 0.0675 (0.0708) lr 9.5173e-05 eta 0:02:14
epoch [45/50] batch [100/244] time 0.096 (0.097) data 0.000 (0.003) loss 1.4450 (1.2299) ce_loss 1.2256 (1.0616) teacher_loss 1.2071 (1.0572) loss_zs_kd 0.2048 (0.1687) loss_oracle 0.1354 (0.0883) acc 68.7500 (71.8438) kd_loss 0.0920 (0.0710) lr 9.5173e-05 eta 0:02:11
epoch [45/50] batch [120/244] time 0.095 (0.096) data 0.000 (0.002) loss 0.7943 (1.2200) ce_loss 0.6353 (1.0518) teacher_loss 0.6401 (1.0471) loss_zs_kd 0.1876 (0.1694) loss_oracle 0.0603 (0.0882) acc 81.2500 (72.2917) kd_loss 0.0675 (0.0712) lr 9.5173e-05 eta 0:02:09
epoch [45/50] batch [140/244] time 0.091 (0.096) data 0.000 (0.002) loss 0.7679 (1.2300) ce_loss 0.5859 (1.0610) teacher_loss 0.5765 (1.0564) loss_zs_kd 0.1621 (0.1702) loss_oracle 0.1103 (0.0885) acc 78.1250 (71.7188) kd_loss 0.0689 (0.0707) lr 9.5173e-05 eta 0:02:06
epoch [45/50] batch [160/244] time 0.100 (0.095) data 0.000 (0.002) loss 0.9603 (1.2256) ce_loss 0.7778 (1.0566) teacher_loss 0.7810 (1.0520) loss_zs_kd 0.1385 (0.1708) loss_oracle 0.1101 (0.0882) acc 81.2500 (71.7578) kd_loss 0.0604 (0.0712) lr 9.5173e-05 eta 0:02:04
epoch [45/50] batch [180/244] time 0.097 (0.095) data 0.000 (0.002) loss 1.4119 (1.2320) ce_loss 1.2529 (1.0640) teacher_loss 1.2340 (1.0593) loss_zs_kd 0.1532 (0.1698) loss_oracle 0.1013 (0.0878) acc 65.6250 (71.7014) kd_loss 0.0778 (0.0711) lr 9.5173e-05 eta 0:02:02
epoch [45/50] batch [200/244] time 0.099 (0.096) data 0.000 (0.002) loss 0.9473 (1.2261) ce_loss 0.7822 (1.0578) teacher_loss 0.7803 (1.0530) loss_zs_kd 0.1580 (0.1692) loss_oracle 0.0880 (0.0884) acc 75.0000 (71.8906) kd_loss 0.0665 (0.0709) lr 9.5173e-05 eta 0:02:01
epoch [45/50] batch [220/244] time 0.097 (0.096) data 0.000 (0.001) loss 1.0826 (1.2223) ce_loss 0.8682 (1.0543) teacher_loss 0.8526 (1.0494) loss_zs_kd 0.2264 (0.1688) loss_oracle 0.1168 (0.0885) acc 68.7500 (71.8892) kd_loss 0.0852 (0.0710) lr 9.5173e-05 eta 0:01:59
epoch [45/50] batch [240/244] time 0.102 (0.096) data 0.000 (0.001) loss 1.3179 (1.2199) ce_loss 1.1182 (1.0516) teacher_loss 1.1177 (1.0470) loss_zs_kd 0.2075 (0.1693) loss_oracle 0.0964 (0.0882) acc 75.0000 (71.9531) kd_loss 0.0717 (0.0712) lr 9.5173e-05 eta 0:01:58
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,836
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,042
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [46/50] batch [20/244] time 0.104 (0.120) data 0.000 (0.014) loss 1.5679 (1.2096) ce_loss 1.3486 (1.0520) teacher_loss 1.3395 (1.0469) loss_zs_kd 0.2208 (0.1665) loss_oracle 0.1181 (0.0795) acc 65.6250 (71.8750) kd_loss 0.0741 (0.0713) lr 7.0224e-05 eta 0:02:24
epoch [46/50] batch [40/244] time 0.099 (0.111) data 0.000 (0.007) loss 1.1103 (1.2442) ce_loss 0.9399 (1.0789) teacher_loss 0.9233 (1.0751) loss_zs_kd 0.1696 (0.1727) loss_oracle 0.1023 (0.0827) acc 75.0000 (71.1719) kd_loss 0.0798 (0.0725) lr 7.0224e-05 eta 0:02:10
epoch [46/50] batch [60/244] time 0.099 (0.107) data 0.000 (0.005) loss 0.8927 (1.2394) ce_loss 0.7124 (1.0702) teacher_loss 0.6921 (1.0653) loss_zs_kd 0.1876 (0.1780) loss_oracle 0.1068 (0.0852) acc 81.2500 (71.6146) kd_loss 0.0938 (0.0727) lr 7.0224e-05 eta 0:02:04
epoch [46/50] batch [80/244] time 0.108 (0.106) data 0.000 (0.004) loss 1.3177 (1.2379) ce_loss 1.1846 (1.0699) teacher_loss 1.1874 (1.0655) loss_zs_kd 0.1571 (0.1743) loss_oracle 0.0517 (0.0853) acc 68.7500 (71.6016) kd_loss 0.0539 (0.0726) lr 7.0224e-05 eta 0:02:00
epoch [46/50] batch [100/244] time 0.099 (0.105) data 0.000 (0.003) loss 1.2598 (1.2205) ce_loss 1.1123 (1.0542) teacher_loss 1.1074 (1.0496) loss_zs_kd 0.1658 (0.1716) loss_oracle 0.0696 (0.0851) acc 71.8750 (72.0000) kd_loss 0.0723 (0.0722) lr 7.0224e-05 eta 0:01:58
epoch [46/50] batch [120/244] time 0.106 (0.105) data 0.000 (0.003) loss 1.0775 (1.2261) ce_loss 0.9473 (1.0603) teacher_loss 0.9345 (1.0555) loss_zs_kd 0.1111 (0.1707) loss_oracle 0.0874 (0.0852) acc 81.2500 (71.6667) kd_loss 0.0739 (0.0720) lr 7.0224e-05 eta 0:01:55
epoch [46/50] batch [140/244] time 0.096 (0.104) data 0.000 (0.002) loss 0.8281 (1.2193) ce_loss 0.6797 (1.0531) teacher_loss 0.6673 (1.0485) loss_zs_kd 0.1111 (0.1696) loss_oracle 0.1052 (0.0859) acc 81.2500 (71.7857) kd_loss 0.0875 (0.0718) lr 7.0224e-05 eta 0:01:52
epoch [46/50] batch [160/244] time 0.116 (0.105) data 0.000 (0.002) loss 1.3441 (1.2096) ce_loss 1.1650 (1.0433) teacher_loss 1.1656 (1.0387) loss_zs_kd 0.1453 (0.1689) loss_oracle 0.1059 (0.0865) acc 75.0000 (72.0898) kd_loss 0.0895 (0.0720) lr 7.0224e-05 eta 0:01:51
epoch [46/50] batch [180/244] time 0.153 (0.108) data 0.000 (0.002) loss 1.6195 (1.2082) ce_loss 1.4668 (1.0424) teacher_loss 1.4750 (1.0376) loss_zs_kd 0.1299 (0.1683) loss_oracle 0.0795 (0.0864) acc 65.6250 (72.1181) kd_loss 0.0532 (0.0716) lr 7.0224e-05 eta 0:01:52
epoch [46/50] batch [200/244] time 0.123 (0.110) data 0.000 (0.002) loss 1.9932 (1.2176) ce_loss 1.7881 (1.0516) teacher_loss 1.8015 (1.0469) loss_zs_kd 0.2374 (0.1686) loss_oracle 0.0730 (0.0863) acc 53.1250 (71.9531) kd_loss 0.0811 (0.0719) lr 7.0224e-05 eta 0:01:52
epoch [46/50] batch [220/244] time 0.115 (0.112) data 0.000 (0.002) loss 1.1228 (1.2194) ce_loss 0.9399 (1.0525) teacher_loss 0.9216 (1.0476) loss_zs_kd 0.1801 (0.1698) loss_oracle 0.1111 (0.0869) acc 78.1250 (72.0312) kd_loss 0.0794 (0.0720) lr 7.0224e-05 eta 0:01:52
epoch [46/50] batch [240/244] time 0.104 (0.111) data 0.000 (0.001) loss 1.1879 (1.2264) ce_loss 0.9814 (1.0582) teacher_loss 0.9754 (1.0531) loss_zs_kd 0.1594 (0.1704) loss_oracle 0.1328 (0.0881) acc 71.8750 (71.8359) kd_loss 0.0927 (0.0721) lr 7.0224e-05 eta 0:01:49
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,836
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,040
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [47/50] batch [20/244] time 0.101 (0.125) data 0.000 (0.018) loss 1.0167 (1.1544) ce_loss 0.8589 (0.9889) teacher_loss 0.8575 (0.9841) loss_zs_kd 0.1506 (0.1654) loss_oracle 0.0839 (0.0876) acc 78.1250 (73.7500) kd_loss 0.0698 (0.0713) lr 4.8943e-05 eta 0:01:59
epoch [47/50] batch [40/244] time 0.099 (0.112) data 0.000 (0.009) loss 0.8246 (1.1631) ce_loss 0.6738 (0.9968) teacher_loss 0.6723 (0.9911) loss_zs_kd 0.1439 (0.1624) loss_oracle 0.0803 (0.0908) acc 78.1250 (73.9844) kd_loss 0.0748 (0.0726) lr 4.8943e-05 eta 0:01:44
epoch [47/50] batch [60/244] time 0.100 (0.107) data 0.001 (0.006) loss 1.0060 (1.2201) ce_loss 0.7974 (1.0530) teacher_loss 0.8040 (1.0479) loss_zs_kd 0.2139 (0.1650) loss_oracle 0.0951 (0.0897) acc 81.2500 (72.1875) kd_loss 0.0710 (0.0715) lr 4.8943e-05 eta 0:01:37
epoch [47/50] batch [80/244] time 0.100 (0.104) data 0.000 (0.005) loss 1.0737 (1.2118) ce_loss 0.9087 (1.0453) teacher_loss 0.9094 (1.0395) loss_zs_kd 0.1698 (0.1648) loss_oracle 0.0794 (0.0899) acc 78.1250 (72.6172) kd_loss 0.0578 (0.0711) lr 4.8943e-05 eta 0:01:33
epoch [47/50] batch [100/244] time 0.108 (0.106) data 0.000 (0.004) loss 1.7910 (1.2287) ce_loss 1.5840 (1.0629) teacher_loss 1.5655 (1.0567) loss_zs_kd 0.2264 (0.1638) loss_oracle 0.1123 (0.0901) acc 59.3750 (72.1562) kd_loss 0.0800 (0.0712) lr 4.8943e-05 eta 0:01:32
epoch [47/50] batch [120/244] time 0.096 (0.105) data 0.000 (0.003) loss 1.2788 (1.2197) ce_loss 1.1035 (1.0541) teacher_loss 1.1004 (1.0484) loss_zs_kd 0.1546 (0.1642) loss_oracle 0.1011 (0.0893) acc 71.8750 (72.3958) kd_loss 0.0704 (0.0714) lr 4.8943e-05 eta 0:01:29
epoch [47/50] batch [140/244] time 0.096 (0.105) data 0.000 (0.003) loss 1.6252 (1.2247) ce_loss 1.4219 (1.0589) teacher_loss 1.4148 (1.0533) loss_zs_kd 0.2143 (0.1642) loss_oracle 0.1032 (0.0893) acc 68.7500 (72.1429) kd_loss 0.0853 (0.0716) lr 4.8943e-05 eta 0:01:27
epoch [47/50] batch [160/244] time 0.099 (0.104) data 0.000 (0.003) loss 1.0580 (1.2249) ce_loss 0.9014 (1.0600) teacher_loss 0.9124 (1.0549) loss_zs_kd 0.1460 (0.1626) loss_oracle 0.0726 (0.0887) acc 84.3750 (72.3633) kd_loss 0.0648 (0.0720) lr 4.8943e-05 eta 0:01:24
epoch [47/50] batch [180/244] time 0.096 (0.103) data 0.000 (0.002) loss 1.2021 (1.2135) ce_loss 1.0088 (1.0481) teacher_loss 1.0052 (1.0431) loss_zs_kd 0.2257 (0.1633) loss_oracle 0.0841 (0.0888) acc 75.0000 (72.6736) kd_loss 0.0610 (0.0719) lr 4.8943e-05 eta 0:01:22
epoch [47/50] batch [200/244] time 0.095 (0.102) data 0.000 (0.002) loss 0.9989 (1.2103) ce_loss 0.8438 (1.0443) teacher_loss 0.8430 (1.0394) loss_zs_kd 0.1480 (0.1642) loss_oracle 0.0819 (0.0887) acc 78.1250 (72.7812) kd_loss 0.0589 (0.0719) lr 4.8943e-05 eta 0:01:19
epoch [47/50] batch [220/244] time 0.092 (0.101) data 0.000 (0.002) loss 1.4509 (1.2197) ce_loss 1.2510 (1.0531) teacher_loss 1.2526 (1.0483) loss_zs_kd 0.2200 (0.1653) loss_oracle 0.0884 (0.0888) acc 68.7500 (72.5142) kd_loss 0.0698 (0.0719) lr 4.8943e-05 eta 0:01:16
epoch [47/50] batch [240/244] time 0.086 (0.100) data 0.000 (0.002) loss 1.2551 (1.2097) ce_loss 1.0352 (1.0420) teacher_loss 1.0224 (1.0372) loss_zs_kd 0.2466 (0.1666) loss_oracle 0.1094 (0.0892) acc 81.2500 (72.8646) kd_loss 0.0929 (0.0720) lr 4.8943e-05 eta 0:01:13
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,836
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [48/50] batch [20/244] time 0.102 (0.126) data 0.000 (0.015) loss 1.0348 (1.2951) ce_loss 0.8110 (1.1221) teacher_loss 0.8178 (1.1148) loss_zs_kd 0.2839 (0.1802) loss_oracle 0.0751 (0.0903) acc 75.0000 (70.1562) kd_loss 0.0729 (0.0737) lr 3.1417e-05 eta 0:01:29
epoch [48/50] batch [40/244] time 0.094 (0.114) data 0.000 (0.008) loss 1.1756 (1.2616) ce_loss 1.0635 (1.0861) teacher_loss 1.0646 (1.0811) loss_zs_kd 0.0863 (0.1785) loss_oracle 0.0678 (0.0912) acc 68.7500 (71.2500) kd_loss 0.0464 (0.0704) lr 3.1417e-05 eta 0:01:18
epoch [48/50] batch [60/244] time 0.101 (0.110) data 0.001 (0.005) loss 1.0958 (1.2542) ce_loss 0.9536 (1.0809) teacher_loss 0.9509 (1.0768) loss_zs_kd 0.1493 (0.1740) loss_oracle 0.0702 (0.0904) acc 78.1250 (71.6667) kd_loss 0.0720 (0.0701) lr 3.1417e-05 eta 0:01:14
epoch [48/50] batch [80/244] time 0.096 (0.107) data 0.000 (0.004) loss 1.3135 (1.2573) ce_loss 1.1602 (1.0861) teacher_loss 1.1551 (1.0805) loss_zs_kd 0.1441 (0.1720) loss_oracle 0.0863 (0.0908) acc 68.7500 (71.4844) kd_loss 0.0752 (0.0717) lr 3.1417e-05 eta 0:01:09
epoch [48/50] batch [100/244] time 0.101 (0.105) data 0.000 (0.003) loss 1.1425 (1.2458) ce_loss 0.9814 (1.0765) teacher_loss 0.9738 (1.0709) loss_zs_kd 0.1568 (0.1706) loss_oracle 0.0903 (0.0896) acc 75.0000 (71.5000) kd_loss 0.0769 (0.0718) lr 3.1417e-05 eta 0:01:06
epoch [48/50] batch [120/244] time 0.092 (0.104) data 0.000 (0.003) loss 0.9548 (1.2512) ce_loss 0.7812 (1.0831) teacher_loss 0.7839 (1.0777) loss_zs_kd 0.1826 (0.1695) loss_oracle 0.0796 (0.0888) acc 78.1250 (71.6667) kd_loss 0.0738 (0.0713) lr 3.1417e-05 eta 0:01:03
epoch [48/50] batch [140/244] time 0.091 (0.103) data 0.000 (0.002) loss 1.2846 (1.2585) ce_loss 1.1289 (1.0896) teacher_loss 1.1264 (1.0843) loss_zs_kd 0.1719 (0.1712) loss_oracle 0.0722 (0.0886) acc 71.8750 (71.4955) kd_loss 0.0689 (0.0710) lr 3.1417e-05 eta 0:01:01
epoch [48/50] batch [160/244] time 0.107 (0.103) data 0.000 (0.002) loss 1.7126 (1.2472) ce_loss 1.5430 (1.0797) teacher_loss 1.5435 (1.0747) loss_zs_kd 0.1267 (0.1688) loss_oracle 0.1057 (0.0881) acc 62.5000 (71.6406) kd_loss 0.0739 (0.0713) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [180/244] time 0.096 (0.103) data 0.000 (0.002) loss 1.0230 (1.2383) ce_loss 0.8462 (1.0702) teacher_loss 0.8348 (1.0652) loss_zs_kd 0.1740 (0.1699) loss_oracle 0.1012 (0.0881) acc 81.2500 (71.7535) kd_loss 0.0743 (0.0715) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [200/244] time 0.100 (0.102) data 0.001 (0.002) loss 1.0891 (1.2434) ce_loss 0.9238 (1.0745) teacher_loss 0.9289 (1.0700) loss_zs_kd 0.1929 (0.1703) loss_oracle 0.0638 (0.0882) acc 81.2500 (71.7969) kd_loss 0.0753 (0.0714) lr 3.1417e-05 eta 0:00:54
epoch [48/50] batch [220/244] time 0.097 (0.102) data 0.000 (0.002) loss 1.2427 (1.2459) ce_loss 1.0586 (1.0773) teacher_loss 1.0577 (1.0727) loss_zs_kd 0.1596 (0.1697) loss_oracle 0.1052 (0.0883) acc 71.8750 (71.7330) kd_loss 0.0718 (0.0714) lr 3.1417e-05 eta 0:00:52
epoch [48/50] batch [240/244] time 0.104 (0.102) data 0.000 (0.001) loss 1.0967 (1.2368) ce_loss 0.9619 (1.0679) teacher_loss 0.9518 (1.0632) loss_zs_kd 0.1480 (0.1699) loss_oracle 0.0710 (0.0886) acc 68.7500 (72.0703) kd_loss 0.0677 (0.0716) lr 3.1417e-05 eta 0:00:50
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,837
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [49/50] batch [20/244] time 0.128 (0.138) data 0.000 (0.011) loss 1.2315 (1.2125) ce_loss 1.0479 (1.0381) teacher_loss 1.0445 (1.0340) loss_zs_kd 0.1454 (0.1831) loss_oracle 0.1143 (0.0870) acc 68.7500 (73.9062) kd_loss 0.0899 (0.0726) lr 1.7713e-05 eta 0:01:04
epoch [49/50] batch [40/244] time 0.128 (0.134) data 0.000 (0.006) loss 1.1695 (1.1933) ce_loss 0.9814 (1.0275) teacher_loss 0.9761 (1.0233) loss_zs_kd 0.1701 (0.1682) loss_oracle 0.1083 (0.0858) acc 71.8750 (73.3594) kd_loss 0.0775 (0.0723) lr 1.7713e-05 eta 0:01:00
epoch [49/50] batch [60/244] time 0.129 (0.131) data 0.001 (0.004) loss 0.9363 (1.1992) ce_loss 0.7300 (1.0325) teacher_loss 0.7261 (1.0290) loss_zs_kd 0.2263 (0.1664) loss_oracle 0.0971 (0.0870) acc 81.2500 (73.0729) kd_loss 0.0709 (0.0726) lr 1.7713e-05 eta 0:00:56
epoch [49/50] batch [80/244] time 0.116 (0.129) data 0.000 (0.003) loss 0.9065 (1.2093) ce_loss 0.7715 (1.0416) teacher_loss 0.7692 (1.0379) loss_zs_kd 0.1245 (0.1691) loss_oracle 0.0750 (0.0869) acc 84.3750 (72.6172) kd_loss 0.0868 (0.0729) lr 1.7713e-05 eta 0:00:52
epoch [49/50] batch [100/244] time 0.119 (0.125) data 0.000 (0.003) loss 1.0040 (1.2300) ce_loss 0.8267 (1.0615) teacher_loss 0.8308 (1.0581) loss_zs_kd 0.1757 (0.1698) loss_oracle 0.0854 (0.0870) acc 75.0000 (72.0625) kd_loss 0.0649 (0.0733) lr 1.7713e-05 eta 0:00:48
epoch [49/50] batch [120/244] time 0.110 (0.124) data 0.000 (0.002) loss 1.1093 (1.2113) ce_loss 0.9531 (1.0430) teacher_loss 0.9420 (1.0392) loss_zs_kd 0.1869 (0.1690) loss_oracle 0.0739 (0.0875) acc 78.1250 (72.6562) kd_loss 0.0761 (0.0724) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [140/244] time 0.128 (0.124) data 0.000 (0.002) loss 1.3993 (1.1932) ce_loss 1.2393 (1.0246) teacher_loss 1.2351 (1.0205) loss_zs_kd 0.1753 (0.1693) loss_oracle 0.0766 (0.0880) acc 62.5000 (73.1696) kd_loss 0.0834 (0.0726) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [160/244] time 0.110 (0.123) data 0.000 (0.002) loss 1.1660 (1.2054) ce_loss 0.9902 (1.0374) teacher_loss 0.9933 (1.0335) loss_zs_kd 0.1316 (0.1685) loss_oracle 0.1068 (0.0877) acc 75.0000 (73.0664) kd_loss 0.0905 (0.0724) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [180/244] time 0.105 (0.123) data 0.000 (0.002) loss 1.0693 (1.2002) ce_loss 0.8911 (1.0329) teacher_loss 0.8801 (1.0287) loss_zs_kd 0.1804 (0.1673) loss_oracle 0.0990 (0.0878) acc 81.2500 (72.9688) kd_loss 0.0764 (0.0727) lr 1.7713e-05 eta 0:00:37
epoch [49/50] batch [200/244] time 0.095 (0.121) data 0.000 (0.001) loss 1.0578 (1.2104) ce_loss 0.9077 (1.0431) teacher_loss 0.9065 (1.0389) loss_zs_kd 0.1385 (0.1670) loss_oracle 0.0821 (0.0881) acc 71.8750 (72.6562) kd_loss 0.0704 (0.0725) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [220/244] time 0.101 (0.119) data 0.000 (0.001) loss 2.0233 (1.2185) ce_loss 1.8447 (1.0510) teacher_loss 1.8422 (1.0465) loss_zs_kd 0.2093 (0.1672) loss_oracle 0.0764 (0.0884) acc 56.2500 (72.3864) kd_loss 0.0725 (0.0728) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [240/244] time 0.104 (0.117) data 0.000 (0.001) loss 1.3876 (1.2175) ce_loss 1.2168 (1.0503) teacher_loss 1.2053 (1.0459) loss_zs_kd 0.1540 (0.1670) loss_oracle 0.1053 (0.0881) acc 65.6250 (72.4089) kd_loss 0.0724 (0.0727) lr 1.7713e-05 eta 0:00:29
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,835
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,042
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.5%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
epoch [50/50] batch [20/244] time 0.111 (0.130) data 0.000 (0.017) loss 1.3201 (1.2298) ce_loss 1.1650 (1.0610) teacher_loss 1.1764 (1.0556) loss_zs_kd 0.1387 (0.1695) loss_oracle 0.0743 (0.0895) acc 65.6250 (71.4062) kd_loss 0.0658 (0.0722) lr 7.8853e-06 eta 0:00:29
epoch [50/50] batch [40/244] time 0.116 (0.126) data 0.000 (0.009) loss 1.4511 (1.2100) ce_loss 1.2910 (1.0435) teacher_loss 1.2804 (1.0398) loss_zs_kd 0.1733 (0.1662) loss_oracle 0.0840 (0.0871) acc 65.6250 (71.8750) kd_loss 0.0766 (0.0712) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [60/244] time 0.133 (0.128) data 0.001 (0.006) loss 0.5477 (1.1874) ce_loss 0.4060 (1.0161) teacher_loss 0.4110 (1.0128) loss_zs_kd 0.1154 (0.1699) loss_oracle 0.0789 (0.0897) acc 90.6250 (72.8646) kd_loss 0.0650 (0.0708) lr 7.8853e-06 eta 0:00:23
epoch [50/50] batch [80/244] time 0.131 (0.129) data 0.000 (0.005) loss 1.3672 (1.1806) ce_loss 1.2148 (1.0125) teacher_loss 1.2082 (1.0088) loss_zs_kd 0.1249 (0.1652) loss_oracle 0.0965 (0.0892) acc 65.6250 (72.8906) kd_loss 0.0743 (0.0708) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [100/244] time 0.127 (0.129) data 0.000 (0.004) loss 1.5076 (1.2025) ce_loss 1.3682 (1.0354) teacher_loss 1.3381 (1.0311) loss_zs_kd 0.1508 (0.1639) loss_oracle 0.0941 (0.0895) acc 65.6250 (72.2812) kd_loss 0.0747 (0.0711) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [120/244] time 0.134 (0.129) data 0.000 (0.003) loss 1.0750 (1.1931) ce_loss 0.9033 (1.0264) teacher_loss 0.8990 (1.0223) loss_zs_kd 0.1916 (0.1638) loss_oracle 0.0802 (0.0889) acc 78.1250 (72.6562) kd_loss 0.0638 (0.0717) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [140/244] time 0.128 (0.129) data 0.000 (0.003) loss 1.1709 (1.2017) ce_loss 1.0244 (1.0356) teacher_loss 1.0193 (1.0310) loss_zs_kd 0.1532 (0.1638) loss_oracle 0.0750 (0.0888) acc 68.7500 (72.3438) kd_loss 0.0800 (0.0721) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [160/244] time 0.126 (0.129) data 0.000 (0.002) loss 0.7867 (1.1947) ce_loss 0.6406 (1.0278) teacher_loss 0.6423 (1.0233) loss_zs_kd 0.1524 (0.1647) loss_oracle 0.0682 (0.0890) acc 87.5000 (72.5000) kd_loss 0.0590 (0.0725) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [180/244] time 0.137 (0.129) data 0.000 (0.002) loss 1.6968 (1.2016) ce_loss 1.5459 (1.0336) teacher_loss 1.5324 (1.0288) loss_zs_kd 0.1249 (0.1673) loss_oracle 0.1020 (0.0892) acc 56.2500 (72.4479) kd_loss 0.0708 (0.0728) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [200/244] time 0.111 (0.126) data 0.000 (0.002) loss 1.1155 (1.2031) ce_loss 0.9028 (1.0341) teacher_loss 0.9043 (1.0291) loss_zs_kd 0.2705 (0.1680) loss_oracle 0.0761 (0.0900) acc 78.1250 (72.4531) kd_loss 0.0611 (0.0725) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [220/244] time 0.111 (0.124) data 0.000 (0.002) loss 1.6724 (1.1989) ce_loss 1.4912 (1.0295) teacher_loss 1.4898 (1.0246) loss_zs_kd 0.2113 (0.1683) loss_oracle 0.0769 (0.0901) acc 53.1250 (72.6705) kd_loss 0.0608 (0.0725) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [240/244] time 0.110 (0.123) data 0.000 (0.002) loss 0.7813 (1.2054) ce_loss 0.6089 (1.0357) teacher_loss 0.6101 (1.0307) loss_zs_kd 0.1310 (0.1695) loss_oracle 0.1057 (0.0899) acc 81.2500 (72.4349) kd_loss 0.0747 (0.0724) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,834
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 5 *******
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:26:55

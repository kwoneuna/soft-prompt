Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'clipart', 'product']
Target     ['real_world']
# classes  65
# train_x  7,877
# val      3,354
# test     4,357
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/246] time 0.114 (0.156) data 0.000 (0.022) loss 1.6049 (1.4868) ce_loss 1.6035 (1.4867) teacher_loss 1.6048 (1.4867) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0000 (0.0000) acc 59.3750 (60.9375) kd_loss 0.0267 (0.0164) lr 1.0000e-05 eta 0:32:00
epoch [1/50] batch [40/246] time 0.131 (0.136) data 0.001 (0.011) loss 1.0217 (1.4160) ce_loss 1.0205 (1.4159) teacher_loss 1.0216 (1.4160) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0001 (0.0000) acc 75.0000 (62.9688) kd_loss 0.0103 (0.0153) lr 1.0000e-05 eta 0:27:51
epoch [1/50] batch [60/246] time 0.098 (0.128) data 0.000 (0.008) loss 1.1298 (1.4168) ce_loss 1.1299 (1.4168) teacher_loss 1.1296 (1.4168) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0001 (0.0000) acc 78.1250 (63.3333) kd_loss 0.0085 (0.0135) lr 1.0000e-05 eta 0:26:02
epoch [1/50] batch [80/246] time 0.111 (0.122) data 0.000 (0.006) loss 1.9283 (1.4096) ce_loss 1.9297 (1.4095) teacher_loss 1.9280 (1.4095) loss_zs_kd 0.0005 (0.0001) loss_oracle 0.0001 (0.0000) acc 50.0000 (63.5547) kd_loss 0.0056 (0.0117) lr 1.0000e-05 eta 0:24:45
epoch [1/50] batch [100/246] time 0.099 (0.119) data 0.000 (0.005) loss 1.4576 (1.3921) ce_loss 1.4580 (1.3920) teacher_loss 1.4570 (1.3919) loss_zs_kd 0.0010 (0.0002) loss_oracle 0.0001 (0.0001) acc 59.3750 (63.8750) kd_loss 0.0047 (0.0105) lr 1.0000e-05 eta 0:24:07
epoch [1/50] batch [120/246] time 0.118 (0.116) data 0.000 (0.004) loss 1.5088 (1.3929) ce_loss 1.5098 (1.3927) teacher_loss 1.5082 (1.3926) loss_zs_kd 0.0011 (0.0003) loss_oracle 0.0001 (0.0001) acc 59.3750 (64.0365) kd_loss 0.0076 (0.0096) lr 1.0000e-05 eta 0:23:36
epoch [1/50] batch [140/246] time 0.102 (0.115) data 0.000 (0.003) loss 1.7437 (1.3924) ce_loss 1.7441 (1.3921) teacher_loss 1.7432 (1.3921) loss_zs_kd 0.0006 (0.0004) loss_oracle 0.0002 (0.0001) acc 53.1250 (64.1071) kd_loss 0.0028 (0.0089) lr 1.0000e-05 eta 0:23:16
epoch [1/50] batch [160/246] time 0.118 (0.114) data 0.000 (0.003) loss 1.6006 (1.4035) ce_loss 1.6006 (1.4032) teacher_loss 1.6000 (1.4031) loss_zs_kd 0.0011 (0.0005) loss_oracle 0.0001 (0.0001) acc 65.6250 (63.6523) kd_loss 0.0032 (0.0082) lr 1.0000e-05 eta 0:22:59
epoch [1/50] batch [180/246] time 0.108 (0.112) data 0.000 (0.003) loss 1.6164 (1.3971) ce_loss 1.6152 (1.3968) teacher_loss 1.6155 (1.3967) loss_zs_kd 0.0015 (0.0007) loss_oracle 0.0001 (0.0001) acc 56.2500 (63.9931) kd_loss 0.0023 (0.0076) lr 1.0000e-05 eta 0:22:40
epoch [1/50] batch [200/246] time 0.116 (0.112) data 0.000 (0.002) loss 2.1326 (1.3982) ce_loss 2.1289 (1.3977) teacher_loss 2.1300 (1.3977) loss_zs_kd 0.0048 (0.0008) loss_oracle 0.0002 (0.0001) acc 40.6250 (63.8750) kd_loss 0.0042 (0.0072) lr 1.0000e-05 eta 0:22:38
epoch [1/50] batch [220/246] time 0.117 (0.112) data 0.000 (0.002) loss 1.2766 (1.3987) ce_loss 1.2754 (1.3982) teacher_loss 1.2746 (1.3981) loss_zs_kd 0.0036 (0.0010) loss_oracle 0.0002 (0.0001) acc 71.8750 (64.0199) kd_loss 0.0036 (0.0068) lr 1.0000e-05 eta 0:22:35
epoch [1/50] batch [240/246] time 0.102 (0.112) data 0.000 (0.002) loss 1.5874 (1.3975) ce_loss 1.5859 (1.3969) teacher_loss 1.5857 (1.3968) loss_zs_kd 0.0027 (0.0012) loss_oracle 0.0002 (0.0001) acc 59.3750 (63.9714) kd_loss 0.0022 (0.0065) lr 1.0000e-05 eta 0:22:30
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,683
* accuracy: 80.0%
* error: 20.0%
* macro_f1: 78.8%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,891
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 87.8%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      80.0%, epoch: 1 *******
******* Domain r best val test acc: 89.3%, epoch: 1 *******
******* Domain r best test acc:     89.3%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/ana
epoch [2/50] batch [20/246] time 0.124 (0.151) data 0.000 (0.026) loss 1.6830 (1.4792) ce_loss 1.6338 (1.4492) teacher_loss 1.6339 (1.4494) loss_zs_kd 0.0885 (0.0534) loss_oracle 0.0049 (0.0030) acc 68.7500 (64.0625) kd_loss 0.0021 (0.0026) lr 2.0000e-03 eta 0:30:17
epoch [2/50] batch [40/246] time 0.096 (0.129) data 0.000 (0.013) loss 1.5303 (1.4355) ce_loss 1.4873 (1.3898) teacher_loss 1.4873 (1.3899) loss_zs_kd 0.0758 (0.0751) loss_oracle 0.0051 (0.0080) acc 62.5000 (65.2344) kd_loss 0.0026 (0.0026) lr 2.0000e-03 eta 0:25:55
epoch [2/50] batch [60/246] time 0.098 (0.119) data 0.000 (0.009) loss 1.3905 (1.3635) ce_loss 1.3359 (1.3181) teacher_loss 1.3337 (1.3182) loss_zs_kd 0.1040 (0.0765) loss_oracle 0.0048 (0.0070) acc 62.5000 (66.7188) kd_loss 0.0035 (0.0031) lr 2.0000e-03 eta 0:23:50
epoch [2/50] batch [80/246] time 0.102 (0.114) data 0.000 (0.007) loss 1.3482 (1.3335) ce_loss 1.2842 (1.2856) teacher_loss 1.2835 (1.2857) loss_zs_kd 0.1132 (0.0815) loss_oracle 0.0081 (0.0070) acc 62.5000 (67.2266) kd_loss 0.0051 (0.0033) lr 2.0000e-03 eta 0:22:50
epoch [2/50] batch [100/246] time 0.104 (0.112) data 0.000 (0.005) loss 1.1504 (1.3256) ce_loss 1.1113 (1.2756) teacher_loss 1.1117 (1.2756) loss_zs_kd 0.0576 (0.0843) loss_oracle 0.0099 (0.0078) acc 65.6250 (67.0000) kd_loss 0.0028 (0.0034) lr 2.0000e-03 eta 0:22:24
epoch [2/50] batch [120/246] time 0.099 (0.111) data 0.000 (0.005) loss 1.0367 (1.3135) ce_loss 0.9951 (1.2618) teacher_loss 0.9960 (1.2618) loss_zs_kd 0.0621 (0.0876) loss_oracle 0.0097 (0.0080) acc 75.0000 (67.6042) kd_loss 0.0042 (0.0036) lr 2.0000e-03 eta 0:22:08
epoch [2/50] batch [140/246] time 0.091 (0.111) data 0.000 (0.004) loss 1.3543 (1.3039) ce_loss 1.3174 (1.2514) teacher_loss 1.3171 (1.2513) loss_zs_kd 0.0554 (0.0888) loss_oracle 0.0095 (0.0082) acc 71.8750 (67.6786) kd_loss 0.0035 (0.0035) lr 2.0000e-03 eta 0:21:57
epoch [2/50] batch [160/246] time 0.110 (0.110) data 0.000 (0.003) loss 1.0910 (1.2976) ce_loss 1.0352 (1.2448) teacher_loss 1.0354 (1.2446) loss_zs_kd 0.0947 (0.0899) loss_oracle 0.0082 (0.0080) acc 68.7500 (67.7930) kd_loss 0.0028 (0.0035) lr 2.0000e-03 eta 0:21:51
epoch [2/50] batch [180/246] time 0.123 (0.111) data 0.000 (0.003) loss 1.3545 (1.2911) ce_loss 1.2637 (1.2361) teacher_loss 1.2629 (1.2360) loss_zs_kd 0.1328 (0.0925) loss_oracle 0.0252 (0.0089) acc 75.0000 (68.1424) kd_loss 0.0027 (0.0034) lr 2.0000e-03 eta 0:21:53
epoch [2/50] batch [200/246] time 0.124 (0.112) data 0.000 (0.003) loss 1.6798 (1.2952) ce_loss 1.6172 (1.2379) teacher_loss 1.6177 (1.2378) loss_zs_kd 0.0897 (0.0954) loss_oracle 0.0173 (0.0097) acc 53.1250 (68.0625) kd_loss 0.0052 (0.0034) lr 2.0000e-03 eta 0:22:03
epoch [2/50] batch [220/246] time 0.120 (0.112) data 0.000 (0.003) loss 1.3136 (1.2914) ce_loss 1.2178 (1.2331) teacher_loss 1.2198 (1.2330) loss_zs_kd 0.1646 (0.0971) loss_oracle 0.0115 (0.0098) acc 68.7500 (68.1392) kd_loss 0.0026 (0.0034) lr 2.0000e-03 eta 0:22:08
epoch [2/50] batch [240/246] time 0.104 (0.112) data 0.000 (0.002) loss 1.3062 (1.2946) ce_loss 1.1729 (1.2346) teacher_loss 1.1745 (1.2345) loss_zs_kd 0.2301 (0.1002) loss_oracle 0.0167 (0.0100) acc 68.7500 (68.1380) kd_loss 0.0036 (0.0034) lr 2.0000e-03 eta 0:22:00
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,792
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 82.3%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,943
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.3%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.2%, epoch: 2 *******
******* Domain r best val test acc: 90.5%, epoch: 2 *******
******* Domain r best test acc:     90.5%, epoch: 2 *******
epoch [3/50] batch [20/246] time 0.092 (0.111) data 0.000 (0.013) loss 1.4902 (1.2655) ce_loss 1.4424 (1.2021) teacher_loss 1.4397 (1.2021) loss_zs_kd 0.0862 (0.1053) loss_oracle 0.0075 (0.0107) acc 56.2500 (68.9062) kd_loss 0.0046 (0.0043) lr 1.9980e-03 eta 0:21:51
epoch [3/50] batch [40/246] time 0.098 (0.103) data 0.000 (0.006) loss 0.7792 (1.2644) ce_loss 0.7427 (1.1997) teacher_loss 0.7429 (1.1996) loss_zs_kd 0.0593 (0.1105) loss_oracle 0.0066 (0.0096) acc 84.3750 (70.0781) kd_loss 0.0033 (0.0044) lr 1.9980e-03 eta 0:20:08
epoch [3/50] batch [60/246] time 0.107 (0.100) data 0.000 (0.004) loss 1.8478 (1.2742) ce_loss 1.7773 (1.2103) teacher_loss 1.7743 (1.2102) loss_zs_kd 0.1124 (0.1088) loss_oracle 0.0172 (0.0095) acc 46.8750 (69.3229) kd_loss 0.0050 (0.0044) lr 1.9980e-03 eta 0:19:37
epoch [3/50] batch [80/246] time 0.095 (0.099) data 0.000 (0.003) loss 1.8457 (1.2925) ce_loss 1.7715 (1.2243) teacher_loss 1.7705 (1.2240) loss_zs_kd 0.1350 (0.1167) loss_oracle 0.0077 (0.0101) acc 62.5000 (69.2969) kd_loss 0.0031 (0.0043) lr 1.9980e-03 eta 0:19:22
epoch [3/50] batch [100/246] time 0.096 (0.098) data 0.000 (0.003) loss 1.1017 (1.2898) ce_loss 1.0488 (1.2199) teacher_loss 1.0480 (1.2198) loss_zs_kd 0.0706 (0.1177) loss_oracle 0.0184 (0.0112) acc 68.7500 (69.1250) kd_loss 0.0055 (0.0042) lr 1.9980e-03 eta 0:19:08
epoch [3/50] batch [120/246] time 0.099 (0.098) data 0.001 (0.002) loss 1.1914 (1.2792) ce_loss 1.1514 (1.2094) teacher_loss 1.1496 (1.2093) loss_zs_kd 0.0562 (0.1148) loss_oracle 0.0138 (0.0125) acc 78.1250 (69.2969) kd_loss 0.0036 (0.0041) lr 1.9980e-03 eta 0:19:04
epoch [3/50] batch [140/246] time 0.098 (0.098) data 0.000 (0.002) loss 1.5701 (1.2823) ce_loss 1.4980 (1.2131) teacher_loss 1.4960 (1.2130) loss_zs_kd 0.1226 (0.1145) loss_oracle 0.0128 (0.0122) acc 59.3750 (68.9286) kd_loss 0.0054 (0.0042) lr 1.9980e-03 eta 0:19:01
epoch [3/50] batch [160/246] time 0.099 (0.097) data 0.000 (0.002) loss 1.1051 (1.2856) ce_loss 1.0127 (1.2145) teacher_loss 1.0180 (1.2144) loss_zs_kd 0.1242 (0.1151) loss_oracle 0.0250 (0.0137) acc 75.0000 (68.9844) kd_loss 0.0047 (0.0042) lr 1.9980e-03 eta 0:18:54
epoch [3/50] batch [180/246] time 0.104 (0.098) data 0.000 (0.002) loss 1.3259 (1.2773) ce_loss 1.2344 (1.2053) teacher_loss 1.2351 (1.2053) loss_zs_kd 0.1311 (0.1156) loss_oracle 0.0252 (0.0141) acc 71.8750 (68.8889) kd_loss 0.0049 (0.0042) lr 1.9980e-03 eta 0:18:55
epoch [3/50] batch [200/246] time 0.097 (0.097) data 0.000 (0.001) loss 1.1975 (1.2776) ce_loss 1.1318 (1.2043) teacher_loss 1.1333 (1.2043) loss_zs_kd 0.0903 (0.1175) loss_oracle 0.0191 (0.0146) acc 71.8750 (68.7812) kd_loss 0.0034 (0.0042) lr 1.9980e-03 eta 0:18:50
epoch [3/50] batch [220/246] time 0.089 (0.097) data 0.000 (0.001) loss 0.9571 (1.2790) ce_loss 0.8975 (1.2052) teacher_loss 0.8982 (1.2052) loss_zs_kd 0.0937 (0.1180) loss_oracle 0.0120 (0.0147) acc 75.0000 (68.5795) kd_loss 0.0042 (0.0043) lr 1.9980e-03 eta 0:18:46
epoch [3/50] batch [240/246] time 0.087 (0.097) data 0.000 (0.001) loss 0.9473 (1.2745) ce_loss 0.8848 (1.1997) teacher_loss 0.8828 (1.1997) loss_zs_kd 0.0892 (0.1191) loss_oracle 0.0199 (0.0152) acc 75.0000 (68.7500) kd_loss 0.0057 (0.0043) lr 1.9980e-03 eta 0:18:40
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,801
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.6%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.5%, epoch: 3 *******
******* Domain r best val test acc: 90.8%, epoch: 3 *******
******* Domain r best test acc:     90.8%, epoch: 3 *******
epoch [4/50] batch [20/246] time 0.094 (0.110) data 0.000 (0.014) loss 1.0765 (1.2008) ce_loss 1.0215 (1.1220) teacher_loss 1.0217 (1.1227) loss_zs_kd 0.0767 (0.1199) loss_oracle 0.0164 (0.0181) acc 71.8750 (71.7188) kd_loss 0.0039 (0.0050) lr 1.9921e-03 eta 0:21:14
epoch [4/50] batch [40/246] time 0.093 (0.102) data 0.000 (0.007) loss 1.2228 (1.1838) ce_loss 1.1289 (1.0993) teacher_loss 1.1288 (1.0999) loss_zs_kd 0.1171 (0.1197) loss_oracle 0.0354 (0.0241) acc 75.0000 (71.8750) kd_loss 0.0058 (0.0051) lr 1.9921e-03 eta 0:19:33
epoch [4/50] batch [60/246] time 0.095 (0.099) data 0.000 (0.005) loss 1.3855 (1.2127) ce_loss 1.3008 (1.1202) teacher_loss 1.3000 (1.1204) loss_zs_kd 0.1192 (0.1207) loss_oracle 0.0259 (0.0319) acc 75.0000 (71.3021) kd_loss 0.0059 (0.0057) lr 1.9921e-03 eta 0:19:03
epoch [4/50] batch [80/246] time 0.097 (0.098) data 0.000 (0.004) loss 0.9285 (1.2076) ce_loss 0.8550 (1.1139) teacher_loss 0.8577 (1.1143) loss_zs_kd 0.0868 (0.1257) loss_oracle 0.0275 (0.0304) acc 75.0000 (71.3672) kd_loss 0.0075 (0.0058) lr 1.9921e-03 eta 0:18:45
epoch [4/50] batch [100/246] time 0.090 (0.098) data 0.000 (0.003) loss 1.2027 (1.2132) ce_loss 1.1250 (1.1209) teacher_loss 1.1243 (1.1212) loss_zs_kd 0.1019 (0.1246) loss_oracle 0.0275 (0.0297) acc 62.5000 (70.9375) kd_loss 0.0052 (0.0058) lr 1.9921e-03 eta 0:18:39
epoch [4/50] batch [120/246] time 0.104 (0.098) data 0.000 (0.003) loss 1.6524 (1.2195) ce_loss 1.5420 (1.1267) teacher_loss 1.5427 (1.1270) loss_zs_kd 0.1235 (0.1252) loss_oracle 0.0479 (0.0299) acc 56.2500 (70.3906) kd_loss 0.0108 (0.0062) lr 1.9921e-03 eta 0:18:38
epoch [4/50] batch [140/246] time 0.093 (0.098) data 0.000 (0.002) loss 1.1843 (1.2070) ce_loss 1.0879 (1.1130) teacher_loss 1.0857 (1.1133) loss_zs_kd 0.1110 (0.1246) loss_oracle 0.0431 (0.0314) acc 71.8750 (70.8259) kd_loss 0.0094 (0.0067) lr 1.9921e-03 eta 0:18:34
epoch [4/50] batch [160/246] time 0.104 (0.097) data 0.000 (0.002) loss 1.2089 (1.2257) ce_loss 1.0859 (1.1303) teacher_loss 1.0861 (1.1305) loss_zs_kd 0.1701 (0.1283) loss_oracle 0.0377 (0.0311) acc 71.8750 (70.2930) kd_loss 0.0110 (0.0071) lr 1.9921e-03 eta 0:18:31
epoch [4/50] batch [180/246] time 0.099 (0.097) data 0.000 (0.002) loss 0.9904 (1.2313) ce_loss 0.9258 (1.1363) teacher_loss 0.9265 (1.1364) loss_zs_kd 0.0904 (0.1285) loss_oracle 0.0188 (0.0307) acc 75.0000 (70.0868) kd_loss 0.0112 (0.0075) lr 1.9921e-03 eta 0:18:26
epoch [4/50] batch [200/246] time 0.098 (0.097) data 0.000 (0.002) loss 1.6505 (1.2354) ce_loss 1.5508 (1.1418) teacher_loss 1.5492 (1.1418) loss_zs_kd 0.1604 (0.1281) loss_oracle 0.0211 (0.0295) acc 65.6250 (69.8906) kd_loss 0.0076 (0.0077) lr 1.9921e-03 eta 0:18:22
epoch [4/50] batch [220/246] time 0.097 (0.097) data 0.000 (0.001) loss 0.8474 (1.2273) ce_loss 0.7471 (1.1334) teacher_loss 0.7500 (1.1334) loss_zs_kd 0.1498 (0.1294) loss_oracle 0.0225 (0.0291) acc 78.1250 (70.0710) kd_loss 0.0069 (0.0077) lr 1.9921e-03 eta 0:18:18
epoch [4/50] batch [240/246] time 0.084 (0.097) data 0.000 (0.001) loss 1.2193 (1.2344) ce_loss 1.1426 (1.1399) teacher_loss 1.1412 (1.1399) loss_zs_kd 0.0770 (0.1298) loss_oracle 0.0395 (0.0296) acc 75.0000 (69.9870) kd_loss 0.0087 (0.0077) lr 1.9921e-03 eta 0:18:13
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,811
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.8%, epoch: 4 *******
******* Domain r best val test acc: 90.9%, epoch: 4 *******
******* Domain r best test acc:     90.9%, epoch: 4 *******
epoch [5/50] batch [20/246] time 0.096 (0.125) data 0.000 (0.020) loss 1.1567 (1.2113) ce_loss 1.0635 (1.1243) teacher_loss 1.0602 (1.1240) loss_zs_kd 0.1198 (0.1205) loss_oracle 0.0366 (0.0271) acc 68.7500 (72.0312) kd_loss 0.0082 (0.0088) lr 1.9823e-03 eta 0:23:35
epoch [5/50] batch [40/246] time 0.115 (0.115) data 0.000 (0.010) loss 1.7688 (1.2220) ce_loss 1.6680 (1.1381) teacher_loss 1.6696 (1.1379) loss_zs_kd 0.1443 (0.1162) loss_oracle 0.0271 (0.0259) acc 59.3750 (71.8750) kd_loss 0.0100 (0.0093) lr 1.9823e-03 eta 0:21:36
epoch [5/50] batch [60/246] time 0.119 (0.113) data 0.001 (0.007) loss 0.8557 (1.2264) ce_loss 0.7798 (1.1390) teacher_loss 0.7802 (1.1391) loss_zs_kd 0.1026 (0.1256) loss_oracle 0.0242 (0.0244) acc 78.1250 (70.9375) kd_loss 0.0071 (0.0092) lr 1.9823e-03 eta 0:21:11
epoch [5/50] batch [80/246] time 0.107 (0.114) data 0.001 (0.005) loss 1.1370 (1.2339) ce_loss 1.0537 (1.1474) teacher_loss 1.0504 (1.1476) loss_zs_kd 0.0933 (0.1226) loss_oracle 0.0399 (0.0250) acc 68.7500 (70.2734) kd_loss 0.0090 (0.0091) lr 1.9823e-03 eta 0:21:21
epoch [5/50] batch [100/246] time 0.102 (0.112) data 0.000 (0.004) loss 1.1825 (1.2419) ce_loss 1.0332 (1.1485) teacher_loss 1.0289 (1.1481) loss_zs_kd 0.2007 (0.1280) loss_oracle 0.0532 (0.0297) acc 65.6250 (69.9375) kd_loss 0.0155 (0.0093) lr 1.9823e-03 eta 0:20:50
epoch [5/50] batch [120/246] time 0.107 (0.110) data 0.000 (0.004) loss 0.9227 (1.2582) ce_loss 0.8354 (1.1649) teacher_loss 0.8348 (1.1646) loss_zs_kd 0.1229 (0.1281) loss_oracle 0.0264 (0.0296) acc 75.0000 (69.5833) kd_loss 0.0118 (0.0094) lr 1.9823e-03 eta 0:20:30
epoch [5/50] batch [140/246] time 0.111 (0.109) data 0.000 (0.003) loss 1.7494 (1.2594) ce_loss 1.6338 (1.1677) teacher_loss 1.6330 (1.1672) loss_zs_kd 0.1857 (0.1259) loss_oracle 0.0236 (0.0293) acc 65.6250 (69.7098) kd_loss 0.0068 (0.0094) lr 1.9823e-03 eta 0:20:14
epoch [5/50] batch [160/246] time 0.104 (0.108) data 0.000 (0.003) loss 1.4589 (1.2680) ce_loss 1.3311 (1.1724) teacher_loss 1.3316 (1.1720) loss_zs_kd 0.1124 (0.1282) loss_oracle 0.0711 (0.0319) acc 62.5000 (69.5312) kd_loss 0.0113 (0.0094) lr 1.9823e-03 eta 0:20:00
epoch [5/50] batch [180/246] time 0.109 (0.107) data 0.000 (0.002) loss 1.3623 (1.2686) ce_loss 1.2500 (1.1693) teacher_loss 1.2484 (1.1689) loss_zs_kd 0.1190 (0.1280) loss_oracle 0.0544 (0.0357) acc 65.6250 (69.4444) kd_loss 0.0088 (0.0095) lr 1.9823e-03 eta 0:19:51
epoch [5/50] batch [200/246] time 0.097 (0.106) data 0.000 (0.002) loss 1.2759 (1.2755) ce_loss 1.1299 (1.1754) teacher_loss 1.1194 (1.1749) loss_zs_kd 0.2061 (0.1287) loss_oracle 0.0535 (0.0363) acc 71.8750 (69.1875) kd_loss 0.0168 (0.0097) lr 1.9823e-03 eta 0:19:43
epoch [5/50] batch [220/246] time 0.102 (0.106) data 0.000 (0.002) loss 1.6281 (1.2714) ce_loss 1.4951 (1.1690) teacher_loss 1.4958 (1.1685) loss_zs_kd 0.1047 (0.1291) loss_oracle 0.0800 (0.0383) acc 62.5000 (69.1477) kd_loss 0.0110 (0.0099) lr 1.9823e-03 eta 0:19:32
epoch [5/50] batch [240/246] time 0.084 (0.105) data 0.000 (0.002) loss 1.2445 (1.2710) ce_loss 1.1504 (1.1675) teacher_loss 1.1513 (1.1670) loss_zs_kd 0.0964 (0.1286) loss_oracle 0.0451 (0.0396) acc 71.8750 (69.1406) kd_loss 0.0145 (0.0100) lr 1.9823e-03 eta 0:19:17
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,810
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.9%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      83.8%, epoch: 4 *******
******* Domain r best val test acc: 90.9%, epoch: 4 *******
******* Domain r best test acc:     90.9%, epoch: 4 *******
epoch [6/50] batch [20/246] time 0.095 (0.119) data 0.000 (0.015) loss 1.1628 (1.2796) ce_loss 1.0645 (1.1745) teacher_loss 1.0651 (1.1737) loss_zs_kd 0.1411 (0.1463) loss_oracle 0.0271 (0.0328) acc 78.1250 (71.8750) kd_loss 0.0128 (0.0121) lr 1.9686e-03 eta 0:21:50
epoch [6/50] batch [40/246] time 0.105 (0.110) data 0.000 (0.007) loss 1.4716 (1.2523) ce_loss 1.3545 (1.1484) teacher_loss 1.3551 (1.1477) loss_zs_kd 0.1461 (0.1430) loss_oracle 0.0435 (0.0330) acc 59.3750 (71.4062) kd_loss 0.0105 (0.0118) lr 1.9686e-03 eta 0:20:13
epoch [6/50] batch [60/246] time 0.109 (0.106) data 0.001 (0.005) loss 1.1970 (1.2388) ce_loss 1.1113 (1.1306) teacher_loss 1.1124 (1.1300) loss_zs_kd 0.0964 (0.1407) loss_oracle 0.0364 (0.0385) acc 78.1250 (71.6146) kd_loss 0.0094 (0.0118) lr 1.9686e-03 eta 0:19:29
epoch [6/50] batch [80/246] time 0.099 (0.105) data 0.000 (0.004) loss 1.2625 (1.2479) ce_loss 1.1475 (1.1401) teacher_loss 1.1466 (1.1396) loss_zs_kd 0.1399 (0.1367) loss_oracle 0.0459 (0.0399) acc 75.0000 (71.0547) kd_loss 0.0093 (0.0116) lr 1.9686e-03 eta 0:19:08
epoch [6/50] batch [100/246] time 0.096 (0.103) data 0.000 (0.003) loss 1.4782 (1.2429) ce_loss 1.3730 (1.1330) teacher_loss 1.3703 (1.1328) loss_zs_kd 0.1343 (0.1411) loss_oracle 0.0407 (0.0396) acc 62.5000 (70.7812) kd_loss 0.0089 (0.0113) lr 1.9686e-03 eta 0:18:55
epoch [6/50] batch [120/246] time 0.099 (0.103) data 0.000 (0.003) loss 1.0286 (1.2231) ce_loss 0.9185 (1.1125) teacher_loss 0.9190 (1.1124) loss_zs_kd 0.1626 (0.1443) loss_oracle 0.0283 (0.0385) acc 71.8750 (71.0417) kd_loss 0.0110 (0.0112) lr 1.9686e-03 eta 0:18:46
epoch [6/50] batch [140/246] time 0.100 (0.103) data 0.000 (0.002) loss 1.1611 (1.2294) ce_loss 1.0547 (1.1196) teacher_loss 1.0540 (1.1195) loss_zs_kd 0.1037 (0.1408) loss_oracle 0.0552 (0.0396) acc 68.7500 (70.8705) kd_loss 0.0076 (0.0110) lr 1.9686e-03 eta 0:18:44
epoch [6/50] batch [160/246] time 0.098 (0.103) data 0.000 (0.002) loss 1.2677 (1.2493) ce_loss 1.1465 (1.1380) teacher_loss 1.1472 (1.1379) loss_zs_kd 0.1263 (0.1416) loss_oracle 0.0574 (0.0406) acc 65.6250 (70.4492) kd_loss 0.0117 (0.0110) lr 1.9686e-03 eta 0:18:40
epoch [6/50] batch [180/246] time 0.097 (0.103) data 0.000 (0.002) loss 1.4576 (1.2467) ce_loss 1.3301 (1.1340) teacher_loss 1.3305 (1.1338) loss_zs_kd 0.1511 (0.1421) loss_oracle 0.0515 (0.0418) acc 65.6250 (70.5729) kd_loss 0.0125 (0.0112) lr 1.9686e-03 eta 0:18:39
epoch [6/50] batch [200/246] time 0.105 (0.103) data 0.000 (0.002) loss 1.1253 (1.2414) ce_loss 1.0303 (1.1284) teacher_loss 1.0301 (1.1281) loss_zs_kd 0.1143 (0.1415) loss_oracle 0.0380 (0.0425) acc 75.0000 (70.7812) kd_loss 0.0151 (0.0116) lr 1.9686e-03 eta 0:18:37
epoch [6/50] batch [220/246] time 0.097 (0.103) data 0.000 (0.002) loss 1.4862 (1.2425) ce_loss 1.3154 (1.1292) teacher_loss 1.3142 (1.1288) loss_zs_kd 0.2173 (0.1414) loss_oracle 0.0632 (0.0429) acc 68.7500 (70.6960) kd_loss 0.0232 (0.0121) lr 1.9686e-03 eta 0:18:34
epoch [6/50] batch [240/246] time 0.106 (0.103) data 0.000 (0.001) loss 1.2134 (1.2399) ce_loss 1.1250 (1.1265) teacher_loss 1.1239 (1.1261) loss_zs_kd 0.0903 (0.1407) loss_oracle 0.0443 (0.0435) acc 68.7500 (70.7292) kd_loss 0.0127 (0.0123) lr 1.9686e-03 eta 0:18:34
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,805
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
******* Domain r best val acc:      83.8%, epoch: 4 *******
******* Domain r best val test acc: 90.9%, epoch: 4 *******
******* Domain r best test acc:     90.9%, epoch: 4 *******
epoch [7/50] batch [20/246] time 0.090 (0.116) data 0.000 (0.013) loss 1.5790 (1.3735) ce_loss 1.4746 (1.2412) teacher_loss 1.4768 (1.2405) loss_zs_kd 0.1167 (0.1223) loss_oracle 0.0438 (0.0719) acc 53.1250 (66.8750) kd_loss 0.0112 (0.0151) lr 1.9511e-03 eta 0:20:49
epoch [7/50] batch [40/246] time 0.097 (0.107) data 0.000 (0.007) loss 0.8741 (1.2736) ce_loss 0.7715 (1.1483) teacher_loss 0.7632 (1.1478) loss_zs_kd 0.1282 (0.1349) loss_oracle 0.0468 (0.0583) acc 81.2500 (70.2344) kd_loss 0.0219 (0.0153) lr 1.9511e-03 eta 0:19:09
epoch [7/50] batch [60/246] time 0.094 (0.103) data 0.000 (0.005) loss 0.7462 (1.2616) ce_loss 0.6006 (1.1346) teacher_loss 0.6000 (1.1337) loss_zs_kd 0.1321 (0.1421) loss_oracle 0.0802 (0.0568) acc 84.3750 (70.0000) kd_loss 0.0134 (0.0155) lr 1.9511e-03 eta 0:18:31
epoch [7/50] batch [80/246] time 0.095 (0.102) data 0.000 (0.004) loss 1.1602 (1.2706) ce_loss 1.0488 (1.1382) teacher_loss 1.0498 (1.1373) loss_zs_kd 0.0958 (0.1412) loss_oracle 0.0624 (0.0627) acc 68.7500 (69.8047) kd_loss 0.0119 (0.0155) lr 1.9511e-03 eta 0:18:12
epoch [7/50] batch [100/246] time 0.099 (0.101) data 0.000 (0.003) loss 1.1062 (1.2749) ce_loss 0.9731 (1.1398) teacher_loss 0.9733 (1.1386) loss_zs_kd 0.1307 (0.1432) loss_oracle 0.0675 (0.0647) acc 71.8750 (69.8750) kd_loss 0.0189 (0.0160) lr 1.9511e-03 eta 0:18:03
epoch [7/50] batch [120/246] time 0.096 (0.100) data 0.000 (0.002) loss 0.7814 (1.2463) ce_loss 0.6548 (1.1152) teacher_loss 0.6570 (1.1142) loss_zs_kd 0.1518 (0.1405) loss_oracle 0.0485 (0.0619) acc 87.5000 (70.7292) kd_loss 0.0174 (0.0161) lr 1.9511e-03 eta 0:17:52
epoch [7/50] batch [140/246] time 0.101 (0.100) data 0.000 (0.002) loss 0.6232 (1.2408) ce_loss 0.5215 (1.1118) teacher_loss 0.5245 (1.1112) loss_zs_kd 0.0859 (0.1411) loss_oracle 0.0557 (0.0590) acc 84.3750 (70.8036) kd_loss 0.0122 (0.0161) lr 1.9511e-03 eta 0:17:46
epoch [7/50] batch [160/246] time 0.094 (0.099) data 0.000 (0.002) loss 1.5918 (1.2610) ce_loss 1.3848 (1.1295) teacher_loss 1.3824 (1.1290) loss_zs_kd 0.2188 (0.1430) loss_oracle 0.1000 (0.0605) acc 62.5000 (70.3516) kd_loss 0.0207 (0.0163) lr 1.9511e-03 eta 0:17:40
epoch [7/50] batch [180/246] time 0.099 (0.099) data 0.000 (0.002) loss 1.5235 (1.2658) ce_loss 1.3496 (1.1304) teacher_loss 1.3528 (1.1299) loss_zs_kd 0.1765 (0.1426) loss_oracle 0.0824 (0.0646) acc 62.5000 (70.1736) kd_loss 0.0156 (0.0166) lr 1.9511e-03 eta 0:17:35
epoch [7/50] batch [200/246] time 0.096 (0.099) data 0.000 (0.002) loss 0.8607 (1.2613) ce_loss 0.7178 (1.1265) teacher_loss 0.7191 (1.1260) loss_zs_kd 0.1592 (0.1412) loss_oracle 0.0620 (0.0647) acc 75.0000 (70.2344) kd_loss 0.0147 (0.0169) lr 1.9511e-03 eta 0:17:30
epoch [7/50] batch [220/246] time 0.102 (0.099) data 0.000 (0.001) loss 1.6034 (1.2584) ce_loss 1.4531 (1.1246) teacher_loss 1.4542 (1.1240) loss_zs_kd 0.1279 (0.1394) loss_oracle 0.0852 (0.0646) acc 65.6250 (70.2273) kd_loss 0.0200 (0.0170) lr 1.9511e-03 eta 0:17:27
epoch [7/50] batch [240/246] time 0.087 (0.098) data 0.000 (0.001) loss 1.1262 (1.2575) ce_loss 0.9771 (1.1223) teacher_loss 0.9802 (1.1217) loss_zs_kd 0.1352 (0.1405) loss_oracle 0.0784 (0.0655) acc 81.2500 (70.1953) kd_loss 0.0195 (0.0171) lr 1.9511e-03 eta 0:17:18
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,814
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      83.9%, epoch: 7 *******
******* Domain r best val test acc: 90.9%, epoch: 7 *******
******* Domain r best test acc:     90.9%, epoch: 4 *******
epoch [8/50] batch [20/246] time 0.107 (0.116) data 0.000 (0.014) loss 1.3880 (1.2612) ce_loss 1.2451 (1.1358) teacher_loss 1.2453 (1.1366) loss_zs_kd 0.1618 (0.1411) loss_oracle 0.0618 (0.0541) acc 68.7500 (70.1562) kd_loss 0.0227 (0.0187) lr 1.9298e-03 eta 0:20:19
epoch [8/50] batch [40/246] time 0.092 (0.107) data 0.000 (0.007) loss 1.4305 (1.2723) ce_loss 1.3047 (1.1497) teacher_loss 1.2968 (1.1495) loss_zs_kd 0.1340 (0.1382) loss_oracle 0.0666 (0.0537) acc 62.5000 (69.7656) kd_loss 0.0206 (0.0189) lr 1.9298e-03 eta 0:18:50
epoch [8/50] batch [60/246] time 0.101 (0.103) data 0.000 (0.005) loss 1.5880 (1.2582) ce_loss 1.4404 (1.1299) teacher_loss 1.4359 (1.1291) loss_zs_kd 0.1715 (0.1413) loss_oracle 0.0663 (0.0585) acc 62.5000 (70.2083) kd_loss 0.0251 (0.0194) lr 1.9298e-03 eta 0:18:01
epoch [8/50] batch [80/246] time 0.090 (0.101) data 0.000 (0.004) loss 0.7807 (1.2514) ce_loss 0.6792 (1.1209) teacher_loss 0.6815 (1.1199) loss_zs_kd 0.0840 (0.1408) loss_oracle 0.0573 (0.0610) acc 84.3750 (70.6641) kd_loss 0.0182 (0.0198) lr 1.9298e-03 eta 0:17:40
epoch [8/50] batch [100/246] time 0.097 (0.100) data 0.000 (0.003) loss 1.2650 (1.2723) ce_loss 1.0723 (1.1381) teacher_loss 1.0684 (1.1370) loss_zs_kd 0.2017 (0.1405) loss_oracle 0.0957 (0.0650) acc 81.2500 (70.2188) kd_loss 0.0287 (0.0199) lr 1.9298e-03 eta 0:17:23
epoch [8/50] batch [120/246] time 0.092 (0.099) data 0.000 (0.003) loss 1.6647 (1.2699) ce_loss 1.4971 (1.1310) teacher_loss 1.4999 (1.1299) loss_zs_kd 0.1697 (0.1420) loss_oracle 0.0799 (0.0689) acc 62.5000 (70.6510) kd_loss 0.0194 (0.0202) lr 1.9298e-03 eta 0:17:12
epoch [8/50] batch [140/246] time 0.089 (0.098) data 0.000 (0.002) loss 1.2640 (1.2790) ce_loss 1.1367 (1.1382) teacher_loss 1.1417 (1.1374) loss_zs_kd 0.1187 (0.1442) loss_oracle 0.0628 (0.0695) acc 68.7500 (70.5357) kd_loss 0.0291 (0.0202) lr 1.9298e-03 eta 0:17:04
epoch [8/50] batch [160/246] time 0.089 (0.097) data 0.000 (0.002) loss 1.5261 (1.2772) ce_loss 1.3984 (1.1399) teacher_loss 1.3948 (1.1390) loss_zs_kd 0.1639 (0.1436) loss_oracle 0.0493 (0.0664) acc 59.3750 (70.5469) kd_loss 0.0219 (0.0201) lr 1.9298e-03 eta 0:16:54
epoch [8/50] batch [180/246] time 0.092 (0.097) data 0.000 (0.002) loss 1.5191 (1.2671) ce_loss 1.4121 (1.1334) teacher_loss 1.4104 (1.1327) loss_zs_kd 0.1323 (0.1421) loss_oracle 0.0426 (0.0634) acc 65.6250 (70.5208) kd_loss 0.0164 (0.0198) lr 1.9298e-03 eta 0:16:43
epoch [8/50] batch [200/246] time 0.094 (0.096) data 0.000 (0.002) loss 1.1352 (1.2674) ce_loss 1.0215 (1.1362) teacher_loss 1.0062 (1.1354) loss_zs_kd 0.1697 (0.1421) loss_oracle 0.0442 (0.0610) acc 75.0000 (70.5000) kd_loss 0.0223 (0.0196) lr 1.9298e-03 eta 0:16:35
epoch [8/50] batch [220/246] time 0.089 (0.096) data 0.000 (0.001) loss 1.2559 (1.2676) ce_loss 1.1572 (1.1373) teacher_loss 1.1565 (1.1365) loss_zs_kd 0.0915 (0.1433) loss_oracle 0.0536 (0.0595) acc 71.8750 (70.4119) kd_loss 0.0152 (0.0193) lr 1.9298e-03 eta 0:16:31
epoch [8/50] batch [240/246] time 0.085 (0.095) data 0.000 (0.001) loss 1.0082 (1.2671) ce_loss 0.8545 (1.1375) teacher_loss 0.8561 (1.1367) loss_zs_kd 0.1736 (0.1438) loss_oracle 0.0653 (0.0585) acc 78.1250 (70.3646) kd_loss 0.0162 (0.0189) lr 1.9298e-03 eta 0:16:25
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,828
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.4%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,970
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.1%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.3%, epoch: 8 *******
******* Domain r best val test acc: 91.1%, epoch: 8 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [9/50] batch [20/246] time 0.097 (0.117) data 0.000 (0.014) loss 0.9421 (1.2605) ce_loss 0.7935 (1.1383) teacher_loss 0.7914 (1.1365) loss_zs_kd 0.1596 (0.1377) loss_oracle 0.0709 (0.0551) acc 78.1250 (71.0938) kd_loss 0.0170 (0.0146) lr 1.9048e-03 eta 0:20:02
epoch [9/50] batch [40/246] time 0.092 (0.106) data 0.000 (0.007) loss 1.5186 (1.2959) ce_loss 1.3809 (1.1611) teacher_loss 1.3786 (1.1591) loss_zs_kd 0.1042 (0.1411) loss_oracle 0.0879 (0.0662) acc 68.7500 (69.7656) kd_loss 0.0111 (0.0147) lr 1.9048e-03 eta 0:18:13
epoch [9/50] batch [60/246] time 0.094 (0.102) data 0.000 (0.005) loss 1.5631 (1.3200) ce_loss 1.3457 (1.1704) teacher_loss 1.3420 (1.1686) loss_zs_kd 0.2102 (0.1443) loss_oracle 0.1160 (0.0793) acc 75.0000 (70.0521) kd_loss 0.0193 (0.0151) lr 1.9048e-03 eta 0:17:25
epoch [9/50] batch [80/246] time 0.097 (0.100) data 0.000 (0.004) loss 1.4089 (1.3203) ce_loss 1.2666 (1.1697) teacher_loss 1.2667 (1.1683) loss_zs_kd 0.1761 (0.1465) loss_oracle 0.0541 (0.0788) acc 56.2500 (69.8438) kd_loss 0.0186 (0.0157) lr 1.9048e-03 eta 0:17:08
epoch [9/50] batch [100/246] time 0.094 (0.099) data 0.000 (0.003) loss 0.8701 (1.2936) ce_loss 0.7734 (1.1506) teacher_loss 0.7702 (1.1491) loss_zs_kd 0.0840 (0.1423) loss_oracle 0.0579 (0.0734) acc 81.2500 (70.1562) kd_loss 0.0201 (0.0161) lr 1.9048e-03 eta 0:16:57
epoch [9/50] batch [120/246] time 0.094 (0.099) data 0.000 (0.003) loss 1.2695 (1.3182) ce_loss 1.1621 (1.1760) teacher_loss 1.1675 (1.1747) loss_zs_kd 0.1047 (0.1450) loss_oracle 0.0497 (0.0710) acc 68.7500 (69.4271) kd_loss 0.0105 (0.0162) lr 1.9048e-03 eta 0:16:47
epoch [9/50] batch [140/246] time 0.089 (0.098) data 0.000 (0.002) loss 1.5257 (1.3210) ce_loss 1.4131 (1.1812) teacher_loss 1.4142 (1.1797) loss_zs_kd 0.1152 (0.1436) loss_oracle 0.0539 (0.0695) acc 65.6250 (69.1295) kd_loss 0.0158 (0.0162) lr 1.9048e-03 eta 0:16:43
epoch [9/50] batch [160/246] time 0.094 (0.098) data 0.000 (0.002) loss 1.2054 (1.3161) ce_loss 1.0654 (1.1778) teacher_loss 1.0653 (1.1765) loss_zs_kd 0.1319 (0.1409) loss_oracle 0.0741 (0.0691) acc 71.8750 (69.2578) kd_loss 0.0107 (0.0161) lr 1.9048e-03 eta 0:16:38
epoch [9/50] batch [180/246] time 0.097 (0.098) data 0.000 (0.002) loss 1.1710 (1.3135) ce_loss 1.0342 (1.1724) teacher_loss 1.0380 (1.1712) loss_zs_kd 0.1198 (0.1408) loss_oracle 0.0731 (0.0719) acc 71.8750 (69.4444) kd_loss 0.0127 (0.0161) lr 1.9048e-03 eta 0:16:34
epoch [9/50] batch [200/246] time 0.097 (0.098) data 0.000 (0.002) loss 1.2975 (1.3126) ce_loss 1.1602 (1.1720) teacher_loss 1.1602 (1.1707) loss_zs_kd 0.1642 (0.1395) loss_oracle 0.0552 (0.0722) acc 65.6250 (69.4062) kd_loss 0.0197 (0.0161) lr 1.9048e-03 eta 0:16:28
epoch [9/50] batch [220/246] time 0.095 (0.097) data 0.000 (0.001) loss 1.1128 (1.3071) ce_loss 0.9800 (1.1669) teacher_loss 0.9803 (1.1656) loss_zs_kd 0.1510 (0.1405) loss_oracle 0.0570 (0.0713) acc 78.1250 (69.5739) kd_loss 0.0093 (0.0160) lr 1.9048e-03 eta 0:16:25
epoch [9/50] batch [240/246] time 0.085 (0.097) data 0.000 (0.001) loss 1.1966 (1.3100) ce_loss 1.0234 (1.1676) teacher_loss 1.0229 (1.1660) loss_zs_kd 0.1565 (0.1413) loss_oracle 0.0955 (0.0734) acc 81.2500 (69.5443) kd_loss 0.0226 (0.0162) lr 1.9048e-03 eta 0:16:17
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,825
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,968
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.0%
******* Domain r best val acc:      84.3%, epoch: 8 *******
******* Domain r best val test acc: 91.1%, epoch: 8 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [10/50] batch [20/246] time 0.139 (0.142) data 0.000 (0.013) loss 1.2121 (1.3171) ce_loss 1.0908 (1.1755) teacher_loss 1.0902 (1.1762) loss_zs_kd 0.1005 (0.1588) loss_oracle 0.0716 (0.0615) acc 65.6250 (69.3750) kd_loss 0.0185 (0.0143) lr 1.8763e-03 eta 0:23:52
epoch [10/50] batch [40/246] time 0.134 (0.135) data 0.000 (0.007) loss 1.5802 (1.3073) ce_loss 1.4189 (1.1633) teacher_loss 1.4085 (1.1615) loss_zs_kd 0.1418 (0.1524) loss_oracle 0.1008 (0.0696) acc 65.6250 (68.9844) kd_loss 0.0238 (0.0166) lr 1.8763e-03 eta 0:22:32
epoch [10/50] batch [60/246] time 0.134 (0.133) data 0.001 (0.004) loss 1.0733 (1.2715) ce_loss 0.9238 (1.1233) teacher_loss 0.9223 (1.1216) loss_zs_kd 0.1300 (0.1502) loss_oracle 0.0860 (0.0748) acc 71.8750 (69.8438) kd_loss 0.0184 (0.0171) lr 1.8763e-03 eta 0:22:14
epoch [10/50] batch [80/246] time 0.129 (0.131) data 0.000 (0.003) loss 1.4578 (1.2745) ce_loss 1.2969 (1.1218) teacher_loss 1.2874 (1.1198) loss_zs_kd 0.1931 (0.1485) loss_oracle 0.0738 (0.0805) acc 59.3750 (69.9219) kd_loss 0.0202 (0.0177) lr 1.8763e-03 eta 0:21:51
epoch [10/50] batch [100/246] time 0.121 (0.130) data 0.000 (0.003) loss 1.4592 (1.2781) ce_loss 1.3506 (1.1302) teacher_loss 1.3503 (1.1281) loss_zs_kd 0.1371 (0.1482) loss_oracle 0.0404 (0.0760) acc 68.7500 (69.8438) kd_loss 0.0161 (0.0177) lr 1.8763e-03 eta 0:21:33
epoch [10/50] batch [120/246] time 0.130 (0.128) data 0.000 (0.002) loss 1.9517 (1.2947) ce_loss 1.7959 (1.1480) teacher_loss 1.7817 (1.1459) loss_zs_kd 0.1358 (0.1496) loss_oracle 0.1021 (0.0740) acc 62.5000 (69.6615) kd_loss 0.0174 (0.0176) lr 1.8763e-03 eta 0:21:19
epoch [10/50] batch [140/246] time 0.126 (0.128) data 0.001 (0.002) loss 0.9248 (1.3046) ce_loss 0.7617 (1.1541) teacher_loss 0.7731 (1.1524) loss_zs_kd 0.1177 (0.1477) loss_oracle 0.0928 (0.0784) acc 81.2500 (69.2857) kd_loss 0.0171 (0.0177) lr 1.8763e-03 eta 0:21:10
epoch [10/50] batch [160/246] time 0.123 (0.127) data 0.000 (0.002) loss 1.4004 (1.3053) ce_loss 1.2793 (1.1558) teacher_loss 1.2787 (1.1543) loss_zs_kd 0.1487 (0.1474) loss_oracle 0.0473 (0.0773) acc 71.8750 (69.2578) kd_loss 0.0163 (0.0179) lr 1.8763e-03 eta 0:21:04
epoch [10/50] batch [180/246] time 0.121 (0.127) data 0.000 (0.002) loss 1.0294 (1.3082) ce_loss 0.9341 (1.1604) teacher_loss 0.9340 (1.1592) loss_zs_kd 0.0708 (0.1469) loss_oracle 0.0599 (0.0755) acc 78.1250 (69.2014) kd_loss 0.0188 (0.0178) lr 1.8763e-03 eta 0:20:59
epoch [10/50] batch [200/246] time 0.121 (0.126) data 0.000 (0.002) loss 1.2261 (1.3067) ce_loss 1.1025 (1.1591) teacher_loss 1.1005 (1.1579) loss_zs_kd 0.1232 (0.1448) loss_oracle 0.0640 (0.0764) acc 75.0000 (69.3906) kd_loss 0.0164 (0.0179) lr 1.8763e-03 eta 0:20:50
epoch [10/50] batch [220/246] time 0.119 (0.126) data 0.000 (0.002) loss 1.5907 (1.2984) ce_loss 1.3857 (1.1522) teacher_loss 1.3850 (1.1508) loss_zs_kd 0.2646 (0.1437) loss_oracle 0.0733 (0.0757) acc 59.3750 (69.5312) kd_loss 0.0216 (0.0178) lr 1.8763e-03 eta 0:20:41
epoch [10/50] batch [240/246] time 0.106 (0.125) data 0.000 (0.001) loss 0.8052 (1.2958) ce_loss 0.6523 (1.1483) teacher_loss 0.6291 (1.1468) loss_zs_kd 0.1270 (0.1448) loss_oracle 0.1126 (0.0767) acc 81.2500 (69.6094) kd_loss 0.0240 (0.0178) lr 1.8763e-03 eta 0:20:27
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,829
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.4%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,950
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.4%
******* Domain r best val acc:      84.3%, epoch: 10 *******
******* Domain r best val test acc: 90.7%, epoch: 10 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [11/50] batch [20/246] time 0.095 (0.114) data 0.001 (0.014) loss 0.9786 (1.3029) ce_loss 0.7598 (1.1429) teacher_loss 0.7568 (1.1399) loss_zs_kd 0.2748 (0.1558) loss_oracle 0.0843 (0.0851) acc 84.3750 (70.4688) kd_loss 0.0194 (0.0183) lr 1.8443e-03 eta 0:18:38
epoch [11/50] batch [40/246] time 0.090 (0.106) data 0.000 (0.007) loss 1.2816 (1.2795) ce_loss 1.1338 (1.1225) teacher_loss 1.1258 (1.1191) loss_zs_kd 0.1480 (0.1523) loss_oracle 0.0818 (0.0842) acc 71.8750 (71.1719) kd_loss 0.0167 (0.0181) lr 1.8443e-03 eta 0:17:22
epoch [11/50] batch [60/246] time 0.099 (0.102) data 0.000 (0.005) loss 1.2388 (1.2713) ce_loss 1.0898 (1.1226) teacher_loss 1.0879 (1.1180) loss_zs_kd 0.1980 (0.1547) loss_oracle 0.0519 (0.0760) acc 65.6250 (70.2083) kd_loss 0.0188 (0.0188) lr 1.8443e-03 eta 0:16:38
epoch [11/50] batch [80/246] time 0.097 (0.101) data 0.000 (0.004) loss 1.1035 (1.2658) ce_loss 0.9746 (1.1172) teacher_loss 0.9783 (1.1133) loss_zs_kd 0.1383 (0.1545) loss_oracle 0.0561 (0.0754) acc 81.2500 (70.4297) kd_loss 0.0135 (0.0181) lr 1.8443e-03 eta 0:16:22
epoch [11/50] batch [100/246] time 0.090 (0.100) data 0.000 (0.003) loss 1.3671 (1.2811) ce_loss 1.2256 (1.1302) teacher_loss 1.2296 (1.1264) loss_zs_kd 0.1464 (0.1553) loss_oracle 0.0643 (0.0770) acc 68.7500 (70.0312) kd_loss 0.0151 (0.0183) lr 1.8443e-03 eta 0:16:14
epoch [11/50] batch [120/246] time 0.090 (0.099) data 0.000 (0.003) loss 0.8962 (1.2599) ce_loss 0.7954 (1.1154) teacher_loss 0.7948 (1.1114) loss_zs_kd 0.1249 (0.1528) loss_oracle 0.0389 (0.0722) acc 78.1250 (70.3906) kd_loss 0.0154 (0.0181) lr 1.8443e-03 eta 0:16:06
epoch [11/50] batch [140/246] time 0.108 (0.099) data 0.000 (0.002) loss 1.2370 (1.2637) ce_loss 1.1045 (1.1205) teacher_loss 1.1067 (1.1165) loss_zs_kd 0.1398 (0.1531) loss_oracle 0.0604 (0.0707) acc 78.1250 (70.4018) kd_loss 0.0101 (0.0178) lr 1.8443e-03 eta 0:16:02
epoch [11/50] batch [160/246] time 0.098 (0.100) data 0.000 (0.002) loss 1.5316 (1.2627) ce_loss 1.4023 (1.1191) teacher_loss 1.3813 (1.1152) loss_zs_kd 0.1252 (0.1529) loss_oracle 0.0878 (0.0710) acc 59.3750 (70.3125) kd_loss 0.0201 (0.0177) lr 1.8443e-03 eta 0:16:04
epoch [11/50] batch [180/246] time 0.100 (0.100) data 0.000 (0.002) loss 1.1177 (1.2519) ce_loss 0.9819 (1.1085) teacher_loss 0.9757 (1.1049) loss_zs_kd 0.1330 (0.1531) loss_oracle 0.0755 (0.0704) acc 65.6250 (70.5729) kd_loss 0.0192 (0.0177) lr 1.8443e-03 eta 0:16:06
epoch [11/50] batch [200/246] time 0.100 (0.100) data 0.000 (0.002) loss 1.1309 (1.2521) ce_loss 1.0352 (1.1096) teacher_loss 1.0362 (1.1064) loss_zs_kd 0.0715 (0.1519) loss_oracle 0.0589 (0.0698) acc 71.8750 (70.7344) kd_loss 0.0100 (0.0177) lr 1.8443e-03 eta 0:16:07
epoch [11/50] batch [220/246] time 0.147 (0.101) data 0.000 (0.002) loss 1.2534 (1.2404) ce_loss 1.1123 (1.0994) teacher_loss 1.1108 (1.0964) loss_zs_kd 0.1490 (0.1513) loss_oracle 0.0681 (0.0683) acc 68.7500 (71.0511) kd_loss 0.0268 (0.0177) lr 1.8443e-03 eta 0:16:15
epoch [11/50] batch [240/246] time 0.103 (0.102) data 0.000 (0.001) loss 0.9906 (1.2488) ce_loss 0.8486 (1.1066) teacher_loss 0.8459 (1.1038) loss_zs_kd 0.1308 (0.1521) loss_oracle 0.0793 (0.0689) acc 81.2500 (70.9245) kd_loss 0.0167 (0.0176) lr 1.8443e-03 eta 0:16:19
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,823
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      84.3%, epoch: 10 *******
******* Domain r best val test acc: 90.7%, epoch: 10 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [12/50] batch [20/246] time 0.126 (0.139) data 0.001 (0.015) loss 1.1657 (1.2161) ce_loss 1.0078 (1.0457) teacher_loss 1.0099 (1.0434) loss_zs_kd 0.1228 (0.1525) loss_oracle 0.0944 (0.0965) acc 65.6250 (72.5000) kd_loss 0.0186 (0.0192) lr 1.8090e-03 eta 0:22:11
epoch [12/50] batch [40/246] time 0.131 (0.134) data 0.000 (0.008) loss 1.8186 (1.2603) ce_loss 1.6631 (1.0907) teacher_loss 1.6681 (1.0880) loss_zs_kd 0.1560 (0.1507) loss_oracle 0.0724 (0.0970) acc 59.3750 (70.8594) kd_loss 0.0116 (0.0195) lr 1.8090e-03 eta 0:21:22
epoch [12/50] batch [60/246] time 0.124 (0.132) data 0.001 (0.005) loss 1.7065 (1.2728) ce_loss 1.5830 (1.1119) teacher_loss 1.5630 (1.1090) loss_zs_kd 0.1421 (0.1519) loss_oracle 0.0725 (0.0879) acc 59.3750 (70.4167) kd_loss 0.0225 (0.0191) lr 1.8090e-03 eta 0:20:58
epoch [12/50] batch [80/246] time 0.122 (0.131) data 0.000 (0.004) loss 1.0849 (1.2722) ce_loss 0.9688 (1.1181) teacher_loss 0.9729 (1.1159) loss_zs_kd 0.1216 (0.1527) loss_oracle 0.0512 (0.0799) acc 65.6250 (70.1953) kd_loss 0.0116 (0.0185) lr 1.8090e-03 eta 0:20:47
epoch [12/50] batch [100/246] time 0.131 (0.131) data 0.000 (0.003) loss 1.5110 (1.2419) ce_loss 1.3525 (1.0939) teacher_loss 1.3472 (1.0918) loss_zs_kd 0.1932 (0.1515) loss_oracle 0.0672 (0.0744) acc 62.5000 (70.9062) kd_loss 0.0225 (0.0181) lr 1.8090e-03 eta 0:20:40
epoch [12/50] batch [120/246] time 0.124 (0.130) data 0.000 (0.003) loss 0.7801 (1.2262) ce_loss 0.6729 (1.0810) teacher_loss 0.6716 (1.0792) loss_zs_kd 0.1101 (0.1537) loss_oracle 0.0535 (0.0701) acc 87.5000 (71.3542) kd_loss 0.0228 (0.0178) lr 1.8090e-03 eta 0:20:32
epoch [12/50] batch [140/246] time 0.126 (0.129) data 0.000 (0.003) loss 1.3991 (1.2327) ce_loss 1.2998 (1.0931) teacher_loss 1.3028 (1.0916) loss_zs_kd 0.1065 (0.1503) loss_oracle 0.0430 (0.0660) acc 71.8750 (71.1161) kd_loss 0.0178 (0.0179) lr 1.8090e-03 eta 0:20:22
epoch [12/50] batch [160/246] time 0.123 (0.129) data 0.000 (0.002) loss 1.5046 (1.2347) ce_loss 1.3936 (1.0996) teacher_loss 1.3983 (1.0981) loss_zs_kd 0.1514 (0.1477) loss_oracle 0.0306 (0.0628) acc 65.6250 (70.8203) kd_loss 0.0126 (0.0178) lr 1.8090e-03 eta 0:20:13
epoch [12/50] batch [180/246] time 0.131 (0.128) data 0.001 (0.002) loss 0.9443 (1.2409) ce_loss 0.8174 (1.1065) teacher_loss 0.8168 (1.1050) loss_zs_kd 0.1618 (0.1495) loss_oracle 0.0467 (0.0611) acc 81.2500 (70.8681) kd_loss 0.0255 (0.0178) lr 1.8090e-03 eta 0:20:07
epoch [12/50] batch [200/246] time 0.094 (0.126) data 0.000 (0.002) loss 1.2378 (1.2350) ce_loss 1.0215 (1.1002) teacher_loss 1.0207 (1.0988) loss_zs_kd 0.2459 (0.1504) loss_oracle 0.0942 (0.0609) acc 71.8750 (70.9531) kd_loss 0.0164 (0.0178) lr 1.8090e-03 eta 0:19:46
epoch [12/50] batch [220/246] time 0.111 (0.124) data 0.000 (0.002) loss 1.0434 (1.2383) ce_loss 0.8975 (1.1034) teacher_loss 0.8991 (1.1021) loss_zs_kd 0.1504 (0.1511) loss_oracle 0.0692 (0.0607) acc 78.1250 (70.8949) kd_loss 0.0222 (0.0178) lr 1.8090e-03 eta 0:19:20
epoch [12/50] batch [240/246] time 0.100 (0.122) data 0.000 (0.002) loss 1.0865 (1.2460) ce_loss 0.9478 (1.1104) teacher_loss 0.9479 (1.1092) loss_zs_kd 0.1101 (0.1521) loss_oracle 0.0835 (0.0607) acc 75.0000 (70.6901) kd_loss 0.0141 (0.0176) lr 1.8090e-03 eta 0:19:00
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,817
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,941
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.3%
******* Domain r best val acc:      84.3%, epoch: 10 *******
******* Domain r best val test acc: 90.7%, epoch: 10 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [13/50] batch [20/246] time 0.127 (0.137) data 0.000 (0.013) loss 1.1525 (1.2533) ce_loss 0.9761 (1.0919) teacher_loss 0.9739 (1.0916) loss_zs_kd 0.1607 (0.1532) loss_oracle 0.0982 (0.0851) acc 78.1250 (70.4688) kd_loss 0.0213 (0.0181) lr 1.7705e-03 eta 0:21:22
epoch [13/50] batch [40/246] time 0.124 (0.134) data 0.000 (0.007) loss 1.3053 (1.2406) ce_loss 1.1562 (1.0876) teacher_loss 1.1582 (1.0870) loss_zs_kd 0.1215 (0.1492) loss_oracle 0.0863 (0.0790) acc 71.8750 (71.0156) kd_loss 0.0134 (0.0188) lr 1.7705e-03 eta 0:20:42
epoch [13/50] batch [60/246] time 0.126 (0.132) data 0.001 (0.005) loss 1.6848 (1.2478) ce_loss 1.5215 (1.0993) teacher_loss 1.5202 (1.0984) loss_zs_kd 0.1292 (0.1473) loss_oracle 0.1000 (0.0758) acc 62.5000 (70.7292) kd_loss 0.0207 (0.0189) lr 1.7705e-03 eta 0:20:27
epoch [13/50] batch [80/246] time 0.128 (0.131) data 0.000 (0.004) loss 1.1674 (1.2477) ce_loss 1.0156 (1.0952) teacher_loss 1.0154 (1.0943) loss_zs_kd 0.1544 (0.1492) loss_oracle 0.0748 (0.0787) acc 71.8750 (70.9766) kd_loss 0.0153 (0.0190) lr 1.7705e-03 eta 0:20:10
epoch [13/50] batch [100/246] time 0.136 (0.131) data 0.000 (0.003) loss 1.0153 (1.2503) ce_loss 0.7974 (1.0933) teacher_loss 0.7957 (1.0921) loss_zs_kd 0.2183 (0.1526) loss_oracle 0.1105 (0.0819) acc 87.5000 (71.2812) kd_loss 0.0259 (0.0192) lr 1.7705e-03 eta 0:20:06
epoch [13/50] batch [120/246] time 0.133 (0.130) data 0.000 (0.002) loss 0.7777 (1.2364) ce_loss 0.6074 (1.0807) teacher_loss 0.6122 (1.0798) loss_zs_kd 0.1613 (0.1509) loss_oracle 0.0849 (0.0812) acc 84.3750 (71.5104) kd_loss 0.0161 (0.0195) lr 1.7705e-03 eta 0:20:03
epoch [13/50] batch [140/246] time 0.123 (0.130) data 0.000 (0.002) loss 1.3356 (1.2465) ce_loss 1.1699 (1.0888) teacher_loss 1.1639 (1.0876) loss_zs_kd 0.1385 (0.1513) loss_oracle 0.1025 (0.0833) acc 71.8750 (71.2723) kd_loss 0.0183 (0.0198) lr 1.7705e-03 eta 0:19:59
epoch [13/50] batch [160/246] time 0.127 (0.130) data 0.000 (0.002) loss 1.8658 (1.2648) ce_loss 1.6318 (1.1037) teacher_loss 1.6324 (1.1024) loss_zs_kd 0.2300 (0.1525) loss_oracle 0.1184 (0.0862) acc 56.2500 (70.8398) kd_loss 0.0231 (0.0199) lr 1.7705e-03 eta 0:19:54
epoch [13/50] batch [180/246] time 0.134 (0.130) data 0.000 (0.002) loss 1.9165 (1.2683) ce_loss 1.7773 (1.1048) teacher_loss 1.7754 (1.1033) loss_zs_kd 0.1187 (0.1520) loss_oracle 0.0818 (0.0890) acc 50.0000 (70.7292) kd_loss 0.0215 (0.0203) lr 1.7705e-03 eta 0:19:51
epoch [13/50] batch [200/246] time 0.131 (0.130) data 0.000 (0.002) loss 1.5073 (1.2735) ce_loss 1.3262 (1.1104) teacher_loss 1.3240 (1.1088) loss_zs_kd 0.2227 (0.1546) loss_oracle 0.0720 (0.0874) acc 65.6250 (70.7812) kd_loss 0.0160 (0.0203) lr 1.7705e-03 eta 0:19:46
epoch [13/50] batch [220/246] time 0.098 (0.129) data 0.000 (0.002) loss 1.1352 (1.2609) ce_loss 0.9512 (1.0970) teacher_loss 0.9502 (1.0955) loss_zs_kd 0.1694 (0.1548) loss_oracle 0.1003 (0.0880) acc 78.1250 (71.0795) kd_loss 0.0222 (0.0203) lr 1.7705e-03 eta 0:19:35
epoch [13/50] batch [240/246] time 0.111 (0.127) data 0.000 (0.001) loss 1.2099 (1.2551) ce_loss 1.0430 (1.0923) teacher_loss 1.0469 (1.0907) loss_zs_kd 0.1822 (0.1536) loss_oracle 0.0719 (0.0877) acc 75.0000 (71.2240) kd_loss 0.0186 (0.0202) lr 1.7705e-03 eta 0:19:15
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,834
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.6%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,950
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      84.5%, epoch: 13 *******
******* Domain r best val test acc: 90.7%, epoch: 13 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [14/50] batch [20/246] time 0.093 (0.119) data 0.000 (0.015) loss 0.7346 (1.2642) ce_loss 0.6362 (1.1210) teacher_loss 0.6359 (1.1193) loss_zs_kd 0.1027 (0.1581) loss_oracle 0.0474 (0.0659) acc 81.2500 (69.0625) kd_loss 0.0178 (0.0200) lr 1.7290e-03 eta 0:18:02
epoch [14/50] batch [40/246] time 0.094 (0.109) data 0.000 (0.007) loss 1.6406 (1.2005) ce_loss 1.5166 (1.0700) teacher_loss 1.5157 (1.0680) loss_zs_kd 0.1474 (0.1521) loss_oracle 0.0512 (0.0564) acc 68.7500 (71.5625) kd_loss 0.0280 (0.0211) lr 1.7290e-03 eta 0:16:29
epoch [14/50] batch [60/246] time 0.093 (0.105) data 0.001 (0.005) loss 1.8935 (1.2359) ce_loss 1.7441 (1.1106) teacher_loss 1.7412 (1.1083) loss_zs_kd 0.2230 (0.1512) loss_oracle 0.0408 (0.0520) acc 56.2500 (70.8854) kd_loss 0.0222 (0.0213) lr 1.7290e-03 eta 0:15:51
epoch [14/50] batch [80/246] time 0.103 (0.103) data 0.000 (0.004) loss 1.0671 (1.2239) ce_loss 0.9429 (1.0992) teacher_loss 0.9435 (1.0968) loss_zs_kd 0.1393 (0.1494) loss_oracle 0.0539 (0.0524) acc 84.3750 (71.4453) kd_loss 0.0176 (0.0216) lr 1.7290e-03 eta 0:15:28
epoch [14/50] batch [100/246] time 0.092 (0.101) data 0.000 (0.003) loss 1.1986 (1.2344) ce_loss 1.0195 (1.1087) teacher_loss 1.0147 (1.1062) loss_zs_kd 0.2530 (0.1512) loss_oracle 0.0574 (0.0527) acc 68.7500 (70.8750) kd_loss 0.0213 (0.0217) lr 1.7290e-03 eta 0:15:13
epoch [14/50] batch [120/246] time 0.096 (0.101) data 0.000 (0.003) loss 1.0667 (1.2416) ce_loss 0.9028 (1.1122) teacher_loss 0.8979 (1.1094) loss_zs_kd 0.1711 (0.1506) loss_oracle 0.0833 (0.0569) acc 75.0000 (70.7812) kd_loss 0.0277 (0.0219) lr 1.7290e-03 eta 0:15:05
epoch [14/50] batch [140/246] time 0.090 (0.100) data 0.000 (0.002) loss 1.8648 (1.2575) ce_loss 1.6709 (1.1201) teacher_loss 1.6575 (1.1170) loss_zs_kd 0.1679 (0.1491) loss_oracle 0.1233 (0.0659) acc 62.5000 (70.6473) kd_loss 0.0331 (0.0222) lr 1.7290e-03 eta 0:14:55
epoch [14/50] batch [160/246] time 0.094 (0.099) data 0.000 (0.002) loss 1.1816 (1.2597) ce_loss 1.0332 (1.1187) teacher_loss 1.0367 (1.1157) loss_zs_kd 0.1424 (0.1477) loss_oracle 0.0737 (0.0702) acc 71.8750 (70.6836) kd_loss 0.0146 (0.0221) lr 1.7290e-03 eta 0:14:48
epoch [14/50] batch [180/246] time 0.104 (0.100) data 0.000 (0.002) loss 1.6357 (1.2525) ce_loss 1.5186 (1.1135) teacher_loss 1.4968 (1.1106) loss_zs_kd 0.1651 (0.1469) loss_oracle 0.0563 (0.0684) acc 62.5000 (70.9549) kd_loss 0.0248 (0.0221) lr 1.7290e-03 eta 0:14:49
epoch [14/50] batch [200/246] time 0.108 (0.100) data 0.000 (0.002) loss 1.2710 (1.2537) ce_loss 1.1289 (1.1169) teacher_loss 1.1283 (1.1139) loss_zs_kd 0.1863 (0.1460) loss_oracle 0.0495 (0.0668) acc 62.5000 (70.9688) kd_loss 0.0210 (0.0224) lr 1.7290e-03 eta 0:14:51
epoch [14/50] batch [220/246] time 0.097 (0.100) data 0.000 (0.002) loss 1.0259 (1.2454) ce_loss 0.8599 (1.1090) teacher_loss 0.8623 (1.1061) loss_zs_kd 0.2066 (0.1475) loss_oracle 0.0603 (0.0655) acc 75.0000 (71.1648) kd_loss 0.0228 (0.0225) lr 1.7290e-03 eta 0:14:50
epoch [14/50] batch [240/246] time 0.110 (0.101) data 0.000 (0.001) loss 1.2388 (1.2385) ce_loss 1.0850 (1.1015) teacher_loss 1.0834 (1.0988) loss_zs_kd 0.2001 (0.1491) loss_oracle 0.0553 (0.0652) acc 71.8750 (71.4583) kd_loss 0.0213 (0.0225) lr 1.7290e-03 eta 0:14:53
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,841
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.9%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,963
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 89.9%
******* Domain r best val acc:      84.7%, epoch: 14 *******
******* Domain r best val test acc: 91.0%, epoch: 14 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [15/50] batch [20/246] time 0.127 (0.146) data 0.000 (0.016) loss 1.2037 (1.2371) ce_loss 1.0889 (1.1069) teacher_loss 1.0930 (1.1053) loss_zs_kd 0.1246 (0.1438) loss_oracle 0.0485 (0.0599) acc 68.7500 (70.3125) kd_loss 0.0345 (0.0240) lr 1.6845e-03 eta 0:21:27
epoch [15/50] batch [40/246] time 0.132 (0.138) data 0.000 (0.008) loss 1.1273 (1.2192) ce_loss 0.9951 (1.0923) teacher_loss 0.9845 (1.0918) loss_zs_kd 0.1590 (0.1428) loss_oracle 0.0633 (0.0560) acc 75.0000 (71.1719) kd_loss 0.0323 (0.0265) lr 1.6845e-03 eta 0:20:13
epoch [15/50] batch [60/246] time 0.133 (0.136) data 0.001 (0.006) loss 0.9692 (1.2327) ce_loss 0.7695 (1.0965) teacher_loss 0.7655 (1.0950) loss_zs_kd 0.1962 (0.1491) loss_oracle 0.1055 (0.0632) acc 78.1250 (70.8333) kd_loss 0.0329 (0.0266) lr 1.6845e-03 eta 0:19:53
epoch [15/50] batch [80/246] time 0.131 (0.134) data 0.001 (0.004) loss 0.9712 (1.2337) ce_loss 0.8564 (1.0908) teacher_loss 0.8406 (1.0890) loss_zs_kd 0.1448 (0.1557) loss_oracle 0.0582 (0.0668) acc 71.8750 (71.0547) kd_loss 0.0548 (0.0268) lr 1.6845e-03 eta 0:19:38
epoch [15/50] batch [100/246] time 0.104 (0.133) data 0.001 (0.004) loss 1.0922 (1.2304) ce_loss 0.9517 (1.0846) teacher_loss 0.9476 (1.0828) loss_zs_kd 0.1308 (0.1546) loss_oracle 0.0791 (0.0703) acc 71.8750 (71.3750) kd_loss 0.0185 (0.0263) lr 1.6845e-03 eta 0:19:22
epoch [15/50] batch [120/246] time 0.099 (0.128) data 0.000 (0.003) loss 1.5076 (1.2317) ce_loss 1.3916 (1.0873) teacher_loss 1.3972 (1.0851) loss_zs_kd 0.1124 (0.1543) loss_oracle 0.0542 (0.0695) acc 62.5000 (71.2500) kd_loss 0.0136 (0.0260) lr 1.6845e-03 eta 0:18:35
epoch [15/50] batch [140/246] time 0.098 (0.124) data 0.000 (0.003) loss 1.4664 (1.2395) ce_loss 1.3066 (1.0946) teacher_loss 1.3057 (1.0925) loss_zs_kd 0.1457 (0.1545) loss_oracle 0.0879 (0.0698) acc 68.7500 (71.1830) kd_loss 0.0308 (0.0256) lr 1.6845e-03 eta 0:18:01
epoch [15/50] batch [160/246] time 0.101 (0.121) data 0.000 (0.002) loss 1.6473 (1.2487) ce_loss 1.4893 (1.1031) teacher_loss 1.4729 (1.1013) loss_zs_kd 0.1636 (0.1543) loss_oracle 0.0927 (0.0703) acc 62.5000 (71.1523) kd_loss 0.0252 (0.0256) lr 1.6845e-03 eta 0:17:32
epoch [15/50] batch [180/246] time 0.126 (0.122) data 0.000 (0.002) loss 1.6455 (1.2344) ce_loss 1.4863 (1.0883) teacher_loss 1.4840 (1.0866) loss_zs_kd 0.2048 (0.1529) loss_oracle 0.0591 (0.0713) acc 59.3750 (71.4757) kd_loss 0.0309 (0.0256) lr 1.6845e-03 eta 0:17:36
epoch [15/50] batch [200/246] time 0.130 (0.123) data 0.001 (0.002) loss 1.1068 (1.2371) ce_loss 0.9629 (1.0915) teacher_loss 0.9597 (1.0898) loss_zs_kd 0.1189 (0.1519) loss_oracle 0.0877 (0.0713) acc 65.6250 (71.3281) kd_loss 0.0190 (0.0256) lr 1.6845e-03 eta 0:17:41
epoch [15/50] batch [220/246] time 0.130 (0.123) data 0.001 (0.002) loss 1.6900 (1.2419) ce_loss 1.5205 (1.0961) teacher_loss 1.5283 (1.0945) loss_zs_kd 0.2033 (0.1531) loss_oracle 0.0600 (0.0709) acc 56.2500 (71.1506) kd_loss 0.0217 (0.0254) lr 1.6845e-03 eta 0:17:46
epoch [15/50] batch [240/246] time 0.112 (0.123) data 0.000 (0.002) loss 0.9888 (1.2448) ce_loss 0.8745 (1.1002) teacher_loss 0.8796 (1.0987) loss_zs_kd 0.1255 (0.1532) loss_oracle 0.0465 (0.0694) acc 75.0000 (71.0417) kd_loss 0.0196 (0.0254) lr 1.6845e-03 eta 0:17:42
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,839
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      84.7%, epoch: 14 *******
******* Domain r best val test acc: 91.0%, epoch: 14 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [16/50] batch [20/246] time 0.109 (0.124) data 0.000 (0.017) loss 0.6624 (1.2141) ce_loss 0.5215 (1.0934) teacher_loss 0.5239 (1.0909) loss_zs_kd 0.1507 (0.1482) loss_oracle 0.0632 (0.0491) acc 90.6250 (71.2500) kd_loss 0.0405 (0.0256) lr 1.6374e-03 eta 0:17:41
epoch [16/50] batch [40/246] time 0.107 (0.116) data 0.000 (0.009) loss 1.1279 (1.2263) ce_loss 0.9644 (1.0952) teacher_loss 0.9493 (1.0926) loss_zs_kd 0.1849 (0.1521) loss_oracle 0.0861 (0.0577) acc 71.8750 (71.5625) kd_loss 0.0326 (0.0244) lr 1.6374e-03 eta 0:16:31
epoch [16/50] batch [60/246] time 0.103 (0.113) data 0.001 (0.006) loss 1.7846 (1.2727) ce_loss 1.5947 (1.1222) teacher_loss 1.5934 (1.1202) loss_zs_kd 0.1523 (0.1559) loss_oracle 0.1151 (0.0745) acc 56.2500 (70.9375) kd_loss 0.0187 (0.0235) lr 1.6374e-03 eta 0:16:04
epoch [16/50] batch [80/246] time 0.107 (0.112) data 0.000 (0.004) loss 1.5396 (1.3045) ce_loss 1.3379 (1.1478) teacher_loss 1.3370 (1.1464) loss_zs_kd 0.2225 (0.1570) loss_oracle 0.0914 (0.0797) acc 62.5000 (70.3125) kd_loss 0.0220 (0.0226) lr 1.6374e-03 eta 0:15:52
epoch [16/50] batch [100/246] time 0.103 (0.111) data 0.000 (0.004) loss 1.1793 (1.2868) ce_loss 1.0273 (1.1292) teacher_loss 1.0189 (1.1278) loss_zs_kd 0.1768 (0.1583) loss_oracle 0.0719 (0.0799) acc 71.8750 (71.0312) kd_loss 0.0244 (0.0230) lr 1.6374e-03 eta 0:15:40
epoch [16/50] batch [120/246] time 0.110 (0.110) data 0.000 (0.003) loss 1.0553 (1.2798) ce_loss 0.9116 (1.1246) teacher_loss 0.8928 (1.1233) loss_zs_kd 0.1872 (0.1574) loss_oracle 0.0690 (0.0779) acc 78.1250 (70.9115) kd_loss 0.0411 (0.0237) lr 1.6374e-03 eta 0:15:32
epoch [16/50] batch [140/246] time 0.103 (0.109) data 0.000 (0.003) loss 1.0836 (1.2771) ce_loss 0.9585 (1.1252) teacher_loss 0.9614 (1.1238) loss_zs_kd 0.1158 (0.1562) loss_oracle 0.0643 (0.0753) acc 75.0000 (70.9152) kd_loss 0.0206 (0.0239) lr 1.6374e-03 eta 0:15:26
epoch [16/50] batch [160/246] time 0.103 (0.109) data 0.000 (0.002) loss 1.7622 (1.2725) ce_loss 1.6533 (1.1228) teacher_loss 1.6429 (1.1211) loss_zs_kd 0.1390 (0.1540) loss_oracle 0.0497 (0.0744) acc 62.5000 (70.8398) kd_loss 0.0314 (0.0241) lr 1.6374e-03 eta 0:15:21
epoch [16/50] batch [180/246] time 0.109 (0.109) data 0.000 (0.002) loss 1.3358 (1.2602) ce_loss 1.1973 (1.1123) teacher_loss 1.1963 (1.1107) loss_zs_kd 0.1275 (0.1522) loss_oracle 0.0758 (0.0734) acc 75.0000 (71.0417) kd_loss 0.0226 (0.0239) lr 1.6374e-03 eta 0:15:18
epoch [16/50] batch [200/246] time 0.102 (0.109) data 0.000 (0.002) loss 1.0258 (1.2670) ce_loss 0.8647 (1.1186) teacher_loss 0.8673 (1.1172) loss_zs_kd 0.1583 (0.1539) loss_oracle 0.0793 (0.0729) acc 75.0000 (70.9375) kd_loss 0.0260 (0.0237) lr 1.6374e-03 eta 0:15:16
epoch [16/50] batch [220/246] time 0.112 (0.109) data 0.000 (0.002) loss 1.2737 (1.2612) ce_loss 1.1387 (1.1117) teacher_loss 1.1402 (1.1104) loss_zs_kd 0.1414 (0.1545) loss_oracle 0.0629 (0.0736) acc 75.0000 (71.3210) kd_loss 0.0239 (0.0235) lr 1.6374e-03 eta 0:15:13
epoch [16/50] batch [240/246] time 0.085 (0.108) data 0.000 (0.002) loss 1.3708 (1.2579) ce_loss 1.2783 (1.1090) teacher_loss 1.2733 (1.1078) loss_zs_kd 0.1300 (0.1535) loss_oracle 0.0324 (0.0733) acc 68.7500 (71.3021) kd_loss 0.0287 (0.0234) lr 1.6374e-03 eta 0:15:03
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,837
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,949
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      84.7%, epoch: 14 *******
******* Domain r best val test acc: 91.0%, epoch: 14 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [17/50] batch [20/246] time 0.117 (0.121) data 0.000 (0.013) loss 1.0628 (1.2401) ce_loss 0.9663 (1.1070) teacher_loss 0.9678 (1.1062) loss_zs_kd 0.0850 (0.1527) loss_oracle 0.0525 (0.0575) acc 71.8750 (71.8750) kd_loss 0.0193 (0.0235) lr 1.5878e-03 eta 0:16:46
epoch [17/50] batch [40/246] time 0.104 (0.114) data 0.000 (0.007) loss 0.7667 (1.2187) ce_loss 0.6592 (1.0891) teacher_loss 0.6565 (1.0871) loss_zs_kd 0.1279 (0.1539) loss_oracle 0.0462 (0.0546) acc 84.3750 (72.2656) kd_loss 0.0259 (0.0267) lr 1.5878e-03 eta 0:15:48
epoch [17/50] batch [60/246] time 0.108 (0.111) data 0.001 (0.005) loss 0.9707 (1.2058) ce_loss 0.7959 (1.0754) teacher_loss 0.7925 (1.0733) loss_zs_kd 0.2415 (0.1578) loss_oracle 0.0575 (0.0536) acc 75.0000 (72.4479) kd_loss 0.0600 (0.0283) lr 1.5878e-03 eta 0:15:25
epoch [17/50] batch [80/246] time 0.130 (0.112) data 0.000 (0.003) loss 1.1532 (1.2261) ce_loss 1.0186 (1.0966) teacher_loss 1.0217 (1.0950) loss_zs_kd 0.1365 (0.1544) loss_oracle 0.0632 (0.0539) acc 78.1250 (71.7969) kd_loss 0.0218 (0.0286) lr 1.5878e-03 eta 0:15:27
epoch [17/50] batch [100/246] time 0.136 (0.116) data 0.000 (0.003) loss 1.2649 (1.2312) ce_loss 1.1299 (1.0991) teacher_loss 1.1375 (1.0975) loss_zs_kd 0.1488 (0.1558) loss_oracle 0.0530 (0.0558) acc 75.0000 (71.7188) kd_loss 0.0385 (0.0291) lr 1.5878e-03 eta 0:15:57
epoch [17/50] batch [120/246] time 0.125 (0.119) data 0.000 (0.002) loss 1.0248 (1.2179) ce_loss 0.8550 (1.0841) teacher_loss 0.8511 (1.0827) loss_zs_kd 0.2087 (0.1563) loss_oracle 0.0693 (0.0571) acc 81.2500 (72.3958) kd_loss 0.0624 (0.0299) lr 1.5878e-03 eta 0:16:16
epoch [17/50] batch [140/246] time 0.129 (0.120) data 0.000 (0.002) loss 1.1918 (1.2240) ce_loss 1.0752 (1.0890) teacher_loss 1.0742 (1.0876) loss_zs_kd 0.1260 (0.1575) loss_oracle 0.0547 (0.0576) acc 75.0000 (72.2321) kd_loss 0.0400 (0.0306) lr 1.5878e-03 eta 0:16:27
epoch [17/50] batch [160/246] time 0.120 (0.121) data 0.000 (0.002) loss 1.0421 (1.2249) ce_loss 0.8765 (1.0902) teacher_loss 0.8664 (1.0888) loss_zs_kd 0.1560 (0.1567) loss_oracle 0.0977 (0.0577) acc 68.7500 (72.1094) kd_loss 0.0318 (0.0305) lr 1.5878e-03 eta 0:16:31
epoch [17/50] batch [180/246] time 0.127 (0.121) data 0.000 (0.002) loss 1.7265 (1.2283) ce_loss 1.5908 (1.0925) teacher_loss 1.5902 (1.0914) loss_zs_kd 0.1687 (0.1565) loss_oracle 0.0520 (0.0586) acc 68.7500 (71.9792) kd_loss 0.0207 (0.0298) lr 1.5878e-03 eta 0:16:33
epoch [17/50] batch [200/246] time 0.133 (0.122) data 0.002 (0.002) loss 1.0159 (1.2238) ce_loss 0.9321 (1.0900) teacher_loss 0.9338 (1.0889) loss_zs_kd 0.0879 (0.1554) loss_oracle 0.0382 (0.0572) acc 78.1250 (72.1250) kd_loss 0.0267 (0.0297) lr 1.5878e-03 eta 0:16:38
epoch [17/50] batch [220/246] time 0.127 (0.122) data 0.000 (0.002) loss 1.0977 (1.2274) ce_loss 0.9385 (1.0936) teacher_loss 0.9394 (1.0925) loss_zs_kd 0.1954 (0.1560) loss_oracle 0.0606 (0.0569) acc 71.8750 (71.8892) kd_loss 0.0284 (0.0294) lr 1.5878e-03 eta 0:16:32
epoch [17/50] batch [240/246] time 0.101 (0.121) data 0.000 (0.001) loss 0.9878 (1.2208) ce_loss 0.8496 (1.0862) teacher_loss 0.8504 (1.0852) loss_zs_kd 0.1460 (0.1571) loss_oracle 0.0645 (0.0571) acc 78.1250 (72.0312) kd_loss 0.0386 (0.0293) lr 1.5878e-03 eta 0:16:25
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,843
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      84.8%, epoch: 17 *******
******* Domain r best val test acc: 90.8%, epoch: 17 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [18/50] batch [20/246] time 0.089 (0.111) data 0.000 (0.014) loss 0.9201 (1.2242) ce_loss 0.7715 (1.0904) teacher_loss 0.7758 (1.0894) loss_zs_kd 0.1960 (0.1631) loss_oracle 0.0463 (0.0533) acc 84.3750 (71.8750) kd_loss 0.0353 (0.0314) lr 1.5358e-03 eta 0:14:55
epoch [18/50] batch [40/246] time 0.101 (0.103) data 0.000 (0.007) loss 1.3803 (1.2440) ce_loss 1.2158 (1.1129) teacher_loss 1.2175 (1.1113) loss_zs_kd 0.1840 (0.1589) loss_oracle 0.0708 (0.0532) acc 68.7500 (71.0938) kd_loss 0.0248 (0.0299) lr 1.5358e-03 eta 0:13:51
epoch [18/50] batch [60/246] time 0.092 (0.100) data 0.000 (0.005) loss 1.1460 (1.2087) ce_loss 1.0117 (1.0714) teacher_loss 1.0109 (1.0701) loss_zs_kd 0.1698 (0.1682) loss_oracle 0.0502 (0.0545) acc 68.7500 (72.7083) kd_loss 0.0233 (0.0296) lr 1.5358e-03 eta 0:13:28
epoch [18/50] batch [80/246] time 0.105 (0.100) data 0.000 (0.004) loss 1.4480 (1.2275) ce_loss 1.3115 (1.0914) teacher_loss 1.3133 (1.0894) loss_zs_kd 0.1389 (0.1632) loss_oracle 0.0653 (0.0565) acc 68.7500 (72.1875) kd_loss 0.0407 (0.0296) lr 1.5358e-03 eta 0:13:19
epoch [18/50] batch [100/246] time 0.098 (0.099) data 0.000 (0.003) loss 1.3814 (1.2233) ce_loss 1.2549 (1.0864) teacher_loss 1.2512 (1.0846) loss_zs_kd 0.1388 (0.1599) loss_oracle 0.0608 (0.0587) acc 68.7500 (71.7812) kd_loss 0.0302 (0.0291) lr 1.5358e-03 eta 0:13:10
epoch [18/50] batch [120/246] time 0.098 (0.098) data 0.000 (0.003) loss 1.5415 (1.2382) ce_loss 1.3994 (1.1001) teacher_loss 1.3972 (1.0982) loss_zs_kd 0.1790 (0.1618) loss_oracle 0.0547 (0.0591) acc 68.7500 (71.3021) kd_loss 0.0235 (0.0281) lr 1.5358e-03 eta 0:13:05
epoch [18/50] batch [140/246] time 0.103 (0.098) data 0.000 (0.002) loss 0.8368 (1.2358) ce_loss 0.7017 (1.0965) teacher_loss 0.6970 (1.0946) loss_zs_kd 0.1202 (0.1620) loss_oracle 0.0797 (0.0602) acc 84.3750 (71.3839) kd_loss 0.0265 (0.0277) lr 1.5358e-03 eta 0:13:03
epoch [18/50] batch [160/246] time 0.099 (0.098) data 0.000 (0.002) loss 0.6682 (1.2324) ce_loss 0.5020 (1.0888) teacher_loss 0.5045 (1.0870) loss_zs_kd 0.1737 (0.1635) loss_oracle 0.0768 (0.0636) acc 90.6250 (71.4062) kd_loss 0.0159 (0.0272) lr 1.5358e-03 eta 0:13:02
epoch [18/50] batch [180/246] time 0.091 (0.098) data 0.000 (0.002) loss 0.8701 (1.2305) ce_loss 0.7563 (1.0883) teacher_loss 0.7507 (1.0866) loss_zs_kd 0.1087 (0.1623) loss_oracle 0.0650 (0.0627) acc 78.1250 (71.2674) kd_loss 0.0214 (0.0270) lr 1.5358e-03 eta 0:13:01
epoch [18/50] batch [200/246] time 0.102 (0.098) data 0.000 (0.002) loss 1.0974 (1.2343) ce_loss 0.9678 (1.0918) teacher_loss 0.9701 (1.0905) loss_zs_kd 0.1841 (0.1633) loss_oracle 0.0352 (0.0622) acc 71.8750 (71.0469) kd_loss 0.0210 (0.0270) lr 1.5358e-03 eta 0:12:56
epoch [18/50] batch [220/246] time 0.093 (0.098) data 0.000 (0.002) loss 0.9113 (1.2354) ce_loss 0.8232 (1.0938) teacher_loss 0.8241 (1.0925) loss_zs_kd 0.0895 (0.1630) loss_oracle 0.0425 (0.0614) acc 78.1250 (71.1648) kd_loss 0.0335 (0.0272) lr 1.5358e-03 eta 0:12:50
epoch [18/50] batch [240/246] time 0.086 (0.097) data 0.000 (0.001) loss 0.9135 (1.2423) ce_loss 0.7563 (1.1015) teacher_loss 0.7562 (1.1001) loss_zs_kd 0.2112 (0.1626) loss_oracle 0.0518 (0.0609) acc 81.2500 (70.9375) kd_loss 0.0385 (0.0276) lr 1.5358e-03 eta 0:12:43
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,840
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.6%
******* Domain r best val acc:      84.8%, epoch: 17 *******
******* Domain r best val test acc: 90.8%, epoch: 17 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [19/50] batch [20/246] time 0.090 (0.109) data 0.000 (0.013) loss 0.9012 (1.1497) ce_loss 0.7930 (1.0153) teacher_loss 0.7895 (1.0140) loss_zs_kd 0.1311 (0.1595) loss_oracle 0.0461 (0.0560) acc 84.3750 (74.3750) kd_loss 0.0278 (0.0340) lr 1.4818e-03 eta 0:14:14
epoch [19/50] batch [40/246] time 0.094 (0.101) data 0.000 (0.007) loss 1.0739 (1.1912) ce_loss 0.9663 (1.0596) teacher_loss 0.9689 (1.0583) loss_zs_kd 0.1152 (0.1559) loss_oracle 0.0473 (0.0549) acc 78.1250 (71.4844) kd_loss 0.0242 (0.0332) lr 1.4818e-03 eta 0:13:09
epoch [19/50] batch [60/246] time 0.099 (0.099) data 0.001 (0.004) loss 1.1598 (1.1939) ce_loss 1.0537 (1.0605) teacher_loss 1.0493 (1.0587) loss_zs_kd 0.1103 (0.1588) loss_oracle 0.0553 (0.0559) acc 71.8750 (71.6146) kd_loss 0.0305 (0.0322) lr 1.4818e-03 eta 0:12:54
epoch [19/50] batch [80/246] time 0.097 (0.099) data 0.001 (0.003) loss 1.3970 (1.1969) ce_loss 1.2520 (1.0611) teacher_loss 1.2403 (1.0594) loss_zs_kd 0.2087 (0.1617) loss_oracle 0.0523 (0.0566) acc 65.6250 (71.4062) kd_loss 0.0294 (0.0317) lr 1.4818e-03 eta 0:12:48
epoch [19/50] batch [100/246] time 0.096 (0.099) data 0.000 (0.003) loss 1.1593 (1.2070) ce_loss 0.9897 (1.0715) teacher_loss 0.9956 (1.0704) loss_zs_kd 0.1821 (0.1601) loss_oracle 0.0727 (0.0565) acc 71.8750 (71.2500) kd_loss 0.0420 (0.0318) lr 1.4818e-03 eta 0:12:47
epoch [19/50] batch [120/246] time 0.108 (0.098) data 0.000 (0.002) loss 1.1496 (1.2148) ce_loss 0.9893 (1.0781) teacher_loss 0.9924 (1.0774) loss_zs_kd 0.2086 (0.1630) loss_oracle 0.0528 (0.0559) acc 71.8750 (70.9115) kd_loss 0.0381 (0.0319) lr 1.4818e-03 eta 0:12:43
epoch [19/50] batch [140/246] time 0.092 (0.098) data 0.000 (0.002) loss 1.0947 (1.2319) ce_loss 0.9780 (1.0968) teacher_loss 0.9795 (1.0963) loss_zs_kd 0.1454 (0.1617) loss_oracle 0.0425 (0.0548) acc 78.1250 (70.6920) kd_loss 0.0292 (0.0321) lr 1.4818e-03 eta 0:12:37
epoch [19/50] batch [160/246] time 0.096 (0.098) data 0.000 (0.002) loss 1.0764 (1.2273) ce_loss 0.9219 (1.0929) teacher_loss 0.9248 (1.0923) loss_zs_kd 0.1698 (0.1607) loss_oracle 0.0668 (0.0546) acc 65.6250 (70.7227) kd_loss 0.0253 (0.0325) lr 1.4818e-03 eta 0:12:34
epoch [19/50] batch [180/246] time 0.092 (0.098) data 0.000 (0.002) loss 1.3493 (1.2319) ce_loss 1.1309 (1.0948) teacher_loss 1.1333 (1.0944) loss_zs_kd 0.2416 (0.1596) loss_oracle 0.0952 (0.0577) acc 71.8750 (70.8333) kd_loss 0.0315 (0.0325) lr 1.4818e-03 eta 0:12:31
epoch [19/50] batch [200/246] time 0.100 (0.097) data 0.000 (0.002) loss 1.3292 (1.2355) ce_loss 1.1904 (1.0958) teacher_loss 1.1907 (1.0954) loss_zs_kd 0.1111 (0.1585) loss_oracle 0.0829 (0.0608) acc 71.8750 (70.8125) kd_loss 0.0357 (0.0322) lr 1.4818e-03 eta 0:12:27
epoch [19/50] batch [220/246] time 0.094 (0.097) data 0.000 (0.001) loss 0.9098 (1.2442) ce_loss 0.7646 (1.1035) teacher_loss 0.7589 (1.1031) loss_zs_kd 0.1797 (0.1584) loss_oracle 0.0610 (0.0618) acc 84.3750 (70.5966) kd_loss 0.0320 (0.0317) lr 1.4818e-03 eta 0:12:24
epoch [19/50] batch [240/246] time 0.087 (0.097) data 0.000 (0.001) loss 1.3053 (1.2447) ce_loss 1.1504 (1.1041) teacher_loss 1.1460 (1.1039) loss_zs_kd 0.1970 (0.1592) loss_oracle 0.0608 (0.0613) acc 68.7500 (70.6250) kd_loss 0.0236 (0.0314) lr 1.4818e-03 eta 0:12:19
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,847
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [20/50] batch [20/246] time 0.097 (0.116) data 0.000 (0.014) loss 1.2715 (1.2666) ce_loss 1.1201 (1.1226) teacher_loss 1.1306 (1.1234) loss_zs_kd 0.1665 (0.1651) loss_oracle 0.0576 (0.0607) acc 71.8750 (71.4062) kd_loss 0.0310 (0.0289) lr 1.4258e-03 eta 0:14:39
epoch [20/50] batch [40/246] time 0.096 (0.106) data 0.000 (0.007) loss 1.1009 (1.2452) ce_loss 0.9336 (1.1052) teacher_loss 0.9330 (1.1052) loss_zs_kd 0.1908 (0.1599) loss_oracle 0.0725 (0.0600) acc 75.0000 (71.4062) kd_loss 0.0206 (0.0296) lr 1.4258e-03 eta 0:13:22
epoch [20/50] batch [60/246] time 0.115 (0.106) data 0.000 (0.005) loss 1.3360 (1.2579) ce_loss 1.1631 (1.1181) teacher_loss 1.1638 (1.1177) loss_zs_kd 0.2025 (0.1582) loss_oracle 0.0709 (0.0611) acc 71.8750 (70.9375) kd_loss 0.0277 (0.0293) lr 1.4258e-03 eta 0:13:18
epoch [20/50] batch [80/246] time 0.106 (0.106) data 0.000 (0.004) loss 1.2756 (1.2636) ce_loss 1.1025 (1.1205) teacher_loss 1.1085 (1.1201) loss_zs_kd 0.1813 (0.1601) loss_oracle 0.0764 (0.0634) acc 81.2500 (71.2109) kd_loss 0.0286 (0.0287) lr 1.4258e-03 eta 0:13:21
epoch [20/50] batch [100/246] time 0.108 (0.106) data 0.000 (0.003) loss 0.8854 (1.2697) ce_loss 0.7134 (1.1256) teacher_loss 0.7147 (1.1252) loss_zs_kd 0.1563 (0.1585) loss_oracle 0.0926 (0.0652) acc 84.3750 (71.1562) kd_loss 0.0248 (0.0285) lr 1.4258e-03 eta 0:13:18
epoch [20/50] batch [120/246] time 0.107 (0.106) data 0.000 (0.003) loss 1.3185 (1.2566) ce_loss 1.0879 (1.1080) teacher_loss 1.0928 (1.1076) loss_zs_kd 0.2814 (0.1611) loss_oracle 0.0849 (0.0684) acc 71.8750 (71.5365) kd_loss 0.0291 (0.0283) lr 1.4258e-03 eta 0:13:17
epoch [20/50] batch [140/246] time 0.130 (0.107) data 0.000 (0.002) loss 1.1180 (1.2494) ce_loss 0.9819 (1.1012) teacher_loss 0.9727 (1.1008) loss_zs_kd 0.1430 (0.1612) loss_oracle 0.0738 (0.0681) acc 75.0000 (71.5625) kd_loss 0.0446 (0.0281) lr 1.4258e-03 eta 0:13:24
epoch [20/50] batch [160/246] time 0.122 (0.110) data 0.000 (0.002) loss 0.7308 (1.2427) ce_loss 0.5913 (1.0943) teacher_loss 0.5961 (1.0938) loss_zs_kd 0.1445 (0.1624) loss_oracle 0.0624 (0.0677) acc 87.5000 (71.8555) kd_loss 0.0400 (0.0288) lr 1.4258e-03 eta 0:13:38
epoch [20/50] batch [180/246] time 0.132 (0.111) data 0.000 (0.002) loss 1.1189 (1.2275) ce_loss 0.9805 (1.0802) teacher_loss 0.9773 (1.0795) loss_zs_kd 0.1647 (0.1616) loss_oracle 0.0592 (0.0672) acc 71.8750 (72.3090) kd_loss 0.0447 (0.0300) lr 1.4258e-03 eta 0:13:49
epoch [20/50] batch [200/246] time 0.125 (0.113) data 0.000 (0.002) loss 1.1726 (1.2296) ce_loss 1.0107 (1.0809) teacher_loss 0.9954 (1.0798) loss_zs_kd 0.2047 (0.1624) loss_oracle 0.0748 (0.0686) acc 68.7500 (72.3906) kd_loss 0.0428 (0.0307) lr 1.4258e-03 eta 0:13:58
epoch [20/50] batch [220/246] time 0.121 (0.114) data 0.000 (0.002) loss 1.5886 (1.2273) ce_loss 1.4531 (1.0793) teacher_loss 1.4439 (1.0779) loss_zs_kd 0.1363 (0.1613) loss_oracle 0.0765 (0.0687) acc 62.5000 (72.1165) kd_loss 0.0327 (0.0311) lr 1.4258e-03 eta 0:14:02
epoch [20/50] batch [240/246] time 0.105 (0.114) data 0.000 (0.001) loss 1.2626 (1.2308) ce_loss 1.1182 (1.0825) teacher_loss 1.1170 (1.0810) loss_zs_kd 0.1535 (0.1615) loss_oracle 0.0688 (0.0690) acc 75.0000 (72.0573) kd_loss 0.0240 (0.0310) lr 1.4258e-03 eta 0:14:00
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,842
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [21/50] batch [20/246] time 0.097 (0.116) data 0.000 (0.014) loss 0.7005 (1.2075) ce_loss 0.5835 (1.0624) teacher_loss 0.5787 (1.0611) loss_zs_kd 0.1104 (0.1690) loss_oracle 0.0666 (0.0619) acc 87.5000 (71.8750) kd_loss 0.0323 (0.0337) lr 1.3681e-03 eta 0:14:10
epoch [21/50] batch [40/246] time 0.122 (0.113) data 0.000 (0.007) loss 1.1259 (1.2324) ce_loss 0.9634 (1.0940) teacher_loss 0.9521 (1.0916) loss_zs_kd 0.1739 (0.1594) loss_oracle 0.0869 (0.0612) acc 71.8750 (71.1719) kd_loss 0.0568 (0.0338) lr 1.3681e-03 eta 0:13:52
epoch [21/50] batch [60/246] time 0.122 (0.116) data 0.001 (0.005) loss 1.1477 (1.2321) ce_loss 0.9531 (1.0887) teacher_loss 0.9632 (1.0864) loss_zs_kd 0.2048 (0.1666) loss_oracle 0.0822 (0.0624) acc 78.1250 (71.5625) kd_loss 0.0345 (0.0341) lr 1.3681e-03 eta 0:14:06
epoch [21/50] batch [80/246] time 0.123 (0.116) data 0.000 (0.004) loss 1.3642 (1.2214) ce_loss 1.2344 (1.0777) teacher_loss 1.2301 (1.0755) loss_zs_kd 0.1487 (0.1652) loss_oracle 0.0596 (0.0633) acc 65.6250 (71.9922) kd_loss 0.0250 (0.0338) lr 1.3681e-03 eta 0:14:10
epoch [21/50] batch [100/246] time 0.121 (0.118) data 0.000 (0.003) loss 1.1652 (1.2243) ce_loss 1.0684 (1.0820) teacher_loss 1.0691 (1.0794) loss_zs_kd 0.1343 (0.1640) loss_oracle 0.0289 (0.0629) acc 68.7500 (72.0000) kd_loss 0.0260 (0.0343) lr 1.3681e-03 eta 0:14:20
epoch [21/50] batch [120/246] time 0.123 (0.120) data 0.000 (0.003) loss 0.8278 (1.2326) ce_loss 0.7056 (1.0927) teacher_loss 0.7116 (1.0906) loss_zs_kd 0.1361 (0.1615) loss_oracle 0.0481 (0.0613) acc 78.1250 (71.8490) kd_loss 0.0294 (0.0341) lr 1.3681e-03 eta 0:14:28
epoch [21/50] batch [140/246] time 0.125 (0.120) data 0.000 (0.002) loss 0.9228 (1.2296) ce_loss 0.7788 (1.0904) teacher_loss 0.7819 (1.0889) loss_zs_kd 0.1556 (0.1610) loss_oracle 0.0631 (0.0602) acc 78.1250 (71.8973) kd_loss 0.0364 (0.0337) lr 1.3681e-03 eta 0:14:32
epoch [21/50] batch [160/246] time 0.125 (0.121) data 0.000 (0.002) loss 0.8830 (1.2257) ce_loss 0.7319 (1.0856) teacher_loss 0.7386 (1.0841) loss_zs_kd 0.1853 (0.1620) loss_oracle 0.0518 (0.0607) acc 81.2500 (72.0117) kd_loss 0.0312 (0.0334) lr 1.3681e-03 eta 0:14:35
epoch [21/50] batch [180/246] time 0.127 (0.122) data 0.000 (0.002) loss 1.3786 (1.2399) ce_loss 1.2256 (1.1000) teacher_loss 1.2203 (1.0983) loss_zs_kd 0.1949 (0.1623) loss_oracle 0.0609 (0.0605) acc 68.7500 (71.5972) kd_loss 0.0483 (0.0342) lr 1.3681e-03 eta 0:14:36
epoch [21/50] batch [200/246] time 0.123 (0.122) data 0.000 (0.002) loss 1.2959 (1.2382) ce_loss 1.1387 (1.0991) teacher_loss 1.1345 (1.0975) loss_zs_kd 0.2053 (0.1617) loss_oracle 0.0588 (0.0599) acc 75.0000 (71.5938) kd_loss 0.0664 (0.0347) lr 1.3681e-03 eta 0:14:36
epoch [21/50] batch [220/246] time 0.126 (0.122) data 0.000 (0.002) loss 1.0850 (1.2433) ce_loss 0.9399 (1.1045) teacher_loss 0.9334 (1.1029) loss_zs_kd 0.1749 (0.1616) loss_oracle 0.0642 (0.0596) acc 65.6250 (71.4347) kd_loss 0.0597 (0.0354) lr 1.3681e-03 eta 0:14:35
epoch [21/50] batch [240/246] time 0.104 (0.122) data 0.000 (0.002) loss 1.1816 (1.2446) ce_loss 1.0488 (1.1061) teacher_loss 1.0560 (1.1047) loss_zs_kd 0.1538 (0.1613) loss_oracle 0.0486 (0.0593) acc 71.8750 (71.2240) kd_loss 0.0354 (0.0358) lr 1.3681e-03 eta 0:14:29
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,843
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [22/50] batch [20/246] time 0.113 (0.128) data 0.001 (0.014) loss 0.9909 (1.1965) ce_loss 0.8535 (1.0570) teacher_loss 0.8487 (1.0552) loss_zs_kd 0.1576 (0.1675) loss_oracle 0.0634 (0.0575) acc 78.1250 (71.2500) kd_loss 0.0391 (0.0455) lr 1.3090e-03 eta 0:15:09
epoch [22/50] batch [40/246] time 0.113 (0.120) data 0.000 (0.007) loss 1.3753 (1.2709) ce_loss 1.2207 (1.1257) teacher_loss 1.2286 (1.1251) loss_zs_kd 0.1827 (0.1702) loss_oracle 0.0553 (0.0607) acc 75.0000 (69.6094) kd_loss 0.0294 (0.0444) lr 1.3090e-03 eta 0:14:14
epoch [22/50] batch [60/246] time 0.103 (0.115) data 0.001 (0.005) loss 1.0734 (1.2632) ce_loss 0.9399 (1.1164) teacher_loss 0.9439 (1.1160) loss_zs_kd 0.1557 (0.1711) loss_oracle 0.0517 (0.0616) acc 71.8750 (69.5833) kd_loss 0.0524 (0.0441) lr 1.3090e-03 eta 0:13:32
epoch [22/50] batch [80/246] time 0.098 (0.112) data 0.000 (0.004) loss 1.4835 (1.2506) ce_loss 1.3330 (1.1063) teacher_loss 1.3332 (1.1054) loss_zs_kd 0.1989 (0.1692) loss_oracle 0.0509 (0.0606) acc 56.2500 (70.0391) kd_loss 0.0388 (0.0439) lr 1.3090e-03 eta 0:13:06
epoch [22/50] batch [100/246] time 0.100 (0.109) data 0.000 (0.003) loss 0.8052 (1.2287) ce_loss 0.7041 (1.0872) teacher_loss 0.6724 (1.0861) loss_zs_kd 0.1344 (0.1658) loss_oracle 0.0655 (0.0597) acc 87.5000 (70.3125) kd_loss 0.0413 (0.0434) lr 1.3090e-03 eta 0:12:48
epoch [22/50] batch [120/246] time 0.097 (0.108) data 0.000 (0.003) loss 1.2291 (1.2195) ce_loss 1.0801 (1.0793) teacher_loss 1.0764 (1.0782) loss_zs_kd 0.1621 (0.1639) loss_oracle 0.0717 (0.0594) acc 68.7500 (70.8594) kd_loss 0.0543 (0.0431) lr 1.3090e-03 eta 0:12:36
epoch [22/50] batch [140/246] time 0.097 (0.107) data 0.000 (0.002) loss 1.1418 (1.2162) ce_loss 0.9639 (1.0756) teacher_loss 0.9618 (1.0748) loss_zs_kd 0.1990 (0.1633) loss_oracle 0.0805 (0.0598) acc 81.2500 (71.3393) kd_loss 0.0349 (0.0422) lr 1.3090e-03 eta 0:12:26
epoch [22/50] batch [160/246] time 0.097 (0.106) data 0.000 (0.002) loss 0.9893 (1.2117) ce_loss 0.8579 (1.0718) teacher_loss 0.8552 (1.0712) loss_zs_kd 0.1180 (0.1594) loss_oracle 0.0751 (0.0608) acc 75.0000 (71.5234) kd_loss 0.0505 (0.0414) lr 1.3090e-03 eta 0:12:19
epoch [22/50] batch [180/246] time 0.097 (0.105) data 0.000 (0.002) loss 1.4967 (1.2123) ce_loss 1.3262 (1.0715) teacher_loss 1.3279 (1.0710) loss_zs_kd 0.1937 (0.1603) loss_oracle 0.0719 (0.0611) acc 59.3750 (71.5451) kd_loss 0.0422 (0.0406) lr 1.3090e-03 eta 0:12:11
epoch [22/50] batch [200/246] time 0.108 (0.105) data 0.000 (0.002) loss 1.3461 (1.2147) ce_loss 1.1699 (1.0737) teacher_loss 1.1724 (1.0730) loss_zs_kd 0.2169 (0.1609) loss_oracle 0.0652 (0.0612) acc 68.7500 (71.4844) kd_loss 0.0509 (0.0404) lr 1.3090e-03 eta 0:12:06
epoch [22/50] batch [220/246] time 0.108 (0.104) data 0.000 (0.002) loss 1.4691 (1.2203) ce_loss 1.3076 (1.0795) teacher_loss 1.3037 (1.0789) loss_zs_kd 0.1911 (0.1604) loss_oracle 0.0699 (0.0612) acc 68.7500 (71.4205) kd_loss 0.0476 (0.0402) lr 1.3090e-03 eta 0:12:01
epoch [22/50] batch [240/246] time 0.102 (0.104) data 0.000 (0.001) loss 0.9999 (1.2253) ce_loss 0.8623 (1.0841) teacher_loss 0.8647 (1.0836) loss_zs_kd 0.1525 (0.1613) loss_oracle 0.0589 (0.0610) acc 78.1250 (71.3151) kd_loss 0.0384 (0.0399) lr 1.3090e-03 eta 0:11:57
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,846
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,951
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [23/50] batch [20/246] time 0.125 (0.148) data 0.001 (0.017) loss 1.1057 (1.2399) ce_loss 0.9448 (1.0915) teacher_loss 0.9429 (1.0916) loss_zs_kd 0.1679 (0.1702) loss_oracle 0.0789 (0.0633) acc 71.8750 (69.3750) kd_loss 0.0377 (0.0364) lr 1.2487e-03 eta 0:16:54
epoch [23/50] batch [40/246] time 0.132 (0.138) data 0.000 (0.009) loss 1.4357 (1.2671) ce_loss 1.3018 (1.1207) teacher_loss 1.3069 (1.1200) loss_zs_kd 0.1470 (0.1685) loss_oracle 0.0553 (0.0629) acc 62.5000 (69.3750) kd_loss 0.0249 (0.0360) lr 1.2487e-03 eta 0:15:47
epoch [23/50] batch [60/246] time 0.129 (0.136) data 0.001 (0.006) loss 1.2711 (1.2503) ce_loss 1.0928 (1.1053) teacher_loss 1.0920 (1.1046) loss_zs_kd 0.2348 (0.1682) loss_oracle 0.0617 (0.0616) acc 68.7500 (70.3646) kd_loss 0.0361 (0.0367) lr 1.2487e-03 eta 0:15:25
epoch [23/50] batch [80/246] time 0.104 (0.132) data 0.000 (0.004) loss 0.9653 (1.2717) ce_loss 0.8403 (1.1303) teacher_loss 0.8406 (1.1292) loss_zs_kd 0.1706 (0.1632) loss_oracle 0.0393 (0.0609) acc 84.3750 (69.7266) kd_loss 0.0366 (0.0370) lr 1.2487e-03 eta 0:14:56
epoch [23/50] batch [100/246] time 0.098 (0.126) data 0.000 (0.004) loss 1.0944 (1.2523) ce_loss 0.9497 (1.1128) teacher_loss 0.9523 (1.1116) loss_zs_kd 0.1881 (0.1626) loss_oracle 0.0480 (0.0594) acc 81.2500 (70.3125) kd_loss 0.0295 (0.0362) lr 1.2487e-03 eta 0:14:16
epoch [23/50] batch [120/246] time 0.098 (0.122) data 0.000 (0.003) loss 0.9734 (1.2318) ce_loss 0.8228 (1.0911) teacher_loss 0.8203 (1.0902) loss_zs_kd 0.1549 (0.1636) loss_oracle 0.0756 (0.0598) acc 71.8750 (70.9896) kd_loss 0.0552 (0.0365) lr 1.2487e-03 eta 0:13:45
epoch [23/50] batch [140/246] time 0.109 (0.119) data 0.000 (0.003) loss 0.9798 (1.2319) ce_loss 0.8516 (1.0887) teacher_loss 0.8523 (1.0882) loss_zs_kd 0.1314 (0.1656) loss_oracle 0.0618 (0.0608) acc 78.1250 (71.1161) kd_loss 0.0463 (0.0370) lr 1.2487e-03 eta 0:13:24
epoch [23/50] batch [160/246] time 0.101 (0.117) data 0.000 (0.002) loss 1.5147 (1.2337) ce_loss 1.3760 (1.0901) teacher_loss 1.3848 (1.0898) loss_zs_kd 0.1289 (0.1641) loss_oracle 0.0654 (0.0619) acc 62.5000 (70.9375) kd_loss 0.0291 (0.0377) lr 1.2487e-03 eta 0:13:08
epoch [23/50] batch [180/246] time 0.119 (0.116) data 0.001 (0.002) loss 1.0275 (1.2245) ce_loss 0.8643 (1.0800) teacher_loss 0.8772 (1.0796) loss_zs_kd 0.1751 (0.1642) loss_oracle 0.0628 (0.0627) acc 78.1250 (71.0243) kd_loss 0.0364 (0.0386) lr 1.2487e-03 eta 0:12:57
epoch [23/50] batch [200/246] time 0.136 (0.117) data 0.000 (0.002) loss 1.6184 (1.2189) ce_loss 1.4814 (1.0745) teacher_loss 1.4854 (1.0741) loss_zs_kd 0.1679 (0.1643) loss_oracle 0.0490 (0.0627) acc 59.3750 (71.1875) kd_loss 0.0354 (0.0388) lr 1.2487e-03 eta 0:13:03
epoch [23/50] batch [220/246] time 0.127 (0.118) data 0.000 (0.002) loss 1.2310 (1.2201) ce_loss 1.0879 (1.0757) teacher_loss 1.0842 (1.0752) loss_zs_kd 0.1775 (0.1646) loss_oracle 0.0580 (0.0626) acc 75.0000 (71.1080) kd_loss 0.0505 (0.0388) lr 1.2487e-03 eta 0:13:09
epoch [23/50] batch [240/246] time 0.102 (0.118) data 0.000 (0.002) loss 0.8736 (1.2219) ce_loss 0.7739 (1.0780) teacher_loss 0.7517 (1.0776) loss_zs_kd 0.1055 (0.1645) loss_oracle 0.0692 (0.0621) acc 78.1250 (71.1198) kd_loss 0.0496 (0.0388) lr 1.2487e-03 eta 0:13:05
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,849
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.1%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,953
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      84.9%, epoch: 23 *******
******* Domain r best val test acc: 90.7%, epoch: 23 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [24/50] batch [20/246] time 0.094 (0.115) data 0.000 (0.015) loss 1.2304 (1.1833) ce_loss 1.1064 (1.0422) teacher_loss 1.1067 (1.0438) loss_zs_kd 0.1656 (0.1699) loss_oracle 0.0408 (0.0545) acc 78.1250 (71.4062) kd_loss 0.0440 (0.0435) lr 1.1874e-03 eta 0:12:44
epoch [24/50] batch [40/246] time 0.092 (0.105) data 0.000 (0.007) loss 1.3678 (1.2175) ce_loss 1.1963 (1.0772) teacher_loss 1.1985 (1.0748) loss_zs_kd 0.2370 (0.1722) loss_oracle 0.0508 (0.0566) acc 65.6250 (71.2500) kd_loss 0.0314 (0.0441) lr 1.1874e-03 eta 0:11:31
epoch [24/50] batch [60/246] time 0.094 (0.102) data 0.001 (0.005) loss 1.3542 (1.2159) ce_loss 1.2275 (1.0736) teacher_loss 1.2243 (1.0709) loss_zs_kd 0.1404 (0.1723) loss_oracle 0.0597 (0.0589) acc 68.7500 (71.6146) kd_loss 0.0413 (0.0428) lr 1.1874e-03 eta 0:11:10
epoch [24/50] batch [80/246] time 0.095 (0.100) data 0.000 (0.004) loss 1.2036 (1.2373) ce_loss 1.0273 (1.0909) teacher_loss 1.0274 (1.0884) loss_zs_kd 0.2266 (0.1778) loss_oracle 0.0628 (0.0600) acc 75.0000 (71.4453) kd_loss 0.0343 (0.0424) lr 1.1874e-03 eta 0:10:57
epoch [24/50] batch [100/246] time 0.089 (0.100) data 0.000 (0.003) loss 1.4257 (1.2484) ce_loss 1.2598 (1.1013) teacher_loss 1.2739 (1.0992) loss_zs_kd 0.1674 (0.1754) loss_oracle 0.0680 (0.0615) acc 71.8750 (71.4062) kd_loss 0.0537 (0.0425) lr 1.1874e-03 eta 0:10:54
epoch [24/50] batch [120/246] time 0.092 (0.099) data 0.000 (0.003) loss 1.1647 (1.2194) ce_loss 1.0137 (1.0710) teacher_loss 1.0118 (1.0691) loss_zs_kd 0.2157 (0.1759) loss_oracle 0.0451 (0.0623) acc 75.0000 (72.0573) kd_loss 0.0346 (0.0433) lr 1.1874e-03 eta 0:10:48
epoch [24/50] batch [140/246] time 0.097 (0.099) data 0.000 (0.002) loss 1.0344 (1.2185) ce_loss 0.9058 (1.0716) teacher_loss 0.9041 (1.0694) loss_zs_kd 0.1574 (0.1739) loss_oracle 0.0516 (0.0621) acc 81.2500 (72.2768) kd_loss 0.0455 (0.0433) lr 1.1874e-03 eta 0:10:42
epoch [24/50] batch [160/246] time 0.091 (0.099) data 0.000 (0.002) loss 1.3214 (1.2215) ce_loss 1.1533 (1.0747) teacher_loss 1.1578 (1.0728) loss_zs_kd 0.2203 (0.1734) loss_oracle 0.0534 (0.0619) acc 65.6250 (72.2266) kd_loss 0.0397 (0.0427) lr 1.1874e-03 eta 0:10:39
epoch [24/50] batch [180/246] time 0.092 (0.098) data 0.000 (0.002) loss 1.7324 (1.2220) ce_loss 1.5566 (1.0748) teacher_loss 1.5566 (1.0730) loss_zs_kd 0.2029 (0.1729) loss_oracle 0.0743 (0.0626) acc 59.3750 (72.2396) kd_loss 0.0339 (0.0424) lr 1.1874e-03 eta 0:10:34
epoch [24/50] batch [200/246] time 0.104 (0.098) data 0.000 (0.002) loss 1.7245 (1.2388) ce_loss 1.5752 (1.0916) teacher_loss 1.5814 (1.0899) loss_zs_kd 0.1589 (0.1712) loss_oracle 0.0636 (0.0634) acc 53.1250 (71.5156) kd_loss 0.0317 (0.0419) lr 1.1874e-03 eta 0:10:30
epoch [24/50] batch [220/246] time 0.095 (0.098) data 0.000 (0.002) loss 1.5053 (1.2381) ce_loss 1.3389 (1.0904) teacher_loss 1.3511 (1.0886) loss_zs_kd 0.1544 (0.1697) loss_oracle 0.0771 (0.0647) acc 59.3750 (71.5767) kd_loss 0.0406 (0.0413) lr 1.1874e-03 eta 0:10:27
epoch [24/50] batch [240/246] time 0.103 (0.098) data 0.000 (0.001) loss 1.2138 (1.2350) ce_loss 1.0635 (1.0870) teacher_loss 1.0598 (1.0851) loss_zs_kd 0.1696 (0.1695) loss_oracle 0.0692 (0.0651) acc 68.7500 (71.6016) kd_loss 0.0296 (0.0407) lr 1.1874e-03 eta 0:10:26
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,852
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.2%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,948
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.5%
******* Domain r best val acc:      85.0%, epoch: 24 *******
******* Domain r best val test acc: 90.6%, epoch: 24 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [25/50] batch [20/246] time 0.095 (0.113) data 0.000 (0.013) loss 1.0713 (1.2283) ce_loss 0.9248 (1.0786) teacher_loss 0.9293 (1.0765) loss_zs_kd 0.1700 (0.1639) loss_oracle 0.0571 (0.0699) acc 71.8750 (71.7188) kd_loss 0.0368 (0.0402) lr 1.1253e-03 eta 0:12:00
epoch [25/50] batch [40/246] time 0.093 (0.104) data 0.001 (0.007) loss 1.0760 (1.1937) ce_loss 0.9224 (1.0391) teacher_loss 0.9186 (1.0378) loss_zs_kd 0.1659 (0.1619) loss_oracle 0.0745 (0.0749) acc 75.0000 (71.4844) kd_loss 0.0408 (0.0372) lr 1.1253e-03 eta 0:10:58
epoch [25/50] batch [60/246] time 0.102 (0.101) data 0.000 (0.005) loss 1.8153 (1.2269) ce_loss 1.6680 (1.0748) teacher_loss 1.6699 (1.0732) loss_zs_kd 0.1729 (0.1635) loss_oracle 0.0590 (0.0719) acc 56.2500 (70.8333) kd_loss 0.0395 (0.0364) lr 1.1253e-03 eta 0:10:39
epoch [25/50] batch [80/246] time 0.100 (0.100) data 0.000 (0.003) loss 1.1187 (1.2194) ce_loss 1.0049 (1.0696) teacher_loss 0.9981 (1.0681) loss_zs_kd 0.1227 (0.1632) loss_oracle 0.0592 (0.0697) acc 71.8750 (70.8984) kd_loss 0.0369 (0.0367) lr 1.1253e-03 eta 0:10:32
epoch [25/50] batch [100/246] time 0.097 (0.099) data 0.000 (0.003) loss 0.9508 (1.2244) ce_loss 0.8193 (1.0750) teacher_loss 0.8215 (1.0744) loss_zs_kd 0.1532 (0.1630) loss_oracle 0.0527 (0.0685) acc 81.2500 (71.0625) kd_loss 0.0314 (0.0368) lr 1.1253e-03 eta 0:10:22
epoch [25/50] batch [120/246] time 0.095 (0.098) data 0.000 (0.002) loss 1.2402 (1.2442) ce_loss 1.0977 (1.0947) teacher_loss 1.0956 (1.0934) loss_zs_kd 0.1682 (0.1655) loss_oracle 0.0605 (0.0681) acc 81.2500 (70.6510) kd_loss 0.0314 (0.0379) lr 1.1253e-03 eta 0:10:17
epoch [25/50] batch [140/246] time 0.097 (0.098) data 0.000 (0.002) loss 1.1402 (1.2384) ce_loss 0.9834 (1.0882) teacher_loss 0.9791 (1.0872) loss_zs_kd 0.1803 (0.1657) loss_oracle 0.0709 (0.0683) acc 78.1250 (71.3170) kd_loss 0.0497 (0.0379) lr 1.1253e-03 eta 0:10:12
epoch [25/50] batch [160/246] time 0.100 (0.098) data 0.000 (0.002) loss 1.4759 (1.2466) ce_loss 1.3496 (1.0969) teacher_loss 1.3571 (1.0962) loss_zs_kd 0.1527 (0.1644) loss_oracle 0.0424 (0.0683) acc 65.6250 (71.0742) kd_loss 0.0327 (0.0379) lr 1.1253e-03 eta 0:10:08
epoch [25/50] batch [180/246] time 0.095 (0.098) data 0.000 (0.002) loss 1.1058 (1.2450) ce_loss 0.9756 (1.0965) teacher_loss 0.9691 (1.0955) loss_zs_kd 0.1395 (0.1638) loss_oracle 0.0670 (0.0676) acc 71.8750 (71.1806) kd_loss 0.0360 (0.0390) lr 1.1253e-03 eta 0:10:06
epoch [25/50] batch [200/246] time 0.095 (0.097) data 0.000 (0.002) loss 1.0905 (1.2341) ce_loss 0.9116 (1.0869) teacher_loss 0.9169 (1.0857) loss_zs_kd 0.2202 (0.1635) loss_oracle 0.0635 (0.0667) acc 75.0000 (71.3750) kd_loss 0.0448 (0.0393) lr 1.1253e-03 eta 0:10:02
epoch [25/50] batch [220/246] time 0.093 (0.097) data 0.000 (0.001) loss 1.2978 (1.2272) ce_loss 1.1807 (1.0800) teacher_loss 1.1759 (1.0789) loss_zs_kd 0.1391 (0.1632) loss_oracle 0.0523 (0.0667) acc 71.8750 (71.7472) kd_loss 0.0456 (0.0399) lr 1.1253e-03 eta 0:10:00
epoch [25/50] batch [240/246] time 0.087 (0.097) data 0.000 (0.001) loss 1.0366 (1.2307) ce_loss 0.8892 (1.0832) teacher_loss 0.8885 (1.0820) loss_zs_kd 0.1533 (0.1640) loss_oracle 0.0714 (0.0667) acc 75.0000 (71.5234) kd_loss 0.0429 (0.0406) lr 1.1253e-03 eta 0:09:55
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,857
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,944
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.5%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [26/50] batch [20/246] time 0.098 (0.118) data 0.000 (0.013) loss 1.1828 (1.2722) ce_loss 1.0391 (1.1235) teacher_loss 1.0472 (1.1224) loss_zs_kd 0.1582 (0.1621) loss_oracle 0.0564 (0.0688) acc 65.6250 (69.5312) kd_loss 0.0253 (0.0477) lr 1.0628e-03 eta 0:12:01
epoch [26/50] batch [40/246] time 0.095 (0.108) data 0.000 (0.007) loss 1.1691 (1.1844) ce_loss 1.0381 (1.0393) teacher_loss 1.0361 (1.0394) loss_zs_kd 0.1515 (0.1610) loss_oracle 0.0572 (0.0645) acc 75.0000 (72.0312) kd_loss 0.0413 (0.0504) lr 1.0628e-03 eta 0:11:00
epoch [26/50] batch [60/246] time 0.094 (0.105) data 0.001 (0.005) loss 1.1530 (1.1824) ce_loss 1.0195 (1.0386) teacher_loss 1.0250 (1.0379) loss_zs_kd 0.1620 (0.1667) loss_oracle 0.0470 (0.0612) acc 65.6250 (71.9792) kd_loss 0.0506 (0.0517) lr 1.0628e-03 eta 0:10:38
epoch [26/50] batch [80/246] time 0.096 (0.103) data 0.000 (0.004) loss 1.1761 (1.1965) ce_loss 1.0488 (1.0555) teacher_loss 1.0536 (1.0543) loss_zs_kd 0.1263 (0.1636) loss_oracle 0.0593 (0.0604) acc 75.0000 (71.6797) kd_loss 0.0587 (0.0511) lr 1.0628e-03 eta 0:10:26
epoch [26/50] batch [100/246] time 0.095 (0.102) data 0.000 (0.003) loss 1.4632 (1.2135) ce_loss 1.2861 (1.0704) teacher_loss 1.2819 (1.0691) loss_zs_kd 0.1984 (0.1671) loss_oracle 0.0820 (0.0609) acc 68.7500 (71.4062) kd_loss 0.0600 (0.0514) lr 1.0628e-03 eta 0:10:16
epoch [26/50] batch [120/246] time 0.096 (0.101) data 0.000 (0.002) loss 1.7118 (1.2348) ce_loss 1.5635 (1.0919) teacher_loss 1.5675 (1.0908) loss_zs_kd 0.1893 (0.1674) loss_oracle 0.0497 (0.0603) acc 62.5000 (70.9375) kd_loss 0.0380 (0.0503) lr 1.0628e-03 eta 0:10:11
epoch [26/50] batch [140/246] time 0.107 (0.101) data 0.000 (0.002) loss 1.1655 (1.2411) ce_loss 1.0430 (1.0994) teacher_loss 1.0528 (1.0982) loss_zs_kd 0.1255 (0.1667) loss_oracle 0.0500 (0.0595) acc 75.0000 (70.8705) kd_loss 0.0547 (0.0495) lr 1.0628e-03 eta 0:10:06
epoch [26/50] batch [160/246] time 0.102 (0.101) data 0.000 (0.002) loss 1.1916 (1.2386) ce_loss 1.0449 (1.0964) teacher_loss 1.0512 (1.0949) loss_zs_kd 0.1713 (0.1648) loss_oracle 0.0548 (0.0612) acc 68.7500 (70.7812) kd_loss 0.0540 (0.0497) lr 1.0628e-03 eta 0:10:03
epoch [26/50] batch [180/246] time 0.109 (0.101) data 0.000 (0.002) loss 1.1923 (1.2317) ce_loss 1.0039 (1.0869) teacher_loss 1.0048 (1.0854) loss_zs_kd 0.1703 (0.1656) loss_oracle 0.1023 (0.0635) acc 62.5000 (70.9722) kd_loss 0.0473 (0.0495) lr 1.0628e-03 eta 0:10:01
epoch [26/50] batch [200/246] time 0.095 (0.101) data 0.000 (0.002) loss 0.8893 (1.2239) ce_loss 0.7285 (1.0798) teacher_loss 0.7331 (1.0784) loss_zs_kd 0.1673 (0.1641) loss_oracle 0.0726 (0.0634) acc 81.2500 (71.2344) kd_loss 0.0626 (0.0488) lr 1.0628e-03 eta 0:09:59
epoch [26/50] batch [220/246] time 0.113 (0.101) data 0.000 (0.001) loss 1.8579 (1.2397) ce_loss 1.7168 (1.0958) teacher_loss 1.6971 (1.0945) loss_zs_kd 0.2034 (0.1646) loss_oracle 0.0591 (0.0629) acc 62.5000 (70.9375) kd_loss 0.0465 (0.0485) lr 1.0628e-03 eta 0:09:58
epoch [26/50] batch [240/246] time 0.104 (0.101) data 0.000 (0.001) loss 1.1276 (1.2390) ce_loss 1.0117 (1.0949) teacher_loss 1.0141 (1.0936) loss_zs_kd 0.1101 (0.1645) loss_oracle 0.0584 (0.0632) acc 75.0000 (70.8594) kd_loss 0.0416 (0.0481) lr 1.0628e-03 eta 0:09:57
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,854
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [27/50] batch [20/246] time 0.096 (0.110) data 0.000 (0.013) loss 0.8352 (1.1557) ce_loss 0.6938 (1.0183) teacher_loss 0.6917 (1.0165) loss_zs_kd 0.1503 (0.1571) loss_oracle 0.0684 (0.0607) acc 78.1250 (72.5000) kd_loss 0.0501 (0.0495) lr 1.0000e-03 eta 0:10:46
epoch [27/50] batch [40/246] time 0.098 (0.101) data 0.000 (0.007) loss 0.9269 (1.1533) ce_loss 0.7578 (1.0127) teacher_loss 0.7546 (1.0107) loss_zs_kd 0.1536 (0.1581) loss_oracle 0.0955 (0.0636) acc 78.1250 (72.4219) kd_loss 0.0665 (0.0482) lr 1.0000e-03 eta 0:09:55
epoch [27/50] batch [60/246] time 0.097 (0.099) data 0.000 (0.004) loss 1.1620 (1.1889) ce_loss 0.9878 (1.0447) teacher_loss 0.9811 (1.0412) loss_zs_kd 0.2198 (0.1643) loss_oracle 0.0710 (0.0655) acc 75.0000 (71.7708) kd_loss 0.0668 (0.0510) lr 1.0000e-03 eta 0:09:39
epoch [27/50] batch [80/246] time 0.093 (0.098) data 0.000 (0.003) loss 1.1864 (1.2151) ce_loss 1.0488 (1.0698) teacher_loss 1.0422 (1.0676) loss_zs_kd 0.1646 (0.1638) loss_oracle 0.0619 (0.0657) acc 65.6250 (71.3281) kd_loss 0.0542 (0.0498) lr 1.0000e-03 eta 0:09:32
epoch [27/50] batch [100/246] time 0.099 (0.098) data 0.000 (0.003) loss 1.2592 (1.2113) ce_loss 1.0811 (1.0635) teacher_loss 1.0915 (1.0615) loss_zs_kd 0.2240 (0.1659) loss_oracle 0.0557 (0.0668) acc 75.0000 (71.7188) kd_loss 0.0321 (0.0494) lr 1.0000e-03 eta 0:09:28
epoch [27/50] batch [120/246] time 0.092 (0.098) data 0.000 (0.002) loss 1.2061 (1.2242) ce_loss 1.0264 (1.0743) teacher_loss 1.0093 (1.0725) loss_zs_kd 0.1592 (0.1665) loss_oracle 0.1172 (0.0685) acc 75.0000 (71.3802) kd_loss 0.0705 (0.0492) lr 1.0000e-03 eta 0:09:24
epoch [27/50] batch [140/246] time 0.098 (0.097) data 0.000 (0.002) loss 1.2106 (1.2258) ce_loss 1.0898 (1.0727) teacher_loss 1.0887 (1.0709) loss_zs_kd 0.0993 (0.1678) loss_oracle 0.0722 (0.0710) acc 65.6250 (71.2500) kd_loss 0.0600 (0.0492) lr 1.0000e-03 eta 0:09:20
epoch [27/50] batch [160/246] time 0.097 (0.097) data 0.000 (0.002) loss 1.2810 (1.2117) ce_loss 1.1250 (1.0566) teacher_loss 1.1198 (1.0553) loss_zs_kd 0.1655 (0.1669) loss_oracle 0.0785 (0.0729) acc 71.8750 (71.7578) kd_loss 0.0679 (0.0501) lr 1.0000e-03 eta 0:09:18
epoch [27/50] batch [180/246] time 0.102 (0.097) data 0.000 (0.002) loss 1.3738 (1.2166) ce_loss 1.2334 (1.0601) teacher_loss 1.2396 (1.0587) loss_zs_kd 0.1162 (0.1684) loss_oracle 0.0761 (0.0737) acc 68.7500 (71.8403) kd_loss 0.0529 (0.0508) lr 1.0000e-03 eta 0:09:16
epoch [27/50] batch [200/246] time 0.092 (0.097) data 0.000 (0.001) loss 1.0456 (1.2160) ce_loss 0.8228 (1.0582) teacher_loss 0.8396 (1.0570) loss_zs_kd 0.2454 (0.1696) loss_oracle 0.0833 (0.0742) acc 75.0000 (71.7500) kd_loss 0.0739 (0.0516) lr 1.0000e-03 eta 0:09:13
epoch [27/50] batch [220/246] time 0.088 (0.097) data 0.000 (0.001) loss 1.2634 (1.2159) ce_loss 1.0830 (1.0584) teacher_loss 1.0551 (1.0568) loss_zs_kd 0.1949 (0.1699) loss_oracle 0.1108 (0.0741) acc 71.8750 (71.8040) kd_loss 0.0869 (0.0527) lr 1.0000e-03 eta 0:09:10
epoch [27/50] batch [240/246] time 0.084 (0.096) data 0.000 (0.001) loss 0.8124 (1.2142) ce_loss 0.6445 (1.0572) teacher_loss 0.6497 (1.0555) loss_zs_kd 0.1988 (0.1703) loss_oracle 0.0633 (0.0736) acc 84.3750 (71.7839) kd_loss 0.0569 (0.0539) lr 1.0000e-03 eta 0:09:06
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,857
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [28/50] batch [20/246] time 0.092 (0.112) data 0.000 (0.013) loss 1.1402 (1.1866) ce_loss 0.9790 (1.0457) teacher_loss 0.9738 (1.0421) loss_zs_kd 0.1850 (0.1625) loss_oracle 0.0739 (0.0633) acc 78.1250 (73.4375) kd_loss 0.0665 (0.0623) lr 9.3721e-04 eta 0:10:33
epoch [28/50] batch [40/246] time 0.100 (0.103) data 0.000 (0.007) loss 1.0942 (1.2070) ce_loss 0.9312 (1.0563) teacher_loss 0.9365 (1.0541) loss_zs_kd 0.1530 (0.1717) loss_oracle 0.0812 (0.0671) acc 71.8750 (72.3438) kd_loss 0.0456 (0.0604) lr 9.3721e-04 eta 0:09:36
epoch [28/50] batch [60/246] time 0.084 (0.098) data 0.000 (0.005) loss 1.1495 (1.2068) ce_loss 1.0117 (1.0565) teacher_loss 1.0089 (1.0545) loss_zs_kd 0.1200 (0.1653) loss_oracle 0.0805 (0.0697) acc 78.1250 (72.3438) kd_loss 0.0556 (0.0607) lr 9.3721e-04 eta 0:09:08
epoch [28/50] batch [80/246] time 0.095 (0.097) data 0.000 (0.003) loss 1.7843 (1.2224) ce_loss 1.6250 (1.0704) teacher_loss 1.6186 (1.0693) loss_zs_kd 0.1764 (0.1623) loss_oracle 0.0775 (0.0720) acc 56.2500 (71.6797) kd_loss 0.0531 (0.0598) lr 9.3721e-04 eta 0:08:58
epoch [28/50] batch [100/246] time 0.088 (0.096) data 0.000 (0.003) loss 1.1405 (1.2157) ce_loss 1.0068 (1.0624) teacher_loss 0.9971 (1.0614) loss_zs_kd 0.1547 (0.1627) loss_oracle 0.0660 (0.0729) acc 75.0000 (71.7188) kd_loss 0.0791 (0.0605) lr 9.3721e-04 eta 0:08:53
epoch [28/50] batch [120/246] time 0.092 (0.096) data 0.000 (0.002) loss 1.0729 (1.2371) ce_loss 0.9199 (1.0815) teacher_loss 0.9095 (1.0799) loss_zs_kd 0.1538 (0.1656) loss_oracle 0.0865 (0.0744) acc 78.1250 (71.0677) kd_loss 0.0808 (0.0607) lr 9.3721e-04 eta 0:08:49
epoch [28/50] batch [140/246] time 0.093 (0.095) data 0.000 (0.002) loss 0.9485 (1.2337) ce_loss 0.7671 (1.0742) teacher_loss 0.7510 (1.0726) loss_zs_kd 0.1617 (0.1674) loss_oracle 0.1166 (0.0774) acc 81.2500 (71.2500) kd_loss 0.0715 (0.0603) lr 9.3721e-04 eta 0:08:44
epoch [28/50] batch [160/246] time 0.101 (0.095) data 0.000 (0.002) loss 1.5585 (1.2368) ce_loss 1.3984 (1.0760) teacher_loss 1.3662 (1.0742) loss_zs_kd 0.2083 (0.1689) loss_oracle 0.0882 (0.0782) acc 65.6250 (70.9961) kd_loss 0.0548 (0.0594) lr 9.3721e-04 eta 0:08:43
epoch [28/50] batch [180/246] time 0.083 (0.095) data 0.000 (0.002) loss 1.1705 (1.2375) ce_loss 1.0137 (1.0766) teacher_loss 1.0085 (1.0749) loss_zs_kd 0.1883 (0.1695) loss_oracle 0.0678 (0.0778) acc 81.2500 (71.1285) kd_loss 0.0597 (0.0584) lr 9.3721e-04 eta 0:08:42
epoch [28/50] batch [200/246] time 0.098 (0.095) data 0.000 (0.001) loss 1.3103 (1.2346) ce_loss 1.1465 (1.0740) teacher_loss 1.1479 (1.0721) loss_zs_kd 0.1845 (0.1698) loss_oracle 0.0702 (0.0776) acc 62.5000 (71.1406) kd_loss 0.0580 (0.0570) lr 9.3721e-04 eta 0:08:38
epoch [28/50] batch [220/246] time 0.082 (0.095) data 0.000 (0.001) loss 1.1143 (1.2359) ce_loss 0.9692 (1.0755) teacher_loss 0.9663 (1.0735) loss_zs_kd 0.1606 (0.1709) loss_oracle 0.0677 (0.0769) acc 71.8750 (71.2074) kd_loss 0.0530 (0.0561) lr 9.3721e-04 eta 0:08:34
epoch [28/50] batch [240/246] time 0.085 (0.094) data 0.000 (0.001) loss 1.0922 (1.2424) ce_loss 0.9771 (1.0821) teacher_loss 0.9467 (1.0800) loss_zs_kd 0.1152 (0.1716) loss_oracle 0.0879 (0.0766) acc 71.8750 (70.9505) kd_loss 0.0365 (0.0554) lr 9.3721e-04 eta 0:08:28
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,844
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [29/50] batch [20/246] time 0.091 (0.108) data 0.000 (0.013) loss 1.1271 (1.2702) ce_loss 0.9775 (1.1181) teacher_loss 0.9672 (1.1119) loss_zs_kd 0.1757 (0.1750) loss_oracle 0.0721 (0.0708) acc 75.0000 (70.6250) kd_loss 0.0445 (0.0460) lr 8.7467e-04 eta 0:09:39
epoch [29/50] batch [40/246] time 0.091 (0.101) data 0.000 (0.007) loss 1.2460 (1.2139) ce_loss 1.0693 (1.0606) teacher_loss 1.0700 (1.0551) loss_zs_kd 0.1917 (0.1728) loss_oracle 0.0801 (0.0723) acc 71.8750 (72.2656) kd_loss 0.0546 (0.0462) lr 8.7467e-04 eta 0:09:03
epoch [29/50] batch [60/246] time 0.094 (0.098) data 0.000 (0.004) loss 2.0886 (1.2266) ce_loss 1.9404 (1.0735) teacher_loss 1.9412 (1.0694) loss_zs_kd 0.1764 (0.1721) loss_oracle 0.0592 (0.0712) acc 46.8750 (71.8750) kd_loss 0.0481 (0.0470) lr 8.7467e-04 eta 0:08:43
epoch [29/50] batch [80/246] time 0.093 (0.097) data 0.000 (0.003) loss 0.8225 (1.2218) ce_loss 0.6929 (1.0695) teacher_loss 0.6881 (1.0654) loss_zs_kd 0.1400 (0.1704) loss_oracle 0.0644 (0.0712) acc 75.0000 (71.8359) kd_loss 0.0304 (0.0468) lr 8.7467e-04 eta 0:08:38
epoch [29/50] batch [100/246] time 0.091 (0.097) data 0.000 (0.003) loss 1.3029 (1.2274) ce_loss 1.1670 (1.0750) teacher_loss 1.1635 (1.0710) loss_zs_kd 0.0974 (0.1697) loss_oracle 0.0907 (0.0715) acc 68.7500 (71.5625) kd_loss 0.0406 (0.0463) lr 8.7467e-04 eta 0:08:34
epoch [29/50] batch [120/246] time 0.093 (0.096) data 0.000 (0.002) loss 1.2987 (1.2227) ce_loss 1.0781 (1.0689) teacher_loss 1.0835 (1.0652) loss_zs_kd 0.2455 (0.1687) loss_oracle 0.0924 (0.0732) acc 75.0000 (71.7188) kd_loss 0.0454 (0.0467) lr 8.7467e-04 eta 0:08:27
epoch [29/50] batch [140/246] time 0.083 (0.095) data 0.000 (0.002) loss 1.6161 (1.2191) ce_loss 1.4697 (1.0635) teacher_loss 1.4631 (1.0597) loss_zs_kd 0.1579 (0.1691) loss_oracle 0.0741 (0.0749) acc 53.1250 (71.9196) kd_loss 0.0575 (0.0477) lr 8.7467e-04 eta 0:08:23
epoch [29/50] batch [160/246] time 0.090 (0.095) data 0.000 (0.002) loss 1.1618 (1.2184) ce_loss 1.0293 (1.0629) teacher_loss 1.0102 (1.0591) loss_zs_kd 0.1239 (0.1685) loss_oracle 0.0896 (0.0750) acc 75.0000 (71.9727) kd_loss 0.0623 (0.0480) lr 8.7467e-04 eta 0:08:17
epoch [29/50] batch [180/246] time 0.087 (0.094) data 0.000 (0.002) loss 1.9371 (1.2297) ce_loss 1.7422 (1.0739) teacher_loss 1.7369 (1.0700) loss_zs_kd 0.1649 (0.1680) loss_oracle 0.1177 (0.0757) acc 59.3750 (71.6667) kd_loss 0.0805 (0.0487) lr 8.7467e-04 eta 0:08:12
epoch [29/50] batch [200/246] time 0.098 (0.094) data 0.000 (0.001) loss 0.9358 (1.2233) ce_loss 0.7314 (1.0668) teacher_loss 0.7371 (1.0631) loss_zs_kd 0.2369 (0.1672) loss_oracle 0.0802 (0.0766) acc 81.2500 (71.8750) kd_loss 0.0433 (0.0494) lr 8.7467e-04 eta 0:08:10
epoch [29/50] batch [220/246] time 0.093 (0.094) data 0.000 (0.001) loss 1.2046 (1.2230) ce_loss 1.0273 (1.0656) teacher_loss 1.0311 (1.0619) loss_zs_kd 0.1808 (0.1675) loss_oracle 0.0831 (0.0774) acc 71.8750 (71.8040) kd_loss 0.0426 (0.0500) lr 8.7467e-04 eta 0:08:09
epoch [29/50] batch [240/246] time 0.085 (0.094) data 0.000 (0.001) loss 1.1213 (1.2149) ce_loss 1.0010 (1.0575) teacher_loss 0.9981 (1.0541) loss_zs_kd 0.1003 (0.1664) loss_oracle 0.0730 (0.0776) acc 78.1250 (72.0182) kd_loss 0.0619 (0.0507) lr 8.7467e-04 eta 0:08:06
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,855
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,950
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [30/50] batch [20/246] time 0.082 (0.105) data 0.000 (0.013) loss 1.0387 (1.2787) ce_loss 0.8589 (1.1187) teacher_loss 0.8607 (1.1101) loss_zs_kd 0.2050 (0.1790) loss_oracle 0.0756 (0.0791) acc 75.0000 (71.0938) kd_loss 0.0466 (0.0639) lr 8.1262e-04 eta 0:09:02
epoch [30/50] batch [40/246] time 0.092 (0.096) data 0.000 (0.007) loss 1.0196 (1.2375) ce_loss 0.8569 (1.0818) teacher_loss 0.8534 (1.0732) loss_zs_kd 0.1557 (0.1708) loss_oracle 0.0883 (0.0789) acc 71.8750 (71.2500) kd_loss 0.0733 (0.0628) lr 8.1262e-04 eta 0:08:14
epoch [30/50] batch [60/246] time 0.083 (0.093) data 0.000 (0.004) loss 1.1412 (1.2530) ce_loss 0.9844 (1.0939) teacher_loss 0.9803 (1.0867) loss_zs_kd 0.2063 (0.1758) loss_oracle 0.0578 (0.0785) acc 65.6250 (70.8333) kd_loss 0.0501 (0.0589) lr 8.1262e-04 eta 0:07:57
epoch [30/50] batch [80/246] time 0.094 (0.093) data 0.000 (0.003) loss 1.0359 (1.2462) ce_loss 0.8628 (1.0852) teacher_loss 0.8640 (1.0793) loss_zs_kd 0.2242 (0.1783) loss_oracle 0.0598 (0.0778) acc 71.8750 (71.1328) kd_loss 0.0518 (0.0566) lr 8.1262e-04 eta 0:07:54
epoch [30/50] batch [100/246] time 0.086 (0.092) data 0.000 (0.003) loss 0.7802 (1.2551) ce_loss 0.6108 (1.0930) teacher_loss 0.6110 (1.0880) loss_zs_kd 0.1624 (0.1778) loss_oracle 0.0880 (0.0782) acc 87.5000 (71.2812) kd_loss 0.0829 (0.0560) lr 8.1262e-04 eta 0:07:47
epoch [30/50] batch [120/246] time 0.090 (0.092) data 0.000 (0.002) loss 1.0285 (1.2705) ce_loss 0.8828 (1.1094) teacher_loss 0.8876 (1.1045) loss_zs_kd 0.1679 (0.1778) loss_oracle 0.0570 (0.0772) acc 78.1250 (71.0417) kd_loss 0.0374 (0.0551) lr 8.1262e-04 eta 0:07:43
epoch [30/50] batch [140/246] time 0.088 (0.091) data 0.000 (0.002) loss 0.9835 (1.2584) ce_loss 0.7808 (1.0987) teacher_loss 0.7704 (1.0939) loss_zs_kd 0.2565 (0.1768) loss_oracle 0.0848 (0.0760) acc 78.1250 (71.3616) kd_loss 0.0573 (0.0548) lr 8.1262e-04 eta 0:07:38
epoch [30/50] batch [160/246] time 0.097 (0.091) data 0.000 (0.002) loss 1.1126 (1.2521) ce_loss 0.9873 (1.0928) teacher_loss 0.9911 (1.0885) loss_zs_kd 0.1048 (0.1754) loss_oracle 0.0690 (0.0758) acc 71.8750 (71.6797) kd_loss 0.0640 (0.0553) lr 8.1262e-04 eta 0:07:36
epoch [30/50] batch [180/246] time 0.082 (0.091) data 0.000 (0.002) loss 0.7555 (1.2479) ce_loss 0.6138 (1.0893) teacher_loss 0.6155 (1.0854) loss_zs_kd 0.0995 (0.1739) loss_oracle 0.0902 (0.0755) acc 84.3750 (71.9792) kd_loss 0.0687 (0.0551) lr 8.1262e-04 eta 0:07:33
epoch [30/50] batch [200/246] time 0.089 (0.091) data 0.000 (0.001) loss 1.2098 (1.2431) ce_loss 1.0400 (1.0839) teacher_loss 1.0418 (1.0802) loss_zs_kd 0.1803 (0.1751) loss_oracle 0.0779 (0.0754) acc 78.1250 (72.0781) kd_loss 0.0497 (0.0549) lr 8.1262e-04 eta 0:07:32
epoch [30/50] batch [220/246] time 0.093 (0.092) data 0.000 (0.001) loss 1.4239 (1.2436) ce_loss 1.2900 (1.0857) teacher_loss 1.2863 (1.0816) loss_zs_kd 0.1515 (0.1738) loss_oracle 0.0618 (0.0750) acc 62.5000 (72.0312) kd_loss 0.0329 (0.0545) lr 8.1262e-04 eta 0:07:33
epoch [30/50] batch [240/246] time 0.087 (0.092) data 0.000 (0.001) loss 0.7267 (1.2408) ce_loss 0.5698 (1.0837) teacher_loss 0.5663 (1.0797) loss_zs_kd 0.1622 (0.1737) loss_oracle 0.0793 (0.0743) acc 87.5000 (72.0833) kd_loss 0.0567 (0.0538) lr 8.1262e-04 eta 0:07:30
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,858
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.2%, epoch: 30 *******
******* Domain r best val test acc: 90.8%, epoch: 30 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [31/50] batch [20/246] time 0.132 (0.145) data 0.000 (0.017) loss 0.9569 (1.1384) ce_loss 0.7920 (0.9805) teacher_loss 0.7925 (0.9791) loss_zs_kd 0.1595 (0.1717) loss_oracle 0.0846 (0.0734) acc 75.0000 (74.3750) kd_loss 0.0428 (0.0481) lr 7.5131e-04 eta 0:11:52
epoch [31/50] batch [40/246] time 0.137 (0.138) data 0.000 (0.009) loss 1.2905 (1.2065) ce_loss 1.1748 (1.0478) teacher_loss 1.1654 (1.0455) loss_zs_kd 0.1118 (0.1723) loss_oracle 0.0693 (0.0748) acc 71.8750 (72.3438) kd_loss 0.0229 (0.0455) lr 7.5131e-04 eta 0:11:11
epoch [31/50] batch [60/246] time 0.129 (0.135) data 0.001 (0.006) loss 1.3006 (1.2258) ce_loss 1.1084 (1.0677) teacher_loss 1.1149 (1.0654) loss_zs_kd 0.2284 (0.1711) loss_oracle 0.0716 (0.0748) acc 75.0000 (71.8750) kd_loss 0.0570 (0.0458) lr 7.5131e-04 eta 0:10:56
epoch [31/50] batch [80/246] time 0.128 (0.134) data 0.000 (0.005) loss 0.7412 (1.2188) ce_loss 0.5767 (1.0603) teacher_loss 0.5777 (1.0576) loss_zs_kd 0.1676 (0.1708) loss_oracle 0.0798 (0.0757) acc 90.6250 (72.1484) kd_loss 0.0365 (0.0455) lr 7.5131e-04 eta 0:10:48
epoch [31/50] batch [100/246] time 0.128 (0.133) data 0.001 (0.004) loss 0.8567 (1.2219) ce_loss 0.6963 (1.0612) teacher_loss 0.7002 (1.0594) loss_zs_kd 0.1801 (0.1738) loss_oracle 0.0664 (0.0756) acc 84.3750 (72.1562) kd_loss 0.0553 (0.0455) lr 7.5131e-04 eta 0:10:40
epoch [31/50] batch [120/246] time 0.125 (0.131) data 0.001 (0.003) loss 1.0590 (1.2346) ce_loss 0.9375 (1.0743) teacher_loss 0.9370 (1.0724) loss_zs_kd 0.1201 (0.1728) loss_oracle 0.0620 (0.0758) acc 65.6250 (71.7448) kd_loss 0.0625 (0.0458) lr 7.5131e-04 eta 0:10:30
epoch [31/50] batch [140/246] time 0.125 (0.131) data 0.000 (0.003) loss 1.5742 (1.2470) ce_loss 1.3623 (1.0851) teacher_loss 1.3566 (1.0835) loss_zs_kd 0.2479 (0.1732) loss_oracle 0.0936 (0.0769) acc 71.8750 (71.7411) kd_loss 0.0473 (0.0450) lr 7.5131e-04 eta 0:10:23
epoch [31/50] batch [160/246] time 0.122 (0.130) data 0.000 (0.003) loss 0.9674 (1.2353) ce_loss 0.7910 (1.0713) teacher_loss 0.7782 (1.0695) loss_zs_kd 0.2290 (0.1746) loss_oracle 0.0747 (0.0784) acc 81.2500 (72.0312) kd_loss 0.0405 (0.0443) lr 7.5131e-04 eta 0:10:17
epoch [31/50] batch [180/246] time 0.123 (0.129) data 0.000 (0.002) loss 1.5360 (1.2281) ce_loss 1.3789 (1.0630) teacher_loss 1.3763 (1.0616) loss_zs_kd 0.1338 (0.1747) loss_oracle 0.0928 (0.0791) acc 65.6250 (72.1528) kd_loss 0.0344 (0.0436) lr 7.5131e-04 eta 0:10:12
epoch [31/50] batch [200/246] time 0.097 (0.127) data 0.000 (0.002) loss 1.2310 (1.2332) ce_loss 1.0723 (1.0679) teacher_loss 1.0700 (1.0663) loss_zs_kd 0.1670 (0.1750) loss_oracle 0.0774 (0.0793) acc 71.8750 (71.9531) kd_loss 0.0452 (0.0432) lr 7.5131e-04 eta 0:09:58
epoch [31/50] batch [220/246] time 0.108 (0.125) data 0.000 (0.002) loss 1.1183 (1.2391) ce_loss 0.9102 (1.0741) teacher_loss 0.8923 (1.0724) loss_zs_kd 0.2447 (0.1744) loss_oracle 0.1037 (0.0794) acc 71.8750 (71.8892) kd_loss 0.0423 (0.0431) lr 7.5131e-04 eta 0:09:45
epoch [31/50] batch [240/246] time 0.104 (0.123) data 0.000 (0.002) loss 1.3106 (1.2374) ce_loss 1.1338 (1.0734) teacher_loss 1.1202 (1.0714) loss_zs_kd 0.1404 (0.1732) loss_oracle 0.1202 (0.0794) acc 65.6250 (71.8750) kd_loss 0.0597 (0.0432) lr 7.5131e-04 eta 0:09:34
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,852
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.9%
******* Domain r best val acc:      85.2%, epoch: 30 *******
******* Domain r best val test acc: 90.8%, epoch: 30 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [32/50] batch [20/246] time 0.111 (0.127) data 0.000 (0.014) loss 1.0050 (1.2303) ce_loss 0.8271 (1.0666) teacher_loss 0.8356 (1.0647) loss_zs_kd 0.1402 (0.1683) loss_oracle 0.0993 (0.0814) acc 71.8750 (70.3125) kd_loss 0.0403 (0.0460) lr 6.9098e-04 eta 0:09:51
epoch [32/50] batch [40/246] time 0.100 (0.119) data 0.000 (0.007) loss 1.0130 (1.2551) ce_loss 0.8389 (1.0947) teacher_loss 0.8355 (1.0918) loss_zs_kd 0.1451 (0.1667) loss_oracle 0.1049 (0.0799) acc 78.1250 (70.7812) kd_loss 0.0654 (0.0473) lr 6.9098e-04 eta 0:09:12
epoch [32/50] batch [60/246] time 0.097 (0.114) data 0.000 (0.005) loss 1.1586 (1.2642) ce_loss 1.0283 (1.1060) teacher_loss 1.0226 (1.1038) loss_zs_kd 0.1293 (0.1670) loss_oracle 0.0713 (0.0769) acc 68.7500 (70.3125) kd_loss 0.0507 (0.0466) lr 6.9098e-04 eta 0:08:44
epoch [32/50] batch [80/246] time 0.096 (0.111) data 0.000 (0.004) loss 0.9895 (1.2405) ce_loss 0.8169 (1.0815) teacher_loss 0.8211 (1.0790) loss_zs_kd 0.2079 (0.1712) loss_oracle 0.0645 (0.0760) acc 78.1250 (71.4062) kd_loss 0.0438 (0.0471) lr 6.9098e-04 eta 0:08:30
epoch [32/50] batch [100/246] time 0.096 (0.109) data 0.000 (0.003) loss 1.2447 (1.2576) ce_loss 1.0664 (1.0985) teacher_loss 1.0711 (1.0956) loss_zs_kd 0.1502 (0.1714) loss_oracle 0.0985 (0.0764) acc 75.0000 (70.6250) kd_loss 0.0523 (0.0481) lr 6.9098e-04 eta 0:08:19
epoch [32/50] batch [120/246] time 0.097 (0.107) data 0.000 (0.003) loss 0.9309 (1.2567) ce_loss 0.7510 (1.0969) teacher_loss 0.7593 (1.0941) loss_zs_kd 0.1543 (0.1732) loss_oracle 0.0945 (0.0760) acc 81.2500 (70.4688) kd_loss 0.0570 (0.0481) lr 6.9098e-04 eta 0:08:08
epoch [32/50] batch [140/246] time 0.100 (0.106) data 0.001 (0.002) loss 1.5041 (1.2413) ce_loss 1.3330 (1.0816) teacher_loss 1.3317 (1.0786) loss_zs_kd 0.1909 (0.1721) loss_oracle 0.0770 (0.0767) acc 59.3750 (71.0714) kd_loss 0.0394 (0.0478) lr 6.9098e-04 eta 0:08:02
epoch [32/50] batch [160/246] time 0.099 (0.106) data 0.000 (0.002) loss 1.0874 (1.2483) ce_loss 0.9355 (1.0887) teacher_loss 0.9319 (1.0856) loss_zs_kd 0.1252 (0.1706) loss_oracle 0.0929 (0.0774) acc 81.2500 (71.0547) kd_loss 0.0641 (0.0485) lr 6.9098e-04 eta 0:07:56
epoch [32/50] batch [180/246] time 0.102 (0.105) data 0.000 (0.002) loss 1.1684 (1.2413) ce_loss 1.0049 (1.0818) teacher_loss 0.9731 (1.0787) loss_zs_kd 0.1876 (0.1693) loss_oracle 0.1015 (0.0779) acc 75.0000 (71.3368) kd_loss 0.0541 (0.0488) lr 6.9098e-04 eta 0:07:51
epoch [32/50] batch [200/246] time 0.099 (0.104) data 0.000 (0.002) loss 1.3505 (1.2421) ce_loss 1.1787 (1.0828) teacher_loss 1.1837 (1.0796) loss_zs_kd 0.2385 (0.1697) loss_oracle 0.0476 (0.0776) acc 68.7500 (71.3281) kd_loss 0.0407 (0.0489) lr 6.9098e-04 eta 0:07:46
epoch [32/50] batch [220/246] time 0.102 (0.104) data 0.000 (0.002) loss 1.1729 (1.2336) ce_loss 0.9536 (1.0745) teacher_loss 0.9465 (1.0714) loss_zs_kd 0.2310 (0.1708) loss_oracle 0.1109 (0.0768) acc 78.1250 (71.5909) kd_loss 0.0576 (0.0489) lr 6.9098e-04 eta 0:07:42
epoch [32/50] batch [240/246] time 0.106 (0.104) data 0.000 (0.001) loss 0.7859 (1.2377) ce_loss 0.6597 (1.0802) teacher_loss 0.6559 (1.0770) loss_zs_kd 0.1121 (0.1697) loss_oracle 0.0739 (0.0758) acc 84.3750 (71.4193) kd_loss 0.0541 (0.0488) lr 6.9098e-04 eta 0:07:40
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,849
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      85.2%, epoch: 30 *******
******* Domain r best val test acc: 90.8%, epoch: 30 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [33/50] batch [20/246] time 0.096 (0.122) data 0.000 (0.020) loss 1.4852 (1.2088) ce_loss 1.3691 (1.0590) teacher_loss 1.3666 (1.0572) loss_zs_kd 0.1167 (0.1546) loss_oracle 0.0602 (0.0743) acc 62.5000 (72.5000) kd_loss 0.0384 (0.0466) lr 6.3188e-04 eta 0:08:57
epoch [33/50] batch [40/246] time 0.097 (0.112) data 0.000 (0.010) loss 0.8030 (1.2403) ce_loss 0.6709 (1.0885) teacher_loss 0.6697 (1.0875) loss_zs_kd 0.1424 (0.1627) loss_oracle 0.0621 (0.0714) acc 81.2500 (71.7969) kd_loss 0.0404 (0.0474) lr 6.3188e-04 eta 0:08:11
epoch [33/50] batch [60/246] time 0.106 (0.109) data 0.001 (0.007) loss 1.3990 (1.2226) ce_loss 1.2412 (1.0702) teacher_loss 1.2266 (1.0684) loss_zs_kd 0.1858 (0.1678) loss_oracle 0.0795 (0.0703) acc 75.0000 (72.1875) kd_loss 0.0624 (0.0482) lr 6.3188e-04 eta 0:07:55
epoch [33/50] batch [80/246] time 0.095 (0.107) data 0.000 (0.005) loss 0.8252 (1.2104) ce_loss 0.6504 (1.0577) teacher_loss 0.6488 (1.0555) loss_zs_kd 0.1956 (0.1674) loss_oracle 0.0786 (0.0711) acc 81.2500 (72.3438) kd_loss 0.0437 (0.0473) lr 6.3188e-04 eta 0:07:44
epoch [33/50] batch [100/246] time 0.101 (0.105) data 0.000 (0.004) loss 1.1756 (1.2074) ce_loss 0.9814 (1.0545) teacher_loss 0.9729 (1.0522) loss_zs_kd 0.2439 (0.1691) loss_oracle 0.0808 (0.0707) acc 75.0000 (72.4062) kd_loss 0.0683 (0.0481) lr 6.3188e-04 eta 0:07:36
epoch [33/50] batch [120/246] time 0.096 (0.105) data 0.000 (0.004) loss 1.8448 (1.2075) ce_loss 1.7246 (1.0552) teacher_loss 1.7169 (1.0523) loss_zs_kd 0.1471 (0.1683) loss_oracle 0.0543 (0.0711) acc 62.5000 (72.2135) kd_loss 0.0415 (0.0480) lr 6.3188e-04 eta 0:07:30
epoch [33/50] batch [140/246] time 0.096 (0.104) data 0.000 (0.003) loss 1.5791 (1.2166) ce_loss 1.4141 (1.0643) teacher_loss 1.4016 (1.0608) loss_zs_kd 0.1943 (0.1695) loss_oracle 0.0804 (0.0710) acc 65.6250 (72.1205) kd_loss 0.0693 (0.0478) lr 6.3188e-04 eta 0:07:25
epoch [33/50] batch [160/246] time 0.103 (0.103) data 0.000 (0.003) loss 1.0538 (1.1967) ce_loss 0.8784 (1.0447) teacher_loss 0.8705 (1.0414) loss_zs_kd 0.2031 (0.1698) loss_oracle 0.0818 (0.0704) acc 78.1250 (72.3828) kd_loss 0.0331 (0.0475) lr 6.3188e-04 eta 0:07:18
epoch [33/50] batch [180/246] time 0.094 (0.102) data 0.000 (0.002) loss 1.3944 (1.2045) ce_loss 1.2236 (1.0522) teacher_loss 1.2334 (1.0491) loss_zs_kd 0.1839 (0.1699) loss_oracle 0.0690 (0.0704) acc 68.7500 (72.2569) kd_loss 0.0459 (0.0469) lr 6.3188e-04 eta 0:07:13
epoch [33/50] batch [200/246] time 0.090 (0.101) data 0.000 (0.002) loss 1.0804 (1.2106) ce_loss 0.9395 (1.0587) teacher_loss 0.9282 (1.0553) loss_zs_kd 0.1321 (0.1692) loss_oracle 0.0862 (0.0707) acc 71.8750 (72.1875) kd_loss 0.0491 (0.0469) lr 6.3188e-04 eta 0:07:08
epoch [33/50] batch [220/246] time 0.092 (0.101) data 0.000 (0.002) loss 1.4229 (1.2099) ce_loss 1.2598 (1.0587) teacher_loss 1.2369 (1.0553) loss_zs_kd 0.1965 (0.1683) loss_oracle 0.0878 (0.0705) acc 65.6250 (72.0312) kd_loss 0.0541 (0.0469) lr 6.3188e-04 eta 0:07:03
epoch [33/50] batch [240/246] time 0.088 (0.100) data 0.000 (0.002) loss 1.3258 (1.2049) ce_loss 1.0820 (1.0524) teacher_loss 1.0832 (1.0494) loss_zs_kd 0.2675 (0.1694) loss_oracle 0.1089 (0.0707) acc 81.2500 (72.0964) kd_loss 0.0617 (0.0469) lr 6.3188e-04 eta 0:06:58
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,865
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.9%, epoch: 33 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [34/50] batch [20/246] time 0.113 (0.122) data 0.000 (0.014) loss 0.9040 (1.1315) ce_loss 0.7710 (0.9638) teacher_loss 0.7748 (0.9638) loss_zs_kd 0.1438 (0.1770) loss_oracle 0.0573 (0.0791) acc 78.1250 (74.3750) kd_loss 0.0328 (0.0535) lr 5.7422e-04 eta 0:08:26
epoch [34/50] batch [40/246] time 0.097 (0.109) data 0.000 (0.007) loss 1.2573 (1.2051) ce_loss 1.1221 (1.0397) teacher_loss 1.1253 (1.0389) loss_zs_kd 0.1520 (0.1811) loss_oracle 0.0559 (0.0756) acc 75.0000 (72.5000) kd_loss 0.0428 (0.0538) lr 5.7422e-04 eta 0:07:32
epoch [34/50] batch [60/246] time 0.093 (0.106) data 0.000 (0.005) loss 0.7872 (1.1624) ce_loss 0.6196 (0.9985) teacher_loss 0.6210 (0.9974) loss_zs_kd 0.1835 (0.1778) loss_oracle 0.0744 (0.0761) acc 87.5000 (73.9062) kd_loss 0.0546 (0.0548) lr 5.7422e-04 eta 0:07:15
epoch [34/50] batch [80/246] time 0.098 (0.102) data 0.000 (0.004) loss 1.1945 (1.1794) ce_loss 1.0420 (1.0175) teacher_loss 1.0361 (1.0158) loss_zs_kd 0.1457 (0.1738) loss_oracle 0.0856 (0.0766) acc 68.7500 (73.3594) kd_loss 0.0768 (0.0555) lr 5.7422e-04 eta 0:06:57
epoch [34/50] batch [100/246] time 0.089 (0.100) data 0.000 (0.003) loss 1.3655 (1.1913) ce_loss 1.1982 (1.0291) teacher_loss 1.1844 (1.0264) loss_zs_kd 0.2113 (0.1771) loss_oracle 0.0755 (0.0764) acc 68.7500 (72.5625) kd_loss 0.0751 (0.0564) lr 5.7422e-04 eta 0:06:46
epoch [34/50] batch [120/246] time 0.095 (0.099) data 0.001 (0.003) loss 1.1568 (1.1702) ce_loss 1.0117 (1.0090) teacher_loss 1.0100 (1.0065) loss_zs_kd 0.1335 (0.1747) loss_oracle 0.0800 (0.0764) acc 68.7500 (73.0469) kd_loss 0.0664 (0.0560) lr 5.7422e-04 eta 0:06:40
epoch [34/50] batch [140/246] time 0.091 (0.098) data 0.000 (0.002) loss 1.2479 (1.1834) ce_loss 1.0947 (1.0224) teacher_loss 1.1028 (1.0196) loss_zs_kd 0.1441 (0.1758) loss_oracle 0.0730 (0.0759) acc 75.0000 (72.9241) kd_loss 0.0419 (0.0554) lr 5.7422e-04 eta 0:06:35
epoch [34/50] batch [160/246] time 0.095 (0.097) data 0.000 (0.002) loss 0.8342 (1.1892) ce_loss 0.6685 (1.0282) teacher_loss 0.6728 (1.0255) loss_zs_kd 0.1832 (0.1764) loss_oracle 0.0698 (0.0756) acc 78.1250 (72.8516) kd_loss 0.0350 (0.0547) lr 5.7422e-04 eta 0:06:31
epoch [34/50] batch [180/246] time 0.100 (0.097) data 0.001 (0.002) loss 0.8819 (1.1927) ce_loss 0.7144 (1.0330) teacher_loss 0.7112 (1.0302) loss_zs_kd 0.1641 (0.1750) loss_oracle 0.0887 (0.0750) acc 81.2500 (72.7083) kd_loss 0.0668 (0.0541) lr 5.7422e-04 eta 0:06:27
epoch [34/50] batch [200/246] time 0.108 (0.097) data 0.000 (0.002) loss 1.0941 (1.2051) ce_loss 0.9800 (1.0453) teacher_loss 0.9738 (1.0421) loss_zs_kd 0.1158 (0.1761) loss_oracle 0.0623 (0.0750) acc 71.8750 (72.2656) kd_loss 0.0442 (0.0539) lr 5.7422e-04 eta 0:06:24
epoch [34/50] batch [220/246] time 0.086 (0.096) data 0.000 (0.001) loss 1.2337 (1.2055) ce_loss 1.0947 (1.0461) teacher_loss 1.0764 (1.0431) loss_zs_kd 0.1069 (0.1752) loss_oracle 0.1038 (0.0749) acc 68.7500 (72.3011) kd_loss 0.0804 (0.0534) lr 5.7422e-04 eta 0:06:19
epoch [34/50] batch [240/246] time 0.085 (0.095) data 0.000 (0.001) loss 1.4209 (1.2077) ce_loss 1.2832 (1.0486) teacher_loss 1.2774 (1.0458) loss_zs_kd 0.1612 (0.1747) loss_oracle 0.0629 (0.0746) acc 59.3750 (72.1875) kd_loss 0.0390 (0.0530) lr 5.7422e-04 eta 0:06:15
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,858
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,961
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.9%, epoch: 33 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [35/50] batch [20/246] time 0.115 (0.122) data 0.000 (0.011) loss 1.5474 (1.1608) ce_loss 1.3633 (1.0027) teacher_loss 1.3678 (1.0029) loss_zs_kd 0.1851 (0.1702) loss_oracle 0.0870 (0.0728) acc 59.3750 (73.9062) kd_loss 0.0544 (0.0440) lr 5.1825e-04 eta 0:07:56
epoch [35/50] batch [40/246] time 0.098 (0.114) data 0.001 (0.006) loss 1.4325 (1.2151) ce_loss 1.2705 (1.0572) teacher_loss 1.2408 (1.0555) loss_zs_kd 0.2006 (0.1745) loss_oracle 0.0914 (0.0724) acc 68.7500 (72.6562) kd_loss 0.0552 (0.0457) lr 5.1825e-04 eta 0:07:23
epoch [35/50] batch [60/246] time 0.097 (0.109) data 0.001 (0.004) loss 0.9934 (1.2108) ce_loss 0.8145 (1.0505) teacher_loss 0.8197 (1.0490) loss_zs_kd 0.1947 (0.1795) loss_oracle 0.0764 (0.0720) acc 78.1250 (72.4479) kd_loss 0.0478 (0.0474) lr 5.1825e-04 eta 0:07:03
epoch [35/50] batch [80/246] time 0.096 (0.107) data 0.000 (0.003) loss 2.1338 (1.2138) ce_loss 1.9375 (1.0544) teacher_loss 1.9220 (1.0523) loss_zs_kd 0.1871 (0.1763) loss_oracle 0.1183 (0.0734) acc 53.1250 (72.2656) kd_loss 0.0663 (0.0497) lr 5.1825e-04 eta 0:06:52
epoch [35/50] batch [100/246] time 0.103 (0.106) data 0.000 (0.003) loss 1.4309 (1.2088) ce_loss 1.2861 (1.0519) teacher_loss 1.2883 (1.0495) loss_zs_kd 0.1459 (0.1735) loss_oracle 0.0697 (0.0726) acc 56.2500 (72.3750) kd_loss 0.0567 (0.0512) lr 5.1825e-04 eta 0:06:45
epoch [35/50] batch [120/246] time 0.102 (0.105) data 0.000 (0.002) loss 1.0573 (1.2083) ce_loss 0.9189 (1.0499) teacher_loss 0.9242 (1.0480) loss_zs_kd 0.1474 (0.1741) loss_oracle 0.0595 (0.0733) acc 75.0000 (72.7083) kd_loss 0.0369 (0.0520) lr 5.1825e-04 eta 0:06:39
epoch [35/50] batch [140/246] time 0.103 (0.104) data 0.000 (0.002) loss 1.0076 (1.2096) ce_loss 0.8525 (1.0521) teacher_loss 0.8498 (1.0500) loss_zs_kd 0.1509 (0.1727) loss_oracle 0.0823 (0.0732) acc 75.0000 (72.6116) kd_loss 0.0581 (0.0526) lr 5.1825e-04 eta 0:06:34
epoch [35/50] batch [160/246] time 0.099 (0.103) data 0.000 (0.002) loss 0.7085 (1.2071) ce_loss 0.5776 (1.0507) teacher_loss 0.5853 (1.0492) loss_zs_kd 0.1527 (0.1721) loss_oracle 0.0469 (0.0719) acc 87.5000 (72.6367) kd_loss 0.0462 (0.0530) lr 5.1825e-04 eta 0:06:28
epoch [35/50] batch [180/246] time 0.097 (0.102) data 0.000 (0.002) loss 1.6319 (1.2035) ce_loss 1.4707 (1.0476) teacher_loss 1.4774 (1.0462) loss_zs_kd 0.1624 (0.1718) loss_oracle 0.0732 (0.0714) acc 71.8750 (72.7604) kd_loss 0.0648 (0.0530) lr 5.1825e-04 eta 0:06:24
epoch [35/50] batch [200/246] time 0.096 (0.102) data 0.000 (0.001) loss 1.1171 (1.2062) ce_loss 0.9399 (1.0499) teacher_loss 0.9392 (1.0485) loss_zs_kd 0.1842 (0.1712) loss_oracle 0.0858 (0.0721) acc 78.1250 (72.5312) kd_loss 0.0579 (0.0528) lr 5.1825e-04 eta 0:06:22
epoch [35/50] batch [220/246] time 0.098 (0.102) data 0.000 (0.001) loss 1.5612 (1.2121) ce_loss 1.3945 (1.0567) teacher_loss 1.3865 (1.0553) loss_zs_kd 0.1799 (0.1697) loss_oracle 0.0848 (0.0720) acc 59.3750 (72.3295) kd_loss 0.0576 (0.0522) lr 5.1825e-04 eta 0:06:20
epoch [35/50] batch [240/246] time 0.106 (0.102) data 0.000 (0.001) loss 1.1878 (1.2168) ce_loss 0.9995 (1.0600) teacher_loss 0.9849 (1.0583) loss_zs_kd 0.2054 (0.1712) loss_oracle 0.1003 (0.0729) acc 71.8750 (72.2526) kd_loss 0.0549 (0.0520) lr 5.1825e-04 eta 0:06:18
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,860
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.9%, epoch: 33 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [36/50] batch [20/246] time 0.095 (0.128) data 0.000 (0.019) loss 1.3276 (1.2494) ce_loss 1.1367 (1.0977) teacher_loss 1.1395 (1.0933) loss_zs_kd 0.2218 (0.1625) loss_oracle 0.0772 (0.0749) acc 68.7500 (70.3125) kd_loss 0.0595 (0.0511) lr 4.6417e-04 eta 0:07:49
epoch [36/50] batch [40/246] time 0.096 (0.114) data 0.000 (0.010) loss 1.6049 (1.2226) ce_loss 1.4717 (1.0669) teacher_loss 1.4701 (1.0633) loss_zs_kd 0.1715 (0.1715) loss_oracle 0.0490 (0.0735) acc 53.1250 (71.0938) kd_loss 0.0432 (0.0507) lr 4.6417e-04 eta 0:06:57
epoch [36/50] batch [60/246] time 0.097 (0.111) data 0.001 (0.006) loss 1.0751 (1.2329) ce_loss 0.9033 (1.0740) teacher_loss 0.9061 (1.0692) loss_zs_kd 0.2084 (0.1764) loss_oracle 0.0648 (0.0755) acc 75.0000 (70.9375) kd_loss 0.0427 (0.0496) lr 4.6417e-04 eta 0:06:42
epoch [36/50] batch [80/246] time 0.115 (0.109) data 0.000 (0.005) loss 1.3695 (1.2557) ce_loss 1.2266 (1.0950) teacher_loss 1.2271 (1.0898) loss_zs_kd 0.1309 (0.1793) loss_oracle 0.0770 (0.0763) acc 62.5000 (70.4297) kd_loss 0.0454 (0.0489) lr 4.6417e-04 eta 0:06:34
epoch [36/50] batch [100/246] time 0.088 (0.107) data 0.000 (0.004) loss 1.5753 (1.2494) ce_loss 1.4121 (1.0871) teacher_loss 1.3920 (1.0825) loss_zs_kd 0.2011 (0.1795) loss_oracle 0.0828 (0.0772) acc 62.5000 (70.7188) kd_loss 0.0412 (0.0481) lr 4.6417e-04 eta 0:06:23
epoch [36/50] batch [120/246] time 0.089 (0.105) data 0.000 (0.003) loss 0.8863 (1.2440) ce_loss 0.7495 (1.0805) teacher_loss 0.7518 (1.0760) loss_zs_kd 0.1548 (0.1801) loss_oracle 0.0571 (0.0779) acc 84.3750 (71.1198) kd_loss 0.0300 (0.0482) lr 4.6417e-04 eta 0:06:13
epoch [36/50] batch [140/246] time 0.096 (0.104) data 0.000 (0.003) loss 1.2627 (1.2361) ce_loss 1.1670 (1.0747) teacher_loss 1.1620 (1.0708) loss_zs_kd 0.0984 (0.1771) loss_oracle 0.0515 (0.0767) acc 68.7500 (71.4732) kd_loss 0.0449 (0.0480) lr 4.6417e-04 eta 0:06:07
epoch [36/50] batch [160/246] time 0.099 (0.103) data 0.000 (0.003) loss 0.6680 (1.2210) ce_loss 0.4800 (1.0609) teacher_loss 0.4828 (1.0570) loss_zs_kd 0.2219 (0.1754) loss_oracle 0.0743 (0.0762) acc 87.5000 (71.7383) kd_loss 0.0387 (0.0482) lr 4.6417e-04 eta 0:06:02
epoch [36/50] batch [180/246] time 0.093 (0.102) data 0.000 (0.002) loss 1.0597 (1.2183) ce_loss 0.9175 (1.0579) teacher_loss 0.9167 (1.0539) loss_zs_kd 0.1374 (0.1764) loss_oracle 0.0743 (0.0762) acc 71.8750 (71.9618) kd_loss 0.0581 (0.0476) lr 4.6417e-04 eta 0:05:57
epoch [36/50] batch [200/246] time 0.090 (0.101) data 0.000 (0.002) loss 1.3913 (1.2254) ce_loss 1.2100 (1.0660) teacher_loss 1.2093 (1.0618) loss_zs_kd 0.1773 (0.1762) loss_oracle 0.0934 (0.0754) acc 68.7500 (71.7656) kd_loss 0.0502 (0.0473) lr 4.6417e-04 eta 0:05:53
epoch [36/50] batch [220/246] time 0.103 (0.101) data 0.000 (0.002) loss 0.7851 (1.2192) ce_loss 0.6572 (1.0600) teacher_loss 0.6585 (1.0561) loss_zs_kd 0.1075 (0.1750) loss_oracle 0.0728 (0.0756) acc 87.5000 (72.0739) kd_loss 0.0358 (0.0465) lr 4.6417e-04 eta 0:05:49
epoch [36/50] batch [240/246] time 0.085 (0.100) data 0.000 (0.002) loss 1.2441 (1.2083) ce_loss 1.0557 (1.0496) teacher_loss 1.0623 (1.0457) loss_zs_kd 0.2100 (0.1742) loss_oracle 0.0768 (0.0755) acc 75.0000 (72.4349) kd_loss 0.0456 (0.0460) lr 4.6417e-04 eta 0:05:44
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,866
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,960
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.5%, epoch: 36 *******
******* Domain r best val test acc: 90.9%, epoch: 36 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [37/50] batch [20/246] time 0.098 (0.110) data 0.000 (0.014) loss 1.3658 (1.2823) ce_loss 1.2500 (1.1208) teacher_loss 1.2357 (1.1167) loss_zs_kd 0.1231 (0.1749) loss_oracle 0.0686 (0.0782) acc 65.6250 (71.2500) kd_loss 0.0509 (0.0405) lr 4.1221e-04 eta 0:06:15
epoch [37/50] batch [40/246] time 0.095 (0.102) data 0.000 (0.007) loss 1.5974 (1.2460) ce_loss 1.4736 (1.0834) teacher_loss 1.4752 (1.0808) loss_zs_kd 0.1327 (0.1723) loss_oracle 0.0559 (0.0791) acc 65.6250 (71.3281) kd_loss 0.0263 (0.0395) lr 4.1221e-04 eta 0:05:47
epoch [37/50] batch [60/246] time 0.095 (0.100) data 0.001 (0.005) loss 0.8860 (1.2294) ce_loss 0.7310 (1.0668) teacher_loss 0.7364 (1.0644) loss_zs_kd 0.1892 (0.1735) loss_oracle 0.0550 (0.0782) acc 68.7500 (71.9792) kd_loss 0.0569 (0.0426) lr 4.1221e-04 eta 0:05:39
epoch [37/50] batch [80/246] time 0.110 (0.100) data 0.001 (0.004) loss 1.0567 (1.2128) ce_loss 0.8833 (1.0526) teacher_loss 0.8861 (1.0501) loss_zs_kd 0.1800 (0.1722) loss_oracle 0.0806 (0.0766) acc 75.0000 (71.9922) kd_loss 0.0363 (0.0436) lr 4.1221e-04 eta 0:05:36
epoch [37/50] batch [100/246] time 0.125 (0.104) data 0.000 (0.003) loss 1.7265 (1.2141) ce_loss 1.5869 (1.0540) teacher_loss 1.5929 (1.0512) loss_zs_kd 0.1455 (0.1719) loss_oracle 0.0608 (0.0770) acc 56.2500 (71.8125) kd_loss 0.0270 (0.0425) lr 4.1221e-04 eta 0:05:47
epoch [37/50] batch [120/246] time 0.116 (0.107) data 0.001 (0.003) loss 1.3536 (1.2223) ce_loss 1.2109 (1.0625) teacher_loss 1.2012 (1.0593) loss_zs_kd 0.1569 (0.1732) loss_oracle 0.0740 (0.0764) acc 65.6250 (71.7188) kd_loss 0.0426 (0.0431) lr 4.1221e-04 eta 0:05:54
epoch [37/50] batch [140/246] time 0.117 (0.108) data 0.000 (0.002) loss 0.9670 (1.2279) ce_loss 0.7935 (1.0671) teacher_loss 0.7847 (1.0642) loss_zs_kd 0.1927 (0.1731) loss_oracle 0.0859 (0.0771) acc 81.2500 (71.8080) kd_loss 0.0447 (0.0428) lr 4.1221e-04 eta 0:05:57
epoch [37/50] batch [160/246] time 0.125 (0.110) data 0.000 (0.002) loss 1.3884 (1.2152) ce_loss 1.2070 (1.0554) teacher_loss 1.2105 (1.0524) loss_zs_kd 0.1768 (0.1717) loss_oracle 0.0895 (0.0770) acc 71.8750 (72.2656) kd_loss 0.0453 (0.0427) lr 4.1221e-04 eta 0:06:00
epoch [37/50] batch [180/246] time 0.141 (0.111) data 0.002 (0.002) loss 1.2101 (1.2128) ce_loss 1.0693 (1.0548) teacher_loss 1.0732 (1.0516) loss_zs_kd 0.1441 (0.1695) loss_oracle 0.0649 (0.0765) acc 65.6250 (72.1181) kd_loss 0.0444 (0.0425) lr 4.1221e-04 eta 0:06:03
epoch [37/50] batch [200/246] time 0.118 (0.112) data 0.000 (0.002) loss 1.0133 (1.2101) ce_loss 0.8604 (1.0518) teacher_loss 0.8676 (1.0487) loss_zs_kd 0.1303 (0.1703) loss_oracle 0.0806 (0.0763) acc 78.1250 (72.1094) kd_loss 0.0441 (0.0425) lr 4.1221e-04 eta 0:06:04
epoch [37/50] batch [220/246] time 0.126 (0.113) data 0.000 (0.002) loss 1.7588 (1.2135) ce_loss 1.5908 (1.0552) teacher_loss 1.5855 (1.0521) loss_zs_kd 0.1923 (0.1699) loss_oracle 0.0772 (0.0765) acc 65.6250 (72.0739) kd_loss 0.0657 (0.0432) lr 4.1221e-04 eta 0:06:03
epoch [37/50] batch [240/246] time 0.103 (0.113) data 0.000 (0.002) loss 1.1414 (1.2123) ce_loss 1.0127 (1.0538) teacher_loss 1.0129 (1.0506) loss_zs_kd 0.1297 (0.1695) loss_oracle 0.0636 (0.0769) acc 71.8750 (72.2135) kd_loss 0.0357 (0.0441) lr 4.1221e-04 eta 0:06:00
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,865
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 36 *******
******* Domain r best val test acc: 90.9%, epoch: 36 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [38/50] batch [20/246] time 0.112 (0.120) data 0.000 (0.017) loss 1.3399 (1.3053) ce_loss 1.1807 (1.1480) teacher_loss 1.1761 (1.1440) loss_zs_kd 0.1411 (0.1784) loss_oracle 0.0933 (0.0721) acc 68.7500 (71.0938) kd_loss 0.0594 (0.0495) lr 3.6258e-04 eta 0:06:21
epoch [38/50] batch [40/246] time 0.097 (0.109) data 0.000 (0.009) loss 1.0159 (1.3009) ce_loss 0.8159 (1.1407) teacher_loss 0.8202 (1.1347) loss_zs_kd 0.1957 (0.1828) loss_oracle 0.0979 (0.0748) acc 71.8750 (70.9375) kd_loss 0.0644 (0.0519) lr 3.6258e-04 eta 0:05:43
epoch [38/50] batch [60/246] time 0.109 (0.106) data 0.000 (0.006) loss 1.4922 (1.2684) ce_loss 1.3418 (1.1067) teacher_loss 1.3382 (1.1017) loss_zs_kd 0.1401 (0.1804) loss_oracle 0.0840 (0.0766) acc 62.5000 (71.8750) kd_loss 0.0459 (0.0531) lr 3.6258e-04 eta 0:05:31
epoch [38/50] batch [80/246] time 0.103 (0.105) data 0.000 (0.004) loss 1.5536 (1.2569) ce_loss 1.3877 (1.0965) teacher_loss 1.3750 (1.0922) loss_zs_kd 0.1785 (0.1789) loss_oracle 0.0894 (0.0752) acc 65.6250 (71.6797) kd_loss 0.0666 (0.0534) lr 3.6258e-04 eta 0:05:26
epoch [38/50] batch [100/246] time 0.118 (0.104) data 0.000 (0.004) loss 1.7284 (1.2564) ce_loss 1.5811 (1.0964) teacher_loss 1.5840 (1.0924) loss_zs_kd 0.1470 (0.1765) loss_oracle 0.0709 (0.0758) acc 59.3750 (71.5312) kd_loss 0.0519 (0.0530) lr 3.6258e-04 eta 0:05:22
epoch [38/50] batch [120/246] time 0.100 (0.103) data 0.000 (0.003) loss 1.0226 (1.2505) ce_loss 0.8833 (1.0914) teacher_loss 0.8753 (1.0878) loss_zs_kd 0.1618 (0.1735) loss_oracle 0.0664 (0.0759) acc 75.0000 (71.5365) kd_loss 0.0522 (0.0524) lr 3.6258e-04 eta 0:05:18
epoch [38/50] batch [140/246] time 0.089 (0.102) data 0.000 (0.003) loss 0.8980 (1.2353) ce_loss 0.7642 (1.0754) teacher_loss 0.7626 (1.0719) loss_zs_kd 0.1281 (0.1728) loss_oracle 0.0713 (0.0770) acc 75.0000 (71.8304) kd_loss 0.0532 (0.0529) lr 3.6258e-04 eta 0:05:12
epoch [38/50] batch [160/246] time 0.102 (0.101) data 0.001 (0.002) loss 1.0012 (1.2404) ce_loss 0.8364 (1.0814) teacher_loss 0.8296 (1.0777) loss_zs_kd 0.1605 (0.1718) loss_oracle 0.0914 (0.0768) acc 75.0000 (71.5625) kd_loss 0.0484 (0.0529) lr 3.6258e-04 eta 0:05:08
epoch [38/50] batch [180/246] time 0.082 (0.100) data 0.000 (0.002) loss 1.0191 (1.2356) ce_loss 0.8511 (1.0758) teacher_loss 0.8613 (1.0717) loss_zs_kd 0.1829 (0.1735) loss_oracle 0.0665 (0.0771) acc 78.1250 (71.7188) kd_loss 0.0422 (0.0531) lr 3.6258e-04 eta 0:05:02
epoch [38/50] batch [200/246] time 0.103 (0.100) data 0.000 (0.002) loss 1.0941 (1.2298) ce_loss 0.9219 (1.0707) teacher_loss 0.9172 (1.0666) loss_zs_kd 0.1823 (0.1724) loss_oracle 0.0857 (0.0770) acc 71.8750 (71.8281) kd_loss 0.0482 (0.0526) lr 3.6258e-04 eta 0:04:59
epoch [38/50] batch [220/246] time 0.092 (0.100) data 0.000 (0.002) loss 1.0234 (1.2288) ce_loss 0.8779 (1.0704) teacher_loss 0.8846 (1.0663) loss_zs_kd 0.1503 (0.1719) loss_oracle 0.0636 (0.0765) acc 78.1250 (71.8608) kd_loss 0.0358 (0.0522) lr 3.6258e-04 eta 0:04:56
epoch [38/50] batch [240/246] time 0.081 (0.099) data 0.000 (0.002) loss 1.4934 (1.2286) ce_loss 1.3125 (1.0696) teacher_loss 1.3104 (1.0656) loss_zs_kd 0.2296 (0.1728) loss_oracle 0.0683 (0.0767) acc 62.5000 (71.8229) kd_loss 0.0411 (0.0522) lr 3.6258e-04 eta 0:04:51
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,864
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,960
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.5%, epoch: 36 *******
******* Domain r best val test acc: 90.9%, epoch: 36 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [39/50] batch [20/246] time 0.101 (0.118) data 0.000 (0.016) loss 0.8722 (1.1938) ce_loss 0.7490 (1.0260) teacher_loss 0.7366 (1.0209) loss_zs_kd 0.1165 (0.1796) loss_oracle 0.0773 (0.0830) acc 87.5000 (73.1250) kd_loss 0.0547 (0.0496) lr 3.1545e-04 eta 0:05:45
epoch [39/50] batch [40/246] time 0.106 (0.109) data 0.000 (0.008) loss 0.8412 (1.1956) ce_loss 0.6748 (1.0286) teacher_loss 0.6752 (1.0227) loss_zs_kd 0.1255 (0.1784) loss_oracle 0.1033 (0.0836) acc 81.2500 (72.7344) kd_loss 0.0426 (0.0529) lr 3.1545e-04 eta 0:05:17
epoch [39/50] batch [60/246] time 0.097 (0.106) data 0.001 (0.005) loss 1.0959 (1.2048) ce_loss 0.9526 (1.0391) teacher_loss 0.9390 (1.0332) loss_zs_kd 0.1449 (0.1753) loss_oracle 0.0845 (0.0840) acc 78.1250 (72.0312) kd_loss 0.0516 (0.0553) lr 3.1545e-04 eta 0:05:07
epoch [39/50] batch [80/246] time 0.091 (0.104) data 0.000 (0.004) loss 1.6094 (1.2085) ce_loss 1.4492 (1.0437) teacher_loss 1.4528 (1.0380) loss_zs_kd 0.1452 (0.1729) loss_oracle 0.0839 (0.0841) acc 65.6250 (71.9922) kd_loss 0.0541 (0.0548) lr 3.1545e-04 eta 0:05:00
epoch [39/50] batch [100/246] time 0.103 (0.104) data 0.000 (0.003) loss 1.3476 (1.2239) ce_loss 1.1504 (1.0589) teacher_loss 1.1405 (1.0535) loss_zs_kd 0.2513 (0.1749) loss_oracle 0.0815 (0.0830) acc 65.6250 (71.4688) kd_loss 0.0680 (0.0542) lr 3.1545e-04 eta 0:04:57
epoch [39/50] batch [120/246] time 0.101 (0.103) data 0.000 (0.003) loss 1.1635 (1.2208) ce_loss 0.9985 (1.0540) teacher_loss 0.9937 (1.0484) loss_zs_kd 0.1485 (0.1785) loss_oracle 0.0956 (0.0832) acc 71.8750 (72.0052) kd_loss 0.0554 (0.0545) lr 3.1545e-04 eta 0:04:52
epoch [39/50] batch [140/246] time 0.103 (0.103) data 0.000 (0.002) loss 1.8186 (1.2423) ce_loss 1.6533 (1.0753) teacher_loss 1.6526 (1.0698) loss_zs_kd 0.2050 (0.1805) loss_oracle 0.0635 (0.0823) acc 65.6250 (71.5848) kd_loss 0.0763 (0.0550) lr 3.1545e-04 eta 0:04:49
epoch [39/50] batch [160/246] time 0.104 (0.103) data 0.000 (0.002) loss 1.1946 (1.2443) ce_loss 1.0244 (1.0772) teacher_loss 1.0153 (1.0720) loss_zs_kd 0.1777 (0.1807) loss_oracle 0.0905 (0.0820) acc 78.1250 (71.5039) kd_loss 0.0914 (0.0555) lr 3.1545e-04 eta 0:04:46
epoch [39/50] batch [180/246] time 0.102 (0.102) data 0.000 (0.002) loss 1.0678 (1.2348) ce_loss 0.8691 (1.0686) teacher_loss 0.8633 (1.0637) loss_zs_kd 0.2398 (0.1797) loss_oracle 0.0847 (0.0812) acc 75.0000 (71.7535) kd_loss 0.0733 (0.0558) lr 3.1545e-04 eta 0:04:43
epoch [39/50] batch [200/246] time 0.096 (0.102) data 0.000 (0.002) loss 1.2787 (1.2379) ce_loss 1.0947 (1.0707) teacher_loss 1.0807 (1.0660) loss_zs_kd 0.1967 (0.1807) loss_oracle 0.0997 (0.0815) acc 65.6250 (71.6562) kd_loss 0.0766 (0.0567) lr 3.1545e-04 eta 0:04:41
epoch [39/50] batch [220/246] time 0.100 (0.102) data 0.001 (0.002) loss 1.3071 (1.2428) ce_loss 1.1357 (1.0758) teacher_loss 1.1501 (1.0715) loss_zs_kd 0.1633 (0.1797) loss_oracle 0.0753 (0.0815) acc 65.6250 (71.4631) kd_loss 0.0580 (0.0569) lr 3.1545e-04 eta 0:04:38
epoch [39/50] batch [240/246] time 0.107 (0.102) data 0.001 (0.002) loss 0.9860 (1.2403) ce_loss 0.8457 (1.0737) teacher_loss 0.8437 (1.0695) loss_zs_kd 0.1366 (0.1792) loss_oracle 0.0741 (0.0811) acc 78.1250 (71.5885) kd_loss 0.0455 (0.0568) lr 3.1545e-04 eta 0:04:35
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,863
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.5%, epoch: 36 *******
******* Domain r best val test acc: 90.9%, epoch: 36 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [40/50] batch [20/246] time 0.132 (0.133) data 0.000 (0.014) loss 0.6893 (1.2876) ce_loss 0.4927 (1.1192) teacher_loss 0.4927 (1.1160) loss_zs_kd 0.2322 (0.1908) loss_oracle 0.0805 (0.0762) acc 87.5000 (68.4375) kd_loss 0.0414 (0.0513) lr 2.7103e-04 eta 0:05:56
epoch [40/50] batch [40/246] time 0.126 (0.130) data 0.000 (0.007) loss 1.5319 (1.2440) ce_loss 1.3496 (1.0731) teacher_loss 1.3539 (1.0695) loss_zs_kd 0.2047 (0.1906) loss_oracle 0.0757 (0.0793) acc 65.6250 (71.4062) kd_loss 0.0396 (0.0536) lr 2.7103e-04 eta 0:05:45
epoch [40/50] batch [60/246] time 0.125 (0.130) data 0.001 (0.005) loss 0.9438 (1.2330) ce_loss 0.7505 (1.0646) teacher_loss 0.7541 (1.0609) loss_zs_kd 0.2439 (0.1871) loss_oracle 0.0678 (0.0786) acc 75.0000 (71.7188) kd_loss 0.0488 (0.0512) lr 2.7103e-04 eta 0:05:43
epoch [40/50] batch [80/246] time 0.126 (0.129) data 0.000 (0.004) loss 1.2779 (1.2233) ce_loss 1.0977 (1.0562) teacher_loss 1.0906 (1.0534) loss_zs_kd 0.2162 (0.1834) loss_oracle 0.0792 (0.0782) acc 71.8750 (72.7734) kd_loss 0.0478 (0.0511) lr 2.7103e-04 eta 0:05:39
epoch [40/50] batch [100/246] time 0.131 (0.129) data 0.000 (0.003) loss 1.3288 (1.2090) ce_loss 1.1553 (1.0417) teacher_loss 1.1533 (1.0384) loss_zs_kd 0.1965 (0.1821) loss_oracle 0.0772 (0.0796) acc 62.5000 (73.1562) kd_loss 0.0507 (0.0513) lr 2.7103e-04 eta 0:05:37
epoch [40/50] batch [120/246] time 0.135 (0.130) data 0.000 (0.003) loss 1.2869 (1.1902) ce_loss 1.1211 (1.0238) teacher_loss 1.1275 (1.0207) loss_zs_kd 0.1937 (0.1789) loss_oracle 0.0625 (0.0800) acc 75.0000 (73.7500) kd_loss 0.0381 (0.0511) lr 2.7103e-04 eta 0:05:34
epoch [40/50] batch [140/246] time 0.124 (0.130) data 0.000 (0.002) loss 1.5169 (1.1739) ce_loss 1.3613 (1.0095) teacher_loss 1.3553 (1.0068) loss_zs_kd 0.1558 (0.1754) loss_oracle 0.0836 (0.0794) acc 56.2500 (73.9955) kd_loss 0.0305 (0.0503) lr 2.7103e-04 eta 0:05:32
epoch [40/50] batch [160/246] time 0.124 (0.130) data 0.000 (0.002) loss 1.4001 (1.1816) ce_loss 1.2432 (1.0173) teacher_loss 1.2420 (1.0142) loss_zs_kd 0.2012 (0.1765) loss_oracle 0.0575 (0.0791) acc 65.6250 (73.5742) kd_loss 0.0495 (0.0500) lr 2.7103e-04 eta 0:05:29
epoch [40/50] batch [180/246] time 0.129 (0.130) data 0.000 (0.002) loss 1.1127 (1.1924) ce_loss 0.8887 (1.0277) teacher_loss 0.8892 (1.0245) loss_zs_kd 0.2810 (0.1778) loss_oracle 0.0831 (0.0791) acc 71.8750 (73.2292) kd_loss 0.0668 (0.0495) lr 2.7103e-04 eta 0:05:27
epoch [40/50] batch [200/246] time 0.130 (0.130) data 0.000 (0.002) loss 1.0763 (1.1972) ce_loss 0.9512 (1.0331) teacher_loss 0.9402 (1.0296) loss_zs_kd 0.1499 (0.1765) loss_oracle 0.0612 (0.0794) acc 78.1250 (73.1094) kd_loss 0.0557 (0.0494) lr 2.7103e-04 eta 0:05:24
epoch [40/50] batch [220/246] time 0.119 (0.129) data 0.000 (0.002) loss 1.3924 (1.1981) ce_loss 1.1982 (1.0332) teacher_loss 1.2068 (1.0297) loss_zs_kd 0.2249 (0.1774) loss_oracle 0.0732 (0.0797) acc 68.7500 (72.9261) kd_loss 0.0504 (0.0493) lr 2.7103e-04 eta 0:05:21
epoch [40/50] batch [240/246] time 0.101 (0.128) data 0.000 (0.002) loss 1.5510 (1.2032) ce_loss 1.3828 (1.0379) teacher_loss 1.3832 (1.0343) loss_zs_kd 0.1702 (0.1775) loss_oracle 0.0827 (0.0802) acc 68.7500 (72.8125) kd_loss 0.0803 (0.0495) lr 2.7103e-04 eta 0:05:15
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,861
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 36 *******
******* Domain r best val test acc: 90.9%, epoch: 36 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [41/50] batch [20/246] time 0.103 (0.117) data 0.000 (0.014) loss 1.5231 (1.1745) ce_loss 1.3262 (1.0158) teacher_loss 1.3262 (1.0147) loss_zs_kd 0.2584 (0.1738) loss_oracle 0.0677 (0.0729) acc 62.5000 (73.1250) kd_loss 0.0280 (0.0475) lr 2.2949e-04 eta 0:04:45
epoch [41/50] batch [40/246] time 0.095 (0.110) data 0.000 (0.007) loss 1.8167 (1.2073) ce_loss 1.6113 (1.0393) teacher_loss 1.5860 (1.0356) loss_zs_kd 0.2742 (0.1829) loss_oracle 0.0937 (0.0803) acc 62.5000 (73.4375) kd_loss 0.0567 (0.0490) lr 2.2949e-04 eta 0:04:25
epoch [41/50] batch [60/246] time 0.097 (0.107) data 0.000 (0.005) loss 1.1914 (1.1807) ce_loss 1.0098 (1.0145) teacher_loss 1.0172 (1.0099) loss_zs_kd 0.1632 (0.1766) loss_oracle 0.0926 (0.0824) acc 75.0000 (72.8125) kd_loss 0.0377 (0.0502) lr 2.2949e-04 eta 0:04:17
epoch [41/50] batch [80/246] time 0.125 (0.106) data 0.000 (0.004) loss 1.0112 (1.1830) ce_loss 0.8525 (1.0199) teacher_loss 0.8448 (1.0142) loss_zs_kd 0.2223 (0.1746) loss_oracle 0.0552 (0.0815) acc 78.1250 (72.3438) kd_loss 0.0450 (0.0511) lr 2.2949e-04 eta 0:04:13
epoch [41/50] batch [100/246] time 0.126 (0.110) data 0.001 (0.003) loss 0.9028 (1.2078) ce_loss 0.7744 (1.0436) teacher_loss 0.7770 (1.0382) loss_zs_kd 0.1442 (0.1768) loss_oracle 0.0537 (0.0812) acc 75.0000 (71.9375) kd_loss 0.0296 (0.0514) lr 2.2949e-04 eta 0:04:20
epoch [41/50] batch [120/246] time 0.130 (0.113) data 0.000 (0.003) loss 1.2759 (1.2245) ce_loss 1.1240 (1.0591) teacher_loss 1.1241 (1.0539) loss_zs_kd 0.1782 (0.1770) loss_oracle 0.0627 (0.0821) acc 71.8750 (71.6406) kd_loss 0.0422 (0.0515) lr 2.2949e-04 eta 0:04:24
epoch [41/50] batch [140/246] time 0.116 (0.115) data 0.000 (0.002) loss 1.1913 (1.2171) ce_loss 1.0029 (1.0512) teacher_loss 0.9885 (1.0460) loss_zs_kd 0.1826 (0.1766) loss_oracle 0.1114 (0.0829) acc 71.8750 (71.9196) kd_loss 0.0551 (0.0518) lr 2.2949e-04 eta 0:04:27
epoch [41/50] batch [160/246] time 0.131 (0.117) data 0.000 (0.002) loss 1.3655 (1.2084) ce_loss 1.1631 (1.0426) teacher_loss 1.1678 (1.0375) loss_zs_kd 0.2119 (0.1760) loss_oracle 0.0918 (0.0829) acc 68.7500 (72.1289) kd_loss 0.0499 (0.0522) lr 2.2949e-04 eta 0:04:28
epoch [41/50] batch [180/246] time 0.132 (0.118) data 0.002 (0.002) loss 1.0566 (1.2163) ce_loss 0.8687 (1.0496) teacher_loss 0.8716 (1.0452) loss_zs_kd 0.1950 (0.1771) loss_oracle 0.0875 (0.0826) acc 75.0000 (71.8576) kd_loss 0.0649 (0.0524) lr 2.2949e-04 eta 0:04:28
epoch [41/50] batch [200/246] time 0.129 (0.119) data 0.000 (0.002) loss 1.2499 (1.2096) ce_loss 1.0752 (1.0430) teacher_loss 1.0793 (1.0387) loss_zs_kd 0.1838 (0.1770) loss_oracle 0.0787 (0.0823) acc 75.0000 (72.0000) kd_loss 0.0393 (0.0524) lr 2.2949e-04 eta 0:04:27
epoch [41/50] batch [220/246] time 0.122 (0.119) data 0.000 (0.002) loss 1.5468 (1.2064) ce_loss 1.3613 (1.0399) teacher_loss 1.3556 (1.0352) loss_zs_kd 0.1616 (0.1768) loss_oracle 0.1105 (0.0829) acc 68.7500 (72.0597) kd_loss 0.0603 (0.0531) lr 2.2949e-04 eta 0:04:27
epoch [41/50] batch [240/246] time 0.105 (0.119) data 0.000 (0.002) loss 1.1301 (1.2112) ce_loss 0.9688 (1.0446) teacher_loss 0.9659 (1.0399) loss_zs_kd 0.2006 (0.1779) loss_oracle 0.0639 (0.0823) acc 75.0000 (71.9401) kd_loss 0.0700 (0.0535) lr 2.2949e-04 eta 0:04:23
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,860
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.5%, epoch: 36 *******
******* Domain r best val test acc: 90.9%, epoch: 36 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [42/50] batch [20/246] time 0.088 (0.108) data 0.000 (0.012) loss 0.7101 (1.1853) ce_loss 0.5586 (1.0246) teacher_loss 0.5663 (1.0212) loss_zs_kd 0.1364 (0.1652) loss_oracle 0.0756 (0.0815) acc 87.5000 (72.3438) kd_loss 0.0594 (0.0610) lr 1.9098e-04 eta 0:03:57
epoch [42/50] batch [40/246] time 0.090 (0.099) data 0.000 (0.006) loss 1.1764 (1.1848) ce_loss 0.9531 (1.0193) teacher_loss 0.9463 (1.0166) loss_zs_kd 0.2678 (0.1739) loss_oracle 0.0962 (0.0813) acc 78.1250 (72.6562) kd_loss 0.0758 (0.0585) lr 1.9098e-04 eta 0:03:35
epoch [42/50] batch [60/246] time 0.092 (0.096) data 0.000 (0.004) loss 1.7152 (1.1955) ce_loss 1.5703 (1.0343) teacher_loss 1.5711 (1.0318) loss_zs_kd 0.1673 (0.1709) loss_oracle 0.0604 (0.0782) acc 62.5000 (72.1875) kd_loss 0.0694 (0.0587) lr 1.9098e-04 eta 0:03:27
epoch [42/50] batch [80/246] time 0.094 (0.095) data 0.000 (0.003) loss 1.2598 (1.2176) ce_loss 1.1240 (1.0540) teacher_loss 1.1118 (1.0508) loss_zs_kd 0.1591 (0.1766) loss_oracle 0.0685 (0.0784) acc 71.8750 (71.5234) kd_loss 0.0445 (0.0588) lr 1.9098e-04 eta 0:03:23
epoch [42/50] batch [100/246] time 0.088 (0.094) data 0.000 (0.003) loss 1.5211 (1.2142) ce_loss 1.3281 (1.0501) teacher_loss 1.3419 (1.0474) loss_zs_kd 0.1918 (0.1768) loss_oracle 0.0833 (0.0784) acc 59.3750 (71.5625) kd_loss 0.0795 (0.0578) lr 1.9098e-04 eta 0:03:19
epoch [42/50] batch [120/246] time 0.090 (0.094) data 0.000 (0.002) loss 1.6596 (1.2119) ce_loss 1.5029 (1.0462) teacher_loss 1.5074 (1.0431) loss_zs_kd 0.1716 (0.1799) loss_oracle 0.0664 (0.0789) acc 59.3750 (71.5104) kd_loss 0.0375 (0.0572) lr 1.9098e-04 eta 0:03:16
epoch [42/50] batch [140/246] time 0.094 (0.094) data 0.000 (0.002) loss 0.7770 (1.2168) ce_loss 0.6094 (1.0500) teacher_loss 0.6038 (1.0464) loss_zs_kd 0.1838 (0.1803) loss_oracle 0.0813 (0.0803) acc 84.3750 (71.6071) kd_loss 0.0515 (0.0571) lr 1.9098e-04 eta 0:03:15
epoch [42/50] batch [160/246] time 0.095 (0.094) data 0.000 (0.002) loss 1.2224 (1.2186) ce_loss 1.0732 (1.0505) teacher_loss 1.0599 (1.0462) loss_zs_kd 0.1616 (0.1804) loss_oracle 0.0817 (0.0822) acc 71.8750 (71.6602) kd_loss 0.0595 (0.0579) lr 1.9098e-04 eta 0:03:13
epoch [42/50] batch [180/246] time 0.099 (0.095) data 0.000 (0.002) loss 1.1099 (1.2210) ce_loss 0.9619 (1.0518) teacher_loss 0.9750 (1.0481) loss_zs_kd 0.1671 (0.1813) loss_oracle 0.0513 (0.0823) acc 81.2500 (71.5104) kd_loss 0.0424 (0.0578) lr 1.9098e-04 eta 0:03:12
epoch [42/50] batch [200/246] time 0.092 (0.095) data 0.000 (0.001) loss 1.4594 (1.2297) ce_loss 1.2451 (1.0602) teacher_loss 1.2463 (1.0565) loss_zs_kd 0.2497 (0.1813) loss_oracle 0.0882 (0.0826) acc 59.3750 (71.3906) kd_loss 0.0645 (0.0578) lr 1.9098e-04 eta 0:03:10
epoch [42/50] batch [220/246] time 0.084 (0.094) data 0.000 (0.001) loss 0.9945 (1.2232) ce_loss 0.8203 (1.0533) teacher_loss 0.8188 (1.0498) loss_zs_kd 0.1774 (0.1818) loss_oracle 0.0870 (0.0825) acc 81.2500 (71.6761) kd_loss 0.0547 (0.0577) lr 1.9098e-04 eta 0:03:08
epoch [42/50] batch [240/246] time 0.087 (0.094) data 0.000 (0.001) loss 1.2993 (1.2221) ce_loss 1.1406 (1.0531) teacher_loss 1.1421 (1.0497) loss_zs_kd 0.1277 (0.1804) loss_oracle 0.0934 (0.0822) acc 62.5000 (71.7448) kd_loss 0.0500 (0.0581) lr 1.9098e-04 eta 0:03:05
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,867
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [43/50] batch [20/246] time 0.102 (0.117) data 0.000 (0.013) loss 0.8714 (1.2270) ce_loss 0.7280 (1.0560) teacher_loss 0.7254 (1.0497) loss_zs_kd 0.1623 (0.1895) loss_oracle 0.0648 (0.0825) acc 87.5000 (72.3438) kd_loss 0.0464 (0.0613) lr 1.5567e-04 eta 0:03:47
epoch [43/50] batch [40/246] time 0.103 (0.111) data 0.000 (0.007) loss 1.5537 (1.1864) ce_loss 1.3896 (1.0154) teacher_loss 1.3840 (1.0100) loss_zs_kd 0.1557 (0.1855) loss_oracle 0.0918 (0.0837) acc 62.5000 (72.7344) kd_loss 0.0597 (0.0613) lr 1.5567e-04 eta 0:03:34
epoch [43/50] batch [60/246] time 0.097 (0.108) data 0.000 (0.005) loss 1.9644 (1.2282) ce_loss 1.7861 (1.0576) teacher_loss 1.7779 (1.0523) loss_zs_kd 0.2181 (0.1872) loss_oracle 0.0774 (0.0823) acc 53.1250 (71.8229) kd_loss 0.0565 (0.0621) lr 1.5567e-04 eta 0:03:26
epoch [43/50] batch [80/246] time 0.108 (0.107) data 0.000 (0.004) loss 1.1174 (1.2073) ce_loss 0.9458 (1.0394) teacher_loss 0.9364 (1.0347) loss_zs_kd 0.1704 (0.1824) loss_oracle 0.0957 (0.0814) acc 78.1250 (72.1875) kd_loss 0.0614 (0.0613) lr 1.5567e-04 eta 0:03:21
epoch [43/50] batch [100/246] time 0.097 (0.105) data 0.000 (0.003) loss 1.5928 (1.2347) ce_loss 1.3672 (1.0664) teacher_loss 1.3615 (1.0614) loss_zs_kd 0.2537 (0.1811) loss_oracle 0.1045 (0.0827) acc 68.7500 (71.4688) kd_loss 0.0743 (0.0619) lr 1.5567e-04 eta 0:03:16
epoch [43/50] batch [120/246] time 0.104 (0.105) data 0.001 (0.003) loss 0.9313 (1.2189) ce_loss 0.7490 (1.0513) teacher_loss 0.7605 (1.0469) loss_zs_kd 0.1697 (0.1773) loss_oracle 0.0860 (0.0834) acc 75.0000 (71.7969) kd_loss 0.0535 (0.0623) lr 1.5567e-04 eta 0:03:13
epoch [43/50] batch [140/246] time 0.097 (0.104) data 0.000 (0.002) loss 1.3395 (1.2278) ce_loss 1.1631 (1.0597) teacher_loss 1.1656 (1.0553) loss_zs_kd 0.1659 (0.1774) loss_oracle 0.0909 (0.0838) acc 65.6250 (71.5179) kd_loss 0.0820 (0.0627) lr 1.5567e-04 eta 0:03:09
epoch [43/50] batch [160/246] time 0.101 (0.103) data 0.000 (0.002) loss 1.3651 (1.2223) ce_loss 1.1670 (1.0547) teacher_loss 1.1469 (1.0501) loss_zs_kd 0.2203 (0.1772) loss_oracle 0.1080 (0.0836) acc 68.7500 (71.7773) kd_loss 0.0724 (0.0624) lr 1.5567e-04 eta 0:03:06
epoch [43/50] batch [180/246] time 0.100 (0.103) data 0.000 (0.002) loss 0.8928 (1.2217) ce_loss 0.7378 (1.0540) teacher_loss 0.7326 (1.0495) loss_zs_kd 0.1536 (0.1777) loss_oracle 0.0834 (0.0834) acc 84.3750 (71.8576) kd_loss 0.0658 (0.0625) lr 1.5567e-04 eta 0:03:04
epoch [43/50] batch [200/246] time 0.090 (0.103) data 0.000 (0.002) loss 0.8832 (1.2228) ce_loss 0.7437 (1.0562) teacher_loss 0.7248 (1.0513) loss_zs_kd 0.1288 (0.1767) loss_oracle 0.0940 (0.0831) acc 75.0000 (71.8594) kd_loss 0.0825 (0.0623) lr 1.5567e-04 eta 0:03:01
epoch [43/50] batch [220/246] time 0.096 (0.102) data 0.000 (0.001) loss 0.8946 (1.2200) ce_loss 0.7617 (1.0527) teacher_loss 0.7640 (1.0479) loss_zs_kd 0.1191 (0.1771) loss_oracle 0.0710 (0.0836) acc 84.3750 (72.0739) kd_loss 0.0641 (0.0623) lr 1.5567e-04 eta 0:02:58
epoch [43/50] batch [240/246] time 0.089 (0.101) data 0.000 (0.001) loss 1.7754 (1.2234) ce_loss 1.6172 (1.0560) teacher_loss 1.6176 (1.0511) loss_zs_kd 0.1488 (0.1782) loss_oracle 0.0834 (0.0832) acc 59.3750 (71.9922) kd_loss 0.0502 (0.0619) lr 1.5567e-04 eta 0:02:55
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,865
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,961
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [44/50] batch [20/246] time 0.102 (0.117) data 0.000 (0.014) loss 1.2221 (1.2160) ce_loss 1.0479 (1.0438) teacher_loss 1.0392 (1.0367) loss_zs_kd 0.1479 (0.1882) loss_oracle 0.1090 (0.0852) acc 68.7500 (72.8125) kd_loss 0.0881 (0.0614) lr 1.2369e-04 eta 0:03:19
epoch [44/50] batch [40/246] time 0.103 (0.106) data 0.000 (0.007) loss 1.1237 (1.2092) ce_loss 0.9062 (1.0406) teacher_loss 0.9083 (1.0341) loss_zs_kd 0.2488 (0.1782) loss_oracle 0.0910 (0.0860) acc 78.1250 (73.1250) kd_loss 0.0688 (0.0620) lr 1.2369e-04 eta 0:02:57
epoch [44/50] batch [60/246] time 0.103 (0.103) data 0.001 (0.005) loss 1.1787 (1.2243) ce_loss 1.0283 (1.0552) teacher_loss 1.0350 (1.0478) loss_zs_kd 0.1355 (0.1802) loss_oracle 0.0760 (0.0864) acc 71.8750 (72.3438) kd_loss 0.0610 (0.0616) lr 1.2369e-04 eta 0:02:50
epoch [44/50] batch [80/246] time 0.111 (0.102) data 0.000 (0.004) loss 1.1500 (1.2199) ce_loss 0.9663 (1.0488) teacher_loss 0.9782 (1.0425) loss_zs_kd 0.2317 (0.1848) loss_oracle 0.0559 (0.0850) acc 75.0000 (72.4219) kd_loss 0.0251 (0.0610) lr 1.2369e-04 eta 0:02:47
epoch [44/50] batch [100/246] time 0.110 (0.103) data 0.000 (0.003) loss 1.2089 (1.2198) ce_loss 0.9785 (1.0471) teacher_loss 0.9853 (1.0417) loss_zs_kd 0.2308 (0.1860) loss_oracle 0.1082 (0.0851) acc 81.2500 (72.6250) kd_loss 0.0677 (0.0613) lr 1.2369e-04 eta 0:02:47
epoch [44/50] batch [120/246] time 0.104 (0.104) data 0.000 (0.003) loss 1.0721 (1.2128) ce_loss 0.9067 (1.0415) teacher_loss 0.9062 (1.0361) loss_zs_kd 0.1767 (0.1849) loss_oracle 0.0776 (0.0842) acc 75.0000 (72.8646) kd_loss 0.0550 (0.0618) lr 1.2369e-04 eta 0:02:45
epoch [44/50] batch [140/246] time 0.135 (0.105) data 0.001 (0.002) loss 0.9254 (1.2032) ce_loss 0.7661 (1.0333) teacher_loss 0.7709 (1.0283) loss_zs_kd 0.1352 (0.1822) loss_oracle 0.0870 (0.0838) acc 75.0000 (72.9018) kd_loss 0.0545 (0.0615) lr 1.2369e-04 eta 0:02:46
epoch [44/50] batch [160/246] time 0.126 (0.108) data 0.000 (0.002) loss 1.1850 (1.2132) ce_loss 0.9707 (1.0428) teacher_loss 0.9780 (1.0377) loss_zs_kd 0.2603 (0.1829) loss_oracle 0.0769 (0.0840) acc 71.8750 (72.8906) kd_loss 0.0471 (0.0614) lr 1.2369e-04 eta 0:02:48
epoch [44/50] batch [180/246] time 0.138 (0.110) data 0.001 (0.002) loss 1.1494 (1.2130) ce_loss 0.9805 (1.0431) teacher_loss 0.9739 (1.0381) loss_zs_kd 0.1433 (0.1819) loss_oracle 0.1038 (0.0839) acc 75.0000 (72.8472) kd_loss 0.0727 (0.0608) lr 1.2369e-04 eta 0:02:50
epoch [44/50] batch [200/246] time 0.129 (0.112) data 0.000 (0.002) loss 1.2531 (1.2072) ce_loss 1.1045 (1.0382) teacher_loss 1.1015 (1.0331) loss_zs_kd 0.1492 (0.1806) loss_oracle 0.0770 (0.0838) acc 71.8750 (72.8750) kd_loss 0.0457 (0.0610) lr 1.2369e-04 eta 0:02:50
epoch [44/50] batch [220/246] time 0.132 (0.114) data 0.002 (0.002) loss 1.3369 (1.2016) ce_loss 1.2148 (1.0337) teacher_loss 1.2059 (1.0286) loss_zs_kd 0.0810 (0.1784) loss_oracle 0.0904 (0.0838) acc 68.7500 (72.8835) kd_loss 0.0701 (0.0613) lr 1.2369e-04 eta 0:02:50
epoch [44/50] batch [240/246] time 0.113 (0.114) data 0.000 (0.002) loss 0.9567 (1.2042) ce_loss 0.8252 (1.0365) teacher_loss 0.8192 (1.0313) loss_zs_kd 0.1288 (0.1777) loss_oracle 0.0731 (0.0841) acc 71.8750 (72.9036) kd_loss 0.0494 (0.0614) lr 1.2369e-04 eta 0:02:49
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,866
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,961
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [45/50] batch [20/246] time 0.081 (0.103) data 0.000 (0.012) loss 1.0546 (1.2899) ce_loss 0.9087 (1.1253) teacher_loss 0.8931 (1.1199) loss_zs_kd 0.1858 (0.1741) loss_oracle 0.0686 (0.0829) acc 81.2500 (70.3125) kd_loss 0.0473 (0.0589) lr 9.5173e-05 eta 0:02:29
epoch [45/50] batch [40/246] time 0.086 (0.096) data 0.000 (0.006) loss 1.9095 (1.2334) ce_loss 1.7549 (1.0656) teacher_loss 1.7415 (1.0602) loss_zs_kd 0.1487 (0.1815) loss_oracle 0.0937 (0.0825) acc 56.2500 (72.5000) kd_loss 0.0734 (0.0626) lr 9.5173e-05 eta 0:02:17
epoch [45/50] batch [60/246] time 0.083 (0.093) data 0.000 (0.004) loss 1.3491 (1.2248) ce_loss 1.1436 (1.0552) teacher_loss 1.1433 (1.0504) loss_zs_kd 0.2168 (0.1841) loss_oracle 0.0974 (0.0823) acc 75.0000 (72.7604) kd_loss 0.0782 (0.0635) lr 9.5173e-05 eta 0:02:11
epoch [45/50] batch [80/246] time 0.091 (0.092) data 0.000 (0.003) loss 0.9808 (1.2532) ce_loss 0.7925 (1.0829) teacher_loss 0.7946 (1.0785) loss_zs_kd 0.1972 (0.1846) loss_oracle 0.0876 (0.0824) acc 84.3750 (71.9141) kd_loss 0.0556 (0.0627) lr 9.5173e-05 eta 0:02:08
epoch [45/50] batch [100/246] time 0.082 (0.092) data 0.000 (0.003) loss 1.2451 (1.2344) ce_loss 1.0547 (1.0636) teacher_loss 1.0575 (1.0589) loss_zs_kd 0.2103 (0.1849) loss_oracle 0.0824 (0.0831) acc 78.1250 (72.4375) kd_loss 0.0662 (0.0619) lr 9.5173e-05 eta 0:02:06
epoch [45/50] batch [120/246] time 0.088 (0.092) data 0.000 (0.002) loss 1.3886 (1.2224) ce_loss 1.2422 (1.0533) teacher_loss 1.2242 (1.0482) loss_zs_kd 0.1459 (0.1822) loss_oracle 0.0915 (0.0831) acc 65.6250 (72.5260) kd_loss 0.0754 (0.0617) lr 9.5173e-05 eta 0:02:05
epoch [45/50] batch [140/246] time 0.088 (0.092) data 0.000 (0.002) loss 0.8884 (1.2160) ce_loss 0.7271 (1.0470) teacher_loss 0.7131 (1.0420) loss_zs_kd 0.1555 (0.1820) loss_oracle 0.0976 (0.0830) acc 78.1250 (72.5223) kd_loss 0.0651 (0.0616) lr 9.5173e-05 eta 0:02:02
epoch [45/50] batch [160/246] time 0.096 (0.092) data 0.000 (0.002) loss 1.5684 (1.2138) ce_loss 1.4023 (1.0446) teacher_loss 1.3962 (1.0398) loss_zs_kd 0.1518 (0.1818) loss_oracle 0.0963 (0.0831) acc 62.5000 (72.5000) kd_loss 0.0633 (0.0612) lr 9.5173e-05 eta 0:02:01
epoch [45/50] batch [180/246] time 0.083 (0.092) data 0.000 (0.002) loss 1.6046 (1.2150) ce_loss 1.4346 (1.0469) teacher_loss 1.4293 (1.0418) loss_zs_kd 0.1496 (0.1804) loss_oracle 0.1005 (0.0830) acc 68.7500 (72.5000) kd_loss 0.0606 (0.0607) lr 9.5173e-05 eta 0:01:59
epoch [45/50] batch [200/246] time 0.091 (0.093) data 0.000 (0.001) loss 0.9587 (1.2122) ce_loss 0.7964 (1.0437) teacher_loss 0.7961 (1.0386) loss_zs_kd 0.1739 (0.1796) loss_oracle 0.0756 (0.0838) acc 87.5000 (72.5938) kd_loss 0.0646 (0.0605) lr 9.5173e-05 eta 0:01:58
epoch [45/50] batch [220/246] time 0.096 (0.093) data 0.000 (0.001) loss 1.4700 (1.2131) ce_loss 1.3018 (1.0446) teacher_loss 1.3058 (1.0399) loss_zs_kd 0.1786 (0.1787) loss_oracle 0.0749 (0.0839) acc 71.8750 (72.5710) kd_loss 0.0655 (0.0603) lr 9.5173e-05 eta 0:01:56
epoch [45/50] batch [240/246] time 0.088 (0.092) data 0.000 (0.001) loss 1.2592 (1.2123) ce_loss 1.0938 (1.0441) teacher_loss 1.0977 (1.0391) loss_zs_kd 0.1221 (0.1785) loss_oracle 0.1004 (0.0838) acc 75.0000 (72.4870) kd_loss 0.0754 (0.0604) lr 9.5173e-05 eta 0:01:54
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,867
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [46/50] batch [20/246] time 0.106 (0.131) data 0.000 (0.016) loss 1.2404 (1.3250) ce_loss 1.0664 (1.1584) teacher_loss 1.0600 (1.1534) loss_zs_kd 0.1715 (0.1789) loss_oracle 0.0946 (0.0822) acc 71.8750 (72.0312) kd_loss 0.0696 (0.0586) lr 7.0224e-05 eta 0:02:38
epoch [46/50] batch [40/246] time 0.107 (0.119) data 0.000 (0.008) loss 1.1155 (1.3001) ce_loss 0.9575 (1.1345) teacher_loss 0.9395 (1.1278) loss_zs_kd 0.1717 (0.1780) loss_oracle 0.0902 (0.0833) acc 75.0000 (71.1719) kd_loss 0.0622 (0.0586) lr 7.0224e-05 eta 0:02:21
epoch [46/50] batch [60/246] time 0.128 (0.114) data 0.002 (0.006) loss 1.0732 (1.2760) ce_loss 0.8315 (1.1096) teacher_loss 0.8214 (1.1033) loss_zs_kd 0.2553 (0.1766) loss_oracle 0.1241 (0.0844) acc 78.1250 (71.0938) kd_loss 0.0765 (0.0586) lr 7.0224e-05 eta 0:02:13
epoch [46/50] batch [80/246] time 0.104 (0.114) data 0.000 (0.004) loss 1.1657 (1.2675) ce_loss 1.0078 (1.1007) teacher_loss 1.0058 (1.0956) loss_zs_kd 0.1843 (0.1803) loss_oracle 0.0677 (0.0817) acc 71.8750 (71.5234) kd_loss 0.0515 (0.0570) lr 7.0224e-05 eta 0:02:10
epoch [46/50] batch [100/246] time 0.106 (0.112) data 0.000 (0.003) loss 1.0032 (1.2647) ce_loss 0.8179 (1.0970) teacher_loss 0.8242 (1.0916) loss_zs_kd 0.2040 (0.1809) loss_oracle 0.0770 (0.0826) acc 71.8750 (71.5312) kd_loss 0.0465 (0.0571) lr 7.0224e-05 eta 0:02:06
epoch [46/50] batch [120/246] time 0.123 (0.113) data 0.000 (0.003) loss 0.7323 (1.2519) ce_loss 0.5762 (1.0848) teacher_loss 0.5885 (1.0799) loss_zs_kd 0.1322 (0.1796) loss_oracle 0.0777 (0.0822) acc 81.2500 (71.8229) kd_loss 0.0510 (0.0569) lr 7.0224e-05 eta 0:02:05
epoch [46/50] batch [140/246] time 0.121 (0.114) data 0.000 (0.003) loss 0.6895 (1.2217) ce_loss 0.4912 (1.0569) teacher_loss 0.4948 (1.0522) loss_zs_kd 0.2569 (0.1757) loss_oracle 0.0662 (0.0817) acc 84.3750 (72.5893) kd_loss 0.0505 (0.0570) lr 7.0224e-05 eta 0:02:04
epoch [46/50] batch [160/246] time 0.121 (0.116) data 0.000 (0.002) loss 1.5919 (1.2159) ce_loss 1.4258 (1.0502) teacher_loss 1.4313 (1.0458) loss_zs_kd 0.2100 (0.1776) loss_oracle 0.0556 (0.0812) acc 59.3750 (72.5977) kd_loss 0.0398 (0.0567) lr 7.0224e-05 eta 0:02:03
epoch [46/50] batch [180/246] time 0.108 (0.116) data 0.000 (0.002) loss 1.1543 (1.2128) ce_loss 1.0234 (1.0470) teacher_loss 1.0107 (1.0427) loss_zs_kd 0.1432 (0.1780) loss_oracle 0.0720 (0.0811) acc 68.7500 (72.6910) kd_loss 0.0703 (0.0569) lr 7.0224e-05 eta 0:02:02
epoch [46/50] batch [200/246] time 0.107 (0.116) data 0.000 (0.002) loss 1.7198 (1.2217) ce_loss 1.5342 (1.0551) teacher_loss 1.5171 (1.0507) loss_zs_kd 0.2447 (0.1785) loss_oracle 0.0804 (0.0818) acc 56.2500 (72.3906) kd_loss 0.0646 (0.0580) lr 7.0224e-05 eta 0:01:59
epoch [46/50] batch [220/246] time 0.113 (0.116) data 0.000 (0.002) loss 1.4450 (1.2160) ce_loss 1.3232 (1.0497) teacher_loss 1.3140 (1.0453) loss_zs_kd 0.1369 (0.1785) loss_oracle 0.0625 (0.0814) acc 59.3750 (72.4716) kd_loss 0.0672 (0.0585) lr 7.0224e-05 eta 0:01:56
epoch [46/50] batch [240/246] time 0.103 (0.115) data 0.000 (0.002) loss 1.0472 (1.2191) ce_loss 0.8901 (1.0522) teacher_loss 0.8919 (1.0477) loss_zs_kd 0.1698 (0.1794) loss_oracle 0.0704 (0.0817) acc 81.2500 (72.4349) kd_loss 0.0493 (0.0586) lr 7.0224e-05 eta 0:01:54
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,867
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [47/50] batch [20/246] time 0.111 (0.124) data 0.000 (0.018) loss 1.3097 (1.1886) ce_loss 1.1797 (1.0237) teacher_loss 1.1714 (1.0177) loss_zs_kd 0.1396 (0.1795) loss_oracle 0.0685 (0.0812) acc 62.5000 (72.6562) kd_loss 0.0472 (0.0575) lr 4.8943e-05 eta 0:01:59
epoch [47/50] batch [40/246] time 0.133 (0.125) data 0.000 (0.009) loss 1.2732 (1.1994) ce_loss 1.0684 (1.0319) teacher_loss 1.0531 (1.0263) loss_zs_kd 0.2795 (0.1858) loss_oracle 0.0803 (0.0801) acc 75.0000 (72.5000) kd_loss 0.0582 (0.0603) lr 4.8943e-05 eta 0:01:57
epoch [47/50] batch [60/246] time 0.137 (0.127) data 0.001 (0.006) loss 0.8292 (1.2076) ce_loss 0.6626 (1.0409) teacher_loss 0.6538 (1.0354) loss_zs_kd 0.1959 (0.1835) loss_oracle 0.0774 (0.0804) acc 78.1250 (72.3958) kd_loss 0.0553 (0.0612) lr 4.8943e-05 eta 0:01:57
epoch [47/50] batch [80/246] time 0.137 (0.128) data 0.000 (0.005) loss 0.7742 (1.1922) ce_loss 0.6616 (1.0273) teacher_loss 0.6665 (1.0222) loss_zs_kd 0.1190 (0.1808) loss_oracle 0.0482 (0.0796) acc 81.2500 (72.6953) kd_loss 0.0409 (0.0609) lr 4.8943e-05 eta 0:01:55
epoch [47/50] batch [100/246] time 0.131 (0.127) data 0.001 (0.004) loss 1.2623 (1.1968) ce_loss 0.9688 (1.0301) teacher_loss 0.9623 (1.0253) loss_zs_kd 0.3632 (0.1822) loss_oracle 0.1185 (0.0804) acc 75.0000 (72.8750) kd_loss 0.0789 (0.0610) lr 4.8943e-05 eta 0:01:52
epoch [47/50] batch [120/246] time 0.121 (0.127) data 0.001 (0.003) loss 1.0458 (1.2172) ce_loss 0.8862 (1.0502) teacher_loss 0.8838 (1.0453) loss_zs_kd 0.1450 (0.1825) loss_oracle 0.0895 (0.0807) acc 81.2500 (72.3438) kd_loss 0.0645 (0.0606) lr 4.8943e-05 eta 0:01:49
epoch [47/50] batch [140/246] time 0.120 (0.126) data 0.000 (0.003) loss 0.9700 (1.2093) ce_loss 0.8018 (1.0422) teacher_loss 0.7981 (1.0380) loss_zs_kd 0.1870 (0.1817) loss_oracle 0.0784 (0.0805) acc 84.3750 (72.7232) kd_loss 0.0672 (0.0601) lr 4.8943e-05 eta 0:01:46
epoch [47/50] batch [160/246] time 0.106 (0.124) data 0.000 (0.003) loss 0.9364 (1.2060) ce_loss 0.7954 (1.0382) teacher_loss 0.7870 (1.0333) loss_zs_kd 0.1369 (0.1821) loss_oracle 0.0809 (0.0816) acc 81.2500 (73.0859) kd_loss 0.0521 (0.0605) lr 4.8943e-05 eta 0:01:42
epoch [47/50] batch [180/246] time 0.096 (0.122) data 0.000 (0.002) loss 0.8767 (1.2025) ce_loss 0.7246 (1.0360) teacher_loss 0.7265 (1.0310) loss_zs_kd 0.1818 (0.1800) loss_oracle 0.0593 (0.0815) acc 81.2500 (73.1424) kd_loss 0.0522 (0.0601) lr 4.8943e-05 eta 0:01:37
epoch [47/50] batch [200/246] time 0.111 (0.120) data 0.000 (0.002) loss 0.9215 (1.1966) ce_loss 0.7812 (1.0308) teacher_loss 0.7732 (1.0256) loss_zs_kd 0.1416 (0.1785) loss_oracle 0.0775 (0.0817) acc 81.2500 (73.2656) kd_loss 0.0491 (0.0600) lr 4.8943e-05 eta 0:01:33
epoch [47/50] batch [220/246] time 0.123 (0.118) data 0.000 (0.002) loss 0.9216 (1.2082) ce_loss 0.7627 (1.0423) teacher_loss 0.7598 (1.0372) loss_zs_kd 0.1693 (0.1788) loss_oracle 0.0771 (0.0816) acc 81.2500 (73.0966) kd_loss 0.0526 (0.0598) lr 4.8943e-05 eta 0:01:30
epoch [47/50] batch [240/246] time 0.104 (0.118) data 0.000 (0.002) loss 1.4152 (1.2122) ce_loss 1.2148 (1.0458) teacher_loss 1.2229 (1.0407) loss_zs_kd 0.2216 (0.1796) loss_oracle 0.0814 (0.0817) acc 71.8750 (72.8646) kd_loss 0.0419 (0.0597) lr 4.8943e-05 eta 0:01:27
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,867
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [48/50] batch [20/246] time 0.110 (0.122) data 0.000 (0.015) loss 0.7605 (1.1497) ce_loss 0.6040 (0.9754) teacher_loss 0.6137 (0.9750) loss_zs_kd 0.1548 (0.1855) loss_oracle 0.0694 (0.0820) acc 84.3750 (74.2188) kd_loss 0.0572 (0.0569) lr 3.1417e-05 eta 0:01:27
epoch [48/50] batch [40/246] time 0.111 (0.112) data 0.000 (0.008) loss 1.1755 (1.1567) ce_loss 0.9990 (0.9819) teacher_loss 0.9996 (0.9806) loss_zs_kd 0.2035 (0.1855) loss_oracle 0.0742 (0.0834) acc 71.8750 (73.5938) kd_loss 0.0519 (0.0582) lr 3.1417e-05 eta 0:01:17
epoch [48/50] batch [60/246] time 0.104 (0.109) data 0.001 (0.005) loss 1.1462 (1.1330) ce_loss 0.9365 (0.9609) teacher_loss 0.9428 (0.9594) loss_zs_kd 0.2261 (0.1813) loss_oracle 0.0903 (0.0829) acc 78.1250 (74.5833) kd_loss 0.0653 (0.0585) lr 3.1417e-05 eta 0:01:13
epoch [48/50] batch [80/246] time 0.104 (0.107) data 0.000 (0.004) loss 1.1505 (1.1601) ce_loss 0.9712 (0.9893) teacher_loss 0.9677 (0.9870) loss_zs_kd 0.1913 (0.1813) loss_oracle 0.0871 (0.0825) acc 75.0000 (73.7500) kd_loss 0.0678 (0.0594) lr 3.1417e-05 eta 0:01:10
epoch [48/50] batch [100/246] time 0.098 (0.106) data 0.000 (0.003) loss 1.4428 (1.1691) ce_loss 1.2529 (1.0007) teacher_loss 1.2378 (0.9974) loss_zs_kd 0.1858 (0.1802) loss_oracle 0.1121 (0.0816) acc 71.8750 (73.4688) kd_loss 0.0841 (0.0603) lr 3.1417e-05 eta 0:01:07
epoch [48/50] batch [120/246] time 0.099 (0.105) data 0.000 (0.003) loss 1.3121 (1.1939) ce_loss 1.1465 (1.0244) teacher_loss 1.1409 (1.0202) loss_zs_kd 0.1506 (0.1816) loss_oracle 0.0958 (0.0829) acc 71.8750 (72.8646) kd_loss 0.0456 (0.0606) lr 3.1417e-05 eta 0:01:04
epoch [48/50] batch [140/246] time 0.095 (0.104) data 0.000 (0.002) loss 1.5006 (1.2024) ce_loss 1.3506 (1.0323) teacher_loss 1.3406 (1.0281) loss_zs_kd 0.1707 (0.1829) loss_oracle 0.0746 (0.0829) acc 68.7500 (72.6786) kd_loss 0.0655 (0.0605) lr 3.1417e-05 eta 0:01:02
epoch [48/50] batch [160/246] time 0.106 (0.104) data 0.000 (0.002) loss 0.8207 (1.2183) ce_loss 0.6846 (1.0487) teacher_loss 0.6688 (1.0443) loss_zs_kd 0.1565 (0.1824) loss_oracle 0.0737 (0.0828) acc 78.1250 (72.2852) kd_loss 0.0764 (0.0605) lr 3.1417e-05 eta 0:00:59
epoch [48/50] batch [180/246] time 0.098 (0.103) data 0.000 (0.002) loss 1.5303 (1.2137) ce_loss 1.3672 (1.0446) teacher_loss 1.3497 (1.0405) loss_zs_kd 0.1535 (0.1809) loss_oracle 0.1039 (0.0827) acc 62.5000 (72.3958) kd_loss 0.0570 (0.0603) lr 3.1417e-05 eta 0:00:57
epoch [48/50] batch [200/246] time 0.105 (0.103) data 0.000 (0.002) loss 1.4719 (1.2279) ce_loss 1.2988 (1.0592) teacher_loss 1.2879 (1.0549) loss_zs_kd 0.1662 (0.1808) loss_oracle 0.1009 (0.0827) acc 65.6250 (72.0312) kd_loss 0.0727 (0.0603) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [220/246] time 0.100 (0.103) data 0.000 (0.002) loss 1.3206 (1.2359) ce_loss 1.1230 (1.0664) teacher_loss 1.1244 (1.0619) loss_zs_kd 0.2111 (0.1814) loss_oracle 0.0906 (0.0833) acc 71.8750 (71.9176) kd_loss 0.0500 (0.0603) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [240/246] time 0.104 (0.103) data 0.000 (0.001) loss 1.6311 (1.2421) ce_loss 1.4844 (1.0726) teacher_loss 1.4762 (1.0681) loss_zs_kd 0.1575 (0.1812) loss_oracle 0.0761 (0.0834) acc 62.5000 (71.8359) kd_loss 0.0583 (0.0605) lr 3.1417e-05 eta 0:00:51
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,867
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [49/50] batch [20/246] time 0.109 (0.123) data 0.000 (0.017) loss 1.3583 (1.2026) ce_loss 1.1973 (1.0318) teacher_loss 1.2042 (1.0270) loss_zs_kd 0.1649 (0.1869) loss_oracle 0.0716 (0.0822) acc 62.5000 (74.5312) kd_loss 0.0414 (0.0593) lr 1.7713e-05 eta 0:00:58
epoch [49/50] batch [40/246] time 0.111 (0.112) data 0.000 (0.009) loss 1.2381 (1.1632) ce_loss 1.0547 (0.9925) teacher_loss 1.0475 (0.9872) loss_zs_kd 0.2016 (0.1823) loss_oracle 0.0898 (0.0849) acc 75.0000 (74.4531) kd_loss 0.0584 (0.0584) lr 1.7713e-05 eta 0:00:50
epoch [49/50] batch [60/246] time 0.109 (0.109) data 0.001 (0.006) loss 1.0688 (1.1975) ce_loss 0.8774 (1.0270) teacher_loss 0.8673 (1.0205) loss_zs_kd 0.2600 (0.1814) loss_oracle 0.0715 (0.0862) acc 81.2500 (72.7604) kd_loss 0.0556 (0.0584) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [80/246] time 0.099 (0.107) data 0.000 (0.005) loss 1.3459 (1.1922) ce_loss 1.1699 (1.0242) teacher_loss 1.1678 (1.0183) loss_zs_kd 0.1951 (0.1779) loss_oracle 0.0805 (0.0849) acc 71.8750 (72.8125) kd_loss 0.0506 (0.0580) lr 1.7713e-05 eta 0:00:44
epoch [49/50] batch [100/246] time 0.100 (0.105) data 0.000 (0.004) loss 1.4398 (1.2254) ce_loss 1.2588 (1.0590) teacher_loss 1.2564 (1.0530) loss_zs_kd 0.2235 (0.1767) loss_oracle 0.0716 (0.0841) acc 68.7500 (72.0625) kd_loss 0.0623 (0.0583) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [120/246] time 0.099 (0.104) data 0.000 (0.003) loss 0.8160 (1.2142) ce_loss 0.6079 (1.0480) teacher_loss 0.6058 (1.0425) loss_zs_kd 0.1961 (0.1737) loss_oracle 0.1122 (0.0849) acc 84.3750 (72.5521) kd_loss 0.0643 (0.0586) lr 1.7713e-05 eta 0:00:38
epoch [49/50] batch [140/246] time 0.099 (0.103) data 0.000 (0.003) loss 1.5063 (1.2120) ce_loss 1.3633 (1.0465) teacher_loss 1.3594 (1.0412) loss_zs_kd 0.1602 (0.1739) loss_oracle 0.0668 (0.0839) acc 65.6250 (72.5893) kd_loss 0.0413 (0.0582) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [160/246] time 0.097 (0.103) data 0.000 (0.002) loss 1.7066 (1.2142) ce_loss 1.5576 (1.0484) teacher_loss 1.5261 (1.0427) loss_zs_kd 0.2040 (0.1753) loss_oracle 0.0786 (0.0839) acc 59.3750 (72.5586) kd_loss 0.0569 (0.0588) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [180/246] time 0.100 (0.103) data 0.000 (0.002) loss 1.0942 (1.2148) ce_loss 0.9097 (1.0483) teacher_loss 0.9019 (1.0427) loss_zs_kd 0.1729 (0.1760) loss_oracle 0.1059 (0.0841) acc 75.0000 (72.5694) kd_loss 0.0807 (0.0589) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [200/246] time 0.101 (0.103) data 0.000 (0.002) loss 1.8217 (1.2237) ce_loss 1.6699 (1.0568) teacher_loss 1.6580 (1.0509) loss_zs_kd 0.2002 (0.1770) loss_oracle 0.0635 (0.0842) acc 50.0000 (72.3906) kd_loss 0.0481 (0.0591) lr 1.7713e-05 eta 0:00:29
epoch [49/50] batch [220/246] time 0.097 (0.102) data 0.000 (0.002) loss 1.1032 (1.2206) ce_loss 0.8901 (1.0528) teacher_loss 0.8782 (1.0470) loss_zs_kd 0.2524 (0.1782) loss_oracle 0.0988 (0.0845) acc 78.1250 (72.5000) kd_loss 0.0656 (0.0597) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [240/246] time 0.105 (0.102) data 0.000 (0.002) loss 1.1687 (1.2139) ce_loss 1.0029 (1.0462) teacher_loss 1.0016 (1.0402) loss_zs_kd 0.1764 (0.1778) loss_oracle 0.0789 (0.0848) acc 75.0000 (72.5781) kd_loss 0.0577 (0.0601) lr 1.7713e-05 eta 0:00:25
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,868
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 49 *******
******* Domain r best val test acc: 90.8%, epoch: 49 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
epoch [50/50] batch [20/246] time 0.095 (0.113) data 0.000 (0.013) loss 1.2636 (1.1752) ce_loss 1.0693 (1.0006) teacher_loss 1.0658 (0.9954) loss_zs_kd 0.2343 (0.1849) loss_oracle 0.0807 (0.0873) acc 68.7500 (73.1250) kd_loss 0.0682 (0.0647) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [40/246] time 0.102 (0.105) data 0.000 (0.006) loss 1.3196 (1.1640) ce_loss 1.1396 (0.9948) teacher_loss 1.1355 (0.9888) loss_zs_kd 0.1743 (0.1812) loss_oracle 0.0969 (0.0846) acc 78.1250 (73.8281) kd_loss 0.0666 (0.0627) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [60/246] time 0.091 (0.102) data 0.000 (0.004) loss 1.6040 (1.1861) ce_loss 1.4424 (1.0175) teacher_loss 1.4266 (1.0111) loss_zs_kd 0.2133 (0.1831) loss_oracle 0.0707 (0.0835) acc 62.5000 (73.5417) kd_loss 0.0626 (0.0624) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [80/246] time 0.091 (0.100) data 0.000 (0.003) loss 1.2641 (1.2122) ce_loss 1.1240 (1.0446) teacher_loss 1.1252 (1.0365) loss_zs_kd 0.1477 (0.1802) loss_oracle 0.0650 (0.0855) acc 68.7500 (72.6953) kd_loss 0.0443 (0.0630) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [100/246] time 0.093 (0.099) data 0.000 (0.003) loss 2.0230 (1.2297) ce_loss 1.8457 (1.0629) teacher_loss 1.8573 (1.0552) loss_zs_kd 0.2061 (0.1794) loss_oracle 0.0626 (0.0848) acc 62.5000 (72.2188) kd_loss 0.0400 (0.0631) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [120/246] time 0.096 (0.099) data 0.000 (0.002) loss 0.9387 (1.2288) ce_loss 0.7700 (1.0604) teacher_loss 0.7397 (1.0531) loss_zs_kd 0.1969 (0.1821) loss_oracle 0.1005 (0.0846) acc 75.0000 (72.1875) kd_loss 0.0717 (0.0635) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [140/246] time 0.099 (0.099) data 0.000 (0.002) loss 1.0621 (1.2202) ce_loss 0.9150 (1.0528) teacher_loss 0.9054 (1.0457) loss_zs_kd 0.1548 (0.1802) loss_oracle 0.0793 (0.0845) acc 81.2500 (72.4554) kd_loss 0.0664 (0.0636) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [160/246] time 0.094 (0.098) data 0.000 (0.002) loss 0.9945 (1.2245) ce_loss 0.8394 (1.0574) teacher_loss 0.8308 (1.0502) loss_zs_kd 0.1750 (0.1804) loss_oracle 0.0762 (0.0841) acc 81.2500 (72.5586) kd_loss 0.0525 (0.0632) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [180/246] time 0.101 (0.098) data 0.000 (0.002) loss 1.0762 (1.2182) ce_loss 0.8979 (1.0504) teacher_loss 0.9016 (1.0435) loss_zs_kd 0.1995 (0.1808) loss_oracle 0.0748 (0.0843) acc 78.1250 (72.6389) kd_loss 0.0698 (0.0628) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [200/246] time 0.094 (0.099) data 0.000 (0.001) loss 1.4551 (1.2159) ce_loss 1.3125 (1.0479) teacher_loss 1.2872 (1.0414) loss_zs_kd 0.1826 (0.1800) loss_oracle 0.0765 (0.0845) acc 59.3750 (72.8750) kd_loss 0.0533 (0.0628) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [220/246] time 0.103 (0.098) data 0.000 (0.001) loss 1.7102 (1.2266) ce_loss 1.5322 (1.0580) teacher_loss 1.5254 (1.0516) loss_zs_kd 0.1816 (0.1807) loss_oracle 0.0940 (0.0847) acc 59.3750 (72.6278) kd_loss 0.0691 (0.0624) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [240/246] time 0.086 (0.098) data 0.000 (0.001) loss 1.4347 (1.2264) ce_loss 1.2305 (1.0580) teacher_loss 1.2332 (1.0518) loss_zs_kd 0.2030 (0.1798) loss_oracle 0.1001 (0.0847) acc 62.5000 (72.3958) kd_loss 0.0563 (0.0627) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,868
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 49 *******
******* Domain r best val test acc: 90.8%, epoch: 49 *******
******* Domain r best test acc:     91.1%, epoch: 8 *******
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:27:46

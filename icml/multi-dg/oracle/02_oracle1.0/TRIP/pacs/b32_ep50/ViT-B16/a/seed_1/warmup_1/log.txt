Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------
Dataset    SPG_PACS
Source     ['cartoon', 'photo', 'sketch']
Target     ['art_painting']
# classes  7
# train_x  5,557
# val      2,385
# test     2,048
---------  ------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/173] time 0.139 (0.152) data 0.000 (0.019) loss 0.3349 (0.4618) ce_loss 0.3350 (0.4614) teacher_loss 0.3348 (0.4614) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0001 (0.0003) acc 90.6250 (83.7500) kd_loss 0.0003 (0.0013) lr 1.0000e-05 eta 0:21:48
epoch [1/50] batch [40/173] time 0.102 (0.131) data 0.000 (0.010) loss 0.5370 (0.4527) ce_loss 0.5361 (0.4523) teacher_loss 0.5366 (0.4524) loss_zs_kd 0.0007 (0.0002) loss_oracle 0.0001 (0.0002) acc 78.1250 (83.9844) kd_loss 0.0004 (0.0008) lr 1.0000e-05 eta 0:18:45
epoch [1/50] batch [60/173] time 0.150 (0.129) data 0.000 (0.007) loss 0.5217 (0.4551) ce_loss 0.5195 (0.4547) teacher_loss 0.5203 (0.4547) loss_zs_kd 0.0023 (0.0005) loss_oracle 0.0002 (0.0002) acc 78.1250 (83.5938) kd_loss 0.0007 (0.0008) lr 1.0000e-05 eta 0:18:30
epoch [1/50] batch [80/173] time 0.144 (0.127) data 0.000 (0.005) loss 0.5134 (0.4592) ce_loss 0.5107 (0.4584) teacher_loss 0.5114 (0.4585) loss_zs_kd 0.0033 (0.0009) loss_oracle 0.0004 (0.0002) acc 81.2500 (82.9297) kd_loss 0.0014 (0.0008) lr 1.0000e-05 eta 0:18:05
epoch [1/50] batch [100/173] time 0.130 (0.126) data 0.000 (0.004) loss 0.5961 (0.4504) ce_loss 0.5942 (0.4494) teacher_loss 0.5935 (0.4494) loss_zs_kd 0.0040 (0.0014) loss_oracle 0.0006 (0.0003) acc 75.0000 (83.4062) kd_loss 0.0024 (0.0010) lr 1.0000e-05 eta 0:17:56
epoch [1/50] batch [120/173] time 0.142 (0.125) data 0.000 (0.003) loss 0.4155 (0.4591) ce_loss 0.4116 (0.4577) teacher_loss 0.4110 (0.4577) loss_zs_kd 0.0070 (0.0021) loss_oracle 0.0009 (0.0003) acc 81.2500 (83.1510) kd_loss 0.0036 (0.0013) lr 1.0000e-05 eta 0:17:49
epoch [1/50] batch [140/173] time 0.137 (0.125) data 0.000 (0.003) loss 0.3329 (0.4598) ce_loss 0.3267 (0.4579) teacher_loss 0.3271 (0.4579) loss_zs_kd 0.0097 (0.0028) loss_oracle 0.0009 (0.0004) acc 84.3750 (83.1920) kd_loss 0.0033 (0.0016) lr 1.0000e-05 eta 0:17:41
epoch [1/50] batch [160/173] time 0.082 (0.123) data 0.000 (0.003) loss 0.3102 (0.4529) ce_loss 0.3057 (0.4507) teacher_loss 0.3059 (0.4507) loss_zs_kd 0.0068 (0.0035) loss_oracle 0.0009 (0.0005) acc 87.5000 (83.4766) kd_loss 0.0033 (0.0018) lr 1.0000e-05 eta 0:17:20
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,265
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 95.7%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,998
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.0%, epoch: 1 *******
******* Domain a best val test acc: 97.6%, epoch: 1 *******
******* Domain a best test acc:     97.6%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/ana
epoch [2/50] batch [20/173] time 0.185 (0.169) data 0.000 (0.018) loss 0.5024 (0.4752) ce_loss 0.4746 (0.4478) teacher_loss 0.4666 (0.4459) loss_zs_kd 0.0407 (0.0439) loss_oracle 0.0155 (0.0075) acc 87.5000 (84.2188) kd_loss 0.0374 (0.0181) lr 2.0000e-03 eta 0:23:51
epoch [2/50] batch [40/173] time 0.098 (0.141) data 0.000 (0.009) loss 0.5009 (0.4431) ce_loss 0.4648 (0.4090) teacher_loss 0.4314 (0.4040) loss_zs_kd 0.0382 (0.0426) loss_oracle 0.0504 (0.0178) acc 84.3750 (85.6250) kd_loss 0.1427 (0.0453) lr 2.0000e-03 eta 0:19:53
epoch [2/50] batch [60/173] time 0.082 (0.127) data 0.000 (0.006) loss 0.6370 (0.4695) ce_loss 0.4675 (0.4121) teacher_loss 0.3875 (0.3930) loss_zs_kd 0.0599 (0.0435) loss_oracle 0.2196 (0.0548) acc 71.8750 (85.3125) kd_loss 0.3231 (0.1050) lr 2.0000e-03 eta 0:17:48
epoch [2/50] batch [80/173] time 0.108 (0.121) data 0.000 (0.005) loss 0.5608 (0.4891) ce_loss 0.3579 (0.3963) teacher_loss 0.2379 (0.3645) loss_zs_kd 0.0459 (0.0455) loss_oracle 0.3000 (0.1019) acc 84.3750 (85.8984) kd_loss 0.4664 (0.1715) lr 2.0000e-03 eta 0:16:55
epoch [2/50] batch [100/173] time 0.086 (0.117) data 0.000 (0.004) loss 0.4272 (0.5115) ce_loss 0.2417 (0.3985) teacher_loss 0.1615 (0.3529) loss_zs_kd 0.0531 (0.0484) loss_oracle 0.2391 (0.1344) acc 90.6250 (85.7812) kd_loss 0.4229 (0.2243) lr 2.0000e-03 eta 0:16:21
epoch [2/50] batch [120/173] time 0.099 (0.115) data 0.000 (0.003) loss 0.5584 (0.5300) ce_loss 0.2700 (0.3980) teacher_loss 0.1485 (0.3388) loss_zs_kd 0.0458 (0.0526) loss_oracle 0.3871 (0.1649) acc 90.6250 (85.9115) kd_loss 0.7519 (0.2733) lr 2.0000e-03 eta 0:15:58
epoch [2/50] batch [140/173] time 0.107 (0.113) data 0.000 (0.003) loss 0.4662 (0.5433) ce_loss 0.1796 (0.3949) teacher_loss 0.1162 (0.3275) loss_zs_kd 0.0592 (0.0559) loss_oracle 0.3204 (0.1878) acc 93.7500 (85.9152) kd_loss 0.5410 (0.3129) lr 2.0000e-03 eta 0:15:45
epoch [2/50] batch [160/173] time 0.085 (0.113) data 0.000 (0.002) loss 0.6729 (0.5704) ce_loss 0.4087 (0.4061) teacher_loss 0.2378 (0.3276) loss_zs_kd 0.0950 (0.0598) loss_oracle 0.3875 (0.2129) acc 84.3750 (85.5273) kd_loss 0.6788 (0.3571) lr 2.0000e-03 eta 0:15:36
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,276
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.0%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,004
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     97.9%, epoch: 2 *******
epoch [3/50] batch [20/173] time 0.134 (0.120) data 0.000 (0.015) loss 0.6733 (0.6978) ce_loss 0.2905 (0.3540) teacher_loss 0.1396 (0.2067) loss_zs_kd 0.0879 (0.0773) loss_oracle 0.4897 (0.4525) acc 87.5000 (86.5625) kd_loss 0.8241 (0.7754) lr 1.9980e-03 eta 0:16:37
epoch [3/50] batch [40/173] time 0.086 (0.110) data 0.000 (0.008) loss 0.9350 (0.7496) ce_loss 0.5537 (0.3953) teacher_loss 0.4622 (0.2452) loss_zs_kd 0.0958 (0.0818) loss_oracle 0.4248 (0.4635) acc 81.2500 (86.0156) kd_loss 0.8240 (0.7889) lr 1.9980e-03 eta 0:15:09
epoch [3/50] batch [60/173] time 0.138 (0.114) data 0.001 (0.005) loss 0.7806 (0.7632) ce_loss 0.4226 (0.4017) teacher_loss 0.2180 (0.2539) loss_zs_kd 0.0957 (0.0866) loss_oracle 0.5147 (0.4661) acc 90.6250 (86.0417) kd_loss 0.8987 (0.8035) lr 1.9980e-03 eta 0:15:36
epoch [3/50] batch [80/173] time 0.139 (0.113) data 0.000 (0.004) loss 0.9434 (0.7885) ce_loss 0.5708 (0.4156) teacher_loss 0.3231 (0.2595) loss_zs_kd 0.0940 (0.0920) loss_oracle 0.5733 (0.4830) acc 81.2500 (85.5469) kd_loss 0.9672 (0.8237) lr 1.9980e-03 eta 0:15:29
epoch [3/50] batch [100/173] time 0.091 (0.113) data 0.000 (0.003) loss 0.5846 (0.7960) ce_loss 0.2456 (0.4156) teacher_loss 0.1076 (0.2543) loss_zs_kd 0.0640 (0.0940) loss_oracle 0.4450 (0.4946) acc 93.7500 (85.5312) kd_loss 0.8187 (0.8413) lr 1.9980e-03 eta 0:15:26
epoch [3/50] batch [120/173] time 0.119 (0.113) data 0.000 (0.003) loss 0.7030 (0.7929) ce_loss 0.3154 (0.4084) teacher_loss 0.1292 (0.2432) loss_zs_kd 0.1344 (0.0981) loss_oracle 0.5067 (0.5006) acc 84.3750 (85.5469) kd_loss 0.9208 (0.8530) lr 1.9980e-03 eta 0:15:23
epoch [3/50] batch [140/173] time 0.087 (0.113) data 0.000 (0.002) loss 0.7888 (0.7884) ce_loss 0.4993 (0.4087) teacher_loss 0.2024 (0.2413) loss_zs_kd 0.1126 (0.0990) loss_oracle 0.5301 (0.4975) acc 81.2500 (85.4464) kd_loss 0.9283 (0.8554) lr 1.9980e-03 eta 0:15:20
epoch [3/50] batch [160/173] time 0.083 (0.113) data 0.000 (0.002) loss 0.7565 (0.7885) ce_loss 0.3132 (0.4116) teacher_loss 0.1751 (0.2421) loss_zs_kd 0.1423 (0.1011) loss_oracle 0.5102 (0.4959) acc 87.5000 (85.4297) kd_loss 0.8714 (0.8569) lr 1.9980e-03 eta 0:15:16
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,269
* accuracy: 95.1%
* error: 4.9%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.9%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [4/50] batch [20/173] time 0.124 (0.135) data 0.001 (0.010) loss 0.7163 (0.7895) ce_loss 0.2939 (0.3994) teacher_loss 0.1169 (0.1897) loss_zs_kd 0.0983 (0.1222) loss_oracle 0.5502 (0.5387) acc 87.5000 (84.3750) kd_loss 0.9606 (0.9298) lr 1.9921e-03 eta 0:18:18
epoch [4/50] batch [40/173] time 0.083 (0.120) data 0.000 (0.005) loss 0.6724 (0.7972) ce_loss 0.2167 (0.4061) teacher_loss 0.1022 (0.1954) loss_zs_kd 0.1178 (0.1278) loss_oracle 0.5113 (0.5379) acc 93.7500 (84.6875) kd_loss 0.9370 (0.9251) lr 1.9921e-03 eta 0:16:12
epoch [4/50] batch [60/173] time 0.167 (0.134) data 0.000 (0.004) loss 0.7940 (0.7717) ce_loss 0.3618 (0.3861) teacher_loss 0.1653 (0.1971) loss_zs_kd 0.1412 (0.1165) loss_oracle 0.5581 (0.5163) acc 90.6250 (85.7812) kd_loss 0.9349 (0.9178) lr 1.9921e-03 eta 0:18:04
epoch [4/50] batch [80/173] time 0.138 (0.133) data 0.000 (0.003) loss 0.8073 (0.7645) ce_loss 0.6055 (0.3832) teacher_loss 0.2589 (0.1943) loss_zs_kd 0.1247 (0.1138) loss_oracle 0.4860 (0.5133) acc 68.7500 (85.9375) kd_loss 0.9787 (0.9186) lr 1.9921e-03 eta 0:17:52
epoch [4/50] batch [100/173] time 0.084 (0.129) data 0.000 (0.002) loss 0.7529 (0.7649) ce_loss 0.3562 (0.3843) teacher_loss 0.1830 (0.1928) loss_zs_kd 0.1155 (0.1167) loss_oracle 0.5121 (0.5138) acc 87.5000 (85.9062) kd_loss 0.9458 (0.9228) lr 1.9921e-03 eta 0:17:19
epoch [4/50] batch [120/173] time 0.094 (0.124) data 0.000 (0.002) loss 0.7323 (0.7567) ce_loss 0.4514 (0.3792) teacher_loss 0.2808 (0.1956) loss_zs_kd 0.0755 (0.1142) loss_oracle 0.4138 (0.5041) acc 84.3750 (86.1198) kd_loss 1.0080 (0.9255) lr 1.9921e-03 eta 0:16:36
epoch [4/50] batch [140/173] time 0.128 (0.121) data 0.000 (0.002) loss 0.6814 (0.7556) ce_loss 0.2498 (0.3818) teacher_loss 0.2178 (0.2068) loss_zs_kd 0.0722 (0.1134) loss_oracle 0.4275 (0.4921) acc 90.6250 (86.1161) kd_loss 1.0159 (0.9288) lr 1.9921e-03 eta 0:16:09
epoch [4/50] batch [160/173] time 0.095 (0.119) data 0.000 (0.001) loss 0.7311 (0.7532) ce_loss 0.3748 (0.3804) teacher_loss 0.2069 (0.2122) loss_zs_kd 0.1118 (0.1109) loss_oracle 0.4683 (0.4855) acc 87.5000 (86.2305) kd_loss 0.9848 (0.9337) lr 1.9921e-03 eta 0:15:49
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,276
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.9%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     97.9%, epoch: 4 *******
epoch [5/50] batch [20/173] time 0.121 (0.127) data 0.000 (0.010) loss 0.7262 (0.7286) ce_loss 0.3438 (0.4053) teacher_loss 0.2588 (0.2884) loss_zs_kd 0.0830 (0.0927) loss_oracle 0.4259 (0.3938) acc 84.3750 (84.0625) kd_loss 0.9555 (0.9574) lr 1.9823e-03 eta 0:16:49
epoch [5/50] batch [40/173] time 0.081 (0.118) data 0.000 (0.005) loss 0.8976 (0.7356) ce_loss 0.4417 (0.4063) teacher_loss 0.3061 (0.2667) loss_zs_kd 0.1702 (0.1018) loss_oracle 0.5063 (0.4181) acc 84.3750 (84.5312) kd_loss 0.9695 (0.9549) lr 1.9823e-03 eta 0:15:35
epoch [5/50] batch [60/173] time 0.096 (0.117) data 0.001 (0.004) loss 0.8303 (0.7542) ce_loss 0.4045 (0.4195) teacher_loss 0.3213 (0.2674) loss_zs_kd 0.1139 (0.1053) loss_oracle 0.4520 (0.4341) acc 90.6250 (84.0104) kd_loss 1.0029 (0.9656) lr 1.9823e-03 eta 0:15:20
epoch [5/50] batch [80/173] time 0.088 (0.115) data 0.000 (0.003) loss 0.7142 (0.7457) ce_loss 0.4177 (0.4128) teacher_loss 0.1994 (0.2593) loss_zs_kd 0.1389 (0.1043) loss_oracle 0.4454 (0.4342) acc 93.7500 (84.5703) kd_loss 0.9984 (0.9650) lr 1.9823e-03 eta 0:15:06
epoch [5/50] batch [100/173] time 0.115 (0.114) data 0.000 (0.002) loss 0.6957 (0.7325) ce_loss 0.3457 (0.4101) teacher_loss 0.2658 (0.2602) loss_zs_kd 0.0941 (0.1010) loss_oracle 0.3828 (0.4219) acc 90.6250 (84.6250) kd_loss 0.9083 (0.9609) lr 1.9823e-03 eta 0:14:53
epoch [5/50] batch [120/173] time 0.091 (0.113) data 0.000 (0.002) loss 0.7039 (0.7321) ce_loss 0.2839 (0.4048) teacher_loss 0.1814 (0.2544) loss_zs_kd 0.0536 (0.1026) loss_oracle 0.4957 (0.4264) acc 90.6250 (84.7656) kd_loss 0.9454 (0.9595) lr 1.9823e-03 eta 0:14:42
epoch [5/50] batch [140/173] time 0.146 (0.113) data 0.000 (0.002) loss 0.6815 (0.7336) ce_loss 0.2544 (0.4069) teacher_loss 0.2005 (0.2554) loss_zs_kd 0.0877 (0.0997) loss_oracle 0.4371 (0.4284) acc 84.3750 (84.9330) kd_loss 0.9652 (0.9545) lr 1.9823e-03 eta 0:14:45
epoch [5/50] batch [160/173] time 0.086 (0.114) data 0.000 (0.002) loss 0.6045 (0.7370) ce_loss 0.1693 (0.4046) teacher_loss 0.1039 (0.2524) loss_zs_kd 0.0656 (0.0999) loss_oracle 0.4678 (0.4346) acc 93.7500 (85.0195) kd_loss 0.9353 (0.9519) lr 1.9823e-03 eta 0:14:49
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,271
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     97.9%, epoch: 4 *******
epoch [6/50] batch [20/173] time 0.079 (0.126) data 0.000 (0.014) loss 0.7488 (0.8698) ce_loss 0.2991 (0.4281) teacher_loss 0.2290 (0.3021) loss_zs_kd 0.0671 (0.0970) loss_oracle 0.4862 (0.5192) acc 87.5000 (83.5938) kd_loss 0.9127 (0.9162) lr 1.9686e-03 eta 0:16:18
epoch [6/50] batch [40/173] time 0.112 (0.118) data 0.000 (0.007) loss 0.8488 (0.8507) ce_loss 0.5142 (0.4144) teacher_loss 0.3647 (0.2997) loss_zs_kd 0.0729 (0.0871) loss_oracle 0.4477 (0.5075) acc 87.5000 (84.6875) kd_loss 0.8491 (0.9182) lr 1.9686e-03 eta 0:15:16
epoch [6/50] batch [60/173] time 0.095 (0.119) data 0.001 (0.005) loss 1.0005 (0.8633) ce_loss 0.4993 (0.4167) teacher_loss 0.4290 (0.3161) loss_zs_kd 0.0511 (0.0768) loss_oracle 0.5459 (0.5088) acc 84.3750 (84.5833) kd_loss 0.9751 (0.9286) lr 1.9686e-03 eta 0:15:16
epoch [6/50] batch [80/173] time 0.085 (0.119) data 0.000 (0.004) loss 0.8243 (0.8899) ce_loss 0.2913 (0.4133) teacher_loss 0.2250 (0.3205) loss_zs_kd 0.0726 (0.0708) loss_oracle 0.5630 (0.5340) acc 90.6250 (84.8438) kd_loss 0.9496 (0.9353) lr 1.9686e-03 eta 0:15:19
epoch [6/50] batch [100/173] time 0.064 (0.114) data 0.000 (0.003) loss 1.0153 (0.9045) ce_loss 0.4106 (0.4102) teacher_loss 0.3005 (0.3225) loss_zs_kd 0.0557 (0.0673) loss_oracle 0.6870 (0.5484) acc 84.3750 (85.0312) kd_loss 0.9648 (0.9348) lr 1.9686e-03 eta 0:14:39
epoch [6/50] batch [120/173] time 0.184 (0.126) data 0.000 (0.003) loss 1.2000 (0.9141) ce_loss 0.6846 (0.4066) teacher_loss 0.4780 (0.3205) loss_zs_kd 0.0711 (0.0640) loss_oracle 0.6864 (0.5616) acc 78.1250 (85.3385) kd_loss 1.0080 (0.9335) lr 1.9686e-03 eta 0:16:08
epoch [6/50] batch [140/173] time 0.189 (0.127) data 0.000 (0.002) loss 0.9506 (0.9321) ce_loss 0.3362 (0.4068) teacher_loss 0.2556 (0.3251) loss_zs_kd 0.0352 (0.0621) loss_oracle 0.6774 (0.5759) acc 90.6250 (85.3795) kd_loss 0.9012 (0.9310) lr 1.9686e-03 eta 0:16:08
epoch [6/50] batch [160/173] time 0.095 (0.126) data 0.000 (0.002) loss 0.8622 (0.9289) ce_loss 0.2986 (0.4018) teacher_loss 0.2812 (0.3222) loss_zs_kd 0.0495 (0.0609) loss_oracle 0.5562 (0.5762) acc 90.6250 (85.4492) kd_loss 0.8912 (0.9250) lr 1.9686e-03 eta 0:15:57
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,270
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.9%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     97.9%, epoch: 4 *******
epoch [7/50] batch [20/173] time 0.138 (0.131) data 0.000 (0.013) loss 0.9721 (0.9298) ce_loss 0.5742 (0.4466) teacher_loss 0.5354 (0.3827) loss_zs_kd 0.0335 (0.0437) loss_oracle 0.4200 (0.5253) acc 84.3750 (82.9688) kd_loss 0.8528 (0.8905) lr 1.9511e-03 eta 0:16:35
epoch [7/50] batch [40/173] time 0.140 (0.135) data 0.000 (0.007) loss 1.0202 (0.8528) ce_loss 0.6060 (0.3977) teacher_loss 0.5083 (0.3394) loss_zs_kd 0.0598 (0.0438) loss_oracle 0.4820 (0.4915) acc 71.8750 (84.7656) kd_loss 0.8639 (0.8803) lr 1.9511e-03 eta 0:17:01
epoch [7/50] batch [60/173] time 0.142 (0.133) data 0.001 (0.005) loss 0.9051 (0.8566) ce_loss 0.4592 (0.3874) teacher_loss 0.3423 (0.3301) loss_zs_kd 0.0469 (0.0431) loss_oracle 0.5393 (0.5049) acc 87.5000 (85.7292) kd_loss 0.8588 (0.8706) lr 1.9511e-03 eta 0:16:41
epoch [7/50] batch [80/173] time 0.124 (0.130) data 0.000 (0.004) loss 0.8896 (0.8610) ce_loss 0.4138 (0.3881) teacher_loss 0.2882 (0.3279) loss_zs_kd 0.0462 (0.0449) loss_oracle 0.5783 (0.5106) acc 84.3750 (85.8203) kd_loss 0.8678 (0.8690) lr 1.9511e-03 eta 0:16:20
epoch [7/50] batch [100/173] time 0.095 (0.130) data 0.000 (0.003) loss 0.7298 (0.8494) ce_loss 0.2703 (0.3786) teacher_loss 0.2151 (0.3195) loss_zs_kd 0.0419 (0.0450) loss_oracle 0.4937 (0.5074) acc 90.6250 (86.0938) kd_loss 0.8526 (0.8624) lr 1.9511e-03 eta 0:16:18
epoch [7/50] batch [120/173] time 0.128 (0.130) data 0.000 (0.002) loss 0.7141 (0.8283) ce_loss 0.2891 (0.3714) teacher_loss 0.2922 (0.3133) loss_zs_kd 0.0577 (0.0474) loss_oracle 0.3930 (0.4913) acc 90.6250 (86.4062) kd_loss 0.8252 (0.8526) lr 1.9511e-03 eta 0:16:16
epoch [7/50] batch [140/173] time 0.133 (0.130) data 0.000 (0.002) loss 0.7633 (0.8147) ce_loss 0.3694 (0.3703) teacher_loss 0.3569 (0.3090) loss_zs_kd 0.0657 (0.0488) loss_oracle 0.3735 (0.4813) acc 90.6250 (86.5179) kd_loss 0.8426 (0.8512) lr 1.9511e-03 eta 0:16:11
epoch [7/50] batch [160/173] time 0.120 (0.130) data 0.000 (0.002) loss 0.7687 (0.8073) ce_loss 0.4805 (0.3737) teacher_loss 0.3564 (0.3100) loss_zs_kd 0.0572 (0.0507) loss_oracle 0.3837 (0.4720) acc 84.3750 (86.4453) kd_loss 0.8423 (0.8495) lr 1.9511e-03 eta 0:16:06
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,275
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [8/50] batch [20/173] time 0.138 (0.142) data 0.000 (0.015) loss 0.6319 (0.7460) ce_loss 0.2532 (0.3599) teacher_loss 0.2138 (0.2912) loss_zs_kd 0.0419 (0.0565) loss_oracle 0.3971 (0.4266) acc 87.5000 (86.0938) kd_loss 0.7735 (0.8159) lr 1.9298e-03 eta 0:17:29
epoch [8/50] batch [40/173] time 0.112 (0.135) data 0.000 (0.008) loss 0.8896 (0.7838) ce_loss 0.4233 (0.3715) teacher_loss 0.3120 (0.2995) loss_zs_kd 0.0472 (0.0541) loss_oracle 0.5540 (0.4573) acc 84.3750 (85.8594) kd_loss 0.9035 (0.8268) lr 1.9298e-03 eta 0:16:37
epoch [8/50] batch [60/173] time 0.136 (0.130) data 0.001 (0.005) loss 0.7538 (0.7988) ce_loss 0.3667 (0.3818) teacher_loss 0.3269 (0.3101) loss_zs_kd 0.0592 (0.0553) loss_oracle 0.3973 (0.4611) acc 87.5000 (85.4688) kd_loss 0.8066 (0.8312) lr 1.9298e-03 eta 0:16:01
epoch [8/50] batch [80/173] time 0.134 (0.126) data 0.000 (0.004) loss 0.8238 (0.7816) ce_loss 0.4219 (0.3721) teacher_loss 0.3659 (0.2997) loss_zs_kd 0.0640 (0.0548) loss_oracle 0.4259 (0.4545) acc 81.2500 (86.0156) kd_loss 0.7999 (0.8263) lr 1.9298e-03 eta 0:15:30
epoch [8/50] batch [100/173] time 0.188 (0.127) data 0.000 (0.003) loss 0.7560 (0.7894) ce_loss 0.3008 (0.3742) teacher_loss 0.2403 (0.2976) loss_zs_kd 0.0735 (0.0572) loss_oracle 0.4790 (0.4632) acc 87.5000 (85.9375) kd_loss 0.7957 (0.8258) lr 1.9298e-03 eta 0:15:30
epoch [8/50] batch [120/173] time 0.084 (0.128) data 0.000 (0.003) loss 0.9204 (0.7857) ce_loss 0.5498 (0.3727) teacher_loss 0.4619 (0.2958) loss_zs_kd 0.0603 (0.0577) loss_oracle 0.4284 (0.4611) acc 78.1250 (86.0417) kd_loss 0.8507 (0.8291) lr 1.9298e-03 eta 0:15:35
epoch [8/50] batch [140/173] time 0.106 (0.130) data 0.001 (0.002) loss 0.6945 (0.7808) ce_loss 0.3052 (0.3743) teacher_loss 0.2134 (0.2959) loss_zs_kd 0.0648 (0.0586) loss_oracle 0.4487 (0.4556) acc 87.5000 (85.9375) kd_loss 0.8063 (0.8329) lr 1.9298e-03 eta 0:15:48
epoch [8/50] batch [160/173] time 0.088 (0.128) data 0.000 (0.002) loss 0.8322 (0.7840) ce_loss 0.4495 (0.3764) teacher_loss 0.3452 (0.2955) loss_zs_kd 0.0961 (0.0600) loss_oracle 0.4390 (0.4586) acc 81.2500 (85.9766) kd_loss 0.8509 (0.8392) lr 1.9298e-03 eta 0:15:28
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,275
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [9/50] batch [20/173] time 0.137 (0.143) data 0.000 (0.015) loss 1.1372 (0.9132) ce_loss 0.5527 (0.3608) teacher_loss 0.4591 (0.2862) loss_zs_kd 0.1228 (0.0812) loss_oracle 0.6167 (0.5864) acc 81.2500 (86.2500) kd_loss 1.0500 (0.9745) lr 1.9048e-03 eta 0:17:14
epoch [9/50] batch [40/173] time 0.140 (0.141) data 0.000 (0.008) loss 1.2309 (1.0039) ce_loss 0.4421 (0.3589) teacher_loss 0.4248 (0.2872) loss_zs_kd 0.1095 (0.0912) loss_oracle 0.7514 (0.6711) acc 84.3750 (86.5625) kd_loss 1.1061 (1.0100) lr 1.9048e-03 eta 0:16:59
epoch [9/50] batch [60/173] time 0.144 (0.141) data 0.000 (0.005) loss 1.1166 (1.0751) ce_loss 0.3354 (0.3757) teacher_loss 0.2724 (0.3097) loss_zs_kd 0.0661 (0.0864) loss_oracle 0.8111 (0.7222) acc 93.7500 (86.0938) kd_loss 1.1098 (1.0344) lr 1.9048e-03 eta 0:16:52
epoch [9/50] batch [80/173] time 0.086 (0.135) data 0.000 (0.004) loss 1.0849 (1.0799) ce_loss 0.3718 (0.3690) teacher_loss 0.2544 (0.3028) loss_zs_kd 0.0733 (0.0813) loss_oracle 0.7938 (0.7365) acc 84.3750 (86.2109) kd_loss 1.1078 (1.0438) lr 1.9048e-03 eta 0:16:11
epoch [9/50] batch [100/173] time 0.083 (0.130) data 0.000 (0.003) loss 1.1533 (1.0770) ce_loss 0.3953 (0.3650) teacher_loss 0.3538 (0.2965) loss_zs_kd 0.0790 (0.0792) loss_oracle 0.7600 (0.7409) acc 84.3750 (86.5625) kd_loss 1.0617 (1.0520) lr 1.9048e-03 eta 0:15:33
epoch [9/50] batch [120/173] time 0.127 (0.128) data 0.000 (0.003) loss 0.9884 (1.0698) ce_loss 0.3806 (0.3731) teacher_loss 0.2657 (0.2971) loss_zs_kd 0.0480 (0.0793) loss_oracle 0.6987 (0.7331) acc 87.5000 (86.2500) kd_loss 1.0847 (1.0577) lr 1.9048e-03 eta 0:15:14
epoch [9/50] batch [140/173] time 0.136 (0.126) data 0.000 (0.002) loss 0.8760 (1.0590) ce_loss 0.3906 (0.3802) teacher_loss 0.3271 (0.3013) loss_zs_kd 0.0857 (0.0802) loss_oracle 0.5061 (0.7175) acc 84.3750 (85.9598) kd_loss 1.0493 (1.0585) lr 1.9048e-03 eta 0:15:00
epoch [9/50] batch [160/173] time 0.134 (0.125) data 0.000 (0.002) loss 0.9903 (1.0411) ce_loss 0.4807 (0.3827) teacher_loss 0.2684 (0.2990) loss_zs_kd 0.1227 (0.0812) loss_oracle 0.6606 (0.7015) acc 78.1250 (85.7227) kd_loss 1.0966 (1.0590) lr 1.9048e-03 eta 0:14:48
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,277
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [10/50] batch [20/173] time 0.144 (0.141) data 0.000 (0.016) loss 0.8168 (0.8776) ce_loss 0.2915 (0.3715) teacher_loss 0.1765 (0.2857) loss_zs_kd 0.0803 (0.0650) loss_oracle 0.6001 (0.5594) acc 87.5000 (85.7812) kd_loss 1.0170 (1.0613) lr 1.8763e-03 eta 0:16:36
epoch [10/50] batch [40/173] time 0.139 (0.135) data 0.001 (0.008) loss 0.8155 (0.9033) ce_loss 0.2355 (0.3797) teacher_loss 0.1411 (0.2789) loss_zs_kd 0.0681 (0.0753) loss_oracle 0.6404 (0.5868) acc 93.7500 (85.7812) kd_loss 1.1776 (1.0751) lr 1.8763e-03 eta 0:15:49
epoch [10/50] batch [60/173] time 0.087 (0.131) data 0.001 (0.006) loss 1.0092 (0.9145) ce_loss 0.2751 (0.3754) teacher_loss 0.1424 (0.2682) loss_zs_kd 0.0835 (0.0770) loss_oracle 0.8251 (0.6077) acc 90.6250 (85.9375) kd_loss 1.1468 (1.0832) lr 1.8763e-03 eta 0:15:23
epoch [10/50] batch [80/173] time 0.139 (0.130) data 0.000 (0.004) loss 1.1093 (0.9230) ce_loss 0.5898 (0.3775) teacher_loss 0.4917 (0.2683) loss_zs_kd 0.0912 (0.0828) loss_oracle 0.5720 (0.6132) acc 78.1250 (85.8984) kd_loss 1.0848 (1.0887) lr 1.8763e-03 eta 0:15:14
epoch [10/50] batch [100/173] time 0.188 (0.131) data 0.000 (0.003) loss 0.9421 (0.9184) ce_loss 0.4895 (0.3812) teacher_loss 0.2624 (0.2705) loss_zs_kd 0.1055 (0.0795) loss_oracle 0.6270 (0.6081) acc 84.3750 (85.8750) kd_loss 1.1156 (1.0868) lr 1.8763e-03 eta 0:15:12
epoch [10/50] batch [120/173] time 0.077 (0.133) data 0.000 (0.003) loss 1.1064 (0.9259) ce_loss 0.5850 (0.3870) teacher_loss 0.3593 (0.2688) loss_zs_kd 0.1583 (0.0835) loss_oracle 0.6679 (0.6153) acc 71.8750 (85.6510) kd_loss 1.0571 (1.0845) lr 1.8763e-03 eta 0:15:25
epoch [10/50] batch [140/173] time 0.070 (0.133) data 0.000 (0.003) loss 0.9682 (0.9297) ce_loss 0.4272 (0.3924) teacher_loss 0.3103 (0.2728) loss_zs_kd 0.0773 (0.0845) loss_oracle 0.6193 (0.6147) acc 84.3750 (85.2232) kd_loss 1.0723 (1.0806) lr 1.8763e-03 eta 0:15:27
epoch [10/50] batch [160/173] time 0.100 (0.130) data 0.000 (0.002) loss 0.9868 (0.9344) ce_loss 0.3218 (0.3985) teacher_loss 0.3388 (0.2745) loss_zs_kd 0.1144 (0.0866) loss_oracle 0.5908 (0.6165) acc 90.6250 (85.0391) kd_loss 1.0855 (1.0768) lr 1.8763e-03 eta 0:14:58
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,267
* accuracy: 95.1%
* error: 4.9%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [11/50] batch [20/173] time 0.102 (0.126) data 0.000 (0.013) loss 0.9319 (0.9668) ce_loss 0.3408 (0.4171) teacher_loss 0.2022 (0.2572) loss_zs_kd 0.1179 (0.0918) loss_oracle 0.6707 (0.6637) acc 90.6250 (85.0000) kd_loss 1.0775 (1.0728) lr 1.8443e-03 eta 0:14:30
epoch [11/50] batch [40/173] time 0.085 (0.118) data 0.000 (0.006) loss 0.8504 (0.9418) ce_loss 0.3472 (0.3949) teacher_loss 0.1680 (0.2608) loss_zs_kd 0.0596 (0.0870) loss_oracle 0.6526 (0.6375) acc 84.3750 (85.7812) kd_loss 1.0677 (1.0568) lr 1.8443e-03 eta 0:13:31
epoch [11/50] batch [60/173] time 0.137 (0.113) data 0.000 (0.004) loss 0.7293 (0.9065) ce_loss 0.3376 (0.3742) teacher_loss 0.2385 (0.2521) loss_zs_kd 0.0712 (0.0823) loss_oracle 0.4551 (0.6132) acc 84.3750 (86.6667) kd_loss 0.9373 (1.0495) lr 1.8443e-03 eta 0:12:55
epoch [11/50] batch [80/173] time 0.140 (0.113) data 0.001 (0.003) loss 0.7070 (0.8860) ce_loss 0.2382 (0.3814) teacher_loss 0.1843 (0.2572) loss_zs_kd 0.0727 (0.0822) loss_oracle 0.4863 (0.5878) acc 90.6250 (86.2891) kd_loss 0.9950 (1.0391) lr 1.8443e-03 eta 0:12:50
epoch [11/50] batch [100/173] time 0.078 (0.112) data 0.000 (0.003) loss 0.6783 (0.8712) ce_loss 0.1924 (0.3745) teacher_loss 0.1265 (0.2583) loss_zs_kd 0.0423 (0.0793) loss_oracle 0.5306 (0.5732) acc 93.7500 (86.4688) kd_loss 0.9807 (1.0310) lr 1.8443e-03 eta 0:12:41
epoch [11/50] batch [120/173] time 0.088 (0.112) data 0.000 (0.002) loss 0.8070 (0.8723) ce_loss 0.2448 (0.3793) teacher_loss 0.2168 (0.2635) loss_zs_kd 0.0808 (0.0792) loss_oracle 0.5498 (0.5692) acc 93.7500 (86.2500) kd_loss 1.0070 (1.0252) lr 1.8443e-03 eta 0:12:41
epoch [11/50] batch [140/173] time 0.139 (0.112) data 0.000 (0.002) loss 0.9616 (0.8741) ce_loss 0.3049 (0.3814) teacher_loss 0.2966 (0.2661) loss_zs_kd 0.0701 (0.0783) loss_oracle 0.6300 (0.5688) acc 81.2500 (86.2277) kd_loss 0.9687 (1.0213) lr 1.8443e-03 eta 0:12:35
epoch [11/50] batch [160/173] time 0.082 (0.111) data 0.000 (0.002) loss 0.7318 (0.8760) ce_loss 0.1109 (0.3770) teacher_loss 0.0728 (0.2622) loss_zs_kd 0.0587 (0.0788) loss_oracle 0.6297 (0.5744) acc 96.8750 (86.4258) kd_loss 1.0310 (1.0196) lr 1.8443e-03 eta 0:12:30
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,273
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [12/50] batch [20/173] time 0.085 (0.128) data 0.000 (0.014) loss 1.0700 (0.9478) ce_loss 0.4397 (0.3922) teacher_loss 0.3155 (0.2664) loss_zs_kd 0.0867 (0.0775) loss_oracle 0.7112 (0.6426) acc 78.1250 (85.6250) kd_loss 1.0718 (1.0368) lr 1.8090e-03 eta 0:14:18
epoch [12/50] batch [40/173] time 0.135 (0.118) data 0.000 (0.007) loss 1.3214 (0.9824) ce_loss 0.8354 (0.3987) teacher_loss 0.6526 (0.2802) loss_zs_kd 0.1041 (0.0786) loss_oracle 0.6168 (0.6628) acc 75.0000 (85.1562) kd_loss 1.0192 (1.0385) lr 1.8090e-03 eta 0:13:14
epoch [12/50] batch [60/173] time 0.120 (0.116) data 0.000 (0.005) loss 0.9969 (0.9950) ce_loss 0.4431 (0.3982) teacher_loss 0.3325 (0.2875) loss_zs_kd 0.0878 (0.0760) loss_oracle 0.6205 (0.6695) acc 87.5000 (85.0521) kd_loss 1.0493 (1.0386) lr 1.8090e-03 eta 0:12:54
epoch [12/50] batch [80/173] time 0.133 (0.114) data 0.000 (0.004) loss 0.9299 (0.9817) ce_loss 0.3713 (0.4030) teacher_loss 0.2644 (0.2914) loss_zs_kd 0.1020 (0.0741) loss_oracle 0.6145 (0.6533) acc 87.5000 (85.4297) kd_loss 0.9873 (1.0302) lr 1.8090e-03 eta 0:12:38
epoch [12/50] batch [100/173] time 0.131 (0.113) data 0.000 (0.003) loss 0.7611 (0.9651) ce_loss 0.2386 (0.3931) teacher_loss 0.2008 (0.2827) loss_zs_kd 0.0534 (0.0758) loss_oracle 0.5336 (0.6445) acc 90.6250 (85.5938) kd_loss 0.9530 (1.0192) lr 1.8090e-03 eta 0:12:31
epoch [12/50] batch [120/173] time 0.121 (0.113) data 0.000 (0.003) loss 0.6581 (0.9545) ce_loss 0.1792 (0.3882) teacher_loss 0.0796 (0.2783) loss_zs_kd 0.0520 (0.0757) loss_oracle 0.5525 (0.6383) acc 93.7500 (85.7292) kd_loss 0.9766 (1.0105) lr 1.8090e-03 eta 0:12:27
epoch [12/50] batch [140/173] time 0.093 (0.113) data 0.000 (0.002) loss 0.8020 (0.9481) ce_loss 0.3811 (0.3903) teacher_loss 0.1825 (0.2792) loss_zs_kd 0.0697 (0.0758) loss_oracle 0.5846 (0.6311) acc 87.5000 (85.6920) kd_loss 0.9159 (1.0015) lr 1.8090e-03 eta 0:12:27
epoch [12/50] batch [160/173] time 0.163 (0.115) data 0.000 (0.002) loss 0.9230 (0.9329) ce_loss 0.4790 (0.3817) teacher_loss 0.3582 (0.2712) loss_zs_kd 0.1009 (0.0762) loss_oracle 0.5144 (0.6235) acc 84.3750 (85.8594) kd_loss 0.9004 (0.9946) lr 1.8090e-03 eta 0:12:35
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,268
* accuracy: 95.1%
* error: 4.9%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [13/50] batch [20/173] time 0.135 (0.128) data 0.000 (0.012) loss 0.7962 (0.8219) ce_loss 0.4551 (0.3771) teacher_loss 0.2812 (0.2613) loss_zs_kd 0.1064 (0.0800) loss_oracle 0.4618 (0.5206) acc 84.3750 (86.2500) kd_loss 0.9266 (0.9399) lr 1.7705e-03 eta 0:14:01
epoch [13/50] batch [40/173] time 0.082 (0.117) data 0.000 (0.006) loss 0.9580 (0.8255) ce_loss 0.5645 (0.3885) teacher_loss 0.3633 (0.2688) loss_zs_kd 0.0675 (0.0819) loss_oracle 0.5609 (0.5158) acc 78.1250 (85.8594) kd_loss 1.0279 (0.9445) lr 1.7705e-03 eta 0:12:42
epoch [13/50] batch [60/173] time 0.124 (0.114) data 0.001 (0.004) loss 0.8829 (0.8165) ce_loss 0.5815 (0.3785) teacher_loss 0.3176 (0.2606) loss_zs_kd 0.0871 (0.0809) loss_oracle 0.5217 (0.5154) acc 78.1250 (86.3542) kd_loss 0.9638 (0.9442) lr 1.7705e-03 eta 0:12:21
epoch [13/50] batch [80/173] time 0.082 (0.108) data 0.000 (0.003) loss 0.8767 (0.8289) ce_loss 0.3743 (0.3813) teacher_loss 0.3074 (0.2625) loss_zs_kd 0.0885 (0.0829) loss_oracle 0.5250 (0.5250) acc 90.6250 (86.1719) kd_loss 0.8516 (0.9403) lr 1.7705e-03 eta 0:11:40
epoch [13/50] batch [100/173] time 0.076 (0.104) data 0.000 (0.003) loss 0.7360 (0.8201) ce_loss 0.2062 (0.3768) teacher_loss 0.2120 (0.2603) loss_zs_kd 0.0672 (0.0809) loss_oracle 0.4905 (0.5193) acc 93.7500 (86.7500) kd_loss 0.9655 (0.9348) lr 1.7705e-03 eta 0:11:10
epoch [13/50] batch [120/173] time 0.085 (0.103) data 0.000 (0.002) loss 0.5691 (0.8151) ce_loss 0.0867 (0.3817) teacher_loss 0.0468 (0.2653) loss_zs_kd 0.0593 (0.0791) loss_oracle 0.4927 (0.5103) acc 96.8750 (86.5885) kd_loss 0.9527 (0.9304) lr 1.7705e-03 eta 0:11:05
epoch [13/50] batch [140/173] time 0.111 (0.102) data 0.000 (0.002) loss 0.7046 (0.8062) ce_loss 0.4717 (0.3859) teacher_loss 0.2813 (0.2685) loss_zs_kd 0.0833 (0.0800) loss_oracle 0.3816 (0.4977) acc 84.3750 (86.3839) kd_loss 0.9023 (0.9267) lr 1.7705e-03 eta 0:10:57
epoch [13/50] batch [160/173] time 0.072 (0.103) data 0.000 (0.002) loss 0.7675 (0.8019) ce_loss 0.3516 (0.3870) teacher_loss 0.2381 (0.2710) loss_zs_kd 0.0628 (0.0796) loss_oracle 0.4979 (0.4911) acc 84.3750 (86.1719) kd_loss 0.9328 (0.9234) lr 1.7705e-03 eta 0:11:00
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,274
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [14/50] batch [20/173] time 0.069 (0.114) data 0.000 (0.015) loss 0.6679 (0.8242) ce_loss 0.2416 (0.3697) teacher_loss 0.1762 (0.2652) loss_zs_kd 0.0455 (0.0877) loss_oracle 0.4689 (0.5152) acc 90.6250 (86.7188) kd_loss 0.8688 (0.9381) lr 1.7290e-03 eta 0:12:06
epoch [14/50] batch [40/173] time 0.096 (0.103) data 0.000 (0.008) loss 0.8235 (0.8153) ce_loss 0.3406 (0.3685) teacher_loss 0.2141 (0.2612) loss_zs_kd 0.0689 (0.0845) loss_oracle 0.5750 (0.5119) acc 87.5000 (86.0938) kd_loss 0.9668 (0.9352) lr 1.7290e-03 eta 0:10:55
epoch [14/50] batch [60/173] time 0.089 (0.106) data 0.000 (0.005) loss 1.0258 (0.8316) ce_loss 0.3853 (0.3713) teacher_loss 0.2977 (0.2580) loss_zs_kd 0.1317 (0.0874) loss_oracle 0.6623 (0.5299) acc 81.2500 (85.6771) kd_loss 0.9241 (0.9234) lr 1.7290e-03 eta 0:11:14
epoch [14/50] batch [80/173] time 0.115 (0.107) data 0.000 (0.004) loss 0.8379 (0.8300) ce_loss 0.3723 (0.3633) teacher_loss 0.2476 (0.2508) loss_zs_kd 0.1234 (0.0893) loss_oracle 0.5286 (0.5346) acc 87.5000 (86.3672) kd_loss 0.8497 (0.9176) lr 1.7290e-03 eta 0:11:16
epoch [14/50] batch [100/173] time 0.138 (0.108) data 0.000 (0.003) loss 1.1365 (0.8327) ce_loss 0.5820 (0.3685) teacher_loss 0.5006 (0.2541) loss_zs_kd 0.1194 (0.0905) loss_oracle 0.5762 (0.5333) acc 78.1250 (86.2188) kd_loss 0.9327 (0.9146) lr 1.7290e-03 eta 0:11:20
epoch [14/50] batch [120/173] time 0.081 (0.109) data 0.000 (0.003) loss 0.7450 (0.8341) ce_loss 0.3491 (0.3746) teacher_loss 0.2638 (0.2622) loss_zs_kd 0.0735 (0.0893) loss_oracle 0.4444 (0.5272) acc 87.5000 (85.9896) kd_loss 0.8897 (0.9122) lr 1.7290e-03 eta 0:11:23
epoch [14/50] batch [140/173] time 0.111 (0.108) data 0.000 (0.002) loss 0.9568 (0.8304) ce_loss 0.6284 (0.3797) teacher_loss 0.3606 (0.2640) loss_zs_kd 0.1220 (0.0918) loss_oracle 0.5353 (0.5206) acc 71.8750 (85.7143) kd_loss 0.9062 (0.9090) lr 1.7290e-03 eta 0:11:17
epoch [14/50] batch [160/173] time 0.086 (0.108) data 0.000 (0.002) loss 0.9185 (0.8232) ce_loss 0.5078 (0.3762) teacher_loss 0.3400 (0.2612) loss_zs_kd 0.0938 (0.0913) loss_oracle 0.5316 (0.5164) acc 75.0000 (85.8008) kd_loss 0.9040 (0.9054) lr 1.7290e-03 eta 0:11:15
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,275
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [15/50] batch [20/173] time 0.076 (0.120) data 0.000 (0.013) loss 0.8234 (0.7625) ce_loss 0.3811 (0.3824) teacher_loss 0.3240 (0.2719) loss_zs_kd 0.0856 (0.0968) loss_oracle 0.4566 (0.4422) acc 90.6250 (85.4688) kd_loss 0.8601 (0.9032) lr 1.6845e-03 eta 0:12:25
epoch [15/50] batch [40/173] time 0.164 (0.134) data 0.000 (0.007) loss 0.8254 (0.7508) ce_loss 0.3855 (0.3714) teacher_loss 0.2601 (0.2634) loss_zs_kd 0.0728 (0.0887) loss_oracle 0.5289 (0.4430) acc 87.5000 (86.0938) kd_loss 0.9354 (0.8951) lr 1.6845e-03 eta 0:13:51
epoch [15/50] batch [60/173] time 0.192 (0.130) data 0.001 (0.005) loss 0.8903 (0.7627) ce_loss 0.4885 (0.3738) teacher_loss 0.3892 (0.2660) loss_zs_kd 0.1108 (0.0913) loss_oracle 0.4457 (0.4510) acc 84.3750 (85.7812) kd_loss 0.8612 (0.8839) lr 1.6845e-03 eta 0:13:22
epoch [15/50] batch [80/173] time 0.080 (0.130) data 0.000 (0.004) loss 0.6958 (0.7525) ce_loss 0.2837 (0.3612) teacher_loss 0.1996 (0.2577) loss_zs_kd 0.0546 (0.0878) loss_oracle 0.4689 (0.4509) acc 90.6250 (86.2500) kd_loss 0.8323 (0.8752) lr 1.6845e-03 eta 0:13:20
epoch [15/50] batch [100/173] time 0.111 (0.127) data 0.000 (0.003) loss 0.6259 (0.7511) ce_loss 0.2314 (0.3584) teacher_loss 0.1361 (0.2537) loss_zs_kd 0.0706 (0.0885) loss_oracle 0.4545 (0.4532) acc 93.7500 (86.5312) kd_loss 0.9274 (0.8732) lr 1.6845e-03 eta 0:12:58
epoch [15/50] batch [120/173] time 0.100 (0.125) data 0.000 (0.002) loss 0.6582 (0.7449) ce_loss 0.2874 (0.3501) teacher_loss 0.1428 (0.2453) loss_zs_kd 0.0686 (0.0866) loss_oracle 0.4811 (0.4563) acc 81.2500 (86.7708) kd_loss 0.8921 (0.8691) lr 1.6845e-03 eta 0:12:44
epoch [15/50] batch [140/173] time 0.100 (0.124) data 0.000 (0.002) loss 0.7854 (0.7479) ce_loss 0.4248 (0.3550) teacher_loss 0.2880 (0.2484) loss_zs_kd 0.0939 (0.0877) loss_oracle 0.4505 (0.4557) acc 81.2500 (86.5402) kd_loss 0.8245 (0.8650) lr 1.6845e-03 eta 0:12:35
epoch [15/50] batch [160/173] time 0.124 (0.123) data 0.000 (0.002) loss 0.6419 (0.7519) ce_loss 0.2328 (0.3583) teacher_loss 0.1344 (0.2519) loss_zs_kd 0.1021 (0.0896) loss_oracle 0.4565 (0.4552) acc 93.7500 (86.5820) kd_loss 0.8239 (0.8620) lr 1.6845e-03 eta 0:12:26
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,276
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [16/50] batch [20/173] time 0.126 (0.121) data 0.000 (0.014) loss 0.7354 (0.7682) ce_loss 0.3232 (0.3579) teacher_loss 0.2254 (0.2464) loss_zs_kd 0.0991 (0.1054) loss_oracle 0.4604 (0.4691) acc 87.5000 (87.6562) kd_loss 0.9750 (0.8743) lr 1.6374e-03 eta 0:12:10
epoch [16/50] batch [40/173] time 0.117 (0.113) data 0.000 (0.007) loss 0.8065 (0.7371) ce_loss 0.4268 (0.3334) teacher_loss 0.2425 (0.2229) loss_zs_kd 0.1064 (0.0903) loss_oracle 0.5109 (0.4690) acc 81.2500 (88.5938) kd_loss 0.8303 (0.8778) lr 1.6374e-03 eta 0:11:21
epoch [16/50] batch [60/173] time 0.133 (0.113) data 0.001 (0.005) loss 0.6814 (0.7415) ce_loss 0.1532 (0.3398) teacher_loss 0.1102 (0.2147) loss_zs_kd 0.0922 (0.0919) loss_oracle 0.5251 (0.4809) acc 96.8750 (88.1250) kd_loss 0.8073 (0.8775) lr 1.6374e-03 eta 0:11:16
epoch [16/50] batch [80/173] time 0.081 (0.109) data 0.000 (0.004) loss 0.6712 (0.7558) ce_loss 0.2249 (0.3513) teacher_loss 0.1799 (0.2180) loss_zs_kd 0.0543 (0.0966) loss_oracle 0.4641 (0.4895) acc 93.7500 (87.6172) kd_loss 0.8486 (0.8812) lr 1.6374e-03 eta 0:10:49
epoch [16/50] batch [100/173] time 0.106 (0.107) data 0.000 (0.003) loss 0.6453 (0.7660) ce_loss 0.1995 (0.3659) teacher_loss 0.1565 (0.2269) loss_zs_kd 0.0709 (0.0977) loss_oracle 0.4534 (0.4902) acc 90.6250 (87.0312) kd_loss 0.8446 (0.8837) lr 1.6374e-03 eta 0:10:38
epoch [16/50] batch [120/173] time 0.084 (0.104) data 0.000 (0.002) loss 0.6817 (0.7676) ce_loss 0.2039 (0.3710) teacher_loss 0.0704 (0.2290) loss_zs_kd 0.1300 (0.0983) loss_oracle 0.5463 (0.4894) acc 90.6250 (86.6667) kd_loss 0.9420 (0.8833) lr 1.6374e-03 eta 0:10:19
epoch [16/50] batch [140/173] time 0.080 (0.103) data 0.000 (0.002) loss 0.8031 (0.7657) ce_loss 0.3330 (0.3730) teacher_loss 0.1927 (0.2265) loss_zs_kd 0.1655 (0.1003) loss_oracle 0.5277 (0.4890) acc 87.5000 (86.4732) kd_loss 0.8675 (0.8848) lr 1.6374e-03 eta 0:10:06
epoch [16/50] batch [160/173] time 0.120 (0.102) data 0.000 (0.002) loss 0.7629 (0.7657) ce_loss 0.3948 (0.3747) teacher_loss 0.1539 (0.2254) loss_zs_kd 0.1054 (0.1018) loss_oracle 0.5564 (0.4894) acc 87.5000 (86.3672) kd_loss 0.9155 (0.8879) lr 1.6374e-03 eta 0:10:00
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,272
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [17/50] batch [20/173] time 0.115 (0.121) data 0.000 (0.015) loss 0.8923 (0.7216) ce_loss 0.5513 (0.3946) teacher_loss 0.3581 (0.2444) loss_zs_kd 0.1148 (0.0866) loss_oracle 0.4768 (0.4339) acc 81.2500 (86.4062) kd_loss 0.8672 (0.8725) lr 1.5878e-03 eta 0:11:46
epoch [17/50] batch [40/173] time 0.072 (0.113) data 0.000 (0.008) loss 0.7517 (0.7267) ce_loss 0.4673 (0.4006) teacher_loss 0.2250 (0.2453) loss_zs_kd 0.1328 (0.0941) loss_oracle 0.4603 (0.4344) acc 78.1250 (85.7031) kd_loss 0.9113 (0.8750) lr 1.5878e-03 eta 0:11:00
epoch [17/50] batch [60/173] time 0.080 (0.110) data 0.001 (0.005) loss 0.8826 (0.7208) ce_loss 0.5220 (0.3874) teacher_loss 0.3581 (0.2366) loss_zs_kd 0.1158 (0.0992) loss_oracle 0.4666 (0.4346) acc 81.2500 (86.4583) kd_loss 0.9268 (0.8709) lr 1.5878e-03 eta 0:10:41
epoch [17/50] batch [80/173] time 0.104 (0.111) data 0.000 (0.004) loss 0.6797 (0.7271) ce_loss 0.2441 (0.3878) teacher_loss 0.1120 (0.2326) loss_zs_kd 0.0869 (0.1030) loss_oracle 0.5243 (0.4430) acc 90.6250 (86.1719) kd_loss 0.8539 (0.8721) lr 1.5878e-03 eta 0:10:45
epoch [17/50] batch [100/173] time 0.092 (0.113) data 0.000 (0.003) loss 0.6766 (0.7243) ce_loss 0.2795 (0.3778) teacher_loss 0.1533 (0.2232) loss_zs_kd 0.0993 (0.1030) loss_oracle 0.4736 (0.4495) acc 93.7500 (86.2500) kd_loss 0.9345 (0.8812) lr 1.5878e-03 eta 0:10:52
epoch [17/50] batch [120/173] time 0.182 (0.119) data 0.000 (0.003) loss 0.6952 (0.7245) ce_loss 0.3325 (0.3803) teacher_loss 0.1558 (0.2198) loss_zs_kd 0.1206 (0.1036) loss_oracle 0.4791 (0.4529) acc 87.5000 (86.1198) kd_loss 0.9158 (0.8867) lr 1.5878e-03 eta 0:11:23
epoch [17/50] batch [140/173] time 0.070 (0.118) data 0.000 (0.002) loss 0.7192 (0.7268) ce_loss 0.3176 (0.3796) teacher_loss 0.1772 (0.2171) loss_zs_kd 0.1316 (0.1073) loss_oracle 0.4761 (0.4560) acc 87.5000 (86.2054) kd_loss 0.8593 (0.8912) lr 1.5878e-03 eta 0:11:16
epoch [17/50] batch [160/173] time 0.086 (0.121) data 0.000 (0.002) loss 0.7847 (0.7249) ce_loss 0.4688 (0.3777) teacher_loss 0.1605 (0.2137) loss_zs_kd 0.1411 (0.1078) loss_oracle 0.5536 (0.4573) acc 84.3750 (86.3086) kd_loss 0.9420 (0.8920) lr 1.5878e-03 eta 0:11:32
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,272
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [18/50] batch [20/173] time 0.108 (0.130) data 0.000 (0.019) loss 0.7385 (0.7323) ce_loss 0.3389 (0.3524) teacher_loss 0.2262 (0.2121) loss_zs_kd 0.1061 (0.0925) loss_oracle 0.4592 (0.4740) acc 81.2500 (86.7188) kd_loss 0.7817 (0.8730) lr 1.5358e-03 eta 0:12:18
epoch [18/50] batch [40/173] time 0.105 (0.120) data 0.001 (0.010) loss 0.7616 (0.7212) ce_loss 0.4216 (0.3395) teacher_loss 0.2469 (0.2063) loss_zs_kd 0.0896 (0.0931) loss_oracle 0.4699 (0.4683) acc 84.3750 (87.0312) kd_loss 0.8915 (0.8619) lr 1.5358e-03 eta 0:11:20
epoch [18/50] batch [60/173] time 0.105 (0.117) data 0.001 (0.006) loss 0.8152 (0.7289) ce_loss 0.3657 (0.3537) teacher_loss 0.3156 (0.2096) loss_zs_kd 0.0958 (0.0931) loss_oracle 0.4517 (0.4727) acc 84.3750 (86.6146) kd_loss 0.8393 (0.8630) lr 1.5358e-03 eta 0:10:58
epoch [18/50] batch [80/173] time 0.134 (0.116) data 0.000 (0.005) loss 0.6468 (0.7315) ce_loss 0.2120 (0.3535) teacher_loss 0.1302 (0.2065) loss_zs_kd 0.0951 (0.0956) loss_oracle 0.4690 (0.4772) acc 93.7500 (86.7578) kd_loss 0.8303 (0.8643) lr 1.5358e-03 eta 0:10:50
epoch [18/50] batch [100/173] time 0.072 (0.115) data 0.000 (0.004) loss 0.8364 (0.7365) ce_loss 0.5391 (0.3579) teacher_loss 0.2886 (0.2092) loss_zs_kd 0.1354 (0.0981) loss_oracle 0.4800 (0.4782) acc 78.1250 (86.5625) kd_loss 0.8741 (0.8708) lr 1.5358e-03 eta 0:10:44
epoch [18/50] batch [120/173] time 0.103 (0.115) data 0.000 (0.003) loss 0.7397 (0.7427) ce_loss 0.3557 (0.3667) teacher_loss 0.2174 (0.2160) loss_zs_kd 0.0888 (0.0999) loss_oracle 0.4779 (0.4767) acc 81.2500 (86.0677) kd_loss 0.9021 (0.8758) lr 1.5358e-03 eta 0:10:40
epoch [18/50] batch [140/173] time 0.131 (0.116) data 0.000 (0.003) loss 0.8951 (0.7456) ce_loss 0.4280 (0.3677) teacher_loss 0.3116 (0.2162) loss_zs_kd 0.1062 (0.1004) loss_oracle 0.5305 (0.4792) acc 87.5000 (86.1830) kd_loss 0.9183 (0.8841) lr 1.5358e-03 eta 0:10:44
epoch [18/50] batch [160/173] time 0.138 (0.116) data 0.000 (0.003) loss 0.5945 (0.7440) ce_loss 0.1738 (0.3635) teacher_loss 0.0745 (0.2141) loss_zs_kd 0.0680 (0.0996) loss_oracle 0.4859 (0.4801) acc 96.8750 (86.4258) kd_loss 0.9733 (0.8935) lr 1.5358e-03 eta 0:10:43
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,274
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [19/50] batch [20/173] time 0.137 (0.132) data 0.000 (0.016) loss 0.7552 (0.8263) ce_loss 0.4802 (0.4133) teacher_loss 0.2789 (0.2562) loss_zs_kd 0.0857 (0.1022) loss_oracle 0.4335 (0.5190) acc 81.2500 (84.8438) kd_loss 0.8840 (0.9321) lr 1.4818e-03 eta 0:12:06
epoch [19/50] batch [40/173] time 0.118 (0.123) data 0.000 (0.008) loss 0.8272 (0.8052) ce_loss 0.4802 (0.4170) teacher_loss 0.2526 (0.2522) loss_zs_kd 0.1422 (0.1001) loss_oracle 0.5035 (0.5030) acc 78.1250 (85.1562) kd_loss 0.9781 (0.9366) lr 1.4818e-03 eta 0:11:16
epoch [19/50] batch [60/173] time 0.089 (0.118) data 0.001 (0.006) loss 0.9291 (0.7907) ce_loss 0.4243 (0.3986) teacher_loss 0.3374 (0.2451) loss_zs_kd 0.1051 (0.1009) loss_oracle 0.5392 (0.4951) acc 84.3750 (85.5729) kd_loss 0.8926 (0.9239) lr 1.4818e-03 eta 0:10:46
epoch [19/50] batch [80/173] time 0.146 (0.115) data 0.000 (0.004) loss 0.6858 (0.7793) ce_loss 0.2485 (0.3884) teacher_loss 0.2040 (0.2388) loss_zs_kd 0.1011 (0.0988) loss_oracle 0.4312 (0.4912) acc 93.7500 (86.1328) kd_loss 0.8906 (0.9169) lr 1.4818e-03 eta 0:10:29
epoch [19/50] batch [100/173] time 0.085 (0.113) data 0.000 (0.003) loss 0.8146 (0.7795) ce_loss 0.5459 (0.3917) teacher_loss 0.2076 (0.2413) loss_zs_kd 0.1374 (0.0994) loss_oracle 0.5383 (0.4885) acc 81.2500 (85.9375) kd_loss 0.9334 (0.9112) lr 1.4818e-03 eta 0:10:16
epoch [19/50] batch [120/173] time 0.109 (0.113) data 0.000 (0.003) loss 0.6389 (0.7709) ce_loss 0.2229 (0.3884) teacher_loss 0.1818 (0.2425) loss_zs_kd 0.0801 (0.0962) loss_oracle 0.4170 (0.4804) acc 93.7500 (85.9635) kd_loss 0.9529 (0.9026) lr 1.4818e-03 eta 0:10:12
epoch [19/50] batch [140/173] time 0.076 (0.112) data 0.000 (0.003) loss 0.7985 (0.7674) ce_loss 0.3357 (0.3825) teacher_loss 0.2042 (0.2412) loss_zs_kd 0.1096 (0.0938) loss_oracle 0.5395 (0.4794) acc 90.6250 (86.0491) kd_loss 0.9401 (0.9010) lr 1.4818e-03 eta 0:10:02
epoch [19/50] batch [160/173] time 0.193 (0.111) data 0.000 (0.002) loss 0.8066 (0.7685) ce_loss 0.4573 (0.3818) teacher_loss 0.2138 (0.2397) loss_zs_kd 0.1296 (0.0941) loss_oracle 0.5280 (0.4817) acc 81.2500 (86.0156) kd_loss 0.9135 (0.9027) lr 1.4818e-03 eta 0:09:59
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,274
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [20/50] batch [20/173] time 0.135 (0.119) data 0.000 (0.015) loss 0.8707 (0.7971) ce_loss 0.5630 (0.4126) teacher_loss 0.4135 (0.2622) loss_zs_kd 0.1522 (0.0960) loss_oracle 0.3811 (0.4869) acc 78.1250 (83.9062) kd_loss 0.8392 (0.8662) lr 1.4258e-03 eta 0:10:34
epoch [20/50] batch [40/173] time 0.138 (0.111) data 0.000 (0.008) loss 0.7445 (0.7907) ce_loss 0.3289 (0.4026) teacher_loss 0.2901 (0.2579) loss_zs_kd 0.1422 (0.0941) loss_oracle 0.3832 (0.4859) acc 93.7500 (84.9219) kd_loss 0.7471 (0.8725) lr 1.4258e-03 eta 0:09:50
epoch [20/50] batch [60/173] time 0.085 (0.114) data 0.001 (0.005) loss 0.9625 (0.7927) ce_loss 0.6348 (0.3987) teacher_loss 0.4445 (0.2556) loss_zs_kd 0.0897 (0.0922) loss_oracle 0.4731 (0.4910) acc 75.0000 (85.1042) kd_loss 0.8517 (0.8740) lr 1.4258e-03 eta 0:10:03
epoch [20/50] batch [80/173] time 0.145 (0.116) data 0.000 (0.004) loss 0.7906 (0.7877) ce_loss 0.3630 (0.3964) teacher_loss 0.2820 (0.2530) loss_zs_kd 0.0978 (0.0905) loss_oracle 0.4597 (0.4895) acc 84.3750 (85.5469) kd_loss 0.8623 (0.8760) lr 1.4258e-03 eta 0:10:12
epoch [20/50] batch [100/173] time 0.143 (0.116) data 0.000 (0.003) loss 0.5919 (0.7795) ce_loss 0.2163 (0.3958) teacher_loss 0.1845 (0.2534) loss_zs_kd 0.0901 (0.0910) loss_oracle 0.3624 (0.4806) acc 90.6250 (85.5312) kd_loss 0.7775 (0.8761) lr 1.4258e-03 eta 0:10:12
epoch [20/50] batch [120/173] time 0.143 (0.118) data 0.000 (0.003) loss 0.5865 (0.7669) ce_loss 0.2092 (0.3870) teacher_loss 0.1242 (0.2482) loss_zs_kd 0.0795 (0.0885) loss_oracle 0.4225 (0.4745) acc 93.7500 (85.6510) kd_loss 0.9063 (0.8806) lr 1.4258e-03 eta 0:10:16
epoch [20/50] batch [140/173] time 0.135 (0.118) data 0.000 (0.002) loss 0.8307 (0.7671) ce_loss 0.3750 (0.3883) teacher_loss 0.3323 (0.2488) loss_zs_kd 0.1224 (0.0903) loss_oracle 0.4371 (0.4731) acc 87.5000 (85.6250) kd_loss 0.7549 (0.8815) lr 1.4258e-03 eta 0:10:14
epoch [20/50] batch [160/173] time 0.142 (0.118) data 0.001 (0.002) loss 0.7227 (0.7706) ce_loss 0.3940 (0.3910) teacher_loss 0.1993 (0.2520) loss_zs_kd 0.1036 (0.0908) loss_oracle 0.4715 (0.4732) acc 90.6250 (85.6445) kd_loss 0.9083 (0.8828) lr 1.4258e-03 eta 0:10:11
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,275
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [21/50] batch [20/173] time 0.119 (0.137) data 0.000 (0.016) loss 0.7812 (0.7832) ce_loss 0.3643 (0.4185) teacher_loss 0.2909 (0.2586) loss_zs_kd 0.1033 (0.0963) loss_oracle 0.4387 (0.4764) acc 84.3750 (84.2188) kd_loss 0.7657 (0.8924) lr 1.3681e-03 eta 0:11:49
epoch [21/50] batch [40/173] time 0.093 (0.125) data 0.000 (0.008) loss 0.8144 (0.7638) ce_loss 0.4275 (0.3903) teacher_loss 0.2633 (0.2467) loss_zs_kd 0.0731 (0.0942) loss_oracle 0.5145 (0.4701) acc 78.1250 (85.2344) kd_loss 0.9387 (0.8946) lr 1.3681e-03 eta 0:10:43
epoch [21/50] batch [60/173] time 0.089 (0.123) data 0.000 (0.005) loss 0.6467 (0.7695) ce_loss 0.2269 (0.3988) teacher_loss 0.1961 (0.2503) loss_zs_kd 0.0682 (0.0944) loss_oracle 0.4166 (0.4720) acc 87.5000 (85.0521) kd_loss 0.8981 (0.8931) lr 1.3681e-03 eta 0:10:30
epoch [21/50] batch [80/173] time 0.139 (0.123) data 0.000 (0.004) loss 0.6419 (0.7627) ce_loss 0.1377 (0.3935) teacher_loss 0.1377 (0.2468) loss_zs_kd 0.0556 (0.0929) loss_oracle 0.4765 (0.4695) acc 93.7500 (85.6641) kd_loss 0.8489 (0.8910) lr 1.3681e-03 eta 0:10:28
epoch [21/50] batch [100/173] time 0.126 (0.122) data 0.000 (0.003) loss 0.7998 (0.7568) ce_loss 0.3618 (0.3833) teacher_loss 0.2798 (0.2382) loss_zs_kd 0.1118 (0.0943) loss_oracle 0.4641 (0.4715) acc 87.5000 (86.0312) kd_loss 0.8990 (0.8918) lr 1.3681e-03 eta 0:10:20
epoch [21/50] batch [120/173] time 0.092 (0.119) data 0.000 (0.003) loss 0.5347 (0.7582) ce_loss 0.2085 (0.3892) teacher_loss 0.1523 (0.2418) loss_zs_kd 0.0904 (0.0953) loss_oracle 0.3372 (0.4687) acc 90.6250 (85.8854) kd_loss 0.7536 (0.8918) lr 1.3681e-03 eta 0:10:04
epoch [21/50] batch [140/173] time 0.118 (0.117) data 0.000 (0.002) loss 0.6807 (0.7586) ce_loss 0.2559 (0.3879) teacher_loss 0.2075 (0.2434) loss_zs_kd 0.0735 (0.0950) loss_oracle 0.4364 (0.4677) acc 93.7500 (85.7589) kd_loss 0.9167 (0.8936) lr 1.3681e-03 eta 0:09:53
epoch [21/50] batch [160/173] time 0.101 (0.116) data 0.000 (0.002) loss 0.6970 (0.7548) ce_loss 0.3567 (0.3849) teacher_loss 0.1956 (0.2402) loss_zs_kd 0.1132 (0.0956) loss_oracle 0.4448 (0.4668) acc 87.5000 (85.8203) kd_loss 0.9599 (0.8965) lr 1.3681e-03 eta 0:09:42
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,269
* accuracy: 95.1%
* error: 4.9%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.5%, epoch: 9 *******
******* Domain a best val test acc: 98.0%, epoch: 9 *******
******* Domain a best test acc:     98.0%, epoch: 21 *******
epoch [22/50] batch [20/173] time 0.187 (0.123) data 0.000 (0.012) loss 0.5646 (0.7352) ce_loss 0.0988 (0.3450) teacher_loss 0.0508 (0.2227) loss_zs_kd 0.0440 (0.0861) loss_oracle 0.4918 (0.4695) acc 96.8750 (88.1250) kd_loss 1.0258 (0.9670) lr 1.3090e-03 eta 0:10:17
epoch [22/50] batch [40/173] time 0.110 (0.131) data 0.000 (0.006) loss 0.8420 (0.7434) ce_loss 0.5171 (0.3758) teacher_loss 0.2932 (0.2355) loss_zs_kd 0.1016 (0.0867) loss_oracle 0.4980 (0.4646) acc 78.1250 (86.3281) kd_loss 0.8886 (0.9407) lr 1.3090e-03 eta 0:10:53
epoch [22/50] batch [60/173] time 0.146 (0.125) data 0.000 (0.004) loss 0.6584 (0.7503) ce_loss 0.2971 (0.3786) teacher_loss 0.1292 (0.2351) loss_zs_kd 0.0477 (0.0890) loss_oracle 0.5053 (0.4707) acc 87.5000 (86.1979) kd_loss 0.8596 (0.9124) lr 1.3090e-03 eta 0:10:18
epoch [22/50] batch [80/173] time 0.078 (0.123) data 0.000 (0.003) loss 0.7360 (0.7448) ce_loss 0.4424 (0.3804) teacher_loss 0.1904 (0.2364) loss_zs_kd 0.1214 (0.0898) loss_oracle 0.4850 (0.4635) acc 81.2500 (86.1328) kd_loss 0.9286 (0.8886) lr 1.3090e-03 eta 0:10:07
epoch [22/50] batch [100/173] time 0.099 (0.124) data 0.000 (0.003) loss 0.6131 (0.7459) ce_loss 0.2170 (0.3857) teacher_loss 0.2620 (0.2460) loss_zs_kd 0.0507 (0.0879) loss_oracle 0.3257 (0.4560) acc 90.6250 (85.9062) kd_loss 0.6805 (0.8735) lr 1.3090e-03 eta 0:10:10
epoch [22/50] batch [120/173] time 0.142 (0.125) data 0.000 (0.002) loss 0.6700 (0.7413) ce_loss 0.3313 (0.3889) teacher_loss 0.1989 (0.2497) loss_zs_kd 0.0863 (0.0863) loss_oracle 0.4280 (0.4484) acc 90.6250 (85.8594) kd_loss 0.7828 (0.8624) lr 1.3090e-03 eta 0:10:11
epoch [22/50] batch [140/173] time 0.143 (0.125) data 0.000 (0.002) loss 0.5025 (0.7376) ce_loss 0.2274 (0.3884) teacher_loss 0.1357 (0.2482) loss_zs_kd 0.0649 (0.0870) loss_oracle 0.3344 (0.4459) acc 90.6250 (85.8705) kd_loss 0.7276 (0.8563) lr 1.3090e-03 eta 0:10:07
epoch [22/50] batch [160/173] time 0.112 (0.123) data 0.000 (0.002) loss 0.9114 (0.7369) ce_loss 0.6543 (0.3900) teacher_loss 0.4360 (0.2498) loss_zs_kd 0.0738 (0.0875) loss_oracle 0.4386 (0.4433) acc 84.3750 (85.7812) kd_loss 0.8090 (0.8511) lr 1.3090e-03 eta 0:09:59
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,279
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,011
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.1%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.6%, epoch: 22 *******
******* Domain a best val test acc: 98.2%, epoch: 22 *******
******* Domain a best test acc:     98.2%, epoch: 22 *******
epoch [23/50] batch [20/173] time 0.101 (0.140) data 0.000 (0.015) loss 0.7735 (0.7361) ce_loss 0.4224 (0.3895) teacher_loss 0.2809 (0.2630) loss_zs_kd 0.1361 (0.0850) loss_oracle 0.4246 (0.4305) acc 81.2500 (85.9375) kd_loss 0.7620 (0.8175) lr 1.2487e-03 eta 0:11:15
epoch [23/50] batch [40/173] time 0.136 (0.130) data 0.000 (0.007) loss 0.7719 (0.7099) ce_loss 0.4851 (0.3728) teacher_loss 0.3253 (0.2481) loss_zs_kd 0.0918 (0.0814) loss_oracle 0.4007 (0.4212) acc 84.3750 (86.5625) kd_loss 0.8078 (0.8087) lr 1.2487e-03 eta 0:10:22
epoch [23/50] batch [60/173] time 0.145 (0.129) data 0.000 (0.005) loss 0.6451 (0.6965) ce_loss 0.3091 (0.3584) teacher_loss 0.0974 (0.2324) loss_zs_kd 0.1096 (0.0847) loss_oracle 0.4929 (0.4218) acc 90.6250 (86.7708) kd_loss 0.9183 (0.8133) lr 1.2487e-03 eta 0:10:17
epoch [23/50] batch [80/173] time 0.086 (0.125) data 0.000 (0.004) loss 0.6973 (0.7084) ce_loss 0.3325 (0.3668) teacher_loss 0.1690 (0.2416) loss_zs_kd 0.0814 (0.0857) loss_oracle 0.4876 (0.4240) acc 87.5000 (86.6016) kd_loss 0.8868 (0.8200) lr 1.2487e-03 eta 0:09:54
epoch [23/50] batch [100/173] time 0.088 (0.122) data 0.000 (0.003) loss 0.5182 (0.6991) ce_loss 0.1954 (0.3599) teacher_loss 0.0879 (0.2321) loss_zs_kd 0.0664 (0.0856) loss_oracle 0.3971 (0.4242) acc 90.6250 (86.6562) kd_loss 0.7653 (0.8246) lr 1.2487e-03 eta 0:09:37
epoch [23/50] batch [120/173] time 0.105 (0.119) data 0.000 (0.003) loss 0.8702 (0.7063) ce_loss 0.6172 (0.3653) teacher_loss 0.2701 (0.2351) loss_zs_kd 0.0874 (0.0872) loss_oracle 0.5565 (0.4277) acc 81.2500 (86.6667) kd_loss 1.0481 (0.8341) lr 1.2487e-03 eta 0:09:23
epoch [23/50] batch [140/173] time 0.079 (0.118) data 0.000 (0.002) loss 0.8152 (0.7086) ce_loss 0.4993 (0.3667) teacher_loss 0.3584 (0.2371) loss_zs_kd 0.0825 (0.0870) loss_oracle 0.4155 (0.4280) acc 84.3750 (86.4509) kd_loss 0.8682 (0.8435) lr 1.2487e-03 eta 0:09:14
epoch [23/50] batch [160/173] time 0.112 (0.117) data 0.000 (0.002) loss 0.4888 (0.7083) ce_loss 0.1100 (0.3650) teacher_loss 0.0993 (0.2381) loss_zs_kd 0.0414 (0.0866) loss_oracle 0.3687 (0.4269) acc 96.8750 (86.6406) kd_loss 0.8785 (0.8506) lr 1.2487e-03 eta 0:09:08
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,281
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.3%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.7%
******* Domain a best val acc:      95.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.2%, epoch: 22 *******
epoch [24/50] batch [20/173] time 0.188 (0.193) data 0.000 (0.014) loss 0.8353 (0.7229) ce_loss 0.5044 (0.3696) teacher_loss 0.3820 (0.2300) loss_zs_kd 0.1158 (0.1019) loss_oracle 0.3954 (0.4420) acc 75.0000 (85.4688) kd_loss 0.8126 (0.9040) lr 1.1874e-03 eta 0:14:57
epoch [24/50] batch [40/173] time 0.188 (0.172) data 0.000 (0.007) loss 0.8099 (0.7443) ce_loss 0.6479 (0.3900) teacher_loss 0.3191 (0.2456) loss_zs_kd 0.1132 (0.0974) loss_oracle 0.4341 (0.4500) acc 75.0000 (84.7656) kd_loss 0.9338 (0.9233) lr 1.1874e-03 eta 0:13:16
epoch [24/50] batch [60/173] time 0.120 (0.153) data 0.001 (0.005) loss 0.7947 (0.7517) ce_loss 0.3284 (0.4007) teacher_loss 0.2377 (0.2514) loss_zs_kd 0.1194 (0.0966) loss_oracle 0.4973 (0.4521) acc 84.3750 (84.4271) kd_loss 0.9226 (0.9172) lr 1.1874e-03 eta 0:11:45
epoch [24/50] batch [80/173] time 0.098 (0.141) data 0.000 (0.004) loss 0.7254 (0.7543) ce_loss 0.3047 (0.4029) teacher_loss 0.1808 (0.2455) loss_zs_kd 0.1081 (0.1001) loss_oracle 0.4905 (0.4587) acc 87.5000 (84.8438) kd_loss 0.9228 (0.9144) lr 1.1874e-03 eta 0:10:48
epoch [24/50] batch [100/173] time 0.111 (0.134) data 0.000 (0.003) loss 0.5344 (0.7488) ce_loss 0.1780 (0.3986) teacher_loss 0.1566 (0.2466) loss_zs_kd 0.0424 (0.0981) loss_oracle 0.3566 (0.4531) acc 96.8750 (85.0938) kd_loss 0.7738 (0.8970) lr 1.1874e-03 eta 0:10:14
epoch [24/50] batch [120/173] time 0.134 (0.130) data 0.000 (0.002) loss 0.7556 (0.7350) ce_loss 0.4792 (0.3861) teacher_loss 0.2874 (0.2420) loss_zs_kd 0.0565 (0.0928) loss_oracle 0.4399 (0.4466) acc 84.3750 (85.6510) kd_loss 0.7584 (0.8811) lr 1.1874e-03 eta 0:09:51
epoch [24/50] batch [140/173] time 0.098 (0.127) data 0.000 (0.002) loss 0.8642 (0.7340) ce_loss 0.4668 (0.3883) teacher_loss 0.3076 (0.2433) loss_zs_kd 0.1172 (0.0922) loss_oracle 0.4980 (0.4446) acc 87.5000 (85.5580) kd_loss 0.8963 (0.8731) lr 1.1874e-03 eta 0:09:33
epoch [24/50] batch [160/173] time 0.100 (0.124) data 0.000 (0.002) loss 1.0000 (0.7303) ce_loss 0.5347 (0.3871) teacher_loss 0.5441 (0.2432) loss_zs_kd 0.1065 (0.0926) loss_oracle 0.4026 (0.4408) acc 71.8750 (85.5664) kd_loss 0.8756 (0.8644) lr 1.1874e-03 eta 0:09:19
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,278
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.7%
******* Domain a best val acc:      95.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.2%, epoch: 22 *******
epoch [25/50] batch [20/173] time 0.133 (0.116) data 0.000 (0.013) loss 0.6774 (0.7421) ce_loss 0.3723 (0.4518) teacher_loss 0.2379 (0.2829) loss_zs_kd 0.0848 (0.0868) loss_oracle 0.3971 (0.4158) acc 84.3750 (84.5312) kd_loss 0.8433 (0.8104) lr 1.1253e-03 eta 0:08:41
epoch [25/50] batch [40/173] time 0.101 (0.112) data 0.000 (0.007) loss 0.5283 (0.7197) ce_loss 0.2296 (0.4122) teacher_loss 0.0836 (0.2591) loss_zs_kd 0.0794 (0.0893) loss_oracle 0.4050 (0.4160) acc 87.5000 (85.8594) kd_loss 0.8695 (0.8160) lr 1.1253e-03 eta 0:08:17
epoch [25/50] batch [60/173] time 0.095 (0.114) data 0.000 (0.005) loss 1.0671 (0.7240) ce_loss 0.9067 (0.4207) teacher_loss 0.5171 (0.2570) loss_zs_kd 0.1081 (0.0897) loss_oracle 0.4960 (0.4221) acc 68.7500 (85.2604) kd_loss 0.9234 (0.8293) lr 1.1253e-03 eta 0:08:25
epoch [25/50] batch [80/173] time 0.142 (0.116) data 0.000 (0.003) loss 0.7237 (0.7311) ce_loss 0.2981 (0.4099) teacher_loss 0.1896 (0.2545) loss_zs_kd 0.0958 (0.0935) loss_oracle 0.4861 (0.4298) acc 87.5000 (85.2734) kd_loss 0.8434 (0.8339) lr 1.1253e-03 eta 0:08:31
epoch [25/50] batch [100/173] time 0.136 (0.116) data 0.000 (0.003) loss 0.6996 (0.7276) ce_loss 0.3352 (0.4016) teacher_loss 0.2046 (0.2515) loss_zs_kd 0.0884 (0.0912) loss_oracle 0.4508 (0.4305) acc 84.3750 (85.5312) kd_loss 0.8646 (0.8354) lr 1.1253e-03 eta 0:08:30
epoch [25/50] batch [120/173] time 0.090 (0.117) data 0.000 (0.002) loss 0.7989 (0.7220) ce_loss 0.5581 (0.3968) teacher_loss 0.2989 (0.2489) loss_zs_kd 0.1171 (0.0891) loss_oracle 0.4414 (0.4285) acc 78.1250 (85.4688) kd_loss 0.8523 (0.8358) lr 1.1253e-03 eta 0:08:30
epoch [25/50] batch [140/173] time 0.137 (0.117) data 0.000 (0.002) loss 0.8109 (0.7229) ce_loss 0.4109 (0.3947) teacher_loss 0.2737 (0.2456) loss_zs_kd 0.1039 (0.0896) loss_oracle 0.4853 (0.4325) acc 90.6250 (85.7143) kd_loss 0.8954 (0.8410) lr 1.1253e-03 eta 0:08:31
epoch [25/50] batch [160/173] time 0.111 (0.117) data 0.000 (0.002) loss 0.7509 (0.7213) ce_loss 0.5654 (0.3926) teacher_loss 0.2477 (0.2427) loss_zs_kd 0.1114 (0.0897) loss_oracle 0.4475 (0.4338) acc 78.1250 (85.8398) kd_loss 0.8645 (0.8429) lr 1.1253e-03 eta 0:08:28
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,276
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      95.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.2%, epoch: 22 *******
epoch [26/50] batch [20/173] time 0.084 (0.124) data 0.000 (0.014) loss 0.6599 (0.6757) ce_loss 0.2515 (0.3327) teacher_loss 0.2060 (0.2024) loss_zs_kd 0.1004 (0.0827) loss_oracle 0.4037 (0.4319) acc 90.6250 (87.3438) kd_loss 0.9476 (0.8526) lr 1.0628e-03 eta 0:08:51
epoch [26/50] batch [40/173] time 0.135 (0.114) data 0.000 (0.007) loss 0.7088 (0.6859) ce_loss 0.4385 (0.3510) teacher_loss 0.2343 (0.2162) loss_zs_kd 0.0502 (0.0815) loss_oracle 0.4495 (0.4290) acc 84.3750 (86.5625) kd_loss 0.8593 (0.8518) lr 1.0628e-03 eta 0:08:10
epoch [26/50] batch [60/173] time 0.186 (0.122) data 0.000 (0.005) loss 0.8716 (0.7091) ce_loss 0.5005 (0.3747) teacher_loss 0.3441 (0.2301) loss_zs_kd 0.1330 (0.0861) loss_oracle 0.4610 (0.4359) acc 81.2500 (85.7292) kd_loss 0.9231 (0.8608) lr 1.0628e-03 eta 0:08:38
epoch [26/50] batch [80/173] time 0.157 (0.127) data 0.000 (0.004) loss 0.5332 (0.7220) ce_loss 0.1807 (0.3778) teacher_loss 0.0992 (0.2380) loss_zs_kd 0.0615 (0.0894) loss_oracle 0.4032 (0.4393) acc 93.7500 (85.8203) kd_loss 0.8522 (0.8572) lr 1.0628e-03 eta 0:08:58
epoch [26/50] batch [100/173] time 0.137 (0.128) data 0.000 (0.003) loss 0.6444 (0.7185) ce_loss 0.3921 (0.3856) teacher_loss 0.2779 (0.2464) loss_zs_kd 0.0737 (0.0883) loss_oracle 0.3297 (0.4279) acc 81.2500 (85.5938) kd_loss 0.7715 (0.8468) lr 1.0628e-03 eta 0:08:59
epoch [26/50] batch [120/173] time 0.134 (0.128) data 0.000 (0.002) loss 0.8633 (0.7200) ce_loss 0.5151 (0.3942) teacher_loss 0.3412 (0.2483) loss_zs_kd 0.0885 (0.0894) loss_oracle 0.4779 (0.4269) acc 84.3750 (85.3385) kd_loss 0.8052 (0.8458) lr 1.0628e-03 eta 0:08:56
epoch [26/50] batch [140/173] time 0.144 (0.127) data 0.000 (0.002) loss 0.7058 (0.7251) ce_loss 0.1807 (0.3941) teacher_loss 0.1280 (0.2498) loss_zs_kd 0.1088 (0.0915) loss_oracle 0.5234 (0.4295) acc 93.7500 (85.3795) kd_loss 0.9247 (0.8438) lr 1.0628e-03 eta 0:08:51
epoch [26/50] batch [160/173] time 0.143 (0.127) data 0.000 (0.002) loss 0.5970 (0.7212) ce_loss 0.2039 (0.3860) teacher_loss 0.1419 (0.2457) loss_zs_kd 0.0666 (0.0898) loss_oracle 0.4218 (0.4306) acc 93.7500 (85.6445) kd_loss 0.8353 (0.8434) lr 1.0628e-03 eta 0:08:46
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,277
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,011
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.1%
******* Domain a best val acc:      95.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.2%, epoch: 22 *******
epoch [27/50] batch [20/173] time 0.142 (0.136) data 0.000 (0.014) loss 0.7387 (0.7426) ce_loss 0.3374 (0.3828) teacher_loss 0.2249 (0.2535) loss_zs_kd 0.0760 (0.0912) loss_oracle 0.4757 (0.4435) acc 87.5000 (86.8750) kd_loss 0.8253 (0.8427) lr 1.0000e-03 eta 0:09:23
epoch [27/50] batch [40/173] time 0.108 (0.134) data 0.000 (0.007) loss 0.6892 (0.7451) ce_loss 0.3044 (0.3697) teacher_loss 0.2066 (0.2417) loss_zs_kd 0.0841 (0.0995) loss_oracle 0.4405 (0.4536) acc 90.6250 (86.9531) kd_loss 0.8698 (0.8633) lr 1.0000e-03 eta 0:09:12
epoch [27/50] batch [60/173] time 0.146 (0.133) data 0.001 (0.005) loss 0.6582 (0.7350) ce_loss 0.2396 (0.3606) teacher_loss 0.1550 (0.2341) loss_zs_kd 0.1055 (0.0994) loss_oracle 0.4505 (0.4512) acc 93.7500 (86.8750) kd_loss 0.8361 (0.8617) lr 1.0000e-03 eta 0:09:05
epoch [27/50] batch [80/173] time 0.140 (0.132) data 0.000 (0.004) loss 0.7537 (0.7346) ce_loss 0.5244 (0.3621) teacher_loss 0.3157 (0.2346) loss_zs_kd 0.0775 (0.0983) loss_oracle 0.3993 (0.4509) acc 84.3750 (86.6797) kd_loss 0.8750 (0.8698) lr 1.0000e-03 eta 0:08:57
epoch [27/50] batch [100/173] time 0.106 (0.131) data 0.000 (0.003) loss 0.6965 (0.7380) ce_loss 0.2274 (0.3607) teacher_loss 0.1647 (0.2360) loss_zs_kd 0.0880 (0.0993) loss_oracle 0.4878 (0.4523) acc 84.3750 (86.6875) kd_loss 0.9023 (0.8725) lr 1.0000e-03 eta 0:08:52
epoch [27/50] batch [120/173] time 0.133 (0.131) data 0.000 (0.003) loss 0.6156 (0.7339) ce_loss 0.2261 (0.3542) teacher_loss 0.1722 (0.2349) loss_zs_kd 0.0817 (0.0978) loss_oracle 0.4026 (0.4500) acc 93.7500 (86.9531) kd_loss 0.7434 (0.8728) lr 1.0000e-03 eta 0:08:47
epoch [27/50] batch [140/173] time 0.144 (0.131) data 0.000 (0.002) loss 0.8839 (0.7378) ce_loss 0.5381 (0.3571) teacher_loss 0.3251 (0.2384) loss_zs_kd 0.1005 (0.0969) loss_oracle 0.5086 (0.4510) acc 78.1250 (86.7411) kd_loss 0.8761 (0.8729) lr 1.0000e-03 eta 0:08:46
epoch [27/50] batch [160/173] time 0.098 (0.130) data 0.000 (0.002) loss 0.9017 (0.7401) ce_loss 0.4827 (0.3583) teacher_loss 0.3904 (0.2405) loss_zs_kd 0.1012 (0.0971) loss_oracle 0.4607 (0.4511) acc 87.5000 (86.5820) kd_loss 0.7972 (0.8731) lr 1.0000e-03 eta 0:08:37
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,280
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      95.6%, epoch: 23 *******
******* Domain a best val test acc: 97.8%, epoch: 23 *******
******* Domain a best test acc:     98.2%, epoch: 22 *******
epoch [28/50] batch [20/173] time 0.102 (0.125) data 0.000 (0.014) loss 0.6696 (0.7231) ce_loss 0.2174 (0.3328) teacher_loss 0.2033 (0.2329) loss_zs_kd 0.0618 (0.0870) loss_oracle 0.4353 (0.4467) acc 93.7500 (87.3438) kd_loss 0.8322 (0.8781) lr 9.3721e-04 eta 0:08:15
epoch [28/50] batch [40/173] time 0.080 (0.121) data 0.000 (0.007) loss 0.6992 (0.7419) ce_loss 0.2561 (0.3422) teacher_loss 0.1909 (0.2370) loss_zs_kd 0.0802 (0.0893) loss_oracle 0.4682 (0.4603) acc 90.6250 (87.4219) kd_loss 0.9060 (0.8657) lr 9.3721e-04 eta 0:07:56
epoch [28/50] batch [60/173] time 0.187 (0.138) data 0.000 (0.005) loss 0.7890 (0.7447) ce_loss 0.4507 (0.3379) teacher_loss 0.2505 (0.2291) loss_zs_kd 0.1182 (0.0925) loss_oracle 0.4795 (0.4693) acc 81.2500 (87.5000) kd_loss 0.8138 (0.8578) lr 9.3721e-04 eta 0:09:01
epoch [28/50] batch [80/173] time 0.198 (0.139) data 0.000 (0.004) loss 0.7543 (0.7485) ce_loss 0.3691 (0.3386) teacher_loss 0.2843 (0.2283) loss_zs_kd 0.1016 (0.0935) loss_oracle 0.4192 (0.4735) acc 84.3750 (87.5391) kd_loss 0.8575 (0.8592) lr 9.3721e-04 eta 0:09:01
epoch [28/50] batch [100/173] time 0.129 (0.135) data 0.000 (0.003) loss 0.8489 (0.7485) ce_loss 0.5156 (0.3416) teacher_loss 0.2471 (0.2226) loss_zs_kd 0.1859 (0.0963) loss_oracle 0.5088 (0.4777) acc 78.1250 (87.2812) kd_loss 0.8850 (0.8620) lr 9.3721e-04 eta 0:08:42
epoch [28/50] batch [120/173] time 0.144 (0.132) data 0.000 (0.003) loss 0.6776 (0.7548) ce_loss 0.2830 (0.3448) teacher_loss 0.1494 (0.2240) loss_zs_kd 0.1300 (0.0996) loss_oracle 0.4632 (0.4810) acc 90.6250 (87.1615) kd_loss 0.7710 (0.8591) lr 9.3721e-04 eta 0:08:27
epoch [28/50] batch [140/173] time 0.121 (0.132) data 0.000 (0.002) loss 0.6061 (0.7522) ce_loss 0.1426 (0.3364) teacher_loss 0.0841 (0.2200) loss_zs_kd 0.0790 (0.0978) loss_oracle 0.4825 (0.4832) acc 93.7500 (87.3661) kd_loss 0.8318 (0.8532) lr 9.3721e-04 eta 0:08:25
epoch [28/50] batch [160/173] time 0.093 (0.130) data 0.000 (0.002) loss 0.9925 (0.7601) ce_loss 0.5474 (0.3455) teacher_loss 0.4192 (0.2299) loss_zs_kd 0.0996 (0.0973) loss_oracle 0.5236 (0.4816) acc 81.2500 (87.1484) kd_loss 0.8072 (0.8431) lr 9.3721e-04 eta 0:08:14
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,289
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,011
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.1%
******* Domain a best val acc:      96.0%, epoch: 28 *******
******* Domain a best val test acc: 98.2%, epoch: 28 *******
******* Domain a best test acc:     98.2%, epoch: 22 *******
epoch [29/50] batch [20/173] time 0.132 (0.115) data 0.000 (0.010) loss 0.7510 (0.7772) ce_loss 0.2605 (0.3768) teacher_loss 0.2079 (0.2796) loss_zs_kd 0.0788 (0.0909) loss_oracle 0.5038 (0.4521) acc 84.3750 (86.5625) kd_loss 0.7977 (0.7483) lr 8.7467e-04 eta 0:07:17
epoch [29/50] batch [40/173] time 0.133 (0.113) data 0.000 (0.005) loss 0.6919 (0.7717) ce_loss 0.2429 (0.3767) teacher_loss 0.1824 (0.2766) loss_zs_kd 0.0952 (0.0955) loss_oracle 0.4618 (0.4473) acc 87.5000 (86.6406) kd_loss 0.7505 (0.7372) lr 8.7467e-04 eta 0:07:04
epoch [29/50] batch [60/173] time 0.109 (0.112) data 0.001 (0.004) loss 0.9283 (0.7741) ce_loss 0.4812 (0.3639) teacher_loss 0.3531 (0.2711) loss_zs_kd 0.1351 (0.0983) loss_oracle 0.5077 (0.4538) acc 81.2500 (87.0312) kd_loss 0.7572 (0.7452) lr 8.7467e-04 eta 0:06:58
epoch [29/50] batch [80/173] time 0.088 (0.110) data 0.000 (0.003) loss 0.9028 (0.7687) ce_loss 0.4426 (0.3624) teacher_loss 0.3949 (0.2714) loss_zs_kd 0.0910 (0.0958) loss_oracle 0.4624 (0.4493) acc 84.3750 (87.1484) kd_loss 0.7462 (0.7451) lr 8.7467e-04 eta 0:06:51
epoch [29/50] batch [100/173] time 0.093 (0.109) data 0.000 (0.002) loss 0.6931 (0.7666) ce_loss 0.3628 (0.3654) teacher_loss 0.2442 (0.2722) loss_zs_kd 0.0716 (0.0951) loss_oracle 0.4131 (0.4468) acc 84.3750 (86.9062) kd_loss 0.8172 (0.7554) lr 8.7467e-04 eta 0:06:45
epoch [29/50] batch [120/173] time 0.121 (0.110) data 0.000 (0.002) loss 0.8759 (0.7623) ce_loss 0.5010 (0.3603) teacher_loss 0.3576 (0.2689) loss_zs_kd 0.0974 (0.0943) loss_oracle 0.4696 (0.4463) acc 78.1250 (86.9271) kd_loss 0.7468 (0.7610) lr 8.7467e-04 eta 0:06:44
epoch [29/50] batch [140/173] time 0.095 (0.111) data 0.000 (0.002) loss 0.9418 (0.7558) ce_loss 0.5835 (0.3523) teacher_loss 0.3991 (0.2624) loss_zs_kd 0.1324 (0.0934) loss_oracle 0.4766 (0.4468) acc 81.2500 (87.1205) kd_loss 0.8253 (0.7627) lr 8.7467e-04 eta 0:06:47
epoch [29/50] batch [160/173] time 0.101 (0.111) data 0.000 (0.001) loss 0.7256 (0.7556) ce_loss 0.1865 (0.3525) teacher_loss 0.1316 (0.2616) loss_zs_kd 0.0697 (0.0935) loss_oracle 0.5591 (0.4473) acc 96.8750 (87.1680) kd_loss 0.7927 (0.7649) lr 8.7467e-04 eta 0:06:45
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,289
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,013
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 98.2%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      96.0%, epoch: 28 *******
******* Domain a best val test acc: 98.2%, epoch: 28 *******
******* Domain a best test acc:     98.3%, epoch: 29 *******
epoch [30/50] batch [20/173] time 0.117 (0.137) data 0.001 (0.015) loss 0.5967 (0.7041) ce_loss 0.1499 (0.3090) teacher_loss 0.0793 (0.2170) loss_zs_kd 0.1335 (0.0987) loss_oracle 0.4506 (0.4377) acc 100.0000 (88.5938) kd_loss 0.7437 (0.8002) lr 8.1262e-04 eta 0:08:16
epoch [30/50] batch [40/173] time 0.133 (0.130) data 0.000 (0.008) loss 0.7049 (0.7075) ce_loss 0.2705 (0.3137) teacher_loss 0.2702 (0.2222) loss_zs_kd 0.0786 (0.0951) loss_oracle 0.3955 (0.4378) acc 93.7500 (87.8125) kd_loss 0.8369 (0.8104) lr 8.1262e-04 eta 0:07:45
epoch [30/50] batch [60/173] time 0.078 (0.124) data 0.000 (0.005) loss 0.6796 (0.7033) ce_loss 0.2959 (0.3153) teacher_loss 0.2503 (0.2245) loss_zs_kd 0.1040 (0.0958) loss_oracle 0.3773 (0.4309) acc 96.8750 (88.0729) kd_loss 0.8221 (0.8165) lr 8.1262e-04 eta 0:07:24
epoch [30/50] batch [80/173] time 0.187 (0.137) data 0.000 (0.004) loss 0.8418 (0.7101) ce_loss 0.4897 (0.3267) teacher_loss 0.3375 (0.2322) loss_zs_kd 0.1055 (0.0972) loss_oracle 0.4516 (0.4293) acc 81.2500 (87.7734) kd_loss 0.8226 (0.8220) lr 8.1262e-04 eta 0:08:05
epoch [30/50] batch [100/173] time 0.184 (0.136) data 0.000 (0.003) loss 0.7801 (0.7143) ce_loss 0.4026 (0.3309) teacher_loss 0.3077 (0.2370) loss_zs_kd 0.1032 (0.1002) loss_oracle 0.4209 (0.4272) acc 87.5000 (87.5000) kd_loss 0.7876 (0.8188) lr 8.1262e-04 eta 0:08:02
epoch [30/50] batch [120/173] time 0.142 (0.132) data 0.000 (0.003) loss 0.7866 (0.7192) ce_loss 0.3816 (0.3406) teacher_loss 0.3085 (0.2469) loss_zs_kd 0.0936 (0.0980) loss_oracle 0.4314 (0.4233) acc 81.2500 (87.0833) kd_loss 0.8571 (0.8157) lr 8.1262e-04 eta 0:07:45
epoch [30/50] batch [140/173] time 0.088 (0.129) data 0.000 (0.002) loss 0.7100 (0.7182) ce_loss 0.3628 (0.3401) teacher_loss 0.2176 (0.2441) loss_zs_kd 0.1079 (0.0985) loss_oracle 0.4384 (0.4248) acc 87.5000 (87.2098) kd_loss 0.8098 (0.8195) lr 8.1262e-04 eta 0:07:31
epoch [30/50] batch [160/173] time 0.128 (0.126) data 0.000 (0.002) loss 0.8026 (0.7218) ce_loss 0.4226 (0.3424) teacher_loss 0.2621 (0.2447) loss_zs_kd 0.1209 (0.1003) loss_oracle 0.4800 (0.4270) acc 81.2500 (87.0312) kd_loss 0.9197 (0.8214) lr 8.1262e-04 eta 0:07:18
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,293
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.7%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,014
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 98.3%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      96.1%, epoch: 30 *******
******* Domain a best val test acc: 98.3%, epoch: 30 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [31/50] batch [20/173] time 0.123 (0.119) data 0.000 (0.012) loss 0.8024 (0.7011) ce_loss 0.4597 (0.3130) teacher_loss 0.3093 (0.2223) loss_zs_kd 0.1226 (0.1053) loss_oracle 0.4318 (0.4262) acc 90.6250 (88.2812) kd_loss 0.9129 (0.8522) lr 7.5131e-04 eta 0:06:48
epoch [31/50] batch [40/173] time 0.141 (0.115) data 0.000 (0.006) loss 0.9256 (0.7158) ce_loss 0.6660 (0.3455) teacher_loss 0.4192 (0.2405) loss_zs_kd 0.1373 (0.1058) loss_oracle 0.4378 (0.4224) acc 78.1250 (86.6406) kd_loss 0.8245 (0.8563) lr 7.5131e-04 eta 0:06:33
epoch [31/50] batch [60/173] time 0.110 (0.113) data 0.001 (0.004) loss 0.7525 (0.7144) ce_loss 0.4294 (0.3471) teacher_loss 0.2941 (0.2413) loss_zs_kd 0.1482 (0.1047) loss_oracle 0.3843 (0.4208) acc 78.1250 (86.4062) kd_loss 0.7562 (0.8475) lr 7.5131e-04 eta 0:06:24
epoch [31/50] batch [80/173] time 0.142 (0.111) data 0.000 (0.003) loss 0.7897 (0.7125) ce_loss 0.3396 (0.3373) teacher_loss 0.2394 (0.2370) loss_zs_kd 0.1332 (0.1041) loss_oracle 0.4836 (0.4234) acc 84.3750 (87.1484) kd_loss 0.9097 (0.8451) lr 7.5131e-04 eta 0:06:16
epoch [31/50] batch [100/173] time 0.080 (0.110) data 0.000 (0.003) loss 0.7968 (0.7064) ce_loss 0.3176 (0.3265) teacher_loss 0.2644 (0.2300) loss_zs_kd 0.0755 (0.1021) loss_oracle 0.4947 (0.4253) acc 96.8750 (87.8750) kd_loss 0.9012 (0.8461) lr 7.5131e-04 eta 0:06:09
epoch [31/50] batch [120/173] time 0.100 (0.109) data 0.000 (0.002) loss 0.8222 (0.7081) ce_loss 0.4302 (0.3229) teacher_loss 0.3142 (0.2265) loss_zs_kd 0.0942 (0.0997) loss_oracle 0.4609 (0.4317) acc 84.3750 (87.7344) kd_loss 0.8670 (0.8526) lr 7.5131e-04 eta 0:06:03
epoch [31/50] batch [140/173] time 0.079 (0.109) data 0.000 (0.002) loss 0.9736 (0.7154) ce_loss 0.5718 (0.3252) teacher_loss 0.4451 (0.2272) loss_zs_kd 0.1334 (0.1004) loss_oracle 0.4618 (0.4380) acc 81.2500 (87.6116) kd_loss 0.9224 (0.8626) lr 7.5131e-04 eta 0:06:03
epoch [31/50] batch [160/173] time 0.122 (0.109) data 0.000 (0.002) loss 0.7967 (0.7201) ce_loss 0.3552 (0.3250) teacher_loss 0.1790 (0.2241) loss_zs_kd 0.1538 (0.1026) loss_oracle 0.5408 (0.4447) acc 90.6250 (87.5000) kd_loss 0.9706 (0.8731) lr 7.5131e-04 eta 0:05:58
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,013
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 98.2%
******* Domain a best val acc:      96.1%, epoch: 30 *******
******* Domain a best val test acc: 98.3%, epoch: 30 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [32/50] batch [20/173] time 0.118 (0.121) data 0.000 (0.013) loss 0.7095 (0.7930) ce_loss 0.2423 (0.3538) teacher_loss 0.1310 (0.2183) loss_zs_kd 0.0947 (0.1097) loss_oracle 0.5312 (0.5198) acc 87.5000 (87.9688) kd_loss 1.0666 (0.9624) lr 6.9098e-04 eta 0:06:33
epoch [32/50] batch [40/173] time 0.117 (0.115) data 0.000 (0.007) loss 0.8194 (0.7949) ce_loss 0.3203 (0.3433) teacher_loss 0.1518 (0.2132) loss_zs_kd 0.1370 (0.1162) loss_oracle 0.5991 (0.5235) acc 87.5000 (87.8906) kd_loss 1.0565 (0.9763) lr 6.9098e-04 eta 0:06:13
epoch [32/50] batch [60/173] time 0.094 (0.112) data 0.001 (0.005) loss 0.8580 (0.8196) ce_loss 0.4714 (0.3679) teacher_loss 0.2259 (0.2334) loss_zs_kd 0.1154 (0.1172) loss_oracle 0.5743 (0.5275) acc 81.2500 (86.7188) kd_loss 0.9788 (0.9864) lr 6.9098e-04 eta 0:06:01
epoch [32/50] batch [80/173] time 0.131 (0.112) data 0.000 (0.003) loss 0.7083 (0.8111) ce_loss 0.2212 (0.3563) teacher_loss 0.1373 (0.2283) loss_zs_kd 0.1020 (0.1126) loss_oracle 0.5200 (0.5265) acc 96.8750 (87.1094) kd_loss 1.0231 (0.9907) lr 6.9098e-04 eta 0:05:58
epoch [32/50] batch [100/173] time 0.093 (0.113) data 0.000 (0.003) loss 0.6244 (0.8132) ce_loss 0.1765 (0.3558) teacher_loss 0.1145 (0.2266) loss_zs_kd 0.0822 (0.1127) loss_oracle 0.4688 (0.5302) acc 93.7500 (87.0000) kd_loss 0.8724 (0.9953) lr 6.9098e-04 eta 0:05:59
epoch [32/50] batch [120/173] time 0.130 (0.112) data 0.000 (0.002) loss 0.6277 (0.8217) ce_loss 0.1516 (0.3635) teacher_loss 0.1110 (0.2345) loss_zs_kd 0.0572 (0.1110) loss_oracle 0.4881 (0.5317) acc 93.7500 (86.7969) kd_loss 0.8898 (1.0017) lr 6.9098e-04 eta 0:05:55
epoch [32/50] batch [140/173] time 0.068 (0.119) data 0.000 (0.002) loss 0.8666 (0.8184) ce_loss 0.3882 (0.3564) teacher_loss 0.2805 (0.2301) loss_zs_kd 0.0858 (0.1087) loss_oracle 0.5432 (0.5339) acc 84.3750 (86.9866) kd_loss 1.0567 (1.0044) lr 6.9098e-04 eta 0:06:15
epoch [32/50] batch [160/173] time 0.148 (0.122) data 0.000 (0.002) loss 0.9708 (0.8183) ce_loss 0.5283 (0.3581) teacher_loss 0.3270 (0.2277) loss_zs_kd 0.1111 (0.1080) loss_oracle 0.5882 (0.5367) acc 78.1250 (87.0312) kd_loss 1.1037 (1.0086) lr 6.9098e-04 eta 0:06:22
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,295
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.8%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,012
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.2%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [33/50] batch [20/173] time 0.076 (0.119) data 0.000 (0.016) loss 0.8192 (0.8468) ce_loss 0.3928 (0.3851) teacher_loss 0.2120 (0.2404) loss_zs_kd 0.1590 (0.1210) loss_oracle 0.5277 (0.5459) acc 81.2500 (86.0938) kd_loss 0.9232 (1.0099) lr 6.3188e-04 eta 0:06:06
epoch [33/50] batch [40/173] time 0.092 (0.115) data 0.000 (0.008) loss 0.7567 (0.8517) ce_loss 0.2058 (0.3904) teacher_loss 0.0635 (0.2225) loss_zs_kd 0.1190 (0.1326) loss_oracle 0.6337 (0.5629) acc 90.6250 (85.4688) kd_loss 1.0776 (1.0098) lr 6.3188e-04 eta 0:05:52
epoch [33/50] batch [60/173] time 0.144 (0.117) data 0.001 (0.006) loss 1.0138 (0.8461) ce_loss 0.5688 (0.3911) teacher_loss 0.3019 (0.2184) loss_zs_kd 0.1182 (0.1308) loss_oracle 0.6528 (0.5623) acc 75.0000 (85.2604) kd_loss 1.1707 (1.0028) lr 6.3188e-04 eta 0:05:58
epoch [33/50] batch [80/173] time 0.102 (0.118) data 0.000 (0.004) loss 0.7690 (0.8415) ce_loss 0.2969 (0.3916) teacher_loss 0.1853 (0.2181) loss_zs_kd 0.0957 (0.1282) loss_oracle 0.5359 (0.5593) acc 90.6250 (85.5078) kd_loss 1.0258 (0.9983) lr 6.3188e-04 eta 0:05:59
epoch [33/50] batch [100/173] time 0.140 (0.119) data 0.001 (0.004) loss 0.6765 (0.8315) ce_loss 0.3105 (0.3857) teacher_loss 0.1405 (0.2154) loss_zs_kd 0.1760 (0.1279) loss_oracle 0.4480 (0.5522) acc 87.5000 (85.8125) kd_loss 0.8263 (0.9805) lr 6.3188e-04 eta 0:05:57
epoch [33/50] batch [120/173] time 0.131 (0.118) data 0.000 (0.003) loss 1.0035 (0.8240) ce_loss 0.6050 (0.3869) teacher_loss 0.5155 (0.2186) loss_zs_kd 0.1261 (0.1273) loss_oracle 0.4250 (0.5418) acc 75.0000 (85.7031) kd_loss 0.8229 (0.9649) lr 6.3188e-04 eta 0:05:53
epoch [33/50] batch [140/173] time 0.135 (0.118) data 0.000 (0.003) loss 0.6573 (0.8151) ce_loss 0.3242 (0.3850) teacher_loss 0.1745 (0.2207) loss_zs_kd 0.1045 (0.1249) loss_oracle 0.4306 (0.5320) acc 81.2500 (85.7143) kd_loss 0.7851 (0.9500) lr 6.3188e-04 eta 0:05:52
epoch [33/50] batch [160/173] time 0.116 (0.119) data 0.000 (0.002) loss 0.7619 (0.8036) ce_loss 0.3977 (0.3754) teacher_loss 0.2395 (0.2200) loss_zs_kd 0.0922 (0.1228) loss_oracle 0.4764 (0.5222) acc 84.3750 (86.0547) kd_loss 0.9090 (0.9347) lr 6.3188e-04 eta 0:05:50
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,283
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,011
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.1%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [34/50] batch [20/173] time 0.140 (0.131) data 0.000 (0.014) loss 0.5795 (0.7460) ce_loss 0.2335 (0.3552) teacher_loss 0.1395 (0.2481) loss_zs_kd 0.0759 (0.0924) loss_oracle 0.4020 (0.4516) acc 93.7500 (86.7188) kd_loss 0.9288 (0.8276) lr 5.7422e-04 eta 0:06:21
epoch [34/50] batch [40/173] time 0.142 (0.122) data 0.000 (0.007) loss 0.8715 (0.7357) ce_loss 0.4412 (0.3407) teacher_loss 0.3505 (0.2367) loss_zs_kd 0.1406 (0.0934) loss_oracle 0.4507 (0.4523) acc 84.3750 (87.1094) kd_loss 0.8421 (0.8445) lr 5.7422e-04 eta 0:05:53
epoch [34/50] batch [60/173] time 0.129 (0.114) data 0.000 (0.005) loss 0.5858 (0.7328) ce_loss 0.1528 (0.3399) teacher_loss 0.1097 (0.2288) loss_zs_kd 0.0783 (0.0952) loss_oracle 0.4370 (0.4564) acc 93.7500 (86.9792) kd_loss 0.7977 (0.8549) lr 5.7422e-04 eta 0:05:29
epoch [34/50] batch [80/173] time 0.084 (0.113) data 0.000 (0.004) loss 0.7833 (0.7421) ce_loss 0.3760 (0.3451) teacher_loss 0.2191 (0.2334) loss_zs_kd 0.1099 (0.0987) loss_oracle 0.5093 (0.4594) acc 84.3750 (86.7969) kd_loss 0.9485 (0.8644) lr 5.7422e-04 eta 0:05:23
epoch [34/50] batch [100/173] time 0.133 (0.112) data 0.000 (0.003) loss 0.8199 (0.7378) ce_loss 0.4412 (0.3401) teacher_loss 0.3033 (0.2313) loss_zs_kd 0.1156 (0.0990) loss_oracle 0.4588 (0.4570) acc 78.1250 (86.7500) kd_loss 0.8366 (0.8564) lr 5.7422e-04 eta 0:05:19
epoch [34/50] batch [120/173] time 0.082 (0.112) data 0.000 (0.002) loss 0.6469 (0.7388) ce_loss 0.2399 (0.3374) teacher_loss 0.1495 (0.2311) loss_zs_kd 0.0895 (0.1001) loss_oracle 0.4527 (0.4577) acc 90.6250 (86.9792) kd_loss 0.7381 (0.8464) lr 5.7422e-04 eta 0:05:14
epoch [34/50] batch [140/173] time 0.134 (0.111) data 0.000 (0.002) loss 0.5738 (0.7381) ce_loss 0.2266 (0.3361) teacher_loss 0.1329 (0.2323) loss_zs_kd 0.0608 (0.0985) loss_oracle 0.4105 (0.4565) acc 93.7500 (87.0312) kd_loss 0.8009 (0.8369) lr 5.7422e-04 eta 0:05:12
epoch [34/50] batch [160/173] time 0.186 (0.111) data 0.000 (0.002) loss 0.6973 (0.7331) ce_loss 0.2729 (0.3312) teacher_loss 0.1735 (0.2295) loss_zs_kd 0.0814 (0.0974) loss_oracle 0.4831 (0.4549) acc 87.5000 (87.3242) kd_loss 0.7529 (0.8250) lr 5.7422e-04 eta 0:05:09
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,297
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [35/50] batch [20/173] time 0.116 (0.128) data 0.000 (0.014) loss 0.7631 (0.7126) ce_loss 0.4531 (0.3243) teacher_loss 0.3561 (0.2289) loss_zs_kd 0.0894 (0.1016) loss_oracle 0.3623 (0.4329) acc 81.2500 (87.9688) kd_loss 0.6967 (0.7493) lr 5.1825e-04 eta 0:05:51
epoch [35/50] batch [40/173] time 0.118 (0.114) data 0.000 (0.007) loss 0.7778 (0.7141) ce_loss 0.4775 (0.3447) teacher_loss 0.2248 (0.2393) loss_zs_kd 0.1693 (0.1013) loss_oracle 0.4684 (0.4241) acc 87.5000 (87.1875) kd_loss 0.8649 (0.7652) lr 5.1825e-04 eta 0:05:11
epoch [35/50] batch [60/173] time 0.091 (0.108) data 0.001 (0.005) loss 0.6101 (0.7076) ce_loss 0.2510 (0.3380) teacher_loss 0.1796 (0.2324) loss_zs_kd 0.0896 (0.1010) loss_oracle 0.3856 (0.4247) acc 93.7500 (87.3958) kd_loss 0.7578 (0.7815) lr 5.1825e-04 eta 0:04:52
epoch [35/50] batch [80/173] time 0.086 (0.108) data 0.000 (0.004) loss 0.7828 (0.7172) ce_loss 0.4280 (0.3504) teacher_loss 0.2845 (0.2410) loss_zs_kd 0.1033 (0.1000) loss_oracle 0.4466 (0.4262) acc 81.2500 (86.9922) kd_loss 0.7743 (0.7887) lr 5.1825e-04 eta 0:04:49
epoch [35/50] batch [100/173] time 0.142 (0.108) data 0.000 (0.003) loss 0.6842 (0.7255) ce_loss 0.2932 (0.3595) teacher_loss 0.2317 (0.2490) loss_zs_kd 0.0941 (0.1006) loss_oracle 0.4055 (0.4262) acc 90.6250 (86.5312) kd_loss 0.8948 (0.7953) lr 5.1825e-04 eta 0:04:47
epoch [35/50] batch [120/173] time 0.143 (0.109) data 0.000 (0.003) loss 0.6543 (0.7261) ce_loss 0.2212 (0.3624) teacher_loss 0.1621 (0.2458) loss_zs_kd 0.0879 (0.1030) loss_oracle 0.4483 (0.4287) acc 90.6250 (86.2500) kd_loss 0.8459 (0.8021) lr 5.1825e-04 eta 0:04:49
epoch [35/50] batch [140/173] time 0.097 (0.111) data 0.000 (0.002) loss 0.7260 (0.7300) ce_loss 0.3369 (0.3652) teacher_loss 0.2317 (0.2470) loss_zs_kd 0.1283 (0.1036) loss_oracle 0.4301 (0.4312) acc 93.7500 (86.1607) kd_loss 0.8977 (0.8084) lr 5.1825e-04 eta 0:04:50
epoch [35/50] batch [160/173] time 0.116 (0.112) data 0.000 (0.002) loss 0.5283 (0.7266) ce_loss 0.1515 (0.3583) teacher_loss 0.1007 (0.2421) loss_zs_kd 0.0547 (0.1026) loss_oracle 0.4003 (0.4332) acc 96.8750 (86.4258) kd_loss 0.8521 (0.8183) lr 5.1825e-04 eta 0:04:52
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,287
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [36/50] batch [20/173] time 0.114 (0.137) data 0.000 (0.016) loss 0.7060 (0.7210) ce_loss 0.3843 (0.4109) teacher_loss 0.2843 (0.2490) loss_zs_kd 0.1084 (0.1063) loss_oracle 0.3674 (0.4189) acc 81.2500 (84.8438) kd_loss 0.8707 (0.8505) lr 4.6417e-04 eta 0:05:52
epoch [36/50] batch [40/173] time 0.083 (0.125) data 0.001 (0.008) loss 0.7378 (0.7097) ce_loss 0.4507 (0.3811) teacher_loss 0.2278 (0.2274) loss_zs_kd 0.1200 (0.1121) loss_oracle 0.4500 (0.4262) acc 87.5000 (85.8594) kd_loss 0.8084 (0.8562) lr 4.6417e-04 eta 0:05:19
epoch [36/50] batch [60/173] time 0.144 (0.124) data 0.001 (0.005) loss 0.7886 (0.6927) ce_loss 0.4802 (0.3487) teacher_loss 0.3358 (0.2147) loss_zs_kd 0.1120 (0.1063) loss_oracle 0.3968 (0.4248) acc 75.0000 (87.0312) kd_loss 0.9266 (0.8462) lr 4.6417e-04 eta 0:05:15
epoch [36/50] batch [80/173] time 0.144 (0.124) data 0.001 (0.004) loss 0.5520 (0.6878) ce_loss 0.1671 (0.3496) teacher_loss 0.0819 (0.2123) loss_zs_kd 0.0846 (0.1045) loss_oracle 0.4278 (0.4233) acc 93.7500 (86.6406) kd_loss 0.7389 (0.8381) lr 4.6417e-04 eta 0:05:12
epoch [36/50] batch [100/173] time 0.149 (0.124) data 0.000 (0.003) loss 0.7582 (0.6867) ce_loss 0.4885 (0.3480) teacher_loss 0.3408 (0.2151) loss_zs_kd 0.1123 (0.1032) loss_oracle 0.3613 (0.4200) acc 84.3750 (86.9062) kd_loss 0.8550 (0.8319) lr 4.6417e-04 eta 0:05:09
epoch [36/50] batch [120/173] time 0.126 (0.124) data 0.000 (0.003) loss 0.6852 (0.6853) ce_loss 0.3123 (0.3500) teacher_loss 0.2495 (0.2190) loss_zs_kd 0.1267 (0.1019) loss_oracle 0.3723 (0.4153) acc 81.2500 (87.0833) kd_loss 0.7393 (0.8235) lr 4.6417e-04 eta 0:05:07
epoch [36/50] batch [140/173] time 0.135 (0.123) data 0.000 (0.002) loss 0.7417 (0.6829) ce_loss 0.3396 (0.3503) teacher_loss 0.2640 (0.2192) loss_zs_kd 0.1281 (0.1009) loss_oracle 0.4137 (0.4132) acc 84.3750 (87.0089) kd_loss 0.7862 (0.8230) lr 4.6417e-04 eta 0:05:03
epoch [36/50] batch [160/173] time 0.132 (0.122) data 0.000 (0.002) loss 0.6195 (0.6815) ce_loss 0.3884 (0.3521) teacher_loss 0.1611 (0.2196) loss_zs_kd 0.1022 (0.1012) loss_oracle 0.4073 (0.4113) acc 87.5000 (86.8945) kd_loss 0.8595 (0.8205) lr 4.6417e-04 eta 0:04:56
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,289
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,011
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.1%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [37/50] batch [20/173] time 0.103 (0.162) data 0.000 (0.013) loss 0.6715 (0.7380) ce_loss 0.2649 (0.3963) teacher_loss 0.1440 (0.2612) loss_zs_kd 0.1021 (0.1212) loss_oracle 0.4764 (0.4162) acc 93.7500 (85.7812) kd_loss 0.9153 (0.8515) lr 4.1221e-04 eta 0:06:27
epoch [37/50] batch [40/173] time 0.135 (0.138) data 0.000 (0.007) loss 0.6586 (0.7059) ce_loss 0.3091 (0.3684) teacher_loss 0.1589 (0.2431) loss_zs_kd 0.0856 (0.1112) loss_oracle 0.4570 (0.4072) acc 87.5000 (86.9531) kd_loss 0.8454 (0.8320) lr 4.1221e-04 eta 0:05:28
epoch [37/50] batch [60/173] time 0.087 (0.129) data 0.000 (0.005) loss 0.7167 (0.7240) ce_loss 0.1968 (0.3818) teacher_loss 0.1696 (0.2406) loss_zs_kd 0.1037 (0.1134) loss_oracle 0.4952 (0.4267) acc 93.7500 (86.6146) kd_loss 0.9279 (0.8505) lr 4.1221e-04 eta 0:05:05
epoch [37/50] batch [80/173] time 0.140 (0.126) data 0.000 (0.003) loss 0.7253 (0.7279) ce_loss 0.3071 (0.3762) teacher_loss 0.1377 (0.2245) loss_zs_kd 0.0918 (0.1148) loss_oracle 0.5416 (0.4460) acc 87.5000 (86.7188) kd_loss 0.9883 (0.8619) lr 4.1221e-04 eta 0:04:55
epoch [37/50] batch [100/173] time 0.087 (0.125) data 0.000 (0.003) loss 0.9171 (0.7447) ce_loss 0.4285 (0.3794) teacher_loss 0.1943 (0.2234) loss_zs_kd 0.1647 (0.1164) loss_oracle 0.6404 (0.4631) acc 78.1250 (86.4062) kd_loss 1.1178 (0.8769) lr 4.1221e-04 eta 0:04:50
epoch [37/50] batch [120/173] time 0.111 (0.125) data 0.000 (0.002) loss 0.7082 (0.7554) ce_loss 0.2288 (0.3786) teacher_loss 0.1418 (0.2217) loss_zs_kd 0.0953 (0.1177) loss_oracle 0.5187 (0.4748) acc 87.5000 (86.4583) kd_loss 0.9165 (0.8852) lr 4.1221e-04 eta 0:04:47
epoch [37/50] batch [140/173] time 0.140 (0.123) data 0.000 (0.002) loss 0.7775 (0.7640) ce_loss 0.2247 (0.3823) teacher_loss 0.1833 (0.2210) loss_zs_kd 0.1373 (0.1189) loss_oracle 0.5256 (0.4835) acc 96.8750 (86.4955) kd_loss 0.8975 (0.8931) lr 4.1221e-04 eta 0:04:41
epoch [37/50] batch [160/173] time 0.081 (0.121) data 0.000 (0.002) loss 0.8186 (0.7665) ce_loss 0.4124 (0.3785) teacher_loss 0.1657 (0.2170) loss_zs_kd 0.1297 (0.1187) loss_oracle 0.5880 (0.4902) acc 81.2500 (86.4258) kd_loss 0.9460 (0.8980) lr 4.1221e-04 eta 0:04:34
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [38/50] batch [20/173] time 0.070 (0.117) data 0.000 (0.016) loss 1.0691 (0.8279) ce_loss 0.4741 (0.3497) teacher_loss 0.3279 (0.1980) loss_zs_kd 0.1207 (0.1211) loss_oracle 0.6809 (0.5694) acc 84.3750 (86.7188) kd_loss 0.9952 (0.9608) lr 3.6258e-04 eta 0:04:21
epoch [38/50] batch [40/173] time 0.135 (0.107) data 0.000 (0.008) loss 0.8809 (0.8433) ce_loss 0.5923 (0.3944) teacher_loss 0.2186 (0.2188) loss_zs_kd 0.1382 (0.1251) loss_oracle 0.5932 (0.5619) acc 71.8750 (84.7656) kd_loss 1.0398 (0.9703) lr 3.6258e-04 eta 0:03:55
epoch [38/50] batch [60/173] time 0.129 (0.105) data 0.000 (0.005) loss 0.8947 (0.8230) ce_loss 0.5005 (0.3704) teacher_loss 0.2543 (0.2034) loss_zs_kd 0.1231 (0.1241) loss_oracle 0.5788 (0.5577) acc 75.0000 (85.5729) kd_loss 1.0751 (0.9668) lr 3.6258e-04 eta 0:03:48
epoch [38/50] batch [80/173] time 0.134 (0.105) data 0.000 (0.004) loss 0.9095 (0.8354) ce_loss 0.4692 (0.3830) teacher_loss 0.2754 (0.2065) loss_zs_kd 0.1288 (0.1271) loss_oracle 0.5696 (0.5653) acc 84.3750 (85.5078) kd_loss 0.9134 (0.9728) lr 3.6258e-04 eta 0:03:47
epoch [38/50] batch [100/173] time 0.100 (0.104) data 0.000 (0.003) loss 1.1305 (0.8412) ce_loss 0.5537 (0.3834) teacher_loss 0.3221 (0.2039) loss_zs_kd 0.1205 (0.1275) loss_oracle 0.7482 (0.5735) acc 84.3750 (85.7188) kd_loss 1.0962 (0.9703) lr 3.6258e-04 eta 0:03:42
epoch [38/50] batch [120/173] time 0.089 (0.104) data 0.000 (0.003) loss 0.6633 (0.8478) ce_loss 0.1409 (0.3778) teacher_loss 0.0740 (0.2023) loss_zs_kd 0.1021 (0.1287) loss_oracle 0.5383 (0.5811) acc 93.7500 (86.0156) kd_loss 0.9091 (0.9744) lr 3.6258e-04 eta 0:03:40
epoch [38/50] batch [140/173] time 0.119 (0.103) data 0.000 (0.002) loss 0.8042 (0.8537) ce_loss 0.2161 (0.3741) teacher_loss 0.1276 (0.2030) loss_zs_kd 0.0653 (0.1269) loss_oracle 0.6440 (0.5872) acc 93.7500 (86.1607) kd_loss 1.0435 (0.9790) lr 3.6258e-04 eta 0:03:37
epoch [38/50] batch [160/173] time 0.071 (0.103) data 0.000 (0.002) loss 1.0000 (0.8550) ce_loss 0.4841 (0.3773) teacher_loss 0.2415 (0.2037) loss_zs_kd 0.0976 (0.1261) loss_oracle 0.7097 (0.5882) acc 87.5000 (86.1523) kd_loss 1.1348 (0.9824) lr 3.6258e-04 eta 0:03:35
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [39/50] batch [20/173] time 0.133 (0.127) data 0.000 (0.012) loss 0.9154 (0.8575) ce_loss 0.4092 (0.3445) teacher_loss 0.2288 (0.1773) loss_zs_kd 0.1289 (0.1220) loss_oracle 0.6221 (0.6192) acc 84.3750 (87.3438) kd_loss 0.9860 (1.0129) lr 3.1545e-04 eta 0:04:20
epoch [39/50] batch [40/173] time 0.083 (0.112) data 0.000 (0.006) loss 0.9687 (0.8744) ce_loss 0.4092 (0.3435) teacher_loss 0.2944 (0.1819) loss_zs_kd 0.1625 (0.1260) loss_oracle 0.5931 (0.6294) acc 84.3750 (87.5781) kd_loss 1.1029 (1.0273) lr 3.1545e-04 eta 0:03:48
epoch [39/50] batch [60/173] time 0.143 (0.131) data 0.000 (0.004) loss 0.7326 (0.8719) ce_loss 0.2473 (0.3475) teacher_loss 0.1463 (0.1778) loss_zs_kd 0.0690 (0.1296) loss_oracle 0.5518 (0.6293) acc 90.6250 (87.4479) kd_loss 0.9810 (1.0375) lr 3.1545e-04 eta 0:04:23
epoch [39/50] batch [80/173] time 0.183 (0.129) data 0.000 (0.003) loss 0.8801 (0.8732) ce_loss 0.4163 (0.3580) teacher_loss 0.2511 (0.1826) loss_zs_kd 0.0994 (0.1284) loss_oracle 0.5793 (0.6263) acc 84.3750 (86.9141) kd_loss 1.0095 (1.0347) lr 3.1545e-04 eta 0:04:16
epoch [39/50] batch [100/173] time 0.112 (0.128) data 0.000 (0.003) loss 0.9676 (0.8663) ce_loss 0.5010 (0.3568) teacher_loss 0.3160 (0.1837) loss_zs_kd 0.1345 (0.1260) loss_oracle 0.5844 (0.6196) acc 87.5000 (87.0938) kd_loss 0.9910 (1.0261) lr 3.1545e-04 eta 0:04:12
epoch [39/50] batch [120/173] time 0.114 (0.126) data 0.000 (0.002) loss 0.8242 (0.8627) ce_loss 0.4805 (0.3574) teacher_loss 0.1800 (0.1821) loss_zs_kd 0.1075 (0.1257) loss_oracle 0.5904 (0.6178) acc 75.0000 (86.9010) kd_loss 1.0077 (1.0229) lr 3.1545e-04 eta 0:04:05
epoch [39/50] batch [140/173] time 0.086 (0.123) data 0.000 (0.002) loss 0.8235 (0.8667) ce_loss 0.2866 (0.3662) teacher_loss 0.2019 (0.1880) loss_zs_kd 0.1200 (0.1264) loss_oracle 0.5616 (0.6155) acc 90.6250 (86.4955) kd_loss 0.9761 (1.0165) lr 3.1545e-04 eta 0:03:58
epoch [39/50] batch [160/173] time 0.079 (0.122) data 0.000 (0.002) loss 0.9761 (0.8617) ce_loss 0.4875 (0.3649) teacher_loss 0.2953 (0.1871) loss_zs_kd 0.1462 (0.1257) loss_oracle 0.6076 (0.6118) acc 81.2500 (86.4844) kd_loss 0.9820 (1.0109) lr 3.1545e-04 eta 0:03:53
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,287
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.9%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [40/50] batch [20/173] time 0.108 (0.123) data 0.000 (0.015) loss 0.8315 (0.8257) ce_loss 0.3013 (0.3285) teacher_loss 0.1240 (0.1773) loss_zs_kd 0.1111 (0.1145) loss_oracle 0.6519 (0.5912) acc 90.6250 (87.5000) kd_loss 1.0257 (0.9775) lr 2.7103e-04 eta 0:03:52
epoch [40/50] batch [40/173] time 0.091 (0.117) data 0.000 (0.007) loss 0.9123 (0.8098) ce_loss 0.5049 (0.3471) teacher_loss 0.2187 (0.1800) loss_zs_kd 0.1682 (0.1151) loss_oracle 0.6095 (0.5722) acc 81.2500 (87.2656) kd_loss 0.9894 (0.9642) lr 2.7103e-04 eta 0:03:37
epoch [40/50] batch [60/173] time 0.131 (0.114) data 0.000 (0.005) loss 0.8194 (0.8246) ce_loss 0.3850 (0.3479) teacher_loss 0.1331 (0.1866) loss_zs_kd 0.1338 (0.1194) loss_oracle 0.6194 (0.5783) acc 84.3750 (87.0833) kd_loss 0.9955 (0.9692) lr 2.7103e-04 eta 0:03:29
epoch [40/50] batch [80/173] time 0.119 (0.111) data 0.000 (0.004) loss 0.7416 (0.8280) ce_loss 0.4548 (0.3547) teacher_loss 0.1909 (0.1846) loss_zs_kd 0.1313 (0.1199) loss_oracle 0.4851 (0.5834) acc 78.1250 (86.7188) kd_loss 0.8976 (0.9737) lr 2.7103e-04 eta 0:03:23
epoch [40/50] batch [100/173] time 0.111 (0.110) data 0.000 (0.003) loss 0.9145 (0.8212) ce_loss 0.4377 (0.3520) teacher_loss 0.2781 (0.1839) loss_zs_kd 0.1293 (0.1223) loss_oracle 0.5718 (0.5763) acc 84.3750 (86.6562) kd_loss 1.0346 (0.9673) lr 2.7103e-04 eta 0:03:18
epoch [40/50] batch [120/173] time 0.108 (0.109) data 0.000 (0.003) loss 0.6916 (0.8227) ce_loss 0.2432 (0.3597) teacher_loss 0.1013 (0.1849) loss_zs_kd 0.1001 (0.1238) loss_oracle 0.5402 (0.5759) acc 93.7500 (86.6406) kd_loss 0.9718 (0.9666) lr 2.7103e-04 eta 0:03:14
epoch [40/50] batch [140/173] time 0.094 (0.108) data 0.000 (0.002) loss 1.0264 (0.8244) ce_loss 0.6157 (0.3590) teacher_loss 0.3161 (0.1841) loss_zs_kd 0.1686 (0.1250) loss_oracle 0.6261 (0.5778) acc 75.0000 (86.7188) kd_loss 1.0116 (0.9666) lr 2.7103e-04 eta 0:03:10
epoch [40/50] batch [160/173] time 0.100 (0.108) data 0.000 (0.002) loss 0.9277 (0.8226) ce_loss 0.5776 (0.3633) teacher_loss 0.2945 (0.1848) loss_zs_kd 0.2165 (0.1260) loss_oracle 0.5249 (0.5748) acc 84.3750 (86.6211) kd_loss 0.8881 (0.9615) lr 2.7103e-04 eta 0:03:08
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [41/50] batch [20/173] time 0.127 (0.122) data 0.000 (0.013) loss 0.9589 (0.8716) ce_loss 0.3906 (0.3595) teacher_loss 0.2020 (0.1928) loss_zs_kd 0.1164 (0.1212) loss_oracle 0.6987 (0.6182) acc 84.3750 (86.2500) kd_loss 1.1413 (1.0091) lr 2.2949e-04 eta 0:03:28
epoch [41/50] batch [40/173] time 0.106 (0.111) data 0.000 (0.007) loss 1.0716 (0.8366) ce_loss 0.6191 (0.3735) teacher_loss 0.3268 (0.1911) loss_zs_kd 0.2079 (0.1324) loss_oracle 0.6409 (0.5793) acc 81.2500 (86.0938) kd_loss 1.0850 (0.9768) lr 2.2949e-04 eta 0:03:07
epoch [41/50] batch [60/173] time 0.116 (0.109) data 0.000 (0.005) loss 0.8948 (0.8294) ce_loss 0.4321 (0.3698) teacher_loss 0.1788 (0.1901) loss_zs_kd 0.1674 (0.1300) loss_oracle 0.6322 (0.5743) acc 84.3750 (86.4583) kd_loss 1.0127 (0.9672) lr 2.2949e-04 eta 0:03:02
epoch [41/50] batch [80/173] time 0.077 (0.108) data 0.000 (0.003) loss 0.7165 (0.8254) ce_loss 0.2620 (0.3673) teacher_loss 0.1616 (0.1877) loss_zs_kd 0.1244 (0.1295) loss_oracle 0.4927 (0.5729) acc 90.6250 (86.6406) kd_loss 0.9005 (0.9672) lr 2.2949e-04 eta 0:02:57
epoch [41/50] batch [100/173] time 0.135 (0.109) data 0.000 (0.003) loss 1.1348 (0.8295) ce_loss 0.6338 (0.3657) teacher_loss 0.3920 (0.1881) loss_zs_kd 0.1698 (0.1308) loss_oracle 0.6580 (0.5760) acc 71.8750 (86.7188) kd_loss 0.9796 (0.9702) lr 2.2949e-04 eta 0:02:57
epoch [41/50] batch [120/173] time 0.188 (0.111) data 0.000 (0.002) loss 1.1497 (0.8229) ce_loss 0.5908 (0.3629) teacher_loss 0.2639 (0.1850) loss_zs_kd 0.1529 (0.1291) loss_oracle 0.8094 (0.5733) acc 78.1250 (86.6927) kd_loss 1.2333 (0.9662) lr 2.2949e-04 eta 0:02:58
epoch [41/50] batch [140/173] time 0.066 (0.116) data 0.000 (0.002) loss 0.8371 (0.8167) ce_loss 0.3574 (0.3612) teacher_loss 0.2148 (0.1834) loss_zs_kd 0.1419 (0.1274) loss_oracle 0.5513 (0.5696) acc 87.5000 (86.6964) kd_loss 1.0053 (0.9632) lr 2.2949e-04 eta 0:03:04
epoch [41/50] batch [160/173] time 0.071 (0.119) data 0.000 (0.002) loss 0.9464 (0.8155) ce_loss 0.5454 (0.3612) teacher_loss 0.2494 (0.1835) loss_zs_kd 0.1002 (0.1271) loss_oracle 0.6468 (0.5685) acc 78.1250 (86.8750) kd_loss 0.9507 (0.9619) lr 2.2949e-04 eta 0:03:07
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,283
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [42/50] batch [20/173] time 0.114 (0.131) data 0.000 (0.012) loss 0.6027 (0.7658) ce_loss 0.1549 (0.2948) teacher_loss 0.0844 (0.1525) loss_zs_kd 0.0688 (0.1074) loss_oracle 0.4839 (0.5595) acc 93.7500 (90.1562) kd_loss 0.8454 (0.9473) lr 1.9098e-04 eta 0:03:20
epoch [42/50] batch [40/173] time 0.136 (0.125) data 0.000 (0.006) loss 0.8157 (0.7641) ce_loss 0.3257 (0.3015) teacher_loss 0.1965 (0.1518) loss_zs_kd 0.0949 (0.1110) loss_oracle 0.5717 (0.5568) acc 90.6250 (89.0625) kd_loss 0.8972 (0.9461) lr 1.9098e-04 eta 0:03:10
epoch [42/50] batch [60/173] time 0.132 (0.125) data 0.001 (0.004) loss 0.9171 (0.7775) ce_loss 0.4258 (0.3169) teacher_loss 0.2550 (0.1646) loss_zs_kd 0.0928 (0.1098) loss_oracle 0.6157 (0.5581) acc 87.5000 (88.3854) kd_loss 0.9175 (0.9476) lr 1.9098e-04 eta 0:03:06
epoch [42/50] batch [80/173] time 0.141 (0.123) data 0.000 (0.003) loss 0.7140 (0.7691) ce_loss 0.3154 (0.3131) teacher_loss 0.1768 (0.1612) loss_zs_kd 0.0953 (0.1097) loss_oracle 0.4896 (0.5530) acc 93.7500 (88.3984) kd_loss 0.8802 (0.9441) lr 1.9098e-04 eta 0:03:02
epoch [42/50] batch [100/173] time 0.147 (0.124) data 0.000 (0.003) loss 0.8735 (0.7773) ce_loss 0.4729 (0.3274) teacher_loss 0.1585 (0.1699) loss_zs_kd 0.1347 (0.1124) loss_oracle 0.6476 (0.5512) acc 81.2500 (87.5000) kd_loss 1.0928 (0.9463) lr 1.9098e-04 eta 0:03:01
epoch [42/50] batch [120/173] time 0.144 (0.126) data 0.000 (0.002) loss 1.0447 (0.7801) ce_loss 0.5161 (0.3362) teacher_loss 0.2510 (0.1734) loss_zs_kd 0.1492 (0.1163) loss_oracle 0.7191 (0.5486) acc 75.0000 (87.1615) kd_loss 1.1352 (0.9456) lr 1.9098e-04 eta 0:03:00
epoch [42/50] batch [140/173] time 0.141 (0.126) data 0.000 (0.002) loss 0.6591 (0.7799) ce_loss 0.1888 (0.3413) teacher_loss 0.1352 (0.1754) loss_zs_kd 0.1037 (0.1179) loss_oracle 0.4721 (0.5455) acc 90.6250 (86.9643) kd_loss 0.8876 (0.9443) lr 1.9098e-04 eta 0:02:58
epoch [42/50] batch [160/173] time 0.106 (0.127) data 0.000 (0.002) loss 0.8012 (0.7829) ce_loss 0.4429 (0.3480) teacher_loss 0.3029 (0.1756) loss_zs_kd 0.1589 (0.1203) loss_oracle 0.4189 (0.5472) acc 78.1250 (86.8750) kd_loss 0.8971 (0.9466) lr 1.9098e-04 eta 0:02:56
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [43/50] batch [20/173] time 0.121 (0.135) data 0.000 (0.015) loss 0.6109 (0.8009) ce_loss 0.2174 (0.3809) teacher_loss 0.1208 (0.1976) loss_zs_kd 0.0857 (0.1339) loss_oracle 0.4472 (0.5363) acc 90.6250 (85.0000) kd_loss 0.8542 (0.9287) lr 1.5567e-04 eta 0:03:04
epoch [43/50] batch [40/173] time 0.105 (0.127) data 0.000 (0.008) loss 0.8182 (0.7844) ce_loss 0.2656 (0.3695) teacher_loss 0.1600 (0.1804) loss_zs_kd 0.1670 (0.1332) loss_oracle 0.5747 (0.5374) acc 90.6250 (86.3281) kd_loss 0.9896 (0.9296) lr 1.5567e-04 eta 0:02:50
epoch [43/50] batch [60/173] time 0.141 (0.127) data 0.000 (0.005) loss 1.2474 (0.7715) ce_loss 0.9077 (0.3536) teacher_loss 0.5736 (0.1741) loss_zs_kd 0.2110 (0.1304) loss_oracle 0.5683 (0.5322) acc 68.7500 (86.8750) kd_loss 0.9419 (0.9200) lr 1.5567e-04 eta 0:02:48
epoch [43/50] batch [80/173] time 0.073 (0.124) data 0.000 (0.004) loss 0.8319 (0.7716) ce_loss 0.3210 (0.3547) teacher_loss 0.2147 (0.1747) loss_zs_kd 0.1484 (0.1322) loss_oracle 0.5430 (0.5308) acc 87.5000 (86.6016) kd_loss 0.9255 (0.9190) lr 1.5567e-04 eta 0:02:41
epoch [43/50] batch [100/173] time 0.128 (0.121) data 0.000 (0.003) loss 0.8127 (0.7725) ce_loss 0.4482 (0.3545) teacher_loss 0.1957 (0.1780) loss_zs_kd 0.1942 (0.1341) loss_oracle 0.5199 (0.5274) acc 87.5000 (86.6875) kd_loss 0.8437 (0.9159) lr 1.5567e-04 eta 0:02:35
epoch [43/50] batch [120/173] time 0.140 (0.119) data 0.000 (0.003) loss 0.6032 (0.7787) ce_loss 0.2186 (0.3608) teacher_loss 0.1027 (0.1828) loss_zs_kd 0.0983 (0.1333) loss_oracle 0.4514 (0.5293) acc 87.5000 (86.5365) kd_loss 0.8775 (0.9171) lr 1.5567e-04 eta 0:02:31
epoch [43/50] batch [140/173] time 0.171 (0.123) data 0.000 (0.002) loss 0.9257 (0.7710) ce_loss 0.5215 (0.3561) teacher_loss 0.2572 (0.1812) loss_zs_kd 0.1897 (0.1316) loss_oracle 0.5736 (0.5241) acc 84.3750 (86.9196) kd_loss 0.9272 (0.9137) lr 1.5567e-04 eta 0:02:32
epoch [43/50] batch [160/173] time 0.181 (0.124) data 0.000 (0.002) loss 0.6065 (0.7679) ce_loss 0.1912 (0.3563) teacher_loss 0.0934 (0.1805) loss_zs_kd 0.0960 (0.1312) loss_oracle 0.4651 (0.5218) acc 93.7500 (86.8359) kd_loss 0.9236 (0.9134) lr 1.5567e-04 eta 0:02:31
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,288
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [44/50] batch [20/173] time 0.101 (0.121) data 0.000 (0.015) loss 0.7953 (0.7685) ce_loss 0.5327 (0.3756) teacher_loss 0.2211 (0.1838) loss_zs_kd 0.1232 (0.1269) loss_oracle 0.5125 (0.5212) acc 81.2500 (86.5625) kd_loss 0.8911 (0.9149) lr 1.2369e-04 eta 0:02:24
epoch [44/50] batch [40/173] time 0.133 (0.113) data 0.000 (0.008) loss 0.7750 (0.7686) ce_loss 0.3945 (0.3811) teacher_loss 0.2316 (0.1878) loss_zs_kd 0.1085 (0.1321) loss_oracle 0.4892 (0.5147) acc 84.3750 (85.5469) kd_loss 0.9131 (0.9100) lr 1.2369e-04 eta 0:02:12
epoch [44/50] batch [60/173] time 0.093 (0.111) data 0.000 (0.005) loss 0.8243 (0.7588) ce_loss 0.4016 (0.3704) teacher_loss 0.1550 (0.1837) loss_zs_kd 0.1113 (0.1267) loss_oracle 0.6136 (0.5118) acc 87.5000 (85.9896) kd_loss 1.0176 (0.9098) lr 1.2369e-04 eta 0:02:07
epoch [44/50] batch [80/173] time 0.077 (0.111) data 0.000 (0.004) loss 0.9239 (0.7599) ce_loss 0.4775 (0.3689) teacher_loss 0.2405 (0.1857) loss_zs_kd 0.1528 (0.1264) loss_oracle 0.6069 (0.5110) acc 81.2500 (86.0547) kd_loss 1.0397 (0.9132) lr 1.2369e-04 eta 0:02:05
epoch [44/50] batch [100/173] time 0.101 (0.111) data 0.000 (0.003) loss 0.6495 (0.7642) ce_loss 0.3667 (0.3731) teacher_loss 0.1207 (0.1892) loss_zs_kd 0.1141 (0.1279) loss_oracle 0.4717 (0.5111) acc 87.5000 (85.7188) kd_loss 0.8801 (0.9109) lr 1.2369e-04 eta 0:02:03
epoch [44/50] batch [120/173] time 0.114 (0.111) data 0.000 (0.003) loss 0.6670 (0.7612) ce_loss 0.3689 (0.3700) teacher_loss 0.2178 (0.1882) loss_zs_kd 0.1129 (0.1272) loss_oracle 0.3927 (0.5095) acc 87.5000 (85.7812) kd_loss 0.7907 (0.9080) lr 1.2369e-04 eta 0:02:00
epoch [44/50] batch [140/173] time 0.070 (0.110) data 0.000 (0.002) loss 0.7433 (0.7663) ce_loss 0.2615 (0.3743) teacher_loss 0.1108 (0.1908) loss_zs_kd 0.1213 (0.1281) loss_oracle 0.5719 (0.5115) acc 87.5000 (85.7366) kd_loss 0.9976 (0.9101) lr 1.2369e-04 eta 0:01:57
epoch [44/50] batch [160/173] time 0.075 (0.108) data 0.000 (0.002) loss 0.9747 (0.7652) ce_loss 0.4797 (0.3698) teacher_loss 0.2676 (0.1883) loss_zs_kd 0.1646 (0.1277) loss_oracle 0.6249 (0.5130) acc 84.3750 (85.9766) kd_loss 0.9899 (0.9110) lr 1.2369e-04 eta 0:01:53
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [45/50] batch [20/173] time 0.098 (0.117) data 0.000 (0.013) loss 0.7294 (0.7387) ce_loss 0.3389 (0.3492) teacher_loss 0.1509 (0.1765) loss_zs_kd 0.1373 (0.1303) loss_oracle 0.5099 (0.4971) acc 93.7500 (87.0312) kd_loss 0.9651 (0.9044) lr 9.5173e-05 eta 0:01:58
epoch [45/50] batch [40/173] time 0.113 (0.113) data 0.000 (0.006) loss 0.7418 (0.7567) ce_loss 0.4648 (0.3660) teacher_loss 0.2478 (0.1919) loss_zs_kd 0.1729 (0.1328) loss_oracle 0.4075 (0.4983) acc 84.3750 (86.8750) kd_loss 0.8035 (0.9086) lr 9.5173e-05 eta 0:01:53
epoch [45/50] batch [60/173] time 0.099 (0.113) data 0.000 (0.004) loss 0.6755 (0.7656) ce_loss 0.2952 (0.3733) teacher_loss 0.1773 (0.1983) loss_zs_kd 0.1082 (0.1350) loss_oracle 0.4441 (0.4998) acc 90.6250 (86.2500) kd_loss 0.8771 (0.9125) lr 9.5173e-05 eta 0:01:50
epoch [45/50] batch [80/173] time 0.107 (0.113) data 0.000 (0.003) loss 0.6367 (0.7612) ce_loss 0.2993 (0.3626) teacher_loss 0.1724 (0.1932) loss_zs_kd 0.1376 (0.1318) loss_oracle 0.3954 (0.5021) acc 87.5000 (86.6406) kd_loss 0.9010 (0.9136) lr 9.5173e-05 eta 0:01:48
epoch [45/50] batch [100/173] time 0.085 (0.112) data 0.000 (0.003) loss 0.8632 (0.7499) ce_loss 0.5425 (0.3538) teacher_loss 0.2742 (0.1883) loss_zs_kd 0.1275 (0.1280) loss_oracle 0.5252 (0.4976) acc 78.1250 (86.9688) kd_loss 0.9154 (0.9080) lr 9.5173e-05 eta 0:01:45
epoch [45/50] batch [120/173] time 0.087 (0.112) data 0.000 (0.002) loss 0.8689 (0.7570) ce_loss 0.3181 (0.3635) teacher_loss 0.2380 (0.1937) loss_zs_kd 0.0770 (0.1287) loss_oracle 0.5924 (0.4990) acc 90.6250 (86.4844) kd_loss 0.9150 (0.9088) lr 9.5173e-05 eta 0:01:42
epoch [45/50] batch [140/173] time 0.100 (0.112) data 0.000 (0.002) loss 0.5602 (0.7532) ce_loss 0.1235 (0.3612) teacher_loss 0.0584 (0.1911) loss_zs_kd 0.0738 (0.1277) loss_oracle 0.4649 (0.4982) acc 93.7500 (86.5625) kd_loss 0.8202 (0.9076) lr 9.5173e-05 eta 0:01:40
epoch [45/50] batch [160/173] time 0.100 (0.112) data 0.000 (0.002) loss 0.7807 (0.7482) ce_loss 0.3650 (0.3559) teacher_loss 0.2803 (0.1885) loss_zs_kd 0.1464 (0.1264) loss_oracle 0.4273 (0.4965) acc 90.6250 (86.8164) kd_loss 0.8384 (0.9057) lr 9.5173e-05 eta 0:01:37
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [46/50] batch [20/173] time 0.186 (0.161) data 0.000 (0.014) loss 0.7162 (0.7642) ce_loss 0.2081 (0.3620) teacher_loss 0.1528 (0.1946) loss_zs_kd 0.0867 (0.1304) loss_oracle 0.5201 (0.5044) acc 90.6250 (86.4062) kd_loss 0.8585 (0.9018) lr 7.0224e-05 eta 0:02:16
epoch [46/50] batch [40/173] time 0.114 (0.146) data 0.000 (0.007) loss 0.8501 (0.7585) ce_loss 0.4033 (0.3488) teacher_loss 0.2508 (0.1858) loss_zs_kd 0.1425 (0.1303) loss_oracle 0.5280 (0.5075) acc 78.1250 (86.5625) kd_loss 0.9269 (0.9029) lr 7.0224e-05 eta 0:02:00
epoch [46/50] batch [60/173] time 0.134 (0.135) data 0.001 (0.005) loss 0.6782 (0.7504) ce_loss 0.2864 (0.3515) teacher_loss 0.1194 (0.1776) loss_zs_kd 0.1236 (0.1337) loss_oracle 0.4969 (0.5060) acc 87.5000 (86.2500) kd_loss 0.8910 (0.9068) lr 7.0224e-05 eta 0:01:48
epoch [46/50] batch [80/173] time 0.145 (0.130) data 0.000 (0.004) loss 0.6171 (0.7559) ce_loss 0.2333 (0.3556) teacher_loss 0.1924 (0.1805) loss_zs_kd 0.0684 (0.1314) loss_oracle 0.3905 (0.5097) acc 93.7500 (86.3281) kd_loss 0.8525 (0.9091) lr 7.0224e-05 eta 0:01:42
epoch [46/50] batch [100/173] time 0.120 (0.127) data 0.000 (0.003) loss 0.7728 (0.7498) ce_loss 0.4116 (0.3501) teacher_loss 0.1789 (0.1766) loss_zs_kd 0.1023 (0.1299) loss_oracle 0.5428 (0.5083) acc 90.6250 (86.6562) kd_loss 0.8894 (0.9095) lr 7.0224e-05 eta 0:01:37
epoch [46/50] batch [120/173] time 0.121 (0.126) data 0.000 (0.002) loss 0.7019 (0.7541) ce_loss 0.3069 (0.3574) teacher_loss 0.2033 (0.1801) loss_zs_kd 0.1233 (0.1313) loss_oracle 0.4370 (0.5083) acc 87.5000 (86.6667) kd_loss 0.7980 (0.9099) lr 7.0224e-05 eta 0:01:33
epoch [46/50] batch [140/173] time 0.125 (0.124) data 0.000 (0.002) loss 0.5703 (0.7496) ce_loss 0.1312 (0.3507) teacher_loss 0.0587 (0.1778) loss_zs_kd 0.1000 (0.1287) loss_oracle 0.4617 (0.5075) acc 96.8750 (86.8750) kd_loss 0.8422 (0.9085) lr 7.0224e-05 eta 0:01:29
epoch [46/50] batch [160/173] time 0.118 (0.123) data 0.000 (0.002) loss 0.9488 (0.7515) ce_loss 0.6313 (0.3536) teacher_loss 0.3182 (0.1792) loss_zs_kd 0.1981 (0.1294) loss_oracle 0.5315 (0.5076) acc 75.0000 (86.7578) kd_loss 0.9548 (0.9104) lr 7.0224e-05 eta 0:01:26
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [47/50] batch [20/173] time 0.146 (0.154) data 0.000 (0.014) loss 0.6918 (0.7317) ce_loss 0.2615 (0.3416) teacher_loss 0.1032 (0.1659) loss_zs_kd 0.1175 (0.1193) loss_oracle 0.5298 (0.5062) acc 93.7500 (86.8750) kd_loss 0.9765 (0.9167) lr 4.8943e-05 eta 0:01:43
epoch [47/50] batch [40/173] time 0.144 (0.142) data 0.000 (0.007) loss 1.0137 (0.7629) ce_loss 0.5415 (0.3654) teacher_loss 0.3277 (0.1801) loss_zs_kd 0.1787 (0.1256) loss_oracle 0.5966 (0.5200) acc 84.3750 (86.4844) kd_loss 0.9516 (0.9346) lr 4.8943e-05 eta 0:01:32
epoch [47/50] batch [60/173] time 0.141 (0.131) data 0.001 (0.005) loss 0.7391 (0.7566) ce_loss 0.4045 (0.3488) teacher_loss 0.1731 (0.1781) loss_zs_kd 0.1272 (0.1243) loss_oracle 0.5024 (0.5163) acc 84.3750 (87.2396) kd_loss 0.8920 (0.9289) lr 4.8943e-05 eta 0:01:23
epoch [47/50] batch [80/173] time 0.089 (0.125) data 0.000 (0.004) loss 0.8202 (0.7552) ce_loss 0.2620 (0.3482) teacher_loss 0.1645 (0.1741) loss_zs_kd 0.1155 (0.1227) loss_oracle 0.5979 (0.5198) acc 93.7500 (87.5391) kd_loss 1.0192 (0.9329) lr 4.8943e-05 eta 0:01:16
epoch [47/50] batch [100/173] time 0.117 (0.122) data 0.000 (0.003) loss 0.7587 (0.7585) ce_loss 0.4028 (0.3540) teacher_loss 0.2467 (0.1767) loss_zs_kd 0.1180 (0.1251) loss_oracle 0.4530 (0.5193) acc 81.2500 (87.3750) kd_loss 0.8871 (0.9355) lr 4.8943e-05 eta 0:01:12
epoch [47/50] batch [120/173] time 0.085 (0.119) data 0.000 (0.002) loss 0.8296 (0.7593) ce_loss 0.5889 (0.3577) teacher_loss 0.3225 (0.1764) loss_zs_kd 0.1113 (0.1258) loss_oracle 0.4514 (0.5199) acc 78.1250 (87.1094) kd_loss 0.9647 (0.9368) lr 4.8943e-05 eta 0:01:07
epoch [47/50] batch [140/173] time 0.084 (0.117) data 0.000 (0.002) loss 0.7236 (0.7517) ce_loss 0.3894 (0.3555) teacher_loss 0.1213 (0.1736) loss_zs_kd 0.1721 (0.1265) loss_oracle 0.5163 (0.5148) acc 84.3750 (87.0982) kd_loss 0.9073 (0.9318) lr 4.8943e-05 eta 0:01:04
epoch [47/50] batch [160/173] time 0.084 (0.118) data 0.000 (0.002) loss 0.7990 (0.7521) ce_loss 0.2466 (0.3524) teacher_loss 0.1677 (0.1760) loss_zs_kd 0.1217 (0.1259) loss_oracle 0.5704 (0.5131) acc 93.7500 (87.2070) kd_loss 1.0020 (0.9316) lr 4.8943e-05 eta 0:01:02
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [48/50] batch [20/173] time 0.074 (0.111) data 0.000 (0.015) loss 0.7604 (0.8325) ce_loss 0.3210 (0.4388) teacher_loss 0.2218 (0.2389) loss_zs_kd 0.1438 (0.1406) loss_oracle 0.4667 (0.5234) acc 87.5000 (83.7500) kd_loss 0.8771 (0.9486) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [40/173] time 0.185 (0.131) data 0.000 (0.007) loss 0.9818 (0.7990) ce_loss 0.5239 (0.4000) teacher_loss 0.2991 (0.2141) loss_zs_kd 0.1687 (0.1367) loss_oracle 0.5984 (0.5165) acc 81.2500 (84.9219) kd_loss 0.9769 (0.9474) lr 3.1417e-05 eta 0:01:02
epoch [48/50] batch [60/173] time 0.181 (0.134) data 0.001 (0.005) loss 0.8738 (0.7830) ce_loss 0.5845 (0.3805) teacher_loss 0.2773 (0.1977) loss_zs_kd 0.1951 (0.1364) loss_oracle 0.4990 (0.5171) acc 81.2500 (85.6771) kd_loss 0.8834 (0.9500) lr 3.1417e-05 eta 0:01:01
epoch [48/50] batch [80/173] time 0.118 (0.132) data 0.000 (0.004) loss 0.7353 (0.7715) ce_loss 0.4163 (0.3801) teacher_loss 0.1668 (0.1938) loss_zs_kd 0.1468 (0.1358) loss_oracle 0.4951 (0.5098) acc 81.2500 (85.3516) kd_loss 0.9741 (0.9422) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [100/173] time 0.085 (0.126) data 0.000 (0.003) loss 0.8804 (0.7678) ce_loss 0.4526 (0.3722) teacher_loss 0.2016 (0.1893) loss_zs_kd 0.1325 (0.1324) loss_oracle 0.6125 (0.5123) acc 78.1250 (85.5938) kd_loss 0.9496 (0.9429) lr 3.1417e-05 eta 0:00:52
epoch [48/50] batch [120/173] time 0.086 (0.124) data 0.000 (0.003) loss 0.7960 (0.7639) ce_loss 0.3186 (0.3670) teacher_loss 0.1800 (0.1883) loss_zs_kd 0.1370 (0.1306) loss_oracle 0.5475 (0.5103) acc 90.6250 (86.0677) kd_loss 0.9442 (0.9392) lr 3.1417e-05 eta 0:00:49
epoch [48/50] batch [140/173] time 0.137 (0.123) data 0.000 (0.002) loss 0.9907 (0.7660) ce_loss 0.4636 (0.3690) teacher_loss 0.2947 (0.1904) loss_zs_kd 0.1556 (0.1313) loss_oracle 0.6181 (0.5099) acc 81.2500 (86.0491) kd_loss 0.9848 (0.9390) lr 3.1417e-05 eta 0:00:46
epoch [48/50] batch [160/173] time 0.075 (0.121) data 0.000 (0.002) loss 0.6788 (0.7619) ce_loss 0.3489 (0.3666) teacher_loss 0.1365 (0.1877) loss_zs_kd 0.1151 (0.1303) loss_oracle 0.4847 (0.5090) acc 87.5000 (86.1328) kd_loss 0.8167 (0.9357) lr 3.1417e-05 eta 0:00:43
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [49/50] batch [20/173] time 0.107 (0.125) data 0.000 (0.015) loss 0.8753 (0.7454) ce_loss 0.3301 (0.3361) teacher_loss 0.2468 (0.1799) loss_zs_kd 0.1761 (0.1169) loss_oracle 0.5405 (0.5071) acc 87.5000 (86.7188) kd_loss 0.9366 (0.9407) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [40/173] time 0.143 (0.127) data 0.000 (0.007) loss 0.7368 (0.7553) ce_loss 0.3770 (0.3535) teacher_loss 0.2041 (0.1936) loss_zs_kd 0.1365 (0.1229) loss_oracle 0.4645 (0.5002) acc 87.5000 (86.7969) kd_loss 0.8759 (0.9189) lr 1.7713e-05 eta 0:00:38
epoch [49/50] batch [60/173] time 0.145 (0.131) data 0.001 (0.005) loss 0.6204 (0.7731) ce_loss 0.1873 (0.3703) teacher_loss 0.0480 (0.2034) loss_zs_kd 0.1455 (0.1253) loss_oracle 0.4996 (0.5070) acc 93.7500 (86.2500) kd_loss 0.9836 (0.9346) lr 1.7713e-05 eta 0:00:37
epoch [49/50] batch [80/173] time 0.145 (0.130) data 0.000 (0.004) loss 0.7172 (0.7700) ce_loss 0.2627 (0.3682) teacher_loss 0.1454 (0.1980) loss_zs_kd 0.1085 (0.1253) loss_oracle 0.5176 (0.5093) acc 87.5000 (86.4062) kd_loss 0.9498 (0.9369) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [100/173] time 0.140 (0.128) data 0.000 (0.003) loss 0.7814 (0.7760) ce_loss 0.2343 (0.3778) teacher_loss 0.1437 (0.2013) loss_zs_kd 0.1152 (0.1282) loss_oracle 0.5800 (0.5107) acc 90.6250 (85.9688) kd_loss 0.9735 (0.9360) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [120/173] time 0.143 (0.126) data 0.000 (0.003) loss 0.8878 (0.7728) ce_loss 0.3350 (0.3693) teacher_loss 0.1581 (0.1946) loss_zs_kd 0.1836 (0.1278) loss_oracle 0.6379 (0.5142) acc 84.3750 (86.2500) kd_loss 1.0801 (0.9378) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [140/173] time 0.084 (0.124) data 0.000 (0.002) loss 0.8298 (0.7711) ce_loss 0.6084 (0.3682) teacher_loss 0.2995 (0.1939) loss_zs_kd 0.1835 (0.1277) loss_oracle 0.4386 (0.5134) acc 78.1250 (86.3393) kd_loss 0.8202 (0.9360) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [160/173] time 0.089 (0.123) data 0.000 (0.002) loss 0.6634 (0.7649) ce_loss 0.2498 (0.3648) teacher_loss 0.1508 (0.1917) loss_zs_kd 0.1054 (0.1264) loss_oracle 0.4599 (0.5100) acc 90.6250 (86.4648) kd_loss 0.9381 (0.9316) lr 1.7713e-05 eta 0:00:22
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [50/50] batch [20/173] time 0.086 (0.116) data 0.000 (0.012) loss 0.9433 (0.7525) ce_loss 0.4514 (0.3740) teacher_loss 0.2567 (0.1831) loss_zs_kd 0.1800 (0.1190) loss_oracle 0.5966 (0.5099) acc 84.3750 (87.0312) kd_loss 1.0027 (0.9351) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [40/173] time 0.119 (0.109) data 0.000 (0.006) loss 0.6814 (0.7398) ce_loss 0.4019 (0.3648) teacher_loss 0.1806 (0.1823) loss_zs_kd 0.1494 (0.1224) loss_oracle 0.4261 (0.4963) acc 90.6250 (87.0312) kd_loss 0.8687 (0.9252) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [60/173] time 0.072 (0.106) data 0.001 (0.004) loss 0.7044 (0.7380) ce_loss 0.2766 (0.3577) teacher_loss 0.1627 (0.1763) loss_zs_kd 0.0977 (0.1221) loss_oracle 0.4929 (0.5007) acc 81.2500 (87.0833) kd_loss 0.9156 (0.9295) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [80/173] time 0.186 (0.122) data 0.000 (0.003) loss 0.8703 (0.7395) ce_loss 0.5884 (0.3512) teacher_loss 0.2539 (0.1722) loss_zs_kd 0.1600 (0.1247) loss_oracle 0.5363 (0.5049) acc 78.1250 (87.3047) kd_loss 0.9879 (0.9324) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [100/173] time 0.182 (0.125) data 0.000 (0.002) loss 0.7631 (0.7419) ce_loss 0.4312 (0.3497) teacher_loss 0.1687 (0.1731) loss_zs_kd 0.1307 (0.1254) loss_oracle 0.5291 (0.5061) acc 90.6250 (87.3750) kd_loss 1.0077 (0.9329) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [120/173] time 0.117 (0.122) data 0.000 (0.002) loss 0.7392 (0.7423) ce_loss 0.3408 (0.3464) teacher_loss 0.1541 (0.1733) loss_zs_kd 0.1120 (0.1239) loss_oracle 0.5291 (0.5071) acc 87.5000 (87.3177) kd_loss 0.9871 (0.9308) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [140/173] time 0.116 (0.120) data 0.000 (0.002) loss 0.5693 (0.7409) ce_loss 0.2004 (0.3460) teacher_loss 0.0592 (0.1744) loss_zs_kd 0.0950 (0.1235) loss_oracle 0.4626 (0.5047) acc 90.6250 (87.3438) kd_loss 0.8539 (0.9305) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [160/173] time 0.084 (0.118) data 0.000 (0.002) loss 0.6653 (0.7443) ce_loss 0.2520 (0.3499) teacher_loss 0.1562 (0.1770) loss_zs_kd 0.1202 (0.1249) loss_oracle 0.4490 (0.5049) acc 87.5000 (87.2461) kd_loss 0.8793 (0.9312) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.3%, epoch: 34 *******
******* Domain a best val test acc: 98.0%, epoch: 34 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
Checkpoint saved to icml/multi-dg/oracle/02_oracle1.0/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:21:17

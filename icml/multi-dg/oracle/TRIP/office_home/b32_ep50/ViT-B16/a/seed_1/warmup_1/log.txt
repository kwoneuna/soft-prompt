Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------------
Dataset    SPG_OfficeHome
Source     ['clipart', 'product', 'real_world']
Target     ['art']
# classes  65
# train_x  9,222
# val      3,939
# test     2,427
---------  ------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/288] time 0.171 (0.213) data 0.000 (0.019) loss 2.2182 (2.4760) ce_loss 1.1074 (1.2364) teacher_loss 1.1082 (1.2364) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0026 (0.0032) acc 71.8750 (68.5938) kd_loss 0.0099 (0.0129) lr 1.0000e-05 eta 0:51:09
epoch [1/50] batch [40/288] time 0.154 (0.185) data 0.000 (0.010) loss 2.4192 (2.5158) ce_loss 1.2080 (1.2562) teacher_loss 1.2066 (1.2563) loss_zs_kd 0.0007 (0.0002) loss_oracle 0.0041 (0.0032) acc 65.6250 (68.3594) kd_loss 0.0169 (0.0130) lr 1.0000e-05 eta 0:44:23
epoch [1/50] batch [60/288] time 0.148 (0.174) data 0.000 (0.007) loss 2.8089 (2.5250) ce_loss 1.4033 (1.2609) teacher_loss 1.4021 (1.2608) loss_zs_kd 0.0030 (0.0004) loss_oracle 0.0020 (0.0031) acc 59.3750 (67.7083) kd_loss 0.0076 (0.0122) lr 1.0000e-05 eta 0:41:37
epoch [1/50] batch [80/288] time 0.165 (0.169) data 0.000 (0.005) loss 2.4921 (2.5285) ce_loss 1.2422 (1.2626) teacher_loss 1.2439 (1.2625) loss_zs_kd 0.0041 (0.0008) loss_oracle 0.0040 (0.0029) acc 62.5000 (67.5391) kd_loss 0.0158 (0.0115) lr 1.0000e-05 eta 0:40:15
epoch [1/50] batch [100/288] time 0.179 (0.163) data 0.000 (0.004) loss 2.1635 (2.4704) ce_loss 1.0801 (1.2336) teacher_loss 1.0795 (1.2335) loss_zs_kd 0.0027 (0.0013) loss_oracle 0.0025 (0.0027) acc 62.5000 (68.1250) kd_loss 0.0101 (0.0106) lr 1.0000e-05 eta 0:38:44
epoch [1/50] batch [120/288] time 0.343 (0.168) data 0.000 (0.003) loss 2.0285 (2.4560) ce_loss 1.0137 (1.2264) teacher_loss 1.0113 (1.2262) loss_zs_kd 0.0029 (0.0018) loss_oracle 0.0020 (0.0025) acc 75.0000 (68.3073) kd_loss 0.0065 (0.0098) lr 1.0000e-05 eta 0:39:57
epoch [1/50] batch [140/288] time 0.158 (0.169) data 0.000 (0.003) loss 2.9123 (2.4251) ce_loss 1.4551 (1.2110) teacher_loss 1.4530 (1.2107) loss_zs_kd 0.0049 (0.0022) loss_oracle 0.0018 (0.0023) acc 56.2500 (68.4821) kd_loss 0.0050 (0.0090) lr 1.0000e-05 eta 0:40:10
epoch [1/50] batch [160/288] time 0.152 (0.167) data 0.000 (0.003) loss 2.1314 (2.4183) ce_loss 1.0635 (1.2075) teacher_loss 1.0638 (1.2072) loss_zs_kd 0.0066 (0.0028) loss_oracle 0.0008 (0.0022) acc 68.7500 (68.7891) kd_loss 0.0024 (0.0084) lr 1.0000e-05 eta 0:39:36
epoch [1/50] batch [180/288] time 0.147 (0.166) data 0.000 (0.002) loss 1.9600 (2.4236) ce_loss 0.9771 (1.2101) teacher_loss 0.9771 (1.2098) loss_zs_kd 0.0098 (0.0033) loss_oracle 0.0009 (0.0021) acc 68.7500 (68.6111) kd_loss 0.0026 (0.0079) lr 1.0000e-05 eta 0:39:16
epoch [1/50] batch [200/288] time 0.167 (0.165) data 0.000 (0.002) loss 2.6812 (2.4170) ce_loss 1.3379 (1.2067) teacher_loss 1.3376 (1.2064) loss_zs_kd 0.0099 (0.0038) loss_oracle 0.0008 (0.0020) acc 65.6250 (68.5469) kd_loss 0.0027 (0.0075) lr 1.0000e-05 eta 0:38:59
epoch [1/50] batch [220/288] time 0.155 (0.164) data 0.000 (0.002) loss 2.7854 (2.4058) ce_loss 1.3906 (1.2009) teacher_loss 1.3889 (1.2007) loss_zs_kd 0.0099 (0.0045) loss_oracle 0.0010 (0.0019) acc 65.6250 (68.8636) kd_loss 0.0028 (0.0071) lr 1.0000e-05 eta 0:38:39
epoch [1/50] batch [240/288] time 0.151 (0.163) data 0.000 (0.002) loss 1.9329 (2.3995) ce_loss 0.9644 (1.1977) teacher_loss 0.9648 (1.1974) loss_zs_kd 0.0053 (0.0050) loss_oracle 0.0011 (0.0018) acc 81.2500 (69.0885) kd_loss 0.0038 (0.0067) lr 1.0000e-05 eta 0:38:25
epoch [1/50] batch [260/288] time 0.294 (0.165) data 0.000 (0.002) loss 2.4796 (2.4073) ce_loss 1.2344 (1.2015) teacher_loss 1.2339 (1.2012) loss_zs_kd 0.0211 (0.0057) loss_oracle 0.0009 (0.0018) acc 71.8750 (69.0024) kd_loss 0.0023 (0.0064) lr 1.0000e-05 eta 0:38:51
epoch [1/50] batch [280/288] time 0.082 (0.167) data 0.000 (0.002) loss 2.9895 (2.4060) ce_loss 1.4893 (1.2007) teacher_loss 1.4892 (1.2004) loss_zs_kd 0.0203 (0.0064) loss_oracle 0.0009 (0.0017) acc 65.6250 (69.0960) kd_loss 0.0027 (0.0061) lr 1.0000e-05 eta 0:39:18
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,299
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,987
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 78.1%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      83.8%, epoch: 1 *******
******* Domain a best val test acc: 81.9%, epoch: 1 *******
******* Domain a best test acc:     81.9%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/ana
epoch [2/50] batch [20/288] time 0.164 (0.187) data 0.000 (0.019) loss 2.1713 (2.4528) ce_loss 1.0361 (1.1840) teacher_loss 1.0418 (1.1873) loss_zs_kd 0.1256 (0.1317) loss_oracle 0.0306 (0.0157) acc 65.6250 (68.9062) kd_loss 0.0029 (0.0020) lr 2.0000e-03 eta 0:43:53
epoch [2/50] batch [40/288] time 0.179 (0.174) data 0.000 (0.010) loss 1.4507 (2.3379) ce_loss 0.6792 (1.1134) teacher_loss 0.6861 (1.1186) loss_zs_kd 0.1278 (0.1551) loss_oracle 0.0215 (0.0283) acc 84.3750 (70.8594) kd_loss 0.0032 (0.0025) lr 2.0000e-03 eta 0:40:44
epoch [2/50] batch [60/288] time 0.091 (0.174) data 0.000 (0.007) loss 2.8771 (2.3465) ce_loss 1.3652 (1.1154) teacher_loss 1.3837 (1.1212) loss_zs_kd 0.1694 (0.1524) loss_oracle 0.0435 (0.0337) acc 68.7500 (71.2500) kd_loss 0.0086 (0.0038) lr 2.0000e-03 eta 0:40:49
epoch [2/50] batch [80/288] time 0.157 (0.184) data 0.000 (0.005) loss 1.7855 (2.3199) ce_loss 0.8154 (1.0958) teacher_loss 0.8259 (1.1033) loss_zs_kd 0.1463 (0.1510) loss_oracle 0.0711 (0.0453) acc 71.8750 (71.7188) kd_loss 0.0154 (0.0064) lr 2.0000e-03 eta 0:42:56
epoch [2/50] batch [100/288] time 0.180 (0.182) data 0.000 (0.004) loss 2.9950 (2.3144) ce_loss 1.4229 (1.0906) teacher_loss 1.4383 (1.0987) loss_zs_kd 0.1427 (0.1541) loss_oracle 0.0624 (0.0480) acc 65.6250 (72.0312) kd_loss 0.0240 (0.0087) lr 2.0000e-03 eta 0:42:26
epoch [2/50] batch [120/288] time 0.176 (0.181) data 0.000 (0.003) loss 2.3100 (2.3030) ce_loss 1.0967 (1.0839) teacher_loss 1.1027 (1.0916) loss_zs_kd 0.1004 (0.1550) loss_oracle 0.0604 (0.0499) acc 71.8750 (71.9792) kd_loss 0.0187 (0.0109) lr 2.0000e-03 eta 0:42:16
epoch [2/50] batch [140/288] time 0.162 (0.179) data 0.000 (0.003) loss 2.4759 (2.3079) ce_loss 1.1455 (1.0858) teacher_loss 1.1565 (1.0937) loss_zs_kd 0.1984 (0.1530) loss_oracle 0.0748 (0.0519) acc 71.8750 (71.9420) kd_loss 0.0216 (0.0122) lr 2.0000e-03 eta 0:41:47
epoch [2/50] batch [160/288] time 0.171 (0.178) data 0.000 (0.003) loss 2.4821 (2.3147) ce_loss 1.1270 (1.0876) teacher_loss 1.1304 (1.0951) loss_zs_kd 0.2552 (0.1530) loss_oracle 0.0971 (0.0556) acc 71.8750 (71.7188) kd_loss 0.0282 (0.0137) lr 2.0000e-03 eta 0:41:16
epoch [2/50] batch [180/288] time 0.107 (0.179) data 0.000 (0.002) loss 2.1078 (2.3060) ce_loss 0.9492 (1.0809) teacher_loss 0.9676 (1.0881) loss_zs_kd 0.1715 (0.1539) loss_oracle 0.1052 (0.0600) acc 81.2500 (71.9444) kd_loss 0.0330 (0.0157) lr 2.0000e-03 eta 0:41:39
epoch [2/50] batch [200/288] time 0.144 (0.182) data 0.000 (0.002) loss 3.6264 (2.3141) ce_loss 1.6934 (1.0818) teacher_loss 1.6997 (1.0890) loss_zs_kd 0.2247 (0.1575) loss_oracle 0.1210 (0.0645) acc 62.5000 (71.8125) kd_loss 0.0509 (0.0178) lr 2.0000e-03 eta 0:42:12
epoch [2/50] batch [220/288] time 0.168 (0.180) data 0.000 (0.002) loss 2.4509 (2.2939) ce_loss 1.1035 (1.0698) teacher_loss 1.1309 (1.0773) loss_zs_kd 0.2090 (0.1583) loss_oracle 0.1120 (0.0676) acc 84.3750 (72.1023) kd_loss 0.0500 (0.0200) lr 2.0000e-03 eta 0:41:42
epoch [2/50] batch [240/288] time 0.146 (0.179) data 0.000 (0.002) loss 2.8376 (2.2862) ce_loss 1.3359 (1.0651) teacher_loss 1.3308 (1.0725) loss_zs_kd 0.1482 (0.1584) loss_oracle 0.0967 (0.0694) acc 62.5000 (72.1094) kd_loss 0.0433 (0.0226) lr 2.0000e-03 eta 0:41:16
epoch [2/50] batch [260/288] time 0.145 (0.177) data 0.000 (0.002) loss 2.2086 (2.2775) ce_loss 0.9814 (1.0596) teacher_loss 0.9962 (1.0670) loss_zs_kd 0.2876 (0.1598) loss_oracle 0.0871 (0.0710) acc 78.1250 (72.1514) kd_loss 0.0467 (0.0249) lr 2.0000e-03 eta 0:40:48
epoch [2/50] batch [280/288] time 0.162 (0.175) data 0.000 (0.002) loss 1.8484 (2.2722) ce_loss 0.8027 (1.0552) teacher_loss 0.8093 (1.0624) loss_zs_kd 0.2073 (0.1610) loss_oracle 0.1327 (0.0741) acc 75.0000 (72.1652) kd_loss 0.0751 (0.0272) lr 2.0000e-03 eta 0:40:24
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,399
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.6%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,012
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.4%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.3%, epoch: 2 *******
******* Domain a best val test acc: 82.9%, epoch: 2 *******
******* Domain a best test acc:     82.9%, epoch: 2 *******
epoch [3/50] batch [20/288] time 0.157 (0.194) data 0.000 (0.017) loss 3.1805 (2.3019) ce_loss 1.4580 (1.0418) teacher_loss 1.4792 (1.0465) loss_zs_kd 0.2102 (0.1775) loss_oracle 0.1382 (0.1249) acc 53.1250 (71.8750) kd_loss 0.0681 (0.0616) lr 1.9980e-03 eta 0:44:31
epoch [3/50] batch [40/288] time 0.159 (0.177) data 0.000 (0.009) loss 1.8388 (2.1609) ce_loss 0.8228 (0.9720) teacher_loss 0.8415 (0.9783) loss_zs_kd 0.1253 (0.1684) loss_oracle 0.1120 (0.1264) acc 75.0000 (73.5156) kd_loss 0.0657 (0.0624) lr 1.9980e-03 eta 0:40:43
epoch [3/50] batch [60/288] time 0.170 (0.172) data 0.000 (0.006) loss 2.0524 (2.2583) ce_loss 0.9536 (1.0224) teacher_loss 0.9556 (1.0278) loss_zs_kd 0.1207 (0.1676) loss_oracle 0.0828 (0.1243) acc 75.0000 (72.4479) kd_loss 0.0608 (0.0634) lr 1.9980e-03 eta 0:39:28
epoch [3/50] batch [80/288] time 0.150 (0.170) data 0.000 (0.004) loss 2.2337 (2.2547) ce_loss 1.0156 (1.0235) teacher_loss 1.0246 (1.0288) loss_zs_kd 0.1608 (0.1656) loss_oracle 0.1131 (0.1195) acc 71.8750 (72.3828) kd_loss 0.0614 (0.0638) lr 1.9980e-03 eta 0:38:54
epoch [3/50] batch [100/288] time 0.169 (0.168) data 0.000 (0.004) loss 2.0794 (2.2734) ce_loss 0.9316 (1.0329) teacher_loss 0.9381 (1.0387) loss_zs_kd 0.1450 (0.1663) loss_oracle 0.1372 (0.1186) acc 75.0000 (72.4688) kd_loss 0.0777 (0.0636) lr 1.9980e-03 eta 0:38:29
epoch [3/50] batch [120/288] time 0.098 (0.169) data 0.000 (0.003) loss 1.5142 (2.2480) ce_loss 0.6685 (1.0187) teacher_loss 0.6648 (1.0245) loss_zs_kd 0.1821 (0.1722) loss_oracle 0.0899 (0.1187) acc 84.3750 (72.9427) kd_loss 0.0611 (0.0639) lr 1.9980e-03 eta 0:38:41
epoch [3/50] batch [140/288] time 0.166 (0.177) data 0.000 (0.003) loss 2.1593 (2.2420) ce_loss 1.0039 (1.0161) teacher_loss 1.0148 (1.0219) loss_zs_kd 0.1121 (0.1715) loss_oracle 0.0845 (0.1181) acc 75.0000 (72.7232) kd_loss 0.0594 (0.0644) lr 1.9980e-03 eta 0:40:16
epoch [3/50] batch [160/288] time 0.150 (0.174) data 0.000 (0.002) loss 3.2116 (2.2504) ce_loss 1.5039 (1.0208) teacher_loss 1.4994 (1.0259) loss_zs_kd 0.2125 (0.1735) loss_oracle 0.1021 (0.1169) acc 59.3750 (72.5586) kd_loss 0.0522 (0.0644) lr 1.9980e-03 eta 0:39:37
epoch [3/50] batch [180/288] time 0.163 (0.172) data 0.000 (0.002) loss 2.4046 (2.2490) ce_loss 1.0928 (1.0200) teacher_loss 1.0950 (1.0248) loss_zs_kd 0.1876 (0.1734) loss_oracle 0.1230 (0.1174) acc 71.8750 (72.6910) kd_loss 0.0609 (0.0650) lr 1.9980e-03 eta 0:39:11
epoch [3/50] batch [200/288] time 0.156 (0.171) data 0.000 (0.002) loss 2.1739 (2.2408) ce_loss 0.9814 (1.0162) teacher_loss 0.9943 (1.0210) loss_zs_kd 0.1449 (0.1742) loss_oracle 0.1257 (0.1165) acc 81.2500 (72.8750) kd_loss 0.0662 (0.0655) lr 1.9980e-03 eta 0:38:46
epoch [3/50] batch [220/288] time 0.164 (0.170) data 0.000 (0.002) loss 1.8634 (2.2633) ce_loss 0.8291 (1.0268) teacher_loss 0.8354 (1.0315) loss_zs_kd 0.1700 (0.1764) loss_oracle 0.1138 (0.1169) acc 75.0000 (72.7415) kd_loss 0.0759 (0.0662) lr 1.9980e-03 eta 0:38:27
epoch [3/50] batch [240/288] time 0.090 (0.168) data 0.000 (0.002) loss 2.8512 (2.2714) ce_loss 1.3408 (1.0313) teacher_loss 1.3370 (1.0356) loss_zs_kd 0.1373 (0.1758) loss_oracle 0.1047 (0.1166) acc 62.5000 (72.5651) kd_loss 0.0652 (0.0670) lr 1.9980e-03 eta 0:38:00
epoch [3/50] batch [260/288] time 0.405 (0.174) data 0.000 (0.002) loss 1.4121 (2.2604) ce_loss 0.5830 (1.0255) teacher_loss 0.5842 (1.0298) loss_zs_kd 0.1964 (0.1755) loss_oracle 0.1467 (0.1173) acc 84.3750 (72.6803) kd_loss 0.0992 (0.0681) lr 1.9980e-03 eta 0:39:20
epoch [3/50] batch [280/288] time 0.163 (0.173) data 0.000 (0.001) loss 2.4665 (2.2539) ce_loss 1.0762 (1.0210) teacher_loss 1.0683 (1.0252) loss_zs_kd 0.3291 (0.1789) loss_oracle 0.1575 (0.1183) acc 68.7500 (72.8125) kd_loss 0.1134 (0.0693) lr 1.9980e-03 eta 0:39:01
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,419
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.2%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.9%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.8%, epoch: 3 *******
******* Domain a best val test acc: 83.2%, epoch: 3 *******
******* Domain a best test acc:     83.2%, epoch: 3 *******
epoch [4/50] batch [20/288] time 0.164 (0.166) data 0.000 (0.013) loss 1.7677 (2.1073) ce_loss 0.7842 (0.9445) teacher_loss 0.7888 (0.9514) loss_zs_kd 0.1570 (0.1877) loss_oracle 0.1162 (0.1176) acc 84.3750 (73.7500) kd_loss 0.0703 (0.0779) lr 1.9921e-03 eta 0:37:22
epoch [4/50] batch [40/288] time 0.165 (0.161) data 0.000 (0.007) loss 2.3681 (2.1512) ce_loss 1.0469 (0.9651) teacher_loss 1.0505 (0.9733) loss_zs_kd 0.3080 (0.1910) loss_oracle 0.1167 (0.1173) acc 75.0000 (73.7500) kd_loss 0.0978 (0.0801) lr 1.9921e-03 eta 0:36:08
epoch [4/50] batch [60/288] time 0.087 (0.164) data 0.000 (0.005) loss 2.5022 (2.1361) ce_loss 1.1621 (0.9600) teacher_loss 1.1686 (0.9684) loss_zs_kd 0.1416 (0.1853) loss_oracle 0.1007 (0.1150) acc 68.7500 (73.8021) kd_loss 0.0791 (0.0830) lr 1.9921e-03 eta 0:36:54
epoch [4/50] batch [80/288] time 0.178 (0.180) data 0.000 (0.003) loss 3.0363 (2.1742) ce_loss 1.4287 (0.9816) teacher_loss 1.4403 (0.9895) loss_zs_kd 0.1450 (0.1815) loss_oracle 0.0948 (0.1123) acc 65.6250 (73.5547) kd_loss 0.0808 (0.0848) lr 1.9921e-03 eta 0:40:25
epoch [4/50] batch [100/288] time 0.164 (0.178) data 0.000 (0.003) loss 1.9082 (2.2079) ce_loss 0.8672 (1.0005) teacher_loss 0.8652 (1.0073) loss_zs_kd 0.1459 (0.1775) loss_oracle 0.1029 (0.1113) acc 81.2500 (73.1875) kd_loss 0.0804 (0.0857) lr 1.9921e-03 eta 0:39:48
epoch [4/50] batch [120/288] time 0.156 (0.175) data 0.000 (0.002) loss 2.0416 (2.2248) ce_loss 0.9272 (1.0090) teacher_loss 0.9232 (1.0144) loss_zs_kd 0.1831 (0.1768) loss_oracle 0.0996 (0.1129) acc 81.2500 (73.1510) kd_loss 0.0885 (0.0864) lr 1.9921e-03 eta 0:39:04
epoch [4/50] batch [140/288] time 0.143 (0.172) data 0.000 (0.002) loss 1.6829 (2.2364) ce_loss 0.7471 (1.0153) teacher_loss 0.7397 (1.0192) loss_zs_kd 0.1558 (0.1762) loss_oracle 0.1182 (0.1138) acc 81.2500 (72.9018) kd_loss 0.0723 (0.0871) lr 1.9921e-03 eta 0:38:24
epoch [4/50] batch [160/288] time 0.154 (0.170) data 0.000 (0.002) loss 2.5571 (2.2245) ce_loss 1.1826 (1.0080) teacher_loss 1.1749 (1.0123) loss_zs_kd 0.1860 (0.1780) loss_oracle 0.1066 (0.1151) acc 71.8750 (72.9688) kd_loss 0.0684 (0.0871) lr 1.9921e-03 eta 0:37:54
epoch [4/50] batch [180/288] time 0.116 (0.167) data 0.000 (0.002) loss 3.1076 (2.2224) ce_loss 1.4277 (1.0061) teacher_loss 1.4267 (1.0101) loss_zs_kd 0.2325 (0.1790) loss_oracle 0.1369 (0.1166) acc 56.2500 (72.9167) kd_loss 0.0965 (0.0871) lr 1.9921e-03 eta 0:37:16
epoch [4/50] batch [200/288] time 0.081 (0.177) data 0.000 (0.002) loss 2.3930 (2.2192) ce_loss 1.0840 (1.0027) teacher_loss 1.0797 (1.0063) loss_zs_kd 0.1864 (0.1839) loss_oracle 0.1361 (0.1183) acc 71.8750 (73.1875) kd_loss 0.1027 (0.0870) lr 1.9921e-03 eta 0:39:21
epoch [4/50] batch [220/288] time 0.166 (0.175) data 0.000 (0.001) loss 2.4484 (2.2213) ce_loss 1.1309 (1.0025) teacher_loss 1.1319 (1.0057) loss_zs_kd 0.1752 (0.1858) loss_oracle 0.0980 (0.1202) acc 71.8750 (73.0824) kd_loss 0.0714 (0.0882) lr 1.9921e-03 eta 0:38:52
epoch [4/50] batch [240/288] time 0.164 (0.174) data 0.000 (0.001) loss 2.5721 (2.2156) ce_loss 1.1680 (0.9997) teacher_loss 1.1532 (1.0026) loss_zs_kd 0.1717 (0.1854) loss_oracle 0.1651 (0.1206) acc 71.8750 (73.2292) kd_loss 0.1205 (0.0882) lr 1.9921e-03 eta 0:38:33
epoch [4/50] batch [260/288] time 0.147 (0.173) data 0.000 (0.001) loss 1.8434 (2.2255) ce_loss 0.8008 (1.0042) teacher_loss 0.7978 (1.0069) loss_zs_kd 0.1821 (0.1860) loss_oracle 0.1537 (0.1214) acc 71.8750 (73.1130) kd_loss 0.0931 (0.0886) lr 1.9921e-03 eta 0:38:14
epoch [4/50] batch [280/288] time 0.171 (0.172) data 0.000 (0.001) loss 1.5937 (2.2152) ce_loss 0.6934 (0.9990) teacher_loss 0.7009 (1.0016) loss_zs_kd 0.1660 (0.1849) loss_oracle 0.1164 (0.1221) acc 78.1250 (73.3371) kd_loss 0.0661 (0.0889) lr 1.9921e-03 eta 0:38:00
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,416
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 86.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,016
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.4%
******* Domain a best val acc:      86.8%, epoch: 3 *******
******* Domain a best val test acc: 83.2%, epoch: 3 *******
******* Domain a best test acc:     83.2%, epoch: 3 *******
epoch [5/50] batch [20/288] time 0.169 (0.184) data 0.000 (0.013) loss 3.0537 (2.4928) ce_loss 1.4082 (1.1250) teacher_loss 1.4134 (1.1232) loss_zs_kd 0.2269 (0.2157) loss_oracle 0.1186 (0.1368) acc 68.7500 (70.0000) kd_loss 0.0905 (0.1033) lr 1.9823e-03 eta 0:40:30
epoch [5/50] batch [40/288] time 0.168 (0.173) data 0.000 (0.007) loss 1.1900 (2.2824) ce_loss 0.4634 (1.0238) teacher_loss 0.4667 (1.0231) loss_zs_kd 0.2723 (0.2107) loss_oracle 0.1238 (0.1302) acc 93.7500 (72.7344) kd_loss 0.1198 (0.1023) lr 1.9823e-03 eta 0:38:11
epoch [5/50] batch [60/288] time 0.171 (0.169) data 0.000 (0.005) loss 2.4106 (2.2067) ce_loss 1.1240 (0.9905) teacher_loss 1.1076 (0.9892) loss_zs_kd 0.1337 (0.2019) loss_oracle 0.1121 (0.1261) acc 65.6250 (73.8542) kd_loss 0.0824 (0.1016) lr 1.9823e-03 eta 0:37:14
epoch [5/50] batch [80/288] time 0.163 (0.168) data 0.000 (0.003) loss 3.0419 (2.1810) ce_loss 1.4209 (0.9770) teacher_loss 1.4199 (0.9757) loss_zs_kd 0.1945 (0.2061) loss_oracle 0.1039 (0.1251) acc 71.8750 (74.1797) kd_loss 0.0852 (0.1018) lr 1.9823e-03 eta 0:36:46
epoch [5/50] batch [100/288] time 0.159 (0.166) data 0.000 (0.003) loss 1.4625 (2.1996) ce_loss 0.6108 (0.9853) teacher_loss 0.6218 (0.9848) loss_zs_kd 0.2058 (0.2072) loss_oracle 0.1270 (0.1260) acc 81.2500 (74.0625) kd_loss 0.0886 (0.1009) lr 1.9823e-03 eta 0:36:27
epoch [5/50] batch [120/288] time 0.117 (0.169) data 0.000 (0.002) loss 2.2189 (2.1799) ce_loss 1.0000 (0.9781) teacher_loss 0.9895 (0.9759) loss_zs_kd 0.2356 (0.2039) loss_oracle 0.1116 (0.1239) acc 75.0000 (74.3750) kd_loss 0.1077 (0.1000) lr 1.9823e-03 eta 0:36:52
epoch [5/50] batch [140/288] time 0.174 (0.177) data 0.000 (0.002) loss 2.2223 (2.1829) ce_loss 1.0059 (0.9815) teacher_loss 1.0222 (0.9797) loss_zs_kd 0.1662 (0.2008) loss_oracle 0.1111 (0.1212) acc 71.8750 (74.2411) kd_loss 0.0862 (0.0985) lr 1.9823e-03 eta 0:38:34
epoch [5/50] batch [160/288] time 0.173 (0.175) data 0.000 (0.002) loss 2.7334 (2.1888) ce_loss 1.2578 (0.9844) teacher_loss 1.2422 (0.9824) loss_zs_kd 0.1788 (0.2001) loss_oracle 0.1439 (0.1220) acc 68.7500 (73.9062) kd_loss 0.0987 (0.0975) lr 1.9823e-03 eta 0:38:12
epoch [5/50] batch [180/288] time 0.151 (0.174) data 0.000 (0.002) loss 2.0538 (2.2043) ce_loss 0.9121 (0.9907) teacher_loss 0.9121 (0.9895) loss_zs_kd 0.1725 (0.2007) loss_oracle 0.1433 (0.1237) acc 71.8750 (73.6632) kd_loss 0.0950 (0.0971) lr 1.9823e-03 eta 0:37:51
epoch [5/50] batch [200/288] time 0.155 (0.173) data 0.000 (0.002) loss 2.0729 (2.2113) ce_loss 0.9072 (0.9931) teacher_loss 0.9130 (0.9925) loss_zs_kd 0.1960 (0.1993) loss_oracle 0.1546 (0.1260) acc 81.2500 (73.7656) kd_loss 0.1279 (0.0974) lr 1.9823e-03 eta 0:37:31
epoch [5/50] batch [220/288] time 0.156 (0.172) data 0.000 (0.001) loss 2.6644 (2.2189) ce_loss 1.2207 (0.9965) teacher_loss 1.2207 (0.9962) loss_zs_kd 0.1908 (0.2002) loss_oracle 0.1275 (0.1260) acc 68.7500 (73.5227) kd_loss 0.0905 (0.0976) lr 1.9823e-03 eta 0:37:14
epoch [5/50] batch [240/288] time 0.112 (0.174) data 0.000 (0.001) loss 1.8070 (2.2148) ce_loss 0.7905 (0.9944) teacher_loss 0.8108 (0.9945) loss_zs_kd 0.1698 (0.2009) loss_oracle 0.1208 (0.1254) acc 81.2500 (73.4896) kd_loss 0.0856 (0.0973) lr 1.9823e-03 eta 0:37:37
epoch [5/50] batch [260/288] time 0.168 (0.176) data 0.000 (0.001) loss 2.4003 (2.2048) ce_loss 1.0977 (0.9898) teacher_loss 1.1087 (0.9898) loss_zs_kd 0.1149 (0.2004) loss_oracle 0.1365 (0.1250) acc 65.6250 (73.5216) kd_loss 0.0990 (0.0976) lr 1.9823e-03 eta 0:38:06
epoch [5/50] batch [280/288] time 0.167 (0.175) data 0.000 (0.001) loss 1.5831 (2.1847) ce_loss 0.6851 (0.9805) teacher_loss 0.6868 (0.9807) loss_zs_kd 0.2234 (0.1995) loss_oracle 0.0995 (0.1238) acc 84.3750 (73.7165) kd_loss 0.0731 (0.0967) lr 1.9823e-03 eta 0:37:48
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,423
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.3%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,029
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.1%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.9%, epoch: 5 *******
******* Domain a best val test acc: 83.6%, epoch: 5 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [6/50] batch [20/288] time 0.173 (0.175) data 0.000 (0.012) loss 2.2715 (1.9692) ce_loss 1.0400 (0.8781) teacher_loss 1.0425 (0.8778) loss_zs_kd 0.1479 (0.1884) loss_oracle 0.1150 (0.1191) acc 68.7500 (73.7500) kd_loss 0.0911 (0.0936) lr 1.9686e-03 eta 0:37:45
epoch [6/50] batch [40/288] time 0.237 (0.187) data 0.000 (0.006) loss 2.0328 (2.0781) ce_loss 0.9131 (0.9337) teacher_loss 0.9083 (0.9351) loss_zs_kd 0.1692 (0.1930) loss_oracle 0.1268 (0.1127) acc 78.1250 (73.5938) kd_loss 0.0853 (0.0909) lr 1.9686e-03 eta 0:40:14
epoch [6/50] batch [60/288] time 0.152 (0.192) data 0.000 (0.004) loss 2.2236 (2.0558) ce_loss 0.9829 (0.9214) teacher_loss 0.9881 (0.9231) loss_zs_kd 0.2650 (0.1961) loss_oracle 0.1200 (0.1133) acc 68.7500 (74.0104) kd_loss 0.0913 (0.0923) lr 1.9686e-03 eta 0:41:20
epoch [6/50] batch [80/288] time 0.166 (0.183) data 0.000 (0.003) loss 2.1339 (2.0734) ce_loss 0.9370 (0.9288) teacher_loss 0.9383 (0.9301) loss_zs_kd 0.2320 (0.1998) loss_oracle 0.1426 (0.1146) acc 78.1250 (74.0234) kd_loss 0.1024 (0.0928) lr 1.9686e-03 eta 0:39:22
epoch [6/50] batch [100/288] time 0.152 (0.178) data 0.000 (0.003) loss 2.5807 (2.1108) ce_loss 1.1650 (0.9475) teacher_loss 1.1550 (0.9484) loss_zs_kd 0.2324 (0.1976) loss_oracle 0.1445 (0.1161) acc 65.6250 (74.0938) kd_loss 0.1045 (0.0929) lr 1.9686e-03 eta 0:38:09
epoch [6/50] batch [120/288] time 0.171 (0.175) data 0.000 (0.002) loss 2.3947 (2.1015) ce_loss 1.0771 (0.9416) teacher_loss 1.0737 (0.9430) loss_zs_kd 0.2392 (0.1983) loss_oracle 0.1242 (0.1178) acc 71.8750 (74.4271) kd_loss 0.0884 (0.0917) lr 1.9686e-03 eta 0:37:21
epoch [6/50] batch [140/288] time 0.155 (0.172) data 0.000 (0.002) loss 1.7745 (2.1052) ce_loss 0.7793 (0.9424) teacher_loss 0.7876 (0.9432) loss_zs_kd 0.1362 (0.1983) loss_oracle 0.1395 (0.1205) acc 78.1250 (74.3527) kd_loss 0.1086 (0.0929) lr 1.9686e-03 eta 0:36:50
epoch [6/50] batch [160/288] time 0.174 (0.171) data 0.000 (0.002) loss 1.5194 (2.1118) ce_loss 0.6323 (0.9453) teacher_loss 0.6372 (0.9457) loss_zs_kd 0.2273 (0.2012) loss_oracle 0.1362 (0.1202) acc 75.0000 (74.1992) kd_loss 0.0930 (0.0929) lr 1.9686e-03 eta 0:36:30
epoch [6/50] batch [180/288] time 0.083 (0.172) data 0.000 (0.001) loss 1.6830 (2.1178) ce_loss 0.7041 (0.9477) teacher_loss 0.7067 (0.9479) loss_zs_kd 0.2981 (0.2041) loss_oracle 0.1231 (0.1201) acc 87.5000 (74.2014) kd_loss 0.1015 (0.0926) lr 1.9686e-03 eta 0:36:44
epoch [6/50] batch [200/288] time 0.174 (0.176) data 0.000 (0.001) loss 2.1488 (2.1257) ce_loss 0.9741 (0.9518) teacher_loss 0.9713 (0.9516) loss_zs_kd 0.1749 (0.2045) loss_oracle 0.1159 (0.1201) acc 68.7500 (74.2031) kd_loss 0.0760 (0.0921) lr 1.9686e-03 eta 0:37:30
epoch [6/50] batch [220/288] time 0.171 (0.175) data 0.000 (0.001) loss 2.5492 (2.1324) ce_loss 1.1484 (0.9552) teacher_loss 1.1298 (0.9548) loss_zs_kd 0.2534 (0.2053) loss_oracle 0.1443 (0.1198) acc 78.1250 (74.1761) kd_loss 0.1067 (0.0917) lr 1.9686e-03 eta 0:37:11
epoch [6/50] batch [240/288] time 0.154 (0.174) data 0.000 (0.001) loss 2.0354 (2.1414) ce_loss 0.9321 (0.9599) teacher_loss 0.9313 (0.9597) loss_zs_kd 0.1255 (0.2046) loss_oracle 0.1093 (0.1195) acc 75.0000 (74.0104) kd_loss 0.0715 (0.0906) lr 1.9686e-03 eta 0:36:52
epoch [6/50] batch [260/288] time 0.160 (0.173) data 0.000 (0.001) loss 2.6292 (2.1462) ce_loss 1.2129 (0.9622) teacher_loss 1.1971 (0.9617) loss_zs_kd 0.1803 (0.2059) loss_oracle 0.1291 (0.1193) acc 71.8750 (73.9303) kd_loss 0.0748 (0.0897) lr 1.9686e-03 eta 0:36:35
epoch [6/50] batch [280/288] time 0.173 (0.172) data 0.000 (0.001) loss 2.5597 (2.1468) ce_loss 1.1562 (0.9626) teacher_loss 1.1612 (0.9619) loss_zs_kd 0.3126 (0.2069) loss_oracle 0.0860 (0.1189) acc 75.0000 (73.9509) kd_loss 0.0633 (0.0892) lr 1.9686e-03 eta 0:36:20
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,412
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 86.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,026
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 80.1%
******* Domain a best val acc:      86.9%, epoch: 5 *******
******* Domain a best val test acc: 83.6%, epoch: 5 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [7/50] batch [20/288] time 0.166 (0.174) data 0.000 (0.013) loss 2.3987 (2.1979) ce_loss 1.1221 (0.9997) teacher_loss 1.1019 (0.9949) loss_zs_kd 0.1764 (0.2009) loss_oracle 0.0866 (0.1029) acc 71.8750 (74.0625) kd_loss 0.0749 (0.0763) lr 1.9511e-03 eta 0:36:39
epoch [7/50] batch [40/288] time 0.165 (0.167) data 0.000 (0.007) loss 1.5778 (2.0949) ce_loss 0.6616 (0.9448) teacher_loss 0.6627 (0.9420) loss_zs_kd 0.2026 (0.2059) loss_oracle 0.1522 (0.1051) acc 84.3750 (75.2344) kd_loss 0.1017 (0.0788) lr 1.9511e-03 eta 0:35:09
epoch [7/50] batch [60/288] time 0.164 (0.166) data 0.000 (0.005) loss 2.5332 (2.0559) ce_loss 1.1445 (0.9232) teacher_loss 1.1630 (0.9203) loss_zs_kd 0.2295 (0.2085) loss_oracle 0.1109 (0.1082) acc 68.7500 (75.3646) kd_loss 0.0728 (0.0797) lr 1.9511e-03 eta 0:34:53
epoch [7/50] batch [80/288] time 0.147 (0.164) data 0.000 (0.003) loss 1.9538 (2.0660) ce_loss 0.8477 (0.9252) teacher_loss 0.8296 (0.9218) loss_zs_kd 0.2371 (0.2134) loss_oracle 0.1580 (0.1123) acc 75.0000 (75.0781) kd_loss 0.1173 (0.0822) lr 1.9511e-03 eta 0:34:22
epoch [7/50] batch [100/288] time 0.167 (0.163) data 0.000 (0.003) loss 1.3438 (2.0688) ce_loss 0.5688 (0.9251) teacher_loss 0.5735 (0.9229) loss_zs_kd 0.1761 (0.2133) loss_oracle 0.1134 (0.1141) acc 87.5000 (74.8438) kd_loss 0.0972 (0.0832) lr 1.9511e-03 eta 0:34:05
epoch [7/50] batch [120/288] time 0.087 (0.165) data 0.000 (0.002) loss 2.8914 (2.0641) ce_loss 1.3174 (0.9232) teacher_loss 1.3432 (0.9215) loss_zs_kd 0.2113 (0.2115) loss_oracle 0.1251 (0.1137) acc 68.7500 (74.8177) kd_loss 0.0890 (0.0844) lr 1.9511e-03 eta 0:34:30
epoch [7/50] batch [140/288] time 0.169 (0.171) data 0.000 (0.002) loss 2.1994 (2.0844) ce_loss 1.0088 (0.9330) teacher_loss 0.9936 (0.9310) loss_zs_kd 0.1827 (0.2119) loss_oracle 0.1056 (0.1144) acc 71.8750 (74.5982) kd_loss 0.0938 (0.0865) lr 1.9511e-03 eta 0:35:48
epoch [7/50] batch [160/288] time 0.165 (0.171) data 0.000 (0.002) loss 2.0622 (2.1152) ce_loss 0.9214 (0.9485) teacher_loss 0.9104 (0.9454) loss_zs_kd 0.1978 (0.2117) loss_oracle 0.1315 (0.1155) acc 75.0000 (74.2969) kd_loss 0.1173 (0.0888) lr 1.9511e-03 eta 0:35:38
epoch [7/50] batch [180/288] time 0.178 (0.170) data 0.000 (0.002) loss 2.2199 (2.1273) ce_loss 0.9795 (0.9537) teacher_loss 0.9919 (0.9507) loss_zs_kd 0.2288 (0.2118) loss_oracle 0.1342 (0.1170) acc 78.1250 (74.3750) kd_loss 0.1024 (0.0897) lr 1.9511e-03 eta 0:35:27
epoch [7/50] batch [200/288] time 0.155 (0.169) data 0.000 (0.002) loss 1.4489 (2.1137) ce_loss 0.5952 (0.9455) teacher_loss 0.6121 (0.9432) loss_zs_kd 0.2589 (0.2135) loss_oracle 0.1121 (0.1183) acc 84.3750 (74.4844) kd_loss 0.0787 (0.0908) lr 1.9511e-03 eta 0:35:13
epoch [7/50] batch [220/288] time 0.163 (0.169) data 0.000 (0.001) loss 2.5896 (2.1168) ce_loss 1.1914 (0.9468) teacher_loss 1.1892 (0.9446) loss_zs_kd 0.2086 (0.2127) loss_oracle 0.1046 (0.1191) acc 71.8750 (74.3892) kd_loss 0.0849 (0.0923) lr 1.9511e-03 eta 0:34:58
epoch [7/50] batch [240/288] time 0.342 (0.169) data 0.000 (0.001) loss 2.9343 (2.1305) ce_loss 1.3535 (0.9530) teacher_loss 1.3386 (0.9511) loss_zs_kd 0.2098 (0.2129) loss_oracle 0.1373 (0.1199) acc 62.5000 (74.2839) kd_loss 0.1182 (0.0933) lr 1.9511e-03 eta 0:34:57
epoch [7/50] batch [260/288] time 0.098 (0.174) data 0.000 (0.001) loss 2.0703 (2.1362) ce_loss 0.9365 (0.9562) teacher_loss 0.9397 (0.9543) loss_zs_kd 0.1778 (0.2112) loss_oracle 0.1052 (0.1201) acc 75.0000 (74.2308) kd_loss 0.0970 (0.0946) lr 1.9511e-03 eta 0:35:57
epoch [7/50] batch [280/288] time 0.150 (0.173) data 0.000 (0.001) loss 1.5648 (2.1271) ce_loss 0.6851 (0.9521) teacher_loss 0.6857 (0.9507) loss_zs_kd 0.1772 (0.2094) loss_oracle 0.1055 (0.1196) acc 84.3750 (74.4978) kd_loss 0.0888 (0.0949) lr 1.9511e-03 eta 0:35:38
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,424
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.4%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 80.1%
******* Domain a best val acc:      86.9%, epoch: 7 *******
******* Domain a best val test acc: 83.3%, epoch: 7 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [8/50] batch [20/288] time 0.184 (0.184) data 0.000 (0.014) loss 1.9570 (2.0979) ce_loss 0.8345 (0.9426) teacher_loss 0.8203 (0.9337) loss_zs_kd 0.3127 (0.2124) loss_oracle 0.1458 (0.1154) acc 87.5000 (75.6250) kd_loss 0.1408 (0.1021) lr 1.9298e-03 eta 0:37:49
epoch [8/50] batch [40/288] time 0.086 (0.185) data 0.001 (0.007) loss 1.8557 (2.0752) ce_loss 0.8003 (0.9313) teacher_loss 0.8173 (0.9286) loss_zs_kd 0.2269 (0.2025) loss_oracle 0.1247 (0.1142) acc 84.3750 (74.9219) kd_loss 0.0927 (0.0939) lr 1.9298e-03 eta 0:37:58
epoch [8/50] batch [60/288] time 0.147 (0.194) data 0.000 (0.005) loss 3.1312 (2.0393) ce_loss 1.4785 (0.9108) teacher_loss 1.4599 (0.9078) loss_zs_kd 0.1316 (0.2053) loss_oracle 0.1269 (0.1179) acc 56.2500 (75.0000) kd_loss 0.0809 (0.0945) lr 1.9298e-03 eta 0:39:51
epoch [8/50] batch [80/288] time 0.169 (0.187) data 0.000 (0.004) loss 2.3343 (2.0252) ce_loss 1.0547 (0.9005) teacher_loss 1.0478 (0.8990) loss_zs_kd 0.1571 (0.2120) loss_oracle 0.1532 (0.1198) acc 68.7500 (75.3906) kd_loss 0.0873 (0.0936) lr 1.9298e-03 eta 0:38:17
epoch [8/50] batch [100/288] time 0.154 (0.183) data 0.000 (0.003) loss 1.7272 (2.0426) ce_loss 0.7241 (0.9078) teacher_loss 0.7269 (0.9072) loss_zs_kd 0.3117 (0.2168) loss_oracle 0.1203 (0.1192) acc 87.5000 (75.4375) kd_loss 0.1008 (0.0930) lr 1.9298e-03 eta 0:37:25
epoch [8/50] batch [120/288] time 0.150 (0.179) data 0.000 (0.002) loss 1.9180 (2.0318) ce_loss 0.8296 (0.9003) teacher_loss 0.8390 (0.8999) loss_zs_kd 0.2542 (0.2192) loss_oracle 0.1224 (0.1219) acc 78.1250 (75.5990) kd_loss 0.0988 (0.0962) lr 1.9298e-03 eta 0:36:32
epoch [8/50] batch [140/288] time 0.164 (0.175) data 0.000 (0.002) loss 2.1238 (2.0582) ce_loss 0.9272 (0.9137) teacher_loss 0.9531 (0.9138) loss_zs_kd 0.2828 (0.2202) loss_oracle 0.1020 (0.1206) acc 71.8750 (75.3795) kd_loss 0.0832 (0.0965) lr 1.9298e-03 eta 0:35:48
epoch [8/50] batch [160/288] time 0.096 (0.172) data 0.000 (0.002) loss 2.3671 (2.0936) ce_loss 1.0518 (0.9313) teacher_loss 1.0751 (0.9306) loss_zs_kd 0.2709 (0.2197) loss_oracle 0.1047 (0.1218) acc 65.6250 (74.9023) kd_loss 0.0855 (0.0969) lr 1.9298e-03 eta 0:35:03
epoch [8/50] batch [180/288] time 0.334 (0.174) data 0.000 (0.002) loss 2.9216 (2.0976) ce_loss 1.3633 (0.9332) teacher_loss 1.3644 (0.9326) loss_zs_kd 0.1972 (0.2175) loss_oracle 0.0953 (0.1231) acc 65.6250 (74.7222) kd_loss 0.0792 (0.0987) lr 1.9298e-03 eta 0:35:20
epoch [8/50] batch [200/288] time 0.158 (0.177) data 0.000 (0.002) loss 2.6758 (2.1040) ce_loss 1.2344 (0.9363) teacher_loss 1.2319 (0.9358) loss_zs_kd 0.1984 (0.2170) loss_oracle 0.1103 (0.1233) acc 68.7500 (74.6406) kd_loss 0.1040 (0.1007) lr 1.9298e-03 eta 0:35:51
epoch [8/50] batch [220/288] time 0.157 (0.175) data 0.000 (0.001) loss 1.5325 (2.0955) ce_loss 0.6592 (0.9317) teacher_loss 0.6712 (0.9315) loss_zs_kd 0.1839 (0.2163) loss_oracle 0.1101 (0.1242) acc 87.5000 (74.8438) kd_loss 0.1112 (0.1026) lr 1.9298e-03 eta 0:35:30
epoch [8/50] batch [240/288] time 0.170 (0.175) data 0.000 (0.001) loss 2.0274 (2.1047) ce_loss 0.8916 (0.9357) teacher_loss 0.8861 (0.9353) loss_zs_kd 0.2854 (0.2181) loss_oracle 0.1070 (0.1246) acc 78.1250 (74.7135) kd_loss 0.1261 (0.1046) lr 1.9298e-03 eta 0:35:20
epoch [8/50] batch [260/288] time 0.175 (0.174) data 0.000 (0.001) loss 1.9574 (2.1035) ce_loss 0.8555 (0.9354) teacher_loss 0.8527 (0.9349) loss_zs_kd 0.2901 (0.2171) loss_oracle 0.1042 (0.1247) acc 78.1250 (74.8077) kd_loss 0.1082 (0.1058) lr 1.9298e-03 eta 0:35:11
epoch [8/50] batch [280/288] time 0.175 (0.173) data 0.000 (0.001) loss 3.1006 (2.1184) ce_loss 1.4170 (0.9428) teacher_loss 1.4419 (0.9424) loss_zs_kd 0.2309 (0.2164) loss_oracle 0.1263 (0.1250) acc 56.2500 (74.5982) kd_loss 0.1200 (0.1067) lr 1.9298e-03 eta 0:34:59
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,440
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.8%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,027
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 79.9%
******* Domain a best val acc:      87.3%, epoch: 8 *******
******* Domain a best val test acc: 83.5%, epoch: 8 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [9/50] batch [20/288] time 0.158 (0.179) data 0.000 (0.014) loss 2.3555 (2.1546) ce_loss 1.0596 (0.9658) teacher_loss 1.0625 (0.9624) loss_zs_kd 0.2050 (0.2085) loss_oracle 0.1309 (0.1222) acc 71.8750 (72.6562) kd_loss 0.0937 (0.1222) lr 1.9048e-03 eta 0:35:57
epoch [9/50] batch [40/288] time 0.171 (0.170) data 0.000 (0.007) loss 1.3442 (2.0443) ce_loss 0.5635 (0.9079) teacher_loss 0.5558 (0.9041) loss_zs_kd 0.1383 (0.2087) loss_oracle 0.1557 (0.1279) acc 87.5000 (75.1562) kd_loss 0.1402 (0.1233) lr 1.9048e-03 eta 0:34:03
epoch [9/50] batch [60/288] time 0.151 (0.166) data 0.000 (0.005) loss 2.3737 (2.0538) ce_loss 1.0742 (0.9095) teacher_loss 1.0571 (0.9070) loss_zs_kd 0.2163 (0.2128) loss_oracle 0.1342 (0.1309) acc 65.6250 (75.1042) kd_loss 0.1283 (0.1246) lr 1.9048e-03 eta 0:33:19
epoch [9/50] batch [80/288] time 0.153 (0.164) data 0.000 (0.004) loss 1.8240 (2.1099) ce_loss 0.7993 (0.9357) teacher_loss 0.7920 (0.9326) loss_zs_kd 0.2028 (0.2195) loss_oracle 0.1313 (0.1319) acc 84.3750 (74.8438) kd_loss 0.1198 (0.1250) lr 1.9048e-03 eta 0:32:51
epoch [9/50] batch [100/288] time 0.401 (0.164) data 0.000 (0.003) loss 1.6853 (2.1145) ce_loss 0.7490 (0.9395) teacher_loss 0.7421 (0.9365) loss_zs_kd 0.1979 (0.2155) loss_oracle 0.0952 (0.1307) acc 68.7500 (74.8438) kd_loss 0.0923 (0.1237) lr 1.9048e-03 eta 0:32:44
epoch [9/50] batch [120/288] time 0.157 (0.177) data 0.000 (0.003) loss 2.1331 (2.1375) ce_loss 0.9595 (0.9512) teacher_loss 0.9691 (0.9489) loss_zs_kd 0.2231 (0.2158) loss_oracle 0.0929 (0.1295) acc 71.8750 (74.4010) kd_loss 0.1130 (0.1231) lr 1.9048e-03 eta 0:35:22
epoch [9/50] batch [140/288] time 0.167 (0.175) data 0.000 (0.002) loss 2.0448 (2.1527) ce_loss 0.9331 (0.9582) teacher_loss 0.9295 (0.9560) loss_zs_kd 0.1107 (0.2162) loss_oracle 0.1269 (0.1305) acc 78.1250 (74.4866) kd_loss 0.1349 (0.1242) lr 1.9048e-03 eta 0:34:46
epoch [9/50] batch [160/288] time 0.174 (0.173) data 0.000 (0.002) loss 1.6604 (2.1430) ce_loss 0.7017 (0.9522) teacher_loss 0.6980 (0.9498) loss_zs_kd 0.2582 (0.2214) loss_oracle 0.1317 (0.1303) acc 84.3750 (74.5898) kd_loss 0.1409 (0.1260) lr 1.9048e-03 eta 0:34:21
epoch [9/50] batch [180/288] time 0.168 (0.171) data 0.000 (0.002) loss 3.4872 (2.1443) ce_loss 1.6143 (0.9539) teacher_loss 1.6091 (0.9505) loss_zs_kd 0.2597 (0.2198) loss_oracle 0.1339 (0.1300) acc 68.7500 (74.5486) kd_loss 0.1259 (0.1261) lr 1.9048e-03 eta 0:34:01
epoch [9/50] batch [200/288] time 0.147 (0.170) data 0.000 (0.002) loss 2.7303 (2.1653) ce_loss 1.2354 (0.9634) teacher_loss 1.2256 (0.9605) loss_zs_kd 0.2323 (0.2211) loss_oracle 0.1532 (0.1309) acc 71.8750 (74.3125) kd_loss 0.1401 (0.1267) lr 1.9048e-03 eta 0:33:39
epoch [9/50] batch [220/288] time 0.170 (0.169) data 0.000 (0.001) loss 1.5636 (2.1647) ce_loss 0.6362 (0.9629) teacher_loss 0.6389 (0.9601) loss_zs_kd 0.2736 (0.2201) loss_oracle 0.1517 (0.1317) acc 84.3750 (74.2188) kd_loss 0.1235 (0.1269) lr 1.9048e-03 eta 0:33:24
epoch [9/50] batch [240/288] time 0.117 (0.169) data 0.000 (0.001) loss 2.2920 (2.1603) ce_loss 1.0166 (0.9605) teacher_loss 1.0023 (0.9577) loss_zs_kd 0.3131 (0.2194) loss_oracle 0.1165 (0.1323) acc 75.0000 (74.3229) kd_loss 0.1015 (0.1267) lr 1.9048e-03 eta 0:33:29
epoch [9/50] batch [260/288] time 0.165 (0.174) data 0.000 (0.001) loss 1.9861 (2.1661) ce_loss 0.8682 (0.9634) teacher_loss 0.8955 (0.9604) loss_zs_kd 0.1879 (0.2193) loss_oracle 0.1284 (0.1327) acc 71.8750 (74.1587) kd_loss 0.1297 (0.1267) lr 1.9048e-03 eta 0:34:18
epoch [9/50] batch [280/288] time 0.156 (0.173) data 0.000 (0.001) loss 1.9976 (2.1544) ce_loss 0.9136 (0.9576) teacher_loss 0.9019 (0.9546) loss_zs_kd 0.1361 (0.2193) loss_oracle 0.1140 (0.1326) acc 75.0000 (74.2076) kd_loss 0.1111 (0.1264) lr 1.9048e-03 eta 0:34:05
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,438
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,015
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 79.6%
******* Domain a best val acc:      87.3%, epoch: 8 *******
******* Domain a best val test acc: 83.5%, epoch: 8 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [10/50] batch [20/288] time 0.098 (0.171) data 0.000 (0.015) loss 1.6829 (2.1942) ce_loss 0.7246 (0.9721) teacher_loss 0.7332 (0.9740) loss_zs_kd 0.1651 (0.2172) loss_oracle 0.1425 (0.1394) acc 78.1250 (75.6250) kd_loss 0.1363 (0.1259) lr 1.8763e-03 eta 0:33:37
epoch [10/50] batch [40/288] time 0.417 (0.219) data 0.001 (0.008) loss 2.5515 (2.1184) ce_loss 1.1240 (0.9297) teacher_loss 1.1249 (0.9306) loss_zs_kd 0.3169 (0.2293) loss_oracle 0.1442 (0.1434) acc 65.6250 (76.1719) kd_loss 0.1301 (0.1295) lr 1.8763e-03 eta 0:43:01
epoch [10/50] batch [60/288] time 0.178 (0.201) data 0.000 (0.005) loss 1.9029 (2.0508) ce_loss 0.8340 (0.8985) teacher_loss 0.8497 (0.8976) loss_zs_kd 0.1762 (0.2246) loss_oracle 0.1312 (0.1424) acc 78.1250 (76.5104) kd_loss 0.1131 (0.1326) lr 1.8763e-03 eta 0:39:22
epoch [10/50] batch [80/288] time 0.148 (0.194) data 0.000 (0.004) loss 2.3473 (2.1010) ce_loss 1.0664 (0.9239) teacher_loss 1.0786 (0.9209) loss_zs_kd 0.1669 (0.2272) loss_oracle 0.1188 (0.1426) acc 81.2500 (75.7812) kd_loss 0.1296 (0.1345) lr 1.8763e-03 eta 0:37:50
epoch [10/50] batch [100/288] time 0.170 (0.187) data 0.000 (0.003) loss 2.6530 (2.0776) ce_loss 1.2041 (0.9140) teacher_loss 1.1752 (0.9098) loss_zs_kd 0.2165 (0.2201) loss_oracle 0.1655 (0.1437) acc 75.0000 (76.0312) kd_loss 0.1465 (0.1352) lr 1.8763e-03 eta 0:36:27
epoch [10/50] batch [120/288] time 0.151 (0.182) data 0.000 (0.003) loss 2.0213 (2.0775) ce_loss 0.8643 (0.9130) teacher_loss 0.8859 (0.9095) loss_zs_kd 0.1899 (0.2177) loss_oracle 0.1761 (0.1461) acc 81.2500 (76.1719) kd_loss 0.1323 (0.1351) lr 1.8763e-03 eta 0:35:25
epoch [10/50] batch [140/288] time 0.162 (0.178) data 0.000 (0.002) loss 2.7282 (2.1126) ce_loss 1.2334 (0.9286) teacher_loss 1.2382 (0.9249) loss_zs_kd 0.2070 (0.2195) loss_oracle 0.1531 (0.1494) acc 71.8750 (75.8036) kd_loss 0.1381 (0.1364) lr 1.8763e-03 eta 0:34:40
epoch [10/50] batch [160/288] time 0.111 (0.179) data 0.000 (0.002) loss 1.4570 (2.1087) ce_loss 0.6216 (0.9272) teacher_loss 0.6019 (0.9230) loss_zs_kd 0.1608 (0.2176) loss_oracle 0.1531 (0.1497) acc 87.5000 (75.6641) kd_loss 0.1516 (0.1380) lr 1.8763e-03 eta 0:34:50
epoch [10/50] batch [180/288] time 0.157 (0.182) data 0.000 (0.002) loss 2.3880 (2.1298) ce_loss 1.0752 (0.9376) teacher_loss 1.0932 (0.9343) loss_zs_kd 0.1695 (0.2173) loss_oracle 0.1348 (0.1492) acc 71.8750 (75.2431) kd_loss 0.1337 (0.1385) lr 1.8763e-03 eta 0:35:12
epoch [10/50] batch [200/288] time 0.166 (0.179) data 0.000 (0.002) loss 2.6670 (2.1414) ce_loss 1.2461 (0.9441) teacher_loss 1.2070 (0.9402) loss_zs_kd 0.1754 (0.2155) loss_oracle 0.1262 (0.1494) acc 65.6250 (75.0938) kd_loss 0.1663 (0.1396) lr 1.8763e-03 eta 0:34:42
epoch [10/50] batch [220/288] time 0.174 (0.178) data 0.000 (0.002) loss 2.2956 (2.1411) ce_loss 1.0371 (0.9449) teacher_loss 1.0269 (0.9406) loss_zs_kd 0.2234 (0.2150) loss_oracle 0.1200 (0.1481) acc 75.0000 (75.1420) kd_loss 0.1656 (0.1405) lr 1.8763e-03 eta 0:34:18
epoch [10/50] batch [240/288] time 0.161 (0.176) data 0.000 (0.001) loss 1.9381 (2.1448) ce_loss 0.8296 (0.9472) teacher_loss 0.8458 (0.9433) loss_zs_kd 0.2356 (0.2147) loss_oracle 0.1449 (0.1470) acc 71.8750 (75.0260) kd_loss 0.1542 (0.1407) lr 1.8763e-03 eta 0:33:57
epoch [10/50] batch [260/288] time 0.174 (0.175) data 0.000 (0.001) loss 2.3369 (2.1439) ce_loss 1.0410 (0.9469) teacher_loss 1.0424 (0.9427) loss_zs_kd 0.2162 (0.2161) loss_oracle 0.1454 (0.1463) acc 78.1250 (74.9639) kd_loss 0.1215 (0.1414) lr 1.8763e-03 eta 0:33:41
epoch [10/50] batch [280/288] time 0.169 (0.174) data 0.000 (0.001) loss 3.1143 (2.1593) ce_loss 1.4258 (0.9547) teacher_loss 1.4351 (0.9509) loss_zs_kd 0.3077 (0.2179) loss_oracle 0.0995 (0.1448) acc 68.7500 (74.7768) kd_loss 0.0805 (0.1406) lr 1.8763e-03 eta 0:33:28
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,440
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,024
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 79.8%
******* Domain a best val acc:      87.3%, epoch: 8 *******
******* Domain a best val test acc: 83.5%, epoch: 8 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [11/50] batch [20/288] time 0.180 (0.186) data 0.000 (0.012) loss 3.2194 (2.1843) ce_loss 1.4688 (0.9725) teacher_loss 1.4861 (0.9708) loss_zs_kd 0.1921 (0.2191) loss_oracle 0.1685 (0.1315) acc 62.5000 (74.2188) kd_loss 0.1553 (0.1292) lr 1.8443e-03 eta 0:35:34
epoch [11/50] batch [40/288] time 0.162 (0.173) data 0.000 (0.006) loss 2.4335 (2.1774) ce_loss 1.0977 (0.9656) teacher_loss 1.0720 (0.9624) loss_zs_kd 0.2746 (0.2247) loss_oracle 0.1265 (0.1371) acc 71.8750 (73.2812) kd_loss 0.1012 (0.1297) lr 1.8443e-03 eta 0:33:01
epoch [11/50] batch [60/288] time 0.156 (0.169) data 0.000 (0.004) loss 1.7183 (2.1735) ce_loss 0.7139 (0.9625) teacher_loss 0.7139 (0.9583) loss_zs_kd 0.2755 (0.2231) loss_oracle 0.1529 (0.1411) acc 81.2500 (73.5417) kd_loss 0.1138 (0.1253) lr 1.8443e-03 eta 0:32:13
epoch [11/50] batch [80/288] time 0.175 (0.168) data 0.000 (0.003) loss 2.4032 (2.1207) ce_loss 1.0996 (0.9386) teacher_loss 1.0798 (0.9344) loss_zs_kd 0.1615 (0.2206) loss_oracle 0.1430 (0.1374) acc 65.6250 (74.2578) kd_loss 0.1454 (0.1240) lr 1.8443e-03 eta 0:31:56
epoch [11/50] batch [100/288] time 0.087 (0.169) data 0.000 (0.003) loss 2.4931 (2.0894) ce_loss 1.1025 (0.9223) teacher_loss 1.1251 (0.9184) loss_zs_kd 0.2941 (0.2221) loss_oracle 0.1184 (0.1376) acc 68.7500 (74.8125) kd_loss 0.0884 (0.1222) lr 1.8443e-03 eta 0:32:11
epoch [11/50] batch [120/288] time 0.156 (0.175) data 0.000 (0.002) loss 3.1018 (2.0963) ce_loss 1.4492 (0.9255) teacher_loss 1.4302 (0.9222) loss_zs_kd 0.1926 (0.2233) loss_oracle 0.1261 (0.1369) acc 56.2500 (74.7396) kd_loss 0.1034 (0.1203) lr 1.8443e-03 eta 0:33:13
epoch [11/50] batch [140/288] time 0.164 (0.173) data 0.000 (0.002) loss 1.8106 (2.0984) ce_loss 0.8057 (0.9274) teacher_loss 0.8030 (0.9239) loss_zs_kd 0.1683 (0.2216) loss_oracle 0.1178 (0.1363) acc 81.2500 (74.8884) kd_loss 0.1154 (0.1204) lr 1.8443e-03 eta 0:32:53
epoch [11/50] batch [160/288] time 0.162 (0.171) data 0.000 (0.002) loss 2.6379 (2.1268) ce_loss 1.2236 (0.9420) teacher_loss 1.2060 (0.9389) loss_zs_kd 0.2041 (0.2216) loss_oracle 0.1062 (0.1351) acc 65.6250 (74.5898) kd_loss 0.1035 (0.1198) lr 1.8443e-03 eta 0:32:27
epoch [11/50] batch [180/288] time 0.170 (0.170) data 0.000 (0.002) loss 2.2404 (2.1155) ce_loss 0.9971 (0.9370) teacher_loss 0.9903 (0.9334) loss_zs_kd 0.2415 (0.2226) loss_oracle 0.1324 (0.1337) acc 78.1250 (74.6354) kd_loss 0.1452 (0.1189) lr 1.8443e-03 eta 0:32:08
epoch [11/50] batch [200/288] time 0.165 (0.169) data 0.000 (0.001) loss 2.2893 (2.1063) ce_loss 1.0127 (0.9326) teacher_loss 1.0041 (0.9297) loss_zs_kd 0.3384 (0.2220) loss_oracle 0.1033 (0.1330) acc 78.1250 (74.7969) kd_loss 0.0951 (0.1180) lr 1.8443e-03 eta 0:31:51
epoch [11/50] batch [220/288] time 0.101 (0.168) data 0.000 (0.001) loss 2.1577 (2.1058) ce_loss 0.9351 (0.9317) teacher_loss 0.9365 (0.9285) loss_zs_kd 0.2410 (0.2257) loss_oracle 0.1656 (0.1328) acc 81.2500 (74.8153) kd_loss 0.1392 (0.1182) lr 1.8443e-03 eta 0:31:34
epoch [11/50] batch [240/288] time 0.332 (0.171) data 0.000 (0.001) loss 2.1284 (2.1014) ce_loss 0.9556 (0.9298) teacher_loss 0.9510 (0.9267) loss_zs_kd 0.1847 (0.2258) loss_oracle 0.1295 (0.1321) acc 71.8750 (74.9219) kd_loss 0.0960 (0.1178) lr 1.8443e-03 eta 0:32:12
epoch [11/50] batch [260/288] time 0.152 (0.172) data 0.000 (0.001) loss 1.8634 (2.1028) ce_loss 0.8208 (0.9306) teacher_loss 0.8033 (0.9275) loss_zs_kd 0.2182 (0.2258) loss_oracle 0.1301 (0.1318) acc 78.1250 (74.8438) kd_loss 0.0805 (0.1174) lr 1.8443e-03 eta 0:32:19
epoch [11/50] batch [280/288] time 0.158 (0.171) data 0.000 (0.001) loss 1.6063 (2.0866) ce_loss 0.7188 (0.9228) teacher_loss 0.7040 (0.9202) loss_zs_kd 0.1605 (0.2252) loss_oracle 0.1032 (0.1309) acc 81.2500 (75.0112) kd_loss 0.1007 (0.1167) lr 1.8443e-03 eta 0:32:04
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,442
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.8%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,026
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 80.1%
******* Domain a best val acc:      87.4%, epoch: 11 *******
******* Domain a best val test acc: 83.5%, epoch: 11 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [12/50] batch [20/288] time 0.174 (0.173) data 0.000 (0.010) loss 2.1178 (2.1489) ce_loss 0.9580 (0.9511) teacher_loss 0.9627 (0.9524) loss_zs_kd 0.1515 (0.2381) loss_oracle 0.1214 (0.1264) acc 81.2500 (74.0625) kd_loss 0.1013 (0.1133) lr 1.8090e-03 eta 0:32:19
epoch [12/50] batch [40/288] time 0.088 (0.173) data 0.000 (0.005) loss 2.2029 (2.0926) ce_loss 0.9814 (0.9250) teacher_loss 0.9738 (0.9217) loss_zs_kd 0.1701 (0.2338) loss_oracle 0.1626 (0.1290) acc 75.0000 (74.2188) kd_loss 0.0974 (0.1158) lr 1.8090e-03 eta 0:32:16
epoch [12/50] batch [60/288] time 0.132 (0.181) data 0.000 (0.004) loss 2.4303 (2.1284) ce_loss 1.1045 (0.9439) teacher_loss 1.0793 (0.9408) loss_zs_kd 0.2216 (0.2297) loss_oracle 0.1357 (0.1289) acc 78.1250 (73.9583) kd_loss 0.1355 (0.1188) lr 1.8090e-03 eta 0:33:45
epoch [12/50] batch [80/288] time 0.168 (0.177) data 0.000 (0.003) loss 4.0115 (2.1456) ce_loss 1.8799 (0.9527) teacher_loss 1.8861 (0.9494) loss_zs_kd 0.2641 (0.2304) loss_oracle 0.1135 (0.1283) acc 56.2500 (74.2578) kd_loss 0.1016 (0.1185) lr 1.8090e-03 eta 0:32:49
epoch [12/50] batch [100/288] time 0.145 (0.172) data 0.000 (0.002) loss 2.1465 (2.1066) ce_loss 0.9468 (0.9346) teacher_loss 0.9409 (0.9319) loss_zs_kd 0.2082 (0.2243) loss_oracle 0.1547 (0.1280) acc 62.5000 (74.5938) kd_loss 0.1120 (0.1173) lr 1.8090e-03 eta 0:31:51
epoch [12/50] batch [120/288] time 0.144 (0.169) data 0.000 (0.002) loss 2.4295 (2.0958) ce_loss 1.0879 (0.9288) teacher_loss 1.0704 (0.9264) loss_zs_kd 0.2179 (0.2219) loss_oracle 0.1623 (0.1296) acc 68.7500 (74.8698) kd_loss 0.1346 (0.1179) lr 1.8090e-03 eta 0:31:17
epoch [12/50] batch [140/288] time 0.170 (0.167) data 0.000 (0.002) loss 1.2130 (2.1065) ce_loss 0.4819 (0.9326) teacher_loss 0.4897 (0.9308) loss_zs_kd 0.1968 (0.2256) loss_oracle 0.1430 (0.1303) acc 87.5000 (74.8214) kd_loss 0.1284 (0.1193) lr 1.8090e-03 eta 0:30:51
epoch [12/50] batch [160/288] time 0.164 (0.165) data 0.000 (0.001) loss 2.1698 (2.1037) ce_loss 0.9355 (0.9311) teacher_loss 0.9361 (0.9299) loss_zs_kd 0.3023 (0.2274) loss_oracle 0.1470 (0.1290) acc 78.1250 (74.7070) kd_loss 0.1421 (0.1194) lr 1.8090e-03 eta 0:30:29
epoch [12/50] batch [180/288] time 0.348 (0.164) data 0.000 (0.001) loss 1.8311 (2.1277) ce_loss 0.7690 (0.9429) teacher_loss 0.7947 (0.9420) loss_zs_kd 0.3049 (0.2295) loss_oracle 0.1149 (0.1281) acc 84.3750 (74.3750) kd_loss 0.1003 (0.1196) lr 1.8090e-03 eta 0:30:11
epoch [12/50] batch [200/288] time 0.082 (0.172) data 0.000 (0.001) loss 2.3561 (2.1289) ce_loss 1.0537 (0.9438) teacher_loss 1.0321 (0.9431) loss_zs_kd 0.2337 (0.2299) loss_oracle 0.1535 (0.1271) acc 71.8750 (74.4375) kd_loss 0.1353 (0.1189) lr 1.8090e-03 eta 0:31:35
epoch [12/50] batch [220/288] time 0.183 (0.171) data 0.000 (0.001) loss 1.6369 (2.1219) ce_loss 0.6631 (0.9387) teacher_loss 0.6682 (0.9383) loss_zs_kd 0.3314 (0.2324) loss_oracle 0.1399 (0.1288) acc 75.0000 (74.6307) kd_loss 0.1166 (0.1192) lr 1.8090e-03 eta 0:31:22
epoch [12/50] batch [240/288] time 0.186 (0.171) data 0.000 (0.001) loss 2.8871 (2.1285) ce_loss 1.2939 (0.9413) teacher_loss 1.2980 (0.9407) loss_zs_kd 0.3297 (0.2335) loss_oracle 0.1303 (0.1297) acc 62.5000 (74.5964) kd_loss 0.1103 (0.1190) lr 1.8090e-03 eta 0:31:16
epoch [12/50] batch [260/288] time 0.152 (0.170) data 0.000 (0.001) loss 1.7608 (2.1224) ce_loss 0.7563 (0.9384) teacher_loss 0.7499 (0.9378) loss_zs_kd 0.2654 (0.2332) loss_oracle 0.1218 (0.1296) acc 81.2500 (74.6995) kd_loss 0.1235 (0.1186) lr 1.8090e-03 eta 0:31:05
epoch [12/50] batch [280/288] time 0.182 (0.169) data 0.001 (0.001) loss 1.9666 (2.1201) ce_loss 0.8745 (0.9371) teacher_loss 0.8843 (0.9366) loss_zs_kd 0.1777 (0.2328) loss_oracle 0.1190 (0.1300) acc 75.0000 (74.7545) kd_loss 0.1258 (0.1187) lr 1.8090e-03 eta 0:30:56
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,440
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,023
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.1%
******* Domain a best val acc:      87.4%, epoch: 11 *******
******* Domain a best val test acc: 83.5%, epoch: 11 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [13/50] batch [20/288] time 0.147 (0.175) data 0.000 (0.013) loss 1.7496 (2.0392) ce_loss 0.7598 (0.9005) teacher_loss 0.7560 (0.9024) loss_zs_kd 0.2602 (0.2301) loss_oracle 0.1037 (0.1213) acc 78.1250 (74.5312) kd_loss 0.1362 (0.1202) lr 1.7705e-03 eta 0:31:48
epoch [13/50] batch [40/288] time 0.104 (0.138) data 0.000 (0.007) loss 1.7034 (2.1808) ce_loss 0.7036 (0.9702) teacher_loss 0.7158 (0.9720) loss_zs_kd 0.3064 (0.2358) loss_oracle 0.1308 (0.1207) acc 81.2500 (73.3594) kd_loss 0.1325 (0.1183) lr 1.7705e-03 eta 0:25:02
epoch [13/50] batch [60/288] time 0.101 (0.125) data 0.000 (0.004) loss 3.2745 (2.2790) ce_loss 1.5068 (1.0193) teacher_loss 1.4906 (1.0189) loss_zs_kd 0.2721 (0.2343) loss_oracle 0.1410 (0.1236) acc 59.3750 (72.3438) kd_loss 0.1288 (0.1213) lr 1.7705e-03 eta 0:22:44
epoch [13/50] batch [80/288] time 0.102 (0.120) data 0.000 (0.003) loss 2.8196 (2.2265) ce_loss 1.2627 (0.9922) teacher_loss 1.2592 (0.9917) loss_zs_kd 0.3096 (0.2336) loss_oracle 0.1429 (0.1258) acc 68.7500 (73.2422) kd_loss 0.1229 (0.1219) lr 1.7705e-03 eta 0:21:44
epoch [13/50] batch [100/288] time 0.091 (0.116) data 0.000 (0.003) loss 1.4580 (2.1631) ce_loss 0.6313 (0.9607) teacher_loss 0.6410 (0.9599) loss_zs_kd 0.1138 (0.2306) loss_oracle 0.1287 (0.1272) acc 84.3750 (73.9062) kd_loss 0.1284 (0.1224) lr 1.7705e-03 eta 0:20:58
epoch [13/50] batch [120/288] time 0.102 (0.113) data 0.000 (0.002) loss 2.1691 (2.1452) ce_loss 0.9482 (0.9512) teacher_loss 0.9420 (0.9515) loss_zs_kd 0.2527 (0.2318) loss_oracle 0.1524 (0.1267) acc 75.0000 (74.5312) kd_loss 0.1372 (0.1227) lr 1.7705e-03 eta 0:20:24
epoch [13/50] batch [140/288] time 0.095 (0.111) data 0.000 (0.002) loss 1.9903 (2.1669) ce_loss 0.8657 (0.9617) teacher_loss 0.8646 (0.9607) loss_zs_kd 0.2102 (0.2303) loss_oracle 0.1548 (0.1293) acc 75.0000 (74.2634) kd_loss 0.1429 (0.1246) lr 1.7705e-03 eta 0:19:57
epoch [13/50] batch [160/288] time 0.102 (0.109) data 0.000 (0.002) loss 2.3912 (2.1404) ce_loss 1.0654 (0.9485) teacher_loss 1.0868 (0.9475) loss_zs_kd 0.1952 (0.2281) loss_oracle 0.1414 (0.1304) acc 75.0000 (74.5312) kd_loss 0.1425 (0.1255) lr 1.7705e-03 eta 0:19:35
epoch [13/50] batch [180/288] time 0.093 (0.108) data 0.000 (0.002) loss 1.4108 (2.1540) ce_loss 0.5977 (0.9552) teacher_loss 0.6097 (0.9536) loss_zs_kd 0.1495 (0.2293) loss_oracle 0.1287 (0.1305) acc 81.2500 (74.3924) kd_loss 0.1186 (0.1261) lr 1.7705e-03 eta 0:19:17
epoch [13/50] batch [200/288] time 0.100 (0.106) data 0.000 (0.001) loss 2.9273 (2.1507) ce_loss 1.3467 (0.9529) teacher_loss 1.3549 (0.9512) loss_zs_kd 0.1859 (0.2311) loss_oracle 0.1328 (0.1311) acc 65.6250 (74.4375) kd_loss 0.1391 (0.1273) lr 1.7705e-03 eta 0:19:02
epoch [13/50] batch [220/288] time 0.102 (0.106) data 0.000 (0.001) loss 1.9336 (2.1400) ce_loss 0.8037 (0.9470) teacher_loss 0.8017 (0.9451) loss_zs_kd 0.3046 (0.2324) loss_oracle 0.1759 (0.1317) acc 81.2500 (74.5312) kd_loss 0.1545 (0.1283) lr 1.7705e-03 eta 0:18:54
epoch [13/50] batch [240/288] time 0.092 (0.105) data 0.000 (0.001) loss 2.5088 (2.1315) ce_loss 1.1367 (0.9436) teacher_loss 1.1340 (0.9418) loss_zs_kd 0.2545 (0.2306) loss_oracle 0.1108 (0.1308) acc 75.0000 (74.6875) kd_loss 0.0843 (0.1274) lr 1.7705e-03 eta 0:18:44
epoch [13/50] batch [260/288] time 0.104 (0.104) data 0.000 (0.001) loss 2.0865 (2.1086) ce_loss 0.9468 (0.9325) teacher_loss 0.9303 (0.9306) loss_zs_kd 0.2175 (0.2282) loss_oracle 0.1006 (0.1314) acc 75.0000 (74.9760) kd_loss 0.1246 (0.1279) lr 1.7705e-03 eta 0:18:35
epoch [13/50] batch [280/288] time 0.085 (0.104) data 0.000 (0.001) loss 1.5014 (2.1102) ce_loss 0.6465 (0.9337) teacher_loss 0.6142 (0.9316) loss_zs_kd 0.1795 (0.2271) loss_oracle 0.1510 (0.1314) acc 75.0000 (74.8996) kd_loss 0.1314 (0.1278) lr 1.7705e-03 eta 0:18:24
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,437
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,013
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.5%
******* Domain a best val acc:      87.4%, epoch: 11 *******
******* Domain a best val test acc: 83.5%, epoch: 11 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [14/50] batch [20/288] time 0.109 (0.124) data 0.000 (0.019) loss 2.2838 (2.1586) ce_loss 1.0078 (0.9614) teacher_loss 1.0146 (0.9650) loss_zs_kd 0.2408 (0.2280) loss_oracle 0.1410 (0.1182) acc 71.8750 (75.3125) kd_loss 0.1122 (0.1120) lr 1.7290e-03 eta 0:21:57
epoch [14/50] batch [40/288] time 0.107 (0.116) data 0.000 (0.010) loss 1.7878 (2.0825) ce_loss 0.7476 (0.9219) teacher_loss 0.7474 (0.9230) loss_zs_kd 0.2930 (0.2241) loss_oracle 0.1463 (0.1255) acc 78.1250 (75.9375) kd_loss 0.1349 (0.1170) lr 1.7290e-03 eta 0:20:34
epoch [14/50] batch [60/288] time 0.097 (0.112) data 0.000 (0.007) loss 1.9204 (2.0381) ce_loss 0.8462 (0.8975) teacher_loss 0.8561 (0.8992) loss_zs_kd 0.2012 (0.2291) loss_oracle 0.1175 (0.1269) acc 75.0000 (76.2500) kd_loss 0.0887 (0.1179) lr 1.7290e-03 eta 0:19:44
epoch [14/50] batch [80/288] time 0.088 (0.106) data 0.000 (0.005) loss 2.4215 (2.0881) ce_loss 1.0859 (0.9194) teacher_loss 1.0723 (0.9203) loss_zs_kd 0.2198 (0.2347) loss_oracle 0.1533 (0.1310) acc 71.8750 (75.6641) kd_loss 0.1236 (0.1199) lr 1.7290e-03 eta 0:18:41
epoch [14/50] batch [100/288] time 0.083 (0.102) data 0.000 (0.004) loss 2.4706 (2.0816) ce_loss 1.0986 (0.9146) teacher_loss 1.1162 (0.9151) loss_zs_kd 0.2510 (0.2401) loss_oracle 0.1303 (0.1319) acc 68.7500 (75.3125) kd_loss 0.1139 (0.1217) lr 1.7290e-03 eta 0:17:59
epoch [14/50] batch [120/288] time 0.091 (0.100) data 0.000 (0.003) loss 1.6726 (2.1027) ce_loss 0.6997 (0.9260) teacher_loss 0.6903 (0.9256) loss_zs_kd 0.2472 (0.2384) loss_oracle 0.1591 (0.1319) acc 84.3750 (75.2344) kd_loss 0.1294 (0.1223) lr 1.7290e-03 eta 0:17:34
epoch [14/50] batch [140/288] time 0.171 (0.107) data 0.000 (0.003) loss 1.7989 (2.1267) ce_loss 0.7710 (0.9380) teacher_loss 0.7796 (0.9371) loss_zs_kd 0.2026 (0.2381) loss_oracle 0.1469 (0.1326) acc 81.2500 (75.0223) kd_loss 0.1345 (0.1226) lr 1.7290e-03 eta 0:18:41
epoch [14/50] batch [160/288] time 0.168 (0.113) data 0.000 (0.003) loss 1.5808 (2.1036) ce_loss 0.6685 (0.9261) teacher_loss 0.6641 (0.9257) loss_zs_kd 0.2115 (0.2361) loss_oracle 0.1425 (0.1338) acc 78.1250 (75.3516) kd_loss 0.1302 (0.1227) lr 1.7290e-03 eta 0:19:48
epoch [14/50] batch [180/288] time 0.167 (0.118) data 0.000 (0.002) loss 1.4303 (2.0832) ce_loss 0.6050 (0.9162) teacher_loss 0.6235 (0.9161) loss_zs_kd 0.1589 (0.2341) loss_oracle 0.1223 (0.1338) acc 84.3750 (75.4688) kd_loss 0.0726 (0.1230) lr 1.7290e-03 eta 0:20:32
epoch [14/50] batch [200/288] time 0.164 (0.122) data 0.000 (0.002) loss 2.4505 (2.0923) ce_loss 1.0977 (0.9210) teacher_loss 1.0859 (0.9206) loss_zs_kd 0.2765 (0.2339) loss_oracle 0.1287 (0.1339) acc 68.7500 (75.3438) kd_loss 0.1228 (0.1228) lr 1.7290e-03 eta 0:21:12
epoch [14/50] batch [220/288] time 0.167 (0.125) data 0.000 (0.002) loss 1.0052 (2.0798) ce_loss 0.3879 (0.9145) teacher_loss 0.3628 (0.9135) loss_zs_kd 0.1804 (0.2347) loss_oracle 0.1642 (0.1344) acc 90.6250 (75.6392) kd_loss 0.1248 (0.1227) lr 1.7290e-03 eta 0:21:40
epoch [14/50] batch [240/288] time 0.128 (0.125) data 0.000 (0.002) loss 1.9264 (2.0715) ce_loss 0.8345 (0.9099) teacher_loss 0.8154 (0.9089) loss_zs_kd 0.2893 (0.2348) loss_oracle 0.1319 (0.1353) acc 81.2500 (75.7031) kd_loss 0.1300 (0.1225) lr 1.7290e-03 eta 0:21:42
epoch [14/50] batch [260/288] time 0.163 (0.129) data 0.000 (0.002) loss 2.5856 (2.0749) ce_loss 1.1631 (0.9111) teacher_loss 1.1467 (0.9099) loss_zs_kd 0.2608 (0.2348) loss_oracle 0.1454 (0.1365) acc 75.0000 (75.7572) kd_loss 0.1399 (0.1234) lr 1.7290e-03 eta 0:22:22
epoch [14/50] batch [280/288] time 0.153 (0.133) data 0.000 (0.002) loss 1.2071 (2.0720) ce_loss 0.4907 (0.9097) teacher_loss 0.5094 (0.9080) loss_zs_kd 0.1902 (0.2337) loss_oracle 0.1119 (0.1374) acc 87.5000 (75.7812) kd_loss 0.1021 (0.1239) lr 1.7290e-03 eta 0:23:00
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,440
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,024
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.0%
******* Domain a best val acc:      87.4%, epoch: 11 *******
******* Domain a best val test acc: 83.5%, epoch: 11 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [15/50] batch [20/288] time 0.159 (0.181) data 0.000 (0.015) loss 2.2468 (2.1068) ce_loss 1.0078 (0.9297) teacher_loss 1.0266 (0.9270) loss_zs_kd 0.1909 (0.2299) loss_oracle 0.1170 (0.1351) acc 78.1250 (75.1562) kd_loss 0.0950 (0.1273) lr 1.6845e-03 eta 0:31:12
epoch [15/50] batch [40/288] time 0.144 (0.170) data 0.000 (0.008) loss 2.3354 (2.2104) ce_loss 1.0449 (0.9814) teacher_loss 1.0498 (0.9795) loss_zs_kd 0.2224 (0.2288) loss_oracle 0.1295 (0.1350) acc 75.0000 (74.4531) kd_loss 0.1431 (0.1239) lr 1.6845e-03 eta 0:29:15
epoch [15/50] batch [60/288] time 0.168 (0.159) data 0.000 (0.005) loss 1.3414 (2.1225) ce_loss 0.5596 (0.9388) teacher_loss 0.5507 (0.9358) loss_zs_kd 0.2059 (0.2270) loss_oracle 0.1282 (0.1344) acc 78.1250 (75.0521) kd_loss 0.1073 (0.1229) lr 1.6845e-03 eta 0:27:18
epoch [15/50] batch [80/288] time 0.344 (0.169) data 0.000 (0.004) loss 2.0157 (2.0442) ce_loss 0.9028 (0.8997) teacher_loss 0.8843 (0.8971) loss_zs_kd 0.2053 (0.2246) loss_oracle 0.1259 (0.1351) acc 81.2500 (75.8594) kd_loss 0.0918 (0.1216) lr 1.6845e-03 eta 0:28:55
epoch [15/50] batch [100/288] time 0.154 (0.171) data 0.000 (0.003) loss 2.0289 (2.0256) ce_loss 0.8955 (0.8882) teacher_loss 0.8875 (0.8861) loss_zs_kd 0.1948 (0.2291) loss_oracle 0.1485 (0.1368) acc 78.1250 (75.7812) kd_loss 0.1103 (0.1213) lr 1.6845e-03 eta 0:29:19
epoch [15/50] batch [120/288] time 0.167 (0.169) data 0.000 (0.003) loss 2.6482 (2.0360) ce_loss 1.1787 (0.8935) teacher_loss 1.1892 (0.8922) loss_zs_kd 0.2752 (0.2280) loss_oracle 0.1427 (0.1363) acc 71.8750 (75.7552) kd_loss 0.1179 (0.1209) lr 1.6845e-03 eta 0:28:46
epoch [15/50] batch [140/288] time 0.161 (0.166) data 0.000 (0.002) loss 2.2693 (2.0565) ce_loss 0.9946 (0.9035) teacher_loss 1.0082 (0.9023) loss_zs_kd 0.2290 (0.2287) loss_oracle 0.1520 (0.1364) acc 71.8750 (75.4688) kd_loss 0.1157 (0.1207) lr 1.6845e-03 eta 0:28:20
epoch [15/50] batch [160/288] time 0.162 (0.165) data 0.000 (0.002) loss 2.3227 (2.0696) ce_loss 1.0439 (0.9089) teacher_loss 1.0396 (0.9082) loss_zs_kd 0.1736 (0.2308) loss_oracle 0.1523 (0.1371) acc 71.8750 (75.2930) kd_loss 0.1375 (0.1207) lr 1.6845e-03 eta 0:28:03
epoch [15/50] batch [180/288] time 0.156 (0.164) data 0.000 (0.002) loss 2.8949 (2.0827) ce_loss 1.3193 (0.9157) teacher_loss 1.3008 (0.9147) loss_zs_kd 0.2596 (0.2296) loss_oracle 0.1449 (0.1375) acc 71.8750 (75.0868) kd_loss 0.1413 (0.1212) lr 1.6845e-03 eta 0:27:48
epoch [15/50] batch [200/288] time 0.163 (0.163) data 0.000 (0.002) loss 1.7609 (2.0960) ce_loss 0.7285 (0.9221) teacher_loss 0.7422 (0.9207) loss_zs_kd 0.2919 (0.2303) loss_oracle 0.1442 (0.1380) acc 78.1250 (74.9531) kd_loss 0.1520 (0.1225) lr 1.6845e-03 eta 0:27:36
epoch [15/50] batch [220/288] time 0.082 (0.164) data 0.000 (0.002) loss 2.3489 (2.0947) ce_loss 1.0547 (0.9219) teacher_loss 1.0522 (0.9205) loss_zs_kd 0.2213 (0.2306) loss_oracle 0.1314 (0.1370) acc 71.8750 (74.9432) kd_loss 0.1397 (0.1227) lr 1.6845e-03 eta 0:27:48
epoch [15/50] batch [240/288] time 0.081 (0.167) data 0.000 (0.001) loss 1.8892 (2.0851) ce_loss 0.7852 (0.9164) teacher_loss 0.7989 (0.9157) loss_zs_kd 0.3624 (0.2323) loss_oracle 0.1240 (0.1368) acc 75.0000 (75.1562) kd_loss 0.1221 (0.1234) lr 1.6845e-03 eta 0:28:11
epoch [15/50] batch [260/288] time 0.173 (0.165) data 0.000 (0.001) loss 2.2308 (2.0913) ce_loss 1.0127 (0.9194) teacher_loss 1.0322 (0.9188) loss_zs_kd 0.1684 (0.2328) loss_oracle 0.1017 (0.1367) acc 78.1250 (75.1562) kd_loss 0.0922 (0.1237) lr 1.6845e-03 eta 0:27:46
epoch [15/50] batch [280/288] time 0.144 (0.164) data 0.000 (0.001) loss 1.9585 (2.0864) ce_loss 0.8799 (0.9174) teacher_loss 0.8706 (0.9170) loss_zs_kd 0.1947 (0.2310) loss_oracle 0.1107 (0.1365) acc 71.8750 (75.1228) kd_loss 0.1161 (0.1239) lr 1.6845e-03 eta 0:27:36
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,448
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 87.0%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,022
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 79.9%
******* Domain a best val acc:      87.5%, epoch: 15 *******
******* Domain a best val test acc: 83.3%, epoch: 15 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [16/50] batch [20/288] time 0.111 (0.182) data 0.000 (0.017) loss 2.8786 (2.1628) ce_loss 1.2969 (0.9611) teacher_loss 1.2949 (0.9590) loss_zs_kd 0.2680 (0.2181) loss_oracle 0.1528 (0.1336) acc 71.8750 (74.2188) kd_loss 0.1436 (0.1212) lr 1.6374e-03 eta 0:30:32
epoch [16/50] batch [40/288] time 0.097 (0.178) data 0.000 (0.009) loss 2.5175 (2.0855) ce_loss 1.1562 (0.9231) teacher_loss 1.1376 (0.9210) loss_zs_kd 0.2196 (0.2215) loss_oracle 0.1139 (0.1307) acc 68.7500 (74.7656) kd_loss 0.1524 (0.1245) lr 1.6374e-03 eta 0:29:46
epoch [16/50] batch [60/288] time 0.164 (0.191) data 0.001 (0.006) loss 2.3717 (2.0818) ce_loss 1.0205 (0.9192) teacher_loss 1.0119 (0.9171) loss_zs_kd 0.2981 (0.2214) loss_oracle 0.1902 (0.1348) acc 78.1250 (74.7396) kd_loss 0.1940 (0.1257) lr 1.6374e-03 eta 0:31:55
epoch [16/50] batch [80/288] time 0.153 (0.186) data 0.000 (0.004) loss 2.8610 (2.0821) ce_loss 1.3135 (0.9199) teacher_loss 1.3047 (0.9163) loss_zs_kd 0.2334 (0.2215) loss_oracle 0.1260 (0.1353) acc 62.5000 (74.5703) kd_loss 0.1276 (0.1254) lr 1.6374e-03 eta 0:31:03
epoch [16/50] batch [100/288] time 0.177 (0.182) data 0.000 (0.004) loss 2.3760 (2.1044) ce_loss 1.0479 (0.9306) teacher_loss 1.0542 (0.9290) loss_zs_kd 0.2632 (0.2240) loss_oracle 0.1423 (0.1328) acc 65.6250 (74.1562) kd_loss 0.1316 (0.1242) lr 1.6374e-03 eta 0:30:19
epoch [16/50] batch [120/288] time 0.150 (0.178) data 0.000 (0.003) loss 1.7283 (2.0904) ce_loss 0.7183 (0.9239) teacher_loss 0.7343 (0.9228) loss_zs_kd 0.2875 (0.2220) loss_oracle 0.1320 (0.1327) acc 81.2500 (74.3490) kd_loss 0.1040 (0.1241) lr 1.6374e-03 eta 0:29:35
epoch [16/50] batch [140/288] time 0.161 (0.175) data 0.000 (0.003) loss 2.2725 (2.0559) ce_loss 1.0176 (0.9060) teacher_loss 1.0298 (0.9053) loss_zs_kd 0.1937 (0.2216) loss_oracle 0.1282 (0.1339) acc 78.1250 (74.8438) kd_loss 0.1211 (0.1263) lr 1.6374e-03 eta 0:29:01
epoch [16/50] batch [160/288] time 0.416 (0.174) data 0.001 (0.002) loss 2.2589 (2.0519) ce_loss 0.9966 (0.9027) teacher_loss 0.9844 (0.9012) loss_zs_kd 0.1998 (0.2236) loss_oracle 0.1780 (0.1362) acc 78.1250 (74.9414) kd_loss 0.1415 (0.1288) lr 1.6374e-03 eta 0:28:41
epoch [16/50] batch [180/288] time 0.145 (0.180) data 0.000 (0.002) loss 1.6078 (2.0735) ce_loss 0.7212 (0.9124) teacher_loss 0.6838 (0.9110) loss_zs_kd 0.1688 (0.2247) loss_oracle 0.1184 (0.1377) acc 81.2500 (75.0174) kd_loss 0.1510 (0.1310) lr 1.6374e-03 eta 0:29:45
epoch [16/50] batch [200/288] time 0.177 (0.178) data 0.000 (0.002) loss 1.7031 (2.0826) ce_loss 0.7100 (0.9166) teacher_loss 0.7068 (0.9153) loss_zs_kd 0.2394 (0.2239) loss_oracle 0.1667 (0.1388) acc 75.0000 (74.7812) kd_loss 0.1421 (0.1326) lr 1.6374e-03 eta 0:29:17
epoch [16/50] batch [220/288] time 0.154 (0.176) data 0.000 (0.002) loss 1.5088 (2.0731) ce_loss 0.6201 (0.9114) teacher_loss 0.6218 (0.9096) loss_zs_kd 0.2290 (0.2257) loss_oracle 0.1524 (0.1392) acc 81.2500 (74.7869) kd_loss 0.1385 (0.1340) lr 1.6374e-03 eta 0:28:54
epoch [16/50] batch [240/288] time 0.145 (0.174) data 0.000 (0.002) loss 1.7630 (2.0567) ce_loss 0.7471 (0.9030) teacher_loss 0.7350 (0.9008) loss_zs_kd 0.2901 (0.2275) loss_oracle 0.1358 (0.1392) acc 75.0000 (75.0000) kd_loss 0.1316 (0.1354) lr 1.6374e-03 eta 0:28:35
epoch [16/50] batch [260/288] time 0.155 (0.173) data 0.000 (0.002) loss 1.9179 (2.0671) ce_loss 0.8301 (0.9075) teacher_loss 0.8392 (0.9053) loss_zs_kd 0.1982 (0.2289) loss_oracle 0.1495 (0.1398) acc 81.2500 (74.9279) kd_loss 0.1573 (0.1364) lr 1.6374e-03 eta 0:28:18
epoch [16/50] batch [280/288] time 0.160 (0.172) data 0.000 (0.001) loss 2.9753 (2.0827) ce_loss 1.3330 (0.9148) teacher_loss 1.3377 (0.9127) loss_zs_kd 0.3289 (0.2308) loss_oracle 0.1402 (0.1399) acc 62.5000 (74.8103) kd_loss 0.1413 (0.1366) lr 1.6374e-03 eta 0:28:01
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,441
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,023
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.1%
******* Domain a best val acc:      87.5%, epoch: 15 *******
******* Domain a best val test acc: 83.3%, epoch: 15 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [17/50] batch [20/288] time 0.175 (0.192) data 0.000 (0.016) loss 2.9978 (1.8171) ce_loss 1.3721 (0.7828) teacher_loss 1.3767 (0.7829) loss_zs_kd 0.2141 (0.2158) loss_oracle 0.1420 (0.1436) acc 71.8750 (78.7500) kd_loss 0.1101 (0.1364) lr 1.5878e-03 eta 0:31:14
epoch [17/50] batch [40/288] time 0.168 (0.176) data 0.000 (0.008) loss 1.8789 (1.9863) ce_loss 0.7910 (0.8694) teacher_loss 0.8006 (0.8680) loss_zs_kd 0.2810 (0.2242) loss_oracle 0.1467 (0.1368) acc 78.1250 (76.8750) kd_loss 0.1373 (0.1372) lr 1.5878e-03 eta 0:28:40
epoch [17/50] batch [60/288] time 0.164 (0.173) data 0.001 (0.005) loss 2.8277 (2.0255) ce_loss 1.2881 (0.8855) teacher_loss 1.2963 (0.8840) loss_zs_kd 0.2128 (0.2297) loss_oracle 0.1369 (0.1411) acc 68.7500 (76.1458) kd_loss 0.0894 (0.1377) lr 1.5878e-03 eta 0:28:00
epoch [17/50] batch [80/288] time 0.170 (0.171) data 0.000 (0.004) loss 1.6950 (2.0148) ce_loss 0.7329 (0.8795) teacher_loss 0.7063 (0.8780) loss_zs_kd 0.2264 (0.2314) loss_oracle 0.1426 (0.1416) acc 78.1250 (76.1328) kd_loss 0.1660 (0.1395) lr 1.5878e-03 eta 0:27:36
epoch [17/50] batch [100/288] time 0.086 (0.171) data 0.000 (0.003) loss 2.3153 (2.0146) ce_loss 1.0234 (0.8800) teacher_loss 1.0406 (0.8771) loss_zs_kd 0.1919 (0.2306) loss_oracle 0.1553 (0.1421) acc 65.6250 (76.1250) kd_loss 0.1318 (0.1413) lr 1.5878e-03 eta 0:27:39
epoch [17/50] batch [120/288] time 0.166 (0.178) data 0.000 (0.003) loss 2.0928 (2.0284) ce_loss 0.9580 (0.8884) teacher_loss 0.9533 (0.8851) loss_zs_kd 0.1436 (0.2286) loss_oracle 0.1097 (0.1406) acc 78.1250 (75.7031) kd_loss 0.1316 (0.1410) lr 1.5878e-03 eta 0:28:43
epoch [17/50] batch [140/288] time 0.167 (0.176) data 0.000 (0.002) loss 2.4829 (2.0745) ce_loss 1.1074 (0.9103) teacher_loss 1.1049 (0.9081) loss_zs_kd 0.2482 (0.2315) loss_oracle 0.1465 (0.1403) acc 68.7500 (75.2455) kd_loss 0.1244 (0.1407) lr 1.5878e-03 eta 0:28:18
epoch [17/50] batch [160/288] time 0.164 (0.174) data 0.000 (0.002) loss 2.2328 (2.0780) ce_loss 0.9888 (0.9122) teacher_loss 0.9831 (0.9102) loss_zs_kd 0.2177 (0.2323) loss_oracle 0.1520 (0.1395) acc 71.8750 (75.2148) kd_loss 0.1708 (0.1411) lr 1.5878e-03 eta 0:27:52
epoch [17/50] batch [180/288] time 0.169 (0.172) data 0.000 (0.002) loss 1.7331 (2.0602) ce_loss 0.7476 (0.9040) teacher_loss 0.7238 (0.9016) loss_zs_kd 0.1863 (0.2302) loss_oracle 0.1685 (0.1395) acc 84.3750 (75.3819) kd_loss 0.1821 (0.1403) lr 1.5878e-03 eta 0:27:30
epoch [17/50] batch [200/288] time 0.153 (0.170) data 0.000 (0.002) loss 1.7429 (2.0538) ce_loss 0.7715 (0.9005) teacher_loss 0.7656 (0.8983) loss_zs_kd 0.1667 (0.2307) loss_oracle 0.1225 (0.1397) acc 75.0000 (75.5625) kd_loss 0.1121 (0.1402) lr 1.5878e-03 eta 0:27:08
epoch [17/50] batch [220/288] time 0.164 (0.169) data 0.000 (0.002) loss 1.6749 (2.0530) ce_loss 0.7407 (0.8999) teacher_loss 0.7431 (0.8977) loss_zs_kd 0.1504 (0.2319) loss_oracle 0.1158 (0.1394) acc 81.2500 (75.5966) kd_loss 0.0929 (0.1394) lr 1.5878e-03 eta 0:26:54
epoch [17/50] batch [240/288] time 0.089 (0.169) data 0.000 (0.001) loss 1.9629 (2.0486) ce_loss 0.8760 (0.8976) teacher_loss 0.8443 (0.8957) loss_zs_kd 0.1980 (0.2318) loss_oracle 0.1436 (0.1394) acc 75.0000 (75.7292) kd_loss 0.1170 (0.1380) lr 1.5878e-03 eta 0:26:51
epoch [17/50] batch [260/288] time 0.149 (0.172) data 0.000 (0.001) loss 2.7403 (2.0544) ce_loss 1.2305 (0.9001) teacher_loss 1.2330 (0.8981) loss_zs_kd 0.2332 (0.2328) loss_oracle 0.1602 (0.1398) acc 68.7500 (75.6971) kd_loss 0.1350 (0.1378) lr 1.5878e-03 eta 0:27:18
epoch [17/50] batch [280/288] time 0.149 (0.171) data 0.000 (0.001) loss 2.4951 (2.0528) ce_loss 1.0957 (0.8986) teacher_loss 1.0567 (0.8965) loss_zs_kd 0.3159 (0.2335) loss_oracle 0.1848 (0.1409) acc 75.0000 (75.7589) kd_loss 0.1450 (0.1381) lr 1.5878e-03 eta 0:27:01
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,442
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.9%
******* Domain a best val acc:      87.5%, epoch: 15 *******
******* Domain a best val test acc: 83.3%, epoch: 15 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [18/50] batch [20/288] time 0.152 (0.178) data 0.000 (0.011) loss 2.6167 (2.0579) ce_loss 1.1602 (0.8928) teacher_loss 1.1486 (0.8882) loss_zs_kd 0.2246 (0.2484) loss_oracle 0.1956 (0.1527) acc 68.7500 (75.3125) kd_loss 0.1498 (0.1298) lr 1.5358e-03 eta 0:28:07
epoch [18/50] batch [40/288] time 0.106 (0.163) data 0.000 (0.005) loss 3.1274 (2.1381) ce_loss 1.4268 (0.9346) teacher_loss 1.4174 (0.9278) loss_zs_kd 0.3215 (0.2487) loss_oracle 0.1225 (0.1514) acc 62.5000 (74.2969) kd_loss 0.1200 (0.1333) lr 1.5358e-03 eta 0:25:45
epoch [18/50] batch [60/288] time 0.404 (0.195) data 0.000 (0.004) loss 1.5221 (2.1303) ce_loss 0.6104 (0.9310) teacher_loss 0.5779 (0.9257) loss_zs_kd 0.2983 (0.2440) loss_oracle 0.1847 (0.1515) acc 87.5000 (74.5833) kd_loss 0.1647 (0.1339) lr 1.5358e-03 eta 0:30:37
epoch [18/50] batch [80/288] time 0.162 (0.184) data 0.000 (0.003) loss 3.9009 (2.1744) ce_loss 1.7949 (0.9527) teacher_loss 1.7774 (0.9494) loss_zs_kd 0.3355 (0.2437) loss_oracle 0.1608 (0.1505) acc 53.1250 (74.1406) kd_loss 0.1426 (0.1338) lr 1.5358e-03 eta 0:28:52
epoch [18/50] batch [100/288] time 0.166 (0.181) data 0.000 (0.002) loss 1.7985 (2.1572) ce_loss 0.7705 (0.9434) teacher_loss 0.7766 (0.9398) loss_zs_kd 0.2011 (0.2419) loss_oracle 0.1508 (0.1531) acc 87.5000 (74.5625) kd_loss 0.1637 (0.1372) lr 1.5358e-03 eta 0:28:17
epoch [18/50] batch [120/288] time 0.173 (0.179) data 0.000 (0.002) loss 2.4343 (2.1266) ce_loss 1.0830 (0.9294) teacher_loss 1.0899 (0.9255) loss_zs_kd 0.2165 (0.2386) loss_oracle 0.1531 (0.1524) acc 75.0000 (75.0521) kd_loss 0.1474 (0.1383) lr 1.5358e-03 eta 0:27:56
epoch [18/50] batch [140/288] time 0.173 (0.177) data 0.000 (0.002) loss 2.3431 (2.1412) ce_loss 1.0332 (0.9368) teacher_loss 1.0637 (0.9339) loss_zs_kd 0.2298 (0.2383) loss_oracle 0.1313 (0.1513) acc 71.8750 (74.7545) kd_loss 0.1414 (0.1386) lr 1.5358e-03 eta 0:27:37
epoch [18/50] batch [160/288] time 0.318 (0.174) data 0.000 (0.002) loss 2.0095 (2.1294) ce_loss 0.8379 (0.9301) teacher_loss 0.8388 (0.9273) loss_zs_kd 0.3095 (0.2390) loss_oracle 0.1781 (0.1524) acc 75.0000 (75.0000) kd_loss 0.1605 (0.1414) lr 1.5358e-03 eta 0:27:07
epoch [18/50] batch [180/288] time 0.346 (0.179) data 0.000 (0.001) loss 1.6651 (2.1137) ce_loss 0.6733 (0.9217) teacher_loss 0.6881 (0.9199) loss_zs_kd 0.3415 (0.2409) loss_oracle 0.1329 (0.1516) acc 75.0000 (75.2604) kd_loss 0.1292 (0.1428) lr 1.5358e-03 eta 0:27:49
epoch [18/50] batch [200/288] time 0.164 (0.178) data 0.000 (0.001) loss 2.9898 (2.0995) ce_loss 1.3545 (0.9149) teacher_loss 1.3318 (0.9132) loss_zs_kd 0.2493 (0.2406) loss_oracle 0.1789 (0.1511) acc 65.6250 (75.3281) kd_loss 0.1786 (0.1433) lr 1.5358e-03 eta 0:27:38
epoch [18/50] batch [220/288] time 0.150 (0.176) data 0.000 (0.001) loss 3.0604 (2.1036) ce_loss 1.4111 (0.9174) teacher_loss 1.4007 (0.9164) loss_zs_kd 0.2122 (0.2409) loss_oracle 0.1425 (0.1494) acc 68.7500 (75.2699) kd_loss 0.1482 (0.1434) lr 1.5358e-03 eta 0:27:14
epoch [18/50] batch [240/288] time 0.146 (0.174) data 0.000 (0.001) loss 1.6610 (2.1046) ce_loss 0.6924 (0.9185) teacher_loss 0.7078 (0.9175) loss_zs_kd 0.2484 (0.2416) loss_oracle 0.1366 (0.1478) acc 84.3750 (75.2474) kd_loss 0.1408 (0.1425) lr 1.5358e-03 eta 0:26:52
epoch [18/50] batch [260/288] time 0.164 (0.172) data 0.000 (0.001) loss 2.1229 (2.1024) ce_loss 0.9644 (0.9183) teacher_loss 0.9438 (0.9171) loss_zs_kd 0.1347 (0.2400) loss_oracle 0.1474 (0.1470) acc 78.1250 (75.3365) kd_loss 0.1407 (0.1418) lr 1.5358e-03 eta 0:26:34
epoch [18/50] batch [280/288] time 0.164 (0.171) data 0.000 (0.001) loss 2.6045 (2.1104) ce_loss 1.1338 (0.9219) teacher_loss 1.1455 (0.9205) loss_zs_kd 0.3540 (0.2404) loss_oracle 0.1483 (0.1478) acc 68.7500 (75.3013) kd_loss 0.1456 (0.1412) lr 1.5358e-03 eta 0:26:17
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,451
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.1%
Checkpoint saved to icml/multi-dg/oracle/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,013
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.9%
******* Domain a best val acc:      87.6%, epoch: 18 *******
******* Domain a best val test acc: 82.9%, epoch: 18 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [19/50] batch [20/288] time 0.154 (0.187) data 0.000 (0.016) loss 2.0589 (1.9796) ce_loss 0.9263 (0.8629) teacher_loss 0.9305 (0.8642) loss_zs_kd 0.1828 (0.2297) loss_oracle 0.1107 (0.1377) acc 78.1250 (75.9375) kd_loss 0.1011 (0.1246) lr 1.4818e-03 eta 0:28:36
epoch [19/50] batch [40/288] time 0.163 (0.173) data 0.000 (0.008) loss 2.1764 (2.1146) ce_loss 0.9365 (0.9292) teacher_loss 0.8999 (0.9245) loss_zs_kd 0.2605 (0.2328) loss_oracle 0.2098 (0.1445) acc 71.8750 (74.7656) kd_loss 0.1528 (0.1293) lr 1.4818e-03 eta 0:26:26
epoch [19/50] batch [60/288] time 0.169 (0.168) data 0.000 (0.005) loss 2.6934 (2.1985) ce_loss 1.2051 (0.9706) teacher_loss 1.1506 (0.9631) loss_zs_kd 0.2775 (0.2392) loss_oracle 0.1989 (0.1452) acc 68.7500 (73.9062) kd_loss 0.1684 (0.1289) lr 1.4818e-03 eta 0:25:34
epoch [19/50] batch [80/288] time 0.150 (0.165) data 0.000 (0.004) loss 1.9104 (2.1171) ce_loss 0.8335 (0.9297) teacher_loss 0.8234 (0.9241) loss_zs_kd 0.2051 (0.2383) loss_oracle 0.1510 (0.1441) acc 68.7500 (74.8047) kd_loss 0.1030 (0.1275) lr 1.4818e-03 eta 0:25:04
epoch [19/50] batch [100/288] time 0.154 (0.163) data 0.000 (0.003) loss 2.2804 (2.1052) ce_loss 1.0088 (0.9241) teacher_loss 1.0195 (0.9198) loss_zs_kd 0.1961 (0.2363) loss_oracle 0.1541 (0.1431) acc 71.8750 (75.0312) kd_loss 0.1213 (0.1251) lr 1.4818e-03 eta 0:24:43
epoch [19/50] batch [120/288] time 0.108 (0.160) data 0.000 (0.003) loss 3.1174 (2.1045) ce_loss 1.4307 (0.9233) teacher_loss 1.4514 (0.9192) loss_zs_kd 0.2171 (0.2355) loss_oracle 0.1268 (0.1443) acc 65.6250 (74.9740) kd_loss 0.1355 (0.1247) lr 1.4818e-03 eta 0:24:12
epoch [19/50] batch [140/288] time 0.088 (0.175) data 0.000 (0.002) loss 2.7314 (2.1011) ce_loss 1.2441 (0.9218) teacher_loss 1.2380 (0.9188) loss_zs_kd 0.1719 (0.2342) loss_oracle 0.1634 (0.1434) acc 78.1250 (75.0893) kd_loss 0.1619 (0.1243) lr 1.4818e-03 eta 0:26:30
epoch [19/50] batch [160/288] time 0.162 (0.171) data 0.000 (0.002) loss 1.9987 (2.1012) ce_loss 0.8755 (0.9232) teacher_loss 0.8425 (0.9196) loss_zs_kd 0.2457 (0.2301) loss_oracle 0.1578 (0.1433) acc 78.1250 (74.9609) kd_loss 0.1592 (0.1260) lr 1.4818e-03 eta 0:25:52
epoch [19/50] batch [180/288] time 0.153 (0.170) data 0.000 (0.002) loss 2.2703 (2.1026) ce_loss 0.9897 (0.9234) teacher_loss 1.0124 (0.9198) loss_zs_kd 0.2276 (0.2309) loss_oracle 0.1544 (0.1440) acc 71.8750 (74.8264) kd_loss 0.1386 (0.1273) lr 1.4818e-03 eta 0:25:35
epoch [19/50] batch [200/288] time 0.174 (0.169) data 0.000 (0.002) loss 1.5187 (2.0889) ce_loss 0.6040 (0.9157) teacher_loss 0.6046 (0.9120) loss_zs_kd 0.2922 (0.2317) loss_oracle 0.1640 (0.1453) acc 87.5000 (75.0000) kd_loss 0.1631 (0.1280) lr 1.4818e-03 eta 0:25:21
epoch [19/50] batch [220/288] time 0.172 (0.169) data 0.000 (0.002) loss 2.0848 (2.1034) ce_loss 0.8838 (0.9217) teacher_loss 0.9100 (0.9180) loss_zs_kd 0.2976 (0.2356) loss_oracle 0.1422 (0.1459) acc 78.1250 (75.0000) kd_loss 0.1296 (0.1290) lr 1.4818e-03 eta 0:25:16
epoch [19/50] batch [240/288] time 0.167 (0.168) data 0.000 (0.001) loss 1.5657 (2.1005) ce_loss 0.6235 (0.9194) teacher_loss 0.6408 (0.9161) loss_zs_kd 0.3442 (0.2370) loss_oracle 0.1293 (0.1465) acc 81.2500 (74.9219) kd_loss 0.1211 (0.1295) lr 1.4818e-03 eta 0:25:09
epoch [19/50] batch [260/288] time 0.099 (0.168) data 0.000 (0.001) loss 2.2178 (2.0915) ce_loss 0.9854 (0.9151) teacher_loss 0.9931 (0.9116) loss_zs_kd 0.2678 (0.2375) loss_oracle 0.1055 (0.1460) acc 75.0000 (75.0240) kd_loss 0.0984 (0.1297) lr 1.4818e-03 eta 0:25:07
epoch [19/50] batch [280/288] time 0.145 (0.171) data 0.000 (0.001) loss 3.0769 (2.0922) ce_loss 1.3916 (0.9157) teacher_loss 1.3997 (0.9121) loss_zs_kd 0.3138 (0.2381) loss_oracle 0.1287 (0.1453) acc 68.7500 (75.1228) kd_loss 0.1016 (0.1291) lr 1.4818e-03 eta 0:25:31
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,447
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,015
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 79.6%
******* Domain a best val acc:      87.6%, epoch: 18 *******
******* Domain a best val test acc: 82.9%, epoch: 18 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [20/50] batch [20/288] time 0.167 (0.183) data 0.000 (0.013) loss 2.8317 (2.0176) ce_loss 1.3174 (0.8767) teacher_loss 1.2796 (0.8694) loss_zs_kd 0.2525 (0.2465) loss_oracle 0.1085 (0.1483) acc 56.2500 (75.1562) kd_loss 0.1149 (0.1223) lr 1.4258e-03 eta 0:27:14
epoch [20/50] batch [40/288] time 0.172 (0.177) data 0.000 (0.007) loss 2.0600 (2.0265) ce_loss 0.8765 (0.8769) teacher_loss 0.8896 (0.8730) loss_zs_kd 0.3788 (0.2591) loss_oracle 0.1045 (0.1470) acc 75.0000 (75.8594) kd_loss 0.0915 (0.1212) lr 1.4258e-03 eta 0:26:08
epoch [20/50] batch [60/288] time 0.097 (0.174) data 0.000 (0.004) loss 1.9420 (2.0242) ce_loss 0.8408 (0.8756) teacher_loss 0.8457 (0.8736) loss_zs_kd 0.1599 (0.2561) loss_oracle 0.1755 (0.1469) acc 78.1250 (75.9896) kd_loss 0.1380 (0.1220) lr 1.4258e-03 eta 0:25:45
epoch [20/50] batch [80/288] time 0.171 (0.183) data 0.000 (0.003) loss 1.5870 (2.0309) ce_loss 0.6724 (0.8797) teacher_loss 0.6665 (0.8782) loss_zs_kd 0.2035 (0.2538) loss_oracle 0.1465 (0.1461) acc 84.3750 (75.9375) kd_loss 0.1201 (0.1236) lr 1.4258e-03 eta 0:26:55
epoch [20/50] batch [100/288] time 0.169 (0.180) data 0.000 (0.003) loss 2.3861 (2.0194) ce_loss 1.0566 (0.8756) teacher_loss 1.0580 (0.8739) loss_zs_kd 0.2278 (0.2494) loss_oracle 0.1576 (0.1453) acc 65.6250 (76.1875) kd_loss 0.1020 (0.1258) lr 1.4258e-03 eta 0:26:24
epoch [20/50] batch [120/288] time 0.169 (0.178) data 0.000 (0.002) loss 1.2877 (2.0554) ce_loss 0.5425 (0.8946) teacher_loss 0.5238 (0.8925) loss_zs_kd 0.1086 (0.2478) loss_oracle 0.1672 (0.1444) acc 84.3750 (75.5469) kd_loss 0.1260 (0.1270) lr 1.4258e-03 eta 0:26:04
epoch [20/50] batch [140/288] time 0.168 (0.176) data 0.000 (0.002) loss 1.7068 (2.0684) ce_loss 0.7324 (0.9008) teacher_loss 0.7371 (0.8991) loss_zs_kd 0.2452 (0.2488) loss_oracle 0.1147 (0.1442) acc 78.1250 (75.4241) kd_loss 0.0873 (0.1266) lr 1.4258e-03 eta 0:25:49
epoch [20/50] batch [160/288] time 0.171 (0.175) data 0.000 (0.002) loss 2.1230 (2.0627) ce_loss 0.9648 (0.8985) teacher_loss 0.9887 (0.8979) loss_zs_kd 0.1733 (0.2471) loss_oracle 0.0827 (0.1427) acc 71.8750 (75.5469) kd_loss 0.1067 (0.1265) lr 1.4258e-03 eta 0:25:38
epoch [20/50] batch [180/288] time 0.097 (0.174) data 0.000 (0.002) loss 1.7194 (2.0444) ce_loss 0.7520 (0.8903) teacher_loss 0.7551 (0.8902) loss_zs_kd 0.1770 (0.2453) loss_oracle 0.1239 (0.1412) acc 78.1250 (75.7812) kd_loss 0.0999 (0.1255) lr 1.4258e-03 eta 0:25:23
epoch [20/50] batch [200/288] time 0.095 (0.176) data 0.000 (0.002) loss 3.0253 (2.0515) ce_loss 1.3232 (0.8941) teacher_loss 1.3118 (0.8938) loss_zs_kd 0.4075 (0.2449) loss_oracle 0.1865 (0.1412) acc 62.5000 (75.6719) kd_loss 0.1686 (0.1251) lr 1.4258e-03 eta 0:25:39
epoch [20/50] batch [220/288] time 0.146 (0.175) data 0.000 (0.001) loss 1.9545 (2.0313) ce_loss 0.8584 (0.8836) teacher_loss 0.8527 (0.8831) loss_zs_kd 0.2211 (0.2446) loss_oracle 0.1328 (0.1423) acc 71.8750 (75.8665) kd_loss 0.1027 (0.1251) lr 1.4258e-03 eta 0:25:22
epoch [20/50] batch [240/288] time 0.174 (0.174) data 0.000 (0.001) loss 2.4201 (2.0297) ce_loss 1.0898 (0.8822) teacher_loss 1.0816 (0.8820) loss_zs_kd 0.2112 (0.2453) loss_oracle 0.1430 (0.1428) acc 65.6250 (75.8724) kd_loss 0.1008 (0.1245) lr 1.4258e-03 eta 0:25:09
epoch [20/50] batch [260/288] time 0.171 (0.173) data 0.000 (0.001) loss 2.6330 (2.0184) ce_loss 1.1934 (0.8764) teacher_loss 1.1816 (0.8758) loss_zs_kd 0.1886 (0.2455) loss_oracle 0.1638 (0.1435) acc 68.7500 (75.9495) kd_loss 0.1215 (0.1242) lr 1.4258e-03 eta 0:25:00
epoch [20/50] batch [280/288] time 0.168 (0.172) data 0.000 (0.001) loss 1.5918 (2.0162) ce_loss 0.6616 (0.8753) teacher_loss 0.6631 (0.8744) loss_zs_kd 0.2054 (0.2444) loss_oracle 0.1644 (0.1443) acc 87.5000 (75.9821) kd_loss 0.1509 (0.1245) lr 1.4258e-03 eta 0:24:48
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,446
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,016
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.8%
******* Domain a best val acc:      87.6%, epoch: 18 *******
******* Domain a best val test acc: 82.9%, epoch: 18 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [21/50] batch [20/288] time 0.165 (0.182) data 0.000 (0.015) loss 1.1089 (1.9556) ce_loss 0.4128 (0.8383) teacher_loss 0.4073 (0.8380) loss_zs_kd 0.2237 (0.2600) loss_oracle 0.1768 (0.1492) acc 90.6250 (76.7188) kd_loss 0.1604 (0.1304) lr 1.3681e-03 eta 0:26:05
epoch [21/50] batch [40/288] time 0.156 (0.170) data 0.000 (0.008) loss 1.3128 (1.9517) ce_loss 0.5264 (0.8374) teacher_loss 0.5162 (0.8377) loss_zs_kd 0.2236 (0.2507) loss_oracle 0.1584 (0.1512) acc 84.3750 (75.6250) kd_loss 0.1510 (0.1311) lr 1.3681e-03 eta 0:24:26
epoch [21/50] batch [60/288] time 0.158 (0.167) data 0.000 (0.005) loss 1.7702 (1.9901) ce_loss 0.7417 (0.8585) teacher_loss 0.7502 (0.8583) loss_zs_kd 0.2719 (0.2449) loss_oracle 0.1423 (0.1508) acc 78.1250 (75.5208) kd_loss 0.1425 (0.1319) lr 1.3681e-03 eta 0:23:50
epoch [21/50] batch [80/288] time 0.172 (0.164) data 0.000 (0.004) loss 1.3705 (2.0394) ce_loss 0.5562 (0.8849) teacher_loss 0.5501 (0.8847) loss_zs_kd 0.1587 (0.2404) loss_oracle 0.1849 (0.1495) acc 84.3750 (74.9609) kd_loss 0.1512 (0.1339) lr 1.3681e-03 eta 0:23:26
epoch [21/50] batch [100/288] time 0.176 (0.166) data 0.000 (0.003) loss 1.9251 (2.0098) ce_loss 0.8540 (0.8717) teacher_loss 0.8573 (0.8700) loss_zs_kd 0.1623 (0.2387) loss_oracle 0.1326 (0.1487) acc 78.1250 (75.6562) kd_loss 0.1430 (0.1382) lr 1.3681e-03 eta 0:23:37
epoch [21/50] batch [120/288] time 0.082 (0.169) data 0.000 (0.003) loss 1.6991 (2.0228) ce_loss 0.7095 (0.8773) teacher_loss 0.7011 (0.8761) loss_zs_kd 0.2078 (0.2404) loss_oracle 0.1846 (0.1492) acc 84.3750 (75.7552) kd_loss 0.1429 (0.1394) lr 1.3681e-03 eta 0:24:03
epoch [21/50] batch [140/288] time 0.168 (0.175) data 0.000 (0.002) loss 2.0990 (2.0474) ce_loss 0.8999 (0.8892) teacher_loss 0.8886 (0.8883) loss_zs_kd 0.2571 (0.2401) loss_oracle 0.1820 (0.1498) acc 78.1250 (75.6027) kd_loss 0.1510 (0.1395) lr 1.3681e-03 eta 0:24:50
epoch [21/50] batch [160/288] time 0.177 (0.174) data 0.000 (0.002) loss 2.0770 (2.0799) ce_loss 0.9126 (0.9041) teacher_loss 0.9043 (0.9035) loss_zs_kd 0.2179 (0.2451) loss_oracle 0.1512 (0.1498) acc 68.7500 (75.1758) kd_loss 0.1404 (0.1400) lr 1.3681e-03 eta 0:24:39
epoch [21/50] batch [180/288] time 0.164 (0.173) data 0.000 (0.002) loss 2.4561 (2.0921) ce_loss 1.0918 (0.9093) teacher_loss 1.0967 (0.9091) loss_zs_kd 0.2092 (0.2469) loss_oracle 0.1630 (0.1503) acc 71.8750 (74.8611) kd_loss 0.1287 (0.1407) lr 1.3681e-03 eta 0:24:25
epoch [21/50] batch [200/288] time 0.162 (0.172) data 0.000 (0.002) loss 2.6272 (2.0797) ce_loss 1.1875 (0.9036) teacher_loss 1.2099 (0.9036) loss_zs_kd 0.1991 (0.2459) loss_oracle 0.1303 (0.1497) acc 71.8750 (75.0781) kd_loss 0.1075 (0.1392) lr 1.3681e-03 eta 0:24:09
epoch [21/50] batch [220/288] time 0.157 (0.171) data 0.000 (0.002) loss 1.7772 (2.0779) ce_loss 0.7964 (0.9031) teacher_loss 0.7798 (0.9033) loss_zs_kd 0.1807 (0.2452) loss_oracle 0.1106 (0.1489) acc 81.2500 (75.0142) kd_loss 0.1090 (0.1379) lr 1.3681e-03 eta 0:23:57
epoch [21/50] batch [240/288] time 0.354 (0.171) data 0.000 (0.001) loss 2.1485 (2.1005) ce_loss 0.8940 (0.9142) teacher_loss 0.9131 (0.9145) loss_zs_kd 0.2803 (0.2442) loss_oracle 0.2012 (0.1497) acc 87.5000 (74.8958) kd_loss 0.1340 (0.1367) lr 1.3681e-03 eta 0:23:59
epoch [21/50] batch [260/288] time 0.354 (0.173) data 0.000 (0.001) loss 1.8377 (2.0927) ce_loss 0.7837 (0.9105) teacher_loss 0.7623 (0.9103) loss_zs_kd 0.2294 (0.2441) loss_oracle 0.1771 (0.1498) acc 78.1250 (75.0000) kd_loss 0.1285 (0.1357) lr 1.3681e-03 eta 0:24:08
epoch [21/50] batch [280/288] time 0.149 (0.172) data 0.000 (0.001) loss 2.0497 (2.0877) ce_loss 0.8950 (0.9082) teacher_loss 0.9002 (0.9079) loss_zs_kd 0.2108 (0.2440) loss_oracle 0.1492 (0.1495) acc 81.2500 (75.1004) kd_loss 0.1300 (0.1347) lr 1.3681e-03 eta 0:23:58
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,449
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 80.0%
******* Domain a best val acc:      87.6%, epoch: 18 *******
******* Domain a best val test acc: 82.9%, epoch: 18 *******
******* Domain a best test acc:     83.6%, epoch: 5 *******
epoch [22/50] batch [20/288] time 0.141 (0.171) data 0.000 (0.013) loss 3.0251 (2.0586) ce_loss 1.3711 (0.8911) teacher_loss 1.3711 (0.8841) loss_zs_kd 0.2587 (0.2653) loss_oracle 0.1535 (0.1508) acc 56.2500 (74.5312) kd_loss 0.1216 (0.1194) lr 1.3090e-03 eta 0:23:47
epoch [22/50] batch [40/288] time 0.175 (0.169) data 0.000 (0.007) loss 1.9868 (2.0301) ce_loss 0.8921 (0.8789) teacher_loss 0.8851 (0.8757) loss_zs_kd 0.1953 (0.2543) loss_oracle 0.1120 (0.1484) acc 81.2500 (75.0781) kd_loss 0.1334 (0.1239) lr 1.3090e-03 eta 0:23:22
epoch [22/50] batch [60/288] time 0.348 (0.172) data 0.000 (0.005) loss 1.4929 (2.0633) ce_loss 0.6045 (0.8959) teacher_loss 0.5883 (0.8941) loss_zs_kd 0.2867 (0.2523) loss_oracle 0.1568 (0.1472) acc 78.1250 (74.8958) kd_loss 0.1148 (0.1213) lr 1.3090e-03 eta 0:23:44
epoch [22/50] batch [80/288] time 0.186 (0.182) data 0.000 (0.004) loss 2.7726 (2.0378) ce_loss 1.2461 (0.8821) teacher_loss 1.2311 (0.8811) loss_zs_kd 0.2824 (0.2541) loss_oracle 0.1542 (0.1476) acc 65.6250 (75.3516) kd_loss 0.1185 (0.1193) lr 1.3090e-03 eta 0:25:01
epoch [22/50] batch [100/288] time 0.158 (0.179) data 0.000 (0.003) loss 1.4315 (2.0386) ce_loss 0.5972 (0.8842) teacher_loss 0.5960 (0.8815) loss_zs_kd 0.1588 (0.2479) loss_oracle 0.1589 (0.1490) acc 84.3750 (75.3125) kd_loss 0.1094 (0.1180) lr 1.3090e-03 eta 0:24:38
epoch [22/50] batch [120/288] time 0.146 (0.176) data 0.000 (0.002) loss 2.1059 (2.0547) ce_loss 0.9170 (0.8924) teacher_loss 0.9126 (0.8907) loss_zs_kd 0.2513 (0.2487) loss_oracle 0.1506 (0.1473) acc 75.0000 (75.4688) kd_loss 0.1379 (0.1180) lr 1.3090e-03 eta 0:24:05
epoch [22/50] batch [140/288] time 0.165 (0.173) data 0.000 (0.002) loss 2.0045 (2.0331) ce_loss 0.8643 (0.8839) teacher_loss 0.8739 (0.8813) loss_zs_kd 0.2482 (0.2431) loss_oracle 0.1422 (0.1463) acc 81.2500 (75.8036) kd_loss 0.1119 (0.1182) lr 1.3090e-03 eta 0:23:40
epoch [22/50] batch [160/288] time 0.175 (0.172) data 0.000 (0.002) loss 1.4653 (2.0524) ce_loss 0.5967 (0.8935) teacher_loss 0.6013 (0.8913) loss_zs_kd 0.1848 (0.2438) loss_oracle 0.1749 (0.1457) acc 84.3750 (75.7031) kd_loss 0.1557 (0.1186) lr 1.3090e-03 eta 0:23:28
epoch [22/50] batch [180/288] time 0.309 (0.174) data 0.000 (0.002) loss 2.0715 (2.0472) ce_loss 0.9072 (0.8898) teacher_loss 0.9108 (0.8884) loss_zs_kd 0.1603 (0.2444) loss_oracle 0.1734 (0.1468) acc 81.2500 (75.8681) kd_loss 0.1484 (0.1199) lr 1.3090e-03 eta 0:23:42
epoch [22/50] batch [200/288] time 0.159 (0.176) data 0.000 (0.002) loss 2.0495 (2.0567) ce_loss 0.8848 (0.8939) teacher_loss 0.8569 (0.8925) loss_zs_kd 0.2342 (0.2443) loss_oracle 0.1908 (0.1481) acc 75.0000 (75.7500) kd_loss 0.1662 (0.1217) lr 1.3090e-03 eta 0:23:58

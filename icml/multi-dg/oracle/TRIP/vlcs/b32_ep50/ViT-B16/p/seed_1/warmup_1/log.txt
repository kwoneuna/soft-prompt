Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'sun']
Target     ['pascal']
# classes  5
# train_x  5,147
# val      2,206
# test     3,376
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/160] time 0.088 (0.122) data 0.000 (0.018) loss 1.5776 (1.3528) ce_loss 0.7886 (0.6760) teacher_loss 0.7881 (0.6763) loss_zs_kd 0.0013 (0.0003) loss_oracle 0.0002 (0.0004) acc 71.8750 (75.4688) kd_loss 0.0008 (0.0013) lr 1.0000e-05 eta 0:16:11
epoch [1/50] batch [40/160] time 0.079 (0.103) data 0.000 (0.009) loss 1.3229 (1.3280) ce_loss 0.6597 (0.6633) teacher_loss 0.6604 (0.6635) loss_zs_kd 0.0048 (0.0019) loss_oracle 0.0004 (0.0003) acc 75.0000 (75.5469) kd_loss 0.0015 (0.0011) lr 1.0000e-05 eta 0:13:37
epoch [1/50] batch [60/160] time 0.078 (0.096) data 0.000 (0.006) loss 1.0552 (1.3818) ce_loss 0.5254 (0.6898) teacher_loss 0.5249 (0.6899) loss_zs_kd 0.0089 (0.0035) loss_oracle 0.0005 (0.0003) acc 78.1250 (75.1562) kd_loss 0.0016 (0.0011) lr 1.0000e-05 eta 0:12:42
epoch [1/50] batch [80/160] time 0.082 (0.093) data 0.000 (0.005) loss 1.8222 (1.4019) ce_loss 0.9087 (0.6995) teacher_loss 0.9084 (0.6995) loss_zs_kd 0.0095 (0.0052) loss_oracle 0.0004 (0.0003) acc 75.0000 (74.4922) kd_loss 0.0013 (0.0011) lr 1.0000e-05 eta 0:12:12
epoch [1/50] batch [100/160] time 0.073 (0.090) data 0.000 (0.004) loss 1.2578 (1.3941) ce_loss 0.6260 (0.6953) teacher_loss 0.6255 (0.6952) loss_zs_kd 0.0117 (0.0065) loss_oracle 0.0005 (0.0003) acc 84.3750 (74.7500) kd_loss 0.0017 (0.0012) lr 1.0000e-05 eta 0:11:50
epoch [1/50] batch [120/160] time 0.082 (0.088) data 0.000 (0.003) loss 1.4230 (1.3735) ce_loss 0.7080 (0.6846) teacher_loss 0.7064 (0.6846) loss_zs_kd 0.0158 (0.0078) loss_oracle 0.0007 (0.0004) acc 75.0000 (75.1302) kd_loss 0.0020 (0.0013) lr 1.0000e-05 eta 0:11:34
epoch [1/50] batch [140/160] time 0.083 (0.087) data 0.000 (0.003) loss 0.9739 (1.3674) ce_loss 0.4824 (0.6812) teacher_loss 0.4828 (0.6812) loss_zs_kd 0.0163 (0.0092) loss_oracle 0.0005 (0.0004) acc 87.5000 (75.0000) kd_loss 0.0017 (0.0014) lr 1.0000e-05 eta 0:11:27
epoch [1/50] batch [160/160] time 0.071 (0.086) data 0.000 (0.003) loss 1.8890 (1.3740) ce_loss 0.9390 (0.6843) teacher_loss 0.9391 (0.6842) loss_zs_kd 0.0210 (0.0102) loss_oracle 0.0004 (0.0004) acc 65.6250 (74.8633) kd_loss 0.0014 (0.0014) lr 2.0000e-03 eta 0:11:15
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,723
* accuracy: 78.1%
* error: 21.9%
* macro_f1: 80.3%
Checkpoint saved to icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,925
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.3%
Checkpoint saved to icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      78.1%, epoch: 1 *******
******* Domain p best val test acc: 86.6%, epoch: 1 *******
******* Domain p best test acc:     86.6%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/ana
epoch [2/50] batch [20/160] time 0.073 (0.106) data 0.000 (0.024) loss 1.5033 (1.3310) ce_loss 0.6904 (0.6281) teacher_loss 0.6899 (0.6321) loss_zs_kd 0.0695 (0.0869) loss_oracle 0.0883 (0.0274) acc 75.0000 (77.5000) kd_loss 0.0615 (0.0205) lr 2.0000e-03 eta 0:13:47
epoch [2/50] batch [40/160] time 0.080 (0.092) data 0.000 (0.012) loss 1.6505 (1.3347) ce_loss 0.7476 (0.6034) teacher_loss 0.7090 (0.5997) loss_zs_kd 0.0785 (0.0877) loss_oracle 0.1546 (0.0877) acc 78.1250 (78.2812) kd_loss 0.3431 (0.1118) lr 2.0000e-03 eta 0:11:56
epoch [2/50] batch [60/160] time 0.074 (0.089) data 0.000 (0.008) loss 1.1651 (1.3663) ce_loss 0.3982 (0.5999) teacher_loss 0.3748 (0.5846) loss_zs_kd 0.2132 (0.0975) loss_oracle 0.2855 (0.1331) acc 87.5000 (78.6458) kd_loss 0.4882 (0.2151) lr 2.0000e-03 eta 0:11:32
epoch [2/50] batch [80/160] time 0.081 (0.088) data 0.000 (0.006) loss 1.0902 (1.3710) ce_loss 0.3848 (0.5828) teacher_loss 0.3450 (0.5572) loss_zs_kd 0.1368 (0.1099) loss_oracle 0.2920 (0.1761) acc 87.5000 (79.3750) kd_loss 0.6693 (0.3069) lr 2.0000e-03 eta 0:11:19
epoch [2/50] batch [100/160] time 0.073 (0.086) data 0.000 (0.005) loss 0.9357 (1.3774) ce_loss 0.3037 (0.5761) teacher_loss 0.2650 (0.5511) loss_zs_kd 0.1654 (0.1123) loss_oracle 0.2843 (0.1940) acc 93.7500 (79.5312) kd_loss 0.8936 (0.3957) lr 2.0000e-03 eta 0:11:03
epoch [2/50] batch [120/160] time 0.085 (0.084) data 0.000 (0.004) loss 1.7945 (1.4127) ce_loss 0.5732 (0.5731) teacher_loss 0.6238 (0.5486) loss_zs_kd 0.1490 (0.1162) loss_oracle 0.5230 (0.2329) acc 81.2500 (79.1927) kd_loss 0.9735 (0.4846) lr 2.0000e-03 eta 0:10:50
epoch [2/50] batch [140/160] time 0.094 (0.084) data 0.000 (0.004) loss 1.1247 (1.4301) ce_loss 0.2361 (0.5552) teacher_loss 0.2530 (0.5322) loss_zs_kd 0.1145 (0.1167) loss_oracle 0.5783 (0.2843) acc 90.6250 (79.5759) kd_loss 0.9777 (0.5583) lr 2.0000e-03 eta 0:10:47
epoch [2/50] batch [160/160] time 0.079 (0.084) data 0.000 (0.003) loss 1.5966 (1.4461) ce_loss 0.5205 (0.5432) teacher_loss 0.5265 (0.5202) loss_zs_kd 0.1317 (0.1200) loss_oracle 0.4837 (0.3227) acc 84.3750 (79.9609) kd_loss 0.9495 (0.6130) lr 1.9980e-03 eta 0:10:41
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,830
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.7%
Checkpoint saved to icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,947
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.4%
Checkpoint saved to icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.0%, epoch: 2 *******
******* Domain p best val test acc: 87.3%, epoch: 2 *******
******* Domain p best test acc:     87.3%, epoch: 2 *******
epoch [3/50] batch [20/160] time 0.084 (0.099) data 0.000 (0.013) loss 1.2041 (1.4547) ce_loss 0.4282 (0.4895) teacher_loss 0.3671 (0.4609) loss_zs_kd 0.1519 (0.1252) loss_oracle 0.3328 (0.4417) acc 84.3750 (81.8750) kd_loss 1.0095 (0.9966) lr 1.9980e-03 eta 0:12:35
epoch [3/50] batch [40/160] time 0.084 (0.091) data 0.000 (0.007) loss 1.2758 (1.4568) ce_loss 0.4109 (0.5069) teacher_loss 0.4182 (0.4869) loss_zs_kd 0.0751 (0.1253) loss_oracle 0.4092 (0.4004) acc 84.3750 (81.4062) kd_loss 0.9677 (0.9846) lr 1.9980e-03 eta 0:11:38
epoch [3/50] batch [60/160] time 0.093 (0.087) data 0.001 (0.005) loss 1.6259 (1.4941) ce_loss 0.6069 (0.5232) teacher_loss 0.5873 (0.5017) loss_zs_kd 0.1084 (0.1219) loss_oracle 0.3775 (0.4084) acc 81.2500 (80.4688) kd_loss 0.9343 (0.9783) lr 1.9980e-03 eta 0:11:04
epoch [3/50] batch [80/160] time 0.082 (0.085) data 0.000 (0.004) loss 1.4830 (1.4905) ce_loss 0.4922 (0.5200) teacher_loss 0.4808 (0.4944) loss_zs_kd 0.1888 (0.1260) loss_oracle 0.4156 (0.4131) acc 81.2500 (80.5469) kd_loss 0.9796 (0.9751) lr 1.9980e-03 eta 0:10:45
epoch [3/50] batch [100/160] time 0.079 (0.084) data 0.000 (0.003) loss 1.2316 (1.4517) ce_loss 0.3828 (0.4977) teacher_loss 0.3517 (0.4752) loss_zs_kd 0.1082 (0.1306) loss_oracle 0.4430 (0.4135) acc 84.3750 (81.4062) kd_loss 0.8487 (0.9699) lr 1.9980e-03 eta 0:10:39
epoch [3/50] batch [120/160] time 0.081 (0.083) data 0.000 (0.002) loss 1.1836 (1.4391) ce_loss 0.3618 (0.4905) teacher_loss 0.3183 (0.4665) loss_zs_kd 0.1990 (0.1341) loss_oracle 0.4040 (0.4151) acc 90.6250 (81.6146) kd_loss 0.9051 (0.9644) lr 1.9980e-03 eta 0:10:29
epoch [3/50] batch [140/160] time 0.078 (0.083) data 0.000 (0.002) loss 1.0726 (1.4323) ce_loss 0.3660 (0.4901) teacher_loss 0.3172 (0.4650) loss_zs_kd 0.1303 (0.1346) loss_oracle 0.3243 (0.4099) acc 90.6250 (81.4286) kd_loss 0.9391 (0.9574) lr 1.9980e-03 eta 0:10:24
epoch [3/50] batch [160/160] time 0.074 (0.082) data 0.000 (0.002) loss 2.7171 (1.4376) ce_loss 1.1162 (0.4963) teacher_loss 1.2390 (0.4721) loss_zs_kd 0.1214 (0.1346) loss_oracle 0.3012 (0.4019) acc 65.6250 (81.3477) kd_loss 0.8751 (0.9515) lr 1.9921e-03 eta 0:10:16
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,848
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.2%
Checkpoint saved to icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,987
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.4%
Checkpoint saved to icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.8%, epoch: 3 *******
******* Domain p best val test acc: 88.5%, epoch: 3 *******
******* Domain p best test acc:     88.5%, epoch: 3 *******
epoch [4/50] batch [20/160] time 0.073 (0.100) data 0.000 (0.023) loss 1.3768 (1.4295) ce_loss 0.4521 (0.5134) teacher_loss 0.4460 (0.4782) loss_zs_kd 0.0981 (0.1250) loss_oracle 0.4296 (0.3754) acc 81.2500 (81.0938) kd_loss 0.9112 (0.9026) lr 1.9921e-03 eta 0:12:32
epoch [4/50] batch [40/160] time 0.104 (0.098) data 0.000 (0.012) loss 1.0833 (1.3079) ce_loss 0.3308 (0.4546) teacher_loss 0.2722 (0.4257) loss_zs_kd 0.1629 (0.1365) loss_oracle 0.3988 (0.3593) acc 87.5000 (82.7344) kd_loss 0.9048 (0.8964) lr 1.9921e-03 eta 0:12:16
epoch [4/50] batch [60/160] time 0.072 (0.100) data 0.000 (0.008) loss 1.2883 (1.3230) ce_loss 0.4568 (0.4661) teacher_loss 0.4132 (0.4385) loss_zs_kd 0.1304 (0.1338) loss_oracle 0.3532 (0.3515) acc 84.3750 (82.3958) kd_loss 0.8655 (0.8899) lr 1.9921e-03 eta 0:12:25
epoch [4/50] batch [80/160] time 0.142 (0.101) data 0.000 (0.006) loss 1.2498 (1.3394) ce_loss 0.4802 (0.4759) teacher_loss 0.4044 (0.4468) loss_zs_kd 0.1200 (0.1392) loss_oracle 0.3052 (0.3471) acc 78.1250 (81.7969) kd_loss 0.8781 (0.8871) lr 1.9921e-03 eta 0:12:30
epoch [4/50] batch [100/160] time 0.100 (0.104) data 0.000 (0.005) loss 1.4287 (1.3749) ce_loss 0.4927 (0.4880) teacher_loss 0.4705 (0.4599) loss_zs_kd 0.1306 (0.1406) loss_oracle 0.4002 (0.3567) acc 81.2500 (81.5312) kd_loss 0.8504 (0.8812) lr 1.9921e-03 eta 0:12:49
epoch [4/50] batch [120/160] time 0.112 (0.105) data 0.000 (0.004) loss 1.7210 (1.3905) ce_loss 0.6509 (0.4908) teacher_loss 0.5970 (0.4629) loss_zs_kd 0.1234 (0.1382) loss_oracle 0.4115 (0.3677) acc 81.2500 (81.6667) kd_loss 0.7878 (0.8748) lr 1.9921e-03 eta 0:12:58
epoch [4/50] batch [140/160] time 0.103 (0.106) data 0.000 (0.004) loss 1.4164 (1.3985) ce_loss 0.5400 (0.4937) teacher_loss 0.5050 (0.4680) loss_zs_kd 0.0695 (0.1362) loss_oracle 0.3367 (0.3687) acc 81.2500 (81.6518) kd_loss 0.8272 (0.8688) lr 1.9921e-03 eta 0:13:03
epoch [4/50] batch [160/160] time 0.077 (0.106) data 0.000 (0.003) loss 0.8399 (1.3805) ce_loss 0.2844 (0.4902) teacher_loss 0.2841 (0.4643) loss_zs_kd 0.0993 (0.1349) loss_oracle 0.2217 (0.3585) acc 93.7500 (81.7578) kd_loss 0.7986 (0.8630) lr 1.9823e-03 eta 0:12:58
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,856
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 85.3%
Checkpoint saved to icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,991
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 89.5%
Checkpoint saved to icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      84.1%, epoch: 4 *******
******* Domain p best val test acc: 88.6%, epoch: 4 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [5/50] batch [20/160] time 0.146 (0.130) data 0.000 (0.015) loss 1.0147 (1.3826) ce_loss 0.3086 (0.5073) teacher_loss 0.2998 (0.4854) loss_zs_kd 0.0946 (0.1239) loss_oracle 0.3591 (0.3280) acc 93.7500 (82.8125) kd_loss 0.8061 (0.8140) lr 1.9823e-03 eta 0:15:54
epoch [5/50] batch [40/160] time 0.096 (0.120) data 0.000 (0.008) loss 0.9515 (1.3545) ce_loss 0.2935 (0.4988) teacher_loss 0.2721 (0.4720) loss_zs_kd 0.0990 (0.1211) loss_oracle 0.3365 (0.3231) acc 90.6250 (82.3438) kd_loss 0.8083 (0.8092) lr 1.9823e-03 eta 0:14:35
epoch [5/50] batch [60/160] time 0.090 (0.116) data 0.001 (0.005) loss 1.8191 (1.3332) ce_loss 0.7549 (0.4929) teacher_loss 0.7565 (0.4642) loss_zs_kd 0.1297 (0.1297) loss_oracle 0.2429 (0.3112) acc 71.8750 (81.9271) kd_loss 0.7416 (0.8025) lr 1.9823e-03 eta 0:14:09
epoch [5/50] batch [80/160] time 0.082 (0.114) data 0.000 (0.004) loss 1.4956 (1.3509) ce_loss 0.5361 (0.4957) teacher_loss 0.5220 (0.4710) loss_zs_kd 0.1217 (0.1318) loss_oracle 0.3766 (0.3182) acc 84.3750 (82.3438) kd_loss 0.7342 (0.7951) lr 1.9823e-03 eta 0:13:52
epoch [5/50] batch [100/160] time 0.126 (0.113) data 0.000 (0.003) loss 1.1677 (1.3225) ce_loss 0.4346 (0.4812) teacher_loss 0.3593 (0.4571) loss_zs_kd 0.0966 (0.1303) loss_oracle 0.3255 (0.3192) acc 84.3750 (82.5000) kd_loss 0.7758 (0.7913) lr 1.9823e-03 eta 0:13:38
epoch [5/50] batch [120/160] time 0.101 (0.113) data 0.001 (0.003) loss 1.2826 (1.3185) ce_loss 0.5000 (0.4832) teacher_loss 0.4799 (0.4602) loss_zs_kd 0.1322 (0.1309) loss_oracle 0.2367 (0.3097) acc 78.1250 (82.4479) kd_loss 0.7728 (0.7871) lr 1.9823e-03 eta 0:13:37
epoch [5/50] batch [140/160] time 0.119 (0.113) data 0.000 (0.002) loss 1.7903 (1.3043) ce_loss 0.7915 (0.4829) teacher_loss 0.7533 (0.4587) loss_zs_kd 0.1417 (0.1323) loss_oracle 0.1746 (0.2965) acc 75.0000 (82.2545) kd_loss 0.7557 (0.7827) lr 1.9823e-03 eta 0:13:35
epoch [5/50] batch [160/160] time 0.110 (0.112) data 0.000 (0.002) loss 1.7877 (1.2901) ce_loss 0.7617 (0.4800) teacher_loss 0.7800 (0.4572) loss_zs_kd 0.1240 (0.1334) loss_oracle 0.1840 (0.2862) acc 75.0000 (82.2070) kd_loss 0.7590 (0.7786) lr 1.9686e-03 eta 0:13:23
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,843
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,988
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.3%
******* Domain p best val acc:      84.1%, epoch: 4 *******
******* Domain p best val test acc: 88.6%, epoch: 4 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [6/50] batch [20/160] time 0.093 (0.118) data 0.000 (0.016) loss 1.1265 (1.2107) ce_loss 0.3899 (0.4727) teacher_loss 0.3454 (0.4436) loss_zs_kd 0.1668 (0.1366) loss_oracle 0.3079 (0.2262) acc 81.2500 (81.7188) kd_loss 0.7479 (0.7438) lr 1.9686e-03 eta 0:14:06
epoch [6/50] batch [40/160] time 0.174 (0.131) data 0.000 (0.008) loss 1.0536 (1.2056) ce_loss 0.3694 (0.4581) teacher_loss 0.3361 (0.4339) loss_zs_kd 0.1208 (0.1502) loss_oracle 0.2878 (0.2385) acc 84.3750 (82.2656) kd_loss 0.7657 (0.7391) lr 1.9686e-03 eta 0:15:38
epoch [6/50] batch [60/160] time 0.088 (0.125) data 0.001 (0.005) loss 1.0578 (1.2104) ce_loss 0.3713 (0.4589) teacher_loss 0.3135 (0.4339) loss_zs_kd 0.1741 (0.1454) loss_oracle 0.2860 (0.2449) acc 90.6250 (82.9688) kd_loss 0.7112 (0.7335) lr 1.9686e-03 eta 0:14:54
epoch [6/50] batch [80/160] time 0.069 (0.128) data 0.000 (0.004) loss 1.1523 (1.2434) ce_loss 0.4294 (0.4723) teacher_loss 0.4127 (0.4483) loss_zs_kd 0.1650 (0.1430) loss_oracle 0.2276 (0.2512) acc 75.0000 (82.7344) kd_loss 0.7361 (0.7316) lr 1.9686e-03 eta 0:15:14
epoch [6/50] batch [100/160] time 0.079 (0.120) data 0.000 (0.003) loss 1.2684 (1.2391) ce_loss 0.5415 (0.4718) teacher_loss 0.4832 (0.4477) loss_zs_kd 0.0843 (0.1371) loss_oracle 0.2016 (0.2511) acc 78.1250 (82.6562) kd_loss 0.7247 (0.7277) lr 1.9686e-03 eta 0:14:08
epoch [6/50] batch [120/160] time 0.114 (0.117) data 0.000 (0.003) loss 1.4328 (1.2310) ce_loss 0.5859 (0.4713) teacher_loss 0.5274 (0.4472) loss_zs_kd 0.2013 (0.1407) loss_oracle 0.2189 (0.2421) acc 75.0000 (82.6562) kd_loss 0.7169 (0.7236) lr 1.9686e-03 eta 0:13:45
epoch [6/50] batch [140/160] time 0.118 (0.116) data 0.000 (0.003) loss 1.0743 (1.2098) ce_loss 0.4080 (0.4634) teacher_loss 0.3607 (0.4393) loss_zs_kd 0.1089 (0.1394) loss_oracle 0.2511 (0.2374) acc 75.0000 (82.9464) kd_loss 0.6930 (0.7195) lr 1.9686e-03 eta 0:13:35
epoch [6/50] batch [160/160] time 0.078 (0.112) data 0.000 (0.002) loss 1.3905 (1.2291) ce_loss 0.5923 (0.4735) teacher_loss 0.5484 (0.4502) loss_zs_kd 0.1465 (0.1397) loss_oracle 0.1766 (0.2355) acc 78.1250 (82.6562) kd_loss 0.6863 (0.7170) lr 1.9511e-03 eta 0:13:10
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,860
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.5%
Checkpoint saved to icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,932
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 88.2%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [7/50] batch [20/160] time 0.078 (0.106) data 0.000 (0.014) loss 1.4145 (1.0899) ce_loss 0.6147 (0.4335) teacher_loss 0.5565 (0.4083) loss_zs_kd 0.1356 (0.1311) loss_oracle 0.1754 (0.1825) acc 71.8750 (84.5312) kd_loss 0.6962 (0.6849) lr 1.9511e-03 eta 0:12:22
epoch [7/50] batch [40/160] time 0.094 (0.102) data 0.000 (0.007) loss 1.4368 (1.1611) ce_loss 0.5649 (0.4699) teacher_loss 0.5845 (0.4419) loss_zs_kd 0.1210 (0.1345) loss_oracle 0.2269 (0.1821) acc 84.3750 (83.2812) kd_loss 0.6482 (0.6831) lr 1.9511e-03 eta 0:11:51
epoch [7/50] batch [60/160] time 0.085 (0.100) data 0.001 (0.005) loss 1.2733 (1.1561) ce_loss 0.5278 (0.4652) teacher_loss 0.4720 (0.4365) loss_zs_kd 0.1388 (0.1376) loss_oracle 0.2040 (0.1856) acc 75.0000 (83.3854) kd_loss 0.6983 (0.6811) lr 1.9511e-03 eta 0:11:40
epoch [7/50] batch [80/160] time 0.126 (0.099) data 0.000 (0.004) loss 1.6733 (1.1753) ce_loss 0.6289 (0.4693) teacher_loss 0.6449 (0.4398) loss_zs_kd 0.1967 (0.1440) loss_oracle 0.3011 (0.1943) acc 84.3750 (82.8516) kd_loss 0.6967 (0.6785) lr 1.9511e-03 eta 0:11:26
epoch [7/50] batch [100/160] time 0.123 (0.099) data 0.000 (0.003) loss 1.0023 (1.1989) ce_loss 0.3682 (0.4746) teacher_loss 0.3478 (0.4469) loss_zs_kd 0.1387 (0.1444) loss_oracle 0.2170 (0.2051) acc 81.2500 (82.6250) kd_loss 0.6602 (0.6748) lr 1.9511e-03 eta 0:11:27
epoch [7/50] batch [120/160] time 0.088 (0.099) data 0.000 (0.003) loss 0.8930 (1.2200) ce_loss 0.3455 (0.4807) teacher_loss 0.3104 (0.4542) loss_zs_kd 0.0785 (0.1432) loss_oracle 0.1978 (0.2135) acc 87.5000 (82.2135) kd_loss 0.6543 (0.6738) lr 1.9511e-03 eta 0:11:25
epoch [7/50] batch [140/160] time 0.080 (0.100) data 0.000 (0.002) loss 1.1081 (1.2053) ce_loss 0.4126 (0.4708) teacher_loss 0.4035 (0.4442) loss_zs_kd 0.1189 (0.1403) loss_oracle 0.2325 (0.2201) acc 84.3750 (82.4554) kd_loss 0.6513 (0.6717) lr 1.9511e-03 eta 0:11:27
epoch [7/50] batch [160/160] time 0.077 (0.099) data 0.000 (0.002) loss 1.5468 (1.2163) ce_loss 0.6484 (0.4757) teacher_loss 0.6306 (0.4499) loss_zs_kd 0.1851 (0.1389) loss_oracle 0.1753 (0.2211) acc 71.8750 (82.4219) kd_loss 0.6348 (0.6701) lr 1.9298e-03 eta 0:11:19
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,836
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,970
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 88.9%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [8/50] batch [20/160] time 0.089 (0.123) data 0.000 (0.014) loss 1.4037 (1.2754) ce_loss 0.5806 (0.5087) teacher_loss 0.5871 (0.4758) loss_zs_kd 0.1253 (0.1174) loss_oracle 0.1734 (0.2323) acc 84.3750 (82.0312) kd_loss 0.6419 (0.6657) lr 1.9298e-03 eta 0:14:02
epoch [8/50] batch [40/160] time 0.076 (0.108) data 0.000 (0.007) loss 1.4132 (1.2462) ce_loss 0.6045 (0.4969) teacher_loss 0.5367 (0.4686) loss_zs_kd 0.1295 (0.1222) loss_oracle 0.2073 (0.2195) acc 71.8750 (81.7969) kd_loss 0.6737 (0.6574) lr 1.9298e-03 eta 0:12:20
epoch [8/50] batch [60/160] time 0.094 (0.105) data 0.001 (0.005) loss 1.2447 (1.2114) ce_loss 0.4976 (0.4808) teacher_loss 0.4770 (0.4472) loss_zs_kd 0.1615 (0.1305) loss_oracle 0.1894 (0.2183) acc 75.0000 (81.7188) kd_loss 0.6546 (0.6551) lr 1.9298e-03 eta 0:11:55
epoch [8/50] batch [80/160] time 0.094 (0.107) data 0.000 (0.004) loss 0.6676 (1.1858) ce_loss 0.2522 (0.4684) teacher_loss 0.2312 (0.4370) loss_zs_kd 0.1489 (0.1337) loss_oracle 0.1098 (0.2135) acc 93.7500 (82.2266) kd_loss 0.6145 (0.6531) lr 1.9298e-03 eta 0:12:07
epoch [8/50] batch [100/160] time 0.136 (0.108) data 0.000 (0.003) loss 1.1025 (1.1769) ce_loss 0.4375 (0.4664) teacher_loss 0.3654 (0.4330) loss_zs_kd 0.1405 (0.1356) loss_oracle 0.2294 (0.2096) acc 87.5000 (82.3438) kd_loss 0.6700 (0.6508) lr 1.9298e-03 eta 0:12:08
epoch [8/50] batch [120/160] time 0.131 (0.108) data 0.001 (0.003) loss 1.0511 (1.1759) ce_loss 0.3628 (0.4666) teacher_loss 0.3074 (0.4325) loss_zs_kd 0.2054 (0.1363) loss_oracle 0.2782 (0.2087) acc 93.7500 (82.6042) kd_loss 0.7018 (0.6494) lr 1.9298e-03 eta 0:12:07
epoch [8/50] batch [140/160] time 0.085 (0.107) data 0.000 (0.002) loss 1.0164 (1.1738) ce_loss 0.3699 (0.4664) teacher_loss 0.3444 (0.4322) loss_zs_kd 0.1019 (0.1362) loss_oracle 0.2512 (0.2070) acc 84.3750 (82.5000) kd_loss 0.6434 (0.6470) lr 1.9298e-03 eta 0:12:00
epoch [8/50] batch [160/160] time 0.128 (0.112) data 0.000 (0.002) loss 1.1880 (1.1730) ce_loss 0.4575 (0.4651) teacher_loss 0.4610 (0.4317) loss_zs_kd 0.0981 (0.1372) loss_oracle 0.2204 (0.2076) acc 71.8750 (82.5391) kd_loss 0.6112 (0.6454) lr 1.9048e-03 eta 0:12:34
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,858
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,946
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.4%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [9/50] batch [20/160] time 0.074 (0.110) data 0.000 (0.014) loss 0.8199 (1.1221) ce_loss 0.2986 (0.4326) teacher_loss 0.2894 (0.4018) loss_zs_kd 0.1346 (0.1444) loss_oracle 0.1646 (0.2155) acc 84.3750 (82.8125) kd_loss 0.6234 (0.6496) lr 1.9048e-03 eta 0:12:16
epoch [9/50] batch [40/160] time 0.089 (0.108) data 0.000 (0.007) loss 1.1613 (1.1306) ce_loss 0.4553 (0.4456) teacher_loss 0.4582 (0.4179) loss_zs_kd 0.1412 (0.1390) loss_oracle 0.1771 (0.1976) acc 84.3750 (83.5938) kd_loss 0.6300 (0.6378) lr 1.9048e-03 eta 0:12:03
epoch [9/50] batch [60/160] time 0.139 (0.108) data 0.000 (0.005) loss 1.1020 (1.1752) ce_loss 0.4355 (0.4706) teacher_loss 0.4094 (0.4402) loss_zs_kd 0.1155 (0.1385) loss_oracle 0.1993 (0.1951) acc 78.1250 (81.9792) kd_loss 0.6229 (0.6355) lr 1.9048e-03 eta 0:11:56
epoch [9/50] batch [80/160] time 0.113 (0.105) data 0.000 (0.004) loss 0.9681 (1.1616) ce_loss 0.3584 (0.4663) teacher_loss 0.3391 (0.4336) loss_zs_kd 0.1365 (0.1389) loss_oracle 0.2023 (0.1923) acc 87.5000 (82.4219) kd_loss 0.6588 (0.6350) lr 1.9048e-03 eta 0:11:35
epoch [9/50] batch [100/160] time 0.086 (0.103) data 0.000 (0.003) loss 1.1791 (1.1493) ce_loss 0.4463 (0.4599) teacher_loss 0.4248 (0.4274) loss_zs_kd 0.1288 (0.1378) loss_oracle 0.2436 (0.1931) acc 93.7500 (82.6562) kd_loss 0.6584 (0.6345) lr 1.9048e-03 eta 0:11:21
epoch [9/50] batch [120/160] time 0.094 (0.102) data 0.000 (0.003) loss 1.4433 (1.1626) ce_loss 0.6143 (0.4647) teacher_loss 0.5135 (0.4285) loss_zs_kd 0.1638 (0.1398) loss_oracle 0.2337 (0.1994) acc 68.7500 (82.3438) kd_loss 0.6132 (0.6337) lr 1.9048e-03 eta 0:11:15
epoch [9/50] batch [140/160] time 0.129 (0.102) data 0.000 (0.002) loss 1.1543 (1.1566) ce_loss 0.4268 (0.4611) teacher_loss 0.3648 (0.4249) loss_zs_kd 0.2553 (0.1412) loss_oracle 0.2350 (0.2001) acc 90.6250 (82.3438) kd_loss 0.6274 (0.6344) lr 1.9048e-03 eta 0:11:10
epoch [9/50] batch [160/160] time 0.097 (0.101) data 0.000 (0.002) loss 0.9936 (1.1545) ce_loss 0.3911 (0.4590) teacher_loss 0.3528 (0.4243) loss_zs_kd 0.1146 (0.1420) loss_oracle 0.1925 (0.2002) acc 81.2500 (82.5391) kd_loss 0.6444 (0.6348) lr 1.8763e-03 eta 0:10:59
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,849
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,968
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.9%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [10/50] batch [20/160] time 0.093 (0.123) data 0.000 (0.014) loss 0.9220 (1.1606) ce_loss 0.3191 (0.4598) teacher_loss 0.2915 (0.4211) loss_zs_kd 0.0865 (0.1228) loss_oracle 0.2682 (0.2183) acc 90.6250 (83.7500) kd_loss 0.6580 (0.6352) lr 1.8763e-03 eta 0:13:24
epoch [10/50] batch [40/160] time 0.083 (0.113) data 0.000 (0.007) loss 1.1812 (1.1340) ce_loss 0.4758 (0.4529) teacher_loss 0.4402 (0.4133) loss_zs_kd 0.1236 (0.1261) loss_oracle 0.2033 (0.2047) acc 81.2500 (83.3594) kd_loss 0.5933 (0.6250) lr 1.8763e-03 eta 0:12:19
epoch [10/50] batch [60/160] time 0.082 (0.110) data 0.001 (0.005) loss 0.9863 (1.1666) ce_loss 0.3665 (0.4659) teacher_loss 0.3401 (0.4259) loss_zs_kd 0.1564 (0.1309) loss_oracle 0.2016 (0.2093) acc 90.6250 (82.6562) kd_loss 0.6111 (0.6248) lr 1.8763e-03 eta 0:11:53
epoch [10/50] batch [80/160] time 0.133 (0.107) data 0.000 (0.004) loss 1.4377 (1.1780) ce_loss 0.6060 (0.4677) teacher_loss 0.6276 (0.4242) loss_zs_kd 0.1276 (0.1360) loss_oracle 0.1404 (0.2182) acc 81.2500 (82.5781) kd_loss 0.5699 (0.6299) lr 1.8763e-03 eta 0:11:35
epoch [10/50] batch [100/160] time 0.075 (0.107) data 0.000 (0.003) loss 1.1901 (1.1770) ce_loss 0.4534 (0.4638) teacher_loss 0.4116 (0.4221) loss_zs_kd 0.2153 (0.1392) loss_oracle 0.2176 (0.2215) acc 81.2500 (82.7500) kd_loss 0.6099 (0.6286) lr 1.8763e-03 eta 0:11:28
epoch [10/50] batch [120/160] time 0.108 (0.106) data 0.000 (0.003) loss 1.6238 (1.1874) ce_loss 0.6621 (0.4665) teacher_loss 0.6248 (0.4265) loss_zs_kd 0.2278 (0.1417) loss_oracle 0.2230 (0.2235) acc 68.7500 (82.5521) kd_loss 0.6011 (0.6287) lr 1.8763e-03 eta 0:11:21
epoch [10/50] batch [140/160] time 0.130 (0.106) data 0.000 (0.002) loss 0.9662 (1.1759) ce_loss 0.3604 (0.4602) teacher_loss 0.2945 (0.4200) loss_zs_kd 0.1331 (0.1425) loss_oracle 0.2448 (0.2245) acc 90.6250 (82.8571) kd_loss 0.6028 (0.6278) lr 1.8763e-03 eta 0:11:21
epoch [10/50] batch [160/160] time 0.090 (0.104) data 0.000 (0.002) loss 1.5685 (1.2014) ce_loss 0.6421 (0.4707) teacher_loss 0.6785 (0.4322) loss_zs_kd 0.1330 (0.1461) loss_oracle 0.1814 (0.2254) acc 71.8750 (82.4219) kd_loss 0.6319 (0.6254) lr 1.8443e-03 eta 0:11:07
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,847
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,926
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 88.1%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [11/50] batch [20/160] time 0.089 (0.120) data 0.000 (0.012) loss 0.9033 (1.1458) ce_loss 0.3193 (0.4517) teacher_loss 0.2831 (0.4099) loss_zs_kd 0.1259 (0.1198) loss_oracle 0.2379 (0.2243) acc 87.5000 (84.2188) kd_loss 0.6131 (0.6097) lr 1.8443e-03 eta 0:12:45
epoch [11/50] batch [40/160] time 0.074 (0.108) data 0.000 (0.006) loss 0.8762 (1.1582) ce_loss 0.3201 (0.4609) teacher_loss 0.3352 (0.4221) loss_zs_kd 0.1228 (0.1278) loss_oracle 0.1595 (0.2112) acc 93.7500 (83.2812) kd_loss 0.6094 (0.6107) lr 1.8443e-03 eta 0:11:25
epoch [11/50] batch [60/160] time 0.178 (0.123) data 0.001 (0.004) loss 0.9602 (1.1697) ce_loss 0.4038 (0.4685) teacher_loss 0.3669 (0.4344) loss_zs_kd 0.1341 (0.1302) loss_oracle 0.1225 (0.2017) acc 81.2500 (83.2292) kd_loss 0.5717 (0.6079) lr 1.8443e-03 eta 0:12:59
epoch [11/50] batch [80/160] time 0.163 (0.122) data 0.000 (0.003) loss 1.2219 (1.1737) ce_loss 0.4961 (0.4699) teacher_loss 0.4860 (0.4341) loss_zs_kd 0.1309 (0.1318) loss_oracle 0.1743 (0.2038) acc 84.3750 (82.7344) kd_loss 0.6085 (0.6073) lr 1.8443e-03 eta 0:12:48
epoch [11/50] batch [100/160] time 0.084 (0.120) data 0.000 (0.003) loss 1.1517 (1.1502) ce_loss 0.4114 (0.4576) teacher_loss 0.3936 (0.4207) loss_zs_kd 0.1798 (0.1337) loss_oracle 0.2569 (0.2050) acc 87.5000 (83.3750) kd_loss 0.6654 (0.6079) lr 1.8443e-03 eta 0:12:38
epoch [11/50] batch [120/160] time 0.124 (0.120) data 0.001 (0.002) loss 1.1092 (1.1511) ce_loss 0.4500 (0.4562) teacher_loss 0.3715 (0.4188) loss_zs_kd 0.1397 (0.1370) loss_oracle 0.2179 (0.2076) acc 81.2500 (83.2812) kd_loss 0.6234 (0.6117) lr 1.8443e-03 eta 0:12:31
epoch [11/50] batch [140/160] time 0.100 (0.117) data 0.000 (0.002) loss 1.0591 (1.1472) ce_loss 0.4187 (0.4541) teacher_loss 0.3926 (0.4147) loss_zs_kd 0.1576 (0.1360) loss_oracle 0.1689 (0.2104) acc 81.2500 (83.3259) kd_loss 0.5600 (0.6121) lr 1.8443e-03 eta 0:12:15
epoch [11/50] batch [160/160] time 0.088 (0.116) data 0.000 (0.002) loss 0.9797 (1.1409) ce_loss 0.3386 (0.4512) teacher_loss 0.3271 (0.4113) loss_zs_kd 0.1905 (0.1382) loss_oracle 0.2188 (0.2093) acc 87.5000 (83.4766) kd_loss 0.6127 (0.6143) lr 1.8090e-03 eta 0:12:05
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,842
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,920
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 87.9%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [12/50] batch [20/160] time 0.100 (0.115) data 0.000 (0.017) loss 0.8610 (1.0879) ce_loss 0.3325 (0.4293) teacher_loss 0.2801 (0.3869) loss_zs_kd 0.1398 (0.1466) loss_oracle 0.1785 (0.1984) acc 90.6250 (83.7500) kd_loss 0.6070 (0.6279) lr 1.8090e-03 eta 0:11:58
epoch [12/50] batch [40/160] time 0.081 (0.109) data 0.000 (0.008) loss 1.0754 (1.0364) ce_loss 0.4094 (0.4030) teacher_loss 0.3485 (0.3586) loss_zs_kd 0.1352 (0.1464) loss_oracle 0.2499 (0.2016) acc 87.5000 (85.1562) kd_loss 0.7050 (0.6309) lr 1.8090e-03 eta 0:11:15
epoch [12/50] batch [60/160] time 0.069 (0.107) data 0.001 (0.006) loss 1.2837 (1.1025) ce_loss 0.4695 (0.4311) teacher_loss 0.4591 (0.3812) loss_zs_kd 0.1741 (0.1538) loss_oracle 0.2680 (0.2132) acc 78.1250 (84.2708) kd_loss 0.6611 (0.6288) lr 1.8090e-03 eta 0:11:01
epoch [12/50] batch [80/160] time 0.128 (0.106) data 0.000 (0.004) loss 0.9370 (1.1343) ce_loss 0.3354 (0.4398) teacher_loss 0.2966 (0.3944) loss_zs_kd 0.1626 (0.1521) loss_oracle 0.2237 (0.2241) acc 84.3750 (83.8281) kd_loss 0.6523 (0.6343) lr 1.8090e-03 eta 0:10:52
epoch [12/50] batch [100/160] time 0.089 (0.106) data 0.000 (0.003) loss 0.9162 (1.1398) ce_loss 0.3401 (0.4434) teacher_loss 0.3301 (0.3964) loss_zs_kd 0.1476 (0.1531) loss_oracle 0.1722 (0.2235) acc 84.3750 (83.6875) kd_loss 0.6245 (0.6353) lr 1.8090e-03 eta 0:10:50
epoch [12/50] batch [120/160] time 0.092 (0.108) data 0.000 (0.003) loss 1.1152 (1.1455) ce_loss 0.4268 (0.4487) teacher_loss 0.3599 (0.3987) loss_zs_kd 0.0912 (0.1501) loss_oracle 0.2830 (0.2230) acc 84.3750 (83.4375) kd_loss 0.7232 (0.6329) lr 1.8090e-03 eta 0:10:58
epoch [12/50] batch [140/160] time 0.118 (0.107) data 0.000 (0.003) loss 0.9851 (1.1495) ce_loss 0.3582 (0.4503) teacher_loss 0.2950 (0.3985) loss_zs_kd 0.1250 (0.1482) loss_oracle 0.2695 (0.2266) acc 87.5000 (83.3929) kd_loss 0.6230 (0.6311) lr 1.8090e-03 eta 0:10:54
epoch [12/50] batch [160/160] time 0.103 (0.105) data 0.000 (0.002) loss 1.3598 (1.1598) ce_loss 0.5347 (0.4514) teacher_loss 0.4412 (0.4000) loss_zs_kd 0.1349 (0.1498) loss_oracle 0.3165 (0.2335) acc 81.2500 (83.2617) kd_loss 0.6219 (0.6314) lr 1.7705e-03 eta 0:10:41
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,844
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,968
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.0%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [13/50] batch [20/160] time 0.084 (0.111) data 0.000 (0.013) loss 0.7723 (1.2277) ce_loss 0.2417 (0.4605) teacher_loss 0.1993 (0.4129) loss_zs_kd 0.0899 (0.1641) loss_oracle 0.2863 (0.2721) acc 93.7500 (82.8125) kd_loss 0.6196 (0.6324) lr 1.7705e-03 eta 0:11:11
epoch [13/50] batch [40/160] time 0.070 (0.107) data 0.000 (0.007) loss 1.1404 (1.2111) ce_loss 0.4087 (0.4580) teacher_loss 0.4125 (0.4078) loss_zs_kd 0.1202 (0.1597) loss_oracle 0.2591 (0.2654) acc 90.6250 (83.2031) kd_loss 0.6229 (0.6390) lr 1.7705e-03 eta 0:10:45
epoch [13/50] batch [60/160] time 0.092 (0.105) data 0.000 (0.004) loss 1.6179 (1.2151) ce_loss 0.6128 (0.4562) teacher_loss 0.5775 (0.3998) loss_zs_kd 0.1237 (0.1590) loss_oracle 0.3657 (0.2796) acc 81.2500 (83.2812) kd_loss 0.7359 (0.6485) lr 1.7705e-03 eta 0:10:31
epoch [13/50] batch [80/160] time 0.113 (0.105) data 0.000 (0.003) loss 0.9392 (1.2100) ce_loss 0.2974 (0.4559) teacher_loss 0.2862 (0.3955) loss_zs_kd 0.1733 (0.1593) loss_oracle 0.2690 (0.2789) acc 90.6250 (83.2031) kd_loss 0.6730 (0.6488) lr 1.7705e-03 eta 0:10:29
epoch [13/50] batch [100/160] time 0.115 (0.105) data 0.000 (0.003) loss 0.9884 (1.2105) ce_loss 0.2871 (0.4559) teacher_loss 0.2535 (0.3930) loss_zs_kd 0.1266 (0.1630) loss_oracle 0.3844 (0.2802) acc 90.6250 (83.1250) kd_loss 0.7208 (0.6511) lr 1.7705e-03 eta 0:10:25
epoch [13/50] batch [120/160] time 0.076 (0.104) data 0.000 (0.002) loss 0.9361 (1.2109) ce_loss 0.3713 (0.4539) teacher_loss 0.3043 (0.3885) loss_zs_kd 0.1530 (0.1658) loss_oracle 0.1840 (0.2856) acc 84.3750 (83.1510) kd_loss 0.6004 (0.6582) lr 1.7705e-03 eta 0:10:20
epoch [13/50] batch [140/160] time 0.074 (0.103) data 0.000 (0.002) loss 1.0152 (1.2011) ce_loss 0.3823 (0.4484) teacher_loss 0.2656 (0.3796) loss_zs_kd 0.1555 (0.1672) loss_oracle 0.2895 (0.2894) acc 81.2500 (83.3482) kd_loss 0.7382 (0.6643) lr 1.7705e-03 eta 0:10:12
epoch [13/50] batch [160/160] time 0.158 (0.105) data 0.000 (0.002) loss 1.4573 (1.2109) ce_loss 0.6191 (0.4495) teacher_loss 0.5173 (0.3771) loss_zs_kd 0.1539 (0.1689) loss_oracle 0.2439 (0.2998) acc 68.7500 (83.3984) kd_loss 0.6284 (0.6739) lr 1.7290e-03 eta 0:10:21
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,849
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,968
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.0%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [14/50] batch [20/160] time 0.090 (0.111) data 0.000 (0.012) loss 1.0113 (1.2350) ce_loss 0.3718 (0.4435) teacher_loss 0.2344 (0.3404) loss_zs_kd 0.1794 (0.1783) loss_oracle 0.3154 (0.3620) acc 84.3750 (82.8125) kd_loss 0.6835 (0.7476) lr 1.7290e-03 eta 0:10:52
epoch [14/50] batch [40/160] time 0.074 (0.104) data 0.000 (0.006) loss 1.4639 (1.2559) ce_loss 0.5786 (0.4581) teacher_loss 0.4712 (0.3515) loss_zs_kd 0.1950 (0.1787) loss_oracle 0.3166 (0.3570) acc 75.0000 (82.0312) kd_loss 0.7477 (0.7333) lr 1.7290e-03 eta 0:10:08
epoch [14/50] batch [60/160] time 0.105 (0.103) data 0.000 (0.004) loss 0.9552 (1.2232) ce_loss 0.3079 (0.4444) teacher_loss 0.1834 (0.3369) loss_zs_kd 0.1630 (0.1829) loss_oracle 0.3824 (0.3505) acc 87.5000 (82.5000) kd_loss 0.7714 (0.7290) lr 1.7290e-03 eta 0:10:04
epoch [14/50] batch [80/160] time 0.068 (0.102) data 0.000 (0.003) loss 1.6732 (1.2499) ce_loss 0.6660 (0.4615) teacher_loss 0.5701 (0.3522) loss_zs_kd 0.1773 (0.1880) loss_oracle 0.3485 (0.3421) acc 75.0000 (81.8750) kd_loss 0.7816 (0.7290) lr 1.7290e-03 eta 0:09:56
epoch [14/50] batch [100/160] time 0.094 (0.101) data 0.000 (0.003) loss 1.3762 (1.2273) ce_loss 0.4719 (0.4540) teacher_loss 0.3585 (0.3425) loss_zs_kd 0.2209 (0.1908) loss_oracle 0.4353 (0.3354) acc 71.8750 (82.1562) kd_loss 0.8391 (0.7288) lr 1.7290e-03 eta 0:09:49
epoch [14/50] batch [120/160] time 0.112 (0.102) data 0.000 (0.002) loss 1.1704 (1.2300) ce_loss 0.4531 (0.4539) teacher_loss 0.3146 (0.3416) loss_zs_kd 0.2009 (0.1925) loss_oracle 0.3022 (0.3381) acc 81.2500 (82.6302) kd_loss 0.7566 (0.7308) lr 1.7290e-03 eta 0:09:49
epoch [14/50] batch [140/160] time 0.081 (0.102) data 0.000 (0.002) loss 1.1191 (1.2224) ce_loss 0.4377 (0.4506) teacher_loss 0.2940 (0.3389) loss_zs_kd 0.1724 (0.1918) loss_oracle 0.3012 (0.3370) acc 87.5000 (82.7232) kd_loss 0.7163 (0.7310) lr 1.7290e-03 eta 0:09:50
epoch [14/50] batch [160/160] time 0.096 (0.101) data 0.000 (0.002) loss 0.7855 (1.2195) ce_loss 0.2388 (0.4497) teacher_loss 0.1434 (0.3363) loss_zs_kd 0.1447 (0.1939) loss_oracle 0.3309 (0.3366) acc 96.8750 (82.7930) kd_loss 0.7967 (0.7343) lr 1.6845e-03 eta 0:09:39
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,849
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,977
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 89.2%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [15/50] batch [20/160] time 0.078 (0.106) data 0.000 (0.012) loss 0.9121 (1.1775) ce_loss 0.3037 (0.4362) teacher_loss 0.1624 (0.3098) loss_zs_kd 0.2534 (0.1842) loss_oracle 0.3194 (0.3394) acc 93.7500 (82.9688) kd_loss 0.7668 (0.7558) lr 1.6845e-03 eta 0:10:10
epoch [15/50] batch [40/160] time 0.114 (0.102) data 0.000 (0.006) loss 1.1099 (1.2220) ce_loss 0.3652 (0.4488) teacher_loss 0.2293 (0.3250) loss_zs_kd 0.2617 (0.1945) loss_oracle 0.3845 (0.3510) acc 87.5000 (82.8125) kd_loss 0.7245 (0.7573) lr 1.6845e-03 eta 0:09:41
epoch [15/50] batch [60/160] time 0.114 (0.101) data 0.000 (0.004) loss 1.2860 (1.2036) ce_loss 0.4917 (0.4394) teacher_loss 0.3362 (0.3031) loss_zs_kd 0.2769 (0.2096) loss_oracle 0.3197 (0.3563) acc 90.6250 (82.5521) kd_loss 0.6690 (0.7623) lr 1.6845e-03 eta 0:09:35
epoch [15/50] batch [80/160] time 0.132 (0.100) data 0.000 (0.003) loss 1.1954 (1.2070) ce_loss 0.4580 (0.4421) teacher_loss 0.2881 (0.3070) loss_zs_kd 0.1997 (0.2095) loss_oracle 0.3495 (0.3532) acc 78.1250 (82.8516) kd_loss 0.8285 (0.7649) lr 1.6845e-03 eta 0:09:28
epoch [15/50] batch [100/160] time 0.085 (0.100) data 0.000 (0.003) loss 0.9635 (1.1969) ce_loss 0.3528 (0.4387) teacher_loss 0.2192 (0.3030) loss_zs_kd 0.2535 (0.2063) loss_oracle 0.2648 (0.3521) acc 84.3750 (83.3125) kd_loss 0.6795 (0.7642) lr 1.6845e-03 eta 0:09:28
epoch [15/50] batch [120/160] time 0.125 (0.100) data 0.000 (0.002) loss 1.0801 (1.1992) ce_loss 0.3811 (0.4399) teacher_loss 0.2700 (0.3030) loss_zs_kd 0.1943 (0.2103) loss_oracle 0.3318 (0.3511) acc 84.3750 (83.2552) kd_loss 0.7102 (0.7612) lr 1.6845e-03 eta 0:09:26
epoch [15/50] batch [140/160] time 0.122 (0.101) data 0.000 (0.002) loss 1.2156 (1.2047) ce_loss 0.4509 (0.4423) teacher_loss 0.3432 (0.3017) loss_zs_kd 0.2765 (0.2112) loss_oracle 0.2832 (0.3550) acc 84.3750 (83.2366) kd_loss 0.6530 (0.7634) lr 1.6845e-03 eta 0:09:26
epoch [15/50] batch [160/160] time 0.077 (0.099) data 0.000 (0.002) loss 1.3676 (1.2221) ce_loss 0.5298 (0.4521) teacher_loss 0.3918 (0.3103) loss_zs_kd 0.2445 (0.2128) loss_oracle 0.3238 (0.3532) acc 87.5000 (82.9688) kd_loss 0.7651 (0.7613) lr 1.6374e-03 eta 0:09:16
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,850
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,970
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 89.1%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [16/50] batch [20/160] time 0.131 (0.121) data 0.000 (0.014) loss 1.1426 (1.1605) ce_loss 0.4382 (0.4406) teacher_loss 0.3416 (0.3018) loss_zs_kd 0.1772 (0.2093) loss_oracle 0.2742 (0.3134) acc 84.3750 (82.5000) kd_loss 0.7048 (0.7215) lr 1.6374e-03 eta 0:11:16
epoch [16/50] batch [40/160] time 0.095 (0.114) data 0.000 (0.007) loss 0.9450 (1.1607) ce_loss 0.3228 (0.4349) teacher_loss 0.2489 (0.3025) loss_zs_kd 0.1074 (0.1984) loss_oracle 0.3196 (0.3240) acc 87.5000 (83.9844) kd_loss 0.7615 (0.7382) lr 1.6374e-03 eta 0:10:35
epoch [16/50] batch [60/160] time 0.161 (0.115) data 0.000 (0.005) loss 0.9153 (1.1569) ce_loss 0.3264 (0.4294) teacher_loss 0.1464 (0.2943) loss_zs_kd 0.1503 (0.2057) loss_oracle 0.3673 (0.3303) acc 90.6250 (84.2188) kd_loss 0.7951 (0.7465) lr 1.6374e-03 eta 0:10:34
epoch [16/50] batch [80/160] time 0.072 (0.122) data 0.000 (0.004) loss 1.3827 (1.1599) ce_loss 0.4690 (0.4305) teacher_loss 0.4307 (0.2957) loss_zs_kd 0.2022 (0.2065) loss_oracle 0.3819 (0.3305) acc 87.5000 (83.8672) kd_loss 0.7796 (0.7472) lr 1.6374e-03 eta 0:11:12
epoch [16/50] batch [100/160] time 0.155 (0.123) data 0.000 (0.003) loss 1.1323 (1.1830) ce_loss 0.3826 (0.4381) teacher_loss 0.2283 (0.3049) loss_zs_kd 0.2600 (0.2107) loss_oracle 0.3914 (0.3346) acc 78.1250 (83.5938) kd_loss 0.7981 (0.7492) lr 1.6374e-03 eta 0:11:17
epoch [16/50] batch [120/160] time 0.127 (0.120) data 0.000 (0.003) loss 0.9587 (1.1938) ce_loss 0.3765 (0.4438) teacher_loss 0.1805 (0.3114) loss_zs_kd 0.2217 (0.2081) loss_oracle 0.2908 (0.3346) acc 81.2500 (83.0208) kd_loss 0.7360 (0.7490) lr 1.6374e-03 eta 0:10:55
epoch [16/50] batch [140/160] time 0.131 (0.118) data 0.000 (0.002) loss 1.9323 (1.2023) ce_loss 0.8701 (0.4454) teacher_loss 0.5230 (0.3116) loss_zs_kd 0.2127 (0.2082) loss_oracle 0.4328 (0.3412) acc 62.5000 (83.1696) kd_loss 0.9077 (0.7523) lr 1.6374e-03 eta 0:10:43
epoch [16/50] batch [160/160] time 0.097 (0.115) data 0.000 (0.002) loss 0.9612 (1.2116) ce_loss 0.2698 (0.4474) teacher_loss 0.2335 (0.3141) loss_zs_kd 0.1656 (0.2099) loss_oracle 0.3752 (0.3452) acc 90.6250 (83.2031) kd_loss 0.7359 (0.7547) lr 1.5878e-03 eta 0:10:23
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,849
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,962
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 89.0%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [17/50] batch [20/160] time 0.114 (0.126) data 0.000 (0.014) loss 1.1671 (1.1579) ce_loss 0.4517 (0.4176) teacher_loss 0.3230 (0.2915) loss_zs_kd 0.1923 (0.1884) loss_oracle 0.2963 (0.3546) acc 90.6250 (84.5312) kd_loss 0.7638 (0.7505) lr 1.5878e-03 eta 0:11:24
epoch [17/50] batch [40/160] time 0.088 (0.120) data 0.000 (0.007) loss 0.9105 (1.1626) ce_loss 0.3003 (0.4192) teacher_loss 0.1495 (0.2904) loss_zs_kd 0.1778 (0.1943) loss_oracle 0.3718 (0.3558) acc 90.6250 (83.8281) kd_loss 0.7249 (0.7521) lr 1.5878e-03 eta 0:10:46
epoch [17/50] batch [60/160] time 0.082 (0.116) data 0.000 (0.005) loss 1.0283 (1.1881) ce_loss 0.3264 (0.4260) teacher_loss 0.1827 (0.2991) loss_zs_kd 0.2429 (0.1956) loss_oracle 0.3978 (0.3652) acc 90.6250 (83.8542) kd_loss 0.7684 (0.7605) lr 1.5878e-03 eta 0:10:24
epoch [17/50] batch [80/160] time 0.109 (0.115) data 0.000 (0.004) loss 1.5798 (1.2068) ce_loss 0.6602 (0.4371) teacher_loss 0.5132 (0.3012) loss_zs_kd 0.2181 (0.2030) loss_oracle 0.2974 (0.3670) acc 71.8750 (83.5547) kd_loss 0.6605 (0.7618) lr 1.5878e-03 eta 0:10:16
epoch [17/50] batch [100/160] time 0.134 (0.114) data 0.000 (0.003) loss 1.4334 (1.2068) ce_loss 0.5229 (0.4373) teacher_loss 0.4181 (0.2953) loss_zs_kd 0.2294 (0.2113) loss_oracle 0.3777 (0.3685) acc 75.0000 (83.3750) kd_loss 0.7877 (0.7613) lr 1.5878e-03 eta 0:10:10
epoch [17/50] batch [120/160] time 0.141 (0.113) data 0.000 (0.003) loss 1.6929 (1.2141) ce_loss 0.6475 (0.4409) teacher_loss 0.4524 (0.3000) loss_zs_kd 0.2362 (0.2122) loss_oracle 0.4749 (0.3671) acc 78.1250 (83.3594) kd_loss 0.7134 (0.7625) lr 1.5878e-03 eta 0:10:00
epoch [17/50] batch [140/160] time 0.097 (0.112) data 0.000 (0.002) loss 1.2324 (1.2274) ce_loss 0.4417 (0.4473) teacher_loss 0.2963 (0.3040) loss_zs_kd 0.2442 (0.2145) loss_oracle 0.3724 (0.3688) acc 78.1250 (83.3929) kd_loss 0.8201 (0.7647) lr 1.5878e-03 eta 0:09:51
epoch [17/50] batch [160/160] time 0.071 (0.109) data 0.000 (0.002) loss 1.4925 (1.2261) ce_loss 0.5532 (0.4460) teacher_loss 0.4496 (0.3025) loss_zs_kd 0.1943 (0.2157) loss_oracle 0.3926 (0.3698) acc 81.2500 (83.6914) kd_loss 0.7679 (0.7661) lr 1.5358e-03 eta 0:09:33
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,856
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,929
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 88.2%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [18/50] batch [20/160] time 0.099 (0.106) data 0.000 (0.013) loss 1.3123 (1.3248) ce_loss 0.5347 (0.4971) teacher_loss 0.4083 (0.3414) loss_zs_kd 0.2291 (0.2269) loss_oracle 0.2548 (0.3728) acc 71.8750 (80.1562) kd_loss 0.7069 (0.7833) lr 1.5358e-03 eta 0:09:18
epoch [18/50] batch [40/160] time 0.076 (0.103) data 0.000 (0.006) loss 1.4344 (1.2294) ce_loss 0.4844 (0.4469) teacher_loss 0.2994 (0.3016) loss_zs_kd 0.2597 (0.2300) loss_oracle 0.5208 (0.3659) acc 90.6250 (82.6562) kd_loss 0.9435 (0.7744) lr 1.5358e-03 eta 0:08:59
epoch [18/50] batch [60/160] time 0.118 (0.102) data 0.000 (0.004) loss 1.5403 (1.2088) ce_loss 0.5947 (0.4333) teacher_loss 0.4527 (0.2944) loss_zs_kd 0.2014 (0.2210) loss_oracle 0.3921 (0.3706) acc 81.2500 (83.6979) kd_loss 0.7639 (0.7783) lr 1.5358e-03 eta 0:08:54
epoch [18/50] batch [80/160] time 0.108 (0.104) data 0.000 (0.003) loss 1.1219 (1.2010) ce_loss 0.3428 (0.4304) teacher_loss 0.2507 (0.2930) loss_zs_kd 0.2884 (0.2179) loss_oracle 0.3842 (0.3687) acc 87.5000 (83.9062) kd_loss 0.7608 (0.7770) lr 1.5358e-03 eta 0:09:00
epoch [18/50] batch [100/160] time 0.124 (0.103) data 0.000 (0.003) loss 1.8890 (1.2123) ce_loss 0.7588 (0.4329) teacher_loss 0.6293 (0.2986) loss_zs_kd 0.1885 (0.2179) loss_oracle 0.4066 (0.3717) acc 78.1250 (83.6875) kd_loss 0.7815 (0.7827) lr 1.5358e-03 eta 0:08:53
epoch [18/50] batch [120/160] time 0.111 (0.103) data 0.000 (0.002) loss 1.2956 (1.2283) ce_loss 0.4280 (0.4403) teacher_loss 0.2673 (0.3040) loss_zs_kd 0.2506 (0.2162) loss_oracle 0.4750 (0.3759) acc 90.6250 (83.5417) kd_loss 0.9068 (0.7867) lr 1.5358e-03 eta 0:08:53
epoch [18/50] batch [140/160] time 0.131 (0.103) data 0.000 (0.002) loss 1.7379 (1.2244) ce_loss 0.6763 (0.4372) teacher_loss 0.5008 (0.3010) loss_zs_kd 0.2247 (0.2152) loss_oracle 0.4484 (0.3786) acc 71.8750 (83.6830) kd_loss 0.8094 (0.7917) lr 1.5358e-03 eta 0:08:51
epoch [18/50] batch [160/160] time 0.106 (0.102) data 0.000 (0.002) loss 1.9167 (1.2230) ce_loss 0.7710 (0.4374) teacher_loss 0.5801 (0.2974) loss_zs_kd 0.2630 (0.2168) loss_oracle 0.4341 (0.3797) acc 71.8750 (83.6719) kd_loss 0.8526 (0.7952) lr 1.4818e-03 eta 0:08:42
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,856
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,932
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 88.2%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [19/50] batch [20/160] time 0.116 (0.111) data 0.000 (0.014) loss 1.1411 (1.1884) ce_loss 0.4065 (0.4193) teacher_loss 0.2388 (0.2683) loss_zs_kd 0.2205 (0.2130) loss_oracle 0.3855 (0.3943) acc 84.3750 (84.6875) kd_loss 0.7860 (0.7891) lr 1.4818e-03 eta 0:09:27
epoch [19/50] batch [40/160] time 0.131 (0.108) data 0.000 (0.007) loss 1.4905 (1.2353) ce_loss 0.5752 (0.4384) teacher_loss 0.3729 (0.2818) loss_zs_kd 0.2859 (0.2271) loss_oracle 0.3995 (0.4016) acc 78.1250 (84.2188) kd_loss 0.7600 (0.7942) lr 1.4818e-03 eta 0:09:09
epoch [19/50] batch [60/160] time 0.082 (0.106) data 0.000 (0.005) loss 1.0120 (1.2483) ce_loss 0.3269 (0.4466) teacher_loss 0.1883 (0.2834) loss_zs_kd 0.1894 (0.2290) loss_oracle 0.4021 (0.4037) acc 84.3750 (83.2292) kd_loss 0.7778 (0.7962) lr 1.4818e-03 eta 0:08:55
epoch [19/50] batch [80/160] time 0.079 (0.105) data 0.000 (0.004) loss 1.5667 (1.2418) ce_loss 0.6260 (0.4405) teacher_loss 0.4364 (0.2804) loss_zs_kd 0.2191 (0.2319) loss_oracle 0.3948 (0.4049) acc 84.3750 (83.6719) kd_loss 0.7424 (0.7967) lr 1.4818e-03 eta 0:08:50
epoch [19/50] batch [100/160] time 0.125 (0.105) data 0.000 (0.003) loss 1.1744 (1.2724) ce_loss 0.4402 (0.4565) teacher_loss 0.2366 (0.2921) loss_zs_kd 0.2900 (0.2306) loss_oracle 0.3526 (0.4085) acc 78.1250 (82.9062) kd_loss 0.7533 (0.8012) lr 1.4818e-03 eta 0:08:45
epoch [19/50] batch [120/160] time 0.088 (0.105) data 0.001 (0.002) loss 1.7596 (1.2663) ce_loss 0.6089 (0.4515) teacher_loss 0.4656 (0.2917) loss_zs_kd 0.3714 (0.2308) loss_oracle 0.4994 (0.4077) acc 78.1250 (83.0469) kd_loss 0.9702 (0.8066) lr 1.4818e-03 eta 0:08:45
epoch [19/50] batch [140/160] time 0.128 (0.106) data 0.000 (0.002) loss 1.0741 (1.2624) ce_loss 0.3765 (0.4517) teacher_loss 0.1768 (0.2935) loss_zs_kd 0.1838 (0.2248) loss_oracle 0.4289 (0.4047) acc 84.3750 (83.1027) kd_loss 0.8635 (0.8014) lr 1.4818e-03 eta 0:08:48
epoch [19/50] batch [160/160] time 0.107 (0.105) data 0.000 (0.002) loss 1.2248 (1.2558) ce_loss 0.4485 (0.4493) teacher_loss 0.2888 (0.2901) loss_zs_kd 0.2566 (0.2267) loss_oracle 0.3592 (0.4031) acc 84.3750 (83.2422) kd_loss 0.7790 (0.8002) lr 1.4258e-03 eta 0:08:39
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,851
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,939
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 88.4%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [20/50] batch [20/160] time 0.105 (0.113) data 0.000 (0.017) loss 1.3070 (1.2597) ce_loss 0.5195 (0.4580) teacher_loss 0.2394 (0.2842) loss_zs_kd 0.2290 (0.2257) loss_oracle 0.4336 (0.4047) acc 75.0000 (81.2500) kd_loss 0.8701 (0.7941) lr 1.4258e-03 eta 0:09:17
epoch [20/50] batch [40/160] time 0.111 (0.105) data 0.000 (0.009) loss 1.5795 (1.2466) ce_loss 0.6011 (0.4495) teacher_loss 0.4939 (0.2927) loss_zs_kd 0.1955 (0.2226) loss_oracle 0.3868 (0.3930) acc 75.0000 (82.1875) kd_loss 0.7566 (0.7947) lr 1.4258e-03 eta 0:08:35
epoch [20/50] batch [60/160] time 0.075 (0.102) data 0.000 (0.006) loss 1.0662 (1.2387) ce_loss 0.3958 (0.4436) teacher_loss 0.2047 (0.2951) loss_zs_kd 0.2009 (0.2176) loss_oracle 0.3653 (0.3912) acc 75.0000 (82.7083) kd_loss 0.7873 (0.7966) lr 1.4258e-03 eta 0:08:19
epoch [20/50] batch [80/160] time 0.078 (0.101) data 0.000 (0.004) loss 1.4809 (1.2494) ce_loss 0.4990 (0.4519) teacher_loss 0.3675 (0.3045) loss_zs_kd 0.1989 (0.2157) loss_oracle 0.5149 (0.3851) acc 87.5000 (82.8125) kd_loss 0.9653 (0.7941) lr 1.4258e-03 eta 0:08:12
epoch [20/50] batch [100/160] time 0.110 (0.101) data 0.000 (0.004) loss 1.1148 (1.2480) ce_loss 0.3867 (0.4511) teacher_loss 0.2871 (0.3030) loss_zs_kd 0.1902 (0.2128) loss_oracle 0.3458 (0.3875) acc 87.5000 (82.5000) kd_loss 0.7392 (0.7960) lr 1.4258e-03 eta 0:08:09
epoch [20/50] batch [120/160] time 0.092 (0.100) data 0.000 (0.003) loss 1.1620 (1.2546) ce_loss 0.4121 (0.4550) teacher_loss 0.3034 (0.3083) loss_zs_kd 0.1690 (0.2101) loss_oracle 0.3620 (0.3862) acc 90.6250 (82.5781) kd_loss 0.7176 (0.7963) lr 1.4258e-03 eta 0:08:06
epoch [20/50] batch [140/160] time 0.077 (0.101) data 0.001 (0.003) loss 0.9878 (1.2343) ce_loss 0.3103 (0.4448) teacher_loss 0.1565 (0.2991) loss_zs_kd 0.1739 (0.2106) loss_oracle 0.4341 (0.3851) acc 87.5000 (82.8795) kd_loss 0.8631 (0.7972) lr 1.4258e-03 eta 0:08:08
epoch [20/50] batch [160/160] time 0.074 (0.100) data 0.000 (0.002) loss 1.1014 (1.2364) ce_loss 0.3958 (0.4438) teacher_loss 0.1931 (0.2959) loss_zs_kd 0.1739 (0.2143) loss_oracle 0.4256 (0.3896) acc 84.3750 (82.8906) kd_loss 0.9283 (0.8039) lr 1.3681e-03 eta 0:08:00
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,853
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,913
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.9%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [21/50] batch [20/160] time 0.106 (0.118) data 0.000 (0.014) loss 1.2207 (1.1813) ce_loss 0.3943 (0.4030) teacher_loss 0.2644 (0.2637) loss_zs_kd 0.2492 (0.2200) loss_oracle 0.4374 (0.4046) acc 81.2500 (86.5625) kd_loss 0.7955 (0.8252) lr 1.3681e-03 eta 0:09:24
epoch [21/50] batch [40/160] time 0.131 (0.112) data 0.000 (0.007) loss 0.9428 (1.2246) ce_loss 0.2299 (0.4203) teacher_loss 0.1920 (0.2712) loss_zs_kd 0.2023 (0.2264) loss_oracle 0.4197 (0.4198) acc 93.7500 (84.6094) kd_loss 0.8284 (0.8333) lr 1.3681e-03 eta 0:08:51
epoch [21/50] batch [60/160] time 0.163 (0.113) data 0.001 (0.005) loss 1.0938 (1.2335) ce_loss 0.3682 (0.4313) teacher_loss 0.1528 (0.2706) loss_zs_kd 0.2663 (0.2236) loss_oracle 0.4397 (0.4198) acc 87.5000 (84.2708) kd_loss 0.8409 (0.8406) lr 1.3681e-03 eta 0:08:57
epoch [21/50] batch [80/160] time 0.064 (0.117) data 0.000 (0.004) loss 1.3599 (1.2363) ce_loss 0.4326 (0.4331) teacher_loss 0.2741 (0.2701) loss_zs_kd 0.2316 (0.2237) loss_oracle 0.5374 (0.4212) acc 84.3750 (84.1016) kd_loss 0.9342 (0.8383) lr 1.3681e-03 eta 0:09:11
epoch [21/50] batch [100/160] time 0.151 (0.115) data 0.000 (0.003) loss 1.2282 (1.2382) ce_loss 0.4360 (0.4333) teacher_loss 0.3457 (0.2731) loss_zs_kd 0.2182 (0.2249) loss_oracle 0.3374 (0.4193) acc 87.5000 (84.2188) kd_loss 0.8036 (0.8427) lr 1.3681e-03 eta 0:09:00
epoch [21/50] batch [120/160] time 0.107 (0.114) data 0.000 (0.003) loss 1.0181 (1.2411) ce_loss 0.4021 (0.4349) teacher_loss 0.2452 (0.2729) loss_zs_kd 0.2054 (0.2250) loss_oracle 0.2681 (0.4208) acc 81.2500 (83.9062) kd_loss 0.6825 (0.8472) lr 1.3681e-03 eta 0:08:51
epoch [21/50] batch [140/160] time 0.089 (0.111) data 0.000 (0.002) loss 1.6016 (1.2485) ce_loss 0.5605 (0.4379) teacher_loss 0.5285 (0.2769) loss_zs_kd 0.2667 (0.2256) loss_oracle 0.3791 (0.4209) acc 75.0000 (83.6161) kd_loss 0.8590 (0.8511) lr 1.3681e-03 eta 0:08:35
epoch [21/50] batch [160/160] time 0.071 (0.108) data 0.000 (0.002) loss 1.2869 (1.2558) ce_loss 0.4460 (0.4423) teacher_loss 0.2568 (0.2799) loss_zs_kd 0.2209 (0.2257) loss_oracle 0.4736 (0.4207) acc 84.3750 (83.3594) kd_loss 0.8811 (0.8507) lr 1.3090e-03 eta 0:08:20
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,849
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,937
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 88.4%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [22/50] batch [20/160] time 0.103 (0.118) data 0.000 (0.014) loss 1.2965 (1.3120) ce_loss 0.4312 (0.4532) teacher_loss 0.2276 (0.2812) loss_zs_kd 0.2795 (0.2275) loss_oracle 0.4980 (0.4638) acc 81.2500 (84.0625) kd_loss 0.9649 (0.8889) lr 1.3090e-03 eta 0:09:06
epoch [22/50] batch [40/160] time 0.084 (0.107) data 0.000 (0.007) loss 1.0411 (1.2976) ce_loss 0.3369 (0.4564) teacher_loss 0.2494 (0.2900) loss_zs_kd 0.1630 (0.2224) loss_oracle 0.3733 (0.4401) acc 87.5000 (83.5938) kd_loss 0.8238 (0.8648) lr 1.3090e-03 eta 0:08:10
epoch [22/50] batch [60/160] time 0.084 (0.103) data 0.000 (0.005) loss 0.8032 (1.2915) ce_loss 0.2272 (0.4552) teacher_loss 0.1328 (0.2864) loss_zs_kd 0.1585 (0.2242) loss_oracle 0.3639 (0.4377) acc 90.6250 (83.4375) kd_loss 0.7647 (0.8649) lr 1.3090e-03 eta 0:07:53
epoch [22/50] batch [80/160] time 0.115 (0.102) data 0.000 (0.004) loss 0.9822 (1.2709) ce_loss 0.2805 (0.4474) teacher_loss 0.1300 (0.2743) loss_zs_kd 0.3388 (0.2311) loss_oracle 0.4023 (0.4336) acc 93.7500 (83.6719) kd_loss 0.7936 (0.8624) lr 1.3090e-03 eta 0:07:46
epoch [22/50] batch [100/160] time 0.095 (0.103) data 0.000 (0.003) loss 1.4153 (1.2572) ce_loss 0.5806 (0.4410) teacher_loss 0.3487 (0.2669) loss_zs_kd 0.2130 (0.2315) loss_oracle 0.3795 (0.4336) acc 78.1250 (83.5000) kd_loss 0.8233 (0.8629) lr 1.3090e-03 eta 0:07:46
epoch [22/50] batch [120/160] time 0.127 (0.104) data 0.000 (0.002) loss 1.3022 (1.2575) ce_loss 0.4539 (0.4402) teacher_loss 0.3320 (0.2688) loss_zs_kd 0.1973 (0.2313) loss_oracle 0.4177 (0.4328) acc 90.6250 (83.6719) kd_loss 0.8417 (0.8603) lr 1.3090e-03 eta 0:07:52
epoch [22/50] batch [140/160] time 0.118 (0.105) data 0.000 (0.002) loss 1.0888 (1.2500) ce_loss 0.3125 (0.4364) teacher_loss 0.1330 (0.2646) loss_zs_kd 0.2575 (0.2293) loss_oracle 0.5146 (0.4344) acc 84.3750 (83.7946) kd_loss 0.9247 (0.8623) lr 1.3090e-03 eta 0:07:54
epoch [22/50] batch [160/160] time 0.116 (0.105) data 0.000 (0.002) loss 1.3538 (1.2504) ce_loss 0.4827 (0.4368) teacher_loss 0.3364 (0.2639) loss_zs_kd 0.2197 (0.2322) loss_oracle 0.4249 (0.4335) acc 78.1250 (83.5156) kd_loss 0.7760 (0.8580) lr 1.2487e-03 eta 0:07:49
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,854
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,960
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.9%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [23/50] batch [20/160] time 0.105 (0.111) data 0.000 (0.014) loss 1.3985 (1.2457) ce_loss 0.4175 (0.4195) teacher_loss 0.3272 (0.2640) loss_zs_kd 0.3630 (0.2199) loss_oracle 0.4723 (0.4522) acc 84.3750 (83.7500) kd_loss 0.7616 (0.8814) lr 1.2487e-03 eta 0:08:14
epoch [23/50] batch [40/160] time 0.075 (0.107) data 0.000 (0.007) loss 1.2577 (1.2301) ce_loss 0.4233 (0.4246) teacher_loss 0.2885 (0.2706) loss_zs_kd 0.2905 (0.2259) loss_oracle 0.4006 (0.4219) acc 84.3750 (84.2969) kd_loss 0.8562 (0.8496) lr 1.2487e-03 eta 0:07:56
epoch [23/50] batch [60/160] time 0.133 (0.104) data 0.001 (0.005) loss 1.6118 (1.2785) ce_loss 0.6787 (0.4473) teacher_loss 0.5793 (0.2958) loss_zs_kd 0.1764 (0.2289) loss_oracle 0.2656 (0.4210) acc 71.8750 (83.8021) kd_loss 0.6894 (0.8405) lr 1.2487e-03 eta 0:07:41
epoch [23/50] batch [80/160] time 0.117 (0.104) data 0.000 (0.004) loss 1.4035 (1.2407) ce_loss 0.5146 (0.4344) teacher_loss 0.3379 (0.2814) loss_zs_kd 0.2531 (0.2178) loss_oracle 0.4244 (0.4160) acc 84.3750 (84.5703) kd_loss 0.8606 (0.8353) lr 1.2487e-03 eta 0:07:36
epoch [23/50] batch [100/160] time 0.105 (0.103) data 0.000 (0.003) loss 1.0491 (1.2548) ce_loss 0.3933 (0.4426) teacher_loss 0.1460 (0.2837) loss_zs_kd 0.2467 (0.2209) loss_oracle 0.3865 (0.4180) acc 84.3750 (84.1250) kd_loss 0.8353 (0.8344) lr 1.2487e-03 eta 0:07:31
epoch [23/50] batch [120/160] time 0.082 (0.102) data 0.000 (0.003) loss 0.9643 (1.2625) ce_loss 0.2805 (0.4453) teacher_loss 0.1415 (0.2850) loss_zs_kd 0.1669 (0.2263) loss_oracle 0.4587 (0.4190) acc 93.7500 (83.9323) kd_loss 0.9017 (0.8336) lr 1.2487e-03 eta 0:07:25
epoch [23/50] batch [140/160] time 0.128 (0.102) data 0.000 (0.002) loss 1.2351 (1.2610) ce_loss 0.4470 (0.4441) teacher_loss 0.2283 (0.2819) loss_zs_kd 0.2636 (0.2292) loss_oracle 0.4280 (0.4204) acc 84.3750 (83.9732) kd_loss 0.8214 (0.8328) lr 1.2487e-03 eta 0:07:22
epoch [23/50] batch [160/160] time 0.074 (0.100) data 0.000 (0.002) loss 1.2464 (1.2569) ce_loss 0.4551 (0.4416) teacher_loss 0.2965 (0.2787) loss_zs_kd 0.2204 (0.2301) loss_oracle 0.3847 (0.4215) acc 78.1250 (83.9844) kd_loss 0.8082 (0.8330) lr 1.1874e-03 eta 0:07:12
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,854
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,934
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.4%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [24/50] batch [20/160] time 0.127 (0.129) data 0.000 (0.013) loss 1.5564 (1.2708) ce_loss 0.5820 (0.4544) teacher_loss 0.5221 (0.2918) loss_zs_kd 0.1493 (0.2271) loss_oracle 0.3776 (0.4111) acc 78.1250 (83.4375) kd_loss 0.7096 (0.8315) lr 1.1874e-03 eta 0:09:13
epoch [24/50] batch [40/160] time 0.077 (0.115) data 0.000 (0.007) loss 1.2151 (1.2541) ce_loss 0.4690 (0.4483) teacher_loss 0.1797 (0.2762) loss_zs_kd 0.2275 (0.2275) loss_oracle 0.4526 (0.4159) acc 78.1250 (83.3594) kd_loss 0.8739 (0.8294) lr 1.1874e-03 eta 0:08:10
epoch [24/50] batch [60/160] time 0.084 (0.111) data 0.000 (0.005) loss 1.5168 (1.2468) ce_loss 0.5737 (0.4428) teacher_loss 0.4798 (0.2762) loss_zs_kd 0.1938 (0.2212) loss_oracle 0.3664 (0.4172) acc 87.5000 (83.3854) kd_loss 0.7351 (0.8298) lr 1.1874e-03 eta 0:07:52
epoch [24/50] batch [80/160] time 0.072 (0.109) data 0.000 (0.004) loss 1.6451 (1.2449) ce_loss 0.6499 (0.4410) teacher_loss 0.4077 (0.2756) loss_zs_kd 0.2152 (0.2159) loss_oracle 0.4798 (0.4204) acc 68.7500 (83.3594) kd_loss 0.9230 (0.8341) lr 1.1874e-03 eta 0:07:42
epoch [24/50] batch [100/160] time 0.132 (0.108) data 0.000 (0.003) loss 1.2352 (1.2532) ce_loss 0.4185 (0.4420) teacher_loss 0.2383 (0.2716) loss_zs_kd 0.3265 (0.2234) loss_oracle 0.4152 (0.4279) acc 81.2500 (83.2812) kd_loss 0.7831 (0.8435) lr 1.1874e-03 eta 0:07:34
epoch [24/50] batch [120/160] time 0.078 (0.107) data 0.000 (0.002) loss 1.6329 (1.2617) ce_loss 0.5659 (0.4427) teacher_loss 0.4802 (0.2698) loss_zs_kd 0.2444 (0.2271) loss_oracle 0.4645 (0.4357) acc 84.3750 (83.2031) kd_loss 0.9308 (0.8515) lr 1.1874e-03 eta 0:07:31
epoch [24/50] batch [140/160] time 0.112 (0.108) data 0.000 (0.002) loss 1.5317 (1.2655) ce_loss 0.6221 (0.4443) teacher_loss 0.3996 (0.2686) loss_zs_kd 0.1945 (0.2301) loss_oracle 0.4128 (0.4376) acc 78.1250 (82.9688) kd_loss 0.8414 (0.8567) lr 1.1874e-03 eta 0:07:29
epoch [24/50] batch [160/160] time 0.095 (0.105) data 0.000 (0.002) loss 1.2021 (1.2589) ce_loss 0.4204 (0.4404) teacher_loss 0.3413 (0.2668) loss_zs_kd 0.2304 (0.2329) loss_oracle 0.3252 (0.4353) acc 81.2500 (83.2227) kd_loss 0.7665 (0.8537) lr 1.1253e-03 eta 0:07:18
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,855
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,930
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 88.2%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [25/50] batch [20/160] time 0.089 (0.117) data 0.000 (0.013) loss 1.4867 (1.1896) ce_loss 0.5137 (0.4146) teacher_loss 0.3465 (0.2408) loss_zs_kd 0.2293 (0.2410) loss_oracle 0.5119 (0.4138) acc 84.3750 (83.7500) kd_loss 0.9044 (0.8019) lr 1.1253e-03 eta 0:08:06
epoch [25/50] batch [40/160] time 0.077 (0.111) data 0.000 (0.006) loss 1.0851 (1.2254) ce_loss 0.3596 (0.4212) teacher_loss 0.2032 (0.2604) loss_zs_kd 0.1908 (0.2334) loss_oracle 0.4269 (0.4271) acc 87.5000 (83.9062) kd_loss 0.8095 (0.8182) lr 1.1253e-03 eta 0:07:37
epoch [25/50] batch [60/160] time 0.077 (0.109) data 0.000 (0.004) loss 0.9998 (1.2331) ce_loss 0.2524 (0.4242) teacher_loss 0.1341 (0.2588) loss_zs_kd 0.2061 (0.2378) loss_oracle 0.5101 (0.4312) acc 93.7500 (83.8021) kd_loss 0.8805 (0.8237) lr 1.1253e-03 eta 0:07:26
epoch [25/50] batch [80/160] time 0.105 (0.107) data 0.000 (0.003) loss 1.0954 (1.2059) ce_loss 0.3174 (0.4093) teacher_loss 0.2043 (0.2464) loss_zs_kd 0.2617 (0.2373) loss_oracle 0.4428 (0.4316) acc 84.3750 (84.4531) kd_loss 0.9002 (0.8259) lr 1.1253e-03 eta 0:07:17
epoch [25/50] batch [100/160] time 0.079 (0.107) data 0.000 (0.003) loss 1.2629 (1.2276) ce_loss 0.4399 (0.4250) teacher_loss 0.2662 (0.2587) loss_zs_kd 0.1881 (0.2375) loss_oracle 0.4627 (0.4251) acc 84.3750 (83.8438) kd_loss 0.8850 (0.8207) lr 1.1253e-03 eta 0:07:13
epoch [25/50] batch [120/160] time 0.080 (0.107) data 0.000 (0.002) loss 1.3311 (1.2499) ce_loss 0.5234 (0.4369) teacher_loss 0.3831 (0.2649) loss_zs_kd 0.2386 (0.2420) loss_oracle 0.3053 (0.4270) acc 84.3750 (83.2292) kd_loss 0.6874 (0.8194) lr 1.1253e-03 eta 0:07:13
epoch [25/50] batch [140/160] time 0.091 (0.108) data 0.000 (0.002) loss 1.1352 (1.2542) ce_loss 0.3831 (0.4388) teacher_loss 0.2860 (0.2685) loss_zs_kd 0.1241 (0.2381) loss_oracle 0.4040 (0.4279) acc 75.0000 (83.1027) kd_loss 0.8336 (0.8220) lr 1.1253e-03 eta 0:07:13
epoch [25/50] batch [160/160] time 0.103 (0.106) data 0.000 (0.002) loss 1.1673 (1.2513) ce_loss 0.4429 (0.4382) teacher_loss 0.2050 (0.2689) loss_zs_kd 0.2507 (0.2370) loss_oracle 0.3940 (0.4257) acc 75.0000 (82.9883) kd_loss 0.7974 (0.8213) lr 1.0628e-03 eta 0:07:04
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,855
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,936
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 88.4%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [26/50] batch [20/160] time 0.113 (0.112) data 0.000 (0.012) loss 1.1177 (1.2825) ce_loss 0.3975 (0.4570) teacher_loss 0.1602 (0.2730) loss_zs_kd 0.2926 (0.2447) loss_oracle 0.4138 (0.4301) acc 87.5000 (81.8750) kd_loss 0.8353 (0.8206) lr 1.0628e-03 eta 0:07:26
epoch [26/50] batch [40/160] time 0.082 (0.107) data 0.000 (0.006) loss 1.4545 (1.2741) ce_loss 0.5420 (0.4609) teacher_loss 0.3179 (0.2757) loss_zs_kd 0.2496 (0.2427) loss_oracle 0.4698 (0.4162) acc 81.2500 (81.7969) kd_loss 0.9291 (0.8131) lr 1.0628e-03 eta 0:07:04
epoch [26/50] batch [60/160] time 0.093 (0.104) data 0.000 (0.004) loss 0.9656 (1.2686) ce_loss 0.3545 (0.4594) teacher_loss 0.1738 (0.2821) loss_zs_kd 0.2105 (0.2362) loss_oracle 0.3321 (0.4090) acc 87.5000 (82.5000) kd_loss 0.7505 (0.8071) lr 1.0628e-03 eta 0:06:51
epoch [26/50] batch [80/160] time 0.110 (0.106) data 0.000 (0.003) loss 1.1569 (1.2480) ce_loss 0.4048 (0.4500) teacher_loss 0.2805 (0.2765) loss_zs_kd 0.3135 (0.2368) loss_oracle 0.3148 (0.4031) acc 81.2500 (82.9688) kd_loss 0.7204 (0.8047) lr 1.0628e-03 eta 0:06:53
epoch [26/50] batch [100/160] time 0.062 (0.108) data 0.000 (0.003) loss 1.0728 (1.2394) ce_loss 0.3328 (0.4445) teacher_loss 0.1898 (0.2725) loss_zs_kd 0.1973 (0.2335) loss_oracle 0.4515 (0.4056) acc 84.3750 (83.3438) kd_loss 0.9162 (0.8047) lr 1.0628e-03 eta 0:07:03
epoch [26/50] batch [120/160] time 0.152 (0.109) data 0.000 (0.002) loss 1.3711 (1.2152) ce_loss 0.5088 (0.4315) teacher_loss 0.3377 (0.2621) loss_zs_kd 0.2906 (0.2372) loss_oracle 0.3793 (0.4031) acc 81.2500 (83.8802) kd_loss 0.7994 (0.8033) lr 1.0628e-03 eta 0:07:03
epoch [26/50] batch [140/160] time 0.113 (0.107) data 0.000 (0.002) loss 1.6688 (1.2228) ce_loss 0.5811 (0.4338) teacher_loss 0.4388 (0.2616) loss_zs_kd 0.2522 (0.2402) loss_oracle 0.5229 (0.4073) acc 78.1250 (83.6161) kd_loss 0.9243 (0.8076) lr 1.0628e-03 eta 0:06:51
epoch [26/50] batch [160/160] time 0.097 (0.104) data 0.000 (0.002) loss 1.2210 (1.2306) ce_loss 0.4414 (0.4359) teacher_loss 0.2216 (0.2637) loss_zs_kd 0.2918 (0.2410) loss_oracle 0.4121 (0.4106) acc 84.3750 (83.4570) kd_loss 0.7620 (0.8104) lr 1.0000e-03 eta 0:06:40
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,858
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,942
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 88.4%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [27/50] batch [20/160] time 0.127 (0.123) data 0.000 (0.014) loss 1.0386 (1.1961) ce_loss 0.2761 (0.4128) teacher_loss 0.1392 (0.2484) loss_zs_kd 0.2811 (0.2290) loss_oracle 0.4828 (0.4204) acc 90.6250 (83.7500) kd_loss 0.8607 (0.8146) lr 1.0000e-03 eta 0:07:48
epoch [27/50] batch [40/160] time 0.097 (0.109) data 0.000 (0.007) loss 1.6078 (1.2175) ce_loss 0.6406 (0.4283) teacher_loss 0.5294 (0.2609) loss_zs_kd 0.2054 (0.2264) loss_oracle 0.3351 (0.4152) acc 75.0000 (83.8281) kd_loss 0.8176 (0.8126) lr 1.0000e-03 eta 0:06:53
epoch [27/50] batch [60/160] time 0.128 (0.104) data 0.000 (0.005) loss 0.8796 (1.2146) ce_loss 0.2615 (0.4309) teacher_loss 0.1114 (0.2608) loss_zs_kd 0.2448 (0.2296) loss_oracle 0.3843 (0.4081) acc 90.6250 (83.2812) kd_loss 0.7946 (0.8088) lr 1.0000e-03 eta 0:06:33
epoch [27/50] batch [80/160] time 0.113 (0.104) data 0.000 (0.004) loss 1.0805 (1.2065) ce_loss 0.3708 (0.4301) teacher_loss 0.2058 (0.2572) loss_zs_kd 0.2296 (0.2294) loss_oracle 0.3890 (0.4045) acc 81.2500 (83.0469) kd_loss 0.7822 (0.8092) lr 1.0000e-03 eta 0:06:32
epoch [27/50] batch [100/160] time 0.100 (0.105) data 0.000 (0.003) loss 1.0218 (1.2174) ce_loss 0.3643 (0.4361) teacher_loss 0.2103 (0.2618) loss_zs_kd 0.2633 (0.2263) loss_oracle 0.3156 (0.4063) acc 87.5000 (83.0938) kd_loss 0.6724 (0.8093) lr 1.0000e-03 eta 0:06:34
epoch [27/50] batch [120/160] time 0.094 (0.106) data 0.000 (0.002) loss 1.0772 (1.2154) ce_loss 0.3518 (0.4351) teacher_loss 0.2240 (0.2625) loss_zs_kd 0.2080 (0.2301) loss_oracle 0.3974 (0.4028) acc 87.5000 (83.3594) kd_loss 0.7575 (0.8056) lr 1.0000e-03 eta 0:06:35
epoch [27/50] batch [140/160] time 0.079 (0.107) data 0.000 (0.002) loss 0.9681 (1.2205) ce_loss 0.3267 (0.4370) teacher_loss 0.1485 (0.2666) loss_zs_kd 0.2642 (0.2301) loss_oracle 0.3608 (0.4019) acc 90.6250 (83.3482) kd_loss 0.7811 (0.8079) lr 1.0000e-03 eta 0:06:35
epoch [27/50] batch [160/160] time 0.094 (0.106) data 0.000 (0.002) loss 1.8737 (1.2195) ce_loss 0.7261 (0.4347) teacher_loss 0.5640 (0.2651) loss_zs_kd 0.2936 (0.2308) loss_oracle 0.4368 (0.4044) acc 75.0000 (83.5352) kd_loss 0.7973 (0.8111) lr 9.3721e-04 eta 0:06:28
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,858
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,935
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.3%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [28/50] batch [20/160] time 0.103 (0.126) data 0.000 (0.015) loss 1.0167 (1.2179) ce_loss 0.3142 (0.4198) teacher_loss 0.2526 (0.2705) loss_zs_kd 0.1735 (0.2367) loss_oracle 0.3631 (0.4093) acc 87.5000 (84.3750) kd_loss 0.7872 (0.8127) lr 9.3721e-04 eta 0:07:41
epoch [28/50] batch [40/160] time 0.088 (0.117) data 0.000 (0.008) loss 1.2574 (1.2268) ce_loss 0.4739 (0.4307) teacher_loss 0.2998 (0.2742) loss_zs_kd 0.2131 (0.2299) loss_oracle 0.3772 (0.4069) acc 81.2500 (83.4375) kd_loss 0.8401 (0.8065) lr 9.3721e-04 eta 0:07:04
epoch [28/50] batch [60/160] time 0.088 (0.113) data 0.000 (0.005) loss 0.9437 (1.2316) ce_loss 0.2373 (0.4318) teacher_loss 0.1186 (0.2649) loss_zs_kd 0.2275 (0.2331) loss_oracle 0.4740 (0.4183) acc 90.6250 (83.5417) kd_loss 0.8280 (0.8184) lr 9.3721e-04 eta 0:06:47
epoch [28/50] batch [80/160] time 0.079 (0.110) data 0.000 (0.004) loss 1.1408 (1.2274) ce_loss 0.3601 (0.4295) teacher_loss 0.2090 (0.2573) loss_zs_kd 0.2736 (0.2361) loss_oracle 0.4349 (0.4225) acc 84.3750 (83.5547) kd_loss 0.7873 (0.8260) lr 9.3721e-04 eta 0:06:37
epoch [28/50] batch [100/160] time 0.136 (0.109) data 0.000 (0.003) loss 1.0750 (1.2290) ce_loss 0.3364 (0.4349) teacher_loss 0.1682 (0.2597) loss_zs_kd 0.2669 (0.2355) loss_oracle 0.4369 (0.4166) acc 78.1250 (83.5312) kd_loss 0.8018 (0.8181) lr 9.3721e-04 eta 0:06:28
epoch [28/50] batch [120/160] time 0.108 (0.108) data 0.000 (0.003) loss 1.1645 (1.2354) ce_loss 0.4282 (0.4368) teacher_loss 0.2104 (0.2632) loss_zs_kd 0.1756 (0.2361) loss_oracle 0.4381 (0.4174) acc 81.2500 (83.5677) kd_loss 0.8343 (0.8209) lr 9.3721e-04 eta 0:06:23
epoch [28/50] batch [140/160] time 0.126 (0.107) data 0.000 (0.002) loss 0.9900 (1.2272) ce_loss 0.3201 (0.4337) teacher_loss 0.1511 (0.2636) loss_zs_kd 0.2712 (0.2355) loss_oracle 0.3832 (0.4122) acc 87.5000 (83.8170) kd_loss 0.7737 (0.8150) lr 9.3721e-04 eta 0:06:20
epoch [28/50] batch [160/160] time 0.100 (0.105) data 0.000 (0.002) loss 1.0372 (1.2327) ce_loss 0.3469 (0.4379) teacher_loss 0.1417 (0.2666) loss_zs_kd 0.2121 (0.2357) loss_oracle 0.4426 (0.4103) acc 81.2500 (83.5547) kd_loss 0.9047 (0.8132) lr 8.7467e-04 eta 0:06:11
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,858
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,953
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 88.7%
******* Domain p best val acc:      84.3%, epoch: 6 *******
******* Domain p best val test acc: 86.8%, epoch: 6 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [29/50] batch [20/160] time 0.075 (0.141) data 0.000 (0.015) loss 1.2523 (1.2541) ce_loss 0.4829 (0.4553) teacher_loss 0.2077 (0.2777) loss_zs_kd 0.3436 (0.2318) loss_oracle 0.3899 (0.4053) acc 84.3750 (82.6562) kd_loss 0.8088 (0.8250) lr 8.7467e-04 eta 0:08:12
epoch [29/50] batch [40/160] time 0.090 (0.119) data 0.000 (0.008) loss 1.1936 (1.2183) ce_loss 0.3845 (0.4306) teacher_loss 0.1996 (0.2510) loss_zs_kd 0.2353 (0.2386) loss_oracle 0.4918 (0.4175) acc 87.5000 (83.9844) kd_loss 0.9132 (0.8246) lr 8.7467e-04 eta 0:06:52
epoch [29/50] batch [60/160] time 0.122 (0.110) data 0.000 (0.005) loss 1.4621 (1.1838) ce_loss 0.5068 (0.4162) teacher_loss 0.2048 (0.2350) loss_zs_kd 0.2661 (0.2394) loss_oracle 0.6174 (0.4129) acc 75.0000 (84.1667) kd_loss 1.0883 (0.8190) lr 8.7467e-04 eta 0:06:22
epoch [29/50] batch [80/160] time 0.136 (0.109) data 0.000 (0.004) loss 0.9604 (1.1935) ce_loss 0.2881 (0.4210) teacher_loss 0.1905 (0.2476) loss_zs_kd 0.1791 (0.2332) loss_oracle 0.3923 (0.4083) acc 90.6250 (84.1016) kd_loss 0.8401 (0.8135) lr 8.7467e-04 eta 0:06:15
epoch [29/50] batch [100/160] time 0.123 (0.108) data 0.001 (0.003) loss 1.3750 (1.2029) ce_loss 0.4927 (0.4250) teacher_loss 0.2493 (0.2547) loss_zs_kd 0.2614 (0.2313) loss_oracle 0.5023 (0.4075) acc 75.0000 (84.0000) kd_loss 0.8935 (0.8115) lr 8.7467e-04 eta 0:06:08
epoch [29/50] batch [120/160] time 0.081 (0.107) data 0.000 (0.003) loss 1.2018 (1.2149) ce_loss 0.4604 (0.4336) teacher_loss 0.2698 (0.2591) loss_zs_kd 0.2791 (0.2335) loss_oracle 0.3320 (0.4054) acc 81.2500 (83.4635) kd_loss 0.7199 (0.8072) lr 8.7467e-04 eta 0:06:02
epoch [29/50] batch [140/160] time 0.130 (0.106) data 0.000 (0.002) loss 1.4584 (1.2288) ce_loss 0.6147 (0.4390) teacher_loss 0.3857 (0.2632) loss_zs_kd 0.2098 (0.2364) loss_oracle 0.3531 (0.4085) acc 75.0000 (83.5938) kd_loss 0.7320 (0.8109) lr 8.7467e-04 eta 0:05:58
epoch [29/50] batch [160/160] time 0.105 (0.104) data 0.000 (0.002) loss 1.2268 (1.2327) ce_loss 0.4338 (0.4407) teacher_loss 0.2679 (0.2656) loss_zs_kd 0.2012 (0.2348) loss_oracle 0.4244 (0.4091) acc 81.2500 (83.5742) kd_loss 0.8330 (0.8112) lr 8.1262e-04 eta 0:05:50
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,865
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 85.9%
Checkpoint saved to icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,936
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 88.4%
******* Domain p best val acc:      84.5%, epoch: 29 *******
******* Domain p best val test acc: 87.0%, epoch: 29 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [30/50] batch [20/160] time 0.082 (0.114) data 0.000 (0.012) loss 1.5020 (1.2584) ce_loss 0.5630 (0.4795) teacher_loss 0.3665 (0.2989) loss_zs_kd 0.2671 (0.2142) loss_oracle 0.4390 (0.3730) acc 78.1250 (82.9688) kd_loss 0.8411 (0.7661) lr 8.1262e-04 eta 0:06:20
epoch [30/50] batch [40/160] time 0.131 (0.104) data 0.000 (0.006) loss 1.2588 (1.2025) ce_loss 0.4963 (0.4381) teacher_loss 0.2998 (0.2709) loss_zs_kd 0.1856 (0.2181) loss_oracle 0.3699 (0.3844) acc 71.8750 (84.1406) kd_loss 0.7787 (0.7859) lr 8.1262e-04 eta 0:05:45
epoch [30/50] batch [60/160] time 0.080 (0.104) data 0.001 (0.004) loss 1.0001 (1.2034) ce_loss 0.3142 (0.4370) teacher_loss 0.1163 (0.2672) loss_zs_kd 0.2048 (0.2199) loss_oracle 0.4672 (0.3892) acc 90.6250 (84.3750) kd_loss 0.8994 (0.7962) lr 8.1262e-04 eta 0:05:44
epoch [30/50] batch [80/160] time 0.134 (0.104) data 0.000 (0.003) loss 1.3456 (1.2250) ce_loss 0.5498 (0.4450) teacher_loss 0.2748 (0.2796) loss_zs_kd 0.2248 (0.2234) loss_oracle 0.4086 (0.3887) acc 78.1250 (83.9844) kd_loss 0.8175 (0.7908) lr 8.1262e-04 eta 0:05:39
epoch [30/50] batch [100/160] time 0.072 (0.104) data 0.000 (0.003) loss 1.2349 (1.2238) ce_loss 0.3967 (0.4399) teacher_loss 0.2060 (0.2738) loss_zs_kd 0.2390 (0.2257) loss_oracle 0.5126 (0.3972) acc 84.3750 (84.0625) kd_loss 0.9744 (0.7989) lr 8.1262e-04 eta 0:05:39
epoch [30/50] batch [120/160] time 0.088 (0.104) data 0.000 (0.002) loss 0.8189 (1.2209) ce_loss 0.2241 (0.4373) teacher_loss 0.1613 (0.2705) loss_zs_kd 0.1694 (0.2283) loss_oracle 0.3488 (0.3991) acc 93.7500 (84.0625) kd_loss 0.7122 (0.7990) lr 8.1262e-04 eta 0:05:36
epoch [30/50] batch [140/160] time 0.070 (0.104) data 0.000 (0.002) loss 1.2094 (1.2212) ce_loss 0.4812 (0.4362) teacher_loss 0.2114 (0.2687) loss_zs_kd 0.2704 (0.2290) loss_oracle 0.3816 (0.4018) acc 84.3750 (84.3304) kd_loss 0.7032 (0.8016) lr 8.1262e-04 eta 0:05:33
epoch [30/50] batch [160/160] time 0.077 (0.102) data 0.000 (0.002) loss 1.5167 (1.2329) ce_loss 0.6416 (0.4402) teacher_loss 0.3776 (0.2722) loss_zs_kd 0.2573 (0.2313) loss_oracle 0.3688 (0.4049) acc 75.0000 (84.0625) kd_loss 0.8161 (0.8050) lr 7.5131e-04 eta 0:05:26
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,859
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,945
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 88.4%
******* Domain p best val acc:      84.5%, epoch: 29 *******
******* Domain p best val test acc: 87.0%, epoch: 29 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [31/50] batch [20/160] time 0.109 (0.119) data 0.000 (0.016) loss 1.7231 (1.2398) ce_loss 0.7061 (0.4471) teacher_loss 0.4711 (0.2741) loss_zs_kd 0.2762 (0.2217) loss_oracle 0.4079 (0.4076) acc 81.2500 (82.9688) kd_loss 0.8453 (0.7981) lr 7.5131e-04 eta 0:06:18
epoch [31/50] batch [40/160] time 0.132 (0.113) data 0.000 (0.008) loss 1.0663 (1.2891) ce_loss 0.3491 (0.4663) teacher_loss 0.1965 (0.2869) loss_zs_kd 0.2488 (0.2430) loss_oracle 0.3963 (0.4144) acc 84.3750 (82.5781) kd_loss 0.7964 (0.8067) lr 7.5131e-04 eta 0:05:57
epoch [31/50] batch [60/160] time 0.076 (0.110) data 0.001 (0.005) loss 1.0904 (1.2486) ce_loss 0.3806 (0.4450) teacher_loss 0.1849 (0.2690) loss_zs_kd 0.2689 (0.2399) loss_oracle 0.3904 (0.4146) acc 84.3750 (83.2292) kd_loss 0.8184 (0.8033) lr 7.5131e-04 eta 0:05:45
epoch [31/50] batch [80/160] time 0.150 (0.117) data 0.000 (0.004) loss 1.1216 (1.2446) ce_loss 0.3450 (0.4416) teacher_loss 0.2060 (0.2627) loss_zs_kd 0.2623 (0.2433) loss_oracle 0.4396 (0.4187) acc 87.5000 (83.3984) kd_loss 0.8109 (0.8065) lr 7.5131e-04 eta 0:06:06
epoch [31/50] batch [100/160] time 0.086 (0.118) data 0.000 (0.003) loss 0.9787 (1.2469) ce_loss 0.2620 (0.4389) teacher_loss 0.1590 (0.2601) loss_zs_kd 0.2001 (0.2475) loss_oracle 0.4577 (0.4241) acc 90.6250 (83.5000) kd_loss 0.8062 (0.8118) lr 7.5131e-04 eta 0:06:05
epoch [31/50] batch [120/160] time 0.104 (0.121) data 0.000 (0.003) loss 1.6490 (1.2568) ce_loss 0.6538 (0.4427) teacher_loss 0.5174 (0.2645) loss_zs_kd 0.2289 (0.2444) loss_oracle 0.3634 (0.4274) acc 81.2500 (83.6719) kd_loss 0.7270 (0.8196) lr 7.5131e-04 eta 0:06:11
epoch [31/50] batch [140/160] time 0.110 (0.117) data 0.000 (0.002) loss 1.1780 (1.2618) ce_loss 0.4006 (0.4434) teacher_loss 0.2236 (0.2685) loss_zs_kd 0.1907 (0.2419) loss_oracle 0.4585 (0.4289) acc 84.3750 (83.3929) kd_loss 0.9474 (0.8195) lr 7.5131e-04 eta 0:05:58
epoch [31/50] batch [160/160] time 0.074 (0.113) data 0.000 (0.002) loss 1.1840 (1.2539) ce_loss 0.2866 (0.4387) teacher_loss 0.1005 (0.2639) loss_zs_kd 0.3973 (0.2432) loss_oracle 0.5983 (0.4298) acc 90.6250 (83.5156) kd_loss 1.0736 (0.8240) lr 6.9098e-04 eta 0:05:44
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,867
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 85.9%
Checkpoint saved to icml/multi-dg/oracle/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,962
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.9%
******* Domain p best val acc:      84.6%, epoch: 31 *******
******* Domain p best val test acc: 87.7%, epoch: 31 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [32/50] batch [20/160] time 0.084 (0.109) data 0.000 (0.014) loss 1.0646 (1.1931) ce_loss 0.3074 (0.4036) teacher_loss 0.1486 (0.2294) loss_zs_kd 0.2053 (0.2326) loss_oracle 0.5059 (0.4438) acc 84.3750 (84.6875) kd_loss 0.8994 (0.8405) lr 6.9098e-04 eta 0:05:28
epoch [32/50] batch [40/160] time 0.146 (0.111) data 0.000 (0.007) loss 1.3676 (1.2842) ce_loss 0.4924 (0.4558) teacher_loss 0.3552 (0.2790) loss_zs_kd 0.2349 (0.2303) loss_oracle 0.4025 (0.4342) acc 78.1250 (82.5000) kd_loss 0.7600 (0.8397) lr 6.9098e-04 eta 0:05:33
epoch [32/50] batch [60/160] time 0.128 (0.112) data 0.000 (0.005) loss 0.9245 (1.2811) ce_loss 0.3262 (0.4551) teacher_loss 0.1687 (0.2743) loss_zs_kd 0.2015 (0.2362) loss_oracle 0.3289 (0.4336) acc 84.3750 (82.5521) kd_loss 0.7875 (0.8385) lr 6.9098e-04 eta 0:05:33
epoch [32/50] batch [80/160] time 0.129 (0.111) data 0.000 (0.004) loss 1.2045 (1.2411) ce_loss 0.3831 (0.4321) teacher_loss 0.1691 (0.2558) loss_zs_kd 0.2659 (0.2364) loss_oracle 0.5194 (0.4350) acc 81.2500 (83.7109) kd_loss 0.9529 (0.8414) lr 6.9098e-04 eta 0:05:29
epoch [32/50] batch [100/160] time 0.098 (0.111) data 0.000 (0.003) loss 0.9983 (1.2492) ce_loss 0.3076 (0.4363) teacher_loss 0.1153 (0.2589) loss_zs_kd 0.2937 (0.2411) loss_oracle 0.4285 (0.4334) acc 87.5000 (83.3125) kd_loss 0.7637 (0.8411) lr 6.9098e-04 eta 0:05:27
epoch [32/50] batch [120/160] time 0.084 (0.112) data 0.000 (0.002) loss 1.4747 (1.2549) ce_loss 0.5259 (0.4372) teacher_loss 0.3759 (0.2623) loss_zs_kd 0.2385 (0.2391) loss_oracle 0.4538 (0.4358) acc 81.2500 (83.6979) kd_loss 0.8395 (0.8429) lr 6.9098e-04 eta 0:05:26
epoch [32/50] batch [140/160] time 0.091 (0.112) data 0.000 (0.002) loss 1.2722 (1.2466) ce_loss 0.4324 (0.4329) teacher_loss 0.2418 (0.2596) loss_zs_kd 0.3100 (0.2386) loss_oracle 0.4430 (0.4348) acc 84.3750 (83.8393) kd_loss 0.7841 (0.8406) lr 6.9098e-04 eta 0:05:26
epoch [32/50] batch [160/160] time 0.130 (0.111) data 0.000 (0.002) loss 1.1525 (1.2532) ce_loss 0.3589 (0.4357) teacher_loss 0.2076 (0.2616) loss_zs_kd 0.3024 (0.2389) loss_oracle 0.4348 (0.4365) acc 81.2500 (83.7305) kd_loss 0.8582 (0.8410) lr 6.3188e-04 eta 0:05:19
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,854
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,938
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 88.3%
******* Domain p best val acc:      84.6%, epoch: 31 *******
******* Domain p best val test acc: 87.7%, epoch: 31 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [33/50] batch [20/160] time 0.102 (0.100) data 0.000 (0.012) loss 1.2534 (1.2486) ce_loss 0.4458 (0.4131) teacher_loss 0.2185 (0.2423) loss_zs_kd 0.2795 (0.2670) loss_oracle 0.4494 (0.4598) acc 84.3750 (84.5312) kd_loss 0.9040 (0.8631) lr 6.3188e-04 eta 0:04:46
epoch [33/50] batch [40/160] time 0.077 (0.094) data 0.000 (0.006) loss 1.3508 (1.2599) ce_loss 0.4995 (0.4278) teacher_loss 0.2787 (0.2549) loss_zs_kd 0.2612 (0.2591) loss_oracle 0.4420 (0.4476) acc 78.1250 (83.1250) kd_loss 0.9134 (0.8559) lr 6.3188e-04 eta 0:04:26
epoch [33/50] batch [60/160] time 0.105 (0.093) data 0.000 (0.004) loss 1.8257 (1.2882) ce_loss 0.6558 (0.4427) teacher_loss 0.6106 (0.2733) loss_zs_kd 0.2320 (0.2498) loss_oracle 0.4434 (0.4473) acc 84.3750 (83.3333) kd_loss 0.8645 (0.8497) lr 6.3188e-04 eta 0:04:20
epoch [33/50] batch [80/160] time 0.081 (0.091) data 0.000 (0.003) loss 1.2085 (1.2655) ce_loss 0.4019 (0.4355) teacher_loss 0.2434 (0.2676) loss_zs_kd 0.2170 (0.2388) loss_oracle 0.4548 (0.4430) acc 84.3750 (83.1250) kd_loss 0.8842 (0.8433) lr 6.3188e-04 eta 0:04:16
epoch [33/50] batch [100/160] time 0.080 (0.093) data 0.000 (0.002) loss 1.1744 (1.2568) ce_loss 0.3586 (0.4318) teacher_loss 0.2528 (0.2664) loss_zs_kd 0.1934 (0.2379) loss_oracle 0.4663 (0.4396) acc 87.5000 (83.4062) kd_loss 0.9220 (0.8450) lr 6.3188e-04 eta 0:04:18
epoch [33/50] batch [120/160] time 0.079 (0.094) data 0.000 (0.002) loss 1.3669 (1.2642) ce_loss 0.4849 (0.4354) teacher_loss 0.2823 (0.2658) loss_zs_kd 0.3627 (0.2406) loss_oracle 0.4184 (0.4427) acc 78.1250 (83.5156) kd_loss 0.8083 (0.8487) lr 6.3188e-04 eta 0:04:20
epoch [33/50] batch [140/160] time 0.088 (0.095) data 0.000 (0.002) loss 1.6591 (1.2627) ce_loss 0.6299 (0.4375) teacher_loss 0.5117 (0.2643) loss_zs_kd 0.2061 (0.2417) loss_oracle 0.4144 (0.4401) acc 84.3750 (83.3929) kd_loss 0.7904 (0.8446) lr 6.3188e-04 eta 0:04:20
epoch [33/50] batch [160/160] time 0.079 (0.095) data 0.000 (0.002) loss 0.8753 (1.2538) ce_loss 0.2424 (0.4341) teacher_loss 0.0998 (0.2618) loss_zs_kd 0.1870 (0.2406) loss_oracle 0.4395 (0.4376) acc 96.8750 (83.5547) kd_loss 0.8635 (0.8408) lr 5.7422e-04 eta 0:04:17
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,855
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,940
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 88.4%
******* Domain p best val acc:      84.6%, epoch: 31 *******
******* Domain p best val test acc: 87.7%, epoch: 31 *******
******* Domain p best test acc:     88.6%, epoch: 4 *******
epoch [34/50] batch [20/160] time 0.140 (0.121) data 0.000 (0.016) loss 0.9421 (1.1981) ce_loss 0.3311 (0.4076) teacher_loss 0.1800 (0.2355) loss_zs_kd 0.2217 (0.2248) loss_oracle 0.3202 (0.4426) acc 93.7500 (83.1250) kd_loss 0.6891 (0.8379) lr 5.7422e-04 eta 0:05:25

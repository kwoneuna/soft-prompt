Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'clipart', 'product']
Target     ['real_world']
# classes  65
# train_x  7,877
# val      3,354
# test     4,357
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/246] time 0.121 (0.163) data 0.000 (0.024) loss 1.6116 (1.4908) ce_loss 1.6035 (1.4867) teacher_loss 1.6048 (1.4867) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0067 (0.0041) acc 59.3750 (60.9375) kd_loss 0.0267 (0.0164) lr 1.0000e-05 eta 0:33:21
epoch [1/50] batch [40/246] time 0.100 (0.133) data 0.000 (0.012) loss 1.0243 (1.4198) ce_loss 1.0205 (1.4159) teacher_loss 1.0216 (1.4160) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0026 (0.0039) acc 75.0000 (62.9688) kd_loss 0.0103 (0.0153) lr 1.0000e-05 eta 0:27:10
epoch [1/50] batch [60/246] time 0.098 (0.123) data 0.000 (0.008) loss 1.1320 (1.4202) ce_loss 1.1299 (1.4168) teacher_loss 1.1296 (1.4168) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0023 (0.0034) acc 78.1250 (63.3333) kd_loss 0.0085 (0.0135) lr 1.0000e-05 eta 0:25:01
epoch [1/50] batch [80/246] time 0.106 (0.117) data 0.000 (0.006) loss 1.9298 (1.4125) ce_loss 1.9297 (1.4095) teacher_loss 1.9280 (1.4095) loss_zs_kd 0.0005 (0.0001) loss_oracle 0.0015 (0.0030) acc 50.0000 (63.5547) kd_loss 0.0056 (0.0117) lr 1.0000e-05 eta 0:23:46
epoch [1/50] batch [100/246] time 0.097 (0.114) data 0.000 (0.005) loss 1.4587 (1.3947) ce_loss 1.4580 (1.3919) teacher_loss 1.4570 (1.3919) loss_zs_kd 0.0010 (0.0002) loss_oracle 0.0012 (0.0027) acc 59.3750 (63.8750) kd_loss 0.0047 (0.0105) lr 1.0000e-05 eta 0:23:06
epoch [1/50] batch [120/246] time 0.098 (0.111) data 0.000 (0.004) loss 1.5107 (1.3953) ce_loss 1.5098 (1.3927) teacher_loss 1.5082 (1.3926) loss_zs_kd 0.0011 (0.0003) loss_oracle 0.0020 (0.0025) acc 59.3750 (64.0365) kd_loss 0.0076 (0.0096) lr 1.0000e-05 eta 0:22:33
epoch [1/50] batch [140/246] time 0.103 (0.110) data 0.000 (0.004) loss 1.7443 (1.3946) ce_loss 1.7441 (1.3921) teacher_loss 1.7432 (1.3921) loss_zs_kd 0.0006 (0.0004) loss_oracle 0.0008 (0.0023) acc 53.1250 (64.1071) kd_loss 0.0028 (0.0089) lr 1.0000e-05 eta 0:22:11
epoch [1/50] batch [160/246] time 0.098 (0.108) data 0.000 (0.003) loss 1.6014 (1.4055) ce_loss 1.6006 (1.4032) teacher_loss 1.6000 (1.4031) loss_zs_kd 0.0011 (0.0005) loss_oracle 0.0009 (0.0021) acc 65.6250 (63.6523) kd_loss 0.0032 (0.0082) lr 1.0000e-05 eta 0:21:54
epoch [1/50] batch [180/246] time 0.108 (0.108) data 0.000 (0.003) loss 1.6169 (1.3990) ce_loss 1.6152 (1.3968) teacher_loss 1.6155 (1.3967) loss_zs_kd 0.0015 (0.0007) loss_oracle 0.0006 (0.0020) acc 56.2500 (63.9931) kd_loss 0.0023 (0.0076) lr 1.0000e-05 eta 0:21:43
epoch [1/50] batch [200/246] time 0.105 (0.107) data 0.000 (0.003) loss 2.1336 (1.3999) ce_loss 2.1289 (1.3977) teacher_loss 2.1300 (1.3977) loss_zs_kd 0.0048 (0.0008) loss_oracle 0.0012 (0.0019) acc 40.6250 (63.8750) kd_loss 0.0042 (0.0072) lr 1.0000e-05 eta 0:21:33
epoch [1/50] batch [220/246] time 0.100 (0.106) data 0.000 (0.002) loss 1.2775 (1.4004) ce_loss 1.2754 (1.3982) teacher_loss 1.2746 (1.3981) loss_zs_kd 0.0036 (0.0010) loss_oracle 0.0011 (0.0018) acc 71.8750 (64.0199) kd_loss 0.0036 (0.0068) lr 1.0000e-05 eta 0:21:22
epoch [1/50] batch [240/246] time 0.102 (0.106) data 0.000 (0.002) loss 1.5878 (1.3991) ce_loss 1.5859 (1.3969) teacher_loss 1.5857 (1.3968) loss_zs_kd 0.0027 (0.0012) loss_oracle 0.0007 (0.0017) acc 59.3750 (63.9714) kd_loss 0.0022 (0.0065) lr 1.0000e-05 eta 0:21:14
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,683
* accuracy: 80.0%
* error: 20.0%
* macro_f1: 78.8%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,891
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 87.8%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      80.0%, epoch: 1 *******
******* Domain r best val test acc: 89.3%, epoch: 1 *******
******* Domain r best test acc:     89.3%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/ana
epoch [2/50] batch [20/246] time 0.103 (0.115) data 0.000 (0.014) loss 1.6802 (1.4779) ce_loss 1.6338 (1.4493) teacher_loss 1.6339 (1.4494) loss_zs_kd 0.0885 (0.0534) loss_oracle 0.0021 (0.0017) acc 68.7500 (64.0625) kd_loss 0.0021 (0.0026) lr 2.0000e-03 eta 0:23:02
epoch [2/50] batch [40/246] time 0.093 (0.106) data 0.000 (0.007) loss 1.5272 (1.4308) ce_loss 1.4873 (1.3899) teacher_loss 1.4873 (1.3899) loss_zs_kd 0.0758 (0.0751) loss_oracle 0.0020 (0.0033) acc 62.5000 (65.2344) kd_loss 0.0026 (0.0026) lr 2.0000e-03 eta 0:21:13
epoch [2/50] batch [60/246] time 0.096 (0.102) data 0.000 (0.005) loss 1.3887 (1.3596) ce_loss 1.3359 (1.3180) teacher_loss 1.3337 (1.3182) loss_zs_kd 0.1040 (0.0765) loss_oracle 0.0030 (0.0031) acc 62.5000 (66.7188) kd_loss 0.0035 (0.0031) lr 2.0000e-03 eta 0:20:24
epoch [2/50] batch [80/246] time 0.089 (0.101) data 0.000 (0.004) loss 1.3436 (1.3297) ce_loss 1.2842 (1.2856) teacher_loss 1.2835 (1.2857) loss_zs_kd 0.1132 (0.0815) loss_oracle 0.0035 (0.0033) acc 62.5000 (67.2266) kd_loss 0.0051 (0.0033) lr 2.0000e-03 eta 0:20:08
epoch [2/50] batch [100/246] time 0.095 (0.100) data 0.000 (0.003) loss 1.1446 (1.3213) ce_loss 1.1123 (1.2756) teacher_loss 1.1117 (1.2756) loss_zs_kd 0.0576 (0.0843) loss_oracle 0.0041 (0.0035) acc 65.6250 (67.0000) kd_loss 0.0028 (0.0034) lr 2.0000e-03 eta 0:19:52
epoch [2/50] batch [120/246] time 0.089 (0.099) data 0.000 (0.003) loss 1.0318 (1.3093) ce_loss 0.9966 (1.2619) teacher_loss 0.9960 (1.2618) loss_zs_kd 0.0621 (0.0876) loss_oracle 0.0048 (0.0037) acc 75.0000 (67.6042) kd_loss 0.0042 (0.0036) lr 2.0000e-03 eta 0:19:37
epoch [2/50] batch [140/246] time 0.089 (0.098) data 0.000 (0.002) loss 1.3490 (1.2995) ce_loss 1.3184 (1.2514) teacher_loss 1.3171 (1.2513) loss_zs_kd 0.0554 (0.0888) loss_oracle 0.0042 (0.0038) acc 71.8750 (67.6562) kd_loss 0.0036 (0.0035) lr 2.0000e-03 eta 0:19:23
epoch [2/50] batch [160/246] time 0.087 (0.097) data 0.000 (0.002) loss 1.0861 (1.2933) ce_loss 1.0352 (1.2448) teacher_loss 1.0354 (1.2446) loss_zs_kd 0.0947 (0.0899) loss_oracle 0.0033 (0.0037) acc 68.7500 (67.7734) kd_loss 0.0029 (0.0035) lr 2.0000e-03 eta 0:19:14
epoch [2/50] batch [180/246] time 0.106 (0.097) data 0.000 (0.002) loss 1.3376 (1.2861) ce_loss 1.2637 (1.2361) teacher_loss 1.2629 (1.2360) loss_zs_kd 0.1328 (0.0925) loss_oracle 0.0083 (0.0039) acc 75.0000 (68.1250) kd_loss 0.0027 (0.0034) lr 2.0000e-03 eta 0:19:07
epoch [2/50] batch [200/246] time 0.088 (0.097) data 0.000 (0.002) loss 1.6696 (1.2896) ce_loss 1.6172 (1.2379) teacher_loss 1.6177 (1.2378) loss_zs_kd 0.0897 (0.0954) loss_oracle 0.0071 (0.0041) acc 53.1250 (68.0469) kd_loss 0.0052 (0.0034) lr 2.0000e-03 eta 0:19:11
epoch [2/50] batch [220/246] time 0.094 (0.097) data 0.000 (0.002) loss 1.3068 (1.2857) ce_loss 1.2188 (1.2331) teacher_loss 1.2198 (1.2330) loss_zs_kd 0.1646 (0.0971) loss_oracle 0.0047 (0.0042) acc 68.7500 (68.1108) kd_loss 0.0026 (0.0034) lr 2.0000e-03 eta 0:19:05
epoch [2/50] batch [240/246] time 0.086 (0.096) data 0.000 (0.001) loss 1.2965 (1.2889) ce_loss 1.1738 (1.2346) teacher_loss 1.1745 (1.2345) loss_zs_kd 0.2301 (0.1002) loss_oracle 0.0070 (0.0043) acc 68.7500 (68.1120) kd_loss 0.0037 (0.0034) lr 2.0000e-03 eta 0:18:58
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,791
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 82.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,944
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.2%, epoch: 2 *******
******* Domain r best val test acc: 90.5%, epoch: 2 *******
******* Domain r best test acc:     90.5%, epoch: 2 *******
epoch [3/50] batch [20/246] time 0.092 (0.113) data 0.000 (0.014) loss 1.4876 (1.2603) ce_loss 1.4443 (1.2023) teacher_loss 1.4397 (1.2021) loss_zs_kd 0.0862 (0.1053) loss_oracle 0.0049 (0.0056) acc 56.2500 (68.9062) kd_loss 0.0047 (0.0044) lr 1.9980e-03 eta 0:22:15
epoch [3/50] batch [40/246] time 0.081 (0.103) data 0.000 (0.007) loss 0.7763 (1.2600) ce_loss 0.7422 (1.1998) teacher_loss 0.7429 (1.1996) loss_zs_kd 0.0593 (0.1105) loss_oracle 0.0038 (0.0052) acc 84.3750 (70.0781) kd_loss 0.0034 (0.0045) lr 1.9980e-03 eta 0:20:13
epoch [3/50] batch [60/246] time 0.099 (0.098) data 0.000 (0.005) loss 1.8396 (1.2699) ce_loss 1.7773 (1.2104) teacher_loss 1.7743 (1.2102) loss_zs_kd 0.1124 (0.1088) loss_oracle 0.0091 (0.0052) acc 46.8750 (69.3229) kd_loss 0.0050 (0.0044) lr 1.9980e-03 eta 0:19:15
epoch [3/50] batch [80/246] time 0.094 (0.098) data 0.000 (0.004) loss 1.8421 (1.2878) ce_loss 1.7705 (1.2243) teacher_loss 1.7705 (1.2240) loss_zs_kd 0.1350 (0.1167) loss_oracle 0.0041 (0.0055) acc 62.5000 (69.2969) kd_loss 0.0032 (0.0043) lr 1.9980e-03 eta 0:19:10
epoch [3/50] batch [100/246] time 0.107 (0.097) data 0.000 (0.003) loss 1.0923 (1.2845) ce_loss 1.0488 (1.2200) teacher_loss 1.0480 (1.2198) loss_zs_kd 0.0706 (0.1177) loss_oracle 0.0090 (0.0058) acc 68.7500 (69.1250) kd_loss 0.0057 (0.0043) lr 1.9980e-03 eta 0:19:01
epoch [3/50] batch [120/246] time 0.096 (0.097) data 0.000 (0.003) loss 1.1845 (1.2729) ce_loss 1.1523 (1.2094) teacher_loss 1.1496 (1.2093) loss_zs_kd 0.0562 (0.1148) loss_oracle 0.0068 (0.0063) acc 78.1250 (69.2969) kd_loss 0.0038 (0.0042) lr 1.9980e-03 eta 0:18:54
epoch [3/50] batch [140/246] time 0.094 (0.097) data 0.000 (0.002) loss 1.5629 (1.2763) ce_loss 1.4990 (1.2131) teacher_loss 1.4960 (1.2130) loss_zs_kd 0.1226 (0.1145) loss_oracle 0.0056 (0.0061) acc 59.3750 (68.9286) kd_loss 0.0056 (0.0043) lr 1.9980e-03 eta 0:18:53
epoch [3/50] batch [160/246] time 0.099 (0.097) data 0.000 (0.002) loss 1.0903 (1.2783) ce_loss 1.0127 (1.2145) teacher_loss 1.0180 (1.2144) loss_zs_kd 0.1242 (0.1151) loss_oracle 0.0102 (0.0064) acc 75.0000 (68.9844) kd_loss 0.0048 (0.0043) lr 1.9980e-03 eta 0:18:52
epoch [3/50] batch [180/246] time 0.092 (0.097) data 0.000 (0.002) loss 1.3118 (1.2697) ce_loss 1.2344 (1.2054) teacher_loss 1.2351 (1.2053) loss_zs_kd 0.1311 (0.1156) loss_oracle 0.0112 (0.0065) acc 71.8750 (68.9062) kd_loss 0.0051 (0.0043) lr 1.9980e-03 eta 0:18:52
epoch [3/50] batch [200/246] time 0.092 (0.097) data 0.000 (0.002) loss 1.1869 (1.2698) ce_loss 1.1299 (1.2043) teacher_loss 1.1333 (1.2043) loss_zs_kd 0.0903 (0.1175) loss_oracle 0.0084 (0.0067) acc 71.8750 (68.7969) kd_loss 0.0036 (0.0044) lr 1.9980e-03 eta 0:18:48
epoch [3/50] batch [220/246] time 0.097 (0.097) data 0.000 (0.001) loss 0.9512 (1.2711) ce_loss 0.8965 (1.2053) teacher_loss 0.8982 (1.2052) loss_zs_kd 0.0937 (0.1180) loss_oracle 0.0061 (0.0069) acc 75.0000 (68.6080) kd_loss 0.0044 (0.0044) lr 1.9980e-03 eta 0:18:43
epoch [3/50] batch [240/246] time 0.086 (0.097) data 0.000 (0.001) loss 0.9383 (1.2664) ce_loss 0.8848 (1.1998) teacher_loss 0.8828 (1.1997) loss_zs_kd 0.0892 (0.1191) loss_oracle 0.0109 (0.0071) acc 75.0000 (68.7760) kd_loss 0.0060 (0.0045) lr 1.9980e-03 eta 0:18:36
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,802
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.6%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.7%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.5%, epoch: 3 *******
******* Domain r best val test acc: 90.9%, epoch: 3 *******
******* Domain r best test acc:     90.9%, epoch: 3 *******
epoch [4/50] batch [20/246] time 0.091 (0.114) data 0.000 (0.014) loss 1.0673 (1.1918) ce_loss 1.0215 (1.1219) teacher_loss 1.0217 (1.1227) loss_zs_kd 0.0767 (0.1199) loss_oracle 0.0073 (0.0091) acc 71.8750 (71.8750) kd_loss 0.0041 (0.0053) lr 1.9921e-03 eta 0:21:51
epoch [4/50] batch [40/246] time 0.089 (0.105) data 0.000 (0.007) loss 1.2036 (1.1709) ce_loss 1.1299 (1.0992) teacher_loss 1.1288 (1.0999) loss_zs_kd 0.1171 (0.1197) loss_oracle 0.0162 (0.0111) acc 75.0000 (71.9531) kd_loss 0.0062 (0.0053) lr 1.9921e-03 eta 0:20:06
epoch [4/50] batch [60/246] time 0.089 (0.100) data 0.000 (0.005) loss 1.3718 (1.1952) ce_loss 1.2998 (1.1201) teacher_loss 1.3000 (1.1204) loss_zs_kd 0.1192 (0.1207) loss_oracle 0.0122 (0.0144) acc 75.0000 (71.4062) kd_loss 0.0063 (0.0060) lr 1.9921e-03 eta 0:19:11
epoch [4/50] batch [80/246] time 0.089 (0.098) data 0.000 (0.004) loss 0.9140 (1.1910) ce_loss 0.8564 (1.1139) teacher_loss 0.8577 (1.1143) loss_zs_kd 0.0868 (0.1257) loss_oracle 0.0129 (0.0138) acc 75.0000 (71.4062) kd_loss 0.0080 (0.0061) lr 1.9921e-03 eta 0:18:44
epoch [4/50] batch [100/246] time 0.088 (0.096) data 0.000 (0.003) loss 1.1877 (1.1971) ce_loss 1.1240 (1.1208) teacher_loss 1.1243 (1.1212) loss_zs_kd 0.1019 (0.1246) loss_oracle 0.0124 (0.0135) acc 62.5000 (71.0000) kd_loss 0.0055 (0.0062) lr 1.9921e-03 eta 0:18:19
epoch [4/50] batch [120/246] time 0.089 (0.095) data 0.000 (0.003) loss 1.6267 (1.2035) ce_loss 1.5439 (1.1266) teacher_loss 1.5427 (1.1270) loss_zs_kd 0.1235 (0.1252) loss_oracle 0.0222 (0.0139) acc 56.2500 (70.4427) kd_loss 0.0113 (0.0066) lr 1.9921e-03 eta 0:18:01
epoch [4/50] batch [140/246] time 0.099 (0.094) data 0.000 (0.002) loss 1.1630 (1.1904) ce_loss 1.0869 (1.1129) teacher_loss 1.0857 (1.1133) loss_zs_kd 0.1110 (0.1246) loss_oracle 0.0219 (0.0148) acc 71.8750 (70.8482) kd_loss 0.0101 (0.0070) lr 1.9921e-03 eta 0:17:58
epoch [4/50] batch [160/246] time 0.098 (0.095) data 0.000 (0.002) loss 1.1924 (1.2097) ce_loss 1.0859 (1.1302) teacher_loss 1.0861 (1.1305) loss_zs_kd 0.1701 (0.1283) loss_oracle 0.0212 (0.0151) acc 71.8750 (70.3125) kd_loss 0.0117 (0.0075) lr 1.9921e-03 eta 0:17:58
epoch [4/50] batch [180/246] time 0.093 (0.095) data 0.000 (0.002) loss 0.9852 (1.2159) ce_loss 0.9258 (1.1363) teacher_loss 0.9265 (1.1364) loss_zs_kd 0.0904 (0.1285) loss_oracle 0.0136 (0.0153) acc 75.0000 (70.0868) kd_loss 0.0118 (0.0080) lr 1.9921e-03 eta 0:17:57
epoch [4/50] batch [200/246] time 0.105 (0.095) data 0.000 (0.002) loss 1.6386 (1.2208) ce_loss 1.5498 (1.1418) teacher_loss 1.5492 (1.1418) loss_zs_kd 0.1604 (0.1281) loss_oracle 0.0092 (0.0149) acc 65.6250 (69.8906) kd_loss 0.0081 (0.0081) lr 1.9921e-03 eta 0:18:01
epoch [4/50] batch [220/246] time 0.095 (0.095) data 0.000 (0.001) loss 0.8362 (1.2128) ce_loss 0.7476 (1.1333) teacher_loss 0.7500 (1.1334) loss_zs_kd 0.1498 (0.1294) loss_oracle 0.0113 (0.0146) acc 78.1250 (70.0710) kd_loss 0.0073 (0.0081) lr 1.9921e-03 eta 0:18:02
epoch [4/50] batch [240/246] time 0.101 (0.096) data 0.000 (0.001) loss 1.2003 (1.2197) ce_loss 1.1436 (1.1399) teacher_loss 1.1412 (1.1399) loss_zs_kd 0.0770 (0.1298) loss_oracle 0.0206 (0.0149) acc 75.0000 (69.9870) kd_loss 0.0094 (0.0082) lr 1.9921e-03 eta 0:18:05
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,811
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.8%, epoch: 4 *******
******* Domain r best val test acc: 90.9%, epoch: 4 *******
******* Domain r best test acc:     90.9%, epoch: 4 *******
epoch [5/50] batch [20/246] time 0.095 (0.123) data 0.000 (0.019) loss 1.1396 (1.1998) ce_loss 1.0635 (1.1239) teacher_loss 1.0602 (1.1240) loss_zs_kd 0.1198 (0.1205) loss_oracle 0.0195 (0.0155) acc 68.7500 (72.0312) kd_loss 0.0088 (0.0094) lr 1.9823e-03 eta 0:23:10
epoch [5/50] batch [40/246] time 0.098 (0.111) data 0.000 (0.010) loss 1.7547 (1.2112) ce_loss 1.6680 (1.1381) teacher_loss 1.6696 (1.1379) loss_zs_kd 0.1443 (0.1162) loss_oracle 0.0129 (0.0152) acc 59.3750 (71.7969) kd_loss 0.0107 (0.0100) lr 1.9823e-03 eta 0:20:56
epoch [5/50] batch [60/246] time 0.096 (0.107) data 0.000 (0.007) loss 0.8437 (1.2159) ce_loss 0.7793 (1.1391) teacher_loss 0.7802 (1.1391) loss_zs_kd 0.1026 (0.1256) loss_oracle 0.0122 (0.0139) acc 78.1250 (70.9375) kd_loss 0.0076 (0.0099) lr 1.9823e-03 eta 0:20:02
epoch [5/50] batch [80/246] time 0.100 (0.104) data 0.000 (0.005) loss 1.1159 (1.2228) ce_loss 1.0547 (1.1477) teacher_loss 1.0504 (1.1476) loss_zs_kd 0.0933 (0.1226) loss_oracle 0.0188 (0.0138) acc 68.7500 (70.2344) kd_loss 0.0096 (0.0097) lr 1.9823e-03 eta 0:19:26
epoch [5/50] batch [100/246] time 0.104 (0.102) data 0.000 (0.004) loss 1.1572 (1.2276) ce_loss 1.0342 (1.1488) teacher_loss 1.0289 (1.1481) loss_zs_kd 0.2007 (0.1280) loss_oracle 0.0279 (0.0155) acc 65.6250 (69.9062) kd_loss 0.0161 (0.0098) lr 1.9823e-03 eta 0:19:04
epoch [5/50] batch [120/246] time 0.091 (0.102) data 0.000 (0.003) loss 0.9121 (1.2442) ce_loss 0.8354 (1.1651) teacher_loss 0.8348 (1.1646) loss_zs_kd 0.1229 (0.1281) loss_oracle 0.0158 (0.0156) acc 75.0000 (69.5573) kd_loss 0.0121 (0.0100) lr 1.9823e-03 eta 0:18:59
epoch [5/50] batch [140/246] time 0.087 (0.100) data 0.000 (0.003) loss 1.7384 (1.2457) ce_loss 1.6348 (1.1679) teacher_loss 1.6330 (1.1672) loss_zs_kd 0.1857 (0.1259) loss_oracle 0.0125 (0.0155) acc 65.6250 (69.6652) kd_loss 0.0072 (0.0100) lr 1.9823e-03 eta 0:18:33
epoch [5/50] batch [160/246] time 0.096 (0.099) data 0.000 (0.003) loss 1.4179 (1.2524) ce_loss 1.3301 (1.1725) teacher_loss 1.3316 (1.1720) loss_zs_kd 0.1124 (0.1282) loss_oracle 0.0301 (0.0163) acc 62.5000 (69.4922) kd_loss 0.0120 (0.0099) lr 1.9823e-03 eta 0:18:20
epoch [5/50] batch [180/246] time 0.090 (0.097) data 0.000 (0.002) loss 1.3338 (1.2505) ce_loss 1.2500 (1.1694) teacher_loss 1.2484 (1.1689) loss_zs_kd 0.1190 (0.1280) loss_oracle 0.0259 (0.0177) acc 65.6250 (69.4097) kd_loss 0.0095 (0.0101) lr 1.9823e-03 eta 0:18:04
epoch [5/50] batch [200/246] time 0.096 (0.097) data 0.000 (0.002) loss 1.2522 (1.2574) ce_loss 1.1299 (1.1755) teacher_loss 1.1194 (1.1749) loss_zs_kd 0.2061 (0.1287) loss_oracle 0.0298 (0.0182) acc 71.8750 (69.1562) kd_loss 0.0176 (0.0103) lr 1.9823e-03 eta 0:17:54
epoch [5/50] batch [220/246] time 0.095 (0.096) data 0.000 (0.002) loss 1.5827 (1.2521) ce_loss 1.4961 (1.1691) teacher_loss 1.4958 (1.1685) loss_zs_kd 0.1047 (0.1291) loss_oracle 0.0346 (0.0190) acc 62.5000 (69.1193) kd_loss 0.0118 (0.0105) lr 1.9823e-03 eta 0:17:45
epoch [5/50] batch [240/246] time 0.085 (0.095) data 0.000 (0.002) loss 1.2262 (1.2511) ce_loss 1.1514 (1.1676) teacher_loss 1.1513 (1.1670) loss_zs_kd 0.0964 (0.1286) loss_oracle 0.0267 (0.0197) acc 71.8750 (69.1146) kd_loss 0.0154 (0.0107) lr 1.9823e-03 eta 0:17:36
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,809
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      83.8%, epoch: 4 *******
******* Domain r best val test acc: 90.9%, epoch: 4 *******
******* Domain r best test acc:     90.9%, epoch: 4 *******
epoch [6/50] batch [20/246] time 0.091 (0.110) data 0.000 (0.014) loss 1.1538 (1.2666) ce_loss 1.0654 (1.1746) teacher_loss 1.0651 (1.1737) loss_zs_kd 0.1411 (0.1463) loss_oracle 0.0181 (0.0197) acc 78.1250 (72.0312) kd_loss 0.0136 (0.0130) lr 1.9686e-03 eta 0:20:13
epoch [6/50] batch [40/246] time 0.089 (0.101) data 0.000 (0.007) loss 1.4506 (1.2386) ce_loss 1.3545 (1.1484) teacher_loss 1.3551 (1.1477) loss_zs_kd 0.1461 (0.1430) loss_oracle 0.0225 (0.0194) acc 59.3750 (71.4062) kd_loss 0.0115 (0.0127) lr 1.9686e-03 eta 0:18:35
epoch [6/50] batch [60/246] time 0.088 (0.098) data 0.000 (0.005) loss 1.1805 (1.2217) ce_loss 1.1104 (1.1307) teacher_loss 1.1124 (1.1300) loss_zs_kd 0.0964 (0.1407) loss_oracle 0.0199 (0.0214) acc 78.1250 (71.6146) kd_loss 0.0099 (0.0126) lr 1.9686e-03 eta 0:17:54
epoch [6/50] batch [80/246] time 0.097 (0.096) data 0.000 (0.004) loss 1.2387 (1.2298) ce_loss 1.1484 (1.1401) teacher_loss 1.1466 (1.1396) loss_zs_kd 0.1399 (0.1367) loss_oracle 0.0221 (0.0219) acc 75.0000 (71.0547) kd_loss 0.0101 (0.0124) lr 1.9686e-03 eta 0:17:31
epoch [6/50] batch [100/246] time 0.100 (0.095) data 0.000 (0.003) loss 1.4570 (1.2248) ce_loss 1.3721 (1.1330) teacher_loss 1.3703 (1.1328) loss_zs_kd 0.1343 (0.1411) loss_oracle 0.0195 (0.0215) acc 62.5000 (70.7500) kd_loss 0.0095 (0.0121) lr 1.9686e-03 eta 0:17:22
epoch [6/50] batch [120/246] time 0.100 (0.096) data 0.000 (0.003) loss 1.0177 (1.2055) ce_loss 0.9194 (1.1125) teacher_loss 0.9190 (1.1124) loss_zs_kd 0.1626 (0.1443) loss_oracle 0.0174 (0.0210) acc 71.8750 (71.0156) kd_loss 0.0117 (0.0119) lr 1.9686e-03 eta 0:17:26
epoch [6/50] batch [140/246] time 0.094 (0.096) data 0.000 (0.002) loss 1.1312 (1.2111) ce_loss 1.0537 (1.1195) teacher_loss 1.0540 (1.1195) loss_zs_kd 0.1037 (0.1408) loss_oracle 0.0253 (0.0213) acc 68.7500 (70.8705) kd_loss 0.0084 (0.0118) lr 1.9686e-03 eta 0:17:24
epoch [6/50] batch [160/246] time 0.100 (0.096) data 0.000 (0.002) loss 1.2387 (1.2304) ce_loss 1.1455 (1.1380) teacher_loss 1.1472 (1.1379) loss_zs_kd 0.1263 (0.1416) loss_oracle 0.0284 (0.0217) acc 65.6250 (70.4688) kd_loss 0.0126 (0.0118) lr 1.9686e-03 eta 0:17:32
epoch [6/50] batch [180/246] time 0.096 (0.097) data 0.000 (0.002) loss 1.4341 (1.2272) ce_loss 1.3301 (1.1340) teacher_loss 1.3305 (1.1338) loss_zs_kd 0.1511 (0.1421) loss_oracle 0.0280 (0.0223) acc 65.6250 (70.6076) kd_loss 0.0136 (0.0120) lr 1.9686e-03 eta 0:17:37
epoch [6/50] batch [200/246] time 0.099 (0.098) data 0.000 (0.002) loss 1.1118 (1.2217) ce_loss 1.0293 (1.1284) teacher_loss 1.0301 (1.1281) loss_zs_kd 0.1143 (0.1415) loss_oracle 0.0245 (0.0228) acc 75.0000 (70.8281) kd_loss 0.0166 (0.0124) lr 1.9686e-03 eta 0:17:41
epoch [6/50] batch [220/246] time 0.101 (0.098) data 0.000 (0.002) loss 1.4577 (1.2228) ce_loss 1.3174 (1.1292) teacher_loss 1.3142 (1.1288) loss_zs_kd 0.2173 (0.1414) loss_oracle 0.0348 (0.0233) acc 68.7500 (70.7386) kd_loss 0.0245 (0.0129) lr 1.9686e-03 eta 0:17:45
epoch [6/50] batch [240/246] time 0.104 (0.099) data 0.000 (0.001) loss 1.1939 (1.2200) ce_loss 1.1240 (1.1264) teacher_loss 1.1239 (1.1261) loss_zs_kd 0.0903 (0.1407) loss_oracle 0.0249 (0.0235) acc 68.7500 (70.7682) kd_loss 0.0138 (0.0132) lr 1.9686e-03 eta 0:17:47
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,806
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,964
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 89.8%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.8%, epoch: 4 *******
******* Domain r best val test acc: 90.9%, epoch: 4 *******
******* Domain r best test acc:     91.0%, epoch: 6 *******
epoch [7/50] batch [20/246] time 0.128 (0.142) data 0.000 (0.015) loss 1.5597 (1.3383) ce_loss 1.4736 (1.2413) teacher_loss 1.4768 (1.2405) loss_zs_kd 0.1167 (0.1223) loss_oracle 0.0245 (0.0367) acc 53.1250 (66.8750) kd_loss 0.0125 (0.0164) lr 1.9511e-03 eta 0:25:37
epoch [7/50] batch [40/246] time 0.129 (0.135) data 0.000 (0.008) loss 0.8593 (1.2473) ce_loss 0.7725 (1.1484) teacher_loss 0.7632 (1.1478) loss_zs_kd 0.1282 (0.1349) loss_oracle 0.0321 (0.0321) acc 81.2500 (70.2344) kd_loss 0.0235 (0.0166) lr 1.9511e-03 eta 0:24:19
epoch [7/50] batch [60/246] time 0.123 (0.133) data 0.002 (0.005) loss 0.7027 (1.2359) ce_loss 0.6011 (1.1347) teacher_loss 0.6000 (1.1337) loss_zs_kd 0.1321 (0.1421) loss_oracle 0.0367 (0.0311) acc 84.3750 (70.0000) kd_loss 0.0147 (0.0169) lr 1.9511e-03 eta 0:23:55
epoch [7/50] batch [80/246] time 0.131 (0.133) data 0.000 (0.004) loss 1.1287 (1.2410) ce_loss 1.0498 (1.1382) teacher_loss 1.0498 (1.1373) loss_zs_kd 0.0958 (0.1412) loss_oracle 0.0309 (0.0331) acc 68.7500 (69.8047) kd_loss 0.0134 (0.0170) lr 1.9511e-03 eta 0:23:45
epoch [7/50] batch [100/246] time 0.137 (0.132) data 0.002 (0.003) loss 1.0784 (1.2447) ce_loss 0.9731 (1.1398) teacher_loss 0.9733 (1.1386) loss_zs_kd 0.1307 (0.1432) loss_oracle 0.0397 (0.0345) acc 71.8750 (69.8750) kd_loss 0.0213 (0.0175) lr 1.9511e-03 eta 0:23:37
epoch [7/50] batch [120/246] time 0.132 (0.132) data 0.000 (0.003) loss 0.7627 (1.2180) ce_loss 0.6548 (1.1152) teacher_loss 0.6570 (1.1142) loss_zs_kd 0.1518 (0.1405) loss_oracle 0.0298 (0.0336) acc 87.5000 (70.7292) kd_loss 0.0197 (0.0177) lr 1.9511e-03 eta 0:23:29
epoch [7/50] batch [140/246] time 0.128 (0.131) data 0.000 (0.003) loss 0.5942 (1.2142) ce_loss 0.5215 (1.1119) teacher_loss 0.5245 (1.1112) loss_zs_kd 0.0859 (0.1411) loss_oracle 0.0267 (0.0324) acc 84.3750 (70.8259) kd_loss 0.0140 (0.0177) lr 1.9511e-03 eta 0:23:22
epoch [7/50] batch [160/246] time 0.137 (0.131) data 0.002 (0.002) loss 1.5428 (1.2335) ce_loss 1.3848 (1.1296) teacher_loss 1.3824 (1.1290) loss_zs_kd 0.2188 (0.1430) loss_oracle 0.0510 (0.0330) acc 62.5000 (70.3711) kd_loss 0.0230 (0.0180) lr 1.9511e-03 eta 0:23:14
epoch [7/50] batch [180/246] time 0.124 (0.130) data 0.000 (0.002) loss 1.4830 (1.2362) ce_loss 1.3506 (1.1305) teacher_loss 1.3528 (1.1299) loss_zs_kd 0.1765 (0.1426) loss_oracle 0.0419 (0.0350) acc 62.5000 (70.1736) kd_loss 0.0177 (0.0185) lr 1.9511e-03 eta 0:23:02
epoch [7/50] batch [200/246] time 0.127 (0.129) data 0.000 (0.002) loss 0.8332 (1.2320) ce_loss 0.7173 (1.1266) teacher_loss 0.7191 (1.1260) loss_zs_kd 0.1592 (0.1412) loss_oracle 0.0345 (0.0354) acc 75.0000 (70.2344) kd_loss 0.0166 (0.0187) lr 1.9511e-03 eta 0:22:54
epoch [7/50] batch [220/246] time 0.123 (0.129) data 0.000 (0.002) loss 1.5663 (1.2293) ce_loss 1.4541 (1.1247) teacher_loss 1.4542 (1.1240) loss_zs_kd 0.1279 (0.1394) loss_oracle 0.0481 (0.0356) acc 65.6250 (70.2273) kd_loss 0.0229 (0.0189) lr 1.9511e-03 eta 0:22:48
epoch [7/50] batch [240/246] time 0.104 (0.128) data 0.000 (0.002) loss 1.0917 (1.2281) ce_loss 0.9775 (1.1224) teacher_loss 0.9802 (1.1217) loss_zs_kd 0.1352 (0.1405) loss_oracle 0.0438 (0.0361) acc 81.2500 (70.1953) kd_loss 0.0221 (0.0190) lr 1.9511e-03 eta 0:22:32
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,813
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      83.9%, epoch: 7 *******
******* Domain r best val test acc: 90.9%, epoch: 7 *******
******* Domain r best test acc:     91.0%, epoch: 6 *******
epoch [8/50] batch [20/246] time 0.103 (0.125) data 0.000 (0.014) loss 1.3661 (1.2416) ce_loss 1.2451 (1.1362) teacher_loss 1.2453 (1.1366) loss_zs_kd 0.1618 (0.1411) loss_oracle 0.0400 (0.0345) acc 68.7500 (70.1562) kd_loss 0.0256 (0.0212) lr 1.9298e-03 eta 0:21:56
epoch [8/50] batch [40/246] time 0.101 (0.113) data 0.000 (0.007) loss 1.4036 (1.2529) ce_loss 1.3057 (1.1500) teacher_loss 1.2968 (1.1495) loss_zs_kd 0.1340 (0.1382) loss_oracle 0.0398 (0.0343) acc 62.5000 (69.8438) kd_loss 0.0230 (0.0214) lr 1.9298e-03 eta 0:19:50
epoch [8/50] batch [60/246] time 0.112 (0.109) data 0.000 (0.005) loss 1.5652 (1.2361) ce_loss 1.4404 (1.1300) teacher_loss 1.4359 (1.1291) loss_zs_kd 0.1715 (0.1413) loss_oracle 0.0435 (0.0363) acc 59.3750 (70.3125) kd_loss 0.0277 (0.0220) lr 1.9298e-03 eta 0:19:01
epoch [8/50] batch [80/246] time 0.113 (0.109) data 0.000 (0.004) loss 0.7563 (1.2275) ce_loss 0.6787 (1.1210) teacher_loss 0.6815 (1.1199) loss_zs_kd 0.0840 (0.1408) loss_oracle 0.0329 (0.0372) acc 84.3750 (70.7812) kd_loss 0.0203 (0.0223) lr 1.9298e-03 eta 0:19:01
epoch [8/50] batch [100/246] time 0.125 (0.111) data 0.000 (0.003) loss 1.2254 (1.2456) ce_loss 1.0742 (1.1383) teacher_loss 1.0684 (1.1370) loss_zs_kd 0.2017 (0.1405) loss_oracle 0.0562 (0.0383) acc 81.2500 (70.3125) kd_loss 0.0323 (0.0224) lr 1.9298e-03 eta 0:19:23
epoch [8/50] batch [120/246] time 0.110 (0.113) data 0.000 (0.003) loss 1.6283 (1.2410) ce_loss 1.4961 (1.1311) teacher_loss 1.4999 (1.1299) loss_zs_kd 0.1697 (0.1420) loss_oracle 0.0435 (0.0400) acc 62.5000 (70.7292) kd_loss 0.0227 (0.0228) lr 1.9298e-03 eta 0:19:42
epoch [8/50] batch [140/246] time 0.122 (0.113) data 0.000 (0.002) loss 1.2451 (1.2497) ce_loss 1.1367 (1.1384) teacher_loss 1.1417 (1.1374) loss_zs_kd 0.1187 (0.1442) loss_oracle 0.0440 (0.0403) acc 68.7500 (70.5804) kd_loss 0.0333 (0.0229) lr 1.9298e-03 eta 0:19:42
epoch [8/50] batch [160/246] time 0.106 (0.113) data 0.000 (0.002) loss 1.5117 (1.2498) ce_loss 1.3975 (1.1400) teacher_loss 1.3948 (1.1390) loss_zs_kd 0.1639 (0.1436) loss_oracle 0.0350 (0.0390) acc 59.3750 (70.5859) kd_loss 0.0253 (0.0228) lr 1.9298e-03 eta 0:19:40
epoch [8/50] batch [180/246] time 0.120 (0.114) data 0.000 (0.002) loss 1.5035 (1.2414) ce_loss 1.4141 (1.1335) teacher_loss 1.4104 (1.1327) loss_zs_kd 0.1323 (0.1421) loss_oracle 0.0270 (0.0377) acc 65.6250 (70.5382) kd_loss 0.0184 (0.0225) lr 1.9298e-03 eta 0:19:40
epoch [8/50] batch [200/246] time 0.083 (0.112) data 0.000 (0.002) loss 1.1229 (1.2429) ce_loss 1.0205 (1.1364) teacher_loss 1.0062 (1.1354) loss_zs_kd 0.1697 (0.1421) loss_oracle 0.0319 (0.0365) acc 75.0000 (70.5312) kd_loss 0.0248 (0.0223) lr 1.9298e-03 eta 0:19:22
epoch [8/50] batch [220/246] time 0.084 (0.110) data 0.000 (0.002) loss 1.2336 (1.2438) ce_loss 1.1572 (1.1374) teacher_loss 1.1565 (1.1365) loss_zs_kd 0.0915 (0.1433) loss_oracle 0.0313 (0.0357) acc 75.0000 (70.4545) kd_loss 0.0172 (0.0219) lr 1.9298e-03 eta 0:18:57
epoch [8/50] batch [240/246] time 0.100 (0.109) data 0.000 (0.001) loss 0.9792 (1.2437) ce_loss 0.8560 (1.1377) teacher_loss 0.8561 (1.1367) loss_zs_kd 0.1736 (0.1438) loss_oracle 0.0363 (0.0351) acc 78.1250 (70.4036) kd_loss 0.0184 (0.0215) lr 1.9298e-03 eta 0:18:41
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,829
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.4%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,972
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.1%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.3%, epoch: 8 *******
******* Domain r best val test acc: 91.2%, epoch: 8 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [9/50] batch [20/246] time 0.113 (0.125) data 0.000 (0.020) loss 0.9111 (1.2372) ce_loss 0.7939 (1.1382) teacher_loss 0.7914 (1.1365) loss_zs_kd 0.1596 (0.1377) loss_oracle 0.0399 (0.0318) acc 78.1250 (70.9375) kd_loss 0.0194 (0.0165) lr 1.9048e-03 eta 0:21:25
epoch [9/50] batch [40/246] time 0.097 (0.115) data 0.000 (0.010) loss 1.4717 (1.2652) ce_loss 1.3809 (1.1610) teacher_loss 1.3786 (1.1591) loss_zs_kd 0.1042 (0.1411) loss_oracle 0.0410 (0.0355) acc 68.7500 (69.6875) kd_loss 0.0130 (0.0165) lr 1.9048e-03 eta 0:19:42
epoch [9/50] batch [60/246] time 0.100 (0.111) data 0.001 (0.007) loss 1.5021 (1.2814) ce_loss 1.3467 (1.1704) teacher_loss 1.3420 (1.1686) loss_zs_kd 0.2102 (0.1443) loss_oracle 0.0549 (0.0407) acc 75.0000 (70.0000) kd_loss 0.0219 (0.0171) lr 1.9048e-03 eta 0:19:01
epoch [9/50] batch [80/246] time 0.101 (0.109) data 0.001 (0.005) loss 1.3885 (1.2826) ce_loss 1.2695 (1.1698) teacher_loss 1.2667 (1.1683) loss_zs_kd 0.1761 (0.1465) loss_oracle 0.0338 (0.0410) acc 56.2500 (69.8438) kd_loss 0.0207 (0.0178) lr 1.9048e-03 eta 0:18:33
epoch [9/50] batch [100/246] time 0.092 (0.107) data 0.000 (0.004) loss 0.8489 (1.2596) ce_loss 0.7725 (1.1507) teacher_loss 0.7702 (1.1491) loss_zs_kd 0.0840 (0.1423) loss_oracle 0.0368 (0.0394) acc 81.2500 (70.2188) kd_loss 0.0226 (0.0184) lr 1.9048e-03 eta 0:18:18
epoch [9/50] batch [120/246] time 0.096 (0.106) data 0.000 (0.004) loss 1.2460 (1.2860) ce_loss 1.1621 (1.1762) teacher_loss 1.1675 (1.1747) loss_zs_kd 0.1047 (0.1450) loss_oracle 0.0262 (0.0388) acc 68.7500 (69.4792) kd_loss 0.0123 (0.0186) lr 1.9048e-03 eta 0:18:01
epoch [9/50] batch [140/246] time 0.111 (0.106) data 0.000 (0.003) loss 1.5035 (1.2898) ce_loss 1.4131 (1.1814) teacher_loss 1.4142 (1.1797) loss_zs_kd 0.1152 (0.1436) loss_oracle 0.0317 (0.0382) acc 65.6250 (69.1741) kd_loss 0.0184 (0.0186) lr 1.9048e-03 eta 0:18:01
epoch [9/50] batch [160/246] time 0.103 (0.106) data 0.000 (0.003) loss 1.1689 (1.2850) ce_loss 1.0654 (1.1781) teacher_loss 1.0653 (1.1765) loss_zs_kd 0.1319 (0.1409) loss_oracle 0.0376 (0.0380) acc 71.8750 (69.2969) kd_loss 0.0133 (0.0184) lr 1.9048e-03 eta 0:17:58
epoch [9/50] batch [180/246] time 0.112 (0.106) data 0.000 (0.003) loss 1.1324 (1.2806) ce_loss 1.0332 (1.1727) teacher_loss 1.0380 (1.1712) loss_zs_kd 0.1198 (0.1408) loss_oracle 0.0345 (0.0390) acc 71.8750 (69.4444) kd_loss 0.0146 (0.0185) lr 1.9048e-03 eta 0:17:56
epoch [9/50] batch [200/246] time 0.110 (0.106) data 0.000 (0.002) loss 1.2770 (1.2795) ce_loss 1.1592 (1.1722) teacher_loss 1.1602 (1.1707) loss_zs_kd 0.1642 (0.1395) loss_oracle 0.0347 (0.0391) acc 65.6250 (69.4219) kd_loss 0.0223 (0.0185) lr 1.9048e-03 eta 0:17:57
epoch [9/50] batch [220/246] time 0.108 (0.107) data 0.000 (0.002) loss 1.0854 (1.2746) ce_loss 0.9790 (1.1672) teacher_loss 0.9803 (1.1656) loss_zs_kd 0.1510 (0.1405) loss_oracle 0.0296 (0.0388) acc 78.1250 (69.6023) kd_loss 0.0115 (0.0184) lr 1.9048e-03 eta 0:17:57
epoch [9/50] batch [240/246] time 0.104 (0.106) data 0.000 (0.002) loss 1.1569 (1.2765) ce_loss 1.0254 (1.1678) teacher_loss 1.0229 (1.1660) loss_zs_kd 0.1565 (0.1413) loss_oracle 0.0558 (0.0398) acc 81.2500 (69.6094) kd_loss 0.0264 (0.0187) lr 1.9048e-03 eta 0:17:52
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,824
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,968
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.0%
******* Domain r best val acc:      84.3%, epoch: 8 *******
******* Domain r best val test acc: 91.2%, epoch: 8 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [10/50] batch [20/246] time 0.107 (0.119) data 0.000 (0.013) loss 1.1845 (1.2898) ce_loss 1.0928 (1.1757) teacher_loss 1.0902 (1.1762) loss_zs_kd 0.1005 (0.1588) loss_oracle 0.0441 (0.0342) acc 65.6250 (69.3750) kd_loss 0.0229 (0.0170) lr 1.8763e-03 eta 0:20:02
epoch [10/50] batch [40/246] time 0.131 (0.123) data 0.000 (0.007) loss 1.5364 (1.2768) ce_loss 1.4199 (1.1634) teacher_loss 1.4085 (1.1615) loss_zs_kd 0.1418 (0.1524) loss_oracle 0.0571 (0.0391) acc 65.6250 (68.9062) kd_loss 0.0273 (0.0192) lr 1.8763e-03 eta 0:20:37
epoch [10/50] batch [60/246] time 0.139 (0.125) data 0.001 (0.005) loss 1.0311 (1.2382) ce_loss 0.9229 (1.1234) teacher_loss 0.9223 (1.1216) loss_zs_kd 0.1300 (0.1502) loss_oracle 0.0438 (0.0414) acc 71.8750 (69.7396) kd_loss 0.0210 (0.0199) lr 1.8763e-03 eta 0:20:55
epoch [10/50] batch [80/246] time 0.135 (0.126) data 0.000 (0.004) loss 1.4244 (1.2380) ce_loss 1.2969 (1.1220) teacher_loss 1.2874 (1.1198) loss_zs_kd 0.1931 (0.1485) loss_oracle 0.0405 (0.0439) acc 59.3750 (69.8047) kd_loss 0.0227 (0.0205) lr 1.8763e-03 eta 0:21:05
epoch [10/50] batch [100/246] time 0.125 (0.127) data 0.000 (0.003) loss 1.4464 (1.2443) ce_loss 1.3516 (1.1306) teacher_loss 1.3503 (1.1281) loss_zs_kd 0.1371 (0.1482) loss_oracle 0.0276 (0.0421) acc 68.7500 (69.7188) kd_loss 0.0205 (0.0206) lr 1.8763e-03 eta 0:21:06
epoch [10/50] batch [120/246] time 0.127 (0.127) data 0.000 (0.003) loss 1.9041 (1.2621) ce_loss 1.7979 (1.1484) teacher_loss 1.7817 (1.1459) loss_zs_kd 0.1358 (0.1496) loss_oracle 0.0545 (0.0414) acc 62.5000 (69.5573) kd_loss 0.0217 (0.0207) lr 1.8763e-03 eta 0:21:09
epoch [10/50] batch [140/246] time 0.126 (0.128) data 0.000 (0.002) loss 0.8821 (1.2695) ce_loss 0.7617 (1.1544) teacher_loss 0.7731 (1.1524) loss_zs_kd 0.1177 (0.1477) loss_oracle 0.0501 (0.0434) acc 81.2500 (69.1964) kd_loss 0.0217 (0.0209) lr 1.8763e-03 eta 0:21:09
epoch [10/50] batch [160/246] time 0.128 (0.128) data 0.000 (0.002) loss 1.3810 (1.2712) ce_loss 1.2822 (1.1562) teacher_loss 1.2787 (1.1543) loss_zs_kd 0.1487 (0.1474) loss_oracle 0.0279 (0.0432) acc 71.8750 (69.1602) kd_loss 0.0205 (0.0212) lr 1.8763e-03 eta 0:21:12
epoch [10/50] batch [180/246] time 0.127 (0.128) data 0.000 (0.002) loss 1.0069 (1.2752) ce_loss 0.9355 (1.1608) teacher_loss 0.9340 (1.1592) loss_zs_kd 0.0708 (0.1469) loss_oracle 0.0375 (0.0426) acc 78.1250 (69.1146) kd_loss 0.0216 (0.0213) lr 1.8763e-03 eta 0:21:12
epoch [10/50] batch [200/246] time 0.135 (0.129) data 0.001 (0.002) loss 1.2023 (1.2734) ce_loss 1.1025 (1.1595) teacher_loss 1.1005 (1.1579) loss_zs_kd 0.1232 (0.1448) loss_oracle 0.0401 (0.0432) acc 75.0000 (69.2969) kd_loss 0.0207 (0.0214) lr 1.8763e-03 eta 0:21:13
epoch [10/50] batch [220/246] time 0.130 (0.129) data 0.000 (0.002) loss 1.5658 (1.2656) ce_loss 1.3877 (1.1526) teacher_loss 1.3850 (1.1508) loss_zs_kd 0.2646 (0.1437) loss_oracle 0.0484 (0.0430) acc 59.3750 (69.4318) kd_loss 0.0264 (0.0213) lr 1.8763e-03 eta 0:21:11
epoch [10/50] batch [240/246] time 0.113 (0.128) data 0.000 (0.001) loss 0.7572 (1.2625) ce_loss 0.6543 (1.1487) teacher_loss 0.6291 (1.1468) loss_zs_kd 0.1270 (0.1448) loss_oracle 0.0647 (0.0434) acc 81.2500 (69.5182) kd_loss 0.0294 (0.0213) lr 1.8763e-03 eta 0:21:03
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,829
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.5%
******* Domain r best val acc:      84.3%, epoch: 8 *******
******* Domain r best val test acc: 91.2%, epoch: 8 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [11/50] batch [20/246] time 0.104 (0.120) data 0.000 (0.013) loss 0.9381 (1.2643) ce_loss 0.7622 (1.1438) teacher_loss 0.7568 (1.1399) loss_zs_kd 0.2748 (0.1558) loss_oracle 0.0438 (0.0465) acc 84.3750 (70.6250) kd_loss 0.0208 (0.0213) lr 1.8443e-03 eta 0:19:42
epoch [11/50] batch [40/246] time 0.110 (0.114) data 0.000 (0.006) loss 1.2458 (1.2416) ce_loss 1.1338 (1.1230) teacher_loss 1.1258 (1.1191) loss_zs_kd 0.1480 (0.1523) loss_oracle 0.0459 (0.0463) acc 71.8750 (71.1719) kd_loss 0.0202 (0.0211) lr 1.8443e-03 eta 0:18:41
epoch [11/50] batch [60/246] time 0.093 (0.110) data 0.001 (0.004) loss 1.2190 (1.2391) ce_loss 1.0898 (1.1229) teacher_loss 1.0879 (1.1180) loss_zs_kd 0.1980 (0.1547) loss_oracle 0.0321 (0.0437) acc 65.6250 (70.2083) kd_loss 0.0206 (0.0221) lr 1.8443e-03 eta 0:17:58
epoch [11/50] batch [80/246] time 0.095 (0.107) data 0.000 (0.003) loss 1.0773 (1.2333) ce_loss 0.9741 (1.1176) teacher_loss 0.9783 (1.1133) loss_zs_kd 0.1383 (0.1545) loss_oracle 0.0300 (0.0428) acc 81.2500 (70.4688) kd_loss 0.0146 (0.0212) lr 1.8443e-03 eta 0:17:24
epoch [11/50] batch [100/246] time 0.096 (0.105) data 0.000 (0.003) loss 1.3399 (1.2475) ce_loss 1.2246 (1.1306) teacher_loss 1.2296 (1.1264) loss_zs_kd 0.1464 (0.1553) loss_oracle 0.0371 (0.0435) acc 68.7500 (70.0625) kd_loss 0.0190 (0.0214) lr 1.8443e-03 eta 0:16:59
epoch [11/50] batch [120/246] time 0.103 (0.103) data 0.000 (0.002) loss 0.8836 (1.2292) ce_loss 0.7964 (1.1159) teacher_loss 0.7948 (1.1114) loss_zs_kd 0.1249 (0.1528) loss_oracle 0.0263 (0.0414) acc 78.1250 (70.3906) kd_loss 0.0182 (0.0211) lr 1.8443e-03 eta 0:16:45
epoch [11/50] batch [140/246] time 0.099 (0.103) data 0.000 (0.002) loss 1.2076 (1.2338) ce_loss 1.1035 (1.1211) teacher_loss 1.1067 (1.1165) loss_zs_kd 0.1398 (0.1531) loss_oracle 0.0310 (0.0407) acc 78.1250 (70.3795) kd_loss 0.0116 (0.0208) lr 1.8443e-03 eta 0:16:36
epoch [11/50] batch [160/246] time 0.099 (0.102) data 0.000 (0.002) loss 1.4915 (1.2324) ce_loss 1.4033 (1.1196) teacher_loss 1.3813 (1.1152) loss_zs_kd 0.1252 (0.1529) loss_oracle 0.0477 (0.0407) acc 59.3750 (70.2930) kd_loss 0.0232 (0.0206) lr 1.8443e-03 eta 0:16:27
epoch [11/50] batch [180/246] time 0.103 (0.102) data 0.000 (0.002) loss 1.0852 (1.2217) ce_loss 0.9844 (1.1090) teacher_loss 0.9757 (1.1049) loss_zs_kd 0.1330 (0.1531) loss_oracle 0.0430 (0.0403) acc 65.6250 (70.5382) kd_loss 0.0234 (0.0205) lr 1.8443e-03 eta 0:16:27
epoch [11/50] batch [200/246] time 0.128 (0.104) data 0.001 (0.001) loss 1.1028 (1.2221) ce_loss 1.0352 (1.1102) teacher_loss 1.0362 (1.1064) loss_zs_kd 0.0715 (0.1519) loss_oracle 0.0308 (0.0398) acc 71.8750 (70.7031) kd_loss 0.0115 (0.0204) lr 1.8443e-03 eta 0:16:39
epoch [11/50] batch [220/246] time 0.109 (0.105) data 0.000 (0.001) loss 1.2274 (1.2111) ce_loss 1.1143 (1.0999) teacher_loss 1.1108 (1.0964) loss_zs_kd 0.1490 (0.1513) loss_oracle 0.0422 (0.0391) acc 68.7500 (71.0369) kd_loss 0.0271 (0.0203) lr 1.8443e-03 eta 0:16:47
epoch [11/50] batch [240/246] time 0.103 (0.106) data 0.000 (0.001) loss 0.9466 (1.2191) ce_loss 0.8496 (1.1071) teacher_loss 0.8459 (1.1038) loss_zs_kd 0.1308 (0.1521) loss_oracle 0.0353 (0.0392) acc 81.2500 (70.8854) kd_loss 0.0159 (0.0201) lr 1.8443e-03 eta 0:16:55
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,826
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      84.3%, epoch: 8 *******
******* Domain r best val test acc: 91.2%, epoch: 8 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [12/50] batch [20/246] time 0.088 (0.115) data 0.000 (0.016) loss 1.1156 (1.1703) ce_loss 1.0098 (1.0464) teacher_loss 1.0099 (1.0434) loss_zs_kd 0.1228 (0.1525) loss_oracle 0.0442 (0.0506) acc 65.6250 (72.5000) kd_loss 0.0196 (0.0215) lr 1.8090e-03 eta 0:18:23
epoch [12/50] batch [40/246] time 0.089 (0.104) data 0.000 (0.008) loss 1.7842 (1.2142) ce_loss 1.6641 (1.0915) teacher_loss 1.6681 (1.0880) loss_zs_kd 0.1560 (0.1507) loss_oracle 0.0381 (0.0509) acc 59.3750 (70.8594) kd_loss 0.0140 (0.0219) lr 1.8090e-03 eta 0:16:35
epoch [12/50] batch [60/246] time 0.105 (0.103) data 0.001 (0.005) loss 1.6823 (1.2325) ce_loss 1.5850 (1.1127) teacher_loss 1.5630 (1.1090) loss_zs_kd 0.1421 (0.1519) loss_oracle 0.0482 (0.0476) acc 59.3750 (70.4167) kd_loss 0.0278 (0.0215) lr 1.8090e-03 eta 0:16:25
epoch [12/50] batch [80/246] time 0.127 (0.105) data 0.000 (0.004) loss 1.0671 (1.2366) ce_loss 0.9692 (1.1189) teacher_loss 0.9729 (1.1159) loss_zs_kd 0.1216 (0.1527) loss_oracle 0.0334 (0.0443) acc 65.6250 (70.2344) kd_loss 0.0170 (0.0212) lr 1.8090e-03 eta 0:16:42
epoch [12/50] batch [100/246] time 0.129 (0.108) data 0.001 (0.003) loss 1.4875 (1.2094) ce_loss 1.3535 (1.0947) teacher_loss 1.3472 (1.0918) loss_zs_kd 0.1932 (0.1515) loss_oracle 0.0437 (0.0419) acc 62.5000 (70.9375) kd_loss 0.0259 (0.0207) lr 1.8090e-03 eta 0:17:05
epoch [12/50] batch [120/246] time 0.112 (0.109) data 0.000 (0.003) loss 0.7546 (1.1954) ce_loss 0.6724 (1.0817) teacher_loss 0.6716 (1.0792) loss_zs_kd 0.1101 (0.1537) loss_oracle 0.0279 (0.0393) acc 87.5000 (71.3802) kd_loss 0.0201 (0.0201) lr 1.8090e-03 eta 0:17:13
epoch [12/50] batch [140/246] time 0.117 (0.111) data 0.001 (0.003) loss 1.3796 (1.2037) ce_loss 1.3018 (1.0937) teacher_loss 1.3028 (1.0916) loss_zs_kd 0.1065 (0.1503) loss_oracle 0.0235 (0.0369) acc 71.8750 (71.1384) kd_loss 0.0169 (0.0198) lr 1.8090e-03 eta 0:17:25
epoch [12/50] batch [160/246] time 0.084 (0.108) data 0.000 (0.002) loss 1.4924 (1.2070) ce_loss 1.3945 (1.1002) teacher_loss 1.3983 (1.0981) loss_zs_kd 0.1514 (0.1477) loss_oracle 0.0183 (0.0352) acc 65.6250 (70.8398) kd_loss 0.0121 (0.0194) lr 1.8090e-03 eta 0:16:59
epoch [12/50] batch [180/246] time 0.084 (0.106) data 0.001 (0.002) loss 0.9268 (1.2140) ce_loss 0.8188 (1.1072) teacher_loss 0.8168 (1.1050) loss_zs_kd 0.1618 (0.1495) loss_oracle 0.0291 (0.0342) acc 81.2500 (70.9028) kd_loss 0.0232 (0.0190) lr 1.8090e-03 eta 0:16:37
epoch [12/50] batch [200/246] time 0.091 (0.105) data 0.000 (0.002) loss 1.1946 (1.2080) ce_loss 1.0234 (1.1008) teacher_loss 1.0207 (1.0988) loss_zs_kd 0.2459 (0.1504) loss_oracle 0.0510 (0.0339) acc 71.8750 (70.9844) kd_loss 0.0195 (0.0188) lr 1.8090e-03 eta 0:16:24
epoch [12/50] batch [220/246] time 0.120 (0.105) data 0.001 (0.002) loss 1.0080 (1.2113) ce_loss 0.8979 (1.1041) teacher_loss 0.8991 (1.1021) loss_zs_kd 0.1504 (0.1511) loss_oracle 0.0337 (0.0336) acc 78.1250 (70.9091) kd_loss 0.0204 (0.0186) lr 1.8090e-03 eta 0:16:28
epoch [12/50] batch [240/246] time 0.104 (0.106) data 0.000 (0.002) loss 1.0441 (1.2189) ce_loss 0.9482 (1.1110) teacher_loss 0.9479 (1.1092) loss_zs_kd 0.1101 (0.1521) loss_oracle 0.0412 (0.0336) acc 75.0000 (70.7031) kd_loss 0.0149 (0.0184) lr 1.8090e-03 eta 0:16:32
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,814
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,940
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.3%
******* Domain r best val acc:      84.3%, epoch: 8 *******
******* Domain r best val test acc: 91.2%, epoch: 8 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [13/50] batch [20/246] time 0.088 (0.121) data 0.000 (0.018) loss 1.1044 (1.2104) ce_loss 0.9756 (1.0924) teacher_loss 0.9739 (1.0916) loss_zs_kd 0.1607 (0.1532) loss_oracle 0.0502 (0.0422) acc 78.1250 (70.6250) kd_loss 0.0220 (0.0184) lr 1.7705e-03 eta 0:18:46
epoch [13/50] batch [40/246] time 0.096 (0.109) data 0.000 (0.009) loss 1.2600 (1.2014) ce_loss 1.1572 (1.0882) teacher_loss 1.1582 (1.0870) loss_zs_kd 0.1215 (0.1492) loss_oracle 0.0410 (0.0398) acc 71.8750 (71.0938) kd_loss 0.0144 (0.0188) lr 1.7705e-03 eta 0:16:50
epoch [13/50] batch [60/246] time 0.103 (0.105) data 0.001 (0.006) loss 1.6345 (1.2111) ce_loss 1.5215 (1.0998) teacher_loss 1.5202 (1.0984) loss_zs_kd 0.1292 (0.1473) loss_oracle 0.0497 (0.0391) acc 62.5000 (70.7812) kd_loss 0.0209 (0.0190) lr 1.7705e-03 eta 0:16:19
epoch [13/50] batch [80/246] time 0.097 (0.104) data 0.000 (0.005) loss 1.1276 (1.2093) ce_loss 1.0156 (1.0957) teacher_loss 1.0154 (1.0943) loss_zs_kd 0.1544 (0.1492) loss_oracle 0.0350 (0.0403) acc 71.8750 (71.0547) kd_loss 0.0143 (0.0192) lr 1.7705e-03 eta 0:16:01
epoch [13/50] batch [100/246] time 0.102 (0.103) data 0.000 (0.004) loss 0.9623 (1.2104) ce_loss 0.7993 (1.0938) teacher_loss 0.7957 (1.0921) loss_zs_kd 0.2183 (0.1526) loss_oracle 0.0574 (0.0419) acc 87.5000 (71.3438) kd_loss 0.0266 (0.0195) lr 1.7705e-03 eta 0:15:50
epoch [13/50] batch [120/246] time 0.111 (0.103) data 0.000 (0.003) loss 0.7352 (1.1974) ce_loss 0.6074 (1.0812) teacher_loss 0.6122 (1.0798) loss_zs_kd 0.1613 (0.1509) loss_oracle 0.0423 (0.0421) acc 84.3750 (71.6146) kd_loss 0.0173 (0.0200) lr 1.7705e-03 eta 0:15:46
epoch [13/50] batch [140/246] time 0.096 (0.102) data 0.001 (0.003) loss 1.2798 (1.2064) ce_loss 1.1709 (1.0894) teacher_loss 1.1639 (1.0876) loss_zs_kd 0.1385 (0.1513) loss_oracle 0.0467 (0.0432) acc 71.8750 (71.3616) kd_loss 0.0175 (0.0203) lr 1.7705e-03 eta 0:15:40
epoch [13/50] batch [160/246] time 0.105 (0.102) data 0.000 (0.003) loss 1.8013 (1.2231) ce_loss 1.6309 (1.1042) teacher_loss 1.6324 (1.1024) loss_zs_kd 0.2300 (0.1525) loss_oracle 0.0539 (0.0444) acc 56.2500 (70.9180) kd_loss 0.0226 (0.0206) lr 1.7705e-03 eta 0:15:37
epoch [13/50] batch [180/246] time 0.102 (0.102) data 0.000 (0.002) loss 1.8783 (1.2253) ce_loss 1.7754 (1.1054) teacher_loss 1.7754 (1.1033) loss_zs_kd 0.1187 (0.1520) loss_oracle 0.0436 (0.0460) acc 50.0000 (70.7986) kd_loss 0.0210 (0.0211) lr 1.7705e-03 eta 0:15:32
epoch [13/50] batch [200/246] time 0.104 (0.102) data 0.000 (0.002) loss 1.4712 (1.2315) ce_loss 1.3281 (1.1110) teacher_loss 1.3240 (1.1088) loss_zs_kd 0.2227 (0.1546) loss_oracle 0.0358 (0.0455) acc 65.6250 (70.8438) kd_loss 0.0151 (0.0210) lr 1.7705e-03 eta 0:15:29
epoch [13/50] batch [220/246] time 0.094 (0.101) data 0.000 (0.002) loss 1.0873 (1.2186) ce_loss 0.9536 (1.0977) teacher_loss 0.9502 (1.0955) loss_zs_kd 0.1694 (0.1548) loss_oracle 0.0525 (0.0458) acc 78.1250 (71.1364) kd_loss 0.0228 (0.0211) lr 1.7705e-03 eta 0:15:21
epoch [13/50] batch [240/246] time 0.086 (0.100) data 0.000 (0.002) loss 1.1790 (1.2131) ce_loss 1.0449 (1.0929) teacher_loss 1.0469 (1.0907) loss_zs_kd 0.1822 (0.1536) loss_oracle 0.0410 (0.0457) acc 75.0000 (71.2891) kd_loss 0.0203 (0.0210) lr 1.7705e-03 eta 0:15:11
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,833
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.5%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,949
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      84.5%, epoch: 13 *******
******* Domain r best val test acc: 90.6%, epoch: 13 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [14/50] batch [20/246] time 0.119 (0.129) data 0.001 (0.013) loss 0.7183 (1.2375) ce_loss 0.6367 (1.1221) teacher_loss 0.6359 (1.1193) loss_zs_kd 0.1027 (0.1581) loss_oracle 0.0311 (0.0391) acc 81.2500 (68.9062) kd_loss 0.0180 (0.0208) lr 1.7290e-03 eta 0:19:32
epoch [14/50] batch [40/246] time 0.095 (0.119) data 0.001 (0.007) loss 1.6244 (1.1793) ce_loss 1.5166 (1.0710) teacher_loss 1.5157 (1.0680) loss_zs_kd 0.1474 (0.1521) loss_oracle 0.0349 (0.0352) acc 68.7500 (71.4844) kd_loss 0.0276 (0.0216) lr 1.7290e-03 eta 0:18:01
epoch [14/50] batch [60/246] time 0.099 (0.112) data 0.000 (0.005) loss 1.8784 (1.2164) ce_loss 1.7412 (1.1113) teacher_loss 1.7412 (1.1083) loss_zs_kd 0.2230 (0.1512) loss_oracle 0.0257 (0.0326) acc 56.2500 (70.7812) kd_loss 0.0199 (0.0211) lr 1.7290e-03 eta 0:16:54
epoch [14/50] batch [80/246] time 0.095 (0.108) data 0.000 (0.003) loss 1.0401 (1.2035) ce_loss 0.9419 (1.1000) teacher_loss 0.9435 (1.0968) loss_zs_kd 0.1393 (0.1494) loss_oracle 0.0269 (0.0320) acc 84.3750 (71.3281) kd_loss 0.0157 (0.0208) lr 1.7290e-03 eta 0:16:14
epoch [14/50] batch [100/246] time 0.094 (0.106) data 0.000 (0.003) loss 1.1787 (1.2136) ce_loss 1.0205 (1.1095) teacher_loss 1.0147 (1.1062) loss_zs_kd 0.2530 (0.1512) loss_oracle 0.0374 (0.0319) acc 68.7500 (70.7188) kd_loss 0.0216 (0.0206) lr 1.7290e-03 eta 0:15:53
epoch [14/50] batch [120/246] time 0.098 (0.104) data 0.000 (0.002) loss 1.0238 (1.2181) ce_loss 0.9019 (1.1129) teacher_loss 0.8979 (1.1094) loss_zs_kd 0.1711 (0.1506) loss_oracle 0.0404 (0.0334) acc 75.0000 (70.5990) kd_loss 0.0236 (0.0206) lr 1.7290e-03 eta 0:15:38
epoch [14/50] batch [140/246] time 0.098 (0.103) data 0.000 (0.002) loss 1.8058 (1.2281) ce_loss 1.6738 (1.1208) teacher_loss 1.6575 (1.1170) loss_zs_kd 0.1679 (0.1491) loss_oracle 0.0644 (0.0365) acc 62.5000 (70.4911) kd_loss 0.0328 (0.0209) lr 1.7290e-03 eta 0:15:26
epoch [14/50] batch [160/246] time 0.101 (0.102) data 0.000 (0.002) loss 1.1502 (1.2280) ce_loss 1.0342 (1.1193) teacher_loss 1.0367 (1.1157) loss_zs_kd 0.1424 (0.1477) loss_oracle 0.0423 (0.0384) acc 71.8750 (70.5273) kd_loss 0.0179 (0.0211) lr 1.7290e-03 eta 0:15:16
epoch [14/50] batch [180/246] time 0.101 (0.102) data 0.000 (0.002) loss 1.6165 (1.2220) ce_loss 1.5195 (1.1140) teacher_loss 1.4968 (1.1106) loss_zs_kd 0.1651 (0.1469) loss_oracle 0.0371 (0.0379) acc 62.5000 (70.7986) kd_loss 0.0246 (0.0211) lr 1.7290e-03 eta 0:15:06
epoch [14/50] batch [200/246] time 0.100 (0.101) data 0.000 (0.002) loss 1.2538 (1.2245) ce_loss 1.1279 (1.1175) teacher_loss 1.1283 (1.1139) loss_zs_kd 0.1863 (0.1460) loss_oracle 0.0323 (0.0376) acc 62.5000 (70.8125) kd_loss 0.0216 (0.0215) lr 1.7290e-03 eta 0:15:00
epoch [14/50] batch [220/246] time 0.096 (0.101) data 0.000 (0.001) loss 0.9990 (1.2170) ce_loss 0.8589 (1.1097) teacher_loss 0.8623 (1.1061) loss_zs_kd 0.2066 (0.1475) loss_oracle 0.0334 (0.0372) acc 75.0000 (70.9943) kd_loss 0.0188 (0.0215) lr 1.7290e-03 eta 0:14:53
epoch [14/50] batch [240/246] time 0.086 (0.100) data 0.000 (0.001) loss 1.2141 (1.2103) ce_loss 1.0840 (1.1022) teacher_loss 1.0834 (1.0988) loss_zs_kd 0.2001 (0.1491) loss_oracle 0.0307 (0.0370) acc 71.8750 (71.3021) kd_loss 0.0206 (0.0215) lr 1.7290e-03 eta 0:14:44
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,839
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.8%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,961
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
******* Domain r best val acc:      84.6%, epoch: 14 *******
******* Domain r best val test acc: 90.9%, epoch: 14 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [15/50] batch [20/246] time 0.081 (0.103) data 0.000 (0.014) loss 1.1844 (1.2063) ce_loss 1.0889 (1.1078) teacher_loss 1.0930 (1.1053) loss_zs_kd 0.1246 (0.1438) loss_oracle 0.0292 (0.0291) acc 68.7500 (70.6250) kd_loss 0.0258 (0.0202) lr 1.6845e-03 eta 0:15:14
epoch [15/50] batch [40/246] time 0.092 (0.096) data 0.000 (0.007) loss 1.1015 (1.1925) ce_loss 0.9961 (1.0931) teacher_loss 0.9845 (1.0918) loss_zs_kd 0.1590 (0.1428) loss_oracle 0.0375 (0.0292) acc 75.0000 (71.1719) kd_loss 0.0274 (0.0217) lr 1.6845e-03 eta 0:14:07
epoch [15/50] batch [60/246] time 0.083 (0.094) data 0.000 (0.005) loss 0.9142 (1.2018) ce_loss 0.7715 (1.0973) teacher_loss 0.7655 (1.0950) loss_zs_kd 0.1962 (0.1491) loss_oracle 0.0506 (0.0323) acc 78.1250 (70.7812) kd_loss 0.0283 (0.0220) lr 1.6845e-03 eta 0:13:49
epoch [15/50] batch [80/246] time 0.095 (0.094) data 0.000 (0.004) loss 0.9548 (1.2010) ce_loss 0.8550 (1.0915) teacher_loss 0.8406 (1.0890) loss_zs_kd 0.1448 (0.1557) loss_oracle 0.0418 (0.0341) acc 71.8750 (70.9766) kd_loss 0.0455 (0.0223) lr 1.6845e-03 eta 0:13:47
epoch [15/50] batch [100/246] time 0.092 (0.095) data 0.000 (0.003) loss 1.0521 (1.1955) ce_loss 0.9512 (1.0854) teacher_loss 0.9476 (1.0828) loss_zs_kd 0.1308 (0.1546) loss_oracle 0.0391 (0.0354) acc 71.8750 (71.3438) kd_loss 0.0170 (0.0220) lr 1.6845e-03 eta 0:13:47
epoch [15/50] batch [120/246] time 0.089 (0.095) data 0.000 (0.003) loss 1.4831 (1.1978) ce_loss 1.3945 (1.0881) teacher_loss 1.3972 (1.0851) loss_zs_kd 0.1124 (0.1543) loss_oracle 0.0298 (0.0356) acc 62.5000 (71.3021) kd_loss 0.0128 (0.0220) lr 1.6845e-03 eta 0:13:45
epoch [15/50] batch [140/246] time 0.084 (0.094) data 0.000 (0.002) loss 1.4274 (1.2055) ce_loss 1.3066 (1.0954) teacher_loss 1.3057 (1.0925) loss_zs_kd 0.1457 (0.1545) loss_oracle 0.0488 (0.0358) acc 68.7500 (71.2277) kd_loss 0.0266 (0.0217) lr 1.6845e-03 eta 0:13:39
epoch [15/50] batch [160/246] time 0.095 (0.094) data 0.000 (0.002) loss 1.5985 (1.2143) ce_loss 1.4863 (1.1039) teacher_loss 1.4729 (1.1013) loss_zs_kd 0.1636 (0.1543) loss_oracle 0.0438 (0.0359) acc 62.5000 (71.1914) kd_loss 0.0215 (0.0216) lr 1.6845e-03 eta 0:13:35
epoch [15/50] batch [180/246] time 0.082 (0.093) data 0.000 (0.002) loss 1.6217 (1.1994) ce_loss 1.4873 (1.0890) teacher_loss 1.4840 (1.0866) loss_zs_kd 0.2048 (0.1529) loss_oracle 0.0353 (0.0363) acc 62.5000 (71.5278) kd_loss 0.0257 (0.0216) lr 1.6845e-03 eta 0:13:27
epoch [15/50] batch [200/246] time 0.092 (0.093) data 0.000 (0.002) loss 1.0604 (1.2022) ce_loss 0.9624 (1.0922) teacher_loss 0.9597 (1.0898) loss_zs_kd 0.1189 (0.1519) loss_oracle 0.0413 (0.0364) acc 68.7500 (71.4062) kd_loss 0.0162 (0.0215) lr 1.6845e-03 eta 0:13:21
epoch [15/50] batch [220/246] time 0.084 (0.092) data 0.000 (0.001) loss 1.6667 (1.2074) ce_loss 1.5205 (1.0968) teacher_loss 1.5283 (1.0945) loss_zs_kd 0.2033 (0.1531) loss_oracle 0.0367 (0.0364) acc 56.2500 (71.2358) kd_loss 0.0199 (0.0214) lr 1.6845e-03 eta 0:13:17
epoch [15/50] batch [240/246] time 0.085 (0.092) data 0.000 (0.001) loss 0.9640 (1.2112) ce_loss 0.8745 (1.1009) teacher_loss 0.8796 (1.0987) loss_zs_kd 0.1255 (0.1532) loss_oracle 0.0216 (0.0359) acc 75.0000 (71.1198) kd_loss 0.0137 (0.0214) lr 1.6845e-03 eta 0:13:13
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,840
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.8%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      84.7%, epoch: 15 *******
******* Domain r best val test acc: 90.7%, epoch: 15 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [16/50] batch [20/246] time 0.127 (0.144) data 0.000 (0.017) loss 0.6399 (1.1948) ce_loss 0.5239 (1.0946) teacher_loss 0.5239 (1.0909) loss_zs_kd 0.1507 (0.1482) loss_oracle 0.0406 (0.0298) acc 90.6250 (70.9375) kd_loss 0.0355 (0.0215) lr 1.6374e-03 eta 0:20:34
epoch [16/50] batch [40/246] time 0.130 (0.137) data 0.000 (0.009) loss 1.0869 (1.2015) ce_loss 0.9648 (1.0960) teacher_loss 0.9493 (1.0926) loss_zs_kd 0.1849 (0.1521) loss_oracle 0.0452 (0.0328) acc 71.8750 (71.3281) kd_loss 0.0283 (0.0207) lr 1.6374e-03 eta 0:19:32
epoch [16/50] batch [60/246] time 0.123 (0.134) data 0.000 (0.006) loss 1.7227 (1.2366) ce_loss 1.5938 (1.1231) teacher_loss 1.5934 (1.1202) loss_zs_kd 0.1523 (0.1559) loss_oracle 0.0532 (0.0384) acc 56.2500 (70.8333) kd_loss 0.0179 (0.0203) lr 1.6374e-03 eta 0:19:04
epoch [16/50] batch [80/246] time 0.114 (0.131) data 0.000 (0.004) loss 1.4997 (1.2658) ce_loss 1.3389 (1.1486) teacher_loss 1.3370 (1.1464) loss_zs_kd 0.2225 (0.1570) loss_oracle 0.0515 (0.0410) acc 59.3750 (70.2344) kd_loss 0.0230 (0.0201) lr 1.6374e-03 eta 0:18:38
epoch [16/50] batch [100/246] time 0.096 (0.127) data 0.000 (0.004) loss 1.1454 (1.2484) ce_loss 1.0283 (1.1299) teacher_loss 1.0189 (1.1278) loss_zs_kd 0.1768 (0.1583) loss_oracle 0.0381 (0.0415) acc 71.8750 (70.9375) kd_loss 0.0213 (0.0206) lr 1.6374e-03 eta 0:18:02
epoch [16/50] batch [120/246] time 0.105 (0.123) data 0.000 (0.003) loss 1.0317 (1.2429) ce_loss 0.9141 (1.1254) teacher_loss 0.8928 (1.1233) loss_zs_kd 0.1872 (0.1574) loss_oracle 0.0453 (0.0410) acc 78.1250 (70.8073) kd_loss 0.0382 (0.0211) lr 1.6374e-03 eta 0:17:26
epoch [16/50] batch [140/246] time 0.119 (0.121) data 0.000 (0.003) loss 1.0533 (1.2421) ce_loss 0.9580 (1.1260) teacher_loss 0.9614 (1.1238) loss_zs_kd 0.1158 (0.1562) loss_oracle 0.0340 (0.0402) acc 75.0000 (70.8259) kd_loss 0.0172 (0.0214) lr 1.6374e-03 eta 0:17:06
epoch [16/50] batch [160/246] time 0.126 (0.121) data 0.000 (0.002) loss 1.7418 (1.2381) ce_loss 1.6523 (1.1235) teacher_loss 1.6429 (1.1211) loss_zs_kd 0.1390 (0.1540) loss_oracle 0.0294 (0.0400) acc 62.5000 (70.7617) kd_loss 0.0237 (0.0215) lr 1.6374e-03 eta 0:17:01
epoch [16/50] batch [180/246] time 0.119 (0.121) data 0.000 (0.002) loss 1.3046 (1.2264) ce_loss 1.1992 (1.1130) teacher_loss 1.1963 (1.1107) loss_zs_kd 0.1275 (0.1522) loss_oracle 0.0446 (0.0397) acc 75.0000 (70.9896) kd_loss 0.0225 (0.0213) lr 1.6374e-03 eta 0:17:03
epoch [16/50] batch [200/246] time 0.120 (0.121) data 0.000 (0.002) loss 0.9887 (1.2336) ce_loss 0.8633 (1.1192) teacher_loss 0.8673 (1.1172) loss_zs_kd 0.1583 (0.1539) loss_oracle 0.0422 (0.0395) acc 75.0000 (70.8750) kd_loss 0.0235 (0.0211) lr 1.6374e-03 eta 0:17:01
epoch [16/50] batch [220/246] time 0.103 (0.120) data 0.000 (0.002) loss 1.2465 (1.2274) ce_loss 1.1406 (1.1123) teacher_loss 1.1402 (1.1104) loss_zs_kd 0.1414 (0.1545) loss_oracle 0.0357 (0.0398) acc 75.0000 (71.2926) kd_loss 0.0206 (0.0209) lr 1.6374e-03 eta 0:16:50
epoch [16/50] batch [240/246] time 0.085 (0.118) data 0.000 (0.002) loss 1.3597 (1.2243) ce_loss 1.2764 (1.1096) teacher_loss 1.2733 (1.1078) loss_zs_kd 0.1300 (0.1535) loss_oracle 0.0214 (0.0398) acc 68.7500 (71.2760) kd_loss 0.0228 (0.0209) lr 1.6374e-03 eta 0:16:27
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,837
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,951
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      84.7%, epoch: 15 *******
******* Domain r best val test acc: 90.7%, epoch: 15 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [17/50] batch [20/246] time 0.083 (0.108) data 0.000 (0.014) loss 1.0391 (1.2137) ce_loss 0.9697 (1.1080) teacher_loss 0.9678 (1.1062) loss_zs_kd 0.0850 (0.1527) loss_oracle 0.0289 (0.0311) acc 71.8750 (72.0312) kd_loss 0.0161 (0.0200) lr 1.5878e-03 eta 0:15:00
epoch [17/50] batch [40/246] time 0.090 (0.099) data 0.000 (0.007) loss 0.7475 (1.1955) ce_loss 0.6606 (1.0899) teacher_loss 0.6565 (1.0871) loss_zs_kd 0.1279 (0.1539) loss_oracle 0.0270 (0.0314) acc 84.3750 (72.4219) kd_loss 0.0198 (0.0224) lr 1.5878e-03 eta 0:13:44
epoch [17/50] batch [60/246] time 0.083 (0.096) data 0.000 (0.005) loss 0.9518 (1.1837) ce_loss 0.7969 (1.0760) teacher_loss 0.7925 (1.0733) loss_zs_kd 0.2415 (0.1578) loss_oracle 0.0386 (0.0314) acc 75.0000 (72.5000) kd_loss 0.0471 (0.0230) lr 1.5878e-03 eta 0:13:15
epoch [17/50] batch [80/246] time 0.097 (0.095) data 0.000 (0.004) loss 1.1220 (1.2033) ce_loss 1.0195 (1.0975) teacher_loss 1.0217 (1.0950) loss_zs_kd 0.1365 (0.1544) loss_oracle 0.0320 (0.0311) acc 78.1250 (71.7969) kd_loss 0.0165 (0.0229) lr 1.5878e-03 eta 0:13:03
epoch [17/50] batch [100/246] time 0.087 (0.094) data 0.000 (0.003) loss 1.2434 (1.2072) ce_loss 1.1289 (1.1001) teacher_loss 1.1375 (1.0975) loss_zs_kd 0.1488 (0.1558) loss_oracle 0.0315 (0.0318) acc 75.0000 (71.5938) kd_loss 0.0272 (0.0231) lr 1.5878e-03 eta 0:13:00
epoch [17/50] batch [120/246] time 0.092 (0.094) data 0.000 (0.002) loss 1.0003 (1.1933) ce_loss 0.8569 (1.0851) teacher_loss 0.8511 (1.0827) loss_zs_kd 0.2087 (0.1563) loss_oracle 0.0448 (0.0324) acc 81.2500 (72.2917) kd_loss 0.0499 (0.0238) lr 1.5878e-03 eta 0:12:54
epoch [17/50] batch [140/246] time 0.084 (0.094) data 0.000 (0.002) loss 1.1727 (1.1991) ce_loss 1.0752 (1.0901) teacher_loss 1.0742 (1.0876) loss_zs_kd 0.1260 (0.1575) loss_oracle 0.0355 (0.0327) acc 75.0000 (72.1205) kd_loss 0.0337 (0.0243) lr 1.5878e-03 eta 0:12:53
epoch [17/50] batch [160/246] time 0.099 (0.094) data 0.000 (0.002) loss 0.9998 (1.1998) ce_loss 0.8799 (1.0913) teacher_loss 0.8664 (1.0888) loss_zs_kd 0.1560 (0.1567) loss_oracle 0.0554 (0.0326) acc 68.7500 (71.9922) kd_loss 0.0294 (0.0242) lr 1.5878e-03 eta 0:12:50
epoch [17/50] batch [180/246] time 0.086 (0.094) data 0.000 (0.002) loss 1.7044 (1.2025) ce_loss 1.5918 (1.0935) teacher_loss 1.5902 (1.0914) loss_zs_kd 0.1687 (0.1565) loss_oracle 0.0298 (0.0328) acc 68.7500 (71.8750) kd_loss 0.0168 (0.0237) lr 1.5878e-03 eta 0:12:46
epoch [17/50] batch [200/246] time 0.097 (0.094) data 0.000 (0.002) loss 0.9985 (1.1989) ce_loss 0.9321 (1.0909) teacher_loss 0.9338 (1.0889) loss_zs_kd 0.0879 (0.1554) loss_oracle 0.0208 (0.0323) acc 78.1250 (72.0312) kd_loss 0.0199 (0.0236) lr 1.5878e-03 eta 0:12:44
epoch [17/50] batch [220/246] time 0.082 (0.093) data 0.000 (0.001) loss 1.0701 (1.2027) ce_loss 0.9399 (1.0945) teacher_loss 0.9394 (1.0925) loss_zs_kd 0.1954 (0.1560) loss_oracle 0.0329 (0.0321) acc 71.8750 (71.8040) kd_loss 0.0224 (0.0234) lr 1.5878e-03 eta 0:12:40
epoch [17/50] batch [240/246] time 0.087 (0.093) data 0.000 (0.001) loss 0.9608 (1.1958) ce_loss 0.8516 (1.0871) teacher_loss 0.8504 (1.0852) loss_zs_kd 0.1460 (0.1571) loss_oracle 0.0374 (0.0321) acc 78.1250 (71.9661) kd_loss 0.0323 (0.0232) lr 1.5878e-03 eta 0:12:33
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,841
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      84.7%, epoch: 17 *******
******* Domain r best val test acc: 90.8%, epoch: 17 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [18/50] batch [20/246] time 0.089 (0.107) data 0.000 (0.014) loss 0.9065 (1.2029) ce_loss 0.7705 (1.0917) teacher_loss 0.7758 (1.0894) loss_zs_kd 0.1960 (0.1631) loss_oracle 0.0327 (0.0320) acc 84.3750 (71.8750) kd_loss 0.0303 (0.0248) lr 1.5358e-03 eta 0:14:28
epoch [18/50] batch [40/246] time 0.102 (0.099) data 0.000 (0.007) loss 1.3464 (1.2225) ce_loss 1.2168 (1.1141) teacher_loss 1.2175 (1.1113) loss_zs_kd 0.1840 (0.1589) loss_oracle 0.0369 (0.0316) acc 68.7500 (71.0938) kd_loss 0.0188 (0.0235) lr 1.5358e-03 eta 0:13:22
epoch [18/50] batch [60/246] time 0.088 (0.098) data 0.000 (0.005) loss 1.1256 (1.1862) ce_loss 1.0137 (1.0727) teacher_loss 1.0109 (1.0701) loss_zs_kd 0.1698 (0.1682) loss_oracle 0.0298 (0.0320) acc 68.7500 (72.6562) kd_loss 0.0181 (0.0231) lr 1.5358e-03 eta 0:13:08
epoch [18/50] batch [80/246] time 0.093 (0.097) data 0.000 (0.004) loss 1.4237 (1.2038) ce_loss 1.3145 (1.0925) teacher_loss 1.3133 (1.0894) loss_zs_kd 0.1389 (0.1632) loss_oracle 0.0410 (0.0328) acc 68.7500 (72.1875) kd_loss 0.0350 (0.0233) lr 1.5358e-03 eta 0:12:58
epoch [18/50] batch [100/246] time 0.084 (0.096) data 0.001 (0.003) loss 1.3549 (1.1980) ce_loss 1.2549 (1.0875) teacher_loss 1.2512 (1.0846) loss_zs_kd 0.1388 (0.1599) loss_oracle 0.0343 (0.0335) acc 68.7500 (71.7500) kd_loss 0.0241 (0.0230) lr 1.5358e-03 eta 0:12:46
epoch [18/50] batch [120/246] time 0.093 (0.095) data 0.000 (0.002) loss 1.5195 (1.2127) ce_loss 1.3975 (1.1011) teacher_loss 1.3972 (1.0982) loss_zs_kd 0.1790 (0.1618) loss_oracle 0.0328 (0.0336) acc 68.7500 (71.2500) kd_loss 0.0202 (0.0223) lr 1.5358e-03 eta 0:12:40
epoch [18/50] batch [140/246] time 0.087 (0.095) data 0.000 (0.002) loss 0.7981 (1.2096) ce_loss 0.7017 (1.0974) teacher_loss 0.6970 (1.0946) loss_zs_kd 0.1202 (0.1620) loss_oracle 0.0410 (0.0339) acc 84.3750 (71.2946) kd_loss 0.0232 (0.0221) lr 1.5358e-03 eta 0:12:35
epoch [18/50] batch [160/246] time 0.098 (0.094) data 0.000 (0.002) loss 0.6271 (1.2037) ce_loss 0.5034 (1.0896) teacher_loss 0.5045 (1.0870) loss_zs_kd 0.1737 (0.1635) loss_oracle 0.0357 (0.0349) acc 90.6250 (71.3477) kd_loss 0.0126 (0.0217) lr 1.5358e-03 eta 0:12:29
epoch [18/50] batch [180/246] time 0.087 (0.094) data 0.000 (0.002) loss 0.8404 (1.2024) ce_loss 0.7603 (1.0891) teacher_loss 0.7507 (1.0866) loss_zs_kd 0.1087 (0.1623) loss_oracle 0.0354 (0.0346) acc 78.1250 (71.1979) kd_loss 0.0175 (0.0218) lr 1.5358e-03 eta 0:12:26
epoch [18/50] batch [200/246] time 0.093 (0.094) data 0.000 (0.002) loss 1.0827 (1.2066) ce_loss 0.9663 (1.0927) teacher_loss 0.9701 (1.0905) loss_zs_kd 0.1841 (0.1633) loss_oracle 0.0205 (0.0345) acc 71.8750 (70.9688) kd_loss 0.0144 (0.0218) lr 1.5358e-03 eta 0:12:23
epoch [18/50] batch [220/246] time 0.089 (0.094) data 0.000 (0.001) loss 0.8965 (1.2083) ce_loss 0.8252 (1.0947) teacher_loss 0.8241 (1.0925) loss_zs_kd 0.0895 (0.1630) loss_oracle 0.0277 (0.0342) acc 78.1250 (71.0795) kd_loss 0.0254 (0.0219) lr 1.5358e-03 eta 0:12:20
epoch [18/50] batch [240/246] time 0.105 (0.094) data 0.000 (0.001) loss 0.8911 (1.2154) ce_loss 0.7573 (1.1023) teacher_loss 0.7562 (1.1001) loss_zs_kd 0.2112 (0.1626) loss_oracle 0.0294 (0.0339) acc 81.2500 (70.8724) kd_loss 0.0308 (0.0221) lr 1.5358e-03 eta 0:12:23
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,838
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,949
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.5%
******* Domain r best val acc:      84.7%, epoch: 17 *******
******* Domain r best val test acc: 90.8%, epoch: 17 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [19/50] batch [20/246] time 0.082 (0.112) data 0.000 (0.014) loss 0.8782 (1.1237) ce_loss 0.7920 (1.0160) teacher_loss 0.7895 (1.0140) loss_zs_kd 0.1311 (0.1595) loss_oracle 0.0232 (0.0299) acc 84.3750 (74.5312) kd_loss 0.0186 (0.0252) lr 1.4818e-03 eta 0:14:39
epoch [19/50] batch [40/246] time 0.089 (0.100) data 0.000 (0.007) loss 1.0515 (1.1663) ce_loss 0.9663 (1.0607) teacher_loss 0.9689 (1.0583) loss_zs_kd 0.1152 (0.1559) loss_oracle 0.0250 (0.0300) acc 78.1250 (71.4844) kd_loss 0.0170 (0.0247) lr 1.4818e-03 eta 0:13:03
epoch [19/50] batch [60/246] time 0.082 (0.097) data 0.000 (0.005) loss 1.1368 (1.1685) ce_loss 1.0557 (1.0616) teacher_loss 1.0493 (1.0587) loss_zs_kd 0.1103 (0.1588) loss_oracle 0.0323 (0.0304) acc 71.8750 (71.6146) kd_loss 0.0221 (0.0238) lr 1.4818e-03 eta 0:12:34
epoch [19/50] batch [80/246] time 0.091 (0.095) data 0.000 (0.004) loss 1.3731 (1.1710) ce_loss 1.2520 (1.0624) teacher_loss 1.2403 (1.0594) loss_zs_kd 0.2087 (0.1617) loss_oracle 0.0285 (0.0308) acc 65.6250 (71.4453) kd_loss 0.0202 (0.0231) lr 1.4818e-03 eta 0:12:20
epoch [19/50] batch [100/246] time 0.082 (0.094) data 0.000 (0.003) loss 1.1255 (1.1808) ce_loss 0.9907 (1.0727) teacher_loss 0.9956 (1.0704) loss_zs_kd 0.1821 (0.1601) loss_oracle 0.0389 (0.0304) acc 71.8750 (71.2812) kd_loss 0.0309 (0.0229) lr 1.4818e-03 eta 0:12:11
epoch [19/50] batch [120/246] time 0.087 (0.093) data 0.000 (0.002) loss 1.1291 (1.1888) ce_loss 0.9902 (1.0792) teacher_loss 0.9924 (1.0774) loss_zs_kd 0.2086 (0.1630) loss_oracle 0.0324 (0.0299) acc 71.8750 (70.9375) kd_loss 0.0283 (0.0228) lr 1.4818e-03 eta 0:12:04
epoch [19/50] batch [140/246] time 0.088 (0.093) data 0.000 (0.002) loss 1.0754 (1.2066) ce_loss 0.9785 (1.0980) teacher_loss 0.9795 (1.0963) loss_zs_kd 0.1454 (0.1617) loss_oracle 0.0232 (0.0295) acc 75.0000 (70.6696) kd_loss 0.0196 (0.0229) lr 1.4818e-03 eta 0:11:59
epoch [19/50] batch [160/246] time 0.097 (0.093) data 0.000 (0.002) loss 1.0393 (1.2021) ce_loss 0.9219 (1.0940) teacher_loss 0.9248 (1.0923) loss_zs_kd 0.1698 (0.1607) loss_oracle 0.0296 (0.0294) acc 65.6250 (70.6836) kd_loss 0.0166 (0.0232) lr 1.4818e-03 eta 0:11:57
epoch [19/50] batch [180/246] time 0.099 (0.093) data 0.000 (0.002) loss 1.3005 (1.2046) ce_loss 1.1328 (1.0958) teacher_loss 1.1333 (1.0944) loss_zs_kd 0.2416 (0.1596) loss_oracle 0.0464 (0.0304) acc 71.8750 (70.7986) kd_loss 0.0256 (0.0233) lr 1.4818e-03 eta 0:11:56
epoch [19/50] batch [200/246] time 0.104 (0.094) data 0.001 (0.002) loss 1.2853 (1.2061) ce_loss 1.1934 (1.0969) teacher_loss 1.1907 (1.0954) loss_zs_kd 0.1111 (0.1585) loss_oracle 0.0390 (0.0314) acc 71.8750 (70.7812) kd_loss 0.0270 (0.0232) lr 1.4818e-03 eta 0:12:01
epoch [19/50] batch [220/246] time 0.095 (0.095) data 0.000 (0.001) loss 0.8833 (1.2142) ce_loss 0.7666 (1.1046) teacher_loss 0.7589 (1.1031) loss_zs_kd 0.1797 (0.1584) loss_oracle 0.0345 (0.0319) acc 81.2500 (70.5540) kd_loss 0.0240 (0.0230) lr 1.4818e-03 eta 0:12:03
epoch [19/50] batch [240/246] time 0.103 (0.095) data 0.000 (0.001) loss 1.2801 (1.2154) ce_loss 1.1553 (1.1052) teacher_loss 1.1460 (1.1039) loss_zs_kd 0.1970 (0.1592) loss_oracle 0.0356 (0.0319) acc 68.7500 (70.6120) kd_loss 0.0195 (0.0229) lr 1.4818e-03 eta 0:12:05
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,849
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.1%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [20/50] batch [20/246] time 0.084 (0.105) data 0.000 (0.014) loss 1.2446 (1.2384) ce_loss 1.1211 (1.1241) teacher_loss 1.1306 (1.1234) loss_zs_kd 0.1665 (0.1651) loss_oracle 0.0307 (0.0324) acc 71.8750 (71.2500) kd_loss 0.0215 (0.0210) lr 1.4258e-03 eta 0:13:20
epoch [20/50] batch [40/246] time 0.098 (0.099) data 0.000 (0.007) loss 1.0636 (1.2172) ce_loss 0.9341 (1.1066) teacher_loss 0.9330 (1.1052) loss_zs_kd 0.1908 (0.1599) loss_oracle 0.0352 (0.0320) acc 75.0000 (71.3281) kd_loss 0.0157 (0.0213) lr 1.4258e-03 eta 0:12:31
epoch [20/50] batch [60/246] time 0.098 (0.099) data 0.000 (0.005) loss 1.2985 (1.2290) ce_loss 1.1641 (1.1193) teacher_loss 1.1638 (1.1177) loss_zs_kd 0.2025 (0.1582) loss_oracle 0.0334 (0.0322) acc 71.8750 (70.9375) kd_loss 0.0192 (0.0210) lr 1.4258e-03 eta 0:12:25
epoch [20/50] batch [80/246] time 0.093 (0.097) data 0.000 (0.004) loss 1.2378 (1.2332) ce_loss 1.1035 (1.1215) teacher_loss 1.1085 (1.1201) loss_zs_kd 0.1813 (0.1601) loss_oracle 0.0386 (0.0331) acc 81.2500 (71.2109) kd_loss 0.0215 (0.0207) lr 1.4258e-03 eta 0:12:15
epoch [20/50] batch [100/246] time 0.093 (0.097) data 0.000 (0.003) loss 0.8349 (1.2382) ce_loss 0.7148 (1.1266) teacher_loss 0.7147 (1.1252) loss_zs_kd 0.1563 (0.1585) loss_oracle 0.0420 (0.0337) acc 84.3750 (71.1875) kd_loss 0.0184 (0.0208) lr 1.4258e-03 eta 0:12:09
epoch [20/50] batch [120/246] time 0.100 (0.097) data 0.000 (0.002) loss 1.2784 (1.2232) ce_loss 1.0879 (1.1089) teacher_loss 1.0928 (1.1076) loss_zs_kd 0.2814 (0.1611) loss_oracle 0.0448 (0.0350) acc 71.8750 (71.5885) kd_loss 0.0234 (0.0208) lr 1.4258e-03 eta 0:12:05
epoch [20/50] batch [140/246] time 0.091 (0.097) data 0.000 (0.002) loss 1.0913 (1.2164) ce_loss 0.9834 (1.1021) teacher_loss 0.9727 (1.1008) loss_zs_kd 0.1430 (0.1612) loss_oracle 0.0471 (0.0350) acc 75.0000 (71.5848) kd_loss 0.0370 (0.0208) lr 1.4258e-03 eta 0:12:03
epoch [20/50] batch [160/246] time 0.095 (0.096) data 0.000 (0.002) loss 0.7032 (1.2102) ce_loss 0.5923 (1.0954) teacher_loss 0.5961 (1.0938) loss_zs_kd 0.1445 (0.1624) loss_oracle 0.0349 (0.0352) acc 87.5000 (71.8750) kd_loss 0.0296 (0.0214) lr 1.4258e-03 eta 0:11:59
epoch [20/50] batch [180/246] time 0.098 (0.096) data 0.000 (0.002) loss 1.0951 (1.1956) ce_loss 0.9790 (1.0812) teacher_loss 0.9773 (1.0795) loss_zs_kd 0.1647 (0.1616) loss_oracle 0.0354 (0.0353) acc 71.8750 (72.3090) kd_loss 0.0340 (0.0224) lr 1.4258e-03 eta 0:11:55
epoch [20/50] batch [200/246] time 0.093 (0.096) data 0.000 (0.002) loss 1.1409 (1.1971) ce_loss 1.0107 (1.0820) teacher_loss 0.9954 (1.0798) loss_zs_kd 0.2047 (0.1624) loss_oracle 0.0431 (0.0361) acc 68.7500 (72.3906) kd_loss 0.0323 (0.0231) lr 1.4258e-03 eta 0:11:52
epoch [20/50] batch [220/246] time 0.089 (0.096) data 0.000 (0.001) loss 1.5554 (1.1950) ce_loss 1.4561 (1.0804) teacher_loss 1.4439 (1.0779) loss_zs_kd 0.1363 (0.1613) loss_oracle 0.0433 (0.0365) acc 62.5000 (72.1307) kd_loss 0.0272 (0.0235) lr 1.4258e-03 eta 0:11:49
epoch [20/50] batch [240/246] time 0.087 (0.095) data 0.000 (0.001) loss 1.2301 (1.1985) ce_loss 1.1230 (1.0836) teacher_loss 1.1170 (1.0810) loss_zs_kd 0.1535 (0.1615) loss_oracle 0.0363 (0.0367) acc 75.0000 (72.0964) kd_loss 0.0195 (0.0237) lr 1.4258e-03 eta 0:11:44
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,840
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [21/50] batch [20/246] time 0.098 (0.114) data 0.000 (0.014) loss 0.6706 (1.1810) ce_loss 0.5835 (1.0635) teacher_loss 0.5787 (1.0611) loss_zs_kd 0.1104 (0.1690) loss_oracle 0.0367 (0.0353) acc 87.5000 (71.8750) kd_loss 0.0229 (0.0263) lr 1.3681e-03 eta 0:13:59
epoch [21/50] batch [40/246] time 0.109 (0.108) data 0.000 (0.007) loss 1.0946 (1.2066) ce_loss 0.9673 (1.0952) teacher_loss 0.9521 (1.0916) loss_zs_kd 0.1739 (0.1594) loss_oracle 0.0556 (0.0353) acc 71.8750 (71.1719) kd_loss 0.0475 (0.0265) lr 1.3681e-03 eta 0:13:14
epoch [21/50] batch [60/246] time 0.110 (0.106) data 0.001 (0.005) loss 1.1126 (1.2056) ce_loss 0.9565 (1.0899) teacher_loss 0.9632 (1.0864) loss_zs_kd 0.2048 (0.1666) loss_oracle 0.0470 (0.0359) acc 78.1250 (71.7188) kd_loss 0.0294 (0.0267) lr 1.3681e-03 eta 0:12:57
epoch [21/50] batch [80/246] time 0.107 (0.105) data 0.000 (0.004) loss 1.3334 (1.1941) ce_loss 1.2314 (1.0789) teacher_loss 1.2301 (1.0755) loss_zs_kd 0.1487 (0.1652) loss_oracle 0.0289 (0.0359) acc 65.6250 (72.0703) kd_loss 0.0182 (0.0265) lr 1.3681e-03 eta 0:12:50
epoch [21/50] batch [100/246] time 0.099 (0.104) data 0.000 (0.003) loss 1.1547 (1.1976) ce_loss 1.0664 (1.0830) teacher_loss 1.0691 (1.0794) loss_zs_kd 0.1343 (0.1640) loss_oracle 0.0184 (0.0361) acc 68.7500 (72.0312) kd_loss 0.0167 (0.0268) lr 1.3681e-03 eta 0:12:40
epoch [21/50] batch [120/246] time 0.112 (0.104) data 0.000 (0.003) loss 0.8056 (1.2066) ce_loss 0.7080 (1.0937) teacher_loss 0.7116 (1.0906) loss_zs_kd 0.1361 (0.1615) loss_oracle 0.0259 (0.0353) acc 78.1250 (71.8490) kd_loss 0.0185 (0.0264) lr 1.3681e-03 eta 0:12:38
epoch [21/50] batch [140/246] time 0.103 (0.104) data 0.000 (0.002) loss 0.8966 (1.2041) ce_loss 0.7808 (1.0914) teacher_loss 0.7819 (1.0889) loss_zs_kd 0.1556 (0.1610) loss_oracle 0.0370 (0.0347) acc 78.1250 (71.8973) kd_loss 0.0274 (0.0258) lr 1.3681e-03 eta 0:12:34
epoch [21/50] batch [160/246] time 0.109 (0.105) data 0.000 (0.002) loss 0.8591 (1.1997) ce_loss 0.7334 (1.0867) teacher_loss 0.7386 (1.0841) loss_zs_kd 0.1853 (0.1620) loss_oracle 0.0279 (0.0346) acc 81.2500 (71.9922) kd_loss 0.0212 (0.0254) lr 1.3681e-03 eta 0:12:37
epoch [21/50] batch [180/246] time 0.114 (0.105) data 0.000 (0.002) loss 1.3568 (1.2142) ce_loss 1.2275 (1.1010) teacher_loss 1.2203 (1.0983) loss_zs_kd 0.1949 (0.1623) loss_oracle 0.0391 (0.0348) acc 68.7500 (71.5625) kd_loss 0.0353 (0.0259) lr 1.3681e-03 eta 0:12:38
epoch [21/50] batch [200/246] time 0.110 (0.106) data 0.001 (0.002) loss 1.2783 (1.2129) ce_loss 1.1426 (1.1002) teacher_loss 1.1345 (1.0975) loss_zs_kd 0.2053 (0.1617) loss_oracle 0.0412 (0.0347) acc 75.0000 (71.5625) kd_loss 0.0532 (0.0263) lr 1.3681e-03 eta 0:12:40
epoch [21/50] batch [220/246] time 0.116 (0.107) data 0.000 (0.002) loss 1.0640 (1.2182) ce_loss 0.9419 (1.1056) teacher_loss 0.9334 (1.1029) loss_zs_kd 0.1749 (0.1616) loss_oracle 0.0432 (0.0346) acc 65.6250 (71.4062) kd_loss 0.0468 (0.0266) lr 1.3681e-03 eta 0:12:42
epoch [21/50] batch [240/246] time 0.105 (0.107) data 0.000 (0.001) loss 1.1586 (1.2196) ce_loss 1.0527 (1.1071) teacher_loss 1.0560 (1.1047) loss_zs_kd 0.1538 (0.1613) loss_oracle 0.0256 (0.0343) acc 71.8750 (71.1849) kd_loss 0.0218 (0.0267) lr 1.3681e-03 eta 0:12:41
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,841
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [22/50] batch [20/246] time 0.110 (0.119) data 0.000 (0.012) loss 0.9604 (1.1740) ce_loss 0.8506 (1.0584) teacher_loss 0.8487 (1.0552) loss_zs_kd 0.1576 (0.1675) loss_oracle 0.0329 (0.0350) acc 78.1250 (71.0938) kd_loss 0.0258 (0.0326) lr 1.3090e-03 eta 0:14:04
epoch [22/50] batch [40/246] time 0.103 (0.113) data 0.000 (0.006) loss 1.3474 (1.2453) ce_loss 1.2197 (1.1266) teacher_loss 1.2286 (1.1251) loss_zs_kd 0.1827 (0.1702) loss_oracle 0.0274 (0.0351) acc 75.0000 (69.4531) kd_loss 0.0188 (0.0313) lr 1.3090e-03 eta 0:13:21
epoch [22/50] batch [60/246] time 0.098 (0.111) data 0.000 (0.004) loss 1.0531 (1.2366) ce_loss 0.9390 (1.1172) teacher_loss 0.9439 (1.1160) loss_zs_kd 0.1557 (0.1711) loss_oracle 0.0314 (0.0350) acc 71.8750 (69.3229) kd_loss 0.0351 (0.0309) lr 1.3090e-03 eta 0:13:02
epoch [22/50] batch [80/246] time 0.113 (0.110) data 0.000 (0.003) loss 1.4632 (1.2247) ce_loss 1.3311 (1.1072) teacher_loss 1.3332 (1.1054) loss_zs_kd 0.1989 (0.1692) loss_oracle 0.0306 (0.0346) acc 56.2500 (69.8828) kd_loss 0.0276 (0.0309) lr 1.3090e-03 eta 0:12:57
epoch [22/50] batch [100/246] time 0.109 (0.109) data 0.000 (0.003) loss 0.7783 (1.2031) ce_loss 0.7080 (1.0881) teacher_loss 0.6724 (1.0861) loss_zs_kd 0.1344 (0.1658) loss_oracle 0.0387 (0.0341) acc 87.5000 (70.2188) kd_loss 0.0321 (0.0305) lr 1.3090e-03 eta 0:12:45
epoch [22/50] batch [120/246] time 0.097 (0.108) data 0.000 (0.002) loss 1.1965 (1.1939) ce_loss 1.0811 (1.0802) teacher_loss 1.0764 (1.0782) loss_zs_kd 0.1621 (0.1639) loss_oracle 0.0390 (0.0338) acc 68.7500 (70.7812) kd_loss 0.0375 (0.0301) lr 1.3090e-03 eta 0:12:34
epoch [22/50] batch [140/246] time 0.097 (0.107) data 0.000 (0.002) loss 1.1039 (1.1899) ce_loss 0.9668 (1.0766) teacher_loss 0.9618 (1.0748) loss_zs_kd 0.1990 (0.1633) loss_oracle 0.0426 (0.0335) acc 81.2500 (71.2277) kd_loss 0.0256 (0.0294) lr 1.3090e-03 eta 0:12:28
epoch [22/50] batch [160/246] time 0.097 (0.106) data 0.000 (0.002) loss 0.9548 (1.1845) ce_loss 0.8594 (1.0728) teacher_loss 0.8552 (1.0712) loss_zs_kd 0.1180 (0.1594) loss_oracle 0.0406 (0.0336) acc 75.0000 (71.4258) kd_loss 0.0370 (0.0289) lr 1.3090e-03 eta 0:12:21
epoch [22/50] batch [180/246] time 0.097 (0.106) data 0.000 (0.002) loss 1.4656 (1.1847) ce_loss 1.3242 (1.0725) teacher_loss 1.3279 (1.0710) loss_zs_kd 0.1937 (0.1603) loss_oracle 0.0408 (0.0336) acc 59.3750 (71.4757) kd_loss 0.0317 (0.0284) lr 1.3090e-03 eta 0:12:15
epoch [22/50] batch [200/246] time 0.100 (0.105) data 0.001 (0.002) loss 1.3187 (1.1872) ce_loss 1.1699 (1.0746) teacher_loss 1.1724 (1.0730) loss_zs_kd 0.2169 (0.1609) loss_oracle 0.0378 (0.0337) acc 68.7500 (71.4062) kd_loss 0.0369 (0.0283) lr 1.3090e-03 eta 0:12:10
epoch [22/50] batch [220/246] time 0.097 (0.105) data 0.000 (0.001) loss 1.4387 (1.1929) ce_loss 1.3086 (1.0805) teacher_loss 1.3037 (1.0789) loss_zs_kd 0.1911 (0.1604) loss_oracle 0.0395 (0.0338) acc 68.7500 (71.3636) kd_loss 0.0340 (0.0282) lr 1.3090e-03 eta 0:12:06
epoch [22/50] batch [240/246] time 0.106 (0.105) data 0.000 (0.001) loss 0.9749 (1.1980) ce_loss 0.8633 (1.0851) teacher_loss 0.8647 (1.0836) loss_zs_kd 0.1525 (0.1613) loss_oracle 0.0339 (0.0338) acc 78.1250 (71.2630) kd_loss 0.0277 (0.0280) lr 1.3090e-03 eta 0:12:03
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,847
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,951
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [23/50] batch [20/246] time 0.125 (0.141) data 0.000 (0.015) loss 1.0679 (1.2103) ce_loss 0.9448 (1.0927) teacher_loss 0.9429 (1.0916) loss_zs_kd 0.1679 (0.1702) loss_oracle 0.0411 (0.0336) acc 71.8750 (69.3750) kd_loss 0.0272 (0.0251) lr 1.2487e-03 eta 0:16:05
epoch [23/50] batch [40/246] time 0.132 (0.135) data 0.000 (0.008) loss 1.4073 (1.2386) ce_loss 1.3018 (1.1220) teacher_loss 1.3069 (1.1200) loss_zs_kd 0.1470 (0.1685) loss_oracle 0.0269 (0.0344) acc 62.5000 (69.3750) kd_loss 0.0155 (0.0252) lr 1.2487e-03 eta 0:15:21
epoch [23/50] batch [60/246] time 0.112 (0.127) data 0.001 (0.005) loss 1.2473 (1.2231) ce_loss 1.0957 (1.1064) teacher_loss 1.0920 (1.1046) loss_zs_kd 0.2348 (0.1682) loss_oracle 0.0379 (0.0344) acc 68.7500 (70.3646) kd_loss 0.0276 (0.0257) lr 1.2487e-03 eta 0:14:30
epoch [23/50] batch [80/246] time 0.121 (0.123) data 0.000 (0.004) loss 0.9494 (1.2452) ce_loss 0.8403 (1.1311) teacher_loss 0.8406 (1.1292) loss_zs_kd 0.1706 (0.1632) loss_oracle 0.0235 (0.0343) acc 84.3750 (69.6875) kd_loss 0.0251 (0.0260) lr 1.2487e-03 eta 0:13:55
epoch [23/50] batch [100/246] time 0.106 (0.121) data 0.000 (0.003) loss 1.0752 (1.2266) ce_loss 0.9512 (1.1136) teacher_loss 0.9523 (1.1116) loss_zs_kd 0.1881 (0.1626) loss_oracle 0.0288 (0.0337) acc 81.2500 (70.3125) kd_loss 0.0205 (0.0254) lr 1.2487e-03 eta 0:13:42
epoch [23/50] batch [120/246] time 0.099 (0.117) data 0.000 (0.003) loss 0.9430 (1.2058) ce_loss 0.8237 (1.0921) teacher_loss 0.8203 (1.0902) loss_zs_kd 0.1549 (0.1636) loss_oracle 0.0453 (0.0338) acc 71.8750 (70.9896) kd_loss 0.0407 (0.0257) lr 1.2487e-03 eta 0:13:14
epoch [23/50] batch [140/246] time 0.096 (0.115) data 0.000 (0.002) loss 0.9541 (1.2049) ce_loss 0.8535 (1.0897) teacher_loss 0.8523 (1.0882) loss_zs_kd 0.1314 (0.1656) loss_oracle 0.0361 (0.0339) acc 78.1250 (71.1384) kd_loss 0.0334 (0.0259) lr 1.2487e-03 eta 0:12:54
epoch [23/50] batch [160/246] time 0.096 (0.113) data 0.000 (0.002) loss 1.4814 (1.2062) ce_loss 1.3818 (1.0912) teacher_loss 1.3848 (1.0898) loss_zs_kd 0.1289 (0.1641) loss_oracle 0.0321 (0.0344) acc 62.5000 (70.9570) kd_loss 0.0195 (0.0265) lr 1.2487e-03 eta 0:12:37
epoch [23/50] batch [180/246] time 0.098 (0.111) data 0.000 (0.002) loss 0.9927 (1.1966) ce_loss 0.8652 (1.0810) teacher_loss 0.8772 (1.0796) loss_zs_kd 0.1751 (0.1642) loss_oracle 0.0280 (0.0349) acc 78.1250 (71.0417) kd_loss 0.0205 (0.0271) lr 1.2487e-03 eta 0:12:23
epoch [23/50] batch [200/246] time 0.097 (0.110) data 0.000 (0.002) loss 1.5941 (1.1911) ce_loss 1.4824 (1.0755) teacher_loss 1.4854 (1.0741) loss_zs_kd 0.1679 (0.1643) loss_oracle 0.0247 (0.0349) acc 59.3750 (71.2031) kd_loss 0.0246 (0.0273) lr 1.2487e-03 eta 0:12:12
epoch [23/50] batch [220/246] time 0.094 (0.108) data 0.000 (0.002) loss 1.2089 (1.1925) ce_loss 1.0879 (1.0767) teacher_loss 1.0842 (1.0752) loss_zs_kd 0.1775 (0.1646) loss_oracle 0.0360 (0.0350) acc 75.0000 (71.0938) kd_loss 0.0372 (0.0274) lr 1.2487e-03 eta 0:12:03
epoch [23/50] batch [240/246] time 0.104 (0.108) data 0.000 (0.002) loss 0.8450 (1.1947) ce_loss 0.7715 (1.0790) teacher_loss 0.7517 (1.0776) loss_zs_kd 0.1055 (0.1645) loss_oracle 0.0406 (0.0349) acc 78.1250 (71.0938) kd_loss 0.0375 (0.0276) lr 1.2487e-03 eta 0:11:56
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,847
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [24/50] batch [20/246] time 0.088 (0.124) data 0.000 (0.019) loss 1.2122 (1.1616) ce_loss 1.1064 (1.0435) teacher_loss 1.1067 (1.0438) loss_zs_kd 0.1656 (0.1699) loss_oracle 0.0226 (0.0328) acc 78.1250 (71.4062) kd_loss 0.0315 (0.0311) lr 1.1874e-03 eta 0:13:40
epoch [24/50] batch [40/246] time 0.090 (0.108) data 0.000 (0.010) loss 1.3472 (1.1953) ce_loss 1.1982 (1.0778) teacher_loss 1.1985 (1.0748) loss_zs_kd 0.2370 (0.1722) loss_oracle 0.0302 (0.0344) acc 65.6250 (71.3281) kd_loss 0.0247 (0.0322) lr 1.1874e-03 eta 0:11:54
epoch [24/50] batch [60/246] time 0.083 (0.103) data 0.001 (0.007) loss 1.3307 (1.1920) ce_loss 1.2285 (1.0740) teacher_loss 1.2243 (1.0709) loss_zs_kd 0.1404 (0.1723) loss_oracle 0.0362 (0.0350) acc 68.7500 (71.6667) kd_loss 0.0292 (0.0312) lr 1.1874e-03 eta 0:11:14
epoch [24/50] batch [80/246] time 0.095 (0.099) data 0.000 (0.005) loss 1.1737 (1.2129) ce_loss 1.0293 (1.0916) teacher_loss 1.0274 (1.0884) loss_zs_kd 0.2266 (0.1778) loss_oracle 0.0330 (0.0356) acc 71.8750 (71.4062) kd_loss 0.0238 (0.0311) lr 1.1874e-03 eta 0:10:52
epoch [24/50] batch [100/246] time 0.089 (0.098) data 0.000 (0.004) loss 1.3984 (1.2226) ce_loss 1.2627 (1.1020) teacher_loss 1.2739 (1.0992) loss_zs_kd 0.1674 (0.1754) loss_oracle 0.0408 (0.0358) acc 71.8750 (71.3438) kd_loss 0.0393 (0.0309) lr 1.1874e-03 eta 0:10:43
epoch [24/50] batch [120/246] time 0.087 (0.097) data 0.000 (0.003) loss 1.1422 (1.1932) ce_loss 1.0127 (1.0717) teacher_loss 1.0118 (1.0691) loss_zs_kd 0.2157 (0.1759) loss_oracle 0.0226 (0.0361) acc 75.0000 (71.9531) kd_loss 0.0203 (0.0315) lr 1.1874e-03 eta 0:10:31
epoch [24/50] batch [140/246] time 0.081 (0.096) data 0.000 (0.003) loss 1.0183 (1.1925) ce_loss 0.9058 (1.0722) teacher_loss 0.9041 (1.0694) loss_zs_kd 0.1574 (0.1739) loss_oracle 0.0355 (0.0361) acc 81.2500 (72.1875) kd_loss 0.0328 (0.0314) lr 1.1874e-03 eta 0:10:21
epoch [24/50] batch [160/246] time 0.094 (0.095) data 0.000 (0.003) loss 1.3008 (1.1954) ce_loss 1.1582 (1.0755) teacher_loss 1.1578 (1.0728) loss_zs_kd 0.2203 (0.1734) loss_oracle 0.0328 (0.0359) acc 65.6250 (72.1094) kd_loss 0.0277 (0.0309) lr 1.1874e-03 eta 0:10:13
epoch [24/50] batch [180/246] time 0.093 (0.095) data 0.000 (0.002) loss 1.6955 (1.1954) ce_loss 1.5547 (1.0755) teacher_loss 1.5566 (1.0730) loss_zs_kd 0.2029 (0.1729) loss_oracle 0.0375 (0.0360) acc 59.3750 (72.1354) kd_loss 0.0234 (0.0306) lr 1.1874e-03 eta 0:10:11
epoch [24/50] batch [200/246] time 0.093 (0.095) data 0.000 (0.002) loss 1.6915 (1.2115) ce_loss 1.5752 (1.0922) teacher_loss 1.5814 (1.0899) loss_zs_kd 0.1589 (0.1712) loss_oracle 0.0306 (0.0360) acc 53.1250 (71.4219) kd_loss 0.0218 (0.0302) lr 1.1874e-03 eta 0:10:11
epoch [24/50] batch [220/246] time 0.100 (0.095) data 0.000 (0.002) loss 1.4687 (1.2099) ce_loss 1.3418 (1.0911) teacher_loss 1.3511 (1.0886) loss_zs_kd 0.1544 (0.1697) loss_oracle 0.0404 (0.0365) acc 59.3750 (71.4773) kd_loss 0.0319 (0.0299) lr 1.1874e-03 eta 0:10:08
epoch [24/50] batch [240/246] time 0.085 (0.095) data 0.000 (0.002) loss 1.1888 (1.2065) ce_loss 1.0645 (1.0876) teacher_loss 1.0598 (1.0851) loss_zs_kd 0.1696 (0.1695) loss_oracle 0.0442 (0.0366) acc 68.7500 (71.4974) kd_loss 0.0278 (0.0296) lr 1.1874e-03 eta 0:10:05
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,850
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.1%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,950
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      85.0%, epoch: 24 *******
******* Domain r best val test acc: 90.7%, epoch: 24 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [25/50] batch [20/246] time 0.093 (0.112) data 0.000 (0.013) loss 1.0510 (1.1995) ce_loss 0.9263 (1.0798) teacher_loss 0.9293 (1.0765) loss_zs_kd 0.1700 (0.1639) loss_oracle 0.0368 (0.0410) acc 75.0000 (71.5625) kd_loss 0.0301 (0.0309) lr 1.1253e-03 eta 0:11:55
epoch [25/50] batch [40/246] time 0.093 (0.103) data 0.000 (0.007) loss 1.0451 (1.1610) ce_loss 0.9219 (1.0404) teacher_loss 0.9186 (1.0378) loss_zs_kd 0.1659 (0.1619) loss_oracle 0.0437 (0.0422) acc 75.0000 (71.3281) kd_loss 0.0317 (0.0288) lr 1.1253e-03 eta 0:10:53
epoch [25/50] batch [60/246] time 0.095 (0.100) data 0.000 (0.005) loss 1.7940 (1.1959) ce_loss 1.6689 (1.0761) teacher_loss 1.6699 (1.0732) loss_zs_kd 0.1729 (0.1635) loss_oracle 0.0376 (0.0409) acc 56.2500 (70.7292) kd_loss 0.0302 (0.0281) lr 1.1253e-03 eta 0:10:34
epoch [25/50] batch [80/246] time 0.100 (0.101) data 0.000 (0.004) loss 1.0945 (1.1899) ce_loss 1.0059 (1.0708) teacher_loss 0.9981 (1.0681) loss_zs_kd 0.1227 (0.1632) loss_oracle 0.0350 (0.0403) acc 71.8750 (70.7812) kd_loss 0.0268 (0.0282) lr 1.1253e-03 eta 0:10:40
epoch [25/50] batch [100/246] time 0.102 (0.103) data 0.000 (0.003) loss 0.9312 (1.1955) ce_loss 0.8237 (1.0763) teacher_loss 0.8215 (1.0744) loss_zs_kd 0.1532 (0.1630) loss_oracle 0.0330 (0.0397) acc 81.2500 (70.9688) kd_loss 0.0254 (0.0281) lr 1.1253e-03 eta 0:10:47
epoch [25/50] batch [120/246] time 0.089 (0.102) data 0.001 (0.003) loss 1.2066 (1.2159) ce_loss 1.0967 (1.0960) teacher_loss 1.0956 (1.0934) loss_zs_kd 0.1682 (0.1655) loss_oracle 0.0268 (0.0398) acc 78.1250 (70.5208) kd_loss 0.0196 (0.0290) lr 1.1253e-03 eta 0:10:43
epoch [25/50] batch [140/246] time 0.096 (0.102) data 0.000 (0.002) loss 1.1116 (1.2098) ce_loss 0.9849 (1.0895) teacher_loss 0.9791 (1.0872) loss_zs_kd 0.1803 (0.1657) loss_oracle 0.0423 (0.0397) acc 78.1250 (71.1830) kd_loss 0.0386 (0.0290) lr 1.1253e-03 eta 0:10:40
epoch [25/50] batch [160/246] time 0.103 (0.103) data 0.001 (0.002) loss 1.4605 (1.2179) ce_loss 1.3496 (1.0982) teacher_loss 1.3571 (1.0962) loss_zs_kd 0.1527 (0.1644) loss_oracle 0.0270 (0.0395) acc 65.6250 (70.9766) kd_loss 0.0251 (0.0290) lr 1.1253e-03 eta 0:10:40
epoch [25/50] batch [180/246] time 0.110 (0.103) data 0.000 (0.002) loss 1.0786 (1.2169) ce_loss 0.9756 (1.0977) teacher_loss 0.9691 (1.0955) loss_zs_kd 0.1395 (0.1638) loss_oracle 0.0397 (0.0395) acc 75.0000 (71.0938) kd_loss 0.0278 (0.0297) lr 1.1253e-03 eta 0:10:41
epoch [25/50] batch [200/246] time 0.103 (0.103) data 0.000 (0.002) loss 1.0630 (1.2066) ce_loss 0.9116 (1.0880) teacher_loss 0.9169 (1.0857) loss_zs_kd 0.2202 (0.1635) loss_oracle 0.0359 (0.0391) acc 75.0000 (71.2812) kd_loss 0.0303 (0.0298) lr 1.1253e-03 eta 0:10:40
epoch [25/50] batch [220/246] time 0.100 (0.104) data 0.000 (0.002) loss 1.2805 (1.1997) ce_loss 1.1826 (1.0812) teacher_loss 1.1759 (1.0789) loss_zs_kd 0.1391 (0.1632) loss_oracle 0.0350 (0.0392) acc 71.8750 (71.6619) kd_loss 0.0340 (0.0303) lr 1.1253e-03 eta 0:10:40
epoch [25/50] batch [240/246] time 0.101 (0.104) data 0.000 (0.001) loss 1.0097 (1.2033) ce_loss 0.8901 (1.0844) teacher_loss 0.8885 (1.0820) loss_zs_kd 0.1533 (0.1640) loss_oracle 0.0446 (0.0393) acc 78.1250 (71.4453) kd_loss 0.0342 (0.0308) lr 1.1253e-03 eta 0:10:37
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,859
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,941
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.4%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [26/50] batch [20/246] time 0.095 (0.121) data 0.000 (0.017) loss 1.1556 (1.2435) ce_loss 1.0439 (1.1243) teacher_loss 1.0472 (1.1224) loss_zs_kd 0.1582 (0.1621) loss_oracle 0.0293 (0.0401) acc 65.6250 (69.6875) kd_loss 0.0175 (0.0351) lr 1.0628e-03 eta 0:12:21
epoch [26/50] batch [40/246] time 0.082 (0.109) data 0.000 (0.008) loss 1.1397 (1.1581) ce_loss 1.0410 (1.0404) teacher_loss 1.0361 (1.0394) loss_zs_kd 0.1515 (0.1610) loss_oracle 0.0278 (0.0382) acc 75.0000 (71.7969) kd_loss 0.0282 (0.0370) lr 1.0628e-03 eta 0:11:06
epoch [26/50] batch [60/246] time 0.092 (0.103) data 0.000 (0.006) loss 1.1378 (1.1584) ce_loss 1.0205 (1.0395) teacher_loss 1.0250 (1.0379) loss_zs_kd 0.1620 (0.1667) loss_oracle 0.0318 (0.0372) acc 65.6250 (71.7708) kd_loss 0.0374 (0.0379) lr 1.0628e-03 eta 0:10:26
epoch [26/50] batch [80/246] time 0.081 (0.100) data 0.000 (0.004) loss 1.1546 (1.1733) ce_loss 1.0498 (1.0564) teacher_loss 1.0536 (1.0543) loss_zs_kd 0.1263 (0.1636) loss_oracle 0.0378 (0.0372) acc 75.0000 (71.5625) kd_loss 0.0413 (0.0375) lr 1.0628e-03 eta 0:10:06
epoch [26/50] batch [100/246] time 0.088 (0.098) data 0.000 (0.003) loss 1.4300 (1.1904) ce_loss 1.2861 (1.0714) teacher_loss 1.2819 (1.0691) loss_zs_kd 0.1984 (0.1671) loss_oracle 0.0488 (0.0377) acc 68.7500 (71.3125) kd_loss 0.0446 (0.0378) lr 1.0628e-03 eta 0:09:50
epoch [26/50] batch [120/246] time 0.091 (0.096) data 0.000 (0.003) loss 1.6899 (1.2116) ce_loss 1.5645 (1.0929) teacher_loss 1.5675 (1.0908) loss_zs_kd 0.1893 (0.1674) loss_oracle 0.0277 (0.0370) acc 62.5000 (70.8854) kd_loss 0.0251 (0.0367) lr 1.0628e-03 eta 0:09:39
epoch [26/50] batch [140/246] time 0.097 (0.096) data 0.000 (0.003) loss 1.1500 (1.2182) ce_loss 1.0459 (1.1003) teacher_loss 1.0528 (1.0982) loss_zs_kd 0.1255 (0.1667) loss_oracle 0.0344 (0.0366) acc 75.0000 (70.8259) kd_loss 0.0403 (0.0361) lr 1.0628e-03 eta 0:09:39
epoch [26/50] batch [160/246] time 0.097 (0.096) data 0.000 (0.002) loss 1.1711 (1.2146) ce_loss 1.0488 (1.0973) teacher_loss 1.0512 (1.0949) loss_zs_kd 0.1713 (0.1648) loss_oracle 0.0342 (0.0373) acc 68.7500 (70.7031) kd_loss 0.0391 (0.0361) lr 1.0628e-03 eta 0:09:37
epoch [26/50] batch [180/246] time 0.103 (0.097) data 0.001 (0.002) loss 1.1427 (1.2061) ce_loss 1.0039 (1.0877) teacher_loss 1.0048 (1.0854) loss_zs_kd 0.1703 (0.1656) loss_oracle 0.0527 (0.0380) acc 62.5000 (70.9028) kd_loss 0.0338 (0.0359) lr 1.0628e-03 eta 0:09:37
epoch [26/50] batch [200/246] time 0.101 (0.097) data 0.000 (0.002) loss 0.8632 (1.1982) ce_loss 0.7319 (1.0806) teacher_loss 0.7331 (1.0784) loss_zs_kd 0.1673 (0.1641) loss_oracle 0.0464 (0.0377) acc 81.2500 (71.1562) kd_loss 0.0475 (0.0353) lr 1.0628e-03 eta 0:09:37
epoch [26/50] batch [220/246] time 0.097 (0.097) data 0.000 (0.002) loss 1.8362 (1.2142) ce_loss 1.7178 (1.0966) teacher_loss 1.6971 (1.0945) loss_zs_kd 0.2034 (0.1646) loss_oracle 0.0375 (0.0374) acc 62.5000 (70.8665) kd_loss 0.0346 (0.0350) lr 1.0628e-03 eta 0:09:35
epoch [26/50] batch [240/246] time 0.101 (0.097) data 0.000 (0.002) loss 1.0997 (1.2131) ce_loss 1.0107 (1.0957) teacher_loss 1.0141 (1.0936) loss_zs_kd 0.1101 (0.1645) loss_oracle 0.0306 (0.0373) acc 75.0000 (70.8073) kd_loss 0.0270 (0.0347) lr 1.0628e-03 eta 0:09:33
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,851
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [27/50] batch [20/246] time 0.098 (0.116) data 0.000 (0.014) loss 0.8051 (1.1315) ce_loss 0.6943 (1.0192) teacher_loss 0.6917 (1.0165) loss_zs_kd 0.1503 (0.1571) loss_oracle 0.0383 (0.0364) acc 78.1250 (72.5000) kd_loss 0.0346 (0.0350) lr 1.0000e-03 eta 0:11:23
epoch [27/50] batch [40/246] time 0.098 (0.110) data 0.001 (0.007) loss 0.8898 (1.1270) ce_loss 0.7578 (1.0136) teacher_loss 0.7546 (1.0107) loss_zs_kd 0.1536 (0.1581) loss_oracle 0.0583 (0.0373) acc 78.1250 (72.3438) kd_loss 0.0492 (0.0338) lr 1.0000e-03 eta 0:10:43
epoch [27/50] batch [60/246] time 0.097 (0.107) data 0.001 (0.005) loss 1.1371 (1.1623) ce_loss 0.9868 (1.0453) teacher_loss 0.9811 (1.0412) loss_zs_kd 0.2198 (0.1643) loss_oracle 0.0460 (0.0389) acc 75.0000 (71.6667) kd_loss 0.0499 (0.0360) lr 1.0000e-03 eta 0:10:25
epoch [27/50] batch [80/246] time 0.110 (0.106) data 0.001 (0.004) loss 1.1592 (1.1881) ce_loss 1.0479 (1.0704) teacher_loss 1.0422 (1.0676) loss_zs_kd 0.1646 (0.1638) loss_oracle 0.0347 (0.0386) acc 65.6250 (71.2891) kd_loss 0.0363 (0.0350) lr 1.0000e-03 eta 0:10:17
epoch [27/50] batch [100/246] time 0.099 (0.106) data 0.000 (0.003) loss 1.2325 (1.1833) ce_loss 1.0830 (1.0643) teacher_loss 1.0915 (1.0615) loss_zs_kd 0.2240 (0.1659) loss_oracle 0.0290 (0.0389) acc 75.0000 (71.6562) kd_loss 0.0203 (0.0348) lr 1.0000e-03 eta 0:10:12
epoch [27/50] batch [120/246] time 0.131 (0.107) data 0.000 (0.003) loss 1.1530 (1.1952) ce_loss 1.0234 (1.0752) teacher_loss 1.0093 (1.0725) loss_zs_kd 0.1592 (0.1665) loss_oracle 0.0641 (0.0395) acc 75.0000 (71.3281) kd_loss 0.0502 (0.0346) lr 1.0000e-03 eta 0:10:21
epoch [27/50] batch [140/246] time 0.127 (0.110) data 0.000 (0.002) loss 1.1816 (1.1952) ce_loss 1.0918 (1.0735) teacher_loss 1.0887 (1.0709) loss_zs_kd 0.0993 (0.1678) loss_oracle 0.0433 (0.0404) acc 65.6250 (71.2054) kd_loss 0.0433 (0.0347) lr 1.0000e-03 eta 0:10:36
epoch [27/50] batch [160/246] time 0.131 (0.113) data 0.000 (0.002) loss 1.2564 (1.1802) ce_loss 1.1260 (1.0574) teacher_loss 1.1198 (1.0553) loss_zs_kd 0.1655 (0.1669) loss_oracle 0.0538 (0.0414) acc 71.8750 (71.6992) kd_loss 0.0517 (0.0353) lr 1.0000e-03 eta 0:10:47
epoch [27/50] batch [180/246] time 0.133 (0.115) data 0.000 (0.002) loss 1.3421 (1.1849) ce_loss 1.2373 (1.0609) teacher_loss 1.2396 (1.0587) loss_zs_kd 0.1162 (0.1684) loss_oracle 0.0444 (0.0420) acc 68.7500 (71.8056) kd_loss 0.0381 (0.0358) lr 1.0000e-03 eta 0:10:56
epoch [27/50] batch [200/246] time 0.122 (0.116) data 0.000 (0.002) loss 1.0140 (1.1843) ce_loss 0.8252 (1.0590) teacher_loss 0.8396 (1.0570) loss_zs_kd 0.2454 (0.1696) loss_oracle 0.0517 (0.0425) acc 75.0000 (71.7031) kd_loss 0.0528 (0.0364) lr 1.0000e-03 eta 0:11:03
epoch [27/50] batch [220/246] time 0.126 (0.117) data 0.000 (0.002) loss 1.2242 (1.1847) ce_loss 1.0791 (1.0593) teacher_loss 1.0551 (1.0568) loss_zs_kd 0.1949 (0.1699) loss_oracle 0.0716 (0.0429) acc 71.8750 (71.7330) kd_loss 0.0647 (0.0373) lr 1.0000e-03 eta 0:11:06
epoch [27/50] batch [240/246] time 0.109 (0.118) data 0.000 (0.002) loss 0.7873 (1.1837) ce_loss 0.6460 (1.0580) teacher_loss 0.6497 (1.0555) loss_zs_kd 0.1988 (0.1703) loss_oracle 0.0382 (0.0431) acc 84.3750 (71.7188) kd_loss 0.0405 (0.0382) lr 1.0000e-03 eta 0:11:06
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,854
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [28/50] batch [20/246] time 0.101 (0.119) data 0.001 (0.015) loss 1.1142 (1.1647) ce_loss 0.9756 (1.0463) teacher_loss 0.9738 (1.0421) loss_zs_kd 0.1850 (0.1625) loss_oracle 0.0480 (0.0414) acc 78.1250 (73.4375) kd_loss 0.0479 (0.0451) lr 9.3721e-04 eta 0:11:08
epoch [28/50] batch [40/246] time 0.102 (0.110) data 0.002 (0.008) loss 1.0559 (1.1818) ce_loss 0.9341 (1.0569) teacher_loss 0.9365 (1.0541) loss_zs_kd 0.1530 (0.1717) loss_oracle 0.0429 (0.0419) acc 71.8750 (72.3438) kd_loss 0.0315 (0.0433) lr 9.3721e-04 eta 0:10:19
epoch [28/50] batch [60/246] time 0.139 (0.109) data 0.001 (0.005) loss 1.1158 (1.1802) ce_loss 1.0117 (1.0573) teacher_loss 1.0089 (1.0545) loss_zs_kd 0.1200 (0.1653) loss_oracle 0.0468 (0.0431) acc 78.1250 (72.2917) kd_loss 0.0380 (0.0435) lr 9.3721e-04 eta 0:10:09
epoch [28/50] batch [80/246] time 0.126 (0.114) data 0.000 (0.004) loss 1.7524 (1.1945) ce_loss 1.6250 (1.0715) teacher_loss 1.6186 (1.0693) loss_zs_kd 0.1764 (0.1623) loss_oracle 0.0456 (0.0440) acc 56.2500 (71.5625) kd_loss 0.0374 (0.0428) lr 9.3721e-04 eta 0:10:35
epoch [28/50] batch [100/246] time 0.135 (0.117) data 0.000 (0.003) loss 1.1239 (1.1875) ce_loss 1.0068 (1.0634) teacher_loss 0.9971 (1.0614) loss_zs_kd 0.1547 (0.1627) loss_oracle 0.0495 (0.0447) acc 75.0000 (71.5938) kd_loss 0.0597 (0.0434) lr 9.3721e-04 eta 0:10:51
epoch [28/50] batch [120/246] time 0.126 (0.120) data 0.000 (0.003) loss 1.0354 (1.2076) ce_loss 0.9194 (1.0824) teacher_loss 0.9095 (1.0799) loss_zs_kd 0.1538 (0.1656) loss_oracle 0.0491 (0.0449) acc 78.1250 (70.9635) kd_loss 0.0613 (0.0434) lr 9.3721e-04 eta 0:11:01
epoch [28/50] batch [140/246] time 0.105 (0.121) data 0.000 (0.002) loss 0.8943 (1.2015) ce_loss 0.7686 (1.0751) teacher_loss 0.7510 (1.0726) loss_zs_kd 0.1617 (0.1674) loss_oracle 0.0624 (0.0452) acc 81.2500 (71.1384) kd_loss 0.0540 (0.0432) lr 9.3721e-04 eta 0:11:05
epoch [28/50] batch [160/246] time 0.098 (0.118) data 0.000 (0.002) loss 1.5253 (1.2039) ce_loss 1.3945 (1.0768) teacher_loss 1.3662 (1.0742) loss_zs_kd 0.2083 (0.1689) loss_oracle 0.0550 (0.0452) acc 65.6250 (70.8789) kd_loss 0.0433 (0.0427) lr 9.3721e-04 eta 0:10:50
epoch [28/50] batch [180/246] time 0.104 (0.116) data 0.000 (0.002) loss 1.1421 (1.2046) ce_loss 1.0137 (1.0774) teacher_loss 1.0085 (1.0749) loss_zs_kd 0.1883 (0.1695) loss_oracle 0.0394 (0.0450) acc 81.2500 (71.0069) kd_loss 0.0439 (0.0421) lr 9.3721e-04 eta 0:10:36
epoch [28/50] batch [200/246] time 0.093 (0.115) data 0.000 (0.002) loss 1.2830 (1.2019) ce_loss 1.1465 (1.0749) teacher_loss 1.1479 (1.0721) loss_zs_kd 0.1845 (0.1698) loss_oracle 0.0428 (0.0448) acc 62.5000 (71.0156) kd_loss 0.0448 (0.0412) lr 9.3721e-04 eta 0:10:25
epoch [28/50] batch [220/246] time 0.096 (0.113) data 0.000 (0.002) loss 1.0879 (1.2036) ce_loss 0.9673 (1.0764) teacher_loss 0.9663 (1.0735) loss_zs_kd 0.1606 (0.1709) loss_oracle 0.0412 (0.0447) acc 71.8750 (71.0938) kd_loss 0.0397 (0.0408) lr 9.3721e-04 eta 0:10:14
epoch [28/50] batch [240/246] time 0.087 (0.111) data 0.000 (0.002) loss 1.0553 (1.2104) ce_loss 0.9819 (1.0830) teacher_loss 0.9467 (1.0800) loss_zs_kd 0.1152 (0.1716) loss_oracle 0.0510 (0.0446) acc 71.8750 (70.8594) kd_loss 0.0304 (0.0404) lr 9.3721e-04 eta 0:10:02
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,843
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [29/50] batch [20/246] time 0.094 (0.119) data 0.000 (0.018) loss 1.0996 (1.2434) ce_loss 0.9751 (1.1183) teacher_loss 0.9672 (1.1119) loss_zs_kd 0.1757 (0.1750) loss_oracle 0.0446 (0.0439) acc 75.0000 (70.7812) kd_loss 0.0347 (0.0357) lr 8.7467e-04 eta 0:10:43
epoch [29/50] batch [40/246] time 0.095 (0.107) data 0.000 (0.009) loss 1.2124 (1.1857) ce_loss 1.0693 (1.0607) teacher_loss 1.0700 (1.0551) loss_zs_kd 0.1917 (0.1728) loss_oracle 0.0465 (0.0442) acc 71.8750 (72.3438) kd_loss 0.0398 (0.0356) lr 8.7467e-04 eta 0:09:36
epoch [29/50] batch [60/246] time 0.089 (0.103) data 0.001 (0.006) loss 2.0672 (1.1991) ce_loss 1.9404 (1.0738) teacher_loss 1.9412 (1.0694) loss_zs_kd 0.1764 (0.1721) loss_oracle 0.0378 (0.0437) acc 46.8750 (72.0312) kd_loss 0.0367 (0.0361) lr 8.7467e-04 eta 0:09:11
epoch [29/50] batch [80/246] time 0.104 (0.101) data 0.001 (0.005) loss 0.7939 (1.1945) ce_loss 0.6919 (1.0699) teacher_loss 0.6881 (1.0654) loss_zs_kd 0.1400 (0.1704) loss_oracle 0.0358 (0.0439) acc 75.0000 (71.9922) kd_loss 0.0225 (0.0360) lr 8.7467e-04 eta 0:08:58
epoch [29/50] batch [100/246] time 0.096 (0.100) data 0.000 (0.004) loss 1.2615 (1.1996) ce_loss 1.1670 (1.0754) teacher_loss 1.1635 (1.0710) loss_zs_kd 0.0974 (0.1697) loss_oracle 0.0493 (0.0438) acc 68.7500 (71.6875) kd_loss 0.0310 (0.0356) lr 8.7467e-04 eta 0:08:50
epoch [29/50] batch [120/246] time 0.100 (0.099) data 0.000 (0.003) loss 1.2579 (1.1941) ce_loss 1.0791 (1.0694) teacher_loss 1.0835 (1.0652) loss_zs_kd 0.2455 (0.1687) loss_oracle 0.0516 (0.0446) acc 75.0000 (71.8490) kd_loss 0.0358 (0.0360) lr 8.7467e-04 eta 0:08:45
epoch [29/50] batch [140/246] time 0.098 (0.099) data 0.000 (0.003) loss 1.5895 (1.1897) ce_loss 1.4688 (1.0641) teacher_loss 1.4631 (1.0597) loss_zs_kd 0.1579 (0.1691) loss_oracle 0.0475 (0.0455) acc 53.1250 (72.0312) kd_loss 0.0436 (0.0367) lr 8.7467e-04 eta 0:08:42
epoch [29/50] batch [160/246] time 0.098 (0.099) data 0.000 (0.002) loss 1.1293 (1.1890) ce_loss 1.0273 (1.0634) teacher_loss 1.0102 (1.0591) loss_zs_kd 0.1239 (0.1685) loss_oracle 0.0571 (0.0455) acc 75.0000 (72.1094) kd_loss 0.0490 (0.0369) lr 8.7467e-04 eta 0:08:37
epoch [29/50] batch [180/246] time 0.101 (0.099) data 0.000 (0.002) loss 1.8899 (1.1998) ce_loss 1.7441 (1.0743) teacher_loss 1.7369 (1.0700) loss_zs_kd 0.1649 (0.1680) loss_oracle 0.0705 (0.0458) acc 59.3750 (71.8056) kd_loss 0.0624 (0.0373) lr 8.7467e-04 eta 0:08:37
epoch [29/50] batch [200/246] time 0.099 (0.100) data 0.000 (0.002) loss 0.9033 (1.1930) ce_loss 0.7339 (1.0673) teacher_loss 0.7371 (1.0631) loss_zs_kd 0.2369 (0.1672) loss_oracle 0.0477 (0.0462) acc 81.2500 (72.0000) kd_loss 0.0339 (0.0378) lr 8.7467e-04 eta 0:08:38
epoch [29/50] batch [220/246] time 0.110 (0.100) data 0.000 (0.002) loss 1.1673 (1.1922) ce_loss 1.0283 (1.0661) teacher_loss 1.0311 (1.0619) loss_zs_kd 0.1808 (0.1675) loss_oracle 0.0458 (0.0466) acc 71.8750 (71.9176) kd_loss 0.0306 (0.0381) lr 8.7467e-04 eta 0:08:39
epoch [29/50] batch [240/246] time 0.102 (0.100) data 0.000 (0.002) loss 1.0953 (1.1840) ce_loss 1.0000 (1.0580) teacher_loss 0.9981 (1.0541) loss_zs_kd 0.1003 (0.1664) loss_oracle 0.0470 (0.0468) acc 78.1250 (72.1094) kd_loss 0.0452 (0.0385) lr 8.7467e-04 eta 0:08:39
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,853
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [30/50] batch [20/246] time 0.131 (0.144) data 0.000 (0.015) loss 1.0081 (1.2490) ce_loss 0.8613 (1.1190) teacher_loss 0.8607 (1.1101) loss_zs_kd 0.2050 (0.1790) loss_oracle 0.0450 (0.0494) acc 75.0000 (71.4062) kd_loss 0.0347 (0.0488) lr 8.1262e-04 eta 0:12:23
epoch [30/50] batch [40/246] time 0.120 (0.136) data 0.000 (0.008) loss 0.9847 (1.2082) ce_loss 0.8579 (1.0820) teacher_loss 0.8534 (1.0732) loss_zs_kd 0.1557 (0.1708) loss_oracle 0.0534 (0.0496) acc 71.8750 (71.4062) kd_loss 0.0548 (0.0478) lr 8.1262e-04 eta 0:11:35
epoch [30/50] batch [60/246] time 0.121 (0.131) data 0.001 (0.005) loss 1.1231 (1.2230) ce_loss 0.9858 (1.0943) teacher_loss 0.9803 (1.0867) loss_zs_kd 0.2063 (0.1758) loss_oracle 0.0397 (0.0484) acc 65.6250 (70.8854) kd_loss 0.0386 (0.0449) lr 8.1262e-04 eta 0:11:07
epoch [30/50] batch [80/246] time 0.127 (0.128) data 0.000 (0.004) loss 1.0150 (1.2159) ce_loss 0.8633 (1.0856) teacher_loss 0.8640 (1.0793) loss_zs_kd 0.2242 (0.1783) loss_oracle 0.0389 (0.0475) acc 71.8750 (71.1719) kd_loss 0.0378 (0.0430) lr 8.1262e-04 eta 0:10:49
epoch [30/50] batch [100/246] time 0.119 (0.126) data 0.000 (0.003) loss 0.7509 (1.2246) ce_loss 0.6099 (1.0935) teacher_loss 0.6110 (1.0880) loss_zs_kd 0.1624 (0.1778) loss_oracle 0.0587 (0.0477) acc 87.5000 (71.3438) kd_loss 0.0620 (0.0425) lr 8.1262e-04 eta 0:10:35
epoch [30/50] batch [120/246] time 0.111 (0.124) data 0.001 (0.003) loss 1.0042 (1.2404) ce_loss 0.8828 (1.1099) teacher_loss 0.8876 (1.1045) loss_zs_kd 0.1679 (0.1778) loss_oracle 0.0327 (0.0470) acc 78.1250 (71.0938) kd_loss 0.0267 (0.0416) lr 8.1262e-04 eta 0:10:24
epoch [30/50] batch [140/246] time 0.126 (0.123) data 0.001 (0.003) loss 0.9518 (1.2288) ce_loss 0.7817 (1.0992) teacher_loss 0.7704 (1.0939) loss_zs_kd 0.2565 (0.1768) loss_oracle 0.0532 (0.0465) acc 78.1250 (71.4062) kd_loss 0.0440 (0.0412) lr 8.1262e-04 eta 0:10:16
epoch [30/50] batch [160/246] time 0.101 (0.121) data 0.000 (0.002) loss 1.0906 (1.2226) ce_loss 0.9863 (1.0934) teacher_loss 0.9911 (1.0885) loss_zs_kd 0.1048 (0.1754) loss_oracle 0.0471 (0.0464) acc 71.8750 (71.6602) kd_loss 0.0514 (0.0416) lr 8.1262e-04 eta 0:10:07
epoch [30/50] batch [180/246] time 0.112 (0.121) data 0.000 (0.002) loss 0.7190 (1.2185) ce_loss 0.6147 (1.0900) teacher_loss 0.6155 (1.0854) loss_zs_kd 0.0995 (0.1739) loss_oracle 0.0538 (0.0462) acc 84.3750 (71.9618) kd_loss 0.0515 (0.0414) lr 8.1262e-04 eta 0:10:02
epoch [30/50] batch [200/246] time 0.093 (0.119) data 0.000 (0.002) loss 1.1834 (1.2138) ce_loss 1.0439 (1.0846) teacher_loss 1.0418 (1.0802) loss_zs_kd 0.1803 (0.1751) loss_oracle 0.0515 (0.0460) acc 78.1250 (72.0781) kd_loss 0.0428 (0.0414) lr 8.1262e-04 eta 0:09:51
epoch [30/50] batch [220/246] time 0.123 (0.118) data 0.000 (0.002) loss 1.3977 (1.2145) ce_loss 1.2930 (1.0864) teacher_loss 1.2863 (1.0816) loss_zs_kd 0.1515 (0.1738) loss_oracle 0.0356 (0.0459) acc 65.6250 (72.0739) kd_loss 0.0259 (0.0412) lr 8.1262e-04 eta 0:09:43
epoch [30/50] batch [240/246] time 0.103 (0.117) data 0.000 (0.002) loss 0.6964 (1.2120) ce_loss 0.5674 (1.0843) teacher_loss 0.5663 (1.0797) loss_zs_kd 0.1622 (0.1737) loss_oracle 0.0490 (0.0455) acc 87.5000 (72.1094) kd_loss 0.0416 (0.0407) lr 8.1262e-04 eta 0:09:35
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,858
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [31/50] batch [20/246] time 0.097 (0.115) data 0.000 (0.014) loss 0.9192 (1.1088) ce_loss 0.7930 (0.9811) teacher_loss 0.7925 (0.9791) loss_zs_kd 0.1595 (0.1717) loss_oracle 0.0469 (0.0438) acc 75.0000 (74.3750) kd_loss 0.0311 (0.0359) lr 7.5131e-04 eta 0:09:22
epoch [31/50] batch [40/246] time 0.102 (0.109) data 0.000 (0.007) loss 1.2576 (1.1757) ce_loss 1.1758 (1.0484) teacher_loss 1.1654 (1.0455) loss_zs_kd 0.1118 (0.1723) loss_oracle 0.0363 (0.0440) acc 71.8750 (72.4219) kd_loss 0.0201 (0.0346) lr 7.5131e-04 eta 0:08:50
epoch [31/50] batch [60/246] time 0.103 (0.108) data 0.001 (0.005) loss 1.2791 (1.1954) ce_loss 1.1113 (1.0682) teacher_loss 1.1149 (1.0654) loss_zs_kd 0.2284 (0.1711) loss_oracle 0.0501 (0.0444) acc 75.0000 (72.0312) kd_loss 0.0462 (0.0351) lr 7.5131e-04 eta 0:08:45
epoch [31/50] batch [80/246] time 0.108 (0.108) data 0.000 (0.004) loss 0.7014 (1.1879) ce_loss 0.5801 (1.0607) teacher_loss 0.5777 (1.0576) loss_zs_kd 0.1676 (0.1708) loss_oracle 0.0400 (0.0449) acc 90.6250 (72.2266) kd_loss 0.0258 (0.0351) lr 7.5131e-04 eta 0:08:41
epoch [31/50] batch [100/246] time 0.114 (0.108) data 0.000 (0.003) loss 0.8330 (1.1911) ce_loss 0.6987 (1.0618) teacher_loss 0.7002 (1.0594) loss_zs_kd 0.1801 (0.1738) loss_oracle 0.0427 (0.0447) acc 84.3750 (72.2188) kd_loss 0.0435 (0.0349) lr 7.5131e-04 eta 0:08:38
epoch [31/50] batch [120/246] time 0.108 (0.108) data 0.000 (0.002) loss 1.0395 (1.2035) ce_loss 0.9346 (1.0749) teacher_loss 0.9370 (1.0724) loss_zs_kd 0.1201 (0.1728) loss_oracle 0.0425 (0.0447) acc 65.6250 (71.7969) kd_loss 0.0466 (0.0351) lr 7.5131e-04 eta 0:08:36
epoch [31/50] batch [140/246] time 0.116 (0.108) data 0.000 (0.002) loss 1.5343 (1.2148) ce_loss 1.3623 (1.0857) teacher_loss 1.3566 (1.0835) loss_zs_kd 0.2479 (0.1732) loss_oracle 0.0537 (0.0447) acc 71.8750 (71.7857) kd_loss 0.0370 (0.0345) lr 7.5131e-04 eta 0:08:35
epoch [31/50] batch [160/246] time 0.130 (0.111) data 0.000 (0.002) loss 0.9366 (1.2020) ce_loss 0.7949 (1.0720) teacher_loss 0.7782 (1.0695) loss_zs_kd 0.2290 (0.1746) loss_oracle 0.0439 (0.0452) acc 81.2500 (72.0703) kd_loss 0.0343 (0.0341) lr 7.5131e-04 eta 0:08:46
epoch [31/50] batch [180/246] time 0.127 (0.113) data 0.001 (0.002) loss 1.4924 (1.1943) ce_loss 1.3789 (1.0638) teacher_loss 1.3763 (1.0616) loss_zs_kd 0.1338 (0.1747) loss_oracle 0.0492 (0.0453) acc 65.6250 (72.1701) kd_loss 0.0278 (0.0336) lr 7.5131e-04 eta 0:08:54
epoch [31/50] batch [200/246] time 0.123 (0.115) data 0.000 (0.002) loss 1.1986 (1.1994) ce_loss 1.0713 (1.0687) teacher_loss 1.0700 (1.0663) loss_zs_kd 0.1670 (0.1750) loss_oracle 0.0451 (0.0455) acc 71.8750 (71.9531) kd_loss 0.0328 (0.0335) lr 7.5131e-04 eta 0:09:00
epoch [31/50] batch [220/246] time 0.126 (0.116) data 0.000 (0.001) loss 1.0730 (1.2055) ce_loss 0.9111 (1.0749) teacher_loss 0.8923 (1.0724) loss_zs_kd 0.2447 (0.1744) loss_oracle 0.0583 (0.0458) acc 71.8750 (71.8892) kd_loss 0.0338 (0.0336) lr 7.5131e-04 eta 0:09:03
epoch [31/50] batch [240/246] time 0.104 (0.116) data 0.000 (0.001) loss 1.2589 (1.2040) ce_loss 1.1348 (1.0742) teacher_loss 1.1202 (1.0714) loss_zs_kd 0.1404 (0.1732) loss_oracle 0.0685 (0.0460) acc 65.6250 (71.8620) kd_loss 0.0468 (0.0337) lr 7.5131e-04 eta 0:09:01
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,849
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [32/50] batch [20/246] time 0.107 (0.119) data 0.000 (0.015) loss 0.9575 (1.1970) ce_loss 0.8286 (1.0682) teacher_loss 0.8356 (1.0647) loss_zs_kd 0.1402 (0.1683) loss_oracle 0.0518 (0.0482) acc 71.8750 (70.3125) kd_loss 0.0295 (0.0360) lr 6.9098e-04 eta 0:09:11
epoch [32/50] batch [40/246] time 0.094 (0.103) data 0.000 (0.007) loss 0.9789 (1.2238) ce_loss 0.8433 (1.0959) teacher_loss 0.8355 (1.0918) loss_zs_kd 0.1451 (0.1667) loss_oracle 0.0709 (0.0486) acc 78.1250 (70.7812) kd_loss 0.0571 (0.0374) lr 6.9098e-04 eta 0:07:59
epoch [32/50] batch [60/246] time 0.102 (0.099) data 0.001 (0.005) loss 1.1297 (1.2343) ce_loss 1.0254 (1.1072) teacher_loss 1.0226 (1.1038) loss_zs_kd 0.1293 (0.1670) loss_oracle 0.0424 (0.0470) acc 68.7500 (70.3125) kd_loss 0.0367 (0.0365) lr 6.9098e-04 eta 0:07:36
epoch [32/50] batch [80/246] time 0.093 (0.098) data 0.000 (0.004) loss 0.9608 (1.2109) ce_loss 0.8184 (1.0824) teacher_loss 0.8211 (1.0790) loss_zs_kd 0.2079 (0.1712) loss_oracle 0.0358 (0.0464) acc 78.1250 (71.3672) kd_loss 0.0340 (0.0367) lr 6.9098e-04 eta 0:07:29
epoch [32/50] batch [100/246] time 0.088 (0.097) data 0.000 (0.003) loss 1.2086 (1.2280) ce_loss 1.0693 (1.0994) teacher_loss 1.0711 (1.0956) loss_zs_kd 0.1502 (0.1714) loss_oracle 0.0624 (0.0467) acc 71.8750 (70.5938) kd_loss 0.0448 (0.0374) lr 6.9098e-04 eta 0:07:23
epoch [32/50] batch [120/246] time 0.094 (0.096) data 0.000 (0.003) loss 0.8927 (1.2272) ce_loss 0.7500 (1.0977) teacher_loss 0.7593 (1.0941) loss_zs_kd 0.1543 (0.1732) loss_oracle 0.0562 (0.0466) acc 81.2500 (70.4427) kd_loss 0.0434 (0.0373) lr 6.9098e-04 eta 0:07:18
epoch [32/50] batch [140/246] time 0.100 (0.096) data 0.000 (0.002) loss 1.4704 (1.2113) ce_loss 1.3311 (1.0825) teacher_loss 1.3317 (1.0786) loss_zs_kd 0.1909 (0.1721) loss_oracle 0.0433 (0.0467) acc 59.3750 (71.0491) kd_loss 0.0298 (0.0371) lr 6.9098e-04 eta 0:07:15
epoch [32/50] batch [160/246] time 0.098 (0.096) data 0.000 (0.002) loss 1.0528 (1.2180) ce_loss 0.9346 (1.0896) teacher_loss 0.9319 (1.0856) loss_zs_kd 0.1252 (0.1706) loss_oracle 0.0583 (0.0471) acc 81.2500 (71.0547) kd_loss 0.0487 (0.0375) lr 6.9098e-04 eta 0:07:13
epoch [32/50] batch [180/246] time 0.083 (0.095) data 0.000 (0.002) loss 1.1242 (1.2106) ce_loss 1.0020 (1.0827) teacher_loss 0.9731 (1.0787) loss_zs_kd 0.1876 (0.1693) loss_oracle 0.0573 (0.0473) acc 75.0000 (71.3368) kd_loss 0.0406 (0.0376) lr 6.9098e-04 eta 0:07:07
epoch [32/50] batch [200/246] time 0.095 (0.095) data 0.000 (0.002) loss 1.3341 (1.2116) ce_loss 1.1797 (1.0837) teacher_loss 1.1837 (1.0796) loss_zs_kd 0.2385 (0.1697) loss_oracle 0.0312 (0.0471) acc 68.7500 (71.3281) kd_loss 0.0305 (0.0377) lr 6.9098e-04 eta 0:07:04
epoch [32/50] batch [220/246] time 0.102 (0.095) data 0.000 (0.002) loss 1.1300 (1.2035) ce_loss 0.9531 (1.0754) teacher_loss 0.9465 (1.0714) loss_zs_kd 0.2310 (0.1708) loss_oracle 0.0680 (0.0468) acc 78.1250 (71.5767) kd_loss 0.0468 (0.0377) lr 6.9098e-04 eta 0:07:02
epoch [32/50] batch [240/246] time 0.085 (0.095) data 0.000 (0.001) loss 0.7569 (1.2081) ce_loss 0.6582 (1.0810) teacher_loss 0.6559 (1.0770) loss_zs_kd 0.1121 (0.1697) loss_oracle 0.0449 (0.0463) acc 84.3750 (71.4062) kd_loss 0.0388 (0.0375) lr 6.9098e-04 eta 0:06:59
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,848
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,949
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.5%
******* Domain r best val acc:      85.2%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [33/50] batch [20/246] time 0.083 (0.108) data 0.000 (0.015) loss 1.4599 (1.1789) ce_loss 1.3672 (1.0598) teacher_loss 1.3666 (1.0572) loss_zs_kd 0.1167 (0.1546) loss_oracle 0.0350 (0.0444) acc 62.5000 (72.6562) kd_loss 0.0283 (0.0356) lr 6.3188e-04 eta 0:07:57
epoch [33/50] batch [40/246] time 0.098 (0.099) data 0.000 (0.008) loss 0.7770 (1.2125) ce_loss 0.6724 (1.0895) teacher_loss 0.6697 (1.0875) loss_zs_kd 0.1424 (0.1627) loss_oracle 0.0361 (0.0436) acc 81.2500 (71.8750) kd_loss 0.0323 (0.0365) lr 6.3188e-04 eta 0:07:13
epoch [33/50] batch [60/246] time 0.084 (0.096) data 0.000 (0.005) loss 1.3725 (1.1955) ce_loss 1.2412 (1.0710) teacher_loss 1.2266 (1.0684) loss_zs_kd 0.1858 (0.1678) loss_oracle 0.0530 (0.0432) acc 75.0000 (72.2396) kd_loss 0.0505 (0.0372) lr 6.3188e-04 eta 0:06:57
epoch [33/50] batch [80/246] time 0.091 (0.094) data 0.000 (0.004) loss 0.7981 (1.1828) ce_loss 0.6499 (1.0585) teacher_loss 0.6488 (1.0555) loss_zs_kd 0.1956 (0.1674) loss_oracle 0.0514 (0.0436) acc 81.2500 (72.3047) kd_loss 0.0374 (0.0366) lr 6.3188e-04 eta 0:06:47
epoch [33/50] batch [100/246] time 0.092 (0.093) data 0.000 (0.003) loss 1.1481 (1.1803) ce_loss 0.9810 (1.0552) teacher_loss 0.9729 (1.0522) loss_zs_kd 0.2439 (0.1691) loss_oracle 0.0532 (0.0436) acc 75.0000 (72.4062) kd_loss 0.0546 (0.0373) lr 6.3188e-04 eta 0:06:43
epoch [33/50] batch [120/246] time 0.097 (0.093) data 0.000 (0.003) loss 1.8232 (1.1801) ce_loss 1.7227 (1.0558) teacher_loss 1.7169 (1.0523) loss_zs_kd 0.1471 (0.1683) loss_oracle 0.0327 (0.0436) acc 62.5000 (72.2135) kd_loss 0.0305 (0.0373) lr 6.3188e-04 eta 0:06:41
epoch [33/50] batch [140/246] time 0.098 (0.094) data 0.000 (0.002) loss 1.5532 (1.1893) ce_loss 1.4131 (1.0648) teacher_loss 1.4016 (1.0608) loss_zs_kd 0.1943 (0.1695) loss_oracle 0.0545 (0.0438) acc 65.6250 (72.1205) kd_loss 0.0558 (0.0373) lr 6.3188e-04 eta 0:06:43
epoch [33/50] batch [160/246] time 0.090 (0.094) data 0.000 (0.002) loss 1.0172 (1.1700) ce_loss 0.8828 (1.0453) teacher_loss 0.8705 (1.0414) loss_zs_kd 0.2031 (0.1698) loss_oracle 0.0451 (0.0437) acc 78.1250 (72.4219) kd_loss 0.0264 (0.0372) lr 6.3188e-04 eta 0:06:42
epoch [33/50] batch [180/246] time 0.088 (0.094) data 0.000 (0.002) loss 1.3649 (1.1776) ce_loss 1.2246 (1.0528) teacher_loss 1.2334 (1.0491) loss_zs_kd 0.1839 (0.1699) loss_oracle 0.0395 (0.0435) acc 68.7500 (72.2396) kd_loss 0.0334 (0.0367) lr 6.3188e-04 eta 0:06:40
epoch [33/50] batch [200/246] time 0.094 (0.094) data 0.000 (0.002) loss 1.0457 (1.1835) ce_loss 0.9409 (1.0593) teacher_loss 0.9282 (1.0553) loss_zs_kd 0.1321 (0.1692) loss_oracle 0.0515 (0.0436) acc 71.8750 (72.1562) kd_loss 0.0390 (0.0368) lr 6.3188e-04 eta 0:06:39
epoch [33/50] batch [220/246] time 0.082 (0.094) data 0.000 (0.002) loss 1.3872 (1.1828) ce_loss 1.2588 (1.0592) teacher_loss 1.2369 (1.0553) loss_zs_kd 0.1965 (0.1683) loss_oracle 0.0521 (0.0433) acc 65.6250 (71.9744) kd_loss 0.0399 (0.0365) lr 6.3188e-04 eta 0:06:36
epoch [33/50] batch [240/246] time 0.085 (0.094) data 0.000 (0.001) loss 1.2795 (1.1775) ce_loss 1.0840 (1.0531) teacher_loss 1.0832 (1.0494) loss_zs_kd 0.2675 (0.1694) loss_oracle 0.0625 (0.0434) acc 81.2500 (72.0312) kd_loss 0.0477 (0.0365) lr 6.3188e-04 eta 0:06:32
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,864
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.9%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.8%, epoch: 33 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [34/50] batch [20/246] time 0.124 (0.135) data 0.000 (0.013) loss 0.8795 (1.0995) ce_loss 0.7734 (0.9643) teacher_loss 0.7748 (0.9638) loss_zs_kd 0.1438 (0.1770) loss_oracle 0.0328 (0.0472) acc 78.1250 (74.2188) kd_loss 0.0242 (0.0398) lr 5.7422e-04 eta 0:09:20
epoch [34/50] batch [40/246] time 0.116 (0.131) data 0.000 (0.007) loss 1.2352 (1.1758) ce_loss 1.1240 (1.0406) teacher_loss 1.1253 (1.0389) loss_zs_kd 0.1520 (0.1811) loss_oracle 0.0339 (0.0463) acc 75.0000 (72.4219) kd_loss 0.0299 (0.0403) lr 5.7422e-04 eta 0:09:01
epoch [34/50] batch [60/246] time 0.128 (0.128) data 0.002 (0.005) loss 0.7602 (1.1331) ce_loss 0.6196 (0.9993) teacher_loss 0.6210 (0.9974) loss_zs_kd 0.1835 (0.1778) loss_oracle 0.0474 (0.0468) acc 87.5000 (73.8542) kd_loss 0.0425 (0.0413) lr 5.7422e-04 eta 0:08:46
epoch [34/50] batch [80/246] time 0.125 (0.128) data 0.001 (0.004) loss 1.1686 (1.1501) ce_loss 1.0410 (1.0184) teacher_loss 1.0361 (1.0158) loss_zs_kd 0.1457 (0.1738) loss_oracle 0.0596 (0.0473) acc 68.7500 (73.2422) kd_loss 0.0622 (0.0420) lr 5.7422e-04 eta 0:08:45
epoch [34/50] batch [100/246] time 0.125 (0.127) data 0.000 (0.003) loss 1.3412 (1.1623) ce_loss 1.1953 (1.0298) teacher_loss 1.1844 (1.0264) loss_zs_kd 0.2113 (0.1771) loss_oracle 0.0511 (0.0474) acc 68.7500 (72.4688) kd_loss 0.0572 (0.0428) lr 5.7422e-04 eta 0:08:39
epoch [34/50] batch [120/246] time 0.136 (0.128) data 0.001 (0.003) loss 1.1280 (1.1408) ce_loss 1.0117 (1.0097) teacher_loss 1.0100 (1.0065) loss_zs_kd 0.1335 (0.1747) loss_oracle 0.0512 (0.0470) acc 68.7500 (72.9688) kd_loss 0.0498 (0.0426) lr 5.7422e-04 eta 0:08:38
epoch [34/50] batch [140/246] time 0.123 (0.128) data 0.000 (0.002) loss 1.2164 (1.1541) ce_loss 1.0986 (1.0231) teacher_loss 1.1028 (1.0196) loss_zs_kd 0.1441 (0.1758) loss_oracle 0.0415 (0.0466) acc 75.0000 (72.8571) kd_loss 0.0305 (0.0420) lr 5.7422e-04 eta 0:08:35
epoch [34/50] batch [160/246] time 0.130 (0.128) data 0.000 (0.002) loss 0.8048 (1.1601) ce_loss 0.6670 (1.0290) teacher_loss 0.6728 (1.0255) loss_zs_kd 0.1832 (0.1764) loss_oracle 0.0403 (0.0464) acc 78.1250 (72.7734) kd_loss 0.0279 (0.0417) lr 5.7422e-04 eta 0:08:33
epoch [34/50] batch [180/246] time 0.129 (0.128) data 0.000 (0.002) loss 0.8526 (1.1639) ce_loss 0.7163 (1.0339) teacher_loss 0.7112 (1.0302) loss_zs_kd 0.1641 (0.1750) loss_oracle 0.0593 (0.0462) acc 81.2500 (72.6215) kd_loss 0.0548 (0.0413) lr 5.7422e-04 eta 0:08:31
epoch [34/50] batch [200/246] time 0.132 (0.128) data 0.000 (0.002) loss 1.0715 (1.1765) ce_loss 0.9800 (1.0461) teacher_loss 0.9738 (1.0421) loss_zs_kd 0.1158 (0.1761) loss_oracle 0.0398 (0.0464) acc 68.7500 (72.1875) kd_loss 0.0342 (0.0413) lr 5.7422e-04 eta 0:08:30
epoch [34/50] batch [220/246] time 0.129 (0.128) data 0.000 (0.002) loss 1.1991 (1.1770) ce_loss 1.0918 (1.0470) teacher_loss 1.0764 (1.0431) loss_zs_kd 0.1069 (0.1752) loss_oracle 0.0692 (0.0464) acc 68.7500 (72.2159) kd_loss 0.0659 (0.0411) lr 5.7422e-04 eta 0:08:28
epoch [34/50] batch [240/246] time 0.108 (0.128) data 0.001 (0.001) loss 1.4002 (1.1793) ce_loss 1.2822 (1.0494) teacher_loss 1.2774 (1.0458) loss_zs_kd 0.1612 (0.1747) loss_oracle 0.0422 (0.0462) acc 59.3750 (72.1094) kd_loss 0.0334 (0.0408) lr 5.7422e-04 eta 0:08:23
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,859
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.8%, epoch: 33 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [35/50] batch [20/246] time 0.104 (0.126) data 0.000 (0.017) loss 1.5146 (1.1309) ce_loss 1.3662 (1.0043) teacher_loss 1.3678 (1.0029) loss_zs_kd 0.1851 (0.1702) loss_oracle 0.0543 (0.0429) acc 59.3750 (73.9062) kd_loss 0.0424 (0.0330) lr 5.1825e-04 eta 0:08:12
epoch [35/50] batch [40/246] time 0.102 (0.116) data 0.000 (0.009) loss 1.3988 (1.1867) ce_loss 1.2646 (1.0585) teacher_loss 1.2408 (1.0555) loss_zs_kd 0.2006 (0.1745) loss_oracle 0.0578 (0.0440) acc 68.7500 (72.7344) kd_loss 0.0435 (0.0348) lr 5.1825e-04 eta 0:07:31
epoch [35/50] batch [60/246] time 0.133 (0.118) data 0.001 (0.006) loss 0.9603 (1.1828) ce_loss 0.8135 (1.0516) teacher_loss 0.8197 (1.0490) loss_zs_kd 0.1947 (0.1795) loss_oracle 0.0433 (0.0440) acc 78.1250 (72.5000) kd_loss 0.0357 (0.0363) lr 5.1825e-04 eta 0:07:38
epoch [35/50] batch [80/246] time 0.123 (0.121) data 0.000 (0.005) loss 2.0897 (1.1856) ce_loss 1.9395 (1.0553) teacher_loss 1.9220 (1.0523) loss_zs_kd 0.1871 (0.1763) loss_oracle 0.0741 (0.0452) acc 53.1250 (72.3438) kd_loss 0.0540 (0.0382) lr 5.1825e-04 eta 0:07:45
epoch [35/50] batch [100/246] time 0.116 (0.122) data 0.000 (0.004) loss 1.4044 (1.1814) ce_loss 1.2842 (1.0529) teacher_loss 1.2883 (1.0495) loss_zs_kd 0.1459 (0.1735) loss_oracle 0.0431 (0.0452) acc 56.2500 (72.4062) kd_loss 0.0426 (0.0393) lr 5.1825e-04 eta 0:07:47
epoch [35/50] batch [120/246] time 0.127 (0.122) data 0.000 (0.003) loss 1.0299 (1.1807) ce_loss 0.9189 (1.0509) teacher_loss 0.9242 (1.0480) loss_zs_kd 0.1474 (0.1741) loss_oracle 0.0320 (0.0457) acc 75.0000 (72.6823) kd_loss 0.0255 (0.0399) lr 5.1825e-04 eta 0:07:44
epoch [35/50] batch [140/246] time 0.115 (0.122) data 0.000 (0.003) loss 0.9729 (1.1821) ce_loss 0.8525 (1.0530) teacher_loss 0.8498 (1.0500) loss_zs_kd 0.1509 (0.1727) loss_oracle 0.0476 (0.0457) acc 75.0000 (72.5893) kd_loss 0.0417 (0.0402) lr 5.1825e-04 eta 0:07:42
epoch [35/50] batch [160/246] time 0.122 (0.122) data 0.000 (0.002) loss 0.6927 (1.1804) ce_loss 0.5796 (1.0516) teacher_loss 0.5853 (1.0492) loss_zs_kd 0.1527 (0.1721) loss_oracle 0.0310 (0.0452) acc 87.5000 (72.6367) kd_loss 0.0321 (0.0404) lr 5.1825e-04 eta 0:07:39
epoch [35/50] batch [180/246] time 0.112 (0.122) data 0.000 (0.002) loss 1.6033 (1.1769) ce_loss 1.4746 (1.0485) teacher_loss 1.4774 (1.0462) loss_zs_kd 0.1624 (0.1718) loss_oracle 0.0447 (0.0447) acc 71.8750 (72.7604) kd_loss 0.0491 (0.0403) lr 5.1825e-04 eta 0:07:39
epoch [35/50] batch [200/246] time 0.131 (0.122) data 0.000 (0.002) loss 1.0794 (1.1788) ce_loss 0.9395 (1.0508) teacher_loss 0.9392 (1.0485) loss_zs_kd 0.1842 (0.1712) loss_oracle 0.0481 (0.0447) acc 78.1250 (72.5312) kd_loss 0.0458 (0.0401) lr 5.1825e-04 eta 0:07:37
epoch [35/50] batch [220/246] time 0.141 (0.123) data 0.000 (0.002) loss 1.5254 (1.1845) ce_loss 1.3926 (1.0576) teacher_loss 1.3865 (1.0553) loss_zs_kd 0.1799 (0.1697) loss_oracle 0.0490 (0.0444) acc 59.3750 (72.3153) kd_loss 0.0416 (0.0397) lr 5.1825e-04 eta 0:07:35
epoch [35/50] batch [240/246] time 0.107 (0.122) data 0.000 (0.002) loss 1.1441 (1.1886) ce_loss 0.9985 (1.0609) teacher_loss 0.9849 (1.0583) loss_zs_kd 0.2054 (0.1712) loss_oracle 0.0565 (0.0448) acc 71.8750 (72.2526) kd_loss 0.0445 (0.0396) lr 5.1825e-04 eta 0:07:30
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,862
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.8%, epoch: 33 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [36/50] batch [20/246] time 0.127 (0.136) data 0.000 (0.014) loss 1.2969 (1.2212) ce_loss 1.1367 (1.0983) teacher_loss 1.1395 (1.0933) loss_zs_kd 0.2218 (0.1625) loss_oracle 0.0465 (0.0466) acc 68.7500 (70.1562) kd_loss 0.0433 (0.0404) lr 4.6417e-04 eta 0:08:17
epoch [36/50] batch [40/246] time 0.116 (0.131) data 0.000 (0.007) loss 1.5894 (1.1952) ce_loss 1.4746 (1.0679) teacher_loss 1.4701 (1.0633) loss_zs_kd 0.1715 (0.1715) loss_oracle 0.0335 (0.0461) acc 53.1250 (71.0938) kd_loss 0.0351 (0.0402) lr 4.6417e-04 eta 0:07:58
epoch [36/50] batch [60/246] time 0.122 (0.124) data 0.001 (0.005) loss 1.0475 (1.2040) ce_loss 0.9058 (1.0751) teacher_loss 0.9061 (1.0692) loss_zs_kd 0.2084 (0.1764) loss_oracle 0.0372 (0.0466) acc 75.0000 (70.8854) kd_loss 0.0319 (0.0394) lr 4.6417e-04 eta 0:07:31
epoch [36/50] batch [80/246] time 0.125 (0.125) data 0.001 (0.004) loss 1.3372 (1.2263) ce_loss 1.2295 (1.0960) teacher_loss 1.2271 (1.0898) loss_zs_kd 0.1309 (0.1793) loss_oracle 0.0446 (0.0469) acc 62.5000 (70.3906) kd_loss 0.0348 (0.0390) lr 4.6417e-04 eta 0:07:31
epoch [36/50] batch [100/246] time 0.125 (0.125) data 0.000 (0.003) loss 1.5377 (1.2193) ce_loss 1.4102 (1.0880) teacher_loss 1.3920 (1.0825) loss_zs_kd 0.2011 (0.1795) loss_oracle 0.0452 (0.0470) acc 62.5000 (70.6562) kd_loss 0.0312 (0.0384) lr 4.6417e-04 eta 0:07:29
epoch [36/50] batch [120/246] time 0.125 (0.126) data 0.000 (0.003) loss 0.8640 (1.2135) ce_loss 0.7520 (1.0814) teacher_loss 0.7518 (1.0760) loss_zs_kd 0.1548 (0.1801) loss_oracle 0.0348 (0.0474) acc 84.3750 (71.0938) kd_loss 0.0251 (0.0385) lr 4.6417e-04 eta 0:07:29
epoch [36/50] batch [140/246] time 0.131 (0.126) data 0.000 (0.002) loss 1.2461 (1.2062) ce_loss 1.1650 (1.0756) teacher_loss 1.1620 (1.0708) loss_zs_kd 0.0984 (0.1771) loss_oracle 0.0349 (0.0468) acc 68.7500 (71.4062) kd_loss 0.0350 (0.0382) lr 4.6417e-04 eta 0:07:27
epoch [36/50] batch [160/246] time 0.127 (0.126) data 0.000 (0.002) loss 0.6353 (1.1913) ce_loss 0.4810 (1.0617) teacher_loss 0.4828 (1.0570) loss_zs_kd 0.2219 (0.1754) loss_oracle 0.0416 (0.0466) acc 87.5000 (71.7188) kd_loss 0.0301 (0.0382) lr 4.6417e-04 eta 0:07:25
epoch [36/50] batch [180/246] time 0.131 (0.126) data 0.000 (0.002) loss 1.0343 (1.1884) ce_loss 0.9199 (1.0587) teacher_loss 0.9167 (1.0539) loss_zs_kd 0.1374 (0.1764) loss_oracle 0.0489 (0.0463) acc 71.8750 (71.9271) kd_loss 0.0464 (0.0377) lr 4.6417e-04 eta 0:07:23
epoch [36/50] batch [200/246] time 0.098 (0.124) data 0.000 (0.002) loss 1.3503 (1.1959) ce_loss 1.2100 (1.0667) teacher_loss 1.2093 (1.0618) loss_zs_kd 0.1773 (0.1762) loss_oracle 0.0523 (0.0460) acc 65.6250 (71.7031) kd_loss 0.0380 (0.0376) lr 4.6417e-04 eta 0:07:13
epoch [36/50] batch [220/246] time 0.099 (0.122) data 0.000 (0.002) loss 0.7532 (1.1895) ce_loss 0.6567 (1.0608) teacher_loss 0.6585 (1.0561) loss_zs_kd 0.1075 (0.1750) loss_oracle 0.0410 (0.0459) acc 87.5000 (72.0028) kd_loss 0.0276 (0.0370) lr 4.6417e-04 eta 0:07:03
epoch [36/50] batch [240/246] time 0.102 (0.120) data 0.000 (0.002) loss 1.2152 (1.1785) ce_loss 1.0576 (1.0504) teacher_loss 1.0623 (1.0457) loss_zs_kd 0.2100 (0.1742) loss_oracle 0.0480 (0.0458) acc 75.0000 (72.3698) kd_loss 0.0372 (0.0366) lr 4.6417e-04 eta 0:06:54
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,865
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,961
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.4%, epoch: 36 *******
******* Domain r best val test acc: 90.9%, epoch: 36 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [37/50] batch [20/246] time 0.102 (0.123) data 0.000 (0.014) loss 1.3437 (1.2512) ce_loss 1.2500 (1.1221) teacher_loss 1.2357 (1.1167) loss_zs_kd 0.1231 (0.1749) loss_oracle 0.0464 (0.0471) acc 65.6250 (71.0938) kd_loss 0.0431 (0.0331) lr 4.1221e-04 eta 0:07:01
epoch [37/50] batch [40/246] time 0.094 (0.110) data 0.000 (0.007) loss 1.5735 (1.2138) ce_loss 1.4727 (1.0842) teacher_loss 1.4752 (1.0808) loss_zs_kd 0.1327 (0.1723) loss_oracle 0.0319 (0.0469) acc 65.6250 (71.2500) kd_loss 0.0211 (0.0326) lr 4.1221e-04 eta 0:06:14
epoch [37/50] batch [60/246] time 0.122 (0.111) data 0.001 (0.005) loss 0.8710 (1.1986) ce_loss 0.7344 (1.0677) teacher_loss 0.7364 (1.0644) loss_zs_kd 0.1892 (0.1735) loss_oracle 0.0401 (0.0474) acc 68.7500 (71.9271) kd_loss 0.0468 (0.0352) lr 4.1221e-04 eta 0:06:14
epoch [37/50] batch [80/246] time 0.129 (0.114) data 0.000 (0.004) loss 1.0192 (1.1829) ce_loss 0.8848 (1.0533) teacher_loss 0.8861 (1.0501) loss_zs_kd 0.1800 (0.1722) loss_oracle 0.0431 (0.0466) acc 75.0000 (71.9531) kd_loss 0.0299 (0.0356) lr 4.1221e-04 eta 0:06:23
epoch [37/50] batch [100/246] time 0.119 (0.116) data 0.000 (0.003) loss 1.6957 (1.1835) ce_loss 1.5889 (1.0547) teacher_loss 1.5929 (1.0512) loss_zs_kd 0.1455 (0.1719) loss_oracle 0.0300 (0.0464) acc 56.2500 (71.8125) kd_loss 0.0190 (0.0346) lr 4.1221e-04 eta 0:06:28
epoch [37/50] batch [120/246] time 0.118 (0.118) data 0.001 (0.003) loss 1.3253 (1.1922) ce_loss 1.2119 (1.0631) teacher_loss 1.2012 (1.0593) loss_zs_kd 0.1569 (0.1732) loss_oracle 0.0457 (0.0463) acc 65.6250 (71.6667) kd_loss 0.0361 (0.0351) lr 4.1221e-04 eta 0:06:31
epoch [37/50] batch [140/246] time 0.120 (0.118) data 0.000 (0.002) loss 0.9335 (1.1973) ce_loss 0.7925 (1.0679) teacher_loss 0.7847 (1.0642) loss_zs_kd 0.1927 (0.1731) loss_oracle 0.0524 (0.0465) acc 81.2500 (71.7411) kd_loss 0.0366 (0.0350) lr 4.1221e-04 eta 0:06:31
epoch [37/50] batch [160/246] time 0.116 (0.118) data 0.001 (0.002) loss 1.3518 (1.1847) ce_loss 1.2109 (1.0561) teacher_loss 1.2105 (1.0524) loss_zs_kd 0.1768 (0.1717) loss_oracle 0.0528 (0.0465) acc 71.8750 (72.2070) kd_loss 0.0376 (0.0350) lr 4.1221e-04 eta 0:06:27
epoch [37/50] batch [180/246] time 0.119 (0.118) data 0.001 (0.002) loss 1.1876 (1.1827) ce_loss 1.0713 (1.0557) teacher_loss 1.0732 (1.0516) loss_zs_kd 0.1441 (0.1695) loss_oracle 0.0424 (0.0463) acc 65.6250 (72.0833) kd_loss 0.0374 (0.0349) lr 4.1221e-04 eta 0:06:25
epoch [37/50] batch [200/246] time 0.123 (0.118) data 0.002 (0.002) loss 0.9768 (1.1800) ce_loss 0.8633 (1.0526) teacher_loss 0.8676 (1.0487) loss_zs_kd 0.1303 (0.1703) loss_oracle 0.0441 (0.0461) acc 78.1250 (72.0625) kd_loss 0.0329 (0.0347) lr 4.1221e-04 eta 0:06:23
epoch [37/50] batch [220/246] time 0.132 (0.119) data 0.000 (0.002) loss 1.7392 (1.1833) ce_loss 1.5918 (1.0560) teacher_loss 1.5855 (1.0521) loss_zs_kd 0.1923 (0.1699) loss_oracle 0.0576 (0.0463) acc 65.6250 (72.0170) kd_loss 0.0553 (0.0352) lr 4.1221e-04 eta 0:06:23
epoch [37/50] batch [240/246] time 0.106 (0.119) data 0.000 (0.002) loss 1.1135 (1.1820) ce_loss 1.0137 (1.0546) teacher_loss 1.0129 (1.0506) loss_zs_kd 0.1297 (0.1695) loss_oracle 0.0357 (0.0467) acc 71.8750 (72.1484) kd_loss 0.0255 (0.0358) lr 4.1221e-04 eta 0:06:20
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,864
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.4%, epoch: 36 *******
******* Domain r best val test acc: 90.9%, epoch: 36 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [38/50] batch [20/246] time 0.122 (0.114) data 0.001 (0.013) loss 1.3052 (1.2786) ce_loss 1.1826 (1.1492) teacher_loss 1.1761 (1.1440) loss_zs_kd 0.1411 (0.1784) loss_oracle 0.0586 (0.0454) acc 68.7500 (70.9375) kd_loss 0.0485 (0.0396) lr 3.6258e-04 eta 0:06:01
epoch [38/50] batch [40/246] time 0.108 (0.113) data 0.000 (0.006) loss 0.9769 (1.2732) ce_loss 0.8179 (1.1412) teacher_loss 0.8202 (1.1347) loss_zs_kd 0.1957 (0.1828) loss_oracle 0.0589 (0.0471) acc 71.8750 (70.7031) kd_loss 0.0498 (0.0415) lr 3.6258e-04 eta 0:05:55
epoch [38/50] batch [60/246] time 0.123 (0.113) data 0.000 (0.004) loss 1.4579 (1.2401) ce_loss 1.3398 (1.1074) teacher_loss 1.3382 (1.1017) loss_zs_kd 0.1401 (0.1804) loss_oracle 0.0497 (0.0482) acc 62.5000 (71.6146) kd_loss 0.0360 (0.0425) lr 3.6258e-04 eta 0:05:54
epoch [38/50] batch [80/246] time 0.137 (0.115) data 0.000 (0.003) loss 1.5259 (1.2292) ce_loss 1.3906 (1.0973) teacher_loss 1.3750 (1.0922) loss_zs_kd 0.1785 (0.1789) loss_oracle 0.0617 (0.0474) acc 65.6250 (71.4453) kd_loss 0.0547 (0.0423) lr 3.6258e-04 eta 0:05:58
epoch [38/50] batch [100/246] time 0.132 (0.118) data 0.000 (0.003) loss 1.7027 (1.2281) ce_loss 1.5820 (1.0972) teacher_loss 1.5840 (1.0924) loss_zs_kd 0.1470 (0.1765) loss_oracle 0.0452 (0.0474) acc 62.5000 (71.3750) kd_loss 0.0401 (0.0418) lr 3.6258e-04 eta 0:06:05
epoch [38/50] batch [120/246] time 0.128 (0.120) data 0.000 (0.002) loss 0.9992 (1.2220) ce_loss 0.8833 (1.0923) teacher_loss 0.8753 (1.0878) loss_zs_kd 0.1618 (0.1735) loss_oracle 0.0430 (0.0474) acc 75.0000 (71.3802) kd_loss 0.0402 (0.0413) lr 3.6258e-04 eta 0:06:08
epoch [38/50] batch [140/246] time 0.131 (0.121) data 0.000 (0.002) loss 0.8700 (1.2063) ce_loss 0.7627 (1.0763) teacher_loss 0.7626 (1.0719) loss_zs_kd 0.1281 (0.1728) loss_oracle 0.0433 (0.0480) acc 75.0000 (71.6964) kd_loss 0.0398 (0.0416) lr 3.6258e-04 eta 0:06:10
epoch [38/50] batch [160/246] time 0.128 (0.122) data 0.000 (0.002) loss 0.9634 (1.2116) ce_loss 0.8374 (1.0823) teacher_loss 0.8296 (1.0777) loss_zs_kd 0.1605 (0.1718) loss_oracle 0.0536 (0.0480) acc 75.0000 (71.4453) kd_loss 0.0374 (0.0416) lr 3.6258e-04 eta 0:06:11
epoch [38/50] batch [180/246] time 0.125 (0.123) data 0.000 (0.002) loss 0.9895 (1.2066) ce_loss 0.8535 (1.0764) teacher_loss 0.8613 (1.0717) loss_zs_kd 0.1829 (0.1735) loss_oracle 0.0368 (0.0481) acc 78.1250 (71.6146) kd_loss 0.0297 (0.0416) lr 3.6258e-04 eta 0:06:11
epoch [38/50] batch [200/246] time 0.128 (0.124) data 0.000 (0.002) loss 1.0595 (1.2007) ce_loss 0.9238 (1.0714) teacher_loss 0.9172 (1.0666) loss_zs_kd 0.1823 (0.1724) loss_oracle 0.0511 (0.0479) acc 71.8750 (71.7188) kd_loss 0.0397 (0.0413) lr 3.6258e-04 eta 0:06:11
epoch [38/50] batch [220/246] time 0.133 (0.124) data 0.000 (0.001) loss 0.9994 (1.1998) ce_loss 0.8799 (1.0710) teacher_loss 0.8846 (1.0663) loss_zs_kd 0.1503 (0.1719) loss_oracle 0.0397 (0.0475) acc 78.1250 (71.7756) kd_loss 0.0289 (0.0410) lr 3.6258e-04 eta 0:06:09
epoch [38/50] batch [240/246] time 0.112 (0.124) data 0.000 (0.001) loss 1.4672 (1.1995) ce_loss 1.3154 (1.0702) teacher_loss 1.3104 (1.0656) loss_zs_kd 0.2296 (0.1728) loss_oracle 0.0421 (0.0476) acc 62.5000 (71.7448) kd_loss 0.0323 (0.0410) lr 3.6258e-04 eta 0:06:07
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,863
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.4%, epoch: 36 *******
******* Domain r best val test acc: 90.9%, epoch: 36 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [39/50] batch [20/246] time 0.094 (0.109) data 0.000 (0.014) loss 0.8427 (1.1607) ce_loss 0.7471 (1.0270) teacher_loss 0.7366 (1.0209) loss_zs_kd 0.1165 (0.1796) loss_oracle 0.0478 (0.0500) acc 87.5000 (72.6562) kd_loss 0.0401 (0.0395) lr 3.1545e-04 eta 0:05:18
epoch [39/50] batch [40/246] time 0.113 (0.103) data 0.000 (0.007) loss 0.7926 (1.1635) ce_loss 0.6748 (1.0295) teacher_loss 0.6752 (1.0227) loss_zs_kd 0.1255 (0.1784) loss_oracle 0.0546 (0.0515) acc 81.2500 (72.5000) kd_loss 0.0339 (0.0423) lr 3.1545e-04 eta 0:05:00
epoch [39/50] batch [60/246] time 0.102 (0.103) data 0.001 (0.005) loss 1.0619 (1.1728) ce_loss 0.9517 (1.0396) teacher_loss 0.9390 (1.0332) loss_zs_kd 0.1449 (0.1753) loss_oracle 0.0505 (0.0519) acc 78.1250 (71.9271) kd_loss 0.0407 (0.0439) lr 3.1545e-04 eta 0:04:58
epoch [39/50] batch [80/246] time 0.091 (0.103) data 0.000 (0.004) loss 1.5730 (1.1763) ce_loss 1.4531 (1.0443) teacher_loss 1.4528 (1.0380) loss_zs_kd 0.1452 (0.1729) loss_oracle 0.0475 (0.0519) acc 65.6250 (71.9531) kd_loss 0.0413 (0.0433) lr 3.1545e-04 eta 0:04:54
epoch [39/50] batch [100/246] time 0.105 (0.101) data 0.000 (0.003) loss 1.3226 (1.1922) ce_loss 1.1514 (1.0594) teacher_loss 1.1405 (1.0535) loss_zs_kd 0.2513 (0.1749) loss_oracle 0.0564 (0.0513) acc 65.6250 (71.4375) kd_loss 0.0543 (0.0428) lr 3.1545e-04 eta 0:04:48
epoch [39/50] batch [120/246] time 0.110 (0.100) data 0.000 (0.002) loss 1.1239 (1.1891) ce_loss 0.9961 (1.0546) teacher_loss 0.9937 (1.0484) loss_zs_kd 0.1485 (0.1785) loss_oracle 0.0560 (0.0515) acc 71.8750 (72.0052) kd_loss 0.0420 (0.0430) lr 3.1545e-04 eta 0:04:44
epoch [39/50] batch [140/246] time 0.104 (0.101) data 0.000 (0.002) loss 1.8029 (1.2113) ce_loss 1.6504 (1.0758) teacher_loss 1.6526 (1.0698) loss_zs_kd 0.2050 (0.1805) loss_oracle 0.0479 (0.0513) acc 65.6250 (71.5848) kd_loss 0.0583 (0.0432) lr 3.1545e-04 eta 0:04:44
epoch [39/50] batch [160/246] time 0.108 (0.102) data 0.000 (0.002) loss 1.1717 (1.2136) ce_loss 1.0244 (1.0777) teacher_loss 1.0153 (1.0720) loss_zs_kd 0.1777 (0.1807) loss_oracle 0.0676 (0.0512) acc 78.1250 (71.5234) kd_loss 0.0763 (0.0437) lr 3.1545e-04 eta 0:04:44
epoch [39/50] batch [180/246] time 0.124 (0.103) data 0.000 (0.002) loss 1.0438 (1.2046) ce_loss 0.8706 (1.0692) teacher_loss 0.8633 (1.0637) loss_zs_kd 0.2398 (0.1797) loss_oracle 0.0606 (0.0510) acc 75.0000 (71.7708) kd_loss 0.0598 (0.0440) lr 3.1545e-04 eta 0:04:46
epoch [39/50] batch [200/246] time 0.126 (0.106) data 0.001 (0.002) loss 1.2435 (1.2078) ce_loss 1.0928 (1.0714) teacher_loss 1.0807 (1.0660) loss_zs_kd 0.1967 (0.1807) loss_oracle 0.0645 (0.0515) acc 65.6250 (71.6719) kd_loss 0.0594 (0.0448) lr 3.1545e-04 eta 0:04:50
epoch [39/50] batch [220/246] time 0.121 (0.108) data 0.000 (0.001) loss 1.2751 (1.2128) ce_loss 1.1387 (1.0764) teacher_loss 1.1501 (1.0715) loss_zs_kd 0.1633 (0.1797) loss_oracle 0.0433 (0.0515) acc 65.6250 (71.5057) kd_loss 0.0408 (0.0450) lr 3.1545e-04 eta 0:04:54
epoch [39/50] batch [240/246] time 0.105 (0.108) data 0.000 (0.001) loss 0.9560 (1.2104) ce_loss 0.8452 (1.0743) teacher_loss 0.8437 (1.0695) loss_zs_kd 0.1366 (0.1792) loss_oracle 0.0440 (0.0512) acc 78.1250 (71.6276) kd_loss 0.0347 (0.0449) lr 3.1545e-04 eta 0:04:53
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,861
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.4%, epoch: 36 *******
******* Domain r best val test acc: 90.9%, epoch: 36 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [40/50] batch [20/246] time 0.127 (0.141) data 0.001 (0.013) loss 0.6520 (1.2577) ce_loss 0.4915 (1.1200) teacher_loss 0.4927 (1.1160) loss_zs_kd 0.2322 (0.1908) loss_oracle 0.0433 (0.0463) acc 87.5000 (67.9688) kd_loss 0.0297 (0.0397) lr 2.7103e-04 eta 0:06:19
epoch [40/50] batch [40/246] time 0.120 (0.134) data 0.000 (0.007) loss 1.4997 (1.2132) ce_loss 1.3496 (1.0736) teacher_loss 1.3539 (1.0695) loss_zs_kd 0.2047 (0.1906) loss_oracle 0.0435 (0.0484) acc 65.6250 (71.1719) kd_loss 0.0307 (0.0419) lr 2.7103e-04 eta 0:05:58
epoch [40/50] batch [60/246] time 0.130 (0.132) data 0.001 (0.005) loss 0.9178 (1.2019) ce_loss 0.7490 (1.0650) teacher_loss 0.7541 (1.0609) loss_zs_kd 0.2439 (0.1871) loss_oracle 0.0418 (0.0475) acc 75.0000 (71.6146) kd_loss 0.0364 (0.0400) lr 2.7103e-04 eta 0:05:48
epoch [40/50] batch [80/246] time 0.118 (0.130) data 0.000 (0.004) loss 1.2459 (1.1925) ce_loss 1.0986 (1.0567) teacher_loss 1.0906 (1.0534) loss_zs_kd 0.2162 (0.1834) loss_oracle 0.0472 (0.0474) acc 71.8750 (72.6953) kd_loss 0.0375 (0.0400) lr 2.7103e-04 eta 0:05:42
epoch [40/50] batch [100/246] time 0.103 (0.127) data 0.000 (0.003) loss 1.3025 (1.1779) ce_loss 1.1562 (1.0422) teacher_loss 1.1533 (1.0384) loss_zs_kd 0.1965 (0.1821) loss_oracle 0.0509 (0.0485) acc 62.5000 (73.0625) kd_loss 0.0406 (0.0403) lr 2.7103e-04 eta 0:05:30
epoch [40/50] batch [120/246] time 0.102 (0.123) data 0.000 (0.002) loss 1.2608 (1.1589) ce_loss 1.1221 (1.0243) teacher_loss 1.1275 (1.0207) loss_zs_kd 0.1937 (0.1789) loss_oracle 0.0364 (0.0488) acc 75.0000 (73.6458) kd_loss 0.0279 (0.0401) lr 2.7103e-04 eta 0:05:17
epoch [40/50] batch [140/246] time 0.093 (0.120) data 0.000 (0.002) loss 1.4833 (1.1428) ce_loss 1.3672 (1.0100) teacher_loss 1.3553 (1.0068) loss_zs_kd 0.1558 (0.1754) loss_oracle 0.0501 (0.0483) acc 56.2500 (73.9509) kd_loss 0.0289 (0.0395) lr 2.7103e-04 eta 0:05:07
epoch [40/50] batch [160/246] time 0.098 (0.118) data 0.000 (0.002) loss 1.3803 (1.1507) ce_loss 1.2451 (1.0178) teacher_loss 1.2420 (1.0142) loss_zs_kd 0.2012 (0.1765) loss_oracle 0.0377 (0.0482) acc 65.6250 (73.5352) kd_loss 0.0381 (0.0393) lr 2.7103e-04 eta 0:04:59
epoch [40/50] batch [180/246] time 0.095 (0.116) data 0.000 (0.002) loss 1.0845 (1.1616) ce_loss 0.8872 (1.0282) teacher_loss 0.8892 (1.0245) loss_zs_kd 0.2810 (0.1778) loss_oracle 0.0548 (0.0483) acc 71.8750 (73.1944) kd_loss 0.0544 (0.0391) lr 2.7103e-04 eta 0:04:51
epoch [40/50] batch [200/246] time 0.109 (0.115) data 0.000 (0.002) loss 1.0572 (1.1664) ce_loss 0.9497 (1.0337) teacher_loss 0.9402 (1.0296) loss_zs_kd 0.1499 (0.1765) loss_oracle 0.0421 (0.0485) acc 78.1250 (73.0938) kd_loss 0.0444 (0.0392) lr 2.7103e-04 eta 0:04:47
epoch [40/50] batch [220/246] time 0.106 (0.113) data 0.000 (0.001) loss 1.3677 (1.1672) ce_loss 1.2031 (1.0339) teacher_loss 1.2068 (1.0297) loss_zs_kd 0.2249 (0.1774) loss_oracle 0.0484 (0.0487) acc 68.7500 (72.8977) kd_loss 0.0434 (0.0393) lr 2.7103e-04 eta 0:04:42
epoch [40/50] batch [240/246] time 0.103 (0.113) data 0.000 (0.001) loss 1.5291 (1.1722) ce_loss 1.3828 (1.0385) teacher_loss 1.3832 (1.0343) loss_zs_kd 0.1702 (0.1775) loss_oracle 0.0607 (0.0491) acc 68.7500 (72.7865) kd_loss 0.0659 (0.0396) lr 2.7103e-04 eta 0:04:37
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,864
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.4%, epoch: 36 *******
******* Domain r best val test acc: 90.9%, epoch: 36 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [41/50] batch [20/246] time 0.119 (0.127) data 0.000 (0.013) loss 1.4957 (1.1496) ce_loss 1.3262 (1.0179) teacher_loss 1.3262 (1.0147) loss_zs_kd 0.2584 (0.1738) loss_oracle 0.0404 (0.0480) acc 62.5000 (73.1250) kd_loss 0.0249 (0.0401) lr 2.2949e-04 eta 0:05:09
epoch [41/50] batch [40/246] time 0.106 (0.117) data 0.000 (0.006) loss 1.7852 (1.1783) ce_loss 1.6094 (1.0408) teacher_loss 1.5860 (1.0356) loss_zs_kd 0.2742 (0.1829) loss_oracle 0.0621 (0.0512) acc 62.5000 (73.3594) kd_loss 0.0487 (0.0411) lr 2.2949e-04 eta 0:04:42
epoch [41/50] batch [60/246] time 0.103 (0.111) data 0.001 (0.004) loss 1.1557 (1.1503) ce_loss 1.0146 (1.0158) teacher_loss 1.0172 (1.0099) loss_zs_kd 0.1632 (0.1766) loss_oracle 0.0569 (0.0521) acc 75.0000 (72.8125) kd_loss 0.0349 (0.0416) lr 2.2949e-04 eta 0:04:27
epoch [41/50] batch [80/246] time 0.101 (0.108) data 0.000 (0.003) loss 0.9919 (1.1529) ce_loss 0.8516 (1.0209) teacher_loss 0.8448 (1.0142) loss_zs_kd 0.2223 (0.1746) loss_oracle 0.0359 (0.0514) acc 78.1250 (72.3047) kd_loss 0.0346 (0.0420) lr 2.2949e-04 eta 0:04:17
epoch [41/50] batch [100/246] time 0.100 (0.107) data 0.000 (0.003) loss 0.8780 (1.1778) ce_loss 0.7764 (1.0445) teacher_loss 0.7770 (1.0382) loss_zs_kd 0.1442 (0.1768) loss_oracle 0.0289 (0.0513) acc 75.0000 (72.0000) kd_loss 0.0210 (0.0420) lr 2.2949e-04 eta 0:04:11
epoch [41/50] batch [120/246] time 0.093 (0.105) data 0.000 (0.002) loss 1.2498 (1.1937) ce_loss 1.1230 (1.0599) teacher_loss 1.1241 (1.0539) loss_zs_kd 0.1782 (0.1770) loss_oracle 0.0366 (0.0513) acc 71.8750 (71.6406) kd_loss 0.0317 (0.0418) lr 2.2949e-04 eta 0:04:06
epoch [41/50] batch [140/246] time 0.089 (0.104) data 0.000 (0.002) loss 1.1440 (1.1858) ce_loss 1.0049 (1.0521) teacher_loss 0.9885 (1.0460) loss_zs_kd 0.1826 (0.1766) loss_oracle 0.0642 (0.0515) acc 71.8750 (71.9196) kd_loss 0.0434 (0.0418) lr 2.2949e-04 eta 0:04:00
epoch [41/50] batch [160/246] time 0.108 (0.103) data 0.000 (0.002) loss 1.3255 (1.1770) ce_loss 1.1670 (1.0436) teacher_loss 1.1678 (1.0375) loss_zs_kd 0.2119 (0.1760) loss_oracle 0.0517 (0.0515) acc 68.7500 (72.1094) kd_loss 0.0374 (0.0419) lr 2.2949e-04 eta 0:03:56
epoch [41/50] batch [180/246] time 0.095 (0.102) data 0.000 (0.002) loss 1.0265 (1.1850) ce_loss 0.8691 (1.0506) teacher_loss 0.8716 (1.0452) loss_zs_kd 0.1950 (0.1771) loss_oracle 0.0575 (0.0512) acc 75.0000 (71.8576) kd_loss 0.0518 (0.0419) lr 2.2949e-04 eta 0:03:53
epoch [41/50] batch [200/246] time 0.097 (0.102) data 0.000 (0.001) loss 1.2157 (1.1783) ce_loss 1.0771 (1.0441) teacher_loss 1.0793 (1.0387) loss_zs_kd 0.1838 (0.1770) loss_oracle 0.0445 (0.0511) acc 75.0000 (72.0000) kd_loss 0.0303 (0.0417) lr 2.2949e-04 eta 0:03:49
epoch [41/50] batch [220/246] time 0.094 (0.101) data 0.001 (0.001) loss 1.5003 (1.1751) ce_loss 1.3643 (1.0409) teacher_loss 1.3556 (1.0352) loss_zs_kd 0.1616 (0.1768) loss_oracle 0.0639 (0.0515) acc 68.7500 (72.0455) kd_loss 0.0461 (0.0423) lr 2.2949e-04 eta 0:03:46
epoch [41/50] batch [240/246] time 0.086 (0.100) data 0.000 (0.001) loss 1.1129 (1.1802) ce_loss 0.9673 (1.0455) teacher_loss 0.9659 (1.0399) loss_zs_kd 0.2006 (0.1779) loss_oracle 0.0467 (0.0514) acc 75.0000 (71.9141) kd_loss 0.0538 (0.0425) lr 2.2949e-04 eta 0:03:42
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,858
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,960
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.4%, epoch: 36 *******
******* Domain r best val test acc: 90.9%, epoch: 36 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [42/50] batch [20/246] time 0.098 (0.108) data 0.000 (0.014) loss 0.6806 (1.1561) ce_loss 0.5591 (1.0247) teacher_loss 0.5663 (1.0212) loss_zs_kd 0.1364 (0.1652) loss_oracle 0.0461 (0.0523) acc 87.5000 (72.3438) kd_loss 0.0439 (0.0469) lr 1.9098e-04 eta 0:03:57
epoch [42/50] batch [40/246] time 0.085 (0.099) data 0.000 (0.007) loss 1.1407 (1.1541) ce_loss 0.9507 (1.0196) teacher_loss 0.9463 (1.0166) loss_zs_kd 0.2678 (0.1739) loss_oracle 0.0605 (0.0506) acc 78.1250 (72.7344) kd_loss 0.0566 (0.0443) lr 1.9098e-04 eta 0:03:35
epoch [42/50] batch [60/246] time 0.096 (0.097) data 0.000 (0.005) loss 1.6985 (1.1666) ce_loss 1.5703 (1.0347) teacher_loss 1.5711 (1.0318) loss_zs_kd 0.1673 (0.1709) loss_oracle 0.0437 (0.0493) acc 62.5000 (72.2396) kd_loss 0.0539 (0.0446) lr 1.9098e-04 eta 0:03:28
epoch [42/50] batch [80/246] time 0.092 (0.096) data 0.000 (0.004) loss 1.2327 (1.1887) ce_loss 1.1230 (1.0545) teacher_loss 1.1118 (1.0508) loss_zs_kd 0.1591 (0.1766) loss_oracle 0.0414 (0.0495) acc 71.8750 (71.5625) kd_loss 0.0345 (0.0449) lr 1.9098e-04 eta 0:03:23
epoch [42/50] batch [100/246] time 0.102 (0.095) data 0.000 (0.003) loss 1.4992 (1.1850) ce_loss 1.3320 (1.0507) teacher_loss 1.3419 (1.0474) loss_zs_kd 0.1918 (0.1768) loss_oracle 0.0614 (0.0492) acc 59.3750 (71.5625) kd_loss 0.0638 (0.0443) lr 1.9098e-04 eta 0:03:20
epoch [42/50] batch [120/246] time 0.083 (0.094) data 0.000 (0.002) loss 1.6289 (1.1825) ce_loss 1.5029 (1.0469) teacher_loss 1.5074 (1.0431) loss_zs_kd 0.1716 (0.1799) loss_oracle 0.0357 (0.0494) acc 59.3750 (71.5104) kd_loss 0.0259 (0.0441) lr 1.9098e-04 eta 0:03:17
epoch [42/50] batch [140/246] time 0.088 (0.094) data 0.000 (0.002) loss 0.7427 (1.1867) ce_loss 0.6084 (1.0507) teacher_loss 0.6038 (1.0464) loss_zs_kd 0.1838 (0.1803) loss_oracle 0.0470 (0.0502) acc 84.3750 (71.6071) kd_loss 0.0379 (0.0442) lr 1.9098e-04 eta 0:03:14
epoch [42/50] batch [160/246] time 0.083 (0.094) data 0.000 (0.002) loss 1.1931 (1.1879) ce_loss 1.0742 (1.0511) teacher_loss 1.0599 (1.0462) loss_zs_kd 0.1616 (0.1804) loss_oracle 0.0523 (0.0514) acc 71.8750 (71.6406) kd_loss 0.0462 (0.0450) lr 1.9098e-04 eta 0:03:12
epoch [42/50] batch [180/246] time 0.105 (0.094) data 0.000 (0.002) loss 1.0897 (1.1902) ce_loss 0.9624 (1.0525) teacher_loss 0.9750 (1.0481) loss_zs_kd 0.1671 (0.1813) loss_oracle 0.0312 (0.0514) acc 81.2500 (71.4931) kd_loss 0.0307 (0.0449) lr 1.9098e-04 eta 0:03:11
epoch [42/50] batch [200/246] time 0.084 (0.094) data 0.000 (0.002) loss 1.4273 (1.1987) ce_loss 1.2451 (1.0610) teacher_loss 1.2463 (1.0565) loss_zs_kd 0.2497 (0.1813) loss_oracle 0.0562 (0.0516) acc 59.3750 (71.4062) kd_loss 0.0501 (0.0449) lr 1.9098e-04 eta 0:03:08
epoch [42/50] batch [220/246] time 0.104 (0.094) data 0.000 (0.001) loss 0.9569 (1.1923) ce_loss 0.8203 (1.0542) teacher_loss 0.8188 (1.0498) loss_zs_kd 0.1774 (0.1818) loss_oracle 0.0494 (0.0515) acc 81.2500 (71.6903) kd_loss 0.0409 (0.0448) lr 1.9098e-04 eta 0:03:06
epoch [42/50] batch [240/246] time 0.107 (0.095) data 0.000 (0.001) loss 1.2617 (1.1914) ce_loss 1.1416 (1.0539) teacher_loss 1.1421 (1.0497) loss_zs_kd 0.1277 (0.1804) loss_oracle 0.0557 (0.0515) acc 62.5000 (71.7578) kd_loss 0.0390 (0.0451) lr 1.9098e-04 eta 0:03:06
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,868
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [43/50] batch [20/246] time 0.107 (0.124) data 0.000 (0.015) loss 0.8481 (1.1976) ce_loss 0.7290 (1.0569) teacher_loss 0.7254 (1.0497) loss_zs_kd 0.1623 (0.1895) loss_oracle 0.0415 (0.0531) acc 87.5000 (72.6562) kd_loss 0.0367 (0.0481) lr 1.5567e-04 eta 0:04:00
epoch [43/50] batch [40/246] time 0.123 (0.122) data 0.001 (0.008) loss 1.5179 (1.1567) ce_loss 1.3887 (1.0160) teacher_loss 1.3840 (1.0100) loss_zs_kd 0.1557 (0.1855) loss_oracle 0.0560 (0.0540) acc 62.5000 (73.0469) kd_loss 0.0460 (0.0483) lr 1.5567e-04 eta 0:03:54
epoch [43/50] batch [60/246] time 0.124 (0.122) data 0.001 (0.005) loss 1.9357 (1.1994) ce_loss 1.7842 (1.0582) teacher_loss 1.7779 (1.0523) loss_zs_kd 0.2181 (0.1872) loss_oracle 0.0488 (0.0535) acc 56.2500 (71.9792) kd_loss 0.0423 (0.0489) lr 1.5567e-04 eta 0:03:53
epoch [43/50] batch [80/246] time 0.126 (0.122) data 0.001 (0.004) loss 1.0813 (1.1785) ce_loss 0.9458 (1.0400) teacher_loss 0.9364 (1.0347) loss_zs_kd 0.1704 (0.1824) loss_oracle 0.0596 (0.0525) acc 78.1250 (72.3047) kd_loss 0.0494 (0.0479) lr 1.5567e-04 eta 0:03:51
epoch [43/50] batch [100/246] time 0.123 (0.123) data 0.000 (0.003) loss 1.5529 (1.2051) ce_loss 1.3672 (1.0670) teacher_loss 1.3615 (1.0614) loss_zs_kd 0.2537 (0.1811) loss_oracle 0.0645 (0.0531) acc 68.7500 (71.5938) kd_loss 0.0578 (0.0482) lr 1.5567e-04 eta 0:03:48
epoch [43/50] batch [120/246] time 0.126 (0.123) data 0.000 (0.003) loss 0.8942 (1.1888) ce_loss 0.7505 (1.0518) teacher_loss 0.7605 (1.0469) loss_zs_kd 0.1697 (0.1773) loss_oracle 0.0489 (0.0532) acc 75.0000 (71.8750) kd_loss 0.0384 (0.0484) lr 1.5567e-04 eta 0:03:46
epoch [43/50] batch [140/246] time 0.125 (0.123) data 0.000 (0.002) loss 1.3085 (1.1975) ce_loss 1.1621 (1.0602) teacher_loss 1.1656 (1.0553) loss_zs_kd 0.1659 (0.1774) loss_oracle 0.0599 (0.0535) acc 65.6250 (71.5848) kd_loss 0.0613 (0.0486) lr 1.5567e-04 eta 0:03:44
epoch [43/50] batch [160/246] time 0.126 (0.123) data 0.000 (0.002) loss 1.3255 (1.1921) ce_loss 1.1650 (1.0552) teacher_loss 1.1469 (1.0501) loss_zs_kd 0.2203 (0.1772) loss_oracle 0.0685 (0.0534) acc 68.7500 (71.8359) kd_loss 0.0561 (0.0483) lr 1.5567e-04 eta 0:03:42
epoch [43/50] batch [180/246] time 0.114 (0.123) data 0.000 (0.002) loss 0.8637 (1.1917) ce_loss 0.7417 (1.0547) teacher_loss 0.7326 (1.0495) loss_zs_kd 0.1536 (0.1777) loss_oracle 0.0544 (0.0534) acc 84.3750 (71.8924) kd_loss 0.0515 (0.0483) lr 1.5567e-04 eta 0:03:39
epoch [43/50] batch [200/246] time 0.114 (0.121) data 0.001 (0.002) loss 0.8548 (1.1928) ce_loss 0.7437 (1.0568) teacher_loss 0.7248 (1.0513) loss_zs_kd 0.1288 (0.1767) loss_oracle 0.0656 (0.0532) acc 75.0000 (71.8750) kd_loss 0.0666 (0.0481) lr 1.5567e-04 eta 0:03:34
epoch [43/50] batch [220/246] time 0.123 (0.120) data 0.000 (0.002) loss 0.8684 (1.1898) ce_loss 0.7612 (1.0532) teacher_loss 0.7640 (1.0479) loss_zs_kd 0.1191 (0.1771) loss_oracle 0.0448 (0.0534) acc 84.3750 (72.0739) kd_loss 0.0462 (0.0483) lr 1.5567e-04 eta 0:03:30
epoch [43/50] batch [240/246] time 0.099 (0.119) data 0.000 (0.002) loss 1.7426 (1.1932) ce_loss 1.6221 (1.0566) teacher_loss 1.6176 (1.0511) loss_zs_kd 0.1488 (0.1782) loss_oracle 0.0506 (0.0530) acc 59.3750 (71.9922) kd_loss 0.0395 (0.0479) lr 1.5567e-04 eta 0:03:25
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,866
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [44/50] batch [20/246] time 0.100 (0.110) data 0.000 (0.013) loss 1.1847 (1.1854) ce_loss 1.0488 (1.0443) teacher_loss 1.0392 (1.0367) loss_zs_kd 0.1479 (0.1882) loss_oracle 0.0716 (0.0546) acc 68.7500 (72.8125) kd_loss 0.0689 (0.0484) lr 1.2369e-04 eta 0:03:07
epoch [44/50] batch [40/246] time 0.093 (0.101) data 0.000 (0.007) loss 1.0896 (1.1778) ce_loss 0.9048 (1.0411) teacher_loss 0.9083 (1.0341) loss_zs_kd 0.2488 (0.1782) loss_oracle 0.0569 (0.0546) acc 75.0000 (72.9688) kd_loss 0.0523 (0.0484) lr 1.2369e-04 eta 0:02:49
epoch [44/50] batch [60/246] time 0.092 (0.099) data 0.000 (0.005) loss 1.1569 (1.1929) ce_loss 1.0312 (1.0556) teacher_loss 1.0350 (1.0478) loss_zs_kd 0.1355 (0.1802) loss_oracle 0.0542 (0.0549) acc 68.7500 (72.2396) kd_loss 0.0506 (0.0482) lr 1.2369e-04 eta 0:02:43
epoch [44/50] batch [80/246] time 0.098 (0.098) data 0.000 (0.004) loss 1.1268 (1.1891) ce_loss 0.9731 (1.0493) teacher_loss 0.9782 (1.0425) loss_zs_kd 0.2317 (0.1848) loss_oracle 0.0327 (0.0541) acc 75.0000 (72.3828) kd_loss 0.0220 (0.0479) lr 1.2369e-04 eta 0:02:40
epoch [44/50] batch [100/246] time 0.097 (0.097) data 0.000 (0.003) loss 1.1636 (1.1890) ce_loss 0.9785 (1.0477) teacher_loss 0.9853 (1.0417) loss_zs_kd 0.2308 (0.1860) loss_oracle 0.0629 (0.0543) acc 81.2500 (72.5625) kd_loss 0.0525 (0.0482) lr 1.2369e-04 eta 0:02:37
epoch [44/50] batch [120/246] time 0.091 (0.097) data 0.000 (0.002) loss 1.0449 (1.1827) ce_loss 0.9062 (1.0420) teacher_loss 0.9062 (1.0361) loss_zs_kd 0.1767 (0.1849) loss_oracle 0.0503 (0.0541) acc 75.0000 (72.7604) kd_loss 0.0429 (0.0487) lr 1.2369e-04 eta 0:02:35
epoch [44/50] batch [140/246] time 0.095 (0.097) data 0.000 (0.002) loss 0.8929 (1.1733) ce_loss 0.7666 (1.0339) teacher_loss 0.7709 (1.0283) loss_zs_kd 0.1352 (0.1822) loss_oracle 0.0545 (0.0538) acc 75.0000 (72.8125) kd_loss 0.0421 (0.0484) lr 1.2369e-04 eta 0:02:33
epoch [44/50] batch [160/246] time 0.091 (0.097) data 0.000 (0.002) loss 1.1553 (1.1831) ce_loss 0.9751 (1.0433) teacher_loss 0.9780 (1.0377) loss_zs_kd 0.2603 (0.1829) loss_oracle 0.0471 (0.0540) acc 71.8750 (72.8125) kd_loss 0.0385 (0.0484) lr 1.2369e-04 eta 0:02:30
epoch [44/50] batch [180/246] time 0.095 (0.097) data 0.000 (0.002) loss 1.1097 (1.1828) ce_loss 0.9780 (1.0436) teacher_loss 0.9739 (1.0381) loss_zs_kd 0.1433 (0.1819) loss_oracle 0.0641 (0.0537) acc 78.1250 (72.7778) kd_loss 0.0550 (0.0479) lr 1.2369e-04 eta 0:02:28
epoch [44/50] batch [200/246] time 0.092 (0.096) data 0.000 (0.002) loss 1.2216 (1.1772) ce_loss 1.1025 (1.0387) teacher_loss 1.1015 (1.0331) loss_zs_kd 0.1492 (0.1806) loss_oracle 0.0455 (0.0538) acc 71.8750 (72.7969) kd_loss 0.0339 (0.0480) lr 1.2369e-04 eta 0:02:26
epoch [44/50] batch [220/246] time 0.092 (0.096) data 0.000 (0.001) loss 1.3076 (1.1718) ce_loss 1.2168 (1.0343) teacher_loss 1.2059 (1.0286) loss_zs_kd 0.0810 (0.1784) loss_oracle 0.0611 (0.0540) acc 68.7500 (72.8267) kd_loss 0.0557 (0.0483) lr 1.2369e-04 eta 0:02:24
epoch [44/50] batch [240/246] time 0.086 (0.096) data 0.000 (0.001) loss 0.9275 (1.1743) ce_loss 0.8262 (1.0371) teacher_loss 0.8192 (1.0313) loss_zs_kd 0.1288 (0.1777) loss_oracle 0.0439 (0.0542) acc 71.8750 (72.8516) kd_loss 0.0383 (0.0483) lr 1.2369e-04 eta 0:02:21
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,866
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [45/50] batch [20/246] time 0.117 (0.124) data 0.000 (0.013) loss 1.0260 (1.2589) ce_loss 0.9067 (1.1263) teacher_loss 0.8931 (1.1199) loss_zs_kd 0.1858 (0.1741) loss_oracle 0.0400 (0.0519) acc 81.2500 (70.4688) kd_loss 0.0347 (0.0458) lr 9.5173e-05 eta 0:02:59
epoch [45/50] batch [40/246] time 0.103 (0.115) data 0.000 (0.007) loss 1.8834 (1.2041) ce_loss 1.7578 (1.0664) teacher_loss 1.7415 (1.0602) loss_zs_kd 0.1487 (0.1815) loss_oracle 0.0676 (0.0531) acc 56.2500 (72.6562) kd_loss 0.0610 (0.0488) lr 9.5173e-05 eta 0:02:45
epoch [45/50] batch [60/246] time 0.104 (0.113) data 0.001 (0.005) loss 1.3164 (1.1958) ce_loss 1.1445 (1.0560) teacher_loss 1.1433 (1.0504) loss_zs_kd 0.2168 (0.1841) loss_oracle 0.0647 (0.0533) acc 75.0000 (72.8646) kd_loss 0.0614 (0.0495) lr 9.5173e-05 eta 0:02:39
epoch [45/50] batch [80/246] time 0.094 (0.109) data 0.000 (0.003) loss 0.9440 (1.2239) ce_loss 0.7910 (1.0837) teacher_loss 0.7946 (1.0785) loss_zs_kd 0.1972 (0.1846) loss_oracle 0.0508 (0.0531) acc 84.3750 (71.9531) kd_loss 0.0418 (0.0489) lr 9.5173e-05 eta 0:02:31
epoch [45/50] batch [100/246] time 0.108 (0.109) data 0.000 (0.003) loss 1.2155 (1.2045) ce_loss 1.0527 (1.0645) teacher_loss 1.0575 (1.0589) loss_zs_kd 0.2103 (0.1849) loss_oracle 0.0528 (0.0532) acc 78.1250 (72.5000) kd_loss 0.0515 (0.0482) lr 9.5173e-05 eta 0:02:29
epoch [45/50] batch [120/246] time 0.103 (0.108) data 0.000 (0.002) loss 1.3590 (1.1925) ce_loss 1.2422 (1.0540) teacher_loss 1.2242 (1.0482) loss_zs_kd 0.1459 (0.1822) loss_oracle 0.0618 (0.0532) acc 65.6250 (72.6042) kd_loss 0.0594 (0.0481) lr 9.5173e-05 eta 0:02:26
epoch [45/50] batch [140/246] time 0.106 (0.108) data 0.000 (0.002) loss 0.8512 (1.1862) ce_loss 0.7256 (1.0477) teacher_loss 0.7131 (1.0420) loss_zs_kd 0.1555 (0.1820) loss_oracle 0.0604 (0.0532) acc 78.1250 (72.5893) kd_loss 0.0490 (0.0481) lr 9.5173e-05 eta 0:02:23
epoch [45/50] batch [160/246] time 0.112 (0.108) data 0.000 (0.002) loss 1.5304 (1.1839) ce_loss 1.4043 (1.0453) teacher_loss 1.3962 (1.0398) loss_zs_kd 0.1518 (0.1818) loss_oracle 0.0583 (0.0532) acc 62.5000 (72.5586) kd_loss 0.0486 (0.0478) lr 9.5173e-05 eta 0:02:21
epoch [45/50] batch [180/246] time 0.111 (0.107) data 0.000 (0.002) loss 1.5628 (1.1852) ce_loss 1.4336 (1.0475) teacher_loss 1.4293 (1.0418) loss_zs_kd 0.1496 (0.1804) loss_oracle 0.0587 (0.0532) acc 68.7500 (72.5521) kd_loss 0.0451 (0.0476) lr 9.5173e-05 eta 0:02:19
epoch [45/50] batch [200/246] time 0.105 (0.107) data 0.000 (0.001) loss 0.9357 (1.1820) ce_loss 0.7964 (1.0443) teacher_loss 0.7961 (1.0386) loss_zs_kd 0.1739 (0.1796) loss_oracle 0.0526 (0.0536) acc 87.5000 (72.6562) kd_loss 0.0493 (0.0474) lr 9.5173e-05 eta 0:02:16
epoch [45/50] batch [220/246] time 0.101 (0.107) data 0.000 (0.001) loss 1.4450 (1.1827) ce_loss 1.3037 (1.0453) teacher_loss 1.3058 (1.0399) loss_zs_kd 0.1786 (0.1787) loss_oracle 0.0498 (0.0535) acc 71.8750 (72.6278) kd_loss 0.0500 (0.0472) lr 9.5173e-05 eta 0:02:14
epoch [45/50] batch [240/246] time 0.090 (0.107) data 0.000 (0.001) loss 1.2232 (1.1820) ce_loss 1.0967 (1.0447) teacher_loss 1.0977 (1.0391) loss_zs_kd 0.1221 (0.1785) loss_oracle 0.0644 (0.0536) acc 75.0000 (72.5521) kd_loss 0.0587 (0.0473) lr 9.5173e-05 eta 0:02:12
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,865
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [46/50] batch [20/246] time 0.095 (0.117) data 0.000 (0.015) loss 1.2055 (1.2948) ce_loss 1.0684 (1.1586) teacher_loss 1.0600 (1.1534) loss_zs_kd 0.1715 (0.1789) loss_oracle 0.0597 (0.0520) acc 71.8750 (71.8750) kd_loss 0.0535 (0.0456) lr 7.0224e-05 eta 0:02:21
epoch [46/50] batch [40/246] time 0.099 (0.106) data 0.000 (0.008) loss 1.0858 (1.2693) ce_loss 0.9570 (1.1345) teacher_loss 0.9395 (1.1278) loss_zs_kd 0.1717 (0.1780) loss_oracle 0.0605 (0.0526) acc 75.0000 (71.1719) kd_loss 0.0517 (0.0455) lr 7.0224e-05 eta 0:02:06
epoch [46/50] batch [60/246] time 0.103 (0.103) data 0.000 (0.005) loss 1.0255 (1.2448) ce_loss 0.8301 (1.1098) teacher_loss 0.8214 (1.1033) loss_zs_kd 0.2553 (0.1766) loss_oracle 0.0764 (0.0533) acc 78.1250 (71.0938) kd_loss 0.0609 (0.0457) lr 7.0224e-05 eta 0:02:00
epoch [46/50] batch [80/246] time 0.094 (0.100) data 0.000 (0.004) loss 1.1387 (1.2369) ce_loss 1.0088 (1.1010) teacher_loss 1.0058 (1.0956) loss_zs_kd 0.1843 (0.1803) loss_oracle 0.0407 (0.0512) acc 71.8750 (71.5234) kd_loss 0.0382 (0.0440) lr 7.0224e-05 eta 0:01:55
epoch [46/50] batch [100/246] time 0.099 (0.099) data 0.000 (0.003) loss 0.9708 (1.2338) ce_loss 0.8193 (1.0975) teacher_loss 0.8242 (1.0916) loss_zs_kd 0.2040 (0.1809) loss_oracle 0.0446 (0.0517) acc 71.8750 (71.4375) kd_loss 0.0346 (0.0442) lr 7.0224e-05 eta 0:01:52
epoch [46/50] batch [120/246] time 0.096 (0.099) data 0.000 (0.003) loss 0.7039 (1.2214) ce_loss 0.5781 (1.0854) teacher_loss 0.5885 (1.0799) loss_zs_kd 0.1322 (0.1796) loss_oracle 0.0493 (0.0517) acc 81.2500 (71.7448) kd_loss 0.0412 (0.0442) lr 7.0224e-05 eta 0:01:49
epoch [46/50] batch [140/246] time 0.100 (0.099) data 0.000 (0.002) loss 0.6671 (1.1916) ce_loss 0.4924 (1.0574) teacher_loss 0.4948 (1.0522) loss_zs_kd 0.2569 (0.1757) loss_oracle 0.0439 (0.0515) acc 84.3750 (72.5446) kd_loss 0.0393 (0.0443) lr 7.0224e-05 eta 0:01:47
epoch [46/50] batch [160/246] time 0.099 (0.099) data 0.000 (0.002) loss 1.5709 (1.1859) ce_loss 1.4277 (1.0507) teacher_loss 1.4313 (1.0458) loss_zs_kd 0.2100 (0.1776) loss_oracle 0.0346 (0.0512) acc 59.3750 (72.5977) kd_loss 0.0297 (0.0440) lr 7.0224e-05 eta 0:01:46
epoch [46/50] batch [180/246] time 0.099 (0.099) data 0.000 (0.002) loss 1.1335 (1.1830) ce_loss 1.0244 (1.0475) teacher_loss 1.0107 (1.0427) loss_zs_kd 0.1432 (0.1780) loss_oracle 0.0513 (0.0513) acc 68.7500 (72.7083) kd_loss 0.0534 (0.0442) lr 7.0224e-05 eta 0:01:44
epoch [46/50] batch [200/246] time 0.126 (0.101) data 0.000 (0.002) loss 1.6910 (1.1918) ce_loss 1.5352 (1.0557) teacher_loss 1.5171 (1.0507) loss_zs_kd 0.2447 (0.1785) loss_oracle 0.0516 (0.0519) acc 56.2500 (72.3906) kd_loss 0.0512 (0.0451) lr 7.0224e-05 eta 0:01:43
epoch [46/50] batch [220/246] time 0.113 (0.102) data 0.000 (0.002) loss 1.4295 (1.1864) ce_loss 1.3242 (1.0503) teacher_loss 1.3140 (1.0453) loss_zs_kd 0.1369 (0.1785) loss_oracle 0.0470 (0.0518) acc 59.3750 (72.4716) kd_loss 0.0543 (0.0455) lr 7.0224e-05 eta 0:01:43
epoch [46/50] batch [240/246] time 0.086 (0.102) data 0.000 (0.002) loss 1.0161 (1.1894) ce_loss 0.8911 (1.0529) teacher_loss 0.8919 (1.0477) loss_zs_kd 0.1698 (0.1794) loss_oracle 0.0393 (0.0520) acc 81.2500 (72.4219) kd_loss 0.0360 (0.0457) lr 7.0224e-05 eta 0:01:41
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,868
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [47/50] batch [20/246] time 0.103 (0.118) data 0.000 (0.015) loss 1.2816 (1.1587) ce_loss 1.1816 (1.0244) teacher_loss 1.1714 (1.0177) loss_zs_kd 0.1396 (0.1795) loss_oracle 0.0404 (0.0513) acc 62.5000 (72.8125) kd_loss 0.0364 (0.0449) lr 4.8943e-05 eta 0:01:54
epoch [47/50] batch [40/246] time 0.100 (0.110) data 0.000 (0.007) loss 1.2472 (1.1708) ce_loss 1.0703 (1.0327) teacher_loss 1.0531 (1.0263) loss_zs_kd 0.2795 (0.1858) loss_oracle 0.0544 (0.0516) acc 75.0000 (72.5000) kd_loss 0.0468 (0.0473) lr 4.8943e-05 eta 0:01:43
epoch [47/50] batch [60/246] time 0.104 (0.107) data 0.001 (0.005) loss 0.8054 (1.1796) ce_loss 0.6665 (1.0417) teacher_loss 0.6538 (1.0354) loss_zs_kd 0.1959 (0.1835) loss_oracle 0.0536 (0.0524) acc 78.1250 (72.3958) kd_loss 0.0459 (0.0484) lr 4.8943e-05 eta 0:01:39
epoch [47/50] batch [80/246] time 0.112 (0.105) data 0.000 (0.004) loss 0.7550 (1.1645) ce_loss 0.6616 (1.0280) teacher_loss 0.6665 (1.0222) loss_zs_kd 0.1190 (0.1808) loss_oracle 0.0290 (0.0520) acc 81.2500 (72.6953) kd_loss 0.0287 (0.0480) lr 4.8943e-05 eta 0:01:35
epoch [47/50] batch [100/246] time 0.100 (0.104) data 0.000 (0.003) loss 1.2218 (1.1688) ce_loss 0.9707 (1.0308) teacher_loss 0.9623 (1.0253) loss_zs_kd 0.3632 (0.1822) loss_oracle 0.0780 (0.0524) acc 75.0000 (72.9375) kd_loss 0.0654 (0.0481) lr 4.8943e-05 eta 0:01:31
epoch [47/50] batch [120/246] time 0.103 (0.103) data 0.000 (0.003) loss 1.0091 (1.1890) ce_loss 0.8838 (1.0509) teacher_loss 0.8838 (1.0453) loss_zs_kd 0.1450 (0.1825) loss_oracle 0.0528 (0.0525) acc 81.2500 (72.3698) kd_loss 0.0463 (0.0478) lr 4.8943e-05 eta 0:01:28
epoch [47/50] batch [140/246] time 0.108 (0.102) data 0.000 (0.002) loss 0.9405 (1.1809) ce_loss 0.8008 (1.0430) teacher_loss 0.7981 (1.0380) loss_zs_kd 0.1870 (0.1817) loss_oracle 0.0489 (0.0521) acc 84.3750 (72.7455) kd_loss 0.0504 (0.0473) lr 4.8943e-05 eta 0:01:26
epoch [47/50] batch [160/246] time 0.097 (0.102) data 0.000 (0.002) loss 0.9033 (1.1771) ce_loss 0.7925 (1.0389) teacher_loss 0.7870 (1.0333) loss_zs_kd 0.1369 (0.1821) loss_oracle 0.0478 (0.0527) acc 81.2500 (73.1055) kd_loss 0.0389 (0.0476) lr 4.8943e-05 eta 0:01:24
epoch [47/50] batch [180/246] time 0.108 (0.103) data 0.000 (0.002) loss 0.8595 (1.1736) ce_loss 0.7261 (1.0367) teacher_loss 0.7265 (1.0310) loss_zs_kd 0.1818 (0.1800) loss_oracle 0.0422 (0.0526) acc 81.2500 (73.1597) kd_loss 0.0414 (0.0473) lr 4.8943e-05 eta 0:01:22
epoch [47/50] batch [200/246] time 0.105 (0.103) data 0.000 (0.002) loss 0.8940 (1.1676) ce_loss 0.7822 (1.0315) teacher_loss 0.7732 (1.0256) loss_zs_kd 0.1416 (0.1785) loss_oracle 0.0500 (0.0527) acc 81.2500 (73.2812) kd_loss 0.0398 (0.0473) lr 4.8943e-05 eta 0:01:20
epoch [47/50] batch [220/246] time 0.110 (0.103) data 0.000 (0.002) loss 0.8975 (1.1791) ce_loss 0.7646 (1.0429) teacher_loss 0.7598 (1.0372) loss_zs_kd 0.1693 (0.1788) loss_oracle 0.0530 (0.0525) acc 81.2500 (73.0966) kd_loss 0.0449 (0.0471) lr 4.8943e-05 eta 0:01:18
epoch [47/50] batch [240/246] time 0.104 (0.103) data 0.000 (0.001) loss 1.3788 (1.1830) ce_loss 1.2158 (1.0465) teacher_loss 1.2229 (1.0407) loss_zs_kd 0.2216 (0.1796) loss_oracle 0.0451 (0.0525) acc 71.8750 (72.8906) kd_loss 0.0311 (0.0470) lr 4.8943e-05 eta 0:01:16
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,868
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [48/50] batch [20/246] time 0.096 (0.115) data 0.000 (0.014) loss 0.7357 (1.1186) ce_loss 0.6055 (0.9768) teacher_loss 0.6137 (0.9750) loss_zs_kd 0.1548 (0.1855) loss_oracle 0.0445 (0.0509) acc 84.3750 (74.2188) kd_loss 0.0428 (0.0440) lr 3.1417e-05 eta 0:01:22
epoch [48/50] batch [40/246] time 0.092 (0.104) data 0.000 (0.007) loss 1.1499 (1.1257) ce_loss 1.0029 (0.9834) teacher_loss 0.9996 (0.9806) loss_zs_kd 0.2035 (0.1855) loss_oracle 0.0486 (0.0524) acc 71.8750 (73.5938) kd_loss 0.0414 (0.0456) lr 3.1417e-05 eta 0:01:12
epoch [48/50] batch [60/246] time 0.089 (0.101) data 0.000 (0.005) loss 1.1134 (1.1023) ce_loss 0.9399 (0.9624) teacher_loss 0.9428 (0.9594) loss_zs_kd 0.2261 (0.1813) loss_oracle 0.0575 (0.0523) acc 78.1250 (74.5312) kd_loss 0.0509 (0.0458) lr 3.1417e-05 eta 0:01:08
epoch [48/50] batch [80/246] time 0.093 (0.100) data 0.000 (0.004) loss 1.1232 (1.1299) ce_loss 0.9746 (0.9908) teacher_loss 0.9677 (0.9870) loss_zs_kd 0.1913 (0.1813) loss_oracle 0.0598 (0.0522) acc 75.0000 (73.7500) kd_loss 0.0564 (0.0464) lr 3.1417e-05 eta 0:01:05
epoch [48/50] batch [100/246] time 0.096 (0.098) data 0.000 (0.003) loss 1.4075 (1.1397) ce_loss 1.2529 (1.0019) teacher_loss 1.2378 (0.9974) loss_zs_kd 0.1858 (0.1802) loss_oracle 0.0768 (0.0523) acc 71.8750 (73.5000) kd_loss 0.0697 (0.0473) lr 3.1417e-05 eta 0:01:02
epoch [48/50] batch [120/246] time 0.093 (0.098) data 0.000 (0.003) loss 1.2717 (1.1638) ce_loss 1.1494 (1.0254) teacher_loss 1.1409 (1.0202) loss_zs_kd 0.1506 (0.1816) loss_oracle 0.0554 (0.0528) acc 71.8750 (72.8385) kd_loss 0.0365 (0.0475) lr 3.1417e-05 eta 0:01:00
epoch [48/50] batch [140/246] time 0.091 (0.098) data 0.000 (0.002) loss 1.4752 (1.1722) ce_loss 1.3506 (1.0333) teacher_loss 1.3406 (1.0281) loss_zs_kd 0.1707 (0.1829) loss_oracle 0.0493 (0.0527) acc 68.7500 (72.6562) kd_loss 0.0492 (0.0473) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [160/246] time 0.097 (0.098) data 0.001 (0.002) loss 0.8055 (1.1882) ce_loss 0.6841 (1.0496) teacher_loss 0.6688 (1.0443) loss_zs_kd 0.1565 (0.1824) loss_oracle 0.0585 (0.0527) acc 78.1250 (72.2852) kd_loss 0.0660 (0.0474) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [180/246] time 0.096 (0.098) data 0.000 (0.002) loss 1.4875 (1.1835) ce_loss 1.3662 (1.0454) teacher_loss 1.3497 (1.0405) loss_zs_kd 0.1535 (0.1809) loss_oracle 0.0611 (0.0526) acc 62.5000 (72.3785) kd_loss 0.0438 (0.0472) lr 3.1417e-05 eta 0:00:54
epoch [48/50] batch [200/246] time 0.097 (0.098) data 0.000 (0.002) loss 1.4365 (1.1978) ce_loss 1.3008 (1.0601) teacher_loss 1.2879 (1.0549) loss_zs_kd 0.1662 (0.1808) loss_oracle 0.0655 (0.0525) acc 65.6250 (72.0156) kd_loss 0.0581 (0.0471) lr 3.1417e-05 eta 0:00:52
epoch [48/50] batch [220/246] time 0.092 (0.098) data 0.000 (0.002) loss 1.2862 (1.2056) ce_loss 1.1260 (1.0673) teacher_loss 1.1244 (1.0619) loss_zs_kd 0.2111 (0.1814) loss_oracle 0.0562 (0.0529) acc 71.8750 (71.9176) kd_loss 0.0415 (0.0472) lr 3.1417e-05 eta 0:00:50
epoch [48/50] batch [240/246] time 0.085 (0.097) data 0.000 (0.001) loss 1.6052 (1.2118) ce_loss 1.4844 (1.0735) teacher_loss 1.4762 (1.0681) loss_zs_kd 0.1575 (0.1812) loss_oracle 0.0502 (0.0531) acc 62.5000 (71.8490) kd_loss 0.0452 (0.0473) lr 3.1417e-05 eta 0:00:48
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,869
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 48 *******
******* Domain r best val test acc: 90.8%, epoch: 48 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [49/50] batch [20/246] time 0.092 (0.115) data 0.000 (0.014) loss 1.3294 (1.1739) ce_loss 1.2012 (1.0328) teacher_loss 1.2042 (1.0270) loss_zs_kd 0.1649 (0.1869) loss_oracle 0.0428 (0.0534) acc 62.5000 (74.5312) kd_loss 0.0322 (0.0467) lr 1.7713e-05 eta 0:00:54
epoch [49/50] batch [40/246] time 0.091 (0.105) data 0.000 (0.007) loss 1.2086 (1.1327) ce_loss 1.0605 (0.9933) teacher_loss 1.0475 (0.9872) loss_zs_kd 0.2016 (0.1823) loss_oracle 0.0603 (0.0544) acc 75.0000 (74.4531) kd_loss 0.0493 (0.0460) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [60/246] time 0.093 (0.101) data 0.000 (0.005) loss 1.0453 (1.1660) ce_loss 0.8789 (1.0278) teacher_loss 0.8673 (1.0205) loss_zs_kd 0.2600 (0.1814) loss_oracle 0.0480 (0.0548) acc 84.3750 (72.7083) kd_loss 0.0439 (0.0460) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [80/246] time 0.089 (0.100) data 0.000 (0.004) loss 1.3163 (1.1611) ce_loss 1.1719 (1.0249) teacher_loss 1.1678 (1.0183) loss_zs_kd 0.1951 (0.1779) loss_oracle 0.0509 (0.0539) acc 71.8750 (72.7344) kd_loss 0.0409 (0.0455) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [100/246] time 0.091 (0.099) data 0.000 (0.003) loss 1.4169 (1.1950) ce_loss 1.2588 (1.0598) teacher_loss 1.2564 (1.0530) loss_zs_kd 0.2235 (0.1767) loss_oracle 0.0487 (0.0536) acc 68.7500 (72.0000) kd_loss 0.0474 (0.0458) lr 1.7713e-05 eta 0:00:38
epoch [49/50] batch [120/246] time 0.090 (0.098) data 0.000 (0.002) loss 0.7742 (1.1834) ce_loss 0.6108 (1.0489) teacher_loss 0.6058 (1.0425) loss_zs_kd 0.1961 (0.1737) loss_oracle 0.0703 (0.0540) acc 84.3750 (72.4479) kd_loss 0.0530 (0.0460) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [140/246] time 0.093 (0.098) data 0.000 (0.002) loss 1.4821 (1.1817) ce_loss 1.3672 (1.0475) teacher_loss 1.3594 (1.0412) loss_zs_kd 0.1602 (0.1739) loss_oracle 0.0426 (0.0535) acc 65.6250 (72.4777) kd_loss 0.0340 (0.0457) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [160/246] time 0.097 (0.098) data 0.000 (0.002) loss 1.6825 (1.1842) ce_loss 1.5498 (1.0493) teacher_loss 1.5261 (1.0427) loss_zs_kd 0.2040 (0.1753) loss_oracle 0.0545 (0.0539) acc 59.3750 (72.4219) kd_loss 0.0482 (0.0463) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [180/246] time 0.099 (0.098) data 0.000 (0.002) loss 1.0580 (1.1846) ce_loss 0.9116 (1.0492) teacher_loss 0.9019 (1.0427) loss_zs_kd 0.1729 (0.1760) loss_oracle 0.0696 (0.0540) acc 75.0000 (72.4653) kd_loss 0.0635 (0.0464) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [200/246] time 0.092 (0.097) data 0.000 (0.002) loss 1.7986 (1.1934) ce_loss 1.6699 (1.0576) teacher_loss 1.6580 (1.0509) loss_zs_kd 0.2002 (0.1770) loss_oracle 0.0404 (0.0540) acc 50.0000 (72.2969) kd_loss 0.0380 (0.0465) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [220/246] time 0.091 (0.097) data 0.000 (0.001) loss 1.0647 (1.1902) ce_loss 0.8906 (1.0535) teacher_loss 0.8782 (1.0470) loss_zs_kd 0.2524 (0.1782) loss_oracle 0.0603 (0.0541) acc 78.1250 (72.4148) kd_loss 0.0508 (0.0469) lr 1.7713e-05 eta 0:00:26
epoch [49/50] batch [240/246] time 0.091 (0.097) data 0.000 (0.001) loss 1.1410 (1.1836) ce_loss 1.0039 (1.0470) teacher_loss 1.0016 (1.0402) loss_zs_kd 0.1764 (0.1778) loss_oracle 0.0512 (0.0544) acc 75.0000 (72.5000) kd_loss 0.0452 (0.0474) lr 1.7713e-05 eta 0:00:24
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,869
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 48 *******
******* Domain r best val test acc: 90.8%, epoch: 48 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [50/50] batch [20/246] time 0.097 (0.115) data 0.000 (0.013) loss 1.2418 (1.1451) ce_loss 1.0742 (1.0012) teacher_loss 1.0658 (0.9954) loss_zs_kd 0.2343 (0.1849) loss_oracle 0.0588 (0.0572) acc 68.7500 (73.1250) kd_loss 0.0578 (0.0521) lr 7.8853e-06 eta 0:00:26
epoch [50/50] batch [40/246] time 0.098 (0.105) data 0.000 (0.007) loss 1.2849 (1.1342) ce_loss 1.1416 (0.9955) teacher_loss 1.1355 (0.9888) loss_zs_kd 0.1743 (0.1812) loss_oracle 0.0622 (0.0548) acc 78.1250 (73.8281) kd_loss 0.0540 (0.0499) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [60/246] time 0.094 (0.102) data 0.000 (0.005) loss 1.5845 (1.1572) ce_loss 1.4453 (1.0183) teacher_loss 1.4266 (1.0111) loss_zs_kd 0.2133 (0.1831) loss_oracle 0.0512 (0.0546) acc 62.5000 (73.4896) kd_loss 0.0503 (0.0497) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [80/246] time 0.094 (0.100) data 0.000 (0.004) loss 1.2363 (1.1824) ce_loss 1.1250 (1.0451) teacher_loss 1.1252 (1.0365) loss_zs_kd 0.1477 (0.1802) loss_oracle 0.0372 (0.0557) acc 68.7500 (72.6562) kd_loss 0.0318 (0.0502) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [100/246] time 0.094 (0.099) data 0.000 (0.003) loss 1.9985 (1.2004) ce_loss 1.8496 (1.0635) teacher_loss 1.8573 (1.0552) loss_zs_kd 0.2061 (0.1794) loss_oracle 0.0381 (0.0555) acc 62.5000 (72.1875) kd_loss 0.0312 (0.0503) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [120/246] time 0.094 (0.099) data 0.000 (0.002) loss 0.9037 (1.1997) ce_loss 0.7695 (1.0612) teacher_loss 0.7397 (1.0531) loss_zs_kd 0.1969 (0.1821) loss_oracle 0.0655 (0.0556) acc 75.0000 (72.1615) kd_loss 0.0590 (0.0507) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [140/246] time 0.091 (0.098) data 0.000 (0.002) loss 1.0329 (1.1913) ce_loss 0.9126 (1.0536) teacher_loss 0.9054 (1.0457) loss_zs_kd 0.1548 (0.1802) loss_oracle 0.0501 (0.0556) acc 81.2500 (72.4107) kd_loss 0.0503 (0.0508) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [160/246] time 0.093 (0.097) data 0.000 (0.002) loss 0.9718 (1.1959) ce_loss 0.8438 (1.0583) teacher_loss 0.8308 (1.0502) loss_zs_kd 0.1750 (0.1804) loss_oracle 0.0534 (0.0555) acc 81.2500 (72.4609) kd_loss 0.0467 (0.0507) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [180/246] time 0.089 (0.097) data 0.000 (0.002) loss 1.0532 (1.1894) ce_loss 0.8979 (1.0513) teacher_loss 0.9016 (1.0435) loss_zs_kd 0.1995 (0.1808) loss_oracle 0.0518 (0.0555) acc 78.1250 (72.5347) kd_loss 0.0533 (0.0503) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [200/246] time 0.097 (0.097) data 0.000 (0.002) loss 1.4240 (1.1869) ce_loss 1.3086 (1.0487) teacher_loss 1.2872 (1.0414) loss_zs_kd 0.1826 (0.1800) loss_oracle 0.0454 (0.0556) acc 59.3750 (72.7656) kd_loss 0.0393 (0.0503) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [220/246] time 0.094 (0.096) data 0.000 (0.001) loss 1.6788 (1.1973) ce_loss 1.5342 (1.0588) teacher_loss 1.5254 (1.0516) loss_zs_kd 0.1816 (0.1807) loss_oracle 0.0626 (0.0554) acc 59.3750 (72.5426) kd_loss 0.0560 (0.0499) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [240/246] time 0.087 (0.096) data 0.000 (0.001) loss 1.3929 (1.1971) ce_loss 1.2305 (1.0588) teacher_loss 1.2332 (1.0518) loss_zs_kd 0.2030 (0.1798) loss_oracle 0.0582 (0.0554) acc 62.5000 (72.3307) kd_loss 0.0436 (0.0499) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,869
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.5%, epoch: 48 *******
******* Domain r best val test acc: 90.8%, epoch: 48 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:27:44

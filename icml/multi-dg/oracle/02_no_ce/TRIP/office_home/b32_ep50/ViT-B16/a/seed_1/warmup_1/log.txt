Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------------
Dataset    SPG_OfficeHome
Source     ['clipart', 'product', 'real_world']
Target     ['art']
# classes  65
# train_x  9,222
# val      3,939
# test     2,427
---------  ------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/288] time 0.157 (0.200) data 0.000 (0.019) loss 1.1134 (1.2413) ce_loss 1.1113 (1.2380) teacher_loss 1.1109 (1.2381) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0025 (0.0032) acc 68.7500 (68.2812) kd_loss 0.0097 (0.0128) lr 1.0000e-05 eta 0:47:57
epoch [1/50] batch [40/288] time 0.155 (0.185) data 0.000 (0.010) loss 1.2206 (1.2627) ce_loss 1.2168 (1.2595) teacher_loss 1.2164 (1.2595) loss_zs_kd 0.0002 (0.0000) loss_oracle 0.0041 (0.0032) acc 65.6250 (68.2031) kd_loss 0.0168 (0.0129) lr 1.0000e-05 eta 0:44:10
epoch [1/50] batch [60/288] time 0.152 (0.178) data 0.000 (0.007) loss 1.4309 (1.2694) ce_loss 1.4297 (1.2663) teacher_loss 1.4285 (1.2663) loss_zs_kd 0.0006 (0.0001) loss_oracle 0.0021 (0.0030) acc 59.3750 (67.6042) kd_loss 0.0076 (0.0122) lr 1.0000e-05 eta 0:42:34
epoch [1/50] batch [80/288] time 0.177 (0.175) data 0.002 (0.005) loss 1.2614 (1.2732) ce_loss 1.2578 (1.2704) teacher_loss 1.2569 (1.2703) loss_zs_kd 0.0008 (0.0002) loss_oracle 0.0040 (0.0029) acc 62.5000 (67.3828) kd_loss 0.0158 (0.0115) lr 1.0000e-05 eta 0:41:45
epoch [1/50] batch [100/288] time 0.096 (0.177) data 0.000 (0.004) loss 1.0926 (1.2454) ce_loss 1.0908 (1.2427) teacher_loss 1.0898 (1.2425) loss_zs_kd 0.0005 (0.0003) loss_oracle 0.0025 (0.0027) acc 62.5000 (68.0938) kd_loss 0.0101 (0.0106) lr 1.0000e-05 eta 0:42:07
epoch [1/50] batch [120/288] time 0.149 (0.185) data 0.000 (0.003) loss 1.0349 (1.2390) ce_loss 1.0352 (1.2366) teacher_loss 1.0325 (1.2363) loss_zs_kd 0.0007 (0.0004) loss_oracle 0.0021 (0.0025) acc 75.0000 (68.1510) kd_loss 0.0066 (0.0097) lr 1.0000e-05 eta 0:44:00
epoch [1/50] batch [140/288] time 0.154 (0.181) data 0.000 (0.003) loss 1.4868 (1.2249) ce_loss 1.4863 (1.2226) teacher_loss 1.4844 (1.2224) loss_zs_kd 0.0010 (0.0005) loss_oracle 0.0019 (0.0023) acc 56.2500 (68.2812) kd_loss 0.0050 (0.0090) lr 1.0000e-05 eta 0:43:06
epoch [1/50] batch [160/288] time 0.158 (0.179) data 0.000 (0.003) loss 1.0574 (1.2224) ce_loss 1.0547 (1.2202) teacher_loss 1.0557 (1.2199) loss_zs_kd 0.0019 (0.0006) loss_oracle 0.0008 (0.0022) acc 71.8750 (68.6133) kd_loss 0.0024 (0.0084) lr 1.0000e-05 eta 0:42:26
epoch [1/50] batch [180/288] time 0.161 (0.177) data 0.000 (0.002) loss 0.9956 (1.2259) ce_loss 0.9922 (1.2237) teacher_loss 0.9936 (1.2234) loss_zs_kd 0.0023 (0.0007) loss_oracle 0.0008 (0.0021) acc 71.8750 (68.4375) kd_loss 0.0026 (0.0079) lr 1.0000e-05 eta 0:41:51
epoch [1/50] batch [200/288] time 0.164 (0.175) data 0.000 (0.002) loss 1.3386 (1.2226) ce_loss 1.3379 (1.2205) teacher_loss 1.3370 (1.2202) loss_zs_kd 0.0020 (0.0008) loss_oracle 0.0007 (0.0020) acc 62.5000 (68.3281) kd_loss 0.0028 (0.0075) lr 1.0000e-05 eta 0:41:28
epoch [1/50] batch [220/288] time 0.102 (0.173) data 0.000 (0.002) loss 1.4192 (1.2183) ce_loss 1.4160 (1.2161) teacher_loss 1.4172 (1.2159) loss_zs_kd 0.0022 (0.0010) loss_oracle 0.0009 (0.0019) acc 65.6250 (68.5938) kd_loss 0.0028 (0.0070) lr 1.0000e-05 eta 0:40:57
epoch [1/50] batch [240/288] time 0.360 (0.176) data 0.000 (0.002) loss 0.9869 (1.2158) ce_loss 0.9849 (1.2137) teacher_loss 0.9854 (1.2135) loss_zs_kd 0.0010 (0.0011) loss_oracle 0.0010 (0.0018) acc 81.2500 (68.8542) kd_loss 0.0038 (0.0067) lr 1.0000e-05 eta 0:41:39
epoch [1/50] batch [260/288] time 0.150 (0.177) data 0.000 (0.002) loss 1.3066 (1.2215) ce_loss 1.3037 (1.2193) teacher_loss 1.3031 (1.2191) loss_zs_kd 0.0053 (0.0012) loss_oracle 0.0009 (0.0017) acc 71.8750 (68.7019) kd_loss 0.0024 (0.0064) lr 1.0000e-05 eta 0:41:48
epoch [1/50] batch [280/288] time 0.159 (0.176) data 0.000 (0.002) loss 1.5228 (1.2214) ce_loss 1.5186 (1.2192) teacher_loss 1.5193 (1.2190) loss_zs_kd 0.0052 (0.0014) loss_oracle 0.0009 (0.0017) acc 62.5000 (68.7612) kd_loss 0.0027 (0.0061) lr 1.0000e-05 eta 0:41:24
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,264
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 81.9%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,963
* accuracy: 80.9%
* error: 19.1%
* macro_f1: 76.6%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      82.9%, epoch: 1 *******
******* Domain a best val test acc: 80.9%, epoch: 1 *******
******* Domain a best test acc:     80.9%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/ana
epoch [2/50] batch [20/288] time 0.117 (0.179) data 0.000 (0.015) loss 1.1004 (1.2407) ce_loss 1.0449 (1.1904) teacher_loss 1.0464 (1.1909) loss_zs_kd 0.0997 (0.0958) loss_oracle 0.0041 (0.0019) acc 65.6250 (68.7500) kd_loss 0.0024 (0.0020) lr 2.0000e-03 eta 0:42:03
epoch [2/50] batch [40/288] time 0.358 (0.217) data 0.000 (0.008) loss 0.7482 (1.1873) ce_loss 0.6919 (1.1246) teacher_loss 0.6936 (1.1264) loss_zs_kd 0.0867 (0.1083) loss_oracle 0.0113 (0.0067) acc 81.2500 (70.2344) kd_loss 0.0011 (0.0019) lr 2.0000e-03 eta 0:50:55
epoch [2/50] batch [60/288] time 0.168 (0.194) data 0.000 (0.005) loss 1.3856 (1.1918) ce_loss 1.3242 (1.1282) teacher_loss 1.3259 (1.1300) loss_zs_kd 0.0938 (0.1062) loss_oracle 0.0129 (0.0087) acc 68.7500 (70.5208) kd_loss 0.0031 (0.0020) lr 2.0000e-03 eta 0:45:29
epoch [2/50] batch [80/288] time 0.171 (0.185) data 0.000 (0.004) loss 0.8877 (1.1756) ce_loss 0.8394 (1.1136) teacher_loss 0.8410 (1.1154) loss_zs_kd 0.0810 (0.1021) loss_oracle 0.0062 (0.0092) acc 71.8750 (71.2891) kd_loss 0.0021 (0.0022) lr 2.0000e-03 eta 0:43:10
epoch [2/50] batch [100/288] time 0.146 (0.179) data 0.000 (0.003) loss 1.5377 (1.1742) ce_loss 1.4922 (1.1133) teacher_loss 1.4937 (1.1150) loss_zs_kd 0.0768 (0.1010) loss_oracle 0.0055 (0.0087) acc 62.5000 (71.2812) kd_loss 0.0034 (0.0023) lr 2.0000e-03 eta 0:41:42
epoch [2/50] batch [120/288] time 0.157 (0.175) data 0.000 (0.003) loss 1.1474 (1.1694) ce_loss 1.1094 (1.1092) teacher_loss 1.1120 (1.1107) loss_zs_kd 0.0552 (0.1007) loss_oracle 0.0078 (0.0084) acc 71.8750 (71.2500) kd_loss 0.0026 (0.0025) lr 2.0000e-03 eta 0:40:45
epoch [2/50] batch [140/288] time 0.153 (0.172) data 0.000 (0.002) loss 1.2924 (1.1729) ce_loss 1.2139 (1.1135) teacher_loss 1.2175 (1.1150) loss_zs_kd 0.1238 (0.0979) loss_oracle 0.0129 (0.0090) acc 68.7500 (71.0045) kd_loss 0.0039 (0.0026) lr 2.0000e-03 eta 0:40:07
epoch [2/50] batch [160/288] time 0.112 (0.170) data 0.000 (0.002) loss 1.2174 (1.1743) ce_loss 1.1055 (1.1136) teacher_loss 1.1109 (1.1154) loss_zs_kd 0.1708 (0.0973) loss_oracle 0.0211 (0.0102) acc 68.7500 (70.9570) kd_loss 0.0047 (0.0028) lr 2.0000e-03 eta 0:39:29
epoch [2/50] batch [180/288] time 0.392 (0.176) data 0.000 (0.002) loss 1.0765 (1.1705) ce_loss 1.0020 (1.1080) teacher_loss 1.0063 (1.1099) loss_zs_kd 0.1072 (0.0982) loss_oracle 0.0166 (0.0115) acc 78.1250 (71.0938) kd_loss 0.0049 (0.0030) lr 2.0000e-03 eta 0:40:46
epoch [2/50] batch [200/288] time 0.160 (0.175) data 0.000 (0.002) loss 1.8515 (1.1742) ce_loss 1.7373 (1.1092) teacher_loss 1.7442 (1.1112) loss_zs_kd 0.1532 (0.1011) loss_oracle 0.0307 (0.0124) acc 56.2500 (70.9375) kd_loss 0.0068 (0.0032) lr 2.0000e-03 eta 0:40:38
epoch [2/50] batch [220/288] time 0.151 (0.174) data 0.000 (0.002) loss 1.2323 (1.1658) ce_loss 1.1328 (1.0977) teacher_loss 1.1318 (1.1000) loss_zs_kd 0.1170 (0.1017) loss_oracle 0.0420 (0.0150) acc 71.8750 (71.1932) kd_loss 0.0083 (0.0036) lr 2.0000e-03 eta 0:40:11
epoch [2/50] batch [240/288] time 0.147 (0.172) data 0.000 (0.001) loss 1.4728 (1.1626) ce_loss 1.3877 (1.0930) teacher_loss 1.3902 (1.0952) loss_zs_kd 0.0970 (0.1019) loss_oracle 0.0341 (0.0164) acc 65.6250 (71.2760) kd_loss 0.0086 (0.0040) lr 2.0000e-03 eta 0:39:50
epoch [2/50] batch [260/288] time 0.145 (0.171) data 0.000 (0.001) loss 1.1971 (1.1599) ce_loss 1.0752 (1.0884) teacher_loss 1.0748 (1.0907) loss_zs_kd 0.1907 (0.1029) loss_oracle 0.0270 (0.0178) acc 78.1250 (71.3822) kd_loss 0.0110 (0.0046) lr 2.0000e-03 eta 0:39:33
epoch [2/50] batch [280/288] time 0.139 (0.170) data 0.000 (0.001) loss 0.9149 (1.1561) ce_loss 0.8145 (1.0837) teacher_loss 0.8171 (1.0859) loss_zs_kd 0.1273 (0.1033) loss_oracle 0.0342 (0.0186) acc 75.0000 (71.4286) kd_loss 0.0142 (0.0052) lr 2.0000e-03 eta 0:39:13
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,389
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 85.4%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,025
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 79.8%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.0%, epoch: 2 *******
******* Domain a best val test acc: 83.4%, epoch: 2 *******
******* Domain a best test acc:     83.4%, epoch: 2 *******
epoch [3/50] batch [20/288] time 0.153 (0.174) data 0.000 (0.013) loss 1.5862 (1.1730) ce_loss 1.4844 (1.0715) teacher_loss 1.4894 (1.0729) loss_zs_kd 0.1307 (0.1162) loss_oracle 0.0315 (0.0420) acc 53.1250 (71.7188) kd_loss 0.0133 (0.0150) lr 1.9980e-03 eta 0:40:02
epoch [3/50] batch [40/288] time 0.164 (0.169) data 0.000 (0.007) loss 0.9312 (1.0908) ce_loss 0.8613 (0.9983) teacher_loss 0.8680 (1.0006) loss_zs_kd 0.0716 (0.1084) loss_oracle 0.0274 (0.0359) acc 78.1250 (73.6719) kd_loss 0.0156 (0.0152) lr 1.9980e-03 eta 0:38:52
epoch [3/50] batch [60/288] time 0.169 (0.168) data 0.000 (0.005) loss 1.0133 (1.1357) ce_loss 0.9365 (1.0461) teacher_loss 0.9385 (1.0483) loss_zs_kd 0.0838 (0.1076) loss_oracle 0.0328 (0.0335) acc 75.0000 (72.6562) kd_loss 0.0197 (0.0156) lr 1.9980e-03 eta 0:38:25
epoch [3/50] batch [80/288] time 0.159 (0.167) data 0.000 (0.003) loss 1.1270 (1.1428) ce_loss 1.0068 (1.0484) teacher_loss 1.0117 (1.0510) loss_zs_kd 0.1045 (0.1080) loss_oracle 0.0631 (0.0377) acc 75.0000 (72.5781) kd_loss 0.0179 (0.0161) lr 1.9980e-03 eta 0:38:18
epoch [3/50] batch [100/288] time 0.099 (0.170) data 0.000 (0.003) loss 1.0634 (1.1567) ce_loss 0.9629 (1.0599) teacher_loss 0.9677 (1.0625) loss_zs_kd 0.0964 (0.1085) loss_oracle 0.0475 (0.0400) acc 75.0000 (72.2812) kd_loss 0.0233 (0.0176) lr 1.9980e-03 eta 0:38:49
epoch [3/50] batch [120/288] time 0.147 (0.177) data 0.000 (0.002) loss 0.8940 (1.1536) ce_loss 0.7051 (1.0491) teacher_loss 0.7066 (1.0519) loss_zs_kd 0.1336 (0.1125) loss_oracle 0.1206 (0.0454) acc 78.1250 (72.6562) kd_loss 0.0390 (0.0197) lr 1.9980e-03 eta 0:40:31
epoch [3/50] batch [140/288] time 0.151 (0.174) data 0.000 (0.002) loss 1.1135 (1.1556) ce_loss 0.9937 (1.0449) teacher_loss 0.9944 (1.0475) loss_zs_kd 0.0731 (0.1130) loss_oracle 0.0825 (0.0517) acc 75.0000 (72.5670) kd_loss 0.0422 (0.0226) lr 1.9980e-03 eta 0:39:41
epoch [3/50] batch [160/288] time 0.155 (0.172) data 0.000 (0.002) loss 1.6860 (1.1649) ce_loss 1.5361 (1.0495) teacher_loss 1.5479 (1.0521) loss_zs_kd 0.1410 (0.1147) loss_oracle 0.0676 (0.0554) acc 59.3750 (72.3438) kd_loss 0.0385 (0.0248) lr 1.9980e-03 eta 0:39:12
epoch [3/50] batch [180/288] time 0.177 (0.172) data 0.000 (0.002) loss 1.2223 (1.1663) ce_loss 1.1016 (1.0495) teacher_loss 1.1080 (1.0519) loss_zs_kd 0.1184 (0.1139) loss_oracle 0.0550 (0.0575) acc 71.8750 (72.3958) kd_loss 0.0355 (0.0266) lr 1.9980e-03 eta 0:39:02
epoch [3/50] batch [200/288] time 0.153 (0.170) data 0.000 (0.002) loss 1.1610 (1.1677) ce_loss 1.0195 (1.0478) teacher_loss 1.0167 (1.0496) loss_zs_kd 0.0948 (0.1139) loss_oracle 0.0969 (0.0611) acc 75.0000 (72.5000) kd_loss 0.0559 (0.0288) lr 1.9980e-03 eta 0:38:42
epoch [3/50] batch [220/288] time 0.095 (0.169) data 0.000 (0.001) loss 0.9413 (1.1797) ce_loss 0.8281 (1.0576) teacher_loss 0.8327 (1.0592) loss_zs_kd 0.1146 (0.1154) loss_oracle 0.0514 (0.0629) acc 75.0000 (72.3011) kd_loss 0.0478 (0.0310) lr 1.9980e-03 eta 0:38:25
epoch [3/50] batch [240/288] time 0.350 (0.174) data 0.000 (0.001) loss 1.4150 (1.1820) ce_loss 1.3096 (1.0616) teacher_loss 1.3128 (1.0629) loss_zs_kd 0.0925 (0.1151) loss_oracle 0.0560 (0.0615) acc 65.6250 (72.2135) kd_loss 0.0551 (0.0325) lr 1.9980e-03 eta 0:39:21
epoch [3/50] batch [260/288] time 0.173 (0.175) data 0.000 (0.001) loss 0.7775 (1.1760) ce_loss 0.6792 (1.0568) teacher_loss 0.6425 (1.0580) loss_zs_kd 0.1177 (0.1153) loss_oracle 0.0761 (0.0603) acc 87.5000 (72.2356) kd_loss 0.0533 (0.0335) lr 1.9980e-03 eta 0:39:32
epoch [3/50] batch [280/288] time 0.160 (0.174) data 0.000 (0.001) loss 1.2810 (1.1732) ce_loss 1.1074 (1.0529) teacher_loss 1.1031 (1.0540) loss_zs_kd 0.1946 (0.1166) loss_oracle 0.0807 (0.0609) acc 68.7500 (72.3884) kd_loss 0.0552 (0.0345) lr 1.9980e-03 eta 0:39:13
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,396
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 85.5%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,012
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.3%
******* Domain a best val acc:      86.2%, epoch: 3 *******
******* Domain a best val test acc: 82.9%, epoch: 3 *******
******* Domain a best test acc:     83.4%, epoch: 2 *******
epoch [4/50] batch [20/288] time 0.175 (0.172) data 0.000 (0.013) loss 0.9972 (1.1230) ce_loss 0.8447 (0.9918) teacher_loss 0.8464 (0.9895) loss_zs_kd 0.0936 (0.1104) loss_oracle 0.1039 (0.0784) acc 84.3750 (73.5938) kd_loss 0.0472 (0.0466) lr 1.9921e-03 eta 0:38:42
epoch [4/50] batch [40/288] time 0.085 (0.171) data 0.000 (0.007) loss 1.2443 (1.1291) ce_loss 1.1035 (1.0011) teacher_loss 1.1008 (0.9996) loss_zs_kd 0.1979 (0.1158) loss_oracle 0.0445 (0.0716) acc 68.7500 (73.2031) kd_loss 0.0413 (0.0459) lr 1.9921e-03 eta 0:38:23
epoch [4/50] batch [60/288] time 0.167 (0.189) data 0.000 (0.005) loss 1.2833 (1.1123) ce_loss 1.1934 (0.9929) teacher_loss 1.2010 (0.9933) loss_zs_kd 0.0900 (0.1133) loss_oracle 0.0373 (0.0623) acc 68.7500 (73.2292) kd_loss 0.0319 (0.0453) lr 1.9921e-03 eta 0:42:25
epoch [4/50] batch [80/288] time 0.168 (0.182) data 0.000 (0.003) loss 1.5281 (1.1271) ce_loss 1.4326 (1.0122) teacher_loss 1.4418 (1.0126) loss_zs_kd 0.0916 (0.1111) loss_oracle 0.0406 (0.0589) acc 65.6250 (73.1250) kd_loss 0.0349 (0.0441) lr 1.9921e-03 eta 0:40:49
epoch [4/50] batch [100/288] time 0.165 (0.178) data 0.000 (0.003) loss 1.0297 (1.1429) ce_loss 0.9512 (1.0329) teacher_loss 0.9394 (1.0332) loss_zs_kd 0.0827 (0.1075) loss_oracle 0.0490 (0.0559) acc 78.1250 (72.6250) kd_loss 0.0375 (0.0423) lr 1.9921e-03 eta 0:39:46
epoch [4/50] batch [120/288] time 0.148 (0.175) data 0.000 (0.002) loss 1.0568 (1.1498) ce_loss 0.9473 (1.0411) teacher_loss 0.9523 (1.0412) loss_zs_kd 0.1095 (0.1066) loss_oracle 0.0498 (0.0552) acc 78.1250 (72.5000) kd_loss 0.0298 (0.0411) lr 1.9921e-03 eta 0:39:01
epoch [4/50] batch [140/288] time 0.170 (0.173) data 0.000 (0.002) loss 0.8833 (1.1564) ce_loss 0.8018 (1.0477) teacher_loss 0.8045 (1.0477) loss_zs_kd 0.0958 (0.1082) loss_oracle 0.0309 (0.0546) acc 81.2500 (72.3661) kd_loss 0.0244 (0.0401) lr 1.9921e-03 eta 0:38:32
epoch [4/50] batch [160/288] time 0.427 (0.173) data 0.000 (0.002) loss 1.3109 (1.1485) ce_loss 1.2285 (1.0406) teacher_loss 1.2214 (1.0404) loss_zs_kd 0.1125 (0.1106) loss_oracle 0.0332 (0.0529) acc 71.8750 (72.4414) kd_loss 0.0294 (0.0392) lr 1.9921e-03 eta 0:38:27
epoch [4/50] batch [180/288] time 0.098 (0.179) data 0.000 (0.002) loss 1.5030 (1.1452) ce_loss 1.3857 (1.0383) teacher_loss 1.3870 (1.0381) loss_zs_kd 0.1500 (0.1114) loss_oracle 0.0410 (0.0514) acc 62.5000 (72.3958) kd_loss 0.0221 (0.0381) lr 1.9921e-03 eta 0:39:54
epoch [4/50] batch [200/288] time 0.151 (0.177) data 0.000 (0.002) loss 1.2289 (1.1433) ce_loss 1.1201 (1.0352) teacher_loss 1.1192 (1.0351) loss_zs_kd 0.1079 (0.1140) loss_oracle 0.0557 (0.0512) acc 71.8750 (72.6250) kd_loss 0.0292 (0.0371) lr 1.9921e-03 eta 0:39:20
epoch [4/50] batch [220/288] time 0.161 (0.176) data 0.000 (0.001) loss 1.2792 (1.1453) ce_loss 1.1768 (1.0361) teacher_loss 1.1776 (1.0360) loss_zs_kd 0.1004 (0.1153) loss_oracle 0.0514 (0.0516) acc 68.7500 (72.4716) kd_loss 0.0297 (0.0366) lr 1.9921e-03 eta 0:39:01
epoch [4/50] batch [240/288] time 0.163 (0.175) data 0.000 (0.001) loss 1.3204 (1.1428) ce_loss 1.2158 (1.0334) teacher_loss 1.1998 (1.0334) loss_zs_kd 0.1290 (0.1153) loss_oracle 0.0561 (0.0517) acc 68.7500 (72.6302) kd_loss 0.0297 (0.0359) lr 1.9921e-03 eta 0:38:47
epoch [4/50] batch [260/288] time 0.168 (0.174) data 0.000 (0.001) loss 0.9514 (1.1480) ce_loss 0.8281 (1.0377) teacher_loss 0.8296 (1.0376) loss_zs_kd 0.1243 (0.1160) loss_oracle 0.0597 (0.0524) acc 75.0000 (72.5000) kd_loss 0.0283 (0.0354) lr 1.9921e-03 eta 0:38:33
epoch [4/50] batch [280/288] time 0.348 (0.173) data 0.000 (0.001) loss 0.8157 (1.1430) ce_loss 0.7266 (1.0333) teacher_loss 0.7317 (1.0332) loss_zs_kd 0.0924 (0.1149) loss_oracle 0.0378 (0.0524) acc 81.2500 (72.7679) kd_loss 0.0211 (0.0351) lr 1.9921e-03 eta 0:38:12
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,411
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 85.8%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,027
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 80.1%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.6%, epoch: 4 *******
******* Domain a best val test acc: 83.5%, epoch: 4 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [5/50] batch [20/288] time 0.153 (0.176) data 0.000 (0.014) loss 1.5670 (1.3022) ce_loss 1.4199 (1.1788) teacher_loss 1.4257 (1.1782) loss_zs_kd 0.1400 (0.1434) loss_oracle 0.0713 (0.0523) acc 71.8750 (69.8438) kd_loss 0.0409 (0.0350) lr 1.9823e-03 eta 0:38:49
epoch [5/50] batch [40/288] time 0.144 (0.167) data 0.000 (0.007) loss 0.6660 (1.1994) ce_loss 0.4944 (1.0695) teacher_loss 0.4970 (1.0679) loss_zs_kd 0.1801 (0.1365) loss_oracle 0.0790 (0.0632) acc 90.6250 (71.9531) kd_loss 0.0432 (0.0383) lr 1.9823e-03 eta 0:36:48
epoch [5/50] batch [60/288] time 0.171 (0.164) data 0.001 (0.005) loss 1.2607 (1.1650) ce_loss 1.1699 (1.0378) teacher_loss 1.1708 (1.0356) loss_zs_kd 0.0793 (0.1286) loss_oracle 0.0502 (0.0650) acc 62.5000 (73.1771) kd_loss 0.0412 (0.0402) lr 1.9823e-03 eta 0:36:03
epoch [5/50] batch [80/288] time 0.094 (0.160) data 0.000 (0.004) loss 1.5133 (1.1448) ce_loss 1.4121 (1.0208) teacher_loss 1.4114 (1.0174) loss_zs_kd 0.1027 (0.1282) loss_oracle 0.0506 (0.0634) acc 71.8750 (73.3594) kd_loss 0.0375 (0.0412) lr 1.9823e-03 eta 0:35:05
epoch [5/50] batch [100/288] time 0.400 (0.179) data 0.000 (0.003) loss 0.8232 (1.1544) ce_loss 0.6899 (1.0290) teacher_loss 0.6842 (1.0256) loss_zs_kd 0.1169 (0.1279) loss_oracle 0.0806 (0.0649) acc 84.3750 (73.2500) kd_loss 0.0431 (0.0423) lr 1.9823e-03 eta 0:39:18
epoch [5/50] batch [120/288] time 0.150 (0.174) data 0.000 (0.002) loss 1.1803 (1.1473) ce_loss 1.0312 (1.0203) teacher_loss 1.0291 (1.0168) loss_zs_kd 0.1432 (0.1250) loss_oracle 0.0797 (0.0680) acc 75.0000 (73.4115) kd_loss 0.0527 (0.0433) lr 1.9823e-03 eta 0:38:01
epoch [5/50] batch [140/288] time 0.151 (0.171) data 0.000 (0.002) loss 1.2182 (1.1508) ce_loss 1.0850 (1.0245) teacher_loss 1.0938 (1.0203) loss_zs_kd 0.1073 (0.1221) loss_oracle 0.0708 (0.0695) acc 65.6250 (73.3929) kd_loss 0.0463 (0.0438) lr 1.9823e-03 eta 0:37:20
epoch [5/50] batch [160/288] time 0.150 (0.169) data 0.000 (0.002) loss 1.4152 (1.1542) ce_loss 1.2959 (1.0270) teacher_loss 1.2994 (1.0230) loss_zs_kd 0.1122 (0.1218) loss_oracle 0.0597 (0.0703) acc 68.7500 (73.2031) kd_loss 0.0416 (0.0446) lr 1.9823e-03 eta 0:36:52
epoch [5/50] batch [180/288] time 0.170 (0.168) data 0.000 (0.002) loss 1.1231 (1.1617) ce_loss 0.9839 (1.0328) teacher_loss 0.9669 (1.0294) loss_zs_kd 0.1093 (0.1223) loss_oracle 0.1016 (0.0712) acc 71.8750 (73.0556) kd_loss 0.0529 (0.0452) lr 1.9823e-03 eta 0:36:35
epoch [5/50] batch [200/288] time 0.149 (0.167) data 0.000 (0.002) loss 1.1113 (1.1647) ce_loss 0.9893 (1.0358) teacher_loss 0.9767 (1.0324) loss_zs_kd 0.1084 (0.1210) loss_oracle 0.0804 (0.0718) acc 78.1250 (72.9688) kd_loss 0.0512 (0.0458) lr 1.9823e-03 eta 0:36:18
epoch [5/50] batch [220/288] time 0.096 (0.164) data 0.000 (0.001) loss 1.3173 (1.1682) ce_loss 1.1934 (1.0391) teacher_loss 1.1900 (1.0360) loss_zs_kd 0.1175 (0.1210) loss_oracle 0.0685 (0.0716) acc 75.0000 (72.6562) kd_loss 0.0387 (0.0457) lr 1.9823e-03 eta 0:35:32
epoch [5/50] batch [240/288] time 0.097 (0.158) data 0.000 (0.001) loss 0.9411 (1.1672) ce_loss 0.8247 (1.0372) teacher_loss 0.8188 (1.0342) loss_zs_kd 0.0984 (0.1206) loss_oracle 0.0731 (0.0726) acc 81.2500 (72.6693) kd_loss 0.0536 (0.0459) lr 1.9823e-03 eta 0:34:19
epoch [5/50] batch [260/288] time 0.097 (0.154) data 0.000 (0.001) loss 1.2158 (1.1620) ce_loss 1.1191 (1.0314) teacher_loss 1.1162 (1.0283) loss_zs_kd 0.0737 (0.1205) loss_oracle 0.0628 (0.0735) acc 65.6250 (72.7404) kd_loss 0.0327 (0.0464) lr 1.9823e-03 eta 0:33:15
epoch [5/50] batch [280/288] time 0.081 (0.149) data 0.000 (0.001) loss 0.8767 (1.1532) ce_loss 0.7598 (1.0225) teacher_loss 0.7385 (1.0191) loss_zs_kd 0.1348 (0.1200) loss_oracle 0.0709 (0.0741) acc 78.1250 (72.9353) kd_loss 0.0427 (0.0468) lr 1.9823e-03 eta 0:32:18
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,401
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,014
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 79.6%
******* Domain a best val acc:      86.6%, epoch: 4 *******
******* Domain a best val test acc: 83.5%, epoch: 4 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [6/50] batch [20/288] time 0.170 (0.176) data 0.000 (0.015) loss 1.2342 (1.0430) ce_loss 1.1143 (0.9242) teacher_loss 1.1130 (0.9216) loss_zs_kd 0.0898 (0.1061) loss_oracle 0.0763 (0.0684) acc 71.8750 (73.5938) kd_loss 0.0575 (0.0510) lr 1.9686e-03 eta 0:37:56
epoch [6/50] batch [40/288] time 0.143 (0.166) data 0.000 (0.008) loss 1.0827 (1.1040) ce_loss 0.9570 (0.9799) teacher_loss 0.9605 (0.9779) loss_zs_kd 0.1113 (0.1095) loss_oracle 0.0666 (0.0714) acc 75.0000 (72.7344) kd_loss 0.0436 (0.0509) lr 1.9686e-03 eta 0:35:50
epoch [6/50] batch [60/288] time 0.145 (0.164) data 0.001 (0.005) loss 1.1824 (1.0925) ce_loss 1.0381 (0.9675) teacher_loss 1.0253 (0.9650) loss_zs_kd 0.1510 (0.1092) loss_oracle 0.0816 (0.0729) acc 62.5000 (73.0729) kd_loss 0.0547 (0.0510) lr 1.9686e-03 eta 0:35:09
epoch [6/50] batch [80/288] time 0.146 (0.161) data 0.000 (0.004) loss 1.1380 (1.0986) ce_loss 1.0264 (0.9744) teacher_loss 1.0055 (0.9717) loss_zs_kd 0.1357 (0.1118) loss_oracle 0.0646 (0.0711) acc 68.7500 (73.1250) kd_loss 0.0419 (0.0506) lr 1.9686e-03 eta 0:34:39
epoch [6/50] batch [100/288] time 0.144 (0.161) data 0.000 (0.003) loss 1.4352 (1.1212) ce_loss 1.2803 (0.9939) teacher_loss 1.2634 (0.9903) loss_zs_kd 0.1310 (0.1116) loss_oracle 0.1063 (0.0751) acc 62.5000 (73.1562) kd_loss 0.0576 (0.0507) lr 1.9686e-03 eta 0:34:24
epoch [6/50] batch [120/288] time 0.151 (0.156) data 0.000 (0.003) loss 1.3327 (1.1179) ce_loss 1.1602 (0.9864) teacher_loss 1.1456 (0.9828) loss_zs_kd 0.1450 (0.1115) loss_oracle 0.1146 (0.0793) acc 71.8750 (73.7760) kd_loss 0.0644 (0.0514) lr 1.9686e-03 eta 0:33:26
epoch [6/50] batch [140/288] time 0.400 (0.163) data 0.000 (0.002) loss 0.9426 (1.1189) ce_loss 0.8271 (0.9869) teacher_loss 0.8259 (0.9831) loss_zs_kd 0.0743 (0.1115) loss_oracle 0.0796 (0.0800) acc 75.0000 (73.6161) kd_loss 0.0645 (0.0523) lr 1.9686e-03 eta 0:34:48
epoch [6/50] batch [160/288] time 0.166 (0.164) data 0.000 (0.002) loss 0.8473 (1.1232) ce_loss 0.6973 (0.9905) teacher_loss 0.6987 (0.9865) loss_zs_kd 0.1320 (0.1146) loss_oracle 0.0827 (0.0794) acc 75.0000 (73.4375) kd_loss 0.0461 (0.0522) lr 1.9686e-03 eta 0:34:56
epoch [6/50] batch [180/288] time 0.170 (0.163) data 0.000 (0.002) loss 0.9495 (1.1282) ce_loss 0.7549 (0.9933) teacher_loss 0.7383 (0.9890) loss_zs_kd 0.1718 (0.1164) loss_oracle 0.1253 (0.0810) acc 81.2500 (73.4722) kd_loss 0.0632 (0.0528) lr 1.9686e-03 eta 0:34:48
epoch [6/50] batch [200/288] time 0.151 (0.163) data 0.000 (0.002) loss 1.1790 (1.1327) ce_loss 1.0391 (0.9975) teacher_loss 1.0331 (0.9932) loss_zs_kd 0.1098 (0.1167) loss_oracle 0.0911 (0.0812) acc 68.7500 (73.4375) kd_loss 0.0616 (0.0526) lr 1.9686e-03 eta 0:34:34
epoch [6/50] batch [220/288] time 0.167 (0.162) data 0.000 (0.002) loss 1.3789 (1.1369) ce_loss 1.2197 (1.0004) teacher_loss 1.2127 (0.9962) loss_zs_kd 0.1434 (0.1174) loss_oracle 0.0945 (0.0820) acc 75.0000 (73.4375) kd_loss 0.0562 (0.0528) lr 1.9686e-03 eta 0:34:23
epoch [6/50] batch [240/288] time 0.166 (0.162) data 0.000 (0.001) loss 1.0753 (1.1415) ce_loss 0.9683 (1.0052) teacher_loss 0.9671 (1.0006) loss_zs_kd 0.0759 (0.1172) loss_oracle 0.0703 (0.0823) acc 75.0000 (73.2552) kd_loss 0.0705 (0.0534) lr 1.9686e-03 eta 0:34:18
epoch [6/50] batch [260/288] time 0.153 (0.161) data 0.000 (0.001) loss 1.3551 (1.1425) ce_loss 1.2520 (1.0076) teacher_loss 1.2420 (1.0029) loss_zs_kd 0.1037 (0.1182) loss_oracle 0.0612 (0.0805) acc 68.7500 (73.2692) kd_loss 0.0510 (0.0532) lr 1.9686e-03 eta 0:34:08
epoch [6/50] batch [280/288] time 0.088 (0.160) data 0.000 (0.001) loss 1.3785 (1.1414) ce_loss 1.2178 (1.0068) teacher_loss 1.2118 (1.0023) loss_zs_kd 0.1616 (0.1185) loss_oracle 0.0859 (0.0798) acc 75.0000 (73.4040) kd_loss 0.0564 (0.0529) lr 1.9686e-03 eta 0:33:44
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,406
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 85.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.7%
******* Domain a best val acc:      86.6%, epoch: 4 *******
******* Domain a best val test acc: 83.5%, epoch: 4 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [7/50] batch [20/288] time 0.144 (0.172) data 0.000 (0.014) loss 1.3115 (1.1728) ce_loss 1.1914 (1.0445) teacher_loss 1.1877 (1.0416) loss_zs_kd 0.1054 (0.1174) loss_oracle 0.0712 (0.0726) acc 71.8750 (73.4375) kd_loss 0.0479 (0.0466) lr 1.9511e-03 eta 0:36:18
epoch [7/50] batch [40/288] time 0.169 (0.164) data 0.000 (0.007) loss 0.8343 (1.1122) ce_loss 0.7046 (0.9868) teacher_loss 0.7183 (0.9846) loss_zs_kd 0.1147 (0.1179) loss_oracle 0.0586 (0.0687) acc 90.6250 (75.0000) kd_loss 0.0322 (0.0457) lr 1.9511e-03 eta 0:34:30
epoch [7/50] batch [60/288] time 0.150 (0.161) data 0.000 (0.005) loss 1.3049 (1.0917) ce_loss 1.1885 (0.9705) teacher_loss 1.1844 (0.9674) loss_zs_kd 0.1176 (0.1178) loss_oracle 0.0616 (0.0654) acc 68.7500 (74.8438) kd_loss 0.0500 (0.0458) lr 1.9511e-03 eta 0:33:56
epoch [7/50] batch [80/288] time 0.150 (0.160) data 0.000 (0.004) loss 1.0692 (1.0947) ce_loss 0.9385 (0.9729) teacher_loss 0.9170 (0.9680) loss_zs_kd 0.1320 (0.1210) loss_oracle 0.0862 (0.0662) acc 75.0000 (74.6094) kd_loss 0.0629 (0.0474) lr 1.9511e-03 eta 0:33:35
epoch [7/50] batch [100/288] time 0.091 (0.159) data 0.000 (0.003) loss 0.7479 (1.0939) ce_loss 0.6226 (0.9714) teacher_loss 0.6167 (0.9668) loss_zs_kd 0.0845 (0.1203) loss_oracle 0.0890 (0.0670) acc 84.3750 (74.2188) kd_loss 0.0583 (0.0478) lr 1.9511e-03 eta 0:33:14
epoch [7/50] batch [120/288] time 0.342 (0.167) data 0.000 (0.003) loss 1.4096 (1.0911) ce_loss 1.2705 (0.9679) teacher_loss 1.2666 (0.9630) loss_zs_kd 0.1111 (0.1192) loss_oracle 0.0874 (0.0685) acc 71.8750 (74.1406) kd_loss 0.0618 (0.0482) lr 1.9511e-03 eta 0:34:51
epoch [7/50] batch [140/288] time 0.147 (0.167) data 0.000 (0.002) loss 1.1842 (1.1034) ce_loss 1.0752 (0.9792) teacher_loss 1.0632 (0.9735) loss_zs_kd 0.1063 (0.1193) loss_oracle 0.0679 (0.0703) acc 71.8750 (73.7723) kd_loss 0.0438 (0.0489) lr 1.9511e-03 eta 0:34:52
epoch [7/50] batch [160/288] time 0.147 (0.165) data 0.000 (0.002) loss 1.1490 (1.1209) ce_loss 1.0127 (0.9960) teacher_loss 1.0100 (0.9898) loss_zs_kd 0.1175 (0.1191) loss_oracle 0.0802 (0.0716) acc 75.0000 (73.3594) kd_loss 0.0472 (0.0494) lr 1.9511e-03 eta 0:34:27
epoch [7/50] batch [180/288] time 0.146 (0.164) data 0.000 (0.002) loss 1.2055 (1.1278) ce_loss 1.0908 (1.0015) teacher_loss 1.0667 (0.9951) loss_zs_kd 0.1230 (0.1191) loss_oracle 0.0772 (0.0732) acc 71.8750 (73.3333) kd_loss 0.0560 (0.0500) lr 1.9511e-03 eta 0:34:06
epoch [7/50] batch [200/288] time 0.152 (0.163) data 0.000 (0.002) loss 0.8561 (1.1212) ce_loss 0.7075 (0.9945) teacher_loss 0.6965 (0.9877) loss_zs_kd 0.1350 (0.1193) loss_oracle 0.0921 (0.0738) acc 75.0000 (73.4375) kd_loss 0.0507 (0.0503) lr 1.9511e-03 eta 0:33:49
epoch [7/50] batch [220/288] time 0.150 (0.162) data 0.000 (0.001) loss 1.3582 (1.1224) ce_loss 1.2305 (0.9954) teacher_loss 1.2347 (0.9887) loss_zs_kd 0.1265 (0.1193) loss_oracle 0.0603 (0.0741) acc 68.7500 (73.3097) kd_loss 0.0424 (0.0504) lr 1.9511e-03 eta 0:33:35
epoch [7/50] batch [240/288] time 0.166 (0.161) data 0.000 (0.001) loss 1.5877 (1.1286) ce_loss 1.4463 (1.0016) teacher_loss 1.4368 (0.9947) loss_zs_kd 0.1137 (0.1195) loss_oracle 0.0940 (0.0743) acc 59.3750 (73.2031) kd_loss 0.0670 (0.0506) lr 1.9511e-03 eta 0:33:23
epoch [7/50] batch [260/288] time 0.154 (0.160) data 0.000 (0.001) loss 1.0668 (1.1302) ce_loss 0.9624 (1.0036) teacher_loss 0.9596 (0.9966) loss_zs_kd 0.0949 (0.1185) loss_oracle 0.0597 (0.0743) acc 75.0000 (73.1130) kd_loss 0.0551 (0.0510) lr 1.9511e-03 eta 0:33:10
epoch [7/50] batch [280/288] time 0.085 (0.161) data 0.000 (0.001) loss 0.8447 (1.1251) ce_loss 0.7256 (0.9989) teacher_loss 0.7278 (0.9922) loss_zs_kd 0.1014 (0.1175) loss_oracle 0.0662 (0.0741) acc 75.0000 (73.3147) kd_loss 0.0416 (0.0512) lr 1.9511e-03 eta 0:33:14
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,403
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,016
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.6%
******* Domain a best val acc:      86.6%, epoch: 4 *******
******* Domain a best val test acc: 83.5%, epoch: 4 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [8/50] batch [20/288] time 0.155 (0.174) data 0.000 (0.015) loss 1.0972 (1.1360) ce_loss 0.9009 (0.9861) teacher_loss 0.8812 (0.9759) loss_zs_kd 0.2063 (0.1296) loss_oracle 0.1129 (0.0953) acc 84.3750 (74.2188) kd_loss 0.0867 (0.0600) lr 1.9298e-03 eta 0:35:49
epoch [8/50] batch [40/288] time 0.146 (0.162) data 0.000 (0.008) loss 0.9771 (1.1172) ce_loss 0.8516 (0.9739) teacher_loss 0.8472 (0.9659) loss_zs_kd 0.1309 (0.1218) loss_oracle 0.0644 (0.0904) acc 81.2500 (73.6719) kd_loss 0.0388 (0.0577) lr 1.9298e-03 eta 0:33:22
epoch [8/50] batch [60/288] time 0.147 (0.160) data 0.001 (0.005) loss 1.6837 (1.0936) ce_loss 1.5918 (0.9594) teacher_loss 1.5841 (0.9513) loss_zs_kd 0.0786 (0.1211) loss_oracle 0.0602 (0.0818) acc 56.2500 (74.0104) kd_loss 0.0472 (0.0560) lr 1.9298e-03 eta 0:32:50
epoch [8/50] batch [80/288] time 0.168 (0.160) data 0.000 (0.004) loss 1.1821 (1.0830) ce_loss 1.0781 (0.9530) teacher_loss 1.0625 (0.9447) loss_zs_kd 0.1022 (0.1226) loss_oracle 0.0685 (0.0771) acc 68.7500 (74.1797) kd_loss 0.0414 (0.0548) lr 1.9298e-03 eta 0:32:48
epoch [8/50] batch [100/288] time 0.084 (0.165) data 0.000 (0.003) loss 0.9261 (1.0893) ce_loss 0.7666 (0.9609) teacher_loss 0.7566 (0.9532) loss_zs_kd 0.1677 (0.1244) loss_oracle 0.0856 (0.0739) acc 84.3750 (74.1562) kd_loss 0.0666 (0.0529) lr 1.9298e-03 eta 0:33:42
epoch [8/50] batch [120/288] time 0.148 (0.168) data 0.000 (0.003) loss 1.0566 (1.0795) ce_loss 0.9185 (0.9514) teacher_loss 0.9049 (0.9442) loss_zs_kd 0.1428 (0.1256) loss_oracle 0.0802 (0.0725) acc 78.1250 (74.4271) kd_loss 0.0478 (0.0518) lr 1.9298e-03 eta 0:34:24
epoch [8/50] batch [140/288] time 0.153 (0.167) data 0.000 (0.002) loss 1.0603 (1.0902) ce_loss 0.9048 (0.9625) teacher_loss 0.9086 (0.9556) loss_zs_kd 0.1463 (0.1255) loss_oracle 0.0785 (0.0718) acc 68.7500 (74.1518) kd_loss 0.0467 (0.0507) lr 1.9298e-03 eta 0:34:06
epoch [8/50] batch [160/288] time 0.170 (0.166) data 0.000 (0.002) loss 1.2478 (1.1066) ce_loss 1.1270 (0.9803) teacher_loss 1.1223 (0.9729) loss_zs_kd 0.1376 (0.1242) loss_oracle 0.0567 (0.0716) acc 68.7500 (73.6719) kd_loss 0.0329 (0.0499) lr 1.9298e-03 eta 0:33:51
epoch [8/50] batch [180/288] time 0.153 (0.165) data 0.000 (0.002) loss 1.5058 (1.1070) ce_loss 1.3896 (0.9816) teacher_loss 1.3823 (0.9748) loss_zs_kd 0.0999 (0.1226) loss_oracle 0.0735 (0.0710) acc 68.7500 (73.5764) kd_loss 0.0429 (0.0489) lr 1.9298e-03 eta 0:33:33
epoch [8/50] batch [200/288] time 0.175 (0.165) data 0.000 (0.002) loss 1.3691 (1.1102) ce_loss 1.2598 (0.9841) teacher_loss 1.2387 (0.9771) loss_zs_kd 0.1154 (0.1228) loss_oracle 0.0727 (0.0717) acc 65.6250 (73.5000) kd_loss 0.0429 (0.0484) lr 1.9298e-03 eta 0:33:29
epoch [8/50] batch [220/288] time 0.139 (0.164) data 0.000 (0.002) loss 0.8087 (1.1051) ce_loss 0.7075 (0.9795) teacher_loss 0.6999 (0.9724) loss_zs_kd 0.1054 (0.1224) loss_oracle 0.0561 (0.0715) acc 84.3750 (73.6648) kd_loss 0.0428 (0.0482) lr 1.9298e-03 eta 0:33:15
epoch [8/50] batch [240/288] time 0.088 (0.162) data 0.000 (0.001) loss 1.0689 (1.1088) ce_loss 0.9385 (0.9834) teacher_loss 0.9272 (0.9764) loss_zs_kd 0.1509 (0.1227) loss_oracle 0.0663 (0.0710) acc 75.0000 (73.5156) kd_loss 0.0405 (0.0480) lr 1.9298e-03 eta 0:32:52
epoch [8/50] batch [260/288] time 0.357 (0.168) data 0.000 (0.001) loss 1.1049 (1.1090) ce_loss 0.9346 (0.9837) teacher_loss 0.9231 (0.9769) loss_zs_kd 0.1678 (0.1222) loss_oracle 0.0980 (0.0711) acc 78.1250 (73.6058) kd_loss 0.0535 (0.0477) lr 1.9298e-03 eta 0:34:02
epoch [8/50] batch [280/288] time 0.165 (0.168) data 0.000 (0.001) loss 1.6217 (1.1155) ce_loss 1.4766 (0.9905) teacher_loss 1.4660 (0.9835) loss_zs_kd 0.1401 (0.1219) loss_oracle 0.0857 (0.0710) acc 59.3750 (73.4821) kd_loss 0.0493 (0.0476) lr 1.9298e-03 eta 0:33:51
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,410
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 86.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,023
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.0%
******* Domain a best val acc:      86.6%, epoch: 4 *******
******* Domain a best val test acc: 83.5%, epoch: 4 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [9/50] batch [20/288] time 0.180 (0.184) data 0.000 (0.014) loss 1.2057 (1.1409) ce_loss 1.0713 (1.0071) teacher_loss 1.0751 (0.9992) loss_zs_kd 0.1111 (0.1210) loss_oracle 0.0751 (0.0812) acc 71.8750 (71.8750) kd_loss 0.0447 (0.0473) lr 1.9048e-03 eta 0:37:03
epoch [9/50] batch [40/288] time 0.172 (0.178) data 0.000 (0.007) loss 0.7472 (1.0912) ce_loss 0.6489 (0.9540) teacher_loss 0.6335 (0.9464) loss_zs_kd 0.0647 (0.1204) loss_oracle 0.0813 (0.0846) acc 84.3750 (74.2188) kd_loss 0.0492 (0.0478) lr 1.9048e-03 eta 0:35:41
epoch [9/50] batch [60/288] time 0.084 (0.179) data 0.000 (0.005) loss 1.2261 (1.0929) ce_loss 1.1133 (0.9601) teacher_loss 1.1172 (0.9532) loss_zs_kd 0.1095 (0.1196) loss_oracle 0.0541 (0.0799) acc 68.7500 (74.0104) kd_loss 0.0283 (0.0474) lr 1.9048e-03 eta 0:35:53
epoch [9/50] batch [80/288] time 0.153 (0.180) data 0.000 (0.004) loss 0.9585 (1.1219) ce_loss 0.8252 (0.9889) teacher_loss 0.8332 (0.9820) loss_zs_kd 0.1188 (0.1227) loss_oracle 0.0658 (0.0785) acc 84.3750 (73.5547) kd_loss 0.0319 (0.0475) lr 1.9048e-03 eta 0:36:04
epoch [9/50] batch [100/288] time 0.172 (0.176) data 0.000 (0.003) loss 0.8881 (1.1213) ce_loss 0.7510 (0.9901) teacher_loss 0.7585 (0.9835) loss_zs_kd 0.1170 (0.1205) loss_oracle 0.0711 (0.0776) acc 71.8750 (73.6250) kd_loss 0.0384 (0.0468) lr 1.9048e-03 eta 0:35:06
epoch [9/50] batch [120/288] time 0.169 (0.173) data 0.000 (0.003) loss 1.1599 (1.1343) ce_loss 1.0146 (1.0023) teacher_loss 1.0203 (0.9955) loss_zs_kd 0.1163 (0.1213) loss_oracle 0.0815 (0.0781) acc 68.7500 (73.1510) kd_loss 0.0460 (0.0467) lr 1.9048e-03 eta 0:34:26
epoch [9/50] batch [140/288] time 0.155 (0.170) data 0.000 (0.002) loss 1.0553 (1.1407) ce_loss 0.9512 (1.0078) teacher_loss 0.9468 (1.0010) loss_zs_kd 0.0670 (0.1225) loss_oracle 0.0751 (0.0784) acc 71.8750 (73.3259) kd_loss 0.0500 (0.0472) lr 1.9048e-03 eta 0:33:58
epoch [9/50] batch [160/288] time 0.160 (0.169) data 0.000 (0.002) loss 0.8704 (1.1344) ce_loss 0.7656 (1.0012) teacher_loss 0.7509 (0.9939) loss_zs_kd 0.1324 (0.1259) loss_oracle 0.0533 (0.0776) acc 78.1250 (73.3594) kd_loss 0.0398 (0.0479) lr 1.9048e-03 eta 0:33:40
epoch [9/50] batch [180/288] time 0.175 (0.169) data 0.000 (0.002) loss 1.7667 (1.1333) ce_loss 1.6562 (1.0036) teacher_loss 1.6504 (0.9961) loss_zs_kd 0.1308 (0.1243) loss_oracle 0.0509 (0.0750) acc 65.6250 (73.2986) kd_loss 0.0391 (0.0475) lr 1.9048e-03 eta 0:33:34
epoch [9/50] batch [200/288] time 0.358 (0.168) data 0.000 (0.002) loss 1.3581 (1.1401) ce_loss 1.2510 (1.0117) teacher_loss 1.2263 (1.0040) loss_zs_kd 0.1252 (0.1244) loss_oracle 0.0692 (0.0739) acc 68.7500 (73.0781) kd_loss 0.0427 (0.0475) lr 1.9048e-03 eta 0:33:21
epoch [9/50] batch [220/288] time 0.342 (0.173) data 0.000 (0.001) loss 0.8049 (1.1382) ce_loss 0.6543 (1.0114) teacher_loss 0.6526 (1.0037) loss_zs_kd 0.1664 (0.1240) loss_oracle 0.0690 (0.0725) acc 81.2500 (73.0540) kd_loss 0.0538 (0.0470) lr 1.9048e-03 eta 0:34:17
epoch [9/50] batch [240/288] time 0.165 (0.172) data 0.000 (0.001) loss 1.2382 (1.1354) ce_loss 1.0967 (1.0097) teacher_loss 1.0772 (1.0020) loss_zs_kd 0.1837 (0.1234) loss_oracle 0.0692 (0.0717) acc 71.8750 (73.0729) kd_loss 0.0427 (0.0463) lr 1.9048e-03 eta 0:33:53
epoch [9/50] batch [260/288] time 0.156 (0.171) data 0.000 (0.001) loss 0.9997 (1.1380) ce_loss 0.8965 (1.0126) teacher_loss 0.9002 (1.0049) loss_zs_kd 0.0940 (0.1230) loss_oracle 0.0525 (0.0716) acc 71.8750 (72.9567) kd_loss 0.0260 (0.0460) lr 1.9048e-03 eta 0:33:42
epoch [9/50] batch [280/288] time 0.169 (0.170) data 0.000 (0.001) loss 0.9718 (1.1312) ce_loss 0.8896 (1.0063) teacher_loss 0.8743 (0.9984) loss_zs_kd 0.0678 (0.1229) loss_oracle 0.0636 (0.0714) acc 75.0000 (73.0357) kd_loss 0.0458 (0.0462) lr 1.9048e-03 eta 0:33:32
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,409
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 85.9%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,022
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 79.9%
******* Domain a best val acc:      86.6%, epoch: 4 *******
******* Domain a best val test acc: 83.5%, epoch: 4 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [10/50] batch [20/288] time 0.084 (0.194) data 0.000 (0.013) loss 0.8727 (1.1307) ce_loss 0.7715 (1.0157) teacher_loss 0.7710 (1.0099) loss_zs_kd 0.0762 (0.1222) loss_oracle 0.0636 (0.0597) acc 78.1250 (74.2188) kd_loss 0.0393 (0.0426) lr 1.8763e-03 eta 0:38:06
epoch [10/50] batch [40/288] time 0.174 (0.198) data 0.000 (0.007) loss 1.2972 (1.0962) ce_loss 1.1504 (0.9752) teacher_loss 1.1472 (0.9669) loss_zs_kd 0.1626 (0.1272) loss_oracle 0.0687 (0.0656) acc 65.6250 (75.0000) kd_loss 0.0583 (0.0466) lr 1.8763e-03 eta 0:38:52
epoch [10/50] batch [60/288] time 0.166 (0.187) data 0.000 (0.005) loss 0.9733 (1.0616) ce_loss 0.8623 (0.9449) teacher_loss 0.8700 (0.9356) loss_zs_kd 0.0947 (0.1246) loss_oracle 0.0560 (0.0637) acc 81.2500 (75.0521) kd_loss 0.0402 (0.0469) lr 1.8763e-03 eta 0:36:41
epoch [10/50] batch [80/288] time 0.148 (0.181) data 0.000 (0.003) loss 1.2240 (1.0884) ce_loss 1.1201 (0.9711) teacher_loss 1.1230 (0.9619) loss_zs_kd 0.1073 (0.1267) loss_oracle 0.0473 (0.0632) acc 81.2500 (74.3750) kd_loss 0.0340 (0.0463) lr 1.8763e-03 eta 0:35:25
epoch [10/50] batch [100/288] time 0.165 (0.177) data 0.000 (0.003) loss 1.4050 (1.0763) ce_loss 1.2861 (0.9612) teacher_loss 1.2809 (0.9525) loss_zs_kd 0.1233 (0.1241) loss_oracle 0.0625 (0.0618) acc 71.8750 (74.5938) kd_loss 0.0450 (0.0448) lr 1.8763e-03 eta 0:34:35
epoch [10/50] batch [120/288] time 0.145 (0.174) data 0.000 (0.002) loss 0.9710 (1.0758) ce_loss 0.8540 (0.9590) teacher_loss 0.8472 (0.9512) loss_zs_kd 0.1161 (0.1236) loss_oracle 0.0658 (0.0629) acc 81.2500 (74.7917) kd_loss 0.0302 (0.0435) lr 1.8763e-03 eta 0:33:59
epoch [10/50] batch [140/288] time 0.178 (0.173) data 0.000 (0.002) loss 1.3828 (1.0940) ce_loss 1.2676 (0.9750) teacher_loss 1.2611 (0.9670) loss_zs_kd 0.1162 (0.1249) loss_oracle 0.0637 (0.0645) acc 68.7500 (74.4420) kd_loss 0.0456 (0.0437) lr 1.8763e-03 eta 0:33:43
epoch [10/50] batch [160/288] time 0.447 (0.178) data 0.000 (0.002) loss 0.8250 (1.0945) ce_loss 0.6875 (0.9742) teacher_loss 0.6931 (0.9663) loss_zs_kd 0.0897 (0.1239) loss_oracle 0.0870 (0.0663) acc 84.3750 (74.4141) kd_loss 0.0508 (0.0442) lr 1.8763e-03 eta 0:34:33
epoch [10/50] batch [180/288] time 0.152 (0.178) data 0.000 (0.002) loss 1.2117 (1.1071) ce_loss 1.1016 (0.9847) teacher_loss 1.1052 (0.9775) loss_zs_kd 0.0918 (0.1232) loss_oracle 0.0606 (0.0680) acc 75.0000 (74.1146) kd_loss 0.0374 (0.0445) lr 1.8763e-03 eta 0:34:31
epoch [10/50] batch [200/288] time 0.164 (0.177) data 0.000 (0.002) loss 1.4185 (1.1136) ce_loss 1.3096 (0.9922) teacher_loss 1.2939 (0.9849) loss_zs_kd 0.1008 (0.1221) loss_oracle 0.0742 (0.0677) acc 62.5000 (74.0469) kd_loss 0.0737 (0.0448) lr 1.8763e-03 eta 0:34:10
epoch [10/50] batch [220/288] time 0.170 (0.175) data 0.000 (0.001) loss 1.2053 (1.1131) ce_loss 1.0957 (0.9932) teacher_loss 1.0750 (0.9856) loss_zs_kd 0.1305 (0.1215) loss_oracle 0.0651 (0.0667) acc 68.7500 (74.1051) kd_loss 0.0563 (0.0450) lr 1.8763e-03 eta 0:33:44
epoch [10/50] batch [240/288] time 0.144 (0.173) data 0.000 (0.001) loss 1.0554 (1.1158) ce_loss 0.9092 (0.9966) teacher_loss 0.9080 (0.9886) loss_zs_kd 0.1445 (0.1217) loss_oracle 0.0751 (0.0664) acc 75.0000 (73.9974) kd_loss 0.0526 (0.0452) lr 1.8763e-03 eta 0:33:18
epoch [10/50] batch [260/288] time 0.152 (0.171) data 0.000 (0.001) loss 1.2151 (1.1162) ce_loss 1.0771 (0.9963) teacher_loss 1.0731 (0.9882) loss_zs_kd 0.1189 (0.1223) loss_oracle 0.0825 (0.0669) acc 75.0000 (73.9062) kd_loss 0.0585 (0.0457) lr 1.8763e-03 eta 0:32:58
epoch [10/50] batch [280/288] time 0.141 (0.170) data 0.000 (0.001) loss 1.6329 (1.1248) ce_loss 1.4609 (1.0042) teacher_loss 1.4644 (0.9960) loss_zs_kd 0.1811 (0.1231) loss_oracle 0.0780 (0.0673) acc 65.6250 (73.6496) kd_loss 0.0610 (0.0460) lr 1.8763e-03 eta 0:32:38
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,411
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 85.9%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.5%
******* Domain a best val acc:      86.6%, epoch: 4 *******
******* Domain a best val test acc: 83.5%, epoch: 4 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [11/50] batch [20/288] time 0.154 (0.186) data 0.000 (0.016) loss 1.6519 (1.1409) ce_loss 1.5322 (1.0211) teacher_loss 1.5206 (1.0148) loss_zs_kd 0.1083 (0.1214) loss_oracle 0.0772 (0.0654) acc 62.5000 (72.5000) kd_loss 0.0586 (0.0505) lr 1.8443e-03 eta 0:35:37
epoch [11/50] batch [40/288] time 0.173 (0.172) data 0.000 (0.008) loss 1.2976 (1.1446) ce_loss 1.1582 (1.0213) teacher_loss 1.1541 (1.0129) loss_zs_kd 0.1410 (0.1253) loss_oracle 0.0731 (0.0690) acc 71.8750 (71.7969) kd_loss 0.0572 (0.0530) lr 1.8443e-03 eta 0:32:56
epoch [11/50] batch [60/288] time 0.170 (0.169) data 0.001 (0.005) loss 0.9452 (1.1382) ce_loss 0.8135 (1.0157) teacher_loss 0.8009 (1.0078) loss_zs_kd 0.1377 (0.1235) loss_oracle 0.0754 (0.0688) acc 78.1250 (72.1875) kd_loss 0.0471 (0.0517) lr 1.8443e-03 eta 0:32:22
epoch [11/50] batch [80/288] time 0.152 (0.167) data 0.000 (0.004) loss 1.1931 (1.1158) ce_loss 1.0840 (0.9922) teacher_loss 1.0920 (0.9830) loss_zs_kd 0.0857 (0.1212) loss_oracle 0.0582 (0.0721) acc 68.7500 (72.8906) kd_loss 0.0360 (0.0526) lr 1.8443e-03 eta 0:31:46
epoch [11/50] batch [100/288] time 0.172 (0.167) data 0.000 (0.003) loss 1.3399 (1.1027) ce_loss 1.1904 (0.9779) teacher_loss 1.1732 (0.9687) loss_zs_kd 0.1450 (0.1206) loss_oracle 0.0942 (0.0737) acc 68.7500 (73.3438) kd_loss 0.0644 (0.0518) lr 1.8443e-03 eta 0:31:41
epoch [11/50] batch [120/288] time 0.414 (0.180) data 0.000 (0.003) loss 1.6173 (1.1056) ce_loss 1.5029 (0.9801) teacher_loss 1.4815 (0.9714) loss_zs_kd 0.1031 (0.1211) loss_oracle 0.0842 (0.0736) acc 53.1250 (73.3333) kd_loss 0.0555 (0.0516) lr 1.8443e-03 eta 0:34:09
epoch [11/50] batch [140/288] time 0.169 (0.177) data 0.000 (0.002) loss 0.9500 (1.1073) ce_loss 0.8408 (0.9816) teacher_loss 0.8385 (0.9734) loss_zs_kd 0.0815 (0.1204) loss_oracle 0.0708 (0.0737) acc 81.2500 (73.2589) kd_loss 0.0518 (0.0520) lr 1.8443e-03 eta 0:33:29
epoch [11/50] batch [160/288] time 0.151 (0.174) data 0.000 (0.002) loss 1.3534 (1.1195) ce_loss 1.2207 (0.9945) teacher_loss 1.2202 (0.9862) loss_zs_kd 0.1149 (0.1199) loss_oracle 0.0758 (0.0734) acc 62.5000 (72.7734) kd_loss 0.0625 (0.0520) lr 1.8443e-03 eta 0:32:57
epoch [11/50] batch [180/288] time 0.169 (0.172) data 0.000 (0.002) loss 1.2004 (1.1151) ce_loss 1.0547 (0.9902) teacher_loss 1.0503 (0.9818) loss_zs_kd 0.1403 (0.1206) loss_oracle 0.0799 (0.0730) acc 78.1250 (72.8472) kd_loss 0.0693 (0.0523) lr 1.8443e-03 eta 0:32:33
epoch [11/50] batch [200/288] time 0.171 (0.171) data 0.000 (0.002) loss 1.2318 (1.1103) ce_loss 1.0674 (0.9863) teacher_loss 1.0503 (0.9778) loss_zs_kd 0.1684 (0.1202) loss_oracle 0.0974 (0.0724) acc 78.1250 (73.0000) kd_loss 0.0681 (0.0525) lr 1.8443e-03 eta 0:32:12
epoch [11/50] batch [220/288] time 0.168 (0.169) data 0.000 (0.002) loss 1.1544 (1.1119) ce_loss 0.9829 (0.9855) teacher_loss 0.9773 (0.9767) loss_zs_kd 0.1439 (0.1226) loss_oracle 0.1051 (0.0739) acc 81.2500 (73.0398) kd_loss 0.0688 (0.0533) lr 1.8443e-03 eta 0:31:53
epoch [11/50] batch [240/288] time 0.169 (0.168) data 0.000 (0.002) loss 1.0835 (1.1090) ce_loss 0.9697 (0.9822) teacher_loss 0.9595 (0.9734) loss_zs_kd 0.1055 (0.1230) loss_oracle 0.0712 (0.0741) acc 71.8750 (73.1901) kd_loss 0.0432 (0.0534) lr 1.8443e-03 eta 0:31:40
epoch [11/50] batch [260/288] time 0.333 (0.170) data 0.000 (0.001) loss 1.0607 (1.1102) ce_loss 0.9585 (0.9832) teacher_loss 0.9499 (0.9745) loss_zs_kd 0.1050 (0.1229) loss_oracle 0.0583 (0.0742) acc 75.0000 (73.1370) kd_loss 0.0393 (0.0536) lr 1.8443e-03 eta 0:31:50
epoch [11/50] batch [280/288] time 0.150 (0.172) data 0.000 (0.001) loss 0.8316 (1.1033) ce_loss 0.7329 (0.9760) teacher_loss 0.7126 (0.9672) loss_zs_kd 0.0847 (0.1223) loss_oracle 0.0766 (0.0749) acc 81.2500 (73.3929) kd_loss 0.0627 (0.0540) lr 1.8443e-03 eta 0:32:11
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,412
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 86.0%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,027
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 80.1%
******* Domain a best val acc:      86.6%, epoch: 11 *******
******* Domain a best val test acc: 83.5%, epoch: 11 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [12/50] batch [20/288] time 0.158 (0.171) data 0.000 (0.012) loss 1.0590 (1.1092) ce_loss 0.9717 (0.9961) teacher_loss 0.9637 (0.9868) loss_zs_kd 0.0783 (0.1260) loss_oracle 0.0561 (0.0594) acc 81.2500 (72.9688) kd_loss 0.0516 (0.0542) lr 1.8090e-03 eta 0:31:51
epoch [12/50] batch [40/288] time 0.164 (0.164) data 0.000 (0.006) loss 1.1433 (1.0910) ce_loss 1.0293 (0.9776) teacher_loss 1.0373 (0.9710) loss_zs_kd 0.0802 (0.1235) loss_oracle 0.0659 (0.0583) acc 75.0000 (73.2812) kd_loss 0.0395 (0.0486) lr 1.8090e-03 eta 0:30:34
epoch [12/50] batch [60/288] time 0.408 (0.171) data 0.000 (0.004) loss 1.3102 (1.1156) ce_loss 1.2188 (1.0016) teacher_loss 1.2211 (0.9941) loss_zs_kd 0.1142 (0.1217) loss_oracle 0.0320 (0.0607) acc 65.6250 (72.8125) kd_loss 0.0282 (0.0472) lr 1.8090e-03 eta 0:31:55
epoch [12/50] batch [80/288] time 0.149 (0.180) data 0.000 (0.003) loss 2.0529 (1.1206) ce_loss 1.9404 (1.0058) teacher_loss 1.9238 (0.9982) loss_zs_kd 0.1451 (0.1232) loss_oracle 0.0565 (0.0608) acc 53.1250 (73.0469) kd_loss 0.0433 (0.0464) lr 1.8090e-03 eta 0:33:27
epoch [12/50] batch [100/288] time 0.144 (0.175) data 0.000 (0.003) loss 1.1706 (1.1017) ce_loss 1.0684 (0.9864) teacher_loss 1.0586 (0.9793) loss_zs_kd 0.1267 (0.1215) loss_oracle 0.0487 (0.0616) acc 59.3750 (73.4062) kd_loss 0.0325 (0.0442) lr 1.8090e-03 eta 0:32:26
epoch [12/50] batch [120/288] time 0.144 (0.172) data 0.000 (0.002) loss 1.2554 (1.0950) ce_loss 1.1240 (0.9786) teacher_loss 1.1288 (0.9721) loss_zs_kd 0.1342 (0.1217) loss_oracle 0.0594 (0.0621) acc 68.7500 (73.8281) kd_loss 0.0307 (0.0434) lr 1.8090e-03 eta 0:31:52
epoch [12/50] batch [140/288] time 0.150 (0.170) data 0.000 (0.002) loss 0.5957 (1.1006) ce_loss 0.4858 (0.9832) teacher_loss 0.4796 (0.9764) loss_zs_kd 0.1112 (0.1236) loss_oracle 0.0606 (0.0624) acc 90.6250 (73.6830) kd_loss 0.0376 (0.0430) lr 1.8090e-03 eta 0:31:23
epoch [12/50] batch [160/288] time 0.151 (0.168) data 0.000 (0.002) loss 1.1563 (1.0990) ce_loss 0.9912 (0.9808) teacher_loss 0.9896 (0.9738) loss_zs_kd 0.1839 (0.1250) loss_oracle 0.0747 (0.0627) acc 71.8750 (73.6328) kd_loss 0.0474 (0.0423) lr 1.8090e-03 eta 0:31:02
epoch [12/50] batch [180/288] time 0.149 (0.167) data 0.000 (0.002) loss 1.0126 (1.1139) ce_loss 0.8604 (0.9951) teacher_loss 0.8650 (0.9881) loss_zs_kd 0.1553 (0.1264) loss_oracle 0.0700 (0.0626) acc 78.1250 (73.2292) kd_loss 0.0353 (0.0417) lr 1.8090e-03 eta 0:30:45
epoch [12/50] batch [200/288] time 0.099 (0.165) data 0.000 (0.001) loss 1.2460 (1.1152) ce_loss 1.1309 (0.9970) teacher_loss 1.1348 (0.9901) loss_zs_kd 0.1124 (0.1257) loss_oracle 0.0550 (0.0623) acc 68.7500 (73.2969) kd_loss 0.0318 (0.0408) lr 1.8090e-03 eta 0:30:23
epoch [12/50] batch [220/288] time 0.338 (0.169) data 0.000 (0.001) loss 0.8359 (1.1116) ce_loss 0.7158 (0.9929) teacher_loss 0.7077 (0.9864) loss_zs_kd 0.1736 (0.1270) loss_oracle 0.0414 (0.0617) acc 75.0000 (73.5085) kd_loss 0.0286 (0.0401) lr 1.8090e-03 eta 0:30:58
epoch [12/50] batch [240/288] time 0.170 (0.169) data 0.000 (0.001) loss 1.5136 (1.1151) ce_loss 1.3730 (0.9960) teacher_loss 1.3629 (0.9895) loss_zs_kd 0.1526 (0.1271) loss_oracle 0.0744 (0.0620) acc 59.3750 (73.5807) kd_loss 0.0448 (0.0397) lr 1.8090e-03 eta 0:31:02
epoch [12/50] batch [260/288] time 0.146 (0.168) data 0.000 (0.001) loss 0.9440 (1.1118) ce_loss 0.7959 (0.9929) teacher_loss 0.7805 (0.9863) loss_zs_kd 0.1548 (0.1269) loss_oracle 0.0861 (0.0620) acc 84.3750 (73.6779) kd_loss 0.0511 (0.0392) lr 1.8090e-03 eta 0:30:45
epoch [12/50] batch [280/288] time 0.144 (0.167) data 0.000 (0.001) loss 0.9879 (1.1108) ce_loss 0.8730 (0.9910) teacher_loss 0.8755 (0.9847) loss_zs_kd 0.0942 (0.1268) loss_oracle 0.0653 (0.0627) acc 75.0000 (73.7835) kd_loss 0.0376 (0.0390) lr 1.8090e-03 eta 0:30:33
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,411
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 86.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,025
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.2%
******* Domain a best val acc:      86.6%, epoch: 11 *******
******* Domain a best val test acc: 83.5%, epoch: 11 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [13/50] batch [20/288] time 0.145 (0.168) data 0.000 (0.014) loss 0.9000 (1.0825) ce_loss 0.7661 (0.9511) teacher_loss 0.7569 (0.9472) loss_zs_kd 0.1458 (0.1339) loss_oracle 0.0702 (0.0684) acc 78.1250 (73.4375) kd_loss 0.0373 (0.0400) lr 1.7705e-03 eta 0:30:36
epoch [13/50] batch [40/288] time 0.100 (0.171) data 0.000 (0.007) loss 0.8580 (1.1510) ce_loss 0.7236 (1.0180) teacher_loss 0.7238 (1.0152) loss_zs_kd 0.1516 (0.1343) loss_oracle 0.0584 (0.0686) acc 81.2500 (72.2656) kd_loss 0.0327 (0.0380) lr 1.7705e-03 eta 0:31:10
epoch [13/50] batch [60/288] time 0.161 (0.175) data 0.001 (0.005) loss 1.7213 (1.1951) ce_loss 1.6035 (1.0695) teacher_loss 1.5772 (1.0635) loss_zs_kd 0.1644 (0.1310) loss_oracle 0.0619 (0.0660) acc 62.5000 (71.0417) kd_loss 0.0439 (0.0381) lr 1.7705e-03 eta 0:31:48
epoch [13/50] batch [80/288] time 0.164 (0.170) data 0.000 (0.004) loss 1.4417 (1.1668) ce_loss 1.3057 (1.0433) teacher_loss 1.2955 (1.0376) loss_zs_kd 0.1948 (0.1317) loss_oracle 0.0488 (0.0633) acc 68.7500 (71.8750) kd_loss 0.0311 (0.0369) lr 1.7705e-03 eta 0:30:43
epoch [13/50] batch [100/288] time 0.165 (0.166) data 0.000 (0.003) loss 0.7677 (1.1346) ce_loss 0.6606 (1.0102) teacher_loss 0.6625 (1.0057) loss_zs_kd 0.0655 (0.1303) loss_oracle 0.0724 (0.0637) acc 84.3750 (72.9062) kd_loss 0.0386 (0.0361) lr 1.7705e-03 eta 0:29:58
epoch [13/50] batch [120/288] time 0.159 (0.163) data 0.000 (0.003) loss 1.1018 (1.1272) ce_loss 0.9951 (1.0019) teacher_loss 0.9873 (0.9977) loss_zs_kd 0.1221 (0.1305) loss_oracle 0.0535 (0.0643) acc 71.8750 (73.3854) kd_loss 0.0352 (0.0365) lr 1.7705e-03 eta 0:29:29
epoch [13/50] batch [140/288] time 0.150 (0.162) data 0.000 (0.002) loss 1.0860 (1.1367) ce_loss 0.9639 (1.0111) teacher_loss 0.9679 (1.0067) loss_zs_kd 0.1167 (0.1304) loss_oracle 0.0597 (0.0648) acc 75.0000 (73.1027) kd_loss 0.0361 (0.0368) lr 1.7705e-03 eta 0:29:07
epoch [13/50] batch [160/288] time 0.146 (0.160) data 0.000 (0.002) loss 1.2246 (1.1237) ce_loss 1.1211 (0.9978) teacher_loss 1.1164 (0.9935) loss_zs_kd 0.1032 (0.1296) loss_oracle 0.0566 (0.0654) acc 75.0000 (73.4570) kd_loss 0.0320 (0.0373) lr 1.7705e-03 eta 0:28:49
epoch [13/50] batch [180/288] time 0.174 (0.160) data 0.000 (0.002) loss 0.7225 (1.1319) ce_loss 0.6294 (1.0054) teacher_loss 0.6291 (1.0009) loss_zs_kd 0.0807 (0.1302) loss_oracle 0.0531 (0.0659) acc 81.2500 (73.2292) kd_loss 0.0312 (0.0379) lr 1.7705e-03 eta 0:28:42
epoch [13/50] batch [200/288] time 0.198 (0.164) data 0.000 (0.002) loss 1.5196 (1.1290) ce_loss 1.4229 (1.0022) teacher_loss 1.4206 (0.9975) loss_zs_kd 0.1057 (0.1307) loss_oracle 0.0462 (0.0661) acc 62.5000 (73.3281) kd_loss 0.0396 (0.0387) lr 1.7705e-03 eta 0:29:17
epoch [13/50] batch [220/288] time 0.146 (0.165) data 0.000 (0.001) loss 0.9517 (1.1234) ce_loss 0.8042 (0.9967) teacher_loss 0.7992 (0.9918) loss_zs_kd 0.1538 (0.1308) loss_oracle 0.0756 (0.0662) acc 81.2500 (73.4091) kd_loss 0.0606 (0.0394) lr 1.7705e-03 eta 0:29:33
epoch [13/50] batch [240/288] time 0.152 (0.165) data 0.000 (0.001) loss 1.2906 (1.1187) ce_loss 1.1514 (0.9931) teacher_loss 1.1569 (0.9877) loss_zs_kd 0.1424 (0.1296) loss_oracle 0.0625 (0.0662) acc 71.8750 (73.4766) kd_loss 0.0403 (0.0397) lr 1.7705e-03 eta 0:29:24
epoch [13/50] batch [260/288] time 0.152 (0.164) data 0.000 (0.001) loss 1.1719 (1.1067) ce_loss 1.0381 (0.9820) teacher_loss 1.0409 (0.9765) loss_zs_kd 0.1226 (0.1282) loss_oracle 0.0696 (0.0661) acc 75.0000 (73.8101) kd_loss 0.0406 (0.0400) lr 1.7705e-03 eta 0:29:16
epoch [13/50] batch [280/288] time 0.152 (0.164) data 0.000 (0.001) loss 0.8183 (1.1073) ce_loss 0.7158 (0.9831) teacher_loss 0.6819 (0.9775) loss_zs_kd 0.0961 (0.1274) loss_oracle 0.0884 (0.0661) acc 84.3750 (73.7500) kd_loss 0.0514 (0.0401) lr 1.7705e-03 eta 0:29:13
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,412
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 86.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,016
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 80.0%
******* Domain a best val acc:      86.6%, epoch: 11 *******
******* Domain a best val test acc: 83.5%, epoch: 11 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [14/50] batch [20/288] time 0.333 (0.194) data 0.000 (0.012) loss 1.1411 (1.1368) ce_loss 1.0156 (0.9983) teacher_loss 1.0050 (0.9979) loss_zs_kd 0.1273 (0.1276) loss_oracle 0.0724 (0.0751) acc 71.8750 (73.9062) kd_loss 0.0531 (0.0417) lr 1.7290e-03 eta 0:34:26
epoch [14/50] batch [40/288] time 0.143 (0.193) data 0.000 (0.006) loss 0.8793 (1.0936) ce_loss 0.7324 (0.9655) teacher_loss 0.7189 (0.9621) loss_zs_kd 0.1828 (0.1258) loss_oracle 0.0690 (0.0685) acc 78.1250 (74.4531) kd_loss 0.0438 (0.0405) lr 1.7290e-03 eta 0:34:13
epoch [14/50] batch [60/288] time 0.143 (0.180) data 0.001 (0.004) loss 1.0040 (1.0697) ce_loss 0.8838 (0.9432) teacher_loss 0.8854 (0.9391) loss_zs_kd 0.1115 (0.1272) loss_oracle 0.0629 (0.0670) acc 75.0000 (74.8438) kd_loss 0.0288 (0.0406) lr 1.7290e-03 eta 0:31:52
epoch [14/50] batch [80/288] time 0.142 (0.175) data 0.000 (0.003) loss 1.2733 (1.0948) ce_loss 1.1299 (0.9634) teacher_loss 1.1183 (0.9597) loss_zs_kd 0.1110 (0.1317) loss_oracle 0.0995 (0.0692) acc 78.1250 (74.2578) kd_loss 0.0575 (0.0407) lr 1.7290e-03 eta 0:30:48
epoch [14/50] batch [100/288] time 0.170 (0.172) data 0.000 (0.003) loss 1.3024 (1.0940) ce_loss 1.1504 (0.9604) teacher_loss 1.1458 (0.9558) loss_zs_kd 0.1602 (0.1348) loss_oracle 0.0765 (0.0708) acc 62.5000 (74.1562) kd_loss 0.0398 (0.0417) lr 1.7290e-03 eta 0:30:16
epoch [14/50] batch [120/288] time 0.147 (0.169) data 0.000 (0.002) loss 0.8654 (1.1067) ce_loss 0.7163 (0.9725) teacher_loss 0.7178 (0.9681) loss_zs_kd 0.1274 (0.1333) loss_oracle 0.0839 (0.0719) acc 84.3750 (73.9844) kd_loss 0.0522 (0.0418) lr 1.7290e-03 eta 0:29:38
epoch [14/50] batch [140/288] time 0.146 (0.167) data 0.000 (0.002) loss 0.9049 (1.1159) ce_loss 0.8032 (0.9837) teacher_loss 0.7697 (0.9785) loss_zs_kd 0.1200 (0.1322) loss_oracle 0.0753 (0.0713) acc 81.2500 (73.9732) kd_loss 0.0572 (0.0422) lr 1.7290e-03 eta 0:29:18
epoch [14/50] batch [160/288] time 0.343 (0.168) data 0.000 (0.002) loss 0.8328 (1.1038) ce_loss 0.6987 (0.9722) teacher_loss 0.7041 (0.9673) loss_zs_kd 0.1150 (0.1310) loss_oracle 0.0712 (0.0709) acc 78.1250 (74.2773) kd_loss 0.0551 (0.0424) lr 1.7290e-03 eta 0:29:26
epoch [14/50] batch [180/288] time 0.150 (0.172) data 0.000 (0.002) loss 0.7340 (1.0920) ce_loss 0.6323 (0.9617) teacher_loss 0.6338 (0.9568) loss_zs_kd 0.0881 (0.1298) loss_oracle 0.0561 (0.0703) acc 84.3750 (74.5312) kd_loss 0.0282 (0.0425) lr 1.7290e-03 eta 0:30:00
epoch [14/50] batch [200/288] time 0.170 (0.171) data 0.000 (0.001) loss 1.3339 (1.0976) ce_loss 1.2070 (0.9679) teacher_loss 1.1881 (0.9630) loss_zs_kd 0.1397 (0.1290) loss_oracle 0.0760 (0.0700) acc 68.7500 (74.3906) kd_loss 0.0481 (0.0423) lr 1.7290e-03 eta 0:29:48
epoch [14/50] batch [220/288] time 0.164 (0.170) data 0.000 (0.001) loss 0.5349 (1.0915) ce_loss 0.4194 (0.9616) teacher_loss 0.4181 (0.9566) loss_zs_kd 0.1039 (0.1294) loss_oracle 0.0649 (0.0702) acc 90.6250 (74.5312) kd_loss 0.0450 (0.0427) lr 1.7290e-03 eta 0:29:38
epoch [14/50] batch [240/288] time 0.168 (0.170) data 0.000 (0.001) loss 1.0203 (1.0869) ce_loss 0.8594 (0.9572) teacher_loss 0.8424 (0.9517) loss_zs_kd 0.1717 (0.1305) loss_oracle 0.0921 (0.0700) acc 75.0000 (74.5833) kd_loss 0.0571 (0.0428) lr 1.7290e-03 eta 0:29:28
epoch [14/50] batch [260/288] time 0.170 (0.169) data 0.000 (0.001) loss 1.4452 (1.0878) ce_loss 1.3145 (0.9588) teacher_loss 1.3035 (0.9534) loss_zs_kd 0.1332 (0.1305) loss_oracle 0.0751 (0.0692) acc 71.8750 (74.6514) kd_loss 0.0455 (0.0427) lr 1.7290e-03 eta 0:29:18
epoch [14/50] batch [280/288] time 0.169 (0.169) data 0.000 (0.001) loss 0.6689 (1.0868) ce_loss 0.5400 (0.9581) teacher_loss 0.5220 (0.9523) loss_zs_kd 0.1118 (0.1300) loss_oracle 0.0911 (0.0696) acc 84.3750 (74.6652) kd_loss 0.0507 (0.0427) lr 1.7290e-03 eta 0:29:12
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,416
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 86.2%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,022
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 80.0%
******* Domain a best val acc:      86.7%, epoch: 14 *******
******* Domain a best val test acc: 83.3%, epoch: 14 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [15/50] batch [20/288] time 0.089 (0.109) data 0.000 (0.014) loss 1.1789 (1.0942) ce_loss 1.0674 (0.9665) teacher_loss 1.0726 (0.9638) loss_zs_kd 0.0916 (0.1293) loss_oracle 0.0605 (0.0658) acc 78.1250 (74.6875) kd_loss 0.0346 (0.0393) lr 1.6845e-03 eta 0:18:46
epoch [15/50] batch [40/288] time 0.100 (0.104) data 0.000 (0.007) loss 1.2259 (1.1576) ce_loss 1.1064 (1.0309) teacher_loss 1.1049 (1.0287) loss_zs_kd 0.1177 (0.1268) loss_oracle 0.0622 (0.0655) acc 78.1250 (73.7500) kd_loss 0.0455 (0.0399) lr 1.6845e-03 eta 0:17:49
epoch [15/50] batch [60/288] time 0.096 (0.103) data 0.001 (0.005) loss 0.8207 (1.1133) ce_loss 0.6821 (0.9862) teacher_loss 0.6844 (0.9840) loss_zs_kd 0.1055 (0.1255) loss_oracle 0.0836 (0.0666) acc 78.1250 (74.4271) kd_loss 0.0473 (0.0407) lr 1.6845e-03 eta 0:17:43
epoch [15/50] batch [80/288] time 0.101 (0.102) data 0.000 (0.004) loss 1.0982 (1.0770) ce_loss 0.9663 (0.9487) teacher_loss 0.9630 (0.9456) loss_zs_kd 0.1113 (0.1251) loss_oracle 0.0796 (0.0688) acc 78.1250 (75.0781) kd_loss 0.0510 (0.0421) lr 1.6845e-03 eta 0:17:28
epoch [15/50] batch [100/288] time 0.095 (0.101) data 0.000 (0.003) loss 1.1484 (1.0697) ce_loss 1.0107 (0.9400) teacher_loss 1.0150 (0.9363) loss_zs_kd 0.1000 (0.1269) loss_oracle 0.0835 (0.0700) acc 71.8750 (74.9688) kd_loss 0.0322 (0.0429) lr 1.6845e-03 eta 0:17:12
epoch [15/50] batch [120/288] time 0.098 (0.101) data 0.000 (0.003) loss 1.3949 (1.0734) ce_loss 1.2539 (0.9433) teacher_loss 1.2521 (0.9396) loss_zs_kd 0.1577 (0.1260) loss_oracle 0.0640 (0.0708) acc 71.8750 (74.8438) kd_loss 0.0386 (0.0435) lr 1.6845e-03 eta 0:17:10
epoch [15/50] batch [140/288] time 0.099 (0.101) data 0.000 (0.002) loss 1.2104 (1.0851) ce_loss 1.0889 (0.9539) teacher_loss 1.0838 (0.9495) loss_zs_kd 0.1027 (0.1258) loss_oracle 0.0753 (0.0727) acc 68.7500 (74.4643) kd_loss 0.0474 (0.0449) lr 1.6845e-03 eta 0:17:10
epoch [15/50] batch [160/288] time 0.101 (0.101) data 0.000 (0.002) loss 1.1403 (1.0912) ce_loss 1.0430 (0.9601) teacher_loss 1.0353 (0.9552) loss_zs_kd 0.1003 (0.1268) loss_oracle 0.0549 (0.0726) acc 71.8750 (74.2773) kd_loss 0.0417 (0.0457) lr 1.6845e-03 eta 0:17:09
epoch [15/50] batch [180/288] time 0.099 (0.101) data 0.000 (0.002) loss 1.5160 (1.0986) ce_loss 1.3594 (0.9679) teacher_loss 1.3363 (0.9629) loss_zs_kd 0.1516 (0.1261) loss_oracle 0.1038 (0.0726) acc 75.0000 (74.1667) kd_loss 0.0664 (0.0461) lr 1.6845e-03 eta 0:17:07
epoch [15/50] batch [200/288] time 0.107 (0.101) data 0.000 (0.002) loss 0.9464 (1.1048) ce_loss 0.8223 (0.9744) teacher_loss 0.7910 (0.9688) loss_zs_kd 0.1563 (0.1268) loss_oracle 0.0773 (0.0727) acc 71.8750 (73.9062) kd_loss 0.0526 (0.0463) lr 1.6845e-03 eta 0:17:03
epoch [15/50] batch [220/288] time 0.090 (0.100) data 0.000 (0.002) loss 1.2456 (1.1039) ce_loss 1.1035 (0.9737) teacher_loss 1.1044 (0.9679) loss_zs_kd 0.1328 (0.1269) loss_oracle 0.0749 (0.0725) acc 71.8750 (73.8778) kd_loss 0.0562 (0.0466) lr 1.6845e-03 eta 0:16:56
epoch [15/50] batch [240/288] time 0.103 (0.100) data 0.000 (0.001) loss 0.9815 (1.0984) ce_loss 0.7793 (0.9675) teacher_loss 0.7718 (0.9615) loss_zs_kd 0.2318 (0.1282) loss_oracle 0.0938 (0.0727) acc 71.8750 (74.0234) kd_loss 0.0697 (0.0470) lr 1.6845e-03 eta 0:16:52
epoch [15/50] batch [260/288] time 0.093 (0.100) data 0.000 (0.001) loss 1.1337 (1.1014) ce_loss 1.0254 (0.9704) teacher_loss 1.0294 (0.9640) loss_zs_kd 0.0924 (0.1290) loss_oracle 0.0581 (0.0730) acc 75.0000 (73.9784) kd_loss 0.0364 (0.0473) lr 1.6845e-03 eta 0:16:48
epoch [15/50] batch [280/288] time 0.105 (0.100) data 0.000 (0.001) loss 1.0839 (1.0984) ce_loss 0.9863 (0.9680) teacher_loss 0.9805 (0.9617) loss_zs_kd 0.0996 (0.1278) loss_oracle 0.0537 (0.0728) acc 71.8750 (73.9732) kd_loss 0.0367 (0.0472) lr 1.6845e-03 eta 0:16:45
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,409
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 86.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.8%
******* Domain a best val acc:      86.7%, epoch: 14 *******
******* Domain a best val test acc: 83.3%, epoch: 14 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [16/50] batch [20/288] time 0.089 (0.125) data 0.000 (0.020) loss 1.4164 (1.1235) ce_loss 1.2764 (1.0034) teacher_loss 1.2673 (0.9943) loss_zs_kd 0.1424 (0.1225) loss_oracle 0.0779 (0.0679) acc 71.8750 (73.2812) kd_loss 0.0478 (0.0425) lr 1.6374e-03 eta 0:20:56
epoch [16/50] batch [40/288] time 0.108 (0.114) data 0.000 (0.010) loss 1.3055 (1.0918) ce_loss 1.1992 (0.9677) teacher_loss 1.1718 (0.9597) loss_zs_kd 0.1443 (0.1259) loss_oracle 0.0615 (0.0691) acc 68.7500 (73.7500) kd_loss 0.0441 (0.0439) lr 1.6374e-03 eta 0:19:06
epoch [16/50] batch [60/288] time 0.103 (0.110) data 0.000 (0.007) loss 1.2815 (1.0889) ce_loss 1.1367 (0.9647) teacher_loss 1.1268 (0.9577) loss_zs_kd 0.1528 (0.1258) loss_oracle 0.0783 (0.0683) acc 78.1250 (74.1667) kd_loss 0.0459 (0.0421) lr 1.6374e-03 eta 0:18:17
epoch [16/50] batch [80/288] time 0.098 (0.107) data 0.000 (0.005) loss 1.5198 (1.0891) ce_loss 1.3760 (0.9625) teacher_loss 1.3728 (0.9561) loss_zs_kd 0.1522 (0.1273) loss_oracle 0.0710 (0.0693) acc 59.3750 (73.9453) kd_loss 0.0383 (0.0411) lr 1.6374e-03 eta 0:17:52
epoch [16/50] batch [100/288] time 0.101 (0.106) data 0.000 (0.004) loss 1.1885 (1.1045) ce_loss 1.0625 (0.9754) teacher_loss 1.0499 (0.9693) loss_zs_kd 0.1479 (0.1294) loss_oracle 0.0647 (0.0706) acc 65.6250 (73.3125) kd_loss 0.0398 (0.0407) lr 1.6374e-03 eta 0:17:34
epoch [16/50] batch [120/288] time 0.102 (0.105) data 0.001 (0.004) loss 0.9241 (1.0984) ce_loss 0.7788 (0.9714) teacher_loss 0.7680 (0.9645) loss_zs_kd 0.1708 (0.1270) loss_oracle 0.0708 (0.0703) acc 81.2500 (73.3333) kd_loss 0.0374 (0.0405) lr 1.6374e-03 eta 0:17:25
epoch [16/50] batch [140/288] time 0.111 (0.105) data 0.000 (0.003) loss 1.1632 (1.0796) ce_loss 1.0449 (0.9535) teacher_loss 1.0452 (0.9474) loss_zs_kd 0.1277 (0.1259) loss_oracle 0.0541 (0.0693) acc 75.0000 (73.9062) kd_loss 0.0260 (0.0396) lr 1.6374e-03 eta 0:17:23
epoch [16/50] batch [160/288] time 0.096 (0.104) data 0.000 (0.003) loss 1.1823 (1.0786) ce_loss 1.0537 (0.9514) teacher_loss 1.0348 (0.9450) loss_zs_kd 0.1191 (0.1270) loss_oracle 0.0880 (0.0701) acc 75.0000 (74.0820) kd_loss 0.0445 (0.0397) lr 1.6374e-03 eta 0:17:16
epoch [16/50] batch [180/288] time 0.106 (0.104) data 0.000 (0.002) loss 0.8552 (1.0890) ce_loss 0.7637 (0.9616) teacher_loss 0.7646 (0.9554) loss_zs_kd 0.0864 (0.1273) loss_oracle 0.0473 (0.0700) acc 81.2500 (74.1146) kd_loss 0.0270 (0.0396) lr 1.6374e-03 eta 0:17:07
epoch [16/50] batch [200/288] time 0.097 (0.103) data 0.000 (0.002) loss 0.9336 (1.0929) ce_loss 0.7842 (0.9661) teacher_loss 0.7856 (0.9599) loss_zs_kd 0.1400 (0.1263) loss_oracle 0.0780 (0.0698) acc 78.1250 (73.8594) kd_loss 0.0468 (0.0396) lr 1.6374e-03 eta 0:16:58
epoch [16/50] batch [220/288] time 0.100 (0.103) data 0.000 (0.002) loss 0.8032 (1.0894) ce_loss 0.6694 (0.9626) teacher_loss 0.6714 (0.9564) loss_zs_kd 0.1485 (0.1270) loss_oracle 0.0575 (0.0695) acc 84.3750 (73.8778) kd_loss 0.0383 (0.0394) lr 1.6374e-03 eta 0:16:52
epoch [16/50] batch [240/288] time 0.096 (0.102) data 0.000 (0.002) loss 0.9673 (1.0821) ce_loss 0.8252 (0.9548) teacher_loss 0.8370 (0.9488) loss_zs_kd 0.1694 (0.1280) loss_oracle 0.0456 (0.0694) acc 78.1250 (74.0755) kd_loss 0.0268 (0.0393) lr 1.6374e-03 eta 0:16:46
epoch [16/50] batch [260/288] time 0.105 (0.102) data 0.000 (0.002) loss 0.9940 (1.0868) ce_loss 0.8721 (0.9591) teacher_loss 0.8802 (0.9533) loss_zs_kd 0.1199 (0.1288) loss_oracle 0.0538 (0.0691) acc 78.1250 (73.9423) kd_loss 0.0268 (0.0394) lr 1.6374e-03 eta 0:16:43
epoch [16/50] batch [280/288] time 0.104 (0.102) data 0.001 (0.002) loss 1.5609 (1.0952) ce_loss 1.4189 (0.9664) teacher_loss 1.4016 (0.9609) loss_zs_kd 0.1635 (0.1299) loss_oracle 0.0776 (0.0693) acc 62.5000 (73.8281) kd_loss 0.0444 (0.0394) lr 1.6374e-03 eta 0:16:39
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,421
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 80.1%
******* Domain a best val acc:      86.8%, epoch: 16 *******
******* Domain a best val test acc: 83.2%, epoch: 16 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [17/50] batch [20/288] time 0.097 (0.114) data 0.000 (0.016) loss 1.5255 (0.9621) ce_loss 1.3975 (0.8283) teacher_loss 1.4015 (0.8239) loss_zs_kd 0.1235 (0.1152) loss_oracle 0.0622 (0.0805) acc 71.8750 (79.0625) kd_loss 0.0225 (0.0418) lr 1.5878e-03 eta 0:18:33
epoch [17/50] batch [40/288] time 0.103 (0.106) data 0.000 (0.008) loss 1.0270 (1.0448) ce_loss 0.8823 (0.9143) teacher_loss 0.8691 (0.9080) loss_zs_kd 0.1423 (0.1187) loss_oracle 0.0868 (0.0775) acc 78.1250 (76.7188) kd_loss 0.0535 (0.0437) lr 1.5878e-03 eta 0:17:17
epoch [17/50] batch [60/288] time 0.095 (0.104) data 0.000 (0.005) loss 1.4510 (1.0622) ce_loss 1.3271 (0.9318) teacher_loss 1.3351 (0.9258) loss_zs_kd 0.1101 (0.1226) loss_oracle 0.0608 (0.0751) acc 68.7500 (75.8333) kd_loss 0.0275 (0.0428) lr 1.5878e-03 eta 0:16:50
epoch [17/50] batch [80/288] time 0.097 (0.101) data 0.000 (0.004) loss 0.8828 (1.0574) ce_loss 0.7729 (0.9272) teacher_loss 0.7439 (0.9212) loss_zs_kd 0.1552 (0.1264) loss_oracle 0.0614 (0.0730) acc 78.1250 (75.8203) kd_loss 0.0389 (0.0424) lr 1.5878e-03 eta 0:16:18
epoch [17/50] batch [100/288] time 0.089 (0.099) data 0.000 (0.003) loss 1.2318 (1.0608) ce_loss 1.0791 (0.9286) teacher_loss 1.0784 (0.9223) loss_zs_kd 0.1228 (0.1282) loss_oracle 0.0921 (0.0744) acc 62.5000 (75.5625) kd_loss 0.0574 (0.0430) lr 1.5878e-03 eta 0:15:55
epoch [17/50] batch [120/288] time 0.082 (0.097) data 0.000 (0.003) loss 1.0983 (1.0684) ce_loss 0.9897 (0.9364) teacher_loss 0.9993 (0.9309) loss_zs_kd 0.0805 (0.1280) loss_oracle 0.0588 (0.0735) acc 75.0000 (75.0521) kd_loss 0.0326 (0.0427) lr 1.5878e-03 eta 0:15:37
epoch [17/50] batch [140/288] time 0.097 (0.096) data 0.000 (0.002) loss 1.2588 (1.0914) ce_loss 1.1416 (0.9590) teacher_loss 1.1449 (0.9529) loss_zs_kd 0.1276 (0.1295) loss_oracle 0.0501 (0.0738) acc 65.6250 (74.5759) kd_loss 0.0342 (0.0435) lr 1.5878e-03 eta 0:15:26
epoch [17/50] batch [160/288] time 0.084 (0.095) data 0.000 (0.002) loss 1.1613 (1.0916) ce_loss 1.0420 (0.9594) teacher_loss 1.0364 (0.9534) loss_zs_kd 0.1206 (0.1298) loss_oracle 0.0645 (0.0733) acc 65.6250 (74.5312) kd_loss 0.0450 (0.0440) lr 1.5878e-03 eta 0:15:16
epoch [17/50] batch [180/288] time 0.095 (0.095) data 0.000 (0.002) loss 0.9914 (1.0827) ce_loss 0.8638 (0.9517) teacher_loss 0.8574 (0.9453) loss_zs_kd 0.0999 (0.1284) loss_oracle 0.0841 (0.0731) acc 78.1250 (74.6701) kd_loss 0.0494 (0.0441) lr 1.5878e-03 eta 0:15:08
epoch [17/50] batch [200/288] time 0.083 (0.094) data 0.000 (0.002) loss 0.9270 (1.0804) ce_loss 0.8086 (0.9487) teacher_loss 0.8122 (0.9423) loss_zs_kd 0.0862 (0.1292) loss_oracle 0.0717 (0.0735) acc 75.0000 (74.7969) kd_loss 0.0416 (0.0444) lr 1.5878e-03 eta 0:15:01
epoch [17/50] batch [220/288] time 0.096 (0.094) data 0.000 (0.002) loss 0.9326 (1.0797) ce_loss 0.8247 (0.9474) teacher_loss 0.8127 (0.9413) loss_zs_kd 0.0737 (0.1302) loss_oracle 0.0830 (0.0733) acc 81.2500 (74.8153) kd_loss 0.0481 (0.0444) lr 1.5878e-03 eta 0:14:56
epoch [17/50] batch [240/288] time 0.086 (0.093) data 0.000 (0.001) loss 1.0469 (1.0779) ce_loss 0.9355 (0.9454) teacher_loss 0.9076 (0.9394) loss_zs_kd 0.1103 (0.1300) loss_oracle 0.0842 (0.0735) acc 71.8750 (74.7786) kd_loss 0.0462 (0.0443) lr 1.5878e-03 eta 0:14:52
epoch [17/50] batch [260/288] time 0.094 (0.093) data 0.000 (0.001) loss 1.4803 (1.0809) ce_loss 1.3613 (0.9479) teacher_loss 1.3606 (0.9418) loss_zs_kd 0.1290 (0.1307) loss_oracle 0.0553 (0.0737) acc 68.7500 (74.6995) kd_loss 0.0354 (0.0444) lr 1.5878e-03 eta 0:14:47
epoch [17/50] batch [280/288] time 0.082 (0.093) data 0.000 (0.001) loss 1.3637 (1.0806) ce_loss 1.2246 (0.9469) teacher_loss 1.1968 (0.9409) loss_zs_kd 0.1731 (0.1316) loss_oracle 0.0803 (0.0739) acc 71.8750 (74.7433) kd_loss 0.0562 (0.0443) lr 1.5878e-03 eta 0:14:41
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,423
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,017
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.9%
******* Domain a best val acc:      86.9%, epoch: 17 *******
******* Domain a best val test acc: 83.1%, epoch: 17 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [18/50] batch [20/288] time 0.092 (0.113) data 0.000 (0.015) loss 1.3605 (1.0747) ce_loss 1.2451 (0.9364) teacher_loss 1.2320 (0.9299) loss_zs_kd 0.1323 (0.1411) loss_oracle 0.0623 (0.0742) acc 68.7500 (75.0000) kd_loss 0.0407 (0.0425) lr 1.5358e-03 eta 0:17:51
epoch [18/50] batch [40/288] time 0.095 (0.103) data 0.000 (0.008) loss 1.6483 (1.1241) ce_loss 1.4854 (0.9849) teacher_loss 1.4868 (0.9781) loss_zs_kd 0.1848 (0.1408) loss_oracle 0.0691 (0.0756) acc 62.5000 (73.7500) kd_loss 0.0433 (0.0445) lr 1.5358e-03 eta 0:16:19
epoch [18/50] batch [60/288] time 0.093 (0.101) data 0.000 (0.005) loss 0.8480 (1.1179) ce_loss 0.7119 (0.9833) teacher_loss 0.7062 (0.9761) loss_zs_kd 0.1238 (0.1348) loss_oracle 0.0799 (0.0744) acc 75.0000 (73.6979) kd_loss 0.0601 (0.0446) lr 1.5358e-03 eta 0:15:53
epoch [18/50] batch [80/288] time 0.097 (0.101) data 0.000 (0.004) loss 1.9831 (1.1385) ce_loss 1.7998 (1.0041) teacher_loss 1.7939 (0.9958) loss_zs_kd 0.1805 (0.1338) loss_oracle 0.0990 (0.0758) acc 53.1250 (73.0469) kd_loss 0.0481 (0.0456) lr 1.5358e-03 eta 0:15:47
epoch [18/50] batch [100/288] time 0.094 (0.100) data 0.000 (0.003) loss 0.9125 (1.1290) ce_loss 0.8081 (0.9919) teacher_loss 0.7867 (0.9840) loss_zs_kd 0.1026 (0.1337) loss_oracle 0.0744 (0.0782) acc 87.5000 (73.2188) kd_loss 0.0482 (0.0472) lr 1.5358e-03 eta 0:15:35
epoch [18/50] batch [120/288] time 0.099 (0.099) data 0.000 (0.003) loss 1.2292 (1.1159) ce_loss 1.0830 (0.9786) teacher_loss 1.0877 (0.9709) loss_zs_kd 0.1290 (0.1323) loss_oracle 0.0770 (0.0789) acc 75.0000 (73.5938) kd_loss 0.0501 (0.0477) lr 1.5358e-03 eta 0:15:27
epoch [18/50] batch [140/288] time 0.094 (0.099) data 0.000 (0.002) loss 1.1637 (1.1235) ce_loss 1.0234 (0.9862) teacher_loss 1.0232 (0.9781) loss_zs_kd 0.1306 (0.1324) loss_oracle 0.0752 (0.0792) acc 75.0000 (73.2812) kd_loss 0.0448 (0.0483) lr 1.5358e-03 eta 0:15:22
epoch [18/50] batch [160/288] time 0.093 (0.098) data 0.000 (0.002) loss 1.0358 (1.1158) ce_loss 0.8921 (0.9775) teacher_loss 0.8642 (0.9691) loss_zs_kd 0.1695 (0.1333) loss_oracle 0.0869 (0.0801) acc 75.0000 (73.5156) kd_loss 0.0428 (0.0491) lr 1.5358e-03 eta 0:15:17
epoch [18/50] batch [180/288] time 0.099 (0.098) data 0.000 (0.002) loss 1.0025 (1.1115) ce_loss 0.8037 (0.9720) teacher_loss 0.8170 (0.9636) loss_zs_kd 0.1731 (0.1340) loss_oracle 0.0989 (0.0809) acc 68.7500 (73.6458) kd_loss 0.0599 (0.0495) lr 1.5358e-03 eta 0:15:11
epoch [18/50] batch [200/288] time 0.095 (0.098) data 0.000 (0.002) loss 1.4553 (1.1026) ce_loss 1.2988 (0.9628) teacher_loss 1.2933 (0.9546) loss_zs_kd 0.1298 (0.1335) loss_oracle 0.0971 (0.0812) acc 62.5000 (73.8125) kd_loss 0.0645 (0.0500) lr 1.5358e-03 eta 0:15:14
epoch [18/50] batch [220/288] time 0.097 (0.098) data 0.000 (0.002) loss 1.6132 (1.1062) ce_loss 1.5049 (0.9677) teacher_loss 1.4899 (0.9587) loss_zs_kd 0.1131 (0.1329) loss_oracle 0.0667 (0.0810) acc 62.5000 (73.6506) kd_loss 0.0390 (0.0501) lr 1.5358e-03 eta 0:15:13
epoch [18/50] batch [240/288] time 0.107 (0.098) data 0.000 (0.001) loss 0.8777 (1.1082) ce_loss 0.7188 (0.9689) teacher_loss 0.7118 (0.9602) loss_zs_kd 0.1407 (0.1332) loss_oracle 0.0955 (0.0814) acc 84.3750 (73.6068) kd_loss 0.0597 (0.0504) lr 1.5358e-03 eta 0:15:12
epoch [18/50] batch [260/288] time 0.115 (0.099) data 0.000 (0.001) loss 1.0735 (1.1072) ce_loss 0.9624 (0.9686) teacher_loss 0.9431 (0.9600) loss_zs_kd 0.0706 (0.1322) loss_oracle 0.0951 (0.0811) acc 78.1250 (73.7981) kd_loss 0.0544 (0.0501) lr 1.5358e-03 eta 0:15:13
epoch [18/50] batch [280/288] time 0.110 (0.099) data 0.000 (0.001) loss 1.4295 (1.1109) ce_loss 1.2480 (0.9718) teacher_loss 1.2290 (0.9631) loss_zs_kd 0.1633 (0.1320) loss_oracle 0.1188 (0.0817) acc 65.6250 (73.7612) kd_loss 0.0767 (0.0504) lr 1.5358e-03 eta 0:15:16
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,429
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.4%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,010
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 79.5%
******* Domain a best val acc:      87.1%, epoch: 18 *******
******* Domain a best val test acc: 82.8%, epoch: 18 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [19/50] batch [20/288] time 0.096 (0.121) data 0.000 (0.017) loss 1.1166 (1.0555) ce_loss 1.0029 (0.9120) teacher_loss 1.0068 (0.9050) loss_zs_kd 0.1041 (0.1310) loss_oracle 0.0577 (0.0850) acc 71.8750 (76.8750) kd_loss 0.0363 (0.0523) lr 1.4818e-03 eta 0:18:28
epoch [19/50] batch [40/288] time 0.111 (0.111) data 0.000 (0.009) loss 1.1800 (1.1079) ce_loss 1.0576 (0.9678) teacher_loss 1.0460 (0.9600) loss_zs_kd 0.1258 (0.1302) loss_oracle 0.0711 (0.0829) acc 65.6250 (74.6094) kd_loss 0.0382 (0.0523) lr 1.4818e-03 eta 0:17:00
epoch [19/50] batch [60/288] time 0.098 (0.107) data 0.000 (0.006) loss 1.3684 (1.1538) ce_loss 1.2217 (1.0153) teacher_loss 1.2122 (1.0061) loss_zs_kd 0.1703 (0.1340) loss_oracle 0.0710 (0.0808) acc 71.8750 (73.4896) kd_loss 0.0534 (0.0520) lr 1.4818e-03 eta 0:16:24
epoch [19/50] batch [80/288] time 0.097 (0.106) data 0.000 (0.004) loss 1.0129 (1.1114) ce_loss 0.8828 (0.9755) teacher_loss 0.8807 (0.9673) loss_zs_kd 0.1249 (0.1329) loss_oracle 0.0697 (0.0776) acc 68.7500 (74.3750) kd_loss 0.0440 (0.0499) lr 1.4818e-03 eta 0:16:05
epoch [19/50] batch [100/288] time 0.100 (0.105) data 0.000 (0.004) loss 1.2135 (1.1058) ce_loss 1.0771 (0.9698) teacher_loss 1.0776 (0.9626) loss_zs_kd 0.1092 (0.1317) loss_oracle 0.0813 (0.0774) acc 65.6250 (74.5000) kd_loss 0.0382 (0.0481) lr 1.4818e-03 eta 0:15:52
epoch [19/50] batch [120/288] time 0.101 (0.104) data 0.000 (0.003) loss 1.5485 (1.1042) ce_loss 1.4414 (0.9679) teacher_loss 1.4017 (0.9607) loss_zs_kd 0.1268 (0.1311) loss_oracle 0.0833 (0.0780) acc 65.6250 (74.6094) kd_loss 0.0524 (0.0480) lr 1.4818e-03 eta 0:15:42
epoch [19/50] batch [140/288] time 0.107 (0.103) data 0.000 (0.003) loss 1.4360 (1.1040) ce_loss 1.3193 (0.9675) teacher_loss 1.3204 (0.9602) loss_zs_kd 0.1049 (0.1310) loss_oracle 0.0632 (0.0783) acc 75.0000 (74.6652) kd_loss 0.0427 (0.0484) lr 1.4818e-03 eta 0:15:38
epoch [19/50] batch [160/288] time 0.090 (0.103) data 0.000 (0.002) loss 1.0994 (1.1032) ce_loss 0.9644 (0.9683) teacher_loss 0.9531 (0.9610) loss_zs_kd 0.1422 (0.1288) loss_oracle 0.0752 (0.0778) acc 71.8750 (74.3945) kd_loss 0.0461 (0.0481) lr 1.4818e-03 eta 0:15:33
epoch [19/50] batch [180/288] time 0.104 (0.103) data 0.000 (0.002) loss 1.1708 (1.1027) ce_loss 1.0371 (0.9684) teacher_loss 1.0174 (0.9611) loss_zs_kd 0.1170 (0.1290) loss_oracle 0.0950 (0.0771) acc 75.0000 (74.2708) kd_loss 0.0588 (0.0477) lr 1.4818e-03 eta 0:15:27
epoch [19/50] batch [200/288] time 0.097 (0.103) data 0.000 (0.002) loss 0.7915 (1.0958) ce_loss 0.6270 (0.9619) teacher_loss 0.6216 (0.9548) loss_zs_kd 0.1599 (0.1294) loss_oracle 0.0899 (0.0763) acc 81.2500 (74.3281) kd_loss 0.0448 (0.0468) lr 1.4818e-03 eta 0:15:24
epoch [19/50] batch [220/288] time 0.131 (0.103) data 0.001 (0.002) loss 1.1249 (1.1048) ce_loss 0.9614 (0.9687) teacher_loss 0.9767 (0.9618) loss_zs_kd 0.1707 (0.1320) loss_oracle 0.0629 (0.0769) acc 78.1250 (74.2898) kd_loss 0.0373 (0.0469) lr 1.4818e-03 eta 0:15:25
epoch [19/50] batch [240/288] time 0.129 (0.105) data 0.001 (0.002) loss 0.8318 (1.1026) ce_loss 0.6553 (0.9665) teacher_loss 0.6506 (0.9594) loss_zs_kd 0.2030 (0.1325) loss_oracle 0.0798 (0.0769) acc 81.2500 (74.2188) kd_loss 0.0485 (0.0469) lr 1.4818e-03 eta 0:15:38
epoch [19/50] batch [260/288] time 0.126 (0.105) data 0.000 (0.001) loss 1.1576 (1.0995) ce_loss 1.0273 (0.9632) teacher_loss 1.0259 (0.9563) loss_zs_kd 0.1478 (0.1331) loss_oracle 0.0578 (0.0767) acc 75.0000 (74.2909) kd_loss 0.0370 (0.0468) lr 1.4818e-03 eta 0:15:42
epoch [19/50] batch [280/288] time 0.106 (0.105) data 0.000 (0.001) loss 1.5669 (1.0999) ce_loss 1.4326 (0.9639) teacher_loss 1.4312 (0.9569) loss_zs_kd 0.1623 (0.1333) loss_oracle 0.0545 (0.0763) acc 59.3750 (74.3192) kd_loss 0.0389 (0.0465) lr 1.4818e-03 eta 0:15:42
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,424
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,019
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 80.0%
******* Domain a best val acc:      87.1%, epoch: 18 *******
******* Domain a best val test acc: 82.8%, epoch: 18 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [20/50] batch [20/288] time 0.097 (0.120) data 0.000 (0.015) loss 1.5044 (1.0763) ce_loss 1.3750 (0.9390) teacher_loss 1.3787 (0.9341) loss_zs_kd 0.1314 (0.1367) loss_oracle 0.0600 (0.0739) acc 59.3750 (73.9062) kd_loss 0.0342 (0.0438) lr 1.4258e-03 eta 0:17:45
epoch [20/50] batch [40/288] time 0.102 (0.109) data 0.000 (0.007) loss 1.1408 (1.0823) ce_loss 0.9448 (0.9405) teacher_loss 0.9356 (0.9343) loss_zs_kd 0.2379 (0.1448) loss_oracle 0.0863 (0.0757) acc 75.0000 (74.0625) kd_loss 0.0398 (0.0440) lr 1.4258e-03 eta 0:16:12
epoch [20/50] batch [60/288] time 0.105 (0.106) data 0.000 (0.005) loss 0.9156 (1.0771) ce_loss 0.8071 (0.9339) teacher_loss 0.8129 (0.9286) loss_zs_kd 0.0852 (0.1456) loss_oracle 0.0601 (0.0757) acc 81.2500 (74.4792) kd_loss 0.0328 (0.0437) lr 1.4258e-03 eta 0:15:36
epoch [20/50] batch [80/288] time 0.096 (0.103) data 0.000 (0.004) loss 0.9229 (1.0799) ce_loss 0.7852 (0.9356) teacher_loss 0.7819 (0.9307) loss_zs_kd 0.1071 (0.1431) loss_oracle 0.0874 (0.0776) acc 81.2500 (74.4141) kd_loss 0.0531 (0.0446) lr 1.4258e-03 eta 0:15:09
epoch [20/50] batch [100/288] time 0.092 (0.101) data 0.000 (0.003) loss 1.2642 (1.0714) ce_loss 1.1533 (0.9291) teacher_loss 1.1292 (0.9243) loss_zs_kd 0.1299 (0.1397) loss_oracle 0.0701 (0.0773) acc 68.7500 (74.6875) kd_loss 0.0418 (0.0443) lr 1.4258e-03 eta 0:14:53
epoch [20/50] batch [120/288] time 0.103 (0.100) data 0.000 (0.003) loss 0.6769 (1.0876) ce_loss 0.5752 (0.9474) teacher_loss 0.5706 (0.9415) loss_zs_kd 0.0710 (0.1386) loss_oracle 0.0708 (0.0768) acc 87.5000 (74.2448) kd_loss 0.0444 (0.0445) lr 1.4258e-03 eta 0:14:44
epoch [20/50] batch [140/288] time 0.099 (0.100) data 0.001 (0.002) loss 0.9394 (1.0932) ce_loss 0.8008 (0.9527) teacher_loss 0.7858 (0.9464) loss_zs_kd 0.1446 (0.1397) loss_oracle 0.0813 (0.0769) acc 78.1250 (74.0402) kd_loss 0.0429 (0.0448) lr 1.4258e-03 eta 0:14:38
epoch [20/50] batch [160/288] time 0.090 (0.099) data 0.000 (0.002) loss 1.0597 (1.0888) ce_loss 0.9561 (0.9493) teacher_loss 0.9631 (0.9434) loss_zs_kd 0.1069 (0.1391) loss_oracle 0.0431 (0.0759) acc 71.8750 (74.1992) kd_loss 0.0215 (0.0443) lr 1.4258e-03 eta 0:14:30
epoch [20/50] batch [180/288] time 0.096 (0.099) data 0.000 (0.002) loss 0.8614 (1.0794) ce_loss 0.7515 (0.9411) teacher_loss 0.7537 (0.9354) loss_zs_kd 0.1015 (0.1387) loss_oracle 0.0570 (0.0746) acc 81.2500 (74.4618) kd_loss 0.0356 (0.0437) lr 1.4258e-03 eta 0:14:23
epoch [20/50] batch [200/288] time 0.087 (0.098) data 0.000 (0.002) loss 1.5950 (1.0841) ce_loss 1.4023 (0.9458) teacher_loss 1.3962 (0.9403) loss_zs_kd 0.2041 (0.1378) loss_oracle 0.0968 (0.0749) acc 62.5000 (74.3125) kd_loss 0.0381 (0.0434) lr 1.4258e-03 eta 0:14:18
epoch [20/50] batch [220/288] time 0.099 (0.098) data 0.000 (0.002) loss 1.0234 (1.0733) ce_loss 0.8955 (0.9344) teacher_loss 0.8795 (0.9292) loss_zs_kd 0.1288 (0.1379) loss_oracle 0.0795 (0.0752) acc 75.0000 (74.4886) kd_loss 0.0382 (0.0428) lr 1.4258e-03 eta 0:14:11
epoch [20/50] batch [240/288] time 0.194 (0.101) data 0.000 (0.001) loss 1.2434 (1.0709) ce_loss 1.0742 (0.9308) teacher_loss 1.0862 (0.9259) loss_zs_kd 0.1393 (0.1388) loss_oracle 0.0875 (0.0756) acc 62.5000 (74.5703) kd_loss 0.0406 (0.0427) lr 1.4258e-03 eta 0:14:39
epoch [20/50] batch [260/288] time 0.191 (0.108) data 0.000 (0.001) loss 1.4030 (1.0673) ce_loss 1.2754 (0.9271) teacher_loss 1.2721 (0.9222) loss_zs_kd 0.0955 (0.1381) loss_oracle 0.0831 (0.0760) acc 65.6250 (74.6755) kd_loss 0.0430 (0.0429) lr 1.4258e-03 eta 0:15:39
epoch [20/50] batch [280/288] time 0.221 (0.115) data 0.000 (0.001) loss 0.8049 (1.0645) ce_loss 0.6826 (0.9251) teacher_loss 0.6796 (0.9201) loss_zs_kd 0.1165 (0.1373) loss_oracle 0.0670 (0.0758) acc 87.5000 (74.7656) kd_loss 0.0336 (0.0429) lr 1.4258e-03 eta 0:16:30
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,430
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 80.2%
******* Domain a best val acc:      87.1%, epoch: 20 *******
******* Domain a best val test acc: 83.3%, epoch: 20 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [21/50] batch [20/288] time 0.189 (0.206) data 0.000 (0.013) loss 0.5963 (1.0370) ce_loss 0.4409 (0.8876) teacher_loss 0.4267 (0.8822) loss_zs_kd 0.1358 (0.1468) loss_oracle 0.1017 (0.0814) acc 90.6250 (74.8438) kd_loss 0.0495 (0.0416) lr 1.3681e-03 eta 0:29:36
epoch [21/50] batch [40/288] time 0.193 (0.200) data 0.000 (0.006) loss 0.7080 (1.0326) ce_loss 0.5869 (0.8885) teacher_loss 0.5859 (0.8836) loss_zs_kd 0.1199 (0.1409) loss_oracle 0.0621 (0.0786) acc 84.3750 (74.2188) kd_loss 0.0417 (0.0412) lr 1.3681e-03 eta 0:28:37
epoch [21/50] batch [60/288] time 0.194 (0.198) data 0.000 (0.004) loss 1.0096 (1.0532) ce_loss 0.8584 (0.9108) teacher_loss 0.8629 (0.9056) loss_zs_kd 0.1396 (0.1379) loss_oracle 0.0769 (0.0786) acc 78.1250 (74.5312) kd_loss 0.0359 (0.0416) lr 1.3681e-03 eta 0:28:15
epoch [21/50] batch [80/288] time 0.195 (0.197) data 0.000 (0.003) loss 0.7099 (1.0792) ce_loss 0.5864 (0.9380) teacher_loss 0.5832 (0.9332) loss_zs_kd 0.0847 (0.1343) loss_oracle 0.0844 (0.0788) acc 81.2500 (74.0234) kd_loss 0.0486 (0.0410) lr 1.3681e-03 eta 0:28:03
epoch [21/50] batch [100/288] time 0.197 (0.196) data 0.000 (0.003) loss 1.0385 (1.0676) ce_loss 0.9131 (0.9263) teacher_loss 0.9090 (0.9211) loss_zs_kd 0.0955 (0.1329) loss_oracle 0.0818 (0.0801) acc 75.0000 (74.4375) kd_loss 0.0372 (0.0417) lr 1.3681e-03 eta 0:27:54
epoch [21/50] batch [120/288] time 0.189 (0.196) data 0.000 (0.002) loss 0.8206 (1.0735) ce_loss 0.6978 (0.9320) teacher_loss 0.6978 (0.9266) loss_zs_kd 0.1050 (0.1352) loss_oracle 0.0703 (0.0792) acc 84.3750 (74.4792) kd_loss 0.0392 (0.0414) lr 1.3681e-03 eta 0:27:47
epoch [21/50] batch [140/288] time 0.194 (0.195) data 0.000 (0.002) loss 1.0781 (1.0833) ce_loss 0.9409 (0.9433) teacher_loss 0.9462 (0.9385) loss_zs_kd 0.1475 (0.1346) loss_oracle 0.0582 (0.0775) acc 81.2500 (74.2411) kd_loss 0.0267 (0.0405) lr 1.3681e-03 eta 0:27:41
epoch [21/50] batch [160/288] time 0.093 (0.193) data 0.000 (0.002) loss 1.0351 (1.0989) ce_loss 0.8940 (0.9572) teacher_loss 0.8851 (0.9528) loss_zs_kd 0.1369 (0.1379) loss_oracle 0.0815 (0.0771) acc 75.0000 (74.0039) kd_loss 0.0480 (0.0407) lr 1.3681e-03 eta 0:27:12
epoch [21/50] batch [180/288] time 0.085 (0.195) data 0.000 (0.002) loss 1.2880 (1.1040) ce_loss 1.1719 (0.9625) teacher_loss 1.1756 (0.9584) loss_zs_kd 0.1098 (0.1387) loss_oracle 0.0575 (0.0762) acc 68.7500 (73.7847) kd_loss 0.0263 (0.0402) lr 1.3681e-03 eta 0:27:31
epoch [21/50] batch [200/288] time 0.092 (0.201) data 0.000 (0.001) loss 1.2956 (1.0962) ce_loss 1.2031 (0.9550) teacher_loss 1.1901 (0.9510) loss_zs_kd 0.1098 (0.1385) loss_oracle 0.0507 (0.0760) acc 68.7500 (74.0625) kd_loss 0.0248 (0.0400) lr 1.3681e-03 eta 0:28:16
epoch [21/50] batch [220/288] time 0.195 (0.199) data 0.000 (0.001) loss 0.9320 (1.0953) ce_loss 0.8213 (0.9537) teacher_loss 0.8114 (0.9498) loss_zs_kd 0.1168 (0.1384) loss_oracle 0.0622 (0.0763) acc 78.1250 (74.0483) kd_loss 0.0320 (0.0401) lr 1.3681e-03 eta 0:27:59
epoch [21/50] batch [240/288] time 0.197 (0.199) data 0.000 (0.001) loss 1.0918 (1.1059) ce_loss 0.9346 (0.9650) teacher_loss 0.9381 (0.9612) loss_zs_kd 0.1682 (0.1381) loss_oracle 0.0696 (0.0757) acc 81.2500 (73.8932) kd_loss 0.0280 (0.0398) lr 1.3681e-03 eta 0:27:51
epoch [21/50] batch [260/288] time 0.194 (0.199) data 0.000 (0.001) loss 0.9967 (1.1023) ce_loss 0.8618 (0.9616) teacher_loss 0.8640 (0.9579) loss_zs_kd 0.1215 (0.1378) loss_oracle 0.0720 (0.0755) acc 75.0000 (73.9543) kd_loss 0.0328 (0.0397) lr 1.3681e-03 eta 0:27:44
epoch [21/50] batch [280/288] time 0.190 (0.198) data 0.000 (0.001) loss 0.9971 (1.0998) ce_loss 0.8794 (0.9594) teacher_loss 0.8761 (0.9557) loss_zs_kd 0.1132 (0.1378) loss_oracle 0.0644 (0.0752) acc 78.1250 (74.0737) kd_loss 0.0352 (0.0396) lr 1.3681e-03 eta 0:27:37
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,428
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 86.4%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,016
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 80.0%
******* Domain a best val acc:      87.1%, epoch: 20 *******
******* Domain a best val test acc: 83.3%, epoch: 20 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [22/50] batch [20/288] time 0.196 (0.213) data 0.000 (0.014) loss 1.5406 (1.0819) ce_loss 1.3965 (0.9341) teacher_loss 1.3927 (0.9281) loss_zs_kd 0.1524 (0.1526) loss_oracle 0.0718 (0.0775) acc 56.2500 (73.2812) kd_loss 0.0359 (0.0421) lr 1.3090e-03 eta 0:29:30
epoch [22/50] batch [40/288] time 0.196 (0.203) data 0.000 (0.007) loss 0.9811 (1.0664) ce_loss 0.8721 (0.9224) teacher_loss 0.8773 (0.9171) loss_zs_kd 0.1249 (0.1446) loss_oracle 0.0413 (0.0771) acc 84.3750 (73.9062) kd_loss 0.0197 (0.0409) lr 1.3090e-03 eta 0:28:08
epoch [22/50] batch [60/288] time 0.193 (0.200) data 0.001 (0.005) loss 0.8017 (1.0838) ce_loss 0.6616 (0.9430) teacher_loss 0.6593 (0.9378) loss_zs_kd 0.1860 (0.1447) loss_oracle 0.0493 (0.0737) acc 81.2500 (73.9583) kd_loss 0.0325 (0.0394) lr 1.3090e-03 eta 0:27:41
epoch [22/50] batch [80/288] time 0.193 (0.199) data 0.000 (0.004) loss 1.4200 (1.0713) ce_loss 1.2881 (0.9297) teacher_loss 1.2640 (0.9247) loss_zs_kd 0.1582 (0.1453) loss_oracle 0.0770 (0.0740) acc 68.7500 (74.5312) kd_loss 0.0433 (0.0400) lr 1.3090e-03 eta 0:27:24
epoch [22/50] batch [100/288] time 0.181 (0.198) data 0.000 (0.003) loss 0.8030 (1.0709) ce_loss 0.6914 (0.9311) teacher_loss 0.6881 (0.9269) loss_zs_kd 0.0850 (0.1405) loss_oracle 0.0724 (0.0738) acc 78.1250 (74.2812) kd_loss 0.0366 (0.0401) lr 1.3090e-03 eta 0:27:10
epoch [22/50] batch [120/288] time 0.193 (0.197) data 0.000 (0.003) loss 1.1308 (1.0806) ce_loss 0.9766 (0.9393) teacher_loss 0.9887 (0.9353) loss_zs_kd 0.1607 (0.1422) loss_oracle 0.0618 (0.0743) acc 75.0000 (74.3229) kd_loss 0.0388 (0.0402) lr 1.3090e-03 eta 0:27:01
epoch [22/50] batch [140/288] time 0.458 (0.196) data 0.000 (0.002) loss 1.0557 (1.0719) ce_loss 0.9048 (0.9318) teacher_loss 0.9034 (0.9274) loss_zs_kd 0.1472 (0.1397) loss_oracle 0.0787 (0.0746) acc 75.0000 (74.5312) kd_loss 0.0400 (0.0405) lr 1.3090e-03 eta 0:26:48
epoch [22/50] batch [160/288] time 0.472 (0.200) data 0.000 (0.002) loss 0.6863 (1.0819) ce_loss 0.5806 (0.9417) teacher_loss 0.5871 (0.9373) loss_zs_kd 0.0973 (0.1401) loss_oracle 0.0506 (0.0746) acc 84.3750 (74.3555) kd_loss 0.0326 (0.0409) lr 1.3090e-03 eta 0:27:14
epoch [22/50] batch [180/288] time 0.193 (0.203) data 0.000 (0.002) loss 0.9863 (1.0766) ce_loss 0.8716 (0.9369) teacher_loss 0.8751 (0.9321) loss_zs_kd 0.0890 (0.1401) loss_oracle 0.0667 (0.0744) acc 81.2500 (74.6354) kd_loss 0.0304 (0.0412) lr 1.3090e-03 eta 0:27:42
epoch [22/50] batch [200/288] time 0.189 (0.202) data 0.000 (0.002) loss 0.9866 (1.0800) ce_loss 0.8696 (0.9411) teacher_loss 0.8553 (0.9362) loss_zs_kd 0.1367 (0.1397) loss_oracle 0.0630 (0.0739) acc 75.0000 (74.5938) kd_loss 0.0361 (0.0410) lr 1.3090e-03 eta 0:27:27
epoch [22/50] batch [220/288] time 0.195 (0.201) data 0.000 (0.001) loss 0.6851 (1.0797) ce_loss 0.5376 (0.9409) teacher_loss 0.5414 (0.9361) loss_zs_kd 0.1323 (0.1406) loss_oracle 0.0776 (0.0733) acc 87.5000 (74.4034) kd_loss 0.0484 (0.0408) lr 1.3090e-03 eta 0:27:17
epoch [22/50] batch [240/288] time 0.192 (0.201) data 0.000 (0.001) loss 1.1634 (1.0829) ce_loss 1.0146 (0.9446) teacher_loss 1.0127 (0.9403) loss_zs_kd 0.1454 (0.1405) loss_oracle 0.0780 (0.0724) acc 71.8750 (74.2839) kd_loss 0.0359 (0.0402) lr 1.3090e-03 eta 0:27:08
epoch [22/50] batch [260/288] time 0.192 (0.200) data 0.000 (0.001) loss 1.0400 (1.0838) ce_loss 0.8613 (0.9456) teacher_loss 0.8625 (0.9414) loss_zs_kd 0.1446 (0.1398) loss_oracle 0.1052 (0.0725) acc 81.2500 (74.3029) kd_loss 0.0509 (0.0401) lr 1.3090e-03 eta 0:26:59
epoch [22/50] batch [280/288] time 0.196 (0.200) data 0.000 (0.001) loss 0.7024 (1.0861) ce_loss 0.5669 (0.9478) teacher_loss 0.5721 (0.9436) loss_zs_kd 0.1317 (0.1400) loss_oracle 0.0644 (0.0725) acc 84.3750 (74.1518) kd_loss 0.0342 (0.0401) lr 1.3090e-03 eta 0:26:51
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,423
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,011
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.8%
******* Domain a best val acc:      87.1%, epoch: 20 *******
******* Domain a best val test acc: 83.3%, epoch: 20 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [23/50] batch [20/288] time 0.194 (0.206) data 0.000 (0.012) loss 1.2265 (1.0425) ce_loss 1.0664 (0.9107) teacher_loss 1.0576 (0.9058) loss_zs_kd 0.1388 (0.1318) loss_oracle 0.0994 (0.0708) acc 68.7500 (74.5312) kd_loss 0.0527 (0.0377) lr 1.2487e-03 eta 0:27:34
epoch [23/50] batch [40/288] time 0.193 (0.199) data 0.000 (0.006) loss 1.0243 (1.0491) ce_loss 0.8750 (0.9111) teacher_loss 0.8650 (0.9073) loss_zs_kd 0.1232 (0.1357) loss_oracle 0.0976 (0.0739) acc 75.0000 (74.7656) kd_loss 0.0550 (0.0388) lr 1.2487e-03 eta 0:26:40
epoch [23/50] batch [60/288] time 0.188 (0.198) data 0.000 (0.004) loss 1.4376 (1.0801) ce_loss 1.2939 (0.9394) teacher_loss 1.2877 (0.9361) loss_zs_kd 0.1875 (0.1405) loss_oracle 0.0562 (0.0737) acc 62.5000 (73.7500) kd_loss 0.0293 (0.0388) lr 1.2487e-03 eta 0:26:22
epoch [23/50] batch [80/288] time 0.196 (0.197) data 0.000 (0.003) loss 1.3555 (1.0698) ce_loss 1.2246 (0.9286) teacher_loss 1.2055 (0.9242) loss_zs_kd 0.1525 (0.1434) loss_oracle 0.0738 (0.0738) acc 65.6250 (74.1016) kd_loss 0.0430 (0.0390) lr 1.2487e-03 eta 0:26:11
epoch [23/50] batch [100/288] time 0.194 (0.196) data 0.000 (0.003) loss 0.8456 (1.0611) ce_loss 0.6938 (0.9191) teacher_loss 0.6991 (0.9143) loss_zs_kd 0.1465 (0.1450) loss_oracle 0.0732 (0.0743) acc 84.3750 (74.5000) kd_loss 0.0418 (0.0400) lr 1.2487e-03 eta 0:26:01
epoch [23/50] batch [120/288] time 0.498 (0.205) data 0.000 (0.002) loss 0.7317 (1.0674) ce_loss 0.5845 (0.9257) teacher_loss 0.5912 (0.9218) loss_zs_kd 0.1449 (0.1452) loss_oracle 0.0680 (0.0730) acc 90.6250 (74.6354) kd_loss 0.0374 (0.0400) lr 1.2487e-03 eta 0:27:06
epoch [23/50] batch [140/288] time 0.200 (0.214) data 0.000 (0.002) loss 1.0053 (1.0642) ce_loss 0.8794 (0.9237) teacher_loss 0.8822 (0.9197) loss_zs_kd 0.1080 (0.1431) loss_oracle 0.0691 (0.0729) acc 78.1250 (74.7545) kd_loss 0.0466 (0.0406) lr 1.2487e-03 eta 0:28:17
epoch [23/50] batch [160/288] time 0.174 (0.212) data 0.000 (0.002) loss 1.0698 (1.0729) ce_loss 0.9282 (0.9334) teacher_loss 0.9301 (0.9294) loss_zs_kd 0.1338 (0.1425) loss_oracle 0.0728 (0.0723) acc 71.8750 (74.3945) kd_loss 0.0437 (0.0407) lr 1.2487e-03 eta 0:27:52
epoch [23/50] batch [180/288] time 0.190 (0.210) data 0.000 (0.002) loss 0.9419 (1.0682) ce_loss 0.8462 (0.9288) teacher_loss 0.8237 (0.9250) loss_zs_kd 0.0900 (0.1419) loss_oracle 0.0732 (0.0722) acc 75.0000 (74.6528) kd_loss 0.0429 (0.0409) lr 1.2487e-03 eta 0:27:35
epoch [23/50] batch [200/288] time 0.193 (0.208) data 0.000 (0.001) loss 0.9657 (1.0699) ce_loss 0.8125 (0.9296) teacher_loss 0.7954 (0.9257) loss_zs_kd 0.1597 (0.1427) loss_oracle 0.0904 (0.0728) acc 75.0000 (74.8438) kd_loss 0.0499 (0.0410) lr 1.2487e-03 eta 0:27:18
epoch [23/50] batch [220/288] time 0.197 (0.207) data 0.000 (0.001) loss 1.2828 (1.0713) ce_loss 1.1602 (0.9310) teacher_loss 1.1520 (0.9272) loss_zs_kd 0.1355 (0.1431) loss_oracle 0.0630 (0.0726) acc 75.0000 (74.8153) kd_loss 0.0343 (0.0409) lr 1.2487e-03 eta 0:27:04
epoch [23/50] batch [240/288] time 0.195 (0.206) data 0.000 (0.001) loss 0.9207 (1.0793) ce_loss 0.7769 (0.9389) teacher_loss 0.7650 (0.9354) loss_zs_kd 0.1509 (0.1423) loss_oracle 0.0801 (0.0728) acc 78.1250 (74.7135) kd_loss 0.0423 (0.0410) lr 1.2487e-03 eta 0:26:51
epoch [23/50] batch [260/288] time 0.194 (0.205) data 0.000 (0.001) loss 0.7824 (1.0878) ce_loss 0.6338 (0.9474) teacher_loss 0.6439 (0.9434) loss_zs_kd 0.1486 (0.1429) loss_oracle 0.0643 (0.0729) acc 84.3750 (74.4471) kd_loss 0.0327 (0.0412) lr 1.2487e-03 eta 0:26:40
epoch [23/50] batch [280/288] time 0.188 (0.204) data 0.000 (0.001) loss 1.0525 (1.0816) ce_loss 0.8809 (0.9412) teacher_loss 0.8790 (0.9374) loss_zs_kd 0.1753 (0.1426) loss_oracle 0.0858 (0.0730) acc 71.8750 (74.5871) kd_loss 0.0487 (0.0413) lr 1.2487e-03 eta 0:26:29
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,431
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,011
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.7%
******* Domain a best val acc:      87.1%, epoch: 23 *******
******* Domain a best val test acc: 82.9%, epoch: 23 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [24/50] batch [20/288] time 0.197 (0.208) data 0.000 (0.013) loss 1.1540 (1.0520) ce_loss 1.0352 (0.9237) teacher_loss 1.0338 (0.9154) loss_zs_kd 0.1198 (0.1309) loss_oracle 0.0603 (0.0711) acc 81.2500 (74.0625) kd_loss 0.0324 (0.0423) lr 1.1874e-03 eta 0:26:57
epoch [24/50] batch [40/288] time 0.195 (0.198) data 0.000 (0.007) loss 1.1442 (1.0971) ce_loss 0.9648 (0.9642) teacher_loss 0.9684 (0.9578) loss_zs_kd 0.1757 (0.1342) loss_oracle 0.0879 (0.0722) acc 75.0000 (73.7500) kd_loss 0.0449 (0.0410) lr 1.1874e-03 eta 0:25:28
epoch [24/50] batch [60/288] time 0.100 (0.190) data 0.000 (0.004) loss 1.0237 (1.1076) ce_loss 0.8989 (0.9700) teacher_loss 0.8945 (0.9644) loss_zs_kd 0.1361 (0.1403) loss_oracle 0.0612 (0.0731) acc 87.5000 (74.1667) kd_loss 0.0335 (0.0408) lr 1.1874e-03 eta 0:24:29
epoch [24/50] batch [80/288] time 0.471 (0.217) data 0.000 (0.003) loss 0.9987 (1.0849) ce_loss 0.8315 (0.9455) teacher_loss 0.8266 (0.9409) loss_zs_kd 0.1663 (0.1390) loss_oracle 0.0890 (0.0745) acc 78.1250 (74.4531) kd_loss 0.0448 (0.0409) lr 1.1874e-03 eta 0:27:48
epoch [24/50] batch [100/288] time 0.219 (0.216) data 0.000 (0.003) loss 0.9656 (1.0829) ce_loss 0.7886 (0.9448) teacher_loss 0.7836 (0.9396) loss_zs_kd 0.1820 (0.1375) loss_oracle 0.0910 (0.0745) acc 84.3750 (74.3750) kd_loss 0.0491 (0.0410) lr 1.1874e-03 eta 0:27:39
epoch [24/50] batch [120/288] time 0.194 (0.213) data 0.000 (0.002) loss 1.0901 (1.0738) ce_loss 0.9648 (0.9368) teacher_loss 0.9688 (0.9311) loss_zs_kd 0.1119 (0.1371) loss_oracle 0.0654 (0.0742) acc 68.7500 (74.7656) kd_loss 0.0379 (0.0410) lr 1.1874e-03 eta 0:27:07
epoch [24/50] batch [140/288] time 0.191 (0.210) data 0.000 (0.002) loss 1.1097 (1.0698) ce_loss 0.9775 (0.9320) teacher_loss 0.9816 (0.9268) loss_zs_kd 0.1152 (0.1389) loss_oracle 0.0705 (0.0735) acc 78.1250 (74.9107) kd_loss 0.0424 (0.0410) lr 1.1874e-03 eta 0:26:42
epoch [24/50] batch [160/288] time 0.197 (0.208) data 0.000 (0.002) loss 1.2112 (1.0756) ce_loss 1.0830 (0.9367) teacher_loss 1.0919 (0.9320) loss_zs_kd 0.1257 (0.1415) loss_oracle 0.0565 (0.0729) acc 65.6250 (74.7461) kd_loss 0.0287 (0.0407) lr 1.1874e-03 eta 0:26:22
epoch [24/50] batch [180/288] time 0.191 (0.206) data 0.000 (0.002) loss 0.9514 (1.0863) ce_loss 0.8340 (0.9477) teacher_loss 0.8216 (0.9434) loss_zs_kd 0.1115 (0.1409) loss_oracle 0.0741 (0.0724) acc 71.8750 (74.3403) kd_loss 0.0390 (0.0407) lr 1.1874e-03 eta 0:26:06
epoch [24/50] batch [200/288] time 0.186 (0.205) data 0.000 (0.001) loss 1.0894 (1.0867) ce_loss 0.9316 (0.9482) teacher_loss 0.9369 (0.9443) loss_zs_kd 0.1235 (0.1407) loss_oracle 0.0907 (0.0721) acc 71.8750 (74.2188) kd_loss 0.0518 (0.0405) lr 1.1874e-03 eta 0:25:51
epoch [24/50] batch [220/288] time 0.196 (0.204) data 0.000 (0.001) loss 0.9041 (1.0864) ce_loss 0.7690 (0.9478) teacher_loss 0.7713 (0.9440) loss_zs_kd 0.1542 (0.1407) loss_oracle 0.0557 (0.0720) acc 78.1250 (74.2614) kd_loss 0.0311 (0.0405) lr 1.1874e-03 eta 0:25:40
epoch [24/50] batch [240/288] time 0.192 (0.203) data 0.000 (0.001) loss 0.9189 (1.0869) ce_loss 0.7759 (0.9482) teacher_loss 0.7792 (0.9443) loss_zs_kd 0.1357 (0.1405) loss_oracle 0.0719 (0.0723) acc 84.3750 (74.2318) kd_loss 0.0461 (0.0406) lr 1.1874e-03 eta 0:25:29
epoch [24/50] batch [260/288] time 0.194 (0.202) data 0.000 (0.001) loss 0.6583 (1.0893) ce_loss 0.5308 (0.9508) teacher_loss 0.5235 (0.9470) loss_zs_kd 0.1492 (0.1402) loss_oracle 0.0601 (0.0722) acc 87.5000 (74.1466) kd_loss 0.0377 (0.0406) lr 1.1874e-03 eta 0:25:20
epoch [24/50] batch [280/288] time 0.199 (0.202) data 0.000 (0.001) loss 1.0125 (1.0924) ce_loss 0.8848 (0.9539) teacher_loss 0.8804 (0.9501) loss_zs_kd 0.1295 (0.1402) loss_oracle 0.0673 (0.0722) acc 75.0000 (74.1071) kd_loss 0.0387 (0.0404) lr 1.1874e-03 eta 0:25:11
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,434
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,019
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 80.0%
******* Domain a best val acc:      87.2%, epoch: 24 *******
******* Domain a best val test acc: 83.2%, epoch: 24 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [25/50] batch [20/288] time 0.082 (0.200) data 0.000 (0.013) loss 1.3921 (1.1041) ce_loss 1.2568 (0.9602) teacher_loss 1.2439 (0.9535) loss_zs_kd 0.1388 (0.1389) loss_oracle 0.0788 (0.0811) acc 65.6250 (74.2188) kd_loss 0.0492 (0.0464) lr 1.1253e-03 eta 0:24:51
epoch [25/50] batch [40/288] time 0.093 (0.208) data 0.000 (0.007) loss 0.7842 (1.1020) ce_loss 0.6655 (0.9589) teacher_loss 0.6590 (0.9528) loss_zs_kd 0.1137 (0.1368) loss_oracle 0.0683 (0.0808) acc 84.3750 (74.7656) kd_loss 0.0360 (0.0443) lr 1.1253e-03 eta 0:25:52
epoch [25/50] batch [60/288] time 0.191 (0.230) data 0.000 (0.004) loss 1.4833 (1.1216) ce_loss 1.3623 (0.9802) teacher_loss 1.3581 (0.9741) loss_zs_kd 0.1317 (0.1349) loss_oracle 0.0593 (0.0801) acc 59.3750 (73.8021) kd_loss 0.0305 (0.0442) lr 1.1253e-03 eta 0:28:25
epoch [25/50] batch [80/288] time 0.196 (0.221) data 0.000 (0.003) loss 1.1683 (1.1191) ce_loss 0.9858 (0.9784) teacher_loss 0.9933 (0.9731) loss_zs_kd 0.2059 (0.1356) loss_oracle 0.0721 (0.0782) acc 78.1250 (74.0234) kd_loss 0.0458 (0.0426) lr 1.1253e-03 eta 0:27:15
epoch [25/50] batch [100/288] time 0.190 (0.215) data 0.000 (0.003) loss 0.9920 (1.1173) ce_loss 0.8228 (0.9740) teacher_loss 0.8298 (0.9694) loss_zs_kd 0.1697 (0.1413) loss_oracle 0.0773 (0.0774) acc 71.8750 (74.1562) kd_loss 0.0444 (0.0424) lr 1.1253e-03 eta 0:26:30
epoch [25/50] batch [120/288] time 0.191 (0.212) data 0.000 (0.002) loss 1.2654 (1.1055) ce_loss 1.1348 (0.9639) teacher_loss 1.1431 (0.9591) loss_zs_kd 0.1188 (0.1399) loss_oracle 0.0628 (0.0765) acc 62.5000 (74.3229) kd_loss 0.0322 (0.0419) lr 1.1253e-03 eta 0:26:00
epoch [25/50] batch [140/288] time 0.201 (0.209) data 0.000 (0.002) loss 0.5227 (1.1038) ce_loss 0.4255 (0.9629) teacher_loss 0.4311 (0.9583) loss_zs_kd 0.1032 (0.1399) loss_oracle 0.0400 (0.0756) acc 87.5000 (74.4196) kd_loss 0.0228 (0.0416) lr 1.1253e-03 eta 0:25:38
epoch [25/50] batch [160/288] time 0.191 (0.207) data 0.000 (0.002) loss 0.9799 (1.0910) ce_loss 0.8423 (0.9509) teacher_loss 0.8407 (0.9466) loss_zs_kd 0.1266 (0.1397) loss_oracle 0.0759 (0.0746) acc 78.1250 (74.6875) kd_loss 0.0428 (0.0411) lr 1.1253e-03 eta 0:25:19
epoch [25/50] batch [180/288] time 0.190 (0.206) data 0.000 (0.002) loss 1.1622 (1.0957) ce_loss 1.0273 (0.9556) teacher_loss 1.0186 (0.9511) loss_zs_kd 0.1458 (0.1400) loss_oracle 0.0707 (0.0747) acc 71.8750 (74.6181) kd_loss 0.0420 (0.0411) lr 1.1253e-03 eta 0:25:04
epoch [25/50] batch [200/288] time 0.200 (0.205) data 0.000 (0.001) loss 0.7963 (1.0922) ce_loss 0.6265 (0.9511) teacher_loss 0.5960 (0.9463) loss_zs_kd 0.1882 (0.1407) loss_oracle 0.1062 (0.0755) acc 84.3750 (74.7188) kd_loss 0.0615 (0.0414) lr 1.1253e-03 eta 0:24:52
epoch [25/50] batch [220/288] time 0.191 (0.204) data 0.000 (0.001) loss 0.9961 (1.0869) ce_loss 0.8110 (0.9449) teacher_loss 0.8160 (0.9396) loss_zs_kd 0.1929 (0.1414) loss_oracle 0.0836 (0.0766) acc 81.2500 (74.7727) kd_loss 0.0432 (0.0420) lr 1.1253e-03 eta 0:24:41
epoch [25/50] batch [240/288] time 0.199 (0.203) data 0.000 (0.001) loss 1.6143 (1.0886) ce_loss 1.4512 (0.9460) teacher_loss 1.4441 (0.9409) loss_zs_kd 0.1417 (0.1419) loss_oracle 0.0994 (0.0767) acc 62.5000 (74.7266) kd_loss 0.0562 (0.0420) lr 1.1253e-03 eta 0:24:32
epoch [25/50] batch [260/288] time 0.197 (0.202) data 0.000 (0.001) loss 0.9594 (1.0871) ce_loss 0.8340 (0.9442) teacher_loss 0.8263 (0.9390) loss_zs_kd 0.1155 (0.1423) loss_oracle 0.0753 (0.0770) acc 78.1250 (74.8077) kd_loss 0.0415 (0.0421) lr 1.1253e-03 eta 0:24:21
epoch [25/50] batch [280/288] time 0.201 (0.202) data 0.000 (0.001) loss 1.1387 (1.0856) ce_loss 1.0029 (0.9424) teacher_loss 0.9893 (0.9372) loss_zs_kd 0.1055 (0.1421) loss_oracle 0.0966 (0.0774) acc 75.0000 (74.9554) kd_loss 0.0474 (0.0423) lr 1.1253e-03 eta 0:24:12
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,418
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.2%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,017
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.8%
******* Domain a best val acc:      87.2%, epoch: 24 *******
******* Domain a best val test acc: 83.2%, epoch: 24 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [26/50] batch [20/288] time 0.197 (0.318) data 0.000 (0.017) loss 0.8046 (0.9547) ce_loss 0.6978 (0.8028) teacher_loss 0.6926 (0.8011) loss_zs_kd 0.0840 (0.1416) loss_oracle 0.0700 (0.0829) acc 75.0000 (78.2812) kd_loss 0.0363 (0.0415) lr 1.0628e-03 eta 0:38:05
epoch [26/50] batch [40/288] time 0.198 (0.257) data 0.000 (0.009) loss 1.1279 (1.0248) ce_loss 1.0244 (0.8750) teacher_loss 1.0308 (0.8727) loss_zs_kd 0.0827 (0.1402) loss_oracle 0.0557 (0.0820) acc 75.0000 (75.4688) kd_loss 0.0286 (0.0420) lr 1.0628e-03 eta 0:30:38
epoch [26/50] batch [60/288] time 0.194 (0.236) data 0.001 (0.006) loss 1.1135 (1.0388) ce_loss 0.9741 (0.8892) teacher_loss 0.9753 (0.8851) loss_zs_kd 0.1269 (0.1419) loss_oracle 0.0747 (0.0828) acc 68.7500 (75.6250) kd_loss 0.0423 (0.0422) lr 1.0628e-03 eta 0:28:04
epoch [26/50] batch [80/288] time 0.203 (0.225) data 0.000 (0.005) loss 1.5296 (1.0481) ce_loss 1.3887 (0.8992) teacher_loss 1.3760 (0.8956) loss_zs_kd 0.1358 (0.1424) loss_oracle 0.0857 (0.0812) acc 71.8750 (75.5078) kd_loss 0.0520 (0.0431) lr 1.0628e-03 eta 0:26:44
epoch [26/50] batch [100/288] time 0.196 (0.219) data 0.000 (0.004) loss 0.8854 (1.0607) ce_loss 0.7739 (0.9131) teacher_loss 0.7665 (0.9100) loss_zs_kd 0.1025 (0.1411) loss_oracle 0.0676 (0.0802) acc 78.1250 (74.9688) kd_loss 0.0458 (0.0431) lr 1.0628e-03 eta 0:25:55
epoch [26/50] batch [120/288] time 0.197 (0.215) data 0.000 (0.003) loss 1.0037 (1.0642) ce_loss 0.8428 (0.9180) teacher_loss 0.8108 (0.9144) loss_zs_kd 0.2151 (0.1403) loss_oracle 0.0853 (0.0796) acc 75.0000 (74.8958) kd_loss 0.0516 (0.0433) lr 1.0628e-03 eta 0:25:22
epoch [26/50] batch [140/288] time 0.190 (0.212) data 0.000 (0.003) loss 1.1247 (1.0597) ce_loss 0.9917 (0.9140) teacher_loss 0.9931 (0.9106) loss_zs_kd 0.1279 (0.1400) loss_oracle 0.0677 (0.0791) acc 78.1250 (75.2455) kd_loss 0.0406 (0.0436) lr 1.0628e-03 eta 0:24:56
epoch [26/50] batch [160/288] time 0.195 (0.210) data 0.000 (0.002) loss 1.2740 (1.0601) ce_loss 1.1133 (0.9140) teacher_loss 1.1169 (0.9103) loss_zs_kd 0.1852 (0.1411) loss_oracle 0.0645 (0.0792) acc 68.7500 (75.1953) kd_loss 0.0311 (0.0438) lr 1.0628e-03 eta 0:24:36
epoch [26/50] batch [180/288] time 0.195 (0.208) data 0.000 (0.002) loss 0.8807 (1.0607) ce_loss 0.7559 (0.9144) teacher_loss 0.7574 (0.9108) loss_zs_kd 0.0989 (0.1408) loss_oracle 0.0739 (0.0795) acc 78.1250 (75.0174) kd_loss 0.0397 (0.0438) lr 1.0628e-03 eta 0:24:19
epoch [26/50] batch [200/288] time 0.191 (0.206) data 0.000 (0.002) loss 1.0430 (1.0652) ce_loss 0.8857 (0.9180) teacher_loss 0.9006 (0.9149) loss_zs_kd 0.1425 (0.1411) loss_oracle 0.0712 (0.0797) acc 84.3750 (74.9688) kd_loss 0.0389 (0.0440) lr 1.0628e-03 eta 0:24:05
epoch [26/50] batch [220/288] time 0.193 (0.205) data 0.000 (0.002) loss 0.4559 (1.0674) ce_loss 0.3223 (0.9197) teacher_loss 0.3181 (0.9164) loss_zs_kd 0.1079 (0.1415) loss_oracle 0.0839 (0.0802) acc 93.7500 (74.8438) kd_loss 0.0476 (0.0443) lr 1.0628e-03 eta 0:23:51
epoch [26/50] batch [240/288] time 0.199 (0.204) data 0.000 (0.002) loss 1.1087 (1.0739) ce_loss 0.9360 (0.9253) teacher_loss 0.9318 (0.9222) loss_zs_kd 0.1677 (0.1422) loss_oracle 0.0931 (0.0806) acc 71.8750 (74.6875) kd_loss 0.0413 (0.0446) lr 1.0628e-03 eta 0:23:41
epoch [26/50] batch [260/288] time 0.084 (0.203) data 0.000 (0.002) loss 1.0788 (1.0833) ce_loss 0.9194 (0.9337) teacher_loss 0.9221 (0.9305) loss_zs_kd 0.1683 (0.1439) loss_oracle 0.0726 (0.0809) acc 75.0000 (74.4471) kd_loss 0.0381 (0.0448) lr 1.0628e-03 eta 0:23:25
epoch [26/50] batch [280/288] time 0.080 (0.203) data 0.000 (0.001) loss 1.2255 (1.0866) ce_loss 1.0420 (0.9367) teacher_loss 1.0518 (0.9335) loss_zs_kd 0.1752 (0.1448) loss_oracle 0.0861 (0.0807) acc 65.6250 (74.4308) kd_loss 0.0582 (0.0448) lr 1.0628e-03 eta 0:23:27
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,431
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,016
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.8%
******* Domain a best val acc:      87.2%, epoch: 24 *******
******* Domain a best val test acc: 83.2%, epoch: 24 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [27/50] batch [20/288] time 0.200 (0.203) data 0.000 (0.012) loss 0.8287 (1.0515) ce_loss 0.6533 (0.8974) teacher_loss 0.6428 (0.8881) loss_zs_kd 0.1759 (0.1580) loss_oracle 0.0979 (0.0845) acc 78.1250 (76.7188) kd_loss 0.0520 (0.0501) lr 1.0000e-03 eta 0:23:19
epoch [27/50] batch [40/288] time 0.189 (0.198) data 0.000 (0.006) loss 0.5463 (1.0928) ce_loss 0.4417 (0.9442) teacher_loss 0.4339 (0.9379) loss_zs_kd 0.0918 (0.1476) loss_oracle 0.0665 (0.0811) acc 93.7500 (75.7031) kd_loss 0.0363 (0.0467) lr 1.0000e-03 eta 0:22:42
epoch [27/50] batch [60/288] time 0.193 (0.197) data 0.000 (0.004) loss 1.5358 (1.0742) ce_loss 1.3398 (0.9275) teacher_loss 1.3284 (0.9211) loss_zs_kd 0.2209 (0.1488) loss_oracle 0.0970 (0.0787) acc 62.5000 (75.6250) kd_loss 0.0599 (0.0451) lr 1.0000e-03 eta 0:22:27
epoch [27/50] batch [80/288] time 0.188 (0.196) data 0.000 (0.003) loss 0.9003 (1.0638) ce_loss 0.7749 (0.9207) teacher_loss 0.7638 (0.9146) loss_zs_kd 0.1488 (0.1444) loss_oracle 0.0620 (0.0769) acc 78.1250 (75.4297) kd_loss 0.0376 (0.0442) lr 1.0000e-03 eta 0:22:17
epoch [27/50] batch [100/288] time 0.192 (0.196) data 0.000 (0.003) loss 0.9601 (1.0733) ce_loss 0.7725 (0.9305) teacher_loss 0.7703 (0.9241) loss_zs_kd 0.1992 (0.1446) loss_oracle 0.0902 (0.0770) acc 81.2500 (75.0312) kd_loss 0.0447 (0.0442) lr 1.0000e-03 eta 0:22:11
epoch [27/50] batch [120/288] time 0.201 (0.195) data 0.000 (0.002) loss 0.8500 (1.0525) ce_loss 0.7305 (0.9113) teacher_loss 0.7056 (0.9045) loss_zs_kd 0.1431 (0.1426) loss_oracle 0.0728 (0.0767) acc 84.3750 (75.7812) kd_loss 0.0468 (0.0439) lr 1.0000e-03 eta 0:22:06
epoch [27/50] batch [140/288] time 0.197 (0.195) data 0.000 (0.002) loss 1.0766 (1.0638) ce_loss 0.9155 (0.9221) teacher_loss 0.8941 (0.9143) loss_zs_kd 0.2229 (0.1448) loss_oracle 0.0711 (0.0771) acc 71.8750 (75.5804) kd_loss 0.0465 (0.0443) lr 1.0000e-03 eta 0:22:00
epoch [27/50] batch [160/288] time 0.189 (0.195) data 0.000 (0.002) loss 1.0901 (1.0627) ce_loss 0.9482 (0.9201) teacher_loss 0.9523 (0.9121) loss_zs_kd 0.1556 (0.1457) loss_oracle 0.0600 (0.0777) acc 68.7500 (75.5664) kd_loss 0.0332 (0.0448) lr 1.0000e-03 eta 0:21:55
epoch [27/50] batch [180/288] time 0.194 (0.195) data 0.000 (0.001) loss 0.8917 (1.0682) ce_loss 0.7446 (0.9243) teacher_loss 0.7406 (0.9171) loss_zs_kd 0.1361 (0.1455) loss_oracle 0.0830 (0.0783) acc 75.0000 (75.4861) kd_loss 0.0423 (0.0448) lr 1.0000e-03 eta 0:21:50
epoch [27/50] batch [200/288] time 0.192 (0.195) data 0.000 (0.001) loss 1.0897 (1.0605) ce_loss 0.9653 (0.9173) teacher_loss 0.9617 (0.9100) loss_zs_kd 0.1044 (0.1445) loss_oracle 0.0758 (0.0782) acc 75.0000 (75.5312) kd_loss 0.0474 (0.0451) lr 1.0000e-03 eta 0:21:46
epoch [27/50] batch [220/288] time 0.197 (0.195) data 0.000 (0.001) loss 1.1334 (1.0594) ce_loss 0.8984 (0.9166) teacher_loss 0.8877 (0.9096) loss_zs_kd 0.2702 (0.1438) loss_oracle 0.1106 (0.0779) acc 81.2500 (75.5824) kd_loss 0.0640 (0.0451) lr 1.0000e-03 eta 0:21:42
epoch [27/50] batch [240/288] time 0.162 (0.200) data 0.000 (0.001) loss 0.7459 (1.0716) ce_loss 0.6289 (0.9290) teacher_loss 0.6188 (0.9222) loss_zs_kd 0.0905 (0.1439) loss_oracle 0.0818 (0.0774) acc 81.2500 (75.0911) kd_loss 0.0381 (0.0449) lr 1.0000e-03 eta 0:22:11
epoch [27/50] batch [260/288] time 0.115 (0.204) data 0.000 (0.001) loss 0.8287 (1.0735) ce_loss 0.6968 (0.9305) teacher_loss 0.6939 (0.9244) loss_zs_kd 0.1143 (0.1439) loss_oracle 0.0776 (0.0772) acc 81.2500 (75.0962) kd_loss 0.0520 (0.0449) lr 1.0000e-03 eta 0:22:36
epoch [27/50] batch [280/288] time 0.194 (0.203) data 0.000 (0.001) loss 1.4539 (1.0777) ce_loss 1.2627 (0.9347) teacher_loss 1.2547 (0.9286) loss_zs_kd 0.2202 (0.1441) loss_oracle 0.0891 (0.0771) acc 50.0000 (74.8884) kd_loss 0.0466 (0.0448) lr 1.0000e-03 eta 0:22:27
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,426
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 86.4%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,009
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 79.6%
******* Domain a best val acc:      87.2%, epoch: 24 *******
******* Domain a best val test acc: 83.2%, epoch: 24 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [28/50] batch [20/288] time 0.199 (0.211) data 0.000 (0.015) loss 0.9060 (1.0485) ce_loss 0.7866 (0.8996) teacher_loss 0.7648 (0.8934) loss_zs_kd 0.1074 (0.1585) loss_oracle 0.0875 (0.0759) acc 78.1250 (75.6250) kd_loss 0.0485 (0.0410) lr 9.3721e-04 eta 0:23:12
epoch [28/50] batch [40/288] time 0.192 (0.202) data 0.000 (0.007) loss 0.7674 (1.0845) ce_loss 0.6079 (0.9412) teacher_loss 0.6119 (0.9358) loss_zs_kd 0.1158 (0.1410) loss_oracle 0.0976 (0.0782) acc 84.3750 (74.5312) kd_loss 0.0443 (0.0423) lr 9.3721e-04 eta 0:22:12
epoch [28/50] batch [60/288] time 0.196 (0.200) data 0.001 (0.005) loss 0.8834 (1.0949) ce_loss 0.7217 (0.9516) teacher_loss 0.7265 (0.9474) loss_zs_kd 0.1669 (0.1412) loss_oracle 0.0734 (0.0770) acc 78.1250 (74.1146) kd_loss 0.0356 (0.0412) lr 9.3721e-04 eta 0:21:51
epoch [28/50] batch [80/288] time 0.194 (0.198) data 0.000 (0.004) loss 0.9034 (1.1062) ce_loss 0.7822 (0.9612) teacher_loss 0.7788 (0.9580) loss_zs_kd 0.1342 (0.1432) loss_oracle 0.0574 (0.0766) acc 68.7500 (73.8281) kd_loss 0.0305 (0.0407) lr 9.3721e-04 eta 0:21:38
epoch [28/50] batch [100/288] time 0.191 (0.197) data 0.000 (0.003) loss 0.9328 (1.0933) ce_loss 0.7925 (0.9476) teacher_loss 0.7982 (0.9454) loss_zs_kd 0.0878 (0.1426) loss_oracle 0.0907 (0.0766) acc 81.2500 (74.2188) kd_loss 0.0480 (0.0408) lr 9.3721e-04 eta 0:21:28
epoch [28/50] batch [120/288] time 0.219 (0.197) data 0.000 (0.003) loss 0.9817 (1.0805) ce_loss 0.8423 (0.9361) teacher_loss 0.8423 (0.9326) loss_zs_kd 0.1066 (0.1399) loss_oracle 0.0860 (0.0780) acc 81.2500 (74.2969) kd_loss 0.0449 (0.0416) lr 9.3721e-04 eta 0:21:20
epoch [28/50] batch [140/288] time 0.193 (0.197) data 0.000 (0.002) loss 0.5614 (1.0753) ce_loss 0.4653 (0.9307) teacher_loss 0.4736 (0.9274) loss_zs_kd 0.0940 (0.1406) loss_oracle 0.0408 (0.0776) acc 90.6250 (74.5759) kd_loss 0.0212 (0.0410) lr 9.3721e-04 eta 0:21:14
epoch [28/50] batch [160/288] time 0.192 (0.196) data 0.000 (0.002) loss 1.3917 (1.0650) ce_loss 1.2334 (0.9205) teacher_loss 1.2342 (0.9170) loss_zs_kd 0.1571 (0.1405) loss_oracle 0.0790 (0.0778) acc 62.5000 (74.8828) kd_loss 0.0348 (0.0409) lr 9.3721e-04 eta 0:21:09
epoch [28/50] batch [180/288] time 0.194 (0.196) data 0.000 (0.002) loss 0.9349 (1.0604) ce_loss 0.7407 (0.9146) teacher_loss 0.7547 (0.9108) loss_zs_kd 0.2064 (0.1419) loss_oracle 0.0771 (0.0787) acc 75.0000 (75.0347) kd_loss 0.0383 (0.0410) lr 9.3721e-04 eta 0:21:03
epoch [28/50] batch [200/288] time 0.443 (0.201) data 0.000 (0.002) loss 1.4790 (1.0696) ce_loss 1.3105 (0.9230) teacher_loss 1.3112 (0.9191) loss_zs_kd 0.1813 (0.1432) loss_oracle 0.0771 (0.0789) acc 71.8750 (75.0000) kd_loss 0.0444 (0.0411) lr 9.3721e-04 eta 0:21:32
epoch [28/50] batch [220/288] time 0.159 (0.206) data 0.000 (0.002) loss 1.0648 (1.0692) ce_loss 0.9419 (0.9222) teacher_loss 0.9385 (0.9181) loss_zs_kd 0.1160 (0.1437) loss_oracle 0.0682 (0.0793) acc 81.2500 (75.1278) kd_loss 0.0354 (0.0415) lr 9.3721e-04 eta 0:22:00
epoch [28/50] batch [240/288] time 0.196 (0.201) data 0.000 (0.001) loss 0.5323 (1.0696) ce_loss 0.3889 (0.9223) teacher_loss 0.3905 (0.9182) loss_zs_kd 0.1236 (0.1440) loss_oracle 0.0801 (0.0794) acc 96.8750 (75.1172) kd_loss 0.0438 (0.0418) lr 9.3721e-04 eta 0:21:25
epoch [28/50] batch [260/288] time 0.193 (0.201) data 0.000 (0.001) loss 0.8148 (1.0732) ce_loss 0.6914 (0.9261) teacher_loss 0.6933 (0.9219) loss_zs_kd 0.1300 (0.1440) loss_oracle 0.0565 (0.0793) acc 81.2500 (75.2043) kd_loss 0.0347 (0.0422) lr 9.3721e-04 eta 0:21:17
epoch [28/50] batch [280/288] time 0.191 (0.200) data 0.000 (0.001) loss 0.9148 (1.0722) ce_loss 0.7739 (0.9248) teacher_loss 0.7783 (0.9204) loss_zs_kd 0.1413 (0.1449) loss_oracle 0.0658 (0.0793) acc 81.2500 (75.2567) kd_loss 0.0387 (0.0426) lr 9.3721e-04 eta 0:21:10
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,428
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 86.4%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,009
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 79.6%
******* Domain a best val acc:      87.2%, epoch: 24 *******
******* Domain a best val test acc: 83.2%, epoch: 24 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [29/50] batch [20/288] time 0.192 (0.217) data 0.000 (0.016) loss 0.8143 (0.9623) ce_loss 0.6519 (0.8189) teacher_loss 0.6494 (0.8143) loss_zs_kd 0.1899 (0.1483) loss_oracle 0.0700 (0.0738) acc 78.1250 (77.5000) kd_loss 0.0474 (0.0450) lr 8.7467e-04 eta 0:22:49
epoch [29/50] batch [40/288] time 0.195 (0.206) data 0.000 (0.008) loss 0.9273 (1.0640) ce_loss 0.8071 (0.9210) teacher_loss 0.8102 (0.9163) loss_zs_kd 0.1175 (0.1428) loss_oracle 0.0584 (0.0763) acc 78.1250 (75.1562) kd_loss 0.0371 (0.0448) lr 8.7467e-04 eta 0:21:39
epoch [29/50] batch [60/288] time 0.196 (0.202) data 0.001 (0.005) loss 1.7899 (1.1010) ce_loss 1.6445 (0.9587) teacher_loss 1.6333 (0.9522) loss_zs_kd 0.1514 (0.1381) loss_oracle 0.0809 (0.0798) acc 62.5000 (74.3750) kd_loss 0.0483 (0.0462) lr 8.7467e-04 eta 0:21:07
epoch [29/50] batch [80/288] time 0.190 (0.200) data 0.000 (0.004) loss 0.8354 (1.1005) ce_loss 0.6636 (0.9549) teacher_loss 0.6568 (0.9490) loss_zs_kd 0.1906 (0.1440) loss_oracle 0.0833 (0.0796) acc 87.5000 (73.8672) kd_loss 0.0492 (0.0459) lr 8.7467e-04 eta 0:20:50
epoch [29/50] batch [100/288] time 0.188 (0.199) data 0.000 (0.003) loss 1.4074 (1.1165) ce_loss 1.2900 (0.9687) teacher_loss 1.2709 (0.9630) loss_zs_kd 0.1544 (0.1469) loss_oracle 0.0593 (0.0800) acc 71.8750 (73.7500) kd_loss 0.0434 (0.0459) lr 8.7467e-04 eta 0:20:39
epoch [29/50] batch [120/288] time 0.195 (0.198) data 0.000 (0.003) loss 0.9635 (1.1009) ce_loss 0.8384 (0.9531) teacher_loss 0.8360 (0.9472) loss_zs_kd 0.1088 (0.1462) loss_oracle 0.0732 (0.0806) acc 75.0000 (74.2708) kd_loss 0.0475 (0.0464) lr 8.7467e-04 eta 0:20:30
epoch [29/50] batch [140/288] time 0.190 (0.197) data 0.000 (0.002) loss 1.1666 (1.0915) ce_loss 1.0303 (0.9439) teacher_loss 1.0312 (0.9383) loss_zs_kd 0.0937 (0.1450) loss_oracle 0.0885 (0.0807) acc 65.6250 (74.4643) kd_loss 0.0517 (0.0462) lr 8.7467e-04 eta 0:20:23
epoch [29/50] batch [160/288] time 0.091 (0.194) data 0.000 (0.002) loss 0.9087 (1.0910) ce_loss 0.7334 (0.9417) teacher_loss 0.7210 (0.9361) loss_zs_kd 0.1714 (0.1464) loss_oracle 0.1020 (0.0817) acc 78.1250 (74.7656) kd_loss 0.0579 (0.0466) lr 8.7467e-04 eta 0:19:59
epoch [29/50] batch [180/288] time 0.469 (0.201) data 0.000 (0.002) loss 1.3373 (1.0992) ce_loss 1.1670 (0.9491) teacher_loss 1.1637 (0.9435) loss_zs_kd 0.1671 (0.1473) loss_oracle 0.0900 (0.0820) acc 62.5000 (74.6875) kd_loss 0.0484 (0.0468) lr 8.7467e-04 eta 0:20:36
epoch [29/50] batch [200/288] time 0.190 (0.205) data 0.000 (0.002) loss 1.3072 (1.0945) ce_loss 1.1191 (0.9440) teacher_loss 1.1092 (0.9385) loss_zs_kd 0.1427 (0.1473) loss_oracle 0.1266 (0.0824) acc 68.7500 (74.7656) kd_loss 0.0679 (0.0468) lr 8.7467e-04 eta 0:20:58
epoch [29/50] batch [220/288] time 0.189 (0.204) data 0.000 (0.002) loss 1.0971 (1.0976) ce_loss 0.9546 (0.9475) teacher_loss 0.9443 (0.9421) loss_zs_kd 0.1687 (0.1462) loss_oracle 0.0684 (0.0824) acc 71.8750 (74.6591) kd_loss 0.0450 (0.0466) lr 8.7467e-04 eta 0:20:48
epoch [29/50] batch [240/288] time 0.196 (0.203) data 0.000 (0.002) loss 0.9829 (1.0980) ce_loss 0.8545 (0.9482) teacher_loss 0.8516 (0.9431) loss_zs_kd 0.1250 (0.1458) loss_oracle 0.0687 (0.0820) acc 78.1250 (74.5443) kd_loss 0.0330 (0.0461) lr 8.7467e-04 eta 0:20:39
epoch [29/50] batch [260/288] time 0.194 (0.203) data 0.000 (0.001) loss 0.9498 (1.0985) ce_loss 0.7754 (0.9483) teacher_loss 0.7738 (0.9433) loss_zs_kd 0.1840 (0.1466) loss_oracle 0.0841 (0.0819) acc 75.0000 (74.6274) kd_loss 0.0423 (0.0457) lr 8.7467e-04 eta 0:20:30
epoch [29/50] batch [280/288] time 0.194 (0.202) data 0.000 (0.001) loss 1.6020 (1.0992) ce_loss 1.4463 (0.9488) teacher_loss 1.4446 (0.9439) loss_zs_kd 0.1431 (0.1472) loss_oracle 0.0859 (0.0817) acc 59.3750 (74.5759) kd_loss 0.0426 (0.0455) lr 8.7467e-04 eta 0:20:22
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,433
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,013
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.7%
******* Domain a best val acc:      87.2%, epoch: 24 *******
******* Domain a best val test acc: 83.2%, epoch: 24 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [30/50] batch [20/288] time 0.192 (0.210) data 0.000 (0.015) loss 0.8497 (1.0524) ce_loss 0.6953 (0.9064) teacher_loss 0.6929 (0.9022) loss_zs_kd 0.1445 (0.1450) loss_oracle 0.0846 (0.0777) acc 75.0000 (73.5938) kd_loss 0.0471 (0.0437) lr 8.1262e-04 eta 0:21:06
epoch [30/50] batch [40/288] time 0.195 (0.202) data 0.000 (0.008) loss 1.0077 (0.9943) ce_loss 0.8770 (0.8508) teacher_loss 0.8714 (0.8475) loss_zs_kd 0.1242 (0.1422) loss_oracle 0.0741 (0.0757) acc 68.7500 (75.4688) kd_loss 0.0417 (0.0433) lr 8.1262e-04 eta 0:20:15
epoch [30/50] batch [60/288] time 0.199 (0.200) data 0.000 (0.005) loss 1.2797 (1.0343) ce_loss 1.0898 (0.8865) teacher_loss 1.0840 (0.8833) loss_zs_kd 0.2097 (0.1452) loss_oracle 0.0909 (0.0784) acc 68.7500 (75.3125) kd_loss 0.0531 (0.0444) lr 8.1262e-04 eta 0:19:59
epoch [30/50] batch [80/288] time 0.190 (0.199) data 0.000 (0.004) loss 0.9729 (1.0517) ce_loss 0.8369 (0.9045) teacher_loss 0.8172 (0.9007) loss_zs_kd 0.1362 (0.1447) loss_oracle 0.0876 (0.0787) acc 75.0000 (75.1172) kd_loss 0.0503 (0.0446) lr 8.1262e-04 eta 0:19:45
epoch [30/50] batch [100/288] time 0.222 (0.198) data 0.000 (0.003) loss 0.6896 (1.0678) ce_loss 0.5703 (0.9217) teacher_loss 0.5717 (0.9168) loss_zs_kd 0.1158 (0.1438) loss_oracle 0.0600 (0.0791) acc 87.5000 (74.7188) kd_loss 0.0492 (0.0450) lr 8.1262e-04 eta 0:19:39
epoch [30/50] batch [120/288] time 0.193 (0.198) data 0.000 (0.003) loss 1.1743 (1.0776) ce_loss 1.0430 (0.9317) teacher_loss 1.0450 (0.9274) loss_zs_kd 0.1067 (0.1438) loss_oracle 0.0760 (0.0783) acc 71.8750 (74.5573) kd_loss 0.0393 (0.0448) lr 8.1262e-04 eta 0:19:32
epoch [30/50] batch [140/288] time 0.084 (0.202) data 0.000 (0.002) loss 1.3485 (1.0938) ce_loss 1.2578 (0.9477) teacher_loss 1.2294 (0.9434) loss_zs_kd 0.0925 (0.1450) loss_oracle 0.0729 (0.0778) acc 56.2500 (74.3080) kd_loss 0.0427 (0.0447) lr 8.1262e-04 eta 0:19:54
epoch [30/50] batch [160/288] time 0.181 (0.211) data 0.000 (0.002) loss 0.8516 (1.0896) ce_loss 0.7163 (0.9442) teacher_loss 0.6917 (0.9396) loss_zs_kd 0.1398 (0.1454) loss_oracle 0.0900 (0.0773) acc 78.1250 (74.5312) kd_loss 0.0564 (0.0443) lr 8.1262e-04 eta 0:20:40
epoch [30/50] batch [180/288] time 0.193 (0.208) data 0.000 (0.002) loss 1.2263 (1.0998) ce_loss 1.0869 (0.9549) teacher_loss 1.0869 (0.9502) loss_zs_kd 0.1403 (0.1453) loss_oracle 0.0693 (0.0769) acc 75.0000 (74.1667) kd_loss 0.0369 (0.0443) lr 8.1262e-04 eta 0:20:21
epoch [30/50] batch [200/288] time 0.195 (0.207) data 0.000 (0.002) loss 1.3221 (1.0956) ce_loss 1.2139 (0.9514) teacher_loss 1.1759 (0.9464) loss_zs_kd 0.1525 (0.1452) loss_oracle 0.0699 (0.0766) acc 65.6250 (74.2500) kd_loss 0.0425 (0.0441) lr 8.1262e-04 eta 0:20:09
epoch [30/50] batch [220/288] time 0.191 (0.206) data 0.000 (0.002) loss 1.1665 (1.0951) ce_loss 1.0020 (0.9509) teacher_loss 1.0077 (0.9458) loss_zs_kd 0.1490 (0.1455) loss_oracle 0.0842 (0.0766) acc 68.7500 (74.1761) kd_loss 0.0386 (0.0440) lr 8.1262e-04 eta 0:19:58
epoch [30/50] batch [240/288] time 0.197 (0.205) data 0.000 (0.001) loss 0.7722 (1.0971) ce_loss 0.6377 (0.9533) teacher_loss 0.6257 (0.9480) loss_zs_kd 0.1322 (0.1450) loss_oracle 0.0803 (0.0766) acc 84.3750 (74.1927) kd_loss 0.0467 (0.0441) lr 8.1262e-04 eta 0:19:48
epoch [30/50] batch [260/288] time 0.190 (0.204) data 0.000 (0.001) loss 0.8595 (1.1048) ce_loss 0.7046 (0.9609) teacher_loss 0.6865 (0.9555) loss_zs_kd 0.1320 (0.1448) loss_oracle 0.1069 (0.0769) acc 84.3750 (74.1587) kd_loss 0.0658 (0.0443) lr 8.1262e-04 eta 0:19:40
epoch [30/50] batch [280/288] time 0.192 (0.203) data 0.000 (0.001) loss 0.8291 (1.0966) ce_loss 0.7144 (0.9534) teacher_loss 0.7034 (0.9480) loss_zs_kd 0.1188 (0.1440) loss_oracle 0.0663 (0.0766) acc 78.1250 (74.4196) kd_loss 0.0466 (0.0441) lr 8.1262e-04 eta 0:19:31
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,427
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 86.4%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,016
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.8%
******* Domain a best val acc:      87.2%, epoch: 24 *******
******* Domain a best val test acc: 83.2%, epoch: 24 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [31/50] batch [20/288] time 0.193 (0.207) data 0.000 (0.013) loss 0.4905 (1.0264) ce_loss 0.3718 (0.8758) teacher_loss 0.3798 (0.8714) loss_zs_kd 0.1169 (0.1583) loss_oracle 0.0524 (0.0759) acc 90.6250 (75.9375) kd_loss 0.0347 (0.0412) lr 7.5131e-04 eta 0:19:47
epoch [31/50] batch [40/288] time 0.193 (0.201) data 0.000 (0.006) loss 0.8166 (1.0839) ce_loss 0.6543 (0.9347) teacher_loss 0.6636 (0.9316) loss_zs_kd 0.1464 (0.1485) loss_oracle 0.0798 (0.0781) acc 87.5000 (75.0781) kd_loss 0.0425 (0.0422) lr 7.5131e-04 eta 0:19:07
epoch [31/50] batch [60/288] time 0.200 (0.198) data 0.000 (0.004) loss 1.0799 (1.0939) ce_loss 0.9238 (0.9472) teacher_loss 0.9232 (0.9427) loss_zs_kd 0.1516 (0.1445) loss_oracle 0.0808 (0.0790) acc 75.0000 (74.6875) kd_loss 0.0389 (0.0428) lr 7.5131e-04 eta 0:18:51
epoch [31/50] batch [80/288] time 0.199 (0.197) data 0.000 (0.003) loss 0.9972 (1.0748) ce_loss 0.8633 (0.9278) teacher_loss 0.8505 (0.9225) loss_zs_kd 0.1195 (0.1456) loss_oracle 0.0869 (0.0795) acc 81.2500 (74.8047) kd_loss 0.0520 (0.0430) lr 7.5131e-04 eta 0:18:41
epoch [31/50] batch [100/288] time 0.485 (0.206) data 0.000 (0.003) loss 1.1549 (1.0621) ce_loss 0.9712 (0.9158) teacher_loss 0.9813 (0.9107) loss_zs_kd 0.2143 (0.1449) loss_oracle 0.0665 (0.0790) acc 75.0000 (75.2188) kd_loss 0.0382 (0.0432) lr 7.5131e-04 eta 0:19:26
epoch [31/50] batch [120/288] time 0.108 (0.216) data 0.000 (0.002) loss 0.6542 (1.0679) ce_loss 0.5107 (0.9208) teacher_loss 0.4890 (0.9153) loss_zs_kd 0.1198 (0.1476) loss_oracle 0.1053 (0.0788) acc 87.5000 (75.2865) kd_loss 0.0646 (0.0437) lr 7.5131e-04 eta 0:20:20
epoch [31/50] batch [140/288] time 0.198 (0.213) data 0.000 (0.002) loss 0.8591 (1.0664) ce_loss 0.7070 (0.9196) teacher_loss 0.6998 (0.9141) loss_zs_kd 0.1707 (0.1474) loss_oracle 0.0739 (0.0786) acc 81.2500 (75.4018) kd_loss 0.0377 (0.0439) lr 7.5131e-04 eta 0:19:57
epoch [31/50] batch [160/288] time 0.186 (0.211) data 0.000 (0.002) loss 0.9453 (1.0726) ce_loss 0.7949 (0.9260) teacher_loss 0.7938 (0.9205) loss_zs_kd 0.1680 (0.1470) loss_oracle 0.0675 (0.0786) acc 81.2500 (75.2148) kd_loss 0.0553 (0.0447) lr 7.5131e-04 eta 0:19:39
epoch [31/50] batch [180/288] time 0.191 (0.208) data 0.000 (0.002) loss 1.3535 (1.0745) ce_loss 1.2139 (0.9294) teacher_loss 1.2029 (0.9237) loss_zs_kd 0.1323 (0.1451) loss_oracle 0.0844 (0.0782) acc 68.7500 (75.0521) kd_loss 0.0510 (0.0447) lr 7.5131e-04 eta 0:19:22
epoch [31/50] batch [200/288] time 0.199 (0.206) data 0.000 (0.001) loss 1.0346 (1.0763) ce_loss 0.8965 (0.9308) teacher_loss 0.8948 (0.9248) loss_zs_kd 0.1230 (0.1456) loss_oracle 0.0784 (0.0787) acc 81.2500 (75.0469) kd_loss 0.0452 (0.0452) lr 7.5131e-04 eta 0:19:08
epoch [31/50] batch [220/288] time 0.193 (0.205) data 0.000 (0.001) loss 1.1184 (1.0808) ce_loss 0.9805 (0.9348) teacher_loss 0.9571 (0.9288) loss_zs_kd 0.1540 (0.1452) loss_oracle 0.0843 (0.0794) acc 71.8750 (75.0852) kd_loss 0.0445 (0.0458) lr 7.5131e-04 eta 0:18:58
epoch [31/50] batch [240/288] time 0.190 (0.204) data 0.000 (0.001) loss 1.0560 (1.0790) ce_loss 0.9248 (0.9330) teacher_loss 0.9277 (0.9269) loss_zs_kd 0.1371 (0.1450) loss_oracle 0.0598 (0.0797) acc 75.0000 (75.0781) kd_loss 0.0331 (0.0463) lr 7.5131e-04 eta 0:18:48
epoch [31/50] batch [260/288] time 0.193 (0.204) data 0.000 (0.001) loss 0.7065 (1.0793) ce_loss 0.5967 (0.9343) teacher_loss 0.5954 (0.9283) loss_zs_kd 0.0790 (0.1437) loss_oracle 0.0716 (0.0792) acc 87.5000 (75.0601) kd_loss 0.0440 (0.0462) lr 7.5131e-04 eta 0:18:40
epoch [31/50] batch [280/288] time 0.192 (0.203) data 0.000 (0.001) loss 0.9207 (1.0706) ce_loss 0.8198 (0.9264) teacher_loss 0.8155 (0.9204) loss_zs_kd 0.0933 (0.1424) loss_oracle 0.0586 (0.0790) acc 84.3750 (75.4129) kd_loss 0.0406 (0.0463) lr 7.5131e-04 eta 0:18:32
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,419
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.2%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,015
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 79.8%
******* Domain a best val acc:      87.2%, epoch: 24 *******
******* Domain a best val test acc: 83.2%, epoch: 24 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [32/50] batch [20/288] time 0.198 (0.214) data 0.000 (0.016) loss 1.0218 (1.0958) ce_loss 0.9111 (0.9523) teacher_loss 0.9145 (0.9453) loss_zs_kd 0.0897 (0.1366) loss_oracle 0.0625 (0.0822) acc 78.1250 (75.1562) kd_loss 0.0377 (0.0494) lr 6.9098e-04 eta 0:19:29
epoch [32/50] batch [40/288] time 0.193 (0.204) data 0.000 (0.008) loss 0.5939 (1.0890) ce_loss 0.4832 (0.9464) teacher_loss 0.4762 (0.9376) loss_zs_kd 0.0777 (0.1428) loss_oracle 0.0789 (0.0800) acc 90.6250 (75.7031) kd_loss 0.0449 (0.0484) lr 6.9098e-04 eta 0:18:29
epoch [32/50] batch [60/288] time 0.233 (0.218) data 0.000 (0.006) loss 0.9755 (1.1042) ce_loss 0.8262 (0.9613) teacher_loss 0.8083 (0.9520) loss_zs_kd 0.1698 (0.1467) loss_oracle 0.0823 (0.0789) acc 78.1250 (74.9479) kd_loss 0.0416 (0.0477) lr 6.9098e-04 eta 0:19:41
epoch [32/50] batch [80/288] time 0.083 (0.228) data 0.000 (0.004) loss 1.5397 (1.0797) ce_loss 1.4287 (0.9376) teacher_loss 1.4290 (0.9279) loss_zs_kd 0.1143 (0.1468) loss_oracle 0.0536 (0.0784) acc 62.5000 (75.3516) kd_loss 0.0255 (0.0474) lr 6.9098e-04 eta 0:20:31
epoch [32/50] batch [100/288] time 0.190 (0.218) data 0.000 (0.003) loss 0.6199 (1.0803) ce_loss 0.4644 (0.9383) teacher_loss 0.4438 (0.9288) loss_zs_kd 0.1438 (0.1445) loss_oracle 0.1042 (0.0793) acc 87.5000 (75.5000) kd_loss 0.0629 (0.0483) lr 6.9098e-04 eta 0:19:32
epoch [32/50] batch [120/288] time 0.194 (0.214) data 0.000 (0.003) loss 0.7021 (1.0776) ce_loss 0.6016 (0.9353) teacher_loss 0.5750 (0.9264) loss_zs_kd 0.1098 (0.1449) loss_oracle 0.0722 (0.0787) acc 78.1250 (75.2865) kd_loss 0.0410 (0.0479) lr 6.9098e-04 eta 0:19:06
epoch [32/50] batch [140/288] time 0.194 (0.211) data 0.000 (0.003) loss 1.0777 (1.0758) ce_loss 0.9141 (0.9343) teacher_loss 0.9067 (0.9254) loss_zs_kd 0.2087 (0.1450) loss_oracle 0.0666 (0.0780) acc 78.1250 (75.1786) kd_loss 0.0422 (0.0475) lr 6.9098e-04 eta 0:18:47
epoch [32/50] batch [160/288] time 0.199 (0.209) data 0.000 (0.002) loss 0.8468 (1.0718) ce_loss 0.7163 (0.9310) teacher_loss 0.6919 (0.9223) loss_zs_kd 0.1557 (0.1441) loss_oracle 0.0771 (0.0774) acc 78.1250 (75.0586) kd_loss 0.0494 (0.0473) lr 6.9098e-04 eta 0:18:31
epoch [32/50] batch [180/288] time 0.192 (0.208) data 0.000 (0.002) loss 1.0373 (1.0812) ce_loss 0.8818 (0.9400) teacher_loss 0.8734 (0.9320) loss_zs_kd 0.1563 (0.1447) loss_oracle 0.0858 (0.0768) acc 71.8750 (74.6354) kd_loss 0.0545 (0.0468) lr 6.9098e-04 eta 0:18:18
epoch [32/50] batch [200/288] time 0.191 (0.206) data 0.000 (0.002) loss 1.0751 (1.0776) ce_loss 0.9131 (0.9369) teacher_loss 0.9138 (0.9294) loss_zs_kd 0.1616 (0.1442) loss_oracle 0.0805 (0.0762) acc 75.0000 (74.7344) kd_loss 0.0505 (0.0464) lr 6.9098e-04 eta 0:18:07
epoch [32/50] batch [220/288] time 0.187 (0.205) data 0.000 (0.002) loss 0.8810 (1.0826) ce_loss 0.7593 (0.9421) teacher_loss 0.7588 (0.9349) loss_zs_kd 0.0997 (0.1434) loss_oracle 0.0724 (0.0760) acc 71.8750 (74.6307) kd_loss 0.0455 (0.0462) lr 6.9098e-04 eta 0:17:57
epoch [32/50] batch [240/288] time 0.196 (0.204) data 0.000 (0.002) loss 1.0488 (1.0756) ce_loss 0.9243 (0.9354) teacher_loss 0.9353 (0.9283) loss_zs_kd 0.1117 (0.1426) loss_oracle 0.0576 (0.0760) acc 78.1250 (74.8568) kd_loss 0.0300 (0.0460) lr 6.9098e-04 eta 0:17:48
epoch [32/50] batch [260/288] time 0.159 (0.204) data 0.000 (0.001) loss 1.0443 (1.0816) ce_loss 0.9180 (0.9412) teacher_loss 0.9001 (0.9340) loss_zs_kd 0.1030 (0.1429) loss_oracle 0.0927 (0.0761) acc 78.1250 (74.7236) kd_loss 0.0482 (0.0459) lr 6.9098e-04 eta 0:17:40
epoch [32/50] batch [280/288] time 0.202 (0.203) data 0.000 (0.001) loss 0.8790 (1.0801) ce_loss 0.7637 (0.9397) teacher_loss 0.7466 (0.9329) loss_zs_kd 0.1221 (0.1429) loss_oracle 0.0714 (0.0758) acc 71.8750 (74.6875) kd_loss 0.0421 (0.0455) lr 6.9098e-04 eta 0:17:33
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,430
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.9%
******* Domain a best val acc:      87.2%, epoch: 24 *******
******* Domain a best val test acc: 83.2%, epoch: 24 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [33/50] batch [20/288] time 0.556 (0.232) data 0.000 (0.015) loss 1.1587 (1.1280) ce_loss 1.0254 (0.9829) teacher_loss 1.0319 (0.9784) loss_zs_kd 0.1346 (0.1505) loss_oracle 0.0595 (0.0743) acc 81.2500 (74.0625) kd_loss 0.0332 (0.0445) lr 6.3188e-04 eta 0:19:57
epoch [33/50] batch [40/288] time 0.092 (0.266) data 0.000 (0.008) loss 1.1532 (1.1393) ce_loss 1.0273 (0.9962) teacher_loss 1.0271 (0.9906) loss_zs_kd 0.1396 (0.1471) loss_oracle 0.0563 (0.0751) acc 75.0000 (73.5156) kd_loss 0.0340 (0.0451) lr 6.3188e-04 eta 0:22:48
epoch [33/50] batch [60/288] time 0.191 (0.242) data 0.000 (0.005) loss 1.0422 (1.1219) ce_loss 0.8955 (0.9798) teacher_loss 0.9122 (0.9731) loss_zs_kd 0.1470 (0.1467) loss_oracle 0.0565 (0.0754) acc 75.0000 (73.8542) kd_loss 0.0312 (0.0452) lr 6.3188e-04 eta 0:20:40
epoch [33/50] batch [80/288] time 0.193 (0.230) data 0.001 (0.004) loss 0.8910 (1.1184) ce_loss 0.7686 (0.9759) teacher_loss 0.7718 (0.9693) loss_zs_kd 0.1067 (0.1445) loss_oracle 0.0658 (0.0768) acc 84.3750 (74.1797) kd_loss 0.0410 (0.0462) lr 6.3188e-04 eta 0:19:33
epoch [33/50] batch [100/288] time 0.193 (0.223) data 0.000 (0.003) loss 0.9803 (1.0998) ce_loss 0.8467 (0.9551) teacher_loss 0.8490 (0.9494) loss_zs_kd 0.1135 (0.1471) loss_oracle 0.0745 (0.0769) acc 81.2500 (74.6562) kd_loss 0.0496 (0.0464) lr 6.3188e-04 eta 0:18:53
epoch [33/50] batch [120/288] time 0.195 (0.218) data 0.000 (0.003) loss 1.7401 (1.0992) ce_loss 1.6025 (0.9543) teacher_loss 1.5967 (0.9491) loss_zs_kd 0.1303 (0.1464) loss_oracle 0.0783 (0.0769) acc 56.2500 (74.8177) kd_loss 0.0487 (0.0466) lr 6.3188e-04 eta 0:18:24
epoch [33/50] batch [140/288] time 0.194 (0.215) data 0.000 (0.002) loss 1.1816 (1.0945) ce_loss 1.0293 (0.9499) teacher_loss 1.0349 (0.9450) loss_zs_kd 0.1620 (0.1462) loss_oracle 0.0658 (0.0764) acc 75.0000 (74.9107) kd_loss 0.0353 (0.0465) lr 6.3188e-04 eta 0:18:03
epoch [33/50] batch [160/288] time 0.194 (0.212) data 0.000 (0.002) loss 1.1875 (1.0906) ce_loss 1.0029 (0.9458) teacher_loss 0.9963 (0.9409) loss_zs_kd 0.1880 (0.1454) loss_oracle 0.0972 (0.0770) acc 65.6250 (74.9219) kd_loss 0.0560 (0.0468) lr 6.3188e-04 eta 0:17:45
epoch [33/50] batch [180/288] time 0.194 (0.210) data 0.000 (0.002) loss 1.2541 (1.0904) ce_loss 1.1094 (0.9453) teacher_loss 1.1106 (0.9400) loss_zs_kd 0.1530 (0.1448) loss_oracle 0.0670 (0.0780) acc 68.7500 (74.9479) kd_loss 0.0451 (0.0475) lr 6.3188e-04 eta 0:17:30
epoch [33/50] batch [200/288] time 0.196 (0.208) data 0.000 (0.002) loss 1.1362 (1.0866) ce_loss 1.0039 (0.9414) teacher_loss 0.9943 (0.9361) loss_zs_kd 0.1115 (0.1445) loss_oracle 0.0862 (0.0782) acc 71.8750 (75.0156) kd_loss 0.0519 (0.0480) lr 6.3188e-04 eta 0:17:18
epoch [33/50] batch [220/288] time 0.193 (0.207) data 0.000 (0.002) loss 1.1646 (1.0839) ce_loss 1.0820 (0.9387) teacher_loss 1.0876 (0.9335) loss_zs_kd 0.0652 (0.1448) loss_oracle 0.0443 (0.0780) acc 71.8750 (75.0426) kd_loss 0.0228 (0.0479) lr 6.3188e-04 eta 0:17:08
epoch [33/50] batch [240/288] time 0.193 (0.206) data 0.000 (0.001) loss 0.7635 (1.0752) ce_loss 0.5898 (0.9293) teacher_loss 0.5976 (0.9242) loss_zs_kd 0.1639 (0.1454) loss_oracle 0.0839 (0.0783) acc 81.2500 (75.2734) kd_loss 0.0463 (0.0480) lr 6.3188e-04 eta 0:16:58
epoch [33/50] batch [260/288] time 0.196 (0.205) data 0.000 (0.001) loss 1.0579 (1.0821) ce_loss 0.9463 (0.9360) teacher_loss 0.9478 (0.9307) loss_zs_kd 0.0991 (0.1453) loss_oracle 0.0605 (0.0787) acc 81.2500 (75.1562) kd_loss 0.0389 (0.0483) lr 6.3188e-04 eta 0:16:50
epoch [33/50] batch [280/288] time 0.195 (0.204) data 0.000 (0.001) loss 0.9996 (1.0829) ce_loss 0.8584 (0.9363) teacher_loss 0.8682 (0.9307) loss_zs_kd 0.1232 (0.1459) loss_oracle 0.0698 (0.0792) acc 81.2500 (75.0670) kd_loss 0.0436 (0.0486) lr 6.3188e-04 eta 0:16:42
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,432
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,012
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.8%
******* Domain a best val acc:      87.2%, epoch: 24 *******
******* Domain a best val test acc: 83.2%, epoch: 24 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [34/50] batch [20/288] time 0.193 (0.209) data 0.000 (0.013) loss 1.3309 (0.9883) ce_loss 1.1885 (0.8400) teacher_loss 1.1561 (0.8403) loss_zs_kd 0.1706 (0.1486) loss_oracle 0.0895 (0.0737) acc 71.8750 (78.1250) kd_loss 0.0547 (0.0459) lr 5.7422e-04 eta 0:16:58
epoch [34/50] batch [40/288] time 0.195 (0.201) data 0.000 (0.007) loss 0.9446 (1.0446) ce_loss 0.8267 (0.9033) teacher_loss 0.8189 (0.8981) loss_zs_kd 0.0970 (0.1443) loss_oracle 0.0773 (0.0743) acc 78.1250 (75.3125) kd_loss 0.0462 (0.0471) lr 5.7422e-04 eta 0:16:16
epoch [34/50] batch [60/288] time 0.170 (0.198) data 0.001 (0.004) loss 0.9110 (1.0508) ce_loss 0.8032 (0.9103) teacher_loss 0.8028 (0.9044) loss_zs_kd 0.0887 (0.1420) loss_oracle 0.0639 (0.0754) acc 78.1250 (75.1042) kd_loss 0.0438 (0.0482) lr 5.7422e-04 eta 0:15:58
epoch [34/50] batch [80/288] time 0.195 (0.198) data 0.000 (0.003) loss 1.0512 (1.0548) ce_loss 0.9175 (0.9142) teacher_loss 0.9172 (0.9093) loss_zs_kd 0.1720 (0.1420) loss_oracle 0.0480 (0.0745) acc 78.1250 (75.4688) kd_loss 0.0316 (0.0473) lr 5.7422e-04 eta 0:15:51
epoch [34/50] batch [100/288] time 0.195 (0.197) data 0.000 (0.003) loss 1.2223 (1.0434) ce_loss 1.0635 (0.9015) teacher_loss 1.0572 (0.8965) loss_zs_kd 0.1784 (0.1421) loss_oracle 0.0759 (0.0758) acc 71.8750 (75.8125) kd_loss 0.0485 (0.0478) lr 5.7422e-04 eta 0:15:44
epoch [34/50] batch [120/288] time 0.186 (0.196) data 0.000 (0.002) loss 1.0901 (1.0560) ce_loss 0.9258 (0.9127) teacher_loss 0.9303 (0.9080) loss_zs_kd 0.1297 (0.1420) loss_oracle 0.0949 (0.0770) acc 71.8750 (75.5469) kd_loss 0.0593 (0.0479) lr 5.7422e-04 eta 0:15:37
epoch [34/50] batch [140/288] time 0.189 (0.196) data 0.000 (0.002) loss 1.1644 (1.0519) ce_loss 1.0498 (0.9079) teacher_loss 1.0318 (0.9029) loss_zs_kd 0.1305 (0.1430) loss_oracle 0.0673 (0.0774) acc 65.6250 (75.7143) kd_loss 0.0373 (0.0478) lr 5.7422e-04 eta 0:15:32
epoch [34/50] batch [160/288] time 0.197 (0.196) data 0.000 (0.002) loss 0.7324 (1.0526) ce_loss 0.5752 (0.9072) teacher_loss 0.5812 (0.9023) loss_zs_kd 0.1530 (0.1447) loss_oracle 0.0748 (0.0779) acc 84.3750 (75.6250) kd_loss 0.0382 (0.0476) lr 5.7422e-04 eta 0:15:27
epoch [34/50] batch [180/288] time 0.194 (0.196) data 0.000 (0.002) loss 1.0521 (1.0588) ce_loss 0.8804 (0.9122) teacher_loss 0.8736 (0.9070) loss_zs_kd 0.1532 (0.1466) loss_oracle 0.1019 (0.0786) acc 75.0000 (75.3819) kd_loss 0.0632 (0.0478) lr 5.7422e-04 eta 0:15:22
epoch [34/50] batch [200/288] time 0.196 (0.196) data 0.000 (0.001) loss 1.5455 (1.0719) ce_loss 1.4033 (0.9252) teacher_loss 1.4060 (0.9199) loss_zs_kd 0.1613 (0.1465) loss_oracle 0.0589 (0.0788) acc 65.6250 (75.1719) kd_loss 0.0354 (0.0476) lr 5.7422e-04 eta 0:15:18
epoch [34/50] batch [220/288] time 0.191 (0.195) data 0.000 (0.001) loss 1.1738 (1.0741) ce_loss 1.0352 (0.9272) teacher_loss 1.0188 (0.9215) loss_zs_kd 0.1222 (0.1471) loss_oracle 0.0938 (0.0791) acc 68.7500 (75.1847) kd_loss 0.0621 (0.0475) lr 5.7422e-04 eta 0:15:13
epoch [34/50] batch [240/288] time 0.190 (0.195) data 0.000 (0.001) loss 1.1500 (1.0812) ce_loss 0.9922 (0.9340) teacher_loss 0.9771 (0.9281) loss_zs_kd 0.1535 (0.1477) loss_oracle 0.0961 (0.0792) acc 68.7500 (75.0911) kd_loss 0.0571 (0.0473) lr 5.7422e-04 eta 0:15:09
epoch [34/50] batch [260/288] time 0.483 (0.193) data 0.000 (0.001) loss 0.9417 (1.0779) ce_loss 0.7910 (0.9316) teacher_loss 0.7852 (0.9255) loss_zs_kd 0.1578 (0.1475) loss_oracle 0.0776 (0.0787) acc 81.2500 (75.2163) kd_loss 0.0427 (0.0468) lr 5.7422e-04 eta 0:14:55
epoch [34/50] batch [280/288] time 0.470 (0.199) data 0.000 (0.001) loss 1.2541 (1.0739) ce_loss 1.0938 (0.9284) teacher_loss 1.0725 (0.9225) loss_zs_kd 0.2030 (0.1464) loss_oracle 0.0802 (0.0781) acc 68.7500 (75.2679) kd_loss 0.0443 (0.0464) lr 5.7422e-04 eta 0:15:18
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,436
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,013
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.8%
******* Domain a best val acc:      87.2%, epoch: 34 *******
******* Domain a best val test acc: 82.9%, epoch: 34 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [35/50] batch [20/288] time 0.197 (0.206) data 0.000 (0.013) loss 1.4233 (1.1599) ce_loss 1.2529 (1.0063) teacher_loss 1.2435 (0.9988) loss_zs_kd 0.1699 (0.1542) loss_oracle 0.0949 (0.0840) acc 71.8750 (73.2812) kd_loss 0.0541 (0.0473) lr 5.1825e-04 eta 0:15:47
epoch [35/50] batch [40/288] time 0.196 (0.200) data 0.000 (0.006) loss 1.1924 (1.1812) ce_loss 1.0527 (1.0276) teacher_loss 1.0676 (1.0209) loss_zs_kd 0.1144 (0.1549) loss_oracle 0.0677 (0.0828) acc 71.8750 (72.5000) kd_loss 0.0338 (0.0472) lr 5.1825e-04 eta 0:15:13
epoch [35/50] batch [60/288] time 0.187 (0.198) data 0.000 (0.004) loss 1.5126 (1.1483) ce_loss 1.4004 (0.9987) teacher_loss 1.3570 (0.9925) loss_zs_kd 0.1391 (0.1495) loss_oracle 0.0861 (0.0811) acc 71.8750 (74.0104) kd_loss 0.0478 (0.0462) lr 5.1825e-04 eta 0:14:59
epoch [35/50] batch [80/288] time 0.193 (0.197) data 0.000 (0.003) loss 1.1475 (1.1458) ce_loss 1.0117 (0.9963) teacher_loss 1.0027 (0.9911) loss_zs_kd 0.1686 (0.1467) loss_oracle 0.0605 (0.0813) acc 71.8750 (73.8672) kd_loss 0.0387 (0.0468) lr 5.1825e-04 eta 0:14:51
epoch [35/50] batch [100/288] time 0.199 (0.196) data 0.000 (0.003) loss 1.2720 (1.1391) ce_loss 1.1416 (0.9901) teacher_loss 1.1417 (0.9851) loss_zs_kd 0.1280 (0.1472) loss_oracle 0.0663 (0.0805) acc 68.7500 (73.9062) kd_loss 0.0383 (0.0470) lr 5.1825e-04 eta 0:14:45
epoch [35/50] batch [120/288] time 0.193 (0.196) data 0.000 (0.002) loss 1.0105 (1.1264) ce_loss 0.8213 (0.9777) teacher_loss 0.8187 (0.9732) loss_zs_kd 0.1939 (0.1477) loss_oracle 0.0949 (0.0794) acc 75.0000 (74.2188) kd_loss 0.0511 (0.0468) lr 5.1825e-04 eta 0:14:40
epoch [35/50] batch [140/288] time 0.191 (0.196) data 0.000 (0.002) loss 0.6183 (1.1218) ce_loss 0.5239 (0.9736) teacher_loss 0.5268 (0.9690) loss_zs_kd 0.0721 (0.1470) loss_oracle 0.0554 (0.0793) acc 87.5000 (74.3080) kd_loss 0.0441 (0.0470) lr 5.1825e-04 eta 0:14:34
epoch [35/50] batch [160/288] time 0.194 (0.196) data 0.000 (0.002) loss 1.0111 (1.1149) ce_loss 0.8735 (0.9674) teacher_loss 0.8735 (0.9631) loss_zs_kd 0.1374 (0.1468) loss_oracle 0.0689 (0.0785) acc 71.8750 (74.4141) kd_loss 0.0416 (0.0464) lr 5.1825e-04 eta 0:14:29
epoch [35/50] batch [180/288] time 0.201 (0.195) data 0.000 (0.002) loss 0.7501 (1.0965) ce_loss 0.6328 (0.9502) teacher_loss 0.6389 (0.9459) loss_zs_kd 0.0823 (0.1449) loss_oracle 0.0700 (0.0782) acc 81.2500 (74.8438) kd_loss 0.0401 (0.0462) lr 5.1825e-04 eta 0:14:24
epoch [35/50] batch [200/288] time 0.201 (0.195) data 0.000 (0.001) loss 0.7287 (1.0910) ce_loss 0.5781 (0.9446) teacher_loss 0.5802 (0.9401) loss_zs_kd 0.1449 (0.1453) loss_oracle 0.0760 (0.0783) acc 75.0000 (74.9219) kd_loss 0.0407 (0.0465) lr 5.1825e-04 eta 0:14:20
epoch [35/50] batch [220/288] time 0.093 (0.192) data 0.000 (0.001) loss 0.7261 (1.0857) ce_loss 0.5898 (0.9399) teacher_loss 0.5966 (0.9355) loss_zs_kd 0.1127 (0.1447) loss_oracle 0.0732 (0.0778) acc 84.3750 (74.9290) kd_loss 0.0470 (0.0466) lr 5.1825e-04 eta 0:14:03
epoch [35/50] batch [240/288] time 0.514 (0.196) data 0.000 (0.001) loss 0.5734 (1.0806) ce_loss 0.4019 (0.9343) teacher_loss 0.3983 (0.9301) loss_zs_kd 0.2081 (0.1454) loss_oracle 0.0711 (0.0778) acc 87.5000 (74.9479) kd_loss 0.0464 (0.0469) lr 5.1825e-04 eta 0:14:17
epoch [35/50] batch [260/288] time 0.194 (0.203) data 0.000 (0.001) loss 0.8106 (1.0675) ce_loss 0.6694 (0.9212) teacher_loss 0.6672 (0.9171) loss_zs_kd 0.1189 (0.1453) loss_oracle 0.0840 (0.0777) acc 90.6250 (75.2524) kd_loss 0.0585 (0.0472) lr 5.1825e-04 eta 0:14:41
epoch [35/50] batch [280/288] time 0.193 (0.202) data 0.000 (0.001) loss 1.1716 (1.0725) ce_loss 1.0264 (0.9254) teacher_loss 1.0253 (0.9211) loss_zs_kd 0.1174 (0.1461) loss_oracle 0.0875 (0.0783) acc 71.8750 (75.1228) kd_loss 0.0487 (0.0478) lr 5.1825e-04 eta 0:14:34
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,430
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,019
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 80.0%
******* Domain a best val acc:      87.2%, epoch: 34 *******
******* Domain a best val test acc: 82.9%, epoch: 34 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [36/50] batch [20/288] time 0.192 (0.209) data 0.000 (0.014) loss 1.4439 (1.0244) ce_loss 1.3320 (0.8797) teacher_loss 1.2960 (0.8780) loss_zs_kd 0.1118 (0.1437) loss_oracle 0.0920 (0.0746) acc 68.7500 (78.1250) kd_loss 0.0584 (0.0460) lr 4.6417e-04 eta 0:14:57
epoch [36/50] batch [40/288] time 0.196 (0.201) data 0.000 (0.007) loss 1.0602 (1.0772) ce_loss 0.9214 (0.9289) teacher_loss 0.9253 (0.9251) loss_zs_kd 0.1201 (0.1525) loss_oracle 0.0748 (0.0758) acc 78.1250 (76.2500) kd_loss 0.0446 (0.0472) lr 4.6417e-04 eta 0:14:22
epoch [36/50] batch [60/288] time 0.195 (0.199) data 0.001 (0.005) loss 0.9201 (1.0795) ce_loss 0.7373 (0.9292) teacher_loss 0.7468 (0.9258) loss_zs_kd 0.1910 (0.1521) loss_oracle 0.0778 (0.0776) acc 84.3750 (76.0938) kd_loss 0.0479 (0.0484) lr 4.6417e-04 eta 0:14:07
epoch [36/50] batch [80/288] time 0.195 (0.198) data 0.000 (0.004) loss 1.0305 (1.0600) ce_loss 0.8696 (0.9106) teacher_loss 0.8848 (0.9079) loss_zs_kd 0.1462 (0.1497) loss_oracle 0.0726 (0.0773) acc 78.1250 (76.5234) kd_loss 0.0423 (0.0483) lr 4.6417e-04 eta 0:13:58
epoch [36/50] batch [100/288] time 0.191 (0.197) data 0.000 (0.003) loss 1.2558 (1.0360) ce_loss 1.1074 (0.8844) teacher_loss 1.1020 (0.8813) loss_zs_kd 0.1275 (0.1507) loss_oracle 0.0900 (0.0794) acc 75.0000 (77.0938) kd_loss 0.0556 (0.0496) lr 4.6417e-04 eta 0:13:51
epoch [36/50] batch [120/288] time 0.192 (0.197) data 0.000 (0.002) loss 0.7959 (1.0469) ce_loss 0.6465 (0.8962) teacher_loss 0.6481 (0.8930) loss_zs_kd 0.1354 (0.1488) loss_oracle 0.0800 (0.0796) acc 87.5000 (76.6927) kd_loss 0.0467 (0.0497) lr 4.6417e-04 eta 0:13:46
epoch [36/50] batch [140/288] time 0.196 (0.196) data 0.000 (0.002) loss 1.0679 (1.0533) ce_loss 0.9468 (0.9024) teacher_loss 0.9417 (0.8989) loss_zs_kd 0.1251 (0.1488) loss_oracle 0.0637 (0.0799) acc 71.8750 (76.5625) kd_loss 0.0397 (0.0505) lr 4.6417e-04 eta 0:13:40
epoch [36/50] batch [160/288] time 0.197 (0.196) data 0.000 (0.002) loss 0.9755 (1.0472) ce_loss 0.8447 (0.8955) teacher_loss 0.8379 (0.8917) loss_zs_kd 0.1122 (0.1499) loss_oracle 0.0815 (0.0805) acc 78.1250 (76.4648) kd_loss 0.0483 (0.0507) lr 4.6417e-04 eta 0:13:35
epoch [36/50] batch [180/288] time 0.081 (0.194) data 0.000 (0.002) loss 1.3980 (1.0528) ce_loss 1.2529 (0.9013) teacher_loss 1.2537 (0.8974) loss_zs_kd 0.1212 (0.1496) loss_oracle 0.0836 (0.0806) acc 68.7500 (76.2500) kd_loss 0.0406 (0.0509) lr 4.6417e-04 eta 0:13:25
epoch [36/50] batch [200/288] time 0.498 (0.202) data 0.000 (0.002) loss 1.1781 (1.0608) ce_loss 1.0332 (0.9097) teacher_loss 1.0104 (0.9056) loss_zs_kd 0.1383 (0.1495) loss_oracle 0.0985 (0.0804) acc 65.6250 (76.0625) kd_loss 0.0594 (0.0507) lr 4.6417e-04 eta 0:13:53
epoch [36/50] batch [220/288] time 0.193 (0.204) data 0.000 (0.001) loss 1.1724 (1.0587) ce_loss 1.0557 (0.9087) teacher_loss 1.0442 (0.9043) loss_zs_kd 0.1447 (0.1484) loss_oracle 0.0558 (0.0802) acc 75.0000 (76.0369) kd_loss 0.0356 (0.0505) lr 4.6417e-04 eta 0:13:58
epoch [36/50] batch [240/288] time 0.193 (0.204) data 0.000 (0.001) loss 0.9266 (1.0570) ce_loss 0.7651 (0.9070) teacher_loss 0.7670 (0.9029) loss_zs_kd 0.1557 (0.1481) loss_oracle 0.0817 (0.0800) acc 75.0000 (76.0547) kd_loss 0.0397 (0.0504) lr 4.6417e-04 eta 0:13:50
epoch [36/50] batch [260/288] time 0.198 (0.203) data 0.000 (0.001) loss 0.8075 (1.0526) ce_loss 0.6387 (0.9025) teacher_loss 0.6384 (0.8989) loss_zs_kd 0.1522 (0.1478) loss_oracle 0.0929 (0.0799) acc 84.3750 (76.1538) kd_loss 0.0541 (0.0502) lr 4.6417e-04 eta 0:13:44
epoch [36/50] batch [280/288] time 0.199 (0.202) data 0.000 (0.001) loss 0.9033 (1.0574) ce_loss 0.7754 (0.9071) teacher_loss 0.7719 (0.9032) loss_zs_kd 0.1526 (0.1493) loss_oracle 0.0551 (0.0796) acc 84.3750 (76.0268) kd_loss 0.0464 (0.0501) lr 4.6417e-04 eta 0:13:37
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,433
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,013
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.5%
******* Domain a best val acc:      87.2%, epoch: 34 *******
******* Domain a best val test acc: 82.9%, epoch: 34 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [37/50] batch [20/288] time 0.164 (0.211) data 0.000 (0.014) loss 1.0612 (1.0888) ce_loss 0.9199 (0.9378) teacher_loss 0.9297 (0.9284) loss_zs_kd 0.1266 (0.1586) loss_oracle 0.0682 (0.0812) acc 75.0000 (75.0000) kd_loss 0.0428 (0.0548) lr 4.1221e-04 eta 0:14:07
epoch [37/50] batch [40/288] time 0.195 (0.203) data 0.000 (0.007) loss 1.0712 (1.1165) ce_loss 0.9175 (0.9695) teacher_loss 0.9103 (0.9614) loss_zs_kd 0.1767 (0.1506) loss_oracle 0.0726 (0.0799) acc 75.0000 (73.9062) kd_loss 0.0494 (0.0539) lr 4.1221e-04 eta 0:13:30
epoch [37/50] batch [60/288] time 0.193 (0.200) data 0.000 (0.005) loss 0.9310 (1.0958) ce_loss 0.7822 (0.9510) teacher_loss 0.7638 (0.9450) loss_zs_kd 0.1607 (0.1458) loss_oracle 0.0869 (0.0780) acc 84.3750 (74.5833) kd_loss 0.0466 (0.0515) lr 4.1221e-04 eta 0:13:14
epoch [37/50] batch [80/288] time 0.194 (0.198) data 0.000 (0.004) loss 0.7527 (1.0845) ce_loss 0.6201 (0.9368) teacher_loss 0.6256 (0.9316) loss_zs_kd 0.1055 (0.1486) loss_oracle 0.0744 (0.0786) acc 81.2500 (75.2344) kd_loss 0.0444 (0.0516) lr 4.1221e-04 eta 0:13:04
epoch [37/50] batch [100/288] time 0.194 (0.198) data 0.000 (0.003) loss 0.9065 (1.0661) ce_loss 0.7778 (0.9178) teacher_loss 0.7648 (0.9119) loss_zs_kd 0.1326 (0.1495) loss_oracle 0.0754 (0.0794) acc 81.2500 (75.7188) kd_loss 0.0572 (0.0513) lr 4.1221e-04 eta 0:12:57
epoch [37/50] batch [120/288] time 0.196 (0.197) data 0.000 (0.002) loss 1.4263 (1.0811) ce_loss 1.3057 (0.9319) teacher_loss 1.2793 (0.9268) loss_zs_kd 0.0938 (0.1504) loss_oracle 0.1001 (0.0791) acc 65.6250 (74.9219) kd_loss 0.0755 (0.0512) lr 4.1221e-04 eta 0:12:50
epoch [37/50] batch [140/288] time 0.194 (0.197) data 0.000 (0.002) loss 1.2161 (1.0828) ce_loss 1.0771 (0.9327) teacher_loss 1.0662 (0.9284) loss_zs_kd 0.1154 (0.1508) loss_oracle 0.0922 (0.0790) acc 71.8750 (74.8438) kd_loss 0.0637 (0.0513) lr 4.1221e-04 eta 0:12:46
epoch [37/50] batch [160/288] time 0.098 (0.201) data 0.000 (0.002) loss 0.9108 (1.0772) ce_loss 0.7749 (0.9265) teacher_loss 0.7710 (0.9224) loss_zs_kd 0.1136 (0.1510) loss_oracle 0.0831 (0.0794) acc 78.1250 (74.9805) kd_loss 0.0664 (0.0515) lr 4.1221e-04 eta 0:12:56
epoch [37/50] batch [180/288] time 0.189 (0.208) data 0.000 (0.002) loss 1.0102 (1.0665) ce_loss 0.8604 (0.9162) teacher_loss 0.8480 (0.9121) loss_zs_kd 0.1560 (0.1503) loss_oracle 0.0842 (0.0793) acc 78.1250 (75.2257) kd_loss 0.0503 (0.0512) lr 4.1221e-04 eta 0:13:20
epoch [37/50] batch [200/288] time 0.196 (0.206) data 0.000 (0.002) loss 0.9220 (1.0674) ce_loss 0.7651 (0.9165) teacher_loss 0.7700 (0.9123) loss_zs_kd 0.1322 (0.1506) loss_oracle 0.0859 (0.0798) acc 78.1250 (75.3750) kd_loss 0.0578 (0.0512) lr 4.1221e-04 eta 0:13:09
epoch [37/50] batch [220/288] time 0.194 (0.205) data 0.000 (0.001) loss 1.3484 (1.0701) ce_loss 1.1826 (0.9195) teacher_loss 1.1695 (0.9150) loss_zs_kd 0.1889 (0.1505) loss_oracle 0.0844 (0.0798) acc 71.8750 (75.2415) kd_loss 0.0533 (0.0509) lr 4.1221e-04 eta 0:13:01
epoch [37/50] batch [240/288] time 0.197 (0.204) data 0.000 (0.001) loss 0.8918 (1.0701) ce_loss 0.7393 (0.9200) teacher_loss 0.7349 (0.9154) loss_zs_kd 0.1465 (0.1500) loss_oracle 0.0837 (0.0797) acc 84.3750 (75.1953) kd_loss 0.0509 (0.0507) lr 4.1221e-04 eta 0:12:53
epoch [37/50] batch [260/288] time 0.195 (0.203) data 0.000 (0.001) loss 1.2426 (1.0738) ce_loss 1.0713 (0.9237) teacher_loss 1.0590 (0.9188) loss_zs_kd 0.1731 (0.1501) loss_oracle 0.0970 (0.0799) acc 78.1250 (75.1202) kd_loss 0.0643 (0.0507) lr 4.1221e-04 eta 0:12:46
epoch [37/50] batch [280/288] time 0.193 (0.203) data 0.000 (0.001) loss 0.8697 (1.0686) ce_loss 0.6929 (0.9181) teacher_loss 0.6837 (0.9130) loss_zs_kd 0.1615 (0.1508) loss_oracle 0.1052 (0.0802) acc 87.5000 (75.2679) kd_loss 0.0661 (0.0507) lr 4.1221e-04 eta 0:12:39
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,437
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 80.0%
******* Domain a best val acc:      87.3%, epoch: 37 *******
******* Domain a best val test acc: 83.3%, epoch: 37 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [38/50] batch [20/288] time 0.192 (0.212) data 0.000 (0.014) loss 1.2928 (1.1115) ce_loss 1.1768 (0.9677) teacher_loss 1.1829 (0.9614) loss_zs_kd 0.0991 (0.1551) loss_oracle 0.0603 (0.0726) acc 65.6250 (74.3750) kd_loss 0.0346 (0.0473) lr 3.6258e-04 eta 0:13:09
epoch [38/50] batch [40/288] time 0.192 (0.203) data 0.000 (0.007) loss 0.5182 (1.0450) ce_loss 0.3328 (0.9009) teacher_loss 0.3339 (0.8951) loss_zs_kd 0.2266 (0.1514) loss_oracle 0.0711 (0.0742) acc 90.6250 (75.8594) kd_loss 0.0445 (0.0481) lr 3.6258e-04 eta 0:12:30
epoch [38/50] batch [60/288] time 0.199 (0.200) data 0.000 (0.005) loss 0.8265 (1.0501) ce_loss 0.7017 (0.9052) teacher_loss 0.7093 (0.9005) loss_zs_kd 0.1494 (0.1512) loss_oracle 0.0424 (0.0740) acc 81.2500 (75.7812) kd_loss 0.0306 (0.0468) lr 3.6258e-04 eta 0:12:15
epoch [38/50] batch [80/288] time 0.197 (0.198) data 0.000 (0.004) loss 1.0921 (1.0599) ce_loss 0.9854 (0.9156) teacher_loss 0.9856 (0.9117) loss_zs_kd 0.0977 (0.1501) loss_oracle 0.0577 (0.0731) acc 78.1250 (75.3125) kd_loss 0.0329 (0.0459) lr 3.6258e-04 eta 0:12:06
epoch [38/50] batch [100/288] time 0.191 (0.197) data 0.000 (0.003) loss 1.0932 (1.0803) ce_loss 0.9272 (0.9360) teacher_loss 0.9406 (0.9316) loss_zs_kd 0.1204 (0.1494) loss_oracle 0.0924 (0.0740) acc 81.2500 (74.9062) kd_loss 0.0560 (0.0464) lr 3.6258e-04 eta 0:11:58
epoch [38/50] batch [120/288] time 0.095 (0.201) data 0.000 (0.003) loss 1.5477 (1.0879) ce_loss 1.4082 (0.9443) teacher_loss 1.4034 (0.9402) loss_zs_kd 0.1557 (0.1485) loss_oracle 0.0665 (0.0734) acc 65.6250 (74.4792) kd_loss 0.0408 (0.0461) lr 3.6258e-04 eta 0:12:08
epoch [38/50] batch [140/288] time 0.088 (0.209) data 0.000 (0.002) loss 0.9229 (1.0950) ce_loss 0.7656 (0.9504) teacher_loss 0.7552 (0.9458) loss_zs_kd 0.1504 (0.1499) loss_oracle 0.0925 (0.0743) acc 84.3750 (74.2857) kd_loss 0.0522 (0.0462) lr 3.6258e-04 eta 0:12:33
epoch [38/50] batch [160/288] time 0.194 (0.207) data 0.000 (0.002) loss 0.7161 (1.1054) ce_loss 0.5938 (0.9597) teacher_loss 0.5885 (0.9551) loss_zs_kd 0.1186 (0.1510) loss_oracle 0.0682 (0.0749) acc 84.3750 (73.9844) kd_loss 0.0477 (0.0465) lr 3.6258e-04 eta 0:12:20
epoch [38/50] batch [180/288] time 0.179 (0.205) data 0.000 (0.002) loss 1.2047 (1.1142) ce_loss 1.0332 (0.9668) teacher_loss 1.0153 (0.9622) loss_zs_kd 0.1904 (0.1530) loss_oracle 0.0943 (0.0756) acc 78.1250 (74.0104) kd_loss 0.0627 (0.0465) lr 3.6258e-04 eta 0:12:11
epoch [38/50] batch [200/288] time 0.173 (0.204) data 0.000 (0.002) loss 0.8548 (1.1022) ce_loss 0.7271 (0.9551) teacher_loss 0.7224 (0.9505) loss_zs_kd 0.1043 (0.1517) loss_oracle 0.0803 (0.0759) acc 75.0000 (74.4062) kd_loss 0.0472 (0.0465) lr 3.6258e-04 eta 0:12:02
epoch [38/50] batch [220/288] time 0.192 (0.203) data 0.000 (0.001) loss 0.7642 (1.0991) ce_loss 0.5938 (0.9517) teacher_loss 0.5843 (0.9468) loss_zs_kd 0.1593 (0.1514) loss_oracle 0.1003 (0.0767) acc 81.2500 (74.5170) kd_loss 0.0579 (0.0468) lr 3.6258e-04 eta 0:11:55
epoch [38/50] batch [240/288] time 0.190 (0.202) data 0.000 (0.001) loss 0.6592 (1.0986) ce_loss 0.4976 (0.9508) teacher_loss 0.5022 (0.9458) loss_zs_kd 0.1318 (0.1517) loss_oracle 0.0911 (0.0769) acc 84.3750 (74.6615) kd_loss 0.0555 (0.0470) lr 3.6258e-04 eta 0:11:48
epoch [38/50] batch [260/288] time 0.190 (0.202) data 0.000 (0.001) loss 1.0521 (1.0967) ce_loss 0.9365 (0.9493) teacher_loss 0.9188 (0.9442) loss_zs_kd 0.1149 (0.1512) loss_oracle 0.0758 (0.0769) acc 81.2500 (74.6755) kd_loss 0.0451 (0.0469) lr 3.6258e-04 eta 0:11:42
epoch [38/50] batch [280/288] time 0.216 (0.201) data 0.000 (0.001) loss 0.7480 (1.0908) ce_loss 0.5933 (0.9432) teacher_loss 0.5935 (0.9379) loss_zs_kd 0.1163 (0.1504) loss_oracle 0.0964 (0.0778) acc 84.3750 (74.8214) kd_loss 0.0672 (0.0473) lr 3.6258e-04 eta 0:11:36
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,435
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,012
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.7%
******* Domain a best val acc:      87.3%, epoch: 37 *******
******* Domain a best val test acc: 83.3%, epoch: 37 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [39/50] batch [20/288] time 0.190 (0.203) data 0.000 (0.012) loss 1.0475 (1.0299) ce_loss 0.9072 (0.8874) teacher_loss 0.8922 (0.8792) loss_zs_kd 0.1357 (0.1432) loss_oracle 0.0874 (0.0791) acc 71.8750 (75.0000) kd_loss 0.0540 (0.0488) lr 3.1545e-04 eta 0:11:38
epoch [39/50] batch [40/288] time 0.195 (0.198) data 0.000 (0.006) loss 1.3025 (1.0681) ce_loss 1.1514 (0.9207) teacher_loss 1.1179 (0.9146) loss_zs_kd 0.1788 (0.1489) loss_oracle 0.0952 (0.0791) acc 62.5000 (75.0781) kd_loss 0.0579 (0.0501) lr 3.1545e-04 eta 0:11:17
epoch [39/50] batch [60/288] time 0.191 (0.197) data 0.000 (0.004) loss 0.9280 (1.0643) ce_loss 0.7793 (0.9192) teacher_loss 0.7674 (0.9118) loss_zs_kd 0.0996 (0.1454) loss_oracle 0.1108 (0.0797) acc 75.0000 (74.6354) kd_loss 0.0573 (0.0499) lr 3.1545e-04 eta 0:11:07
epoch [39/50] batch [80/288] time 0.489 (0.193) data 0.000 (0.003) loss 1.4558 (1.0636) ce_loss 1.3076 (0.9168) teacher_loss 1.2771 (0.9100) loss_zs_kd 0.1268 (0.1463) loss_oracle 0.1153 (0.0804) acc 62.5000 (75.1562) kd_loss 0.0596 (0.0498) lr 3.1545e-04 eta 0:10:51
epoch [39/50] batch [100/288] time 0.318 (0.223) data 0.000 (0.003) loss 1.0342 (1.0684) ce_loss 0.8945 (0.9211) teacher_loss 0.8990 (0.9148) loss_zs_kd 0.1385 (0.1465) loss_oracle 0.0660 (0.0803) acc 71.8750 (74.9375) kd_loss 0.0457 (0.0502) lr 3.1545e-04 eta 0:12:27
epoch [39/50] batch [120/288] time 0.194 (0.211) data 0.000 (0.002) loss 0.7371 (1.0733) ce_loss 0.5928 (0.9267) teacher_loss 0.6105 (0.9207) loss_zs_kd 0.1247 (0.1463) loss_oracle 0.0642 (0.0794) acc 84.3750 (74.7656) kd_loss 0.0434 (0.0499) lr 3.1545e-04 eta 0:11:44
epoch [39/50] batch [140/288] time 0.192 (0.209) data 0.000 (0.002) loss 1.2385 (1.0743) ce_loss 1.1104 (0.9265) teacher_loss 1.0864 (0.9199) loss_zs_kd 0.1754 (0.1495) loss_oracle 0.0644 (0.0797) acc 65.6250 (74.6875) kd_loss 0.0400 (0.0502) lr 3.1545e-04 eta 0:11:32
epoch [39/50] batch [160/288] time 0.192 (0.207) data 0.000 (0.002) loss 1.1686 (1.0704) ce_loss 1.0205 (0.9230) teacher_loss 1.0213 (0.9169) loss_zs_kd 0.1651 (0.1495) loss_oracle 0.0648 (0.0787) acc 75.0000 (74.9805) kd_loss 0.0444 (0.0496) lr 3.1545e-04 eta 0:11:22
epoch [39/50] batch [180/288] time 0.197 (0.206) data 0.000 (0.002) loss 0.9323 (1.0672) ce_loss 0.7524 (0.9200) teacher_loss 0.7654 (0.9139) loss_zs_kd 0.1808 (0.1486) loss_oracle 0.0766 (0.0790) acc 81.2500 (74.9306) kd_loss 0.0543 (0.0499) lr 3.1545e-04 eta 0:11:13
epoch [39/50] batch [200/288] time 0.194 (0.204) data 0.000 (0.001) loss 0.8468 (1.0778) ce_loss 0.6807 (0.9299) teacher_loss 0.6902 (0.9243) loss_zs_kd 0.1704 (0.1489) loss_oracle 0.0714 (0.0790) acc 78.1250 (74.6875) kd_loss 0.0530 (0.0498) lr 3.1545e-04 eta 0:11:05
epoch [39/50] batch [220/288] time 0.192 (0.203) data 0.000 (0.001) loss 1.4073 (1.0756) ce_loss 1.2578 (0.9280) teacher_loss 1.2367 (0.9226) loss_zs_kd 0.1739 (0.1483) loss_oracle 0.0836 (0.0789) acc 75.0000 (74.9290) kd_loss 0.0469 (0.0496) lr 3.1545e-04 eta 0:10:58
epoch [39/50] batch [240/288] time 0.192 (0.203) data 0.000 (0.001) loss 0.9200 (1.0785) ce_loss 0.7354 (0.9302) teacher_loss 0.7370 (0.9245) loss_zs_kd 0.1808 (0.1497) loss_oracle 0.0926 (0.0791) acc 71.8750 (74.7135) kd_loss 0.0543 (0.0495) lr 3.1545e-04 eta 0:10:51
epoch [39/50] batch [260/288] time 0.193 (0.202) data 0.000 (0.001) loss 0.6399 (1.0783) ce_loss 0.5200 (0.9307) teacher_loss 0.5113 (0.9249) loss_zs_kd 0.0995 (0.1488) loss_oracle 0.0789 (0.0790) acc 87.5000 (74.6274) kd_loss 0.0480 (0.0493) lr 3.1545e-04 eta 0:10:45
epoch [39/50] batch [280/288] time 0.192 (0.201) data 0.000 (0.001) loss 0.9540 (1.0765) ce_loss 0.8462 (0.9290) teacher_loss 0.8384 (0.9233) loss_zs_kd 0.1104 (0.1487) loss_oracle 0.0604 (0.0788) acc 78.1250 (74.6429) kd_loss 0.0283 (0.0491) lr 3.1545e-04 eta 0:10:39
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,436
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,023
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.2%
******* Domain a best val acc:      87.3%, epoch: 37 *******
******* Domain a best val test acc: 83.3%, epoch: 37 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [40/50] batch [20/288] time 0.209 (0.204) data 0.000 (0.013) loss 0.9490 (1.0547) ce_loss 0.8223 (0.9135) teacher_loss 0.8262 (0.9092) loss_zs_kd 0.1277 (0.1445) loss_oracle 0.0589 (0.0732) acc 78.1250 (76.0938) kd_loss 0.0299 (0.0435) lr 2.7103e-04 eta 0:10:43
epoch [40/50] batch [40/288] time 0.082 (0.190) data 0.000 (0.007) loss 1.3935 (1.0938) ce_loss 1.2188 (0.9461) teacher_loss 1.2195 (0.9414) loss_zs_kd 0.2066 (0.1511) loss_oracle 0.0708 (0.0769) acc 68.7500 (74.3750) kd_loss 0.0356 (0.0453) lr 2.7103e-04 eta 0:09:55
epoch [40/50] batch [60/288] time 0.404 (0.205) data 0.000 (0.005) loss 0.9396 (1.0714) ce_loss 0.8115 (0.9257) teacher_loss 0.8034 (0.9209) loss_zs_kd 0.1483 (0.1476) loss_oracle 0.0621 (0.0767) acc 78.1250 (74.7917) kd_loss 0.0472 (0.0460) lr 2.7103e-04 eta 0:10:36
epoch [40/50] batch [80/288] time 0.190 (0.218) data 0.000 (0.004) loss 1.3493 (1.0804) ce_loss 1.1816 (0.9319) teacher_loss 1.1875 (0.9269) loss_zs_kd 0.1685 (0.1497) loss_oracle 0.0775 (0.0786) acc 68.7500 (74.6875) kd_loss 0.0502 (0.0473) lr 2.7103e-04 eta 0:11:12
epoch [40/50] batch [100/288] time 0.192 (0.213) data 0.000 (0.003) loss 1.0863 (1.0856) ce_loss 0.9453 (0.9384) teacher_loss 0.9334 (0.9329) loss_zs_kd 0.1255 (0.1478) loss_oracle 0.0901 (0.0788) acc 68.7500 (74.4688) kd_loss 0.0538 (0.0474) lr 2.7103e-04 eta 0:10:53
epoch [40/50] batch [120/288] time 0.196 (0.210) data 0.000 (0.002) loss 1.1076 (1.0823) ce_loss 0.9150 (0.9342) teacher_loss 0.9236 (0.9285) loss_zs_kd 0.1760 (0.1486) loss_oracle 0.0960 (0.0795) acc 78.1250 (74.7135) kd_loss 0.0524 (0.0480) lr 2.7103e-04 eta 0:10:39
epoch [40/50] batch [140/288] time 0.194 (0.207) data 0.000 (0.002) loss 1.1152 (1.0838) ce_loss 0.9937 (0.9355) teacher_loss 1.0022 (0.9298) loss_zs_kd 0.1095 (0.1481) loss_oracle 0.0582 (0.0800) acc 68.7500 (74.6875) kd_loss 0.0314 (0.0485) lr 2.7103e-04 eta 0:10:27
epoch [40/50] batch [160/288] time 0.198 (0.206) data 0.000 (0.002) loss 1.4176 (1.0846) ce_loss 1.2656 (0.9360) teacher_loss 1.2601 (0.9302) loss_zs_kd 0.1679 (0.1492) loss_oracle 0.0734 (0.0799) acc 71.8750 (74.7656) kd_loss 0.0437 (0.0482) lr 2.7103e-04 eta 0:10:18
epoch [40/50] batch [180/288] time 0.191 (0.204) data 0.000 (0.002) loss 0.8562 (1.0941) ce_loss 0.7158 (0.9456) teacher_loss 0.6986 (0.9400) loss_zs_kd 0.1521 (0.1497) loss_oracle 0.0815 (0.0794) acc 84.3750 (74.6354) kd_loss 0.0599 (0.0481) lr 2.7103e-04 eta 0:10:10
epoch [40/50] batch [200/288] time 0.191 (0.203) data 0.000 (0.001) loss 1.1343 (1.0866) ce_loss 0.9141 (0.9380) teacher_loss 0.9006 (0.9327) loss_zs_kd 0.2014 (0.1494) loss_oracle 0.1330 (0.0792) acc 65.6250 (74.7969) kd_loss 0.0774 (0.0479) lr 2.7103e-04 eta 0:10:03
epoch [40/50] batch [220/288] time 0.194 (0.202) data 0.000 (0.001) loss 0.8829 (1.0871) ce_loss 0.7969 (0.9386) teacher_loss 0.7993 (0.9331) loss_zs_kd 0.0695 (0.1500) loss_oracle 0.0488 (0.0790) acc 81.2500 (74.8011) kd_loss 0.0374 (0.0478) lr 2.7103e-04 eta 0:09:56
epoch [40/50] batch [240/288] time 0.192 (0.202) data 0.000 (0.001) loss 0.7262 (1.0778) ce_loss 0.5605 (0.9293) teacher_loss 0.5555 (0.9239) loss_zs_kd 0.1785 (0.1496) loss_oracle 0.0814 (0.0791) acc 84.3750 (75.0521) kd_loss 0.0502 (0.0483) lr 2.7103e-04 eta 0:09:50
epoch [40/50] batch [260/288] time 0.196 (0.201) data 0.000 (0.001) loss 1.2750 (1.0732) ce_loss 1.0938 (0.9241) teacher_loss 1.0821 (0.9190) loss_zs_kd 0.1996 (0.1508) loss_oracle 0.0931 (0.0789) acc 65.6250 (75.1202) kd_loss 0.0536 (0.0480) lr 2.7103e-04 eta 0:09:44
epoch [40/50] batch [280/288] time 0.194 (0.201) data 0.000 (0.001) loss 1.2325 (1.0703) ce_loss 1.0801 (0.9215) teacher_loss 1.0554 (0.9165) loss_zs_kd 0.2039 (0.1503) loss_oracle 0.0751 (0.0786) acc 78.1250 (75.1451) kd_loss 0.0392 (0.0479) lr 2.7103e-04 eta 0:09:39
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,436
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,011
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.5%
******* Domain a best val acc:      87.3%, epoch: 37 *******
******* Domain a best val test acc: 83.3%, epoch: 37 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [41/50] batch [20/288] time 0.098 (0.255) data 0.000 (0.014) loss 0.8743 (1.0767) ce_loss 0.6982 (0.9205) teacher_loss 0.7000 (0.9116) loss_zs_kd 0.1705 (0.1670) loss_oracle 0.0890 (0.0816) acc 78.1250 (75.9375) kd_loss 0.0520 (0.0509) lr 2.2949e-04 eta 0:12:10
epoch [41/50] batch [40/288] time 0.107 (0.258) data 0.000 (0.007) loss 0.9549 (1.0727) ce_loss 0.8154 (0.9243) teacher_loss 0.8094 (0.9171) loss_zs_kd 0.1534 (0.1532) loss_oracle 0.0687 (0.0790) acc 78.1250 (75.4688) kd_loss 0.0408 (0.0483) lr 2.2949e-04 eta 0:12:12
epoch [41/50] batch [60/288] time 0.226 (0.236) data 0.000 (0.005) loss 1.2884 (1.0853) ce_loss 1.1172 (0.9370) teacher_loss 1.1214 (0.9318) loss_zs_kd 0.1623 (0.1483) loss_oracle 0.0858 (0.0794) acc 75.0000 (75.1042) kd_loss 0.0457 (0.0479) lr 2.2949e-04 eta 0:11:06
epoch [41/50] batch [80/288] time 0.197 (0.226) data 0.000 (0.004) loss 0.6588 (1.0887) ce_loss 0.5283 (0.9413) teacher_loss 0.5268 (0.9359) loss_zs_kd 0.1151 (0.1455) loss_oracle 0.0744 (0.0801) acc 78.1250 (75.1562) kd_loss 0.0444 (0.0479) lr 2.2949e-04 eta 0:10:32
epoch [41/50] batch [100/288] time 0.191 (0.219) data 0.000 (0.003) loss 1.5388 (1.0932) ce_loss 1.3740 (0.9438) teacher_loss 1.3767 (0.9394) loss_zs_kd 0.1710 (0.1486) loss_oracle 0.0767 (0.0795) acc 59.3750 (74.8125) kd_loss 0.0394 (0.0471) lr 2.2949e-04 eta 0:10:09
epoch [41/50] batch [120/288] time 0.196 (0.215) data 0.000 (0.003) loss 1.3806 (1.0912) ce_loss 1.2285 (0.9416) teacher_loss 1.2176 (0.9362) loss_zs_kd 0.1962 (0.1481) loss_oracle 0.0649 (0.0810) acc 65.6250 (74.7396) kd_loss 0.0501 (0.0481) lr 2.2949e-04 eta 0:09:53
epoch [41/50] batch [140/288] time 0.200 (0.212) data 0.000 (0.002) loss 1.2745 (1.0849) ce_loss 1.1523 (0.9347) teacher_loss 1.1513 (0.9297) loss_zs_kd 0.1166 (0.1479) loss_oracle 0.0649 (0.0812) acc 68.7500 (75.0000) kd_loss 0.0474 (0.0483) lr 2.2949e-04 eta 0:09:41
epoch [41/50] batch [160/288] time 0.190 (0.210) data 0.000 (0.002) loss 0.7592 (1.0742) ce_loss 0.6357 (0.9250) teacher_loss 0.6441 (0.9204) loss_zs_kd 0.1062 (0.1470) loss_oracle 0.0621 (0.0803) acc 87.5000 (75.1562) kd_loss 0.0415 (0.0481) lr 2.2949e-04 eta 0:09:30
epoch [41/50] batch [180/288] time 0.196 (0.208) data 0.000 (0.002) loss 1.8209 (1.0732) ce_loss 1.6240 (0.9238) teacher_loss 1.6017 (0.9188) loss_zs_kd 0.2372 (0.1477) loss_oracle 0.1006 (0.0805) acc 62.5000 (75.2951) kd_loss 0.0667 (0.0483) lr 2.2949e-04 eta 0:09:21
epoch [41/50] batch [200/288] time 0.191 (0.207) data 0.000 (0.002) loss 1.1163 (1.0749) ce_loss 0.9443 (0.9258) teacher_loss 0.9326 (0.9204) loss_zs_kd 0.1498 (0.1482) loss_oracle 0.1088 (0.0804) acc 65.6250 (75.3750) kd_loss 0.0641 (0.0486) lr 2.2949e-04 eta 0:09:14
epoch [41/50] batch [220/288] time 0.196 (0.206) data 0.000 (0.001) loss 1.0607 (1.0740) ce_loss 0.8784 (0.9243) teacher_loss 0.8812 (0.9188) loss_zs_kd 0.1993 (0.1491) loss_oracle 0.0798 (0.0807) acc 81.2500 (75.4403) kd_loss 0.0511 (0.0487) lr 2.2949e-04 eta 0:09:06
epoch [41/50] batch [240/288] time 0.194 (0.205) data 0.000 (0.001) loss 1.0819 (1.0728) ce_loss 0.8999 (0.9236) teacher_loss 0.8891 (0.9182) loss_zs_kd 0.1807 (0.1474) loss_oracle 0.1025 (0.0810) acc 84.3750 (75.5599) kd_loss 0.0564 (0.0490) lr 2.2949e-04 eta 0:09:00
epoch [41/50] batch [260/288] time 0.194 (0.204) data 0.000 (0.001) loss 1.6812 (1.0753) ce_loss 1.5098 (0.9263) teacher_loss 1.4858 (0.9206) loss_zs_kd 0.1829 (0.1474) loss_oracle 0.1040 (0.0810) acc 62.5000 (75.4207) kd_loss 0.0620 (0.0491) lr 2.2949e-04 eta 0:08:53
epoch [41/50] batch [280/288] time 0.186 (0.203) data 0.000 (0.001) loss 0.8250 (1.0750) ce_loss 0.6904 (0.9267) teacher_loss 0.7007 (0.9213) loss_zs_kd 0.1530 (0.1469) loss_oracle 0.0478 (0.0803) acc 81.2500 (75.3013) kd_loss 0.0405 (0.0488) lr 2.2949e-04 eta 0:08:47
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,430
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,014
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 79.7%
******* Domain a best val acc:      87.3%, epoch: 37 *******
******* Domain a best val test acc: 83.3%, epoch: 37 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [42/50] batch [20/288] time 0.194 (0.229) data 0.000 (0.013) loss 0.9170 (1.0416) ce_loss 0.7983 (0.8991) teacher_loss 0.7860 (0.8955) loss_zs_kd 0.1192 (0.1378) loss_oracle 0.0715 (0.0772) acc 81.2500 (76.5625) kd_loss 0.0365 (0.0482) lr 1.9098e-04 eta 0:09:49
epoch [42/50] batch [40/288] time 0.192 (0.211) data 0.000 (0.007) loss 1.0073 (1.0666) ce_loss 0.8740 (0.9219) teacher_loss 0.8819 (0.9183) loss_zs_kd 0.1434 (0.1418) loss_oracle 0.0536 (0.0774) acc 78.1250 (76.2500) kd_loss 0.0306 (0.0471) lr 1.9098e-04 eta 0:08:58
epoch [42/50] batch [60/288] time 0.197 (0.206) data 0.001 (0.004) loss 1.4339 (1.0948) ce_loss 1.2998 (0.9460) teacher_loss 1.3000 (0.9405) loss_zs_kd 0.1334 (0.1483) loss_oracle 0.0672 (0.0801) acc 68.7500 (75.6771) kd_loss 0.0374 (0.0492) lr 1.9098e-04 eta 0:08:40
epoch [42/50] batch [80/288] time 0.197 (0.203) data 0.000 (0.003) loss 0.8940 (1.0798) ce_loss 0.7207 (0.9301) teacher_loss 0.7154 (0.9248) loss_zs_kd 0.1394 (0.1495) loss_oracle 0.1089 (0.0803) acc 78.1250 (75.2734) kd_loss 0.0705 (0.0494) lr 1.9098e-04 eta 0:08:28
epoch [42/50] batch [100/288] time 0.190 (0.201) data 0.000 (0.003) loss 1.0241 (1.0942) ce_loss 0.8750 (0.9431) teacher_loss 0.8786 (0.9390) loss_zs_kd 0.1777 (0.1515) loss_oracle 0.0566 (0.0794) acc 78.1250 (74.8750) kd_loss 0.0369 (0.0483) lr 1.9098e-04 eta 0:08:20
epoch [42/50] batch [120/288] time 0.193 (0.200) data 0.000 (0.002) loss 0.8113 (1.0675) ce_loss 0.6646 (0.9176) teacher_loss 0.6473 (0.9134) loss_zs_kd 0.1804 (0.1484) loss_oracle 0.0738 (0.0799) acc 75.0000 (75.4167) kd_loss 0.0403 (0.0479) lr 1.9098e-04 eta 0:08:13
epoch [42/50] batch [140/288] time 0.189 (0.199) data 0.000 (0.002) loss 1.2650 (1.0633) ce_loss 1.0840 (0.9132) teacher_loss 1.0617 (0.9081) loss_zs_kd 0.1601 (0.1499) loss_oracle 0.1232 (0.0803) acc 59.3750 (75.6250) kd_loss 0.0778 (0.0476) lr 1.9098e-04 eta 0:08:07
epoch [42/50] batch [160/288] time 0.225 (0.198) data 0.000 (0.002) loss 1.2943 (1.0681) ce_loss 1.1152 (0.9171) teacher_loss 1.1059 (0.9122) loss_zs_kd 0.2071 (0.1510) loss_oracle 0.0848 (0.0804) acc 71.8750 (75.4883) kd_loss 0.0577 (0.0476) lr 1.9098e-04 eta 0:08:02
epoch [42/50] batch [180/288] time 0.196 (0.198) data 0.000 (0.002) loss 1.1600 (1.0646) ce_loss 0.9854 (0.9139) teacher_loss 0.9863 (0.9088) loss_zs_kd 0.1957 (0.1508) loss_oracle 0.0759 (0.0804) acc 75.0000 (75.5556) kd_loss 0.0436 (0.0478) lr 1.9098e-04 eta 0:07:57
epoch [42/50] batch [200/288] time 0.186 (0.197) data 0.000 (0.001) loss 1.0325 (1.0655) ce_loss 0.8877 (0.9147) teacher_loss 0.8728 (0.9092) loss_zs_kd 0.1319 (0.1508) loss_oracle 0.0937 (0.0809) acc 71.8750 (75.6875) kd_loss 0.0598 (0.0479) lr 1.9098e-04 eta 0:07:51
epoch [42/50] batch [220/288] time 0.198 (0.197) data 0.000 (0.001) loss 1.0339 (1.0698) ce_loss 0.8931 (0.9188) teacher_loss 0.8955 (0.9134) loss_zs_kd 0.1348 (0.1505) loss_oracle 0.0710 (0.0812) acc 78.1250 (75.5256) kd_loss 0.0511 (0.0480) lr 1.9098e-04 eta 0:07:47
epoch [42/50] batch [240/288] time 0.192 (0.197) data 0.000 (0.001) loss 1.1173 (1.0676) ce_loss 0.9731 (0.9174) teacher_loss 0.9445 (0.9119) loss_zs_kd 0.1471 (0.1499) loss_oracle 0.0992 (0.0808) acc 78.1250 (75.6380) kd_loss 0.0624 (0.0477) lr 1.9098e-04 eta 0:07:42
epoch [42/50] batch [260/288] time 0.468 (0.197) data 0.000 (0.001) loss 1.2887 (1.0725) ce_loss 1.1289 (0.9223) teacher_loss 1.1163 (0.9165) loss_zs_kd 0.1755 (0.1500) loss_oracle 0.0847 (0.0810) acc 78.1250 (75.4808) kd_loss 0.0505 (0.0479) lr 1.9098e-04 eta 0:07:40
epoch [42/50] batch [280/288] time 0.082 (0.206) data 0.000 (0.001) loss 0.9719 (1.0668) ce_loss 0.8418 (0.9169) teacher_loss 0.8477 (0.9115) loss_zs_kd 0.1287 (0.1493) loss_oracle 0.0599 (0.0807) acc 87.5000 (75.6696) kd_loss 0.0455 (0.0476) lr 1.9098e-04 eta 0:07:56
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,435
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,008
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 79.4%
******* Domain a best val acc:      87.3%, epoch: 37 *******
******* Domain a best val test acc: 83.3%, epoch: 37 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [43/50] batch [20/288] time 0.171 (0.216) data 0.000 (0.017) loss 1.3831 (1.1366) ce_loss 1.2549 (0.9896) teacher_loss 1.2302 (0.9776) loss_zs_kd 0.1332 (0.1513) loss_oracle 0.0863 (0.0833) acc 68.7500 (71.7188) kd_loss 0.0428 (0.0527) lr 1.5567e-04 eta 0:08:14
epoch [43/50] batch [40/288] time 0.194 (0.205) data 0.000 (0.008) loss 1.1675 (1.1110) ce_loss 1.0244 (0.9621) teacher_loss 1.0217 (0.9537) loss_zs_kd 0.1491 (0.1536) loss_oracle 0.0712 (0.0805) acc 71.8750 (72.9688) kd_loss 0.0378 (0.0502) lr 1.5567e-04 eta 0:07:45
epoch [43/50] batch [60/288] time 0.195 (0.202) data 0.000 (0.006) loss 1.8377 (1.1304) ce_loss 1.7021 (0.9789) teacher_loss 1.6967 (0.9715) loss_zs_kd 0.1575 (0.1582) loss_oracle 0.0622 (0.0798) acc 53.1250 (72.8125) kd_loss 0.0376 (0.0498) lr 1.5567e-04 eta 0:07:32
epoch [43/50] batch [80/288] time 0.196 (0.200) data 0.000 (0.004) loss 0.6790 (1.0813) ce_loss 0.5518 (0.9324) teacher_loss 0.5633 (0.9260) loss_zs_kd 0.0696 (0.1505) loss_oracle 0.0809 (0.0800) acc 87.5000 (74.3750) kd_loss 0.0457 (0.0502) lr 1.5567e-04 eta 0:07:24
epoch [43/50] batch [100/288] time 0.196 (0.198) data 0.000 (0.003) loss 1.4472 (1.0887) ce_loss 1.2803 (0.9406) teacher_loss 1.2708 (0.9344) loss_zs_kd 0.1681 (0.1489) loss_oracle 0.0924 (0.0798) acc 68.7500 (73.9062) kd_loss 0.0574 (0.0500) lr 1.5567e-04 eta 0:07:17
epoch [43/50] batch [120/288] time 0.191 (0.198) data 0.000 (0.003) loss 0.8666 (1.0872) ce_loss 0.7075 (0.9367) teacher_loss 0.7154 (0.9310) loss_zs_kd 0.1332 (0.1513) loss_oracle 0.0846 (0.0806) acc 75.0000 (74.2969) kd_loss 0.0531 (0.0505) lr 1.5567e-04 eta 0:07:11
epoch [43/50] batch [140/288] time 0.195 (0.197) data 0.000 (0.003) loss 0.8802 (1.0858) ce_loss 0.6953 (0.9348) teacher_loss 0.6903 (0.9284) loss_zs_kd 0.1715 (0.1514) loss_oracle 0.1041 (0.0817) acc 84.3750 (74.4866) kd_loss 0.0659 (0.0512) lr 1.5567e-04 eta 0:07:06
epoch [43/50] batch [160/288] time 0.197 (0.197) data 0.000 (0.002) loss 0.9538 (1.0800) ce_loss 0.8179 (0.9282) teacher_loss 0.8111 (0.9223) loss_zs_kd 0.1356 (0.1517) loss_oracle 0.0749 (0.0819) acc 75.0000 (74.6094) kd_loss 0.0461 (0.0512) lr 1.5567e-04 eta 0:07:01
epoch [43/50] batch [180/288] time 0.194 (0.196) data 0.000 (0.002) loss 0.8674 (1.0710) ce_loss 0.7183 (0.9192) teacher_loss 0.7169 (0.9139) loss_zs_kd 0.1179 (0.1507) loss_oracle 0.0916 (0.0817) acc 81.2500 (74.8090) kd_loss 0.0503 (0.0513) lr 1.5567e-04 eta 0:06:57
epoch [43/50] batch [200/288] time 0.194 (0.196) data 0.000 (0.002) loss 0.9931 (1.0734) ce_loss 0.8525 (0.9213) teacher_loss 0.8484 (0.9166) loss_zs_kd 0.1618 (0.1508) loss_oracle 0.0638 (0.0814) acc 84.3750 (74.7969) kd_loss 0.0342 (0.0509) lr 1.5567e-04 eta 0:06:52
epoch [43/50] batch [220/288] time 0.264 (0.201) data 0.000 (0.002) loss 1.0535 (1.0745) ce_loss 0.8799 (0.9227) teacher_loss 0.8783 (0.9179) loss_zs_kd 0.1663 (0.1506) loss_oracle 0.0920 (0.0813) acc 68.7500 (74.7869) kd_loss 0.0503 (0.0508) lr 1.5567e-04 eta 0:06:59
epoch [43/50] batch [240/288] time 0.215 (0.207) data 0.000 (0.002) loss 1.1594 (1.0705) ce_loss 0.9678 (0.9187) teacher_loss 0.9667 (0.9138) loss_zs_kd 0.2195 (0.1502) loss_oracle 0.0829 (0.0816) acc 68.7500 (74.7917) kd_loss 0.0544 (0.0509) lr 1.5567e-04 eta 0:07:06
epoch [43/50] batch [260/288] time 0.194 (0.206) data 0.000 (0.001) loss 0.8751 (1.0705) ce_loss 0.7476 (0.9188) teacher_loss 0.7389 (0.9137) loss_zs_kd 0.1539 (0.1502) loss_oracle 0.0593 (0.0817) acc 78.1250 (74.7716) kd_loss 0.0373 (0.0511) lr 1.5567e-04 eta 0:07:01
epoch [43/50] batch [280/288] time 0.190 (0.205) data 0.000 (0.001) loss 1.0605 (1.0700) ce_loss 0.9253 (0.9184) teacher_loss 0.9081 (0.9135) loss_zs_kd 0.1483 (0.1502) loss_oracle 0.0782 (0.0814) acc 78.1250 (74.7879) kd_loss 0.0451 (0.0508) lr 1.5567e-04 eta 0:06:55
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,434
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,011
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.7%
******* Domain a best val acc:      87.3%, epoch: 37 *******
******* Domain a best val test acc: 83.3%, epoch: 37 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [44/50] batch [20/288] time 0.194 (0.214) data 0.000 (0.016) loss 1.2790 (1.0731) ce_loss 1.1396 (0.9233) teacher_loss 1.1366 (0.9194) loss_zs_kd 0.1327 (0.1479) loss_oracle 0.0760 (0.0797) acc 65.6250 (74.2188) kd_loss 0.0430 (0.0490) lr 1.2369e-04 eta 0:07:06
epoch [44/50] batch [40/288] time 0.188 (0.204) data 0.000 (0.008) loss 0.8751 (1.1090) ce_loss 0.7251 (0.9592) teacher_loss 0.7293 (0.9550) loss_zs_kd 0.1470 (0.1463) loss_oracle 0.0723 (0.0809) acc 81.2500 (73.5938) kd_loss 0.0567 (0.0507) lr 1.2369e-04 eta 0:06:42
epoch [44/50] batch [60/288] time 0.194 (0.201) data 0.000 (0.006) loss 0.8412 (1.0939) ce_loss 0.7139 (0.9424) teacher_loss 0.7069 (0.9372) loss_zs_kd 0.0947 (0.1508) loss_oracle 0.0870 (0.0814) acc 81.2500 (74.1146) kd_loss 0.0659 (0.0511) lr 1.2369e-04 eta 0:06:32
epoch [44/50] batch [80/288] time 0.196 (0.199) data 0.000 (0.004) loss 1.2254 (1.0899) ce_loss 1.0654 (0.9382) teacher_loss 1.0643 (0.9333) loss_zs_kd 0.1895 (0.1499) loss_oracle 0.0664 (0.0817) acc 75.0000 (74.1016) kd_loss 0.0453 (0.0512) lr 1.2369e-04 eta 0:06:25
epoch [44/50] batch [100/288] time 0.191 (0.198) data 0.000 (0.003) loss 1.1693 (1.0809) ce_loss 1.0244 (0.9294) teacher_loss 1.0178 (0.9242) loss_zs_kd 0.1303 (0.1495) loss_oracle 0.0864 (0.0819) acc 75.0000 (74.5625) kd_loss 0.0542 (0.0513) lr 1.2369e-04 eta 0:06:19
epoch [44/50] batch [120/288] time 0.195 (0.197) data 0.000 (0.003) loss 1.1473 (1.0707) ce_loss 0.9707 (0.9202) teacher_loss 0.9608 (0.9156) loss_zs_kd 0.2107 (0.1485) loss_oracle 0.0812 (0.0809) acc 71.8750 (75.0781) kd_loss 0.0434 (0.0508) lr 1.2369e-04 eta 0:06:13
epoch [44/50] batch [140/288] time 0.191 (0.197) data 0.000 (0.002) loss 1.0205 (1.0723) ce_loss 0.8369 (0.9217) teacher_loss 0.8355 (0.9169) loss_zs_kd 0.1637 (0.1488) loss_oracle 0.1031 (0.0810) acc 78.1250 (75.2902) kd_loss 0.0557 (0.0506) lr 1.2369e-04 eta 0:06:08
epoch [44/50] batch [160/288] time 0.189 (0.196) data 0.000 (0.002) loss 1.2468 (1.0763) ce_loss 1.0977 (0.9266) teacher_loss 1.1056 (0.9220) loss_zs_kd 0.1473 (0.1491) loss_oracle 0.0675 (0.0798) acc 62.5000 (75.0586) kd_loss 0.0388 (0.0499) lr 1.2369e-04 eta 0:06:03
epoch [44/50] batch [180/288] time 0.084 (0.199) data 0.000 (0.002) loss 0.9488 (1.0844) ce_loss 0.8179 (0.9343) teacher_loss 0.8023 (0.9295) loss_zs_kd 0.1205 (0.1493) loss_oracle 0.0862 (0.0803) acc 78.1250 (74.9132) kd_loss 0.0550 (0.0500) lr 1.2369e-04 eta 0:06:05
epoch [44/50] batch [200/288] time 0.194 (0.207) data 0.000 (0.002) loss 0.9177 (1.0855) ce_loss 0.7764 (0.9345) teacher_loss 0.7865 (0.9299) loss_zs_kd 0.1488 (0.1512) loss_oracle 0.0568 (0.0800) acc 78.1250 (74.8438) kd_loss 0.0312 (0.0500) lr 1.2369e-04 eta 0:06:16
epoch [44/50] batch [220/288] time 0.190 (0.206) data 0.000 (0.002) loss 1.0033 (1.0876) ce_loss 0.8872 (0.9378) teacher_loss 0.8749 (0.9329) loss_zs_kd 0.1397 (0.1506) loss_oracle 0.0587 (0.0794) acc 75.0000 (74.7585) kd_loss 0.0435 (0.0496) lr 1.2369e-04 eta 0:06:10
epoch [44/50] batch [240/288] time 0.193 (0.205) data 0.000 (0.002) loss 1.0383 (1.0992) ce_loss 0.9111 (0.9493) teacher_loss 0.8900 (0.9442) loss_zs_kd 0.1457 (0.1504) loss_oracle 0.0754 (0.0798) acc 75.0000 (74.4401) kd_loss 0.0456 (0.0497) lr 1.2369e-04 eta 0:06:04
epoch [44/50] batch [260/288] time 0.191 (0.204) data 0.000 (0.001) loss 1.4552 (1.0953) ce_loss 1.3525 (0.9459) teacher_loss 1.3440 (0.9405) loss_zs_kd 0.1156 (0.1497) loss_oracle 0.0533 (0.0800) acc 68.7500 (74.5192) kd_loss 0.0428 (0.0497) lr 1.2369e-04 eta 0:05:58
epoch [44/50] batch [280/288] time 0.190 (0.204) data 0.000 (0.001) loss 1.3908 (1.0944) ce_loss 1.2441 (0.9445) teacher_loss 1.2492 (0.9394) loss_zs_kd 0.1252 (0.1503) loss_oracle 0.0790 (0.0798) acc 65.6250 (74.4643) kd_loss 0.0509 (0.0494) lr 1.2369e-04 eta 0:05:53
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,443
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.8%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,012
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.6%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 82.9%, epoch: 44 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [45/50] batch [20/288] time 0.197 (0.213) data 0.000 (0.018) loss 1.3163 (1.0908) ce_loss 1.1846 (0.9339) teacher_loss 1.1793 (0.9293) loss_zs_kd 0.1102 (0.1547) loss_oracle 0.0819 (0.0842) acc 62.5000 (75.1562) kd_loss 0.0499 (0.0508) lr 9.5173e-05 eta 0:06:03
epoch [45/50] batch [40/288] time 0.196 (0.203) data 0.000 (0.009) loss 0.8479 (1.0322) ce_loss 0.7466 (0.8788) teacher_loss 0.7392 (0.8767) loss_zs_kd 0.0726 (0.1514) loss_oracle 0.0724 (0.0798) acc 78.1250 (76.3281) kd_loss 0.0506 (0.0489) lr 9.5173e-05 eta 0:05:43
epoch [45/50] batch [60/288] time 0.192 (0.200) data 0.000 (0.006) loss 0.6748 (1.0342) ce_loss 0.5151 (0.8821) teacher_loss 0.5165 (0.8783) loss_zs_kd 0.1359 (0.1477) loss_oracle 0.0904 (0.0820) acc 84.3750 (76.4062) kd_loss 0.0623 (0.0499) lr 9.5173e-05 eta 0:05:33
epoch [45/50] batch [80/288] time 0.194 (0.198) data 0.000 (0.005) loss 0.7261 (1.0448) ce_loss 0.5933 (0.8946) teacher_loss 0.5967 (0.8898) loss_zs_kd 0.1098 (0.1458) loss_oracle 0.0746 (0.0821) acc 84.3750 (75.9375) kd_loss 0.0498 (0.0509) lr 9.5173e-05 eta 0:05:27
epoch [45/50] batch [100/288] time 0.193 (0.197) data 0.000 (0.004) loss 1.5374 (1.0389) ce_loss 1.3965 (0.8895) teacher_loss 1.3914 (0.8846) loss_zs_kd 0.1337 (0.1455) loss_oracle 0.0791 (0.0815) acc 59.3750 (75.9062) kd_loss 0.0489 (0.0510) lr 9.5173e-05 eta 0:05:21
epoch [45/50] batch [120/288] time 0.093 (0.192) data 0.000 (0.003) loss 0.9324 (1.0480) ce_loss 0.8018 (0.8982) teacher_loss 0.8000 (0.8930) loss_zs_kd 0.1307 (0.1476) loss_oracle 0.0671 (0.0812) acc 81.2500 (75.8333) kd_loss 0.0456 (0.0506) lr 9.5173e-05 eta 0:05:09
epoch [45/50] batch [140/288] time 0.496 (0.212) data 0.001 (0.003) loss 0.4753 (1.0517) ce_loss 0.3198 (0.9022) teacher_loss 0.3243 (0.8972) loss_zs_kd 0.1213 (0.1472) loss_oracle 0.0903 (0.0810) acc 87.5000 (75.8036) kd_loss 0.0581 (0.0502) lr 9.5173e-05 eta 0:05:37
epoch [45/50] batch [160/288] time 0.193 (0.212) data 0.000 (0.002) loss 1.0863 (1.0572) ce_loss 0.9219 (0.9063) teacher_loss 0.9357 (0.9011) loss_zs_kd 0.1834 (0.1491) loss_oracle 0.0589 (0.0816) acc 75.0000 (75.4492) kd_loss 0.0347 (0.0505) lr 9.5173e-05 eta 0:05:32
epoch [45/50] batch [180/288] time 0.193 (0.210) data 0.000 (0.002) loss 1.2768 (1.0625) ce_loss 1.1016 (0.9119) teacher_loss 1.1108 (0.9064) loss_zs_kd 0.2093 (0.1495) loss_oracle 0.0613 (0.0813) acc 65.6250 (75.1389) kd_loss 0.0375 (0.0502) lr 9.5173e-05 eta 0:05:24
epoch [45/50] batch [200/288] time 0.194 (0.208) data 0.000 (0.002) loss 0.7107 (1.0670) ce_loss 0.5713 (0.9157) teacher_loss 0.5765 (0.9098) loss_zs_kd 0.1167 (0.1500) loss_oracle 0.0759 (0.0821) acc 87.5000 (75.3281) kd_loss 0.0529 (0.0510) lr 9.5173e-05 eta 0:05:18
epoch [45/50] batch [220/288] time 0.195 (0.207) data 0.000 (0.002) loss 0.9267 (1.0616) ce_loss 0.7578 (0.9107) teacher_loss 0.7673 (0.9046) loss_zs_kd 0.1931 (0.1500) loss_oracle 0.0628 (0.0820) acc 84.3750 (75.4830) kd_loss 0.0305 (0.0510) lr 9.5173e-05 eta 0:05:12
epoch [45/50] batch [240/288] time 0.191 (0.206) data 0.000 (0.002) loss 1.0485 (1.0536) ce_loss 0.9033 (0.9030) teacher_loss 0.8994 (0.8970) loss_zs_kd 0.1231 (0.1492) loss_oracle 0.0876 (0.0820) acc 71.8750 (75.7682) kd_loss 0.0531 (0.0512) lr 9.5173e-05 eta 0:05:06
epoch [45/50] batch [260/288] time 0.201 (0.205) data 0.000 (0.002) loss 1.3906 (1.0524) ce_loss 1.1807 (0.9011) teacher_loss 1.1544 (0.8954) loss_zs_kd 0.2242 (0.1503) loss_oracle 0.1241 (0.0818) acc 68.7500 (75.8534) kd_loss 0.0774 (0.0511) lr 9.5173e-05 eta 0:05:00
epoch [45/50] batch [280/288] time 0.201 (0.204) data 0.000 (0.002) loss 1.1263 (1.0620) ce_loss 0.9517 (0.9102) teacher_loss 0.9545 (0.9044) loss_zs_kd 0.1617 (0.1511) loss_oracle 0.0910 (0.0821) acc 81.2500 (75.6473) kd_loss 0.0570 (0.0513) lr 9.5173e-05 eta 0:04:55
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,438
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,012
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.6%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 82.9%, epoch: 44 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [46/50] batch [20/288] time 0.197 (0.209) data 0.000 (0.014) loss 0.8657 (1.0550) ce_loss 0.7280 (0.9059) teacher_loss 0.7071 (0.8992) loss_zs_kd 0.1220 (0.1467) loss_oracle 0.0976 (0.0824) acc 78.1250 (75.7812) kd_loss 0.0657 (0.0543) lr 7.0224e-05 eta 0:04:57
epoch [46/50] batch [40/288] time 0.199 (0.202) data 0.000 (0.007) loss 1.2178 (1.0987) ce_loss 1.0732 (0.9475) teacher_loss 1.0833 (0.9428) loss_zs_kd 0.1496 (0.1512) loss_oracle 0.0597 (0.0803) acc 71.8750 (75.8594) kd_loss 0.0369 (0.0526) lr 7.0224e-05 eta 0:04:42
epoch [46/50] batch [60/288] time 0.190 (0.199) data 0.000 (0.005) loss 0.9865 (1.1073) ce_loss 0.8320 (0.9520) teacher_loss 0.8284 (0.9469) loss_zs_kd 0.1552 (0.1558) loss_oracle 0.0805 (0.0825) acc 78.1250 (75.2083) kd_loss 0.0448 (0.0531) lr 7.0224e-05 eta 0:04:34
epoch [46/50] batch [80/288] time 0.096 (0.191) data 0.000 (0.004) loss 0.8902 (1.0791) ce_loss 0.7471 (0.9268) teacher_loss 0.7498 (0.9223) loss_zs_kd 0.1212 (0.1522) loss_oracle 0.0798 (0.0807) acc 81.2500 (75.8594) kd_loss 0.0462 (0.0522) lr 7.0224e-05 eta 0:04:19
epoch [46/50] batch [100/288] time 0.462 (0.223) data 0.000 (0.003) loss 0.9001 (1.0686) ce_loss 0.7485 (0.9165) teacher_loss 0.7558 (0.9132) loss_zs_kd 0.1501 (0.1518) loss_oracle 0.0692 (0.0795) acc 71.8750 (76.1250) kd_loss 0.0393 (0.0505) lr 7.0224e-05 eta 0:04:58
epoch [46/50] batch [120/288] time 0.194 (0.219) data 0.000 (0.003) loss 0.6651 (1.0723) ce_loss 0.4968 (0.9201) teacher_loss 0.4938 (0.9161) loss_zs_kd 0.1583 (0.1522) loss_oracle 0.0922 (0.0801) acc 87.5000 (75.8854) kd_loss 0.0550 (0.0505) lr 7.0224e-05 eta 0:04:48
epoch [46/50] batch [140/288] time 0.193 (0.215) data 0.000 (0.002) loss 0.9892 (1.0713) ce_loss 0.8560 (0.9198) teacher_loss 0.8405 (0.9153) loss_zs_kd 0.1457 (0.1519) loss_oracle 0.0758 (0.0801) acc 78.1250 (75.8036) kd_loss 0.0461 (0.0505) lr 7.0224e-05 eta 0:04:39
epoch [46/50] batch [160/288] time 0.196 (0.213) data 0.000 (0.002) loss 1.1034 (1.0635) ce_loss 0.9258 (0.9131) teacher_loss 0.9208 (0.9088) loss_zs_kd 0.2070 (0.1512) loss_oracle 0.0792 (0.0791) acc 75.0000 (75.7422) kd_loss 0.0572 (0.0500) lr 7.0224e-05 eta 0:04:32
epoch [46/50] batch [180/288] time 0.200 (0.211) data 0.000 (0.002) loss 1.1710 (1.0709) ce_loss 0.9863 (0.9205) teacher_loss 0.9830 (0.9157) loss_zs_kd 0.1954 (0.1518) loss_oracle 0.0903 (0.0793) acc 78.1250 (75.5382) kd_loss 0.0567 (0.0501) lr 7.0224e-05 eta 0:04:25
epoch [46/50] batch [200/288] time 0.197 (0.209) data 0.000 (0.002) loss 1.3250 (1.0807) ce_loss 1.2197 (0.9299) teacher_loss 1.2127 (0.9250) loss_zs_kd 0.0879 (0.1518) loss_oracle 0.0683 (0.0797) acc 71.8750 (75.2344) kd_loss 0.0463 (0.0504) lr 7.0224e-05 eta 0:04:19
epoch [46/50] batch [220/288] time 0.192 (0.208) data 0.000 (0.001) loss 1.0074 (1.0834) ce_loss 0.8682 (0.9326) teacher_loss 0.8682 (0.9278) loss_zs_kd 0.1378 (0.1509) loss_oracle 0.0703 (0.0801) acc 75.0000 (75.0994) kd_loss 0.0430 (0.0504) lr 7.0224e-05 eta 0:04:13
epoch [46/50] batch [240/288] time 0.191 (0.207) data 0.000 (0.001) loss 1.0096 (1.0853) ce_loss 0.8682 (0.9341) teacher_loss 0.8776 (0.9291) loss_zs_kd 0.1590 (0.1513) loss_oracle 0.0525 (0.0806) acc 75.0000 (75.1172) kd_loss 0.0393 (0.0507) lr 7.0224e-05 eta 0:04:07
epoch [46/50] batch [260/288] time 0.193 (0.206) data 0.000 (0.001) loss 0.9128 (1.0807) ce_loss 0.7676 (0.9293) teacher_loss 0.7660 (0.9243) loss_zs_kd 0.1179 (0.1517) loss_oracle 0.0878 (0.0806) acc 87.5000 (75.2524) kd_loss 0.0577 (0.0507) lr 7.0224e-05 eta 0:04:02
epoch [46/50] batch [280/288] time 0.187 (0.205) data 0.000 (0.001) loss 1.4394 (1.0839) ce_loss 1.2832 (0.9325) teacher_loss 1.2734 (0.9273) loss_zs_kd 0.1490 (0.1519) loss_oracle 0.0915 (0.0807) acc 65.6250 (75.1674) kd_loss 0.0516 (0.0508) lr 7.0224e-05 eta 0:03:57
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,439
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,012
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.6%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 82.9%, epoch: 44 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [47/50] batch [20/288] time 0.195 (0.207) data 0.000 (0.012) loss 1.3036 (1.1002) ce_loss 1.1621 (0.9486) teacher_loss 1.1531 (0.9422) loss_zs_kd 0.1307 (0.1506) loss_oracle 0.0851 (0.0827) acc 68.7500 (75.1562) kd_loss 0.0482 (0.0527) lr 4.8943e-05 eta 0:03:54
epoch [47/50] batch [40/288] time 0.179 (0.186) data 0.000 (0.006) loss 1.3821 (1.0857) ce_loss 1.2383 (0.9408) teacher_loss 1.2182 (0.9353) loss_zs_kd 0.1320 (0.1430) loss_oracle 0.0979 (0.0789) acc 71.8750 (75.2344) kd_loss 0.0587 (0.0497) lr 4.8943e-05 eta 0:03:27
epoch [47/50] batch [60/288] time 0.477 (0.234) data 0.001 (0.004) loss 1.6670 (1.0884) ce_loss 1.5742 (0.9429) teacher_loss 1.5405 (0.9368) loss_zs_kd 0.1317 (0.1437) loss_oracle 0.0606 (0.0799) acc 62.5000 (75.3646) kd_loss 0.0507 (0.0505) lr 4.8943e-05 eta 0:04:15
epoch [47/50] batch [80/288] time 0.180 (0.226) data 0.000 (0.003) loss 1.1856 (1.0860) ce_loss 1.0459 (0.9373) teacher_loss 1.0553 (0.9310) loss_zs_kd 0.1331 (0.1463) loss_oracle 0.0637 (0.0818) acc 75.0000 (75.6641) kd_loss 0.0410 (0.0510) lr 4.8943e-05 eta 0:04:02
epoch [47/50] batch [100/288] time 0.188 (0.220) data 0.000 (0.003) loss 0.7856 (1.0786) ce_loss 0.6641 (0.9284) teacher_loss 0.6565 (0.9217) loss_zs_kd 0.1010 (0.1478) loss_oracle 0.0785 (0.0830) acc 78.1250 (75.3438) kd_loss 0.0489 (0.0515) lr 4.8943e-05 eta 0:03:51
epoch [47/50] batch [120/288] time 0.188 (0.216) data 0.000 (0.002) loss 1.3682 (1.0683) ce_loss 1.2188 (0.9174) teacher_loss 1.2111 (0.9112) loss_zs_kd 0.1186 (0.1487) loss_oracle 0.0977 (0.0827) acc 75.0000 (75.5729) kd_loss 0.0554 (0.0514) lr 4.8943e-05 eta 0:03:42
epoch [47/50] batch [140/288] time 0.191 (0.213) data 0.000 (0.002) loss 0.8602 (1.0696) ce_loss 0.7114 (0.9182) teacher_loss 0.7103 (0.9120) loss_zs_kd 0.1897 (0.1507) loss_oracle 0.0550 (0.0822) acc 71.8750 (75.4241) kd_loss 0.0348 (0.0510) lr 4.8943e-05 eta 0:03:35
epoch [47/50] batch [160/288] time 0.185 (0.210) data 0.000 (0.002) loss 1.1021 (1.0746) ce_loss 0.9121 (0.9219) teacher_loss 0.9111 (0.9160) loss_zs_kd 0.2389 (0.1525) loss_oracle 0.0716 (0.0824) acc 78.1250 (75.1758) kd_loss 0.0418 (0.0510) lr 4.8943e-05 eta 0:03:28
epoch [47/50] batch [180/288] time 0.191 (0.208) data 0.000 (0.002) loss 1.0338 (1.0770) ce_loss 0.9028 (0.9245) teacher_loss 0.8970 (0.9181) loss_zs_kd 0.1403 (0.1530) loss_oracle 0.0666 (0.0824) acc 68.7500 (74.8958) kd_loss 0.0443 (0.0510) lr 4.8943e-05 eta 0:03:21
epoch [47/50] batch [200/288] time 0.194 (0.206) data 0.000 (0.001) loss 0.5226 (1.0756) ce_loss 0.3916 (0.9238) teacher_loss 0.3940 (0.9176) loss_zs_kd 0.1086 (0.1510) loss_oracle 0.0743 (0.0826) acc 84.3750 (75.0312) kd_loss 0.0456 (0.0510) lr 4.8943e-05 eta 0:03:16
epoch [47/50] batch [220/288] time 0.195 (0.205) data 0.000 (0.001) loss 0.8890 (1.0808) ce_loss 0.7539 (0.9285) teacher_loss 0.7406 (0.9222) loss_zs_kd 0.1537 (0.1520) loss_oracle 0.0716 (0.0826) acc 78.1250 (75.0568) kd_loss 0.0452 (0.0510) lr 4.8943e-05 eta 0:03:11
epoch [47/50] batch [240/288] time 0.192 (0.204) data 0.000 (0.001) loss 0.7640 (1.0800) ce_loss 0.6133 (0.9276) teacher_loss 0.6147 (0.9217) loss_zs_kd 0.1283 (0.1524) loss_oracle 0.0852 (0.0821) acc 84.3750 (75.0521) kd_loss 0.0390 (0.0506) lr 4.8943e-05 eta 0:03:06
epoch [47/50] batch [260/288] time 0.189 (0.203) data 0.000 (0.001) loss 1.5406 (1.0816) ce_loss 1.3184 (0.9289) teacher_loss 1.3319 (0.9232) loss_zs_kd 0.2347 (0.1527) loss_oracle 0.0913 (0.0821) acc 68.7500 (75.0240) kd_loss 0.0636 (0.0506) lr 4.8943e-05 eta 0:03:01
epoch [47/50] batch [280/288] time 0.192 (0.203) data 0.000 (0.001) loss 0.6498 (1.0848) ce_loss 0.5195 (0.9321) teacher_loss 0.5170 (0.9263) loss_zs_kd 0.1171 (0.1531) loss_oracle 0.0743 (0.0820) acc 90.6250 (74.9777) kd_loss 0.0429 (0.0505) lr 4.8943e-05 eta 0:02:56
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,440
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,011
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.6%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 82.9%, epoch: 44 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [48/50] batch [20/288] time 0.512 (0.357) data 0.000 (0.013) loss 1.2097 (1.1607) ce_loss 1.0371 (1.0015) teacher_loss 1.0441 (1.0003) loss_zs_kd 0.1511 (0.1562) loss_oracle 0.0900 (0.0823) acc 62.5000 (71.8750) kd_loss 0.0549 (0.0490) lr 3.1417e-05 eta 0:05:01
epoch [48/50] batch [40/288] time 0.189 (0.271) data 0.000 (0.006) loss 1.4086 (1.1229) ce_loss 1.2354 (0.9706) teacher_loss 1.2321 (0.9672) loss_zs_kd 0.1733 (0.1538) loss_oracle 0.0899 (0.0788) acc 65.6250 (73.6719) kd_loss 0.0563 (0.0478) lr 3.1417e-05 eta 0:03:43
epoch [48/50] batch [60/288] time 0.191 (0.245) data 0.000 (0.004) loss 1.1819 (1.1020) ce_loss 1.0479 (0.9453) teacher_loss 1.0560 (0.9418) loss_zs_kd 0.1411 (0.1618) loss_oracle 0.0554 (0.0794) acc 71.8750 (74.4792) kd_loss 0.0416 (0.0484) lr 3.1417e-05 eta 0:03:17
epoch [48/50] batch [80/288] time 0.190 (0.232) data 0.000 (0.003) loss 1.2522 (1.0963) ce_loss 1.0654 (0.9420) teacher_loss 1.0653 (0.9379) loss_zs_kd 0.1620 (0.1574) loss_oracle 0.1059 (0.0796) acc 75.0000 (74.4141) kd_loss 0.0642 (0.0488) lr 3.1417e-05 eta 0:03:01
epoch [48/50] batch [100/288] time 0.193 (0.224) data 0.000 (0.003) loss 0.9912 (1.0822) ce_loss 0.8638 (0.9293) teacher_loss 0.8592 (0.9248) loss_zs_kd 0.1141 (0.1558) loss_oracle 0.0750 (0.0794) acc 75.0000 (74.6562) kd_loss 0.0470 (0.0490) lr 3.1417e-05 eta 0:02:51
epoch [48/50] batch [120/288] time 0.193 (0.219) data 0.000 (0.002) loss 1.2101 (1.0826) ce_loss 1.0654 (0.9302) teacher_loss 1.0171 (0.9253) loss_zs_kd 0.2083 (0.1547) loss_oracle 0.0888 (0.0799) acc 68.7500 (74.5312) kd_loss 0.0558 (0.0492) lr 3.1417e-05 eta 0:02:43
epoch [48/50] batch [140/288] time 0.188 (0.215) data 0.000 (0.002) loss 0.9786 (1.0820) ce_loss 0.8389 (0.9304) teacher_loss 0.8409 (0.9254) loss_zs_kd 0.1563 (0.1542) loss_oracle 0.0595 (0.0795) acc 81.2500 (74.5536) kd_loss 0.0450 (0.0492) lr 3.1417e-05 eta 0:02:35
epoch [48/50] batch [160/288] time 0.191 (0.213) data 0.000 (0.002) loss 1.1120 (1.0912) ce_loss 0.9756 (0.9392) teacher_loss 0.9679 (0.9334) loss_zs_kd 0.1151 (0.1547) loss_oracle 0.0865 (0.0805) acc 68.7500 (74.3750) kd_loss 0.0587 (0.0496) lr 3.1417e-05 eta 0:02:29
epoch [48/50] batch [180/288] time 0.194 (0.211) data 0.000 (0.002) loss 0.8683 (1.0829) ce_loss 0.7246 (0.9305) teacher_loss 0.7259 (0.9248) loss_zs_kd 0.1412 (0.1554) loss_oracle 0.0719 (0.0804) acc 84.3750 (74.6181) kd_loss 0.0432 (0.0495) lr 3.1417e-05 eta 0:02:24
epoch [48/50] batch [200/288] time 0.188 (0.209) data 0.000 (0.001) loss 0.9047 (1.0828) ce_loss 0.7515 (0.9304) teacher_loss 0.7633 (0.9244) loss_zs_kd 0.1586 (0.1551) loss_oracle 0.0621 (0.0809) acc 84.3750 (74.7031) kd_loss 0.0323 (0.0500) lr 3.1417e-05 eta 0:02:18
epoch [48/50] batch [220/288] time 0.195 (0.208) data 0.000 (0.001) loss 1.0051 (1.0814) ce_loss 0.8398 (0.9285) teacher_loss 0.8238 (0.9223) loss_zs_kd 0.1659 (0.1553) loss_oracle 0.0983 (0.0815) acc 81.2500 (74.8438) kd_loss 0.0633 (0.0504) lr 3.1417e-05 eta 0:02:13
epoch [48/50] batch [240/288] time 0.193 (0.206) data 0.000 (0.001) loss 1.1535 (1.0824) ce_loss 1.0225 (0.9296) teacher_loss 1.0227 (0.9230) loss_zs_kd 0.1373 (0.1555) loss_oracle 0.0621 (0.0817) acc 75.0000 (74.7786) kd_loss 0.0356 (0.0504) lr 3.1417e-05 eta 0:02:08
epoch [48/50] batch [260/288] time 0.192 (0.205) data 0.000 (0.001) loss 1.1027 (1.0800) ce_loss 0.9653 (0.9278) teacher_loss 0.9499 (0.9214) loss_zs_kd 0.1553 (0.1547) loss_oracle 0.0751 (0.0813) acc 78.1250 (74.8317) kd_loss 0.0500 (0.0501) lr 3.1417e-05 eta 0:02:04
epoch [48/50] batch [280/288] time 0.476 (0.207) data 0.000 (0.001) loss 0.9979 (1.0774) ce_loss 0.8188 (0.9252) teacher_loss 0.8070 (0.9188) loss_zs_kd 0.1516 (0.1549) loss_oracle 0.1152 (0.0811) acc 84.3750 (74.9330) kd_loss 0.0758 (0.0498) lr 3.1417e-05 eta 0:02:00
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,437
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,012
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.6%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 82.9%, epoch: 44 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [49/50] batch [20/288] time 0.194 (0.215) data 0.000 (0.015) loss 1.1043 (1.0283) ce_loss 0.9673 (0.8769) teacher_loss 0.9480 (0.8715) loss_zs_kd 0.1352 (0.1567) loss_oracle 0.0887 (0.0784) acc 68.7500 (75.7812) kd_loss 0.0525 (0.0454) lr 1.7713e-05 eta 0:01:59
epoch [49/50] batch [40/288] time 0.194 (0.204) data 0.000 (0.008) loss 1.4495 (1.0504) ce_loss 1.3057 (0.9041) teacher_loss 1.3053 (0.8971) loss_zs_kd 0.1455 (0.1522) loss_oracle 0.0714 (0.0772) acc 59.3750 (75.3125) kd_loss 0.0487 (0.0459) lr 1.7713e-05 eta 0:01:49
epoch [49/50] batch [60/288] time 0.195 (0.200) data 0.000 (0.005) loss 0.6624 (1.0502) ce_loss 0.5195 (0.9003) teacher_loss 0.5211 (0.8938) loss_zs_kd 0.1391 (0.1546) loss_oracle 0.0718 (0.0791) acc 87.5000 (75.7292) kd_loss 0.0517 (0.0475) lr 1.7713e-05 eta 0:01:43
epoch [49/50] batch [80/288] time 0.196 (0.199) data 0.000 (0.004) loss 1.1551 (1.0400) ce_loss 0.9883 (0.8887) teacher_loss 0.9889 (0.8808) loss_zs_kd 0.1512 (0.1552) loss_oracle 0.0907 (0.0816) acc 71.8750 (76.3281) kd_loss 0.0532 (0.0503) lr 1.7713e-05 eta 0:01:38
epoch [49/50] batch [100/288] time 0.190 (0.197) data 0.000 (0.003) loss 0.7120 (1.0554) ce_loss 0.5332 (0.9020) teacher_loss 0.5217 (0.8949) loss_zs_kd 0.1476 (0.1566) loss_oracle 0.1166 (0.0822) acc 90.6250 (76.0312) kd_loss 0.0663 (0.0510) lr 1.7713e-05 eta 0:01:33
epoch [49/50] batch [120/288] time 0.188 (0.197) data 0.000 (0.003) loss 1.1465 (1.0620) ce_loss 0.9966 (0.9089) teacher_loss 0.9929 (0.9019) loss_zs_kd 0.1445 (0.1551) loss_oracle 0.0814 (0.0825) acc 75.0000 (75.8073) kd_loss 0.0455 (0.0515) lr 1.7713e-05 eta 0:01:29
epoch [49/50] batch [140/288] time 0.192 (0.196) data 0.000 (0.002) loss 1.4721 (1.0622) ce_loss 1.2656 (0.9077) teacher_loss 1.2694 (0.9013) loss_zs_kd 0.1987 (0.1563) loss_oracle 0.1033 (0.0828) acc 68.7500 (75.7589) kd_loss 0.0574 (0.0518) lr 1.7713e-05 eta 0:01:25
epoch [49/50] batch [160/288] time 0.198 (0.196) data 0.000 (0.002) loss 0.8560 (1.0585) ce_loss 0.7134 (0.9046) teacher_loss 0.7161 (0.8986) loss_zs_kd 0.1438 (0.1548) loss_oracle 0.0680 (0.0825) acc 81.2500 (75.7812) kd_loss 0.0445 (0.0516) lr 1.7713e-05 eta 0:01:21
epoch [49/50] batch [180/288] time 0.193 (0.196) data 0.000 (0.002) loss 1.3435 (1.0533) ce_loss 1.1416 (0.8992) teacher_loss 1.1586 (0.8936) loss_zs_kd 0.2422 (0.1545) loss_oracle 0.0638 (0.0825) acc 68.7500 (75.9028) kd_loss 0.0278 (0.0514) lr 1.7713e-05 eta 0:01:17
epoch [49/50] batch [200/288] time 0.193 (0.195) data 0.000 (0.002) loss 1.7032 (1.0653) ce_loss 1.5684 (0.9115) teacher_loss 1.5809 (0.9060) loss_zs_kd 0.1537 (0.1545) loss_oracle 0.0454 (0.0821) acc 59.3750 (75.5938) kd_loss 0.0252 (0.0513) lr 1.7713e-05 eta 0:01:13
epoch [49/50] batch [220/288] time 0.192 (0.195) data 0.000 (0.002) loss 1.2575 (1.0712) ce_loss 1.0977 (0.9172) teacher_loss 1.0984 (0.9119) loss_zs_kd 0.1630 (0.1547) loss_oracle 0.0775 (0.0819) acc 68.7500 (75.5540) kd_loss 0.0510 (0.0511) lr 1.7713e-05 eta 0:01:09
epoch [49/50] batch [240/288] time 0.529 (0.197) data 0.000 (0.001) loss 0.7782 (1.0694) ce_loss 0.6250 (0.9155) teacher_loss 0.6302 (0.9103) loss_zs_kd 0.1485 (0.1544) loss_oracle 0.0737 (0.0820) acc 81.2500 (75.6120) kd_loss 0.0525 (0.0512) lr 1.7713e-05 eta 0:01:06
epoch [49/50] batch [260/288] time 0.086 (0.205) data 0.001 (0.001) loss 1.1904 (1.0607) ce_loss 1.0146 (0.9073) teacher_loss 1.0199 (0.9023) loss_zs_kd 0.1779 (0.1533) loss_oracle 0.0815 (0.0817) acc 78.1250 (75.9135) kd_loss 0.0485 (0.0510) lr 1.7713e-05 eta 0:01:04
epoch [49/50] batch [280/288] time 0.191 (0.204) data 0.000 (0.001) loss 0.6930 (1.0538) ce_loss 0.5684 (0.9013) teacher_loss 0.5724 (0.8962) loss_zs_kd 0.1130 (0.1526) loss_oracle 0.0641 (0.0814) acc 84.3750 (75.9375) kd_loss 0.0406 (0.0508) lr 1.7713e-05 eta 0:01:00
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,440
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,011
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.6%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 82.9%, epoch: 44 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
epoch [50/50] batch [20/288] time 0.201 (0.210) data 0.000 (0.013) loss 1.2324 (0.9865) ce_loss 1.0830 (0.8316) teacher_loss 1.0623 (0.8259) loss_zs_kd 0.1192 (0.1532) loss_oracle 0.1105 (0.0839) acc 71.8750 (77.3438) kd_loss 0.0683 (0.0547) lr 7.8853e-06 eta 0:00:56
epoch [50/50] batch [40/288] time 0.194 (0.201) data 0.000 (0.007) loss 1.2086 (1.0513) ce_loss 1.0674 (0.8980) teacher_loss 1.0348 (0.8924) loss_zs_kd 0.1660 (0.1534) loss_oracle 0.0908 (0.0822) acc 68.7500 (75.8594) kd_loss 0.0562 (0.0534) lr 7.8853e-06 eta 0:00:49
epoch [50/50] batch [60/288] time 0.194 (0.199) data 0.000 (0.005) loss 0.9479 (1.0506) ce_loss 0.7925 (0.9005) teacher_loss 0.7802 (0.8950) loss_zs_kd 0.1493 (0.1494) loss_oracle 0.0930 (0.0808) acc 78.1250 (76.0417) kd_loss 0.0646 (0.0517) lr 7.8853e-06 eta 0:00:45
epoch [50/50] batch [80/288] time 0.195 (0.198) data 0.000 (0.003) loss 0.9087 (1.0657) ce_loss 0.7456 (0.9145) teacher_loss 0.7544 (0.9099) loss_zs_kd 0.1301 (0.1505) loss_oracle 0.0893 (0.0806) acc 75.0000 (75.2344) kd_loss 0.0521 (0.0508) lr 7.8853e-06 eta 0:00:41
epoch [50/50] batch [100/288] time 0.198 (0.197) data 0.000 (0.003) loss 1.2974 (1.0832) ce_loss 1.1523 (0.9323) teacher_loss 1.1321 (0.9261) loss_zs_kd 0.1586 (0.1518) loss_oracle 0.0861 (0.0812) acc 75.0000 (75.0625) kd_loss 0.0477 (0.0508) lr 7.8853e-06 eta 0:00:37
epoch [50/50] batch [120/288] time 0.190 (0.196) data 0.000 (0.002) loss 0.9325 (1.0804) ce_loss 0.8101 (0.9293) teacher_loss 0.8011 (0.9234) loss_zs_kd 0.1456 (0.1518) loss_oracle 0.0586 (0.0811) acc 75.0000 (75.1042) kd_loss 0.0404 (0.0506) lr 7.8853e-06 eta 0:00:32
epoch [50/50] batch [140/288] time 0.196 (0.196) data 0.000 (0.002) loss 1.3638 (1.0768) ce_loss 1.1973 (0.9240) teacher_loss 1.1732 (0.9180) loss_zs_kd 0.1780 (0.1549) loss_oracle 0.1015 (0.0813) acc 68.7500 (75.2902) kd_loss 0.0660 (0.0508) lr 7.8853e-06 eta 0:00:28
epoch [50/50] batch [160/288] time 0.188 (0.196) data 0.000 (0.002) loss 0.9677 (1.0659) ce_loss 0.8311 (0.9137) teacher_loss 0.8173 (0.9082) loss_zs_kd 0.1103 (0.1531) loss_oracle 0.0952 (0.0812) acc 78.1250 (75.5273) kd_loss 0.0588 (0.0507) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [180/288] time 0.189 (0.195) data 0.000 (0.002) loss 1.1848 (1.0822) ce_loss 1.0303 (0.9299) teacher_loss 1.0311 (0.9244) loss_zs_kd 0.1638 (0.1537) loss_oracle 0.0719 (0.0809) acc 78.1250 (75.3646) kd_loss 0.0452 (0.0505) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [200/288] time 0.315 (0.201) data 0.000 (0.001) loss 1.2068 (1.0858) ce_loss 1.0762 (0.9337) teacher_loss 1.0598 (0.9282) loss_zs_kd 0.1187 (0.1539) loss_oracle 0.0876 (0.0807) acc 59.3750 (75.3125) kd_loss 0.0510 (0.0500) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [220/288] time 0.200 (0.207) data 0.000 (0.001) loss 0.8126 (1.0819) ce_loss 0.6758 (0.9294) teacher_loss 0.6623 (0.9240) loss_zs_kd 0.1225 (0.1545) loss_oracle 0.0891 (0.0807) acc 71.8750 (75.2415) kd_loss 0.0512 (0.0497) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [240/288] time 0.194 (0.206) data 0.000 (0.001) loss 0.9199 (1.0900) ce_loss 0.7710 (0.9375) teacher_loss 0.7765 (0.9323) loss_zs_kd 0.1201 (0.1542) loss_oracle 0.0833 (0.0807) acc 78.1250 (75.1432) kd_loss 0.0472 (0.0495) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [260/288] time 0.197 (0.205) data 0.000 (0.001) loss 0.7977 (1.0958) ce_loss 0.6616 (0.9431) teacher_loss 0.6548 (0.9380) loss_zs_kd 0.1356 (0.1546) loss_oracle 0.0751 (0.0805) acc 78.1250 (74.9639) kd_loss 0.0464 (0.0492) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [280/288] time 0.191 (0.204) data 0.000 (0.001) loss 1.4370 (1.0910) ce_loss 1.2539 (0.9381) teacher_loss 1.2521 (0.9328) loss_zs_kd 0.1576 (0.1545) loss_oracle 0.1061 (0.0809) acc 59.3750 (75.0781) kd_loss 0.0592 (0.0495) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,440
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,012
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 79.6%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 82.9%, epoch: 44 *******
******* Domain a best test acc:     83.5%, epoch: 4 *******
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:49:44

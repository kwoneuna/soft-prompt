Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------------
Dataset    SPG_OfficeHome
Source     ['clipart', 'product', 'real_world']
Target     ['art']
# classes  65
# train_x  9,222
# val      3,939
# test     2,427
---------  ------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/288] time 0.157 (0.200) data 0.000 (0.019) loss 1.1134 (1.2413) ce_loss 1.1113 (1.2380) teacher_loss 1.1109 (1.2381) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0025 (0.0032) acc 68.7500 (68.2812) kd_loss 0.0097 (0.0128) lr 1.0000e-05 eta 0:47:57
epoch [1/50] batch [40/288] time 0.155 (0.185) data 0.000 (0.010) loss 1.2206 (1.2627) ce_loss 1.2168 (1.2595) teacher_loss 1.2164 (1.2595) loss_zs_kd 0.0002 (0.0000) loss_oracle 0.0041 (0.0032) acc 65.6250 (68.2031) kd_loss 0.0168 (0.0129) lr 1.0000e-05 eta 0:44:10
epoch [1/50] batch [60/288] time 0.152 (0.178) data 0.000 (0.007) loss 1.4309 (1.2694) ce_loss 1.4297 (1.2663) teacher_loss 1.4285 (1.2663) loss_zs_kd 0.0006 (0.0001) loss_oracle 0.0021 (0.0030) acc 59.3750 (67.6042) kd_loss 0.0076 (0.0122) lr 1.0000e-05 eta 0:42:34
epoch [1/50] batch [80/288] time 0.177 (0.175) data 0.002 (0.005) loss 1.2614 (1.2732) ce_loss 1.2578 (1.2704) teacher_loss 1.2569 (1.2703) loss_zs_kd 0.0008 (0.0002) loss_oracle 0.0040 (0.0029) acc 62.5000 (67.3828) kd_loss 0.0158 (0.0115) lr 1.0000e-05 eta 0:41:45
epoch [1/50] batch [100/288] time 0.096 (0.177) data 0.000 (0.004) loss 1.0926 (1.2454) ce_loss 1.0908 (1.2427) teacher_loss 1.0898 (1.2425) loss_zs_kd 0.0005 (0.0003) loss_oracle 0.0025 (0.0027) acc 62.5000 (68.0938) kd_loss 0.0101 (0.0106) lr 1.0000e-05 eta 0:42:07
epoch [1/50] batch [120/288] time 0.149 (0.185) data 0.000 (0.003) loss 1.0349 (1.2390) ce_loss 1.0352 (1.2366) teacher_loss 1.0325 (1.2363) loss_zs_kd 0.0007 (0.0004) loss_oracle 0.0021 (0.0025) acc 75.0000 (68.1510) kd_loss 0.0066 (0.0097) lr 1.0000e-05 eta 0:44:00
epoch [1/50] batch [140/288] time 0.154 (0.181) data 0.000 (0.003) loss 1.4868 (1.2249) ce_loss 1.4863 (1.2226) teacher_loss 1.4844 (1.2224) loss_zs_kd 0.0010 (0.0005) loss_oracle 0.0019 (0.0023) acc 56.2500 (68.2812) kd_loss 0.0050 (0.0090) lr 1.0000e-05 eta 0:43:06
epoch [1/50] batch [160/288] time 0.158 (0.179) data 0.000 (0.003) loss 1.0574 (1.2224) ce_loss 1.0547 (1.2202) teacher_loss 1.0557 (1.2199) loss_zs_kd 0.0019 (0.0006) loss_oracle 0.0008 (0.0022) acc 71.8750 (68.6133) kd_loss 0.0024 (0.0084) lr 1.0000e-05 eta 0:42:26
epoch [1/50] batch [180/288] time 0.161 (0.177) data 0.000 (0.002) loss 0.9956 (1.2259) ce_loss 0.9922 (1.2237) teacher_loss 0.9936 (1.2234) loss_zs_kd 0.0023 (0.0007) loss_oracle 0.0008 (0.0021) acc 71.8750 (68.4375) kd_loss 0.0026 (0.0079) lr 1.0000e-05 eta 0:41:51
epoch [1/50] batch [200/288] time 0.164 (0.175) data 0.000 (0.002) loss 1.3386 (1.2226) ce_loss 1.3379 (1.2205) teacher_loss 1.3370 (1.2202) loss_zs_kd 0.0020 (0.0008) loss_oracle 0.0007 (0.0020) acc 62.5000 (68.3281) kd_loss 0.0028 (0.0075) lr 1.0000e-05 eta 0:41:28
epoch [1/50] batch [220/288] time 0.102 (0.173) data 0.000 (0.002) loss 1.4192 (1.2183) ce_loss 1.4160 (1.2161) teacher_loss 1.4172 (1.2159) loss_zs_kd 0.0022 (0.0010) loss_oracle 0.0009 (0.0019) acc 65.6250 (68.5938) kd_loss 0.0028 (0.0070) lr 1.0000e-05 eta 0:40:57
epoch [1/50] batch [240/288] time 0.360 (0.176) data 0.000 (0.002) loss 0.9869 (1.2158) ce_loss 0.9849 (1.2137) teacher_loss 0.9854 (1.2135) loss_zs_kd 0.0010 (0.0011) loss_oracle 0.0010 (0.0018) acc 81.2500 (68.8542) kd_loss 0.0038 (0.0067) lr 1.0000e-05 eta 0:41:39
epoch [1/50] batch [260/288] time 0.150 (0.177) data 0.000 (0.002) loss 1.3066 (1.2215) ce_loss 1.3037 (1.2193) teacher_loss 1.3031 (1.2191) loss_zs_kd 0.0053 (0.0012) loss_oracle 0.0009 (0.0017) acc 71.8750 (68.7019) kd_loss 0.0024 (0.0064) lr 1.0000e-05 eta 0:41:48
epoch [1/50] batch [280/288] time 0.159 (0.176) data 0.000 (0.002) loss 1.5228 (1.2214) ce_loss 1.5186 (1.2192) teacher_loss 1.5193 (1.2190) loss_zs_kd 0.0052 (0.0014) loss_oracle 0.0009 (0.0017) acc 62.5000 (68.7612) kd_loss 0.0027 (0.0061) lr 1.0000e-05 eta 0:41:24
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,264
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 81.9%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,963
* accuracy: 80.9%
* error: 19.1%
* macro_f1: 76.6%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      82.9%, epoch: 1 *******
******* Domain a best val test acc: 80.9%, epoch: 1 *******
******* Domain a best test acc:     80.9%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/ana

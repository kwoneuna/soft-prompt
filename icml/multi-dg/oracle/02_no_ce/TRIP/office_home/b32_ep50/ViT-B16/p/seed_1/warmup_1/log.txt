Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'clipart', 'real_world']
Target     ['product']
# classes  65
# train_x  7,815
# val      3,334
# test     4,439
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/244] time 0.108 (0.161) data 0.000 (0.020) loss 1.4317 (1.4267) ce_loss 1.4297 (1.4243) teacher_loss 1.4285 (1.4243) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0032 (0.0024) acc 62.5000 (65.0000) kd_loss 0.0126 (0.0098) lr 1.0000e-05 eta 0:32:40
epoch [1/50] batch [40/244] time 0.115 (0.139) data 0.000 (0.010) loss 1.5012 (1.3965) ce_loss 1.4980 (1.3939) teacher_loss 1.4992 (1.3940) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0020 (0.0025) acc 56.2500 (65.2344) kd_loss 0.0079 (0.0101) lr 1.0000e-05 eta 0:28:13
epoch [1/50] batch [60/244] time 0.109 (0.130) data 0.002 (0.007) loss 1.3195 (1.4301) ce_loss 1.3184 (1.4277) teacher_loss 1.3182 (1.4277) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0012 (0.0023) acc 65.6250 (64.0104) kd_loss 0.0049 (0.0093) lr 1.0000e-05 eta 0:26:14
epoch [1/50] batch [80/244] time 0.099 (0.123) data 0.001 (0.005) loss 1.5659 (1.4359) ce_loss 1.5654 (1.4337) teacher_loss 1.5646 (1.4337) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0011 (0.0021) acc 59.3750 (63.9844) kd_loss 0.0043 (0.0085) lr 1.0000e-05 eta 0:24:49
epoch [1/50] batch [100/244] time 0.100 (0.119) data 0.000 (0.004) loss 1.5576 (1.4164) ce_loss 1.5557 (1.4144) teacher_loss 1.5554 (1.4144) loss_zs_kd 0.0006 (0.0002) loss_oracle 0.0019 (0.0019) acc 62.5000 (64.1875) kd_loss 0.0071 (0.0077) lr 1.0000e-05 eta 0:23:55
epoch [1/50] batch [120/244] time 0.100 (0.116) data 0.000 (0.004) loss 0.9579 (1.4020) ce_loss 0.9565 (1.4001) teacher_loss 0.9567 (1.4001) loss_zs_kd 0.0005 (0.0002) loss_oracle 0.0010 (0.0018) acc 75.0000 (64.5573) kd_loss 0.0039 (0.0071) lr 1.0000e-05 eta 0:23:21
epoch [1/50] batch [140/244] time 0.104 (0.114) data 0.001 (0.003) loss 1.0928 (1.3832) ce_loss 1.0908 (1.3815) teacher_loss 1.0914 (1.3815) loss_zs_kd 0.0007 (0.0003) loss_oracle 0.0010 (0.0016) acc 75.0000 (65.0000) kd_loss 0.0040 (0.0065) lr 1.0000e-05 eta 0:22:54
epoch [1/50] batch [160/244] time 0.100 (0.112) data 0.000 (0.003) loss 1.4831 (1.3748) ce_loss 1.4814 (1.3731) teacher_loss 1.4815 (1.3731) loss_zs_kd 0.0016 (0.0004) loss_oracle 0.0008 (0.0015) acc 56.2500 (65.1367) kd_loss 0.0029 (0.0060) lr 1.0000e-05 eta 0:22:31
epoch [1/50] batch [180/244] time 0.104 (0.111) data 0.000 (0.003) loss 0.9852 (1.3742) ce_loss 0.9834 (1.3725) teacher_loss 0.9837 (1.3725) loss_zs_kd 0.0010 (0.0005) loss_oracle 0.0011 (0.0014) acc 81.2500 (65.1910) kd_loss 0.0041 (0.0057) lr 1.0000e-05 eta 0:22:15
epoch [1/50] batch [200/244] time 0.105 (0.110) data 0.000 (0.002) loss 1.4865 (1.3734) ce_loss 1.4844 (1.3717) teacher_loss 1.4848 (1.3717) loss_zs_kd 0.0013 (0.0007) loss_oracle 0.0011 (0.0014) acc 62.5000 (65.2344) kd_loss 0.0041 (0.0054) lr 1.0000e-05 eta 0:22:04
epoch [1/50] batch [220/244] time 0.103 (0.110) data 0.000 (0.002) loss 1.2263 (1.3700) ce_loss 1.2227 (1.3683) teacher_loss 1.2226 (1.3683) loss_zs_kd 0.0063 (0.0008) loss_oracle 0.0006 (0.0013) acc 68.7500 (65.2557) kd_loss 0.0021 (0.0052) lr 1.0000e-05 eta 0:21:52
epoch [1/50] batch [240/244] time 0.102 (0.109) data 0.000 (0.002) loss 1.3157 (1.3666) ce_loss 1.3135 (1.3649) teacher_loss 1.3137 (1.3649) loss_zs_kd 0.0016 (0.0009) loss_oracle 0.0012 (0.0013) acc 75.0000 (65.4557) kd_loss 0.0042 (0.0050) lr 1.0000e-05 eta 0:21:42
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,673
* accuracy: 80.2%
* error: 19.8%
* macro_f1: 78.6%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,943
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 87.9%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      80.2%, epoch: 1 *******
******* Domain p best val test acc: 88.8%, epoch: 1 *******
******* Domain p best test acc:     88.8%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/ana
epoch [2/50] batch [20/244] time 0.098 (0.122) data 0.000 (0.016) loss 1.0386 (1.4210) ce_loss 1.0000 (1.3728) teacher_loss 0.9998 (1.3729) loss_zs_kd 0.0726 (0.0918) loss_oracle 0.0026 (0.0022) acc 75.0000 (63.9062) kd_loss 0.0021 (0.0027) lr 2.0000e-03 eta 0:24:11
epoch [2/50] batch [40/244] time 0.096 (0.111) data 0.000 (0.008) loss 1.1303 (1.3476) ce_loss 1.0977 (1.3023) teacher_loss 1.0983 (1.3024) loss_zs_kd 0.0525 (0.0838) loss_oracle 0.0058 (0.0033) acc 71.8750 (66.4844) kd_loss 0.0017 (0.0026) lr 2.0000e-03 eta 0:22:08
epoch [2/50] batch [60/244] time 0.097 (0.108) data 0.001 (0.006) loss 1.4568 (1.3885) ce_loss 1.3818 (1.3359) teacher_loss 1.3835 (1.3363) loss_zs_kd 0.0845 (0.0805) loss_oracle 0.0311 (0.0120) acc 62.5000 (65.2604) kd_loss 0.0077 (0.0030) lr 2.0000e-03 eta 0:21:21
epoch [2/50] batch [80/244] time 0.105 (0.106) data 0.000 (0.004) loss 1.1357 (1.3395) ce_loss 1.0801 (1.2846) teacher_loss 1.0795 (1.2851) loss_zs_kd 0.1017 (0.0839) loss_oracle 0.0053 (0.0125) acc 68.7500 (66.2500) kd_loss 0.0048 (0.0036) lr 2.0000e-03 eta 0:20:59
epoch [2/50] batch [100/244] time 0.100 (0.105) data 0.000 (0.003) loss 0.9505 (1.3249) ce_loss 0.9136 (1.2707) teacher_loss 0.9137 (1.2714) loss_zs_kd 0.0626 (0.0850) loss_oracle 0.0055 (0.0111) acc 71.8750 (66.9062) kd_loss 0.0034 (0.0040) lr 2.0000e-03 eta 0:20:43
epoch [2/50] batch [120/244] time 0.099 (0.104) data 0.000 (0.003) loss 1.7207 (1.3025) ce_loss 1.6768 (1.2501) teacher_loss 1.6759 (1.2507) loss_zs_kd 0.0753 (0.0830) loss_oracle 0.0072 (0.0102) acc 62.5000 (67.7083) kd_loss 0.0061 (0.0042) lr 2.0000e-03 eta 0:20:34
epoch [2/50] batch [140/244] time 0.103 (0.104) data 0.000 (0.003) loss 1.0413 (1.2969) ce_loss 0.9829 (1.2438) teacher_loss 0.9833 (1.2444) loss_zs_kd 0.0975 (0.0854) loss_oracle 0.0093 (0.0098) acc 75.0000 (67.9911) kd_loss 0.0059 (0.0043) lr 2.0000e-03 eta 0:20:26
epoch [2/50] batch [160/244] time 0.097 (0.103) data 0.000 (0.002) loss 1.2222 (1.3030) ce_loss 1.1787 (1.2501) teacher_loss 1.1791 (1.2507) loss_zs_kd 0.0626 (0.0855) loss_oracle 0.0117 (0.0096) acc 68.7500 (67.8125) kd_loss 0.0056 (0.0045) lr 2.0000e-03 eta 0:20:17
epoch [2/50] batch [180/244] time 0.093 (0.102) data 0.000 (0.002) loss 1.1298 (1.2898) ce_loss 1.0723 (1.2363) teacher_loss 1.0729 (1.2369) loss_zs_kd 0.0825 (0.0860) loss_oracle 0.0157 (0.0098) acc 71.8750 (68.1250) kd_loss 0.0048 (0.0047) lr 2.0000e-03 eta 0:20:06
epoch [2/50] batch [200/244] time 0.096 (0.102) data 0.001 (0.002) loss 1.4286 (1.3006) ce_loss 1.3799 (1.2452) teacher_loss 1.3816 (1.2459) loss_zs_kd 0.0689 (0.0889) loss_oracle 0.0125 (0.0103) acc 65.6250 (67.8125) kd_loss 0.0074 (0.0048) lr 2.0000e-03 eta 0:19:56
epoch [2/50] batch [220/244] time 0.094 (0.101) data 0.000 (0.002) loss 1.1600 (1.2958) ce_loss 1.0771 (1.2399) teacher_loss 1.0772 (1.2407) loss_zs_kd 0.1359 (0.0893) loss_oracle 0.0148 (0.0104) acc 75.0000 (67.8267) kd_loss 0.0056 (0.0048) lr 2.0000e-03 eta 0:19:47
epoch [2/50] batch [240/244] time 0.087 (0.100) data 0.000 (0.002) loss 1.5049 (1.2954) ce_loss 1.4121 (1.2388) teacher_loss 1.4126 (1.2396) loss_zs_kd 0.1641 (0.0905) loss_oracle 0.0103 (0.0106) acc 65.6250 (67.6693) kd_loss 0.0056 (0.0049) lr 2.0000e-03 eta 0:19:36
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,780
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 82.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,030
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.2%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.4%, epoch: 2 *******
******* Domain p best val test acc: 90.8%, epoch: 2 *******
******* Domain p best test acc:     90.8%, epoch: 2 *******
epoch [3/50] batch [20/244] time 0.090 (0.109) data 0.000 (0.014) loss 1.2844 (1.2834) ce_loss 1.1953 (1.2034) teacher_loss 1.1980 (1.2044) loss_zs_kd 0.1410 (0.1320) loss_oracle 0.0159 (0.0130) acc 65.6250 (69.5312) kd_loss 0.0106 (0.0072) lr 1.9980e-03 eta 0:21:18
epoch [3/50] batch [40/244] time 0.112 (0.106) data 0.001 (0.007) loss 0.8453 (1.2794) ce_loss 0.7847 (1.2100) teacher_loss 0.7866 (1.2105) loss_zs_kd 0.0969 (0.1125) loss_oracle 0.0103 (0.0126) acc 68.7500 (69.3750) kd_loss 0.0065 (0.0071) lr 1.9980e-03 eta 0:20:39
epoch [3/50] batch [60/244] time 0.105 (0.105) data 0.001 (0.005) loss 0.7334 (1.2441) ce_loss 0.6714 (1.1795) teacher_loss 0.6724 (1.1800) loss_zs_kd 0.1021 (0.1051) loss_oracle 0.0100 (0.0116) acc 84.3750 (69.7396) kd_loss 0.0052 (0.0073) lr 1.9980e-03 eta 0:20:22
epoch [3/50] batch [80/244] time 0.099 (0.104) data 0.000 (0.004) loss 1.5744 (1.2871) ce_loss 1.5273 (1.2206) teacher_loss 1.5292 (1.2207) loss_zs_kd 0.0693 (0.1089) loss_oracle 0.0105 (0.0120) acc 65.6250 (68.6719) kd_loss 0.0060 (0.0075) lr 1.9980e-03 eta 0:20:10
epoch [3/50] batch [100/244] time 0.101 (0.104) data 0.000 (0.003) loss 1.7345 (1.2751) ce_loss 1.6445 (1.2100) teacher_loss 1.6429 (1.2101) loss_zs_kd 0.1524 (0.1059) loss_oracle 0.0155 (0.0121) acc 56.2500 (69.0312) kd_loss 0.0106 (0.0076) lr 1.9980e-03 eta 0:20:05
epoch [3/50] batch [120/244] time 0.105 (0.103) data 0.000 (0.003) loss 0.9205 (1.2750) ce_loss 0.8198 (1.2093) teacher_loss 0.8210 (1.2094) loss_zs_kd 0.1614 (0.1069) loss_oracle 0.0188 (0.0121) acc 75.0000 (68.8542) kd_loss 0.0092 (0.0078) lr 1.9980e-03 eta 0:19:55
epoch [3/50] batch [140/244] time 0.101 (0.103) data 0.000 (0.002) loss 1.3403 (1.2649) ce_loss 1.2686 (1.1979) teacher_loss 1.2655 (1.1981) loss_zs_kd 0.1184 (0.1091) loss_oracle 0.0155 (0.0122) acc 68.7500 (69.1518) kd_loss 0.0090 (0.0078) lr 1.9980e-03 eta 0:19:53
epoch [3/50] batch [160/244] time 0.098 (0.103) data 0.000 (0.002) loss 1.2439 (1.2754) ce_loss 1.1875 (1.2090) teacher_loss 1.1872 (1.2094) loss_zs_kd 0.0813 (0.1075) loss_oracle 0.0161 (0.0123) acc 68.7500 (68.9062) kd_loss 0.0080 (0.0078) lr 1.9980e-03 eta 0:19:46
epoch [3/50] batch [180/244] time 0.096 (0.102) data 0.000 (0.002) loss 0.9792 (1.2680) ce_loss 0.9009 (1.2019) teacher_loss 0.9027 (1.2022) loss_zs_kd 0.1141 (0.1068) loss_oracle 0.0196 (0.0124) acc 75.0000 (69.1667) kd_loss 0.0093 (0.0078) lr 1.9980e-03 eta 0:19:40
epoch [3/50] batch [200/244] time 0.100 (0.102) data 0.000 (0.002) loss 1.4307 (1.2672) ce_loss 1.3574 (1.1998) teacher_loss 1.3460 (1.2003) loss_zs_kd 0.1184 (0.1080) loss_oracle 0.0255 (0.0130) acc 62.5000 (69.1250) kd_loss 0.0136 (0.0078) lr 1.9980e-03 eta 0:19:38
epoch [3/50] batch [220/244] time 0.098 (0.102) data 0.000 (0.002) loss 1.3852 (1.2722) ce_loss 1.3115 (1.2039) teacher_loss 1.3131 (1.2044) loss_zs_kd 0.1268 (0.1087) loss_oracle 0.0087 (0.0134) acc 75.0000 (69.1761) kd_loss 0.0074 (0.0079) lr 1.9980e-03 eta 0:19:33
epoch [3/50] batch [240/244] time 0.107 (0.102) data 0.000 (0.001) loss 0.9274 (1.2692) ce_loss 0.8838 (1.2008) teacher_loss 0.8840 (1.2012) loss_zs_kd 0.0712 (0.1091) loss_oracle 0.0077 (0.0134) acc 71.8750 (69.2448) kd_loss 0.0056 (0.0080) lr 1.9980e-03 eta 0:19:33
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,784
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,033
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.5%, epoch: 3 *******
******* Domain p best val test acc: 90.9%, epoch: 3 *******
******* Domain p best test acc:     90.9%, epoch: 3 *******
epoch [4/50] batch [20/244] time 0.096 (0.109) data 0.000 (0.014) loss 1.6043 (1.2956) ce_loss 1.5488 (1.2208) teacher_loss 1.5428 (1.2216) loss_zs_kd 0.0899 (0.1209) loss_oracle 0.0165 (0.0136) acc 59.3750 (67.1875) kd_loss 0.0118 (0.0094) lr 1.9921e-03 eta 0:20:52
epoch [4/50] batch [40/244] time 0.093 (0.101) data 0.000 (0.007) loss 0.8512 (1.2571) ce_loss 0.7720 (1.1867) teacher_loss 0.7744 (1.1879) loss_zs_kd 0.1349 (0.1129) loss_oracle 0.0094 (0.0128) acc 84.3750 (68.4375) kd_loss 0.0069 (0.0089) lr 1.9921e-03 eta 0:19:17
epoch [4/50] batch [60/244] time 0.103 (0.099) data 0.000 (0.005) loss 1.5026 (1.2331) ce_loss 1.4229 (1.1617) teacher_loss 1.4214 (1.1630) loss_zs_kd 0.1269 (0.1139) loss_oracle 0.0178 (0.0132) acc 56.2500 (69.4271) kd_loss 0.0116 (0.0091) lr 1.9921e-03 eta 0:18:48
epoch [4/50] batch [80/244] time 0.100 (0.099) data 0.001 (0.004) loss 1.9393 (1.2372) ce_loss 1.8467 (1.1638) teacher_loss 1.8401 (1.1646) loss_zs_kd 0.1616 (0.1187) loss_oracle 0.0184 (0.0132) acc 46.8750 (69.5312) kd_loss 0.0124 (0.0092) lr 1.9921e-03 eta 0:18:44
epoch [4/50] batch [100/244] time 0.095 (0.098) data 0.000 (0.003) loss 1.4149 (1.2602) ce_loss 1.3486 (1.1858) teacher_loss 1.3497 (1.1863) loss_zs_kd 0.1069 (0.1214) loss_oracle 0.0118 (0.0133) acc 65.6250 (68.9375) kd_loss 0.0067 (0.0091) lr 1.9921e-03 eta 0:18:37
epoch [4/50] batch [120/244] time 0.096 (0.098) data 0.000 (0.003) loss 1.0703 (1.2716) ce_loss 0.9976 (1.1972) teacher_loss 1.0038 (1.1976) loss_zs_kd 0.1029 (0.1212) loss_oracle 0.0151 (0.0135) acc 81.2500 (68.9844) kd_loss 0.0072 (0.0090) lr 1.9921e-03 eta 0:18:29
epoch [4/50] batch [140/244] time 0.119 (0.099) data 0.000 (0.002) loss 0.9123 (1.2565) ce_loss 0.8418 (1.1827) teacher_loss 0.8445 (1.1830) loss_zs_kd 0.1018 (0.1200) loss_oracle 0.0169 (0.0135) acc 78.1250 (69.2857) kd_loss 0.0106 (0.0089) lr 1.9921e-03 eta 0:18:40
epoch [4/50] batch [160/244] time 0.100 (0.100) data 0.000 (0.002) loss 1.0605 (1.2602) ce_loss 0.9961 (1.1852) teacher_loss 0.9954 (1.1855) loss_zs_kd 0.0989 (0.1217) loss_oracle 0.0156 (0.0138) acc 71.8750 (68.8867) kd_loss 0.0080 (0.0089) lr 1.9921e-03 eta 0:18:46
epoch [4/50] batch [180/244] time 0.101 (0.100) data 0.000 (0.002) loss 0.7412 (1.2448) ce_loss 0.6777 (1.1699) teacher_loss 0.6783 (1.1702) loss_zs_kd 0.1047 (0.1211) loss_oracle 0.0105 (0.0140) acc 81.2500 (69.5139) kd_loss 0.0077 (0.0089) lr 1.9921e-03 eta 0:18:51
epoch [4/50] batch [200/244] time 0.098 (0.101) data 0.000 (0.002) loss 1.4132 (1.2420) ce_loss 1.3525 (1.1674) teacher_loss 1.3501 (1.1676) loss_zs_kd 0.0959 (0.1207) loss_oracle 0.0152 (0.0141) acc 71.8750 (69.4688) kd_loss 0.0091 (0.0088) lr 1.9921e-03 eta 0:18:53
epoch [4/50] batch [220/244] time 0.099 (0.101) data 0.000 (0.002) loss 1.8664 (1.2339) ce_loss 1.7949 (1.1586) teacher_loss 1.7929 (1.1588) loss_zs_kd 0.1068 (0.1212) loss_oracle 0.0200 (0.0145) acc 59.3750 (69.6307) kd_loss 0.0111 (0.0087) lr 1.9921e-03 eta 0:18:54
epoch [4/50] batch [240/244] time 0.103 (0.101) data 0.000 (0.001) loss 1.4652 (1.2328) ce_loss 1.4092 (1.1577) teacher_loss 1.4008 (1.1579) loss_zs_kd 0.0886 (0.1205) loss_oracle 0.0201 (0.0146) acc 59.3750 (69.6745) kd_loss 0.0090 (0.0087) lr 1.9921e-03 eta 0:18:56
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,793
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.7%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.8%, epoch: 4 *******
******* Domain p best val test acc: 90.9%, epoch: 4 *******
******* Domain p best test acc:     90.9%, epoch: 4 *******
epoch [5/50] batch [20/244] time 0.104 (0.110) data 0.000 (0.013) loss 1.4560 (1.2984) ce_loss 1.3965 (1.2102) teacher_loss 1.3947 (1.2117) loss_zs_kd 0.0881 (0.1350) loss_oracle 0.0172 (0.0192) acc 62.5000 (67.0312) kd_loss 0.0097 (0.0090) lr 1.9823e-03 eta 0:20:30
epoch [5/50] batch [40/244] time 0.097 (0.101) data 0.000 (0.007) loss 1.1549 (1.1998) ce_loss 1.0635 (1.1173) teacher_loss 1.0673 (1.1185) loss_zs_kd 0.1344 (0.1260) loss_oracle 0.0204 (0.0183) acc 71.8750 (70.0000) kd_loss 0.0081 (0.0090) lr 1.9823e-03 eta 0:18:49
epoch [5/50] batch [60/244] time 0.102 (0.099) data 0.001 (0.004) loss 1.1654 (1.2002) ce_loss 1.0771 (1.1177) teacher_loss 1.0771 (1.1188) loss_zs_kd 0.1392 (0.1240) loss_oracle 0.0187 (0.0194) acc 68.7500 (69.6875) kd_loss 0.0105 (0.0091) lr 1.9823e-03 eta 0:18:22
epoch [5/50] batch [80/244] time 0.103 (0.098) data 0.000 (0.003) loss 1.4444 (1.2001) ce_loss 1.3623 (1.1161) teacher_loss 1.3589 (1.1171) loss_zs_kd 0.1355 (0.1278) loss_oracle 0.0177 (0.0191) acc 65.6250 (70.7422) kd_loss 0.0096 (0.0093) lr 1.9823e-03 eta 0:18:11
epoch [5/50] batch [100/244] time 0.095 (0.097) data 0.000 (0.003) loss 1.6307 (1.2057) ce_loss 1.5674 (1.1230) teacher_loss 1.5672 (1.1238) loss_zs_kd 0.0911 (0.1264) loss_oracle 0.0179 (0.0186) acc 65.6250 (70.4688) kd_loss 0.0101 (0.0094) lr 1.9823e-03 eta 0:18:01
epoch [5/50] batch [120/244] time 0.094 (0.097) data 0.000 (0.002) loss 1.1424 (1.2223) ce_loss 1.0635 (1.1394) teacher_loss 1.0594 (1.1399) loss_zs_kd 0.1246 (0.1272) loss_oracle 0.0207 (0.0188) acc 75.0000 (69.9740) kd_loss 0.0115 (0.0097) lr 1.9823e-03 eta 0:17:53
epoch [5/50] batch [140/244] time 0.091 (0.097) data 0.001 (0.002) loss 1.3513 (1.2200) ce_loss 1.2734 (1.1377) teacher_loss 1.2641 (1.1380) loss_zs_kd 0.1238 (0.1266) loss_oracle 0.0253 (0.0188) acc 62.5000 (70.0893) kd_loss 0.0169 (0.0098) lr 1.9823e-03 eta 0:17:50
epoch [5/50] batch [160/244] time 0.101 (0.097) data 0.000 (0.002) loss 1.0400 (1.2293) ce_loss 0.9600 (1.1484) teacher_loss 0.9615 (1.1485) loss_zs_kd 0.1071 (0.1242) loss_oracle 0.0250 (0.0187) acc 78.1250 (69.6875) kd_loss 0.0106 (0.0098) lr 1.9823e-03 eta 0:17:47
epoch [5/50] batch [180/244] time 0.102 (0.097) data 0.000 (0.002) loss 1.5469 (1.2288) ce_loss 1.4346 (1.1478) teacher_loss 1.4365 (1.1479) loss_zs_kd 0.1679 (0.1234) loss_oracle 0.0265 (0.0192) acc 68.7500 (69.9132) kd_loss 0.0119 (0.0099) lr 1.9823e-03 eta 0:17:47
epoch [5/50] batch [200/244] time 0.092 (0.096) data 0.000 (0.002) loss 1.2245 (1.2275) ce_loss 1.1523 (1.1466) teacher_loss 1.1552 (1.1468) loss_zs_kd 0.1069 (0.1231) loss_oracle 0.0159 (0.0192) acc 75.0000 (69.9062) kd_loss 0.0086 (0.0099) lr 1.9823e-03 eta 0:17:43
epoch [5/50] batch [220/244] time 0.097 (0.097) data 0.000 (0.001) loss 1.5653 (1.2287) ce_loss 1.4326 (1.1474) teacher_loss 1.4286 (1.1474) loss_zs_kd 0.2315 (0.1243) loss_oracle 0.0210 (0.0191) acc 56.2500 (69.9432) kd_loss 0.0132 (0.0100) lr 1.9823e-03 eta 0:17:42
epoch [5/50] batch [240/244] time 0.085 (0.096) data 0.000 (0.001) loss 1.5652 (1.2275) ce_loss 1.4287 (1.1463) teacher_loss 1.4244 (1.1463) loss_zs_kd 0.2372 (0.1241) loss_oracle 0.0222 (0.0191) acc 68.7500 (70.0391) kd_loss 0.0117 (0.0100) lr 1.9823e-03 eta 0:17:34
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,792
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 82.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,046
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.8%, epoch: 4 *******
******* Domain p best val test acc: 90.9%, epoch: 4 *******
******* Domain p best test acc:     91.1%, epoch: 5 *******
epoch [6/50] batch [20/244] time 0.095 (0.113) data 0.000 (0.014) loss 1.3792 (1.1872) ce_loss 1.3066 (1.1065) teacher_loss 1.3037 (1.1057) loss_zs_kd 0.1140 (0.1235) loss_oracle 0.0185 (0.0197) acc 71.8750 (71.0938) kd_loss 0.0100 (0.0101) lr 1.9686e-03 eta 0:20:43
epoch [6/50] batch [40/244] time 0.096 (0.104) data 0.000 (0.007) loss 1.3969 (1.2239) ce_loss 1.3203 (1.1407) teacher_loss 1.3242 (1.1403) loss_zs_kd 0.1097 (0.1268) loss_oracle 0.0178 (0.0202) acc 68.7500 (70.4688) kd_loss 0.0075 (0.0101) lr 1.9686e-03 eta 0:19:00
epoch [6/50] batch [60/244] time 0.089 (0.101) data 0.000 (0.005) loss 1.4957 (1.2269) ce_loss 1.3789 (1.1453) teacher_loss 1.3781 (1.1451) loss_zs_kd 0.1803 (0.1230) loss_oracle 0.0274 (0.0203) acc 65.6250 (70.6250) kd_loss 0.0112 (0.0101) lr 1.9686e-03 eta 0:18:25
epoch [6/50] batch [80/244] time 0.101 (0.100) data 0.001 (0.004) loss 1.1018 (1.2278) ce_loss 1.0234 (1.1458) teacher_loss 1.0248 (1.1456) loss_zs_kd 0.1146 (0.1220) loss_oracle 0.0196 (0.0212) acc 71.8750 (70.2734) kd_loss 0.0077 (0.0102) lr 1.9686e-03 eta 0:18:09
epoch [6/50] batch [100/244] time 0.092 (0.099) data 0.000 (0.003) loss 1.5550 (1.2241) ce_loss 1.4697 (1.1429) teacher_loss 1.4672 (1.1428) loss_zs_kd 0.1235 (0.1201) loss_oracle 0.0261 (0.0212) acc 53.1250 (70.1562) kd_loss 0.0148 (0.0103) lr 1.9686e-03 eta 0:17:57
epoch [6/50] batch [120/244] time 0.090 (0.098) data 0.000 (0.003) loss 1.3480 (1.2267) ce_loss 1.2461 (1.1456) teacher_loss 1.2473 (1.1457) loss_zs_kd 0.1525 (0.1201) loss_oracle 0.0245 (0.0209) acc 62.5000 (70.0781) kd_loss 0.0115 (0.0102) lr 1.9686e-03 eta 0:17:48
epoch [6/50] batch [140/244] time 0.106 (0.098) data 0.001 (0.002) loss 1.5531 (1.2411) ce_loss 1.4766 (1.1575) teacher_loss 1.4761 (1.1576) loss_zs_kd 0.1076 (0.1238) loss_oracle 0.0232 (0.0216) acc 62.5000 (69.7768) kd_loss 0.0093 (0.0102) lr 1.9686e-03 eta 0:17:47
epoch [6/50] batch [160/244] time 0.096 (0.099) data 0.000 (0.002) loss 0.9020 (1.2414) ce_loss 0.8008 (1.1568) teacher_loss 0.8017 (1.1570) loss_zs_kd 0.1490 (0.1250) loss_oracle 0.0259 (0.0220) acc 75.0000 (69.7461) kd_loss 0.0116 (0.0102) lr 1.9686e-03 eta 0:17:46
epoch [6/50] batch [180/244] time 0.097 (0.099) data 0.000 (0.002) loss 1.0242 (1.2424) ce_loss 0.9111 (1.1565) teacher_loss 0.9117 (1.1568) loss_zs_kd 0.1718 (0.1265) loss_oracle 0.0265 (0.0223) acc 75.0000 (69.8438) kd_loss 0.0120 (0.0104) lr 1.9686e-03 eta 0:17:46
epoch [6/50] batch [200/244] time 0.097 (0.099) data 0.000 (0.002) loss 1.3239 (1.2441) ce_loss 1.2227 (1.1579) teacher_loss 1.2193 (1.1582) loss_zs_kd 0.1663 (0.1267) loss_oracle 0.0215 (0.0225) acc 71.8750 (69.7656) kd_loss 0.0113 (0.0105) lr 1.9686e-03 eta 0:17:44
epoch [6/50] batch [220/244] time 0.096 (0.099) data 0.000 (0.002) loss 1.3483 (1.2474) ce_loss 1.2568 (1.1613) teacher_loss 1.2493 (1.1615) loss_zs_kd 0.1381 (0.1275) loss_oracle 0.0300 (0.0222) acc 68.7500 (69.6591) kd_loss 0.0148 (0.0106) lr 1.9686e-03 eta 0:17:42
epoch [6/50] batch [240/244] time 0.090 (0.099) data 0.000 (0.001) loss 1.4143 (1.2408) ce_loss 1.3291 (1.1550) teacher_loss 1.3273 (1.1553) loss_zs_kd 0.1322 (0.1265) loss_oracle 0.0210 (0.0223) acc 56.2500 (69.7266) kd_loss 0.0134 (0.0106) lr 1.9686e-03 eta 0:17:39
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,798
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,030
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.2%
******* Domain p best val acc:      83.9%, epoch: 6 *******
******* Domain p best val test acc: 90.8%, epoch: 6 *******
******* Domain p best test acc:     91.1%, epoch: 5 *******
epoch [7/50] batch [20/244] time 0.091 (0.111) data 0.000 (0.013) loss 1.1804 (1.3319) ce_loss 1.0957 (1.2433) teacher_loss 1.0971 (1.2435) loss_zs_kd 0.1182 (0.1236) loss_oracle 0.0242 (0.0266) acc 68.7500 (66.4062) kd_loss 0.0096 (0.0117) lr 1.9511e-03 eta 0:19:45
epoch [7/50] batch [40/244] time 0.092 (0.102) data 0.000 (0.007) loss 1.0172 (1.2618) ce_loss 0.9312 (1.1746) teacher_loss 0.9296 (1.1749) loss_zs_kd 0.1211 (0.1215) loss_oracle 0.0271 (0.0261) acc 75.0000 (68.5156) kd_loss 0.0141 (0.0113) lr 1.9511e-03 eta 0:18:08
epoch [7/50] batch [60/244] time 0.090 (0.100) data 0.000 (0.005) loss 0.8955 (1.2732) ce_loss 0.8174 (1.1845) teacher_loss 0.8147 (1.1851) loss_zs_kd 0.0944 (0.1204) loss_oracle 0.0336 (0.0279) acc 75.0000 (67.6042) kd_loss 0.0157 (0.0120) lr 1.9511e-03 eta 0:17:42
epoch [7/50] batch [80/244] time 0.092 (0.099) data 0.000 (0.003) loss 1.2515 (1.2590) ce_loss 1.0996 (1.1689) teacher_loss 1.1001 (1.1698) loss_zs_kd 0.2412 (0.1240) loss_oracle 0.0308 (0.0272) acc 68.7500 (68.1250) kd_loss 0.0132 (0.0122) lr 1.9511e-03 eta 0:17:32
epoch [7/50] batch [100/244] time 0.093 (0.098) data 0.000 (0.003) loss 1.5598 (1.2487) ce_loss 1.4121 (1.1591) teacher_loss 1.4165 (1.1599) loss_zs_kd 0.2230 (0.1252) loss_oracle 0.0319 (0.0262) acc 62.5000 (68.7500) kd_loss 0.0195 (0.0123) lr 1.9511e-03 eta 0:17:22
epoch [7/50] batch [120/244] time 0.096 (0.098) data 0.000 (0.002) loss 1.2510 (1.2537) ce_loss 1.1797 (1.1637) teacher_loss 1.1810 (1.1643) loss_zs_kd 0.1012 (0.1263) loss_oracle 0.0193 (0.0262) acc 65.6250 (68.9323) kd_loss 0.0102 (0.0126) lr 1.9511e-03 eta 0:17:18
epoch [7/50] batch [140/244] time 0.104 (0.098) data 0.000 (0.002) loss 0.8612 (1.2418) ce_loss 0.7402 (1.1520) teacher_loss 0.7441 (1.1523) loss_zs_kd 0.1574 (0.1263) loss_oracle 0.0384 (0.0264) acc 78.1250 (69.2634) kd_loss 0.0189 (0.0128) lr 1.9511e-03 eta 0:17:15
epoch [7/50] batch [160/244] time 0.098 (0.097) data 0.000 (0.002) loss 1.7298 (1.2441) ce_loss 1.6182 (1.1542) teacher_loss 1.6178 (1.1546) loss_zs_kd 0.1765 (0.1265) loss_oracle 0.0238 (0.0263) acc 62.5000 (69.3164) kd_loss 0.0113 (0.0129) lr 1.9511e-03 eta 0:17:10
epoch [7/50] batch [180/244] time 0.099 (0.097) data 0.000 (0.002) loss 1.1061 (1.2506) ce_loss 1.0000 (1.1597) teacher_loss 0.9989 (1.1601) loss_zs_kd 0.1551 (0.1284) loss_oracle 0.0296 (0.0264) acc 75.0000 (69.2535) kd_loss 0.0178 (0.0129) lr 1.9511e-03 eta 0:17:07
epoch [7/50] batch [200/244] time 0.094 (0.097) data 0.000 (0.001) loss 1.0974 (1.2450) ce_loss 1.0098 (1.1528) teacher_loss 1.0106 (1.1531) loss_zs_kd 0.1237 (0.1296) loss_oracle 0.0250 (0.0271) acc 68.7500 (69.5469) kd_loss 0.0166 (0.0131) lr 1.9511e-03 eta 0:17:04
epoch [7/50] batch [220/244] time 0.098 (0.097) data 0.000 (0.001) loss 1.3190 (1.2507) ce_loss 1.2119 (1.1573) teacher_loss 1.2176 (1.1577) loss_zs_kd 0.1541 (0.1312) loss_oracle 0.0243 (0.0273) acc 75.0000 (69.4744) kd_loss 0.0102 (0.0133) lr 1.9511e-03 eta 0:17:02
epoch [7/50] batch [240/244] time 0.085 (0.097) data 0.000 (0.001) loss 1.0700 (1.2412) ce_loss 0.9478 (1.1486) teacher_loss 0.9476 (1.1490) loss_zs_kd 0.1797 (0.1298) loss_oracle 0.0326 (0.0273) acc 78.1250 (69.7917) kd_loss 0.0175 (0.0134) lr 1.9511e-03 eta 0:16:55
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,785
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,024
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.1%
******* Domain p best val acc:      83.9%, epoch: 6 *******
******* Domain p best val test acc: 90.8%, epoch: 6 *******
******* Domain p best test acc:     91.1%, epoch: 5 *******
epoch [8/50] batch [20/244] time 0.095 (0.117) data 0.000 (0.014) loss 1.3869 (1.3245) ce_loss 1.2939 (1.2294) teacher_loss 1.2969 (1.2297) loss_zs_kd 0.1208 (0.1250) loss_oracle 0.0296 (0.0323) acc 65.6250 (66.0938) kd_loss 0.0128 (0.0148) lr 1.9298e-03 eta 0:20:28
epoch [8/50] batch [40/244] time 0.114 (0.110) data 0.000 (0.007) loss 1.1367 (1.2545) ce_loss 1.0391 (1.1517) teacher_loss 1.0371 (1.1519) loss_zs_kd 0.1373 (0.1368) loss_oracle 0.0309 (0.0342) acc 71.8750 (68.6719) kd_loss 0.0115 (0.0146) lr 1.9298e-03 eta 0:19:07
epoch [8/50] batch [60/244] time 0.097 (0.106) data 0.001 (0.005) loss 1.1041 (1.2431) ce_loss 0.9922 (1.1427) teacher_loss 0.9967 (1.1428) loss_zs_kd 0.1489 (0.1344) loss_oracle 0.0329 (0.0331) acc 78.1250 (69.2188) kd_loss 0.0166 (0.0147) lr 1.9298e-03 eta 0:18:28
epoch [8/50] batch [80/244] time 0.098 (0.105) data 0.000 (0.004) loss 1.3610 (1.2318) ce_loss 1.2227 (1.1323) teacher_loss 1.2204 (1.1325) loss_zs_kd 0.1997 (0.1367) loss_oracle 0.0408 (0.0309) acc 68.7500 (69.4141) kd_loss 0.0218 (0.0145) lr 1.9298e-03 eta 0:18:12
epoch [8/50] batch [100/244] time 0.099 (0.104) data 0.000 (0.003) loss 1.0396 (1.2433) ce_loss 0.9595 (1.1444) teacher_loss 0.9617 (1.1445) loss_zs_kd 0.1074 (0.1371) loss_oracle 0.0243 (0.0303) acc 75.0000 (68.9375) kd_loss 0.0103 (0.0143) lr 1.9298e-03 eta 0:18:02
epoch [8/50] batch [120/244] time 0.101 (0.104) data 0.000 (0.003) loss 1.0855 (1.2328) ce_loss 1.0078 (1.1348) teacher_loss 1.0090 (1.1349) loss_zs_kd 0.1151 (0.1381) loss_oracle 0.0189 (0.0288) acc 75.0000 (69.3229) kd_loss 0.0134 (0.0140) lr 1.9298e-03 eta 0:17:55
epoch [8/50] batch [140/244] time 0.102 (0.103) data 0.000 (0.002) loss 1.5918 (1.2472) ce_loss 1.4834 (1.1509) teacher_loss 1.4829 (1.1509) loss_zs_kd 0.1435 (0.1366) loss_oracle 0.0371 (0.0280) acc 65.6250 (69.2634) kd_loss 0.0193 (0.0141) lr 1.9298e-03 eta 0:17:50
epoch [8/50] batch [160/244] time 0.099 (0.103) data 0.000 (0.002) loss 1.4818 (1.2377) ce_loss 1.3818 (1.1422) teacher_loss 1.3800 (1.1423) loss_zs_kd 0.1494 (0.1362) loss_oracle 0.0270 (0.0273) acc 65.6250 (69.5508) kd_loss 0.0125 (0.0139) lr 1.9298e-03 eta 0:17:49
epoch [8/50] batch [180/244] time 0.109 (0.104) data 0.000 (0.002) loss 1.0570 (1.2320) ce_loss 0.9399 (1.1374) teacher_loss 0.9383 (1.1374) loss_zs_kd 0.1815 (0.1353) loss_oracle 0.0280 (0.0270) acc 78.1250 (69.8264) kd_loss 0.0139 (0.0138) lr 1.9298e-03 eta 0:17:49
epoch [8/50] batch [200/244] time 0.097 (0.103) data 0.000 (0.002) loss 1.2547 (1.2331) ce_loss 1.1855 (1.1398) teacher_loss 1.1885 (1.1396) loss_zs_kd 0.0963 (0.1336) loss_oracle 0.0180 (0.0267) acc 75.0000 (70.0938) kd_loss 0.0105 (0.0137) lr 1.9298e-03 eta 0:17:41
epoch [8/50] batch [220/244] time 0.096 (0.103) data 0.000 (0.001) loss 1.2263 (1.2305) ce_loss 1.1504 (1.1380) teacher_loss 1.1458 (1.1379) loss_zs_kd 0.1147 (0.1328) loss_oracle 0.0231 (0.0263) acc 62.5000 (70.0284) kd_loss 0.0126 (0.0137) lr 1.9298e-03 eta 0:17:38
epoch [8/50] batch [240/244] time 0.102 (0.103) data 0.000 (0.001) loss 1.4381 (1.2343) ce_loss 1.3477 (1.1420) teacher_loss 1.3448 (1.1419) loss_zs_kd 0.1326 (0.1324) loss_oracle 0.0270 (0.0263) acc 65.6250 (69.9740) kd_loss 0.0100 (0.0136) lr 1.9298e-03 eta 0:17:33
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,801
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.0%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.0%, epoch: 8 *******
******* Domain p best val test acc: 90.9%, epoch: 8 *******
******* Domain p best test acc:     91.1%, epoch: 5 *******
epoch [9/50] batch [20/244] time 0.096 (0.117) data 0.000 (0.014) loss 1.5289 (1.3839) ce_loss 1.4365 (1.2740) teacher_loss 1.4316 (1.2730) loss_zs_kd 0.1182 (0.1441) loss_oracle 0.0382 (0.0388) acc 62.5000 (68.9062) kd_loss 0.0131 (0.0144) lr 1.9048e-03 eta 0:19:56
epoch [9/50] batch [40/244] time 0.095 (0.106) data 0.000 (0.007) loss 1.3197 (1.2849) ce_loss 1.2539 (1.1832) teacher_loss 1.2552 (1.1830) loss_zs_kd 0.0793 (0.1296) loss_oracle 0.0248 (0.0371) acc 62.5000 (70.3125) kd_loss 0.0134 (0.0147) lr 1.9048e-03 eta 0:18:06
epoch [9/50] batch [60/244] time 0.090 (0.103) data 0.000 (0.005) loss 1.7783 (1.2760) ce_loss 1.6670 (1.1739) teacher_loss 1.6662 (1.1740) loss_zs_kd 0.1602 (0.1339) loss_oracle 0.0319 (0.0350) acc 59.3750 (70.3125) kd_loss 0.0140 (0.0143) lr 1.9048e-03 eta 0:17:30
epoch [9/50] batch [80/244] time 0.090 (0.100) data 0.000 (0.004) loss 1.7072 (1.2867) ce_loss 1.6172 (1.1811) teacher_loss 1.6142 (1.1808) loss_zs_kd 0.0932 (0.1372) loss_oracle 0.0464 (0.0373) acc 59.3750 (69.7656) kd_loss 0.0160 (0.0148) lr 1.9048e-03 eta 0:17:01
epoch [9/50] batch [100/244] time 0.099 (0.099) data 0.000 (0.003) loss 1.0485 (1.2751) ce_loss 0.9570 (1.1681) teacher_loss 0.9549 (1.1679) loss_zs_kd 0.1113 (0.1357) loss_oracle 0.0379 (0.0393) acc 65.6250 (69.8125) kd_loss 0.0155 (0.0155) lr 1.9048e-03 eta 0:16:45
epoch [9/50] batch [120/244] time 0.101 (0.098) data 0.000 (0.003) loss 1.6412 (1.2769) ce_loss 1.5557 (1.1694) teacher_loss 1.5510 (1.1693) loss_zs_kd 0.1000 (0.1357) loss_oracle 0.0402 (0.0397) acc 59.3750 (69.6354) kd_loss 0.0161 (0.0159) lr 1.9048e-03 eta 0:16:37
epoch [9/50] batch [140/244] time 0.090 (0.098) data 0.000 (0.002) loss 1.0628 (1.2869) ce_loss 0.9902 (1.1798) teacher_loss 0.9942 (1.1794) loss_zs_kd 0.0813 (0.1351) loss_oracle 0.0279 (0.0400) acc 71.8750 (69.2411) kd_loss 0.0127 (0.0165) lr 1.9048e-03 eta 0:16:31
epoch [9/50] batch [160/244] time 0.096 (0.098) data 0.000 (0.002) loss 0.7885 (1.2742) ce_loss 0.6880 (1.1668) teacher_loss 0.6893 (1.1662) loss_zs_kd 0.1190 (0.1362) loss_oracle 0.0397 (0.0399) acc 81.2500 (69.6484) kd_loss 0.0148 (0.0167) lr 1.9048e-03 eta 0:16:25
epoch [9/50] batch [180/244] time 0.094 (0.097) data 0.000 (0.002) loss 1.3695 (1.2680) ce_loss 1.2393 (1.1603) teacher_loss 1.2378 (1.1596) loss_zs_kd 0.1690 (0.1365) loss_oracle 0.0472 (0.0401) acc 68.7500 (69.5486) kd_loss 0.0206 (0.0171) lr 1.9048e-03 eta 0:16:20
epoch [9/50] batch [200/244] time 0.092 (0.097) data 0.000 (0.002) loss 1.3189 (1.2685) ce_loss 1.2158 (1.1590) teacher_loss 1.2187 (1.1585) loss_zs_kd 0.1131 (0.1383) loss_oracle 0.0437 (0.0408) acc 65.6250 (69.5781) kd_loss 0.0224 (0.0174) lr 1.9048e-03 eta 0:16:16
epoch [9/50] batch [220/244] time 0.095 (0.097) data 0.001 (0.001) loss 1.5558 (1.2678) ce_loss 1.4209 (1.1577) teacher_loss 1.4192 (1.1572) loss_zs_kd 0.1845 (0.1382) loss_oracle 0.0445 (0.0414) acc 71.8750 (69.6591) kd_loss 0.0186 (0.0177) lr 1.9048e-03 eta 0:16:12
epoch [9/50] batch [240/244] time 0.086 (0.097) data 0.000 (0.001) loss 1.5532 (1.2655) ce_loss 1.4307 (1.1545) teacher_loss 1.4348 (1.1540) loss_zs_kd 0.1687 (0.1391) loss_oracle 0.0341 (0.0420) acc 65.6250 (69.8177) kd_loss 0.0162 (0.0180) lr 1.9048e-03 eta 0:16:06
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,790
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 82.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,027
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.3%
******* Domain p best val acc:      84.0%, epoch: 8 *******
******* Domain p best val test acc: 90.9%, epoch: 8 *******
******* Domain p best test acc:     91.1%, epoch: 5 *******
epoch [10/50] batch [20/244] time 0.086 (0.108) data 0.000 (0.014) loss 1.1097 (1.1787) ce_loss 1.0186 (1.0788) teacher_loss 1.0184 (1.0792) loss_zs_kd 0.1083 (0.1249) loss_oracle 0.0371 (0.0371) acc 65.6250 (71.0938) kd_loss 0.0214 (0.0196) lr 1.8763e-03 eta 0:17:54
epoch [10/50] batch [40/244] time 0.096 (0.099) data 0.000 (0.007) loss 1.1365 (1.1925) ce_loss 1.0068 (1.0868) teacher_loss 1.0054 (1.0867) loss_zs_kd 0.1757 (0.1382) loss_oracle 0.0432 (0.0367) acc 81.2500 (71.1719) kd_loss 0.0230 (0.0203) lr 1.8763e-03 eta 0:16:30
epoch [10/50] batch [60/244] time 0.086 (0.096) data 0.000 (0.005) loss 1.2711 (1.2018) ce_loss 1.1738 (1.0966) teacher_loss 1.1776 (1.0968) loss_zs_kd 0.1141 (0.1359) loss_oracle 0.0364 (0.0371) acc 71.8750 (70.8854) kd_loss 0.0186 (0.0197) lr 1.8763e-03 eta 0:15:50
epoch [10/50] batch [80/244] time 0.091 (0.095) data 0.000 (0.004) loss 1.2249 (1.2246) ce_loss 1.1309 (1.1194) teacher_loss 1.1292 (1.1194) loss_zs_kd 0.1050 (0.1331) loss_oracle 0.0431 (0.0386) acc 65.6250 (70.3125) kd_loss 0.0172 (0.0196) lr 1.8763e-03 eta 0:15:45
epoch [10/50] batch [100/244] time 0.093 (0.095) data 0.000 (0.003) loss 1.3490 (1.2370) ce_loss 1.2354 (1.1300) teacher_loss 1.2367 (1.1301) loss_zs_kd 0.1513 (0.1357) loss_oracle 0.0366 (0.0391) acc 65.6250 (70.1562) kd_loss 0.0204 (0.0195) lr 1.8763e-03 eta 0:15:42
epoch [10/50] batch [120/244] time 0.099 (0.095) data 0.000 (0.002) loss 1.5214 (1.2477) ce_loss 1.4287 (1.1377) teacher_loss 1.4238 (1.1380) loss_zs_kd 0.1269 (0.1395) loss_oracle 0.0341 (0.0400) acc 65.6250 (69.9479) kd_loss 0.0150 (0.0196) lr 1.8763e-03 eta 0:15:39
epoch [10/50] batch [140/244] time 0.094 (0.095) data 0.000 (0.002) loss 1.1388 (1.2521) ce_loss 1.0449 (1.1420) teacher_loss 1.0456 (1.1422) loss_zs_kd 0.1071 (0.1407) loss_oracle 0.0396 (0.0395) acc 71.8750 (69.6875) kd_loss 0.0252 (0.0198) lr 1.8763e-03 eta 0:15:39
epoch [10/50] batch [160/244] time 0.103 (0.095) data 0.000 (0.002) loss 0.9439 (1.2380) ce_loss 0.8779 (1.1282) teacher_loss 0.8734 (1.1283) loss_zs_kd 0.0714 (0.1404) loss_oracle 0.0348 (0.0394) acc 75.0000 (70.0977) kd_loss 0.0161 (0.0196) lr 1.8763e-03 eta 0:15:36
epoch [10/50] batch [180/244] time 0.096 (0.095) data 0.000 (0.002) loss 1.3801 (1.2343) ce_loss 1.2803 (1.1250) teacher_loss 1.2786 (1.1250) loss_zs_kd 0.1208 (0.1400) loss_oracle 0.0411 (0.0393) acc 75.0000 (70.2604) kd_loss 0.0185 (0.0193) lr 1.8763e-03 eta 0:15:34
epoch [10/50] batch [200/244] time 0.094 (0.095) data 0.000 (0.002) loss 1.2669 (1.2471) ce_loss 1.1729 (1.1379) teacher_loss 1.1719 (1.1378) loss_zs_kd 0.1238 (0.1405) loss_oracle 0.0331 (0.0391) acc 65.6250 (69.9531) kd_loss 0.0140 (0.0191) lr 1.8763e-03 eta 0:15:34
epoch [10/50] batch [220/244] time 0.096 (0.095) data 0.000 (0.001) loss 1.1408 (1.2549) ce_loss 1.0029 (1.1461) teacher_loss 0.9995 (1.1458) loss_zs_kd 0.1939 (0.1403) loss_oracle 0.0444 (0.0390) acc 81.2500 (69.9148) kd_loss 0.0181 (0.0190) lr 1.8763e-03 eta 0:15:34
epoch [10/50] batch [240/244] time 0.085 (0.095) data 0.000 (0.001) loss 1.6618 (1.2576) ce_loss 1.5410 (1.1487) teacher_loss 1.5414 (1.1485) loss_zs_kd 0.1769 (0.1409) loss_oracle 0.0320 (0.0386) acc 59.3750 (69.7917) kd_loss 0.0127 (0.0188) lr 1.8763e-03 eta 0:15:29
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,805
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.0%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,048
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.7%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      84.1%, epoch: 10 *******
******* Domain p best val test acc: 91.2%, epoch: 10 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [11/50] batch [20/244] time 0.096 (0.111) data 0.000 (0.014) loss 0.8863 (1.2231) ce_loss 0.8032 (1.1244) teacher_loss 0.8069 (1.1246) loss_zs_kd 0.0990 (0.1274) loss_oracle 0.0299 (0.0348) acc 75.0000 (70.9375) kd_loss 0.0169 (0.0175) lr 1.8443e-03 eta 0:17:59
epoch [11/50] batch [40/244] time 0.097 (0.103) data 0.000 (0.007) loss 1.2373 (1.2280) ce_loss 1.1348 (1.1265) teacher_loss 1.1305 (1.1256) loss_zs_kd 0.1280 (0.1317) loss_oracle 0.0429 (0.0365) acc 75.0000 (70.6250) kd_loss 0.0161 (0.0176) lr 1.8443e-03 eta 0:16:43
epoch [11/50] batch [60/244] time 0.098 (0.101) data 0.000 (0.005) loss 1.0400 (1.2324) ce_loss 0.9565 (1.1288) teacher_loss 0.9594 (1.1283) loss_zs_kd 0.1156 (0.1350) loss_oracle 0.0228 (0.0365) acc 75.0000 (70.7292) kd_loss 0.0106 (0.0177) lr 1.8443e-03 eta 0:16:23
epoch [11/50] batch [80/244] time 0.091 (0.099) data 0.000 (0.004) loss 1.1662 (1.2263) ce_loss 1.0850 (1.1243) teacher_loss 1.0831 (1.1235) loss_zs_kd 0.1210 (0.1341) loss_oracle 0.0226 (0.0357) acc 68.7500 (70.7812) kd_loss 0.0097 (0.0175) lr 1.8443e-03 eta 0:16:01
epoch [11/50] batch [100/244] time 0.093 (0.098) data 0.000 (0.003) loss 1.1880 (1.2098) ce_loss 1.0576 (1.1066) teacher_loss 1.0632 (1.1059) loss_zs_kd 0.1443 (0.1344) loss_oracle 0.0527 (0.0367) acc 71.8750 (70.7500) kd_loss 0.0244 (0.0177) lr 1.8443e-03 eta 0:15:48
epoch [11/50] batch [120/244] time 0.097 (0.098) data 0.000 (0.002) loss 1.0514 (1.2240) ce_loss 0.9673 (1.1195) teacher_loss 0.9737 (1.1189) loss_zs_kd 0.0932 (0.1369) loss_oracle 0.0311 (0.0367) acc 78.1250 (70.7031) kd_loss 0.0151 (0.0177) lr 1.8443e-03 eta 0:15:41
epoch [11/50] batch [140/244] time 0.102 (0.097) data 0.000 (0.002) loss 0.6370 (1.2266) ce_loss 0.5762 (1.1241) teacher_loss 0.5780 (1.1237) loss_zs_kd 0.0722 (0.1346) loss_oracle 0.0229 (0.0357) acc 84.3750 (70.5804) kd_loss 0.0120 (0.0176) lr 1.8443e-03 eta 0:15:35
epoch [11/50] batch [160/244] time 0.097 (0.098) data 0.000 (0.002) loss 1.1790 (1.2356) ce_loss 1.0605 (1.1341) teacher_loss 1.0570 (1.1333) loss_zs_kd 0.1704 (0.1348) loss_oracle 0.0368 (0.0349) acc 75.0000 (70.4102) kd_loss 0.0227 (0.0176) lr 1.8443e-03 eta 0:15:36
epoch [11/50] batch [180/244] time 0.100 (0.098) data 0.000 (0.002) loss 1.1500 (1.2301) ce_loss 1.0586 (1.1285) teacher_loss 1.0611 (1.1277) loss_zs_kd 0.1134 (0.1347) loss_oracle 0.0322 (0.0350) acc 75.0000 (70.3993) kd_loss 0.0118 (0.0175) lr 1.8443e-03 eta 0:15:39
epoch [11/50] batch [200/244] time 0.099 (0.098) data 0.000 (0.002) loss 1.3137 (1.2288) ce_loss 1.2402 (1.1275) teacher_loss 1.2381 (1.1266) loss_zs_kd 0.0754 (0.1345) loss_oracle 0.0379 (0.0350) acc 68.7500 (70.3750) kd_loss 0.0160 (0.0174) lr 1.8443e-03 eta 0:15:41
epoch [11/50] batch [220/244] time 0.096 (0.099) data 0.000 (0.001) loss 0.6923 (1.2158) ce_loss 0.5864 (1.1143) teacher_loss 0.5878 (1.1134) loss_zs_kd 0.0948 (0.1341) loss_oracle 0.0570 (0.0354) acc 90.6250 (70.8239) kd_loss 0.0207 (0.0172) lr 1.8443e-03 eta 0:15:40
epoch [11/50] batch [240/244] time 0.103 (0.099) data 0.000 (0.001) loss 0.9785 (1.2170) ce_loss 0.8613 (1.1151) teacher_loss 0.8613 (1.1142) loss_zs_kd 0.1622 (0.1340) loss_oracle 0.0360 (0.0358) acc 75.0000 (70.8464) kd_loss 0.0162 (0.0172) lr 1.8443e-03 eta 0:15:41
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,807
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.1%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.2%, epoch: 11 *******
******* Domain p best val test acc: 91.1%, epoch: 11 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [12/50] batch [20/244] time 0.094 (0.109) data 0.000 (0.014) loss 1.3873 (1.1640) ce_loss 1.2334 (1.0468) teacher_loss 1.2360 (1.0456) loss_zs_kd 0.1956 (0.1443) loss_oracle 0.0535 (0.0462) acc 65.6250 (72.0312) kd_loss 0.0253 (0.0193) lr 1.8090e-03 eta 0:17:19
epoch [12/50] batch [40/244] time 0.093 (0.101) data 0.000 (0.007) loss 1.0918 (1.1913) ce_loss 0.9863 (1.0734) teacher_loss 0.9895 (1.0740) loss_zs_kd 0.1384 (0.1472) loss_oracle 0.0330 (0.0438) acc 78.1250 (71.7969) kd_loss 0.0172 (0.0183) lr 1.8090e-03 eta 0:15:59
epoch [12/50] batch [60/244] time 0.094 (0.100) data 0.000 (0.005) loss 1.1492 (1.2108) ce_loss 1.0625 (1.0982) teacher_loss 1.0635 (1.0984) loss_zs_kd 0.0953 (0.1433) loss_oracle 0.0380 (0.0407) acc 68.7500 (71.7708) kd_loss 0.0175 (0.0179) lr 1.8090e-03 eta 0:15:42
epoch [12/50] batch [80/244] time 0.102 (0.099) data 0.000 (0.004) loss 0.9695 (1.2300) ce_loss 0.8755 (1.1182) teacher_loss 0.8739 (1.1184) loss_zs_kd 0.1170 (0.1448) loss_oracle 0.0371 (0.0392) acc 78.1250 (71.1719) kd_loss 0.0182 (0.0174) lr 1.8090e-03 eta 0:15:37
epoch [12/50] batch [100/244] time 0.092 (0.099) data 0.000 (0.003) loss 1.3608 (1.2273) ce_loss 1.2598 (1.1160) teacher_loss 1.2599 (1.1160) loss_zs_kd 0.1470 (0.1451) loss_oracle 0.0274 (0.0387) acc 62.5000 (70.7500) kd_loss 0.0158 (0.0174) lr 1.8090e-03 eta 0:15:28
epoch [12/50] batch [120/244] time 0.093 (0.098) data 0.000 (0.003) loss 1.1196 (1.2287) ce_loss 0.9688 (1.1178) teacher_loss 0.9702 (1.1178) loss_zs_kd 0.2157 (0.1443) loss_oracle 0.0415 (0.0388) acc 71.8750 (70.5990) kd_loss 0.0194 (0.0173) lr 1.8090e-03 eta 0:15:25
epoch [12/50] batch [140/244] time 0.102 (0.098) data 0.000 (0.002) loss 1.5950 (1.2460) ce_loss 1.4648 (1.1334) teacher_loss 1.4675 (1.1335) loss_zs_kd 0.1442 (0.1459) loss_oracle 0.0554 (0.0396) acc 56.2500 (70.1786) kd_loss 0.0222 (0.0172) lr 1.8090e-03 eta 0:15:22
epoch [12/50] batch [160/244] time 0.092 (0.098) data 0.000 (0.002) loss 1.3735 (1.2382) ce_loss 1.2764 (1.1256) teacher_loss 1.2757 (1.1257) loss_zs_kd 0.1402 (0.1451) loss_oracle 0.0277 (0.0399) acc 65.6250 (70.3320) kd_loss 0.0132 (0.0174) lr 1.8090e-03 eta 0:15:18
epoch [12/50] batch [180/244] time 0.107 (0.098) data 0.000 (0.002) loss 1.4544 (1.2409) ce_loss 1.3057 (1.1289) teacher_loss 1.3036 (1.1289) loss_zs_kd 0.2250 (0.1457) loss_oracle 0.0383 (0.0391) acc 68.7500 (70.3819) kd_loss 0.0186 (0.0174) lr 1.8090e-03 eta 0:15:14
epoch [12/50] batch [200/244] time 0.097 (0.098) data 0.000 (0.002) loss 1.3461 (1.2342) ce_loss 1.2305 (1.1230) teacher_loss 1.2271 (1.1228) loss_zs_kd 0.1614 (0.1453) loss_oracle 0.0383 (0.0387) acc 62.5000 (70.5000) kd_loss 0.0217 (0.0176) lr 1.8090e-03 eta 0:15:11
epoch [12/50] batch [220/244] time 0.104 (0.098) data 0.000 (0.002) loss 1.4268 (1.2350) ce_loss 1.3408 (1.1237) teacher_loss 1.3382 (1.1236) loss_zs_kd 0.1091 (0.1462) loss_oracle 0.0341 (0.0383) acc 62.5000 (70.4403) kd_loss 0.0149 (0.0174) lr 1.8090e-03 eta 0:15:10
epoch [12/50] batch [240/244] time 0.086 (0.097) data 0.000 (0.001) loss 0.9960 (1.2296) ce_loss 0.9131 (1.1185) teacher_loss 0.9066 (1.1183) loss_zs_kd 0.1073 (0.1460) loss_oracle 0.0357 (0.0383) acc 78.1250 (70.5729) kd_loss 0.0155 (0.0174) lr 1.8090e-03 eta 0:15:04
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,794
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.2%, epoch: 11 *******
******* Domain p best val test acc: 91.1%, epoch: 11 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [13/50] batch [20/244] time 0.098 (0.119) data 0.000 (0.013) loss 0.8209 (1.1469) ce_loss 0.7051 (1.0391) teacher_loss 0.7079 (1.0387) loss_zs_kd 0.1322 (0.1348) loss_oracle 0.0469 (0.0408) acc 84.3750 (72.0312) kd_loss 0.0173 (0.0186) lr 1.7705e-03 eta 0:18:17
epoch [13/50] batch [40/244] time 0.094 (0.108) data 0.000 (0.007) loss 1.1043 (1.1809) ce_loss 0.9839 (1.0714) teacher_loss 0.9861 (1.0706) loss_zs_kd 0.1562 (0.1381) loss_oracle 0.0401 (0.0412) acc 81.2500 (71.0938) kd_loss 0.0187 (0.0192) lr 1.7705e-03 eta 0:16:33
epoch [13/50] batch [60/244] time 0.102 (0.104) data 0.000 (0.005) loss 1.1378 (1.1968) ce_loss 1.0293 (1.0895) teacher_loss 1.0309 (1.0890) loss_zs_kd 0.1758 (0.1384) loss_oracle 0.0190 (0.0386) acc 75.0000 (70.9375) kd_loss 0.0136 (0.0189) lr 1.7705e-03 eta 0:15:59
epoch [13/50] batch [80/244] time 0.090 (0.102) data 0.000 (0.004) loss 1.8030 (1.2270) ce_loss 1.6777 (1.1185) teacher_loss 1.6778 (1.1178) loss_zs_kd 0.1536 (0.1415) loss_oracle 0.0483 (0.0385) acc 53.1250 (70.2734) kd_loss 0.0196 (0.0188) lr 1.7705e-03 eta 0:15:35
epoch [13/50] batch [100/244] time 0.102 (0.101) data 0.000 (0.003) loss 1.6446 (1.2334) ce_loss 1.5635 (1.1240) teacher_loss 1.5653 (1.1235) loss_zs_kd 0.1044 (0.1422) loss_oracle 0.0271 (0.0388) acc 59.3750 (70.2500) kd_loss 0.0123 (0.0185) lr 1.7705e-03 eta 0:15:25
epoch [13/50] batch [120/244] time 0.097 (0.100) data 0.000 (0.002) loss 1.3498 (1.2295) ce_loss 1.2373 (1.1211) teacher_loss 1.2329 (1.1206) loss_zs_kd 0.1366 (0.1402) loss_oracle 0.0486 (0.0388) acc 68.7500 (70.5729) kd_loss 0.0251 (0.0187) lr 1.7705e-03 eta 0:15:16
epoch [13/50] batch [140/244] time 0.093 (0.100) data 0.000 (0.002) loss 1.6711 (1.2425) ce_loss 1.5293 (1.1322) teacher_loss 1.5298 (1.1316) loss_zs_kd 0.1843 (0.1430) loss_oracle 0.0492 (0.0394) acc 65.6250 (70.5580) kd_loss 0.0232 (0.0187) lr 1.7705e-03 eta 0:15:09
epoch [13/50] batch [160/244] time 0.100 (0.099) data 0.000 (0.002) loss 1.6343 (1.2319) ce_loss 1.5117 (1.1218) teacher_loss 1.5065 (1.1214) loss_zs_kd 0.1349 (0.1403) loss_oracle 0.0604 (0.0404) acc 65.6250 (70.7227) kd_loss 0.0231 (0.0188) lr 1.7705e-03 eta 0:15:05
epoch [13/50] batch [180/244] time 0.101 (0.099) data 0.000 (0.002) loss 1.3292 (1.2368) ce_loss 1.2070 (1.1263) teacher_loss 1.2075 (1.1257) loss_zs_kd 0.1708 (0.1404) loss_oracle 0.0363 (0.0408) acc 78.1250 (70.6076) kd_loss 0.0203 (0.0188) lr 1.7705e-03 eta 0:15:01
epoch [13/50] batch [200/244] time 0.091 (0.099) data 0.000 (0.002) loss 1.2203 (1.2387) ce_loss 1.1152 (1.1290) teacher_loss 1.1138 (1.1286) loss_zs_kd 0.1367 (0.1395) loss_oracle 0.0382 (0.0403) acc 71.8750 (70.5000) kd_loss 0.0217 (0.0188) lr 1.7705e-03 eta 0:14:57
epoch [13/50] batch [220/244] time 0.100 (0.099) data 0.000 (0.001) loss 0.7233 (1.2291) ce_loss 0.5806 (1.1204) teacher_loss 0.5827 (1.1200) loss_zs_kd 0.2078 (0.1391) loss_oracle 0.0368 (0.0396) acc 87.5000 (70.7812) kd_loss 0.0196 (0.0189) lr 1.7705e-03 eta 0:14:53
epoch [13/50] batch [240/244] time 0.086 (0.098) data 0.000 (0.001) loss 1.4159 (1.2253) ce_loss 1.3125 (1.1176) teacher_loss 1.3115 (1.1171) loss_zs_kd 0.1454 (0.1389) loss_oracle 0.0317 (0.0387) acc 68.7500 (70.8203) kd_loss 0.0197 (0.0189) lr 1.7705e-03 eta 0:14:44
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,800
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 82.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.2%, epoch: 11 *******
******* Domain p best val test acc: 91.1%, epoch: 11 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [14/50] batch [20/244] time 0.090 (0.113) data 0.000 (0.013) loss 1.1014 (1.2115) ce_loss 0.9790 (1.0999) teacher_loss 0.9848 (1.0987) loss_zs_kd 0.1609 (0.1533) loss_oracle 0.0361 (0.0362) acc 71.8750 (70.1562) kd_loss 0.0163 (0.0192) lr 1.7290e-03 eta 0:16:54
epoch [14/50] batch [40/244] time 0.093 (0.104) data 0.000 (0.007) loss 1.0663 (1.2179) ce_loss 0.9487 (1.1069) teacher_loss 0.9535 (1.1043) loss_zs_kd 0.1490 (0.1545) loss_oracle 0.0383 (0.0364) acc 71.8750 (70.2344) kd_loss 0.0173 (0.0193) lr 1.7290e-03 eta 0:15:31
epoch [14/50] batch [60/244] time 0.100 (0.101) data 0.000 (0.005) loss 1.1670 (1.2119) ce_loss 1.0635 (1.0995) teacher_loss 1.0616 (1.0971) loss_zs_kd 0.1167 (0.1546) loss_oracle 0.0470 (0.0375) acc 81.2500 (70.5208) kd_loss 0.0258 (0.0194) lr 1.7290e-03 eta 0:15:02
epoch [14/50] batch [80/244] time 0.091 (0.099) data 0.000 (0.003) loss 1.0602 (1.1868) ce_loss 0.9717 (1.0743) teacher_loss 0.9709 (1.0723) loss_zs_kd 0.1211 (0.1549) loss_oracle 0.0287 (0.0371) acc 75.0000 (71.3281) kd_loss 0.0166 (0.0190) lr 1.7290e-03 eta 0:14:49
epoch [14/50] batch [100/244] time 0.089 (0.099) data 0.000 (0.003) loss 1.3349 (1.1771) ce_loss 1.2461 (1.0666) teacher_loss 1.2448 (1.0645) loss_zs_kd 0.1122 (0.1515) loss_oracle 0.0340 (0.0369) acc 68.7500 (71.7500) kd_loss 0.0158 (0.0191) lr 1.7290e-03 eta 0:14:41
epoch [14/50] batch [120/244] time 0.099 (0.098) data 0.000 (0.002) loss 1.0102 (1.1633) ce_loss 0.9258 (1.0538) teacher_loss 0.9308 (1.0520) loss_zs_kd 0.0955 (0.1492) loss_oracle 0.0316 (0.0367) acc 81.2500 (72.0312) kd_loss 0.0125 (0.0189) lr 1.7290e-03 eta 0:14:36
epoch [14/50] batch [140/244] time 0.089 (0.098) data 0.000 (0.002) loss 1.5092 (1.1722) ce_loss 1.4023 (1.0629) teacher_loss 1.3989 (1.0611) loss_zs_kd 0.1440 (0.1488) loss_oracle 0.0382 (0.0367) acc 62.5000 (71.8080) kd_loss 0.0184 (0.0189) lr 1.7290e-03 eta 0:14:28
epoch [14/50] batch [160/244] time 0.091 (0.097) data 0.000 (0.002) loss 1.3684 (1.1782) ce_loss 1.2607 (1.0696) teacher_loss 1.2618 (1.0678) loss_zs_kd 0.1615 (0.1487) loss_oracle 0.0258 (0.0360) acc 75.0000 (71.7188) kd_loss 0.0184 (0.0188) lr 1.7290e-03 eta 0:14:23
epoch [14/50] batch [180/244] time 0.097 (0.097) data 0.000 (0.002) loss 1.2755 (1.1680) ce_loss 1.1963 (1.0609) teacher_loss 1.1932 (1.0593) loss_zs_kd 0.0880 (0.1465) loss_oracle 0.0384 (0.0355) acc 68.7500 (71.9271) kd_loss 0.0188 (0.0186) lr 1.7290e-03 eta 0:14:20
epoch [14/50] batch [200/244] time 0.091 (0.097) data 0.000 (0.001) loss 1.0785 (1.1698) ce_loss 0.9824 (1.0630) teacher_loss 0.9795 (1.0615) loss_zs_kd 0.1310 (0.1454) loss_oracle 0.0335 (0.0356) acc 71.8750 (71.8281) kd_loss 0.0181 (0.0186) lr 1.7290e-03 eta 0:14:15
epoch [14/50] batch [220/244] time 0.096 (0.097) data 0.000 (0.001) loss 0.8168 (1.1633) ce_loss 0.7114 (1.0567) teacher_loss 0.6984 (1.0552) loss_zs_kd 0.1381 (0.1460) loss_oracle 0.0493 (0.0351) acc 84.3750 (72.0455) kd_loss 0.0229 (0.0186) lr 1.7290e-03 eta 0:14:12
epoch [14/50] batch [240/244] time 0.087 (0.096) data 0.000 (0.001) loss 1.2776 (1.1731) ce_loss 1.1719 (1.0678) teacher_loss 1.1705 (1.0662) loss_zs_kd 0.1654 (0.1446) loss_oracle 0.0244 (0.0345) acc 68.7500 (71.7188) kd_loss 0.0114 (0.0185) lr 1.7290e-03 eta 0:14:07
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,804
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,035
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.2%, epoch: 11 *******
******* Domain p best val test acc: 91.1%, epoch: 11 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [15/50] batch [20/244] time 0.107 (0.117) data 0.000 (0.013) loss 0.8717 (1.1768) ce_loss 0.7915 (1.0799) teacher_loss 0.7928 (1.0781) loss_zs_kd 0.1030 (0.1300) loss_oracle 0.0274 (0.0338) acc 81.2500 (72.0312) kd_loss 0.0163 (0.0189) lr 1.6845e-03 eta 0:17:02
epoch [15/50] batch [40/244] time 0.108 (0.111) data 0.000 (0.007) loss 0.9074 (1.2187) ce_loss 0.8091 (1.1135) teacher_loss 0.8070 (1.1121) loss_zs_kd 0.1160 (0.1385) loss_oracle 0.0424 (0.0373) acc 75.0000 (70.3906) kd_loss 0.0262 (0.0189) lr 1.6845e-03 eta 0:16:12
epoch [15/50] batch [60/244] time 0.102 (0.110) data 0.000 (0.005) loss 0.6973 (1.2103) ce_loss 0.5815 (1.1029) teacher_loss 0.5882 (1.1016) loss_zs_kd 0.1585 (0.1406) loss_oracle 0.0299 (0.0384) acc 81.2500 (70.9375) kd_loss 0.0173 (0.0201) lr 1.6845e-03 eta 0:15:58
epoch [15/50] batch [80/244] time 0.107 (0.109) data 0.000 (0.003) loss 1.4909 (1.2071) ce_loss 1.3887 (1.1004) teacher_loss 1.3811 (1.0986) loss_zs_kd 0.1282 (0.1408) loss_oracle 0.0458 (0.0382) acc 68.7500 (70.8203) kd_loss 0.0239 (0.0208) lr 1.6845e-03 eta 0:15:48
epoch [15/50] batch [100/244] time 0.104 (0.108) data 0.000 (0.003) loss 1.4045 (1.1940) ce_loss 1.2637 (1.0869) teacher_loss 1.2680 (1.0857) loss_zs_kd 0.2069 (0.1434) loss_oracle 0.0331 (0.0366) acc 59.3750 (71.1562) kd_loss 0.0188 (0.0205) lr 1.6845e-03 eta 0:15:39
epoch [15/50] batch [120/244] time 0.106 (0.107) data 0.000 (0.002) loss 1.0852 (1.1857) ce_loss 0.9771 (1.0787) teacher_loss 0.9655 (1.0776) loss_zs_kd 0.1448 (0.1439) loss_oracle 0.0473 (0.0361) acc 59.3750 (71.1458) kd_loss 0.0226 (0.0201) lr 1.6845e-03 eta 0:15:30
epoch [15/50] batch [140/244] time 0.102 (0.107) data 0.000 (0.002) loss 0.8609 (1.1893) ce_loss 0.7305 (1.0819) teacher_loss 0.7302 (1.0807) loss_zs_kd 0.1862 (0.1445) loss_oracle 0.0376 (0.0363) acc 84.3750 (71.2054) kd_loss 0.0181 (0.0200) lr 1.6845e-03 eta 0:15:23
epoch [15/50] batch [160/244] time 0.104 (0.107) data 0.000 (0.002) loss 1.0664 (1.1965) ce_loss 0.9531 (1.0888) teacher_loss 0.9532 (1.0875) loss_zs_kd 0.1519 (0.1447) loss_oracle 0.0372 (0.0367) acc 78.1250 (71.1523) kd_loss 0.0183 (0.0199) lr 1.6845e-03 eta 0:15:19
epoch [15/50] batch [180/244] time 0.108 (0.107) data 0.000 (0.002) loss 0.7851 (1.1895) ce_loss 0.6865 (1.0815) teacher_loss 0.6881 (1.0803) loss_zs_kd 0.1319 (0.1455) loss_oracle 0.0310 (0.0365) acc 81.2500 (71.3194) kd_loss 0.0153 (0.0198) lr 1.6845e-03 eta 0:15:17
epoch [15/50] batch [200/244] time 0.108 (0.107) data 0.000 (0.001) loss 0.8814 (1.1856) ce_loss 0.7651 (1.0780) teacher_loss 0.7663 (1.0768) loss_zs_kd 0.1846 (0.1459) loss_oracle 0.0228 (0.0359) acc 84.3750 (71.5469) kd_loss 0.0192 (0.0199) lr 1.6845e-03 eta 0:15:16
epoch [15/50] batch [220/244] time 0.112 (0.107) data 0.000 (0.001) loss 1.0784 (1.1933) ce_loss 0.9858 (1.0871) teacher_loss 0.9820 (1.0858) loss_zs_kd 0.1314 (0.1449) loss_oracle 0.0307 (0.0351) acc 84.3750 (71.3920) kd_loss 0.0254 (0.0200) lr 1.6845e-03 eta 0:15:14
epoch [15/50] batch [240/244] time 0.086 (0.106) data 0.000 (0.001) loss 1.1477 (1.1981) ce_loss 0.9829 (1.0922) teacher_loss 0.9772 (1.0909) loss_zs_kd 0.2690 (0.1454) loss_oracle 0.0360 (0.0346) acc 71.8750 (71.2370) kd_loss 0.0294 (0.0202) lr 1.6845e-03 eta 0:15:09
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,814
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,028
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.2%
******* Domain p best val acc:      84.4%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [16/50] batch [20/244] time 0.094 (0.115) data 0.000 (0.014) loss 0.8546 (1.2394) ce_loss 0.7441 (1.1320) teacher_loss 0.7399 (1.1313) loss_zs_kd 0.1653 (0.1561) loss_oracle 0.0320 (0.0301) acc 75.0000 (70.0000) kd_loss 0.0195 (0.0200) lr 1.6374e-03 eta 0:16:19
epoch [16/50] batch [40/244] time 0.114 (0.108) data 0.000 (0.007) loss 0.8059 (1.2414) ce_loss 0.7148 (1.1302) teacher_loss 0.7133 (1.1293) loss_zs_kd 0.1059 (0.1579) loss_oracle 0.0397 (0.0332) acc 84.3750 (70.7031) kd_loss 0.0232 (0.0201) lr 1.6374e-03 eta 0:15:19
epoch [16/50] batch [60/244] time 0.097 (0.107) data 0.000 (0.005) loss 1.0164 (1.2335) ce_loss 0.8921 (1.1207) teacher_loss 0.8940 (1.1199) loss_zs_kd 0.1698 (0.1574) loss_oracle 0.0376 (0.0349) acc 68.7500 (70.0521) kd_loss 0.0157 (0.0201) lr 1.6374e-03 eta 0:15:04
epoch [16/50] batch [80/244] time 0.117 (0.106) data 0.000 (0.004) loss 1.1980 (1.2461) ce_loss 1.0605 (1.1354) teacher_loss 1.0635 (1.1348) loss_zs_kd 0.2060 (0.1539) loss_oracle 0.0315 (0.0343) acc 65.6250 (70.1172) kd_loss 0.0207 (0.0197) lr 1.6374e-03 eta 0:15:00
epoch [16/50] batch [100/244] time 0.124 (0.108) data 0.001 (0.003) loss 1.0406 (1.2440) ce_loss 0.9272 (1.1346) teacher_loss 0.9296 (1.1337) loss_zs_kd 0.1419 (0.1503) loss_oracle 0.0400 (0.0352) acc 75.0000 (70.1562) kd_loss 0.0172 (0.0198) lr 1.6374e-03 eta 0:15:09
epoch [16/50] batch [120/244] time 0.121 (0.110) data 0.000 (0.002) loss 1.6639 (1.2450) ce_loss 1.5635 (1.1349) teacher_loss 1.5592 (1.1338) loss_zs_kd 0.1141 (0.1474) loss_oracle 0.0476 (0.0374) acc 65.6250 (70.1042) kd_loss 0.0206 (0.0201) lr 1.6374e-03 eta 0:15:27
epoch [16/50] batch [140/244] time 0.121 (0.112) data 0.001 (0.002) loss 0.7776 (1.2308) ce_loss 0.6519 (1.1190) teacher_loss 0.6541 (1.1181) loss_zs_kd 0.1507 (0.1476) loss_oracle 0.0482 (0.0388) acc 84.3750 (70.4688) kd_loss 0.0277 (0.0205) lr 1.6374e-03 eta 0:15:40
epoch [16/50] batch [160/244] time 0.124 (0.113) data 0.000 (0.002) loss 0.7348 (1.2171) ce_loss 0.6362 (1.1061) teacher_loss 0.6395 (1.1054) loss_zs_kd 0.1237 (0.1461) loss_oracle 0.0334 (0.0386) acc 84.3750 (70.7617) kd_loss 0.0232 (0.0207) lr 1.6374e-03 eta 0:15:48
epoch [16/50] batch [180/244] time 0.123 (0.114) data 0.000 (0.002) loss 0.9721 (1.2157) ce_loss 0.8501 (1.1050) teacher_loss 0.8486 (1.1040) loss_zs_kd 0.1655 (0.1459) loss_oracle 0.0408 (0.0387) acc 81.2500 (70.7986) kd_loss 0.0278 (0.0209) lr 1.6374e-03 eta 0:15:54
epoch [16/50] batch [200/244] time 0.122 (0.115) data 0.000 (0.002) loss 1.3577 (1.2228) ce_loss 1.2295 (1.1119) teacher_loss 1.2206 (1.1111) loss_zs_kd 0.1718 (0.1446) loss_oracle 0.0512 (0.0394) acc 71.8750 (70.7031) kd_loss 0.0277 (0.0211) lr 1.6374e-03 eta 0:15:58
epoch [16/50] batch [220/244] time 0.115 (0.116) data 0.000 (0.002) loss 1.8299 (1.2185) ce_loss 1.6719 (1.1075) teacher_loss 1.6628 (1.1065) loss_zs_kd 0.2312 (0.1444) loss_oracle 0.0515 (0.0398) acc 50.0000 (70.7528) kd_loss 0.0292 (0.0213) lr 1.6374e-03 eta 0:16:01
epoch [16/50] batch [240/244] time 0.104 (0.115) data 0.000 (0.001) loss 0.7435 (1.2186) ce_loss 0.6519 (1.1075) teacher_loss 0.6537 (1.1063) loss_zs_kd 0.1078 (0.1445) loss_oracle 0.0359 (0.0400) acc 84.3750 (70.6510) kd_loss 0.0246 (0.0217) lr 1.6374e-03 eta 0:15:57
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,813
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.4%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [17/50] batch [20/244] time 0.101 (0.109) data 0.000 (0.013) loss 1.2589 (1.2499) ce_loss 1.1631 (1.1454) teacher_loss 1.1680 (1.1430) loss_zs_kd 0.1114 (0.1412) loss_oracle 0.0353 (0.0363) acc 68.7500 (68.5938) kd_loss 0.0200 (0.0263) lr 1.5878e-03 eta 0:14:59
epoch [17/50] batch [40/244] time 0.097 (0.103) data 0.000 (0.007) loss 1.2799 (1.2638) ce_loss 1.1973 (1.1603) teacher_loss 1.1867 (1.1581) loss_zs_kd 0.1104 (0.1410) loss_oracle 0.0380 (0.0353) acc 62.5000 (68.2031) kd_loss 0.0281 (0.0257) lr 1.5878e-03 eta 0:14:12
epoch [17/50] batch [60/244] time 0.097 (0.101) data 0.000 (0.005) loss 1.5183 (1.2308) ce_loss 1.4150 (1.1271) teacher_loss 1.4126 (1.1252) loss_zs_kd 0.1459 (0.1407) loss_oracle 0.0327 (0.0352) acc 59.3750 (69.0625) kd_loss 0.0211 (0.0242) lr 1.5878e-03 eta 0:13:55
epoch [17/50] batch [80/244] time 0.090 (0.100) data 0.000 (0.004) loss 0.8317 (1.2420) ce_loss 0.7183 (1.1373) teacher_loss 0.7145 (1.1354) loss_zs_kd 0.1391 (0.1403) loss_oracle 0.0476 (0.0364) acc 81.2500 (69.1016) kd_loss 0.0325 (0.0240) lr 1.5878e-03 eta 0:13:43
epoch [17/50] batch [100/244] time 0.093 (0.099) data 0.000 (0.003) loss 1.0057 (1.2254) ce_loss 0.8872 (1.1198) teacher_loss 0.8890 (1.1178) loss_zs_kd 0.1509 (0.1413) loss_oracle 0.0413 (0.0369) acc 71.8750 (69.6875) kd_loss 0.0240 (0.0240) lr 1.5878e-03 eta 0:13:30
epoch [17/50] batch [120/244] time 0.095 (0.098) data 0.000 (0.002) loss 1.0172 (1.2216) ce_loss 0.9004 (1.1143) teacher_loss 0.9045 (1.1125) loss_zs_kd 0.1689 (0.1439) loss_oracle 0.0283 (0.0371) acc 75.0000 (70.1823) kd_loss 0.0188 (0.0241) lr 1.5878e-03 eta 0:13:22
epoch [17/50] batch [140/244] time 0.092 (0.098) data 0.000 (0.002) loss 1.0322 (1.2189) ce_loss 0.9551 (1.1108) teacher_loss 0.9538 (1.1090) loss_zs_kd 0.0903 (0.1454) loss_oracle 0.0333 (0.0372) acc 68.7500 (70.1339) kd_loss 0.0242 (0.0242) lr 1.5878e-03 eta 0:13:16
epoch [17/50] batch [160/244] time 0.092 (0.097) data 0.000 (0.002) loss 1.0793 (1.2198) ce_loss 0.9546 (1.1121) teacher_loss 0.9569 (1.1102) loss_zs_kd 0.1697 (0.1447) loss_oracle 0.0376 (0.0373) acc 81.2500 (70.2344) kd_loss 0.0273 (0.0244) lr 1.5878e-03 eta 0:13:11
epoch [17/50] batch [180/244] time 0.095 (0.097) data 0.000 (0.002) loss 0.7920 (1.2151) ce_loss 0.6582 (1.1059) teacher_loss 0.6579 (1.1041) loss_zs_kd 0.1550 (0.1466) loss_oracle 0.0566 (0.0376) acc 78.1250 (70.3993) kd_loss 0.0259 (0.0244) lr 1.5878e-03 eta 0:13:06
epoch [17/50] batch [200/244] time 0.093 (0.097) data 0.000 (0.002) loss 0.9070 (1.2256) ce_loss 0.8198 (1.1162) teacher_loss 0.8209 (1.1145) loss_zs_kd 0.1037 (0.1461) loss_oracle 0.0343 (0.0381) acc 68.7500 (70.2500) kd_loss 0.0157 (0.0243) lr 1.5878e-03 eta 0:13:02
epoch [17/50] batch [220/244] time 0.089 (0.097) data 0.000 (0.001) loss 1.0850 (1.2225) ce_loss 0.9854 (1.1135) teacher_loss 0.9888 (1.1119) loss_zs_kd 0.1245 (0.1457) loss_oracle 0.0339 (0.0378) acc 68.7500 (70.5114) kd_loss 0.0275 (0.0242) lr 1.5878e-03 eta 0:12:59
epoch [17/50] batch [240/244] time 0.084 (0.096) data 0.000 (0.001) loss 0.9841 (1.2213) ce_loss 0.8706 (1.1125) teacher_loss 0.8709 (1.1110) loss_zs_kd 0.1542 (0.1454) loss_oracle 0.0361 (0.0376) acc 81.2500 (70.6250) kd_loss 0.0226 (0.0241) lr 1.5878e-03 eta 0:12:53
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,808
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,033
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.3%
******* Domain p best val acc:      84.4%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [18/50] batch [20/244] time 0.096 (0.118) data 0.000 (0.014) loss 1.3123 (1.1883) ce_loss 1.2178 (1.0836) teacher_loss 1.2086 (1.0825) loss_zs_kd 0.1261 (0.1432) loss_oracle 0.0407 (0.0342) acc 71.8750 (71.0938) kd_loss 0.0242 (0.0226) lr 1.5358e-03 eta 0:15:49
epoch [18/50] batch [40/244] time 0.101 (0.110) data 0.000 (0.007) loss 1.2307 (1.2103) ce_loss 1.1260 (1.1089) teacher_loss 1.1254 (1.1076) loss_zs_kd 0.1339 (0.1385) loss_oracle 0.0383 (0.0335) acc 65.6250 (70.8594) kd_loss 0.0199 (0.0226) lr 1.5358e-03 eta 0:14:38
epoch [18/50] batch [60/244] time 0.100 (0.107) data 0.001 (0.005) loss 1.1897 (1.2116) ce_loss 1.0967 (1.1108) teacher_loss 1.0960 (1.1089) loss_zs_kd 0.1282 (0.1373) loss_oracle 0.0296 (0.0340) acc 75.0000 (71.1979) kd_loss 0.0212 (0.0229) lr 1.5358e-03 eta 0:14:14
epoch [18/50] batch [80/244] time 0.099 (0.105) data 0.000 (0.004) loss 1.1003 (1.2401) ce_loss 0.9985 (1.1373) teacher_loss 1.0008 (1.1358) loss_zs_kd 0.1413 (0.1413) loss_oracle 0.0288 (0.0336) acc 78.1250 (70.5078) kd_loss 0.0170 (0.0224) lr 1.5358e-03 eta 0:14:00
epoch [18/50] batch [100/244] time 0.100 (0.104) data 0.000 (0.003) loss 1.6951 (1.2451) ce_loss 1.5557 (1.1406) teacher_loss 1.5556 (1.1392) loss_zs_kd 0.1890 (0.1437) loss_oracle 0.0450 (0.0341) acc 62.5000 (70.0312) kd_loss 0.0312 (0.0222) lr 1.5358e-03 eta 0:13:49
epoch [18/50] batch [120/244] time 0.092 (0.103) data 0.000 (0.003) loss 1.6809 (1.2520) ce_loss 1.5771 (1.1453) teacher_loss 1.5783 (1.1439) loss_zs_kd 0.1400 (0.1461) loss_oracle 0.0326 (0.0351) acc 59.3750 (69.9219) kd_loss 0.0192 (0.0224) lr 1.5358e-03 eta 0:13:38
epoch [18/50] batch [140/244] time 0.088 (0.102) data 0.000 (0.002) loss 0.8199 (1.2411) ce_loss 0.7539 (1.1349) teacher_loss 0.7556 (1.1336) loss_zs_kd 0.0869 (0.1461) loss_oracle 0.0209 (0.0344) acc 71.8750 (70.1786) kd_loss 0.0162 (0.0222) lr 1.5358e-03 eta 0:13:26
epoch [18/50] batch [160/244] time 0.093 (0.101) data 0.000 (0.002) loss 1.2836 (1.2403) ce_loss 1.1416 (1.1334) teacher_loss 1.1433 (1.1323) loss_zs_kd 0.2202 (0.1465) loss_oracle 0.0302 (0.0347) acc 78.1250 (70.2539) kd_loss 0.0198 (0.0221) lr 1.5358e-03 eta 0:13:19
epoch [18/50] batch [180/244] time 0.097 (0.101) data 0.000 (0.002) loss 0.5939 (1.2384) ce_loss 0.5117 (1.1312) teacher_loss 0.5105 (1.1302) loss_zs_kd 0.0791 (0.1455) loss_oracle 0.0438 (0.0355) acc 84.3750 (70.3125) kd_loss 0.0267 (0.0224) lr 1.5358e-03 eta 0:13:13
epoch [18/50] batch [200/244] time 0.101 (0.101) data 0.000 (0.002) loss 1.0905 (1.2270) ce_loss 0.9688 (1.1195) teacher_loss 0.9704 (1.1183) loss_zs_kd 0.1626 (0.1451) loss_oracle 0.0388 (0.0362) acc 71.8750 (70.7188) kd_loss 0.0231 (0.0227) lr 1.5358e-03 eta 0:13:09
epoch [18/50] batch [220/244] time 0.089 (0.100) data 0.000 (0.001) loss 1.2025 (1.2212) ce_loss 1.1016 (1.1139) teacher_loss 1.0898 (1.1125) loss_zs_kd 0.1583 (0.1450) loss_oracle 0.0335 (0.0362) acc 71.8750 (70.8381) kd_loss 0.0262 (0.0229) lr 1.5358e-03 eta 0:13:04
epoch [18/50] batch [240/244] time 0.085 (0.099) data 0.000 (0.001) loss 1.2319 (1.2237) ce_loss 1.1201 (1.1164) teacher_loss 1.1168 (1.1150) loss_zs_kd 0.1599 (0.1453) loss_oracle 0.0352 (0.0360) acc 59.3750 (70.7943) kd_loss 0.0184 (0.0228) lr 1.5358e-03 eta 0:12:56
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,813
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,024
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.1%
******* Domain p best val acc:      84.4%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [19/50] batch [20/244] time 0.098 (0.113) data 0.000 (0.015) loss 1.0344 (1.2623) ce_loss 0.9307 (1.1566) teacher_loss 0.9277 (1.1534) loss_zs_kd 0.1247 (0.1408) loss_oracle 0.0443 (0.0385) acc 75.0000 (69.3750) kd_loss 0.0246 (0.0214) lr 1.4818e-03 eta 0:14:43
epoch [19/50] batch [40/244] time 0.097 (0.104) data 0.000 (0.007) loss 1.3458 (1.2542) ce_loss 1.2109 (1.1378) teacher_loss 1.2041 (1.1351) loss_zs_kd 0.1869 (0.1499) loss_oracle 0.0482 (0.0440) acc 78.1250 (69.9219) kd_loss 0.0284 (0.0234) lr 1.4818e-03 eta 0:13:25
epoch [19/50] batch [60/244] time 0.091 (0.100) data 0.000 (0.005) loss 0.7351 (1.2759) ce_loss 0.6411 (1.1544) teacher_loss 0.6409 (1.1520) loss_zs_kd 0.0990 (0.1550) loss_oracle 0.0447 (0.0464) acc 84.3750 (69.4792) kd_loss 0.0326 (0.0255) lr 1.4818e-03 eta 0:12:55
epoch [19/50] batch [80/244] time 0.093 (0.098) data 0.000 (0.004) loss 1.3196 (1.2555) ce_loss 1.2324 (1.1362) teacher_loss 1.2292 (1.1337) loss_zs_kd 0.1189 (0.1531) loss_oracle 0.0310 (0.0453) acc 59.3750 (69.6875) kd_loss 0.0201 (0.0266) lr 1.4818e-03 eta 0:12:37
epoch [19/50] batch [100/244] time 0.109 (0.097) data 0.000 (0.003) loss 1.6721 (1.2490) ce_loss 1.5303 (1.1332) teacher_loss 1.5300 (1.1311) loss_zs_kd 0.1996 (0.1481) loss_oracle 0.0423 (0.0439) acc 59.3750 (69.8750) kd_loss 0.0290 (0.0268) lr 1.4818e-03 eta 0:12:30
epoch [19/50] batch [120/244] time 0.103 (0.099) data 0.000 (0.003) loss 1.5093 (1.2538) ce_loss 1.3584 (1.1383) teacher_loss 1.3501 (1.1360) loss_zs_kd 0.1734 (0.1470) loss_oracle 0.0724 (0.0443) acc 65.6250 (69.5833) kd_loss 0.0446 (0.0270) lr 1.4818e-03 eta 0:12:37
epoch [19/50] batch [140/244] time 0.099 (0.099) data 0.000 (0.002) loss 1.3465 (1.2457) ce_loss 1.2246 (1.1310) teacher_loss 1.2201 (1.1288) loss_zs_kd 0.1747 (0.1455) loss_oracle 0.0390 (0.0441) acc 68.7500 (69.9330) kd_loss 0.0212 (0.0272) lr 1.4818e-03 eta 0:12:39
epoch [19/50] batch [160/244] time 0.097 (0.099) data 0.000 (0.002) loss 1.1599 (1.2429) ce_loss 1.0547 (1.1288) teacher_loss 1.0589 (1.1268) loss_zs_kd 0.1481 (0.1457) loss_oracle 0.0270 (0.0432) acc 78.1250 (70.0000) kd_loss 0.0160 (0.0268) lr 1.4818e-03 eta 0:12:39
epoch [19/50] batch [180/244] time 0.095 (0.100) data 0.000 (0.002) loss 0.8959 (1.2389) ce_loss 0.7778 (1.1249) teacher_loss 0.7708 (1.1229) loss_zs_kd 0.1537 (0.1464) loss_oracle 0.0482 (0.0428) acc 84.3750 (70.1562) kd_loss 0.0326 (0.0268) lr 1.4818e-03 eta 0:12:40
epoch [19/50] batch [200/244] time 0.098 (0.099) data 0.000 (0.002) loss 1.0837 (1.2212) ce_loss 0.9590 (1.1074) teacher_loss 0.9381 (1.1053) loss_zs_kd 0.1944 (0.1472) loss_oracle 0.0484 (0.0423) acc 68.7500 (70.5781) kd_loss 0.0377 (0.0268) lr 1.4818e-03 eta 0:12:35
epoch [19/50] batch [220/244] time 0.095 (0.099) data 0.000 (0.002) loss 1.1833 (1.2212) ce_loss 1.1094 (1.1083) teacher_loss 1.1067 (1.1062) loss_zs_kd 0.0946 (0.1466) loss_oracle 0.0293 (0.0417) acc 75.0000 (70.6960) kd_loss 0.0184 (0.0266) lr 1.4818e-03 eta 0:12:30
epoch [19/50] batch [240/244] time 0.105 (0.099) data 0.000 (0.001) loss 1.3402 (1.2105) ce_loss 1.2314 (1.0986) teacher_loss 1.2285 (1.0967) loss_zs_kd 0.1593 (0.1458) loss_oracle 0.0320 (0.0409) acc 71.8750 (70.8594) kd_loss 0.0294 (0.0264) lr 1.4818e-03 eta 0:12:30
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,813
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.4%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [20/50] batch [20/244] time 0.132 (0.144) data 0.000 (0.016) loss 1.2671 (1.1888) ce_loss 1.1699 (1.0810) teacher_loss 1.1695 (1.0799) loss_zs_kd 0.1444 (0.1466) loss_oracle 0.0254 (0.0356) acc 62.5000 (71.7188) kd_loss 0.0202 (0.0248) lr 1.4258e-03 eta 0:18:08
epoch [20/50] batch [40/244] time 0.130 (0.137) data 0.001 (0.008) loss 1.1748 (1.1903) ce_loss 1.0811 (1.0838) teacher_loss 1.0778 (1.0833) loss_zs_kd 0.1030 (0.1439) loss_oracle 0.0455 (0.0351) acc 78.1250 (72.4219) kd_loss 0.0299 (0.0227) lr 1.4258e-03 eta 0:17:12
epoch [20/50] batch [60/244] time 0.134 (0.135) data 0.001 (0.005) loss 1.2682 (1.1859) ce_loss 1.1475 (1.0781) teacher_loss 1.1484 (1.0774) loss_zs_kd 0.1514 (0.1417) loss_oracle 0.0440 (0.0376) acc 68.7500 (72.3438) kd_loss 0.0241 (0.0220) lr 1.4258e-03 eta 0:16:51
epoch [20/50] batch [80/244] time 0.132 (0.133) data 0.000 (0.004) loss 1.1707 (1.1847) ce_loss 1.0615 (1.0752) teacher_loss 1.0555 (1.0744) loss_zs_kd 0.1420 (0.1425) loss_oracle 0.0442 (0.0390) acc 65.6250 (72.4219) kd_loss 0.0261 (0.0220) lr 1.4258e-03 eta 0:16:37
epoch [20/50] batch [100/244] time 0.123 (0.133) data 0.000 (0.003) loss 1.4387 (1.2160) ce_loss 1.3516 (1.1052) teacher_loss 1.3466 (1.1041) loss_zs_kd 0.1074 (0.1435) loss_oracle 0.0384 (0.0402) acc 71.8750 (71.4688) kd_loss 0.0187 (0.0219) lr 1.4258e-03 eta 0:16:29
epoch [20/50] batch [120/244] time 0.130 (0.132) data 0.000 (0.003) loss 1.0979 (1.2240) ce_loss 0.9883 (1.1126) teacher_loss 0.9871 (1.1116) loss_zs_kd 0.1476 (0.1449) loss_oracle 0.0370 (0.0399) acc 78.1250 (71.5625) kd_loss 0.0231 (0.0218) lr 1.4258e-03 eta 0:16:24
epoch [20/50] batch [140/244] time 0.130 (0.132) data 0.000 (0.003) loss 1.5458 (1.2275) ce_loss 1.4590 (1.1158) teacher_loss 1.4458 (1.1147) loss_zs_kd 0.1105 (0.1451) loss_oracle 0.0447 (0.0402) acc 59.3750 (71.4062) kd_loss 0.0192 (0.0219) lr 1.4258e-03 eta 0:16:20
epoch [20/50] batch [160/244] time 0.131 (0.132) data 0.000 (0.002) loss 0.7766 (1.2220) ce_loss 0.6963 (1.1116) teacher_loss 0.7003 (1.1106) loss_zs_kd 0.0690 (0.1428) loss_oracle 0.0418 (0.0400) acc 84.3750 (71.4062) kd_loss 0.0238 (0.0221) lr 1.4258e-03 eta 0:16:15
epoch [20/50] batch [180/244] time 0.125 (0.132) data 0.000 (0.002) loss 1.3611 (1.2124) ce_loss 1.2178 (1.1030) teacher_loss 1.2199 (1.1020) loss_zs_kd 0.1900 (0.1415) loss_oracle 0.0462 (0.0397) acc 65.6250 (71.4062) kd_loss 0.0254 (0.0219) lr 1.4258e-03 eta 0:16:12
epoch [20/50] batch [200/244] time 0.129 (0.131) data 0.000 (0.002) loss 0.7736 (1.2152) ce_loss 0.6577 (1.1048) teacher_loss 0.6545 (1.1036) loss_zs_kd 0.1463 (0.1428) loss_oracle 0.0460 (0.0402) acc 75.0000 (71.2031) kd_loss 0.0270 (0.0221) lr 1.4258e-03 eta 0:16:08
epoch [20/50] batch [220/244] time 0.133 (0.131) data 0.000 (0.002) loss 1.2060 (1.2096) ce_loss 1.0498 (1.0985) teacher_loss 1.0495 (1.0972) loss_zs_kd 0.2333 (0.1440) loss_oracle 0.0398 (0.0404) acc 78.1250 (71.3636) kd_loss 0.0196 (0.0221) lr 1.4258e-03 eta 0:16:05
epoch [20/50] batch [240/244] time 0.102 (0.130) data 0.000 (0.002) loss 0.8861 (1.2086) ce_loss 0.7886 (1.0972) teacher_loss 0.7885 (1.0957) loss_zs_kd 0.1229 (0.1443) loss_oracle 0.0362 (0.0407) acc 78.1250 (71.2891) kd_loss 0.0159 (0.0221) lr 1.4258e-03 eta 0:15:53
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,812
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,035
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.4%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [21/50] batch [20/244] time 0.114 (0.124) data 0.000 (0.014) loss 0.8327 (1.1579) ce_loss 0.7324 (1.0441) teacher_loss 0.7312 (1.0436) loss_zs_kd 0.1265 (0.1474) loss_oracle 0.0382 (0.0406) acc 78.1250 (71.2500) kd_loss 0.0154 (0.0204) lr 1.3681e-03 eta 0:15:04
epoch [21/50] batch [40/244] time 0.108 (0.116) data 0.000 (0.007) loss 0.8328 (1.1640) ce_loss 0.7085 (1.0508) teacher_loss 0.7115 (1.0505) loss_zs_kd 0.1791 (0.1489) loss_oracle 0.0317 (0.0391) acc 81.2500 (71.3281) kd_loss 0.0155 (0.0199) lr 1.3681e-03 eta 0:14:05
epoch [21/50] batch [60/244] time 0.106 (0.115) data 0.001 (0.005) loss 0.9804 (1.1938) ce_loss 0.8945 (1.0818) teacher_loss 0.8922 (1.0810) loss_zs_kd 0.1062 (0.1475) loss_oracle 0.0351 (0.0390) acc 71.8750 (70.6250) kd_loss 0.0191 (0.0202) lr 1.3681e-03 eta 0:13:52
epoch [21/50] batch [80/244] time 0.124 (0.115) data 0.000 (0.004) loss 0.9906 (1.2115) ce_loss 0.8394 (1.0984) teacher_loss 0.8459 (1.0975) loss_zs_kd 0.2176 (0.1498) loss_oracle 0.0359 (0.0391) acc 81.2500 (70.5078) kd_loss 0.0185 (0.0205) lr 1.3681e-03 eta 0:13:50
epoch [21/50] batch [100/244] time 0.101 (0.113) data 0.000 (0.003) loss 0.9187 (1.2241) ce_loss 0.7949 (1.1105) teacher_loss 0.8014 (1.1098) loss_zs_kd 0.1596 (0.1515) loss_oracle 0.0375 (0.0386) acc 75.0000 (70.1250) kd_loss 0.0188 (0.0204) lr 1.3681e-03 eta 0:13:36
epoch [21/50] batch [120/244] time 0.099 (0.111) data 0.000 (0.002) loss 1.0341 (1.2309) ce_loss 0.9233 (1.1184) teacher_loss 0.9236 (1.1178) loss_zs_kd 0.1307 (0.1499) loss_oracle 0.0452 (0.0381) acc 75.0000 (70.1042) kd_loss 0.0209 (0.0207) lr 1.3681e-03 eta 0:13:20
epoch [21/50] batch [140/244] time 0.100 (0.110) data 0.000 (0.002) loss 1.4117 (1.2354) ce_loss 1.2979 (1.1235) teacher_loss 1.2953 (1.1226) loss_zs_kd 0.1562 (0.1496) loss_oracle 0.0383 (0.0380) acc 65.6250 (70.2009) kd_loss 0.0246 (0.0211) lr 1.3681e-03 eta 0:13:10
epoch [21/50] batch [160/244] time 0.105 (0.109) data 0.000 (0.002) loss 1.5753 (1.2307) ce_loss 1.4805 (1.1183) teacher_loss 1.4712 (1.1172) loss_zs_kd 0.1081 (0.1497) loss_oracle 0.0500 (0.0386) acc 65.6250 (70.5078) kd_loss 0.0293 (0.0214) lr 1.3681e-03 eta 0:13:00
epoch [21/50] batch [180/244] time 0.103 (0.108) data 0.000 (0.002) loss 0.8119 (1.2185) ce_loss 0.7129 (1.1064) teacher_loss 0.7123 (1.1053) loss_zs_kd 0.1181 (0.1493) loss_oracle 0.0405 (0.0386) acc 81.2500 (70.9201) kd_loss 0.0355 (0.0218) lr 1.3681e-03 eta 0:12:52
epoch [21/50] batch [200/244] time 0.100 (0.108) data 0.000 (0.002) loss 1.1220 (1.2156) ce_loss 0.9819 (1.1041) teacher_loss 0.9838 (1.1027) loss_zs_kd 0.1919 (0.1485) loss_oracle 0.0422 (0.0386) acc 71.8750 (70.9375) kd_loss 0.0298 (0.0220) lr 1.3681e-03 eta 0:12:45
epoch [21/50] batch [220/244] time 0.104 (0.107) data 0.000 (0.001) loss 1.2099 (1.2167) ce_loss 1.0791 (1.1053) teacher_loss 1.0879 (1.1038) loss_zs_kd 0.1923 (0.1483) loss_oracle 0.0259 (0.0388) acc 75.0000 (70.8665) kd_loss 0.0229 (0.0225) lr 1.3681e-03 eta 0:12:38
epoch [21/50] batch [240/244] time 0.104 (0.106) data 0.000 (0.001) loss 1.1703 (1.2260) ce_loss 1.0400 (1.1143) teacher_loss 1.0360 (1.1129) loss_zs_kd 0.1801 (0.1488) loss_oracle 0.0442 (0.0387) acc 71.8750 (70.8203) kd_loss 0.0250 (0.0225) lr 1.3681e-03 eta 0:12:33
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.6%, epoch: 21 *******
******* Domain p best val test acc: 90.9%, epoch: 21 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [22/50] batch [20/244] time 0.134 (0.126) data 0.000 (0.012) loss 1.1893 (1.2074) ce_loss 1.0850 (1.0937) teacher_loss 1.0852 (1.0917) loss_zs_kd 0.1421 (0.1512) loss_oracle 0.0330 (0.0401) acc 75.0000 (70.9375) kd_loss 0.0173 (0.0243) lr 1.3090e-03 eta 0:14:49
epoch [22/50] batch [40/244] time 0.123 (0.126) data 0.000 (0.006) loss 0.8535 (1.2259) ce_loss 0.7651 (1.1122) teacher_loss 0.7571 (1.1101) loss_zs_kd 0.1239 (0.1505) loss_oracle 0.0345 (0.0405) acc 71.8750 (70.4688) kd_loss 0.0244 (0.0249) lr 1.3090e-03 eta 0:14:48
epoch [22/50] batch [60/244] time 0.113 (0.125) data 0.000 (0.004) loss 0.9680 (1.1985) ce_loss 0.8574 (1.0841) teacher_loss 0.8588 (1.0819) loss_zs_kd 0.1375 (0.1534) loss_oracle 0.0404 (0.0399) acc 81.2500 (71.0938) kd_loss 0.0260 (0.0249) lr 1.3090e-03 eta 0:14:39
epoch [22/50] batch [80/244] time 0.120 (0.124) data 0.000 (0.003) loss 1.8604 (1.1988) ce_loss 1.7568 (1.0852) teacher_loss 1.7495 (1.0829) loss_zs_kd 0.1563 (0.1535) loss_oracle 0.0328 (0.0391) acc 46.8750 (71.3672) kd_loss 0.0248 (0.0250) lr 1.3090e-03 eta 0:14:28
epoch [22/50] batch [100/244] time 0.120 (0.124) data 0.000 (0.003) loss 0.9245 (1.1777) ce_loss 0.8140 (1.0651) teacher_loss 0.8107 (1.0628) loss_zs_kd 0.1474 (0.1517) loss_oracle 0.0401 (0.0391) acc 71.8750 (71.9375) kd_loss 0.0234 (0.0249) lr 1.3090e-03 eta 0:14:27
epoch [22/50] batch [120/244] time 0.114 (0.122) data 0.000 (0.002) loss 0.9699 (1.1714) ce_loss 0.8735 (1.0578) teacher_loss 0.8633 (1.0553) loss_zs_kd 0.1379 (0.1534) loss_oracle 0.0376 (0.0394) acc 78.1250 (72.0052) kd_loss 0.0225 (0.0249) lr 1.3090e-03 eta 0:14:09
epoch [22/50] batch [140/244] time 0.113 (0.120) data 0.000 (0.002) loss 1.6344 (1.1766) ce_loss 1.5293 (1.0640) teacher_loss 1.5251 (1.0616) loss_zs_kd 0.1576 (0.1519) loss_oracle 0.0304 (0.0390) acc 53.1250 (71.5625) kd_loss 0.0194 (0.0246) lr 1.3090e-03 eta 0:13:51
epoch [22/50] batch [160/244] time 0.097 (0.118) data 0.000 (0.002) loss 1.1954 (1.1913) ce_loss 1.0869 (1.0780) teacher_loss 1.0886 (1.0758) loss_zs_kd 0.1485 (0.1538) loss_oracle 0.0325 (0.0386) acc 78.1250 (71.3477) kd_loss 0.0184 (0.0246) lr 1.3090e-03 eta 0:13:37
epoch [22/50] batch [180/244] time 0.109 (0.117) data 0.001 (0.002) loss 1.3963 (1.1930) ce_loss 1.2900 (1.0804) teacher_loss 1.2875 (1.0784) loss_zs_kd 0.1466 (0.1522) loss_oracle 0.0355 (0.0384) acc 56.2500 (71.3194) kd_loss 0.0185 (0.0241) lr 1.3090e-03 eta 0:13:26
epoch [22/50] batch [200/244] time 0.096 (0.115) data 0.000 (0.002) loss 1.1457 (1.1897) ce_loss 1.0488 (1.0754) teacher_loss 1.0459 (1.0734) loss_zs_kd 0.1279 (0.1547) loss_oracle 0.0358 (0.0390) acc 78.1250 (71.4688) kd_loss 0.0196 (0.0241) lr 1.3090e-03 eta 0:13:12
epoch [22/50] batch [220/244] time 0.103 (0.114) data 0.001 (0.001) loss 0.8949 (1.1866) ce_loss 0.7681 (1.0724) teacher_loss 0.7672 (1.0704) loss_zs_kd 0.1624 (0.1543) loss_oracle 0.0464 (0.0391) acc 81.2500 (71.6761) kd_loss 0.0273 (0.0240) lr 1.3090e-03 eta 0:13:03
epoch [22/50] batch [240/244] time 0.085 (0.112) data 0.000 (0.001) loss 1.4051 (1.1994) ce_loss 1.2520 (1.0839) teacher_loss 1.2415 (1.0819) loss_zs_kd 0.1934 (0.1551) loss_oracle 0.0668 (0.0399) acc 71.8750 (71.3151) kd_loss 0.0368 (0.0243) lr 1.3090e-03 eta 0:12:47
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,822
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,030
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.2%
******* Domain p best val acc:      84.6%, epoch: 22 *******
******* Domain p best val test acc: 90.8%, epoch: 22 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [23/50] batch [20/244] time 0.103 (0.128) data 0.000 (0.019) loss 1.2004 (1.2639) ce_loss 1.1152 (1.1486) teacher_loss 1.1069 (1.1457) loss_zs_kd 0.1118 (0.1503) loss_oracle 0.0377 (0.0430) acc 68.7500 (70.0000) kd_loss 0.0311 (0.0269) lr 1.2487e-03 eta 0:14:28
epoch [23/50] batch [40/244] time 0.117 (0.118) data 0.001 (0.010) loss 1.2064 (1.2475) ce_loss 1.0762 (1.1339) teacher_loss 1.0750 (1.1319) loss_zs_kd 0.1815 (0.1511) loss_oracle 0.0406 (0.0401) acc 65.6250 (70.0781) kd_loss 0.0246 (0.0264) lr 1.2487e-03 eta 0:13:21
epoch [23/50] batch [60/244] time 0.104 (0.114) data 0.000 (0.007) loss 1.2175 (1.2420) ce_loss 1.0977 (1.1259) teacher_loss 1.0955 (1.1242) loss_zs_kd 0.1821 (0.1550) loss_oracle 0.0310 (0.0402) acc 71.8750 (70.7292) kd_loss 0.0201 (0.0265) lr 1.2487e-03 eta 0:12:51
epoch [23/50] batch [80/244] time 0.096 (0.111) data 0.000 (0.005) loss 1.0457 (1.2144) ce_loss 0.9292 (1.0989) teacher_loss 0.9341 (1.0974) loss_zs_kd 0.1642 (0.1540) loss_oracle 0.0295 (0.0400) acc 68.7500 (71.3281) kd_loss 0.0236 (0.0266) lr 1.2487e-03 eta 0:12:32
epoch [23/50] batch [100/244] time 0.100 (0.109) data 0.000 (0.004) loss 1.4725 (1.2016) ce_loss 1.3779 (1.0871) teacher_loss 1.3710 (1.0853) loss_zs_kd 0.1390 (0.1540) loss_oracle 0.0320 (0.0394) acc 62.5000 (71.3750) kd_loss 0.0260 (0.0267) lr 1.2487e-03 eta 0:12:15
epoch [23/50] batch [120/244] time 0.120 (0.110) data 0.000 (0.003) loss 1.3415 (1.1989) ce_loss 1.2227 (1.0850) teacher_loss 1.2257 (1.0832) loss_zs_kd 0.1425 (0.1539) loss_oracle 0.0446 (0.0388) acc 68.7500 (71.3802) kd_loss 0.0219 (0.0264) lr 1.2487e-03 eta 0:12:17
epoch [23/50] batch [140/244] time 0.099 (0.111) data 0.000 (0.003) loss 1.1452 (1.2009) ce_loss 1.0596 (1.0867) teacher_loss 1.0625 (1.0852) loss_zs_kd 0.1093 (0.1538) loss_oracle 0.0280 (0.0388) acc 81.2500 (71.2946) kd_loss 0.0211 (0.0265) lr 1.2487e-03 eta 0:12:19
epoch [23/50] batch [160/244] time 0.099 (0.109) data 0.000 (0.003) loss 1.4271 (1.2001) ce_loss 1.2988 (1.0864) teacher_loss 1.2928 (1.0847) loss_zs_kd 0.1638 (0.1532) loss_oracle 0.0525 (0.0388) acc 59.3750 (71.0938) kd_loss 0.0333 (0.0264) lr 1.2487e-03 eta 0:12:06
epoch [23/50] batch [180/244] time 0.096 (0.108) data 0.000 (0.002) loss 1.0487 (1.1999) ce_loss 0.9536 (1.0863) teacher_loss 0.9551 (1.0848) loss_zs_kd 0.1128 (0.1527) loss_oracle 0.0372 (0.0388) acc 75.0000 (71.1458) kd_loss 0.0190 (0.0263) lr 1.2487e-03 eta 0:11:56
epoch [23/50] batch [200/244] time 0.100 (0.107) data 0.000 (0.002) loss 0.8462 (1.1896) ce_loss 0.7295 (1.0764) teacher_loss 0.7309 (1.0748) loss_zs_kd 0.1656 (0.1521) loss_oracle 0.0325 (0.0388) acc 78.1250 (71.2500) kd_loss 0.0242 (0.0261) lr 1.2487e-03 eta 0:11:47
epoch [23/50] batch [220/244] time 0.102 (0.106) data 0.000 (0.002) loss 1.4701 (1.1944) ce_loss 1.3447 (1.0810) teacher_loss 1.3504 (1.0794) loss_zs_kd 0.1856 (0.1529) loss_oracle 0.0270 (0.0385) acc 65.6250 (71.0653) kd_loss 0.0183 (0.0259) lr 1.2487e-03 eta 0:11:41
epoch [23/50] batch [240/244] time 0.105 (0.106) data 0.000 (0.002) loss 0.7988 (1.1974) ce_loss 0.6909 (1.0837) teacher_loss 0.6906 (1.0822) loss_zs_kd 0.1553 (0.1541) loss_oracle 0.0305 (0.0382) acc 87.5000 (71.1328) kd_loss 0.0204 (0.0257) lr 1.2487e-03 eta 0:11:36
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,816
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.6%, epoch: 22 *******
******* Domain p best val test acc: 90.8%, epoch: 22 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [24/50] batch [20/244] time 0.098 (0.118) data 0.001 (0.014) loss 1.4049 (1.1405) ce_loss 1.3096 (1.0364) teacher_loss 1.2995 (1.0335) loss_zs_kd 0.1538 (0.1503) loss_oracle 0.0285 (0.0318) acc 65.6250 (72.1875) kd_loss 0.0251 (0.0243) lr 1.1874e-03 eta 0:12:56
epoch [24/50] batch [40/244] time 0.101 (0.110) data 0.000 (0.007) loss 1.8385 (1.2356) ce_loss 1.7324 (1.1293) teacher_loss 1.7195 (1.1263) loss_zs_kd 0.1360 (0.1471) loss_oracle 0.0510 (0.0358) acc 50.0000 (69.8438) kd_loss 0.0258 (0.0252) lr 1.1874e-03 eta 0:11:59
epoch [24/50] batch [60/244] time 0.097 (0.106) data 0.001 (0.005) loss 1.6067 (1.2556) ce_loss 1.4756 (1.1452) teacher_loss 1.4785 (1.1422) loss_zs_kd 0.1710 (0.1519) loss_oracle 0.0428 (0.0375) acc 62.5000 (69.6354) kd_loss 0.0273 (0.0250) lr 1.1874e-03 eta 0:11:31
epoch [24/50] batch [80/244] time 0.099 (0.104) data 0.000 (0.004) loss 1.2270 (1.2508) ce_loss 1.1445 (1.1375) teacher_loss 1.1430 (1.1351) loss_zs_kd 0.1200 (0.1552) loss_oracle 0.0240 (0.0381) acc 65.6250 (69.7656) kd_loss 0.0211 (0.0251) lr 1.1874e-03 eta 0:11:14
epoch [24/50] batch [100/244] time 0.086 (0.101) data 0.000 (0.003) loss 1.0839 (1.2218) ce_loss 0.9663 (1.1089) teacher_loss 0.9689 (1.1064) loss_zs_kd 0.1561 (0.1547) loss_oracle 0.0370 (0.0381) acc 75.0000 (70.4688) kd_loss 0.0226 (0.0255) lr 1.1874e-03 eta 0:10:55
epoch [24/50] batch [120/244] time 0.095 (0.099) data 0.000 (0.003) loss 1.3919 (1.2251) ce_loss 1.2754 (1.1135) teacher_loss 1.2749 (1.1110) loss_zs_kd 0.1515 (0.1525) loss_oracle 0.0413 (0.0378) acc 68.7500 (70.6250) kd_loss 0.0329 (0.0255) lr 1.1874e-03 eta 0:10:39
epoch [24/50] batch [140/244] time 0.093 (0.098) data 0.000 (0.002) loss 0.9158 (1.2257) ce_loss 0.8164 (1.1142) teacher_loss 0.8029 (1.1117) loss_zs_kd 0.1521 (0.1521) loss_oracle 0.0369 (0.0380) acc 84.3750 (70.6696) kd_loss 0.0241 (0.0255) lr 1.1874e-03 eta 0:10:30
epoch [24/50] batch [160/244] time 0.098 (0.097) data 0.000 (0.002) loss 1.2681 (1.2072) ce_loss 1.1484 (1.0960) teacher_loss 1.1515 (1.0936) loss_zs_kd 0.1737 (0.1512) loss_oracle 0.0298 (0.0381) acc 65.6250 (70.8008) kd_loss 0.0204 (0.0257) lr 1.1874e-03 eta 0:10:23
epoch [24/50] batch [180/244] time 0.083 (0.096) data 0.000 (0.002) loss 1.3069 (1.2161) ce_loss 1.1680 (1.1057) teacher_loss 1.1722 (1.1034) loss_zs_kd 0.1986 (0.1499) loss_oracle 0.0354 (0.0377) acc 62.5000 (70.5382) kd_loss 0.0212 (0.0253) lr 1.1874e-03 eta 0:10:16
epoch [24/50] batch [200/244] time 0.094 (0.095) data 0.000 (0.002) loss 1.1723 (1.2068) ce_loss 1.0674 (1.0953) teacher_loss 1.0680 (1.0933) loss_zs_kd 0.1528 (0.1516) loss_oracle 0.0279 (0.0377) acc 78.1250 (70.8438) kd_loss 0.0186 (0.0252) lr 1.1874e-03 eta 0:10:09
epoch [24/50] batch [220/244] time 0.097 (0.095) data 0.000 (0.001) loss 1.4820 (1.1958) ce_loss 1.3623 (1.0832) teacher_loss 1.3592 (1.0814) loss_zs_kd 0.1733 (0.1528) loss_oracle 0.0361 (0.0380) acc 62.5000 (71.1080) kd_loss 0.0242 (0.0253) lr 1.1874e-03 eta 0:10:05
epoch [24/50] batch [240/244] time 0.105 (0.096) data 0.000 (0.001) loss 1.4090 (1.1974) ce_loss 1.2842 (1.0845) teacher_loss 1.2826 (1.0828) loss_zs_kd 0.1619 (0.1531) loss_oracle 0.0454 (0.0380) acc 62.5000 (71.1198) kd_loss 0.0292 (0.0254) lr 1.1874e-03 eta 0:10:06
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,827
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.7%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,046
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [25/50] batch [20/244] time 0.103 (0.123) data 0.000 (0.014) loss 0.9871 (1.1824) ce_loss 0.8701 (1.0738) teacher_loss 0.8611 (1.0727) loss_zs_kd 0.1359 (0.1344) loss_oracle 0.0580 (0.0425) acc 71.8750 (70.4688) kd_loss 0.0317 (0.0289) lr 1.1253e-03 eta 0:12:55
epoch [25/50] batch [40/244] time 0.109 (0.114) data 0.000 (0.007) loss 1.0587 (1.1749) ce_loss 0.9517 (1.0673) teacher_loss 0.9410 (1.0672) loss_zs_kd 0.1507 (0.1363) loss_oracle 0.0423 (0.0396) acc 71.8750 (70.7031) kd_loss 0.0315 (0.0278) lr 1.1253e-03 eta 0:11:59
epoch [25/50] batch [60/244] time 0.095 (0.111) data 0.000 (0.005) loss 1.0413 (1.1599) ce_loss 0.9297 (1.0490) teacher_loss 0.9365 (1.0487) loss_zs_kd 0.1487 (0.1417) loss_oracle 0.0305 (0.0403) acc 78.1250 (72.0312) kd_loss 0.0266 (0.0285) lr 1.1253e-03 eta 0:11:36
epoch [25/50] batch [80/244] time 0.120 (0.109) data 0.000 (0.004) loss 1.0436 (1.1880) ce_loss 0.8804 (1.0731) teacher_loss 0.8853 (1.0728) loss_zs_kd 0.2521 (0.1497) loss_oracle 0.0322 (0.0404) acc 81.2500 (71.7578) kd_loss 0.0298 (0.0286) lr 1.1253e-03 eta 0:11:22
epoch [25/50] batch [100/244] time 0.104 (0.109) data 0.000 (0.003) loss 1.3901 (1.1948) ce_loss 1.2783 (1.0758) teacher_loss 1.2716 (1.0753) loss_zs_kd 0.1378 (0.1570) loss_oracle 0.0496 (0.0410) acc 65.6250 (71.7500) kd_loss 0.0323 (0.0291) lr 1.1253e-03 eta 0:11:23
epoch [25/50] batch [120/244] time 0.102 (0.108) data 0.000 (0.003) loss 1.6010 (1.1942) ce_loss 1.4971 (1.0726) teacher_loss 1.4988 (1.0721) loss_zs_kd 0.1259 (0.1598) loss_oracle 0.0392 (0.0423) acc 59.3750 (71.6146) kd_loss 0.0347 (0.0302) lr 1.1253e-03 eta 0:11:14
epoch [25/50] batch [140/244] time 0.107 (0.108) data 0.000 (0.002) loss 1.2695 (1.2046) ce_loss 1.1279 (1.0832) teacher_loss 1.1247 (1.0824) loss_zs_kd 0.1899 (0.1588) loss_oracle 0.0499 (0.0429) acc 68.7500 (71.3170) kd_loss 0.0417 (0.0307) lr 1.1253e-03 eta 0:11:08
epoch [25/50] batch [160/244] time 0.108 (0.108) data 0.001 (0.002) loss 1.3774 (1.2075) ce_loss 1.2607 (1.0867) teacher_loss 1.2467 (1.0856) loss_zs_kd 0.1628 (0.1575) loss_oracle 0.0493 (0.0432) acc 71.8750 (71.4062) kd_loss 0.0401 (0.0315) lr 1.1253e-03 eta 0:11:05
epoch [25/50] batch [180/244] time 0.105 (0.108) data 0.000 (0.002) loss 1.4610 (1.2052) ce_loss 1.3604 (1.0846) teacher_loss 1.3690 (1.0833) loss_zs_kd 0.1299 (0.1568) loss_oracle 0.0270 (0.0436) acc 62.5000 (71.3889) kd_loss 0.0226 (0.0320) lr 1.1253e-03 eta 0:11:05
epoch [25/50] batch [200/244] time 0.104 (0.108) data 0.000 (0.002) loss 1.1255 (1.2082) ce_loss 0.9814 (1.0882) teacher_loss 0.9769 (1.0868) loss_zs_kd 0.2002 (0.1562) loss_oracle 0.0485 (0.0433) acc 78.1250 (71.4531) kd_loss 0.0499 (0.0321) lr 1.1253e-03 eta 0:11:00
epoch [25/50] batch [220/244] time 0.118 (0.107) data 0.001 (0.002) loss 0.8327 (1.2055) ce_loss 0.6909 (1.0864) teacher_loss 0.6863 (1.0851) loss_zs_kd 0.2093 (0.1550) loss_oracle 0.0418 (0.0428) acc 75.0000 (71.3778) kd_loss 0.0386 (0.0321) lr 1.1253e-03 eta 0:10:57
epoch [25/50] batch [240/244] time 0.105 (0.107) data 0.000 (0.001) loss 1.0474 (1.2063) ce_loss 0.9297 (1.0872) teacher_loss 0.9305 (1.0857) loss_zs_kd 0.1352 (0.1558) loss_oracle 0.0494 (0.0427) acc 78.1250 (71.4714) kd_loss 0.0324 (0.0323) lr 1.1253e-03 eta 0:10:56
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,817
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,032
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [26/50] batch [20/244] time 0.097 (0.116) data 0.000 (0.013) loss 1.0505 (1.1574) ce_loss 0.9175 (1.0392) teacher_loss 0.9125 (1.0316) loss_zs_kd 0.1544 (0.1570) loss_oracle 0.0608 (0.0472) acc 75.0000 (71.8750) kd_loss 0.0425 (0.0373) lr 1.0628e-03 eta 0:11:43
epoch [26/50] batch [40/244] time 0.095 (0.105) data 0.000 (0.007) loss 1.3133 (1.1292) ce_loss 1.2051 (1.0064) teacher_loss 1.2026 (1.0015) loss_zs_kd 0.1318 (0.1633) loss_oracle 0.0448 (0.0461) acc 65.6250 (72.5781) kd_loss 0.0322 (0.0345) lr 1.0628e-03 eta 0:10:36
epoch [26/50] batch [60/244] time 0.091 (0.101) data 0.000 (0.004) loss 0.8615 (1.1659) ce_loss 0.7461 (1.0435) teacher_loss 0.7503 (1.0394) loss_zs_kd 0.1356 (0.1579) loss_oracle 0.0434 (0.0476) acc 84.3750 (71.7188) kd_loss 0.0223 (0.0345) lr 1.0628e-03 eta 0:10:10
epoch [26/50] batch [80/244] time 0.089 (0.099) data 0.000 (0.003) loss 1.0517 (1.1768) ce_loss 0.9141 (1.0526) teacher_loss 0.9206 (1.0485) loss_zs_kd 0.1591 (0.1579) loss_oracle 0.0515 (0.0494) acc 81.2500 (71.6016) kd_loss 0.0328 (0.0353) lr 1.0628e-03 eta 0:09:58
epoch [26/50] batch [100/244] time 0.100 (0.099) data 0.000 (0.003) loss 1.4133 (1.1777) ce_loss 1.3125 (1.0543) teacher_loss 1.3102 (1.0503) loss_zs_kd 0.1350 (0.1572) loss_oracle 0.0356 (0.0488) acc 62.5000 (71.4688) kd_loss 0.0327 (0.0353) lr 1.0628e-03 eta 0:09:51
epoch [26/50] batch [120/244] time 0.101 (0.098) data 0.000 (0.002) loss 1.0268 (1.1797) ce_loss 0.9004 (1.0582) teacher_loss 0.8941 (1.0544) loss_zs_kd 0.1603 (0.1552) loss_oracle 0.0525 (0.0477) acc 71.8750 (71.4323) kd_loss 0.0410 (0.0350) lr 1.0628e-03 eta 0:09:46
epoch [26/50] batch [140/244] time 0.104 (0.098) data 0.000 (0.002) loss 1.6400 (1.1934) ce_loss 1.5391 (1.0727) teacher_loss 1.5390 (1.0692) loss_zs_kd 0.1129 (0.1547) loss_oracle 0.0446 (0.0468) acc 65.6250 (71.3616) kd_loss 0.0308 (0.0345) lr 1.0628e-03 eta 0:09:45
epoch [26/50] batch [160/244] time 0.093 (0.098) data 0.000 (0.002) loss 1.5250 (1.2036) ce_loss 1.3994 (1.0827) teacher_loss 1.3902 (1.0788) loss_zs_kd 0.1767 (0.1557) loss_oracle 0.0465 (0.0470) acc 65.6250 (71.1914) kd_loss 0.0394 (0.0348) lr 1.0628e-03 eta 0:09:44
epoch [26/50] batch [180/244] time 0.093 (0.098) data 0.000 (0.002) loss 0.9206 (1.1898) ce_loss 0.7495 (1.0689) teacher_loss 0.7462 (1.0653) loss_zs_kd 0.2255 (0.1549) loss_oracle 0.0616 (0.0470) acc 78.1250 (71.4931) kd_loss 0.0389 (0.0347) lr 1.0628e-03 eta 0:09:40
epoch [26/50] batch [200/244] time 0.096 (0.098) data 0.000 (0.001) loss 0.8796 (1.1925) ce_loss 0.7705 (1.0718) teacher_loss 0.7694 (1.0682) loss_zs_kd 0.1452 (0.1546) loss_oracle 0.0376 (0.0469) acc 84.3750 (71.5156) kd_loss 0.0315 (0.0347) lr 1.0628e-03 eta 0:09:37
epoch [26/50] batch [220/244] time 0.096 (0.098) data 0.000 (0.001) loss 1.1176 (1.2004) ce_loss 1.0303 (1.0798) teacher_loss 1.0223 (1.0764) loss_zs_kd 0.1164 (0.1547) loss_oracle 0.0372 (0.0467) acc 75.0000 (71.3210) kd_loss 0.0326 (0.0344) lr 1.0628e-03 eta 0:09:34
epoch [26/50] batch [240/244] time 0.087 (0.097) data 0.000 (0.001) loss 1.0266 (1.2012) ce_loss 0.9517 (1.0809) teacher_loss 0.9402 (1.0772) loss_zs_kd 0.0827 (0.1539) loss_oracle 0.0451 (0.0470) acc 75.0000 (71.2760) kd_loss 0.0305 (0.0344) lr 1.0628e-03 eta 0:09:28
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,827
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,040
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.6%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [27/50] batch [20/244] time 0.109 (0.115) data 0.000 (0.014) loss 1.1970 (1.1129) ce_loss 1.0713 (0.9977) teacher_loss 1.0666 (0.9942) loss_zs_kd 0.1561 (0.1485) loss_oracle 0.0523 (0.0445) acc 65.6250 (72.3438) kd_loss 0.0341 (0.0322) lr 1.0000e-03 eta 0:11:12
epoch [27/50] batch [40/244] time 0.097 (0.108) data 0.000 (0.007) loss 0.8223 (1.1467) ce_loss 0.7261 (1.0286) teacher_loss 0.7213 (1.0263) loss_zs_kd 0.1076 (0.1534) loss_oracle 0.0471 (0.0438) acc 75.0000 (73.2031) kd_loss 0.0305 (0.0317) lr 1.0000e-03 eta 0:10:27
epoch [27/50] batch [60/244] time 0.102 (0.106) data 0.000 (0.005) loss 1.3283 (1.1816) ce_loss 1.2031 (1.0623) teacher_loss 1.2098 (1.0600) loss_zs_kd 0.1521 (0.1565) loss_oracle 0.0425 (0.0433) acc 71.8750 (72.2917) kd_loss 0.0273 (0.0311) lr 1.0000e-03 eta 0:10:15
epoch [27/50] batch [80/244] time 0.104 (0.109) data 0.000 (0.004) loss 1.6432 (1.1962) ce_loss 1.5254 (1.0752) teacher_loss 1.5056 (1.0725) loss_zs_kd 0.1598 (0.1592) loss_oracle 0.0578 (0.0441) acc 56.2500 (71.7188) kd_loss 0.0299 (0.0307) lr 1.0000e-03 eta 0:10:27
epoch [27/50] batch [100/244] time 0.126 (0.111) data 0.000 (0.003) loss 1.0936 (1.1876) ce_loss 0.9692 (1.0643) teacher_loss 0.9703 (1.0618) loss_zs_kd 0.1499 (0.1623) loss_oracle 0.0483 (0.0446) acc 71.8750 (72.2812) kd_loss 0.0254 (0.0305) lr 1.0000e-03 eta 0:10:39
epoch [27/50] batch [120/244] time 0.130 (0.113) data 0.001 (0.003) loss 0.7693 (1.1886) ce_loss 0.6426 (1.0648) teacher_loss 0.6480 (1.0622) loss_zs_kd 0.1709 (0.1641) loss_oracle 0.0359 (0.0444) acc 87.5000 (72.1094) kd_loss 0.0231 (0.0302) lr 1.0000e-03 eta 0:10:49
epoch [27/50] batch [140/244] time 0.125 (0.115) data 0.000 (0.002) loss 0.9600 (1.1757) ce_loss 0.8296 (1.0528) teacher_loss 0.8347 (1.0506) loss_zs_kd 0.1432 (0.1618) loss_oracle 0.0536 (0.0442) acc 75.0000 (72.3214) kd_loss 0.0295 (0.0298) lr 1.0000e-03 eta 0:10:58
epoch [27/50] batch [160/244] time 0.118 (0.116) data 0.000 (0.002) loss 1.1252 (1.1694) ce_loss 1.0117 (1.0458) teacher_loss 0.9874 (1.0432) loss_zs_kd 0.1576 (0.1626) loss_oracle 0.0590 (0.0449) acc 68.7500 (72.3242) kd_loss 0.0389 (0.0301) lr 1.0000e-03 eta 0:11:02
epoch [27/50] batch [180/244] time 0.122 (0.117) data 0.001 (0.002) loss 1.1074 (1.1683) ce_loss 0.9966 (1.0458) teacher_loss 0.9968 (1.0434) loss_zs_kd 0.1527 (0.1615) loss_oracle 0.0342 (0.0442) acc 71.8750 (72.5521) kd_loss 0.0303 (0.0299) lr 1.0000e-03 eta 0:11:05
epoch [27/50] batch [200/244] time 0.131 (0.118) data 0.000 (0.002) loss 1.4634 (1.1735) ce_loss 1.3545 (1.0521) teacher_loss 1.3458 (1.0497) loss_zs_kd 0.1433 (0.1601) loss_oracle 0.0460 (0.0437) acc 62.5000 (72.4375) kd_loss 0.0263 (0.0297) lr 1.0000e-03 eta 0:11:07
epoch [27/50] batch [220/244] time 0.123 (0.118) data 0.000 (0.002) loss 1.1293 (1.1694) ce_loss 1.0010 (1.0480) teacher_loss 1.0002 (1.0458) loss_zs_kd 0.1563 (0.1603) loss_oracle 0.0510 (0.0435) acc 68.7500 (72.5852) kd_loss 0.0340 (0.0296) lr 1.0000e-03 eta 0:11:07
epoch [27/50] batch [240/244] time 0.103 (0.118) data 0.000 (0.002) loss 1.2068 (1.1727) ce_loss 1.1104 (1.0521) teacher_loss 1.1121 (1.0498) loss_zs_kd 0.1362 (0.1587) loss_oracle 0.0266 (0.0436) acc 71.8750 (72.4740) kd_loss 0.0175 (0.0297) lr 1.0000e-03 eta 0:11:02
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,830
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,049
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.8%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.2%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [28/50] batch [20/244] time 0.081 (0.118) data 0.000 (0.020) loss 1.3983 (1.1503) ce_loss 1.2393 (1.0249) teacher_loss 1.2360 (1.0237) loss_zs_kd 0.2107 (0.1576) loss_oracle 0.0569 (0.0478) acc 71.8750 (73.2812) kd_loss 0.0314 (0.0288) lr 9.3721e-04 eta 0:10:57
epoch [28/50] batch [40/244] time 0.112 (0.105) data 0.000 (0.010) loss 1.3348 (1.1929) ce_loss 1.1865 (1.0674) teacher_loss 1.1849 (1.0658) loss_zs_kd 0.1934 (0.1599) loss_oracle 0.0532 (0.0471) acc 68.7500 (71.8750) kd_loss 0.0271 (0.0292) lr 9.3721e-04 eta 0:09:46
epoch [28/50] batch [60/244] time 0.085 (0.100) data 0.000 (0.007) loss 1.2968 (1.1796) ce_loss 1.1699 (1.0582) teacher_loss 1.1664 (1.0560) loss_zs_kd 0.1706 (0.1565) loss_oracle 0.0451 (0.0454) acc 68.7500 (72.0312) kd_loss 0.0283 (0.0289) lr 9.3721e-04 eta 0:09:17
epoch [28/50] batch [80/244] time 0.107 (0.098) data 0.000 (0.005) loss 1.6287 (1.2109) ce_loss 1.4932 (1.0911) teacher_loss 1.4853 (1.0888) loss_zs_kd 0.1895 (0.1564) loss_oracle 0.0487 (0.0439) acc 68.7500 (71.4844) kd_loss 0.0348 (0.0284) lr 9.3721e-04 eta 0:09:01
epoch [28/50] batch [100/244] time 0.081 (0.096) data 0.000 (0.004) loss 1.3936 (1.2084) ce_loss 1.2842 (1.0882) teacher_loss 1.2780 (1.0860) loss_zs_kd 0.1593 (0.1568) loss_oracle 0.0359 (0.0440) acc 59.3750 (71.6562) kd_loss 0.0268 (0.0280) lr 9.3721e-04 eta 0:08:50
epoch [28/50] batch [120/244] time 0.092 (0.095) data 0.000 (0.003) loss 1.1523 (1.2167) ce_loss 1.0244 (1.0950) teacher_loss 1.0178 (1.0933) loss_zs_kd 0.1616 (0.1592) loss_oracle 0.0536 (0.0438) acc 81.2500 (71.4062) kd_loss 0.0291 (0.0276) lr 9.3721e-04 eta 0:08:43
epoch [28/50] batch [140/244] time 0.088 (0.094) data 0.000 (0.003) loss 1.3881 (1.2042) ce_loss 1.2695 (1.0823) teacher_loss 1.2613 (1.0803) loss_zs_kd 0.1587 (0.1590) loss_oracle 0.0474 (0.0444) acc 65.6250 (71.7411) kd_loss 0.0283 (0.0276) lr 9.3721e-04 eta 0:08:36
epoch [28/50] batch [160/244] time 0.102 (0.095) data 0.000 (0.003) loss 1.4543 (1.1988) ce_loss 1.2803 (1.0770) teacher_loss 1.2706 (1.0747) loss_zs_kd 0.2521 (0.1596) loss_oracle 0.0576 (0.0443) acc 59.3750 (71.9336) kd_loss 0.0353 (0.0277) lr 9.3721e-04 eta 0:08:35
epoch [28/50] batch [180/244] time 0.098 (0.096) data 0.000 (0.002) loss 0.9454 (1.1896) ce_loss 0.8110 (1.0686) teacher_loss 0.8223 (1.0663) loss_zs_kd 0.1732 (0.1584) loss_oracle 0.0365 (0.0442) acc 81.2500 (72.1354) kd_loss 0.0243 (0.0277) lr 9.3721e-04 eta 0:08:39
epoch [28/50] batch [200/244] time 0.100 (0.097) data 0.000 (0.002) loss 1.1516 (1.1810) ce_loss 1.0000 (1.0599) teacher_loss 0.9955 (1.0578) loss_zs_kd 0.1987 (0.1583) loss_oracle 0.0567 (0.0440) acc 68.7500 (72.2188) kd_loss 0.0335 (0.0277) lr 9.3721e-04 eta 0:08:42
epoch [28/50] batch [220/244] time 0.100 (0.097) data 0.000 (0.002) loss 1.0006 (1.1748) ce_loss 0.8662 (1.0536) teacher_loss 0.8638 (1.0517) loss_zs_kd 0.1899 (0.1588) loss_oracle 0.0418 (0.0437) acc 81.2500 (72.3722) kd_loss 0.0319 (0.0276) lr 9.3721e-04 eta 0:08:42
epoch [28/50] batch [240/244] time 0.086 (0.097) data 0.000 (0.002) loss 1.1495 (1.1726) ce_loss 1.0430 (1.0513) teacher_loss 1.0412 (1.0492) loss_zs_kd 0.1194 (0.1590) loss_oracle 0.0486 (0.0439) acc 71.8750 (72.3958) kd_loss 0.0286 (0.0278) lr 9.3721e-04 eta 0:08:39
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.2%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [29/50] batch [20/244] time 0.105 (0.108) data 0.000 (0.013) loss 0.9602 (1.1548) ce_loss 0.8496 (1.0349) teacher_loss 0.8498 (1.0322) loss_zs_kd 0.1452 (0.1603) loss_oracle 0.0378 (0.0425) acc 78.1250 (74.2188) kd_loss 0.0228 (0.0297) lr 8.7467e-04 eta 0:09:35
epoch [29/50] batch [40/244] time 0.093 (0.102) data 0.000 (0.007) loss 1.4505 (1.1949) ce_loss 1.3262 (1.0730) teacher_loss 1.3305 (1.0697) loss_zs_kd 0.1384 (0.1608) loss_oracle 0.0508 (0.0449) acc 62.5000 (72.1094) kd_loss 0.0314 (0.0304) lr 8.7467e-04 eta 0:09:03
epoch [29/50] batch [60/244] time 0.093 (0.101) data 0.001 (0.005) loss 1.5819 (1.1972) ce_loss 1.4590 (1.0768) teacher_loss 1.4549 (1.0743) loss_zs_kd 0.1394 (0.1541) loss_oracle 0.0573 (0.0458) acc 62.5000 (71.7708) kd_loss 0.0310 (0.0292) lr 8.7467e-04 eta 0:08:55
epoch [29/50] batch [80/244] time 0.096 (0.099) data 0.000 (0.004) loss 0.5631 (1.2027) ce_loss 0.4546 (1.0824) teacher_loss 0.4527 (1.0792) loss_zs_kd 0.1446 (0.1541) loss_oracle 0.0381 (0.0465) acc 93.7500 (71.8750) kd_loss 0.0248 (0.0289) lr 8.7467e-04 eta 0:08:44
epoch [29/50] batch [100/244] time 0.098 (0.098) data 0.000 (0.003) loss 1.3355 (1.2158) ce_loss 1.2480 (1.0946) teacher_loss 1.2459 (1.0916) loss_zs_kd 0.0960 (0.1563) loss_oracle 0.0415 (0.0461) acc 68.7500 (71.3750) kd_loss 0.0267 (0.0285) lr 8.7467e-04 eta 0:08:38
epoch [29/50] batch [120/244] time 0.099 (0.098) data 0.000 (0.002) loss 1.3234 (1.2258) ce_loss 1.1719 (1.1038) teacher_loss 1.1795 (1.1007) loss_zs_kd 0.2093 (0.1585) loss_oracle 0.0393 (0.0458) acc 68.7500 (71.0938) kd_loss 0.0204 (0.0284) lr 8.7467e-04 eta 0:08:36
epoch [29/50] batch [140/244] time 0.095 (0.098) data 0.000 (0.002) loss 2.0004 (1.2228) ce_loss 1.8721 (1.1011) teacher_loss 1.8750 (1.0980) loss_zs_kd 0.1908 (0.1589) loss_oracle 0.0300 (0.0453) acc 53.1250 (71.0045) kd_loss 0.0196 (0.0280) lr 8.7467e-04 eta 0:08:32
epoch [29/50] batch [160/244] time 0.107 (0.098) data 0.000 (0.002) loss 1.1531 (1.2136) ce_loss 1.0137 (1.0923) teacher_loss 1.0099 (1.0892) loss_zs_kd 0.1900 (0.1586) loss_oracle 0.0482 (0.0451) acc 75.0000 (71.2891) kd_loss 0.0290 (0.0278) lr 8.7467e-04 eta 0:08:28
epoch [29/50] batch [180/244] time 0.101 (0.098) data 0.000 (0.002) loss 1.9338 (1.2235) ce_loss 1.8223 (1.1030) teacher_loss 1.8257 (1.0999) loss_zs_kd 0.1518 (0.1578) loss_oracle 0.0321 (0.0447) acc 56.2500 (71.2500) kd_loss 0.0213 (0.0275) lr 8.7467e-04 eta 0:08:27
epoch [29/50] batch [200/244] time 0.109 (0.098) data 0.000 (0.002) loss 1.3132 (1.2173) ce_loss 1.1641 (1.0961) teacher_loss 1.1543 (1.0928) loss_zs_kd 0.1874 (0.1585) loss_oracle 0.0651 (0.0453) acc 65.6250 (71.3281) kd_loss 0.0381 (0.0280) lr 8.7467e-04 eta 0:08:24
epoch [29/50] batch [220/244] time 0.097 (0.098) data 0.000 (0.001) loss 0.8206 (1.2148) ce_loss 0.7178 (1.0936) teacher_loss 0.7235 (1.0903) loss_zs_kd 0.1353 (0.1585) loss_oracle 0.0294 (0.0453) acc 84.3750 (71.4205) kd_loss 0.0167 (0.0278) lr 8.7467e-04 eta 0:08:22
epoch [29/50] batch [240/244] time 0.086 (0.097) data 0.000 (0.001) loss 0.7473 (1.2051) ce_loss 0.6338 (1.0836) teacher_loss 0.6195 (1.0801) loss_zs_kd 0.1297 (0.1583) loss_oracle 0.0629 (0.0458) acc 87.5000 (71.6276) kd_loss 0.0414 (0.0282) lr 8.7467e-04 eta 0:08:16
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,826
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.2%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [30/50] batch [20/244] time 0.090 (0.109) data 0.000 (0.014) loss 0.9262 (1.1316) ce_loss 0.8076 (1.0097) teacher_loss 0.8066 (1.0069) loss_zs_kd 0.1160 (0.1514) loss_oracle 0.0616 (0.0490) acc 75.0000 (74.0625) kd_loss 0.0423 (0.0300) lr 8.1262e-04 eta 0:09:18
epoch [30/50] batch [40/244] time 0.096 (0.102) data 0.000 (0.007) loss 0.8735 (1.1355) ce_loss 0.7637 (1.0162) teacher_loss 0.7650 (1.0134) loss_zs_kd 0.1229 (0.1477) loss_oracle 0.0470 (0.0483) acc 81.2500 (73.6719) kd_loss 0.0307 (0.0311) lr 8.1262e-04 eta 0:08:36
epoch [30/50] batch [60/244] time 0.098 (0.099) data 0.001 (0.005) loss 0.9471 (1.1622) ce_loss 0.8281 (1.0437) teacher_loss 0.8217 (1.0404) loss_zs_kd 0.1713 (0.1493) loss_oracle 0.0397 (0.0471) acc 84.3750 (72.7083) kd_loss 0.0356 (0.0316) lr 8.1262e-04 eta 0:08:22
epoch [30/50] batch [80/244] time 0.089 (0.098) data 0.000 (0.004) loss 0.9253 (1.1736) ce_loss 0.7876 (1.0560) teacher_loss 0.7830 (1.0527) loss_zs_kd 0.1751 (0.1494) loss_oracle 0.0547 (0.0461) acc 75.0000 (72.2656) kd_loss 0.0423 (0.0314) lr 8.1262e-04 eta 0:08:13
epoch [30/50] batch [100/244] time 0.093 (0.097) data 0.000 (0.003) loss 0.7027 (1.1904) ce_loss 0.5840 (1.0713) teacher_loss 0.5855 (1.0676) loss_zs_kd 0.1335 (0.1521) loss_oracle 0.0505 (0.0468) acc 87.5000 (71.7812) kd_loss 0.0347 (0.0315) lr 8.1262e-04 eta 0:08:08
epoch [30/50] batch [120/244] time 0.093 (0.097) data 0.000 (0.002) loss 1.0844 (1.1867) ce_loss 0.9741 (1.0664) teacher_loss 0.9752 (1.0628) loss_zs_kd 0.1294 (0.1532) loss_oracle 0.0445 (0.0473) acc 71.8750 (71.6406) kd_loss 0.0318 (0.0317) lr 8.1262e-04 eta 0:08:04
epoch [30/50] batch [140/244] time 0.096 (0.097) data 0.000 (0.002) loss 0.9350 (1.1700) ce_loss 0.7632 (1.0486) teacher_loss 0.7585 (1.0451) loss_zs_kd 0.2405 (0.1548) loss_oracle 0.0563 (0.0476) acc 78.1250 (72.1429) kd_loss 0.0346 (0.0318) lr 8.1262e-04 eta 0:08:01
epoch [30/50] batch [160/244] time 0.096 (0.096) data 0.000 (0.002) loss 0.8295 (1.1776) ce_loss 0.7100 (1.0552) teacher_loss 0.7094 (1.0518) loss_zs_kd 0.1795 (0.1576) loss_oracle 0.0304 (0.0471) acc 71.8750 (71.9141) kd_loss 0.0235 (0.0319) lr 8.1262e-04 eta 0:07:58
epoch [30/50] batch [180/244] time 0.098 (0.096) data 0.000 (0.002) loss 1.1722 (1.1747) ce_loss 1.0469 (1.0527) teacher_loss 1.0379 (1.0493) loss_zs_kd 0.1664 (0.1576) loss_oracle 0.0511 (0.0466) acc 71.8750 (72.0486) kd_loss 0.0398 (0.0322) lr 8.1262e-04 eta 0:07:55
epoch [30/50] batch [200/244] time 0.096 (0.096) data 0.000 (0.002) loss 0.9941 (1.1731) ce_loss 0.8701 (1.0508) teacher_loss 0.8554 (1.0476) loss_zs_kd 0.1459 (0.1584) loss_oracle 0.0658 (0.0463) acc 71.8750 (72.0625) kd_loss 0.0466 (0.0322) lr 8.1262e-04 eta 0:07:52
epoch [30/50] batch [220/244] time 0.094 (0.096) data 0.000 (0.001) loss 1.2162 (1.1791) ce_loss 1.0859 (1.0566) teacher_loss 1.0816 (1.0533) loss_zs_kd 0.1646 (0.1595) loss_oracle 0.0523 (0.0461) acc 71.8750 (71.9176) kd_loss 0.0413 (0.0323) lr 8.1262e-04 eta 0:07:51
epoch [30/50] batch [240/244] time 0.086 (0.096) data 0.000 (0.001) loss 1.0230 (1.1854) ce_loss 0.9160 (1.0636) teacher_loss 0.9076 (1.0605) loss_zs_kd 0.1452 (0.1582) loss_oracle 0.0428 (0.0458) acc 68.7500 (71.7448) kd_loss 0.0373 (0.0323) lr 8.1262e-04 eta 0:07:47
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.2%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [31/50] batch [20/244] time 0.101 (0.122) data 0.000 (0.016) loss 0.8031 (1.1372) ce_loss 0.6646 (1.0247) teacher_loss 0.6649 (1.0209) loss_zs_kd 0.1794 (0.1467) loss_oracle 0.0485 (0.0430) acc 78.1250 (71.4062) kd_loss 0.0344 (0.0331) lr 7.5131e-04 eta 0:09:51
epoch [31/50] batch [40/244] time 0.104 (0.114) data 0.000 (0.008) loss 1.1507 (1.1518) ce_loss 1.0410 (1.0319) teacher_loss 1.0411 (1.0293) loss_zs_kd 0.1623 (0.1606) loss_oracle 0.0285 (0.0422) acc 71.8750 (71.3281) kd_loss 0.0221 (0.0318) lr 7.5131e-04 eta 0:09:11
epoch [31/50] batch [60/244] time 0.100 (0.110) data 0.001 (0.006) loss 1.5615 (1.1903) ce_loss 1.4365 (1.0704) teacher_loss 1.4330 (1.0679) loss_zs_kd 0.1679 (0.1597) loss_oracle 0.0446 (0.0425) acc 62.5000 (70.6771) kd_loss 0.0254 (0.0312) lr 7.5131e-04 eta 0:08:48
epoch [31/50] batch [80/244] time 0.103 (0.107) data 0.000 (0.004) loss 1.3523 (1.1649) ce_loss 1.2412 (1.0441) teacher_loss 1.2385 (1.0416) loss_zs_kd 0.1629 (0.1592) loss_oracle 0.0324 (0.0437) acc 65.6250 (71.7969) kd_loss 0.0200 (0.0313) lr 7.5131e-04 eta 0:08:35
epoch [31/50] batch [100/244] time 0.098 (0.107) data 0.000 (0.003) loss 1.3591 (1.1460) ce_loss 1.2012 (1.0253) teacher_loss 1.2012 (1.0228) loss_zs_kd 0.2267 (0.1597) loss_oracle 0.0446 (0.0434) acc 68.7500 (72.1875) kd_loss 0.0381 (0.0316) lr 7.5131e-04 eta 0:08:29
epoch [31/50] batch [120/244] time 0.100 (0.106) data 0.000 (0.003) loss 1.3775 (1.1696) ce_loss 1.1641 (1.0476) teacher_loss 1.1560 (1.0446) loss_zs_kd 0.3114 (0.1617) loss_oracle 0.0657 (0.0441) acc 65.6250 (71.6406) kd_loss 0.0400 (0.0321) lr 7.5131e-04 eta 0:08:22
epoch [31/50] batch [140/244] time 0.109 (0.105) data 0.000 (0.003) loss 0.8392 (1.1820) ce_loss 0.7007 (1.0604) teacher_loss 0.7071 (1.0576) loss_zs_kd 0.1698 (0.1611) loss_oracle 0.0471 (0.0438) acc 84.3750 (71.6071) kd_loss 0.0321 (0.0319) lr 7.5131e-04 eta 0:08:17
epoch [31/50] batch [160/244] time 0.101 (0.104) data 0.000 (0.002) loss 1.1935 (1.1703) ce_loss 1.0781 (1.0491) teacher_loss 1.0821 (1.0461) loss_zs_kd 0.1499 (0.1599) loss_oracle 0.0365 (0.0443) acc 75.0000 (71.9922) kd_loss 0.0293 (0.0323) lr 7.5131e-04 eta 0:08:12
epoch [31/50] batch [180/244] time 0.102 (0.104) data 0.000 (0.002) loss 0.9372 (1.1648) ce_loss 0.8101 (1.0430) teacher_loss 0.8126 (1.0401) loss_zs_kd 0.1517 (0.1608) loss_oracle 0.0487 (0.0443) acc 75.0000 (72.2396) kd_loss 0.0321 (0.0324) lr 7.5131e-04 eta 0:08:07
epoch [31/50] batch [200/244] time 0.103 (0.104) data 0.000 (0.002) loss 1.4830 (1.1718) ce_loss 1.3398 (1.0507) teacher_loss 1.3380 (1.0475) loss_zs_kd 0.2041 (0.1604) loss_oracle 0.0430 (0.0441) acc 71.8750 (71.9688) kd_loss 0.0323 (0.0324) lr 7.5131e-04 eta 0:08:04
epoch [31/50] batch [220/244] time 0.098 (0.103) data 0.000 (0.002) loss 1.0113 (1.1763) ce_loss 0.9189 (1.0558) teacher_loss 0.9207 (1.0528) loss_zs_kd 0.1179 (0.1595) loss_oracle 0.0317 (0.0438) acc 68.7500 (71.8892) kd_loss 0.0273 (0.0323) lr 7.5131e-04 eta 0:08:01
epoch [31/50] batch [240/244] time 0.102 (0.103) data 0.000 (0.002) loss 0.9429 (1.1784) ce_loss 0.8257 (1.0573) teacher_loss 0.8183 (1.0545) loss_zs_kd 0.1614 (0.1604) loss_oracle 0.0438 (0.0437) acc 84.3750 (71.9922) kd_loss 0.0370 (0.0322) lr 7.5131e-04 eta 0:07:58
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,826
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.2%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [32/50] batch [20/244] time 0.107 (0.120) data 0.000 (0.015) loss 1.5549 (1.1459) ce_loss 1.4385 (1.0177) teacher_loss 1.4409 (1.0173) loss_zs_kd 0.1599 (0.1644) loss_oracle 0.0341 (0.0464) acc 62.5000 (72.8125) kd_loss 0.0300 (0.0318) lr 6.9098e-04 eta 0:09:12
epoch [32/50] batch [40/244] time 0.095 (0.110) data 0.000 (0.007) loss 1.1723 (1.1613) ce_loss 1.0566 (1.0381) teacher_loss 1.0555 (1.0371) loss_zs_kd 0.1523 (0.1604) loss_oracle 0.0406 (0.0440) acc 75.0000 (73.1250) kd_loss 0.0296 (0.0312) lr 6.9098e-04 eta 0:08:26
epoch [32/50] batch [60/244] time 0.098 (0.106) data 0.000 (0.005) loss 1.2078 (1.1822) ce_loss 1.0488 (1.0570) teacher_loss 1.0553 (1.0554) loss_zs_kd 0.2282 (0.1671) loss_oracle 0.0384 (0.0433) acc 75.0000 (72.9167) kd_loss 0.0323 (0.0322) lr 6.9098e-04 eta 0:08:05
epoch [32/50] batch [80/244] time 0.092 (0.104) data 0.000 (0.004) loss 0.9890 (1.1761) ce_loss 0.8369 (1.0502) teacher_loss 0.8357 (1.0481) loss_zs_kd 0.2176 (0.1685) loss_oracle 0.0444 (0.0437) acc 84.3750 (72.6562) kd_loss 0.0357 (0.0332) lr 6.9098e-04 eta 0:07:54
epoch [32/50] batch [100/244] time 0.095 (0.103) data 0.000 (0.003) loss 1.3009 (1.2023) ce_loss 1.1699 (1.0760) teacher_loss 1.1670 (1.0735) loss_zs_kd 0.1891 (0.1698) loss_oracle 0.0393 (0.0440) acc 68.7500 (72.0938) kd_loss 0.0361 (0.0333) lr 6.9098e-04 eta 0:07:47
epoch [32/50] batch [120/244] time 0.115 (0.103) data 0.000 (0.003) loss 0.8879 (1.2067) ce_loss 0.7505 (1.0820) teacher_loss 0.7446 (1.0793) loss_zs_kd 0.2054 (0.1673) loss_oracle 0.0406 (0.0437) acc 78.1250 (71.9792) kd_loss 0.0313 (0.0337) lr 6.9098e-04 eta 0:07:44
epoch [32/50] batch [140/244] time 0.101 (0.103) data 0.000 (0.002) loss 1.3182 (1.1922) ce_loss 1.1953 (1.0684) teacher_loss 1.1858 (1.0651) loss_zs_kd 0.1850 (0.1664) loss_oracle 0.0398 (0.0439) acc 59.3750 (72.2768) kd_loss 0.0394 (0.0342) lr 6.9098e-04 eta 0:07:42
epoch [32/50] batch [160/244] time 0.108 (0.103) data 0.000 (0.002) loss 1.1267 (1.1864) ce_loss 0.9634 (1.0629) teacher_loss 0.9689 (1.0597) loss_zs_kd 0.1977 (0.1655) loss_oracle 0.0590 (0.0440) acc 81.2500 (72.5391) kd_loss 0.0395 (0.0343) lr 6.9098e-04 eta 0:07:39
epoch [32/50] batch [180/244] time 0.101 (0.103) data 0.001 (0.002) loss 0.8483 (1.1937) ce_loss 0.6768 (1.0717) teacher_loss 0.6812 (1.0683) loss_zs_kd 0.2413 (0.1630) loss_oracle 0.0464 (0.0438) acc 90.6250 (72.3785) kd_loss 0.0359 (0.0342) lr 6.9098e-04 eta 0:07:37
epoch [32/50] batch [200/244] time 0.104 (0.103) data 0.000 (0.002) loss 1.2524 (1.1996) ce_loss 1.1523 (1.0776) teacher_loss 1.1457 (1.0743) loss_zs_kd 0.1286 (0.1627) loss_oracle 0.0423 (0.0439) acc 65.6250 (72.2500) kd_loss 0.0276 (0.0342) lr 6.9098e-04 eta 0:07:36
epoch [32/50] batch [220/244] time 0.106 (0.103) data 0.002 (0.002) loss 1.4700 (1.1996) ce_loss 1.3359 (1.0785) teacher_loss 1.3263 (1.0753) loss_zs_kd 0.1889 (0.1613) loss_oracle 0.0492 (0.0437) acc 59.3750 (71.9602) kd_loss 0.0332 (0.0340) lr 6.9098e-04 eta 0:07:35
epoch [32/50] batch [240/244] time 0.103 (0.103) data 0.000 (0.002) loss 0.9192 (1.2060) ce_loss 0.8032 (1.0850) teacher_loss 0.8032 (1.0817) loss_zs_kd 0.1305 (0.1603) loss_oracle 0.0507 (0.0441) acc 75.0000 (71.7839) kd_loss 0.0371 (0.0343) lr 6.9098e-04 eta 0:07:32
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,825
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,040
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.2%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [33/50] batch [20/244] time 0.098 (0.122) data 0.000 (0.018) loss 1.1808 (1.1926) ce_loss 1.0820 (1.0683) teacher_loss 1.0764 (1.0623) loss_zs_kd 0.1219 (0.1540) loss_oracle 0.0434 (0.0533) acc 81.2500 (72.6562) kd_loss 0.0360 (0.0404) lr 6.3188e-04 eta 0:08:53
epoch [33/50] batch [40/244] time 0.097 (0.111) data 0.000 (0.009) loss 0.9752 (1.1471) ce_loss 0.8584 (1.0236) teacher_loss 0.8529 (1.0188) loss_zs_kd 0.1338 (0.1535) loss_oracle 0.0554 (0.0516) acc 78.1250 (73.9844) kd_loss 0.0377 (0.0384) lr 6.3188e-04 eta 0:08:03
epoch [33/50] batch [60/244] time 0.097 (0.108) data 0.001 (0.006) loss 2.0344 (1.1831) ce_loss 1.9033 (1.0603) teacher_loss 1.8878 (1.0554) loss_zs_kd 0.1844 (0.1549) loss_oracle 0.0545 (0.0503) acc 50.0000 (72.2396) kd_loss 0.0407 (0.0378) lr 6.3188e-04 eta 0:07:47
epoch [33/50] batch [80/244] time 0.098 (0.106) data 0.000 (0.005) loss 1.1235 (1.2081) ce_loss 0.9878 (1.0836) teacher_loss 0.9904 (1.0793) loss_zs_kd 0.1967 (0.1591) loss_oracle 0.0348 (0.0492) acc 75.0000 (71.6406) kd_loss 0.0305 (0.0372) lr 6.3188e-04 eta 0:07:36
epoch [33/50] batch [100/244] time 0.100 (0.104) data 0.000 (0.004) loss 1.0274 (1.1903) ce_loss 0.9004 (1.0670) teacher_loss 0.9012 (1.0631) loss_zs_kd 0.1657 (0.1566) loss_oracle 0.0434 (0.0489) acc 71.8750 (72.1562) kd_loss 0.0293 (0.0366) lr 6.3188e-04 eta 0:07:28
epoch [33/50] batch [120/244] time 0.096 (0.103) data 0.000 (0.003) loss 1.4039 (1.1943) ce_loss 1.2441 (1.0701) teacher_loss 1.2483 (1.0659) loss_zs_kd 0.2106 (0.1586) loss_oracle 0.0503 (0.0491) acc 62.5000 (72.1354) kd_loss 0.0261 (0.0364) lr 6.3188e-04 eta 0:07:20
epoch [33/50] batch [140/244] time 0.097 (0.102) data 0.000 (0.003) loss 1.1382 (1.1917) ce_loss 1.0332 (1.0672) teacher_loss 1.0196 (1.0633) loss_zs_kd 0.1351 (0.1587) loss_oracle 0.0511 (0.0490) acc 68.7500 (72.4554) kd_loss 0.0375 (0.0360) lr 6.3188e-04 eta 0:07:14
epoch [33/50] batch [160/244] time 0.106 (0.102) data 0.000 (0.002) loss 0.7801 (1.1842) ce_loss 0.6382 (1.0593) teacher_loss 0.6422 (1.0556) loss_zs_kd 0.1940 (0.1600) loss_oracle 0.0410 (0.0486) acc 87.5000 (72.6562) kd_loss 0.0271 (0.0357) lr 6.3188e-04 eta 0:07:11
epoch [33/50] batch [180/244] time 0.097 (0.101) data 0.000 (0.002) loss 1.5964 (1.1904) ce_loss 1.4648 (1.0662) teacher_loss 1.4639 (1.0624) loss_zs_kd 0.1695 (0.1589) loss_oracle 0.0477 (0.0486) acc 68.7500 (72.3785) kd_loss 0.0408 (0.0356) lr 6.3188e-04 eta 0:07:06
epoch [33/50] batch [200/244] time 0.092 (0.101) data 0.000 (0.002) loss 0.8577 (1.1966) ce_loss 0.7446 (1.0726) teacher_loss 0.7454 (1.0687) loss_zs_kd 0.1435 (0.1590) loss_oracle 0.0406 (0.0484) acc 81.2500 (72.2344) kd_loss 0.0256 (0.0354) lr 6.3188e-04 eta 0:07:02
epoch [33/50] batch [220/244] time 0.099 (0.100) data 0.000 (0.002) loss 1.3270 (1.1979) ce_loss 1.1953 (1.0739) teacher_loss 1.1962 (1.0701) loss_zs_kd 0.1686 (0.1596) loss_oracle 0.0465 (0.0480) acc 65.6250 (72.0881) kd_loss 0.0330 (0.0351) lr 6.3188e-04 eta 0:06:59
epoch [33/50] batch [240/244] time 0.087 (0.100) data 0.000 (0.002) loss 0.7284 (1.1963) ce_loss 0.6201 (1.0716) teacher_loss 0.6151 (1.0678) loss_zs_kd 0.1447 (0.1604) loss_oracle 0.0409 (0.0483) acc 75.0000 (72.0182) kd_loss 0.0296 (0.0351) lr 6.3188e-04 eta 0:06:54
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,833
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      85.0%, epoch: 33 *******
******* Domain p best val test acc: 90.9%, epoch: 33 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [34/50] batch [20/244] time 0.120 (0.135) data 0.001 (0.016) loss 1.0072 (1.2110) ce_loss 0.8813 (1.0852) teacher_loss 0.8845 (1.0834) loss_zs_kd 0.1596 (0.1611) loss_oracle 0.0429 (0.0469) acc 81.2500 (72.9688) kd_loss 0.0248 (0.0303) lr 5.7422e-04 eta 0:09:17
epoch [34/50] batch [40/244] time 0.101 (0.121) data 0.000 (0.008) loss 1.6452 (1.1863) ce_loss 1.5234 (1.0589) teacher_loss 1.5071 (1.0555) loss_zs_kd 0.1688 (0.1668) loss_oracle 0.0536 (0.0475) acc 65.6250 (72.5000) kd_loss 0.0421 (0.0328) lr 5.7422e-04 eta 0:08:15
epoch [34/50] batch [60/244] time 0.114 (0.114) data 0.001 (0.005) loss 1.4063 (1.1725) ce_loss 1.2676 (1.0467) teacher_loss 1.2661 (1.0434) loss_zs_kd 0.1850 (0.1630) loss_oracle 0.0477 (0.0477) acc 65.6250 (72.8125) kd_loss 0.0396 (0.0338) lr 5.7422e-04 eta 0:07:46
epoch [34/50] batch [80/244] time 0.099 (0.111) data 0.000 (0.004) loss 1.4658 (1.1589) ce_loss 1.3311 (1.0334) teacher_loss 1.3374 (1.0300) loss_zs_kd 0.1725 (0.1633) loss_oracle 0.0421 (0.0472) acc 68.7500 (73.0469) kd_loss 0.0304 (0.0337) lr 5.7422e-04 eta 0:07:32
epoch [34/50] batch [100/244] time 0.121 (0.109) data 0.000 (0.003) loss 1.1072 (1.1683) ce_loss 0.9648 (1.0425) teacher_loss 0.9696 (1.0395) loss_zs_kd 0.1824 (0.1629) loss_oracle 0.0465 (0.0474) acc 78.1250 (72.8125) kd_loss 0.0304 (0.0334) lr 5.7422e-04 eta 0:07:21
epoch [34/50] batch [120/244] time 0.093 (0.108) data 0.000 (0.003) loss 0.8296 (1.1676) ce_loss 0.6948 (1.0422) teacher_loss 0.6789 (1.0390) loss_zs_kd 0.1551 (0.1609) loss_oracle 0.0732 (0.0482) acc 81.2500 (72.5781) kd_loss 0.0526 (0.0338) lr 5.7422e-04 eta 0:07:15
epoch [34/50] batch [140/244] time 0.099 (0.107) data 0.000 (0.002) loss 0.8907 (1.1591) ce_loss 0.7729 (1.0346) teacher_loss 0.7785 (1.0315) loss_zs_kd 0.1560 (0.1590) loss_oracle 0.0342 (0.0481) acc 78.1250 (72.5446) kd_loss 0.0272 (0.0339) lr 5.7422e-04 eta 0:07:08
epoch [34/50] batch [160/244] time 0.121 (0.107) data 0.000 (0.002) loss 1.3174 (1.1630) ce_loss 1.1846 (1.0372) teacher_loss 1.1816 (1.0338) loss_zs_kd 0.1552 (0.1608) loss_oracle 0.0582 (0.0488) acc 65.6250 (72.5977) kd_loss 0.0455 (0.0344) lr 5.7422e-04 eta 0:07:07
epoch [34/50] batch [180/244] time 0.119 (0.107) data 0.000 (0.002) loss 1.4275 (1.1737) ce_loss 1.2998 (1.0485) teacher_loss 1.2987 (1.0445) loss_zs_kd 0.1672 (0.1611) loss_oracle 0.0452 (0.0486) acc 71.8750 (72.2396) kd_loss 0.0362 (0.0347) lr 5.7422e-04 eta 0:07:06
epoch [34/50] batch [200/244] time 0.099 (0.107) data 0.000 (0.002) loss 1.1732 (1.1699) ce_loss 1.0410 (1.0453) teacher_loss 1.0349 (1.0411) loss_zs_kd 0.1603 (0.1602) loss_oracle 0.0581 (0.0487) acc 68.7500 (72.3438) kd_loss 0.0388 (0.0350) lr 5.7422e-04 eta 0:07:03
epoch [34/50] batch [220/244] time 0.153 (0.108) data 0.001 (0.002) loss 1.2033 (1.1680) ce_loss 1.1152 (1.0438) teacher_loss 1.1170 (1.0397) loss_zs_kd 0.1014 (0.1597) loss_oracle 0.0356 (0.0485) acc 71.8750 (72.5710) kd_loss 0.0323 (0.0349) lr 5.7422e-04 eta 0:07:03
epoch [34/50] batch [240/244] time 0.107 (0.108) data 0.000 (0.002) loss 1.0412 (1.1658) ce_loss 0.8896 (1.0417) teacher_loss 0.8843 (1.0377) loss_zs_kd 0.2123 (0.1598) loss_oracle 0.0508 (0.0483) acc 84.3750 (72.6562) kd_loss 0.0362 (0.0347) lr 5.7422e-04 eta 0:07:02
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,837
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,038
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [35/50] batch [20/244] time 0.108 (0.123) data 0.000 (0.014) loss 1.1497 (1.2000) ce_loss 1.0371 (1.0743) teacher_loss 1.0263 (1.0722) loss_zs_kd 0.1553 (0.1661) loss_oracle 0.0457 (0.0448) acc 68.7500 (70.3125) kd_loss 0.0293 (0.0338) lr 5.1825e-04 eta 0:07:58
epoch [35/50] batch [40/244] time 0.122 (0.118) data 0.000 (0.007) loss 1.1897 (1.2253) ce_loss 1.0840 (1.1000) teacher_loss 1.0809 (1.0949) loss_zs_kd 0.1258 (0.1654) loss_oracle 0.0459 (0.0477) acc 68.7500 (70.1562) kd_loss 0.0343 (0.0366) lr 5.1825e-04 eta 0:07:34
epoch [35/50] batch [60/244] time 0.128 (0.120) data 0.001 (0.005) loss 0.9500 (1.2062) ce_loss 0.8467 (1.0804) teacher_loss 0.8517 (1.0757) loss_zs_kd 0.1257 (0.1649) loss_oracle 0.0354 (0.0481) acc 78.1250 (70.4167) kd_loss 0.0297 (0.0368) lr 5.1825e-04 eta 0:07:39
epoch [35/50] batch [80/244] time 0.123 (0.120) data 0.000 (0.004) loss 1.0691 (1.2044) ce_loss 0.9390 (1.0772) teacher_loss 0.9236 (1.0725) loss_zs_kd 0.1706 (0.1668) loss_oracle 0.0602 (0.0485) acc 78.1250 (70.5078) kd_loss 0.0429 (0.0373) lr 5.1825e-04 eta 0:07:40
epoch [35/50] batch [100/244] time 0.109 (0.120) data 0.000 (0.003) loss 0.9371 (1.1940) ce_loss 0.8174 (1.0648) teacher_loss 0.8204 (1.0605) loss_zs_kd 0.1450 (0.1695) loss_oracle 0.0442 (0.0487) acc 75.0000 (71.2188) kd_loss 0.0376 (0.0378) lr 5.1825e-04 eta 0:07:37
epoch [35/50] batch [120/244] time 0.103 (0.117) data 0.000 (0.003) loss 1.1274 (1.1849) ce_loss 1.0244 (1.0562) teacher_loss 1.0205 (1.0519) loss_zs_kd 0.1048 (0.1684) loss_oracle 0.0544 (0.0488) acc 81.2500 (71.6667) kd_loss 0.0433 (0.0382) lr 5.1825e-04 eta 0:07:22
epoch [35/50] batch [140/244] time 0.102 (0.115) data 0.000 (0.002) loss 1.0357 (1.1725) ce_loss 0.9067 (1.0447) teacher_loss 0.9096 (1.0408) loss_zs_kd 0.1679 (0.1662) loss_oracle 0.0422 (0.0487) acc 81.2500 (71.9866) kd_loss 0.0409 (0.0384) lr 5.1825e-04 eta 0:07:11
epoch [35/50] batch [160/244] time 0.096 (0.112) data 0.000 (0.002) loss 1.5352 (1.1744) ce_loss 1.3828 (1.0462) teacher_loss 1.3767 (1.0423) loss_zs_kd 0.1922 (0.1672) loss_oracle 0.0624 (0.0485) acc 53.1250 (71.9531) kd_loss 0.0526 (0.0386) lr 5.1825e-04 eta 0:07:00
epoch [35/50] batch [180/244] time 0.100 (0.111) data 0.002 (0.002) loss 1.5329 (1.1869) ce_loss 1.4121 (1.0605) teacher_loss 1.3896 (1.0564) loss_zs_kd 0.1468 (0.1648) loss_oracle 0.0699 (0.0481) acc 53.1250 (71.6493) kd_loss 0.0541 (0.0389) lr 5.1825e-04 eta 0:06:53
epoch [35/50] batch [200/244] time 0.099 (0.110) data 0.000 (0.002) loss 0.7270 (1.1949) ce_loss 0.6016 (1.0692) teacher_loss 0.5871 (1.0645) loss_zs_kd 0.1674 (0.1637) loss_oracle 0.0562 (0.0485) acc 90.6250 (71.3750) kd_loss 0.0450 (0.0395) lr 5.1825e-04 eta 0:06:46
epoch [35/50] batch [220/244] time 0.097 (0.109) data 0.000 (0.002) loss 1.2938 (1.1967) ce_loss 1.1602 (1.0705) teacher_loss 1.1581 (1.0660) loss_zs_kd 0.1650 (0.1641) loss_oracle 0.0532 (0.0486) acc 68.7500 (71.3778) kd_loss 0.0385 (0.0396) lr 5.1825e-04 eta 0:06:41
epoch [35/50] batch [240/244] time 0.102 (0.108) data 0.000 (0.001) loss 1.0300 (1.2047) ce_loss 0.9453 (1.0789) teacher_loss 0.9397 (1.0743) loss_zs_kd 0.1023 (0.1633) loss_oracle 0.0392 (0.0487) acc 71.8750 (71.2240) kd_loss 0.0359 (0.0396) lr 5.1825e-04 eta 0:06:37
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,833
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,045
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [36/50] batch [20/244] time 0.121 (0.143) data 0.000 (0.016) loss 1.5511 (1.3752) ce_loss 1.4395 (1.2448) teacher_loss 1.4297 (1.2408) loss_zs_kd 0.1458 (0.1682) loss_oracle 0.0485 (0.0503) acc 59.3750 (66.5625) kd_loss 0.0415 (0.0397) lr 4.6417e-04 eta 0:08:41
epoch [36/50] batch [40/244] time 0.123 (0.136) data 0.000 (0.008) loss 1.3625 (1.2920) ce_loss 1.2354 (1.1601) teacher_loss 1.2367 (1.1571) loss_zs_kd 0.1861 (0.1684) loss_oracle 0.0328 (0.0507) acc 62.5000 (68.9844) kd_loss 0.0316 (0.0410) lr 4.6417e-04 eta 0:08:12
epoch [36/50] batch [60/244] time 0.097 (0.125) data 0.001 (0.006) loss 0.7961 (1.2559) ce_loss 0.6851 (1.1283) teacher_loss 0.6780 (1.1253) loss_zs_kd 0.1169 (0.1613) loss_oracle 0.0596 (0.0500) acc 84.3750 (70.1042) kd_loss 0.0452 (0.0409) lr 4.6417e-04 eta 0:07:29
epoch [36/50] batch [80/244] time 0.097 (0.119) data 0.000 (0.004) loss 1.1218 (1.2281) ce_loss 0.9443 (1.1027) teacher_loss 0.9490 (1.0997) loss_zs_kd 0.2349 (0.1582) loss_oracle 0.0554 (0.0493) acc 78.1250 (70.4297) kd_loss 0.0387 (0.0400) lr 4.6417e-04 eta 0:07:06
epoch [36/50] batch [100/244] time 0.108 (0.115) data 0.001 (0.004) loss 1.1335 (1.2097) ce_loss 0.9731 (1.0828) teacher_loss 0.9716 (1.0795) loss_zs_kd 0.2301 (0.1605) loss_oracle 0.0469 (0.0500) acc 71.8750 (70.9688) kd_loss 0.0403 (0.0401) lr 4.6417e-04 eta 0:06:51
epoch [36/50] batch [120/244] time 0.110 (0.114) data 0.000 (0.003) loss 1.0769 (1.2125) ce_loss 0.9878 (1.0841) teacher_loss 0.9845 (1.0807) loss_zs_kd 0.1238 (0.1628) loss_oracle 0.0305 (0.0504) acc 68.7500 (71.2240) kd_loss 0.0312 (0.0402) lr 4.6417e-04 eta 0:06:42
epoch [36/50] batch [140/244] time 0.120 (0.114) data 0.000 (0.003) loss 1.0215 (1.2059) ce_loss 0.8896 (1.0779) teacher_loss 0.8978 (1.0751) loss_zs_kd 0.1764 (0.1626) loss_oracle 0.0355 (0.0494) acc 75.0000 (71.4062) kd_loss 0.0510 (0.0400) lr 4.6417e-04 eta 0:06:42
epoch [36/50] batch [160/244] time 0.130 (0.116) data 0.000 (0.002) loss 1.1201 (1.2106) ce_loss 0.9751 (1.0836) teacher_loss 0.9729 (1.0809) loss_zs_kd 0.2144 (0.1622) loss_oracle 0.0401 (0.0486) acc 71.8750 (71.4648) kd_loss 0.0375 (0.0400) lr 4.6417e-04 eta 0:06:45
epoch [36/50] batch [180/244] time 0.131 (0.117) data 0.000 (0.002) loss 1.0047 (1.2058) ce_loss 0.8853 (1.0789) teacher_loss 0.8908 (1.0761) loss_zs_kd 0.1510 (0.1614) loss_oracle 0.0384 (0.0490) acc 71.8750 (71.4583) kd_loss 0.0360 (0.0408) lr 4.6417e-04 eta 0:06:47
epoch [36/50] batch [200/244] time 0.119 (0.118) data 0.000 (0.002) loss 1.3005 (1.2034) ce_loss 1.1641 (1.0764) teacher_loss 1.1523 (1.0736) loss_zs_kd 0.1887 (0.1616) loss_oracle 0.0538 (0.0490) acc 65.6250 (71.5469) kd_loss 0.0498 (0.0412) lr 4.6417e-04 eta 0:06:47
epoch [36/50] batch [220/244] time 0.119 (0.118) data 0.000 (0.002) loss 1.3995 (1.1989) ce_loss 1.2207 (1.0722) teacher_loss 1.2141 (1.0692) loss_zs_kd 0.2593 (0.1614) loss_oracle 0.0557 (0.0490) acc 59.3750 (71.6903) kd_loss 0.0377 (0.0413) lr 4.6417e-04 eta 0:06:47
epoch [36/50] batch [240/244] time 0.104 (0.118) data 0.000 (0.002) loss 1.2045 (1.1909) ce_loss 1.1279 (1.0647) teacher_loss 1.1221 (1.0618) loss_zs_kd 0.0986 (0.1607) loss_oracle 0.0331 (0.0488) acc 59.3750 (71.7839) kd_loss 0.0332 (0.0412) lr 4.6417e-04 eta 0:06:43
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,831
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [37/50] batch [20/244] time 0.099 (0.122) data 0.000 (0.017) loss 0.5850 (1.1943) ce_loss 0.4792 (1.0707) teacher_loss 0.4818 (1.0675) loss_zs_kd 0.0987 (0.1528) loss_oracle 0.0538 (0.0504) acc 93.7500 (72.5000) kd_loss 0.0438 (0.0403) lr 4.1221e-04 eta 0:06:53
epoch [37/50] batch [40/244] time 0.105 (0.111) data 0.001 (0.009) loss 1.1741 (1.1881) ce_loss 1.0527 (1.0663) teacher_loss 1.0565 (1.0623) loss_zs_kd 0.1317 (0.1492) loss_oracle 0.0518 (0.0511) acc 71.8750 (71.9531) kd_loss 0.0319 (0.0391) lr 4.1221e-04 eta 0:06:14
epoch [37/50] batch [60/244] time 0.100 (0.108) data 0.000 (0.006) loss 1.2230 (1.2063) ce_loss 1.0938 (1.0828) teacher_loss 1.0681 (1.0775) loss_zs_kd 0.1705 (0.1554) loss_oracle 0.0696 (0.0511) acc 75.0000 (71.6667) kd_loss 0.0381 (0.0383) lr 4.1221e-04 eta 0:06:03
epoch [37/50] batch [80/244] time 0.105 (0.106) data 0.000 (0.004) loss 1.3140 (1.2210) ce_loss 1.1592 (1.0974) teacher_loss 1.1601 (1.0922) loss_zs_kd 0.1873 (0.1543) loss_oracle 0.0602 (0.0516) acc 68.7500 (71.2109) kd_loss 0.0331 (0.0375) lr 4.1221e-04 eta 0:05:55
epoch [37/50] batch [100/244] time 0.114 (0.106) data 0.000 (0.004) loss 1.0491 (1.2301) ce_loss 0.9292 (1.1031) teacher_loss 0.9248 (1.0982) loss_zs_kd 0.1660 (0.1589) loss_oracle 0.0413 (0.0524) acc 75.0000 (70.6250) kd_loss 0.0293 (0.0373) lr 4.1221e-04 eta 0:05:50
epoch [37/50] batch [120/244] time 0.108 (0.105) data 0.000 (0.003) loss 1.0004 (1.2269) ce_loss 0.8599 (1.0977) teacher_loss 0.8637 (1.0934) loss_zs_kd 0.1850 (0.1632) loss_oracle 0.0442 (0.0519) acc 75.0000 (71.0677) kd_loss 0.0310 (0.0367) lr 4.1221e-04 eta 0:05:46
epoch [37/50] batch [140/244] time 0.102 (0.104) data 0.000 (0.003) loss 1.4368 (1.2308) ce_loss 1.2988 (1.1010) teacher_loss 1.3005 (1.0970) loss_zs_kd 0.1760 (0.1644) loss_oracle 0.0483 (0.0516) acc 65.6250 (71.1384) kd_loss 0.0322 (0.0366) lr 4.1221e-04 eta 0:05:42
epoch [37/50] batch [160/244] time 0.090 (0.103) data 0.000 (0.002) loss 1.4095 (1.2239) ce_loss 1.3018 (1.0937) teacher_loss 1.2950 (1.0897) loss_zs_kd 0.1318 (0.1648) loss_oracle 0.0485 (0.0518) acc 62.5000 (71.4648) kd_loss 0.0379 (0.0368) lr 4.1221e-04 eta 0:05:36
epoch [37/50] batch [180/244] time 0.094 (0.103) data 0.000 (0.002) loss 1.6672 (1.2170) ce_loss 1.5332 (1.0871) teacher_loss 1.5263 (1.0832) loss_zs_kd 0.1652 (0.1640) loss_oracle 0.0583 (0.0518) acc 59.3750 (71.6146) kd_loss 0.0551 (0.0371) lr 4.1221e-04 eta 0:05:32
epoch [37/50] batch [200/244] time 0.091 (0.102) data 0.000 (0.002) loss 1.0604 (1.2129) ce_loss 0.9087 (1.0830) teacher_loss 0.9082 (1.0793) loss_zs_kd 0.1995 (0.1637) loss_oracle 0.0525 (0.0518) acc 75.0000 (71.6406) kd_loss 0.0431 (0.0373) lr 4.1221e-04 eta 0:05:29
epoch [37/50] batch [220/244] time 0.103 (0.102) data 0.000 (0.002) loss 1.3070 (1.2126) ce_loss 1.1973 (1.0827) teacher_loss 1.1898 (1.0789) loss_zs_kd 0.1464 (0.1637) loss_oracle 0.0439 (0.0518) acc 62.5000 (71.6477) kd_loss 0.0361 (0.0373) lr 4.1221e-04 eta 0:05:25
epoch [37/50] batch [240/244] time 0.104 (0.102) data 0.000 (0.002) loss 1.4349 (1.2139) ce_loss 1.3301 (1.0842) teacher_loss 1.3248 (1.0805) loss_zs_kd 0.1218 (0.1638) loss_oracle 0.0492 (0.0515) acc 65.6250 (71.6016) kd_loss 0.0378 (0.0374) lr 4.1221e-04 eta 0:05:22
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,829
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [38/50] batch [20/244] time 0.096 (0.120) data 0.000 (0.013) loss 1.4980 (1.2528) ce_loss 1.3818 (1.1298) teacher_loss 1.3771 (1.1246) loss_zs_kd 0.1206 (0.1558) loss_oracle 0.0606 (0.0502) acc 71.8750 (69.3750) kd_loss 0.0542 (0.0409) lr 3.6258e-04 eta 0:06:17
epoch [38/50] batch [40/244] time 0.099 (0.112) data 0.000 (0.007) loss 1.3144 (1.1695) ce_loss 1.2002 (1.0500) teacher_loss 1.1847 (1.0460) loss_zs_kd 0.1596 (0.1505) loss_oracle 0.0499 (0.0483) acc 71.8750 (71.6406) kd_loss 0.0425 (0.0397) lr 3.6258e-04 eta 0:05:49
epoch [38/50] batch [60/244] time 0.101 (0.108) data 0.001 (0.005) loss 1.4217 (1.1515) ce_loss 1.3223 (1.0312) teacher_loss 1.3173 (1.0273) loss_zs_kd 0.1182 (0.1502) loss_oracle 0.0453 (0.0491) acc 59.3750 (72.8125) kd_loss 0.0393 (0.0408) lr 3.6258e-04 eta 0:05:36
epoch [38/50] batch [80/244] time 0.094 (0.106) data 0.000 (0.004) loss 1.6167 (1.1791) ce_loss 1.4775 (1.0564) teacher_loss 1.4723 (1.0526) loss_zs_kd 0.1793 (0.1547) loss_oracle 0.0547 (0.0492) acc 59.3750 (72.3047) kd_loss 0.0438 (0.0409) lr 3.6258e-04 eta 0:05:28
epoch [38/50] batch [100/244] time 0.101 (0.106) data 0.000 (0.003) loss 1.8695 (1.1831) ce_loss 1.7354 (1.0586) teacher_loss 1.7305 (1.0548) loss_zs_kd 0.1706 (0.1578) loss_oracle 0.0536 (0.0494) acc 40.6250 (71.9062) kd_loss 0.0502 (0.0410) lr 3.6258e-04 eta 0:05:24
epoch [38/50] batch [120/244] time 0.100 (0.105) data 0.000 (0.002) loss 0.9441 (1.1876) ce_loss 0.8174 (1.0638) teacher_loss 0.8192 (1.0599) loss_zs_kd 0.1646 (0.1562) loss_oracle 0.0425 (0.0496) acc 81.2500 (71.9792) kd_loss 0.0495 (0.0412) lr 3.6258e-04 eta 0:05:20
epoch [38/50] batch [140/244] time 0.093 (0.104) data 0.000 (0.002) loss 1.2879 (1.1898) ce_loss 1.1680 (1.0658) teacher_loss 1.1594 (1.0612) loss_zs_kd 0.1403 (0.1566) loss_oracle 0.0583 (0.0503) acc 68.7500 (72.0089) kd_loss 0.0520 (0.0414) lr 3.6258e-04 eta 0:05:15
epoch [38/50] batch [160/244] time 0.101 (0.104) data 0.000 (0.002) loss 1.1251 (1.1883) ce_loss 1.0156 (1.0633) teacher_loss 1.0195 (1.0591) loss_zs_kd 0.1496 (0.1584) loss_oracle 0.0308 (0.0500) acc 75.0000 (72.0312) kd_loss 0.0267 (0.0410) lr 3.6258e-04 eta 0:05:11
epoch [38/50] batch [180/244] time 0.097 (0.103) data 0.000 (0.002) loss 1.3401 (1.1937) ce_loss 1.2002 (1.0688) teacher_loss 1.1972 (1.0646) loss_zs_kd 0.1797 (0.1589) loss_oracle 0.0530 (0.0497) acc 65.6250 (71.8576) kd_loss 0.0360 (0.0406) lr 3.6258e-04 eta 0:05:07
epoch [38/50] batch [200/244] time 0.107 (0.102) data 0.000 (0.002) loss 1.0414 (1.1971) ce_loss 0.9341 (1.0713) teacher_loss 0.9370 (1.0672) loss_zs_kd 0.1308 (0.1607) loss_oracle 0.0390 (0.0496) acc 78.1250 (71.9062) kd_loss 0.0367 (0.0404) lr 3.6258e-04 eta 0:05:02
epoch [38/50] batch [220/244] time 0.083 (0.101) data 0.000 (0.001) loss 0.9190 (1.2023) ce_loss 0.7881 (1.0761) teacher_loss 0.7908 (1.0716) loss_zs_kd 0.1386 (0.1617) loss_oracle 0.0589 (0.0499) acc 81.2500 (71.8466) kd_loss 0.0419 (0.0405) lr 3.6258e-04 eta 0:04:58
epoch [38/50] batch [240/244] time 0.086 (0.100) data 0.000 (0.001) loss 1.3280 (1.1988) ce_loss 1.1768 (1.0723) teacher_loss 1.1815 (1.0679) loss_zs_kd 0.1945 (0.1621) loss_oracle 0.0492 (0.0498) acc 65.6250 (72.0052) kd_loss 0.0306 (0.0404) lr 3.6258e-04 eta 0:04:53
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,835
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [39/50] batch [20/244] time 0.084 (0.109) data 0.000 (0.014) loss 1.6679 (1.2253) ce_loss 1.5234 (1.1024) teacher_loss 1.5297 (1.0981) loss_zs_kd 0.1689 (0.1546) loss_oracle 0.0537 (0.0500) acc 59.3750 (73.2812) kd_loss 0.0425 (0.0424) lr 3.1545e-04 eta 0:05:15
epoch [39/50] batch [40/244] time 0.097 (0.100) data 0.000 (0.007) loss 1.3942 (1.2077) ce_loss 1.2783 (1.0786) teacher_loss 1.2762 (1.0754) loss_zs_kd 0.1472 (0.1629) loss_oracle 0.0443 (0.0508) acc 65.6250 (72.1094) kd_loss 0.0376 (0.0423) lr 3.1545e-04 eta 0:04:48
epoch [39/50] batch [60/244] time 0.093 (0.099) data 0.000 (0.005) loss 0.9348 (1.1884) ce_loss 0.8125 (1.0573) teacher_loss 0.7987 (1.0532) loss_zs_kd 0.1549 (0.1676) loss_oracle 0.0587 (0.0513) acc 84.3750 (72.2917) kd_loss 0.0547 (0.0430) lr 3.1545e-04 eta 0:04:44
epoch [39/50] batch [80/244] time 0.103 (0.099) data 0.000 (0.004) loss 1.2464 (1.1987) ce_loss 1.1338 (1.0703) teacher_loss 1.1319 (1.0658) loss_zs_kd 0.1282 (0.1641) loss_oracle 0.0504 (0.0509) acc 68.7500 (72.1094) kd_loss 0.0454 (0.0431) lr 3.1545e-04 eta 0:04:42
epoch [39/50] batch [100/244] time 0.107 (0.100) data 0.000 (0.003) loss 1.2297 (1.1879) ce_loss 1.0967 (1.0585) teacher_loss 1.0964 (1.0541) loss_zs_kd 0.1477 (0.1646) loss_oracle 0.0595 (0.0515) acc 65.6250 (71.9688) kd_loss 0.0443 (0.0431) lr 3.1545e-04 eta 0:04:41
epoch [39/50] batch [120/244] time 0.092 (0.099) data 0.000 (0.002) loss 0.9932 (1.1912) ce_loss 0.8530 (1.0606) teacher_loss 0.8459 (1.0560) loss_zs_kd 0.1996 (0.1666) loss_oracle 0.0475 (0.0519) acc 78.1250 (71.8750) kd_loss 0.0485 (0.0436) lr 3.1545e-04 eta 0:04:37
epoch [39/50] batch [140/244] time 0.096 (0.098) data 0.000 (0.002) loss 1.3549 (1.1917) ce_loss 1.2480 (1.0604) teacher_loss 1.2499 (1.0560) loss_zs_kd 0.1421 (0.1684) loss_oracle 0.0340 (0.0515) acc 62.5000 (71.8080) kd_loss 0.0324 (0.0434) lr 3.1545e-04 eta 0:04:34
epoch [39/50] batch [160/244] time 0.096 (0.098) data 0.000 (0.002) loss 1.2775 (1.2030) ce_loss 1.1367 (1.0720) teacher_loss 1.1281 (1.0674) loss_zs_kd 0.2187 (0.1678) loss_oracle 0.0401 (0.0517) acc 65.6250 (71.6797) kd_loss 0.0445 (0.0436) lr 3.1545e-04 eta 0:04:31
epoch [39/50] batch [180/244] time 0.090 (0.098) data 0.000 (0.002) loss 0.8314 (1.2047) ce_loss 0.7104 (1.0731) teacher_loss 0.7175 (1.0685) loss_zs_kd 0.1423 (0.1683) loss_oracle 0.0428 (0.0520) acc 75.0000 (71.5625) kd_loss 0.0433 (0.0438) lr 3.1545e-04 eta 0:04:28
epoch [39/50] batch [200/244] time 0.093 (0.098) data 0.000 (0.002) loss 1.2774 (1.2072) ce_loss 1.1562 (1.0761) teacher_loss 1.1615 (1.0714) loss_zs_kd 0.1447 (0.1680) loss_oracle 0.0436 (0.0518) acc 75.0000 (71.5625) kd_loss 0.0380 (0.0440) lr 3.1545e-04 eta 0:04:26
epoch [39/50] batch [220/244] time 0.097 (0.098) data 0.000 (0.001) loss 1.8888 (1.2128) ce_loss 1.7852 (1.0823) teacher_loss 1.7842 (1.0774) loss_zs_kd 0.1111 (0.1667) loss_oracle 0.0490 (0.0521) acc 53.1250 (71.4205) kd_loss 0.0430 (0.0443) lr 3.1545e-04 eta 0:04:24
epoch [39/50] batch [240/244] time 0.085 (0.097) data 0.000 (0.001) loss 1.1235 (1.2127) ce_loss 1.0107 (1.0819) teacher_loss 1.0094 (1.0771) loss_zs_kd 0.1400 (0.1663) loss_oracle 0.0441 (0.0525) acc 68.7500 (71.3802) kd_loss 0.0393 (0.0446) lr 3.1545e-04 eta 0:04:20
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,833
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [40/50] batch [20/244] time 0.111 (0.121) data 0.000 (0.015) loss 1.0980 (1.2393) ce_loss 0.9658 (1.1068) teacher_loss 0.9626 (1.1011) loss_zs_kd 0.1893 (0.1640) loss_oracle 0.0408 (0.0562) acc 78.1250 (70.4688) kd_loss 0.0335 (0.0498) lr 2.7103e-04 eta 0:05:23
epoch [40/50] batch [40/244] time 0.124 (0.120) data 0.000 (0.008) loss 1.1704 (1.2296) ce_loss 1.0303 (1.0967) teacher_loss 1.0370 (1.0921) loss_zs_kd 0.1871 (0.1672) loss_oracle 0.0398 (0.0539) acc 75.0000 (71.3281) kd_loss 0.0267 (0.0471) lr 2.7103e-04 eta 0:05:16
epoch [40/50] batch [60/244] time 0.134 (0.123) data 0.000 (0.005) loss 1.1052 (1.2196) ce_loss 1.0137 (1.0856) teacher_loss 1.0062 (1.0818) loss_zs_kd 0.1058 (0.1703) loss_oracle 0.0461 (0.0526) acc 68.7500 (72.0312) kd_loss 0.0366 (0.0465) lr 2.7103e-04 eta 0:05:23
epoch [40/50] batch [80/244] time 0.137 (0.125) data 0.000 (0.004) loss 1.0817 (1.2394) ce_loss 0.9702 (1.1004) teacher_loss 0.9746 (1.0960) loss_zs_kd 0.1200 (0.1772) loss_oracle 0.0471 (0.0548) acc 78.1250 (71.5234) kd_loss 0.0420 (0.0468) lr 2.7103e-04 eta 0:05:25
epoch [40/50] batch [100/244] time 0.131 (0.126) data 0.000 (0.003) loss 0.8994 (1.2169) ce_loss 0.7656 (1.0781) teacher_loss 0.7536 (1.0736) loss_zs_kd 0.1508 (0.1759) loss_oracle 0.0704 (0.0554) acc 75.0000 (72.0312) kd_loss 0.0539 (0.0470) lr 2.7103e-04 eta 0:05:26
epoch [40/50] batch [120/244] time 0.134 (0.127) data 0.001 (0.003) loss 1.0586 (1.2134) ce_loss 0.9653 (1.0762) teacher_loss 0.9489 (1.0718) loss_zs_kd 0.0981 (0.1726) loss_oracle 0.0607 (0.0553) acc 78.1250 (72.0573) kd_loss 0.0546 (0.0473) lr 2.7103e-04 eta 0:05:26
epoch [40/50] batch [140/244] time 0.132 (0.128) data 0.000 (0.003) loss 0.7685 (1.2061) ce_loss 0.6479 (1.0685) teacher_loss 0.6510 (1.0639) loss_zs_kd 0.1194 (0.1739) loss_oracle 0.0578 (0.0552) acc 84.3750 (72.2768) kd_loss 0.0515 (0.0475) lr 2.7103e-04 eta 0:05:24
epoch [40/50] batch [160/244] time 0.132 (0.128) data 0.000 (0.002) loss 1.3413 (1.1941) ce_loss 1.2090 (1.0575) teacher_loss 1.2070 (1.0532) loss_zs_kd 0.1774 (0.1722) loss_oracle 0.0455 (0.0547) acc 81.2500 (72.5586) kd_loss 0.0369 (0.0473) lr 2.7103e-04 eta 0:05:23
epoch [40/50] batch [180/244] time 0.129 (0.128) data 0.000 (0.002) loss 1.0107 (1.2017) ce_loss 0.8765 (1.0652) teacher_loss 0.8738 (1.0608) loss_zs_kd 0.1880 (0.1727) loss_oracle 0.0429 (0.0545) acc 71.8750 (72.3785) kd_loss 0.0448 (0.0472) lr 2.7103e-04 eta 0:05:21
epoch [40/50] batch [200/244] time 0.135 (0.129) data 0.000 (0.002) loss 0.6953 (1.2005) ce_loss 0.5347 (1.0652) teacher_loss 0.5324 (1.0607) loss_zs_kd 0.2243 (0.1710) loss_oracle 0.0507 (0.0543) acc 90.6250 (72.2969) kd_loss 0.0530 (0.0471) lr 2.7103e-04 eta 0:05:19
epoch [40/50] batch [220/244] time 0.135 (0.129) data 0.000 (0.002) loss 0.8701 (1.1888) ce_loss 0.7705 (1.0542) teacher_loss 0.7697 (1.0498) loss_zs_kd 0.1230 (0.1706) loss_oracle 0.0389 (0.0537) acc 75.0000 (72.5710) kd_loss 0.0380 (0.0468) lr 2.7103e-04 eta 0:05:17
epoch [40/50] batch [240/244] time 0.113 (0.128) data 0.000 (0.002) loss 1.0396 (1.1853) ce_loss 0.9053 (1.0510) teacher_loss 0.8877 (1.0466) loss_zs_kd 0.1770 (0.1704) loss_oracle 0.0634 (0.0535) acc 78.1250 (72.6302) kd_loss 0.0494 (0.0466) lr 2.7103e-04 eta 0:05:13
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,833
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [41/50] batch [20/244] time 0.111 (0.124) data 0.000 (0.015) loss 0.9273 (1.1574) ce_loss 0.8179 (1.0231) teacher_loss 0.8135 (1.0185) loss_zs_kd 0.1380 (0.1748) loss_oracle 0.0448 (0.0515) acc 78.1250 (72.8125) kd_loss 0.0465 (0.0456) lr 2.2949e-04 eta 0:04:59
epoch [41/50] batch [40/244] time 0.115 (0.117) data 0.000 (0.007) loss 1.0437 (1.1477) ce_loss 0.9121 (1.0129) teacher_loss 0.9132 (1.0077) loss_zs_kd 0.1533 (0.1741) loss_oracle 0.0539 (0.0530) acc 81.2500 (74.0625) kd_loss 0.0514 (0.0463) lr 2.2949e-04 eta 0:04:41
epoch [41/50] batch [60/244] time 0.131 (0.115) data 0.000 (0.005) loss 0.8565 (1.1588) ce_loss 0.7583 (1.0260) teacher_loss 0.7550 (1.0211) loss_zs_kd 0.1200 (0.1703) loss_oracle 0.0414 (0.0525) acc 75.0000 (72.9688) kd_loss 0.0333 (0.0469) lr 2.2949e-04 eta 0:04:32
epoch [41/50] batch [80/244] time 0.129 (0.118) data 0.001 (0.004) loss 1.0847 (1.1617) ce_loss 0.9204 (1.0272) teacher_loss 0.9119 (1.0224) loss_zs_kd 0.2210 (0.1729) loss_oracle 0.0623 (0.0529) acc 68.7500 (72.7344) kd_loss 0.0630 (0.0483) lr 2.2949e-04 eta 0:04:37
epoch [41/50] batch [100/244] time 0.110 (0.117) data 0.000 (0.003) loss 0.8839 (1.1717) ce_loss 0.7651 (1.0357) teacher_loss 0.7564 (1.0310) loss_zs_kd 0.1546 (0.1758) loss_oracle 0.0502 (0.0528) acc 78.1250 (72.4375) kd_loss 0.0446 (0.0483) lr 2.2949e-04 eta 0:04:33
epoch [41/50] batch [120/244] time 0.107 (0.115) data 0.000 (0.003) loss 0.6754 (1.1685) ce_loss 0.5283 (1.0326) teacher_loss 0.5246 (1.0277) loss_zs_kd 0.1585 (0.1754) loss_oracle 0.0716 (0.0531) acc 87.5000 (72.4219) kd_loss 0.0600 (0.0491) lr 2.2949e-04 eta 0:04:27
epoch [41/50] batch [140/244] time 0.110 (0.114) data 0.000 (0.002) loss 1.3816 (1.1575) ce_loss 1.2363 (1.0225) teacher_loss 1.2346 (1.0177) loss_zs_kd 0.1852 (0.1730) loss_oracle 0.0544 (0.0533) acc 68.7500 (72.8571) kd_loss 0.0532 (0.0492) lr 2.2949e-04 eta 0:04:22
epoch [41/50] batch [160/244] time 0.109 (0.113) data 0.000 (0.002) loss 0.6170 (1.1538) ce_loss 0.4788 (1.0195) teacher_loss 0.4812 (1.0152) loss_zs_kd 0.1710 (0.1717) loss_oracle 0.0503 (0.0527) acc 87.5000 (73.0859) kd_loss 0.0388 (0.0488) lr 2.2949e-04 eta 0:04:17
epoch [41/50] batch [180/244] time 0.104 (0.112) data 0.000 (0.002) loss 1.0365 (1.1573) ce_loss 0.9038 (1.0233) teacher_loss 0.9041 (1.0189) loss_zs_kd 0.1796 (0.1722) loss_oracle 0.0426 (0.0523) acc 71.8750 (72.9514) kd_loss 0.0382 (0.0487) lr 2.2949e-04 eta 0:04:14
epoch [41/50] batch [200/244] time 0.092 (0.112) data 0.000 (0.002) loss 1.1048 (1.1556) ce_loss 1.0010 (1.0221) teacher_loss 0.9994 (1.0176) loss_zs_kd 0.1283 (0.1713) loss_oracle 0.0413 (0.0523) acc 81.2500 (73.0469) kd_loss 0.0438 (0.0485) lr 2.2949e-04 eta 0:04:10
epoch [41/50] batch [220/244] time 0.117 (0.111) data 0.000 (0.002) loss 1.4222 (1.1548) ce_loss 1.2754 (1.0219) teacher_loss 1.2679 (1.0174) loss_zs_kd 0.1951 (0.1702) loss_oracle 0.0568 (0.0523) acc 62.5000 (73.1676) kd_loss 0.0526 (0.0480) lr 2.2949e-04 eta 0:04:06
epoch [41/50] batch [240/244] time 0.085 (0.110) data 0.000 (0.001) loss 1.2499 (1.1560) ce_loss 1.1016 (1.0233) teacher_loss 1.0927 (1.0188) loss_zs_kd 0.2000 (0.1701) loss_oracle 0.0572 (0.0522) acc 68.7500 (73.1250) kd_loss 0.0531 (0.0479) lr 2.2949e-04 eta 0:04:01
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,831
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,042
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [42/50] batch [20/244] time 0.106 (0.112) data 0.000 (0.013) loss 1.0305 (1.1689) ce_loss 0.9023 (1.0480) teacher_loss 0.9081 (1.0432) loss_zs_kd 0.1668 (0.1501) loss_oracle 0.0390 (0.0507) acc 78.1250 (71.8750) kd_loss 0.0408 (0.0478) lr 1.9098e-04 eta 0:04:04
epoch [42/50] batch [40/244] time 0.096 (0.106) data 0.000 (0.006) loss 1.2237 (1.1785) ce_loss 1.1074 (1.0518) teacher_loss 1.0994 (1.0469) loss_zs_kd 0.1534 (0.1603) loss_oracle 0.0477 (0.0515) acc 68.7500 (71.5625) kd_loss 0.0497 (0.0475) lr 1.9098e-04 eta 0:03:48
epoch [42/50] batch [60/244] time 0.092 (0.104) data 0.000 (0.004) loss 0.9648 (1.1817) ce_loss 0.8018 (1.0509) teacher_loss 0.7948 (1.0448) loss_zs_kd 0.2213 (0.1675) loss_oracle 0.0593 (0.0531) acc 84.3750 (71.7708) kd_loss 0.0550 (0.0482) lr 1.9098e-04 eta 0:03:41
epoch [42/50] batch [80/244] time 0.091 (0.101) data 0.000 (0.003) loss 1.2732 (1.1909) ce_loss 1.1348 (1.0588) teacher_loss 1.1333 (1.0523) loss_zs_kd 0.1590 (0.1681) loss_oracle 0.0605 (0.0546) acc 78.1250 (72.1094) kd_loss 0.0668 (0.0493) lr 1.9098e-04 eta 0:03:34
epoch [42/50] batch [100/244] time 0.093 (0.100) data 0.000 (0.003) loss 1.6827 (1.1832) ce_loss 1.5625 (1.0539) teacher_loss 1.5519 (1.0478) loss_zs_kd 0.1639 (0.1640) loss_oracle 0.0489 (0.0533) acc 59.3750 (72.2188) kd_loss 0.0441 (0.0479) lr 1.9098e-04 eta 0:03:29
epoch [42/50] batch [120/244] time 0.089 (0.099) data 0.000 (0.002) loss 1.2570 (1.1932) ce_loss 1.1455 (1.0629) teacher_loss 1.1437 (1.0565) loss_zs_kd 0.1510 (0.1670) loss_oracle 0.0379 (0.0532) acc 65.6250 (71.9792) kd_loss 0.0474 (0.0475) lr 1.9098e-04 eta 0:03:25
epoch [42/50] batch [140/244] time 0.089 (0.098) data 0.000 (0.002) loss 0.5995 (1.1854) ce_loss 0.4976 (1.0557) teacher_loss 0.4922 (1.0495) loss_zs_kd 0.1232 (0.1655) loss_oracle 0.0457 (0.0532) acc 87.5000 (72.2545) kd_loss 0.0413 (0.0478) lr 1.9098e-04 eta 0:03:22
epoch [42/50] batch [160/244] time 0.097 (0.098) data 0.000 (0.002) loss 1.1087 (1.1868) ce_loss 0.9619 (1.0552) teacher_loss 0.9684 (1.0492) loss_zs_kd 0.1949 (0.1678) loss_oracle 0.0428 (0.0537) acc 78.1250 (72.4023) kd_loss 0.0460 (0.0483) lr 1.9098e-04 eta 0:03:19
epoch [42/50] batch [180/244] time 0.092 (0.098) data 0.000 (0.002) loss 1.2821 (1.1807) ce_loss 1.1455 (1.0487) teacher_loss 1.1474 (1.0431) loss_zs_kd 0.1720 (0.1683) loss_oracle 0.0487 (0.0534) acc 71.8750 (72.6562) kd_loss 0.0424 (0.0479) lr 1.9098e-04 eta 0:03:16
epoch [42/50] batch [200/244] time 0.089 (0.097) data 0.000 (0.001) loss 0.9804 (1.1741) ce_loss 0.8926 (1.0429) teacher_loss 0.8883 (1.0375) loss_zs_kd 0.1156 (0.1667) loss_oracle 0.0343 (0.0532) acc 78.1250 (72.8438) kd_loss 0.0367 (0.0478) lr 1.9098e-04 eta 0:03:14
epoch [42/50] batch [220/244] time 0.094 (0.097) data 0.000 (0.001) loss 1.3047 (1.1755) ce_loss 1.1582 (1.0447) teacher_loss 1.1570 (1.0396) loss_zs_kd 0.1876 (0.1655) loss_oracle 0.0539 (0.0531) acc 75.0000 (72.7983) kd_loss 0.0524 (0.0479) lr 1.9098e-04 eta 0:03:12
epoch [42/50] batch [240/244] time 0.087 (0.097) data 0.000 (0.001) loss 0.8879 (1.1839) ce_loss 0.7300 (1.0531) teacher_loss 0.7407 (1.0478) loss_zs_kd 0.2067 (0.1663) loss_oracle 0.0439 (0.0529) acc 81.2500 (72.6302) kd_loss 0.0366 (0.0479) lr 1.9098e-04 eta 0:03:09
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,831
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.6%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [43/50] batch [20/244] time 0.106 (0.110) data 0.001 (0.014) loss 1.0728 (1.1042) ce_loss 0.9653 (0.9698) teacher_loss 0.9545 (0.9653) loss_zs_kd 0.1500 (0.1748) loss_oracle 0.0433 (0.0515) acc 71.8750 (74.8438) kd_loss 0.0480 (0.0482) lr 1.5567e-04 eta 0:03:31
epoch [43/50] batch [40/244] time 0.100 (0.102) data 0.000 (0.007) loss 0.8280 (1.1604) ce_loss 0.6938 (1.0234) teacher_loss 0.6847 (1.0190) loss_zs_kd 0.1655 (0.1761) loss_oracle 0.0605 (0.0534) acc 81.2500 (72.9688) kd_loss 0.0579 (0.0484) lr 1.5567e-04 eta 0:03:15
epoch [43/50] batch [60/244] time 0.092 (0.100) data 0.000 (0.005) loss 1.1992 (1.1671) ce_loss 1.0850 (1.0290) teacher_loss 1.0769 (1.0251) loss_zs_kd 0.1398 (0.1771) loss_oracle 0.0524 (0.0534) acc 65.6250 (73.2812) kd_loss 0.0559 (0.0484) lr 1.5567e-04 eta 0:03:08
epoch [43/50] batch [80/244] time 0.093 (0.099) data 0.000 (0.004) loss 0.8591 (1.1803) ce_loss 0.7271 (1.0439) teacher_loss 0.7210 (1.0397) loss_zs_kd 0.1507 (0.1747) loss_oracle 0.0628 (0.0532) acc 75.0000 (72.6562) kd_loss 0.0542 (0.0487) lr 1.5567e-04 eta 0:03:05
epoch [43/50] batch [100/244] time 0.100 (0.099) data 0.000 (0.003) loss 1.2305 (1.1765) ce_loss 1.0869 (1.0411) teacher_loss 1.0895 (1.0373) loss_zs_kd 0.1602 (0.1719) loss_oracle 0.0609 (0.0533) acc 68.7500 (72.5312) kd_loss 0.0675 (0.0493) lr 1.5567e-04 eta 0:03:04
epoch [43/50] batch [120/244] time 0.101 (0.099) data 0.000 (0.003) loss 1.3216 (1.1869) ce_loss 1.1406 (1.0535) teacher_loss 1.1308 (1.0494) loss_zs_kd 0.2860 (0.1695) loss_oracle 0.0477 (0.0528) acc 68.7500 (72.2396) kd_loss 0.0480 (0.0493) lr 1.5567e-04 eta 0:03:02
epoch [43/50] batch [140/244] time 0.103 (0.099) data 0.000 (0.002) loss 1.1501 (1.1825) ce_loss 1.0068 (1.0490) teacher_loss 1.0071 (1.0452) loss_zs_kd 0.1748 (0.1709) loss_oracle 0.0556 (0.0518) acc 78.1250 (72.3438) kd_loss 0.0494 (0.0484) lr 1.5567e-04 eta 0:02:59
epoch [43/50] batch [160/244] time 0.090 (0.099) data 0.000 (0.002) loss 0.8126 (1.1766) ce_loss 0.7373 (1.0453) teacher_loss 0.7332 (1.0416) loss_zs_kd 0.0995 (0.1674) loss_oracle 0.0297 (0.0513) acc 75.0000 (72.5000) kd_loss 0.0389 (0.0479) lr 1.5567e-04 eta 0:02:57
epoch [43/50] batch [180/244] time 0.097 (0.099) data 0.000 (0.002) loss 1.0520 (1.1770) ce_loss 0.9111 (1.0458) teacher_loss 0.9053 (1.0418) loss_zs_kd 0.1961 (0.1675) loss_oracle 0.0486 (0.0514) acc 65.6250 (72.5347) kd_loss 0.0423 (0.0477) lr 1.5567e-04 eta 0:02:55
epoch [43/50] batch [200/244] time 0.090 (0.099) data 0.000 (0.002) loss 1.3899 (1.1788) ce_loss 1.2695 (1.0482) teacher_loss 1.2550 (1.0439) loss_zs_kd 0.1484 (0.1663) loss_oracle 0.0607 (0.0517) acc 56.2500 (72.3125) kd_loss 0.0431 (0.0477) lr 1.5567e-04 eta 0:02:52
epoch [43/50] batch [220/244] time 0.095 (0.099) data 0.000 (0.001) loss 1.0251 (1.1851) ce_loss 0.8726 (1.0544) teacher_loss 0.8860 (1.0500) loss_zs_kd 0.1756 (0.1671) loss_oracle 0.0513 (0.0515) acc 78.1250 (72.0597) kd_loss 0.0428 (0.0474) lr 1.5567e-04 eta 0:02:50
epoch [43/50] batch [240/244] time 0.087 (0.098) data 0.000 (0.001) loss 1.6089 (1.1850) ce_loss 1.4795 (1.0550) teacher_loss 1.4696 (1.0507) loss_zs_kd 0.1781 (0.1660) loss_oracle 0.0502 (0.0513) acc 56.2500 (71.9531) kd_loss 0.0500 (0.0469) lr 1.5567e-04 eta 0:02:47
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,832
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [44/50] batch [20/244] time 0.096 (0.118) data 0.000 (0.014) loss 1.5146 (1.2002) ce_loss 1.3369 (1.0686) teacher_loss 1.3387 (1.0649) loss_zs_kd 0.2517 (0.1687) loss_oracle 0.0501 (0.0510) acc 59.3750 (71.5625) kd_loss 0.0423 (0.0451) lr 1.2369e-04 eta 0:03:19
epoch [44/50] batch [40/244] time 0.091 (0.107) data 0.000 (0.007) loss 1.2833 (1.1410) ce_loss 1.1445 (1.0086) teacher_loss 1.1391 (1.0046) loss_zs_kd 0.1869 (0.1679) loss_oracle 0.0508 (0.0525) acc 71.8750 (73.9062) kd_loss 0.0470 (0.0452) lr 1.2369e-04 eta 0:02:58
epoch [44/50] batch [60/244] time 0.095 (0.103) data 0.000 (0.005) loss 1.0767 (1.1231) ce_loss 0.9502 (0.9934) teacher_loss 0.9473 (0.9891) loss_zs_kd 0.1528 (0.1639) loss_oracle 0.0530 (0.0520) acc 81.2500 (74.3229) kd_loss 0.0374 (0.0450) lr 1.2369e-04 eta 0:02:49
epoch [44/50] batch [80/244] time 0.096 (0.101) data 0.000 (0.004) loss 1.4057 (1.1328) ce_loss 1.2734 (1.0043) teacher_loss 1.2750 (1.0001) loss_zs_kd 0.1492 (0.1627) loss_oracle 0.0561 (0.0513) acc 68.7500 (74.0625) kd_loss 0.0487 (0.0448) lr 1.2369e-04 eta 0:02:45
epoch [44/50] batch [100/244] time 0.094 (0.100) data 0.000 (0.003) loss 1.1703 (1.1408) ce_loss 1.0596 (1.0135) teacher_loss 1.0588 (1.0096) loss_zs_kd 0.1306 (0.1610) loss_oracle 0.0462 (0.0507) acc 84.3750 (73.4688) kd_loss 0.0386 (0.0442) lr 1.2369e-04 eta 0:02:41
epoch [44/50] batch [120/244] time 0.094 (0.099) data 0.000 (0.002) loss 1.2674 (1.1598) ce_loss 1.1494 (1.0319) teacher_loss 1.1425 (1.0279) loss_zs_kd 0.1376 (0.1622) loss_oracle 0.0561 (0.0507) acc 65.6250 (72.9167) kd_loss 0.0425 (0.0440) lr 1.2369e-04 eta 0:02:37
epoch [44/50] batch [140/244] time 0.093 (0.099) data 0.000 (0.002) loss 1.0867 (1.1687) ce_loss 0.9741 (1.0403) teacher_loss 0.9807 (1.0360) loss_zs_kd 0.1414 (0.1638) loss_oracle 0.0353 (0.0508) acc 75.0000 (72.6562) kd_loss 0.0301 (0.0439) lr 1.2369e-04 eta 0:02:34
epoch [44/50] batch [160/244] time 0.093 (0.098) data 0.000 (0.002) loss 1.1164 (1.1732) ce_loss 0.9277 (1.0445) teacher_loss 0.9251 (1.0402) loss_zs_kd 0.2460 (0.1643) loss_oracle 0.0683 (0.0508) acc 78.1250 (72.4609) kd_loss 0.0522 (0.0439) lr 1.2369e-04 eta 0:02:32
epoch [44/50] batch [180/244] time 0.094 (0.098) data 0.000 (0.002) loss 1.5806 (1.1813) ce_loss 1.4434 (1.0498) teacher_loss 1.4372 (1.0456) loss_zs_kd 0.1767 (0.1681) loss_oracle 0.0551 (0.0516) acc 53.1250 (72.3785) kd_loss 0.0564 (0.0445) lr 1.2369e-04 eta 0:02:29
epoch [44/50] batch [200/244] time 0.098 (0.098) data 0.000 (0.002) loss 1.3883 (1.1841) ce_loss 1.2549 (1.0524) teacher_loss 1.2663 (1.0486) loss_zs_kd 0.1560 (0.1681) loss_oracle 0.0440 (0.0514) acc 71.8750 (72.3906) kd_loss 0.0448 (0.0444) lr 1.2369e-04 eta 0:02:27
epoch [44/50] batch [220/244] time 0.097 (0.097) data 0.000 (0.001) loss 1.6852 (1.1882) ce_loss 1.5381 (1.0564) teacher_loss 1.5182 (1.0523) loss_zs_kd 0.1847 (0.1684) loss_oracle 0.0747 (0.0517) acc 68.7500 (72.3011) kd_loss 0.0613 (0.0446) lr 1.2369e-04 eta 0:02:24
epoch [44/50] batch [240/244] time 0.084 (0.097) data 0.000 (0.001) loss 1.3011 (1.1869) ce_loss 1.1445 (1.0545) teacher_loss 1.1490 (1.0506) loss_zs_kd 0.2045 (0.1692) loss_oracle 0.0499 (0.0516) acc 65.6250 (72.2135) kd_loss 0.0356 (0.0446) lr 1.2369e-04 eta 0:02:21
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,840
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.2%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,046
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [45/50] batch [20/244] time 0.103 (0.112) data 0.000 (0.013) loss 1.0086 (1.1860) ce_loss 0.8872 (1.0505) teacher_loss 0.8757 (1.0470) loss_zs_kd 0.1514 (0.1710) loss_oracle 0.0572 (0.0535) acc 78.1250 (71.8750) kd_loss 0.0571 (0.0491) lr 9.5173e-05 eta 0:02:41
epoch [45/50] batch [40/244] time 0.098 (0.103) data 0.000 (0.007) loss 1.2737 (1.1482) ce_loss 1.1758 (1.0147) teacher_loss 1.1717 (1.0120) loss_zs_kd 0.1150 (0.1698) loss_oracle 0.0445 (0.0513) acc 62.5000 (72.7344) kd_loss 0.0481 (0.0479) lr 9.5173e-05 eta 0:02:27
epoch [45/50] batch [60/244] time 0.096 (0.101) data 0.001 (0.004) loss 1.4766 (1.1657) ce_loss 1.3516 (1.0317) teacher_loss 1.3454 (1.0281) loss_zs_kd 0.1560 (0.1707) loss_oracle 0.0532 (0.0522) acc 65.6250 (72.3438) kd_loss 0.0504 (0.0472) lr 9.5173e-05 eta 0:02:21
epoch [45/50] batch [80/244] time 0.089 (0.099) data 0.000 (0.003) loss 0.8626 (1.1836) ce_loss 0.7334 (1.0514) teacher_loss 0.7339 (1.0473) loss_zs_kd 0.1500 (0.1683) loss_oracle 0.0537 (0.0522) acc 84.3750 (71.9922) kd_loss 0.0461 (0.0472) lr 9.5173e-05 eta 0:02:16
epoch [45/50] batch [100/244] time 0.096 (0.098) data 0.000 (0.003) loss 1.3968 (1.1940) ce_loss 1.2266 (1.0614) teacher_loss 1.2071 (1.0572) loss_zs_kd 0.2048 (0.1687) loss_oracle 0.0872 (0.0524) acc 68.7500 (71.8750) kd_loss 0.0700 (0.0472) lr 9.5173e-05 eta 0:02:13
epoch [45/50] batch [120/244] time 0.096 (0.098) data 0.000 (0.002) loss 0.7706 (1.1842) ce_loss 0.6353 (1.0516) teacher_loss 0.6401 (1.0471) loss_zs_kd 0.1876 (0.1694) loss_oracle 0.0367 (0.0524) acc 81.2500 (72.2917) kd_loss 0.0403 (0.0473) lr 9.5173e-05 eta 0:02:11
epoch [45/50] batch [140/244] time 0.093 (0.098) data 0.000 (0.002) loss 0.7194 (1.1940) ce_loss 0.5830 (1.0607) teacher_loss 0.5765 (1.0564) loss_zs_kd 0.1621 (0.1702) loss_oracle 0.0618 (0.0525) acc 78.1250 (71.7634) kd_loss 0.0462 (0.0471) lr 9.5173e-05 eta 0:02:09
epoch [45/50] batch [160/244] time 0.096 (0.098) data 0.000 (0.002) loss 0.9124 (1.1900) ce_loss 0.7808 (1.0565) teacher_loss 0.7810 (1.0520) loss_zs_kd 0.1385 (0.1708) loss_oracle 0.0621 (0.0526) acc 81.2500 (71.8164) kd_loss 0.0431 (0.0475) lr 9.5173e-05 eta 0:02:08
epoch [45/50] batch [180/244] time 0.097 (0.098) data 0.000 (0.002) loss 1.3669 (1.1966) ce_loss 1.2520 (1.0638) teacher_loss 1.2340 (1.0593) loss_zs_kd 0.1532 (0.1698) loss_oracle 0.0563 (0.0524) acc 68.7500 (71.7708) kd_loss 0.0497 (0.0474) lr 9.5173e-05 eta 0:02:06
epoch [45/50] batch [200/244] time 0.099 (0.098) data 0.000 (0.002) loss 0.9076 (1.1903) ce_loss 0.7822 (1.0576) teacher_loss 0.7803 (1.0530) loss_zs_kd 0.1580 (0.1692) loss_oracle 0.0483 (0.0527) acc 75.0000 (71.9375) kd_loss 0.0431 (0.0473) lr 9.5173e-05 eta 0:02:04
epoch [45/50] batch [220/244] time 0.098 (0.098) data 0.000 (0.001) loss 1.0361 (1.1866) ce_loss 0.8696 (1.0541) teacher_loss 0.8526 (1.0494) loss_zs_kd 0.2264 (0.1688) loss_oracle 0.0703 (0.0528) acc 68.7500 (71.9318) kd_loss 0.0591 (0.0473) lr 9.5173e-05 eta 0:02:02
epoch [45/50] batch [240/244] time 0.100 (0.099) data 0.000 (0.001) loss 1.2820 (1.1845) ce_loss 1.1191 (1.0515) teacher_loss 1.1177 (1.0470) loss_zs_kd 0.2075 (0.1693) loss_oracle 0.0605 (0.0529) acc 75.0000 (72.0052) kd_loss 0.0508 (0.0475) lr 9.5173e-05 eta 0:02:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,836
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,042
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [46/50] batch [20/244] time 0.105 (0.117) data 0.000 (0.017) loss 1.5153 (1.1785) ce_loss 1.3467 (1.0519) teacher_loss 1.3395 (1.0469) loss_zs_kd 0.2208 (0.1665) loss_oracle 0.0654 (0.0484) acc 65.6250 (72.0312) kd_loss 0.0499 (0.0468) lr 7.0224e-05 eta 0:02:20
epoch [46/50] batch [40/244] time 0.096 (0.107) data 0.000 (0.009) loss 1.0714 (1.2116) ce_loss 0.9360 (1.0787) teacher_loss 0.9233 (1.0751) loss_zs_kd 0.1696 (0.1727) loss_oracle 0.0633 (0.0501) acc 75.0000 (71.1719) kd_loss 0.0546 (0.0477) lr 7.0224e-05 eta 0:02:06
epoch [46/50] batch [60/244] time 0.090 (0.103) data 0.000 (0.006) loss 0.8539 (1.2056) ce_loss 0.7095 (1.0699) teacher_loss 0.6921 (1.0653) loss_zs_kd 0.1876 (0.1780) loss_oracle 0.0680 (0.0514) acc 81.2500 (71.5625) kd_loss 0.0635 (0.0479) lr 7.0224e-05 eta 0:01:59
epoch [46/50] batch [80/244] time 0.099 (0.101) data 0.000 (0.004) loss 1.2973 (1.2042) ce_loss 1.1846 (1.0697) teacher_loss 1.1874 (1.0655) loss_zs_kd 0.1571 (0.1743) loss_oracle 0.0313 (0.0516) acc 68.7500 (71.5625) kd_loss 0.0342 (0.0480) lr 7.0224e-05 eta 0:01:55
epoch [46/50] batch [100/244] time 0.091 (0.100) data 0.000 (0.004) loss 1.2366 (1.1869) ce_loss 1.1133 (1.0540) teacher_loss 1.1074 (1.0496) loss_zs_kd 0.1658 (0.1716) loss_oracle 0.0463 (0.0515) acc 75.0000 (72.0625) kd_loss 0.0487 (0.0478) lr 7.0224e-05 eta 0:01:52
epoch [46/50] batch [120/244] time 0.097 (0.100) data 0.000 (0.003) loss 1.0432 (1.1923) ce_loss 0.9453 (1.0601) teacher_loss 0.9345 (1.0555) loss_zs_kd 0.1111 (0.1707) loss_oracle 0.0531 (0.0514) acc 81.2500 (71.7448) kd_loss 0.0488 (0.0476) lr 7.0224e-05 eta 0:01:49
epoch [46/50] batch [140/244] time 0.089 (0.099) data 0.000 (0.003) loss 0.7932 (1.1850) ce_loss 0.6772 (1.0529) teacher_loss 0.6673 (1.0485) loss_zs_kd 0.1111 (0.1696) loss_oracle 0.0703 (0.0517) acc 81.2500 (71.8527) kd_loss 0.0629 (0.0476) lr 7.0224e-05 eta 0:01:47
epoch [46/50] batch [160/244] time 0.091 (0.099) data 0.000 (0.002) loss 1.3011 (1.1751) ce_loss 1.1660 (1.0431) teacher_loss 1.1656 (1.0387) loss_zs_kd 0.1453 (0.1689) loss_oracle 0.0629 (0.0520) acc 75.0000 (72.1289) kd_loss 0.0596 (0.0478) lr 7.0224e-05 eta 0:01:45
epoch [46/50] batch [180/244] time 0.098 (0.099) data 0.000 (0.002) loss 1.5808 (1.1736) ce_loss 1.4678 (1.0422) teacher_loss 1.4750 (1.0376) loss_zs_kd 0.1299 (0.1683) loss_oracle 0.0408 (0.0518) acc 65.6250 (72.1354) kd_loss 0.0324 (0.0475) lr 7.0224e-05 eta 0:01:42
epoch [46/50] batch [200/244] time 0.098 (0.099) data 0.000 (0.002) loss 1.9656 (1.1830) ce_loss 1.7910 (1.0514) teacher_loss 1.8015 (1.0469) loss_zs_kd 0.2374 (0.1686) loss_oracle 0.0455 (0.0518) acc 53.1250 (71.9531) kd_loss 0.0527 (0.0477) lr 7.0224e-05 eta 0:01:40
epoch [46/50] batch [220/244] time 0.098 (0.099) data 0.000 (0.002) loss 1.0828 (1.1846) ce_loss 0.9409 (1.0522) teacher_loss 0.9216 (1.0476) loss_zs_kd 0.1801 (0.1698) loss_oracle 0.0711 (0.0521) acc 78.1250 (72.0170) kd_loss 0.0595 (0.0479) lr 7.0224e-05 eta 0:01:38
epoch [46/50] batch [240/244] time 0.087 (0.098) data 0.000 (0.002) loss 1.1350 (1.1911) ce_loss 0.9785 (1.0580) teacher_loss 0.9754 (1.0531) loss_zs_kd 0.1594 (0.1704) loss_oracle 0.0799 (0.0528) acc 71.8750 (71.8099) kd_loss 0.0652 (0.0481) lr 7.0224e-05 eta 0:01:35
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,835
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [47/50] batch [20/244] time 0.091 (0.113) data 0.000 (0.014) loss 0.9825 (1.1187) ce_loss 0.8579 (0.9886) teacher_loss 0.8575 (0.9841) loss_zs_kd 0.1506 (0.1654) loss_oracle 0.0497 (0.0519) acc 78.1250 (73.5938) kd_loss 0.0464 (0.0475) lr 4.8943e-05 eta 0:01:48
epoch [47/50] batch [40/244] time 0.091 (0.103) data 0.000 (0.007) loss 0.7942 (1.1263) ce_loss 0.6743 (0.9965) teacher_loss 0.6723 (0.9911) loss_zs_kd 0.1439 (0.1624) loss_oracle 0.0499 (0.0540) acc 78.1250 (73.9844) kd_loss 0.0511 (0.0488) lr 4.8943e-05 eta 0:01:36
epoch [47/50] batch [60/244] time 0.093 (0.100) data 0.000 (0.005) loss 0.9686 (1.1840) ce_loss 0.7998 (1.0529) teacher_loss 0.8040 (1.0479) loss_zs_kd 0.2139 (0.1650) loss_oracle 0.0576 (0.0537) acc 81.2500 (72.1875) kd_loss 0.0498 (0.0483) lr 4.8943e-05 eta 0:01:31
epoch [47/50] batch [80/244] time 0.097 (0.099) data 0.000 (0.004) loss 1.0419 (1.1756) ce_loss 0.9087 (1.0452) teacher_loss 0.9094 (1.0395) loss_zs_kd 0.1698 (0.1648) loss_oracle 0.0477 (0.0537) acc 78.1250 (72.6562) kd_loss 0.0389 (0.0482) lr 4.8943e-05 eta 0:01:28
epoch [47/50] batch [100/244] time 0.099 (0.099) data 0.000 (0.003) loss 1.7440 (1.1924) ce_loss 1.5811 (1.0627) teacher_loss 1.5655 (1.0567) loss_zs_kd 0.2264 (0.1638) loss_oracle 0.0653 (0.0537) acc 59.3750 (72.2188) kd_loss 0.0540 (0.0481) lr 4.8943e-05 eta 0:01:26
epoch [47/50] batch [120/244] time 0.092 (0.098) data 0.000 (0.002) loss 1.2385 (1.1838) ce_loss 1.1016 (1.0540) teacher_loss 1.1004 (1.0484) loss_zs_kd 0.1546 (0.1642) loss_oracle 0.0609 (0.0533) acc 71.8750 (72.3958) kd_loss 0.0485 (0.0482) lr 4.8943e-05 eta 0:01:23
epoch [47/50] batch [140/244] time 0.094 (0.098) data 0.000 (0.002) loss 1.5867 (1.1888) ce_loss 1.4180 (1.0587) teacher_loss 1.4148 (1.0533) loss_zs_kd 0.2143 (0.1642) loss_oracle 0.0647 (0.0534) acc 68.7500 (72.1429) kd_loss 0.0591 (0.0482) lr 4.8943e-05 eta 0:01:21
epoch [47/50] batch [160/244] time 0.094 (0.098) data 0.001 (0.002) loss 1.0267 (1.1894) ce_loss 0.9048 (1.0599) teacher_loss 0.9124 (1.0549) loss_zs_kd 0.1460 (0.1626) loss_oracle 0.0413 (0.0532) acc 84.3750 (72.3633) kd_loss 0.0401 (0.0485) lr 4.8943e-05 eta 0:01:19
epoch [47/50] batch [180/244] time 0.100 (0.098) data 0.000 (0.002) loss 1.1640 (1.1779) ce_loss 1.0068 (1.0479) teacher_loss 1.0052 (1.0431) loss_zs_kd 0.2257 (0.1633) loss_oracle 0.0460 (0.0532) acc 75.0000 (72.6910) kd_loss 0.0382 (0.0484) lr 4.8943e-05 eta 0:01:17
epoch [47/50] batch [200/244] time 0.091 (0.098) data 0.000 (0.002) loss 0.9643 (1.1746) ce_loss 0.8447 (1.0441) teacher_loss 0.8430 (1.0394) loss_zs_kd 0.1480 (0.1642) loss_oracle 0.0473 (0.0531) acc 78.1250 (72.7812) kd_loss 0.0388 (0.0483) lr 4.8943e-05 eta 0:01:15
epoch [47/50] batch [220/244] time 0.094 (0.097) data 0.000 (0.001) loss 1.4136 (1.1840) ce_loss 1.2500 (1.0529) teacher_loss 1.2526 (1.0483) loss_zs_kd 0.2200 (0.1653) loss_oracle 0.0511 (0.0531) acc 68.7500 (72.5000) kd_loss 0.0454 (0.0483) lr 4.8943e-05 eta 0:01:13
epoch [47/50] batch [240/244] time 0.085 (0.097) data 0.000 (0.001) loss 1.2175 (1.1738) ce_loss 1.0342 (1.0417) teacher_loss 1.0224 (1.0372) loss_zs_kd 0.2466 (0.1666) loss_oracle 0.0717 (0.0534) acc 81.2500 (72.8385) kd_loss 0.0654 (0.0483) lr 4.8943e-05 eta 0:01:11
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,838
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [48/50] batch [20/244] time 0.101 (0.118) data 0.000 (0.014) loss 1.0070 (1.2596) ce_loss 0.8120 (1.1212) teacher_loss 0.8178 (1.1148) loss_zs_kd 0.2839 (0.1802) loss_oracle 0.0473 (0.0547) acc 78.1250 (70.3125) kd_loss 0.0475 (0.0494) lr 3.1417e-05 eta 0:01:24
epoch [48/50] batch [40/244] time 0.095 (0.109) data 0.000 (0.007) loss 1.1441 (1.2243) ce_loss 1.0645 (1.0857) teacher_loss 1.0646 (1.0811) loss_zs_kd 0.0863 (0.1785) loss_oracle 0.0364 (0.0539) acc 68.7500 (71.4062) kd_loss 0.0280 (0.0468) lr 3.1417e-05 eta 0:01:15
epoch [48/50] batch [60/244] time 0.099 (0.106) data 0.000 (0.005) loss 1.0661 (1.2173) ce_loss 0.9526 (1.0807) teacher_loss 0.9509 (1.0768) loss_zs_kd 0.1493 (0.1740) loss_oracle 0.0405 (0.0535) acc 78.1250 (71.7708) kd_loss 0.0432 (0.0466) lr 3.1417e-05 eta 0:01:11
epoch [48/50] batch [80/244] time 0.096 (0.104) data 0.000 (0.004) loss 1.2782 (1.2208) ce_loss 1.1602 (1.0858) teacher_loss 1.1551 (1.0805) loss_zs_kd 0.1441 (0.1720) loss_oracle 0.0510 (0.0543) acc 68.7500 (71.5625) kd_loss 0.0483 (0.0479) lr 3.1417e-05 eta 0:01:08
epoch [48/50] batch [100/244] time 0.098 (0.104) data 0.001 (0.003) loss 1.1072 (1.2098) ce_loss 0.9819 (1.0761) teacher_loss 0.9738 (1.0709) loss_zs_kd 0.1568 (0.1706) loss_oracle 0.0550 (0.0536) acc 75.0000 (71.5938) kd_loss 0.0508 (0.0479) lr 3.1417e-05 eta 0:01:05
epoch [48/50] batch [120/244] time 0.106 (0.103) data 0.000 (0.003) loss 0.9219 (1.2156) ce_loss 0.7798 (1.0827) teacher_loss 0.7839 (1.0777) loss_zs_kd 0.1826 (0.1695) loss_oracle 0.0467 (0.0531) acc 78.1250 (71.7708) kd_loss 0.0471 (0.0475) lr 3.1417e-05 eta 0:01:02
epoch [48/50] batch [140/244] time 0.099 (0.102) data 0.000 (0.002) loss 1.2580 (1.2229) ce_loss 1.1289 (1.0892) teacher_loss 1.1264 (1.0843) loss_zs_kd 0.1719 (0.1712) loss_oracle 0.0457 (0.0530) acc 71.8750 (71.5625) kd_loss 0.0449 (0.0474) lr 3.1417e-05 eta 0:01:00
epoch [48/50] batch [160/244] time 0.099 (0.102) data 0.000 (0.002) loss 1.6683 (1.2118) ce_loss 1.5420 (1.0794) teacher_loss 1.5435 (1.0747) loss_zs_kd 0.1267 (0.1688) loss_oracle 0.0614 (0.0528) acc 62.5000 (71.6602) kd_loss 0.0505 (0.0475) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [180/244] time 0.106 (0.102) data 0.000 (0.002) loss 0.9799 (1.2030) ce_loss 0.8442 (1.0698) teacher_loss 0.8348 (1.0652) loss_zs_kd 0.1740 (0.1699) loss_oracle 0.0581 (0.0528) acc 81.2500 (71.7535) kd_loss 0.0487 (0.0477) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [200/244] time 0.086 (0.102) data 0.000 (0.002) loss 1.0672 (1.2080) ce_loss 0.9238 (1.0741) teacher_loss 0.9289 (1.0700) loss_zs_kd 0.1929 (0.1703) loss_oracle 0.0419 (0.0528) acc 81.2500 (71.8125) kd_loss 0.0490 (0.0476) lr 3.1417e-05 eta 0:00:54
epoch [48/50] batch [220/244] time 0.085 (0.101) data 0.000 (0.002) loss 1.1973 (1.2104) ce_loss 1.0596 (1.0769) teacher_loss 1.0577 (1.0727) loss_zs_kd 0.1596 (0.1697) loss_oracle 0.0598 (0.0529) acc 71.8750 (71.7472) kd_loss 0.0489 (0.0476) lr 3.1417e-05 eta 0:00:51
epoch [48/50] batch [240/244] time 0.086 (0.100) data 0.000 (0.001) loss 1.0708 (1.2013) ce_loss 0.9590 (1.0675) teacher_loss 0.9518 (1.0632) loss_zs_kd 0.1480 (0.1699) loss_oracle 0.0450 (0.0531) acc 68.7500 (72.0703) kd_loss 0.0440 (0.0478) lr 3.1417e-05 eta 0:00:49
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,837
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [49/50] batch [20/244] time 0.100 (0.118) data 0.000 (0.015) loss 1.1895 (1.1782) ce_loss 1.0488 (1.0383) teacher_loss 1.0445 (1.0340) loss_zs_kd 0.1454 (0.1831) loss_oracle 0.0723 (0.0528) acc 71.8750 (73.4375) kd_loss 0.0639 (0.0491) lr 1.7713e-05 eta 0:00:55
epoch [49/50] batch [40/244] time 0.100 (0.110) data 0.000 (0.008) loss 1.1222 (1.1595) ce_loss 0.9810 (1.0275) teacher_loss 0.9761 (1.0233) loss_zs_kd 0.1701 (0.1682) loss_oracle 0.0610 (0.0521) acc 71.8750 (73.2812) kd_loss 0.0517 (0.0486) lr 1.7713e-05 eta 0:00:49
epoch [49/50] batch [60/244] time 0.108 (0.107) data 0.001 (0.005) loss 0.8922 (1.1649) ce_loss 0.7310 (1.0326) teacher_loss 0.7261 (1.0290) loss_zs_kd 0.2263 (0.1664) loss_oracle 0.0530 (0.0527) acc 81.2500 (73.0208) kd_loss 0.0459 (0.0489) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [80/244] time 0.098 (0.106) data 0.000 (0.004) loss 0.8803 (1.1749) ce_loss 0.7690 (1.0416) teacher_loss 0.7692 (1.0379) loss_zs_kd 0.1245 (0.1691) loss_oracle 0.0489 (0.0524) acc 84.3750 (72.5781) kd_loss 0.0568 (0.0490) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [100/244] time 0.095 (0.104) data 0.000 (0.003) loss 0.9674 (1.1956) ce_loss 0.8286 (1.0617) teacher_loss 0.8308 (1.0581) loss_zs_kd 0.1757 (0.1698) loss_oracle 0.0488 (0.0526) acc 75.0000 (72.0312) kd_loss 0.0421 (0.0494) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [120/244] time 0.105 (0.104) data 0.000 (0.003) loss 1.0846 (1.1764) ce_loss 0.9521 (1.0431) teacher_loss 0.9420 (1.0392) loss_zs_kd 0.1869 (0.1690) loss_oracle 0.0492 (0.0526) acc 78.1250 (72.6302) kd_loss 0.0530 (0.0488) lr 1.7713e-05 eta 0:00:38
epoch [49/50] batch [140/244] time 0.096 (0.103) data 0.000 (0.002) loss 1.3703 (1.1581) ce_loss 1.2363 (1.0245) teacher_loss 1.2351 (1.0205) loss_zs_kd 0.1753 (0.1693) loss_oracle 0.0476 (0.0529) acc 62.5000 (73.1473) kd_loss 0.0528 (0.0488) lr 1.7713e-05 eta 0:00:35
epoch [49/50] batch [160/244] time 0.109 (0.103) data 0.001 (0.002) loss 1.1229 (1.1702) ce_loss 0.9907 (1.0374) teacher_loss 0.9933 (1.0335) loss_zs_kd 0.1316 (0.1685) loss_oracle 0.0638 (0.0525) acc 75.0000 (73.0469) kd_loss 0.0606 (0.0485) lr 1.7713e-05 eta 0:00:33
epoch [49/50] batch [180/244] time 0.097 (0.103) data 0.000 (0.002) loss 1.0285 (1.1651) ce_loss 0.8896 (1.0328) teacher_loss 0.8801 (1.0287) loss_zs_kd 0.1804 (0.1673) loss_oracle 0.0582 (0.0528) acc 81.2500 (72.9514) kd_loss 0.0506 (0.0488) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [200/244] time 0.099 (0.102) data 0.000 (0.002) loss 1.0263 (1.1752) ce_loss 0.9067 (1.0430) teacher_loss 0.9065 (1.0389) loss_zs_kd 0.1385 (0.1670) loss_oracle 0.0505 (0.0529) acc 71.8750 (72.6406) kd_loss 0.0462 (0.0486) lr 1.7713e-05 eta 0:00:29
epoch [49/50] batch [220/244] time 0.098 (0.102) data 0.000 (0.002) loss 1.9967 (1.1833) ce_loss 1.8457 (1.0508) teacher_loss 1.8422 (1.0465) loss_zs_kd 0.2093 (0.1672) loss_oracle 0.0498 (0.0532) acc 56.2500 (72.3722) kd_loss 0.0498 (0.0489) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [240/244] time 0.103 (0.102) data 0.000 (0.001) loss 1.3412 (1.1824) ce_loss 1.2178 (1.0502) teacher_loss 1.2053 (1.0459) loss_zs_kd 0.1540 (0.1670) loss_oracle 0.0589 (0.0530) acc 65.6250 (72.3958) kd_loss 0.0481 (0.0488) lr 1.7713e-05 eta 0:00:25
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,835
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
epoch [50/50] batch [20/244] time 0.102 (0.108) data 0.000 (0.012) loss 1.2917 (1.1953) ce_loss 1.1660 (1.0612) teacher_loss 1.1764 (1.0556) loss_zs_kd 0.1387 (0.1695) loss_oracle 0.0459 (0.0550) acc 65.6250 (71.5625) kd_loss 0.0432 (0.0501) lr 7.8853e-06 eta 0:00:24
epoch [50/50] batch [40/244] time 0.092 (0.102) data 0.000 (0.006) loss 1.4214 (1.1757) ce_loss 1.2891 (1.0434) teacher_loss 1.2804 (1.0398) loss_zs_kd 0.1733 (0.1662) loss_oracle 0.0543 (0.0527) acc 65.6250 (71.9531) kd_loss 0.0523 (0.0484) lr 7.8853e-06 eta 0:00:20
epoch [50/50] batch [60/244] time 0.101 (0.100) data 0.000 (0.004) loss 0.5178 (1.1516) ce_loss 0.4058 (1.0163) teacher_loss 0.4110 (1.0128) loss_zs_kd 0.1154 (0.1699) loss_oracle 0.0490 (0.0539) acc 90.6250 (72.9167) kd_loss 0.0467 (0.0485) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [80/244] time 0.096 (0.099) data 0.000 (0.003) loss 1.3276 (1.1448) ce_loss 1.2148 (1.0126) teacher_loss 1.2082 (1.0088) loss_zs_kd 0.1249 (0.1652) loss_oracle 0.0569 (0.0534) acc 65.6250 (72.9297) kd_loss 0.0508 (0.0483) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [100/244] time 0.100 (0.098) data 0.000 (0.003) loss 1.4753 (1.1667) ce_loss 1.3672 (1.0354) teacher_loss 1.3381 (1.0311) loss_zs_kd 0.1508 (0.1639) loss_oracle 0.0618 (0.0537) acc 65.6250 (72.3750) kd_loss 0.0543 (0.0485) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [120/244] time 0.092 (0.097) data 0.000 (0.002) loss 1.0411 (1.1578) ce_loss 0.9019 (1.0264) teacher_loss 0.8990 (1.0223) loss_zs_kd 0.1916 (0.1638) loss_oracle 0.0463 (0.0536) acc 78.1250 (72.7865) kd_loss 0.0419 (0.0488) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [140/244] time 0.103 (0.097) data 0.000 (0.002) loss 1.1443 (1.1665) ce_loss 1.0244 (1.0355) teacher_loss 1.0193 (1.0310) loss_zs_kd 0.1532 (0.1638) loss_oracle 0.0485 (0.0536) acc 68.7500 (72.4330) kd_loss 0.0529 (0.0491) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [160/244] time 0.090 (0.097) data 0.000 (0.002) loss 0.7580 (1.1593) ce_loss 0.6392 (1.0276) teacher_loss 0.6423 (1.0233) loss_zs_kd 0.1524 (0.1647) loss_oracle 0.0395 (0.0537) acc 87.5000 (72.5781) kd_loss 0.0374 (0.0492) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [180/244] time 0.093 (0.097) data 0.000 (0.001) loss 1.6541 (1.1662) ce_loss 1.5459 (1.0333) teacher_loss 1.5324 (1.0288) loss_zs_kd 0.1249 (0.1673) loss_oracle 0.0593 (0.0538) acc 56.2500 (72.5174) kd_loss 0.0491 (0.0494) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [200/244] time 0.093 (0.097) data 0.000 (0.001) loss 1.0833 (1.1673) ce_loss 0.9043 (1.0339) teacher_loss 0.9043 (1.0291) loss_zs_kd 0.2705 (0.1680) loss_oracle 0.0438 (0.0542) acc 78.1250 (72.5156) kd_loss 0.0407 (0.0493) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [220/244] time 0.098 (0.097) data 0.000 (0.001) loss 1.6350 (1.1630) ce_loss 1.4902 (1.0294) teacher_loss 1.4898 (1.0246) loss_zs_kd 0.2113 (0.1683) loss_oracle 0.0395 (0.0543) acc 53.1250 (72.6989) kd_loss 0.0360 (0.0492) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [240/244] time 0.082 (0.096) data 0.000 (0.001) loss 0.7410 (1.1696) ce_loss 0.6084 (1.0355) teacher_loss 0.6101 (1.0307) loss_zs_kd 0.1310 (0.1695) loss_oracle 0.0654 (0.0541) acc 81.2500 (72.4870) kd_loss 0.0527 (0.0491) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,837
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.1%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 27 *******
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:26:59

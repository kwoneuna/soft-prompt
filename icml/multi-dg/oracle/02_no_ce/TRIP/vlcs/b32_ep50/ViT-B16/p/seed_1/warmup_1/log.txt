Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'sun']
Target     ['pascal']
# classes  5
# train_x  5,147
# val      2,206
# test     3,376
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/160] time 0.109 (0.143) data 0.000 (0.019) loss 0.8045 (0.6808) ce_loss 0.8037 (0.6803) teacher_loss 0.8041 (0.6804) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0002 (0.0004) acc 71.8750 (75.3125) kd_loss 0.0008 (0.0013) lr 1.0000e-05 eta 0:18:59
epoch [1/50] batch [40/160] time 0.119 (0.125) data 0.000 (0.009) loss 0.6830 (0.6694) ce_loss 0.6816 (0.6688) teacher_loss 0.6820 (0.6689) loss_zs_kd 0.0012 (0.0004) loss_oracle 0.0004 (0.0003) acc 75.0000 (75.3125) kd_loss 0.0015 (0.0011) lr 1.0000e-05 eta 0:16:36
epoch [1/50] batch [60/160] time 0.075 (0.114) data 0.000 (0.006) loss 0.5400 (0.6975) ce_loss 0.5386 (0.6968) teacher_loss 0.5384 (0.6968) loss_zs_kd 0.0022 (0.0009) loss_oracle 0.0005 (0.0003) acc 78.1250 (74.9479) kd_loss 0.0017 (0.0011) lr 1.0000e-05 eta 0:15:06
epoch [1/50] batch [80/160] time 0.115 (0.114) data 0.000 (0.005) loss 0.9223 (0.7084) ce_loss 0.9199 (0.7074) teacher_loss 0.9205 (0.7074) loss_zs_kd 0.0028 (0.0014) loss_oracle 0.0004 (0.0003) acc 75.0000 (74.1797) kd_loss 0.0013 (0.0011) lr 1.0000e-05 eta 0:15:04
epoch [1/50] batch [100/160] time 0.122 (0.114) data 0.000 (0.004) loss 0.6284 (0.7056) ce_loss 0.6255 (0.7043) teacher_loss 0.6261 (0.7044) loss_zs_kd 0.0039 (0.0019) loss_oracle 0.0005 (0.0003) acc 81.2500 (74.3750) kd_loss 0.0017 (0.0012) lr 1.0000e-05 eta 0:14:59
epoch [1/50] batch [120/160] time 0.082 (0.112) data 0.000 (0.003) loss 0.7181 (0.6962) ce_loss 0.7139 (0.6946) teacher_loss 0.7145 (0.6946) loss_zs_kd 0.0061 (0.0024) loss_oracle 0.0006 (0.0004) acc 71.8750 (74.7135) kd_loss 0.0019 (0.0013) lr 1.0000e-05 eta 0:14:39
epoch [1/50] batch [140/160] time 0.116 (0.111) data 0.000 (0.003) loss 0.5151 (0.6932) ce_loss 0.5112 (0.6912) teacher_loss 0.5115 (0.6912) loss_zs_kd 0.0061 (0.0030) loss_oracle 0.0005 (0.0004) acc 87.5000 (74.7545) kd_loss 0.0016 (0.0014) lr 1.0000e-05 eta 0:14:35
epoch [1/50] batch [160/160] time 0.110 (0.110) data 0.000 (0.003) loss 0.9846 (0.6972) ce_loss 0.9780 (0.6949) teacher_loss 0.9790 (0.6950) loss_zs_kd 0.0105 (0.0036) loss_oracle 0.0003 (0.0004) acc 65.6250 (74.6094) kd_loss 0.0014 (0.0014) lr 2.0000e-03 eta 0:14:19
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,728
* accuracy: 78.3%
* error: 21.7%
* macro_f1: 80.2%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,924
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      78.3%, epoch: 1 *******
******* Domain p best val test acc: 86.6%, epoch: 1 *******
******* Domain p best test acc:     86.6%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/ana
epoch [2/50] batch [20/160] time 0.068 (0.125) data 0.000 (0.019) loss 0.7591 (0.6612) ce_loss 0.7046 (0.6238) teacher_loss 0.6946 (0.6251) loss_zs_kd 0.0822 (0.0545) loss_oracle 0.0234 (0.0088) acc 75.0000 (77.6562) kd_loss 0.0510 (0.0113) lr 2.0000e-03 eta 0:16:17
epoch [2/50] batch [40/160] time 0.132 (0.125) data 0.000 (0.010) loss 0.8017 (0.6574) ce_loss 0.8540 (0.6221) teacher_loss 0.5946 (0.5781) loss_zs_kd 0.0959 (0.0669) loss_oracle 0.1591 (0.0458) acc 71.8750 (77.7344) kd_loss 0.5872 (0.1600) lr 2.0000e-03 eta 0:16:13
epoch [2/50] batch [60/160] time 0.139 (0.124) data 0.000 (0.006) loss 0.6741 (0.6800) ce_loss 0.5708 (0.6302) teacher_loss 0.3396 (0.5502) loss_zs_kd 0.1475 (0.0812) loss_oracle 0.2608 (0.0892) acc 81.2500 (78.2812) kd_loss 0.7001 (0.2757) lr 2.0000e-03 eta 0:16:07
epoch [2/50] batch [80/160] time 0.073 (0.126) data 0.001 (0.005) loss 0.5784 (0.6876) ce_loss 0.3818 (0.6228) teacher_loss 0.3021 (0.5284) loss_zs_kd 0.1326 (0.0888) loss_oracle 0.2100 (0.1148) acc 90.6250 (77.9688) kd_loss 0.7329 (0.3695) lr 2.0000e-03 eta 0:16:14
epoch [2/50] batch [100/160] time 0.102 (0.121) data 0.000 (0.004) loss 0.6790 (0.7088) ce_loss 0.3770 (0.6245) teacher_loss 0.2839 (0.5211) loss_zs_kd 0.1176 (0.0891) loss_oracle 0.3362 (0.1431) acc 90.6250 (77.7188) kd_loss 0.7983 (0.4352) lr 2.0000e-03 eta 0:15:40
epoch [2/50] batch [120/160] time 0.111 (0.119) data 0.001 (0.003) loss 0.7151 (0.7197) ce_loss 0.5815 (0.6275) teacher_loss 0.5176 (0.5220) loss_zs_kd 0.0636 (0.0893) loss_oracle 0.1657 (0.1529) acc 87.5000 (77.6042) kd_loss 0.6407 (0.4851) lr 2.0000e-03 eta 0:15:17
epoch [2/50] batch [140/160] time 0.140 (0.118) data 0.000 (0.003) loss 0.5024 (0.7094) ce_loss 0.3062 (0.6108) teacher_loss 0.2175 (0.5080) loss_zs_kd 0.0709 (0.0874) loss_oracle 0.2495 (0.1577) acc 93.7500 (78.0134) kd_loss 0.6853 (0.5189) lr 2.0000e-03 eta 0:15:06
epoch [2/50] batch [160/160] time 0.090 (0.116) data 0.000 (0.003) loss 0.7543 (0.7066) ce_loss 0.5635 (0.5995) teacher_loss 0.4726 (0.4995) loss_zs_kd 0.0871 (0.0874) loss_oracle 0.2382 (0.1634) acc 81.2500 (78.1250) kd_loss 0.6735 (0.5475) lr 1.9980e-03 eta 0:14:49
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,817
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 84.2%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,962
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.7%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.4%, epoch: 2 *******
******* Domain p best val test acc: 87.7%, epoch: 2 *******
******* Domain p best test acc:     87.7%, epoch: 2 *******
epoch [3/50] batch [20/160] time 0.114 (0.119) data 0.000 (0.014) loss 0.7231 (0.7418) ce_loss 0.5708 (0.5624) teacher_loss 0.4608 (0.4632) loss_zs_kd 0.0820 (0.0773) loss_oracle 0.2213 (0.2400) acc 81.2500 (79.2188) kd_loss 0.7561 (0.7554) lr 1.9980e-03 eta 0:15:11
epoch [3/50] batch [40/160] time 0.132 (0.117) data 0.000 (0.007) loss 0.5833 (0.7571) ce_loss 0.4502 (0.5602) teacher_loss 0.3196 (0.4755) loss_zs_kd 0.0579 (0.0812) loss_oracle 0.2347 (0.2410) acc 84.3750 (79.8438) kd_loss 0.8051 (0.7759) lr 1.9980e-03 eta 0:14:56
epoch [3/50] batch [60/160] time 0.138 (0.116) data 0.001 (0.005) loss 0.9306 (0.7870) ce_loss 0.6714 (0.5775) teacher_loss 0.5443 (0.4893) loss_zs_kd 0.0745 (0.0809) loss_oracle 0.3490 (0.2573) acc 81.2500 (79.2188) kd_loss 0.7459 (0.7908) lr 1.9980e-03 eta 0:14:47
epoch [3/50] batch [80/160] time 0.086 (0.115) data 0.000 (0.004) loss 0.8384 (0.7896) ce_loss 0.5645 (0.5837) teacher_loss 0.5196 (0.4874) loss_zs_kd 0.1109 (0.0824) loss_oracle 0.2633 (0.2610) acc 78.1250 (78.6328) kd_loss 0.8130 (0.8027) lr 1.9980e-03 eta 0:14:34
epoch [3/50] batch [100/160] time 0.110 (0.114) data 0.000 (0.003) loss 0.7430 (0.7842) ce_loss 0.4524 (0.5611) teacher_loss 0.3659 (0.4719) loss_zs_kd 0.0602 (0.0846) loss_oracle 0.3470 (0.2700) acc 84.3750 (79.2812) kd_loss 0.8061 (0.8103) lr 1.9980e-03 eta 0:14:21
epoch [3/50] batch [120/160] time 0.122 (0.113) data 0.000 (0.003) loss 0.8087 (0.8016) ce_loss 0.4519 (0.5541) teacher_loss 0.3863 (0.4679) loss_zs_kd 0.1327 (0.0880) loss_oracle 0.3560 (0.2897) acc 81.2500 (79.3750) kd_loss 0.8149 (0.8172) lr 1.9980e-03 eta 0:14:17
epoch [3/50] batch [140/160] time 0.097 (0.113) data 0.000 (0.002) loss 0.7855 (0.8179) ce_loss 0.4495 (0.5533) teacher_loss 0.3077 (0.4686) loss_zs_kd 0.1049 (0.0888) loss_oracle 0.4254 (0.3049) acc 81.2500 (79.1295) kd_loss 0.9088 (0.8248) lr 1.9980e-03 eta 0:14:11
epoch [3/50] batch [160/160] time 0.083 (0.112) data 0.000 (0.002) loss 1.5677 (0.8507) ce_loss 1.0791 (0.5565) teacher_loss 1.0071 (0.4745) loss_zs_kd 0.1122 (0.0915) loss_oracle 0.5046 (0.3304) acc 65.6250 (79.0234) kd_loss 0.9064 (0.8334) lr 1.9921e-03 eta 0:14:01
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,819
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,965
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.7%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.5%, epoch: 3 *******
******* Domain p best val test acc: 87.8%, epoch: 3 *******
******* Domain p best test acc:     87.8%, epoch: 3 *******
epoch [4/50] batch [20/160] time 0.086 (0.127) data 0.000 (0.016) loss 1.0261 (1.0605) ce_loss 0.5059 (0.5673) teacher_loss 0.4912 (0.4967) loss_zs_kd 0.1037 (0.1034) loss_oracle 0.4830 (0.5121) acc 78.1250 (77.9688) kd_loss 0.9493 (0.9132) lr 1.9921e-03 eta 0:15:51
epoch [4/50] batch [40/160] time 0.099 (0.115) data 0.000 (0.008) loss 0.9131 (1.0090) ce_loss 0.3794 (0.5040) teacher_loss 0.3648 (0.4442) loss_zs_kd 0.1318 (0.1079) loss_oracle 0.4824 (0.5108) acc 90.6250 (81.1719) kd_loss 0.9721 (0.9160) lr 1.9921e-03 eta 0:14:21
epoch [4/50] batch [60/160] time 0.094 (0.113) data 0.001 (0.005) loss 1.0086 (1.0413) ce_loss 0.5200 (0.5121) teacher_loss 0.4197 (0.4540) loss_zs_kd 0.1118 (0.1044) loss_oracle 0.5331 (0.5352) acc 84.3750 (81.0938) kd_loss 0.9054 (0.9174) lr 1.9921e-03 eta 0:14:03
epoch [4/50] batch [80/160] time 0.152 (0.117) data 0.000 (0.004) loss 1.1597 (1.0652) ce_loss 0.6108 (0.5270) teacher_loss 0.4019 (0.4614) loss_zs_kd 0.0912 (0.1062) loss_oracle 0.7121 (0.5507) acc 75.0000 (80.4688) kd_loss 0.9585 (0.9195) lr 1.9921e-03 eta 0:14:27
epoch [4/50] batch [100/160] time 0.072 (0.119) data 0.000 (0.003) loss 1.0920 (1.0870) ce_loss 0.4871 (0.5367) teacher_loss 0.5047 (0.4741) loss_zs_kd 0.1018 (0.1081) loss_oracle 0.5364 (0.5589) acc 81.2500 (79.9062) kd_loss 0.9298 (0.9182) lr 1.9921e-03 eta 0:14:40
epoch [4/50] batch [120/160] time 0.142 (0.120) data 0.000 (0.003) loss 1.2537 (1.0876) ce_loss 0.7266 (0.5413) teacher_loss 0.6716 (0.4796) loss_zs_kd 0.0838 (0.1048) loss_oracle 0.5402 (0.5556) acc 81.2500 (79.8958) kd_loss 0.8624 (0.9157) lr 1.9921e-03 eta 0:14:45
epoch [4/50] batch [140/160] time 0.087 (0.118) data 0.000 (0.002) loss 0.9742 (1.0838) ce_loss 0.5562 (0.5418) teacher_loss 0.4455 (0.4783) loss_zs_kd 0.0809 (0.1053) loss_oracle 0.4882 (0.5528) acc 81.2500 (79.7545) kd_loss 0.8529 (0.9128) lr 1.9921e-03 eta 0:14:31
epoch [4/50] batch [160/160] time 0.126 (0.115) data 0.000 (0.002) loss 0.8780 (1.0751) ce_loss 0.3323 (0.5380) teacher_loss 0.2941 (0.4712) loss_zs_kd 0.0956 (0.1070) loss_oracle 0.5362 (0.5504) acc 93.7500 (79.8828) kd_loss 0.7947 (0.9088) lr 1.9823e-03 eta 0:14:09
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,827
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 84.4%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,983
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.2%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.8%, epoch: 4 *******
******* Domain p best val test acc: 88.4%, epoch: 4 *******
******* Domain p best test acc:     88.4%, epoch: 4 *******
epoch [5/50] batch [20/160] time 0.098 (0.112) data 0.000 (0.015) loss 0.7753 (1.0329) ce_loss 0.3286 (0.5520) teacher_loss 0.2553 (0.4351) loss_zs_kd 0.1010 (0.1176) loss_oracle 0.4695 (0.5390) acc 90.6250 (81.2500) kd_loss 0.8165 (0.8878) lr 1.9823e-03 eta 0:13:43
epoch [5/50] batch [40/160] time 0.093 (0.100) data 0.000 (0.007) loss 0.9215 (1.0410) ce_loss 0.3230 (0.5439) teacher_loss 0.3144 (0.4407) loss_zs_kd 0.1022 (0.1148) loss_oracle 0.5560 (0.5429) acc 93.7500 (80.7812) kd_loss 0.8341 (0.8790) lr 1.9823e-03 eta 0:12:12
epoch [5/50] batch [60/160] time 0.091 (0.100) data 0.001 (0.005) loss 1.1963 (1.0337) ce_loss 0.7261 (0.5379) teacher_loss 0.6900 (0.4318) loss_zs_kd 0.1417 (0.1233) loss_oracle 0.4355 (0.5403) acc 78.1250 (80.6771) kd_loss 0.7444 (0.8724) lr 1.9823e-03 eta 0:12:09
epoch [5/50] batch [80/160] time 0.087 (0.098) data 0.000 (0.004) loss 0.8641 (0.9982) ce_loss 0.5688 (0.5394) teacher_loss 0.4133 (0.4316) loss_zs_kd 0.1401 (0.1276) loss_oracle 0.3808 (0.5028) acc 81.2500 (81.2891) kd_loss 0.8405 (0.8707) lr 1.9823e-03 eta 0:11:51
epoch [5/50] batch [100/160] time 0.110 (0.099) data 0.000 (0.003) loss 0.8922 (0.9623) ce_loss 0.5093 (0.5279) teacher_loss 0.4457 (0.4170) loss_zs_kd 0.1231 (0.1270) loss_oracle 0.3849 (0.4819) acc 81.2500 (81.0625) kd_loss 0.7448 (0.8681) lr 1.9823e-03 eta 0:11:56
epoch [5/50] batch [120/160] time 0.092 (0.099) data 0.000 (0.003) loss 0.8172 (0.9485) ce_loss 0.5645 (0.5287) teacher_loss 0.3492 (0.4098) loss_zs_kd 0.1533 (0.1322) loss_oracle 0.3913 (0.4726) acc 75.0000 (80.9896) kd_loss 0.8302 (0.8684) lr 1.9823e-03 eta 0:12:00
epoch [5/50] batch [140/160] time 0.087 (0.100) data 0.000 (0.002) loss 1.1520 (0.9369) ce_loss 0.8799 (0.5304) teacher_loss 0.6024 (0.4031) loss_zs_kd 0.1634 (0.1359) loss_oracle 0.4678 (0.4658) acc 81.2500 (80.8929) kd_loss 0.9271 (0.8715) lr 1.9823e-03 eta 0:12:03
epoch [5/50] batch [160/160] time 0.077 (0.100) data 0.000 (0.002) loss 1.0853 (0.9263) ce_loss 0.8569 (0.5286) teacher_loss 0.6103 (0.3959) loss_zs_kd 0.1050 (0.1389) loss_oracle 0.4225 (0.4610) acc 68.7500 (80.8203) kd_loss 0.9025 (0.8738) lr 1.9686e-03 eta 0:12:02
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,833
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 84.5%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,969
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.0%
******* Domain p best val acc:      83.1%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.4%, epoch: 4 *******
epoch [6/50] batch [20/160] time 0.089 (0.112) data 0.000 (0.013) loss 0.7018 (0.7954) ce_loss 0.4875 (0.5421) teacher_loss 0.2468 (0.3443) loss_zs_kd 0.1450 (0.1493) loss_oracle 0.3825 (0.3765) acc 78.1250 (80.6250) kd_loss 0.9693 (0.9131) lr 1.9686e-03 eta 0:13:21
epoch [6/50] batch [40/160] time 0.091 (0.104) data 0.000 (0.007) loss 0.7257 (0.7962) ce_loss 0.3914 (0.5231) teacher_loss 0.2725 (0.3329) loss_zs_kd 0.1467 (0.1608) loss_oracle 0.3799 (0.3829) acc 84.3750 (81.1719) kd_loss 0.9150 (0.9139) lr 1.9686e-03 eta 0:12:24
epoch [6/50] batch [60/160] time 0.136 (0.107) data 0.001 (0.005) loss 0.6872 (0.7959) ce_loss 0.4829 (0.5292) teacher_loss 0.2603 (0.3412) loss_zs_kd 0.1704 (0.1553) loss_oracle 0.3417 (0.3770) acc 75.0000 (81.7188) kd_loss 0.9565 (0.9195) lr 1.9686e-03 eta 0:12:47
epoch [6/50] batch [80/160] time 0.107 (0.106) data 0.000 (0.003) loss 0.7401 (0.8020) ce_loss 0.5215 (0.5432) teacher_loss 0.3630 (0.3555) loss_zs_kd 0.1326 (0.1515) loss_oracle 0.3108 (0.3707) acc 78.1250 (81.3672) kd_loss 0.9805 (0.9253) lr 1.9686e-03 eta 0:12:36
epoch [6/50] batch [100/160] time 0.107 (0.106) data 0.000 (0.003) loss 0.7801 (0.7928) ce_loss 0.7163 (0.5424) teacher_loss 0.3954 (0.3558) loss_zs_kd 0.1093 (0.1474) loss_oracle 0.3301 (0.3633) acc 75.0000 (80.9688) kd_loss 1.0331 (0.9281) lr 1.9686e-03 eta 0:12:35
epoch [6/50] batch [120/160] time 0.118 (0.107) data 0.000 (0.002) loss 0.8948 (0.7911) ce_loss 0.7837 (0.5465) teacher_loss 0.4182 (0.3559) loss_zs_kd 0.1881 (0.1487) loss_oracle 0.3826 (0.3609) acc 68.7500 (80.7292) kd_loss 1.0625 (0.9306) lr 1.9686e-03 eta 0:12:36
epoch [6/50] batch [140/160] time 0.080 (0.108) data 0.000 (0.002) loss 0.6752 (0.7823) ce_loss 0.5464 (0.5372) teacher_loss 0.3513 (0.3535) loss_zs_kd 0.0942 (0.1456) loss_oracle 0.2769 (0.3560) acc 75.0000 (81.1384) kd_loss 0.9777 (0.9307) lr 1.9686e-03 eta 0:12:39
epoch [6/50] batch [160/160] time 0.063 (0.106) data 0.000 (0.002) loss 0.9703 (0.7876) ce_loss 0.7021 (0.5478) teacher_loss 0.5608 (0.3637) loss_zs_kd 0.1556 (0.1443) loss_oracle 0.3317 (0.3517) acc 75.0000 (80.5273) kd_loss 0.9737 (0.9361) lr 1.9511e-03 eta 0:12:26
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,819
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.8%
******* Domain p best val acc:      83.1%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.4%, epoch: 4 *******
epoch [7/50] batch [20/160] time 0.091 (0.113) data 0.000 (0.012) loss 0.8602 (0.7147) ce_loss 0.7505 (0.5106) teacher_loss 0.5239 (0.3508) loss_zs_kd 0.1041 (0.1315) loss_oracle 0.2842 (0.2981) acc 65.6250 (82.8125) kd_loss 1.0562 (0.9599) lr 1.9511e-03 eta 0:13:13
epoch [7/50] batch [40/160] time 0.098 (0.100) data 0.000 (0.006) loss 0.8552 (0.7343) ce_loss 0.5010 (0.5535) teacher_loss 0.4980 (0.3867) loss_zs_kd 0.1107 (0.1267) loss_oracle 0.3019 (0.2842) acc 84.3750 (81.4062) kd_loss 0.9041 (0.9684) lr 1.9511e-03 eta 0:11:41
epoch [7/50] batch [60/160] time 0.132 (0.100) data 0.001 (0.004) loss 0.8704 (0.7308) ce_loss 0.6128 (0.5450) teacher_loss 0.4777 (0.3845) loss_zs_kd 0.1269 (0.1265) loss_oracle 0.3292 (0.2830) acc 78.1250 (80.8333) kd_loss 1.0728 (0.9699) lr 1.9511e-03 eta 0:11:39
epoch [7/50] batch [80/160] time 0.072 (0.100) data 0.000 (0.003) loss 0.8457 (0.7411) ce_loss 0.6528 (0.5587) teacher_loss 0.5377 (0.3922) loss_zs_kd 0.1496 (0.1296) loss_oracle 0.2333 (0.2841) acc 78.1250 (80.2344) kd_loss 1.0096 (0.9742) lr 1.9511e-03 eta 0:11:33
epoch [7/50] batch [100/160] time 0.077 (0.098) data 0.000 (0.002) loss 0.6162 (0.7500) ce_loss 0.4993 (0.5647) teacher_loss 0.2767 (0.3961) loss_zs_kd 0.1317 (0.1287) loss_oracle 0.2737 (0.2897) acc 75.0000 (79.7188) kd_loss 1.0103 (0.9746) lr 1.9511e-03 eta 0:11:21
epoch [7/50] batch [120/160] time 0.134 (0.098) data 0.000 (0.002) loss 0.5869 (0.7554) ce_loss 0.3950 (0.5698) teacher_loss 0.2690 (0.4078) loss_zs_kd 0.0652 (0.1258) loss_oracle 0.2853 (0.2847) acc 87.5000 (79.5833) kd_loss 0.9300 (0.9764) lr 1.9511e-03 eta 0:11:15
epoch [7/50] batch [140/160] time 0.087 (0.097) data 0.000 (0.002) loss 0.6697 (0.7420) ce_loss 0.4675 (0.5589) teacher_loss 0.4130 (0.4032) loss_zs_kd 0.0891 (0.1224) loss_oracle 0.2121 (0.2776) acc 84.3750 (79.9554) kd_loss 0.9464 (0.9781) lr 1.9511e-03 eta 0:11:07
epoch [7/50] batch [160/160] time 0.076 (0.095) data 0.000 (0.002) loss 0.9208 (0.7430) ce_loss 0.7529 (0.5625) teacher_loss 0.5616 (0.4079) loss_zs_kd 0.1465 (0.1210) loss_oracle 0.2859 (0.2746) acc 78.1250 (80.0391) kd_loss 1.0052 (0.9787) lr 1.9298e-03 eta 0:10:56
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,831
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,966
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.0%
******* Domain p best val acc:      83.1%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.4%, epoch: 4 *******
epoch [8/50] batch [20/160] time 0.084 (0.114) data 0.000 (0.014) loss 0.7561 (0.7425) ce_loss 0.6440 (0.5850) teacher_loss 0.4767 (0.4184) loss_zs_kd 0.1096 (0.1073) loss_oracle 0.2246 (0.2704) acc 81.2500 (79.8438) kd_loss 0.9818 (0.9809) lr 1.9298e-03 eta 0:13:04
epoch [8/50] batch [40/160] time 0.076 (0.108) data 0.000 (0.007) loss 0.8367 (0.7442) ce_loss 0.7817 (0.5714) teacher_loss 0.5070 (0.4137) loss_zs_kd 0.1227 (0.1097) loss_oracle 0.2683 (0.2757) acc 62.5000 (79.5312) kd_loss 1.0290 (0.9746) lr 1.9298e-03 eta 0:12:20
epoch [8/50] batch [60/160] time 0.136 (0.108) data 0.001 (0.005) loss 0.8290 (0.7380) ce_loss 0.5879 (0.5665) teacher_loss 0.4382 (0.4015) loss_zs_kd 0.1410 (0.1132) loss_oracle 0.3204 (0.2799) acc 71.8750 (79.6354) kd_loss 0.9531 (0.9720) lr 1.9298e-03 eta 0:12:14
epoch [8/50] batch [80/160] time 0.098 (0.107) data 0.000 (0.004) loss 0.5377 (0.7333) ce_loss 0.3433 (0.5514) teacher_loss 0.2462 (0.4003) loss_zs_kd 0.1118 (0.1136) loss_oracle 0.2355 (0.2762) acc 90.6250 (79.8438) kd_loss 1.0794 (0.9686) lr 1.9298e-03 eta 0:12:05
epoch [8/50] batch [100/160] time 0.141 (0.107) data 0.000 (0.003) loss 0.7423 (0.7318) ce_loss 0.5786 (0.5518) teacher_loss 0.3275 (0.3979) loss_zs_kd 0.1299 (0.1158) loss_oracle 0.3498 (0.2760) acc 81.2500 (80.1250) kd_loss 0.9723 (0.9688) lr 1.9298e-03 eta 0:12:07
epoch [8/50] batch [120/160] time 0.137 (0.108) data 0.000 (0.003) loss 0.6652 (0.7333) ce_loss 0.4290 (0.5525) teacher_loss 0.3052 (0.4009) loss_zs_kd 0.1696 (0.1155) loss_oracle 0.2752 (0.2747) acc 87.5000 (80.4167) kd_loss 1.0583 (0.9677) lr 1.9298e-03 eta 0:12:12
epoch [8/50] batch [140/160] time 0.100 (0.108) data 0.000 (0.002) loss 0.6374 (0.7313) ce_loss 0.3755 (0.5536) teacher_loss 0.3541 (0.3986) loss_zs_kd 0.0902 (0.1168) loss_oracle 0.2382 (0.2743) acc 87.5000 (80.3571) kd_loss 0.9491 (0.9631) lr 1.9298e-03 eta 0:12:09
epoch [8/50] batch [160/160] time 0.110 (0.107) data 0.000 (0.002) loss 0.6278 (0.7297) ce_loss 0.5098 (0.5524) teacher_loss 0.3466 (0.3976) loss_zs_kd 0.0753 (0.1165) loss_oracle 0.2436 (0.2739) acc 75.0000 (80.3320) kd_loss 0.9848 (0.9615) lr 1.9048e-03 eta 0:12:01
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,819
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,965
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.8%
******* Domain p best val acc:      83.1%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.4%, epoch: 4 *******
epoch [9/50] batch [20/160] time 0.138 (0.134) data 0.001 (0.015) loss 0.5574 (0.6785) ce_loss 0.4067 (0.5323) teacher_loss 0.2385 (0.3676) loss_zs_kd 0.1051 (0.1172) loss_oracle 0.2664 (0.2523) acc 84.3750 (80.4688) kd_loss 0.9211 (0.9522) lr 1.9048e-03 eta 0:15:00
epoch [9/50] batch [40/160] time 0.099 (0.124) data 0.000 (0.008) loss 0.8219 (0.6992) ce_loss 0.5210 (0.5355) teacher_loss 0.4838 (0.3787) loss_zs_kd 0.1270 (0.1144) loss_oracle 0.2746 (0.2633) acc 81.2500 (80.4688) kd_loss 0.9538 (0.9450) lr 1.9048e-03 eta 0:13:50
epoch [9/50] batch [60/160] time 0.138 (0.123) data 0.001 (0.005) loss 0.7158 (0.7305) ce_loss 0.5312 (0.5589) teacher_loss 0.3387 (0.3972) loss_zs_kd 0.1118 (0.1173) loss_oracle 0.3212 (0.2747) acc 78.1250 (79.6875) kd_loss 0.9627 (0.9428) lr 1.9048e-03 eta 0:13:37
epoch [9/50] batch [80/160] time 0.072 (0.125) data 0.000 (0.004) loss 0.7042 (0.7319) ce_loss 0.4399 (0.5542) teacher_loss 0.3245 (0.3928) loss_zs_kd 0.1193 (0.1198) loss_oracle 0.3200 (0.2793) acc 78.1250 (79.9609) kd_loss 0.9643 (0.9386) lr 1.9048e-03 eta 0:13:49
epoch [9/50] batch [100/160] time 0.084 (0.127) data 0.000 (0.003) loss 0.6931 (0.7311) ce_loss 0.4702 (0.5441) teacher_loss 0.3697 (0.3902) loss_zs_kd 0.0910 (0.1172) loss_oracle 0.2779 (0.2823) acc 90.6250 (80.3125) kd_loss 0.9445 (0.9355) lr 1.9048e-03 eta 0:13:59
epoch [9/50] batch [120/160] time 0.117 (0.122) data 0.000 (0.003) loss 0.9826 (0.7425) ce_loss 0.7891 (0.5535) teacher_loss 0.4916 (0.3952) loss_zs_kd 0.1379 (0.1171) loss_oracle 0.4221 (0.2888) acc 71.8750 (80.2083) kd_loss 0.9287 (0.9373) lr 1.9048e-03 eta 0:13:26
epoch [9/50] batch [140/160] time 0.131 (0.119) data 0.000 (0.002) loss 0.7435 (0.7423) ce_loss 0.5801 (0.5489) teacher_loss 0.3301 (0.3910) loss_zs_kd 0.1770 (0.1167) loss_oracle 0.3248 (0.2929) acc 75.0000 (80.2009) kd_loss 0.9924 (0.9376) lr 1.9048e-03 eta 0:13:05
epoch [9/50] batch [160/160] time 0.092 (0.117) data 0.000 (0.002) loss 0.6599 (0.7416) ce_loss 0.4692 (0.5453) teacher_loss 0.3104 (0.3888) loss_zs_kd 0.1090 (0.1183) loss_oracle 0.2950 (0.2936) acc 78.1250 (80.3516) kd_loss 0.9035 (0.9378) lr 1.8763e-03 eta 0:12:47
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,829
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,980
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 89.1%
******* Domain p best val acc:      83.1%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.4%, epoch: 4 *******
epoch [10/50] batch [20/160] time 0.080 (0.119) data 0.000 (0.014) loss 0.5779 (0.7523) ce_loss 0.3706 (0.5306) teacher_loss 0.2912 (0.4075) loss_zs_kd 0.0806 (0.1029) loss_oracle 0.2464 (0.2933) acc 87.5000 (80.6250) kd_loss 1.0060 (0.9378) lr 1.8763e-03 eta 0:12:59
epoch [10/50] batch [40/160] time 0.079 (0.109) data 0.000 (0.007) loss 0.6794 (0.7418) ce_loss 0.4507 (0.5197) teacher_loss 0.3191 (0.3922) loss_zs_kd 0.1089 (0.1051) loss_oracle 0.3059 (0.2970) acc 81.2500 (80.7031) kd_loss 0.9353 (0.9268) lr 1.8763e-03 eta 0:11:49
epoch [10/50] batch [60/160] time 0.095 (0.105) data 0.001 (0.005) loss 0.7265 (0.7620) ce_loss 0.4421 (0.5415) teacher_loss 0.3152 (0.4027) loss_zs_kd 0.1307 (0.1110) loss_oracle 0.3460 (0.3038) acc 87.5000 (79.7917) kd_loss 0.9124 (0.9253) lr 1.8763e-03 eta 0:11:23
epoch [10/50] batch [80/160] time 0.099 (0.100) data 0.000 (0.004) loss 0.9566 (0.7657) ce_loss 0.6401 (0.5438) teacher_loss 0.5968 (0.4013) loss_zs_kd 0.1172 (0.1143) loss_oracle 0.3012 (0.3071) acc 84.3750 (80.1172) kd_loss 0.9032 (0.9252) lr 1.8763e-03 eta 0:10:47
epoch [10/50] batch [100/160] time 0.091 (0.097) data 0.000 (0.003) loss 0.7018 (0.7636) ce_loss 0.5718 (0.5409) teacher_loss 0.3650 (0.3990) loss_zs_kd 0.1619 (0.1169) loss_oracle 0.2558 (0.3061) acc 78.1250 (80.4375) kd_loss 0.9030 (0.9214) lr 1.8763e-03 eta 0:10:25
epoch [10/50] batch [120/160] time 0.076 (0.095) data 0.000 (0.003) loss 0.9685 (0.7632) ce_loss 0.8169 (0.5442) teacher_loss 0.5845 (0.3991) loss_zs_kd 0.1858 (0.1188) loss_oracle 0.2912 (0.3047) acc 68.7500 (80.4688) kd_loss 0.9416 (0.9190) lr 1.8763e-03 eta 0:10:12
epoch [10/50] batch [140/160] time 0.073 (0.094) data 0.000 (0.002) loss 0.6713 (0.7568) ce_loss 0.4653 (0.5416) teacher_loss 0.3533 (0.3945) loss_zs_kd 0.1027 (0.1189) loss_oracle 0.2666 (0.3028) acc 84.3750 (80.7143) kd_loss 0.8099 (0.9183) lr 1.8763e-03 eta 0:10:00
epoch [10/50] batch [160/160] time 0.125 (0.093) data 0.000 (0.002) loss 0.9374 (0.7674) ce_loss 0.5947 (0.5513) teacher_loss 0.5743 (0.4049) loss_zs_kd 0.0969 (0.1194) loss_oracle 0.3146 (0.3028) acc 78.1250 (80.2344) kd_loss 0.8742 (0.9148) lr 1.8443e-03 eta 0:09:54
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,834
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 85.1%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,977
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 89.2%
******* Domain p best val acc:      83.1%, epoch: 10 *******
******* Domain p best val test acc: 88.2%, epoch: 10 *******
******* Domain p best test acc:     88.4%, epoch: 4 *******
epoch [11/50] batch [20/160] time 0.141 (0.129) data 0.000 (0.012) loss 0.6700 (0.7480) ce_loss 0.3755 (0.5353) teacher_loss 0.2716 (0.3858) loss_zs_kd 0.1322 (0.1048) loss_oracle 0.3323 (0.3099) acc 78.1250 (80.0000) kd_loss 0.9360 (0.9082) lr 1.8443e-03 eta 0:13:44
epoch [11/50] batch [40/160] time 0.128 (0.122) data 0.000 (0.006) loss 0.6607 (0.7509) ce_loss 0.3328 (0.5485) teacher_loss 0.3518 (0.4008) loss_zs_kd 0.0988 (0.1073) loss_oracle 0.2594 (0.2965) acc 87.5000 (80.2344) kd_loss 0.8459 (0.8988) lr 1.8443e-03 eta 0:12:55
epoch [11/50] batch [60/160] time 0.091 (0.119) data 0.001 (0.004) loss 0.7095 (0.7584) ce_loss 0.4990 (0.5495) teacher_loss 0.3246 (0.4112) loss_zs_kd 0.1047 (0.1045) loss_oracle 0.3326 (0.2949) acc 81.2500 (80.5208) kd_loss 0.8699 (0.8948) lr 1.8443e-03 eta 0:12:31
epoch [11/50] batch [80/160] time 0.126 (0.118) data 0.001 (0.003) loss 0.7281 (0.7591) ce_loss 0.5435 (0.5534) teacher_loss 0.4509 (0.4167) loss_zs_kd 0.0922 (0.1053) loss_oracle 0.2311 (0.2898) acc 84.3750 (80.3906) kd_loss 0.8484 (0.8926) lr 1.8443e-03 eta 0:12:26
epoch [11/50] batch [100/160] time 0.084 (0.117) data 0.000 (0.003) loss 0.6988 (0.7466) ce_loss 0.3796 (0.5398) teacher_loss 0.3371 (0.4061) loss_zs_kd 0.1302 (0.1046) loss_oracle 0.2966 (0.2883) acc 87.5000 (80.8125) kd_loss 0.8603 (0.8939) lr 1.8443e-03 eta 0:12:15
epoch [11/50] batch [120/160] time 0.117 (0.116) data 0.000 (0.002) loss 0.6881 (0.7431) ce_loss 0.5645 (0.5406) teacher_loss 0.3877 (0.4073) loss_zs_kd 0.0981 (0.1038) loss_oracle 0.2513 (0.2839) acc 71.8750 (80.8594) kd_loss 0.8580 (0.8926) lr 1.8443e-03 eta 0:12:08
epoch [11/50] batch [140/160] time 0.068 (0.115) data 0.001 (0.002) loss 0.7372 (0.7425) ce_loss 0.4780 (0.5393) teacher_loss 0.4089 (0.4084) loss_zs_kd 0.1038 (0.1023) loss_oracle 0.2764 (0.2829) acc 84.3750 (80.7812) kd_loss 0.9023 (0.8939) lr 1.8443e-03 eta 0:11:59
epoch [11/50] batch [160/160] time 0.147 (0.118) data 0.000 (0.002) loss 0.6375 (0.7403) ce_loss 0.3826 (0.5356) teacher_loss 0.3460 (0.4062) loss_zs_kd 0.1128 (0.1032) loss_oracle 0.2351 (0.2825) acc 87.5000 (80.9375) kd_loss 0.8885 (0.8938) lr 1.8090e-03 eta 0:12:13
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,833
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,983
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.2%
******* Domain p best val acc:      83.1%, epoch: 10 *******
******* Domain p best val test acc: 88.2%, epoch: 10 *******
******* Domain p best test acc:     88.4%, epoch: 4 *******
epoch [12/50] batch [20/160] time 0.137 (0.123) data 0.000 (0.016) loss 0.6408 (0.7106) ce_loss 0.4458 (0.4975) teacher_loss 0.3176 (0.3975) loss_zs_kd 0.0935 (0.0994) loss_oracle 0.2765 (0.2634) acc 87.5000 (82.0312) kd_loss 0.9301 (0.8785) lr 1.8090e-03 eta 0:12:45
epoch [12/50] batch [40/160] time 0.132 (0.116) data 0.000 (0.008) loss 0.6892 (0.6828) ce_loss 0.4563 (0.4809) teacher_loss 0.3668 (0.3701) loss_zs_kd 0.0947 (0.0982) loss_oracle 0.2751 (0.2636) acc 84.3750 (83.1250) kd_loss 0.8662 (0.8827) lr 1.8090e-03 eta 0:12:00
epoch [12/50] batch [60/160] time 0.139 (0.113) data 0.001 (0.006) loss 0.7130 (0.7219) ce_loss 0.5068 (0.5145) teacher_loss 0.3985 (0.3954) loss_zs_kd 0.1071 (0.1041) loss_oracle 0.2610 (0.2745) acc 75.0000 (81.8229) kd_loss 0.9277 (0.8800) lr 1.8090e-03 eta 0:11:37
epoch [12/50] batch [80/160] time 0.079 (0.112) data 0.000 (0.004) loss 0.6248 (0.7358) ce_loss 0.4260 (0.5221) teacher_loss 0.3489 (0.4070) loss_zs_kd 0.0916 (0.1020) loss_oracle 0.2300 (0.2778) acc 84.3750 (81.5234) kd_loss 0.9126 (0.8810) lr 1.8090e-03 eta 0:11:31
epoch [12/50] batch [100/160] time 0.128 (0.111) data 0.000 (0.003) loss 0.5957 (0.7353) ce_loss 0.3809 (0.5261) teacher_loss 0.3031 (0.4129) loss_zs_kd 0.0862 (0.1007) loss_oracle 0.2495 (0.2720) acc 81.2500 (81.2500) kd_loss 0.9094 (0.8780) lr 1.8090e-03 eta 0:11:22
epoch [12/50] batch [120/160] time 0.140 (0.110) data 0.000 (0.003) loss 0.7032 (0.7355) ce_loss 0.5244 (0.5288) teacher_loss 0.3469 (0.4133) loss_zs_kd 0.0674 (0.1003) loss_oracle 0.3225 (0.2721) acc 78.1250 (80.9635) kd_loss 0.8995 (0.8760) lr 1.8090e-03 eta 0:11:12
epoch [12/50] batch [140/160] time 0.131 (0.110) data 0.000 (0.003) loss 0.6347 (0.7362) ce_loss 0.4331 (0.5303) teacher_loss 0.3246 (0.4146) loss_zs_kd 0.0955 (0.1004) loss_oracle 0.2624 (0.2715) acc 84.3750 (80.8929) kd_loss 0.8564 (0.8759) lr 1.8090e-03 eta 0:11:12
epoch [12/50] batch [160/160] time 0.078 (0.108) data 0.000 (0.002) loss 0.8976 (0.7366) ce_loss 0.6807 (0.5326) teacher_loss 0.5484 (0.4144) loss_zs_kd 0.0860 (0.1016) loss_oracle 0.3062 (0.2714) acc 78.1250 (80.7812) kd_loss 0.8417 (0.8757) lr 1.7705e-03 eta 0:10:57
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,834
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,987
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.1%, epoch: 10 *******
******* Domain p best val test acc: 88.2%, epoch: 10 *******
******* Domain p best test acc:     88.5%, epoch: 12 *******
epoch [13/50] batch [20/160] time 0.084 (0.106) data 0.000 (0.013) loss 0.5571 (0.7592) ce_loss 0.2556 (0.5403) teacher_loss 0.2740 (0.4264) loss_zs_kd 0.0741 (0.1122) loss_oracle 0.2461 (0.2767) acc 93.7500 (79.0625) kd_loss 0.7215 (0.8520) lr 1.7705e-03 eta 0:10:39
epoch [13/50] batch [40/160] time 0.081 (0.100) data 0.000 (0.007) loss 0.7237 (0.7551) ce_loss 0.4534 (0.5340) teacher_loss 0.3593 (0.4210) loss_zs_kd 0.0838 (0.1085) loss_oracle 0.3225 (0.2799) acc 84.3750 (79.9219) kd_loss 0.8746 (0.8547) lr 1.7705e-03 eta 0:10:06
epoch [13/50] batch [60/160] time 0.094 (0.102) data 0.001 (0.005) loss 0.9692 (0.7574) ce_loss 0.6338 (0.5333) teacher_loss 0.5968 (0.4168) loss_zs_kd 0.0782 (0.1072) loss_oracle 0.3333 (0.2870) acc 75.0000 (80.0521) kd_loss 0.9211 (0.8595) lr 1.7705e-03 eta 0:10:11
epoch [13/50] batch [80/160] time 0.091 (0.103) data 0.000 (0.003) loss 0.5759 (0.7592) ce_loss 0.3372 (0.5330) teacher_loss 0.2772 (0.4149) loss_zs_kd 0.1243 (0.1085) loss_oracle 0.2366 (0.2901) acc 84.3750 (80.0000) kd_loss 0.8877 (0.8624) lr 1.7705e-03 eta 0:10:18
epoch [13/50] batch [100/160] time 0.078 (0.102) data 0.000 (0.003) loss 0.6239 (0.7635) ce_loss 0.3384 (0.5339) teacher_loss 0.2900 (0.4173) loss_zs_kd 0.0692 (0.1084) loss_oracle 0.2993 (0.2921) acc 87.5000 (80.2500) kd_loss 0.8624 (0.8635) lr 1.7705e-03 eta 0:10:08
epoch [13/50] batch [120/160] time 0.077 (0.099) data 0.000 (0.002) loss 0.6708 (0.7649) ce_loss 0.4888 (0.5324) teacher_loss 0.3466 (0.4171) loss_zs_kd 0.0819 (0.1063) loss_oracle 0.2833 (0.2947) acc 81.2500 (80.4167) kd_loss 0.8390 (0.8630) lr 1.7705e-03 eta 0:09:51
epoch [13/50] batch [140/160] time 0.116 (0.098) data 0.000 (0.002) loss 0.6196 (0.7617) ce_loss 0.4866 (0.5287) teacher_loss 0.3321 (0.4114) loss_zs_kd 0.0830 (0.1059) loss_oracle 0.2460 (0.2973) acc 81.2500 (80.6250) kd_loss 0.8438 (0.8614) lr 1.7705e-03 eta 0:09:44
epoch [13/50] batch [160/160] time 0.074 (0.097) data 0.000 (0.002) loss 0.9302 (0.7633) ce_loss 0.6914 (0.5265) teacher_loss 0.5797 (0.4114) loss_zs_kd 0.0861 (0.1048) loss_oracle 0.3075 (0.2995) acc 71.8750 (80.6641) kd_loss 0.8584 (0.8597) lr 1.7290e-03 eta 0:09:34
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.4%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,985
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.3%
******* Domain p best val acc:      83.5%, epoch: 13 *******
******* Domain p best val test acc: 88.4%, epoch: 13 *******
******* Domain p best test acc:     88.5%, epoch: 12 *******
epoch [14/50] batch [20/160] time 0.064 (0.122) data 0.000 (0.013) loss 0.7272 (0.7604) ce_loss 0.4258 (0.5257) teacher_loss 0.3134 (0.4016) loss_zs_kd 0.0971 (0.0996) loss_oracle 0.3653 (0.3091) acc 87.5000 (78.7500) kd_loss 0.8752 (0.8547) lr 1.7290e-03 eta 0:11:58
epoch [14/50] batch [40/160] time 0.108 (0.125) data 0.000 (0.007) loss 0.7591 (0.7656) ce_loss 0.5342 (0.5362) teacher_loss 0.4771 (0.4144) loss_zs_kd 0.1057 (0.0947) loss_oracle 0.2292 (0.3039) acc 78.1250 (79.2969) kd_loss 0.8308 (0.8578) lr 1.7290e-03 eta 0:12:16
epoch [14/50] batch [60/160] time 0.114 (0.123) data 0.001 (0.005) loss 0.6269 (0.7479) ce_loss 0.4163 (0.5220) teacher_loss 0.2689 (0.4019) loss_zs_kd 0.0755 (0.0958) loss_oracle 0.3202 (0.2980) acc 84.3750 (79.9479) kd_loss 0.8883 (0.8495) lr 1.7290e-03 eta 0:12:00
epoch [14/50] batch [80/160] time 0.071 (0.123) data 0.001 (0.004) loss 0.9331 (0.7656) ce_loss 0.6938 (0.5421) teacher_loss 0.6409 (0.4211) loss_zs_kd 0.0865 (0.0987) loss_oracle 0.2489 (0.2952) acc 68.7500 (79.0625) kd_loss 0.8973 (0.8488) lr 1.7290e-03 eta 0:11:58
epoch [14/50] batch [100/160] time 0.094 (0.117) data 0.000 (0.003) loss 0.7911 (0.7644) ce_loss 0.5376 (0.5362) teacher_loss 0.4717 (0.4171) loss_zs_kd 0.0990 (0.0997) loss_oracle 0.2700 (0.2974) acc 71.8750 (79.4688) kd_loss 0.8596 (0.8480) lr 1.7290e-03 eta 0:11:18
epoch [14/50] batch [120/160] time 0.092 (0.112) data 0.000 (0.002) loss 0.8489 (0.7636) ce_loss 0.5620 (0.5306) teacher_loss 0.4604 (0.4169) loss_zs_kd 0.1040 (0.1007) loss_oracle 0.3366 (0.2964) acc 81.2500 (79.9479) kd_loss 0.8860 (0.8468) lr 1.7290e-03 eta 0:10:49
epoch [14/50] batch [140/160] time 0.115 (0.109) data 0.000 (0.002) loss 0.6962 (0.7582) ce_loss 0.4814 (0.5278) teacher_loss 0.3781 (0.4104) loss_zs_kd 0.1077 (0.1013) loss_oracle 0.2642 (0.2971) acc 84.3750 (79.9330) kd_loss 0.7872 (0.8471) lr 1.7290e-03 eta 0:10:29
epoch [14/50] batch [160/160] time 0.078 (0.106) data 0.000 (0.002) loss 0.5375 (0.7553) ce_loss 0.2781 (0.5255) teacher_loss 0.2486 (0.4078) loss_zs_kd 0.0732 (0.1024) loss_oracle 0.2523 (0.2963) acc 87.5000 (80.0000) kd_loss 0.8024 (0.8464) lr 1.6845e-03 eta 0:10:11
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,829
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,007
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 89.7%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.5%, epoch: 13 *******
******* Domain p best val test acc: 88.4%, epoch: 13 *******
******* Domain p best test acc:     89.1%, epoch: 14 *******
epoch [15/50] batch [20/160] time 0.070 (0.108) data 0.000 (0.015) loss 0.7255 (0.7519) ce_loss 0.4424 (0.4962) teacher_loss 0.3853 (0.4013) loss_zs_kd 0.1279 (0.0994) loss_oracle 0.2763 (0.3009) acc 81.2500 (80.7812) kd_loss 0.8606 (0.8536) lr 1.6845e-03 eta 0:10:17
epoch [15/50] batch [40/160] time 0.076 (0.098) data 0.000 (0.008) loss 0.7507 (0.7638) ce_loss 0.5068 (0.5174) teacher_loss 0.3024 (0.4121) loss_zs_kd 0.1324 (0.0993) loss_oracle 0.3821 (0.3020) acc 81.2500 (80.8594) kd_loss 0.8633 (0.8462) lr 1.6845e-03 eta 0:09:21
epoch [15/50] batch [60/160] time 0.098 (0.095) data 0.000 (0.005) loss 0.8136 (0.7530) ce_loss 0.5146 (0.5075) teacher_loss 0.4537 (0.3990) loss_zs_kd 0.1422 (0.1007) loss_oracle 0.2887 (0.3036) acc 90.6250 (80.5208) kd_loss 0.8766 (0.8438) lr 1.6845e-03 eta 0:09:01
epoch [15/50] batch [80/160] time 0.102 (0.093) data 0.000 (0.004) loss 0.8492 (0.7582) ce_loss 0.5479 (0.5135) teacher_loss 0.4593 (0.4027) loss_zs_kd 0.1032 (0.1029) loss_oracle 0.3383 (0.3040) acc 78.1250 (80.3125) kd_loss 0.8021 (0.8407) lr 1.6845e-03 eta 0:08:46
epoch [15/50] batch [100/160] time 0.087 (0.091) data 0.000 (0.003) loss 0.6495 (0.7592) ce_loss 0.5298 (0.5111) teacher_loss 0.3110 (0.4003) loss_zs_kd 0.1125 (0.1014) loss_oracle 0.2822 (0.3082) acc 78.1250 (80.5312) kd_loss 0.8208 (0.8379) lr 1.6845e-03 eta 0:08:35
epoch [15/50] batch [120/160] time 0.094 (0.090) data 0.000 (0.003) loss 0.6953 (0.7587) ce_loss 0.3804 (0.5126) teacher_loss 0.3367 (0.4012) loss_zs_kd 0.1217 (0.1035) loss_oracle 0.2977 (0.3057) acc 84.3750 (80.6250) kd_loss 0.8550 (0.8351) lr 1.6845e-03 eta 0:08:27
epoch [15/50] batch [140/160] time 0.084 (0.090) data 0.000 (0.002) loss 0.7795 (0.7556) ce_loss 0.5884 (0.5140) teacher_loss 0.4352 (0.4029) loss_zs_kd 0.1141 (0.1028) loss_oracle 0.2873 (0.3014) acc 84.3750 (80.7812) kd_loss 0.8019 (0.8331) lr 1.6845e-03 eta 0:08:23
epoch [15/50] batch [160/160] time 0.077 (0.089) data 0.000 (0.002) loss 0.8619 (0.7644) ce_loss 0.5669 (0.5241) teacher_loss 0.4948 (0.4140) loss_zs_kd 0.0980 (0.1030) loss_oracle 0.3181 (0.2990) acc 78.1250 (80.4688) kd_loss 0.8245 (0.8293) lr 1.6374e-03 eta 0:08:18
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,842
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.4%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,013
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 89.9%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.5%, epoch: 15 *******
******* Domain p best val test acc: 89.2%, epoch: 15 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [16/50] batch [20/160] time 0.083 (0.111) data 0.000 (0.015) loss 0.7073 (0.7526) ce_loss 0.5278 (0.5153) teacher_loss 0.3492 (0.3987) loss_zs_kd 0.0876 (0.1024) loss_oracle 0.3143 (0.3027) acc 81.2500 (80.7812) kd_loss 0.7634 (0.8308) lr 1.6374e-03 eta 0:10:17
epoch [16/50] batch [40/160] time 0.090 (0.109) data 0.000 (0.008) loss 0.6213 (0.7392) ce_loss 0.3828 (0.5173) teacher_loss 0.2416 (0.3934) loss_zs_kd 0.0404 (0.0966) loss_oracle 0.3595 (0.2975) acc 84.3750 (81.3281) kd_loss 0.8853 (0.8210) lr 1.6374e-03 eta 0:10:06
epoch [16/50] batch [60/160] time 0.090 (0.104) data 0.001 (0.005) loss 0.6497 (0.7335) ce_loss 0.4263 (0.5077) teacher_loss 0.2975 (0.3856) loss_zs_kd 0.0702 (0.1000) loss_oracle 0.3171 (0.2979) acc 87.5000 (81.1458) kd_loss 0.8708 (0.8233) lr 1.6374e-03 eta 0:09:34
epoch [16/50] batch [80/160] time 0.109 (0.101) data 0.000 (0.004) loss 0.8047 (0.7304) ce_loss 0.4651 (0.5088) teacher_loss 0.4452 (0.3856) loss_zs_kd 0.1108 (0.1008) loss_oracle 0.3041 (0.2944) acc 81.2500 (81.1719) kd_loss 0.8270 (0.8252) lr 1.6374e-03 eta 0:09:20
epoch [16/50] batch [100/160] time 0.130 (0.101) data 0.000 (0.003) loss 0.7123 (0.7367) ce_loss 0.4890 (0.5123) teacher_loss 0.3684 (0.3966) loss_zs_kd 0.1348 (0.1035) loss_oracle 0.2765 (0.2884) acc 78.1250 (81.0938) kd_loss 0.8133 (0.8224) lr 1.6374e-03 eta 0:09:14
epoch [16/50] batch [120/160] time 0.115 (0.101) data 0.000 (0.003) loss 0.6141 (0.7392) ce_loss 0.4988 (0.5171) teacher_loss 0.3296 (0.4054) loss_zs_kd 0.0967 (0.1023) loss_oracle 0.2362 (0.2827) acc 84.3750 (80.8854) kd_loss 0.8220 (0.8198) lr 1.6374e-03 eta 0:09:15
epoch [16/50] batch [140/160] time 0.133 (0.103) data 0.000 (0.002) loss 1.1214 (0.7424) ce_loss 0.9868 (0.5184) teacher_loss 0.7151 (0.4076) loss_zs_kd 0.1113 (0.1024) loss_oracle 0.3507 (0.2836) acc 59.3750 (80.8259) kd_loss 0.8177 (0.8197) lr 1.6374e-03 eta 0:09:20
epoch [16/50] batch [160/160] time 0.126 (0.104) data 0.000 (0.002) loss 0.6410 (0.7433) ce_loss 0.3374 (0.5184) teacher_loss 0.2908 (0.4110) loss_zs_kd 0.0700 (0.1022) loss_oracle 0.3152 (0.2812) acc 90.6250 (80.9570) kd_loss 0.8001 (0.8171) lr 1.5878e-03 eta 0:09:27
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,832
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,987
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.4%
******* Domain p best val acc:      83.5%, epoch: 15 *******
******* Domain p best val test acc: 89.2%, epoch: 15 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [17/50] batch [20/160] time 0.100 (0.121) data 0.000 (0.015) loss 0.7082 (0.7018) ce_loss 0.5371 (0.4837) teacher_loss 0.4202 (0.3875) loss_zs_kd 0.0991 (0.0924) loss_oracle 0.2384 (0.2682) acc 75.0000 (82.1875) kd_loss 0.8269 (0.8021) lr 1.5878e-03 eta 0:10:54
epoch [17/50] batch [40/160] time 0.130 (0.114) data 0.000 (0.007) loss 0.5714 (0.6979) ce_loss 0.3896 (0.4809) teacher_loss 0.2627 (0.3820) loss_zs_kd 0.0948 (0.0973) loss_oracle 0.2613 (0.2673) acc 87.5000 (82.4219) kd_loss 0.7926 (0.8017) lr 1.5878e-03 eta 0:10:14
epoch [17/50] batch [60/160] time 0.136 (0.113) data 0.000 (0.005) loss 0.7327 (0.7093) ce_loss 0.4475 (0.4909) teacher_loss 0.3227 (0.3887) loss_zs_kd 0.1165 (0.0962) loss_oracle 0.3517 (0.2725) acc 81.2500 (82.0312) kd_loss 0.8207 (0.8001) lr 1.5878e-03 eta 0:10:05
epoch [17/50] batch [80/160] time 0.117 (0.111) data 0.000 (0.004) loss 0.9838 (0.7255) ce_loss 0.7676 (0.5078) teacher_loss 0.6290 (0.3997) loss_zs_kd 0.0907 (0.0991) loss_oracle 0.3095 (0.2763) acc 65.6250 (80.7422) kd_loss 0.8166 (0.8023) lr 1.5878e-03 eta 0:09:52
epoch [17/50] batch [100/160] time 0.089 (0.111) data 0.000 (0.003) loss 0.8851 (0.7286) ce_loss 0.5894 (0.5110) teacher_loss 0.5210 (0.3990) loss_zs_kd 0.1101 (0.1015) loss_oracle 0.3090 (0.2788) acc 75.0000 (80.4688) kd_loss 0.7960 (0.7998) lr 1.5878e-03 eta 0:09:52
epoch [17/50] batch [120/160] time 0.079 (0.108) data 0.000 (0.003) loss 0.9114 (0.7337) ce_loss 0.6147 (0.5124) teacher_loss 0.5502 (0.4027) loss_zs_kd 0.1025 (0.1021) loss_oracle 0.3099 (0.2800) acc 81.2500 (80.8854) kd_loss 0.7870 (0.8014) lr 1.5878e-03 eta 0:09:33
epoch [17/50] batch [140/160] time 0.078 (0.105) data 0.000 (0.002) loss 0.8739 (0.7421) ce_loss 0.5947 (0.5199) teacher_loss 0.4613 (0.4067) loss_zs_kd 0.0981 (0.1030) loss_oracle 0.3635 (0.2840) acc 75.0000 (80.7143) kd_loss 0.8110 (0.8006) lr 1.5878e-03 eta 0:09:14
epoch [17/50] batch [160/160] time 0.071 (0.102) data 0.000 (0.002) loss 0.8618 (0.7479) ce_loss 0.5913 (0.5176) teacher_loss 0.5261 (0.4045) loss_zs_kd 0.0815 (0.1042) loss_oracle 0.2949 (0.2913) acc 81.2500 (80.9375) kd_loss 0.8002 (0.8045) lr 1.5358e-03 eta 0:08:59
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,838
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,980
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 89.3%
******* Domain p best val acc:      83.5%, epoch: 15 *******
******* Domain p best val test acc: 89.2%, epoch: 15 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [18/50] batch [20/160] time 0.077 (0.108) data 0.000 (0.013) loss 0.8935 (0.8076) ce_loss 0.5825 (0.5604) teacher_loss 0.4595 (0.4433) loss_zs_kd 0.1156 (0.1109) loss_oracle 0.3762 (0.3089) acc 78.1250 (78.9062) kd_loss 0.8712 (0.8089) lr 1.5358e-03 eta 0:09:25
epoch [18/50] batch [40/160] time 0.075 (0.100) data 0.000 (0.006) loss 0.8537 (0.7794) ce_loss 0.6411 (0.5184) teacher_loss 0.4743 (0.4037) loss_zs_kd 0.1241 (0.1159) loss_oracle 0.3173 (0.3178) acc 75.0000 (79.9219) kd_loss 0.7829 (0.8074) lr 1.5358e-03 eta 0:08:44
epoch [18/50] batch [60/160] time 0.071 (0.099) data 0.001 (0.004) loss 0.9195 (0.7629) ce_loss 0.6465 (0.4980) teacher_loss 0.5248 (0.3927) loss_zs_kd 0.0905 (0.1090) loss_oracle 0.3495 (0.3157) acc 78.1250 (81.5104) kd_loss 0.8054 (0.8033) lr 1.5358e-03 eta 0:08:37
epoch [18/50] batch [80/160] time 0.127 (0.100) data 0.000 (0.003) loss 0.6835 (0.7606) ce_loss 0.3726 (0.4967) teacher_loss 0.3393 (0.3900) loss_zs_kd 0.1488 (0.1086) loss_oracle 0.2698 (0.3163) acc 87.5000 (81.7188) kd_loss 0.7376 (0.8037) lr 1.5358e-03 eta 0:08:40
epoch [18/50] batch [100/160] time 0.106 (0.101) data 0.000 (0.003) loss 0.9876 (0.7545) ce_loss 0.8037 (0.4968) teacher_loss 0.6824 (0.3917) loss_zs_kd 0.0927 (0.1080) loss_oracle 0.2589 (0.3088) acc 81.2500 (81.6250) kd_loss 0.7758 (0.7988) lr 1.5358e-03 eta 0:08:43
epoch [18/50] batch [120/160] time 0.069 (0.101) data 0.000 (0.002) loss 0.7420 (0.7582) ce_loss 0.4619 (0.5052) teacher_loss 0.4237 (0.3993) loss_zs_kd 0.1325 (0.1069) loss_oracle 0.2521 (0.3055) acc 81.2500 (81.1719) kd_loss 0.7838 (0.7948) lr 1.5358e-03 eta 0:08:42
epoch [18/50] batch [140/160] time 0.084 (0.101) data 0.000 (0.002) loss 0.8967 (0.7549) ce_loss 0.7002 (0.5024) teacher_loss 0.6589 (0.3959) loss_zs_kd 0.0911 (0.1057) loss_oracle 0.1922 (0.3062) acc 65.6250 (81.1830) kd_loss 0.7321 (0.7940) lr 1.5358e-03 eta 0:08:39
epoch [18/50] batch [160/160] time 0.092 (0.100) data 0.000 (0.002) loss 1.0842 (0.7557) ce_loss 0.8267 (0.5031) teacher_loss 0.7107 (0.3964) loss_zs_kd 0.1180 (0.1053) loss_oracle 0.3145 (0.3066) acc 71.8750 (81.0547) kd_loss 0.7970 (0.7949) lr 1.4818e-03 eta 0:08:29
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,844
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 84.9%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,978
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 89.2%
******* Domain p best val acc:      83.6%, epoch: 18 *******
******* Domain p best val test acc: 88.2%, epoch: 18 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [19/50] batch [20/160] time 0.079 (0.128) data 0.000 (0.014) loss 0.7424 (0.7643) ce_loss 0.5005 (0.4882) teacher_loss 0.3571 (0.3907) loss_zs_kd 0.1277 (0.1044) loss_oracle 0.3214 (0.3213) acc 71.8750 (82.0312) kd_loss 0.8776 (0.7926) lr 1.4818e-03 eta 0:10:54
epoch [19/50] batch [40/160] time 0.146 (0.110) data 0.000 (0.007) loss 0.9367 (0.7764) ce_loss 0.7261 (0.5140) teacher_loss 0.4735 (0.4017) loss_zs_kd 0.1339 (0.1085) loss_oracle 0.3963 (0.3205) acc 71.8750 (81.1719) kd_loss 0.7830 (0.7898) lr 1.4818e-03 eta 0:09:20
epoch [19/50] batch [60/160] time 0.153 (0.121) data 0.001 (0.005) loss 0.6077 (0.7811) ce_loss 0.3694 (0.5234) teacher_loss 0.2852 (0.4103) loss_zs_kd 0.0997 (0.1066) loss_oracle 0.2726 (0.3175) acc 87.5000 (80.2604) kd_loss 0.7350 (0.7846) lr 1.4818e-03 eta 0:10:14
epoch [19/50] batch [80/160] time 0.153 (0.120) data 0.000 (0.004) loss 0.8966 (0.7705) ce_loss 0.7588 (0.5094) teacher_loss 0.5394 (0.4048) loss_zs_kd 0.0852 (0.1070) loss_oracle 0.3147 (0.3122) acc 78.1250 (80.4688) kd_loss 0.7604 (0.7823) lr 1.4818e-03 eta 0:10:04
epoch [19/50] batch [100/160] time 0.135 (0.118) data 0.000 (0.003) loss 0.7067 (0.7843) ce_loss 0.5986 (0.5259) teacher_loss 0.3898 (0.4189) loss_zs_kd 0.1417 (0.1062) loss_oracle 0.2461 (0.3122) acc 71.8750 (80.4062) kd_loss 0.7882 (0.7814) lr 1.4818e-03 eta 0:09:51
epoch [19/50] batch [120/160] time 0.101 (0.116) data 0.000 (0.003) loss 0.8732 (0.7750) ce_loss 0.6538 (0.5198) teacher_loss 0.4842 (0.4148) loss_zs_kd 0.1619 (0.1059) loss_oracle 0.3080 (0.3073) acc 75.0000 (80.9375) kd_loss 0.7821 (0.7791) lr 1.4818e-03 eta 0:09:41
epoch [19/50] batch [140/160] time 0.133 (0.114) data 0.001 (0.002) loss 0.5807 (0.7707) ce_loss 0.4712 (0.5193) teacher_loss 0.3213 (0.4135) loss_zs_kd 0.0838 (0.1044) loss_oracle 0.2175 (0.3050) acc 81.2500 (81.1607) kd_loss 0.7400 (0.7773) lr 1.4818e-03 eta 0:09:29
epoch [19/50] batch [160/160] time 0.080 (0.111) data 0.000 (0.002) loss 0.7667 (0.7666) ce_loss 0.4836 (0.5182) teacher_loss 0.4518 (0.4107) loss_zs_kd 0.1232 (0.1050) loss_oracle 0.2533 (0.3034) acc 81.2500 (80.9961) kd_loss 0.7419 (0.7762) lr 1.4258e-03 eta 0:09:11
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,838
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,983
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.3%
******* Domain p best val acc:      83.6%, epoch: 18 *******
******* Domain p best val test acc: 88.2%, epoch: 18 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [20/50] batch [20/160] time 0.077 (0.107) data 0.000 (0.015) loss 0.7851 (0.7576) ce_loss 0.5684 (0.5148) teacher_loss 0.4885 (0.4110) loss_zs_kd 0.0804 (0.1051) loss_oracle 0.2564 (0.2941) acc 81.2500 (81.5625) kd_loss 0.7409 (0.7818) lr 1.4258e-03 eta 0:08:48
epoch [20/50] batch [40/160] time 0.077 (0.096) data 0.000 (0.008) loss 0.8682 (0.7565) ce_loss 0.5889 (0.5072) teacher_loss 0.5474 (0.4159) loss_zs_kd 0.0762 (0.0975) loss_oracle 0.2827 (0.2919) acc 75.0000 (81.4844) kd_loss 0.7459 (0.7753) lr 1.4258e-03 eta 0:07:54
epoch [20/50] batch [60/160] time 0.130 (0.098) data 0.000 (0.005) loss 0.7218 (0.7504) ce_loss 0.5405 (0.5031) teacher_loss 0.4221 (0.4130) loss_zs_kd 0.0843 (0.0965) loss_oracle 0.2576 (0.2892) acc 81.2500 (81.4062) kd_loss 0.7274 (0.7703) lr 1.4258e-03 eta 0:08:01
epoch [20/50] batch [80/160] time 0.110 (0.100) data 0.000 (0.004) loss 0.7673 (0.7564) ce_loss 0.5215 (0.5139) teacher_loss 0.4634 (0.4205) loss_zs_kd 0.0863 (0.0977) loss_oracle 0.2608 (0.2870) acc 87.5000 (81.3672) kd_loss 0.7034 (0.7655) lr 1.4258e-03 eta 0:08:06
epoch [20/50] batch [100/160] time 0.115 (0.100) data 0.000 (0.003) loss 0.7437 (0.7509) ce_loss 0.4585 (0.5139) teacher_loss 0.3544 (0.4181) loss_zs_kd 0.0976 (0.0966) loss_oracle 0.3405 (0.2844) acc 81.2500 (80.9688) kd_loss 0.7418 (0.7663) lr 1.4258e-03 eta 0:08:07
epoch [20/50] batch [120/160] time 0.110 (0.100) data 0.000 (0.003) loss 0.7383 (0.7546) ce_loss 0.4670 (0.5182) teacher_loss 0.4241 (0.4216) loss_zs_kd 0.1008 (0.0979) loss_oracle 0.2638 (0.2840) acc 90.6250 (81.2500) kd_loss 0.8002 (0.7670) lr 1.4258e-03 eta 0:08:05
epoch [20/50] batch [140/160] time 0.103 (0.099) data 0.000 (0.002) loss 0.6493 (0.7448) ce_loss 0.3115 (0.5069) teacher_loss 0.3118 (0.4112) loss_zs_kd 0.0781 (0.0997) loss_oracle 0.2984 (0.2837) acc 87.5000 (81.4955) kd_loss 0.7988 (0.7661) lr 1.4258e-03 eta 0:07:58
epoch [20/50] batch [160/160] time 0.105 (0.100) data 0.000 (0.002) loss 0.6643 (0.7439) ce_loss 0.4863 (0.5064) teacher_loss 0.3495 (0.4086) loss_zs_kd 0.0700 (0.1006) loss_oracle 0.2798 (0.2850) acc 87.5000 (81.5820) kd_loss 0.7530 (0.7644) lr 1.3681e-03 eta 0:07:58
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,842
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,981
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 89.3%
******* Domain p best val acc:      83.6%, epoch: 18 *******
******* Domain p best val test acc: 88.2%, epoch: 18 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [21/50] batch [20/160] time 0.086 (0.105) data 0.000 (0.015) loss 0.6506 (0.7089) ce_loss 0.4768 (0.4609) teacher_loss 0.3647 (0.3657) loss_zs_kd 0.1187 (0.1033) loss_oracle 0.2266 (0.2916) acc 78.1250 (83.4375) kd_loss 0.7372 (0.7648) lr 1.3681e-03 eta 0:08:23
epoch [21/50] batch [40/160] time 0.087 (0.096) data 0.001 (0.007) loss 0.6424 (0.7407) ce_loss 0.2695 (0.4775) teacher_loss 0.2457 (0.3888) loss_zs_kd 0.0759 (0.1009) loss_oracle 0.3587 (0.3014) acc 87.5000 (81.7188) kd_loss 0.7404 (0.7669) lr 1.3681e-03 eta 0:07:36
epoch [21/50] batch [60/160] time 0.095 (0.091) data 0.001 (0.005) loss 0.7586 (0.7559) ce_loss 0.5078 (0.4894) teacher_loss 0.3943 (0.3986) loss_zs_kd 0.1078 (0.0988) loss_oracle 0.3104 (0.3079) acc 75.0000 (81.6667) kd_loss 0.8161 (0.7695) lr 1.3681e-03 eta 0:07:11
epoch [21/50] batch [80/160] time 0.085 (0.090) data 0.000 (0.004) loss 0.7725 (0.7612) ce_loss 0.5239 (0.4933) teacher_loss 0.3990 (0.4015) loss_zs_kd 0.0897 (0.0998) loss_oracle 0.3287 (0.3097) acc 81.2500 (81.4844) kd_loss 0.6971 (0.7667) lr 1.3681e-03 eta 0:07:02
epoch [21/50] batch [100/160] time 0.078 (0.089) data 0.000 (0.003) loss 0.7254 (0.7568) ce_loss 0.4705 (0.4942) teacher_loss 0.3956 (0.4001) loss_zs_kd 0.1015 (0.1006) loss_oracle 0.2791 (0.3064) acc 90.6250 (81.7500) kd_loss 0.7110 (0.7646) lr 1.3681e-03 eta 0:06:59
epoch [21/50] batch [120/160] time 0.088 (0.088) data 0.001 (0.003) loss 0.7319 (0.7609) ce_loss 0.4844 (0.4977) teacher_loss 0.3680 (0.4024) loss_zs_kd 0.0934 (0.1001) loss_oracle 0.3172 (0.3084) acc 81.2500 (81.6146) kd_loss 0.7843 (0.7664) lr 1.3681e-03 eta 0:06:54
epoch [21/50] batch [140/160] time 0.093 (0.088) data 0.001 (0.002) loss 0.8987 (0.7625) ce_loss 0.6025 (0.5006) teacher_loss 0.4132 (0.4055) loss_zs_kd 0.1493 (0.1011) loss_oracle 0.4108 (0.3064) acc 81.2500 (81.4286) kd_loss 0.7538 (0.7639) lr 1.3681e-03 eta 0:06:50
epoch [21/50] batch [160/160] time 0.066 (0.087) data 0.000 (0.002) loss 0.7239 (0.7633) ce_loss 0.4485 (0.5045) teacher_loss 0.4521 (0.4098) loss_zs_kd 0.1041 (0.1008) loss_oracle 0.2198 (0.3031) acc 81.2500 (81.2305) kd_loss 0.7177 (0.7609) lr 1.3090e-03 eta 0:06:42
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,845
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 85.0%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,999
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 89.7%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 88.8%, epoch: 21 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [22/50] batch [20/160] time 0.066 (0.082) data 0.000 (0.015) loss 0.7468 (0.7485) ce_loss 0.5244 (0.5051) teacher_loss 0.3977 (0.4073) loss_zs_kd 0.1255 (0.0990) loss_oracle 0.2863 (0.2917) acc 78.1250 (83.4375) kd_loss 0.7472 (0.7562) lr 1.3090e-03 eta 0:06:18
epoch [22/50] batch [40/160] time 0.082 (0.091) data 0.000 (0.008) loss 0.6921 (0.7404) ce_loss 0.4041 (0.5127) teacher_loss 0.3048 (0.4143) loss_zs_kd 0.0849 (0.0970) loss_oracle 0.3448 (0.2776) acc 84.3750 (82.9688) kd_loss 0.7738 (0.7519) lr 1.3090e-03 eta 0:06:59
epoch [22/50] batch [60/160] time 0.084 (0.096) data 0.001 (0.005) loss 0.5171 (0.7410) ce_loss 0.2959 (0.5140) teacher_loss 0.2531 (0.4181) loss_zs_kd 0.0646 (0.0993) loss_oracle 0.2317 (0.2732) acc 90.6250 (82.4479) kd_loss 0.6803 (0.7506) lr 1.3090e-03 eta 0:07:18
epoch [22/50] batch [80/160] time 0.072 (0.097) data 0.000 (0.004) loss 0.6532 (0.7389) ce_loss 0.3611 (0.5112) teacher_loss 0.2858 (0.4105) loss_zs_kd 0.1632 (0.1016) loss_oracle 0.2858 (0.2776) acc 84.3750 (82.3047) kd_loss 0.7772 (0.7528) lr 1.3090e-03 eta 0:07:20
epoch [22/50] batch [100/160] time 0.133 (0.098) data 0.000 (0.003) loss 0.7704 (0.7359) ce_loss 0.6460 (0.5055) teacher_loss 0.4308 (0.4050) loss_zs_kd 0.0851 (0.1010) loss_oracle 0.2970 (0.2804) acc 75.0000 (82.1562) kd_loss 0.7575 (0.7563) lr 1.3090e-03 eta 0:07:27
epoch [22/50] batch [120/160] time 0.092 (0.099) data 0.000 (0.003) loss 0.7422 (0.7370) ce_loss 0.5376 (0.5039) teacher_loss 0.4214 (0.4035) loss_zs_kd 0.1049 (0.1011) loss_oracle 0.2683 (0.2830) acc 84.3750 (82.3177) kd_loss 0.7281 (0.7562) lr 1.3090e-03 eta 0:07:26
epoch [22/50] batch [140/160] time 0.126 (0.099) data 0.000 (0.002) loss 0.6556 (0.7371) ce_loss 0.3474 (0.5002) teacher_loss 0.3037 (0.4006) loss_zs_kd 0.1237 (0.1005) loss_oracle 0.2900 (0.2862) acc 87.5000 (82.3214) kd_loss 0.7028 (0.7583) lr 1.3090e-03 eta 0:07:27
epoch [22/50] batch [160/160] time 0.078 (0.098) data 0.000 (0.002) loss 0.8065 (0.7428) ce_loss 0.5176 (0.5002) teacher_loss 0.4528 (0.3997) loss_zs_kd 0.1040 (0.1021) loss_oracle 0.3017 (0.2921) acc 78.1250 (82.1289) kd_loss 0.7435 (0.7603) lr 1.2487e-03 eta 0:07:20
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,843
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,991
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 89.4%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 88.8%, epoch: 21 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [23/50] batch [20/160] time 0.084 (0.122) data 0.000 (0.012) loss 0.7836 (0.7432) ce_loss 0.4775 (0.4801) teacher_loss 0.3729 (0.3931) loss_zs_kd 0.1625 (0.0989) loss_oracle 0.3294 (0.3006) acc 90.6250 (82.6562) kd_loss 0.7697 (0.7689) lr 1.2487e-03 eta 0:09:05
epoch [23/50] batch [40/160] time 0.135 (0.116) data 0.000 (0.006) loss 0.7933 (0.7508) ce_loss 0.5161 (0.4906) teacher_loss 0.4758 (0.3899) loss_zs_kd 0.1296 (0.1003) loss_oracle 0.2527 (0.3108) acc 84.3750 (82.3438) kd_loss 0.7653 (0.7688) lr 1.2487e-03 eta 0:08:35
epoch [23/50] batch [60/160] time 0.084 (0.113) data 0.001 (0.004) loss 0.9078 (0.7594) ce_loss 0.6992 (0.5076) teacher_loss 0.5896 (0.4061) loss_zs_kd 0.0927 (0.1042) loss_oracle 0.2719 (0.3012) acc 65.6250 (81.1458) kd_loss 0.7525 (0.7611) lr 1.2487e-03 eta 0:08:21
epoch [23/50] batch [80/160] time 0.089 (0.113) data 0.000 (0.003) loss 0.8743 (0.7439) ce_loss 0.5527 (0.4929) teacher_loss 0.4619 (0.3911) loss_zs_kd 0.1404 (0.1030) loss_oracle 0.3422 (0.3013) acc 81.2500 (81.9922) kd_loss 0.7619 (0.7575) lr 1.2487e-03 eta 0:08:16
epoch [23/50] batch [100/160] time 0.135 (0.112) data 0.000 (0.003) loss 0.6858 (0.7534) ce_loss 0.5298 (0.5033) teacher_loss 0.3008 (0.3969) loss_zs_kd 0.1046 (0.1055) loss_oracle 0.3327 (0.3037) acc 81.2500 (81.5312) kd_loss 0.7647 (0.7599) lr 1.2487e-03 eta 0:08:10
epoch [23/50] batch [120/160] time 0.078 (0.110) data 0.000 (0.002) loss 0.7029 (0.7591) ce_loss 0.2974 (0.5065) teacher_loss 0.2297 (0.3967) loss_zs_kd 0.0861 (0.1085) loss_oracle 0.4302 (0.3082) acc 90.6250 (81.3021) kd_loss 0.8287 (0.7600) lr 1.2487e-03 eta 0:07:59
epoch [23/50] batch [140/160] time 0.084 (0.109) data 0.000 (0.002) loss 0.7948 (0.7610) ce_loss 0.4797 (0.5054) teacher_loss 0.3987 (0.3965) loss_zs_kd 0.1325 (0.1093) loss_oracle 0.3298 (0.3098) acc 75.0000 (81.1161) kd_loss 0.7629 (0.7604) lr 1.2487e-03 eta 0:07:50
epoch [23/50] batch [160/160] time 0.107 (0.106) data 0.000 (0.002) loss 0.7739 (0.7625) ce_loss 0.4668 (0.5015) teacher_loss 0.3599 (0.3942) loss_zs_kd 0.1060 (0.1099) loss_oracle 0.3609 (0.3134) acc 84.3750 (81.4258) kd_loss 0.8060 (0.7616) lr 1.1874e-03 eta 0:07:38
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,848
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.3%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,990
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [24/50] batch [20/160] time 0.089 (0.128) data 0.000 (0.017) loss 0.8570 (0.7832) ce_loss 0.5591 (0.5120) teacher_loss 0.5080 (0.4134) loss_zs_kd 0.0810 (0.1011) loss_oracle 0.3085 (0.3192) acc 84.3750 (80.4688) kd_loss 0.7115 (0.7589) lr 1.1874e-03 eta 0:09:08
epoch [24/50] batch [40/160] time 0.085 (0.118) data 0.000 (0.008) loss 0.8779 (0.7758) ce_loss 0.5396 (0.5094) teacher_loss 0.4463 (0.3973) loss_zs_kd 0.1121 (0.1051) loss_oracle 0.3756 (0.3259) acc 78.1250 (81.0156) kd_loss 0.8193 (0.7657) lr 1.1874e-03 eta 0:08:26
epoch [24/50] batch [60/160] time 0.089 (0.114) data 0.001 (0.006) loss 0.9330 (0.7729) ce_loss 0.6382 (0.5024) teacher_loss 0.4981 (0.3962) loss_zs_kd 0.0987 (0.1038) loss_oracle 0.3856 (0.3248) acc 87.5000 (81.5625) kd_loss 0.7663 (0.7611) lr 1.1874e-03 eta 0:08:05
epoch [24/50] batch [80/160] time 0.138 (0.116) data 0.000 (0.004) loss 0.9072 (0.7697) ce_loss 0.8115 (0.5022) teacher_loss 0.5270 (0.3957) loss_zs_kd 0.0964 (0.1009) loss_oracle 0.3320 (0.3236) acc 71.8750 (81.6016) kd_loss 0.7523 (0.7624) lr 1.1874e-03 eta 0:08:11
epoch [24/50] batch [100/160] time 0.079 (0.117) data 0.000 (0.004) loss 0.8268 (0.7734) ce_loss 0.5996 (0.5042) teacher_loss 0.4213 (0.4004) loss_zs_kd 0.1468 (0.1013) loss_oracle 0.3321 (0.3224) acc 71.8750 (81.6562) kd_loss 0.7255 (0.7617) lr 1.1874e-03 eta 0:08:14
epoch [24/50] batch [120/160] time 0.098 (0.120) data 0.000 (0.003) loss 0.8533 (0.7725) ce_loss 0.5571 (0.5043) teacher_loss 0.4627 (0.3997) loss_zs_kd 0.1119 (0.1024) loss_oracle 0.3346 (0.3216) acc 87.5000 (81.4062) kd_loss 0.7769 (0.7584) lr 1.1874e-03 eta 0:08:23
epoch [24/50] batch [140/160] time 0.097 (0.116) data 0.000 (0.003) loss 0.8847 (0.7774) ce_loss 0.6738 (0.5076) teacher_loss 0.5114 (0.4000) loss_zs_kd 0.1069 (0.1047) loss_oracle 0.3199 (0.3250) acc 75.0000 (81.3170) kd_loss 0.7457 (0.7611) lr 1.1874e-03 eta 0:08:04
epoch [24/50] batch [160/160] time 0.093 (0.113) data 0.000 (0.002) loss 0.8170 (0.7788) ce_loss 0.4451 (0.5025) teacher_loss 0.3644 (0.3961) loss_zs_kd 0.1073 (0.1077) loss_oracle 0.3990 (0.3288) acc 75.0000 (81.4648) kd_loss 0.7686 (0.7617) lr 1.1253e-03 eta 0:07:49
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,846
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,980
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [25/50] batch [20/160] time 0.132 (0.126) data 0.000 (0.016) loss 0.8224 (0.7679) ce_loss 0.5034 (0.4783) teacher_loss 0.4480 (0.3791) loss_zs_kd 0.0799 (0.1063) loss_oracle 0.3345 (0.3357) acc 84.3750 (82.6562) kd_loss 0.7939 (0.7604) lr 1.1253e-03 eta 0:08:43
epoch [25/50] batch [40/160] time 0.079 (0.119) data 0.000 (0.008) loss 0.7821 (0.7861) ce_loss 0.4480 (0.4812) teacher_loss 0.2753 (0.3809) loss_zs_kd 0.1119 (0.1051) loss_oracle 0.4509 (0.3527) acc 81.2500 (82.3438) kd_loss 0.7663 (0.7708) lr 1.1253e-03 eta 0:08:09
epoch [25/50] batch [60/160] time 0.137 (0.117) data 0.001 (0.005) loss 0.6170 (0.7865) ce_loss 0.2893 (0.4786) teacher_loss 0.2402 (0.3814) loss_zs_kd 0.0822 (0.1068) loss_oracle 0.3357 (0.3516) acc 90.6250 (82.5000) kd_loss 0.7956 (0.7716) lr 1.1253e-03 eta 0:07:59
epoch [25/50] batch [80/160] time 0.087 (0.116) data 0.000 (0.004) loss 0.7282 (0.7756) ce_loss 0.3623 (0.4658) teacher_loss 0.2824 (0.3675) loss_zs_kd 0.1315 (0.1079) loss_oracle 0.3800 (0.3542) acc 87.5000 (83.4375) kd_loss 0.8183 (0.7738) lr 1.1253e-03 eta 0:07:52
epoch [25/50] batch [100/160] time 0.078 (0.114) data 0.000 (0.003) loss 0.7682 (0.7878) ce_loss 0.5142 (0.4850) teacher_loss 0.3455 (0.3813) loss_zs_kd 0.1005 (0.1104) loss_oracle 0.3725 (0.3513) acc 81.2500 (82.4375) kd_loss 0.7279 (0.7695) lr 1.1253e-03 eta 0:07:44
epoch [25/50] batch [120/160] time 0.093 (0.114) data 0.000 (0.003) loss 0.8688 (0.7975) ce_loss 0.5693 (0.4960) teacher_loss 0.4834 (0.3893) loss_zs_kd 0.1215 (0.1130) loss_oracle 0.3247 (0.3517) acc 84.3750 (81.8490) kd_loss 0.7071 (0.7670) lr 1.1253e-03 eta 0:07:39
epoch [25/50] batch [140/160] time 0.086 (0.113) data 0.000 (0.002) loss 0.7210 (0.7983) ce_loss 0.4031 (0.4984) teacher_loss 0.3692 (0.3924) loss_zs_kd 0.0667 (0.1109) loss_oracle 0.3185 (0.3504) acc 84.3750 (81.7188) kd_loss 0.7219 (0.7678) lr 1.1253e-03 eta 0:07:34
epoch [25/50] batch [160/160] time 0.096 (0.112) data 0.000 (0.002) loss 0.7521 (0.7980) ce_loss 0.5806 (0.4992) teacher_loss 0.3854 (0.3910) loss_zs_kd 0.1012 (0.1112) loss_oracle 0.3161 (0.3515) acc 75.0000 (81.6602) kd_loss 0.7414 (0.7674) lr 1.0628e-03 eta 0:07:26
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,990
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 89.5%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [26/50] batch [20/160] time 0.109 (0.132) data 0.000 (0.015) loss 0.7820 (0.7969) ce_loss 0.4834 (0.5261) teacher_loss 0.3381 (0.4050) loss_zs_kd 0.1240 (0.1137) loss_oracle 0.3819 (0.3351) acc 78.1250 (78.4375) kd_loss 0.8262 (0.7604) lr 1.0628e-03 eta 0:08:46
epoch [26/50] batch [40/160] time 0.086 (0.119) data 0.000 (0.008) loss 0.9173 (0.8019) ce_loss 0.5679 (0.5276) teacher_loss 0.5015 (0.4062) loss_zs_kd 0.1140 (0.1141) loss_oracle 0.3588 (0.3387) acc 75.0000 (79.3750) kd_loss 0.7765 (0.7594) lr 1.0628e-03 eta 0:07:51
epoch [26/50] batch [60/160] time 0.118 (0.115) data 0.001 (0.005) loss 0.5883 (0.7990) ce_loss 0.4639 (0.5286) teacher_loss 0.2948 (0.4044) loss_zs_kd 0.1069 (0.1115) loss_oracle 0.2400 (0.3388) acc 78.1250 (79.4271) kd_loss 0.7204 (0.7587) lr 1.0628e-03 eta 0:07:33
epoch [26/50] batch [80/160] time 0.076 (0.112) data 0.000 (0.004) loss 0.7337 (0.7909) ce_loss 0.4766 (0.5151) teacher_loss 0.3685 (0.3966) loss_zs_kd 0.1395 (0.1129) loss_oracle 0.2954 (0.3379) acc 78.1250 (80.3906) kd_loss 0.8075 (0.7613) lr 1.0628e-03 eta 0:07:20
epoch [26/50] batch [100/160] time 0.090 (0.109) data 0.000 (0.003) loss 0.7815 (0.7829) ce_loss 0.3979 (0.5076) teacher_loss 0.3434 (0.3940) loss_zs_kd 0.0999 (0.1102) loss_oracle 0.3881 (0.3338) acc 81.2500 (80.9062) kd_loss 0.7932 (0.7587) lr 1.0628e-03 eta 0:07:06
epoch [26/50] batch [120/160] time 0.110 (0.109) data 0.000 (0.003) loss 0.8083 (0.7725) ce_loss 0.5835 (0.4950) teacher_loss 0.3893 (0.3823) loss_zs_kd 0.1509 (0.1122) loss_oracle 0.3435 (0.3341) acc 78.1250 (81.6667) kd_loss 0.7598 (0.7607) lr 1.0628e-03 eta 0:07:02
epoch [26/50] batch [140/160] time 0.129 (0.109) data 0.000 (0.002) loss 0.8660 (0.7717) ce_loss 0.5469 (0.4975) teacher_loss 0.4882 (0.3823) loss_zs_kd 0.1046 (0.1140) loss_oracle 0.3255 (0.3324) acc 81.2500 (81.6071) kd_loss 0.7414 (0.7597) lr 1.0628e-03 eta 0:06:59
epoch [26/50] batch [160/160] time 0.137 (0.107) data 0.000 (0.002) loss 0.7878 (0.7708) ce_loss 0.5815 (0.5004) teacher_loss 0.4083 (0.3855) loss_zs_kd 0.1231 (0.1142) loss_oracle 0.3179 (0.3282) acc 78.1250 (81.5820) kd_loss 0.6960 (0.7597) lr 1.0000e-03 eta 0:06:50
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,844
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,990
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [27/50] batch [20/160] time 0.099 (0.107) data 0.000 (0.013) loss 0.6225 (0.7197) ce_loss 0.2739 (0.4805) teacher_loss 0.2192 (0.3580) loss_zs_kd 0.1303 (0.1019) loss_oracle 0.3381 (0.3107) acc 96.8750 (82.6562) kd_loss 0.7775 (0.7666) lr 1.0000e-03 eta 0:06:50
epoch [27/50] batch [40/160] time 0.108 (0.104) data 0.000 (0.007) loss 0.8594 (0.7468) ce_loss 0.6089 (0.4887) teacher_loss 0.5453 (0.3778) loss_zs_kd 0.1195 (0.1054) loss_oracle 0.2543 (0.3162) acc 75.0000 (81.7969) kd_loss 0.7610 (0.7675) lr 1.0000e-03 eta 0:06:33
epoch [27/50] batch [60/160] time 0.085 (0.100) data 0.001 (0.005) loss 0.6128 (0.7556) ce_loss 0.2795 (0.4933) teacher_loss 0.1899 (0.3750) loss_zs_kd 0.1281 (0.1088) loss_oracle 0.3589 (0.3262) acc 90.6250 (81.6667) kd_loss 0.7238 (0.7714) lr 1.0000e-03 eta 0:06:19
epoch [27/50] batch [80/160] time 0.108 (0.099) data 0.000 (0.003) loss 0.7195 (0.7608) ce_loss 0.4583 (0.4924) teacher_loss 0.3607 (0.3791) loss_zs_kd 0.1034 (0.1080) loss_oracle 0.3071 (0.3277) acc 81.2500 (81.7188) kd_loss 0.7444 (0.7702) lr 1.0000e-03 eta 0:06:10
epoch [27/50] batch [100/160] time 0.087 (0.098) data 0.000 (0.003) loss 0.7513 (0.7662) ce_loss 0.4634 (0.5003) teacher_loss 0.3131 (0.3843) loss_zs_kd 0.1424 (0.1055) loss_oracle 0.3670 (0.3292) acc 81.2500 (81.4375) kd_loss 0.7718 (0.7707) lr 1.0000e-03 eta 0:06:07
epoch [27/50] batch [120/160] time 0.091 (0.096) data 0.000 (0.002) loss 0.6436 (0.7666) ce_loss 0.3838 (0.5014) teacher_loss 0.3278 (0.3836) loss_zs_kd 0.0966 (0.1081) loss_oracle 0.2675 (0.3290) acc 81.2500 (81.3802) kd_loss 0.7239 (0.7677) lr 1.0000e-03 eta 0:05:57
epoch [27/50] batch [140/160] time 0.087 (0.096) data 0.000 (0.002) loss 0.7488 (0.7700) ce_loss 0.4136 (0.5044) teacher_loss 0.2920 (0.3860) loss_zs_kd 0.1418 (0.1095) loss_oracle 0.3859 (0.3293) acc 87.5000 (81.4955) kd_loss 0.8093 (0.7668) lr 1.0000e-03 eta 0:05:54
epoch [27/50] batch [160/160] time 0.076 (0.094) data 0.000 (0.002) loss 1.0611 (0.7638) ce_loss 0.8569 (0.5004) teacher_loss 0.6864 (0.3830) loss_zs_kd 0.1319 (0.1102) loss_oracle 0.3088 (0.3257) acc 59.3750 (81.5430) kd_loss 0.7358 (0.7643) lr 9.3721e-04 eta 0:05:47
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,848
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,986
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [28/50] batch [20/160] time 0.106 (0.134) data 0.000 (0.013) loss 0.6005 (0.7496) ce_loss 0.3730 (0.4689) teacher_loss 0.3296 (0.3802) loss_zs_kd 0.0890 (0.1198) loss_oracle 0.2264 (0.3095) acc 84.3750 (82.6562) kd_loss 0.7536 (0.7470) lr 9.3721e-04 eta 0:08:11
epoch [28/50] batch [40/160] time 0.136 (0.122) data 0.000 (0.006) loss 0.7876 (0.7586) ce_loss 0.5298 (0.4897) teacher_loss 0.4271 (0.3823) loss_zs_kd 0.0972 (0.1133) loss_oracle 0.3119 (0.3197) acc 78.1250 (81.9531) kd_loss 0.7787 (0.7517) lr 9.3721e-04 eta 0:07:24
epoch [28/50] batch [60/160] time 0.122 (0.118) data 0.000 (0.004) loss 0.6799 (0.7647) ce_loss 0.2827 (0.4911) teacher_loss 0.1949 (0.3826) loss_zs_kd 0.1182 (0.1133) loss_oracle 0.4259 (0.3255) acc 90.6250 (81.7708) kd_loss 0.7962 (0.7508) lr 9.3721e-04 eta 0:07:06
epoch [28/50] batch [80/160] time 0.095 (0.113) data 0.000 (0.003) loss 0.7561 (0.7625) ce_loss 0.4297 (0.4869) teacher_loss 0.3621 (0.3814) loss_zs_kd 0.1109 (0.1136) loss_oracle 0.3385 (0.3243) acc 84.3750 (81.8750) kd_loss 0.7052 (0.7528) lr 9.3721e-04 eta 0:06:48
epoch [28/50] batch [100/160] time 0.123 (0.111) data 0.000 (0.003) loss 0.7299 (0.7662) ce_loss 0.4285 (0.4972) teacher_loss 0.3409 (0.3834) loss_zs_kd 0.1243 (0.1130) loss_oracle 0.3268 (0.3262) acc 81.2500 (81.6875) kd_loss 0.7058 (0.7511) lr 9.3721e-04 eta 0:06:36
epoch [28/50] batch [120/160] time 0.098 (0.110) data 0.000 (0.002) loss 0.8945 (0.7713) ce_loss 0.5132 (0.4992) teacher_loss 0.4979 (0.3855) loss_zs_kd 0.0879 (0.1126) loss_oracle 0.3527 (0.3295) acc 78.1250 (81.4583) kd_loss 0.8192 (0.7535) lr 9.3721e-04 eta 0:06:31
epoch [28/50] batch [140/160] time 0.109 (0.109) data 0.000 (0.002) loss 0.6713 (0.7716) ce_loss 0.4431 (0.4966) teacher_loss 0.2470 (0.3825) loss_zs_kd 0.1415 (0.1139) loss_oracle 0.3536 (0.3322) acc 84.3750 (81.7188) kd_loss 0.7866 (0.7546) lr 9.3721e-04 eta 0:06:25
epoch [28/50] batch [160/160] time 0.091 (0.107) data 0.000 (0.002) loss 0.7381 (0.7749) ce_loss 0.4399 (0.5007) teacher_loss 0.3139 (0.3858) loss_zs_kd 0.0869 (0.1138) loss_oracle 0.3807 (0.3322) acc 84.3750 (81.6211) kd_loss 0.8122 (0.7543) lr 8.7467e-04 eta 0:06:15
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,842
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,993
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [29/50] batch [20/160] time 0.088 (0.117) data 0.000 (0.016) loss 0.7648 (0.7811) ce_loss 0.5103 (0.5158) teacher_loss 0.3934 (0.3996) loss_zs_kd 0.1837 (0.1131) loss_oracle 0.2795 (0.3250) acc 78.1250 (80.0000) kd_loss 0.7107 (0.7384) lr 8.7467e-04 eta 0:06:48
epoch [29/50] batch [40/160] time 0.105 (0.110) data 0.000 (0.008) loss 0.8113 (0.7681) ce_loss 0.4788 (0.4926) teacher_loss 0.3686 (0.3772) loss_zs_kd 0.1007 (0.1137) loss_oracle 0.3923 (0.3341) acc 84.3750 (81.2500) kd_loss 0.8395 (0.7510) lr 8.7467e-04 eta 0:06:22
epoch [29/50] batch [60/160] time 0.132 (0.111) data 0.001 (0.006) loss 0.7749 (0.7507) ce_loss 0.5327 (0.4770) teacher_loss 0.4261 (0.3620) loss_zs_kd 0.0971 (0.1128) loss_oracle 0.3003 (0.3323) acc 75.0000 (82.1875) kd_loss 0.7965 (0.7520) lr 8.7467e-04 eta 0:06:23
epoch [29/50] batch [80/160] time 0.141 (0.112) data 0.000 (0.004) loss 0.7044 (0.7516) ce_loss 0.3367 (0.4803) teacher_loss 0.2247 (0.3659) loss_zs_kd 0.0914 (0.1122) loss_oracle 0.4340 (0.3295) acc 87.5000 (82.1094) kd_loss 0.8584 (0.7537) lr 8.7467e-04 eta 0:06:26
epoch [29/50] batch [100/160] time 0.080 (0.116) data 0.000 (0.003) loss 0.8650 (0.7576) ce_loss 0.5645 (0.4860) teacher_loss 0.4430 (0.3712) loss_zs_kd 0.1317 (0.1124) loss_oracle 0.3562 (0.3302) acc 78.1250 (82.0625) kd_loss 0.7886 (0.7561) lr 8.7467e-04 eta 0:06:37
epoch [29/50] batch [120/160] time 0.152 (0.119) data 0.000 (0.003) loss 0.8534 (0.7709) ce_loss 0.5352 (0.4938) teacher_loss 0.5014 (0.3782) loss_zs_kd 0.1428 (0.1146) loss_oracle 0.2806 (0.3354) acc 78.1250 (81.4323) kd_loss 0.6828 (0.7591) lr 8.7467e-04 eta 0:06:45
epoch [29/50] batch [140/160] time 0.083 (0.117) data 0.000 (0.003) loss 0.9746 (0.7777) ce_loss 0.6880 (0.4999) teacher_loss 0.5795 (0.3839) loss_zs_kd 0.0943 (0.1148) loss_oracle 0.3479 (0.3363) acc 78.1250 (81.2277) kd_loss 0.7724 (0.7593) lr 8.7467e-04 eta 0:06:35
epoch [29/50] batch [160/160] time 0.095 (0.114) data 0.000 (0.002) loss 0.7940 (0.7804) ce_loss 0.4773 (0.5008) teacher_loss 0.3613 (0.3843) loss_zs_kd 0.1099 (0.1146) loss_oracle 0.3778 (0.3388) acc 78.1250 (81.2695) kd_loss 0.7876 (0.7607) lr 8.1262e-04 eta 0:06:24
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,843
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,986
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [30/50] batch [20/160] time 0.077 (0.113) data 0.000 (0.014) loss 0.9963 (0.8059) ce_loss 0.6523 (0.5401) teacher_loss 0.5359 (0.3983) loss_zs_kd 0.1500 (0.1150) loss_oracle 0.3854 (0.3501) acc 75.0000 (79.6875) kd_loss 0.8095 (0.7604) lr 8.1262e-04 eta 0:06:17
epoch [30/50] batch [40/160] time 0.143 (0.108) data 0.000 (0.007) loss 0.8737 (0.7863) ce_loss 0.5518 (0.4930) teacher_loss 0.4429 (0.3696) loss_zs_kd 0.1096 (0.1181) loss_oracle 0.3760 (0.3576) acc 75.0000 (82.1094) kd_loss 0.8569 (0.7743) lr 8.1262e-04 eta 0:05:58
epoch [30/50] batch [60/160] time 0.077 (0.105) data 0.000 (0.005) loss 0.6849 (0.7819) ce_loss 0.3955 (0.4959) teacher_loss 0.2330 (0.3713) loss_zs_kd 0.0985 (0.1178) loss_oracle 0.4027 (0.3517) acc 90.6250 (82.5000) kd_loss 0.8106 (0.7701) lr 8.1262e-04 eta 0:05:46
epoch [30/50] batch [80/160] time 0.111 (0.105) data 0.001 (0.004) loss 0.9543 (0.7939) ce_loss 0.6631 (0.5073) teacher_loss 0.4657 (0.3840) loss_zs_kd 0.1420 (0.1194) loss_oracle 0.4176 (0.3502) acc 68.7500 (81.9531) kd_loss 0.7859 (0.7645) lr 8.1262e-04 eta 0:05:45
epoch [30/50] batch [100/160] time 0.127 (0.105) data 0.000 (0.003) loss 0.7405 (0.7917) ce_loss 0.4531 (0.5007) teacher_loss 0.3705 (0.3801) loss_zs_kd 0.1346 (0.1202) loss_oracle 0.3027 (0.3515) acc 81.2500 (81.7500) kd_loss 0.8204 (0.7675) lr 8.1262e-04 eta 0:05:43
epoch [30/50] batch [120/160] time 0.094 (0.105) data 0.000 (0.003) loss 0.5954 (0.7894) ce_loss 0.2629 (0.4965) teacher_loss 0.2049 (0.3771) loss_zs_kd 0.0991 (0.1208) loss_oracle 0.3410 (0.3518) acc 93.7500 (81.9531) kd_loss 0.6806 (0.7670) lr 8.1262e-04 eta 0:05:40
epoch [30/50] batch [140/160] time 0.085 (0.104) data 0.000 (0.002) loss 0.7854 (0.7907) ce_loss 0.5444 (0.4959) teacher_loss 0.3680 (0.3757) loss_zs_kd 0.1308 (0.1213) loss_oracle 0.3520 (0.3542) acc 84.3750 (81.9196) kd_loss 0.7822 (0.7695) lr 8.1262e-04 eta 0:05:36
epoch [30/50] batch [160/160] time 0.071 (0.103) data 0.000 (0.002) loss 0.9077 (0.7929) ce_loss 0.7515 (0.5002) teacher_loss 0.5190 (0.3786) loss_zs_kd 0.1177 (0.1219) loss_oracle 0.3299 (0.3534) acc 71.8750 (81.6992) kd_loss 0.7540 (0.7698) lr 7.5131e-04 eta 0:05:28
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,843
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,988
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [31/50] batch [20/160] time 0.106 (0.117) data 0.000 (0.015) loss 1.0167 (0.7761) ce_loss 0.7397 (0.4998) teacher_loss 0.5665 (0.3596) loss_zs_kd 0.1552 (0.1166) loss_oracle 0.3726 (0.3582) acc 81.2500 (83.2812) kd_loss 0.7656 (0.7756) lr 7.5131e-04 eta 0:06:12
epoch [31/50] batch [40/160] time 0.094 (0.107) data 0.000 (0.007) loss 0.7246 (0.8169) ce_loss 0.4109 (0.5265) teacher_loss 0.2853 (0.3933) loss_zs_kd 0.1301 (0.1267) loss_oracle 0.3743 (0.3602) acc 84.3750 (81.0938) kd_loss 0.7551 (0.7738) lr 7.5131e-04 eta 0:05:38
epoch [31/50] batch [60/160] time 0.079 (0.105) data 0.000 (0.005) loss 0.7099 (0.7906) ce_loss 0.5400 (0.5091) teacher_loss 0.2909 (0.3700) loss_zs_kd 0.1522 (0.1266) loss_oracle 0.3430 (0.3573) acc 75.0000 (81.3021) kd_loss 0.7277 (0.7683) lr 7.5131e-04 eta 0:05:29
epoch [31/50] batch [80/160] time 0.100 (0.103) data 0.000 (0.004) loss 0.7660 (0.7915) ce_loss 0.4006 (0.5103) teacher_loss 0.2759 (0.3684) loss_zs_kd 0.1714 (0.1292) loss_oracle 0.4044 (0.3584) acc 84.3750 (81.2500) kd_loss 0.8084 (0.7689) lr 7.5131e-04 eta 0:05:19
epoch [31/50] batch [100/160] time 0.137 (0.100) data 0.000 (0.003) loss 0.6526 (0.7891) ce_loss 0.2856 (0.5031) teacher_loss 0.2327 (0.3652) loss_zs_kd 0.1059 (0.1295) loss_oracle 0.3670 (0.3592) acc 87.5000 (81.5625) kd_loss 0.8171 (0.7729) lr 7.5131e-04 eta 0:05:11
epoch [31/50] batch [120/160] time 0.100 (0.099) data 0.000 (0.003) loss 0.8764 (0.7937) ce_loss 0.7861 (0.5064) teacher_loss 0.5515 (0.3676) loss_zs_kd 0.1171 (0.1277) loss_oracle 0.2664 (0.3623) acc 71.8750 (81.5365) kd_loss 0.7394 (0.7777) lr 7.5131e-04 eta 0:05:04
epoch [31/50] batch [140/160] time 0.072 (0.098) data 0.000 (0.002) loss 0.7513 (0.7936) ce_loss 0.4717 (0.5056) teacher_loss 0.3660 (0.3666) loss_zs_kd 0.0964 (0.1277) loss_oracle 0.3371 (0.3630) acc 87.5000 (81.4955) kd_loss 0.7604 (0.7774) lr 7.5131e-04 eta 0:05:00
epoch [31/50] batch [160/160] time 0.094 (0.097) data 0.000 (0.002) loss 0.7360 (0.7884) ce_loss 0.3481 (0.4993) teacher_loss 0.2063 (0.3628) loss_zs_kd 0.2115 (0.1286) loss_oracle 0.4240 (0.3613) acc 90.6250 (81.6602) kd_loss 0.8738 (0.7773) lr 6.9098e-04 eta 0:04:54
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,988
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [32/50] batch [20/160] time 0.080 (0.121) data 0.000 (0.017) loss 0.7096 (0.7530) ce_loss 0.3987 (0.4623) teacher_loss 0.2270 (0.3370) loss_zs_kd 0.1171 (0.1159) loss_oracle 0.4240 (0.3581) acc 84.3750 (83.7500) kd_loss 0.7820 (0.7783) lr 6.9098e-04 eta 0:06:05
epoch [32/50] batch [40/160] time 0.072 (0.129) data 0.000 (0.009) loss 0.8898 (0.8052) ce_loss 0.5659 (0.5152) teacher_loss 0.4237 (0.3778) loss_zs_kd 0.1407 (0.1236) loss_oracle 0.3957 (0.3657) acc 78.1250 (81.6406) kd_loss 0.7735 (0.7826) lr 6.9098e-04 eta 0:06:26
epoch [32/50] batch [60/160] time 0.093 (0.119) data 0.000 (0.006) loss 0.7579 (0.8116) ce_loss 0.4214 (0.5181) teacher_loss 0.2803 (0.3748) loss_zs_kd 0.1291 (0.1295) loss_oracle 0.4130 (0.3720) acc 81.2500 (81.0417) kd_loss 0.7928 (0.7853) lr 6.9098e-04 eta 0:05:55
epoch [32/50] batch [80/160] time 0.083 (0.115) data 0.000 (0.005) loss 0.7274 (0.7883) ce_loss 0.4678 (0.4914) teacher_loss 0.2915 (0.3545) loss_zs_kd 0.1276 (0.1285) loss_oracle 0.3721 (0.3696) acc 84.3750 (82.0703) kd_loss 0.8310 (0.7880) lr 6.9098e-04 eta 0:05:39
epoch [32/50] batch [100/160] time 0.114 (0.113) data 0.000 (0.004) loss 0.7834 (0.7937) ce_loss 0.4324 (0.4995) teacher_loss 0.2335 (0.3576) loss_zs_kd 0.1503 (0.1304) loss_oracle 0.4748 (0.3709) acc 87.5000 (81.7500) kd_loss 0.8720 (0.7876) lr 6.9098e-04 eta 0:05:32
epoch [32/50] batch [120/160] time 0.090 (0.113) data 0.001 (0.003) loss 0.8370 (0.7963) ce_loss 0.5742 (0.4997) teacher_loss 0.4161 (0.3581) loss_zs_kd 0.1181 (0.1303) loss_oracle 0.3618 (0.3731) acc 75.0000 (81.6406) kd_loss 0.7697 (0.7903) lr 6.9098e-04 eta 0:05:30
epoch [32/50] batch [140/160] time 0.116 (0.112) data 0.000 (0.003) loss 0.7593 (0.7917) ce_loss 0.5366 (0.4951) teacher_loss 0.3325 (0.3511) loss_zs_kd 0.1960 (0.1307) loss_oracle 0.3288 (0.3752) acc 84.3750 (82.0312) kd_loss 0.7260 (0.7923) lr 6.9098e-04 eta 0:05:25
epoch [32/50] batch [160/160] time 0.092 (0.110) data 0.000 (0.002) loss 0.8064 (0.7908) ce_loss 0.4016 (0.4961) teacher_loss 0.2771 (0.3515) loss_zs_kd 0.1745 (0.1316) loss_oracle 0.4421 (0.3736) acc 84.3750 (81.9336) kd_loss 0.8397 (0.7912) lr 6.3188e-04 eta 0:05:15
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,847
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,987
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.2%, epoch: 15 *******
epoch [33/50] batch [20/160] time 0.080 (0.130) data 0.000 (0.016) loss 0.7604 (0.7900) ce_loss 0.5020 (0.4745) teacher_loss 0.3285 (0.3310) loss_zs_kd 0.1429 (0.1474) loss_oracle 0.3604 (0.3853) acc 84.3750 (82.8125) kd_loss 0.8339 (0.7962) lr 6.3188e-04 eta 0:06:10
epoch [33/50] batch [40/160] time 0.117 (0.117) data 0.001 (0.008) loss 0.9610 (0.8009) ce_loss 0.5703 (0.4940) teacher_loss 0.5539 (0.3478) loss_zs_kd 0.1655 (0.1402) loss_oracle 0.3244 (0.3831) acc 84.3750 (81.8750) kd_loss 0.8305 (0.8002) lr 6.3188e-04 eta 0:05:30
epoch [33/50] batch [60/160] time 0.118 (0.116) data 0.001 (0.005) loss 0.9741 (0.8087) ce_loss 0.6465 (0.5059) teacher_loss 0.5191 (0.3534) loss_zs_kd 0.1415 (0.1399) loss_oracle 0.3843 (0.3853) acc 84.3750 (81.6146) kd_loss 0.8566 (0.8014) lr 6.3188e-04 eta 0:05:28
epoch [33/50] batch [80/160] time 0.116 (0.113) data 0.000 (0.004) loss 0.8648 (0.8010) ce_loss 0.4592 (0.4993) teacher_loss 0.3230 (0.3457) loss_zs_kd 0.1253 (0.1360) loss_oracle 0.4791 (0.3873) acc 81.2500 (81.5234) kd_loss 0.9234 (0.8008) lr 6.3188e-04 eta 0:05:15
epoch [33/50] batch [100/160] time 0.117 (0.109) data 0.000 (0.003) loss 0.7754 (0.8030) ce_loss 0.3733 (0.4964) teacher_loss 0.3176 (0.3449) loss_zs_kd 0.1017 (0.1369) loss_oracle 0.4071 (0.3896) acc 87.5000 (81.5938) kd_loss 0.8416 (0.8038) lr 6.3188e-04 eta 0:05:03
epoch [33/50] batch [120/160] time 0.078 (0.107) data 0.000 (0.003) loss 0.8717 (0.8088) ce_loss 0.5845 (0.5003) teacher_loss 0.4156 (0.3472) loss_zs_kd 0.2095 (0.1386) loss_oracle 0.3513 (0.3922) acc 75.0000 (81.6927) kd_loss 0.7962 (0.8071) lr 6.3188e-04 eta 0:04:54
epoch [33/50] batch [140/160] time 0.109 (0.107) data 0.001 (0.002) loss 0.9131 (0.8080) ce_loss 0.5820 (0.5035) teacher_loss 0.5255 (0.3478) loss_zs_kd 0.1095 (0.1382) loss_oracle 0.3328 (0.3911) acc 87.5000 (81.5402) kd_loss 0.7749 (0.8067) lr 6.3188e-04 eta 0:04:52

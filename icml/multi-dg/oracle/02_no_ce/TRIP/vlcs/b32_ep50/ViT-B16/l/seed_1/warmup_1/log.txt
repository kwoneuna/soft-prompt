Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'pascal', 'sun']
Target     ['labelme']
# classes  5
# train_x  5,651
# val      2,422
# test     2,656
---------  ----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/176] time 0.088 (0.174) data 0.000 (0.023) loss 0.3724 (0.5079) ce_loss 0.3723 (0.5075) teacher_loss 0.3722 (0.5075) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0002 (0.0004) acc 81.2500 (80.6250) kd_loss 0.0005 (0.0015) lr 1.0000e-05 eta 0:25:23
epoch [1/50] batch [40/176] time 0.120 (0.140) data 0.000 (0.011) loss 0.5270 (0.5274) ce_loss 0.5269 (0.5271) teacher_loss 0.5268 (0.5272) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0001 (0.0002) acc 81.2500 (80.6250) kd_loss 0.0005 (0.0009) lr 1.0000e-05 eta 0:20:23
epoch [1/50] batch [60/176] time 0.120 (0.130) data 0.001 (0.008) loss 0.5233 (0.5306) ce_loss 0.5229 (0.5303) teacher_loss 0.5229 (0.5303) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0003 (0.0002) acc 78.1250 (81.0938) kd_loss 0.0013 (0.0009) lr 1.0000e-05 eta 0:18:58
epoch [1/50] batch [80/176] time 0.116 (0.125) data 0.000 (0.006) loss 0.4569 (0.5284) ce_loss 0.4561 (0.5280) teacher_loss 0.4564 (0.5281) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0004 (0.0003) acc 87.5000 (81.5625) kd_loss 0.0013 (0.0010) lr 1.0000e-05 eta 0:18:09
epoch [1/50] batch [100/176] time 0.094 (0.122) data 0.000 (0.005) loss 0.3659 (0.5203) ce_loss 0.3657 (0.5200) teacher_loss 0.3655 (0.5200) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0003 (0.0003) acc 87.5000 (81.9375) kd_loss 0.0010 (0.0010) lr 1.0000e-05 eta 0:17:38
epoch [1/50] batch [120/176] time 0.092 (0.121) data 0.000 (0.004) loss 0.2441 (0.5189) ce_loss 0.2437 (0.5185) teacher_loss 0.2436 (0.5185) loss_zs_kd 0.0004 (0.0001) loss_oracle 0.0004 (0.0003) acc 93.7500 (81.9010) kd_loss 0.0013 (0.0011) lr 1.0000e-05 eta 0:17:27
epoch [1/50] batch [140/176] time 0.095 (0.120) data 0.000 (0.003) loss 0.6484 (0.5303) ce_loss 0.6479 (0.5299) teacher_loss 0.6478 (0.5299) loss_zs_kd 0.0005 (0.0002) loss_oracle 0.0004 (0.0003) acc 78.1250 (81.4955) kd_loss 0.0015 (0.0012) lr 1.0000e-05 eta 0:17:15
epoch [1/50] batch [160/176] time 0.083 (0.118) data 0.000 (0.003) loss 0.3227 (0.5287) ce_loss 0.3220 (0.5283) teacher_loss 0.3218 (0.5283) loss_zs_kd 0.0003 (0.0002) loss_oracle 0.0007 (0.0003) acc 87.5000 (81.3477) kd_loss 0.0027 (0.0012) lr 1.0000e-05 eta 0:16:58
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,071
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 87.9%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,832
* accuracy: 69.0%
* error: 31.0%
* macro_f1: 61.7%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain l best val acc:      85.5%, epoch: 1 *******
******* Domain l best val test acc: 69.0%, epoch: 1 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/ana
epoch [2/50] batch [20/176] time 0.097 (0.126) data 0.000 (0.018) loss 0.5716 (0.5526) ce_loss 0.5244 (0.5217) teacher_loss 0.5258 (0.5226) loss_zs_kd 0.0673 (0.0481) loss_oracle 0.0122 (0.0059) acc 81.2500 (80.1562) kd_loss 0.0105 (0.0053) lr 2.0000e-03 eta 0:18:05
epoch [2/50] batch [40/176] time 0.093 (0.116) data 0.000 (0.009) loss 0.5553 (0.5296) ce_loss 0.5205 (0.4870) teacher_loss 0.5008 (0.4864) loss_zs_kd 0.0598 (0.0574) loss_oracle 0.0246 (0.0144) acc 78.1250 (82.2656) kd_loss 0.0861 (0.0226) lr 2.0000e-03 eta 0:16:38
epoch [2/50] batch [60/176] time 0.105 (0.116) data 0.000 (0.006) loss 0.4941 (0.5442) ce_loss 0.4099 (0.4799) teacher_loss 0.4040 (0.4807) loss_zs_kd 0.0544 (0.0598) loss_oracle 0.0630 (0.0336) acc 87.5000 (82.9167) kd_loss 0.3675 (0.1037) lr 2.0000e-03 eta 0:16:32
epoch [2/50] batch [80/176] time 0.102 (0.116) data 0.000 (0.005) loss 0.7977 (0.5487) ce_loss 0.6553 (0.4716) teacher_loss 0.6202 (0.4665) loss_zs_kd 0.0859 (0.0630) loss_oracle 0.1346 (0.0508) acc 81.2500 (82.9688) kd_loss 0.5040 (0.1878) lr 2.0000e-03 eta 0:16:27
epoch [2/50] batch [100/176] time 0.125 (0.115) data 0.000 (0.004) loss 1.0016 (0.5598) ce_loss 0.7686 (0.4706) teacher_loss 0.7148 (0.4567) loss_zs_kd 0.1022 (0.0670) loss_oracle 0.2357 (0.0697) acc 71.8750 (83.0625) kd_loss 0.5666 (0.2562) lr 2.0000e-03 eta 0:16:22
epoch [2/50] batch [120/176] time 0.134 (0.114) data 0.000 (0.003) loss 0.5390 (0.5616) ce_loss 0.4165 (0.4628) teacher_loss 0.3367 (0.4398) loss_zs_kd 0.1021 (0.0701) loss_oracle 0.1513 (0.0868) acc 84.3750 (83.3594) kd_loss 0.6369 (0.3138) lr 2.0000e-03 eta 0:16:06
epoch [2/50] batch [140/176] time 0.088 (0.113) data 0.000 (0.003) loss 0.4531 (0.5672) ce_loss 0.2788 (0.4566) teacher_loss 0.2498 (0.4292) loss_zs_kd 0.0424 (0.0727) loss_oracle 0.1821 (0.1016) acc 90.6250 (83.6830) kd_loss 0.5755 (0.3575) lr 2.0000e-03 eta 0:15:55
epoch [2/50] batch [160/176] time 0.083 (0.112) data 0.000 (0.002) loss 0.5077 (0.5789) ce_loss 0.2844 (0.4514) teacher_loss 0.2741 (0.4223) loss_zs_kd 0.0300 (0.0746) loss_oracle 0.2186 (0.1193) acc 93.7500 (84.0234) kd_loss 0.7156 (0.3970) lr 2.0000e-03 eta 0:15:49
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,176
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.4%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,717
* accuracy: 64.6%
* error: 35.4%
* macro_f1: 60.8%
******* Domain l best val acc:      89.8%, epoch: 2 *******
******* Domain l best val test acc: 64.6%, epoch: 2 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [3/50] batch [20/176] time 0.148 (0.147) data 0.000 (0.016) loss 1.0524 (0.6938) ce_loss 0.7446 (0.4482) teacher_loss 0.5216 (0.3584) loss_zs_kd 0.1772 (0.0914) loss_oracle 0.4422 (0.2898) acc 68.7500 (83.2812) kd_loss 0.9098 (0.7917) lr 1.9980e-03 eta 0:20:39
epoch [3/50] batch [40/176] time 0.107 (0.123) data 0.000 (0.008) loss 0.6933 (0.7250) ce_loss 0.3994 (0.4424) teacher_loss 0.2809 (0.3540) loss_zs_kd 0.0988 (0.0966) loss_oracle 0.3630 (0.3226) acc 81.2500 (83.7500) kd_loss 0.9384 (0.8273) lr 1.9980e-03 eta 0:17:17
epoch [3/50] batch [60/176] time 0.132 (0.119) data 0.000 (0.005) loss 1.0059 (0.7251) ce_loss 0.6187 (0.4210) teacher_loss 0.4874 (0.3301) loss_zs_kd 0.0972 (0.0975) loss_oracle 0.4700 (0.3463) acc 81.2500 (85.1562) kd_loss 0.8802 (0.8488) lr 1.9980e-03 eta 0:16:39
epoch [3/50] batch [80/176] time 0.132 (0.116) data 0.000 (0.004) loss 0.5979 (0.7208) ce_loss 0.3064 (0.4112) teacher_loss 0.2565 (0.3228) loss_zs_kd 0.0652 (0.0952) loss_oracle 0.3088 (0.3504) acc 84.3750 (85.8203) kd_loss 0.8984 (0.8591) lr 1.9980e-03 eta 0:16:14
epoch [3/50] batch [100/176] time 0.087 (0.114) data 0.000 (0.003) loss 0.5902 (0.7113) ce_loss 0.3379 (0.4166) teacher_loss 0.2003 (0.3244) loss_zs_kd 0.1189 (0.0956) loss_oracle 0.3304 (0.3391) acc 90.6250 (85.8438) kd_loss 0.8850 (0.8674) lr 1.9980e-03 eta 0:15:55
epoch [3/50] batch [120/176] time 0.094 (0.113) data 0.000 (0.003) loss 0.5988 (0.7023) ce_loss 0.3850 (0.4166) teacher_loss 0.2662 (0.3188) loss_zs_kd 0.1035 (0.0990) loss_oracle 0.2809 (0.3340) acc 81.2500 (85.6510) kd_loss 0.9327 (0.8708) lr 1.9980e-03 eta 0:15:42
epoch [3/50] batch [140/176] time 0.089 (0.113) data 0.000 (0.002) loss 0.5033 (0.6940) ce_loss 0.2759 (0.4151) teacher_loss 0.1811 (0.3126) loss_zs_kd 0.0950 (0.1007) loss_oracle 0.2747 (0.3310) acc 93.7500 (85.7589) kd_loss 0.8833 (0.8753) lr 1.9980e-03 eta 0:15:38
epoch [3/50] batch [160/176] time 0.125 (0.113) data 0.000 (0.002) loss 0.6234 (0.6962) ce_loss 0.3528 (0.4211) teacher_loss 0.1995 (0.3133) loss_zs_kd 0.1300 (0.1028) loss_oracle 0.3589 (0.3314) acc 84.3750 (85.6836) kd_loss 0.9175 (0.8809) lr 1.9980e-03 eta 0:15:34
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,164
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,770
* accuracy: 66.6%
* error: 33.4%
* macro_f1: 61.8%
******* Domain l best val acc:      89.8%, epoch: 2 *******
******* Domain l best val test acc: 64.6%, epoch: 2 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [4/50] batch [20/176] time 0.121 (0.135) data 0.000 (0.015) loss 0.6432 (0.7051) ce_loss 0.3452 (0.4324) teacher_loss 0.2881 (0.3102) loss_zs_kd 0.0919 (0.1244) loss_oracle 0.3091 (0.3327) acc 93.7500 (86.4062) kd_loss 0.9016 (0.8891) lr 1.9921e-03 eta 0:18:33
epoch [4/50] batch [40/176] time 0.133 (0.124) data 0.000 (0.008) loss 0.5507 (0.6537) ce_loss 0.3320 (0.4124) teacher_loss 0.1832 (0.2911) loss_zs_kd 0.0984 (0.1122) loss_oracle 0.3183 (0.3064) acc 87.5000 (86.2500) kd_loss 0.9140 (0.8734) lr 1.9921e-03 eta 0:17:03
epoch [4/50] batch [60/176] time 0.112 (0.121) data 0.000 (0.005) loss 0.7021 (0.6705) ce_loss 0.4280 (0.4161) teacher_loss 0.2446 (0.2972) loss_zs_kd 0.1103 (0.1130) loss_oracle 0.4023 (0.3168) acc 78.1250 (85.7812) kd_loss 0.9588 (0.8660) lr 1.9921e-03 eta 0:16:34
epoch [4/50] batch [80/176] time 0.090 (0.120) data 0.000 (0.004) loss 0.8331 (0.6811) ce_loss 0.4934 (0.4146) teacher_loss 0.2832 (0.2988) loss_zs_kd 0.1774 (0.1098) loss_oracle 0.4612 (0.3274) acc 81.2500 (85.6250) kd_loss 0.9519 (0.8705) lr 1.9921e-03 eta 0:16:23
epoch [4/50] batch [100/176] time 0.108 (0.119) data 0.000 (0.003) loss 0.5476 (0.6939) ce_loss 0.2468 (0.4208) teacher_loss 0.1617 (0.2996) loss_zs_kd 0.0950 (0.1118) loss_oracle 0.3384 (0.3383) acc 87.5000 (85.0938) kd_loss 0.8337 (0.8723) lr 1.9921e-03 eta 0:16:08
epoch [4/50] batch [120/176] time 0.134 (0.118) data 0.000 (0.003) loss 0.5544 (0.7053) ce_loss 0.1857 (0.4283) teacher_loss 0.1285 (0.3028) loss_zs_kd 0.1157 (0.1143) loss_oracle 0.3680 (0.3454) acc 93.7500 (84.8958) kd_loss 0.8699 (0.8734) lr 1.9921e-03 eta 0:16:00
epoch [4/50] batch [140/176] time 0.109 (0.117) data 0.000 (0.002) loss 1.0514 (0.7109) ce_loss 0.6724 (0.4300) teacher_loss 0.5209 (0.3038) loss_zs_kd 0.1661 (0.1167) loss_oracle 0.4475 (0.3487) acc 81.2500 (84.9330) kd_loss 0.9275 (0.8746) lr 1.9921e-03 eta 0:15:53
epoch [4/50] batch [160/176] time 0.135 (0.118) data 0.000 (0.002) loss 0.5797 (0.7120) ce_loss 0.2791 (0.4269) teacher_loss 0.1691 (0.3015) loss_zs_kd 0.1048 (0.1166) loss_oracle 0.3582 (0.3522) acc 93.7500 (85.1953) kd_loss 0.8924 (0.8740) lr 1.9921e-03 eta 0:15:55
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,166
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,840
* accuracy: 69.3%
* error: 30.7%
* macro_f1: 62.5%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain l best val acc:      89.8%, epoch: 2 *******
******* Domain l best val test acc: 64.6%, epoch: 2 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [5/50] batch [20/176] time 0.150 (0.167) data 0.000 (0.017) loss 0.6308 (0.7422) ce_loss 0.3013 (0.4042) teacher_loss 0.1806 (0.2960) loss_zs_kd 0.1075 (0.1120) loss_oracle 0.3964 (0.3903) acc 84.3750 (85.1562) kd_loss 0.9458 (0.8682) lr 1.9823e-03 eta 0:22:30
epoch [5/50] batch [40/176] time 0.173 (0.135) data 0.000 (0.008) loss 0.7974 (0.7607) ce_loss 0.3477 (0.4075) teacher_loss 0.2600 (0.3025) loss_zs_kd 0.1356 (0.1136) loss_oracle 0.4696 (0.4014) acc 90.6250 (85.7031) kd_loss 0.8931 (0.8507) lr 1.9823e-03 eta 0:18:06
epoch [5/50] batch [60/176] time 0.083 (0.134) data 0.001 (0.006) loss 0.6429 (0.7386) ce_loss 0.1940 (0.3831) teacher_loss 0.1521 (0.2858) loss_zs_kd 0.0832 (0.1077) loss_oracle 0.4492 (0.3990) acc 96.8750 (87.2396) kd_loss 0.8831 (0.8509) lr 1.9823e-03 eta 0:17:53
epoch [5/50] batch [80/176] time 0.080 (0.127) data 0.000 (0.004) loss 0.7855 (0.7575) ce_loss 0.4624 (0.4055) teacher_loss 0.3709 (0.3061) loss_zs_kd 0.1187 (0.1067) loss_oracle 0.3552 (0.3981) acc 84.3750 (86.2891) kd_loss 0.7455 (0.8481) lr 1.9823e-03 eta 0:17:00
epoch [5/50] batch [100/176] time 0.113 (0.125) data 0.000 (0.004) loss 0.6763 (0.7603) ce_loss 0.3345 (0.4076) teacher_loss 0.2790 (0.3131) loss_zs_kd 0.0868 (0.1066) loss_oracle 0.3539 (0.3939) acc 87.5000 (86.1562) kd_loss 0.8204 (0.8476) lr 1.9823e-03 eta 0:16:36
epoch [5/50] batch [120/176] time 0.132 (0.124) data 0.000 (0.003) loss 0.7623 (0.7638) ce_loss 0.4128 (0.4138) teacher_loss 0.2891 (0.3184) loss_zs_kd 0.1022 (0.1075) loss_oracle 0.4221 (0.3916) acc 81.2500 (85.7292) kd_loss 0.8359 (0.8470) lr 1.9823e-03 eta 0:16:26
epoch [5/50] batch [140/176] time 0.134 (0.122) data 0.000 (0.003) loss 0.5716 (0.7605) ce_loss 0.2507 (0.4137) teacher_loss 0.1794 (0.3230) loss_zs_kd 0.0758 (0.1061) loss_oracle 0.3544 (0.3844) acc 93.7500 (85.8259) kd_loss 0.8143 (0.8455) lr 1.9823e-03 eta 0:16:07
epoch [5/50] batch [160/176] time 0.129 (0.120) data 0.000 (0.002) loss 0.6770 (0.7616) ce_loss 0.3081 (0.4152) teacher_loss 0.2280 (0.3267) loss_zs_kd 0.0973 (0.1060) loss_oracle 0.4003 (0.3819) acc 87.5000 (85.6641) kd_loss 0.8740 (0.8414) lr 1.9823e-03 eta 0:15:53
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.7%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,751
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 60.8%
******* Domain l best val acc:      89.9%, epoch: 5 *******
******* Domain l best val test acc: 65.9%, epoch: 5 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [6/50] batch [20/176] time 0.093 (0.121) data 0.000 (0.018) loss 0.5456 (0.6959) ce_loss 0.1965 (0.3824) teacher_loss 0.1564 (0.3058) loss_zs_kd 0.0870 (0.0969) loss_oracle 0.3457 (0.3416) acc 93.7500 (85.7812) kd_loss 0.7777 (0.7894) lr 1.9686e-03 eta 0:15:52
epoch [6/50] batch [40/176] time 0.090 (0.114) data 0.000 (0.009) loss 0.6194 (0.7292) ce_loss 0.3645 (0.4090) teacher_loss 0.2551 (0.3228) loss_zs_kd 0.0650 (0.1014) loss_oracle 0.3318 (0.3557) acc 81.2500 (85.4688) kd_loss 0.7844 (0.7996) lr 1.9686e-03 eta 0:14:55
epoch [6/50] batch [60/176] time 0.136 (0.111) data 0.001 (0.006) loss 0.5740 (0.7334) ce_loss 0.2644 (0.4165) teacher_loss 0.1957 (0.3318) loss_zs_kd 0.0891 (0.0991) loss_oracle 0.3337 (0.3521) acc 90.6250 (85.2083) kd_loss 0.8233 (0.7966) lr 1.9686e-03 eta 0:14:35
epoch [6/50] batch [80/176] time 0.135 (0.113) data 0.000 (0.005) loss 0.5301 (0.7143) ce_loss 0.2310 (0.4045) teacher_loss 0.2111 (0.3199) loss_zs_kd 0.1010 (0.1005) loss_oracle 0.2685 (0.3442) acc 93.7500 (85.8594) kd_loss 0.7495 (0.7904) lr 1.9686e-03 eta 0:14:42
epoch [6/50] batch [100/176] time 0.117 (0.112) data 0.000 (0.004) loss 0.8119 (0.7175) ce_loss 0.4736 (0.4102) teacher_loss 0.4235 (0.3267) loss_zs_kd 0.1392 (0.1015) loss_oracle 0.3188 (0.3400) acc 84.3750 (85.7188) kd_loss 0.8215 (0.7870) lr 1.9686e-03 eta 0:14:35
epoch [6/50] batch [120/176] time 0.120 (0.111) data 0.000 (0.003) loss 0.7757 (0.7164) ce_loss 0.5591 (0.4103) teacher_loss 0.3837 (0.3257) loss_zs_kd 0.1114 (0.1030) loss_oracle 0.3363 (0.3392) acc 78.1250 (85.5729) kd_loss 0.7680 (0.7838) lr 1.9686e-03 eta 0:14:28
epoch [6/50] batch [140/176] time 0.123 (0.111) data 0.000 (0.003) loss 0.6891 (0.7135) ce_loss 0.4861 (0.4092) teacher_loss 0.3549 (0.3259) loss_zs_kd 0.1009 (0.1037) loss_oracle 0.2838 (0.3358) acc 84.3750 (85.6696) kd_loss 0.7147 (0.7794) lr 1.9686e-03 eta 0:14:26
epoch [6/50] batch [160/176] time 0.133 (0.112) data 0.000 (0.002) loss 0.7707 (0.7117) ce_loss 0.4917 (0.4118) teacher_loss 0.3394 (0.3256) loss_zs_kd 0.1426 (0.1030) loss_oracle 0.3600 (0.3346) acc 78.1250 (85.4492) kd_loss 0.8723 (0.7791) lr 1.9686e-03 eta 0:14:27
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,174
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,719
* accuracy: 64.7%
* error: 35.3%
* macro_f1: 59.3%
******* Domain l best val acc:      89.9%, epoch: 5 *******
******* Domain l best val test acc: 65.9%, epoch: 5 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [7/50] batch [20/176] time 0.099 (0.116) data 0.000 (0.015) loss 0.7414 (0.6490) ce_loss 0.4333 (0.3745) teacher_loss 0.3806 (0.3049) loss_zs_kd 0.0927 (0.1000) loss_oracle 0.3144 (0.2941) acc 84.3750 (87.8125) kd_loss 0.8088 (0.7512) lr 1.9511e-03 eta 0:14:58
epoch [7/50] batch [40/176] time 0.073 (0.107) data 0.000 (0.007) loss 0.6100 (0.6603) ce_loss 0.2898 (0.3795) teacher_loss 0.2931 (0.3062) loss_zs_kd 0.1113 (0.0987) loss_oracle 0.2612 (0.3048) acc 90.6250 (86.9531) kd_loss 0.6712 (0.7619) lr 1.9511e-03 eta 0:13:47
epoch [7/50] batch [60/176] time 0.181 (0.116) data 0.001 (0.005) loss 0.5946 (0.6958) ce_loss 0.3596 (0.4180) teacher_loss 0.2245 (0.3321) loss_zs_kd 0.0919 (0.1017) loss_oracle 0.3241 (0.3129) acc 87.5000 (85.3646) kd_loss 0.7803 (0.7670) lr 1.9511e-03 eta 0:14:47
epoch [7/50] batch [80/176] time 0.147 (0.116) data 0.000 (0.004) loss 0.5333 (0.7104) ce_loss 0.1547 (0.4210) teacher_loss 0.1655 (0.3339) loss_zs_kd 0.0751 (0.1035) loss_oracle 0.3302 (0.3247) acc 96.8750 (85.1172) kd_loss 0.7329 (0.7683) lr 1.9511e-03 eta 0:14:50
epoch [7/50] batch [100/176] time 0.066 (0.118) data 0.000 (0.003) loss 0.7556 (0.7153) ce_loss 0.4404 (0.4116) teacher_loss 0.3551 (0.3267) loss_zs_kd 0.1133 (0.1026) loss_oracle 0.3439 (0.3373) acc 81.2500 (85.4375) kd_loss 0.6784 (0.7731) lr 1.9511e-03 eta 0:15:03
epoch [7/50] batch [120/176] time 0.104 (0.115) data 0.000 (0.003) loss 0.8886 (0.7167) ce_loss 0.6548 (0.4131) teacher_loss 0.5499 (0.3319) loss_zs_kd 0.0537 (0.1000) loss_oracle 0.3118 (0.3348) acc 71.8750 (85.4948) kd_loss 0.7484 (0.7710) lr 1.9511e-03 eta 0:14:35
epoch [7/50] batch [140/176] time 0.077 (0.113) data 0.000 (0.002) loss 0.9020 (0.7243) ce_loss 0.5376 (0.4176) teacher_loss 0.4709 (0.3364) loss_zs_kd 0.0887 (0.0993) loss_oracle 0.3867 (0.3383) acc 84.3750 (85.3348) kd_loss 0.7199 (0.7710) lr 1.9511e-03 eta 0:14:15
epoch [7/50] batch [160/176] time 0.070 (0.111) data 0.000 (0.002) loss 0.9188 (0.7269) ce_loss 0.5898 (0.4162) teacher_loss 0.5014 (0.3357) loss_zs_kd 0.0916 (0.0999) loss_oracle 0.3716 (0.3412) acc 78.1250 (85.2930) kd_loss 0.7400 (0.7703) lr 1.9511e-03 eta 0:14:02
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,183
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.0%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,786
* accuracy: 67.2%
* error: 32.8%
* macro_f1: 61.3%
******* Domain l best val acc:      90.1%, epoch: 7 *******
******* Domain l best val test acc: 67.2%, epoch: 7 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [8/50] batch [20/176] time 0.133 (0.124) data 0.000 (0.012) loss 0.5087 (0.6901) ce_loss 0.2452 (0.3662) teacher_loss 0.1998 (0.2897) loss_zs_kd 0.0779 (0.1087) loss_oracle 0.2699 (0.3460) acc 90.6250 (87.1875) kd_loss 0.7839 (0.7820) lr 1.9298e-03 eta 0:15:38
epoch [8/50] batch [40/176] time 0.118 (0.120) data 0.000 (0.006) loss 0.6631 (0.6937) ce_loss 0.3594 (0.3826) teacher_loss 0.2822 (0.3026) loss_zs_kd 0.0646 (0.1019) loss_oracle 0.3487 (0.3402) acc 90.6250 (86.6406) kd_loss 0.7759 (0.7874) lr 1.9298e-03 eta 0:14:59
epoch [8/50] batch [60/176] time 0.117 (0.117) data 0.000 (0.004) loss 0.7878 (0.7034) ce_loss 0.3809 (0.3876) teacher_loss 0.3702 (0.3119) loss_zs_kd 0.1063 (0.0972) loss_oracle 0.3645 (0.3429) acc 87.5000 (86.5104) kd_loss 0.7579 (0.7851) lr 1.9298e-03 eta 0:14:35
epoch [8/50] batch [80/176] time 0.122 (0.115) data 0.000 (0.003) loss 0.6490 (0.7072) ce_loss 0.3215 (0.3891) teacher_loss 0.2848 (0.3143) loss_zs_kd 0.0752 (0.0976) loss_oracle 0.3266 (0.3441) acc 93.7500 (86.7188) kd_loss 0.7569 (0.7829) lr 1.9298e-03 eta 0:14:23
epoch [8/50] batch [100/176] time 0.130 (0.113) data 0.000 (0.003) loss 0.6094 (0.7062) ce_loss 0.3232 (0.3914) teacher_loss 0.1862 (0.3148) loss_zs_kd 0.0961 (0.0965) loss_oracle 0.3752 (0.3432) acc 87.5000 (86.4062) kd_loss 0.7988 (0.7833) lr 1.9298e-03 eta 0:14:06
epoch [8/50] batch [120/176] time 0.116 (0.112) data 0.000 (0.002) loss 0.7587 (0.7023) ce_loss 0.4768 (0.3936) teacher_loss 0.4037 (0.3175) loss_zs_kd 0.1003 (0.0955) loss_oracle 0.3048 (0.3370) acc 78.1250 (86.3281) kd_loss 0.7242 (0.7792) lr 1.9298e-03 eta 0:13:53
epoch [8/50] batch [140/176] time 0.135 (0.111) data 0.000 (0.002) loss 0.6633 (0.6978) ce_loss 0.3853 (0.3961) teacher_loss 0.3169 (0.3198) loss_zs_kd 0.0842 (0.0942) loss_oracle 0.3043 (0.3310) acc 81.2500 (86.1384) kd_loss 0.7867 (0.7751) lr 1.9298e-03 eta 0:13:45
epoch [8/50] batch [160/176] time 0.107 (0.110) data 0.000 (0.002) loss 0.6831 (0.6953) ce_loss 0.4207 (0.3997) teacher_loss 0.3095 (0.3200) loss_zs_kd 0.1169 (0.0958) loss_oracle 0.3152 (0.3274) acc 87.5000 (86.1523) kd_loss 0.7113 (0.7706) lr 1.9298e-03 eta 0:13:34
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,186
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.0%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,725
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 60.3%
******* Domain l best val acc:      90.3%, epoch: 8 *******
******* Domain l best val test acc: 64.9%, epoch: 8 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [9/50] batch [20/176] time 0.120 (0.117) data 0.000 (0.014) loss 0.6138 (0.6694) ce_loss 0.4038 (0.4123) teacher_loss 0.2992 (0.3357) loss_zs_kd 0.1125 (0.1015) loss_oracle 0.2584 (0.2829) acc 84.3750 (83.5938) kd_loss 0.7311 (0.7212) lr 1.9048e-03 eta 0:14:18
epoch [9/50] batch [40/176] time 0.087 (0.108) data 0.000 (0.007) loss 0.8706 (0.6921) ce_loss 0.6597 (0.4321) teacher_loss 0.5401 (0.3603) loss_zs_kd 0.0918 (0.0919) loss_oracle 0.2846 (0.2859) acc 68.7500 (84.1406) kd_loss 0.7127 (0.7290) lr 1.9048e-03 eta 0:13:16
epoch [9/50] batch [60/176] time 0.078 (0.105) data 0.000 (0.005) loss 0.5689 (0.6838) ce_loss 0.3145 (0.4121) teacher_loss 0.2628 (0.3361) loss_zs_kd 0.1015 (0.0958) loss_oracle 0.2554 (0.2998) acc 87.5000 (84.9479) kd_loss 0.7288 (0.7394) lr 1.9048e-03 eta 0:12:50
epoch [9/50] batch [80/176] time 0.076 (0.104) data 0.000 (0.004) loss 0.7367 (0.6890) ce_loss 0.4268 (0.4123) teacher_loss 0.3083 (0.3319) loss_zs_kd 0.1313 (0.1017) loss_oracle 0.3627 (0.3062) acc 84.3750 (85.5078) kd_loss 0.8357 (0.7451) lr 1.9048e-03 eta 0:12:37
epoch [9/50] batch [100/176] time 0.115 (0.103) data 0.000 (0.003) loss 0.5584 (0.6896) ce_loss 0.3071 (0.4101) teacher_loss 0.2382 (0.3262) loss_zs_kd 0.1098 (0.1044) loss_oracle 0.2653 (0.3112) acc 93.7500 (85.8750) kd_loss 0.7808 (0.7465) lr 1.9048e-03 eta 0:12:30
epoch [9/50] batch [120/176] time 0.141 (0.104) data 0.000 (0.003) loss 0.8666 (0.6942) ce_loss 0.5254 (0.4163) teacher_loss 0.4492 (0.3288) loss_zs_kd 0.1490 (0.1061) loss_oracle 0.3430 (0.3124) acc 90.6250 (85.7292) kd_loss 0.8447 (0.7485) lr 1.9048e-03 eta 0:12:39
epoch [9/50] batch [140/176] time 0.062 (0.108) data 0.000 (0.002) loss 0.5549 (0.6890) ce_loss 0.2520 (0.4090) teacher_loss 0.1960 (0.3224) loss_zs_kd 0.1117 (0.1060) loss_oracle 0.3030 (0.3137) acc 96.8750 (85.9821) kd_loss 0.6366 (0.7452) lr 1.9048e-03 eta 0:13:05
epoch [9/50] batch [160/176] time 0.138 (0.110) data 0.000 (0.002) loss 0.7806 (0.6936) ce_loss 0.4851 (0.4113) teacher_loss 0.5041 (0.3234) loss_zs_kd 0.0756 (0.1056) loss_oracle 0.2387 (0.3174) acc 87.5000 (85.7422) kd_loss 0.6748 (0.7453) lr 1.9048e-03 eta 0:13:18
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,189
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.2%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,724
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 60.0%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 64.9%, epoch: 9 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [10/50] batch [20/176] time 0.097 (0.109) data 0.000 (0.012) loss 0.7839 (0.6978) ce_loss 0.5142 (0.4225) teacher_loss 0.4042 (0.3204) loss_zs_kd 0.0965 (0.1131) loss_oracle 0.3315 (0.3209) acc 75.0000 (82.9688) kd_loss 0.7601 (0.7288) lr 1.8763e-03 eta 0:13:05
epoch [10/50] batch [40/176] time 0.109 (0.106) data 0.000 (0.006) loss 0.7344 (0.6776) ce_loss 0.4041 (0.3859) teacher_loss 0.3304 (0.2975) loss_zs_kd 0.0723 (0.1094) loss_oracle 0.3679 (0.3254) acc 81.2500 (84.8438) kd_loss 0.7981 (0.7416) lr 1.8763e-03 eta 0:12:39
epoch [10/50] batch [60/176] time 0.103 (0.105) data 0.000 (0.004) loss 0.7155 (0.6879) ce_loss 0.4014 (0.3893) teacher_loss 0.3488 (0.3102) loss_zs_kd 0.1293 (0.1066) loss_oracle 0.3021 (0.3244) acc 90.6250 (85.6771) kd_loss 0.7511 (0.7403) lr 1.8763e-03 eta 0:12:28
epoch [10/50] batch [80/176] time 0.128 (0.104) data 0.000 (0.003) loss 0.7292 (0.6882) ce_loss 0.4954 (0.3913) teacher_loss 0.3971 (0.3099) loss_zs_kd 0.1000 (0.1058) loss_oracle 0.2822 (0.3254) acc 87.5000 (85.7812) kd_loss 0.7113 (0.7437) lr 1.8763e-03 eta 0:12:19
epoch [10/50] batch [100/176] time 0.105 (0.104) data 0.000 (0.002) loss 0.7610 (0.7004) ce_loss 0.5234 (0.4008) teacher_loss 0.4286 (0.3182) loss_zs_kd 0.1422 (0.1072) loss_oracle 0.2612 (0.3286) acc 84.3750 (85.6562) kd_loss 0.7675 (0.7496) lr 1.8763e-03 eta 0:12:18
epoch [10/50] batch [120/176] time 0.079 (0.103) data 0.000 (0.002) loss 0.8869 (0.6992) ce_loss 0.6138 (0.3987) teacher_loss 0.5344 (0.3148) loss_zs_kd 0.0976 (0.1076) loss_oracle 0.3037 (0.3306) acc 78.1250 (85.6250) kd_loss 0.7208 (0.7518) lr 1.8763e-03 eta 0:12:12
epoch [10/50] batch [140/176] time 0.111 (0.104) data 0.000 (0.002) loss 0.7772 (0.7027) ce_loss 0.3931 (0.3991) teacher_loss 0.3268 (0.3151) loss_zs_kd 0.1172 (0.1085) loss_oracle 0.3918 (0.3333) acc 87.5000 (85.5357) kd_loss 0.9463 (0.7563) lr 1.8763e-03 eta 0:12:13
epoch [10/50] batch [160/176] time 0.090 (0.103) data 0.000 (0.002) loss 0.5724 (0.7004) ce_loss 0.3049 (0.3988) teacher_loss 0.1532 (0.3123) loss_zs_kd 0.0905 (0.1085) loss_oracle 0.3739 (0.3338) acc 93.7500 (85.5273) kd_loss 0.9013 (0.7591) lr 1.8763e-03 eta 0:12:09
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,185
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,703
* accuracy: 64.1%
* error: 35.9%
* macro_f1: 59.4%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 64.9%, epoch: 9 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [11/50] batch [20/176] time 0.107 (0.121) data 0.000 (0.013) loss 0.8607 (0.7530) ce_loss 0.4683 (0.4334) teacher_loss 0.4352 (0.3169) loss_zs_kd 0.1401 (0.1412) loss_oracle 0.3554 (0.3655) acc 90.6250 (84.0625) kd_loss 0.8251 (0.8398) lr 1.8443e-03 eta 0:14:06
epoch [11/50] batch [40/176] time 0.134 (0.109) data 0.000 (0.007) loss 0.6494 (0.7230) ce_loss 0.4241 (0.4046) teacher_loss 0.2431 (0.2959) loss_zs_kd 0.1253 (0.1210) loss_oracle 0.3436 (0.3666) acc 84.3750 (85.9375) kd_loss 0.8283 (0.8330) lr 1.8443e-03 eta 0:12:44
epoch [11/50] batch [60/176] time 0.135 (0.108) data 0.001 (0.005) loss 0.7739 (0.7431) ce_loss 0.4707 (0.4124) teacher_loss 0.3282 (0.3031) loss_zs_kd 0.1642 (0.1244) loss_oracle 0.3636 (0.3778) acc 81.2500 (85.5208) kd_loss 0.8498 (0.8418) lr 1.8443e-03 eta 0:12:30
epoch [11/50] batch [80/176] time 0.136 (0.109) data 0.001 (0.004) loss 1.0328 (0.7488) ce_loss 0.5605 (0.4129) teacher_loss 0.5386 (0.3090) loss_zs_kd 0.0963 (0.1204) loss_oracle 0.4460 (0.3795) acc 84.3750 (85.4297) kd_loss 0.9679 (0.8403) lr 1.8443e-03 eta 0:12:40
epoch [11/50] batch [100/176] time 0.109 (0.110) data 0.000 (0.003) loss 0.7565 (0.7307) ce_loss 0.4268 (0.3945) teacher_loss 0.3368 (0.2970) loss_zs_kd 0.0975 (0.1166) loss_oracle 0.3709 (0.3753) acc 81.2500 (86.2812) kd_loss 0.8436 (0.8380) lr 1.8443e-03 eta 0:12:46
epoch [11/50] batch [120/176] time 0.130 (0.111) data 0.000 (0.002) loss 0.6796 (0.7306) ce_loss 0.2612 (0.3939) teacher_loss 0.2154 (0.2966) loss_zs_kd 0.1058 (0.1167) loss_oracle 0.4114 (0.3757) acc 84.3750 (86.0677) kd_loss 0.7735 (0.8369) lr 1.8443e-03 eta 0:12:47
epoch [11/50] batch [140/176] time 0.123 (0.111) data 0.000 (0.002) loss 0.7555 (0.7345) ce_loss 0.4238 (0.3982) teacher_loss 0.3115 (0.2994) loss_zs_kd 0.1068 (0.1163) loss_oracle 0.3906 (0.3770) acc 87.5000 (86.0491) kd_loss 0.7585 (0.8377) lr 1.8443e-03 eta 0:12:48
epoch [11/50] batch [160/176] time 0.109 (0.112) data 0.000 (0.002) loss 0.6937 (0.7395) ce_loss 0.2480 (0.4016) teacher_loss 0.1932 (0.3034) loss_zs_kd 0.1348 (0.1167) loss_oracle 0.4331 (0.3777) acc 100.0000 (86.0352) kd_loss 0.9434 (0.8383) lr 1.8443e-03 eta 0:12:53
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,179
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,780
* accuracy: 67.0%
* error: 33.0%
* macro_f1: 61.5%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 64.9%, epoch: 9 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [12/50] batch [20/176] time 0.103 (0.117) data 0.000 (0.013) loss 0.6593 (0.7432) ce_loss 0.2939 (0.3971) teacher_loss 0.2524 (0.2927) loss_zs_kd 0.0908 (0.1240) loss_oracle 0.3616 (0.3885) acc 93.7500 (84.8438) kd_loss 0.8892 (0.8483) lr 1.8090e-03 eta 0:13:20
epoch [12/50] batch [40/176] time 0.073 (0.109) data 0.000 (0.007) loss 0.8521 (0.7550) ce_loss 0.5103 (0.3968) teacher_loss 0.4316 (0.2862) loss_zs_kd 0.1300 (0.1282) loss_oracle 0.3554 (0.4047) acc 87.5000 (85.5469) kd_loss 0.7946 (0.8593) lr 1.8090e-03 eta 0:12:24
epoch [12/50] batch [60/176] time 0.086 (0.107) data 0.001 (0.005) loss 0.9094 (0.7538) ce_loss 0.5869 (0.3974) teacher_loss 0.4154 (0.2849) loss_zs_kd 0.1536 (0.1273) loss_oracle 0.4173 (0.4053) acc 84.3750 (85.8333) kd_loss 0.8644 (0.8676) lr 1.8090e-03 eta 0:12:11
epoch [12/50] batch [80/176] time 0.096 (0.106) data 0.000 (0.003) loss 0.7008 (0.7468) ce_loss 0.2942 (0.3924) teacher_loss 0.1810 (0.2782) loss_zs_kd 0.1425 (0.1265) loss_oracle 0.4485 (0.4053) acc 93.7500 (86.2500) kd_loss 0.8801 (0.8692) lr 1.8090e-03 eta 0:12:00
epoch [12/50] batch [100/176] time 0.115 (0.106) data 0.000 (0.003) loss 0.6189 (0.7439) ce_loss 0.2454 (0.3943) teacher_loss 0.2051 (0.2806) loss_zs_kd 0.0724 (0.1258) loss_oracle 0.3776 (0.4004) acc 90.6250 (86.2812) kd_loss 0.8505 (0.8638) lr 1.8090e-03 eta 0:11:54
epoch [12/50] batch [120/176] time 0.098 (0.104) data 0.000 (0.002) loss 0.6391 (0.7402) ce_loss 0.2361 (0.3886) teacher_loss 0.1406 (0.2771) loss_zs_kd 0.0803 (0.1246) loss_oracle 0.4583 (0.4008) acc 93.7500 (86.4583) kd_loss 0.8664 (0.8622) lr 1.8090e-03 eta 0:11:38
epoch [12/50] batch [140/176] time 0.135 (0.104) data 0.000 (0.002) loss 1.0437 (0.7398) ce_loss 0.5947 (0.3872) teacher_loss 0.5483 (0.2787) loss_zs_kd 0.1110 (0.1232) loss_oracle 0.4398 (0.3995) acc 81.2500 (86.5848) kd_loss 0.9209 (0.8618) lr 1.8090e-03 eta 0:11:40
epoch [12/50] batch [160/176] time 0.108 (0.104) data 0.000 (0.002) loss 0.8193 (0.7399) ce_loss 0.4502 (0.3891) teacher_loss 0.3962 (0.2832) loss_zs_kd 0.0856 (0.1209) loss_oracle 0.3803 (0.3963) acc 78.1250 (86.4648) kd_loss 0.8693 (0.8602) lr 1.8090e-03 eta 0:11:34
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,174
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,673
* accuracy: 63.0%
* error: 37.0%
* macro_f1: 58.3%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 64.9%, epoch: 9 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [13/50] batch [20/176] time 0.130 (0.116) data 0.000 (0.014) loss 0.8866 (0.7656) ce_loss 0.5850 (0.4240) teacher_loss 0.4220 (0.2960) loss_zs_kd 0.1177 (0.1303) loss_oracle 0.4058 (0.4045) acc 78.1250 (85.9375) kd_loss 0.8214 (0.8602) lr 1.7705e-03 eta 0:12:55
epoch [13/50] batch [40/176] time 0.129 (0.111) data 0.000 (0.007) loss 0.7261 (0.7423) ce_loss 0.3201 (0.3994) teacher_loss 0.2546 (0.2807) loss_zs_kd 0.0849 (0.1279) loss_oracle 0.4291 (0.3977) acc 87.5000 (86.4062) kd_loss 0.8419 (0.8514) lr 1.7705e-03 eta 0:12:15
epoch [13/50] batch [60/176] time 0.133 (0.110) data 0.001 (0.005) loss 0.6438 (0.7404) ce_loss 0.2469 (0.3927) teacher_loss 0.1799 (0.2793) loss_zs_kd 0.1090 (0.1249) loss_oracle 0.4095 (0.3986) acc 93.7500 (86.5104) kd_loss 0.8987 (0.8398) lr 1.7705e-03 eta 0:12:08
epoch [13/50] batch [80/176] time 0.117 (0.109) data 0.000 (0.004) loss 0.6597 (0.7464) ce_loss 0.3110 (0.4089) teacher_loss 0.1856 (0.2956) loss_zs_kd 0.1155 (0.1229) loss_oracle 0.4164 (0.3893) acc 90.6250 (85.9766) kd_loss 0.7752 (0.8269) lr 1.7705e-03 eta 0:11:57
epoch [13/50] batch [100/176] time 0.075 (0.109) data 0.000 (0.003) loss 0.5244 (0.7463) ce_loss 0.1525 (0.4037) teacher_loss 0.1054 (0.2952) loss_zs_kd 0.1129 (0.1237) loss_oracle 0.3625 (0.3892) acc 96.8750 (86.0000) kd_loss 0.7529 (0.8207) lr 1.7705e-03 eta 0:11:56
epoch [13/50] batch [120/176] time 0.080 (0.108) data 0.000 (0.002) loss 0.7366 (0.7425) ce_loss 0.3850 (0.3958) teacher_loss 0.2950 (0.2902) loss_zs_kd 0.0951 (0.1214) loss_oracle 0.3941 (0.3916) acc 84.3750 (86.4062) kd_loss 0.8088 (0.8155) lr 1.7705e-03 eta 0:11:48
epoch [13/50] batch [140/176] time 0.133 (0.109) data 0.000 (0.002) loss 0.7060 (0.7477) ce_loss 0.3784 (0.3981) teacher_loss 0.2397 (0.2940) loss_zs_kd 0.1080 (0.1219) loss_oracle 0.4122 (0.3928) acc 81.2500 (86.2277) kd_loss 0.7422 (0.8091) lr 1.7705e-03 eta 0:11:50
epoch [13/50] batch [160/176] time 0.086 (0.108) data 0.000 (0.002) loss 0.7695 (0.7408) ce_loss 0.4377 (0.3932) teacher_loss 0.3710 (0.2933) loss_zs_kd 0.0989 (0.1191) loss_oracle 0.3491 (0.3880) acc 78.1250 (86.3477) kd_loss 0.7699 (0.8008) lr 1.7705e-03 eta 0:11:46
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,182
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,780
* accuracy: 67.0%
* error: 33.0%
* macro_f1: 61.3%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 64.9%, epoch: 9 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [14/50] batch [20/176] time 0.132 (0.117) data 0.000 (0.012) loss 0.7608 (0.7159) ce_loss 0.4045 (0.3930) teacher_loss 0.3523 (0.3146) loss_zs_kd 0.0956 (0.1056) loss_oracle 0.3607 (0.3485) acc 93.7500 (87.5000) kd_loss 0.7120 (0.7356) lr 1.7290e-03 eta 0:12:39
epoch [14/50] batch [40/176] time 0.138 (0.103) data 0.000 (0.006) loss 0.6979 (0.7290) ce_loss 0.3962 (0.4038) teacher_loss 0.2513 (0.3340) loss_zs_kd 0.1275 (0.1035) loss_oracle 0.3830 (0.3433) acc 87.5000 (86.4062) kd_loss 0.8030 (0.7294) lr 1.7290e-03 eta 0:11:08
epoch [14/50] batch [60/176] time 0.146 (0.118) data 0.001 (0.004) loss 0.8289 (0.7217) ce_loss 0.5488 (0.4012) teacher_loss 0.4890 (0.3328) loss_zs_kd 0.1259 (0.0978) loss_oracle 0.2769 (0.3400) acc 75.0000 (86.5625) kd_loss 0.7119 (0.7346) lr 1.7290e-03 eta 0:12:44
epoch [14/50] batch [80/176] time 0.151 (0.118) data 0.000 (0.003) loss 0.8392 (0.7289) ce_loss 0.4570 (0.4101) teacher_loss 0.4118 (0.3430) loss_zs_kd 0.0964 (0.0968) loss_oracle 0.3792 (0.3375) acc 87.5000 (86.2109) kd_loss 0.7459 (0.7303) lr 1.7290e-03 eta 0:12:36
epoch [14/50] batch [100/176] time 0.105 (0.118) data 0.000 (0.003) loss 0.5808 (0.7218) ce_loss 0.2164 (0.4024) teacher_loss 0.1744 (0.3361) loss_zs_kd 0.1117 (0.0969) loss_oracle 0.3505 (0.3373) acc 96.8750 (86.2188) kd_loss 0.7208 (0.7340) lr 1.7290e-03 eta 0:12:36
epoch [14/50] batch [120/176] time 0.138 (0.116) data 0.000 (0.002) loss 0.5625 (0.7149) ce_loss 0.2327 (0.4028) teacher_loss 0.1815 (0.3339) loss_zs_kd 0.0666 (0.0962) loss_oracle 0.3476 (0.3329) acc 93.7500 (85.9635) kd_loss 0.7376 (0.7322) lr 1.7290e-03 eta 0:12:20
epoch [14/50] batch [140/176] time 0.073 (0.114) data 0.000 (0.002) loss 0.4908 (0.7126) ce_loss 0.1831 (0.4015) teacher_loss 0.1429 (0.3339) loss_zs_kd 0.0909 (0.0960) loss_oracle 0.3024 (0.3307) acc 96.8750 (86.0938) kd_loss 0.7341 (0.7335) lr 1.7290e-03 eta 0:12:07
epoch [14/50] batch [160/176] time 0.114 (0.113) data 0.000 (0.002) loss 0.5653 (0.7113) ce_loss 0.2966 (0.4003) teacher_loss 0.2081 (0.3330) loss_zs_kd 0.0950 (0.0956) loss_oracle 0.3097 (0.3305) acc 87.5000 (86.0352) kd_loss 0.7304 (0.7338) lr 1.7290e-03 eta 0:11:59
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,178
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.8%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,721
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 59.9%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 64.9%, epoch: 9 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [15/50] batch [20/176] time 0.131 (0.128) data 0.000 (0.015) loss 0.7702 (0.7004) ce_loss 0.4119 (0.3996) teacher_loss 0.3889 (0.3441) loss_zs_kd 0.0971 (0.0953) loss_oracle 0.3327 (0.3086) acc 81.2500 (85.7812) kd_loss 0.7755 (0.7191) lr 1.6845e-03 eta 0:13:28
epoch [15/50] batch [40/176] time 0.077 (0.117) data 0.000 (0.007) loss 0.7399 (0.6971) ce_loss 0.3547 (0.3849) teacher_loss 0.2923 (0.3218) loss_zs_kd 0.1405 (0.0931) loss_oracle 0.3774 (0.3288) acc 84.3750 (86.1719) kd_loss 0.7844 (0.7373) lr 1.6845e-03 eta 0:12:15
epoch [15/50] batch [60/176] time 0.136 (0.114) data 0.001 (0.005) loss 0.6029 (0.7029) ce_loss 0.2563 (0.3833) teacher_loss 0.2416 (0.3215) loss_zs_kd 0.0730 (0.0912) loss_oracle 0.3248 (0.3358) acc 93.7500 (86.3542) kd_loss 0.6990 (0.7414) lr 1.6845e-03 eta 0:11:53
epoch [15/50] batch [80/176] time 0.104 (0.112) data 0.000 (0.004) loss 0.6664 (0.7141) ce_loss 0.3701 (0.3920) teacher_loss 0.3035 (0.3232) loss_zs_kd 0.0784 (0.0948) loss_oracle 0.3237 (0.3435) acc 90.6250 (86.0547) kd_loss 0.7383 (0.7441) lr 1.6845e-03 eta 0:11:40
epoch [15/50] batch [100/176] time 0.089 (0.111) data 0.000 (0.003) loss 0.7429 (0.7174) ce_loss 0.4475 (0.3889) teacher_loss 0.3937 (0.3205) loss_zs_kd 0.0962 (0.0979) loss_oracle 0.3011 (0.3480) acc 87.5000 (86.2188) kd_loss 0.7979 (0.7490) lr 1.6845e-03 eta 0:11:33
epoch [15/50] batch [120/176] time 0.105 (0.110) data 0.000 (0.003) loss 0.6460 (0.7162) ce_loss 0.2595 (0.3852) teacher_loss 0.2469 (0.3168) loss_zs_kd 0.1263 (0.0986) loss_oracle 0.3360 (0.3501) acc 90.6250 (86.1979) kd_loss 0.7633 (0.7544) lr 1.6845e-03 eta 0:11:26
epoch [15/50] batch [140/176] time 0.113 (0.110) data 0.000 (0.002) loss 0.7180 (0.7156) ce_loss 0.3542 (0.3824) teacher_loss 0.3061 (0.3155) loss_zs_kd 0.0698 (0.0976) loss_oracle 0.3770 (0.3513) acc 81.2500 (86.3839) kd_loss 0.7054 (0.7563) lr 1.6845e-03 eta 0:11:21
epoch [15/50] batch [160/176] time 0.074 (0.109) data 0.000 (0.002) loss 0.7691 (0.7133) ce_loss 0.4541 (0.3823) teacher_loss 0.3226 (0.3146) loss_zs_kd 0.0921 (0.0967) loss_oracle 0.4004 (0.3503) acc 78.1250 (86.3281) kd_loss 0.7875 (0.7549) lr 1.6845e-03 eta 0:11:15
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,181
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,755
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 59.9%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 64.9%, epoch: 9 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [16/50] batch [20/176] time 0.068 (0.116) data 0.000 (0.014) loss 0.9713 (0.7079) ce_loss 0.6719 (0.3973) teacher_loss 0.5885 (0.3347) loss_zs_kd 0.1245 (0.0992) loss_oracle 0.3205 (0.3236) acc 65.6250 (85.0000) kd_loss 0.7431 (0.7196) lr 1.6374e-03 eta 0:11:52
epoch [16/50] batch [40/176] time 0.132 (0.115) data 0.000 (0.007) loss 0.6382 (0.6850) ce_loss 0.4019 (0.3867) teacher_loss 0.3150 (0.3293) loss_zs_kd 0.1068 (0.0945) loss_oracle 0.2698 (0.3084) acc 90.6250 (85.7812) kd_loss 0.6808 (0.7142) lr 1.6374e-03 eta 0:11:42
epoch [16/50] batch [60/176] time 0.135 (0.113) data 0.001 (0.005) loss 0.4657 (0.6868) ce_loss 0.2703 (0.3948) teacher_loss 0.1643 (0.3328) loss_zs_kd 0.0857 (0.0948) loss_oracle 0.2585 (0.3066) acc 93.7500 (85.6250) kd_loss 0.6466 (0.7086) lr 1.6374e-03 eta 0:11:30
epoch [16/50] batch [80/176] time 0.122 (0.113) data 0.000 (0.004) loss 0.8712 (0.7011) ce_loss 0.5332 (0.3997) teacher_loss 0.5142 (0.3372) loss_zs_kd 0.0950 (0.0975) loss_oracle 0.3096 (0.3152) acc 81.2500 (85.8984) kd_loss 0.7935 (0.7171) lr 1.6374e-03 eta 0:11:28
epoch [16/50] batch [100/176] time 0.169 (0.113) data 0.000 (0.003) loss 0.7178 (0.7107) ce_loss 0.3611 (0.3965) teacher_loss 0.3047 (0.3355) loss_zs_kd 0.0535 (0.0969) loss_oracle 0.3863 (0.3268) acc 84.3750 (86.0312) kd_loss 0.8093 (0.7286) lr 1.6374e-03 eta 0:11:27
epoch [16/50] batch [120/176] time 0.070 (0.118) data 0.000 (0.002) loss 0.7264 (0.7117) ce_loss 0.3213 (0.3935) teacher_loss 0.2632 (0.3303) loss_zs_kd 0.1273 (0.0966) loss_oracle 0.3995 (0.3331) acc 87.5000 (85.7812) kd_loss 0.8181 (0.7352) lr 1.6374e-03 eta 0:11:54
epoch [16/50] batch [140/176] time 0.133 (0.121) data 0.000 (0.002) loss 0.6323 (0.7070) ce_loss 0.3198 (0.3825) teacher_loss 0.2872 (0.3210) loss_zs_kd 0.1023 (0.0955) loss_oracle 0.2940 (0.3382) acc 87.5000 (86.4732) kd_loss 0.6867 (0.7383) lr 1.6374e-03 eta 0:12:05
epoch [16/50] batch [160/176] time 0.084 (0.119) data 0.000 (0.002) loss 0.7364 (0.7049) ce_loss 0.3699 (0.3823) teacher_loss 0.3330 (0.3215) loss_zs_kd 0.0751 (0.0947) loss_oracle 0.3659 (0.3361) acc 87.5000 (86.5625) kd_loss 0.7920 (0.7392) lr 1.6374e-03 eta 0:11:53
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,191
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 92.2%
Checkpoint saved to icml/multi-dg/oracle/02_no_ce/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,731
* accuracy: 65.2%
* error: 34.8%
* macro_f1: 60.1%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [17/50] batch [20/176] time 0.136 (0.134) data 0.000 (0.016) loss 0.6059 (0.7205) ce_loss 0.3074 (0.4190) teacher_loss 0.1921 (0.3407) loss_zs_kd 0.1164 (0.0992) loss_oracle 0.3556 (0.3303) acc 93.7500 (85.1562) kd_loss 0.7209 (0.7354) lr 1.5878e-03 eta 0:13:17
epoch [17/50] batch [40/176] time 0.124 (0.126) data 0.000 (0.008) loss 0.5842 (0.6927) ce_loss 0.2390 (0.3929) teacher_loss 0.1952 (0.3195) loss_zs_kd 0.0846 (0.0988) loss_oracle 0.3468 (0.3238) acc 96.8750 (86.0938) kd_loss 0.7637 (0.7382) lr 1.5878e-03 eta 0:12:26
epoch [17/50] batch [60/176] time 0.104 (0.122) data 0.001 (0.006) loss 0.6055 (0.6919) ce_loss 0.3984 (0.3973) teacher_loss 0.3470 (0.3315) loss_zs_kd 0.0552 (0.0976) loss_oracle 0.2309 (0.3116) acc 90.6250 (86.1458) kd_loss 0.6340 (0.7274) lr 1.5878e-03 eta 0:12:04
epoch [17/50] batch [80/176] time 0.117 (0.121) data 0.000 (0.004) loss 0.6117 (0.6905) ce_loss 0.3564 (0.4006) teacher_loss 0.2821 (0.3330) loss_zs_kd 0.1172 (0.0966) loss_oracle 0.2710 (0.3092) acc 84.3750 (86.1719) kd_loss 0.6976 (0.7285) lr 1.5878e-03 eta 0:11:57
epoch [17/50] batch [100/176] time 0.135 (0.120) data 0.000 (0.003) loss 0.6129 (0.6911) ce_loss 0.3354 (0.3997) teacher_loss 0.2431 (0.3334) loss_zs_kd 0.1114 (0.0977) loss_oracle 0.3141 (0.3089) acc 90.6250 (86.5000) kd_loss 0.7507 (0.7290) lr 1.5878e-03 eta 0:11:48
epoch [17/50] batch [120/176] time 0.093 (0.120) data 0.000 (0.003) loss 0.8256 (0.6964) ce_loss 0.3489 (0.3992) teacher_loss 0.2839 (0.3324) loss_zs_kd 0.1078 (0.0975) loss_oracle 0.4879 (0.3153) acc 87.5000 (86.3021) kd_loss 0.8131 (0.7341) lr 1.5878e-03 eta 0:11:42
epoch [17/50] batch [140/176] time 0.125 (0.119) data 0.000 (0.003) loss 0.6365 (0.6958) ce_loss 0.3765 (0.3979) teacher_loss 0.2904 (0.3304) loss_zs_kd 0.1205 (0.0969) loss_oracle 0.2858 (0.3170) acc 87.5000 (86.4732) kd_loss 0.6569 (0.7352) lr 1.5878e-03 eta 0:11:37
epoch [17/50] batch [160/176] time 0.091 (0.118) data 0.000 (0.002) loss 0.7699 (0.6920) ce_loss 0.3552 (0.3920) teacher_loss 0.2857 (0.3238) loss_zs_kd 0.1124 (0.0965) loss_oracle 0.4281 (0.3200) acc 84.3750 (86.5625) kd_loss 0.7724 (0.7379) lr 1.5878e-03 eta 0:11:25
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,191
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 92.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,750
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 60.5%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [18/50] batch [20/176] time 0.075 (0.117) data 0.000 (0.013) loss 0.6437 (0.6888) ce_loss 0.2930 (0.3608) teacher_loss 0.2170 (0.2761) loss_zs_kd 0.1109 (0.1149) loss_oracle 0.3712 (0.3553) acc 90.6250 (88.2812) kd_loss 0.7632 (0.7509) lr 1.5358e-03 eta 0:11:16
epoch [18/50] batch [40/176] time 0.130 (0.106) data 0.000 (0.007) loss 0.7893 (0.6803) ce_loss 0.4912 (0.3537) teacher_loss 0.3537 (0.2785) loss_zs_kd 0.1169 (0.1114) loss_oracle 0.3771 (0.3461) acc 81.2500 (88.1250) kd_loss 0.7836 (0.7504) lr 1.5358e-03 eta 0:10:10
epoch [18/50] batch [60/176] time 0.096 (0.103) data 0.001 (0.004) loss 0.6400 (0.7078) ce_loss 0.3176 (0.3884) teacher_loss 0.3229 (0.3077) loss_zs_kd 0.1407 (0.1111) loss_oracle 0.2468 (0.3445) acc 93.7500 (86.3542) kd_loss 0.7340 (0.7481) lr 1.5358e-03 eta 0:09:51
epoch [18/50] batch [80/176] time 0.100 (0.102) data 0.000 (0.003) loss 0.6408 (0.7105) ce_loss 0.3044 (0.3940) teacher_loss 0.2728 (0.3164) loss_zs_kd 0.0791 (0.1077) loss_oracle 0.3284 (0.3403) acc 93.7500 (86.2109) kd_loss 0.7179 (0.7404) lr 1.5358e-03 eta 0:09:41
epoch [18/50] batch [100/176] time 0.075 (0.100) data 0.000 (0.003) loss 0.6415 (0.7111) ce_loss 0.3574 (0.3910) teacher_loss 0.2989 (0.3151) loss_zs_kd 0.1187 (0.1064) loss_oracle 0.2832 (0.3428) acc 81.2500 (86.2500) kd_loss 0.6549 (0.7404) lr 1.5358e-03 eta 0:09:30
epoch [18/50] batch [120/176] time 0.070 (0.099) data 0.000 (0.002) loss 0.7352 (0.7089) ce_loss 0.4062 (0.3894) teacher_loss 0.3269 (0.3136) loss_zs_kd 0.0860 (0.1060) loss_oracle 0.3654 (0.3423) acc 87.5000 (86.5365) kd_loss 0.7809 (0.7433) lr 1.5358e-03 eta 0:09:22
epoch [18/50] batch [140/176] time 0.169 (0.102) data 0.000 (0.002) loss 0.5932 (0.7015) ce_loss 0.2327 (0.3827) teacher_loss 0.1491 (0.3074) loss_zs_kd 0.1002 (0.1027) loss_oracle 0.3940 (0.3427) acc 90.6250 (86.8750) kd_loss 0.8727 (0.7453) lr 1.5358e-03 eta 0:09:38
epoch [18/50] batch [160/176] time 0.154 (0.106) data 0.000 (0.002) loss 0.7191 (0.7035) ce_loss 0.4277 (0.3833) teacher_loss 0.3913 (0.3084) loss_zs_kd 0.1060 (0.1029) loss_oracle 0.2748 (0.3436) acc 81.2500 (86.9531) kd_loss 0.7019 (0.7466) lr 1.5358e-03 eta 0:09:57
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,188
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,706
* accuracy: 64.2%
* error: 35.8%
* macro_f1: 59.6%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [19/50] batch [20/176] time 0.092 (0.129) data 0.000 (0.015) loss 0.8665 (0.7426) ce_loss 0.6987 (0.4204) teacher_loss 0.4392 (0.3254) loss_zs_kd 0.1230 (0.1004) loss_oracle 0.3657 (0.3670) acc 78.1250 (83.9062) kd_loss 0.7406 (0.7453) lr 1.4818e-03 eta 0:12:04
epoch [19/50] batch [40/176] time 0.142 (0.121) data 0.000 (0.008) loss 0.5374 (0.7300) ce_loss 0.2440 (0.4102) teacher_loss 0.1388 (0.3145) loss_zs_kd 0.1032 (0.1100) loss_oracle 0.3470 (0.3605) acc 93.7500 (84.7656) kd_loss 0.7306 (0.7402) lr 1.4818e-03 eta 0:11:16
epoch [19/50] batch [60/176] time 0.088 (0.114) data 0.001 (0.005) loss 0.6126 (0.7245) ce_loss 0.3057 (0.4072) teacher_loss 0.2618 (0.3150) loss_zs_kd 0.0968 (0.1085) loss_oracle 0.3024 (0.3553) acc 93.7500 (84.9479) kd_loss 0.7573 (0.7377) lr 1.4818e-03 eta 0:10:36
epoch [19/50] batch [80/176] time 0.095 (0.111) data 0.000 (0.004) loss 0.7414 (0.7097) ce_loss 0.3425 (0.3896) teacher_loss 0.2428 (0.2990) loss_zs_kd 0.1228 (0.1083) loss_oracle 0.4372 (0.3566) acc 84.3750 (86.1719) kd_loss 0.8127 (0.7382) lr 1.4818e-03 eta 0:10:18
epoch [19/50] batch [100/176] time 0.118 (0.108) data 0.000 (0.003) loss 0.7556 (0.7128) ce_loss 0.5122 (0.3909) teacher_loss 0.3727 (0.3019) loss_zs_kd 0.0911 (0.1091) loss_oracle 0.3374 (0.3563) acc 78.1250 (86.2500) kd_loss 0.7081 (0.7370) lr 1.4818e-03 eta 0:09:59
epoch [19/50] batch [120/176] time 0.102 (0.109) data 0.000 (0.003) loss 0.7445 (0.7049) ce_loss 0.4561 (0.3895) teacher_loss 0.3768 (0.3015) loss_zs_kd 0.1083 (0.1068) loss_oracle 0.3135 (0.3500) acc 81.2500 (86.5104) kd_loss 0.7050 (0.7309) lr 1.4818e-03 eta 0:09:59
epoch [19/50] batch [140/176] time 0.133 (0.109) data 0.000 (0.002) loss 0.6857 (0.6975) ce_loss 0.2983 (0.3857) teacher_loss 0.2838 (0.2979) loss_zs_kd 0.1354 (0.1075) loss_oracle 0.3342 (0.3459) acc 93.7500 (86.7411) kd_loss 0.6875 (0.7265) lr 1.4818e-03 eta 0:10:00
epoch [19/50] batch [160/176] time 0.119 (0.108) data 0.000 (0.002) loss 0.7857 (0.6912) ce_loss 0.4961 (0.3775) teacher_loss 0.4380 (0.2929) loss_zs_kd 0.1111 (0.1070) loss_oracle 0.2922 (0.3447) acc 81.2500 (87.0508) kd_loss 0.6768 (0.7251) lr 1.4818e-03 eta 0:09:50
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,185
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,670
* accuracy: 62.9%
* error: 37.1%
* macro_f1: 59.0%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.3%, epoch: 4 *******
epoch [20/50] batch [20/176] time 0.078 (0.118) data 0.000 (0.013) loss 0.6812 (0.6859) ce_loss 0.3284 (0.3688) teacher_loss 0.2503 (0.3059) loss_zs_kd 0.1146 (0.0940) loss_oracle 0.3736 (0.3330) acc 84.3750 (87.9688) kd_loss 0.7551 (0.7233) lr 1.4258e-03 eta 0:10:41
epoch [20/50] batch [40/176] time 0.123 (0.104) data 0.000 (0.007) loss 0.4753 (0.6721) ce_loss 0.1958 (0.3618) teacher_loss 0.1461 (0.2954) loss_zs_kd 0.0703 (0.0973) loss_oracle 0.2940 (0.3281) acc 93.7500 (88.0469) kd_loss 0.7292 (0.7187) lr 1.4258e-03 eta 0:09:24
epoch [20/50] batch [60/176] time 0.094 (0.100) data 0.001 (0.005) loss 0.6577 (0.6714) ce_loss 0.3765 (0.3668) teacher_loss 0.3359 (0.2948) loss_zs_kd 0.0889 (0.0992) loss_oracle 0.2773 (0.3270) acc 90.6250 (87.6562) kd_loss 0.6890 (0.7178) lr 1.4258e-03 eta 0:09:00
epoch [20/50] batch [80/176] time 0.085 (0.100) data 0.000 (0.003) loss 0.6522 (0.6748) ce_loss 0.3564 (0.3712) teacher_loss 0.2582 (0.2964) loss_zs_kd 0.1150 (0.0999) loss_oracle 0.3365 (0.3285) acc 90.6250 (87.6172) kd_loss 0.6554 (0.7247) lr 1.4258e-03 eta 0:08:55
epoch [20/50] batch [100/176] time 0.089 (0.099) data 0.000 (0.003) loss 0.7654 (0.6810) ce_loss 0.4131 (0.3743) teacher_loss 0.3282 (0.2947) loss_zs_kd 0.0757 (0.1009) loss_oracle 0.3994 (0.3359) acc 84.3750 (87.5000) kd_loss 0.8008 (0.7295) lr 1.4258e-03 eta 0:08:50
epoch [20/50] batch [120/176] time 0.087 (0.099) data 0.000 (0.002) loss 0.7030 (0.6827) ce_loss 0.4209 (0.3749) teacher_loss 0.3142 (0.2931) loss_zs_kd 0.1202 (0.1034) loss_oracle 0.3287 (0.3379) acc 81.2500 (87.1875) kd_loss 0.7189 (0.7297) lr 1.4258e-03 eta 0:08:49
epoch [20/50] batch [140/176] time 0.080 (0.099) data 0.000 (0.002) loss 0.7323 (0.6868) ce_loss 0.4521 (0.3733) teacher_loss 0.3346 (0.2921) loss_zs_kd 0.1663 (0.1041) loss_oracle 0.3145 (0.3426) acc 84.3750 (87.0759) kd_loss 0.6590 (0.7346) lr 1.4258e-03 eta 0:08:44
epoch [20/50] batch [160/176] time 0.119 (0.098) data 0.000 (0.002) loss 0.5736 (0.6905) ce_loss 0.2576 (0.3760) teacher_loss 0.1989 (0.2952) loss_zs_kd 0.0861 (0.1043) loss_oracle 0.3316 (0.3432) acc 93.7500 (86.9336) kd_loss 0.7678 (0.7372) lr 1.4258e-03 eta 0:08:39

Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'clipart', 'real_world']
Target     ['product']
# classes  65
# train_x  7,815
# val      3,334
# test     4,439
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/244] time 0.175 (0.246) data 0.000 (0.019) loss 1.4317 (1.4267) ce_loss 1.4297 (1.4243) teacher_loss 1.4285 (1.4243) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0032 (0.0024) acc 62.5000 (65.0000) kd_loss 0.0126 (0.0098) lr 1.0000e-05 eta 0:49:57
epoch [1/50] batch [40/244] time 0.162 (0.199) data 0.000 (0.009) loss 1.5012 (1.3965) ce_loss 1.4980 (1.3939) teacher_loss 1.4992 (1.3940) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0020 (0.0025) acc 56.2500 (65.2344) kd_loss 0.0079 (0.0101) lr 1.0000e-05 eta 0:40:22
epoch [1/50] batch [60/244] time 0.156 (0.187) data 0.000 (0.006) loss 1.3195 (1.4301) ce_loss 1.3184 (1.4277) teacher_loss 1.3182 (1.4277) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0012 (0.0023) acc 65.6250 (64.0104) kd_loss 0.0049 (0.0093) lr 1.0000e-05 eta 0:37:45
epoch [1/50] batch [80/244] time 0.168 (0.180) data 0.000 (0.005) loss 1.5659 (1.4359) ce_loss 1.5654 (1.4337) teacher_loss 1.5646 (1.4337) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0011 (0.0021) acc 59.3750 (63.9844) kd_loss 0.0043 (0.0085) lr 1.0000e-05 eta 0:36:16
epoch [1/50] batch [100/244] time 0.180 (0.175) data 0.000 (0.004) loss 1.5576 (1.4164) ce_loss 1.5557 (1.4144) teacher_loss 1.5554 (1.4144) loss_zs_kd 0.0006 (0.0002) loss_oracle 0.0019 (0.0019) acc 62.5000 (64.1875) kd_loss 0.0071 (0.0077) lr 1.0000e-05 eta 0:35:22
epoch [1/50] batch [120/244] time 0.167 (0.174) data 0.000 (0.003) loss 0.9579 (1.4020) ce_loss 0.9565 (1.4001) teacher_loss 0.9567 (1.4001) loss_zs_kd 0.0005 (0.0002) loss_oracle 0.0010 (0.0018) acc 75.0000 (64.5573) kd_loss 0.0039 (0.0071) lr 1.0000e-05 eta 0:35:04
epoch [1/50] batch [140/244] time 0.410 (0.176) data 0.000 (0.003) loss 1.0928 (1.3832) ce_loss 1.0908 (1.3815) teacher_loss 1.0914 (1.3815) loss_zs_kd 0.0007 (0.0003) loss_oracle 0.0010 (0.0016) acc 75.0000 (65.0000) kd_loss 0.0040 (0.0065) lr 1.0000e-05 eta 0:35:23
epoch [1/50] batch [160/244] time 0.151 (0.178) data 0.000 (0.002) loss 1.4831 (1.3748) ce_loss 1.4814 (1.3731) teacher_loss 1.4815 (1.3731) loss_zs_kd 0.0016 (0.0004) loss_oracle 0.0008 (0.0015) acc 56.2500 (65.1367) kd_loss 0.0029 (0.0060) lr 1.0000e-05 eta 0:35:48
epoch [1/50] batch [180/244] time 0.150 (0.176) data 0.001 (0.002) loss 0.9852 (1.3742) ce_loss 0.9834 (1.3725) teacher_loss 0.9837 (1.3725) loss_zs_kd 0.0010 (0.0005) loss_oracle 0.0011 (0.0014) acc 81.2500 (65.1910) kd_loss 0.0041 (0.0057) lr 1.0000e-05 eta 0:35:18
epoch [1/50] batch [200/244] time 0.151 (0.174) data 0.000 (0.002) loss 1.4865 (1.3734) ce_loss 1.4844 (1.3717) teacher_loss 1.4848 (1.3717) loss_zs_kd 0.0013 (0.0007) loss_oracle 0.0011 (0.0014) acc 62.5000 (65.2344) kd_loss 0.0041 (0.0054) lr 1.0000e-05 eta 0:34:50
epoch [1/50] batch [220/244] time 0.153 (0.172) data 0.000 (0.002) loss 1.2263 (1.3700) ce_loss 1.2227 (1.3683) teacher_loss 1.2226 (1.3683) loss_zs_kd 0.0063 (0.0008) loss_oracle 0.0006 (0.0013) acc 68.7500 (65.2557) kd_loss 0.0021 (0.0052) lr 1.0000e-05 eta 0:34:26
epoch [1/50] batch [240/244] time 0.154 (0.171) data 0.000 (0.002) loss 1.3157 (1.3666) ce_loss 1.3135 (1.3649) teacher_loss 1.3137 (1.3649) loss_zs_kd 0.0016 (0.0009) loss_oracle 0.0012 (0.0013) acc 75.0000 (65.4557) kd_loss 0.0042 (0.0050) lr 1.0000e-05 eta 0:34:07
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,673
* accuracy: 80.2%
* error: 19.8%
* macro_f1: 78.6%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,943
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 87.9%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      80.2%, epoch: 1 *******
******* Domain p best val test acc: 88.8%, epoch: 1 *******
******* Domain p best test acc:     88.8%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/ana
epoch [2/50] batch [20/244] time 0.166 (0.236) data 0.000 (0.023) loss 1.0386 (1.4210) ce_loss 1.0000 (1.3728) teacher_loss 0.9998 (1.3729) loss_zs_kd 0.0726 (0.0918) loss_oracle 0.0026 (0.0022) acc 75.0000 (63.9062) kd_loss 0.0021 (0.0027) lr 2.0000e-03 eta 0:46:50
epoch [2/50] batch [40/244] time 0.155 (0.203) data 0.000 (0.012) loss 1.1303 (1.3476) ce_loss 1.0977 (1.3023) teacher_loss 1.0983 (1.3024) loss_zs_kd 0.0525 (0.0838) loss_oracle 0.0058 (0.0033) acc 71.8750 (66.4844) kd_loss 0.0017 (0.0026) lr 2.0000e-03 eta 0:40:15
epoch [2/50] batch [60/244] time 0.156 (0.190) data 0.001 (0.008) loss 1.4568 (1.3885) ce_loss 1.3828 (1.3360) teacher_loss 1.3835 (1.3363) loss_zs_kd 0.0845 (0.0805) loss_oracle 0.0311 (0.0120) acc 62.5000 (65.2604) kd_loss 0.0077 (0.0030) lr 2.0000e-03 eta 0:37:37
epoch [2/50] batch [80/244] time 0.160 (0.182) data 0.000 (0.006) loss 1.1357 (1.3395) ce_loss 1.0791 (1.2846) teacher_loss 1.0795 (1.2851) loss_zs_kd 0.1017 (0.0839) loss_oracle 0.0053 (0.0125) acc 68.7500 (66.2500) kd_loss 0.0048 (0.0036) lr 2.0000e-03 eta 0:36:02
epoch [2/50] batch [100/244] time 0.168 (0.177) data 0.000 (0.005) loss 0.9505 (1.3249) ce_loss 0.9136 (1.2707) teacher_loss 0.9137 (1.2714) loss_zs_kd 0.0626 (0.0850) loss_oracle 0.0055 (0.0111) acc 71.8750 (66.9062) kd_loss 0.0034 (0.0040) lr 2.0000e-03 eta 0:34:58
epoch [2/50] batch [120/244] time 0.170 (0.174) data 0.000 (0.004) loss 1.7207 (1.3025) ce_loss 1.6758 (1.2501) teacher_loss 1.6759 (1.2507) loss_zs_kd 0.0753 (0.0830) loss_oracle 0.0072 (0.0102) acc 62.5000 (67.7083) kd_loss 0.0062 (0.0042) lr 2.0000e-03 eta 0:34:20
epoch [2/50] batch [140/244] time 0.233 (0.177) data 0.000 (0.003) loss 1.0413 (1.2969) ce_loss 0.9834 (1.2438) teacher_loss 0.9833 (1.2444) loss_zs_kd 0.0975 (0.0854) loss_oracle 0.0093 (0.0098) acc 75.0000 (67.9911) kd_loss 0.0059 (0.0043) lr 2.0000e-03 eta 0:34:54
epoch [2/50] batch [160/244] time 0.171 (0.179) data 0.000 (0.003) loss 1.2222 (1.3030) ce_loss 1.1797 (1.2501) teacher_loss 1.1791 (1.2507) loss_zs_kd 0.0626 (0.0855) loss_oracle 0.0117 (0.0096) acc 68.7500 (67.8125) kd_loss 0.0056 (0.0045) lr 2.0000e-03 eta 0:35:07
epoch [2/50] batch [180/244] time 0.155 (0.177) data 0.000 (0.003) loss 1.1298 (1.2898) ce_loss 1.0732 (1.2363) teacher_loss 1.0729 (1.2369) loss_zs_kd 0.0825 (0.0860) loss_oracle 0.0157 (0.0098) acc 71.8750 (68.1076) kd_loss 0.0048 (0.0047) lr 2.0000e-03 eta 0:34:42
epoch [2/50] batch [200/244] time 0.169 (0.175) data 0.000 (0.002) loss 1.4286 (1.3007) ce_loss 1.3799 (1.2452) teacher_loss 1.3816 (1.2459) loss_zs_kd 0.0689 (0.0889) loss_oracle 0.0125 (0.0103) acc 65.6250 (67.7969) kd_loss 0.0074 (0.0048) lr 2.0000e-03 eta 0:34:19
epoch [2/50] batch [220/244] time 0.172 (0.174) data 0.000 (0.002) loss 1.1600 (1.2958) ce_loss 1.0771 (1.2399) teacher_loss 1.0772 (1.2407) loss_zs_kd 0.1359 (0.0893) loss_oracle 0.0148 (0.0104) acc 75.0000 (67.8267) kd_loss 0.0056 (0.0048) lr 2.0000e-03 eta 0:34:04
epoch [2/50] batch [240/244] time 0.154 (0.173) data 0.000 (0.002) loss 1.5050 (1.2954) ce_loss 1.4131 (1.2388) teacher_loss 1.4126 (1.2396) loss_zs_kd 0.1641 (0.0905) loss_oracle 0.0103 (0.0106) acc 65.6250 (67.6693) kd_loss 0.0056 (0.0049) lr 2.0000e-03 eta 0:33:46
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,781
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 82.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,030
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.2%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.4%, epoch: 2 *******
******* Domain p best val test acc: 90.8%, epoch: 2 *******
******* Domain p best test acc:     90.8%, epoch: 2 *******
epoch [3/50] batch [20/244] time 0.155 (0.176) data 0.000 (0.015) loss 1.2845 (1.2835) ce_loss 1.1963 (1.2035) teacher_loss 1.1980 (1.2044) loss_zs_kd 0.1410 (0.1320) loss_oracle 0.0159 (0.0130) acc 65.6250 (69.5312) kd_loss 0.0106 (0.0072) lr 1.9980e-03 eta 0:34:21
epoch [3/50] batch [40/244] time 0.159 (0.171) data 0.000 (0.008) loss 0.8453 (1.2794) ce_loss 0.7842 (1.2100) teacher_loss 0.7866 (1.2105) loss_zs_kd 0.0969 (0.1125) loss_oracle 0.0103 (0.0126) acc 68.7500 (69.3750) kd_loss 0.0065 (0.0071) lr 1.9980e-03 eta 0:33:19
epoch [3/50] batch [60/244] time 0.155 (0.168) data 0.000 (0.005) loss 0.7334 (1.2441) ce_loss 0.6714 (1.1794) teacher_loss 0.6724 (1.1800) loss_zs_kd 0.1021 (0.1051) loss_oracle 0.0100 (0.0116) acc 84.3750 (69.7396) kd_loss 0.0052 (0.0073) lr 1.9980e-03 eta 0:32:41
epoch [3/50] batch [80/244] time 0.175 (0.168) data 0.000 (0.004) loss 1.5745 (1.2871) ce_loss 1.5283 (1.2205) teacher_loss 1.5292 (1.2207) loss_zs_kd 0.0693 (0.1089) loss_oracle 0.0106 (0.0120) acc 65.6250 (68.6719) kd_loss 0.0060 (0.0075) lr 1.9980e-03 eta 0:32:31
epoch [3/50] batch [100/244] time 0.175 (0.169) data 0.000 (0.003) loss 1.7346 (1.2751) ce_loss 1.6445 (1.2099) teacher_loss 1.6429 (1.2101) loss_zs_kd 0.1524 (0.1059) loss_oracle 0.0155 (0.0121) acc 56.2500 (69.0000) kd_loss 0.0106 (0.0076) lr 1.9980e-03 eta 0:32:39
epoch [3/50] batch [120/244] time 0.083 (0.167) data 0.000 (0.003) loss 0.9205 (1.2750) ce_loss 0.8193 (1.2092) teacher_loss 0.8210 (1.2094) loss_zs_kd 0.1614 (0.1069) loss_oracle 0.0188 (0.0121) acc 71.8750 (68.8021) kd_loss 0.0092 (0.0078) lr 1.9980e-03 eta 0:32:13
epoch [3/50] batch [140/244] time 0.305 (0.170) data 0.000 (0.002) loss 1.3403 (1.2649) ce_loss 1.2686 (1.1978) teacher_loss 1.2655 (1.1981) loss_zs_kd 0.1184 (0.1091) loss_oracle 0.0156 (0.0122) acc 68.7500 (69.1071) kd_loss 0.0091 (0.0078) lr 1.9980e-03 eta 0:32:42
epoch [3/50] batch [160/244] time 0.151 (0.171) data 0.000 (0.002) loss 1.2439 (1.2754) ce_loss 1.1865 (1.2089) teacher_loss 1.1872 (1.2094) loss_zs_kd 0.0813 (0.1075) loss_oracle 0.0161 (0.0123) acc 68.7500 (68.8672) kd_loss 0.0081 (0.0079) lr 1.9980e-03 eta 0:33:00
epoch [3/50] batch [180/244] time 0.150 (0.170) data 0.000 (0.002) loss 0.9793 (1.2681) ce_loss 0.9009 (1.2018) teacher_loss 0.9027 (1.2022) loss_zs_kd 0.1141 (0.1068) loss_oracle 0.0196 (0.0124) acc 75.0000 (69.1319) kd_loss 0.0093 (0.0078) lr 1.9980e-03 eta 0:32:43
epoch [3/50] batch [200/244] time 0.153 (0.169) data 0.000 (0.002) loss 1.4308 (1.2673) ce_loss 1.3574 (1.1998) teacher_loss 1.3460 (1.2003) loss_zs_kd 0.1184 (0.1080) loss_oracle 0.0256 (0.0130) acc 62.5000 (69.0781) kd_loss 0.0136 (0.0078) lr 1.9980e-03 eta 0:32:30
epoch [3/50] batch [220/244] time 0.165 (0.169) data 0.000 (0.002) loss 1.3852 (1.2722) ce_loss 1.3105 (1.2038) teacher_loss 1.3131 (1.2044) loss_zs_kd 0.1268 (0.1087) loss_oracle 0.0087 (0.0135) acc 75.0000 (69.1193) kd_loss 0.0075 (0.0079) lr 1.9980e-03 eta 0:32:18
epoch [3/50] batch [240/244] time 0.157 (0.168) data 0.000 (0.001) loss 0.9274 (1.2692) ce_loss 0.8843 (1.2007) teacher_loss 0.8840 (1.2012) loss_zs_kd 0.0712 (0.1091) loss_oracle 0.0078 (0.0135) acc 71.8750 (69.1797) kd_loss 0.0056 (0.0080) lr 1.9980e-03 eta 0:32:09
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,783
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.2%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,032
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.5%, epoch: 3 *******
******* Domain p best val test acc: 90.8%, epoch: 3 *******
******* Domain p best test acc:     90.8%, epoch: 3 *******
epoch [4/50] batch [20/244] time 0.149 (0.183) data 0.000 (0.016) loss 1.6043 (1.2957) ce_loss 1.5469 (1.2207) teacher_loss 1.5428 (1.2216) loss_zs_kd 0.0899 (0.1209) loss_oracle 0.0166 (0.0136) acc 59.3750 (67.1875) kd_loss 0.0119 (0.0095) lr 1.9921e-03 eta 0:34:51
epoch [4/50] batch [40/244] time 0.148 (0.172) data 0.000 (0.008) loss 0.8512 (1.2571) ce_loss 0.7725 (1.1868) teacher_loss 0.7744 (1.1879) loss_zs_kd 0.1349 (0.1129) loss_oracle 0.0094 (0.0128) acc 84.3750 (68.4375) kd_loss 0.0069 (0.0090) lr 1.9921e-03 eta 0:32:43
epoch [4/50] batch [60/244] time 0.155 (0.167) data 0.001 (0.005) loss 1.5026 (1.2331) ce_loss 1.4219 (1.1619) teacher_loss 1.4214 (1.1630) loss_zs_kd 0.1269 (0.1139) loss_oracle 0.0178 (0.0132) acc 56.2500 (69.4271) kd_loss 0.0116 (0.0092) lr 1.9921e-03 eta 0:31:50
epoch [4/50] batch [80/244] time 0.149 (0.167) data 0.000 (0.004) loss 1.9393 (1.2372) ce_loss 1.8457 (1.1639) teacher_loss 1.8401 (1.1646) loss_zs_kd 0.1616 (0.1187) loss_oracle 0.0184 (0.0132) acc 46.8750 (69.5312) kd_loss 0.0125 (0.0092) lr 1.9921e-03 eta 0:31:37
epoch [4/50] batch [100/244] time 0.154 (0.164) data 0.000 (0.003) loss 1.4149 (1.2602) ce_loss 1.3486 (1.1858) teacher_loss 1.3497 (1.1863) loss_zs_kd 0.1069 (0.1214) loss_oracle 0.0118 (0.0133) acc 65.6250 (68.9375) kd_loss 0.0067 (0.0092) lr 1.9921e-03 eta 0:31:08
epoch [4/50] batch [120/244] time 0.088 (0.161) data 0.000 (0.003) loss 1.0703 (1.2716) ce_loss 0.9985 (1.1973) teacher_loss 1.0038 (1.1976) loss_zs_kd 0.1029 (0.1212) loss_oracle 0.0151 (0.0135) acc 81.2500 (68.9844) kd_loss 0.0073 (0.0090) lr 1.9921e-03 eta 0:30:25
epoch [4/50] batch [140/244] time 0.086 (0.172) data 0.000 (0.002) loss 0.9122 (1.2565) ce_loss 0.8418 (1.1828) teacher_loss 0.8445 (1.1830) loss_zs_kd 0.1018 (0.1200) loss_oracle 0.0169 (0.0135) acc 78.1250 (69.2857) kd_loss 0.0106 (0.0090) lr 1.9921e-03 eta 0:32:31
epoch [4/50] batch [160/244] time 0.147 (0.169) data 0.000 (0.002) loss 1.0604 (1.2602) ce_loss 0.9966 (1.1852) teacher_loss 0.9954 (1.1855) loss_zs_kd 0.0989 (0.1217) loss_oracle 0.0156 (0.0138) acc 71.8750 (68.8867) kd_loss 0.0080 (0.0089) lr 1.9921e-03 eta 0:31:45
epoch [4/50] batch [180/244] time 0.145 (0.166) data 0.000 (0.002) loss 0.7412 (1.2448) ce_loss 0.6792 (1.1700) teacher_loss 0.6783 (1.1702) loss_zs_kd 0.1047 (0.1211) loss_oracle 0.0105 (0.0140) acc 81.2500 (69.5139) kd_loss 0.0077 (0.0089) lr 1.9921e-03 eta 0:31:19
epoch [4/50] batch [200/244] time 0.159 (0.165) data 0.000 (0.002) loss 1.4132 (1.2420) ce_loss 1.3525 (1.1675) teacher_loss 1.3501 (1.1676) loss_zs_kd 0.0959 (0.1207) loss_oracle 0.0152 (0.0141) acc 75.0000 (69.4688) kd_loss 0.0091 (0.0088) lr 1.9921e-03 eta 0:31:00
epoch [4/50] batch [220/244] time 0.153 (0.164) data 0.000 (0.002) loss 1.8664 (1.2339) ce_loss 1.7959 (1.1587) teacher_loss 1.7929 (1.1588) loss_zs_kd 0.1068 (0.1212) loss_oracle 0.0200 (0.0144) acc 59.3750 (69.6307) kd_loss 0.0111 (0.0087) lr 1.9921e-03 eta 0:30:45
epoch [4/50] batch [240/244] time 0.146 (0.163) data 0.000 (0.002) loss 1.4652 (1.2328) ce_loss 1.4092 (1.1578) teacher_loss 1.4008 (1.1579) loss_zs_kd 0.0886 (0.1205) loss_oracle 0.0201 (0.0146) acc 59.3750 (69.6745) kd_loss 0.0090 (0.0087) lr 1.9921e-03 eta 0:30:29
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,793
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.7%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.8%, epoch: 4 *******
******* Domain p best val test acc: 90.9%, epoch: 4 *******
******* Domain p best test acc:     90.9%, epoch: 4 *******
epoch [5/50] batch [20/244] time 0.174 (0.223) data 0.000 (0.017) loss 1.4560 (1.2984) ce_loss 1.3965 (1.2104) teacher_loss 1.3947 (1.2117) loss_zs_kd 0.0881 (0.1350) loss_oracle 0.0172 (0.0192) acc 62.5000 (67.0312) kd_loss 0.0097 (0.0090) lr 1.9823e-03 eta 0:41:39
epoch [5/50] batch [40/244] time 0.151 (0.193) data 0.000 (0.008) loss 1.1549 (1.1998) ce_loss 1.0625 (1.1175) teacher_loss 1.0673 (1.1185) loss_zs_kd 0.1344 (0.1260) loss_oracle 0.0204 (0.0183) acc 71.8750 (70.0781) kd_loss 0.0081 (0.0090) lr 1.9823e-03 eta 0:35:54
epoch [5/50] batch [60/244] time 0.156 (0.182) data 0.001 (0.006) loss 1.1654 (1.2002) ce_loss 1.0771 (1.1177) teacher_loss 1.0771 (1.1188) loss_zs_kd 0.1392 (0.1240) loss_oracle 0.0187 (0.0194) acc 68.7500 (69.7396) kd_loss 0.0105 (0.0091) lr 1.9823e-03 eta 0:33:48
epoch [5/50] batch [80/244] time 0.159 (0.177) data 0.000 (0.004) loss 1.4444 (1.2001) ce_loss 1.3623 (1.1162) teacher_loss 1.3589 (1.1171) loss_zs_kd 0.1355 (0.1278) loss_oracle 0.0177 (0.0191) acc 65.6250 (70.7422) kd_loss 0.0096 (0.0093) lr 1.9823e-03 eta 0:32:47
epoch [5/50] batch [100/244] time 0.177 (0.173) data 0.000 (0.003) loss 1.6307 (1.2057) ce_loss 1.5684 (1.1231) teacher_loss 1.5672 (1.1238) loss_zs_kd 0.0911 (0.1264) loss_oracle 0.0179 (0.0186) acc 65.6250 (70.5000) kd_loss 0.0101 (0.0094) lr 1.9823e-03 eta 0:32:09
epoch [5/50] batch [120/244] time 0.176 (0.172) data 0.000 (0.003) loss 1.1424 (1.2223) ce_loss 1.0625 (1.1395) teacher_loss 1.0594 (1.1399) loss_zs_kd 0.1246 (0.1272) loss_oracle 0.0207 (0.0188) acc 75.0000 (70.0000) kd_loss 0.0115 (0.0097) lr 1.9823e-03 eta 0:31:50
epoch [5/50] batch [140/244] time 0.087 (0.173) data 0.000 (0.003) loss 1.3513 (1.2200) ce_loss 1.2744 (1.1378) teacher_loss 1.2641 (1.1380) loss_zs_kd 0.1238 (0.1266) loss_oracle 0.0253 (0.0188) acc 62.5000 (70.1116) kd_loss 0.0169 (0.0098) lr 1.9823e-03 eta 0:31:58
epoch [5/50] batch [160/244] time 0.151 (0.176) data 0.000 (0.002) loss 1.0400 (1.2293) ce_loss 0.9604 (1.1484) teacher_loss 0.9615 (1.1485) loss_zs_kd 0.1071 (0.1242) loss_oracle 0.0250 (0.0187) acc 78.1250 (69.7070) kd_loss 0.0106 (0.0098) lr 1.9823e-03 eta 0:32:26
epoch [5/50] batch [180/244] time 0.172 (0.174) data 0.000 (0.002) loss 1.5469 (1.2288) ce_loss 1.4346 (1.1478) teacher_loss 1.4365 (1.1479) loss_zs_kd 0.1679 (0.1234) loss_oracle 0.0265 (0.0192) acc 68.7500 (69.9306) kd_loss 0.0119 (0.0099) lr 1.9823e-03 eta 0:31:57
epoch [5/50] batch [200/244] time 0.166 (0.172) data 0.000 (0.002) loss 1.2245 (1.2275) ce_loss 1.1523 (1.1467) teacher_loss 1.1552 (1.1468) loss_zs_kd 0.1069 (0.1231) loss_oracle 0.0159 (0.0192) acc 75.0000 (69.9219) kd_loss 0.0086 (0.0099) lr 1.9823e-03 eta 0:31:31
epoch [5/50] batch [220/244] time 0.151 (0.170) data 0.000 (0.002) loss 1.5653 (1.2287) ce_loss 1.4326 (1.1474) teacher_loss 1.4286 (1.1474) loss_zs_kd 0.2315 (0.1243) loss_oracle 0.0210 (0.0191) acc 56.2500 (69.9574) kd_loss 0.0132 (0.0100) lr 1.9823e-03 eta 0:31:10
epoch [5/50] batch [240/244] time 0.148 (0.169) data 0.000 (0.002) loss 1.5652 (1.2275) ce_loss 1.4287 (1.1463) teacher_loss 1.4244 (1.1463) loss_zs_kd 0.2372 (0.1241) loss_oracle 0.0222 (0.0191) acc 68.7500 (70.0521) kd_loss 0.0117 (0.0100) lr 1.9823e-03 eta 0:30:55
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,792
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 82.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,046
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.8%, epoch: 4 *******
******* Domain p best val test acc: 90.9%, epoch: 4 *******
******* Domain p best test acc:     91.1%, epoch: 5 *******
epoch [6/50] batch [20/244] time 0.145 (0.214) data 0.000 (0.013) loss 1.3792 (1.1872) ce_loss 1.3066 (1.1064) teacher_loss 1.3037 (1.1057) loss_zs_kd 0.1140 (0.1235) loss_oracle 0.0185 (0.0198) acc 71.8750 (71.0938) kd_loss 0.0100 (0.0101) lr 1.9686e-03 eta 0:39:06
epoch [6/50] batch [40/244] time 0.146 (0.184) data 0.000 (0.007) loss 1.3969 (1.2239) ce_loss 1.3193 (1.1406) teacher_loss 1.3242 (1.1403) loss_zs_kd 0.1097 (0.1268) loss_oracle 0.0179 (0.0202) acc 68.7500 (70.4688) kd_loss 0.0075 (0.0101) lr 1.9686e-03 eta 0:33:34
epoch [6/50] batch [60/244] time 0.170 (0.175) data 0.000 (0.005) loss 1.4957 (1.2269) ce_loss 1.3789 (1.1453) teacher_loss 1.3781 (1.1451) loss_zs_kd 0.1803 (0.1230) loss_oracle 0.0274 (0.0203) acc 65.6250 (70.6250) kd_loss 0.0112 (0.0101) lr 1.9686e-03 eta 0:31:46
epoch [6/50] batch [80/244] time 0.156 (0.169) data 0.000 (0.003) loss 1.1018 (1.2279) ce_loss 1.0225 (1.1458) teacher_loss 1.0248 (1.1456) loss_zs_kd 0.1146 (0.1220) loss_oracle 0.0196 (0.0212) acc 71.8750 (70.2734) kd_loss 0.0077 (0.0102) lr 1.9686e-03 eta 0:30:46
epoch [6/50] batch [100/244] time 0.146 (0.166) data 0.000 (0.003) loss 1.5550 (1.2241) ce_loss 1.4707 (1.1429) teacher_loss 1.4672 (1.1428) loss_zs_kd 0.1235 (0.1201) loss_oracle 0.0261 (0.0212) acc 53.1250 (70.1875) kd_loss 0.0148 (0.0103) lr 1.9686e-03 eta 0:30:08
epoch [6/50] batch [120/244] time 0.157 (0.164) data 0.000 (0.002) loss 1.3480 (1.2267) ce_loss 1.2471 (1.1457) teacher_loss 1.2473 (1.1457) loss_zs_kd 0.1525 (0.1201) loss_oracle 0.0245 (0.0209) acc 62.5000 (70.1042) kd_loss 0.0115 (0.0102) lr 1.9686e-03 eta 0:29:41
epoch [6/50] batch [140/244] time 0.161 (0.163) data 0.000 (0.002) loss 1.5531 (1.2411) ce_loss 1.4775 (1.1575) teacher_loss 1.4761 (1.1576) loss_zs_kd 0.1076 (0.1238) loss_oracle 0.0232 (0.0216) acc 62.5000 (69.8214) kd_loss 0.0093 (0.0102) lr 1.9686e-03 eta 0:29:23
epoch [6/50] batch [160/244] time 0.379 (0.168) data 0.000 (0.002) loss 0.9020 (1.2414) ce_loss 0.8008 (1.1568) teacher_loss 0.8017 (1.1570) loss_zs_kd 0.1490 (0.1250) loss_oracle 0.0259 (0.0220) acc 75.0000 (69.7852) kd_loss 0.0116 (0.0102) lr 1.9686e-03 eta 0:30:21
epoch [6/50] batch [180/244] time 0.155 (0.171) data 0.000 (0.002) loss 1.0242 (1.2424) ce_loss 0.9102 (1.1566) teacher_loss 0.9117 (1.1568) loss_zs_kd 0.1718 (0.1265) loss_oracle 0.0265 (0.0223) acc 75.0000 (69.8785) kd_loss 0.0120 (0.0104) lr 1.9686e-03 eta 0:30:47
epoch [6/50] batch [200/244] time 0.148 (0.170) data 0.000 (0.002) loss 1.3240 (1.2441) ce_loss 1.2217 (1.1580) teacher_loss 1.2193 (1.1582) loss_zs_kd 0.1663 (0.1267) loss_oracle 0.0215 (0.0225) acc 71.8750 (69.7969) kd_loss 0.0113 (0.0105) lr 1.9686e-03 eta 0:30:33
epoch [6/50] batch [220/244] time 0.169 (0.169) data 0.000 (0.001) loss 1.3483 (1.2475) ce_loss 1.2568 (1.1614) teacher_loss 1.2493 (1.1615) loss_zs_kd 0.1381 (0.1275) loss_oracle 0.0300 (0.0222) acc 68.7500 (69.6875) kd_loss 0.0148 (0.0106) lr 1.9686e-03 eta 0:30:15
epoch [6/50] batch [240/244] time 0.155 (0.168) data 0.000 (0.001) loss 1.4143 (1.2408) ce_loss 1.3301 (1.1551) teacher_loss 1.3273 (1.1553) loss_zs_kd 0.1322 (0.1265) loss_oracle 0.0209 (0.0223) acc 56.2500 (69.7396) kd_loss 0.0134 (0.0106) lr 1.9686e-03 eta 0:29:59
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,798
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,031
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
******* Domain p best val acc:      83.9%, epoch: 6 *******
******* Domain p best val test acc: 90.8%, epoch: 6 *******
******* Domain p best test acc:     91.1%, epoch: 5 *******
epoch [7/50] batch [20/244] time 0.087 (0.203) data 0.000 (0.014) loss 1.1805 (1.3319) ce_loss 1.0947 (1.2436) teacher_loss 1.0971 (1.2435) loss_zs_kd 0.1182 (0.1236) loss_oracle 0.0243 (0.0266) acc 68.7500 (66.2500) kd_loss 0.0097 (0.0117) lr 1.9511e-03 eta 0:36:17
epoch [7/50] batch [40/244] time 0.157 (0.198) data 0.000 (0.007) loss 1.0172 (1.2618) ce_loss 0.9321 (1.1747) teacher_loss 0.9296 (1.1749) loss_zs_kd 0.1211 (0.1215) loss_oracle 0.0271 (0.0262) acc 75.0000 (68.4375) kd_loss 0.0142 (0.0113) lr 1.9511e-03 eta 0:35:15
epoch [7/50] batch [60/244] time 0.146 (0.186) data 0.001 (0.005) loss 0.8956 (1.2732) ce_loss 0.8174 (1.1846) teacher_loss 0.8147 (1.1851) loss_zs_kd 0.0944 (0.1204) loss_oracle 0.0337 (0.0279) acc 75.0000 (67.5521) kd_loss 0.0157 (0.0120) lr 1.9511e-03 eta 0:33:09
epoch [7/50] batch [80/244] time 0.180 (0.180) data 0.000 (0.004) loss 1.2515 (1.2590) ce_loss 1.0996 (1.1689) teacher_loss 1.1001 (1.1698) loss_zs_kd 0.2412 (0.1240) loss_oracle 0.0308 (0.0272) acc 68.7500 (68.0859) kd_loss 0.0132 (0.0122) lr 1.9511e-03 eta 0:32:02
epoch [7/50] batch [100/244] time 0.149 (0.176) data 0.000 (0.003) loss 1.5599 (1.2487) ce_loss 1.4131 (1.1591) teacher_loss 1.4165 (1.1599) loss_zs_kd 0.2230 (0.1252) loss_oracle 0.0319 (0.0262) acc 62.5000 (68.7500) kd_loss 0.0196 (0.0123) lr 1.9511e-03 eta 0:31:17
epoch [7/50] batch [120/244] time 0.173 (0.174) data 0.000 (0.002) loss 1.2510 (1.2537) ce_loss 1.1797 (1.1637) teacher_loss 1.1810 (1.1643) loss_zs_kd 0.1012 (0.1263) loss_oracle 0.0193 (0.0263) acc 65.6250 (68.9583) kd_loss 0.0102 (0.0126) lr 1.9511e-03 eta 0:30:49
epoch [7/50] batch [140/244] time 0.179 (0.173) data 0.000 (0.002) loss 0.8613 (1.2419) ce_loss 0.7412 (1.1520) teacher_loss 0.7441 (1.1523) loss_zs_kd 0.1574 (0.1263) loss_oracle 0.0385 (0.0265) acc 78.1250 (69.2857) kd_loss 0.0189 (0.0128) lr 1.9511e-03 eta 0:30:31
epoch [7/50] batch [160/244] time 0.095 (0.174) data 0.000 (0.002) loss 1.7299 (1.2442) ce_loss 1.6182 (1.1542) teacher_loss 1.6178 (1.1546) loss_zs_kd 0.1765 (0.1265) loss_oracle 0.0238 (0.0263) acc 62.5000 (69.3359) kd_loss 0.0113 (0.0129) lr 1.9511e-03 eta 0:30:36
epoch [7/50] batch [180/244] time 0.158 (0.176) data 0.000 (0.002) loss 1.1061 (1.2507) ce_loss 1.0020 (1.1598) teacher_loss 0.9989 (1.1601) loss_zs_kd 0.1551 (0.1284) loss_oracle 0.0297 (0.0264) acc 75.0000 (69.2882) kd_loss 0.0178 (0.0129) lr 1.9511e-03 eta 0:30:56
epoch [7/50] batch [200/244] time 0.155 (0.175) data 0.000 (0.002) loss 1.0975 (1.2451) ce_loss 1.0098 (1.1528) teacher_loss 1.0106 (1.1531) loss_zs_kd 0.1237 (0.1296) loss_oracle 0.0251 (0.0271) acc 68.7500 (69.5781) kd_loss 0.0166 (0.0131) lr 1.9511e-03 eta 0:30:39
epoch [7/50] batch [220/244] time 0.169 (0.174) data 0.000 (0.001) loss 1.3190 (1.2507) ce_loss 1.2129 (1.1573) teacher_loss 1.2176 (1.1577) loss_zs_kd 0.1541 (0.1312) loss_oracle 0.0244 (0.0274) acc 75.0000 (69.5170) kd_loss 0.0102 (0.0133) lr 1.9511e-03 eta 0:30:27
epoch [7/50] batch [240/244] time 0.171 (0.173) data 0.000 (0.001) loss 1.0701 (1.2412) ce_loss 0.9463 (1.1486) teacher_loss 0.9476 (1.1490) loss_zs_kd 0.1797 (0.1298) loss_oracle 0.0327 (0.0273) acc 78.1250 (69.8307) kd_loss 0.0175 (0.0134) lr 1.9511e-03 eta 0:30:12
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,785
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,024
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.1%
******* Domain p best val acc:      83.9%, epoch: 6 *******
******* Domain p best val test acc: 90.8%, epoch: 6 *******
******* Domain p best test acc:     91.1%, epoch: 5 *******
epoch [8/50] batch [20/244] time 0.150 (0.256) data 0.000 (0.014) loss 1.3870 (1.3246) ce_loss 1.2939 (1.2298) teacher_loss 1.2969 (1.2297) loss_zs_kd 0.1208 (0.1250) loss_oracle 0.0298 (0.0324) acc 65.6250 (66.2500) kd_loss 0.0128 (0.0149) lr 1.9298e-03 eta 0:44:44
epoch [8/50] batch [40/244] time 0.165 (0.214) data 0.000 (0.007) loss 1.1368 (1.2546) ce_loss 1.0391 (1.1520) teacher_loss 1.0371 (1.1519) loss_zs_kd 0.1373 (0.1368) loss_oracle 0.0311 (0.0343) acc 71.8750 (68.7500) kd_loss 0.0115 (0.0147) lr 1.9298e-03 eta 0:37:14
epoch [8/50] batch [60/244] time 0.167 (0.196) data 0.001 (0.005) loss 1.1042 (1.2432) ce_loss 0.9917 (1.1430) teacher_loss 0.9967 (1.1428) loss_zs_kd 0.1489 (0.1344) loss_oracle 0.0330 (0.0333) acc 78.1250 (69.2708) kd_loss 0.0167 (0.0148) lr 1.9298e-03 eta 0:34:08
epoch [8/50] batch [80/244] time 0.171 (0.188) data 0.000 (0.004) loss 1.3612 (1.2319) ce_loss 1.2217 (1.1325) teacher_loss 1.2204 (1.1325) loss_zs_kd 0.1997 (0.1367) loss_oracle 0.0409 (0.0311) acc 68.7500 (69.4531) kd_loss 0.0219 (0.0145) lr 1.9298e-03 eta 0:32:37
epoch [8/50] batch [100/244] time 0.165 (0.183) data 0.000 (0.003) loss 1.0398 (1.2435) ce_loss 0.9590 (1.1445) teacher_loss 0.9617 (1.1445) loss_zs_kd 0.1074 (0.1371) loss_oracle 0.0244 (0.0304) acc 75.0000 (68.9688) kd_loss 0.0104 (0.0143) lr 1.9298e-03 eta 0:31:37
epoch [8/50] batch [120/244] time 0.170 (0.180) data 0.000 (0.002) loss 1.0856 (1.2329) ce_loss 1.0078 (1.1349) teacher_loss 1.0090 (1.1349) loss_zs_kd 0.1151 (0.1381) loss_oracle 0.0190 (0.0290) acc 75.0000 (69.3490) kd_loss 0.0135 (0.0140) lr 1.9298e-03 eta 0:31:06
epoch [8/50] batch [140/244] time 0.085 (0.179) data 0.000 (0.002) loss 1.5919 (1.2473) ce_loss 1.4844 (1.1510) teacher_loss 1.4829 (1.1509) loss_zs_kd 0.1435 (0.1366) loss_oracle 0.0373 (0.0281) acc 65.6250 (69.2857) kd_loss 0.0194 (0.0141) lr 1.9298e-03 eta 0:30:55
epoch [8/50] batch [160/244] time 0.170 (0.182) data 0.000 (0.002) loss 1.4819 (1.2378) ce_loss 1.3809 (1.1423) teacher_loss 1.3800 (1.1423) loss_zs_kd 0.1494 (0.1362) loss_oracle 0.0271 (0.0274) acc 65.6250 (69.5703) kd_loss 0.0125 (0.0139) lr 1.9298e-03 eta 0:31:18
epoch [8/50] batch [180/244] time 0.144 (0.179) data 0.000 (0.002) loss 1.0571 (1.2322) ce_loss 0.9395 (1.1375) teacher_loss 0.9383 (1.1374) loss_zs_kd 0.1815 (0.1353) loss_oracle 0.0281 (0.0271) acc 78.1250 (69.8438) kd_loss 0.0139 (0.0138) lr 1.9298e-03 eta 0:30:46
epoch [8/50] batch [200/244] time 0.158 (0.177) data 0.000 (0.002) loss 1.2547 (1.2332) ce_loss 1.1865 (1.1399) teacher_loss 1.1885 (1.1396) loss_zs_kd 0.0963 (0.1336) loss_oracle 0.0180 (0.0268) acc 75.0000 (70.1094) kd_loss 0.0105 (0.0137) lr 1.9298e-03 eta 0:30:20
epoch [8/50] batch [220/244] time 0.159 (0.175) data 0.000 (0.001) loss 1.2264 (1.2307) ce_loss 1.1504 (1.1381) teacher_loss 1.1458 (1.1379) loss_zs_kd 0.1147 (0.1328) loss_oracle 0.0232 (0.0264) acc 62.5000 (70.0426) kd_loss 0.0126 (0.0137) lr 1.9298e-03 eta 0:29:58
epoch [8/50] batch [240/244] time 0.151 (0.174) data 0.000 (0.001) loss 1.4382 (1.2345) ce_loss 1.3467 (1.1421) teacher_loss 1.3448 (1.1419) loss_zs_kd 0.1326 (0.1324) loss_oracle 0.0271 (0.0264) acc 68.7500 (70.0000) kd_loss 0.0100 (0.0136) lr 1.9298e-03 eta 0:29:44
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,801
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.0%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.0%, epoch: 8 *******
******* Domain p best val test acc: 90.9%, epoch: 8 *******
******* Domain p best test acc:     91.1%, epoch: 5 *******
epoch [9/50] batch [20/244] time 0.176 (0.218) data 0.000 (0.017) loss 1.5291 (1.3840) ce_loss 1.4365 (1.2739) teacher_loss 1.4316 (1.2730) loss_zs_kd 0.1182 (0.1441) loss_oracle 0.0384 (0.0390) acc 62.5000 (69.0625) kd_loss 0.0132 (0.0145) lr 1.9048e-03 eta 0:37:14
epoch [9/50] batch [40/244] time 0.165 (0.195) data 0.000 (0.009) loss 1.3198 (1.2851) ce_loss 1.2539 (1.1830) teacher_loss 1.2552 (1.1830) loss_zs_kd 0.0793 (0.1296) loss_oracle 0.0250 (0.0373) acc 62.5000 (70.3906) kd_loss 0.0135 (0.0148) lr 1.9048e-03 eta 0:33:14
epoch [9/50] batch [60/244] time 0.171 (0.186) data 0.001 (0.006) loss 1.7784 (1.2762) ce_loss 1.6680 (1.1738) teacher_loss 1.6662 (1.1740) loss_zs_kd 0.1602 (0.1339) loss_oracle 0.0321 (0.0352) acc 59.3750 (70.3125) kd_loss 0.0141 (0.0144) lr 1.9048e-03 eta 0:31:30
epoch [9/50] batch [80/244] time 0.169 (0.180) data 0.000 (0.004) loss 1.7075 (1.2869) ce_loss 1.6182 (1.1810) teacher_loss 1.6142 (1.1808) loss_zs_kd 0.0932 (0.1372) loss_oracle 0.0467 (0.0375) acc 59.3750 (69.7656) kd_loss 0.0162 (0.0149) lr 1.9048e-03 eta 0:30:32
epoch [9/50] batch [100/244] time 0.174 (0.176) data 0.000 (0.004) loss 1.0487 (1.2753) ce_loss 0.9570 (1.1681) teacher_loss 0.9549 (1.1679) loss_zs_kd 0.1113 (0.1357) loss_oracle 0.0381 (0.0395) acc 65.6250 (69.8125) kd_loss 0.0155 (0.0156) lr 1.9048e-03 eta 0:29:46
epoch [9/50] batch [120/244] time 0.418 (0.179) data 0.000 (0.003) loss 1.6414 (1.2771) ce_loss 1.5566 (1.1694) teacher_loss 1.5510 (1.1693) loss_zs_kd 0.1000 (0.1357) loss_oracle 0.0404 (0.0400) acc 59.3750 (69.6354) kd_loss 0.0161 (0.0160) lr 1.9048e-03 eta 0:30:11
epoch [9/50] batch [140/244] time 0.167 (0.181) data 0.000 (0.003) loss 1.0631 (1.2871) ce_loss 0.9917 (1.1798) teacher_loss 0.9942 (1.1794) loss_zs_kd 0.0813 (0.1351) loss_oracle 0.0282 (0.0402) acc 71.8750 (69.2411) kd_loss 0.0128 (0.0166) lr 1.9048e-03 eta 0:30:32
epoch [9/50] batch [160/244] time 0.170 (0.179) data 0.000 (0.002) loss 0.7888 (1.2744) ce_loss 0.6875 (1.1667) teacher_loss 0.6893 (1.1662) loss_zs_kd 0.1190 (0.1362) loss_oracle 0.0400 (0.0401) acc 81.2500 (69.6484) kd_loss 0.0150 (0.0168) lr 1.9048e-03 eta 0:30:06
epoch [9/50] batch [180/244] time 0.158 (0.177) data 0.000 (0.002) loss 1.3699 (1.2682) ce_loss 1.2393 (1.1602) teacher_loss 1.2378 (1.1596) loss_zs_kd 0.1690 (0.1365) loss_oracle 0.0476 (0.0403) acc 68.7500 (69.5486) kd_loss 0.0208 (0.0172) lr 1.9048e-03 eta 0:29:43
epoch [9/50] batch [200/244] time 0.168 (0.176) data 0.000 (0.002) loss 1.3194 (1.2687) ce_loss 1.2158 (1.1590) teacher_loss 1.2187 (1.1585) loss_zs_kd 0.1131 (0.1383) loss_oracle 0.0441 (0.0411) acc 65.6250 (69.5781) kd_loss 0.0226 (0.0175) lr 1.9048e-03 eta 0:29:25
epoch [9/50] batch [220/244] time 0.154 (0.174) data 0.000 (0.002) loss 1.5563 (1.2680) ce_loss 1.4199 (1.1577) teacher_loss 1.4192 (1.1572) loss_zs_kd 0.1845 (0.1382) loss_oracle 0.0449 (0.0417) acc 71.8750 (69.6449) kd_loss 0.0188 (0.0179) lr 1.9048e-03 eta 0:29:09
epoch [9/50] batch [240/244] time 0.151 (0.173) data 0.000 (0.002) loss 1.5537 (1.2658) ce_loss 1.4316 (1.1544) teacher_loss 1.4348 (1.1540) loss_zs_kd 0.1687 (0.1391) loss_oracle 0.0345 (0.0423) acc 65.6250 (69.8047) kd_loss 0.0165 (0.0181) lr 1.9048e-03 eta 0:28:50
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,792
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,029
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
******* Domain p best val acc:      84.0%, epoch: 8 *******
******* Domain p best val test acc: 90.9%, epoch: 8 *******
******* Domain p best test acc:     91.1%, epoch: 5 *******
epoch [10/50] batch [20/244] time 0.171 (0.176) data 0.000 (0.015) loss 1.1101 (1.1791) ce_loss 1.0186 (1.0790) teacher_loss 1.0184 (1.0792) loss_zs_kd 0.1083 (0.1249) loss_oracle 0.0375 (0.0375) acc 65.6250 (71.0938) kd_loss 0.0216 (0.0199) lr 1.8763e-03 eta 0:29:21
epoch [10/50] batch [40/244] time 0.158 (0.169) data 0.000 (0.007) loss 1.1369 (1.1929) ce_loss 1.0078 (1.0869) teacher_loss 1.0054 (1.0867) loss_zs_kd 0.1757 (0.1382) loss_oracle 0.0437 (0.0371) acc 81.2500 (71.1719) kd_loss 0.0233 (0.0205) lr 1.8763e-03 eta 0:28:05
epoch [10/50] batch [60/244] time 0.177 (0.167) data 0.001 (0.005) loss 1.2714 (1.2022) ce_loss 1.1738 (1.0965) teacher_loss 1.1776 (1.0968) loss_zs_kd 0.1141 (0.1359) loss_oracle 0.0368 (0.0375) acc 71.8750 (70.8854) kd_loss 0.0188 (0.0199) lr 1.8763e-03 eta 0:27:37
epoch [10/50] batch [80/244] time 0.159 (0.165) data 0.000 (0.004) loss 1.2253 (1.2250) ce_loss 1.1309 (1.1195) teacher_loss 1.1292 (1.1194) loss_zs_kd 0.1050 (0.1331) loss_oracle 0.0436 (0.0390) acc 65.6250 (70.2344) kd_loss 0.0174 (0.0199) lr 1.8763e-03 eta 0:27:16
epoch [10/50] batch [100/244] time 0.181 (0.165) data 0.000 (0.003) loss 1.3495 (1.2374) ce_loss 1.2354 (1.1302) teacher_loss 1.2367 (1.1301) loss_zs_kd 0.1513 (0.1357) loss_oracle 0.0370 (0.0395) acc 62.5000 (70.0625) kd_loss 0.0206 (0.0197) lr 1.8763e-03 eta 0:27:16
epoch [10/50] batch [120/244] time 0.107 (0.165) data 0.000 (0.003) loss 1.5218 (1.2482) ce_loss 1.4297 (1.1378) teacher_loss 1.4238 (1.1380) loss_zs_kd 0.1269 (0.1395) loss_oracle 0.0346 (0.0404) acc 65.6250 (69.8958) kd_loss 0.0153 (0.0198) lr 1.8763e-03 eta 0:27:14
epoch [10/50] batch [140/244] time 0.150 (0.170) data 0.000 (0.002) loss 1.1392 (1.2525) ce_loss 1.0449 (1.1421) teacher_loss 1.0456 (1.1422) loss_zs_kd 0.1071 (0.1407) loss_oracle 0.0401 (0.0399) acc 71.8750 (69.6875) kd_loss 0.0254 (0.0200) lr 1.8763e-03 eta 0:27:54
epoch [10/50] batch [160/244] time 0.151 (0.168) data 0.000 (0.002) loss 0.9444 (1.2384) ce_loss 0.8770 (1.1283) teacher_loss 0.8734 (1.1283) loss_zs_kd 0.0714 (0.1404) loss_oracle 0.0352 (0.0399) acc 75.0000 (70.0977) kd_loss 0.0163 (0.0198) lr 1.8763e-03 eta 0:27:33
epoch [10/50] batch [180/244] time 0.159 (0.167) data 0.001 (0.002) loss 1.3806 (1.2347) ce_loss 1.2803 (1.1250) teacher_loss 1.2786 (1.1250) loss_zs_kd 0.1208 (0.1400) loss_oracle 0.0416 (0.0397) acc 75.0000 (70.2604) kd_loss 0.0188 (0.0196) lr 1.8763e-03 eta 0:27:16
epoch [10/50] batch [200/244] time 0.171 (0.166) data 0.000 (0.002) loss 1.2673 (1.2476) ce_loss 1.1738 (1.1379) teacher_loss 1.1719 (1.1378) loss_zs_kd 0.1238 (0.1405) loss_oracle 0.0335 (0.0395) acc 65.6250 (69.9531) kd_loss 0.0142 (0.0193) lr 1.8763e-03 eta 0:27:02
epoch [10/50] batch [220/244] time 0.153 (0.165) data 0.000 (0.002) loss 1.1413 (1.2553) ce_loss 1.0029 (1.1461) teacher_loss 0.9995 (1.1458) loss_zs_kd 0.1939 (0.1403) loss_oracle 0.0448 (0.0394) acc 81.2500 (69.9006) kd_loss 0.0183 (0.0193) lr 1.8763e-03 eta 0:26:51
epoch [10/50] batch [240/244] time 0.154 (0.164) data 0.000 (0.001) loss 1.6623 (1.2580) ce_loss 1.5400 (1.1487) teacher_loss 1.5414 (1.1485) loss_zs_kd 0.1769 (0.1409) loss_oracle 0.0325 (0.0390) acc 59.3750 (69.7786) kd_loss 0.0129 (0.0190) lr 1.8763e-03 eta 0:26:45
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,804
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.0%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,048
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.7%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      84.1%, epoch: 10 *******
******* Domain p best val test acc: 91.2%, epoch: 10 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [11/50] batch [20/244] time 0.171 (0.179) data 0.000 (0.014) loss 0.8867 (1.2235) ce_loss 0.8032 (1.1245) teacher_loss 0.8069 (1.1246) loss_zs_kd 0.0990 (0.1274) loss_oracle 0.0303 (0.0352) acc 75.0000 (70.9375) kd_loss 0.0172 (0.0176) lr 1.8443e-03 eta 0:29:04
epoch [11/50] batch [40/244] time 0.166 (0.170) data 0.000 (0.007) loss 1.2378 (1.2285) ce_loss 1.1348 (1.1264) teacher_loss 1.1305 (1.1256) loss_zs_kd 0.1280 (0.1317) loss_oracle 0.0434 (0.0370) acc 75.0000 (70.7031) kd_loss 0.0163 (0.0178) lr 1.8443e-03 eta 0:27:31
epoch [11/50] batch [60/244] time 0.160 (0.167) data 0.001 (0.005) loss 1.0403 (1.2328) ce_loss 0.9565 (1.1288) teacher_loss 0.9594 (1.1283) loss_zs_kd 0.1156 (0.1350) loss_oracle 0.0231 (0.0370) acc 75.0000 (70.7812) kd_loss 0.0108 (0.0179) lr 1.8443e-03 eta 0:26:57
epoch [11/50] batch [80/244] time 0.154 (0.165) data 0.000 (0.004) loss 1.1666 (1.2267) ce_loss 1.0859 (1.1243) teacher_loss 1.0831 (1.1235) loss_zs_kd 0.1210 (0.1341) loss_oracle 0.0230 (0.0362) acc 68.7500 (70.8203) kd_loss 0.0099 (0.0177) lr 1.8443e-03 eta 0:26:37
epoch [11/50] batch [100/244] time 0.085 (0.164) data 0.000 (0.003) loss 1.1884 (1.2103) ce_loss 1.0576 (1.1066) teacher_loss 1.0632 (1.1059) loss_zs_kd 0.1443 (0.1344) loss_oracle 0.0531 (0.0372) acc 71.8750 (70.7812) kd_loss 0.0245 (0.0180) lr 1.8443e-03 eta 0:26:19
epoch [11/50] batch [120/244] time 0.350 (0.167) data 0.000 (0.003) loss 1.0518 (1.2245) ce_loss 0.9663 (1.1194) teacher_loss 0.9737 (1.1189) loss_zs_kd 0.0932 (0.1369) loss_oracle 0.0316 (0.0371) acc 78.1250 (70.7292) kd_loss 0.0154 (0.0180) lr 1.8443e-03 eta 0:26:53
epoch [11/50] batch [140/244] time 0.164 (0.170) data 0.000 (0.002) loss 0.6372 (1.2271) ce_loss 0.5767 (1.1240) teacher_loss 0.5780 (1.1237) loss_zs_kd 0.0722 (0.1346) loss_oracle 0.0231 (0.0361) acc 84.3750 (70.6250) kd_loss 0.0122 (0.0179) lr 1.8443e-03 eta 0:27:19
epoch [11/50] batch [160/244] time 0.180 (0.170) data 0.001 (0.002) loss 1.1791 (1.2360) ce_loss 1.0605 (1.1340) teacher_loss 1.0570 (1.1333) loss_zs_kd 0.1704 (0.1348) loss_oracle 0.0370 (0.0353) acc 75.0000 (70.4492) kd_loss 0.0228 (0.0178) lr 1.8443e-03 eta 0:27:13
epoch [11/50] batch [180/244] time 0.173 (0.170) data 0.000 (0.002) loss 1.1504 (1.2305) ce_loss 1.0576 (1.1285) teacher_loss 1.0611 (1.1277) loss_zs_kd 0.1134 (0.1347) loss_oracle 0.0327 (0.0355) acc 75.0000 (70.4514) kd_loss 0.0120 (0.0177) lr 1.8443e-03 eta 0:27:03
epoch [11/50] batch [200/244] time 0.167 (0.169) data 0.000 (0.002) loss 1.3142 (1.2293) ce_loss 1.2402 (1.1274) teacher_loss 1.2381 (1.1266) loss_zs_kd 0.0754 (0.1345) loss_oracle 0.0384 (0.0355) acc 68.7500 (70.4219) kd_loss 0.0161 (0.0176) lr 1.8443e-03 eta 0:26:56
epoch [11/50] batch [220/244] time 0.169 (0.168) data 0.000 (0.001) loss 0.6931 (1.2163) ce_loss 0.5869 (1.1141) teacher_loss 0.5878 (1.1134) loss_zs_kd 0.0948 (0.1341) loss_oracle 0.0578 (0.0358) acc 90.6250 (70.8665) kd_loss 0.0210 (0.0174) lr 1.8443e-03 eta 0:26:46
epoch [11/50] batch [240/244] time 0.333 (0.170) data 0.000 (0.001) loss 0.9792 (1.2175) ce_loss 0.8604 (1.1151) teacher_loss 0.8613 (1.1142) loss_zs_kd 0.1622 (0.1340) loss_oracle 0.0368 (0.0363) acc 75.0000 (70.8724) kd_loss 0.0166 (0.0174) lr 1.8443e-03 eta 0:26:57
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,808
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.1%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,046
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      84.2%, epoch: 11 *******
******* Domain p best val test acc: 91.1%, epoch: 11 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [12/50] batch [20/244] time 0.110 (0.118) data 0.000 (0.013) loss 1.3882 (1.1647) ce_loss 1.2324 (1.0465) teacher_loss 1.2360 (1.0456) loss_zs_kd 0.1956 (0.1443) loss_oracle 0.0544 (0.0470) acc 65.6250 (72.0312) kd_loss 0.0257 (0.0196) lr 1.8090e-03 eta 0:18:38
epoch [12/50] batch [40/244] time 0.142 (0.122) data 0.000 (0.007) loss 1.0923 (1.1920) ce_loss 0.9868 (1.0732) teacher_loss 0.9895 (1.0740) loss_zs_kd 0.1384 (0.1472) loss_oracle 0.0336 (0.0445) acc 78.1250 (71.9531) kd_loss 0.0175 (0.0186) lr 1.8090e-03 eta 0:19:18
epoch [12/50] batch [60/244] time 0.170 (0.133) data 0.000 (0.005) loss 1.1498 (1.2114) ce_loss 1.0625 (1.0982) teacher_loss 1.0635 (1.0984) loss_zs_kd 0.0953 (0.1433) loss_oracle 0.0386 (0.0414) acc 68.7500 (71.8750) kd_loss 0.0179 (0.0182) lr 1.8090e-03 eta 0:20:58
epoch [12/50] batch [80/244] time 0.157 (0.139) data 0.000 (0.003) loss 0.9699 (1.2306) ce_loss 0.8755 (1.1182) teacher_loss 0.8739 (1.1184) loss_zs_kd 0.1170 (0.1448) loss_oracle 0.0376 (0.0398) acc 78.1250 (71.2109) kd_loss 0.0184 (0.0177) lr 1.8090e-03 eta 0:21:54
epoch [12/50] batch [100/244] time 0.146 (0.142) data 0.000 (0.003) loss 1.3613 (1.2279) ce_loss 1.2598 (1.1160) teacher_loss 1.2599 (1.1160) loss_zs_kd 0.1470 (0.1451) loss_oracle 0.0278 (0.0393) acc 62.5000 (70.7812) kd_loss 0.0159 (0.0177) lr 1.8090e-03 eta 0:22:21
epoch [12/50] batch [120/244] time 0.170 (0.144) data 0.000 (0.002) loss 1.1203 (1.2293) ce_loss 0.9683 (1.1178) teacher_loss 0.9702 (1.1178) loss_zs_kd 0.2157 (0.1443) loss_oracle 0.0422 (0.0393) acc 71.8750 (70.6250) kd_loss 0.0197 (0.0175) lr 1.8090e-03 eta 0:22:35
epoch [12/50] batch [140/244] time 0.150 (0.146) data 0.000 (0.002) loss 1.5956 (1.2466) ce_loss 1.4668 (1.1334) teacher_loss 1.4675 (1.1335) loss_zs_kd 0.1442 (0.1459) loss_oracle 0.0560 (0.0401) acc 56.2500 (70.2009) kd_loss 0.0223 (0.0175) lr 1.8090e-03 eta 0:22:47
epoch [12/50] batch [160/244] time 0.155 (0.147) data 0.000 (0.002) loss 1.3740 (1.2388) ce_loss 1.2754 (1.1256) teacher_loss 1.2757 (1.1257) loss_zs_kd 0.1402 (0.1451) loss_oracle 0.0282 (0.0405) acc 65.6250 (70.3711) kd_loss 0.0134 (0.0176) lr 1.8090e-03 eta 0:22:58
epoch [12/50] batch [180/244] time 0.403 (0.151) data 0.000 (0.002) loss 1.4547 (1.2415) ce_loss 1.3047 (1.1289) teacher_loss 1.3036 (1.1289) loss_zs_kd 0.2250 (0.1457) loss_oracle 0.0386 (0.0397) acc 68.7500 (70.4167) kd_loss 0.0188 (0.0176) lr 1.8090e-03 eta 0:23:29
epoch [12/50] batch [200/244] time 0.117 (0.153) data 0.000 (0.002) loss 1.3466 (1.2347) ce_loss 1.2324 (1.1230) teacher_loss 1.2271 (1.1228) loss_zs_kd 0.1614 (0.1453) loss_oracle 0.0388 (0.0392) acc 62.5000 (70.5312) kd_loss 0.0219 (0.0178) lr 1.8090e-03 eta 0:23:44
epoch [12/50] batch [220/244] time 0.164 (0.154) data 0.000 (0.001) loss 1.4275 (1.2356) ce_loss 1.3418 (1.1237) teacher_loss 1.3382 (1.1236) loss_zs_kd 0.1091 (0.1462) loss_oracle 0.0348 (0.0389) acc 62.5000 (70.4688) kd_loss 0.0151 (0.0176) lr 1.8090e-03 eta 0:23:55
epoch [12/50] batch [240/244] time 0.152 (0.155) data 0.000 (0.001) loss 0.9969 (1.2302) ce_loss 0.9126 (1.1184) teacher_loss 0.9066 (1.1183) loss_zs_kd 0.1073 (0.1460) loss_oracle 0.0366 (0.0389) acc 78.1250 (70.5990) kd_loss 0.0158 (0.0176) lr 1.8090e-03 eta 0:23:56
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,795
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.2%, epoch: 11 *******
******* Domain p best val test acc: 91.1%, epoch: 11 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [13/50] batch [20/244] time 0.148 (0.171) data 0.000 (0.013) loss 0.8218 (1.1476) ce_loss 0.7051 (1.0391) teacher_loss 0.7079 (1.0387) loss_zs_kd 0.1322 (0.1348) loss_oracle 0.0478 (0.0415) acc 84.3750 (72.0312) kd_loss 0.0177 (0.0189) lr 1.7705e-03 eta 0:26:21
epoch [13/50] batch [40/244] time 0.089 (0.159) data 0.000 (0.007) loss 1.1050 (1.1816) ce_loss 0.9824 (1.0715) teacher_loss 0.9861 (1.0706) loss_zs_kd 0.1562 (0.1381) loss_oracle 0.0408 (0.0419) acc 81.2500 (71.0938) kd_loss 0.0190 (0.0195) lr 1.7705e-03 eta 0:24:30
epoch [13/50] batch [60/244] time 0.274 (0.181) data 0.001 (0.005) loss 1.1379 (1.1974) ce_loss 1.0303 (1.0897) teacher_loss 1.0309 (1.0890) loss_zs_kd 0.1758 (0.1384) loss_oracle 0.0191 (0.0392) acc 75.0000 (70.9896) kd_loss 0.0135 (0.0191) lr 1.7705e-03 eta 0:27:43
epoch [13/50] batch [80/244] time 0.147 (0.172) data 0.000 (0.003) loss 1.8035 (1.2276) ce_loss 1.6787 (1.1187) teacher_loss 1.6778 (1.1178) loss_zs_kd 0.1536 (0.1415) loss_oracle 0.0488 (0.0391) acc 53.1250 (70.3125) kd_loss 0.0197 (0.0190) lr 1.7705e-03 eta 0:26:17
epoch [13/50] batch [100/244] time 0.149 (0.169) data 0.000 (0.003) loss 1.6451 (1.2340) ce_loss 1.5625 (1.1242) teacher_loss 1.5653 (1.1235) loss_zs_kd 0.1044 (0.1422) loss_oracle 0.0276 (0.0394) acc 59.3750 (70.2500) kd_loss 0.0124 (0.0187) lr 1.7705e-03 eta 0:25:45
epoch [13/50] batch [120/244] time 0.150 (0.166) data 0.000 (0.002) loss 1.3507 (1.2301) ce_loss 1.2373 (1.1213) teacher_loss 1.2329 (1.1206) loss_zs_kd 0.1366 (0.1402) loss_oracle 0.0494 (0.0394) acc 68.7500 (70.5729) kd_loss 0.0253 (0.0188) lr 1.7705e-03 eta 0:25:21
epoch [13/50] batch [140/244] time 0.157 (0.165) data 0.000 (0.002) loss 1.6719 (1.2431) ce_loss 1.5293 (1.1324) teacher_loss 1.5298 (1.1316) loss_zs_kd 0.1843 (0.1430) loss_oracle 0.0500 (0.0400) acc 65.6250 (70.5357) kd_loss 0.0236 (0.0189) lr 1.7705e-03 eta 0:25:05
epoch [13/50] batch [160/244] time 0.157 (0.164) data 0.000 (0.002) loss 1.6354 (1.2326) ce_loss 1.5127 (1.1220) teacher_loss 1.5065 (1.1214) loss_zs_kd 0.1349 (0.1403) loss_oracle 0.0615 (0.0410) acc 65.6250 (70.7031) kd_loss 0.0237 (0.0190) lr 1.7705e-03 eta 0:24:54
epoch [13/50] batch [180/244] time 0.163 (0.164) data 0.000 (0.002) loss 1.3300 (1.2374) ce_loss 1.2090 (1.1265) teacher_loss 1.2075 (1.1257) loss_zs_kd 0.1708 (0.1404) loss_oracle 0.0371 (0.0415) acc 78.1250 (70.5903) kd_loss 0.0205 (0.0190) lr 1.7705e-03 eta 0:24:49
epoch [13/50] batch [200/244] time 0.089 (0.162) data 0.000 (0.001) loss 1.2206 (1.2393) ce_loss 1.1152 (1.1292) teacher_loss 1.1138 (1.1286) loss_zs_kd 0.1367 (0.1395) loss_oracle 0.0384 (0.0409) acc 71.8750 (70.5000) kd_loss 0.0218 (0.0190) lr 1.7705e-03 eta 0:24:27
epoch [13/50] batch [220/244] time 0.346 (0.166) data 0.000 (0.001) loss 0.7239 (1.2298) ce_loss 0.5811 (1.1205) teacher_loss 0.5827 (1.1200) loss_zs_kd 0.2078 (0.1391) loss_oracle 0.0373 (0.0402) acc 87.5000 (70.7955) kd_loss 0.0197 (0.0191) lr 1.7705e-03 eta 0:25:04
epoch [13/50] batch [240/244] time 0.159 (0.166) data 0.000 (0.001) loss 1.4163 (1.2259) ce_loss 1.3135 (1.1178) teacher_loss 1.3115 (1.1171) loss_zs_kd 0.1454 (0.1389) loss_oracle 0.0321 (0.0394) acc 68.7500 (70.8464) kd_loss 0.0198 (0.0191) lr 1.7705e-03 eta 0:24:55
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,800
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 82.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.2%, epoch: 11 *******
******* Domain p best val test acc: 91.1%, epoch: 11 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [14/50] batch [20/244] time 0.168 (0.182) data 0.000 (0.016) loss 1.1017 (1.2120) ce_loss 0.9795 (1.0998) teacher_loss 0.9848 (1.0987) loss_zs_kd 0.1609 (0.1533) loss_oracle 0.0364 (0.0367) acc 71.8750 (70.1562) kd_loss 0.0163 (0.0193) lr 1.7290e-03 eta 0:27:16
epoch [14/50] batch [40/244] time 0.172 (0.174) data 0.000 (0.008) loss 1.0669 (1.2184) ce_loss 0.9473 (1.1068) teacher_loss 0.9535 (1.1043) loss_zs_kd 0.1490 (0.1545) loss_oracle 0.0390 (0.0369) acc 71.8750 (70.2344) kd_loss 0.0172 (0.0193) lr 1.7290e-03 eta 0:26:04
epoch [14/50] batch [60/244] time 0.366 (0.174) data 0.001 (0.006) loss 1.1678 (1.2125) ce_loss 1.0645 (1.0996) teacher_loss 1.0616 (1.0971) loss_zs_kd 0.1167 (0.1546) loss_oracle 0.0478 (0.0381) acc 81.2500 (70.5729) kd_loss 0.0260 (0.0195) lr 1.7290e-03 eta 0:26:03
epoch [14/50] batch [80/244] time 0.084 (0.176) data 0.000 (0.004) loss 1.0606 (1.1875) ce_loss 0.9702 (1.0742) teacher_loss 0.9709 (1.0723) loss_zs_kd 0.1211 (0.1549) loss_oracle 0.0291 (0.0377) acc 75.0000 (71.3672) kd_loss 0.0167 (0.0190) lr 1.7290e-03 eta 0:26:13
epoch [14/50] batch [100/244] time 0.147 (0.171) data 0.000 (0.003) loss 1.3356 (1.1777) ce_loss 1.2451 (1.0665) teacher_loss 1.2448 (1.0645) loss_zs_kd 0.1122 (0.1515) loss_oracle 0.0347 (0.0374) acc 68.7500 (71.8125) kd_loss 0.0159 (0.0191) lr 1.7290e-03 eta 0:25:26
epoch [14/50] batch [120/244] time 0.163 (0.169) data 0.000 (0.003) loss 1.0108 (1.1638) ce_loss 0.9253 (1.0537) teacher_loss 0.9308 (1.0520) loss_zs_kd 0.0955 (0.1492) loss_oracle 0.0322 (0.0373) acc 81.2500 (72.1094) kd_loss 0.0125 (0.0190) lr 1.7290e-03 eta 0:25:05
epoch [14/50] batch [140/244] time 0.170 (0.167) data 0.000 (0.002) loss 1.5099 (1.1728) ce_loss 1.4033 (1.0629) teacher_loss 1.3989 (1.0611) loss_zs_kd 0.1440 (0.1488) loss_oracle 0.0389 (0.0372) acc 62.5000 (71.8750) kd_loss 0.0184 (0.0189) lr 1.7290e-03 eta 0:24:46
epoch [14/50] batch [160/244] time 0.147 (0.166) data 0.000 (0.002) loss 1.3687 (1.1788) ce_loss 1.2607 (1.0695) teacher_loss 1.2618 (1.0678) loss_zs_kd 0.1615 (0.1487) loss_oracle 0.0261 (0.0366) acc 75.0000 (71.7773) kd_loss 0.0183 (0.0189) lr 1.7290e-03 eta 0:24:29
epoch [14/50] batch [180/244] time 0.171 (0.165) data 0.000 (0.002) loss 1.2757 (1.1686) ce_loss 1.1934 (1.0609) teacher_loss 1.1932 (1.0593) loss_zs_kd 0.0880 (0.1465) loss_oracle 0.0385 (0.0360) acc 68.7500 (71.9792) kd_loss 0.0186 (0.0186) lr 1.7290e-03 eta 0:24:18
epoch [14/50] batch [200/244] time 0.170 (0.164) data 0.000 (0.002) loss 1.0786 (1.1703) ce_loss 0.9810 (1.0630) teacher_loss 0.9795 (1.0615) loss_zs_kd 0.1310 (0.1454) loss_oracle 0.0337 (0.0361) acc 71.8750 (71.8750) kd_loss 0.0178 (0.0186) lr 1.7290e-03 eta 0:24:09
epoch [14/50] batch [220/244] time 0.106 (0.163) data 0.000 (0.002) loss 0.8170 (1.1638) ce_loss 0.7104 (1.0567) teacher_loss 0.6984 (1.0552) loss_zs_kd 0.1381 (0.1460) loss_oracle 0.0495 (0.0356) acc 84.3750 (72.0881) kd_loss 0.0226 (0.0186) lr 1.7290e-03 eta 0:23:53
epoch [14/50] batch [240/244] time 0.087 (0.168) data 0.000 (0.002) loss 1.2779 (1.1735) ce_loss 1.1699 (1.0678) teacher_loss 1.1705 (1.0662) loss_zs_kd 0.1654 (0.1446) loss_oracle 0.0247 (0.0350) acc 68.7500 (71.7578) kd_loss 0.0113 (0.0185) lr 1.7290e-03 eta 0:24:34
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,804
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,035
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.2%, epoch: 11 *******
******* Domain p best val test acc: 91.1%, epoch: 11 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [15/50] batch [20/244] time 0.148 (0.172) data 0.000 (0.014) loss 0.8722 (1.1772) ce_loss 0.7910 (1.0802) teacher_loss 0.7928 (1.0781) loss_zs_kd 0.1030 (0.1300) loss_oracle 0.0279 (0.0341) acc 81.2500 (72.0312) kd_loss 0.0161 (0.0187) lr 1.6845e-03 eta 0:25:09
epoch [15/50] batch [40/244] time 0.164 (0.163) data 0.000 (0.007) loss 0.9075 (1.2190) ce_loss 0.8101 (1.1134) teacher_loss 0.8070 (1.1121) loss_zs_kd 0.1160 (0.1385) loss_oracle 0.0425 (0.0377) acc 75.0000 (70.3906) kd_loss 0.0258 (0.0187) lr 1.6845e-03 eta 0:23:45
epoch [15/50] batch [60/244] time 0.169 (0.161) data 0.001 (0.005) loss 0.6974 (1.2106) ce_loss 0.5830 (1.1029) teacher_loss 0.5882 (1.1016) loss_zs_kd 0.1585 (0.1406) loss_oracle 0.0299 (0.0387) acc 81.2500 (70.9375) kd_loss 0.0171 (0.0199) lr 1.6845e-03 eta 0:23:27
epoch [15/50] batch [80/244] time 0.178 (0.160) data 0.000 (0.004) loss 1.4911 (1.2074) ce_loss 1.3877 (1.1004) teacher_loss 1.3811 (1.0986) loss_zs_kd 0.1282 (0.1408) loss_oracle 0.0460 (0.0384) acc 71.8750 (70.8594) kd_loss 0.0237 (0.0205) lr 1.6845e-03 eta 0:23:15
epoch [15/50] batch [100/244] time 0.084 (0.167) data 0.000 (0.003) loss 1.4049 (1.1942) ce_loss 1.2646 (1.0870) teacher_loss 1.2680 (1.0857) loss_zs_kd 0.2069 (0.1434) loss_oracle 0.0335 (0.0368) acc 59.3750 (71.1875) kd_loss 0.0185 (0.0202) lr 1.6845e-03 eta 0:24:08
epoch [15/50] batch [120/244] time 0.176 (0.165) data 0.000 (0.002) loss 1.0859 (1.1859) ce_loss 0.9746 (1.0787) teacher_loss 0.9655 (1.0776) loss_zs_kd 0.1448 (0.1439) loss_oracle 0.0479 (0.0363) acc 59.3750 (71.1719) kd_loss 0.0224 (0.0199) lr 1.6845e-03 eta 0:23:52
epoch [15/50] batch [140/244] time 0.144 (0.164) data 0.000 (0.002) loss 0.8614 (1.1896) ce_loss 0.7295 (1.0819) teacher_loss 0.7302 (1.0807) loss_zs_kd 0.1862 (0.1445) loss_oracle 0.0381 (0.0366) acc 84.3750 (71.2500) kd_loss 0.0178 (0.0197) lr 1.6845e-03 eta 0:23:35
epoch [15/50] batch [160/244] time 0.152 (0.162) data 0.000 (0.002) loss 1.0666 (1.1969) ce_loss 0.9521 (1.0888) teacher_loss 0.9532 (1.0875) loss_zs_kd 0.1519 (0.1447) loss_oracle 0.0375 (0.0370) acc 78.1250 (71.2109) kd_loss 0.0181 (0.0197) lr 1.6845e-03 eta 0:23:17
epoch [15/50] batch [180/244] time 0.162 (0.162) data 0.000 (0.002) loss 0.7854 (1.1898) ce_loss 0.6860 (1.0815) teacher_loss 0.6881 (1.0803) loss_zs_kd 0.1319 (0.1455) loss_oracle 0.0313 (0.0368) acc 81.2500 (71.3715) kd_loss 0.0153 (0.0196) lr 1.6845e-03 eta 0:23:14
epoch [15/50] batch [200/244] time 0.151 (0.163) data 0.000 (0.002) loss 0.8814 (1.1858) ce_loss 0.7661 (1.0780) teacher_loss 0.7663 (1.0768) loss_zs_kd 0.1846 (0.1459) loss_oracle 0.0228 (0.0361) acc 84.3750 (71.5938) kd_loss 0.0191 (0.0197) lr 1.6845e-03 eta 0:23:15
epoch [15/50] batch [220/244] time 0.153 (0.162) data 0.000 (0.001) loss 1.0785 (1.1936) ce_loss 0.9858 (1.0871) teacher_loss 0.9820 (1.0858) loss_zs_kd 0.1314 (0.1449) loss_oracle 0.0308 (0.0354) acc 84.3750 (71.4347) kd_loss 0.0250 (0.0198) lr 1.6845e-03 eta 0:23:04
epoch [15/50] batch [240/244] time 0.141 (0.161) data 0.000 (0.001) loss 1.1479 (1.1984) ce_loss 0.9810 (1.0922) teacher_loss 0.9772 (1.0909) loss_zs_kd 0.2690 (0.1454) loss_oracle 0.0362 (0.0348) acc 71.8750 (71.2760) kd_loss 0.0290 (0.0199) lr 1.6845e-03 eta 0:22:57
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,814
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.4%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,028
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.2%
******* Domain p best val acc:      84.4%, epoch: 15 *******
******* Domain p best val test acc: 90.7%, epoch: 15 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [16/50] batch [20/244] time 0.147 (0.171) data 0.000 (0.012) loss 0.8550 (1.2398) ce_loss 0.7441 (1.1315) teacher_loss 0.7399 (1.1313) loss_zs_kd 0.1653 (0.1561) loss_oracle 0.0325 (0.0305) acc 75.0000 (69.8438) kd_loss 0.0191 (0.0196) lr 1.6374e-03 eta 0:24:13
epoch [16/50] batch [40/244] time 0.146 (0.163) data 0.000 (0.006) loss 0.8063 (1.2418) ce_loss 0.7148 (1.1298) teacher_loss 0.7133 (1.1293) loss_zs_kd 0.1059 (0.1579) loss_oracle 0.0401 (0.0336) acc 84.3750 (70.5469) kd_loss 0.0229 (0.0198) lr 1.6374e-03 eta 0:23:02
epoch [16/50] batch [60/244] time 0.152 (0.160) data 0.000 (0.004) loss 1.0172 (1.2339) ce_loss 0.8911 (1.1205) teacher_loss 0.8940 (1.1199) loss_zs_kd 0.1698 (0.1574) loss_oracle 0.0384 (0.0353) acc 68.7500 (69.9479) kd_loss 0.0157 (0.0198) lr 1.6374e-03 eta 0:22:33
epoch [16/50] batch [80/244] time 0.171 (0.160) data 0.000 (0.003) loss 1.1986 (1.2466) ce_loss 1.0586 (1.1352) teacher_loss 1.0635 (1.1348) loss_zs_kd 0.2060 (0.1539) loss_oracle 0.0320 (0.0348) acc 65.6250 (70.0391) kd_loss 0.0205 (0.0194) lr 1.6374e-03 eta 0:22:32
epoch [16/50] batch [100/244] time 0.154 (0.160) data 0.000 (0.003) loss 1.0415 (1.2446) ce_loss 0.9268 (1.1344) teacher_loss 0.9296 (1.1337) loss_zs_kd 0.1419 (0.1503) loss_oracle 0.0409 (0.0358) acc 75.0000 (70.1250) kd_loss 0.0173 (0.0196) lr 1.6374e-03 eta 0:22:28
epoch [16/50] batch [120/244] time 0.174 (0.160) data 0.000 (0.002) loss 1.6649 (1.2456) ce_loss 1.5635 (1.1347) teacher_loss 1.5592 (1.1338) loss_zs_kd 0.1141 (0.1474) loss_oracle 0.0486 (0.0380) acc 65.6250 (70.1042) kd_loss 0.0208 (0.0200) lr 1.6374e-03 eta 0:22:30
epoch [16/50] batch [140/244] time 0.083 (0.164) data 0.000 (0.002) loss 0.7782 (1.2314) ce_loss 0.6523 (1.1189) teacher_loss 0.6541 (1.1181) loss_zs_kd 0.1507 (0.1476) loss_oracle 0.0488 (0.0395) acc 84.3750 (70.5134) kd_loss 0.0277 (0.0204) lr 1.6374e-03 eta 0:22:55
epoch [16/50] batch [160/244] time 0.158 (0.166) data 0.000 (0.002) loss 0.7352 (1.2177) ce_loss 0.6367 (1.1060) teacher_loss 0.6395 (1.1054) loss_zs_kd 0.1237 (0.1461) loss_oracle 0.0338 (0.0392) acc 84.3750 (70.7812) kd_loss 0.0231 (0.0206) lr 1.6374e-03 eta 0:23:07
epoch [16/50] batch [180/244] time 0.158 (0.165) data 0.000 (0.002) loss 0.9726 (1.2163) ce_loss 0.8496 (1.1049) teacher_loss 0.8486 (1.1040) loss_zs_kd 0.1655 (0.1459) loss_oracle 0.0413 (0.0393) acc 81.2500 (70.8160) kd_loss 0.0277 (0.0208) lr 1.6374e-03 eta 0:23:02
epoch [16/50] batch [200/244] time 0.172 (0.165) data 0.000 (0.001) loss 1.3585 (1.2233) ce_loss 1.2295 (1.1118) teacher_loss 1.2206 (1.1111) loss_zs_kd 0.1718 (0.1446) loss_oracle 0.0520 (0.0400) acc 71.8750 (70.7188) kd_loss 0.0278 (0.0210) lr 1.6374e-03 eta 0:22:56
epoch [16/50] batch [220/244] time 0.160 (0.164) data 0.000 (0.001) loss 1.8308 (1.2191) ce_loss 1.6709 (1.1073) teacher_loss 1.6628 (1.1065) loss_zs_kd 0.2312 (0.1444) loss_oracle 0.0525 (0.0404) acc 50.0000 (70.7670) kd_loss 0.0294 (0.0212) lr 1.6374e-03 eta 0:22:47
epoch [16/50] batch [240/244] time 0.175 (0.164) data 0.000 (0.001) loss 0.7437 (1.2192) ce_loss 0.6519 (1.1073) teacher_loss 0.6537 (1.1063) loss_zs_kd 0.1078 (0.1445) loss_oracle 0.0360 (0.0406) acc 84.3750 (70.6641) kd_loss 0.0244 (0.0216) lr 1.6374e-03 eta 0:22:41
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,815
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.4%, epoch: 16 *******
******* Domain p best val test acc: 91.0%, epoch: 16 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [17/50] batch [20/244] time 0.102 (0.232) data 0.000 (0.017) loss 1.2589 (1.2501) ce_loss 1.1641 (1.1454) teacher_loss 1.1680 (1.1430) loss_zs_kd 0.1114 (0.1412) loss_oracle 0.0353 (0.0365) acc 68.7500 (68.7500) kd_loss 0.0198 (0.0262) lr 1.5878e-03 eta 0:31:57
epoch [17/50] batch [40/244] time 0.161 (0.196) data 0.000 (0.009) loss 1.2802 (1.2640) ce_loss 1.1973 (1.1604) teacher_loss 1.1867 (1.1581) loss_zs_kd 0.1104 (0.1410) loss_oracle 0.0383 (0.0355) acc 62.5000 (68.2812) kd_loss 0.0281 (0.0256) lr 1.5878e-03 eta 0:26:56
epoch [17/50] batch [60/244] time 0.170 (0.184) data 0.000 (0.006) loss 1.5190 (1.2310) ce_loss 1.4180 (1.1273) teacher_loss 1.4126 (1.1252) loss_zs_kd 0.1459 (0.1407) loss_oracle 0.0334 (0.0355) acc 59.3750 (69.1146) kd_loss 0.0212 (0.0241) lr 1.5878e-03 eta 0:25:17
epoch [17/50] batch [80/244] time 0.168 (0.180) data 0.000 (0.004) loss 0.8320 (1.2422) ce_loss 0.7183 (1.1374) teacher_loss 0.7145 (1.1354) loss_zs_kd 0.1391 (0.1403) loss_oracle 0.0480 (0.0367) acc 81.2500 (69.1406) kd_loss 0.0322 (0.0238) lr 1.5878e-03 eta 0:24:40
epoch [17/50] batch [100/244] time 0.168 (0.178) data 0.000 (0.004) loss 1.0058 (1.2256) ce_loss 0.8862 (1.1199) teacher_loss 0.8890 (1.1178) loss_zs_kd 0.1509 (0.1413) loss_oracle 0.0414 (0.0372) acc 71.8750 (69.7500) kd_loss 0.0237 (0.0239) lr 1.5878e-03 eta 0:24:21
epoch [17/50] batch [120/244] time 0.173 (0.176) data 0.000 (0.003) loss 1.0172 (1.2218) ce_loss 0.9014 (1.1144) teacher_loss 0.9045 (1.1125) loss_zs_kd 0.1689 (0.1439) loss_oracle 0.0283 (0.0373) acc 75.0000 (70.2344) kd_loss 0.0182 (0.0239) lr 1.5878e-03 eta 0:24:00
epoch [17/50] batch [140/244] time 0.177 (0.176) data 0.000 (0.003) loss 1.0325 (1.2191) ce_loss 0.9541 (1.1109) teacher_loss 0.9538 (1.1090) loss_zs_kd 0.0903 (0.1454) loss_oracle 0.0335 (0.0375) acc 68.7500 (70.1786) kd_loss 0.0238 (0.0240) lr 1.5878e-03 eta 0:23:51
epoch [17/50] batch [160/244] time 0.272 (0.182) data 0.000 (0.002) loss 1.0796 (1.2200) ce_loss 0.9551 (1.1122) teacher_loss 0.9569 (1.1102) loss_zs_kd 0.1697 (0.1447) loss_oracle 0.0379 (0.0375) acc 81.2500 (70.2734) kd_loss 0.0269 (0.0242) lr 1.5878e-03 eta 0:24:39
epoch [17/50] batch [180/244] time 0.151 (0.178) data 0.000 (0.002) loss 0.7925 (1.2153) ce_loss 0.6577 (1.1060) teacher_loss 0.6579 (1.1041) loss_zs_kd 0.1550 (0.1466) loss_oracle 0.0572 (0.0379) acc 78.1250 (70.4340) kd_loss 0.0256 (0.0241) lr 1.5878e-03 eta 0:24:04
epoch [17/50] batch [200/244] time 0.154 (0.176) data 0.000 (0.002) loss 0.9074 (1.2259) ce_loss 0.8213 (1.1163) teacher_loss 0.8209 (1.1145) loss_zs_kd 0.1037 (0.1461) loss_oracle 0.0348 (0.0384) acc 68.7500 (70.2812) kd_loss 0.0155 (0.0241) lr 1.5878e-03 eta 0:23:47
epoch [17/50] batch [220/244] time 0.153 (0.175) data 0.000 (0.002) loss 1.0853 (1.2228) ce_loss 0.9858 (1.1136) teacher_loss 0.9888 (1.1119) loss_zs_kd 0.1245 (0.1457) loss_oracle 0.0343 (0.0381) acc 68.7500 (70.5256) kd_loss 0.0272 (0.0240) lr 1.5878e-03 eta 0:23:35
epoch [17/50] batch [240/244] time 0.166 (0.174) data 0.000 (0.002) loss 0.9846 (1.2216) ce_loss 0.8711 (1.1126) teacher_loss 0.8709 (1.1110) loss_zs_kd 0.1542 (0.1454) loss_oracle 0.0367 (0.0379) acc 78.1250 (70.6250) kd_loss 0.0224 (0.0239) lr 1.5878e-03 eta 0:23:23
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,808
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,032
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
******* Domain p best val acc:      84.4%, epoch: 16 *******
******* Domain p best val test acc: 91.0%, epoch: 16 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [18/50] batch [20/244] time 0.165 (0.217) data 0.000 (0.017) loss 1.3129 (1.1887) ce_loss 1.2168 (1.0835) teacher_loss 1.2086 (1.0825) loss_zs_kd 0.1261 (0.1432) loss_oracle 0.0413 (0.0346) acc 71.8750 (71.0938) kd_loss 0.0242 (0.0223) lr 1.5358e-03 eta 0:29:05
epoch [18/50] batch [40/244] time 0.171 (0.190) data 0.000 (0.008) loss 1.2310 (1.2107) ce_loss 1.1260 (1.1088) teacher_loss 1.1254 (1.1076) loss_zs_kd 0.1339 (0.1385) loss_oracle 0.0386 (0.0338) acc 65.6250 (70.8594) kd_loss 0.0196 (0.0223) lr 1.5358e-03 eta 0:25:19
epoch [18/50] batch [60/244] time 0.156 (0.182) data 0.001 (0.006) loss 1.1902 (1.2120) ce_loss 1.0967 (1.1107) teacher_loss 1.0960 (1.1089) loss_zs_kd 0.1282 (0.1373) loss_oracle 0.0301 (0.0344) acc 75.0000 (71.1979) kd_loss 0.0210 (0.0226) lr 1.5358e-03 eta 0:24:11
epoch [18/50] batch [80/244] time 0.175 (0.176) data 0.000 (0.004) loss 1.1008 (1.2404) ce_loss 0.9980 (1.1373) teacher_loss 1.0008 (1.1358) loss_zs_kd 0.1413 (0.1413) loss_oracle 0.0293 (0.0340) acc 78.1250 (70.5078) kd_loss 0.0166 (0.0221) lr 1.5358e-03 eta 0:23:20
epoch [18/50] batch [100/244] time 0.165 (0.172) data 0.000 (0.003) loss 1.6954 (1.2455) ce_loss 1.5566 (1.1406) teacher_loss 1.5556 (1.1392) loss_zs_kd 0.1890 (0.1437) loss_oracle 0.0453 (0.0344) acc 62.5000 (70.0312) kd_loss 0.0305 (0.0219) lr 1.5358e-03 eta 0:22:47
epoch [18/50] batch [120/244] time 0.176 (0.171) data 0.000 (0.003) loss 1.6814 (1.2524) ce_loss 1.5762 (1.1453) teacher_loss 1.5783 (1.1439) loss_zs_kd 0.1400 (0.1461) loss_oracle 0.0332 (0.0355) acc 59.3750 (69.9219) kd_loss 0.0189 (0.0220) lr 1.5358e-03 eta 0:22:33
epoch [18/50] batch [140/244] time 0.138 (0.170) data 0.000 (0.003) loss 0.8200 (1.2415) ce_loss 0.7520 (1.1349) teacher_loss 0.7556 (1.1336) loss_zs_kd 0.0869 (0.1461) loss_oracle 0.0210 (0.0348) acc 71.8750 (70.1786) kd_loss 0.0156 (0.0219) lr 1.5358e-03 eta 0:22:25
epoch [18/50] batch [160/244] time 0.348 (0.177) data 0.000 (0.002) loss 1.2841 (1.2407) ce_loss 1.1406 (1.1334) teacher_loss 1.1433 (1.1323) loss_zs_kd 0.2202 (0.1465) loss_oracle 0.0307 (0.0351) acc 78.1250 (70.2344) kd_loss 0.0194 (0.0218) lr 1.5358e-03 eta 0:23:17
epoch [18/50] batch [180/244] time 0.148 (0.173) data 0.000 (0.002) loss 0.5945 (1.2388) ce_loss 0.5122 (1.1312) teacher_loss 0.5105 (1.1302) loss_zs_kd 0.0791 (0.1455) loss_oracle 0.0444 (0.0359) acc 84.3750 (70.2951) kd_loss 0.0267 (0.0221) lr 1.5358e-03 eta 0:22:44
epoch [18/50] batch [200/244] time 0.153 (0.172) data 0.000 (0.002) loss 1.0913 (1.2275) ce_loss 0.9678 (1.1194) teacher_loss 0.9704 (1.1183) loss_zs_kd 0.1626 (0.1451) loss_oracle 0.0395 (0.0366) acc 75.0000 (70.7188) kd_loss 0.0232 (0.0224) lr 1.5358e-03 eta 0:22:32
epoch [18/50] batch [220/244] time 0.159 (0.171) data 0.000 (0.002) loss 1.2027 (1.2217) ce_loss 1.1006 (1.1139) teacher_loss 1.0898 (1.1125) loss_zs_kd 0.1583 (0.1450) loss_oracle 0.0337 (0.0366) acc 71.8750 (70.8381) kd_loss 0.0258 (0.0226) lr 1.5358e-03 eta 0:22:22
epoch [18/50] batch [240/244] time 0.152 (0.171) data 0.000 (0.002) loss 1.2325 (1.2241) ce_loss 1.1201 (1.1164) teacher_loss 1.1168 (1.1150) loss_zs_kd 0.1599 (0.1453) loss_oracle 0.0358 (0.0364) acc 59.3750 (70.7943) kd_loss 0.0184 (0.0226) lr 1.5358e-03 eta 0:22:13
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,812
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,024
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.1%
******* Domain p best val acc:      84.4%, epoch: 16 *******
******* Domain p best val test acc: 91.0%, epoch: 16 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [19/50] batch [20/244] time 0.179 (0.254) data 0.000 (0.015) loss 1.0353 (1.2630) ce_loss 0.9312 (1.1566) teacher_loss 0.9277 (1.1534) loss_zs_kd 0.1247 (0.1408) loss_oracle 0.0452 (0.0392) acc 75.0000 (69.3750) kd_loss 0.0245 (0.0213) lr 1.4818e-03 eta 0:33:01
epoch [19/50] batch [40/244] time 0.156 (0.209) data 0.000 (0.007) loss 1.3466 (1.2549) ce_loss 1.2129 (1.1378) teacher_loss 1.2041 (1.1351) loss_zs_kd 0.1869 (0.1499) loss_oracle 0.0490 (0.0448) acc 78.1250 (69.9219) kd_loss 0.0283 (0.0234) lr 1.4818e-03 eta 0:27:06
epoch [19/50] batch [60/244] time 0.157 (0.193) data 0.000 (0.005) loss 0.7358 (1.2767) ce_loss 0.6436 (1.1542) teacher_loss 0.6409 (1.1520) loss_zs_kd 0.0990 (0.1550) loss_oracle 0.0454 (0.0472) acc 84.3750 (69.5312) kd_loss 0.0324 (0.0255) lr 1.4818e-03 eta 0:24:56
epoch [19/50] batch [80/244] time 0.154 (0.186) data 0.000 (0.004) loss 1.3196 (1.2563) ce_loss 1.2314 (1.1360) teacher_loss 1.2292 (1.1337) loss_zs_kd 0.1189 (0.1531) loss_oracle 0.0310 (0.0461) acc 59.3750 (69.7266) kd_loss 0.0198 (0.0266) lr 1.4818e-03 eta 0:23:53
epoch [19/50] batch [100/244] time 0.168 (0.181) data 0.000 (0.003) loss 1.6728 (1.2497) ce_loss 1.5303 (1.1330) teacher_loss 1.5300 (1.1311) loss_zs_kd 0.1996 (0.1481) loss_oracle 0.0430 (0.0445) acc 59.3750 (69.9062) kd_loss 0.0289 (0.0267) lr 1.4818e-03 eta 0:23:16
epoch [19/50] batch [120/244] time 0.171 (0.178) data 0.000 (0.003) loss 1.5103 (1.2545) ce_loss 1.3584 (1.1381) teacher_loss 1.3501 (1.1360) loss_zs_kd 0.1734 (0.1470) loss_oracle 0.0734 (0.0450) acc 65.6250 (69.6094) kd_loss 0.0448 (0.0270) lr 1.4818e-03 eta 0:22:45
epoch [19/50] batch [140/244] time 0.094 (0.174) data 0.000 (0.002) loss 1.3467 (1.2464) ce_loss 1.2266 (1.1308) teacher_loss 1.2201 (1.1288) loss_zs_kd 0.1747 (0.1455) loss_oracle 0.0393 (0.0448) acc 68.7500 (69.9554) kd_loss 0.0210 (0.0271) lr 1.4818e-03 eta 0:22:13
epoch [19/50] batch [160/244] time 0.327 (0.180) data 0.000 (0.002) loss 1.1607 (1.2435) ce_loss 1.0537 (1.1286) teacher_loss 1.0589 (1.1268) loss_zs_kd 0.1481 (0.1457) loss_oracle 0.0278 (0.0438) acc 78.1250 (70.0391) kd_loss 0.0160 (0.0267) lr 1.4818e-03 eta 0:22:53
epoch [19/50] batch [180/244] time 0.155 (0.175) data 0.000 (0.002) loss 0.8965 (1.2395) ce_loss 0.7773 (1.1246) teacher_loss 0.7708 (1.1229) loss_zs_kd 0.1537 (0.1464) loss_oracle 0.0488 (0.0434) acc 84.3750 (70.1910) kd_loss 0.0324 (0.0267) lr 1.4818e-03 eta 0:22:16
epoch [19/50] batch [200/244] time 0.165 (0.173) data 0.000 (0.002) loss 1.0843 (1.2218) ce_loss 0.9585 (1.1072) teacher_loss 0.9381 (1.1053) loss_zs_kd 0.1944 (0.1472) loss_oracle 0.0491 (0.0429) acc 68.7500 (70.6094) kd_loss 0.0375 (0.0267) lr 1.4818e-03 eta 0:21:57
epoch [19/50] batch [220/244] time 0.159 (0.171) data 0.000 (0.002) loss 1.1836 (1.2218) ce_loss 1.1094 (1.1081) teacher_loss 1.1067 (1.1062) loss_zs_kd 0.0946 (0.1466) loss_oracle 0.0296 (0.0422) acc 75.0000 (70.7244) kd_loss 0.0185 (0.0265) lr 1.4818e-03 eta 0:21:41
epoch [19/50] batch [240/244] time 0.152 (0.170) data 0.000 (0.001) loss 1.3403 (1.2111) ce_loss 1.2314 (1.0984) teacher_loss 1.2285 (1.0967) loss_zs_kd 0.1593 (0.1458) loss_oracle 0.0321 (0.0415) acc 71.8750 (70.8854) kd_loss 0.0290 (0.0262) lr 1.4818e-03 eta 0:21:28
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,811
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.4%
******* Domain p best val acc:      84.4%, epoch: 16 *******
******* Domain p best val test acc: 91.0%, epoch: 16 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [20/50] batch [20/244] time 0.087 (0.222) data 0.000 (0.013) loss 1.2675 (1.1892) ce_loss 1.1699 (1.0813) teacher_loss 1.1695 (1.0799) loss_zs_kd 0.1444 (0.1466) loss_oracle 0.0259 (0.0361) acc 62.5000 (71.5625) kd_loss 0.0198 (0.0245) lr 1.4258e-03 eta 0:27:55
epoch [20/50] batch [40/244] time 0.154 (0.189) data 0.000 (0.007) loss 1.1757 (1.1909) ce_loss 1.0801 (1.0839) teacher_loss 1.0778 (1.0833) loss_zs_kd 0.1030 (0.1439) loss_oracle 0.0465 (0.0357) acc 81.2500 (72.4219) kd_loss 0.0298 (0.0224) lr 1.4258e-03 eta 0:23:40
epoch [20/50] batch [60/244] time 0.156 (0.183) data 0.000 (0.005) loss 1.2690 (1.1866) ce_loss 1.1465 (1.0782) teacher_loss 1.1484 (1.0774) loss_zs_kd 0.1514 (0.1417) loss_oracle 0.0449 (0.0383) acc 68.7500 (72.3438) kd_loss 0.0239 (0.0218) lr 1.4258e-03 eta 0:22:53
epoch [20/50] batch [80/244] time 0.182 (0.180) data 0.000 (0.004) loss 1.1714 (1.1855) ce_loss 1.0625 (1.0753) teacher_loss 1.0555 (1.0744) loss_zs_kd 0.1420 (0.1425) loss_oracle 0.0449 (0.0398) acc 65.6250 (72.4219) kd_loss 0.0260 (0.0219) lr 1.4258e-03 eta 0:22:27
epoch [20/50] batch [100/244] time 0.163 (0.178) data 0.000 (0.003) loss 1.4391 (1.2168) ce_loss 1.3506 (1.1052) teacher_loss 1.3466 (1.1041) loss_zs_kd 0.1074 (0.1435) loss_oracle 0.0389 (0.0410) acc 71.8750 (71.4688) kd_loss 0.0185 (0.0219) lr 1.4258e-03 eta 0:22:07
epoch [20/50] batch [120/244] time 0.153 (0.175) data 0.000 (0.002) loss 1.0986 (1.2248) ce_loss 0.9878 (1.1126) teacher_loss 0.9871 (1.1116) loss_zs_kd 0.1476 (0.1449) loss_oracle 0.0377 (0.0406) acc 78.1250 (71.5625) kd_loss 0.0229 (0.0217) lr 1.4258e-03 eta 0:21:42
epoch [20/50] batch [140/244] time 0.156 (0.173) data 0.000 (0.002) loss 1.5468 (1.2283) ce_loss 1.4600 (1.1158) teacher_loss 1.4458 (1.1147) loss_zs_kd 0.1105 (0.1451) loss_oracle 0.0457 (0.0410) acc 59.3750 (71.3839) kd_loss 0.0194 (0.0218) lr 1.4258e-03 eta 0:21:23
epoch [20/50] batch [160/244] time 0.386 (0.175) data 0.000 (0.002) loss 0.7765 (1.2227) ce_loss 0.6968 (1.1117) teacher_loss 0.7003 (1.1106) loss_zs_kd 0.0690 (0.1428) loss_oracle 0.0417 (0.0408) acc 84.3750 (71.3867) kd_loss 0.0235 (0.0220) lr 1.4258e-03 eta 0:21:32
epoch [20/50] batch [180/244] time 0.182 (0.177) data 0.000 (0.002) loss 1.3624 (1.2132) ce_loss 1.2168 (1.1031) teacher_loss 1.2199 (1.1020) loss_zs_kd 0.1900 (0.1415) loss_oracle 0.0475 (0.0405) acc 65.6250 (71.4062) kd_loss 0.0255 (0.0218) lr 1.4258e-03 eta 0:21:49
epoch [20/50] batch [200/244] time 0.158 (0.176) data 0.000 (0.002) loss 0.7745 (1.2160) ce_loss 0.6592 (1.1049) teacher_loss 0.6545 (1.1036) loss_zs_kd 0.1463 (0.1428) loss_oracle 0.0469 (0.0409) acc 75.0000 (71.1875) kd_loss 0.0270 (0.0220) lr 1.4258e-03 eta 0:21:35
epoch [20/50] batch [220/244] time 0.151 (0.174) data 0.000 (0.001) loss 1.2070 (1.2104) ce_loss 1.0498 (1.0986) teacher_loss 1.0495 (1.0972) loss_zs_kd 0.2333 (0.1440) loss_oracle 0.0408 (0.0412) acc 78.1250 (71.3494) kd_loss 0.0198 (0.0221) lr 1.4258e-03 eta 0:21:20
epoch [20/50] batch [240/244] time 0.152 (0.173) data 0.000 (0.001) loss 0.8870 (1.2094) ce_loss 0.7886 (1.0973) teacher_loss 0.7885 (1.0957) loss_zs_kd 0.1229 (0.1443) loss_oracle 0.0370 (0.0415) acc 78.1250 (71.2630) kd_loss 0.0160 (0.0220) lr 1.4258e-03 eta 0:21:07
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,814
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.4%, epoch: 16 *******
******* Domain p best val test acc: 91.0%, epoch: 16 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [21/50] batch [20/244] time 0.343 (0.222) data 0.000 (0.015) loss 0.8327 (1.1589) ce_loss 0.7324 (1.0437) teacher_loss 0.7312 (1.0436) loss_zs_kd 0.1265 (0.1474) loss_oracle 0.0382 (0.0415) acc 78.1250 (71.2500) kd_loss 0.0153 (0.0206) lr 1.3681e-03 eta 0:26:57
epoch [21/50] batch [40/244] time 0.163 (0.195) data 0.000 (0.007) loss 0.8331 (1.1648) ce_loss 0.7095 (1.0508) teacher_loss 0.7115 (1.0505) loss_zs_kd 0.1791 (0.1489) loss_oracle 0.0320 (0.0398) acc 81.2500 (71.3281) kd_loss 0.0154 (0.0201) lr 1.3681e-03 eta 0:23:36
epoch [21/50] batch [60/244] time 0.161 (0.185) data 0.000 (0.005) loss 0.9806 (1.1944) ce_loss 0.8945 (1.0819) teacher_loss 0.8922 (1.0810) loss_zs_kd 0.1062 (0.1475) loss_oracle 0.0353 (0.0397) acc 71.8750 (70.5729) kd_loss 0.0188 (0.0203) lr 1.3681e-03 eta 0:22:22
epoch [21/50] batch [80/244] time 0.150 (0.177) data 0.000 (0.004) loss 0.9908 (1.2121) ce_loss 0.8398 (1.0984) teacher_loss 0.8459 (1.0975) loss_zs_kd 0.2176 (0.1498) loss_oracle 0.0361 (0.0397) acc 81.2500 (70.4688) kd_loss 0.0183 (0.0206) lr 1.3681e-03 eta 0:21:24
epoch [21/50] batch [100/244] time 0.173 (0.173) data 0.000 (0.003) loss 0.9196 (1.2247) ce_loss 0.7944 (1.1105) teacher_loss 0.8014 (1.1098) loss_zs_kd 0.1596 (0.1515) loss_oracle 0.0383 (0.0391) acc 75.0000 (70.0938) kd_loss 0.0187 (0.0204) lr 1.3681e-03 eta 0:20:51
epoch [21/50] batch [120/244] time 0.152 (0.171) data 0.000 (0.003) loss 1.0350 (1.2314) ce_loss 0.9238 (1.1185) teacher_loss 0.9236 (1.1178) loss_zs_kd 0.1307 (0.1499) loss_oracle 0.0461 (0.0387) acc 75.0000 (70.0521) kd_loss 0.0212 (0.0207) lr 1.3681e-03 eta 0:20:28
epoch [21/50] batch [140/244] time 0.149 (0.169) data 0.000 (0.002) loss 1.4117 (1.2360) ce_loss 1.2969 (1.1235) teacher_loss 1.2953 (1.1226) loss_zs_kd 0.1562 (0.1496) loss_oracle 0.0383 (0.0386) acc 65.6250 (70.1562) kd_loss 0.0239 (0.0211) lr 1.3681e-03 eta 0:20:12
epoch [21/50] batch [160/244] time 0.144 (0.167) data 0.000 (0.002) loss 1.5766 (1.2313) ce_loss 1.4795 (1.1183) teacher_loss 1.4712 (1.1172) loss_zs_kd 0.1081 (0.1497) loss_oracle 0.0514 (0.0392) acc 62.5000 (70.4688) kd_loss 0.0295 (0.0214) lr 1.3681e-03 eta 0:19:57
epoch [21/50] batch [180/244] time 0.343 (0.171) data 0.000 (0.002) loss 0.8128 (1.2192) ce_loss 0.7129 (1.1065) teacher_loss 0.7123 (1.1053) loss_zs_kd 0.1181 (0.1493) loss_oracle 0.0415 (0.0393) acc 81.2500 (70.8681) kd_loss 0.0359 (0.0217) lr 1.3681e-03 eta 0:20:19
epoch [21/50] batch [200/244] time 0.152 (0.169) data 0.000 (0.002) loss 1.1231 (1.2162) ce_loss 0.9829 (1.1041) teacher_loss 0.9838 (1.1027) loss_zs_kd 0.1919 (0.1485) loss_oracle 0.0433 (0.0392) acc 71.8750 (70.9062) kd_loss 0.0299 (0.0220) lr 1.3681e-03 eta 0:20:00
epoch [21/50] batch [220/244] time 0.149 (0.167) data 0.000 (0.002) loss 1.2106 (1.2173) ce_loss 1.0791 (1.1053) teacher_loss 1.0879 (1.1038) loss_zs_kd 0.1923 (0.1483) loss_oracle 0.0265 (0.0394) acc 75.0000 (70.8239) kd_loss 0.0227 (0.0224) lr 1.3681e-03 eta 0:19:48
epoch [21/50] batch [240/244] time 0.149 (0.167) data 0.000 (0.001) loss 1.1714 (1.2267) ce_loss 1.0400 (1.1144) teacher_loss 1.0360 (1.1129) loss_zs_kd 0.1801 (0.1488) loss_oracle 0.0453 (0.0394) acc 71.8750 (70.7812) kd_loss 0.0251 (0.0225) lr 1.3681e-03 eta 0:19:39
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.6%, epoch: 21 *******
******* Domain p best val test acc: 90.9%, epoch: 21 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [22/50] batch [20/244] time 0.147 (0.171) data 0.000 (0.012) loss 1.1900 (1.2081) ce_loss 1.0850 (1.0937) teacher_loss 1.0852 (1.0917) loss_zs_kd 0.1421 (0.1512) loss_oracle 0.0337 (0.0408) acc 75.0000 (70.9375) kd_loss 0.0172 (0.0244) lr 1.3090e-03 eta 0:20:05
epoch [22/50] batch [40/244] time 0.101 (0.165) data 0.000 (0.006) loss 0.8536 (1.2267) ce_loss 0.7656 (1.1123) teacher_loss 0.7571 (1.1101) loss_zs_kd 0.1239 (0.1505) loss_oracle 0.0346 (0.0413) acc 71.8750 (70.3125) kd_loss 0.0238 (0.0249) lr 1.3090e-03 eta 0:19:22
epoch [22/50] batch [60/244] time 0.414 (0.181) data 0.000 (0.004) loss 0.9689 (1.1992) ce_loss 0.8594 (1.0841) teacher_loss 0.8588 (1.0819) loss_zs_kd 0.1375 (0.1534) loss_oracle 0.0414 (0.0406) acc 78.1250 (70.9375) kd_loss 0.0265 (0.0250) lr 1.3090e-03 eta 0:21:09
epoch [22/50] batch [80/244] time 0.155 (0.178) data 0.000 (0.003) loss 1.8612 (1.1995) ce_loss 1.7559 (1.0854) teacher_loss 1.7495 (1.0829) loss_zs_kd 0.1563 (0.1535) loss_oracle 0.0336 (0.0398) acc 50.0000 (71.2891) kd_loss 0.0249 (0.0250) lr 1.3090e-03 eta 0:20:45
epoch [22/50] batch [100/244] time 0.170 (0.175) data 0.000 (0.003) loss 0.9248 (1.1783) ce_loss 0.8159 (1.0653) teacher_loss 0.8107 (1.0628) loss_zs_kd 0.1474 (0.1517) loss_oracle 0.0404 (0.0397) acc 71.8750 (71.8750) kd_loss 0.0234 (0.0249) lr 1.3090e-03 eta 0:20:22
epoch [22/50] batch [120/244] time 0.168 (0.173) data 0.001 (0.002) loss 0.9703 (1.1720) ce_loss 0.8735 (1.0579) teacher_loss 0.8633 (1.0553) loss_zs_kd 0.1379 (0.1534) loss_oracle 0.0380 (0.0399) acc 78.1250 (72.0052) kd_loss 0.0220 (0.0249) lr 1.3090e-03 eta 0:20:01
epoch [22/50] batch [140/244] time 0.153 (0.171) data 0.000 (0.002) loss 1.6347 (1.1771) ce_loss 1.5283 (1.0641) teacher_loss 1.5251 (1.0616) loss_zs_kd 0.1576 (0.1519) loss_oracle 0.0307 (0.0395) acc 53.1250 (71.5179) kd_loss 0.0192 (0.0246) lr 1.3090e-03 eta 0:19:48
epoch [22/50] batch [160/244] time 0.171 (0.170) data 0.000 (0.002) loss 1.1960 (1.1918) ce_loss 1.0859 (1.0781) teacher_loss 1.0886 (1.0758) loss_zs_kd 0.1485 (0.1538) loss_oracle 0.0332 (0.0391) acc 78.1250 (71.3086) kd_loss 0.0182 (0.0245) lr 1.3090e-03 eta 0:19:35
epoch [22/50] batch [180/244] time 0.149 (0.169) data 0.000 (0.002) loss 1.3972 (1.1935) ce_loss 1.2891 (1.0806) teacher_loss 1.2875 (1.0784) loss_zs_kd 0.1466 (0.1522) loss_oracle 0.0364 (0.0390) acc 56.2500 (71.2847) kd_loss 0.0183 (0.0240) lr 1.3090e-03 eta 0:19:25
epoch [22/50] batch [200/244] time 0.097 (0.172) data 0.000 (0.001) loss 1.1461 (1.1903) ce_loss 1.0479 (1.0755) teacher_loss 1.0459 (1.0734) loss_zs_kd 0.1279 (0.1547) loss_oracle 0.0363 (0.0396) acc 78.1250 (71.4375) kd_loss 0.0194 (0.0240) lr 1.3090e-03 eta 0:19:44
epoch [22/50] batch [220/244] time 0.162 (0.171) data 0.000 (0.001) loss 0.8958 (1.1872) ce_loss 0.7686 (1.0725) teacher_loss 0.7672 (1.0704) loss_zs_kd 0.1624 (0.1543) loss_oracle 0.0474 (0.0397) acc 81.2500 (71.6477) kd_loss 0.0275 (0.0239) lr 1.3090e-03 eta 0:19:31
epoch [22/50] batch [240/244] time 0.168 (0.170) data 0.000 (0.001) loss 1.4060 (1.2000) ce_loss 1.2520 (1.0840) teacher_loss 1.2415 (1.0819) loss_zs_kd 0.1934 (0.1551) loss_oracle 0.0677 (0.0405) acc 71.8750 (71.2891) kd_loss 0.0367 (0.0242) lr 1.3090e-03 eta 0:19:21
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,029
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.2%
******* Domain p best val acc:      84.6%, epoch: 21 *******
******* Domain p best val test acc: 90.9%, epoch: 21 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [23/50] batch [20/244] time 0.150 (0.175) data 0.000 (0.017) loss 1.2005 (1.2646) ce_loss 1.1143 (1.1489) teacher_loss 1.1069 (1.1457) loss_zs_kd 0.1118 (0.1503) loss_oracle 0.0377 (0.0437) acc 68.7500 (70.0000) kd_loss 0.0303 (0.0267) lr 1.2487e-03 eta 0:19:52
epoch [23/50] batch [40/244] time 0.155 (0.166) data 0.000 (0.008) loss 1.2068 (1.2479) ce_loss 1.0762 (1.1339) teacher_loss 1.0750 (1.1319) loss_zs_kd 0.1815 (0.1511) loss_oracle 0.0410 (0.0405) acc 65.6250 (70.0781) kd_loss 0.0244 (0.0261) lr 1.2487e-03 eta 0:18:46
epoch [23/50] batch [60/244] time 0.102 (0.163) data 0.001 (0.006) loss 1.2179 (1.2423) ce_loss 1.0967 (1.1259) teacher_loss 1.0955 (1.1242) loss_zs_kd 0.1821 (0.1550) loss_oracle 0.0313 (0.0406) acc 71.8750 (70.7292) kd_loss 0.0198 (0.0261) lr 1.2487e-03 eta 0:18:25
epoch [23/50] batch [80/244] time 0.379 (0.171) data 0.000 (0.004) loss 1.0461 (1.2148) ce_loss 0.9292 (1.0991) teacher_loss 0.9341 (1.0974) loss_zs_kd 0.1642 (0.1540) loss_oracle 0.0298 (0.0403) acc 68.7500 (71.3281) kd_loss 0.0232 (0.0262) lr 1.2487e-03 eta 0:19:17
epoch [23/50] batch [100/244] time 0.168 (0.170) data 0.000 (0.003) loss 1.4725 (1.2019) ce_loss 1.3779 (1.0872) teacher_loss 1.3710 (1.0853) loss_zs_kd 0.1390 (0.1540) loss_oracle 0.0320 (0.0397) acc 62.5000 (71.3125) kd_loss 0.0255 (0.0263) lr 1.2487e-03 eta 0:19:02
epoch [23/50] batch [120/244] time 0.160 (0.169) data 0.000 (0.003) loss 1.3418 (1.1992) ce_loss 1.2217 (1.0851) teacher_loss 1.2257 (1.0832) loss_zs_kd 0.1425 (0.1539) loss_oracle 0.0449 (0.0391) acc 68.7500 (71.3281) kd_loss 0.0212 (0.0260) lr 1.2487e-03 eta 0:18:52
epoch [23/50] batch [140/244] time 0.147 (0.167) data 0.000 (0.003) loss 1.1453 (1.2012) ce_loss 1.0596 (1.0868) teacher_loss 1.0625 (1.0852) loss_zs_kd 0.1093 (0.1538) loss_oracle 0.0281 (0.0391) acc 81.2500 (71.2500) kd_loss 0.0201 (0.0260) lr 1.2487e-03 eta 0:18:36
epoch [23/50] batch [160/244] time 0.167 (0.166) data 0.000 (0.002) loss 1.4279 (1.2004) ce_loss 1.2998 (1.0865) teacher_loss 1.2928 (1.0847) loss_zs_kd 0.1638 (0.1532) loss_oracle 0.0533 (0.0391) acc 59.3750 (71.0742) kd_loss 0.0327 (0.0260) lr 1.2487e-03 eta 0:18:27
epoch [23/50] batch [180/244] time 0.157 (0.166) data 0.000 (0.002) loss 1.0490 (1.2003) ce_loss 0.9551 (1.0864) teacher_loss 0.9551 (1.0848) loss_zs_kd 0.1128 (0.1527) loss_oracle 0.0375 (0.0392) acc 75.0000 (71.1111) kd_loss 0.0184 (0.0258) lr 1.2487e-03 eta 0:18:23
epoch [23/50] batch [200/244] time 0.169 (0.166) data 0.000 (0.002) loss 0.8463 (1.1900) ce_loss 0.7290 (1.0766) teacher_loss 0.7309 (1.0748) loss_zs_kd 0.1656 (0.1521) loss_oracle 0.0326 (0.0392) acc 78.1250 (71.2188) kd_loss 0.0237 (0.0257) lr 1.2487e-03 eta 0:18:17
epoch [23/50] batch [220/244] time 0.357 (0.169) data 0.000 (0.002) loss 1.4703 (1.1948) ce_loss 1.3457 (1.0811) teacher_loss 1.3504 (1.0794) loss_zs_kd 0.1856 (0.1529) loss_oracle 0.0271 (0.0389) acc 65.6250 (71.0369) kd_loss 0.0176 (0.0254) lr 1.2487e-03 eta 0:18:40
epoch [23/50] batch [240/244] time 0.149 (0.169) data 0.000 (0.002) loss 0.7992 (1.1979) ce_loss 0.6904 (1.0838) teacher_loss 0.6906 (1.0822) loss_zs_kd 0.1553 (0.1541) loss_oracle 0.0309 (0.0386) acc 87.5000 (71.1068) kd_loss 0.0201 (0.0253) lr 1.2487e-03 eta 0:18:31
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,815
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,033
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.6%, epoch: 21 *******
******* Domain p best val test acc: 90.9%, epoch: 21 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [24/50] batch [20/244] time 0.156 (0.187) data 0.000 (0.016) loss 1.4050 (1.1409) ce_loss 1.3086 (1.0368) teacher_loss 1.2995 (1.0335) loss_zs_kd 0.1538 (0.1503) loss_oracle 0.0286 (0.0322) acc 65.6250 (72.1875) kd_loss 0.0245 (0.0238) lr 1.1874e-03 eta 0:20:28
epoch [24/50] batch [40/244] time 0.170 (0.173) data 0.000 (0.008) loss 1.8388 (1.2361) ce_loss 1.7305 (1.1296) teacher_loss 1.7195 (1.1263) loss_zs_kd 0.1360 (0.1471) loss_oracle 0.0513 (0.0363) acc 50.0000 (69.8438) kd_loss 0.0252 (0.0248) lr 1.1874e-03 eta 0:18:52
epoch [24/50] batch [60/244] time 0.175 (0.168) data 0.001 (0.005) loss 1.6075 (1.2562) ce_loss 1.4756 (1.1454) teacher_loss 1.4785 (1.1422) loss_zs_kd 0.1710 (0.1519) loss_oracle 0.0435 (0.0381) acc 62.5000 (69.6354) kd_loss 0.0270 (0.0246) lr 1.1874e-03 eta 0:18:15
epoch [24/50] batch [80/244] time 0.112 (0.162) data 0.000 (0.004) loss 1.2273 (1.2514) ce_loss 1.1436 (1.1377) teacher_loss 1.1430 (1.1351) loss_zs_kd 0.1200 (0.1552) loss_oracle 0.0243 (0.0387) acc 65.6250 (69.7656) kd_loss 0.0206 (0.0248) lr 1.1874e-03 eta 0:17:36
epoch [24/50] batch [100/244] time 0.086 (0.174) data 0.000 (0.003) loss 1.0839 (1.2224) ce_loss 0.9663 (1.1090) teacher_loss 0.9689 (1.1064) loss_zs_kd 0.1561 (0.1547) loss_oracle 0.0370 (0.0387) acc 75.0000 (70.4688) kd_loss 0.0220 (0.0252) lr 1.1874e-03 eta 0:18:51
epoch [24/50] batch [120/244] time 0.149 (0.170) data 0.000 (0.003) loss 1.3926 (1.2256) ce_loss 1.2744 (1.1137) teacher_loss 1.2749 (1.1110) loss_zs_kd 0.1515 (0.1525) loss_oracle 0.0420 (0.0383) acc 68.7500 (70.6510) kd_loss 0.0329 (0.0252) lr 1.1874e-03 eta 0:18:18
epoch [24/50] batch [140/244] time 0.148 (0.168) data 0.000 (0.002) loss 0.9158 (1.2262) ce_loss 0.8159 (1.1143) teacher_loss 0.8029 (1.1117) loss_zs_kd 0.1521 (0.1521) loss_oracle 0.0368 (0.0385) acc 84.3750 (70.6920) kd_loss 0.0236 (0.0252) lr 1.1874e-03 eta 0:18:00
epoch [24/50] batch [160/244] time 0.153 (0.167) data 0.000 (0.002) loss 1.2682 (1.2076) ce_loss 1.1504 (1.0961) teacher_loss 1.1515 (1.0936) loss_zs_kd 0.1737 (0.1512) loss_oracle 0.0299 (0.0385) acc 65.6250 (70.8203) kd_loss 0.0199 (0.0253) lr 1.1874e-03 eta 0:17:51
epoch [24/50] batch [180/244] time 0.158 (0.166) data 0.000 (0.002) loss 1.3073 (1.2165) ce_loss 1.1670 (1.1058) teacher_loss 1.1722 (1.1034) loss_zs_kd 0.1986 (0.1499) loss_oracle 0.0358 (0.0381) acc 62.5000 (70.5729) kd_loss 0.0208 (0.0250) lr 1.1874e-03 eta 0:17:41
epoch [24/50] batch [200/244] time 0.150 (0.164) data 0.000 (0.002) loss 1.1727 (1.2072) ce_loss 1.0674 (1.0954) teacher_loss 1.0680 (1.0933) loss_zs_kd 0.1528 (0.1516) loss_oracle 0.0283 (0.0381) acc 78.1250 (70.8750) kd_loss 0.0185 (0.0248) lr 1.1874e-03 eta 0:17:29
epoch [24/50] batch [220/244] time 0.156 (0.164) data 0.000 (0.002) loss 1.4820 (1.1962) ce_loss 1.3633 (1.0833) teacher_loss 1.3592 (1.0814) loss_zs_kd 0.1733 (0.1528) loss_oracle 0.0362 (0.0383) acc 62.5000 (71.1506) kd_loss 0.0236 (0.0248) lr 1.1874e-03 eta 0:17:22
epoch [24/50] batch [240/244] time 0.155 (0.163) data 0.000 (0.002) loss 1.4090 (1.1977) ce_loss 1.2822 (1.0846) teacher_loss 1.2826 (1.0828) loss_zs_kd 0.1619 (0.1531) loss_oracle 0.0454 (0.0384) acc 62.5000 (71.1719) kd_loss 0.0286 (0.0249) lr 1.1874e-03 eta 0:17:15
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,827
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.7%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,046
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [25/50] batch [20/244] time 0.182 (0.191) data 0.000 (0.015) loss 0.9873 (1.1822) ce_loss 0.8701 (1.0739) teacher_loss 0.8611 (1.0727) loss_zs_kd 0.1359 (0.1344) loss_oracle 0.0582 (0.0423) acc 71.8750 (70.6250) kd_loss 0.0313 (0.0281) lr 1.1253e-03 eta 0:20:06
epoch [25/50] batch [40/244] time 0.158 (0.177) data 0.000 (0.007) loss 1.0586 (1.1748) ce_loss 0.9517 (1.0674) teacher_loss 0.9410 (1.0672) loss_zs_kd 0.1507 (0.1363) loss_oracle 0.0423 (0.0394) acc 71.8750 (70.7812) kd_loss 0.0306 (0.0270) lr 1.1253e-03 eta 0:18:38
epoch [25/50] batch [60/244] time 0.169 (0.176) data 0.001 (0.005) loss 1.0415 (1.1598) ce_loss 0.9302 (1.0490) teacher_loss 0.9365 (1.0487) loss_zs_kd 0.1487 (0.1417) loss_oracle 0.0306 (0.0403) acc 78.1250 (72.0833) kd_loss 0.0257 (0.0276) lr 1.1253e-03 eta 0:18:25
epoch [25/50] batch [80/244] time 0.184 (0.176) data 0.000 (0.004) loss 1.0438 (1.1881) ce_loss 0.8804 (1.0731) teacher_loss 0.8853 (1.0728) loss_zs_kd 0.2521 (0.1497) loss_oracle 0.0324 (0.0404) acc 81.2500 (71.7578) kd_loss 0.0290 (0.0278) lr 1.1253e-03 eta 0:18:21
epoch [25/50] batch [100/244] time 0.379 (0.183) data 0.000 (0.003) loss 1.3905 (1.1950) ce_loss 1.2793 (1.0757) teacher_loss 1.2716 (1.0753) loss_zs_kd 0.1378 (0.1570) loss_oracle 0.0499 (0.0411) acc 65.6250 (71.7500) kd_loss 0.0315 (0.0283) lr 1.1253e-03 eta 0:18:59
epoch [25/50] batch [120/244] time 0.177 (0.179) data 0.000 (0.003) loss 1.6013 (1.1944) ce_loss 1.4980 (1.0726) teacher_loss 1.4988 (1.0721) loss_zs_kd 0.1259 (0.1598) loss_oracle 0.0396 (0.0425) acc 59.3750 (71.5885) kd_loss 0.0337 (0.0295) lr 1.1253e-03 eta 0:18:33
epoch [25/50] batch [140/244] time 0.149 (0.177) data 0.000 (0.002) loss 1.2700 (1.2049) ce_loss 1.1279 (1.0831) teacher_loss 1.1247 (1.0824) loss_zs_kd 0.1899 (0.1588) loss_oracle 0.0504 (0.0431) acc 68.7500 (71.2946) kd_loss 0.0413 (0.0300) lr 1.1253e-03 eta 0:18:15
epoch [25/50] batch [160/244] time 0.153 (0.175) data 0.000 (0.002) loss 1.3781 (1.2077) ce_loss 1.2598 (1.0866) teacher_loss 1.2467 (1.0856) loss_zs_kd 0.1628 (0.1575) loss_oracle 0.0500 (0.0434) acc 71.8750 (71.3672) kd_loss 0.0398 (0.0308) lr 1.1253e-03 eta 0:18:00
epoch [25/50] batch [180/244] time 0.174 (0.173) data 0.000 (0.002) loss 1.4609 (1.2055) ce_loss 1.3604 (1.0845) teacher_loss 1.3690 (1.0833) loss_zs_kd 0.1299 (0.1568) loss_oracle 0.0270 (0.0439) acc 62.5000 (71.3368) kd_loss 0.0219 (0.0314) lr 1.1253e-03 eta 0:17:47
epoch [25/50] batch [200/244] time 0.167 (0.172) data 0.000 (0.002) loss 1.1259 (1.2085) ce_loss 0.9824 (1.0881) teacher_loss 0.9769 (1.0868) loss_zs_kd 0.2002 (0.1562) loss_oracle 0.0489 (0.0436) acc 78.1250 (71.4062) kd_loss 0.0494 (0.0315) lr 1.1253e-03 eta 0:17:39
epoch [25/50] batch [220/244] time 0.156 (0.172) data 0.000 (0.002) loss 0.8329 (1.2057) ce_loss 0.6899 (1.0863) teacher_loss 0.6863 (1.0851) loss_zs_kd 0.2093 (0.1550) loss_oracle 0.0420 (0.0431) acc 75.0000 (71.3352) kd_loss 0.0378 (0.0314) lr 1.1253e-03 eta 0:17:31
epoch [25/50] batch [240/244] time 0.267 (0.170) data 0.000 (0.001) loss 1.0477 (1.2066) ce_loss 0.9307 (1.0871) teacher_loss 0.9305 (1.0857) loss_zs_kd 0.1352 (0.1558) loss_oracle 0.0496 (0.0430) acc 78.1250 (71.4323) kd_loss 0.0317 (0.0317) lr 1.1253e-03 eta 0:17:17
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,816
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,031
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [26/50] batch [20/244] time 0.174 (0.178) data 0.000 (0.015) loss 1.0515 (1.1578) ce_loss 0.9160 (1.0392) teacher_loss 0.9125 (1.0316) loss_zs_kd 0.1544 (0.1570) loss_oracle 0.0618 (0.0476) acc 75.0000 (71.7188) kd_loss 0.0422 (0.0368) lr 1.0628e-03 eta 0:18:00
epoch [26/50] batch [40/244] time 0.153 (0.168) data 0.000 (0.008) loss 1.3141 (1.1298) ce_loss 1.2051 (1.0063) teacher_loss 1.2026 (1.0015) loss_zs_kd 0.1318 (0.1633) loss_oracle 0.0456 (0.0467) acc 65.6250 (72.5000) kd_loss 0.0318 (0.0340) lr 1.0628e-03 eta 0:16:56
epoch [26/50] batch [60/244] time 0.176 (0.167) data 0.001 (0.005) loss 0.8622 (1.1666) ce_loss 0.7456 (1.0435) teacher_loss 0.7503 (1.0394) loss_zs_kd 0.1356 (0.1579) loss_oracle 0.0441 (0.0483) acc 84.3750 (71.6667) kd_loss 0.0219 (0.0341) lr 1.0628e-03 eta 0:16:46
epoch [26/50] batch [80/244] time 0.168 (0.166) data 0.000 (0.004) loss 1.0520 (1.1775) ce_loss 0.9126 (1.0526) teacher_loss 0.9206 (1.0485) loss_zs_kd 0.1591 (0.1579) loss_oracle 0.0519 (0.0501) acc 81.2500 (71.5625) kd_loss 0.0322 (0.0349) lr 1.0628e-03 eta 0:16:41
epoch [26/50] batch [100/244] time 0.084 (0.174) data 0.000 (0.003) loss 1.4134 (1.1784) ce_loss 1.3135 (1.0543) teacher_loss 1.3102 (1.0503) loss_zs_kd 0.1350 (0.1572) loss_oracle 0.0357 (0.0495) acc 62.5000 (71.4375) kd_loss 0.0322 (0.0348) lr 1.0628e-03 eta 0:17:24
epoch [26/50] batch [120/244] time 0.160 (0.176) data 0.000 (0.003) loss 1.0271 (1.1803) ce_loss 0.9014 (1.0582) teacher_loss 0.8941 (1.0544) loss_zs_kd 0.1603 (0.1552) loss_oracle 0.0528 (0.0483) acc 71.8750 (71.4323) kd_loss 0.0407 (0.0346) lr 1.0628e-03 eta 0:17:29
epoch [26/50] batch [140/244] time 0.160 (0.174) data 0.000 (0.002) loss 1.6400 (1.1939) ce_loss 1.5410 (1.0727) teacher_loss 1.5390 (1.0692) loss_zs_kd 0.1129 (0.1547) loss_oracle 0.0446 (0.0474) acc 65.6250 (71.3170) kd_loss 0.0303 (0.0341) lr 1.0628e-03 eta 0:17:19
epoch [26/50] batch [160/244] time 0.156 (0.173) data 0.000 (0.002) loss 1.5255 (1.2041) ce_loss 1.3984 (1.0827) teacher_loss 1.3902 (1.0788) loss_zs_kd 0.1767 (0.1557) loss_oracle 0.0469 (0.0475) acc 65.6250 (71.1719) kd_loss 0.0392 (0.0344) lr 1.0628e-03 eta 0:17:07
epoch [26/50] batch [180/244] time 0.175 (0.171) data 0.000 (0.002) loss 0.9209 (1.1902) ce_loss 0.7490 (1.0690) teacher_loss 0.7462 (1.0653) loss_zs_kd 0.2255 (0.1549) loss_oracle 0.0619 (0.0474) acc 78.1250 (71.4757) kd_loss 0.0383 (0.0343) lr 1.0628e-03 eta 0:16:53
epoch [26/50] batch [200/244] time 0.180 (0.170) data 0.000 (0.002) loss 0.8799 (1.1929) ce_loss 0.7715 (1.0718) teacher_loss 0.7694 (1.0682) loss_zs_kd 0.1452 (0.1546) loss_oracle 0.0379 (0.0474) acc 84.3750 (71.5000) kd_loss 0.0307 (0.0342) lr 1.0628e-03 eta 0:16:44
epoch [26/50] batch [220/244] time 0.164 (0.170) data 0.000 (0.002) loss 1.1179 (1.2009) ce_loss 1.0303 (1.0798) teacher_loss 1.0223 (1.0764) loss_zs_kd 0.1164 (0.1547) loss_oracle 0.0374 (0.0472) acc 75.0000 (71.2926) kd_loss 0.0320 (0.0339) lr 1.0628e-03 eta 0:16:38
epoch [26/50] batch [240/244] time 0.404 (0.171) data 0.000 (0.001) loss 1.0276 (1.2017) ce_loss 0.9526 (1.0809) teacher_loss 0.9402 (1.0772) loss_zs_kd 0.0827 (0.1539) loss_oracle 0.0461 (0.0475) acc 75.0000 (71.2500) kd_loss 0.0306 (0.0340) lr 1.0628e-03 eta 0:16:43
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,827
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.6%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [27/50] batch [20/244] time 0.174 (0.178) data 0.000 (0.013) loss 1.1974 (1.1132) ce_loss 1.0703 (0.9980) teacher_loss 1.0666 (0.9942) loss_zs_kd 0.1561 (0.1485) loss_oracle 0.0528 (0.0448) acc 65.6250 (72.3438) kd_loss 0.0340 (0.0318) lr 1.0000e-03 eta 0:17:20
epoch [27/50] batch [40/244] time 0.173 (0.171) data 0.000 (0.007) loss 0.8222 (1.1470) ce_loss 0.7256 (1.0287) teacher_loss 0.7213 (1.0263) loss_zs_kd 0.1076 (0.1534) loss_oracle 0.0471 (0.0440) acc 75.0000 (73.1250) kd_loss 0.0300 (0.0313) lr 1.0000e-03 eta 0:16:35
epoch [27/50] batch [60/244] time 0.180 (0.173) data 0.001 (0.004) loss 1.3284 (1.1818) ce_loss 1.2031 (1.0624) teacher_loss 1.2098 (1.0600) loss_zs_kd 0.1521 (0.1565) loss_oracle 0.0425 (0.0436) acc 71.8750 (72.2917) kd_loss 0.0267 (0.0307) lr 1.0000e-03 eta 0:16:40
epoch [27/50] batch [80/244] time 0.102 (0.170) data 0.000 (0.003) loss 1.6437 (1.1964) ce_loss 1.5254 (1.0753) teacher_loss 1.5056 (1.0725) loss_zs_kd 0.1598 (0.1592) loss_oracle 0.0583 (0.0443) acc 56.2500 (71.7188) kd_loss 0.0294 (0.0303) lr 1.0000e-03 eta 0:16:21
epoch [27/50] batch [100/244] time 0.084 (0.180) data 0.000 (0.003) loss 1.0939 (1.1879) ce_loss 0.9688 (1.0644) teacher_loss 0.9703 (1.0618) loss_zs_kd 0.1499 (0.1623) loss_oracle 0.0486 (0.0449) acc 71.8750 (72.2812) kd_loss 0.0250 (0.0301) lr 1.0000e-03 eta 0:17:16
epoch [27/50] batch [120/244] time 0.147 (0.175) data 0.000 (0.002) loss 0.7694 (1.1889) ce_loss 0.6421 (1.0649) teacher_loss 0.6480 (1.0622) loss_zs_kd 0.1709 (0.1641) loss_oracle 0.0360 (0.0447) acc 87.5000 (72.1094) kd_loss 0.0225 (0.0297) lr 1.0000e-03 eta 0:16:44
epoch [27/50] batch [140/244] time 0.147 (0.172) data 0.000 (0.002) loss 0.9605 (1.1760) ce_loss 0.8291 (1.0530) teacher_loss 0.8347 (1.0506) loss_zs_kd 0.1432 (0.1618) loss_oracle 0.0542 (0.0445) acc 75.0000 (72.3214) kd_loss 0.0289 (0.0294) lr 1.0000e-03 eta 0:16:25
epoch [27/50] batch [160/244] time 0.152 (0.171) data 0.000 (0.002) loss 1.1255 (1.1698) ce_loss 1.0117 (1.0460) teacher_loss 0.9874 (1.0432) loss_zs_kd 0.1576 (0.1626) loss_oracle 0.0593 (0.0452) acc 68.7500 (72.3438) kd_loss 0.0382 (0.0297) lr 1.0000e-03 eta 0:16:12
epoch [27/50] batch [180/244] time 0.159 (0.170) data 0.000 (0.002) loss 1.1078 (1.1687) ce_loss 0.9966 (1.0459) teacher_loss 0.9968 (1.0434) loss_zs_kd 0.1527 (0.1615) loss_oracle 0.0347 (0.0446) acc 71.8750 (72.5694) kd_loss 0.0299 (0.0295) lr 1.0000e-03 eta 0:16:03
epoch [27/50] batch [200/244] time 0.172 (0.170) data 0.000 (0.001) loss 1.4635 (1.1738) ce_loss 1.3545 (1.0523) teacher_loss 1.3458 (1.0497) loss_zs_kd 0.1433 (0.1601) loss_oracle 0.0460 (0.0440) acc 62.5000 (72.4531) kd_loss 0.0258 (0.0292) lr 1.0000e-03 eta 0:16:01
epoch [27/50] batch [220/244] time 0.178 (0.170) data 0.000 (0.001) loss 1.1293 (1.1698) ce_loss 1.0010 (1.0482) teacher_loss 1.0002 (1.0458) loss_zs_kd 0.1563 (0.1603) loss_oracle 0.0510 (0.0438) acc 68.7500 (72.5994) kd_loss 0.0334 (0.0292) lr 1.0000e-03 eta 0:15:59
epoch [27/50] batch [240/244] time 0.083 (0.171) data 0.000 (0.001) loss 1.2072 (1.1731) ce_loss 1.1113 (1.0522) teacher_loss 1.1121 (1.0498) loss_zs_kd 0.1362 (0.1587) loss_oracle 0.0270 (0.0439) acc 71.8750 (72.4870) kd_loss 0.0168 (0.0292) lr 1.0000e-03 eta 0:16:01
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,831
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,048
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.8%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.2%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [28/50] batch [20/244] time 0.165 (0.168) data 0.000 (0.015) loss 1.3993 (1.1511) ce_loss 1.2412 (1.0254) teacher_loss 1.2360 (1.0237) loss_zs_kd 0.2107 (0.1576) loss_oracle 0.0580 (0.0486) acc 71.8750 (73.2812) kd_loss 0.0313 (0.0285) lr 9.3721e-04 eta 0:15:40
epoch [28/50] batch [40/244] time 0.169 (0.162) data 0.000 (0.007) loss 1.3356 (1.1936) ce_loss 1.1865 (1.0675) teacher_loss 1.1849 (1.0658) loss_zs_kd 0.1934 (0.1599) loss_oracle 0.0541 (0.0478) acc 68.7500 (71.8750) kd_loss 0.0269 (0.0289) lr 9.3721e-04 eta 0:15:03
epoch [28/50] batch [60/244] time 0.188 (0.164) data 0.000 (0.005) loss 1.2975 (1.1803) ce_loss 1.1699 (1.0583) teacher_loss 1.1664 (1.0560) loss_zs_kd 0.1706 (0.1565) loss_oracle 0.0458 (0.0460) acc 68.7500 (72.0312) kd_loss 0.0281 (0.0285) lr 9.3721e-04 eta 0:15:12
epoch [28/50] batch [80/244] time 0.151 (0.162) data 0.000 (0.004) loss 1.6288 (1.2115) ce_loss 1.4941 (1.0912) teacher_loss 1.4853 (1.0888) loss_zs_kd 0.1895 (0.1564) loss_oracle 0.0487 (0.0445) acc 68.7500 (71.4844) kd_loss 0.0342 (0.0281) lr 9.3721e-04 eta 0:14:57
epoch [28/50] batch [100/244] time 0.280 (0.159) data 0.000 (0.003) loss 1.3939 (1.2089) ce_loss 1.2852 (1.0884) teacher_loss 1.2780 (1.0860) loss_zs_kd 0.1593 (0.1568) loss_oracle 0.0363 (0.0445) acc 59.3750 (71.6562) kd_loss 0.0263 (0.0277) lr 9.3721e-04 eta 0:14:37
epoch [28/50] batch [120/244] time 0.087 (0.168) data 0.000 (0.003) loss 1.1531 (1.2172) ce_loss 1.0244 (1.0952) teacher_loss 1.0178 (1.0933) loss_zs_kd 0.1616 (0.1592) loss_oracle 0.0545 (0.0443) acc 81.2500 (71.4062) kd_loss 0.0289 (0.0272) lr 9.3721e-04 eta 0:15:23
epoch [28/50] batch [140/244] time 0.174 (0.167) data 0.000 (0.002) loss 1.3890 (1.2047) ce_loss 1.2695 (1.0824) teacher_loss 1.2613 (1.0803) loss_zs_kd 0.1587 (0.1590) loss_oracle 0.0483 (0.0449) acc 65.6250 (71.7634) kd_loss 0.0282 (0.0272) lr 9.3721e-04 eta 0:15:11
epoch [28/50] batch [160/244] time 0.156 (0.166) data 0.000 (0.002) loss 1.4548 (1.1993) ce_loss 1.2812 (1.0771) teacher_loss 1.2706 (1.0747) loss_zs_kd 0.2521 (0.1596) loss_oracle 0.0581 (0.0448) acc 59.3750 (71.9531) kd_loss 0.0351 (0.0273) lr 9.3721e-04 eta 0:15:05
epoch [28/50] batch [180/244] time 0.156 (0.166) data 0.000 (0.002) loss 0.9459 (1.1901) ce_loss 0.8120 (1.0687) teacher_loss 0.8223 (1.0663) loss_zs_kd 0.1732 (0.1584) loss_oracle 0.0371 (0.0446) acc 81.2500 (72.1875) kd_loss 0.0243 (0.0273) lr 9.3721e-04 eta 0:14:59
epoch [28/50] batch [200/244] time 0.157 (0.165) data 0.000 (0.002) loss 1.1515 (1.1814) ce_loss 0.9995 (1.0601) teacher_loss 0.9955 (1.0578) loss_zs_kd 0.1987 (0.1583) loss_oracle 0.0566 (0.0445) acc 68.7500 (72.2656) kd_loss 0.0328 (0.0273) lr 9.3721e-04 eta 0:14:54
epoch [28/50] batch [220/244] time 0.171 (0.165) data 0.000 (0.002) loss 1.0005 (1.1752) ce_loss 0.8662 (1.0538) teacher_loss 0.8638 (1.0517) loss_zs_kd 0.1899 (0.1588) loss_oracle 0.0416 (0.0441) acc 81.2500 (72.4148) kd_loss 0.0314 (0.0272) lr 9.3721e-04 eta 0:14:50
epoch [28/50] batch [240/244] time 0.084 (0.165) data 0.000 (0.001) loss 1.1500 (1.1730) ce_loss 1.0430 (1.0515) teacher_loss 1.0412 (1.0492) loss_zs_kd 0.1194 (0.1590) loss_oracle 0.0490 (0.0443) acc 71.8750 (72.4349) kd_loss 0.0281 (0.0274) lr 9.3721e-04 eta 0:14:47
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,820
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,035
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.2%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [29/50] batch [20/244] time 0.184 (0.183) data 0.000 (0.013) loss 0.9605 (1.1549) ce_loss 0.8511 (1.0351) teacher_loss 0.8498 (1.0322) loss_zs_kd 0.1452 (0.1603) loss_oracle 0.0381 (0.0425) acc 78.1250 (74.2188) kd_loss 0.0221 (0.0290) lr 8.7467e-04 eta 0:16:20
epoch [29/50] batch [40/244] time 0.168 (0.172) data 0.000 (0.007) loss 1.4513 (1.1952) ce_loss 1.3262 (1.0729) teacher_loss 1.3305 (1.0697) loss_zs_kd 0.1384 (0.1608) loss_oracle 0.0517 (0.0451) acc 62.5000 (72.0312) kd_loss 0.0311 (0.0298) lr 8.7467e-04 eta 0:15:17
epoch [29/50] batch [60/244] time 0.149 (0.168) data 0.000 (0.005) loss 1.5823 (1.1976) ce_loss 1.4590 (1.0768) teacher_loss 1.4549 (1.0743) loss_zs_kd 0.1394 (0.1541) loss_oracle 0.0577 (0.0462) acc 62.5000 (71.7188) kd_loss 0.0306 (0.0287) lr 8.7467e-04 eta 0:14:53
epoch [29/50] batch [80/244] time 0.151 (0.166) data 0.000 (0.003) loss 0.5636 (1.2032) ce_loss 0.4536 (1.0824) teacher_loss 0.4527 (1.0792) loss_zs_kd 0.1446 (0.1541) loss_oracle 0.0386 (0.0470) acc 93.7500 (71.8359) kd_loss 0.0242 (0.0285) lr 8.7467e-04 eta 0:14:37
epoch [29/50] batch [100/244] time 0.173 (0.166) data 0.000 (0.003) loss 1.3358 (1.2163) ce_loss 1.2490 (1.0946) teacher_loss 1.2459 (1.0916) loss_zs_kd 0.0960 (0.1563) loss_oracle 0.0418 (0.0466) acc 71.8750 (71.3750) kd_loss 0.0265 (0.0281) lr 8.7467e-04 eta 0:14:34
epoch [29/50] batch [120/244] time 0.424 (0.172) data 0.000 (0.002) loss 1.3236 (1.2262) ce_loss 1.1699 (1.1038) teacher_loss 1.1795 (1.1007) loss_zs_kd 0.2093 (0.1585) loss_oracle 0.0395 (0.0463) acc 68.7500 (71.0938) kd_loss 0.0202 (0.0281) lr 8.7467e-04 eta 0:15:02
epoch [29/50] batch [140/244] time 0.161 (0.171) data 0.000 (0.002) loss 2.0008 (1.2232) ce_loss 1.8730 (1.1011) teacher_loss 1.8750 (1.0980) loss_zs_kd 0.1908 (0.1589) loss_oracle 0.0303 (0.0458) acc 53.1250 (71.0045) kd_loss 0.0194 (0.0277) lr 8.7467e-04 eta 0:14:51
epoch [29/50] batch [160/244] time 0.156 (0.169) data 0.000 (0.002) loss 1.1543 (1.2140) ce_loss 1.0137 (1.0923) teacher_loss 1.0099 (1.0892) loss_zs_kd 0.1900 (0.1586) loss_oracle 0.0494 (0.0456) acc 75.0000 (71.2695) kd_loss 0.0293 (0.0275) lr 8.7467e-04 eta 0:14:41
epoch [29/50] batch [180/244] time 0.153 (0.168) data 0.000 (0.002) loss 1.9345 (1.2240) ce_loss 1.8242 (1.1030) teacher_loss 1.8257 (1.0999) loss_zs_kd 0.1518 (0.1578) loss_oracle 0.0328 (0.0452) acc 56.2500 (71.2153) kd_loss 0.0210 (0.0273) lr 8.7467e-04 eta 0:14:32
epoch [29/50] batch [200/244] time 0.178 (0.167) data 0.000 (0.001) loss 1.3141 (1.2178) ce_loss 1.1631 (1.0962) teacher_loss 1.1543 (1.0928) loss_zs_kd 0.1874 (0.1585) loss_oracle 0.0661 (0.0458) acc 65.6250 (71.2969) kd_loss 0.0382 (0.0277) lr 8.7467e-04 eta 0:14:25
epoch [29/50] batch [220/244] time 0.147 (0.167) data 0.000 (0.001) loss 0.8210 (1.2153) ce_loss 0.7173 (1.0936) teacher_loss 0.7235 (1.0903) loss_zs_kd 0.1353 (0.1585) loss_oracle 0.0298 (0.0458) acc 84.3750 (71.3778) kd_loss 0.0162 (0.0275) lr 8.7467e-04 eta 0:14:18
epoch [29/50] batch [240/244] time 0.152 (0.166) data 0.000 (0.001) loss 0.7477 (1.2056) ce_loss 0.6333 (1.0837) teacher_loss 0.6195 (1.0801) loss_zs_kd 0.1297 (0.1583) loss_oracle 0.0633 (0.0463) acc 87.5000 (71.5885) kd_loss 0.0412 (0.0280) lr 8.7467e-04 eta 0:14:11
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,827
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.2%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [30/50] batch [20/244] time 0.177 (0.185) data 0.000 (0.015) loss 0.9267 (1.1321) ce_loss 0.8071 (1.0100) teacher_loss 0.8066 (1.0069) loss_zs_kd 0.1160 (0.1514) loss_oracle 0.0621 (0.0495) acc 75.0000 (74.0625) kd_loss 0.0417 (0.0295) lr 8.1262e-04 eta 0:15:45
epoch [30/50] batch [40/244] time 0.150 (0.172) data 0.000 (0.007) loss 0.8736 (1.1360) ce_loss 0.7642 (1.0164) teacher_loss 0.7650 (1.0134) loss_zs_kd 0.1229 (0.1477) loss_oracle 0.0471 (0.0488) acc 81.2500 (73.6719) kd_loss 0.0300 (0.0305) lr 8.1262e-04 eta 0:14:36
epoch [30/50] batch [60/244] time 0.171 (0.168) data 0.000 (0.005) loss 0.9471 (1.1626) ce_loss 0.8271 (1.0439) teacher_loss 0.8217 (1.0404) loss_zs_kd 0.1713 (0.1493) loss_oracle 0.0398 (0.0475) acc 84.3750 (72.6562) kd_loss 0.0350 (0.0311) lr 8.1262e-04 eta 0:14:12
epoch [30/50] batch [80/244] time 0.153 (0.166) data 0.000 (0.004) loss 0.9260 (1.1740) ce_loss 0.7886 (1.0561) teacher_loss 0.7830 (1.0527) loss_zs_kd 0.1751 (0.1494) loss_oracle 0.0555 (0.0466) acc 75.0000 (72.2656) kd_loss 0.0422 (0.0309) lr 8.1262e-04 eta 0:13:59
epoch [30/50] batch [100/244] time 0.170 (0.165) data 0.000 (0.003) loss 0.7033 (1.1909) ce_loss 0.5835 (1.0715) teacher_loss 0.5855 (1.0676) loss_zs_kd 0.1335 (0.1521) loss_oracle 0.0510 (0.0472) acc 87.5000 (71.7812) kd_loss 0.0342 (0.0310) lr 8.1262e-04 eta 0:13:50
epoch [30/50] batch [120/244] time 0.085 (0.171) data 0.000 (0.003) loss 1.0846 (1.1872) ce_loss 0.9746 (1.0666) teacher_loss 0.9752 (1.0628) loss_zs_kd 0.1294 (0.1532) loss_oracle 0.0447 (0.0478) acc 71.8750 (71.6406) kd_loss 0.0313 (0.0312) lr 8.1262e-04 eta 0:14:14
epoch [30/50] batch [140/244] time 0.170 (0.171) data 0.000 (0.002) loss 0.9352 (1.1705) ce_loss 0.7632 (1.0487) teacher_loss 0.7585 (1.0451) loss_zs_kd 0.2405 (0.1548) loss_oracle 0.0564 (0.0480) acc 78.1250 (72.1205) kd_loss 0.0340 (0.0313) lr 8.1262e-04 eta 0:14:14
epoch [30/50] batch [160/244] time 0.156 (0.170) data 0.000 (0.002) loss 0.8295 (1.1781) ce_loss 0.7085 (1.0553) teacher_loss 0.7094 (1.0518) loss_zs_kd 0.1795 (0.1576) loss_oracle 0.0304 (0.0475) acc 71.8750 (71.8945) kd_loss 0.0226 (0.0314) lr 8.1262e-04 eta 0:14:05
epoch [30/50] batch [180/244] time 0.172 (0.169) data 0.000 (0.002) loss 1.1722 (1.1751) ce_loss 1.0479 (1.0528) teacher_loss 1.0379 (1.0493) loss_zs_kd 0.1664 (0.1576) loss_oracle 0.0510 (0.0470) acc 71.8750 (72.0312) kd_loss 0.0392 (0.0316) lr 8.1262e-04 eta 0:13:55
epoch [30/50] batch [200/244] time 0.170 (0.168) data 0.000 (0.002) loss 0.9943 (1.1735) ce_loss 0.8701 (1.0510) teacher_loss 0.8554 (1.0476) loss_zs_kd 0.1459 (0.1584) loss_oracle 0.0659 (0.0467) acc 71.8750 (72.0469) kd_loss 0.0459 (0.0317) lr 8.1262e-04 eta 0:13:47
epoch [30/50] batch [220/244] time 0.171 (0.167) data 0.000 (0.001) loss 1.2164 (1.1795) ce_loss 1.0850 (1.0567) teacher_loss 1.0816 (1.0533) loss_zs_kd 0.1646 (0.1595) loss_oracle 0.0525 (0.0464) acc 71.8750 (71.9034) kd_loss 0.0405 (0.0318) lr 8.1262e-04 eta 0:13:40
epoch [30/50] batch [240/244] time 0.152 (0.167) data 0.000 (0.001) loss 1.0231 (1.1857) ce_loss 0.9170 (1.0637) teacher_loss 0.9076 (1.0605) loss_zs_kd 0.1452 (0.1582) loss_oracle 0.0429 (0.0461) acc 68.7500 (71.7188) kd_loss 0.0364 (0.0317) lr 8.1262e-04 eta 0:13:33
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,819
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.2%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [31/50] batch [20/244] time 0.167 (0.185) data 0.000 (0.015) loss 0.8031 (1.1373) ce_loss 0.6646 (1.0247) teacher_loss 0.6649 (1.0209) loss_zs_kd 0.1794 (0.1467) loss_oracle 0.0485 (0.0431) acc 78.1250 (71.5625) kd_loss 0.0335 (0.0323) lr 7.5131e-04 eta 0:15:01
epoch [31/50] batch [40/244] time 0.166 (0.173) data 0.000 (0.008) loss 1.1508 (1.1520) ce_loss 1.0410 (1.0320) teacher_loss 1.0411 (1.0293) loss_zs_kd 0.1623 (0.1606) loss_oracle 0.0286 (0.0423) acc 71.8750 (71.4062) kd_loss 0.0212 (0.0311) lr 7.5131e-04 eta 0:13:58
epoch [31/50] batch [60/244] time 0.175 (0.170) data 0.001 (0.005) loss 1.5617 (1.1905) ce_loss 1.4375 (1.0706) teacher_loss 1.4330 (1.0679) loss_zs_kd 0.1679 (0.1597) loss_oracle 0.0448 (0.0427) acc 62.5000 (70.6771) kd_loss 0.0247 (0.0305) lr 7.5131e-04 eta 0:13:38
epoch [31/50] batch [80/244] time 0.163 (0.169) data 0.000 (0.004) loss 1.3523 (1.1650) ce_loss 1.2412 (1.0443) teacher_loss 1.2385 (1.0416) loss_zs_kd 0.1629 (0.1592) loss_oracle 0.0324 (0.0438) acc 65.6250 (71.7969) kd_loss 0.0191 (0.0305) lr 7.5131e-04 eta 0:13:30
epoch [31/50] batch [100/244] time 0.177 (0.170) data 0.000 (0.003) loss 1.3592 (1.1461) ce_loss 1.2012 (1.0255) teacher_loss 1.2012 (1.0228) loss_zs_kd 0.2267 (0.1597) loss_oracle 0.0447 (0.0434) acc 68.7500 (72.1875) kd_loss 0.0374 (0.0309) lr 7.5131e-04 eta 0:13:32
epoch [31/50] batch [120/244] time 0.125 (0.171) data 0.000 (0.003) loss 1.3776 (1.1697) ce_loss 1.1650 (1.0478) teacher_loss 1.1560 (1.0446) loss_zs_kd 0.3114 (0.1617) loss_oracle 0.0659 (0.0442) acc 65.6250 (71.6667) kd_loss 0.0393 (0.0314) lr 7.5131e-04 eta 0:13:33
epoch [31/50] batch [140/244] time 0.156 (0.173) data 0.000 (0.002) loss 0.8394 (1.1821) ce_loss 0.7007 (1.0605) teacher_loss 0.7071 (1.0576) loss_zs_kd 0.1698 (0.1611) loss_oracle 0.0474 (0.0439) acc 84.3750 (71.6295) kd_loss 0.0312 (0.0311) lr 7.5131e-04 eta 0:13:38
epoch [31/50] batch [160/244] time 0.180 (0.172) data 0.000 (0.002) loss 1.1942 (1.1704) ce_loss 1.0781 (1.0493) teacher_loss 1.0821 (1.0461) loss_zs_kd 0.1499 (0.1599) loss_oracle 0.0372 (0.0444) acc 75.0000 (72.0117) kd_loss 0.0288 (0.0315) lr 7.5131e-04 eta 0:13:30
epoch [31/50] batch [180/244] time 0.149 (0.171) data 0.000 (0.002) loss 0.9370 (1.1649) ce_loss 0.8101 (1.0432) teacher_loss 0.8126 (1.0401) loss_zs_kd 0.1517 (0.1608) loss_oracle 0.0485 (0.0444) acc 75.0000 (72.2743) kd_loss 0.0313 (0.0317) lr 7.5131e-04 eta 0:13:24
epoch [31/50] batch [200/244] time 0.153 (0.170) data 0.000 (0.002) loss 1.4829 (1.1719) ce_loss 1.3408 (1.0508) teacher_loss 1.3380 (1.0475) loss_zs_kd 0.2041 (0.1604) loss_oracle 0.0429 (0.0442) acc 71.8750 (72.0000) kd_loss 0.0317 (0.0316) lr 7.5131e-04 eta 0:13:15
epoch [31/50] batch [220/244] time 0.155 (0.169) data 0.000 (0.002) loss 1.0115 (1.1764) ce_loss 0.9185 (1.0559) teacher_loss 0.9207 (1.0528) loss_zs_kd 0.1179 (0.1595) loss_oracle 0.0318 (0.0439) acc 68.7500 (71.9176) kd_loss 0.0265 (0.0315) lr 7.5131e-04 eta 0:13:06
epoch [31/50] batch [240/244] time 0.155 (0.168) data 0.000 (0.001) loss 0.9431 (1.1785) ce_loss 0.8257 (1.0575) teacher_loss 0.8183 (1.0545) loss_zs_kd 0.1614 (0.1604) loss_oracle 0.0441 (0.0437) acc 84.3750 (72.0312) kd_loss 0.0364 (0.0314) lr 7.5131e-04 eta 0:13:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,826
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.2%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [32/50] batch [20/244] time 0.177 (0.190) data 0.000 (0.017) loss 1.5551 (1.1461) ce_loss 1.4385 (1.0178) teacher_loss 1.4409 (1.0173) loss_zs_kd 0.1599 (0.1644) loss_oracle 0.0343 (0.0466) acc 62.5000 (72.6562) kd_loss 0.0291 (0.0310) lr 6.9098e-04 eta 0:14:35
epoch [32/50] batch [40/244] time 0.146 (0.177) data 0.000 (0.009) loss 1.1722 (1.1615) ce_loss 1.0576 (1.0381) teacher_loss 1.0555 (1.0371) loss_zs_kd 0.1523 (0.1604) loss_oracle 0.0406 (0.0442) acc 75.0000 (73.0469) kd_loss 0.0286 (0.0304) lr 6.9098e-04 eta 0:13:34
epoch [32/50] batch [60/244] time 0.169 (0.173) data 0.001 (0.006) loss 1.2078 (1.1823) ce_loss 1.0488 (1.0571) teacher_loss 1.0553 (1.0554) loss_zs_kd 0.2282 (0.1671) loss_oracle 0.0385 (0.0434) acc 75.0000 (72.9167) kd_loss 0.0315 (0.0314) lr 6.9098e-04 eta 0:13:09
epoch [32/50] batch [80/244] time 0.149 (0.169) data 0.000 (0.004) loss 0.9890 (1.1762) ce_loss 0.8364 (1.0502) teacher_loss 0.8357 (1.0481) loss_zs_kd 0.2176 (0.1685) loss_oracle 0.0445 (0.0439) acc 84.3750 (72.6562) kd_loss 0.0348 (0.0324) lr 6.9098e-04 eta 0:12:50
epoch [32/50] batch [100/244] time 0.171 (0.168) data 0.000 (0.004) loss 1.3007 (1.2025) ce_loss 1.1689 (1.0760) teacher_loss 1.1670 (1.0735) loss_zs_kd 0.1891 (0.1698) loss_oracle 0.0391 (0.0441) acc 68.7500 (72.0938) kd_loss 0.0352 (0.0325) lr 6.9098e-04 eta 0:12:42
epoch [32/50] batch [120/244] time 0.085 (0.171) data 0.000 (0.003) loss 0.8878 (1.2068) ce_loss 0.7500 (1.0820) teacher_loss 0.7446 (1.0793) loss_zs_kd 0.2054 (0.1673) loss_oracle 0.0405 (0.0438) acc 78.1250 (71.9531) kd_loss 0.0305 (0.0329) lr 6.9098e-04 eta 0:12:51
epoch [32/50] batch [140/244] time 0.161 (0.172) data 0.000 (0.003) loss 1.3183 (1.1924) ce_loss 1.1963 (1.0684) teacher_loss 1.1858 (1.0651) loss_zs_kd 0.1850 (0.1664) loss_oracle 0.0400 (0.0440) acc 59.3750 (72.2321) kd_loss 0.0386 (0.0334) lr 6.9098e-04 eta 0:12:53
epoch [32/50] batch [160/244] time 0.164 (0.170) data 0.000 (0.002) loss 1.1265 (1.1866) ce_loss 0.9639 (1.0629) teacher_loss 0.9689 (1.0597) loss_zs_kd 0.1977 (0.1655) loss_oracle 0.0588 (0.0441) acc 81.2500 (72.5195) kd_loss 0.0385 (0.0335) lr 6.9098e-04 eta 0:12:41
epoch [32/50] batch [180/244] time 0.147 (0.168) data 0.000 (0.002) loss 0.8482 (1.1938) ce_loss 0.6768 (1.0716) teacher_loss 0.6812 (1.0683) loss_zs_kd 0.2413 (0.1630) loss_oracle 0.0463 (0.0439) acc 90.6250 (72.3611) kd_loss 0.0350 (0.0334) lr 6.9098e-04 eta 0:12:27
epoch [32/50] batch [200/244] time 0.159 (0.166) data 0.000 (0.002) loss 1.2531 (1.1997) ce_loss 1.1533 (1.0776) teacher_loss 1.1457 (1.0743) loss_zs_kd 0.1286 (0.1627) loss_oracle 0.0430 (0.0440) acc 65.6250 (72.2344) kd_loss 0.0275 (0.0334) lr 6.9098e-04 eta 0:12:16
epoch [32/50] batch [220/244] time 0.158 (0.165) data 0.000 (0.002) loss 1.4703 (1.1997) ce_loss 1.3369 (1.0784) teacher_loss 1.3263 (1.0753) loss_zs_kd 0.1889 (0.1613) loss_oracle 0.0495 (0.0438) acc 59.3750 (71.9460) kd_loss 0.0325 (0.0332) lr 6.9098e-04 eta 0:12:09
epoch [32/50] batch [240/244] time 0.148 (0.165) data 0.000 (0.002) loss 0.9195 (1.2061) ce_loss 0.8027 (1.0849) teacher_loss 0.8032 (1.0817) loss_zs_kd 0.1305 (0.1603) loss_oracle 0.0511 (0.0442) acc 75.0000 (71.7708) kd_loss 0.0366 (0.0335) lr 6.9098e-04 eta 0:12:04
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,824
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,040
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.9%, epoch: 27 *******
******* Domain p best val test acc: 91.2%, epoch: 27 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [33/50] batch [20/244] time 0.154 (0.195) data 0.000 (0.012) loss 1.1809 (1.1929) ce_loss 1.0811 (1.0681) teacher_loss 1.0764 (1.0623) loss_zs_kd 0.1219 (0.1540) loss_oracle 0.0435 (0.0536) acc 81.2500 (72.6562) kd_loss 0.0353 (0.0398) lr 6.3188e-04 eta 0:14:11
epoch [33/50] batch [40/244] time 0.167 (0.176) data 0.000 (0.006) loss 0.9760 (1.1473) ce_loss 0.8594 (1.0236) teacher_loss 0.8529 (1.0188) loss_zs_kd 0.1338 (0.1535) loss_oracle 0.0562 (0.0518) acc 78.1250 (74.0625) kd_loss 0.0377 (0.0378) lr 6.3188e-04 eta 0:12:44
epoch [33/50] batch [60/244] time 0.166 (0.172) data 0.001 (0.004) loss 2.0347 (1.1833) ce_loss 1.9023 (1.0604) teacher_loss 1.8878 (1.0554) loss_zs_kd 0.1844 (0.1549) loss_oracle 0.0547 (0.0504) acc 50.0000 (72.2396) kd_loss 0.0401 (0.0372) lr 6.3188e-04 eta 0:12:23
epoch [33/50] batch [80/244] time 0.178 (0.169) data 0.000 (0.003) loss 1.1235 (1.2083) ce_loss 0.9888 (1.0837) teacher_loss 0.9904 (1.0793) loss_zs_kd 0.1967 (0.1591) loss_oracle 0.0348 (0.0494) acc 75.0000 (71.6797) kd_loss 0.0297 (0.0365) lr 6.3188e-04 eta 0:12:10
epoch [33/50] batch [100/244] time 0.168 (0.167) data 0.000 (0.003) loss 1.0281 (1.1905) ce_loss 0.9014 (1.0670) teacher_loss 0.9012 (1.0631) loss_zs_kd 0.1657 (0.1566) loss_oracle 0.0440 (0.0491) acc 71.8750 (72.1875) kd_loss 0.0288 (0.0360) lr 6.3188e-04 eta 0:11:57
epoch [33/50] batch [120/244] time 0.159 (0.166) data 0.000 (0.002) loss 1.4043 (1.1946) ce_loss 1.2461 (1.0702) teacher_loss 1.2483 (1.0659) loss_zs_kd 0.2106 (0.1586) loss_oracle 0.0508 (0.0494) acc 62.5000 (72.1615) kd_loss 0.0256 (0.0358) lr 6.3188e-04 eta 0:11:49
epoch [33/50] batch [140/244] time 0.193 (0.163) data 0.000 (0.002) loss 1.1380 (1.1919) ce_loss 1.0322 (1.0672) teacher_loss 1.0196 (1.0633) loss_zs_kd 0.1351 (0.1587) loss_oracle 0.0508 (0.0493) acc 68.7500 (72.4330) kd_loss 0.0366 (0.0353) lr 6.3188e-04 eta 0:11:35
epoch [33/50] batch [160/244] time 0.154 (0.170) data 0.000 (0.002) loss 0.7800 (1.1844) ce_loss 0.6377 (1.0593) teacher_loss 0.6422 (1.0556) loss_zs_kd 0.1940 (0.1600) loss_oracle 0.0408 (0.0488) acc 87.5000 (72.6172) kd_loss 0.0262 (0.0351) lr 6.3188e-04 eta 0:12:00
epoch [33/50] batch [180/244] time 0.146 (0.169) data 0.000 (0.002) loss 1.5962 (1.1906) ce_loss 1.4648 (1.0662) teacher_loss 1.4639 (1.0624) loss_zs_kd 0.1695 (0.1589) loss_oracle 0.0476 (0.0488) acc 68.7500 (72.3438) kd_loss 0.0400 (0.0350) lr 6.3188e-04 eta 0:11:50
epoch [33/50] batch [200/244] time 0.151 (0.168) data 0.000 (0.001) loss 0.8580 (1.1968) ce_loss 0.7441 (1.0727) teacher_loss 0.7454 (1.0687) loss_zs_kd 0.1435 (0.1590) loss_oracle 0.0409 (0.0486) acc 81.2500 (72.2031) kd_loss 0.0251 (0.0348) lr 6.3188e-04 eta 0:11:42
epoch [33/50] batch [220/244] time 0.148 (0.166) data 0.000 (0.001) loss 1.3268 (1.1981) ce_loss 1.1953 (1.0739) teacher_loss 1.1962 (1.0701) loss_zs_kd 0.1686 (0.1596) loss_oracle 0.0463 (0.0482) acc 65.6250 (72.0597) kd_loss 0.0320 (0.0345) lr 6.3188e-04 eta 0:11:34
epoch [33/50] batch [240/244] time 0.151 (0.166) data 0.000 (0.001) loss 0.7286 (1.1964) ce_loss 0.6201 (1.0716) teacher_loss 0.6151 (1.0678) loss_zs_kd 0.1447 (0.1604) loss_oracle 0.0412 (0.0485) acc 75.0000 (71.9922) kd_loss 0.0291 (0.0344) lr 6.3188e-04 eta 0:11:27
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,833
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      85.0%, epoch: 33 *******
******* Domain p best val test acc: 90.9%, epoch: 33 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [34/50] batch [20/244] time 0.114 (0.202) data 0.000 (0.015) loss 1.0075 (1.2113) ce_loss 0.8828 (1.0850) teacher_loss 0.8845 (1.0834) loss_zs_kd 0.1596 (0.1611) loss_oracle 0.0431 (0.0473) acc 81.2500 (72.9688) kd_loss 0.0242 (0.0297) lr 5.7422e-04 eta 0:13:53
epoch [34/50] batch [40/244] time 0.179 (0.193) data 0.000 (0.008) loss 1.6451 (1.1866) ce_loss 1.5234 (1.0589) teacher_loss 1.5071 (1.0555) loss_zs_kd 0.1688 (0.1668) loss_oracle 0.0536 (0.0477) acc 65.6250 (72.5000) kd_loss 0.0414 (0.0323) lr 5.7422e-04 eta 0:13:12
epoch [34/50] batch [60/244] time 0.148 (0.181) data 0.000 (0.005) loss 1.4064 (1.1728) ce_loss 1.2686 (1.0469) teacher_loss 1.2661 (1.0434) loss_zs_kd 0.1850 (0.1630) loss_oracle 0.0477 (0.0479) acc 65.6250 (72.7604) kd_loss 0.0389 (0.0333) lr 5.7422e-04 eta 0:12:21
epoch [34/50] batch [80/244] time 0.155 (0.175) data 0.000 (0.004) loss 1.4653 (1.1591) ce_loss 1.3320 (1.0336) teacher_loss 1.3374 (1.0300) loss_zs_kd 0.1725 (0.1633) loss_oracle 0.0417 (0.0474) acc 68.7500 (73.0078) kd_loss 0.0296 (0.0331) lr 5.7422e-04 eta 0:11:51
epoch [34/50] batch [100/244] time 0.172 (0.172) data 0.000 (0.003) loss 1.1072 (1.1685) ce_loss 0.9639 (1.0428) teacher_loss 0.9696 (1.0395) loss_zs_kd 0.1824 (0.1629) loss_oracle 0.0465 (0.0476) acc 78.1250 (72.7812) kd_loss 0.0297 (0.0329) lr 5.7422e-04 eta 0:11:34
epoch [34/50] batch [120/244] time 0.170 (0.169) data 0.000 (0.003) loss 0.8303 (1.1678) ce_loss 0.6963 (1.0424) teacher_loss 0.6789 (1.0390) loss_zs_kd 0.1551 (0.1609) loss_oracle 0.0739 (0.0484) acc 81.2500 (72.5521) kd_loss 0.0524 (0.0333) lr 5.7422e-04 eta 0:11:20
epoch [34/50] batch [140/244] time 0.162 (0.168) data 0.000 (0.002) loss 0.8909 (1.1593) ce_loss 0.7725 (1.0348) teacher_loss 0.7785 (1.0315) loss_zs_kd 0.1560 (0.1590) loss_oracle 0.0344 (0.0483) acc 78.1250 (72.5670) kd_loss 0.0265 (0.0334) lr 5.7422e-04 eta 0:11:14
epoch [34/50] batch [160/244] time 0.095 (0.168) data 0.000 (0.002) loss 1.3174 (1.1632) ce_loss 1.1846 (1.0374) teacher_loss 1.1816 (1.0338) loss_zs_kd 0.1552 (0.1608) loss_oracle 0.0581 (0.0490) acc 65.6250 (72.6172) kd_loss 0.0448 (0.0338) lr 5.7422e-04 eta 0:11:09
epoch [34/50] batch [180/244] time 0.328 (0.175) data 0.000 (0.002) loss 1.4276 (1.1738) ce_loss 1.2988 (1.0487) teacher_loss 1.2987 (1.0445) loss_zs_kd 0.1672 (0.1611) loss_oracle 0.0452 (0.0488) acc 71.8750 (72.2569) kd_loss 0.0357 (0.0341) lr 5.7422e-04 eta 0:11:34
epoch [34/50] batch [200/244] time 0.145 (0.172) data 0.000 (0.002) loss 1.1730 (1.1701) ce_loss 1.0410 (1.0454) teacher_loss 1.0349 (1.0411) loss_zs_kd 0.1603 (0.1602) loss_oracle 0.0579 (0.0489) acc 68.7500 (72.3594) kd_loss 0.0381 (0.0344) lr 5.7422e-04 eta 0:11:19
epoch [34/50] batch [220/244] time 0.148 (0.171) data 0.000 (0.002) loss 1.2031 (1.1682) ce_loss 1.1152 (1.0440) teacher_loss 1.1170 (1.0397) loss_zs_kd 0.1014 (0.1597) loss_oracle 0.0354 (0.0486) acc 71.8750 (72.5852) kd_loss 0.0314 (0.0343) lr 5.7422e-04 eta 0:11:10
epoch [34/50] batch [240/244] time 0.182 (0.170) data 0.000 (0.001) loss 1.0413 (1.1660) ce_loss 0.8896 (1.0419) teacher_loss 0.8843 (1.0377) loss_zs_kd 0.2123 (0.1598) loss_oracle 0.0508 (0.0484) acc 84.3750 (72.6693) kd_loss 0.0354 (0.0342) lr 5.7422e-04 eta 0:11:03
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,836
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [35/50] batch [20/244] time 0.121 (0.175) data 0.000 (0.013) loss 1.1501 (1.2001) ce_loss 1.0371 (1.0746) teacher_loss 1.0263 (1.0722) loss_zs_kd 0.1553 (0.1661) loss_oracle 0.0461 (0.0449) acc 68.7500 (70.4688) kd_loss 0.0288 (0.0331) lr 5.1825e-04 eta 0:11:21
epoch [35/50] batch [40/244] time 0.162 (0.202) data 0.000 (0.007) loss 1.1896 (1.2254) ce_loss 1.0850 (1.1002) teacher_loss 1.0809 (1.0949) loss_zs_kd 0.1258 (0.1654) loss_oracle 0.0459 (0.0478) acc 68.7500 (70.1562) kd_loss 0.0334 (0.0358) lr 5.1825e-04 eta 0:13:00
epoch [35/50] batch [60/244] time 0.172 (0.188) data 0.001 (0.004) loss 0.9498 (1.2064) ce_loss 0.8481 (1.0806) teacher_loss 0.8517 (1.0757) loss_zs_kd 0.1257 (0.1649) loss_oracle 0.0352 (0.0483) acc 78.1250 (70.4167) kd_loss 0.0286 (0.0360) lr 5.1825e-04 eta 0:12:01
epoch [35/50] batch [80/244] time 0.155 (0.180) data 0.000 (0.003) loss 1.0697 (1.2046) ce_loss 0.9395 (1.0774) teacher_loss 0.9236 (1.0725) loss_zs_kd 0.1706 (0.1668) loss_oracle 0.0607 (0.0487) acc 78.1250 (70.5469) kd_loss 0.0424 (0.0365) lr 5.1825e-04 eta 0:11:27
epoch [35/50] batch [100/244] time 0.177 (0.175) data 0.000 (0.003) loss 0.9371 (1.1942) ce_loss 0.8174 (1.0650) teacher_loss 0.8204 (1.0605) loss_zs_kd 0.1450 (0.1695) loss_oracle 0.0442 (0.0490) acc 75.0000 (71.2188) kd_loss 0.0368 (0.0371) lr 5.1825e-04 eta 0:11:05
epoch [35/50] batch [120/244] time 0.156 (0.172) data 0.000 (0.002) loss 1.1274 (1.1851) ce_loss 1.0244 (1.0563) teacher_loss 1.0205 (1.0519) loss_zs_kd 0.1048 (0.1684) loss_oracle 0.0545 (0.0490) acc 81.2500 (71.6667) kd_loss 0.0425 (0.0375) lr 5.1825e-04 eta 0:10:49
epoch [35/50] batch [140/244] time 0.147 (0.170) data 0.000 (0.002) loss 1.0357 (1.1727) ce_loss 0.9067 (1.0448) teacher_loss 0.9096 (1.0408) loss_zs_kd 0.1679 (0.1662) loss_oracle 0.0423 (0.0489) acc 81.2500 (71.9866) kd_loss 0.0401 (0.0377) lr 5.1825e-04 eta 0:10:38
epoch [35/50] batch [160/244] time 0.147 (0.168) data 0.000 (0.002) loss 1.5350 (1.1745) ce_loss 1.3828 (1.0463) teacher_loss 1.3767 (1.0423) loss_zs_kd 0.1922 (0.1672) loss_oracle 0.0622 (0.0486) acc 53.1250 (71.9531) kd_loss 0.0516 (0.0378) lr 5.1825e-04 eta 0:10:28
epoch [35/50] batch [180/244] time 0.101 (0.166) data 0.000 (0.002) loss 1.5328 (1.1870) ce_loss 1.4121 (1.0605) teacher_loss 1.3896 (1.0564) loss_zs_kd 0.1468 (0.1648) loss_oracle 0.0698 (0.0482) acc 53.1250 (71.6319) kd_loss 0.0532 (0.0381) lr 5.1825e-04 eta 0:10:17
epoch [35/50] batch [200/244] time 0.085 (0.172) data 0.000 (0.001) loss 0.7268 (1.1950) ce_loss 0.6016 (1.0692) teacher_loss 0.5871 (1.0645) loss_zs_kd 0.1674 (0.1637) loss_oracle 0.0559 (0.0486) acc 90.6250 (71.3594) kd_loss 0.0439 (0.0387) lr 5.1825e-04 eta 0:10:35
epoch [35/50] batch [220/244] time 0.154 (0.170) data 0.000 (0.001) loss 1.2937 (1.1968) ce_loss 1.1602 (1.0706) teacher_loss 1.1581 (1.0660) loss_zs_kd 0.1650 (0.1641) loss_oracle 0.0530 (0.0487) acc 68.7500 (71.3494) kd_loss 0.0374 (0.0388) lr 5.1825e-04 eta 0:10:25
epoch [35/50] batch [240/244] time 0.156 (0.169) data 0.000 (0.001) loss 1.0296 (1.2048) ce_loss 0.9443 (1.0789) teacher_loss 0.9397 (1.0743) loss_zs_kd 0.1023 (0.1633) loss_oracle 0.0388 (0.0488) acc 71.8750 (71.1979) kd_loss 0.0348 (0.0388) lr 5.1825e-04 eta 0:10:18
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,833
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,045
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [36/50] batch [20/244] time 0.182 (0.182) data 0.000 (0.012) loss 1.5507 (1.3750) ce_loss 1.4395 (1.2449) teacher_loss 1.4297 (1.2408) loss_zs_kd 0.1458 (0.1682) loss_oracle 0.0480 (0.0500) acc 59.3750 (66.7188) kd_loss 0.0404 (0.0387) lr 4.6417e-04 eta 0:11:03
epoch [36/50] batch [40/244] time 0.102 (0.167) data 0.000 (0.006) loss 1.3623 (1.2917) ce_loss 1.2344 (1.1604) teacher_loss 1.2367 (1.1571) loss_zs_kd 0.1861 (0.1684) loss_oracle 0.0326 (0.0504) acc 62.5000 (69.0625) kd_loss 0.0305 (0.0399) lr 4.6417e-04 eta 0:10:03
epoch [36/50] batch [60/244] time 0.083 (0.185) data 0.001 (0.004) loss 0.7959 (1.2557) ce_loss 0.6860 (1.1285) teacher_loss 0.6780 (1.1253) loss_zs_kd 0.1169 (0.1613) loss_oracle 0.0594 (0.0497) acc 84.3750 (70.1562) kd_loss 0.0441 (0.0398) lr 4.6417e-04 eta 0:11:05
epoch [36/50] batch [80/244] time 0.179 (0.180) data 0.000 (0.003) loss 1.1216 (1.2278) ce_loss 0.9443 (1.1028) teacher_loss 0.9490 (1.0997) loss_zs_kd 0.2349 (0.1582) loss_oracle 0.0552 (0.0490) acc 78.1250 (70.4688) kd_loss 0.0378 (0.0389) lr 4.6417e-04 eta 0:10:43
epoch [36/50] batch [100/244] time 0.154 (0.176) data 0.000 (0.003) loss 1.1331 (1.2095) ce_loss 0.9746 (1.0829) teacher_loss 0.9716 (1.0795) loss_zs_kd 0.2301 (0.1605) loss_oracle 0.0465 (0.0497) acc 71.8750 (71.0000) kd_loss 0.0392 (0.0390) lr 4.6417e-04 eta 0:10:28
epoch [36/50] batch [120/244] time 0.155 (0.174) data 0.000 (0.002) loss 1.0770 (1.2122) ce_loss 0.9878 (1.0841) teacher_loss 0.9845 (1.0807) loss_zs_kd 0.1238 (0.1628) loss_oracle 0.0306 (0.0501) acc 68.7500 (71.2500) kd_loss 0.0304 (0.0391) lr 4.6417e-04 eta 0:10:16
epoch [36/50] batch [140/244] time 0.169 (0.173) data 0.000 (0.002) loss 1.0207 (1.2056) ce_loss 0.8906 (1.0780) teacher_loss 0.8978 (1.0751) loss_zs_kd 0.1764 (0.1626) loss_oracle 0.0347 (0.0492) acc 75.0000 (71.4509) kd_loss 0.0492 (0.0389) lr 4.6417e-04 eta 0:10:07
epoch [36/50] batch [160/244] time 0.155 (0.171) data 0.000 (0.002) loss 1.1198 (1.2104) ce_loss 0.9736 (1.0836) teacher_loss 0.9729 (1.0809) loss_zs_kd 0.2144 (0.1622) loss_oracle 0.0397 (0.0483) acc 71.8750 (71.5039) kd_loss 0.0363 (0.0389) lr 4.6417e-04 eta 0:09:58
epoch [36/50] batch [180/244] time 0.100 (0.170) data 0.000 (0.002) loss 1.0044 (1.2055) ce_loss 0.8862 (1.0790) teacher_loss 0.8908 (1.0761) loss_zs_kd 0.1510 (0.1614) loss_oracle 0.0380 (0.0487) acc 71.8750 (71.4931) kd_loss 0.0348 (0.0396) lr 4.6417e-04 eta 0:09:50
epoch [36/50] batch [200/244] time 0.087 (0.175) data 0.000 (0.001) loss 1.2999 (1.2030) ce_loss 1.1621 (1.0765) teacher_loss 1.1523 (1.0736) loss_zs_kd 0.1887 (0.1616) loss_oracle 0.0532 (0.0487) acc 65.6250 (71.5625) kd_loss 0.0484 (0.0400) lr 4.6417e-04 eta 0:10:05
epoch [36/50] batch [220/244] time 0.148 (0.173) data 0.000 (0.001) loss 1.3995 (1.1986) ce_loss 1.2217 (1.0722) teacher_loss 1.2141 (1.0692) loss_zs_kd 0.2593 (0.1614) loss_oracle 0.0557 (0.0487) acc 59.3750 (71.7045) kd_loss 0.0370 (0.0402) lr 4.6417e-04 eta 0:09:54
epoch [36/50] batch [240/244] time 0.166 (0.172) data 0.000 (0.001) loss 1.2043 (1.1906) ce_loss 1.1289 (1.0648) teacher_loss 1.1221 (1.0618) loss_zs_kd 0.0986 (0.1607) loss_oracle 0.0329 (0.0485) acc 59.3750 (71.7969) kd_loss 0.0321 (0.0401) lr 4.6417e-04 eta 0:09:47
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,830
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [37/50] batch [20/244] time 0.149 (0.171) data 0.000 (0.013) loss 0.5848 (1.1942) ce_loss 0.4795 (1.0709) teacher_loss 0.4818 (1.0675) loss_zs_kd 0.0987 (0.1528) loss_oracle 0.0537 (0.0503) acc 93.7500 (72.5000) kd_loss 0.0429 (0.0393) lr 4.1221e-04 eta 0:09:39
epoch [37/50] batch [40/244] time 0.160 (0.165) data 0.000 (0.007) loss 1.1744 (1.1880) ce_loss 1.0518 (1.0663) teacher_loss 1.0565 (1.0623) loss_zs_kd 0.1317 (0.1492) loss_oracle 0.0521 (0.0510) acc 71.8750 (71.9531) kd_loss 0.0311 (0.0381) lr 4.1221e-04 eta 0:09:16
epoch [37/50] batch [60/244] time 0.384 (0.181) data 0.001 (0.004) loss 1.2230 (1.2062) ce_loss 1.0938 (1.0828) teacher_loss 1.0681 (1.0775) loss_zs_kd 0.1705 (0.1554) loss_oracle 0.0697 (0.0510) acc 75.0000 (71.6667) kd_loss 0.0373 (0.0373) lr 4.1221e-04 eta 0:10:06
epoch [37/50] batch [80/244] time 0.170 (0.173) data 0.000 (0.003) loss 1.3142 (1.2210) ce_loss 1.1592 (1.0973) teacher_loss 1.1601 (1.0922) loss_zs_kd 0.1873 (0.1543) loss_oracle 0.0605 (0.0516) acc 68.7500 (71.2109) kd_loss 0.0325 (0.0366) lr 4.1221e-04 eta 0:09:38
epoch [37/50] batch [100/244] time 0.158 (0.171) data 0.000 (0.003) loss 1.0491 (1.2301) ce_loss 0.9292 (1.1030) teacher_loss 0.9248 (1.0982) loss_zs_kd 0.1660 (0.1589) loss_oracle 0.0414 (0.0524) acc 75.0000 (70.6562) kd_loss 0.0288 (0.0364) lr 4.1221e-04 eta 0:09:27
epoch [37/50] batch [120/244] time 0.154 (0.170) data 0.000 (0.002) loss 1.0002 (1.2269) ce_loss 0.8594 (1.0976) teacher_loss 0.8637 (1.0934) loss_zs_kd 0.1850 (0.1632) loss_oracle 0.0441 (0.0519) acc 75.0000 (71.0938) kd_loss 0.0303 (0.0358) lr 4.1221e-04 eta 0:09:18
epoch [37/50] batch [140/244] time 0.157 (0.168) data 0.000 (0.002) loss 1.4366 (1.2307) ce_loss 1.2998 (1.1009) teacher_loss 1.3005 (1.0970) loss_zs_kd 0.1760 (0.1644) loss_oracle 0.0481 (0.0515) acc 65.6250 (71.1830) kd_loss 0.0314 (0.0358) lr 4.1221e-04 eta 0:09:11
epoch [37/50] batch [160/244] time 0.155 (0.168) data 0.000 (0.002) loss 1.4092 (1.2238) ce_loss 1.3008 (1.0937) teacher_loss 1.2950 (1.0897) loss_zs_kd 0.1318 (0.1648) loss_oracle 0.0482 (0.0517) acc 62.5000 (71.5039) kd_loss 0.0370 (0.0360) lr 4.1221e-04 eta 0:09:05
epoch [37/50] batch [180/244] time 0.172 (0.168) data 0.002 (0.002) loss 1.6671 (1.2169) ce_loss 1.5342 (1.0871) teacher_loss 1.5263 (1.0832) loss_zs_kd 0.1652 (0.1640) loss_oracle 0.0581 (0.0517) acc 59.3750 (71.6493) kd_loss 0.0544 (0.0363) lr 4.1221e-04 eta 0:09:02
epoch [37/50] batch [200/244] time 0.162 (0.171) data 0.000 (0.001) loss 1.0600 (1.2128) ce_loss 0.9077 (1.0831) teacher_loss 0.9082 (1.0793) loss_zs_kd 0.1995 (0.1637) loss_oracle 0.0521 (0.0517) acc 75.0000 (71.6719) kd_loss 0.0423 (0.0365) lr 4.1221e-04 eta 0:09:09
epoch [37/50] batch [220/244] time 0.148 (0.169) data 0.000 (0.001) loss 1.3071 (1.2125) ce_loss 1.1973 (1.0828) teacher_loss 1.1898 (1.0789) loss_zs_kd 0.1464 (0.1637) loss_oracle 0.0441 (0.0517) acc 62.5000 (71.6903) kd_loss 0.0355 (0.0365) lr 4.1221e-04 eta 0:09:01
epoch [37/50] batch [240/244] time 0.165 (0.168) data 0.000 (0.001) loss 1.4347 (1.2138) ce_loss 1.3291 (1.0843) teacher_loss 1.3248 (1.0805) loss_zs_kd 0.1218 (0.1638) loss_oracle 0.0489 (0.0513) acc 65.6250 (71.6536) kd_loss 0.0368 (0.0366) lr 4.1221e-04 eta 0:08:54
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,829
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,038
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [38/50] batch [20/244] time 0.167 (0.173) data 0.000 (0.014) loss 1.4981 (1.2527) ce_loss 1.3828 (1.1300) teacher_loss 1.3771 (1.1246) loss_zs_kd 0.1206 (0.1558) loss_oracle 0.0607 (0.0502) acc 71.8750 (69.3750) kd_loss 0.0534 (0.0401) lr 3.6258e-04 eta 0:09:05
epoch [38/50] batch [40/244] time 0.171 (0.167) data 0.000 (0.007) loss 1.3140 (1.1694) ce_loss 1.2002 (1.0501) teacher_loss 1.1847 (1.0460) loss_zs_kd 0.1596 (0.1505) loss_oracle 0.0495 (0.0482) acc 71.8750 (71.6406) kd_loss 0.0415 (0.0389) lr 3.6258e-04 eta 0:08:42
epoch [38/50] batch [60/244] time 0.172 (0.165) data 0.001 (0.005) loss 1.4215 (1.1513) ce_loss 1.3232 (1.0312) teacher_loss 1.3173 (1.0273) loss_zs_kd 0.1182 (0.1502) loss_oracle 0.0451 (0.0490) acc 59.3750 (72.8125) kd_loss 0.0385 (0.0400) lr 3.6258e-04 eta 0:08:34
epoch [38/50] batch [80/244] time 0.091 (0.169) data 0.001 (0.004) loss 1.6164 (1.1790) ce_loss 1.4775 (1.0564) teacher_loss 1.4723 (1.0526) loss_zs_kd 0.1793 (0.1547) loss_oracle 0.0544 (0.0490) acc 59.3750 (72.3047) kd_loss 0.0426 (0.0401) lr 3.6258e-04 eta 0:08:42
epoch [38/50] batch [100/244] time 0.091 (0.165) data 0.000 (0.003) loss 1.8693 (1.1830) ce_loss 1.7383 (1.0587) teacher_loss 1.7305 (1.0548) loss_zs_kd 0.1706 (0.1578) loss_oracle 0.0534 (0.0493) acc 40.6250 (71.9062) kd_loss 0.0492 (0.0401) lr 3.6258e-04 eta 0:08:25
epoch [38/50] batch [120/244] time 0.111 (0.155) data 0.000 (0.003) loss 0.9438 (1.1875) ce_loss 0.8179 (1.0639) teacher_loss 0.8192 (1.0599) loss_zs_kd 0.1646 (0.1562) loss_oracle 0.0423 (0.0495) acc 81.2500 (71.9792) kd_loss 0.0485 (0.0404) lr 3.6258e-04 eta 0:07:53
epoch [38/50] batch [140/244] time 0.088 (0.148) data 0.000 (0.002) loss 1.2877 (1.1897) ce_loss 1.1680 (1.0658) teacher_loss 1.1594 (1.0612) loss_zs_kd 0.1403 (0.1566) loss_oracle 0.0582 (0.0502) acc 68.7500 (71.9866) kd_loss 0.0511 (0.0406) lr 3.6258e-04 eta 0:07:29
epoch [38/50] batch [160/244] time 0.095 (0.142) data 0.000 (0.002) loss 1.1250 (1.1882) ce_loss 1.0166 (1.0634) teacher_loss 1.0195 (1.0591) loss_zs_kd 0.1496 (0.1584) loss_oracle 0.0307 (0.0499) acc 75.0000 (72.0117) kd_loss 0.0259 (0.0401) lr 3.6258e-04 eta 0:07:07
epoch [38/50] batch [180/244] time 0.163 (0.143) data 0.000 (0.002) loss 1.3400 (1.1936) ce_loss 1.2021 (1.0688) teacher_loss 1.1972 (1.0646) loss_zs_kd 0.1797 (0.1589) loss_oracle 0.0529 (0.0496) acc 65.6250 (71.8403) kd_loss 0.0352 (0.0397) lr 3.6258e-04 eta 0:07:07
epoch [38/50] batch [200/244] time 0.153 (0.145) data 0.000 (0.002) loss 1.0412 (1.1970) ce_loss 0.9336 (1.0713) teacher_loss 0.9370 (1.0672) loss_zs_kd 0.1308 (0.1607) loss_oracle 0.0388 (0.0494) acc 78.1250 (71.8906) kd_loss 0.0359 (0.0396) lr 3.6258e-04 eta 0:07:11
epoch [38/50] batch [220/244] time 0.181 (0.147) data 0.000 (0.002) loss 0.9188 (1.2021) ce_loss 0.7866 (1.0760) teacher_loss 0.7908 (1.0716) loss_zs_kd 0.1386 (0.1617) loss_oracle 0.0588 (0.0497) acc 81.2500 (71.8324) kd_loss 0.0411 (0.0396) lr 3.6258e-04 eta 0:07:14
epoch [38/50] batch [240/244] time 0.170 (0.148) data 0.000 (0.001) loss 1.3280 (1.1987) ce_loss 1.1768 (1.0722) teacher_loss 1.1815 (1.0679) loss_zs_kd 0.1945 (0.1621) loss_oracle 0.0492 (0.0497) acc 65.6250 (72.0052) kd_loss 0.0299 (0.0396) lr 3.6258e-04 eta 0:07:13
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,834
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [39/50] batch [20/244] time 0.166 (0.208) data 0.000 (0.014) loss 1.6677 (1.2251) ce_loss 1.5234 (1.1028) teacher_loss 1.5297 (1.0981) loss_zs_kd 0.1689 (0.1546) loss_oracle 0.0535 (0.0498) acc 59.3750 (73.2812) kd_loss 0.0416 (0.0416) lr 3.1545e-04 eta 0:10:04
epoch [39/50] batch [40/244] time 0.160 (0.184) data 0.000 (0.007) loss 1.3939 (1.2075) ce_loss 1.2773 (1.0789) teacher_loss 1.2762 (1.0754) loss_zs_kd 0.1472 (0.1629) loss_oracle 0.0441 (0.0506) acc 65.6250 (72.1875) kd_loss 0.0369 (0.0415) lr 3.1545e-04 eta 0:08:51
epoch [39/50] batch [60/244] time 0.171 (0.178) data 0.000 (0.005) loss 0.9345 (1.1882) ce_loss 0.8115 (1.0575) teacher_loss 0.7987 (1.0532) loss_zs_kd 0.1549 (0.1676) loss_oracle 0.0584 (0.0512) acc 84.3750 (72.3438) kd_loss 0.0538 (0.0421) lr 3.1545e-04 eta 0:08:30
epoch [39/50] batch [80/244] time 0.149 (0.173) data 0.000 (0.004) loss 1.2457 (1.1985) ce_loss 1.1338 (1.0705) teacher_loss 1.1319 (1.0658) loss_zs_kd 0.1282 (0.1641) loss_oracle 0.0497 (0.0507) acc 68.7500 (72.2266) kd_loss 0.0444 (0.0423) lr 3.1545e-04 eta 0:08:12
epoch [39/50] batch [100/244] time 0.156 (0.170) data 0.000 (0.003) loss 1.2296 (1.1877) ce_loss 1.0977 (1.0586) teacher_loss 1.0964 (1.0541) loss_zs_kd 0.1477 (0.1646) loss_oracle 0.0594 (0.0513) acc 65.6250 (72.0625) kd_loss 0.0435 (0.0423) lr 3.1545e-04 eta 0:08:01
epoch [39/50] batch [120/244] time 0.090 (0.170) data 0.000 (0.003) loss 0.9930 (1.1910) ce_loss 0.8525 (1.0608) teacher_loss 0.8459 (1.0560) loss_zs_kd 0.1996 (0.1666) loss_oracle 0.0473 (0.0517) acc 78.1250 (71.9271) kd_loss 0.0476 (0.0428) lr 3.1545e-04 eta 0:07:56
epoch [39/50] batch [140/244] time 0.091 (0.176) data 0.000 (0.002) loss 1.3547 (1.1916) ce_loss 1.2471 (1.0604) teacher_loss 1.2499 (1.0560) loss_zs_kd 0.1421 (0.1684) loss_oracle 0.0337 (0.0514) acc 62.5000 (71.8750) kd_loss 0.0315 (0.0426) lr 3.1545e-04 eta 0:08:11
epoch [39/50] batch [160/244] time 0.149 (0.174) data 0.000 (0.002) loss 1.2773 (1.2029) ce_loss 1.1367 (1.0720) teacher_loss 1.1281 (1.0674) loss_zs_kd 0.2187 (0.1678) loss_oracle 0.0399 (0.0516) acc 65.6250 (71.7383) kd_loss 0.0433 (0.0428) lr 3.1545e-04 eta 0:08:00
epoch [39/50] batch [180/244] time 0.155 (0.172) data 0.000 (0.002) loss 0.8313 (1.2046) ce_loss 0.7109 (1.0731) teacher_loss 0.7175 (1.0685) loss_zs_kd 0.1423 (0.1683) loss_oracle 0.0427 (0.0519) acc 75.0000 (71.6146) kd_loss 0.0425 (0.0431) lr 3.1545e-04 eta 0:07:53
epoch [39/50] batch [200/244] time 0.169 (0.172) data 0.000 (0.002) loss 1.2775 (1.2071) ce_loss 1.1553 (1.0761) teacher_loss 1.1615 (1.0714) loss_zs_kd 0.1447 (0.1680) loss_oracle 0.0436 (0.0517) acc 75.0000 (71.6094) kd_loss 0.0374 (0.0432) lr 3.1545e-04 eta 0:07:48
epoch [39/50] batch [220/244] time 0.176 (0.171) data 0.000 (0.001) loss 1.8889 (1.2127) ce_loss 1.7881 (1.0823) teacher_loss 1.7842 (1.0774) loss_zs_kd 0.1111 (0.1667) loss_oracle 0.0491 (0.0520) acc 53.1250 (71.4773) kd_loss 0.0424 (0.0435) lr 3.1545e-04 eta 0:07:43
epoch [39/50] batch [240/244] time 0.083 (0.171) data 0.000 (0.001) loss 1.1235 (1.2127) ce_loss 1.0107 (1.0819) teacher_loss 1.0094 (1.0771) loss_zs_kd 0.1400 (0.1663) loss_oracle 0.0441 (0.0524) acc 68.7500 (71.4453) kd_loss 0.0387 (0.0439) lr 3.1545e-04 eta 0:07:39
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,831
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [40/50] batch [20/244] time 0.146 (0.169) data 0.000 (0.013) loss 1.0978 (1.2392) ce_loss 0.9658 (1.1067) teacher_loss 0.9626 (1.1011) loss_zs_kd 0.1893 (0.1640) loss_oracle 0.0405 (0.0560) acc 78.1250 (70.4688) kd_loss 0.0327 (0.0489) lr 2.7103e-04 eta 0:07:29
epoch [40/50] batch [40/244] time 0.153 (0.162) data 0.000 (0.007) loss 1.1703 (1.2293) ce_loss 1.0312 (1.0967) teacher_loss 1.0370 (1.0921) loss_zs_kd 0.1871 (0.1672) loss_oracle 0.0398 (0.0537) acc 75.0000 (71.4062) kd_loss 0.0262 (0.0463) lr 2.7103e-04 eta 0:07:07
epoch [40/50] batch [60/244] time 0.151 (0.160) data 0.000 (0.005) loss 1.1051 (1.2193) ce_loss 1.0137 (1.0856) teacher_loss 1.0062 (1.0818) loss_zs_kd 0.1058 (0.1703) loss_oracle 0.0460 (0.0523) acc 68.7500 (72.0312) kd_loss 0.0357 (0.0455) lr 2.7103e-04 eta 0:06:59
epoch [40/50] batch [80/244] time 0.177 (0.160) data 0.000 (0.003) loss 1.0810 (1.2391) ce_loss 0.9702 (1.1005) teacher_loss 0.9746 (1.0960) loss_zs_kd 0.1200 (0.1772) loss_oracle 0.0464 (0.0545) acc 78.1250 (71.5625) kd_loss 0.0407 (0.0459) lr 2.7103e-04 eta 0:06:55
epoch [40/50] batch [100/244] time 0.348 (0.162) data 0.000 (0.003) loss 0.8994 (1.2166) ce_loss 0.7666 (1.0781) teacher_loss 0.7536 (1.0736) loss_zs_kd 0.1508 (0.1759) loss_oracle 0.0704 (0.0550) acc 75.0000 (72.0625) kd_loss 0.0532 (0.0460) lr 2.7103e-04 eta 0:06:59
epoch [40/50] batch [120/244] time 0.173 (0.169) data 0.000 (0.002) loss 1.0584 (1.2131) ce_loss 0.9658 (1.0763) teacher_loss 0.9489 (1.0718) loss_zs_kd 0.0981 (0.1726) loss_oracle 0.0604 (0.0550) acc 78.1250 (72.0833) kd_loss 0.0537 (0.0464) lr 2.7103e-04 eta 0:07:13
epoch [40/50] batch [140/244] time 0.166 (0.168) data 0.000 (0.002) loss 0.7682 (1.2058) ce_loss 0.6479 (1.0686) teacher_loss 0.6510 (1.0639) loss_zs_kd 0.1194 (0.1739) loss_oracle 0.0575 (0.0549) acc 84.3750 (72.3214) kd_loss 0.0506 (0.0465) lr 2.7103e-04 eta 0:07:07
epoch [40/50] batch [160/244] time 0.168 (0.166) data 0.000 (0.002) loss 1.3409 (1.1938) ce_loss 1.2080 (1.0576) teacher_loss 1.2070 (1.0532) loss_zs_kd 0.1774 (0.1722) loss_oracle 0.0451 (0.0544) acc 81.2500 (72.5781) kd_loss 0.0360 (0.0463) lr 2.7103e-04 eta 0:06:59
epoch [40/50] batch [180/244] time 0.144 (0.164) data 0.000 (0.002) loss 1.0102 (1.2014) ce_loss 0.8770 (1.0653) teacher_loss 0.8738 (1.0608) loss_zs_kd 0.1880 (0.1727) loss_oracle 0.0424 (0.0542) acc 71.8750 (72.4132) kd_loss 0.0438 (0.0462) lr 2.7103e-04 eta 0:06:51
epoch [40/50] batch [200/244] time 0.151 (0.163) data 0.000 (0.002) loss 0.6953 (1.2001) ce_loss 0.5352 (1.0653) teacher_loss 0.5324 (1.0607) loss_zs_kd 0.2243 (0.1710) loss_oracle 0.0507 (0.0540) acc 90.6250 (72.3281) kd_loss 0.0521 (0.0461) lr 2.7103e-04 eta 0:06:45
epoch [40/50] batch [220/244] time 0.154 (0.162) data 0.000 (0.001) loss 0.8699 (1.1885) ce_loss 0.7715 (1.0543) teacher_loss 0.7697 (1.0498) loss_zs_kd 0.1230 (0.1706) loss_oracle 0.0387 (0.0534) acc 75.0000 (72.5994) kd_loss 0.0371 (0.0459) lr 2.7103e-04 eta 0:06:40
epoch [40/50] batch [240/244] time 0.081 (0.161) data 0.000 (0.001) loss 1.0393 (1.1850) ce_loss 0.9053 (1.0510) teacher_loss 0.8877 (1.0466) loss_zs_kd 0.1770 (0.1704) loss_oracle 0.0631 (0.0532) acc 78.1250 (72.6823) kd_loss 0.0483 (0.0456) lr 2.7103e-04 eta 0:06:34
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,834
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [41/50] batch [20/244] time 0.165 (0.164) data 0.000 (0.013) loss 0.9268 (1.1571) ce_loss 0.8179 (1.0233) teacher_loss 0.8135 (1.0185) loss_zs_kd 0.1380 (0.1748) loss_oracle 0.0442 (0.0512) acc 78.1250 (72.8125) kd_loss 0.0454 (0.0446) lr 2.2949e-04 eta 0:06:36
epoch [41/50] batch [40/244] time 0.146 (0.158) data 0.000 (0.007) loss 1.0434 (1.1475) ce_loss 0.9126 (1.0130) teacher_loss 0.9132 (1.0077) loss_zs_kd 0.1533 (0.1741) loss_oracle 0.0536 (0.0527) acc 81.2500 (74.0625) kd_loss 0.0503 (0.0453) lr 2.2949e-04 eta 0:06:18
epoch [41/50] batch [60/244] time 0.171 (0.154) data 0.000 (0.005) loss 0.8563 (1.1585) ce_loss 0.7573 (1.0261) teacher_loss 0.7550 (1.0211) loss_zs_kd 0.1200 (0.1703) loss_oracle 0.0412 (0.0523) acc 75.0000 (72.9688) kd_loss 0.0324 (0.0460) lr 2.2949e-04 eta 0:06:07
epoch [41/50] batch [80/244] time 0.172 (0.154) data 0.000 (0.004) loss 1.0841 (1.1614) ce_loss 0.9224 (1.0273) teacher_loss 0.9119 (1.0224) loss_zs_kd 0.2210 (0.1729) loss_oracle 0.0617 (0.0525) acc 68.7500 (72.7344) kd_loss 0.0617 (0.0473) lr 2.2949e-04 eta 0:06:02
epoch [41/50] batch [100/244] time 0.101 (0.155) data 0.000 (0.003) loss 0.8836 (1.1714) ce_loss 0.7656 (1.0358) teacher_loss 0.7564 (1.0310) loss_zs_kd 0.1546 (0.1758) loss_oracle 0.0499 (0.0525) acc 78.1250 (72.4375) kd_loss 0.0436 (0.0473) lr 2.2949e-04 eta 0:06:02
epoch [41/50] batch [120/244] time 0.102 (0.165) data 0.000 (0.002) loss 0.6748 (1.1681) ce_loss 0.5283 (1.0327) teacher_loss 0.5246 (1.0277) loss_zs_kd 0.1585 (0.1754) loss_oracle 0.0709 (0.0528) acc 87.5000 (72.4219) kd_loss 0.0586 (0.0481) lr 2.2949e-04 eta 0:06:23
epoch [41/50] batch [140/244] time 0.164 (0.163) data 0.000 (0.002) loss 1.3812 (1.1571) ce_loss 1.2363 (1.0226) teacher_loss 1.2346 (1.0177) loss_zs_kd 0.1852 (0.1730) loss_oracle 0.0541 (0.0530) acc 68.7500 (72.8795) kd_loss 0.0522 (0.0482) lr 2.2949e-04 eta 0:06:15
epoch [41/50] batch [160/244] time 0.152 (0.163) data 0.000 (0.002) loss 0.6170 (1.1534) ce_loss 0.4785 (1.0196) teacher_loss 0.4812 (1.0152) loss_zs_kd 0.1710 (0.1717) loss_oracle 0.0503 (0.0524) acc 87.5000 (73.1055) kd_loss 0.0380 (0.0478) lr 2.2949e-04 eta 0:06:11
epoch [41/50] batch [180/244] time 0.148 (0.162) data 0.000 (0.002) loss 1.0364 (1.1570) ce_loss 0.9038 (1.0233) teacher_loss 0.9041 (1.0189) loss_zs_kd 0.1796 (0.1722) loss_oracle 0.0426 (0.0520) acc 71.8750 (73.0035) kd_loss 0.0373 (0.0476) lr 2.2949e-04 eta 0:06:05
epoch [41/50] batch [200/244] time 0.177 (0.162) data 0.000 (0.002) loss 1.1044 (1.1553) ce_loss 1.0020 (1.0222) teacher_loss 0.9994 (1.0176) loss_zs_kd 0.1283 (0.1713) loss_oracle 0.0408 (0.0520) acc 81.2500 (73.0781) kd_loss 0.0427 (0.0474) lr 2.2949e-04 eta 0:06:02
epoch [41/50] batch [220/244] time 0.420 (0.163) data 0.000 (0.001) loss 1.4217 (1.1545) ce_loss 1.2744 (1.0219) teacher_loss 1.2679 (1.0174) loss_zs_kd 0.1951 (0.1702) loss_oracle 0.0563 (0.0519) acc 62.5000 (73.1960) kd_loss 0.0514 (0.0470) lr 2.2949e-04 eta 0:06:01
epoch [41/50] batch [240/244] time 0.082 (0.168) data 0.000 (0.001) loss 1.2493 (1.1557) ce_loss 1.1006 (1.0233) teacher_loss 1.0927 (1.0188) loss_zs_kd 0.2000 (0.1701) loss_oracle 0.0566 (0.0519) acc 68.7500 (73.1510) kd_loss 0.0518 (0.0468) lr 2.2949e-04 eta 0:06:09
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,831
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,042
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [42/50] batch [20/244] time 0.163 (0.182) data 0.000 (0.015) loss 1.0299 (1.1685) ce_loss 0.9028 (1.0482) teacher_loss 0.9081 (1.0432) loss_zs_kd 0.1668 (0.1501) loss_oracle 0.0384 (0.0503) acc 78.1250 (71.7188) kd_loss 0.0396 (0.0467) lr 1.9098e-04 eta 0:06:35
epoch [42/50] batch [40/244] time 0.179 (0.178) data 0.000 (0.008) loss 1.2233 (1.1781) ce_loss 1.1074 (1.0518) teacher_loss 1.0994 (1.0469) loss_zs_kd 0.1534 (0.1603) loss_oracle 0.0472 (0.0511) acc 68.7500 (71.4844) kd_loss 0.0487 (0.0464) lr 1.9098e-04 eta 0:06:22
epoch [42/50] batch [60/244] time 0.411 (0.182) data 0.000 (0.005) loss 0.9644 (1.1813) ce_loss 0.8013 (1.0509) teacher_loss 0.7948 (1.0448) loss_zs_kd 0.2213 (0.1675) loss_oracle 0.0589 (0.0527) acc 84.3750 (71.7188) kd_loss 0.0539 (0.0472) lr 1.9098e-04 eta 0:06:28
epoch [42/50] batch [80/244] time 0.150 (0.189) data 0.000 (0.004) loss 1.2724 (1.1905) ce_loss 1.1348 (1.0588) teacher_loss 1.1333 (1.0523) loss_zs_kd 0.1590 (0.1681) loss_oracle 0.0596 (0.0542) acc 78.1250 (72.0703) kd_loss 0.0654 (0.0483) lr 1.9098e-04 eta 0:06:40
epoch [42/50] batch [100/244] time 0.153 (0.183) data 0.000 (0.003) loss 1.6823 (1.1828) ce_loss 1.5625 (1.0540) teacher_loss 1.5519 (1.0478) loss_zs_kd 0.1639 (0.1640) loss_oracle 0.0485 (0.0530) acc 59.3750 (72.1875) kd_loss 0.0431 (0.0468) lr 1.9098e-04 eta 0:06:24
epoch [42/50] batch [120/244] time 0.170 (0.179) data 0.000 (0.003) loss 1.2566 (1.1929) ce_loss 1.1445 (1.0629) teacher_loss 1.1437 (1.0565) loss_zs_kd 0.1510 (0.1670) loss_oracle 0.0374 (0.0528) acc 65.6250 (71.9271) kd_loss 0.0463 (0.0466) lr 1.9098e-04 eta 0:06:12
epoch [42/50] batch [140/244] time 0.163 (0.176) data 0.000 (0.002) loss 0.5994 (1.1851) ce_loss 0.4978 (1.0558) teacher_loss 0.4922 (1.0495) loss_zs_kd 0.1232 (0.1655) loss_oracle 0.0455 (0.0528) acc 87.5000 (72.2098) kd_loss 0.0405 (0.0468) lr 1.9098e-04 eta 0:06:02
epoch [42/50] batch [160/244] time 0.177 (0.175) data 0.000 (0.002) loss 1.1085 (1.1865) ce_loss 0.9619 (1.0553) teacher_loss 0.9684 (1.0492) loss_zs_kd 0.1949 (0.1678) loss_oracle 0.0425 (0.0534) acc 78.1250 (72.3633) kd_loss 0.0451 (0.0473) lr 1.9098e-04 eta 0:05:55
epoch [42/50] batch [180/244] time 0.126 (0.173) data 0.000 (0.002) loss 1.2819 (1.1803) ce_loss 1.1455 (1.0488) teacher_loss 1.1474 (1.0431) loss_zs_kd 0.1720 (0.1683) loss_oracle 0.0486 (0.0530) acc 71.8750 (72.6389) kd_loss 0.0416 (0.0469) lr 1.9098e-04 eta 0:05:49
epoch [42/50] batch [200/244] time 0.165 (0.180) data 0.000 (0.002) loss 0.9800 (1.1738) ce_loss 0.8926 (1.0430) teacher_loss 0.8883 (1.0375) loss_zs_kd 0.1156 (0.1667) loss_oracle 0.0339 (0.0529) acc 78.1250 (72.8281) kd_loss 0.0356 (0.0469) lr 1.9098e-04 eta 0:05:59
epoch [42/50] batch [220/244] time 0.179 (0.179) data 0.000 (0.002) loss 1.3046 (1.1752) ce_loss 1.1602 (1.0448) teacher_loss 1.1570 (1.0396) loss_zs_kd 0.1876 (0.1655) loss_oracle 0.0537 (0.0528) acc 75.0000 (72.7983) kd_loss 0.0517 (0.0470) lr 1.9098e-04 eta 0:05:53
epoch [42/50] batch [240/244] time 0.149 (0.178) data 0.000 (0.001) loss 0.8878 (1.1835) ce_loss 0.7314 (1.0531) teacher_loss 0.7407 (1.0478) loss_zs_kd 0.2067 (0.1663) loss_oracle 0.0438 (0.0526) acc 81.2500 (72.6302) kd_loss 0.0359 (0.0470) lr 1.9098e-04 eta 0:05:47
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,832
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.6%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [43/50] batch [20/244] time 0.156 (0.259) data 0.000 (0.014) loss 1.0725 (1.1039) ce_loss 0.9653 (0.9698) teacher_loss 0.9545 (0.9653) loss_zs_kd 0.1500 (0.1748) loss_oracle 0.0431 (0.0512) acc 71.8750 (74.8438) kd_loss 0.0470 (0.0473) lr 1.5567e-04 eta 0:08:20
epoch [43/50] batch [40/244] time 0.156 (0.213) data 0.000 (0.007) loss 0.8276 (1.1601) ce_loss 0.6934 (1.0234) teacher_loss 0.6847 (1.0190) loss_zs_kd 0.1655 (0.1761) loss_oracle 0.0601 (0.0531) acc 81.2500 (72.9688) kd_loss 0.0569 (0.0475) lr 1.5567e-04 eta 0:06:46
epoch [43/50] batch [60/244] time 0.149 (0.194) data 0.000 (0.005) loss 1.1988 (1.1668) ce_loss 1.0840 (1.0289) teacher_loss 1.0769 (1.0251) loss_zs_kd 0.1398 (0.1771) loss_oracle 0.0520 (0.0531) acc 65.6250 (73.3333) kd_loss 0.0549 (0.0475) lr 1.5567e-04 eta 0:06:07
epoch [43/50] batch [80/244] time 0.147 (0.186) data 0.000 (0.004) loss 0.8590 (1.1800) ce_loss 0.7275 (1.0439) teacher_loss 0.7210 (1.0397) loss_zs_kd 0.1507 (0.1747) loss_oracle 0.0627 (0.0529) acc 75.0000 (72.7344) kd_loss 0.0534 (0.0478) lr 1.5567e-04 eta 0:05:47
epoch [43/50] batch [100/244] time 0.148 (0.180) data 0.000 (0.003) loss 1.2301 (1.1762) ce_loss 1.0879 (1.0411) teacher_loss 1.0895 (1.0373) loss_zs_kd 0.1602 (0.1719) loss_oracle 0.0606 (0.0530) acc 68.7500 (72.5938) kd_loss 0.0665 (0.0483) lr 1.5567e-04 eta 0:05:33
epoch [43/50] batch [120/244] time 0.088 (0.178) data 0.000 (0.003) loss 1.3213 (1.1866) ce_loss 1.1396 (1.0534) teacher_loss 1.1308 (1.0494) loss_zs_kd 0.2860 (0.1695) loss_oracle 0.0475 (0.0525) acc 68.7500 (72.2656) kd_loss 0.0471 (0.0484) lr 1.5567e-04 eta 0:05:25
epoch [43/50] batch [140/244] time 0.170 (0.185) data 0.000 (0.002) loss 1.1504 (1.1822) ce_loss 1.0059 (1.0489) teacher_loss 1.0071 (1.0452) loss_zs_kd 0.1748 (0.1709) loss_oracle 0.0558 (0.0516) acc 78.1250 (72.4107) kd_loss 0.0489 (0.0475) lr 1.5567e-04 eta 0:05:34
epoch [43/50] batch [160/244] time 0.172 (0.182) data 0.000 (0.002) loss 0.8127 (1.1764) ce_loss 0.7363 (1.0453) teacher_loss 0.7332 (1.0416) loss_zs_kd 0.0995 (0.1674) loss_oracle 0.0298 (0.0511) acc 78.1250 (72.5586) kd_loss 0.0382 (0.0470) lr 1.5567e-04 eta 0:05:26
epoch [43/50] batch [180/244] time 0.147 (0.179) data 0.000 (0.002) loss 1.0517 (1.1768) ce_loss 0.9116 (1.0458) teacher_loss 0.9053 (1.0418) loss_zs_kd 0.1961 (0.1675) loss_oracle 0.0483 (0.0512) acc 65.6250 (72.6042) kd_loss 0.0414 (0.0468) lr 1.5567e-04 eta 0:05:17
epoch [43/50] batch [200/244] time 0.148 (0.176) data 0.000 (0.002) loss 1.3895 (1.1786) ce_loss 1.2695 (1.0483) teacher_loss 1.2550 (1.0439) loss_zs_kd 0.1484 (0.1663) loss_oracle 0.0603 (0.0515) acc 56.2500 (72.3906) kd_loss 0.0423 (0.0468) lr 1.5567e-04 eta 0:05:08
epoch [43/50] batch [220/244] time 0.143 (0.174) data 0.000 (0.001) loss 1.0251 (1.1849) ce_loss 0.8730 (1.0544) teacher_loss 0.8860 (1.0500) loss_zs_kd 0.1756 (0.1671) loss_oracle 0.0513 (0.0513) acc 78.1250 (72.1449) kd_loss 0.0420 (0.0466) lr 1.5567e-04 eta 0:05:01
epoch [43/50] batch [240/244] time 0.080 (0.171) data 0.000 (0.001) loss 1.6087 (1.1848) ce_loss 1.4795 (1.0551) teacher_loss 1.4696 (1.0507) loss_zs_kd 0.1781 (0.1660) loss_oracle 0.0500 (0.0511) acc 56.2500 (72.0443) kd_loss 0.0492 (0.0460) lr 1.5567e-04 eta 0:04:53
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,833
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.1%, epoch: 34 *******
******* Domain p best val test acc: 91.0%, epoch: 34 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [44/50] batch [20/244] time 0.161 (0.163) data 0.000 (0.013) loss 1.5144 (1.2001) ce_loss 1.3389 (1.0685) teacher_loss 1.3387 (1.0649) loss_zs_kd 0.2517 (0.1687) loss_oracle 0.0499 (0.0509) acc 59.3750 (71.4062) kd_loss 0.0415 (0.0443) lr 1.2369e-04 eta 0:04:34
epoch [44/50] batch [40/244] time 0.145 (0.157) data 0.000 (0.006) loss 1.2829 (1.1408) ce_loss 1.1445 (1.0084) teacher_loss 1.1391 (1.0046) loss_zs_kd 0.1869 (0.1679) loss_oracle 0.0505 (0.0523) acc 71.8750 (73.7500) kd_loss 0.0461 (0.0444) lr 1.2369e-04 eta 0:04:21
epoch [44/50] batch [60/244] time 0.157 (0.156) data 0.000 (0.004) loss 1.0765 (1.1229) ce_loss 0.9507 (0.9933) teacher_loss 0.9473 (0.9891) loss_zs_kd 0.1528 (0.1639) loss_oracle 0.0528 (0.0518) acc 81.2500 (74.1667) kd_loss 0.0368 (0.0442) lr 1.2369e-04 eta 0:04:17
epoch [44/50] batch [80/244] time 0.155 (0.156) data 0.000 (0.003) loss 1.4053 (1.1327) ce_loss 1.2725 (1.0042) teacher_loss 1.2750 (1.0001) loss_zs_kd 0.1492 (0.1627) loss_oracle 0.0558 (0.0512) acc 68.7500 (73.9453) kd_loss 0.0479 (0.0441) lr 1.2369e-04 eta 0:04:13
epoch [44/50] batch [100/244] time 0.081 (0.160) data 0.000 (0.003) loss 1.1704 (1.1406) ce_loss 1.0596 (1.0134) teacher_loss 1.0588 (1.0096) loss_zs_kd 0.1306 (0.1610) loss_oracle 0.0463 (0.0505) acc 84.3750 (73.3750) kd_loss 0.0381 (0.0435) lr 1.2369e-04 eta 0:04:17
epoch [44/50] batch [120/244] time 0.148 (0.169) data 0.000 (0.002) loss 1.2675 (1.1596) ce_loss 1.1494 (1.0318) teacher_loss 1.1425 (1.0279) loss_zs_kd 0.1376 (0.1622) loss_oracle 0.0562 (0.0506) acc 65.6250 (72.7865) kd_loss 0.0419 (0.0432) lr 1.2369e-04 eta 0:04:29
epoch [44/50] batch [140/244] time 0.139 (0.167) data 0.000 (0.002) loss 1.0867 (1.1685) ce_loss 0.9746 (1.0403) teacher_loss 0.9807 (1.0360) loss_zs_kd 0.1414 (0.1638) loss_oracle 0.0353 (0.0506) acc 75.0000 (72.5446) kd_loss 0.0297 (0.0432) lr 1.2369e-04 eta 0:04:21
epoch [44/50] batch [160/244] time 0.150 (0.165) data 0.000 (0.002) loss 1.1162 (1.1730) ce_loss 0.9272 (1.0445) teacher_loss 0.9251 (1.0402) loss_zs_kd 0.2460 (0.1643) loss_oracle 0.0681 (0.0506) acc 78.1250 (72.3438) kd_loss 0.0514 (0.0432) lr 1.2369e-04 eta 0:04:15
epoch [44/50] batch [180/244] time 0.147 (0.164) data 0.000 (0.002) loss 1.5805 (1.1811) ce_loss 1.4424 (1.0498) teacher_loss 1.4372 (1.0456) loss_zs_kd 0.1767 (0.1681) loss_oracle 0.0550 (0.0515) acc 53.1250 (72.2743) kd_loss 0.0556 (0.0437) lr 1.2369e-04 eta 0:04:10
epoch [44/50] batch [200/244] time 0.160 (0.163) data 0.000 (0.001) loss 1.3881 (1.1839) ce_loss 1.2559 (1.0525) teacher_loss 1.2663 (1.0486) loss_zs_kd 0.1560 (0.1681) loss_oracle 0.0438 (0.0512) acc 71.8750 (72.2969) kd_loss 0.0440 (0.0436) lr 1.2369e-04 eta 0:04:05
epoch [44/50] batch [220/244] time 0.094 (0.162) data 0.000 (0.001) loss 1.6850 (1.1880) ce_loss 1.5371 (1.0564) teacher_loss 1.5182 (1.0523) loss_zs_kd 0.1847 (0.1684) loss_oracle 0.0745 (0.0515) acc 68.7500 (72.2017) kd_loss 0.0606 (0.0438) lr 1.2369e-04 eta 0:04:01
epoch [44/50] batch [240/244] time 0.366 (0.168) data 0.000 (0.001) loss 1.3012 (1.1867) ce_loss 1.1465 (1.0545) teacher_loss 1.1490 (1.0506) loss_zs_kd 0.2045 (0.1692) loss_oracle 0.0499 (0.0514) acc 65.6250 (72.1224) kd_loss 0.0350 (0.0438) lr 1.2369e-04 eta 0:04:06
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,840
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.2%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,047
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.7%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.2%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [45/50] batch [20/244] time 0.180 (0.187) data 0.001 (0.015) loss 1.0081 (1.1857) ce_loss 0.8872 (1.0504) teacher_loss 0.8757 (1.0470) loss_zs_kd 0.1514 (0.1710) loss_oracle 0.0568 (0.0532) acc 78.1250 (72.0312) kd_loss 0.0560 (0.0482) lr 9.5173e-05 eta 0:04:29
epoch [45/50] batch [40/244] time 0.169 (0.173) data 0.000 (0.008) loss 1.2735 (1.1479) ce_loss 1.1768 (1.0147) teacher_loss 1.1717 (1.0120) loss_zs_kd 0.1150 (0.1698) loss_oracle 0.0443 (0.0511) acc 62.5000 (72.7344) kd_loss 0.0474 (0.0470) lr 9.5173e-05 eta 0:04:06
epoch [45/50] batch [60/244] time 0.086 (0.172) data 0.001 (0.005) loss 1.4764 (1.1655) ce_loss 1.3506 (1.0316) teacher_loss 1.3454 (1.0281) loss_zs_kd 0.1560 (0.1707) loss_oracle 0.0530 (0.0520) acc 65.6250 (72.2396) kd_loss 0.0495 (0.0463) lr 9.5173e-05 eta 0:04:02
epoch [45/50] batch [80/244] time 0.107 (0.183) data 0.000 (0.004) loss 0.8625 (1.1833) ce_loss 0.7334 (1.0513) teacher_loss 0.7339 (1.0473) loss_zs_kd 0.1500 (0.1683) loss_oracle 0.0536 (0.0519) acc 84.3750 (71.9141) kd_loss 0.0453 (0.0463) lr 9.5173e-05 eta 0:04:13
epoch [45/50] batch [100/244] time 0.150 (0.179) data 0.000 (0.003) loss 1.3963 (1.1937) ce_loss 1.2266 (1.0614) teacher_loss 1.2071 (1.0572) loss_zs_kd 0.2048 (0.1687) loss_oracle 0.0867 (0.0521) acc 68.7500 (71.8125) kd_loss 0.0690 (0.0463) lr 9.5173e-05 eta 0:04:04
epoch [45/50] batch [120/244] time 0.170 (0.177) data 0.000 (0.003) loss 0.7701 (1.1839) ce_loss 0.6357 (1.0515) teacher_loss 0.6401 (1.0471) loss_zs_kd 0.1876 (0.1694) loss_oracle 0.0361 (0.0521) acc 81.2500 (72.2135) kd_loss 0.0393 (0.0464) lr 9.5173e-05 eta 0:03:57
epoch [45/50] batch [140/244] time 0.166 (0.175) data 0.000 (0.002) loss 0.7190 (1.1937) ce_loss 0.5835 (1.0607) teacher_loss 0.5765 (1.0564) loss_zs_kd 0.1621 (0.1702) loss_oracle 0.0614 (0.0522) acc 78.1250 (71.6964) kd_loss 0.0454 (0.0462) lr 9.5173e-05 eta 0:03:51
epoch [45/50] batch [160/244] time 0.176 (0.174) data 0.000 (0.002) loss 0.9123 (1.1897) ce_loss 0.7817 (1.0564) teacher_loss 0.7810 (1.0520) loss_zs_kd 0.1385 (0.1708) loss_oracle 0.0621 (0.0523) acc 81.2500 (71.7383) kd_loss 0.0424 (0.0466) lr 9.5173e-05 eta 0:03:46
epoch [45/50] batch [180/244] time 0.401 (0.177) data 0.000 (0.002) loss 1.3663 (1.1963) ce_loss 1.2529 (1.0637) teacher_loss 1.2340 (1.0593) loss_zs_kd 0.1532 (0.1698) loss_oracle 0.0557 (0.0521) acc 68.7500 (71.7188) kd_loss 0.0485 (0.0465) lr 9.5173e-05 eta 0:03:47
epoch [45/50] batch [200/244] time 0.146 (0.180) data 0.000 (0.002) loss 0.9072 (1.1900) ce_loss 0.7822 (1.0575) teacher_loss 0.7803 (1.0530) loss_zs_kd 0.1580 (0.1692) loss_oracle 0.0479 (0.0524) acc 75.0000 (71.8906) kd_loss 0.0421 (0.0464) lr 9.5173e-05 eta 0:03:47
epoch [45/50] batch [220/244] time 0.163 (0.177) data 0.000 (0.002) loss 1.0357 (1.1863) ce_loss 0.8691 (1.0540) teacher_loss 0.8526 (1.0494) loss_zs_kd 0.2264 (0.1688) loss_oracle 0.0700 (0.0525) acc 68.7500 (71.8750) kd_loss 0.0584 (0.0465) lr 9.5173e-05 eta 0:03:40
epoch [45/50] batch [240/244] time 0.145 (0.175) data 0.000 (0.001) loss 1.2818 (1.1842) ce_loss 1.1201 (1.0514) teacher_loss 1.1177 (1.0470) loss_zs_kd 0.2075 (0.1693) loss_oracle 0.0603 (0.0525) acc 75.0000 (71.9661) kd_loss 0.0500 (0.0466) lr 9.5173e-05 eta 0:03:34
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,839
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,042
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.2%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [46/50] batch [20/244] time 0.089 (0.182) data 0.001 (0.015) loss 1.5148 (1.1782) ce_loss 1.3467 (1.0519) teacher_loss 1.3395 (1.0469) loss_zs_kd 0.2208 (0.1665) loss_oracle 0.0649 (0.0480) acc 65.6250 (71.8750) kd_loss 0.0489 (0.0458) lr 7.0224e-05 eta 0:03:38
epoch [46/50] batch [40/244] time 0.154 (0.211) data 0.000 (0.008) loss 1.0711 (1.2112) ce_loss 0.9375 (1.0789) teacher_loss 0.9233 (1.0751) loss_zs_kd 0.1696 (0.1727) loss_oracle 0.0630 (0.0497) acc 75.0000 (71.0938) kd_loss 0.0537 (0.0468) lr 7.0224e-05 eta 0:04:08
epoch [46/50] batch [60/244] time 0.154 (0.195) data 0.000 (0.005) loss 0.8531 (1.2052) ce_loss 0.7090 (1.0700) teacher_loss 0.6921 (1.0653) loss_zs_kd 0.1876 (0.1780) loss_oracle 0.0672 (0.0510) acc 81.2500 (71.5104) kd_loss 0.0623 (0.0470) lr 7.0224e-05 eta 0:03:45
epoch [46/50] batch [80/244] time 0.171 (0.187) data 0.000 (0.004) loss 1.2972 (1.2038) ce_loss 1.1846 (1.0699) teacher_loss 1.1874 (1.0655) loss_zs_kd 0.1571 (0.1743) loss_oracle 0.0312 (0.0512) acc 68.7500 (71.5234) kd_loss 0.0335 (0.0471) lr 7.0224e-05 eta 0:03:33
epoch [46/50] batch [100/244] time 0.157 (0.182) data 0.000 (0.003) loss 1.2362 (1.1865) ce_loss 1.1143 (1.0542) teacher_loss 1.1074 (1.0496) loss_zs_kd 0.1658 (0.1716) loss_oracle 0.0460 (0.0511) acc 75.0000 (72.0312) kd_loss 0.0478 (0.0469) lr 7.0224e-05 eta 0:03:23
epoch [46/50] batch [120/244] time 0.176 (0.179) data 0.000 (0.003) loss 1.0426 (1.1920) ce_loss 0.9438 (1.0601) teacher_loss 0.9345 (1.0555) loss_zs_kd 0.1111 (0.1707) loss_oracle 0.0525 (0.0511) acc 81.2500 (71.7188) kd_loss 0.0478 (0.0467) lr 7.0224e-05 eta 0:03:16
epoch [46/50] batch [140/244] time 0.405 (0.186) data 0.000 (0.002) loss 0.7927 (1.1847) ce_loss 0.6772 (1.0530) teacher_loss 0.6673 (1.0485) loss_zs_kd 0.1111 (0.1696) loss_oracle 0.0699 (0.0514) acc 81.2500 (71.8080) kd_loss 0.0619 (0.0466) lr 7.0224e-05 eta 0:03:20
epoch [46/50] batch [160/244] time 0.150 (0.186) data 0.000 (0.002) loss 1.3007 (1.1748) ce_loss 1.1660 (1.0432) teacher_loss 1.1656 (1.0387) loss_zs_kd 0.1453 (0.1689) loss_oracle 0.0625 (0.0517) acc 75.0000 (72.0898) kd_loss 0.0586 (0.0469) lr 7.0224e-05 eta 0:03:16
epoch [46/50] batch [180/244] time 0.158 (0.183) data 0.000 (0.002) loss 1.5805 (1.1732) ce_loss 1.4678 (1.0422) teacher_loss 1.4750 (1.0376) loss_zs_kd 0.1299 (0.1683) loss_oracle 0.0406 (0.0514) acc 65.6250 (72.1007) kd_loss 0.0316 (0.0466) lr 7.0224e-05 eta 0:03:10
epoch [46/50] batch [200/244] time 0.154 (0.181) data 0.000 (0.002) loss 1.9651 (1.1827) ce_loss 1.7920 (1.0515) teacher_loss 1.8015 (1.0469) loss_zs_kd 0.2374 (0.1686) loss_oracle 0.0449 (0.0515) acc 53.1250 (71.9219) kd_loss 0.0514 (0.0468) lr 7.0224e-05 eta 0:03:04
epoch [46/50] batch [220/244] time 0.146 (0.179) data 0.000 (0.002) loss 1.0826 (1.1842) ce_loss 0.9414 (1.0523) teacher_loss 0.9216 (1.0476) loss_zs_kd 0.1801 (0.1698) loss_oracle 0.0709 (0.0518) acc 78.1250 (71.9886) kd_loss 0.0588 (0.0469) lr 7.0224e-05 eta 0:02:58
epoch [46/50] batch [240/244] time 0.091 (0.176) data 0.000 (0.001) loss 1.1345 (1.1907) ce_loss 0.9795 (1.0580) teacher_loss 0.9754 (1.0531) loss_zs_kd 0.1594 (0.1704) loss_oracle 0.0794 (0.0525) acc 71.8750 (71.7969) kd_loss 0.0641 (0.0472) lr 7.0224e-05 eta 0:02:52
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,838
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.2%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [47/50] batch [20/244] time 0.148 (0.168) data 0.000 (0.013) loss 0.9821 (1.1183) ce_loss 0.8579 (0.9886) teacher_loss 0.8575 (0.9841) loss_zs_kd 0.1506 (0.1654) loss_oracle 0.0493 (0.0515) acc 78.1250 (73.5938) kd_loss 0.0455 (0.0466) lr 4.8943e-05 eta 0:02:40
epoch [47/50] batch [40/244] time 0.152 (0.165) data 0.000 (0.007) loss 0.7942 (1.1260) ce_loss 0.6733 (0.9963) teacher_loss 0.6723 (0.9911) loss_zs_kd 0.1439 (0.1624) loss_oracle 0.0499 (0.0537) acc 78.1250 (74.0625) kd_loss 0.0505 (0.0479) lr 4.8943e-05 eta 0:02:34
epoch [47/50] batch [60/244] time 0.171 (0.164) data 0.001 (0.005) loss 0.9683 (1.1837) ce_loss 0.7983 (1.0528) teacher_loss 0.8040 (1.0479) loss_zs_kd 0.2139 (0.1650) loss_oracle 0.0574 (0.0533) acc 81.2500 (72.2396) kd_loss 0.0490 (0.0474) lr 4.8943e-05 eta 0:02:30
epoch [47/50] batch [80/244] time 0.242 (0.161) data 0.000 (0.003) loss 1.0417 (1.1753) ce_loss 0.9077 (1.0450) teacher_loss 0.9094 (1.0395) loss_zs_kd 0.1698 (0.1648) loss_oracle 0.0475 (0.0534) acc 78.1250 (72.6562) kd_loss 0.0382 (0.0473) lr 4.8943e-05 eta 0:02:23
epoch [47/50] batch [100/244] time 0.184 (0.182) data 0.000 (0.003) loss 1.7436 (1.1920) ce_loss 1.5801 (1.0625) teacher_loss 1.5655 (1.0567) loss_zs_kd 0.2264 (0.1638) loss_oracle 0.0649 (0.0534) acc 59.3750 (72.2188) kd_loss 0.0531 (0.0473) lr 4.8943e-05 eta 0:02:39
epoch [47/50] batch [120/244] time 0.167 (0.176) data 0.000 (0.002) loss 1.2383 (1.1835) ce_loss 1.1025 (1.0537) teacher_loss 1.1004 (1.0484) loss_zs_kd 0.1546 (0.1642) loss_oracle 0.0607 (0.0530) acc 71.8750 (72.3958) kd_loss 0.0477 (0.0473) lr 4.8943e-05 eta 0:02:30
epoch [47/50] batch [140/244] time 0.153 (0.173) data 0.000 (0.002) loss 1.5865 (1.1884) ce_loss 1.4170 (1.0585) teacher_loss 1.4148 (1.0533) loss_zs_kd 0.2143 (0.1642) loss_oracle 0.0645 (0.0531) acc 68.7500 (72.1429) kd_loss 0.0582 (0.0474) lr 4.8943e-05 eta 0:02:24
epoch [47/50] batch [160/244] time 0.161 (0.171) data 0.000 (0.002) loss 1.0263 (1.1891) ce_loss 0.9048 (1.0598) teacher_loss 0.9124 (1.0549) loss_zs_kd 0.1460 (0.1626) loss_oracle 0.0408 (0.0529) acc 84.3750 (72.3633) kd_loss 0.0391 (0.0476) lr 4.8943e-05 eta 0:02:19
epoch [47/50] batch [180/244] time 0.149 (0.170) data 0.000 (0.002) loss 1.1637 (1.1776) ce_loss 1.0068 (1.0478) teacher_loss 1.0052 (1.0431) loss_zs_kd 0.2257 (0.1633) loss_oracle 0.0457 (0.0529) acc 75.0000 (72.7083) kd_loss 0.0373 (0.0475) lr 4.8943e-05 eta 0:02:15
epoch [47/50] batch [200/244] time 0.091 (0.167) data 0.000 (0.001) loss 0.9642 (1.1743) ce_loss 0.8452 (1.0440) teacher_loss 0.8430 (1.0394) loss_zs_kd 0.1480 (0.1642) loss_oracle 0.0473 (0.0528) acc 75.0000 (72.8125) kd_loss 0.0382 (0.0475) lr 4.8943e-05 eta 0:02:09
epoch [47/50] batch [220/244] time 0.089 (0.177) data 0.000 (0.001) loss 1.4134 (1.1837) ce_loss 1.2500 (1.0528) teacher_loss 1.2526 (1.0483) loss_zs_kd 0.2200 (0.1653) loss_oracle 0.0508 (0.0528) acc 68.7500 (72.5284) kd_loss 0.0447 (0.0475) lr 4.8943e-05 eta 0:02:13
epoch [47/50] batch [240/244] time 0.148 (0.174) data 0.000 (0.001) loss 1.2171 (1.1735) ce_loss 1.0342 (1.0416) teacher_loss 1.0224 (1.0372) loss_zs_kd 0.2466 (0.1666) loss_oracle 0.0713 (0.0530) acc 81.2500 (72.8646) kd_loss 0.0645 (0.0475) lr 4.8943e-05 eta 0:02:08
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,838
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.2%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [48/50] batch [20/244] time 0.157 (0.181) data 0.000 (0.014) loss 1.0068 (1.2592) ce_loss 0.8115 (1.1216) teacher_loss 0.8178 (1.1148) loss_zs_kd 0.2839 (0.1802) loss_oracle 0.0471 (0.0543) acc 78.1250 (70.3125) kd_loss 0.0467 (0.0485) lr 3.1417e-05 eta 0:02:09
epoch [48/50] batch [40/244] time 0.093 (0.188) data 0.000 (0.007) loss 1.1439 (1.2239) ce_loss 1.0625 (1.0859) teacher_loss 1.0646 (1.0811) loss_zs_kd 0.0863 (0.1785) loss_oracle 0.0361 (0.0536) acc 68.7500 (71.4062) kd_loss 0.0272 (0.0460) lr 3.1417e-05 eta 0:02:10
epoch [48/50] batch [60/244] time 0.156 (0.202) data 0.000 (0.005) loss 1.0655 (1.2170) ce_loss 0.9531 (1.0809) teacher_loss 0.9509 (1.0768) loss_zs_kd 0.1493 (0.1740) loss_oracle 0.0399 (0.0532) acc 78.1250 (71.7708) kd_loss 0.0420 (0.0458) lr 3.1417e-05 eta 0:02:15
epoch [48/50] batch [80/244] time 0.162 (0.194) data 0.000 (0.004) loss 1.2778 (1.2205) ce_loss 1.1611 (1.0860) teacher_loss 1.1551 (1.0805) loss_zs_kd 0.1441 (0.1720) loss_oracle 0.0506 (0.0540) acc 68.7500 (71.5625) kd_loss 0.0473 (0.0471) lr 3.1417e-05 eta 0:02:06
epoch [48/50] batch [100/244] time 0.155 (0.186) data 0.000 (0.003) loss 1.1068 (1.2095) ce_loss 0.9814 (1.0763) teacher_loss 0.9738 (1.0709) loss_zs_kd 0.1568 (0.1706) loss_oracle 0.0546 (0.0533) acc 75.0000 (71.5938) kd_loss 0.0499 (0.0470) lr 3.1417e-05 eta 0:01:57
epoch [48/50] batch [120/244] time 0.174 (0.181) data 0.000 (0.003) loss 0.9215 (1.2152) ce_loss 0.7817 (1.0829) teacher_loss 0.7839 (1.0777) loss_zs_kd 0.1826 (0.1695) loss_oracle 0.0463 (0.0528) acc 78.1250 (71.7448) kd_loss 0.0461 (0.0467) lr 3.1417e-05 eta 0:01:50
epoch [48/50] batch [140/244] time 0.165 (0.178) data 0.000 (0.002) loss 1.2579 (1.2226) ce_loss 1.1289 (1.0895) teacher_loss 1.1264 (1.0843) loss_zs_kd 0.1719 (0.1712) loss_oracle 0.0455 (0.0527) acc 71.8750 (71.5402) kd_loss 0.0443 (0.0465) lr 3.1417e-05 eta 0:01:45
epoch [48/50] batch [160/244] time 0.415 (0.175) data 0.000 (0.002) loss 1.6680 (1.2115) ce_loss 1.5420 (1.0796) teacher_loss 1.5435 (1.0747) loss_zs_kd 0.1267 (0.1688) loss_oracle 0.0611 (0.0525) acc 62.5000 (71.6406) kd_loss 0.0496 (0.0467) lr 3.1417e-05 eta 0:01:39
epoch [48/50] batch [180/244] time 0.089 (0.184) data 0.000 (0.002) loss 0.9794 (1.2027) ce_loss 0.8438 (1.0700) teacher_loss 0.8348 (1.0652) loss_zs_kd 0.1740 (0.1699) loss_oracle 0.0576 (0.0525) acc 81.2500 (71.7361) kd_loss 0.0477 (0.0468) lr 3.1417e-05 eta 0:01:41
epoch [48/50] batch [200/244] time 0.153 (0.181) data 0.000 (0.002) loss 1.0668 (1.2077) ce_loss 0.9238 (1.0743) teacher_loss 0.9289 (1.0700) loss_zs_kd 0.1929 (0.1703) loss_oracle 0.0415 (0.0525) acc 81.2500 (71.7812) kd_loss 0.0481 (0.0468) lr 3.1417e-05 eta 0:01:36
epoch [48/50] batch [220/244] time 0.168 (0.179) data 0.000 (0.001) loss 1.1971 (1.2101) ce_loss 1.0596 (1.0771) teacher_loss 1.0577 (1.0727) loss_zs_kd 0.1596 (0.1697) loss_oracle 0.0596 (0.0526) acc 71.8750 (71.7188) kd_loss 0.0482 (0.0468) lr 3.1417e-05 eta 0:01:31
epoch [48/50] batch [240/244] time 0.157 (0.177) data 0.000 (0.001) loss 1.0705 (1.2009) ce_loss 0.9561 (1.0677) teacher_loss 0.9518 (1.0632) loss_zs_kd 0.1480 (0.1699) loss_oracle 0.0448 (0.0528) acc 68.7500 (72.0573) kd_loss 0.0433 (0.0470) lr 3.1417e-05 eta 0:01:27
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,837
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.2%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [49/50] batch [20/244] time 0.170 (0.257) data 0.000 (0.014) loss 1.1890 (1.1780) ce_loss 1.0488 (1.0383) teacher_loss 1.0445 (1.0340) loss_zs_kd 0.1454 (0.1831) loss_oracle 0.0719 (0.0525) acc 71.8750 (73.5938) kd_loss 0.0629 (0.0483) lr 1.7713e-05 eta 0:02:00
epoch [49/50] batch [40/244] time 0.159 (0.209) data 0.000 (0.007) loss 1.1218 (1.1592) ce_loss 0.9805 (1.0272) teacher_loss 0.9761 (1.0233) loss_zs_kd 0.1701 (0.1682) loss_oracle 0.0607 (0.0518) acc 71.8750 (73.3594) kd_loss 0.0508 (0.0478) lr 1.7713e-05 eta 0:01:33
epoch [49/50] batch [60/244] time 0.158 (0.193) data 0.001 (0.005) loss 0.8918 (1.1646) ce_loss 0.7300 (1.0324) teacher_loss 0.7261 (1.0290) loss_zs_kd 0.2263 (0.1664) loss_oracle 0.0526 (0.0524) acc 81.2500 (73.0729) kd_loss 0.0450 (0.0481) lr 1.7713e-05 eta 0:01:22
epoch [49/50] batch [80/244] time 0.155 (0.185) data 0.000 (0.004) loss 0.8796 (1.1746) ce_loss 0.7695 (1.0415) teacher_loss 0.7692 (1.0379) loss_zs_kd 0.1245 (0.1691) loss_oracle 0.0481 (0.0522) acc 84.3750 (72.6562) kd_loss 0.0556 (0.0482) lr 1.7713e-05 eta 0:01:15
epoch [49/50] batch [100/244] time 0.145 (0.180) data 0.000 (0.003) loss 0.9671 (1.1953) ce_loss 0.8267 (1.0615) teacher_loss 0.8308 (1.0581) loss_zs_kd 0.1757 (0.1698) loss_oracle 0.0485 (0.0524) acc 75.0000 (72.0938) kd_loss 0.0414 (0.0486) lr 1.7713e-05 eta 0:01:10
epoch [49/50] batch [120/244] time 0.393 (0.183) data 0.000 (0.002) loss 1.0844 (1.1761) ce_loss 0.9541 (1.0430) teacher_loss 0.9420 (1.0392) loss_zs_kd 0.1869 (0.1690) loss_oracle 0.0490 (0.0523) acc 78.1250 (72.7083) kd_loss 0.0525 (0.0479) lr 1.7713e-05 eta 0:01:07
epoch [49/50] batch [140/244] time 0.171 (0.186) data 0.000 (0.002) loss 1.3696 (1.1578) ce_loss 1.2354 (1.0245) teacher_loss 1.2351 (1.0205) loss_zs_kd 0.1753 (0.1693) loss_oracle 0.0469 (0.0526) acc 62.5000 (73.2366) kd_loss 0.0516 (0.0480) lr 1.7713e-05 eta 0:01:04
epoch [49/50] batch [160/244] time 0.155 (0.183) data 0.000 (0.002) loss 1.1224 (1.1699) ce_loss 0.9917 (1.0374) teacher_loss 0.9933 (1.0335) loss_zs_kd 0.1316 (0.1685) loss_oracle 0.0633 (0.0522) acc 75.0000 (73.1250) kd_loss 0.0595 (0.0476) lr 1.7713e-05 eta 0:01:00
epoch [49/50] batch [180/244] time 0.161 (0.181) data 0.000 (0.002) loss 1.0281 (1.1648) ce_loss 0.8892 (1.0328) teacher_loss 0.8801 (1.0287) loss_zs_kd 0.1804 (0.1673) loss_oracle 0.0577 (0.0525) acc 81.2500 (73.0208) kd_loss 0.0496 (0.0479) lr 1.7713e-05 eta 0:00:55
epoch [49/50] batch [200/244] time 0.152 (0.179) data 0.000 (0.002) loss 1.0258 (1.1749) ce_loss 0.9067 (1.0430) teacher_loss 0.9065 (1.0389) loss_zs_kd 0.1385 (0.1670) loss_oracle 0.0501 (0.0526) acc 71.8750 (72.7188) kd_loss 0.0453 (0.0478) lr 1.7713e-05 eta 0:00:51
epoch [49/50] batch [220/244] time 0.102 (0.176) data 0.000 (0.001) loss 1.9965 (1.1830) ce_loss 1.8447 (1.0509) teacher_loss 1.8422 (1.0465) loss_zs_kd 0.2093 (0.1672) loss_oracle 0.0497 (0.0529) acc 56.2500 (72.4432) kd_loss 0.0490 (0.0481) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [240/244] time 0.367 (0.178) data 0.000 (0.001) loss 1.3409 (1.1821) ce_loss 1.2168 (1.0502) teacher_loss 1.2053 (1.0459) loss_zs_kd 0.1540 (0.1670) loss_oracle 0.0585 (0.0527) acc 65.6250 (72.4609) kd_loss 0.0472 (0.0480) lr 1.7713e-05 eta 0:00:44
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,837
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.2%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
epoch [50/50] batch [20/244] time 0.151 (0.173) data 0.000 (0.014) loss 1.2915 (1.1952) ce_loss 1.1660 (1.0613) teacher_loss 1.1764 (1.0556) loss_zs_kd 0.1387 (0.1695) loss_oracle 0.0457 (0.0548) acc 65.6250 (71.5625) kd_loss 0.0424 (0.0494) lr 7.8853e-06 eta 0:00:38
epoch [50/50] batch [40/244] time 0.151 (0.166) data 0.000 (0.007) loss 1.4209 (1.1754) ce_loss 1.2891 (1.0432) teacher_loss 1.2804 (1.0398) loss_zs_kd 0.1733 (0.1662) loss_oracle 0.0538 (0.0525) acc 65.6250 (71.9531) kd_loss 0.0514 (0.0477) lr 7.8853e-06 eta 0:00:33
epoch [50/50] batch [60/244] time 0.108 (0.160) data 0.000 (0.005) loss 0.5177 (1.1514) ce_loss 0.4055 (1.0162) teacher_loss 0.4110 (1.0128) loss_zs_kd 0.1154 (0.1699) loss_oracle 0.0490 (0.0537) acc 90.6250 (72.9167) kd_loss 0.0463 (0.0478) lr 7.8853e-06 eta 0:00:29
epoch [50/50] batch [80/244] time 0.085 (0.188) data 0.000 (0.004) loss 1.3273 (1.1446) ce_loss 1.2148 (1.0126) teacher_loss 1.2082 (1.0088) loss_zs_kd 0.1249 (0.1652) loss_oracle 0.0566 (0.0532) acc 65.6250 (72.9297) kd_loss 0.0500 (0.0475) lr 7.8853e-06 eta 0:00:30
epoch [50/50] batch [100/244] time 0.146 (0.180) data 0.000 (0.003) loss 1.4751 (1.1665) ce_loss 1.3662 (1.0353) teacher_loss 1.3381 (1.0311) loss_zs_kd 0.1508 (0.1639) loss_oracle 0.0617 (0.0535) acc 65.6250 (72.3750) kd_loss 0.0536 (0.0478) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [120/244] time 0.151 (0.176) data 0.000 (0.003) loss 1.0409 (1.1575) ce_loss 0.9033 (1.0263) teacher_loss 0.8990 (1.0223) loss_zs_kd 0.1916 (0.1638) loss_oracle 0.0461 (0.0533) acc 78.1250 (72.7865) kd_loss 0.0413 (0.0481) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [140/244] time 0.148 (0.173) data 0.000 (0.002) loss 1.1438 (1.1662) ce_loss 1.0244 (1.0354) teacher_loss 1.0193 (1.0310) loss_zs_kd 0.1532 (0.1638) loss_oracle 0.0479 (0.0533) acc 68.7500 (72.4554) kd_loss 0.0518 (0.0483) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [160/244] time 0.143 (0.171) data 0.000 (0.002) loss 0.7579 (1.1590) ce_loss 0.6387 (1.0276) teacher_loss 0.6423 (1.0233) loss_zs_kd 0.1524 (0.1647) loss_oracle 0.0394 (0.0534) acc 87.5000 (72.5977) kd_loss 0.0367 (0.0485) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [180/244] time 0.170 (0.170) data 0.000 (0.002) loss 1.6538 (1.1659) ce_loss 1.5479 (1.0332) teacher_loss 1.5324 (1.0288) loss_zs_kd 0.1249 (0.1673) loss_oracle 0.0590 (0.0535) acc 56.2500 (72.5347) kd_loss 0.0483 (0.0486) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [200/244] time 0.131 (0.169) data 0.000 (0.002) loss 1.0833 (1.1670) ce_loss 0.9038 (1.0338) teacher_loss 0.9043 (1.0291) loss_zs_kd 0.2705 (0.1680) loss_oracle 0.0438 (0.0539) acc 78.1250 (72.5312) kd_loss 0.0401 (0.0485) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [220/244] time 0.155 (0.175) data 0.000 (0.001) loss 1.6345 (1.1627) ce_loss 1.4893 (1.0293) teacher_loss 1.4898 (1.0246) loss_zs_kd 0.2113 (0.1683) loss_oracle 0.0390 (0.0540) acc 53.1250 (72.6847) kd_loss 0.0351 (0.0484) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [240/244] time 0.146 (0.174) data 0.000 (0.001) loss 0.7407 (1.1693) ce_loss 0.6079 (1.0355) teacher_loss 0.6101 (1.0307) loss_zs_kd 0.1310 (0.1695) loss_oracle 0.0651 (0.0538) acc 81.2500 (72.4870) kd_loss 0.0519 (0.0483) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,839
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,045
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      85.2%, epoch: 44 *******
******* Domain p best val test acc: 91.2%, epoch: 44 *******
******* Domain p best test acc:     91.2%, epoch: 10 *******
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:42:11

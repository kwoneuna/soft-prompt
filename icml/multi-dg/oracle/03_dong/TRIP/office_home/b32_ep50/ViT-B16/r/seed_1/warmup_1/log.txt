Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'clipart', 'product']
Target     ['real_world']
# classes  65
# train_x  7,877
# val      3,354
# test     4,357
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/246] time 0.173 (0.220) data 0.000 (0.023) loss 1.6116 (1.4908) ce_loss 1.6035 (1.4867) teacher_loss 1.6048 (1.4867) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0067 (0.0041) acc 59.3750 (60.9375) kd_loss 0.0267 (0.0164) lr 1.0000e-05 eta 0:45:06
epoch [1/50] batch [40/246] time 0.168 (0.192) data 0.000 (0.011) loss 1.0243 (1.4198) ce_loss 1.0205 (1.4159) teacher_loss 1.0216 (1.4160) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0026 (0.0039) acc 75.0000 (62.9688) kd_loss 0.0103 (0.0153) lr 1.0000e-05 eta 0:39:14
epoch [1/50] batch [60/246] time 0.174 (0.181) data 0.001 (0.008) loss 1.1320 (1.4202) ce_loss 1.1299 (1.4168) teacher_loss 1.1296 (1.4168) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0023 (0.0034) acc 78.1250 (63.3333) kd_loss 0.0085 (0.0135) lr 1.0000e-05 eta 0:36:53
epoch [1/50] batch [80/246] time 0.171 (0.176) data 0.000 (0.006) loss 1.9298 (1.4125) ce_loss 1.9297 (1.4095) teacher_loss 1.9280 (1.4095) loss_zs_kd 0.0005 (0.0001) loss_oracle 0.0015 (0.0030) acc 50.0000 (63.5547) kd_loss 0.0056 (0.0117) lr 1.0000e-05 eta 0:35:50
epoch [1/50] batch [100/246] time 0.104 (0.171) data 0.000 (0.005) loss 1.4587 (1.3947) ce_loss 1.4580 (1.3919) teacher_loss 1.4570 (1.3919) loss_zs_kd 0.0010 (0.0002) loss_oracle 0.0012 (0.0027) acc 59.3750 (63.8750) kd_loss 0.0047 (0.0105) lr 1.0000e-05 eta 0:34:49
epoch [1/50] batch [120/246] time 0.102 (0.188) data 0.000 (0.004) loss 1.5107 (1.3953) ce_loss 1.5098 (1.3927) teacher_loss 1.5082 (1.3926) loss_zs_kd 0.0011 (0.0003) loss_oracle 0.0020 (0.0025) acc 59.3750 (64.0365) kd_loss 0.0076 (0.0096) lr 1.0000e-05 eta 0:38:15
epoch [1/50] batch [140/246] time 0.174 (0.185) data 0.000 (0.003) loss 1.7443 (1.3946) ce_loss 1.7441 (1.3921) teacher_loss 1.7432 (1.3921) loss_zs_kd 0.0006 (0.0004) loss_oracle 0.0008 (0.0023) acc 53.1250 (64.1071) kd_loss 0.0028 (0.0089) lr 1.0000e-05 eta 0:37:33
epoch [1/50] batch [160/246] time 0.162 (0.183) data 0.000 (0.003) loss 1.6014 (1.4055) ce_loss 1.6006 (1.4032) teacher_loss 1.6000 (1.4031) loss_zs_kd 0.0011 (0.0005) loss_oracle 0.0009 (0.0021) acc 65.6250 (63.6523) kd_loss 0.0032 (0.0082) lr 1.0000e-05 eta 0:36:58
epoch [1/50] batch [180/246] time 0.157 (0.180) data 0.000 (0.003) loss 1.6169 (1.3990) ce_loss 1.6152 (1.3968) teacher_loss 1.6155 (1.3967) loss_zs_kd 0.0015 (0.0007) loss_oracle 0.0006 (0.0020) acc 56.2500 (63.9931) kd_loss 0.0023 (0.0076) lr 1.0000e-05 eta 0:36:27
epoch [1/50] batch [200/246] time 0.179 (0.179) data 0.000 (0.002) loss 2.1336 (1.3999) ce_loss 2.1289 (1.3977) teacher_loss 2.1300 (1.3977) loss_zs_kd 0.0048 (0.0008) loss_oracle 0.0012 (0.0019) acc 40.6250 (63.8750) kd_loss 0.0042 (0.0072) lr 1.0000e-05 eta 0:36:03
epoch [1/50] batch [220/246] time 0.094 (0.178) data 0.000 (0.002) loss 1.2775 (1.4004) ce_loss 1.2754 (1.3982) teacher_loss 1.2746 (1.3981) loss_zs_kd 0.0036 (0.0010) loss_oracle 0.0011 (0.0018) acc 71.8750 (64.0199) kd_loss 0.0036 (0.0068) lr 1.0000e-05 eta 0:35:50
epoch [1/50] batch [240/246] time 0.168 (0.183) data 0.000 (0.002) loss 1.5878 (1.3991) ce_loss 1.5859 (1.3969) teacher_loss 1.5857 (1.3968) loss_zs_kd 0.0027 (0.0012) loss_oracle 0.0007 (0.0017) acc 59.3750 (63.9714) kd_loss 0.0022 (0.0065) lr 1.0000e-05 eta 0:36:46
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,683
* accuracy: 80.0%
* error: 20.0%
* macro_f1: 78.8%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,891
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 87.8%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      80.0%, epoch: 1 *******
******* Domain r best val test acc: 89.3%, epoch: 1 *******
******* Domain r best test acc:     89.3%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/ana
epoch [2/50] batch [20/246] time 0.177 (0.192) data 0.000 (0.017) loss 1.6802 (1.4779) ce_loss 1.6338 (1.4493) teacher_loss 1.6339 (1.4494) loss_zs_kd 0.0885 (0.0534) loss_oracle 0.0021 (0.0017) acc 68.7500 (64.0625) kd_loss 0.0021 (0.0026) lr 2.0000e-03 eta 0:38:32
epoch [2/50] batch [40/246] time 0.344 (0.190) data 0.000 (0.009) loss 1.5272 (1.4308) ce_loss 1.4873 (1.3899) teacher_loss 1.4873 (1.3899) loss_zs_kd 0.0758 (0.0751) loss_oracle 0.0020 (0.0033) acc 62.5000 (65.2344) kd_loss 0.0026 (0.0026) lr 2.0000e-03 eta 0:37:57
epoch [2/50] batch [60/246] time 0.150 (0.194) data 0.000 (0.006) loss 1.3887 (1.3596) ce_loss 1.3359 (1.3181) teacher_loss 1.3337 (1.3182) loss_zs_kd 0.1040 (0.0765) loss_oracle 0.0030 (0.0031) acc 62.5000 (66.7188) kd_loss 0.0035 (0.0031) lr 2.0000e-03 eta 0:38:47
epoch [2/50] batch [80/246] time 0.153 (0.185) data 0.000 (0.004) loss 1.3436 (1.3297) ce_loss 1.2832 (1.2856) teacher_loss 1.2835 (1.2857) loss_zs_kd 0.1132 (0.0815) loss_oracle 0.0035 (0.0033) acc 62.5000 (67.2266) kd_loss 0.0051 (0.0033) lr 2.0000e-03 eta 0:36:58
epoch [2/50] batch [100/246] time 0.167 (0.180) data 0.000 (0.004) loss 1.1447 (1.3213) ce_loss 1.1113 (1.2756) teacher_loss 1.1117 (1.2756) loss_zs_kd 0.0576 (0.0843) loss_oracle 0.0041 (0.0035) acc 65.6250 (67.0000) kd_loss 0.0028 (0.0034) lr 2.0000e-03 eta 0:35:46
epoch [2/50] batch [120/246] time 0.172 (0.176) data 0.000 (0.003) loss 1.0319 (1.3093) ce_loss 0.9961 (1.2618) teacher_loss 0.9960 (1.2618) loss_zs_kd 0.0621 (0.0876) loss_oracle 0.0048 (0.0037) acc 75.0000 (67.6042) kd_loss 0.0042 (0.0036) lr 2.0000e-03 eta 0:34:56
epoch [2/50] batch [140/246] time 0.165 (0.173) data 0.000 (0.003) loss 1.3490 (1.2995) ce_loss 1.3184 (1.2514) teacher_loss 1.3171 (1.2513) loss_zs_kd 0.0554 (0.0888) loss_oracle 0.0042 (0.0038) acc 71.8750 (67.6562) kd_loss 0.0036 (0.0035) lr 2.0000e-03 eta 0:34:15
epoch [2/50] batch [160/246] time 0.365 (0.174) data 0.000 (0.002) loss 1.0861 (1.2933) ce_loss 1.0352 (1.2448) teacher_loss 1.0354 (1.2446) loss_zs_kd 0.0947 (0.0899) loss_oracle 0.0033 (0.0037) acc 65.6250 (67.7539) kd_loss 0.0029 (0.0035) lr 2.0000e-03 eta 0:34:27
epoch [2/50] batch [180/246] time 0.111 (0.179) data 0.000 (0.002) loss 1.3376 (1.2861) ce_loss 1.2637 (1.2361) teacher_loss 1.2629 (1.2360) loss_zs_kd 0.1328 (0.0925) loss_oracle 0.0083 (0.0039) acc 75.0000 (68.0903) kd_loss 0.0027 (0.0034) lr 2.0000e-03 eta 0:35:22
epoch [2/50] batch [200/246] time 0.166 (0.177) data 0.000 (0.002) loss 1.6696 (1.2896) ce_loss 1.6182 (1.2379) teacher_loss 1.6177 (1.2378) loss_zs_kd 0.0897 (0.0954) loss_oracle 0.0071 (0.0041) acc 53.1250 (68.0156) kd_loss 0.0052 (0.0034) lr 2.0000e-03 eta 0:35:01
epoch [2/50] batch [220/246] time 0.176 (0.176) data 0.000 (0.002) loss 1.3068 (1.2858) ce_loss 1.2188 (1.2331) teacher_loss 1.2198 (1.2330) loss_zs_kd 0.1646 (0.0971) loss_oracle 0.0047 (0.0042) acc 68.7500 (68.0824) kd_loss 0.0026 (0.0034) lr 2.0000e-03 eta 0:34:43
epoch [2/50] batch [240/246] time 0.160 (0.175) data 0.000 (0.002) loss 1.2965 (1.2889) ce_loss 1.1738 (1.2346) teacher_loss 1.1745 (1.2345) loss_zs_kd 0.2301 (0.1002) loss_oracle 0.0070 (0.0043) acc 68.7500 (68.0859) kd_loss 0.0037 (0.0034) lr 2.0000e-03 eta 0:34:33
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,791
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 82.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,944
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.2%, epoch: 2 *******
******* Domain r best val test acc: 90.5%, epoch: 2 *******
******* Domain r best test acc:     90.5%, epoch: 2 *******
epoch [3/50] batch [20/246] time 0.170 (0.171) data 0.000 (0.014) loss 1.4877 (1.2603) ce_loss 1.4424 (1.2021) teacher_loss 1.4397 (1.2021) loss_zs_kd 0.0862 (0.1053) loss_oracle 0.0049 (0.0056) acc 56.2500 (68.9062) kd_loss 0.0048 (0.0044) lr 1.9980e-03 eta 0:33:32
epoch [3/50] batch [40/246] time 0.173 (0.173) data 0.000 (0.007) loss 0.7764 (1.2600) ce_loss 0.7417 (1.1997) teacher_loss 0.7429 (1.1996) loss_zs_kd 0.0593 (0.1105) loss_oracle 0.0038 (0.0052) acc 84.3750 (70.0781) kd_loss 0.0034 (0.0045) lr 1.9980e-03 eta 0:33:54
epoch [3/50] batch [60/246] time 0.183 (0.173) data 0.000 (0.005) loss 1.8397 (1.2699) ce_loss 1.7783 (1.2103) teacher_loss 1.7743 (1.2102) loss_zs_kd 0.1124 (0.1088) loss_oracle 0.0091 (0.0053) acc 46.8750 (69.3229) kd_loss 0.0050 (0.0044) lr 1.9980e-03 eta 0:33:51
epoch [3/50] batch [80/246] time 0.177 (0.171) data 0.000 (0.004) loss 1.8421 (1.2879) ce_loss 1.7705 (1.2242) teacher_loss 1.7705 (1.2240) loss_zs_kd 0.1350 (0.1167) loss_oracle 0.0041 (0.0055) acc 62.5000 (69.2969) kd_loss 0.0032 (0.0043) lr 1.9980e-03 eta 0:33:24
epoch [3/50] batch [100/246] time 0.183 (0.175) data 0.000 (0.003) loss 1.0923 (1.2845) ce_loss 1.0498 (1.2198) teacher_loss 1.0480 (1.2198) loss_zs_kd 0.0706 (0.1177) loss_oracle 0.0090 (0.0058) acc 68.7500 (69.1250) kd_loss 0.0057 (0.0043) lr 1.9980e-03 eta 0:34:04
epoch [3/50] batch [120/246] time 0.086 (0.181) data 0.000 (0.003) loss 1.1845 (1.2729) ce_loss 1.1523 (1.2093) teacher_loss 1.1496 (1.2093) loss_zs_kd 0.0562 (0.1148) loss_oracle 0.0068 (0.0063) acc 78.1250 (69.2969) kd_loss 0.0038 (0.0043) lr 1.9980e-03 eta 0:35:15
epoch [3/50] batch [140/246] time 0.147 (0.176) data 0.000 (0.002) loss 1.5629 (1.2763) ce_loss 1.4971 (1.2130) teacher_loss 1.4960 (1.2130) loss_zs_kd 0.1226 (0.1145) loss_oracle 0.0056 (0.0061) acc 59.3750 (68.9286) kd_loss 0.0056 (0.0043) lr 1.9980e-03 eta 0:34:18
epoch [3/50] batch [160/246] time 0.172 (0.174) data 0.000 (0.002) loss 1.0903 (1.2783) ce_loss 1.0127 (1.2144) teacher_loss 1.0180 (1.2144) loss_zs_kd 0.1242 (0.1151) loss_oracle 0.0102 (0.0064) acc 75.0000 (68.9844) kd_loss 0.0049 (0.0043) lr 1.9980e-03 eta 0:33:42
epoch [3/50] batch [180/246] time 0.153 (0.172) data 0.000 (0.002) loss 1.3118 (1.2697) ce_loss 1.2334 (1.2053) teacher_loss 1.2351 (1.2053) loss_zs_kd 0.1311 (0.1156) loss_oracle 0.0112 (0.0065) acc 71.8750 (68.9062) kd_loss 0.0051 (0.0043) lr 1.9980e-03 eta 0:33:16
epoch [3/50] batch [200/246] time 0.169 (0.170) data 0.000 (0.002) loss 1.1869 (1.2698) ce_loss 1.1309 (1.2043) teacher_loss 1.1333 (1.2043) loss_zs_kd 0.0903 (0.1175) loss_oracle 0.0084 (0.0067) acc 71.8750 (68.8125) kd_loss 0.0036 (0.0044) lr 1.9980e-03 eta 0:32:57
epoch [3/50] batch [220/246] time 0.165 (0.169) data 0.000 (0.002) loss 0.9512 (1.2711) ce_loss 0.8965 (1.2052) teacher_loss 0.8982 (1.2052) loss_zs_kd 0.0937 (0.1180) loss_oracle 0.0061 (0.0069) acc 75.0000 (68.6222) kd_loss 0.0044 (0.0044) lr 1.9980e-03 eta 0:32:40
epoch [3/50] batch [240/246] time 0.085 (0.168) data 0.000 (0.001) loss 0.9384 (1.2664) ce_loss 0.8853 (1.1997) teacher_loss 0.8828 (1.1997) loss_zs_kd 0.0892 (0.1191) loss_oracle 0.0109 (0.0072) acc 75.0000 (68.7891) kd_loss 0.0060 (0.0045) lr 1.9980e-03 eta 0:32:27
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,801
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.6%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.7%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.5%, epoch: 3 *******
******* Domain r best val test acc: 90.9%, epoch: 3 *******
******* Domain r best test acc:     90.9%, epoch: 3 *******
epoch [4/50] batch [20/246] time 0.157 (0.176) data 0.000 (0.013) loss 1.0674 (1.1918) ce_loss 1.0215 (1.1220) teacher_loss 1.0217 (1.1227) loss_zs_kd 0.0767 (0.1199) loss_oracle 0.0073 (0.0091) acc 71.8750 (71.8750) kd_loss 0.0041 (0.0053) lr 1.9921e-03 eta 0:33:52
epoch [4/50] batch [40/246] time 0.169 (0.168) data 0.000 (0.007) loss 1.2036 (1.1709) ce_loss 1.1289 (1.0994) teacher_loss 1.1288 (1.0999) loss_zs_kd 0.1171 (0.1197) loss_oracle 0.0163 (0.0112) acc 75.0000 (71.9531) kd_loss 0.0062 (0.0054) lr 1.9921e-03 eta 0:32:20
epoch [4/50] batch [60/246] time 0.085 (0.175) data 0.001 (0.005) loss 1.3718 (1.1952) ce_loss 1.2998 (1.1202) teacher_loss 1.3000 (1.1204) loss_zs_kd 0.1192 (0.1207) loss_oracle 0.0122 (0.0145) acc 75.0000 (71.4062) kd_loss 0.0063 (0.0060) lr 1.9921e-03 eta 0:33:28
epoch [4/50] batch [80/246] time 0.151 (0.187) data 0.000 (0.003) loss 0.9141 (1.1910) ce_loss 0.8555 (1.1139) teacher_loss 0.8577 (1.1143) loss_zs_kd 0.0868 (0.1257) loss_oracle 0.0130 (0.0138) acc 75.0000 (71.4453) kd_loss 0.0081 (0.0062) lr 1.9921e-03 eta 0:35:52
epoch [4/50] batch [100/246] time 0.154 (0.182) data 0.000 (0.003) loss 1.1877 (1.1971) ce_loss 1.1240 (1.1209) teacher_loss 1.1243 (1.1212) loss_zs_kd 0.1019 (0.1246) loss_oracle 0.0125 (0.0136) acc 62.5000 (71.0312) kd_loss 0.0055 (0.0062) lr 1.9921e-03 eta 0:34:47
epoch [4/50] batch [120/246] time 0.156 (0.178) data 0.000 (0.002) loss 1.6268 (1.2035) ce_loss 1.5420 (1.1266) teacher_loss 1.5427 (1.1270) loss_zs_kd 0.1235 (0.1252) loss_oracle 0.0223 (0.0139) acc 56.2500 (70.4688) kd_loss 0.0114 (0.0066) lr 1.9921e-03 eta 0:34:01
epoch [4/50] batch [140/246] time 0.156 (0.176) data 0.000 (0.002) loss 1.1631 (1.1905) ce_loss 1.0879 (1.1129) teacher_loss 1.0857 (1.1133) loss_zs_kd 0.1110 (0.1246) loss_oracle 0.0220 (0.0149) acc 71.8750 (70.8705) kd_loss 0.0102 (0.0071) lr 1.9921e-03 eta 0:33:27
epoch [4/50] batch [160/246] time 0.178 (0.174) data 0.000 (0.002) loss 1.1926 (1.2098) ce_loss 1.0859 (1.1303) teacher_loss 1.0861 (1.1305) loss_zs_kd 0.1701 (0.1283) loss_oracle 0.0214 (0.0152) acc 71.8750 (70.3320) kd_loss 0.0118 (0.0076) lr 1.9921e-03 eta 0:33:05
epoch [4/50] batch [180/246] time 0.091 (0.174) data 0.000 (0.002) loss 0.9853 (1.2160) ce_loss 0.9253 (1.1363) teacher_loss 0.9265 (1.1364) loss_zs_kd 0.0904 (0.1285) loss_oracle 0.0137 (0.0153) acc 75.0000 (70.1042) kd_loss 0.0119 (0.0080) lr 1.9921e-03 eta 0:33:00
epoch [4/50] batch [200/246] time 0.172 (0.180) data 0.000 (0.002) loss 1.6386 (1.2209) ce_loss 1.5518 (1.1418) teacher_loss 1.5492 (1.1418) loss_zs_kd 0.1604 (0.1281) loss_oracle 0.0093 (0.0150) acc 65.6250 (69.9062) kd_loss 0.0082 (0.0082) lr 1.9921e-03 eta 0:34:07
epoch [4/50] batch [220/246] time 0.146 (0.178) data 0.000 (0.001) loss 0.8362 (1.2129) ce_loss 0.7461 (1.1334) teacher_loss 0.7500 (1.1334) loss_zs_kd 0.1498 (0.1294) loss_oracle 0.0114 (0.0147) acc 78.1250 (70.0852) kd_loss 0.0073 (0.0082) lr 1.9921e-03 eta 0:33:40
epoch [4/50] batch [240/246] time 0.169 (0.177) data 0.000 (0.001) loss 1.2005 (1.2198) ce_loss 1.1426 (1.1399) teacher_loss 1.1412 (1.1399) loss_zs_kd 0.0770 (0.1298) loss_oracle 0.0208 (0.0150) acc 75.0000 (70.0000) kd_loss 0.0095 (0.0083) lr 1.9921e-03 eta 0:33:19
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,811
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,960
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.8%, epoch: 4 *******
******* Domain r best val test acc: 90.9%, epoch: 4 *******
******* Domain r best test acc:     90.9%, epoch: 4 *******
epoch [5/50] batch [20/246] time 0.349 (0.289) data 0.000 (0.014) loss 1.1397 (1.1999) ce_loss 1.0645 (1.1241) teacher_loss 1.0602 (1.1240) loss_zs_kd 0.1198 (0.1205) loss_oracle 0.0196 (0.0157) acc 68.7500 (72.0312) kd_loss 0.0089 (0.0095) lr 1.9823e-03 eta 0:54:20
epoch [5/50] batch [40/246] time 0.163 (0.216) data 0.000 (0.007) loss 1.7547 (1.2113) ce_loss 1.6680 (1.1380) teacher_loss 1.6696 (1.1379) loss_zs_kd 0.1443 (0.1162) loss_oracle 0.0130 (0.0153) acc 59.3750 (71.8750) kd_loss 0.0108 (0.0101) lr 1.9823e-03 eta 0:40:40
epoch [5/50] batch [60/246] time 0.152 (0.198) data 0.001 (0.005) loss 0.8438 (1.2160) ce_loss 0.7798 (1.1391) teacher_loss 0.7802 (1.1391) loss_zs_kd 0.1026 (0.1256) loss_oracle 0.0123 (0.0140) acc 78.1250 (70.8333) kd_loss 0.0077 (0.0100) lr 1.9823e-03 eta 0:37:10
epoch [5/50] batch [80/246] time 0.153 (0.188) data 0.000 (0.004) loss 1.1160 (1.2229) ce_loss 1.0537 (1.1475) teacher_loss 1.0504 (1.1476) loss_zs_kd 0.0933 (0.1226) loss_oracle 0.0190 (0.0139) acc 68.7500 (70.1562) kd_loss 0.0097 (0.0098) lr 1.9823e-03 eta 0:35:09
epoch [5/50] batch [100/246] time 0.148 (0.182) data 0.000 (0.003) loss 1.1573 (1.2277) ce_loss 1.0342 (1.1487) teacher_loss 1.0289 (1.1481) loss_zs_kd 0.2007 (0.1280) loss_oracle 0.0280 (0.0156) acc 65.6250 (69.8125) kd_loss 0.0163 (0.0100) lr 1.9823e-03 eta 0:33:56
epoch [5/50] batch [120/246] time 0.099 (0.178) data 0.000 (0.003) loss 0.9122 (1.2443) ce_loss 0.8340 (1.1650) teacher_loss 0.8348 (1.1646) loss_zs_kd 0.1229 (0.1281) loss_oracle 0.0159 (0.0157) acc 75.0000 (69.4792) kd_loss 0.0122 (0.0101) lr 1.9823e-03 eta 0:33:07
epoch [5/50] batch [140/246] time 0.358 (0.180) data 0.000 (0.002) loss 1.7385 (1.2458) ce_loss 1.6338 (1.1678) teacher_loss 1.6330 (1.1672) loss_zs_kd 0.1857 (0.1259) loss_oracle 0.0126 (0.0156) acc 65.6250 (69.5536) kd_loss 0.0073 (0.0101) lr 1.9823e-03 eta 0:33:26
epoch [5/50] batch [160/246] time 0.171 (0.184) data 0.000 (0.002) loss 1.4179 (1.2525) ce_loss 1.3291 (1.1724) teacher_loss 1.3316 (1.1720) loss_zs_kd 0.1124 (0.1282) loss_oracle 0.0302 (0.0164) acc 62.5000 (69.3945) kd_loss 0.0121 (0.0100) lr 1.9823e-03 eta 0:34:09
epoch [5/50] batch [180/246] time 0.172 (0.181) data 0.000 (0.002) loss 1.3339 (1.2506) ce_loss 1.2510 (1.1693) teacher_loss 1.2484 (1.1689) loss_zs_kd 0.1190 (0.1280) loss_oracle 0.0260 (0.0178) acc 65.6250 (69.2882) kd_loss 0.0096 (0.0102) lr 1.9823e-03 eta 0:33:39
epoch [5/50] batch [200/246] time 0.172 (0.180) data 0.000 (0.002) loss 1.2523 (1.2575) ce_loss 1.1289 (1.1754) teacher_loss 1.1194 (1.1749) loss_zs_kd 0.2061 (0.1287) loss_oracle 0.0298 (0.0183) acc 71.8750 (69.0469) kd_loss 0.0178 (0.0104) lr 1.9823e-03 eta 0:33:16
epoch [5/50] batch [220/246] time 0.153 (0.178) data 0.000 (0.001) loss 1.5827 (1.2522) ce_loss 1.4961 (1.1690) teacher_loss 1.4958 (1.1685) loss_zs_kd 0.1047 (0.1291) loss_oracle 0.0346 (0.0191) acc 62.5000 (69.0199) kd_loss 0.0118 (0.0106) lr 1.9823e-03 eta 0:32:57
epoch [5/50] batch [240/246] time 0.393 (0.177) data 0.000 (0.001) loss 1.2263 (1.2512) ce_loss 1.1514 (1.1675) teacher_loss 1.1513 (1.1670) loss_zs_kd 0.0964 (0.1286) loss_oracle 0.0268 (0.0198) acc 71.8750 (69.0104) kd_loss 0.0155 (0.0108) lr 1.9823e-03 eta 0:32:37
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,809
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.9%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      83.8%, epoch: 4 *******
******* Domain r best val test acc: 90.9%, epoch: 4 *******
******* Domain r best test acc:     90.9%, epoch: 4 *******
epoch [6/50] batch [20/246] time 0.143 (0.172) data 0.000 (0.013) loss 1.1539 (1.2667) ce_loss 1.0645 (1.1746) teacher_loss 1.0651 (1.1737) loss_zs_kd 0.1411 (0.1463) loss_oracle 0.0182 (0.0199) acc 78.1250 (72.0312) kd_loss 0.0137 (0.0131) lr 1.9686e-03 eta 0:31:44
epoch [6/50] batch [40/246] time 0.146 (0.165) data 0.000 (0.007) loss 1.4507 (1.2387) ce_loss 1.3545 (1.1485) teacher_loss 1.3551 (1.1477) loss_zs_kd 0.1461 (0.1430) loss_oracle 0.0226 (0.0195) acc 59.3750 (71.4062) kd_loss 0.0116 (0.0128) lr 1.9686e-03 eta 0:30:15
epoch [6/50] batch [60/246] time 0.161 (0.165) data 0.000 (0.004) loss 1.1805 (1.2218) ce_loss 1.1104 (1.1308) teacher_loss 1.1124 (1.1300) loss_zs_kd 0.0964 (0.1407) loss_oracle 0.0200 (0.0215) acc 78.1250 (71.5625) kd_loss 0.0100 (0.0127) lr 1.9686e-03 eta 0:30:19
epoch [6/50] batch [80/246] time 0.102 (0.170) data 0.000 (0.003) loss 1.2388 (1.2300) ce_loss 1.1475 (1.1402) teacher_loss 1.1466 (1.1396) loss_zs_kd 0.1399 (0.1367) loss_oracle 0.0223 (0.0220) acc 75.0000 (71.0156) kd_loss 0.0101 (0.0125) lr 1.9686e-03 eta 0:31:11
epoch [6/50] batch [100/246] time 0.168 (0.184) data 0.000 (0.003) loss 1.4572 (1.2250) ce_loss 1.3740 (1.1331) teacher_loss 1.3703 (1.1328) loss_zs_kd 0.1343 (0.1411) loss_oracle 0.0198 (0.0216) acc 62.5000 (70.7500) kd_loss 0.0096 (0.0122) lr 1.9686e-03 eta 0:33:43
epoch [6/50] batch [120/246] time 0.159 (0.181) data 0.000 (0.002) loss 1.0178 (1.2057) ce_loss 0.9185 (1.1126) teacher_loss 0.9190 (1.1124) loss_zs_kd 0.1626 (0.1443) loss_oracle 0.0176 (0.0211) acc 71.8750 (70.9896) kd_loss 0.0118 (0.0120) lr 1.9686e-03 eta 0:33:00
epoch [6/50] batch [140/246] time 0.157 (0.178) data 0.000 (0.002) loss 1.1315 (1.2113) ce_loss 1.0537 (1.1196) teacher_loss 1.0540 (1.1195) loss_zs_kd 0.1037 (0.1408) loss_oracle 0.0256 (0.0214) acc 68.7500 (70.8482) kd_loss 0.0085 (0.0119) lr 1.9686e-03 eta 0:32:27
epoch [6/50] batch [160/246] time 0.150 (0.176) data 0.000 (0.002) loss 1.2390 (1.2306) ce_loss 1.1455 (1.1380) teacher_loss 1.1472 (1.1379) loss_zs_kd 0.1263 (0.1416) loss_oracle 0.0286 (0.0218) acc 65.6250 (70.4297) kd_loss 0.0128 (0.0119) lr 1.9686e-03 eta 0:32:05
epoch [6/50] batch [180/246] time 0.096 (0.175) data 0.000 (0.002) loss 1.4344 (1.2273) ce_loss 1.3311 (1.1340) teacher_loss 1.3305 (1.1338) loss_zs_kd 0.1511 (0.1421) loss_oracle 0.0283 (0.0225) acc 65.6250 (70.5556) kd_loss 0.0138 (0.0122) lr 1.9686e-03 eta 0:31:42
epoch [6/50] batch [200/246] time 0.379 (0.184) data 0.000 (0.002) loss 1.1121 (1.2218) ce_loss 1.0303 (1.1284) teacher_loss 1.0301 (1.1281) loss_zs_kd 0.1143 (0.1415) loss_oracle 0.0249 (0.0230) acc 75.0000 (70.7656) kd_loss 0.0168 (0.0125) lr 1.9686e-03 eta 0:33:23
epoch [6/50] batch [220/246] time 0.167 (0.181) data 0.000 (0.001) loss 1.4580 (1.2230) ce_loss 1.3164 (1.1292) teacher_loss 1.3142 (1.1288) loss_zs_kd 0.2173 (0.1414) loss_oracle 0.0351 (0.0235) acc 68.7500 (70.6818) kd_loss 0.0248 (0.0131) lr 1.9686e-03 eta 0:32:39
epoch [6/50] batch [240/246] time 0.171 (0.179) data 0.000 (0.001) loss 1.1942 (1.2202) ce_loss 1.1240 (1.1265) teacher_loss 1.1239 (1.1261) loss_zs_kd 0.0903 (0.1407) loss_oracle 0.0252 (0.0238) acc 68.7500 (70.7161) kd_loss 0.0140 (0.0133) lr 1.9686e-03 eta 0:32:17
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,807
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,964
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 89.8%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.8%, epoch: 4 *******
******* Domain r best val test acc: 90.9%, epoch: 4 *******
******* Domain r best test acc:     91.0%, epoch: 6 *******
epoch [7/50] batch [20/246] time 0.365 (0.239) data 0.000 (0.025) loss 1.5601 (1.3387) ce_loss 1.4756 (1.2415) teacher_loss 1.4768 (1.2405) loss_zs_kd 0.1167 (0.1223) loss_oracle 0.0249 (0.0371) acc 53.1250 (66.8750) kd_loss 0.0127 (0.0167) lr 1.9511e-03 eta 0:43:06
epoch [7/50] batch [40/246] time 0.177 (0.222) data 0.000 (0.013) loss 0.8597 (1.2477) ce_loss 0.7715 (1.1485) teacher_loss 0.7632 (1.1478) loss_zs_kd 0.1282 (0.1349) loss_oracle 0.0324 (0.0325) acc 81.2500 (70.2344) kd_loss 0.0238 (0.0169) lr 1.9511e-03 eta 0:39:54
epoch [7/50] batch [60/246] time 0.180 (0.207) data 0.001 (0.008) loss 0.7031 (1.2363) ce_loss 0.6006 (1.1347) teacher_loss 0.6000 (1.1337) loss_zs_kd 0.1321 (0.1421) loss_oracle 0.0370 (0.0315) acc 84.3750 (70.0000) kd_loss 0.0149 (0.0171) lr 1.9511e-03 eta 0:37:04
epoch [7/50] batch [80/246] time 0.170 (0.197) data 0.000 (0.006) loss 1.1291 (1.2414) ce_loss 1.0488 (1.1383) teacher_loss 1.0498 (1.1373) loss_zs_kd 0.0958 (0.1412) loss_oracle 0.0314 (0.0335) acc 68.7500 (69.8047) kd_loss 0.0137 (0.0172) lr 1.9511e-03 eta 0:35:11
epoch [7/50] batch [100/246] time 0.153 (0.190) data 0.000 (0.005) loss 1.0789 (1.2451) ce_loss 0.9731 (1.1398) teacher_loss 0.9733 (1.1386) loss_zs_kd 0.1307 (0.1432) loss_oracle 0.0402 (0.0349) acc 71.8750 (69.8750) kd_loss 0.0217 (0.0179) lr 1.9511e-03 eta 0:33:52
epoch [7/50] batch [120/246] time 0.097 (0.190) data 0.001 (0.004) loss 0.7631 (1.2184) ce_loss 0.6548 (1.1153) teacher_loss 0.6570 (1.1142) loss_zs_kd 0.1518 (0.1405) loss_oracle 0.0303 (0.0340) acc 87.5000 (70.7292) kd_loss 0.0201 (0.0180) lr 1.9511e-03 eta 0:33:52
epoch [7/50] batch [140/246] time 0.158 (0.196) data 0.000 (0.004) loss 0.5944 (1.2146) ce_loss 0.5215 (1.1119) teacher_loss 0.5245 (1.1112) loss_zs_kd 0.0859 (0.1411) loss_oracle 0.0270 (0.0328) acc 84.3750 (70.8036) kd_loss 0.0144 (0.0181) lr 1.9511e-03 eta 0:34:51
epoch [7/50] batch [160/246] time 0.159 (0.192) data 0.000 (0.003) loss 1.5434 (1.2339) ce_loss 1.3838 (1.1296) teacher_loss 1.3824 (1.1290) loss_zs_kd 0.2188 (0.1430) loss_oracle 0.0517 (0.0334) acc 62.5000 (70.3516) kd_loss 0.0235 (0.0183) lr 1.9511e-03 eta 0:34:06
epoch [7/50] batch [180/246] time 0.150 (0.189) data 0.000 (0.003) loss 1.4836 (1.2366) ce_loss 1.3486 (1.1305) teacher_loss 1.3528 (1.1299) loss_zs_kd 0.1765 (0.1426) loss_oracle 0.0425 (0.0354) acc 62.5000 (70.1736) kd_loss 0.0181 (0.0188) lr 1.9511e-03 eta 0:33:29
epoch [7/50] batch [200/246] time 0.164 (0.186) data 0.000 (0.003) loss 0.8337 (1.2325) ce_loss 0.7192 (1.1267) teacher_loss 0.7191 (1.1260) loss_zs_kd 0.1592 (0.1412) loss_oracle 0.0350 (0.0358) acc 75.0000 (70.2344) kd_loss 0.0170 (0.0191) lr 1.9511e-03 eta 0:32:59
epoch [7/50] batch [220/246] time 0.093 (0.184) data 0.000 (0.002) loss 1.5671 (1.2298) ce_loss 1.4541 (1.1247) teacher_loss 1.4542 (1.1240) loss_zs_kd 0.1279 (0.1394) loss_oracle 0.0489 (0.0361) acc 65.6250 (70.2273) kd_loss 0.0234 (0.0193) lr 1.9511e-03 eta 0:32:30
epoch [7/50] batch [240/246] time 0.375 (0.186) data 0.000 (0.002) loss 1.0925 (1.2286) ce_loss 0.9771 (1.1224) teacher_loss 0.9802 (1.1217) loss_zs_kd 0.1352 (0.1405) loss_oracle 0.0447 (0.0366) acc 81.2500 (70.1953) kd_loss 0.0227 (0.0194) lr 1.9511e-03 eta 0:32:48
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,813
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      83.9%, epoch: 7 *******
******* Domain r best val test acc: 90.9%, epoch: 7 *******
******* Domain r best test acc:     91.0%, epoch: 6 *******
epoch [8/50] batch [20/246] time 0.164 (0.186) data 0.000 (0.015) loss 1.3670 (1.2423) ce_loss 1.2471 (1.1362) teacher_loss 1.2453 (1.1366) loss_zs_kd 0.1618 (0.1411) loss_oracle 0.0408 (0.0352) acc 68.7500 (70.1562) kd_loss 0.0263 (0.0218) lr 1.9298e-03 eta 0:32:40
epoch [8/50] batch [40/246] time 0.160 (0.175) data 0.000 (0.008) loss 1.4043 (1.2536) ce_loss 1.3066 (1.1499) teacher_loss 1.2968 (1.1495) loss_zs_kd 0.1340 (0.1382) loss_oracle 0.0405 (0.0350) acc 62.5000 (69.8438) kd_loss 0.0236 (0.0220) lr 1.9298e-03 eta 0:30:42
epoch [8/50] batch [60/246] time 0.091 (0.175) data 0.001 (0.005) loss 1.5661 (1.2369) ce_loss 1.4395 (1.1301) teacher_loss 1.4359 (1.1291) loss_zs_kd 0.1715 (0.1413) loss_oracle 0.0444 (0.0371) acc 62.5000 (70.3125) kd_loss 0.0284 (0.0225) lr 1.9298e-03 eta 0:30:35
epoch [8/50] batch [80/246] time 0.172 (0.191) data 0.000 (0.004) loss 0.7571 (1.2283) ce_loss 0.6787 (1.1211) teacher_loss 0.6815 (1.1199) loss_zs_kd 0.0840 (0.1408) loss_oracle 0.0336 (0.0379) acc 84.3750 (70.7422) kd_loss 0.0209 (0.0229) lr 1.9298e-03 eta 0:33:28
epoch [8/50] batch [100/246] time 0.166 (0.185) data 0.000 (0.003) loss 1.2264 (1.2463) ce_loss 1.0742 (1.1384) teacher_loss 1.0684 (1.1370) loss_zs_kd 0.2017 (0.1405) loss_oracle 0.0572 (0.0391) acc 81.2500 (70.2812) kd_loss 0.0330 (0.0230) lr 1.9298e-03 eta 0:32:22
epoch [8/50] batch [120/246] time 0.173 (0.182) data 0.000 (0.003) loss 1.6292 (1.2417) ce_loss 1.4961 (1.1313) teacher_loss 1.4999 (1.1299) loss_zs_kd 0.1697 (0.1420) loss_oracle 0.0444 (0.0408) acc 62.5000 (70.6771) kd_loss 0.0235 (0.0235) lr 1.9298e-03 eta 0:31:40
epoch [8/50] batch [140/246] time 0.172 (0.179) data 0.000 (0.002) loss 1.2460 (1.2505) ce_loss 1.1367 (1.1386) teacher_loss 1.1417 (1.1374) loss_zs_kd 0.1187 (0.1442) loss_oracle 0.0448 (0.0411) acc 68.7500 (70.5357) kd_loss 0.0342 (0.0235) lr 1.9298e-03 eta 0:31:07
epoch [8/50] batch [160/246] time 0.094 (0.177) data 0.000 (0.002) loss 1.5126 (1.2506) ce_loss 1.3994 (1.1403) teacher_loss 1.3948 (1.1390) loss_zs_kd 0.1639 (0.1436) loss_oracle 0.0358 (0.0398) acc 59.3750 (70.5469) kd_loss 0.0261 (0.0235) lr 1.9298e-03 eta 0:30:40
epoch [8/50] batch [180/246] time 0.351 (0.180) data 0.000 (0.002) loss 1.5040 (1.2422) ce_loss 1.4131 (1.1337) teacher_loss 1.4104 (1.1327) loss_zs_kd 0.1323 (0.1421) loss_oracle 0.0275 (0.0385) acc 65.6250 (70.5035) kd_loss 0.0189 (0.0232) lr 1.9298e-03 eta 0:31:12
epoch [8/50] batch [200/246] time 0.161 (0.182) data 0.000 (0.002) loss 1.1236 (1.2437) ce_loss 1.0205 (1.1366) teacher_loss 1.0062 (1.1354) loss_zs_kd 0.1697 (0.1421) loss_oracle 0.0326 (0.0373) acc 75.0000 (70.5000) kd_loss 0.0255 (0.0230) lr 1.9298e-03 eta 0:31:23
epoch [8/50] batch [220/246] time 0.154 (0.179) data 0.000 (0.002) loss 1.2345 (1.2446) ce_loss 1.1553 (1.1376) teacher_loss 1.1565 (1.1365) loss_zs_kd 0.0915 (0.1433) loss_oracle 0.0322 (0.0365) acc 71.8750 (70.4119) kd_loss 0.0177 (0.0226) lr 1.9298e-03 eta 0:30:54
epoch [8/50] batch [240/246] time 0.148 (0.177) data 0.000 (0.001) loss 0.9801 (1.2445) ce_loss 0.8545 (1.1378) teacher_loss 0.8561 (1.1367) loss_zs_kd 0.1736 (0.1438) loss_oracle 0.0372 (0.0359) acc 78.1250 (70.3646) kd_loss 0.0191 (0.0221) lr 1.9298e-03 eta 0:30:30
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,828
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.4%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,973
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.1%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.3%, epoch: 8 *******
******* Domain r best val test acc: 91.2%, epoch: 8 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [9/50] batch [20/246] time 0.087 (0.286) data 0.000 (0.019) loss 0.9122 (1.2381) ce_loss 0.7949 (1.1384) teacher_loss 0.7914 (1.1365) loss_zs_kd 0.1596 (0.1377) loss_oracle 0.0410 (0.0328) acc 78.1250 (70.7812) kd_loss 0.0201 (0.0171) lr 1.9048e-03 eta 0:49:06
epoch [9/50] batch [40/246] time 0.153 (0.220) data 0.000 (0.009) loss 1.4729 (1.2663) ce_loss 1.3818 (1.1615) teacher_loss 1.3786 (1.1591) loss_zs_kd 0.1042 (0.1411) loss_oracle 0.0423 (0.0366) acc 68.7500 (69.5312) kd_loss 0.0136 (0.0171) lr 1.9048e-03 eta 0:37:43
epoch [9/50] batch [60/246] time 0.172 (0.199) data 0.001 (0.006) loss 1.5036 (1.2825) ce_loss 1.3457 (1.1707) teacher_loss 1.3420 (1.1686) loss_zs_kd 0.2102 (0.1443) loss_oracle 0.0565 (0.0418) acc 75.0000 (69.8958) kd_loss 0.0227 (0.0178) lr 1.9048e-03 eta 0:34:06
epoch [9/50] batch [80/246] time 0.172 (0.189) data 0.000 (0.005) loss 1.3896 (1.2838) ce_loss 1.2676 (1.1701) teacher_loss 1.2667 (1.1683) loss_zs_kd 0.1761 (0.1465) loss_oracle 0.0348 (0.0422) acc 56.2500 (69.7656) kd_loss 0.0215 (0.0185) lr 1.9048e-03 eta 0:32:15
epoch [9/50] batch [100/246] time 0.164 (0.183) data 0.000 (0.004) loss 0.8501 (1.2608) ce_loss 0.7729 (1.1509) teacher_loss 0.7702 (1.1491) loss_zs_kd 0.0840 (0.1423) loss_oracle 0.0379 (0.0406) acc 81.2500 (70.1562) kd_loss 0.0234 (0.0191) lr 1.9048e-03 eta 0:31:07
epoch [9/50] batch [120/246] time 0.130 (0.179) data 0.000 (0.003) loss 1.2470 (1.2872) ce_loss 1.1631 (1.1763) teacher_loss 1.1675 (1.1747) loss_zs_kd 0.1047 (0.1450) loss_oracle 0.0272 (0.0400) acc 68.7500 (69.4531) kd_loss 0.0129 (0.0193) lr 1.9048e-03 eta 0:30:23
epoch [9/50] batch [140/246] time 0.404 (0.184) data 0.000 (0.003) loss 1.5046 (1.2909) ce_loss 1.4111 (1.1815) teacher_loss 1.4142 (1.1797) loss_zs_kd 0.1152 (0.1436) loss_oracle 0.0327 (0.0394) acc 65.6250 (69.1295) kd_loss 0.0193 (0.0193) lr 1.9048e-03 eta 0:31:10
epoch [9/50] batch [160/246] time 0.094 (0.180) data 0.000 (0.003) loss 1.1704 (1.2862) ce_loss 1.0654 (1.1782) teacher_loss 1.0653 (1.1765) loss_zs_kd 0.1319 (0.1409) loss_oracle 0.0391 (0.0392) acc 71.8750 (69.2383) kd_loss 0.0141 (0.0192) lr 1.9048e-03 eta 0:30:34
epoch [9/50] batch [180/246] time 0.097 (0.171) data 0.000 (0.002) loss 1.1338 (1.2818) ce_loss 1.0332 (1.1727) teacher_loss 1.0380 (1.1712) loss_zs_kd 0.1198 (0.1408) loss_oracle 0.0360 (0.0403) acc 71.8750 (69.4097) kd_loss 0.0154 (0.0193) lr 1.9048e-03 eta 0:28:53
epoch [9/50] batch [200/246] time 0.096 (0.164) data 0.000 (0.002) loss 1.2783 (1.2807) ce_loss 1.1592 (1.1723) teacher_loss 1.1602 (1.1707) loss_zs_kd 0.1642 (0.1395) loss_oracle 0.0360 (0.0403) acc 65.6250 (69.3750) kd_loss 0.0232 (0.0193) lr 1.9048e-03 eta 0:27:39
epoch [9/50] batch [220/246] time 0.129 (0.159) data 0.000 (0.002) loss 1.0867 (1.2759) ce_loss 0.9790 (1.1673) teacher_loss 0.9803 (1.1656) loss_zs_kd 0.1510 (0.1405) loss_oracle 0.0309 (0.0400) acc 78.1250 (69.5455) kd_loss 0.0123 (0.0192) lr 1.9048e-03 eta 0:26:52
epoch [9/50] batch [240/246] time 0.157 (0.158) data 0.000 (0.002) loss 1.1587 (1.2777) ce_loss 1.0254 (1.1680) teacher_loss 1.0229 (1.1660) loss_zs_kd 0.1565 (0.1413) loss_oracle 0.0576 (0.0411) acc 81.2500 (69.5312) kd_loss 0.0276 (0.0195) lr 1.9048e-03 eta 0:26:31
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,826
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,968
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.0%
******* Domain r best val acc:      84.3%, epoch: 8 *******
******* Domain r best val test acc: 91.2%, epoch: 8 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [10/50] batch [20/246] time 0.149 (0.176) data 0.000 (0.015) loss 1.1863 (1.2912) ce_loss 1.0928 (1.1763) teacher_loss 1.0902 (1.1762) loss_zs_kd 0.1005 (0.1588) loss_oracle 0.0458 (0.0356) acc 65.6250 (69.3750) kd_loss 0.0241 (0.0179) lr 1.8763e-03 eta 0:29:35
epoch [10/50] batch [40/246] time 0.164 (0.167) data 0.000 (0.008) loss 1.5385 (1.2783) ce_loss 1.4209 (1.1638) teacher_loss 1.4085 (1.1615) loss_zs_kd 0.1418 (0.1524) loss_oracle 0.0592 (0.0406) acc 65.6250 (68.9844) kd_loss 0.0285 (0.0202) lr 1.8763e-03 eta 0:27:56
epoch [10/50] batch [60/246] time 0.180 (0.164) data 0.000 (0.005) loss 1.0331 (1.2398) ce_loss 0.9243 (1.1238) teacher_loss 0.9223 (1.1216) loss_zs_kd 0.1300 (0.1502) loss_oracle 0.0457 (0.0430) acc 71.8750 (69.7396) kd_loss 0.0220 (0.0208) lr 1.8763e-03 eta 0:27:27
epoch [10/50] batch [80/246] time 0.364 (0.155) data 0.000 (0.004) loss 1.4259 (1.2397) ce_loss 1.2949 (1.1223) teacher_loss 1.2874 (1.1198) loss_zs_kd 0.1931 (0.1485) loss_oracle 0.0420 (0.0456) acc 59.3750 (69.8438) kd_loss 0.0237 (0.0216) lr 1.8763e-03 eta 0:25:47
epoch [10/50] batch [100/246] time 0.207 (0.165) data 0.000 (0.003) loss 1.4477 (1.2460) ce_loss 1.3516 (1.1309) teacher_loss 1.3503 (1.1281) loss_zs_kd 0.1371 (0.1482) loss_oracle 0.0290 (0.0438) acc 68.7500 (69.7500) kd_loss 0.0219 (0.0217) lr 1.8763e-03 eta 0:27:29
epoch [10/50] batch [120/246] time 0.166 (0.161) data 0.000 (0.003) loss 1.9064 (1.2637) ce_loss 1.7979 (1.1487) teacher_loss 1.7817 (1.1459) loss_zs_kd 0.1358 (0.1496) loss_oracle 0.0569 (0.0431) acc 62.5000 (69.5833) kd_loss 0.0230 (0.0217) lr 1.8763e-03 eta 0:26:41
epoch [10/50] batch [140/246] time 0.143 (0.160) data 0.000 (0.002) loss 0.8846 (1.2713) ce_loss 0.7622 (1.1548) teacher_loss 0.7731 (1.1524) loss_zs_kd 0.1177 (0.1477) loss_oracle 0.0526 (0.0451) acc 81.2500 (69.2188) kd_loss 0.0232 (0.0220) lr 1.8763e-03 eta 0:26:28
epoch [10/50] batch [160/246] time 0.164 (0.160) data 0.000 (0.002) loss 1.3825 (1.2730) ce_loss 1.2832 (1.1564) teacher_loss 1.2787 (1.1543) loss_zs_kd 0.1487 (0.1474) loss_oracle 0.0294 (0.0450) acc 71.8750 (69.1797) kd_loss 0.0219 (0.0224) lr 1.8763e-03 eta 0:26:24
epoch [10/50] batch [180/246] time 0.160 (0.160) data 0.000 (0.002) loss 1.0091 (1.2771) ce_loss 0.9351 (1.1610) teacher_loss 0.9340 (1.1592) loss_zs_kd 0.0708 (0.1469) loss_oracle 0.0397 (0.0444) acc 78.1250 (69.1319) kd_loss 0.0228 (0.0224) lr 1.8763e-03 eta 0:26:20
epoch [10/50] batch [200/246] time 0.168 (0.159) data 0.000 (0.002) loss 1.2046 (1.2753) ce_loss 1.1025 (1.1598) teacher_loss 1.1005 (1.1579) loss_zs_kd 0.1232 (0.1448) loss_oracle 0.0425 (0.0450) acc 75.0000 (69.3125) kd_loss 0.0222 (0.0226) lr 1.8763e-03 eta 0:26:13
epoch [10/50] batch [220/246] time 0.150 (0.159) data 0.000 (0.002) loss 1.5684 (1.2675) ce_loss 1.3887 (1.1529) teacher_loss 1.3850 (1.1508) loss_zs_kd 0.2646 (0.1437) loss_oracle 0.0511 (0.0449) acc 59.3750 (69.4460) kd_loss 0.0281 (0.0225) lr 1.8763e-03 eta 0:26:07
epoch [10/50] batch [240/246] time 0.173 (0.159) data 0.000 (0.001) loss 0.7605 (1.2645) ce_loss 0.6558 (1.1490) teacher_loss 0.6291 (1.1468) loss_zs_kd 0.1270 (0.1448) loss_oracle 0.0679 (0.0453) acc 81.2500 (69.5182) kd_loss 0.0313 (0.0225) lr 1.8763e-03 eta 0:26:01
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,828
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,951
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.4%
******* Domain r best val acc:      84.3%, epoch: 8 *******
******* Domain r best val test acc: 91.2%, epoch: 8 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [11/50] batch [20/246] time 0.150 (0.180) data 0.000 (0.013) loss 0.9404 (1.2668) ce_loss 0.7607 (1.1438) teacher_loss 0.7568 (1.1399) loss_zs_kd 0.2748 (0.1558) loss_oracle 0.0461 (0.0490) acc 84.3750 (70.6250) kd_loss 0.0217 (0.0227) lr 1.8443e-03 eta 0:29:24
epoch [11/50] batch [40/246] time 0.176 (0.174) data 0.000 (0.007) loss 1.2483 (1.2441) ce_loss 1.1367 (1.1233) teacher_loss 1.1258 (1.1191) loss_zs_kd 0.1480 (0.1523) loss_oracle 0.0484 (0.0488) acc 71.8750 (71.1719) kd_loss 0.0217 (0.0225) lr 1.8443e-03 eta 0:28:27
epoch [11/50] batch [60/246] time 0.159 (0.172) data 0.001 (0.005) loss 1.2205 (1.2414) ce_loss 1.0898 (1.1232) teacher_loss 1.0879 (1.1180) loss_zs_kd 0.1980 (0.1547) loss_oracle 0.0336 (0.0460) acc 65.6250 (70.2083) kd_loss 0.0217 (0.0235) lr 1.8443e-03 eta 0:28:04
epoch [11/50] batch [80/246] time 0.166 (0.171) data 0.000 (0.004) loss 1.0793 (1.2357) ce_loss 0.9751 (1.1179) teacher_loss 0.9783 (1.1133) loss_zs_kd 0.1383 (0.1545) loss_oracle 0.0319 (0.0452) acc 81.2500 (70.4688) kd_loss 0.0152 (0.0226) lr 1.8443e-03 eta 0:27:50
epoch [11/50] batch [100/246] time 0.167 (0.171) data 0.000 (0.003) loss 1.3423 (1.2499) ce_loss 1.2246 (1.1309) teacher_loss 1.2296 (1.1264) loss_zs_kd 0.1464 (0.1553) loss_oracle 0.0395 (0.0458) acc 68.7500 (70.0625) kd_loss 0.0207 (0.0227) lr 1.8443e-03 eta 0:27:45
epoch [11/50] batch [120/246] time 0.183 (0.170) data 0.000 (0.002) loss 0.8853 (1.2315) ce_loss 0.7964 (1.1162) teacher_loss 0.7948 (1.1114) loss_zs_kd 0.1249 (0.1528) loss_oracle 0.0280 (0.0437) acc 78.1250 (70.3646) kd_loss 0.0194 (0.0225) lr 1.8443e-03 eta 0:27:29
epoch [11/50] batch [140/246] time 0.109 (0.179) data 0.000 (0.002) loss 1.2098 (1.2360) ce_loss 1.1035 (1.1214) teacher_loss 1.1067 (1.1165) loss_zs_kd 0.1398 (0.1531) loss_oracle 0.0332 (0.0430) acc 78.1250 (70.3125) kd_loss 0.0124 (0.0221) lr 1.8443e-03 eta 0:28:56
epoch [11/50] batch [160/246] time 0.151 (0.174) data 0.000 (0.002) loss 1.4934 (1.2347) ce_loss 1.4043 (1.1199) teacher_loss 1.3813 (1.1152) loss_zs_kd 0.1252 (0.1529) loss_oracle 0.0496 (0.0430) acc 59.3750 (70.2344) kd_loss 0.0245 (0.0219) lr 1.8443e-03 eta 0:28:08
epoch [11/50] batch [180/246] time 0.155 (0.173) data 0.000 (0.002) loss 1.0879 (1.2239) ce_loss 0.9849 (1.1093) teacher_loss 0.9757 (1.1049) loss_zs_kd 0.1330 (0.1531) loss_oracle 0.0457 (0.0425) acc 65.6250 (70.5035) kd_loss 0.0251 (0.0218) lr 1.8443e-03 eta 0:27:46
epoch [11/50] batch [200/246] time 0.168 (0.172) data 0.000 (0.002) loss 1.1046 (1.2243) ce_loss 1.0332 (1.1105) teacher_loss 1.0362 (1.1064) loss_zs_kd 0.0715 (0.1519) loss_oracle 0.0327 (0.0420) acc 71.8750 (70.6719) kd_loss 0.0124 (0.0216) lr 1.8443e-03 eta 0:27:36
epoch [11/50] batch [220/246] time 0.159 (0.171) data 0.000 (0.001) loss 1.2286 (1.2132) ce_loss 1.1152 (1.1002) teacher_loss 1.1108 (1.0964) loss_zs_kd 0.1490 (0.1513) loss_oracle 0.0434 (0.0412) acc 68.7500 (70.9943) kd_loss 0.0277 (0.0215) lr 1.8443e-03 eta 0:27:25
epoch [11/50] batch [240/246] time 0.142 (0.170) data 0.000 (0.001) loss 0.9492 (1.2212) ce_loss 0.8486 (1.1075) teacher_loss 0.8459 (1.1038) loss_zs_kd 0.1308 (0.1521) loss_oracle 0.0379 (0.0413) acc 81.2500 (70.8464) kd_loss 0.0163 (0.0213) lr 1.8443e-03 eta 0:27:12
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,825
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      84.3%, epoch: 8 *******
******* Domain r best val test acc: 91.2%, epoch: 8 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [12/50] batch [20/246] time 0.156 (0.225) data 0.000 (0.015) loss 1.1186 (1.1735) ce_loss 1.0088 (1.0469) teacher_loss 1.0099 (1.0434) loss_zs_kd 0.1228 (0.1525) loss_oracle 0.0473 (0.0539) acc 65.6250 (72.3438) kd_loss 0.0202 (0.0228) lr 1.8090e-03 eta 0:35:55
epoch [12/50] batch [40/246] time 0.155 (0.195) data 0.000 (0.008) loss 1.7874 (1.2176) ce_loss 1.6631 (1.0918) teacher_loss 1.6681 (1.0880) loss_zs_kd 0.1560 (0.1507) loss_oracle 0.0413 (0.0543) acc 59.3750 (70.7812) kd_loss 0.0153 (0.0232) lr 1.8090e-03 eta 0:31:06
epoch [12/50] batch [60/246] time 0.167 (0.182) data 0.000 (0.005) loss 1.6858 (1.2357) ce_loss 1.5859 (1.1129) teacher_loss 1.5630 (1.1090) loss_zs_kd 0.1421 (0.1519) loss_oracle 0.0517 (0.0508) acc 59.3750 (70.3646) kd_loss 0.0299 (0.0229) lr 1.8090e-03 eta 0:28:50
epoch [12/50] batch [80/246] time 0.141 (0.175) data 0.000 (0.004) loss 1.0701 (1.2396) ce_loss 0.9683 (1.1190) teacher_loss 0.9729 (1.1159) loss_zs_kd 0.1216 (0.1527) loss_oracle 0.0364 (0.0473) acc 65.6250 (70.1562) kd_loss 0.0193 (0.0226) lr 1.8090e-03 eta 0:27:43
epoch [12/50] batch [100/246] time 0.163 (0.171) data 0.000 (0.003) loss 1.4903 (1.2122) ce_loss 1.3564 (1.0948) teacher_loss 1.3472 (1.0918) loss_zs_kd 0.1932 (0.1515) loss_oracle 0.0464 (0.0446) acc 62.5000 (70.8750) kd_loss 0.0277 (0.0221) lr 1.8090e-03 eta 0:27:05
epoch [12/50] batch [120/246] time 0.170 (0.169) data 0.000 (0.003) loss 0.7542 (1.1978) ce_loss 0.6724 (1.0818) teacher_loss 0.6716 (1.0792) loss_zs_kd 0.1101 (0.1537) loss_oracle 0.0275 (0.0417) acc 87.5000 (71.3281) kd_loss 0.0201 (0.0215) lr 1.8090e-03 eta 0:26:40
epoch [12/50] batch [140/246] time 0.157 (0.167) data 0.000 (0.002) loss 1.3799 (1.2058) ce_loss 1.3027 (1.0938) teacher_loss 1.3028 (1.0916) loss_zs_kd 0.1065 (0.1503) loss_oracle 0.0238 (0.0390) acc 71.8750 (71.0714) kd_loss 0.0171 (0.0210) lr 1.8090e-03 eta 0:26:23
epoch [12/50] batch [160/246] time 0.098 (0.164) data 0.000 (0.002) loss 1.4933 (1.2090) ce_loss 1.3945 (1.1003) teacher_loss 1.3983 (1.0981) loss_zs_kd 0.1514 (0.1477) loss_oracle 0.0193 (0.0371) acc 65.6250 (70.8008) kd_loss 0.0124 (0.0205) lr 1.8090e-03 eta 0:25:51
epoch [12/50] batch [180/246] time 0.089 (0.171) data 0.000 (0.002) loss 0.9278 (1.2158) ce_loss 0.8188 (1.1072) teacher_loss 0.8168 (1.1050) loss_zs_kd 0.1618 (0.1495) loss_oracle 0.0301 (0.0360) acc 81.2500 (70.8507) kd_loss 0.0230 (0.0200) lr 1.8090e-03 eta 0:26:47
epoch [12/50] batch [200/246] time 0.151 (0.169) data 0.000 (0.002) loss 1.1981 (1.2098) ce_loss 1.0244 (1.1009) teacher_loss 1.0207 (1.0988) loss_zs_kd 0.2459 (0.1504) loss_oracle 0.0545 (0.0357) acc 71.8750 (70.9375) kd_loss 0.0211 (0.0197) lr 1.8090e-03 eta 0:26:26
epoch [12/50] batch [220/246] time 0.167 (0.168) data 0.000 (0.002) loss 1.0095 (1.2131) ce_loss 0.8994 (1.1042) teacher_loss 0.8991 (1.1021) loss_zs_kd 0.1504 (0.1511) loss_oracle 0.0353 (0.0354) acc 78.1250 (70.8523) kd_loss 0.0206 (0.0195) lr 1.8090e-03 eta 0:26:12
epoch [12/50] batch [240/246] time 0.141 (0.167) data 0.000 (0.001) loss 1.0463 (1.2207) ce_loss 0.9492 (1.1111) teacher_loss 0.9479 (1.1092) loss_zs_kd 0.1101 (0.1521) loss_oracle 0.0434 (0.0354) acc 75.0000 (70.6510) kd_loss 0.0157 (0.0192) lr 1.8090e-03 eta 0:26:03
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,815
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,942
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.4%
******* Domain r best val acc:      84.3%, epoch: 8 *******
******* Domain r best val test acc: 91.2%, epoch: 8 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [13/50] batch [20/246] time 0.161 (0.172) data 0.000 (0.013) loss 1.1072 (1.2128) ce_loss 0.9761 (1.0928) teacher_loss 0.9739 (1.0916) loss_zs_kd 0.1607 (0.1532) loss_oracle 0.0530 (0.0446) acc 78.1250 (70.6250) kd_loss 0.0228 (0.0191) lr 1.7705e-03 eta 0:26:42
epoch [13/50] batch [40/246] time 0.383 (0.190) data 0.000 (0.006) loss 1.2629 (1.2037) ce_loss 1.1572 (1.0883) teacher_loss 1.1582 (1.0870) loss_zs_kd 0.1215 (0.1492) loss_oracle 0.0439 (0.0421) acc 71.8750 (71.1719) kd_loss 0.0153 (0.0195) lr 1.7705e-03 eta 0:29:27
epoch [13/50] batch [60/246] time 0.149 (0.181) data 0.000 (0.004) loss 1.6379 (1.2135) ce_loss 1.5225 (1.1000) teacher_loss 1.5202 (1.0984) loss_zs_kd 0.1292 (0.1473) loss_oracle 0.0531 (0.0415) acc 62.5000 (70.8333) kd_loss 0.0217 (0.0197) lr 1.7705e-03 eta 0:27:57
epoch [13/50] batch [80/246] time 0.167 (0.174) data 0.000 (0.003) loss 1.1309 (1.2119) ce_loss 1.0146 (1.0958) teacher_loss 1.0154 (1.0943) loss_zs_kd 0.1544 (0.1492) loss_oracle 0.0383 (0.0430) acc 71.8750 (71.0547) kd_loss 0.0149 (0.0199) lr 1.7705e-03 eta 0:26:54
epoch [13/50] batch [100/246] time 0.150 (0.170) data 0.000 (0.003) loss 0.9661 (1.2132) ce_loss 0.8003 (1.0939) teacher_loss 0.7957 (1.0921) loss_zs_kd 0.2183 (0.1526) loss_oracle 0.0612 (0.0448) acc 87.5000 (71.3125) kd_loss 0.0277 (0.0203) lr 1.7705e-03 eta 0:26:14
epoch [13/50] batch [120/246] time 0.154 (0.168) data 0.000 (0.002) loss 0.7391 (1.2003) ce_loss 0.6050 (1.0813) teacher_loss 0.6122 (1.0798) loss_zs_kd 0.1613 (0.1509) loss_oracle 0.0462 (0.0451) acc 84.3750 (71.5885) kd_loss 0.0187 (0.0208) lr 1.7705e-03 eta 0:25:49
epoch [13/50] batch [140/246] time 0.171 (0.167) data 0.000 (0.002) loss 1.2832 (1.2095) ce_loss 1.1709 (1.0896) teacher_loss 1.1639 (1.0876) loss_zs_kd 0.1385 (0.1513) loss_oracle 0.0500 (0.0463) acc 71.8750 (71.3616) kd_loss 0.0181 (0.0213) lr 1.7705e-03 eta 0:25:35
epoch [13/50] batch [160/246] time 0.180 (0.167) data 0.000 (0.002) loss 1.8058 (1.2262) ce_loss 1.6318 (1.1044) teacher_loss 1.6324 (1.1024) loss_zs_kd 0.2300 (0.1525) loss_oracle 0.0584 (0.0476) acc 56.2500 (70.9180) kd_loss 0.0234 (0.0215) lr 1.7705e-03 eta 0:25:34
epoch [13/50] batch [180/246] time 0.177 (0.167) data 0.000 (0.002) loss 1.8810 (1.2286) ce_loss 1.7754 (1.1056) teacher_loss 1.7754 (1.1033) loss_zs_kd 0.1187 (0.1520) loss_oracle 0.0463 (0.0493) acc 50.0000 (70.7986) kd_loss 0.0216 (0.0221) lr 1.7705e-03 eta 0:25:32
epoch [13/50] batch [200/246] time 0.090 (0.172) data 0.000 (0.001) loss 1.4741 (1.2348) ce_loss 1.3271 (1.1112) teacher_loss 1.3240 (1.1088) loss_zs_kd 0.2227 (0.1546) loss_oracle 0.0387 (0.0487) acc 65.6250 (70.8594) kd_loss 0.0156 (0.0220) lr 1.7705e-03 eta 0:26:11
epoch [13/50] batch [220/246] time 0.172 (0.172) data 0.000 (0.001) loss 1.0914 (1.2220) ce_loss 0.9541 (1.0979) teacher_loss 0.9502 (1.0955) loss_zs_kd 0.1694 (0.1548) loss_oracle 0.0565 (0.0491) acc 78.1250 (71.1506) kd_loss 0.0240 (0.0221) lr 1.7705e-03 eta 0:26:06
epoch [13/50] batch [240/246] time 0.147 (0.171) data 0.000 (0.001) loss 1.1833 (1.2165) ce_loss 1.0420 (1.0931) teacher_loss 1.0469 (1.0907) loss_zs_kd 0.1822 (0.1536) loss_oracle 0.0452 (0.0491) acc 75.0000 (71.3021) kd_loss 0.0220 (0.0220) lr 1.7705e-03 eta 0:25:57
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,833
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.5%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,950
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      84.5%, epoch: 13 *******
******* Domain r best val test acc: 90.7%, epoch: 13 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [14/50] batch [20/246] time 0.169 (0.177) data 0.000 (0.014) loss 0.7212 (1.2407) ce_loss 0.6353 (1.1222) teacher_loss 0.6359 (1.1193) loss_zs_kd 0.1027 (0.1581) loss_oracle 0.0340 (0.0423) acc 81.2500 (68.9062) kd_loss 0.0194 (0.0222) lr 1.7290e-03 eta 0:26:51
epoch [14/50] batch [40/246] time 0.172 (0.170) data 0.000 (0.007) loss 1.6265 (1.1820) ce_loss 1.5146 (1.0712) teacher_loss 1.5157 (1.0680) loss_zs_kd 0.1474 (0.1521) loss_oracle 0.0371 (0.0379) acc 68.7500 (71.4062) kd_loss 0.0288 (0.0228) lr 1.7290e-03 eta 0:25:37
epoch [14/50] batch [60/246] time 0.086 (0.181) data 0.001 (0.005) loss 1.8794 (1.2187) ce_loss 1.7432 (1.1115) teacher_loss 1.7412 (1.1083) loss_zs_kd 0.2230 (0.1512) loss_oracle 0.0267 (0.0348) acc 56.2500 (70.7292) kd_loss 0.0202 (0.0223) lr 1.7290e-03 eta 0:27:15
epoch [14/50] batch [80/246] time 0.158 (0.174) data 0.000 (0.004) loss 1.0410 (1.2054) ce_loss 0.9424 (1.1002) teacher_loss 0.9435 (1.0968) loss_zs_kd 0.1393 (0.1494) loss_oracle 0.0278 (0.0339) acc 84.3750 (71.2891) kd_loss 0.0165 (0.0218) lr 1.7290e-03 eta 0:26:10
epoch [14/50] batch [100/246] time 0.178 (0.173) data 0.000 (0.003) loss 1.1815 (1.2154) ce_loss 1.0215 (1.1097) teacher_loss 1.0147 (1.1062) loss_zs_kd 0.2530 (0.1512) loss_oracle 0.0403 (0.0336) acc 68.7500 (70.6875) kd_loss 0.0228 (0.0215) lr 1.7290e-03 eta 0:25:55
epoch [14/50] batch [120/246] time 0.161 (0.173) data 0.000 (0.002) loss 1.0270 (1.2201) ce_loss 0.9033 (1.1131) teacher_loss 0.8979 (1.1094) loss_zs_kd 0.1711 (0.1506) loss_oracle 0.0436 (0.0354) acc 75.0000 (70.6250) kd_loss 0.0235 (0.0215) lr 1.7290e-03 eta 0:25:50
epoch [14/50] batch [140/246] time 0.161 (0.172) data 0.000 (0.002) loss 1.8111 (1.2305) ce_loss 1.6738 (1.1209) teacher_loss 1.6575 (1.1170) loss_zs_kd 0.1679 (0.1491) loss_oracle 0.0696 (0.0389) acc 62.5000 (70.5134) kd_loss 0.0339 (0.0217) lr 1.7290e-03 eta 0:25:42
epoch [14/50] batch [160/246] time 0.173 (0.172) data 0.000 (0.002) loss 1.1546 (1.2307) ce_loss 1.0352 (1.1194) teacher_loss 1.0367 (1.1157) loss_zs_kd 0.1424 (0.1477) loss_oracle 0.0467 (0.0411) acc 71.8750 (70.5469) kd_loss 0.0203 (0.0219) lr 1.7290e-03 eta 0:25:34
epoch [14/50] batch [180/246] time 0.169 (0.170) data 0.000 (0.002) loss 1.6185 (1.2247) ce_loss 1.5186 (1.1142) teacher_loss 1.4968 (1.1106) loss_zs_kd 0.1651 (0.1469) loss_oracle 0.0391 (0.0406) acc 62.5000 (70.8507) kd_loss 0.0258 (0.0221) lr 1.7290e-03 eta 0:25:20
epoch [14/50] batch [200/246] time 0.112 (0.169) data 0.000 (0.002) loss 1.2558 (1.2272) ce_loss 1.1289 (1.1177) teacher_loss 1.1283 (1.1139) loss_zs_kd 0.1863 (0.1460) loss_oracle 0.0343 (0.0403) acc 62.5000 (70.8594) kd_loss 0.0233 (0.0225) lr 1.7290e-03 eta 0:25:01
epoch [14/50] batch [220/246] time 0.086 (0.174) data 0.000 (0.001) loss 1.0009 (1.2197) ce_loss 0.8589 (1.1099) teacher_loss 0.8623 (1.1061) loss_zs_kd 0.2066 (0.1475) loss_oracle 0.0353 (0.0398) acc 75.0000 (71.0369) kd_loss 0.0188 (0.0225) lr 1.7290e-03 eta 0:25:41
epoch [14/50] batch [240/246] time 0.150 (0.172) data 0.000 (0.001) loss 1.2152 (1.2129) ce_loss 1.0850 (1.1025) teacher_loss 1.0834 (1.0988) loss_zs_kd 0.2001 (0.1491) loss_oracle 0.0317 (0.0396) acc 71.8750 (71.3411) kd_loss 0.0213 (0.0224) lr 1.7290e-03 eta 0:25:22
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,838
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.7%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      84.6%, epoch: 14 *******
******* Domain r best val test acc: 90.9%, epoch: 14 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [15/50] batch [20/246] time 0.143 (0.174) data 0.000 (0.014) loss 1.1830 (1.2058) ce_loss 1.0889 (1.1081) teacher_loss 1.0930 (1.1053) loss_zs_kd 0.1246 (0.1438) loss_oracle 0.0278 (0.0286) acc 68.7500 (70.4688) kd_loss 0.0241 (0.0203) lr 1.6845e-03 eta 0:25:35
epoch [15/50] batch [40/246] time 0.155 (0.166) data 0.000 (0.007) loss 1.1042 (1.1924) ce_loss 0.9980 (1.0936) teacher_loss 0.9845 (1.0918) loss_zs_kd 0.1590 (0.1428) loss_oracle 0.0402 (0.0292) acc 75.0000 (71.1719) kd_loss 0.0270 (0.0214) lr 1.6845e-03 eta 0:24:22
epoch [15/50] batch [60/246] time 0.183 (0.167) data 0.001 (0.005) loss 0.9182 (1.2028) ce_loss 0.7720 (1.0977) teacher_loss 0.7655 (1.0950) loss_zs_kd 0.1962 (0.1491) loss_oracle 0.0545 (0.0333) acc 78.1250 (70.8333) kd_loss 0.0282 (0.0217) lr 1.6845e-03 eta 0:24:29
epoch [15/50] batch [80/246] time 0.085 (0.175) data 0.000 (0.004) loss 0.9556 (1.2025) ce_loss 0.8550 (1.0919) teacher_loss 0.8406 (1.0890) loss_zs_kd 0.1448 (0.1557) loss_oracle 0.0427 (0.0357) acc 71.8750 (71.0156) kd_loss 0.0439 (0.0221) lr 1.6845e-03 eta 0:25:36
epoch [15/50] batch [100/246] time 0.166 (0.175) data 0.000 (0.003) loss 1.0559 (1.1974) ce_loss 0.9502 (1.0857) teacher_loss 0.9476 (1.0828) loss_zs_kd 0.1308 (0.1546) loss_oracle 0.0429 (0.0373) acc 71.8750 (71.3750) kd_loss 0.0178 (0.0218) lr 1.6845e-03 eta 0:25:28
epoch [15/50] batch [120/246] time 0.152 (0.173) data 0.000 (0.002) loss 1.4868 (1.1999) ce_loss 1.3955 (1.0884) teacher_loss 1.3972 (1.0851) loss_zs_kd 0.1124 (0.1543) loss_oracle 0.0335 (0.0377) acc 62.5000 (71.2760) kd_loss 0.0141 (0.0219) lr 1.6845e-03 eta 0:25:10
epoch [15/50] batch [140/246] time 0.166 (0.171) data 0.000 (0.002) loss 1.4300 (1.2078) ce_loss 1.3076 (1.0957) teacher_loss 1.3057 (1.0925) loss_zs_kd 0.1457 (0.1545) loss_oracle 0.0515 (0.0380) acc 68.7500 (71.2054) kd_loss 0.0267 (0.0217) lr 1.6845e-03 eta 0:24:53
epoch [15/50] batch [160/246] time 0.171 (0.170) data 0.000 (0.002) loss 1.6022 (1.2167) ce_loss 1.4883 (1.1042) teacher_loss 1.4729 (1.1013) loss_zs_kd 0.1636 (0.1543) loss_oracle 0.0475 (0.0383) acc 62.5000 (71.1719) kd_loss 0.0221 (0.0216) lr 1.6845e-03 eta 0:24:36
epoch [15/50] batch [180/246] time 0.172 (0.169) data 0.000 (0.002) loss 1.6242 (1.2018) ce_loss 1.4873 (1.0894) teacher_loss 1.4840 (1.0866) loss_zs_kd 0.2048 (0.1529) loss_oracle 0.0378 (0.0388) acc 62.5000 (71.5104) kd_loss 0.0254 (0.0216) lr 1.6845e-03 eta 0:24:25
epoch [15/50] batch [200/246] time 0.177 (0.168) data 0.000 (0.002) loss 1.0641 (1.2047) ce_loss 0.9644 (1.0925) teacher_loss 0.9597 (1.0898) loss_zs_kd 0.1189 (0.1519) loss_oracle 0.0449 (0.0389) acc 68.7500 (71.4062) kd_loss 0.0165 (0.0215) lr 1.6845e-03 eta 0:24:18
epoch [15/50] batch [220/246] time 0.095 (0.167) data 0.000 (0.001) loss 1.6696 (1.2099) ce_loss 1.5205 (1.0971) teacher_loss 1.5283 (1.0945) loss_zs_kd 0.2033 (0.1531) loss_oracle 0.0396 (0.0389) acc 56.2500 (71.2358) kd_loss 0.0205 (0.0214) lr 1.6845e-03 eta 0:23:59
epoch [15/50] batch [240/246] time 0.103 (0.171) data 0.000 (0.001) loss 0.9646 (1.2136) ce_loss 0.8750 (1.1012) teacher_loss 0.8796 (1.0987) loss_zs_kd 0.1255 (0.1532) loss_oracle 0.0223 (0.0383) acc 75.0000 (71.1198) kd_loss 0.0132 (0.0214) lr 1.6845e-03 eta 0:24:36
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,839
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.8%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      84.6%, epoch: 15 *******
******* Domain r best val test acc: 90.7%, epoch: 15 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [16/50] batch [20/246] time 0.152 (0.183) data 0.000 (0.014) loss 0.6418 (1.1966) ce_loss 0.5249 (1.0947) teacher_loss 0.5239 (1.0909) loss_zs_kd 0.1507 (0.1482) loss_oracle 0.0425 (0.0316) acc 90.6250 (70.9375) kd_loss 0.0347 (0.0214) lr 1.6374e-03 eta 0:26:13
epoch [16/50] batch [40/246] time 0.169 (0.177) data 0.000 (0.007) loss 1.0904 (1.2039) ce_loss 0.9658 (1.0962) teacher_loss 0.9493 (1.0926) loss_zs_kd 0.1849 (0.1521) loss_oracle 0.0487 (0.0353) acc 71.8750 (71.4062) kd_loss 0.0280 (0.0208) lr 1.6374e-03 eta 0:25:14
epoch [16/50] batch [60/246] time 0.183 (0.174) data 0.000 (0.005) loss 1.7284 (1.2399) ce_loss 1.5947 (1.1235) teacher_loss 1.5934 (1.1202) loss_zs_kd 0.1523 (0.1559) loss_oracle 0.0589 (0.0417) acc 56.2500 (70.8854) kd_loss 0.0190 (0.0205) lr 1.6374e-03 eta 0:24:43
epoch [16/50] batch [80/246] time 0.090 (0.178) data 0.000 (0.004) loss 1.5048 (1.2694) ce_loss 1.3389 (1.1490) teacher_loss 1.3370 (1.1464) loss_zs_kd 0.2225 (0.1570) loss_oracle 0.0566 (0.0445) acc 59.3750 (70.2734) kd_loss 0.0244 (0.0206) lr 1.6374e-03 eta 0:25:18
epoch [16/50] batch [100/246] time 0.178 (0.181) data 0.000 (0.003) loss 1.1479 (1.2518) ce_loss 1.0303 (1.1303) teacher_loss 1.0189 (1.1278) loss_zs_kd 0.1768 (0.1583) loss_oracle 0.0405 (0.0449) acc 71.8750 (71.0000) kd_loss 0.0215 (0.0210) lr 1.6374e-03 eta 0:25:39
epoch [16/50] batch [120/246] time 0.174 (0.179) data 0.000 (0.003) loss 1.0338 (1.2461) ce_loss 0.9146 (1.1258) teacher_loss 0.8928 (1.1233) loss_zs_kd 0.1872 (0.1574) loss_oracle 0.0474 (0.0442) acc 78.1250 (70.8594) kd_loss 0.0384 (0.0216) lr 1.6374e-03 eta 0:25:19
epoch [16/50] batch [140/246] time 0.164 (0.177) data 0.000 (0.002) loss 1.0558 (1.2451) ce_loss 0.9585 (1.1264) teacher_loss 0.9614 (1.1238) loss_zs_kd 0.1158 (0.1562) loss_oracle 0.0364 (0.0432) acc 75.0000 (70.8482) kd_loss 0.0172 (0.0218) lr 1.6374e-03 eta 0:25:02
epoch [16/50] batch [160/246] time 0.170 (0.176) data 0.000 (0.002) loss 1.7422 (1.2411) ce_loss 1.6533 (1.1239) teacher_loss 1.6429 (1.1211) loss_zs_kd 0.1390 (0.1540) loss_oracle 0.0298 (0.0430) acc 62.5000 (70.7812) kd_loss 0.0225 (0.0219) lr 1.6374e-03 eta 0:24:43
epoch [16/50] batch [180/246] time 0.154 (0.174) data 0.000 (0.002) loss 1.3090 (1.2295) ce_loss 1.2021 (1.1134) teacher_loss 1.1963 (1.1107) loss_zs_kd 0.1275 (0.1522) loss_oracle 0.0490 (0.0427) acc 75.0000 (71.0069) kd_loss 0.0236 (0.0217) lr 1.6374e-03 eta 0:24:26
epoch [16/50] batch [200/246] time 0.151 (0.173) data 0.000 (0.002) loss 0.9931 (1.2367) ce_loss 0.8647 (1.1197) teacher_loss 0.8673 (1.1172) loss_zs_kd 0.1583 (0.1539) loss_oracle 0.0467 (0.0425) acc 75.0000 (70.8906) kd_loss 0.0240 (0.0215) lr 1.6374e-03 eta 0:24:13
epoch [16/50] batch [220/246] time 0.085 (0.176) data 0.000 (0.001) loss 1.2491 (1.2306) ce_loss 1.1406 (1.1128) teacher_loss 1.1402 (1.1104) loss_zs_kd 0.1414 (0.1545) loss_oracle 0.0383 (0.0429) acc 75.0000 (71.3068) kd_loss 0.0205 (0.0213) lr 1.6374e-03 eta 0:24:37
epoch [16/50] batch [240/246] time 0.155 (0.174) data 0.000 (0.001) loss 1.3609 (1.2275) ce_loss 1.2754 (1.1101) teacher_loss 1.2733 (1.1078) loss_zs_kd 0.1300 (0.1535) loss_oracle 0.0226 (0.0429) acc 68.7500 (71.2891) kd_loss 0.0218 (0.0213) lr 1.6374e-03 eta 0:24:18
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,836
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      84.6%, epoch: 15 *******
******* Domain r best val test acc: 90.7%, epoch: 15 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [17/50] batch [20/246] time 0.148 (0.185) data 0.000 (0.015) loss 1.0413 (1.2159) ce_loss 0.9697 (1.1086) teacher_loss 0.9678 (1.1062) loss_zs_kd 0.0850 (0.1527) loss_oracle 0.0310 (0.0333) acc 71.8750 (71.8750) kd_loss 0.0165 (0.0202) lr 1.5878e-03 eta 0:25:47
epoch [17/50] batch [40/246] time 0.149 (0.172) data 0.000 (0.008) loss 0.7490 (1.1974) ce_loss 0.6611 (1.0904) teacher_loss 0.6565 (1.0871) loss_zs_kd 0.1279 (0.1539) loss_oracle 0.0285 (0.0333) acc 84.3750 (72.3438) kd_loss 0.0191 (0.0223) lr 1.5878e-03 eta 0:23:53
epoch [17/50] batch [60/246] time 0.168 (0.168) data 0.001 (0.005) loss 0.9522 (1.1853) ce_loss 0.7974 (1.0766) teacher_loss 0.7925 (1.0733) loss_zs_kd 0.2415 (0.1578) loss_oracle 0.0390 (0.0330) acc 75.0000 (72.3958) kd_loss 0.0444 (0.0227) lr 1.5878e-03 eta 0:23:15
epoch [17/50] batch [80/246] time 0.098 (0.164) data 0.000 (0.004) loss 1.1244 (1.2051) ce_loss 1.0215 (1.0980) teacher_loss 1.0217 (1.0950) loss_zs_kd 0.1365 (0.1544) loss_oracle 0.0344 (0.0329) acc 78.1250 (71.7578) kd_loss 0.0164 (0.0224) lr 1.5878e-03 eta 0:22:37
epoch [17/50] batch [100/246] time 0.085 (0.176) data 0.000 (0.003) loss 1.2424 (1.2088) ce_loss 1.1279 (1.1005) teacher_loss 1.1375 (1.0975) loss_zs_kd 0.1488 (0.1558) loss_oracle 0.0305 (0.0334) acc 75.0000 (71.6250) kd_loss 0.0250 (0.0225) lr 1.5878e-03 eta 0:24:13
epoch [17/50] batch [120/246] time 0.170 (0.172) data 0.000 (0.003) loss 1.0005 (1.1949) ce_loss 0.8564 (1.0856) teacher_loss 0.8511 (1.0827) loss_zs_kd 0.2087 (0.1563) loss_oracle 0.0450 (0.0340) acc 81.2500 (72.2917) kd_loss 0.0471 (0.0231) lr 1.5878e-03 eta 0:23:37
epoch [17/50] batch [140/246] time 0.157 (0.170) data 0.000 (0.002) loss 1.1750 (1.2007) ce_loss 1.0742 (1.0905) teacher_loss 1.0742 (1.0876) loss_zs_kd 0.1260 (0.1575) loss_oracle 0.0379 (0.0343) acc 75.0000 (72.1205) kd_loss 0.0327 (0.0236) lr 1.5878e-03 eta 0:23:18
epoch [17/50] batch [160/246] time 0.143 (0.168) data 0.000 (0.002) loss 1.0034 (1.2015) ce_loss 0.8828 (1.0917) teacher_loss 0.8664 (1.0888) loss_zs_kd 0.1560 (0.1567) loss_oracle 0.0590 (0.0343) acc 68.7500 (71.9922) kd_loss 0.0297 (0.0235) lr 1.5878e-03 eta 0:22:58
epoch [17/50] batch [180/246] time 0.152 (0.167) data 0.000 (0.002) loss 1.7071 (1.2044) ce_loss 1.5928 (1.0940) teacher_loss 1.5902 (1.0914) loss_zs_kd 0.1687 (0.1565) loss_oracle 0.0326 (0.0347) acc 68.7500 (71.8750) kd_loss 0.0168 (0.0230) lr 1.5878e-03 eta 0:22:44
epoch [17/50] batch [200/246] time 0.153 (0.166) data 0.000 (0.002) loss 0.9990 (1.2007) ce_loss 0.9331 (1.0914) teacher_loss 0.9338 (1.0889) loss_zs_kd 0.0879 (0.1554) loss_oracle 0.0213 (0.0342) acc 78.1250 (72.0312) kd_loss 0.0186 (0.0229) lr 1.5878e-03 eta 0:22:32
epoch [17/50] batch [220/246] time 0.166 (0.166) data 0.000 (0.002) loss 1.0724 (1.2045) ce_loss 0.9414 (1.0950) teacher_loss 0.9394 (1.0925) loss_zs_kd 0.1954 (0.1560) loss_oracle 0.0353 (0.0339) acc 71.8750 (71.8040) kd_loss 0.0215 (0.0227) lr 1.5878e-03 eta 0:22:27
epoch [17/50] batch [240/246] time 0.087 (0.164) data 0.000 (0.001) loss 0.9627 (1.1977) ce_loss 0.8530 (1.0876) teacher_loss 0.8504 (1.0852) loss_zs_kd 0.1460 (0.1571) loss_oracle 0.0394 (0.0339) acc 78.1250 (71.9661) kd_loss 0.0316 (0.0225) lr 1.5878e-03 eta 0:22:15
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,839
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      84.6%, epoch: 15 *******
******* Domain r best val test acc: 90.7%, epoch: 15 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [18/50] batch [20/246] time 0.167 (0.178) data 0.000 (0.014) loss 0.9074 (1.2035) ce_loss 0.7705 (1.0917) teacher_loss 0.7758 (1.0894) loss_zs_kd 0.1960 (0.1631) loss_oracle 0.0336 (0.0326) acc 84.3750 (72.0312) kd_loss 0.0299 (0.0239) lr 1.5358e-03 eta 0:23:59
epoch [18/50] batch [40/246] time 0.166 (0.169) data 0.000 (0.007) loss 1.3473 (1.2232) ce_loss 1.2158 (1.1144) teacher_loss 1.2175 (1.1113) loss_zs_kd 0.1840 (0.1589) loss_oracle 0.0378 (0.0324) acc 68.7500 (71.1719) kd_loss 0.0179 (0.0226) lr 1.5358e-03 eta 0:22:44
epoch [18/50] batch [60/246] time 0.172 (0.167) data 0.001 (0.005) loss 1.1279 (1.1872) ce_loss 1.0146 (1.0730) teacher_loss 1.0109 (1.0701) loss_zs_kd 0.1698 (0.1682) loss_oracle 0.0321 (0.0330) acc 65.6250 (72.6562) kd_loss 0.0176 (0.0222) lr 1.5358e-03 eta 0:22:29
epoch [18/50] batch [80/246] time 0.153 (0.165) data 0.000 (0.004) loss 1.4261 (1.2051) ce_loss 1.3145 (1.0927) teacher_loss 1.3133 (1.0894) loss_zs_kd 0.1389 (0.1632) loss_oracle 0.0434 (0.0340) acc 68.7500 (72.1484) kd_loss 0.0345 (0.0224) lr 1.5358e-03 eta 0:22:09
epoch [18/50] batch [100/246] time 0.083 (0.163) data 0.000 (0.003) loss 1.3566 (1.1996) ce_loss 1.2539 (1.0877) teacher_loss 1.2512 (1.0846) loss_zs_kd 0.1388 (0.1599) loss_oracle 0.0360 (0.0350) acc 68.7500 (71.7500) kd_loss 0.0233 (0.0223) lr 1.5358e-03 eta 0:21:46
epoch [18/50] batch [120/246] time 0.131 (0.166) data 0.000 (0.003) loss 1.5227 (1.2145) ce_loss 1.3984 (1.1014) teacher_loss 1.3972 (1.0982) loss_zs_kd 0.1790 (0.1618) loss_oracle 0.0359 (0.0354) acc 68.7500 (71.2760) kd_loss 0.0203 (0.0217) lr 1.5358e-03 eta 0:22:11
epoch [18/50] batch [140/246] time 0.148 (0.169) data 0.000 (0.002) loss 0.8024 (1.2115) ce_loss 0.7021 (1.0977) teacher_loss 0.6970 (1.0946) loss_zs_kd 0.1202 (0.1620) loss_oracle 0.0453 (0.0359) acc 84.3750 (71.3393) kd_loss 0.0232 (0.0215) lr 1.5358e-03 eta 0:22:25
epoch [18/50] batch [160/246] time 0.166 (0.167) data 0.000 (0.002) loss 0.6314 (1.2059) ce_loss 0.5039 (1.0899) teacher_loss 0.5045 (1.0870) loss_zs_kd 0.1737 (0.1635) loss_oracle 0.0400 (0.0371) acc 90.6250 (71.3672) kd_loss 0.0128 (0.0212) lr 1.5358e-03 eta 0:22:12
epoch [18/50] batch [180/246] time 0.176 (0.166) data 0.000 (0.002) loss 0.8424 (1.2046) ce_loss 0.7593 (1.0894) teacher_loss 0.7507 (1.0866) loss_zs_kd 0.1087 (0.1623) loss_oracle 0.0373 (0.0369) acc 78.1250 (71.1979) kd_loss 0.0176 (0.0213) lr 1.5358e-03 eta 0:22:00
epoch [18/50] batch [200/246] time 0.156 (0.165) data 0.000 (0.002) loss 1.0840 (1.2088) ce_loss 0.9668 (1.0930) teacher_loss 0.9701 (1.0905) loss_zs_kd 0.1841 (0.1633) loss_oracle 0.0219 (0.0367) acc 71.8750 (70.9688) kd_loss 0.0136 (0.0213) lr 1.5358e-03 eta 0:21:49
epoch [18/50] batch [220/246] time 0.148 (0.165) data 0.000 (0.001) loss 0.8974 (1.2103) ce_loss 0.8242 (1.0950) teacher_loss 0.8241 (1.0925) loss_zs_kd 0.0895 (0.1630) loss_oracle 0.0286 (0.0363) acc 78.1250 (71.0795) kd_loss 0.0242 (0.0214) lr 1.5358e-03 eta 0:21:41
epoch [18/50] batch [240/246] time 0.157 (0.165) data 0.000 (0.001) loss 0.8935 (1.2175) ce_loss 0.7559 (1.1027) teacher_loss 0.7562 (1.1001) loss_zs_kd 0.2112 (0.1626) loss_oracle 0.0317 (0.0360) acc 81.2500 (70.8594) kd_loss 0.0296 (0.0216) lr 1.5358e-03 eta 0:21:36
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,839
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      84.6%, epoch: 15 *******
******* Domain r best val test acc: 90.7%, epoch: 15 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [19/50] batch [20/246] time 0.173 (0.177) data 0.000 (0.015) loss 0.8796 (1.1253) ce_loss 0.7920 (1.0162) teacher_loss 0.7895 (1.0140) loss_zs_kd 0.1311 (0.1595) loss_oracle 0.0245 (0.0316) acc 84.3750 (74.5312) kd_loss 0.0170 (0.0237) lr 1.4818e-03 eta 0:23:07
epoch [19/50] batch [40/246] time 0.163 (0.168) data 0.000 (0.007) loss 1.0531 (1.1679) ce_loss 0.9658 (1.0610) teacher_loss 0.9689 (1.0583) loss_zs_kd 0.1152 (0.1559) loss_oracle 0.0265 (0.0316) acc 78.1250 (71.5625) kd_loss 0.0160 (0.0233) lr 1.4818e-03 eta 0:21:59
epoch [19/50] batch [60/246] time 0.163 (0.166) data 0.001 (0.005) loss 1.1370 (1.1698) ce_loss 1.0547 (1.0621) teacher_loss 1.0493 (1.0587) loss_zs_kd 0.1103 (0.1588) loss_oracle 0.0325 (0.0317) acc 71.8750 (71.6667) kd_loss 0.0208 (0.0224) lr 1.4818e-03 eta 0:21:40
epoch [19/50] batch [80/246] time 0.155 (0.165) data 0.000 (0.004) loss 1.3746 (1.1723) ce_loss 1.2510 (1.0629) teacher_loss 1.2403 (1.0594) loss_zs_kd 0.2087 (0.1617) loss_oracle 0.0300 (0.0321) acc 65.6250 (71.5234) kd_loss 0.0188 (0.0218) lr 1.4818e-03 eta 0:21:28
epoch [19/50] batch [100/246] time 0.162 (0.165) data 0.000 (0.003) loss 1.1262 (1.1821) ce_loss 0.9907 (1.0731) teacher_loss 0.9956 (1.0704) loss_zs_kd 0.1821 (0.1601) loss_oracle 0.0396 (0.0317) acc 71.8750 (71.3125) kd_loss 0.0286 (0.0215) lr 1.4818e-03 eta 0:21:19
epoch [19/50] batch [120/246] time 0.162 (0.164) data 0.000 (0.003) loss 1.1301 (1.1902) ce_loss 0.9902 (1.0796) teacher_loss 0.9924 (1.0774) loss_zs_kd 0.2086 (0.1630) loss_oracle 0.0334 (0.0313) acc 71.8750 (70.9375) kd_loss 0.0265 (0.0213) lr 1.4818e-03 eta 0:21:11
epoch [19/50] batch [140/246] time 0.085 (0.168) data 0.001 (0.002) loss 1.0761 (1.2078) ce_loss 0.9790 (1.0984) teacher_loss 0.9795 (1.0963) loss_zs_kd 0.1454 (0.1617) loss_oracle 0.0239 (0.0307) acc 75.0000 (70.6696) kd_loss 0.0181 (0.0213) lr 1.4818e-03 eta 0:21:37
epoch [19/50] batch [160/246] time 0.180 (0.169) data 0.000 (0.002) loss 1.0420 (1.2033) ce_loss 0.9209 (1.0943) teacher_loss 0.9248 (1.0923) loss_zs_kd 0.1698 (0.1607) loss_oracle 0.0323 (0.0306) acc 65.6250 (70.6836) kd_loss 0.0154 (0.0216) lr 1.4818e-03 eta 0:21:41
epoch [19/50] batch [180/246] time 0.138 (0.168) data 0.000 (0.002) loss 1.3048 (1.2061) ce_loss 1.1338 (1.0961) teacher_loss 1.1333 (1.0944) loss_zs_kd 0.2416 (0.1596) loss_oracle 0.0507 (0.0319) acc 71.8750 (70.7986) kd_loss 0.0254 (0.0218) lr 1.4818e-03 eta 0:21:32
epoch [19/50] batch [200/246] time 0.171 (0.167) data 0.000 (0.002) loss 1.2884 (1.2078) ce_loss 1.1943 (1.0972) teacher_loss 1.1907 (1.0954) loss_zs_kd 0.1111 (0.1585) loss_oracle 0.0421 (0.0331) acc 71.8750 (70.7500) kd_loss 0.0256 (0.0218) lr 1.4818e-03 eta 0:21:20
epoch [19/50] batch [220/246] time 0.147 (0.166) data 0.000 (0.002) loss 0.8843 (1.2160) ce_loss 0.7656 (1.1049) teacher_loss 0.7589 (1.1031) loss_zs_kd 0.1797 (0.1584) loss_oracle 0.0355 (0.0337) acc 81.2500 (70.5256) kd_loss 0.0229 (0.0216) lr 1.4818e-03 eta 0:21:13
epoch [19/50] batch [240/246] time 0.152 (0.166) data 0.000 (0.001) loss 1.2836 (1.2172) ce_loss 1.1562 (1.1055) teacher_loss 1.1460 (1.1039) loss_zs_kd 0.1970 (0.1592) loss_oracle 0.0391 (0.0337) acc 68.7500 (70.5859) kd_loss 0.0196 (0.0216) lr 1.4818e-03 eta 0:21:04
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,847
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,961
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [20/50] batch [20/246] time 0.175 (0.216) data 0.000 (0.015) loss 1.2464 (1.2406) ce_loss 1.1211 (1.1243) teacher_loss 1.1306 (1.1234) loss_zs_kd 0.1665 (0.1651) loss_oracle 0.0325 (0.0346) acc 71.8750 (71.2500) kd_loss 0.0199 (0.0199) lr 1.4258e-03 eta 0:27:24
epoch [20/50] batch [40/246] time 0.153 (0.191) data 0.000 (0.008) loss 1.0675 (1.2193) ce_loss 0.9346 (1.1069) teacher_loss 0.9330 (1.1052) loss_zs_kd 0.1908 (0.1599) loss_oracle 0.0391 (0.0341) acc 75.0000 (71.2500) kd_loss 0.0155 (0.0202) lr 1.4258e-03 eta 0:24:05
epoch [20/50] batch [60/246] time 0.154 (0.181) data 0.001 (0.005) loss 1.3013 (1.2313) ce_loss 1.1660 (1.1198) teacher_loss 1.1638 (1.1177) loss_zs_kd 0.2025 (0.1582) loss_oracle 0.0362 (0.0345) acc 71.8750 (70.9375) kd_loss 0.0182 (0.0200) lr 1.4258e-03 eta 0:22:48
epoch [20/50] batch [80/246] time 0.146 (0.175) data 0.000 (0.004) loss 1.2406 (1.2357) ce_loss 1.1055 (1.1220) teacher_loss 1.1085 (1.1201) loss_zs_kd 0.1813 (0.1601) loss_oracle 0.0414 (0.0355) acc 81.2500 (71.1719) kd_loss 0.0208 (0.0198) lr 1.4258e-03 eta 0:22:03
epoch [20/50] batch [100/246] time 0.154 (0.172) data 0.000 (0.003) loss 0.8392 (1.2407) ce_loss 0.7158 (1.1272) teacher_loss 0.7147 (1.1252) loss_zs_kd 0.1563 (0.1585) loss_oracle 0.0463 (0.0362) acc 84.3750 (71.1562) kd_loss 0.0182 (0.0199) lr 1.4258e-03 eta 0:21:31
epoch [20/50] batch [120/246] time 0.151 (0.169) data 0.000 (0.003) loss 1.2816 (1.2260) ce_loss 1.0859 (1.1094) teacher_loss 1.0928 (1.1076) loss_zs_kd 0.2814 (0.1611) loss_oracle 0.0480 (0.0378) acc 71.8750 (71.5625) kd_loss 0.0236 (0.0201) lr 1.4258e-03 eta 0:21:06
epoch [20/50] batch [140/246] time 0.151 (0.167) data 0.000 (0.002) loss 1.0925 (1.2191) ce_loss 0.9844 (1.1026) teacher_loss 0.9727 (1.1008) loss_zs_kd 0.1430 (0.1612) loss_oracle 0.0483 (0.0377) acc 75.0000 (71.5179) kd_loss 0.0367 (0.0202) lr 1.4258e-03 eta 0:20:52
epoch [20/50] batch [160/246] time 0.345 (0.169) data 0.001 (0.002) loss 0.7038 (1.2126) ce_loss 0.5938 (1.0958) teacher_loss 0.5961 (1.0938) loss_zs_kd 0.1445 (0.1624) loss_oracle 0.0354 (0.0376) acc 87.5000 (71.7773) kd_loss 0.0282 (0.0208) lr 1.4258e-03 eta 0:21:04
epoch [20/50] batch [180/246] time 0.166 (0.171) data 0.000 (0.002) loss 1.0971 (1.1980) ce_loss 0.9785 (1.0817) teacher_loss 0.9773 (1.0795) loss_zs_kd 0.1647 (0.1616) loss_oracle 0.0374 (0.0377) acc 71.8750 (72.2222) kd_loss 0.0327 (0.0217) lr 1.4258e-03 eta 0:21:12
epoch [20/50] batch [200/246] time 0.152 (0.170) data 0.000 (0.002) loss 1.1429 (1.1996) ce_loss 1.0127 (1.0824) teacher_loss 0.9954 (1.0798) loss_zs_kd 0.2047 (0.1624) loss_oracle 0.0451 (0.0386) acc 68.7500 (72.3281) kd_loss 0.0310 (0.0224) lr 1.4258e-03 eta 0:21:03
epoch [20/50] batch [220/246] time 0.153 (0.169) data 0.000 (0.002) loss 1.5589 (1.1975) ce_loss 1.4590 (1.0808) teacher_loss 1.4439 (1.0779) loss_zs_kd 0.1363 (0.1613) loss_oracle 0.0468 (0.0389) acc 62.5000 (72.0739) kd_loss 0.0274 (0.0229) lr 1.4258e-03 eta 0:20:52
epoch [20/50] batch [240/246] time 0.167 (0.168) data 0.000 (0.001) loss 1.2321 (1.2010) ce_loss 1.1230 (1.0840) teacher_loss 1.1170 (1.0810) loss_zs_kd 0.1535 (0.1615) loss_oracle 0.0383 (0.0393) acc 75.0000 (72.0443) kd_loss 0.0195 (0.0231) lr 1.4258e-03 eta 0:20:42
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,838
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [21/50] batch [20/246] time 0.137 (0.176) data 0.000 (0.012) loss 0.6713 (1.1822) ce_loss 0.5830 (1.0640) teacher_loss 0.5787 (1.0611) loss_zs_kd 0.1104 (0.1690) loss_oracle 0.0374 (0.0365) acc 87.5000 (71.8750) kd_loss 0.0216 (0.0256) lr 1.3681e-03 eta 0:21:31
epoch [21/50] batch [40/246] time 0.099 (0.176) data 0.000 (0.006) loss 1.0964 (1.2079) ce_loss 0.9688 (1.0955) teacher_loss 0.9521 (1.0916) loss_zs_kd 0.1739 (0.1594) loss_oracle 0.0573 (0.0366) acc 71.8750 (71.1719) kd_loss 0.0463 (0.0259) lr 1.3681e-03 eta 0:21:35
epoch [21/50] batch [60/246] time 0.154 (0.176) data 0.001 (0.004) loss 1.1158 (1.2072) ce_loss 0.9575 (1.0900) teacher_loss 0.9632 (1.0864) loss_zs_kd 0.2048 (0.1666) loss_oracle 0.0503 (0.0375) acc 78.1250 (71.6667) kd_loss 0.0293 (0.0260) lr 1.3681e-03 eta 0:21:28
epoch [21/50] batch [80/246] time 0.152 (0.172) data 0.000 (0.003) loss 1.3363 (1.1960) ce_loss 1.2324 (1.0791) teacher_loss 1.2301 (1.0755) loss_zs_kd 0.1487 (0.1652) loss_oracle 0.0318 (0.0379) acc 65.6250 (72.0312) kd_loss 0.0176 (0.0258) lr 1.3681e-03 eta 0:20:55
epoch [21/50] batch [100/246] time 0.155 (0.169) data 0.000 (0.003) loss 1.1553 (1.1995) ce_loss 1.0693 (1.0833) teacher_loss 1.0691 (1.0794) loss_zs_kd 0.1343 (0.1640) loss_oracle 0.0190 (0.0380) acc 68.7500 (72.0000) kd_loss 0.0153 (0.0261) lr 1.3681e-03 eta 0:20:31
epoch [21/50] batch [120/246] time 0.153 (0.167) data 0.000 (0.002) loss 0.8056 (1.2083) ce_loss 0.7085 (1.0941) teacher_loss 0.7116 (1.0906) loss_zs_kd 0.1361 (0.1615) loss_oracle 0.0259 (0.0370) acc 78.1250 (71.8229) kd_loss 0.0170 (0.0255) lr 1.3681e-03 eta 0:20:13
epoch [21/50] batch [140/246] time 0.169 (0.167) data 0.000 (0.002) loss 0.8974 (1.2057) ce_loss 0.7803 (1.0918) teacher_loss 0.7819 (1.0889) loss_zs_kd 0.1556 (0.1610) loss_oracle 0.0378 (0.0363) acc 78.1250 (71.8750) kd_loss 0.0263 (0.0249) lr 1.3681e-03 eta 0:20:08
epoch [21/50] batch [160/246] time 0.165 (0.166) data 0.000 (0.002) loss 0.8607 (1.2013) ce_loss 0.7344 (1.0870) teacher_loss 0.7386 (1.0841) loss_zs_kd 0.1853 (0.1620) loss_oracle 0.0295 (0.0362) acc 81.2500 (71.9531) kd_loss 0.0198 (0.0245) lr 1.3681e-03 eta 0:19:58
epoch [21/50] batch [180/246] time 0.181 (0.166) data 0.000 (0.002) loss 1.3561 (1.2158) ce_loss 1.2275 (1.1014) teacher_loss 1.2203 (1.0983) loss_zs_kd 0.1949 (0.1623) loss_oracle 0.0384 (0.0363) acc 68.7500 (71.5278) kd_loss 0.0334 (0.0249) lr 1.3681e-03 eta 0:19:54
epoch [21/50] batch [200/246] time 0.086 (0.167) data 0.000 (0.001) loss 1.2781 (1.2143) ce_loss 1.1436 (1.1006) teacher_loss 1.1345 (1.0975) loss_zs_kd 0.2053 (0.1617) loss_oracle 0.0409 (0.0360) acc 75.0000 (71.5469) kd_loss 0.0505 (0.0253) lr 1.3681e-03 eta 0:20:01
epoch [21/50] batch [220/246] time 0.150 (0.168) data 0.000 (0.001) loss 1.0626 (1.2194) ce_loss 0.9414 (1.1059) teacher_loss 0.9334 (1.1029) loss_zs_kd 0.1749 (0.1616) loss_oracle 0.0418 (0.0357) acc 65.6250 (71.3920) kd_loss 0.0444 (0.0255) lr 1.3681e-03 eta 0:20:02
epoch [21/50] batch [240/246] time 0.154 (0.167) data 0.000 (0.001) loss 1.1588 (1.2206) ce_loss 1.0537 (1.1075) teacher_loss 1.0560 (1.1047) loss_zs_kd 0.1538 (0.1613) loss_oracle 0.0258 (0.0353) acc 71.8750 (71.1589) kd_loss 0.0196 (0.0255) lr 1.3681e-03 eta 0:19:55
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,844
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [22/50] batch [20/246] time 0.151 (0.178) data 0.000 (0.013) loss 0.9601 (1.1743) ce_loss 0.8506 (1.0589) teacher_loss 0.8487 (1.0552) loss_zs_kd 0.1576 (0.1675) loss_oracle 0.0326 (0.0353) acc 78.1250 (71.2500) kd_loss 0.0235 (0.0305) lr 1.3090e-03 eta 0:21:07
epoch [22/50] batch [40/246] time 0.091 (0.171) data 0.000 (0.007) loss 1.3481 (1.2454) ce_loss 1.2188 (1.1270) teacher_loss 1.2286 (1.1251) loss_zs_kd 0.1827 (0.1702) loss_oracle 0.0281 (0.0352) acc 75.0000 (69.5312) kd_loss 0.0174 (0.0292) lr 1.3090e-03 eta 0:20:16
epoch [22/50] batch [60/246] time 0.109 (0.175) data 0.001 (0.004) loss 1.0523 (1.2367) ce_loss 0.9395 (1.1176) teacher_loss 0.9439 (1.1160) loss_zs_kd 0.1557 (0.1711) loss_oracle 0.0306 (0.0352) acc 71.8750 (69.4271) kd_loss 0.0322 (0.0288) lr 1.3090e-03 eta 0:20:39
epoch [22/50] batch [80/246] time 0.156 (0.176) data 0.000 (0.003) loss 1.4637 (1.2249) ce_loss 1.3311 (1.1076) teacher_loss 1.3332 (1.1054) loss_zs_kd 0.1989 (0.1692) loss_oracle 0.0311 (0.0349) acc 56.2500 (69.8828) kd_loss 0.0260 (0.0289) lr 1.3090e-03 eta 0:20:39
epoch [22/50] batch [100/246] time 0.154 (0.172) data 0.000 (0.003) loss 0.7806 (1.2035) ce_loss 0.7100 (1.0885) teacher_loss 0.6724 (1.0861) loss_zs_kd 0.1344 (0.1658) loss_oracle 0.0410 (0.0344) acc 87.5000 (70.1875) kd_loss 0.0312 (0.0284) lr 1.3090e-03 eta 0:20:13
epoch [22/50] batch [120/246] time 0.151 (0.171) data 0.000 (0.002) loss 1.1967 (1.1943) ce_loss 1.0811 (1.0805) teacher_loss 1.0764 (1.0782) loss_zs_kd 0.1621 (0.1639) loss_oracle 0.0393 (0.0342) acc 68.7500 (70.7031) kd_loss 0.0349 (0.0282) lr 1.3090e-03 eta 0:19:56
epoch [22/50] batch [140/246] time 0.157 (0.169) data 0.000 (0.002) loss 1.1061 (1.1905) ce_loss 0.9678 (1.0769) teacher_loss 0.9618 (1.0748) loss_zs_kd 0.1990 (0.1633) loss_oracle 0.0447 (0.0341) acc 81.2500 (71.1607) kd_loss 0.0248 (0.0275) lr 1.3090e-03 eta 0:19:40
epoch [22/50] batch [160/246] time 0.174 (0.168) data 0.000 (0.002) loss 0.9561 (1.1853) ce_loss 0.8599 (1.0731) teacher_loss 0.8552 (1.0712) loss_zs_kd 0.1180 (0.1594) loss_oracle 0.0420 (0.0344) acc 75.0000 (71.3672) kd_loss 0.0349 (0.0271) lr 1.3090e-03 eta 0:19:31
epoch [22/50] batch [180/246] time 0.161 (0.167) data 0.000 (0.002) loss 1.4669 (1.1857) ce_loss 1.3271 (1.0728) teacher_loss 1.3279 (1.0710) loss_zs_kd 0.1937 (0.1603) loss_oracle 0.0421 (0.0345) acc 59.3750 (71.4410) kd_loss 0.0303 (0.0266) lr 1.3090e-03 eta 0:19:21
epoch [22/50] batch [200/246] time 0.175 (0.166) data 0.000 (0.001) loss 1.3183 (1.1882) ce_loss 1.1709 (1.0750) teacher_loss 1.1724 (1.0730) loss_zs_kd 0.2169 (0.1609) loss_oracle 0.0374 (0.0347) acc 68.7500 (71.3750) kd_loss 0.0344 (0.0266) lr 1.3090e-03 eta 0:19:13
epoch [22/50] batch [220/246] time 0.087 (0.168) data 0.000 (0.001) loss 1.4393 (1.1939) ce_loss 1.3076 (1.0808) teacher_loss 1.3037 (1.0789) loss_zs_kd 0.1911 (0.1604) loss_oracle 0.0401 (0.0348) acc 68.7500 (71.3068) kd_loss 0.0317 (0.0264) lr 1.3090e-03 eta 0:19:23
epoch [22/50] batch [240/246] time 0.148 (0.168) data 0.000 (0.001) loss 0.9758 (1.1990) ce_loss 0.8633 (1.0855) teacher_loss 0.8647 (1.0836) loss_zs_kd 0.1525 (0.1613) loss_oracle 0.0348 (0.0347) acc 78.1250 (71.2109) kd_loss 0.0263 (0.0263) lr 1.3090e-03 eta 0:19:16
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,844
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,950
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [23/50] batch [20/246] time 0.155 (0.176) data 0.000 (0.013) loss 1.0683 (1.2114) ce_loss 0.9434 (1.0930) teacher_loss 0.9429 (1.0916) loss_zs_kd 0.1679 (0.1702) loss_oracle 0.0415 (0.0347) acc 71.8750 (69.5312) kd_loss 0.0261 (0.0236) lr 1.2487e-03 eta 0:20:08
epoch [23/50] batch [40/246] time 0.172 (0.171) data 0.000 (0.007) loss 1.4082 (1.2396) ce_loss 1.2988 (1.1223) teacher_loss 1.3069 (1.1200) loss_zs_kd 0.1470 (0.1685) loss_oracle 0.0278 (0.0354) acc 62.5000 (69.4531) kd_loss 0.0146 (0.0238) lr 1.2487e-03 eta 0:19:28
epoch [23/50] batch [60/246] time 0.171 (0.167) data 0.001 (0.005) loss 1.2482 (1.2239) ce_loss 1.0967 (1.1067) teacher_loss 1.0920 (1.1046) loss_zs_kd 0.2348 (0.1682) loss_oracle 0.0388 (0.0352) acc 68.7500 (70.4167) kd_loss 0.0266 (0.0244) lr 1.2487e-03 eta 0:19:03
epoch [23/50] batch [80/246] time 0.355 (0.168) data 0.000 (0.003) loss 0.9501 (1.2459) ce_loss 0.8403 (1.1315) teacher_loss 0.8406 (1.1292) loss_zs_kd 0.1706 (0.1632) loss_oracle 0.0241 (0.0350) acc 84.3750 (69.7266) kd_loss 0.0235 (0.0246) lr 1.2487e-03 eta 0:19:05
epoch [23/50] batch [100/246] time 0.183 (0.179) data 0.000 (0.003) loss 1.0762 (1.2273) ce_loss 0.9512 (1.1140) teacher_loss 0.9523 (1.1116) loss_zs_kd 0.1881 (0.1626) loss_oracle 0.0298 (0.0344) acc 81.2500 (70.3438) kd_loss 0.0197 (0.0241) lr 1.2487e-03 eta 0:20:18
epoch [23/50] batch [120/246] time 0.156 (0.177) data 0.000 (0.002) loss 0.9435 (1.2065) ce_loss 0.8228 (1.0925) teacher_loss 0.8203 (1.0902) loss_zs_kd 0.1549 (0.1636) loss_oracle 0.0457 (0.0345) acc 71.8750 (70.9635) kd_loss 0.0385 (0.0243) lr 1.2487e-03 eta 0:19:58
epoch [23/50] batch [140/246] time 0.172 (0.175) data 0.000 (0.002) loss 0.9543 (1.2057) ce_loss 0.8555 (1.0901) teacher_loss 0.8523 (1.0882) loss_zs_kd 0.1314 (0.1656) loss_oracle 0.0363 (0.0346) acc 78.1250 (71.0714) kd_loss 0.0313 (0.0245) lr 1.2487e-03 eta 0:19:41
epoch [23/50] batch [160/246] time 0.164 (0.173) data 0.000 (0.002) loss 1.4824 (1.2070) ce_loss 1.3828 (1.0916) teacher_loss 1.3848 (1.0898) loss_zs_kd 0.1289 (0.1641) loss_oracle 0.0332 (0.0351) acc 62.5000 (70.8984) kd_loss 0.0186 (0.0250) lr 1.2487e-03 eta 0:19:26
epoch [23/50] batch [180/246] time 0.146 (0.172) data 0.000 (0.002) loss 0.9911 (1.1972) ce_loss 0.8647 (1.0814) teacher_loss 0.8772 (1.0796) loss_zs_kd 0.1751 (0.1642) loss_oracle 0.0264 (0.0355) acc 78.1250 (70.9896) kd_loss 0.0180 (0.0256) lr 1.2487e-03 eta 0:19:14
epoch [23/50] batch [200/246] time 0.152 (0.171) data 0.000 (0.002) loss 1.5955 (1.1918) ce_loss 1.4834 (1.0759) teacher_loss 1.4854 (1.0741) loss_zs_kd 0.1679 (0.1643) loss_oracle 0.0261 (0.0356) acc 59.3750 (71.1562) kd_loss 0.0236 (0.0259) lr 1.2487e-03 eta 0:19:01
epoch [23/50] batch [220/246] time 0.172 (0.170) data 0.000 (0.001) loss 1.2085 (1.1931) ce_loss 1.0859 (1.0770) teacher_loss 1.0842 (1.0752) loss_zs_kd 0.1775 (0.1646) loss_oracle 0.0356 (0.0356) acc 75.0000 (71.0653) kd_loss 0.0349 (0.0260) lr 1.2487e-03 eta 0:18:53
epoch [23/50] batch [240/246] time 0.084 (0.171) data 0.000 (0.001) loss 0.8456 (1.1953) ce_loss 0.7705 (1.0793) teacher_loss 0.7517 (1.0776) loss_zs_kd 0.1055 (0.1645) loss_oracle 0.0412 (0.0355) acc 78.1250 (71.0677) kd_loss 0.0360 (0.0261) lr 1.2487e-03 eta 0:18:56
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,847
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      84.9%, epoch: 19 *******
******* Domain r best val test acc: 90.9%, epoch: 19 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [24/50] batch [20/246] time 0.163 (0.185) data 0.000 (0.015) loss 1.2131 (1.1622) ce_loss 1.1064 (1.0438) teacher_loss 1.1067 (1.0438) loss_zs_kd 0.1656 (0.1699) loss_oracle 0.0235 (0.0334) acc 78.1250 (71.4062) kd_loss 0.0300 (0.0296) lr 1.1874e-03 eta 0:20:25
epoch [24/50] batch [40/246] time 0.161 (0.176) data 0.000 (0.008) loss 1.3497 (1.1961) ce_loss 1.1982 (1.0779) teacher_loss 1.1985 (1.0748) loss_zs_kd 0.2370 (0.1722) loss_oracle 0.0327 (0.0352) acc 65.6250 (71.3281) kd_loss 0.0245 (0.0307) lr 1.1874e-03 eta 0:19:19
epoch [24/50] batch [60/246] time 0.170 (0.173) data 0.001 (0.005) loss 1.3305 (1.1929) ce_loss 1.2275 (1.0741) teacher_loss 1.2243 (1.0709) loss_zs_kd 0.1404 (0.1723) loss_oracle 0.0360 (0.0359) acc 68.7500 (71.7188) kd_loss 0.0276 (0.0297) lr 1.1874e-03 eta 0:18:55
epoch [24/50] batch [80/246] time 0.156 (0.171) data 0.000 (0.004) loss 1.1744 (1.2137) ce_loss 1.0312 (1.0917) teacher_loss 1.0274 (1.0884) loss_zs_kd 0.2266 (0.1778) loss_oracle 0.0337 (0.0364) acc 71.8750 (71.4453) kd_loss 0.0227 (0.0297) lr 1.1874e-03 eta 0:18:40
epoch [24/50] batch [100/246] time 0.377 (0.182) data 0.000 (0.003) loss 1.3989 (1.2234) ce_loss 1.2627 (1.1022) teacher_loss 1.2739 (1.0992) loss_zs_kd 0.1674 (0.1754) loss_oracle 0.0413 (0.0365) acc 71.8750 (71.3750) kd_loss 0.0371 (0.0295) lr 1.1874e-03 eta 0:19:48
epoch [24/50] batch [120/246] time 0.182 (0.179) data 0.000 (0.003) loss 1.1417 (1.1940) ce_loss 1.0107 (1.0719) teacher_loss 1.0118 (1.0691) loss_zs_kd 0.2157 (0.1759) loss_oracle 0.0221 (0.0369) acc 75.0000 (71.9531) kd_loss 0.0181 (0.0300) lr 1.1874e-03 eta 0:19:30
epoch [24/50] batch [140/246] time 0.173 (0.179) data 0.000 (0.002) loss 1.0184 (1.1931) ce_loss 0.9053 (1.0724) teacher_loss 0.9041 (1.0694) loss_zs_kd 0.1574 (0.1739) loss_oracle 0.0356 (0.0368) acc 81.2500 (72.1875) kd_loss 0.0311 (0.0299) lr 1.1874e-03 eta 0:19:21
epoch [24/50] batch [160/246] time 0.174 (0.178) data 0.000 (0.002) loss 1.3010 (1.1961) ce_loss 1.1562 (1.0757) teacher_loss 1.1578 (1.0728) loss_zs_kd 0.2203 (0.1734) loss_oracle 0.0331 (0.0365) acc 65.6250 (72.0703) kd_loss 0.0260 (0.0293) lr 1.1874e-03 eta 0:19:10
epoch [24/50] batch [180/246] time 0.175 (0.177) data 0.000 (0.002) loss 1.6968 (1.1961) ce_loss 1.5566 (1.0757) teacher_loss 1.5566 (1.0730) loss_zs_kd 0.2029 (0.1729) loss_oracle 0.0387 (0.0367) acc 59.3750 (72.1181) kd_loss 0.0222 (0.0291) lr 1.1874e-03 eta 0:19:03
epoch [24/50] batch [200/246] time 0.176 (0.176) data 0.000 (0.002) loss 1.6934 (1.2122) ce_loss 1.5732 (1.0924) teacher_loss 1.5814 (1.0899) loss_zs_kd 0.1589 (0.1712) loss_oracle 0.0326 (0.0368) acc 53.1250 (71.4062) kd_loss 0.0207 (0.0287) lr 1.1874e-03 eta 0:18:55
epoch [24/50] batch [220/246] time 0.169 (0.176) data 0.000 (0.002) loss 1.4715 (1.2108) ce_loss 1.3418 (1.0913) teacher_loss 1.3511 (1.0886) loss_zs_kd 0.1544 (0.1697) loss_oracle 0.0433 (0.0374) acc 59.3750 (71.4631) kd_loss 0.0313 (0.0285) lr 1.1874e-03 eta 0:18:50
epoch [24/50] batch [240/246] time 0.441 (0.180) data 0.000 (0.002) loss 1.1909 (1.2075) ce_loss 1.0654 (1.0878) teacher_loss 1.0598 (1.0851) loss_zs_kd 0.1696 (0.1695) loss_oracle 0.0463 (0.0376) acc 68.7500 (71.4844) kd_loss 0.0285 (0.0283) lr 1.1874e-03 eta 0:19:12
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,851
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.1%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,948
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.5%
******* Domain r best val acc:      85.0%, epoch: 24 *******
******* Domain r best val test acc: 90.6%, epoch: 24 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [25/50] batch [20/246] time 0.154 (0.179) data 0.000 (0.014) loss 1.0534 (1.2005) ce_loss 0.9258 (1.0799) teacher_loss 0.9293 (1.0765) loss_zs_kd 0.1700 (0.1639) loss_oracle 0.0391 (0.0421) acc 75.0000 (71.4062) kd_loss 0.0300 (0.0302) lr 1.1253e-03 eta 0:19:03
epoch [25/50] batch [40/246] time 0.167 (0.172) data 0.000 (0.007) loss 1.0475 (1.1627) ce_loss 0.9238 (1.0409) teacher_loss 0.9186 (1.0378) loss_zs_kd 0.1659 (0.1619) loss_oracle 0.0460 (0.0439) acc 75.0000 (71.2500) kd_loss 0.0314 (0.0283) lr 1.1253e-03 eta 0:18:11
epoch [25/50] batch [60/246] time 0.152 (0.169) data 0.001 (0.005) loss 1.7938 (1.1973) ce_loss 1.6689 (1.0766) teacher_loss 1.6699 (1.0732) loss_zs_kd 0.1729 (0.1635) loss_oracle 0.0374 (0.0424) acc 56.2500 (70.6250) kd_loss 0.0291 (0.0276) lr 1.1253e-03 eta 0:17:53
epoch [25/50] batch [80/246] time 0.129 (0.165) data 0.000 (0.004) loss 1.0946 (1.1913) ce_loss 1.0068 (1.0711) teacher_loss 0.9981 (1.0681) loss_zs_kd 0.1227 (0.1632) loss_oracle 0.0351 (0.0416) acc 71.8750 (70.7031) kd_loss 0.0256 (0.0277) lr 1.1253e-03 eta 0:17:21
epoch [25/50] batch [100/246] time 0.096 (0.176) data 0.000 (0.003) loss 0.9319 (1.1966) ce_loss 0.8242 (1.0767) teacher_loss 0.8215 (1.0744) loss_zs_kd 0.1532 (0.1630) loss_oracle 0.0338 (0.0408) acc 81.2500 (70.9062) kd_loss 0.0256 (0.0276) lr 1.1253e-03 eta 0:18:27
epoch [25/50] batch [120/246] time 0.161 (0.174) data 0.000 (0.003) loss 1.2056 (1.2168) ce_loss 1.0967 (1.0962) teacher_loss 1.0956 (1.0934) loss_zs_kd 0.1682 (0.1655) loss_oracle 0.0259 (0.0407) acc 78.1250 (70.4688) kd_loss 0.0186 (0.0284) lr 1.1253e-03 eta 0:18:12
epoch [25/50] batch [140/246] time 0.157 (0.173) data 0.000 (0.002) loss 1.1112 (1.2106) ce_loss 0.9849 (1.0899) teacher_loss 0.9791 (1.0872) loss_zs_kd 0.1803 (0.1657) loss_oracle 0.0419 (0.0405) acc 78.1250 (71.1161) kd_loss 0.0374 (0.0285) lr 1.1253e-03 eta 0:18:00
epoch [25/50] batch [160/246] time 0.168 (0.172) data 0.000 (0.002) loss 1.4619 (1.2187) ce_loss 1.3506 (1.0986) teacher_loss 1.3571 (1.0962) loss_zs_kd 0.1527 (0.1644) loss_oracle 0.0284 (0.0403) acc 65.6250 (70.8789) kd_loss 0.0247 (0.0284) lr 1.1253e-03 eta 0:17:54
epoch [25/50] batch [180/246] time 0.175 (0.172) data 0.000 (0.002) loss 1.0798 (1.2176) ce_loss 0.9766 (1.0980) teacher_loss 0.9691 (1.0955) loss_zs_kd 0.1395 (0.1638) loss_oracle 0.0409 (0.0402) acc 75.0000 (71.0069) kd_loss 0.0273 (0.0290) lr 1.1253e-03 eta 0:17:49
epoch [25/50] batch [200/246] time 0.172 (0.171) data 0.000 (0.002) loss 1.0617 (1.2073) ce_loss 0.9126 (1.0884) teacher_loss 0.9169 (1.0857) loss_zs_kd 0.2202 (0.1635) loss_oracle 0.0347 (0.0398) acc 75.0000 (71.2031) kd_loss 0.0285 (0.0291) lr 1.1253e-03 eta 0:17:38
epoch [25/50] batch [220/246] time 0.131 (0.170) data 0.000 (0.002) loss 1.2805 (1.2003) ce_loss 1.1816 (1.0816) teacher_loss 1.1759 (1.0789) loss_zs_kd 0.1391 (0.1632) loss_oracle 0.0350 (0.0399) acc 75.0000 (71.6051) kd_loss 0.0324 (0.0295) lr 1.1253e-03 eta 0:17:31
epoch [25/50] batch [240/246] time 0.340 (0.172) data 0.000 (0.001) loss 1.0105 (1.2039) ce_loss 0.8921 (1.0847) teacher_loss 0.8885 (1.0820) loss_zs_kd 0.1533 (0.1640) loss_oracle 0.0453 (0.0399) acc 78.1250 (71.4062) kd_loss 0.0337 (0.0299) lr 1.1253e-03 eta 0:17:40
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,860
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.4%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,944
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.5%
******* Domain r best val acc:      85.3%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [26/50] batch [20/246] time 0.152 (0.173) data 0.000 (0.013) loss 1.1578 (1.2436) ce_loss 1.0449 (1.1247) teacher_loss 1.0472 (1.1224) loss_zs_kd 0.1582 (0.1621) loss_oracle 0.0315 (0.0402) acc 65.6250 (69.6875) kd_loss 0.0171 (0.0337) lr 1.0628e-03 eta 0:17:43
epoch [26/50] batch [40/246] time 0.147 (0.167) data 0.000 (0.007) loss 1.1407 (1.1585) ce_loss 1.0420 (1.0407) teacher_loss 1.0361 (1.0394) loss_zs_kd 0.1515 (0.1610) loss_oracle 0.0288 (0.0385) acc 75.0000 (71.7969) kd_loss 0.0269 (0.0354) lr 1.0628e-03 eta 0:17:00
epoch [26/50] batch [60/246] time 0.163 (0.165) data 0.001 (0.004) loss 1.1378 (1.1586) ce_loss 1.0215 (1.0398) teacher_loss 1.0250 (1.0379) loss_zs_kd 0.1620 (0.1667) loss_oracle 0.0318 (0.0374) acc 65.6250 (71.7708) kd_loss 0.0358 (0.0362) lr 1.0628e-03 eta 0:16:45
epoch [26/50] batch [80/246] time 0.171 (0.163) data 0.000 (0.003) loss 1.1532 (1.1733) ce_loss 1.0479 (1.0567) teacher_loss 1.0536 (1.0543) loss_zs_kd 0.1263 (0.1636) loss_oracle 0.0364 (0.0372) acc 75.0000 (71.5625) kd_loss 0.0385 (0.0359) lr 1.0628e-03 eta 0:16:32
epoch [26/50] batch [100/246] time 0.085 (0.173) data 0.000 (0.003) loss 1.4299 (1.1904) ce_loss 1.2852 (1.0718) teacher_loss 1.2819 (1.0691) loss_zs_kd 0.1984 (0.1671) loss_oracle 0.0488 (0.0377) acc 68.7500 (71.3125) kd_loss 0.0425 (0.0361) lr 1.0628e-03 eta 0:17:25
epoch [26/50] batch [120/246] time 0.168 (0.170) data 0.000 (0.002) loss 1.6905 (1.2116) ce_loss 1.5654 (1.0932) teacher_loss 1.5675 (1.0908) loss_zs_kd 0.1893 (0.1674) loss_oracle 0.0284 (0.0371) acc 62.5000 (70.8854) kd_loss 0.0237 (0.0350) lr 1.0628e-03 eta 0:17:04
epoch [26/50] batch [140/246] time 0.156 (0.169) data 0.000 (0.002) loss 1.1500 (1.2182) ce_loss 1.0459 (1.1007) teacher_loss 1.0528 (1.0982) loss_zs_kd 0.1255 (0.1667) loss_oracle 0.0344 (0.0366) acc 75.0000 (70.8259) kd_loss 0.0385 (0.0344) lr 1.0628e-03 eta 0:16:52
epoch [26/50] batch [160/246] time 0.167 (0.167) data 0.000 (0.002) loss 1.1705 (1.2146) ce_loss 1.0488 (1.0976) teacher_loss 1.0512 (1.0949) loss_zs_kd 0.1713 (0.1648) loss_oracle 0.0336 (0.0373) acc 68.7500 (70.7031) kd_loss 0.0369 (0.0345) lr 1.0628e-03 eta 0:16:43
epoch [26/50] batch [180/246] time 0.163 (0.167) data 0.000 (0.002) loss 1.1435 (1.2061) ce_loss 1.0068 (1.0880) teacher_loss 1.0048 (1.0854) loss_zs_kd 0.1703 (0.1656) loss_oracle 0.0535 (0.0380) acc 62.5000 (70.9201) kd_loss 0.0329 (0.0343) lr 1.0628e-03 eta 0:16:36
epoch [26/50] batch [200/246] time 0.163 (0.166) data 0.000 (0.001) loss 0.8629 (1.1982) ce_loss 0.7324 (1.0809) teacher_loss 0.7331 (1.0784) loss_zs_kd 0.1673 (0.1641) loss_oracle 0.0461 (0.0377) acc 81.2500 (71.1875) kd_loss 0.0457 (0.0338) lr 1.0628e-03 eta 0:16:27
epoch [26/50] batch [220/246] time 0.166 (0.167) data 0.000 (0.001) loss 1.8369 (1.2142) ce_loss 1.7188 (1.0969) teacher_loss 1.6971 (1.0945) loss_zs_kd 0.2034 (0.1646) loss_oracle 0.0382 (0.0374) acc 65.6250 (70.9091) kd_loss 0.0335 (0.0335) lr 1.0628e-03 eta 0:16:28
epoch [26/50] batch [240/246] time 0.181 (0.167) data 0.000 (0.001) loss 1.1002 (1.2132) ce_loss 1.0107 (1.0959) teacher_loss 1.0141 (1.0936) loss_zs_kd 0.1101 (0.1645) loss_oracle 0.0310 (0.0374) acc 75.0000 (70.8333) kd_loss 0.0256 (0.0332) lr 1.0628e-03 eta 0:16:27
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,849
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.3%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [27/50] batch [20/246] time 0.165 (0.187) data 0.000 (0.014) loss 0.8043 (1.1309) ce_loss 0.6963 (1.0194) teacher_loss 0.6917 (1.0165) loss_zs_kd 0.1503 (0.1571) loss_oracle 0.0375 (0.0359) acc 78.1250 (72.5000) kd_loss 0.0329 (0.0331) lr 1.0000e-03 eta 0:18:17
epoch [27/50] batch [40/246] time 0.161 (0.175) data 0.000 (0.007) loss 0.8884 (1.1263) ce_loss 0.7578 (1.0139) teacher_loss 0.7546 (1.0107) loss_zs_kd 0.1536 (0.1581) loss_oracle 0.0570 (0.0366) acc 78.1250 (72.3438) kd_loss 0.0472 (0.0320) lr 1.0000e-03 eta 0:17:06
epoch [27/50] batch [60/246] time 0.154 (0.172) data 0.001 (0.005) loss 1.1365 (1.1615) ce_loss 0.9868 (1.0455) teacher_loss 0.9811 (1.0412) loss_zs_kd 0.2198 (0.1643) loss_oracle 0.0455 (0.0381) acc 75.0000 (71.6667) kd_loss 0.0476 (0.0341) lr 1.0000e-03 eta 0:16:46
epoch [27/50] batch [80/246] time 0.175 (0.170) data 0.000 (0.004) loss 1.1584 (1.1875) ce_loss 1.0469 (1.0707) teacher_loss 1.0422 (1.0676) loss_zs_kd 0.1646 (0.1638) loss_oracle 0.0339 (0.0380) acc 65.6250 (71.2891) kd_loss 0.0337 (0.0332) lr 1.0000e-03 eta 0:16:32
epoch [27/50] batch [100/246] time 0.167 (0.169) data 0.000 (0.003) loss 1.2327 (1.1829) ce_loss 1.0840 (1.0646) teacher_loss 1.0915 (1.0615) loss_zs_kd 0.2240 (0.1659) loss_oracle 0.0292 (0.0385) acc 75.0000 (71.6562) kd_loss 0.0190 (0.0331) lr 1.0000e-03 eta 0:16:22
epoch [27/50] batch [120/246] time 0.097 (0.173) data 0.000 (0.003) loss 1.1515 (1.1948) ce_loss 1.0234 (1.0755) teacher_loss 1.0093 (1.0725) loss_zs_kd 0.1592 (0.1665) loss_oracle 0.0626 (0.0390) acc 75.0000 (71.3281) kd_loss 0.0480 (0.0329) lr 1.0000e-03 eta 0:16:41
epoch [27/50] batch [140/246] time 0.154 (0.174) data 0.000 (0.002) loss 1.1804 (1.1947) ce_loss 1.0928 (1.0739) teacher_loss 1.0887 (1.0709) loss_zs_kd 0.0993 (0.1678) loss_oracle 0.0421 (0.0399) acc 65.6250 (71.2054) kd_loss 0.0413 (0.0330) lr 1.0000e-03 eta 0:16:43
epoch [27/50] batch [160/246] time 0.154 (0.173) data 0.000 (0.002) loss 1.2559 (1.1797) ce_loss 1.1260 (1.0578) teacher_loss 1.1198 (1.0553) loss_zs_kd 0.1655 (0.1669) loss_oracle 0.0534 (0.0409) acc 71.8750 (71.7383) kd_loss 0.0502 (0.0336) lr 1.0000e-03 eta 0:16:34
epoch [27/50] batch [180/246] time 0.175 (0.172) data 0.000 (0.002) loss 1.3409 (1.1844) ce_loss 1.2393 (1.0613) teacher_loss 1.2396 (1.0587) loss_zs_kd 0.1162 (0.1684) loss_oracle 0.0432 (0.0415) acc 68.7500 (71.8576) kd_loss 0.0365 (0.0341) lr 1.0000e-03 eta 0:16:22
epoch [27/50] batch [200/246] time 0.156 (0.171) data 0.000 (0.002) loss 1.0135 (1.1838) ce_loss 0.8262 (1.0593) teacher_loss 0.8396 (1.0570) loss_zs_kd 0.2454 (0.1696) loss_oracle 0.0512 (0.0420) acc 75.0000 (71.7500) kd_loss 0.0508 (0.0347) lr 1.0000e-03 eta 0:16:14
epoch [27/50] batch [220/246] time 0.170 (0.170) data 0.000 (0.001) loss 1.2235 (1.1842) ce_loss 1.0801 (1.0596) teacher_loss 1.0551 (1.0568) loss_zs_kd 0.1949 (0.1699) loss_oracle 0.0709 (0.0424) acc 71.8750 (71.7756) kd_loss 0.0630 (0.0356) lr 1.0000e-03 eta 0:16:06
epoch [27/50] batch [240/246] time 0.158 (0.169) data 0.000 (0.001) loss 0.7875 (1.1832) ce_loss 0.6455 (1.0583) teacher_loss 0.6497 (1.0555) loss_zs_kd 0.1988 (0.1703) loss_oracle 0.0384 (0.0426) acc 84.3750 (71.7578) kd_loss 0.0393 (0.0366) lr 1.0000e-03 eta 0:15:59
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,853
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.3%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [28/50] batch [20/246] time 0.174 (0.179) data 0.000 (0.014) loss 1.1139 (1.1645) ce_loss 0.9771 (1.0467) teacher_loss 0.9738 (1.0421) loss_zs_kd 0.1850 (0.1625) loss_oracle 0.0476 (0.0412) acc 78.1250 (73.4375) kd_loss 0.0464 (0.0438) lr 9.3721e-04 eta 0:16:48
epoch [28/50] batch [40/246] time 0.154 (0.170) data 0.000 (0.007) loss 1.0565 (1.1819) ce_loss 0.9331 (1.0573) teacher_loss 0.9365 (1.0541) loss_zs_kd 0.1530 (0.1717) loss_oracle 0.0435 (0.0419) acc 71.8750 (72.3438) kd_loss 0.0306 (0.0421) lr 9.3721e-04 eta 0:15:54
epoch [28/50] batch [60/246] time 0.161 (0.168) data 0.001 (0.005) loss 1.1156 (1.1802) ce_loss 1.0098 (1.0576) teacher_loss 1.0089 (1.0545) loss_zs_kd 0.1200 (0.1653) loss_oracle 0.0467 (0.0431) acc 78.1250 (72.3438) kd_loss 0.0367 (0.0422) lr 9.3721e-04 eta 0:15:37
epoch [28/50] batch [80/246] time 0.161 (0.166) data 0.000 (0.004) loss 1.7523 (1.1945) ce_loss 1.6260 (1.0717) teacher_loss 1.6186 (1.0693) loss_zs_kd 0.1764 (0.1623) loss_oracle 0.0455 (0.0440) acc 56.2500 (71.6797) kd_loss 0.0365 (0.0416) lr 9.3721e-04 eta 0:15:27
epoch [28/50] batch [100/246] time 0.151 (0.165) data 0.000 (0.003) loss 1.1237 (1.1875) ce_loss 1.0068 (1.0637) teacher_loss 0.9971 (1.0614) loss_zs_kd 0.1547 (0.1627) loss_oracle 0.0493 (0.0447) acc 75.0000 (71.6562) kd_loss 0.0583 (0.0422) lr 9.3721e-04 eta 0:15:19
epoch [28/50] batch [120/246] time 0.399 (0.167) data 0.000 (0.002) loss 1.0360 (1.2077) ce_loss 0.9214 (1.0828) teacher_loss 0.9095 (1.0799) loss_zs_kd 0.1538 (0.1656) loss_oracle 0.0496 (0.0450) acc 78.1250 (71.0156) kd_loss 0.0595 (0.0422) lr 9.3721e-04 eta 0:15:25
epoch [28/50] batch [140/246] time 0.101 (0.169) data 0.000 (0.002) loss 0.8952 (1.2018) ce_loss 0.7666 (1.0754) teacher_loss 0.7510 (1.0726) loss_zs_kd 0.1617 (0.1674) loss_oracle 0.0633 (0.0455) acc 81.2500 (71.1830) kd_loss 0.0528 (0.0421) lr 9.3721e-04 eta 0:15:32
epoch [28/50] batch [160/246] time 0.172 (0.168) data 0.000 (0.002) loss 1.5265 (1.2042) ce_loss 1.3926 (1.0770) teacher_loss 1.3662 (1.0742) loss_zs_kd 0.2083 (0.1689) loss_oracle 0.0562 (0.0456) acc 65.6250 (70.9570) kd_loss 0.0429 (0.0415) lr 9.3721e-04 eta 0:15:23
epoch [28/50] batch [180/246] time 0.168 (0.167) data 0.000 (0.002) loss 1.1429 (1.2050) ce_loss 1.0127 (1.0777) teacher_loss 1.0085 (1.0749) loss_zs_kd 0.1883 (0.1695) loss_oracle 0.0403 (0.0454) acc 81.2500 (71.0764) kd_loss 0.0429 (0.0410) lr 9.3721e-04 eta 0:15:15
epoch [28/50] batch [200/246] time 0.169 (0.167) data 0.000 (0.002) loss 1.2843 (1.2024) ce_loss 1.1484 (1.0751) teacher_loss 1.1479 (1.0721) loss_zs_kd 0.1845 (0.1698) loss_oracle 0.0442 (0.0454) acc 62.5000 (71.0938) kd_loss 0.0445 (0.0402) lr 9.3721e-04 eta 0:15:09
epoch [28/50] batch [220/246] time 0.166 (0.166) data 0.000 (0.001) loss 1.0882 (1.2042) ce_loss 0.9683 (1.0766) teacher_loss 0.9663 (1.0735) loss_zs_kd 0.1606 (0.1709) loss_oracle 0.0415 (0.0452) acc 71.8750 (71.1648) kd_loss 0.0387 (0.0399) lr 9.3721e-04 eta 0:15:03
epoch [28/50] batch [240/246] time 0.166 (0.166) data 0.000 (0.001) loss 1.0571 (1.2110) ce_loss 0.9839 (1.0832) teacher_loss 0.9467 (1.0800) loss_zs_kd 0.1152 (0.1716) loss_oracle 0.0528 (0.0453) acc 71.8750 (70.8984) kd_loss 0.0309 (0.0396) lr 9.3721e-04 eta 0:14:58
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,843
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.3%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [29/50] batch [20/246] time 0.160 (0.178) data 0.000 (0.013) loss 1.1003 (1.2442) ce_loss 0.9741 (1.1189) teacher_loss 0.9672 (1.1119) loss_zs_kd 0.1757 (0.1750) loss_oracle 0.0453 (0.0448) acc 75.0000 (70.6250) kd_loss 0.0345 (0.0357) lr 8.7467e-04 eta 0:16:01
epoch [29/50] batch [40/246] time 0.179 (0.173) data 0.000 (0.007) loss 1.2126 (1.1864) ce_loss 1.0713 (1.0613) teacher_loss 1.0700 (1.0551) loss_zs_kd 0.1917 (0.1728) loss_oracle 0.0467 (0.0449) acc 71.8750 (72.2656) kd_loss 0.0392 (0.0356) lr 8.7467e-04 eta 0:15:31
epoch [29/50] batch [60/246] time 0.180 (0.172) data 0.001 (0.005) loss 2.0680 (1.1997) ce_loss 1.9414 (1.0743) teacher_loss 1.9412 (1.0694) loss_zs_kd 0.1764 (0.1721) loss_oracle 0.0386 (0.0443) acc 46.8750 (71.9792) kd_loss 0.0367 (0.0360) lr 8.7467e-04 eta 0:15:19
epoch [29/50] batch [80/246] time 0.177 (0.172) data 0.000 (0.004) loss 0.7951 (1.1952) ce_loss 0.6929 (1.0704) teacher_loss 0.6881 (1.0654) loss_zs_kd 0.1400 (0.1704) loss_oracle 0.0370 (0.0446) acc 75.0000 (71.9531) kd_loss 0.0227 (0.0360) lr 8.7467e-04 eta 0:15:15
epoch [29/50] batch [100/246] time 0.157 (0.171) data 0.000 (0.003) loss 1.2624 (1.2004) ce_loss 1.1680 (1.0759) teacher_loss 1.1635 (1.0710) loss_zs_kd 0.0974 (0.1697) loss_oracle 0.0502 (0.0445) acc 68.7500 (71.6562) kd_loss 0.0312 (0.0355) lr 8.7467e-04 eta 0:15:06
epoch [29/50] batch [120/246] time 0.158 (0.169) data 0.000 (0.002) loss 1.2594 (1.1949) ce_loss 1.0791 (1.0698) teacher_loss 1.0835 (1.0652) loss_zs_kd 0.2455 (0.1687) loss_oracle 0.0532 (0.0454) acc 75.0000 (71.8229) kd_loss 0.0361 (0.0359) lr 8.7467e-04 eta 0:14:53
epoch [29/50] batch [140/246] time 0.381 (0.175) data 0.000 (0.002) loss 1.5902 (1.1906) ce_loss 1.4697 (1.0645) teacher_loss 1.4631 (1.0597) loss_zs_kd 0.1579 (0.1691) loss_oracle 0.0482 (0.0463) acc 53.1250 (72.0089) kd_loss 0.0435 (0.0366) lr 8.7467e-04 eta 0:15:21
epoch [29/50] batch [160/246] time 0.147 (0.172) data 0.000 (0.002) loss 1.1296 (1.1898) ce_loss 1.0273 (1.0638) teacher_loss 1.0102 (1.0591) loss_zs_kd 0.1239 (0.1685) loss_oracle 0.0575 (0.0463) acc 75.0000 (72.0898) kd_loss 0.0487 (0.0368) lr 8.7467e-04 eta 0:15:02
epoch [29/50] batch [180/246] time 0.154 (0.171) data 0.000 (0.002) loss 1.8902 (1.2006) ce_loss 1.7432 (1.0747) teacher_loss 1.7369 (1.0700) loss_zs_kd 0.1649 (0.1680) loss_oracle 0.0708 (0.0466) acc 59.3750 (71.7882) kd_loss 0.0618 (0.0372) lr 8.7467e-04 eta 0:14:55
epoch [29/50] batch [200/246] time 0.146 (0.170) data 0.000 (0.002) loss 0.9045 (1.1938) ce_loss 0.7339 (1.0676) teacher_loss 0.7371 (1.0631) loss_zs_kd 0.2369 (0.1672) loss_oracle 0.0490 (0.0470) acc 81.2500 (71.9844) kd_loss 0.0345 (0.0377) lr 8.7467e-04 eta 0:14:44
epoch [29/50] batch [220/246] time 0.145 (0.168) data 0.000 (0.001) loss 1.1680 (1.1930) ce_loss 1.0273 (1.0664) teacher_loss 1.0311 (1.0619) loss_zs_kd 0.1808 (0.1675) loss_oracle 0.0465 (0.0473) acc 71.8750 (71.8892) kd_loss 0.0309 (0.0380) lr 8.7467e-04 eta 0:14:34
epoch [29/50] batch [240/246] time 0.142 (0.167) data 0.000 (0.001) loss 1.0958 (1.1847) ce_loss 1.0010 (1.0583) teacher_loss 0.9981 (1.0541) loss_zs_kd 0.1003 (0.1664) loss_oracle 0.0475 (0.0475) acc 78.1250 (72.0964) kd_loss 0.0448 (0.0384) lr 8.7467e-04 eta 0:14:25
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,855
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,953
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      85.3%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [30/50] batch [20/246] time 0.132 (0.250) data 0.001 (0.014) loss 1.0094 (1.2498) ce_loss 0.8618 (1.1190) teacher_loss 0.8607 (1.1101) loss_zs_kd 0.2050 (0.1790) loss_oracle 0.0462 (0.0502) acc 75.0000 (71.4062) kd_loss 0.0348 (0.0484) lr 8.1262e-04 eta 0:21:24
epoch [30/50] batch [40/246] time 0.181 (0.207) data 0.000 (0.007) loss 0.9853 (1.2091) ce_loss 0.8579 (1.0821) teacher_loss 0.8534 (1.0732) loss_zs_kd 0.1557 (0.1708) loss_oracle 0.0541 (0.0504) acc 71.8750 (71.4844) kd_loss 0.0541 (0.0475) lr 8.1262e-04 eta 0:17:42
epoch [30/50] batch [60/246] time 0.170 (0.194) data 0.001 (0.005) loss 1.1241 (1.2238) ce_loss 0.9863 (1.0944) teacher_loss 0.9803 (1.0867) loss_zs_kd 0.2063 (0.1758) loss_oracle 0.0407 (0.0493) acc 65.6250 (70.9896) kd_loss 0.0388 (0.0446) lr 8.1262e-04 eta 0:16:29
epoch [30/50] batch [80/246] time 0.154 (0.186) data 0.000 (0.004) loss 1.0149 (1.2167) ce_loss 0.8633 (1.0858) teacher_loss 0.8640 (1.0793) loss_zs_kd 0.2242 (0.1783) loss_oracle 0.0388 (0.0483) acc 71.8750 (71.2500) kd_loss 0.0374 (0.0428) lr 8.1262e-04 eta 0:15:43
epoch [30/50] batch [100/246] time 0.170 (0.181) data 0.000 (0.003) loss 0.7505 (1.2252) ce_loss 0.6099 (1.0937) teacher_loss 0.6110 (1.0880) loss_zs_kd 0.1624 (0.1778) loss_oracle 0.0584 (0.0484) acc 87.5000 (71.4062) kd_loss 0.0611 (0.0423) lr 8.1262e-04 eta 0:15:15
epoch [30/50] batch [120/246] time 0.181 (0.178) data 0.000 (0.003) loss 1.0049 (1.2410) ce_loss 0.8833 (1.1101) teacher_loss 0.8876 (1.1045) loss_zs_kd 0.1679 (0.1778) loss_oracle 0.0334 (0.0476) acc 78.1250 (71.1458) kd_loss 0.0267 (0.0414) lr 8.1262e-04 eta 0:14:58
epoch [30/50] batch [140/246] time 0.170 (0.176) data 0.000 (0.002) loss 0.9531 (1.2293) ce_loss 0.7822 (1.0994) teacher_loss 0.7704 (1.0939) loss_zs_kd 0.2565 (0.1768) loss_oracle 0.0545 (0.0470) acc 78.1250 (71.4509) kd_loss 0.0444 (0.0410) lr 8.1262e-04 eta 0:14:44
epoch [30/50] batch [160/246] time 0.405 (0.182) data 0.000 (0.002) loss 1.0915 (1.2232) ce_loss 0.9868 (1.0936) teacher_loss 0.9911 (1.0885) loss_zs_kd 0.1048 (0.1754) loss_oracle 0.0480 (0.0469) acc 71.8750 (71.7188) kd_loss 0.0513 (0.0413) lr 8.1262e-04 eta 0:15:08
epoch [30/50] batch [180/246] time 0.167 (0.181) data 0.000 (0.002) loss 0.7194 (1.2191) ce_loss 0.6143 (1.0902) teacher_loss 0.6155 (1.0854) loss_zs_kd 0.0995 (0.1739) loss_oracle 0.0542 (0.0468) acc 84.3750 (72.0139) kd_loss 0.0510 (0.0412) lr 8.1262e-04 eta 0:15:00
epoch [30/50] batch [200/246] time 0.156 (0.180) data 0.000 (0.002) loss 1.1844 (1.2144) ce_loss 1.0439 (1.0848) teacher_loss 1.0418 (1.0802) loss_zs_kd 0.1803 (0.1751) loss_oracle 0.0525 (0.0466) acc 78.1250 (72.1250) kd_loss 0.0433 (0.0412) lr 8.1262e-04 eta 0:14:53
epoch [30/50] batch [220/246] time 0.145 (0.179) data 0.000 (0.002) loss 1.3982 (1.2150) ce_loss 1.2930 (1.0866) teacher_loss 1.2863 (1.0816) loss_zs_kd 0.1515 (0.1738) loss_oracle 0.0362 (0.0465) acc 65.6250 (72.1023) kd_loss 0.0262 (0.0409) lr 8.1262e-04 eta 0:14:43
epoch [30/50] batch [240/246] time 0.164 (0.177) data 0.000 (0.001) loss 0.6961 (1.2125) ce_loss 0.5669 (1.0845) teacher_loss 0.5663 (1.0797) loss_zs_kd 0.1622 (0.1737) loss_oracle 0.0487 (0.0460) acc 87.5000 (72.1484) kd_loss 0.0408 (0.0404) lr 8.1262e-04 eta 0:14:31
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,857
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.3%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [31/50] batch [20/246] time 0.365 (0.220) data 0.000 (0.014) loss 0.9196 (1.1091) ce_loss 0.7930 (0.9812) teacher_loss 0.7925 (0.9791) loss_zs_kd 0.1595 (0.1717) loss_oracle 0.0473 (0.0441) acc 75.0000 (74.2188) kd_loss 0.0311 (0.0356) lr 7.5131e-04 eta 0:17:58
epoch [31/50] batch [40/246] time 0.185 (0.185) data 0.000 (0.007) loss 1.2586 (1.1761) ce_loss 1.1758 (1.0487) teacher_loss 1.1654 (1.0455) loss_zs_kd 0.1118 (0.1723) loss_oracle 0.0373 (0.0445) acc 71.8750 (72.2656) kd_loss 0.0204 (0.0344) lr 7.5131e-04 eta 0:15:01
epoch [31/50] batch [60/246] time 0.161 (0.180) data 0.001 (0.005) loss 1.2795 (1.1958) ce_loss 1.1113 (1.0685) teacher_loss 1.1149 (1.0654) loss_zs_kd 0.2284 (0.1711) loss_oracle 0.0504 (0.0448) acc 75.0000 (71.9792) kd_loss 0.0459 (0.0349) lr 7.5131e-04 eta 0:14:32
epoch [31/50] batch [80/246] time 0.172 (0.176) data 0.000 (0.004) loss 0.7019 (1.1883) ce_loss 0.5815 (1.0609) teacher_loss 0.5777 (1.0576) loss_zs_kd 0.1676 (0.1708) loss_oracle 0.0405 (0.0453) acc 90.6250 (72.1875) kd_loss 0.0259 (0.0349) lr 7.5131e-04 eta 0:14:13
epoch [31/50] batch [100/246] time 0.158 (0.174) data 0.000 (0.003) loss 0.8330 (1.1914) ce_loss 0.6987 (1.0621) teacher_loss 0.7002 (1.0594) loss_zs_kd 0.1801 (0.1738) loss_oracle 0.0428 (0.0451) acc 84.3750 (72.1875) kd_loss 0.0431 (0.0347) lr 7.5131e-04 eta 0:13:59
epoch [31/50] batch [120/246] time 0.171 (0.171) data 0.000 (0.003) loss 1.0394 (1.2038) ce_loss 0.9355 (1.0753) teacher_loss 0.9370 (1.0724) loss_zs_kd 0.1201 (0.1728) loss_oracle 0.0423 (0.0450) acc 65.6250 (71.7708) kd_loss 0.0459 (0.0349) lr 7.5131e-04 eta 0:13:41
epoch [31/50] batch [140/246] time 0.151 (0.169) data 0.000 (0.002) loss 1.5348 (1.2152) ce_loss 1.3633 (1.0860) teacher_loss 1.3566 (1.0835) loss_zs_kd 0.2479 (0.1732) loss_oracle 0.0542 (0.0451) acc 71.8750 (71.7634) kd_loss 0.0367 (0.0343) lr 7.5131e-04 eta 0:13:26
epoch [31/50] batch [160/246] time 0.146 (0.167) data 0.000 (0.002) loss 0.9381 (1.2025) ce_loss 0.7954 (1.0723) teacher_loss 0.7782 (1.0695) loss_zs_kd 0.2290 (0.1746) loss_oracle 0.0454 (0.0457) acc 81.2500 (72.0312) kd_loss 0.0344 (0.0340) lr 7.5131e-04 eta 0:13:14
epoch [31/50] batch [180/246] time 0.101 (0.165) data 0.000 (0.002) loss 1.4937 (1.1948) ce_loss 1.3799 (1.0641) teacher_loss 1.3763 (1.0616) loss_zs_kd 0.1338 (0.1747) loss_oracle 0.0505 (0.0459) acc 65.6250 (72.1354) kd_loss 0.0283 (0.0335) lr 7.5131e-04 eta 0:13:01
epoch [31/50] batch [200/246] time 0.088 (0.171) data 0.000 (0.002) loss 1.1985 (1.2000) ce_loss 1.0703 (1.0691) teacher_loss 1.0700 (1.0663) loss_zs_kd 0.1670 (0.1750) loss_oracle 0.0449 (0.0461) acc 71.8750 (71.9062) kd_loss 0.0323 (0.0333) lr 7.5131e-04 eta 0:13:26
epoch [31/50] batch [220/246] time 0.142 (0.169) data 0.000 (0.001) loss 1.0737 (1.2061) ce_loss 0.9116 (1.0752) teacher_loss 0.8923 (1.0724) loss_zs_kd 0.2447 (0.1744) loss_oracle 0.0591 (0.0464) acc 71.8750 (71.8466) kd_loss 0.0340 (0.0334) lr 7.5131e-04 eta 0:13:13
epoch [31/50] batch [240/246] time 0.172 (0.168) data 0.000 (0.001) loss 1.2595 (1.2046) ce_loss 1.1348 (1.0745) teacher_loss 1.1202 (1.0714) loss_zs_kd 0.1404 (0.1732) loss_oracle 0.0691 (0.0466) acc 65.6250 (71.8490) kd_loss 0.0466 (0.0336) lr 7.5131e-04 eta 0:13:05
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,848
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
******* Domain r best val acc:      85.3%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [32/50] batch [20/246] time 0.147 (0.174) data 0.000 (0.013) loss 0.9582 (1.1975) ce_loss 0.8281 (1.0683) teacher_loss 0.8356 (1.0647) loss_zs_kd 0.1402 (0.1683) loss_oracle 0.0524 (0.0487) acc 71.8750 (70.3125) kd_loss 0.0297 (0.0360) lr 6.9098e-04 eta 0:13:28
epoch [32/50] batch [40/246] time 0.159 (0.166) data 0.000 (0.007) loss 0.9797 (1.2242) ce_loss 0.8433 (1.0962) teacher_loss 0.8355 (1.0918) loss_zs_kd 0.1451 (0.1667) loss_oracle 0.0717 (0.0491) acc 78.1250 (70.7031) kd_loss 0.0575 (0.0374) lr 6.9098e-04 eta 0:12:47
epoch [32/50] batch [60/246] time 0.355 (0.180) data 0.001 (0.005) loss 1.1303 (1.2348) ce_loss 1.0273 (1.1076) teacher_loss 1.0226 (1.1038) loss_zs_kd 0.1293 (0.1670) loss_oracle 0.0430 (0.0475) acc 68.7500 (70.2604) kd_loss 0.0366 (0.0366) lr 6.9098e-04 eta 0:13:52
epoch [32/50] batch [80/246] time 0.153 (0.172) data 0.000 (0.003) loss 0.9615 (1.2115) ce_loss 0.8193 (1.0829) teacher_loss 0.8211 (1.0790) loss_zs_kd 0.2079 (0.1712) loss_oracle 0.0365 (0.0469) acc 78.1250 (71.3281) kd_loss 0.0335 (0.0366) lr 6.9098e-04 eta 0:13:09
epoch [32/50] batch [100/246] time 0.176 (0.171) data 0.000 (0.003) loss 1.2093 (1.2286) ce_loss 1.0713 (1.0998) teacher_loss 1.0711 (1.0956) loss_zs_kd 0.1502 (0.1714) loss_oracle 0.0631 (0.0473) acc 75.0000 (70.5938) kd_loss 0.0451 (0.0373) lr 6.9098e-04 eta 0:13:01
epoch [32/50] batch [120/246] time 0.164 (0.170) data 0.000 (0.002) loss 0.8924 (1.2278) ce_loss 0.7510 (1.0981) teacher_loss 0.7593 (1.0941) loss_zs_kd 0.1543 (0.1732) loss_oracle 0.0560 (0.0472) acc 81.2500 (70.4688) kd_loss 0.0427 (0.0373) lr 6.9098e-04 eta 0:12:55
epoch [32/50] batch [140/246] time 0.165 (0.169) data 0.000 (0.002) loss 1.4712 (1.2120) ce_loss 1.3330 (1.0828) teacher_loss 1.3317 (1.0786) loss_zs_kd 0.1909 (0.1721) loss_oracle 0.0441 (0.0474) acc 59.3750 (71.0714) kd_loss 0.0299 (0.0371) lr 6.9098e-04 eta 0:12:47
epoch [32/50] batch [160/246] time 0.174 (0.168) data 0.000 (0.002) loss 1.0533 (1.2186) ce_loss 0.9326 (1.0900) teacher_loss 0.9319 (1.0856) loss_zs_kd 0.1252 (0.1706) loss_oracle 0.0588 (0.0477) acc 81.2500 (71.0352) kd_loss 0.0488 (0.0375) lr 6.9098e-04 eta 0:12:40
epoch [32/50] batch [180/246] time 0.158 (0.168) data 0.000 (0.002) loss 1.1247 (1.2113) ce_loss 1.0029 (1.0830) teacher_loss 0.9731 (1.0787) loss_zs_kd 0.1876 (0.1693) loss_oracle 0.0578 (0.0479) acc 75.0000 (71.3194) kd_loss 0.0410 (0.0376) lr 6.9098e-04 eta 0:12:34
epoch [32/50] batch [200/246] time 0.090 (0.167) data 0.000 (0.002) loss 1.3348 (1.2122) ce_loss 1.1787 (1.0840) teacher_loss 1.1837 (1.0796) loss_zs_kd 0.2385 (0.1697) loss_oracle 0.0319 (0.0477) acc 68.7500 (71.3125) kd_loss 0.0308 (0.0377) lr 6.9098e-04 eta 0:12:28
epoch [32/50] batch [220/246] time 0.400 (0.172) data 0.000 (0.001) loss 1.1310 (1.2041) ce_loss 0.9541 (1.0758) teacher_loss 0.9465 (1.0714) loss_zs_kd 0.2310 (0.1708) loss_oracle 0.0690 (0.0473) acc 78.1250 (71.5767) kd_loss 0.0473 (0.0377) lr 6.9098e-04 eta 0:12:46
epoch [32/50] batch [240/246] time 0.148 (0.170) data 0.000 (0.001) loss 0.7566 (1.2086) ce_loss 0.6582 (1.0814) teacher_loss 0.6559 (1.0770) loss_zs_kd 0.1121 (0.1697) loss_oracle 0.0446 (0.0468) acc 84.3750 (71.3802) kd_loss 0.0383 (0.0375) lr 6.9098e-04 eta 0:12:35
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,847
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,949
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.5%
******* Domain r best val acc:      85.3%, epoch: 25 *******
******* Domain r best val test acc: 90.5%, epoch: 25 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [33/50] batch [20/246] time 0.155 (0.182) data 0.000 (0.017) loss 1.4603 (1.1793) ce_loss 1.3662 (1.0601) teacher_loss 1.3666 (1.0572) loss_zs_kd 0.1167 (0.1546) loss_oracle 0.0354 (0.0447) acc 62.5000 (72.5000) kd_loss 0.0279 (0.0355) lr 6.3188e-04 eta 0:13:22
epoch [33/50] batch [40/246] time 0.167 (0.175) data 0.000 (0.008) loss 0.7771 (1.2128) ce_loss 0.6719 (1.0899) teacher_loss 0.6697 (1.0875) loss_zs_kd 0.1424 (0.1627) loss_oracle 0.0363 (0.0439) acc 81.2500 (71.7969) kd_loss 0.0321 (0.0363) lr 6.3188e-04 eta 0:12:47
epoch [33/50] batch [60/246] time 0.132 (0.165) data 0.001 (0.006) loss 1.3729 (1.1957) ce_loss 1.2412 (1.0715) teacher_loss 1.2266 (1.0684) loss_zs_kd 0.1858 (0.1678) loss_oracle 0.0534 (0.0434) acc 71.8750 (72.1875) kd_loss 0.0501 (0.0369) lr 6.3188e-04 eta 0:12:02
epoch [33/50] batch [80/246] time 0.083 (0.178) data 0.000 (0.004) loss 0.7986 (1.1830) ce_loss 0.6504 (1.0589) teacher_loss 0.6488 (1.0555) loss_zs_kd 0.1956 (0.1674) loss_oracle 0.0520 (0.0438) acc 81.2500 (72.2656) kd_loss 0.0377 (0.0364) lr 6.3188e-04 eta 0:12:55
epoch [33/50] batch [100/246] time 0.151 (0.173) data 0.001 (0.003) loss 1.1477 (1.1805) ce_loss 0.9829 (1.0555) teacher_loss 0.9729 (1.0522) loss_zs_kd 0.2439 (0.1691) loss_oracle 0.0528 (0.0437) acc 75.0000 (72.3750) kd_loss 0.0537 (0.0370) lr 6.3188e-04 eta 0:12:30
epoch [33/50] batch [120/246] time 0.150 (0.171) data 0.000 (0.003) loss 1.8225 (1.1802) ce_loss 1.7207 (1.0561) teacher_loss 1.7169 (1.0523) loss_zs_kd 0.1471 (0.1683) loss_oracle 0.0320 (0.0437) acc 62.5000 (72.1875) kd_loss 0.0296 (0.0370) lr 6.3188e-04 eta 0:12:16
epoch [33/50] batch [140/246] time 0.171 (0.169) data 0.000 (0.003) loss 1.5522 (1.1894) ce_loss 1.4131 (1.0651) teacher_loss 1.4016 (1.0608) loss_zs_kd 0.1943 (0.1695) loss_oracle 0.0534 (0.0439) acc 65.6250 (72.0759) kd_loss 0.0545 (0.0369) lr 6.3188e-04 eta 0:12:05
epoch [33/50] batch [160/246] time 0.152 (0.168) data 0.000 (0.002) loss 1.0178 (1.1701) ce_loss 0.8823 (1.0456) teacher_loss 0.8705 (1.0414) loss_zs_kd 0.2031 (0.1698) loss_oracle 0.0458 (0.0438) acc 78.1250 (72.3633) kd_loss 0.0264 (0.0369) lr 6.3188e-04 eta 0:11:57
epoch [33/50] batch [180/246] time 0.156 (0.167) data 0.000 (0.002) loss 1.3641 (1.1776) ce_loss 1.2246 (1.0530) teacher_loss 1.2334 (1.0491) loss_zs_kd 0.1839 (0.1699) loss_oracle 0.0387 (0.0435) acc 68.7500 (72.1875) kd_loss 0.0323 (0.0363) lr 6.3188e-04 eta 0:11:49
epoch [33/50] batch [200/246] time 0.169 (0.166) data 0.000 (0.002) loss 1.0457 (1.1835) ce_loss 0.9399 (1.0596) teacher_loss 0.9282 (1.0553) loss_zs_kd 0.1321 (0.1692) loss_oracle 0.0514 (0.0436) acc 71.8750 (72.1094) kd_loss 0.0382 (0.0363) lr 6.3188e-04 eta 0:11:41
epoch [33/50] batch [220/246] time 0.086 (0.165) data 0.000 (0.002) loss 1.3864 (1.1827) ce_loss 1.2598 (1.0595) teacher_loss 1.2369 (1.0553) loss_zs_kd 0.1965 (0.1683) loss_oracle 0.0513 (0.0433) acc 65.6250 (71.9460) kd_loss 0.0387 (0.0360) lr 6.3188e-04 eta 0:11:32
epoch [33/50] batch [240/246] time 0.175 (0.169) data 0.000 (0.002) loss 1.2787 (1.1774) ce_loss 1.0840 (1.0533) teacher_loss 1.0832 (1.0494) loss_zs_kd 0.2675 (0.1694) loss_oracle 0.0618 (0.0433) acc 81.2500 (72.0052) kd_loss 0.0468 (0.0359) lr 6.3188e-04 eta 0:11:48
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,864
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.8%, epoch: 33 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [34/50] batch [20/246] time 0.148 (0.172) data 0.000 (0.014) loss 0.8791 (1.0986) ce_loss 0.7739 (0.9646) teacher_loss 0.7748 (0.9638) loss_zs_kd 0.1438 (0.1770) loss_oracle 0.0324 (0.0463) acc 78.1250 (74.2188) kd_loss 0.0236 (0.0387) lr 5.7422e-04 eta 0:11:57
epoch [34/50] batch [40/246] time 0.168 (0.164) data 0.000 (0.007) loss 1.2350 (1.1750) ce_loss 1.1230 (1.0408) teacher_loss 1.1253 (1.0389) loss_zs_kd 0.1520 (0.1811) loss_oracle 0.0337 (0.0455) acc 75.0000 (72.4219) kd_loss 0.0292 (0.0392) lr 5.7422e-04 eta 0:11:20
epoch [34/50] batch [60/246] time 0.178 (0.162) data 0.000 (0.005) loss 0.7607 (1.1324) ce_loss 0.6201 (0.9995) teacher_loss 0.6210 (0.9974) loss_zs_kd 0.1835 (0.1778) loss_oracle 0.0479 (0.0461) acc 87.5000 (73.8542) kd_loss 0.0423 (0.0402) lr 5.7422e-04 eta 0:11:08
epoch [34/50] batch [80/246] time 0.148 (0.161) data 0.000 (0.004) loss 1.1685 (1.1495) ce_loss 1.0410 (1.0186) teacher_loss 1.0361 (1.0158) loss_zs_kd 0.1457 (0.1738) loss_oracle 0.0595 (0.0467) acc 68.7500 (73.2812) kd_loss 0.0611 (0.0409) lr 5.7422e-04 eta 0:10:58
epoch [34/50] batch [100/246] time 0.403 (0.169) data 0.000 (0.003) loss 1.3406 (1.1618) ce_loss 1.1943 (1.0300) teacher_loss 1.1844 (1.0264) loss_zs_kd 0.2113 (0.1771) loss_oracle 0.0506 (0.0469) acc 68.7500 (72.5000) kd_loss 0.0560 (0.0418) lr 5.7422e-04 eta 0:11:28
epoch [34/50] batch [120/246] time 0.145 (0.167) data 0.000 (0.003) loss 1.1278 (1.1405) ce_loss 1.0107 (1.0099) teacher_loss 1.0100 (1.0065) loss_zs_kd 0.1335 (0.1747) loss_oracle 0.0510 (0.0467) acc 68.7500 (72.9948) kd_loss 0.0488 (0.0416) lr 5.7422e-04 eta 0:11:17
epoch [34/50] batch [140/246] time 0.151 (0.166) data 0.000 (0.002) loss 1.2164 (1.1539) ce_loss 1.0986 (1.0233) teacher_loss 1.1028 (1.0196) loss_zs_kd 0.1441 (0.1758) loss_oracle 0.0415 (0.0464) acc 75.0000 (72.8795) kd_loss 0.0300 (0.0412) lr 5.7422e-04 eta 0:11:11
epoch [34/50] batch [160/246] time 0.176 (0.165) data 0.000 (0.002) loss 0.8054 (1.1599) ce_loss 0.6680 (1.0292) teacher_loss 0.6728 (1.0255) loss_zs_kd 0.1832 (0.1764) loss_oracle 0.0409 (0.0463) acc 78.1250 (72.7930) kd_loss 0.0278 (0.0409) lr 5.7422e-04 eta 0:11:04
epoch [34/50] batch [180/246] time 0.172 (0.165) data 0.000 (0.002) loss 0.8530 (1.1638) ce_loss 0.7148 (1.0341) teacher_loss 0.7112 (1.0302) loss_zs_kd 0.1641 (0.1750) loss_oracle 0.0597 (0.0461) acc 81.2500 (72.6389) kd_loss 0.0547 (0.0406) lr 5.7422e-04 eta 0:10:59
epoch [34/50] batch [200/246] time 0.155 (0.164) data 0.000 (0.002) loss 1.0717 (1.1764) ce_loss 0.9795 (1.0463) teacher_loss 0.9738 (1.0421) loss_zs_kd 0.1158 (0.1761) loss_oracle 0.0400 (0.0463) acc 71.8750 (72.2188) kd_loss 0.0339 (0.0407) lr 5.7422e-04 eta 0:10:53
epoch [34/50] batch [220/246] time 0.150 (0.164) data 0.000 (0.001) loss 1.1981 (1.1770) ce_loss 1.0918 (1.0471) teacher_loss 1.0764 (1.0431) loss_zs_kd 0.1069 (0.1752) loss_oracle 0.0682 (0.0463) acc 68.7500 (72.2443) kd_loss 0.0648 (0.0404) lr 5.7422e-04 eta 0:10:49
epoch [34/50] batch [240/246] time 0.170 (0.163) data 0.000 (0.001) loss 1.4003 (1.1792) ce_loss 1.2842 (1.0496) teacher_loss 1.2774 (1.0458) loss_zs_kd 0.1612 (0.1747) loss_oracle 0.0423 (0.0461) acc 59.3750 (72.1094) kd_loss 0.0335 (0.0401) lr 5.7422e-04 eta 0:10:44
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,859
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.8%, epoch: 33 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [35/50] batch [20/246] time 0.163 (0.172) data 0.000 (0.013) loss 1.5151 (1.1307) ce_loss 1.3672 (1.0050) teacher_loss 1.3678 (1.0029) loss_zs_kd 0.1851 (0.1702) loss_oracle 0.0547 (0.0427) acc 59.3750 (73.9062) kd_loss 0.0425 (0.0326) lr 5.1825e-04 eta 0:11:15
epoch [35/50] batch [40/246] time 0.155 (0.164) data 0.000 (0.007) loss 1.3990 (1.1867) ce_loss 1.2656 (1.0589) teacher_loss 1.2408 (1.0555) loss_zs_kd 0.2006 (0.1745) loss_oracle 0.0579 (0.0440) acc 68.7500 (72.6562) kd_loss 0.0432 (0.0345) lr 5.1825e-04 eta 0:10:39
epoch [35/50] batch [60/246] time 0.150 (0.161) data 0.000 (0.004) loss 0.9602 (1.1828) ce_loss 0.8145 (1.0520) teacher_loss 0.8197 (1.0490) loss_zs_kd 0.1947 (0.1795) loss_oracle 0.0432 (0.0440) acc 78.1250 (72.3438) kd_loss 0.0351 (0.0359) lr 5.1825e-04 eta 0:10:25
epoch [35/50] batch [80/246] time 0.165 (0.161) data 0.000 (0.003) loss 2.0897 (1.1856) ce_loss 1.9404 (1.0557) teacher_loss 1.9220 (1.0523) loss_zs_kd 0.1871 (0.1763) loss_oracle 0.0742 (0.0452) acc 53.1250 (72.2266) kd_loss 0.0537 (0.0377) lr 5.1825e-04 eta 0:10:21
epoch [35/50] batch [100/246] time 0.165 (0.161) data 0.000 (0.003) loss 1.4039 (1.1813) ce_loss 1.2852 (1.0532) teacher_loss 1.2883 (1.0495) loss_zs_kd 0.1459 (0.1735) loss_oracle 0.0427 (0.0451) acc 56.2500 (72.3125) kd_loss 0.0417 (0.0388) lr 5.1825e-04 eta 0:10:17
epoch [35/50] batch [120/246] time 0.400 (0.164) data 0.000 (0.002) loss 1.0291 (1.1806) ce_loss 0.9204 (1.0513) teacher_loss 0.9242 (1.0480) loss_zs_kd 0.1474 (0.1741) loss_oracle 0.0313 (0.0456) acc 75.0000 (72.6042) kd_loss 0.0247 (0.0394) lr 5.1825e-04 eta 0:10:24
epoch [35/50] batch [140/246] time 0.171 (0.169) data 0.000 (0.002) loss 0.9728 (1.1819) ce_loss 0.8530 (1.0533) teacher_loss 0.8498 (1.0500) loss_zs_kd 0.1509 (0.1727) loss_oracle 0.0475 (0.0455) acc 75.0000 (72.5000) kd_loss 0.0410 (0.0396) lr 5.1825e-04 eta 0:10:42
epoch [35/50] batch [160/246] time 0.166 (0.169) data 0.000 (0.002) loss 0.6924 (1.1801) ce_loss 0.5806 (1.0519) teacher_loss 0.5853 (1.0492) loss_zs_kd 0.1527 (0.1721) loss_oracle 0.0308 (0.0449) acc 87.5000 (72.5781) kd_loss 0.0316 (0.0398) lr 5.1825e-04 eta 0:10:36
epoch [35/50] batch [180/246] time 0.174 (0.168) data 0.000 (0.002) loss 1.6023 (1.1766) ce_loss 1.4736 (1.0488) teacher_loss 1.4774 (1.0462) loss_zs_kd 0.1624 (0.1718) loss_oracle 0.0437 (0.0445) acc 71.8750 (72.7083) kd_loss 0.0481 (0.0396) lr 5.1825e-04 eta 0:10:31
epoch [35/50] batch [200/246] time 0.167 (0.167) data 0.000 (0.001) loss 1.0801 (1.1785) ce_loss 0.9399 (1.0510) teacher_loss 0.9392 (1.0485) loss_zs_kd 0.1842 (0.1712) loss_oracle 0.0488 (0.0445) acc 78.1250 (72.4844) kd_loss 0.0453 (0.0395) lr 5.1825e-04 eta 0:10:25
epoch [35/50] batch [220/246] time 0.154 (0.167) data 0.000 (0.001) loss 1.5253 (1.1843) ce_loss 1.3926 (1.0578) teacher_loss 1.3865 (1.0553) loss_zs_kd 0.1799 (0.1697) loss_oracle 0.0489 (0.0442) acc 59.3750 (72.2727) kd_loss 0.0410 (0.0390) lr 5.1825e-04 eta 0:10:19
epoch [35/50] batch [240/246] time 0.169 (0.166) data 0.000 (0.001) loss 1.1439 (1.1885) ce_loss 0.9985 (1.0612) teacher_loss 0.9849 (1.0583) loss_zs_kd 0.2054 (0.1712) loss_oracle 0.0564 (0.0446) acc 71.8750 (72.2135) kd_loss 0.0435 (0.0390) lr 5.1825e-04 eta 0:10:14
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,862
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.8%, epoch: 33 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [36/50] batch [20/246] time 0.151 (0.179) data 0.000 (0.015) loss 1.2967 (1.2213) ce_loss 1.1367 (1.0982) teacher_loss 1.1395 (1.0933) loss_zs_kd 0.2218 (0.1625) loss_oracle 0.0463 (0.0468) acc 68.7500 (70.3125) kd_loss 0.0427 (0.0398) lr 4.6417e-04 eta 0:10:56
epoch [36/50] batch [40/246] time 0.150 (0.170) data 0.000 (0.008) loss 1.5893 (1.1954) ce_loss 1.4746 (1.0680) teacher_loss 1.4701 (1.0633) loss_zs_kd 0.1715 (0.1715) loss_oracle 0.0334 (0.0463) acc 53.1250 (71.1719) kd_loss 0.0343 (0.0397) lr 4.6417e-04 eta 0:10:21
epoch [36/50] batch [60/246] time 0.160 (0.168) data 0.000 (0.005) loss 1.0484 (1.2043) ce_loss 0.9058 (1.0752) teacher_loss 0.9061 (1.0692) loss_zs_kd 0.2084 (0.1764) loss_oracle 0.0381 (0.0469) acc 75.0000 (70.9375) kd_loss 0.0323 (0.0391) lr 4.6417e-04 eta 0:10:10
epoch [36/50] batch [80/246] time 0.159 (0.168) data 0.000 (0.004) loss 1.3376 (1.2266) ce_loss 1.2295 (1.0961) teacher_loss 1.2271 (1.0898) loss_zs_kd 0.1309 (0.1793) loss_oracle 0.0450 (0.0472) acc 62.5000 (70.4297) kd_loss 0.0347 (0.0388) lr 4.6417e-04 eta 0:10:07
epoch [36/50] batch [100/246] time 0.162 (0.168) data 0.000 (0.003) loss 1.5381 (1.2197) ce_loss 1.4111 (1.0881) teacher_loss 1.3920 (1.0825) loss_zs_kd 0.2011 (0.1795) loss_oracle 0.0456 (0.0474) acc 62.5000 (70.6875) kd_loss 0.0311 (0.0382) lr 4.6417e-04 eta 0:10:03
epoch [36/50] batch [120/246] time 0.143 (0.167) data 0.000 (0.003) loss 0.8650 (1.2139) ce_loss 0.7524 (1.0816) teacher_loss 0.7518 (1.0760) loss_zs_kd 0.1548 (0.1801) loss_oracle 0.0359 (0.0478) acc 84.3750 (71.1458) kd_loss 0.0254 (0.0383) lr 4.6417e-04 eta 0:09:57
epoch [36/50] batch [140/246] time 0.409 (0.175) data 0.000 (0.002) loss 1.2464 (1.2066) ce_loss 1.1650 (1.0758) teacher_loss 1.1620 (1.0708) loss_zs_kd 0.0984 (0.1771) loss_oracle 0.0352 (0.0473) acc 68.7500 (71.4509) kd_loss 0.0349 (0.0381) lr 4.6417e-04 eta 0:10:19
epoch [36/50] batch [160/246] time 0.111 (0.168) data 0.000 (0.002) loss 0.6359 (1.1918) ce_loss 0.4819 (1.0619) teacher_loss 0.4828 (1.0570) loss_zs_kd 0.2219 (0.1754) loss_oracle 0.0421 (0.0471) acc 87.5000 (71.7578) kd_loss 0.0301 (0.0381) lr 4.6417e-04 eta 0:09:52
epoch [36/50] batch [180/246] time 0.109 (0.161) data 0.000 (0.002) loss 1.0348 (1.1889) ce_loss 0.9214 (1.0589) teacher_loss 0.9167 (1.0539) loss_zs_kd 0.1374 (0.1764) loss_oracle 0.0494 (0.0468) acc 71.8750 (71.9618) kd_loss 0.0464 (0.0376) lr 4.6417e-04 eta 0:09:24
epoch [36/50] batch [200/246] time 0.114 (0.155) data 0.000 (0.002) loss 1.3512 (1.1964) ce_loss 1.2100 (1.0669) teacher_loss 1.2093 (1.0618) loss_zs_kd 0.1773 (0.1762) loss_oracle 0.0532 (0.0465) acc 65.6250 (71.7344) kd_loss 0.0381 (0.0375) lr 4.6417e-04 eta 0:09:01
epoch [36/50] batch [220/246] time 0.193 (0.151) data 0.000 (0.002) loss 0.7541 (1.1900) ce_loss 0.6577 (1.0610) teacher_loss 0.6585 (1.0561) loss_zs_kd 0.1075 (0.1750) loss_oracle 0.0419 (0.0464) acc 87.5000 (72.0312) kd_loss 0.0278 (0.0369) lr 4.6417e-04 eta 0:08:44
epoch [36/50] batch [240/246] time 0.155 (0.153) data 0.000 (0.002) loss 1.2161 (1.1791) ce_loss 1.0576 (1.0506) teacher_loss 1.0623 (1.0457) loss_zs_kd 0.2100 (0.1742) loss_oracle 0.0488 (0.0463) acc 75.0000 (72.3958) kd_loss 0.0375 (0.0365) lr 4.6417e-04 eta 0:08:47
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,864
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,961
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.8%, epoch: 33 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [37/50] batch [20/246] time 0.154 (0.178) data 0.000 (0.013) loss 1.3432 (1.2516) ce_loss 1.2500 (1.1221) teacher_loss 1.2357 (1.1167) loss_zs_kd 0.1231 (0.1749) loss_oracle 0.0460 (0.0475) acc 65.6250 (71.0938) kd_loss 0.0423 (0.0330) lr 4.1221e-04 eta 0:10:09
epoch [37/50] batch [40/246] time 0.125 (0.160) data 0.000 (0.007) loss 1.5735 (1.2142) ce_loss 1.4717 (1.0845) teacher_loss 1.4752 (1.0808) loss_zs_kd 0.1327 (0.1723) loss_oracle 0.0320 (0.0473) acc 65.6250 (71.2500) kd_loss 0.0207 (0.0326) lr 4.1221e-04 eta 0:09:04
epoch [37/50] batch [60/246] time 0.085 (0.162) data 0.000 (0.005) loss 0.8719 (1.1990) ce_loss 0.7354 (1.0679) teacher_loss 0.7364 (1.0644) loss_zs_kd 0.1892 (0.1735) loss_oracle 0.0409 (0.0478) acc 68.7500 (71.9271) kd_loss 0.0470 (0.0351) lr 4.1221e-04 eta 0:09:09
epoch [37/50] batch [80/246] time 0.148 (0.169) data 0.000 (0.004) loss 1.0191 (1.1833) ce_loss 0.8872 (1.0536) teacher_loss 0.8861 (1.0501) loss_zs_kd 0.1800 (0.1722) loss_oracle 0.0430 (0.0470) acc 75.0000 (71.9141) kd_loss 0.0298 (0.0355) lr 4.1221e-04 eta 0:09:27
epoch [37/50] batch [100/246] time 0.168 (0.167) data 0.000 (0.003) loss 1.6958 (1.1838) ce_loss 1.5889 (1.0550) teacher_loss 1.5929 (1.0512) loss_zs_kd 0.1455 (0.1719) loss_oracle 0.0302 (0.0467) acc 56.2500 (71.7812) kd_loss 0.0190 (0.0345) lr 4.1221e-04 eta 0:09:17
epoch [37/50] batch [120/246] time 0.147 (0.166) data 0.000 (0.002) loss 1.3257 (1.1924) ce_loss 1.2139 (1.0635) teacher_loss 1.2012 (1.0593) loss_zs_kd 0.1569 (0.1732) loss_oracle 0.0461 (0.0466) acc 65.6250 (71.6406) kd_loss 0.0358 (0.0350) lr 4.1221e-04 eta 0:09:10
epoch [37/50] batch [140/246] time 0.142 (0.164) data 0.000 (0.002) loss 0.9342 (1.1976) ce_loss 0.7920 (1.0682) teacher_loss 0.7847 (1.0642) loss_zs_kd 0.1927 (0.1731) loss_oracle 0.0532 (0.0469) acc 81.2500 (71.7188) kd_loss 0.0369 (0.0349) lr 4.1221e-04 eta 0:09:03
epoch [37/50] batch [160/246] time 0.150 (0.163) data 0.000 (0.002) loss 1.3519 (1.1850) ce_loss 1.2090 (1.0563) teacher_loss 1.2105 (1.0524) loss_zs_kd 0.1768 (0.1717) loss_oracle 0.0530 (0.0468) acc 71.8750 (72.1875) kd_loss 0.0371 (0.0349) lr 4.1221e-04 eta 0:08:55
epoch [37/50] batch [180/246] time 0.153 (0.162) data 0.000 (0.002) loss 1.1880 (1.1830) ce_loss 1.0713 (1.0559) teacher_loss 1.0732 (1.0516) loss_zs_kd 0.1441 (0.1695) loss_oracle 0.0428 (0.0467) acc 65.6250 (72.0833) kd_loss 0.0372 (0.0348) lr 4.1221e-04 eta 0:08:49
epoch [37/50] batch [200/246] time 0.101 (0.160) data 0.000 (0.002) loss 0.9769 (1.1803) ce_loss 0.8633 (1.0529) teacher_loss 0.8676 (1.0487) loss_zs_kd 0.1303 (0.1703) loss_oracle 0.0442 (0.0465) acc 78.1250 (72.0625) kd_loss 0.0325 (0.0346) lr 4.1221e-04 eta 0:08:40
epoch [37/50] batch [220/246] time 0.204 (0.162) data 0.000 (0.001) loss 1.7396 (1.1837) ce_loss 1.5918 (1.0563) teacher_loss 1.5855 (1.0521) loss_zs_kd 0.1923 (0.1699) loss_oracle 0.0579 (0.0467) acc 65.6250 (72.0028) kd_loss 0.0551 (0.0351) lr 4.1221e-04 eta 0:08:40
epoch [37/50] batch [240/246] time 0.145 (0.165) data 0.000 (0.001) loss 1.1135 (1.1824) ce_loss 1.0137 (1.0549) teacher_loss 1.0129 (1.0506) loss_zs_kd 0.1297 (0.1695) loss_oracle 0.0357 (0.0470) acc 71.8750 (72.1224) kd_loss 0.0253 (0.0357) lr 4.1221e-04 eta 0:08:48
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,862
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.8%, epoch: 33 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [38/50] batch [20/246] time 0.172 (0.172) data 0.000 (0.012) loss 1.3057 (1.2790) ce_loss 1.1807 (1.1497) teacher_loss 1.1761 (1.1440) loss_zs_kd 0.1411 (0.1784) loss_oracle 0.0591 (0.0458) acc 68.7500 (70.9375) kd_loss 0.0486 (0.0395) lr 3.6258e-04 eta 0:09:06
epoch [38/50] batch [40/246] time 0.146 (0.163) data 0.000 (0.006) loss 0.9770 (1.2736) ce_loss 0.8174 (1.1416) teacher_loss 0.8202 (1.1347) loss_zs_kd 0.1957 (0.1828) loss_oracle 0.0590 (0.0474) acc 71.8750 (70.7812) kd_loss 0.0497 (0.0415) lr 3.6258e-04 eta 0:08:34
epoch [38/50] batch [60/246] time 0.104 (0.161) data 0.001 (0.004) loss 1.4581 (1.2404) ce_loss 1.3398 (1.1078) teacher_loss 1.3382 (1.1017) loss_zs_kd 0.1401 (0.1804) loss_oracle 0.0498 (0.0485) acc 62.5000 (71.6667) kd_loss 0.0361 (0.0424) lr 3.6258e-04 eta 0:08:23
epoch [38/50] batch [80/246] time 0.401 (0.176) data 0.000 (0.003) loss 1.5264 (1.2295) ce_loss 1.3916 (1.0976) teacher_loss 1.3750 (1.0922) loss_zs_kd 0.1785 (0.1789) loss_oracle 0.0621 (0.0478) acc 65.6250 (71.4844) kd_loss 0.0548 (0.0423) lr 3.6258e-04 eta 0:09:09
epoch [38/50] batch [100/246] time 0.145 (0.173) data 0.000 (0.003) loss 1.7030 (1.2284) ce_loss 1.5820 (1.0974) teacher_loss 1.5840 (1.0924) loss_zs_kd 0.1470 (0.1765) loss_oracle 0.0455 (0.0478) acc 62.5000 (71.4062) kd_loss 0.0398 (0.0417) lr 3.6258e-04 eta 0:08:56
epoch [38/50] batch [120/246] time 0.164 (0.170) data 0.000 (0.002) loss 0.9992 (1.2223) ce_loss 0.8823 (1.0926) teacher_loss 0.8753 (1.0878) loss_zs_kd 0.1618 (0.1735) loss_oracle 0.0430 (0.0478) acc 75.0000 (71.4062) kd_loss 0.0400 (0.0412) lr 3.6258e-04 eta 0:08:43
epoch [38/50] batch [140/246] time 0.181 (0.170) data 0.000 (0.002) loss 0.8694 (1.2066) ce_loss 0.7627 (1.0766) teacher_loss 0.7626 (1.0719) loss_zs_kd 0.1281 (0.1728) loss_oracle 0.0428 (0.0483) acc 75.0000 (71.7411) kd_loss 0.0392 (0.0416) lr 3.6258e-04 eta 0:08:39
epoch [38/50] batch [160/246] time 0.171 (0.170) data 0.001 (0.002) loss 0.9642 (1.2119) ce_loss 0.8374 (1.0826) teacher_loss 0.8296 (1.0777) loss_zs_kd 0.1605 (0.1718) loss_oracle 0.0544 (0.0483) acc 75.0000 (71.4844) kd_loss 0.0377 (0.0415) lr 3.6258e-04 eta 0:08:37
epoch [38/50] batch [180/246] time 0.160 (0.170) data 0.000 (0.002) loss 0.9900 (1.2069) ce_loss 0.8540 (1.0767) teacher_loss 0.8613 (1.0717) loss_zs_kd 0.1829 (0.1735) loss_oracle 0.0374 (0.0484) acc 78.1250 (71.6493) kd_loss 0.0296 (0.0415) lr 3.6258e-04 eta 0:08:33
epoch [38/50] batch [200/246] time 0.174 (0.170) data 0.001 (0.001) loss 1.0608 (1.2010) ce_loss 0.9243 (1.0716) teacher_loss 0.9172 (1.0666) loss_zs_kd 0.1823 (0.1724) loss_oracle 0.0525 (0.0482) acc 71.8750 (71.7344) kd_loss 0.0401 (0.0412) lr 3.6258e-04 eta 0:08:30
epoch [38/50] batch [220/246] time 0.088 (0.173) data 0.000 (0.001) loss 1.0000 (1.2001) ce_loss 0.8799 (1.0713) teacher_loss 0.8846 (1.0663) loss_zs_kd 0.1503 (0.1719) loss_oracle 0.0403 (0.0478) acc 78.1250 (71.7898) kd_loss 0.0290 (0.0408) lr 3.6258e-04 eta 0:08:33
epoch [38/50] batch [240/246] time 0.168 (0.173) data 0.000 (0.001) loss 1.4672 (1.1999) ce_loss 1.3145 (1.0705) teacher_loss 1.3104 (1.0656) loss_zs_kd 0.2296 (0.1728) loss_oracle 0.0420 (0.0479) acc 62.5000 (71.7578) kd_loss 0.0319 (0.0409) lr 3.6258e-04 eta 0:08:31
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,862
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.8%, epoch: 33 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [39/50] batch [20/246] time 0.154 (0.176) data 0.000 (0.015) loss 0.8433 (1.1609) ce_loss 0.7480 (1.0270) teacher_loss 0.7366 (1.0209) loss_zs_kd 0.1165 (0.1796) loss_oracle 0.0484 (0.0501) acc 87.5000 (72.8125) kd_loss 0.0403 (0.0392) lr 3.1545e-04 eta 0:08:35
epoch [39/50] batch [40/246] time 0.169 (0.166) data 0.000 (0.007) loss 0.7933 (1.1636) ce_loss 0.6763 (1.0295) teacher_loss 0.6752 (1.0227) loss_zs_kd 0.1255 (0.1784) loss_oracle 0.0554 (0.0517) acc 81.2500 (72.5000) kd_loss 0.0340 (0.0420) lr 3.1545e-04 eta 0:08:03
epoch [39/50] batch [60/246] time 0.169 (0.163) data 0.001 (0.005) loss 1.0623 (1.1729) ce_loss 0.9531 (1.0396) teacher_loss 0.9390 (1.0332) loss_zs_kd 0.1449 (0.1753) loss_oracle 0.0509 (0.0521) acc 78.1250 (71.9792) kd_loss 0.0405 (0.0435) lr 3.1545e-04 eta 0:07:50
epoch [39/50] batch [80/246] time 0.346 (0.166) data 0.000 (0.004) loss 1.5724 (1.1765) ce_loss 1.4521 (1.0443) teacher_loss 1.4528 (1.0380) loss_zs_kd 0.1452 (0.1729) loss_oracle 0.0470 (0.0520) acc 65.6250 (71.9922) kd_loss 0.0400 (0.0430) lr 3.1545e-04 eta 0:07:57
epoch [39/50] batch [100/246] time 0.085 (0.174) data 0.000 (0.003) loss 1.3228 (1.1923) ce_loss 1.1514 (1.0596) teacher_loss 1.1405 (1.0535) loss_zs_kd 0.2513 (0.1749) loss_oracle 0.0566 (0.0514) acc 65.6250 (71.4688) kd_loss 0.0540 (0.0425) lr 3.1545e-04 eta 0:08:16
epoch [39/50] batch [120/246] time 0.167 (0.169) data 0.000 (0.003) loss 1.1236 (1.1893) ce_loss 0.9961 (1.0548) teacher_loss 0.9937 (1.0484) loss_zs_kd 0.1485 (0.1785) loss_oracle 0.0557 (0.0517) acc 71.8750 (72.0312) kd_loss 0.0414 (0.0426) lr 3.1545e-04 eta 0:07:59
epoch [39/50] batch [140/246] time 0.163 (0.167) data 0.000 (0.002) loss 1.8027 (1.2114) ce_loss 1.6484 (1.0760) teacher_loss 1.6526 (1.0698) loss_zs_kd 0.2050 (0.1805) loss_oracle 0.0476 (0.0514) acc 65.6250 (71.5848) kd_loss 0.0574 (0.0429) lr 3.1545e-04 eta 0:07:50
epoch [39/50] batch [160/246] time 0.165 (0.166) data 0.000 (0.002) loss 1.1707 (1.2136) ce_loss 1.0254 (1.0779) teacher_loss 1.0153 (1.0720) loss_zs_kd 0.1777 (0.1807) loss_oracle 0.0665 (0.0513) acc 78.1250 (71.5039) kd_loss 0.0747 (0.0433) lr 3.1545e-04 eta 0:07:43
epoch [39/50] batch [180/246] time 0.151 (0.165) data 0.000 (0.002) loss 1.0439 (1.2047) ce_loss 0.8711 (1.0694) teacher_loss 0.8633 (1.0637) loss_zs_kd 0.2398 (0.1797) loss_oracle 0.0608 (0.0511) acc 75.0000 (71.7361) kd_loss 0.0597 (0.0435) lr 3.1545e-04 eta 0:07:36
epoch [39/50] batch [200/246] time 0.144 (0.164) data 0.000 (0.002) loss 1.2429 (1.2078) ce_loss 1.0928 (1.0716) teacher_loss 1.0807 (1.0660) loss_zs_kd 0.1967 (0.1807) loss_oracle 0.0639 (0.0514) acc 65.6250 (71.6562) kd_loss 0.0583 (0.0443) lr 3.1545e-04 eta 0:07:30
epoch [39/50] batch [220/246] time 0.155 (0.163) data 0.000 (0.001) loss 1.2744 (1.2127) ce_loss 1.1396 (1.0767) teacher_loss 1.1501 (1.0715) loss_zs_kd 0.1633 (0.1797) loss_oracle 0.0426 (0.0514) acc 65.6250 (71.4915) kd_loss 0.0401 (0.0445) lr 3.1545e-04 eta 0:07:25
epoch [39/50] batch [240/246] time 0.389 (0.164) data 0.000 (0.001) loss 0.9562 (1.2103) ce_loss 0.8452 (1.0746) teacher_loss 0.8437 (1.0695) loss_zs_kd 0.1366 (0.1792) loss_oracle 0.0442 (0.0511) acc 78.1250 (71.6146) kd_loss 0.0344 (0.0444) lr 3.1545e-04 eta 0:07:24
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,861
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.8%, epoch: 33 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [40/50] batch [20/246] time 0.159 (0.176) data 0.000 (0.013) loss 0.6516 (1.2576) ce_loss 0.4915 (1.1205) teacher_loss 0.4927 (1.1160) loss_zs_kd 0.2322 (0.1908) loss_oracle 0.0428 (0.0462) acc 87.5000 (67.9688) kd_loss 0.0290 (0.0390) lr 2.7103e-04 eta 0:07:52
epoch [40/50] batch [40/246] time 0.172 (0.166) data 0.000 (0.007) loss 1.4999 (1.2130) ce_loss 1.3506 (1.0740) teacher_loss 1.3539 (1.0695) loss_zs_kd 0.2047 (0.1906) loss_oracle 0.0437 (0.0483) acc 65.6250 (71.1719) kd_loss 0.0302 (0.0412) lr 2.7103e-04 eta 0:07:22
epoch [40/50] batch [60/246] time 0.164 (0.161) data 0.000 (0.005) loss 0.9181 (1.2019) ce_loss 0.7495 (1.0654) teacher_loss 0.7541 (1.0609) loss_zs_kd 0.2439 (0.1871) loss_oracle 0.0421 (0.0475) acc 75.0000 (71.5625) kd_loss 0.0359 (0.0394) lr 2.7103e-04 eta 0:07:06
epoch [40/50] batch [80/246] time 0.141 (0.159) data 0.000 (0.003) loss 1.2456 (1.1925) ce_loss 1.0986 (1.0572) teacher_loss 1.0906 (1.0534) loss_zs_kd 0.2162 (0.1834) loss_oracle 0.0469 (0.0474) acc 71.8750 (72.6172) kd_loss 0.0368 (0.0394) lr 2.7103e-04 eta 0:06:57
epoch [40/50] batch [100/246] time 0.098 (0.158) data 0.000 (0.003) loss 1.3032 (1.1779) ce_loss 1.1553 (1.0425) teacher_loss 1.1533 (1.0384) loss_zs_kd 0.1965 (0.1821) loss_oracle 0.0516 (0.0485) acc 62.5000 (73.0000) kd_loss 0.0409 (0.0397) lr 2.7103e-04 eta 0:06:50
epoch [40/50] batch [120/246] time 0.098 (0.160) data 0.000 (0.002) loss 1.2605 (1.1589) ce_loss 1.1230 (1.0247) teacher_loss 1.1275 (1.0207) loss_zs_kd 0.1937 (0.1789) loss_oracle 0.0360 (0.0488) acc 75.0000 (73.5677) kd_loss 0.0272 (0.0396) lr 2.7103e-04 eta 0:06:54
epoch [40/50] batch [140/246] time 0.168 (0.166) data 0.000 (0.002) loss 1.4843 (1.1428) ce_loss 1.3682 (1.0104) teacher_loss 1.3553 (1.0068) loss_zs_kd 0.1558 (0.1754) loss_oracle 0.0511 (0.0483) acc 56.2500 (73.8839) kd_loss 0.0294 (0.0389) lr 2.7103e-04 eta 0:07:06
epoch [40/50] batch [160/246] time 0.163 (0.165) data 0.000 (0.002) loss 1.3802 (1.1507) ce_loss 1.2451 (1.0181) teacher_loss 1.2420 (1.0142) loss_zs_kd 0.2012 (0.1765) loss_oracle 0.0376 (0.0483) acc 65.6250 (73.4570) kd_loss 0.0375 (0.0388) lr 2.7103e-04 eta 0:06:59
epoch [40/50] batch [180/246] time 0.159 (0.164) data 0.000 (0.002) loss 1.0838 (1.1617) ce_loss 0.8882 (1.0285) teacher_loss 0.8892 (1.0245) loss_zs_kd 0.2810 (0.1778) loss_oracle 0.0541 (0.0484) acc 71.8750 (73.1250) kd_loss 0.0532 (0.0387) lr 2.7103e-04 eta 0:06:53
epoch [40/50] batch [200/246] time 0.146 (0.163) data 0.000 (0.001) loss 1.0575 (1.1664) ce_loss 0.9492 (1.0340) teacher_loss 0.9402 (1.0296) loss_zs_kd 0.1499 (0.1765) loss_oracle 0.0423 (0.0486) acc 78.1250 (73.0312) kd_loss 0.0444 (0.0388) lr 2.7103e-04 eta 0:06:47
epoch [40/50] batch [220/246] time 0.151 (0.162) data 0.000 (0.001) loss 1.3681 (1.1672) ce_loss 1.2031 (1.0341) teacher_loss 1.2068 (1.0297) loss_zs_kd 0.2249 (0.1774) loss_oracle 0.0488 (0.0488) acc 68.7500 (72.8409) kd_loss 0.0433 (0.0389) lr 2.7103e-04 eta 0:06:43
epoch [40/50] batch [240/246] time 0.146 (0.162) data 0.000 (0.001) loss 1.5287 (1.1723) ce_loss 1.3838 (1.0388) teacher_loss 1.3832 (1.0343) loss_zs_kd 0.1702 (0.1775) loss_oracle 0.0604 (0.0492) acc 68.7500 (72.7474) kd_loss 0.0650 (0.0392) lr 2.7103e-04 eta 0:06:38
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,863
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.8%, epoch: 33 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [41/50] batch [20/246] time 0.159 (0.178) data 0.000 (0.014) loss 1.4962 (1.1497) ce_loss 1.3271 (1.0182) teacher_loss 1.3262 (1.0147) loss_zs_kd 0.2584 (0.1738) loss_oracle 0.0408 (0.0481) acc 62.5000 (73.2812) kd_loss 0.0249 (0.0397) lr 2.2949e-04 eta 0:07:14
epoch [41/50] batch [40/246] time 0.152 (0.167) data 0.000 (0.007) loss 1.7853 (1.1784) ce_loss 1.6113 (1.0411) teacher_loss 1.5860 (1.0356) loss_zs_kd 0.2742 (0.1829) loss_oracle 0.0622 (0.0514) acc 62.5000 (73.5156) kd_loss 0.0484 (0.0408) lr 2.2949e-04 eta 0:06:45
epoch [41/50] batch [60/246] time 0.176 (0.165) data 0.001 (0.005) loss 1.1567 (1.1505) ce_loss 1.0127 (1.0161) teacher_loss 1.0172 (1.0099) loss_zs_kd 0.1632 (0.1766) loss_oracle 0.0579 (0.0522) acc 75.0000 (72.9167) kd_loss 0.0352 (0.0413) lr 2.2949e-04 eta 0:06:34
epoch [41/50] batch [80/246] time 0.162 (0.165) data 0.001 (0.004) loss 0.9921 (1.1531) ce_loss 0.8501 (1.0210) teacher_loss 0.8448 (1.0142) loss_zs_kd 0.2223 (0.1746) loss_oracle 0.0362 (0.0516) acc 78.1250 (72.3438) kd_loss 0.0342 (0.0417) lr 2.2949e-04 eta 0:06:32
epoch [41/50] batch [100/246] time 0.156 (0.165) data 0.000 (0.003) loss 0.8787 (1.1780) ce_loss 0.7764 (1.0447) teacher_loss 0.7770 (1.0382) loss_zs_kd 0.1442 (0.1768) loss_oracle 0.0296 (0.0515) acc 75.0000 (72.0000) kd_loss 0.0209 (0.0417) lr 2.2949e-04 eta 0:06:29
epoch [41/50] batch [120/246] time 0.381 (0.164) data 0.000 (0.003) loss 1.2502 (1.1939) ce_loss 1.1221 (1.0601) teacher_loss 1.1241 (1.0539) loss_zs_kd 0.1782 (0.1770) loss_oracle 0.0370 (0.0515) acc 71.8750 (71.6406) kd_loss 0.0315 (0.0415) lr 2.2949e-04 eta 0:06:23
epoch [41/50] batch [140/246] time 0.328 (0.174) data 0.000 (0.002) loss 1.1445 (1.1860) ce_loss 1.0059 (1.0524) teacher_loss 0.9885 (1.0460) loss_zs_kd 0.1826 (0.1766) loss_oracle 0.0647 (0.0518) acc 71.8750 (71.9196) kd_loss 0.0434 (0.0415) lr 2.2949e-04 eta 0:06:43
epoch [41/50] batch [160/246] time 0.151 (0.171) data 0.000 (0.002) loss 1.3264 (1.1772) ce_loss 1.1670 (1.0438) teacher_loss 1.1678 (1.0375) loss_zs_kd 0.2119 (0.1760) loss_oracle 0.0526 (0.0517) acc 71.8750 (72.1484) kd_loss 0.0377 (0.0416) lr 2.2949e-04 eta 0:06:32
epoch [41/50] batch [180/246] time 0.139 (0.169) data 0.000 (0.002) loss 1.0273 (1.1852) ce_loss 0.8696 (1.0509) teacher_loss 0.8716 (1.0452) loss_zs_kd 0.1950 (0.1771) loss_oracle 0.0582 (0.0515) acc 75.0000 (71.8924) kd_loss 0.0517 (0.0416) lr 2.2949e-04 eta 0:06:24
epoch [41/50] batch [200/246] time 0.154 (0.167) data 0.000 (0.002) loss 1.2164 (1.1786) ce_loss 1.0771 (1.0443) teacher_loss 1.0793 (1.0387) loss_zs_kd 0.1838 (0.1770) loss_oracle 0.0452 (0.0513) acc 75.0000 (72.0156) kd_loss 0.0307 (0.0414) lr 2.2949e-04 eta 0:06:18
epoch [41/50] batch [220/246] time 0.160 (0.166) data 0.000 (0.001) loss 1.5004 (1.1753) ce_loss 1.3633 (1.0411) teacher_loss 1.3556 (1.0352) loss_zs_kd 0.1616 (0.1768) loss_oracle 0.0641 (0.0517) acc 68.7500 (72.0597) kd_loss 0.0459 (0.0420) lr 2.2949e-04 eta 0:06:12
epoch [41/50] batch [240/246] time 0.149 (0.165) data 0.000 (0.001) loss 1.1125 (1.1804) ce_loss 0.9678 (1.0458) teacher_loss 0.9659 (1.0399) loss_zs_kd 0.2006 (0.1779) loss_oracle 0.0463 (0.0516) acc 75.0000 (71.9401) kd_loss 0.0531 (0.0422) lr 2.2949e-04 eta 0:06:07
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,857
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.4%, epoch: 33 *******
******* Domain r best val test acc: 90.8%, epoch: 33 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [42/50] batch [20/246] time 0.166 (0.190) data 0.000 (0.012) loss 0.6804 (1.1562) ce_loss 0.5591 (1.0250) teacher_loss 0.5663 (1.0212) loss_zs_kd 0.1364 (0.1652) loss_oracle 0.0460 (0.0524) acc 87.5000 (72.5000) kd_loss 0.0433 (0.0465) lr 1.9098e-04 eta 0:06:57
epoch [42/50] batch [40/246] time 0.169 (0.180) data 0.000 (0.006) loss 1.1403 (1.1542) ce_loss 0.9517 (1.0198) teacher_loss 0.9463 (1.0166) loss_zs_kd 0.2678 (0.1739) loss_oracle 0.0601 (0.0507) acc 78.1250 (72.8125) kd_loss 0.0556 (0.0439) lr 1.9098e-04 eta 0:06:32
epoch [42/50] batch [60/246] time 0.163 (0.175) data 0.001 (0.004) loss 1.6984 (1.1667) ce_loss 1.5713 (1.0350) teacher_loss 1.5711 (1.0318) loss_zs_kd 0.1673 (0.1709) loss_oracle 0.0436 (0.0494) acc 62.5000 (72.2917) kd_loss 0.0531 (0.0442) lr 1.9098e-04 eta 0:06:16
epoch [42/50] batch [80/246] time 0.154 (0.171) data 0.000 (0.003) loss 1.2329 (1.1889) ce_loss 1.1211 (1.0547) teacher_loss 1.1118 (1.0508) loss_zs_kd 0.1591 (0.1766) loss_oracle 0.0415 (0.0497) acc 71.8750 (71.6406) kd_loss 0.0342 (0.0446) lr 1.9098e-04 eta 0:06:05
epoch [42/50] batch [100/246] time 0.151 (0.169) data 0.000 (0.003) loss 1.4993 (1.1853) ce_loss 1.3320 (1.0509) teacher_loss 1.3419 (1.0474) loss_zs_kd 0.1918 (0.1768) loss_oracle 0.0615 (0.0495) acc 59.3750 (71.6250) kd_loss 0.0636 (0.0440) lr 1.9098e-04 eta 0:05:56
epoch [42/50] batch [120/246] time 0.112 (0.165) data 0.000 (0.002) loss 1.6287 (1.1828) ce_loss 1.5029 (1.0471) teacher_loss 1.5074 (1.0431) loss_zs_kd 0.1716 (0.1799) loss_oracle 0.0356 (0.0497) acc 59.3750 (71.5365) kd_loss 0.0252 (0.0439) lr 1.9098e-04 eta 0:05:46
epoch [42/50] batch [140/246] time 0.369 (0.176) data 0.000 (0.002) loss 0.7430 (1.1871) ce_loss 0.6089 (1.0509) teacher_loss 0.6038 (1.0464) loss_zs_kd 0.1838 (0.1803) loss_oracle 0.0473 (0.0506) acc 84.3750 (71.6295) kd_loss 0.0380 (0.0440) lr 1.9098e-04 eta 0:06:05
epoch [42/50] batch [160/246] time 0.169 (0.174) data 0.000 (0.002) loss 1.1933 (1.1882) ce_loss 1.0752 (1.0513) teacher_loss 1.0599 (1.0462) loss_zs_kd 0.1616 (0.1804) loss_oracle 0.0526 (0.0518) acc 71.8750 (71.6602) kd_loss 0.0459 (0.0448) lr 1.9098e-04 eta 0:05:58
epoch [42/50] batch [180/246] time 0.152 (0.172) data 0.000 (0.002) loss 1.0904 (1.1905) ce_loss 0.9634 (1.0527) teacher_loss 0.9750 (1.0481) loss_zs_kd 0.1671 (0.1813) loss_oracle 0.0319 (0.0518) acc 81.2500 (71.5104) kd_loss 0.0307 (0.0447) lr 1.9098e-04 eta 0:05:50
epoch [42/50] batch [200/246] time 0.150 (0.171) data 0.000 (0.001) loss 1.4287 (1.1991) ce_loss 1.2471 (1.0611) teacher_loss 1.2463 (1.0565) loss_zs_kd 0.2497 (0.1813) loss_oracle 0.0575 (0.0520) acc 59.3750 (71.4062) kd_loss 0.0505 (0.0447) lr 1.9098e-04 eta 0:05:44
epoch [42/50] batch [220/246] time 0.171 (0.170) data 0.000 (0.001) loss 0.9576 (1.1927) ce_loss 0.8208 (1.0543) teacher_loss 0.8188 (1.0498) loss_zs_kd 0.1774 (0.1818) loss_oracle 0.0501 (0.0519) acc 81.2500 (71.6903) kd_loss 0.0410 (0.0446) lr 1.9098e-04 eta 0:05:39
epoch [42/50] batch [240/246] time 0.164 (0.170) data 0.000 (0.001) loss 1.2624 (1.1918) ce_loss 1.1406 (1.0540) teacher_loss 1.1421 (1.0497) loss_zs_kd 0.1277 (0.1804) loss_oracle 0.0564 (0.0519) acc 62.5000 (71.7578) kd_loss 0.0391 (0.0450) lr 1.9098e-04 eta 0:05:34
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,868
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [43/50] batch [20/246] time 0.171 (0.188) data 0.000 (0.013) loss 0.8483 (1.1980) ce_loss 0.7295 (1.0571) teacher_loss 0.7254 (1.0497) loss_zs_kd 0.1623 (0.1895) loss_oracle 0.0417 (0.0536) acc 87.5000 (72.6562) kd_loss 0.0367 (0.0483) lr 1.5567e-04 eta 0:06:07
epoch [43/50] batch [40/246] time 0.166 (0.177) data 0.000 (0.007) loss 1.5182 (1.1571) ce_loss 1.3887 (1.0163) teacher_loss 1.3840 (1.0100) loss_zs_kd 0.1557 (0.1855) loss_oracle 0.0563 (0.0544) acc 62.5000 (73.0469) kd_loss 0.0463 (0.0484) lr 1.5567e-04 eta 0:05:40
epoch [43/50] batch [60/246] time 0.170 (0.170) data 0.001 (0.005) loss 1.9361 (1.1997) ce_loss 1.7842 (1.0583) teacher_loss 1.7779 (1.0523) loss_zs_kd 0.2181 (0.1872) loss_oracle 0.0492 (0.0538) acc 56.2500 (71.9792) kd_loss 0.0422 (0.0489) lr 1.5567e-04 eta 0:05:24
epoch [43/50] batch [80/246] time 0.148 (0.166) data 0.000 (0.003) loss 1.0814 (1.1787) ce_loss 0.9463 (1.0402) teacher_loss 0.9364 (1.0347) loss_zs_kd 0.1704 (0.1824) loss_oracle 0.0598 (0.0528) acc 78.1250 (72.3047) kd_loss 0.0490 (0.0479) lr 1.5567e-04 eta 0:05:13
epoch [43/50] batch [100/246] time 0.170 (0.164) data 0.000 (0.003) loss 1.5528 (1.2053) ce_loss 1.3662 (1.0671) teacher_loss 1.3615 (1.0614) loss_zs_kd 0.2537 (0.1811) loss_oracle 0.0645 (0.0533) acc 68.7500 (71.5938) kd_loss 0.0572 (0.0481) lr 1.5567e-04 eta 0:05:06
epoch [43/50] batch [120/246] time 0.356 (0.165) data 0.000 (0.002) loss 0.8945 (1.1890) ce_loss 0.7505 (1.0520) teacher_loss 0.7605 (1.0469) loss_zs_kd 0.1697 (0.1773) loss_oracle 0.0492 (0.0534) acc 75.0000 (71.8750) kd_loss 0.0385 (0.0482) lr 1.5567e-04 eta 0:05:05
epoch [43/50] batch [140/246] time 0.102 (0.172) data 0.000 (0.002) loss 1.3081 (1.1977) ce_loss 1.1611 (1.0603) teacher_loss 1.1656 (1.0553) loss_zs_kd 0.1659 (0.1774) loss_oracle 0.0596 (0.0537) acc 65.6250 (71.5848) kd_loss 0.0608 (0.0484) lr 1.5567e-04 eta 0:05:13
epoch [43/50] batch [160/246] time 0.160 (0.171) data 0.000 (0.002) loss 1.3260 (1.1923) ce_loss 1.1641 (1.0553) teacher_loss 1.1469 (1.0501) loss_zs_kd 0.2203 (0.1772) loss_oracle 0.0689 (0.0536) acc 68.7500 (71.8359) kd_loss 0.0562 (0.0481) lr 1.5567e-04 eta 0:05:08
epoch [43/50] batch [180/246] time 0.171 (0.170) data 0.000 (0.002) loss 0.8645 (1.1919) ce_loss 0.7422 (1.0548) teacher_loss 0.7326 (1.0495) loss_zs_kd 0.1536 (0.1777) loss_oracle 0.0552 (0.0536) acc 84.3750 (71.8924) kd_loss 0.0518 (0.0482) lr 1.5567e-04 eta 0:05:04
epoch [43/50] batch [200/246] time 0.152 (0.169) data 0.000 (0.002) loss 0.8557 (1.1930) ce_loss 0.7441 (1.0569) teacher_loss 0.7248 (1.0513) loss_zs_kd 0.1288 (0.1767) loss_oracle 0.0665 (0.0534) acc 75.0000 (71.8750) kd_loss 0.0668 (0.0480) lr 1.5567e-04 eta 0:04:58
epoch [43/50] batch [220/246] time 0.152 (0.168) data 0.000 (0.001) loss 0.8684 (1.1900) ce_loss 0.7612 (1.0534) teacher_loss 0.7640 (1.0479) loss_zs_kd 0.1191 (0.1771) loss_oracle 0.0448 (0.0536) acc 84.3750 (72.0597) kd_loss 0.0456 (0.0481) lr 1.5567e-04 eta 0:04:53
epoch [43/50] batch [240/246] time 0.170 (0.167) data 0.000 (0.001) loss 1.7428 (1.1935) ce_loss 1.6240 (1.0567) teacher_loss 1.6176 (1.0511) loss_zs_kd 0.1488 (0.1782) loss_oracle 0.0508 (0.0532) acc 59.3750 (71.9792) kd_loss 0.0392 (0.0477) lr 1.5567e-04 eta 0:04:48
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,866
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,960
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [44/50] batch [20/246] time 0.173 (0.180) data 0.000 (0.014) loss 1.1845 (1.1859) ce_loss 1.0488 (1.0446) teacher_loss 1.0392 (1.0367) loss_zs_kd 0.1479 (0.1882) loss_oracle 0.0714 (0.0551) acc 68.7500 (72.8125) kd_loss 0.0683 (0.0484) lr 1.2369e-04 eta 0:05:06
epoch [44/50] batch [40/246] time 0.168 (0.174) data 0.000 (0.007) loss 1.0903 (1.1782) ce_loss 0.9062 (1.0413) teacher_loss 0.9083 (1.0341) loss_zs_kd 0.2488 (0.1782) loss_oracle 0.0575 (0.0549) acc 78.1250 (73.0469) kd_loss 0.0525 (0.0484) lr 1.2369e-04 eta 0:04:52
epoch [44/50] batch [60/246] time 0.165 (0.170) data 0.001 (0.005) loss 1.1574 (1.1932) ce_loss 1.0322 (1.0558) teacher_loss 1.0350 (1.0478) loss_zs_kd 0.1355 (0.1802) loss_oracle 0.0546 (0.0553) acc 71.8750 (72.2917) kd_loss 0.0507 (0.0482) lr 1.2369e-04 eta 0:04:42
epoch [44/50] batch [80/246] time 0.148 (0.167) data 0.000 (0.004) loss 1.1271 (1.1894) ce_loss 0.9731 (1.0494) teacher_loss 0.9782 (1.0425) loss_zs_kd 0.2317 (0.1848) loss_oracle 0.0330 (0.0545) acc 75.0000 (72.4219) kd_loss 0.0220 (0.0479) lr 1.2369e-04 eta 0:04:33
epoch [44/50] batch [100/246] time 0.165 (0.165) data 0.000 (0.003) loss 1.1644 (1.1894) ce_loss 0.9785 (1.0478) teacher_loss 0.9853 (1.0417) loss_zs_kd 0.2308 (0.1860) loss_oracle 0.0637 (0.0547) acc 81.2500 (72.5938) kd_loss 0.0526 (0.0482) lr 1.2369e-04 eta 0:04:27
epoch [44/50] batch [120/246] time 0.344 (0.163) data 0.000 (0.002) loss 1.0461 (1.1831) ce_loss 0.9058 (1.0421) teacher_loss 0.9062 (1.0361) loss_zs_kd 0.1767 (0.1849) loss_oracle 0.0516 (0.0545) acc 75.0000 (72.7865) kd_loss 0.0437 (0.0486) lr 1.2369e-04 eta 0:04:20
epoch [44/50] batch [140/246] time 0.089 (0.172) data 0.000 (0.002) loss 0.8935 (1.1736) ce_loss 0.7676 (1.0340) teacher_loss 0.7709 (1.0283) loss_zs_kd 0.1352 (0.1822) loss_oracle 0.0551 (0.0542) acc 75.0000 (72.8571) kd_loss 0.0425 (0.0484) lr 1.2369e-04 eta 0:04:32
epoch [44/50] batch [160/246] time 0.150 (0.169) data 0.000 (0.002) loss 1.1558 (1.1834) ce_loss 0.9756 (1.0434) teacher_loss 0.9780 (1.0377) loss_zs_kd 0.2603 (0.1829) loss_oracle 0.0476 (0.0543) acc 71.8750 (72.8516) kd_loss 0.0387 (0.0484) lr 1.2369e-04 eta 0:04:24
epoch [44/50] batch [180/246] time 0.169 (0.168) data 0.000 (0.002) loss 1.1100 (1.1831) ce_loss 0.9775 (1.0438) teacher_loss 0.9739 (1.0381) loss_zs_kd 0.1433 (0.1819) loss_oracle 0.0644 (0.0541) acc 78.1250 (72.8299) kd_loss 0.0549 (0.0478) lr 1.2369e-04 eta 0:04:19
epoch [44/50] batch [200/246] time 0.168 (0.168) data 0.000 (0.002) loss 1.2218 (1.1776) ce_loss 1.1025 (1.0389) teacher_loss 1.1015 (1.0331) loss_zs_kd 0.1492 (0.1806) loss_oracle 0.0457 (0.0542) acc 71.8750 (72.8281) kd_loss 0.0338 (0.0480) lr 1.2369e-04 eta 0:04:15
epoch [44/50] batch [220/246] time 0.151 (0.168) data 0.000 (0.001) loss 1.3074 (1.1722) ce_loss 1.2168 (1.0344) teacher_loss 1.2059 (1.0286) loss_zs_kd 0.0810 (0.1784) loss_oracle 0.0609 (0.0544) acc 68.7500 (72.8267) kd_loss 0.0554 (0.0483) lr 1.2369e-04 eta 0:04:11
epoch [44/50] batch [240/246] time 0.159 (0.168) data 0.000 (0.001) loss 0.9282 (1.1747) ce_loss 0.8257 (1.0372) teacher_loss 0.8192 (1.0313) loss_zs_kd 0.1288 (0.1777) loss_oracle 0.0445 (0.0545) acc 71.8750 (72.8516) kd_loss 0.0384 (0.0484) lr 1.2369e-04 eta 0:04:08
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,868
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [45/50] batch [20/246] time 0.160 (0.175) data 0.000 (0.013) loss 1.0266 (1.2594) ce_loss 0.9072 (1.1266) teacher_loss 0.8931 (1.1199) loss_zs_kd 0.1858 (0.1741) loss_oracle 0.0406 (0.0524) acc 81.2500 (70.4688) kd_loss 0.0348 (0.0458) lr 9.5173e-05 eta 0:04:15
epoch [45/50] batch [40/246] time 0.170 (0.169) data 0.000 (0.007) loss 1.8840 (1.2046) ce_loss 1.7568 (1.0668) teacher_loss 1.7415 (1.0602) loss_zs_kd 0.1487 (0.1815) loss_oracle 0.0682 (0.0536) acc 56.2500 (72.6562) kd_loss 0.0610 (0.0489) lr 9.5173e-05 eta 0:04:02
epoch [45/50] batch [60/246] time 0.167 (0.167) data 0.001 (0.005) loss 1.3168 (1.1963) ce_loss 1.1436 (1.0563) teacher_loss 1.1433 (1.0504) loss_zs_kd 0.2168 (0.1841) loss_oracle 0.0652 (0.0538) acc 75.0000 (72.8646) kd_loss 0.0614 (0.0496) lr 9.5173e-05 eta 0:03:56
epoch [45/50] batch [80/246] time 0.153 (0.167) data 0.000 (0.003) loss 0.9440 (1.2243) ce_loss 0.7925 (1.0841) teacher_loss 0.7946 (1.0785) loss_zs_kd 0.1972 (0.1846) loss_oracle 0.0509 (0.0535) acc 84.3750 (71.9531) kd_loss 0.0417 (0.0490) lr 9.5173e-05 eta 0:03:53
epoch [45/50] batch [100/246] time 0.102 (0.165) data 0.000 (0.003) loss 1.2155 (1.2050) ce_loss 1.0537 (1.0648) teacher_loss 1.0575 (1.0589) loss_zs_kd 0.2103 (0.1849) loss_oracle 0.0528 (0.0536) acc 78.1250 (72.4688) kd_loss 0.0513 (0.0483) lr 9.5173e-05 eta 0:03:46
epoch [45/50] batch [120/246] time 0.403 (0.177) data 0.000 (0.002) loss 1.3590 (1.1929) ce_loss 1.2432 (1.0543) teacher_loss 1.2242 (1.0482) loss_zs_kd 0.1459 (0.1822) loss_oracle 0.0618 (0.0537) acc 65.6250 (72.5781) kd_loss 0.0593 (0.0482) lr 9.5173e-05 eta 0:04:00
epoch [45/50] batch [140/246] time 0.165 (0.174) data 0.000 (0.002) loss 0.8516 (1.1867) ce_loss 0.7266 (1.0481) teacher_loss 0.7131 (1.0420) loss_zs_kd 0.1555 (0.1820) loss_oracle 0.0607 (0.0537) acc 78.1250 (72.5670) kd_loss 0.0492 (0.0482) lr 9.5173e-05 eta 0:03:52
epoch [45/50] batch [160/246] time 0.164 (0.172) data 0.000 (0.002) loss 1.5308 (1.1843) ce_loss 1.4053 (1.0456) teacher_loss 1.3962 (1.0398) loss_zs_kd 0.1518 (0.1818) loss_oracle 0.0587 (0.0536) acc 62.5000 (72.5391) kd_loss 0.0490 (0.0479) lr 9.5173e-05 eta 0:03:46
epoch [45/50] batch [180/246] time 0.152 (0.171) data 0.000 (0.002) loss 1.5630 (1.1856) ce_loss 1.4326 (1.0478) teacher_loss 1.4293 (1.0418) loss_zs_kd 0.1496 (0.1804) loss_oracle 0.0588 (0.0536) acc 68.7500 (72.5521) kd_loss 0.0450 (0.0477) lr 9.5173e-05 eta 0:03:41
epoch [45/50] batch [200/246] time 0.148 (0.169) data 0.000 (0.002) loss 0.9361 (1.1824) ce_loss 0.7959 (1.0445) teacher_loss 0.7961 (1.0386) loss_zs_kd 0.1739 (0.1796) loss_oracle 0.0530 (0.0540) acc 87.5000 (72.6406) kd_loss 0.0495 (0.0475) lr 9.5173e-05 eta 0:03:35
epoch [45/50] batch [220/246] time 0.146 (0.168) data 0.000 (0.001) loss 1.4448 (1.1831) ce_loss 1.3037 (1.0455) teacher_loss 1.3058 (1.0399) loss_zs_kd 0.1786 (0.1787) loss_oracle 0.0497 (0.0539) acc 71.8750 (72.5994) kd_loss 0.0497 (0.0473) lr 9.5173e-05 eta 0:03:31
epoch [45/50] batch [240/246] time 0.186 (0.168) data 0.000 (0.001) loss 1.2232 (1.1824) ce_loss 1.0986 (1.0449) teacher_loss 1.0977 (1.0391) loss_zs_kd 0.1221 (0.1785) loss_oracle 0.0644 (0.0540) acc 75.0000 (72.5391) kd_loss 0.0583 (0.0474) lr 9.5173e-05 eta 0:03:27
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,865
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [46/50] batch [20/246] time 0.154 (0.179) data 0.000 (0.015) loss 1.2062 (1.2951) ce_loss 1.0693 (1.1591) teacher_loss 1.0600 (1.1534) loss_zs_kd 0.1715 (0.1789) loss_oracle 0.0604 (0.0523) acc 71.8750 (71.8750) kd_loss 0.0539 (0.0456) lr 7.0224e-05 eta 0:03:36
epoch [46/50] batch [40/246] time 0.163 (0.172) data 0.000 (0.008) loss 1.0861 (1.2697) ce_loss 0.9575 (1.1349) teacher_loss 0.9395 (1.1278) loss_zs_kd 0.1717 (0.1780) loss_oracle 0.0608 (0.0529) acc 75.0000 (71.1719) kd_loss 0.0519 (0.0456) lr 7.0224e-05 eta 0:03:24
epoch [46/50] batch [60/246] time 0.164 (0.169) data 0.001 (0.005) loss 1.0259 (1.2452) ce_loss 0.8296 (1.1101) teacher_loss 0.8214 (1.1033) loss_zs_kd 0.2553 (0.1766) loss_oracle 0.0768 (0.0537) acc 78.1250 (71.0417) kd_loss 0.0608 (0.0458) lr 7.0224e-05 eta 0:03:18
epoch [46/50] batch [80/246] time 0.165 (0.168) data 0.000 (0.004) loss 1.1392 (1.2373) ce_loss 1.0107 (1.1014) teacher_loss 1.0058 (1.0956) loss_zs_kd 0.1843 (0.1803) loss_oracle 0.0412 (0.0515) acc 71.8750 (71.4844) kd_loss 0.0386 (0.0441) lr 7.0224e-05 eta 0:03:13
epoch [46/50] batch [100/246] time 0.387 (0.172) data 0.000 (0.003) loss 0.9713 (1.2342) ce_loss 0.8193 (1.0979) teacher_loss 0.8242 (1.0916) loss_zs_kd 0.2040 (0.1809) loss_oracle 0.0452 (0.0521) acc 71.8750 (71.4062) kd_loss 0.0349 (0.0443) lr 7.0224e-05 eta 0:03:13
epoch [46/50] batch [120/246] time 0.155 (0.178) data 0.000 (0.003) loss 0.7046 (1.2217) ce_loss 0.5786 (1.0857) teacher_loss 0.5885 (1.0799) loss_zs_kd 0.1322 (0.1796) loss_oracle 0.0500 (0.0520) acc 81.2500 (71.7188) kd_loss 0.0416 (0.0443) lr 7.0224e-05 eta 0:03:17
epoch [46/50] batch [140/246] time 0.180 (0.177) data 0.000 (0.002) loss 0.6668 (1.1919) ce_loss 0.4919 (1.0578) teacher_loss 0.4948 (1.0522) loss_zs_kd 0.2569 (0.1757) loss_oracle 0.0436 (0.0519) acc 84.3750 (72.5000) kd_loss 0.0391 (0.0444) lr 7.0224e-05 eta 0:03:13
epoch [46/50] batch [160/246] time 0.154 (0.176) data 0.000 (0.002) loss 1.5706 (1.1862) ce_loss 1.4258 (1.0510) teacher_loss 1.4313 (1.0458) loss_zs_kd 0.2100 (0.1776) loss_oracle 0.0343 (0.0516) acc 59.3750 (72.5586) kd_loss 0.0292 (0.0441) lr 7.0224e-05 eta 0:03:07
epoch [46/50] batch [180/246] time 0.159 (0.174) data 0.000 (0.002) loss 1.1339 (1.1833) ce_loss 1.0244 (1.0478) teacher_loss 1.0107 (1.0427) loss_zs_kd 0.1432 (0.1780) loss_oracle 0.0517 (0.0516) acc 68.7500 (72.6562) kd_loss 0.0534 (0.0442) lr 7.0224e-05 eta 0:03:02
epoch [46/50] batch [200/246] time 0.153 (0.173) data 0.000 (0.002) loss 1.6911 (1.1922) ce_loss 1.5352 (1.0559) teacher_loss 1.5171 (1.0507) loss_zs_kd 0.2447 (0.1785) loss_oracle 0.0516 (0.0523) acc 56.2500 (72.3594) kd_loss 0.0510 (0.0451) lr 7.0224e-05 eta 0:02:58
epoch [46/50] batch [220/246] time 0.165 (0.172) data 0.000 (0.002) loss 1.4297 (1.1867) ce_loss 1.3242 (1.0505) teacher_loss 1.3140 (1.0453) loss_zs_kd 0.1369 (0.1785) loss_oracle 0.0473 (0.0522) acc 59.3750 (72.4432) kd_loss 0.0544 (0.0455) lr 7.0224e-05 eta 0:02:53
epoch [46/50] batch [240/246] time 0.085 (0.174) data 0.000 (0.001) loss 1.0164 (1.1897) ce_loss 0.8916 (1.0531) teacher_loss 0.8919 (1.0477) loss_zs_kd 0.1698 (0.1794) loss_oracle 0.0396 (0.0523) acc 81.2500 (72.3958) kd_loss 0.0357 (0.0457) lr 7.0224e-05 eta 0:02:52
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,866
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [47/50] batch [20/246] time 0.186 (0.191) data 0.000 (0.015) loss 1.2812 (1.1592) ce_loss 1.1826 (1.0243) teacher_loss 1.1714 (1.0177) loss_zs_kd 0.1396 (0.1795) loss_oracle 0.0400 (0.0518) acc 62.5000 (72.8125) kd_loss 0.0357 (0.0450) lr 4.8943e-05 eta 0:03:04
epoch [47/50] batch [40/246] time 0.155 (0.177) data 0.000 (0.008) loss 1.2476 (1.1713) ce_loss 1.0713 (1.0328) teacher_loss 1.0531 (1.0263) loss_zs_kd 0.2795 (0.1858) loss_oracle 0.0548 (0.0521) acc 75.0000 (72.5000) kd_loss 0.0467 (0.0473) lr 4.8943e-05 eta 0:02:47
epoch [47/50] batch [60/246] time 0.169 (0.172) data 0.001 (0.005) loss 0.8063 (1.1800) ce_loss 0.6665 (1.0418) teacher_loss 0.6538 (1.0354) loss_zs_kd 0.1959 (0.1835) loss_oracle 0.0545 (0.0529) acc 78.1250 (72.4479) kd_loss 0.0463 (0.0484) lr 4.8943e-05 eta 0:02:39
epoch [47/50] batch [80/246] time 0.343 (0.171) data 0.000 (0.004) loss 0.7554 (1.1649) ce_loss 0.6621 (1.0282) teacher_loss 0.6665 (1.0222) loss_zs_kd 0.1190 (0.1808) loss_oracle 0.0294 (0.0524) acc 81.2500 (72.7344) kd_loss 0.0286 (0.0481) lr 4.8943e-05 eta 0:02:34
epoch [47/50] batch [100/246] time 0.097 (0.182) data 0.000 (0.003) loss 1.2225 (1.1692) ce_loss 0.9717 (1.0310) teacher_loss 0.9623 (1.0253) loss_zs_kd 0.3632 (0.1822) loss_oracle 0.0786 (0.0528) acc 75.0000 (72.9688) kd_loss 0.0656 (0.0482) lr 4.8943e-05 eta 0:02:41
epoch [47/50] batch [120/246] time 0.143 (0.178) data 0.000 (0.003) loss 1.0090 (1.1894) ce_loss 0.8843 (1.0512) teacher_loss 0.8838 (1.0453) loss_zs_kd 0.1450 (0.1825) loss_oracle 0.0527 (0.0529) acc 81.2500 (72.3958) kd_loss 0.0463 (0.0479) lr 4.8943e-05 eta 0:02:33
epoch [47/50] batch [140/246] time 0.146 (0.175) data 0.000 (0.002) loss 0.9403 (1.1813) ce_loss 0.8008 (1.0433) teacher_loss 0.7981 (1.0380) loss_zs_kd 0.1870 (0.1817) loss_oracle 0.0487 (0.0525) acc 84.3750 (72.7679) kd_loss 0.0498 (0.0474) lr 4.8943e-05 eta 0:02:27
epoch [47/50] batch [160/246] time 0.166 (0.173) data 0.000 (0.002) loss 0.9039 (1.1775) ce_loss 0.7925 (1.0391) teacher_loss 0.7870 (1.0333) loss_zs_kd 0.1369 (0.1821) loss_oracle 0.0485 (0.0531) acc 81.2500 (73.1250) kd_loss 0.0392 (0.0477) lr 4.8943e-05 eta 0:02:22
epoch [47/50] batch [180/246] time 0.153 (0.171) data 0.000 (0.002) loss 0.8600 (1.1740) ce_loss 0.7266 (1.0369) teacher_loss 0.7265 (1.0310) loss_zs_kd 0.1818 (0.1800) loss_oracle 0.0426 (0.0530) acc 81.2500 (73.1771) kd_loss 0.0414 (0.0474) lr 4.8943e-05 eta 0:02:17
epoch [47/50] batch [200/246] time 0.145 (0.170) data 0.000 (0.002) loss 0.8944 (1.1680) ce_loss 0.7827 (1.0318) teacher_loss 0.7732 (1.0256) loss_zs_kd 0.1416 (0.1785) loss_oracle 0.0504 (0.0531) acc 81.2500 (73.3125) kd_loss 0.0400 (0.0474) lr 4.8943e-05 eta 0:02:13
epoch [47/50] batch [220/246] time 0.174 (0.169) data 0.000 (0.002) loss 0.8985 (1.1795) ce_loss 0.7656 (1.0432) teacher_loss 0.7598 (1.0372) loss_zs_kd 0.1693 (0.1788) loss_oracle 0.0541 (0.0529) acc 81.2500 (73.1392) kd_loss 0.0456 (0.0471) lr 4.8943e-05 eta 0:02:09
epoch [47/50] batch [240/246] time 0.276 (0.170) data 0.000 (0.001) loss 1.3797 (1.1834) ce_loss 1.2148 (1.0467) teacher_loss 1.2229 (1.0407) loss_zs_kd 0.2216 (0.1796) loss_oracle 0.0459 (0.0529) acc 71.8750 (72.9427) kd_loss 0.0315 (0.0470) lr 4.8943e-05 eta 0:02:06
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,866
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.5%, epoch: 42 *******
******* Domain r best val test acc: 90.8%, epoch: 42 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [48/50] batch [20/246] time 0.177 (0.185) data 0.000 (0.013) loss 0.7358 (1.1191) ce_loss 0.6060 (0.9768) teacher_loss 0.6137 (0.9750) loss_zs_kd 0.1548 (0.1855) loss_oracle 0.0447 (0.0514) acc 84.3750 (74.0625) kd_loss 0.0425 (0.0441) lr 3.1417e-05 eta 0:02:12
epoch [48/50] batch [40/246] time 0.166 (0.176) data 0.000 (0.007) loss 1.1503 (1.1261) ce_loss 1.0039 (0.9836) teacher_loss 0.9996 (0.9806) loss_zs_kd 0.2035 (0.1855) loss_oracle 0.0490 (0.0528) acc 71.8750 (73.4375) kd_loss 0.0414 (0.0457) lr 3.1417e-05 eta 0:02:02
epoch [48/50] batch [60/246] time 0.150 (0.170) data 0.001 (0.005) loss 1.1139 (1.1028) ce_loss 0.9399 (0.9626) teacher_loss 0.9428 (0.9594) loss_zs_kd 0.2261 (0.1813) loss_oracle 0.0580 (0.0528) acc 78.1250 (74.4271) kd_loss 0.0511 (0.0459) lr 3.1417e-05 eta 0:01:55
epoch [48/50] batch [80/246] time 0.088 (0.178) data 0.000 (0.003) loss 1.1239 (1.1303) ce_loss 0.9746 (0.9909) teacher_loss 0.9677 (0.9870) loss_zs_kd 0.1913 (0.1813) loss_oracle 0.0605 (0.0527) acc 75.0000 (73.7109) kd_loss 0.0566 (0.0465) lr 3.1417e-05 eta 0:01:56
epoch [48/50] batch [100/246] time 0.151 (0.182) data 0.000 (0.003) loss 1.4083 (1.1402) ce_loss 1.2529 (1.0022) teacher_loss 1.2378 (0.9974) loss_zs_kd 0.1858 (0.1802) loss_oracle 0.0776 (0.0527) acc 71.8750 (73.4688) kd_loss 0.0702 (0.0474) lr 3.1417e-05 eta 0:01:55
epoch [48/50] batch [120/246] time 0.164 (0.178) data 0.000 (0.002) loss 1.2723 (1.1642) ce_loss 1.1494 (1.0257) teacher_loss 1.1409 (1.0202) loss_zs_kd 0.1506 (0.1816) loss_oracle 0.0560 (0.0533) acc 71.8750 (72.7865) kd_loss 0.0368 (0.0476) lr 3.1417e-05 eta 0:01:49
epoch [48/50] batch [140/246] time 0.168 (0.175) data 0.001 (0.002) loss 1.4751 (1.1726) ce_loss 1.3525 (1.0336) teacher_loss 1.3406 (1.0281) loss_zs_kd 0.1707 (0.1829) loss_oracle 0.0492 (0.0531) acc 68.7500 (72.6116) kd_loss 0.0490 (0.0474) lr 3.1417e-05 eta 0:01:44
epoch [48/50] batch [160/246] time 0.156 (0.173) data 0.000 (0.002) loss 0.8062 (1.1887) ce_loss 0.6841 (1.0500) teacher_loss 0.6688 (1.0443) loss_zs_kd 0.1565 (0.1824) loss_oracle 0.0592 (0.0532) acc 78.1250 (72.2461) kd_loss 0.0662 (0.0475) lr 3.1417e-05 eta 0:01:39
epoch [48/50] batch [180/246] time 0.168 (0.172) data 0.000 (0.002) loss 1.4884 (1.1840) ce_loss 1.3662 (1.0458) teacher_loss 1.3497 (1.0405) loss_zs_kd 0.1535 (0.1809) loss_oracle 0.0620 (0.0530) acc 62.5000 (72.3438) kd_loss 0.0444 (0.0473) lr 3.1417e-05 eta 0:01:35
epoch [48/50] batch [200/246] time 0.172 (0.170) data 0.000 (0.002) loss 1.4367 (1.1982) ce_loss 1.2998 (1.0603) teacher_loss 1.2879 (1.0549) loss_zs_kd 0.1662 (0.1808) loss_oracle 0.0657 (0.0530) acc 65.6250 (71.9844) kd_loss 0.0579 (0.0472) lr 3.1417e-05 eta 0:01:31
epoch [48/50] batch [220/246] time 0.414 (0.172) data 0.000 (0.001) loss 1.2871 (1.2060) ce_loss 1.1250 (1.0676) teacher_loss 1.1244 (1.0619) loss_zs_kd 0.2111 (0.1814) loss_oracle 0.0571 (0.0534) acc 71.8750 (71.8892) kd_loss 0.0419 (0.0473) lr 3.1417e-05 eta 0:01:29
epoch [48/50] batch [240/246] time 0.147 (0.174) data 0.000 (0.001) loss 1.6059 (1.2123) ce_loss 1.4844 (1.0738) teacher_loss 1.4762 (1.0681) loss_zs_kd 0.1575 (0.1812) loss_oracle 0.0509 (0.0536) acc 62.5000 (71.8099) kd_loss 0.0456 (0.0474) lr 3.1417e-05 eta 0:01:26
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,869
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 48 *******
******* Domain r best val test acc: 90.8%, epoch: 48 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [49/50] batch [20/246] time 0.171 (0.183) data 0.000 (0.015) loss 1.3294 (1.1745) ce_loss 1.2012 (1.0332) teacher_loss 1.2042 (1.0270) loss_zs_kd 0.1649 (0.1869) loss_oracle 0.0428 (0.0540) acc 62.5000 (74.5312) kd_loss 0.0319 (0.0470) lr 1.7713e-05 eta 0:01:26
epoch [49/50] batch [40/246] time 0.155 (0.173) data 0.000 (0.008) loss 1.2093 (1.1334) ce_loss 1.0615 (0.9936) teacher_loss 1.0475 (0.9872) loss_zs_kd 0.2016 (0.1823) loss_oracle 0.0610 (0.0550) acc 75.0000 (74.4531) kd_loss 0.0496 (0.0463) lr 1.7713e-05 eta 0:01:18
epoch [49/50] batch [60/246] time 0.182 (0.184) data 0.001 (0.005) loss 1.0463 (1.1667) ce_loss 0.8789 (1.0281) teacher_loss 0.8673 (1.0205) loss_zs_kd 0.2600 (0.1814) loss_oracle 0.0491 (0.0555) acc 84.3750 (72.7083) kd_loss 0.0444 (0.0462) lr 1.7713e-05 eta 0:01:19
epoch [49/50] batch [80/246] time 0.148 (0.184) data 0.000 (0.004) loss 1.3169 (1.1618) ce_loss 1.1729 (1.0252) teacher_loss 1.1678 (1.0183) loss_zs_kd 0.1951 (0.1779) loss_oracle 0.0515 (0.0545) acc 71.8750 (72.7344) kd_loss 0.0411 (0.0457) lr 1.7713e-05 eta 0:01:15
epoch [49/50] batch [100/246] time 0.149 (0.179) data 0.000 (0.003) loss 1.4174 (1.1956) ce_loss 1.2607 (1.0601) teacher_loss 1.2564 (1.0530) loss_zs_kd 0.2235 (0.1767) loss_oracle 0.0493 (0.0542) acc 68.7500 (72.0000) kd_loss 0.0477 (0.0460) lr 1.7713e-05 eta 0:01:09
epoch [49/50] batch [120/246] time 0.157 (0.175) data 0.000 (0.003) loss 0.7751 (1.1840) ce_loss 0.6099 (1.0492) teacher_loss 0.6058 (1.0425) loss_zs_kd 0.1961 (0.1737) loss_oracle 0.0713 (0.0546) acc 84.3750 (72.4740) kd_loss 0.0538 (0.0462) lr 1.7713e-05 eta 0:01:05
epoch [49/50] batch [140/246] time 0.163 (0.174) data 0.000 (0.002) loss 1.4826 (1.1823) ce_loss 1.3652 (1.0478) teacher_loss 1.3594 (1.0412) loss_zs_kd 0.1602 (0.1739) loss_oracle 0.0431 (0.0541) acc 65.6250 (72.5223) kd_loss 0.0342 (0.0460) lr 1.7713e-05 eta 0:01:01
epoch [49/50] batch [160/246] time 0.172 (0.172) data 0.000 (0.002) loss 1.6827 (1.1848) ce_loss 1.5508 (1.0496) teacher_loss 1.5261 (1.0427) loss_zs_kd 0.2040 (0.1753) loss_oracle 0.0546 (0.0544) acc 59.3750 (72.4414) kd_loss 0.0482 (0.0466) lr 1.7713e-05 eta 0:00:57
epoch [49/50] batch [180/246] time 0.162 (0.171) data 0.000 (0.002) loss 1.0585 (1.1852) ce_loss 0.9141 (1.0495) teacher_loss 0.9019 (1.0427) loss_zs_kd 0.1729 (0.1760) loss_oracle 0.0701 (0.0545) acc 75.0000 (72.4826) kd_loss 0.0635 (0.0466) lr 1.7713e-05 eta 0:00:53
epoch [49/50] batch [200/246] time 0.247 (0.175) data 0.000 (0.002) loss 1.7987 (1.1940) ce_loss 1.6689 (1.0579) teacher_loss 1.6580 (1.0509) loss_zs_kd 0.2002 (0.1770) loss_oracle 0.0405 (0.0545) acc 50.0000 (72.2969) kd_loss 0.0378 (0.0467) lr 1.7713e-05 eta 0:00:50
epoch [49/50] batch [220/246] time 0.162 (0.175) data 0.000 (0.002) loss 1.0650 (1.1908) ce_loss 0.8911 (1.0539) teacher_loss 0.8782 (1.0470) loss_zs_kd 0.2524 (0.1782) loss_oracle 0.0606 (0.0547) acc 78.1250 (72.4148) kd_loss 0.0510 (0.0471) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [240/246] time 0.147 (0.174) data 0.000 (0.001) loss 1.1406 (1.1841) ce_loss 1.0039 (1.0473) teacher_loss 1.0016 (1.0402) loss_zs_kd 0.1764 (0.1778) loss_oracle 0.0508 (0.0550) acc 75.0000 (72.5000) kd_loss 0.0445 (0.0476) lr 1.7713e-05 eta 0:00:43
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,868
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.5%, epoch: 48 *******
******* Domain r best val test acc: 90.8%, epoch: 48 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
epoch [50/50] batch [20/246] time 0.153 (0.174) data 0.000 (0.012) loss 1.2424 (1.1457) ce_loss 1.0742 (1.0016) teacher_loss 1.0658 (0.9954) loss_zs_kd 0.2343 (0.1849) loss_oracle 0.0595 (0.0578) acc 68.7500 (73.1250) kd_loss 0.0579 (0.0523) lr 7.8853e-06 eta 0:00:39
epoch [50/50] batch [40/246] time 0.177 (0.167) data 0.000 (0.006) loss 1.2855 (1.1347) ce_loss 1.1416 (0.9957) teacher_loss 1.1355 (0.9888) loss_zs_kd 0.1743 (0.1812) loss_oracle 0.0628 (0.0553) acc 78.1250 (73.8281) kd_loss 0.0540 (0.0500) lr 7.8853e-06 eta 0:00:34
epoch [50/50] batch [60/246] time 0.088 (0.171) data 0.001 (0.004) loss 1.5841 (1.1577) ce_loss 1.4443 (1.0184) teacher_loss 1.4266 (1.0111) loss_zs_kd 0.2133 (0.1831) loss_oracle 0.0508 (0.0551) acc 62.5000 (73.4896) kd_loss 0.0498 (0.0499) lr 7.8853e-06 eta 0:00:31
epoch [50/50] batch [80/246] time 0.172 (0.179) data 0.000 (0.003) loss 1.2362 (1.1829) ce_loss 1.1260 (1.0453) teacher_loss 1.1252 (1.0365) loss_zs_kd 0.1477 (0.1802) loss_oracle 0.0371 (0.0562) acc 68.7500 (72.6562) kd_loss 0.0313 (0.0504) lr 7.8853e-06 eta 0:00:29
epoch [50/50] batch [100/246] time 0.144 (0.174) data 0.000 (0.003) loss 1.9985 (1.2009) ce_loss 1.8496 (1.0637) teacher_loss 1.8573 (1.0552) loss_zs_kd 0.2061 (0.1794) loss_oracle 0.0380 (0.0560) acc 62.5000 (72.1875) kd_loss 0.0310 (0.0505) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [120/246] time 0.159 (0.173) data 0.000 (0.002) loss 0.9049 (1.2003) ce_loss 0.7710 (1.0613) teacher_loss 0.7397 (1.0531) loss_zs_kd 0.1969 (0.1821) loss_oracle 0.0667 (0.0561) acc 75.0000 (72.1354) kd_loss 0.0598 (0.0509) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [140/246] time 0.160 (0.171) data 0.000 (0.002) loss 1.0339 (1.1919) ce_loss 0.9131 (1.0537) teacher_loss 0.9054 (1.0457) loss_zs_kd 0.1548 (0.1802) loss_oracle 0.0511 (0.0561) acc 81.2500 (72.3884) kd_loss 0.0511 (0.0511) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [160/246] time 0.172 (0.170) data 0.000 (0.002) loss 0.9724 (1.1964) ce_loss 0.8433 (1.0584) teacher_loss 0.8308 (1.0502) loss_zs_kd 0.1750 (0.1804) loss_oracle 0.0540 (0.0560) acc 81.2500 (72.4609) kd_loss 0.0471 (0.0509) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [180/246] time 0.177 (0.169) data 0.000 (0.002) loss 1.0539 (1.1899) ce_loss 0.8989 (1.0514) teacher_loss 0.9016 (1.0435) loss_zs_kd 0.1995 (0.1808) loss_oracle 0.0525 (0.0560) acc 78.1250 (72.5347) kd_loss 0.0538 (0.0506) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [200/246] time 0.085 (0.171) data 0.000 (0.001) loss 1.4248 (1.1875) ce_loss 1.3096 (1.0488) teacher_loss 1.2872 (1.0414) loss_zs_kd 0.1826 (0.1800) loss_oracle 0.0463 (0.0561) acc 59.3750 (72.7656) kd_loss 0.0398 (0.0505) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [220/246] time 0.156 (0.174) data 0.000 (0.001) loss 1.6793 (1.1979) ce_loss 1.5361 (1.0590) teacher_loss 1.5254 (1.0516) loss_zs_kd 0.1816 (0.1807) loss_oracle 0.0631 (0.0560) acc 59.3750 (72.5426) kd_loss 0.0560 (0.0501) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [240/246] time 0.173 (0.173) data 0.000 (0.001) loss 1.3931 (1.1976) ce_loss 1.2324 (1.0590) teacher_loss 1.2332 (1.0518) loss_zs_kd 0.2030 (0.1798) loss_oracle 0.0584 (0.0560) acc 62.5000 (72.3438) kd_loss 0.0438 (0.0501) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,869
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,953
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.7%
******* Domain r best val acc:      85.5%, epoch: 48 *******
******* Domain r best val test acc: 90.8%, epoch: 48 *******
******* Domain r best test acc:     91.2%, epoch: 8 *******
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:42:39

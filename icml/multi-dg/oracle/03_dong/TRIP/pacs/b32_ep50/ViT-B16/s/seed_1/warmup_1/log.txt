Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------------
Dataset    SPG_PACS
Source     ['art_painting', 'cartoon', 'photo']
Target     ['sketch']
# classes  7
# train_x  4,241
# val      1,821
# test     3,928
---------  ------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/132] time 0.087 (0.142) data 0.000 (0.023) loss 0.1689 (0.2720) ce_loss 0.1688 (0.2716) teacher_loss 0.1687 (0.2717) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0002 (0.0004) acc 96.8750 (90.0000) kd_loss 0.0007 (0.0014) lr 1.0000e-05 eta 0:15:35
epoch [1/50] batch [40/132] time 0.086 (0.116) data 0.000 (0.012) loss 0.2077 (0.2598) ce_loss 0.2074 (0.2595) teacher_loss 0.2074 (0.2595) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0003 (0.0003) acc 93.7500 (90.9375) kd_loss 0.0010 (0.0011) lr 1.0000e-05 eta 0:12:38
epoch [1/50] batch [60/132] time 0.087 (0.106) data 0.000 (0.008) loss 0.4267 (0.2504) ce_loss 0.4268 (0.2501) teacher_loss 0.4261 (0.2501) loss_zs_kd 0.0004 (0.0001) loss_oracle 0.0004 (0.0003) acc 81.2500 (91.2500) kd_loss 0.0014 (0.0011) lr 1.0000e-05 eta 0:11:33
epoch [1/50] batch [80/132] time 0.085 (0.101) data 0.000 (0.006) loss 0.3852 (0.2517) ce_loss 0.3850 (0.2514) teacher_loss 0.3846 (0.2513) loss_zs_kd 0.0004 (0.0001) loss_oracle 0.0004 (0.0003) acc 84.3750 (91.3672) kd_loss 0.0016 (0.0012) lr 1.0000e-05 eta 0:10:58
epoch [1/50] batch [100/132] time 0.091 (0.099) data 0.000 (0.005) loss 0.1748 (0.2585) ce_loss 0.1741 (0.2581) teacher_loss 0.1741 (0.2581) loss_zs_kd 0.0005 (0.0002) loss_oracle 0.0004 (0.0003) acc 90.6250 (91.3750) kd_loss 0.0016 (0.0012) lr 1.0000e-05 eta 0:10:43
epoch [1/50] batch [120/132] time 0.078 (0.097) data 0.000 (0.004) loss 0.3607 (0.2580) ce_loss 0.3604 (0.2576) teacher_loss 0.3600 (0.2575) loss_zs_kd 0.0002 (0.0002) loss_oracle 0.0006 (0.0004) acc 87.5000 (91.4062) kd_loss 0.0024 (0.0013) lr 1.0000e-05 eta 0:10:27
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,800
* accuracy: 98.8%
* error: 1.2%
* macro_f1: 98.9%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,472
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 90.7%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      98.8%, epoch: 1 *******
******* Domain s best val test acc: 88.4%, epoch: 1 *******
******* Domain s best test acc:     88.4%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/ana
epoch [2/50] batch [20/132] time 0.094 (0.105) data 0.000 (0.022) loss 0.1074 (0.2564) ce_loss 0.1005 (0.2433) teacher_loss 0.1001 (0.2432) loss_zs_kd 0.0106 (0.0231) loss_oracle 0.0020 (0.0016) acc 96.8750 (92.0312) kd_loss 0.0047 (0.0038) lr 2.0000e-03 eta 0:11:18
epoch [2/50] batch [40/132] time 0.084 (0.096) data 0.000 (0.011) loss 0.4224 (0.2388) ce_loss 0.4070 (0.2252) teacher_loss 0.4062 (0.2251) loss_zs_kd 0.0222 (0.0227) loss_oracle 0.0051 (0.0024) acc 90.6250 (92.7344) kd_loss 0.0112 (0.0056) lr 2.0000e-03 eta 0:10:16
epoch [2/50] batch [60/132] time 0.112 (0.093) data 0.001 (0.008) loss 0.3505 (0.2347) ce_loss 0.3228 (0.2181) teacher_loss 0.3205 (0.2177) loss_zs_kd 0.0390 (0.0251) loss_oracle 0.0105 (0.0045) acc 87.5000 (93.0208) kd_loss 0.0242 (0.0094) lr 2.0000e-03 eta 0:09:58
epoch [2/50] batch [80/132] time 0.082 (0.091) data 0.000 (0.006) loss 0.1801 (0.2390) ce_loss 0.1193 (0.2141) teacher_loss 0.1165 (0.2126) loss_zs_kd 0.0303 (0.0273) loss_oracle 0.0484 (0.0127) acc 96.8750 (92.9688) kd_loss 0.0730 (0.0186) lr 2.0000e-03 eta 0:09:42
epoch [2/50] batch [100/132] time 0.080 (0.090) data 0.000 (0.005) loss 0.4709 (0.2583) ce_loss 0.2556 (0.2118) teacher_loss 0.2298 (0.2082) loss_zs_kd 0.0289 (0.0294) loss_oracle 0.2267 (0.0354) acc 93.7500 (93.1250) kd_loss 0.2431 (0.0445) lr 2.0000e-03 eta 0:09:32
epoch [2/50] batch [120/132] time 0.077 (0.089) data 0.000 (0.004) loss 0.5074 (0.2801) ce_loss 0.1901 (0.2103) teacher_loss 0.1756 (0.2048) loss_zs_kd 0.0216 (0.0287) loss_oracle 0.3210 (0.0609) acc 90.6250 (93.0990) kd_loss 0.3794 (0.0778) lr 2.0000e-03 eta 0:09:27
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,803
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.0%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,504
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 91.6%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.0%, epoch: 2 *******
******* Domain s best val test acc: 89.2%, epoch: 2 *******
******* Domain s best test acc:     89.2%, epoch: 2 *******
epoch [3/50] batch [20/132] time 0.087 (0.102) data 0.000 (0.014) loss 0.7819 (0.5688) ce_loss 0.3997 (0.2028) teacher_loss 0.3707 (0.1800) loss_zs_kd 0.0363 (0.0292) loss_oracle 0.3930 (0.3742) acc 84.3750 (93.1250) kd_loss 0.6487 (0.6048) lr 1.9980e-03 eta 0:10:44
epoch [3/50] batch [40/132] time 0.079 (0.094) data 0.000 (0.007) loss 0.4367 (0.5797) ce_loss 0.2446 (0.2187) teacher_loss 0.2304 (0.1929) loss_zs_kd 0.0373 (0.0325) loss_oracle 0.1876 (0.3706) acc 93.7500 (92.5781) kd_loss 0.4843 (0.6052) lr 1.9980e-03 eta 0:09:53
epoch [3/50] batch [60/132] time 0.090 (0.091) data 0.000 (0.005) loss 0.5297 (0.5423) ce_loss 0.2063 (0.2153) teacher_loss 0.1478 (0.1860) loss_zs_kd 0.0258 (0.0335) loss_oracle 0.3690 (0.3395) acc 90.6250 (92.7604) kd_loss 0.5677 (0.5700) lr 1.9980e-03 eta 0:09:28
epoch [3/50] batch [80/132] time 0.086 (0.090) data 0.000 (0.004) loss 0.5324 (0.5292) ce_loss 0.2854 (0.2124) teacher_loss 0.2024 (0.1789) loss_zs_kd 0.0433 (0.0370) loss_oracle 0.3083 (0.3318) acc 87.5000 (92.7734) kd_loss 0.5314 (0.5594) lr 1.9980e-03 eta 0:09:24
epoch [3/50] batch [100/132] time 0.085 (0.090) data 0.000 (0.003) loss 0.4409 (0.5186) ce_loss 0.1230 (0.2124) teacher_loss 0.1111 (0.1776) loss_zs_kd 0.0282 (0.0385) loss_oracle 0.3157 (0.3217) acc 96.8750 (92.6875) kd_loss 0.6199 (0.5574) lr 1.9980e-03 eta 0:09:21
epoch [3/50] batch [120/132] time 0.086 (0.090) data 0.000 (0.003) loss 0.4609 (0.5104) ce_loss 0.1995 (0.2101) teacher_loss 0.1663 (0.1770) loss_zs_kd 0.0467 (0.0399) loss_oracle 0.2713 (0.3134) acc 96.8750 (92.9167) kd_loss 0.6195 (0.5651) lr 1.9980e-03 eta 0:09:17
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,805
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,524
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.9%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.1%, epoch: 3 *******
******* Domain s best val test acc: 89.7%, epoch: 3 *******
******* Domain s best test acc:     89.7%, epoch: 3 *******
epoch [4/50] batch [20/132] time 0.089 (0.101) data 0.000 (0.014) loss 0.4652 (0.4948) ce_loss 0.1715 (0.2074) teacher_loss 0.1361 (0.1789) loss_zs_kd 0.0300 (0.0471) loss_oracle 0.3141 (0.2923) acc 96.8750 (93.2812) kd_loss 0.7913 (0.6739) lr 1.9921e-03 eta 0:10:26
epoch [4/50] batch [40/132] time 0.085 (0.094) data 0.000 (0.007) loss 0.8202 (0.5298) ce_loss 0.4871 (0.2166) teacher_loss 0.3431 (0.1826) loss_zs_kd 0.0591 (0.0483) loss_oracle 0.4476 (0.3230) acc 90.6250 (92.8906) kd_loss 0.8435 (0.7207) lr 1.9921e-03 eta 0:09:40
epoch [4/50] batch [60/132] time 0.089 (0.093) data 0.001 (0.005) loss 0.7276 (0.5794) ce_loss 0.2228 (0.2072) teacher_loss 0.1421 (0.1751) loss_zs_kd 0.0503 (0.0486) loss_oracle 0.5603 (0.3800) acc 87.5000 (93.3333) kd_loss 0.9197 (0.7777) lr 1.9921e-03 eta 0:09:30
epoch [4/50] batch [80/132] time 0.092 (0.092) data 0.000 (0.004) loss 0.5098 (0.5743) ce_loss 0.1743 (0.2021) teacher_loss 0.1579 (0.1740) loss_zs_kd 0.0249 (0.0453) loss_oracle 0.3395 (0.3776) acc 93.7500 (93.3984) kd_loss 0.9166 (0.8143) lr 1.9921e-03 eta 0:09:22
epoch [4/50] batch [100/132] time 0.078 (0.090) data 0.000 (0.003) loss 0.7508 (0.5804) ce_loss 0.3696 (0.2111) teacher_loss 0.2982 (0.1813) loss_zs_kd 0.0579 (0.0434) loss_oracle 0.4236 (0.3774) acc 87.5000 (93.0312) kd_loss 0.9632 (0.8401) lr 1.9921e-03 eta 0:09:12
epoch [4/50] batch [120/132] time 0.072 (0.089) data 0.000 (0.003) loss 0.6317 (0.5766) ce_loss 0.3411 (0.2121) teacher_loss 0.2545 (0.1835) loss_zs_kd 0.0413 (0.0424) loss_oracle 0.3566 (0.3719) acc 84.3750 (93.0208) kd_loss 0.8853 (0.8545) lr 1.9921e-03 eta 0:09:02
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,804
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.0%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,527
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.0%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.1%, epoch: 3 *******
******* Domain s best val test acc: 89.7%, epoch: 3 *******
******* Domain s best test acc:     89.8%, epoch: 4 *******
epoch [5/50] batch [20/132] time 0.085 (0.109) data 0.000 (0.022) loss 0.6082 (0.6388) ce_loss 0.2032 (0.2255) teacher_loss 0.1801 (0.1858) loss_zs_kd 0.0397 (0.0390) loss_oracle 0.4082 (0.4335) acc 93.7500 (92.9688) kd_loss 0.8690 (0.8865) lr 1.9823e-03 eta 0:10:57
epoch [5/50] batch [40/132] time 0.085 (0.095) data 0.000 (0.011) loss 0.6773 (0.6213) ce_loss 0.2712 (0.2193) teacher_loss 0.2474 (0.1771) loss_zs_kd 0.0318 (0.0445) loss_oracle 0.4140 (0.4219) acc 90.6250 (93.2031) kd_loss 0.8905 (0.8769) lr 1.9823e-03 eta 0:09:35
epoch [5/50] batch [60/132] time 0.086 (0.093) data 0.000 (0.007) loss 0.6855 (0.6239) ce_loss 0.3088 (0.2201) teacher_loss 0.2382 (0.1777) loss_zs_kd 0.0459 (0.0444) loss_oracle 0.4244 (0.4239) acc 87.5000 (92.9688) kd_loss 0.8659 (0.8801) lr 1.9823e-03 eta 0:09:17
epoch [5/50] batch [80/132] time 0.086 (0.091) data 0.000 (0.006) loss 0.8146 (0.6238) ce_loss 0.3770 (0.2148) teacher_loss 0.3540 (0.1770) loss_zs_kd 0.0450 (0.0437) loss_oracle 0.4380 (0.4250) acc 84.3750 (93.0859) kd_loss 0.8846 (0.8805) lr 1.9823e-03 eta 0:09:03
epoch [5/50] batch [100/132] time 0.093 (0.090) data 0.000 (0.005) loss 0.4703 (0.6297) ce_loss 0.0502 (0.2197) teacher_loss 0.0349 (0.1809) loss_zs_kd 0.0270 (0.0427) loss_oracle 0.4219 (0.4275) acc 100.0000 (93.0312) kd_loss 0.8908 (0.8840) lr 1.9823e-03 eta 0:08:54
epoch [5/50] batch [120/132] time 0.071 (0.089) data 0.000 (0.004) loss 0.5719 (0.6290) ce_loss 0.2205 (0.2188) teacher_loss 0.1867 (0.1809) loss_zs_kd 0.0307 (0.0434) loss_oracle 0.3699 (0.4264) acc 93.7500 (93.0208) kd_loss 0.8499 (0.8860) lr 1.9823e-03 eta 0:08:48
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,804
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.0%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,533
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 92.2%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.1%, epoch: 3 *******
******* Domain s best val test acc: 89.7%, epoch: 3 *******
******* Domain s best test acc:     89.9%, epoch: 5 *******
epoch [6/50] batch [20/132] time 0.072 (0.096) data 0.000 (0.018) loss 0.5178 (0.6106) ce_loss 0.0554 (0.2100) teacher_loss 0.0358 (0.1707) loss_zs_kd 0.0370 (0.0398) loss_oracle 0.4635 (0.4200) acc 100.0000 (92.3438) kd_loss 0.8958 (0.8646) lr 1.9686e-03 eta 0:09:31
epoch [6/50] batch [40/132] time 0.090 (0.088) data 0.000 (0.009) loss 0.7018 (0.5945) ce_loss 0.2903 (0.1942) teacher_loss 0.2193 (0.1575) loss_zs_kd 0.0845 (0.0386) loss_oracle 0.4402 (0.4177) acc 87.5000 (93.2812) kd_loss 0.8273 (0.8576) lr 1.9686e-03 eta 0:08:37
epoch [6/50] batch [60/132] time 0.070 (0.085) data 0.000 (0.006) loss 0.4913 (0.6038) ce_loss 0.1294 (0.1956) teacher_loss 0.0881 (0.1596) loss_zs_kd 0.0368 (0.0406) loss_oracle 0.3847 (0.4239) acc 96.8750 (93.3333) kd_loss 0.7581 (0.8525) lr 1.9686e-03 eta 0:08:17
epoch [6/50] batch [80/132] time 0.082 (0.081) data 0.000 (0.005) loss 0.7521 (0.6362) ce_loss 0.2747 (0.2135) teacher_loss 0.2087 (0.1717) loss_zs_kd 0.0736 (0.0441) loss_oracle 0.5065 (0.4424) acc 87.5000 (92.7734) kd_loss 0.9241 (0.8570) lr 1.9686e-03 eta 0:07:57
epoch [6/50] batch [100/132] time 0.066 (0.080) data 0.000 (0.004) loss 0.6096 (0.6434) ce_loss 0.1741 (0.2116) teacher_loss 0.1421 (0.1715) loss_zs_kd 0.0391 (0.0433) loss_oracle 0.4481 (0.4502) acc 93.7500 (92.7812) kd_loss 0.8666 (0.8642) lr 1.9686e-03 eta 0:07:45
epoch [6/50] batch [120/132] time 0.068 (0.078) data 0.000 (0.003) loss 0.7983 (0.6438) ce_loss 0.3613 (0.2043) teacher_loss 0.2722 (0.1646) loss_zs_kd 0.0408 (0.0425) loss_oracle 0.5057 (0.4580) acc 87.5000 (93.0208) kd_loss 0.9167 (0.8706) lr 1.9686e-03 eta 0:07:34
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,534
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 92.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.2%, epoch: 6 *******
******* Domain s best val test acc: 90.0%, epoch: 6 *******
******* Domain s best test acc:     90.0%, epoch: 6 *******
epoch [7/50] batch [20/132] time 0.074 (0.084) data 0.000 (0.013) loss 0.9264 (0.7021) ce_loss 0.4075 (0.2613) teacher_loss 0.3982 (0.2111) loss_zs_kd 0.0554 (0.0498) loss_oracle 0.5005 (0.4661) acc 87.5000 (91.0938) kd_loss 0.8620 (0.8851) lr 1.9511e-03 eta 0:08:06
epoch [7/50] batch [40/132] time 0.084 (0.080) data 0.000 (0.007) loss 0.5560 (0.7122) ce_loss 0.0217 (0.2348) teacher_loss 0.0121 (0.1844) loss_zs_kd 0.0227 (0.0499) loss_oracle 0.5326 (0.5028) acc 100.0000 (91.5625) kd_loss 0.9247 (0.8841) lr 1.9511e-03 eta 0:07:40
epoch [7/50] batch [60/132] time 0.069 (0.079) data 0.000 (0.005) loss 0.7424 (0.6943) ce_loss 0.1985 (0.2152) teacher_loss 0.1966 (0.1729) loss_zs_kd 0.0506 (0.0476) loss_oracle 0.5206 (0.4976) acc 93.7500 (92.3438) kd_loss 0.8631 (0.8804) lr 1.9511e-03 eta 0:07:31
epoch [7/50] batch [80/132] time 0.082 (0.077) data 0.000 (0.003) loss 0.7692 (0.6901) ce_loss 0.2374 (0.2096) teacher_loss 0.2516 (0.1719) loss_zs_kd 0.0282 (0.0447) loss_oracle 0.5035 (0.4959) acc 93.7500 (92.7734) kd_loss 0.8436 (0.8751) lr 1.9511e-03 eta 0:07:22
epoch [7/50] batch [100/132] time 0.085 (0.078) data 0.000 (0.003) loss 0.5563 (0.6972) ce_loss 0.0762 (0.2128) teacher_loss 0.0688 (0.1744) loss_zs_kd 0.0275 (0.0435) loss_oracle 0.4738 (0.5011) acc 96.8750 (92.7500) kd_loss 0.7979 (0.8677) lr 1.9511e-03 eta 0:07:27
epoch [7/50] batch [120/132] time 0.071 (0.079) data 0.000 (0.002) loss 0.6839 (0.6933) ce_loss 0.2747 (0.2147) teacher_loss 0.2401 (0.1761) loss_zs_kd 0.0311 (0.0435) loss_oracle 0.4283 (0.4954) acc 90.6250 (92.7083) kd_loss 0.8508 (0.8609) lr 1.9511e-03 eta 0:07:26
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,538
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.2%, epoch: 6 *******
******* Domain s best val test acc: 90.0%, epoch: 6 *******
******* Domain s best test acc:     90.1%, epoch: 7 *******
epoch [8/50] batch [20/132] time 0.088 (0.106) data 0.000 (0.015) loss 0.6572 (0.6244) ce_loss 0.1832 (0.1759) teacher_loss 0.1406 (0.1445) loss_zs_kd 0.0551 (0.0531) loss_oracle 0.4890 (0.4534) acc 93.7500 (94.0625) kd_loss 0.8938 (0.8516) lr 1.9298e-03 eta 0:09:58
epoch [8/50] batch [40/132] time 0.084 (0.095) data 0.000 (0.008) loss 0.4861 (0.6123) ce_loss 0.0702 (0.1837) teacher_loss 0.0446 (0.1521) loss_zs_kd 0.0405 (0.0498) loss_oracle 0.4212 (0.4353) acc 100.0000 (93.9844) kd_loss 0.7772 (0.8267) lr 1.9298e-03 eta 0:08:57
epoch [8/50] batch [60/132] time 0.092 (0.092) data 0.001 (0.005) loss 0.5463 (0.6062) ce_loss 0.1704 (0.1865) teacher_loss 0.0899 (0.1534) loss_zs_kd 0.0402 (0.0496) loss_oracle 0.4363 (0.4280) acc 96.8750 (94.2188) kd_loss 0.8844 (0.8286) lr 1.9298e-03 eta 0:08:38
epoch [8/50] batch [80/132] time 0.091 (0.091) data 0.000 (0.004) loss 0.5762 (0.6047) ce_loss 0.1987 (0.1880) teacher_loss 0.1511 (0.1526) loss_zs_kd 0.0570 (0.0485) loss_oracle 0.3966 (0.4278) acc 93.7500 (93.9453) kd_loss 0.7909 (0.8280) lr 1.9298e-03 eta 0:08:28
epoch [8/50] batch [100/132] time 0.084 (0.090) data 0.000 (0.003) loss 0.5168 (0.6001) ce_loss 0.1233 (0.1844) teacher_loss 0.0985 (0.1496) loss_zs_kd 0.0398 (0.0488) loss_oracle 0.3984 (0.4262) acc 96.8750 (94.0312) kd_loss 0.7940 (0.8269) lr 1.9298e-03 eta 0:08:19
epoch [8/50] batch [120/132] time 0.070 (0.088) data 0.000 (0.003) loss 0.6471 (0.6036) ce_loss 0.1897 (0.1874) teacher_loss 0.1196 (0.1505) loss_zs_kd 0.0741 (0.0491) loss_oracle 0.4905 (0.4286) acc 93.7500 (93.9323) kd_loss 0.9117 (0.8310) lr 1.9298e-03 eta 0:08:11
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,805
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,513
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.9%
******* Domain s best val acc:      99.2%, epoch: 6 *******
******* Domain s best val test acc: 90.0%, epoch: 6 *******
******* Domain s best test acc:     90.1%, epoch: 7 *******
epoch [9/50] batch [20/132] time 0.088 (0.098) data 0.000 (0.016) loss 0.6420 (0.5903) ce_loss 0.2126 (0.2058) teacher_loss 0.2059 (0.1497) loss_zs_kd 0.0588 (0.0505) loss_oracle 0.4067 (0.4153) acc 93.7500 (93.5938) kd_loss 0.7871 (0.8391) lr 1.9048e-03 eta 0:08:59
epoch [9/50] batch [40/132] time 0.086 (0.088) data 0.000 (0.008) loss 0.5938 (0.5999) ce_loss 0.2307 (0.2157) teacher_loss 0.1760 (0.1660) loss_zs_kd 0.0454 (0.0502) loss_oracle 0.3951 (0.4088) acc 87.5000 (92.8906) kd_loss 0.8965 (0.8380) lr 1.9048e-03 eta 0:08:04
epoch [9/50] batch [60/132] time 0.082 (0.086) data 0.000 (0.006) loss 0.6411 (0.6061) ce_loss 0.3679 (0.2238) teacher_loss 0.2621 (0.1767) loss_zs_kd 0.0582 (0.0510) loss_oracle 0.3499 (0.4039) acc 84.3750 (92.5521) kd_loss 0.7670 (0.8415) lr 1.9048e-03 eta 0:07:53
epoch [9/50] batch [80/132] time 0.088 (0.086) data 0.000 (0.004) loss 0.7939 (0.6152) ce_loss 0.3682 (0.2331) teacher_loss 0.2085 (0.1812) loss_zs_kd 0.1072 (0.0522) loss_oracle 0.5318 (0.4078) acc 87.5000 (91.9531) kd_loss 0.8916 (0.8451) lr 1.9048e-03 eta 0:07:47
epoch [9/50] batch [100/132] time 0.087 (0.085) data 0.001 (0.003) loss 0.5874 (0.6057) ce_loss 0.2710 (0.2223) teacher_loss 0.2226 (0.1731) loss_zs_kd 0.0462 (0.0519) loss_oracle 0.3417 (0.4066) acc 90.6250 (92.2812) kd_loss 0.7042 (0.8367) lr 1.9048e-03 eta 0:07:43
epoch [9/50] batch [120/132] time 0.074 (0.085) data 0.000 (0.003) loss 0.6956 (0.6196) ce_loss 0.3667 (0.2326) teacher_loss 0.2157 (0.1825) loss_zs_kd 0.1395 (0.0547) loss_oracle 0.4102 (0.4098) acc 87.5000 (92.0052) kd_loss 0.8401 (0.8403) lr 1.9048e-03 eta 0:07:40
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,501
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 91.7%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.1%, epoch: 7 *******
epoch [10/50] batch [20/132] time 0.089 (0.104) data 0.000 (0.018) loss 0.6512 (0.6573) ce_loss 0.3047 (0.2559) teacher_loss 0.2067 (0.1912) loss_zs_kd 0.0616 (0.0535) loss_oracle 0.4138 (0.4394) acc 90.6250 (91.2500) kd_loss 0.8180 (0.8516) lr 1.8763e-03 eta 0:09:20
epoch [10/50] batch [40/132] time 0.087 (0.092) data 0.000 (0.009) loss 0.5184 (0.6075) ce_loss 0.1685 (0.2031) teacher_loss 0.1600 (0.1487) loss_zs_kd 0.0494 (0.0544) loss_oracle 0.3337 (0.4316) acc 93.7500 (93.1250) kd_loss 0.7670 (0.8417) lr 1.8763e-03 eta 0:08:16
epoch [10/50] batch [60/132] time 0.089 (0.089) data 0.000 (0.006) loss 0.6686 (0.6132) ce_loss 0.2343 (0.2009) teacher_loss 0.2273 (0.1471) loss_zs_kd 0.0607 (0.0544) loss_oracle 0.4110 (0.4389) acc 90.6250 (93.2292) kd_loss 0.9234 (0.8579) lr 1.8763e-03 eta 0:07:57
epoch [10/50] batch [80/132] time 0.084 (0.088) data 0.000 (0.005) loss 0.6505 (0.6062) ce_loss 0.2173 (0.1914) teacher_loss 0.1685 (0.1390) loss_zs_kd 0.0516 (0.0544) loss_oracle 0.4562 (0.4401) acc 93.7500 (93.8281) kd_loss 0.8968 (0.8601) lr 1.8763e-03 eta 0:07:47
epoch [10/50] batch [100/132] time 0.086 (0.087) data 0.000 (0.004) loss 0.6409 (0.6084) ce_loss 0.3145 (0.2007) teacher_loss 0.2337 (0.1440) loss_zs_kd 0.0541 (0.0551) loss_oracle 0.3801 (0.4368) acc 87.5000 (93.4688) kd_loss 0.7898 (0.8573) lr 1.8763e-03 eta 0:07:42
epoch [10/50] batch [120/132] time 0.074 (0.086) data 0.000 (0.003) loss 0.8200 (0.6116) ce_loss 0.3403 (0.2052) teacher_loss 0.2892 (0.1474) loss_zs_kd 0.0926 (0.0568) loss_oracle 0.4845 (0.4358) acc 87.5000 (93.1771) kd_loss 0.8814 (0.8567) lr 1.8763e-03 eta 0:07:37
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,801
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.9%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,508
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.4%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.1%, epoch: 7 *******
epoch [11/50] batch [20/132] time 0.085 (0.097) data 0.000 (0.013) loss 0.6892 (0.6362) ce_loss 0.2120 (0.2107) teacher_loss 0.1609 (0.1524) loss_zs_kd 0.0682 (0.0539) loss_oracle 0.4942 (0.4569) acc 90.6250 (92.8125) kd_loss 0.9592 (0.9025) lr 1.8443e-03 eta 0:08:31
epoch [11/50] batch [40/132] time 0.087 (0.091) data 0.000 (0.007) loss 0.6249 (0.6287) ce_loss 0.1685 (0.2070) teacher_loss 0.1725 (0.1463) loss_zs_kd 0.0438 (0.0549) loss_oracle 0.4305 (0.4549) acc 90.6250 (92.7344) kd_loss 0.8601 (0.9099) lr 1.8443e-03 eta 0:07:57
epoch [11/50] batch [60/132] time 0.084 (0.089) data 0.000 (0.005) loss 0.7689 (0.6325) ce_loss 0.3145 (0.2094) teacher_loss 0.2417 (0.1453) loss_zs_kd 0.0663 (0.0549) loss_oracle 0.4940 (0.4597) acc 84.3750 (92.9167) kd_loss 0.9276 (0.9039) lr 1.8443e-03 eta 0:07:45
epoch [11/50] batch [80/132] time 0.080 (0.089) data 0.000 (0.004) loss 0.5281 (0.6335) ce_loss 0.1052 (0.2001) teacher_loss 0.0386 (0.1403) loss_zs_kd 0.0720 (0.0563) loss_oracle 0.4535 (0.4650) acc 100.0000 (93.3594) kd_loss 0.8931 (0.9042) lr 1.8443e-03 eta 0:07:41
epoch [11/50] batch [100/132] time 0.084 (0.088) data 0.000 (0.003) loss 0.6924 (0.6394) ce_loss 0.2323 (0.2080) teacher_loss 0.1707 (0.1449) loss_zs_kd 0.0443 (0.0558) loss_oracle 0.4995 (0.4666) acc 90.6250 (93.0000) kd_loss 0.9903 (0.9037) lr 1.8443e-03 eta 0:07:36
epoch [11/50] batch [120/132] time 0.074 (0.087) data 0.000 (0.002) loss 0.7047 (0.6405) ce_loss 0.2681 (0.2106) teacher_loss 0.1913 (0.1471) loss_zs_kd 0.0868 (0.0572) loss_oracle 0.4701 (0.4648) acc 93.7500 (92.9688) kd_loss 0.8784 (0.9042) lr 1.8443e-03 eta 0:07:31
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,507
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.5%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.1%, epoch: 7 *******
epoch [12/50] batch [20/132] time 0.088 (0.105) data 0.000 (0.016) loss 0.6751 (0.5975) ce_loss 0.2000 (0.1821) teacher_loss 0.1750 (0.1255) loss_zs_kd 0.0348 (0.0473) loss_oracle 0.4827 (0.4484) acc 93.7500 (94.2188) kd_loss 0.8908 (0.9137) lr 1.8090e-03 eta 0:08:57
epoch [12/50] batch [40/132] time 0.087 (0.095) data 0.000 (0.008) loss 0.6552 (0.6200) ce_loss 0.2786 (0.2064) teacher_loss 0.1671 (0.1410) loss_zs_kd 0.0721 (0.0525) loss_oracle 0.4520 (0.4528) acc 93.7500 (93.1250) kd_loss 0.8604 (0.9115) lr 1.8090e-03 eta 0:08:04
epoch [12/50] batch [60/132] time 0.083 (0.092) data 0.000 (0.005) loss 0.9254 (0.6415) ce_loss 0.4478 (0.2230) teacher_loss 0.3188 (0.1505) loss_zs_kd 0.1181 (0.0564) loss_oracle 0.5475 (0.4627) acc 81.2500 (92.4479) kd_loss 0.9559 (0.9098) lr 1.8090e-03 eta 0:07:47
epoch [12/50] batch [80/132] time 0.095 (0.091) data 0.000 (0.004) loss 0.6439 (0.6483) ce_loss 0.2103 (0.2208) teacher_loss 0.1219 (0.1494) loss_zs_kd 0.0649 (0.0557) loss_oracle 0.4895 (0.4711) acc 90.6250 (92.5781) kd_loss 0.8988 (0.9120) lr 1.8090e-03 eta 0:07:40
epoch [12/50] batch [100/132] time 0.088 (0.091) data 0.000 (0.003) loss 0.6254 (0.6493) ce_loss 0.1960 (0.2209) teacher_loss 0.1664 (0.1503) loss_zs_kd 0.0535 (0.0558) loss_oracle 0.4321 (0.4711) acc 93.7500 (92.5312) kd_loss 0.8508 (0.9109) lr 1.8090e-03 eta 0:07:38
epoch [12/50] batch [120/132] time 0.077 (0.090) data 0.000 (0.003) loss 0.6360 (0.6487) ce_loss 0.1803 (0.2190) teacher_loss 0.0784 (0.1472) loss_zs_kd 0.0855 (0.0576) loss_oracle 0.5149 (0.4727) acc 90.6250 (92.7344) kd_loss 0.9710 (0.9136) lr 1.8090e-03 eta 0:07:32
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,803
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.0%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,533
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 92.0%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.1%, epoch: 7 *******
epoch [13/50] batch [20/132] time 0.086 (0.100) data 0.000 (0.015) loss 0.6259 (0.6471) ce_loss 0.2712 (0.2294) teacher_loss 0.1439 (0.1534) loss_zs_kd 0.0625 (0.0541) loss_oracle 0.4507 (0.4666) acc 93.7500 (92.9688) kd_loss 0.9168 (0.9068) lr 1.7705e-03 eta 0:08:21
epoch [13/50] batch [40/132] time 0.085 (0.093) data 0.000 (0.007) loss 0.6800 (0.6592) ce_loss 0.2173 (0.2241) teacher_loss 0.1802 (0.1436) loss_zs_kd 0.0758 (0.0629) loss_oracle 0.4618 (0.4842) acc 90.6250 (92.6562) kd_loss 0.8186 (0.9154) lr 1.7705e-03 eta 0:07:41
epoch [13/50] batch [60/132] time 0.081 (0.091) data 0.001 (0.005) loss 0.7129 (0.6679) ce_loss 0.2054 (0.2258) teacher_loss 0.1424 (0.1444) loss_zs_kd 0.0575 (0.0631) loss_oracle 0.5418 (0.4921) acc 93.7500 (92.7083) kd_loss 0.9555 (0.9209) lr 1.7705e-03 eta 0:07:30
epoch [13/50] batch [80/132] time 0.096 (0.090) data 0.001 (0.004) loss 0.7120 (0.6647) ce_loss 0.2842 (0.2173) teacher_loss 0.1431 (0.1380) loss_zs_kd 0.0931 (0.0624) loss_oracle 0.5224 (0.4955) acc 90.6250 (92.9688) kd_loss 0.9603 (0.9182) lr 1.7705e-03 eta 0:07:26
epoch [13/50] batch [100/132] time 0.090 (0.090) data 0.000 (0.003) loss 0.6406 (0.6672) ce_loss 0.1466 (0.2194) teacher_loss 0.0960 (0.1351) loss_zs_kd 0.0644 (0.0640) loss_oracle 0.5124 (0.5000) acc 93.7500 (92.7812) kd_loss 0.8501 (0.9175) lr 1.7705e-03 eta 0:07:21
epoch [13/50] batch [120/132] time 0.069 (0.089) data 0.000 (0.003) loss 0.5870 (0.6662) ce_loss 0.1375 (0.2179) teacher_loss 0.0832 (0.1336) loss_zs_kd 0.0382 (0.0651) loss_oracle 0.4847 (0.5001) acc 96.8750 (92.6823) kd_loss 0.9427 (0.9190) lr 1.7705e-03 eta 0:07:15
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,804
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.0%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,524
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.8%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.1%, epoch: 7 *******
epoch [14/50] batch [20/132] time 0.086 (0.105) data 0.000 (0.016) loss 0.7529 (0.6844) ce_loss 0.2937 (0.2569) teacher_loss 0.2265 (0.1637) loss_zs_kd 0.0807 (0.0726) loss_oracle 0.4861 (0.4844) acc 93.7500 (91.7188) kd_loss 0.9165 (0.9150) lr 1.7290e-03 eta 0:08:29
epoch [14/50] batch [40/132] time 0.081 (0.094) data 0.000 (0.008) loss 0.4746 (0.6503) ce_loss 0.0636 (0.2204) teacher_loss 0.0356 (0.1307) loss_zs_kd 0.0354 (0.0698) loss_oracle 0.4213 (0.4847) acc 100.0000 (92.8125) kd_loss 0.8705 (0.9084) lr 1.7290e-03 eta 0:07:37
epoch [14/50] batch [60/132] time 0.084 (0.092) data 0.000 (0.005) loss 0.6396 (0.6405) ce_loss 0.1339 (0.2071) teacher_loss 0.1056 (0.1187) loss_zs_kd 0.0556 (0.0670) loss_oracle 0.5062 (0.4882) acc 93.7500 (93.1250) kd_loss 0.9139 (0.9141) lr 1.7290e-03 eta 0:07:22
epoch [14/50] batch [80/132] time 0.087 (0.091) data 0.000 (0.004) loss 0.6544 (0.6445) ce_loss 0.1583 (0.2110) teacher_loss 0.0561 (0.1190) loss_zs_kd 0.0817 (0.0686) loss_oracle 0.5574 (0.4912) acc 96.8750 (92.8516) kd_loss 0.9381 (0.9168) lr 1.7290e-03 eta 0:07:17
epoch [14/50] batch [100/132] time 0.084 (0.090) data 0.000 (0.003) loss 0.6869 (0.6457) ce_loss 0.1490 (0.2028) teacher_loss 0.1011 (0.1141) loss_zs_kd 0.0879 (0.0687) loss_oracle 0.5418 (0.4972) acc 93.7500 (93.1875) kd_loss 0.8600 (0.9163) lr 1.7290e-03 eta 0:07:10
epoch [14/50] batch [120/132] time 0.074 (0.089) data 0.000 (0.003) loss 0.6347 (0.6538) ce_loss 0.2430 (0.2040) teacher_loss 0.1147 (0.1177) loss_zs_kd 0.0311 (0.0682) loss_oracle 0.5044 (0.5020) acc 90.6250 (93.0469) kd_loss 0.9333 (0.9174) lr 1.7290e-03 eta 0:07:02
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,525
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.9%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.1%, epoch: 7 *******
epoch [15/50] batch [20/132] time 0.088 (0.102) data 0.000 (0.015) loss 0.8134 (0.6646) ce_loss 0.4490 (0.1989) teacher_loss 0.1954 (0.1144) loss_zs_kd 0.0915 (0.0633) loss_oracle 0.5723 (0.5186) acc 84.3750 (92.9688) kd_loss 0.9551 (0.9211) lr 1.6845e-03 eta 0:08:01
epoch [15/50] batch [40/132] time 0.086 (0.094) data 0.000 (0.008) loss 0.4931 (0.6692) ce_loss 0.0682 (0.2270) teacher_loss 0.0589 (0.1353) loss_zs_kd 0.0386 (0.0659) loss_oracle 0.4148 (0.5009) acc 100.0000 (92.1094) kd_loss 0.7958 (0.9108) lr 1.6845e-03 eta 0:07:22
epoch [15/50] batch [60/132] time 0.083 (0.092) data 0.000 (0.005) loss 0.5577 (0.6510) ce_loss 0.1782 (0.2120) teacher_loss 0.0828 (0.1299) loss_zs_kd 0.0491 (0.0642) loss_oracle 0.4503 (0.4890) acc 93.7500 (92.7083) kd_loss 0.8747 (0.9023) lr 1.6845e-03 eta 0:07:10
epoch [15/50] batch [80/132] time 0.090 (0.091) data 0.000 (0.004) loss 0.6275 (0.6431) ce_loss 0.1583 (0.2103) teacher_loss 0.1154 (0.1262) loss_zs_kd 0.0812 (0.0640) loss_oracle 0.4715 (0.4849) acc 93.7500 (92.8906) kd_loss 0.9386 (0.9013) lr 1.6845e-03 eta 0:07:03
epoch [15/50] batch [100/132] time 0.087 (0.090) data 0.001 (0.003) loss 0.6527 (0.6276) ce_loss 0.2744 (0.2038) teacher_loss 0.2092 (0.1220) loss_zs_kd 0.0517 (0.0619) loss_oracle 0.4176 (0.4746) acc 90.6250 (93.2188) kd_loss 0.8196 (0.8928) lr 1.6845e-03 eta 0:06:58
epoch [15/50] batch [120/132] time 0.076 (0.090) data 0.000 (0.003) loss 0.6888 (0.6229) ce_loss 0.2295 (0.1997) teacher_loss 0.1922 (0.1222) loss_zs_kd 0.0395 (0.0605) loss_oracle 0.4769 (0.4704) acc 93.7500 (93.2812) kd_loss 0.8958 (0.8927) lr 1.6845e-03 eta 0:06:55
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,549
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.4%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [16/50] batch [20/132] time 0.078 (0.106) data 0.000 (0.019) loss 0.5407 (0.6392) ce_loss 0.1254 (0.2418) teacher_loss 0.1245 (0.1589) loss_zs_kd 0.0708 (0.0599) loss_oracle 0.3807 (0.4503) acc 96.8750 (91.8750) kd_loss 0.7720 (0.8699) lr 1.6374e-03 eta 0:08:07
epoch [16/50] batch [40/132] time 0.092 (0.097) data 0.000 (0.010) loss 0.5202 (0.6395) ce_loss 0.0691 (0.2120) teacher_loss 0.0522 (0.1379) loss_zs_kd 0.0357 (0.0590) loss_oracle 0.4502 (0.4721) acc 96.8750 (93.1250) kd_loss 0.8392 (0.8900) lr 1.6374e-03 eta 0:07:22
epoch [16/50] batch [60/132] time 0.092 (0.094) data 0.001 (0.007) loss 0.7130 (0.6423) ce_loss 0.3066 (0.2166) teacher_loss 0.1156 (0.1357) loss_zs_kd 0.1094 (0.0606) loss_oracle 0.5427 (0.4762) acc 87.5000 (92.8646) kd_loss 0.9960 (0.8953) lr 1.6374e-03 eta 0:07:08
epoch [16/50] batch [80/132] time 0.093 (0.092) data 0.000 (0.005) loss 0.6689 (0.6447) ce_loss 0.1581 (0.2181) teacher_loss 0.1553 (0.1360) loss_zs_kd 0.0668 (0.0611) loss_oracle 0.4802 (0.4781) acc 93.7500 (92.6953) kd_loss 0.8871 (0.8989) lr 1.6374e-03 eta 0:06:57
epoch [16/50] batch [100/132] time 0.092 (0.091) data 0.000 (0.004) loss 0.6196 (0.6495) ce_loss 0.1743 (0.2177) teacher_loss 0.1008 (0.1359) loss_zs_kd 0.0516 (0.0626) loss_oracle 0.4929 (0.4823) acc 93.7500 (92.6562) kd_loss 0.8101 (0.9012) lr 1.6374e-03 eta 0:06:52
epoch [16/50] batch [120/132] time 0.077 (0.091) data 0.000 (0.003) loss 0.5665 (0.6512) ce_loss 0.1453 (0.2193) teacher_loss 0.0739 (0.1348) loss_zs_kd 0.0519 (0.0630) loss_oracle 0.4667 (0.4849) acc 93.7500 (92.4740) kd_loss 0.8568 (0.8990) lr 1.6374e-03 eta 0:06:48
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,513
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.7%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [17/50] batch [20/132] time 0.086 (0.099) data 0.000 (0.014) loss 0.5477 (0.6324) ce_loss 0.0424 (0.1978) teacher_loss 0.0358 (0.1207) loss_zs_kd 0.0433 (0.0502) loss_oracle 0.4903 (0.4866) acc 100.0000 (93.7500) kd_loss 0.9177 (0.8750) lr 1.5878e-03 eta 0:07:22
epoch [17/50] batch [40/132] time 0.087 (0.092) data 0.000 (0.007) loss 0.6314 (0.6477) ce_loss 0.2585 (0.2237) teacher_loss 0.1312 (0.1371) loss_zs_kd 0.0773 (0.0606) loss_oracle 0.4615 (0.4803) acc 90.6250 (92.4219) kd_loss 0.8713 (0.8755) lr 1.5878e-03 eta 0:06:48
epoch [17/50] batch [60/132] time 0.088 (0.090) data 0.000 (0.005) loss 0.5725 (0.6499) ce_loss 0.1755 (0.2253) teacher_loss 0.0897 (0.1345) loss_zs_kd 0.0566 (0.0611) loss_oracle 0.4545 (0.4849) acc 90.6250 (92.2917) kd_loss 0.8748 (0.8841) lr 1.5878e-03 eta 0:06:36
epoch [17/50] batch [80/132] time 0.084 (0.089) data 0.000 (0.004) loss 0.5371 (0.6441) ce_loss 0.0780 (0.2176) teacher_loss 0.0553 (0.1323) loss_zs_kd 0.0216 (0.0622) loss_oracle 0.4710 (0.4807) acc 93.7500 (92.5391) kd_loss 0.8880 (0.8862) lr 1.5878e-03 eta 0:06:32
epoch [17/50] batch [100/132] time 0.091 (0.089) data 0.000 (0.003) loss 0.4929 (0.6403) ce_loss 0.1736 (0.2175) teacher_loss 0.1206 (0.1320) loss_zs_kd 0.0671 (0.0635) loss_oracle 0.3388 (0.4765) acc 93.7500 (92.6875) kd_loss 0.7367 (0.8875) lr 1.5878e-03 eta 0:06:29
epoch [17/50] batch [120/132] time 0.075 (0.088) data 0.000 (0.003) loss 0.4822 (0.6350) ce_loss 0.0882 (0.2103) teacher_loss 0.0414 (0.1307) loss_zs_kd 0.0535 (0.0617) loss_oracle 0.4140 (0.4735) acc 96.8750 (92.8906) kd_loss 0.8882 (0.8906) lr 1.5878e-03 eta 0:06:24
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,803
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.0%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,508
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.6%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [18/50] batch [20/132] time 0.079 (0.105) data 0.000 (0.017) loss 0.5435 (0.6144) ce_loss 0.1868 (0.2238) teacher_loss 0.1047 (0.1589) loss_zs_kd 0.0480 (0.0573) loss_oracle 0.4148 (0.4269) acc 93.7500 (92.6562) kd_loss 0.8718 (0.8862) lr 1.5358e-03 eta 0:07:37
epoch [18/50] batch [40/132] time 0.085 (0.096) data 0.000 (0.008) loss 0.6953 (0.6043) ce_loss 0.3403 (0.2065) teacher_loss 0.2092 (0.1463) loss_zs_kd 0.0588 (0.0559) loss_oracle 0.4567 (0.4300) acc 87.5000 (93.0469) kd_loss 0.8912 (0.8856) lr 1.5358e-03 eta 0:06:52
epoch [18/50] batch [60/132] time 0.088 (0.092) data 0.001 (0.006) loss 0.4520 (0.5950) ce_loss 0.0312 (0.1972) teacher_loss 0.0198 (0.1389) loss_zs_kd 0.0235 (0.0538) loss_oracle 0.4205 (0.4291) acc 100.0000 (93.4896) kd_loss 0.8547 (0.8774) lr 1.5358e-03 eta 0:06:35
epoch [18/50] batch [80/132] time 0.092 (0.091) data 0.000 (0.004) loss 0.5355 (0.6088) ce_loss 0.2268 (0.2100) teacher_loss 0.1215 (0.1462) loss_zs_kd 0.0561 (0.0547) loss_oracle 0.3860 (0.4352) acc 96.8750 (93.1250) kd_loss 0.8740 (0.8774) lr 1.5358e-03 eta 0:06:27
epoch [18/50] batch [100/132] time 0.084 (0.090) data 0.000 (0.004) loss 0.5044 (0.6049) ce_loss 0.0865 (0.2013) teacher_loss 0.0396 (0.1409) loss_zs_kd 0.0454 (0.0542) loss_oracle 0.4421 (0.4369) acc 96.8750 (93.3125) kd_loss 0.8914 (0.8762) lr 1.5358e-03 eta 0:06:24
epoch [18/50] batch [120/132] time 0.087 (0.090) data 0.000 (0.003) loss 0.5236 (0.6053) ce_loss 0.1963 (0.2016) teacher_loss 0.1207 (0.1429) loss_zs_kd 0.0399 (0.0545) loss_oracle 0.3830 (0.4351) acc 90.6250 (93.3073) kd_loss 0.7974 (0.8688) lr 1.5358e-03 eta 0:06:20
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,514
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 91.8%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [19/50] batch [20/132] time 0.085 (0.099) data 0.000 (0.014) loss 0.5942 (0.6278) ce_loss 0.3340 (0.2243) teacher_loss 0.1268 (0.1525) loss_zs_kd 0.0968 (0.0557) loss_oracle 0.4190 (0.4475) acc 90.6250 (92.3438) kd_loss 0.7744 (0.8612) lr 1.4818e-03 eta 0:06:57
epoch [19/50] batch [40/132] time 0.088 (0.089) data 0.000 (0.007) loss 0.4119 (0.6051) ce_loss 0.0134 (0.1931) teacher_loss 0.0143 (0.1309) loss_zs_kd 0.0181 (0.0553) loss_oracle 0.3886 (0.4466) acc 100.0000 (93.5156) kd_loss 0.7917 (0.8544) lr 1.4818e-03 eta 0:06:11
epoch [19/50] batch [60/132] time 0.085 (0.086) data 0.001 (0.005) loss 0.7019 (0.5997) ce_loss 0.2454 (0.1969) teacher_loss 0.2131 (0.1391) loss_zs_kd 0.0482 (0.0543) loss_oracle 0.4647 (0.4335) acc 93.7500 (93.2292) kd_loss 0.8472 (0.8467) lr 1.4818e-03 eta 0:05:57
epoch [19/50] batch [80/132] time 0.075 (0.084) data 0.000 (0.004) loss 0.4594 (0.5833) ce_loss 0.0680 (0.1883) teacher_loss 0.0460 (0.1340) loss_zs_kd 0.0394 (0.0524) loss_oracle 0.3937 (0.4231) acc 96.8750 (93.5938) kd_loss 0.8349 (0.8455) lr 1.4818e-03 eta 0:05:47
epoch [19/50] batch [100/132] time 0.089 (0.084) data 0.000 (0.003) loss 0.7194 (0.5812) ce_loss 0.3501 (0.1912) teacher_loss 0.3439 (0.1384) loss_zs_kd 0.0764 (0.0519) loss_oracle 0.3373 (0.4169) acc 90.6250 (93.6875) kd_loss 0.8685 (0.8525) lr 1.4818e-03 eta 0:05:46
epoch [19/50] batch [120/132] time 0.074 (0.084) data 0.000 (0.003) loss 0.6372 (0.5840) ce_loss 0.3721 (0.1981) teacher_loss 0.2546 (0.1449) loss_zs_kd 0.0716 (0.0526) loss_oracle 0.3468 (0.4128) acc 90.6250 (93.6458) kd_loss 0.8251 (0.8533) lr 1.4818e-03 eta 0:05:44
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,526
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.0%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [20/50] batch [20/132] time 0.087 (0.108) data 0.000 (0.019) loss 0.3794 (0.5399) ce_loss 0.0382 (0.1832) teacher_loss 0.0238 (0.1329) loss_zs_kd 0.0289 (0.0471) loss_oracle 0.3412 (0.3835) acc 100.0000 (94.0625) kd_loss 0.7883 (0.8592) lr 1.4258e-03 eta 0:07:18
epoch [20/50] batch [40/132] time 0.074 (0.095) data 0.000 (0.009) loss 0.5547 (0.5528) ce_loss 0.1664 (0.1838) teacher_loss 0.1586 (0.1373) loss_zs_kd 0.0408 (0.0496) loss_oracle 0.3757 (0.3907) acc 93.7500 (94.2188) kd_loss 0.8298 (0.8580) lr 1.4258e-03 eta 0:06:24
epoch [20/50] batch [60/132] time 0.086 (0.089) data 0.001 (0.006) loss 0.5940 (0.5513) ce_loss 0.2316 (0.1800) teacher_loss 0.1353 (0.1337) loss_zs_kd 0.0648 (0.0495) loss_oracle 0.4264 (0.3929) acc 93.7500 (94.2708) kd_loss 0.8837 (0.8582) lr 1.4258e-03 eta 0:05:56
epoch [20/50] batch [80/132] time 0.082 (0.086) data 0.001 (0.005) loss 0.6767 (0.5508) ce_loss 0.2939 (0.1794) teacher_loss 0.2783 (0.1309) loss_zs_kd 0.0315 (0.0492) loss_oracle 0.3827 (0.3953) acc 90.6250 (94.2969) kd_loss 0.8457 (0.8582) lr 1.4258e-03 eta 0:05:44
epoch [20/50] batch [100/132] time 0.090 (0.086) data 0.000 (0.004) loss 0.6966 (0.5636) ce_loss 0.2389 (0.1861) teacher_loss 0.2398 (0.1349) loss_zs_kd 0.0592 (0.0500) loss_oracle 0.4272 (0.4037) acc 87.5000 (93.9375) kd_loss 0.9816 (0.8656) lr 1.4258e-03 eta 0:05:42
epoch [20/50] batch [120/132] time 0.074 (0.085) data 0.000 (0.003) loss 0.5058 (0.5714) ce_loss 0.0888 (0.1895) teacher_loss 0.0664 (0.1356) loss_zs_kd 0.0657 (0.0510) loss_oracle 0.4065 (0.4103) acc 100.0000 (93.8021) kd_loss 0.8804 (0.8669) lr 1.4258e-03 eta 0:05:38
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,518
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.9%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [21/50] batch [20/132] time 0.083 (0.103) data 0.000 (0.017) loss 0.7132 (0.6299) ce_loss 0.2612 (0.2190) teacher_loss 0.1489 (0.1501) loss_zs_kd 0.0847 (0.0653) loss_oracle 0.5220 (0.4471) acc 90.6250 (92.5000) kd_loss 0.9253 (0.9065) lr 1.3681e-03 eta 0:06:46
epoch [21/50] batch [40/132] time 0.080 (0.093) data 0.000 (0.008) loss 0.5411 (0.6182) ce_loss 0.0751 (0.2019) teacher_loss 0.0421 (0.1429) loss_zs_kd 0.0613 (0.0637) loss_oracle 0.4684 (0.4434) acc 100.0000 (92.9688) kd_loss 0.8968 (0.8753) lr 1.3681e-03 eta 0:06:05
epoch [21/50] batch [60/132] time 0.063 (0.088) data 0.001 (0.006) loss 0.6308 (0.6143) ce_loss 0.2142 (0.2048) teacher_loss 0.1378 (0.1427) loss_zs_kd 0.0579 (0.0607) loss_oracle 0.4641 (0.4413) acc 93.7500 (93.0729) kd_loss 0.8696 (0.8761) lr 1.3681e-03 eta 0:05:43
epoch [21/50] batch [80/132] time 0.065 (0.084) data 0.000 (0.004) loss 0.9373 (0.6128) ce_loss 0.4688 (0.2017) teacher_loss 0.2922 (0.1405) loss_zs_kd 0.0570 (0.0591) loss_oracle 0.6166 (0.4428) acc 84.3750 (93.2812) kd_loss 1.0010 (0.8797) lr 1.3681e-03 eta 0:05:26
epoch [21/50] batch [100/132] time 0.083 (0.082) data 0.000 (0.004) loss 0.6315 (0.6127) ce_loss 0.3135 (0.2108) teacher_loss 0.2390 (0.1448) loss_zs_kd 0.0588 (0.0599) loss_oracle 0.3632 (0.4379) acc 87.5000 (93.0625) kd_loss 0.8734 (0.8797) lr 1.3681e-03 eta 0:05:18
epoch [21/50] batch [120/132] time 0.074 (0.082) data 0.000 (0.003) loss 0.5852 (0.6102) ce_loss 0.1754 (0.2107) teacher_loss 0.1779 (0.1444) loss_zs_kd 0.0374 (0.0591) loss_oracle 0.3887 (0.4362) acc 93.7500 (92.9427) kd_loss 0.8686 (0.8839) lr 1.3681e-03 eta 0:05:15
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,804
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.0%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,548
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.4%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [22/50] batch [20/132] time 0.084 (0.098) data 0.000 (0.016) loss 0.7437 (0.5966) ce_loss 0.3843 (0.1893) teacher_loss 0.3177 (0.1233) loss_zs_kd 0.0423 (0.0581) loss_oracle 0.4048 (0.4443) acc 87.5000 (93.4375) kd_loss 0.9057 (0.8894) lr 1.3090e-03 eta 0:06:14
epoch [22/50] batch [40/132] time 0.094 (0.092) data 0.001 (0.008) loss 0.6690 (0.5970) ce_loss 0.2659 (0.1960) teacher_loss 0.1716 (0.1251) loss_zs_kd 0.0705 (0.0560) loss_oracle 0.4622 (0.4438) acc 87.5000 (93.3594) kd_loss 0.9289 (0.8905) lr 1.3090e-03 eta 0:05:47
epoch [22/50] batch [60/132] time 0.084 (0.090) data 0.000 (0.005) loss 0.5103 (0.5973) ce_loss 0.1025 (0.1961) teacher_loss 0.0448 (0.1278) loss_zs_kd 0.0416 (0.0597) loss_oracle 0.4447 (0.4396) acc 93.7500 (93.4375) kd_loss 0.8477 (0.8828) lr 1.3090e-03 eta 0:05:37
epoch [22/50] batch [80/132] time 0.082 (0.089) data 0.000 (0.004) loss 0.5340 (0.5974) ce_loss 0.2064 (0.1961) teacher_loss 0.1325 (0.1295) loss_zs_kd 0.0579 (0.0579) loss_oracle 0.3726 (0.4389) acc 93.7500 (93.4766) kd_loss 0.7962 (0.8832) lr 1.3090e-03 eta 0:05:34
epoch [22/50] batch [100/132] time 0.081 (0.088) data 0.000 (0.003) loss 0.5083 (0.5949) ce_loss 0.0361 (0.1888) teacher_loss 0.0180 (0.1253) loss_zs_kd 0.0560 (0.0564) loss_oracle 0.4623 (0.4414) acc 100.0000 (93.8125) kd_loss 0.8933 (0.8859) lr 1.3090e-03 eta 0:05:29
epoch [22/50] batch [120/132] time 0.072 (0.088) data 0.000 (0.003) loss 0.6280 (0.5969) ce_loss 0.2634 (0.1890) teacher_loss 0.2116 (0.1269) loss_zs_kd 0.0560 (0.0566) loss_oracle 0.3884 (0.4417) acc 90.6250 (93.8281) kd_loss 0.7851 (0.8863) lr 1.3090e-03 eta 0:05:24
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,538
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.1%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [23/50] batch [20/132] time 0.086 (0.099) data 0.000 (0.014) loss 0.8173 (0.6309) ce_loss 0.3918 (0.2142) teacher_loss 0.3966 (0.1551) loss_zs_kd 0.0734 (0.0605) loss_oracle 0.3840 (0.4455) acc 84.3750 (92.1875) kd_loss 0.8623 (0.8850) lr 1.2487e-03 eta 0:06:02
epoch [23/50] batch [40/132] time 0.086 (0.093) data 0.000 (0.007) loss 0.5480 (0.6071) ce_loss 0.1361 (0.2065) teacher_loss 0.1170 (0.1479) loss_zs_kd 0.0529 (0.0557) loss_oracle 0.4046 (0.4314) acc 96.8750 (92.7344) kd_loss 0.8416 (0.8809) lr 1.2487e-03 eta 0:05:39
epoch [23/50] batch [60/132] time 0.093 (0.090) data 0.001 (0.005) loss 0.5122 (0.5982) ce_loss 0.0924 (0.1985) teacher_loss 0.0546 (0.1405) loss_zs_kd 0.0332 (0.0523) loss_oracle 0.4410 (0.4316) acc 96.8750 (93.1771) kd_loss 0.8803 (0.8820) lr 1.2487e-03 eta 0:05:28
epoch [23/50] batch [80/132] time 0.085 (0.090) data 0.000 (0.004) loss 0.5657 (0.6043) ce_loss 0.1263 (0.2048) teacher_loss 0.0710 (0.1412) loss_zs_kd 0.0449 (0.0539) loss_oracle 0.4723 (0.4362) acc 96.8750 (92.9688) kd_loss 0.8855 (0.8841) lr 1.2487e-03 eta 0:05:24
epoch [23/50] batch [100/132] time 0.082 (0.089) data 0.000 (0.003) loss 0.4291 (0.6066) ce_loss 0.0215 (0.2043) teacher_loss 0.0270 (0.1396) loss_zs_kd 0.0262 (0.0541) loss_oracle 0.3890 (0.4399) acc 100.0000 (92.9688) kd_loss 0.8557 (0.8863) lr 1.2487e-03 eta 0:05:20
epoch [23/50] batch [120/132] time 0.076 (0.088) data 0.000 (0.003) loss 0.5415 (0.6111) ce_loss 0.1144 (0.2080) teacher_loss 0.0916 (0.1407) loss_zs_kd 0.0485 (0.0559) loss_oracle 0.4256 (0.4424) acc 96.8750 (92.8125) kd_loss 0.7960 (0.8872) lr 1.2487e-03 eta 0:05:15
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,804
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.0%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,522
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.9%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [24/50] batch [20/132] time 0.069 (0.099) data 0.000 (0.019) loss 0.5964 (0.6037) ce_loss 0.2333 (0.2063) teacher_loss 0.0778 (0.1295) loss_zs_kd 0.1208 (0.0648) loss_oracle 0.4582 (0.4418) acc 90.6250 (93.1250) kd_loss 0.9515 (0.9064) lr 1.1874e-03 eta 0:05:50
epoch [24/50] batch [40/132] time 0.086 (0.086) data 0.000 (0.010) loss 0.6334 (0.6170) ce_loss 0.1492 (0.2107) teacher_loss 0.0581 (0.1316) loss_zs_kd 0.0437 (0.0652) loss_oracle 0.5535 (0.4528) acc 93.7500 (92.6562) kd_loss 0.9469 (0.9123) lr 1.1874e-03 eta 0:05:03
epoch [24/50] batch [60/132] time 0.067 (0.081) data 0.000 (0.007) loss 0.7811 (0.6219) ce_loss 0.3567 (0.2069) teacher_loss 0.2659 (0.1353) loss_zs_kd 0.0392 (0.0645) loss_oracle 0.4955 (0.4543) acc 87.5000 (93.1250) kd_loss 0.9640 (0.9056) lr 1.1874e-03 eta 0:04:44
epoch [24/50] batch [80/132] time 0.075 (0.079) data 0.000 (0.005) loss 0.6220 (0.6252) ce_loss 0.1271 (0.2102) teacher_loss 0.1109 (0.1390) loss_zs_kd 0.0506 (0.0636) loss_oracle 0.4858 (0.4545) acc 96.8750 (92.7344) kd_loss 0.9371 (0.9007) lr 1.1874e-03 eta 0:04:34
epoch [24/50] batch [100/132] time 0.063 (0.076) data 0.000 (0.004) loss 0.6405 (0.6140) ce_loss 0.2849 (0.1995) teacher_loss 0.2197 (0.1342) loss_zs_kd 0.0675 (0.0618) loss_oracle 0.3870 (0.4489) acc 93.7500 (93.2188) kd_loss 0.8847 (0.8989) lr 1.1874e-03 eta 0:04:24
epoch [24/50] batch [120/132] time 0.067 (0.075) data 0.000 (0.003) loss 0.5303 (0.6065) ce_loss 0.1522 (0.1952) teacher_loss 0.0950 (0.1334) loss_zs_kd 0.0731 (0.0582) loss_oracle 0.3988 (0.4440) acc 96.8750 (93.3594) kd_loss 0.7962 (0.8986) lr 1.1874e-03 eta 0:04:19
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,493
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 91.3%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [25/50] batch [20/132] time 0.078 (0.103) data 0.000 (0.019) loss 0.5753 (0.5707) ce_loss 0.1654 (0.1786) teacher_loss 0.0842 (0.1263) loss_zs_kd 0.0544 (0.0434) loss_oracle 0.4639 (0.4227) acc 96.8750 (94.0625) kd_loss 0.8696 (0.8792) lr 1.1253e-03 eta 0:05:51
epoch [25/50] batch [40/132] time 0.084 (0.092) data 0.000 (0.010) loss 0.7032 (0.5867) ce_loss 0.2932 (0.1913) teacher_loss 0.2326 (0.1322) loss_zs_kd 0.0328 (0.0454) loss_oracle 0.4543 (0.4318) acc 90.6250 (93.6719) kd_loss 0.9752 (0.8739) lr 1.1253e-03 eta 0:05:10
epoch [25/50] batch [60/132] time 0.090 (0.088) data 0.001 (0.006) loss 0.7674 (0.5918) ce_loss 0.3528 (0.1881) teacher_loss 0.2348 (0.1276) loss_zs_kd 0.1007 (0.0489) loss_oracle 0.4823 (0.4398) acc 84.3750 (93.9062) kd_loss 0.8452 (0.8751) lr 1.1253e-03 eta 0:04:57
epoch [25/50] batch [80/132] time 0.090 (0.087) data 0.000 (0.005) loss 0.5181 (0.5968) ce_loss 0.1569 (0.1907) teacher_loss 0.0919 (0.1294) loss_zs_kd 0.0505 (0.0490) loss_oracle 0.4009 (0.4428) acc 96.8750 (93.7891) kd_loss 0.8809 (0.8740) lr 1.1253e-03 eta 0:04:52
epoch [25/50] batch [100/132] time 0.085 (0.087) data 0.000 (0.004) loss 0.6637 (0.5975) ce_loss 0.1483 (0.1892) teacher_loss 0.1226 (0.1294) loss_zs_kd 0.0668 (0.0507) loss_oracle 0.5077 (0.4428) acc 93.7500 (94.0000) kd_loss 0.8727 (0.8743) lr 1.1253e-03 eta 0:04:50
epoch [25/50] batch [120/132] time 0.073 (0.087) data 0.000 (0.003) loss 0.6154 (0.6009) ce_loss 0.2156 (0.1940) teacher_loss 0.1925 (0.1310) loss_zs_kd 0.0564 (0.0521) loss_oracle 0.3947 (0.4438) acc 93.7500 (93.6979) kd_loss 0.8762 (0.8753) lr 1.1253e-03 eta 0:04:46
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,519
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.8%
******* Domain s best val acc:      99.3%, epoch: 9 *******
******* Domain s best val test acc: 89.1%, epoch: 9 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [26/50] batch [20/132] time 0.084 (0.101) data 0.000 (0.016) loss 0.4648 (0.5740) ce_loss 0.1302 (0.1582) teacher_loss 0.0766 (0.1103) loss_zs_kd 0.0475 (0.0463) loss_oracle 0.3645 (0.4406) acc 93.7500 (94.6875) kd_loss 0.8166 (0.8825) lr 1.0628e-03 eta 0:05:30
epoch [26/50] batch [40/132] time 0.084 (0.093) data 0.000 (0.008) loss 0.7439 (0.6078) ce_loss 0.4185 (0.2009) teacher_loss 0.2790 (0.1458) loss_zs_kd 0.0637 (0.0515) loss_oracle 0.4330 (0.4362) acc 87.5000 (93.5156) kd_loss 0.8335 (0.8840) lr 1.0628e-03 eta 0:05:03
epoch [26/50] batch [60/132] time 0.089 (0.091) data 0.001 (0.005) loss 0.6713 (0.6257) ce_loss 0.2255 (0.2139) teacher_loss 0.1759 (0.1551) loss_zs_kd 0.0482 (0.0546) loss_oracle 0.4714 (0.4433) acc 93.7500 (92.9688) kd_loss 0.8838 (0.8839) lr 1.0628e-03 eta 0:04:53
epoch [26/50] batch [80/132] time 0.095 (0.090) data 0.000 (0.004) loss 0.6045 (0.6322) ce_loss 0.1164 (0.2144) teacher_loss 0.0886 (0.1557) loss_zs_kd 0.0876 (0.0573) loss_oracle 0.4721 (0.4478) acc 96.8750 (92.9297) kd_loss 0.8661 (0.8811) lr 1.0628e-03 eta 0:04:50
epoch [26/50] batch [100/132] time 0.086 (0.090) data 0.000 (0.003) loss 0.4382 (0.6329) ce_loss 0.1183 (0.2147) teacher_loss 0.0513 (0.1573) loss_zs_kd 0.0385 (0.0558) loss_oracle 0.3677 (0.4477) acc 93.7500 (92.9375) kd_loss 0.8083 (0.8761) lr 1.0628e-03 eta 0:04:49
epoch [26/50] batch [120/132] time 0.079 (0.090) data 0.000 (0.003) loss 0.5336 (0.6304) ce_loss 0.1018 (0.2124) teacher_loss 0.0763 (0.1542) loss_zs_kd 0.0372 (0.0549) loss_oracle 0.4387 (0.4488) acc 100.0000 (92.9167) kd_loss 0.8046 (0.8755) lr 1.0628e-03 eta 0:04:45
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,529
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.1%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [27/50] batch [20/132] time 0.082 (0.102) data 0.000 (0.016) loss 0.6111 (0.6350) ce_loss 0.1752 (0.2072) teacher_loss 0.0903 (0.1478) loss_zs_kd 0.0296 (0.0585) loss_oracle 0.5061 (0.4579) acc 96.8750 (92.1875) kd_loss 0.9721 (0.8751) lr 1.0000e-03 eta 0:05:20
epoch [27/50] batch [40/132] time 0.086 (0.093) data 0.000 (0.008) loss 0.5375 (0.6319) ce_loss 0.0969 (0.1975) teacher_loss 0.0750 (0.1437) loss_zs_kd 0.0329 (0.0585) loss_oracle 0.4461 (0.4589) acc 96.8750 (92.6562) kd_loss 0.9740 (0.8781) lr 1.0000e-03 eta 0:04:51
epoch [27/50] batch [60/132] time 0.098 (0.092) data 0.000 (0.006) loss 0.5173 (0.6340) ce_loss 0.0367 (0.2010) teacher_loss 0.0381 (0.1425) loss_zs_kd 0.0551 (0.0574) loss_oracle 0.4517 (0.4628) acc 100.0000 (92.9167) kd_loss 0.8939 (0.8818) lr 1.0000e-03 eta 0:04:45
epoch [27/50] batch [80/132] time 0.080 (0.091) data 0.000 (0.004) loss 0.5374 (0.6297) ce_loss 0.1205 (0.1950) teacher_loss 0.0790 (0.1384) loss_zs_kd 0.0560 (0.0571) loss_oracle 0.4304 (0.4627) acc 96.8750 (93.1641) kd_loss 0.8338 (0.8855) lr 1.0000e-03 eta 0:04:40
epoch [27/50] batch [100/132] time 0.084 (0.090) data 0.000 (0.003) loss 0.7431 (0.6363) ce_loss 0.2023 (0.2004) teacher_loss 0.2067 (0.1437) loss_zs_kd 0.0358 (0.0561) loss_oracle 0.5186 (0.4646) acc 90.6250 (92.9688) kd_loss 0.8723 (0.8904) lr 1.0000e-03 eta 0:04:34
epoch [27/50] batch [120/132] time 0.084 (0.089) data 0.001 (0.003) loss 0.5637 (0.6386) ce_loss 0.1083 (0.2009) teacher_loss 0.0835 (0.1440) loss_zs_kd 0.0449 (0.0550) loss_oracle 0.4578 (0.4671) acc 96.8750 (93.0208) kd_loss 1.0152 (0.8964) lr 1.0000e-03 eta 0:04:30
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,501
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 91.5%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [28/50] batch [20/132] time 0.087 (0.105) data 0.000 (0.018) loss 0.6145 (0.6744) ce_loss 0.1815 (0.1951) teacher_loss 0.0818 (0.1244) loss_zs_kd 0.0540 (0.0547) loss_oracle 0.5057 (0.5226) acc 93.7500 (93.7500) kd_loss 1.0073 (0.9348) lr 9.3721e-04 eta 0:05:16
epoch [28/50] batch [40/132] time 0.084 (0.095) data 0.000 (0.009) loss 0.7230 (0.6791) ce_loss 0.2585 (0.2026) teacher_loss 0.1672 (0.1365) loss_zs_kd 0.0844 (0.0570) loss_oracle 0.5136 (0.5141) acc 90.6250 (93.4375) kd_loss 0.9396 (0.9316) lr 9.3721e-04 eta 0:04:45
epoch [28/50] batch [60/132] time 0.086 (0.093) data 0.000 (0.006) loss 0.5790 (0.6754) ce_loss 0.0368 (0.2033) teacher_loss 0.0232 (0.1431) loss_zs_kd 0.0342 (0.0555) loss_oracle 0.5387 (0.5046) acc 100.0000 (93.2812) kd_loss 0.9462 (0.9334) lr 9.3721e-04 eta 0:04:37
epoch [28/50] batch [80/132] time 0.083 (0.091) data 0.000 (0.005) loss 0.9836 (0.6731) ce_loss 0.5781 (0.2055) teacher_loss 0.3644 (0.1429) loss_zs_kd 0.0724 (0.0545) loss_oracle 0.5830 (0.5029) acc 78.1250 (93.1250) kd_loss 1.0514 (0.9313) lr 9.3721e-04 eta 0:04:30
epoch [28/50] batch [100/132] time 0.088 (0.090) data 0.000 (0.004) loss 0.6143 (0.6631) ce_loss 0.1479 (0.1958) teacher_loss 0.0912 (0.1350) loss_zs_kd 0.0593 (0.0543) loss_oracle 0.4934 (0.5010) acc 93.7500 (93.6250) kd_loss 0.9316 (0.9299) lr 9.3721e-04 eta 0:04:24
epoch [28/50] batch [120/132] time 0.082 (0.090) data 0.000 (0.003) loss 0.5760 (0.6642) ce_loss 0.1924 (0.1955) teacher_loss 0.0615 (0.1352) loss_zs_kd 0.0727 (0.0543) loss_oracle 0.4781 (0.5018) acc 93.7500 (93.6198) kd_loss 0.9383 (0.9303) lr 9.3721e-04 eta 0:04:21
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,494
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 91.4%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [29/50] batch [20/132] time 0.087 (0.098) data 0.000 (0.013) loss 0.6310 (0.6705) ce_loss 0.1790 (0.2060) teacher_loss 0.1690 (0.1432) loss_zs_kd 0.0364 (0.0487) loss_oracle 0.4438 (0.5030) acc 93.7500 (93.2812) kd_loss 0.9064 (0.9519) lr 8.7467e-04 eta 0:04:44
epoch [29/50] batch [40/132] time 0.095 (0.093) data 0.001 (0.007) loss 0.6123 (0.6847) ce_loss 0.0712 (0.2337) teacher_loss 0.0479 (0.1585) loss_zs_kd 0.0459 (0.0511) loss_oracle 0.5415 (0.5007) acc 96.8750 (92.7344) kd_loss 0.9702 (0.9556) lr 8.7467e-04 eta 0:04:24
epoch [29/50] batch [60/132] time 0.082 (0.090) data 0.001 (0.005) loss 0.7926 (0.6736) ce_loss 0.3264 (0.2107) teacher_loss 0.2281 (0.1441) loss_zs_kd 0.0488 (0.0524) loss_oracle 0.5400 (0.5033) acc 90.6250 (93.1250) kd_loss 0.9777 (0.9575) lr 8.7467e-04 eta 0:04:15
epoch [29/50] batch [80/132] time 0.087 (0.089) data 0.000 (0.003) loss 0.4977 (0.6665) ce_loss 0.0482 (0.2064) teacher_loss 0.0311 (0.1426) loss_zs_kd 0.0591 (0.0540) loss_oracle 0.4370 (0.4970) acc 100.0000 (93.3203) kd_loss 0.9343 (0.9564) lr 8.7467e-04 eta 0:04:10
epoch [29/50] batch [100/132] time 0.085 (0.088) data 0.000 (0.003) loss 0.7220 (0.6605) ce_loss 0.2971 (0.2032) teacher_loss 0.1691 (0.1391) loss_zs_kd 0.0733 (0.0541) loss_oracle 0.5163 (0.4943) acc 90.6250 (93.1562) kd_loss 0.8855 (0.9551) lr 8.7467e-04 eta 0:04:07
epoch [29/50] batch [120/132] time 0.086 (0.088) data 0.000 (0.002) loss 0.7965 (0.6594) ce_loss 0.2297 (0.2022) teacher_loss 0.2133 (0.1360) loss_zs_kd 0.0593 (0.0548) loss_oracle 0.5535 (0.4960) acc 93.7500 (93.2812) kd_loss 0.9932 (0.9574) lr 8.7467e-04 eta 0:04:06
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,805
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,492
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 91.4%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [30/50] batch [20/132] time 0.086 (0.107) data 0.000 (0.018) loss 0.6749 (0.6367) ce_loss 0.0966 (0.1858) teacher_loss 0.0843 (0.1227) loss_zs_kd 0.0657 (0.0606) loss_oracle 0.5578 (0.4838) acc 96.8750 (93.9062) kd_loss 0.9924 (0.9557) lr 8.1262e-04 eta 0:04:55
epoch [30/50] batch [40/132] time 0.086 (0.096) data 0.000 (0.009) loss 0.4527 (0.6551) ce_loss 0.0533 (0.2011) teacher_loss 0.0300 (0.1292) loss_zs_kd 0.0468 (0.0610) loss_oracle 0.3993 (0.4954) acc 96.8750 (93.2812) kd_loss 0.9535 (0.9623) lr 8.1262e-04 eta 0:04:22
epoch [30/50] batch [60/132] time 0.094 (0.093) data 0.000 (0.006) loss 0.7940 (0.6663) ce_loss 0.3711 (0.2140) teacher_loss 0.2390 (0.1367) loss_zs_kd 0.0822 (0.0636) loss_oracle 0.5139 (0.4977) acc 84.3750 (92.9688) kd_loss 0.9421 (0.9632) lr 8.1262e-04 eta 0:04:13
epoch [30/50] batch [80/132] time 0.085 (0.092) data 0.000 (0.005) loss 0.6557 (0.6670) ce_loss 0.2444 (0.2132) teacher_loss 0.1403 (0.1375) loss_zs_kd 0.0676 (0.0632) loss_oracle 0.4816 (0.4979) acc 90.6250 (92.9297) kd_loss 0.9643 (0.9686) lr 8.1262e-04 eta 0:04:06
epoch [30/50] batch [100/132] time 0.084 (0.090) data 0.000 (0.004) loss 0.8072 (0.6661) ce_loss 0.3071 (0.2077) teacher_loss 0.3125 (0.1347) loss_zs_kd 0.0427 (0.0630) loss_oracle 0.4734 (0.4999) acc 90.6250 (93.1875) kd_loss 1.0010 (0.9680) lr 8.1262e-04 eta 0:04:00
epoch [30/50] batch [120/132] time 0.074 (0.089) data 0.000 (0.003) loss 0.6766 (0.6675) ce_loss 0.1963 (0.2100) teacher_loss 0.1664 (0.1356) loss_zs_kd 0.0658 (0.0632) loss_oracle 0.4773 (0.5003) acc 93.7500 (93.1250) kd_loss 0.8727 (0.9664) lr 8.1262e-04 eta 0:03:56
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,504
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 91.6%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [31/50] batch [20/132] time 0.084 (0.104) data 0.000 (0.014) loss 0.7299 (0.6976) ce_loss 0.2893 (0.2242) teacher_loss 0.1854 (0.1437) loss_zs_kd 0.0498 (0.0615) loss_oracle 0.5196 (0.5232) acc 93.7500 (91.8750) kd_loss 0.9268 (0.9767) lr 7.5131e-04 eta 0:04:33
epoch [31/50] batch [40/132] time 0.084 (0.095) data 0.000 (0.007) loss 0.6574 (0.6926) ce_loss 0.2175 (0.2156) teacher_loss 0.1213 (0.1388) loss_zs_kd 0.0623 (0.0641) loss_oracle 0.5050 (0.5218) acc 93.7500 (92.4219) kd_loss 1.0467 (0.9743) lr 7.5131e-04 eta 0:04:05
epoch [31/50] batch [60/132] time 0.082 (0.092) data 0.001 (0.005) loss 0.7911 (0.6923) ce_loss 0.3076 (0.2157) teacher_loss 0.2612 (0.1404) loss_zs_kd 0.0566 (0.0646) loss_oracle 0.5016 (0.5196) acc 87.5000 (92.5000) kd_loss 0.9095 (0.9686) lr 7.5131e-04 eta 0:03:56
epoch [31/50] batch [80/132] time 0.081 (0.090) data 0.000 (0.004) loss 0.5172 (0.6814) ce_loss 0.0946 (0.2075) teacher_loss 0.0595 (0.1331) loss_zs_kd 0.0285 (0.0620) loss_oracle 0.4434 (0.5173) acc 93.7500 (92.7734) kd_loss 0.8748 (0.9673) lr 7.5131e-04 eta 0:03:50
epoch [31/50] batch [100/132] time 0.085 (0.089) data 0.000 (0.003) loss 0.5314 (0.6788) ce_loss 0.0829 (0.2056) teacher_loss 0.0460 (0.1315) loss_zs_kd 0.0355 (0.0616) loss_oracle 0.4676 (0.5165) acc 96.8750 (92.7812) kd_loss 0.8579 (0.9659) lr 7.5131e-04 eta 0:03:46
epoch [31/50] batch [120/132] time 0.074 (0.088) data 0.000 (0.002) loss 0.6213 (0.6764) ce_loss 0.2947 (0.2055) teacher_loss 0.1992 (0.1320) loss_zs_kd 0.0304 (0.0621) loss_oracle 0.4069 (0.5134) acc 93.7500 (92.9427) kd_loss 0.9492 (0.9662) lr 7.5131e-04 eta 0:03:41
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,523
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 92.0%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [32/50] batch [20/132] time 0.069 (0.096) data 0.000 (0.013) loss 0.5938 (0.6808) ce_loss 0.1075 (0.1783) teacher_loss 0.0775 (0.1269) loss_zs_kd 0.0459 (0.0643) loss_oracle 0.4933 (0.5217) acc 100.0000 (94.3750) kd_loss 0.9242 (0.9554) lr 6.9098e-04 eta 0:03:58
epoch [32/50] batch [40/132] time 0.084 (0.086) data 0.000 (0.006) loss 0.6668 (0.7019) ce_loss 0.2131 (0.2030) teacher_loss 0.1132 (0.1336) loss_zs_kd 0.0686 (0.0635) loss_oracle 0.5193 (0.5365) acc 93.7500 (93.2812) kd_loss 0.9516 (0.9732) lr 6.9098e-04 eta 0:03:32
epoch [32/50] batch [60/132] time 0.061 (0.082) data 0.001 (0.004) loss 0.6420 (0.7084) ce_loss 0.0713 (0.2047) teacher_loss 0.0651 (0.1310) loss_zs_kd 0.0706 (0.0630) loss_oracle 0.5416 (0.5459) acc 100.0000 (93.2812) kd_loss 1.0141 (0.9779) lr 6.9098e-04 eta 0:03:20
epoch [32/50] batch [80/132] time 0.070 (0.079) data 0.000 (0.003) loss 0.8170 (0.7108) ce_loss 0.2935 (0.2019) teacher_loss 0.1777 (0.1286) loss_zs_kd 0.1256 (0.0639) loss_oracle 0.5765 (0.5503) acc 87.5000 (93.3984) kd_loss 1.0082 (0.9805) lr 6.9098e-04 eta 0:03:12
epoch [32/50] batch [100/132] time 0.082 (0.079) data 0.000 (0.003) loss 0.7235 (0.7205) ce_loss 0.2754 (0.2080) teacher_loss 0.0689 (0.1322) loss_zs_kd 0.0961 (0.0649) loss_oracle 0.6065 (0.5558) acc 93.7500 (93.2188) kd_loss 0.9936 (0.9840) lr 6.9098e-04 eta 0:03:11
epoch [32/50] batch [120/132] time 0.072 (0.080) data 0.000 (0.002) loss 0.5475 (0.7257) ce_loss 0.0396 (0.2140) teacher_loss 0.0236 (0.1356) loss_zs_kd 0.0488 (0.0652) loss_oracle 0.4996 (0.5575) acc 100.0000 (92.9427) kd_loss 0.9629 (0.9842) lr 6.9098e-04 eta 0:03:10
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,496
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 91.5%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [33/50] batch [20/132] time 0.075 (0.107) data 0.000 (0.017) loss 0.5997 (0.7112) ce_loss 0.1676 (0.2047) teacher_loss 0.0666 (0.1352) loss_zs_kd 0.0402 (0.0672) loss_oracle 0.5130 (0.5424) acc 93.7500 (92.8125) kd_loss 1.0064 (0.9697) lr 6.3188e-04 eta 0:04:12
epoch [33/50] batch [40/132] time 0.084 (0.094) data 0.000 (0.008) loss 0.6497 (0.7159) ce_loss 0.1654 (0.1998) teacher_loss 0.1336 (0.1262) loss_zs_kd 0.0425 (0.0671) loss_oracle 0.4949 (0.5561) acc 93.7500 (92.9688) kd_loss 0.9587 (0.9777) lr 6.3188e-04 eta 0:03:39
epoch [33/50] batch [60/132] time 0.088 (0.090) data 0.001 (0.006) loss 0.7322 (0.7135) ce_loss 0.2942 (0.1986) teacher_loss 0.1427 (0.1245) loss_zs_kd 0.0593 (0.0638) loss_oracle 0.5599 (0.5572) acc 90.6250 (92.9688) kd_loss 0.9927 (0.9782) lr 6.3188e-04 eta 0:03:29
epoch [33/50] batch [80/132] time 0.082 (0.089) data 0.000 (0.004) loss 0.6736 (0.6994) ce_loss 0.2451 (0.1907) teacher_loss 0.1499 (0.1172) loss_zs_kd 0.0550 (0.0625) loss_oracle 0.4962 (0.5509) acc 87.5000 (93.3594) kd_loss 0.9822 (0.9765) lr 6.3188e-04 eta 0:03:24
epoch [33/50] batch [100/132] time 0.081 (0.088) data 0.000 (0.004) loss 0.6602 (0.6989) ce_loss 0.1857 (0.1962) teacher_loss 0.1187 (0.1221) loss_zs_kd 0.0602 (0.0626) loss_oracle 0.5114 (0.5455) acc 93.7500 (93.1875) kd_loss 1.0293 (0.9754) lr 6.3188e-04 eta 0:03:21
epoch [33/50] batch [120/132] time 0.075 (0.087) data 0.000 (0.003) loss 0.6179 (0.6992) ce_loss 0.2556 (0.2025) teacher_loss 0.1104 (0.1273) loss_zs_kd 0.0530 (0.0627) loss_oracle 0.4810 (0.5406) acc 93.7500 (92.9688) kd_loss 1.0174 (0.9756) lr 6.3188e-04 eta 0:03:17
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,805
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,483
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 91.2%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [34/50] batch [20/132] time 0.070 (0.092) data 0.000 (0.013) loss 0.7357 (0.6487) ce_loss 0.2474 (0.1813) teacher_loss 0.1386 (0.1037) loss_zs_kd 0.0433 (0.0593) loss_oracle 0.5755 (0.5154) acc 90.6250 (94.0625) kd_loss 0.9738 (0.9743) lr 5.7422e-04 eta 0:03:25
epoch [34/50] batch [40/132] time 0.082 (0.085) data 0.000 (0.007) loss 0.7574 (0.6597) ce_loss 0.2834 (0.1862) teacher_loss 0.2175 (0.1126) loss_zs_kd 0.0681 (0.0614) loss_oracle 0.5059 (0.5164) acc 87.5000 (93.9844) kd_loss 0.9909 (0.9635) lr 5.7422e-04 eta 0:03:07
epoch [34/50] batch [60/132] time 0.090 (0.084) data 0.001 (0.005) loss 0.5582 (0.6555) ce_loss 0.1421 (0.1753) teacher_loss 0.1049 (0.1091) loss_zs_kd 0.0330 (0.0589) loss_oracle 0.4368 (0.5170) acc 93.7500 (94.4792) kd_loss 0.9403 (0.9608) lr 5.7422e-04 eta 0:03:02
epoch [34/50] batch [80/132] time 0.088 (0.084) data 0.000 (0.004) loss 0.6629 (0.6681) ce_loss 0.0632 (0.1829) teacher_loss 0.0305 (0.1174) loss_zs_kd 0.0464 (0.0592) loss_oracle 0.6092 (0.5211) acc 100.0000 (94.3359) kd_loss 1.0085 (0.9629) lr 5.7422e-04 eta 0:03:01
epoch [34/50] batch [100/132] time 0.087 (0.085) data 0.000 (0.003) loss 0.7914 (0.6775) ce_loss 0.4148 (0.1918) teacher_loss 0.2752 (0.1230) loss_zs_kd 0.0528 (0.0594) loss_oracle 0.4898 (0.5248) acc 87.5000 (93.8438) kd_loss 0.9372 (0.9633) lr 5.7422e-04 eta 0:03:01
epoch [34/50] batch [120/132] time 0.076 (0.084) data 0.000 (0.002) loss 0.6358 (0.6858) ce_loss 0.3042 (0.1971) teacher_loss 0.1320 (0.1261) loss_zs_kd 0.0788 (0.0599) loss_oracle 0.4643 (0.5297) acc 93.7500 (93.7500) kd_loss 0.9638 (0.9672) lr 5.7422e-04 eta 0:02:58
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,488
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 91.3%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [35/50] batch [20/132] time 0.091 (0.101) data 0.000 (0.013) loss 0.9106 (0.6910) ce_loss 0.4153 (0.2069) teacher_loss 0.3154 (0.1269) loss_zs_kd 0.0594 (0.0537) loss_oracle 0.5655 (0.5372) acc 84.3750 (93.5938) kd_loss 0.9238 (0.9584) lr 5.1825e-04 eta 0:03:31
epoch [35/50] batch [40/132] time 0.088 (0.095) data 0.000 (0.007) loss 0.6331 (0.6788) ce_loss 0.1357 (0.1918) teacher_loss 0.0740 (0.1200) loss_zs_kd 0.0750 (0.0584) loss_oracle 0.5216 (0.5296) acc 96.8750 (94.0625) kd_loss 0.9653 (0.9557) lr 5.1825e-04 eta 0:03:16
epoch [35/50] batch [60/132] time 0.089 (0.092) data 0.001 (0.005) loss 0.6565 (0.6763) ce_loss 0.1591 (0.1969) teacher_loss 0.1162 (0.1245) loss_zs_kd 0.0576 (0.0576) loss_oracle 0.5115 (0.5230) acc 93.7500 (93.8021) kd_loss 0.9663 (0.9584) lr 5.1825e-04 eta 0:03:09
epoch [35/50] batch [80/132] time 0.080 (0.091) data 0.000 (0.004) loss 0.5695 (0.6815) ce_loss 0.1870 (0.1964) teacher_loss 0.1034 (0.1241) loss_zs_kd 0.0541 (0.0575) loss_oracle 0.4391 (0.5286) acc 93.7500 (93.9062) kd_loss 0.9143 (0.9632) lr 5.1825e-04 eta 0:03:03
epoch [35/50] batch [100/132] time 0.089 (0.090) data 0.000 (0.003) loss 0.5789 (0.6746) ce_loss 0.1155 (0.1920) teacher_loss 0.0938 (0.1212) loss_zs_kd 0.0627 (0.0572) loss_oracle 0.4537 (0.5248) acc 93.7500 (93.9688) kd_loss 0.9058 (0.9665) lr 5.1825e-04 eta 0:03:01
epoch [35/50] batch [120/132] time 0.074 (0.089) data 0.000 (0.002) loss 0.7069 (0.6749) ce_loss 0.2837 (0.1900) teacher_loss 0.1554 (0.1208) loss_zs_kd 0.0712 (0.0571) loss_oracle 0.5160 (0.5256) acc 90.6250 (93.8542) kd_loss 0.9425 (0.9662) lr 5.1825e-04 eta 0:02:57
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,488
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 91.3%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [36/50] batch [20/132] time 0.071 (0.098) data 0.000 (0.016) loss 0.6611 (0.6571) ce_loss 0.1482 (0.1810) teacher_loss 0.1252 (0.1232) loss_zs_kd 0.0518 (0.0559) loss_oracle 0.5100 (0.5059) acc 90.6250 (93.5938) kd_loss 1.0033 (0.9526) lr 4.6417e-04 eta 0:03:11
epoch [36/50] batch [40/132] time 0.084 (0.088) data 0.000 (0.008) loss 0.5543 (0.6485) ce_loss 0.0866 (0.1829) teacher_loss 0.0779 (0.1216) loss_zs_kd 0.0576 (0.0552) loss_oracle 0.4476 (0.4993) acc 96.8750 (93.5938) kd_loss 0.8861 (0.9534) lr 4.6417e-04 eta 0:02:50
epoch [36/50] batch [60/132] time 0.067 (0.085) data 0.001 (0.006) loss 0.6884 (0.6518) ce_loss 0.1752 (0.1851) teacher_loss 0.1402 (0.1244) loss_zs_kd 0.0517 (0.0553) loss_oracle 0.5224 (0.4997) acc 93.7500 (93.5417) kd_loss 1.0095 (0.9606) lr 4.6417e-04 eta 0:02:43
epoch [36/50] batch [80/132] time 0.083 (0.083) data 0.000 (0.004) loss 0.4727 (0.6497) ce_loss 0.0513 (0.1832) teacher_loss 0.0208 (0.1221) loss_zs_kd 0.0337 (0.0554) loss_oracle 0.4350 (0.4999) acc 100.0000 (93.6719) kd_loss 0.9180 (0.9569) lr 4.6417e-04 eta 0:02:37
epoch [36/50] batch [100/132] time 0.079 (0.083) data 0.000 (0.003) loss 0.7515 (0.6540) ce_loss 0.3860 (0.1857) teacher_loss 0.1966 (0.1248) loss_zs_kd 0.0832 (0.0555) loss_oracle 0.5132 (0.5015) acc 87.5000 (93.6562) kd_loss 0.9812 (0.9577) lr 4.6417e-04 eta 0:02:35
epoch [36/50] batch [120/132] time 0.074 (0.082) data 0.000 (0.003) loss 0.6268 (0.6571) ce_loss 0.1678 (0.1893) teacher_loss 0.1299 (0.1239) loss_zs_kd 0.0466 (0.0570) loss_oracle 0.4737 (0.5047) acc 93.7500 (93.4635) kd_loss 0.8580 (0.9574) lr 4.6417e-04 eta 0:02:33
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,491
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 91.4%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [37/50] batch [20/132] time 0.075 (0.095) data 0.000 (0.013) loss 0.9316 (0.6962) ce_loss 0.5591 (0.2238) teacher_loss 0.3690 (0.1469) loss_zs_kd 0.1078 (0.0628) loss_oracle 0.5087 (0.5179) acc 81.2500 (91.4062) kd_loss 0.9399 (0.9587) lr 4.1221e-04 eta 0:02:53
epoch [37/50] batch [40/132] time 0.090 (0.090) data 0.000 (0.007) loss 0.6090 (0.6898) ce_loss 0.1236 (0.2202) teacher_loss 0.1218 (0.1489) loss_zs_kd 0.0298 (0.0599) loss_oracle 0.4723 (0.5110) acc 96.8750 (92.1875) kd_loss 0.9553 (0.9518) lr 4.1221e-04 eta 0:02:42
epoch [37/50] batch [60/132] time 0.085 (0.087) data 0.001 (0.005) loss 0.6065 (0.6849) ce_loss 0.0975 (0.2100) teacher_loss 0.0589 (0.1418) loss_zs_kd 0.0357 (0.0589) loss_oracle 0.5297 (0.5136) acc 96.8750 (92.7604) kd_loss 1.0177 (0.9561) lr 4.1221e-04 eta 0:02:36
epoch [37/50] batch [80/132] time 0.080 (0.086) data 0.000 (0.003) loss 0.6717 (0.6828) ce_loss 0.1070 (0.2095) teacher_loss 0.0572 (0.1406) loss_zs_kd 0.0834 (0.0592) loss_oracle 0.5729 (0.5126) acc 100.0000 (92.8906) kd_loss 1.0415 (0.9550) lr 4.1221e-04 eta 0:02:31
epoch [37/50] batch [100/132] time 0.072 (0.085) data 0.000 (0.003) loss 0.8656 (0.6856) ce_loss 0.2683 (0.2093) teacher_loss 0.2206 (0.1415) loss_zs_kd 0.0517 (0.0586) loss_oracle 0.6191 (0.5147) acc 93.7500 (92.9375) kd_loss 0.9464 (0.9554) lr 4.1221e-04 eta 0:02:28
epoch [37/50] batch [120/132] time 0.076 (0.084) data 0.000 (0.002) loss 0.5832 (0.6872) ce_loss 0.0625 (0.2064) teacher_loss 0.0489 (0.1389) loss_zs_kd 0.0442 (0.0596) loss_oracle 0.5122 (0.5185) acc 100.0000 (93.0208) kd_loss 0.9986 (0.9577) lr 4.1221e-04 eta 0:02:25
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,488
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 91.3%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [38/50] batch [20/132] time 0.077 (0.098) data 0.000 (0.014) loss 0.7256 (0.6886) ce_loss 0.4282 (0.2034) teacher_loss 0.2384 (0.1352) loss_zs_kd 0.0659 (0.0529) loss_oracle 0.4542 (0.5269) acc 90.6250 (93.7500) kd_loss 0.9336 (0.9635) lr 3.6258e-04 eta 0:02:45
epoch [38/50] batch [40/132] time 0.086 (0.093) data 0.000 (0.007) loss 0.5535 (0.7018) ce_loss 0.1791 (0.2156) teacher_loss 0.0921 (0.1479) loss_zs_kd 0.0334 (0.0552) loss_oracle 0.4447 (0.5264) acc 96.8750 (92.8906) kd_loss 0.9679 (0.9583) lr 3.6258e-04 eta 0:02:35
epoch [38/50] batch [60/132] time 0.091 (0.092) data 0.001 (0.005) loss 0.6984 (0.6883) ce_loss 0.2020 (0.2053) teacher_loss 0.1193 (0.1398) loss_zs_kd 0.0809 (0.0532) loss_oracle 0.5387 (0.5219) acc 96.8750 (92.9688) kd_loss 0.9515 (0.9584) lr 3.6258e-04 eta 0:02:31
epoch [38/50] batch [80/132] time 0.085 (0.090) data 0.000 (0.004) loss 0.6586 (0.6878) ce_loss 0.1230 (0.2039) teacher_loss 0.0385 (0.1397) loss_zs_kd 0.0433 (0.0547) loss_oracle 0.5984 (0.5208) acc 96.8750 (92.8906) kd_loss 0.9980 (0.9535) lr 3.6258e-04 eta 0:02:28
epoch [38/50] batch [100/132] time 0.085 (0.090) data 0.000 (0.003) loss 0.6105 (0.6878) ce_loss 0.1542 (0.2028) teacher_loss 0.0933 (0.1378) loss_zs_kd 0.0615 (0.0550) loss_oracle 0.4864 (0.5226) acc 93.7500 (93.0625) kd_loss 0.9298 (0.9527) lr 3.6258e-04 eta 0:02:25
epoch [38/50] batch [120/132] time 0.075 (0.090) data 0.000 (0.003) loss 0.7359 (0.6858) ce_loss 0.1931 (0.2009) teacher_loss 0.1290 (0.1357) loss_zs_kd 0.0891 (0.0559) loss_oracle 0.5624 (0.5222) acc 93.7500 (93.2031) kd_loss 0.9961 (0.9559) lr 3.6258e-04 eta 0:02:22
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,491
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 91.4%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [39/50] batch [20/132] time 0.083 (0.102) data 0.000 (0.018) loss 0.7225 (0.6403) ce_loss 0.2168 (0.1626) teacher_loss 0.1383 (0.1120) loss_zs_kd 0.0485 (0.0507) loss_oracle 0.5600 (0.5029) acc 90.6250 (93.9062) kd_loss 0.9533 (0.9465) lr 3.1545e-04 eta 0:02:38
epoch [39/50] batch [40/132] time 0.090 (0.091) data 0.000 (0.009) loss 0.7446 (0.6654) ce_loss 0.2400 (0.1834) teacher_loss 0.2472 (0.1297) loss_zs_kd 0.0622 (0.0526) loss_oracle 0.4662 (0.5094) acc 93.7500 (93.8281) kd_loss 0.8695 (0.9387) lr 3.1545e-04 eta 0:02:20
epoch [39/50] batch [60/132] time 0.079 (0.088) data 0.001 (0.006) loss 0.7151 (0.6721) ce_loss 0.1492 (0.1985) teacher_loss 0.1255 (0.1413) loss_zs_kd 0.0494 (0.0556) loss_oracle 0.5649 (0.5029) acc 96.8750 (93.3333) kd_loss 1.0210 (0.9345) lr 3.1545e-04 eta 0:02:14
epoch [39/50] batch [80/132] time 0.088 (0.087) data 0.000 (0.005) loss 0.5146 (0.6695) ce_loss 0.0715 (0.1947) teacher_loss 0.0218 (0.1390) loss_zs_kd 0.0481 (0.0551) loss_oracle 0.4687 (0.5030) acc 96.8750 (93.3594) kd_loss 0.9292 (0.9386) lr 3.1545e-04 eta 0:02:10
epoch [39/50] batch [100/132] time 0.088 (0.087) data 0.000 (0.004) loss 0.8141 (0.6620) ce_loss 0.2245 (0.1952) teacher_loss 0.2560 (0.1364) loss_zs_kd 0.0664 (0.0539) loss_oracle 0.5249 (0.4986) acc 96.8750 (93.4688) kd_loss 0.9228 (0.9401) lr 3.1545e-04 eta 0:02:09
epoch [39/50] batch [120/132] time 0.080 (0.087) data 0.000 (0.003) loss 0.6462 (0.6605) ce_loss 0.1349 (0.1908) teacher_loss 0.1059 (0.1344) loss_zs_kd 0.0519 (0.0544) loss_oracle 0.5144 (0.4989) acc 96.8750 (93.7240) kd_loss 0.9120 (0.9412) lr 3.1545e-04 eta 0:02:07
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,483
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 91.2%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [40/50] batch [20/132] time 0.084 (0.099) data 0.000 (0.012) loss 0.6117 (0.6551) ce_loss 0.1841 (0.2042) teacher_loss 0.1265 (0.1439) loss_zs_kd 0.0662 (0.0522) loss_oracle 0.4521 (0.4851) acc 96.8750 (93.5938) kd_loss 1.0157 (0.9527) lr 2.7103e-04 eta 0:02:22
epoch [40/50] batch [40/132] time 0.089 (0.093) data 0.000 (0.006) loss 0.5913 (0.6453) ce_loss 0.2277 (0.1953) teacher_loss 0.1039 (0.1357) loss_zs_kd 0.0673 (0.0525) loss_oracle 0.4537 (0.4833) acc 90.6250 (93.5156) kd_loss 0.8951 (0.9503) lr 2.7103e-04 eta 0:02:11
epoch [40/50] batch [60/132] time 0.096 (0.091) data 0.000 (0.004) loss 0.6513 (0.6348) ce_loss 0.2607 (0.1845) teacher_loss 0.2019 (0.1258) loss_zs_kd 0.0552 (0.0533) loss_oracle 0.4218 (0.4823) acc 90.6250 (93.8021) kd_loss 0.9315 (0.9471) lr 2.7103e-04 eta 0:02:07
epoch [40/50] batch [80/132] time 0.084 (0.091) data 0.000 (0.003) loss 0.6097 (0.6363) ce_loss 0.1840 (0.1883) teacher_loss 0.0940 (0.1312) loss_zs_kd 0.0528 (0.0544) loss_oracle 0.4893 (0.4779) acc 93.7500 (93.6328) kd_loss 0.9209 (0.9383) lr 2.7103e-04 eta 0:02:04
epoch [40/50] batch [100/132] time 0.092 (0.090) data 0.000 (0.003) loss 0.6263 (0.6382) ce_loss 0.1931 (0.1890) teacher_loss 0.1670 (0.1338) loss_zs_kd 0.0554 (0.0530) loss_oracle 0.4316 (0.4780) acc 93.7500 (93.5938) kd_loss 0.9293 (0.9370) lr 2.7103e-04 eta 0:02:01
epoch [40/50] batch [120/132] time 0.070 (0.089) data 0.000 (0.002) loss 0.5209 (0.6345) ce_loss 0.1047 (0.1866) teacher_loss 0.0364 (0.1318) loss_zs_kd 0.0434 (0.0521) loss_oracle 0.4627 (0.4767) acc 93.7500 (93.8281) kd_loss 0.9390 (0.9347) lr 2.7103e-04 eta 0:01:58
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,480
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 91.2%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [41/50] batch [20/132] time 0.084 (0.099) data 0.000 (0.015) loss 0.7109 (0.6598) ce_loss 0.1816 (0.2252) teacher_loss 0.2134 (0.1620) loss_zs_kd 0.0629 (0.0538) loss_oracle 0.4660 (0.4710) acc 90.6250 (92.1875) kd_loss 0.8867 (0.9267) lr 2.2949e-04 eta 0:02:08
epoch [41/50] batch [40/132] time 0.098 (0.091) data 0.000 (0.008) loss 0.7880 (0.6493) ce_loss 0.4666 (0.2093) teacher_loss 0.3437 (0.1509) loss_zs_kd 0.0772 (0.0527) loss_oracle 0.4058 (0.4721) acc 78.1250 (92.8906) kd_loss 0.8789 (0.9278) lr 2.2949e-04 eta 0:01:57
epoch [41/50] batch [60/132] time 0.092 (0.090) data 0.000 (0.005) loss 0.6504 (0.6412) ce_loss 0.3652 (0.2052) teacher_loss 0.2136 (0.1437) loss_zs_kd 0.0618 (0.0528) loss_oracle 0.4059 (0.4711) acc 90.6250 (92.9167) kd_loss 0.8503 (0.9276) lr 2.2949e-04 eta 0:01:52
epoch [41/50] batch [80/132] time 0.084 (0.089) data 0.000 (0.004) loss 0.5766 (0.6427) ce_loss 0.0587 (0.2000) teacher_loss 0.0401 (0.1408) loss_zs_kd 0.0411 (0.0542) loss_oracle 0.5159 (0.4748) acc 100.0000 (93.0859) kd_loss 0.9803 (0.9282) lr 2.2949e-04 eta 0:01:50
epoch [41/50] batch [100/132] time 0.082 (0.089) data 0.000 (0.003) loss 0.6224 (0.6444) ce_loss 0.1748 (0.2021) teacher_loss 0.1316 (0.1468) loss_zs_kd 0.0645 (0.0542) loss_oracle 0.4585 (0.4705) acc 96.8750 (93.0000) kd_loss 0.9412 (0.9268) lr 2.2949e-04 eta 0:01:48
epoch [41/50] batch [120/132] time 0.074 (0.089) data 0.000 (0.003) loss 0.5806 (0.6427) ce_loss 0.1137 (0.1999) teacher_loss 0.0917 (0.1434) loss_zs_kd 0.0440 (0.0539) loss_oracle 0.4669 (0.4723) acc 96.8750 (93.2552) kd_loss 0.9266 (0.9259) lr 2.2949e-04 eta 0:01:46
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,479
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 91.2%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [42/50] batch [20/132] time 0.072 (0.101) data 0.000 (0.015) loss 0.6212 (0.6349) ce_loss 0.1567 (0.2206) teacher_loss 0.1587 (0.1509) loss_zs_kd 0.0490 (0.0459) loss_oracle 0.4380 (0.4611) acc 93.7500 (92.9688) kd_loss 0.9295 (0.9309) lr 1.9098e-04 eta 0:01:57
epoch [42/50] batch [40/132] time 0.096 (0.092) data 0.000 (0.008) loss 0.5061 (0.6418) ce_loss 0.0497 (0.1968) teacher_loss 0.0275 (0.1376) loss_zs_kd 0.0480 (0.0489) loss_oracle 0.4545 (0.4797) acc 100.0000 (94.0625) kd_loss 0.8944 (0.9352) lr 1.9098e-04 eta 0:01:45
epoch [42/50] batch [60/132] time 0.090 (0.090) data 0.001 (0.005) loss 0.6057 (0.6406) ce_loss 0.1908 (0.2039) teacher_loss 0.1187 (0.1349) loss_zs_kd 0.0569 (0.0538) loss_oracle 0.4585 (0.4788) acc 93.7500 (93.2812) kd_loss 0.9216 (0.9373) lr 1.9098e-04 eta 0:01:41
epoch [42/50] batch [80/132] time 0.083 (0.089) data 0.000 (0.004) loss 0.6149 (0.6389) ce_loss 0.1854 (0.1976) teacher_loss 0.1174 (0.1278) loss_zs_kd 0.0517 (0.0531) loss_oracle 0.4716 (0.4846) acc 93.7500 (93.5156) kd_loss 1.0167 (0.9429) lr 1.9098e-04 eta 0:01:38
epoch [42/50] batch [100/132] time 0.084 (0.088) data 0.000 (0.003) loss 0.5825 (0.6389) ce_loss 0.1758 (0.1984) teacher_loss 0.1420 (0.1299) loss_zs_kd 0.0608 (0.0545) loss_oracle 0.4101 (0.4817) acc 93.7500 (93.4062) kd_loss 0.9592 (0.9421) lr 1.9098e-04 eta 0:01:36
epoch [42/50] batch [120/132] time 0.080 (0.088) data 0.000 (0.003) loss 0.6642 (0.6404) ce_loss 0.1874 (0.1982) teacher_loss 0.1040 (0.1305) loss_zs_kd 0.0683 (0.0555) loss_oracle 0.5261 (0.4822) acc 93.7500 (93.3594) kd_loss 0.9175 (0.9390) lr 1.9098e-04 eta 0:01:34
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,483
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 91.2%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [43/50] batch [20/132] time 0.086 (0.102) data 0.000 (0.013) loss 0.7229 (0.6758) ce_loss 0.1699 (0.2279) teacher_loss 0.1647 (0.1666) loss_zs_kd 0.0558 (0.0632) loss_oracle 0.5303 (0.4777) acc 93.7500 (91.5625) kd_loss 0.9593 (0.9462) lr 1.5567e-04 eta 0:01:46
epoch [43/50] batch [40/132] time 0.091 (0.095) data 0.001 (0.007) loss 0.6035 (0.6532) ce_loss 0.2357 (0.2035) teacher_loss 0.1194 (0.1395) loss_zs_kd 0.0851 (0.0569) loss_oracle 0.4416 (0.4853) acc 96.8750 (93.0469) kd_loss 0.9338 (0.9456) lr 1.5567e-04 eta 0:01:36
epoch [43/50] batch [60/132] time 0.086 (0.092) data 0.001 (0.005) loss 0.7899 (0.6640) ce_loss 0.2881 (0.2149) teacher_loss 0.2707 (0.1453) loss_zs_kd 0.0624 (0.0560) loss_oracle 0.4879 (0.4907) acc 90.6250 (92.8646) kd_loss 0.8876 (0.9395) lr 1.5567e-04 eta 0:01:31
epoch [43/50] batch [80/132] time 0.084 (0.091) data 0.000 (0.003) loss 0.5756 (0.6597) ce_loss 0.0747 (0.2097) teacher_loss 0.0529 (0.1407) loss_zs_kd 0.0437 (0.0571) loss_oracle 0.5009 (0.4904) acc 100.0000 (93.0469) kd_loss 0.9323 (0.9347) lr 1.5567e-04 eta 0:01:28
epoch [43/50] batch [100/132] time 0.091 (0.090) data 0.000 (0.003) loss 0.6135 (0.6613) ce_loss 0.1927 (0.2102) teacher_loss 0.1305 (0.1415) loss_zs_kd 0.0588 (0.0573) loss_oracle 0.4536 (0.4911) acc 93.7500 (93.0625) kd_loss 0.8891 (0.9311) lr 1.5567e-04 eta 0:01:26
epoch [43/50] batch [120/132] time 0.074 (0.089) data 0.000 (0.002) loss 0.5427 (0.6585) ce_loss 0.1322 (0.2078) teacher_loss 0.0546 (0.1402) loss_zs_kd 0.0538 (0.0576) loss_oracle 0.4612 (0.4895) acc 96.8750 (93.1250) kd_loss 0.9639 (0.9305) lr 1.5567e-04 eta 0:01:23
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,481
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 91.2%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [44/50] batch [20/132] time 0.068 (0.093) data 0.000 (0.015) loss 0.7259 (0.6378) ce_loss 0.2510 (0.1814) teacher_loss 0.1960 (0.1241) loss_zs_kd 0.0497 (0.0581) loss_oracle 0.5051 (0.4846) acc 90.6250 (94.2188) kd_loss 0.9596 (0.9397) lr 1.2369e-04 eta 0:01:24
epoch [44/50] batch [40/132] time 0.079 (0.082) data 0.000 (0.008) loss 0.5750 (0.6433) ce_loss 0.0892 (0.1857) teacher_loss 0.0547 (0.1278) loss_zs_kd 0.0414 (0.0577) loss_oracle 0.4996 (0.4866) acc 96.8750 (93.9062) kd_loss 0.9240 (0.9308) lr 1.2369e-04 eta 0:01:12
epoch [44/50] batch [60/132] time 0.077 (0.079) data 0.000 (0.005) loss 0.6588 (0.6543) ce_loss 0.2446 (0.2027) teacher_loss 0.1184 (0.1384) loss_zs_kd 0.0525 (0.0576) loss_oracle 0.5141 (0.4871) acc 93.7500 (93.3854) kd_loss 0.9801 (0.9306) lr 1.2369e-04 eta 0:01:08
epoch [44/50] batch [80/132] time 0.093 (0.078) data 0.000 (0.004) loss 0.7551 (0.6526) ce_loss 0.1890 (0.1991) teacher_loss 0.1387 (0.1365) loss_zs_kd 0.0518 (0.0571) loss_oracle 0.5904 (0.4876) acc 93.7500 (93.5938) kd_loss 1.0374 (0.9322) lr 1.2369e-04 eta 0:01:05
epoch [44/50] batch [100/132] time 0.063 (0.077) data 0.000 (0.003) loss 0.5948 (0.6482) ce_loss 0.2052 (0.1961) teacher_loss 0.0957 (0.1332) loss_zs_kd 0.0614 (0.0566) loss_oracle 0.4684 (0.4867) acc 93.7500 (93.7188) kd_loss 0.9141 (0.9324) lr 1.2369e-04 eta 0:01:03
epoch [44/50] batch [120/132] time 0.065 (0.075) data 0.000 (0.003) loss 0.8175 (0.6520) ce_loss 0.4331 (0.1989) teacher_loss 0.3315 (0.1364) loss_zs_kd 0.0735 (0.0568) loss_oracle 0.4492 (0.4872) acc 90.6250 (93.6719) kd_loss 0.9163 (0.9329) lr 1.2369e-04 eta 0:01:00
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,487
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 91.3%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [45/50] batch [20/132] time 0.086 (0.098) data 0.000 (0.013) loss 0.6261 (0.6451) ce_loss 0.2209 (0.2002) teacher_loss 0.1492 (0.1365) loss_zs_kd 0.0628 (0.0582) loss_oracle 0.4455 (0.4795) acc 90.6250 (93.7500) kd_loss 0.8263 (0.9167) lr 9.5173e-05 eta 0:01:15
epoch [45/50] batch [40/132] time 0.082 (0.091) data 0.000 (0.007) loss 0.6600 (0.6437) ce_loss 0.1780 (0.1835) teacher_loss 0.1186 (0.1308) loss_zs_kd 0.0809 (0.0565) loss_oracle 0.5009 (0.4846) acc 96.8750 (94.0625) kd_loss 0.9148 (0.9274) lr 9.5173e-05 eta 0:01:08
epoch [45/50] batch [60/132] time 0.087 (0.089) data 0.000 (0.005) loss 0.4939 (0.6451) ce_loss 0.0113 (0.1915) teacher_loss 0.0057 (0.1316) loss_zs_kd 0.0344 (0.0557) loss_oracle 0.4709 (0.4856) acc 100.0000 (94.0625) kd_loss 0.9433 (0.9220) lr 9.5173e-05 eta 0:01:04
epoch [45/50] batch [80/132] time 0.075 (0.087) data 0.000 (0.004) loss 0.5875 (0.6512) ce_loss 0.0442 (0.2003) teacher_loss 0.0440 (0.1392) loss_zs_kd 0.0510 (0.0583) loss_oracle 0.5180 (0.4828) acc 100.0000 (93.5938) kd_loss 0.9321 (0.9236) lr 9.5173e-05 eta 0:01:01
epoch [45/50] batch [100/132] time 0.082 (0.086) data 0.000 (0.003) loss 0.5005 (0.6515) ce_loss 0.1843 (0.2034) teacher_loss 0.0810 (0.1386) loss_zs_kd 0.0202 (0.0587) loss_oracle 0.4094 (0.4836) acc 96.8750 (93.3125) kd_loss 0.8358 (0.9231) lr 9.5173e-05 eta 0:00:59
epoch [45/50] batch [120/132] time 0.083 (0.086) data 0.001 (0.002) loss 0.5617 (0.6531) ce_loss 0.1118 (0.2048) teacher_loss 0.1025 (0.1407) loss_zs_kd 0.0489 (0.0593) loss_oracle 0.4347 (0.4828) acc 96.8750 (93.1771) kd_loss 0.8820 (0.9237) lr 9.5173e-05 eta 0:00:57
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,486
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 91.3%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [46/50] batch [20/132] time 0.090 (0.106) data 0.000 (0.019) loss 0.5799 (0.6179) ce_loss 0.1022 (0.1839) teacher_loss 0.0562 (0.1260) loss_zs_kd 0.0430 (0.0599) loss_oracle 0.5021 (0.4620) acc 93.7500 (93.4375) kd_loss 0.8604 (0.9267) lr 7.0224e-05 eta 0:01:07
epoch [46/50] batch [40/132] time 0.079 (0.096) data 0.000 (0.010) loss 0.7244 (0.6173) ce_loss 0.4028 (0.1902) teacher_loss 0.2516 (0.1283) loss_zs_kd 0.0965 (0.0583) loss_oracle 0.4245 (0.4598) acc 81.2500 (93.0469) kd_loss 0.9258 (0.9198) lr 7.0224e-05 eta 0:00:59
epoch [46/50] batch [60/132] time 0.093 (0.093) data 0.001 (0.007) loss 0.5580 (0.6301) ce_loss 0.0588 (0.1950) teacher_loss 0.0550 (0.1315) loss_zs_kd 0.0269 (0.0568) loss_oracle 0.4896 (0.4703) acc 100.0000 (93.1250) kd_loss 0.9001 (0.9200) lr 7.0224e-05 eta 0:00:55
epoch [46/50] batch [80/132] time 0.095 (0.091) data 0.000 (0.005) loss 0.6061 (0.6302) ce_loss 0.1749 (0.1925) teacher_loss 0.1468 (0.1314) loss_zs_kd 0.0400 (0.0566) loss_oracle 0.4394 (0.4705) acc 96.8750 (93.3984) kd_loss 0.9219 (0.9201) lr 7.0224e-05 eta 0:00:53
epoch [46/50] batch [100/132] time 0.087 (0.090) data 0.000 (0.004) loss 0.5574 (0.6264) ce_loss 0.1139 (0.1874) teacher_loss 0.0515 (0.1284) loss_zs_kd 0.0330 (0.0547) loss_oracle 0.4894 (0.4707) acc 96.8750 (93.6250) kd_loss 0.8817 (0.9201) lr 7.0224e-05 eta 0:00:50
epoch [46/50] batch [120/132] time 0.073 (0.089) data 0.000 (0.003) loss 0.8055 (0.6324) ce_loss 0.2087 (0.1914) teacher_loss 0.2087 (0.1315) loss_zs_kd 0.0218 (0.0552) loss_oracle 0.5859 (0.4733) acc 93.7500 (93.3333) kd_loss 0.9400 (0.9170) lr 7.0224e-05 eta 0:00:48
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,484
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 91.2%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [47/50] batch [20/132] time 0.074 (0.104) data 0.000 (0.018) loss 0.5712 (0.6431) ce_loss 0.1166 (0.2023) teacher_loss 0.1029 (0.1435) loss_zs_kd 0.0449 (0.0550) loss_oracle 0.4458 (0.4721) acc 96.8750 (93.4375) kd_loss 0.8838 (0.9175) lr 4.8943e-05 eta 0:00:52
epoch [47/50] batch [40/132] time 0.081 (0.095) data 0.000 (0.009) loss 0.4797 (0.6669) ce_loss 0.0543 (0.2159) teacher_loss 0.0433 (0.1521) loss_zs_kd 0.0330 (0.0566) loss_oracle 0.4199 (0.4864) acc 100.0000 (92.5781) kd_loss 0.8616 (0.9181) lr 4.8943e-05 eta 0:00:46
epoch [47/50] batch [60/132] time 0.090 (0.092) data 0.001 (0.006) loss 0.4924 (0.6570) ce_loss 0.0542 (0.2161) teacher_loss 0.0442 (0.1507) loss_zs_kd 0.0575 (0.0570) loss_oracle 0.4194 (0.4779) acc 100.0000 (92.7604) kd_loss 0.9139 (0.9170) lr 4.8943e-05 eta 0:00:42
epoch [47/50] batch [80/132] time 0.082 (0.090) data 0.000 (0.005) loss 0.9209 (0.6522) ce_loss 0.5869 (0.2114) teacher_loss 0.3804 (0.1494) loss_zs_kd 0.0508 (0.0565) loss_oracle 0.5151 (0.4746) acc 84.3750 (92.8906) kd_loss 0.9139 (0.9171) lr 4.8943e-05 eta 0:00:40
epoch [47/50] batch [100/132] time 0.073 (0.089) data 0.000 (0.004) loss 0.8335 (0.6510) ce_loss 0.3220 (0.2093) teacher_loss 0.2024 (0.1469) loss_zs_kd 0.0896 (0.0554) loss_oracle 0.5863 (0.4764) acc 90.6250 (93.0000) kd_loss 0.9290 (0.9152) lr 4.8943e-05 eta 0:00:38
epoch [47/50] batch [120/132] time 0.077 (0.088) data 0.000 (0.003) loss 0.6298 (0.6481) ce_loss 0.2908 (0.2048) teacher_loss 0.1915 (0.1427) loss_zs_kd 0.0546 (0.0565) loss_oracle 0.4110 (0.4771) acc 93.7500 (93.1510) kd_loss 0.9406 (0.9162) lr 4.8943e-05 eta 0:00:35
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,482
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 91.2%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [48/50] batch [20/132] time 0.095 (0.104) data 0.000 (0.014) loss 0.5368 (0.6460) ce_loss 0.1039 (0.2045) teacher_loss 0.0233 (0.1426) loss_zs_kd 0.0571 (0.0555) loss_oracle 0.4849 (0.4756) acc 96.8750 (92.5000) kd_loss 0.9235 (0.9058) lr 3.1417e-05 eta 0:00:38
epoch [48/50] batch [40/132] time 0.082 (0.093) data 0.000 (0.007) loss 0.8880 (0.6347) ce_loss 0.4980 (0.1878) teacher_loss 0.3279 (0.1279) loss_zs_kd 0.0902 (0.0555) loss_oracle 0.5149 (0.4790) acc 84.3750 (93.4375) kd_loss 0.9356 (0.9161) lr 3.1417e-05 eta 0:00:33
epoch [48/50] batch [60/132] time 0.083 (0.090) data 0.001 (0.005) loss 0.6250 (0.6289) ce_loss 0.1968 (0.1835) teacher_loss 0.1151 (0.1278) loss_zs_kd 0.0379 (0.0541) loss_oracle 0.4909 (0.4740) acc 93.7500 (93.5417) kd_loss 0.8955 (0.9083) lr 3.1417e-05 eta 0:00:30
epoch [48/50] batch [80/132] time 0.081 (0.089) data 0.000 (0.004) loss 0.5854 (0.6336) ce_loss 0.1432 (0.1913) teacher_loss 0.0586 (0.1311) loss_zs_kd 0.0323 (0.0543) loss_oracle 0.5107 (0.4754) acc 96.8750 (93.3984) kd_loss 0.9460 (0.9125) lr 3.1417e-05 eta 0:00:27
epoch [48/50] batch [100/132] time 0.088 (0.088) data 0.000 (0.003) loss 0.6323 (0.6346) ce_loss 0.2090 (0.1922) teacher_loss 0.1299 (0.1337) loss_zs_kd 0.0471 (0.0541) loss_oracle 0.4789 (0.4739) acc 90.6250 (93.3438) kd_loss 0.8849 (0.9097) lr 3.1417e-05 eta 0:00:26
epoch [48/50] batch [120/132] time 0.081 (0.089) data 0.000 (0.003) loss 0.5334 (0.6369) ce_loss 0.0990 (0.1979) teacher_loss 0.0537 (0.1387) loss_zs_kd 0.0478 (0.0545) loss_oracle 0.4558 (0.4709) acc 96.8750 (93.1250) kd_loss 0.8243 (0.9082) lr 3.1417e-05 eta 0:00:24
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,484
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 91.2%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [49/50] batch [20/132] time 0.083 (0.104) data 0.000 (0.017) loss 0.7061 (0.6400) ce_loss 0.2837 (0.1990) teacher_loss 0.2586 (0.1492) loss_zs_kd 0.0564 (0.0480) loss_oracle 0.4193 (0.4669) acc 90.6250 (93.5938) kd_loss 0.8661 (0.9135) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [40/132] time 0.084 (0.096) data 0.000 (0.009) loss 0.6583 (0.6637) ce_loss 0.2421 (0.2101) teacher_loss 0.2026 (0.1523) loss_zs_kd 0.0445 (0.0544) loss_oracle 0.4335 (0.4842) acc 90.6250 (92.7344) kd_loss 0.8328 (0.9056) lr 1.7713e-05 eta 0:00:21
epoch [49/50] batch [60/132] time 0.088 (0.092) data 0.001 (0.006) loss 0.7157 (0.6586) ce_loss 0.3464 (0.2096) teacher_loss 0.2489 (0.1526) loss_zs_kd 0.0670 (0.0526) loss_oracle 0.4333 (0.4797) acc 90.6250 (92.9167) kd_loss 0.9041 (0.9040) lr 1.7713e-05 eta 0:00:18
epoch [49/50] batch [80/132] time 0.086 (0.090) data 0.000 (0.004) loss 0.5293 (0.6490) ce_loss 0.1815 (0.2032) teacher_loss 0.0773 (0.1455) loss_zs_kd 0.0426 (0.0534) loss_oracle 0.4307 (0.4767) acc 93.7500 (92.9688) kd_loss 0.9353 (0.9025) lr 1.7713e-05 eta 0:00:16
epoch [49/50] batch [100/132] time 0.091 (0.090) data 0.000 (0.004) loss 0.6077 (0.6505) ce_loss 0.1130 (0.2081) teacher_loss 0.0928 (0.1506) loss_zs_kd 0.0686 (0.0554) loss_oracle 0.4806 (0.4723) acc 96.8750 (92.8750) kd_loss 0.9287 (0.9025) lr 1.7713e-05 eta 0:00:14
epoch [49/50] batch [120/132] time 0.076 (0.089) data 0.000 (0.003) loss 0.5494 (0.6436) ce_loss 0.0735 (0.2030) teacher_loss 0.0631 (0.1472) loss_zs_kd 0.0292 (0.0538) loss_oracle 0.4718 (0.4695) acc 100.0000 (93.0990) kd_loss 0.9422 (0.9039) lr 1.7713e-05 eta 0:00:12
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,485
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 91.3%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
epoch [50/50] batch [20/132] time 0.091 (0.106) data 0.000 (0.014) loss 0.8881 (0.6158) ce_loss 0.5625 (0.1906) teacher_loss 0.3795 (0.1316) loss_zs_kd 0.0584 (0.0573) loss_oracle 0.4794 (0.4556) acc 81.2500 (93.4375) kd_loss 0.9424 (0.9039) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [40/132] time 0.092 (0.096) data 0.000 (0.007) loss 0.5534 (0.5967) ce_loss 0.0802 (0.1634) teacher_loss 0.0807 (0.1109) loss_zs_kd 0.0400 (0.0524) loss_oracle 0.4527 (0.4596) acc 100.0000 (94.7656) kd_loss 0.8370 (0.9036) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [60/132] time 0.081 (0.093) data 0.001 (0.005) loss 0.5671 (0.6045) ce_loss 0.0501 (0.1759) teacher_loss 0.0220 (0.1190) loss_zs_kd 0.0503 (0.0535) loss_oracle 0.5199 (0.4588) acc 100.0000 (93.9583) kd_loss 0.9194 (0.9020) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [80/132] time 0.085 (0.092) data 0.000 (0.004) loss 0.6145 (0.6115) ce_loss 0.1561 (0.1797) teacher_loss 0.0542 (0.1252) loss_zs_kd 0.0619 (0.0546) loss_oracle 0.5293 (0.4589) acc 96.8750 (93.7109) kd_loss 0.9261 (0.9037) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [100/132] time 0.094 (0.091) data 0.000 (0.003) loss 0.5593 (0.6214) ce_loss 0.1209 (0.1847) teacher_loss 0.0697 (0.1302) loss_zs_kd 0.0664 (0.0541) loss_oracle 0.4565 (0.4641) acc 96.8750 (93.6875) kd_loss 0.8869 (0.9053) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [120/132] time 0.087 (0.090) data 0.000 (0.003) loss 0.5088 (0.6205) ce_loss 0.0627 (0.1856) teacher_loss 0.0532 (0.1290) loss_zs_kd 0.0360 (0.0545) loss_oracle 0.4376 (0.4642) acc 96.8750 (93.6719) kd_loss 0.9298 (0.9049) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,484
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 91.2%
******* Domain s best val acc:      99.4%, epoch: 26 *******
******* Domain s best val test acc: 89.8%, epoch: 26 *******
******* Domain s best test acc:     90.4%, epoch: 15 *******
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/pacs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:13:54

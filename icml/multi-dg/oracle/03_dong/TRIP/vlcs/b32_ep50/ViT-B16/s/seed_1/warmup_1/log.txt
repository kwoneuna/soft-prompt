Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'pascal']
Target     ['sun']
# classes  5
# train_x  5,213
# val      2,234
# test     3,282
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/162] time 0.081 (0.131) data 0.000 (0.024) loss 1.0015 (0.6226) ce_loss 1.0010 (0.6222) teacher_loss 1.0011 (0.6221) loss_zs_kd 0.0004 (0.0001) loss_oracle 0.0003 (0.0005) acc 65.6250 (78.9062) kd_loss 0.0011 (0.0019) lr 1.0000e-05 eta 0:17:38
epoch [1/50] batch [40/162] time 0.090 (0.109) data 0.000 (0.012) loss 0.9350 (0.6317) ce_loss 0.9331 (0.6311) teacher_loss 0.9337 (0.6310) loss_zs_kd 0.0019 (0.0007) loss_oracle 0.0003 (0.0004) acc 68.7500 (78.9062) kd_loss 0.0013 (0.0014) lr 1.0000e-05 eta 0:14:35
epoch [1/50] batch [60/162] time 0.085 (0.101) data 0.000 (0.008) loss 0.5796 (0.6265) ce_loss 0.5762 (0.6253) teacher_loss 0.5762 (0.6252) loss_zs_kd 0.0054 (0.0018) loss_oracle 0.0007 (0.0004) acc 84.3750 (78.6458) kd_loss 0.0024 (0.0014) lr 1.0000e-05 eta 0:13:36
epoch [1/50] batch [80/162] time 0.080 (0.098) data 0.000 (0.006) loss 0.6349 (0.6184) ce_loss 0.6299 (0.6165) teacher_loss 0.6304 (0.6164) loss_zs_kd 0.0085 (0.0032) loss_oracle 0.0003 (0.0004) acc 75.0000 (78.9062) kd_loss 0.0013 (0.0013) lr 1.0000e-05 eta 0:13:07
epoch [1/50] batch [100/162] time 0.085 (0.095) data 0.000 (0.005) loss 0.4969 (0.6118) ce_loss 0.4937 (0.6093) teacher_loss 0.4933 (0.6092) loss_zs_kd 0.0066 (0.0045) loss_oracle 0.0003 (0.0004) acc 84.3750 (79.2500) kd_loss 0.0009 (0.0013) lr 1.0000e-05 eta 0:12:40
epoch [1/50] batch [120/162] time 0.080 (0.093) data 0.000 (0.004) loss 0.8192 (0.5960) ce_loss 0.8159 (0.5931) teacher_loss 0.8150 (0.5930) loss_zs_kd 0.0074 (0.0054) loss_oracle 0.0004 (0.0004) acc 65.6250 (79.5573) kd_loss 0.0017 (0.0013) lr 1.0000e-05 eta 0:12:19
epoch [1/50] batch [140/162] time 0.074 (0.091) data 0.000 (0.004) loss 0.3582 (0.5881) ce_loss 0.3506 (0.5847) teacher_loss 0.3504 (0.5845) loss_zs_kd 0.0150 (0.0063) loss_oracle 0.0004 (0.0004) acc 87.5000 (80.0000) kd_loss 0.0013 (0.0014) lr 1.0000e-05 eta 0:12:02
epoch [1/50] batch [160/162] time 0.080 (0.089) data 0.001 (0.003) loss 0.3428 (0.5935) ce_loss 0.3359 (0.5896) teacher_loss 0.3354 (0.5894) loss_zs_kd 0.0134 (0.0074) loss_oracle 0.0007 (0.0004) acc 84.3750 (79.6875) kd_loss 0.0022 (0.0015) lr 1.0000e-05 eta 0:11:49
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,900
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 87.1%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,371
* accuracy: 72.2%
* error: 27.8%
* macro_f1: 66.9%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      85.0%, epoch: 1 *******
******* Domain s best val test acc: 72.2%, epoch: 1 *******
******* Domain s best test acc:     72.2%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/ana
epoch [2/50] batch [20/162] time 0.085 (0.107) data 0.000 (0.024) loss 0.6619 (0.5951) ce_loss 0.6377 (0.5706) teacher_loss 0.6299 (0.5686) loss_zs_kd 0.0406 (0.0435) loss_oracle 0.0117 (0.0048) acc 81.2500 (81.4062) kd_loss 0.0123 (0.0072) lr 2.0000e-03 eta 0:14:03
epoch [2/50] batch [40/162] time 0.089 (0.096) data 0.000 (0.012) loss 0.5142 (0.5617) ce_loss 0.4780 (0.5321) teacher_loss 0.4486 (0.5248) loss_zs_kd 0.0801 (0.0511) loss_oracle 0.0255 (0.0113) acc 71.8750 (82.0312) kd_loss 0.0660 (0.0217) lr 2.0000e-03 eta 0:12:41
epoch [2/50] batch [60/162] time 0.073 (0.089) data 0.000 (0.008) loss 0.5218 (0.5664) ce_loss 0.4675 (0.5362) teacher_loss 0.3785 (0.5099) loss_zs_kd 0.1136 (0.0565) loss_oracle 0.0865 (0.0283) acc 81.2500 (81.8750) kd_loss 0.2383 (0.0630) lr 2.0000e-03 eta 0:11:44
epoch [2/50] batch [80/162] time 0.074 (0.085) data 0.000 (0.006) loss 0.4600 (0.5506) ce_loss 0.4983 (0.5294) teacher_loss 0.2369 (0.4677) loss_zs_kd 0.1653 (0.0666) loss_oracle 0.1404 (0.0496) acc 78.1250 (81.7578) kd_loss 0.5564 (0.1457) lr 2.0000e-03 eta 0:11:10
epoch [2/50] batch [100/162] time 0.062 (0.083) data 0.000 (0.005) loss 0.5814 (0.5526) ce_loss 0.5366 (0.5328) teacher_loss 0.3432 (0.4405) loss_zs_kd 0.1096 (0.0766) loss_oracle 0.1834 (0.0739) acc 87.5000 (81.5000) kd_loss 0.5264 (0.2197) lr 2.0000e-03 eta 0:10:50
epoch [2/50] batch [120/162] time 0.083 (0.083) data 0.000 (0.004) loss 0.7365 (0.5645) ce_loss 0.6831 (0.5372) teacher_loss 0.4091 (0.4214) loss_zs_kd 0.1290 (0.0856) loss_oracle 0.2629 (0.1003) acc 84.3750 (81.3802) kd_loss 0.5701 (0.2749) lr 2.0000e-03 eta 0:10:45
epoch [2/50] batch [140/162] time 0.083 (0.082) data 0.001 (0.004) loss 0.5924 (0.5708) ce_loss 0.3936 (0.5320) teacher_loss 0.2749 (0.3999) loss_zs_kd 0.1124 (0.0940) loss_oracle 0.2613 (0.1239) acc 90.6250 (81.4286) kd_loss 0.5751 (0.3232) lr 2.0000e-03 eta 0:10:41
epoch [2/50] batch [160/162] time 0.070 (0.081) data 0.000 (0.003) loss 0.6245 (0.5807) ce_loss 0.4338 (0.5321) teacher_loss 0.2273 (0.3870) loss_zs_kd 0.1731 (0.1013) loss_oracle 0.3107 (0.1430) acc 84.3750 (81.3281) kd_loss 0.8243 (0.3660) lr 2.0000e-03 eta 0:10:30
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,929
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 88.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,505
* accuracy: 76.3%
* error: 23.7%
* macro_f1: 73.1%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      86.3%, epoch: 2 *******
******* Domain s best val test acc: 76.3%, epoch: 2 *******
******* Domain s best test acc:     76.3%, epoch: 2 *******
epoch [3/50] batch [20/162] time 0.080 (0.095) data 0.000 (0.013) loss 0.7011 (0.6932) ce_loss 0.5308 (0.5051) teacher_loss 0.3246 (0.3357) loss_zs_kd 0.0817 (0.1210) loss_oracle 0.3357 (0.2969) acc 87.5000 (82.0312) kd_loss 0.8168 (0.8196) lr 1.9980e-03 eta 0:12:19
epoch [3/50] batch [40/162] time 0.087 (0.088) data 0.000 (0.007) loss 0.9484 (0.7649) ce_loss 0.6426 (0.5136) teacher_loss 0.5408 (0.3871) loss_zs_kd 0.0734 (0.1124) loss_oracle 0.3709 (0.3216) acc 75.0000 (81.4844) kd_loss 0.9768 (0.8491) lr 1.9980e-03 eta 0:11:22
epoch [3/50] batch [60/162] time 0.083 (0.086) data 0.001 (0.005) loss 0.8079 (0.8082) ce_loss 0.3984 (0.5298) teacher_loss 0.4192 (0.4314) loss_zs_kd 0.1118 (0.1014) loss_oracle 0.3329 (0.3260) acc 84.3750 (81.0938) kd_loss 0.9461 (0.8823) lr 1.9980e-03 eta 0:11:04
epoch [3/50] batch [80/162] time 0.088 (0.086) data 0.000 (0.004) loss 0.7827 (0.8187) ce_loss 0.4790 (0.5217) teacher_loss 0.4350 (0.4438) loss_zs_kd 0.0445 (0.0906) loss_oracle 0.3254 (0.3297) acc 78.1250 (80.8203) kd_loss 0.9891 (0.9098) lr 1.9980e-03 eta 0:11:03
epoch [3/50] batch [100/162] time 0.086 (0.086) data 0.000 (0.003) loss 0.4913 (0.8133) ce_loss 0.2224 (0.5206) teacher_loss 0.2004 (0.4531) loss_zs_kd 0.0537 (0.0838) loss_oracle 0.2640 (0.3183) acc 93.7500 (81.2188) kd_loss 0.9712 (0.9234) lr 1.9980e-03 eta 0:10:58
epoch [3/50] batch [120/162] time 0.086 (0.085) data 0.000 (0.002) loss 0.7727 (0.7983) ce_loss 0.4609 (0.5130) teacher_loss 0.4784 (0.4502) loss_zs_kd 0.0592 (0.0804) loss_oracle 0.2648 (0.3080) acc 78.1250 (81.6146) kd_loss 0.9372 (0.9249) lr 1.9980e-03 eta 0:10:53
epoch [3/50] batch [140/162] time 0.082 (0.085) data 0.000 (0.002) loss 0.6307 (0.7871) ce_loss 0.4238 (0.5073) teacher_loss 0.3634 (0.4462) loss_zs_kd 0.0490 (0.0776) loss_oracle 0.2428 (0.3021) acc 87.5000 (81.6964) kd_loss 0.8549 (0.9274) lr 1.9980e-03 eta 0:10:52
epoch [3/50] batch [160/162] time 0.071 (0.084) data 0.000 (0.002) loss 0.6127 (0.7790) ce_loss 0.2649 (0.5022) teacher_loss 0.2288 (0.4409) loss_zs_kd 0.0730 (0.0776) loss_oracle 0.3474 (0.2993) acc 90.6250 (81.9336) kd_loss 0.9185 (0.9252) lr 1.9980e-03 eta 0:10:42
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.9%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,534
* accuracy: 77.2%
* error: 22.8%
* macro_f1: 73.7%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      86.9%, epoch: 3 *******
******* Domain s best val test acc: 77.2%, epoch: 3 *******
******* Domain s best test acc:     77.2%, epoch: 3 *******
epoch [4/50] batch [20/162] time 0.085 (0.105) data 0.000 (0.020) loss 0.8997 (0.7536) ce_loss 0.6538 (0.4707) teacher_loss 0.5309 (0.3989) loss_zs_kd 0.1234 (0.0837) loss_oracle 0.3070 (0.3129) acc 71.8750 (83.4375) kd_loss 0.8533 (0.8596) lr 1.9921e-03 eta 0:13:16
epoch [4/50] batch [40/162] time 0.079 (0.095) data 0.000 (0.010) loss 0.8027 (0.7709) ce_loss 0.4478 (0.4688) teacher_loss 0.3451 (0.3960) loss_zs_kd 0.0955 (0.0960) loss_oracle 0.4099 (0.3270) acc 87.5000 (83.6719) kd_loss 0.8563 (0.8408) lr 1.9921e-03 eta 0:12:02
epoch [4/50] batch [60/162] time 0.089 (0.092) data 0.001 (0.007) loss 0.7018 (0.7865) ce_loss 0.3535 (0.4778) teacher_loss 0.2771 (0.4009) loss_zs_kd 0.0903 (0.0953) loss_oracle 0.3796 (0.3380) acc 90.6250 (83.2292) kd_loss 0.7941 (0.8307) lr 1.9921e-03 eta 0:11:33
epoch [4/50] batch [80/162] time 0.079 (0.090) data 0.000 (0.005) loss 0.7317 (0.7872) ce_loss 0.4490 (0.4680) teacher_loss 0.3447 (0.3826) loss_zs_kd 0.1209 (0.0975) loss_oracle 0.3266 (0.3558) acc 81.2500 (83.2422) kd_loss 0.7840 (0.8322) lr 1.9921e-03 eta 0:11:18
epoch [4/50] batch [100/162] time 0.082 (0.089) data 0.000 (0.004) loss 0.7256 (0.8057) ce_loss 0.3767 (0.4761) teacher_loss 0.3079 (0.3834) loss_zs_kd 0.1137 (0.1064) loss_oracle 0.3608 (0.3691) acc 84.3750 (82.6250) kd_loss 0.7010 (0.8283) lr 1.9921e-03 eta 0:11:07
epoch [4/50] batch [120/162] time 0.090 (0.088) data 0.001 (0.004) loss 1.1194 (0.8230) ce_loss 0.7642 (0.4824) teacher_loss 0.5884 (0.3833) loss_zs_kd 0.1474 (0.1092) loss_oracle 0.4574 (0.3851) acc 68.7500 (82.3438) kd_loss 0.8544 (0.8308) lr 1.9921e-03 eta 0:10:59
epoch [4/50] batch [140/162] time 0.076 (0.088) data 0.000 (0.003) loss 0.7642 (0.8348) ce_loss 0.4702 (0.4831) teacher_loss 0.2809 (0.3818) loss_zs_kd 0.0653 (0.1084) loss_oracle 0.4506 (0.3988) acc 81.2500 (82.5000) kd_loss 0.8504 (0.8352) lr 1.9921e-03 eta 0:10:55
epoch [4/50] batch [160/162] time 0.070 (0.086) data 0.000 (0.003) loss 1.1620 (0.8529) ce_loss 0.8262 (0.4909) teacher_loss 0.6102 (0.3879) loss_zs_kd 0.1177 (0.1094) loss_oracle 0.4929 (0.4103) acc 71.8750 (82.0312) kd_loss 0.8268 (0.8380) lr 1.9921e-03 eta 0:10:43
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,916
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 88.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,666
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 75.1%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      86.9%, epoch: 3 *******
******* Domain s best val test acc: 77.2%, epoch: 3 *******
******* Domain s best test acc:     81.2%, epoch: 4 *******
epoch [5/50] batch [20/162] time 0.080 (0.093) data 0.000 (0.012) loss 0.9471 (0.9292) ce_loss 0.5518 (0.5235) teacher_loss 0.4591 (0.3892) loss_zs_kd 0.0843 (0.0995) loss_oracle 0.4458 (0.4902) acc 78.1250 (80.4688) kd_loss 0.8672 (0.8600) lr 1.9823e-03 eta 0:11:34
epoch [5/50] batch [40/162] time 0.083 (0.088) data 0.000 (0.006) loss 0.9919 (0.9184) ce_loss 0.4497 (0.4695) teacher_loss 0.3218 (0.3461) loss_zs_kd 0.0740 (0.1106) loss_oracle 0.6331 (0.5170) acc 84.3750 (82.9688) kd_loss 0.8880 (0.8721) lr 1.9823e-03 eta 0:10:55
epoch [5/50] batch [60/162] time 0.079 (0.087) data 0.000 (0.004) loss 0.7146 (0.9364) ce_loss 0.2659 (0.4758) teacher_loss 0.1754 (0.3617) loss_zs_kd 0.0835 (0.1093) loss_oracle 0.4975 (0.5200) acc 87.5000 (83.2292) kd_loss 0.8974 (0.8766) lr 1.9823e-03 eta 0:10:45
epoch [5/50] batch [80/162] time 0.093 (0.087) data 0.000 (0.003) loss 1.0580 (0.9170) ce_loss 0.7339 (0.4772) teacher_loss 0.5768 (0.3600) loss_zs_kd 0.1183 (0.1119) loss_oracle 0.4221 (0.5011) acc 75.0000 (82.8906) kd_loss 0.9153 (0.8798) lr 1.9823e-03 eta 0:10:38
epoch [5/50] batch [100/162] time 0.086 (0.087) data 0.001 (0.003) loss 1.0515 (0.9036) ce_loss 0.5044 (0.4802) teacher_loss 0.5033 (0.3520) loss_zs_kd 0.2022 (0.1186) loss_oracle 0.4471 (0.4922) acc 84.3750 (82.6250) kd_loss 0.9460 (0.8868) lr 1.9823e-03 eta 0:10:36
epoch [5/50] batch [120/162] time 0.080 (0.086) data 0.000 (0.002) loss 1.0801 (0.8964) ce_loss 0.6597 (0.4816) teacher_loss 0.4942 (0.3461) loss_zs_kd 0.1268 (0.1193) loss_oracle 0.5225 (0.4906) acc 84.3750 (82.8646) kd_loss 0.9369 (0.8933) lr 1.9823e-03 eta 0:10:31
epoch [5/50] batch [140/162] time 0.086 (0.086) data 0.001 (0.002) loss 0.6771 (0.8992) ce_loss 0.2832 (0.4851) teacher_loss 0.1381 (0.3447) loss_zs_kd 0.1290 (0.1223) loss_oracle 0.4745 (0.4933) acc 90.6250 (82.8125) kd_loss 0.9185 (0.8960) lr 1.9823e-03 eta 0:10:26
epoch [5/50] batch [160/162] time 0.072 (0.084) data 0.000 (0.002) loss 0.7138 (0.8937) ce_loss 0.3069 (0.4867) teacher_loss 0.1620 (0.3385) loss_zs_kd 0.0970 (0.1225) loss_oracle 0.5033 (0.4940) acc 93.7500 (82.7148) kd_loss 0.9330 (0.9014) lr 1.9823e-03 eta 0:10:15
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,951
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 89.2%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,604
* accuracy: 79.3%
* error: 20.7%
* macro_f1: 74.8%
******* Domain s best val acc:      87.3%, epoch: 5 *******
******* Domain s best val test acc: 79.3%, epoch: 5 *******
******* Domain s best test acc:     81.2%, epoch: 4 *******
epoch [6/50] batch [20/162] time 0.077 (0.094) data 0.000 (0.012) loss 0.9559 (0.9073) ce_loss 0.5151 (0.5202) teacher_loss 0.3562 (0.3195) loss_zs_kd 0.1205 (0.1347) loss_oracle 0.5395 (0.5204) acc 81.2500 (80.6250) kd_loss 0.9299 (0.9401) lr 1.9686e-03 eta 0:11:26
epoch [6/50] batch [40/162] time 0.085 (0.087) data 0.001 (0.006) loss 0.7417 (0.8612) ce_loss 0.3667 (0.4798) teacher_loss 0.1279 (0.2775) loss_zs_kd 0.1497 (0.1369) loss_oracle 0.5389 (0.5153) acc 84.3750 (82.8906) kd_loss 0.9375 (0.9401) lr 1.9686e-03 eta 0:10:33
epoch [6/50] batch [60/162] time 0.085 (0.086) data 0.000 (0.004) loss 0.7848 (0.8522) ce_loss 0.3953 (0.4842) teacher_loss 0.2600 (0.2845) loss_zs_kd 0.0961 (0.1349) loss_oracle 0.4768 (0.5003) acc 87.5000 (82.3958) kd_loss 0.8805 (0.9333) lr 1.9686e-03 eta 0:10:21
epoch [6/50] batch [80/162] time 0.089 (0.085) data 0.000 (0.003) loss 0.7644 (0.8524) ce_loss 0.4109 (0.4854) teacher_loss 0.2988 (0.2900) loss_zs_kd 0.0972 (0.1317) loss_oracle 0.4171 (0.4966) acc 87.5000 (82.7734) kd_loss 0.9038 (0.9299) lr 1.9686e-03 eta 0:10:11
epoch [6/50] batch [100/162] time 0.084 (0.085) data 0.000 (0.003) loss 0.7526 (0.8452) ce_loss 0.4324 (0.4844) teacher_loss 0.2050 (0.2881) loss_zs_kd 0.1429 (0.1316) loss_oracle 0.4762 (0.4913) acc 78.1250 (82.5938) kd_loss 0.9297 (0.9263) lr 1.9686e-03 eta 0:10:12
epoch [6/50] batch [120/162] time 0.089 (0.085) data 0.000 (0.002) loss 0.7534 (0.8435) ce_loss 0.4053 (0.4902) teacher_loss 0.2080 (0.2930) loss_zs_kd 0.1036 (0.1339) loss_oracle 0.4935 (0.4835) acc 84.3750 (82.5260) kd_loss 0.9141 (0.9248) lr 1.9686e-03 eta 0:10:11
epoch [6/50] batch [140/162] time 0.093 (0.085) data 0.000 (0.002) loss 1.2075 (0.8486) ce_loss 0.9688 (0.4950) teacher_loss 0.6706 (0.2960) loss_zs_kd 0.1355 (0.1328) loss_oracle 0.4691 (0.4863) acc 71.8750 (82.3438) kd_loss 0.8826 (0.9230) lr 1.9686e-03 eta 0:10:09
epoch [6/50] batch [160/162] time 0.071 (0.084) data 0.000 (0.002) loss 0.7746 (0.8501) ce_loss 0.4934 (0.5005) teacher_loss 0.2518 (0.2940) loss_zs_kd 0.1679 (0.1370) loss_oracle 0.4389 (0.4876) acc 81.2500 (82.1289) kd_loss 0.8961 (0.9214) lr 1.9686e-03 eta 0:10:00
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,912
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 88.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,597
* accuracy: 79.1%
* error: 20.9%
* macro_f1: 73.4%
******* Domain s best val acc:      87.3%, epoch: 5 *******
******* Domain s best val test acc: 79.3%, epoch: 5 *******
******* Domain s best test acc:     81.2%, epoch: 4 *******
epoch [7/50] batch [20/162] time 0.083 (0.098) data 0.000 (0.013) loss 0.9206 (0.7724) ce_loss 0.6182 (0.4650) teacher_loss 0.3785 (0.2636) loss_zs_kd 0.1390 (0.1303) loss_oracle 0.4725 (0.4436) acc 78.1250 (83.7500) kd_loss 0.8967 (0.8976) lr 1.9511e-03 eta 0:11:39
epoch [7/50] batch [40/162] time 0.093 (0.092) data 0.001 (0.007) loss 0.6456 (0.7973) ce_loss 0.2408 (0.4779) teacher_loss 0.2082 (0.2817) loss_zs_kd 0.0807 (0.1196) loss_oracle 0.3971 (0.4557) acc 90.6250 (82.5781) kd_loss 0.8578 (0.8947) lr 1.9511e-03 eta 0:10:51
epoch [7/50] batch [60/162] time 0.081 (0.089) data 0.000 (0.005) loss 0.9947 (0.8052) ce_loss 0.6978 (0.5034) teacher_loss 0.5086 (0.2960) loss_zs_kd 0.1703 (0.1272) loss_oracle 0.4010 (0.4456) acc 78.1250 (81.6146) kd_loss 0.8909 (0.8921) lr 1.9511e-03 eta 0:10:30
epoch [7/50] batch [80/162] time 0.086 (0.087) data 0.000 (0.004) loss 0.9014 (0.8028) ce_loss 0.5518 (0.5063) teacher_loss 0.4009 (0.2968) loss_zs_kd 0.1480 (0.1267) loss_oracle 0.4264 (0.4427) acc 78.1250 (81.3281) kd_loss 0.8653 (0.8900) lr 1.9511e-03 eta 0:10:15
epoch [7/50] batch [100/162] time 0.082 (0.087) data 0.000 (0.003) loss 0.7776 (0.7866) ce_loss 0.5723 (0.4935) teacher_loss 0.2960 (0.2872) loss_zs_kd 0.1414 (0.1276) loss_oracle 0.4109 (0.4356) acc 75.0000 (81.9062) kd_loss 0.9095 (0.8887) lr 1.9511e-03 eta 0:10:09
epoch [7/50] batch [120/162] time 0.085 (0.087) data 0.000 (0.002) loss 0.8631 (0.7839) ce_loss 0.6006 (0.4952) teacher_loss 0.3413 (0.2893) loss_zs_kd 0.1745 (0.1297) loss_oracle 0.4345 (0.4298) acc 81.2500 (82.2656) kd_loss 0.8919 (0.8863) lr 1.9511e-03 eta 0:10:06
epoch [7/50] batch [140/162] time 0.082 (0.086) data 0.000 (0.002) loss 0.6992 (0.7841) ce_loss 0.4360 (0.4951) teacher_loss 0.2268 (0.2894) loss_zs_kd 0.1251 (0.1315) loss_oracle 0.4099 (0.4290) acc 81.2500 (82.3214) kd_loss 0.8557 (0.8846) lr 1.9511e-03 eta 0:10:00
epoch [7/50] batch [160/162] time 0.066 (0.085) data 0.000 (0.002) loss 0.5960 (0.7755) ce_loss 0.3994 (0.4939) teacher_loss 0.1925 (0.2897) loss_zs_kd 0.1340 (0.1319) loss_oracle 0.3365 (0.4199) acc 84.3750 (82.4023) kd_loss 0.8535 (0.8813) lr 1.9511e-03 eta 0:09:49
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,938
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 88.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,551
* accuracy: 77.7%
* error: 22.3%
* macro_f1: 74.3%
******* Domain s best val acc:      87.3%, epoch: 5 *******
******* Domain s best val test acc: 79.3%, epoch: 5 *******
******* Domain s best test acc:     81.2%, epoch: 4 *******
epoch [8/50] batch [20/162] time 0.075 (0.103) data 0.000 (0.016) loss 0.6963 (0.7153) ce_loss 0.4482 (0.4985) teacher_loss 0.2936 (0.2951) loss_zs_kd 0.1040 (0.1226) loss_oracle 0.3507 (0.3589) acc 81.2500 (81.2500) kd_loss 0.8762 (0.8489) lr 1.9298e-03 eta 0:11:58
epoch [8/50] batch [40/162] time 0.079 (0.090) data 0.000 (0.008) loss 0.8453 (0.7568) ce_loss 0.6245 (0.5273) teacher_loss 0.4114 (0.3009) loss_zs_kd 0.1529 (0.1508) loss_oracle 0.3575 (0.3806) acc 68.7500 (81.0938) kd_loss 0.8163 (0.8516) lr 1.9298e-03 eta 0:10:25
epoch [8/50] batch [60/162] time 0.085 (0.088) data 0.000 (0.005) loss 0.8209 (0.7187) ce_loss 0.6201 (0.4948) teacher_loss 0.3277 (0.2814) loss_zs_kd 0.1427 (0.1481) loss_oracle 0.4219 (0.3632) acc 71.8750 (81.4583) kd_loss 0.8655 (0.8456) lr 1.9298e-03 eta 0:10:04
epoch [8/50] batch [80/162] time 0.088 (0.087) data 0.001 (0.004) loss 0.9389 (0.7086) ce_loss 0.8555 (0.4907) teacher_loss 0.4788 (0.2763) loss_zs_kd 0.1359 (0.1432) loss_oracle 0.3921 (0.3607) acc 75.0000 (81.8750) kd_loss 0.8461 (0.8436) lr 1.9298e-03 eta 0:09:59
epoch [8/50] batch [100/162] time 0.087 (0.087) data 0.000 (0.003) loss 0.8001 (0.7061) ce_loss 0.6465 (0.4903) teacher_loss 0.3457 (0.2710) loss_zs_kd 0.1264 (0.1457) loss_oracle 0.3913 (0.3623) acc 71.8750 (81.8750) kd_loss 0.8576 (0.8409) lr 1.9298e-03 eta 0:09:54
epoch [8/50] batch [120/162] time 0.079 (0.086) data 0.000 (0.003) loss 0.9046 (0.7156) ce_loss 0.7466 (0.4968) teacher_loss 0.4576 (0.2731) loss_zs_kd 0.1647 (0.1479) loss_oracle 0.3647 (0.3684) acc 75.0000 (81.6667) kd_loss 0.8087 (0.8393) lr 1.9298e-03 eta 0:09:49
epoch [8/50] batch [140/162] time 0.089 (0.085) data 0.001 (0.002) loss 0.6544 (0.7126) ce_loss 0.4829 (0.4969) teacher_loss 0.2636 (0.2702) loss_zs_kd 0.1139 (0.1470) loss_oracle 0.3338 (0.3689) acc 87.5000 (81.7188) kd_loss 0.8214 (0.8373) lr 1.9298e-03 eta 0:09:40
epoch [8/50] batch [160/162] time 0.076 (0.084) data 0.000 (0.002) loss 0.7562 (0.7047) ce_loss 0.7100 (0.4903) teacher_loss 0.2523 (0.2628) loss_zs_kd 0.1452 (0.1494) loss_oracle 0.4312 (0.3673) acc 71.8750 (81.8359) kd_loss 0.9046 (0.8369) lr 1.9298e-03 eta 0:09:34
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,948
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 89.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,575
* accuracy: 78.5%
* error: 21.5%
* macro_f1: 74.8%
******* Domain s best val acc:      87.3%, epoch: 5 *******
******* Domain s best val test acc: 79.3%, epoch: 5 *******
******* Domain s best test acc:     81.2%, epoch: 4 *******
epoch [9/50] batch [20/162] time 0.089 (0.099) data 0.001 (0.015) loss 0.7879 (0.7064) ce_loss 0.6709 (0.5244) teacher_loss 0.3079 (0.2611) loss_zs_kd 0.2041 (0.1632) loss_oracle 0.3780 (0.3638) acc 81.2500 (80.3125) kd_loss 0.8356 (0.8406) lr 1.9048e-03 eta 0:11:14
epoch [9/50] batch [40/162] time 0.100 (0.093) data 0.000 (0.008) loss 0.6763 (0.6887) ce_loss 0.4731 (0.5005) teacher_loss 0.2618 (0.2659) loss_zs_kd 0.1210 (0.1535) loss_oracle 0.3540 (0.3461) acc 87.5000 (81.9531) kd_loss 0.8936 (0.8381) lr 1.9048e-03 eta 0:10:25
epoch [9/50] batch [60/162] time 0.083 (0.089) data 0.001 (0.005) loss 0.6904 (0.6781) ce_loss 0.4578 (0.4933) teacher_loss 0.2486 (0.2675) loss_zs_kd 0.1472 (0.1475) loss_oracle 0.3682 (0.3368) acc 87.5000 (82.3438) kd_loss 0.8923 (0.8356) lr 1.9048e-03 eta 0:10:03
epoch [9/50] batch [80/162] time 0.082 (0.088) data 0.000 (0.004) loss 0.7294 (0.6771) ce_loss 0.5903 (0.4981) teacher_loss 0.3562 (0.2750) loss_zs_kd 0.1571 (0.1428) loss_oracle 0.2947 (0.3308) acc 81.2500 (82.0312) kd_loss 0.8483 (0.8296) lr 1.9048e-03 eta 0:09:49
epoch [9/50] batch [100/162] time 0.081 (0.087) data 0.000 (0.003) loss 0.5615 (0.6692) ce_loss 0.4290 (0.4952) teacher_loss 0.2007 (0.2736) loss_zs_kd 0.1130 (0.1404) loss_oracle 0.3043 (0.3254) acc 81.2500 (81.9062) kd_loss 0.8049 (0.8273) lr 1.9048e-03 eta 0:09:42
epoch [9/50] batch [120/162] time 0.088 (0.086) data 0.000 (0.003) loss 0.5673 (0.6660) ce_loss 0.3748 (0.4931) teacher_loss 0.2184 (0.2705) loss_zs_kd 0.0879 (0.1422) loss_oracle 0.3050 (0.3245) acc 90.6250 (82.1615) kd_loss 0.8029 (0.8283) lr 1.9048e-03 eta 0:09:36
epoch [9/50] batch [140/162] time 0.090 (0.086) data 0.001 (0.002) loss 0.6078 (0.6628) ce_loss 0.4294 (0.4919) teacher_loss 0.2030 (0.2685) loss_zs_kd 0.1166 (0.1424) loss_oracle 0.3465 (0.3231) acc 81.2500 (82.2991) kd_loss 0.8329 (0.8247) lr 1.9048e-03 eta 0:09:35
epoch [9/50] batch [160/162] time 0.076 (0.086) data 0.000 (0.002) loss 0.7237 (0.6571) ce_loss 0.6230 (0.4876) teacher_loss 0.3328 (0.2653) loss_zs_kd 0.1497 (0.1427) loss_oracle 0.3161 (0.3205) acc 71.8750 (82.5781) kd_loss 0.7940 (0.8245) lr 1.9048e-03 eta 0:09:28
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,939
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,559
* accuracy: 78.0%
* error: 22.0%
* macro_f1: 74.1%
******* Domain s best val acc:      87.3%, epoch: 5 *******
******* Domain s best val test acc: 79.3%, epoch: 5 *******
******* Domain s best test acc:     81.2%, epoch: 4 *******
epoch [10/50] batch [20/162] time 0.090 (0.097) data 0.000 (0.013) loss 0.8116 (0.6798) ce_loss 0.8687 (0.5309) teacher_loss 0.3580 (0.2397) loss_zs_kd 0.1891 (0.1819) loss_oracle 0.3591 (0.3492) acc 62.5000 (80.0000) kd_loss 0.8218 (0.8376) lr 1.8763e-03 eta 0:10:40
epoch [10/50] batch [40/162] time 0.088 (0.090) data 0.001 (0.007) loss 0.6107 (0.6631) ce_loss 0.4443 (0.4995) teacher_loss 0.2074 (0.2287) loss_zs_kd 0.1608 (0.1754) loss_oracle 0.3229 (0.3466) acc 81.2500 (81.5625) kd_loss 0.8499 (0.8474) lr 1.8763e-03 eta 0:09:55
epoch [10/50] batch [60/162] time 0.072 (0.088) data 0.001 (0.005) loss 0.7114 (0.6553) ce_loss 0.4998 (0.4836) teacher_loss 0.2347 (0.2231) loss_zs_kd 0.1633 (0.1701) loss_oracle 0.3951 (0.3471) acc 71.8750 (82.2396) kd_loss 0.8642 (0.8521) lr 1.8763e-03 eta 0:09:38
epoch [10/50] batch [80/162] time 0.064 (0.084) data 0.000 (0.004) loss 0.5960 (0.6602) ce_loss 0.3489 (0.4821) teacher_loss 0.1314 (0.2214) loss_zs_kd 0.1967 (0.1684) loss_oracle 0.3663 (0.3546) acc 84.3750 (82.1484) kd_loss 0.7947 (0.8570) lr 1.8763e-03 eta 0:09:10
epoch [10/50] batch [100/162] time 0.068 (0.082) data 0.000 (0.003) loss 0.8732 (0.6675) ce_loss 0.7085 (0.4813) teacher_loss 0.3467 (0.2206) loss_zs_kd 0.1708 (0.1709) loss_oracle 0.4411 (0.3615) acc 78.1250 (82.1562) kd_loss 0.9798 (0.8613) lr 1.8763e-03 eta 0:08:59
epoch [10/50] batch [120/162] time 0.069 (0.081) data 0.000 (0.002) loss 0.7980 (0.6688) ce_loss 0.6177 (0.4831) teacher_loss 0.2886 (0.2185) loss_zs_kd 0.1949 (0.1729) loss_oracle 0.4120 (0.3638) acc 71.8750 (82.2396) kd_loss 0.8731 (0.8623) lr 1.8763e-03 eta 0:08:45
epoch [10/50] batch [140/162] time 0.069 (0.079) data 0.000 (0.002) loss 0.7416 (0.6756) ce_loss 0.5337 (0.4831) teacher_loss 0.2648 (0.2200) loss_zs_kd 0.1695 (0.1723) loss_oracle 0.3921 (0.3695) acc 78.1250 (82.1429) kd_loss 0.8592 (0.8646) lr 1.8763e-03 eta 0:08:35
epoch [10/50] batch [160/162] time 0.073 (0.078) data 0.000 (0.002) loss 0.6370 (0.6764) ce_loss 0.4426 (0.4799) teacher_loss 0.2184 (0.2172) loss_zs_kd 0.1890 (0.1731) loss_oracle 0.3242 (0.3726) acc 84.3750 (82.3242) kd_loss 0.7476 (0.8662) lr 1.8763e-03 eta 0:08:27
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,948
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 88.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,524
* accuracy: 76.9%
* error: 23.1%
* macro_f1: 73.4%
******* Domain s best val acc:      87.3%, epoch: 5 *******
******* Domain s best val test acc: 79.3%, epoch: 5 *******
******* Domain s best test acc:     81.2%, epoch: 4 *******
epoch [11/50] batch [20/162] time 0.072 (0.088) data 0.001 (0.014) loss 0.5640 (0.6681) ce_loss 0.2913 (0.4182) teacher_loss 0.1320 (0.2099) loss_zs_kd 0.1751 (0.1557) loss_oracle 0.3444 (0.3803) acc 90.6250 (85.4688) kd_loss 0.8667 (0.8694) lr 1.8443e-03 eta 0:09:31
epoch [11/50] batch [40/162] time 0.082 (0.080) data 0.000 (0.007) loss 0.5486 (0.6775) ce_loss 0.2510 (0.4243) teacher_loss 0.0920 (0.1995) loss_zs_kd 0.2014 (0.1603) loss_oracle 0.3560 (0.3979) acc 96.8750 (85.0000) kd_loss 0.8479 (0.8767) lr 1.8443e-03 eta 0:08:36
epoch [11/50] batch [60/162] time 0.059 (0.075) data 0.000 (0.005) loss 0.7869 (0.6936) ce_loss 0.5400 (0.4387) teacher_loss 0.3200 (0.2157) loss_zs_kd 0.1787 (0.1601) loss_oracle 0.3776 (0.3978) acc 84.3750 (84.9479) kd_loss 0.8906 (0.8800) lr 1.8443e-03 eta 0:08:04
epoch [11/50] batch [80/162] time 0.083 (0.075) data 0.000 (0.004) loss 0.6897 (0.6990) ce_loss 0.3447 (0.4456) teacher_loss 0.2082 (0.2215) loss_zs_kd 0.1743 (0.1624) loss_oracle 0.3943 (0.3963) acc 90.6250 (84.5703) kd_loss 0.8932 (0.8787) lr 1.8443e-03 eta 0:08:01
epoch [11/50] batch [100/162] time 0.078 (0.077) data 0.000 (0.003) loss 0.6318 (0.7106) ce_loss 0.4216 (0.4609) teacher_loss 0.2336 (0.2333) loss_zs_kd 0.1130 (0.1596) loss_oracle 0.3417 (0.3975) acc 81.2500 (84.0000) kd_loss 0.8652 (0.8788) lr 1.8443e-03 eta 0:08:09
epoch [11/50] batch [120/162] time 0.091 (0.077) data 0.001 (0.003) loss 0.5995 (0.7125) ce_loss 0.2773 (0.4610) teacher_loss 0.1334 (0.2331) loss_zs_kd 0.1494 (0.1589) loss_oracle 0.3914 (0.4000) acc 90.6250 (83.6198) kd_loss 0.9120 (0.8791) lr 1.8443e-03 eta 0:08:11
epoch [11/50] batch [140/162] time 0.080 (0.079) data 0.000 (0.002) loss 0.6875 (0.7167) ce_loss 0.3569 (0.4631) teacher_loss 0.1492 (0.2358) loss_zs_kd 0.1567 (0.1598) loss_oracle 0.4600 (0.4010) acc 93.7500 (83.4598) kd_loss 0.8992 (0.8815) lr 1.8443e-03 eta 0:08:18
epoch [11/50] batch [160/162] time 0.072 (0.078) data 0.000 (0.002) loss 0.5921 (0.7198) ce_loss 0.2432 (0.4634) teacher_loss 0.0895 (0.2380) loss_zs_kd 0.1659 (0.1583) loss_oracle 0.4196 (0.4026) acc 90.6250 (83.3594) kd_loss 0.8601 (0.8810) lr 1.8443e-03 eta 0:08:13
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,953
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 89.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,512
* accuracy: 76.5%
* error: 23.5%
* macro_f1: 72.6%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     81.2%, epoch: 4 *******
epoch [12/50] batch [20/162] time 0.073 (0.089) data 0.000 (0.015) loss 0.8506 (0.7935) ce_loss 0.4048 (0.5044) teacher_loss 0.1612 (0.2574) loss_zs_kd 0.1597 (0.1683) loss_oracle 0.6096 (0.4519) acc 84.3750 (81.8750) kd_loss 0.9614 (0.8742) lr 1.8090e-03 eta 0:09:23
epoch [12/50] batch [40/162] time 0.087 (0.082) data 0.000 (0.008) loss 0.8080 (0.8066) ce_loss 0.4722 (0.5056) teacher_loss 0.2278 (0.2796) loss_zs_kd 0.1822 (0.1631) loss_oracle 0.4891 (0.4454) acc 78.1250 (81.1719) kd_loss 0.9077 (0.8617) lr 1.8090e-03 eta 0:08:36
epoch [12/50] batch [60/162] time 0.076 (0.081) data 0.000 (0.005) loss 1.0420 (0.8211) ce_loss 0.6772 (0.5043) teacher_loss 0.4375 (0.2830) loss_zs_kd 0.2055 (0.1620) loss_oracle 0.5018 (0.4572) acc 75.0000 (81.7708) kd_loss 0.8904 (0.8568) lr 1.8090e-03 eta 0:08:24
epoch [12/50] batch [80/162] time 0.078 (0.080) data 0.000 (0.004) loss 0.7904 (0.8254) ce_loss 0.4609 (0.4928) teacher_loss 0.2256 (0.2786) loss_zs_kd 0.1588 (0.1596) loss_oracle 0.4854 (0.4670) acc 81.2500 (82.1094) kd_loss 0.9152 (0.8636) lr 1.8090e-03 eta 0:08:20
epoch [12/50] batch [100/162] time 0.072 (0.079) data 0.000 (0.003) loss 0.8725 (0.8302) ce_loss 0.4783 (0.4915) teacher_loss 0.2913 (0.2831) loss_zs_kd 0.1366 (0.1560) loss_oracle 0.5130 (0.4691) acc 84.3750 (82.0625) kd_loss 0.9420 (0.8696) lr 1.8090e-03 eta 0:08:14
epoch [12/50] batch [120/162] time 0.087 (0.079) data 0.000 (0.003) loss 0.6398 (0.8241) ce_loss 0.4192 (0.4815) teacher_loss 0.1821 (0.2768) loss_zs_kd 0.0814 (0.1534) loss_oracle 0.4170 (0.4706) acc 87.5000 (82.5260) kd_loss 0.8832 (0.8719) lr 1.8090e-03 eta 0:08:10
epoch [12/50] batch [140/162] time 0.083 (0.079) data 0.000 (0.002) loss 0.8498 (0.8313) ce_loss 0.3745 (0.4835) teacher_loss 0.2845 (0.2792) loss_zs_kd 0.1651 (0.1535) loss_oracle 0.4828 (0.4754) acc 87.5000 (82.3661) kd_loss 0.8953 (0.8785) lr 1.8090e-03 eta 0:08:10
epoch [12/50] batch [160/162] time 0.072 (0.079) data 0.000 (0.002) loss 1.0472 (0.8260) ce_loss 0.7183 (0.4727) teacher_loss 0.4435 (0.2764) loss_zs_kd 0.1286 (0.1511) loss_oracle 0.5395 (0.4741) acc 78.1250 (82.8125) kd_loss 1.0015 (0.8789) lr 1.8090e-03 eta 0:08:04
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,592
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 73.6%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     81.2%, epoch: 4 *******
epoch [13/50] batch [20/162] time 0.075 (0.093) data 0.000 (0.015) loss 0.7705 (0.8217) ce_loss 0.4329 (0.4722) teacher_loss 0.2443 (0.2803) loss_zs_kd 0.1495 (0.1367) loss_oracle 0.4514 (0.4730) acc 87.5000 (82.9688) kd_loss 0.8525 (0.8770) lr 1.7705e-03 eta 0:09:30
epoch [13/50] batch [40/162] time 0.084 (0.086) data 0.000 (0.008) loss 0.8232 (0.8122) ce_loss 0.5581 (0.4792) teacher_loss 0.3381 (0.2770) loss_zs_kd 0.1742 (0.1410) loss_oracle 0.3979 (0.4646) acc 84.3750 (83.0469) kd_loss 0.8526 (0.8817) lr 1.7705e-03 eta 0:08:43
epoch [13/50] batch [60/162] time 0.074 (0.082) data 0.000 (0.005) loss 0.8540 (0.8025) ce_loss 0.5332 (0.4679) teacher_loss 0.2888 (0.2647) loss_zs_kd 0.1606 (0.1454) loss_oracle 0.4850 (0.4652) acc 84.3750 (83.4375) kd_loss 0.9115 (0.8811) lr 1.7705e-03 eta 0:08:22
epoch [13/50] batch [80/162] time 0.087 (0.081) data 0.000 (0.004) loss 1.3142 (0.8080) ce_loss 0.9126 (0.4778) teacher_loss 0.7217 (0.2717) loss_zs_kd 0.1630 (0.1450) loss_oracle 0.5110 (0.4638) acc 78.1250 (82.9297) kd_loss 0.8932 (0.8792) lr 1.7705e-03 eta 0:08:11
epoch [13/50] batch [100/162] time 0.072 (0.079) data 0.000 (0.003) loss 0.6325 (0.7932) ce_loss 0.3198 (0.4686) teacher_loss 0.1511 (0.2600) loss_zs_kd 0.1894 (0.1481) loss_oracle 0.3867 (0.4591) acc 90.6250 (83.1875) kd_loss 0.8596 (0.8782) lr 1.7705e-03 eta 0:07:58
epoch [13/50] batch [120/162] time 0.082 (0.078) data 0.000 (0.003) loss 0.7849 (0.7948) ce_loss 0.4810 (0.4686) teacher_loss 0.2050 (0.2636) loss_zs_kd 0.1121 (0.1435) loss_oracle 0.5239 (0.4594) acc 75.0000 (82.9948) kd_loss 0.8750 (0.8771) lr 1.7705e-03 eta 0:07:53
epoch [13/50] batch [140/162] time 0.067 (0.078) data 0.000 (0.002) loss 0.7485 (0.7939) ce_loss 0.3296 (0.4669) teacher_loss 0.2109 (0.2612) loss_zs_kd 0.1955 (0.1456) loss_oracle 0.4398 (0.4599) acc 84.3750 (83.2366) kd_loss 0.9011 (0.8787) lr 1.7705e-03 eta 0:07:47
epoch [13/50] batch [160/162] time 0.075 (0.078) data 0.001 (0.002) loss 0.6040 (0.7929) ce_loss 0.2910 (0.4685) teacher_loss 0.1315 (0.2589) loss_zs_kd 0.1310 (0.1473) loss_oracle 0.4070 (0.4604) acc 90.6250 (83.1445) kd_loss 0.8793 (0.8790) lr 1.7705e-03 eta 0:07:46
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,937
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 88.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,609
* accuracy: 79.5%
* error: 20.5%
* macro_f1: 73.8%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     81.2%, epoch: 4 *******
epoch [14/50] batch [20/162] time 0.066 (0.100) data 0.000 (0.015) loss 0.8265 (0.7740) ce_loss 0.5825 (0.4735) teacher_loss 0.4400 (0.2912) loss_zs_kd 0.1094 (0.1424) loss_oracle 0.3318 (0.4116) acc 81.2500 (81.5625) kd_loss 0.8269 (0.8558) lr 1.7290e-03 eta 0:09:55
epoch [14/50] batch [40/162] time 0.091 (0.095) data 0.000 (0.008) loss 0.7712 (0.7713) ce_loss 0.5586 (0.4826) teacher_loss 0.3701 (0.2925) loss_zs_kd 0.0986 (0.1283) loss_oracle 0.3518 (0.4146) acc 84.3750 (81.4844) kd_loss 0.8390 (0.8637) lr 1.7290e-03 eta 0:09:23
epoch [14/50] batch [60/162] time 0.091 (0.092) data 0.002 (0.005) loss 0.7650 (0.7629) ce_loss 0.4746 (0.4805) teacher_loss 0.2105 (0.2859) loss_zs_kd 0.1722 (0.1345) loss_oracle 0.4684 (0.4098) acc 81.2500 (81.6146) kd_loss 0.8606 (0.8575) lr 1.7290e-03 eta 0:09:03
epoch [14/50] batch [80/162] time 0.082 (0.091) data 0.000 (0.004) loss 0.8448 (0.7655) ce_loss 0.4185 (0.4907) teacher_loss 0.3688 (0.2895) loss_zs_kd 0.1069 (0.1358) loss_oracle 0.4225 (0.4081) acc 93.7500 (81.6406) kd_loss 0.8739 (0.8535) lr 1.7290e-03 eta 0:08:55
epoch [14/50] batch [100/162] time 0.082 (0.089) data 0.000 (0.003) loss 0.7940 (0.7582) ce_loss 0.6177 (0.4915) teacher_loss 0.2860 (0.2840) loss_zs_kd 0.1777 (0.1385) loss_oracle 0.4192 (0.4049) acc 78.1250 (81.4062) kd_loss 0.8607 (0.8502) lr 1.7290e-03 eta 0:08:45
epoch [14/50] batch [120/162] time 0.092 (0.089) data 0.000 (0.003) loss 0.5448 (0.7495) ce_loss 0.2749 (0.4812) teacher_loss 0.1417 (0.2771) loss_zs_kd 0.1155 (0.1392) loss_oracle 0.3453 (0.4027) acc 90.6250 (82.0573) kd_loss 0.8182 (0.8474) lr 1.7290e-03 eta 0:08:43
epoch [14/50] batch [140/162] time 0.084 (0.089) data 0.000 (0.002) loss 0.6071 (0.7482) ce_loss 0.4417 (0.4799) teacher_loss 0.1537 (0.2772) loss_zs_kd 0.2083 (0.1383) loss_oracle 0.3493 (0.4019) acc 87.5000 (82.2098) kd_loss 0.8333 (0.8454) lr 1.7290e-03 eta 0:08:39
epoch [14/50] batch [160/162] time 0.080 (0.088) data 0.000 (0.002) loss 0.7377 (0.7504) ce_loss 0.5806 (0.4827) teacher_loss 0.3655 (0.2791) loss_zs_kd 0.1289 (0.1390) loss_oracle 0.3077 (0.4018) acc 78.1250 (82.0312) kd_loss 0.7685 (0.8446) lr 1.7290e-03 eta 0:08:32
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,937
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 88.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,613
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 74.4%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     81.2%, epoch: 4 *******
epoch [15/50] batch [20/162] time 0.086 (0.103) data 0.000 (0.011) loss 0.9622 (0.7347) ce_loss 0.7324 (0.4456) teacher_loss 0.4574 (0.2545) loss_zs_kd 0.0926 (0.1333) loss_oracle 0.4585 (0.4135) acc 78.1250 (83.7500) kd_loss 0.8187 (0.8525) lr 1.6845e-03 eta 0:09:57
epoch [15/50] batch [40/162] time 0.089 (0.096) data 0.000 (0.006) loss 0.6955 (0.7126) ce_loss 0.4868 (0.4451) teacher_loss 0.1332 (0.2310) loss_zs_kd 0.1730 (0.1417) loss_oracle 0.4759 (0.4107) acc 78.1250 (83.5938) kd_loss 0.9220 (0.8554) lr 1.6845e-03 eta 0:09:13
epoch [15/50] batch [60/162] time 0.084 (0.093) data 0.001 (0.004) loss 0.6779 (0.7229) ce_loss 0.3247 (0.4639) teacher_loss 0.1927 (0.2532) loss_zs_kd 0.0931 (0.1441) loss_oracle 0.4386 (0.3976) acc 90.6250 (83.0729) kd_loss 0.8945 (0.8448) lr 1.6845e-03 eta 0:08:56
epoch [15/50] batch [80/162] time 0.083 (0.092) data 0.001 (0.003) loss 0.9643 (0.7201) ce_loss 0.5996 (0.4654) teacher_loss 0.4185 (0.2563) loss_zs_kd 0.1543 (0.1445) loss_oracle 0.4686 (0.3916) acc 75.0000 (82.9297) kd_loss 0.8368 (0.8446) lr 1.6845e-03 eta 0:08:46
epoch [15/50] batch [100/162] time 0.081 (0.090) data 0.000 (0.003) loss 0.6962 (0.7369) ce_loss 0.4026 (0.4753) teacher_loss 0.2460 (0.2661) loss_zs_kd 0.1219 (0.1438) loss_oracle 0.3892 (0.3989) acc 84.3750 (82.6875) kd_loss 0.9118 (0.8471) lr 1.6845e-03 eta 0:08:35
epoch [15/50] batch [120/162] time 0.094 (0.089) data 0.000 (0.002) loss 0.9985 (0.7407) ce_loss 0.6665 (0.4746) teacher_loss 0.5661 (0.2719) loss_zs_kd 0.1448 (0.1445) loss_oracle 0.3600 (0.3966) acc 87.5000 (82.6042) kd_loss 0.8081 (0.8452) lr 1.6845e-03 eta 0:08:30
epoch [15/50] batch [140/162] time 0.088 (0.089) data 0.000 (0.002) loss 0.6930 (0.7421) ce_loss 0.4021 (0.4749) teacher_loss 0.1941 (0.2783) loss_zs_kd 0.1192 (0.1412) loss_oracle 0.4394 (0.3932) acc 81.2500 (82.7009) kd_loss 0.8674 (0.8440) lr 1.6845e-03 eta 0:08:28
epoch [15/50] batch [160/162] time 0.080 (0.089) data 0.000 (0.002) loss 0.7074 (0.7357) ce_loss 0.4443 (0.4650) teacher_loss 0.2420 (0.2756) loss_zs_kd 0.1072 (0.1382) loss_oracle 0.4119 (0.3910) acc 90.6250 (83.0078) kd_loss 0.8077 (0.8409) lr 1.6845e-03 eta 0:08:22
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,933
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 88.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,618
* accuracy: 79.8%
* error: 20.2%
* macro_f1: 74.6%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     81.2%, epoch: 4 *******
epoch [16/50] batch [20/162] time 0.089 (0.104) data 0.001 (0.017) loss 0.7667 (0.7861) ce_loss 0.4602 (0.4966) teacher_loss 0.3552 (0.3046) loss_zs_kd 0.1477 (0.1363) loss_oracle 0.3377 (0.4133) acc 78.1250 (81.0938) kd_loss 0.8405 (0.8373) lr 1.6374e-03 eta 0:09:47
epoch [16/50] batch [40/162] time 0.085 (0.095) data 0.000 (0.009) loss 0.5088 (0.7850) ce_loss 0.2198 (0.4880) teacher_loss 0.1476 (0.3161) loss_zs_kd 0.0726 (0.1298) loss_oracle 0.3249 (0.4040) acc 90.6250 (81.4844) kd_loss 0.7112 (0.8367) lr 1.6374e-03 eta 0:08:55
epoch [16/50] batch [60/162] time 0.094 (0.093) data 0.001 (0.006) loss 0.7953 (0.7840) ce_loss 0.5298 (0.5001) teacher_loss 0.2995 (0.3293) loss_zs_kd 0.2047 (0.1287) loss_oracle 0.3934 (0.3903) acc 81.2500 (80.7812) kd_loss 0.8573 (0.8283) lr 1.6374e-03 eta 0:08:42
epoch [16/50] batch [80/162] time 0.084 (0.092) data 0.000 (0.004) loss 0.9837 (0.7662) ce_loss 0.7212 (0.4843) teacher_loss 0.4976 (0.3178) loss_zs_kd 0.1235 (0.1262) loss_oracle 0.4243 (0.3853) acc 75.0000 (81.7188) kd_loss 0.8734 (0.8261) lr 1.6374e-03 eta 0:08:34
epoch [16/50] batch [100/162] time 0.097 (0.092) data 0.000 (0.004) loss 0.8062 (0.7654) ce_loss 0.6758 (0.4850) teacher_loss 0.3463 (0.3183) loss_zs_kd 0.1596 (0.1262) loss_oracle 0.3801 (0.3840) acc 81.2500 (82.0938) kd_loss 0.8745 (0.8287) lr 1.6374e-03 eta 0:08:29
epoch [16/50] batch [120/162] time 0.089 (0.091) data 0.000 (0.003) loss 0.7232 (0.7692) ce_loss 0.4795 (0.4937) teacher_loss 0.3532 (0.3253) loss_zs_kd 0.1025 (0.1269) loss_oracle 0.3188 (0.3805) acc 87.5000 (82.0573) kd_loss 0.8153 (0.8200) lr 1.6374e-03 eta 0:08:26
epoch [16/50] batch [140/162] time 0.091 (0.091) data 0.000 (0.003) loss 0.5772 (0.7584) ce_loss 0.2595 (0.4785) teacher_loss 0.1346 (0.3147) loss_zs_kd 0.1173 (0.1257) loss_oracle 0.3840 (0.3808) acc 93.7500 (82.6339) kd_loss 0.8656 (0.8173) lr 1.6374e-03 eta 0:08:23
epoch [16/50] batch [160/162] time 0.080 (0.090) data 0.000 (0.002) loss 0.8494 (0.7569) ce_loss 0.5190 (0.4761) teacher_loss 0.3574 (0.3162) loss_zs_kd 0.1113 (0.1229) loss_oracle 0.4364 (0.3792) acc 71.8750 (82.7930) kd_loss 0.8829 (0.8162) lr 1.6374e-03 eta 0:08:16
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,934
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 88.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,671
* accuracy: 81.4%
* error: 18.6%
* macro_f1: 75.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     81.4%, epoch: 16 *******
epoch [17/50] batch [20/162] time 0.082 (0.102) data 0.000 (0.015) loss 0.7952 (0.7283) ce_loss 0.4448 (0.4332) teacher_loss 0.3645 (0.3044) loss_zs_kd 0.1091 (0.1169) loss_oracle 0.3762 (0.3656) acc 84.3750 (85.7812) kd_loss 0.8820 (0.8099) lr 1.5878e-03 eta 0:09:20
epoch [17/50] batch [40/162] time 0.091 (0.095) data 0.000 (0.008) loss 0.7648 (0.7192) ce_loss 0.4324 (0.4224) teacher_loss 0.2773 (0.2909) loss_zs_kd 0.1367 (0.1131) loss_oracle 0.4191 (0.3717) acc 78.1250 (85.3125) kd_loss 0.8464 (0.8165) lr 1.5878e-03 eta 0:08:38
epoch [17/50] batch [60/162] time 0.089 (0.092) data 0.001 (0.005) loss 0.6440 (0.7338) ce_loss 0.4763 (0.4426) teacher_loss 0.2263 (0.3017) loss_zs_kd 0.1196 (0.1140) loss_oracle 0.3579 (0.3751) acc 81.2500 (84.4271) kd_loss 0.8142 (0.8153) lr 1.5878e-03 eta 0:08:23
epoch [17/50] batch [80/162] time 0.090 (0.091) data 0.000 (0.004) loss 0.7794 (0.7486) ce_loss 0.5454 (0.4613) teacher_loss 0.2723 (0.3173) loss_zs_kd 0.0878 (0.1132) loss_oracle 0.4632 (0.3747) acc 71.8750 (83.6328) kd_loss 0.8909 (0.8165) lr 1.5878e-03 eta 0:08:14
epoch [17/50] batch [100/162] time 0.084 (0.091) data 0.000 (0.003) loss 0.8178 (0.7653) ce_loss 0.5859 (0.4799) teacher_loss 0.4227 (0.3298) loss_zs_kd 0.1122 (0.1148) loss_oracle 0.3389 (0.3781) acc 75.0000 (83.1562) kd_loss 0.7829 (0.8164) lr 1.5878e-03 eta 0:08:10
epoch [17/50] batch [120/162] time 0.086 (0.090) data 0.000 (0.003) loss 0.6831 (0.7639) ce_loss 0.3191 (0.4775) teacher_loss 0.2397 (0.3288) loss_zs_kd 0.1041 (0.1124) loss_oracle 0.3914 (0.3789) acc 87.5000 (83.1771) kd_loss 0.7969 (0.8167) lr 1.5878e-03 eta 0:08:05
epoch [17/50] batch [140/162] time 0.090 (0.090) data 0.001 (0.002) loss 0.5212 (0.7626) ce_loss 0.2856 (0.4786) teacher_loss 0.1370 (0.3272) loss_zs_kd 0.0880 (0.1136) loss_oracle 0.3403 (0.3786) acc 87.5000 (82.7455) kd_loss 0.8220 (0.8190) lr 1.5878e-03 eta 0:08:02
epoch [17/50] batch [160/162] time 0.073 (0.088) data 0.000 (0.002) loss 0.6724 (0.7612) ce_loss 0.4441 (0.4783) teacher_loss 0.2831 (0.3277) loss_zs_kd 0.0932 (0.1139) loss_oracle 0.3427 (0.3766) acc 81.2500 (82.7344) kd_loss 0.7447 (0.8189) lr 1.5878e-03 eta 0:07:50
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,943
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,613
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 73.9%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     81.4%, epoch: 16 *******
epoch [18/50] batch [20/162] time 0.081 (0.095) data 0.000 (0.012) loss 0.5377 (0.7174) ce_loss 0.2788 (0.4709) teacher_loss 0.1722 (0.3383) loss_zs_kd 0.1017 (0.0896) loss_oracle 0.3146 (0.3344) acc 90.6250 (81.5625) kd_loss 0.8108 (0.8150) lr 1.5358e-03 eta 0:08:23
epoch [18/50] batch [40/162] time 0.083 (0.088) data 0.000 (0.006) loss 0.6354 (0.7313) ce_loss 0.3540 (0.4612) teacher_loss 0.2590 (0.3376) loss_zs_kd 0.0946 (0.0962) loss_oracle 0.3291 (0.3456) acc 87.5000 (83.2812) kd_loss 0.8081 (0.8177) lr 1.5358e-03 eta 0:07:44
epoch [18/50] batch [60/162] time 0.085 (0.086) data 0.000 (0.004) loss 0.8834 (0.7354) ce_loss 0.4746 (0.4614) teacher_loss 0.3851 (0.3300) loss_zs_kd 0.1804 (0.1037) loss_oracle 0.4082 (0.3535) acc 75.0000 (83.2292) kd_loss 0.8519 (0.8203) lr 1.5358e-03 eta 0:07:34
epoch [18/50] batch [80/162] time 0.087 (0.086) data 0.000 (0.003) loss 0.7538 (0.7460) ce_loss 0.4705 (0.4690) teacher_loss 0.3784 (0.3397) loss_zs_kd 0.0944 (0.1034) loss_oracle 0.3283 (0.3545) acc 78.1250 (82.8516) kd_loss 0.8225 (0.8190) lr 1.5358e-03 eta 0:07:30
epoch [18/50] batch [100/162] time 0.081 (0.085) data 0.000 (0.003) loss 0.7730 (0.7523) ce_loss 0.5293 (0.4715) teacher_loss 0.3237 (0.3423) loss_zs_kd 0.1338 (0.1064) loss_oracle 0.3824 (0.3568) acc 71.8750 (82.5625) kd_loss 0.8239 (0.8116) lr 1.5358e-03 eta 0:07:26
epoch [18/50] batch [120/162] time 0.080 (0.086) data 0.000 (0.002) loss 1.0742 (0.7518) ce_loss 0.7637 (0.4637) teacher_loss 0.6660 (0.3383) loss_zs_kd 0.1215 (0.1062) loss_oracle 0.3474 (0.3604) acc 78.1250 (82.7083) kd_loss 0.7454 (0.8095) lr 1.5358e-03 eta 0:07:27
epoch [18/50] batch [140/162] time 0.079 (0.085) data 0.000 (0.002) loss 0.4841 (0.7509) ce_loss 0.1997 (0.4675) teacher_loss 0.1432 (0.3400) loss_zs_kd 0.0746 (0.1051) loss_oracle 0.3036 (0.3583) acc 93.7500 (82.9241) kd_loss 0.8201 (0.8068) lr 1.5358e-03 eta 0:07:24
epoch [18/50] batch [160/162] time 0.072 (0.084) data 0.000 (0.002) loss 0.5426 (0.7574) ce_loss 0.3340 (0.4809) teacher_loss 0.1887 (0.3473) loss_zs_kd 0.0796 (0.1065) loss_oracle 0.3141 (0.3569) acc 87.5000 (82.3828) kd_loss 0.7248 (0.8030) lr 1.5358e-03 eta 0:07:17
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,926
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 88.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,690
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 74.9%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [19/50] batch [20/162] time 0.083 (0.101) data 0.000 (0.016) loss 1.0657 (0.7484) ce_loss 0.7959 (0.4647) teacher_loss 0.6172 (0.3405) loss_zs_kd 0.1195 (0.1078) loss_oracle 0.3888 (0.3540) acc 62.5000 (82.1875) kd_loss 0.7690 (0.7747) lr 1.4818e-03 eta 0:08:42
epoch [19/50] batch [40/162] time 0.088 (0.092) data 0.000 (0.008) loss 0.6942 (0.7576) ce_loss 0.4739 (0.4876) teacher_loss 0.3130 (0.3551) loss_zs_kd 0.0854 (0.1103) loss_oracle 0.3385 (0.3474) acc 84.3750 (81.7188) kd_loss 0.7895 (0.7816) lr 1.4818e-03 eta 0:07:54
epoch [19/50] batch [60/162] time 0.084 (0.090) data 0.001 (0.006) loss 0.8452 (0.7556) ce_loss 0.5303 (0.4818) teacher_loss 0.4533 (0.3503) loss_zs_kd 0.0861 (0.1146) loss_oracle 0.3489 (0.3480) acc 75.0000 (81.8229) kd_loss 0.7366 (0.7779) lr 1.4818e-03 eta 0:07:41
epoch [19/50] batch [80/162] time 0.086 (0.089) data 0.000 (0.004) loss 0.7195 (0.7504) ce_loss 0.4761 (0.4725) teacher_loss 0.2692 (0.3483) loss_zs_kd 0.0928 (0.1086) loss_oracle 0.4039 (0.3478) acc 87.5000 (82.3828) kd_loss 0.8879 (0.7814) lr 1.4818e-03 eta 0:07:32
epoch [19/50] batch [100/162] time 0.083 (0.088) data 0.000 (0.004) loss 0.7526 (0.7553) ce_loss 0.5264 (0.4791) teacher_loss 0.2870 (0.3517) loss_zs_kd 0.1332 (0.1106) loss_oracle 0.3991 (0.3483) acc 81.2500 (82.2500) kd_loss 0.8188 (0.7819) lr 1.4818e-03 eta 0:07:28
epoch [19/50] batch [120/162] time 0.080 (0.088) data 0.000 (0.003) loss 0.6270 (0.7486) ce_loss 0.2629 (0.4717) teacher_loss 0.2426 (0.3478) loss_zs_kd 0.1166 (0.1075) loss_oracle 0.3261 (0.3470) acc 93.7500 (82.3177) kd_loss 0.8078 (0.7833) lr 1.4818e-03 eta 0:07:23
epoch [19/50] batch [140/162] time 0.091 (0.087) data 0.000 (0.003) loss 0.6681 (0.7470) ce_loss 0.3765 (0.4729) teacher_loss 0.2418 (0.3490) loss_zs_kd 0.1384 (0.1069) loss_oracle 0.3571 (0.3445) acc 90.6250 (82.3214) kd_loss 0.8407 (0.7854) lr 1.4818e-03 eta 0:07:19
epoch [19/50] batch [160/162] time 0.071 (0.086) data 0.000 (0.002) loss 0.6334 (0.7467) ce_loss 0.3435 (0.4762) teacher_loss 0.2126 (0.3515) loss_zs_kd 0.0982 (0.1065) loss_oracle 0.3718 (0.3420) acc 84.3750 (82.3828) kd_loss 0.8384 (0.7875) lr 1.4818e-03 eta 0:07:12
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,937
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 88.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,652
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 75.5%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [20/50] batch [20/162] time 0.069 (0.087) data 0.000 (0.013) loss 0.7419 (0.7592) ce_loss 0.5562 (0.4907) teacher_loss 0.2888 (0.3372) loss_zs_kd 0.1569 (0.1205) loss_oracle 0.3746 (0.3617) acc 81.2500 (81.4062) kd_loss 0.8073 (0.8247) lr 1.4258e-03 eta 0:07:14
epoch [20/50] batch [40/162] time 0.078 (0.080) data 0.000 (0.007) loss 0.5936 (0.7531) ce_loss 0.3601 (0.4689) teacher_loss 0.2117 (0.3363) loss_zs_kd 0.1173 (0.1202) loss_oracle 0.3233 (0.3567) acc 84.3750 (82.8906) kd_loss 0.8226 (0.8122) lr 1.4258e-03 eta 0:06:38
epoch [20/50] batch [60/162] time 0.068 (0.077) data 0.000 (0.005) loss 0.6281 (0.7567) ce_loss 0.3496 (0.4858) teacher_loss 0.2076 (0.3491) loss_zs_kd 0.0781 (0.1131) loss_oracle 0.3814 (0.3511) acc 84.3750 (82.2917) kd_loss 0.7606 (0.8103) lr 1.4258e-03 eta 0:06:19
epoch [20/50] batch [80/162] time 0.079 (0.078) data 0.000 (0.003) loss 0.7240 (0.7436) ce_loss 0.5444 (0.4718) teacher_loss 0.2832 (0.3396) loss_zs_kd 0.1207 (0.1121) loss_oracle 0.3805 (0.3480) acc 81.2500 (82.8906) kd_loss 0.8511 (0.8088) lr 1.4258e-03 eta 0:06:26
epoch [20/50] batch [100/162] time 0.093 (0.080) data 0.000 (0.003) loss 0.6964 (0.7416) ce_loss 0.4856 (0.4728) teacher_loss 0.2049 (0.3343) loss_zs_kd 0.1155 (0.1144) loss_oracle 0.4338 (0.3501) acc 81.2500 (82.6562) kd_loss 0.8784 (0.8090) lr 1.4258e-03 eta 0:06:32
epoch [20/50] batch [120/162] time 0.085 (0.081) data 0.000 (0.002) loss 0.6295 (0.7390) ce_loss 0.3396 (0.4690) teacher_loss 0.2109 (0.3296) loss_zs_kd 0.0903 (0.1132) loss_oracle 0.3734 (0.3528) acc 93.7500 (83.0990) kd_loss 0.8336 (0.8100) lr 1.4258e-03 eta 0:06:35
epoch [20/50] batch [140/162] time 0.083 (0.081) data 0.000 (0.002) loss 0.8650 (0.7343) ce_loss 0.5684 (0.4663) teacher_loss 0.4044 (0.3260) loss_zs_kd 0.1365 (0.1131) loss_oracle 0.3923 (0.3518) acc 84.3750 (83.3259) kd_loss 0.8384 (0.8122) lr 1.4258e-03 eta 0:06:37
epoch [20/50] batch [160/162] time 0.067 (0.081) data 0.000 (0.002) loss 0.6178 (0.7335) ce_loss 0.3474 (0.4677) teacher_loss 0.1790 (0.3214) loss_zs_kd 0.1215 (0.1152) loss_oracle 0.3781 (0.3545) acc 93.7500 (83.2617) kd_loss 0.7835 (0.8140) lr 1.4258e-03 eta 0:06:32
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,938
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 88.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,644
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 74.9%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [21/50] batch [20/162] time 0.079 (0.102) data 0.000 (0.017) loss 0.7650 (0.7191) ce_loss 0.5029 (0.4882) teacher_loss 0.3334 (0.3047) loss_zs_kd 0.1384 (0.1161) loss_oracle 0.3624 (0.3563) acc 75.0000 (81.0938) kd_loss 0.8491 (0.8219) lr 1.3681e-03 eta 0:08:14
epoch [21/50] batch [40/162] time 0.086 (0.091) data 0.000 (0.009) loss 0.8249 (0.7144) ce_loss 0.6533 (0.4725) teacher_loss 0.3181 (0.2866) loss_zs_kd 0.1340 (0.1165) loss_oracle 0.4398 (0.3695) acc 78.1250 (82.2656) kd_loss 0.9239 (0.8295) lr 1.3681e-03 eta 0:07:19
epoch [21/50] batch [60/162] time 0.084 (0.089) data 0.000 (0.006) loss 0.6267 (0.7317) ce_loss 0.3938 (0.4746) teacher_loss 0.1360 (0.2891) loss_zs_kd 0.1624 (0.1224) loss_oracle 0.4095 (0.3814) acc 84.3750 (81.8750) kd_loss 0.8688 (0.8370) lr 1.3681e-03 eta 0:07:08
epoch [21/50] batch [80/162] time 0.079 (0.088) data 0.000 (0.005) loss 0.9107 (0.7436) ce_loss 0.5938 (0.4867) teacher_loss 0.4969 (0.3010) loss_zs_kd 0.0992 (0.1213) loss_oracle 0.3642 (0.3819) acc 78.1250 (81.6406) kd_loss 0.8376 (0.8385) lr 1.3681e-03 eta 0:07:00
epoch [21/50] batch [100/162] time 0.083 (0.087) data 0.000 (0.004) loss 1.0870 (0.7553) ce_loss 0.8950 (0.4863) teacher_loss 0.5264 (0.3010) loss_zs_kd 0.1438 (0.1255) loss_oracle 0.4887 (0.3916) acc 62.5000 (81.7812) kd_loss 0.9408 (0.8473) lr 1.3681e-03 eta 0:06:55
epoch [21/50] batch [120/162] time 0.093 (0.087) data 0.000 (0.003) loss 0.8176 (0.7636) ce_loss 0.5610 (0.4861) teacher_loss 0.3627 (0.3046) loss_zs_kd 0.1039 (0.1253) loss_oracle 0.4030 (0.3963) acc 81.2500 (82.1094) kd_loss 0.9174 (0.8513) lr 1.3681e-03 eta 0:06:53
epoch [21/50] batch [140/162] time 0.084 (0.087) data 0.000 (0.003) loss 0.6678 (0.7712) ce_loss 0.3279 (0.4878) teacher_loss 0.1684 (0.3059) loss_zs_kd 0.1264 (0.1279) loss_oracle 0.4362 (0.4014) acc 84.3750 (82.0089) kd_loss 0.8943 (0.8547) lr 1.3681e-03 eta 0:06:51
epoch [21/50] batch [160/162] time 0.072 (0.086) data 0.000 (0.002) loss 0.7054 (0.7719) ce_loss 0.3022 (0.4854) teacher_loss 0.2981 (0.3056) loss_zs_kd 0.1165 (0.1271) loss_oracle 0.3490 (0.4027) acc 90.6250 (82.1680) kd_loss 0.8409 (0.8600) lr 1.3681e-03 eta 0:06:43
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,938
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 88.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,630
* accuracy: 80.1%
* error: 19.9%
* macro_f1: 75.1%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [22/50] batch [20/162] time 0.085 (0.093) data 0.000 (0.012) loss 0.8113 (0.7695) ce_loss 0.4182 (0.4255) teacher_loss 0.3059 (0.2626) loss_zs_kd 0.1412 (0.1299) loss_oracle 0.4347 (0.4419) acc 84.3750 (85.6250) kd_loss 0.8625 (0.9184) lr 1.3090e-03 eta 0:07:16
epoch [22/50] batch [40/162] time 0.096 (0.088) data 0.000 (0.006) loss 0.8778 (0.8100) ce_loss 0.3945 (0.4534) teacher_loss 0.3152 (0.2902) loss_zs_kd 0.1187 (0.1284) loss_oracle 0.5032 (0.4556) acc 87.5000 (83.9062) kd_loss 1.0551 (0.9521) lr 1.3090e-03 eta 0:06:48
epoch [22/50] batch [60/162] time 0.091 (0.086) data 0.001 (0.004) loss 1.0592 (0.8218) ce_loss 0.5942 (0.4703) teacher_loss 0.4596 (0.2999) loss_zs_kd 0.1230 (0.1308) loss_oracle 0.5381 (0.4565) acc 75.0000 (82.9167) kd_loss 1.0323 (0.9643) lr 1.3090e-03 eta 0:06:40
epoch [22/50] batch [80/162] time 0.091 (0.086) data 0.000 (0.003) loss 1.0247 (0.8204) ce_loss 0.5254 (0.4694) teacher_loss 0.4238 (0.2926) loss_zs_kd 0.1578 (0.1348) loss_oracle 0.5220 (0.4604) acc 84.3750 (82.7734) kd_loss 1.0554 (0.9689) lr 1.3090e-03 eta 0:06:37
epoch [22/50] batch [100/162] time 0.083 (0.086) data 0.000 (0.003) loss 0.6788 (0.8168) ce_loss 0.2942 (0.4627) teacher_loss 0.1843 (0.2870) loss_zs_kd 0.1487 (0.1360) loss_oracle 0.4202 (0.4618) acc 84.3750 (83.0938) kd_loss 0.9375 (0.9715) lr 1.3090e-03 eta 0:06:33
epoch [22/50] batch [120/162] time 0.073 (0.085) data 0.000 (0.002) loss 0.8988 (0.8175) ce_loss 0.4209 (0.4647) teacher_loss 0.3353 (0.2890) loss_zs_kd 0.1404 (0.1350) loss_oracle 0.4932 (0.4609) acc 87.5000 (82.6823) kd_loss 0.9708 (0.9662) lr 1.3090e-03 eta 0:06:31
epoch [22/50] batch [140/162] time 0.084 (0.085) data 0.000 (0.002) loss 0.8125 (0.8226) ce_loss 0.4277 (0.4720) teacher_loss 0.2464 (0.2906) loss_zs_kd 0.1277 (0.1353) loss_oracle 0.5023 (0.4643) acc 84.3750 (82.5893) kd_loss 1.0026 (0.9650) lr 1.3090e-03 eta 0:06:28
epoch [22/50] batch [160/162] time 0.079 (0.085) data 0.000 (0.002) loss 0.7034 (0.8242) ce_loss 0.3979 (0.4771) teacher_loss 0.1673 (0.2923) loss_zs_kd 0.1631 (0.1368) loss_oracle 0.4545 (0.4635) acc 84.3750 (82.5391) kd_loss 0.8681 (0.9604) lr 1.3090e-03 eta 0:06:24
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,944
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,651
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 75.2%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [23/50] batch [20/162] time 0.081 (0.094) data 0.000 (0.013) loss 0.8993 (0.8114) ce_loss 0.5991 (0.5081) teacher_loss 0.2998 (0.2970) loss_zs_kd 0.1941 (0.1607) loss_oracle 0.5025 (0.4340) acc 84.3750 (81.8750) kd_loss 0.9392 (0.9073) lr 1.2487e-03 eta 0:07:03
epoch [23/50] batch [40/162] time 0.077 (0.087) data 0.000 (0.007) loss 0.5685 (0.7875) ce_loss 0.2637 (0.4762) teacher_loss 0.1865 (0.2745) loss_zs_kd 0.0988 (0.1555) loss_oracle 0.3327 (0.4352) acc 90.6250 (83.0469) kd_loss 0.8064 (0.9086) lr 1.2487e-03 eta 0:06:30
epoch [23/50] batch [60/162] time 0.081 (0.085) data 0.000 (0.004) loss 0.8614 (0.7778) ce_loss 0.6113 (0.4644) teacher_loss 0.4088 (0.2781) loss_zs_kd 0.1246 (0.1453) loss_oracle 0.3902 (0.4271) acc 78.1250 (83.3854) kd_loss 0.8512 (0.9007) lr 1.2487e-03 eta 0:06:21
epoch [23/50] batch [80/162] time 0.090 (0.085) data 0.000 (0.003) loss 0.7567 (0.7788) ce_loss 0.4641 (0.4681) teacher_loss 0.2573 (0.2803) loss_zs_kd 0.1322 (0.1442) loss_oracle 0.4333 (0.4264) acc 93.7500 (83.5938) kd_loss 0.9153 (0.8931) lr 1.2487e-03 eta 0:06:18
epoch [23/50] batch [100/162] time 0.073 (0.084) data 0.000 (0.003) loss 0.8521 (0.7858) ce_loss 0.5107 (0.4758) teacher_loss 0.3406 (0.2940) loss_zs_kd 0.1266 (0.1418) loss_oracle 0.4483 (0.4208) acc 81.2500 (83.2500) kd_loss 0.9054 (0.8882) lr 1.2487e-03 eta 0:06:14
epoch [23/50] batch [120/162] time 0.082 (0.084) data 0.000 (0.002) loss 0.6432 (0.7789) ce_loss 0.3809 (0.4731) teacher_loss 0.1794 (0.2939) loss_zs_kd 0.1470 (0.1387) loss_oracle 0.3902 (0.4157) acc 84.3750 (83.2812) kd_loss 0.8400 (0.8819) lr 1.2487e-03 eta 0:06:13
epoch [23/50] batch [140/162] time 0.088 (0.085) data 0.000 (0.002) loss 0.9966 (0.7749) ce_loss 0.6621 (0.4692) teacher_loss 0.4232 (0.2939) loss_zs_kd 0.1211 (0.1373) loss_oracle 0.5129 (0.4124) acc 78.1250 (83.2812) kd_loss 0.9475 (0.8791) lr 1.2487e-03 eta 0:06:12
epoch [23/50] batch [160/162] time 0.073 (0.084) data 0.000 (0.002) loss 0.6949 (0.7779) ce_loss 0.3293 (0.4765) teacher_loss 0.2337 (0.3000) loss_zs_kd 0.1000 (0.1347) loss_oracle 0.4112 (0.4106) acc 93.7500 (83.1641) kd_loss 0.8996 (0.8746) lr 1.2487e-03 eta 0:06:07
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,932
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 88.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,687
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 76.0%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [24/50] batch [20/162] time 0.074 (0.098) data 0.000 (0.018) loss 0.8681 (0.7693) ce_loss 0.5977 (0.4846) teacher_loss 0.4665 (0.2872) loss_zs_kd 0.1106 (0.1373) loss_oracle 0.3463 (0.4135) acc 84.3750 (82.8125) kd_loss 0.7744 (0.8477) lr 1.1874e-03 eta 0:07:08
epoch [24/50] batch [40/162] time 0.084 (0.090) data 0.000 (0.009) loss 0.6515 (0.7702) ce_loss 0.3369 (0.4853) teacher_loss 0.2260 (0.2927) loss_zs_kd 0.1412 (0.1355) loss_oracle 0.3550 (0.4097) acc 87.5000 (82.1094) kd_loss 0.7958 (0.8448) lr 1.1874e-03 eta 0:06:30
epoch [24/50] batch [60/162] time 0.079 (0.086) data 0.001 (0.006) loss 0.9372 (0.7624) ce_loss 0.6709 (0.4723) teacher_loss 0.4354 (0.2903) loss_zs_kd 0.1274 (0.1318) loss_oracle 0.4381 (0.4062) acc 78.1250 (82.2917) kd_loss 0.8736 (0.8449) lr 1.1874e-03 eta 0:06:13
epoch [24/50] batch [80/162] time 0.085 (0.086) data 0.000 (0.005) loss 0.8754 (0.7697) ce_loss 0.6064 (0.4762) teacher_loss 0.4237 (0.3023) loss_zs_kd 0.1168 (0.1282) loss_oracle 0.3934 (0.4032) acc 78.1250 (82.3828) kd_loss 0.8466 (0.8510) lr 1.1874e-03 eta 0:06:10
epoch [24/50] batch [100/162] time 0.081 (0.086) data 0.000 (0.004) loss 0.7102 (0.7692) ce_loss 0.4441 (0.4830) teacher_loss 0.2533 (0.3102) loss_zs_kd 0.1092 (0.1285) loss_oracle 0.4024 (0.3947) acc 84.3750 (82.2500) kd_loss 0.7913 (0.8390) lr 1.1874e-03 eta 0:06:08
epoch [24/50] batch [120/162] time 0.081 (0.086) data 0.000 (0.003) loss 0.7561 (0.7609) ce_loss 0.4106 (0.4735) teacher_loss 0.3362 (0.3079) loss_zs_kd 0.1470 (0.1271) loss_oracle 0.3464 (0.3894) acc 90.6250 (82.3958) kd_loss 0.8028 (0.8350) lr 1.1874e-03 eta 0:06:06
epoch [24/50] batch [140/162] time 0.086 (0.087) data 0.000 (0.003) loss 0.7382 (0.7573) ce_loss 0.3684 (0.4723) teacher_loss 0.3433 (0.3088) loss_zs_kd 0.1516 (0.1261) loss_oracle 0.3191 (0.3854) acc 93.7500 (82.4777) kd_loss 0.8662 (0.8340) lr 1.1874e-03 eta 0:06:08
epoch [24/50] batch [160/162] time 0.072 (0.086) data 0.000 (0.003) loss 0.8592 (0.7578) ce_loss 0.6592 (0.4722) teacher_loss 0.3350 (0.3078) loss_zs_kd 0.1333 (0.1259) loss_oracle 0.4576 (0.3870) acc 75.0000 (82.5195) kd_loss 0.8916 (0.8347) lr 1.1874e-03 eta 0:06:02
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,936
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 88.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,680
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 76.2%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [25/50] batch [20/162] time 0.089 (0.102) data 0.000 (0.017) loss 0.6587 (0.8278) ce_loss 0.4453 (0.5482) teacher_loss 0.3959 (0.3695) loss_zs_kd 0.0744 (0.1341) loss_oracle 0.2255 (0.3913) acc 84.3750 (80.1562) kd_loss 0.7251 (0.8419) lr 1.1253e-03 eta 0:07:07
epoch [25/50] batch [40/162] time 0.086 (0.091) data 0.000 (0.009) loss 0.7060 (0.7881) ce_loss 0.3540 (0.4940) teacher_loss 0.2409 (0.3282) loss_zs_kd 0.0922 (0.1286) loss_oracle 0.4190 (0.3955) acc 81.2500 (81.7969) kd_loss 0.8723 (0.8523) lr 1.1253e-03 eta 0:06:19
epoch [25/50] batch [60/162] time 0.080 (0.086) data 0.000 (0.006) loss 0.7828 (0.7678) ce_loss 0.3975 (0.4814) teacher_loss 0.2623 (0.3136) loss_zs_kd 0.1356 (0.1273) loss_oracle 0.4527 (0.3905) acc 87.5000 (82.4479) kd_loss 0.9200 (0.8543) lr 1.1253e-03 eta 0:05:58
epoch [25/50] batch [80/162] time 0.071 (0.085) data 0.000 (0.004) loss 0.6642 (0.7576) ce_loss 0.3174 (0.4722) teacher_loss 0.1900 (0.3034) loss_zs_kd 0.1131 (0.1289) loss_oracle 0.4176 (0.3898) acc 87.5000 (82.6172) kd_loss 0.9111 (0.8516) lr 1.1253e-03 eta 0:05:49
epoch [25/50] batch [100/162] time 0.078 (0.084) data 0.000 (0.004) loss 0.7300 (0.7549) ce_loss 0.4067 (0.4691) teacher_loss 0.2462 (0.2985) loss_zs_kd 0.1176 (0.1256) loss_oracle 0.4249 (0.3935) acc 87.5000 (82.6875) kd_loss 0.8401 (0.8549) lr 1.1253e-03 eta 0:05:43
epoch [25/50] batch [120/162] time 0.065 (0.083) data 0.000 (0.003) loss 0.9326 (0.7630) ce_loss 0.5312 (0.4763) teacher_loss 0.4052 (0.2998) loss_zs_kd 0.1396 (0.1293) loss_oracle 0.4576 (0.3986) acc 84.3750 (82.4740) kd_loss 0.9036 (0.8618) lr 1.1253e-03 eta 0:05:37
epoch [25/50] batch [140/162] time 0.082 (0.082) data 0.000 (0.003) loss 0.6410 (0.7664) ce_loss 0.2698 (0.4757) teacher_loss 0.1379 (0.2947) loss_zs_kd 0.0982 (0.1292) loss_oracle 0.4540 (0.4071) acc 93.7500 (82.5893) kd_loss 0.9522 (0.8688) lr 1.1253e-03 eta 0:05:32
epoch [25/50] batch [160/162] time 0.072 (0.081) data 0.000 (0.002) loss 0.6834 (0.7728) ce_loss 0.4192 (0.4773) teacher_loss 0.2193 (0.2937) loss_zs_kd 0.0887 (0.1311) loss_oracle 0.4198 (0.4135) acc 84.3750 (82.4414) kd_loss 0.9389 (0.8757) lr 1.1253e-03 eta 0:05:27
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,940
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,650
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 76.0%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [26/50] batch [20/162] time 0.082 (0.106) data 0.000 (0.018) loss 0.7697 (0.7983) ce_loss 0.3750 (0.4834) teacher_loss 0.1644 (0.2731) loss_zs_kd 0.2271 (0.1589) loss_oracle 0.4918 (0.4458) acc 87.5000 (81.5625) kd_loss 0.9713 (0.9052) lr 1.0628e-03 eta 0:07:06
epoch [26/50] batch [40/162] time 0.082 (0.096) data 0.000 (0.009) loss 0.7418 (0.8077) ce_loss 0.4521 (0.4842) teacher_loss 0.1948 (0.2832) loss_zs_kd 0.1657 (0.1518) loss_oracle 0.4641 (0.4486) acc 81.2500 (81.6406) kd_loss 0.9724 (0.9176) lr 1.0628e-03 eta 0:06:24
epoch [26/50] batch [60/162] time 0.081 (0.092) data 0.000 (0.006) loss 0.6905 (0.8001) ce_loss 0.2686 (0.4763) teacher_loss 0.1544 (0.2763) loss_zs_kd 0.1546 (0.1525) loss_oracle 0.4587 (0.4476) acc 87.5000 (81.9792) kd_loss 0.8950 (0.9150) lr 1.0628e-03 eta 0:06:07
epoch [26/50] batch [80/162] time 0.084 (0.090) data 0.000 (0.005) loss 0.7556 (0.8033) ce_loss 0.4380 (0.4816) teacher_loss 0.1983 (0.2816) loss_zs_kd 0.1398 (0.1484) loss_oracle 0.4875 (0.4475) acc 81.2500 (82.0312) kd_loss 1.0366 (0.9155) lr 1.0628e-03 eta 0:05:57
epoch [26/50] batch [100/162] time 0.094 (0.089) data 0.000 (0.004) loss 0.9770 (0.8057) ce_loss 0.5117 (0.4800) teacher_loss 0.3939 (0.2798) loss_zs_kd 0.1859 (0.1490) loss_oracle 0.4901 (0.4514) acc 84.3750 (82.0000) kd_loss 0.9535 (0.9210) lr 1.0628e-03 eta 0:05:49
epoch [26/50] batch [120/162] time 0.079 (0.088) data 0.000 (0.003) loss 0.6468 (0.8080) ce_loss 0.3848 (0.4784) teacher_loss 0.1232 (0.2787) loss_zs_kd 0.1350 (0.1499) loss_oracle 0.4561 (0.4544) acc 90.6250 (82.2396) kd_loss 1.0080 (0.9238) lr 1.0628e-03 eta 0:05:43
epoch [26/50] batch [140/162] time 0.091 (0.087) data 0.000 (0.003) loss 0.7403 (0.7973) ce_loss 0.3342 (0.4706) teacher_loss 0.2547 (0.2692) loss_zs_kd 0.1713 (0.1505) loss_oracle 0.4000 (0.4529) acc 90.6250 (82.6562) kd_loss 0.9187 (0.9241) lr 1.0628e-03 eta 0:05:39
epoch [26/50] batch [160/162] time 0.073 (0.086) data 0.000 (0.003) loss 0.7717 (0.7956) ce_loss 0.4771 (0.4703) teacher_loss 0.3139 (0.2665) loss_zs_kd 0.0911 (0.1506) loss_oracle 0.4123 (0.4538) acc 87.5000 (82.6953) kd_loss 0.8588 (0.9246) lr 1.0628e-03 eta 0:05:33
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,938
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 88.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,666
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 75.7%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [27/50] batch [20/162] time 0.086 (0.097) data 0.000 (0.013) loss 0.8825 (0.7820) ce_loss 0.4124 (0.4963) teacher_loss 0.2705 (0.2393) loss_zs_kd 0.1979 (0.1609) loss_oracle 0.5131 (0.4623) acc 87.5000 (81.0938) kd_loss 0.9196 (0.9051) lr 1.0000e-03 eta 0:06:14
epoch [27/50] batch [40/162] time 0.088 (0.091) data 0.000 (0.007) loss 0.6914 (0.8002) ce_loss 0.2974 (0.4938) teacher_loss 0.1610 (0.2660) loss_zs_kd 0.1278 (0.1539) loss_oracle 0.4665 (0.4573) acc 90.6250 (81.9531) kd_loss 0.9556 (0.9106) lr 1.0000e-03 eta 0:05:48
epoch [27/50] batch [60/162] time 0.082 (0.089) data 0.000 (0.005) loss 0.7950 (0.7980) ce_loss 0.3235 (0.4901) teacher_loss 0.1661 (0.2679) loss_zs_kd 0.1657 (0.1505) loss_oracle 0.5460 (0.4549) acc 90.6250 (82.0833) kd_loss 0.9971 (0.9175) lr 1.0000e-03 eta 0:05:39
epoch [27/50] batch [80/162] time 0.097 (0.088) data 0.001 (0.004) loss 0.9781 (0.8054) ce_loss 0.6416 (0.4857) teacher_loss 0.4052 (0.2699) loss_zs_kd 0.1502 (0.1510) loss_oracle 0.4978 (0.4599) acc 81.2500 (81.8750) kd_loss 0.9861 (0.9252) lr 1.0000e-03 eta 0:05:34
epoch [27/50] batch [100/162] time 0.079 (0.088) data 0.000 (0.003) loss 0.6167 (0.7941) ce_loss 0.2969 (0.4707) teacher_loss 0.1589 (0.2589) loss_zs_kd 0.1307 (0.1520) loss_oracle 0.3925 (0.4592) acc 87.5000 (82.6875) kd_loss 0.8806 (0.9289) lr 1.0000e-03 eta 0:05:31
epoch [27/50] batch [120/162] time 0.083 (0.087) data 0.000 (0.002) loss 0.9066 (0.7896) ce_loss 0.4873 (0.4662) teacher_loss 0.3408 (0.2544) loss_zs_kd 0.1316 (0.1513) loss_oracle 0.5000 (0.4596) acc 84.3750 (82.8906) kd_loss 0.9811 (0.9315) lr 1.0000e-03 eta 0:05:27
epoch [27/50] batch [140/162] time 0.084 (0.086) data 0.000 (0.002) loss 0.6627 (0.7920) ce_loss 0.3999 (0.4692) teacher_loss 0.2081 (0.2555) loss_zs_kd 0.0937 (0.1508) loss_oracle 0.4077 (0.4611) acc 90.6250 (82.6786) kd_loss 0.9577 (0.9351) lr 1.0000e-03 eta 0:05:23
epoch [27/50] batch [160/162] time 0.067 (0.085) data 0.000 (0.002) loss 0.4864 (0.7885) ce_loss 0.3037 (0.4647) teacher_loss 0.1173 (0.2518) loss_zs_kd 0.1111 (0.1502) loss_oracle 0.3136 (0.4616) acc 87.5000 (82.8516) kd_loss 0.7490 (0.9346) lr 1.0000e-03 eta 0:05:16
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,946
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,645
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 75.3%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [28/50] batch [20/162] time 0.082 (0.093) data 0.000 (0.015) loss 0.8875 (0.8220) ce_loss 0.5312 (0.4900) teacher_loss 0.3353 (0.2657) loss_zs_kd 0.1804 (0.1579) loss_oracle 0.4621 (0.4773) acc 78.1250 (80.6250) kd_loss 0.9272 (0.9512) lr 9.3721e-04 eta 0:05:45
epoch [28/50] batch [40/162] time 0.083 (0.084) data 0.001 (0.007) loss 1.0620 (0.8392) ce_loss 0.7192 (0.5190) teacher_loss 0.4777 (0.2685) loss_zs_kd 0.2128 (0.1652) loss_oracle 0.4779 (0.4881) acc 68.7500 (80.0781) kd_loss 0.9225 (0.9521) lr 9.3721e-04 eta 0:05:09
epoch [28/50] batch [60/162] time 0.093 (0.085) data 0.000 (0.005) loss 0.8387 (0.8265) ce_loss 0.4507 (0.5053) teacher_loss 0.2388 (0.2676) loss_zs_kd 0.1563 (0.1541) loss_oracle 0.5217 (0.4818) acc 84.3750 (80.9896) kd_loss 0.9633 (0.9460) lr 9.3721e-04 eta 0:05:10
epoch [28/50] batch [80/162] time 0.080 (0.084) data 0.000 (0.004) loss 0.7694 (0.8223) ce_loss 0.4280 (0.5006) teacher_loss 0.1697 (0.2643) loss_zs_kd 0.1277 (0.1547) loss_oracle 0.5359 (0.4806) acc 81.2500 (81.0156) kd_loss 1.0134 (0.9455) lr 9.3721e-04 eta 0:05:07
epoch [28/50] batch [100/162] time 0.079 (0.084) data 0.000 (0.003) loss 0.8745 (0.8014) ce_loss 0.6064 (0.4814) teacher_loss 0.3364 (0.2506) loss_zs_kd 0.1981 (0.1534) loss_oracle 0.4390 (0.4741) acc 81.2500 (81.8125) kd_loss 0.9502 (0.9470) lr 9.3721e-04 eta 0:05:05
epoch [28/50] batch [120/162] time 0.092 (0.085) data 0.000 (0.003) loss 0.9265 (0.7953) ce_loss 0.7329 (0.4743) teacher_loss 0.3958 (0.2481) loss_zs_kd 0.1648 (0.1526) loss_oracle 0.4484 (0.4708) acc 71.8750 (82.2396) kd_loss 0.9136 (0.9454) lr 9.3721e-04 eta 0:05:05
epoch [28/50] batch [140/162] time 0.095 (0.084) data 0.000 (0.002) loss 0.9114 (0.7929) ce_loss 0.6841 (0.4746) teacher_loss 0.4075 (0.2506) loss_zs_kd 0.1434 (0.1509) loss_oracle 0.4322 (0.4668) acc 71.8750 (82.3661) kd_loss 0.8669 (0.9443) lr 9.3721e-04 eta 0:05:02
epoch [28/50] batch [160/162] time 0.071 (0.083) data 0.000 (0.002) loss 0.7155 (0.7899) ce_loss 0.4309 (0.4705) teacher_loss 0.2794 (0.2501) loss_zs_kd 0.0904 (0.1494) loss_oracle 0.3909 (0.4651) acc 87.5000 (82.6367) kd_loss 0.8996 (0.9445) lr 9.3721e-04 eta 0:04:57
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,939
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,661
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 75.4%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [29/50] batch [20/162] time 0.081 (0.093) data 0.000 (0.012) loss 0.7948 (0.7479) ce_loss 0.5259 (0.4652) teacher_loss 0.3175 (0.2274) loss_zs_kd 0.1224 (0.1536) loss_oracle 0.4161 (0.4438) acc 81.2500 (83.9062) kd_loss 0.8524 (0.9129) lr 8.7467e-04 eta 0:05:28
epoch [29/50] batch [40/162] time 0.077 (0.084) data 0.000 (0.006) loss 0.9824 (0.7666) ce_loss 0.7275 (0.4914) teacher_loss 0.4211 (0.2487) loss_zs_kd 0.1388 (0.1558) loss_oracle 0.4919 (0.4400) acc 68.7500 (82.1875) kd_loss 0.8964 (0.9076) lr 8.7467e-04 eta 0:04:55
epoch [29/50] batch [60/162] time 0.079 (0.082) data 0.001 (0.004) loss 0.7364 (0.7603) ce_loss 0.3838 (0.4833) teacher_loss 0.2281 (0.2491) loss_zs_kd 0.1354 (0.1510) loss_oracle 0.4406 (0.4358) acc 87.5000 (82.1354) kd_loss 0.8824 (0.9082) lr 8.7467e-04 eta 0:04:48
epoch [29/50] batch [80/162] time 0.074 (0.081) data 0.000 (0.003) loss 0.5664 (0.7509) ce_loss 0.3757 (0.4786) teacher_loss 0.1433 (0.2419) loss_zs_kd 0.0913 (0.1495) loss_oracle 0.3775 (0.4342) acc 84.3750 (82.5391) kd_loss 0.9048 (0.9098) lr 8.7467e-04 eta 0:04:41
epoch [29/50] batch [100/162] time 0.080 (0.080) data 0.000 (0.003) loss 0.6210 (0.7558) ce_loss 0.3945 (0.4783) teacher_loss 0.2263 (0.2463) loss_zs_kd 0.1079 (0.1495) loss_oracle 0.3407 (0.4348) acc 93.7500 (82.6250) kd_loss 0.9127 (0.9112) lr 8.7467e-04 eta 0:04:38
epoch [29/50] batch [120/162] time 0.071 (0.079) data 0.000 (0.002) loss 0.7124 (0.7668) ce_loss 0.5801 (0.4864) teacher_loss 0.2598 (0.2524) loss_zs_kd 0.1584 (0.1490) loss_oracle 0.3734 (0.4399) acc 78.1250 (82.4479) kd_loss 0.9593 (0.9164) lr 8.7467e-04 eta 0:04:32
epoch [29/50] batch [140/162] time 0.074 (0.079) data 0.000 (0.002) loss 0.8282 (0.7714) ce_loss 0.3555 (0.4838) teacher_loss 0.2218 (0.2517) loss_zs_kd 0.1021 (0.1500) loss_oracle 0.5554 (0.4446) acc 81.2500 (82.7455) kd_loss 0.9518 (0.9208) lr 8.7467e-04 eta 0:04:29
epoch [29/50] batch [160/162] time 0.071 (0.077) data 0.000 (0.002) loss 0.8489 (0.7678) ce_loss 0.4661 (0.4758) teacher_loss 0.2377 (0.2471) loss_zs_kd 0.1479 (0.1495) loss_oracle 0.5373 (0.4460) acc 81.2500 (82.8516) kd_loss 1.0027 (0.9238) lr 8.7467e-04 eta 0:04:23
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,944
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,632
* accuracy: 80.2%
* error: 19.8%
* macro_f1: 75.1%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [30/50] batch [20/162] time 0.075 (0.101) data 0.000 (0.015) loss 0.5987 (0.7674) ce_loss 0.3218 (0.4695) teacher_loss 0.0934 (0.2359) loss_zs_kd 0.1671 (0.1517) loss_oracle 0.4217 (0.4557) acc 90.6250 (82.6562) kd_loss 0.8951 (0.9577) lr 8.1262e-04 eta 0:05:41
epoch [30/50] batch [40/162] time 0.088 (0.090) data 0.000 (0.008) loss 0.6679 (0.7770) ce_loss 0.2322 (0.4485) teacher_loss 0.0883 (0.2152) loss_zs_kd 0.1772 (0.1531) loss_oracle 0.4910 (0.4852) acc 93.7500 (83.8281) kd_loss 0.9501 (0.9687) lr 8.1262e-04 eta 0:05:01
epoch [30/50] batch [60/162] time 0.073 (0.086) data 0.001 (0.005) loss 0.7935 (0.7946) ce_loss 0.5366 (0.4613) teacher_loss 0.1572 (0.2256) loss_zs_kd 0.2746 (0.1575) loss_oracle 0.4990 (0.4903) acc 75.0000 (83.1771) kd_loss 0.9828 (0.9753) lr 8.1262e-04 eta 0:04:46
epoch [30/50] batch [80/162] time 0.078 (0.084) data 0.000 (0.004) loss 1.0013 (0.8135) ce_loss 0.6235 (0.4763) teacher_loss 0.4812 (0.2399) loss_zs_kd 0.1843 (0.1575) loss_oracle 0.4280 (0.4948) acc 75.0000 (83.0469) kd_loss 0.9679 (0.9770) lr 8.1262e-04 eta 0:04:38
epoch [30/50] batch [100/162] time 0.069 (0.082) data 0.000 (0.003) loss 0.5926 (0.8062) ce_loss 0.3887 (0.4677) teacher_loss 0.1267 (0.2336) loss_zs_kd 0.1433 (0.1571) loss_oracle 0.3942 (0.4940) acc 87.5000 (83.1562) kd_loss 0.9519 (0.9771) lr 8.1262e-04 eta 0:04:30
epoch [30/50] batch [120/162] time 0.073 (0.080) data 0.000 (0.003) loss 0.7246 (0.8063) ce_loss 0.4524 (0.4609) teacher_loss 0.1520 (0.2299) loss_zs_kd 0.1689 (0.1585) loss_oracle 0.4882 (0.4972) acc 87.5000 (83.2292) kd_loss 1.0129 (0.9800) lr 8.1262e-04 eta 0:04:22
epoch [30/50] batch [140/162] time 0.064 (0.079) data 0.000 (0.002) loss 0.8131 (0.8061) ce_loss 0.4727 (0.4663) teacher_loss 0.2324 (0.2345) loss_zs_kd 0.1725 (0.1575) loss_oracle 0.4944 (0.4929) acc 87.5000 (83.1920) kd_loss 0.9407 (0.9781) lr 8.1262e-04 eta 0:04:17
epoch [30/50] batch [160/162] time 0.070 (0.078) data 0.000 (0.002) loss 0.7338 (0.8078) ce_loss 0.3269 (0.4685) teacher_loss 0.1109 (0.2344) loss_zs_kd 0.1790 (0.1582) loss_oracle 0.5334 (0.4943) acc 90.6250 (82.8516) kd_loss 0.9932 (0.9783) lr 8.1262e-04 eta 0:04:12
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,934
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 88.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,651
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 75.5%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [31/50] batch [20/162] time 0.072 (0.097) data 0.000 (0.015) loss 0.9982 (0.8301) ce_loss 0.6353 (0.5139) teacher_loss 0.3865 (0.2540) loss_zs_kd 0.2015 (0.1676) loss_oracle 0.5109 (0.4923) acc 78.1250 (80.7812) kd_loss 0.9034 (0.9678) lr 7.5131e-04 eta 0:05:11
epoch [31/50] batch [40/162] time 0.083 (0.086) data 0.000 (0.008) loss 0.7397 (0.8156) ce_loss 0.2335 (0.4742) teacher_loss 0.1882 (0.2443) loss_zs_kd 0.1292 (0.1596) loss_oracle 0.4870 (0.4915) acc 93.7500 (82.5781) kd_loss 0.9526 (0.9656) lr 7.5131e-04 eta 0:04:36
epoch [31/50] batch [60/162] time 0.061 (0.081) data 0.000 (0.005) loss 0.5007 (0.8122) ce_loss 0.1686 (0.4612) teacher_loss 0.1106 (0.2479) loss_zs_kd 0.0842 (0.1467) loss_oracle 0.3481 (0.4910) acc 93.7500 (83.4375) kd_loss 0.9368 (0.9647) lr 7.5131e-04 eta 0:04:17
epoch [31/50] batch [80/162] time 0.074 (0.078) data 0.000 (0.004) loss 0.6467 (0.8156) ce_loss 0.4624 (0.4697) teacher_loss 0.1164 (0.2450) loss_zs_kd 0.1989 (0.1484) loss_oracle 0.4308 (0.4964) acc 87.5000 (82.6172) kd_loss 0.9097 (0.9708) lr 7.5131e-04 eta 0:04:05
epoch [31/50] batch [100/162] time 0.066 (0.076) data 0.000 (0.003) loss 0.6882 (0.8175) ce_loss 0.4253 (0.4732) teacher_loss 0.2002 (0.2467) loss_zs_kd 0.1259 (0.1506) loss_oracle 0.4250 (0.4956) acc 84.3750 (82.6875) kd_loss 0.9343 (0.9687) lr 7.5131e-04 eta 0:03:57
epoch [31/50] batch [120/162] time 0.070 (0.076) data 0.000 (0.003) loss 0.6973 (0.8165) ce_loss 0.3123 (0.4719) teacher_loss 0.1418 (0.2441) loss_zs_kd 0.1096 (0.1493) loss_oracle 0.5007 (0.4977) acc 87.5000 (82.5781) kd_loss 0.8981 (0.9713) lr 7.5131e-04 eta 0:03:55
epoch [31/50] batch [140/162] time 0.081 (0.076) data 0.000 (0.002) loss 0.8448 (0.8198) ce_loss 0.5249 (0.4715) teacher_loss 0.2729 (0.2464) loss_zs_kd 0.1535 (0.1488) loss_oracle 0.4951 (0.4990) acc 75.0000 (82.5223) kd_loss 0.9681 (0.9700) lr 7.5131e-04 eta 0:03:56
epoch [31/50] batch [160/162] time 0.073 (0.076) data 0.000 (0.002) loss 0.8648 (0.8176) ce_loss 0.5283 (0.4669) teacher_loss 0.3307 (0.2451) loss_zs_kd 0.1798 (0.1472) loss_oracle 0.4441 (0.4989) acc 81.2500 (82.7148) kd_loss 0.8733 (0.9691) lr 7.5131e-04 eta 0:03:54
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,937
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,659
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 75.0%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [32/50] batch [20/162] time 0.075 (0.092) data 0.000 (0.014) loss 0.8394 (0.8474) ce_loss 0.4873 (0.4621) teacher_loss 0.2858 (0.2624) loss_zs_kd 0.1223 (0.1366) loss_oracle 0.4924 (0.5168) acc 78.1250 (83.5938) kd_loss 0.9227 (0.9791) lr 6.9098e-04 eta 0:04:42
epoch [32/50] batch [40/162] time 0.066 (0.081) data 0.000 (0.007) loss 0.6749 (0.8278) ce_loss 0.4275 (0.4741) teacher_loss 0.1812 (0.2645) loss_zs_kd 0.1500 (0.1356) loss_oracle 0.4187 (0.4954) acc 81.2500 (82.4219) kd_loss 1.0130 (0.9589) lr 6.9098e-04 eta 0:04:06
epoch [32/50] batch [60/162] time 0.075 (0.078) data 0.000 (0.005) loss 0.9513 (0.8220) ce_loss 0.6104 (0.4625) teacher_loss 0.4357 (0.2540) loss_zs_kd 0.1193 (0.1452) loss_oracle 0.4559 (0.4955) acc 75.0000 (82.6562) kd_loss 0.8903 (0.9550) lr 6.9098e-04 eta 0:03:56
epoch [32/50] batch [80/162] time 0.066 (0.077) data 0.000 (0.004) loss 0.6672 (0.8120) ce_loss 0.3491 (0.4558) teacher_loss 0.2126 (0.2539) loss_zs_kd 0.0970 (0.1415) loss_oracle 0.4061 (0.4873) acc 87.5000 (83.3203) kd_loss 0.9013 (0.9529) lr 6.9098e-04 eta 0:03:51
epoch [32/50] batch [100/162] time 0.083 (0.078) data 0.000 (0.003) loss 0.8933 (0.8054) ce_loss 0.5825 (0.4508) teacher_loss 0.3510 (0.2459) loss_zs_kd 0.1268 (0.1424) loss_oracle 0.4789 (0.4882) acc 71.8750 (83.4062) kd_loss 0.9608 (0.9565) lr 6.9098e-04 eta 0:03:52
epoch [32/50] batch [120/162] time 0.073 (0.078) data 0.000 (0.003) loss 0.7395 (0.8097) ce_loss 0.5068 (0.4618) teacher_loss 0.2066 (0.2516) loss_zs_kd 0.1645 (0.1441) loss_oracle 0.4507 (0.4861) acc 87.5000 (83.2292) kd_loss 0.8727 (0.9526) lr 6.9098e-04 eta 0:03:51
epoch [32/50] batch [140/162] time 0.093 (0.078) data 0.000 (0.002) loss 0.5605 (0.8066) ce_loss 0.3435 (0.4585) teacher_loss 0.1554 (0.2476) loss_zs_kd 0.1646 (0.1451) loss_oracle 0.3228 (0.4864) acc 90.6250 (83.2589) kd_loss 0.8021 (0.9519) lr 6.9098e-04 eta 0:03:50
epoch [32/50] batch [160/162] time 0.072 (0.078) data 0.000 (0.002) loss 0.9790 (0.8085) ce_loss 0.8301 (0.4613) teacher_loss 0.4201 (0.2476) loss_zs_kd 0.1680 (0.1463) loss_oracle 0.4750 (0.4877) acc 62.5000 (83.1055) kd_loss 0.9419 (0.9538) lr 6.9098e-04 eta 0:03:47
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,643
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 75.3%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [33/50] batch [20/162] time 0.086 (0.101) data 0.000 (0.016) loss 0.8793 (0.8399) ce_loss 0.6953 (0.4955) teacher_loss 0.3410 (0.2709) loss_zs_kd 0.1993 (0.1617) loss_oracle 0.4386 (0.4882) acc 65.6250 (81.0938) kd_loss 0.9131 (0.9666) lr 6.3188e-04 eta 0:04:51
epoch [33/50] batch [40/162] time 0.084 (0.092) data 0.000 (0.008) loss 0.9838 (0.8137) ce_loss 0.6167 (0.4779) teacher_loss 0.3774 (0.2610) loss_zs_kd 0.1131 (0.1509) loss_oracle 0.5499 (0.4773) acc 75.0000 (82.3438) kd_loss 1.0140 (0.9573) lr 6.3188e-04 eta 0:04:25
epoch [33/50] batch [60/162] time 0.079 (0.090) data 0.001 (0.005) loss 0.8405 (0.8104) ce_loss 0.4121 (0.4662) teacher_loss 0.1808 (0.2550) loss_zs_kd 0.1364 (0.1462) loss_oracle 0.5916 (0.4823) acc 87.5000 (82.8125) kd_loss 1.0726 (0.9589) lr 6.3188e-04 eta 0:04:16
epoch [33/50] batch [80/162] time 0.082 (0.089) data 0.000 (0.004) loss 0.8015 (0.8067) ce_loss 0.5767 (0.4681) teacher_loss 0.2623 (0.2486) loss_zs_kd 0.1591 (0.1475) loss_oracle 0.4597 (0.4843) acc 78.1250 (82.6953) kd_loss 0.9560 (0.9613) lr 6.3188e-04 eta 0:04:11
epoch [33/50] batch [100/162] time 0.084 (0.088) data 0.000 (0.003) loss 0.8325 (0.8070) ce_loss 0.5903 (0.4653) teacher_loss 0.2429 (0.2452) loss_zs_kd 0.1936 (0.1497) loss_oracle 0.4927 (0.4869) acc 78.1250 (82.9688) kd_loss 0.9776 (0.9637) lr 6.3188e-04 eta 0:04:06
epoch [33/50] batch [120/162] time 0.082 (0.086) data 0.000 (0.003) loss 0.9854 (0.8102) ce_loss 0.6001 (0.4669) teacher_loss 0.2094 (0.2451) loss_zs_kd 0.1400 (0.1487) loss_oracle 0.7060 (0.4907) acc 75.0000 (82.9427) kd_loss 1.0696 (0.9665) lr 6.3188e-04 eta 0:04:01
epoch [33/50] batch [140/162] time 0.079 (0.086) data 0.000 (0.003) loss 0.8657 (0.8089) ce_loss 0.2996 (0.4688) teacher_loss 0.1999 (0.2453) loss_zs_kd 0.1773 (0.1495) loss_oracle 0.5771 (0.4889) acc 87.5000 (82.9018) kd_loss 1.0614 (0.9648) lr 6.3188e-04 eta 0:03:58
epoch [33/50] batch [160/162] time 0.072 (0.084) data 0.000 (0.002) loss 0.5533 (0.8053) ce_loss 0.1577 (0.4646) teacher_loss 0.0713 (0.2459) loss_zs_kd 0.0984 (0.1482) loss_oracle 0.4328 (0.4853) acc 96.8750 (82.9492) kd_loss 0.9585 (0.9603) lr 6.3188e-04 eta 0:03:52
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,655
* accuracy: 80.9%
* error: 19.1%
* macro_f1: 76.6%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [34/50] batch [20/162] time 0.082 (0.099) data 0.000 (0.016) loss 0.6814 (0.7808) ce_loss 0.2502 (0.4553) teacher_loss 0.1026 (0.2626) loss_zs_kd 0.1600 (0.1478) loss_oracle 0.4987 (0.4443) acc 90.6250 (84.6875) kd_loss 0.9495 (0.9325) lr 5.7422e-04 eta 0:04:29
epoch [34/50] batch [40/162] time 0.095 (0.091) data 0.001 (0.008) loss 0.6401 (0.7732) ce_loss 0.3909 (0.4522) teacher_loss 0.2165 (0.2445) loss_zs_kd 0.1492 (0.1471) loss_oracle 0.3490 (0.4551) acc 87.5000 (83.4375) kd_loss 0.8565 (0.9378) lr 5.7422e-04 eta 0:04:06
epoch [34/50] batch [60/162] time 0.077 (0.088) data 0.001 (0.005) loss 0.7951 (0.7783) ce_loss 0.5015 (0.4598) teacher_loss 0.2505 (0.2443) loss_zs_kd 0.1518 (0.1472) loss_oracle 0.4686 (0.4604) acc 78.1250 (83.4375) kd_loss 0.9433 (0.9366) lr 5.7422e-04 eta 0:03:56
epoch [34/50] batch [80/162] time 0.080 (0.087) data 0.000 (0.004) loss 0.8357 (0.7760) ce_loss 0.4629 (0.4630) teacher_loss 0.2091 (0.2408) loss_zs_kd 0.1585 (0.1470) loss_oracle 0.5473 (0.4617) acc 84.3750 (83.1250) kd_loss 1.0465 (0.9378) lr 5.7422e-04 eta 0:03:52
epoch [34/50] batch [100/162] time 0.082 (0.087) data 0.000 (0.003) loss 0.8157 (0.7781) ce_loss 0.6226 (0.4665) teacher_loss 0.2536 (0.2432) loss_zs_kd 0.1203 (0.1458) loss_oracle 0.5021 (0.4620) acc 81.2500 (83.0625) kd_loss 1.0028 (0.9387) lr 5.7422e-04 eta 0:03:50
epoch [34/50] batch [120/162] time 0.085 (0.087) data 0.000 (0.003) loss 0.7693 (0.7764) ce_loss 0.3984 (0.4654) teacher_loss 0.2309 (0.2423) loss_zs_kd 0.1772 (0.1465) loss_oracle 0.4498 (0.4608) acc 87.5000 (83.4896) kd_loss 0.9061 (0.9366) lr 5.7422e-04 eta 0:03:49
epoch [34/50] batch [140/162] time 0.080 (0.087) data 0.000 (0.003) loss 0.7019 (0.7810) ce_loss 0.4734 (0.4665) teacher_loss 0.2597 (0.2415) loss_zs_kd 0.1334 (0.1468) loss_oracle 0.3755 (0.4661) acc 90.6250 (83.5045) kd_loss 0.8906 (0.9407) lr 5.7422e-04 eta 0:03:47
epoch [34/50] batch [160/162] time 0.069 (0.085) data 0.000 (0.002) loss 0.7207 (0.7809) ce_loss 0.3872 (0.4627) teacher_loss 0.1184 (0.2381) loss_zs_kd 0.1453 (0.1470) loss_oracle 0.5296 (0.4693) acc 87.5000 (83.5352) kd_loss 0.9953 (0.9434) lr 5.7422e-04 eta 0:03:41
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,947
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,638
* accuracy: 80.4%
* error: 19.6%
* macro_f1: 75.2%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [35/50] batch [20/162] time 0.091 (0.102) data 0.000 (0.015) loss 0.6948 (0.7942) ce_loss 0.2803 (0.4788) teacher_loss 0.0981 (0.2152) loss_zs_kd 0.1744 (0.1681) loss_oracle 0.5095 (0.4950) acc 90.6250 (84.2188) kd_loss 0.9741 (0.9704) lr 5.1825e-04 eta 0:04:21
epoch [35/50] batch [40/162] time 0.077 (0.094) data 0.000 (0.008) loss 0.6779 (0.8257) ce_loss 0.2986 (0.4828) teacher_loss 0.1838 (0.2292) loss_zs_kd 0.1493 (0.1682) loss_oracle 0.4195 (0.5125) acc 90.6250 (83.2031) kd_loss 0.9588 (0.9789) lr 5.1825e-04 eta 0:03:58
epoch [35/50] batch [60/162] time 0.094 (0.091) data 0.001 (0.005) loss 1.0499 (0.8142) ce_loss 0.6885 (0.4829) teacher_loss 0.3931 (0.2245) loss_zs_kd 0.1539 (0.1644) loss_oracle 0.5798 (0.5075) acc 78.1250 (82.6562) kd_loss 1.0068 (0.9775) lr 5.1825e-04 eta 0:03:49
epoch [35/50] batch [80/162] time 0.088 (0.089) data 0.000 (0.004) loss 0.7528 (0.8155) ce_loss 0.4609 (0.4837) teacher_loss 0.1554 (0.2247) loss_zs_kd 0.1963 (0.1685) loss_oracle 0.4992 (0.5066) acc 81.2500 (82.3828) kd_loss 1.0333 (0.9785) lr 5.1825e-04 eta 0:03:43
epoch [35/50] batch [100/162] time 0.081 (0.088) data 0.000 (0.003) loss 0.7489 (0.8171) ce_loss 0.4282 (0.4874) teacher_loss 0.1625 (0.2242) loss_zs_kd 0.1523 (0.1699) loss_oracle 0.5103 (0.5079) acc 81.2500 (82.1250) kd_loss 1.0316 (0.9789) lr 5.1825e-04 eta 0:03:38
epoch [35/50] batch [120/162] time 0.092 (0.088) data 0.000 (0.003) loss 0.7010 (0.8160) ce_loss 0.2852 (0.4867) teacher_loss 0.0836 (0.2208) loss_zs_kd 0.1306 (0.1726) loss_oracle 0.5521 (0.5090) acc 90.6250 (82.2917) kd_loss 1.0554 (0.9782) lr 5.1825e-04 eta 0:03:36
epoch [35/50] batch [140/162] time 0.078 (0.087) data 0.000 (0.002) loss 0.6574 (0.8087) ce_loss 0.2830 (0.4760) teacher_loss 0.1432 (0.2156) loss_zs_kd 0.1321 (0.1711) loss_oracle 0.4481 (0.5076) acc 93.7500 (82.8571) kd_loss 0.9788 (0.9786) lr 5.1825e-04 eta 0:03:33
epoch [35/50] batch [160/162] time 0.073 (0.086) data 0.000 (0.002) loss 0.7638 (0.8074) ce_loss 0.4214 (0.4741) teacher_loss 0.1216 (0.2152) loss_zs_kd 0.1629 (0.1712) loss_oracle 0.5607 (0.5066) acc 84.3750 (83.2227) kd_loss 0.9994 (0.9791) lr 5.1825e-04 eta 0:03:28
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,945
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,658
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 75.9%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [36/50] batch [20/162] time 0.084 (0.097) data 0.001 (0.017) loss 0.8197 (0.7946) ce_loss 0.3940 (0.4335) teacher_loss 0.2248 (0.1874) loss_zs_kd 0.1583 (0.1605) loss_oracle 0.5157 (0.5269) acc 87.5000 (83.9062) kd_loss 0.9832 (0.9974) lr 4.6417e-04 eta 0:03:53
epoch [36/50] batch [40/162] time 0.094 (0.090) data 0.000 (0.009) loss 0.9979 (0.7942) ce_loss 0.7705 (0.4720) teacher_loss 0.2992 (0.1890) loss_zs_kd 0.2526 (0.1750) loss_oracle 0.5724 (0.5177) acc 68.7500 (81.5625) kd_loss 1.0393 (0.9971) lr 4.6417e-04 eta 0:03:34
epoch [36/50] batch [60/162] time 0.087 (0.088) data 0.000 (0.006) loss 0.7055 (0.7935) ce_loss 0.3037 (0.4665) teacher_loss 0.1355 (0.1986) loss_zs_kd 0.1358 (0.1718) loss_oracle 0.5022 (0.5090) acc 90.6250 (82.5521) kd_loss 0.9988 (0.9916) lr 4.6417e-04 eta 0:03:28
epoch [36/50] batch [80/162] time 0.079 (0.087) data 0.000 (0.004) loss 0.7261 (0.7932) ce_loss 0.4492 (0.4680) teacher_loss 0.1085 (0.2026) loss_zs_kd 0.2220 (0.1707) loss_oracle 0.5066 (0.5052) acc 84.3750 (82.7734) kd_loss 0.9895 (0.9898) lr 4.6417e-04 eta 0:03:24
epoch [36/50] batch [100/162] time 0.083 (0.087) data 0.000 (0.004) loss 0.7809 (0.7801) ce_loss 0.5034 (0.4556) teacher_loss 0.2592 (0.1989) loss_zs_kd 0.1296 (0.1687) loss_oracle 0.4569 (0.4968) acc 81.2500 (83.3750) kd_loss 0.9589 (0.9861) lr 4.6417e-04 eta 0:03:21
epoch [36/50] batch [120/162] time 0.088 (0.086) data 0.000 (0.003) loss 0.7983 (0.7884) ce_loss 0.5259 (0.4697) teacher_loss 0.2711 (0.2105) loss_zs_kd 0.1350 (0.1667) loss_oracle 0.4597 (0.4945) acc 87.5000 (82.9427) kd_loss 0.9351 (0.9838) lr 4.6417e-04 eta 0:03:19
epoch [36/50] batch [140/162] time 0.088 (0.087) data 0.001 (0.003) loss 0.7892 (0.7894) ce_loss 0.5537 (0.4712) teacher_loss 0.2414 (0.2116) loss_zs_kd 0.2226 (0.1689) loss_oracle 0.4364 (0.4933) acc 78.1250 (82.7679) kd_loss 0.9536 (0.9830) lr 4.6417e-04 eta 0:03:18
epoch [36/50] batch [160/162] time 0.068 (0.085) data 0.000 (0.002) loss 0.9517 (0.7897) ce_loss 0.4988 (0.4768) teacher_loss 0.2548 (0.2120) loss_zs_kd 0.2083 (0.1691) loss_oracle 0.5928 (0.4931) acc 78.1250 (82.5000) kd_loss 0.9991 (0.9807) lr 4.6417e-04 eta 0:03:14
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,939
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,659
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 75.9%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [37/50] batch [20/162] time 0.080 (0.096) data 0.000 (0.016) loss 0.7788 (0.8570) ce_loss 0.4644 (0.5181) teacher_loss 0.2014 (0.2421) loss_zs_kd 0.2330 (0.1707) loss_oracle 0.4609 (0.5295) acc 81.2500 (80.7812) kd_loss 0.9499 (0.9962) lr 4.1221e-04 eta 0:03:35
epoch [37/50] batch [40/162] time 0.066 (0.084) data 0.000 (0.008) loss 1.0230 (0.8335) ce_loss 0.6660 (0.5193) teacher_loss 0.3657 (0.2375) loss_zs_kd 0.2233 (0.1765) loss_oracle 0.5457 (0.5078) acc 75.0000 (80.3906) kd_loss 0.9656 (0.9708) lr 4.1221e-04 eta 0:03:07
epoch [37/50] batch [60/162] time 0.070 (0.081) data 0.001 (0.006) loss 0.6891 (0.8185) ce_loss 0.3760 (0.4971) teacher_loss 0.2109 (0.2207) loss_zs_kd 0.1587 (0.1779) loss_oracle 0.3988 (0.5088) acc 90.6250 (81.6667) kd_loss 0.9444 (0.9729) lr 4.1221e-04 eta 0:02:57
epoch [37/50] batch [80/162] time 0.066 (0.078) data 0.000 (0.004) loss 0.8520 (0.8082) ce_loss 0.4768 (0.4833) teacher_loss 0.2841 (0.2194) loss_zs_kd 0.1435 (0.1734) loss_oracle 0.4962 (0.5021) acc 81.2500 (82.0703) kd_loss 0.9943 (0.9720) lr 4.1221e-04 eta 0:02:50
epoch [37/50] batch [100/162] time 0.072 (0.078) data 0.000 (0.004) loss 0.8603 (0.8008) ce_loss 0.5913 (0.4800) teacher_loss 0.3183 (0.2199) loss_zs_kd 0.1780 (0.1715) loss_oracle 0.4530 (0.4951) acc 75.0000 (82.0625) kd_loss 0.9393 (0.9682) lr 4.1221e-04 eta 0:02:50
epoch [37/50] batch [120/162] time 0.073 (0.079) data 0.000 (0.003) loss 0.9657 (0.8018) ce_loss 0.6416 (0.4869) teacher_loss 0.4295 (0.2223) loss_zs_kd 0.1841 (0.1735) loss_oracle 0.4441 (0.4927) acc 81.2500 (81.8490) kd_loss 0.9678 (0.9651) lr 4.1221e-04 eta 0:02:50
epoch [37/50] batch [140/162] time 0.086 (0.080) data 0.000 (0.003) loss 0.8093 (0.7923) ce_loss 0.4839 (0.4810) teacher_loss 0.2330 (0.2164) loss_zs_kd 0.1350 (0.1719) loss_oracle 0.5088 (0.4900) acc 87.5000 (82.1429) kd_loss 0.9901 (0.9635) lr 4.1221e-04 eta 0:02:49
epoch [37/50] batch [160/162] time 0.073 (0.080) data 0.000 (0.002) loss 0.6643 (0.7878) ce_loss 0.3770 (0.4787) teacher_loss 0.1371 (0.2156) loss_zs_kd 0.1698 (0.1721) loss_oracle 0.4423 (0.4861) acc 90.6250 (82.4023) kd_loss 0.9499 (0.9600) lr 4.1221e-04 eta 0:02:47
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,946
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,646
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 75.3%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [38/50] batch [20/162] time 0.082 (0.081) data 0.000 (0.011) loss 0.7924 (0.8043) ce_loss 0.4419 (0.5129) teacher_loss 0.1723 (0.2268) loss_zs_kd 0.1506 (0.1845) loss_oracle 0.5448 (0.4852) acc 84.3750 (80.3125) kd_loss 1.0086 (0.9512) lr 3.6258e-04 eta 0:02:49
epoch [38/50] batch [40/162] time 0.067 (0.076) data 0.000 (0.006) loss 0.7770 (0.8002) ce_loss 0.4617 (0.4979) teacher_loss 0.2449 (0.2294) loss_zs_kd 0.0929 (0.1669) loss_oracle 0.4857 (0.4873) acc 87.5000 (81.6406) kd_loss 0.9336 (0.9585) lr 3.6258e-04 eta 0:02:36
epoch [38/50] batch [60/162] time 0.083 (0.076) data 0.001 (0.004) loss 0.7228 (0.7960) ce_loss 0.4189 (0.5059) teacher_loss 0.1659 (0.2349) loss_zs_kd 0.1938 (0.1649) loss_oracle 0.4600 (0.4786) acc 84.3750 (81.3021) kd_loss 0.9179 (0.9510) lr 3.6258e-04 eta 0:02:34
epoch [38/50] batch [80/162] time 0.072 (0.075) data 0.000 (0.003) loss 0.7706 (0.7889) ce_loss 0.3386 (0.4878) teacher_loss 0.1581 (0.2281) loss_zs_kd 0.1591 (0.1653) loss_oracle 0.5329 (0.4781) acc 90.6250 (82.0703) kd_loss 0.9965 (0.9500) lr 3.6258e-04 eta 0:02:32
epoch [38/50] batch [100/162] time 0.077 (0.075) data 0.000 (0.003) loss 0.7813 (0.7896) ce_loss 0.3030 (0.4857) teacher_loss 0.1485 (0.2282) loss_zs_kd 0.1547 (0.1652) loss_oracle 0.5554 (0.4788) acc 96.8750 (82.0000) kd_loss 1.0070 (0.9489) lr 3.6258e-04 eta 0:02:30
epoch [38/50] batch [120/162] time 0.083 (0.075) data 0.000 (0.002) loss 0.8987 (0.7858) ce_loss 0.6147 (0.4821) teacher_loss 0.2829 (0.2239) loss_zs_kd 0.2161 (0.1638) loss_oracle 0.5078 (0.4800) acc 78.1250 (82.2917) kd_loss 0.9515 (0.9499) lr 3.6258e-04 eta 0:02:28
epoch [38/50] batch [140/162] time 0.086 (0.076) data 0.000 (0.002) loss 0.6302 (0.7836) ce_loss 0.3838 (0.4811) teacher_loss 0.1213 (0.2236) loss_zs_kd 0.1792 (0.1645) loss_oracle 0.4192 (0.4778) acc 87.5000 (82.5000) kd_loss 0.9133 (0.9495) lr 3.6258e-04 eta 0:02:28
epoch [38/50] batch [160/162] time 0.071 (0.076) data 0.000 (0.002) loss 0.9641 (0.7841) ce_loss 0.5776 (0.4831) teacher_loss 0.4019 (0.2236) loss_zs_kd 0.1829 (0.1653) loss_oracle 0.4708 (0.4779) acc 71.8750 (82.2852) kd_loss 0.9823 (0.9499) lr 3.6258e-04 eta 0:02:27
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,944
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,643
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 75.6%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [39/50] batch [20/162] time 0.093 (0.112) data 0.001 (0.018) loss 0.7768 (0.7735) ce_loss 0.4683 (0.4618) teacher_loss 0.1976 (0.2061) loss_zs_kd 0.2137 (0.1765) loss_oracle 0.4723 (0.4792) acc 84.3750 (82.0312) kd_loss 1.0141 (0.9501) lr 3.1545e-04 eta 0:03:35
epoch [39/50] batch [40/162] time 0.078 (0.097) data 0.000 (0.009) loss 0.9851 (0.7936) ce_loss 0.7402 (0.4749) teacher_loss 0.3210 (0.2209) loss_zs_kd 0.1968 (0.1732) loss_oracle 0.5657 (0.4861) acc 65.6250 (81.9531) kd_loss 1.0241 (0.9554) lr 3.1545e-04 eta 0:03:05
epoch [39/50] batch [60/162] time 0.085 (0.093) data 0.000 (0.006) loss 0.6708 (0.7923) ce_loss 0.4346 (0.4760) teacher_loss 0.1896 (0.2238) loss_zs_kd 0.1469 (0.1662) loss_oracle 0.4077 (0.4854) acc 84.3750 (82.0833) kd_loss 0.9350 (0.9557) lr 3.1545e-04 eta 0:02:55
epoch [39/50] batch [80/162] time 0.081 (0.091) data 0.000 (0.005) loss 0.9329 (0.7912) ce_loss 0.7783 (0.4861) teacher_loss 0.3251 (0.2265) loss_zs_kd 0.1527 (0.1631) loss_oracle 0.5314 (0.4831) acc 68.7500 (81.9922) kd_loss 0.9323 (0.9555) lr 3.1545e-04 eta 0:02:49
epoch [39/50] batch [100/162] time 0.083 (0.089) data 0.000 (0.004) loss 0.8722 (0.7903) ce_loss 0.6533 (0.4875) teacher_loss 0.2623 (0.2257) loss_zs_kd 0.1814 (0.1651) loss_oracle 0.5192 (0.4820) acc 75.0000 (81.7188) kd_loss 0.9358 (0.9561) lr 3.1545e-04 eta 0:02:44
epoch [39/50] batch [120/162] time 0.081 (0.089) data 0.000 (0.003) loss 0.9613 (0.7853) ce_loss 0.6704 (0.4817) teacher_loss 0.2785 (0.2212) loss_zs_kd 0.1561 (0.1653) loss_oracle 0.6047 (0.4815) acc 75.0000 (82.0312) kd_loss 1.0669 (0.9561) lr 3.1545e-04 eta 0:02:41
epoch [39/50] batch [140/162] time 0.086 (0.088) data 0.000 (0.003) loss 0.7403 (0.7827) ce_loss 0.6089 (0.4753) teacher_loss 0.2273 (0.2193) loss_zs_kd 0.1995 (0.1653) loss_oracle 0.4132 (0.4807) acc 84.3750 (82.3214) kd_loss 0.9145 (0.9536) lr 3.1545e-04 eta 0:02:39
epoch [39/50] batch [160/162] time 0.074 (0.087) data 0.000 (0.002) loss 0.7930 (0.7850) ce_loss 0.5483 (0.4802) teacher_loss 0.1838 (0.2217) loss_zs_kd 0.1767 (0.1646) loss_oracle 0.5208 (0.4809) acc 84.3750 (82.3242) kd_loss 0.9413 (0.9539) lr 3.1545e-04 eta 0:02:34
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,941
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,647
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 75.3%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [40/50] batch [20/162] time 0.075 (0.103) data 0.000 (0.018) loss 0.6578 (0.7806) ce_loss 0.3530 (0.4819) teacher_loss 0.1677 (0.2315) loss_zs_kd 0.1460 (0.1574) loss_oracle 0.4171 (0.4704) acc 81.2500 (82.5000) kd_loss 0.9615 (0.9385) lr 2.7103e-04 eta 0:03:00
epoch [40/50] batch [40/162] time 0.079 (0.094) data 0.000 (0.009) loss 0.8120 (0.7802) ce_loss 0.5327 (0.4860) teacher_loss 0.2330 (0.2248) loss_zs_kd 0.1740 (0.1649) loss_oracle 0.4920 (0.4730) acc 75.0000 (81.9531) kd_loss 0.9148 (0.9568) lr 2.7103e-04 eta 0:02:43
epoch [40/50] batch [60/162] time 0.095 (0.091) data 0.001 (0.006) loss 0.8294 (0.7922) ce_loss 0.5068 (0.4868) teacher_loss 0.2268 (0.2336) loss_zs_kd 0.1525 (0.1655) loss_oracle 0.5264 (0.4759) acc 78.1250 (82.5521) kd_loss 1.0476 (0.9553) lr 2.7103e-04 eta 0:02:37
epoch [40/50] batch [80/162] time 0.081 (0.090) data 0.000 (0.005) loss 0.7511 (0.7976) ce_loss 0.4985 (0.5002) teacher_loss 0.1915 (0.2331) loss_zs_kd 0.1672 (0.1688) loss_oracle 0.4760 (0.4801) acc 78.1250 (82.1875) kd_loss 0.9208 (0.9555) lr 2.7103e-04 eta 0:02:32
epoch [40/50] batch [100/162] time 0.096 (0.089) data 0.001 (0.004) loss 0.6268 (0.7904) ce_loss 0.2537 (0.4881) teacher_loss 0.1599 (0.2290) loss_zs_kd 0.1320 (0.1674) loss_oracle 0.4008 (0.4778) acc 96.8750 (82.5625) kd_loss 0.8782 (0.9537) lr 2.7103e-04 eta 0:02:30
epoch [40/50] batch [120/162] time 0.096 (0.089) data 0.000 (0.003) loss 0.7996 (0.7878) ce_loss 0.5933 (0.4905) teacher_loss 0.3224 (0.2292) loss_zs_kd 0.1507 (0.1655) loss_oracle 0.4018 (0.4758) acc 75.0000 (82.3698) kd_loss 0.9790 (0.9514) lr 2.7103e-04 eta 0:02:27
epoch [40/50] batch [140/162] time 0.079 (0.088) data 0.000 (0.003) loss 0.7823 (0.7869) ce_loss 0.3452 (0.4903) teacher_loss 0.1014 (0.2266) loss_zs_kd 0.1641 (0.1661) loss_oracle 0.5988 (0.4773) acc 87.5000 (82.4777) kd_loss 0.9962 (0.9510) lr 2.7103e-04 eta 0:02:25
epoch [40/50] batch [160/162] time 0.072 (0.087) data 0.000 (0.003) loss 0.6222 (0.7796) ce_loss 0.2280 (0.4843) teacher_loss 0.1767 (0.2229) loss_zs_kd 0.1330 (0.1658) loss_oracle 0.3790 (0.4738) acc 93.7500 (82.7148) kd_loss 0.9456 (0.9473) lr 2.7103e-04 eta 0:02:20
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,939
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,649
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 75.7%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [41/50] batch [20/162] time 0.084 (0.107) data 0.000 (0.015) loss 0.8446 (0.7656) ce_loss 0.6338 (0.4591) teacher_loss 0.2372 (0.2112) loss_zs_kd 0.1764 (0.1630) loss_oracle 0.5192 (0.4728) acc 75.0000 (81.8750) kd_loss 1.0171 (0.9499) lr 2.2949e-04 eta 0:02:51
epoch [41/50] batch [40/162] time 0.077 (0.094) data 0.000 (0.008) loss 0.8091 (0.7829) ce_loss 0.4470 (0.4787) teacher_loss 0.2624 (0.2295) loss_zs_kd 0.1921 (0.1645) loss_oracle 0.4507 (0.4711) acc 75.0000 (81.7969) kd_loss 0.8810 (0.9428) lr 2.2949e-04 eta 0:02:27
epoch [41/50] batch [60/162] time 0.086 (0.090) data 0.000 (0.005) loss 1.1553 (0.7858) ce_loss 1.0439 (0.4902) teacher_loss 0.5399 (0.2290) loss_zs_kd 0.2090 (0.1645) loss_oracle 0.5109 (0.4746) acc 68.7500 (81.6667) kd_loss 0.9130 (0.9436) lr 2.2949e-04 eta 0:02:20
epoch [41/50] batch [80/162] time 0.070 (0.089) data 0.000 (0.004) loss 0.7928 (0.7773) ce_loss 0.5762 (0.4778) teacher_loss 0.2748 (0.2158) loss_zs_kd 0.1371 (0.1668) loss_oracle 0.4494 (0.4781) acc 81.2500 (82.5781) kd_loss 0.9476 (0.9492) lr 2.2949e-04 eta 0:02:17
epoch [41/50] batch [100/162] time 0.082 (0.089) data 0.000 (0.003) loss 0.6400 (0.7809) ce_loss 0.4133 (0.4783) teacher_loss 0.1970 (0.2146) loss_zs_kd 0.1256 (0.1693) loss_oracle 0.3801 (0.4816) acc 87.5000 (82.7188) kd_loss 0.8847 (0.9501) lr 2.2949e-04 eta 0:02:14
epoch [41/50] batch [120/162] time 0.074 (0.087) data 0.000 (0.003) loss 0.8205 (0.7849) ce_loss 0.5366 (0.4814) teacher_loss 0.1426 (0.2149) loss_zs_kd 0.2336 (0.1710) loss_oracle 0.5611 (0.4845) acc 78.1250 (82.5521) kd_loss 0.9605 (0.9492) lr 2.2949e-04 eta 0:02:11
epoch [41/50] batch [140/162] time 0.081 (0.087) data 0.000 (0.002) loss 0.8288 (0.7815) ce_loss 0.5835 (0.4784) teacher_loss 0.3143 (0.2172) loss_zs_kd 0.1159 (0.1700) loss_oracle 0.4565 (0.4793) acc 81.2500 (82.4777) kd_loss 0.9432 (0.9448) lr 2.2949e-04 eta 0:02:08
epoch [41/50] batch [160/162] time 0.075 (0.085) data 0.000 (0.002) loss 0.7074 (0.7817) ce_loss 0.3174 (0.4784) teacher_loss 0.1408 (0.2199) loss_zs_kd 0.1477 (0.1669) loss_oracle 0.4927 (0.4783) acc 93.7500 (82.5391) kd_loss 0.9998 (0.9455) lr 2.2949e-04 eta 0:02:04
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,940
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,653
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 75.2%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [42/50] batch [20/162] time 0.089 (0.096) data 0.001 (0.013) loss 0.9317 (0.7669) ce_loss 0.6611 (0.4694) teacher_loss 0.3115 (0.2103) loss_zs_kd 0.1906 (0.1591) loss_oracle 0.5249 (0.4771) acc 78.1250 (81.5625) kd_loss 0.9820 (0.9424) lr 1.9098e-04 eta 0:02:18
epoch [42/50] batch [40/162] time 0.081 (0.090) data 0.000 (0.006) loss 0.7768 (0.7693) ce_loss 0.5005 (0.4446) teacher_loss 0.2728 (0.1991) loss_zs_kd 0.1320 (0.1615) loss_oracle 0.4380 (0.4894) acc 81.2500 (82.8125) kd_loss 0.9113 (0.9503) lr 1.9098e-04 eta 0:02:07
epoch [42/50] batch [60/162] time 0.082 (0.088) data 0.001 (0.004) loss 0.7345 (0.7703) ce_loss 0.3496 (0.4604) teacher_loss 0.1412 (0.2012) loss_zs_kd 0.2044 (0.1649) loss_oracle 0.4911 (0.4867) acc 81.2500 (82.1354) kd_loss 0.9398 (0.9542) lr 1.9098e-04 eta 0:02:02
epoch [42/50] batch [80/162] time 0.087 (0.087) data 0.000 (0.003) loss 0.8829 (0.7690) ce_loss 0.5845 (0.4699) teacher_loss 0.2733 (0.2041) loss_zs_kd 0.1380 (0.1655) loss_oracle 0.5405 (0.4822) acc 81.2500 (82.0312) kd_loss 1.0047 (0.9526) lr 1.9098e-04 eta 0:02:00
epoch [42/50] batch [100/162] time 0.088 (0.087) data 0.000 (0.003) loss 0.8631 (0.7693) ce_loss 0.6470 (0.4651) teacher_loss 0.2563 (0.2008) loss_zs_kd 0.1962 (0.1660) loss_oracle 0.5087 (0.4855) acc 65.6250 (82.1250) kd_loss 0.9375 (0.9538) lr 1.9098e-04 eta 0:01:57
epoch [42/50] batch [120/162] time 0.077 (0.086) data 0.000 (0.002) loss 0.9095 (0.7717) ce_loss 0.5371 (0.4683) teacher_loss 0.3001 (0.2037) loss_zs_kd 0.1754 (0.1673) loss_oracle 0.5218 (0.4843) acc 81.2500 (81.9792) kd_loss 1.0419 (0.9549) lr 1.9098e-04 eta 0:01:54
epoch [42/50] batch [140/162] time 0.083 (0.085) data 0.000 (0.002) loss 0.9991 (0.7722) ce_loss 0.5186 (0.4673) teacher_loss 0.3186 (0.2031) loss_zs_kd 0.2042 (0.1687) loss_oracle 0.5785 (0.4848) acc 78.1250 (82.2321) kd_loss 1.0318 (0.9549) lr 1.9098e-04 eta 0:01:52
epoch [42/50] batch [160/162] time 0.075 (0.084) data 0.000 (0.002) loss 0.7695 (0.7814) ce_loss 0.3459 (0.4752) teacher_loss 0.0991 (0.2073) loss_zs_kd 0.2255 (0.1706) loss_oracle 0.5577 (0.4888) acc 87.5000 (82.1094) kd_loss 0.9565 (0.9571) lr 1.9098e-04 eta 0:01:49
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,941
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,655
* accuracy: 80.9%
* error: 19.1%
* macro_f1: 75.2%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [43/50] batch [20/162] time 0.089 (0.099) data 0.000 (0.013) loss 0.7384 (0.7899) ce_loss 0.4163 (0.4666) teacher_loss 0.1483 (0.2190) loss_zs_kd 0.1699 (0.1698) loss_oracle 0.5052 (0.4860) acc 90.6250 (83.7500) kd_loss 0.9739 (0.9639) lr 1.5567e-04 eta 0:02:05
epoch [43/50] batch [40/162] time 0.087 (0.092) data 0.000 (0.007) loss 0.7897 (0.7983) ce_loss 0.5254 (0.4865) teacher_loss 0.2398 (0.2197) loss_zs_kd 0.1457 (0.1700) loss_oracle 0.4770 (0.4935) acc 81.2500 (82.3438) kd_loss 0.9822 (0.9712) lr 1.5567e-04 eta 0:01:55
epoch [43/50] batch [60/162] time 0.091 (0.090) data 0.001 (0.004) loss 1.1008 (0.7864) ce_loss 0.8237 (0.4739) teacher_loss 0.4445 (0.2108) loss_zs_kd 0.2077 (0.1702) loss_oracle 0.5525 (0.4905) acc 68.7500 (82.5521) kd_loss 0.9905 (0.9651) lr 1.5567e-04 eta 0:01:50
epoch [43/50] batch [80/162] time 0.079 (0.088) data 0.000 (0.003) loss 0.7374 (0.7791) ce_loss 0.5894 (0.4641) teacher_loss 0.2096 (0.2061) loss_zs_kd 0.1544 (0.1663) loss_oracle 0.4506 (0.4898) acc 81.2500 (82.5781) kd_loss 0.9956 (0.9643) lr 1.5567e-04 eta 0:01:47
epoch [43/50] batch [100/162] time 0.081 (0.086) data 0.000 (0.003) loss 0.8264 (0.7753) ce_loss 0.3105 (0.4634) teacher_loss 0.1600 (0.2046) loss_zs_kd 0.1432 (0.1649) loss_oracle 0.5948 (0.4882) acc 96.8750 (82.8750) kd_loss 0.9847 (0.9610) lr 1.5567e-04 eta 0:01:43
epoch [43/50] batch [120/162] time 0.081 (0.086) data 0.000 (0.002) loss 0.8109 (0.7804) ce_loss 0.6631 (0.4707) teacher_loss 0.2887 (0.2086) loss_zs_kd 0.1951 (0.1668) loss_oracle 0.4247 (0.4884) acc 75.0000 (82.8385) kd_loss 0.8885 (0.9611) lr 1.5567e-04 eta 0:01:41
epoch [43/50] batch [140/162] time 0.084 (0.087) data 0.000 (0.002) loss 0.8235 (0.7776) ce_loss 0.5425 (0.4649) teacher_loss 0.2031 (0.2050) loss_zs_kd 0.1615 (0.1678) loss_oracle 0.5397 (0.4887) acc 81.2500 (83.1473) kd_loss 0.9301 (0.9592) lr 1.5567e-04 eta 0:01:40
epoch [43/50] batch [160/162] time 0.074 (0.086) data 0.000 (0.002) loss 0.7020 (0.7748) ce_loss 0.3596 (0.4634) teacher_loss 0.1177 (0.2042) loss_zs_kd 0.1889 (0.1690) loss_oracle 0.4898 (0.4861) acc 84.3750 (83.2227) kd_loss 0.9820 (0.9592) lr 1.5567e-04 eta 0:01:37
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,945
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,653
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 74.9%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [44/50] batch [20/162] time 0.093 (0.100) data 0.000 (0.013) loss 0.8736 (0.7694) ce_loss 0.4678 (0.4274) teacher_loss 0.2858 (0.1874) loss_zs_kd 0.1877 (0.1671) loss_oracle 0.4940 (0.4985) acc 84.3750 (84.3750) kd_loss 0.9726 (0.9726) lr 1.2369e-04 eta 0:01:51
epoch [44/50] batch [40/162] time 0.081 (0.091) data 0.000 (0.007) loss 0.7877 (0.7650) ce_loss 0.3447 (0.4345) teacher_loss 0.1801 (0.1882) loss_zs_kd 0.1436 (0.1666) loss_oracle 0.5358 (0.4935) acc 84.3750 (84.0625) kd_loss 0.9857 (0.9689) lr 1.2369e-04 eta 0:01:39
epoch [44/50] batch [60/162] time 0.082 (0.089) data 0.001 (0.004) loss 0.7441 (0.7821) ce_loss 0.4170 (0.4638) teacher_loss 0.1409 (0.2069) loss_zs_kd 0.1760 (0.1655) loss_oracle 0.5152 (0.4924) acc 81.2500 (83.3333) kd_loss 0.9615 (0.9640) lr 1.2369e-04 eta 0:01:35
epoch [44/50] batch [80/162] time 0.082 (0.088) data 0.000 (0.003) loss 0.7553 (0.7866) ce_loss 0.4380 (0.4751) teacher_loss 0.1607 (0.2122) loss_zs_kd 0.1643 (0.1668) loss_oracle 0.5125 (0.4910) acc 87.5000 (83.0859) kd_loss 0.9667 (0.9660) lr 1.2369e-04 eta 0:01:33
epoch [44/50] batch [100/162] time 0.088 (0.087) data 0.000 (0.003) loss 0.7791 (0.7800) ce_loss 0.5532 (0.4658) teacher_loss 0.1828 (0.2068) loss_zs_kd 0.1555 (0.1656) loss_oracle 0.5185 (0.4904) acc 78.1250 (83.3750) kd_loss 0.9404 (0.9649) lr 1.2369e-04 eta 0:01:30
epoch [44/50] batch [120/162] time 0.086 (0.088) data 0.000 (0.002) loss 0.7208 (0.7816) ce_loss 0.4875 (0.4646) teacher_loss 0.2134 (0.2088) loss_zs_kd 0.1685 (0.1653) loss_oracle 0.4231 (0.4902) acc 84.3750 (83.6719) kd_loss 0.9368 (0.9668) lr 1.2369e-04 eta 0:01:28
epoch [44/50] batch [140/162] time 0.084 (0.087) data 0.000 (0.002) loss 0.7547 (0.7839) ce_loss 0.5342 (0.4772) teacher_loss 0.2135 (0.2148) loss_zs_kd 0.1644 (0.1658) loss_oracle 0.4590 (0.4862) acc 84.3750 (83.1027) kd_loss 0.9398 (0.9644) lr 1.2369e-04 eta 0:01:26
epoch [44/50] batch [160/162] time 0.077 (0.086) data 0.000 (0.002) loss 0.9121 (0.7851) ce_loss 0.8262 (0.4772) teacher_loss 0.3867 (0.2164) loss_zs_kd 0.1784 (0.1660) loss_oracle 0.4362 (0.4857) acc 56.2500 (82.9492) kd_loss 0.8896 (0.9630) lr 1.2369e-04 eta 0:01:24
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,944
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,653
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 75.2%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [45/50] batch [20/162] time 0.092 (0.101) data 0.000 (0.015) loss 0.9236 (0.7656) ce_loss 0.7119 (0.4890) teacher_loss 0.3932 (0.2074) loss_zs_kd 0.1723 (0.1703) loss_oracle 0.4442 (0.4731) acc 75.0000 (81.7188) kd_loss 0.8757 (0.9348) lr 9.5173e-05 eta 0:01:36
epoch [45/50] batch [40/162] time 0.079 (0.091) data 0.000 (0.008) loss 0.8588 (0.7899) ce_loss 0.4373 (0.4913) teacher_loss 0.3837 (0.2250) loss_zs_kd 0.1100 (0.1648) loss_oracle 0.4201 (0.4825) acc 90.6250 (81.4062) kd_loss 0.9413 (0.9440) lr 9.5173e-05 eta 0:01:25
epoch [45/50] batch [60/162] time 0.083 (0.089) data 0.001 (0.005) loss 0.6142 (0.7743) ce_loss 0.1851 (0.4694) teacher_loss 0.0472 (0.2058) loss_zs_kd 0.1348 (0.1665) loss_oracle 0.4997 (0.4852) acc 93.7500 (82.2396) kd_loss 0.9575 (0.9497) lr 9.5173e-05 eta 0:01:21
epoch [45/50] batch [80/162] time 0.075 (0.087) data 0.000 (0.004) loss 0.6357 (0.7679) ce_loss 0.3330 (0.4590) teacher_loss 0.1240 (0.2025) loss_zs_kd 0.1141 (0.1657) loss_oracle 0.4547 (0.4826) acc 84.3750 (82.7344) kd_loss 0.9866 (0.9526) lr 9.5173e-05 eta 0:01:17
epoch [45/50] batch [100/162] time 0.079 (0.087) data 0.000 (0.003) loss 0.6808 (0.7641) ce_loss 0.3569 (0.4569) teacher_loss 0.1540 (0.2041) loss_zs_kd 0.1663 (0.1648) loss_oracle 0.4437 (0.4776) acc 90.6250 (82.8750) kd_loss 0.9418 (0.9523) lr 9.5173e-05 eta 0:01:15
epoch [45/50] batch [120/162] time 0.081 (0.086) data 0.000 (0.003) loss 0.6371 (0.7697) ce_loss 0.4014 (0.4612) teacher_loss 0.1139 (0.2093) loss_zs_kd 0.1500 (0.1644) loss_oracle 0.4482 (0.4783) acc 87.5000 (83.1250) kd_loss 0.8627 (0.9513) lr 9.5173e-05 eta 0:01:13
epoch [45/50] batch [140/162] time 0.096 (0.086) data 0.000 (0.002) loss 0.6406 (0.7727) ce_loss 0.3103 (0.4632) teacher_loss 0.1524 (0.2109) loss_zs_kd 0.1607 (0.1647) loss_oracle 0.4079 (0.4795) acc 90.6250 (83.0804) kd_loss 0.9581 (0.9515) lr 9.5173e-05 eta 0:01:11
epoch [45/50] batch [160/162] time 0.073 (0.086) data 0.000 (0.002) loss 0.9751 (0.7759) ce_loss 0.6421 (0.4662) teacher_loss 0.2476 (0.2129) loss_zs_kd 0.1692 (0.1646) loss_oracle 0.6429 (0.4807) acc 81.2500 (82.9688) kd_loss 1.0344 (0.9509) lr 9.5173e-05 eta 0:01:09
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,945
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,661
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 75.3%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [46/50] batch [20/162] time 0.079 (0.097) data 0.000 (0.013) loss 0.8055 (0.8115) ce_loss 0.4666 (0.5162) teacher_loss 0.2028 (0.2480) loss_zs_kd 0.1330 (0.1589) loss_oracle 0.5363 (0.4841) acc 81.2500 (81.2500) kd_loss 1.0104 (0.9393) lr 7.0224e-05 eta 0:01:16
epoch [46/50] batch [40/162] time 0.087 (0.092) data 0.000 (0.007) loss 0.8599 (0.7985) ce_loss 0.5986 (0.4975) teacher_loss 0.2804 (0.2405) loss_zs_kd 0.1727 (0.1626) loss_oracle 0.4931 (0.4766) acc 81.2500 (82.1875) kd_loss 0.9351 (0.9365) lr 7.0224e-05 eta 0:01:11
epoch [46/50] batch [60/162] time 0.087 (0.091) data 0.001 (0.005) loss 0.7967 (0.7879) ce_loss 0.4019 (0.4860) teacher_loss 0.1844 (0.2283) loss_zs_kd 0.1469 (0.1666) loss_oracle 0.5388 (0.4763) acc 84.3750 (82.3958) kd_loss 1.0186 (0.9394) lr 7.0224e-05 eta 0:01:08
epoch [46/50] batch [80/162] time 0.079 (0.089) data 0.000 (0.004) loss 0.7501 (0.7774) ce_loss 0.4460 (0.4693) teacher_loss 0.1781 (0.2173) loss_zs_kd 0.1400 (0.1654) loss_oracle 0.5020 (0.4773) acc 87.5000 (83.2812) kd_loss 1.0354 (0.9421) lr 7.0224e-05 eta 0:01:05
epoch [46/50] batch [100/162] time 0.085 (0.089) data 0.000 (0.003) loss 0.8770 (0.7692) ce_loss 0.5278 (0.4666) teacher_loss 0.2338 (0.2151) loss_zs_kd 0.2012 (0.1629) loss_oracle 0.5426 (0.4727) acc 75.0000 (83.0938) kd_loss 0.9251 (0.9395) lr 7.0224e-05 eta 0:01:02
epoch [46/50] batch [120/162] time 0.089 (0.088) data 0.001 (0.002) loss 0.6398 (0.7793) ce_loss 0.4321 (0.4769) teacher_loss 0.1440 (0.2223) loss_zs_kd 0.1567 (0.1630) loss_oracle 0.4175 (0.4754) acc 87.5000 (82.7604) kd_loss 0.9592 (0.9415) lr 7.0224e-05 eta 0:01:00
epoch [46/50] batch [140/162] time 0.094 (0.088) data 0.000 (0.002) loss 0.7518 (0.7824) ce_loss 0.4995 (0.4751) teacher_loss 0.2712 (0.2222) loss_zs_kd 0.1380 (0.1635) loss_oracle 0.4116 (0.4784) acc 78.1250 (82.7902) kd_loss 0.9006 (0.9415) lr 7.0224e-05 eta 0:00:58
epoch [46/50] batch [160/162] time 0.076 (0.086) data 0.000 (0.002) loss 0.7687 (0.7837) ce_loss 0.5181 (0.4758) teacher_loss 0.2144 (0.2221) loss_zs_kd 0.1575 (0.1620) loss_oracle 0.4756 (0.4807) acc 75.0000 (82.7539) kd_loss 0.9580 (0.9442) lr 7.0224e-05 eta 0:00:56
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,944
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,660
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 75.9%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [47/50] batch [20/162] time 0.074 (0.099) data 0.000 (0.016) loss 0.6304 (0.7502) ce_loss 0.3818 (0.4453) teacher_loss 0.1346 (0.1965) loss_zs_kd 0.1509 (0.1603) loss_oracle 0.4203 (0.4735) acc 75.0000 (82.0312) kd_loss 0.9324 (0.9481) lr 4.8943e-05 eta 0:01:01
epoch [47/50] batch [40/162] time 0.088 (0.087) data 0.000 (0.008) loss 0.8667 (0.7627) ce_loss 0.6191 (0.4568) teacher_loss 0.3054 (0.1994) loss_zs_kd 0.2091 (0.1620) loss_oracle 0.4568 (0.4823) acc 78.1250 (82.1875) kd_loss 0.9599 (0.9483) lr 4.8943e-05 eta 0:00:52
epoch [47/50] batch [60/162] time 0.078 (0.082) data 0.001 (0.006) loss 1.0726 (0.7877) ce_loss 0.5894 (0.4949) teacher_loss 0.4516 (0.2219) loss_zs_kd 0.1656 (0.1658) loss_oracle 0.5382 (0.4829) acc 87.5000 (81.7188) kd_loss 1.0156 (0.9476) lr 4.8943e-05 eta 0:00:48
epoch [47/50] batch [80/162] time 0.079 (0.081) data 0.000 (0.004) loss 0.7778 (0.7760) ce_loss 0.4553 (0.4799) teacher_loss 0.2073 (0.2138) loss_zs_kd 0.1708 (0.1643) loss_oracle 0.4851 (0.4801) acc 78.1250 (82.3828) kd_loss 0.8949 (0.9491) lr 4.8943e-05 eta 0:00:45
epoch [47/50] batch [100/162] time 0.082 (0.081) data 0.000 (0.003) loss 0.8227 (0.7741) ce_loss 0.5137 (0.4702) teacher_loss 0.1952 (0.2097) loss_zs_kd 0.1838 (0.1637) loss_oracle 0.5356 (0.4825) acc 78.1250 (82.5000) kd_loss 1.0375 (0.9525) lr 4.8943e-05 eta 0:00:44
epoch [47/50] batch [120/162] time 0.079 (0.082) data 0.000 (0.003) loss 0.6931 (0.7750) ce_loss 0.3462 (0.4713) teacher_loss 0.1216 (0.2105) loss_zs_kd 0.1828 (0.1640) loss_oracle 0.4801 (0.4826) acc 90.6250 (82.6042) kd_loss 0.9553 (0.9550) lr 4.8943e-05 eta 0:00:43
epoch [47/50] batch [140/162] time 0.088 (0.082) data 0.000 (0.003) loss 0.8571 (0.7749) ce_loss 0.5952 (0.4727) teacher_loss 0.2569 (0.2109) loss_zs_kd 0.1882 (0.1637) loss_oracle 0.5060 (0.4822) acc 71.8750 (82.5446) kd_loss 0.9823 (0.9542) lr 4.8943e-05 eta 0:00:41
epoch [47/50] batch [160/162] time 0.074 (0.081) data 0.001 (0.002) loss 0.7690 (0.7764) ce_loss 0.4424 (0.4713) teacher_loss 0.2467 (0.2131) loss_zs_kd 0.1422 (0.1631) loss_oracle 0.4512 (0.4817) acc 87.5000 (82.6953) kd_loss 0.8886 (0.9533) lr 4.8943e-05 eta 0:00:39
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,944
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,658
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 75.9%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [48/50] batch [20/162] time 0.083 (0.098) data 0.000 (0.014) loss 0.7631 (0.7698) ce_loss 0.4226 (0.4694) teacher_loss 0.1493 (0.2057) loss_zs_kd 0.1338 (0.1671) loss_oracle 0.5469 (0.4805) acc 84.3750 (82.5000) kd_loss 1.0499 (0.9388) lr 3.1417e-05 eta 0:00:45
epoch [48/50] batch [40/162] time 0.080 (0.090) data 0.000 (0.007) loss 0.8909 (0.7613) ce_loss 0.4458 (0.4442) teacher_loss 0.2830 (0.1980) loss_zs_kd 0.1138 (0.1621) loss_oracle 0.5511 (0.4823) acc 87.5000 (83.1250) kd_loss 0.9692 (0.9510) lr 3.1417e-05 eta 0:00:40
epoch [48/50] batch [60/162] time 0.080 (0.087) data 0.001 (0.005) loss 0.8218 (0.7624) ce_loss 0.5244 (0.4543) teacher_loss 0.3109 (0.2068) loss_zs_kd 0.1766 (0.1602) loss_oracle 0.4226 (0.4755) acc 84.3750 (83.3333) kd_loss 0.8871 (0.9450) lr 3.1417e-05 eta 0:00:36
epoch [48/50] batch [80/162] time 0.090 (0.087) data 0.000 (0.004) loss 0.7946 (0.7642) ce_loss 0.4690 (0.4696) teacher_loss 0.2511 (0.2075) loss_zs_kd 0.1468 (0.1620) loss_oracle 0.4701 (0.4758) acc 81.2500 (82.8125) kd_loss 0.9407 (0.9439) lr 3.1417e-05 eta 0:00:35
epoch [48/50] batch [100/162] time 0.098 (0.086) data 0.001 (0.003) loss 0.9627 (0.7690) ce_loss 0.6440 (0.4737) teacher_loss 0.4180 (0.2115) loss_zs_kd 0.1547 (0.1624) loss_oracle 0.4674 (0.4764) acc 78.1250 (82.7188) kd_loss 0.9691 (0.9427) lr 3.1417e-05 eta 0:00:33
epoch [48/50] batch [120/162] time 0.093 (0.086) data 0.000 (0.003) loss 0.7926 (0.7772) ce_loss 0.3938 (0.4757) teacher_loss 0.1945 (0.2197) loss_zs_kd 0.1547 (0.1638) loss_oracle 0.5208 (0.4756) acc 78.1250 (82.8125) kd_loss 0.9680 (0.9416) lr 3.1417e-05 eta 0:00:31
epoch [48/50] batch [140/162] time 0.086 (0.087) data 0.000 (0.002) loss 0.8246 (0.7756) ce_loss 0.4355 (0.4692) teacher_loss 0.2443 (0.2185) loss_zs_kd 0.1212 (0.1632) loss_oracle 0.5197 (0.4755) acc 81.2500 (83.0357) kd_loss 1.0080 (0.9423) lr 3.1417e-05 eta 0:00:29
epoch [48/50] batch [160/162] time 0.075 (0.085) data 0.000 (0.002) loss 0.6590 (0.7788) ce_loss 0.3052 (0.4750) teacher_loss 0.1175 (0.2197) loss_zs_kd 0.1544 (0.1641) loss_oracle 0.4643 (0.4771) acc 90.6250 (82.8906) kd_loss 0.8829 (0.9426) lr 3.1417e-05 eta 0:00:27
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,945
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,659
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 75.9%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [49/50] batch [20/162] time 0.090 (0.100) data 0.000 (0.017) loss 0.7361 (0.8055) ce_loss 0.2913 (0.5201) teacher_loss 0.1028 (0.2388) loss_zs_kd 0.1822 (0.1696) loss_oracle 0.5422 (0.4819) acc 93.7500 (80.1562) kd_loss 0.9759 (0.9418) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [40/162] time 0.081 (0.092) data 0.000 (0.009) loss 0.7000 (0.7990) ce_loss 0.4734 (0.4961) teacher_loss 0.2273 (0.2247) loss_zs_kd 0.1544 (0.1622) loss_oracle 0.3954 (0.4932) acc 71.8750 (82.1875) kd_loss 0.9620 (0.9518) lr 1.7713e-05 eta 0:00:26
epoch [49/50] batch [60/162] time 0.079 (0.089) data 0.000 (0.006) loss 0.6878 (0.7951) ce_loss 0.4209 (0.4868) teacher_loss 0.1760 (0.2212) loss_zs_kd 0.1482 (0.1632) loss_oracle 0.4377 (0.4923) acc 84.3750 (82.3438) kd_loss 0.9688 (0.9561) lr 1.7713e-05 eta 0:00:23
epoch [49/50] batch [80/162] time 0.091 (0.088) data 0.000 (0.004) loss 0.7592 (0.7974) ce_loss 0.5425 (0.4847) teacher_loss 0.2664 (0.2212) loss_zs_kd 0.1803 (0.1627) loss_oracle 0.4026 (0.4949) acc 87.5000 (82.8516) kd_loss 0.8280 (0.9558) lr 1.7713e-05 eta 0:00:21
epoch [49/50] batch [100/162] time 0.088 (0.088) data 0.000 (0.004) loss 0.9238 (0.7970) ce_loss 0.6011 (0.4792) teacher_loss 0.3345 (0.2198) loss_zs_kd 0.1727 (0.1637) loss_oracle 0.5029 (0.4953) acc 78.1250 (82.9375) kd_loss 1.0010 (0.9576) lr 1.7713e-05 eta 0:00:19
epoch [49/50] batch [120/162] time 0.096 (0.088) data 0.001 (0.003) loss 0.7486 (0.7964) ce_loss 0.4141 (0.4817) teacher_loss 0.1036 (0.2226) loss_zs_kd 0.1801 (0.1644) loss_oracle 0.5549 (0.4916) acc 87.5000 (82.8125) kd_loss 0.9930 (0.9562) lr 1.7713e-05 eta 0:00:17
epoch [49/50] batch [140/162] time 0.079 (0.088) data 0.000 (0.003) loss 0.8582 (0.7912) ce_loss 0.4846 (0.4761) teacher_loss 0.1637 (0.2181) loss_zs_kd 0.1955 (0.1636) loss_oracle 0.5967 (0.4912) acc 84.3750 (82.7679) kd_loss 1.0269 (0.9576) lr 1.7713e-05 eta 0:00:16
epoch [49/50] batch [160/162] time 0.072 (0.086) data 0.000 (0.002) loss 0.8180 (0.7965) ce_loss 0.7231 (0.4823) teacher_loss 0.3087 (0.2234) loss_zs_kd 0.1647 (0.1649) loss_oracle 0.4269 (0.4907) acc 78.1250 (82.7539) kd_loss 0.9207 (0.9581) lr 1.7713e-05 eta 0:00:14
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,945
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,661
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 75.9%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
epoch [50/50] batch [20/162] time 0.084 (0.104) data 0.000 (0.015) loss 0.8016 (0.7592) ce_loss 0.6343 (0.4435) teacher_loss 0.2139 (0.1890) loss_zs_kd 0.1903 (0.1636) loss_oracle 0.4926 (0.4884) acc 71.8750 (84.2188) kd_loss 0.9858 (0.9504) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [40/162] time 0.087 (0.092) data 0.000 (0.007) loss 0.7093 (0.7765) ce_loss 0.5264 (0.4823) teacher_loss 0.1994 (0.2100) loss_zs_kd 0.1393 (0.1651) loss_oracle 0.4402 (0.4839) acc 78.1250 (82.5781) kd_loss 0.9012 (0.9431) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [60/162] time 0.081 (0.089) data 0.000 (0.005) loss 0.6422 (0.7655) ce_loss 0.3342 (0.4591) teacher_loss 0.1696 (0.2026) loss_zs_kd 0.1249 (0.1623) loss_oracle 0.4101 (0.4818) acc 84.3750 (83.4896) kd_loss 0.9453 (0.9493) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [80/162] time 0.091 (0.087) data 0.000 (0.004) loss 0.7898 (0.7679) ce_loss 0.5288 (0.4603) teacher_loss 0.2462 (0.2070) loss_zs_kd 0.1809 (0.1613) loss_oracle 0.4531 (0.4802) acc 87.5000 (83.0469) kd_loss 0.9828 (0.9465) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [100/162] time 0.086 (0.086) data 0.000 (0.003) loss 0.8753 (0.7713) ce_loss 0.6455 (0.4632) teacher_loss 0.3377 (0.2097) loss_zs_kd 0.2489 (0.1638) loss_oracle 0.4131 (0.4798) acc 75.0000 (83.1250) kd_loss 0.8604 (0.9460) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [120/162] time 0.068 (0.084) data 0.000 (0.003) loss 0.7505 (0.7686) ce_loss 0.4109 (0.4625) teacher_loss 0.2331 (0.2086) loss_zs_kd 0.1651 (0.1623) loss_oracle 0.4348 (0.4789) acc 81.2500 (83.2292) kd_loss 0.9201 (0.9463) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [140/162] time 0.069 (0.082) data 0.000 (0.002) loss 1.1284 (0.7749) ce_loss 0.9487 (0.4649) teacher_loss 0.5664 (0.2121) loss_zs_kd 0.1618 (0.1629) loss_oracle 0.4811 (0.4814) acc 75.0000 (83.3036) kd_loss 0.8864 (0.9495) lr 7.8853e-06 eta 0:00:01
epoch [50/50] batch [160/162] time 0.071 (0.081) data 0.000 (0.002) loss 0.8488 (0.7752) ce_loss 0.3938 (0.4651) teacher_loss 0.2649 (0.2123) loss_zs_kd 0.1572 (0.1625) loss_oracle 0.5054 (0.4817) acc 90.6250 (83.3008) kd_loss 0.9327 (0.9498) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,946
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 89.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,659
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 75.9%
******* Domain s best val acc:      87.4%, epoch: 11 *******
******* Domain s best val test acc: 76.5%, epoch: 11 *******
******* Domain s best test acc:     82.0%, epoch: 18 *******
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:15:35

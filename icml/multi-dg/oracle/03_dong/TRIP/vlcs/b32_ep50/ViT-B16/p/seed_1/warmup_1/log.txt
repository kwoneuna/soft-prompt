Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'sun']
Target     ['pascal']
# classes  5
# train_x  5,147
# val      2,206
# test     3,376
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/160] time 0.077 (0.120) data 0.000 (0.019) loss 0.8045 (0.6808) ce_loss 0.8037 (0.6803) teacher_loss 0.8041 (0.6804) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0002 (0.0004) acc 71.8750 (75.3125) kd_loss 0.0008 (0.0013) lr 1.0000e-05 eta 0:15:55
epoch [1/50] batch [40/160] time 0.084 (0.100) data 0.000 (0.010) loss 0.6830 (0.6694) ce_loss 0.6816 (0.6688) teacher_loss 0.6820 (0.6689) loss_zs_kd 0.0012 (0.0004) loss_oracle 0.0004 (0.0003) acc 75.0000 (75.3125) kd_loss 0.0015 (0.0011) lr 1.0000e-05 eta 0:13:15
epoch [1/50] batch [60/160] time 0.082 (0.094) data 0.000 (0.006) loss 0.5400 (0.6975) ce_loss 0.5386 (0.6968) teacher_loss 0.5384 (0.6968) loss_zs_kd 0.0022 (0.0009) loss_oracle 0.0005 (0.0003) acc 78.1250 (74.9479) kd_loss 0.0017 (0.0011) lr 1.0000e-05 eta 0:12:27
epoch [1/50] batch [80/160] time 0.090 (0.091) data 0.000 (0.005) loss 0.9223 (0.7084) ce_loss 0.9199 (0.7074) teacher_loss 0.9205 (0.7074) loss_zs_kd 0.0028 (0.0014) loss_oracle 0.0004 (0.0003) acc 75.0000 (74.1797) kd_loss 0.0013 (0.0011) lr 1.0000e-05 eta 0:11:59
epoch [1/50] batch [100/160] time 0.080 (0.090) data 0.000 (0.004) loss 0.6284 (0.7056) ce_loss 0.6255 (0.7043) teacher_loss 0.6261 (0.7044) loss_zs_kd 0.0039 (0.0019) loss_oracle 0.0005 (0.0003) acc 81.2500 (74.3750) kd_loss 0.0017 (0.0012) lr 1.0000e-05 eta 0:11:49
epoch [1/50] batch [120/160] time 0.084 (0.089) data 0.000 (0.003) loss 0.7181 (0.6962) ce_loss 0.7139 (0.6946) teacher_loss 0.7145 (0.6946) loss_zs_kd 0.0061 (0.0024) loss_oracle 0.0006 (0.0004) acc 71.8750 (74.7135) kd_loss 0.0019 (0.0013) lr 1.0000e-05 eta 0:11:37
epoch [1/50] batch [140/160] time 0.070 (0.086) data 0.000 (0.003) loss 0.5151 (0.6932) ce_loss 0.5112 (0.6912) teacher_loss 0.5115 (0.6912) loss_zs_kd 0.0061 (0.0030) loss_oracle 0.0005 (0.0004) acc 87.5000 (74.7545) kd_loss 0.0016 (0.0014) lr 1.0000e-05 eta 0:11:18
epoch [1/50] batch [160/160] time 0.078 (0.085) data 0.000 (0.003) loss 0.9846 (0.6972) ce_loss 0.9780 (0.6949) teacher_loss 0.9790 (0.6950) loss_zs_kd 0.0105 (0.0036) loss_oracle 0.0003 (0.0004) acc 65.6250 (74.6094) kd_loss 0.0014 (0.0014) lr 2.0000e-03 eta 0:11:07
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,728
* accuracy: 78.3%
* error: 21.7%
* macro_f1: 80.2%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,924
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      78.3%, epoch: 1 *******
******* Domain p best val test acc: 86.6%, epoch: 1 *******
******* Domain p best test acc:     86.6%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/ana
epoch [2/50] batch [20/160] time 0.086 (0.112) data 0.000 (0.020) loss 0.7591 (0.6612) ce_loss 0.7046 (0.6238) teacher_loss 0.6946 (0.6251) loss_zs_kd 0.0822 (0.0545) loss_oracle 0.0234 (0.0088) acc 75.0000 (77.6562) kd_loss 0.0510 (0.0113) lr 2.0000e-03 eta 0:14:33
epoch [2/50] batch [40/160] time 0.070 (0.098) data 0.000 (0.010) loss 0.8017 (0.6574) ce_loss 0.8535 (0.6221) teacher_loss 0.5946 (0.5781) loss_zs_kd 0.0959 (0.0669) loss_oracle 0.1591 (0.0458) acc 71.8750 (77.7344) kd_loss 0.5873 (0.1600) lr 2.0000e-03 eta 0:12:42
epoch [2/50] batch [60/160] time 0.082 (0.092) data 0.000 (0.007) loss 0.6742 (0.6800) ce_loss 0.5693 (0.6302) teacher_loss 0.3396 (0.5502) loss_zs_kd 0.1475 (0.0812) loss_oracle 0.2609 (0.0892) acc 81.2500 (78.2812) kd_loss 0.7002 (0.2758) lr 2.0000e-03 eta 0:11:59
epoch [2/50] batch [80/160] time 0.077 (0.090) data 0.000 (0.005) loss 0.5785 (0.6876) ce_loss 0.3821 (0.6228) teacher_loss 0.3021 (0.5284) loss_zs_kd 0.1326 (0.0888) loss_oracle 0.2101 (0.1149) acc 90.6250 (77.9688) kd_loss 0.7332 (0.3695) lr 2.0000e-03 eta 0:11:34
epoch [2/50] batch [100/160] time 0.080 (0.088) data 0.000 (0.004) loss 0.6792 (0.7088) ce_loss 0.3770 (0.6245) teacher_loss 0.2839 (0.5211) loss_zs_kd 0.1176 (0.0891) loss_oracle 0.3364 (0.1432) acc 90.6250 (77.7188) kd_loss 0.7987 (0.4353) lr 2.0000e-03 eta 0:11:23
epoch [2/50] batch [120/160] time 0.083 (0.087) data 0.000 (0.004) loss 0.7152 (0.7197) ce_loss 0.5820 (0.6275) teacher_loss 0.5176 (0.5220) loss_zs_kd 0.0636 (0.0893) loss_oracle 0.1658 (0.1530) acc 87.5000 (77.6042) kd_loss 0.6412 (0.4853) lr 2.0000e-03 eta 0:11:12
epoch [2/50] batch [140/160] time 0.079 (0.086) data 0.000 (0.003) loss 0.5026 (0.7095) ce_loss 0.3064 (0.6108) teacher_loss 0.2175 (0.5080) loss_zs_kd 0.0709 (0.0874) loss_oracle 0.2497 (0.1578) acc 93.7500 (78.0134) kd_loss 0.6859 (0.5191) lr 2.0000e-03 eta 0:11:00
epoch [2/50] batch [160/160] time 0.072 (0.084) data 0.000 (0.003) loss 0.7545 (0.7067) ce_loss 0.5640 (0.5994) teacher_loss 0.4726 (0.4995) loss_zs_kd 0.0871 (0.0874) loss_oracle 0.2383 (0.1635) acc 81.2500 (78.1445) kd_loss 0.6740 (0.5478) lr 1.9980e-03 eta 0:10:48
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,817
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 84.2%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,962
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.7%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.4%, epoch: 2 *******
******* Domain p best val test acc: 87.7%, epoch: 2 *******
******* Domain p best test acc:     87.7%, epoch: 2 *******
epoch [3/50] batch [20/160] time 0.088 (0.104) data 0.000 (0.017) loss 0.7234 (0.7421) ce_loss 0.5703 (0.5624) teacher_loss 0.4608 (0.4632) loss_zs_kd 0.0820 (0.0773) loss_oracle 0.2215 (0.2403) acc 81.2500 (79.2188) kd_loss 0.7569 (0.7561) lr 1.9980e-03 eta 0:13:14
epoch [3/50] batch [40/160] time 0.077 (0.094) data 0.000 (0.009) loss 0.5837 (0.7573) ce_loss 0.4504 (0.5603) teacher_loss 0.3196 (0.4755) loss_zs_kd 0.0579 (0.0812) loss_oracle 0.2351 (0.2413) acc 84.3750 (79.8438) kd_loss 0.8059 (0.7766) lr 1.9980e-03 eta 0:11:59
epoch [3/50] batch [60/160] time 0.096 (0.092) data 0.001 (0.006) loss 0.9309 (0.7873) ce_loss 0.6714 (0.5776) teacher_loss 0.5443 (0.4893) loss_zs_kd 0.0745 (0.0809) loss_oracle 0.3494 (0.2576) acc 81.2500 (79.2188) kd_loss 0.7466 (0.7915) lr 1.9980e-03 eta 0:11:38
epoch [3/50] batch [80/160] time 0.080 (0.090) data 0.000 (0.004) loss 0.8389 (0.7900) ce_loss 0.5635 (0.5838) teacher_loss 0.5196 (0.4874) loss_zs_kd 0.1109 (0.0824) loss_oracle 0.2639 (0.2614) acc 78.1250 (78.6719) kd_loss 0.8141 (0.8035) lr 1.9980e-03 eta 0:11:22
epoch [3/50] batch [100/160] time 0.091 (0.089) data 0.000 (0.004) loss 0.7435 (0.7846) ce_loss 0.4521 (0.5612) teacher_loss 0.3659 (0.4719) loss_zs_kd 0.0602 (0.0846) loss_oracle 0.3475 (0.2704) acc 84.3750 (79.3438) kd_loss 0.8071 (0.8111) lr 1.9980e-03 eta 0:11:15
epoch [3/50] batch [120/160] time 0.094 (0.089) data 0.001 (0.003) loss 0.8093 (0.8020) ce_loss 0.4524 (0.5542) teacher_loss 0.3863 (0.4679) loss_zs_kd 0.1327 (0.0880) loss_oracle 0.3566 (0.2902) acc 81.2500 (79.4271) kd_loss 0.8159 (0.8181) lr 1.9980e-03 eta 0:11:09
epoch [3/50] batch [140/160] time 0.083 (0.088) data 0.000 (0.003) loss 0.7865 (0.8184) ce_loss 0.4490 (0.5534) teacher_loss 0.3077 (0.4686) loss_zs_kd 0.1049 (0.0888) loss_oracle 0.4264 (0.3054) acc 81.2500 (79.1741) kd_loss 0.9100 (0.8257) lr 1.9980e-03 eta 0:11:06
epoch [3/50] batch [160/160] time 0.073 (0.087) data 0.000 (0.002) loss 1.5691 (0.8513) ce_loss 1.0791 (0.5567) teacher_loss 1.0071 (0.4745) loss_zs_kd 0.1122 (0.0915) loss_oracle 0.5060 (0.3310) acc 65.6250 (79.0820) kd_loss 0.9078 (0.8344) lr 1.9921e-03 eta 0:10:51
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,819
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,966
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.7%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.5%, epoch: 3 *******
******* Domain p best val test acc: 87.9%, epoch: 3 *******
******* Domain p best test acc:     87.9%, epoch: 3 *******
epoch [4/50] batch [20/160] time 0.074 (0.107) data 0.000 (0.019) loss 1.0278 (1.0622) ce_loss 0.5063 (0.5673) teacher_loss 0.4912 (0.4967) loss_zs_kd 0.1037 (0.1034) loss_oracle 0.4847 (0.5137) acc 78.1250 (77.9688) kd_loss 0.9514 (0.9150) lr 1.9921e-03 eta 0:13:19
epoch [4/50] batch [40/160] time 0.078 (0.094) data 0.000 (0.010) loss 0.9152 (1.0108) ce_loss 0.3794 (0.5040) teacher_loss 0.3648 (0.4442) loss_zs_kd 0.1318 (0.1079) loss_oracle 0.4845 (0.5126) acc 90.6250 (81.0938) kd_loss 0.9741 (0.9180) lr 1.9921e-03 eta 0:11:41
epoch [4/50] batch [60/160] time 0.083 (0.090) data 0.000 (0.007) loss 1.0113 (1.0435) ce_loss 0.5190 (0.5121) teacher_loss 0.4197 (0.4540) loss_zs_kd 0.1118 (0.1044) loss_oracle 0.5357 (0.5373) acc 84.3750 (81.0417) kd_loss 0.9079 (0.9197) lr 1.9921e-03 eta 0:11:10
epoch [4/50] batch [80/160] time 0.085 (0.088) data 0.000 (0.005) loss 1.1639 (1.0676) ce_loss 0.6128 (0.5272) teacher_loss 0.4019 (0.4614) loss_zs_kd 0.0912 (0.1062) loss_oracle 0.7164 (0.5531) acc 75.0000 (80.4297) kd_loss 0.9630 (0.9221) lr 1.9921e-03 eta 0:10:56
epoch [4/50] batch [100/160] time 0.072 (0.087) data 0.000 (0.004) loss 1.0957 (1.0898) ce_loss 0.4868 (0.5368) teacher_loss 0.5047 (0.4741) loss_zs_kd 0.1018 (0.1081) loss_oracle 0.5402 (0.5616) acc 81.2500 (79.9062) kd_loss 0.9336 (0.9211) lr 1.9921e-03 eta 0:10:48
epoch [4/50] batch [120/160] time 0.083 (0.087) data 0.000 (0.003) loss 1.2586 (1.0906) ce_loss 0.7271 (0.5416) teacher_loss 0.6716 (0.4796) loss_zs_kd 0.0838 (0.1048) loss_oracle 0.5451 (0.5586) acc 81.2500 (79.9219) kd_loss 0.8677 (0.9188) lr 1.9921e-03 eta 0:10:43
epoch [4/50] batch [140/160] time 0.074 (0.087) data 0.000 (0.003) loss 0.9790 (1.0871) ce_loss 0.5557 (0.5420) teacher_loss 0.4455 (0.4783) loss_zs_kd 0.0809 (0.1053) loss_oracle 0.4930 (0.5561) acc 81.2500 (79.7768) kd_loss 0.8579 (0.9163) lr 1.9921e-03 eta 0:10:39
epoch [4/50] batch [160/160] time 0.073 (0.086) data 0.000 (0.003) loss 0.8847 (1.0787) ce_loss 0.3330 (0.5382) teacher_loss 0.2941 (0.4712) loss_zs_kd 0.0956 (0.1070) loss_oracle 0.5429 (0.5541) acc 93.7500 (79.9023) kd_loss 0.8017 (0.9126) lr 1.9823e-03 eta 0:10:29
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,826
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 84.4%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,982
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 89.2%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.8%, epoch: 4 *******
******* Domain p best val test acc: 88.3%, epoch: 4 *******
******* Domain p best test acc:     88.3%, epoch: 4 *******
epoch [5/50] batch [20/160] time 0.080 (0.097) data 0.000 (0.017) loss 0.7818 (1.0394) ce_loss 0.3291 (0.5525) teacher_loss 0.2553 (0.4351) loss_zs_kd 0.1010 (0.1176) loss_oracle 0.4761 (0.5455) acc 90.6250 (81.2500) kd_loss 0.8215 (0.8937) lr 1.9823e-03 eta 0:11:54
epoch [5/50] batch [40/160] time 0.078 (0.086) data 0.000 (0.009) loss 0.9295 (1.0481) ce_loss 0.3230 (0.5443) teacher_loss 0.3144 (0.4407) loss_zs_kd 0.1022 (0.1148) loss_oracle 0.5641 (0.5500) acc 93.7500 (80.7812) kd_loss 0.8404 (0.8853) lr 1.9823e-03 eta 0:10:31
epoch [5/50] batch [60/160] time 0.077 (0.083) data 0.001 (0.006) loss 1.2037 (1.0412) ce_loss 0.7251 (0.5383) teacher_loss 0.6900 (0.4318) loss_zs_kd 0.1417 (0.1233) loss_oracle 0.4428 (0.5477) acc 78.1250 (80.6771) kd_loss 0.7500 (0.8787) lr 1.9823e-03 eta 0:10:08
epoch [5/50] batch [80/160] time 0.080 (0.083) data 0.000 (0.004) loss 0.8681 (1.0049) ce_loss 0.5684 (0.5397) teacher_loss 0.4133 (0.4316) loss_zs_kd 0.1401 (0.1276) loss_oracle 0.3848 (0.5095) acc 81.2500 (81.2500) kd_loss 0.8442 (0.8766) lr 1.9823e-03 eta 0:10:02
epoch [5/50] batch [100/160] time 0.084 (0.082) data 0.000 (0.004) loss 0.8988 (0.9688) ce_loss 0.5093 (0.5282) teacher_loss 0.4457 (0.4170) loss_zs_kd 0.1231 (0.1270) loss_oracle 0.3915 (0.4884) acc 81.2500 (81.0625) kd_loss 0.7509 (0.8737) lr 1.9823e-03 eta 0:09:58
epoch [5/50] batch [120/160] time 0.082 (0.082) data 0.000 (0.003) loss 0.8229 (0.9550) ce_loss 0.5630 (0.5290) teacher_loss 0.3492 (0.4098) loss_zs_kd 0.1533 (0.1322) loss_oracle 0.3970 (0.4791) acc 75.0000 (81.0156) kd_loss 0.8328 (0.8739) lr 1.9823e-03 eta 0:09:57
epoch [5/50] batch [140/160] time 0.084 (0.082) data 0.000 (0.003) loss 1.1610 (0.9435) ce_loss 0.8818 (0.5306) teacher_loss 0.6024 (0.4031) loss_zs_kd 0.1634 (0.1359) loss_oracle 0.4768 (0.4724) acc 81.2500 (80.8929) kd_loss 0.9312 (0.8767) lr 1.9823e-03 eta 0:09:54
epoch [5/50] batch [160/160] time 0.071 (0.081) data 0.000 (0.002) loss 1.0921 (0.9331) ce_loss 0.8555 (0.5287) teacher_loss 0.6103 (0.3959) loss_zs_kd 0.1050 (0.1389) loss_oracle 0.4293 (0.4678) acc 68.7500 (80.8203) kd_loss 0.9042 (0.8786) lr 1.9686e-03 eta 0:09:46
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,836
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 84.6%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,969
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.0%
******* Domain p best val acc:      83.2%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.3%, epoch: 4 *******
epoch [6/50] batch [20/160] time 0.086 (0.089) data 0.000 (0.012) loss 0.7054 (0.8010) ce_loss 0.4863 (0.5414) teacher_loss 0.2468 (0.3443) loss_zs_kd 0.1450 (0.1493) loss_oracle 0.3861 (0.3821) acc 78.1250 (80.7812) kd_loss 0.9692 (0.9161) lr 1.9686e-03 eta 0:10:36
epoch [6/50] batch [40/160] time 0.085 (0.087) data 0.000 (0.006) loss 0.7332 (0.8020) ce_loss 0.3928 (0.5227) teacher_loss 0.2725 (0.3329) loss_zs_kd 0.1467 (0.1608) loss_oracle 0.3873 (0.3888) acc 84.3750 (81.2500) kd_loss 0.9174 (0.9168) lr 1.9686e-03 eta 0:10:24
epoch [6/50] batch [60/160] time 0.090 (0.086) data 0.001 (0.004) loss 0.6910 (0.8015) ce_loss 0.4817 (0.5288) teacher_loss 0.2603 (0.3412) loss_zs_kd 0.1704 (0.1553) loss_oracle 0.3455 (0.3826) acc 75.0000 (81.6667) kd_loss 0.9553 (0.9215) lr 1.9686e-03 eta 0:10:11
epoch [6/50] batch [80/160] time 0.087 (0.085) data 0.000 (0.003) loss 0.7437 (0.8074) ce_loss 0.5210 (0.5427) teacher_loss 0.3630 (0.3555) loss_zs_kd 0.1326 (0.1515) loss_oracle 0.3145 (0.3762) acc 78.1250 (81.3672) kd_loss 0.9801 (0.9269) lr 1.9686e-03 eta 0:10:08
epoch [6/50] batch [100/160] time 0.089 (0.086) data 0.000 (0.003) loss 0.7825 (0.7982) ce_loss 0.7129 (0.5418) teacher_loss 0.3954 (0.3558) loss_zs_kd 0.1093 (0.1474) loss_oracle 0.3325 (0.3686) acc 75.0000 (81.0000) kd_loss 1.0316 (0.9294) lr 1.9686e-03 eta 0:10:08
epoch [6/50] batch [120/160] time 0.080 (0.086) data 0.000 (0.002) loss 0.8964 (0.7964) ce_loss 0.7817 (0.5459) teacher_loss 0.4182 (0.3559) loss_zs_kd 0.1881 (0.1487) loss_oracle 0.3841 (0.3661) acc 71.8750 (80.8073) kd_loss 1.0587 (0.9319) lr 1.9686e-03 eta 0:10:09
epoch [6/50] batch [140/160] time 0.086 (0.086) data 0.000 (0.002) loss 0.6785 (0.7875) ce_loss 0.5449 (0.5366) teacher_loss 0.3513 (0.3535) loss_zs_kd 0.0942 (0.1456) loss_oracle 0.2801 (0.3612) acc 75.0000 (81.2500) kd_loss 0.9759 (0.9320) lr 1.9686e-03 eta 0:10:10
epoch [6/50] batch [160/160] time 0.074 (0.085) data 0.000 (0.002) loss 0.9729 (0.7927) ce_loss 0.6987 (0.5471) teacher_loss 0.5608 (0.3637) loss_zs_kd 0.1556 (0.1443) loss_oracle 0.3343 (0.3568) acc 78.1250 (80.6641) kd_loss 0.9719 (0.9371) lr 1.9511e-03 eta 0:10:01
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,822
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,958
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.8%
******* Domain p best val acc:      83.2%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.3%, epoch: 4 *******
epoch [7/50] batch [20/160] time 0.071 (0.096) data 0.000 (0.018) loss 0.8598 (0.7187) ce_loss 0.7476 (0.5097) teacher_loss 0.5239 (0.3508) loss_zs_kd 0.1041 (0.1315) loss_oracle 0.2839 (0.3022) acc 65.6250 (82.9688) kd_loss 1.0510 (0.9601) lr 1.9511e-03 eta 0:11:11
epoch [7/50] batch [40/160] time 0.080 (0.085) data 0.000 (0.009) loss 0.8597 (0.7377) ce_loss 0.5005 (0.5528) teacher_loss 0.4980 (0.3867) loss_zs_kd 0.1107 (0.1267) loss_oracle 0.3063 (0.2877) acc 84.3750 (81.3281) kd_loss 0.9072 (0.9680) lr 1.9511e-03 eta 0:09:56
epoch [7/50] batch [60/160] time 0.064 (0.082) data 0.000 (0.006) loss 0.8713 (0.7339) ce_loss 0.6123 (0.5445) teacher_loss 0.4777 (0.3845) loss_zs_kd 0.1269 (0.1265) loss_oracle 0.3301 (0.2862) acc 78.1250 (80.7292) kd_loss 1.0704 (0.9695) lr 1.9511e-03 eta 0:09:32
epoch [7/50] batch [80/160] time 0.070 (0.079) data 0.000 (0.005) loss 0.8472 (0.7439) ce_loss 0.6538 (0.5581) teacher_loss 0.5377 (0.3922) loss_zs_kd 0.1496 (0.1296) loss_oracle 0.2348 (0.2869) acc 78.1250 (80.1953) kd_loss 1.0060 (0.9735) lr 1.9511e-03 eta 0:09:07
epoch [7/50] batch [100/160] time 0.080 (0.078) data 0.000 (0.004) loss 0.6177 (0.7527) ce_loss 0.4983 (0.5642) teacher_loss 0.2767 (0.3961) loss_zs_kd 0.1317 (0.1287) loss_oracle 0.2752 (0.2924) acc 75.0000 (79.6562) kd_loss 1.0098 (0.9741) lr 1.9511e-03 eta 0:09:00
epoch [7/50] batch [120/160] time 0.087 (0.078) data 0.000 (0.003) loss 0.5889 (0.7578) ce_loss 0.3962 (0.5694) teacher_loss 0.2690 (0.4078) loss_zs_kd 0.0652 (0.1258) loss_oracle 0.2873 (0.2871) acc 87.5000 (79.5573) kd_loss 0.9309 (0.9758) lr 1.9511e-03 eta 0:08:57
epoch [7/50] batch [140/160] time 0.084 (0.078) data 0.000 (0.003) loss 0.6721 (0.7444) ce_loss 0.4690 (0.5586) teacher_loss 0.4130 (0.4032) loss_zs_kd 0.0891 (0.1224) loss_oracle 0.2145 (0.2799) acc 84.3750 (79.9554) kd_loss 0.9464 (0.9777) lr 1.9511e-03 eta 0:08:59
epoch [7/50] batch [160/160] time 0.078 (0.079) data 0.000 (0.003) loss 0.9246 (0.7455) ce_loss 0.7544 (0.5622) teacher_loss 0.5616 (0.4079) loss_zs_kd 0.1465 (0.1210) loss_oracle 0.2897 (0.2770) acc 78.1250 (80.0586) kd_loss 1.0071 (0.9785) lr 1.9298e-03 eta 0:09:00
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,830
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,969
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.0%
******* Domain p best val acc:      83.2%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.3%, epoch: 4 *******
epoch [8/50] batch [20/160] time 0.094 (0.104) data 0.001 (0.017) loss 0.7587 (0.7459) ce_loss 0.6426 (0.5854) teacher_loss 0.4767 (0.4184) loss_zs_kd 0.1096 (0.1073) loss_oracle 0.2272 (0.2738) acc 81.2500 (79.6875) kd_loss 0.9821 (0.9824) lr 1.9298e-03 eta 0:11:55
epoch [8/50] batch [40/160] time 0.086 (0.096) data 0.000 (0.009) loss 0.8401 (0.7480) ce_loss 0.7822 (0.5717) teacher_loss 0.5070 (0.4137) loss_zs_kd 0.1227 (0.1097) loss_oracle 0.2717 (0.2794) acc 62.5000 (79.4531) kd_loss 1.0293 (0.9764) lr 1.9298e-03 eta 0:10:56
epoch [8/50] batch [60/160] time 0.094 (0.094) data 0.001 (0.006) loss 0.8336 (0.7416) ce_loss 0.5889 (0.5669) teacher_loss 0.4382 (0.4015) loss_zs_kd 0.1410 (0.1132) loss_oracle 0.3250 (0.2835) acc 71.8750 (79.5833) kd_loss 0.9572 (0.9740) lr 1.9298e-03 eta 0:10:43
epoch [8/50] batch [80/160] time 0.096 (0.093) data 0.000 (0.005) loss 0.5422 (0.7373) ce_loss 0.3440 (0.5518) teacher_loss 0.2462 (0.4003) loss_zs_kd 0.1118 (0.1136) loss_oracle 0.2401 (0.2802) acc 90.6250 (79.8438) kd_loss 1.0828 (0.9712) lr 1.9298e-03 eta 0:10:35
epoch [8/50] batch [100/160] time 0.083 (0.093) data 0.000 (0.004) loss 0.7488 (0.7360) ce_loss 0.5776 (0.5522) teacher_loss 0.3275 (0.3979) loss_zs_kd 0.1299 (0.1158) loss_oracle 0.3563 (0.2802) acc 81.2500 (80.1250) kd_loss 0.9793 (0.9720) lr 1.9298e-03 eta 0:10:27
epoch [8/50] batch [120/160] time 0.086 (0.092) data 0.000 (0.003) loss 0.6709 (0.7376) ce_loss 0.4297 (0.5530) teacher_loss 0.3052 (0.4009) loss_zs_kd 0.1696 (0.1155) loss_oracle 0.2810 (0.2790) acc 87.5000 (80.4167) kd_loss 1.0636 (0.9712) lr 1.9298e-03 eta 0:10:19
epoch [8/50] batch [140/160] time 0.087 (0.091) data 0.000 (0.003) loss 0.6432 (0.7357) ce_loss 0.3765 (0.5541) teacher_loss 0.3541 (0.3986) loss_zs_kd 0.0902 (0.1168) loss_oracle 0.2440 (0.2787) acc 87.5000 (80.3571) kd_loss 0.9567 (0.9669) lr 1.9298e-03 eta 0:10:16
epoch [8/50] batch [160/160] time 0.079 (0.090) data 0.000 (0.002) loss 0.6306 (0.7341) ce_loss 0.5093 (0.5530) teacher_loss 0.3466 (0.3976) loss_zs_kd 0.0753 (0.1165) loss_oracle 0.2464 (0.2783) acc 75.0000 (80.2930) kd_loss 0.9905 (0.9656) lr 1.9048e-03 eta 0:10:06
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,820
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,966
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.8%
******* Domain p best val acc:      83.2%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.3%, epoch: 4 *******
epoch [9/50] batch [20/160] time 0.078 (0.099) data 0.000 (0.012) loss 0.5597 (0.6819) ce_loss 0.4080 (0.5330) teacher_loss 0.2385 (0.3676) loss_zs_kd 0.1051 (0.1172) loss_oracle 0.2686 (0.2557) acc 84.3750 (80.4688) kd_loss 0.9267 (0.9584) lr 1.9048e-03 eta 0:11:03
epoch [9/50] batch [40/160] time 0.083 (0.089) data 0.000 (0.006) loss 0.8292 (0.7030) ce_loss 0.5225 (0.5364) teacher_loss 0.4838 (0.3787) loss_zs_kd 0.1270 (0.1144) loss_oracle 0.2818 (0.2671) acc 81.2500 (80.4688) kd_loss 0.9628 (0.9514) lr 1.9048e-03 eta 0:09:56
epoch [9/50] batch [60/160] time 0.085 (0.087) data 0.001 (0.004) loss 0.7189 (0.7349) ce_loss 0.5308 (0.5600) teacher_loss 0.3387 (0.3972) loss_zs_kd 0.1118 (0.1173) loss_oracle 0.3243 (0.2790) acc 78.1250 (79.6354) kd_loss 0.9691 (0.9494) lr 1.9048e-03 eta 0:09:38
epoch [9/50] batch [80/160] time 0.079 (0.086) data 0.000 (0.003) loss 0.7071 (0.7365) ce_loss 0.4421 (0.5553) teacher_loss 0.3245 (0.3928) loss_zs_kd 0.1193 (0.1198) loss_oracle 0.3229 (0.2838) acc 78.1250 (79.9219) kd_loss 0.9704 (0.9456) lr 1.9048e-03 eta 0:09:31
epoch [9/50] batch [100/160] time 0.086 (0.086) data 0.000 (0.003) loss 0.6988 (0.7356) ce_loss 0.4712 (0.5452) teacher_loss 0.3697 (0.3902) loss_zs_kd 0.0910 (0.1172) loss_oracle 0.2837 (0.2869) acc 90.6250 (80.3125) kd_loss 0.9528 (0.9426) lr 1.9048e-03 eta 0:09:27
epoch [9/50] batch [120/160] time 0.080 (0.086) data 0.000 (0.002) loss 0.9896 (0.7472) ce_loss 0.7910 (0.5547) teacher_loss 0.4916 (0.3952) loss_zs_kd 0.1379 (0.1171) loss_oracle 0.4290 (0.2935) acc 71.8750 (80.1562) kd_loss 0.9380 (0.9447) lr 1.9048e-03 eta 0:09:24
epoch [9/50] batch [140/160] time 0.091 (0.086) data 0.000 (0.002) loss 0.7469 (0.7470) ce_loss 0.5825 (0.5501) teacher_loss 0.3301 (0.3910) loss_zs_kd 0.1770 (0.1167) loss_oracle 0.3283 (0.2976) acc 75.0000 (80.1562) kd_loss 1.0014 (0.9453) lr 1.9048e-03 eta 0:09:23
epoch [9/50] batch [160/160] time 0.074 (0.085) data 0.000 (0.002) loss 0.6665 (0.7461) ce_loss 0.4705 (0.5466) teacher_loss 0.3104 (0.3888) loss_zs_kd 0.1090 (0.1183) loss_oracle 0.3017 (0.2982) acc 78.1250 (80.2734) kd_loss 0.9159 (0.9456) lr 1.8763e-03 eta 0:09:14
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,828
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,980
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 89.1%
******* Domain p best val acc:      83.2%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.3%, epoch: 4 *******
epoch [10/50] batch [20/160] time 0.081 (0.100) data 0.000 (0.016) loss 0.5823 (0.7573) ce_loss 0.3706 (0.5318) teacher_loss 0.2912 (0.4075) loss_zs_kd 0.0806 (0.1029) loss_oracle 0.2509 (0.2983) acc 87.5000 (80.4688) kd_loss 1.0148 (0.9480) lr 1.8763e-03 eta 0:10:53
epoch [10/50] batch [40/160] time 0.087 (0.091) data 0.000 (0.008) loss 0.6863 (0.7472) ce_loss 0.4524 (0.5211) teacher_loss 0.3191 (0.3922) loss_zs_kd 0.1089 (0.1051) loss_oracle 0.3128 (0.3024) acc 81.2500 (80.7031) kd_loss 0.9467 (0.9377) lr 1.8763e-03 eta 0:09:50
epoch [10/50] batch [60/160] time 0.082 (0.088) data 0.001 (0.005) loss 0.7319 (0.7676) ce_loss 0.4441 (0.5431) teacher_loss 0.3152 (0.4027) loss_zs_kd 0.1307 (0.1110) loss_oracle 0.3513 (0.3095) acc 87.5000 (79.8438) kd_loss 0.9244 (0.9366) lr 1.8763e-03 eta 0:09:34
epoch [10/50] batch [80/160] time 0.088 (0.088) data 0.000 (0.004) loss 0.9635 (0.7714) ce_loss 0.6411 (0.5455) teacher_loss 0.5968 (0.4013) loss_zs_kd 0.1172 (0.1143) loss_oracle 0.3082 (0.3129) acc 84.3750 (80.1562) kd_loss 0.9159 (0.9367) lr 1.8763e-03 eta 0:09:31
epoch [10/50] batch [100/160] time 0.067 (0.086) data 0.000 (0.003) loss 0.7094 (0.7696) ce_loss 0.5752 (0.5427) teacher_loss 0.3650 (0.3990) loss_zs_kd 0.1619 (0.1169) loss_oracle 0.2634 (0.3121) acc 78.1250 (80.4688) kd_loss 0.9189 (0.9332) lr 1.8763e-03 eta 0:09:17
epoch [10/50] batch [120/160] time 0.073 (0.085) data 0.000 (0.003) loss 0.9788 (0.7693) ce_loss 0.8218 (0.5461) teacher_loss 0.5845 (0.3991) loss_zs_kd 0.1858 (0.1188) loss_oracle 0.3014 (0.3108) acc 68.7500 (80.4688) kd_loss 0.9592 (0.9311) lr 1.8763e-03 eta 0:09:04
epoch [10/50] batch [140/160] time 0.090 (0.085) data 0.000 (0.003) loss 0.6779 (0.7630) ce_loss 0.4675 (0.5435) teacher_loss 0.3533 (0.3945) loss_zs_kd 0.1027 (0.1189) loss_oracle 0.2733 (0.3090) acc 84.3750 (80.7143) kd_loss 0.8248 (0.9307) lr 1.8763e-03 eta 0:09:02
epoch [10/50] batch [160/160] time 0.072 (0.084) data 0.000 (0.002) loss 0.9431 (0.7736) ce_loss 0.5933 (0.5532) teacher_loss 0.5743 (0.4049) loss_zs_kd 0.0969 (0.1194) loss_oracle 0.3204 (0.3090) acc 78.1250 (80.2344) kd_loss 0.8874 (0.9275) lr 1.8443e-03 eta 0:08:54
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,833
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,973
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 89.1%
******* Domain p best val acc:      83.2%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.3%, epoch: 4 *******
epoch [11/50] batch [20/160] time 0.085 (0.100) data 0.000 (0.014) loss 0.6784 (0.7553) ce_loss 0.3782 (0.5378) teacher_loss 0.2716 (0.3858) loss_zs_kd 0.1322 (0.1048) loss_oracle 0.3407 (0.3172) acc 78.1250 (79.6875) kd_loss 0.9523 (0.9244) lr 1.8443e-03 eta 0:10:35
epoch [11/50] batch [40/160] time 0.075 (0.089) data 0.000 (0.007) loss 0.6696 (0.7583) ce_loss 0.3335 (0.5511) teacher_loss 0.3518 (0.4008) loss_zs_kd 0.0988 (0.1073) loss_oracle 0.2684 (0.3039) acc 87.5000 (80.0781) kd_loss 0.8638 (0.9154) lr 1.8443e-03 eta 0:09:24
epoch [11/50] batch [60/160] time 0.086 (0.088) data 0.001 (0.005) loss 0.7165 (0.7661) ce_loss 0.5029 (0.5519) teacher_loss 0.3246 (0.4112) loss_zs_kd 0.1047 (0.1045) loss_oracle 0.3395 (0.3026) acc 75.0000 (80.3646) kd_loss 0.8879 (0.9117) lr 1.8443e-03 eta 0:09:18
epoch [11/50] batch [80/160] time 0.075 (0.085) data 0.000 (0.004) loss 0.7376 (0.7671) ce_loss 0.5444 (0.5560) teacher_loss 0.4509 (0.4167) loss_zs_kd 0.0922 (0.1053) loss_oracle 0.2406 (0.2978) acc 84.3750 (80.2734) kd_loss 0.8695 (0.9101) lr 1.8443e-03 eta 0:09:00
epoch [11/50] batch [100/160] time 0.082 (0.084) data 0.002 (0.003) loss 0.7076 (0.7548) ce_loss 0.3794 (0.5425) teacher_loss 0.3371 (0.4061) loss_zs_kd 0.1302 (0.1046) loss_oracle 0.3054 (0.2965) acc 87.5000 (80.7188) kd_loss 0.8813 (0.9120) lr 1.8443e-03 eta 0:08:47
epoch [11/50] batch [120/160] time 0.081 (0.083) data 0.001 (0.003) loss 0.6950 (0.7514) ce_loss 0.5679 (0.5433) teacher_loss 0.3877 (0.4073) loss_zs_kd 0.0981 (0.1038) loss_oracle 0.2583 (0.2922) acc 71.8750 (80.8073) kd_loss 0.8752 (0.9112) lr 1.8443e-03 eta 0:08:43
epoch [11/50] batch [140/160] time 0.091 (0.083) data 0.000 (0.002) loss 0.7485 (0.7509) ce_loss 0.4805 (0.5420) teacher_loss 0.4089 (0.4084) loss_zs_kd 0.1038 (0.1023) loss_oracle 0.2877 (0.2913) acc 84.3750 (80.6920) kd_loss 0.9258 (0.9128) lr 1.8443e-03 eta 0:08:40
epoch [11/50] batch [160/160] time 0.074 (0.083) data 0.000 (0.002) loss 0.6500 (0.7489) ce_loss 0.3855 (0.5385) teacher_loss 0.3460 (0.4062) loss_zs_kd 0.1128 (0.1032) loss_oracle 0.2477 (0.2911) acc 87.5000 (80.8008) kd_loss 0.9151 (0.9130) lr 1.8090e-03 eta 0:08:37
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,831
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,984
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.2%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.2%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.4%, epoch: 11 *******
epoch [12/50] batch [20/160] time 0.077 (0.102) data 0.000 (0.019) loss 0.6512 (0.7200) ce_loss 0.4495 (0.5003) teacher_loss 0.3176 (0.3975) loss_zs_kd 0.0935 (0.0994) loss_oracle 0.2868 (0.2728) acc 87.5000 (81.8750) kd_loss 0.9526 (0.8997) lr 1.8090e-03 eta 0:10:33
epoch [12/50] batch [40/160] time 0.081 (0.092) data 0.000 (0.010) loss 0.6993 (0.6926) ce_loss 0.4592 (0.4840) teacher_loss 0.3668 (0.3701) loss_zs_kd 0.0947 (0.0982) loss_oracle 0.2852 (0.2734) acc 84.3750 (82.9688) kd_loss 0.8906 (0.9052) lr 1.8090e-03 eta 0:09:33
epoch [12/50] batch [60/160] time 0.093 (0.089) data 0.001 (0.007) loss 0.7238 (0.7318) ce_loss 0.5107 (0.5178) teacher_loss 0.3985 (0.3954) loss_zs_kd 0.1071 (0.1041) loss_oracle 0.2718 (0.2844) acc 71.8750 (81.5625) kd_loss 0.9545 (0.9028) lr 1.8090e-03 eta 0:09:09
epoch [12/50] batch [80/160] time 0.072 (0.088) data 0.000 (0.005) loss 0.6314 (0.7455) ce_loss 0.4299 (0.5254) teacher_loss 0.3489 (0.4070) loss_zs_kd 0.0916 (0.1020) loss_oracle 0.2366 (0.2875) acc 84.3750 (81.2500) kd_loss 0.9358 (0.9037) lr 1.8090e-03 eta 0:09:02
epoch [12/50] batch [100/160] time 0.079 (0.087) data 0.000 (0.004) loss 0.6038 (0.7448) ce_loss 0.3828 (0.5294) teacher_loss 0.3031 (0.4129) loss_zs_kd 0.0862 (0.1007) loss_oracle 0.2576 (0.2815) acc 81.2500 (81.0000) kd_loss 0.9344 (0.9011) lr 1.8090e-03 eta 0:08:53
epoch [12/50] batch [120/160] time 0.089 (0.086) data 0.000 (0.003) loss 0.7032 (0.7447) ce_loss 0.5278 (0.5322) teacher_loss 0.3469 (0.4133) loss_zs_kd 0.0674 (0.1003) loss_oracle 0.3226 (0.2813) acc 78.1250 (80.7292) kd_loss 0.9118 (0.8990) lr 1.8090e-03 eta 0:08:47
epoch [12/50] batch [140/160] time 0.083 (0.085) data 0.000 (0.003) loss 0.6356 (0.7452) ce_loss 0.4358 (0.5337) teacher_loss 0.3246 (0.4146) loss_zs_kd 0.0955 (0.1004) loss_oracle 0.2633 (0.2804) acc 84.3750 (80.6696) kd_loss 0.8740 (0.8989) lr 1.8090e-03 eta 0:08:39
epoch [12/50] batch [160/160] time 0.074 (0.084) data 0.000 (0.003) loss 0.9051 (0.7456) ce_loss 0.6855 (0.5361) teacher_loss 0.5484 (0.4144) loss_zs_kd 0.0860 (0.1016) loss_oracle 0.3137 (0.2803) acc 78.1250 (80.5469) kd_loss 0.8621 (0.8988) lr 1.7705e-03 eta 0:08:30
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,829
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,988
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.2%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.5%, epoch: 12 *******
epoch [13/50] batch [20/160] time 0.090 (0.107) data 0.000 (0.020) loss 0.5649 (0.7679) ce_loss 0.2559 (0.5442) teacher_loss 0.2740 (0.4264) loss_zs_kd 0.0741 (0.1122) loss_oracle 0.2539 (0.2853) acc 93.7500 (78.9062) kd_loss 0.7438 (0.8748) lr 1.7705e-03 eta 0:10:46
epoch [13/50] batch [40/160] time 0.090 (0.096) data 0.001 (0.010) loss 0.7300 (0.7638) ce_loss 0.4556 (0.5377) teacher_loss 0.3593 (0.4210) loss_zs_kd 0.0838 (0.1085) loss_oracle 0.3288 (0.2886) acc 84.3750 (79.7656) kd_loss 0.8957 (0.8776) lr 1.7705e-03 eta 0:09:38
epoch [13/50] batch [60/160] time 0.083 (0.091) data 0.001 (0.007) loss 0.9726 (0.7655) ce_loss 0.6367 (0.5370) teacher_loss 0.5968 (0.4168) loss_zs_kd 0.0782 (0.1072) loss_oracle 0.3367 (0.2952) acc 71.8750 (79.9479) kd_loss 0.9371 (0.8818) lr 1.7705e-03 eta 0:09:09
epoch [13/50] batch [80/160] time 0.084 (0.090) data 0.000 (0.005) loss 0.5857 (0.7679) ce_loss 0.3406 (0.5368) teacher_loss 0.2772 (0.4149) loss_zs_kd 0.1243 (0.1085) loss_oracle 0.2464 (0.2988) acc 84.3750 (79.9219) kd_loss 0.9141 (0.8853) lr 1.7705e-03 eta 0:08:57
epoch [13/50] batch [100/160] time 0.072 (0.088) data 0.000 (0.004) loss 0.6323 (0.7725) ce_loss 0.3403 (0.5376) teacher_loss 0.2900 (0.4173) loss_zs_kd 0.0692 (0.1084) loss_oracle 0.3077 (0.3011) acc 87.5000 (80.1875) kd_loss 0.8873 (0.8867) lr 1.7705e-03 eta 0:08:47
epoch [13/50] batch [120/160] time 0.080 (0.087) data 0.000 (0.004) loss 0.6811 (0.7741) ce_loss 0.4932 (0.5361) teacher_loss 0.3466 (0.4171) loss_zs_kd 0.0819 (0.1063) loss_oracle 0.2936 (0.3039) acc 81.2500 (80.3385) kd_loss 0.8639 (0.8863) lr 1.7705e-03 eta 0:08:41
epoch [13/50] batch [140/160] time 0.088 (0.087) data 0.000 (0.003) loss 0.6303 (0.7710) ce_loss 0.4910 (0.5326) teacher_loss 0.3321 (0.4114) loss_zs_kd 0.0830 (0.1059) loss_oracle 0.2567 (0.3066) acc 81.2500 (80.5580) kd_loss 0.8718 (0.8849) lr 1.7705e-03 eta 0:08:34
epoch [13/50] batch [160/160] time 0.072 (0.085) data 0.000 (0.003) loss 0.9426 (0.7725) ce_loss 0.6968 (0.5303) teacher_loss 0.5797 (0.4114) loss_zs_kd 0.0861 (0.1048) loss_oracle 0.3199 (0.3088) acc 71.8750 (80.6055) kd_loss 0.8870 (0.8832) lr 1.7290e-03 eta 0:08:24
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,835
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,987
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.3%
******* Domain p best val acc:      83.2%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     88.5%, epoch: 12 *******
epoch [14/50] batch [20/160] time 0.086 (0.096) data 0.000 (0.013) loss 0.7363 (0.7714) ce_loss 0.4297 (0.5301) teacher_loss 0.3134 (0.4016) loss_zs_kd 0.0971 (0.0996) loss_oracle 0.3744 (0.3201) acc 87.5000 (78.7500) kd_loss 0.8973 (0.8802) lr 1.7290e-03 eta 0:09:25
epoch [14/50] batch [40/160] time 0.089 (0.088) data 0.000 (0.007) loss 0.7662 (0.7755) ce_loss 0.5366 (0.5407) teacher_loss 0.4771 (0.4144) loss_zs_kd 0.1057 (0.0947) loss_oracle 0.2363 (0.3138) acc 78.1250 (79.2188) kd_loss 0.8565 (0.8830) lr 1.7290e-03 eta 0:08:40
epoch [14/50] batch [60/160] time 0.082 (0.087) data 0.000 (0.004) loss 0.6322 (0.7570) ce_loss 0.4211 (0.5263) teacher_loss 0.2689 (0.4019) loss_zs_kd 0.0755 (0.0958) loss_oracle 0.3255 (0.3072) acc 84.3750 (79.8438) kd_loss 0.9099 (0.8743) lr 1.7290e-03 eta 0:08:27
epoch [14/50] batch [80/160] time 0.079 (0.086) data 0.000 (0.003) loss 0.9419 (0.7749) ce_loss 0.6968 (0.5467) teacher_loss 0.6409 (0.4211) loss_zs_kd 0.0865 (0.0987) loss_oracle 0.2578 (0.3045) acc 68.7500 (78.9453) kd_loss 0.9248 (0.8739) lr 1.7290e-03 eta 0:08:20
epoch [14/50] batch [100/160] time 0.085 (0.086) data 0.001 (0.003) loss 0.7978 (0.7737) ce_loss 0.5400 (0.5407) teacher_loss 0.4717 (0.4171) loss_zs_kd 0.0990 (0.0997) loss_oracle 0.2767 (0.3067) acc 71.8750 (79.3125) kd_loss 0.8861 (0.8731) lr 1.7290e-03 eta 0:08:18
epoch [14/50] batch [120/160] time 0.082 (0.085) data 0.000 (0.002) loss 0.8614 (0.7726) ce_loss 0.5698 (0.5350) teacher_loss 0.4604 (0.4169) loss_zs_kd 0.1040 (0.1007) loss_oracle 0.3490 (0.3054) acc 81.2500 (79.7656) kd_loss 0.9137 (0.8718) lr 1.7290e-03 eta 0:08:13
epoch [14/50] batch [140/160] time 0.088 (0.085) data 0.000 (0.002) loss 0.7057 (0.7670) ce_loss 0.4834 (0.5324) teacher_loss 0.3781 (0.4104) loss_zs_kd 0.1077 (0.1013) loss_oracle 0.2737 (0.3059) acc 84.3750 (79.7768) kd_loss 0.8153 (0.8721) lr 1.7290e-03 eta 0:08:11
epoch [14/50] batch [160/160] time 0.072 (0.084) data 0.000 (0.002) loss 0.5456 (0.7639) ce_loss 0.2791 (0.5300) teacher_loss 0.2486 (0.4078) loss_zs_kd 0.0732 (0.1024) loss_oracle 0.2604 (0.3049) acc 87.5000 (79.8633) kd_loss 0.8276 (0.8710) lr 1.6845e-03 eta 0:08:02
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,827
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,008
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 89.8%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.2%, epoch: 5 *******
******* Domain p best val test acc: 87.9%, epoch: 5 *******
******* Domain p best test acc:     89.1%, epoch: 14 *******
epoch [15/50] batch [20/160] time 0.081 (0.101) data 0.000 (0.014) loss 0.7366 (0.7587) ce_loss 0.4480 (0.4998) teacher_loss 0.3853 (0.4013) loss_zs_kd 0.1279 (0.0994) loss_oracle 0.2874 (0.3077) acc 81.2500 (81.0938) kd_loss 0.8896 (0.8774) lr 1.6845e-03 eta 0:09:41
epoch [15/50] batch [40/160] time 0.090 (0.092) data 0.000 (0.007) loss 0.7597 (0.7711) ce_loss 0.5151 (0.5213) teacher_loss 0.3024 (0.4121) loss_zs_kd 0.1324 (0.0993) loss_oracle 0.3911 (0.3093) acc 81.2500 (80.8594) kd_loss 0.8848 (0.8703) lr 1.6845e-03 eta 0:08:46
epoch [15/50] batch [60/160] time 0.087 (0.089) data 0.001 (0.005) loss 0.8289 (0.7614) ce_loss 0.5176 (0.5116) teacher_loss 0.4537 (0.3990) loss_zs_kd 0.1422 (0.1007) loss_oracle 0.3040 (0.3121) acc 90.6250 (80.6771) kd_loss 0.9083 (0.8688) lr 1.6845e-03 eta 0:08:28
epoch [15/50] batch [80/160] time 0.088 (0.090) data 0.001 (0.004) loss 0.8596 (0.7669) ce_loss 0.5513 (0.5176) teacher_loss 0.4593 (0.4027) loss_zs_kd 0.1032 (0.1029) loss_oracle 0.3487 (0.3127) acc 78.1250 (80.3516) kd_loss 0.8270 (0.8655) lr 1.6845e-03 eta 0:08:30
epoch [15/50] batch [100/160] time 0.090 (0.089) data 0.000 (0.003) loss 0.6682 (0.7681) ce_loss 0.5400 (0.5152) teacher_loss 0.3110 (0.4003) loss_zs_kd 0.1125 (0.1014) loss_oracle 0.3009 (0.3171) acc 78.1250 (80.5000) kd_loss 0.8560 (0.8628) lr 1.6845e-03 eta 0:08:22
epoch [15/50] batch [120/160] time 0.077 (0.088) data 0.000 (0.003) loss 0.6972 (0.7676) ce_loss 0.3811 (0.5168) teacher_loss 0.3367 (0.4012) loss_zs_kd 0.1217 (0.1035) loss_oracle 0.2996 (0.3147) acc 84.3750 (80.5469) kd_loss 0.8739 (0.8601) lr 1.6845e-03 eta 0:08:14
epoch [15/50] batch [140/160] time 0.087 (0.087) data 0.000 (0.002) loss 0.7869 (0.7644) ce_loss 0.5962 (0.5182) teacher_loss 0.4352 (0.4029) loss_zs_kd 0.1141 (0.1028) loss_oracle 0.2946 (0.3102) acc 81.2500 (80.6920) kd_loss 0.8264 (0.8584) lr 1.6845e-03 eta 0:08:09
epoch [15/50] batch [160/160] time 0.075 (0.086) data 0.000 (0.002) loss 0.8713 (0.7733) ce_loss 0.5688 (0.5284) teacher_loss 0.4948 (0.4140) loss_zs_kd 0.0980 (0.1030) loss_oracle 0.3275 (0.3078) acc 78.1250 (80.3125) kd_loss 0.8465 (0.8546) lr 1.6374e-03 eta 0:07:59
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 85.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,017
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 90.0%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.4%, epoch: 15 *******
******* Domain p best val test acc: 89.4%, epoch: 15 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [16/50] batch [20/160] time 0.086 (0.104) data 0.000 (0.019) loss 0.7146 (0.7629) ce_loss 0.5322 (0.5201) teacher_loss 0.3492 (0.3987) loss_zs_kd 0.0876 (0.1024) loss_oracle 0.3215 (0.3130) acc 81.2500 (80.4688) kd_loss 0.7884 (0.8586) lr 1.6374e-03 eta 0:09:39
epoch [16/50] batch [40/160] time 0.083 (0.092) data 0.000 (0.010) loss 0.6198 (0.7488) ce_loss 0.3889 (0.5222) teacher_loss 0.2416 (0.3934) loss_zs_kd 0.0404 (0.0966) loss_oracle 0.3580 (0.3072) acc 84.3750 (81.0156) kd_loss 0.9005 (0.8479) lr 1.6374e-03 eta 0:08:30
epoch [16/50] batch [60/160] time 0.079 (0.087) data 0.001 (0.007) loss 0.6565 (0.7429) ce_loss 0.4304 (0.5126) teacher_loss 0.2975 (0.3856) loss_zs_kd 0.0702 (0.1000) loss_oracle 0.3239 (0.3072) acc 87.5000 (80.7812) kd_loss 0.8954 (0.8499) lr 1.6374e-03 eta 0:08:04
epoch [16/50] batch [80/160] time 0.083 (0.086) data 0.000 (0.005) loss 0.8104 (0.7395) ce_loss 0.4661 (0.5137) teacher_loss 0.4452 (0.3856) loss_zs_kd 0.1108 (0.1008) loss_oracle 0.3097 (0.3035) acc 81.2500 (80.8594) kd_loss 0.8500 (0.8518) lr 1.6374e-03 eta 0:07:54
epoch [16/50] batch [100/160] time 0.077 (0.084) data 0.000 (0.004) loss 0.7286 (0.7460) ce_loss 0.4949 (0.5170) teacher_loss 0.3684 (0.3966) loss_zs_kd 0.1348 (0.1035) loss_oracle 0.2928 (0.2977) acc 75.0000 (80.7812) kd_loss 0.8450 (0.8494) lr 1.6374e-03 eta 0:07:42
epoch [16/50] batch [120/160] time 0.083 (0.083) data 0.000 (0.003) loss 0.6252 (0.7487) ce_loss 0.5078 (0.5219) teacher_loss 0.3296 (0.4054) loss_zs_kd 0.0967 (0.1023) loss_oracle 0.2473 (0.2921) acc 84.3750 (80.5990) kd_loss 0.8532 (0.8472) lr 1.6374e-03 eta 0:07:35
epoch [16/50] batch [140/160] time 0.069 (0.082) data 0.000 (0.003) loss 1.1294 (0.7519) ce_loss 0.9927 (0.5231) teacher_loss 0.7151 (0.4076) loss_zs_kd 0.1113 (0.1024) loss_oracle 0.3587 (0.2931) acc 59.3750 (80.5580) kd_loss 0.8409 (0.8472) lr 1.6374e-03 eta 0:07:26
epoch [16/50] batch [160/160] time 0.072 (0.081) data 0.000 (0.003) loss 0.6423 (0.7529) ce_loss 0.3396 (0.5230) teacher_loss 0.2908 (0.4110) loss_zs_kd 0.0700 (0.1022) loss_oracle 0.3165 (0.2908) acc 90.6250 (80.7031) kd_loss 0.8194 (0.8448) lr 1.5878e-03 eta 0:07:19
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,830
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,989
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.5%
******* Domain p best val acc:      83.4%, epoch: 15 *******
******* Domain p best val test acc: 89.4%, epoch: 15 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [17/50] batch [20/160] time 0.080 (0.099) data 0.000 (0.015) loss 0.7212 (0.7117) ce_loss 0.5405 (0.4878) teacher_loss 0.4202 (0.3875) loss_zs_kd 0.0991 (0.0924) loss_oracle 0.2514 (0.2780) acc 75.0000 (82.1875) kd_loss 0.8606 (0.8308) lr 1.5878e-03 eta 0:08:58
epoch [17/50] batch [40/160] time 0.084 (0.090) data 0.000 (0.008) loss 0.5853 (0.7071) ce_loss 0.3967 (0.4850) teacher_loss 0.2627 (0.3820) loss_zs_kd 0.0948 (0.0973) loss_oracle 0.2752 (0.2764) acc 87.5000 (82.2656) kd_loss 0.8246 (0.8303) lr 1.5878e-03 eta 0:08:05
epoch [17/50] batch [60/160] time 0.083 (0.087) data 0.001 (0.005) loss 0.7425 (0.7180) ce_loss 0.4548 (0.4952) teacher_loss 0.3227 (0.3887) loss_zs_kd 0.1165 (0.0962) loss_oracle 0.3615 (0.2812) acc 81.2500 (81.9271) kd_loss 0.8460 (0.8280) lr 1.5878e-03 eta 0:07:50
epoch [17/50] batch [80/160] time 0.076 (0.086) data 0.000 (0.004) loss 0.9893 (0.7341) ce_loss 0.7725 (0.5124) teacher_loss 0.6290 (0.3997) loss_zs_kd 0.0907 (0.0991) loss_oracle 0.3150 (0.2849) acc 65.6250 (80.7031) kd_loss 0.8382 (0.8297) lr 1.5878e-03 eta 0:07:42
epoch [17/50] batch [100/160] time 0.072 (0.086) data 0.000 (0.003) loss 0.8964 (0.7372) ce_loss 0.5933 (0.5158) teacher_loss 0.5210 (0.3990) loss_zs_kd 0.1101 (0.1015) loss_oracle 0.3203 (0.2875) acc 75.0000 (80.3750) kd_loss 0.8254 (0.8270) lr 1.5878e-03 eta 0:07:36
epoch [17/50] batch [120/160] time 0.082 (0.085) data 0.000 (0.003) loss 0.9261 (0.7424) ce_loss 0.6182 (0.5171) teacher_loss 0.5502 (0.4027) loss_zs_kd 0.1025 (0.1021) loss_oracle 0.3247 (0.2887) acc 81.2500 (80.8073) kd_loss 0.8155 (0.8285) lr 1.5878e-03 eta 0:07:30
epoch [17/50] batch [140/160] time 0.074 (0.084) data 0.000 (0.002) loss 0.8843 (0.7510) ce_loss 0.6040 (0.5248) teacher_loss 0.4613 (0.4067) loss_zs_kd 0.0981 (0.1030) loss_oracle 0.3739 (0.2928) acc 75.0000 (80.5580) kd_loss 0.8342 (0.8274) lr 1.5878e-03 eta 0:07:26
epoch [17/50] batch [160/160] time 0.072 (0.083) data 0.000 (0.002) loss 0.8676 (0.7567) ce_loss 0.5928 (0.5225) teacher_loss 0.5261 (0.4045) loss_zs_kd 0.0815 (0.1042) loss_oracle 0.3008 (0.3001) acc 81.2500 (80.7617) kd_loss 0.8244 (0.8309) lr 1.5358e-03 eta 0:07:17
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,834
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,980
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 89.3%
******* Domain p best val acc:      83.4%, epoch: 15 *******
******* Domain p best val test acc: 89.4%, epoch: 15 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [18/50] batch [20/160] time 0.064 (0.094) data 0.000 (0.018) loss 0.9010 (0.8177) ce_loss 0.5869 (0.5659) teacher_loss 0.4595 (0.4433) loss_zs_kd 0.1156 (0.1109) loss_oracle 0.3837 (0.3190) acc 78.1250 (78.7500) kd_loss 0.8925 (0.8346) lr 1.5358e-03 eta 0:08:13
epoch [18/50] batch [40/160] time 0.070 (0.082) data 0.000 (0.009) loss 0.8649 (0.7886) ce_loss 0.6504 (0.5239) teacher_loss 0.4743 (0.4037) loss_zs_kd 0.1241 (0.1159) loss_oracle 0.3285 (0.3269) acc 75.0000 (79.7656) kd_loss 0.8113 (0.8321) lr 1.5358e-03 eta 0:07:10
epoch [18/50] batch [60/160] time 0.064 (0.077) data 0.001 (0.006) loss 0.9253 (0.7714) ce_loss 0.6494 (0.5027) teacher_loss 0.5248 (0.3927) loss_zs_kd 0.0905 (0.1090) loss_oracle 0.3552 (0.3243) acc 75.0000 (81.2500) kd_loss 0.8257 (0.8277) lr 1.5358e-03 eta 0:06:42
epoch [18/50] batch [80/160] time 0.069 (0.075) data 0.000 (0.005) loss 0.6994 (0.7691) ce_loss 0.3755 (0.5016) teacher_loss 0.3393 (0.3900) loss_zs_kd 0.1488 (0.1086) loss_oracle 0.2857 (0.3249) acc 87.5000 (81.4062) kd_loss 0.7706 (0.8282) lr 1.5358e-03 eta 0:06:28
epoch [18/50] batch [100/160] time 0.079 (0.075) data 0.000 (0.004) loss 0.9971 (0.7627) ce_loss 0.8062 (0.5015) teacher_loss 0.6824 (0.3917) loss_zs_kd 0.0927 (0.1080) loss_oracle 0.2684 (0.3169) acc 81.2500 (81.3750) kd_loss 0.8044 (0.8233) lr 1.5358e-03 eta 0:06:27
epoch [18/50] batch [120/160] time 0.087 (0.076) data 0.000 (0.003) loss 0.7515 (0.7665) ce_loss 0.4641 (0.5098) teacher_loss 0.4237 (0.3993) loss_zs_kd 0.1325 (0.1069) loss_oracle 0.2616 (0.3138) acc 81.2500 (80.9896) kd_loss 0.8111 (0.8195) lr 1.5358e-03 eta 0:06:30
epoch [18/50] batch [140/160] time 0.082 (0.076) data 0.000 (0.003) loss 0.9071 (0.7629) ce_loss 0.7031 (0.5071) teacher_loss 0.6589 (0.3959) loss_zs_kd 0.0911 (0.1057) loss_oracle 0.2026 (0.3141) acc 65.6250 (81.0045) kd_loss 0.7638 (0.8184) lr 1.5358e-03 eta 0:06:32
epoch [18/50] batch [160/160] time 0.071 (0.076) data 0.001 (0.002) loss 1.0894 (0.7634) ce_loss 0.8315 (0.5077) teacher_loss 0.7107 (0.3964) loss_zs_kd 0.1180 (0.1053) loss_oracle 0.3196 (0.3143) acc 71.8750 (80.9375) kd_loss 0.8185 (0.8189) lr 1.4818e-03 eta 0:06:28
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,840
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 84.8%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,985
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.3%
******* Domain p best val acc:      83.4%, epoch: 18 *******
******* Domain p best val test acc: 88.4%, epoch: 18 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [19/50] batch [20/160] time 0.082 (0.107) data 0.000 (0.018) loss 0.7488 (0.7702) ce_loss 0.5068 (0.4921) teacher_loss 0.3571 (0.3907) loss_zs_kd 0.1277 (0.1044) loss_oracle 0.3279 (0.3272) acc 71.8750 (82.1875) kd_loss 0.9013 (0.8144) lr 1.4818e-03 eta 0:09:07
epoch [19/50] batch [40/160] time 0.082 (0.095) data 0.000 (0.009) loss 0.9419 (0.7836) ce_loss 0.7354 (0.5188) teacher_loss 0.4735 (0.4017) loss_zs_kd 0.1339 (0.1085) loss_oracle 0.4015 (0.3276) acc 71.8750 (81.0156) kd_loss 0.7971 (0.8126) lr 1.4818e-03 eta 0:08:03
epoch [19/50] batch [60/160] time 0.089 (0.092) data 0.001 (0.006) loss 0.6131 (0.7892) ce_loss 0.3716 (0.5282) teacher_loss 0.2852 (0.4103) loss_zs_kd 0.0997 (0.1066) loss_oracle 0.2781 (0.3256) acc 87.5000 (80.2604) kd_loss 0.7559 (0.8081) lr 1.4818e-03 eta 0:07:46
epoch [19/50] batch [80/160] time 0.085 (0.090) data 0.000 (0.005) loss 0.9175 (0.7788) ce_loss 0.7695 (0.5140) teacher_loss 0.5394 (0.4048) loss_zs_kd 0.0852 (0.1070) loss_oracle 0.3355 (0.3206) acc 78.1250 (80.4688) kd_loss 0.7956 (0.8064) lr 1.4818e-03 eta 0:07:32
epoch [19/50] batch [100/160] time 0.093 (0.088) data 0.000 (0.004) loss 0.7202 (0.7932) ce_loss 0.6084 (0.5306) teacher_loss 0.3898 (0.4189) loss_zs_kd 0.1417 (0.1062) loss_oracle 0.2595 (0.3211) acc 71.8750 (80.3438) kd_loss 0.8216 (0.8059) lr 1.4818e-03 eta 0:07:21
epoch [19/50] batch [120/160] time 0.086 (0.087) data 0.000 (0.003) loss 0.8822 (0.7841) ce_loss 0.6582 (0.5244) teacher_loss 0.4842 (0.4148) loss_zs_kd 0.1619 (0.1059) loss_oracle 0.3171 (0.3164) acc 75.0000 (80.9375) kd_loss 0.8059 (0.8041) lr 1.4818e-03 eta 0:07:16
epoch [19/50] batch [140/160] time 0.080 (0.087) data 0.000 (0.003) loss 0.5916 (0.7797) ce_loss 0.4797 (0.5239) teacher_loss 0.3213 (0.4135) loss_zs_kd 0.0838 (0.1044) loss_oracle 0.2285 (0.3140) acc 81.2500 (81.1161) kd_loss 0.7740 (0.8024) lr 1.4818e-03 eta 0:07:11
epoch [19/50] batch [160/160] time 0.072 (0.085) data 0.000 (0.003) loss 0.7692 (0.7756) ce_loss 0.4858 (0.5229) teacher_loss 0.4518 (0.4107) loss_zs_kd 0.1232 (0.1050) loss_oracle 0.2559 (0.3124) acc 81.2500 (80.9375) kd_loss 0.7642 (0.8014) lr 1.4258e-03 eta 0:07:03
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,990
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 89.5%
******* Domain p best val acc:      83.4%, epoch: 18 *******
******* Domain p best val test acc: 88.4%, epoch: 18 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [20/50] batch [20/160] time 0.088 (0.102) data 0.000 (0.017) loss 0.7970 (0.7667) ce_loss 0.5737 (0.5194) teacher_loss 0.4885 (0.4110) loss_zs_kd 0.0804 (0.1051) loss_oracle 0.2683 (0.3032) acc 81.2500 (81.0938) kd_loss 0.7718 (0.8084) lr 1.4258e-03 eta 0:08:22
epoch [20/50] batch [40/160] time 0.076 (0.092) data 0.000 (0.009) loss 0.8848 (0.7647) ce_loss 0.5894 (0.5113) teacher_loss 0.5474 (0.4159) loss_zs_kd 0.0762 (0.0975) loss_oracle 0.2993 (0.3001) acc 75.0000 (81.2500) kd_loss 0.7794 (0.8009) lr 1.4258e-03 eta 0:07:32
epoch [20/50] batch [60/160] time 0.092 (0.089) data 0.001 (0.006) loss 0.7309 (0.7591) ce_loss 0.5469 (0.5070) teacher_loss 0.4221 (0.4130) loss_zs_kd 0.0843 (0.0965) loss_oracle 0.2666 (0.2979) acc 81.2500 (81.3021) kd_loss 0.7553 (0.7964) lr 1.4258e-03 eta 0:07:14
epoch [20/50] batch [80/160] time 0.079 (0.087) data 0.000 (0.004) loss 0.7765 (0.7657) ce_loss 0.5239 (0.5180) teacher_loss 0.4634 (0.4205) loss_zs_kd 0.0863 (0.0977) loss_oracle 0.2700 (0.2964) acc 87.5000 (81.2891) kd_loss 0.7327 (0.7923) lr 1.4258e-03 eta 0:07:04
epoch [20/50] batch [100/160] time 0.079 (0.086) data 0.000 (0.004) loss 0.7485 (0.7604) ce_loss 0.4604 (0.5180) teacher_loss 0.3544 (0.4181) loss_zs_kd 0.0976 (0.0966) loss_oracle 0.3452 (0.2939) acc 81.2500 (80.8750) kd_loss 0.7622 (0.7933) lr 1.4258e-03 eta 0:06:59
epoch [20/50] batch [120/160] time 0.080 (0.086) data 0.000 (0.003) loss 0.7497 (0.7641) ce_loss 0.4709 (0.5224) teacher_loss 0.4241 (0.4216) loss_zs_kd 0.1008 (0.0979) loss_oracle 0.2752 (0.2935) acc 90.6250 (81.1198) kd_loss 0.8286 (0.7942) lr 1.4258e-03 eta 0:06:54
epoch [20/50] batch [140/160] time 0.083 (0.085) data 0.000 (0.003) loss 0.6546 (0.7542) ce_loss 0.3123 (0.5111) teacher_loss 0.3118 (0.4112) loss_zs_kd 0.0781 (0.0997) loss_oracle 0.3037 (0.2932) acc 90.6250 (81.3616) kd_loss 0.8232 (0.7933) lr 1.4258e-03 eta 0:06:49
epoch [20/50] batch [160/160] time 0.071 (0.084) data 0.000 (0.002) loss 0.6742 (0.7535) ce_loss 0.4919 (0.5107) teacher_loss 0.3495 (0.4086) loss_zs_kd 0.0700 (0.1006) loss_oracle 0.2897 (0.2946) acc 87.5000 (81.4648) kd_loss 0.7823 (0.7916) lr 1.3681e-03 eta 0:06:42
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,844
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 85.2%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,982
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 89.3%
******* Domain p best val acc:      83.6%, epoch: 20 *******
******* Domain p best val test acc: 88.3%, epoch: 20 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [21/50] batch [20/160] time 0.081 (0.095) data 0.000 (0.014) loss 0.6617 (0.7169) ce_loss 0.4822 (0.4654) teacher_loss 0.3647 (0.3657) loss_zs_kd 0.1187 (0.1033) loss_oracle 0.2377 (0.2995) acc 78.1250 (83.4375) kd_loss 0.7661 (0.7890) lr 1.3681e-03 eta 0:07:33
epoch [21/50] batch [40/160] time 0.085 (0.089) data 0.000 (0.007) loss 0.6447 (0.7487) ce_loss 0.2715 (0.4816) teacher_loss 0.2457 (0.3888) loss_zs_kd 0.0759 (0.1009) loss_oracle 0.3611 (0.3094) acc 87.5000 (81.7188) kd_loss 0.7548 (0.7907) lr 1.3681e-03 eta 0:07:03
epoch [21/50] batch [60/160] time 0.084 (0.088) data 0.000 (0.005) loss 0.7663 (0.7631) ce_loss 0.5151 (0.4934) teacher_loss 0.3943 (0.3986) loss_zs_kd 0.1078 (0.0988) loss_oracle 0.3181 (0.3151) acc 75.0000 (81.6146) kd_loss 0.8379 (0.7925) lr 1.3681e-03 eta 0:06:57
epoch [21/50] batch [80/160] time 0.085 (0.088) data 0.000 (0.004) loss 0.7737 (0.7685) ce_loss 0.5283 (0.4974) teacher_loss 0.3990 (0.4015) loss_zs_kd 0.0897 (0.0998) loss_oracle 0.3298 (0.3170) acc 81.2500 (81.4453) kd_loss 0.7129 (0.7899) lr 1.3681e-03 eta 0:06:57
epoch [21/50] batch [100/160] time 0.085 (0.088) data 0.000 (0.003) loss 0.7340 (0.7640) ce_loss 0.4751 (0.4984) teacher_loss 0.3956 (0.4001) loss_zs_kd 0.1015 (0.1006) loss_oracle 0.2876 (0.3136) acc 84.3750 (81.5625) kd_loss 0.7366 (0.7879) lr 1.3681e-03 eta 0:06:53
epoch [21/50] batch [120/160] time 0.083 (0.088) data 0.000 (0.003) loss 0.7390 (0.7682) ce_loss 0.4897 (0.5020) teacher_loss 0.3680 (0.4024) loss_zs_kd 0.0934 (0.1001) loss_oracle 0.3243 (0.3157) acc 81.2500 (81.4323) kd_loss 0.8071 (0.7898) lr 1.3681e-03 eta 0:06:49
epoch [21/50] batch [140/160] time 0.093 (0.087) data 0.000 (0.002) loss 0.9054 (0.7701) ce_loss 0.6045 (0.5049) teacher_loss 0.4132 (0.4055) loss_zs_kd 0.1493 (0.1011) loss_oracle 0.4175 (0.3140) acc 81.2500 (81.2946) kd_loss 0.7699 (0.7876) lr 1.3681e-03 eta 0:06:47
epoch [21/50] batch [160/160] time 0.079 (0.087) data 0.000 (0.002) loss 0.7322 (0.7709) ce_loss 0.4509 (0.5088) teacher_loss 0.4521 (0.4098) loss_zs_kd 0.1041 (0.1008) loss_oracle 0.2280 (0.3107) acc 81.2500 (81.0938) kd_loss 0.7493 (0.7849) lr 1.3090e-03 eta 0:06:41
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,845
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 85.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,997
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 89.6%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 88.8%, epoch: 21 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [22/50] batch [20/160] time 0.080 (0.098) data 0.000 (0.015) loss 0.7508 (0.7554) ce_loss 0.5303 (0.5091) teacher_loss 0.3977 (0.4073) loss_zs_kd 0.1255 (0.0990) loss_oracle 0.2903 (0.2986) acc 78.1250 (83.2812) kd_loss 0.7652 (0.7806) lr 1.3090e-03 eta 0:07:31
epoch [22/50] batch [40/160] time 0.089 (0.089) data 0.001 (0.008) loss 0.6964 (0.7474) ce_loss 0.4077 (0.5169) teacher_loss 0.3048 (0.4143) loss_zs_kd 0.0849 (0.0970) loss_oracle 0.3491 (0.2846) acc 84.3750 (82.5781) kd_loss 0.7929 (0.7770) lr 1.3090e-03 eta 0:06:47
epoch [22/50] batch [60/160] time 0.080 (0.087) data 0.000 (0.005) loss 0.5184 (0.7479) ce_loss 0.3005 (0.5183) teacher_loss 0.2531 (0.4181) loss_zs_kd 0.0646 (0.0993) loss_oracle 0.2330 (0.2802) acc 90.6250 (82.1875) kd_loss 0.7026 (0.7758) lr 1.3090e-03 eta 0:06:36
epoch [22/50] batch [80/160] time 0.086 (0.086) data 0.000 (0.004) loss 0.6625 (0.7453) ce_loss 0.3672 (0.5158) teacher_loss 0.2858 (0.4105) loss_zs_kd 0.1632 (0.1016) loss_oracle 0.2951 (0.2840) acc 84.3750 (82.0703) kd_loss 0.8046 (0.7774) lr 1.3090e-03 eta 0:06:31
epoch [22/50] batch [100/160] time 0.084 (0.086) data 0.000 (0.003) loss 0.7737 (0.7419) ce_loss 0.6548 (0.5101) teacher_loss 0.4308 (0.4050) loss_zs_kd 0.0851 (0.1010) loss_oracle 0.3004 (0.2864) acc 78.1250 (81.9688) kd_loss 0.7770 (0.7801) lr 1.3090e-03 eta 0:06:28
epoch [22/50] batch [120/160] time 0.084 (0.085) data 0.000 (0.003) loss 0.7451 (0.7428) ce_loss 0.5391 (0.5085) teacher_loss 0.4214 (0.4035) loss_zs_kd 0.1049 (0.1011) loss_oracle 0.2712 (0.2887) acc 84.3750 (82.0573) kd_loss 0.7487 (0.7797) lr 1.3090e-03 eta 0:06:25
epoch [22/50] batch [140/160] time 0.082 (0.085) data 0.000 (0.002) loss 0.6627 (0.7425) ce_loss 0.3508 (0.5048) teacher_loss 0.3037 (0.4006) loss_zs_kd 0.1237 (0.1005) loss_oracle 0.2971 (0.2917) acc 87.5000 (82.0982) kd_loss 0.7243 (0.7813) lr 1.3090e-03 eta 0:06:22
epoch [22/50] batch [160/160] time 0.072 (0.084) data 0.000 (0.002) loss 0.8139 (0.7478) ce_loss 0.5200 (0.5047) teacher_loss 0.4528 (0.3997) loss_zs_kd 0.1040 (0.1021) loss_oracle 0.3091 (0.2971) acc 78.1250 (81.9336) kd_loss 0.7665 (0.7824) lr 1.2487e-03 eta 0:06:14
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,845
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,995
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 89.5%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 88.8%, epoch: 21 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [23/50] batch [20/160] time 0.070 (0.098) data 0.000 (0.018) loss 0.7858 (0.7463) ce_loss 0.4797 (0.4835) teacher_loss 0.3729 (0.3931) loss_zs_kd 0.1625 (0.0989) loss_oracle 0.3317 (0.3037) acc 90.6250 (82.5000) kd_loss 0.7878 (0.7877) lr 1.2487e-03 eta 0:07:17
epoch [23/50] batch [40/160] time 0.083 (0.092) data 0.000 (0.009) loss 0.7981 (0.7541) ce_loss 0.5215 (0.4943) teacher_loss 0.4758 (0.3899) loss_zs_kd 0.1296 (0.1003) loss_oracle 0.2574 (0.3140) acc 84.3750 (82.1875) kd_loss 0.7866 (0.7870) lr 1.2487e-03 eta 0:06:49
epoch [23/50] batch [60/160] time 0.073 (0.089) data 0.000 (0.006) loss 0.9121 (0.7636) ce_loss 0.7036 (0.5114) teacher_loss 0.5896 (0.4061) loss_zs_kd 0.0927 (0.1042) loss_oracle 0.2761 (0.3055) acc 65.6250 (80.8854) kd_loss 0.7712 (0.7807) lr 1.2487e-03 eta 0:06:34
epoch [23/50] batch [80/160] time 0.088 (0.087) data 0.000 (0.005) loss 0.8742 (0.7480) ce_loss 0.5532 (0.4968) teacher_loss 0.4619 (0.3911) loss_zs_kd 0.1404 (0.1030) loss_oracle 0.3422 (0.3054) acc 81.2500 (81.7969) kd_loss 0.7739 (0.7770) lr 1.2487e-03 eta 0:06:22
epoch [23/50] batch [100/160] time 0.072 (0.086) data 0.000 (0.004) loss 0.6953 (0.7573) ce_loss 0.5386 (0.5074) teacher_loss 0.3008 (0.3969) loss_zs_kd 0.1046 (0.1055) loss_oracle 0.3422 (0.3076) acc 81.2500 (81.2812) kd_loss 0.7888 (0.7790) lr 1.2487e-03 eta 0:06:14
epoch [23/50] batch [120/160] time 0.081 (0.084) data 0.000 (0.003) loss 0.6991 (0.7631) ce_loss 0.3000 (0.5108) teacher_loss 0.2297 (0.3967) loss_zs_kd 0.0861 (0.1085) loss_oracle 0.4263 (0.3122) acc 90.6250 (81.0938) kd_loss 0.8351 (0.7789) lr 1.2487e-03 eta 0:06:08
epoch [23/50] batch [140/160] time 0.092 (0.084) data 0.000 (0.003) loss 0.8036 (0.7651) ce_loss 0.4822 (0.5097) teacher_loss 0.3987 (0.3965) loss_zs_kd 0.1325 (0.1093) loss_oracle 0.3386 (0.3140) acc 75.0000 (80.9598) kd_loss 0.7838 (0.7792) lr 1.2487e-03 eta 0:06:03
epoch [23/50] batch [160/160] time 0.071 (0.083) data 0.000 (0.002) loss 0.7728 (0.7667) ce_loss 0.4700 (0.5058) teacher_loss 0.3599 (0.3942) loss_zs_kd 0.1060 (0.1099) loss_oracle 0.3599 (0.3176) acc 84.3750 (81.1914) kd_loss 0.8142 (0.7801) lr 1.1874e-03 eta 0:05:58
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,848
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.3%
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,991
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [24/50] batch [20/160] time 0.093 (0.106) data 0.000 (0.015) loss 0.8594 (0.7880) ce_loss 0.5605 (0.5159) teacher_loss 0.5080 (0.4134) loss_zs_kd 0.0810 (0.1011) loss_oracle 0.3109 (0.3240) acc 84.3750 (80.4688) kd_loss 0.7289 (0.7768) lr 1.1874e-03 eta 0:07:35
epoch [24/50] batch [40/160] time 0.078 (0.097) data 0.000 (0.008) loss 0.8767 (0.7803) ce_loss 0.5435 (0.5137) teacher_loss 0.4463 (0.3973) loss_zs_kd 0.1121 (0.1051) loss_oracle 0.3743 (0.3304) acc 78.1250 (80.7031) kd_loss 0.8312 (0.7833) lr 1.1874e-03 eta 0:06:56
epoch [24/50] batch [60/160] time 0.089 (0.094) data 0.000 (0.005) loss 0.9303 (0.7771) ce_loss 0.6392 (0.5064) teacher_loss 0.4981 (0.3962) loss_zs_kd 0.0987 (0.1038) loss_oracle 0.3829 (0.3290) acc 90.6250 (81.4062) kd_loss 0.7744 (0.7785) lr 1.1874e-03 eta 0:06:38
epoch [24/50] batch [80/160] time 0.093 (0.093) data 0.000 (0.004) loss 0.9162 (0.7737) ce_loss 0.8203 (0.5062) teacher_loss 0.5270 (0.3957) loss_zs_kd 0.0964 (0.1009) loss_oracle 0.3411 (0.3276) acc 71.8750 (81.4453) kd_loss 0.7752 (0.7797) lr 1.1874e-03 eta 0:06:32
epoch [24/50] batch [100/160] time 0.087 (0.092) data 0.000 (0.003) loss 0.8434 (0.7779) ce_loss 0.6094 (0.5083) teacher_loss 0.4213 (0.4004) loss_zs_kd 0.1468 (0.1013) loss_oracle 0.3487 (0.3269) acc 71.8750 (81.5938) kd_loss 0.7552 (0.7796) lr 1.1874e-03 eta 0:06:28
epoch [24/50] batch [120/160] time 0.088 (0.091) data 0.000 (0.003) loss 0.8510 (0.7771) ce_loss 0.5557 (0.5083) teacher_loss 0.4627 (0.3997) loss_zs_kd 0.1119 (0.1024) loss_oracle 0.3323 (0.3262) acc 87.5000 (81.3281) kd_loss 0.7870 (0.7762) lr 1.1874e-03 eta 0:06:23
epoch [24/50] batch [140/160] time 0.087 (0.091) data 0.000 (0.003) loss 0.8870 (0.7818) ce_loss 0.6792 (0.5118) teacher_loss 0.5114 (0.4000) loss_zs_kd 0.1069 (0.1047) loss_oracle 0.3221 (0.3295) acc 75.0000 (81.2946) kd_loss 0.7631 (0.7786) lr 1.1874e-03 eta 0:06:19
epoch [24/50] batch [160/160] time 0.073 (0.089) data 0.000 (0.002) loss 0.8135 (0.7831) ce_loss 0.4478 (0.5066) teacher_loss 0.3644 (0.3961) loss_zs_kd 0.1073 (0.1077) loss_oracle 0.3954 (0.3331) acc 75.0000 (81.4648) kd_loss 0.7766 (0.7789) lr 1.1253e-03 eta 0:06:12
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,846
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,985
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [25/50] batch [20/160] time 0.081 (0.095) data 0.000 (0.013) loss 0.8252 (0.7717) ce_loss 0.5039 (0.4820) teacher_loss 0.4480 (0.3791) loss_zs_kd 0.0799 (0.1063) loss_oracle 0.3372 (0.3395) acc 84.3750 (82.8125) kd_loss 0.8065 (0.7758) lr 1.1253e-03 eta 0:06:35
epoch [25/50] batch [40/160] time 0.077 (0.088) data 0.000 (0.007) loss 0.7864 (0.7888) ce_loss 0.4521 (0.4848) teacher_loss 0.2753 (0.3809) loss_zs_kd 0.1119 (0.1051) loss_oracle 0.4552 (0.3554) acc 81.2500 (82.1875) kd_loss 0.7775 (0.7843) lr 1.1253e-03 eta 0:06:03
epoch [25/50] batch [60/160] time 0.088 (0.086) data 0.001 (0.005) loss 0.6176 (0.7890) ce_loss 0.2913 (0.4820) teacher_loss 0.2402 (0.3814) loss_zs_kd 0.0822 (0.1068) loss_oracle 0.3363 (0.3542) acc 90.6250 (82.3958) kd_loss 0.8088 (0.7848) lr 1.1253e-03 eta 0:05:52
epoch [25/50] batch [80/160] time 0.081 (0.086) data 0.000 (0.004) loss 0.7338 (0.7779) ce_loss 0.3655 (0.4693) teacher_loss 0.2824 (0.3675) loss_zs_kd 0.1315 (0.1079) loss_oracle 0.3856 (0.3564) acc 87.5000 (83.3594) kd_loss 0.8333 (0.7866) lr 1.1253e-03 eta 0:05:49
epoch [25/50] batch [100/160] time 0.083 (0.085) data 0.000 (0.003) loss 0.7695 (0.7903) ce_loss 0.5200 (0.4887) teacher_loss 0.3455 (0.3813) loss_zs_kd 0.1005 (0.1104) loss_oracle 0.3738 (0.3538) acc 81.2500 (82.3750) kd_loss 0.7375 (0.7825) lr 1.1253e-03 eta 0:05:45
epoch [25/50] batch [120/160] time 0.083 (0.086) data 0.000 (0.002) loss 0.8776 (0.8005) ce_loss 0.5728 (0.4997) teacher_loss 0.4834 (0.3893) loss_zs_kd 0.1215 (0.1130) loss_oracle 0.3334 (0.3546) acc 84.3750 (81.7708) kd_loss 0.7272 (0.7805) lr 1.1253e-03 eta 0:05:45
epoch [25/50] batch [140/160] time 0.086 (0.085) data 0.000 (0.002) loss 0.7200 (0.8010) ce_loss 0.4048 (0.5021) teacher_loss 0.3692 (0.3924) loss_zs_kd 0.0667 (0.1109) loss_oracle 0.3175 (0.3531) acc 84.3750 (81.6741) kd_loss 0.7324 (0.7811) lr 1.1253e-03 eta 0:05:42
epoch [25/50] batch [160/160] time 0.072 (0.084) data 0.000 (0.002) loss 0.7615 (0.8008) ce_loss 0.5850 (0.5029) teacher_loss 0.3854 (0.3910) loss_zs_kd 0.1012 (0.1112) loss_oracle 0.3256 (0.3542) acc 75.0000 (81.6406) kd_loss 0.7627 (0.7806) lr 1.0628e-03 eta 0:05:36
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,840
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,987
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [26/50] batch [20/160] time 0.090 (0.093) data 0.000 (0.013) loss 0.7854 (0.8002) ce_loss 0.4868 (0.5298) teacher_loss 0.3381 (0.4050) loss_zs_kd 0.1240 (0.1137) loss_oracle 0.3854 (0.3384) acc 78.1250 (78.2812) kd_loss 0.8398 (0.7744) lr 1.0628e-03 eta 0:06:11
epoch [26/50] batch [40/160] time 0.078 (0.087) data 0.000 (0.007) loss 0.9158 (0.8056) ce_loss 0.5693 (0.5315) teacher_loss 0.5015 (0.4062) loss_zs_kd 0.1140 (0.1141) loss_oracle 0.3573 (0.3424) acc 75.0000 (79.2969) kd_loss 0.7850 (0.7735) lr 1.0628e-03 eta 0:05:45
epoch [26/50] batch [60/160] time 0.082 (0.085) data 0.000 (0.004) loss 0.5949 (0.8029) ce_loss 0.4695 (0.5326) teacher_loss 0.2948 (0.4044) loss_zs_kd 0.1069 (0.1115) loss_oracle 0.2466 (0.3428) acc 78.1250 (79.2708) kd_loss 0.7431 (0.7733) lr 1.0628e-03 eta 0:05:36
epoch [26/50] batch [80/160] time 0.080 (0.084) data 0.000 (0.003) loss 0.7371 (0.7945) ce_loss 0.4819 (0.5190) teacher_loss 0.3685 (0.3966) loss_zs_kd 0.1395 (0.1129) loss_oracle 0.2988 (0.3414) acc 78.1250 (80.2344) kd_loss 0.8232 (0.7757) lr 1.0628e-03 eta 0:05:30
epoch [26/50] batch [100/160] time 0.079 (0.084) data 0.000 (0.003) loss 0.7786 (0.7860) ce_loss 0.3975 (0.5112) teacher_loss 0.3434 (0.3940) loss_zs_kd 0.0999 (0.1102) loss_oracle 0.3852 (0.3369) acc 81.2500 (80.7812) kd_loss 0.7998 (0.7730) lr 1.0628e-03 eta 0:05:26
epoch [26/50] batch [120/160] time 0.089 (0.084) data 0.000 (0.002) loss 0.8138 (0.7755) ce_loss 0.5845 (0.4987) teacher_loss 0.3893 (0.3823) loss_zs_kd 0.1509 (0.1122) loss_oracle 0.3491 (0.3371) acc 78.1250 (81.5625) kd_loss 0.7759 (0.7749) lr 1.0628e-03 eta 0:05:24
epoch [26/50] batch [140/160] time 0.081 (0.084) data 0.000 (0.002) loss 0.8673 (0.7748) ce_loss 0.5479 (0.5012) teacher_loss 0.4882 (0.3823) loss_zs_kd 0.1046 (0.1140) loss_oracle 0.3268 (0.3355) acc 81.2500 (81.4955) kd_loss 0.7551 (0.7740) lr 1.0628e-03 eta 0:05:25
epoch [26/50] batch [160/160] time 0.077 (0.083) data 0.001 (0.002) loss 0.7977 (0.7740) ce_loss 0.5889 (0.5042) teacher_loss 0.4083 (0.3855) loss_zs_kd 0.1231 (0.1142) loss_oracle 0.3279 (0.3313) acc 78.1250 (81.4648) kd_loss 0.7163 (0.7742) lr 1.0000e-03 eta 0:05:19
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,984
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.2%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [27/50] batch [20/160] time 0.082 (0.095) data 0.000 (0.013) loss 0.6244 (0.7229) ce_loss 0.2747 (0.4844) teacher_loss 0.2192 (0.3580) loss_zs_kd 0.1303 (0.1019) loss_oracle 0.3400 (0.3139) acc 96.8750 (82.5000) kd_loss 0.7899 (0.7809) lr 1.0000e-03 eta 0:06:01
epoch [27/50] batch [40/160] time 0.088 (0.089) data 0.000 (0.007) loss 0.8624 (0.7495) ce_loss 0.6099 (0.4923) teacher_loss 0.5453 (0.3778) loss_zs_kd 0.1195 (0.1054) loss_oracle 0.2574 (0.3190) acc 75.0000 (81.7188) kd_loss 0.7780 (0.7810) lr 1.0000e-03 eta 0:05:39
epoch [27/50] batch [60/160] time 0.082 (0.088) data 0.000 (0.005) loss 0.6139 (0.7583) ce_loss 0.2827 (0.4968) teacher_loss 0.1899 (0.3750) loss_zs_kd 0.1281 (0.1088) loss_oracle 0.3600 (0.3289) acc 90.6250 (81.6667) kd_loss 0.7352 (0.7847) lr 1.0000e-03 eta 0:05:31
epoch [27/50] batch [80/160] time 0.081 (0.086) data 0.000 (0.004) loss 0.7237 (0.7637) ce_loss 0.4622 (0.4959) teacher_loss 0.3607 (0.3791) loss_zs_kd 0.1034 (0.1080) loss_oracle 0.3113 (0.3306) acc 81.2500 (81.6797) kd_loss 0.7601 (0.7836) lr 1.0000e-03 eta 0:05:25
epoch [27/50] batch [100/160] time 0.083 (0.086) data 0.000 (0.003) loss 0.7567 (0.7693) ce_loss 0.4680 (0.5039) teacher_loss 0.3131 (0.3843) loss_zs_kd 0.1424 (0.1055) loss_oracle 0.3724 (0.3323) acc 81.2500 (81.3750) kd_loss 0.7862 (0.7843) lr 1.0000e-03 eta 0:05:21
epoch [27/50] batch [120/160] time 0.082 (0.086) data 0.000 (0.002) loss 0.6484 (0.7701) ce_loss 0.3848 (0.5051) teacher_loss 0.3278 (0.3836) loss_zs_kd 0.0966 (0.1081) loss_oracle 0.2723 (0.3325) acc 81.2500 (81.3281) kd_loss 0.7422 (0.7815) lr 1.0000e-03 eta 0:05:19
epoch [27/50] batch [140/160] time 0.089 (0.085) data 0.000 (0.002) loss 0.7499 (0.7735) ce_loss 0.4182 (0.5081) teacher_loss 0.2920 (0.3860) loss_zs_kd 0.1418 (0.1095) loss_oracle 0.3871 (0.3328) acc 87.5000 (81.4732) kd_loss 0.8160 (0.7807) lr 1.0000e-03 eta 0:05:15
epoch [27/50] batch [160/160] time 0.072 (0.084) data 0.000 (0.002) loss 1.0680 (0.7674) ce_loss 0.8613 (0.5040) teacher_loss 0.6864 (0.3830) loss_zs_kd 0.1319 (0.1102) loss_oracle 0.3157 (0.3293) acc 59.3750 (81.5234) kd_loss 0.7523 (0.7784) lr 9.3721e-04 eta 0:05:08
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,848
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,988
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [28/50] batch [20/160] time 0.068 (0.090) data 0.000 (0.013) loss 0.6044 (0.7547) ce_loss 0.3770 (0.4723) teacher_loss 0.3296 (0.3802) loss_zs_kd 0.0890 (0.1198) loss_oracle 0.2303 (0.3146) acc 84.3750 (82.8125) kd_loss 0.7709 (0.7627) lr 9.3721e-04 eta 0:05:28
epoch [28/50] batch [40/160] time 0.060 (0.083) data 0.000 (0.007) loss 0.7927 (0.7630) ce_loss 0.5327 (0.4933) teacher_loss 0.4271 (0.3823) loss_zs_kd 0.0972 (0.1133) loss_oracle 0.3170 (0.3241) acc 78.1250 (81.9531) kd_loss 0.7955 (0.7664) lr 9.3721e-04 eta 0:05:03
epoch [28/50] batch [60/160] time 0.060 (0.080) data 0.000 (0.004) loss 0.6834 (0.7691) ce_loss 0.2849 (0.4944) teacher_loss 0.1949 (0.3826) loss_zs_kd 0.1182 (0.1133) loss_oracle 0.4294 (0.3299) acc 90.6250 (81.7708) kd_loss 0.8072 (0.7653) lr 9.3721e-04 eta 0:04:48
epoch [28/50] batch [80/160] time 0.080 (0.078) data 0.000 (0.003) loss 0.7628 (0.7670) ce_loss 0.4326 (0.4902) teacher_loss 0.3621 (0.3814) loss_zs_kd 0.1109 (0.1136) loss_oracle 0.3453 (0.3288) acc 84.3750 (81.8750) kd_loss 0.7203 (0.7673) lr 9.3721e-04 eta 0:04:39
epoch [28/50] batch [100/160] time 0.072 (0.077) data 0.000 (0.003) loss 0.7358 (0.7710) ce_loss 0.4312 (0.5007) teacher_loss 0.3409 (0.3834) loss_zs_kd 0.1243 (0.1130) loss_oracle 0.3327 (0.3311) acc 81.2500 (81.6562) kd_loss 0.7193 (0.7659) lr 9.3721e-04 eta 0:04:34
epoch [28/50] batch [120/160] time 0.071 (0.077) data 0.000 (0.002) loss 0.8972 (0.7761) ce_loss 0.5176 (0.5027) teacher_loss 0.4979 (0.3855) loss_zs_kd 0.0879 (0.1126) loss_oracle 0.3555 (0.3343) acc 78.1250 (81.4323) kd_loss 0.8303 (0.7680) lr 9.3721e-04 eta 0:04:32
epoch [28/50] batch [140/160] time 0.057 (0.076) data 0.000 (0.002) loss 0.6803 (0.7762) ce_loss 0.4500 (0.5001) teacher_loss 0.2470 (0.3825) loss_zs_kd 0.1415 (0.1139) loss_oracle 0.3626 (0.3368) acc 87.5000 (81.7188) kd_loss 0.8052 (0.7688) lr 9.3721e-04 eta 0:04:27
epoch [28/50] batch [160/160] time 0.070 (0.075) data 0.000 (0.002) loss 0.7401 (0.7795) ce_loss 0.4453 (0.5041) teacher_loss 0.3139 (0.3858) loss_zs_kd 0.0869 (0.1138) loss_oracle 0.3827 (0.3368) acc 84.3750 (81.6211) kd_loss 0.8219 (0.7685) lr 8.7467e-04 eta 0:04:23
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,842
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,992
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [29/50] batch [20/160] time 0.089 (0.103) data 0.000 (0.014) loss 0.7717 (0.7847) ce_loss 0.5146 (0.5192) teacher_loss 0.3934 (0.3996) loss_zs_kd 0.1837 (0.1131) loss_oracle 0.2864 (0.3286) acc 81.2500 (80.1562) kd_loss 0.7297 (0.7510) lr 8.7467e-04 eta 0:05:59
epoch [29/50] batch [40/160] time 0.088 (0.095) data 0.000 (0.007) loss 0.8134 (0.7716) ce_loss 0.4829 (0.4959) teacher_loss 0.3686 (0.3772) loss_zs_kd 0.1007 (0.1137) loss_oracle 0.3945 (0.3376) acc 84.3750 (81.3281) kd_loss 0.8504 (0.7636) lr 8.7467e-04 eta 0:05:32
epoch [29/50] batch [60/160] time 0.082 (0.092) data 0.001 (0.005) loss 0.7739 (0.7539) ce_loss 0.5332 (0.4803) teacher_loss 0.4261 (0.3620) loss_zs_kd 0.0971 (0.1128) loss_oracle 0.2993 (0.3355) acc 78.1250 (82.1354) kd_loss 0.8020 (0.7645) lr 8.7467e-04 eta 0:05:19
epoch [29/50] batch [80/160] time 0.069 (0.090) data 0.000 (0.004) loss 0.7041 (0.7544) ce_loss 0.3398 (0.4835) teacher_loss 0.2247 (0.3659) loss_zs_kd 0.0914 (0.1122) loss_oracle 0.4336 (0.3324) acc 87.5000 (82.1094) kd_loss 0.8635 (0.7660) lr 8.7467e-04 eta 0:05:08
epoch [29/50] batch [100/160] time 0.078 (0.088) data 0.000 (0.003) loss 0.8666 (0.7603) ce_loss 0.5679 (0.4892) teacher_loss 0.4430 (0.3712) loss_zs_kd 0.1317 (0.1124) loss_oracle 0.3578 (0.3329) acc 81.2500 (82.0625) kd_loss 0.7983 (0.7682) lr 8.7467e-04 eta 0:05:01
epoch [29/50] batch [120/160] time 0.075 (0.087) data 0.000 (0.003) loss 0.8568 (0.7734) ce_loss 0.5410 (0.4971) teacher_loss 0.5014 (0.3782) loss_zs_kd 0.1428 (0.1146) loss_oracle 0.2840 (0.3379) acc 78.1250 (81.3802) kd_loss 0.6961 (0.7707) lr 8.7467e-04 eta 0:04:55
epoch [29/50] batch [140/160] time 0.087 (0.086) data 0.001 (0.002) loss 0.9746 (0.7802) ce_loss 0.6904 (0.5032) teacher_loss 0.5795 (0.3839) loss_zs_kd 0.0943 (0.1148) loss_oracle 0.3479 (0.3388) acc 78.1250 (81.1607) kd_loss 0.7809 (0.7709) lr 8.7467e-04 eta 0:04:50
epoch [29/50] batch [160/160] time 0.073 (0.084) data 0.000 (0.002) loss 0.7969 (0.7827) ce_loss 0.4810 (0.5041) teacher_loss 0.3613 (0.3843) loss_zs_kd 0.1099 (0.1146) loss_oracle 0.3806 (0.3412) acc 78.1250 (81.1914) kd_loss 0.8000 (0.7720) lr 8.1262e-04 eta 0:04:43
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,837
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,986
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [30/50] batch [20/160] time 0.076 (0.098) data 0.000 (0.016) loss 0.9972 (0.8090) ce_loss 0.6543 (0.5435) teacher_loss 0.5359 (0.3983) loss_zs_kd 0.1500 (0.1150) loss_oracle 0.3864 (0.3533) acc 75.0000 (79.8438) kd_loss 0.8160 (0.7709) lr 8.1262e-04 eta 0:05:27
epoch [30/50] batch [40/160] time 0.070 (0.086) data 0.000 (0.008) loss 0.8731 (0.7889) ce_loss 0.5522 (0.4959) teacher_loss 0.4429 (0.3696) loss_zs_kd 0.1096 (0.1181) loss_oracle 0.3753 (0.3603) acc 75.0000 (82.1094) kd_loss 0.8599 (0.7841) lr 8.1262e-04 eta 0:04:44
epoch [30/50] batch [60/160] time 0.075 (0.082) data 0.001 (0.005) loss 0.6857 (0.7847) ce_loss 0.4011 (0.4991) teacher_loss 0.2330 (0.3713) loss_zs_kd 0.0985 (0.1178) loss_oracle 0.4035 (0.3545) acc 90.6250 (82.3438) kd_loss 0.8185 (0.7802) lr 8.1262e-04 eta 0:04:29
epoch [30/50] batch [80/160] time 0.067 (0.081) data 0.000 (0.004) loss 0.9557 (0.7970) ce_loss 0.6694 (0.5104) teacher_loss 0.4657 (0.3840) loss_zs_kd 0.1420 (0.1194) loss_oracle 0.4189 (0.3533) acc 68.7500 (81.8359) kd_loss 0.7905 (0.7748) lr 8.1262e-04 eta 0:04:24
epoch [30/50] batch [100/160] time 0.075 (0.079) data 0.000 (0.003) loss 0.7390 (0.7945) ce_loss 0.4543 (0.5038) teacher_loss 0.3705 (0.3801) loss_zs_kd 0.1346 (0.1202) loss_oracle 0.3012 (0.3543) acc 81.2500 (81.5938) kd_loss 0.8278 (0.7775) lr 8.1262e-04 eta 0:04:18
epoch [30/50] batch [120/160] time 0.062 (0.079) data 0.000 (0.003) loss 0.5965 (0.7920) ce_loss 0.2649 (0.4995) teacher_loss 0.2049 (0.3771) loss_zs_kd 0.0991 (0.1208) loss_oracle 0.3422 (0.3545) acc 93.7500 (81.7969) kd_loss 0.6890 (0.7767) lr 8.1262e-04 eta 0:04:16
epoch [30/50] batch [140/160] time 0.071 (0.077) data 0.000 (0.003) loss 0.7861 (0.7931) ce_loss 0.5498 (0.4988) teacher_loss 0.3680 (0.3757) loss_zs_kd 0.1308 (0.1213) loss_oracle 0.3527 (0.3567) acc 84.3750 (81.8080) kd_loss 0.7898 (0.7790) lr 8.1262e-04 eta 0:04:07
epoch [30/50] batch [160/160] time 0.077 (0.076) data 0.000 (0.002) loss 0.9164 (0.7953) ce_loss 0.7573 (0.5032) teacher_loss 0.5190 (0.3786) loss_zs_kd 0.1177 (0.1219) loss_oracle 0.3386 (0.3558) acc 71.8750 (81.6211) kd_loss 0.7695 (0.7792) lr 7.5131e-04 eta 0:04:04
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,992
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [31/50] batch [20/160] time 0.080 (0.095) data 0.000 (0.015) loss 1.0170 (0.7786) ce_loss 0.7412 (0.5021) teacher_loss 0.5665 (0.3596) loss_zs_kd 0.1552 (0.1166) loss_oracle 0.3729 (0.3607) acc 81.2500 (83.1250) kd_loss 0.7709 (0.7842) lr 7.5131e-04 eta 0:05:03
epoch [31/50] batch [40/160] time 0.087 (0.089) data 0.000 (0.007) loss 0.7277 (0.8192) ce_loss 0.4133 (0.5289) teacher_loss 0.2853 (0.3933) loss_zs_kd 0.1301 (0.1267) loss_oracle 0.3774 (0.3625) acc 84.3750 (80.9375) kd_loss 0.7647 (0.7822) lr 7.5131e-04 eta 0:04:42
epoch [31/50] batch [60/160] time 0.080 (0.087) data 0.000 (0.005) loss 0.7152 (0.7931) ce_loss 0.5474 (0.5120) teacher_loss 0.2909 (0.3700) loss_zs_kd 0.1522 (0.1266) loss_oracle 0.3483 (0.3598) acc 75.0000 (81.1458) kd_loss 0.7403 (0.7773) lr 7.5131e-04 eta 0:04:33
epoch [31/50] batch [80/160] time 0.083 (0.086) data 0.000 (0.004) loss 0.7649 (0.7939) ce_loss 0.4048 (0.5134) teacher_loss 0.2759 (0.3684) loss_zs_kd 0.1714 (0.1292) loss_oracle 0.4034 (0.3609) acc 84.3750 (81.1328) kd_loss 0.8114 (0.7780) lr 7.5131e-04 eta 0:04:29
epoch [31/50] batch [100/160] time 0.078 (0.085) data 0.000 (0.003) loss 0.6496 (0.7913) ce_loss 0.2878 (0.5060) teacher_loss 0.2327 (0.3652) loss_zs_kd 0.1059 (0.1295) loss_oracle 0.3639 (0.3614) acc 87.5000 (81.4688) kd_loss 0.8189 (0.7818) lr 7.5131e-04 eta 0:04:22
epoch [31/50] batch [120/160] time 0.083 (0.083) data 0.000 (0.003) loss 0.8820 (0.7958) ce_loss 0.7900 (0.5093) teacher_loss 0.5515 (0.3676) loss_zs_kd 0.1171 (0.1277) loss_oracle 0.2720 (0.3644) acc 71.8750 (81.5104) kd_loss 0.7540 (0.7864) lr 7.5131e-04 eta 0:04:16
epoch [31/50] batch [140/160] time 0.077 (0.082) data 0.000 (0.002) loss 0.7535 (0.7957) ce_loss 0.4739 (0.5084) teacher_loss 0.3660 (0.3666) loss_zs_kd 0.0964 (0.1277) loss_oracle 0.3393 (0.3651) acc 84.3750 (81.4286) kd_loss 0.7699 (0.7861) lr 7.5131e-04 eta 0:04:12
epoch [31/50] batch [160/160] time 0.071 (0.081) data 0.000 (0.002) loss 0.7349 (0.7904) ce_loss 0.3511 (0.5021) teacher_loss 0.2063 (0.3628) loss_zs_kd 0.2115 (0.1286) loss_oracle 0.4229 (0.3633) acc 90.6250 (81.6602) kd_loss 0.8757 (0.7859) lr 6.9098e-04 eta 0:04:06
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,987
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [32/50] batch [20/160] time 0.079 (0.091) data 0.000 (0.013) loss 0.7058 (0.7542) ce_loss 0.4001 (0.4650) teacher_loss 0.2270 (0.3370) loss_zs_kd 0.1171 (0.1159) loss_oracle 0.4202 (0.3593) acc 84.3750 (83.5938) kd_loss 0.7813 (0.7857) lr 6.9098e-04 eta 0:04:34
epoch [32/50] batch [40/160] time 0.071 (0.082) data 0.000 (0.007) loss 0.8925 (0.8071) ce_loss 0.5688 (0.5183) teacher_loss 0.4237 (0.3778) loss_zs_kd 0.1407 (0.1236) loss_oracle 0.3985 (0.3675) acc 78.1250 (81.5625) kd_loss 0.7819 (0.7903) lr 6.9098e-04 eta 0:04:05
epoch [32/50] batch [60/160] time 0.062 (0.078) data 0.000 (0.004) loss 0.7581 (0.8134) ce_loss 0.4260 (0.5212) teacher_loss 0.2803 (0.3748) loss_zs_kd 0.1291 (0.1295) loss_oracle 0.4133 (0.3738) acc 81.2500 (81.0417) kd_loss 0.7990 (0.7929) lr 6.9098e-04 eta 0:03:52
epoch [32/50] batch [80/160] time 0.078 (0.078) data 0.000 (0.003) loss 0.7290 (0.7902) ce_loss 0.4727 (0.4943) teacher_loss 0.2915 (0.3545) loss_zs_kd 0.1276 (0.1285) loss_oracle 0.3737 (0.3715) acc 84.3750 (82.1484) kd_loss 0.8383 (0.7957) lr 6.9098e-04 eta 0:03:49
epoch [32/50] batch [100/160] time 0.063 (0.076) data 0.000 (0.003) loss 0.7876 (0.7956) ce_loss 0.4368 (0.5025) teacher_loss 0.2335 (0.3576) loss_zs_kd 0.1503 (0.1304) loss_oracle 0.4790 (0.3728) acc 87.5000 (81.7500) kd_loss 0.8822 (0.7953) lr 6.9098e-04 eta 0:03:42
epoch [32/50] batch [120/160] time 0.070 (0.075) data 0.000 (0.002) loss 0.8397 (0.7980) ce_loss 0.5747 (0.5026) teacher_loss 0.4161 (0.3581) loss_zs_kd 0.1181 (0.1303) loss_oracle 0.3645 (0.3747) acc 78.1250 (81.6146) kd_loss 0.7790 (0.7977) lr 6.9098e-04 eta 0:03:39
epoch [32/50] batch [140/160] time 0.079 (0.075) data 0.000 (0.002) loss 0.7639 (0.7932) ce_loss 0.5405 (0.4979) teacher_loss 0.3325 (0.3511) loss_zs_kd 0.1960 (0.1307) loss_oracle 0.3335 (0.3768) acc 84.3750 (81.9866) kd_loss 0.7374 (0.7996) lr 6.9098e-04 eta 0:03:36
epoch [32/50] batch [160/160] time 0.072 (0.075) data 0.000 (0.002) loss 0.8055 (0.7923) ce_loss 0.4033 (0.4988) teacher_loss 0.2771 (0.3515) loss_zs_kd 0.1745 (0.1316) loss_oracle 0.4412 (0.3751) acc 84.3750 (81.9141) kd_loss 0.8431 (0.7984) lr 6.3188e-04 eta 0:03:35
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,847
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,980
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 89.2%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [33/50] batch [20/160] time 0.082 (0.097) data 0.000 (0.015) loss 0.7610 (0.7912) ce_loss 0.5024 (0.4769) teacher_loss 0.3285 (0.3310) loss_zs_kd 0.1429 (0.1474) loss_oracle 0.3610 (0.3865) acc 84.3750 (82.9688) kd_loss 0.8391 (0.8028) lr 6.3188e-04 eta 0:04:37
epoch [33/50] batch [40/160] time 0.079 (0.089) data 0.001 (0.008) loss 0.9572 (0.8021) ce_loss 0.5688 (0.4964) teacher_loss 0.5539 (0.3478) loss_zs_kd 0.1655 (0.1402) loss_oracle 0.3206 (0.3842) acc 84.3750 (81.7969) kd_loss 0.8334 (0.8068) lr 6.3188e-04 eta 0:04:12
epoch [33/50] batch [60/160] time 0.085 (0.087) data 0.000 (0.005) loss 0.9747 (0.8099) ce_loss 0.6484 (0.5084) teacher_loss 0.5191 (0.3534) loss_zs_kd 0.1415 (0.1399) loss_oracle 0.3849 (0.3865) acc 84.3750 (81.5104) kd_loss 0.8612 (0.8080) lr 6.3188e-04 eta 0:04:04
epoch [33/50] batch [80/160] time 0.081 (0.087) data 0.000 (0.004) loss 0.8635 (0.8022) ce_loss 0.4626 (0.5018) teacher_loss 0.3230 (0.3457) loss_zs_kd 0.1253 (0.1360) loss_oracle 0.4779 (0.3884) acc 81.2500 (81.4062) kd_loss 0.9260 (0.8072) lr 6.3188e-04 eta 0:04:04
epoch [33/50] batch [100/160] time 0.081 (0.086) data 0.000 (0.003) loss 0.7736 (0.8040) ce_loss 0.3730 (0.4989) teacher_loss 0.3176 (0.3449) loss_zs_kd 0.1017 (0.1369) loss_oracle 0.4053 (0.3907) acc 87.5000 (81.4062) kd_loss 0.8442 (0.8100) lr 6.3188e-04 eta 0:03:59
epoch [33/50] batch [120/160] time 0.088 (0.086) data 0.000 (0.003) loss 0.8760 (0.8097) ce_loss 0.5889 (0.5029) teacher_loss 0.4156 (0.3472) loss_zs_kd 0.2095 (0.1386) loss_oracle 0.3556 (0.3932) acc 75.0000 (81.5885) kd_loss 0.8077 (0.8132) lr 6.3188e-04 eta 0:03:56
epoch [33/50] batch [140/160] time 0.094 (0.085) data 0.000 (0.002) loss 0.9106 (0.8088) ce_loss 0.5811 (0.5061) teacher_loss 0.5255 (0.3478) loss_zs_kd 0.1095 (0.1382) loss_oracle 0.3303 (0.3919) acc 87.5000 (81.4286) kd_loss 0.7783 (0.8127) lr 6.3188e-04 eta 0:03:53
epoch [33/50] batch [160/160] time 0.072 (0.084) data 0.000 (0.002) loss 0.6848 (0.8059) ce_loss 0.2717 (0.5014) teacher_loss 0.1980 (0.3451) loss_zs_kd 0.0962 (0.1379) loss_oracle 0.4388 (0.3918) acc 90.6250 (81.5430) kd_loss 0.8535 (0.8111) lr 5.7422e-04 eta 0:03:48
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,843
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,986
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [34/50] batch [20/160] time 0.077 (0.094) data 0.000 (0.013) loss 0.7456 (0.7789) ce_loss 0.3589 (0.4677) teacher_loss 0.2720 (0.3209) loss_zs_kd 0.1404 (0.1212) loss_oracle 0.4034 (0.3974) acc 90.6250 (82.9688) kd_loss 0.7783 (0.8206) lr 5.7422e-04 eta 0:04:14
epoch [34/50] batch [40/160] time 0.083 (0.086) data 0.000 (0.007) loss 0.6788 (0.8031) ce_loss 0.3274 (0.4900) teacher_loss 0.2816 (0.3413) loss_zs_kd 0.2024 (0.1345) loss_oracle 0.2960 (0.3946) acc 90.6250 (81.7188) kd_loss 0.8033 (0.8146) lr 5.7422e-04 eta 0:03:49
epoch [34/50] batch [60/160] time 0.073 (0.083) data 0.001 (0.005) loss 0.9224 (0.8120) ce_loss 0.5840 (0.5048) teacher_loss 0.4460 (0.3523) loss_zs_kd 0.1360 (0.1373) loss_oracle 0.4084 (0.3910) acc 81.2500 (81.6146) kd_loss 0.9117 (0.8120) lr 5.7422e-04 eta 0:03:39
epoch [34/50] batch [80/160] time 0.091 (0.081) data 0.002 (0.004) loss 0.8820 (0.8101) ce_loss 0.6538 (0.5046) teacher_loss 0.4059 (0.3524) loss_zs_kd 0.1483 (0.1374) loss_oracle 0.4020 (0.3889) acc 68.7500 (81.2500) kd_loss 0.8167 (0.8102) lr 5.7422e-04 eta 0:03:34
epoch [34/50] batch [100/160] time 0.087 (0.081) data 0.000 (0.003) loss 0.6714 (0.8083) ce_loss 0.3142 (0.5059) teacher_loss 0.2235 (0.3488) loss_zs_kd 0.1224 (0.1405) loss_oracle 0.3868 (0.3893) acc 87.5000 (81.1875) kd_loss 0.8267 (0.8094) lr 5.7422e-04 eta 0:03:33
epoch [34/50] batch [120/160] time 0.082 (0.082) data 0.000 (0.002) loss 0.8091 (0.8110) ce_loss 0.5527 (0.5087) teacher_loss 0.2772 (0.3469) loss_zs_kd 0.1735 (0.1414) loss_oracle 0.4451 (0.3934) acc 75.0000 (81.1719) kd_loss 0.8584 (0.8142) lr 5.7422e-04 eta 0:03:33
epoch [34/50] batch [140/160] time 0.085 (0.082) data 0.000 (0.002) loss 1.0261 (0.8007) ce_loss 0.7534 (0.4970) teacher_loss 0.5344 (0.3372) loss_zs_kd 0.1600 (0.1409) loss_oracle 0.4117 (0.3930) acc 75.0000 (81.7411) kd_loss 0.8032 (0.8121) lr 5.7422e-04 eta 0:03:32
epoch [34/50] batch [160/160] time 0.077 (0.082) data 0.000 (0.002) loss 0.9454 (0.7987) ce_loss 0.5361 (0.4933) teacher_loss 0.5152 (0.3364) loss_zs_kd 0.1177 (0.1402) loss_oracle 0.3714 (0.3922) acc 84.3750 (81.8555) kd_loss 0.8000 (0.8151) lr 5.1825e-04 eta 0:03:29
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,840
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,989
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [35/50] batch [20/160] time 0.081 (0.096) data 0.000 (0.013) loss 0.6214 (0.8344) ce_loss 0.2375 (0.5250) teacher_loss 0.1622 (0.3681) loss_zs_kd 0.1282 (0.1330) loss_oracle 0.3951 (0.3998) acc 93.7500 (81.4062) kd_loss 0.8724 (0.8264) lr 5.1825e-04 eta 0:04:04
epoch [35/50] batch [40/160] time 0.087 (0.090) data 0.000 (0.007) loss 0.6404 (0.8023) ce_loss 0.4106 (0.5035) teacher_loss 0.2276 (0.3392) loss_zs_kd 0.1035 (0.1308) loss_oracle 0.3610 (0.3977) acc 87.5000 (81.7188) kd_loss 0.7506 (0.8197) lr 5.1825e-04 eta 0:03:46
epoch [35/50] batch [60/160] time 0.082 (0.088) data 0.001 (0.005) loss 0.7441 (0.7794) ce_loss 0.4534 (0.4739) teacher_loss 0.2724 (0.3142) loss_zs_kd 0.1187 (0.1362) loss_oracle 0.4124 (0.3971) acc 81.2500 (83.1771) kd_loss 0.8552 (0.8159) lr 5.1825e-04 eta 0:03:40
epoch [35/50] batch [80/160] time 0.082 (0.087) data 0.000 (0.004) loss 0.8955 (0.8015) ce_loss 0.6890 (0.4993) teacher_loss 0.4424 (0.3353) loss_zs_kd 0.1860 (0.1385) loss_oracle 0.3602 (0.3970) acc 75.0000 (81.9531) kd_loss 0.7768 (0.8128) lr 5.1825e-04 eta 0:03:36
epoch [35/50] batch [100/160] time 0.087 (0.087) data 0.000 (0.003) loss 0.8348 (0.7954) ce_loss 0.5596 (0.4984) teacher_loss 0.3820 (0.3337) loss_zs_kd 0.0953 (0.1387) loss_oracle 0.4052 (0.3924) acc 87.5000 (82.1875) kd_loss 0.8474 (0.8121) lr 5.1825e-04 eta 0:03:33
epoch [35/50] batch [120/160] time 0.082 (0.087) data 0.000 (0.002) loss 0.7484 (0.7995) ce_loss 0.4421 (0.4984) teacher_loss 0.2909 (0.3336) loss_zs_kd 0.1768 (0.1419) loss_oracle 0.3691 (0.3950) acc 81.2500 (81.9010) kd_loss 0.8571 (0.8151) lr 5.1825e-04 eta 0:03:31
epoch [35/50] batch [140/160] time 0.083 (0.087) data 0.000 (0.002) loss 0.9189 (0.7976) ce_loss 0.6875 (0.4954) teacher_loss 0.4036 (0.3329) loss_zs_kd 0.1474 (0.1414) loss_oracle 0.4415 (0.3940) acc 71.8750 (82.0089) kd_loss 0.8159 (0.8150) lr 5.1825e-04 eta 0:03:29
epoch [35/50] batch [160/160] time 0.078 (0.086) data 0.000 (0.002) loss 0.8844 (0.7973) ce_loss 0.4390 (0.4974) teacher_loss 0.3055 (0.3312) loss_zs_kd 0.1781 (0.1433) loss_oracle 0.4899 (0.3944) acc 90.6250 (81.8945) kd_loss 0.8467 (0.8162) lr 4.6417e-04 eta 0:03:25
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,842
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,993
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 89.5%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [36/50] batch [20/160] time 0.083 (0.095) data 0.000 (0.013) loss 0.8146 (0.7794) ce_loss 0.4583 (0.4826) teacher_loss 0.3755 (0.3099) loss_zs_kd 0.1411 (0.1518) loss_oracle 0.3685 (0.3936) acc 78.1250 (81.0938) kd_loss 0.7824 (0.8143) lr 4.6417e-04 eta 0:03:47
epoch [36/50] batch [40/160] time 0.084 (0.090) data 0.000 (0.007) loss 0.8166 (0.7855) ce_loss 0.4355 (0.4844) teacher_loss 0.2816 (0.3216) loss_zs_kd 0.1550 (0.1486) loss_oracle 0.4574 (0.3896) acc 87.5000 (81.0938) kd_loss 0.8527 (0.8171) lr 4.6417e-04 eta 0:03:31
epoch [36/50] batch [60/160] time 0.081 (0.088) data 0.001 (0.004) loss 0.6784 (0.7892) ce_loss 0.3647 (0.4926) teacher_loss 0.1783 (0.3239) loss_zs_kd 0.1382 (0.1460) loss_oracle 0.4310 (0.3923) acc 90.6250 (81.5104) kd_loss 0.8425 (0.8166) lr 4.6417e-04 eta 0:03:25
epoch [36/50] batch [80/160] time 0.090 (0.088) data 0.000 (0.003) loss 0.6236 (0.7905) ce_loss 0.3862 (0.4959) teacher_loss 0.1773 (0.3237) loss_zs_kd 0.1753 (0.1459) loss_oracle 0.3587 (0.3938) acc 84.3750 (81.6406) kd_loss 0.8028 (0.8181) lr 4.6417e-04 eta 0:03:24
epoch [36/50] batch [100/160] time 0.084 (0.087) data 0.000 (0.003) loss 0.8554 (0.7963) ce_loss 0.4509 (0.4937) teacher_loss 0.3553 (0.3233) loss_zs_kd 0.1320 (0.1480) loss_oracle 0.4340 (0.3990) acc 81.2500 (81.8125) kd_loss 0.8599 (0.8222) lr 4.6417e-04 eta 0:03:21
epoch [36/50] batch [120/160] time 0.085 (0.087) data 0.000 (0.002) loss 0.7177 (0.7995) ce_loss 0.3252 (0.4919) teacher_loss 0.2261 (0.3214) loss_zs_kd 0.1736 (0.1499) loss_oracle 0.4048 (0.4031) acc 87.5000 (81.9271) kd_loss 0.8134 (0.8240) lr 4.6417e-04 eta 0:03:18
epoch [36/50] batch [140/160] time 0.089 (0.086) data 0.001 (0.002) loss 0.7301 (0.7968) ce_loss 0.4233 (0.4909) teacher_loss 0.2588 (0.3158) loss_zs_kd 0.1770 (0.1503) loss_oracle 0.3828 (0.4058) acc 84.3750 (82.1652) kd_loss 0.8553 (0.8248) lr 4.6417e-04 eta 0:03:15
epoch [36/50] batch [160/160] time 0.070 (0.085) data 0.000 (0.002) loss 0.9148 (0.7925) ce_loss 0.5322 (0.4847) teacher_loss 0.3456 (0.3100) loss_zs_kd 0.1721 (0.1528) loss_oracle 0.4832 (0.4061) acc 78.1250 (82.4023) kd_loss 0.8797 (0.8255) lr 4.1221e-04 eta 0:03:10
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,832
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,985
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.2%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [37/50] batch [20/160] time 0.091 (0.099) data 0.001 (0.014) loss 0.7451 (0.8099) ce_loss 0.4988 (0.5095) teacher_loss 0.2610 (0.3276) loss_zs_kd 0.1930 (0.1567) loss_oracle 0.3877 (0.4040) acc 75.0000 (82.3438) kd_loss 0.7963 (0.8242) lr 4.1221e-04 eta 0:03:40
epoch [37/50] batch [40/160] time 0.082 (0.093) data 0.000 (0.007) loss 0.8081 (0.7955) ce_loss 0.4988 (0.4770) teacher_loss 0.2937 (0.3022) loss_zs_kd 0.1411 (0.1475) loss_oracle 0.4438 (0.4195) acc 81.2500 (83.0469) kd_loss 0.8456 (0.8356) lr 4.1221e-04 eta 0:03:24
epoch [37/50] batch [60/160] time 0.085 (0.090) data 0.000 (0.005) loss 0.8425 (0.7945) ce_loss 0.5405 (0.4750) teacher_loss 0.2995 (0.3000) loss_zs_kd 0.1288 (0.1494) loss_oracle 0.4786 (0.4199) acc 84.3750 (82.8125) kd_loss 0.8479 (0.8349) lr 4.1221e-04 eta 0:03:16
epoch [37/50] batch [80/160] time 0.082 (0.089) data 0.000 (0.004) loss 0.8264 (0.8010) ce_loss 0.5864 (0.4821) teacher_loss 0.3290 (0.3077) loss_zs_kd 0.1397 (0.1501) loss_oracle 0.4275 (0.4183) acc 78.1250 (82.5000) kd_loss 0.8183 (0.8342) lr 4.1221e-04 eta 0:03:12
epoch [37/50] batch [100/160] time 0.080 (0.088) data 0.000 (0.003) loss 1.1841 (0.7953) ce_loss 0.9102 (0.4784) teacher_loss 0.6379 (0.3054) loss_zs_kd 0.2050 (0.1482) loss_oracle 0.4437 (0.4158) acc 62.5000 (82.8125) kd_loss 0.8949 (0.8305) lr 4.1221e-04 eta 0:03:07
epoch [37/50] batch [120/160] time 0.090 (0.087) data 0.001 (0.003) loss 0.6868 (0.8084) ce_loss 0.3174 (0.4899) teacher_loss 0.2776 (0.3152) loss_zs_kd 0.1640 (0.1513) loss_oracle 0.3272 (0.4175) acc 90.6250 (82.0833) kd_loss 0.7915 (0.8316) lr 4.1221e-04 eta 0:03:04
epoch [37/50] batch [140/160] time 0.084 (0.087) data 0.000 (0.002) loss 0.8470 (0.8042) ce_loss 0.5083 (0.4852) teacher_loss 0.4114 (0.3131) loss_zs_kd 0.1547 (0.1511) loss_oracle 0.3582 (0.4156) acc 81.2500 (82.4107) kd_loss 0.8543 (0.8283) lr 4.1221e-04 eta 0:03:02
epoch [37/50] batch [160/160] time 0.072 (0.085) data 0.000 (0.002) loss 0.9027 (0.8105) ce_loss 0.5234 (0.4914) teacher_loss 0.4429 (0.3194) loss_zs_kd 0.1137 (0.1499) loss_oracle 0.4029 (0.4162) acc 84.3750 (82.2070) kd_loss 0.8017 (0.8285) lr 3.6258e-04 eta 0:02:57
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,835
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,991
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [38/50] batch [20/160] time 0.082 (0.103) data 0.000 (0.019) loss 0.8716 (0.8258) ce_loss 0.6450 (0.5185) teacher_loss 0.4786 (0.3454) loss_zs_kd 0.1340 (0.1424) loss_oracle 0.3260 (0.4092) acc 75.0000 (80.6250) kd_loss 0.8218 (0.8194) lr 3.6258e-04 eta 0:03:32
epoch [38/50] batch [40/160] time 0.078 (0.094) data 0.000 (0.010) loss 1.0069 (0.8314) ce_loss 0.5537 (0.5293) teacher_loss 0.4458 (0.3537) loss_zs_kd 0.1659 (0.1468) loss_oracle 0.4781 (0.4044) acc 78.1250 (81.3281) kd_loss 0.8081 (0.8133) lr 3.6258e-04 eta 0:03:12
epoch [38/50] batch [60/160] time 0.092 (0.091) data 0.001 (0.007) loss 0.7384 (0.8193) ce_loss 0.4692 (0.5097) teacher_loss 0.2691 (0.3396) loss_zs_kd 0.1512 (0.1480) loss_oracle 0.3937 (0.4056) acc 87.5000 (81.8229) kd_loss 0.8120 (0.8176) lr 3.6258e-04 eta 0:03:04
epoch [38/50] batch [80/160] time 0.081 (0.090) data 0.000 (0.005) loss 0.8992 (0.8143) ce_loss 0.6328 (0.5027) teacher_loss 0.4037 (0.3369) loss_zs_kd 0.1165 (0.1479) loss_oracle 0.4373 (0.4034) acc 71.8750 (81.6016) kd_loss 0.8687 (0.8175) lr 3.6258e-04 eta 0:02:59
epoch [38/50] batch [100/160] time 0.082 (0.088) data 0.000 (0.004) loss 0.6863 (0.8081) ce_loss 0.4885 (0.5006) teacher_loss 0.3468 (0.3344) loss_zs_kd 0.0924 (0.1448) loss_oracle 0.2933 (0.4013) acc 78.1250 (81.7812) kd_loss 0.7111 (0.8161) lr 3.6258e-04 eta 0:02:53
epoch [38/50] batch [120/160] time 0.096 (0.088) data 0.000 (0.003) loss 0.7929 (0.8006) ce_loss 0.5195 (0.4982) teacher_loss 0.3257 (0.3295) loss_zs_kd 0.1562 (0.1429) loss_oracle 0.3891 (0.3997) acc 84.3750 (81.8229) kd_loss 0.7951 (0.8163) lr 3.6258e-04 eta 0:02:51
epoch [38/50] batch [140/160] time 0.078 (0.087) data 0.000 (0.003) loss 0.7557 (0.8019) ce_loss 0.3020 (0.4965) teacher_loss 0.3083 (0.3313) loss_zs_kd 0.1262 (0.1435) loss_oracle 0.3843 (0.3988) acc 87.5000 (81.9643) kd_loss 0.8915 (0.8188) lr 3.6258e-04 eta 0:02:48
epoch [38/50] batch [160/160] time 0.070 (0.085) data 0.000 (0.003) loss 0.6160 (0.8024) ce_loss 0.4221 (0.4987) teacher_loss 0.2311 (0.3316) loss_zs_kd 0.1349 (0.1424) loss_oracle 0.3175 (0.3996) acc 90.6250 (81.9727) kd_loss 0.8397 (0.8194) lr 3.1545e-04 eta 0:02:43
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,977
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 89.0%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [39/50] batch [20/160] time 0.092 (0.102) data 0.001 (0.016) loss 0.7063 (0.7606) ce_loss 0.2288 (0.4857) teacher_loss 0.2531 (0.3184) loss_zs_kd 0.0863 (0.1415) loss_oracle 0.4101 (0.3714) acc 93.7500 (81.4062) kd_loss 0.8760 (0.7975) lr 3.1545e-04 eta 0:03:14
epoch [39/50] batch [40/160] time 0.094 (0.093) data 0.000 (0.008) loss 0.7441 (0.7937) ce_loss 0.4849 (0.4999) teacher_loss 0.2685 (0.3319) loss_zs_kd 0.1566 (0.1483) loss_oracle 0.3973 (0.3876) acc 84.3750 (81.4062) kd_loss 0.8176 (0.8097) lr 3.1545e-04 eta 0:02:55
epoch [39/50] batch [60/160] time 0.091 (0.090) data 0.001 (0.006) loss 0.7862 (0.7966) ce_loss 0.3967 (0.4927) teacher_loss 0.2702 (0.3256) loss_zs_kd 0.1059 (0.1504) loss_oracle 0.4631 (0.3958) acc 78.1250 (81.7188) kd_loss 0.9121 (0.8145) lr 3.1545e-04 eta 0:02:48
epoch [39/50] batch [80/160] time 0.077 (0.088) data 0.000 (0.004) loss 0.8154 (0.8000) ce_loss 0.4868 (0.5003) teacher_loss 0.2970 (0.3281) loss_zs_kd 0.1536 (0.1505) loss_oracle 0.4416 (0.3967) acc 87.5000 (81.6016) kd_loss 0.8595 (0.8154) lr 3.1545e-04 eta 0:02:42
epoch [39/50] batch [100/160] time 0.077 (0.087) data 0.000 (0.003) loss 0.6530 (0.7997) ce_loss 0.2651 (0.5003) teacher_loss 0.1503 (0.3250) loss_zs_kd 0.1357 (0.1525) loss_oracle 0.4348 (0.3984) acc 90.6250 (81.7812) kd_loss 0.9313 (0.8163) lr 3.1545e-04 eta 0:02:38
epoch [39/50] batch [120/160] time 0.086 (0.086) data 0.002 (0.003) loss 0.8490 (0.8048) ce_loss 0.5586 (0.5027) teacher_loss 0.4045 (0.3253) loss_zs_kd 0.1441 (0.1548) loss_oracle 0.3725 (0.4021) acc 84.3750 (81.4583) kd_loss 0.8396 (0.8169) lr 3.1545e-04 eta 0:02:34
epoch [39/50] batch [140/160] time 0.077 (0.085) data 0.000 (0.003) loss 0.5656 (0.8028) ce_loss 0.2422 (0.4995) teacher_loss 0.1420 (0.3232) loss_zs_kd 0.1060 (0.1527) loss_oracle 0.3706 (0.4032) acc 90.6250 (81.5179) kd_loss 0.7879 (0.8184) lr 3.1545e-04 eta 0:02:31
epoch [39/50] batch [160/160] time 0.073 (0.084) data 0.000 (0.002) loss 0.6945 (0.8008) ce_loss 0.3677 (0.4959) teacher_loss 0.2145 (0.3196) loss_zs_kd 0.2105 (0.1539) loss_oracle 0.3748 (0.4042) acc 87.5000 (81.7188) kd_loss 0.8202 (0.8197) lr 2.7103e-04 eta 0:02:27
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,834
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,984
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [40/50] batch [20/160] time 0.079 (0.089) data 0.000 (0.014) loss 0.7311 (0.7656) ce_loss 0.3738 (0.4443) teacher_loss 0.2054 (0.2853) loss_zs_kd 0.1463 (0.1454) loss_oracle 0.4525 (0.4076) acc 87.5000 (83.5938) kd_loss 0.8211 (0.8277) lr 2.7103e-04 eta 0:02:35
epoch [40/50] batch [40/160] time 0.062 (0.082) data 0.000 (0.007) loss 0.7373 (0.7680) ce_loss 0.5459 (0.4563) teacher_loss 0.3220 (0.2993) loss_zs_kd 0.1430 (0.1426) loss_oracle 0.3439 (0.3973) acc 78.1250 (83.2812) kd_loss 0.8074 (0.8224) lr 2.7103e-04 eta 0:02:20
epoch [40/50] batch [60/160] time 0.072 (0.078) data 0.000 (0.005) loss 0.6063 (0.7503) ce_loss 0.2588 (0.4459) teacher_loss 0.1471 (0.2918) loss_zs_kd 0.1170 (0.1427) loss_oracle 0.4006 (0.3872) acc 87.5000 (83.9062) kd_loss 0.8431 (0.8142) lr 2.7103e-04 eta 0:02:12
epoch [40/50] batch [80/160] time 0.057 (0.078) data 0.000 (0.004) loss 0.8403 (0.7719) ce_loss 0.4060 (0.4703) teacher_loss 0.2315 (0.3052) loss_zs_kd 0.1624 (0.1445) loss_oracle 0.5276 (0.3945) acc 90.6250 (82.8516) kd_loss 0.8921 (0.8173) lr 2.7103e-04 eta 0:02:10
epoch [40/50] batch [100/160] time 0.087 (0.077) data 0.000 (0.003) loss 0.9070 (0.7836) ce_loss 0.7939 (0.4829) teacher_loss 0.4880 (0.3110) loss_zs_kd 0.1167 (0.1460) loss_oracle 0.3606 (0.3997) acc 75.0000 (82.3750) kd_loss 0.7958 (0.8216) lr 2.7103e-04 eta 0:02:07
epoch [40/50] batch [120/160] time 0.079 (0.076) data 0.000 (0.002) loss 0.6954 (0.7877) ce_loss 0.5146 (0.4845) teacher_loss 0.2814 (0.3106) loss_zs_kd 0.1466 (0.1490) loss_oracle 0.3407 (0.4026) acc 90.6250 (82.1875) kd_loss 0.8268 (0.8225) lr 2.7103e-04 eta 0:02:05
epoch [40/50] batch [140/160] time 0.083 (0.077) data 0.000 (0.002) loss 0.6721 (0.7921) ce_loss 0.3005 (0.4890) teacher_loss 0.2438 (0.3138) loss_zs_kd 0.1719 (0.1501) loss_oracle 0.3423 (0.4033) acc 90.6250 (82.0312) kd_loss 0.7923 (0.8218) lr 2.7103e-04 eta 0:02:04
epoch [40/50] batch [160/160] time 0.072 (0.077) data 0.000 (0.002) loss 0.7226 (0.7983) ce_loss 0.4060 (0.4956) teacher_loss 0.2965 (0.3215) loss_zs_kd 0.1208 (0.1501) loss_oracle 0.3657 (0.4017) acc 84.3750 (81.6992) kd_loss 0.7929 (0.8195) lr 2.2949e-04 eta 0:02:02
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,989
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [41/50] batch [20/160] time 0.072 (0.088) data 0.000 (0.015) loss 0.7018 (0.8072) ce_loss 0.5488 (0.5000) teacher_loss 0.2917 (0.3388) loss_zs_kd 0.1161 (0.1360) loss_oracle 0.3520 (0.4004) acc 84.3750 (81.7188) kd_loss 0.7684 (0.8207) lr 2.2949e-04 eta 0:02:18
epoch [41/50] batch [40/160] time 0.056 (0.077) data 0.000 (0.008) loss 0.7855 (0.8072) ce_loss 0.5083 (0.5208) teacher_loss 0.3654 (0.3388) loss_zs_kd 0.1486 (0.1383) loss_oracle 0.3458 (0.3992) acc 75.0000 (81.0156) kd_loss 0.7608 (0.8212) lr 2.2949e-04 eta 0:02:00
epoch [41/50] batch [60/160] time 0.063 (0.072) data 0.000 (0.005) loss 0.7960 (0.8017) ce_loss 0.3918 (0.5081) teacher_loss 0.2432 (0.3262) loss_zs_kd 0.1311 (0.1414) loss_oracle 0.4872 (0.4048) acc 87.5000 (81.6667) kd_loss 0.9192 (0.8243) lr 2.2949e-04 eta 0:01:51
epoch [41/50] batch [80/160] time 0.057 (0.071) data 0.000 (0.004) loss 0.6449 (0.7977) ce_loss 0.3574 (0.5067) teacher_loss 0.1990 (0.3255) loss_zs_kd 0.1340 (0.1427) loss_oracle 0.3789 (0.4008) acc 81.2500 (81.6406) kd_loss 0.8077 (0.8221) lr 2.2949e-04 eta 0:01:47
epoch [41/50] batch [100/160] time 0.061 (0.069) data 0.000 (0.003) loss 0.7376 (0.7976) ce_loss 0.5571 (0.5015) teacher_loss 0.2530 (0.3262) loss_zs_kd 0.1656 (0.1436) loss_oracle 0.4018 (0.3995) acc 78.1250 (81.7812) kd_loss 0.8440 (0.8236) lr 2.2949e-04 eta 0:01:44
epoch [41/50] batch [120/160] time 0.077 (0.069) data 0.000 (0.003) loss 0.8291 (0.7928) ce_loss 0.5430 (0.4994) teacher_loss 0.3259 (0.3250) loss_zs_kd 0.1742 (0.1424) loss_oracle 0.4161 (0.3965) acc 81.2500 (81.9792) kd_loss 0.8538 (0.8212) lr 2.2949e-04 eta 0:01:42
epoch [41/50] batch [140/160] time 0.072 (0.070) data 0.000 (0.002) loss 0.7596 (0.7962) ce_loss 0.5820 (0.5040) teacher_loss 0.3611 (0.3290) loss_zs_kd 0.1145 (0.1420) loss_oracle 0.3412 (0.3961) acc 75.0000 (81.7411) kd_loss 0.7675 (0.8197) lr 2.2949e-04 eta 0:01:42
epoch [41/50] batch [160/160] time 0.074 (0.070) data 0.000 (0.002) loss 0.7580 (0.7951) ce_loss 0.5752 (0.5022) teacher_loss 0.3056 (0.3257) loss_zs_kd 0.1584 (0.1431) loss_oracle 0.3731 (0.3979) acc 68.7500 (81.5430) kd_loss 0.7889 (0.8196) lr 1.9098e-04 eta 0:01:41
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,983
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.2%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [42/50] batch [20/160] time 0.086 (0.103) data 0.000 (0.020) loss 1.0015 (0.8001) ce_loss 0.6265 (0.4883) teacher_loss 0.5483 (0.3072) loss_zs_kd 0.1744 (0.1607) loss_oracle 0.3660 (0.4125) acc 71.8750 (83.2812) kd_loss 0.7483 (0.8057) lr 1.9098e-04 eta 0:02:25
epoch [42/50] batch [40/160] time 0.080 (0.091) data 0.000 (0.010) loss 0.6982 (0.8270) ce_loss 0.3872 (0.5182) teacher_loss 0.3052 (0.3316) loss_zs_kd 0.1197 (0.1570) loss_oracle 0.3332 (0.4169) acc 84.3750 (81.4844) kd_loss 0.8768 (0.8234) lr 1.9098e-04 eta 0:02:07
epoch [42/50] batch [60/160] time 0.086 (0.088) data 0.000 (0.007) loss 0.7992 (0.8111) ce_loss 0.5630 (0.5037) teacher_loss 0.4455 (0.3275) loss_zs_kd 0.1150 (0.1501) loss_oracle 0.2962 (0.4085) acc 81.2500 (81.9792) kd_loss 0.8129 (0.8229) lr 1.9098e-04 eta 0:02:00
epoch [42/50] batch [80/160] time 0.090 (0.086) data 0.001 (0.005) loss 0.6786 (0.7903) ce_loss 0.3201 (0.4830) teacher_loss 0.1917 (0.3121) loss_zs_kd 0.1254 (0.1478) loss_oracle 0.4241 (0.4043) acc 84.3750 (82.7734) kd_loss 0.8049 (0.8217) lr 1.9098e-04 eta 0:01:57
epoch [42/50] batch [100/160] time 0.092 (0.087) data 0.001 (0.004) loss 0.7756 (0.7928) ce_loss 0.3801 (0.4846) teacher_loss 0.2677 (0.3170) loss_zs_kd 0.1299 (0.1457) loss_oracle 0.4429 (0.4029) acc 87.5000 (82.5625) kd_loss 0.8736 (0.8227) lr 1.9098e-04 eta 0:01:56
epoch [42/50] batch [120/160] time 0.090 (0.087) data 0.000 (0.004) loss 0.7665 (0.7887) ce_loss 0.3501 (0.4824) teacher_loss 0.3184 (0.3164) loss_zs_kd 0.1276 (0.1436) loss_oracle 0.3843 (0.4005) acc 81.2500 (82.4219) kd_loss 0.8400 (0.8231) lr 1.9098e-04 eta 0:01:54
epoch [42/50] batch [140/160] time 0.091 (0.087) data 0.001 (0.003) loss 0.8611 (0.7935) ce_loss 0.6045 (0.4936) teacher_loss 0.4117 (0.3256) loss_zs_kd 0.1175 (0.1434) loss_oracle 0.3906 (0.3962) acc 75.0000 (82.1205) kd_loss 0.8355 (0.8209) lr 1.9098e-04 eta 0:01:53
epoch [42/50] batch [160/160] time 0.074 (0.086) data 0.000 (0.003) loss 0.7701 (0.7892) ce_loss 0.3691 (0.4915) teacher_loss 0.2840 (0.3216) loss_zs_kd 0.1447 (0.1437) loss_oracle 0.4137 (0.3957) acc 84.3750 (81.9531) kd_loss 0.8573 (0.8200) lr 1.5567e-04 eta 0:01:50
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,983
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [43/50] batch [20/160] time 0.086 (0.100) data 0.000 (0.017) loss 0.8919 (0.7854) ce_loss 0.6187 (0.4696) teacher_loss 0.3927 (0.3073) loss_zs_kd 0.1676 (0.1449) loss_oracle 0.4155 (0.4057) acc 75.0000 (83.1250) kd_loss 0.8341 (0.8217) lr 1.5567e-04 eta 0:02:05
epoch [43/50] batch [40/160] time 0.080 (0.092) data 0.000 (0.009) loss 0.8004 (0.7660) ce_loss 0.4636 (0.4707) teacher_loss 0.3272 (0.2947) loss_zs_kd 0.1499 (0.1450) loss_oracle 0.3982 (0.3988) acc 87.5000 (83.2812) kd_loss 0.8890 (0.8216) lr 1.5567e-04 eta 0:01:53
epoch [43/50] batch [60/160] time 0.078 (0.088) data 0.001 (0.006) loss 0.8690 (0.7749) ce_loss 0.5493 (0.4749) teacher_loss 0.3012 (0.3051) loss_zs_kd 0.2273 (0.1469) loss_oracle 0.4541 (0.3963) acc 78.1250 (83.2812) kd_loss 0.8438 (0.8202) lr 1.5567e-04 eta 0:01:47
epoch [43/50] batch [80/160] time 0.077 (0.086) data 0.000 (0.004) loss 0.8350 (0.7930) ce_loss 0.3552 (0.4884) teacher_loss 0.2763 (0.3189) loss_zs_kd 0.1915 (0.1496) loss_oracle 0.4630 (0.3993) acc 90.6250 (82.8906) kd_loss 0.8435 (0.8211) lr 1.5567e-04 eta 0:01:43
epoch [43/50] batch [100/160] time 0.084 (0.085) data 0.000 (0.004) loss 0.5802 (0.7856) ce_loss 0.2922 (0.4823) teacher_loss 0.2001 (0.3141) loss_zs_kd 0.1453 (0.1471) loss_oracle 0.3075 (0.3980) acc 87.5000 (82.7500) kd_loss 0.7337 (0.8228) lr 1.5567e-04 eta 0:01:40
epoch [43/50] batch [120/160] time 0.091 (0.085) data 0.000 (0.003) loss 0.5333 (0.7875) ce_loss 0.2871 (0.4834) teacher_loss 0.1443 (0.3188) loss_zs_kd 0.1178 (0.1468) loss_oracle 0.3301 (0.3953) acc 90.6250 (82.8385) kd_loss 0.7129 (0.8202) lr 1.5567e-04 eta 0:01:39
epoch [43/50] batch [140/160] time 0.077 (0.085) data 0.000 (0.003) loss 0.6549 (0.7783) ce_loss 0.3557 (0.4773) teacher_loss 0.2656 (0.3122) loss_zs_kd 0.1122 (0.1468) loss_oracle 0.3333 (0.3927) acc 87.5000 (82.8348) kd_loss 0.8132 (0.8182) lr 1.5567e-04 eta 0:01:37
epoch [43/50] batch [160/160] time 0.077 (0.084) data 0.000 (0.002) loss 0.6876 (0.7816) ce_loss 0.4248 (0.4856) teacher_loss 0.2714 (0.3147) loss_zs_kd 0.1496 (0.1474) loss_oracle 0.3414 (0.3932) acc 87.5000 (82.5000) kd_loss 0.7671 (0.8188) lr 1.2369e-04 eta 0:01:34
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,982
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [44/50] batch [20/160] time 0.077 (0.098) data 0.000 (0.014) loss 0.7616 (0.7965) ce_loss 0.5020 (0.4806) teacher_loss 0.2658 (0.3037) loss_zs_kd 0.1400 (0.1520) loss_oracle 0.4258 (0.4168) acc 81.2500 (82.3438) kd_loss 0.8101 (0.8393) lr 1.2369e-04 eta 0:01:48
epoch [44/50] batch [40/160] time 0.084 (0.092) data 0.000 (0.007) loss 0.9511 (0.7894) ce_loss 0.5210 (0.4884) teacher_loss 0.4170 (0.3083) loss_zs_kd 0.1749 (0.1510) loss_oracle 0.4467 (0.4056) acc 87.5000 (82.2656) kd_loss 0.7720 (0.8265) lr 1.2369e-04 eta 0:01:38
epoch [44/50] batch [60/160] time 0.093 (0.089) data 0.001 (0.005) loss 0.8242 (0.8021) ce_loss 0.5674 (0.4903) teacher_loss 0.3130 (0.3163) loss_zs_kd 0.1518 (0.1515) loss_oracle 0.4353 (0.4100) acc 81.2500 (81.9792) kd_loss 0.8162 (0.8266) lr 1.2369e-04 eta 0:01:33
epoch [44/50] batch [80/160] time 0.090 (0.088) data 0.000 (0.004) loss 0.7138 (0.7962) ce_loss 0.3840 (0.4893) teacher_loss 0.2449 (0.3120) loss_zs_kd 0.1519 (0.1510) loss_oracle 0.3929 (0.4086) acc 90.6250 (81.9922) kd_loss 0.8341 (0.8255) lr 1.2369e-04 eta 0:01:31
epoch [44/50] batch [100/160] time 0.083 (0.088) data 0.000 (0.003) loss 0.8821 (0.7960) ce_loss 0.5708 (0.4887) teacher_loss 0.4284 (0.3145) loss_zs_kd 0.1313 (0.1510) loss_oracle 0.3881 (0.4060) acc 75.0000 (81.7188) kd_loss 0.8077 (0.8261) lr 1.2369e-04 eta 0:01:29
epoch [44/50] batch [120/160] time 0.078 (0.087) data 0.000 (0.003) loss 0.7221 (0.7910) ce_loss 0.5801 (0.4902) teacher_loss 0.3088 (0.3150) loss_zs_kd 0.1150 (0.1490) loss_oracle 0.3558 (0.4015) acc 75.0000 (81.7188) kd_loss 0.7810 (0.8256) lr 1.2369e-04 eta 0:01:27
epoch [44/50] batch [140/160] time 0.085 (0.087) data 0.000 (0.002) loss 0.8846 (0.7888) ce_loss 0.6162 (0.4889) teacher_loss 0.3814 (0.3141) loss_zs_kd 0.1919 (0.1502) loss_oracle 0.4073 (0.3996) acc 71.8750 (81.8080) kd_loss 0.7892 (0.8234) lr 1.2369e-04 eta 0:01:24
epoch [44/50] batch [160/160] time 0.072 (0.085) data 0.000 (0.002) loss 0.9853 (0.7910) ce_loss 0.5601 (0.4918) teacher_loss 0.4714 (0.3176) loss_zs_kd 0.1548 (0.1498) loss_oracle 0.4365 (0.3985) acc 84.3750 (81.7578) kd_loss 0.8145 (0.8236) lr 9.5173e-05 eta 0:01:21
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,842
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,987
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [45/50] batch [20/160] time 0.078 (0.095) data 0.000 (0.013) loss 0.6988 (0.7865) ce_loss 0.4172 (0.5074) teacher_loss 0.2317 (0.3171) loss_zs_kd 0.1499 (0.1365) loss_oracle 0.3921 (0.4012) acc 84.3750 (80.7812) kd_loss 0.7690 (0.8119) lr 9.5173e-05 eta 0:01:29
epoch [45/50] batch [40/160] time 0.083 (0.089) data 0.000 (0.007) loss 0.9045 (0.7790) ce_loss 0.5034 (0.4968) teacher_loss 0.4025 (0.3221) loss_zs_kd 0.0885 (0.1384) loss_oracle 0.4578 (0.3877) acc 87.5000 (81.3281) kd_loss 0.8022 (0.8151) lr 9.5173e-05 eta 0:01:21
epoch [45/50] batch [60/160] time 0.091 (0.087) data 0.000 (0.005) loss 0.7016 (0.7886) ce_loss 0.3923 (0.5082) teacher_loss 0.2317 (0.3321) loss_zs_kd 0.1209 (0.1410) loss_oracle 0.4095 (0.3861) acc 93.7500 (81.6146) kd_loss 0.8490 (0.8124) lr 9.5173e-05 eta 0:01:18
epoch [45/50] batch [80/160] time 0.083 (0.086) data 0.000 (0.004) loss 0.7081 (0.7856) ce_loss 0.4324 (0.5072) teacher_loss 0.2645 (0.3259) loss_zs_kd 0.1484 (0.1421) loss_oracle 0.3693 (0.3888) acc 81.2500 (81.4453) kd_loss 0.8310 (0.8135) lr 9.5173e-05 eta 0:01:15
epoch [45/50] batch [100/160] time 0.094 (0.086) data 0.001 (0.003) loss 0.8390 (0.7870) ce_loss 0.4697 (0.5013) teacher_loss 0.2682 (0.3238) loss_zs_kd 0.1630 (0.1441) loss_oracle 0.4893 (0.3911) acc 84.3750 (81.7188) kd_loss 0.8231 (0.8134) lr 9.5173e-05 eta 0:01:14
epoch [45/50] batch [120/160] time 0.082 (0.086) data 0.000 (0.003) loss 0.7883 (0.7870) ce_loss 0.3909 (0.4970) teacher_loss 0.2434 (0.3219) loss_zs_kd 0.1825 (0.1448) loss_oracle 0.4537 (0.3927) acc 78.1250 (81.7708) kd_loss 0.8640 (0.8166) lr 9.5173e-05 eta 0:01:12
epoch [45/50] batch [140/160] time 0.085 (0.086) data 0.001 (0.002) loss 0.8600 (0.7826) ce_loss 0.6128 (0.4918) teacher_loss 0.4044 (0.3164) loss_zs_kd 0.1340 (0.1437) loss_oracle 0.3886 (0.3943) acc 71.8750 (81.8527) kd_loss 0.8249 (0.8175) lr 9.5173e-05 eta 0:01:10
epoch [45/50] batch [160/160] time 0.071 (0.085) data 0.000 (0.002) loss 0.8240 (0.7831) ce_loss 0.5200 (0.4933) teacher_loss 0.4132 (0.3191) loss_zs_kd 0.1331 (0.1431) loss_oracle 0.3443 (0.3925) acc 71.8750 (81.6602) kd_loss 0.8223 (0.8170) lr 7.0224e-05 eta 0:01:07
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,986
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [46/50] batch [20/160] time 0.088 (0.099) data 0.000 (0.014) loss 1.0739 (0.7907) ce_loss 0.8672 (0.4809) teacher_loss 0.6450 (0.3257) loss_zs_kd 0.1499 (0.1539) loss_oracle 0.3539 (0.3881) acc 71.8750 (83.1250) kd_loss 0.8118 (0.8152) lr 7.0224e-05 eta 0:01:17
epoch [46/50] batch [40/160] time 0.076 (0.090) data 0.000 (0.007) loss 0.7373 (0.8011) ce_loss 0.4963 (0.5219) teacher_loss 0.2369 (0.3454) loss_zs_kd 0.1690 (0.1513) loss_oracle 0.4159 (0.3801) acc 87.5000 (82.1094) kd_loss 0.8354 (0.8094) lr 7.0224e-05 eta 0:01:08
epoch [46/50] batch [60/160] time 0.094 (0.089) data 0.001 (0.005) loss 0.7094 (0.7911) ce_loss 0.4314 (0.4989) teacher_loss 0.2958 (0.3269) loss_zs_kd 0.1144 (0.1477) loss_oracle 0.3564 (0.3903) acc 75.0000 (82.3438) kd_loss 0.8001 (0.8183) lr 7.0224e-05 eta 0:01:05
epoch [46/50] batch [80/160] time 0.081 (0.087) data 0.000 (0.004) loss 0.6921 (0.7867) ce_loss 0.4067 (0.4959) teacher_loss 0.2387 (0.3194) loss_zs_kd 0.1256 (0.1475) loss_oracle 0.3907 (0.3936) acc 87.5000 (82.2656) kd_loss 0.7788 (0.8193) lr 7.0224e-05 eta 0:01:02
epoch [46/50] batch [100/160] time 0.083 (0.087) data 0.000 (0.003) loss 0.6195 (0.7888) ce_loss 0.3472 (0.4932) teacher_loss 0.1873 (0.3167) loss_zs_kd 0.1275 (0.1468) loss_oracle 0.3685 (0.3988) acc 84.3750 (82.3125) kd_loss 0.7754 (0.8216) lr 7.0224e-05 eta 0:01:00
epoch [46/50] batch [120/160] time 0.079 (0.086) data 0.000 (0.003) loss 0.7216 (0.7936) ce_loss 0.5376 (0.4977) teacher_loss 0.3207 (0.3195) loss_zs_kd 0.1662 (0.1484) loss_oracle 0.3178 (0.3999) acc 81.2500 (82.0573) kd_loss 0.8231 (0.8230) lr 7.0224e-05 eta 0:00:58
epoch [46/50] batch [140/160] time 0.084 (0.086) data 0.000 (0.002) loss 0.5981 (0.7953) ce_loss 0.3057 (0.4998) teacher_loss 0.1637 (0.3234) loss_zs_kd 0.1063 (0.1471) loss_oracle 0.3812 (0.3983) acc 90.6250 (81.8973) kd_loss 0.8482 (0.8214) lr 7.0224e-05 eta 0:00:56
epoch [46/50] batch [160/160] time 0.072 (0.085) data 0.000 (0.002) loss 0.6578 (0.7921) ce_loss 0.3215 (0.4969) teacher_loss 0.2190 (0.3200) loss_zs_kd 0.1579 (0.1463) loss_oracle 0.3599 (0.3990) acc 90.6250 (81.7969) kd_loss 0.8722 (0.8234) lr 4.8943e-05 eta 0:00:54
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,838
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,986
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [47/50] batch [20/160] time 0.086 (0.092) data 0.000 (0.013) loss 0.9046 (0.7775) ce_loss 0.5542 (0.4731) teacher_loss 0.4275 (0.3146) loss_zs_kd 0.1189 (0.1464) loss_oracle 0.4177 (0.3897) acc 78.1250 (83.5938) kd_loss 0.8221 (0.8077) lr 4.8943e-05 eta 0:00:57
epoch [47/50] batch [40/160] time 0.074 (0.088) data 0.000 (0.006) loss 0.8962 (0.7809) ce_loss 0.6567 (0.4805) teacher_loss 0.4285 (0.3182) loss_zs_kd 0.1630 (0.1465) loss_oracle 0.3862 (0.3895) acc 75.0000 (83.1250) kd_loss 0.8531 (0.8090) lr 4.8943e-05 eta 0:00:52
epoch [47/50] batch [60/160] time 0.074 (0.086) data 0.001 (0.004) loss 0.7502 (0.7851) ce_loss 0.4751 (0.4820) teacher_loss 0.2773 (0.3173) loss_zs_kd 0.1516 (0.1467) loss_oracle 0.3972 (0.3945) acc 84.3750 (82.7083) kd_loss 0.8851 (0.8149) lr 4.8943e-05 eta 0:00:50
epoch [47/50] batch [80/160] time 0.080 (0.086) data 0.000 (0.003) loss 0.7396 (0.7871) ce_loss 0.4316 (0.4777) teacher_loss 0.2802 (0.3187) loss_zs_kd 0.1063 (0.1452) loss_oracle 0.4062 (0.3959) acc 84.3750 (83.2812) kd_loss 0.8230 (0.8204) lr 4.8943e-05 eta 0:00:48
epoch [47/50] batch [100/160] time 0.084 (0.085) data 0.000 (0.003) loss 0.7795 (0.7925) ce_loss 0.5518 (0.4848) teacher_loss 0.3664 (0.3214) loss_zs_kd 0.1218 (0.1486) loss_oracle 0.3521 (0.3968) acc 78.1250 (82.7812) kd_loss 0.7919 (0.8203) lr 4.8943e-05 eta 0:00:45
epoch [47/50] batch [120/160] time 0.091 (0.085) data 0.000 (0.002) loss 0.9434 (0.7887) ce_loss 0.6494 (0.4873) teacher_loss 0.4592 (0.3193) loss_zs_kd 0.1819 (0.1487) loss_oracle 0.3933 (0.3951) acc 75.0000 (82.5781) kd_loss 0.8325 (0.8189) lr 4.8943e-05 eta 0:00:44
epoch [47/50] batch [140/160] time 0.087 (0.085) data 0.000 (0.002) loss 0.7992 (0.7875) ce_loss 0.5020 (0.4856) teacher_loss 0.2953 (0.3189) loss_zs_kd 0.1809 (0.1492) loss_oracle 0.4134 (0.3940) acc 71.8750 (82.4554) kd_loss 0.8217 (0.8197) lr 4.8943e-05 eta 0:00:42
epoch [47/50] batch [160/160] time 0.075 (0.084) data 0.000 (0.002) loss 0.9000 (0.7911) ce_loss 0.6611 (0.4934) teacher_loss 0.4681 (0.3227) loss_zs_kd 0.1368 (0.1494) loss_oracle 0.3635 (0.3937) acc 78.1250 (82.1484) kd_loss 0.7717 (0.8186) lr 3.1417e-05 eta 0:00:40
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,983
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [48/50] batch [20/160] time 0.081 (0.103) data 0.000 (0.016) loss 0.7807 (0.8186) ce_loss 0.4587 (0.5174) teacher_loss 0.3416 (0.3490) loss_zs_kd 0.1268 (0.1491) loss_oracle 0.3757 (0.3950) acc 81.2500 (81.8750) kd_loss 0.8317 (0.8192) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [40/160] time 0.082 (0.092) data 0.000 (0.008) loss 0.7317 (0.7971) ce_loss 0.4084 (0.5048) teacher_loss 0.2747 (0.3260) loss_zs_kd 0.1105 (0.1501) loss_oracle 0.4017 (0.3961) acc 81.2500 (81.6406) kd_loss 0.8006 (0.8216) lr 3.1417e-05 eta 0:00:40
epoch [48/50] batch [60/160] time 0.085 (0.089) data 0.001 (0.005) loss 0.7794 (0.7962) ce_loss 0.5581 (0.5075) teacher_loss 0.3825 (0.3255) loss_zs_kd 0.1598 (0.1500) loss_oracle 0.3170 (0.3957) acc 75.0000 (81.1979) kd_loss 0.7910 (0.8188) lr 3.1417e-05 eta 0:00:37
epoch [48/50] batch [80/160] time 0.094 (0.088) data 0.001 (0.004) loss 0.8524 (0.7906) ce_loss 0.6460 (0.5065) teacher_loss 0.4004 (0.3192) loss_zs_kd 0.1498 (0.1478) loss_oracle 0.3771 (0.3975) acc 71.8750 (80.9766) kd_loss 0.8476 (0.8198) lr 3.1417e-05 eta 0:00:35
epoch [48/50] batch [100/160] time 0.087 (0.088) data 0.000 (0.003) loss 0.7994 (0.7839) ce_loss 0.5884 (0.4930) teacher_loss 0.3841 (0.3116) loss_zs_kd 0.1256 (0.1482) loss_oracle 0.3525 (0.3982) acc 87.5000 (81.7812) kd_loss 0.8310 (0.8219) lr 3.1417e-05 eta 0:00:33
epoch [48/50] batch [120/160] time 0.082 (0.087) data 0.000 (0.003) loss 0.6777 (0.7838) ce_loss 0.3931 (0.4871) teacher_loss 0.2375 (0.3097) loss_zs_kd 0.1202 (0.1473) loss_oracle 0.3801 (0.4005) acc 78.1250 (81.9531) kd_loss 0.8356 (0.8246) lr 3.1417e-05 eta 0:00:31
epoch [48/50] batch [140/160] time 0.081 (0.087) data 0.000 (0.002) loss 0.7699 (0.7819) ce_loss 0.4258 (0.4835) teacher_loss 0.2650 (0.3081) loss_zs_kd 0.1752 (0.1477) loss_oracle 0.4173 (0.3999) acc 90.6250 (82.1429) kd_loss 0.8240 (0.8235) lr 3.1417e-05 eta 0:00:29
epoch [48/50] batch [160/160] time 0.071 (0.086) data 0.000 (0.002) loss 1.0445 (0.7892) ce_loss 0.7349 (0.4918) teacher_loss 0.5254 (0.3151) loss_zs_kd 0.1488 (0.1475) loss_oracle 0.4447 (0.4004) acc 75.0000 (81.8555) kd_loss 0.8461 (0.8226) lr 1.7713e-05 eta 0:00:27
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,840
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,988
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [49/50] batch [20/160] time 0.081 (0.094) data 0.000 (0.014) loss 1.1032 (0.7724) ce_loss 0.8413 (0.4957) teacher_loss 0.6186 (0.3039) loss_zs_kd 0.1718 (0.1470) loss_oracle 0.3987 (0.3950) acc 59.3750 (80.7812) kd_loss 0.7954 (0.8135) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [40/160] time 0.077 (0.087) data 0.000 (0.007) loss 0.7325 (0.8005) ce_loss 0.5049 (0.5252) teacher_loss 0.2078 (0.3251) loss_zs_kd 0.1951 (0.1457) loss_oracle 0.4272 (0.4025) acc 81.2500 (79.6094) kd_loss 0.8666 (0.8199) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [60/160] time 0.082 (0.085) data 0.001 (0.005) loss 1.0424 (0.7851) ce_loss 0.7803 (0.4959) teacher_loss 0.5923 (0.3082) loss_zs_kd 0.1625 (0.1469) loss_oracle 0.3689 (0.4034) acc 65.6250 (81.1458) kd_loss 0.7904 (0.8229) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [80/160] time 0.085 (0.085) data 0.000 (0.004) loss 0.7974 (0.7876) ce_loss 0.3906 (0.4934) teacher_loss 0.2800 (0.3096) loss_zs_kd 0.1495 (0.1487) loss_oracle 0.4427 (0.4037) acc 87.5000 (81.4844) kd_loss 0.9150 (0.8265) lr 1.7713e-05 eta 0:00:20
epoch [49/50] batch [100/160] time 0.089 (0.085) data 0.000 (0.003) loss 0.7876 (0.7929) ce_loss 0.4727 (0.5058) teacher_loss 0.3473 (0.3166) loss_zs_kd 0.1774 (0.1500) loss_oracle 0.3516 (0.4013) acc 75.0000 (80.8438) kd_loss 0.8766 (0.8273) lr 1.7713e-05 eta 0:00:18
epoch [49/50] batch [120/160] time 0.085 (0.085) data 0.000 (0.003) loss 0.8817 (0.7938) ce_loss 0.6157 (0.5071) teacher_loss 0.3423 (0.3181) loss_zs_kd 0.1564 (0.1504) loss_oracle 0.4612 (0.4006) acc 81.2500 (80.8594) kd_loss 0.8043 (0.8262) lr 1.7713e-05 eta 0:00:16
epoch [49/50] batch [140/160] time 0.088 (0.085) data 0.000 (0.002) loss 0.7820 (0.7943) ce_loss 0.5093 (0.5082) teacher_loss 0.3519 (0.3212) loss_zs_kd 0.1367 (0.1483) loss_oracle 0.3618 (0.3990) acc 78.1250 (81.0268) kd_loss 0.8064 (0.8239) lr 1.7713e-05 eta 0:00:15
epoch [49/50] batch [160/160] time 0.067 (0.084) data 0.000 (0.002) loss 0.8340 (0.7935) ce_loss 0.4907 (0.5031) teacher_loss 0.3273 (0.3185) loss_zs_kd 0.1723 (0.1480) loss_oracle 0.4205 (0.4010) acc 78.1250 (81.2500) kd_loss 0.8363 (0.8254) lr 7.8853e-06 eta 0:00:13
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,840
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,983
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.3%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
epoch [50/50] batch [20/160] time 0.081 (0.098) data 0.000 (0.015) loss 0.9737 (0.7780) ce_loss 0.5737 (0.5048) teacher_loss 0.3819 (0.3145) loss_zs_kd 0.1410 (0.1481) loss_oracle 0.5213 (0.3895) acc 84.3750 (81.5625) kd_loss 0.9085 (0.8180) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [40/160] time 0.091 (0.092) data 0.000 (0.008) loss 0.9682 (0.7651) ce_loss 0.5938 (0.4865) teacher_loss 0.4399 (0.3041) loss_zs_kd 0.1663 (0.1508) loss_oracle 0.4452 (0.3856) acc 81.2500 (82.4219) kd_loss 0.8485 (0.8158) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [60/160] time 0.084 (0.091) data 0.001 (0.005) loss 0.9001 (0.7623) ce_loss 0.5278 (0.4739) teacher_loss 0.3589 (0.2986) loss_zs_kd 0.1581 (0.1493) loss_oracle 0.4622 (0.3891) acc 78.1250 (83.0729) kd_loss 0.8241 (0.8152) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [80/160] time 0.089 (0.089) data 0.000 (0.004) loss 0.8006 (0.7701) ce_loss 0.5293 (0.4813) teacher_loss 0.3104 (0.3028) loss_zs_kd 0.1649 (0.1495) loss_oracle 0.4077 (0.3925) acc 78.1250 (82.6172) kd_loss 0.8070 (0.8180) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [100/160] time 0.086 (0.088) data 0.000 (0.003) loss 0.8891 (0.7751) ce_loss 0.4958 (0.4822) teacher_loss 0.5508 (0.3066) loss_zs_kd 0.0889 (0.1486) loss_oracle 0.2939 (0.3942) acc 84.3750 (82.4688) kd_loss 0.6893 (0.8207) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [120/160] time 0.091 (0.088) data 0.000 (0.003) loss 0.7337 (0.7749) ce_loss 0.3704 (0.4809) teacher_loss 0.2769 (0.3049) loss_zs_kd 0.1167 (0.1494) loss_oracle 0.3984 (0.3953) acc 87.5000 (82.3438) kd_loss 0.7826 (0.8209) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [140/160] time 0.085 (0.088) data 0.000 (0.002) loss 0.7042 (0.7754) ce_loss 0.2893 (0.4829) teacher_loss 0.1843 (0.3062) loss_zs_kd 0.1497 (0.1504) loss_oracle 0.4450 (0.3940) acc 96.8750 (82.2768) kd_loss 0.8904 (0.8194) lr 7.8853e-06 eta 0:00:01
epoch [50/50] batch [160/160] time 0.072 (0.086) data 0.000 (0.002) loss 0.7104 (0.7789) ce_loss 0.3425 (0.4844) teacher_loss 0.2731 (0.3091) loss_zs_kd 0.1415 (0.1489) loss_oracle 0.3665 (0.3953) acc 87.5000 (82.3242) kd_loss 0.8176 (0.8201) lr 1.9733e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,989
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.4%
******* Domain p best val acc:      83.8%, epoch: 23 *******
******* Domain p best val test acc: 88.6%, epoch: 23 *******
******* Domain p best test acc:     89.4%, epoch: 15 *******
Checkpoint saved to icml/multi-dg/oracle/03_dong/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:15:31

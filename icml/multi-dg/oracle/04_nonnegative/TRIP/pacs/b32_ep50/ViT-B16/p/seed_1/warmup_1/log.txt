Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------------------------
Dataset    SPG_PACS
Source     ['art_painting', 'cartoon', 'sketch']
Target     ['photo']
# classes  7
# train_x  5,823
# val      2,497
# test     1,670
---------  -------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/181] time 0.136 (0.153) data 0.000 (0.015) loss 0.6402 (0.5732) ce_loss 0.6392 (0.5724) teacher_loss 0.6399 (0.5725) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0003 (0.0006) acc 71.8750 (79.0625) kd_loss 0.0009 (0.0024) lr 1.0000e-05 eta 0:23:01
epoch [1/50] batch [40/181] time 0.136 (0.138) data 0.000 (0.008) loss 0.8236 (0.5701) ce_loss 0.8232 (0.5696) teacher_loss 0.8228 (0.5696) loss_zs_kd 0.0012 (0.0002) loss_oracle 0.0001 (0.0004) acc 75.0000 (79.6094) kd_loss 0.0005 (0.0016) lr 1.0000e-05 eta 0:20:47
epoch [1/50] batch [60/181] time 0.122 (0.131) data 0.000 (0.005) loss 0.7319 (0.5606) ce_loss 0.7310 (0.5600) teacher_loss 0.7302 (0.5600) loss_zs_kd 0.0030 (0.0006) loss_oracle 0.0003 (0.0004) acc 78.1250 (80.1042) kd_loss 0.0010 (0.0014) lr 1.0000e-05 eta 0:19:37
epoch [1/50] batch [80/181] time 0.143 (0.127) data 0.000 (0.004) loss 0.4355 (0.5528) ce_loss 0.4331 (0.5519) teacher_loss 0.4329 (0.5519) loss_zs_kd 0.0042 (0.0012) loss_oracle 0.0005 (0.0004) acc 84.3750 (80.3516) kd_loss 0.0016 (0.0014) lr 1.0000e-05 eta 0:18:56
epoch [1/50] batch [100/181] time 0.136 (0.127) data 0.000 (0.003) loss 0.4763 (0.5420) ce_loss 0.4729 (0.5406) teacher_loss 0.4729 (0.5406) loss_zs_kd 0.0057 (0.0019) loss_oracle 0.0006 (0.0004) acc 87.5000 (80.6875) kd_loss 0.0019 (0.0015) lr 1.0000e-05 eta 0:18:55
epoch [1/50] batch [120/181] time 0.100 (0.126) data 0.000 (0.003) loss 0.5668 (0.5260) ce_loss 0.5625 (0.5243) teacher_loss 0.5621 (0.5243) loss_zs_kd 0.0070 (0.0026) loss_oracle 0.0012 (0.0005) acc 81.2500 (81.6146) kd_loss 0.0044 (0.0017) lr 1.0000e-05 eta 0:18:43
epoch [1/50] batch [140/181] time 0.117 (0.126) data 0.000 (0.002) loss 0.3319 (0.5219) ce_loss 0.3267 (0.5197) teacher_loss 0.3265 (0.5196) loss_zs_kd 0.0076 (0.0034) loss_oracle 0.0016 (0.0006) acc 84.3750 (81.8973) kd_loss 0.0055 (0.0022) lr 1.0000e-05 eta 0:18:40
epoch [1/50] batch [160/181] time 0.109 (0.125) data 0.000 (0.002) loss 0.3560 (0.5129) ce_loss 0.3489 (0.5102) teacher_loss 0.3483 (0.5101) loss_zs_kd 0.0094 (0.0041) loss_oracle 0.0031 (0.0008) acc 90.6250 (82.1875) kd_loss 0.0107 (0.0030) lr 1.0000e-05 eta 0:18:28
epoch [1/50] batch [180/181] time 0.100 (0.122) data 0.000 (0.002) loss 0.6252 (0.5127) ce_loss 0.6157 (0.5093) teacher_loss 0.6143 (0.5091) loss_zs_kd 0.0144 (0.0049) loss_oracle 0.0037 (0.0012) acc 81.2500 (82.2222) kd_loss 0.0126 (0.0041) lr 1.0000e-05 eta 0:18:04
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,367
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 95.4%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      94.8%, epoch: 1 *******
******* Domain p best val test acc: 99.9%, epoch: 1 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/ana
epoch [2/50] batch [20/181] time 0.105 (0.114) data 0.000 (0.013) loss 0.5952 (0.6097) ce_loss 0.4561 (0.5289) teacher_loss 0.4300 (0.5193) loss_zs_kd 0.0530 (0.0610) loss_oracle 0.1387 (0.0599) acc 87.5000 (82.5000) kd_loss 0.2680 (0.0810) lr 2.0000e-03 eta 0:16:47
epoch [2/50] batch [40/181] time 0.135 (0.110) data 0.000 (0.007) loss 0.5412 (0.6811) ce_loss 0.3118 (0.4821) teacher_loss 0.2939 (0.4596) loss_zs_kd 0.0453 (0.0505) loss_oracle 0.2246 (0.1962) acc 90.6250 (83.5156) kd_loss 0.4110 (0.3135) lr 2.0000e-03 eta 0:16:14
epoch [2/50] batch [60/181] time 0.085 (0.110) data 0.000 (0.005) loss 0.7726 (0.7508) ce_loss 0.3967 (0.4877) teacher_loss 0.3614 (0.4513) loss_zs_kd 0.0518 (0.0478) loss_oracle 0.3853 (0.2756) acc 84.3750 (83.1250) kd_loss 0.6643 (0.4225) lr 2.0000e-03 eta 0:16:05
epoch [2/50] batch [80/181] time 0.177 (0.106) data 0.000 (0.003) loss 0.9390 (0.7760) ce_loss 0.5537 (0.4878) teacher_loss 0.4866 (0.4452) loss_zs_kd 0.0339 (0.0465) loss_oracle 0.4355 (0.3076) acc 81.2500 (83.1641) kd_loss 0.7795 (0.5035) lr 2.0000e-03 eta 0:15:32
epoch [2/50] batch [100/181] time 0.079 (0.117) data 0.000 (0.003) loss 0.5773 (0.7961) ce_loss 0.2947 (0.4837) teacher_loss 0.2506 (0.4377) loss_zs_kd 0.0244 (0.0437) loss_oracle 0.3145 (0.3365) acc 90.6250 (83.2188) kd_loss 0.8201 (0.5655) lr 2.0000e-03 eta 0:17:04
epoch [2/50] batch [120/181] time 0.190 (0.125) data 0.000 (0.002) loss 0.6968 (0.7910) ce_loss 0.3491 (0.4808) teacher_loss 0.2877 (0.4314) loss_zs_kd 0.0340 (0.0432) loss_oracle 0.3921 (0.3381) acc 87.5000 (83.3594) kd_loss 0.7322 (0.6008) lr 2.0000e-03 eta 0:18:17
epoch [2/50] batch [140/181] time 0.089 (0.125) data 0.000 (0.002) loss 0.9924 (0.7890) ce_loss 0.7705 (0.4773) teacher_loss 0.5097 (0.4196) loss_zs_kd 0.0855 (0.0455) loss_oracle 0.4400 (0.3467) acc 68.7500 (83.5045) kd_loss 0.8514 (0.6237) lr 2.0000e-03 eta 0:18:12
epoch [2/50] batch [160/181] time 0.119 (0.125) data 0.000 (0.002) loss 0.7283 (0.8046) ce_loss 0.3333 (0.4844) teacher_loss 0.2491 (0.4140) loss_zs_kd 0.0819 (0.0509) loss_oracle 0.4382 (0.3651) acc 87.5000 (83.3008) kd_loss 0.7981 (0.6477) lr 2.0000e-03 eta 0:18:06
epoch [2/50] batch [180/181] time 0.082 (0.122) data 0.000 (0.002) loss 0.7859 (0.8149) ce_loss 0.4185 (0.4824) teacher_loss 0.2463 (0.4083) loss_zs_kd 0.0697 (0.0530) loss_oracle 0.5047 (0.3801) acc 87.5000 (83.2465) kd_loss 0.8252 (0.6666) lr 2.0000e-03 eta 0:17:41
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,363
* accuracy: 94.6%
* error: 5.4%
* macro_f1: 95.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      94.8%, epoch: 1 *******
******* Domain p best val test acc: 99.9%, epoch: 1 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [3/50] batch [20/181] time 0.143 (0.140) data 0.000 (0.011) loss 0.8679 (0.8722) ce_loss 0.4331 (0.4193) teacher_loss 0.2525 (0.2848) loss_zs_kd 0.0797 (0.0834) loss_oracle 0.5756 (0.5457) acc 84.3750 (84.0625) kd_loss 0.8522 (0.8424) lr 1.9980e-03 eta 0:20:09
epoch [3/50] batch [40/181] time 0.083 (0.129) data 0.000 (0.005) loss 0.9539 (0.8836) ce_loss 0.5166 (0.4274) teacher_loss 0.4286 (0.3043) loss_zs_kd 0.0680 (0.0784) loss_oracle 0.4912 (0.5401) acc 81.2500 (84.3750) kd_loss 0.7385 (0.8396) lr 1.9980e-03 eta 0:18:38
epoch [3/50] batch [60/181] time 0.115 (0.126) data 0.001 (0.004) loss 0.9687 (0.8908) ce_loss 0.5820 (0.4504) teacher_loss 0.4471 (0.3192) loss_zs_kd 0.0855 (0.0787) loss_oracle 0.4789 (0.5323) acc 78.1250 (83.0729) kd_loss 0.8703 (0.8402) lr 1.9980e-03 eta 0:18:07
epoch [3/50] batch [80/181] time 0.121 (0.124) data 0.000 (0.003) loss 0.9675 (0.8748) ce_loss 0.5088 (0.4488) teacher_loss 0.4043 (0.3285) loss_zs_kd 0.0606 (0.0770) loss_oracle 0.5329 (0.5078) acc 78.1250 (83.3594) kd_loss 0.8426 (0.8255) lr 1.9980e-03 eta 0:17:51
epoch [3/50] batch [100/181] time 0.109 (0.123) data 0.000 (0.002) loss 0.5459 (0.8681) ce_loss 0.1560 (0.4474) teacher_loss 0.1289 (0.3293) loss_zs_kd 0.0546 (0.0764) loss_oracle 0.3898 (0.5006) acc 96.8750 (83.3438) kd_loss 0.7637 (0.8243) lr 1.9980e-03 eta 0:17:38
epoch [3/50] batch [120/181] time 0.140 (0.122) data 0.000 (0.002) loss 0.9754 (0.8659) ce_loss 0.4644 (0.4484) teacher_loss 0.4149 (0.3317) loss_zs_kd 0.0542 (0.0763) loss_oracle 0.5334 (0.4961) acc 81.2500 (83.5677) kd_loss 0.8669 (0.8213) lr 1.9980e-03 eta 0:17:26
epoch [3/50] batch [140/181] time 0.071 (0.120) data 0.000 (0.002) loss 0.8311 (0.8682) ce_loss 0.4531 (0.4542) teacher_loss 0.3235 (0.3370) loss_zs_kd 0.0624 (0.0753) loss_oracle 0.4764 (0.4935) acc 84.3750 (83.2812) kd_loss 0.8519 (0.8223) lr 1.9980e-03 eta 0:17:04
epoch [3/50] batch [160/181] time 0.102 (0.118) data 0.000 (0.002) loss 0.7533 (0.8595) ce_loss 0.4192 (0.4530) teacher_loss 0.3634 (0.3396) loss_zs_kd 0.0520 (0.0735) loss_oracle 0.3640 (0.4832) acc 81.2500 (83.3203) kd_loss 0.8262 (0.8219) lr 1.9980e-03 eta 0:16:44
epoch [3/50] batch [180/181] time 0.094 (0.116) data 0.000 (0.001) loss 0.7667 (0.8543) ce_loss 0.3748 (0.4563) teacher_loss 0.1942 (0.3407) loss_zs_kd 0.1050 (0.0735) loss_oracle 0.5201 (0.4768) acc 87.5000 (83.2292) kd_loss 0.8622 (0.8204) lr 1.9980e-03 eta 0:16:25
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,375
* accuracy: 95.1%
* error: 4.9%
* macro_f1: 95.8%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.1%, epoch: 3 *******
******* Domain p best val test acc: 99.9%, epoch: 3 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [4/50] batch [20/181] time 0.107 (0.122) data 0.000 (0.013) loss 0.5510 (0.8163) ce_loss 0.1757 (0.4348) teacher_loss 0.1040 (0.3245) loss_zs_kd 0.0519 (0.0932) loss_oracle 0.4211 (0.4451) acc 90.6250 (83.5938) kd_loss 0.8416 (0.8040) lr 1.9921e-03 eta 0:17:14
epoch [4/50] batch [40/181] time 0.149 (0.110) data 0.000 (0.007) loss 1.1074 (0.8539) ce_loss 0.6436 (0.4608) teacher_loss 0.5601 (0.3452) loss_zs_kd 0.0877 (0.0844) loss_oracle 0.5034 (0.4665) acc 78.1250 (83.2812) kd_loss 0.8490 (0.8359) lr 1.9921e-03 eta 0:15:34
epoch [4/50] batch [60/181] time 0.061 (0.123) data 0.000 (0.004) loss 0.9660 (0.8570) ce_loss 0.5698 (0.4601) teacher_loss 0.4222 (0.3379) loss_zs_kd 0.0929 (0.0842) loss_oracle 0.4973 (0.4770) acc 81.2500 (83.5938) kd_loss 0.8524 (0.8471) lr 1.9921e-03 eta 0:17:16
epoch [4/50] batch [80/181] time 0.143 (0.126) data 0.000 (0.003) loss 0.7410 (0.8532) ce_loss 0.3767 (0.4543) teacher_loss 0.2690 (0.3383) loss_zs_kd 0.0418 (0.0808) loss_oracle 0.4510 (0.4744) acc 87.5000 (83.8281) kd_loss 0.9256 (0.8532) lr 1.9921e-03 eta 0:17:41
epoch [4/50] batch [100/181] time 0.086 (0.127) data 0.000 (0.003) loss 1.0080 (0.8594) ce_loss 0.5347 (0.4639) teacher_loss 0.4857 (0.3468) loss_zs_kd 0.1107 (0.0802) loss_oracle 0.4670 (0.4725) acc 81.2500 (83.4688) kd_loss 0.8439 (0.8519) lr 1.9921e-03 eta 0:17:45
epoch [4/50] batch [120/181] time 0.089 (0.123) data 0.000 (0.002) loss 0.7937 (0.8718) ce_loss 0.3940 (0.4781) teacher_loss 0.2939 (0.3581) loss_zs_kd 0.0730 (0.0802) loss_oracle 0.4633 (0.4735) acc 81.2500 (82.8385) kd_loss 0.8283 (0.8501) lr 1.9921e-03 eta 0:17:14
epoch [4/50] batch [140/181] time 0.106 (0.121) data 0.000 (0.002) loss 0.8297 (0.8623) ce_loss 0.4678 (0.4677) teacher_loss 0.3257 (0.3503) loss_zs_kd 0.0718 (0.0785) loss_oracle 0.4680 (0.4727) acc 81.2500 (83.0357) kd_loss 0.8983 (0.8480) lr 1.9921e-03 eta 0:16:48
epoch [4/50] batch [160/181] time 0.131 (0.118) data 0.000 (0.002) loss 0.8300 (0.8615) ce_loss 0.3430 (0.4640) teacher_loss 0.3350 (0.3475) loss_zs_kd 0.0603 (0.0787) loss_oracle 0.4649 (0.4747) acc 87.5000 (83.2031) kd_loss 0.7923 (0.8479) lr 1.9921e-03 eta 0:16:24
epoch [4/50] batch [180/181] time 0.077 (0.115) data 0.000 (0.002) loss 1.0247 (0.8611) ce_loss 0.6318 (0.4614) teacher_loss 0.5246 (0.3476) loss_zs_kd 0.0839 (0.0788) loss_oracle 0.4582 (0.4741) acc 87.5000 (83.2986) kd_loss 0.8268 (0.8461) lr 1.9921e-03 eta 0:16:01
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,384
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.5%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [5/50] batch [20/181] time 0.127 (0.135) data 0.000 (0.014) loss 0.7383 (0.8864) ce_loss 0.2996 (0.4608) teacher_loss 0.2566 (0.3781) loss_zs_kd 0.0586 (0.0727) loss_oracle 0.4523 (0.4720) acc 90.6250 (82.0312) kd_loss 0.8499 (0.8390) lr 1.9823e-03 eta 0:18:40
epoch [5/50] batch [40/181] time 0.111 (0.126) data 0.000 (0.007) loss 0.8911 (0.8613) ce_loss 0.4465 (0.4303) teacher_loss 0.3812 (0.3408) loss_zs_kd 0.0803 (0.0717) loss_oracle 0.4697 (0.4846) acc 81.2500 (83.6719) kd_loss 0.8843 (0.8452) lr 1.9823e-03 eta 0:17:26
epoch [5/50] batch [60/181] time 0.141 (0.123) data 0.000 (0.005) loss 0.7015 (0.8747) ce_loss 0.3047 (0.4421) teacher_loss 0.2408 (0.3521) loss_zs_kd 0.0790 (0.0799) loss_oracle 0.4212 (0.4826) acc 87.5000 (83.5938) kd_loss 0.8362 (0.8508) lr 1.9823e-03 eta 0:16:57
epoch [5/50] batch [80/181] time 0.139 (0.122) data 0.000 (0.004) loss 0.8471 (0.8775) ce_loss 0.4346 (0.4371) teacher_loss 0.3627 (0.3571) loss_zs_kd 0.0775 (0.0790) loss_oracle 0.4456 (0.4809) acc 87.5000 (83.9844) kd_loss 0.8253 (0.8566) lr 1.9823e-03 eta 0:16:43
epoch [5/50] batch [100/181] time 0.113 (0.122) data 0.000 (0.003) loss 0.8133 (0.8815) ce_loss 0.3179 (0.4419) teacher_loss 0.2918 (0.3585) loss_zs_kd 0.0881 (0.0792) loss_oracle 0.4774 (0.4834) acc 87.5000 (83.8125) kd_loss 0.8671 (0.8577) lr 1.9823e-03 eta 0:16:41
epoch [5/50] batch [120/181] time 0.098 (0.121) data 0.000 (0.003) loss 0.8610 (0.8866) ce_loss 0.3877 (0.4455) teacher_loss 0.3339 (0.3644) loss_zs_kd 0.0583 (0.0791) loss_oracle 0.4979 (0.4826) acc 84.3750 (83.5677) kd_loss 0.8426 (0.8538) lr 1.9823e-03 eta 0:16:32
epoch [5/50] batch [140/181] time 0.139 (0.121) data 0.000 (0.002) loss 0.7866 (0.8858) ce_loss 0.3091 (0.4468) teacher_loss 0.2601 (0.3629) loss_zs_kd 0.0942 (0.0808) loss_oracle 0.4793 (0.4826) acc 90.6250 (83.6161) kd_loss 0.8578 (0.8510) lr 1.9823e-03 eta 0:16:29
epoch [5/50] batch [160/181] time 0.087 (0.120) data 0.000 (0.002) loss 0.7108 (0.8799) ce_loss 0.2830 (0.4469) teacher_loss 0.2274 (0.3617) loss_zs_kd 0.0584 (0.0805) loss_oracle 0.4542 (0.4778) acc 84.3750 (83.6719) kd_loss 0.9004 (0.8485) lr 1.9823e-03 eta 0:16:21
epoch [5/50] batch [180/181] time 0.127 (0.119) data 0.000 (0.002) loss 1.0008 (0.8794) ce_loss 0.3840 (0.4452) teacher_loss 0.3566 (0.3598) loss_zs_kd 0.1081 (0.0799) loss_oracle 0.5901 (0.4797) acc 84.3750 (83.9410) kd_loss 0.9276 (0.8507) lr 1.9823e-03 eta 0:16:08
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,384
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.5%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [6/50] batch [20/181] time 0.184 (0.155) data 0.000 (0.015) loss 0.8044 (0.9034) ce_loss 0.3555 (0.4113) teacher_loss 0.2291 (0.3093) loss_zs_kd 0.1100 (0.0929) loss_oracle 0.5203 (0.5476) acc 90.6250 (85.9375) kd_loss 0.8513 (0.9136) lr 1.9686e-03 eta 0:21:01
epoch [6/50] batch [40/181] time 0.186 (0.146) data 0.000 (0.008) loss 0.6726 (0.8796) ce_loss 0.2844 (0.3916) teacher_loss 0.1432 (0.2923) loss_zs_kd 0.0595 (0.0926) loss_oracle 0.4996 (0.5410) acc 87.5000 (85.8594) kd_loss 0.9231 (0.9178) lr 1.9686e-03 eta 0:19:40
epoch [6/50] batch [60/181] time 0.088 (0.154) data 0.000 (0.005) loss 0.9275 (0.8745) ce_loss 0.4392 (0.3936) teacher_loss 0.3306 (0.2963) loss_zs_kd 0.0834 (0.0911) loss_oracle 0.5552 (0.5326) acc 84.3750 (85.8854) kd_loss 0.9713 (0.9213) lr 1.9686e-03 eta 0:20:44
epoch [6/50] batch [80/181] time 0.143 (0.142) data 0.000 (0.004) loss 0.9696 (0.8846) ce_loss 0.4353 (0.3923) teacher_loss 0.3533 (0.2988) loss_zs_kd 0.1114 (0.0910) loss_oracle 0.5606 (0.5403) acc 81.2500 (86.0547) kd_loss 0.9124 (0.9268) lr 1.9686e-03 eta 0:19:08
epoch [6/50] batch [100/181] time 0.116 (0.137) data 0.000 (0.003) loss 1.1384 (0.8989) ce_loss 0.6323 (0.4012) teacher_loss 0.4142 (0.3042) loss_zs_kd 0.1006 (0.0931) loss_oracle 0.6739 (0.5483) acc 81.2500 (85.6875) kd_loss 1.0120 (0.9329) lr 1.9686e-03 eta 0:18:25
epoch [6/50] batch [120/181] time 0.133 (0.135) data 0.000 (0.003) loss 1.1895 (0.9038) ce_loss 0.6318 (0.4031) teacher_loss 0.5451 (0.3036) loss_zs_kd 0.1089 (0.0928) loss_oracle 0.5900 (0.5538) acc 81.2500 (85.6510) kd_loss 0.9720 (0.9365) lr 1.9686e-03 eta 0:18:00
epoch [6/50] batch [140/181] time 0.141 (0.131) data 0.000 (0.002) loss 1.0501 (0.9237) ce_loss 0.4907 (0.4176) teacher_loss 0.3003 (0.3126) loss_zs_kd 0.1427 (0.0959) loss_oracle 0.6784 (0.5631) acc 81.2500 (85.0893) kd_loss 1.1126 (0.9467) lr 1.9686e-03 eta 0:17:31
epoch [6/50] batch [160/181] time 0.113 (0.130) data 0.000 (0.002) loss 0.9047 (0.9344) ce_loss 0.3684 (0.4238) teacher_loss 0.3188 (0.3134) loss_zs_kd 0.0862 (0.0979) loss_oracle 0.5428 (0.5721) acc 81.2500 (84.9609) kd_loss 1.0427 (0.9567) lr 1.9686e-03 eta 0:17:14
epoch [6/50] batch [180/181] time 0.098 (0.126) data 0.000 (0.002) loss 0.8261 (0.9328) ce_loss 0.3408 (0.4263) teacher_loss 0.2439 (0.3139) loss_zs_kd 0.0854 (0.0997) loss_oracle 0.5396 (0.5691) acc 84.3750 (84.7743) kd_loss 0.9422 (0.9614) lr 1.9686e-03 eta 0:16:44
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,387
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.1%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.6%, epoch: 6 *******
******* Domain p best val test acc: 99.9%, epoch: 6 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [7/50] batch [20/181] time 0.124 (0.140) data 0.000 (0.015) loss 0.9137 (0.9436) ce_loss 0.3625 (0.4314) teacher_loss 0.2630 (0.3152) loss_zs_kd 0.1046 (0.1159) loss_oracle 0.5985 (0.5704) acc 90.6250 (82.9688) kd_loss 0.9547 (0.9930) lr 1.9511e-03 eta 0:18:32
epoch [7/50] batch [40/181] time 0.111 (0.132) data 0.000 (0.008) loss 0.8079 (0.9415) ce_loss 0.3184 (0.4312) teacher_loss 0.2277 (0.3188) loss_zs_kd 0.0662 (0.1081) loss_oracle 0.5471 (0.5686) acc 87.5000 (83.2031) kd_loss 0.9741 (0.9920) lr 1.9511e-03 eta 0:17:24
epoch [7/50] batch [60/181] time 0.093 (0.132) data 0.001 (0.005) loss 1.0949 (0.9314) ce_loss 0.5815 (0.4261) teacher_loss 0.4174 (0.3065) loss_zs_kd 0.1408 (0.1083) loss_oracle 0.6072 (0.5707) acc 71.8750 (83.9062) kd_loss 0.9535 (0.9854) lr 1.9511e-03 eta 0:17:22
epoch [7/50] batch [80/181] time 0.147 (0.131) data 0.000 (0.004) loss 0.8704 (0.9282) ce_loss 0.3235 (0.4206) teacher_loss 0.3204 (0.3009) loss_zs_kd 0.0834 (0.1069) loss_oracle 0.5083 (0.5738) acc 87.5000 (84.2969) kd_loss 0.9555 (0.9767) lr 1.9511e-03 eta 0:17:11
epoch [7/50] batch [100/181] time 0.093 (0.130) data 0.000 (0.003) loss 1.0624 (0.9303) ce_loss 0.5723 (0.4181) teacher_loss 0.4443 (0.2968) loss_zs_kd 0.0872 (0.1064) loss_oracle 0.5746 (0.5803) acc 81.2500 (84.5000) kd_loss 1.0176 (0.9729) lr 1.9511e-03 eta 0:17:03
epoch [7/50] batch [120/181] time 0.146 (0.130) data 0.000 (0.003) loss 1.0195 (0.9385) ce_loss 0.4600 (0.4217) teacher_loss 0.2559 (0.3017) loss_zs_kd 0.1065 (0.1040) loss_oracle 0.7103 (0.5848) acc 78.1250 (84.4010) kd_loss 1.0180 (0.9689) lr 1.9511e-03 eta 0:17:00
epoch [7/50] batch [140/181] time 0.090 (0.128) data 0.000 (0.002) loss 1.0126 (0.9510) ce_loss 0.5688 (0.4258) teacher_loss 0.3186 (0.3038) loss_zs_kd 0.0909 (0.1044) loss_oracle 0.6486 (0.5950) acc 78.1250 (84.1295) kd_loss 1.0050 (0.9711) lr 1.9511e-03 eta 0:16:45
epoch [7/50] batch [160/181] time 0.065 (0.128) data 0.000 (0.002) loss 1.0450 (0.9672) ce_loss 0.2888 (0.4235) teacher_loss 0.2188 (0.3033) loss_zs_kd 0.1007 (0.1040) loss_oracle 0.7758 (0.6119) acc 87.5000 (84.1992) kd_loss 1.0206 (0.9776) lr 1.9511e-03 eta 0:16:35
epoch [7/50] batch [180/181] time 0.142 (0.128) data 0.000 (0.002) loss 0.8093 (0.9720) ce_loss 0.3999 (0.4222) teacher_loss 0.1634 (0.3028) loss_zs_kd 0.0695 (0.1036) loss_oracle 0.6112 (0.6174) acc 87.5000 (84.2361) kd_loss 1.0828 (0.9855) lr 1.9511e-03 eta 0:16:34
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,379
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.6%, epoch: 6 *******
******* Domain p best val test acc: 99.9%, epoch: 6 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [8/50] batch [20/181] time 0.136 (0.139) data 0.000 (0.013) loss 1.2492 (1.1184) ce_loss 0.5762 (0.4540) teacher_loss 0.4086 (0.3160) loss_zs_kd 0.0737 (0.1347) loss_oracle 0.8038 (0.7350) acc 84.3750 (83.9062) kd_loss 1.0141 (1.0312) lr 1.9298e-03 eta 0:18:02
epoch [8/50] batch [40/181] time 0.082 (0.129) data 0.000 (0.006) loss 1.0386 (1.1121) ce_loss 0.2328 (0.4363) teacher_loss 0.1833 (0.3156) loss_zs_kd 0.1027 (0.1132) loss_oracle 0.8040 (0.7399) acc 96.8750 (84.0625) kd_loss 1.0384 (1.0325) lr 1.9298e-03 eta 0:16:40
epoch [8/50] batch [60/181] time 0.091 (0.128) data 0.000 (0.004) loss 1.0379 (1.1190) ce_loss 0.4048 (0.4550) teacher_loss 0.3596 (0.3322) loss_zs_kd 0.0878 (0.1106) loss_oracle 0.6343 (0.7315) acc 87.5000 (82.9167) kd_loss 0.9924 (1.0345) lr 1.9298e-03 eta 0:16:25
epoch [8/50] batch [80/181] time 0.140 (0.126) data 0.000 (0.003) loss 0.9805 (1.0986) ce_loss 0.4912 (0.4481) teacher_loss 0.2340 (0.3229) loss_zs_kd 0.0761 (0.1072) loss_oracle 0.7085 (0.7222) acc 75.0000 (82.7734) kd_loss 1.0672 (1.0366) lr 1.9298e-03 eta 0:16:12
epoch [8/50] batch [100/181] time 0.137 (0.124) data 0.000 (0.003) loss 1.2491 (1.0954) ce_loss 0.5703 (0.4430) teacher_loss 0.4746 (0.3181) loss_zs_kd 0.0872 (0.1075) loss_oracle 0.7309 (0.7236) acc 78.1250 (83.0000) kd_loss 0.9552 (1.0341) lr 1.9298e-03 eta 0:15:55
epoch [8/50] batch [120/181] time 0.142 (0.122) data 0.000 (0.002) loss 1.0978 (1.0879) ce_loss 0.5332 (0.4362) teacher_loss 0.3408 (0.3129) loss_zs_kd 0.0754 (0.1025) loss_oracle 0.7194 (0.7237) acc 84.3750 (83.4115) kd_loss 1.0161 (1.0325) lr 1.9298e-03 eta 0:15:36
epoch [8/50] batch [140/181] time 0.110 (0.121) data 0.000 (0.002) loss 1.0618 (1.0834) ce_loss 0.4402 (0.4357) teacher_loss 0.2946 (0.3116) loss_zs_kd 0.0866 (0.1010) loss_oracle 0.7239 (0.7213) acc 84.3750 (83.5714) kd_loss 1.0643 (1.0326) lr 1.9298e-03 eta 0:15:23
epoch [8/50] batch [160/181] time 0.075 (0.120) data 0.000 (0.002) loss 1.2659 (1.0837) ce_loss 0.6724 (0.4383) teacher_loss 0.4253 (0.3129) loss_zs_kd 0.1479 (0.1010) loss_oracle 0.7667 (0.7203) acc 84.3750 (83.6523) kd_loss 1.0184 (1.0296) lr 1.9298e-03 eta 0:15:12
epoch [8/50] batch [180/181] time 0.077 (0.117) data 0.000 (0.002) loss 1.1235 (1.0879) ce_loss 0.3928 (0.4452) teacher_loss 0.3500 (0.3170) loss_zs_kd 0.0787 (0.1019) loss_oracle 0.7342 (0.7199) acc 90.6250 (83.4549) kd_loss 1.0017 (1.0266) lr 1.9298e-03 eta 0:14:49
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,378
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      95.6%, epoch: 6 *******
******* Domain p best val test acc: 99.9%, epoch: 6 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [9/50] batch [20/181] time 0.116 (0.135) data 0.001 (0.013) loss 1.0379 (1.0693) ce_loss 0.4263 (0.4702) teacher_loss 0.3078 (0.2984) loss_zs_kd 0.1577 (0.1198) loss_oracle 0.6513 (0.7111) acc 87.5000 (82.1875) kd_loss 1.0205 (1.0066) lr 1.9048e-03 eta 0:17:00
epoch [9/50] batch [40/181] time 0.142 (0.128) data 0.000 (0.007) loss 0.9609 (1.0736) ce_loss 0.4336 (0.4768) teacher_loss 0.2673 (0.3045) loss_zs_kd 0.0895 (0.1171) loss_oracle 0.6488 (0.7105) acc 87.5000 (82.1875) kd_loss 1.0388 (1.0031) lr 1.9048e-03 eta 0:16:04
epoch [9/50] batch [60/181] time 0.095 (0.124) data 0.000 (0.005) loss 0.9444 (1.0728) ce_loss 0.3384 (0.4738) teacher_loss 0.1978 (0.3172) loss_zs_kd 0.0859 (0.1086) loss_oracle 0.7037 (0.7012) acc 84.3750 (81.8229) kd_loss 0.9720 (0.9975) lr 1.9048e-03 eta 0:15:36
epoch [9/50] batch [80/181] time 0.096 (0.123) data 0.000 (0.004) loss 1.0359 (1.0712) ce_loss 0.3137 (0.4698) teacher_loss 0.3077 (0.3177) loss_zs_kd 0.0791 (0.1050) loss_oracle 0.6887 (0.7010) acc 90.6250 (82.2656) kd_loss 0.9283 (0.9952) lr 1.9048e-03 eta 0:15:26
epoch [9/50] batch [100/181] time 0.142 (0.123) data 0.000 (0.003) loss 0.9820 (1.0643) ce_loss 0.3403 (0.4663) teacher_loss 0.2491 (0.3153) loss_zs_kd 0.0425 (0.1028) loss_oracle 0.7116 (0.6976) acc 87.5000 (82.3125) kd_loss 1.0249 (0.9930) lr 1.9048e-03 eta 0:15:21
epoch [9/50] batch [120/181] time 0.121 (0.122) data 0.000 (0.002) loss 0.9527 (1.0625) ce_loss 0.4932 (0.4661) teacher_loss 0.3176 (0.3167) loss_zs_kd 0.0870 (0.1034) loss_oracle 0.5916 (0.6941) acc 84.3750 (82.4219) kd_loss 0.9869 (0.9896) lr 1.9048e-03 eta 0:15:13
epoch [9/50] batch [140/181] time 0.189 (0.122) data 0.000 (0.002) loss 0.9330 (1.0634) ce_loss 0.4070 (0.4706) teacher_loss 0.2031 (0.3224) loss_zs_kd 0.0640 (0.1009) loss_oracle 0.6979 (0.6906) acc 87.5000 (82.4107) kd_loss 1.0182 (0.9880) lr 1.9048e-03 eta 0:15:13
epoch [9/50] batch [160/181] time 0.086 (0.125) data 0.000 (0.002) loss 1.0101 (1.0604) ce_loss 0.4609 (0.4683) teacher_loss 0.3374 (0.3211) loss_zs_kd 0.0962 (0.1014) loss_oracle 0.6246 (0.6886) acc 87.5000 (82.6172) kd_loss 0.9335 (0.9845) lr 1.9048e-03 eta 0:15:28
epoch [9/50] batch [180/181] time 0.187 (0.131) data 0.000 (0.002) loss 1.0751 (1.0477) ce_loss 0.5254 (0.4586) teacher_loss 0.4088 (0.3138) loss_zs_kd 0.1156 (0.1005) loss_oracle 0.6085 (0.6836) acc 71.8750 (83.0035) kd_loss 0.9460 (0.9822) lr 1.9048e-03 eta 0:16:10
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,378
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.6%, epoch: 6 *******
******* Domain p best val test acc: 99.9%, epoch: 6 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [10/50] batch [20/181] time 0.139 (0.131) data 0.000 (0.014) loss 0.8589 (0.9969) ce_loss 0.4294 (0.4868) teacher_loss 0.2406 (0.3358) loss_zs_kd 0.0873 (0.0949) loss_oracle 0.5746 (0.6137) acc 87.5000 (82.0312) kd_loss 0.9823 (0.9477) lr 1.8763e-03 eta 0:16:07
epoch [10/50] batch [40/181] time 0.137 (0.122) data 0.000 (0.007) loss 0.8078 (0.9586) ce_loss 0.2893 (0.4518) teacher_loss 0.2268 (0.3080) loss_zs_kd 0.0937 (0.0954) loss_oracle 0.5341 (0.6029) acc 90.6250 (84.0625) kd_loss 0.9132 (0.9459) lr 1.8763e-03 eta 0:14:59
epoch [10/50] batch [60/181] time 0.129 (0.119) data 0.000 (0.005) loss 0.8322 (0.9330) ce_loss 0.3755 (0.4354) teacher_loss 0.2372 (0.3002) loss_zs_kd 0.0940 (0.0941) loss_oracle 0.5480 (0.5857) acc 90.6250 (84.3229) kd_loss 0.9665 (0.9430) lr 1.8763e-03 eta 0:14:35
epoch [10/50] batch [80/181] time 0.093 (0.115) data 0.000 (0.004) loss 0.7752 (0.9367) ce_loss 0.2375 (0.4478) teacher_loss 0.1225 (0.3042) loss_zs_kd 0.1068 (0.0958) loss_oracle 0.5992 (0.5846) acc 93.7500 (83.7500) kd_loss 0.9258 (0.9431) lr 1.8763e-03 eta 0:14:05
epoch [10/50] batch [100/181] time 0.104 (0.114) data 0.000 (0.003) loss 1.0446 (0.9429) ce_loss 0.5269 (0.4568) teacher_loss 0.3667 (0.3025) loss_zs_kd 0.1872 (0.1001) loss_oracle 0.5843 (0.5904) acc 75.0000 (83.3125) kd_loss 0.8988 (0.9415) lr 1.8763e-03 eta 0:13:54
epoch [10/50] batch [120/181] time 0.100 (0.113) data 0.000 (0.002) loss 0.9819 (0.9485) ce_loss 0.4519 (0.4584) teacher_loss 0.2946 (0.3068) loss_zs_kd 0.0939 (0.1002) loss_oracle 0.6404 (0.5916) acc 84.3750 (83.1510) kd_loss 0.9803 (0.9409) lr 1.8763e-03 eta 0:13:47
epoch [10/50] batch [140/181] time 0.079 (0.114) data 0.000 (0.002) loss 0.9315 (0.9523) ce_loss 0.5264 (0.4613) teacher_loss 0.3191 (0.3100) loss_zs_kd 0.1126 (0.0992) loss_oracle 0.5561 (0.5927) acc 75.0000 (83.0804) kd_loss 0.9781 (0.9381) lr 1.8763e-03 eta 0:13:49
epoch [10/50] batch [160/181] time 0.134 (0.114) data 0.000 (0.002) loss 0.9237 (0.9407) ce_loss 0.5962 (0.4544) teacher_loss 0.2712 (0.3036) loss_zs_kd 0.1057 (0.0993) loss_oracle 0.5997 (0.5875) acc 75.0000 (83.2227) kd_loss 0.9671 (0.9357) lr 1.8763e-03 eta 0:13:47
epoch [10/50] batch [180/181] time 0.098 (0.112) data 0.000 (0.002) loss 0.8505 (0.9369) ce_loss 0.5034 (0.4497) teacher_loss 0.2017 (0.3015) loss_zs_kd 0.0846 (0.0986) loss_oracle 0.6065 (0.5861) acc 78.1250 (83.3160) kd_loss 0.9687 (0.9335) lr 1.8763e-03 eta 0:13:30
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,378
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      95.6%, epoch: 6 *******
******* Domain p best val test acc: 99.9%, epoch: 6 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [11/50] batch [20/181] time 0.134 (0.126) data 0.000 (0.014) loss 1.0954 (0.9273) ce_loss 0.6235 (0.4181) teacher_loss 0.3807 (0.2788) loss_zs_kd 0.1468 (0.1118) loss_oracle 0.6413 (0.5926) acc 68.7500 (83.9062) kd_loss 0.9620 (0.9109) lr 1.8443e-03 eta 0:15:09
epoch [11/50] batch [40/181] time 0.084 (0.117) data 0.000 (0.007) loss 0.9323 (0.9255) ce_loss 0.4365 (0.4330) teacher_loss 0.2335 (0.2750) loss_zs_kd 0.1063 (0.1085) loss_oracle 0.6456 (0.5962) acc 84.3750 (84.4531) kd_loss 0.9930 (0.9172) lr 1.8443e-03 eta 0:14:02
epoch [11/50] batch [60/181] time 0.076 (0.112) data 0.001 (0.005) loss 0.9604 (0.9465) ce_loss 0.5327 (0.4529) teacher_loss 0.3557 (0.2904) loss_zs_kd 0.0791 (0.1064) loss_oracle 0.5651 (0.6029) acc 78.1250 (84.0104) kd_loss 0.9182 (0.9282) lr 1.8443e-03 eta 0:13:26
epoch [11/50] batch [80/181] time 0.082 (0.110) data 0.000 (0.004) loss 0.8608 (0.9334) ce_loss 0.5425 (0.4406) teacher_loss 0.3392 (0.2838) loss_zs_kd 0.0774 (0.1074) loss_oracle 0.4830 (0.5959) acc 84.3750 (84.1797) kd_loss 0.8384 (0.9260) lr 1.8443e-03 eta 0:13:05
epoch [11/50] batch [100/181] time 0.084 (0.109) data 0.000 (0.003) loss 0.8605 (0.9246) ce_loss 0.3018 (0.4267) teacher_loss 0.1501 (0.2775) loss_zs_kd 0.0598 (0.1052) loss_oracle 0.6805 (0.5945) acc 90.6250 (84.8750) kd_loss 1.0390 (0.9222) lr 1.8443e-03 eta 0:12:57
epoch [11/50] batch [120/181] time 0.135 (0.109) data 0.000 (0.002) loss 1.0129 (0.9200) ce_loss 0.5171 (0.4220) teacher_loss 0.3736 (0.2789) loss_zs_kd 0.0975 (0.1011) loss_oracle 0.5906 (0.5905) acc 78.1250 (84.8698) kd_loss 0.9025 (0.9185) lr 1.8443e-03 eta 0:12:55
epoch [11/50] batch [140/181] time 0.166 (0.110) data 0.000 (0.002) loss 0.9792 (0.9242) ce_loss 0.6313 (0.4262) teacher_loss 0.3631 (0.2832) loss_zs_kd 0.0822 (0.1005) loss_oracle 0.5750 (0.5908) acc 81.2500 (84.7321) kd_loss 0.9419 (0.9195) lr 1.8443e-03 eta 0:13:04
epoch [11/50] batch [160/181] time 0.094 (0.112) data 0.000 (0.002) loss 0.8332 (0.9245) ce_loss 0.2927 (0.4266) teacher_loss 0.1900 (0.2855) loss_zs_kd 0.0901 (0.0989) loss_oracle 0.5982 (0.5895) acc 93.7500 (84.7070) kd_loss 0.9683 (0.9181) lr 1.8443e-03 eta 0:13:12
epoch [11/50] batch [180/181] time 0.188 (0.118) data 0.000 (0.002) loss 0.8790 (0.9276) ce_loss 0.4663 (0.4299) teacher_loss 0.2732 (0.2906) loss_zs_kd 0.0806 (0.0983) loss_oracle 0.5655 (0.5878) acc 87.5000 (84.7396) kd_loss 0.9303 (0.9161) lr 1.8443e-03 eta 0:13:51
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,380
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.6%, epoch: 6 *******
******* Domain p best val test acc: 99.9%, epoch: 6 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [12/50] batch [20/181] time 0.136 (0.131) data 0.000 (0.014) loss 1.0015 (0.9274) ce_loss 0.4656 (0.4562) teacher_loss 0.2242 (0.3059) loss_zs_kd 0.1152 (0.1002) loss_oracle 0.7197 (0.5714) acc 75.0000 (82.0312) kd_loss 0.9886 (0.9086) lr 1.8090e-03 eta 0:15:23
epoch [12/50] batch [40/181] time 0.129 (0.119) data 0.000 (0.007) loss 0.9631 (0.9013) ce_loss 0.5703 (0.4196) teacher_loss 0.4649 (0.2840) loss_zs_kd 0.0778 (0.0954) loss_oracle 0.4593 (0.5696) acc 81.2500 (84.2969) kd_loss 0.8294 (0.9088) lr 1.8090e-03 eta 0:13:57
epoch [12/50] batch [60/181] time 0.106 (0.116) data 0.000 (0.005) loss 0.9308 (0.9085) ce_loss 0.5225 (0.4239) teacher_loss 0.2762 (0.2917) loss_zs_kd 0.1206 (0.0938) loss_oracle 0.5943 (0.5699) acc 81.2500 (83.6458) kd_loss 0.9532 (0.9073) lr 1.8090e-03 eta 0:13:29
epoch [12/50] batch [80/181] time 0.139 (0.116) data 0.000 (0.004) loss 0.8600 (0.9202) ce_loss 0.3745 (0.4320) teacher_loss 0.1629 (0.2944) loss_zs_kd 0.1394 (0.0969) loss_oracle 0.6273 (0.5773) acc 90.6250 (83.4766) kd_loss 0.9395 (0.9104) lr 1.8090e-03 eta 0:13:30
epoch [12/50] batch [100/181] time 0.106 (0.116) data 0.000 (0.003) loss 0.7617 (0.9253) ce_loss 0.3640 (0.4319) teacher_loss 0.1547 (0.2905) loss_zs_kd 0.0768 (0.0989) loss_oracle 0.5686 (0.5853) acc 90.6250 (83.1562) kd_loss 0.8599 (0.9144) lr 1.8090e-03 eta 0:13:30
epoch [12/50] batch [120/181] time 0.075 (0.116) data 0.000 (0.003) loss 0.9878 (0.9342) ce_loss 0.3645 (0.4387) teacher_loss 0.3133 (0.2935) loss_zs_kd 0.1205 (0.1000) loss_oracle 0.6143 (0.5907) acc 87.5000 (83.0729) kd_loss 0.8725 (0.9127) lr 1.8090e-03 eta 0:13:23
epoch [12/50] batch [140/181] time 0.134 (0.114) data 0.000 (0.002) loss 0.9627 (0.9427) ce_loss 0.3884 (0.4402) teacher_loss 0.2696 (0.2930) loss_zs_kd 0.1100 (0.1011) loss_oracle 0.6382 (0.5992) acc 87.5000 (83.1696) kd_loss 0.9482 (0.9142) lr 1.8090e-03 eta 0:13:11
epoch [12/50] batch [160/181] time 0.131 (0.113) data 0.000 (0.002) loss 0.9902 (0.9444) ce_loss 0.4768 (0.4363) teacher_loss 0.3302 (0.2902) loss_zs_kd 0.0843 (0.1014) loss_oracle 0.6179 (0.6035) acc 84.3750 (83.4766) kd_loss 0.8798 (0.9135) lr 1.8090e-03 eta 0:13:00
epoch [12/50] batch [180/181] time 0.080 (0.111) data 0.000 (0.002) loss 0.9913 (0.9488) ce_loss 0.4124 (0.4367) teacher_loss 0.2862 (0.2907) loss_zs_kd 0.0982 (0.1008) loss_oracle 0.6560 (0.6078) acc 78.1250 (83.4201) kd_loss 0.9432 (0.9144) lr 1.8090e-03 eta 0:12:41
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,387
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      95.6%, epoch: 6 *******
******* Domain p best val test acc: 99.9%, epoch: 6 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [13/50] batch [20/181] time 0.143 (0.131) data 0.000 (0.014) loss 0.8453 (1.0318) ce_loss 0.3188 (0.4751) teacher_loss 0.1849 (0.2899) loss_zs_kd 0.1070 (0.1189) loss_oracle 0.6069 (0.6825) acc 84.3750 (82.9688) kd_loss 0.9764 (0.9484) lr 1.7705e-03 eta 0:15:00
epoch [13/50] batch [40/181] time 0.067 (0.119) data 0.000 (0.007) loss 0.9222 (0.9931) ce_loss 0.3428 (0.4323) teacher_loss 0.1663 (0.2752) loss_zs_kd 0.0679 (0.1064) loss_oracle 0.7219 (0.6648) acc 87.5000 (84.2188) kd_loss 0.9278 (0.9253) lr 1.7705e-03 eta 0:13:34
epoch [13/50] batch [60/181] time 0.124 (0.115) data 0.000 (0.005) loss 0.9952 (0.9872) ce_loss 0.4412 (0.4300) teacher_loss 0.3050 (0.2816) loss_zs_kd 0.0779 (0.1026) loss_oracle 0.6512 (0.6542) acc 84.3750 (84.5833) kd_loss 0.9195 (0.9235) lr 1.7705e-03 eta 0:13:06
epoch [13/50] batch [80/181] time 0.110 (0.111) data 0.000 (0.004) loss 1.0285 (0.9755) ce_loss 0.5967 (0.4261) teacher_loss 0.3477 (0.2813) loss_zs_kd 0.0905 (0.0990) loss_oracle 0.6356 (0.6447) acc 75.0000 (84.6875) kd_loss 0.9057 (0.9194) lr 1.7705e-03 eta 0:12:37
epoch [13/50] batch [100/181] time 0.106 (0.109) data 0.000 (0.003) loss 0.9835 (0.9798) ce_loss 0.3821 (0.4251) teacher_loss 0.2587 (0.2860) loss_zs_kd 0.1241 (0.1014) loss_oracle 0.6628 (0.6431) acc 84.3750 (84.5312) kd_loss 0.8973 (0.9164) lr 1.7705e-03 eta 0:12:21
epoch [13/50] batch [120/181] time 0.117 (0.110) data 0.000 (0.003) loss 0.8978 (0.9802) ce_loss 0.1670 (0.4262) teacher_loss 0.1705 (0.2864) loss_zs_kd 0.0876 (0.1019) loss_oracle 0.6836 (0.6428) acc 96.8750 (84.4792) kd_loss 0.9520 (0.9173) lr 1.7705e-03 eta 0:12:20
epoch [13/50] batch [140/181] time 0.156 (0.112) data 0.000 (0.002) loss 0.8227 (0.9857) ce_loss 0.2306 (0.4331) teacher_loss 0.1103 (0.2922) loss_zs_kd 0.0970 (0.1024) loss_oracle 0.6638 (0.6423) acc 90.6250 (84.1518) kd_loss 0.9860 (0.9212) lr 1.7705e-03 eta 0:12:37
epoch [13/50] batch [160/181] time 0.145 (0.114) data 0.000 (0.002) loss 1.1765 (0.9852) ce_loss 0.5522 (0.4237) teacher_loss 0.3457 (0.2853) loss_zs_kd 0.1116 (0.1024) loss_oracle 0.7751 (0.6487) acc 78.1250 (84.5117) kd_loss 1.0363 (0.9314) lr 1.7705e-03 eta 0:12:48
epoch [13/50] batch [180/181] time 0.132 (0.119) data 0.000 (0.002) loss 1.0172 (0.9819) ce_loss 0.5464 (0.4211) teacher_loss 0.2969 (0.2818) loss_zs_kd 0.1423 (0.1028) loss_oracle 0.6492 (0.6487) acc 78.1250 (84.5312) kd_loss 0.9498 (0.9389) lr 1.7705e-03 eta 0:13:15
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,381
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.6%, epoch: 6 *******
******* Domain p best val test acc: 99.9%, epoch: 6 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [14/50] batch [20/181] time 0.139 (0.126) data 0.000 (0.013) loss 0.9275 (1.0175) ce_loss 0.3699 (0.4469) teacher_loss 0.2006 (0.2989) loss_zs_kd 0.0578 (0.0982) loss_oracle 0.6980 (0.6695) acc 87.5000 (83.9062) kd_loss 1.0558 (0.9824) lr 1.7290e-03 eta 0:14:01
epoch [14/50] batch [40/181] time 0.117 (0.118) data 0.000 (0.007) loss 0.8636 (1.0174) ce_loss 0.1245 (0.4316) teacher_loss 0.0911 (0.2963) loss_zs_kd 0.0777 (0.1046) loss_oracle 0.7337 (0.6688) acc 96.8750 (84.6094) kd_loss 1.0600 (0.9794) lr 1.7290e-03 eta 0:13:07
epoch [14/50] batch [60/181] time 0.099 (0.115) data 0.000 (0.004) loss 0.8473 (1.0014) ce_loss 0.2900 (0.4352) teacher_loss 0.1825 (0.2962) loss_zs_kd 0.0680 (0.0985) loss_oracle 0.6308 (0.6559) acc 90.6250 (84.4271) kd_loss 0.9855 (0.9646) lr 1.7290e-03 eta 0:12:42
epoch [14/50] batch [80/181] time 0.089 (0.113) data 0.000 (0.003) loss 1.0759 (0.9979) ce_loss 0.5293 (0.4371) teacher_loss 0.3019 (0.2984) loss_zs_kd 0.1142 (0.1006) loss_oracle 0.7169 (0.6492) acc 81.2500 (84.2578) kd_loss 1.0438 (0.9558) lr 1.7290e-03 eta 0:12:29
epoch [14/50] batch [100/181] time 0.132 (0.113) data 0.000 (0.003) loss 1.0712 (0.9905) ce_loss 0.4275 (0.4305) teacher_loss 0.3915 (0.2942) loss_zs_kd 0.0752 (0.0978) loss_oracle 0.6421 (0.6474) acc 81.2500 (84.2188) kd_loss 0.8973 (0.9487) lr 1.7290e-03 eta 0:12:22
epoch [14/50] batch [120/181] time 0.134 (0.111) data 0.000 (0.002) loss 1.0828 (0.9963) ce_loss 0.4126 (0.4275) teacher_loss 0.3939 (0.2970) loss_zs_kd 0.0563 (0.0969) loss_oracle 0.6608 (0.6509) acc 87.5000 (84.4271) kd_loss 0.9361 (0.9448) lr 1.7290e-03 eta 0:12:13
epoch [14/50] batch [140/181] time 0.116 (0.111) data 0.000 (0.002) loss 1.1591 (0.9959) ce_loss 0.6133 (0.4280) teacher_loss 0.4165 (0.2993) loss_zs_kd 0.1305 (0.0965) loss_oracle 0.6773 (0.6484) acc 84.3750 (84.7098) kd_loss 1.0446 (0.9411) lr 1.7290e-03 eta 0:12:09
epoch [14/50] batch [160/181] time 0.082 (0.111) data 0.000 (0.002) loss 1.0788 (0.9964) ce_loss 0.3479 (0.4321) teacher_loss 0.2517 (0.3013) loss_zs_kd 0.0936 (0.0961) loss_oracle 0.7802 (0.6470) acc 84.3750 (84.4727) kd_loss 0.9919 (0.9402) lr 1.7290e-03 eta 0:12:05
epoch [14/50] batch [180/181] time 0.098 (0.110) data 0.000 (0.002) loss 1.0002 (0.9936) ce_loss 0.4778 (0.4298) teacher_loss 0.3024 (0.2976) loss_zs_kd 0.0768 (0.0959) loss_oracle 0.6594 (0.6481) acc 81.2500 (84.4965) kd_loss 1.0295 (0.9446) lr 1.7290e-03 eta 0:11:54
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,382
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.6%, epoch: 6 *******
******* Domain p best val test acc: 99.9%, epoch: 6 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [15/50] batch [20/181] time 0.092 (0.136) data 0.000 (0.014) loss 1.0520 (0.9765) ce_loss 0.5728 (0.4266) teacher_loss 0.3544 (0.2978) loss_zs_kd 0.0971 (0.0983) loss_oracle 0.6490 (0.6296) acc 78.1250 (85.1562) kd_loss 0.9136 (0.9259) lr 1.6845e-03 eta 0:14:43
epoch [15/50] batch [40/181] time 0.093 (0.128) data 0.000 (0.007) loss 0.9739 (0.9911) ce_loss 0.3579 (0.4426) teacher_loss 0.2934 (0.2983) loss_zs_kd 0.0951 (0.1044) loss_oracle 0.6329 (0.6406) acc 87.5000 (84.2188) kd_loss 0.9121 (0.9369) lr 1.6845e-03 eta 0:13:46
epoch [15/50] batch [60/181] time 0.113 (0.125) data 0.000 (0.005) loss 1.0375 (0.9871) ce_loss 0.3513 (0.4265) teacher_loss 0.3025 (0.2942) loss_zs_kd 0.0825 (0.0986) loss_oracle 0.6938 (0.6435) acc 81.2500 (84.4271) kd_loss 0.9831 (0.9399) lr 1.6845e-03 eta 0:13:28
epoch [15/50] batch [80/181] time 0.139 (0.125) data 0.000 (0.004) loss 1.1422 (0.9944) ce_loss 0.4558 (0.4240) teacher_loss 0.3340 (0.2923) loss_zs_kd 0.1039 (0.0962) loss_oracle 0.7563 (0.6540) acc 81.2500 (84.6875) kd_loss 1.0254 (0.9502) lr 1.6845e-03 eta 0:13:22
epoch [15/50] batch [100/181] time 0.124 (0.123) data 0.000 (0.003) loss 0.8381 (0.9968) ce_loss 0.1970 (0.4176) teacher_loss 0.1731 (0.2906) loss_zs_kd 0.0983 (0.0957) loss_oracle 0.6158 (0.6585) acc 96.8750 (84.8125) kd_loss 0.9611 (0.9574) lr 1.6845e-03 eta 0:13:09
epoch [15/50] batch [120/181] time 0.189 (0.124) data 0.000 (0.003) loss 0.9761 (0.9893) ce_loss 0.5386 (0.4046) teacher_loss 0.3255 (0.2815) loss_zs_kd 0.0934 (0.0936) loss_oracle 0.6039 (0.6611) acc 81.2500 (85.4167) kd_loss 0.9312 (0.9588) lr 1.6845e-03 eta 0:13:12
epoch [15/50] batch [140/181] time 0.178 (0.124) data 0.000 (0.002) loss 0.9752 (0.9896) ce_loss 0.3979 (0.4019) teacher_loss 0.2797 (0.2836) loss_zs_kd 0.0948 (0.0933) loss_oracle 0.6480 (0.6594) acc 87.5000 (85.4464) kd_loss 0.9459 (0.9577) lr 1.6845e-03 eta 0:13:11
epoch [15/50] batch [160/181] time 0.183 (0.130) data 0.000 (0.002) loss 1.0135 (0.9903) ce_loss 0.3491 (0.4041) teacher_loss 0.2981 (0.2877) loss_zs_kd 0.0835 (0.0914) loss_oracle 0.6737 (0.6569) acc 87.5000 (85.2734) kd_loss 0.9979 (0.9607) lr 1.6845e-03 eta 0:13:47
epoch [15/50] batch [180/181] time 0.084 (0.126) data 0.000 (0.002) loss 1.2951 (0.9939) ce_loss 0.7798 (0.4084) teacher_loss 0.5514 (0.2893) loss_zs_kd 0.1546 (0.0918) loss_oracle 0.6664 (0.6587) acc 65.6250 (85.0347) kd_loss 1.0220 (0.9664) lr 1.6845e-03 eta 0:13:18
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,388
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.6%, epoch: 15 *******
******* Domain p best val test acc: 99.9%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [16/50] batch [20/181] time 0.136 (0.125) data 0.000 (0.015) loss 1.0872 (1.0330) ce_loss 0.6040 (0.4402) teacher_loss 0.4004 (0.3225) loss_zs_kd 0.1161 (0.1111) loss_oracle 0.6287 (0.6550) acc 78.1250 (82.9688) kd_loss 0.9276 (0.9667) lr 1.6374e-03 eta 0:13:07
epoch [16/50] batch [40/181] time 0.113 (0.114) data 0.000 (0.008) loss 1.0756 (1.0183) ce_loss 0.4531 (0.4438) teacher_loss 0.4110 (0.3282) loss_zs_kd 0.1024 (0.1019) loss_oracle 0.6134 (0.6391) acc 81.2500 (82.1875) kd_loss 0.9302 (0.9553) lr 1.6374e-03 eta 0:11:59
epoch [16/50] batch [60/181] time 0.087 (0.112) data 0.000 (0.005) loss 0.9539 (1.0142) ce_loss 0.3018 (0.4272) teacher_loss 0.2857 (0.3285) loss_zs_kd 0.0623 (0.0988) loss_oracle 0.6370 (0.6363) acc 93.7500 (83.3854) kd_loss 0.8880 (0.9415) lr 1.6374e-03 eta 0:11:41
epoch [16/50] batch [80/181] time 0.087 (0.109) data 0.000 (0.004) loss 0.9611 (1.0145) ce_loss 0.4180 (0.4197) teacher_loss 0.3725 (0.3299) loss_zs_kd 0.1070 (0.0941) loss_oracle 0.5352 (0.6376) acc 78.1250 (83.7891) kd_loss 0.8929 (0.9322) lr 1.6374e-03 eta 0:11:24
epoch [16/50] batch [100/181] time 0.129 (0.109) data 0.000 (0.003) loss 1.0606 (1.0290) ce_loss 0.4043 (0.4309) teacher_loss 0.3894 (0.3464) loss_zs_kd 0.0780 (0.0918) loss_oracle 0.6322 (0.6367) acc 84.3750 (83.2188) kd_loss 0.8739 (0.9212) lr 1.6374e-03 eta 0:11:17
epoch [16/50] batch [120/181] time 0.139 (0.109) data 0.000 (0.003) loss 1.3152 (1.0340) ce_loss 0.6230 (0.4326) teacher_loss 0.6064 (0.3486) loss_zs_kd 0.0770 (0.0899) loss_oracle 0.6702 (0.6405) acc 75.0000 (83.3854) kd_loss 0.8593 (0.9158) lr 1.6374e-03 eta 0:11:18
epoch [16/50] batch [140/181] time 0.137 (0.110) data 0.000 (0.002) loss 0.8707 (1.0298) ce_loss 0.4016 (0.4264) teacher_loss 0.2169 (0.3439) loss_zs_kd 0.0761 (0.0882) loss_oracle 0.6157 (0.6417) acc 84.3750 (83.6384) kd_loss 0.8717 (0.9097) lr 1.6374e-03 eta 0:11:19
epoch [16/50] batch [160/181] time 0.115 (0.110) data 0.000 (0.002) loss 0.9726 (1.0316) ce_loss 0.3809 (0.4254) teacher_loss 0.2987 (0.3429) loss_zs_kd 0.0721 (0.0883) loss_oracle 0.6378 (0.6446) acc 87.5000 (83.8086) kd_loss 0.9164 (0.9098) lr 1.6374e-03 eta 0:11:18
epoch [16/50] batch [180/181] time 0.098 (0.108) data 0.000 (0.002) loss 0.9034 (1.0328) ce_loss 0.2585 (0.4210) teacher_loss 0.1934 (0.3405) loss_zs_kd 0.0562 (0.0862) loss_oracle 0.6819 (0.6492) acc 87.5000 (84.1840) kd_loss 0.9633 (0.9136) lr 1.6374e-03 eta 0:11:06
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,385
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.6%, epoch: 15 *******
******* Domain p best val test acc: 99.9%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [17/50] batch [20/181] time 0.086 (0.123) data 0.000 (0.013) loss 1.1328 (1.0601) ce_loss 0.4834 (0.4237) teacher_loss 0.3953 (0.3333) loss_zs_kd 0.0923 (0.0951) loss_oracle 0.6914 (0.6792) acc 84.3750 (84.3750) kd_loss 0.9186 (0.9460) lr 1.5878e-03 eta 0:12:35
epoch [17/50] batch [40/181] time 0.132 (0.116) data 0.000 (0.007) loss 1.0163 (1.0362) ce_loss 0.3467 (0.4095) teacher_loss 0.3008 (0.3226) loss_zs_kd 0.0643 (0.0884) loss_oracle 0.6833 (0.6694) acc 87.5000 (84.6094) kd_loss 0.9639 (0.9483) lr 1.5878e-03 eta 0:11:51
epoch [17/50] batch [60/181] time 0.131 (0.114) data 0.000 (0.005) loss 0.7900 (1.0225) ce_loss 0.2480 (0.4013) teacher_loss 0.1947 (0.3213) loss_zs_kd 0.0487 (0.0838) loss_oracle 0.5709 (0.6594) acc 90.6250 (84.7917) kd_loss 1.0125 (0.9580) lr 1.5878e-03 eta 0:11:37
epoch [17/50] batch [80/181] time 0.081 (0.114) data 0.000 (0.004) loss 0.9855 (1.0185) ce_loss 0.3250 (0.4050) teacher_loss 0.2930 (0.3250) loss_zs_kd 0.0735 (0.0832) loss_oracle 0.6557 (0.6519) acc 87.5000 (84.7656) kd_loss 0.9437 (0.9497) lr 1.5878e-03 eta 0:11:32
epoch [17/50] batch [100/181] time 0.133 (0.112) data 0.000 (0.003) loss 0.9888 (1.0081) ce_loss 0.4277 (0.3985) teacher_loss 0.3555 (0.3195) loss_zs_kd 0.0678 (0.0812) loss_oracle 0.5994 (0.6480) acc 87.5000 (85.1875) kd_loss 0.9380 (0.9479) lr 1.5878e-03 eta 0:11:16
epoch [17/50] batch [120/181] time 0.190 (0.116) data 0.000 (0.002) loss 0.9175 (1.0022) ce_loss 0.2642 (0.3940) teacher_loss 0.2558 (0.3165) loss_zs_kd 0.0775 (0.0805) loss_oracle 0.6230 (0.6455) acc 87.5000 (85.4167) kd_loss 0.8386 (0.9406) lr 1.5878e-03 eta 0:11:37
epoch [17/50] batch [140/181] time 0.188 (0.119) data 0.000 (0.002) loss 1.1784 (1.0053) ce_loss 0.5874 (0.4058) teacher_loss 0.4316 (0.3240) loss_zs_kd 0.1212 (0.0814) loss_oracle 0.6863 (0.6406) acc 78.1250 (84.8214) kd_loss 0.9316 (0.9349) lr 1.5878e-03 eta 0:11:57
epoch [17/50] batch [160/181] time 0.066 (0.125) data 0.000 (0.002) loss 0.9776 (1.0071) ce_loss 0.4563 (0.4071) teacher_loss 0.3709 (0.3251) loss_zs_kd 0.1091 (0.0827) loss_oracle 0.5521 (0.6407) acc 84.3750 (84.8828) kd_loss 0.8070 (0.9320) lr 1.5878e-03 eta 0:12:29
epoch [17/50] batch [180/181] time 0.098 (0.121) data 0.000 (0.002) loss 1.0601 (1.0087) ce_loss 0.4160 (0.4068) teacher_loss 0.3265 (0.3260) loss_zs_kd 0.0884 (0.0828) loss_oracle 0.6893 (0.6413) acc 84.3750 (84.9826) kd_loss 0.9633 (0.9289) lr 1.5878e-03 eta 0:12:00
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,383
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.6%, epoch: 15 *******
******* Domain p best val test acc: 99.9%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [18/50] batch [20/181] time 0.090 (0.125) data 0.000 (0.014) loss 1.0524 (1.0416) ce_loss 0.5225 (0.4374) teacher_loss 0.3588 (0.3422) loss_zs_kd 0.0828 (0.0851) loss_oracle 0.6522 (0.6569) acc 81.2500 (83.4375) kd_loss 1.0024 (0.9268) lr 1.5358e-03 eta 0:12:26
epoch [18/50] batch [40/181] time 0.112 (0.118) data 0.000 (0.007) loss 1.1627 (1.0588) ce_loss 0.4216 (0.4366) teacher_loss 0.3801 (0.3485) loss_zs_kd 0.1006 (0.0852) loss_oracle 0.7323 (0.6678) acc 81.2500 (83.2812) kd_loss 0.9013 (0.9340) lr 1.5358e-03 eta 0:11:41
epoch [18/50] batch [60/181] time 0.136 (0.120) data 0.001 (0.005) loss 0.9740 (1.0568) ce_loss 0.3086 (0.4306) teacher_loss 0.2360 (0.3431) loss_zs_kd 0.0701 (0.0843) loss_oracle 0.7030 (0.6715) acc 87.5000 (82.8646) kd_loss 1.0039 (0.9459) lr 1.5358e-03 eta 0:11:51
epoch [18/50] batch [80/181] time 0.079 (0.120) data 0.000 (0.004) loss 1.3892 (1.0548) ce_loss 0.8647 (0.4237) teacher_loss 0.7066 (0.3385) loss_zs_kd 0.0848 (0.0833) loss_oracle 0.6402 (0.6746) acc 68.7500 (83.0469) kd_loss 0.8596 (0.9548) lr 1.5358e-03 eta 0:11:45
epoch [18/50] batch [100/181] time 0.102 (0.121) data 0.000 (0.003) loss 0.9801 (1.0529) ce_loss 0.3586 (0.4203) teacher_loss 0.2532 (0.3374) loss_zs_kd 0.0923 (0.0828) loss_oracle 0.6808 (0.6742) acc 84.3750 (83.5625) kd_loss 0.9429 (0.9568) lr 1.5358e-03 eta 0:11:47
epoch [18/50] batch [120/181] time 0.139 (0.120) data 0.000 (0.003) loss 1.2261 (1.0537) ce_loss 0.6724 (0.4225) teacher_loss 0.5065 (0.3377) loss_zs_kd 0.0721 (0.0834) loss_oracle 0.6836 (0.6743) acc 78.1250 (83.5417) kd_loss 1.0264 (0.9627) lr 1.5358e-03 eta 0:11:43
epoch [18/50] batch [140/181] time 0.090 (0.119) data 0.000 (0.002) loss 1.2399 (1.0442) ce_loss 0.5298 (0.4141) teacher_loss 0.5365 (0.3316) loss_zs_kd 0.0894 (0.0832) loss_oracle 0.6587 (0.6711) acc 78.1250 (83.9955) kd_loss 1.0169 (0.9710) lr 1.5358e-03 eta 0:11:35
epoch [18/50] batch [160/181] time 0.099 (0.119) data 0.000 (0.002) loss 0.8854 (1.0432) ce_loss 0.2720 (0.4138) teacher_loss 0.2671 (0.3334) loss_zs_kd 0.0549 (0.0823) loss_oracle 0.5909 (0.6687) acc 87.5000 (84.1602) kd_loss 0.9446 (0.9746) lr 1.5358e-03 eta 0:11:30
epoch [18/50] batch [180/181] time 0.081 (0.118) data 0.000 (0.002) loss 1.1559 (1.0428) ce_loss 0.5259 (0.4135) teacher_loss 0.4586 (0.3337) loss_zs_kd 0.0476 (0.0820) loss_oracle 0.6735 (0.6681) acc 81.2500 (84.2535) kd_loss 1.0301 (0.9794) lr 1.5358e-03 eta 0:11:24
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,389
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.2%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      95.7%, epoch: 18 *******
******* Domain p best val test acc: 99.8%, epoch: 18 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [19/50] batch [20/181] time 0.141 (0.131) data 0.000 (0.013) loss 0.9471 (0.9942) ce_loss 0.4204 (0.3566) teacher_loss 0.3146 (0.2849) loss_zs_kd 0.0854 (0.0838) loss_oracle 0.5898 (0.6674) acc 84.3750 (87.8125) kd_loss 0.9528 (1.0132) lr 1.4818e-03 eta 0:12:38
epoch [19/50] batch [40/181] time 0.121 (0.123) data 0.000 (0.007) loss 0.9019 (1.0110) ce_loss 0.2140 (0.3722) teacher_loss 0.1673 (0.3080) loss_zs_kd 0.0705 (0.0823) loss_oracle 0.6994 (0.6618) acc 87.5000 (86.0938) kd_loss 0.9661 (1.0079) lr 1.4818e-03 eta 0:11:50
epoch [19/50] batch [60/181] time 0.142 (0.120) data 0.000 (0.005) loss 0.9384 (1.0230) ce_loss 0.3203 (0.3919) teacher_loss 0.2178 (0.3189) loss_zs_kd 0.0817 (0.0822) loss_oracle 0.6797 (0.6630) acc 90.6250 (85.3646) kd_loss 1.0403 (1.0128) lr 1.4818e-03 eta 0:11:27
epoch [19/50] batch [80/181] time 0.187 (0.126) data 0.000 (0.003) loss 1.0439 (1.0203) ce_loss 0.3901 (0.3921) teacher_loss 0.3113 (0.3137) loss_zs_kd 0.0901 (0.0850) loss_oracle 0.6876 (0.6641) acc 90.6250 (85.6641) kd_loss 1.0579 (1.0174) lr 1.4818e-03 eta 0:11:58
epoch [19/50] batch [100/181] time 0.181 (0.125) data 0.000 (0.003) loss 1.0049 (1.0344) ce_loss 0.3669 (0.4100) teacher_loss 0.3126 (0.3231) loss_zs_kd 0.0893 (0.0900) loss_oracle 0.6477 (0.6663) acc 87.5000 (84.8750) kd_loss 1.0279 (1.0212) lr 1.4818e-03 eta 0:11:53
epoch [19/50] batch [120/181] time 0.133 (0.135) data 0.000 (0.002) loss 1.0784 (1.0370) ce_loss 0.4524 (0.4183) teacher_loss 0.3333 (0.3280) loss_zs_kd 0.0738 (0.0919) loss_oracle 0.7082 (0.6630) acc 84.3750 (84.4792) kd_loss 1.0205 (1.0205) lr 1.4818e-03 eta 0:12:43
epoch [19/50] batch [140/181] time 0.136 (0.130) data 0.000 (0.002) loss 1.0382 (1.0319) ce_loss 0.5039 (0.4158) teacher_loss 0.3606 (0.3271) loss_zs_kd 0.0652 (0.0910) loss_oracle 0.6450 (0.6592) acc 87.5000 (84.5312) kd_loss 1.0286 (1.0205) lr 1.4818e-03 eta 0:12:13
epoch [19/50] batch [160/181] time 0.109 (0.128) data 0.000 (0.002) loss 1.1299 (1.0271) ce_loss 0.3728 (0.4170) teacher_loss 0.3124 (0.3252) loss_zs_kd 0.1071 (0.0923) loss_oracle 0.7640 (0.6558) acc 87.5000 (84.5312) kd_loss 1.1740 (1.0223) lr 1.4818e-03 eta 0:12:02
epoch [19/50] batch [180/181] time 0.083 (0.125) data 0.000 (0.002) loss 1.1542 (1.0256) ce_loss 0.5947 (0.4163) teacher_loss 0.3926 (0.3214) loss_zs_kd 0.1092 (0.0929) loss_oracle 0.7071 (0.6577) acc 75.0000 (84.6007) kd_loss 1.0812 (1.0281) lr 1.4818e-03 eta 0:11:44
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,386
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.7%, epoch: 18 *******
******* Domain p best val test acc: 99.8%, epoch: 18 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [20/50] batch [20/181] time 0.123 (0.137) data 0.000 (0.015) loss 1.1663 (1.0428) ce_loss 0.5518 (0.4269) teacher_loss 0.4702 (0.2951) loss_zs_kd 0.0922 (0.1153) loss_oracle 0.6500 (0.6900) acc 81.2500 (84.2188) kd_loss 0.9920 (1.0757) lr 1.4258e-03 eta 0:12:46
epoch [20/50] batch [40/181] time 0.093 (0.128) data 0.000 (0.007) loss 0.9221 (1.0078) ce_loss 0.2681 (0.3946) teacher_loss 0.2018 (0.2717) loss_zs_kd 0.0801 (0.1087) loss_oracle 0.6803 (0.6818) acc 93.7500 (85.5469) kd_loss 1.0899 (1.0715) lr 1.4258e-03 eta 0:11:50
epoch [20/50] batch [60/181] time 0.080 (0.123) data 0.000 (0.005) loss 1.0748 (1.0192) ce_loss 0.4634 (0.4017) teacher_loss 0.3381 (0.2796) loss_zs_kd 0.0964 (0.1058) loss_oracle 0.6885 (0.6867) acc 78.1250 (85.6771) kd_loss 1.0365 (1.0728) lr 1.4258e-03 eta 0:11:22
epoch [20/50] batch [80/181] time 0.130 (0.120) data 0.000 (0.004) loss 0.8511 (1.0270) ce_loss 0.2585 (0.3995) teacher_loss 0.1870 (0.2749) loss_zs_kd 0.0752 (0.1062) loss_oracle 0.6265 (0.6990) acc 90.6250 (85.8594) kd_loss 1.0866 (1.0757) lr 1.4258e-03 eta 0:11:01
epoch [20/50] batch [100/181] time 0.135 (0.117) data 0.000 (0.003) loss 1.2470 (1.0232) ce_loss 0.6182 (0.3955) teacher_loss 0.4645 (0.2748) loss_zs_kd 0.1390 (0.1065) loss_oracle 0.7129 (0.6951) acc 78.1250 (85.6875) kd_loss 1.1258 (1.0698) lr 1.4258e-03 eta 0:10:44
epoch [20/50] batch [120/181] time 0.083 (0.115) data 0.000 (0.003) loss 0.8934 (1.0245) ce_loss 0.2700 (0.3991) teacher_loss 0.1776 (0.2777) loss_zs_kd 0.1093 (0.1050) loss_oracle 0.6612 (0.6942) acc 90.6250 (85.5208) kd_loss 0.9632 (1.0618) lr 1.4258e-03 eta 0:10:32
epoch [20/50] batch [140/181] time 0.137 (0.115) data 0.000 (0.002) loss 0.8958 (1.0346) ce_loss 0.3442 (0.4098) teacher_loss 0.1877 (0.2872) loss_zs_kd 0.0983 (0.1054) loss_oracle 0.6590 (0.6947) acc 87.5000 (85.0446) kd_loss 1.0179 (1.0514) lr 1.4258e-03 eta 0:10:27
epoch [20/50] batch [160/181] time 0.086 (0.114) data 0.000 (0.002) loss 1.0021 (1.0381) ce_loss 0.3853 (0.4156) teacher_loss 0.3350 (0.2933) loss_zs_kd 0.0962 (0.1057) loss_oracle 0.6189 (0.6920) acc 90.6250 (84.7656) kd_loss 0.8142 (1.0397) lr 1.4258e-03 eta 0:10:20
epoch [20/50] batch [180/181] time 0.098 (0.112) data 0.000 (0.002) loss 0.9058 (1.0293) ce_loss 0.3782 (0.4112) teacher_loss 0.2448 (0.2915) loss_zs_kd 0.1072 (0.1035) loss_oracle 0.6073 (0.6861) acc 87.5000 (84.9653) kd_loss 0.8913 (1.0262) lr 1.4258e-03 eta 0:10:08
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,393
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.8%, epoch: 20 *******
******* Domain p best val test acc: 99.9%, epoch: 20 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [21/50] batch [20/181] time 0.144 (0.131) data 0.000 (0.012) loss 0.9896 (1.0104) ce_loss 0.3330 (0.3922) teacher_loss 0.2470 (0.2886) loss_zs_kd 0.0755 (0.0966) loss_oracle 0.7048 (0.6735) acc 84.3750 (85.9375) kd_loss 0.9829 (0.9685) lr 1.3681e-03 eta 0:11:50
epoch [21/50] batch [40/181] time 0.087 (0.119) data 0.000 (0.006) loss 1.0057 (1.0360) ce_loss 0.4629 (0.4165) teacher_loss 0.3188 (0.3014) loss_zs_kd 0.0955 (0.0994) loss_oracle 0.6391 (0.6848) acc 84.3750 (84.2188) kd_loss 1.0378 (0.9969) lr 1.3681e-03 eta 0:10:43
epoch [21/50] batch [60/181] time 0.185 (0.124) data 0.000 (0.004) loss 0.9643 (1.0305) ce_loss 0.3096 (0.4007) teacher_loss 0.2214 (0.2895) loss_zs_kd 0.1103 (0.1005) loss_oracle 0.6877 (0.6908) acc 90.6250 (85.0000) kd_loss 1.0912 (1.0109) lr 1.3681e-03 eta 0:11:06
epoch [21/50] batch [80/181] time 0.188 (0.129) data 0.000 (0.003) loss 0.9571 (1.0285) ce_loss 0.3691 (0.4054) teacher_loss 0.2208 (0.2921) loss_zs_kd 0.1660 (0.0981) loss_oracle 0.6533 (0.6874) acc 87.5000 (84.8438) kd_loss 1.0331 (1.0189) lr 1.3681e-03 eta 0:11:31
epoch [21/50] batch [100/181] time 0.088 (0.136) data 0.000 (0.003) loss 1.0440 (1.0353) ce_loss 0.4160 (0.4115) teacher_loss 0.3162 (0.2922) loss_zs_kd 0.1302 (0.1029) loss_oracle 0.6628 (0.6917) acc 84.3750 (84.5938) kd_loss 1.0277 (1.0235) lr 1.3681e-03 eta 0:12:04
epoch [21/50] batch [120/181] time 0.124 (0.133) data 0.000 (0.002) loss 0.9765 (1.0419) ce_loss 0.3108 (0.4113) teacher_loss 0.2053 (0.2939) loss_zs_kd 0.0711 (0.1012) loss_oracle 0.7356 (0.6974) acc 87.5000 (84.8698) kd_loss 1.1105 (1.0313) lr 1.3681e-03 eta 0:11:47
epoch [21/50] batch [140/181] time 0.120 (0.132) data 0.000 (0.002) loss 1.1716 (1.0534) ce_loss 0.4556 (0.4207) teacher_loss 0.4363 (0.2999) loss_zs_kd 0.1087 (0.1031) loss_oracle 0.6809 (0.7019) acc 84.3750 (84.5312) kd_loss 1.0642 (1.0325) lr 1.3681e-03 eta 0:11:36
epoch [21/50] batch [160/181] time 0.128 (0.130) data 0.000 (0.002) loss 1.1470 (1.0530) ce_loss 0.4446 (0.4188) teacher_loss 0.3244 (0.2983) loss_zs_kd 0.0757 (0.1044) loss_oracle 0.7847 (0.7025) acc 81.2500 (84.4922) kd_loss 1.0513 (1.0306) lr 1.3681e-03 eta 0:11:26
epoch [21/50] batch [180/181] time 0.094 (0.127) data 0.000 (0.002) loss 1.0406 (1.0560) ce_loss 0.3511 (0.4205) teacher_loss 0.3004 (0.2986) loss_zs_kd 0.1118 (0.1038) loss_oracle 0.6844 (0.7055) acc 90.6250 (84.5139) kd_loss 1.0318 (1.0327) lr 1.3681e-03 eta 0:11:08
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,387
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.8%, epoch: 20 *******
******* Domain p best val test acc: 99.9%, epoch: 20 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [22/50] batch [20/181] time 0.103 (0.131) data 0.000 (0.015) loss 1.1329 (1.0594) ce_loss 0.5229 (0.4085) teacher_loss 0.3789 (0.2738) loss_zs_kd 0.0939 (0.1052) loss_oracle 0.7071 (0.7330) acc 81.2500 (85.1562) kd_loss 1.0094 (1.0455) lr 1.3090e-03 eta 0:11:24
epoch [22/50] batch [40/181] time 0.137 (0.119) data 0.000 (0.008) loss 1.0236 (1.0684) ce_loss 0.4036 (0.4178) teacher_loss 0.2638 (0.2817) loss_zs_kd 0.1047 (0.1094) loss_oracle 0.7074 (0.7319) acc 84.3750 (84.3750) kd_loss 1.0428 (1.0502) lr 1.3090e-03 eta 0:10:20
epoch [22/50] batch [60/181] time 0.139 (0.119) data 0.001 (0.005) loss 0.9033 (1.0456) ce_loss 0.2659 (0.4011) teacher_loss 0.1571 (0.2705) loss_zs_kd 0.0813 (0.1068) loss_oracle 0.7055 (0.7217) acc 87.5000 (85.0000) kd_loss 1.0740 (1.0460) lr 1.3090e-03 eta 0:10:16
epoch [22/50] batch [80/181] time 0.083 (0.119) data 0.000 (0.004) loss 1.1250 (1.0439) ce_loss 0.4106 (0.4024) teacher_loss 0.3300 (0.2715) loss_zs_kd 0.1253 (0.1072) loss_oracle 0.7324 (0.7188) acc 84.3750 (84.8438) kd_loss 0.9987 (1.0409) lr 1.3090e-03 eta 0:10:15
epoch [22/50] batch [100/181] time 0.137 (0.117) data 0.001 (0.003) loss 0.9698 (1.0465) ce_loss 0.3213 (0.3962) teacher_loss 0.1921 (0.2678) loss_zs_kd 0.0746 (0.1067) loss_oracle 0.7404 (0.7253) acc 87.5000 (85.0312) kd_loss 0.9915 (1.0395) lr 1.3090e-03 eta 0:10:03
epoch [22/50] batch [120/181] time 0.083 (0.115) data 0.000 (0.003) loss 0.9347 (1.0521) ce_loss 0.3076 (0.3997) teacher_loss 0.2284 (0.2700) loss_zs_kd 0.0717 (0.1071) loss_oracle 0.6704 (0.7286) acc 87.5000 (84.7396) kd_loss 0.9350 (1.0366) lr 1.3090e-03 eta 0:09:47
epoch [22/50] batch [140/181] time 0.086 (0.113) data 0.000 (0.002) loss 1.2229 (1.0517) ce_loss 0.5293 (0.3937) teacher_loss 0.3191 (0.2655) loss_zs_kd 0.1457 (0.1074) loss_oracle 0.8309 (0.7326) acc 78.1250 (84.9330) kd_loss 1.0846 (1.0349) lr 1.3090e-03 eta 0:09:39
epoch [22/50] batch [160/181] time 0.118 (0.113) data 0.000 (0.002) loss 1.1697 (1.0604) ce_loss 0.3406 (0.3992) teacher_loss 0.2090 (0.2677) loss_zs_kd 0.1111 (0.1095) loss_oracle 0.9052 (0.7380) acc 90.6250 (84.6484) kd_loss 1.1124 (1.0372) lr 1.3090e-03 eta 0:09:33
epoch [22/50] batch [180/181] time 0.098 (0.111) data 0.000 (0.002) loss 1.1563 (1.0659) ce_loss 0.5210 (0.4010) teacher_loss 0.3122 (0.2708) loss_zs_kd 0.0952 (0.1087) loss_oracle 0.7965 (0.7407) acc 78.1250 (84.6875) kd_loss 1.0975 (1.0408) lr 1.3090e-03 eta 0:09:21
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,387
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.8%, epoch: 20 *******
******* Domain p best val test acc: 99.9%, epoch: 20 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [23/50] batch [20/181] time 0.203 (0.137) data 0.000 (0.014) loss 1.2680 (1.1150) ce_loss 0.7090 (0.4621) teacher_loss 0.5158 (0.3256) loss_zs_kd 0.1376 (0.1135) loss_oracle 0.6835 (0.7326) acc 71.8750 (82.9688) kd_loss 1.0915 (1.0578) lr 1.2487e-03 eta 0:11:31
epoch [23/50] batch [40/181] time 0.076 (0.148) data 0.000 (0.007) loss 1.0700 (1.1069) ce_loss 0.4089 (0.4606) teacher_loss 0.3158 (0.3185) loss_zs_kd 0.1096 (0.1129) loss_oracle 0.6993 (0.7320) acc 87.5000 (82.7344) kd_loss 1.0958 (1.0631) lr 1.2487e-03 eta 0:12:25
epoch [23/50] batch [60/181] time 0.191 (0.157) data 0.001 (0.005) loss 0.8547 (1.0729) ce_loss 0.2771 (0.4322) teacher_loss 0.2063 (0.3040) loss_zs_kd 0.1007 (0.1116) loss_oracle 0.5981 (0.7131) acc 90.6250 (84.1667) kd_loss 0.9693 (1.0535) lr 1.2487e-03 eta 0:13:04
epoch [23/50] batch [80/181] time 0.088 (0.146) data 0.000 (0.004) loss 0.8278 (1.0579) ce_loss 0.2876 (0.4253) teacher_loss 0.2062 (0.2997) loss_zs_kd 0.0624 (0.1081) loss_oracle 0.5903 (0.7042) acc 87.5000 (84.4922) kd_loss 0.9545 (1.0428) lr 1.2487e-03 eta 0:12:07
epoch [23/50] batch [100/181] time 0.134 (0.138) data 0.000 (0.003) loss 0.9818 (1.0488) ce_loss 0.4324 (0.4237) teacher_loss 0.2288 (0.2955) loss_zs_kd 0.1037 (0.1058) loss_oracle 0.7012 (0.7004) acc 81.2500 (84.6562) kd_loss 1.0255 (1.0320) lr 1.2487e-03 eta 0:11:23
epoch [23/50] batch [120/181] time 0.149 (0.134) data 0.000 (0.003) loss 0.7983 (1.0406) ce_loss 0.3003 (0.4213) teacher_loss 0.1648 (0.2891) loss_zs_kd 0.1260 (0.1065) loss_oracle 0.5704 (0.6982) acc 87.5000 (84.6615) kd_loss 0.9512 (1.0229) lr 1.2487e-03 eta 0:11:00
epoch [23/50] batch [140/181] time 0.141 (0.131) data 0.000 (0.002) loss 0.9061 (1.0385) ce_loss 0.2964 (0.4231) teacher_loss 0.2046 (0.2873) loss_zs_kd 0.1018 (0.1081) loss_oracle 0.6506 (0.6971) acc 90.6250 (84.6429) kd_loss 0.8853 (1.0162) lr 1.2487e-03 eta 0:10:47
epoch [23/50] batch [160/181] time 0.135 (0.129) data 0.000 (0.002) loss 1.0968 (1.0418) ce_loss 0.3975 (0.4266) teacher_loss 0.2609 (0.2890) loss_zs_kd 0.1161 (0.1102) loss_oracle 0.7779 (0.6978) acc 84.3750 (84.4141) kd_loss 1.0289 (1.0109) lr 1.2487e-03 eta 0:10:35
epoch [23/50] batch [180/181] time 0.092 (0.126) data 0.000 (0.002) loss 1.0576 (1.0369) ce_loss 0.5044 (0.4212) teacher_loss 0.3388 (0.2835) loss_zs_kd 0.0950 (0.1103) loss_oracle 0.6713 (0.6983) acc 81.2500 (84.5833) kd_loss 1.0482 (1.0097) lr 1.2487e-03 eta 0:10:16
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,392
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.8%, epoch: 20 *******
******* Domain p best val test acc: 99.9%, epoch: 20 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [24/50] batch [20/181] time 0.146 (0.143) data 0.000 (0.015) loss 1.0424 (0.9530) ce_loss 0.5015 (0.3641) teacher_loss 0.2674 (0.2302) loss_zs_kd 0.1477 (0.1155) loss_oracle 0.7012 (0.6651) acc 78.1250 (86.2500) kd_loss 0.9474 (0.9693) lr 1.1874e-03 eta 0:11:35
epoch [24/50] batch [40/181] time 0.093 (0.134) data 0.000 (0.008) loss 0.9203 (0.9816) ce_loss 0.4631 (0.4215) teacher_loss 0.3450 (0.2714) loss_zs_kd 0.1427 (0.1165) loss_oracle 0.5040 (0.6519) acc 84.3750 (84.5312) kd_loss 0.9898 (0.9699) lr 1.1874e-03 eta 0:10:51
epoch [24/50] batch [60/181] time 0.136 (0.128) data 0.000 (0.005) loss 1.0409 (0.9923) ce_loss 0.5435 (0.4195) teacher_loss 0.4080 (0.2730) loss_zs_kd 0.1067 (0.1174) loss_oracle 0.5796 (0.6606) acc 81.2500 (84.3750) kd_loss 0.9907 (0.9837) lr 1.1874e-03 eta 0:10:19
epoch [24/50] batch [80/181] time 0.088 (0.126) data 0.000 (0.004) loss 1.0376 (0.9936) ce_loss 0.3696 (0.4200) teacher_loss 0.1905 (0.2730) loss_zs_kd 0.1583 (0.1161) loss_oracle 0.7680 (0.6626) acc 87.5000 (84.4531) kd_loss 1.0782 (0.9821) lr 1.1874e-03 eta 0:10:06
epoch [24/50] batch [100/181] time 0.095 (0.125) data 0.000 (0.003) loss 0.9096 (1.0029) ce_loss 0.2837 (0.4243) teacher_loss 0.1353 (0.2797) loss_zs_kd 0.0809 (0.1151) loss_oracle 0.7338 (0.6657) acc 87.5000 (84.3750) kd_loss 1.0631 (0.9787) lr 1.1874e-03 eta 0:09:58
epoch [24/50] batch [120/181] time 0.128 (0.125) data 0.000 (0.003) loss 1.0814 (0.9977) ce_loss 0.4453 (0.4166) teacher_loss 0.3283 (0.2720) loss_zs_kd 0.1361 (0.1141) loss_oracle 0.6850 (0.6687) acc 90.6250 (84.6875) kd_loss 0.9154 (0.9764) lr 1.1874e-03 eta 0:09:57
epoch [24/50] batch [140/181] time 0.137 (0.125) data 0.000 (0.002) loss 0.8818 (0.9980) ce_loss 0.2441 (0.4185) teacher_loss 0.2375 (0.2746) loss_zs_kd 0.0585 (0.1129) loss_oracle 0.6151 (0.6669) acc 93.7500 (84.5759) kd_loss 0.9204 (0.9714) lr 1.1874e-03 eta 0:09:54
epoch [24/50] batch [160/181] time 0.142 (0.125) data 0.000 (0.002) loss 1.1703 (0.9960) ce_loss 0.4055 (0.4134) teacher_loss 0.2921 (0.2723) loss_zs_kd 0.1183 (0.1109) loss_oracle 0.8190 (0.6683) acc 84.3750 (84.8438) kd_loss 1.0599 (0.9707) lr 1.1874e-03 eta 0:09:51
epoch [24/50] batch [180/181] time 0.128 (0.123) data 0.000 (0.002) loss 0.9592 (0.9980) ce_loss 0.3850 (0.4139) teacher_loss 0.2701 (0.2726) loss_zs_kd 0.1332 (0.1119) loss_oracle 0.6226 (0.6695) acc 90.6250 (84.6875) kd_loss 0.8935 (0.9695) lr 1.1874e-03 eta 0:09:40
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,391
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.8%, epoch: 20 *******
******* Domain p best val test acc: 99.9%, epoch: 20 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [25/50] batch [20/181] time 0.134 (0.205) data 0.000 (0.017) loss 0.8990 (1.0335) ce_loss 0.3877 (0.4745) teacher_loss 0.1900 (0.3079) loss_zs_kd 0.0986 (0.1168) loss_oracle 0.6597 (0.6672) acc 84.3750 (82.6562) kd_loss 0.9633 (0.9672) lr 1.1253e-03 eta 0:15:58
epoch [25/50] batch [40/181] time 0.077 (0.146) data 0.000 (0.009) loss 0.8741 (1.0078) ce_loss 0.1826 (0.4328) teacher_loss 0.1025 (0.2777) loss_zs_kd 0.1588 (0.1216) loss_oracle 0.6922 (0.6693) acc 93.7500 (83.2031) kd_loss 1.0567 (0.9767) lr 1.1253e-03 eta 0:11:22
epoch [25/50] batch [60/181] time 0.067 (0.132) data 0.000 (0.006) loss 1.2814 (1.0020) ce_loss 0.7402 (0.4193) teacher_loss 0.4018 (0.2656) loss_zs_kd 0.1623 (0.1214) loss_oracle 0.7984 (0.6757) acc 78.1250 (83.9583) kd_loss 1.0645 (0.9779) lr 1.1253e-03 eta 0:10:11
epoch [25/50] batch [80/181] time 0.137 (0.125) data 0.000 (0.004) loss 0.9310 (0.9880) ce_loss 0.4668 (0.4098) teacher_loss 0.2172 (0.2563) loss_zs_kd 0.1167 (0.1208) loss_oracle 0.6555 (0.6712) acc 78.1250 (84.2578) kd_loss 0.9681 (0.9767) lr 1.1253e-03 eta 0:09:37
epoch [25/50] batch [100/181] time 0.068 (0.120) data 0.000 (0.004) loss 0.9498 (0.9936) ce_loss 0.3596 (0.4131) teacher_loss 0.2272 (0.2601) loss_zs_kd 0.1534 (0.1196) loss_oracle 0.6459 (0.6737) acc 87.5000 (84.2188) kd_loss 1.0363 (0.9803) lr 1.1253e-03 eta 0:09:13
epoch [25/50] batch [120/181] time 0.086 (0.117) data 0.000 (0.003) loss 0.9815 (1.0025) ce_loss 0.4238 (0.4197) teacher_loss 0.2629 (0.2679) loss_zs_kd 0.1207 (0.1201) loss_oracle 0.6582 (0.6746) acc 90.6250 (84.0885) kd_loss 0.9036 (0.9803) lr 1.1253e-03 eta 0:08:54
epoch [25/50] batch [140/181] time 0.079 (0.114) data 0.000 (0.003) loss 0.9072 (0.9985) ce_loss 0.3982 (0.4141) teacher_loss 0.2505 (0.2648) loss_zs_kd 0.1014 (0.1194) loss_oracle 0.6060 (0.6740) acc 84.3750 (84.3750) kd_loss 0.9487 (0.9833) lr 1.1253e-03 eta 0:08:40
epoch [25/50] batch [160/181] time 0.085 (0.111) data 0.000 (0.002) loss 0.9119 (1.0025) ce_loss 0.2427 (0.4169) teacher_loss 0.1244 (0.2678) loss_zs_kd 0.0756 (0.1176) loss_oracle 0.7497 (0.6759) acc 87.5000 (84.3164) kd_loss 1.0796 (0.9848) lr 1.1253e-03 eta 0:08:26
epoch [25/50] batch [180/181] time 0.080 (0.109) data 0.000 (0.002) loss 1.0084 (0.9990) ce_loss 0.4106 (0.4127) teacher_loss 0.2429 (0.2657) loss_zs_kd 0.0947 (0.1162) loss_oracle 0.7181 (0.6752) acc 84.3750 (84.4792) kd_loss 1.0188 (0.9863) lr 1.1253e-03 eta 0:08:12
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,389
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      95.8%, epoch: 20 *******
******* Domain p best val test acc: 99.9%, epoch: 20 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [26/50] batch [20/181] time 0.110 (0.123) data 0.000 (0.013) loss 1.1561 (0.9923) ce_loss 0.5386 (0.4156) teacher_loss 0.4021 (0.2763) loss_zs_kd 0.1413 (0.1047) loss_oracle 0.6834 (0.6636) acc 81.2500 (84.0625) kd_loss 0.9617 (0.9923) lr 1.0628e-03 eta 0:09:14
epoch [26/50] batch [40/181] time 0.141 (0.118) data 0.000 (0.006) loss 0.7789 (1.0099) ce_loss 0.2014 (0.4193) teacher_loss 0.1583 (0.2710) loss_zs_kd 0.0677 (0.1105) loss_oracle 0.5868 (0.6836) acc 90.6250 (84.1406) kd_loss 0.9663 (0.9998) lr 1.0628e-03 eta 0:08:49
epoch [26/50] batch [60/181] time 0.138 (0.114) data 0.000 (0.004) loss 0.9968 (1.0111) ce_loss 0.3672 (0.4243) teacher_loss 0.2501 (0.2721) loss_zs_kd 0.1045 (0.1176) loss_oracle 0.6945 (0.6802) acc 84.3750 (84.0625) kd_loss 0.9605 (0.9943) lr 1.0628e-03 eta 0:08:29
epoch [26/50] batch [80/181] time 0.138 (0.115) data 0.000 (0.003) loss 0.9910 (0.9930) ce_loss 0.5254 (0.4156) teacher_loss 0.3160 (0.2607) loss_zs_kd 0.1037 (0.1181) loss_oracle 0.6231 (0.6732) acc 84.3750 (84.4531) kd_loss 0.9794 (0.9869) lr 1.0628e-03 eta 0:08:32
epoch [26/50] batch [100/181] time 0.140 (0.114) data 0.000 (0.003) loss 0.8591 (1.0053) ce_loss 0.2249 (0.4309) teacher_loss 0.1495 (0.2706) loss_zs_kd 0.0826 (0.1215) loss_oracle 0.6682 (0.6740) acc 93.7500 (83.7500) kd_loss 0.9981 (0.9873) lr 1.0628e-03 eta 0:08:22
epoch [26/50] batch [120/181] time 0.110 (0.112) data 0.000 (0.002) loss 0.9940 (1.0017) ce_loss 0.3862 (0.4228) teacher_loss 0.2252 (0.2690) loss_zs_kd 0.1132 (0.1219) loss_oracle 0.7122 (0.6717) acc 84.3750 (84.1927) kd_loss 1.0256 (0.9879) lr 1.0628e-03 eta 0:08:11
epoch [26/50] batch [140/181] time 0.086 (0.111) data 0.000 (0.002) loss 1.1040 (1.0013) ce_loss 0.5430 (0.4267) teacher_loss 0.3051 (0.2734) loss_zs_kd 0.1779 (0.1200) loss_oracle 0.7100 (0.6679) acc 81.2500 (83.9732) kd_loss 1.0586 (0.9864) lr 1.0628e-03 eta 0:08:07
epoch [26/50] batch [160/181] time 0.082 (0.110) data 0.000 (0.002) loss 0.9667 (1.0007) ce_loss 0.3477 (0.4228) teacher_loss 0.2630 (0.2733) loss_zs_kd 0.0964 (0.1180) loss_oracle 0.6554 (0.6685) acc 90.6250 (84.2383) kd_loss 1.0056 (0.9897) lr 1.0628e-03 eta 0:08:02
epoch [26/50] batch [180/181] time 0.080 (0.109) data 0.000 (0.002) loss 0.7913 (0.9932) ce_loss 0.3328 (0.4176) teacher_loss 0.1739 (0.2698) loss_zs_kd 0.0794 (0.1153) loss_oracle 0.5777 (0.6658) acc 84.3750 (84.3576) kd_loss 0.9992 (0.9933) lr 1.0628e-03 eta 0:07:51
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,388
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.8%, epoch: 20 *******
******* Domain p best val test acc: 99.9%, epoch: 20 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [27/50] batch [20/181] time 0.188 (0.152) data 0.000 (0.011) loss 0.9340 (0.9673) ce_loss 0.4424 (0.3860) teacher_loss 0.2836 (0.2592) loss_zs_kd 0.0809 (0.1089) loss_oracle 0.6100 (0.6536) acc 81.2500 (85.9375) kd_loss 0.9546 (1.0212) lr 1.0000e-03 eta 0:10:59
epoch [27/50] batch [40/181] time 0.087 (0.161) data 0.000 (0.005) loss 1.0776 (0.9883) ce_loss 0.4900 (0.4081) teacher_loss 0.3183 (0.2798) loss_zs_kd 0.0915 (0.1115) loss_oracle 0.7136 (0.6527) acc 87.5000 (84.8438) kd_loss 1.1300 (1.0169) lr 1.0000e-03 eta 0:11:31
epoch [27/50] batch [60/181] time 0.092 (0.140) data 0.000 (0.004) loss 1.0393 (1.0086) ce_loss 0.3684 (0.4081) teacher_loss 0.2781 (0.2927) loss_zs_kd 0.1288 (0.1123) loss_oracle 0.6968 (0.6598) acc 87.5000 (84.7917) kd_loss 1.1025 (1.0237) lr 1.0000e-03 eta 0:09:58
epoch [27/50] batch [80/181] time 0.090 (0.133) data 0.000 (0.003) loss 1.1237 (1.0009) ce_loss 0.5039 (0.4051) teacher_loss 0.3373 (0.2870) loss_zs_kd 0.1324 (0.1123) loss_oracle 0.7202 (0.6577) acc 84.3750 (84.9609) kd_loss 1.0658 (1.0264) lr 1.0000e-03 eta 0:09:28
epoch [27/50] batch [100/181] time 0.111 (0.130) data 0.000 (0.002) loss 0.9627 (1.0068) ce_loss 0.3406 (0.4128) teacher_loss 0.2328 (0.2933) loss_zs_kd 0.1014 (0.1129) loss_oracle 0.6792 (0.6571) acc 90.6250 (85.0938) kd_loss 1.1094 (1.0322) lr 1.0000e-03 eta 0:09:10
epoch [27/50] batch [120/181] time 0.087 (0.126) data 0.000 (0.002) loss 0.9584 (1.0039) ce_loss 0.3018 (0.4016) teacher_loss 0.1898 (0.2865) loss_zs_kd 0.0766 (0.1109) loss_oracle 0.7303 (0.6620) acc 87.5000 (85.3385) kd_loss 1.1126 (1.0352) lr 1.0000e-03 eta 0:08:53
epoch [27/50] batch [140/181] time 0.143 (0.123) data 0.000 (0.002) loss 1.1349 (1.0115) ce_loss 0.4280 (0.4034) teacher_loss 0.2703 (0.2867) loss_zs_kd 0.1209 (0.1094) loss_oracle 0.8042 (0.6700) acc 84.3750 (85.2455) kd_loss 1.0959 (1.0387) lr 1.0000e-03 eta 0:08:37
epoch [27/50] batch [160/181] time 0.108 (0.120) data 0.000 (0.002) loss 1.0362 (1.0089) ce_loss 0.5864 (0.3991) teacher_loss 0.3693 (0.2796) loss_zs_kd 0.1193 (0.1094) loss_oracle 0.6072 (0.6746) acc 78.1250 (85.5078) kd_loss 0.9787 (1.0407) lr 1.0000e-03 eta 0:08:22
epoch [27/50] batch [180/181] time 0.098 (0.117) data 0.000 (0.001) loss 0.9980 (1.0181) ce_loss 0.3025 (0.4004) teacher_loss 0.1996 (0.2805) loss_zs_kd 0.1237 (0.1095) loss_oracle 0.7366 (0.6828) acc 90.6250 (85.3472) kd_loss 0.9900 (1.0416) lr 1.0000e-03 eta 0:08:07
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,387
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.8%, epoch: 20 *******
******* Domain p best val test acc: 99.9%, epoch: 20 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [28/50] batch [20/181] time 0.113 (0.128) data 0.000 (0.015) loss 1.2270 (0.9838) ce_loss 0.5371 (0.3441) teacher_loss 0.3630 (0.2254) loss_zs_kd 0.1159 (0.0982) loss_oracle 0.8061 (0.7093) acc 81.2500 (86.7188) kd_loss 1.1351 (1.0324) lr 9.3721e-04 eta 0:08:51
epoch [28/50] batch [40/181] time 0.131 (0.118) data 0.000 (0.008) loss 0.8628 (1.0273) ce_loss 0.3137 (0.3774) teacher_loss 0.2166 (0.2479) loss_zs_kd 0.1294 (0.1029) loss_oracle 0.5815 (0.7279) acc 90.6250 (85.5469) kd_loss 1.0487 (1.0425) lr 9.3721e-04 eta 0:08:05
epoch [28/50] batch [60/181] time 0.102 (0.114) data 0.001 (0.005) loss 1.0247 (1.0214) ce_loss 0.4246 (0.3770) teacher_loss 0.2432 (0.2477) loss_zs_kd 0.1492 (0.1058) loss_oracle 0.7069 (0.7207) acc 81.2500 (85.5208) kd_loss 1.0679 (1.0432) lr 9.3721e-04 eta 0:07:49
epoch [28/50] batch [80/181] time 0.114 (0.112) data 0.000 (0.004) loss 1.0864 (1.0288) ce_loss 0.5308 (0.3863) teacher_loss 0.3353 (0.2545) loss_zs_kd 0.1161 (0.1086) loss_oracle 0.6931 (0.7200) acc 81.2500 (85.4297) kd_loss 1.0730 (1.0456) lr 9.3721e-04 eta 0:07:37
epoch [28/50] batch [100/181] time 0.137 (0.114) data 0.000 (0.003) loss 1.3283 (1.0325) ce_loss 0.8447 (0.3908) teacher_loss 0.5209 (0.2541) loss_zs_kd 0.1244 (0.1110) loss_oracle 0.7451 (0.7228) acc 81.2500 (85.4688) kd_loss 1.0849 (1.0450) lr 9.3721e-04 eta 0:07:44
epoch [28/50] batch [120/181] time 0.098 (0.113) data 0.000 (0.003) loss 1.0732 (1.0333) ce_loss 0.4900 (0.3964) teacher_loss 0.2590 (0.2589) loss_zs_kd 0.1085 (0.1119) loss_oracle 0.7600 (0.7185) acc 81.2500 (85.3385) kd_loss 1.0688 (1.0459) lr 9.3721e-04 eta 0:07:36
epoch [28/50] batch [140/181] time 0.113 (0.112) data 0.000 (0.002) loss 0.8503 (1.0321) ce_loss 0.2074 (0.3920) teacher_loss 0.1293 (0.2576) loss_zs_kd 0.0915 (0.1117) loss_oracle 0.6752 (0.7186) acc 93.7500 (85.7812) kd_loss 1.0467 (1.0479) lr 9.3721e-04 eta 0:07:30
epoch [28/50] batch [160/181] time 0.086 (0.111) data 0.000 (0.002) loss 1.0970 (1.0382) ce_loss 0.3916 (0.4005) teacher_loss 0.2682 (0.2642) loss_zs_kd 0.1216 (0.1117) loss_oracle 0.7680 (0.7182) acc 84.3750 (85.2930) kd_loss 1.0545 (1.0491) lr 9.3721e-04 eta 0:07:23
epoch [28/50] batch [180/181] time 0.076 (0.109) data 0.000 (0.002) loss 1.1853 (1.0391) ce_loss 0.6040 (0.4028) teacher_loss 0.3868 (0.2646) loss_zs_kd 0.1255 (0.1115) loss_oracle 0.7358 (0.7187) acc 78.1250 (85.3472) kd_loss 1.0391 (1.0487) lr 9.3721e-04 eta 0:07:13
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,387
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.8%, epoch: 20 *******
******* Domain p best val test acc: 99.9%, epoch: 20 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [29/50] batch [20/181] time 0.152 (0.146) data 0.000 (0.015) loss 1.0526 (1.0716) ce_loss 0.5205 (0.4247) teacher_loss 0.3145 (0.2848) loss_zs_kd 0.0971 (0.1117) loss_oracle 0.6896 (0.7310) acc 87.5000 (83.7500) kd_loss 1.0944 (1.0363) lr 8.7467e-04 eta 0:09:37
epoch [29/50] batch [40/181] time 0.161 (0.160) data 0.000 (0.007) loss 1.2674 (1.0698) ce_loss 0.6318 (0.4201) teacher_loss 0.4382 (0.2790) loss_zs_kd 0.1335 (0.1169) loss_oracle 0.7624 (0.7323) acc 68.7500 (84.3750) kd_loss 0.9703 (1.0428) lr 8.7467e-04 eta 0:10:31
epoch [29/50] batch [60/181] time 0.114 (0.143) data 0.001 (0.005) loss 1.0973 (1.0634) ce_loss 0.5283 (0.4150) teacher_loss 0.3956 (0.2745) loss_zs_kd 0.0957 (0.1142) loss_oracle 0.6538 (0.7317) acc 78.1250 (84.6354) kd_loss 1.0396 (1.0405) lr 8.7467e-04 eta 0:09:22
epoch [29/50] batch [80/181] time 0.143 (0.134) data 0.000 (0.004) loss 0.8169 (1.0455) ce_loss 0.2471 (0.4049) teacher_loss 0.1632 (0.2690) loss_zs_kd 0.1026 (0.1118) loss_oracle 0.6024 (0.7206) acc 90.6250 (85.1172) kd_loss 0.9612 (1.0318) lr 8.7467e-04 eta 0:08:42
epoch [29/50] batch [100/181] time 0.078 (0.128) data 0.000 (0.003) loss 1.2039 (1.0448) ce_loss 0.5132 (0.4004) teacher_loss 0.3320 (0.2673) loss_zs_kd 0.1382 (0.1113) loss_oracle 0.8028 (0.7219) acc 84.3750 (85.3125) kd_loss 1.0311 (1.0331) lr 8.7467e-04 eta 0:08:18
epoch [29/50] batch [120/181] time 0.074 (0.122) data 0.000 (0.003) loss 1.1340 (1.0464) ce_loss 0.4285 (0.3971) teacher_loss 0.3185 (0.2652) loss_zs_kd 0.1606 (0.1103) loss_oracle 0.7352 (0.7261) acc 84.3750 (85.6250) kd_loss 0.9458 (1.0325) lr 8.7467e-04 eta 0:07:49
epoch [29/50] batch [140/181] time 0.084 (0.117) data 0.000 (0.002) loss 1.4118 (1.0503) ce_loss 0.7417 (0.4016) teacher_loss 0.5286 (0.2658) loss_zs_kd 0.1264 (0.1106) loss_oracle 0.8199 (0.7292) acc 65.6250 (85.3125) kd_loss 1.0136 (1.0297) lr 8.7467e-04 eta 0:07:30
epoch [29/50] batch [160/181] time 0.134 (0.115) data 0.000 (0.002) loss 0.8887 (1.0490) ce_loss 0.1658 (0.4018) teacher_loss 0.0750 (0.2656) loss_zs_kd 0.0887 (0.1102) loss_oracle 0.7693 (0.7283) acc 96.8750 (85.3906) kd_loss 1.0656 (1.0301) lr 8.7467e-04 eta 0:07:18
epoch [29/50] batch [180/181] time 0.078 (0.112) data 0.000 (0.002) loss 1.0860 (1.0485) ce_loss 0.5767 (0.3999) teacher_loss 0.3624 (0.2643) loss_zs_kd 0.1395 (0.1093) loss_oracle 0.6538 (0.7295) acc 78.1250 (85.3819) kd_loss 1.0458 (1.0338) lr 8.7467e-04 eta 0:07:06
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,386
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.8%, epoch: 20 *******
******* Domain p best val test acc: 99.9%, epoch: 20 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [30/50] batch [20/181] time 0.116 (0.136) data 0.000 (0.012) loss 1.0174 (1.0312) ce_loss 0.4397 (0.3821) teacher_loss 0.2533 (0.2558) loss_zs_kd 0.1102 (0.1065) loss_oracle 0.7090 (0.7222) acc 90.6250 (85.0000) kd_loss 1.0050 (1.0526) lr 8.1262e-04 eta 0:08:32
epoch [30/50] batch [40/181] time 0.142 (0.127) data 0.000 (0.006) loss 0.9331 (1.0310) ce_loss 0.2961 (0.4022) teacher_loss 0.1085 (0.2685) loss_zs_kd 0.1271 (0.1087) loss_oracle 0.7611 (0.7081) acc 90.6250 (84.6094) kd_loss 1.0250 (1.0481) lr 8.1262e-04 eta 0:07:59
epoch [30/50] batch [60/181] time 0.114 (0.126) data 0.000 (0.004) loss 1.0773 (1.0362) ce_loss 0.3455 (0.4114) teacher_loss 0.1946 (0.2780) loss_zs_kd 0.1033 (0.1107) loss_oracle 0.8310 (0.7028) acc 87.5000 (84.1146) kd_loss 1.0481 (1.0424) lr 8.1262e-04 eta 0:07:50
epoch [30/50] batch [80/181] time 0.086 (0.122) data 0.000 (0.003) loss 1.1469 (1.0300) ce_loss 0.5508 (0.4081) teacher_loss 0.3466 (0.2759) loss_zs_kd 0.0900 (0.1094) loss_oracle 0.7552 (0.6994) acc 78.1250 (84.2969) kd_loss 1.0918 (1.0415) lr 8.1262e-04 eta 0:07:33
epoch [30/50] batch [100/181] time 0.135 (0.119) data 0.000 (0.003) loss 0.9097 (1.0293) ce_loss 0.3184 (0.4136) teacher_loss 0.2029 (0.2760) loss_zs_kd 0.1009 (0.1119) loss_oracle 0.6564 (0.6973) acc 84.3750 (84.3750) kd_loss 1.0507 (1.0405) lr 8.1262e-04 eta 0:07:21
epoch [30/50] batch [120/181] time 0.109 (0.116) data 0.000 (0.002) loss 0.9817 (1.0258) ce_loss 0.3938 (0.4095) teacher_loss 0.2517 (0.2729) loss_zs_kd 0.0874 (0.1123) loss_oracle 0.6863 (0.6968) acc 81.2500 (84.4531) kd_loss 1.0038 (1.0396) lr 8.1262e-04 eta 0:07:08
epoch [30/50] batch [140/181] time 0.106 (0.115) data 0.000 (0.002) loss 0.7952 (1.0244) ce_loss 0.1356 (0.4066) teacher_loss 0.0801 (0.2716) loss_zs_kd 0.0682 (0.1123) loss_oracle 0.6810 (0.6967) acc 96.8750 (84.5089) kd_loss 1.0184 (1.0407) lr 8.1262e-04 eta 0:06:59
epoch [30/50] batch [160/181] time 0.086 (0.113) data 0.000 (0.002) loss 0.9204 (1.0254) ce_loss 0.2759 (0.4077) teacher_loss 0.1997 (0.2713) loss_zs_kd 0.0963 (0.1125) loss_oracle 0.6725 (0.6978) acc 90.6250 (84.3750) kd_loss 0.9765 (1.0443) lr 8.1262e-04 eta 0:06:52
epoch [30/50] batch [180/181] time 0.080 (0.111) data 0.000 (0.001) loss 1.0652 (1.0203) ce_loss 0.4961 (0.4018) teacher_loss 0.3322 (0.2689) loss_zs_kd 0.1132 (0.1130) loss_oracle 0.6764 (0.6949) acc 78.1250 (84.7049) kd_loss 1.0788 (1.0501) lr 8.1262e-04 eta 0:06:40
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,392
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.8%, epoch: 20 *******
******* Domain p best val test acc: 99.9%, epoch: 20 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [31/50] batch [20/181] time 0.076 (0.184) data 0.000 (0.016) loss 1.1851 (0.9771) ce_loss 0.4622 (0.3575) teacher_loss 0.3284 (0.2489) loss_zs_kd 0.1481 (0.1105) loss_oracle 0.7827 (0.6729) acc 81.2500 (86.7188) kd_loss 1.1347 (1.1171) lr 7.5131e-04 eta 0:11:02
epoch [31/50] batch [40/181] time 0.189 (0.158) data 0.000 (0.008) loss 0.8797 (1.0029) ce_loss 0.3118 (0.3973) teacher_loss 0.1623 (0.2770) loss_zs_kd 0.1224 (0.1137) loss_oracle 0.6562 (0.6690) acc 87.5000 (85.7812) kd_loss 1.1409 (1.1140) lr 7.5131e-04 eta 0:09:26
epoch [31/50] batch [60/181] time 0.140 (0.156) data 0.000 (0.005) loss 1.0260 (0.9991) ce_loss 0.3418 (0.4017) teacher_loss 0.2545 (0.2740) loss_zs_kd 0.0917 (0.1162) loss_oracle 0.7257 (0.6671) acc 87.5000 (85.6250) kd_loss 1.1429 (1.1143) lr 7.5131e-04 eta 0:09:13
epoch [31/50] batch [80/181] time 0.097 (0.148) data 0.000 (0.004) loss 1.0180 (0.9880) ce_loss 0.3440 (0.3872) teacher_loss 0.2239 (0.2641) loss_zs_kd 0.0769 (0.1135) loss_oracle 0.7556 (0.6671) acc 87.5000 (86.0938) kd_loss 1.0945 (1.1197) lr 7.5131e-04 eta 0:08:45
epoch [31/50] batch [100/181] time 0.083 (0.143) data 0.000 (0.003) loss 0.8964 (0.9808) ce_loss 0.1381 (0.3789) teacher_loss 0.0876 (0.2555) loss_zs_kd 0.0597 (0.1145) loss_oracle 0.7790 (0.6680) acc 96.8750 (86.3125) kd_loss 1.2107 (1.1263) lr 7.5131e-04 eta 0:08:23
epoch [31/50] batch [120/181] time 0.105 (0.138) data 0.000 (0.003) loss 0.8517 (0.9837) ce_loss 0.1641 (0.3844) teacher_loss 0.1175 (0.2586) loss_zs_kd 0.0585 (0.1142) loss_oracle 0.7049 (0.6680) acc 93.7500 (86.0156) kd_loss 1.2423 (1.1324) lr 7.5131e-04 eta 0:08:03
epoch [31/50] batch [140/181] time 0.107 (0.135) data 0.000 (0.002) loss 0.9031 (0.9869) ce_loss 0.2247 (0.3890) teacher_loss 0.1931 (0.2600) loss_zs_kd 0.1342 (0.1165) loss_oracle 0.6428 (0.6686) acc 96.8750 (85.7812) kd_loss 1.1511 (1.1351) lr 7.5131e-04 eta 0:07:51
epoch [31/50] batch [160/181] time 0.140 (0.134) data 0.000 (0.002) loss 1.0958 (0.9879) ce_loss 0.4775 (0.3900) teacher_loss 0.3327 (0.2588) loss_zs_kd 0.1212 (0.1178) loss_oracle 0.7025 (0.6702) acc 81.2500 (85.7031) kd_loss 1.1402 (1.1373) lr 7.5131e-04 eta 0:07:43
epoch [31/50] batch [180/181] time 0.080 (0.131) data 0.000 (0.002) loss 0.9162 (0.9827) ce_loss 0.3970 (0.3872) teacher_loss 0.1869 (0.2562) loss_zs_kd 0.1246 (0.1173) loss_oracle 0.6670 (0.6678) acc 87.5000 (85.8160) kd_loss 1.1040 (1.1375) lr 7.5131e-04 eta 0:07:30
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,391
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.8%, epoch: 20 *******
******* Domain p best val test acc: 99.9%, epoch: 20 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [32/50] batch [20/181] time 0.087 (0.127) data 0.000 (0.015) loss 0.9498 (0.9689) ce_loss 0.3359 (0.4011) teacher_loss 0.2164 (0.2568) loss_zs_kd 0.1147 (0.1145) loss_oracle 0.6761 (0.6549) acc 87.5000 (84.8438) kd_loss 1.1172 (1.1544) lr 6.9098e-04 eta 0:07:15
epoch [32/50] batch [40/181] time 0.129 (0.119) data 0.000 (0.008) loss 0.8198 (0.9841) ce_loss 0.1904 (0.4089) teacher_loss 0.1219 (0.2639) loss_zs_kd 0.1017 (0.1147) loss_oracle 0.6471 (0.6628) acc 93.7500 (84.6875) kd_loss 1.1166 (1.1509) lr 6.9098e-04 eta 0:06:43
epoch [32/50] batch [60/181] time 0.091 (0.116) data 0.000 (0.005) loss 1.1760 (0.9919) ce_loss 0.5615 (0.4138) teacher_loss 0.3983 (0.2679) loss_zs_kd 0.1176 (0.1170) loss_oracle 0.7189 (0.6655) acc 84.3750 (85.0521) kd_loss 1.1478 (1.1573) lr 6.9098e-04 eta 0:06:30
epoch [32/50] batch [80/181] time 0.093 (0.115) data 0.000 (0.004) loss 0.8879 (0.9885) ce_loss 0.3193 (0.4085) teacher_loss 0.2178 (0.2583) loss_zs_kd 0.1141 (0.1199) loss_oracle 0.6131 (0.6703) acc 90.6250 (85.2734) kd_loss 1.1112 (1.1565) lr 6.9098e-04 eta 0:06:25
epoch [32/50] batch [100/181] time 0.123 (0.114) data 0.000 (0.003) loss 0.8681 (1.0028) ce_loss 0.2205 (0.4075) teacher_loss 0.1801 (0.2593) loss_zs_kd 0.1301 (0.1224) loss_oracle 0.6230 (0.6823) acc 90.6250 (85.1875) kd_loss 0.9884 (1.1497) lr 6.9098e-04 eta 0:06:19
epoch [32/50] batch [120/181] time 0.106 (0.113) data 0.000 (0.003) loss 0.8723 (0.9978) ce_loss 0.4678 (0.4062) teacher_loss 0.2418 (0.2548) loss_zs_kd 0.0956 (0.1231) loss_oracle 0.5828 (0.6814) acc 84.3750 (85.1823) kd_loss 0.9673 (1.1415) lr 6.9098e-04 eta 0:06:14
epoch [32/50] batch [140/181] time 0.141 (0.112) data 0.000 (0.002) loss 0.9865 (1.0018) ce_loss 0.3267 (0.4012) teacher_loss 0.1960 (0.2516) loss_zs_kd 0.1347 (0.1227) loss_oracle 0.7231 (0.6888) acc 87.5000 (85.4464) kd_loss 1.1243 (1.1399) lr 6.9098e-04 eta 0:06:08
epoch [32/50] batch [160/181] time 0.119 (0.110) data 0.000 (0.002) loss 1.2338 (1.0018) ce_loss 0.4839 (0.3956) teacher_loss 0.3563 (0.2492) loss_zs_kd 0.1333 (0.1210) loss_oracle 0.8109 (0.6921) acc 78.1250 (85.8203) kd_loss 1.1689 (1.1353) lr 6.9098e-04 eta 0:06:02
epoch [32/50] batch [180/181] time 0.091 (0.108) data 0.000 (0.002) loss 0.7396 (1.0063) ce_loss 0.1791 (0.4001) teacher_loss 0.0978 (0.2530) loss_zs_kd 0.0671 (0.1203) loss_oracle 0.6082 (0.6932) acc 93.7500 (85.4514) kd_loss 1.1708 (1.1301) lr 6.9098e-04 eta 0:05:53
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,395
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.9%, epoch: 32 *******
******* Domain p best val test acc: 99.9%, epoch: 32 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [33/50] batch [20/181] time 0.150 (0.195) data 0.000 (0.015) loss 0.8994 (0.9963) ce_loss 0.3281 (0.3879) teacher_loss 0.1755 (0.2407) loss_zs_kd 0.1395 (0.1160) loss_oracle 0.6541 (0.6976) acc 90.6250 (87.1875) kd_loss 1.1457 (1.0967) lr 6.3188e-04 eta 0:10:32
epoch [33/50] batch [40/181] time 0.150 (0.151) data 0.000 (0.008) loss 1.0018 (1.0119) ce_loss 0.4807 (0.3991) teacher_loss 0.2854 (0.2563) loss_zs_kd 0.1237 (0.1167) loss_oracle 0.6546 (0.6973) acc 84.3750 (86.5625) kd_loss 1.0960 (1.0919) lr 6.3188e-04 eta 0:08:04
epoch [33/50] batch [60/181] time 0.074 (0.135) data 0.000 (0.005) loss 1.0332 (1.0292) ce_loss 0.3911 (0.4328) teacher_loss 0.2710 (0.2801) loss_zs_kd 0.1588 (0.1181) loss_oracle 0.6828 (0.6900) acc 87.5000 (85.0000) kd_loss 1.1827 (1.0888) lr 6.3188e-04 eta 0:07:10
epoch [33/50] batch [80/181] time 0.138 (0.129) data 0.000 (0.004) loss 0.9358 (1.0318) ce_loss 0.2668 (0.4324) teacher_loss 0.1508 (0.2785) loss_zs_kd 0.1200 (0.1203) loss_oracle 0.7250 (0.6931) acc 96.8750 (84.9219) kd_loss 1.1021 (1.0796) lr 6.3188e-04 eta 0:06:49
epoch [33/50] batch [100/181] time 0.089 (0.125) data 0.000 (0.003) loss 0.8939 (1.0372) ce_loss 0.3071 (0.4353) teacher_loss 0.1488 (0.2829) loss_zs_kd 0.0825 (0.1227) loss_oracle 0.7039 (0.6930) acc 87.5000 (84.7812) kd_loss 1.1282 (1.0800) lr 6.3188e-04 eta 0:06:34
epoch [33/50] batch [120/181] time 0.082 (0.122) data 0.000 (0.003) loss 1.0607 (1.0387) ce_loss 0.5098 (0.4272) teacher_loss 0.2730 (0.2774) loss_zs_kd 0.1405 (0.1201) loss_oracle 0.7174 (0.7013) acc 81.2500 (84.9740) kd_loss 0.9821 (1.0788) lr 6.3188e-04 eta 0:06:24
epoch [33/50] batch [140/181] time 0.087 (0.121) data 0.000 (0.002) loss 0.7691 (1.0421) ce_loss 0.1164 (0.4290) teacher_loss 0.0725 (0.2799) loss_zs_kd 0.0754 (0.1203) loss_oracle 0.6589 (0.7021) acc 96.8750 (84.6875) kd_loss 1.0269 (1.0763) lr 6.3188e-04 eta 0:06:17
epoch [33/50] batch [160/181] time 0.081 (0.120) data 0.000 (0.002) loss 0.8765 (1.0332) ce_loss 0.2216 (0.4163) teacher_loss 0.1426 (0.2742) loss_zs_kd 0.0888 (0.1180) loss_oracle 0.6896 (0.7000) acc 90.6250 (85.3125) kd_loss 0.9997 (1.0751) lr 6.3188e-04 eta 0:06:11
epoch [33/50] batch [180/181] time 0.077 (0.117) data 0.000 (0.002) loss 0.9836 (1.0338) ce_loss 0.3669 (0.4148) teacher_loss 0.2485 (0.2755) loss_zs_kd 0.1320 (0.1167) loss_oracle 0.6691 (0.6999) acc 87.5000 (85.2778) kd_loss 1.0493 (1.0706) lr 6.3188e-04 eta 0:05:59
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,393
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.9%, epoch: 32 *******
******* Domain p best val test acc: 99.9%, epoch: 32 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [34/50] batch [20/181] time 0.080 (0.127) data 0.000 (0.016) loss 0.9514 (1.0144) ce_loss 0.2371 (0.4073) teacher_loss 0.1757 (0.2820) loss_zs_kd 0.0995 (0.1019) loss_oracle 0.7259 (0.6815) acc 90.6250 (85.3125) kd_loss 1.0507 (1.0213) lr 5.7422e-04 eta 0:06:28
epoch [34/50] batch [40/181] time 0.109 (0.119) data 0.000 (0.008) loss 0.9552 (1.0120) ce_loss 0.3474 (0.4205) teacher_loss 0.2458 (0.2884) loss_zs_kd 0.0848 (0.1065) loss_oracle 0.6670 (0.6703) acc 84.3750 (84.5312) kd_loss 0.9897 (1.0174) lr 5.7422e-04 eta 0:06:01
epoch [34/50] batch [60/181] time 0.111 (0.117) data 0.000 (0.005) loss 0.9373 (0.9917) ce_loss 0.3037 (0.4066) teacher_loss 0.2542 (0.2820) loss_zs_kd 0.1095 (0.1094) loss_oracle 0.6284 (0.6550) acc 90.6250 (85.1042) kd_loss 0.9473 (1.0119) lr 5.7422e-04 eta 0:05:52
epoch [34/50] batch [80/181] time 0.140 (0.117) data 0.000 (0.004) loss 0.8988 (0.9853) ce_loss 0.3062 (0.4101) teacher_loss 0.2443 (0.2863) loss_zs_kd 0.0946 (0.1104) loss_oracle 0.6072 (0.6438) acc 87.5000 (84.8828) kd_loss 0.9035 (0.9992) lr 5.7422e-04 eta 0:05:49
epoch [34/50] batch [100/181] time 0.142 (0.116) data 0.000 (0.003) loss 0.7802 (0.9842) ce_loss 0.1698 (0.4100) teacher_loss 0.1337 (0.2909) loss_zs_kd 0.0711 (0.1104) loss_oracle 0.6109 (0.6381) acc 93.7500 (84.9062) kd_loss 0.9032 (0.9926) lr 5.7422e-04 eta 0:05:44
epoch [34/50] batch [120/181] time 0.087 (0.115) data 0.000 (0.003) loss 0.8279 (0.9679) ce_loss 0.2664 (0.3967) teacher_loss 0.1528 (0.2855) loss_zs_kd 0.0962 (0.1079) loss_oracle 0.6271 (0.6285) acc 87.5000 (85.3906) kd_loss 1.0191 (0.9903) lr 5.7422e-04 eta 0:05:39
epoch [34/50] batch [140/181] time 0.134 (0.115) data 0.000 (0.002) loss 1.0730 (0.9687) ce_loss 0.4949 (0.3886) teacher_loss 0.4020 (0.2827) loss_zs_kd 0.1273 (0.1071) loss_oracle 0.6073 (0.6324) acc 84.3750 (85.7812) kd_loss 1.0906 (0.9971) lr 5.7422e-04 eta 0:05:37
epoch [34/50] batch [160/181] time 0.118 (0.114) data 0.000 (0.002) loss 1.0052 (0.9737) ce_loss 0.4668 (0.3899) teacher_loss 0.3275 (0.2841) loss_zs_kd 0.1180 (0.1066) loss_oracle 0.6187 (0.6363) acc 81.2500 (85.8594) kd_loss 0.9975 (1.0028) lr 5.7422e-04 eta 0:05:33
epoch [34/50] batch [180/181] time 0.169 (0.112) data 0.000 (0.002) loss 0.9142 (0.9732) ce_loss 0.3406 (0.3851) teacher_loss 0.2791 (0.2814) loss_zs_kd 0.0848 (0.1069) loss_oracle 0.5926 (0.6384) acc 87.5000 (86.0938) kd_loss 1.0410 (1.0087) lr 5.7422e-04 eta 0:05:23
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,391
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      95.9%, epoch: 32 *******
******* Domain p best val test acc: 99.9%, epoch: 32 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [35/50] batch [20/181] time 0.083 (0.154) data 0.000 (0.015) loss 1.2035 (1.0118) ce_loss 0.5977 (0.3656) teacher_loss 0.4375 (0.2615) loss_zs_kd 0.0793 (0.0971) loss_oracle 0.7264 (0.7017) acc 81.2500 (86.5625) kd_loss 1.0706 (1.0677) lr 5.1825e-04 eta 0:07:23
epoch [35/50] batch [40/181] time 0.104 (0.131) data 0.000 (0.007) loss 1.1755 (1.0323) ce_loss 0.6348 (0.4110) teacher_loss 0.4492 (0.2844) loss_zs_kd 0.1026 (0.1094) loss_oracle 0.6750 (0.6932) acc 81.2500 (84.7656) kd_loss 1.0302 (1.0633) lr 5.1825e-04 eta 0:06:13
epoch [35/50] batch [60/181] time 0.117 (0.123) data 0.000 (0.005) loss 1.3255 (1.0407) ce_loss 0.7197 (0.4007) teacher_loss 0.5571 (0.2809) loss_zs_kd 0.1069 (0.1109) loss_oracle 0.7150 (0.7044) acc 75.0000 (85.3646) kd_loss 1.0354 (1.0676) lr 5.1825e-04 eta 0:05:47
epoch [35/50] batch [80/181] time 0.116 (0.120) data 0.000 (0.004) loss 0.9234 (1.0390) ce_loss 0.3901 (0.4067) teacher_loss 0.2056 (0.2808) loss_zs_kd 0.1488 (0.1128) loss_oracle 0.6434 (0.7018) acc 87.5000 (85.2344) kd_loss 0.9868 (1.0677) lr 5.1825e-04 eta 0:05:36
epoch [35/50] batch [100/181] time 0.090 (0.118) data 0.000 (0.003) loss 1.0632 (1.0354) ce_loss 0.3513 (0.3954) teacher_loss 0.2403 (0.2705) loss_zs_kd 0.1212 (0.1112) loss_oracle 0.7622 (0.7093) acc 87.5000 (85.4688) kd_loss 1.0503 (1.0724) lr 5.1825e-04 eta 0:05:29
epoch [35/50] batch [120/181] time 0.089 (0.117) data 0.000 (0.003) loss 0.9224 (1.0334) ce_loss 0.1720 (0.3939) teacher_loss 0.1286 (0.2696) loss_zs_kd 0.0660 (0.1093) loss_oracle 0.7608 (0.7091) acc 96.8750 (85.6510) kd_loss 1.1161 (1.0732) lr 5.1825e-04 eta 0:05:23
epoch [35/50] batch [140/181] time 0.137 (0.116) data 0.000 (0.002) loss 1.1237 (1.0371) ce_loss 0.4443 (0.3995) teacher_loss 0.3096 (0.2738) loss_zs_kd 0.1056 (0.1112) loss_oracle 0.7613 (0.7077) acc 87.5000 (85.4241) kd_loss 1.1024 (1.0709) lr 5.1825e-04 eta 0:05:18
epoch [35/50] batch [160/181] time 0.136 (0.115) data 0.000 (0.002) loss 0.9250 (1.0317) ce_loss 0.3015 (0.3938) teacher_loss 0.1420 (0.2689) loss_zs_kd 0.0982 (0.1099) loss_oracle 0.7340 (0.7079) acc 87.5000 (85.7227) kd_loss 1.0558 (1.0725) lr 5.1825e-04 eta 0:05:14
epoch [35/50] batch [180/181] time 0.096 (0.113) data 0.000 (0.002) loss 1.0676 (1.0288) ce_loss 0.4236 (0.3942) teacher_loss 0.2784 (0.2680) loss_zs_kd 0.1186 (0.1098) loss_oracle 0.7298 (0.7059) acc 81.2500 (85.7118) kd_loss 1.0769 (1.0733) lr 5.1825e-04 eta 0:05:05
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,389
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.9%, epoch: 32 *******
******* Domain p best val test acc: 99.9%, epoch: 32 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [36/50] batch [20/181] time 0.141 (0.120) data 0.000 (0.012) loss 0.9906 (1.0800) ce_loss 0.2900 (0.4256) teacher_loss 0.1737 (0.2765) loss_zs_kd 0.0957 (0.1241) loss_oracle 0.7690 (0.7415) acc 93.7500 (85.0000) kd_loss 1.0872 (1.0651) lr 4.6417e-04 eta 0:05:22
epoch [36/50] batch [40/181] time 0.134 (0.112) data 0.000 (0.006) loss 1.0281 (1.0642) ce_loss 0.4250 (0.4208) teacher_loss 0.2614 (0.2769) loss_zs_kd 0.1161 (0.1202) loss_oracle 0.7087 (0.7273) acc 81.2500 (84.9219) kd_loss 1.0486 (1.0671) lr 4.6417e-04 eta 0:05:00
epoch [36/50] batch [60/181] time 0.137 (0.112) data 0.000 (0.004) loss 1.0250 (1.0569) ce_loss 0.4993 (0.4031) teacher_loss 0.3185 (0.2672) loss_zs_kd 0.1190 (0.1166) loss_oracle 0.6470 (0.7314) acc 81.2500 (85.2604) kd_loss 1.0378 (1.0657) lr 4.6417e-04 eta 0:04:57
epoch [36/50] batch [80/181] time 0.112 (0.112) data 0.000 (0.003) loss 0.9952 (1.0464) ce_loss 0.2859 (0.3907) teacher_loss 0.1897 (0.2613) loss_zs_kd 0.1064 (0.1152) loss_oracle 0.7523 (0.7274) acc 90.6250 (85.7812) kd_loss 1.0610 (1.0684) lr 4.6417e-04 eta 0:04:55
epoch [36/50] batch [100/181] time 0.136 (0.112) data 0.000 (0.003) loss 1.2420 (1.0382) ce_loss 0.5000 (0.3823) teacher_loss 0.3897 (0.2566) loss_zs_kd 0.1439 (0.1149) loss_oracle 0.7803 (0.7242) acc 87.5000 (86.1875) kd_loss 1.0678 (1.0687) lr 4.6417e-04 eta 0:04:52
epoch [36/50] batch [120/181] time 0.136 (0.112) data 0.000 (0.002) loss 0.9980 (1.0370) ce_loss 0.3845 (0.3818) teacher_loss 0.2463 (0.2571) loss_zs_kd 0.1243 (0.1129) loss_oracle 0.6895 (0.7235) acc 90.6250 (86.0938) kd_loss 1.0032 (1.0681) lr 4.6417e-04 eta 0:04:49
epoch [36/50] batch [140/181] time 0.097 (0.111) data 0.000 (0.002) loss 0.8649 (1.0366) ce_loss 0.2430 (0.3821) teacher_loss 0.1423 (0.2593) loss_zs_kd 0.1223 (0.1129) loss_oracle 0.6615 (0.7209) acc 93.7500 (86.1161) kd_loss 1.0637 (1.0671) lr 4.6417e-04 eta 0:04:46
epoch [36/50] batch [160/181] time 0.096 (0.111) data 0.000 (0.002) loss 0.8657 (1.0293) ce_loss 0.3425 (0.3768) teacher_loss 0.2041 (0.2571) loss_zs_kd 0.0727 (0.1108) loss_oracle 0.6253 (0.7167) acc 84.3750 (86.3672) kd_loss 0.9350 (1.0647) lr 4.6417e-04 eta 0:04:44
epoch [36/50] batch [180/181] time 0.175 (0.110) data 0.000 (0.002) loss 1.0211 (1.0261) ce_loss 0.4980 (0.3777) teacher_loss 0.3215 (0.2605) loss_zs_kd 0.1491 (0.1099) loss_oracle 0.6251 (0.7107) acc 81.2500 (86.3368) kd_loss 1.0516 (1.0600) lr 4.6417e-04 eta 0:04:38
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,399
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.6%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [37/50] batch [20/181] time 0.111 (0.135) data 0.000 (0.011) loss 0.9025 (0.9949) ce_loss 0.2532 (0.3810) teacher_loss 0.2015 (0.2877) loss_zs_kd 0.0776 (0.1018) loss_oracle 0.6622 (0.6564) acc 90.6250 (86.2500) kd_loss 1.0799 (1.0364) lr 4.1221e-04 eta 0:05:39
epoch [37/50] batch [40/181] time 0.087 (0.120) data 0.000 (0.005) loss 0.9380 (0.9927) ce_loss 0.3635 (0.3958) teacher_loss 0.2167 (0.2968) loss_zs_kd 0.0718 (0.1043) loss_oracle 0.6854 (0.6437) acc 87.5000 (85.2344) kd_loss 1.0909 (1.0257) lr 4.1221e-04 eta 0:04:58
epoch [37/50] batch [60/181] time 0.087 (0.115) data 0.000 (0.004) loss 0.8154 (0.9921) ce_loss 0.3552 (0.4042) teacher_loss 0.2093 (0.3031) loss_zs_kd 0.1004 (0.1062) loss_oracle 0.5559 (0.6359) acc 90.6250 (85.4167) kd_loss 1.0070 (1.0166) lr 4.1221e-04 eta 0:04:45
epoch [37/50] batch [80/181] time 0.121 (0.114) data 0.000 (0.003) loss 0.9895 (0.9900) ce_loss 0.3992 (0.4022) teacher_loss 0.2436 (0.2997) loss_zs_kd 0.0926 (0.1084) loss_oracle 0.6996 (0.6362) acc 78.1250 (85.1953) kd_loss 1.0229 (1.0170) lr 4.1221e-04 eta 0:04:39
epoch [37/50] batch [100/181] time 0.089 (0.113) data 0.000 (0.002) loss 1.1439 (0.9992) ce_loss 0.5737 (0.4051) teacher_loss 0.4337 (0.3053) loss_zs_kd 0.1796 (0.1095) loss_oracle 0.6204 (0.6391) acc 84.3750 (85.2188) kd_loss 1.0021 (1.0148) lr 4.1221e-04 eta 0:04:34
epoch [37/50] batch [120/181] time 0.107 (0.111) data 0.000 (0.002) loss 0.9859 (1.0008) ce_loss 0.2983 (0.4066) teacher_loss 0.2982 (0.3056) loss_zs_kd 0.1059 (0.1095) loss_oracle 0.6347 (0.6404) acc 87.5000 (85.1042) kd_loss 1.0353 (1.0178) lr 4.1221e-04 eta 0:04:28
epoch [37/50] batch [140/181] time 0.075 (0.110) data 0.000 (0.002) loss 1.1126 (1.0007) ce_loss 0.5796 (0.4064) teacher_loss 0.4662 (0.3068) loss_zs_kd 0.1331 (0.1088) loss_oracle 0.5799 (0.6395) acc 81.2500 (85.1786) kd_loss 0.9795 (1.0147) lr 4.1221e-04 eta 0:04:22
epoch [37/50] batch [160/181] time 0.110 (0.109) data 0.000 (0.001) loss 1.0665 (1.0016) ce_loss 0.4521 (0.4052) teacher_loss 0.3633 (0.3072) loss_zs_kd 0.1241 (0.1067) loss_oracle 0.6411 (0.6410) acc 84.3750 (85.2539) kd_loss 1.0633 (1.0131) lr 4.1221e-04 eta 0:04:17
epoch [37/50] batch [180/181] time 0.078 (0.107) data 0.000 (0.001) loss 1.2739 (1.0019) ce_loss 0.4839 (0.4047) teacher_loss 0.4747 (0.3074) loss_zs_kd 0.1130 (0.1053) loss_oracle 0.7427 (0.6418) acc 81.2500 (85.4514) kd_loss 1.0375 (1.0118) lr 4.1221e-04 eta 0:04:11
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,390
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [38/50] batch [20/181] time 0.076 (0.126) data 0.000 (0.015) loss 1.0369 (1.0587) ce_loss 0.3887 (0.3959) teacher_loss 0.3230 (0.3166) loss_zs_kd 0.0789 (0.0875) loss_oracle 0.6744 (0.6983) acc 84.3750 (85.4688) kd_loss 0.9994 (1.0317) lr 3.6258e-04 eta 0:04:54
epoch [38/50] batch [40/181] time 0.137 (0.119) data 0.000 (0.008) loss 0.9651 (1.0328) ce_loss 0.4111 (0.4055) teacher_loss 0.2737 (0.3203) loss_zs_kd 0.0461 (0.0857) loss_oracle 0.6683 (0.6697) acc 84.3750 (85.5469) kd_loss 0.9966 (1.0194) lr 3.6258e-04 eta 0:04:35
epoch [38/50] batch [60/181] time 0.076 (0.114) data 0.000 (0.005) loss 1.0087 (1.0296) ce_loss 0.3108 (0.3960) teacher_loss 0.2136 (0.3115) loss_zs_kd 0.0661 (0.0854) loss_oracle 0.7621 (0.6754) acc 87.5000 (85.6250) kd_loss 1.0245 (1.0159) lr 3.6258e-04 eta 0:04:21
epoch [38/50] batch [80/181] time 0.087 (0.113) data 0.000 (0.004) loss 1.1034 (1.0259) ce_loss 0.4702 (0.3990) teacher_loss 0.3697 (0.3098) loss_zs_kd 0.1295 (0.0856) loss_oracle 0.6689 (0.6733) acc 78.1250 (85.3906) kd_loss 1.0609 (1.0084) lr 3.6258e-04 eta 0:04:16
epoch [38/50] batch [100/181] time 0.085 (0.113) data 0.000 (0.003) loss 1.2976 (1.0325) ce_loss 0.7700 (0.4074) teacher_loss 0.6116 (0.3154) loss_zs_kd 0.1309 (0.0877) loss_oracle 0.6206 (0.6732) acc 65.6250 (84.9375) kd_loss 0.9542 (1.0046) lr 3.6258e-04 eta 0:04:14
epoch [38/50] batch [120/181] time 0.117 (0.114) data 0.000 (0.003) loss 1.1459 (1.0375) ce_loss 0.5254 (0.4106) teacher_loss 0.3348 (0.3149) loss_zs_kd 0.0763 (0.0901) loss_oracle 0.7729 (0.6777) acc 84.3750 (84.8698) kd_loss 1.0669 (1.0048) lr 3.6258e-04 eta 0:04:14
epoch [38/50] batch [140/181] time 0.120 (0.114) data 0.000 (0.002) loss 0.9508 (1.0364) ce_loss 0.2817 (0.4062) teacher_loss 0.2245 (0.3103) loss_zs_kd 0.0610 (0.0902) loss_oracle 0.6959 (0.6810) acc 90.6250 (85.1116) kd_loss 1.0530 (1.0061) lr 3.6258e-04 eta 0:04:11
epoch [38/50] batch [160/181] time 0.084 (0.113) data 0.000 (0.002) loss 0.9004 (1.0364) ce_loss 0.3647 (0.4109) teacher_loss 0.2332 (0.3093) loss_zs_kd 0.1011 (0.0934) loss_oracle 0.6167 (0.6804) acc 90.6250 (84.9219) kd_loss 1.0388 (1.0072) lr 3.6258e-04 eta 0:04:07
epoch [38/50] batch [180/181] time 0.096 (0.110) data 0.000 (0.002) loss 0.8435 (1.0295) ce_loss 0.2010 (0.4034) teacher_loss 0.1198 (0.3016) loss_zs_kd 0.0800 (0.0940) loss_oracle 0.6837 (0.6808) acc 96.8750 (85.2778) kd_loss 1.0293 (1.0085) lr 3.6258e-04 eta 0:03:58
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,391
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [39/50] batch [20/181] time 0.081 (0.163) data 0.000 (0.015) loss 1.0284 (0.9622) ce_loss 0.3821 (0.3119) teacher_loss 0.2706 (0.2308) loss_zs_kd 0.1414 (0.0986) loss_oracle 0.6872 (0.6821) acc 87.5000 (89.5312) kd_loss 1.0406 (1.0166) lr 3.1545e-04 eta 0:05:50
epoch [39/50] batch [40/181] time 0.111 (0.134) data 0.001 (0.008) loss 1.0707 (1.0045) ce_loss 0.4861 (0.3747) teacher_loss 0.2964 (0.2648) loss_zs_kd 0.1250 (0.0992) loss_oracle 0.7118 (0.6901) acc 78.1250 (87.1875) kd_loss 0.9541 (1.0059) lr 3.1545e-04 eta 0:04:46
epoch [39/50] batch [60/181] time 0.089 (0.125) data 0.000 (0.005) loss 1.0560 (1.0169) ce_loss 0.4695 (0.3891) teacher_loss 0.3189 (0.2698) loss_zs_kd 0.1038 (0.1016) loss_oracle 0.6852 (0.6962) acc 81.2500 (85.8854) kd_loss 0.9410 (1.0057) lr 3.1545e-04 eta 0:04:23
epoch [39/50] batch [80/181] time 0.139 (0.121) data 0.000 (0.004) loss 0.8908 (1.0313) ce_loss 0.2344 (0.4013) teacher_loss 0.1476 (0.2761) loss_zs_kd 0.0851 (0.1073) loss_oracle 0.7007 (0.7015) acc 93.7500 (85.1172) kd_loss 1.0412 (1.0098) lr 3.1545e-04 eta 0:04:13
epoch [39/50] batch [100/181] time 0.110 (0.119) data 0.000 (0.003) loss 1.1282 (1.0351) ce_loss 0.4692 (0.4006) teacher_loss 0.3058 (0.2748) loss_zs_kd 0.1425 (0.1095) loss_oracle 0.7512 (0.7056) acc 78.1250 (84.9062) kd_loss 1.0524 (1.0073) lr 3.1545e-04 eta 0:04:05
epoch [39/50] batch [120/181] time 0.133 (0.117) data 0.000 (0.003) loss 0.9431 (1.0373) ce_loss 0.2438 (0.3993) teacher_loss 0.1839 (0.2753) loss_zs_kd 0.0951 (0.1092) loss_oracle 0.7116 (0.7074) acc 96.8750 (85.1042) kd_loss 1.0552 (1.0021) lr 3.1545e-04 eta 0:04:00
epoch [39/50] batch [140/181] time 0.083 (0.117) data 0.000 (0.002) loss 1.2059 (1.0405) ce_loss 0.5034 (0.4021) teacher_loss 0.3314 (0.2771) loss_zs_kd 0.1527 (0.1093) loss_oracle 0.7981 (0.7088) acc 84.3750 (85.0670) kd_loss 0.9928 (0.9996) lr 3.1545e-04 eta 0:03:56
epoch [39/50] batch [160/181] time 0.131 (0.116) data 0.000 (0.002) loss 1.0356 (1.0394) ce_loss 0.4153 (0.4000) teacher_loss 0.2711 (0.2748) loss_zs_kd 0.1319 (0.1098) loss_oracle 0.6986 (0.7098) acc 84.3750 (85.2734) kd_loss 0.9606 (1.0007) lr 3.1545e-04 eta 0:03:53
epoch [39/50] batch [180/181] time 0.099 (0.113) data 0.000 (0.002) loss 0.8753 (1.0367) ce_loss 0.1455 (0.3988) teacher_loss 0.0833 (0.2727) loss_zs_kd 0.0493 (0.1097) loss_oracle 0.7673 (0.7092) acc 93.7500 (85.2951) kd_loss 0.9943 (0.9992) lr 3.1545e-04 eta 0:03:46
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,390
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [40/50] batch [20/181] time 0.122 (0.131) data 0.000 (0.012) loss 0.8376 (1.0392) ce_loss 0.1522 (0.4113) teacher_loss 0.0918 (0.2998) loss_zs_kd 0.1031 (0.1091) loss_oracle 0.6942 (0.6849) acc 90.6250 (85.1562) kd_loss 0.9702 (0.9521) lr 2.7103e-04 eta 0:04:18
epoch [40/50] batch [40/181] time 0.122 (0.124) data 0.000 (0.006) loss 1.0857 (1.0382) ce_loss 0.4348 (0.4215) teacher_loss 0.2845 (0.2879) loss_zs_kd 0.1407 (0.1196) loss_oracle 0.7308 (0.6905) acc 78.1250 (84.1406) kd_loss 0.9856 (0.9661) lr 2.7103e-04 eta 0:04:02
epoch [40/50] batch [60/181] time 0.120 (0.126) data 0.001 (0.004) loss 0.8819 (1.0219) ce_loss 0.2622 (0.4005) teacher_loss 0.1581 (0.2763) loss_zs_kd 0.0802 (0.1130) loss_oracle 0.6837 (0.6891) acc 93.7500 (85.1562) kd_loss 1.0681 (0.9678) lr 2.7103e-04 eta 0:04:03
epoch [40/50] batch [80/181] time 0.148 (0.128) data 0.000 (0.003) loss 1.0564 (1.0193) ce_loss 0.4771 (0.4031) teacher_loss 0.3162 (0.2774) loss_zs_kd 0.1198 (0.1124) loss_oracle 0.6804 (0.6857) acc 84.3750 (85.2344) kd_loss 0.9483 (0.9693) lr 2.7103e-04 eta 0:04:04
epoch [40/50] batch [100/181] time 0.144 (0.128) data 0.000 (0.003) loss 1.1976 (1.0132) ce_loss 0.6040 (0.3942) teacher_loss 0.3940 (0.2720) loss_zs_kd 0.1024 (0.1100) loss_oracle 0.7523 (0.6862) acc 78.1250 (85.6875) kd_loss 0.9834 (0.9698) lr 2.7103e-04 eta 0:04:02
epoch [40/50] batch [120/181] time 0.093 (0.127) data 0.000 (0.002) loss 0.9731 (1.0029) ce_loss 0.3892 (0.3861) teacher_loss 0.2854 (0.2644) loss_zs_kd 0.1271 (0.1104) loss_oracle 0.6241 (0.6834) acc 90.6250 (85.8073) kd_loss 0.9357 (0.9683) lr 2.7103e-04 eta 0:03:56
epoch [40/50] batch [140/181] time 0.109 (0.126) data 0.000 (0.002) loss 1.0686 (0.9991) ce_loss 0.4978 (0.3850) teacher_loss 0.3878 (0.2628) loss_zs_kd 0.1121 (0.1108) loss_oracle 0.6247 (0.6809) acc 78.1250 (85.8036) kd_loss 0.9071 (0.9711) lr 2.7103e-04 eta 0:03:53
epoch [40/50] batch [160/181] time 0.188 (0.128) data 0.000 (0.002) loss 1.0430 (0.9929) ce_loss 0.6465 (0.3858) teacher_loss 0.3560 (0.2636) loss_zs_kd 0.1595 (0.1103) loss_oracle 0.6072 (0.6741) acc 78.1250 (85.7617) kd_loss 0.9409 (0.9675) lr 2.7103e-04 eta 0:03:54
epoch [40/50] batch [180/181] time 0.187 (0.128) data 0.000 (0.002) loss 1.0221 (0.9935) ce_loss 0.4014 (0.3896) teacher_loss 0.2684 (0.2657) loss_zs_kd 0.0944 (0.1110) loss_oracle 0.7064 (0.6723) acc 87.5000 (85.6076) kd_loss 0.9740 (0.9659) lr 2.7103e-04 eta 0:03:52
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,397
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [41/50] batch [20/181] time 0.141 (0.136) data 0.000 (0.014) loss 1.1203 (0.9717) ce_loss 0.5664 (0.3905) teacher_loss 0.3521 (0.2718) loss_zs_kd 0.1317 (0.1083) loss_oracle 0.7024 (0.6458) acc 81.2500 (86.7188) kd_loss 0.9347 (0.9558) lr 2.2949e-04 eta 0:04:02
epoch [41/50] batch [40/181] time 0.083 (0.124) data 0.000 (0.007) loss 0.8853 (0.9558) ce_loss 0.4121 (0.3762) teacher_loss 0.2410 (0.2584) loss_zs_kd 0.1121 (0.1131) loss_oracle 0.5883 (0.6409) acc 84.3750 (86.7188) kd_loss 0.9133 (0.9747) lr 2.2949e-04 eta 0:03:39
epoch [41/50] batch [60/181] time 0.137 (0.120) data 0.001 (0.005) loss 0.9595 (0.9558) ce_loss 0.3511 (0.3706) teacher_loss 0.1899 (0.2454) loss_zs_kd 0.2160 (0.1176) loss_oracle 0.6616 (0.6516) acc 96.8750 (86.6146) kd_loss 1.0244 (0.9980) lr 2.2949e-04 eta 0:03:29
epoch [41/50] batch [80/181] time 0.097 (0.117) data 0.000 (0.004) loss 0.7654 (0.9517) ce_loss 0.2532 (0.3654) teacher_loss 0.1424 (0.2416) loss_zs_kd 0.1123 (0.1165) loss_oracle 0.5668 (0.6519) acc 96.8750 (86.9922) kd_loss 1.0379 (1.0079) lr 2.2949e-04 eta 0:03:21
epoch [41/50] batch [100/181] time 0.117 (0.115) data 0.000 (0.003) loss 1.1298 (0.9646) ce_loss 0.5054 (0.3749) teacher_loss 0.3528 (0.2483) loss_zs_kd 0.1144 (0.1173) loss_oracle 0.7197 (0.6577) acc 81.2500 (86.3750) kd_loss 1.1269 (1.0147) lr 2.2949e-04 eta 0:03:17
epoch [41/50] batch [120/181] time 0.137 (0.115) data 0.000 (0.003) loss 1.0289 (0.9643) ce_loss 0.5122 (0.3803) teacher_loss 0.2635 (0.2470) loss_zs_kd 0.1041 (0.1176) loss_oracle 0.7134 (0.6585) acc 87.5000 (86.1979) kd_loss 1.0355 (1.0193) lr 2.2949e-04 eta 0:03:14
epoch [41/50] batch [140/181] time 0.141 (0.115) data 0.000 (0.002) loss 0.9832 (0.9667) ce_loss 0.2886 (0.3829) teacher_loss 0.1968 (0.2462) loss_zs_kd 0.1294 (0.1186) loss_oracle 0.7216 (0.6612) acc 93.7500 (86.0938) kd_loss 1.1213 (1.0236) lr 2.2949e-04 eta 0:03:11
epoch [41/50] batch [160/181] time 0.119 (0.114) data 0.000 (0.002) loss 1.1891 (0.9730) ce_loss 0.5210 (0.3868) teacher_loss 0.3813 (0.2473) loss_zs_kd 0.1544 (0.1206) loss_oracle 0.7306 (0.6654) acc 84.3750 (85.9766) kd_loss 1.1174 (1.0283) lr 2.2949e-04 eta 0:03:08
epoch [41/50] batch [180/181] time 0.080 (0.112) data 0.000 (0.002) loss 0.9018 (0.9746) ce_loss 0.4287 (0.3868) teacher_loss 0.2401 (0.2468) loss_zs_kd 0.1064 (0.1217) loss_oracle 0.6085 (0.6670) acc 87.5000 (85.9722) kd_loss 1.0241 (1.0323) lr 2.2949e-04 eta 0:03:02
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,393
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [42/50] batch [20/181] time 0.088 (0.133) data 0.000 (0.015) loss 0.7182 (0.9721) ce_loss 0.0809 (0.3605) teacher_loss 0.0533 (0.2332) loss_zs_kd 0.0621 (0.1138) loss_oracle 0.6339 (0.6819) acc 100.0000 (87.3438) kd_loss 1.0975 (1.0704) lr 1.9098e-04 eta 0:03:33
epoch [42/50] batch [40/181] time 0.132 (0.127) data 0.000 (0.008) loss 0.9264 (0.9841) ce_loss 0.2401 (0.3830) teacher_loss 0.1465 (0.2475) loss_zs_kd 0.0989 (0.1177) loss_oracle 0.7305 (0.6778) acc 93.7500 (85.8594) kd_loss 1.1213 (1.0768) lr 1.9098e-04 eta 0:03:22
epoch [42/50] batch [60/181] time 0.142 (0.126) data 0.000 (0.005) loss 1.1540 (0.9943) ce_loss 0.6948 (0.4054) teacher_loss 0.4754 (0.2684) loss_zs_kd 0.1638 (0.1161) loss_oracle 0.5967 (0.6678) acc 78.1250 (84.8958) kd_loss 1.0395 (1.0743) lr 1.9098e-04 eta 0:03:17
epoch [42/50] batch [80/181] time 0.123 (0.125) data 0.000 (0.004) loss 0.8950 (0.9767) ce_loss 0.3740 (0.3912) teacher_loss 0.1841 (0.2552) loss_zs_kd 0.1436 (0.1160) loss_oracle 0.6391 (0.6636) acc 90.6250 (85.5078) kd_loss 1.0331 (1.0747) lr 1.9098e-04 eta 0:03:13
epoch [42/50] batch [100/181] time 0.120 (0.124) data 0.000 (0.003) loss 0.9732 (0.9757) ce_loss 0.3159 (0.3890) teacher_loss 0.1779 (0.2565) loss_zs_kd 0.1091 (0.1173) loss_oracle 0.7408 (0.6606) acc 87.5000 (85.8750) kd_loss 1.1306 (1.0780) lr 1.9098e-04 eta 0:03:08
epoch [42/50] batch [120/181] time 0.177 (0.122) data 0.000 (0.003) loss 0.9655 (0.9681) ce_loss 0.4304 (0.3834) teacher_loss 0.3183 (0.2551) loss_zs_kd 0.1295 (0.1165) loss_oracle 0.5825 (0.6547) acc 81.2500 (86.1198) kd_loss 1.0119 (1.0822) lr 1.9098e-04 eta 0:03:03
epoch [42/50] batch [140/181] time 0.085 (0.127) data 0.000 (0.002) loss 0.8675 (0.9682) ce_loss 0.3220 (0.3909) teacher_loss 0.2021 (0.2601) loss_zs_kd 0.1161 (0.1164) loss_oracle 0.6074 (0.6499) acc 84.3750 (85.8036) kd_loss 1.2146 (1.0858) lr 1.9098e-04 eta 0:03:09
epoch [42/50] batch [160/181] time 0.192 (0.130) data 0.001 (0.002) loss 1.0329 (0.9659) ce_loss 0.4346 (0.3889) teacher_loss 0.2979 (0.2605) loss_zs_kd 0.1197 (0.1162) loss_oracle 0.6751 (0.6473) acc 84.3750 (85.7812) kd_loss 1.1697 (1.0911) lr 1.9098e-04 eta 0:03:11
epoch [42/50] batch [180/181] time 0.094 (0.130) data 0.000 (0.002) loss 0.9925 (0.9641) ce_loss 0.4185 (0.3881) teacher_loss 0.3569 (0.2628) loss_zs_kd 0.0834 (0.1166) loss_oracle 0.5939 (0.6429) acc 81.2500 (85.8681) kd_loss 1.1456 (1.0946) lr 1.9098e-04 eta 0:03:08
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,395
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [43/50] batch [20/181] time 0.132 (0.124) data 0.000 (0.016) loss 1.0470 (0.9613) ce_loss 0.4155 (0.3626) teacher_loss 0.4346 (0.2862) loss_zs_kd 0.1520 (0.1161) loss_oracle 0.5364 (0.6170) acc 84.3750 (85.9375) kd_loss 1.1113 (1.1484) lr 1.5567e-04 eta 0:02:57
epoch [43/50] batch [40/181] time 0.143 (0.118) data 0.000 (0.008) loss 0.9257 (0.9372) ce_loss 0.3879 (0.3662) teacher_loss 0.3693 (0.2912) loss_zs_kd 0.1133 (0.1118) loss_oracle 0.4997 (0.5901) acc 87.5000 (86.9531) kd_loss 1.1406 (1.1458) lr 1.5567e-04 eta 0:02:45
epoch [43/50] batch [60/181] time 0.144 (0.118) data 0.000 (0.006) loss 0.9172 (0.9482) ce_loss 0.5073 (0.3750) teacher_loss 0.3556 (0.2973) loss_zs_kd 0.1373 (0.1132) loss_oracle 0.4930 (0.5943) acc 81.2500 (86.5625) kd_loss 1.1129 (1.1656) lr 1.5567e-04 eta 0:02:43
epoch [43/50] batch [80/181] time 0.092 (0.118) data 0.000 (0.004) loss 0.7981 (0.9447) ce_loss 0.2343 (0.3661) teacher_loss 0.2110 (0.2908) loss_zs_kd 0.1037 (0.1116) loss_oracle 0.5353 (0.5982) acc 93.7500 (87.2656) kd_loss 1.2852 (1.1787) lr 1.5567e-04 eta 0:02:41
epoch [43/50] batch [100/181] time 0.141 (0.119) data 0.000 (0.003) loss 1.0426 (0.9471) ce_loss 0.2734 (0.3740) teacher_loss 0.2239 (0.3013) loss_zs_kd 0.1135 (0.1091) loss_oracle 0.7619 (0.5913) acc 96.8750 (86.8125) kd_loss 1.3032 (1.1938) lr 1.5567e-04 eta 0:02:40
epoch [43/50] batch [120/181] time 0.145 (0.120) data 0.000 (0.003) loss 0.8972 (0.9535) ce_loss 0.2822 (0.3813) teacher_loss 0.2183 (0.3060) loss_zs_kd 0.1106 (0.1080) loss_oracle 0.6235 (0.5935) acc 90.6250 (86.5365) kd_loss 1.3229 (1.2047) lr 1.5567e-04 eta 0:02:39
epoch [43/50] batch [140/181] time 0.102 (0.119) data 0.001 (0.003) loss 0.7753 (0.9536) ce_loss 0.2458 (0.3802) teacher_loss 0.2027 (0.3071) loss_zs_kd 0.0944 (0.1093) loss_oracle 0.5254 (0.5918) acc 90.6250 (86.4955) kd_loss 1.2282 (1.2120) lr 1.5567e-04 eta 0:02:36
epoch [43/50] batch [160/181] time 0.135 (0.119) data 0.000 (0.002) loss 0.9369 (0.9616) ce_loss 0.3914 (0.3861) teacher_loss 0.3213 (0.3143) loss_zs_kd 0.1106 (0.1099) loss_oracle 0.5603 (0.5924) acc 78.1250 (86.2891) kd_loss 1.2782 (1.2199) lr 1.5567e-04 eta 0:02:32
epoch [43/50] batch [180/181] time 0.089 (0.117) data 0.000 (0.002) loss 0.9296 (0.9601) ce_loss 0.2258 (0.3876) teacher_loss 0.2410 (0.3172) loss_zs_kd 0.0920 (0.1096) loss_oracle 0.6426 (0.5881) acc 87.5000 (86.2500) kd_loss 1.3302 (1.2279) lr 1.5567e-04 eta 0:02:28
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,392
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [44/50] batch [20/181] time 0.091 (0.129) data 0.000 (0.015) loss 0.9964 (0.9255) ce_loss 0.4700 (0.3795) teacher_loss 0.3366 (0.3108) loss_zs_kd 0.1278 (0.1061) loss_oracle 0.5958 (0.5616) acc 81.2500 (86.8750) kd_loss 1.2911 (1.2773) lr 1.2369e-04 eta 0:02:40
epoch [44/50] batch [40/181] time 0.092 (0.122) data 0.000 (0.008) loss 0.9375 (0.9398) ce_loss 0.3113 (0.3891) teacher_loss 0.3600 (0.3174) loss_zs_kd 0.0902 (0.1084) loss_oracle 0.5323 (0.5682) acc 87.5000 (85.8594) kd_loss 1.2413 (1.2725) lr 1.2369e-04 eta 0:02:29
epoch [44/50] batch [60/181] time 0.132 (0.122) data 0.000 (0.005) loss 0.9178 (0.9424) ce_loss 0.3889 (0.3874) teacher_loss 0.2487 (0.3143) loss_zs_kd 0.1140 (0.1066) loss_oracle 0.6121 (0.5748) acc 81.2500 (85.5208) kd_loss 1.2706 (1.2809) lr 1.2369e-04 eta 0:02:27
epoch [44/50] batch [80/181] time 0.099 (0.119) data 0.000 (0.004) loss 1.3086 (0.9425) ce_loss 0.5952 (0.3818) teacher_loss 0.4973 (0.3151) loss_zs_kd 0.1177 (0.1049) loss_oracle 0.7525 (0.5749) acc 78.1250 (85.7031) kd_loss 1.2740 (1.2831) lr 1.2369e-04 eta 0:02:21
epoch [44/50] batch [100/181] time 0.131 (0.119) data 0.000 (0.003) loss 0.8302 (0.9477) ce_loss 0.2103 (0.3864) teacher_loss 0.1828 (0.3204) loss_zs_kd 0.0983 (0.1042) loss_oracle 0.5983 (0.5752) acc 87.5000 (85.7188) kd_loss 1.2501 (1.2795) lr 1.2369e-04 eta 0:02:18
epoch [44/50] batch [120/181] time 0.083 (0.120) data 0.000 (0.003) loss 1.2105 (0.9527) ce_loss 0.6392 (0.3932) teacher_loss 0.4788 (0.3271) loss_zs_kd 0.1177 (0.1029) loss_oracle 0.6728 (0.5742) acc 78.1250 (85.3385) kd_loss 1.3239 (1.2802) lr 1.2369e-04 eta 0:02:17
epoch [44/50] batch [140/181] time 0.188 (0.125) data 0.000 (0.002) loss 0.7882 (0.9581) ce_loss 0.3743 (0.3993) teacher_loss 0.2368 (0.3319) loss_zs_kd 0.0902 (0.1032) loss_oracle 0.5064 (0.5745) acc 90.6250 (85.1339) kd_loss 1.3312 (1.2782) lr 1.2369e-04 eta 0:02:20
epoch [44/50] batch [160/181] time 0.080 (0.126) data 0.000 (0.002) loss 1.3342 (0.9593) ce_loss 0.5928 (0.4016) teacher_loss 0.5738 (0.3341) loss_zs_kd 0.1607 (0.1029) loss_oracle 0.6800 (0.5738) acc 75.0000 (85.1562) kd_loss 1.3162 (1.2771) lr 1.2369e-04 eta 0:02:19
epoch [44/50] batch [180/181] time 0.099 (0.123) data 0.000 (0.002) loss 0.7954 (0.9496) ce_loss 0.2991 (0.3930) teacher_loss 0.1830 (0.3261) loss_zs_kd 0.0951 (0.1014) loss_oracle 0.5649 (0.5728) acc 87.5000 (85.3993) kd_loss 1.2330 (1.2760) lr 1.2369e-04 eta 0:02:13
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,392
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [45/50] batch [20/181] time 0.096 (0.131) data 0.001 (0.012) loss 0.8294 (0.9288) ce_loss 0.1965 (0.3736) teacher_loss 0.1452 (0.3183) loss_zs_kd 0.0896 (0.0921) loss_oracle 0.6394 (0.5645) acc 93.7500 (86.2500) kd_loss 1.2411 (1.2845) lr 9.5173e-05 eta 0:02:19
epoch [45/50] batch [40/181] time 0.147 (0.126) data 0.000 (0.006) loss 0.8363 (0.9267) ce_loss 0.3616 (0.3634) teacher_loss 0.2799 (0.2985) loss_zs_kd 0.1483 (0.0972) loss_oracle 0.4822 (0.5795) acc 87.5000 (87.5000) kd_loss 1.3043 (1.2713) lr 9.5173e-05 eta 0:02:11
epoch [45/50] batch [60/181] time 0.115 (0.124) data 0.000 (0.004) loss 1.1288 (0.9460) ce_loss 0.5410 (0.3849) teacher_loss 0.4013 (0.3179) loss_zs_kd 0.1456 (0.0981) loss_oracle 0.6547 (0.5791) acc 75.0000 (86.2500) kd_loss 1.2580 (1.2712) lr 9.5173e-05 eta 0:02:06
epoch [45/50] batch [80/181] time 0.132 (0.124) data 0.000 (0.003) loss 0.9040 (0.9304) ce_loss 0.4048 (0.3788) teacher_loss 0.2530 (0.3113) loss_zs_kd 0.0926 (0.0951) loss_oracle 0.6047 (0.5716) acc 81.2500 (86.2109) kd_loss 1.2414 (1.2698) lr 9.5173e-05 eta 0:02:04
epoch [45/50] batch [100/181] time 0.092 (0.123) data 0.000 (0.003) loss 0.9021 (0.9307) ce_loss 0.3999 (0.3830) teacher_loss 0.3862 (0.3145) loss_zs_kd 0.0782 (0.0942) loss_oracle 0.4767 (0.5691) acc 87.5000 (86.0312) kd_loss 1.3322 (1.2724) lr 9.5173e-05 eta 0:02:01
epoch [45/50] batch [120/181] time 0.141 (0.123) data 0.000 (0.002) loss 0.8378 (0.9326) ce_loss 0.2888 (0.3826) teacher_loss 0.2743 (0.3144) loss_zs_kd 0.0677 (0.0945) loss_oracle 0.5297 (0.5710) acc 90.6250 (86.1458) kd_loss 1.2809 (1.2713) lr 9.5173e-05 eta 0:01:58
epoch [45/50] batch [140/181] time 0.119 (0.123) data 0.000 (0.002) loss 0.8613 (0.9375) ce_loss 0.3660 (0.3916) teacher_loss 0.2855 (0.3195) loss_zs_kd 0.1193 (0.0959) loss_oracle 0.5162 (0.5701) acc 84.3750 (85.7589) kd_loss 1.3002 (1.2697) lr 9.5173e-05 eta 0:01:56
epoch [45/50] batch [160/181] time 0.139 (0.122) data 0.000 (0.002) loss 1.0053 (0.9411) ce_loss 0.4492 (0.3909) teacher_loss 0.3655 (0.3176) loss_zs_kd 0.1242 (0.0957) loss_oracle 0.5777 (0.5757) acc 81.2500 (85.7227) kd_loss 1.2582 (1.2686) lr 9.5173e-05 eta 0:01:53
epoch [45/50] batch [180/181] time 0.120 (0.120) data 0.000 (0.002) loss 0.9309 (0.9462) ce_loss 0.3142 (0.3984) teacher_loss 0.2616 (0.3205) loss_zs_kd 0.0827 (0.0965) loss_oracle 0.6278 (0.5775) acc 87.5000 (85.4514) kd_loss 1.2494 (1.2694) lr 9.5173e-05 eta 0:01:49
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,392
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [46/50] batch [20/181] time 0.135 (0.132) data 0.000 (0.011) loss 0.8471 (0.8798) ce_loss 0.2646 (0.3331) teacher_loss 0.1931 (0.2671) loss_zs_kd 0.0941 (0.0891) loss_oracle 0.6070 (0.5682) acc 90.6250 (87.3438) kd_loss 1.2665 (1.2789) lr 7.0224e-05 eta 0:01:56
epoch [46/50] batch [40/181] time 0.121 (0.124) data 0.000 (0.006) loss 1.1142 (0.9157) ce_loss 0.4824 (0.3698) teacher_loss 0.3671 (0.2885) loss_zs_kd 0.0879 (0.0955) loss_oracle 0.7032 (0.5794) acc 87.5000 (86.2500) kd_loss 1.2642 (1.2727) lr 7.0224e-05 eta 0:01:47
epoch [46/50] batch [60/181] time 0.072 (0.119) data 0.000 (0.004) loss 0.9162 (0.9266) ce_loss 0.3521 (0.3840) teacher_loss 0.2105 (0.2982) loss_zs_kd 0.0843 (0.0977) loss_oracle 0.6636 (0.5795) acc 84.3750 (85.4167) kd_loss 1.2550 (1.2649) lr 7.0224e-05 eta 0:01:40
epoch [46/50] batch [80/181] time 0.188 (0.125) data 0.000 (0.003) loss 0.8451 (0.9355) ce_loss 0.3511 (0.3899) teacher_loss 0.2473 (0.3026) loss_zs_kd 0.1045 (0.0998) loss_oracle 0.5455 (0.5830) acc 90.6250 (85.3516) kd_loss 1.2083 (1.2665) lr 7.0224e-05 eta 0:01:43
epoch [46/50] batch [100/181] time 0.137 (0.123) data 0.000 (0.002) loss 0.7655 (0.9233) ce_loss 0.3201 (0.3823) teacher_loss 0.2217 (0.2995) loss_zs_kd 0.0744 (0.0988) loss_oracle 0.5066 (0.5744) acc 87.5000 (85.6562) kd_loss 1.3024 (1.2673) lr 7.0224e-05 eta 0:01:39
epoch [46/50] batch [120/181] time 0.063 (0.133) data 0.000 (0.002) loss 0.9279 (0.9282) ce_loss 0.5005 (0.3903) teacher_loss 0.3889 (0.3052) loss_zs_kd 0.0962 (0.0999) loss_oracle 0.4909 (0.5730) acc 87.5000 (85.5469) kd_loss 1.2616 (1.2657) lr 7.0224e-05 eta 0:01:44
epoch [46/50] batch [140/181] time 0.096 (0.128) data 0.000 (0.002) loss 0.8704 (0.9282) ce_loss 0.3308 (0.3876) teacher_loss 0.2328 (0.3014) loss_zs_kd 0.0895 (0.1001) loss_oracle 0.5928 (0.5768) acc 90.6250 (85.6473) kd_loss 1.2233 (1.2653) lr 7.0224e-05 eta 0:01:38
epoch [46/50] batch [160/181] time 0.094 (0.125) data 0.000 (0.002) loss 0.9391 (0.9317) ce_loss 0.4575 (0.3890) teacher_loss 0.3832 (0.3042) loss_zs_kd 0.1179 (0.1001) loss_oracle 0.4970 (0.5774) acc 84.3750 (85.7031) kd_loss 1.2975 (1.2665) lr 7.0224e-05 eta 0:01:33
epoch [46/50] batch [180/181] time 0.098 (0.121) data 0.000 (0.001) loss 0.9485 (0.9304) ce_loss 0.3350 (0.3863) teacher_loss 0.2734 (0.3034) loss_zs_kd 0.0918 (0.0994) loss_oracle 0.6291 (0.5774) acc 84.3750 (85.6424) kd_loss 1.2304 (1.2674) lr 7.0224e-05 eta 0:01:27
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,388
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [47/50] batch [20/181] time 0.082 (0.118) data 0.000 (0.013) loss 0.9301 (0.9779) ce_loss 0.4258 (0.4366) teacher_loss 0.2850 (0.3426) loss_zs_kd 0.0827 (0.1005) loss_oracle 0.6037 (0.5850) acc 81.2500 (83.5938) kd_loss 1.3059 (1.2637) lr 4.8943e-05 eta 0:01:23
epoch [47/50] batch [40/181] time 0.092 (0.107) data 0.000 (0.007) loss 0.8830 (0.9431) ce_loss 0.4976 (0.4165) teacher_loss 0.3394 (0.3259) loss_zs_kd 0.1324 (0.0983) loss_oracle 0.4775 (0.5680) acc 87.5000 (85.0000) kd_loss 1.2373 (1.2682) lr 4.8943e-05 eta 0:01:13
epoch [47/50] batch [60/181] time 0.113 (0.108) data 0.000 (0.004) loss 0.9174 (0.9350) ce_loss 0.3943 (0.4120) teacher_loss 0.3288 (0.3193) loss_zs_kd 0.0858 (0.0956) loss_oracle 0.5456 (0.5679) acc 84.3750 (85.1562) kd_loss 1.3079 (1.2715) lr 4.8943e-05 eta 0:01:11
epoch [47/50] batch [80/181] time 0.132 (0.109) data 0.000 (0.003) loss 0.7369 (0.9212) ce_loss 0.2258 (0.3946) teacher_loss 0.1574 (0.3070) loss_zs_kd 0.0898 (0.0957) loss_oracle 0.5346 (0.5664) acc 90.6250 (85.7031) kd_loss 1.2844 (1.2687) lr 4.8943e-05 eta 0:01:10
epoch [47/50] batch [100/181] time 0.087 (0.109) data 0.000 (0.003) loss 0.9253 (0.9268) ce_loss 0.3716 (0.4014) teacher_loss 0.2708 (0.3088) loss_zs_kd 0.1005 (0.0956) loss_oracle 0.6042 (0.5702) acc 87.5000 (85.4062) kd_loss 1.2960 (1.2671) lr 4.8943e-05 eta 0:01:08
epoch [47/50] batch [120/181] time 0.089 (0.109) data 0.000 (0.002) loss 0.7900 (0.9282) ce_loss 0.3198 (0.4027) teacher_loss 0.2416 (0.3088) loss_zs_kd 0.1192 (0.0969) loss_oracle 0.4888 (0.5710) acc 93.7500 (85.2083) kd_loss 1.2695 (1.2660) lr 4.8943e-05 eta 0:01:05
epoch [47/50] batch [140/181] time 0.145 (0.109) data 0.000 (0.002) loss 0.7055 (0.9210) ce_loss 0.2561 (0.3952) teacher_loss 0.1703 (0.3011) loss_zs_kd 0.0672 (0.0966) loss_oracle 0.5017 (0.5715) acc 90.6250 (85.5804) kd_loss 1.2523 (1.2637) lr 4.8943e-05 eta 0:01:03
epoch [47/50] batch [160/181] time 0.087 (0.109) data 0.000 (0.002) loss 0.6511 (0.9276) ce_loss 0.1440 (0.3971) teacher_loss 0.1254 (0.3049) loss_zs_kd 0.0584 (0.0974) loss_oracle 0.4965 (0.5741) acc 93.7500 (85.4102) kd_loss 1.2989 (1.2640) lr 4.8943e-05 eta 0:01:01
epoch [47/50] batch [180/181] time 0.074 (0.107) data 0.000 (0.002) loss 0.7200 (0.9212) ce_loss 0.1580 (0.3892) teacher_loss 0.0959 (0.2996) loss_zs_kd 0.0803 (0.0970) loss_oracle 0.5839 (0.5731) acc 96.8750 (85.7812) kd_loss 1.2419 (1.2640) lr 4.8943e-05 eta 0:00:58
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,389
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [48/50] batch [20/181] time 0.099 (0.127) data 0.000 (0.015) loss 0.6779 (0.9069) ce_loss 0.1526 (0.3901) teacher_loss 0.1128 (0.2855) loss_zs_kd 0.0594 (0.1068) loss_oracle 0.5355 (0.5681) acc 96.8750 (85.7812) kd_loss 1.2769 (1.2525) lr 3.1417e-05 eta 0:01:06
epoch [48/50] batch [40/181] time 0.129 (0.119) data 0.000 (0.008) loss 0.9086 (0.9078) ce_loss 0.5493 (0.3894) teacher_loss 0.4142 (0.2942) loss_zs_kd 0.1202 (0.1003) loss_oracle 0.4344 (0.5635) acc 78.1250 (85.7031) kd_loss 1.2371 (1.2607) lr 3.1417e-05 eta 0:01:00
epoch [48/50] batch [60/181] time 0.115 (0.115) data 0.000 (0.005) loss 0.8568 (0.9190) ce_loss 0.4043 (0.3912) teacher_loss 0.2590 (0.3014) loss_zs_kd 0.1460 (0.1018) loss_oracle 0.5248 (0.5668) acc 78.1250 (85.5208) kd_loss 1.2230 (1.2587) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [80/181] time 0.164 (0.119) data 0.000 (0.004) loss 1.0191 (0.9224) ce_loss 0.4785 (0.4010) teacher_loss 0.3771 (0.3081) loss_zs_kd 0.1163 (0.1013) loss_oracle 0.5838 (0.5637) acc 81.2500 (85.0781) kd_loss 1.2882 (1.2563) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [100/181] time 0.174 (0.119) data 0.000 (0.003) loss 0.8365 (0.9235) ce_loss 0.1461 (0.3983) teacher_loss 0.1242 (0.3059) loss_zs_kd 0.0562 (0.1004) loss_oracle 0.6842 (0.5675) acc 93.7500 (85.2812) kd_loss 1.2566 (1.2570) lr 3.1417e-05 eta 0:00:52
epoch [48/50] batch [120/181] time 0.197 (0.128) data 0.000 (0.003) loss 1.0172 (0.9269) ce_loss 0.4658 (0.3980) teacher_loss 0.3579 (0.3066) loss_zs_kd 0.0841 (0.0996) loss_oracle 0.6172 (0.5705) acc 81.2500 (85.1823) kd_loss 1.2210 (1.2582) lr 3.1417e-05 eta 0:00:54
epoch [48/50] batch [140/181] time 0.145 (0.126) data 0.000 (0.002) loss 1.0313 (0.9248) ce_loss 0.4766 (0.3964) teacher_loss 0.4493 (0.3059) loss_zs_kd 0.0897 (0.1001) loss_oracle 0.5372 (0.5689) acc 78.1250 (85.2679) kd_loss 1.2760 (1.2582) lr 3.1417e-05 eta 0:00:50
epoch [48/50] batch [160/181] time 0.111 (0.125) data 0.000 (0.002) loss 0.9422 (0.9270) ce_loss 0.5610 (0.3984) teacher_loss 0.4885 (0.3077) loss_zs_kd 0.0900 (0.1014) loss_oracle 0.4088 (0.5686) acc 81.2500 (85.0195) kd_loss 1.2581 (1.2584) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [180/181] time 0.133 (0.123) data 0.000 (0.002) loss 0.9520 (0.9266) ce_loss 0.5215 (0.3982) teacher_loss 0.4232 (0.3067) loss_zs_kd 0.0965 (0.1014) loss_oracle 0.4805 (0.5692) acc 81.2500 (85.0868) kd_loss 1.2909 (1.2592) lr 3.1417e-05 eta 0:00:44
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,389
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [49/50] batch [20/181] time 0.072 (0.134) data 0.000 (0.013) loss 0.8916 (0.8753) ce_loss 0.3552 (0.3724) teacher_loss 0.2962 (0.2717) loss_zs_kd 0.0977 (0.0860) loss_oracle 0.5465 (0.5606) acc 84.3750 (85.9375) kd_loss 1.2468 (1.2672) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [40/181] time 0.133 (0.123) data 0.000 (0.006) loss 1.0816 (0.9002) ce_loss 0.5708 (0.3779) teacher_loss 0.4607 (0.2832) loss_zs_kd 0.0949 (0.0940) loss_oracle 0.5734 (0.5700) acc 81.2500 (85.9375) kd_loss 1.2719 (1.2687) lr 1.7713e-05 eta 0:00:39
epoch [49/50] batch [60/181] time 0.121 (0.118) data 0.001 (0.004) loss 1.0955 (0.9177) ce_loss 0.5244 (0.3927) teacher_loss 0.4825 (0.3022) loss_zs_kd 0.1199 (0.0978) loss_oracle 0.5531 (0.5666) acc 78.1250 (85.3646) kd_loss 1.2682 (1.2667) lr 1.7713e-05 eta 0:00:35
epoch [49/50] batch [80/181] time 0.124 (0.116) data 0.000 (0.003) loss 0.8299 (0.9163) ce_loss 0.3289 (0.3945) teacher_loss 0.2219 (0.3005) loss_zs_kd 0.0895 (0.0992) loss_oracle 0.5633 (0.5663) acc 87.5000 (85.3516) kd_loss 1.2508 (1.2667) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [100/181] time 0.113 (0.115) data 0.000 (0.003) loss 1.0932 (0.9274) ce_loss 0.6216 (0.4074) teacher_loss 0.4101 (0.3109) loss_zs_kd 0.1362 (0.1008) loss_oracle 0.6150 (0.5661) acc 81.2500 (84.8125) kd_loss 1.2788 (1.2631) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [120/181] time 0.088 (0.115) data 0.000 (0.002) loss 0.7719 (0.9208) ce_loss 0.3169 (0.4012) teacher_loss 0.2225 (0.3047) loss_zs_kd 0.0653 (0.0986) loss_oracle 0.5167 (0.5668) acc 90.6250 (85.2604) kd_loss 1.2052 (1.2617) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [140/181] time 0.096 (0.114) data 0.000 (0.002) loss 1.0307 (0.9219) ce_loss 0.5547 (0.4012) teacher_loss 0.4327 (0.3041) loss_zs_kd 0.0991 (0.0985) loss_oracle 0.5484 (0.5686) acc 71.8750 (85.2902) kd_loss 1.2777 (1.2621) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [160/181] time 0.139 (0.113) data 0.000 (0.002) loss 1.0326 (0.9258) ce_loss 0.5254 (0.4031) teacher_loss 0.5075 (0.3080) loss_zs_kd 0.1145 (0.0987) loss_oracle 0.4678 (0.5685) acc 81.2500 (85.1758) kd_loss 1.3058 (1.2610) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [180/181] time 0.092 (0.111) data 0.000 (0.002) loss 0.8018 (0.9212) ce_loss 0.3794 (0.3975) teacher_loss 0.3010 (0.3043) loss_zs_kd 0.0937 (0.0988) loss_oracle 0.4540 (0.5675) acc 90.6250 (85.4167) kd_loss 1.2286 (1.2604) lr 1.7713e-05 eta 0:00:20
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,389
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [50/50] batch [20/181] time 0.140 (0.141) data 0.000 (0.015) loss 1.0505 (0.9036) ce_loss 0.5537 (0.3722) teacher_loss 0.3928 (0.2779) loss_zs_kd 0.1579 (0.0966) loss_oracle 0.5787 (0.5774) acc 71.8750 (87.0312) kd_loss 1.2611 (1.2731) lr 7.8853e-06 eta 0:00:22
epoch [50/50] batch [40/181] time 0.073 (0.125) data 0.000 (0.007) loss 0.9976 (0.9258) ce_loss 0.5142 (0.3847) teacher_loss 0.3903 (0.2981) loss_zs_kd 0.1491 (0.0959) loss_oracle 0.5328 (0.5797) acc 81.2500 (86.3281) kd_loss 1.2186 (1.2689) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [60/181] time 0.190 (0.137) data 0.001 (0.005) loss 0.9705 (0.9211) ce_loss 0.5273 (0.3866) teacher_loss 0.4055 (0.2999) loss_zs_kd 0.0720 (0.0959) loss_oracle 0.5290 (0.5733) acc 75.0000 (85.9375) kd_loss 1.2603 (1.2650) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [80/181] time 0.184 (0.141) data 0.000 (0.004) loss 0.8416 (0.9165) ce_loss 0.4258 (0.3954) teacher_loss 0.2848 (0.3005) loss_zs_kd 0.1019 (0.0993) loss_oracle 0.5059 (0.5663) acc 81.2500 (85.7422) kd_loss 1.2491 (1.2629) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [100/181] time 0.121 (0.141) data 0.000 (0.003) loss 0.9241 (0.9301) ce_loss 0.3682 (0.4026) teacher_loss 0.3006 (0.3086) loss_zs_kd 0.1257 (0.0990) loss_oracle 0.5606 (0.5720) acc 90.6250 (85.4688) kd_loss 1.2619 (1.2613) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [120/181] time 0.108 (0.137) data 0.000 (0.003) loss 0.5562 (0.9244) ce_loss 0.1150 (0.4005) teacher_loss 0.0692 (0.3030) loss_zs_kd 0.0864 (0.1002) loss_oracle 0.4438 (0.5714) acc 100.0000 (85.6250) kd_loss 1.3050 (1.2605) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [140/181] time 0.089 (0.135) data 0.000 (0.002) loss 0.7343 (0.9221) ce_loss 0.2048 (0.3979) teacher_loss 0.1718 (0.3019) loss_zs_kd 0.0891 (0.0997) loss_oracle 0.5180 (0.5704) acc 93.7500 (85.8929) kd_loss 1.2743 (1.2610) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [160/181] time 0.143 (0.133) data 0.000 (0.002) loss 0.8397 (0.9180) ce_loss 0.3872 (0.3947) teacher_loss 0.2656 (0.2994) loss_zs_kd 0.1157 (0.0987) loss_oracle 0.5163 (0.5692) acc 84.3750 (85.8203) kd_loss 1.2391 (1.2615) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [180/181] time 0.077 (0.130) data 0.000 (0.002) loss 1.0458 (0.9170) ce_loss 0.5342 (0.3938) teacher_loss 0.3684 (0.2968) loss_zs_kd 0.1241 (0.0988) loss_oracle 0.6154 (0.5708) acc 81.2500 (85.9028) kd_loss 1.2834 (1.2601) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,389
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.1%, epoch: 36 *******
******* Domain p best val test acc: 99.9%, epoch: 36 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:21:56

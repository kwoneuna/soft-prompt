Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------
Dataset    SPG_PACS
Source     ['cartoon', 'photo', 'sketch']
Target     ['art_painting']
# classes  7
# train_x  5,557
# val      2,385
# test     2,048
---------  ------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/173] time 0.087 (0.151) data 0.000 (0.015) loss 0.3349 (0.4618) ce_loss 0.3350 (0.4614) teacher_loss 0.3348 (0.4614) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0001 (0.0003) acc 90.6250 (83.7500) kd_loss 0.0003 (0.0013) lr 1.0000e-05 eta 0:21:42
epoch [1/50] batch [40/173] time 0.079 (0.134) data 0.000 (0.007) loss 0.5370 (0.4527) ce_loss 0.5361 (0.4523) teacher_loss 0.5366 (0.4524) loss_zs_kd 0.0007 (0.0002) loss_oracle 0.0001 (0.0002) acc 78.1250 (83.9844) kd_loss 0.0004 (0.0008) lr 1.0000e-05 eta 0:19:11
epoch [1/50] batch [60/173] time 0.087 (0.127) data 0.000 (0.005) loss 0.5217 (0.4551) ce_loss 0.5195 (0.4547) teacher_loss 0.5203 (0.4547) loss_zs_kd 0.0023 (0.0005) loss_oracle 0.0002 (0.0002) acc 78.1250 (83.5938) kd_loss 0.0007 (0.0008) lr 1.0000e-05 eta 0:18:10
epoch [1/50] batch [80/173] time 0.107 (0.127) data 0.000 (0.004) loss 0.5134 (0.4592) ce_loss 0.5107 (0.4584) teacher_loss 0.5114 (0.4585) loss_zs_kd 0.0033 (0.0009) loss_oracle 0.0004 (0.0002) acc 81.2500 (82.9297) kd_loss 0.0014 (0.0008) lr 1.0000e-05 eta 0:18:06
epoch [1/50] batch [100/173] time 0.092 (0.126) data 0.000 (0.003) loss 0.5961 (0.4504) ce_loss 0.5942 (0.4494) teacher_loss 0.5935 (0.4494) loss_zs_kd 0.0040 (0.0014) loss_oracle 0.0006 (0.0003) acc 75.0000 (83.4062) kd_loss 0.0024 (0.0010) lr 1.0000e-05 eta 0:17:59
epoch [1/50] batch [120/173] time 0.100 (0.123) data 0.000 (0.003) loss 0.4155 (0.4591) ce_loss 0.4116 (0.4577) teacher_loss 0.4110 (0.4577) loss_zs_kd 0.0070 (0.0021) loss_oracle 0.0009 (0.0003) acc 81.2500 (83.1510) kd_loss 0.0036 (0.0013) lr 1.0000e-05 eta 0:17:32
epoch [1/50] batch [140/173] time 0.141 (0.122) data 0.000 (0.002) loss 0.3329 (0.4598) ce_loss 0.3267 (0.4579) teacher_loss 0.3271 (0.4579) loss_zs_kd 0.0097 (0.0028) loss_oracle 0.0009 (0.0004) acc 84.3750 (83.1920) kd_loss 0.0033 (0.0016) lr 1.0000e-05 eta 0:17:14
epoch [1/50] batch [160/173] time 0.136 (0.121) data 0.000 (0.002) loss 0.3102 (0.4529) ce_loss 0.3057 (0.4507) teacher_loss 0.3059 (0.4507) loss_zs_kd 0.0068 (0.0035) loss_oracle 0.0009 (0.0005) acc 87.5000 (83.4766) kd_loss 0.0033 (0.0018) lr 1.0000e-05 eta 0:17:07
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,265
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 95.7%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 1,998
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.0%, epoch: 1 *******
******* Domain a best val test acc: 97.6%, epoch: 1 *******
******* Domain a best test acc:     97.6%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/ana
epoch [2/50] batch [20/173] time 0.127 (0.135) data 0.000 (0.018) loss 0.5024 (0.4753) ce_loss 0.4746 (0.4478) teacher_loss 0.4666 (0.4459) loss_zs_kd 0.0407 (0.0439) loss_oracle 0.0155 (0.0075) acc 87.5000 (84.2188) kd_loss 0.0374 (0.0181) lr 2.0000e-03 eta 0:19:05
epoch [2/50] batch [40/173] time 0.145 (0.128) data 0.000 (0.009) loss 0.5010 (0.4431) ce_loss 0.4646 (0.4090) teacher_loss 0.4314 (0.4040) loss_zs_kd 0.0382 (0.0426) loss_oracle 0.0505 (0.0179) acc 84.3750 (85.6250) kd_loss 0.1427 (0.0453) lr 2.0000e-03 eta 0:18:01
epoch [2/50] batch [60/173] time 0.113 (0.129) data 0.000 (0.006) loss 0.6371 (0.4695) ce_loss 0.4675 (0.4120) teacher_loss 0.3875 (0.3930) loss_zs_kd 0.0599 (0.0435) loss_oracle 0.2196 (0.0548) acc 71.8750 (85.3125) kd_loss 0.3232 (0.1051) lr 2.0000e-03 eta 0:18:08
epoch [2/50] batch [80/173] time 0.145 (0.128) data 0.000 (0.005) loss 0.5610 (0.4891) ce_loss 0.3589 (0.3963) teacher_loss 0.2379 (0.3645) loss_zs_kd 0.0459 (0.0455) loss_oracle 0.3002 (0.1019) acc 84.3750 (85.8984) kd_loss 0.4667 (0.1716) lr 2.0000e-03 eta 0:17:53
epoch [2/50] batch [100/173] time 0.144 (0.123) data 0.000 (0.004) loss 0.4272 (0.5116) ce_loss 0.2416 (0.3985) teacher_loss 0.1615 (0.3529) loss_zs_kd 0.0531 (0.0484) loss_oracle 0.2391 (0.1345) acc 90.6250 (85.7812) kd_loss 0.4229 (0.2244) lr 2.0000e-03 eta 0:17:09
epoch [2/50] batch [120/173] time 0.081 (0.129) data 0.000 (0.003) loss 0.5587 (0.5300) ce_loss 0.2708 (0.3981) teacher_loss 0.1485 (0.3388) loss_zs_kd 0.0458 (0.0526) loss_oracle 0.3874 (0.1650) acc 90.6250 (85.8854) kd_loss 0.7523 (0.2734) lr 2.0000e-03 eta 0:18:01
epoch [2/50] batch [140/173] time 0.190 (0.133) data 0.000 (0.003) loss 0.4662 (0.5433) ce_loss 0.1796 (0.3949) teacher_loss 0.1162 (0.3275) loss_zs_kd 0.0592 (0.0559) loss_oracle 0.3205 (0.1879) acc 93.7500 (85.8929) kd_loss 0.5412 (0.3130) lr 2.0000e-03 eta 0:18:32
epoch [2/50] batch [160/173] time 0.131 (0.133) data 0.000 (0.002) loss 0.6729 (0.5705) ce_loss 0.4094 (0.4061) teacher_loss 0.2378 (0.3276) loss_zs_kd 0.0950 (0.0598) loss_oracle 0.3875 (0.2129) acc 84.3750 (85.5078) kd_loss 0.6788 (0.3572) lr 2.0000e-03 eta 0:18:24
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,276
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.0%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,004
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     97.9%, epoch: 2 *******
epoch [3/50] batch [20/173] time 0.106 (0.147) data 0.000 (0.014) loss 0.6737 (0.6980) ce_loss 0.2908 (0.3542) teacher_loss 0.1396 (0.2067) loss_zs_kd 0.0879 (0.0773) loss_oracle 0.4901 (0.4527) acc 87.5000 (86.5625) kd_loss 0.8245 (0.7755) lr 1.9980e-03 eta 0:20:16
epoch [3/50] batch [40/173] time 0.115 (0.133) data 0.000 (0.007) loss 0.9353 (0.7497) ce_loss 0.5542 (0.3955) teacher_loss 0.4622 (0.2452) loss_zs_kd 0.0958 (0.0818) loss_oracle 0.4251 (0.4637) acc 81.2500 (86.0156) kd_loss 0.8243 (0.7891) lr 1.9980e-03 eta 0:18:15
epoch [3/50] batch [60/173] time 0.136 (0.129) data 0.000 (0.005) loss 0.7809 (0.7635) ce_loss 0.4219 (0.4018) teacher_loss 0.2180 (0.2539) loss_zs_kd 0.0957 (0.0866) loss_oracle 0.5150 (0.4663) acc 90.6250 (86.0938) kd_loss 0.8990 (0.8038) lr 1.9980e-03 eta 0:17:43
epoch [3/50] batch [80/173] time 0.081 (0.127) data 0.000 (0.004) loss 0.9435 (0.7887) ce_loss 0.5708 (0.4156) teacher_loss 0.3231 (0.2595) loss_zs_kd 0.0940 (0.0920) loss_oracle 0.5734 (0.4833) acc 81.2500 (85.5859) kd_loss 0.9674 (0.8240) lr 1.9980e-03 eta 0:17:22
epoch [3/50] batch [100/173] time 0.105 (0.124) data 0.000 (0.003) loss 0.5847 (0.7962) ce_loss 0.2462 (0.4157) teacher_loss 0.1076 (0.2543) loss_zs_kd 0.0640 (0.0940) loss_oracle 0.4451 (0.4948) acc 93.7500 (85.5938) kd_loss 0.8188 (0.8416) lr 1.9980e-03 eta 0:16:59
epoch [3/50] batch [120/173] time 0.089 (0.122) data 0.000 (0.003) loss 0.7031 (0.7932) ce_loss 0.3154 (0.4085) teacher_loss 0.1292 (0.2432) loss_zs_kd 0.1344 (0.0981) loss_oracle 0.5067 (0.5009) acc 84.3750 (85.5990) kd_loss 0.9210 (0.8533) lr 1.9980e-03 eta 0:16:35
epoch [3/50] batch [140/173] time 0.143 (0.123) data 0.001 (0.002) loss 0.7890 (0.7886) ce_loss 0.4990 (0.4088) teacher_loss 0.2024 (0.2413) loss_zs_kd 0.1126 (0.0990) loss_oracle 0.5303 (0.4978) acc 81.2500 (85.4911) kd_loss 0.9285 (0.8556) lr 1.9980e-03 eta 0:16:44
epoch [3/50] batch [160/173] time 0.144 (0.124) data 0.000 (0.002) loss 0.7568 (0.7888) ce_loss 0.3145 (0.4117) teacher_loss 0.1751 (0.2421) loss_zs_kd 0.1423 (0.1011) loss_oracle 0.5105 (0.4961) acc 87.5000 (85.4688) kd_loss 0.8715 (0.8572) lr 1.9980e-03 eta 0:16:46
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,269
* accuracy: 95.1%
* error: 4.9%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.9%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     97.9%, epoch: 3 *******
epoch [4/50] batch [20/173] time 0.134 (0.139) data 0.000 (0.013) loss 0.7170 (0.7899) ce_loss 0.2944 (0.3994) teacher_loss 0.1169 (0.1897) loss_zs_kd 0.0983 (0.1222) loss_oracle 0.5510 (0.5390) acc 87.5000 (84.2188) kd_loss 0.9616 (0.9302) lr 1.9921e-03 eta 0:18:48
epoch [4/50] batch [40/173] time 0.101 (0.126) data 0.000 (0.007) loss 0.6726 (0.7974) ce_loss 0.2169 (0.4060) teacher_loss 0.1022 (0.1954) loss_zs_kd 0.1178 (0.1278) loss_oracle 0.5115 (0.5381) acc 93.7500 (84.6094) kd_loss 0.9371 (0.9254) lr 1.9921e-03 eta 0:16:56
epoch [4/50] batch [60/173] time 0.187 (0.126) data 0.001 (0.005) loss 0.7944 (0.7720) ce_loss 0.3621 (0.3860) teacher_loss 0.1653 (0.1971) loss_zs_kd 0.1412 (0.1165) loss_oracle 0.5585 (0.5166) acc 90.6250 (85.7292) kd_loss 0.9351 (0.9181) lr 1.9921e-03 eta 0:17:00
epoch [4/50] batch [80/173] time 0.174 (0.131) data 0.000 (0.003) loss 0.8071 (0.7648) ce_loss 0.6050 (0.3832) teacher_loss 0.2589 (0.1943) loss_zs_kd 0.1247 (0.1138) loss_oracle 0.4859 (0.5136) acc 68.7500 (85.8984) kd_loss 0.9782 (0.9188) lr 1.9921e-03 eta 0:17:38
epoch [4/50] batch [100/173] time 0.147 (0.142) data 0.000 (0.003) loss 0.7529 (0.7652) ce_loss 0.3560 (0.3842) teacher_loss 0.1830 (0.1928) loss_zs_kd 0.1155 (0.1167) loss_oracle 0.5121 (0.5141) acc 87.5000 (85.8750) kd_loss 0.9455 (0.9229) lr 1.9921e-03 eta 0:18:57
epoch [4/50] batch [120/173] time 0.144 (0.135) data 0.001 (0.002) loss 0.7320 (0.7569) ce_loss 0.4521 (0.3791) teacher_loss 0.2808 (0.1956) loss_zs_kd 0.0755 (0.1142) loss_oracle 0.4135 (0.5043) acc 84.3750 (86.0417) kd_loss 1.0071 (0.9255) lr 1.9921e-03 eta 0:18:03
epoch [4/50] batch [140/173] time 0.146 (0.133) data 0.000 (0.002) loss 0.6809 (0.7557) ce_loss 0.2505 (0.3818) teacher_loss 0.2178 (0.2068) loss_zs_kd 0.0722 (0.1134) loss_oracle 0.4270 (0.4922) acc 90.6250 (86.0491) kd_loss 1.0152 (0.9287) lr 1.9921e-03 eta 0:17:41
epoch [4/50] batch [160/173] time 0.134 (0.131) data 0.000 (0.002) loss 0.7308 (0.7532) ce_loss 0.3738 (0.3804) teacher_loss 0.2069 (0.2122) loss_zs_kd 0.1118 (0.1109) loss_oracle 0.4680 (0.4856) acc 87.5000 (86.1719) kd_loss 0.9841 (0.9335) lr 1.9921e-03 eta 0:17:22
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,276
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.9%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     97.9%, epoch: 4 *******
epoch [5/50] batch [20/173] time 0.118 (0.132) data 0.000 (0.010) loss 0.7264 (0.7286) ce_loss 0.3445 (0.4054) teacher_loss 0.2588 (0.2884) loss_zs_kd 0.0830 (0.0927) loss_oracle 0.4261 (0.3939) acc 84.3750 (84.0625) kd_loss 0.9552 (0.9569) lr 1.9823e-03 eta 0:17:25
epoch [5/50] batch [40/173] time 0.134 (0.125) data 0.000 (0.005) loss 0.8974 (0.7356) ce_loss 0.4426 (0.4064) teacher_loss 0.3061 (0.2667) loss_zs_kd 0.1702 (0.1018) loss_oracle 0.5061 (0.4180) acc 84.3750 (84.5312) kd_loss 0.9691 (0.9544) lr 1.9823e-03 eta 0:16:32
epoch [5/50] batch [60/173] time 0.119 (0.121) data 0.000 (0.004) loss 0.8302 (0.7541) ce_loss 0.4045 (0.4195) teacher_loss 0.3213 (0.2674) loss_zs_kd 0.1139 (0.1053) loss_oracle 0.4519 (0.4341) acc 90.6250 (84.0104) kd_loss 1.0026 (0.9652) lr 1.9823e-03 eta 0:15:55
epoch [5/50] batch [80/173] time 0.081 (0.118) data 0.000 (0.003) loss 0.7142 (0.7456) ce_loss 0.4177 (0.4128) teacher_loss 0.1994 (0.2593) loss_zs_kd 0.1389 (0.1043) loss_oracle 0.4453 (0.4341) acc 93.7500 (84.5703) kd_loss 0.9981 (0.9646) lr 1.9823e-03 eta 0:15:25
epoch [5/50] batch [100/173] time 0.115 (0.116) data 0.000 (0.002) loss 0.6959 (0.7325) ce_loss 0.3447 (0.4101) teacher_loss 0.2658 (0.2602) loss_zs_kd 0.0941 (0.1010) loss_oracle 0.3830 (0.4218) acc 90.6250 (84.6250) kd_loss 0.9082 (0.9605) lr 1.9823e-03 eta 0:15:11
epoch [5/50] batch [120/173] time 0.145 (0.115) data 0.000 (0.002) loss 0.7039 (0.7321) ce_loss 0.2839 (0.4047) teacher_loss 0.1814 (0.2544) loss_zs_kd 0.0536 (0.1026) loss_oracle 0.4957 (0.4263) acc 90.6250 (84.7656) kd_loss 0.9453 (0.9592) lr 1.9823e-03 eta 0:15:03
epoch [5/50] batch [140/173] time 0.093 (0.115) data 0.000 (0.002) loss 0.6814 (0.7336) ce_loss 0.2551 (0.4069) teacher_loss 0.2005 (0.2554) loss_zs_kd 0.0877 (0.0997) loss_oracle 0.4371 (0.4284) acc 84.3750 (84.9330) kd_loss 0.9651 (0.9542) lr 1.9823e-03 eta 0:14:57
epoch [5/50] batch [160/173] time 0.129 (0.114) data 0.000 (0.001) loss 0.6045 (0.7369) ce_loss 0.1694 (0.4045) teacher_loss 0.1039 (0.2524) loss_zs_kd 0.0656 (0.0999) loss_oracle 0.4678 (0.4346) acc 93.7500 (85.0000) kd_loss 0.9352 (0.9516) lr 1.9823e-03 eta 0:14:51
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,271
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     97.9%, epoch: 4 *******
epoch [6/50] batch [20/173] time 0.080 (0.119) data 0.000 (0.012) loss 0.7490 (0.8699) ce_loss 0.2996 (0.4283) teacher_loss 0.2290 (0.3021) loss_zs_kd 0.0671 (0.0970) loss_oracle 0.4864 (0.5193) acc 87.5000 (83.5938) kd_loss 0.9129 (0.9162) lr 1.9686e-03 eta 0:15:22
epoch [6/50] batch [40/173] time 0.078 (0.107) data 0.000 (0.006) loss 0.8493 (0.8509) ce_loss 0.5146 (0.4146) teacher_loss 0.3647 (0.2997) loss_zs_kd 0.0729 (0.0871) loss_oracle 0.4481 (0.5077) acc 87.5000 (84.7656) kd_loss 0.8497 (0.9184) lr 1.9686e-03 eta 0:13:51
epoch [6/50] batch [60/173] time 0.075 (0.128) data 0.001 (0.004) loss 1.0014 (0.8636) ce_loss 0.4998 (0.4169) teacher_loss 0.4290 (0.3161) loss_zs_kd 0.0511 (0.0768) loss_oracle 0.5469 (0.5092) acc 84.3750 (84.6354) kd_loss 0.9763 (0.9291) lr 1.9686e-03 eta 0:16:26
epoch [6/50] batch [80/173] time 0.187 (0.128) data 0.000 (0.003) loss 0.8257 (0.8905) ce_loss 0.2922 (0.4135) teacher_loss 0.2250 (0.3205) loss_zs_kd 0.0726 (0.0708) loss_oracle 0.5644 (0.5346) acc 90.6250 (84.8438) kd_loss 0.9512 (0.9360) lr 1.9686e-03 eta 0:16:27
epoch [6/50] batch [100/173] time 0.133 (0.132) data 0.000 (0.003) loss 1.0176 (0.9054) ce_loss 0.4119 (0.4105) teacher_loss 0.3005 (0.3225) loss_zs_kd 0.0557 (0.0673) loss_oracle 0.6893 (0.5492) acc 84.3750 (85.0312) kd_loss 0.9674 (0.9358) lr 1.9686e-03 eta 0:16:53
epoch [6/50] batch [120/173] time 0.105 (0.130) data 0.000 (0.002) loss 1.2032 (0.9153) ce_loss 0.6865 (0.4068) teacher_loss 0.4780 (0.3205) loss_zs_kd 0.0711 (0.0640) loss_oracle 0.6897 (0.5628) acc 75.0000 (85.2865) kd_loss 1.0116 (0.9348) lr 1.9686e-03 eta 0:16:34
epoch [6/50] batch [140/173] time 0.100 (0.128) data 0.000 (0.002) loss 0.9543 (0.9335) ce_loss 0.3359 (0.4070) teacher_loss 0.2556 (0.3251) loss_zs_kd 0.0352 (0.0621) loss_oracle 0.6811 (0.5774) acc 90.6250 (85.3348) kd_loss 0.9049 (0.9326) lr 1.9686e-03 eta 0:16:16
epoch [6/50] batch [160/173] time 0.102 (0.127) data 0.000 (0.002) loss 0.8665 (0.9306) ce_loss 0.2991 (0.4020) teacher_loss 0.2812 (0.3222) loss_zs_kd 0.0495 (0.0609) loss_oracle 0.5605 (0.5780) acc 90.6250 (85.4102) kd_loss 0.8962 (0.9270) lr 1.9686e-03 eta 0:16:08
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,268
* accuracy: 95.1%
* error: 4.9%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.9%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     97.9%, epoch: 4 *******
epoch [7/50] batch [20/173] time 0.144 (0.139) data 0.000 (0.013) loss 0.9763 (0.9343) ce_loss 0.5737 (0.4470) teacher_loss 0.5354 (0.3827) loss_zs_kd 0.0335 (0.0437) loss_oracle 0.4242 (0.5298) acc 84.3750 (83.1250) kd_loss 0.8588 (0.8962) lr 1.9511e-03 eta 0:17:36
epoch [7/50] batch [40/173] time 0.130 (0.130) data 0.000 (0.006) loss 1.0261 (0.8574) ce_loss 0.6069 (0.3981) teacher_loss 0.5083 (0.3394) loss_zs_kd 0.0598 (0.0438) loss_oracle 0.4879 (0.4961) acc 75.0000 (84.9219) kd_loss 0.8711 (0.8863) lr 1.9511e-03 eta 0:16:26
epoch [7/50] batch [60/173] time 0.138 (0.124) data 0.001 (0.004) loss 0.9116 (0.8615) ce_loss 0.4607 (0.3879) teacher_loss 0.3423 (0.3301) loss_zs_kd 0.0469 (0.0431) loss_oracle 0.5458 (0.5098) acc 87.5000 (85.8333) kd_loss 0.8663 (0.8767) lr 1.9511e-03 eta 0:15:36
epoch [7/50] batch [80/173] time 0.082 (0.121) data 0.000 (0.003) loss 0.8965 (0.8662) ce_loss 0.4146 (0.3886) teacher_loss 0.2882 (0.3279) loss_zs_kd 0.0462 (0.0449) loss_oracle 0.5852 (0.5158) acc 84.3750 (85.8984) kd_loss 0.8753 (0.8753) lr 1.9511e-03 eta 0:15:10
epoch [7/50] batch [100/173] time 0.085 (0.119) data 0.000 (0.003) loss 0.7333 (0.8546) ce_loss 0.2722 (0.3791) teacher_loss 0.2151 (0.3195) loss_zs_kd 0.0419 (0.0450) loss_oracle 0.4973 (0.5126) acc 90.6250 (86.1562) kd_loss 0.8549 (0.8685) lr 1.9511e-03 eta 0:14:52
epoch [7/50] batch [120/173] time 0.117 (0.118) data 0.000 (0.002) loss 0.7135 (0.8330) ce_loss 0.2886 (0.3719) teacher_loss 0.2922 (0.3133) loss_zs_kd 0.0577 (0.0474) loss_oracle 0.3925 (0.4960) acc 90.6250 (86.4583) kd_loss 0.8242 (0.8580) lr 1.9511e-03 eta 0:14:46
epoch [7/50] batch [140/173] time 0.115 (0.118) data 0.000 (0.002) loss 0.7671 (0.8191) ce_loss 0.3701 (0.3708) teacher_loss 0.3569 (0.3090) loss_zs_kd 0.0657 (0.0488) loss_oracle 0.3773 (0.4857) acc 90.6250 (86.5848) kd_loss 0.8480 (0.8562) lr 1.9511e-03 eta 0:14:39
epoch [7/50] batch [160/173] time 0.093 (0.117) data 0.000 (0.002) loss 0.7725 (0.8116) ce_loss 0.4819 (0.3742) teacher_loss 0.3564 (0.3100) loss_zs_kd 0.0572 (0.0507) loss_oracle 0.3875 (0.4763) acc 84.3750 (86.4844) kd_loss 0.8486 (0.8546) lr 1.9511e-03 eta 0:14:32
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,274
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [8/50] batch [20/173] time 0.068 (0.119) data 0.000 (0.014) loss 0.6377 (0.7518) ce_loss 0.2529 (0.3606) teacher_loss 0.2138 (0.2912) loss_zs_kd 0.0419 (0.0565) loss_oracle 0.4029 (0.4324) acc 87.5000 (86.0938) kd_loss 0.7820 (0.8244) lr 1.9298e-03 eta 0:14:39
epoch [8/50] batch [40/173] time 0.067 (0.143) data 0.000 (0.007) loss 0.8987 (0.7905) ce_loss 0.4248 (0.3723) teacher_loss 0.3120 (0.2995) loss_zs_kd 0.0472 (0.0541) loss_oracle 0.5631 (0.4639) acc 84.3750 (85.7812) kd_loss 0.9146 (0.8359) lr 1.9298e-03 eta 0:17:39
epoch [8/50] batch [60/173] time 0.188 (0.144) data 0.001 (0.005) loss 0.7603 (0.8060) ce_loss 0.3674 (0.3827) teacher_loss 0.3269 (0.3101) loss_zs_kd 0.0592 (0.0553) loss_oracle 0.4038 (0.4683) acc 87.5000 (85.4167) kd_loss 0.8164 (0.8408) lr 1.9298e-03 eta 0:17:39
epoch [8/50] batch [80/173] time 0.143 (0.143) data 0.000 (0.004) loss 0.8317 (0.7891) ce_loss 0.4236 (0.3730) teacher_loss 0.3659 (0.2997) loss_zs_kd 0.0640 (0.0548) loss_oracle 0.4337 (0.4620) acc 81.2500 (85.9375) kd_loss 0.8099 (0.8362) lr 1.9298e-03 eta 0:17:31
epoch [8/50] batch [100/173] time 0.110 (0.139) data 0.000 (0.003) loss 0.7665 (0.7972) ce_loss 0.3022 (0.3752) teacher_loss 0.2403 (0.2976) loss_zs_kd 0.0735 (0.0572) loss_oracle 0.4894 (0.4710) acc 87.5000 (85.8750) kd_loss 0.8077 (0.8357) lr 1.9298e-03 eta 0:16:58
epoch [8/50] batch [120/173] time 0.139 (0.136) data 0.000 (0.003) loss 0.9266 (0.7935) ce_loss 0.5513 (0.3737) teacher_loss 0.4619 (0.2958) loss_zs_kd 0.0603 (0.0577) loss_oracle 0.4345 (0.4688) acc 78.1250 (85.9896) kd_loss 0.8586 (0.8389) lr 1.9298e-03 eta 0:16:36
epoch [8/50] batch [140/173] time 0.091 (0.134) data 0.000 (0.002) loss 0.7021 (0.7880) ce_loss 0.3083 (0.3753) teacher_loss 0.2134 (0.2959) loss_zs_kd 0.0648 (0.0586) loss_oracle 0.4563 (0.4628) acc 87.5000 (85.8929) kd_loss 0.8166 (0.8422) lr 1.9298e-03 eta 0:16:17
epoch [8/50] batch [160/173] time 0.127 (0.132) data 0.000 (0.002) loss 0.8387 (0.7912) ce_loss 0.4514 (0.3774) teacher_loss 0.3452 (0.2955) loss_zs_kd 0.0961 (0.0600) loss_oracle 0.4455 (0.4658) acc 81.2500 (85.9180) kd_loss 0.8578 (0.8483) lr 1.9298e-03 eta 0:16:02
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,275
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [9/50] batch [20/173] time 0.086 (0.137) data 0.000 (0.015) loss 1.1328 (0.9086) ce_loss 0.5557 (0.3620) teacher_loss 0.4591 (0.2862) loss_zs_kd 0.1228 (0.0812) loss_oracle 0.6122 (0.5818) acc 81.2500 (86.0938) kd_loss 1.0446 (0.9702) lr 1.9048e-03 eta 0:16:29
epoch [9/50] batch [40/173] time 0.087 (0.130) data 0.000 (0.008) loss 1.2236 (0.9982) ce_loss 0.4414 (0.3600) teacher_loss 0.4248 (0.2872) loss_zs_kd 0.1095 (0.0912) loss_oracle 0.7441 (0.6654) acc 84.3750 (86.4062) kd_loss 1.0980 (1.0040) lr 1.9048e-03 eta 0:15:39
epoch [9/50] batch [60/173] time 0.148 (0.129) data 0.000 (0.005) loss 1.1112 (1.0693) ce_loss 0.3362 (0.3766) teacher_loss 0.2724 (0.3097) loss_zs_kd 0.0661 (0.0864) loss_oracle 0.8057 (0.7164) acc 93.7500 (85.9896) kd_loss 1.1032 (1.0281) lr 1.9048e-03 eta 0:15:33
epoch [9/50] batch [80/173] time 0.126 (0.128) data 0.000 (0.004) loss 1.0806 (1.0744) ce_loss 0.3713 (0.3696) teacher_loss 0.2544 (0.3028) loss_zs_kd 0.0733 (0.0813) loss_oracle 0.7896 (0.7310) acc 84.3750 (86.1328) kd_loss 1.1017 (1.0377) lr 1.9048e-03 eta 0:15:16
epoch [9/50] batch [100/173] time 0.147 (0.128) data 0.000 (0.003) loss 1.1508 (1.0719) ce_loss 0.3960 (0.3656) teacher_loss 0.3538 (0.2965) loss_zs_kd 0.0790 (0.0792) loss_oracle 0.7575 (0.7358) acc 84.3750 (86.4375) kd_loss 1.0590 (1.0462) lr 1.9048e-03 eta 0:15:15
epoch [9/50] batch [120/173] time 0.143 (0.129) data 0.000 (0.003) loss 0.9887 (1.0651) ce_loss 0.3811 (0.3736) teacher_loss 0.2657 (0.2971) loss_zs_kd 0.0480 (0.0793) loss_oracle 0.6990 (0.7284) acc 87.5000 (86.1458) kd_loss 1.0831 (1.0522) lr 1.9048e-03 eta 0:15:18
epoch [9/50] batch [140/173] time 0.144 (0.128) data 0.000 (0.002) loss 0.8765 (1.0549) ce_loss 0.3918 (0.3807) teacher_loss 0.3271 (0.3013) loss_zs_kd 0.0857 (0.0802) loss_oracle 0.5066 (0.7134) acc 81.2500 (85.8482) kd_loss 1.0511 (1.0535) lr 1.9048e-03 eta 0:15:15
epoch [9/50] batch [160/173] time 0.144 (0.130) data 0.000 (0.002) loss 0.9849 (1.0373) ce_loss 0.4800 (0.3832) teacher_loss 0.2684 (0.2990) loss_zs_kd 0.1227 (0.0812) loss_oracle 0.6551 (0.6977) acc 78.1250 (85.6055) kd_loss 1.0905 (1.0544) lr 1.9048e-03 eta 0:15:21
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,276
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [10/50] batch [20/173] time 0.077 (0.163) data 0.000 (0.012) loss 0.8154 (0.8743) ce_loss 0.2935 (0.3719) teacher_loss 0.1765 (0.2857) loss_zs_kd 0.0803 (0.0650) loss_oracle 0.5987 (0.5561) acc 87.5000 (85.7812) kd_loss 1.0147 (1.0571) lr 1.8763e-03 eta 0:19:15
epoch [10/50] batch [40/173] time 0.142 (0.137) data 0.000 (0.006) loss 0.8095 (0.9003) ce_loss 0.2349 (0.3800) teacher_loss 0.1411 (0.2789) loss_zs_kd 0.0681 (0.0753) loss_oracle 0.6343 (0.5838) acc 93.7500 (85.7812) kd_loss 1.1690 (1.0710) lr 1.8763e-03 eta 0:16:03
epoch [10/50] batch [60/173] time 0.081 (0.126) data 0.000 (0.004) loss 1.0065 (0.9116) ce_loss 0.2754 (0.3758) teacher_loss 0.1424 (0.2682) loss_zs_kd 0.0835 (0.0770) loss_oracle 0.8223 (0.6049) acc 90.6250 (85.9375) kd_loss 1.1437 (1.0793) lr 1.8763e-03 eta 0:14:48
epoch [10/50] batch [80/173] time 0.085 (0.122) data 0.000 (0.003) loss 1.1044 (0.9201) ce_loss 0.5894 (0.3779) teacher_loss 0.4917 (0.2683) loss_zs_kd 0.0912 (0.0828) loss_oracle 0.5671 (0.6104) acc 78.1250 (85.8984) kd_loss 1.0777 (1.0848) lr 1.8763e-03 eta 0:14:18
epoch [10/50] batch [100/173] time 0.111 (0.120) data 0.000 (0.003) loss 0.9420 (0.9158) ce_loss 0.4900 (0.3816) teacher_loss 0.2624 (0.2705) loss_zs_kd 0.1055 (0.0795) loss_oracle 0.6269 (0.6055) acc 84.3750 (85.8750) kd_loss 1.1142 (1.0833) lr 1.8763e-03 eta 0:13:56
epoch [10/50] batch [120/173] time 0.121 (0.117) data 0.000 (0.002) loss 1.1062 (0.9236) ce_loss 0.5854 (0.3874) teacher_loss 0.3593 (0.2688) loss_zs_kd 0.1583 (0.0835) loss_oracle 0.6677 (0.6130) acc 71.8750 (85.6510) kd_loss 1.0569 (1.0813) lr 1.8763e-03 eta 0:13:38
epoch [10/50] batch [140/173] time 0.094 (0.116) data 0.000 (0.002) loss 0.9678 (0.9278) ce_loss 0.4280 (0.3927) teacher_loss 0.3103 (0.2728) loss_zs_kd 0.0773 (0.0845) loss_oracle 0.6188 (0.6127) acc 84.3750 (85.2679) kd_loss 1.0715 (1.0779) lr 1.8763e-03 eta 0:13:26
epoch [10/50] batch [160/173] time 0.078 (0.115) data 0.000 (0.002) loss 0.9866 (0.9328) ce_loss 0.3213 (0.3989) teacher_loss 0.3388 (0.2745) loss_zs_kd 0.1144 (0.0866) loss_oracle 0.5906 (0.6149) acc 90.6250 (85.0977) kd_loss 1.0853 (1.0745) lr 1.8763e-03 eta 0:13:18
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,268
* accuracy: 95.1%
* error: 4.9%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [11/50] batch [20/173] time 0.079 (0.123) data 0.000 (0.014) loss 0.9311 (0.9672) ce_loss 0.3398 (0.4175) teacher_loss 0.2022 (0.2572) loss_zs_kd 0.1179 (0.0918) loss_oracle 0.6700 (0.6642) acc 90.6250 (84.8438) kd_loss 1.0766 (1.0736) lr 1.8443e-03 eta 0:14:10
epoch [11/50] batch [40/173] time 0.107 (0.117) data 0.000 (0.007) loss 0.8515 (0.9426) ce_loss 0.3477 (0.3953) teacher_loss 0.1680 (0.2608) loss_zs_kd 0.0596 (0.0870) loss_oracle 0.6537 (0.6384) acc 84.3750 (85.6250) kd_loss 1.0696 (1.0581) lr 1.8443e-03 eta 0:13:27
epoch [11/50] batch [60/173] time 0.096 (0.116) data 0.000 (0.005) loss 0.7304 (0.9075) ce_loss 0.3384 (0.3746) teacher_loss 0.2385 (0.2521) loss_zs_kd 0.0712 (0.0823) loss_oracle 0.4563 (0.6142) acc 84.3750 (86.5625) kd_loss 0.9406 (1.0510) lr 1.8443e-03 eta 0:13:17
epoch [11/50] batch [80/173] time 0.145 (0.117) data 0.000 (0.004) loss 0.7086 (0.8872) ce_loss 0.2377 (0.3819) teacher_loss 0.1843 (0.2572) loss_zs_kd 0.0727 (0.0822) loss_oracle 0.4880 (0.5889) acc 90.6250 (86.2109) kd_loss 0.9991 (1.0411) lr 1.8443e-03 eta 0:13:22
epoch [11/50] batch [100/173] time 0.131 (0.117) data 0.000 (0.003) loss 0.6796 (0.8723) ce_loss 0.1934 (0.3749) teacher_loss 0.1265 (0.2583) loss_zs_kd 0.0423 (0.0793) loss_oracle 0.5320 (0.5744) acc 93.7500 (86.4375) kd_loss 0.9840 (1.0333) lr 1.8443e-03 eta 0:13:19
epoch [11/50] batch [120/173] time 0.097 (0.118) data 0.000 (0.003) loss 0.8104 (0.8737) ce_loss 0.2448 (0.3797) teacher_loss 0.2168 (0.2635) loss_zs_kd 0.0808 (0.0792) loss_oracle 0.5532 (0.5706) acc 93.7500 (86.2500) kd_loss 1.0115 (1.0278) lr 1.8443e-03 eta 0:13:20
epoch [11/50] batch [140/173] time 0.134 (0.117) data 0.000 (0.002) loss 0.9640 (0.8757) ce_loss 0.3054 (0.3817) teacher_loss 0.2966 (0.2661) loss_zs_kd 0.0701 (0.0783) loss_oracle 0.6324 (0.5704) acc 81.2500 (86.2500) kd_loss 0.9726 (1.0241) lr 1.8443e-03 eta 0:13:12
epoch [11/50] batch [160/173] time 0.074 (0.116) data 0.000 (0.002) loss 0.7337 (0.8777) ce_loss 0.1113 (0.3773) teacher_loss 0.0728 (0.2622) loss_zs_kd 0.0587 (0.0788) loss_oracle 0.6316 (0.5761) acc 96.8750 (86.4258) kd_loss 1.0347 (1.0226) lr 1.8443e-03 eta 0:13:00
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,273
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,001
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.6%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [12/50] batch [20/173] time 0.081 (0.125) data 0.000 (0.015) loss 1.0737 (0.9513) ce_loss 0.4395 (0.3926) teacher_loss 0.3155 (0.2664) loss_zs_kd 0.0867 (0.0775) loss_oracle 0.7149 (0.6461) acc 78.1250 (85.6250) kd_loss 1.0763 (1.0415) lr 1.8090e-03 eta 0:13:59
epoch [12/50] batch [40/173] time 0.087 (0.116) data 0.000 (0.008) loss 1.3261 (0.9863) ce_loss 0.8354 (0.3990) teacher_loss 0.6526 (0.2802) loss_zs_kd 0.1041 (0.0786) loss_oracle 0.6214 (0.6667) acc 75.0000 (85.1562) kd_loss 1.0249 (1.0436) lr 1.8090e-03 eta 0:12:56
epoch [12/50] batch [60/173] time 0.124 (0.110) data 0.000 (0.005) loss 1.0025 (0.9994) ce_loss 0.4446 (0.3986) teacher_loss 0.3325 (0.2875) loss_zs_kd 0.0878 (0.0760) loss_oracle 0.6261 (0.6739) acc 84.3750 (85.0000) kd_loss 1.0560 (1.0441) lr 1.8090e-03 eta 0:12:14
epoch [12/50] batch [80/173] time 0.135 (0.109) data 0.000 (0.004) loss 0.9360 (0.9863) ce_loss 0.3721 (0.4033) teacher_loss 0.2644 (0.2914) loss_zs_kd 0.1020 (0.0741) loss_oracle 0.6206 (0.6579) acc 87.5000 (85.3906) kd_loss 0.9946 (1.0360) lr 1.8090e-03 eta 0:12:07
epoch [12/50] batch [100/173] time 0.141 (0.110) data 0.000 (0.003) loss 0.7651 (0.9699) ce_loss 0.2382 (0.3934) teacher_loss 0.2008 (0.2827) loss_zs_kd 0.0534 (0.0758) loss_oracle 0.5377 (0.6494) acc 90.6250 (85.5625) kd_loss 0.9577 (1.0252) lr 1.8090e-03 eta 0:12:08
epoch [12/50] batch [120/173] time 0.091 (0.111) data 0.000 (0.003) loss 0.6635 (0.9595) ce_loss 0.1794 (0.3885) teacher_loss 0.0796 (0.2783) loss_zs_kd 0.0520 (0.0757) loss_oracle 0.5579 (0.6433) acc 93.7500 (85.7031) kd_loss 0.9826 (1.0167) lr 1.8090e-03 eta 0:12:15
epoch [12/50] batch [140/173] time 0.105 (0.111) data 0.000 (0.002) loss 0.8096 (0.9534) ce_loss 0.3809 (0.3906) teacher_loss 0.1825 (0.2792) loss_zs_kd 0.0697 (0.0758) loss_oracle 0.5922 (0.6363) acc 87.5000 (85.6696) kd_loss 0.9244 (1.0080) lr 1.8090e-03 eta 0:12:10
epoch [12/50] batch [160/173] time 0.141 (0.112) data 0.000 (0.002) loss 0.9288 (0.9382) ce_loss 0.4797 (0.3820) teacher_loss 0.3582 (0.2712) loss_zs_kd 0.1009 (0.0762) loss_oracle 0.5202 (0.6289) acc 84.3750 (85.8398) kd_loss 0.9071 (1.0012) lr 1.8090e-03 eta 0:12:18
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,268
* accuracy: 95.1%
* error: 4.9%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.0%, epoch: 7 *******
epoch [13/50] batch [20/173] time 0.137 (0.132) data 0.000 (0.010) loss 0.8026 (0.8273) ce_loss 0.4568 (0.3776) teacher_loss 0.2812 (0.2613) loss_zs_kd 0.1064 (0.0800) loss_oracle 0.4682 (0.5261) acc 84.3750 (86.0938) kd_loss 0.9358 (0.9477) lr 1.7705e-03 eta 0:14:26
epoch [13/50] batch [40/173] time 0.132 (0.128) data 0.000 (0.005) loss 0.9652 (0.8310) ce_loss 0.5649 (0.3889) teacher_loss 0.3633 (0.2688) loss_zs_kd 0.0675 (0.0819) loss_oracle 0.5681 (0.5213) acc 78.1250 (85.7812) kd_loss 1.0375 (0.9523) lr 1.7705e-03 eta 0:13:53
epoch [13/50] batch [60/173] time 0.141 (0.125) data 0.000 (0.004) loss 0.8904 (0.8220) ce_loss 0.5811 (0.3788) teacher_loss 0.3176 (0.2606) loss_zs_kd 0.0871 (0.0809) loss_oracle 0.5292 (0.5210) acc 78.1250 (86.3021) kd_loss 0.9723 (0.9515) lr 1.7705e-03 eta 0:13:34
epoch [13/50] batch [80/173] time 0.091 (0.123) data 0.000 (0.003) loss 0.8860 (0.8349) ce_loss 0.3745 (0.3816) teacher_loss 0.3074 (0.2625) loss_zs_kd 0.0885 (0.0829) loss_oracle 0.5344 (0.5310) acc 90.6250 (86.1328) kd_loss 0.8624 (0.9480) lr 1.7705e-03 eta 0:13:15
epoch [13/50] batch [100/173] time 0.082 (0.121) data 0.000 (0.002) loss 0.7440 (0.8265) ce_loss 0.2058 (0.3772) teacher_loss 0.2120 (0.2603) loss_zs_kd 0.0672 (0.0809) loss_oracle 0.4985 (0.5257) acc 93.7500 (86.6875) kd_loss 0.9756 (0.9429) lr 1.7705e-03 eta 0:13:02
epoch [13/50] batch [120/173] time 0.140 (0.120) data 0.000 (0.002) loss 0.5761 (0.8218) ce_loss 0.0870 (0.3820) teacher_loss 0.0468 (0.2653) loss_zs_kd 0.0593 (0.0791) loss_oracle 0.4996 (0.5169) acc 96.8750 (86.5365) kd_loss 0.9629 (0.9390) lr 1.7705e-03 eta 0:12:55
epoch [13/50] batch [140/173] time 0.142 (0.118) data 0.001 (0.002) loss 0.7106 (0.8129) ce_loss 0.4719 (0.3862) teacher_loss 0.2813 (0.2685) loss_zs_kd 0.0833 (0.0800) loss_oracle 0.3876 (0.5043) acc 84.3750 (86.3393) kd_loss 0.9137 (0.9358) lr 1.7705e-03 eta 0:12:40
epoch [13/50] batch [160/173] time 0.179 (0.118) data 0.000 (0.001) loss 0.7747 (0.8085) ce_loss 0.3521 (0.3872) teacher_loss 0.2381 (0.2710) loss_zs_kd 0.0628 (0.0796) loss_oracle 0.5051 (0.4978) acc 84.3750 (86.1523) kd_loss 0.9448 (0.9328) lr 1.7705e-03 eta 0:12:36
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,276
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.0%, epoch: 13 *******
epoch [14/50] batch [20/173] time 0.133 (0.118) data 0.000 (0.015) loss 0.6742 (0.8273) ce_loss 0.2429 (0.3693) teacher_loss 0.1762 (0.2652) loss_zs_kd 0.0455 (0.0877) loss_oracle 0.4752 (0.5183) acc 90.6250 (86.7188) kd_loss 0.8769 (0.9423) lr 1.7290e-03 eta 0:12:35
epoch [14/50] batch [40/173] time 0.119 (0.109) data 0.000 (0.007) loss 0.8307 (0.8197) ce_loss 0.3389 (0.3685) teacher_loss 0.2141 (0.2612) loss_zs_kd 0.0689 (0.0845) loss_oracle 0.5821 (0.5163) acc 87.5000 (86.0938) kd_loss 0.9718 (0.9392) lr 1.7290e-03 eta 0:11:35
epoch [14/50] batch [60/173] time 0.099 (0.109) data 0.000 (0.005) loss 1.0398 (0.8377) ce_loss 0.3887 (0.3714) teacher_loss 0.2977 (0.2580) loss_zs_kd 0.1317 (0.0874) loss_oracle 0.6763 (0.5360) acc 81.2500 (85.6771) kd_loss 0.9398 (0.9289) lr 1.7290e-03 eta 0:11:28
epoch [14/50] batch [80/173] time 0.116 (0.106) data 0.000 (0.004) loss 0.8518 (0.8371) ce_loss 0.3733 (0.3633) teacher_loss 0.2476 (0.2508) loss_zs_kd 0.1234 (0.0893) loss_oracle 0.5425 (0.5417) acc 87.5000 (86.3281) kd_loss 0.8655 (0.9245) lr 1.7290e-03 eta 0:11:09
epoch [14/50] batch [100/173] time 0.129 (0.105) data 0.000 (0.003) loss 1.1465 (0.8406) ce_loss 0.5806 (0.3685) teacher_loss 0.5006 (0.2541) loss_zs_kd 0.1194 (0.0905) loss_oracle 0.5862 (0.5413) acc 78.1250 (86.1562) kd_loss 0.9427 (0.9228) lr 1.7290e-03 eta 0:11:01
epoch [14/50] batch [120/173] time 0.126 (0.104) data 0.000 (0.003) loss 0.7552 (0.8426) ce_loss 0.3472 (0.3747) teacher_loss 0.2638 (0.2622) loss_zs_kd 0.0735 (0.0893) loss_oracle 0.4547 (0.5357) acc 87.5000 (85.9375) kd_loss 0.9026 (0.9214) lr 1.7290e-03 eta 0:10:53
epoch [14/50] batch [140/173] time 0.106 (0.104) data 0.000 (0.002) loss 0.9679 (0.8394) ce_loss 0.6260 (0.3797) teacher_loss 0.3606 (0.2640) loss_zs_kd 0.1220 (0.0918) loss_oracle 0.5463 (0.5295) acc 71.8750 (85.6473) kd_loss 0.9202 (0.9188) lr 1.7290e-03 eta 0:10:48
epoch [14/50] batch [160/173] time 0.121 (0.104) data 0.000 (0.002) loss 0.9321 (0.8326) ce_loss 0.5054 (0.3761) teacher_loss 0.3400 (0.2612) loss_zs_kd 0.0938 (0.0913) loss_oracle 0.5452 (0.5258) acc 75.0000 (85.7617) kd_loss 0.9197 (0.9160) lr 1.7290e-03 eta 0:10:48
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,276
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.0%, epoch: 13 *******
epoch [15/50] batch [20/173] time 0.112 (0.125) data 0.000 (0.016) loss 0.8376 (0.7726) ce_loss 0.3818 (0.3830) teacher_loss 0.3240 (0.2719) loss_zs_kd 0.0856 (0.0968) loss_oracle 0.4708 (0.4523) acc 90.6250 (85.3125) kd_loss 0.8707 (0.9145) lr 1.6845e-03 eta 0:12:54
epoch [15/50] batch [40/173] time 0.088 (0.113) data 0.000 (0.008) loss 0.8390 (0.7614) ce_loss 0.3867 (0.3721) teacher_loss 0.2601 (0.2634) loss_zs_kd 0.0728 (0.0887) loss_oracle 0.5425 (0.4536) acc 87.5000 (85.9375) kd_loss 0.9494 (0.9062) lr 1.6845e-03 eta 0:11:41
epoch [15/50] batch [60/173] time 0.132 (0.115) data 0.001 (0.005) loss 0.9019 (0.7743) ce_loss 0.4851 (0.3743) teacher_loss 0.3892 (0.2660) loss_zs_kd 0.1108 (0.0913) loss_oracle 0.4573 (0.4626) acc 84.3750 (85.6771) kd_loss 0.8752 (0.8961) lr 1.6845e-03 eta 0:11:52
epoch [15/50] batch [80/173] time 0.104 (0.116) data 0.000 (0.004) loss 0.7113 (0.7647) ce_loss 0.2834 (0.3617) teacher_loss 0.1996 (0.2577) loss_zs_kd 0.0546 (0.0878) loss_oracle 0.4843 (0.4631) acc 90.6250 (86.2109) kd_loss 0.8498 (0.8885) lr 1.6845e-03 eta 0:11:53
epoch [15/50] batch [100/173] time 0.090 (0.113) data 0.000 (0.003) loss 0.6289 (0.7638) ce_loss 0.2275 (0.3588) teacher_loss 0.1361 (0.2537) loss_zs_kd 0.0706 (0.0885) loss_oracle 0.4575 (0.4659) acc 93.7500 (86.5312) kd_loss 0.9319 (0.8874) lr 1.6845e-03 eta 0:11:32
epoch [15/50] batch [120/173] time 0.079 (0.111) data 0.000 (0.003) loss 0.6676 (0.7582) ce_loss 0.2878 (0.3505) teacher_loss 0.1428 (0.2453) loss_zs_kd 0.0686 (0.0866) loss_oracle 0.4906 (0.4696) acc 81.2500 (86.7448) kd_loss 0.9028 (0.8843) lr 1.6845e-03 eta 0:11:15
epoch [15/50] batch [140/173] time 0.132 (0.109) data 0.000 (0.002) loss 0.7956 (0.7613) ce_loss 0.4238 (0.3553) teacher_loss 0.2880 (0.2484) loss_zs_kd 0.0939 (0.0877) loss_oracle 0.4607 (0.4691) acc 81.2500 (86.4509) kd_loss 0.8372 (0.8806) lr 1.6845e-03 eta 0:11:00
epoch [15/50] batch [160/173] time 0.091 (0.107) data 0.000 (0.002) loss 0.6618 (0.7656) ce_loss 0.2369 (0.3588) teacher_loss 0.1344 (0.2519) loss_zs_kd 0.1021 (0.0896) loss_oracle 0.4764 (0.4690) acc 90.6250 (86.4648) kd_loss 0.8501 (0.8783) lr 1.6845e-03 eta 0:10:49
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,275
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.7%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.0%, epoch: 13 *******
epoch [16/50] batch [20/173] time 0.188 (0.180) data 0.000 (0.013) loss 0.7351 (0.7819) ce_loss 0.3184 (0.3591) teacher_loss 0.2254 (0.2464) loss_zs_kd 0.0991 (0.1054) loss_oracle 0.4601 (0.4828) acc 87.5000 (87.6562) kd_loss 0.9731 (0.8886) lr 1.6374e-03 eta 0:18:04
epoch [16/50] batch [40/173] time 0.069 (0.135) data 0.000 (0.007) loss 0.8311 (0.7524) ce_loss 0.4255 (0.3342) teacher_loss 0.2425 (0.2229) loss_zs_kd 0.1064 (0.0903) loss_oracle 0.5355 (0.4843) acc 81.2500 (88.5156) kd_loss 0.8605 (0.8950) lr 1.6374e-03 eta 0:13:32
epoch [16/50] batch [60/173] time 0.117 (0.124) data 0.000 (0.005) loss 0.7102 (0.7577) ce_loss 0.1567 (0.3403) teacher_loss 0.1102 (0.2147) loss_zs_kd 0.0922 (0.0919) loss_oracle 0.5539 (0.4970) acc 96.8750 (88.0208) kd_loss 0.8395 (0.8956) lr 1.6374e-03 eta 0:12:24
epoch [16/50] batch [80/173] time 0.108 (0.120) data 0.000 (0.003) loss 0.6938 (0.7723) ce_loss 0.2233 (0.3515) teacher_loss 0.1799 (0.2180) loss_zs_kd 0.0543 (0.0966) loss_oracle 0.4868 (0.5060) acc 96.8750 (87.5781) kd_loss 0.8809 (0.8998) lr 1.6374e-03 eta 0:11:54
epoch [16/50] batch [100/173] time 0.134 (0.117) data 0.000 (0.003) loss 0.6652 (0.7824) ce_loss 0.2018 (0.3659) teacher_loss 0.1565 (0.2269) loss_zs_kd 0.0709 (0.0977) loss_oracle 0.4733 (0.5067) acc 90.6250 (87.0000) kd_loss 0.8678 (0.9024) lr 1.6374e-03 eta 0:11:35
epoch [16/50] batch [120/173] time 0.119 (0.114) data 0.000 (0.002) loss 0.6951 (0.7846) ce_loss 0.2004 (0.3711) teacher_loss 0.0704 (0.2290) loss_zs_kd 0.1300 (0.0983) loss_oracle 0.5597 (0.5064) acc 90.6250 (86.6927) kd_loss 0.9587 (0.9028) lr 1.6374e-03 eta 0:11:16
epoch [16/50] batch [140/173] time 0.082 (0.112) data 0.000 (0.002) loss 0.8281 (0.7826) ce_loss 0.3372 (0.3732) teacher_loss 0.1927 (0.2265) loss_zs_kd 0.1655 (0.1003) loss_oracle 0.5527 (0.5060) acc 87.5000 (86.5402) kd_loss 0.8972 (0.9044) lr 1.6374e-03 eta 0:11:03
epoch [16/50] batch [160/173] time 0.100 (0.112) data 0.000 (0.002) loss 0.7806 (0.7830) ce_loss 0.3882 (0.3748) teacher_loss 0.1539 (0.2254) loss_zs_kd 0.1054 (0.1018) loss_oracle 0.5740 (0.5067) acc 87.5000 (86.4062) kd_loss 0.9380 (0.9077) lr 1.6374e-03 eta 0:10:59
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,273
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,003
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.7%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.0%, epoch: 13 *******
epoch [17/50] batch [20/173] time 0.108 (0.111) data 0.000 (0.013) loss 0.9102 (0.7382) ce_loss 0.5508 (0.3937) teacher_loss 0.3581 (0.2444) loss_zs_kd 0.1148 (0.0866) loss_oracle 0.4947 (0.4505) acc 81.2500 (86.4062) kd_loss 0.8926 (0.8997) lr 1.5878e-03 eta 0:10:53
epoch [17/50] batch [40/173] time 0.100 (0.105) data 0.000 (0.007) loss 0.7639 (0.7434) ce_loss 0.4639 (0.4002) teacher_loss 0.2250 (0.2453) loss_zs_kd 0.1328 (0.0941) loss_oracle 0.4725 (0.4511) acc 78.1250 (85.7031) kd_loss 0.9287 (0.9005) lr 1.5878e-03 eta 0:10:15
epoch [17/50] batch [60/173] time 0.136 (0.104) data 0.000 (0.005) loss 0.8971 (0.7369) ce_loss 0.5176 (0.3877) teacher_loss 0.3581 (0.2366) loss_zs_kd 0.1158 (0.0992) loss_oracle 0.4811 (0.4507) acc 81.2500 (86.4062) kd_loss 0.9447 (0.8956) lr 1.5878e-03 eta 0:10:02
epoch [17/50] batch [80/173] time 0.084 (0.102) data 0.000 (0.003) loss 0.7086 (0.7429) ce_loss 0.2444 (0.3882) teacher_loss 0.1120 (0.2326) loss_zs_kd 0.0869 (0.1030) loss_oracle 0.5532 (0.4588) acc 90.6250 (86.1328) kd_loss 0.8848 (0.8956) lr 1.5878e-03 eta 0:09:53
epoch [17/50] batch [100/173] time 0.139 (0.104) data 0.000 (0.003) loss 0.6791 (0.7389) ce_loss 0.2837 (0.3783) teacher_loss 0.1533 (0.2232) loss_zs_kd 0.0993 (0.1030) loss_oracle 0.4761 (0.4641) acc 93.7500 (86.2188) kd_loss 0.9356 (0.9020) lr 1.5878e-03 eta 0:10:01
epoch [17/50] batch [120/173] time 0.102 (0.104) data 0.000 (0.002) loss 0.7126 (0.7382) ce_loss 0.3376 (0.3806) teacher_loss 0.1558 (0.2198) loss_zs_kd 0.1206 (0.1036) loss_oracle 0.4965 (0.4667) acc 87.5000 (86.0938) kd_loss 0.9267 (0.9058) lr 1.5878e-03 eta 0:10:00
epoch [17/50] batch [140/173] time 0.088 (0.105) data 0.000 (0.002) loss 0.7447 (0.7405) ce_loss 0.3154 (0.3799) teacher_loss 0.1772 (0.2171) loss_zs_kd 0.1316 (0.1073) loss_oracle 0.5017 (0.4697) acc 87.5000 (86.1384) kd_loss 0.8813 (0.9088) lr 1.5878e-03 eta 0:10:02
epoch [17/50] batch [160/173] time 0.089 (0.104) data 0.000 (0.002) loss 0.7948 (0.7384) ce_loss 0.4641 (0.3780) teacher_loss 0.1605 (0.2137) loss_zs_kd 0.1411 (0.1078) loss_oracle 0.5637 (0.4708) acc 84.3750 (86.2305) kd_loss 0.9543 (0.9087) lr 1.5878e-03 eta 0:09:56
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,271
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.1%, epoch: 17 *******
epoch [18/50] batch [20/173] time 0.171 (0.163) data 0.000 (0.014) loss 0.7631 (0.7481) ce_loss 0.3438 (0.3541) teacher_loss 0.2262 (0.2121) loss_zs_kd 0.1061 (0.0925) loss_oracle 0.4838 (0.4897) acc 81.2500 (86.4062) kd_loss 0.8099 (0.8888) lr 1.5358e-03 eta 0:15:27
epoch [18/50] batch [40/173] time 0.068 (0.128) data 0.000 (0.007) loss 0.7699 (0.7377) ce_loss 0.4219 (0.3411) teacher_loss 0.2469 (0.2063) loss_zs_kd 0.0896 (0.0931) loss_oracle 0.4782 (0.4848) acc 84.3750 (86.9531) kd_loss 0.9007 (0.8805) lr 1.5358e-03 eta 0:12:06
epoch [18/50] batch [60/173] time 0.189 (0.142) data 0.000 (0.005) loss 0.8243 (0.7445) ce_loss 0.3647 (0.3547) teacher_loss 0.3156 (0.2096) loss_zs_kd 0.0958 (0.0931) loss_oracle 0.4608 (0.4883) acc 84.3750 (86.6146) kd_loss 0.8505 (0.8808) lr 1.5358e-03 eta 0:13:23
epoch [18/50] batch [80/173] time 0.099 (0.132) data 0.000 (0.004) loss 0.6642 (0.7455) ce_loss 0.2159 (0.3545) teacher_loss 0.1302 (0.2065) loss_zs_kd 0.0951 (0.0956) loss_oracle 0.4864 (0.4913) acc 93.7500 (86.7969) kd_loss 0.8512 (0.8807) lr 1.5358e-03 eta 0:12:21
epoch [18/50] batch [100/173] time 0.108 (0.123) data 0.000 (0.003) loss 0.8444 (0.7490) ce_loss 0.5376 (0.3587) teacher_loss 0.2886 (0.2092) loss_zs_kd 0.1354 (0.0981) loss_oracle 0.4880 (0.4907) acc 78.1250 (86.5938) kd_loss 0.8798 (0.8852) lr 1.5358e-03 eta 0:11:31
epoch [18/50] batch [120/173] time 0.102 (0.118) data 0.000 (0.002) loss 0.7497 (0.7545) ce_loss 0.3606 (0.3677) teacher_loss 0.2174 (0.2160) loss_zs_kd 0.0888 (0.0999) loss_oracle 0.4879 (0.4885) acc 84.3750 (86.0677) kd_loss 0.9083 (0.8885) lr 1.5358e-03 eta 0:10:56
epoch [18/50] batch [140/173] time 0.103 (0.114) data 0.001 (0.002) loss 0.9008 (0.7562) ce_loss 0.4265 (0.3684) teacher_loss 0.3116 (0.2162) loss_zs_kd 0.1062 (0.1004) loss_oracle 0.5361 (0.4898) acc 87.5000 (86.1607) kd_loss 0.9182 (0.8945) lr 1.5358e-03 eta 0:10:32
epoch [18/50] batch [160/173] time 0.097 (0.110) data 0.000 (0.002) loss 0.5984 (0.7539) ce_loss 0.1804 (0.3643) teacher_loss 0.0745 (0.2141) loss_zs_kd 0.0680 (0.0996) loss_oracle 0.4899 (0.4900) acc 96.8750 (86.4062) kd_loss 0.9709 (0.9022) lr 1.5358e-03 eta 0:10:12
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,274
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.1%, epoch: 17 *******
epoch [19/50] batch [20/173] time 0.146 (0.145) data 0.000 (0.017) loss 0.7587 (0.8314) ce_loss 0.4807 (0.4126) teacher_loss 0.2789 (0.2562) loss_zs_kd 0.0857 (0.1022) loss_oracle 0.4369 (0.5241) acc 81.2500 (84.5312) kd_loss 0.8815 (0.9318) lr 1.4818e-03 eta 0:13:17
epoch [19/50] batch [40/173] time 0.078 (0.123) data 0.000 (0.009) loss 0.8338 (0.8104) ce_loss 0.4788 (0.4164) teacher_loss 0.2526 (0.2522) loss_zs_kd 0.1422 (0.1001) loss_oracle 0.5101 (0.5082) acc 81.2500 (84.9219) kd_loss 0.9780 (0.9363) lr 1.4818e-03 eta 0:11:17
epoch [19/50] batch [60/173] time 0.113 (0.116) data 0.000 (0.006) loss 0.9405 (0.7961) ce_loss 0.4270 (0.3988) teacher_loss 0.3374 (0.2451) loss_zs_kd 0.1051 (0.1009) loss_oracle 0.5506 (0.5005) acc 84.3750 (85.4167) kd_loss 0.9053 (0.9250) lr 1.4818e-03 eta 0:10:33
epoch [19/50] batch [80/173] time 0.092 (0.111) data 0.000 (0.004) loss 0.6930 (0.7845) ce_loss 0.2499 (0.3887) teacher_loss 0.2040 (0.2388) loss_zs_kd 0.1011 (0.0988) loss_oracle 0.4385 (0.4964) acc 90.6250 (86.0156) kd_loss 0.9003 (0.9196) lr 1.4818e-03 eta 0:10:06
epoch [19/50] batch [100/173] time 0.095 (0.114) data 0.000 (0.004) loss 0.8094 (0.7840) ce_loss 0.5405 (0.3917) teacher_loss 0.2076 (0.2413) loss_zs_kd 0.1374 (0.0994) loss_oracle 0.5332 (0.4930) acc 81.2500 (85.8750) kd_loss 0.9338 (0.9142) lr 1.4818e-03 eta 0:10:17
epoch [19/50] batch [120/173] time 0.147 (0.116) data 0.000 (0.003) loss 0.6369 (0.7755) ce_loss 0.2236 (0.3886) teacher_loss 0.1818 (0.2425) loss_zs_kd 0.0801 (0.0962) loss_oracle 0.4150 (0.4849) acc 93.7500 (85.8594) kd_loss 0.9486 (0.9066) lr 1.4818e-03 eta 0:10:27
epoch [19/50] batch [140/173] time 0.131 (0.117) data 0.000 (0.003) loss 0.7954 (0.7717) ce_loss 0.3340 (0.3828) teacher_loss 0.2042 (0.2412) loss_zs_kd 0.1096 (0.0938) loss_oracle 0.5364 (0.4837) acc 90.6250 (85.9821) kd_loss 0.9340 (0.9047) lr 1.4818e-03 eta 0:10:32
epoch [19/50] batch [160/173] time 0.075 (0.117) data 0.000 (0.002) loss 0.8123 (0.7729) ce_loss 0.4590 (0.3822) teacher_loss 0.2138 (0.2397) loss_zs_kd 0.1296 (0.0941) loss_oracle 0.5337 (0.4861) acc 84.3750 (85.9766) kd_loss 0.9160 (0.9063) lr 1.4818e-03 eta 0:10:27
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,272
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.1%, epoch: 17 *******
epoch [20/50] batch [20/173] time 0.135 (0.134) data 0.000 (0.013) loss 0.8832 (0.8066) ce_loss 0.5635 (0.4134) teacher_loss 0.4135 (0.2622) loss_zs_kd 0.1522 (0.0960) loss_oracle 0.3935 (0.4964) acc 78.1250 (83.9062) kd_loss 0.8568 (0.8774) lr 1.4258e-03 eta 0:11:54
epoch [20/50] batch [40/173] time 0.185 (0.124) data 0.000 (0.007) loss 0.7544 (0.7999) ce_loss 0.3311 (0.4041) teacher_loss 0.2901 (0.2579) loss_zs_kd 0.1422 (0.0941) loss_oracle 0.3932 (0.4950) acc 93.7500 (84.7656) kd_loss 0.7554 (0.8830) lr 1.4258e-03 eta 0:10:58
epoch [20/50] batch [60/173] time 0.090 (0.128) data 0.000 (0.005) loss 0.9735 (0.8005) ce_loss 0.6338 (0.3998) teacher_loss 0.4445 (0.2556) loss_zs_kd 0.0897 (0.0922) loss_oracle 0.4842 (0.4988) acc 71.8750 (84.9479) kd_loss 0.8672 (0.8835) lr 1.4258e-03 eta 0:11:19
epoch [20/50] batch [80/173] time 0.185 (0.137) data 0.001 (0.004) loss 0.7957 (0.7941) ce_loss 0.3689 (0.3970) teacher_loss 0.2820 (0.2530) loss_zs_kd 0.0978 (0.0905) loss_oracle 0.4648 (0.4958) acc 84.3750 (85.3516) kd_loss 0.8681 (0.8838) lr 1.4258e-03 eta 0:12:04
epoch [20/50] batch [100/173] time 0.093 (0.136) data 0.000 (0.003) loss 0.6057 (0.7854) ce_loss 0.2192 (0.3964) teacher_loss 0.1845 (0.2534) loss_zs_kd 0.0901 (0.0910) loss_oracle 0.3762 (0.4865) acc 90.6250 (85.4062) kd_loss 0.7925 (0.8828) lr 1.4258e-03 eta 0:11:53
epoch [20/50] batch [120/173] time 0.140 (0.133) data 0.000 (0.002) loss 0.5879 (0.7719) ce_loss 0.2094 (0.3875) teacher_loss 0.1242 (0.2482) loss_zs_kd 0.0795 (0.0885) loss_oracle 0.4240 (0.4795) acc 93.7500 (85.5729) kd_loss 0.9043 (0.8859) lr 1.4258e-03 eta 0:11:39
epoch [20/50] batch [140/173] time 0.125 (0.131) data 0.000 (0.002) loss 0.8460 (0.7719) ce_loss 0.3811 (0.3889) teacher_loss 0.3323 (0.2488) loss_zs_kd 0.1224 (0.0903) loss_oracle 0.4525 (0.4779) acc 87.5000 (85.5804) kd_loss 0.7673 (0.8861) lr 1.4258e-03 eta 0:11:26
epoch [20/50] batch [160/173] time 0.112 (0.130) data 0.000 (0.002) loss 0.7214 (0.7753) ce_loss 0.3904 (0.3915) teacher_loss 0.1993 (0.2520) loss_zs_kd 0.1036 (0.0908) loss_oracle 0.4703 (0.4779) acc 87.5000 (85.5859) kd_loss 0.9060 (0.8871) lr 1.4258e-03 eta 0:11:14
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,274
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,002
* accuracy: 97.8%
* error: 2.2%
* macro_f1: 97.6%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.1%, epoch: 17 *******
epoch [21/50] batch [20/173] time 0.088 (0.117) data 0.000 (0.012) loss 0.8023 (0.7892) ce_loss 0.3662 (0.4184) teacher_loss 0.2909 (0.2586) loss_zs_kd 0.1033 (0.0963) loss_oracle 0.4598 (0.4825) acc 84.3750 (84.2188) kd_loss 0.7822 (0.8949) lr 1.3681e-03 eta 0:10:04
epoch [21/50] batch [40/173] time 0.085 (0.112) data 0.000 (0.006) loss 0.8159 (0.7707) ce_loss 0.4265 (0.3904) teacher_loss 0.2633 (0.2467) loss_zs_kd 0.0731 (0.0942) loss_oracle 0.5160 (0.4769) acc 78.1250 (85.1562) kd_loss 0.9407 (0.8983) lr 1.3681e-03 eta 0:09:34
epoch [21/50] batch [60/173] time 0.073 (0.111) data 0.000 (0.004) loss 0.6517 (0.7777) ce_loss 0.2272 (0.3989) teacher_loss 0.1961 (0.2503) loss_zs_kd 0.0682 (0.0944) loss_oracle 0.4215 (0.4802) acc 87.5000 (84.8958) kd_loss 0.9001 (0.8995) lr 1.3681e-03 eta 0:09:30
epoch [21/50] batch [80/173] time 0.109 (0.110) data 0.000 (0.003) loss 0.6596 (0.7715) ce_loss 0.1384 (0.3934) teacher_loss 0.1377 (0.2468) loss_zs_kd 0.0556 (0.0929) loss_oracle 0.4942 (0.4783) acc 93.7500 (85.5078) kd_loss 0.8683 (0.8984) lr 1.3681e-03 eta 0:09:21
epoch [21/50] batch [100/173] time 0.085 (0.109) data 0.000 (0.003) loss 0.8090 (0.7661) ce_loss 0.3623 (0.3834) teacher_loss 0.2798 (0.2382) loss_zs_kd 0.1118 (0.0943) loss_oracle 0.4733 (0.4807) acc 87.5000 (85.9062) kd_loss 0.9115 (0.8999) lr 1.3681e-03 eta 0:09:16
epoch [21/50] batch [120/173] time 0.103 (0.110) data 0.000 (0.002) loss 0.5485 (0.7674) ce_loss 0.2128 (0.3894) teacher_loss 0.1523 (0.2418) loss_zs_kd 0.0904 (0.0953) loss_oracle 0.3509 (0.4779) acc 90.6250 (85.8073) kd_loss 0.7717 (0.9003) lr 1.3681e-03 eta 0:09:15
epoch [21/50] batch [140/173] time 0.088 (0.109) data 0.000 (0.002) loss 0.6914 (0.7675) ce_loss 0.2583 (0.3882) teacher_loss 0.2075 (0.2434) loss_zs_kd 0.0735 (0.0950) loss_oracle 0.4471 (0.4766) acc 93.7500 (85.7143) kd_loss 0.9277 (0.9019) lr 1.3681e-03 eta 0:09:12
epoch [21/50] batch [160/173] time 0.082 (0.109) data 0.000 (0.002) loss 0.6984 (0.7630) ce_loss 0.3572 (0.3850) teacher_loss 0.1956 (0.2402) loss_zs_kd 0.1132 (0.0956) loss_oracle 0.4462 (0.4750) acc 87.5000 (85.7422) kd_loss 0.9586 (0.9039) lr 1.3681e-03 eta 0:09:07
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,272
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      95.4%, epoch: 2 *******
******* Domain a best val test acc: 97.9%, epoch: 2 *******
******* Domain a best test acc:     98.1%, epoch: 17 *******
epoch [22/50] batch [20/173] time 0.080 (0.118) data 0.000 (0.010) loss 0.5594 (0.7367) ce_loss 0.0973 (0.3450) teacher_loss 0.0508 (0.2227) loss_zs_kd 0.0440 (0.0861) loss_oracle 0.4865 (0.4710) acc 96.8750 (87.9688) kd_loss 1.0153 (0.9628) lr 1.3090e-03 eta 0:09:49
epoch [22/50] batch [40/173] time 0.146 (0.109) data 0.000 (0.005) loss 0.8478 (0.7449) ce_loss 0.5171 (0.3758) teacher_loss 0.2932 (0.2355) loss_zs_kd 0.1016 (0.0867) loss_oracle 0.5038 (0.4661) acc 78.1250 (86.2500) kd_loss 0.8968 (0.9381) lr 1.3090e-03 eta 0:09:04
epoch [22/50] batch [60/173] time 0.065 (0.126) data 0.000 (0.003) loss 0.6678 (0.7536) ce_loss 0.2961 (0.3784) teacher_loss 0.1292 (0.2351) loss_zs_kd 0.0477 (0.0890) loss_oracle 0.5147 (0.4740) acc 87.5000 (86.1979) kd_loss 0.8698 (0.9136) lr 1.3090e-03 eta 0:10:23
epoch [22/50] batch [80/173] time 0.189 (0.132) data 0.000 (0.003) loss 0.7406 (0.7501) ce_loss 0.4402 (0.3802) teacher_loss 0.1904 (0.2364) loss_zs_kd 0.1214 (0.0898) loss_oracle 0.4895 (0.4687) acc 81.2500 (86.2109) kd_loss 0.9386 (0.8934) lr 1.3090e-03 eta 0:10:51
epoch [22/50] batch [100/173] time 0.084 (0.129) data 0.000 (0.002) loss 0.6242 (0.7519) ce_loss 0.2156 (0.3857) teacher_loss 0.2620 (0.2460) loss_zs_kd 0.0507 (0.0879) loss_oracle 0.3368 (0.4620) acc 90.6250 (85.9688) kd_loss 0.7022 (0.8807) lr 1.3090e-03 eta 0:10:36
epoch [22/50] batch [120/173] time 0.078 (0.126) data 0.000 (0.002) loss 0.6777 (0.7479) ce_loss 0.3301 (0.3889) teacher_loss 0.1989 (0.2497) loss_zs_kd 0.0863 (0.0863) loss_oracle 0.4357 (0.4550) acc 87.5000 (85.8854) kd_loss 0.7992 (0.8713) lr 1.3090e-03 eta 0:10:14
epoch [22/50] batch [140/173] time 0.140 (0.126) data 0.000 (0.002) loss 0.5051 (0.7445) ce_loss 0.2240 (0.3882) teacher_loss 0.1357 (0.2482) loss_zs_kd 0.0649 (0.0870) loss_oracle 0.3370 (0.4528) acc 90.6250 (85.8705) kd_loss 0.7354 (0.8661) lr 1.3090e-03 eta 0:10:14
epoch [22/50] batch [160/173] time 0.112 (0.125) data 0.000 (0.001) loss 0.9222 (0.7440) ce_loss 0.6558 (0.3900) teacher_loss 0.4360 (0.2498) loss_zs_kd 0.0738 (0.0875) loss_oracle 0.4493 (0.4504) acc 84.3750 (85.7812) kd_loss 0.8262 (0.8615) lr 1.3090e-03 eta 0:10:06
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,279
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,010
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.1%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.6%, epoch: 22 *******
******* Domain a best val test acc: 98.1%, epoch: 22 *******
******* Domain a best test acc:     98.1%, epoch: 22 *******
epoch [23/50] batch [20/173] time 0.119 (0.123) data 0.000 (0.013) loss 0.7848 (0.7467) ce_loss 0.4187 (0.3896) teacher_loss 0.2809 (0.2630) loss_zs_kd 0.1361 (0.0850) loss_oracle 0.4359 (0.4411) acc 81.2500 (85.6250) kd_loss 0.7795 (0.8330) lr 1.2487e-03 eta 0:09:52
epoch [23/50] batch [40/173] time 0.077 (0.116) data 0.000 (0.007) loss 0.7805 (0.7196) ce_loss 0.4836 (0.3726) teacher_loss 0.3253 (0.2481) loss_zs_kd 0.0918 (0.0814) loss_oracle 0.4093 (0.4309) acc 84.3750 (86.4062) kd_loss 0.8209 (0.8230) lr 1.2487e-03 eta 0:09:15
epoch [23/50] batch [60/173] time 0.136 (0.114) data 0.000 (0.004) loss 0.6409 (0.7052) ce_loss 0.3054 (0.3582) teacher_loss 0.0974 (0.2324) loss_zs_kd 0.1096 (0.0847) loss_oracle 0.4886 (0.4305) acc 90.6250 (86.6146) kd_loss 0.9151 (0.8258) lr 1.2487e-03 eta 0:09:07
epoch [23/50] batch [80/173] time 0.113 (0.114) data 0.000 (0.003) loss 0.7040 (0.7165) ce_loss 0.3350 (0.3667) teacher_loss 0.1690 (0.2416) loss_zs_kd 0.0814 (0.0857) loss_oracle 0.4943 (0.4321) acc 87.5000 (86.4844) kd_loss 0.8897 (0.8311) lr 1.2487e-03 eta 0:09:02
epoch [23/50] batch [100/173] time 0.086 (0.113) data 0.000 (0.003) loss 0.5284 (0.7065) ce_loss 0.1946 (0.3597) teacher_loss 0.0879 (0.2321) loss_zs_kd 0.0664 (0.0856) loss_oracle 0.4072 (0.4316) acc 90.6250 (86.6562) kd_loss 0.7764 (0.8344) lr 1.2487e-03 eta 0:08:54
epoch [23/50] batch [120/173] time 0.100 (0.112) data 0.000 (0.002) loss 0.8612 (0.7130) ce_loss 0.6172 (0.3650) teacher_loss 0.2701 (0.2351) loss_zs_kd 0.0874 (0.0872) loss_oracle 0.5475 (0.4343) acc 81.2500 (86.6667) kd_loss 1.0338 (0.8427) lr 1.2487e-03 eta 0:08:49
epoch [23/50] batch [140/173] time 0.091 (0.112) data 0.000 (0.002) loss 0.8126 (0.7146) ce_loss 0.4980 (0.3666) teacher_loss 0.3584 (0.2371) loss_zs_kd 0.0825 (0.0870) loss_oracle 0.4129 (0.4341) acc 84.3750 (86.4509) kd_loss 0.8650 (0.8511) lr 1.2487e-03 eta 0:08:45
epoch [23/50] batch [160/173] time 0.087 (0.111) data 0.000 (0.002) loss 0.4883 (0.7138) ce_loss 0.1102 (0.3650) teacher_loss 0.0993 (0.2381) loss_zs_kd 0.0414 (0.0866) loss_oracle 0.3683 (0.4324) acc 96.8750 (86.6211) kd_loss 0.8786 (0.8574) lr 1.2487e-03 eta 0:08:40
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,278
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      95.6%, epoch: 22 *******
******* Domain a best val test acc: 98.1%, epoch: 22 *******
******* Domain a best test acc:     98.1%, epoch: 22 *******
epoch [24/50] batch [20/173] time 0.146 (0.133) data 0.000 (0.014) loss 0.8402 (0.7245) ce_loss 0.5054 (0.3700) teacher_loss 0.3820 (0.2300) loss_zs_kd 0.1158 (0.1019) loss_oracle 0.4003 (0.4436) acc 75.0000 (85.4688) kd_loss 0.8206 (0.9064) lr 1.1874e-03 eta 0:10:19
epoch [24/50] batch [40/173] time 0.187 (0.126) data 0.000 (0.007) loss 0.8091 (0.7444) ce_loss 0.6470 (0.3901) teacher_loss 0.3191 (0.2456) loss_zs_kd 0.1132 (0.0974) loss_oracle 0.4334 (0.4502) acc 75.0000 (84.6875) kd_loss 0.9311 (0.9237) lr 1.1874e-03 eta 0:09:42
epoch [24/50] batch [60/173] time 0.091 (0.133) data 0.000 (0.005) loss 0.7967 (0.7527) ce_loss 0.3308 (0.4014) teacher_loss 0.2377 (0.2514) loss_zs_kd 0.1194 (0.0966) loss_oracle 0.4993 (0.4530) acc 84.3750 (84.3750) kd_loss 0.9234 (0.9183) lr 1.1874e-03 eta 0:10:11
epoch [24/50] batch [80/173] time 0.187 (0.146) data 0.001 (0.004) loss 0.7204 (0.7555) ce_loss 0.3059 (0.4032) teacher_loss 0.1808 (0.2455) loss_zs_kd 0.1081 (0.1001) loss_oracle 0.4856 (0.4599) acc 87.5000 (84.8047) kd_loss 0.9119 (0.9150) lr 1.1874e-03 eta 0:11:09
epoch [24/50] batch [100/173] time 0.090 (0.138) data 0.000 (0.003) loss 0.5451 (0.7518) ce_loss 0.1790 (0.3990) teacher_loss 0.1566 (0.2466) loss_zs_kd 0.0424 (0.0981) loss_oracle 0.3672 (0.4562) acc 96.8750 (85.0312) kd_loss 0.7885 (0.8998) lr 1.1874e-03 eta 0:10:32
epoch [24/50] batch [120/173] time 0.115 (0.134) data 0.000 (0.003) loss 0.7720 (0.7394) ce_loss 0.4792 (0.3865) teacher_loss 0.2874 (0.2420) loss_zs_kd 0.0565 (0.0928) loss_oracle 0.4563 (0.4510) acc 84.3750 (85.6250) kd_loss 0.7795 (0.8859) lr 1.1874e-03 eta 0:10:10
epoch [24/50] batch [140/173] time 0.135 (0.132) data 0.000 (0.002) loss 0.8696 (0.7391) ce_loss 0.4644 (0.3886) teacher_loss 0.3076 (0.2433) loss_zs_kd 0.1172 (0.0922) loss_oracle 0.5035 (0.4497) acc 87.5000 (85.5580) kd_loss 0.9036 (0.8792) lr 1.1874e-03 eta 0:09:58
epoch [24/50] batch [160/173] time 0.115 (0.130) data 0.000 (0.002) loss 1.0048 (0.7360) ce_loss 0.5342 (0.3874) teacher_loss 0.5441 (0.2432) loss_zs_kd 0.1065 (0.0926) loss_oracle 0.4074 (0.4465) acc 71.8750 (85.5469) kd_loss 0.8858 (0.8716) lr 1.1874e-03 eta 0:09:47
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,277
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,005
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.8%
******* Domain a best val acc:      95.6%, epoch: 22 *******
******* Domain a best val test acc: 98.1%, epoch: 22 *******
******* Domain a best test acc:     98.1%, epoch: 22 *******
epoch [25/50] batch [20/173] time 0.108 (0.136) data 0.000 (0.014) loss 0.6819 (0.7495) ce_loss 0.3701 (0.4507) teacher_loss 0.2379 (0.2829) loss_zs_kd 0.0848 (0.0868) loss_oracle 0.4015 (0.4232) acc 84.3750 (84.5312) kd_loss 0.8522 (0.8238) lr 1.1253e-03 eta 0:10:10
epoch [25/50] batch [40/173] time 0.144 (0.130) data 0.000 (0.007) loss 0.5303 (0.7277) ce_loss 0.2263 (0.4120) teacher_loss 0.0836 (0.2591) loss_zs_kd 0.0794 (0.0893) loss_oracle 0.4069 (0.4240) acc 87.5000 (85.8594) kd_loss 0.8763 (0.8302) lr 1.1253e-03 eta 0:09:40
epoch [25/50] batch [60/173] time 0.139 (0.128) data 0.000 (0.005) loss 1.0692 (0.7314) ce_loss 0.9053 (0.4204) teacher_loss 0.5171 (0.2570) loss_zs_kd 0.1081 (0.0897) loss_oracle 0.4980 (0.4296) acc 68.7500 (85.2604) kd_loss 0.9306 (0.8427) lr 1.1253e-03 eta 0:09:27
epoch [25/50] batch [80/173] time 0.143 (0.128) data 0.000 (0.004) loss 0.7345 (0.7381) ce_loss 0.3010 (0.4101) teacher_loss 0.1896 (0.2545) loss_zs_kd 0.0958 (0.0935) loss_oracle 0.4969 (0.4368) acc 87.5000 (85.2344) kd_loss 0.8587 (0.8464) lr 1.1253e-03 eta 0:09:25
epoch [25/50] batch [100/173] time 0.143 (0.127) data 0.000 (0.003) loss 0.7087 (0.7349) ce_loss 0.3369 (0.4020) teacher_loss 0.2046 (0.2515) loss_zs_kd 0.0884 (0.0912) loss_oracle 0.4599 (0.4378) acc 84.3750 (85.4688) kd_loss 0.8755 (0.8477) lr 1.1253e-03 eta 0:09:18
epoch [25/50] batch [120/173] time 0.130 (0.127) data 0.001 (0.003) loss 0.8045 (0.7291) ce_loss 0.5586 (0.3973) teacher_loss 0.2989 (0.2489) loss_zs_kd 0.1171 (0.0891) loss_oracle 0.4470 (0.4357) acc 78.1250 (85.4167) kd_loss 0.8655 (0.8480) lr 1.1253e-03 eta 0:09:17
epoch [25/50] batch [140/173] time 0.120 (0.126) data 0.000 (0.002) loss 0.8122 (0.7296) ce_loss 0.4114 (0.3950) teacher_loss 0.2737 (0.2456) loss_zs_kd 0.1039 (0.0896) loss_oracle 0.4866 (0.4392) acc 90.6250 (85.6696) kd_loss 0.8999 (0.8528) lr 1.1253e-03 eta 0:09:08
epoch [25/50] batch [160/173] time 0.091 (0.125) data 0.000 (0.002) loss 0.7592 (0.7278) ce_loss 0.5649 (0.3929) teacher_loss 0.2477 (0.2427) loss_zs_kd 0.1114 (0.0897) loss_oracle 0.4557 (0.4403) acc 78.1250 (85.7812) kd_loss 0.8798 (0.8545) lr 1.1253e-03 eta 0:09:00
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,274
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      95.6%, epoch: 22 *******
******* Domain a best val test acc: 98.1%, epoch: 22 *******
******* Domain a best test acc:     98.1%, epoch: 22 *******
epoch [26/50] batch [20/173] time 0.187 (0.160) data 0.000 (0.014) loss 0.6565 (0.6812) ce_loss 0.2520 (0.3330) teacher_loss 0.2060 (0.2024) loss_zs_kd 0.1004 (0.0827) loss_oracle 0.4003 (0.4374) acc 90.6250 (87.3438) kd_loss 0.9438 (0.8627) lr 1.0628e-03 eta 0:11:28
epoch [26/50] batch [40/173] time 0.187 (0.154) data 0.000 (0.007) loss 0.7144 (0.6915) ce_loss 0.4368 (0.3515) teacher_loss 0.2343 (0.2162) loss_zs_kd 0.0502 (0.0815) loss_oracle 0.4550 (0.4346) acc 84.3750 (86.4844) kd_loss 0.8692 (0.8618) lr 1.0628e-03 eta 0:10:58
epoch [26/50] batch [60/173] time 0.070 (0.156) data 0.001 (0.005) loss 0.8713 (0.7139) ce_loss 0.5054 (0.3751) teacher_loss 0.3441 (0.2301) loss_zs_kd 0.1330 (0.0861) loss_oracle 0.4607 (0.4407) acc 81.2500 (85.7812) kd_loss 0.9220 (0.8699) lr 1.0628e-03 eta 0:11:06
epoch [26/50] batch [80/173] time 0.141 (0.148) data 0.000 (0.004) loss 0.5350 (0.7269) ce_loss 0.1790 (0.3784) teacher_loss 0.0992 (0.2380) loss_zs_kd 0.0615 (0.0894) loss_oracle 0.4050 (0.4443) acc 96.8750 (85.8203) kd_loss 0.8612 (0.8664) lr 1.0628e-03 eta 0:10:27
epoch [26/50] batch [100/173] time 0.139 (0.143) data 0.000 (0.003) loss 0.6498 (0.7232) ce_loss 0.3972 (0.3860) teacher_loss 0.2779 (0.2464) loss_zs_kd 0.0737 (0.0883) loss_oracle 0.3351 (0.4326) acc 81.2500 (85.5625) kd_loss 0.7870 (0.8567) lr 1.0628e-03 eta 0:10:04
epoch [26/50] batch [120/173] time 0.139 (0.140) data 0.000 (0.002) loss 0.8672 (0.7243) ce_loss 0.5146 (0.3946) teacher_loss 0.3412 (0.2483) loss_zs_kd 0.0885 (0.0894) loss_oracle 0.4818 (0.4313) acc 84.3750 (85.3125) kd_loss 0.8145 (0.8557) lr 1.0628e-03 eta 0:09:47
epoch [26/50] batch [140/173] time 0.135 (0.136) data 0.001 (0.002) loss 0.7047 (0.7295) ce_loss 0.1814 (0.3946) teacher_loss 0.1280 (0.2498) loss_zs_kd 0.1088 (0.0915) loss_oracle 0.5223 (0.4339) acc 93.7500 (85.3795) kd_loss 0.9277 (0.8538) lr 1.0628e-03 eta 0:09:27
epoch [26/50] batch [160/173] time 0.084 (0.132) data 0.000 (0.002) loss 0.6006 (0.7254) ce_loss 0.2040 (0.3864) teacher_loss 0.1419 (0.2457) loss_zs_kd 0.0666 (0.0898) loss_oracle 0.4253 (0.4348) acc 93.7500 (85.6445) kd_loss 0.8417 (0.8530) lr 1.0628e-03 eta 0:09:10
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,277
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,012
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.2%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      95.6%, epoch: 22 *******
******* Domain a best val test acc: 98.1%, epoch: 22 *******
******* Domain a best test acc:     98.2%, epoch: 26 *******
epoch [27/50] batch [20/173] time 0.092 (0.121) data 0.000 (0.011) loss 0.7474 (0.7485) ce_loss 0.3423 (0.3838) teacher_loss 0.2249 (0.2535) loss_zs_kd 0.0760 (0.0912) loss_oracle 0.4845 (0.4494) acc 87.5000 (86.5625) kd_loss 0.8355 (0.8486) lr 1.0000e-03 eta 0:08:20
epoch [27/50] batch [40/173] time 0.088 (0.117) data 0.000 (0.005) loss 0.6934 (0.7501) ce_loss 0.3037 (0.3703) teacher_loss 0.2066 (0.2417) loss_zs_kd 0.0841 (0.0995) loss_oracle 0.4447 (0.4586) acc 90.6250 (86.7969) kd_loss 0.8757 (0.8676) lr 1.0000e-03 eta 0:08:00
epoch [27/50] batch [60/173] time 0.131 (0.116) data 0.001 (0.004) loss 0.6679 (0.7408) ce_loss 0.2390 (0.3613) teacher_loss 0.1550 (0.2341) loss_zs_kd 0.1055 (0.0994) loss_oracle 0.4602 (0.4571) acc 93.7500 (86.6146) kd_loss 0.8439 (0.8667) lr 1.0000e-03 eta 0:07:55
epoch [27/50] batch [80/173] time 0.091 (0.119) data 0.000 (0.003) loss 0.7602 (0.7398) ce_loss 0.5303 (0.3627) teacher_loss 0.3157 (0.2346) loss_zs_kd 0.0775 (0.0983) loss_oracle 0.4057 (0.4560) acc 84.3750 (86.5234) kd_loss 0.8794 (0.8737) lr 1.0000e-03 eta 0:08:04
epoch [27/50] batch [100/173] time 0.096 (0.120) data 0.000 (0.002) loss 0.7024 (0.7427) ce_loss 0.2286 (0.3611) teacher_loss 0.1647 (0.2360) loss_zs_kd 0.0880 (0.0993) loss_oracle 0.4937 (0.4571) acc 84.3750 (86.5625) kd_loss 0.9039 (0.8755) lr 1.0000e-03 eta 0:08:06
epoch [27/50] batch [120/173] time 0.135 (0.120) data 0.001 (0.002) loss 0.6297 (0.7386) ce_loss 0.2260 (0.3546) teacher_loss 0.1722 (0.2349) loss_zs_kd 0.0817 (0.0978) loss_oracle 0.4167 (0.4548) acc 93.7500 (86.8490) kd_loss 0.7553 (0.8752) lr 1.0000e-03 eta 0:08:05
epoch [27/50] batch [140/173] time 0.081 (0.120) data 0.000 (0.002) loss 0.8941 (0.7424) ce_loss 0.5435 (0.3575) teacher_loss 0.3251 (0.2384) loss_zs_kd 0.1005 (0.0969) loss_oracle 0.5188 (0.4556) acc 78.1250 (86.6295) kd_loss 0.8809 (0.8748) lr 1.0000e-03 eta 0:08:01
epoch [27/50] batch [160/173] time 0.120 (0.120) data 0.000 (0.002) loss 0.9155 (0.7450) ce_loss 0.4878 (0.3588) teacher_loss 0.3904 (0.2405) loss_zs_kd 0.1012 (0.0971) loss_oracle 0.4745 (0.4559) acc 87.5000 (86.5430) kd_loss 0.8077 (0.8747) lr 1.0000e-03 eta 0:08:00
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,280
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
******* Domain a best val acc:      95.6%, epoch: 27 *******
******* Domain a best val test acc: 98.1%, epoch: 27 *******
******* Domain a best test acc:     98.2%, epoch: 26 *******
epoch [28/50] batch [20/173] time 0.155 (0.189) data 0.000 (0.012) loss 0.6801 (0.7291) ce_loss 0.2188 (0.3322) teacher_loss 0.2033 (0.2329) loss_zs_kd 0.0618 (0.0870) loss_oracle 0.4458 (0.4528) acc 93.7500 (87.3438) kd_loss 0.8383 (0.8789) lr 9.3721e-04 eta 0:12:29
epoch [28/50] batch [40/173] time 0.076 (0.141) data 0.000 (0.006) loss 0.7056 (0.7492) ce_loss 0.2549 (0.3419) teacher_loss 0.1909 (0.2370) loss_zs_kd 0.0802 (0.0893) loss_oracle 0.4746 (0.4675) acc 90.6250 (87.4219) kd_loss 0.9017 (0.8672) lr 9.3721e-04 eta 0:09:15
epoch [28/50] batch [60/173] time 0.105 (0.128) data 0.000 (0.004) loss 0.7983 (0.7528) ce_loss 0.4529 (0.3376) teacher_loss 0.2505 (0.2291) loss_zs_kd 0.1182 (0.0925) loss_oracle 0.4888 (0.4775) acc 81.2500 (87.3958) kd_loss 0.8212 (0.8608) lr 9.3721e-04 eta 0:08:20
epoch [28/50] batch [80/173] time 0.143 (0.124) data 0.000 (0.003) loss 0.7615 (0.7568) ce_loss 0.3645 (0.3380) teacher_loss 0.2843 (0.2283) loss_zs_kd 0.1016 (0.0935) loss_oracle 0.4264 (0.4818) acc 84.3750 (87.4609) kd_loss 0.8612 (0.8631) lr 9.3721e-04 eta 0:08:04
epoch [28/50] batch [100/173] time 0.145 (0.123) data 0.000 (0.003) loss 0.8570 (0.7571) ce_loss 0.5103 (0.3411) teacher_loss 0.2471 (0.2226) loss_zs_kd 0.1859 (0.0963) loss_oracle 0.5169 (0.4863) acc 78.1250 (87.2188) kd_loss 0.8907 (0.8667) lr 9.3721e-04 eta 0:07:55
epoch [28/50] batch [120/173] time 0.093 (0.121) data 0.000 (0.002) loss 0.6943 (0.7640) ce_loss 0.2815 (0.3445) teacher_loss 0.1494 (0.2240) loss_zs_kd 0.1300 (0.0996) loss_oracle 0.4800 (0.4901) acc 90.6250 (87.2135) kd_loss 0.7847 (0.8645) lr 9.3721e-04 eta 0:07:46
epoch [28/50] batch [140/173] time 0.136 (0.121) data 0.000 (0.002) loss 0.6196 (0.7621) ce_loss 0.1431 (0.3361) teacher_loss 0.0841 (0.2200) loss_zs_kd 0.0790 (0.0978) loss_oracle 0.4960 (0.4932) acc 93.7500 (87.3661) kd_loss 0.8410 (0.8595) lr 9.3721e-04 eta 0:07:42
epoch [28/50] batch [160/173] time 0.120 (0.120) data 0.000 (0.002) loss 1.0120 (0.7711) ce_loss 0.5527 (0.3453) teacher_loss 0.4192 (0.2299) loss_zs_kd 0.0996 (0.0973) loss_oracle 0.5430 (0.4925) acc 81.2500 (87.1484) kd_loss 0.8273 (0.8509) lr 9.3721e-04 eta 0:07:38
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,289
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,011
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.1%
******* Domain a best val acc:      96.0%, epoch: 28 *******
******* Domain a best val test acc: 98.2%, epoch: 28 *******
******* Domain a best test acc:     98.2%, epoch: 26 *******
epoch [29/50] batch [20/173] time 0.122 (0.136) data 0.001 (0.014) loss 0.7648 (0.7946) ce_loss 0.2632 (0.3784) teacher_loss 0.2079 (0.2796) loss_zs_kd 0.0788 (0.0909) loss_oracle 0.5176 (0.4695) acc 84.3750 (86.7188) kd_loss 0.8147 (0.7684) lr 8.7467e-04 eta 0:08:34
epoch [29/50] batch [40/173] time 0.086 (0.131) data 0.000 (0.007) loss 0.7104 (0.7885) ce_loss 0.2443 (0.3780) teacher_loss 0.1824 (0.2766) loss_zs_kd 0.0952 (0.0955) loss_oracle 0.4804 (0.4641) acc 87.5000 (86.6406) kd_loss 0.7709 (0.7567) lr 8.7467e-04 eta 0:08:12
epoch [29/50] batch [60/173] time 0.136 (0.126) data 0.000 (0.005) loss 0.9386 (0.7906) ce_loss 0.4832 (0.3653) teacher_loss 0.3531 (0.2711) loss_zs_kd 0.1351 (0.0983) loss_oracle 0.5180 (0.4704) acc 78.1250 (87.0833) kd_loss 0.7697 (0.7644) lr 8.7467e-04 eta 0:07:53
epoch [29/50] batch [80/173] time 0.088 (0.126) data 0.000 (0.004) loss 0.9171 (0.7853) ce_loss 0.4434 (0.3639) teacher_loss 0.3949 (0.2714) loss_zs_kd 0.0910 (0.0958) loss_oracle 0.4767 (0.4659) acc 84.3750 (87.2266) kd_loss 0.7621 (0.7648) lr 8.7467e-04 eta 0:07:50
epoch [29/50] batch [100/173] time 0.111 (0.126) data 0.000 (0.003) loss 0.7048 (0.7825) ce_loss 0.3667 (0.3669) teacher_loss 0.2442 (0.2722) loss_zs_kd 0.0716 (0.0951) loss_oracle 0.4248 (0.4628) acc 84.3750 (86.9062) kd_loss 0.8325 (0.7746) lr 8.7467e-04 eta 0:07:45
epoch [29/50] batch [120/173] time 0.138 (0.127) data 0.000 (0.003) loss 0.8970 (0.7781) ce_loss 0.5039 (0.3620) teacher_loss 0.3576 (0.2689) loss_zs_kd 0.0974 (0.0943) loss_oracle 0.4907 (0.4620) acc 78.1250 (86.9010) kd_loss 0.7716 (0.7799) lr 8.7467e-04 eta 0:07:47
epoch [29/50] batch [140/173] time 0.087 (0.126) data 0.000 (0.002) loss 0.9534 (0.7717) ce_loss 0.5854 (0.3541) teacher_loss 0.3991 (0.2624) loss_zs_kd 0.1324 (0.0934) loss_oracle 0.4881 (0.4627) acc 81.2500 (87.0982) kd_loss 0.8408 (0.7816) lr 8.7467e-04 eta 0:07:41
epoch [29/50] batch [160/173] time 0.187 (0.125) data 0.000 (0.002) loss 0.7381 (0.7715) ce_loss 0.1863 (0.3544) teacher_loss 0.1316 (0.2616) loss_zs_kd 0.0697 (0.0935) loss_oracle 0.5716 (0.4632) acc 96.8750 (87.0898) kd_loss 0.8076 (0.7838) lr 8.7467e-04 eta 0:07:36
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,288
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,013
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 98.2%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      96.0%, epoch: 28 *******
******* Domain a best val test acc: 98.2%, epoch: 28 *******
******* Domain a best test acc:     98.3%, epoch: 29 *******
epoch [30/50] batch [20/173] time 0.093 (0.113) data 0.000 (0.013) loss 0.6137 (0.7172) ce_loss 0.1525 (0.3109) teacher_loss 0.0793 (0.2170) loss_zs_kd 0.1335 (0.0987) loss_oracle 0.4677 (0.4508) acc 100.0000 (88.1250) kd_loss 0.7645 (0.8166) lr 8.1262e-04 eta 0:06:46
epoch [30/50] batch [40/173] time 0.137 (0.109) data 0.000 (0.007) loss 0.7118 (0.7196) ce_loss 0.2725 (0.3157) teacher_loss 0.2702 (0.2222) loss_zs_kd 0.0786 (0.0951) loss_oracle 0.4024 (0.4499) acc 93.7500 (87.5781) kd_loss 0.8466 (0.8260) lr 8.1262e-04 eta 0:06:30
epoch [30/50] batch [60/173] time 0.137 (0.108) data 0.000 (0.005) loss 0.6893 (0.7145) ce_loss 0.2986 (0.3170) teacher_loss 0.2503 (0.2245) loss_zs_kd 0.1040 (0.0958) loss_oracle 0.3869 (0.4421) acc 96.8750 (87.7604) kd_loss 0.8361 (0.8318) lr 8.1262e-04 eta 0:06:24
epoch [30/50] batch [80/173] time 0.138 (0.109) data 0.000 (0.003) loss 0.8515 (0.7205) ce_loss 0.4880 (0.3285) teacher_loss 0.3375 (0.2322) loss_zs_kd 0.1055 (0.0972) loss_oracle 0.4613 (0.4397) acc 81.2500 (87.5391) kd_loss 0.8362 (0.8366) lr 8.1262e-04 eta 0:06:26
epoch [30/50] batch [100/173] time 0.135 (0.108) data 0.000 (0.003) loss 0.7935 (0.7246) ce_loss 0.4070 (0.3328) teacher_loss 0.3077 (0.2370) loss_zs_kd 0.1032 (0.1002) loss_oracle 0.4342 (0.4375) acc 87.5000 (87.2812) kd_loss 0.8043 (0.8335) lr 8.1262e-04 eta 0:06:21
epoch [30/50] batch [120/173] time 0.118 (0.109) data 0.000 (0.002) loss 0.7914 (0.7294) ce_loss 0.3845 (0.3426) teacher_loss 0.3085 (0.2469) loss_zs_kd 0.0936 (0.0980) loss_oracle 0.4361 (0.4335) acc 81.2500 (86.9010) kd_loss 0.8664 (0.8302) lr 8.1262e-04 eta 0:06:22
epoch [30/50] batch [140/173] time 0.132 (0.109) data 0.000 (0.002) loss 0.7224 (0.7281) ce_loss 0.3704 (0.3421) teacher_loss 0.2176 (0.2441) loss_zs_kd 0.1079 (0.0985) loss_oracle 0.4508 (0.4347) acc 87.5000 (87.0312) kd_loss 0.8246 (0.8336) lr 8.1262e-04 eta 0:06:21
epoch [30/50] batch [160/173] time 0.070 (0.108) data 0.000 (0.002) loss 0.8097 (0.7318) ce_loss 0.4272 (0.3445) teacher_loss 0.2621 (0.2447) loss_zs_kd 0.1209 (0.1003) loss_oracle 0.4872 (0.4370) acc 81.2500 (86.8555) kd_loss 0.9281 (0.8351) lr 8.1262e-04 eta 0:06:15
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,290
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.6%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,014
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 98.3%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      96.0%, epoch: 30 *******
******* Domain a best val test acc: 98.3%, epoch: 30 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [31/50] batch [20/173] time 0.074 (0.106) data 0.000 (0.012) loss 0.8041 (0.7095) ce_loss 0.4619 (0.3154) teacher_loss 0.3093 (0.2223) loss_zs_kd 0.1226 (0.1053) loss_oracle 0.4335 (0.4345) acc 90.6250 (88.2812) kd_loss 0.9167 (0.8620) lr 7.5131e-04 eta 0:06:03
epoch [31/50] batch [40/173] time 0.122 (0.098) data 0.000 (0.006) loss 0.9367 (0.7237) ce_loss 0.6714 (0.3476) teacher_loss 0.4192 (0.2405) loss_zs_kd 0.1373 (0.1058) loss_oracle 0.4489 (0.4302) acc 78.1250 (86.5625) kd_loss 0.8369 (0.8660) lr 7.5131e-04 eta 0:05:36
epoch [31/50] batch [60/173] time 0.122 (0.096) data 0.000 (0.004) loss 0.7644 (0.7225) ce_loss 0.4312 (0.3491) teacher_loss 0.2941 (0.2413) loss_zs_kd 0.1482 (0.1047) loss_oracle 0.3962 (0.4288) acc 78.1250 (86.3021) kd_loss 0.7729 (0.8575) lr 7.5131e-04 eta 0:05:28
epoch [31/50] batch [80/173] time 0.122 (0.100) data 0.000 (0.003) loss 0.7928 (0.7199) ce_loss 0.3423 (0.3392) teacher_loss 0.2394 (0.2370) loss_zs_kd 0.1332 (0.1041) loss_oracle 0.4867 (0.4309) acc 84.3750 (86.9922) kd_loss 0.9131 (0.8546) lr 7.5131e-04 eta 0:05:36
epoch [31/50] batch [100/173] time 0.144 (0.103) data 0.000 (0.003) loss 0.8016 (0.7135) ce_loss 0.3188 (0.3283) teacher_loss 0.2644 (0.2300) loss_zs_kd 0.0755 (0.1021) loss_oracle 0.4995 (0.4324) acc 93.7500 (87.6562) kd_loss 0.9058 (0.8550) lr 7.5131e-04 eta 0:05:44
epoch [31/50] batch [120/173] time 0.129 (0.105) data 0.000 (0.002) loss 0.8288 (0.7146) ce_loss 0.4319 (0.3247) teacher_loss 0.3142 (0.2265) loss_zs_kd 0.0942 (0.0997) loss_oracle 0.4675 (0.4383) acc 84.3750 (87.5521) kd_loss 0.8737 (0.8604) lr 7.5131e-04 eta 0:05:51
epoch [31/50] batch [140/173] time 0.136 (0.108) data 0.000 (0.002) loss 0.9711 (0.7211) ce_loss 0.5708 (0.3269) teacher_loss 0.4451 (0.2272) loss_zs_kd 0.1334 (0.1004) loss_oracle 0.4593 (0.4437) acc 81.2500 (87.4554) kd_loss 0.9164 (0.8692) lr 7.5131e-04 eta 0:05:57
epoch [31/50] batch [160/173] time 0.191 (0.110) data 0.000 (0.002) loss 0.7880 (0.7251) ce_loss 0.3533 (0.3266) teacher_loss 0.1790 (0.2241) loss_zs_kd 0.1538 (0.1026) loss_oracle 0.5321 (0.4497) acc 90.6250 (87.3633) kd_loss 0.9592 (0.8785) lr 7.5131e-04 eta 0:06:02
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,283
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,013
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 98.2%
******* Domain a best val acc:      96.0%, epoch: 30 *******
******* Domain a best val test acc: 98.3%, epoch: 30 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [32/50] batch [20/173] time 0.106 (0.130) data 0.000 (0.012) loss 0.7001 (0.7889) ce_loss 0.2421 (0.3547) teacher_loss 0.1310 (0.2183) loss_zs_kd 0.0947 (0.1097) loss_oracle 0.5217 (0.5157) acc 87.5000 (87.8125) kd_loss 1.0515 (0.9567) lr 6.9098e-04 eta 0:07:03
epoch [32/50] batch [40/173] time 0.143 (0.123) data 0.000 (0.006) loss 0.8131 (0.7898) ce_loss 0.3176 (0.3445) teacher_loss 0.1518 (0.2132) loss_zs_kd 0.1370 (0.1162) loss_oracle 0.5928 (0.5185) acc 87.5000 (87.7344) kd_loss 1.0462 (0.9695) lr 6.9098e-04 eta 0:06:40
epoch [32/50] batch [60/173] time 0.084 (0.122) data 0.000 (0.004) loss 0.8548 (0.8150) ce_loss 0.4707 (0.3689) teacher_loss 0.2259 (0.2334) loss_zs_kd 0.1154 (0.1172) loss_oracle 0.5711 (0.5230) acc 81.2500 (86.6146) kd_loss 0.9707 (0.9792) lr 6.9098e-04 eta 0:06:33
epoch [32/50] batch [80/173] time 0.130 (0.122) data 0.000 (0.003) loss 0.7027 (0.8070) ce_loss 0.2212 (0.3571) teacher_loss 0.1373 (0.2283) loss_zs_kd 0.1020 (0.1126) loss_oracle 0.5144 (0.5224) acc 96.8750 (87.0312) kd_loss 1.0127 (0.9833) lr 6.9098e-04 eta 0:06:31
epoch [32/50] batch [100/173] time 0.084 (0.122) data 0.000 (0.003) loss 0.6219 (0.8089) ce_loss 0.1779 (0.3565) teacher_loss 0.1145 (0.2266) loss_zs_kd 0.0822 (0.1127) loss_oracle 0.4663 (0.5259) acc 93.7500 (86.9062) kd_loss 0.8665 (0.9875) lr 6.9098e-04 eta 0:06:27
epoch [32/50] batch [120/173] time 0.140 (0.122) data 0.000 (0.002) loss 0.6282 (0.8167) ce_loss 0.1512 (0.3640) teacher_loss 0.1110 (0.2345) loss_zs_kd 0.0572 (0.1110) loss_oracle 0.4886 (0.5267) acc 93.7500 (86.7188) kd_loss 0.8883 (0.9930) lr 6.9098e-04 eta 0:06:25
epoch [32/50] batch [140/173] time 0.143 (0.121) data 0.001 (0.002) loss 0.8586 (0.8130) ce_loss 0.3872 (0.3569) teacher_loss 0.2805 (0.2301) loss_zs_kd 0.0858 (0.1087) loss_oracle 0.5352 (0.5286) acc 84.3750 (86.9196) kd_loss 1.0451 (0.9954) lr 6.9098e-04 eta 0:06:20
epoch [32/50] batch [160/173] time 0.115 (0.121) data 0.000 (0.002) loss 0.9605 (0.8125) ce_loss 0.5249 (0.3585) teacher_loss 0.3270 (0.2277) loss_zs_kd 0.1111 (0.1080) loss_oracle 0.5779 (0.5308) acc 78.1250 (86.9922) kd_loss 1.0899 (0.9993) lr 6.9098e-04 eta 0:06:19
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,295
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.8%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,012
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.2%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [33/50] batch [20/173] time 0.117 (0.137) data 0.000 (0.015) loss 0.8136 (0.8392) ce_loss 0.3938 (0.3853) teacher_loss 0.2120 (0.2404) loss_zs_kd 0.1590 (0.1210) loss_oracle 0.5221 (0.5383) acc 78.1250 (85.9375) kd_loss 0.9162 (0.9993) lr 6.3188e-04 eta 0:07:02
epoch [33/50] batch [40/173] time 0.089 (0.128) data 0.000 (0.008) loss 0.7477 (0.8442) ce_loss 0.2043 (0.3903) teacher_loss 0.0635 (0.2225) loss_zs_kd 0.1190 (0.1326) loss_oracle 0.6247 (0.5554) acc 90.6250 (85.3125) kd_loss 1.0645 (0.9996) lr 6.3188e-04 eta 0:06:34
epoch [33/50] batch [60/173] time 0.140 (0.126) data 0.001 (0.005) loss 1.0019 (0.8396) ce_loss 0.5684 (0.3906) teacher_loss 0.3019 (0.2184) loss_zs_kd 0.1182 (0.1308) loss_oracle 0.6409 (0.5558) acc 75.0000 (85.2083) kd_loss 1.1544 (0.9936) lr 6.3188e-04 eta 0:06:25
epoch [33/50] batch [80/173] time 0.139 (0.124) data 0.000 (0.004) loss 0.7641 (0.8359) ce_loss 0.2971 (0.3911) teacher_loss 0.1853 (0.2181) loss_zs_kd 0.0957 (0.1282) loss_oracle 0.5310 (0.5537) acc 90.6250 (85.5078) kd_loss 1.0152 (0.9899) lr 6.3188e-04 eta 0:06:16
epoch [33/50] batch [100/173] time 0.145 (0.125) data 0.000 (0.003) loss 0.6803 (0.8268) ce_loss 0.3110 (0.3853) teacher_loss 0.1405 (0.2154) loss_zs_kd 0.1760 (0.1279) loss_oracle 0.4518 (0.5475) acc 87.5000 (85.7812) kd_loss 0.8304 (0.9733) lr 6.3188e-04 eta 0:06:16
epoch [33/50] batch [120/173] time 0.190 (0.129) data 0.000 (0.003) loss 1.0039 (0.8201) ce_loss 0.6050 (0.3866) teacher_loss 0.5155 (0.2186) loss_zs_kd 0.1261 (0.1273) loss_oracle 0.4254 (0.5379) acc 75.0000 (85.6510) kd_loss 0.8223 (0.9588) lr 6.3188e-04 eta 0:06:26
epoch [33/50] batch [140/173] time 0.168 (0.131) data 0.000 (0.002) loss 0.6646 (0.8121) ce_loss 0.3254 (0.3847) teacher_loss 0.1745 (0.2207) loss_zs_kd 0.1045 (0.1249) loss_oracle 0.4379 (0.5290) acc 81.2500 (85.6696) kd_loss 0.7929 (0.9449) lr 6.3188e-04 eta 0:06:29
epoch [33/50] batch [160/173] time 0.076 (0.134) data 0.000 (0.002) loss 0.7647 (0.8016) ce_loss 0.3962 (0.3752) teacher_loss 0.2395 (0.2200) loss_zs_kd 0.0922 (0.1228) loss_oracle 0.4792 (0.5203) acc 84.3750 (86.0352) kd_loss 0.9062 (0.9307) lr 6.3188e-04 eta 0:06:34
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,283
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,011
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.1%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [34/50] batch [20/173] time 0.130 (0.126) data 0.000 (0.011) loss 0.5819 (0.7515) ce_loss 0.2345 (0.3558) teacher_loss 0.1395 (0.2481) loss_zs_kd 0.0759 (0.0924) loss_oracle 0.4044 (0.4571) acc 93.7500 (86.4062) kd_loss 0.9265 (0.8321) lr 5.7422e-04 eta 0:06:08
epoch [34/50] batch [40/173] time 0.140 (0.119) data 0.000 (0.005) loss 0.8795 (0.7397) ce_loss 0.4412 (0.3411) teacher_loss 0.3505 (0.2367) loss_zs_kd 0.1406 (0.0934) loss_oracle 0.4587 (0.4563) acc 84.3750 (86.9531) kd_loss 0.8479 (0.8472) lr 5.7422e-04 eta 0:05:45
epoch [34/50] batch [60/173] time 0.082 (0.115) data 0.000 (0.004) loss 0.5912 (0.7364) ce_loss 0.1519 (0.3403) teacher_loss 0.1097 (0.2288) loss_zs_kd 0.0783 (0.0952) loss_oracle 0.4424 (0.4600) acc 93.7500 (86.8750) kd_loss 0.8016 (0.8568) lr 5.7422e-04 eta 0:05:31
epoch [34/50] batch [80/173] time 0.100 (0.114) data 0.000 (0.003) loss 0.7824 (0.7458) ce_loss 0.3767 (0.3453) teacher_loss 0.2191 (0.2334) loss_zs_kd 0.1099 (0.0987) loss_oracle 0.5084 (0.4631) acc 84.3750 (86.7969) kd_loss 0.9417 (0.8657) lr 5.7422e-04 eta 0:05:26
epoch [34/50] batch [100/173] time 0.082 (0.113) data 0.000 (0.002) loss 0.8308 (0.7424) ce_loss 0.4460 (0.3404) teacher_loss 0.3033 (0.2313) loss_zs_kd 0.1156 (0.0990) loss_oracle 0.4696 (0.4616) acc 78.1250 (86.7500) kd_loss 0.8427 (0.8582) lr 5.7422e-04 eta 0:05:21
epoch [34/50] batch [120/173] time 0.086 (0.112) data 0.000 (0.002) loss 0.6570 (0.7441) ce_loss 0.2384 (0.3377) teacher_loss 0.1495 (0.2311) loss_zs_kd 0.0895 (0.1001) loss_oracle 0.4628 (0.4630) acc 90.6250 (87.0052) kd_loss 0.7486 (0.8491) lr 5.7422e-04 eta 0:05:15
epoch [34/50] batch [140/173] time 0.108 (0.111) data 0.000 (0.002) loss 0.5821 (0.7439) ce_loss 0.2264 (0.3364) teacher_loss 0.1329 (0.2323) loss_zs_kd 0.0608 (0.0985) loss_oracle 0.4189 (0.4623) acc 93.7500 (87.0982) kd_loss 0.8055 (0.8401) lr 5.7422e-04 eta 0:05:10
epoch [34/50] batch [160/173] time 0.082 (0.110) data 0.000 (0.002) loss 0.7088 (0.7396) ce_loss 0.2751 (0.3316) teacher_loss 0.1735 (0.2295) loss_zs_kd 0.0814 (0.0974) loss_oracle 0.4947 (0.4614) acc 87.5000 (87.3633) kd_loss 0.7653 (0.8291) lr 5.7422e-04 eta 0:05:07
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,294
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [35/50] batch [20/173] time 0.088 (0.124) data 0.000 (0.013) loss 0.7721 (0.7240) ce_loss 0.4539 (0.3246) teacher_loss 0.3561 (0.2289) loss_zs_kd 0.0894 (0.1016) loss_oracle 0.3712 (0.4443) acc 81.2500 (87.8125) kd_loss 0.7043 (0.7593) lr 5.1825e-04 eta 0:05:39
epoch [35/50] batch [40/173] time 0.132 (0.113) data 0.000 (0.007) loss 0.7833 (0.7245) ce_loss 0.4771 (0.3451) teacher_loss 0.2248 (0.2393) loss_zs_kd 0.1693 (0.1013) loss_oracle 0.4738 (0.4345) acc 87.5000 (87.1094) kd_loss 0.8648 (0.7736) lr 5.1825e-04 eta 0:05:08
epoch [35/50] batch [60/173] time 0.101 (0.109) data 0.000 (0.004) loss 0.6157 (0.7172) ce_loss 0.2510 (0.3383) teacher_loss 0.1796 (0.2324) loss_zs_kd 0.0896 (0.1010) loss_oracle 0.3913 (0.4343) acc 93.7500 (87.3438) kd_loss 0.7594 (0.7886) lr 5.1825e-04 eta 0:04:54
epoch [35/50] batch [80/173] time 0.132 (0.108) data 0.000 (0.003) loss 0.7972 (0.7269) ce_loss 0.4348 (0.3509) teacher_loss 0.2845 (0.2410) loss_zs_kd 0.1033 (0.1000) loss_oracle 0.4610 (0.4359) acc 81.2500 (86.8750) kd_loss 0.7865 (0.7959) lr 5.1825e-04 eta 0:04:49
epoch [35/50] batch [100/173] time 0.085 (0.108) data 0.000 (0.003) loss 0.6917 (0.7348) ce_loss 0.2952 (0.3600) teacher_loss 0.2317 (0.2490) loss_zs_kd 0.0941 (0.1006) loss_oracle 0.4130 (0.4356) acc 90.6250 (86.4375) kd_loss 0.8969 (0.8021) lr 5.1825e-04 eta 0:04:48
epoch [35/50] batch [120/173] time 0.075 (0.106) data 0.000 (0.002) loss 0.6637 (0.7351) ce_loss 0.2230 (0.3628) teacher_loss 0.1621 (0.2458) loss_zs_kd 0.0879 (0.1030) loss_oracle 0.4577 (0.4378) acc 90.6250 (86.1719) kd_loss 0.8539 (0.8087) lr 5.1825e-04 eta 0:04:40
epoch [35/50] batch [140/173] time 0.183 (0.115) data 0.000 (0.002) loss 0.7323 (0.7388) ce_loss 0.3352 (0.3656) teacher_loss 0.2317 (0.2470) loss_zs_kd 0.1283 (0.1036) loss_oracle 0.4364 (0.4400) acc 93.7500 (86.0938) kd_loss 0.9031 (0.8149) lr 5.1825e-04 eta 0:05:02
epoch [35/50] batch [160/173] time 0.187 (0.118) data 0.000 (0.002) loss 0.5333 (0.7348) ce_loss 0.1530 (0.3586) teacher_loss 0.1007 (0.2421) loss_zs_kd 0.0547 (0.1026) loss_oracle 0.4053 (0.4414) acc 96.8750 (86.3477) kd_loss 0.8559 (0.8243) lr 5.1825e-04 eta 0:05:08
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,287
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [36/50] batch [20/173] time 0.079 (0.121) data 0.000 (0.010) loss 0.7103 (0.7269) ce_loss 0.3882 (0.4110) teacher_loss 0.2843 (0.2490) loss_zs_kd 0.1084 (0.1063) loss_oracle 0.3718 (0.4248) acc 81.2500 (84.5312) kd_loss 0.8743 (0.8552) lr 4.6417e-04 eta 0:05:11
epoch [36/50] batch [40/173] time 0.089 (0.117) data 0.000 (0.005) loss 0.7464 (0.7162) ce_loss 0.4504 (0.3811) teacher_loss 0.2278 (0.2274) loss_zs_kd 0.1200 (0.1121) loss_oracle 0.4586 (0.4328) acc 87.5000 (85.6250) kd_loss 0.8174 (0.8610) lr 4.6417e-04 eta 0:04:58
epoch [36/50] batch [60/173] time 0.109 (0.116) data 0.001 (0.004) loss 0.7938 (0.7001) ce_loss 0.4795 (0.3487) teacher_loss 0.3358 (0.2147) loss_zs_kd 0.1120 (0.1063) loss_oracle 0.4020 (0.4323) acc 75.0000 (86.7708) kd_loss 0.9284 (0.8519) lr 4.6417e-04 eta 0:04:54
epoch [36/50] batch [80/173] time 0.086 (0.115) data 0.000 (0.003) loss 0.5666 (0.6959) ce_loss 0.1676 (0.3494) teacher_loss 0.0819 (0.2123) loss_zs_kd 0.0846 (0.1045) loss_oracle 0.4424 (0.4314) acc 93.7500 (86.4062) kd_loss 0.7523 (0.8446) lr 4.6417e-04 eta 0:04:49
epoch [36/50] batch [100/173] time 0.081 (0.115) data 0.000 (0.002) loss 0.7658 (0.6953) ce_loss 0.4873 (0.3478) teacher_loss 0.3408 (0.2151) loss_zs_kd 0.1123 (0.1032) loss_oracle 0.3689 (0.4286) acc 84.3750 (86.7188) kd_loss 0.8638 (0.8392) lr 4.6417e-04 eta 0:04:45
epoch [36/50] batch [120/173] time 0.132 (0.114) data 0.000 (0.002) loss 0.6978 (0.6943) ce_loss 0.3142 (0.3499) teacher_loss 0.2495 (0.2190) loss_zs_kd 0.1267 (0.1019) loss_oracle 0.3850 (0.4243) acc 81.2500 (86.9271) kd_loss 0.7535 (0.8317) lr 4.6417e-04 eta 0:04:42
epoch [36/50] batch [140/173] time 0.140 (0.113) data 0.000 (0.002) loss 0.7542 (0.6918) ce_loss 0.3416 (0.3501) teacher_loss 0.2640 (0.2192) loss_zs_kd 0.1281 (0.1009) loss_oracle 0.4262 (0.4222) acc 84.3750 (86.8750) kd_loss 0.8011 (0.8314) lr 4.6417e-04 eta 0:04:38
epoch [36/50] batch [160/173] time 0.079 (0.112) data 0.000 (0.002) loss 0.6200 (0.6901) ce_loss 0.3877 (0.3519) teacher_loss 0.1611 (0.2196) loss_zs_kd 0.1022 (0.1012) loss_oracle 0.4078 (0.4198) acc 87.5000 (86.7969) kd_loss 0.8611 (0.8289) lr 4.6417e-04 eta 0:04:33
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,289
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,011
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 98.1%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [37/50] batch [20/173] time 0.144 (0.144) data 0.000 (0.011) loss 0.6701 (0.7417) ce_loss 0.2637 (0.3968) teacher_loss 0.1440 (0.2612) loss_zs_kd 0.1021 (0.1212) loss_oracle 0.4750 (0.4199) acc 93.7500 (85.6250) kd_loss 0.9174 (0.8576) lr 4.1221e-04 eta 0:05:44
epoch [37/50] batch [40/173] time 0.102 (0.136) data 0.000 (0.005) loss 0.6551 (0.7095) ce_loss 0.3079 (0.3686) teacher_loss 0.1589 (0.2431) loss_zs_kd 0.0856 (0.1112) loss_oracle 0.4534 (0.4107) acc 87.5000 (86.8750) kd_loss 0.8414 (0.8383) lr 4.1221e-04 eta 0:05:24
epoch [37/50] batch [60/173] time 0.095 (0.131) data 0.001 (0.004) loss 0.7135 (0.7260) ce_loss 0.1980 (0.3818) teacher_loss 0.1696 (0.2406) loss_zs_kd 0.1037 (0.1134) loss_oracle 0.4920 (0.4287) acc 93.7500 (86.4062) kd_loss 0.9239 (0.8548) lr 4.1221e-04 eta 0:05:09
epoch [37/50] batch [80/173] time 0.143 (0.130) data 0.000 (0.003) loss 0.7207 (0.7287) ce_loss 0.3049 (0.3760) teacher_loss 0.1377 (0.2245) loss_zs_kd 0.0918 (0.1148) loss_oracle 0.5370 (0.4468) acc 87.5000 (86.5234) kd_loss 0.9829 (0.8647) lr 4.1221e-04 eta 0:05:04
epoch [37/50] batch [100/173] time 0.086 (0.130) data 0.000 (0.002) loss 0.9065 (0.7447) ce_loss 0.4241 (0.3790) teacher_loss 0.1943 (0.2234) loss_zs_kd 0.1647 (0.1164) loss_oracle 0.6299 (0.4631) acc 78.1250 (86.2500) kd_loss 1.1054 (0.8786) lr 4.1221e-04 eta 0:05:01
epoch [37/50] batch [120/173] time 0.187 (0.136) data 0.000 (0.002) loss 0.7067 (0.7549) ce_loss 0.2291 (0.3781) teacher_loss 0.1418 (0.2217) loss_zs_kd 0.0953 (0.1177) loss_oracle 0.5173 (0.4743) acc 87.5000 (86.3021) kd_loss 0.9136 (0.8861) lr 4.1221e-04 eta 0:05:13
epoch [37/50] batch [140/173] time 0.188 (0.137) data 0.000 (0.002) loss 0.7738 (0.7631) ce_loss 0.2247 (0.3819) teacher_loss 0.1833 (0.2210) loss_zs_kd 0.1373 (0.1189) loss_oracle 0.5219 (0.4826) acc 96.8750 (86.3393) kd_loss 0.8959 (0.8934) lr 4.1221e-04 eta 0:05:13
epoch [37/50] batch [160/173] time 0.082 (0.137) data 0.000 (0.002) loss 0.8133 (0.7655) ce_loss 0.4119 (0.3780) teacher_loss 0.1657 (0.2170) loss_zs_kd 0.1297 (0.1187) loss_oracle 0.5827 (0.4891) acc 81.2500 (86.3086) kd_loss 0.9415 (0.8980) lr 4.1221e-04 eta 0:05:10
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [38/50] batch [20/173] time 0.086 (0.122) data 0.000 (0.012) loss 1.0628 (0.8233) ce_loss 0.4731 (0.3494) teacher_loss 0.3279 (0.1980) loss_zs_kd 0.1207 (0.1211) loss_oracle 0.6746 (0.5647) acc 84.3750 (86.8750) kd_loss 0.9890 (0.9570) lr 3.6258e-04 eta 0:04:31
epoch [38/50] batch [40/173] time 0.128 (0.116) data 0.000 (0.006) loss 0.8736 (0.8386) ce_loss 0.5894 (0.3937) teacher_loss 0.2186 (0.2188) loss_zs_kd 0.1382 (0.1251) loss_oracle 0.5859 (0.5572) acc 71.8750 (84.8438) kd_loss 1.0289 (0.9661) lr 3.6258e-04 eta 0:04:16
epoch [38/50] batch [60/173] time 0.103 (0.115) data 0.000 (0.004) loss 0.8861 (0.8184) ce_loss 0.5005 (0.3697) teacher_loss 0.2543 (0.2034) loss_zs_kd 0.1231 (0.1241) loss_oracle 0.5702 (0.5530) acc 75.0000 (85.5208) kd_loss 1.0648 (0.9626) lr 3.6258e-04 eta 0:04:11
epoch [38/50] batch [80/173] time 0.113 (0.114) data 0.000 (0.003) loss 0.9082 (0.8306) ce_loss 0.4692 (0.3824) teacher_loss 0.2754 (0.2065) loss_zs_kd 0.1288 (0.1271) loss_oracle 0.5684 (0.5606) acc 84.3750 (85.5078) kd_loss 0.9139 (0.9685) lr 3.6258e-04 eta 0:04:07
epoch [38/50] batch [100/173] time 0.074 (0.113) data 0.000 (0.003) loss 1.1183 (0.8365) ce_loss 0.5483 (0.3829) teacher_loss 0.3221 (0.2039) loss_zs_kd 0.1205 (0.1275) loss_oracle 0.7360 (0.5688) acc 84.3750 (85.7188) kd_loss 1.0825 (0.9660) lr 3.6258e-04 eta 0:04:02
epoch [38/50] batch [120/173] time 0.143 (0.111) data 0.000 (0.002) loss 0.6635 (0.8430) ce_loss 0.1434 (0.3772) teacher_loss 0.0740 (0.2023) loss_zs_kd 0.1021 (0.1287) loss_oracle 0.5385 (0.5763) acc 93.7500 (86.0417) kd_loss 0.9101 (0.9701) lr 3.6258e-04 eta 0:03:56
epoch [38/50] batch [140/173] time 0.087 (0.110) data 0.000 (0.002) loss 0.7958 (0.8487) ce_loss 0.2190 (0.3736) teacher_loss 0.1276 (0.2030) loss_zs_kd 0.0653 (0.1269) loss_oracle 0.6355 (0.5822) acc 93.7500 (86.1607) kd_loss 1.0354 (0.9743) lr 3.6258e-04 eta 0:03:51
epoch [38/50] batch [160/173] time 0.085 (0.109) data 0.000 (0.002) loss 0.9887 (0.8499) ce_loss 0.4812 (0.3767) teacher_loss 0.2415 (0.2037) loss_zs_kd 0.0976 (0.1261) loss_oracle 0.6984 (0.5831) acc 87.5000 (86.1719) kd_loss 1.1221 (0.9776) lr 3.6258e-04 eta 0:03:48
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [39/50] batch [20/173] time 0.142 (0.125) data 0.000 (0.015) loss 0.9128 (0.8530) ce_loss 0.4114 (0.3445) teacher_loss 0.2288 (0.1773) loss_zs_kd 0.1289 (0.1220) loss_oracle 0.6196 (0.6146) acc 84.3750 (87.3438) kd_loss 0.9844 (1.0080) lr 3.1545e-04 eta 0:04:16
epoch [39/50] batch [40/173] time 0.086 (0.120) data 0.000 (0.007) loss 0.9618 (0.8686) ce_loss 0.4102 (0.3430) teacher_loss 0.2944 (0.1819) loss_zs_kd 0.1625 (0.1260) loss_oracle 0.5861 (0.6237) acc 84.3750 (87.6562) kd_loss 1.0951 (1.0211) lr 3.1545e-04 eta 0:04:04
epoch [39/50] batch [60/173] time 0.088 (0.115) data 0.000 (0.005) loss 0.7292 (0.8660) ce_loss 0.2500 (0.3471) teacher_loss 0.1463 (0.1778) loss_zs_kd 0.0690 (0.1296) loss_oracle 0.5484 (0.6234) acc 90.6250 (87.5000) kd_loss 0.9778 (1.0310) lr 3.1545e-04 eta 0:03:52
epoch [39/50] batch [80/173] time 0.119 (0.115) data 0.000 (0.004) loss 0.8735 (0.8673) ce_loss 0.4155 (0.3575) teacher_loss 0.2511 (0.1826) loss_zs_kd 0.0994 (0.1284) loss_oracle 0.5727 (0.6205) acc 84.3750 (86.9531) kd_loss 1.0008 (1.0282) lr 3.1545e-04 eta 0:03:49
epoch [39/50] batch [100/173] time 0.097 (0.113) data 0.000 (0.003) loss 0.9625 (0.8607) ce_loss 0.4998 (0.3563) teacher_loss 0.3160 (0.1837) loss_zs_kd 0.1345 (0.1260) loss_oracle 0.5793 (0.6140) acc 87.5000 (87.0938) kd_loss 0.9862 (1.0200) lr 3.1545e-04 eta 0:03:44
epoch [39/50] batch [120/173] time 0.175 (0.112) data 0.000 (0.003) loss 0.8188 (0.8572) ce_loss 0.4800 (0.3568) teacher_loss 0.1800 (0.1821) loss_zs_kd 0.1075 (0.1257) loss_oracle 0.5850 (0.6123) acc 75.0000 (86.9010) kd_loss 1.0034 (1.0171) lr 3.1545e-04 eta 0:03:38
epoch [39/50] batch [140/173] time 0.083 (0.117) data 0.000 (0.002) loss 0.8183 (0.8614) ce_loss 0.2854 (0.3655) teacher_loss 0.2019 (0.1880) loss_zs_kd 0.1200 (0.1264) loss_oracle 0.5564 (0.6102) acc 90.6250 (86.4955) kd_loss 0.9718 (1.0111) lr 3.1545e-04 eta 0:03:46
epoch [39/50] batch [160/173] time 0.145 (0.122) data 0.000 (0.002) loss 0.9717 (0.8567) ce_loss 0.4846 (0.3642) teacher_loss 0.2953 (0.1871) loss_zs_kd 0.1462 (0.1257) loss_oracle 0.6033 (0.6067) acc 81.2500 (86.4648) kd_loss 0.9808 (1.0059) lr 3.1545e-04 eta 0:03:54
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,006
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 97.9%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [40/50] batch [20/173] time 0.087 (0.134) data 0.000 (0.011) loss 0.8289 (0.8220) ce_loss 0.3013 (0.3275) teacher_loss 0.1240 (0.1773) loss_zs_kd 0.1111 (0.1145) loss_oracle 0.6493 (0.5875) acc 90.6250 (87.6562) kd_loss 1.0233 (0.9752) lr 2.7103e-04 eta 0:04:12
epoch [40/50] batch [40/173] time 0.084 (0.120) data 0.000 (0.005) loss 0.9102 (0.8071) ce_loss 0.5024 (0.3466) teacher_loss 0.2187 (0.1800) loss_zs_kd 0.1682 (0.1151) loss_oracle 0.6073 (0.5696) acc 81.2500 (87.3438) kd_loss 0.9878 (0.9632) lr 2.7103e-04 eta 0:03:44
epoch [40/50] batch [60/173] time 0.080 (0.116) data 0.001 (0.004) loss 0.8147 (0.8219) ce_loss 0.3831 (0.3474) teacher_loss 0.1331 (0.1866) loss_zs_kd 0.1338 (0.1194) loss_oracle 0.6147 (0.5757) acc 84.3750 (87.1354) kd_loss 0.9904 (0.9682) lr 2.7103e-04 eta 0:03:33
epoch [40/50] batch [80/173] time 0.131 (0.114) data 0.000 (0.003) loss 0.7384 (0.8253) ce_loss 0.4531 (0.3540) teacher_loss 0.1909 (0.1846) loss_zs_kd 0.1313 (0.1199) loss_oracle 0.4819 (0.5807) acc 78.1250 (86.8750) kd_loss 0.8955 (0.9727) lr 2.7103e-04 eta 0:03:28
epoch [40/50] batch [100/173] time 0.102 (0.114) data 0.000 (0.002) loss 0.9109 (0.8188) ce_loss 0.4387 (0.3514) teacher_loss 0.2781 (0.1839) loss_zs_kd 0.1293 (0.1223) loss_oracle 0.5682 (0.5738) acc 84.3750 (86.8750) kd_loss 1.0335 (0.9666) lr 2.7103e-04 eta 0:03:25
epoch [40/50] batch [120/173] time 0.132 (0.113) data 0.000 (0.002) loss 0.6904 (0.8205) ce_loss 0.2424 (0.3592) teacher_loss 0.1013 (0.1849) loss_zs_kd 0.1001 (0.1238) loss_oracle 0.5390 (0.5737) acc 93.7500 (86.8229) kd_loss 0.9738 (0.9661) lr 2.7103e-04 eta 0:03:21
epoch [40/50] batch [140/173] time 0.131 (0.112) data 0.000 (0.002) loss 1.0257 (0.8223) ce_loss 0.6133 (0.3585) teacher_loss 0.3161 (0.1841) loss_zs_kd 0.1686 (0.1250) loss_oracle 0.6253 (0.5758) acc 75.0000 (86.8527) kd_loss 1.0137 (0.9664) lr 2.7103e-04 eta 0:03:17
epoch [40/50] batch [160/173] time 0.080 (0.112) data 0.000 (0.002) loss 0.9294 (0.8209) ce_loss 0.5781 (0.3628) teacher_loss 0.2945 (0.1848) loss_zs_kd 0.2165 (0.1260) loss_oracle 0.5266 (0.5730) acc 84.3750 (86.7383) kd_loss 0.8933 (0.9615) lr 2.7103e-04 eta 0:03:14
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,007
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 97.9%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [41/50] batch [20/173] time 0.147 (0.137) data 0.000 (0.010) loss 0.9523 (0.8691) ce_loss 0.3889 (0.3583) teacher_loss 0.2020 (0.1928) loss_zs_kd 0.1164 (0.1212) loss_oracle 0.6921 (0.6157) acc 84.3750 (86.4062) kd_loss 1.1337 (1.0079) lr 2.2949e-04 eta 0:03:54
epoch [41/50] batch [40/173] time 0.125 (0.123) data 0.000 (0.005) loss 1.0679 (0.8357) ce_loss 0.6172 (0.3730) teacher_loss 0.3268 (0.1911) loss_zs_kd 0.2079 (0.1324) loss_oracle 0.6372 (0.5785) acc 81.2500 (86.1719) kd_loss 1.0805 (0.9776) lr 2.2949e-04 eta 0:03:27
epoch [41/50] batch [60/173] time 0.141 (0.122) data 0.001 (0.004) loss 0.8936 (0.8289) ce_loss 0.4333 (0.3694) teacher_loss 0.1788 (0.1901) loss_zs_kd 0.1674 (0.1300) loss_oracle 0.6311 (0.5738) acc 84.3750 (86.5104) kd_loss 1.0130 (0.9686) lr 2.2949e-04 eta 0:03:23
epoch [41/50] batch [80/173] time 0.133 (0.120) data 0.000 (0.003) loss 0.7196 (0.8249) ce_loss 0.2625 (0.3669) teacher_loss 0.1616 (0.1877) loss_zs_kd 0.1244 (0.1295) loss_oracle 0.4958 (0.5725) acc 90.6250 (86.7188) kd_loss 0.9078 (0.9685) lr 2.2949e-04 eta 0:03:17
epoch [41/50] batch [100/173] time 0.144 (0.120) data 0.000 (0.002) loss 1.1305 (0.8289) ce_loss 0.6299 (0.3652) teacher_loss 0.3920 (0.1881) loss_zs_kd 0.1698 (0.1308) loss_oracle 0.6537 (0.5754) acc 71.8750 (86.7500) kd_loss 0.9760 (0.9714) lr 2.2949e-04 eta 0:03:15
epoch [41/50] batch [120/173] time 0.155 (0.117) data 0.000 (0.002) loss 1.1421 (0.8225) ce_loss 0.5894 (0.3624) teacher_loss 0.2639 (0.1850) loss_zs_kd 0.1529 (0.1291) loss_oracle 0.8018 (0.5729) acc 78.1250 (86.7448) kd_loss 1.2249 (0.9676) lr 2.2949e-04 eta 0:03:08
epoch [41/50] batch [140/173] time 0.076 (0.124) data 0.000 (0.002) loss 0.8358 (0.8163) ce_loss 0.3555 (0.3607) teacher_loss 0.2148 (0.1834) loss_zs_kd 0.1419 (0.1274) loss_oracle 0.5500 (0.5692) acc 90.6250 (86.7634) kd_loss 1.0065 (0.9646) lr 2.2949e-04 eta 0:03:16
epoch [41/50] batch [160/173] time 0.187 (0.129) data 0.000 (0.002) loss 0.9484 (0.8153) ce_loss 0.5425 (0.3608) teacher_loss 0.2494 (0.1835) loss_zs_kd 0.1002 (0.1271) loss_oracle 0.6489 (0.5682) acc 78.1250 (86.9141) kd_loss 0.9548 (0.9635) lr 2.2949e-04 eta 0:03:22
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,283
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [42/50] batch [20/173] time 0.139 (0.135) data 0.000 (0.017) loss 0.6062 (0.7661) ce_loss 0.1565 (0.2943) teacher_loss 0.0844 (0.1525) loss_zs_kd 0.0688 (0.1074) loss_oracle 0.4874 (0.5599) acc 93.7500 (90.0000) kd_loss 0.8498 (0.9501) lr 1.9098e-04 eta 0:03:27
epoch [42/50] batch [40/173] time 0.081 (0.127) data 0.000 (0.009) loss 0.8186 (0.7648) ce_loss 0.3242 (0.3011) teacher_loss 0.1965 (0.1518) loss_zs_kd 0.0949 (0.1110) loss_oracle 0.5746 (0.5575) acc 90.6250 (88.9844) kd_loss 0.9039 (0.9494) lr 1.9098e-04 eta 0:03:12
epoch [42/50] batch [60/173] time 0.123 (0.125) data 0.000 (0.006) loss 0.9179 (0.7780) ce_loss 0.4246 (0.3165) teacher_loss 0.2550 (0.1646) loss_zs_kd 0.0928 (0.1098) loss_oracle 0.6166 (0.5585) acc 87.5000 (88.3854) kd_loss 0.9195 (0.9505) lr 1.9098e-04 eta 0:03:06
epoch [42/50] batch [80/173] time 0.137 (0.123) data 0.000 (0.004) loss 0.7162 (0.7696) ce_loss 0.3130 (0.3128) teacher_loss 0.1768 (0.1612) loss_zs_kd 0.0953 (0.1097) loss_oracle 0.4918 (0.5535) acc 93.7500 (88.3984) kd_loss 0.8853 (0.9470) lr 1.9098e-04 eta 0:03:01
epoch [42/50] batch [100/173] time 0.109 (0.121) data 0.000 (0.004) loss 0.8675 (0.7779) ce_loss 0.4680 (0.3270) teacher_loss 0.1585 (0.1699) loss_zs_kd 0.1347 (0.1124) loss_oracle 0.6417 (0.5518) acc 81.2500 (87.5000) kd_loss 1.0881 (0.9493) lr 1.9098e-04 eta 0:02:55
epoch [42/50] batch [120/173] time 0.084 (0.119) data 0.000 (0.003) loss 1.0421 (0.7808) ce_loss 0.5122 (0.3359) teacher_loss 0.2510 (0.1734) loss_zs_kd 0.1492 (0.1163) loss_oracle 0.7165 (0.5493) acc 75.0000 (87.2135) kd_loss 1.1327 (0.9487) lr 1.9098e-04 eta 0:02:50
epoch [42/50] batch [140/173] time 0.086 (0.118) data 0.000 (0.003) loss 0.6663 (0.7807) ce_loss 0.1899 (0.3409) teacher_loss 0.1352 (0.1754) loss_zs_kd 0.1037 (0.1179) loss_oracle 0.4792 (0.5463) acc 90.6250 (87.0089) kd_loss 0.8958 (0.9474) lr 1.9098e-04 eta 0:02:46
epoch [42/50] batch [160/173] time 0.091 (0.117) data 0.000 (0.002) loss 0.8016 (0.7837) ce_loss 0.4417 (0.3475) teacher_loss 0.3029 (0.1756) loss_zs_kd 0.1589 (0.1203) loss_oracle 0.4193 (0.5479) acc 78.1250 (86.8945) kd_loss 0.8985 (0.9496) lr 1.9098e-04 eta 0:02:43
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,287
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [43/50] batch [20/173] time 0.133 (0.137) data 0.000 (0.015) loss 0.6133 (0.8026) ce_loss 0.2163 (0.3800) teacher_loss 0.1208 (0.1976) loss_zs_kd 0.0857 (0.1339) loss_oracle 0.4497 (0.5381) acc 90.6250 (85.1562) kd_loss 0.8615 (0.9323) lr 1.5567e-04 eta 0:03:06
epoch [43/50] batch [40/173] time 0.135 (0.127) data 0.000 (0.008) loss 0.8169 (0.7857) ce_loss 0.2634 (0.3686) teacher_loss 0.1600 (0.1804) loss_zs_kd 0.1670 (0.1332) loss_oracle 0.5734 (0.5387) acc 90.6250 (86.4062) kd_loss 0.9886 (0.9328) lr 1.5567e-04 eta 0:02:50
epoch [43/50] batch [60/173] time 0.132 (0.122) data 0.000 (0.005) loss 1.2453 (0.7730) ce_loss 0.9062 (0.3529) teacher_loss 0.5736 (0.1741) loss_zs_kd 0.2110 (0.1304) loss_oracle 0.5662 (0.5337) acc 68.7500 (86.9271) kd_loss 0.9412 (0.9235) lr 1.5567e-04 eta 0:02:41
epoch [43/50] batch [80/173] time 0.071 (0.118) data 0.000 (0.004) loss 0.8338 (0.7733) ce_loss 0.3210 (0.3541) teacher_loss 0.2147 (0.1747) loss_zs_kd 0.1484 (0.1322) loss_oracle 0.5450 (0.5325) acc 87.5000 (86.6406) kd_loss 0.9290 (0.9228) lr 1.5567e-04 eta 0:02:33
epoch [43/50] batch [100/173] time 0.083 (0.114) data 0.000 (0.003) loss 0.8187 (0.7743) ce_loss 0.4473 (0.3538) teacher_loss 0.1957 (0.1780) loss_zs_kd 0.1942 (0.1341) loss_oracle 0.5259 (0.5293) acc 90.6250 (86.7500) kd_loss 0.8517 (0.9199) lr 1.5567e-04 eta 0:02:26
epoch [43/50] batch [120/173] time 0.067 (0.123) data 0.000 (0.003) loss 0.6031 (0.7805) ce_loss 0.2192 (0.3602) teacher_loss 0.1027 (0.1828) loss_zs_kd 0.0983 (0.1333) loss_oracle 0.4512 (0.5311) acc 87.5000 (86.6146) kd_loss 0.8790 (0.9211) lr 1.5567e-04 eta 0:02:35
epoch [43/50] batch [140/173] time 0.162 (0.126) data 0.000 (0.002) loss 0.9276 (0.7730) ce_loss 0.5190 (0.3555) teacher_loss 0.2572 (0.1812) loss_zs_kd 0.1897 (0.1316) loss_oracle 0.5755 (0.5261) acc 84.3750 (87.0089) kd_loss 0.9300 (0.9179) lr 1.5567e-04 eta 0:02:37
epoch [43/50] batch [160/173] time 0.078 (0.126) data 0.000 (0.002) loss 0.6085 (0.7699) ce_loss 0.1923 (0.3557) teacher_loss 0.0934 (0.1805) loss_zs_kd 0.0960 (0.1312) loss_oracle 0.4671 (0.5238) acc 93.7500 (86.9141) kd_loss 0.9282 (0.9175) lr 1.5567e-04 eta 0:02:34
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,289
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [44/50] batch [20/173] time 0.104 (0.133) data 0.000 (0.012) loss 0.7969 (0.7702) ce_loss 0.5303 (0.3754) teacher_loss 0.2211 (0.1838) loss_zs_kd 0.1232 (0.1269) loss_oracle 0.5142 (0.5230) acc 81.2500 (86.5625) kd_loss 0.8948 (0.9187) lr 1.2369e-04 eta 0:02:38
epoch [44/50] batch [40/173] time 0.112 (0.127) data 0.000 (0.006) loss 0.7772 (0.7704) ce_loss 0.3923 (0.3806) teacher_loss 0.2316 (0.1878) loss_zs_kd 0.1085 (0.1321) loss_oracle 0.4914 (0.5165) acc 84.3750 (85.6250) kd_loss 0.9177 (0.9137) lr 1.2369e-04 eta 0:02:29
epoch [44/50] batch [60/173] time 0.096 (0.124) data 0.000 (0.004) loss 0.8228 (0.7607) ce_loss 0.4021 (0.3699) teacher_loss 0.1550 (0.1837) loss_zs_kd 0.1113 (0.1267) loss_oracle 0.6121 (0.5136) acc 87.5000 (86.0417) kd_loss 1.0186 (0.9135) lr 1.2369e-04 eta 0:02:22
epoch [44/50] batch [80/173] time 0.079 (0.123) data 0.000 (0.003) loss 0.9243 (0.7617) ce_loss 0.4768 (0.3685) teacher_loss 0.2405 (0.1857) loss_zs_kd 0.1528 (0.1264) loss_oracle 0.6073 (0.5128) acc 81.2500 (86.0938) kd_loss 1.0403 (0.9168) lr 1.2369e-04 eta 0:02:19
epoch [44/50] batch [100/173] time 0.137 (0.121) data 0.000 (0.003) loss 0.6499 (0.7660) ce_loss 0.3672 (0.3725) teacher_loss 0.1207 (0.1892) loss_zs_kd 0.1141 (0.1279) loss_oracle 0.4721 (0.5129) acc 87.5000 (85.7500) kd_loss 0.8825 (0.9145) lr 1.2369e-04 eta 0:02:14
epoch [44/50] batch [120/173] time 0.093 (0.119) data 0.000 (0.002) loss 0.6728 (0.7630) ce_loss 0.3699 (0.3693) teacher_loss 0.2178 (0.1882) loss_zs_kd 0.1129 (0.1272) loss_oracle 0.3985 (0.5113) acc 87.5000 (85.7812) kd_loss 0.7994 (0.9117) lr 1.2369e-04 eta 0:02:09
epoch [44/50] batch [140/173] time 0.099 (0.117) data 0.000 (0.002) loss 0.7424 (0.7681) ce_loss 0.2605 (0.3737) teacher_loss 0.1108 (0.1908) loss_zs_kd 0.1213 (0.1281) loss_oracle 0.5710 (0.5133) acc 87.5000 (85.7366) kd_loss 0.9964 (0.9137) lr 1.2369e-04 eta 0:02:05
epoch [44/50] batch [160/173] time 0.085 (0.116) data 0.000 (0.002) loss 0.9757 (0.7670) ce_loss 0.4810 (0.3692) teacher_loss 0.2676 (0.1883) loss_zs_kd 0.1646 (0.1277) loss_oracle 0.6259 (0.5149) acc 81.2500 (85.9570) kd_loss 0.9915 (0.9148) lr 1.2369e-04 eta 0:02:02
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,288
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [45/50] batch [20/173] time 0.137 (0.126) data 0.000 (0.013) loss 0.7344 (0.7405) ce_loss 0.3394 (0.3489) teacher_loss 0.1509 (0.1765) loss_zs_kd 0.1373 (0.1303) loss_oracle 0.5148 (0.4989) acc 93.7500 (87.0312) kd_loss 0.9722 (0.9082) lr 9.5173e-05 eta 0:02:08
epoch [45/50] batch [40/173] time 0.083 (0.119) data 0.000 (0.007) loss 0.7461 (0.7582) ce_loss 0.4666 (0.3654) teacher_loss 0.2478 (0.1919) loss_zs_kd 0.1729 (0.1328) loss_oracle 0.4118 (0.4998) acc 84.3750 (86.8750) kd_loss 0.8097 (0.9118) lr 9.5173e-05 eta 0:01:58
epoch [45/50] batch [60/173] time 0.083 (0.117) data 0.000 (0.004) loss 0.6797 (0.7670) ce_loss 0.2949 (0.3728) teacher_loss 0.1773 (0.1983) loss_zs_kd 0.1082 (0.1350) loss_oracle 0.4482 (0.5012) acc 90.6250 (86.4062) kd_loss 0.8838 (0.9156) lr 9.5173e-05 eta 0:01:54
epoch [45/50] batch [80/173] time 0.116 (0.115) data 0.000 (0.003) loss 0.6382 (0.7626) ce_loss 0.3013 (0.3622) teacher_loss 0.1724 (0.1932) loss_zs_kd 0.1376 (0.1318) loss_oracle 0.3970 (0.5034) acc 87.5000 (86.8359) kd_loss 0.9038 (0.9166) lr 9.5173e-05 eta 0:01:50
epoch [45/50] batch [100/173] time 0.152 (0.119) data 0.000 (0.003) loss 0.8635 (0.7513) ce_loss 0.5420 (0.3534) teacher_loss 0.2742 (0.1883) loss_zs_kd 0.1275 (0.1280) loss_oracle 0.5254 (0.4990) acc 78.1250 (87.1562) kd_loss 0.9160 (0.9111) lr 9.5173e-05 eta 0:01:51
epoch [45/50] batch [120/173] time 0.185 (0.123) data 0.000 (0.002) loss 0.8728 (0.7585) ce_loss 0.3176 (0.3631) teacher_loss 0.2380 (0.1937) loss_zs_kd 0.0770 (0.1287) loss_oracle 0.5962 (0.5005) acc 90.6250 (86.6406) kd_loss 0.9214 (0.9119) lr 9.5173e-05 eta 0:01:52
epoch [45/50] batch [140/173] time 0.063 (0.129) data 0.000 (0.002) loss 0.5652 (0.7547) ce_loss 0.1243 (0.3607) teacher_loss 0.0584 (0.1911) loss_zs_kd 0.0738 (0.1277) loss_oracle 0.4699 (0.4997) acc 93.7500 (86.7188) kd_loss 0.8276 (0.9106) lr 9.5173e-05 eta 0:01:56
epoch [45/50] batch [160/173] time 0.082 (0.126) data 0.000 (0.002) loss 0.7824 (0.7497) ce_loss 0.3652 (0.3555) teacher_loss 0.2803 (0.1885) loss_zs_kd 0.1464 (0.1264) loss_oracle 0.4289 (0.4979) acc 87.5000 (86.9336) kd_loss 0.8407 (0.9089) lr 9.5173e-05 eta 0:01:50
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,287
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,009
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [46/50] batch [20/173] time 0.088 (0.124) data 0.000 (0.010) loss 0.7191 (0.7662) ce_loss 0.2090 (0.3617) teacher_loss 0.1528 (0.1946) loss_zs_kd 0.0867 (0.1304) loss_oracle 0.5230 (0.5064) acc 90.6250 (86.4062) kd_loss 0.8635 (0.9050) lr 7.0224e-05 eta 0:01:44
epoch [46/50] batch [40/173] time 0.132 (0.119) data 0.000 (0.005) loss 0.8465 (0.7600) ce_loss 0.4053 (0.3486) teacher_loss 0.2508 (0.1858) loss_zs_kd 0.1425 (0.1303) loss_oracle 0.5245 (0.5090) acc 78.1250 (86.5625) kd_loss 0.9227 (0.9056) lr 7.0224e-05 eta 0:01:38
epoch [46/50] batch [60/173] time 0.118 (0.116) data 0.001 (0.004) loss 0.6787 (0.7516) ce_loss 0.2837 (0.3512) teacher_loss 0.1194 (0.1776) loss_zs_kd 0.1236 (0.1337) loss_oracle 0.4975 (0.5071) acc 87.5000 (86.3542) kd_loss 0.8927 (0.9090) lr 7.0224e-05 eta 0:01:33
epoch [46/50] batch [80/173] time 0.125 (0.115) data 0.000 (0.003) loss 0.6202 (0.7569) ce_loss 0.2325 (0.3553) teacher_loss 0.1924 (0.1805) loss_zs_kd 0.0684 (0.1314) loss_oracle 0.3936 (0.5107) acc 93.7500 (86.4062) kd_loss 0.8585 (0.9112) lr 7.0224e-05 eta 0:01:30
epoch [46/50] batch [100/173] time 0.111 (0.114) data 0.000 (0.002) loss 0.7675 (0.7505) ce_loss 0.4092 (0.3496) teacher_loss 0.1789 (0.1766) loss_zs_kd 0.1023 (0.1299) loss_oracle 0.5375 (0.5090) acc 90.6250 (86.8438) kd_loss 0.8849 (0.9112) lr 7.0224e-05 eta 0:01:26
epoch [46/50] batch [120/173] time 0.137 (0.113) data 0.000 (0.002) loss 0.7020 (0.7546) ce_loss 0.3064 (0.3569) teacher_loss 0.2033 (0.1801) loss_zs_kd 0.1233 (0.1313) loss_oracle 0.4370 (0.5088) acc 87.5000 (86.8490) kd_loss 0.8007 (0.9113) lr 7.0224e-05 eta 0:01:24
epoch [46/50] batch [140/173] time 0.110 (0.112) data 0.000 (0.002) loss 0.5739 (0.7501) ce_loss 0.1317 (0.3502) teacher_loss 0.0587 (0.1778) loss_zs_kd 0.1000 (0.1287) loss_oracle 0.4652 (0.5079) acc 96.8750 (87.0312) kd_loss 0.8466 (0.9099) lr 7.0224e-05 eta 0:01:21
epoch [46/50] batch [160/173] time 0.077 (0.112) data 0.000 (0.001) loss 0.9481 (0.7518) ce_loss 0.6279 (0.3530) teacher_loss 0.3182 (0.1792) loss_zs_kd 0.1981 (0.1294) loss_oracle 0.5308 (0.5080) acc 75.0000 (86.9141) kd_loss 0.9550 (0.9116) lr 7.0224e-05 eta 0:01:18
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [47/50] batch [20/173] time 0.134 (0.120) data 0.000 (0.013) loss 0.6901 (0.7318) ce_loss 0.2593 (0.3408) teacher_loss 0.1032 (0.1659) loss_zs_kd 0.1175 (0.1193) loss_oracle 0.5281 (0.5062) acc 93.7500 (86.8750) kd_loss 0.9734 (0.9170) lr 4.8943e-05 eta 0:01:20
epoch [47/50] batch [40/173] time 0.118 (0.111) data 0.000 (0.007) loss 1.0129 (0.7621) ce_loss 0.5420 (0.3647) teacher_loss 0.3277 (0.1801) loss_zs_kd 0.1787 (0.1256) loss_oracle 0.5959 (0.5192) acc 84.3750 (86.4844) kd_loss 0.9499 (0.9336) lr 4.8943e-05 eta 0:01:12
epoch [47/50] batch [60/173] time 0.141 (0.111) data 0.000 (0.004) loss 0.7412 (0.7561) ce_loss 0.4041 (0.3481) teacher_loss 0.1731 (0.1781) loss_zs_kd 0.1272 (0.1243) loss_oracle 0.5045 (0.5158) acc 84.3750 (87.1875) kd_loss 0.8960 (0.9283) lr 4.8943e-05 eta 0:01:10
epoch [47/50] batch [80/173] time 0.081 (0.107) data 0.000 (0.003) loss 0.8188 (0.7545) ce_loss 0.2622 (0.3475) teacher_loss 0.1645 (0.1741) loss_zs_kd 0.1155 (0.1227) loss_oracle 0.5966 (0.5190) acc 93.7500 (87.5000) kd_loss 1.0160 (0.9321) lr 4.8943e-05 eta 0:01:05
epoch [47/50] batch [100/173] time 0.093 (0.105) data 0.000 (0.003) loss 0.7589 (0.7578) ce_loss 0.4033 (0.3533) teacher_loss 0.2467 (0.1767) loss_zs_kd 0.1180 (0.1251) loss_oracle 0.4532 (0.5185) acc 81.2500 (87.3438) kd_loss 0.8879 (0.9347) lr 4.8943e-05 eta 0:01:02
epoch [47/50] batch [120/173] time 0.064 (0.115) data 0.000 (0.002) loss 0.8304 (0.7584) ce_loss 0.5898 (0.3569) teacher_loss 0.3225 (0.1764) loss_zs_kd 0.1113 (0.1258) loss_oracle 0.4523 (0.5191) acc 78.1250 (87.0573) kd_loss 0.9642 (0.9359) lr 4.8943e-05 eta 0:01:05
epoch [47/50] batch [140/173] time 0.180 (0.119) data 0.000 (0.002) loss 0.7250 (0.7511) ce_loss 0.3899 (0.3547) teacher_loss 0.1213 (0.1736) loss_zs_kd 0.1721 (0.1265) loss_oracle 0.5177 (0.5143) acc 84.3750 (87.0536) kd_loss 0.9107 (0.9313) lr 4.8943e-05 eta 0:01:05
epoch [47/50] batch [160/173] time 0.091 (0.121) data 0.000 (0.002) loss 0.7969 (0.7515) ce_loss 0.2456 (0.3517) teacher_loss 0.1677 (0.1760) loss_zs_kd 0.1217 (0.1259) loss_oracle 0.5684 (0.5126) acc 93.7500 (87.1875) kd_loss 0.9994 (0.9312) lr 4.8943e-05 eta 0:01:04
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,286
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [48/50] batch [20/173] time 0.083 (0.114) data 0.000 (0.014) loss 0.7635 (0.8319) ce_loss 0.3206 (0.4379) teacher_loss 0.2218 (0.2389) loss_zs_kd 0.1438 (0.1406) loss_oracle 0.4697 (0.5228) acc 87.5000 (83.7500) kd_loss 0.8797 (0.9480) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [40/173] time 0.116 (0.110) data 0.000 (0.007) loss 0.9766 (0.7981) ce_loss 0.5215 (0.3990) teacher_loss 0.2991 (0.2141) loss_zs_kd 0.1687 (0.1367) loss_oracle 0.5932 (0.5156) acc 81.2500 (85.0000) kd_loss 0.9700 (0.9463) lr 3.1417e-05 eta 0:00:52
epoch [48/50] batch [60/173] time 0.117 (0.110) data 0.001 (0.005) loss 0.8727 (0.7821) ce_loss 0.5830 (0.3795) teacher_loss 0.2773 (0.1977) loss_zs_kd 0.1951 (0.1364) loss_oracle 0.4978 (0.5162) acc 81.2500 (85.7292) kd_loss 0.8825 (0.9490) lr 3.1417e-05 eta 0:00:50
epoch [48/50] batch [80/173] time 0.136 (0.109) data 0.000 (0.004) loss 0.7340 (0.7707) ce_loss 0.4136 (0.3792) teacher_loss 0.1668 (0.1938) loss_zs_kd 0.1468 (0.1358) loss_oracle 0.4938 (0.5090) acc 81.2500 (85.3906) kd_loss 0.9727 (0.9413) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [100/173] time 0.083 (0.109) data 0.000 (0.003) loss 0.8758 (0.7669) ce_loss 0.4500 (0.3712) teacher_loss 0.2016 (0.1893) loss_zs_kd 0.1325 (0.1324) loss_oracle 0.6079 (0.5114) acc 78.1250 (85.6250) kd_loss 0.9447 (0.9420) lr 3.1417e-05 eta 0:00:45
epoch [48/50] batch [120/173] time 0.088 (0.107) data 0.000 (0.002) loss 0.7978 (0.7632) ce_loss 0.3179 (0.3661) teacher_loss 0.1800 (0.1883) loss_zs_kd 0.1370 (0.1306) loss_oracle 0.5492 (0.5096) acc 90.6250 (86.0677) kd_loss 0.9460 (0.9385) lr 3.1417e-05 eta 0:00:42
epoch [48/50] batch [140/173] time 0.087 (0.107) data 0.000 (0.002) loss 0.9902 (0.7653) ce_loss 0.4622 (0.3682) teacher_loss 0.2947 (0.1904) loss_zs_kd 0.1556 (0.1313) loss_oracle 0.6177 (0.5092) acc 81.2500 (86.0491) kd_loss 0.9848 (0.9383) lr 3.1417e-05 eta 0:00:40
epoch [48/50] batch [160/173] time 0.096 (0.107) data 0.000 (0.002) loss 0.6812 (0.7613) ce_loss 0.3472 (0.3658) teacher_loss 0.1365 (0.1877) loss_zs_kd 0.1151 (0.1303) loss_oracle 0.4870 (0.5084) acc 87.5000 (86.1328) kd_loss 0.8226 (0.9351) lr 3.1417e-05 eta 0:00:38
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [49/50] batch [20/173] time 0.141 (0.138) data 0.001 (0.012) loss 0.8741 (0.7442) ce_loss 0.3291 (0.3349) teacher_loss 0.2468 (0.1799) loss_zs_kd 0.1761 (0.1169) loss_oracle 0.5393 (0.5059) acc 87.5000 (86.7188) kd_loss 0.9368 (0.9391) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [40/173] time 0.120 (0.131) data 0.000 (0.006) loss 0.7391 (0.7554) ce_loss 0.3770 (0.3529) teacher_loss 0.2041 (0.1936) loss_zs_kd 0.1365 (0.1229) loss_oracle 0.4668 (0.5003) acc 87.5000 (86.7969) kd_loss 0.8797 (0.9192) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [60/173] time 0.141 (0.128) data 0.001 (0.004) loss 0.6167 (0.7725) ce_loss 0.1844 (0.3695) teacher_loss 0.0480 (0.2034) loss_zs_kd 0.1455 (0.1253) loss_oracle 0.4959 (0.5065) acc 96.8750 (86.2500) kd_loss 0.9809 (0.9341) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [80/173] time 0.142 (0.126) data 0.000 (0.003) loss 0.7169 (0.7696) ce_loss 0.2637 (0.3674) teacher_loss 0.1454 (0.1980) loss_zs_kd 0.1085 (0.1253) loss_oracle 0.5173 (0.5089) acc 87.5000 (86.4453) kd_loss 0.9491 (0.9366) lr 1.7713e-05 eta 0:00:33
epoch [49/50] batch [100/173] time 0.080 (0.121) data 0.000 (0.003) loss 0.7798 (0.7757) ce_loss 0.2343 (0.3768) teacher_loss 0.1437 (0.2013) loss_zs_kd 0.1152 (0.1282) loss_oracle 0.5785 (0.5104) acc 90.6250 (86.0312) kd_loss 0.9709 (0.9358) lr 1.7713e-05 eta 0:00:29
epoch [49/50] batch [120/173] time 0.088 (0.129) data 0.000 (0.002) loss 0.8821 (0.7724) ce_loss 0.3330 (0.3684) teacher_loss 0.1581 (0.1946) loss_zs_kd 0.1836 (0.1278) loss_oracle 0.6322 (0.5138) acc 84.3750 (86.3021) kd_loss 1.0730 (0.9376) lr 1.7713e-05 eta 0:00:29
epoch [49/50] batch [140/173] time 0.188 (0.135) data 0.000 (0.002) loss 0.8296 (0.7707) ce_loss 0.6060 (0.3674) teacher_loss 0.2995 (0.1939) loss_zs_kd 0.1835 (0.1277) loss_oracle 0.4384 (0.5130) acc 78.1250 (86.3839) kd_loss 0.8209 (0.9358) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [160/173] time 0.095 (0.134) data 0.000 (0.002) loss 0.6652 (0.7646) ce_loss 0.2510 (0.3640) teacher_loss 0.1508 (0.1917) loss_zs_kd 0.1054 (0.1264) loss_oracle 0.4617 (0.5097) acc 90.6250 (86.5234) kd_loss 0.9401 (0.9316) lr 1.7713e-05 eta 0:00:24
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
epoch [50/50] batch [20/173] time 0.066 (0.119) data 0.000 (0.014) loss 0.9446 (0.7520) ce_loss 0.4514 (0.3732) teacher_loss 0.2567 (0.1831) loss_zs_kd 0.1800 (0.1190) loss_oracle 0.5979 (0.5093) acc 84.3750 (86.8750) kd_loss 1.0055 (0.9349) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [40/173] time 0.082 (0.112) data 0.000 (0.007) loss 0.6854 (0.7399) ce_loss 0.4026 (0.3642) teacher_loss 0.1806 (0.1823) loss_zs_kd 0.1494 (0.1224) loss_oracle 0.4300 (0.4964) acc 90.6250 (86.9531) kd_loss 0.8742 (0.9260) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [60/173] time 0.119 (0.113) data 0.000 (0.005) loss 0.7040 (0.7378) ce_loss 0.2766 (0.3570) teacher_loss 0.1627 (0.1763) loss_zs_kd 0.0977 (0.1221) loss_oracle 0.4924 (0.5005) acc 81.2500 (87.0312) kd_loss 0.9160 (0.9299) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [80/173] time 0.138 (0.113) data 0.000 (0.004) loss 0.8676 (0.7393) ce_loss 0.5840 (0.3506) teacher_loss 0.2539 (0.1722) loss_zs_kd 0.1600 (0.1247) loss_oracle 0.5337 (0.5047) acc 78.1250 (87.3047) kd_loss 0.9842 (0.9326) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [100/173] time 0.086 (0.112) data 0.000 (0.003) loss 0.7618 (0.7419) ce_loss 0.4292 (0.3490) teacher_loss 0.1687 (0.1731) loss_zs_kd 0.1307 (0.1254) loss_oracle 0.5278 (0.5060) acc 90.6250 (87.4062) kd_loss 1.0048 (0.9334) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [120/173] time 0.133 (0.111) data 0.000 (0.003) loss 0.7380 (0.7423) ce_loss 0.3396 (0.3457) teacher_loss 0.1541 (0.1733) loss_zs_kd 0.1120 (0.1239) loss_oracle 0.5279 (0.5071) acc 87.5000 (87.3177) kd_loss 0.9858 (0.9314) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [140/173] time 0.078 (0.110) data 0.000 (0.002) loss 0.5698 (0.7409) ce_loss 0.1982 (0.3452) teacher_loss 0.0592 (0.1744) loss_zs_kd 0.0950 (0.1235) loss_oracle 0.4632 (0.5047) acc 90.6250 (87.3438) kd_loss 0.8559 (0.9310) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [160/173] time 0.083 (0.109) data 0.000 (0.002) loss 0.6684 (0.7443) ce_loss 0.2512 (0.3492) teacher_loss 0.1562 (0.1770) loss_zs_kd 0.1202 (0.1249) loss_oracle 0.4521 (0.5049) acc 87.5000 (87.2461) kd_loss 0.8852 (0.9317) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 2,385
* correct: 2,285
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,048
* correct: 2,008
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
******* Domain a best val acc:      96.2%, epoch: 32 *******
******* Domain a best val test acc: 98.2%, epoch: 32 *******
******* Domain a best test acc:     98.3%, epoch: 30 *******
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/pacs/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:21:27

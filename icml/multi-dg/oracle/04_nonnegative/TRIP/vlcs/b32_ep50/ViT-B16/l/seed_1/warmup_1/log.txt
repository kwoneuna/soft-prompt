Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'pascal', 'sun']
Target     ['labelme']
# classes  5
# train_x  5,651
# val      2,422
# test     2,656
---------  ----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/176] time 0.115 (0.142) data 0.000 (0.019) loss 0.3724 (0.5079) ce_loss 0.3723 (0.5075) teacher_loss 0.3722 (0.5075) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0002 (0.0004) acc 81.2500 (80.6250) kd_loss 0.0005 (0.0015) lr 1.0000e-05 eta 0:20:45
epoch [1/50] batch [40/176] time 0.096 (0.118) data 0.000 (0.010) loss 0.5270 (0.5274) ce_loss 0.5269 (0.5271) teacher_loss 0.5268 (0.5272) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0001 (0.0002) acc 81.2500 (80.6250) kd_loss 0.0005 (0.0009) lr 1.0000e-05 eta 0:17:15
epoch [1/50] batch [60/176] time 0.189 (0.115) data 0.000 (0.007) loss 0.5233 (0.5306) ce_loss 0.5229 (0.5303) teacher_loss 0.5229 (0.5303) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0003 (0.0002) acc 78.1250 (81.0938) kd_loss 0.0013 (0.0009) lr 1.0000e-05 eta 0:16:45
epoch [1/50] batch [80/176] time 0.070 (0.121) data 0.000 (0.005) loss 0.4569 (0.5284) ce_loss 0.4561 (0.5280) teacher_loss 0.4564 (0.5281) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0004 (0.0003) acc 87.5000 (81.5625) kd_loss 0.0013 (0.0010) lr 1.0000e-05 eta 0:17:33
epoch [1/50] batch [100/176] time 0.149 (0.122) data 0.000 (0.004) loss 0.3659 (0.5203) ce_loss 0.3657 (0.5200) teacher_loss 0.3655 (0.5200) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0003 (0.0003) acc 87.5000 (81.9375) kd_loss 0.0010 (0.0010) lr 1.0000e-05 eta 0:17:44
epoch [1/50] batch [120/176] time 0.062 (0.122) data 0.000 (0.003) loss 0.2441 (0.5189) ce_loss 0.2437 (0.5185) teacher_loss 0.2436 (0.5185) loss_zs_kd 0.0004 (0.0001) loss_oracle 0.0004 (0.0003) acc 93.7500 (81.9010) kd_loss 0.0013 (0.0011) lr 1.0000e-05 eta 0:17:39
epoch [1/50] batch [140/176] time 0.077 (0.119) data 0.000 (0.003) loss 0.6484 (0.5303) ce_loss 0.6479 (0.5299) teacher_loss 0.6478 (0.5299) loss_zs_kd 0.0005 (0.0002) loss_oracle 0.0004 (0.0003) acc 78.1250 (81.4955) kd_loss 0.0015 (0.0012) lr 1.0000e-05 eta 0:17:08
epoch [1/50] batch [160/176] time 0.129 (0.117) data 0.000 (0.003) loss 0.3227 (0.5287) ce_loss 0.3220 (0.5283) teacher_loss 0.3218 (0.5283) loss_zs_kd 0.0003 (0.0002) loss_oracle 0.0007 (0.0003) acc 87.5000 (81.3477) kd_loss 0.0027 (0.0012) lr 1.0000e-05 eta 0:16:47
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,071
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 87.9%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,832
* accuracy: 69.0%
* error: 31.0%
* macro_f1: 61.7%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain l best val acc:      85.5%, epoch: 1 *******
******* Domain l best val test acc: 69.0%, epoch: 1 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/ana
epoch [2/50] batch [20/176] time 0.123 (0.128) data 0.000 (0.017) loss 0.5716 (0.5526) ce_loss 0.5244 (0.5217) teacher_loss 0.5258 (0.5226) loss_zs_kd 0.0673 (0.0481) loss_oracle 0.0122 (0.0059) acc 81.2500 (80.1562) kd_loss 0.0105 (0.0053) lr 2.0000e-03 eta 0:18:20
epoch [2/50] batch [40/176] time 0.093 (0.113) data 0.000 (0.009) loss 0.5553 (0.5296) ce_loss 0.5210 (0.4869) teacher_loss 0.5008 (0.4864) loss_zs_kd 0.0598 (0.0574) loss_oracle 0.0246 (0.0144) acc 78.1250 (82.2656) kd_loss 0.0861 (0.0226) lr 2.0000e-03 eta 0:16:08
epoch [2/50] batch [60/176] time 0.094 (0.107) data 0.000 (0.006) loss 0.4941 (0.5442) ce_loss 0.4099 (0.4799) teacher_loss 0.4040 (0.4807) loss_zs_kd 0.0544 (0.0598) loss_oracle 0.0630 (0.0336) acc 87.5000 (82.9167) kd_loss 0.3675 (0.1037) lr 2.0000e-03 eta 0:15:20
epoch [2/50] batch [80/176] time 0.110 (0.107) data 0.000 (0.004) loss 0.7978 (0.5487) ce_loss 0.6558 (0.4716) teacher_loss 0.6202 (0.4665) loss_zs_kd 0.0859 (0.0630) loss_oracle 0.1346 (0.0508) acc 81.2500 (82.9688) kd_loss 0.5041 (0.1878) lr 2.0000e-03 eta 0:15:15
epoch [2/50] batch [100/176] time 0.126 (0.108) data 0.000 (0.004) loss 1.0017 (0.5598) ce_loss 0.7676 (0.4706) teacher_loss 0.7148 (0.4567) loss_zs_kd 0.1022 (0.0670) loss_oracle 0.2358 (0.0697) acc 71.8750 (83.0938) kd_loss 0.5668 (0.2563) lr 2.0000e-03 eta 0:15:19
epoch [2/50] batch [120/176] time 0.082 (0.109) data 0.000 (0.003) loss 0.5391 (0.5616) ce_loss 0.4167 (0.4628) teacher_loss 0.3367 (0.4398) loss_zs_kd 0.1021 (0.0701) loss_oracle 0.1514 (0.0868) acc 84.3750 (83.3594) kd_loss 0.6372 (0.3139) lr 2.0000e-03 eta 0:15:22
epoch [2/50] batch [140/176] time 0.142 (0.110) data 0.000 (0.003) loss 0.4533 (0.5672) ce_loss 0.2788 (0.4566) teacher_loss 0.2498 (0.4292) loss_zs_kd 0.0424 (0.0727) loss_oracle 0.1822 (0.1017) acc 90.6250 (83.7054) kd_loss 0.5758 (0.3576) lr 2.0000e-03 eta 0:15:34
epoch [2/50] batch [160/176] time 0.114 (0.110) data 0.001 (0.002) loss 0.5080 (0.5790) ce_loss 0.2832 (0.4514) teacher_loss 0.2741 (0.4223) loss_zs_kd 0.0300 (0.0746) loss_oracle 0.2189 (0.1194) acc 93.7500 (84.0430) kd_loss 0.7162 (0.3971) lr 2.0000e-03 eta 0:15:32
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,174
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.4%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,717
* accuracy: 64.6%
* error: 35.4%
* macro_f1: 60.8%
******* Domain l best val acc:      89.8%, epoch: 2 *******
******* Domain l best val test acc: 64.6%, epoch: 2 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [3/50] batch [20/176] time 0.111 (0.132) data 0.000 (0.016) loss 1.0530 (0.6943) ce_loss 0.7451 (0.4484) teacher_loss 0.5216 (0.3584) loss_zs_kd 0.1772 (0.0914) loss_oracle 0.4428 (0.2902) acc 68.7500 (83.2812) kd_loss 0.9105 (0.7924) lr 1.9980e-03 eta 0:18:32
epoch [3/50] batch [40/176] time 0.180 (0.127) data 0.000 (0.008) loss 0.6941 (0.7255) ce_loss 0.4004 (0.4426) teacher_loss 0.2809 (0.3540) loss_zs_kd 0.0988 (0.0966) loss_oracle 0.3638 (0.3232) acc 81.2500 (83.7500) kd_loss 0.9398 (0.8282) lr 1.9980e-03 eta 0:17:44
epoch [3/50] batch [60/176] time 0.167 (0.126) data 0.000 (0.005) loss 1.0074 (0.7258) ce_loss 0.6187 (0.4211) teacher_loss 0.4874 (0.3301) loss_zs_kd 0.0972 (0.0975) loss_oracle 0.4714 (0.3470) acc 81.2500 (85.1562) kd_loss 0.8821 (0.8499) lr 1.9980e-03 eta 0:17:37
epoch [3/50] batch [80/176] time 0.174 (0.134) data 0.000 (0.004) loss 0.5989 (0.7216) ce_loss 0.3066 (0.4112) teacher_loss 0.2565 (0.3228) loss_zs_kd 0.0652 (0.0952) loss_oracle 0.3098 (0.3512) acc 84.3750 (85.8203) kd_loss 0.9002 (0.8603) lr 1.9980e-03 eta 0:18:42
epoch [3/50] batch [100/176] time 0.126 (0.129) data 0.000 (0.003) loss 0.5907 (0.7121) ce_loss 0.3374 (0.4167) teacher_loss 0.2003 (0.3244) loss_zs_kd 0.1189 (0.0956) loss_oracle 0.3310 (0.3399) acc 90.6250 (85.8438) kd_loss 0.8865 (0.8688) lr 1.9980e-03 eta 0:17:53
epoch [3/50] batch [120/176] time 0.137 (0.125) data 0.000 (0.003) loss 0.6001 (0.7031) ce_loss 0.3850 (0.4166) teacher_loss 0.2662 (0.3188) loss_zs_kd 0.1035 (0.0990) loss_oracle 0.2821 (0.3348) acc 81.2500 (85.6510) kd_loss 0.9353 (0.8722) lr 1.9980e-03 eta 0:17:24
epoch [3/50] batch [140/176] time 0.134 (0.123) data 0.000 (0.002) loss 0.5045 (0.6949) ce_loss 0.2754 (0.4152) teacher_loss 0.1811 (0.3126) loss_zs_kd 0.0950 (0.1007) loss_oracle 0.2758 (0.3319) acc 93.7500 (85.7589) kd_loss 0.8859 (0.8768) lr 1.9980e-03 eta 0:17:03
epoch [3/50] batch [160/176] time 0.132 (0.121) data 0.000 (0.002) loss 0.6249 (0.6971) ce_loss 0.3533 (0.4211) teacher_loss 0.1995 (0.3133) loss_zs_kd 0.1300 (0.1028) loss_oracle 0.3605 (0.3323) acc 84.3750 (85.6836) kd_loss 0.9200 (0.8825) lr 1.9980e-03 eta 0:16:46
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,164
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,769
* accuracy: 66.6%
* error: 33.4%
* macro_f1: 61.7%
******* Domain l best val acc:      89.8%, epoch: 2 *******
******* Domain l best val test acc: 64.6%, epoch: 2 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [4/50] batch [20/176] time 0.118 (0.132) data 0.000 (0.017) loss 0.6440 (0.7064) ce_loss 0.3452 (0.4325) teacher_loss 0.2881 (0.3102) loss_zs_kd 0.0919 (0.1244) loss_oracle 0.3100 (0.3340) acc 93.7500 (86.4062) kd_loss 0.9038 (0.8917) lr 1.9921e-03 eta 0:18:12
epoch [4/50] batch [40/176] time 0.093 (0.125) data 0.000 (0.009) loss 0.5512 (0.6548) ce_loss 0.3325 (0.4125) teacher_loss 0.1832 (0.2911) loss_zs_kd 0.0984 (0.1122) loss_oracle 0.3188 (0.3076) acc 87.5000 (86.1719) kd_loss 0.9161 (0.8760) lr 1.9921e-03 eta 0:17:12
epoch [4/50] batch [60/176] time 0.133 (0.120) data 0.000 (0.006) loss 0.7034 (0.6716) ce_loss 0.4285 (0.4162) teacher_loss 0.2446 (0.2972) loss_zs_kd 0.1103 (0.1130) loss_oracle 0.4036 (0.3179) acc 78.1250 (85.7292) kd_loss 0.9612 (0.8685) lr 1.9921e-03 eta 0:16:26
epoch [4/50] batch [80/176] time 0.101 (0.116) data 0.000 (0.004) loss 0.8352 (0.6824) ce_loss 0.4929 (0.4147) teacher_loss 0.2832 (0.2988) loss_zs_kd 0.1774 (0.1098) loss_oracle 0.4633 (0.3286) acc 81.2500 (85.5859) kd_loss 0.9549 (0.8730) lr 1.9921e-03 eta 0:15:48
epoch [4/50] batch [100/176] time 0.103 (0.114) data 0.000 (0.004) loss 0.5505 (0.6952) ce_loss 0.2477 (0.4209) teacher_loss 0.1617 (0.2996) loss_zs_kd 0.0950 (0.1118) loss_oracle 0.3413 (0.3397) acc 87.5000 (85.0625) kd_loss 0.8384 (0.8750) lr 1.9921e-03 eta 0:15:34
epoch [4/50] batch [120/176] time 0.121 (0.114) data 0.000 (0.003) loss 0.5561 (0.7068) ce_loss 0.1857 (0.4284) teacher_loss 0.1285 (0.3028) loss_zs_kd 0.1157 (0.1143) loss_oracle 0.3697 (0.3469) acc 93.7500 (84.8698) kd_loss 0.8731 (0.8762) lr 1.9921e-03 eta 0:15:29
epoch [4/50] batch [140/176] time 0.104 (0.114) data 0.001 (0.003) loss 1.0541 (0.7125) ce_loss 0.6724 (0.4301) teacher_loss 0.5209 (0.3038) loss_zs_kd 0.1661 (0.1167) loss_oracle 0.4502 (0.3503) acc 81.2500 (84.9107) kd_loss 0.9313 (0.8775) lr 1.9921e-03 eta 0:15:24
epoch [4/50] batch [160/176] time 0.147 (0.114) data 0.000 (0.002) loss 0.5821 (0.7136) ce_loss 0.2798 (0.4271) teacher_loss 0.1691 (0.3015) loss_zs_kd 0.1048 (0.1166) loss_oracle 0.3606 (0.3538) acc 93.7500 (85.1758) kd_loss 0.8965 (0.8770) lr 1.9921e-03 eta 0:15:24
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,168
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,839
* accuracy: 69.2%
* error: 30.8%
* macro_f1: 62.4%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain l best val acc:      89.8%, epoch: 2 *******
******* Domain l best val test acc: 64.6%, epoch: 2 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [5/50] batch [20/176] time 0.139 (0.135) data 0.000 (0.014) loss 0.6340 (0.7452) ce_loss 0.3018 (0.4046) teacher_loss 0.1806 (0.2960) loss_zs_kd 0.1075 (0.1120) loss_oracle 0.3996 (0.3933) acc 84.3750 (85.0000) kd_loss 0.9506 (0.8728) lr 1.9823e-03 eta 0:18:07
epoch [5/50] batch [40/176] time 0.073 (0.135) data 0.000 (0.007) loss 0.8021 (0.7640) ce_loss 0.3479 (0.4078) teacher_loss 0.2600 (0.3025) loss_zs_kd 0.1356 (0.1136) loss_oracle 0.4743 (0.4047) acc 90.6250 (85.6250) kd_loss 0.8989 (0.8554) lr 1.9823e-03 eta 0:18:10
epoch [5/50] batch [60/176] time 0.161 (0.141) data 0.001 (0.005) loss 0.6470 (0.7421) ce_loss 0.1949 (0.3834) teacher_loss 0.1521 (0.2858) loss_zs_kd 0.0832 (0.1077) loss_oracle 0.4533 (0.4025) acc 96.8750 (87.1875) kd_loss 0.8886 (0.8558) lr 1.9823e-03 eta 0:18:56
epoch [5/50] batch [80/176] time 0.142 (0.135) data 0.000 (0.004) loss 0.7900 (0.7611) ce_loss 0.4629 (0.4058) teacher_loss 0.3709 (0.3061) loss_zs_kd 0.1187 (0.1067) loss_oracle 0.3597 (0.4017) acc 84.3750 (86.2109) kd_loss 0.7525 (0.8530) lr 1.9823e-03 eta 0:18:00
epoch [5/50] batch [100/176] time 0.081 (0.129) data 0.000 (0.003) loss 0.6812 (0.7642) ce_loss 0.3350 (0.4079) teacher_loss 0.2790 (0.3131) loss_zs_kd 0.0868 (0.1066) loss_oracle 0.3588 (0.3978) acc 87.5000 (86.0938) kd_loss 0.8285 (0.8530) lr 1.9823e-03 eta 0:17:10
epoch [5/50] batch [120/176] time 0.124 (0.126) data 0.000 (0.003) loss 0.7669 (0.7679) ce_loss 0.4138 (0.4142) teacher_loss 0.2891 (0.3184) loss_zs_kd 0.1022 (0.1075) loss_oracle 0.4267 (0.3957) acc 81.2500 (85.6771) kd_loss 0.8438 (0.8529) lr 1.9823e-03 eta 0:16:47
epoch [5/50] batch [140/176] time 0.143 (0.125) data 0.000 (0.002) loss 0.5761 (0.7646) ce_loss 0.2517 (0.4142) teacher_loss 0.1794 (0.3230) loss_zs_kd 0.0758 (0.1061) loss_oracle 0.3588 (0.3886) acc 93.7500 (85.8036) kd_loss 0.8216 (0.8517) lr 1.9823e-03 eta 0:16:34
epoch [5/50] batch [160/176] time 0.092 (0.123) data 0.000 (0.002) loss 0.6825 (0.7659) ce_loss 0.3083 (0.4157) teacher_loss 0.2280 (0.3267) loss_zs_kd 0.0973 (0.1060) loss_oracle 0.4058 (0.3861) acc 87.5000 (85.6445) kd_loss 0.8824 (0.8478) lr 1.9823e-03 eta 0:16:19
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,175
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.6%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,751
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 60.8%
******* Domain l best val acc:      89.8%, epoch: 5 *******
******* Domain l best val test acc: 65.9%, epoch: 5 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [6/50] batch [20/176] time 0.126 (0.128) data 0.000 (0.016) loss 0.5531 (0.7015) ce_loss 0.1969 (0.3831) teacher_loss 0.1564 (0.3058) loss_zs_kd 0.0870 (0.0969) loss_oracle 0.3533 (0.3472) acc 93.7500 (85.7812) kd_loss 0.7879 (0.7984) lr 1.9686e-03 eta 0:16:50
epoch [6/50] batch [40/176] time 0.077 (0.120) data 0.000 (0.008) loss 0.6249 (0.7352) ce_loss 0.3657 (0.4098) teacher_loss 0.2551 (0.3228) loss_zs_kd 0.0650 (0.1014) loss_oracle 0.3373 (0.3617) acc 81.2500 (85.3906) kd_loss 0.7936 (0.8087) lr 1.9686e-03 eta 0:15:42
epoch [6/50] batch [60/176] time 0.131 (0.115) data 0.001 (0.006) loss 0.5798 (0.7396) ce_loss 0.2649 (0.4174) teacher_loss 0.1957 (0.3318) loss_zs_kd 0.0891 (0.0991) loss_oracle 0.3395 (0.3583) acc 90.6250 (85.1562) kd_loss 0.8319 (0.8061) lr 1.9686e-03 eta 0:15:07
epoch [6/50] batch [80/176] time 0.109 (0.114) data 0.000 (0.004) loss 0.5334 (0.7202) ce_loss 0.2312 (0.4054) teacher_loss 0.2111 (0.3199) loss_zs_kd 0.1010 (0.1005) loss_oracle 0.2717 (0.3501) acc 93.7500 (85.8203) kd_loss 0.7580 (0.7998) lr 1.9686e-03 eta 0:14:55
epoch [6/50] batch [100/176] time 0.122 (0.114) data 0.000 (0.003) loss 0.8185 (0.7230) ce_loss 0.4741 (0.4110) teacher_loss 0.4235 (0.3267) loss_zs_kd 0.1392 (0.1015) loss_oracle 0.3255 (0.3455) acc 84.3750 (85.7188) kd_loss 0.8315 (0.7957) lr 1.9686e-03 eta 0:14:54
epoch [6/50] batch [120/176] time 0.084 (0.114) data 0.000 (0.003) loss 0.7824 (0.7219) ce_loss 0.5605 (0.4111) teacher_loss 0.3837 (0.3257) loss_zs_kd 0.1114 (0.1030) loss_oracle 0.3430 (0.3447) acc 78.1250 (85.5729) kd_loss 0.7773 (0.7922) lr 1.9686e-03 eta 0:14:48
epoch [6/50] batch [140/176] time 0.081 (0.114) data 0.000 (0.003) loss 0.6933 (0.7187) ce_loss 0.4873 (0.4100) teacher_loss 0.3549 (0.3259) loss_zs_kd 0.1009 (0.1037) loss_oracle 0.2880 (0.3409) acc 84.3750 (85.6473) kd_loss 0.7264 (0.7878) lr 1.9686e-03 eta 0:14:47
epoch [6/50] batch [160/176] time 0.139 (0.114) data 0.000 (0.002) loss 0.7719 (0.7164) ce_loss 0.4944 (0.4127) teacher_loss 0.3394 (0.3256) loss_zs_kd 0.1426 (0.1030) loss_oracle 0.3612 (0.3393) acc 78.1250 (85.4297) kd_loss 0.8776 (0.7873) lr 1.9686e-03 eta 0:14:45
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,174
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,717
* accuracy: 64.6%
* error: 35.4%
* macro_f1: 59.3%
******* Domain l best val acc:      89.8%, epoch: 5 *******
******* Domain l best val test acc: 65.9%, epoch: 5 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [7/50] batch [20/176] time 0.128 (0.148) data 0.000 (0.017) loss 0.7470 (0.6537) ce_loss 0.4331 (0.3752) teacher_loss 0.3806 (0.3049) loss_zs_kd 0.0927 (0.1000) loss_oracle 0.3201 (0.2988) acc 84.3750 (87.8125) kd_loss 0.8173 (0.7586) lr 1.9511e-03 eta 0:19:03
epoch [7/50] batch [40/176] time 0.076 (0.152) data 0.000 (0.009) loss 0.6140 (0.6650) ce_loss 0.2900 (0.3803) teacher_loss 0.2931 (0.3062) loss_zs_kd 0.1113 (0.0987) loss_oracle 0.2652 (0.3096) acc 90.6250 (86.9531) kd_loss 0.6776 (0.7697) lr 1.9511e-03 eta 0:19:33
epoch [7/50] batch [60/176] time 0.135 (0.138) data 0.001 (0.006) loss 0.6033 (0.7007) ce_loss 0.3618 (0.4189) teacher_loss 0.2245 (0.3321) loss_zs_kd 0.0919 (0.1017) loss_oracle 0.3328 (0.3177) acc 87.5000 (85.4167) kd_loss 0.7942 (0.7751) lr 1.9511e-03 eta 0:17:40
epoch [7/50] batch [80/176] time 0.152 (0.132) data 0.000 (0.005) loss 0.5387 (0.7157) ce_loss 0.1547 (0.4218) teacher_loss 0.1655 (0.3339) loss_zs_kd 0.0751 (0.1035) loss_oracle 0.3356 (0.3300) acc 96.8750 (85.1562) kd_loss 0.7393 (0.7767) lr 1.9511e-03 eta 0:16:53
epoch [7/50] batch [100/176] time 0.140 (0.130) data 0.000 (0.004) loss 0.7622 (0.7213) ce_loss 0.4407 (0.4125) teacher_loss 0.3551 (0.3267) loss_zs_kd 0.1133 (0.1026) loss_oracle 0.3505 (0.3434) acc 81.2500 (85.4688) kd_loss 0.6877 (0.7821) lr 1.9511e-03 eta 0:16:33
epoch [7/50] batch [120/176] time 0.129 (0.128) data 0.000 (0.003) loss 0.8982 (0.7231) ce_loss 0.6567 (0.4140) teacher_loss 0.5499 (0.3319) loss_zs_kd 0.0537 (0.1000) loss_oracle 0.3215 (0.3412) acc 71.8750 (85.5208) kd_loss 0.7635 (0.7808) lr 1.9511e-03 eta 0:16:18
epoch [7/50] batch [140/176] time 0.110 (0.126) data 0.000 (0.003) loss 0.9148 (0.7312) ce_loss 0.5386 (0.4186) teacher_loss 0.4709 (0.3364) loss_zs_kd 0.0887 (0.0993) loss_oracle 0.3995 (0.3452) acc 84.3750 (85.3348) kd_loss 0.7363 (0.7813) lr 1.9511e-03 eta 0:16:00
epoch [7/50] batch [160/176] time 0.087 (0.125) data 0.000 (0.002) loss 0.9320 (0.7343) ce_loss 0.5938 (0.4172) teacher_loss 0.5014 (0.3357) loss_zs_kd 0.0916 (0.0999) loss_oracle 0.3848 (0.3486) acc 78.1250 (85.2930) kd_loss 0.7569 (0.7812) lr 1.9511e-03 eta 0:15:49
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,178
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.7%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,791
* accuracy: 67.4%
* error: 32.6%
* macro_f1: 61.4%
******* Domain l best val acc:      89.9%, epoch: 7 *******
******* Domain l best val test acc: 67.4%, epoch: 7 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [8/50] batch [20/176] time 0.109 (0.126) data 0.000 (0.017) loss 0.5193 (0.7017) ce_loss 0.2463 (0.3678) teacher_loss 0.1998 (0.2897) loss_zs_kd 0.0779 (0.1087) loss_oracle 0.2805 (0.3576) acc 90.6250 (87.1875) kd_loss 0.8011 (0.7996) lr 1.9298e-03 eta 0:15:52
epoch [8/50] batch [40/176] time 0.114 (0.118) data 0.000 (0.009) loss 0.6727 (0.7051) ce_loss 0.3616 (0.3841) teacher_loss 0.2822 (0.3026) loss_zs_kd 0.0646 (0.1019) loss_oracle 0.3583 (0.3516) acc 90.6250 (86.6406) kd_loss 0.7923 (0.8048) lr 1.9298e-03 eta 0:14:48
epoch [8/50] batch [60/176] time 0.131 (0.115) data 0.001 (0.006) loss 0.8044 (0.7156) ce_loss 0.3813 (0.3891) teacher_loss 0.3702 (0.3119) loss_zs_kd 0.1063 (0.0972) loss_oracle 0.3811 (0.3551) acc 87.5000 (86.4583) kd_loss 0.7813 (0.8034) lr 1.9298e-03 eta 0:14:24
epoch [8/50] batch [80/176] time 0.110 (0.116) data 0.000 (0.004) loss 0.6606 (0.7200) ce_loss 0.3220 (0.3905) teacher_loss 0.2848 (0.3143) loss_zs_kd 0.0752 (0.0976) loss_oracle 0.3381 (0.3569) acc 93.7500 (86.6406) kd_loss 0.7770 (0.8024) lr 1.9298e-03 eta 0:14:30
epoch [8/50] batch [100/176] time 0.089 (0.116) data 0.000 (0.004) loss 0.6224 (0.7193) ce_loss 0.3250 (0.3928) teacher_loss 0.1862 (0.3148) loss_zs_kd 0.0961 (0.0965) loss_oracle 0.3882 (0.3562) acc 87.5000 (86.3438) kd_loss 0.8193 (0.8033) lr 1.9298e-03 eta 0:14:26
epoch [8/50] batch [120/176] time 0.104 (0.115) data 0.000 (0.003) loss 0.7770 (0.7155) ce_loss 0.4780 (0.3950) teacher_loss 0.4037 (0.3175) loss_zs_kd 0.1003 (0.0955) loss_oracle 0.3232 (0.3502) acc 78.1250 (86.3281) kd_loss 0.7504 (0.7996) lr 1.9298e-03 eta 0:14:12
epoch [8/50] batch [140/176] time 0.101 (0.114) data 0.000 (0.003) loss 0.6725 (0.7108) ce_loss 0.3870 (0.3975) teacher_loss 0.3169 (0.3198) loss_zs_kd 0.0842 (0.0942) loss_oracle 0.3135 (0.3440) acc 81.2500 (86.1161) kd_loss 0.8045 (0.7955) lr 1.9298e-03 eta 0:14:04
epoch [8/50] batch [160/176] time 0.103 (0.113) data 0.000 (0.002) loss 0.6979 (0.7080) ce_loss 0.4219 (0.4012) teacher_loss 0.3095 (0.3200) loss_zs_kd 0.1169 (0.0958) loss_oracle 0.3299 (0.3401) acc 87.5000 (86.0742) kd_loss 0.7330 (0.7910) lr 1.9298e-03 eta 0:13:55
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,185
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.0%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,729
* accuracy: 65.1%
* error: 34.9%
* macro_f1: 60.4%
******* Domain l best val acc:      90.2%, epoch: 8 *******
******* Domain l best val test acc: 65.1%, epoch: 8 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [9/50] batch [20/176] time 0.117 (0.119) data 0.000 (0.014) loss 0.6200 (0.6769) ce_loss 0.4067 (0.4143) teacher_loss 0.2992 (0.3357) loss_zs_kd 0.1125 (0.1015) loss_oracle 0.2646 (0.2905) acc 84.3750 (83.5938) kd_loss 0.7443 (0.7384) lr 1.9048e-03 eta 0:14:39
epoch [9/50] batch [40/176] time 0.139 (0.116) data 0.000 (0.007) loss 0.8767 (0.6997) ce_loss 0.6606 (0.4340) teacher_loss 0.5401 (0.3603) loss_zs_kd 0.0918 (0.0919) loss_oracle 0.2907 (0.2934) acc 68.7500 (84.2188) kd_loss 0.7270 (0.7454) lr 1.9048e-03 eta 0:14:11
epoch [9/50] batch [60/176] time 0.101 (0.116) data 0.001 (0.005) loss 0.5751 (0.6908) ce_loss 0.3159 (0.4142) teacher_loss 0.2628 (0.3361) loss_zs_kd 0.1015 (0.0958) loss_oracle 0.2615 (0.3068) acc 87.5000 (85.0000) kd_loss 0.7393 (0.7540) lr 1.9048e-03 eta 0:14:10
epoch [9/50] batch [80/176] time 0.103 (0.114) data 0.000 (0.004) loss 0.7460 (0.6957) ce_loss 0.4299 (0.4143) teacher_loss 0.3083 (0.3319) loss_zs_kd 0.1313 (0.1017) loss_oracle 0.3720 (0.3129) acc 84.3750 (85.5469) kd_loss 0.8497 (0.7586) lr 1.9048e-03 eta 0:13:52
epoch [9/50] batch [100/176] time 0.081 (0.112) data 0.000 (0.003) loss 0.5653 (0.6961) ce_loss 0.3064 (0.4118) teacher_loss 0.2382 (0.3262) loss_zs_kd 0.1098 (0.1044) loss_oracle 0.2722 (0.3178) acc 93.7500 (85.8750) kd_loss 0.7901 (0.7593) lr 1.9048e-03 eta 0:13:35
epoch [9/50] batch [120/176] time 0.129 (0.111) data 0.000 (0.003) loss 0.8706 (0.7009) ce_loss 0.5264 (0.4181) teacher_loss 0.4492 (0.3288) loss_zs_kd 0.1490 (0.1061) loss_oracle 0.3470 (0.3191) acc 90.6250 (85.6510) kd_loss 0.8568 (0.7614) lr 1.9048e-03 eta 0:13:23
epoch [9/50] batch [140/176] time 0.100 (0.109) data 0.000 (0.002) loss 0.5615 (0.6960) ce_loss 0.2520 (0.4108) teacher_loss 0.1960 (0.3224) loss_zs_kd 0.1117 (0.1060) loss_oracle 0.3097 (0.3207) acc 96.8750 (85.8929) kd_loss 0.6495 (0.7584) lr 1.9048e-03 eta 0:13:11
epoch [9/50] batch [160/176] time 0.099 (0.109) data 0.000 (0.002) loss 0.7939 (0.7014) ce_loss 0.4854 (0.4130) teacher_loss 0.5041 (0.3234) loss_zs_kd 0.0756 (0.1056) loss_oracle 0.2519 (0.3252) acc 87.5000 (85.6836) kd_loss 0.6977 (0.7590) lr 1.9048e-03 eta 0:13:06
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,189
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.0%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,729
* accuracy: 65.1%
* error: 34.9%
* macro_f1: 60.1%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 65.1%, epoch: 9 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [10/50] batch [20/176] time 0.080 (0.120) data 0.000 (0.011) loss 0.7987 (0.7104) ce_loss 0.5210 (0.4251) teacher_loss 0.4042 (0.3204) loss_zs_kd 0.0965 (0.1131) loss_oracle 0.3463 (0.3334) acc 75.0000 (82.9688) kd_loss 0.7809 (0.7498) lr 1.8763e-03 eta 0:14:20
epoch [10/50] batch [40/176] time 0.128 (0.116) data 0.000 (0.006) loss 0.7438 (0.6892) ce_loss 0.4075 (0.3882) teacher_loss 0.3304 (0.2975) loss_zs_kd 0.0723 (0.1094) loss_oracle 0.3773 (0.3370) acc 81.2500 (84.9219) kd_loss 0.8130 (0.7604) lr 1.8763e-03 eta 0:13:55
epoch [10/50] batch [60/176] time 0.118 (0.116) data 0.001 (0.004) loss 0.7254 (0.6997) ce_loss 0.4045 (0.3914) teacher_loss 0.3488 (0.3102) loss_zs_kd 0.1293 (0.1066) loss_oracle 0.3120 (0.3363) acc 90.6250 (85.7292) kd_loss 0.7649 (0.7593) lr 1.8763e-03 eta 0:13:50
epoch [10/50] batch [80/176] time 0.135 (0.116) data 0.000 (0.003) loss 0.7418 (0.6994) ce_loss 0.4978 (0.3935) teacher_loss 0.3971 (0.3099) loss_zs_kd 0.1000 (0.1058) loss_oracle 0.2948 (0.3366) acc 87.5000 (85.7812) kd_loss 0.7326 (0.7616) lr 1.8763e-03 eta 0:13:46
epoch [10/50] batch [100/176] time 0.125 (0.115) data 0.000 (0.002) loss 0.7651 (0.7104) ce_loss 0.5283 (0.4029) teacher_loss 0.4286 (0.3182) loss_zs_kd 0.1422 (0.1072) loss_oracle 0.2653 (0.3386) acc 84.3750 (85.7188) kd_loss 0.7788 (0.7662) lr 1.8763e-03 eta 0:13:37
epoch [10/50] batch [120/176] time 0.083 (0.114) data 0.000 (0.002) loss 0.8966 (0.7089) ce_loss 0.6167 (0.4007) teacher_loss 0.5344 (0.3148) loss_zs_kd 0.0976 (0.1076) loss_oracle 0.3134 (0.3403) acc 78.1250 (85.6771) kd_loss 0.7373 (0.7678) lr 1.8763e-03 eta 0:13:31
epoch [10/50] batch [140/176] time 0.111 (0.114) data 0.000 (0.002) loss 0.7785 (0.7121) ce_loss 0.3960 (0.4010) teacher_loss 0.3268 (0.3151) loss_zs_kd 0.1172 (0.1085) loss_oracle 0.3930 (0.3427) acc 87.5000 (85.5804) kd_loss 0.9470 (0.7715) lr 1.8763e-03 eta 0:13:27
epoch [10/50] batch [160/176] time 0.134 (0.114) data 0.000 (0.002) loss 0.5684 (0.7093) ce_loss 0.3052 (0.4007) teacher_loss 0.1532 (0.3123) loss_zs_kd 0.0905 (0.1085) loss_oracle 0.3700 (0.3428) acc 93.7500 (85.5469) kd_loss 0.8993 (0.7739) lr 1.8763e-03 eta 0:13:25
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,188
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,712
* accuracy: 64.5%
* error: 35.5%
* macro_f1: 59.6%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 65.1%, epoch: 9 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [11/50] batch [20/176] time 0.107 (0.106) data 0.000 (0.015) loss 0.8659 (0.7555) ce_loss 0.4724 (0.4358) teacher_loss 0.4352 (0.3169) loss_zs_kd 0.1401 (0.1412) loss_oracle 0.3606 (0.3681) acc 90.6250 (84.2188) kd_loss 0.8298 (0.8446) lr 1.8443e-03 eta 0:12:26
epoch [11/50] batch [40/176] time 0.093 (0.102) data 0.000 (0.008) loss 0.6475 (0.7249) ce_loss 0.4268 (0.4066) teacher_loss 0.2431 (0.2959) loss_zs_kd 0.1253 (0.1210) loss_oracle 0.3417 (0.3685) acc 84.3750 (86.0156) kd_loss 0.8302 (0.8376) lr 1.8443e-03 eta 0:11:53
epoch [11/50] batch [60/176] time 0.084 (0.101) data 0.001 (0.005) loss 0.7699 (0.7437) ce_loss 0.4717 (0.4138) teacher_loss 0.3282 (0.3031) loss_zs_kd 0.1642 (0.1244) loss_oracle 0.3596 (0.3784) acc 84.3750 (85.5729) kd_loss 0.8475 (0.8452) lr 1.8443e-03 eta 0:11:47
epoch [11/50] batch [80/176] time 0.122 (0.102) data 0.000 (0.004) loss 1.0242 (0.7492) ce_loss 0.5610 (0.4144) teacher_loss 0.5386 (0.3090) loss_zs_kd 0.0963 (0.1204) loss_oracle 0.4374 (0.3800) acc 84.3750 (85.5469) kd_loss 0.9545 (0.8439) lr 1.8443e-03 eta 0:11:49
epoch [11/50] batch [100/176] time 0.136 (0.103) data 0.000 (0.003) loss 0.7644 (0.7319) ce_loss 0.4272 (0.3959) teacher_loss 0.3368 (0.2970) loss_zs_kd 0.0975 (0.1166) loss_oracle 0.3788 (0.3765) acc 81.2500 (86.3438) kd_loss 0.8514 (0.8420) lr 1.8443e-03 eta 0:11:52
epoch [11/50] batch [120/176] time 0.076 (0.103) data 0.000 (0.003) loss 0.6814 (0.7323) ce_loss 0.2607 (0.3953) teacher_loss 0.2154 (0.2966) loss_zs_kd 0.1058 (0.1167) loss_oracle 0.4131 (0.3774) acc 84.3750 (86.0938) kd_loss 0.7784 (0.8410) lr 1.8443e-03 eta 0:11:53
epoch [11/50] batch [140/176] time 0.115 (0.105) data 0.000 (0.002) loss 0.7598 (0.7364) ce_loss 0.4211 (0.3996) teacher_loss 0.3115 (0.2994) loss_zs_kd 0.1068 (0.1163) loss_oracle 0.3949 (0.3789) acc 87.5000 (86.0491) kd_loss 0.7613 (0.8416) lr 1.8443e-03 eta 0:12:03
epoch [11/50] batch [160/176] time 0.134 (0.106) data 0.000 (0.002) loss 0.6957 (0.7417) ce_loss 0.2485 (0.4030) teacher_loss 0.1932 (0.3034) loss_zs_kd 0.1348 (0.1167) loss_oracle 0.4350 (0.3799) acc 100.0000 (85.9961) kd_loss 0.9416 (0.8421) lr 1.8443e-03 eta 0:12:07
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,178
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,781
* accuracy: 67.1%
* error: 32.9%
* macro_f1: 61.1%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 65.1%, epoch: 9 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [12/50] batch [20/176] time 0.134 (0.123) data 0.000 (0.015) loss 0.6592 (0.7465) ce_loss 0.2939 (0.3980) teacher_loss 0.2524 (0.2927) loss_zs_kd 0.0908 (0.1240) loss_oracle 0.3614 (0.3918) acc 93.7500 (84.8438) kd_loss 0.8888 (0.8524) lr 1.8090e-03 eta 0:14:01
epoch [12/50] batch [40/176] time 0.099 (0.117) data 0.000 (0.008) loss 0.8541 (0.7582) ce_loss 0.5112 (0.3977) teacher_loss 0.4316 (0.2862) loss_zs_kd 0.1300 (0.1282) loss_oracle 0.3575 (0.4079) acc 87.5000 (85.3906) kd_loss 0.8005 (0.8636) lr 1.8090e-03 eta 0:13:18
epoch [12/50] batch [60/176] time 0.108 (0.116) data 0.001 (0.005) loss 0.9137 (0.7565) ce_loss 0.5898 (0.3984) teacher_loss 0.4154 (0.2849) loss_zs_kd 0.1536 (0.1273) loss_oracle 0.4216 (0.4080) acc 84.3750 (85.6771) kd_loss 0.8681 (0.8710) lr 1.8090e-03 eta 0:13:09
epoch [12/50] batch [80/176] time 0.114 (0.113) data 0.000 (0.004) loss 0.7002 (0.7495) ce_loss 0.2935 (0.3934) teacher_loss 0.1810 (0.2782) loss_zs_kd 0.1425 (0.1265) loss_oracle 0.4479 (0.4080) acc 93.7500 (86.0938) kd_loss 0.8792 (0.8725) lr 1.8090e-03 eta 0:12:47
epoch [12/50] batch [100/176] time 0.134 (0.110) data 0.000 (0.003) loss 0.6244 (0.7469) ce_loss 0.2450 (0.3954) teacher_loss 0.2051 (0.2806) loss_zs_kd 0.0724 (0.1258) loss_oracle 0.3831 (0.4034) acc 90.6250 (86.0938) kd_loss 0.8582 (0.8675) lr 1.8090e-03 eta 0:12:27
epoch [12/50] batch [120/176] time 0.115 (0.109) data 0.000 (0.003) loss 0.6379 (0.7433) ce_loss 0.2369 (0.3896) teacher_loss 0.1406 (0.2771) loss_zs_kd 0.0803 (0.1246) loss_oracle 0.4571 (0.4039) acc 93.7500 (86.2500) kd_loss 0.8643 (0.8662) lr 1.8090e-03 eta 0:12:16
epoch [12/50] batch [140/176] time 0.084 (0.108) data 0.000 (0.002) loss 1.0453 (0.7430) ce_loss 0.5942 (0.3882) teacher_loss 0.5483 (0.2787) loss_zs_kd 0.1110 (0.1232) loss_oracle 0.4414 (0.4027) acc 81.2500 (86.4062) kd_loss 0.9235 (0.8661) lr 1.8090e-03 eta 0:12:07
epoch [12/50] batch [160/176] time 0.080 (0.106) data 0.000 (0.002) loss 0.8228 (0.7429) ce_loss 0.4553 (0.3902) teacher_loss 0.3962 (0.2832) loss_zs_kd 0.0856 (0.1209) loss_oracle 0.3838 (0.3993) acc 78.1250 (86.2695) kd_loss 0.8766 (0.8646) lr 1.8090e-03 eta 0:11:53
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,175
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,680
* accuracy: 63.3%
* error: 36.7%
* macro_f1: 59.0%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 65.1%, epoch: 9 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [13/50] batch [20/176] time 0.082 (0.108) data 0.000 (0.013) loss 0.8854 (0.7653) ce_loss 0.5874 (0.4247) teacher_loss 0.4220 (0.2960) loss_zs_kd 0.1177 (0.1303) loss_oracle 0.4046 (0.4042) acc 78.1250 (85.6250) kd_loss 0.8239 (0.8639) lr 1.7705e-03 eta 0:12:01
epoch [13/50] batch [40/176] time 0.095 (0.100) data 0.000 (0.006) loss 0.7288 (0.7434) ce_loss 0.3206 (0.4002) teacher_loss 0.2546 (0.2807) loss_zs_kd 0.0849 (0.1279) loss_oracle 0.4318 (0.3987) acc 87.5000 (86.0156) kd_loss 0.8457 (0.8567) lr 1.7705e-03 eta 0:11:05
epoch [13/50] batch [60/176] time 0.111 (0.103) data 0.001 (0.004) loss 0.6352 (0.7432) ce_loss 0.2455 (0.3939) teacher_loss 0.1799 (0.2793) loss_zs_kd 0.1090 (0.1249) loss_oracle 0.4008 (0.4014) acc 93.7500 (86.1979) kd_loss 0.8927 (0.8467) lr 1.7705e-03 eta 0:11:21
epoch [13/50] batch [80/176] time 0.115 (0.104) data 0.000 (0.003) loss 0.6619 (0.7496) ce_loss 0.3120 (0.4100) teacher_loss 0.1856 (0.2956) loss_zs_kd 0.1155 (0.1229) loss_oracle 0.4186 (0.3926) acc 90.6250 (85.8203) kd_loss 0.7830 (0.8347) lr 1.7705e-03 eta 0:11:24
epoch [13/50] batch [100/176] time 0.101 (0.105) data 0.000 (0.003) loss 0.5340 (0.7501) ce_loss 0.1534 (0.4049) teacher_loss 0.1054 (0.2952) loss_zs_kd 0.1129 (0.1237) loss_oracle 0.3721 (0.3930) acc 96.8750 (85.8750) kd_loss 0.7664 (0.8293) lr 1.7705e-03 eta 0:11:31
epoch [13/50] batch [120/176] time 0.102 (0.107) data 0.000 (0.002) loss 0.7441 (0.7469) ce_loss 0.3857 (0.3971) teacher_loss 0.2950 (0.2902) loss_zs_kd 0.0951 (0.1214) loss_oracle 0.4016 (0.3960) acc 84.3750 (86.2500) kd_loss 0.8202 (0.8245) lr 1.7705e-03 eta 0:11:42
epoch [13/50] batch [140/176] time 0.083 (0.108) data 0.000 (0.002) loss 0.7160 (0.7523) ce_loss 0.3804 (0.3994) teacher_loss 0.2397 (0.2940) loss_zs_kd 0.1080 (0.1219) loss_oracle 0.4223 (0.3974) acc 81.2500 (86.0938) kd_loss 0.7560 (0.8183) lr 1.7705e-03 eta 0:11:49
epoch [13/50] batch [160/176] time 0.084 (0.109) data 0.000 (0.002) loss 0.7758 (0.7459) ce_loss 0.4395 (0.3945) teacher_loss 0.3710 (0.2933) loss_zs_kd 0.0989 (0.1191) loss_oracle 0.3554 (0.3931) acc 78.1250 (86.2305) kd_loss 0.7827 (0.8109) lr 1.7705e-03 eta 0:11:49
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,182
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,785
* accuracy: 67.2%
* error: 32.8%
* macro_f1: 61.4%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 65.1%, epoch: 9 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [14/50] batch [20/176] time 0.085 (0.122) data 0.000 (0.016) loss 0.7732 (0.7253) ce_loss 0.4058 (0.3949) teacher_loss 0.3523 (0.3146) loss_zs_kd 0.0956 (0.1056) loss_oracle 0.3731 (0.3580) acc 93.7500 (87.3438) kd_loss 0.7320 (0.7519) lr 1.7290e-03 eta 0:13:13
epoch [14/50] batch [40/176] time 0.071 (0.114) data 0.000 (0.008) loss 0.7051 (0.7385) ce_loss 0.3999 (0.4056) teacher_loss 0.2513 (0.3340) loss_zs_kd 0.1275 (0.1035) loss_oracle 0.3901 (0.3528) acc 87.5000 (86.1719) kd_loss 0.8186 (0.7464) lr 1.7290e-03 eta 0:12:20
epoch [14/50] batch [60/176] time 0.102 (0.112) data 0.000 (0.005) loss 0.8362 (0.7302) ce_loss 0.5488 (0.4029) teacher_loss 0.4890 (0.3328) loss_zs_kd 0.1259 (0.0978) loss_oracle 0.2842 (0.3485) acc 75.0000 (86.4062) kd_loss 0.7330 (0.7515) lr 1.7290e-03 eta 0:12:03
epoch [14/50] batch [80/176] time 0.120 (0.113) data 0.000 (0.004) loss 0.8431 (0.7374) ce_loss 0.4578 (0.4119) teacher_loss 0.4118 (0.3430) loss_zs_kd 0.0964 (0.0968) loss_oracle 0.3831 (0.3460) acc 87.5000 (86.0547) kd_loss 0.7551 (0.7474) lr 1.7290e-03 eta 0:12:05
epoch [14/50] batch [100/176] time 0.099 (0.113) data 0.000 (0.003) loss 0.5857 (0.7302) ce_loss 0.2183 (0.4043) teacher_loss 0.1744 (0.3361) loss_zs_kd 0.1117 (0.0969) loss_oracle 0.3554 (0.3456) acc 96.8750 (86.1250) kd_loss 0.7352 (0.7509) lr 1.7290e-03 eta 0:12:01
epoch [14/50] batch [120/176] time 0.088 (0.112) data 0.000 (0.003) loss 0.5692 (0.7230) ce_loss 0.2330 (0.4048) teacher_loss 0.1815 (0.3339) loss_zs_kd 0.0666 (0.0962) loss_oracle 0.3544 (0.3410) acc 93.7500 (85.8333) kd_loss 0.7550 (0.7490) lr 1.7290e-03 eta 0:11:52
epoch [14/50] batch [140/176] time 0.081 (0.111) data 0.000 (0.002) loss 0.4994 (0.7205) ce_loss 0.1847 (0.4034) teacher_loss 0.1429 (0.3339) loss_zs_kd 0.0909 (0.0960) loss_oracle 0.3110 (0.3386) acc 96.8750 (85.9821) kd_loss 0.7496 (0.7499) lr 1.7290e-03 eta 0:11:47
epoch [14/50] batch [160/176] time 0.093 (0.110) data 0.000 (0.002) loss 0.5715 (0.7188) ce_loss 0.3013 (0.4022) teacher_loss 0.2081 (0.3330) loss_zs_kd 0.0950 (0.0956) loss_oracle 0.3158 (0.3381) acc 87.5000 (85.9375) kd_loss 0.7441 (0.7498) lr 1.7290e-03 eta 0:11:38
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,182
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,730
* accuracy: 65.1%
* error: 34.9%
* macro_f1: 60.1%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 65.1%, epoch: 9 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [15/50] batch [20/176] time 0.127 (0.125) data 0.000 (0.015) loss 0.7724 (0.7057) ce_loss 0.4136 (0.4016) teacher_loss 0.3889 (0.3441) loss_zs_kd 0.0971 (0.0953) loss_oracle 0.3349 (0.3140) acc 78.1250 (85.7812) kd_loss 0.7861 (0.7324) lr 1.6845e-03 eta 0:13:12
epoch [15/50] batch [40/176] time 0.110 (0.111) data 0.000 (0.008) loss 0.7488 (0.7020) ce_loss 0.3569 (0.3868) teacher_loss 0.2923 (0.3218) loss_zs_kd 0.1405 (0.0931) loss_oracle 0.3863 (0.3337) acc 84.3750 (86.1719) kd_loss 0.8004 (0.7494) lr 1.6845e-03 eta 0:11:36
epoch [15/50] batch [60/176] time 0.136 (0.105) data 0.001 (0.005) loss 0.6081 (0.7083) ce_loss 0.2554 (0.3850) teacher_loss 0.2416 (0.3215) loss_zs_kd 0.0730 (0.0912) loss_oracle 0.3300 (0.3412) acc 93.7500 (86.3021) kd_loss 0.7087 (0.7530) lr 1.6845e-03 eta 0:10:59
epoch [15/50] batch [80/176] time 0.088 (0.105) data 0.000 (0.004) loss 0.6750 (0.7198) ce_loss 0.3713 (0.3940) teacher_loss 0.3035 (0.3232) loss_zs_kd 0.0784 (0.0948) loss_oracle 0.3323 (0.3492) acc 90.6250 (86.0156) kd_loss 0.7552 (0.7555) lr 1.6845e-03 eta 0:10:59
epoch [15/50] batch [100/176] time 0.119 (0.105) data 0.000 (0.003) loss 0.7475 (0.7228) ce_loss 0.4490 (0.3909) teacher_loss 0.3937 (0.3205) loss_zs_kd 0.0962 (0.0979) loss_oracle 0.3057 (0.3534) acc 87.5000 (86.1875) kd_loss 0.8055 (0.7597) lr 1.6845e-03 eta 0:10:52
epoch [15/50] batch [120/176] time 0.083 (0.105) data 0.000 (0.003) loss 0.6509 (0.7214) ce_loss 0.2600 (0.3871) teacher_loss 0.2469 (0.3168) loss_zs_kd 0.1263 (0.0986) loss_oracle 0.3409 (0.3552) acc 90.6250 (86.1719) kd_loss 0.7702 (0.7645) lr 1.6845e-03 eta 0:10:53
epoch [15/50] batch [140/176] time 0.136 (0.106) data 0.000 (0.002) loss 0.7267 (0.7206) ce_loss 0.3567 (0.3843) teacher_loss 0.3061 (0.3155) loss_zs_kd 0.0698 (0.0976) loss_oracle 0.3857 (0.3562) acc 81.2500 (86.3839) kd_loss 0.7202 (0.7661) lr 1.6845e-03 eta 0:10:58
epoch [15/50] batch [160/176] time 0.116 (0.106) data 0.000 (0.002) loss 0.7786 (0.7184) ce_loss 0.4592 (0.3841) teacher_loss 0.3226 (0.3146) loss_zs_kd 0.0921 (0.0967) loss_oracle 0.4100 (0.3555) acc 78.1250 (86.3086) kd_loss 0.8024 (0.7649) lr 1.6845e-03 eta 0:10:54
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,180
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,756
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 59.9%
******* Domain l best val acc:      90.4%, epoch: 9 *******
******* Domain l best val test acc: 65.1%, epoch: 9 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [16/50] batch [20/176] time 0.093 (0.127) data 0.000 (0.017) loss 0.9773 (0.7131) ce_loss 0.6743 (0.3989) teacher_loss 0.5885 (0.3347) loss_zs_kd 0.1245 (0.0992) loss_oracle 0.3265 (0.3288) acc 65.6250 (85.0000) kd_loss 0.7607 (0.7337) lr 1.6374e-03 eta 0:12:57
epoch [16/50] batch [40/176] time 0.092 (0.119) data 0.000 (0.009) loss 0.6494 (0.6898) ce_loss 0.4060 (0.3885) teacher_loss 0.3150 (0.3293) loss_zs_kd 0.1068 (0.0945) loss_oracle 0.2810 (0.3132) acc 90.6250 (85.7031) kd_loss 0.7032 (0.7288) lr 1.6374e-03 eta 0:12:05
epoch [16/50] batch [60/176] time 0.107 (0.113) data 0.000 (0.006) loss 0.4696 (0.6917) ce_loss 0.2737 (0.3967) teacher_loss 0.1643 (0.3328) loss_zs_kd 0.0857 (0.0948) loss_oracle 0.2624 (0.3115) acc 93.7500 (85.5729) kd_loss 0.6619 (0.7233) lr 1.6374e-03 eta 0:11:29
epoch [16/50] batch [80/176] time 0.110 (0.110) data 0.000 (0.004) loss 0.8705 (0.7055) ce_loss 0.5332 (0.4016) teacher_loss 0.5142 (0.3372) loss_zs_kd 0.0950 (0.0975) loss_oracle 0.3088 (0.3196) acc 81.2500 (85.8203) kd_loss 0.8035 (0.7312) lr 1.6374e-03 eta 0:11:10
epoch [16/50] batch [100/176] time 0.096 (0.108) data 0.000 (0.004) loss 0.7159 (0.7148) ce_loss 0.3604 (0.3984) teacher_loss 0.3047 (0.3355) loss_zs_kd 0.0535 (0.0969) loss_oracle 0.3845 (0.3308) acc 84.3750 (85.9688) kd_loss 0.8117 (0.7418) lr 1.6374e-03 eta 0:10:52
epoch [16/50] batch [120/176] time 0.109 (0.105) data 0.000 (0.003) loss 0.7335 (0.7158) ce_loss 0.3230 (0.3954) teacher_loss 0.2632 (0.3303) loss_zs_kd 0.1273 (0.0966) loss_oracle 0.4066 (0.3372) acc 87.5000 (85.7552) kd_loss 0.8285 (0.7476) lr 1.6374e-03 eta 0:10:32
epoch [16/50] batch [140/176] time 0.080 (0.103) data 0.000 (0.003) loss 0.6423 (0.7114) ce_loss 0.3228 (0.3843) teacher_loss 0.2872 (0.3210) loss_zs_kd 0.1023 (0.0955) loss_oracle 0.3039 (0.3426) acc 87.5000 (86.4286) kd_loss 0.7063 (0.7505) lr 1.6374e-03 eta 0:10:22
epoch [16/50] batch [160/176] time 0.113 (0.103) data 0.000 (0.002) loss 0.7327 (0.7091) ce_loss 0.3696 (0.3840) teacher_loss 0.3330 (0.3215) loss_zs_kd 0.0751 (0.0947) loss_oracle 0.3622 (0.3403) acc 87.5000 (86.5820) kd_loss 0.7939 (0.7514) lr 1.6374e-03 eta 0:10:15
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,192
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 92.3%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,733
* accuracy: 65.2%
* error: 34.8%
* macro_f1: 60.1%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [17/50] batch [20/176] time 0.084 (0.131) data 0.000 (0.014) loss 0.6124 (0.7257) ce_loss 0.3086 (0.4206) teacher_loss 0.1921 (0.3407) loss_zs_kd 0.1164 (0.0992) loss_oracle 0.3620 (0.3355) acc 93.7500 (85.1562) kd_loss 0.7368 (0.7480) lr 1.5878e-03 eta 0:13:01
epoch [17/50] batch [40/176] time 0.132 (0.116) data 0.000 (0.007) loss 0.5844 (0.6973) ce_loss 0.2411 (0.3946) teacher_loss 0.1952 (0.3195) loss_zs_kd 0.0846 (0.0988) loss_oracle 0.3470 (0.3284) acc 96.8750 (86.0938) kd_loss 0.7718 (0.7509) lr 1.5878e-03 eta 0:11:28
epoch [17/50] batch [60/176] time 0.078 (0.110) data 0.001 (0.005) loss 0.6161 (0.6972) ce_loss 0.4001 (0.3990) teacher_loss 0.3470 (0.3315) loss_zs_kd 0.0552 (0.0976) loss_oracle 0.2415 (0.3169) acc 90.6250 (86.0417) kd_loss 0.6574 (0.7412) lr 1.5878e-03 eta 0:10:53
epoch [17/50] batch [80/176] time 0.106 (0.108) data 0.000 (0.004) loss 0.6154 (0.6956) ce_loss 0.3584 (0.4023) teacher_loss 0.2821 (0.3330) loss_zs_kd 0.1172 (0.0966) loss_oracle 0.2747 (0.3144) acc 84.3750 (86.0938) kd_loss 0.7117 (0.7422) lr 1.5878e-03 eta 0:10:39
epoch [17/50] batch [100/176] time 0.081 (0.107) data 0.000 (0.003) loss 0.6155 (0.6958) ce_loss 0.3374 (0.4013) teacher_loss 0.2431 (0.3334) loss_zs_kd 0.1114 (0.0977) loss_oracle 0.3167 (0.3136) acc 90.6250 (86.4375) kd_loss 0.7632 (0.7424) lr 1.5878e-03 eta 0:10:29
epoch [17/50] batch [120/176] time 0.134 (0.106) data 0.000 (0.002) loss 0.8258 (0.7007) ce_loss 0.3521 (0.4008) teacher_loss 0.2839 (0.3324) loss_zs_kd 0.1078 (0.0975) loss_oracle 0.4880 (0.3196) acc 87.5000 (86.2500) kd_loss 0.8191 (0.7471) lr 1.5878e-03 eta 0:10:23
epoch [17/50] batch [140/176] time 0.122 (0.106) data 0.000 (0.002) loss 0.6471 (0.7001) ce_loss 0.3796 (0.3995) teacher_loss 0.2904 (0.3304) loss_zs_kd 0.1205 (0.0969) loss_oracle 0.2964 (0.3213) acc 87.5000 (86.4062) kd_loss 0.6752 (0.7482) lr 1.5878e-03 eta 0:10:17
epoch [17/50] batch [160/176] time 0.082 (0.104) data 0.000 (0.002) loss 0.7758 (0.6963) ce_loss 0.3574 (0.3936) teacher_loss 0.2857 (0.3238) loss_zs_kd 0.1124 (0.0965) loss_oracle 0.4339 (0.3243) acc 84.3750 (86.5039) kd_loss 0.7873 (0.7508) lr 1.5878e-03 eta 0:10:07
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,190
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,750
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 60.2%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [18/50] batch [20/176] time 0.132 (0.125) data 0.000 (0.012) loss 0.6473 (0.6928) ce_loss 0.2961 (0.3628) teacher_loss 0.2170 (0.2761) loss_zs_kd 0.1109 (0.1149) loss_oracle 0.3749 (0.3593) acc 90.6250 (88.1250) kd_loss 0.7728 (0.7617) lr 1.5358e-03 eta 0:12:02
epoch [18/50] batch [40/176] time 0.101 (0.115) data 0.000 (0.006) loss 0.7941 (0.6841) ce_loss 0.4937 (0.3556) teacher_loss 0.3537 (0.2785) loss_zs_kd 0.1169 (0.1114) loss_oracle 0.3820 (0.3499) acc 81.2500 (88.1250) kd_loss 0.7956 (0.7611) lr 1.5358e-03 eta 0:11:01
epoch [18/50] batch [60/176] time 0.131 (0.113) data 0.001 (0.004) loss 0.6468 (0.7120) ce_loss 0.3174 (0.3903) teacher_loss 0.3229 (0.3077) loss_zs_kd 0.1407 (0.1111) loss_oracle 0.2536 (0.3487) acc 93.7500 (86.3542) kd_loss 0.7499 (0.7595) lr 1.5358e-03 eta 0:10:49
epoch [18/50] batch [80/176] time 0.129 (0.112) data 0.000 (0.003) loss 0.6440 (0.7152) ce_loss 0.3054 (0.3959) teacher_loss 0.2728 (0.3164) loss_zs_kd 0.0791 (0.1077) loss_oracle 0.3316 (0.3449) acc 93.7500 (86.2109) kd_loss 0.7280 (0.7523) lr 1.5358e-03 eta 0:10:43
epoch [18/50] batch [100/176] time 0.082 (0.112) data 0.000 (0.003) loss 0.6503 (0.7160) ce_loss 0.3594 (0.3928) teacher_loss 0.2989 (0.3151) loss_zs_kd 0.1187 (0.1064) loss_oracle 0.2921 (0.3476) acc 81.2500 (86.2500) kd_loss 0.6723 (0.7525) lr 1.5358e-03 eta 0:10:40
epoch [18/50] batch [120/176] time 0.080 (0.112) data 0.000 (0.002) loss 0.7422 (0.7136) ce_loss 0.4092 (0.3911) teacher_loss 0.3269 (0.3136) loss_zs_kd 0.0860 (0.1060) loss_oracle 0.3723 (0.3470) acc 87.5000 (86.5365) kd_loss 0.7941 (0.7552) lr 1.5358e-03 eta 0:10:36
epoch [18/50] batch [140/176] time 0.078 (0.112) data 0.000 (0.002) loss 0.5933 (0.7059) ce_loss 0.2332 (0.3844) teacher_loss 0.1491 (0.3074) loss_zs_kd 0.1002 (0.1027) loss_oracle 0.3941 (0.3471) acc 90.6250 (86.8750) kd_loss 0.8786 (0.7569) lr 1.5358e-03 eta 0:10:33
epoch [18/50] batch [160/176] time 0.099 (0.111) data 0.000 (0.002) loss 0.7255 (0.7078) ce_loss 0.4287 (0.3850) teacher_loss 0.3913 (0.3084) loss_zs_kd 0.1060 (0.1029) loss_oracle 0.2812 (0.3479) acc 81.2500 (86.9922) kd_loss 0.7167 (0.7580) lr 1.5358e-03 eta 0:10:25
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,189
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,705
* accuracy: 64.2%
* error: 35.8%
* macro_f1: 59.5%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [19/50] batch [20/176] time 0.071 (0.152) data 0.000 (0.014) loss 0.8738 (0.7483) ce_loss 0.7002 (0.4223) teacher_loss 0.4392 (0.3254) loss_zs_kd 0.1230 (0.1004) loss_oracle 0.3731 (0.3727) acc 75.0000 (83.9062) kd_loss 0.7533 (0.7559) lr 1.4818e-03 eta 0:14:11
epoch [19/50] batch [40/176] time 0.079 (0.125) data 0.000 (0.007) loss 0.5427 (0.7352) ce_loss 0.2472 (0.4118) teacher_loss 0.1388 (0.3145) loss_zs_kd 0.1032 (0.1100) loss_oracle 0.3523 (0.3658) acc 93.7500 (84.8438) kd_loss 0.7442 (0.7510) lr 1.4818e-03 eta 0:11:37
epoch [19/50] batch [60/176] time 0.074 (0.115) data 0.000 (0.005) loss 0.6176 (0.7295) ce_loss 0.3081 (0.4088) teacher_loss 0.2618 (0.3150) loss_zs_kd 0.0968 (0.1085) loss_oracle 0.3073 (0.3602) acc 93.7500 (84.9479) kd_loss 0.7716 (0.7490) lr 1.4818e-03 eta 0:10:42
epoch [19/50] batch [80/176] time 0.108 (0.111) data 0.000 (0.004) loss 0.7430 (0.7143) ce_loss 0.3452 (0.3911) teacher_loss 0.2428 (0.2990) loss_zs_kd 0.1228 (0.1083) loss_oracle 0.4388 (0.3611) acc 84.3750 (86.1719) kd_loss 0.8215 (0.7493) lr 1.4818e-03 eta 0:10:16
epoch [19/50] batch [100/176] time 0.087 (0.109) data 0.000 (0.003) loss 0.7607 (0.7173) ce_loss 0.5132 (0.3924) teacher_loss 0.3727 (0.3019) loss_zs_kd 0.0911 (0.1091) loss_oracle 0.3425 (0.3608) acc 78.1250 (86.2500) kd_loss 0.7206 (0.7483) lr 1.4818e-03 eta 0:10:03
epoch [19/50] batch [120/176] time 0.113 (0.108) data 0.000 (0.003) loss 0.7479 (0.7094) ce_loss 0.4568 (0.3910) teacher_loss 0.3768 (0.3015) loss_zs_kd 0.1083 (0.1068) loss_oracle 0.3170 (0.3546) acc 81.2500 (86.4844) kd_loss 0.7183 (0.7427) lr 1.4818e-03 eta 0:09:55
epoch [19/50] batch [140/176] time 0.088 (0.107) data 0.000 (0.002) loss 0.6855 (0.7022) ce_loss 0.2964 (0.3873) teacher_loss 0.2838 (0.2979) loss_zs_kd 0.1354 (0.1075) loss_oracle 0.3339 (0.3505) acc 93.7500 (86.6741) kd_loss 0.6962 (0.7386) lr 1.4818e-03 eta 0:09:47
epoch [19/50] batch [160/176] time 0.077 (0.105) data 0.000 (0.002) loss 0.7923 (0.6959) ce_loss 0.4966 (0.3790) teacher_loss 0.4380 (0.2929) loss_zs_kd 0.1111 (0.1070) loss_oracle 0.2988 (0.3495) acc 81.2500 (86.9922) kd_loss 0.6931 (0.7374) lr 1.4818e-03 eta 0:09:34
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,186
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,669
* accuracy: 62.8%
* error: 37.2%
* macro_f1: 58.7%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [20/50] batch [20/176] time 0.142 (0.126) data 0.000 (0.012) loss 0.6856 (0.6890) ce_loss 0.3303 (0.3705) teacher_loss 0.2503 (0.3059) loss_zs_kd 0.1146 (0.0940) loss_oracle 0.3781 (0.3361) acc 84.3750 (87.8125) kd_loss 0.7681 (0.7349) lr 1.4258e-03 eta 0:11:24
epoch [20/50] batch [40/176] time 0.100 (0.116) data 0.000 (0.006) loss 0.4788 (0.6755) ce_loss 0.1974 (0.3635) teacher_loss 0.1461 (0.2954) loss_zs_kd 0.0703 (0.0973) loss_oracle 0.2975 (0.3314) acc 93.7500 (87.8906) kd_loss 0.7429 (0.7305) lr 1.4258e-03 eta 0:10:30
epoch [20/50] batch [60/176] time 0.095 (0.110) data 0.000 (0.004) loss 0.6609 (0.6745) ce_loss 0.3765 (0.3685) teacher_loss 0.3359 (0.2948) loss_zs_kd 0.0889 (0.0992) loss_oracle 0.2805 (0.3301) acc 90.6250 (87.5521) kd_loss 0.7015 (0.7291) lr 1.4258e-03 eta 0:09:55
epoch [20/50] batch [80/176] time 0.087 (0.109) data 0.000 (0.003) loss 0.6550 (0.6775) ce_loss 0.3572 (0.3727) teacher_loss 0.2582 (0.2964) loss_zs_kd 0.1150 (0.0999) loss_oracle 0.3393 (0.3311) acc 90.6250 (87.5781) kd_loss 0.6659 (0.7355) lr 1.4258e-03 eta 0:09:46
epoch [20/50] batch [100/176] time 0.134 (0.108) data 0.000 (0.003) loss 0.7619 (0.6834) ce_loss 0.4114 (0.3758) teacher_loss 0.3282 (0.2947) loss_zs_kd 0.0757 (0.1009) loss_oracle 0.3959 (0.3383) acc 84.3750 (87.4062) kd_loss 0.8040 (0.7398) lr 1.4258e-03 eta 0:09:36
epoch [20/50] batch [120/176] time 0.100 (0.107) data 0.000 (0.002) loss 0.7088 (0.6852) ce_loss 0.4258 (0.3765) teacher_loss 0.3142 (0.2931) loss_zs_kd 0.1202 (0.1034) loss_oracle 0.3346 (0.3404) acc 81.2500 (87.1094) kd_loss 0.7334 (0.7399) lr 1.4258e-03 eta 0:09:30
epoch [20/50] batch [140/176] time 0.117 (0.107) data 0.000 (0.002) loss 0.7372 (0.6889) ce_loss 0.4551 (0.3747) teacher_loss 0.3346 (0.2921) loss_zs_kd 0.1663 (0.1041) loss_oracle 0.3194 (0.3448) acc 84.3750 (87.0089) kd_loss 0.6720 (0.7443) lr 1.4258e-03 eta 0:09:26
epoch [20/50] batch [160/176] time 0.112 (0.106) data 0.000 (0.002) loss 0.5761 (0.6927) ce_loss 0.2585 (0.3775) teacher_loss 0.1989 (0.2952) loss_zs_kd 0.0861 (0.1043) loss_oracle 0.3342 (0.3454) acc 93.7500 (86.8750) kd_loss 0.7782 (0.7468) lr 1.4258e-03 eta 0:09:23
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,179
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.8%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,731
* accuracy: 65.2%
* error: 34.8%
* macro_f1: 59.0%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [21/50] batch [20/176] time 0.151 (0.134) data 0.000 (0.014) loss 0.6449 (0.6818) ce_loss 0.2664 (0.3879) teacher_loss 0.2000 (0.3075) loss_zs_kd 0.0815 (0.0985) loss_oracle 0.4041 (0.3250) acc 90.6250 (87.6562) kd_loss 0.8049 (0.7347) lr 1.3681e-03 eta 0:11:46
epoch [21/50] batch [40/176] time 0.137 (0.141) data 0.000 (0.007) loss 0.5395 (0.6677) ce_loss 0.2201 (0.3631) teacher_loss 0.1657 (0.2898) loss_zs_kd 0.0736 (0.0947) loss_oracle 0.3369 (0.3305) acc 93.7500 (88.2031) kd_loss 0.7065 (0.7419) lr 1.3681e-03 eta 0:12:17
epoch [21/50] batch [60/176] time 0.117 (0.129) data 0.000 (0.005) loss 0.6875 (0.6795) ce_loss 0.3462 (0.3711) teacher_loss 0.2969 (0.2942) loss_zs_kd 0.1223 (0.0977) loss_oracle 0.3295 (0.3365) acc 96.8750 (87.6562) kd_loss 0.7521 (0.7514) lr 1.3681e-03 eta 0:11:11
epoch [21/50] batch [80/176] time 0.088 (0.120) data 0.000 (0.004) loss 0.7243 (0.6955) ce_loss 0.4385 (0.3777) teacher_loss 0.3071 (0.3049) loss_zs_kd 0.1137 (0.0987) loss_oracle 0.3603 (0.3413) acc 93.7500 (87.5781) kd_loss 0.7590 (0.7561) lr 1.3681e-03 eta 0:10:21
epoch [21/50] batch [100/176] time 0.077 (0.114) data 0.000 (0.003) loss 0.6102 (0.6969) ce_loss 0.2944 (0.3801) teacher_loss 0.2013 (0.3085) loss_zs_kd 0.1416 (0.0992) loss_oracle 0.3381 (0.3388) acc 90.6250 (87.2812) kd_loss 0.7727 (0.7517) lr 1.3681e-03 eta 0:09:52
epoch [21/50] batch [120/176] time 0.092 (0.114) data 0.000 (0.003) loss 0.8140 (0.7010) ce_loss 0.5278 (0.3890) teacher_loss 0.4452 (0.3134) loss_zs_kd 0.0733 (0.0993) loss_oracle 0.3322 (0.3379) acc 81.2500 (86.9792) kd_loss 0.8259 (0.7505) lr 1.3681e-03 eta 0:09:48
epoch [21/50] batch [140/176] time 0.089 (0.113) data 0.000 (0.002) loss 0.5747 (0.6967) ce_loss 0.2009 (0.3837) teacher_loss 0.2055 (0.3081) loss_zs_kd 0.0752 (0.1005) loss_oracle 0.3317 (0.3384) acc 93.7500 (87.1205) kd_loss 0.7161 (0.7484) lr 1.3681e-03 eta 0:09:39
epoch [21/50] batch [160/176] time 0.129 (0.111) data 0.000 (0.002) loss 0.6767 (0.6937) ce_loss 0.2764 (0.3832) teacher_loss 0.2808 (0.3071) loss_zs_kd 0.1129 (0.1004) loss_oracle 0.3395 (0.3365) acc 90.6250 (86.7969) kd_loss 0.7709 (0.7469) lr 1.3681e-03 eta 0:09:29
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,185
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,675
* accuracy: 63.1%
* error: 36.9%
* macro_f1: 58.3%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [22/50] batch [20/176] time 0.105 (0.125) data 0.001 (0.015) loss 0.7023 (0.6705) ce_loss 0.3828 (0.3899) teacher_loss 0.3158 (0.3203) loss_zs_kd 0.0811 (0.1020) loss_oracle 0.3460 (0.2992) acc 84.3750 (85.4688) kd_loss 0.7238 (0.7065) lr 1.3090e-03 eta 0:10:34
epoch [22/50] batch [40/176] time 0.127 (0.117) data 0.001 (0.008) loss 0.7107 (0.6810) ce_loss 0.4421 (0.3893) teacher_loss 0.3819 (0.3192) loss_zs_kd 0.0644 (0.0981) loss_oracle 0.2966 (0.3128) acc 81.2500 (85.6250) kd_loss 0.6390 (0.7188) lr 1.3090e-03 eta 0:09:51
epoch [22/50] batch [60/176] time 0.088 (0.116) data 0.001 (0.005) loss 0.6296 (0.6821) ce_loss 0.3008 (0.3882) teacher_loss 0.2789 (0.3155) loss_zs_kd 0.1034 (0.0957) loss_oracle 0.2990 (0.3188) acc 87.5000 (86.1979) kd_loss 0.7047 (0.7219) lr 1.3090e-03 eta 0:09:43
epoch [22/50] batch [80/176] time 0.094 (0.114) data 0.000 (0.004) loss 0.7087 (0.6916) ce_loss 0.3396 (0.3847) teacher_loss 0.2866 (0.3135) loss_zs_kd 0.0935 (0.0966) loss_oracle 0.3754 (0.3299) acc 93.7500 (86.3281) kd_loss 0.7927 (0.7318) lr 1.3090e-03 eta 0:09:34
epoch [22/50] batch [100/176] time 0.135 (0.114) data 0.001 (0.003) loss 0.6541 (0.7006) ce_loss 0.3027 (0.3900) teacher_loss 0.2500 (0.3186) loss_zs_kd 0.1090 (0.0982) loss_oracle 0.3495 (0.3329) acc 87.5000 (86.1875) kd_loss 0.8070 (0.7371) lr 1.3090e-03 eta 0:09:31
epoch [22/50] batch [120/176] time 0.132 (0.114) data 0.000 (0.003) loss 1.0603 (0.7037) ce_loss 0.6748 (0.3920) teacher_loss 0.5997 (0.3187) loss_zs_kd 0.1169 (0.0990) loss_oracle 0.4021 (0.3356) acc 78.1250 (85.9896) kd_loss 0.8524 (0.7405) lr 1.3090e-03 eta 0:09:26
epoch [22/50] batch [140/176] time 0.077 (0.113) data 0.000 (0.002) loss 0.5704 (0.6991) ce_loss 0.2764 (0.3864) teacher_loss 0.1780 (0.3107) loss_zs_kd 0.1001 (0.0990) loss_oracle 0.3424 (0.3389) acc 90.6250 (86.2054) kd_loss 0.7149 (0.7418) lr 1.3090e-03 eta 0:09:18
epoch [22/50] batch [160/176] time 0.117 (0.112) data 0.000 (0.002) loss 0.7056 (0.6991) ce_loss 0.4304 (0.3880) teacher_loss 0.3013 (0.3103) loss_zs_kd 0.1029 (0.0991) loss_oracle 0.3528 (0.3392) acc 78.1250 (86.2109) kd_loss 0.7783 (0.7423) lr 1.3090e-03 eta 0:09:13
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,182
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 91.8%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,743
* accuracy: 65.6%
* error: 34.4%
* macro_f1: 60.0%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [23/50] batch [20/176] time 0.178 (0.160) data 0.000 (0.014) loss 0.7941 (0.7023) ce_loss 0.4348 (0.4127) teacher_loss 0.3528 (0.3206) loss_zs_kd 0.0839 (0.0917) loss_oracle 0.3993 (0.3359) acc 81.2500 (83.5938) kd_loss 0.7993 (0.7286) lr 1.2487e-03 eta 0:13:07
epoch [23/50] batch [40/176] time 0.177 (0.139) data 0.000 (0.007) loss 0.7918 (0.6951) ce_loss 0.4182 (0.3880) teacher_loss 0.3681 (0.3033) loss_zs_kd 0.1003 (0.0955) loss_oracle 0.3735 (0.3441) acc 78.1250 (85.4688) kd_loss 0.7367 (0.7310) lr 1.2487e-03 eta 0:11:20
epoch [23/50] batch [60/176] time 0.175 (0.147) data 0.001 (0.005) loss 0.7048 (0.6993) ce_loss 0.4192 (0.3940) teacher_loss 0.3987 (0.3071) loss_zs_kd 0.0928 (0.0992) loss_oracle 0.2597 (0.3426) acc 84.3750 (85.9896) kd_loss 0.6611 (0.7398) lr 1.2487e-03 eta 0:11:56
epoch [23/50] batch [80/176] time 0.128 (0.134) data 0.000 (0.004) loss 0.7633 (0.7015) ce_loss 0.4854 (0.3956) teacher_loss 0.4130 (0.3065) loss_zs_kd 0.0850 (0.1015) loss_oracle 0.3078 (0.3443) acc 78.1250 (86.0156) kd_loss 0.7167 (0.7457) lr 1.2487e-03 eta 0:10:47
epoch [23/50] batch [100/176] time 0.096 (0.127) data 0.000 (0.003) loss 0.8705 (0.7007) ce_loss 0.4919 (0.3881) teacher_loss 0.4362 (0.3005) loss_zs_kd 0.1036 (0.1024) loss_oracle 0.3826 (0.3490) acc 78.1250 (86.0625) kd_loss 0.8360 (0.7585) lr 1.2487e-03 eta 0:10:15
epoch [23/50] batch [120/176] time 0.119 (0.123) data 0.000 (0.003) loss 0.5851 (0.7020) ce_loss 0.1957 (0.3875) teacher_loss 0.1808 (0.2993) loss_zs_kd 0.0695 (0.1039) loss_oracle 0.3695 (0.3508) acc 90.6250 (86.0938) kd_loss 0.7933 (0.7605) lr 1.2487e-03 eta 0:09:49
epoch [23/50] batch [140/176] time 0.119 (0.119) data 0.000 (0.002) loss 0.7154 (0.7019) ce_loss 0.3191 (0.3893) teacher_loss 0.2613 (0.2986) loss_zs_kd 0.1275 (0.1043) loss_oracle 0.3903 (0.3511) acc 90.6250 (86.0491) kd_loss 0.8332 (0.7626) lr 1.2487e-03 eta 0:09:31
epoch [23/50] batch [160/176] time 0.079 (0.118) data 0.000 (0.002) loss 0.6664 (0.6981) ce_loss 0.3088 (0.3833) teacher_loss 0.2410 (0.2947) loss_zs_kd 0.1118 (0.1037) loss_oracle 0.3694 (0.3515) acc 96.8750 (86.3867) kd_loss 0.7488 (0.7627) lr 1.2487e-03 eta 0:09:20
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,186
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,672
* accuracy: 63.0%
* error: 37.0%
* macro_f1: 58.2%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [24/50] batch [20/176] time 0.078 (0.120) data 0.000 (0.012) loss 0.6795 (0.6876) ce_loss 0.2959 (0.3524) teacher_loss 0.2416 (0.2695) loss_zs_kd 0.1445 (0.1163) loss_oracle 0.3656 (0.3600) acc 93.7500 (89.5312) kd_loss 0.7762 (0.7530) lr 1.1874e-03 eta 0:09:26
epoch [24/50] batch [40/176] time 0.142 (0.118) data 0.000 (0.006) loss 0.5493 (0.6774) ce_loss 0.2413 (0.3490) teacher_loss 0.1991 (0.2691) loss_zs_kd 0.1108 (0.1107) loss_oracle 0.2948 (0.3529) acc 93.7500 (88.3594) kd_loss 0.7102 (0.7469) lr 1.1874e-03 eta 0:09:14
epoch [24/50] batch [60/176] time 0.114 (0.116) data 0.000 (0.004) loss 0.5745 (0.6958) ce_loss 0.3374 (0.3751) teacher_loss 0.2723 (0.2954) loss_zs_kd 0.0960 (0.1100) loss_oracle 0.2542 (0.3454) acc 87.5000 (87.3958) kd_loss 0.5990 (0.7386) lr 1.1874e-03 eta 0:09:02
epoch [24/50] batch [80/176] time 0.091 (0.115) data 0.000 (0.003) loss 0.6047 (0.6989) ce_loss 0.2837 (0.3763) teacher_loss 0.1970 (0.2934) loss_zs_kd 0.0685 (0.1075) loss_oracle 0.3735 (0.3517) acc 90.6250 (87.0703) kd_loss 0.8397 (0.7454) lr 1.1874e-03 eta 0:08:56
epoch [24/50] batch [100/176] time 0.072 (0.112) data 0.000 (0.003) loss 0.4292 (0.6952) ce_loss 0.1786 (0.3740) teacher_loss 0.1278 (0.2902) loss_zs_kd 0.0597 (0.1073) loss_oracle 0.2715 (0.3514) acc 96.8750 (87.3125) kd_loss 0.6962 (0.7469) lr 1.1874e-03 eta 0:08:42
epoch [24/50] batch [120/176] time 0.133 (0.111) data 0.000 (0.002) loss 0.5601 (0.6952) ce_loss 0.2786 (0.3713) teacher_loss 0.1886 (0.2914) loss_zs_kd 0.0886 (0.1057) loss_oracle 0.3271 (0.3509) acc 87.5000 (87.2656) kd_loss 0.8353 (0.7509) lr 1.1874e-03 eta 0:08:33
epoch [24/50] batch [140/176] time 0.088 (0.110) data 0.000 (0.002) loss 0.5949 (0.6846) ce_loss 0.2944 (0.3671) teacher_loss 0.2092 (0.2864) loss_zs_kd 0.1069 (0.1046) loss_oracle 0.3322 (0.3459) acc 90.6250 (87.2098) kd_loss 0.7421 (0.7481) lr 1.1874e-03 eta 0:08:25
epoch [24/50] batch [160/176] time 0.103 (0.108) data 0.000 (0.002) loss 0.7853 (0.6937) ce_loss 0.4575 (0.3730) teacher_loss 0.4242 (0.2920) loss_zs_kd 0.1117 (0.1063) loss_oracle 0.3053 (0.3485) acc 84.3750 (87.0117) kd_loss 0.7076 (0.7478) lr 1.1874e-03 eta 0:08:17
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,186
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,701
* accuracy: 64.0%
* error: 36.0%
* macro_f1: 59.3%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [25/50] batch [20/176] time 0.074 (0.099) data 0.000 (0.014) loss 0.8426 (0.7002) ce_loss 0.3853 (0.3644) teacher_loss 0.3361 (0.3022) loss_zs_kd 0.1145 (0.1019) loss_oracle 0.4492 (0.3470) acc 87.5000 (87.3438) kd_loss 0.8340 (0.7348) lr 1.1253e-03 eta 0:07:29
epoch [25/50] batch [40/176] time 0.154 (0.120) data 0.000 (0.007) loss 0.7118 (0.6998) ce_loss 0.3704 (0.3702) teacher_loss 0.2934 (0.3028) loss_zs_kd 0.0912 (0.0979) loss_oracle 0.3728 (0.3481) acc 87.5000 (87.2656) kd_loss 0.7397 (0.7327) lr 1.1253e-03 eta 0:09:06
epoch [25/50] batch [60/176] time 0.119 (0.109) data 0.001 (0.005) loss 0.7139 (0.6909) ce_loss 0.3948 (0.3653) teacher_loss 0.2934 (0.2960) loss_zs_kd 0.1055 (0.0976) loss_oracle 0.3678 (0.3462) acc 87.5000 (87.9167) kd_loss 0.8263 (0.7365) lr 1.1253e-03 eta 0:08:13
epoch [25/50] batch [80/176] time 0.146 (0.119) data 0.000 (0.004) loss 0.6873 (0.6927) ce_loss 0.3137 (0.3644) teacher_loss 0.2473 (0.2945) loss_zs_kd 0.0995 (0.0994) loss_oracle 0.3903 (0.3485) acc 87.5000 (88.0078) kd_loss 0.7692 (0.7492) lr 1.1253e-03 eta 0:08:55
epoch [25/50] batch [100/176] time 0.140 (0.117) data 0.000 (0.003) loss 0.7122 (0.6999) ce_loss 0.4121 (0.3717) teacher_loss 0.2577 (0.2962) loss_zs_kd 0.0927 (0.1016) loss_oracle 0.4082 (0.3529) acc 87.5000 (87.5938) kd_loss 0.8364 (0.7554) lr 1.1253e-03 eta 0:08:43
epoch [25/50] batch [120/176] time 0.071 (0.113) data 0.000 (0.003) loss 0.9654 (0.7136) ce_loss 0.5923 (0.3785) teacher_loss 0.4163 (0.3017) loss_zs_kd 0.1006 (0.1043) loss_oracle 0.4988 (0.3598) acc 81.2500 (87.3958) kd_loss 0.9272 (0.7649) lr 1.1253e-03 eta 0:08:22
epoch [25/50] batch [140/176] time 0.120 (0.112) data 0.000 (0.002) loss 0.5679 (0.7211) ce_loss 0.2450 (0.3831) teacher_loss 0.1971 (0.3026) loss_zs_kd 0.0817 (0.1063) loss_oracle 0.3299 (0.3654) acc 90.6250 (87.1652) kd_loss 0.7102 (0.7725) lr 1.1253e-03 eta 0:08:15
epoch [25/50] batch [160/176] time 0.098 (0.110) data 0.000 (0.002) loss 0.8157 (0.7259) ce_loss 0.5195 (0.3833) teacher_loss 0.3706 (0.3036) loss_zs_kd 0.0965 (0.1075) loss_oracle 0.3968 (0.3686) acc 84.3750 (87.1289) kd_loss 0.8267 (0.7767) lr 1.1253e-03 eta 0:08:05
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,186
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,722
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 59.7%
******* Domain l best val acc:      90.5%, epoch: 16 *******
******* Domain l best val test acc: 65.2%, epoch: 16 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [26/50] batch [20/176] time 0.118 (0.126) data 0.000 (0.015) loss 0.7819 (0.7154) ce_loss 0.4487 (0.3547) teacher_loss 0.3164 (0.2703) loss_zs_kd 0.1150 (0.1127) loss_oracle 0.4080 (0.3888) acc 87.5000 (89.3750) kd_loss 0.9286 (0.7940) lr 1.0628e-03 eta 0:09:11
epoch [26/50] batch [40/176] time 0.107 (0.119) data 0.000 (0.008) loss 0.9090 (0.7629) ce_loss 0.5693 (0.3924) teacher_loss 0.4676 (0.3064) loss_zs_kd 0.1164 (0.1128) loss_oracle 0.3832 (0.4001) acc 78.1250 (87.2656) kd_loss 0.8058 (0.8092) lr 1.0628e-03 eta 0:08:39
epoch [26/50] batch [60/176] time 0.114 (0.115) data 0.000 (0.005) loss 0.6886 (0.7616) ce_loss 0.4031 (0.3948) teacher_loss 0.2702 (0.3078) loss_zs_kd 0.0952 (0.1120) loss_oracle 0.3708 (0.3977) acc 78.1250 (86.8750) kd_loss 0.7561 (0.7948) lr 1.0628e-03 eta 0:08:21
epoch [26/50] batch [80/176] time 0.094 (0.112) data 0.000 (0.004) loss 0.6014 (0.7564) ce_loss 0.3174 (0.3950) teacher_loss 0.2177 (0.3045) loss_zs_kd 0.1148 (0.1131) loss_oracle 0.3263 (0.3953) acc 84.3750 (86.6406) kd_loss 0.7097 (0.7941) lr 1.0628e-03 eta 0:08:02
epoch [26/50] batch [100/176] time 0.098 (0.109) data 0.000 (0.003) loss 0.7486 (0.7661) ce_loss 0.2812 (0.4004) teacher_loss 0.2353 (0.3093) loss_zs_kd 0.1643 (0.1142) loss_oracle 0.4311 (0.3997) acc 90.6250 (86.1875) kd_loss 0.7685 (0.7994) lr 1.0628e-03 eta 0:07:50
epoch [26/50] batch [120/176] time 0.134 (0.109) data 0.000 (0.003) loss 0.6783 (0.7566) ce_loss 0.2325 (0.3925) teacher_loss 0.2032 (0.3061) loss_zs_kd 0.0694 (0.1116) loss_oracle 0.4404 (0.3947) acc 93.7500 (86.5885) kd_loss 0.8435 (0.7968) lr 1.0628e-03 eta 0:07:44
epoch [26/50] batch [140/176] time 0.122 (0.108) data 0.000 (0.002) loss 0.7526 (0.7508) ce_loss 0.4441 (0.3878) teacher_loss 0.3529 (0.3035) loss_zs_kd 0.1454 (0.1105) loss_oracle 0.3270 (0.3921) acc 93.7500 (86.8973) kd_loss 0.7082 (0.8005) lr 1.0628e-03 eta 0:07:39
epoch [26/50] batch [160/176] time 0.118 (0.107) data 0.000 (0.002) loss 0.6073 (0.7441) ce_loss 0.2213 (0.3832) teacher_loss 0.1504 (0.2990) loss_zs_kd 0.0756 (0.1095) loss_oracle 0.4191 (0.3903) acc 93.7500 (86.9922) kd_loss 0.7902 (0.8004) lr 1.0628e-03 eta 0:07:33
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,193
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 92.3%
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,707
* accuracy: 64.3%
* error: 35.7%
* macro_f1: 59.8%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [27/50] batch [20/176] time 0.115 (0.116) data 0.000 (0.016) loss 0.5419 (0.7040) ce_loss 0.1956 (0.3541) teacher_loss 0.1663 (0.2786) loss_zs_kd 0.1392 (0.1145) loss_oracle 0.3060 (0.3682) acc 90.6250 (88.2812) kd_loss 0.7154 (0.7920) lr 1.0000e-03 eta 0:08:09
epoch [27/50] batch [40/176] time 0.078 (0.108) data 0.000 (0.008) loss 0.4486 (0.7011) ce_loss 0.1198 (0.3412) teacher_loss 0.1000 (0.2674) loss_zs_kd 0.0546 (0.1131) loss_oracle 0.3214 (0.3772) acc 93.7500 (88.4375) kd_loss 0.7790 (0.8016) lr 1.0000e-03 eta 0:07:33
epoch [27/50] batch [60/176] time 0.191 (0.107) data 0.001 (0.005) loss 0.8441 (0.7177) ce_loss 0.4106 (0.3575) teacher_loss 0.3729 (0.2831) loss_zs_kd 0.1317 (0.1123) loss_oracle 0.4053 (0.3784) acc 87.5000 (87.7604) kd_loss 0.7994 (0.8058) lr 1.0000e-03 eta 0:07:25
epoch [27/50] batch [80/176] time 0.069 (0.113) data 0.000 (0.004) loss 0.8366 (0.7224) ce_loss 0.2930 (0.3586) teacher_loss 0.2784 (0.2844) loss_zs_kd 0.1378 (0.1129) loss_oracle 0.4893 (0.3816) acc 96.8750 (87.8906) kd_loss 0.9336 (0.8145) lr 1.0000e-03 eta 0:07:47
epoch [27/50] batch [100/176] time 0.178 (0.122) data 0.000 (0.003) loss 0.6571 (0.7245) ce_loss 0.2842 (0.3578) teacher_loss 0.2442 (0.2832) loss_zs_kd 0.1031 (0.1126) loss_oracle 0.3613 (0.3850) acc 90.6250 (87.7188) kd_loss 0.7933 (0.8206) lr 1.0000e-03 eta 0:08:24
epoch [27/50] batch [120/176] time 0.118 (0.122) data 0.000 (0.003) loss 0.6624 (0.7256) ce_loss 0.3320 (0.3591) teacher_loss 0.2773 (0.2813) loss_zs_kd 0.1541 (0.1144) loss_oracle 0.3080 (0.3871) acc 81.2500 (87.3438) kd_loss 0.7875 (0.8196) lr 1.0000e-03 eta 0:08:20
epoch [27/50] batch [140/176] time 0.133 (0.120) data 0.000 (0.003) loss 0.5725 (0.7335) ce_loss 0.2578 (0.3674) teacher_loss 0.1607 (0.2871) loss_zs_kd 0.0896 (0.1141) loss_oracle 0.3670 (0.3894) acc 90.6250 (86.9866) kd_loss 0.7504 (0.8201) lr 1.0000e-03 eta 0:08:08
epoch [27/50] batch [160/176] time 0.076 (0.118) data 0.000 (0.002) loss 0.8574 (0.7404) ce_loss 0.5303 (0.3724) teacher_loss 0.3644 (0.2893) loss_zs_kd 0.1282 (0.1153) loss_oracle 0.4290 (0.3934) acc 90.6250 (86.6992) kd_loss 0.8312 (0.8227) lr 1.0000e-03 eta 0:07:59
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,193
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 92.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,704
* accuracy: 64.2%
* error: 35.8%
* macro_f1: 59.2%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [28/50] batch [20/176] time 0.075 (0.125) data 0.000 (0.016) loss 0.6419 (0.7097) ce_loss 0.2847 (0.3490) teacher_loss 0.2048 (0.2771) loss_zs_kd 0.1222 (0.1158) loss_oracle 0.3760 (0.3747) acc 90.6250 (88.9062) kd_loss 0.8045 (0.8091) lr 9.3721e-04 eta 0:08:22
epoch [28/50] batch [40/176] time 0.114 (0.119) data 0.000 (0.008) loss 0.6297 (0.7229) ce_loss 0.1979 (0.3618) teacher_loss 0.1343 (0.2873) loss_zs_kd 0.0855 (0.1118) loss_oracle 0.4526 (0.3797) acc 90.6250 (87.6562) kd_loss 0.8735 (0.8148) lr 9.3721e-04 eta 0:07:56
epoch [28/50] batch [60/176] time 0.118 (0.113) data 0.001 (0.006) loss 0.9379 (0.7252) ce_loss 0.5996 (0.3724) teacher_loss 0.4668 (0.2878) loss_zs_kd 0.1252 (0.1088) loss_oracle 0.4084 (0.3830) acc 81.2500 (86.5625) kd_loss 0.8852 (0.8167) lr 9.3721e-04 eta 0:07:29
epoch [28/50] batch [80/176] time 0.122 (0.111) data 0.000 (0.004) loss 0.6667 (0.7274) ce_loss 0.2896 (0.3691) teacher_loss 0.2192 (0.2864) loss_zs_kd 0.0902 (0.1092) loss_oracle 0.4024 (0.3864) acc 87.5000 (86.3281) kd_loss 0.7756 (0.8150) lr 9.3721e-04 eta 0:07:20
epoch [28/50] batch [100/176] time 0.117 (0.109) data 0.000 (0.004) loss 0.5569 (0.7293) ce_loss 0.1761 (0.3684) teacher_loss 0.1323 (0.2835) loss_zs_kd 0.1183 (0.1099) loss_oracle 0.3654 (0.3909) acc 96.8750 (86.4688) kd_loss 0.8265 (0.8204) lr 9.3721e-04 eta 0:07:12
epoch [28/50] batch [120/176] time 0.120 (0.109) data 0.000 (0.003) loss 0.7349 (0.7304) ce_loss 0.5322 (0.3724) teacher_loss 0.3941 (0.2861) loss_zs_kd 0.1160 (0.1111) loss_oracle 0.2827 (0.3887) acc 87.5000 (86.5625) kd_loss 0.6488 (0.8192) lr 9.3721e-04 eta 0:07:06
epoch [28/50] batch [140/176] time 0.124 (0.108) data 0.000 (0.003) loss 0.6947 (0.7302) ce_loss 0.3743 (0.3693) teacher_loss 0.2348 (0.2831) loss_zs_kd 0.1306 (0.1114) loss_oracle 0.3945 (0.3914) acc 81.2500 (86.5179) kd_loss 0.8549 (0.8235) lr 9.3721e-04 eta 0:07:02
epoch [28/50] batch [160/176] time 0.120 (0.107) data 0.000 (0.002) loss 0.6444 (0.7310) ce_loss 0.3154 (0.3695) teacher_loss 0.1676 (0.2832) loss_zs_kd 0.0989 (0.1111) loss_oracle 0.4274 (0.3923) acc 87.5000 (86.7383) kd_loss 0.8606 (0.8250) lr 9.3721e-04 eta 0:06:55
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,188
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,740
* accuracy: 65.5%
* error: 34.5%
* macro_f1: 60.5%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [29/50] batch [20/176] time 0.103 (0.116) data 0.000 (0.014) loss 0.7402 (0.7480) ce_loss 0.4058 (0.3878) teacher_loss 0.2986 (0.2906) loss_zs_kd 0.1401 (0.1181) loss_oracle 0.3715 (0.3983) acc 87.5000 (86.7188) kd_loss 0.8263 (0.8619) lr 8.7467e-04 eta 0:07:28
epoch [29/50] batch [40/176] time 0.133 (0.112) data 0.000 (0.007) loss 0.6581 (0.7456) ce_loss 0.2786 (0.3795) teacher_loss 0.1723 (0.2912) loss_zs_kd 0.1199 (0.1175) loss_oracle 0.4258 (0.3957) acc 90.6250 (87.1094) kd_loss 0.8784 (0.8570) lr 8.7467e-04 eta 0:07:07
epoch [29/50] batch [60/176] time 0.068 (0.103) data 0.001 (0.005) loss 1.0502 (0.7554) ce_loss 0.6489 (0.3822) teacher_loss 0.5614 (0.2952) loss_zs_kd 0.1454 (0.1153) loss_oracle 0.4162 (0.4025) acc 78.1250 (87.0312) kd_loss 0.8603 (0.8624) lr 8.7467e-04 eta 0:06:33
epoch [29/50] batch [80/176] time 0.158 (0.114) data 0.000 (0.004) loss 0.7164 (0.7666) ce_loss 0.3994 (0.3818) teacher_loss 0.2815 (0.2935) loss_zs_kd 0.1107 (0.1144) loss_oracle 0.3795 (0.4159) acc 87.5000 (87.3047) kd_loss 0.8906 (0.8767) lr 8.7467e-04 eta 0:07:12
epoch [29/50] batch [100/176] time 0.152 (0.114) data 0.000 (0.003) loss 0.8765 (0.7771) ce_loss 0.5557 (0.3882) teacher_loss 0.4045 (0.2962) loss_zs_kd 0.1029 (0.1167) loss_oracle 0.4205 (0.4226) acc 84.3750 (86.8438) kd_loss 0.8877 (0.8883) lr 8.7467e-04 eta 0:07:08
epoch [29/50] batch [120/176] time 0.145 (0.119) data 0.000 (0.002) loss 0.8220 (0.7743) ce_loss 0.3215 (0.3842) teacher_loss 0.2218 (0.2911) loss_zs_kd 0.1307 (0.1186) loss_oracle 0.5349 (0.4240) acc 90.6250 (86.8750) kd_loss 1.0305 (0.8960) lr 8.7467e-04 eta 0:07:27
epoch [29/50] batch [140/176] time 0.065 (0.113) data 0.000 (0.002) loss 0.7121 (0.7710) ce_loss 0.4238 (0.3823) teacher_loss 0.2733 (0.2863) loss_zs_kd 0.1241 (0.1186) loss_oracle 0.3768 (0.4253) acc 90.6250 (86.9196) kd_loss 0.8530 (0.8999) lr 8.7467e-04 eta 0:07:01
epoch [29/50] batch [160/176] time 0.069 (0.108) data 0.000 (0.002) loss 0.7468 (0.7766) ce_loss 0.3040 (0.3798) teacher_loss 0.2052 (0.2827) loss_zs_kd 0.1430 (0.1201) loss_oracle 0.4701 (0.4338) acc 96.8750 (87.2461) kd_loss 0.9079 (0.9085) lr 8.7467e-04 eta 0:06:39
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,181
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.8%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,767
* accuracy: 66.5%
* error: 33.5%
* macro_f1: 61.0%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [30/50] batch [20/176] time 0.089 (0.144) data 0.000 (0.020) loss 0.4752 (0.7601) ce_loss 0.2712 (0.3712) teacher_loss 0.1524 (0.2498) loss_zs_kd 0.1031 (0.1325) loss_oracle 0.2713 (0.4441) acc 90.6250 (87.9688) kd_loss 0.7321 (0.9301) lr 8.1262e-04 eta 0:08:50
epoch [30/50] batch [40/176] time 0.121 (0.129) data 0.000 (0.010) loss 0.7477 (0.7777) ce_loss 0.3108 (0.3599) teacher_loss 0.1872 (0.2481) loss_zs_kd 0.1423 (0.1318) loss_oracle 0.4893 (0.4637) acc 84.3750 (88.2031) kd_loss 0.9171 (0.9448) lr 8.1262e-04 eta 0:07:50
epoch [30/50] batch [60/176] time 0.081 (0.123) data 0.001 (0.007) loss 0.6876 (0.7785) ce_loss 0.3066 (0.3654) teacher_loss 0.2198 (0.2534) loss_zs_kd 0.1005 (0.1309) loss_oracle 0.4175 (0.4596) acc 93.7500 (87.9688) kd_loss 0.9982 (0.9401) lr 8.1262e-04 eta 0:07:26
epoch [30/50] batch [80/176] time 0.100 (0.120) data 0.000 (0.005) loss 0.7819 (0.7882) ce_loss 0.4177 (0.3742) teacher_loss 0.3139 (0.2596) loss_zs_kd 0.1020 (0.1305) loss_oracle 0.4170 (0.4634) acc 81.2500 (87.4219) kd_loss 0.9328 (0.9410) lr 8.1262e-04 eta 0:07:13
epoch [30/50] batch [100/176] time 0.115 (0.118) data 0.000 (0.004) loss 0.6752 (0.7921) ce_loss 0.3074 (0.3809) teacher_loss 0.1613 (0.2649) loss_zs_kd 0.1410 (0.1334) loss_oracle 0.4435 (0.4605) acc 87.5000 (87.0000) kd_loss 0.8797 (0.9381) lr 8.1262e-04 eta 0:07:05
epoch [30/50] batch [120/176] time 0.130 (0.117) data 0.000 (0.004) loss 0.8478 (0.7904) ce_loss 0.3984 (0.3821) teacher_loss 0.2833 (0.2651) loss_zs_kd 0.1113 (0.1339) loss_oracle 0.5088 (0.4584) acc 87.5000 (86.8750) kd_loss 1.0034 (0.9309) lr 8.1262e-04 eta 0:06:56
epoch [30/50] batch [140/176] time 0.105 (0.116) data 0.000 (0.003) loss 0.6958 (0.7885) ce_loss 0.3379 (0.3826) teacher_loss 0.1914 (0.2646) loss_zs_kd 0.1275 (0.1340) loss_oracle 0.4406 (0.4569) acc 81.2500 (86.7857) kd_loss 1.0010 (0.9269) lr 8.1262e-04 eta 0:06:52
epoch [30/50] batch [160/176] time 0.132 (0.116) data 0.000 (0.003) loss 0.6858 (0.7839) ce_loss 0.2190 (0.3768) teacher_loss 0.1431 (0.2612) loss_zs_kd 0.1430 (0.1325) loss_oracle 0.4712 (0.4564) acc 90.6250 (86.9531) kd_loss 0.9602 (0.9299) lr 8.1262e-04 eta 0:06:49
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,184
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,715
* accuracy: 64.6%
* error: 35.4%
* macro_f1: 59.9%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [31/50] batch [20/176] time 0.145 (0.124) data 0.000 (0.016) loss 0.6344 (0.7677) ce_loss 0.1838 (0.3408) teacher_loss 0.1156 (0.2334) loss_zs_kd 0.1596 (0.1335) loss_oracle 0.4390 (0.4675) acc 93.7500 (87.5000) kd_loss 0.8670 (0.9299) lr 7.5131e-04 eta 0:07:13
epoch [31/50] batch [40/176] time 0.100 (0.117) data 0.000 (0.008) loss 0.8089 (0.7877) ce_loss 0.4260 (0.3643) teacher_loss 0.3368 (0.2514) loss_zs_kd 0.1310 (0.1354) loss_oracle 0.4066 (0.4686) acc 87.5000 (87.7344) kd_loss 0.8616 (0.9363) lr 7.5131e-04 eta 0:06:46
epoch [31/50] batch [60/176] time 0.086 (0.111) data 0.000 (0.005) loss 0.9539 (0.7938) ce_loss 0.5244 (0.3766) teacher_loss 0.4118 (0.2606) loss_zs_kd 0.1488 (0.1353) loss_oracle 0.4676 (0.4655) acc 75.0000 (87.0833) kd_loss 0.8963 (0.9317) lr 7.5131e-04 eta 0:06:24
epoch [31/50] batch [80/176] time 0.087 (0.111) data 0.001 (0.004) loss 0.6692 (0.7933) ce_loss 0.3579 (0.3817) teacher_loss 0.1768 (0.2611) loss_zs_kd 0.1625 (0.1355) loss_oracle 0.4111 (0.4645) acc 87.5000 (86.7188) kd_loss 0.8022 (0.9304) lr 7.5131e-04 eta 0:06:20
epoch [31/50] batch [100/176] time 0.089 (0.110) data 0.000 (0.003) loss 0.8394 (0.7924) ce_loss 0.4556 (0.3784) teacher_loss 0.3150 (0.2576) loss_zs_kd 0.1763 (0.1358) loss_oracle 0.4362 (0.4669) acc 78.1250 (86.7500) kd_loss 0.9628 (0.9323) lr 7.5131e-04 eta 0:06:15
epoch [31/50] batch [120/176] time 0.123 (0.109) data 0.000 (0.003) loss 0.7602 (0.7949) ce_loss 0.2629 (0.3745) teacher_loss 0.1906 (0.2562) loss_zs_kd 0.0920 (0.1345) loss_oracle 0.5236 (0.4715) acc 90.6250 (87.0312) kd_loss 0.9739 (0.9396) lr 7.5131e-04 eta 0:06:09
epoch [31/50] batch [140/176] time 0.123 (0.108) data 0.000 (0.003) loss 0.5353 (0.7918) ce_loss 0.1476 (0.3723) teacher_loss 0.0806 (0.2560) loss_zs_kd 0.0812 (0.1341) loss_oracle 0.4142 (0.4688) acc 100.0000 (87.2545) kd_loss 0.8875 (0.9386) lr 7.5131e-04 eta 0:06:04
epoch [31/50] batch [160/176] time 0.120 (0.108) data 0.000 (0.002) loss 0.9082 (0.7906) ce_loss 0.4783 (0.3733) teacher_loss 0.3433 (0.2544) loss_zs_kd 0.1319 (0.1352) loss_oracle 0.4990 (0.4686) acc 93.7500 (87.3242) kd_loss 0.9210 (0.9393) lr 7.5131e-04 eta 0:06:01
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,178
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,713
* accuracy: 64.5%
* error: 35.5%
* macro_f1: 60.1%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [32/50] batch [20/176] time 0.154 (0.146) data 0.000 (0.015) loss 0.7706 (0.8048) ce_loss 0.3306 (0.3993) teacher_loss 0.2404 (0.2619) loss_zs_kd 0.1253 (0.1395) loss_oracle 0.4676 (0.4732) acc 87.5000 (87.1875) kd_loss 0.9290 (0.9402) lr 6.9098e-04 eta 0:08:04
epoch [32/50] batch [40/176] time 0.083 (0.135) data 0.000 (0.007) loss 0.6222 (0.8018) ce_loss 0.2473 (0.3897) teacher_loss 0.1319 (0.2582) loss_zs_kd 0.1592 (0.1447) loss_oracle 0.4107 (0.4712) acc 93.7500 (87.6562) kd_loss 0.9334 (0.9566) lr 6.9098e-04 eta 0:07:26
epoch [32/50] batch [60/176] time 0.088 (0.137) data 0.002 (0.005) loss 1.0769 (0.8101) ce_loss 0.7163 (0.3925) teacher_loss 0.5953 (0.2637) loss_zs_kd 0.1426 (0.1445) loss_oracle 0.4103 (0.4742) acc 81.2500 (87.2917) kd_loss 0.8744 (0.9587) lr 6.9098e-04 eta 0:07:29
epoch [32/50] batch [80/176] time 0.135 (0.128) data 0.000 (0.004) loss 0.9556 (0.8059) ce_loss 0.6250 (0.3828) teacher_loss 0.3625 (0.2588) loss_zs_kd 0.1104 (0.1406) loss_oracle 0.5379 (0.4767) acc 75.0000 (87.5000) kd_loss 1.0463 (0.9587) lr 6.9098e-04 eta 0:06:56
epoch [32/50] batch [100/176] time 0.091 (0.122) data 0.000 (0.003) loss 0.9333 (0.8102) ce_loss 0.5181 (0.3881) teacher_loss 0.4050 (0.2614) loss_zs_kd 0.1666 (0.1407) loss_oracle 0.4450 (0.4784) acc 68.7500 (87.1250) kd_loss 0.8952 (0.9646) lr 6.9098e-04 eta 0:06:36
epoch [32/50] batch [120/176] time 0.074 (0.120) data 0.000 (0.003) loss 0.8736 (0.8036) ce_loss 0.4917 (0.3818) teacher_loss 0.2785 (0.2539) loss_zs_kd 0.1853 (0.1402) loss_oracle 0.5024 (0.4796) acc 75.0000 (87.0573) kd_loss 0.9143 (0.9689) lr 6.9098e-04 eta 0:06:26
epoch [32/50] batch [140/176] time 0.085 (0.118) data 0.000 (0.002) loss 0.6968 (0.7981) ce_loss 0.2573 (0.3766) teacher_loss 0.1493 (0.2483) loss_zs_kd 0.1203 (0.1397) loss_oracle 0.4874 (0.4800) acc 87.5000 (87.2545) kd_loss 1.0513 (0.9738) lr 6.9098e-04 eta 0:06:18
epoch [32/50] batch [160/176] time 0.115 (0.117) data 0.000 (0.002) loss 0.6903 (0.7989) ce_loss 0.2964 (0.3767) teacher_loss 0.1999 (0.2484) loss_zs_kd 0.1252 (0.1397) loss_oracle 0.4278 (0.4807) acc 84.3750 (87.2461) kd_loss 0.9219 (0.9787) lr 6.9098e-04 eta 0:06:10
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,175
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,734
* accuracy: 65.3%
* error: 34.7%
* macro_f1: 60.3%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [33/50] batch [20/176] time 0.097 (0.114) data 0.000 (0.012) loss 0.7886 (0.8398) ce_loss 0.4565 (0.3905) teacher_loss 0.2429 (0.2486) loss_zs_kd 0.1194 (0.1396) loss_oracle 0.4860 (0.5214) acc 87.5000 (87.0312) kd_loss 1.0375 (1.0404) lr 6.3188e-04 eta 0:05:58
epoch [33/50] batch [40/176] time 0.106 (0.109) data 0.000 (0.006) loss 0.8162 (0.8365) ce_loss 0.3350 (0.3879) teacher_loss 0.2054 (0.2466) loss_zs_kd 0.1274 (0.1406) loss_oracle 0.5471 (0.5196) acc 90.6250 (87.0312) kd_loss 0.9961 (1.0146) lr 6.3188e-04 eta 0:05:40
epoch [33/50] batch [60/176] time 0.108 (0.105) data 0.000 (0.004) loss 0.7252 (0.8231) ce_loss 0.2888 (0.3815) teacher_loss 0.1650 (0.2439) loss_zs_kd 0.1378 (0.1418) loss_oracle 0.4912 (0.5083) acc 87.5000 (86.9271) kd_loss 1.0137 (1.0063) lr 6.3188e-04 eta 0:05:27
epoch [33/50] batch [80/176] time 0.115 (0.105) data 0.000 (0.003) loss 0.7954 (0.8324) ce_loss 0.3804 (0.3958) teacher_loss 0.2879 (0.2564) loss_zs_kd 0.1503 (0.1432) loss_oracle 0.4323 (0.5044) acc 90.6250 (86.5234) kd_loss 1.0092 (1.0085) lr 6.3188e-04 eta 0:05:25
epoch [33/50] batch [100/176] time 0.085 (0.104) data 0.000 (0.003) loss 0.6678 (0.8201) ce_loss 0.2625 (0.3914) teacher_loss 0.0993 (0.2486) loss_zs_kd 0.1343 (0.1438) loss_oracle 0.5013 (0.4996) acc 90.6250 (86.5938) kd_loss 1.0885 (1.0083) lr 6.3188e-04 eta 0:05:17
epoch [33/50] batch [120/176] time 0.113 (0.102) data 0.000 (0.002) loss 0.7811 (0.8228) ce_loss 0.3301 (0.3940) teacher_loss 0.1787 (0.2487) loss_zs_kd 0.1328 (0.1456) loss_oracle 0.5360 (0.5013) acc 84.3750 (86.4062) kd_loss 1.0604 (1.0086) lr 6.3188e-04 eta 0:05:12
epoch [33/50] batch [140/176] time 0.095 (0.101) data 0.000 (0.002) loss 0.6925 (0.8166) ce_loss 0.2106 (0.3860) teacher_loss 0.1081 (0.2421) loss_zs_kd 0.1011 (0.1451) loss_oracle 0.5338 (0.5020) acc 90.6250 (86.6964) kd_loss 1.0526 (1.0092) lr 6.3188e-04 eta 0:05:07
epoch [33/50] batch [160/176] time 0.105 (0.100) data 0.000 (0.002) loss 0.8310 (0.8170) ce_loss 0.4700 (0.3885) teacher_loss 0.2452 (0.2436) loss_zs_kd 0.1539 (0.1446) loss_oracle 0.5088 (0.5011) acc 81.2500 (86.5039) kd_loss 0.9697 (1.0093) lr 6.3188e-04 eta 0:05:00
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,168
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,681
* accuracy: 63.3%
* error: 36.7%
* macro_f1: 59.1%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [34/50] batch [20/176] time 0.104 (0.112) data 0.000 (0.016) loss 0.6595 (0.8112) ce_loss 0.3159 (0.3798) teacher_loss 0.1566 (0.2328) loss_zs_kd 0.1448 (0.1456) loss_oracle 0.4305 (0.5056) acc 90.6250 (85.9375) kd_loss 1.0514 (0.9932) lr 5.7422e-04 eta 0:05:32
epoch [34/50] batch [40/176] time 0.106 (0.102) data 0.000 (0.008) loss 0.8248 (0.8060) ce_loss 0.4441 (0.3865) teacher_loss 0.2577 (0.2319) loss_zs_kd 0.1259 (0.1469) loss_oracle 0.5042 (0.5007) acc 75.0000 (85.7031) kd_loss 1.0129 (0.9982) lr 5.7422e-04 eta 0:04:59
epoch [34/50] batch [60/176] time 0.093 (0.098) data 0.000 (0.006) loss 0.7088 (0.7864) ce_loss 0.3284 (0.3634) teacher_loss 0.2069 (0.2150) loss_zs_kd 0.1545 (0.1445) loss_oracle 0.4246 (0.4992) acc 90.6250 (86.8229) kd_loss 0.9813 (1.0039) lr 5.7422e-04 eta 0:04:47
epoch [34/50] batch [80/176] time 0.107 (0.096) data 0.000 (0.004) loss 0.7926 (0.7967) ce_loss 0.4143 (0.3798) teacher_loss 0.2826 (0.2232) loss_zs_kd 0.1766 (0.1480) loss_oracle 0.4217 (0.4996) acc 87.5000 (86.2891) kd_loss 0.9188 (1.0066) lr 5.7422e-04 eta 0:04:40
epoch [34/50] batch [100/176] time 0.092 (0.095) data 0.000 (0.003) loss 0.9422 (0.7966) ce_loss 0.4905 (0.3800) teacher_loss 0.3636 (0.2241) loss_zs_kd 0.1394 (0.1487) loss_oracle 0.5088 (0.4981) acc 81.2500 (86.2188) kd_loss 1.0642 (1.0051) lr 5.7422e-04 eta 0:04:34
epoch [34/50] batch [120/176] time 0.133 (0.095) data 0.000 (0.003) loss 0.8925 (0.8015) ce_loss 0.4463 (0.3824) teacher_loss 0.3137 (0.2302) loss_zs_kd 0.1183 (0.1474) loss_oracle 0.5195 (0.4976) acc 81.2500 (86.1719) kd_loss 1.0826 (1.0075) lr 5.7422e-04 eta 0:04:31
epoch [34/50] batch [140/176] time 0.116 (0.097) data 0.000 (0.002) loss 0.7771 (0.7946) ce_loss 0.2749 (0.3791) teacher_loss 0.1814 (0.2291) loss_zs_kd 0.1464 (0.1462) loss_oracle 0.5224 (0.4924) acc 93.7500 (86.1830) kd_loss 1.1064 (1.0027) lr 5.7422e-04 eta 0:04:36
epoch [34/50] batch [160/176] time 0.070 (0.102) data 0.000 (0.002) loss 0.8073 (0.7910) ce_loss 0.4905 (0.3815) teacher_loss 0.3253 (0.2308) loss_zs_kd 0.1184 (0.1455) loss_oracle 0.4228 (0.4874) acc 78.1250 (86.1523) kd_loss 0.8315 (0.9961) lr 5.7422e-04 eta 0:04:48
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,178
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,751
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 60.7%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [35/50] batch [20/176] time 0.093 (0.104) data 0.000 (0.011) loss 0.8903 (0.7650) ce_loss 0.5361 (0.3594) teacher_loss 0.3552 (0.2125) loss_zs_kd 0.1441 (0.1493) loss_oracle 0.4631 (0.4778) acc 75.0000 (87.5000) kd_loss 0.9453 (0.9644) lr 5.1825e-04 eta 0:04:51
epoch [35/50] batch [40/176] time 0.094 (0.097) data 0.000 (0.006) loss 0.8159 (0.7715) ce_loss 0.3972 (0.3647) teacher_loss 0.2665 (0.2287) loss_zs_kd 0.1172 (0.1443) loss_oracle 0.4908 (0.4706) acc 90.6250 (88.1250) kd_loss 0.9820 (0.9511) lr 5.1825e-04 eta 0:04:28
epoch [35/50] batch [60/176] time 0.104 (0.094) data 0.000 (0.004) loss 0.6902 (0.7633) ce_loss 0.1487 (0.3569) teacher_loss 0.1256 (0.2233) loss_zs_kd 0.1303 (0.1414) loss_oracle 0.4994 (0.4694) acc 100.0000 (88.3333) kd_loss 0.8607 (0.9552) lr 5.1825e-04 eta 0:04:19
epoch [35/50] batch [80/176] time 0.135 (0.097) data 0.000 (0.003) loss 0.8436 (0.7633) ce_loss 0.4006 (0.3567) teacher_loss 0.2902 (0.2230) loss_zs_kd 0.1501 (0.1425) loss_oracle 0.4783 (0.4691) acc 96.8750 (87.8516) kd_loss 1.0037 (0.9562) lr 5.1825e-04 eta 0:04:24
epoch [35/50] batch [100/176] time 0.086 (0.097) data 0.000 (0.002) loss 0.6440 (0.7628) ce_loss 0.2416 (0.3596) teacher_loss 0.1091 (0.2262) loss_zs_kd 0.1047 (0.1431) loss_oracle 0.4826 (0.4651) acc 90.6250 (87.4062) kd_loss 1.0360 (0.9508) lr 5.1825e-04 eta 0:04:24
epoch [35/50] batch [120/176] time 0.137 (0.099) data 0.000 (0.002) loss 0.6759 (0.7630) ce_loss 0.3933 (0.3633) teacher_loss 0.2473 (0.2285) loss_zs_kd 0.1292 (0.1423) loss_oracle 0.3640 (0.4634) acc 81.2500 (87.0833) kd_loss 0.8506 (0.9514) lr 5.1825e-04 eta 0:04:27
epoch [35/50] batch [140/176] time 0.113 (0.101) data 0.000 (0.002) loss 0.7451 (0.7705) ce_loss 0.4192 (0.3741) teacher_loss 0.2465 (0.2376) loss_zs_kd 0.1593 (0.1429) loss_oracle 0.4190 (0.4614) acc 87.5000 (86.8750) kd_loss 0.8960 (0.9465) lr 5.1825e-04 eta 0:04:29
epoch [35/50] batch [160/176] time 0.087 (0.102) data 0.000 (0.002) loss 0.7583 (0.7713) ce_loss 0.4668 (0.3795) teacher_loss 0.2663 (0.2406) loss_zs_kd 0.1640 (0.1432) loss_oracle 0.4100 (0.4591) acc 81.2500 (86.7188) kd_loss 0.8181 (0.9480) lr 5.1825e-04 eta 0:04:31
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,171
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,724
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 60.2%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [36/50] batch [20/176] time 0.102 (0.121) data 0.000 (0.013) loss 0.7006 (0.7408) ce_loss 0.3435 (0.3728) teacher_loss 0.2273 (0.2358) loss_zs_kd 0.1327 (0.1522) loss_oracle 0.4070 (0.4288) acc 87.5000 (87.5000) kd_loss 0.9092 (0.9393) lr 4.6417e-04 eta 0:05:16
epoch [36/50] batch [40/176] time 0.079 (0.114) data 0.000 (0.007) loss 0.6991 (0.7433) ce_loss 0.2593 (0.3655) teacher_loss 0.1186 (0.2270) loss_zs_kd 0.1400 (0.1440) loss_oracle 0.5106 (0.4443) acc 87.5000 (88.2812) kd_loss 1.0095 (0.9573) lr 4.6417e-04 eta 0:04:57
epoch [36/50] batch [60/176] time 0.090 (0.115) data 0.000 (0.005) loss 0.9519 (0.7468) ce_loss 0.5039 (0.3733) teacher_loss 0.3794 (0.2276) loss_zs_kd 0.1442 (0.1415) loss_oracle 0.5005 (0.4484) acc 87.5000 (88.3333) kd_loss 1.0293 (0.9614) lr 4.6417e-04 eta 0:04:57
epoch [36/50] batch [80/176] time 0.083 (0.114) data 0.000 (0.003) loss 1.0680 (0.7614) ce_loss 0.7222 (0.3861) teacher_loss 0.5141 (0.2347) loss_zs_kd 0.1424 (0.1425) loss_oracle 0.4827 (0.4555) acc 78.1250 (87.4609) kd_loss 1.0683 (0.9740) lr 4.6417e-04 eta 0:04:52
epoch [36/50] batch [100/176] time 0.135 (0.113) data 0.000 (0.003) loss 0.7690 (0.7548) ce_loss 0.3142 (0.3781) teacher_loss 0.1398 (0.2271) loss_zs_kd 0.1535 (0.1433) loss_oracle 0.5524 (0.4560) acc 90.6250 (87.5625) kd_loss 1.0898 (0.9756) lr 4.6417e-04 eta 0:04:48
epoch [36/50] batch [120/176] time 0.111 (0.112) data 0.000 (0.002) loss 0.7881 (0.7586) ce_loss 0.3293 (0.3798) teacher_loss 0.2942 (0.2283) loss_zs_kd 0.1132 (0.1434) loss_oracle 0.4374 (0.4586) acc 81.2500 (87.2917) kd_loss 1.0002 (0.9833) lr 4.6417e-04 eta 0:04:43
epoch [36/50] batch [140/176] time 0.075 (0.112) data 0.000 (0.002) loss 0.8605 (0.7563) ce_loss 0.4468 (0.3751) teacher_loss 0.3761 (0.2245) loss_zs_kd 0.1285 (0.1441) loss_oracle 0.4202 (0.4597) acc 84.3750 (87.5000) kd_loss 1.0543 (0.9870) lr 4.6417e-04 eta 0:04:39
epoch [36/50] batch [160/176] time 0.125 (0.111) data 0.000 (0.002) loss 0.6012 (0.7572) ce_loss 0.2917 (0.3765) teacher_loss 0.1433 (0.2259) loss_zs_kd 0.1095 (0.1441) loss_oracle 0.4031 (0.4593) acc 93.7500 (87.2656) kd_loss 0.9300 (0.9876) lr 4.6417e-04 eta 0:04:35
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,173
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,725
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 60.0%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [37/50] batch [20/176] time 0.086 (0.168) data 0.000 (0.016) loss 0.8104 (0.7415) ce_loss 0.3953 (0.3649) teacher_loss 0.3406 (0.2016) loss_zs_kd 0.1745 (0.1494) loss_oracle 0.3825 (0.4653) acc 81.2500 (86.5625) kd_loss 0.9329 (1.0017) lr 4.1221e-04 eta 0:06:51
epoch [37/50] batch [40/176] time 0.174 (0.150) data 0.000 (0.008) loss 0.8384 (0.7518) ce_loss 0.4260 (0.3726) teacher_loss 0.2875 (0.2148) loss_zs_kd 0.1693 (0.1430) loss_oracle 0.4662 (0.4655) acc 84.3750 (86.8750) kd_loss 1.1138 (1.0031) lr 4.1221e-04 eta 0:06:03
epoch [37/50] batch [60/176] time 0.077 (0.133) data 0.000 (0.006) loss 0.6996 (0.7544) ce_loss 0.2749 (0.3769) teacher_loss 0.1635 (0.2204) loss_zs_kd 0.1289 (0.1389) loss_oracle 0.4716 (0.4646) acc 93.7500 (87.3438) kd_loss 0.9815 (1.0003) lr 4.1221e-04 eta 0:05:20
epoch [37/50] batch [80/176] time 0.089 (0.126) data 0.000 (0.004) loss 0.7218 (0.7579) ce_loss 0.2778 (0.3815) teacher_loss 0.1512 (0.2232) loss_zs_kd 0.1378 (0.1424) loss_oracle 0.5017 (0.4636) acc 90.6250 (87.0312) kd_loss 1.0612 (0.9956) lr 4.1221e-04 eta 0:05:01
epoch [37/50] batch [100/176] time 0.129 (0.122) data 0.000 (0.003) loss 0.8368 (0.7596) ce_loss 0.5566 (0.3881) teacher_loss 0.2930 (0.2281) loss_zs_kd 0.1605 (0.1410) loss_oracle 0.4635 (0.4610) acc 75.0000 (86.6875) kd_loss 1.0119 (0.9893) lr 4.1221e-04 eta 0:04:49
epoch [37/50] batch [120/176] time 0.078 (0.119) data 0.000 (0.003) loss 0.7212 (0.7648) ce_loss 0.3379 (0.3913) teacher_loss 0.1517 (0.2307) loss_zs_kd 0.1398 (0.1428) loss_oracle 0.4997 (0.4627) acc 87.5000 (86.6146) kd_loss 1.0381 (0.9877) lr 4.1221e-04 eta 0:04:38
epoch [37/50] batch [140/176] time 0.128 (0.117) data 0.000 (0.003) loss 0.7028 (0.7700) ce_loss 0.3718 (0.3959) teacher_loss 0.1553 (0.2349) loss_zs_kd 0.1815 (0.1450) loss_oracle 0.4567 (0.4626) acc 87.5000 (86.2946) kd_loss 1.0161 (0.9873) lr 4.1221e-04 eta 0:04:30
epoch [37/50] batch [160/176] time 0.128 (0.115) data 0.000 (0.002) loss 0.7419 (0.7672) ce_loss 0.3289 (0.3929) teacher_loss 0.1403 (0.2319) loss_zs_kd 0.1435 (0.1449) loss_oracle 0.5298 (0.4629) acc 84.3750 (86.3867) kd_loss 0.9981 (0.9867) lr 4.1221e-04 eta 0:04:24
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,180
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,732
* accuracy: 65.2%
* error: 34.8%
* macro_f1: 60.1%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [38/50] batch [20/176] time 0.111 (0.122) data 0.000 (0.017) loss 0.8487 (0.7792) ce_loss 0.4534 (0.3917) teacher_loss 0.2369 (0.2307) loss_zs_kd 0.1871 (0.1609) loss_oracle 0.5183 (0.4680) acc 81.2500 (87.1875) kd_loss 0.9685 (0.9771) lr 3.6258e-04 eta 0:04:36
epoch [38/50] batch [40/176] time 0.109 (0.113) data 0.000 (0.009) loss 0.5584 (0.7747) ce_loss 0.2944 (0.3968) teacher_loss 0.1595 (0.2397) loss_zs_kd 0.1280 (0.1507) loss_oracle 0.3350 (0.4597) acc 93.7500 (86.5625) kd_loss 0.8065 (0.9718) lr 3.6258e-04 eta 0:04:14
epoch [38/50] batch [60/176] time 0.101 (0.110) data 0.000 (0.006) loss 0.9055 (0.7537) ce_loss 0.4902 (0.3695) teacher_loss 0.2956 (0.2185) loss_zs_kd 0.1592 (0.1459) loss_oracle 0.5303 (0.4623) acc 71.8750 (87.3958) kd_loss 1.0723 (0.9771) lr 3.6258e-04 eta 0:04:05
epoch [38/50] batch [80/176] time 0.076 (0.109) data 0.000 (0.004) loss 0.7341 (0.7557) ce_loss 0.3098 (0.3707) teacher_loss 0.1226 (0.2181) loss_zs_kd 0.1619 (0.1453) loss_oracle 0.5306 (0.4649) acc 84.3750 (87.3438) kd_loss 1.0504 (0.9793) lr 3.6258e-04 eta 0:04:00
epoch [38/50] batch [100/176] time 0.082 (0.108) data 0.000 (0.004) loss 1.0192 (0.7668) ce_loss 0.6138 (0.3794) teacher_loss 0.4685 (0.2239) loss_zs_kd 0.1510 (0.1459) loss_oracle 0.4752 (0.4699) acc 75.0000 (87.0938) kd_loss 1.0144 (0.9820) lr 3.6258e-04 eta 0:03:56
epoch [38/50] batch [120/176] time 0.131 (0.108) data 0.000 (0.003) loss 0.7660 (0.7615) ce_loss 0.5508 (0.3729) teacher_loss 0.2840 (0.2178) loss_zs_kd 0.1411 (0.1442) loss_oracle 0.4114 (0.4715) acc 78.1250 (87.3698) kd_loss 0.8428 (0.9816) lr 3.6258e-04 eta 0:03:53
epoch [38/50] batch [140/176] time 0.128 (0.107) data 0.000 (0.003) loss 0.8874 (0.7616) ce_loss 0.4836 (0.3736) teacher_loss 0.4296 (0.2212) loss_zs_kd 0.1305 (0.1444) loss_oracle 0.3926 (0.4682) acc 90.6250 (87.3884) kd_loss 0.8893 (0.9788) lr 3.6258e-04 eta 0:03:49
epoch [38/50] batch [160/176] time 0.134 (0.107) data 0.000 (0.002) loss 0.8447 (0.7618) ce_loss 0.5078 (0.3767) teacher_loss 0.3135 (0.2237) loss_zs_kd 0.1786 (0.1431) loss_oracle 0.4419 (0.4666) acc 81.2500 (87.2266) kd_loss 0.9024 (0.9757) lr 3.6258e-04 eta 0:03:47
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,183
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,746
* accuracy: 65.7%
* error: 34.3%
* macro_f1: 60.6%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [39/50] batch [20/176] time 0.076 (0.132) data 0.000 (0.015) loss 0.8025 (0.7206) ce_loss 0.4382 (0.3661) teacher_loss 0.2612 (0.1983) loss_zs_kd 0.1630 (0.1450) loss_oracle 0.4598 (0.4498) acc 84.3750 (86.4062) kd_loss 1.0222 (0.9860) lr 3.1545e-04 eta 0:04:36
epoch [39/50] batch [40/176] time 0.128 (0.126) data 0.000 (0.007) loss 0.6263 (0.7291) ce_loss 0.1943 (0.3710) teacher_loss 0.1415 (0.2101) loss_zs_kd 0.1095 (0.1421) loss_oracle 0.4301 (0.4479) acc 96.8750 (86.9531) kd_loss 0.9793 (0.9680) lr 3.1545e-04 eta 0:04:20
epoch [39/50] batch [60/176] time 0.174 (0.122) data 0.000 (0.005) loss 0.6806 (0.7322) ce_loss 0.3577 (0.3667) teacher_loss 0.1841 (0.2104) loss_zs_kd 0.1433 (0.1461) loss_oracle 0.4249 (0.4488) acc 81.2500 (87.2396) kd_loss 0.9768 (0.9696) lr 3.1545e-04 eta 0:04:10
epoch [39/50] batch [80/176] time 0.154 (0.128) data 0.000 (0.004) loss 0.6577 (0.7580) ce_loss 0.2142 (0.3825) teacher_loss 0.1096 (0.2265) loss_zs_kd 0.1429 (0.1464) loss_oracle 0.4767 (0.4584) acc 93.7500 (86.4062) kd_loss 0.9406 (0.9757) lr 3.1545e-04 eta 0:04:19
epoch [39/50] batch [100/176] time 0.182 (0.123) data 0.000 (0.003) loss 0.6178 (0.7594) ce_loss 0.2583 (0.3820) teacher_loss 0.1506 (0.2266) loss_zs_kd 0.1299 (0.1475) loss_oracle 0.4023 (0.4591) acc 87.5000 (86.2500) kd_loss 0.8857 (0.9727) lr 3.1545e-04 eta 0:04:07
epoch [39/50] batch [120/176] time 0.138 (0.123) data 0.000 (0.003) loss 0.8592 (0.7602) ce_loss 0.4146 (0.3802) teacher_loss 0.2729 (0.2274) loss_zs_kd 0.1542 (0.1482) loss_oracle 0.5092 (0.4586) acc 84.3750 (86.2500) kd_loss 1.0179 (0.9702) lr 3.1545e-04 eta 0:04:04
epoch [39/50] batch [140/176] time 0.136 (0.121) data 0.000 (0.002) loss 0.7105 (0.7635) ce_loss 0.5171 (0.3830) teacher_loss 0.2752 (0.2309) loss_zs_kd 0.1532 (0.1465) loss_oracle 0.3587 (0.4594) acc 84.3750 (86.2723) kd_loss 0.8542 (0.9694) lr 3.1545e-04 eta 0:03:58
epoch [39/50] batch [160/176] time 0.084 (0.120) data 0.000 (0.002) loss 0.7037 (0.7658) ce_loss 0.3940 (0.3845) teacher_loss 0.1865 (0.2330) loss_zs_kd 0.1336 (0.1469) loss_oracle 0.4504 (0.4593) acc 87.5000 (86.2500) kd_loss 0.9808 (0.9679) lr 3.1545e-04 eta 0:03:54
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,179
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,727
* accuracy: 65.0%
* error: 35.0%
* macro_f1: 60.6%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [40/50] batch [20/176] time 0.091 (0.130) data 0.000 (0.017) loss 0.7087 (0.7376) ce_loss 0.2234 (0.3622) teacher_loss 0.1609 (0.2091) loss_zs_kd 0.1018 (0.1477) loss_oracle 0.4969 (0.4546) acc 93.7500 (86.4062) kd_loss 1.0283 (0.9542) lr 2.7103e-04 eta 0:04:09
epoch [40/50] batch [40/176] time 0.098 (0.117) data 0.000 (0.009) loss 0.8998 (0.7740) ce_loss 0.4814 (0.3944) teacher_loss 0.3367 (0.2493) loss_zs_kd 0.1262 (0.1461) loss_oracle 0.5000 (0.4516) acc 78.1250 (85.3125) kd_loss 0.9835 (0.9366) lr 2.7103e-04 eta 0:03:42
epoch [40/50] batch [60/176] time 0.130 (0.111) data 0.001 (0.006) loss 0.7994 (0.7854) ce_loss 0.4875 (0.4078) teacher_loss 0.3961 (0.2626) loss_zs_kd 0.1517 (0.1443) loss_oracle 0.3275 (0.4506) acc 84.3750 (85.5208) kd_loss 0.7611 (0.9288) lr 2.7103e-04 eta 0:03:28
epoch [40/50] batch [80/176] time 0.088 (0.109) data 0.000 (0.004) loss 0.5761 (0.7845) ce_loss 0.2180 (0.4025) teacher_loss 0.1207 (0.2641) loss_zs_kd 0.1056 (0.1416) loss_oracle 0.4027 (0.4496) acc 93.7500 (85.8984) kd_loss 0.8718 (0.9200) lr 2.7103e-04 eta 0:03:21
epoch [40/50] batch [100/176] time 0.080 (0.107) data 0.000 (0.004) loss 0.6365 (0.7750) ce_loss 0.2585 (0.3884) teacher_loss 0.1614 (0.2537) loss_zs_kd 0.1089 (0.1391) loss_oracle 0.4206 (0.4518) acc 87.5000 (86.6250) kd_loss 0.8511 (0.9186) lr 2.7103e-04 eta 0:03:17
epoch [40/50] batch [120/176] time 0.123 (0.107) data 0.000 (0.003) loss 0.6782 (0.7643) ce_loss 0.3064 (0.3792) teacher_loss 0.2048 (0.2483) loss_zs_kd 0.0910 (0.1360) loss_oracle 0.4280 (0.4480) acc 87.5000 (86.9531) kd_loss 0.9099 (0.9138) lr 2.7103e-04 eta 0:03:14
epoch [40/50] batch [140/176] time 0.116 (0.107) data 0.000 (0.003) loss 0.7308 (0.7628) ce_loss 0.3508 (0.3776) teacher_loss 0.2979 (0.2482) loss_zs_kd 0.1127 (0.1354) loss_oracle 0.3766 (0.4470) acc 87.5000 (87.2098) kd_loss 0.8129 (0.9136) lr 2.7103e-04 eta 0:03:11
epoch [40/50] batch [160/176] time 0.132 (0.107) data 0.000 (0.002) loss 0.7908 (0.7615) ce_loss 0.3411 (0.3798) teacher_loss 0.2017 (0.2497) loss_zs_kd 0.1644 (0.1348) loss_oracle 0.5069 (0.4444) acc 87.5000 (87.1289) kd_loss 0.9238 (0.9074) lr 2.7103e-04 eta 0:03:10
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,189
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,767
* accuracy: 66.5%
* error: 33.5%
* macro_f1: 61.5%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [41/50] batch [20/176] time 0.082 (0.126) data 0.000 (0.016) loss 0.8677 (0.7410) ce_loss 0.5781 (0.3838) teacher_loss 0.3114 (0.2600) loss_zs_kd 0.1517 (0.1233) loss_oracle 0.4805 (0.4193) acc 75.0000 (87.6562) kd_loss 0.9582 (0.8540) lr 2.2949e-04 eta 0:03:39
epoch [41/50] batch [40/176] time 0.110 (0.117) data 0.000 (0.008) loss 0.8477 (0.7306) ce_loss 0.5215 (0.3685) teacher_loss 0.3290 (0.2487) loss_zs_kd 0.1167 (0.1263) loss_oracle 0.4604 (0.4187) acc 71.8750 (87.2656) kd_loss 0.8459 (0.8558) lr 2.2949e-04 eta 0:03:22
epoch [41/50] batch [60/176] time 0.128 (0.115) data 0.000 (0.006) loss 0.8169 (0.7360) ce_loss 0.4006 (0.3699) teacher_loss 0.3171 (0.2544) loss_zs_kd 0.1201 (0.1277) loss_oracle 0.4397 (0.4177) acc 90.6250 (87.0833) kd_loss 0.8512 (0.8521) lr 2.2949e-04 eta 0:03:15
epoch [41/50] batch [80/176] time 0.140 (0.115) data 0.000 (0.004) loss 0.7379 (0.7368) ce_loss 0.3413 (0.3707) teacher_loss 0.2522 (0.2547) loss_zs_kd 0.1100 (0.1256) loss_oracle 0.4307 (0.4194) acc 87.5000 (87.0703) kd_loss 0.7827 (0.8530) lr 2.2949e-04 eta 0:03:13
epoch [41/50] batch [100/176] time 0.127 (0.114) data 0.000 (0.003) loss 0.6429 (0.7317) ce_loss 0.3167 (0.3664) teacher_loss 0.2151 (0.2539) loss_zs_kd 0.0856 (0.1252) loss_oracle 0.3850 (0.4152) acc 87.5000 (87.0938) kd_loss 0.7672 (0.8490) lr 2.2949e-04 eta 0:03:09
epoch [41/50] batch [120/176] time 0.166 (0.114) data 0.000 (0.003) loss 0.6994 (0.7377) ce_loss 0.3577 (0.3705) teacher_loss 0.2418 (0.2599) loss_zs_kd 0.1256 (0.1252) loss_oracle 0.3948 (0.4151) acc 87.5000 (86.7188) kd_loss 0.8187 (0.8471) lr 2.2949e-04 eta 0:03:07
epoch [41/50] batch [140/176] time 0.076 (0.118) data 0.000 (0.003) loss 0.6846 (0.7352) ce_loss 0.3044 (0.3727) teacher_loss 0.2304 (0.2621) loss_zs_kd 0.1542 (0.1249) loss_oracle 0.3771 (0.4106) acc 93.7500 (86.6964) kd_loss 0.8279 (0.8439) lr 2.2949e-04 eta 0:03:11
epoch [41/50] batch [160/176] time 0.147 (0.120) data 0.000 (0.002) loss 0.8381 (0.7377) ce_loss 0.4670 (0.3780) teacher_loss 0.3790 (0.2664) loss_zs_kd 0.1143 (0.1240) loss_oracle 0.4020 (0.4092) acc 81.2500 (86.5820) kd_loss 0.8381 (0.8396) lr 2.2949e-04 eta 0:03:11
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,184
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,760
* accuracy: 66.3%
* error: 33.7%
* macro_f1: 61.1%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [42/50] batch [20/176] time 0.147 (0.114) data 0.000 (0.013) loss 0.7673 (0.7117) ce_loss 0.4099 (0.3588) teacher_loss 0.3458 (0.2820) loss_zs_kd 0.1224 (0.1208) loss_oracle 0.3603 (0.3692) acc 84.3750 (87.9688) kd_loss 0.8431 (0.7808) lr 1.9098e-04 eta 0:02:58
epoch [42/50] batch [40/176] time 0.062 (0.109) data 0.000 (0.007) loss 0.5894 (0.6970) ce_loss 0.2172 (0.3493) teacher_loss 0.1590 (0.2588) loss_zs_kd 0.0978 (0.1197) loss_oracle 0.3814 (0.3784) acc 96.8750 (88.5938) kd_loss 0.7987 (0.7817) lr 1.9098e-04 eta 0:02:48
epoch [42/50] batch [60/176] time 0.090 (0.104) data 0.000 (0.004) loss 0.7662 (0.7026) ce_loss 0.4231 (0.3630) teacher_loss 0.3373 (0.2651) loss_zs_kd 0.0876 (0.1182) loss_oracle 0.3851 (0.3785) acc 84.3750 (87.2396) kd_loss 0.8097 (0.7864) lr 1.9098e-04 eta 0:02:38
epoch [42/50] batch [80/176] time 0.108 (0.100) data 0.000 (0.003) loss 0.4794 (0.6997) ce_loss 0.1843 (0.3593) teacher_loss 0.1225 (0.2625) loss_zs_kd 0.1228 (0.1185) loss_oracle 0.2955 (0.3779) acc 96.8750 (87.4609) kd_loss 0.6755 (0.7874) lr 1.9098e-04 eta 0:02:30
epoch [42/50] batch [100/176] time 0.116 (0.100) data 0.000 (0.003) loss 0.8449 (0.7052) ce_loss 0.5522 (0.3673) teacher_loss 0.4180 (0.2701) loss_zs_kd 0.1001 (0.1167) loss_oracle 0.3768 (0.3767) acc 75.0000 (87.2188) kd_loss 0.7580 (0.7883) lr 1.9098e-04 eta 0:02:28
epoch [42/50] batch [120/176] time 0.084 (0.100) data 0.000 (0.002) loss 0.8924 (0.7082) ce_loss 0.4961 (0.3664) teacher_loss 0.4538 (0.2720) loss_zs_kd 0.1282 (0.1167) loss_oracle 0.3745 (0.3778) acc 87.5000 (87.4219) kd_loss 0.7379 (0.7876) lr 1.9098e-04 eta 0:02:26
epoch [42/50] batch [140/176] time 0.082 (0.100) data 0.000 (0.002) loss 0.7257 (0.7186) ce_loss 0.4180 (0.3749) teacher_loss 0.3341 (0.2807) loss_zs_kd 0.1342 (0.1156) loss_oracle 0.3245 (0.3801) acc 87.5000 (87.1875) kd_loss 0.7612 (0.7893) lr 1.9098e-04 eta 0:02:23
epoch [42/50] batch [160/176] time 0.078 (0.099) data 0.000 (0.002) loss 0.6365 (0.7167) ce_loss 0.3098 (0.3724) teacher_loss 0.1786 (0.2794) loss_zs_kd 0.1533 (0.1155) loss_oracle 0.3813 (0.3796) acc 87.5000 (87.3047) kd_loss 0.7322 (0.7879) lr 1.9098e-04 eta 0:02:21
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,182
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,759
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 61.2%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [43/50] batch [20/176] time 0.069 (0.107) data 0.000 (0.012) loss 0.6661 (0.7146) ce_loss 0.3127 (0.3733) teacher_loss 0.2693 (0.2778) loss_zs_kd 0.0946 (0.1222) loss_oracle 0.3496 (0.3756) acc 87.5000 (85.6250) kd_loss 0.7242 (0.7647) lr 1.5567e-04 eta 0:02:28
epoch [43/50] batch [40/176] time 0.073 (0.103) data 0.000 (0.006) loss 0.6614 (0.7057) ce_loss 0.2920 (0.3569) teacher_loss 0.1997 (0.2724) loss_zs_kd 0.1108 (0.1197) loss_oracle 0.4062 (0.3736) acc 90.6250 (86.7969) kd_loss 0.7632 (0.7679) lr 1.5567e-04 eta 0:02:20
epoch [43/50] batch [60/176] time 0.089 (0.099) data 0.000 (0.004) loss 0.7556 (0.7142) ce_loss 0.4299 (0.3632) teacher_loss 0.2919 (0.2783) loss_zs_kd 0.1154 (0.1155) loss_oracle 0.4060 (0.3781) acc 81.2500 (86.8750) kd_loss 0.7820 (0.7774) lr 1.5567e-04 eta 0:02:13
epoch [43/50] batch [80/176] time 0.122 (0.099) data 0.000 (0.003) loss 0.6027 (0.7065) ce_loss 0.2437 (0.3564) teacher_loss 0.1672 (0.2732) loss_zs_kd 0.0975 (0.1142) loss_oracle 0.3868 (0.3762) acc 93.7500 (87.1094) kd_loss 0.7900 (0.7769) lr 1.5567e-04 eta 0:02:11
epoch [43/50] batch [100/176] time 0.131 (0.100) data 0.000 (0.003) loss 0.6301 (0.7102) ce_loss 0.2871 (0.3577) teacher_loss 0.2172 (0.2769) loss_zs_kd 0.1296 (0.1142) loss_oracle 0.3481 (0.3762) acc 87.5000 (87.0625) kd_loss 0.7749 (0.7769) lr 1.5567e-04 eta 0:02:10
epoch [43/50] batch [120/176] time 0.105 (0.099) data 0.000 (0.002) loss 0.6004 (0.7196) ce_loss 0.3323 (0.3651) teacher_loss 0.2878 (0.2865) loss_zs_kd 0.1015 (0.1127) loss_oracle 0.2619 (0.3767) acc 87.5000 (86.8229) kd_loss 0.6042 (0.7764) lr 1.5567e-04 eta 0:02:07
epoch [43/50] batch [140/176] time 0.077 (0.097) data 0.000 (0.002) loss 0.9941 (0.7229) ce_loss 0.5942 (0.3686) teacher_loss 0.4898 (0.2908) loss_zs_kd 0.1209 (0.1115) loss_oracle 0.4438 (0.3763) acc 81.2500 (86.8527) kd_loss 0.8604 (0.7794) lr 1.5567e-04 eta 0:02:03
epoch [43/50] batch [160/176] time 0.132 (0.098) data 0.000 (0.002) loss 0.7149 (0.7285) ce_loss 0.3928 (0.3770) teacher_loss 0.2494 (0.2974) loss_zs_kd 0.1533 (0.1115) loss_oracle 0.3889 (0.3753) acc 87.5000 (86.5820) kd_loss 0.7642 (0.7791) lr 1.5567e-04 eta 0:02:01
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,182
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,750
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 60.5%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [44/50] batch [20/176] time 0.146 (0.163) data 0.000 (0.016) loss 0.6833 (0.6794) ce_loss 0.3230 (0.3489) teacher_loss 0.3184 (0.2738) loss_zs_kd 0.0941 (0.1107) loss_oracle 0.3179 (0.3502) acc 87.5000 (88.2812) kd_loss 0.7764 (0.7580) lr 1.2369e-04 eta 0:03:17
epoch [44/50] batch [40/176] time 0.157 (0.139) data 0.000 (0.008) loss 0.8398 (0.7066) ce_loss 0.4143 (0.3691) teacher_loss 0.3216 (0.2845) loss_zs_kd 0.1262 (0.1117) loss_oracle 0.4551 (0.3662) acc 84.3750 (86.6406) kd_loss 0.8094 (0.7757) lr 1.2369e-04 eta 0:02:45
epoch [44/50] batch [60/176] time 0.077 (0.129) data 0.000 (0.005) loss 0.6047 (0.7080) ce_loss 0.2751 (0.3639) teacher_loss 0.2053 (0.2779) loss_zs_kd 0.0741 (0.1104) loss_oracle 0.3624 (0.3749) acc 84.3750 (87.2396) kd_loss 0.7432 (0.7848) lr 1.2369e-04 eta 0:02:31
epoch [44/50] batch [80/176] time 0.132 (0.124) data 0.000 (0.004) loss 0.8026 (0.7115) ce_loss 0.4204 (0.3687) teacher_loss 0.3073 (0.2808) loss_zs_kd 0.1118 (0.1114) loss_oracle 0.4394 (0.3749) acc 81.2500 (87.5391) kd_loss 0.8979 (0.7835) lr 1.2369e-04 eta 0:02:22
epoch [44/50] batch [100/176] time 0.105 (0.121) data 0.000 (0.003) loss 0.6596 (0.7179) ce_loss 0.2268 (0.3728) teacher_loss 0.1905 (0.2858) loss_zs_kd 0.1426 (0.1128) loss_oracle 0.3978 (0.3757) acc 93.7500 (87.2188) kd_loss 0.7954 (0.7824) lr 1.2369e-04 eta 0:02:16
epoch [44/50] batch [120/176] time 0.076 (0.119) data 0.000 (0.003) loss 0.6478 (0.7209) ce_loss 0.3611 (0.3756) teacher_loss 0.2817 (0.2904) loss_zs_kd 0.1247 (0.1130) loss_oracle 0.3038 (0.3739) acc 81.2500 (87.0573) kd_loss 0.7108 (0.7809) lr 1.2369e-04 eta 0:02:12
epoch [44/50] batch [140/176] time 0.076 (0.117) data 0.000 (0.002) loss 0.6319 (0.7246) ce_loss 0.2539 (0.3790) teacher_loss 0.1555 (0.2936) loss_zs_kd 0.0910 (0.1125) loss_oracle 0.4308 (0.3748) acc 90.6250 (86.8080) kd_loss 0.8012 (0.7817) lr 1.2369e-04 eta 0:02:07
epoch [44/50] batch [160/176] time 0.069 (0.115) data 0.000 (0.002) loss 0.6383 (0.7257) ce_loss 0.2617 (0.3785) teacher_loss 0.1977 (0.2939) loss_zs_kd 0.1781 (0.1126) loss_oracle 0.3515 (0.3755) acc 93.7500 (86.8555) kd_loss 0.7921 (0.7840) lr 1.2369e-04 eta 0:02:03
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,183
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,758
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 60.7%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [45/50] batch [20/176] time 0.097 (0.110) data 0.000 (0.012) loss 0.7404 (0.7046) ce_loss 0.5425 (0.4049) teacher_loss 0.3271 (0.2977) loss_zs_kd 0.1487 (0.1109) loss_oracle 0.3390 (0.3515) acc 75.0000 (84.2188) kd_loss 0.7438 (0.7588) lr 9.5173e-05 eta 0:01:53
epoch [45/50] batch [40/176] time 0.083 (0.104) data 0.000 (0.006) loss 0.6250 (0.7052) ce_loss 0.2861 (0.3802) teacher_loss 0.2005 (0.2862) loss_zs_kd 0.1109 (0.1086) loss_oracle 0.3690 (0.3648) acc 90.6250 (86.4062) kd_loss 0.7396 (0.7686) lr 9.5173e-05 eta 0:01:45
epoch [45/50] batch [60/176] time 0.108 (0.102) data 0.000 (0.004) loss 0.7170 (0.7112) ce_loss 0.3650 (0.3771) teacher_loss 0.2728 (0.2889) loss_zs_kd 0.1352 (0.1100) loss_oracle 0.3766 (0.3673) acc 90.6250 (86.9792) kd_loss 0.7041 (0.7669) lr 9.5173e-05 eta 0:01:41
epoch [45/50] batch [80/176] time 0.130 (0.103) data 0.000 (0.003) loss 0.8152 (0.7297) ce_loss 0.5273 (0.3948) teacher_loss 0.3362 (0.3039) loss_zs_kd 0.1278 (0.1149) loss_oracle 0.4150 (0.3684) acc 84.3750 (86.1328) kd_loss 0.8951 (0.7665) lr 9.5173e-05 eta 0:01:40
epoch [45/50] batch [100/176] time 0.072 (0.102) data 0.000 (0.003) loss 0.7100 (0.7219) ce_loss 0.4321 (0.3874) teacher_loss 0.2776 (0.2981) loss_zs_kd 0.0937 (0.1131) loss_oracle 0.3856 (0.3673) acc 87.5000 (86.3438) kd_loss 0.7807 (0.7691) lr 9.5173e-05 eta 0:01:37
epoch [45/50] batch [120/176] time 0.110 (0.102) data 0.000 (0.002) loss 0.6111 (0.7210) ce_loss 0.2686 (0.3845) teacher_loss 0.2263 (0.2974) loss_zs_kd 0.0888 (0.1138) loss_oracle 0.3404 (0.3667) acc 90.6250 (86.5365) kd_loss 0.7734 (0.7680) lr 9.5173e-05 eta 0:01:35
epoch [45/50] batch [140/176] time 0.084 (0.103) data 0.000 (0.002) loss 0.7813 (0.7172) ce_loss 0.4504 (0.3802) teacher_loss 0.3598 (0.2952) loss_zs_kd 0.0923 (0.1138) loss_oracle 0.3753 (0.3651) acc 81.2500 (86.6518) kd_loss 0.7678 (0.7636) lr 9.5173e-05 eta 0:01:34
epoch [45/50] batch [160/176] time 0.134 (0.104) data 0.001 (0.002) loss 1.1304 (0.7198) ce_loss 0.8252 (0.3832) teacher_loss 0.6574 (0.2997) loss_zs_kd 0.1304 (0.1130) loss_oracle 0.4078 (0.3636) acc 68.7500 (86.5234) kd_loss 0.8396 (0.7638) lr 9.5173e-05 eta 0:01:32
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,187
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,769
* accuracy: 66.6%
* error: 33.4%
* macro_f1: 61.1%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [46/50] batch [20/176] time 0.092 (0.120) data 0.000 (0.015) loss 0.9313 (0.6961) ce_loss 0.5342 (0.3783) teacher_loss 0.3849 (0.2886) loss_zs_kd 0.1449 (0.1178) loss_oracle 0.4739 (0.3486) acc 81.2500 (86.5625) kd_loss 0.8789 (0.7442) lr 7.0224e-05 eta 0:01:42
epoch [46/50] batch [40/176] time 0.072 (0.111) data 0.000 (0.007) loss 0.7303 (0.7008) ce_loss 0.4363 (0.3715) teacher_loss 0.3335 (0.2891) loss_zs_kd 0.0952 (0.1109) loss_oracle 0.3491 (0.3563) acc 84.3750 (87.2656) kd_loss 0.7399 (0.7516) lr 7.0224e-05 eta 0:01:33
epoch [46/50] batch [60/176] time 0.098 (0.109) data 0.001 (0.005) loss 0.5729 (0.6973) ce_loss 0.2598 (0.3665) teacher_loss 0.1843 (0.2838) loss_zs_kd 0.0796 (0.1076) loss_oracle 0.3489 (0.3597) acc 90.6250 (87.6042) kd_loss 0.7732 (0.7572) lr 7.0224e-05 eta 0:01:29
epoch [46/50] batch [80/176] time 0.071 (0.106) data 0.000 (0.004) loss 0.6794 (0.6952) ce_loss 0.3235 (0.3595) teacher_loss 0.2262 (0.2765) loss_zs_kd 0.1258 (0.1086) loss_oracle 0.3903 (0.3644) acc 93.7500 (87.7344) kd_loss 0.8092 (0.7647) lr 7.0224e-05 eta 0:01:25
epoch [46/50] batch [100/176] time 0.153 (0.115) data 0.000 (0.003) loss 0.6388 (0.6913) ce_loss 0.2764 (0.3521) teacher_loss 0.1800 (0.2706) loss_zs_kd 0.0946 (0.1089) loss_oracle 0.4114 (0.3663) acc 90.6250 (88.2188) kd_loss 0.8106 (0.7686) lr 7.0224e-05 eta 0:01:29
epoch [46/50] batch [120/176] time 0.193 (0.117) data 0.000 (0.003) loss 0.6925 (0.6993) ce_loss 0.3066 (0.3586) teacher_loss 0.2677 (0.2778) loss_zs_kd 0.1185 (0.1078) loss_oracle 0.3656 (0.3676) acc 90.6250 (88.0990) kd_loss 0.8705 (0.7723) lr 7.0224e-05 eta 0:01:28
epoch [46/50] batch [140/176] time 0.082 (0.116) data 0.000 (0.002) loss 0.7263 (0.7024) ce_loss 0.3032 (0.3585) teacher_loss 0.3107 (0.2787) loss_zs_kd 0.0928 (0.1087) loss_oracle 0.3692 (0.3694) acc 87.5000 (88.1473) kd_loss 0.8186 (0.7738) lr 7.0224e-05 eta 0:01:25
epoch [46/50] batch [160/176] time 0.109 (0.114) data 0.000 (0.002) loss 0.8551 (0.7027) ce_loss 0.3933 (0.3591) teacher_loss 0.3677 (0.2787) loss_zs_kd 0.1200 (0.1091) loss_oracle 0.4273 (0.3695) acc 84.3750 (87.9102) kd_loss 0.8744 (0.7746) lr 7.0224e-05 eta 0:01:22
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,181
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,756
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 61.5%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [47/50] batch [20/176] time 0.139 (0.110) data 0.000 (0.012) loss 0.6679 (0.7785) ce_loss 0.3230 (0.4212) teacher_loss 0.2656 (0.3375) loss_zs_kd 0.1174 (0.1090) loss_oracle 0.3436 (0.3865) acc 93.7500 (86.4062) kd_loss 0.7927 (0.7832) lr 4.8943e-05 eta 0:01:15
epoch [47/50] batch [40/176] time 0.081 (0.105) data 0.000 (0.006) loss 0.7744 (0.7520) ce_loss 0.4434 (0.4095) teacher_loss 0.3332 (0.3199) loss_zs_kd 0.1171 (0.1080) loss_oracle 0.3826 (0.3781) acc 87.5000 (86.1719) kd_loss 0.7730 (0.7796) lr 4.8943e-05 eta 0:01:09
epoch [47/50] batch [60/176] time 0.134 (0.104) data 0.000 (0.004) loss 0.7337 (0.7360) ce_loss 0.3242 (0.3939) teacher_loss 0.2810 (0.3028) loss_zs_kd 0.1309 (0.1083) loss_oracle 0.3873 (0.3791) acc 87.5000 (86.4062) kd_loss 0.8414 (0.7803) lr 4.8943e-05 eta 0:01:07
epoch [47/50] batch [80/176] time 0.077 (0.103) data 0.000 (0.003) loss 0.9654 (0.7380) ce_loss 0.6201 (0.3966) teacher_loss 0.5724 (0.3096) loss_zs_kd 0.1069 (0.1068) loss_oracle 0.3396 (0.3750) acc 78.1250 (86.1328) kd_loss 0.7685 (0.7816) lr 4.8943e-05 eta 0:01:04
epoch [47/50] batch [100/176] time 0.115 (0.104) data 0.000 (0.003) loss 0.6818 (0.7266) ce_loss 0.3362 (0.3841) teacher_loss 0.2238 (0.2960) loss_zs_kd 0.1232 (0.1082) loss_oracle 0.3964 (0.3765) acc 93.7500 (86.6562) kd_loss 0.8281 (0.7846) lr 4.8943e-05 eta 0:01:02
epoch [47/50] batch [120/176] time 0.135 (0.104) data 0.000 (0.002) loss 0.6356 (0.7233) ce_loss 0.3159 (0.3791) teacher_loss 0.2107 (0.2909) loss_zs_kd 0.1313 (0.1096) loss_oracle 0.3592 (0.3776) acc 87.5000 (86.8750) kd_loss 0.7722 (0.7860) lr 4.8943e-05 eta 0:01:00
epoch [47/50] batch [140/176] time 0.079 (0.104) data 0.000 (0.002) loss 0.5044 (0.7209) ce_loss 0.1747 (0.3751) teacher_loss 0.1459 (0.2877) loss_zs_kd 0.1070 (0.1108) loss_oracle 0.3050 (0.3778) acc 93.7500 (86.9420) kd_loss 0.6903 (0.7869) lr 4.8943e-05 eta 0:00:58
epoch [47/50] batch [160/176] time 0.133 (0.104) data 0.000 (0.002) loss 0.5519 (0.7174) ce_loss 0.2534 (0.3731) teacher_loss 0.1826 (0.2862) loss_zs_kd 0.0960 (0.1108) loss_oracle 0.3214 (0.3758) acc 90.6250 (86.8359) kd_loss 0.7809 (0.7882) lr 4.8943e-05 eta 0:00:56
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,181
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,759
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 61.5%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [48/50] batch [20/176] time 0.071 (0.123) data 0.000 (0.018) loss 0.6957 (0.7517) ce_loss 0.3838 (0.4187) teacher_loss 0.2339 (0.3050) loss_zs_kd 0.1212 (0.1150) loss_oracle 0.4012 (0.3892) acc 87.5000 (84.6875) kd_loss 0.7735 (0.8041) lr 3.1417e-05 eta 0:01:02
epoch [48/50] batch [40/176] time 0.119 (0.110) data 0.000 (0.009) loss 0.8224 (0.7559) ce_loss 0.3748 (0.4080) teacher_loss 0.3306 (0.3081) loss_zs_kd 0.1527 (0.1157) loss_oracle 0.4154 (0.3900) acc 90.6250 (85.1562) kd_loss 0.8376 (0.7995) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [60/176] time 0.127 (0.108) data 0.000 (0.006) loss 0.8595 (0.7372) ce_loss 0.5332 (0.3940) teacher_loss 0.4467 (0.2984) loss_zs_kd 0.1552 (0.1164) loss_oracle 0.3353 (0.3806) acc 81.2500 (85.6771) kd_loss 0.8370 (0.7973) lr 3.1417e-05 eta 0:00:50
epoch [48/50] batch [80/176] time 0.081 (0.109) data 0.000 (0.005) loss 0.7072 (0.7497) ce_loss 0.3232 (0.4043) teacher_loss 0.3082 (0.3101) loss_zs_kd 0.0944 (0.1163) loss_oracle 0.3518 (0.3814) acc 93.7500 (86.0547) kd_loss 0.7204 (0.8013) lr 3.1417e-05 eta 0:00:48
epoch [48/50] batch [100/176] time 0.110 (0.110) data 0.000 (0.004) loss 0.6967 (0.7425) ce_loss 0.3538 (0.3986) teacher_loss 0.2691 (0.3047) loss_zs_kd 0.1691 (0.1162) loss_oracle 0.3430 (0.3798) acc 90.6250 (86.3125) kd_loss 0.7514 (0.7963) lr 3.1417e-05 eta 0:00:46
epoch [48/50] batch [120/176] time 0.118 (0.111) data 0.000 (0.003) loss 0.7020 (0.7438) ce_loss 0.2800 (0.3989) teacher_loss 0.2204 (0.3066) loss_zs_kd 0.1027 (0.1149) loss_oracle 0.4302 (0.3797) acc 87.5000 (86.2240) kd_loss 0.8044 (0.7975) lr 3.1417e-05 eta 0:00:45
epoch [48/50] batch [140/176] time 0.073 (0.110) data 0.000 (0.003) loss 0.6857 (0.7416) ce_loss 0.4087 (0.3962) teacher_loss 0.3255 (0.3043) loss_zs_kd 0.0890 (0.1142) loss_oracle 0.3157 (0.3802) acc 87.5000 (86.2500) kd_loss 0.8031 (0.7967) lr 3.1417e-05 eta 0:00:42
epoch [48/50] batch [160/176] time 0.180 (0.114) data 0.000 (0.002) loss 0.6481 (0.7394) ce_loss 0.3284 (0.3947) teacher_loss 0.2343 (0.3033) loss_zs_kd 0.1239 (0.1130) loss_oracle 0.3518 (0.3796) acc 87.5000 (86.2891) kd_loss 0.7813 (0.7956) lr 3.1417e-05 eta 0:00:42
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,180
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,759
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 61.5%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [49/50] batch [20/176] time 0.091 (0.122) data 0.000 (0.018) loss 0.5768 (0.6405) ce_loss 0.3479 (0.3041) teacher_loss 0.2567 (0.2215) loss_zs_kd 0.0928 (0.1005) loss_oracle 0.2737 (0.3688) acc 87.5000 (90.4688) kd_loss 0.6485 (0.7854) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [40/176] time 0.109 (0.112) data 0.000 (0.009) loss 0.6583 (0.6798) ce_loss 0.3145 (0.3367) teacher_loss 0.2137 (0.2476) loss_zs_kd 0.1384 (0.1120) loss_oracle 0.3754 (0.3762) acc 90.6250 (89.0625) kd_loss 0.7592 (0.7934) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [60/176] time 0.073 (0.111) data 0.000 (0.006) loss 0.7364 (0.6968) ce_loss 0.4814 (0.3573) teacher_loss 0.3011 (0.2644) loss_zs_kd 0.1111 (0.1125) loss_oracle 0.3797 (0.3761) acc 75.0000 (87.7604) kd_loss 0.7598 (0.7866) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [80/176] time 0.087 (0.110) data 0.000 (0.005) loss 0.5734 (0.6957) ce_loss 0.2019 (0.3557) teacher_loss 0.1992 (0.2651) loss_zs_kd 0.0823 (0.1120) loss_oracle 0.3330 (0.3746) acc 93.7500 (87.9688) kd_loss 0.7493 (0.7826) lr 1.7713e-05 eta 0:00:29
epoch [49/50] batch [100/176] time 0.089 (0.108) data 0.000 (0.004) loss 0.5185 (0.6963) ce_loss 0.1709 (0.3552) teacher_loss 0.1043 (0.2656) loss_zs_kd 0.1077 (0.1126) loss_oracle 0.3604 (0.3743) acc 93.7500 (87.8438) kd_loss 0.7778 (0.7889) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [120/176] time 0.101 (0.107) data 0.000 (0.003) loss 0.6513 (0.7020) ce_loss 0.3049 (0.3601) teacher_loss 0.2522 (0.2687) loss_zs_kd 0.1050 (0.1132) loss_oracle 0.3465 (0.3767) acc 87.5000 (87.4740) kd_loss 0.8110 (0.7920) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [140/176] time 0.087 (0.106) data 0.000 (0.003) loss 0.8472 (0.7098) ce_loss 0.4946 (0.3652) teacher_loss 0.4156 (0.2749) loss_zs_kd 0.1269 (0.1135) loss_oracle 0.3681 (0.3781) acc 84.3750 (87.2321) kd_loss 0.7750 (0.7929) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [160/176] time 0.109 (0.105) data 0.000 (0.002) loss 0.7387 (0.7101) ce_loss 0.3984 (0.3649) teacher_loss 0.3281 (0.2748) loss_zs_kd 0.1211 (0.1144) loss_oracle 0.3501 (0.3782) acc 93.7500 (87.1875) kd_loss 0.7866 (0.7955) lr 1.7713e-05 eta 0:00:20
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,181
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,755
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 61.2%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
epoch [50/50] batch [20/176] time 0.132 (0.112) data 0.000 (0.012) loss 0.5664 (0.6861) ce_loss 0.2365 (0.3369) teacher_loss 0.1498 (0.2405) loss_zs_kd 0.0922 (0.1148) loss_oracle 0.3705 (0.3882) acc 90.6250 (88.1250) kd_loss 0.8246 (0.8092) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [40/176] time 0.116 (0.108) data 0.000 (0.006) loss 0.8715 (0.6916) ce_loss 0.4456 (0.3500) teacher_loss 0.3917 (0.2563) loss_zs_kd 0.1007 (0.1136) loss_oracle 0.4294 (0.3785) acc 84.3750 (87.5781) kd_loss 0.8430 (0.7958) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [60/176] time 0.100 (0.105) data 0.001 (0.004) loss 0.6959 (0.6886) ce_loss 0.3740 (0.3494) teacher_loss 0.2355 (0.2522) loss_zs_kd 0.1084 (0.1132) loss_oracle 0.4062 (0.3797) acc 87.5000 (87.5521) kd_loss 0.7695 (0.7962) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [80/176] time 0.084 (0.104) data 0.000 (0.003) loss 0.8799 (0.7007) ce_loss 0.4893 (0.3638) teacher_loss 0.3674 (0.2689) loss_zs_kd 0.1033 (0.1117) loss_oracle 0.4609 (0.3760) acc 81.2500 (87.0703) kd_loss 0.8164 (0.7912) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [100/176] time 0.097 (0.104) data 0.000 (0.003) loss 0.7599 (0.7035) ce_loss 0.3101 (0.3617) teacher_loss 0.2788 (0.2702) loss_zs_kd 0.0893 (0.1121) loss_oracle 0.4365 (0.3773) acc 87.5000 (87.2188) kd_loss 0.8940 (0.7930) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [120/176] time 0.071 (0.102) data 0.000 (0.002) loss 0.7346 (0.7120) ce_loss 0.4351 (0.3689) teacher_loss 0.3206 (0.2794) loss_zs_kd 0.1131 (0.1142) loss_oracle 0.3574 (0.3756) acc 90.6250 (86.9010) kd_loss 0.6799 (0.7931) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [140/176] time 0.113 (0.101) data 0.000 (0.002) loss 0.6318 (0.7204) ce_loss 0.3550 (0.3777) teacher_loss 0.2326 (0.2863) loss_zs_kd 0.0999 (0.1138) loss_oracle 0.3493 (0.3772) acc 90.6250 (86.7857) kd_loss 0.7901 (0.7942) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [160/176] time 0.098 (0.102) data 0.001 (0.002) loss 0.6808 (0.7192) ce_loss 0.2952 (0.3748) teacher_loss 0.1978 (0.2855) loss_zs_kd 0.0855 (0.1128) loss_oracle 0.4402 (0.3773) acc 87.5000 (87.0117) kd_loss 0.8368 (0.7937) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,182
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,758
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 61.5%
******* Domain l best val acc:      90.5%, epoch: 26 *******
******* Domain l best val test acc: 64.3%, epoch: 26 *******
******* Domain l best test acc:     69.2%, epoch: 4 *******
Checkpoint saved to icml/multi-dg/oracle/04_nonnegative/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:20:51

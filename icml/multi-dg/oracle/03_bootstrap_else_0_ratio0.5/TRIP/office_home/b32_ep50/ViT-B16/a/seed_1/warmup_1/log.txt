Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------------
Dataset    SPG_OfficeHome
Source     ['clipart', 'product', 'real_world']
Target     ['art']
# classes  65
# train_x  9,222
# val      3,939
# test     2,427
---------  ------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/288] time 0.113 (0.163) data 0.000 (0.021) loss 1.1131 (1.2412) ce_loss 1.1104 (1.2377) teacher_loss 1.1106 (1.2380) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0024 (0.0032) acc 71.8750 (68.5938) kd_loss 0.0098 (0.0128) lr 1.0000e-05 eta 0:39:08
epoch [1/50] batch [40/288] time 0.100 (0.137) data 0.000 (0.011) loss 1.2211 (1.2627) ce_loss 1.2178 (1.2591) teacher_loss 1.2169 (1.2594) loss_zs_kd 0.0002 (0.0000) loss_oracle 0.0041 (0.0032) acc 65.6250 (68.3594) kd_loss 0.0168 (0.0129) lr 1.0000e-05 eta 0:32:48
epoch [1/50] batch [60/288] time 0.118 (0.126) data 0.001 (0.007) loss 1.4317 (1.2693) ce_loss 1.4297 (1.2662) teacher_loss 1.4293 (1.2662) loss_zs_kd 0.0006 (0.0001) loss_oracle 0.0021 (0.0031) acc 59.3750 (67.7083) kd_loss 0.0076 (0.0122) lr 1.0000e-05 eta 0:30:11
epoch [1/50] batch [80/288] time 0.093 (0.120) data 0.000 (0.005) loss 1.2609 (1.2732) ce_loss 1.2568 (1.2702) teacher_loss 1.2564 (1.2702) loss_zs_kd 0.0008 (0.0002) loss_oracle 0.0040 (0.0029) acc 62.5000 (67.5000) kd_loss 0.0158 (0.0115) lr 1.0000e-05 eta 0:28:39
epoch [1/50] batch [100/288] time 0.088 (0.115) data 0.000 (0.004) loss 1.0931 (1.2453) ce_loss 1.0908 (1.2426) teacher_loss 1.0902 (1.2425) loss_zs_kd 0.0006 (0.0003) loss_oracle 0.0027 (0.0027) acc 62.5000 (68.1875) kd_loss 0.0101 (0.0106) lr 1.0000e-05 eta 0:27:19
epoch [1/50] batch [120/288] time 0.100 (0.111) data 0.000 (0.004) loss 1.0351 (1.2390) ce_loss 1.0352 (1.2365) teacher_loss 1.0328 (1.2363) loss_zs_kd 0.0007 (0.0004) loss_oracle 0.0020 (0.0025) acc 75.0000 (68.2292) kd_loss 0.0066 (0.0097) lr 1.0000e-05 eta 0:26:31
epoch [1/50] batch [140/288] time 0.093 (0.109) data 0.000 (0.003) loss 1.4882 (1.2250) ce_loss 1.4883 (1.2225) teacher_loss 1.4858 (1.2224) loss_zs_kd 0.0010 (0.0005) loss_oracle 0.0019 (0.0023) acc 56.2500 (68.3259) kd_loss 0.0050 (0.0090) lr 1.0000e-05 eta 0:25:57
epoch [1/50] batch [160/288] time 0.095 (0.108) data 0.000 (0.003) loss 1.0588 (1.2224) ce_loss 1.0557 (1.2201) teacher_loss 1.0571 (1.2199) loss_zs_kd 0.0019 (0.0006) loss_oracle 0.0008 (0.0022) acc 71.8750 (68.6523) kd_loss 0.0024 (0.0084) lr 1.0000e-05 eta 0:25:34
epoch [1/50] batch [180/288] time 0.092 (0.107) data 0.000 (0.003) loss 0.9960 (1.2259) ce_loss 0.9927 (1.2236) teacher_loss 0.9940 (1.2234) loss_zs_kd 0.0023 (0.0007) loss_oracle 0.0009 (0.0021) acc 71.8750 (68.4549) kd_loss 0.0026 (0.0079) lr 1.0000e-05 eta 0:25:16
epoch [1/50] batch [200/288] time 0.099 (0.106) data 0.000 (0.002) loss 1.3383 (1.2226) ce_loss 1.3359 (1.2203) teacher_loss 1.3366 (1.2202) loss_zs_kd 0.0019 (0.0008) loss_oracle 0.0007 (0.0020) acc 62.5000 (68.3438) kd_loss 0.0027 (0.0075) lr 1.0000e-05 eta 0:24:58
epoch [1/50] batch [220/288] time 0.096 (0.105) data 0.000 (0.002) loss 1.4186 (1.2183) ce_loss 1.4170 (1.2160) teacher_loss 1.4166 (1.2159) loss_zs_kd 0.0022 (0.0010) loss_oracle 0.0010 (0.0019) acc 65.6250 (68.6080) kd_loss 0.0028 (0.0070) lr 1.0000e-05 eta 0:24:42
epoch [1/50] batch [240/288] time 0.102 (0.104) data 0.000 (0.002) loss 0.9870 (1.2159) ce_loss 0.9849 (1.2136) teacher_loss 0.9854 (1.2135) loss_zs_kd 0.0010 (0.0011) loss_oracle 0.0011 (0.0018) acc 81.2500 (68.8672) kd_loss 0.0038 (0.0067) lr 1.0000e-05 eta 0:24:30
epoch [1/50] batch [260/288] time 0.097 (0.103) data 0.000 (0.002) loss 1.3075 (1.2215) ce_loss 1.3037 (1.2192) teacher_loss 1.3039 (1.2191) loss_zs_kd 0.0053 (0.0012) loss_oracle 0.0009 (0.0018) acc 71.8750 (68.7139) kd_loss 0.0023 (0.0064) lr 1.0000e-05 eta 0:24:21
epoch [1/50] batch [280/288] time 0.091 (0.103) data 0.000 (0.002) loss 1.5232 (1.2214) ce_loss 1.5205 (1.2191) teacher_loss 1.5197 (1.2190) loss_zs_kd 0.0051 (0.0014) loss_oracle 0.0009 (0.0017) acc 62.5000 (68.7612) kd_loss 0.0027 (0.0061) lr 1.0000e-05 eta 0:24:15
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,267
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 82.0%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,966
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 76.8%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      82.9%, epoch: 1 *******
******* Domain a best val test acc: 81.0%, epoch: 1 *******
******* Domain a best test acc:     81.0%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/ana
epoch [2/50] batch [20/288] time 0.101 (0.125) data 0.000 (0.020) loss 1.1004 (1.2416) ce_loss 1.0439 (1.1907) teacher_loss 1.0466 (1.1914) loss_zs_kd 0.0995 (0.0957) loss_oracle 0.0041 (0.0024) acc 65.6250 (68.5938) kd_loss 0.0024 (0.0020) lr 2.0000e-03 eta 0:29:19
epoch [2/50] batch [40/288] time 0.115 (0.114) data 0.000 (0.010) loss 0.7524 (1.1862) ce_loss 0.6978 (1.1242) teacher_loss 0.6992 (1.1259) loss_zs_kd 0.0873 (0.1099) loss_oracle 0.0096 (0.0054) acc 81.2500 (70.0781) kd_loss 0.0014 (0.0019) lr 2.0000e-03 eta 0:26:40
epoch [2/50] batch [60/288] time 0.102 (0.110) data 0.000 (0.007) loss 1.3701 (1.1893) ce_loss 1.3125 (1.1277) teacher_loss 1.3139 (1.1295) loss_zs_kd 0.0952 (0.1077) loss_oracle 0.0087 (0.0060) acc 68.7500 (70.4688) kd_loss 0.0034 (0.0022) lr 2.0000e-03 eta 0:25:45
epoch [2/50] batch [80/288] time 0.112 (0.108) data 0.000 (0.005) loss 0.8990 (1.1741) ce_loss 0.8481 (1.1137) teacher_loss 0.8507 (1.1155) loss_zs_kd 0.0830 (0.1035) loss_oracle 0.0068 (0.0069) acc 71.8750 (71.1328) kd_loss 0.0026 (0.0024) lr 2.0000e-03 eta 0:25:14
epoch [2/50] batch [100/288] time 0.111 (0.107) data 0.001 (0.004) loss 1.5397 (1.1725) ce_loss 1.4941 (1.1131) teacher_loss 1.4958 (1.1148) loss_zs_kd 0.0759 (0.1019) loss_oracle 0.0060 (0.0068) acc 59.3750 (71.1562) kd_loss 0.0030 (0.0025) lr 2.0000e-03 eta 0:24:56
epoch [2/50] batch [120/288] time 0.099 (0.106) data 0.000 (0.004) loss 1.1599 (1.1680) ce_loss 1.1221 (1.1089) teacher_loss 1.1239 (1.1105) loss_zs_kd 0.0606 (0.1015) loss_oracle 0.0057 (0.0067) acc 71.8750 (71.0417) kd_loss 0.0026 (0.0026) lr 2.0000e-03 eta 0:24:39
epoch [2/50] batch [140/288] time 0.099 (0.105) data 0.000 (0.003) loss 1.2990 (1.1709) ce_loss 1.2178 (1.1125) teacher_loss 1.2209 (1.1141) loss_zs_kd 0.1323 (0.0995) loss_oracle 0.0119 (0.0070) acc 68.7500 (70.8929) kd_loss 0.0043 (0.0027) lr 2.0000e-03 eta 0:24:32
epoch [2/50] batch [160/288] time 0.103 (0.105) data 0.000 (0.003) loss 1.1931 (1.1711) ce_loss 1.1074 (1.1126) teacher_loss 1.1083 (1.1143) loss_zs_kd 0.1569 (0.0987) loss_oracle 0.0064 (0.0075) acc 68.7500 (70.7812) kd_loss 0.0039 (0.0029) lr 2.0000e-03 eta 0:24:24
epoch [2/50] batch [180/288] time 0.099 (0.105) data 0.000 (0.002) loss 1.0653 (1.1657) ce_loss 1.0000 (1.1070) teacher_loss 1.0041 (1.1087) loss_zs_kd 0.1073 (0.0990) loss_oracle 0.0076 (0.0075) acc 78.1250 (70.9201) kd_loss 0.0046 (0.0030) lr 2.0000e-03 eta 0:24:20
epoch [2/50] batch [200/288] time 0.109 (0.104) data 0.000 (0.002) loss 1.8191 (1.1684) ce_loss 1.7197 (1.1082) teacher_loss 1.7224 (1.1098) loss_zs_kd 0.1647 (0.1019) loss_oracle 0.0144 (0.0076) acc 59.3750 (70.8125) kd_loss 0.0072 (0.0032) lr 2.0000e-03 eta 0:24:12
epoch [2/50] batch [220/288] time 0.105 (0.104) data 0.000 (0.002) loss 1.2065 (1.1579) ce_loss 1.1338 (1.0970) teacher_loss 1.1352 (1.0986) loss_zs_kd 0.1174 (0.1026) loss_oracle 0.0125 (0.0081) acc 71.8750 (71.0938) kd_loss 0.0050 (0.0034) lr 2.0000e-03 eta 0:24:11
epoch [2/50] batch [240/288] time 0.109 (0.104) data 0.000 (0.002) loss 1.4501 (1.1539) ce_loss 1.3936 (1.0929) teacher_loss 1.3947 (1.0944) loss_zs_kd 0.0919 (0.1024) loss_oracle 0.0095 (0.0082) acc 65.6250 (71.1458) kd_loss 0.0052 (0.0036) lr 2.0000e-03 eta 0:24:08
epoch [2/50] batch [260/288] time 0.104 (0.104) data 0.000 (0.002) loss 1.1758 (1.1502) ce_loss 1.0586 (1.0885) teacher_loss 1.0595 (1.0900) loss_zs_kd 0.1888 (0.1028) loss_oracle 0.0219 (0.0088) acc 78.1250 (71.2260) kd_loss 0.0065 (0.0038) lr 2.0000e-03 eta 0:24:05
epoch [2/50] batch [280/288] time 0.105 (0.104) data 0.000 (0.002) loss 0.8735 (1.1464) ce_loss 0.8032 (1.0840) teacher_loss 0.8023 (1.0856) loss_zs_kd 0.1140 (0.1032) loss_oracle 0.0143 (0.0092) acc 75.0000 (71.2946) kd_loss 0.0064 (0.0040) lr 2.0000e-03 eta 0:24:03
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,381
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 85.2%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.5%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      85.8%, epoch: 2 *******
******* Domain a best val test acc: 83.2%, epoch: 2 *******
******* Domain a best test acc:     83.2%, epoch: 2 *******
epoch [3/50] batch [20/288] time 0.085 (0.110) data 0.000 (0.013) loss 1.5637 (1.1552) ce_loss 1.4824 (1.0777) teacher_loss 1.4835 (1.0789) loss_zs_kd 0.1294 (0.1159) loss_oracle 0.0154 (0.0184) acc 53.1250 (71.2500) kd_loss 0.0075 (0.0071) lr 1.9980e-03 eta 0:25:22
epoch [3/50] batch [40/288] time 0.093 (0.102) data 0.000 (0.007) loss 0.9294 (1.0842) ce_loss 0.8677 (1.0031) teacher_loss 0.8708 (1.0051) loss_zs_kd 0.0680 (0.1073) loss_oracle 0.0246 (0.0255) acc 78.1250 (73.3594) kd_loss 0.0111 (0.0078) lr 1.9980e-03 eta 0:23:23
epoch [3/50] batch [60/288] time 0.096 (0.101) data 0.000 (0.005) loss 0.9971 (1.1314) ce_loss 0.9263 (1.0502) teacher_loss 0.9261 (1.0518) loss_zs_kd 0.0875 (0.1078) loss_oracle 0.0273 (0.0257) acc 75.0000 (72.1875) kd_loss 0.0145 (0.0088) lr 1.9980e-03 eta 0:23:08
epoch [3/50] batch [80/288] time 0.097 (0.100) data 0.000 (0.003) loss 1.1150 (1.1359) ce_loss 1.0166 (1.0514) teacher_loss 1.0180 (1.0533) loss_zs_kd 0.1032 (0.1084) loss_oracle 0.0454 (0.0284) acc 71.8750 (71.9141) kd_loss 0.0127 (0.0096) lr 1.9980e-03 eta 0:22:53
epoch [3/50] batch [100/288] time 0.098 (0.099) data 0.000 (0.003) loss 1.0553 (1.1512) ce_loss 0.9468 (1.0629) teacher_loss 0.9430 (1.0645) loss_zs_kd 0.0864 (0.1079) loss_oracle 0.0691 (0.0327) acc 75.0000 (71.7188) kd_loss 0.0208 (0.0111) lr 1.9980e-03 eta 0:22:40
epoch [3/50] batch [120/288] time 0.100 (0.099) data 0.000 (0.002) loss 0.8333 (1.1490) ce_loss 0.6826 (1.0510) teacher_loss 0.6849 (1.0524) loss_zs_kd 0.1217 (0.1120) loss_oracle 0.0875 (0.0407) acc 81.2500 (72.1615) kd_loss 0.0262 (0.0134) lr 1.9980e-03 eta 0:22:34
epoch [3/50] batch [140/288] time 0.095 (0.098) data 0.000 (0.002) loss 1.0878 (1.1490) ce_loss 0.9932 (1.0469) teacher_loss 0.9905 (1.0480) loss_zs_kd 0.0712 (0.1120) loss_oracle 0.0617 (0.0450) acc 75.0000 (72.0759) kd_loss 0.0326 (0.0161) lr 1.9980e-03 eta 0:22:24
epoch [3/50] batch [160/288] time 0.098 (0.098) data 0.000 (0.002) loss 1.6668 (1.1538) ce_loss 1.5479 (1.0513) teacher_loss 1.5470 (1.0525) loss_zs_kd 0.1367 (0.1136) loss_oracle 0.0514 (0.0445) acc 59.3750 (71.8945) kd_loss 0.0410 (0.0182) lr 1.9980e-03 eta 0:22:16
epoch [3/50] batch [180/288] time 0.087 (0.097) data 0.000 (0.002) loss 1.2296 (1.1532) ce_loss 1.1182 (1.0515) teacher_loss 1.1220 (1.0527) loss_zs_kd 0.1110 (0.1125) loss_oracle 0.0521 (0.0443) acc 71.8750 (71.9444) kd_loss 0.0332 (0.0196) lr 1.9980e-03 eta 0:22:01
epoch [3/50] batch [200/288] time 0.100 (0.097) data 0.000 (0.002) loss 1.1568 (1.1528) ce_loss 1.0215 (1.0492) teacher_loss 1.0240 (1.0501) loss_zs_kd 0.0920 (0.1125) loss_oracle 0.0868 (0.0465) acc 75.0000 (72.1094) kd_loss 0.0435 (0.0211) lr 1.9980e-03 eta 0:21:58
epoch [3/50] batch [220/288] time 0.093 (0.096) data 0.000 (0.001) loss 0.9268 (1.1661) ce_loss 0.8247 (1.0589) teacher_loss 0.8305 (1.0597) loss_zs_kd 0.1139 (0.1145) loss_oracle 0.0394 (0.0492) acc 75.0000 (71.8892) kd_loss 0.0330 (0.0230) lr 1.9980e-03 eta 0:21:47
epoch [3/50] batch [240/288] time 0.090 (0.096) data 0.000 (0.001) loss 1.4231 (1.1706) ce_loss 1.3037 (1.0627) teacher_loss 1.3064 (1.0635) loss_zs_kd 0.0846 (0.1141) loss_oracle 0.0744 (0.0502) acc 65.6250 (71.8620) kd_loss 0.0500 (0.0245) lr 1.9980e-03 eta 0:21:40
epoch [3/50] batch [260/288] time 0.092 (0.095) data 0.000 (0.001) loss 0.7825 (1.1659) ce_loss 0.6553 (1.0579) teacher_loss 0.6405 (1.0585) loss_zs_kd 0.1118 (0.1137) loss_oracle 0.0860 (0.0506) acc 87.5000 (71.9952) kd_loss 0.0465 (0.0258) lr 1.9980e-03 eta 0:21:35
epoch [3/50] batch [280/288] time 0.087 (0.095) data 0.000 (0.001) loss 1.2927 (1.1655) ce_loss 1.0967 (1.0540) teacher_loss 1.0887 (1.0545) loss_zs_kd 0.1961 (0.1149) loss_oracle 0.1059 (0.0535) acc 68.7500 (72.1205) kd_loss 0.0590 (0.0272) lr 1.9980e-03 eta 0:21:29
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,386
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 85.2%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,014
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 79.5%
******* Domain a best val acc:      86.0%, epoch: 3 *******
******* Domain a best val test acc: 83.0%, epoch: 3 *******
******* Domain a best test acc:     83.2%, epoch: 2 *******
epoch [4/50] batch [20/288] time 0.112 (0.121) data 0.000 (0.012) loss 0.9764 (1.1099) ce_loss 0.8696 (0.9846) teacher_loss 0.8651 (0.9812) loss_zs_kd 0.0864 (0.1092) loss_oracle 0.0682 (0.0741) acc 84.3750 (73.5938) kd_loss 0.0366 (0.0455) lr 1.9921e-03 eta 0:27:20
epoch [4/50] batch [40/288] time 0.112 (0.114) data 0.001 (0.006) loss 1.2493 (1.1254) ce_loss 1.1113 (1.0003) teacher_loss 1.1033 (0.9993) loss_zs_kd 0.1912 (0.1135) loss_oracle 0.0505 (0.0695) acc 68.7500 (73.4375) kd_loss 0.0435 (0.0438) lr 1.9921e-03 eta 0:25:45
epoch [4/50] batch [60/288] time 0.105 (0.110) data 0.001 (0.004) loss 1.2686 (1.1090) ce_loss 1.1865 (0.9922) teacher_loss 1.1923 (0.9919) loss_zs_kd 0.0899 (0.1116) loss_oracle 0.0313 (0.0613) acc 68.7500 (73.5938) kd_loss 0.0232 (0.0421) lr 1.9921e-03 eta 0:24:44
epoch [4/50] batch [80/288] time 0.110 (0.108) data 0.001 (0.003) loss 1.5345 (1.1256) ce_loss 1.4326 (1.0124) teacher_loss 1.4340 (1.0123) loss_zs_kd 0.0979 (0.1097) loss_oracle 0.0515 (0.0585) acc 65.6250 (73.3594) kd_loss 0.0346 (0.0409) lr 1.9921e-03 eta 0:24:06
epoch [4/50] batch [100/288] time 0.102 (0.107) data 0.000 (0.003) loss 1.0437 (1.1438) ce_loss 0.9453 (1.0339) teacher_loss 0.9417 (1.0337) loss_zs_kd 0.0845 (0.1065) loss_oracle 0.0598 (0.0569) acc 78.1250 (72.7500) kd_loss 0.0365 (0.0394) lr 1.9921e-03 eta 0:24:00
epoch [4/50] batch [120/288] time 0.087 (0.106) data 0.000 (0.002) loss 1.0588 (1.1519) ce_loss 0.9341 (1.0425) teacher_loss 0.9395 (1.0421) loss_zs_kd 0.1095 (0.1056) loss_oracle 0.0646 (0.0570) acc 78.1250 (72.5260) kd_loss 0.0295 (0.0384) lr 1.9921e-03 eta 0:23:46
epoch [4/50] batch [140/288] time 0.096 (0.105) data 0.000 (0.002) loss 0.8953 (1.1594) ce_loss 0.8096 (1.0490) teacher_loss 0.8109 (1.0486) loss_zs_kd 0.0948 (0.1067) loss_oracle 0.0370 (0.0574) acc 81.2500 (72.2768) kd_loss 0.0298 (0.0381) lr 1.9921e-03 eta 0:23:23
epoch [4/50] batch [160/288] time 0.110 (0.104) data 0.000 (0.002) loss 1.3131 (1.1506) ce_loss 1.2246 (1.0420) teacher_loss 1.2203 (1.0413) loss_zs_kd 0.1138 (0.1087) loss_oracle 0.0359 (0.0549) acc 68.7500 (72.3633) kd_loss 0.0304 (0.0374) lr 1.9921e-03 eta 0:23:07
epoch [4/50] batch [180/288] time 0.100 (0.103) data 0.000 (0.002) loss 1.5060 (1.1468) ce_loss 1.3906 (1.0395) teacher_loss 1.3809 (1.0387) loss_zs_kd 0.1516 (0.1096) loss_oracle 0.0492 (0.0534) acc 62.5000 (72.3090) kd_loss 0.0250 (0.0365) lr 1.9921e-03 eta 0:22:57
epoch [4/50] batch [200/288] time 0.097 (0.102) data 0.000 (0.001) loss 1.2429 (1.1455) ce_loss 1.1357 (1.0366) teacher_loss 1.1320 (1.0358) loss_zs_kd 0.1096 (0.1123) loss_oracle 0.0561 (0.0535) acc 71.8750 (72.5469) kd_loss 0.0280 (0.0359) lr 1.9921e-03 eta 0:22:45
epoch [4/50] batch [220/288] time 0.095 (0.102) data 0.000 (0.001) loss 1.2872 (1.1481) ce_loss 1.1807 (1.0376) teacher_loss 1.1784 (1.0365) loss_zs_kd 0.0953 (0.1135) loss_oracle 0.0612 (0.0548) acc 71.8750 (72.4006) kd_loss 0.0348 (0.0358) lr 1.9921e-03 eta 0:22:44
epoch [4/50] batch [240/288] time 0.097 (0.102) data 0.000 (0.001) loss 1.3422 (1.1459) ce_loss 1.2188 (1.0352) teacher_loss 1.2079 (1.0343) loss_zs_kd 0.1185 (0.1131) loss_oracle 0.0751 (0.0551) acc 68.7500 (72.5521) kd_loss 0.0313 (0.0352) lr 1.9921e-03 eta 0:22:36
epoch [4/50] batch [260/288] time 0.090 (0.102) data 0.000 (0.001) loss 0.9578 (1.1520) ce_loss 0.8228 (1.0397) teacher_loss 0.8197 (1.0387) loss_zs_kd 0.1224 (0.1137) loss_oracle 0.0769 (0.0564) acc 71.8750 (72.4038) kd_loss 0.0415 (0.0352) lr 1.9921e-03 eta 0:22:31
epoch [4/50] batch [280/288] time 0.086 (0.101) data 0.000 (0.001) loss 0.8231 (1.1477) ce_loss 0.7188 (1.0350) teacher_loss 0.7238 (1.0340) loss_zs_kd 0.0950 (0.1129) loss_oracle 0.0518 (0.0572) acc 81.2500 (72.6339) kd_loss 0.0258 (0.0350) lr 1.9921e-03 eta 0:22:20
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,406
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 85.8%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 79.6%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.5%, epoch: 4 *******
******* Domain a best val test acc: 83.3%, epoch: 4 *******
******* Domain a best test acc:     83.3%, epoch: 4 *******
epoch [5/50] batch [20/288] time 0.106 (0.118) data 0.001 (0.014) loss 1.5428 (1.3121) ce_loss 1.4111 (1.1753) teacher_loss 1.4221 (1.1748) loss_zs_kd 0.1275 (0.1418) loss_oracle 0.0570 (0.0664) acc 71.8750 (70.4688) kd_loss 0.0342 (0.0376) lr 1.9823e-03 eta 0:25:55
epoch [5/50] batch [40/288] time 0.102 (0.112) data 0.001 (0.007) loss 0.6609 (1.2029) ce_loss 0.4993 (1.0687) teacher_loss 0.5029 (1.0669) loss_zs_kd 0.1739 (0.1340) loss_oracle 0.0710 (0.0690) acc 90.6250 (72.3438) kd_loss 0.0342 (0.0379) lr 1.9823e-03 eta 0:24:37
epoch [5/50] batch [60/288] time 0.106 (0.109) data 0.001 (0.005) loss 1.2859 (1.1692) ce_loss 1.1748 (1.0371) teacher_loss 1.1718 (1.0350) loss_zs_kd 0.0820 (0.1259) loss_oracle 0.0731 (0.0713) acc 62.5000 (73.1771) kd_loss 0.0430 (0.0382) lr 1.9823e-03 eta 0:23:55
epoch [5/50] batch [80/288] time 0.101 (0.107) data 0.001 (0.004) loss 1.5008 (1.1495) ce_loss 1.4062 (1.0189) teacher_loss 1.4017 (1.0159) loss_zs_kd 0.1060 (0.1268) loss_oracle 0.0461 (0.0702) acc 75.0000 (73.3203) kd_loss 0.0279 (0.0382) lr 1.9823e-03 eta 0:23:27
epoch [5/50] batch [100/288] time 0.099 (0.106) data 0.000 (0.003) loss 0.8037 (1.1570) ce_loss 0.6816 (1.0284) teacher_loss 0.6711 (1.0253) loss_zs_kd 0.1187 (0.1265) loss_oracle 0.0733 (0.0684) acc 81.2500 (73.1562) kd_loss 0.0355 (0.0380) lr 1.9823e-03 eta 0:23:16
epoch [5/50] batch [120/288] time 0.098 (0.106) data 0.000 (0.003) loss 1.1966 (1.1470) ce_loss 1.0420 (1.0199) teacher_loss 1.0345 (1.0166) loss_zs_kd 0.1478 (0.1233) loss_oracle 0.0882 (0.0687) acc 75.0000 (73.3333) kd_loss 0.0509 (0.0379) lr 1.9823e-03 eta 0:23:06
epoch [5/50] batch [140/288] time 0.100 (0.105) data 0.000 (0.002) loss 1.1722 (1.1472) ce_loss 1.0732 (1.0243) teacher_loss 1.0728 (1.0206) loss_zs_kd 0.1092 (0.1204) loss_oracle 0.0448 (0.0664) acc 65.6250 (73.3482) kd_loss 0.0353 (0.0371) lr 1.9823e-03 eta 0:22:58
epoch [5/50] batch [160/288] time 0.101 (0.105) data 0.000 (0.002) loss 1.3999 (1.1481) ce_loss 1.2891 (1.0275) teacher_loss 1.2839 (1.0238) loss_zs_kd 0.1070 (0.1196) loss_oracle 0.0626 (0.0645) acc 65.6250 (73.0469) kd_loss 0.0364 (0.0364) lr 1.9823e-03 eta 0:22:52
epoch [5/50] batch [180/288] time 0.111 (0.105) data 0.000 (0.002) loss 1.0686 (1.1527) ce_loss 0.9761 (1.0331) teacher_loss 0.9649 (1.0296) loss_zs_kd 0.1013 (0.1197) loss_oracle 0.0530 (0.0632) acc 71.8750 (72.8646) kd_loss 0.0325 (0.0359) lr 1.9823e-03 eta 0:22:49
epoch [5/50] batch [200/288] time 0.108 (0.105) data 0.000 (0.002) loss 1.0952 (1.1536) ce_loss 0.9966 (1.0357) teacher_loss 0.9876 (1.0324) loss_zs_kd 0.0977 (0.1185) loss_oracle 0.0588 (0.0620) acc 78.1250 (72.8750) kd_loss 0.0283 (0.0352) lr 1.9823e-03 eta 0:22:44
epoch [5/50] batch [220/288] time 0.102 (0.104) data 0.000 (0.002) loss 1.3330 (1.1571) ce_loss 1.2188 (1.0391) teacher_loss 1.2220 (1.0361) loss_zs_kd 0.1153 (0.1183) loss_oracle 0.0534 (0.0618) acc 75.0000 (72.5994) kd_loss 0.0234 (0.0343) lr 1.9823e-03 eta 0:22:41
epoch [5/50] batch [240/288] time 0.112 (0.104) data 0.001 (0.001) loss 0.9595 (1.1570) ce_loss 0.8447 (1.0375) teacher_loss 0.8348 (1.0345) loss_zs_kd 0.0990 (0.1177) loss_oracle 0.0751 (0.0636) acc 81.2500 (72.5781) kd_loss 0.0354 (0.0341) lr 1.9823e-03 eta 0:22:36
epoch [5/50] batch [260/288] time 0.104 (0.104) data 0.000 (0.001) loss 1.2017 (1.1521) ce_loss 1.1191 (1.0324) teacher_loss 1.1192 (1.0292) loss_zs_kd 0.0742 (0.1172) loss_oracle 0.0453 (0.0643) acc 68.7500 (72.6442) kd_loss 0.0272 (0.0343) lr 1.9823e-03 eta 0:22:31
epoch [5/50] batch [280/288] time 0.107 (0.104) data 0.001 (0.001) loss 0.8541 (1.1430) ce_loss 0.7368 (1.0233) teacher_loss 0.7089 (1.0199) loss_zs_kd 0.1345 (0.1166) loss_oracle 0.0780 (0.0647) acc 81.2500 (72.8237) kd_loss 0.0361 (0.0344) lr 1.9823e-03 eta 0:22:25
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,402
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.7%
******* Domain a best val acc:      86.5%, epoch: 4 *******
******* Domain a best val test acc: 83.3%, epoch: 4 *******
******* Domain a best test acc:     83.3%, epoch: 4 *******
epoch [6/50] batch [20/288] time 0.106 (0.128) data 0.000 (0.017) loss 1.2069 (1.0367) ce_loss 1.1084 (0.9239) teacher_loss 1.1094 (0.9178) loss_zs_kd 0.0839 (0.1029) loss_oracle 0.0556 (0.0675) acc 71.8750 (73.4375) kd_loss 0.0308 (0.0354) lr 1.9686e-03 eta 0:27:31
epoch [6/50] batch [40/288] time 0.114 (0.118) data 0.000 (0.009) loss 1.0861 (1.0960) ce_loss 0.9414 (0.9778) teacher_loss 0.9431 (0.9729) loss_zs_kd 0.1193 (0.1077) loss_oracle 0.0834 (0.0692) acc 75.0000 (72.8906) kd_loss 0.0379 (0.0361) lr 1.9686e-03 eta 0:25:19
epoch [6/50] batch [60/288] time 0.109 (0.113) data 0.000 (0.006) loss 1.2155 (1.0885) ce_loss 1.0576 (0.9654) teacher_loss 1.0535 (0.9615) loss_zs_kd 0.1479 (0.1078) loss_oracle 0.0881 (0.0731) acc 65.6250 (73.1771) kd_loss 0.0416 (0.0363) lr 1.9686e-03 eta 0:24:18
epoch [6/50] batch [80/288] time 0.108 (0.110) data 0.000 (0.004) loss 1.1593 (1.1003) ce_loss 1.0254 (0.9723) teacher_loss 1.0071 (0.9686) loss_zs_kd 0.1249 (0.1098) loss_oracle 0.0897 (0.0768) acc 71.8750 (73.1641) kd_loss 0.0408 (0.0373) lr 1.9686e-03 eta 0:23:42
epoch [6/50] batch [100/288] time 0.103 (0.109) data 0.000 (0.004) loss 1.4415 (1.1257) ce_loss 1.2920 (0.9932) teacher_loss 1.2739 (0.9891) loss_zs_kd 0.1316 (0.1088) loss_oracle 0.1018 (0.0822) acc 65.6250 (73.1562) kd_loss 0.0461 (0.0386) lr 1.9686e-03 eta 0:23:23
epoch [6/50] batch [120/288] time 0.102 (0.108) data 0.000 (0.003) loss 1.2856 (1.1217) ce_loss 1.1416 (0.9859) teacher_loss 1.1344 (0.9824) loss_zs_kd 0.1454 (0.1092) loss_oracle 0.0785 (0.0847) acc 71.8750 (73.5417) kd_loss 0.0435 (0.0398) lr 1.9686e-03 eta 0:23:06
epoch [6/50] batch [140/288] time 0.103 (0.107) data 0.000 (0.003) loss 0.8978 (1.1197) ce_loss 0.8013 (0.9854) teacher_loss 0.7982 (0.9818) loss_zs_kd 0.0793 (0.1098) loss_oracle 0.0599 (0.0830) acc 87.5000 (73.5491) kd_loss 0.0488 (0.0405) lr 1.9686e-03 eta 0:22:54
epoch [6/50] batch [160/288] time 0.097 (0.106) data 0.000 (0.002) loss 0.8456 (1.1206) ce_loss 0.7188 (0.9874) teacher_loss 0.7191 (0.9837) loss_zs_kd 0.1327 (0.1139) loss_oracle 0.0601 (0.0799) acc 75.0000 (73.4766) kd_loss 0.0361 (0.0406) lr 1.9686e-03 eta 0:22:41
epoch [6/50] batch [180/288] time 0.091 (0.105) data 0.000 (0.002) loss 0.9072 (1.1224) ce_loss 0.7671 (0.9907) teacher_loss 0.7516 (0.9867) loss_zs_kd 0.1702 (0.1158) loss_oracle 0.0705 (0.0778) acc 81.2500 (73.5069) kd_loss 0.0434 (0.0405) lr 1.9686e-03 eta 0:22:26
epoch [6/50] batch [200/288] time 0.097 (0.105) data 0.000 (0.002) loss 1.1385 (1.1237) ce_loss 1.0332 (0.9944) teacher_loss 1.0189 (0.9905) loss_zs_kd 0.1061 (0.1159) loss_oracle 0.0666 (0.0752) acc 68.7500 (73.3906) kd_loss 0.0522 (0.0401) lr 1.9686e-03 eta 0:22:15
epoch [6/50] batch [220/288] time 0.097 (0.104) data 0.000 (0.002) loss 1.3235 (1.1254) ce_loss 1.1973 (0.9979) teacher_loss 1.1959 (0.9940) loss_zs_kd 0.1423 (0.1163) loss_oracle 0.0564 (0.0732) acc 71.8750 (73.3807) kd_loss 0.0300 (0.0393) lr 1.9686e-03 eta 0:22:02
epoch [6/50] batch [240/288] time 0.102 (0.103) data 0.000 (0.002) loss 1.0849 (1.1296) ce_loss 0.9912 (1.0028) teacher_loss 0.9884 (0.9989) loss_zs_kd 0.0683 (0.1160) loss_oracle 0.0624 (0.0726) acc 75.0000 (73.2161) kd_loss 0.0408 (0.0389) lr 1.9686e-03 eta 0:21:56
epoch [6/50] batch [260/288] time 0.105 (0.103) data 0.000 (0.002) loss 1.3552 (1.1313) ce_loss 1.2539 (1.0059) teacher_loss 1.2462 (1.0020) loss_zs_kd 0.1002 (0.1168) loss_oracle 0.0588 (0.0709) acc 68.7500 (73.1490) kd_loss 0.0338 (0.0382) lr 1.9686e-03 eta 0:21:51
epoch [6/50] batch [280/288] time 0.107 (0.103) data 0.000 (0.001) loss 1.3729 (1.1308) ce_loss 1.2070 (1.0054) teacher_loss 1.2066 (1.0018) loss_zs_kd 0.1694 (0.1171) loss_oracle 0.0816 (0.0704) acc 71.8750 (73.2812) kd_loss 0.0297 (0.0375) lr 1.9686e-03 eta 0:21:48
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,401
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,032
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 80.4%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.5%, epoch: 4 *******
******* Domain a best val test acc: 83.3%, epoch: 4 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [7/50] batch [20/288] time 0.101 (0.123) data 0.000 (0.019) loss 1.3023 (1.1657) ce_loss 1.1934 (1.0450) teacher_loss 1.1835 (1.0427) loss_zs_kd 0.1037 (0.1131) loss_oracle 0.0670 (0.0665) acc 71.8750 (74.2188) kd_loss 0.0266 (0.0279) lr 1.9511e-03 eta 0:26:00
epoch [7/50] batch [40/288] time 0.098 (0.112) data 0.000 (0.010) loss 0.7972 (1.1060) ce_loss 0.6909 (0.9858) teacher_loss 0.6809 (0.9836) loss_zs_kd 0.1163 (0.1168) loss_oracle 0.0582 (0.0641) acc 87.5000 (75.1562) kd_loss 0.0259 (0.0281) lr 1.9511e-03 eta 0:23:33
epoch [7/50] batch [60/288] time 0.112 (0.109) data 0.000 (0.007) loss 1.2940 (1.0846) ce_loss 1.1875 (0.9683) teacher_loss 1.1923 (0.9657) loss_zs_kd 0.1181 (0.1194) loss_oracle 0.0426 (0.0592) acc 68.7500 (74.9479) kd_loss 0.0265 (0.0277) lr 1.9511e-03 eta 0:22:53
epoch [7/50] batch [80/288] time 0.108 (0.108) data 0.000 (0.005) loss 1.0150 (1.0850) ce_loss 0.8994 (0.9693) teacher_loss 0.8888 (0.9668) loss_zs_kd 0.1279 (0.1229) loss_oracle 0.0623 (0.0567) acc 75.0000 (74.8047) kd_loss 0.0375 (0.0278) lr 1.9511e-03 eta 0:22:35
epoch [7/50] batch [100/288] time 0.099 (0.107) data 0.001 (0.004) loss 0.7231 (1.0827) ce_loss 0.6196 (0.9682) teacher_loss 0.6215 (0.9658) loss_zs_kd 0.0907 (0.1227) loss_oracle 0.0562 (0.0555) acc 84.3750 (74.4062) kd_loss 0.0338 (0.0279) lr 1.9511e-03 eta 0:22:20
epoch [7/50] batch [120/288] time 0.108 (0.106) data 0.000 (0.003) loss 1.3853 (1.0788) ce_loss 1.2568 (0.9652) teacher_loss 1.2515 (0.9625) loss_zs_kd 0.1154 (0.1212) loss_oracle 0.0761 (0.0557) acc 75.0000 (74.2708) kd_loss 0.0363 (0.0277) lr 1.9511e-03 eta 0:22:13
epoch [7/50] batch [140/288] time 0.098 (0.105) data 0.000 (0.003) loss 1.1494 (1.0895) ce_loss 1.0615 (0.9765) teacher_loss 1.0592 (0.9734) loss_zs_kd 0.1067 (0.1212) loss_oracle 0.0368 (0.0555) acc 71.8750 (73.8393) kd_loss 0.0204 (0.0275) lr 1.9511e-03 eta 0:22:02
epoch [7/50] batch [160/288] time 0.093 (0.105) data 0.000 (0.003) loss 1.1046 (1.1062) ce_loss 0.9937 (0.9935) teacher_loss 0.9906 (0.9902) loss_zs_kd 0.1181 (0.1208) loss_oracle 0.0549 (0.0556) acc 75.0000 (73.4375) kd_loss 0.0280 (0.0274) lr 1.9511e-03 eta 0:21:53
epoch [7/50] batch [180/288] time 0.100 (0.104) data 0.000 (0.002) loss 1.1728 (1.1111) ce_loss 1.0693 (0.9990) teacher_loss 1.0483 (0.9958) loss_zs_kd 0.1312 (0.1208) loss_oracle 0.0589 (0.0549) acc 78.1250 (73.4549) kd_loss 0.0327 (0.0271) lr 1.9511e-03 eta 0:21:44
epoch [7/50] batch [200/288] time 0.097 (0.104) data 0.000 (0.002) loss 0.8198 (1.1041) ce_loss 0.7036 (0.9919) teacher_loss 0.7089 (0.9888) loss_zs_kd 0.1444 (0.1214) loss_oracle 0.0387 (0.0546) acc 68.7500 (73.5312) kd_loss 0.0129 (0.0267) lr 1.9511e-03 eta 0:21:34
epoch [7/50] batch [220/288] time 0.097 (0.103) data 0.000 (0.002) loss 1.3543 (1.1044) ce_loss 1.2412 (0.9930) teacher_loss 1.2479 (0.9899) loss_zs_kd 0.1229 (0.1212) loss_oracle 0.0450 (0.0540) acc 68.7500 (73.3807) kd_loss 0.0236 (0.0264) lr 1.9511e-03 eta 0:21:24
epoch [7/50] batch [240/288] time 0.096 (0.103) data 0.000 (0.002) loss 1.5563 (1.1107) ce_loss 1.4375 (0.9991) teacher_loss 1.4288 (0.9961) loss_zs_kd 0.1142 (0.1212) loss_oracle 0.0705 (0.0540) acc 59.3750 (73.2943) kd_loss 0.0286 (0.0263) lr 1.9511e-03 eta 0:21:15
epoch [7/50] batch [260/288] time 0.092 (0.102) data 0.000 (0.002) loss 1.0881 (1.1133) ce_loss 0.9434 (1.0012) teacher_loss 0.9385 (0.9984) loss_zs_kd 0.1067 (0.1203) loss_oracle 0.0962 (0.0548) acc 75.0000 (73.1971) kd_loss 0.0409 (0.0263) lr 1.9511e-03 eta 0:21:07
epoch [7/50] batch [280/288] time 0.087 (0.101) data 0.000 (0.002) loss 0.7984 (1.1086) ce_loss 0.7085 (0.9966) teacher_loss 0.7156 (0.9939) loss_zs_kd 0.0949 (0.1193) loss_oracle 0.0353 (0.0550) acc 78.1250 (73.4152) kd_loss 0.0169 (0.0264) lr 1.9511e-03 eta 0:20:57
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,405
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,029
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.3%
******* Domain a best val acc:      86.5%, epoch: 4 *******
******* Domain a best val test acc: 83.3%, epoch: 4 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [8/50] batch [20/288] time 0.120 (0.140) data 0.000 (0.019) loss 1.0357 (1.0936) ce_loss 0.8911 (0.9885) teacher_loss 0.8737 (0.9829) loss_zs_kd 0.1901 (0.1226) loss_oracle 0.0669 (0.0493) acc 84.3750 (74.0625) kd_loss 0.0455 (0.0288) lr 1.9298e-03 eta 0:28:48
epoch [8/50] batch [40/288] time 0.114 (0.129) data 0.000 (0.010) loss 0.9836 (1.0831) ce_loss 0.8594 (0.9764) teacher_loss 0.8573 (0.9725) loss_zs_kd 0.1494 (0.1187) loss_oracle 0.0516 (0.0513) acc 78.1250 (73.4375) kd_loss 0.0241 (0.0273) lr 1.9298e-03 eta 0:26:36
epoch [8/50] batch [60/288] time 0.104 (0.123) data 0.002 (0.007) loss 1.6255 (1.0664) ce_loss 1.5635 (0.9577) teacher_loss 1.5499 (0.9544) loss_zs_kd 0.0752 (0.1198) loss_oracle 0.0380 (0.0520) acc 59.3750 (74.0104) kd_loss 0.0228 (0.0276) lr 1.9298e-03 eta 0:25:14
epoch [8/50] batch [80/288] time 0.122 (0.124) data 0.000 (0.005) loss 1.1936 (1.0597) ce_loss 1.0996 (0.9513) teacher_loss 1.0887 (0.9476) loss_zs_kd 0.0961 (0.1213) loss_oracle 0.0569 (0.0514) acc 68.7500 (74.2578) kd_loss 0.0285 (0.0276) lr 1.9298e-03 eta 0:25:28
epoch [8/50] batch [100/288] time 0.135 (0.125) data 0.000 (0.004) loss 0.9047 (1.0670) ce_loss 0.7617 (0.9586) teacher_loss 0.7570 (0.9554) loss_zs_kd 0.1838 (0.1236) loss_oracle 0.0559 (0.0499) acc 84.3750 (74.2812) kd_loss 0.0323 (0.0268) lr 1.9298e-03 eta 0:25:36
epoch [8/50] batch [120/288] time 0.100 (0.124) data 0.000 (0.003) loss 1.0215 (1.0580) ce_loss 0.9092 (0.9496) teacher_loss 0.9141 (0.9470) loss_zs_kd 0.1404 (0.1260) loss_oracle 0.0372 (0.0481) acc 75.0000 (74.4531) kd_loss 0.0196 (0.0264) lr 1.9298e-03 eta 0:25:19
epoch [8/50] batch [140/288] time 0.101 (0.121) data 0.000 (0.003) loss 1.0796 (1.0695) ce_loss 0.9272 (0.9611) teacher_loss 0.9306 (0.9589) loss_zs_kd 0.1815 (0.1264) loss_oracle 0.0582 (0.0474) acc 68.7500 (74.1071) kd_loss 0.0334 (0.0261) lr 1.9298e-03 eta 0:24:39
epoch [8/50] batch [160/288] time 0.101 (0.119) data 0.000 (0.003) loss 1.2639 (1.0867) ce_loss 1.1504 (0.9789) teacher_loss 1.1494 (0.9765) loss_zs_kd 0.1274 (0.1251) loss_oracle 0.0508 (0.0476) acc 65.6250 (73.6914) kd_loss 0.0246 (0.0260) lr 1.9298e-03 eta 0:24:12
epoch [8/50] batch [180/288] time 0.096 (0.117) data 0.000 (0.002) loss 1.5074 (1.0870) ce_loss 1.3965 (0.9798) teacher_loss 1.3977 (0.9776) loss_zs_kd 0.0978 (0.1233) loss_oracle 0.0608 (0.0477) acc 68.7500 (73.6285) kd_loss 0.0229 (0.0259) lr 1.9298e-03 eta 0:23:47
epoch [8/50] batch [200/288] time 0.133 (0.116) data 0.000 (0.002) loss 1.3610 (1.0900) ce_loss 1.2617 (0.9826) teacher_loss 1.2567 (0.9802) loss_zs_kd 0.1149 (0.1234) loss_oracle 0.0469 (0.0481) acc 65.6250 (73.4844) kd_loss 0.0263 (0.0258) lr 1.9298e-03 eta 0:23:39
epoch [8/50] batch [220/288] time 0.100 (0.115) data 0.000 (0.002) loss 0.8236 (1.0859) ce_loss 0.7188 (0.9782) teacher_loss 0.7188 (0.9759) loss_zs_kd 0.1011 (0.1233) loss_oracle 0.0542 (0.0483) acc 84.3750 (73.6222) kd_loss 0.0223 (0.0255) lr 1.9298e-03 eta 0:23:24
epoch [8/50] batch [240/288] time 0.103 (0.115) data 0.000 (0.002) loss 1.0649 (1.0899) ce_loss 0.9307 (0.9816) teacher_loss 0.9203 (0.9793) loss_zs_kd 0.1628 (0.1239) loss_oracle 0.0632 (0.0487) acc 75.0000 (73.4635) kd_loss 0.0308 (0.0253) lr 1.9298e-03 eta 0:23:10
epoch [8/50] batch [260/288] time 0.093 (0.114) data 0.001 (0.002) loss 1.0697 (1.0901) ce_loss 0.9204 (0.9820) teacher_loss 0.9247 (0.9797) loss_zs_kd 0.1652 (0.1232) loss_oracle 0.0624 (0.0487) acc 78.1250 (73.5697) kd_loss 0.0278 (0.0251) lr 1.9298e-03 eta 0:22:58
epoch [8/50] batch [280/288] time 0.102 (0.113) data 0.000 (0.002) loss 1.5732 (1.0966) ce_loss 1.4609 (0.9887) teacher_loss 1.4493 (0.9863) loss_zs_kd 0.1289 (0.1227) loss_oracle 0.0594 (0.0490) acc 59.3750 (73.4263) kd_loss 0.0265 (0.0251) lr 1.9298e-03 eta 0:22:42
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,411
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 86.0%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,029
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.2%
******* Domain a best val acc:      86.6%, epoch: 8 *******
******* Domain a best val test acc: 83.6%, epoch: 8 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [9/50] batch [20/288] time 0.108 (0.127) data 0.000 (0.018) loss 1.1710 (1.1149) ce_loss 1.0693 (1.0087) teacher_loss 1.0655 (1.0086) loss_zs_kd 0.1110 (0.1173) loss_oracle 0.0500 (0.0476) acc 71.8750 (72.3438) kd_loss 0.0267 (0.0242) lr 1.9048e-03 eta 0:25:38
epoch [9/50] batch [40/288] time 0.105 (0.118) data 0.001 (0.009) loss 0.7032 (1.0588) ce_loss 0.6333 (0.9537) teacher_loss 0.6201 (0.9517) loss_zs_kd 0.0666 (0.1174) loss_oracle 0.0498 (0.0483) acc 81.2500 (74.2969) kd_loss 0.0217 (0.0238) lr 1.9048e-03 eta 0:23:38
epoch [9/50] batch [60/288] time 0.099 (0.112) data 0.001 (0.006) loss 1.2054 (1.0653) ce_loss 1.1055 (0.9584) teacher_loss 1.1107 (0.9571) loss_zs_kd 0.1118 (0.1188) loss_oracle 0.0388 (0.0488) acc 65.6250 (74.1667) kd_loss 0.0231 (0.0236) lr 1.9048e-03 eta 0:22:33
epoch [9/50] batch [80/288] time 0.102 (0.111) data 0.000 (0.005) loss 0.9135 (1.0956) ce_loss 0.7930 (0.9849) teacher_loss 0.7981 (0.9842) loss_zs_kd 0.1220 (0.1244) loss_oracle 0.0544 (0.0492) acc 87.5000 (73.7109) kd_loss 0.0241 (0.0235) lr 1.9048e-03 eta 0:22:09
epoch [9/50] batch [100/288] time 0.096 (0.109) data 0.000 (0.004) loss 0.8473 (1.0975) ce_loss 0.7451 (0.9872) teacher_loss 0.7454 (0.9863) loss_zs_kd 0.1251 (0.1231) loss_oracle 0.0394 (0.0497) acc 71.8750 (73.8438) kd_loss 0.0234 (0.0237) lr 1.9048e-03 eta 0:21:45
epoch [9/50] batch [120/288] time 0.109 (0.108) data 0.000 (0.003) loss 1.1520 (1.1099) ce_loss 1.0391 (0.9994) teacher_loss 1.0421 (0.9983) loss_zs_kd 0.1132 (0.1237) loss_oracle 0.0533 (0.0497) acc 68.7500 (73.3333) kd_loss 0.0252 (0.0237) lr 1.9048e-03 eta 0:21:31
epoch [9/50] batch [140/288] time 0.098 (0.107) data 0.000 (0.003) loss 1.0060 (1.1149) ce_loss 0.9478 (1.0054) teacher_loss 0.9480 (1.0044) loss_zs_kd 0.0697 (0.1247) loss_oracle 0.0231 (0.0481) acc 71.8750 (73.5268) kd_loss 0.0173 (0.0237) lr 1.9048e-03 eta 0:21:20
epoch [9/50] batch [160/288] time 0.103 (0.107) data 0.000 (0.002) loss 0.8829 (1.1093) ce_loss 0.7632 (0.9986) teacher_loss 0.7673 (0.9974) loss_zs_kd 0.1420 (0.1282) loss_oracle 0.0446 (0.0478) acc 81.2500 (73.5156) kd_loss 0.0190 (0.0241) lr 1.9048e-03 eta 0:21:11
epoch [9/50] batch [180/288] time 0.097 (0.106) data 0.000 (0.002) loss 1.7456 (1.1106) ce_loss 1.6494 (1.0010) teacher_loss 1.6295 (0.9995) loss_zs_kd 0.1445 (0.1267) loss_oracle 0.0439 (0.0477) acc 68.7500 (73.5069) kd_loss 0.0304 (0.0242) lr 1.9048e-03 eta 0:21:02
epoch [9/50] batch [200/288] time 0.103 (0.105) data 0.000 (0.002) loss 1.3377 (1.1184) ce_loss 1.2393 (1.0093) teacher_loss 1.2266 (1.0076) loss_zs_kd 0.1198 (0.1265) loss_oracle 0.0513 (0.0476) acc 68.7500 (73.2344) kd_loss 0.0205 (0.0246) lr 1.9048e-03 eta 0:20:54
epoch [9/50] batch [220/288] time 0.103 (0.105) data 0.000 (0.002) loss 0.8172 (1.1188) ce_loss 0.6582 (1.0093) teacher_loss 0.6625 (1.0074) loss_zs_kd 0.1644 (0.1259) loss_oracle 0.0726 (0.0484) acc 81.2500 (73.1960) kd_loss 0.0289 (0.0248) lr 1.9048e-03 eta 0:20:49
epoch [9/50] batch [240/288] time 0.111 (0.105) data 0.001 (0.002) loss 1.2334 (1.1176) ce_loss 1.0830 (1.0074) teacher_loss 1.0796 (1.0054) loss_zs_kd 0.1814 (0.1251) loss_oracle 0.0632 (0.0496) acc 71.8750 (73.2161) kd_loss 0.0251 (0.0248) lr 1.9048e-03 eta 0:20:45
epoch [9/50] batch [260/288] time 0.107 (0.105) data 0.000 (0.002) loss 0.9937 (1.1211) ce_loss 0.8867 (1.0106) teacher_loss 0.8891 (1.0084) loss_zs_kd 0.0945 (0.1247) loss_oracle 0.0573 (0.0503) acc 71.8750 (73.0529) kd_loss 0.0246 (0.0249) lr 1.9048e-03 eta 0:20:41
epoch [9/50] batch [280/288] time 0.108 (0.105) data 0.000 (0.002) loss 0.9809 (1.1149) ce_loss 0.9155 (1.0040) teacher_loss 0.9103 (1.0014) loss_zs_kd 0.0694 (0.1248) loss_oracle 0.0359 (0.0511) acc 75.0000 (73.1027) kd_loss 0.0236 (0.0254) lr 1.9048e-03 eta 0:20:39
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,414
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 86.1%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.8%
******* Domain a best val acc:      86.7%, epoch: 9 *******
******* Domain a best val test acc: 83.2%, epoch: 9 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [10/50] batch [20/288] time 0.093 (0.118) data 0.000 (0.014) loss 0.8534 (1.1301) ce_loss 0.7705 (1.0187) teacher_loss 0.7727 (1.0166) loss_zs_kd 0.0739 (0.1196) loss_oracle 0.0438 (0.0537) acc 78.1250 (74.2188) kd_loss 0.0219 (0.0280) lr 1.8763e-03 eta 0:23:05
epoch [10/50] batch [40/288] time 0.112 (0.108) data 0.000 (0.007) loss 1.3098 (1.0867) ce_loss 1.1641 (0.9729) teacher_loss 1.1645 (0.9690) loss_zs_kd 0.1654 (0.1246) loss_oracle 0.0626 (0.0554) acc 68.7500 (75.7812) kd_loss 0.0356 (0.0294) lr 1.8763e-03 eta 0:21:16
epoch [10/50] batch [60/288] time 0.110 (0.107) data 0.000 (0.005) loss 0.9535 (1.0537) ce_loss 0.8574 (0.9427) teacher_loss 0.8596 (0.9385) loss_zs_kd 0.0957 (0.1230) loss_oracle 0.0460 (0.0536) acc 81.2500 (75.8854) kd_loss 0.0226 (0.0297) lr 1.8763e-03 eta 0:20:53
epoch [10/50] batch [80/288] time 0.112 (0.106) data 0.000 (0.004) loss 1.2240 (1.0816) ce_loss 1.1211 (0.9684) teacher_loss 1.1205 (0.9636) loss_zs_kd 0.1063 (0.1257) loss_oracle 0.0503 (0.0551) acc 78.1250 (74.8828) kd_loss 0.0218 (0.0296) lr 1.8763e-03 eta 0:20:42
epoch [10/50] batch [100/288] time 0.103 (0.104) data 0.000 (0.003) loss 1.3828 (1.0687) ce_loss 1.2734 (0.9574) teacher_loss 1.2719 (0.9535) loss_zs_kd 0.1253 (0.1236) loss_oracle 0.0481 (0.0534) acc 71.8750 (75.0312) kd_loss 0.0315 (0.0290) lr 1.8763e-03 eta 0:20:19
epoch [10/50] batch [120/288] time 0.098 (0.103) data 0.000 (0.003) loss 0.9664 (1.0672) ce_loss 0.8594 (0.9554) teacher_loss 0.8600 (0.9519) loss_zs_kd 0.1192 (0.1233) loss_oracle 0.0468 (0.0537) acc 81.2500 (75.1042) kd_loss 0.0227 (0.0288) lr 1.8763e-03 eta 0:20:05
epoch [10/50] batch [140/288] time 0.098 (0.102) data 0.000 (0.002) loss 1.3927 (1.0853) ce_loss 1.2676 (0.9727) teacher_loss 1.2643 (0.9692) loss_zs_kd 0.1174 (0.1245) loss_oracle 0.0696 (0.0538) acc 68.7500 (74.7098) kd_loss 0.0342 (0.0286) lr 1.8763e-03 eta 0:19:54
epoch [10/50] batch [160/288] time 0.096 (0.102) data 0.000 (0.002) loss 0.7881 (1.0859) ce_loss 0.6748 (0.9718) teacher_loss 0.6745 (0.9686) loss_zs_kd 0.0898 (0.1235) loss_oracle 0.0687 (0.0556) acc 84.3750 (74.6289) kd_loss 0.0345 (0.0290) lr 1.8763e-03 eta 0:19:43
epoch [10/50] batch [180/288] time 0.100 (0.101) data 0.000 (0.002) loss 1.1789 (1.0974) ce_loss 1.0859 (0.9823) teacher_loss 1.0874 (0.9793) loss_zs_kd 0.0957 (0.1236) loss_oracle 0.0436 (0.0564) acc 75.0000 (74.2882) kd_loss 0.0319 (0.0290) lr 1.8763e-03 eta 0:19:35
epoch [10/50] batch [200/288] time 0.092 (0.100) data 0.000 (0.002) loss 1.3870 (1.1035) ce_loss 1.2959 (0.9892) teacher_loss 1.2889 (0.9861) loss_zs_kd 0.0992 (0.1228) loss_oracle 0.0485 (0.0560) acc 65.6250 (74.1562) kd_loss 0.0298 (0.0290) lr 1.8763e-03 eta 0:19:26
epoch [10/50] batch [220/288] time 0.096 (0.100) data 0.000 (0.001) loss 1.1748 (1.1034) ce_loss 1.0703 (0.9903) teacher_loss 1.0610 (0.9873) loss_zs_kd 0.1381 (0.1224) loss_oracle 0.0448 (0.0549) acc 68.7500 (74.1761) kd_loss 0.0273 (0.0287) lr 1.8763e-03 eta 0:19:17
epoch [10/50] batch [240/288] time 0.109 (0.100) data 0.000 (0.001) loss 1.0211 (1.1053) ce_loss 0.8921 (0.9930) teacher_loss 0.8937 (0.9899) loss_zs_kd 0.1521 (0.1229) loss_oracle 0.0514 (0.0539) acc 78.1250 (74.0495) kd_loss 0.0222 (0.0286) lr 1.8763e-03 eta 0:19:12
epoch [10/50] batch [260/288] time 0.092 (0.099) data 0.000 (0.001) loss 1.2000 (1.1051) ce_loss 1.0723 (0.9927) teacher_loss 1.0751 (0.9895) loss_zs_kd 0.1253 (0.1241) loss_oracle 0.0622 (0.0535) acc 75.0000 (73.9183) kd_loss 0.0329 (0.0286) lr 1.8763e-03 eta 0:19:08
epoch [10/50] batch [280/288] time 0.087 (0.099) data 0.000 (0.001) loss 1.6016 (1.1139) ce_loss 1.4307 (1.0011) teacher_loss 1.4437 (0.9981) loss_zs_kd 0.1972 (0.1254) loss_oracle 0.0594 (0.0531) acc 65.6250 (73.6830) kd_loss 0.0309 (0.0286) lr 1.8763e-03 eta 0:19:00
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,423
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.2%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,019
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.8%
******* Domain a best val acc:      86.9%, epoch: 10 *******
******* Domain a best val test acc: 83.2%, epoch: 10 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [11/50] batch [20/288] time 0.117 (0.122) data 0.000 (0.014) loss 1.6220 (1.1305) ce_loss 1.5176 (1.0150) teacher_loss 1.5168 (1.0157) loss_zs_kd 0.1085 (0.1313) loss_oracle 0.0510 (0.0491) acc 62.5000 (72.8125) kd_loss 0.0262 (0.0289) lr 1.8443e-03 eta 0:23:27
epoch [11/50] batch [40/288] time 0.099 (0.112) data 0.000 (0.007) loss 1.2557 (1.1282) ce_loss 1.1367 (1.0120) teacher_loss 1.1402 (1.0106) loss_zs_kd 0.1556 (0.1315) loss_oracle 0.0377 (0.0519) acc 71.8750 (72.3438) kd_loss 0.0250 (0.0322) lr 1.8443e-03 eta 0:21:30
epoch [11/50] batch [60/288] time 0.100 (0.109) data 0.000 (0.005) loss 0.9205 (1.1222) ce_loss 0.8066 (1.0086) teacher_loss 0.8094 (1.0070) loss_zs_kd 0.1418 (0.1290) loss_oracle 0.0402 (0.0507) acc 78.1250 (72.8125) kd_loss 0.0263 (0.0318) lr 1.8443e-03 eta 0:20:49
epoch [11/50] batch [80/288] time 0.112 (0.109) data 0.000 (0.004) loss 1.1657 (1.0973) ce_loss 1.0859 (0.9867) teacher_loss 1.0930 (0.9839) loss_zs_kd 0.0906 (0.1273) loss_oracle 0.0274 (0.0498) acc 65.6250 (73.4375) kd_loss 0.0278 (0.0326) lr 1.8443e-03 eta 0:20:51
epoch [11/50] batch [100/288] time 0.100 (0.108) data 0.000 (0.003) loss 1.3196 (1.0824) ce_loss 1.1924 (0.9723) teacher_loss 1.1797 (0.9693) loss_zs_kd 0.1498 (0.1270) loss_oracle 0.0650 (0.0496) acc 68.7500 (73.7500) kd_loss 0.0453 (0.0327) lr 1.8443e-03 eta 0:20:35
epoch [11/50] batch [120/288] time 0.116 (0.108) data 0.000 (0.003) loss 1.6321 (1.0847) ce_loss 1.5283 (0.9743) teacher_loss 1.5284 (0.9718) loss_zs_kd 0.1074 (0.1273) loss_oracle 0.0501 (0.0493) acc 53.1250 (73.6198) kd_loss 0.0302 (0.0320) lr 1.8443e-03 eta 0:20:27
epoch [11/50] batch [140/288] time 0.099 (0.107) data 0.000 (0.002) loss 0.9329 (1.0869) ce_loss 0.8433 (0.9762) teacher_loss 0.8387 (0.9736) loss_zs_kd 0.0834 (0.1262) loss_oracle 0.0525 (0.0502) acc 81.2500 (73.5045) kd_loss 0.0293 (0.0316) lr 1.8443e-03 eta 0:20:16
epoch [11/50] batch [160/288] time 0.101 (0.106) data 0.000 (0.002) loss 1.3400 (1.1001) ce_loss 1.2324 (0.9902) teacher_loss 1.2334 (0.9873) loss_zs_kd 0.1132 (0.1255) loss_oracle 0.0499 (0.0501) acc 65.6250 (73.0859) kd_loss 0.0331 (0.0313) lr 1.8443e-03 eta 0:20:09
epoch [11/50] batch [180/288] time 0.100 (0.106) data 0.000 (0.002) loss 1.1530 (1.0954) ce_loss 1.0352 (0.9859) teacher_loss 1.0381 (0.9830) loss_zs_kd 0.1377 (0.1259) loss_oracle 0.0461 (0.0495) acc 78.1250 (73.1597) kd_loss 0.0243 (0.0311) lr 1.8443e-03 eta 0:20:05
epoch [11/50] batch [200/288] time 0.106 (0.106) data 0.000 (0.002) loss 1.2278 (1.0916) ce_loss 1.0830 (0.9825) teacher_loss 1.0838 (0.9800) loss_zs_kd 0.1903 (0.1255) loss_oracle 0.0488 (0.0488) acc 78.1250 (73.2344) kd_loss 0.0297 (0.0307) lr 1.8443e-03 eta 0:19:54
epoch [11/50] batch [220/288] time 0.101 (0.105) data 0.000 (0.001) loss 1.0706 (1.0917) ce_loss 0.9590 (0.9815) teacher_loss 0.9463 (0.9790) loss_zs_kd 0.1425 (0.1279) loss_oracle 0.0530 (0.0487) acc 81.2500 (73.3239) kd_loss 0.0334 (0.0306) lr 1.8443e-03 eta 0:19:48
epoch [11/50] batch [240/288] time 0.092 (0.105) data 0.000 (0.001) loss 1.0988 (1.0890) ce_loss 1.0068 (0.9790) teacher_loss 1.0071 (0.9766) loss_zs_kd 0.1004 (0.1279) loss_oracle 0.0415 (0.0484) acc 71.8750 (73.4635) kd_loss 0.0237 (0.0302) lr 1.8443e-03 eta 0:19:41
epoch [11/50] batch [260/288] time 0.102 (0.105) data 0.000 (0.001) loss 1.0295 (1.0902) ce_loss 0.9517 (0.9806) teacher_loss 0.9285 (0.9779) loss_zs_kd 0.0993 (0.1275) loss_oracle 0.0514 (0.0485) acc 75.0000 (73.3534) kd_loss 0.0300 (0.0300) lr 1.8443e-03 eta 0:19:38
epoch [11/50] batch [280/288] time 0.108 (0.105) data 0.000 (0.001) loss 0.8291 (1.0833) ce_loss 0.7549 (0.9737) teacher_loss 0.7451 (0.9711) loss_zs_kd 0.0915 (0.1270) loss_oracle 0.0383 (0.0487) acc 81.2500 (73.5938) kd_loss 0.0296 (0.0299) lr 1.8443e-03 eta 0:19:36
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,421
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.2%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,025
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.1%
******* Domain a best val acc:      86.9%, epoch: 10 *******
******* Domain a best val test acc: 83.2%, epoch: 10 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [12/50] batch [20/288] time 0.114 (0.138) data 0.000 (0.018) loss 1.0786 (1.1016) ce_loss 0.9785 (0.9933) teacher_loss 0.9778 (0.9887) loss_zs_kd 0.0852 (0.1348) loss_oracle 0.0582 (0.0456) acc 81.2500 (73.5938) kd_loss 0.0381 (0.0274) lr 1.8090e-03 eta 0:25:46
epoch [12/50] batch [40/288] time 0.109 (0.127) data 0.000 (0.009) loss 1.1234 (1.0784) ce_loss 1.0342 (0.9687) teacher_loss 1.0429 (0.9654) loss_zs_kd 0.0801 (0.1315) loss_oracle 0.0405 (0.0472) acc 75.0000 (73.6719) kd_loss 0.0162 (0.0267) lr 1.8090e-03 eta 0:23:35
epoch [12/50] batch [60/288] time 0.099 (0.119) data 0.001 (0.006) loss 1.3276 (1.1013) ce_loss 1.2256 (0.9915) teacher_loss 1.2211 (0.9892) loss_zs_kd 0.1263 (0.1307) loss_oracle 0.0433 (0.0468) acc 68.7500 (73.3854) kd_loss 0.0320 (0.0263) lr 1.8090e-03 eta 0:22:10
epoch [12/50] batch [80/288] time 0.102 (0.116) data 0.000 (0.005) loss 2.0883 (1.1078) ce_loss 1.9844 (0.9985) teacher_loss 1.9716 (0.9957) loss_zs_kd 0.1535 (0.1324) loss_oracle 0.0399 (0.0458) acc 56.2500 (73.6328) kd_loss 0.0272 (0.0266) lr 1.8090e-03 eta 0:21:31
epoch [12/50] batch [100/288] time 0.102 (0.113) data 0.000 (0.004) loss 1.1741 (1.0871) ce_loss 1.0742 (0.9804) teacher_loss 1.0651 (0.9780) loss_zs_kd 0.1256 (0.1294) loss_oracle 0.0462 (0.0444) acc 59.3750 (73.7812) kd_loss 0.0382 (0.0269) lr 1.8090e-03 eta 0:21:02
epoch [12/50] batch [120/288] time 0.102 (0.112) data 0.000 (0.003) loss 1.2615 (1.0791) ce_loss 1.1455 (0.9729) teacher_loss 1.1421 (0.9703) loss_zs_kd 0.1361 (0.1292) loss_oracle 0.0514 (0.0443) acc 68.7500 (74.1667) kd_loss 0.0254 (0.0270) lr 1.8090e-03 eta 0:20:39
epoch [12/50] batch [140/288] time 0.104 (0.111) data 0.001 (0.003) loss 0.5908 (1.0850) ce_loss 0.4824 (0.9773) teacher_loss 0.4823 (0.9746) loss_zs_kd 0.1110 (0.1313) loss_oracle 0.0530 (0.0447) acc 90.6250 (74.1964) kd_loss 0.0285 (0.0273) lr 1.8090e-03 eta 0:20:26
epoch [12/50] batch [160/288] time 0.102 (0.109) data 0.000 (0.002) loss 1.1091 (1.0847) ce_loss 0.9668 (0.9756) teacher_loss 0.9674 (0.9730) loss_zs_kd 0.1779 (0.1325) loss_oracle 0.0528 (0.0455) acc 71.8750 (74.0430) kd_loss 0.0357 (0.0273) lr 1.8090e-03 eta 0:20:11
epoch [12/50] batch [180/288] time 0.105 (0.109) data 0.000 (0.002) loss 0.9648 (1.0993) ce_loss 0.8354 (0.9898) teacher_loss 0.8457 (0.9875) loss_zs_kd 0.1653 (0.1330) loss_oracle 0.0364 (0.0453) acc 81.2500 (73.5938) kd_loss 0.0163 (0.0272) lr 1.8090e-03 eta 0:20:05
epoch [12/50] batch [200/288] time 0.101 (0.108) data 0.000 (0.002) loss 1.2546 (1.1014) ce_loss 1.1514 (0.9922) teacher_loss 1.1483 (0.9898) loss_zs_kd 0.1264 (0.1321) loss_oracle 0.0431 (0.0456) acc 71.8750 (73.7188) kd_loss 0.0307 (0.0274) lr 1.8090e-03 eta 0:19:55
epoch [12/50] batch [220/288] time 0.101 (0.108) data 0.000 (0.002) loss 0.8500 (1.0984) ce_loss 0.7148 (0.9887) teacher_loss 0.7201 (0.9866) loss_zs_kd 0.1879 (0.1328) loss_oracle 0.0360 (0.0454) acc 75.0000 (73.8068) kd_loss 0.0201 (0.0275) lr 1.8090e-03 eta 0:19:49
epoch [12/50] batch [240/288] time 0.104 (0.108) data 0.000 (0.002) loss 1.4979 (1.1019) ce_loss 1.3789 (0.9923) teacher_loss 1.3692 (0.9904) loss_zs_kd 0.1535 (0.1326) loss_oracle 0.0519 (0.0452) acc 59.3750 (73.7760) kd_loss 0.0279 (0.0277) lr 1.8090e-03 eta 0:19:41
epoch [12/50] batch [260/288] time 0.103 (0.107) data 0.000 (0.002) loss 0.9324 (1.0980) ce_loss 0.7993 (0.9889) teacher_loss 0.7946 (0.9869) loss_zs_kd 0.1525 (0.1317) loss_oracle 0.0615 (0.0453) acc 84.3750 (73.8221) kd_loss 0.0409 (0.0279) lr 1.8090e-03 eta 0:19:35
epoch [12/50] batch [280/288] time 0.108 (0.107) data 0.000 (0.002) loss 0.9819 (1.0966) ce_loss 0.8994 (0.9876) teacher_loss 0.8950 (0.9855) loss_zs_kd 0.0931 (0.1312) loss_oracle 0.0403 (0.0455) acc 78.1250 (73.8839) kd_loss 0.0366 (0.0282) lr 1.8090e-03 eta 0:19:33
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,408
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 86.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 79.8%
******* Domain a best val acc:      86.9%, epoch: 10 *******
******* Domain a best val test acc: 83.2%, epoch: 10 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [13/50] batch [20/288] time 0.100 (0.120) data 0.000 (0.017) loss 0.9036 (1.0577) ce_loss 0.7695 (0.9447) teacher_loss 0.7767 (0.9425) loss_zs_kd 0.1605 (0.1374) loss_oracle 0.0467 (0.0465) acc 78.1250 (73.9062) kd_loss 0.0363 (0.0345) lr 1.7705e-03 eta 0:21:48
epoch [13/50] batch [40/288] time 0.102 (0.109) data 0.000 (0.009) loss 0.8817 (1.1288) ce_loss 0.7324 (1.0127) teacher_loss 0.7371 (1.0130) loss_zs_kd 0.1600 (0.1380) loss_oracle 0.0647 (0.0467) acc 81.2500 (72.6562) kd_loss 0.0347 (0.0319) lr 1.7705e-03 eta 0:19:45
epoch [13/50] batch [60/288] time 0.107 (0.107) data 0.000 (0.006) loss 1.7119 (1.1799) ce_loss 1.5820 (1.0632) teacher_loss 1.5690 (1.0629) loss_zs_kd 0.1593 (0.1356) loss_oracle 0.0632 (0.0493) acc 56.2500 (71.2500) kd_loss 0.0401 (0.0341) lr 1.7705e-03 eta 0:19:19
epoch [13/50] batch [80/288] time 0.098 (0.106) data 0.000 (0.004) loss 1.4510 (1.1563) ce_loss 1.2988 (1.0394) teacher_loss 1.2946 (1.0379) loss_zs_kd 0.1955 (0.1376) loss_oracle 0.0587 (0.0496) acc 68.7500 (71.9922) kd_loss 0.0305 (0.0342) lr 1.7705e-03 eta 0:19:06
epoch [13/50] batch [100/288] time 0.106 (0.105) data 0.000 (0.004) loss 0.7327 (1.1231) ce_loss 0.6562 (1.0063) teacher_loss 0.6630 (1.0053) loss_zs_kd 0.0628 (0.1355) loss_oracle 0.0383 (0.0500) acc 84.3750 (73.0625) kd_loss 0.0206 (0.0334) lr 1.7705e-03 eta 0:18:55
epoch [13/50] batch [120/288] time 0.103 (0.105) data 0.000 (0.003) loss 1.1080 (1.1156) ce_loss 0.9956 (0.9995) teacher_loss 0.9936 (0.9984) loss_zs_kd 0.1206 (0.1347) loss_oracle 0.0541 (0.0498) acc 75.0000 (73.5938) kd_loss 0.0346 (0.0334) lr 1.7705e-03 eta 0:19:00
epoch [13/50] batch [140/288] time 0.109 (0.106) data 0.000 (0.003) loss 1.0713 (1.1243) ce_loss 0.9556 (1.0092) teacher_loss 0.9588 (1.0081) loss_zs_kd 0.1185 (0.1335) loss_oracle 0.0532 (0.0495) acc 78.1250 (73.3259) kd_loss 0.0362 (0.0331) lr 1.7705e-03 eta 0:19:03
epoch [13/50] batch [160/288] time 0.109 (0.106) data 0.000 (0.002) loss 1.2571 (1.1103) ce_loss 1.1553 (0.9956) teacher_loss 1.1579 (0.9946) loss_zs_kd 0.1121 (0.1326) loss_oracle 0.0432 (0.0493) acc 75.0000 (73.6523) kd_loss 0.0312 (0.0330) lr 1.7705e-03 eta 0:19:05
epoch [13/50] batch [180/288] time 0.106 (0.106) data 0.001 (0.002) loss 0.7301 (1.1188) ce_loss 0.6396 (1.0033) teacher_loss 0.6412 (1.0028) loss_zs_kd 0.0912 (0.1333) loss_oracle 0.0434 (0.0494) acc 81.2500 (73.4201) kd_loss 0.0283 (0.0326) lr 1.7705e-03 eta 0:19:03
epoch [13/50] batch [200/288] time 0.115 (0.107) data 0.001 (0.002) loss 1.4974 (1.1167) ce_loss 1.4102 (1.0006) teacher_loss 1.3994 (1.0001) loss_zs_kd 0.1054 (0.1340) loss_oracle 0.0453 (0.0496) acc 62.5000 (73.4062) kd_loss 0.0321 (0.0324) lr 1.7705e-03 eta 0:19:05
epoch [13/50] batch [220/288] time 0.108 (0.107) data 0.001 (0.002) loss 0.9204 (1.1103) ce_loss 0.7881 (0.9948) teacher_loss 0.7814 (0.9939) loss_zs_kd 0.1650 (0.1344) loss_oracle 0.0565 (0.0492) acc 81.2500 (73.5227) kd_loss 0.0349 (0.0322) lr 1.7705e-03 eta 0:19:12
epoch [13/50] batch [240/288] time 0.121 (0.108) data 0.000 (0.002) loss 1.3095 (1.1057) ce_loss 1.1982 (0.9916) teacher_loss 1.2041 (0.9905) loss_zs_kd 0.1342 (0.1328) loss_oracle 0.0383 (0.0488) acc 71.8750 (73.6458) kd_loss 0.0200 (0.0317) lr 1.7705e-03 eta 0:19:15
epoch [13/50] batch [260/288] time 0.139 (0.109) data 0.000 (0.002) loss 1.1359 (1.0934) ce_loss 1.0391 (0.9803) teacher_loss 1.0336 (0.9792) loss_zs_kd 0.1217 (0.1312) loss_oracle 0.0415 (0.0486) acc 75.0000 (73.9784) kd_loss 0.0274 (0.0313) lr 1.7705e-03 eta 0:19:19
epoch [13/50] batch [280/288] time 0.108 (0.109) data 0.001 (0.001) loss 0.7817 (1.0938) ce_loss 0.7109 (0.9816) teacher_loss 0.6948 (0.9805) loss_zs_kd 0.0915 (0.1304) loss_oracle 0.0411 (0.0481) acc 84.3750 (73.9621) kd_loss 0.0302 (0.0310) lr 1.7705e-03 eta 0:19:23
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,414
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 86.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.9%
******* Domain a best val acc:      86.9%, epoch: 10 *******
******* Domain a best val test acc: 83.2%, epoch: 10 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [14/50] batch [20/288] time 0.102 (0.122) data 0.000 (0.014) loss 1.1169 (1.1085) ce_loss 1.0039 (1.0001) teacher_loss 1.0008 (0.9996) loss_zs_kd 0.1337 (0.1244) loss_oracle 0.0493 (0.0467) acc 71.8750 (73.2812) kd_loss 0.0272 (0.0297) lr 1.7290e-03 eta 0:21:40
epoch [14/50] batch [40/288] time 0.113 (0.113) data 0.000 (0.007) loss 0.8831 (1.0729) ce_loss 0.7681 (0.9674) teacher_loss 0.7606 (0.9660) loss_zs_kd 0.1556 (0.1223) loss_oracle 0.0447 (0.0458) acc 75.0000 (74.2969) kd_loss 0.0306 (0.0293) lr 1.7290e-03 eta 0:20:02
epoch [14/50] batch [60/288] time 0.115 (0.111) data 0.000 (0.005) loss 0.9999 (1.0510) ce_loss 0.8955 (0.9437) teacher_loss 0.8981 (0.9426) loss_zs_kd 0.1106 (0.1261) loss_oracle 0.0465 (0.0453) acc 71.8750 (74.6354) kd_loss 0.0289 (0.0284) lr 1.7290e-03 eta 0:19:34
epoch [14/50] batch [80/288] time 0.108 (0.109) data 0.000 (0.004) loss 1.2658 (1.0741) ce_loss 1.1602 (0.9643) teacher_loss 1.1674 (0.9634) loss_zs_kd 0.1110 (0.1303) loss_oracle 0.0429 (0.0456) acc 71.8750 (73.8672) kd_loss 0.0206 (0.0284) lr 1.7290e-03 eta 0:19:13
epoch [14/50] batch [100/288] time 0.104 (0.108) data 0.001 (0.003) loss 1.2853 (1.0752) ce_loss 1.1514 (0.9620) teacher_loss 1.1544 (0.9614) loss_zs_kd 0.1607 (0.1335) loss_oracle 0.0506 (0.0471) acc 68.7500 (73.8125) kd_loss 0.0243 (0.0290) lr 1.7290e-03 eta 0:19:00
epoch [14/50] batch [120/288] time 0.105 (0.107) data 0.000 (0.003) loss 0.8588 (1.0867) ce_loss 0.7407 (0.9740) teacher_loss 0.7471 (0.9735) loss_zs_kd 0.1191 (0.1320) loss_oracle 0.0521 (0.0472) acc 84.3750 (73.5156) kd_loss 0.0341 (0.0284) lr 1.7290e-03 eta 0:18:46
epoch [14/50] batch [140/288] time 0.103 (0.106) data 0.000 (0.002) loss 0.9076 (1.0974) ce_loss 0.8179 (0.9858) teacher_loss 0.8176 (0.9850) loss_zs_kd 0.1212 (0.1317) loss_oracle 0.0295 (0.0465) acc 81.2500 (73.4375) kd_loss 0.0176 (0.0282) lr 1.7290e-03 eta 0:18:37
epoch [14/50] batch [160/288] time 0.106 (0.106) data 0.000 (0.002) loss 0.8092 (1.0848) ce_loss 0.6943 (0.9740) teacher_loss 0.6995 (0.9734) loss_zs_kd 0.1255 (0.1308) loss_oracle 0.0470 (0.0460) acc 78.1250 (73.7695) kd_loss 0.0301 (0.0277) lr 1.7290e-03 eta 0:18:28
epoch [14/50] batch [180/288] time 0.110 (0.105) data 0.000 (0.002) loss 0.7305 (1.0724) ce_loss 0.6616 (0.9626) teacher_loss 0.6637 (0.9624) loss_zs_kd 0.0867 (0.1303) loss_oracle 0.0235 (0.0449) acc 81.2500 (74.0799) kd_loss 0.0175 (0.0273) lr 1.7290e-03 eta 0:18:24
epoch [14/50] batch [200/288] time 0.098 (0.105) data 0.000 (0.002) loss 1.2935 (1.0783) ce_loss 1.1816 (0.9692) teacher_loss 1.1921 (0.9691) loss_zs_kd 0.1352 (0.1297) loss_oracle 0.0338 (0.0443) acc 68.7500 (74.0312) kd_loss 0.0179 (0.0271) lr 1.7290e-03 eta 0:18:19
epoch [14/50] batch [220/288] time 0.091 (0.105) data 0.000 (0.002) loss 0.5226 (1.0721) ce_loss 0.4160 (0.9631) teacher_loss 0.4211 (0.9631) loss_zs_kd 0.1124 (0.1297) loss_oracle 0.0454 (0.0442) acc 87.5000 (74.2330) kd_loss 0.0213 (0.0270) lr 1.7290e-03 eta 0:18:10
epoch [14/50] batch [240/288] time 0.099 (0.104) data 0.000 (0.001) loss 0.9679 (1.0677) ce_loss 0.8325 (0.9586) teacher_loss 0.8349 (0.9584) loss_zs_kd 0.1821 (0.1305) loss_oracle 0.0419 (0.0441) acc 78.1250 (74.3229) kd_loss 0.0232 (0.0269) lr 1.7290e-03 eta 0:18:05
epoch [14/50] batch [260/288] time 0.103 (0.104) data 0.000 (0.001) loss 1.4341 (1.0695) ce_loss 1.3096 (0.9602) teacher_loss 1.3118 (0.9601) loss_zs_kd 0.1390 (0.1309) loss_oracle 0.0528 (0.0439) acc 68.7500 (74.4111) kd_loss 0.0213 (0.0265) lr 1.7290e-03 eta 0:18:03
epoch [14/50] batch [280/288] time 0.105 (0.104) data 0.000 (0.001) loss 0.6607 (1.0685) ce_loss 0.5620 (0.9598) teacher_loss 0.5530 (0.9596) loss_zs_kd 0.1087 (0.1305) loss_oracle 0.0534 (0.0436) acc 84.3750 (74.4420) kd_loss 0.0287 (0.0263) lr 1.7290e-03 eta 0:18:02
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,424
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.3%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,016
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.6%
******* Domain a best val acc:      86.9%, epoch: 14 *******
******* Domain a best val test acc: 83.1%, epoch: 14 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [15/50] batch [20/288] time 0.112 (0.122) data 0.000 (0.015) loss 1.1631 (1.0827) ce_loss 1.0684 (0.9712) teacher_loss 1.0728 (0.9727) loss_zs_kd 0.1009 (0.1362) loss_oracle 0.0398 (0.0418) acc 78.1250 (75.1562) kd_loss 0.0215 (0.0240) lr 1.6845e-03 eta 0:20:57
epoch [15/50] batch [40/288] time 0.099 (0.112) data 0.000 (0.008) loss 1.1984 (1.1381) ce_loss 1.0986 (1.0291) teacher_loss 1.1027 (1.0299) loss_zs_kd 0.1144 (0.1321) loss_oracle 0.0385 (0.0422) acc 78.1250 (74.2188) kd_loss 0.0217 (0.0243) lr 1.6845e-03 eta 0:19:17
epoch [15/50] batch [60/288] time 0.100 (0.109) data 0.000 (0.005) loss 0.8056 (1.0941) ce_loss 0.6992 (0.9855) teacher_loss 0.7014 (0.9859) loss_zs_kd 0.1128 (0.1308) loss_oracle 0.0479 (0.0428) acc 78.1250 (74.6875) kd_loss 0.0222 (0.0246) lr 1.6845e-03 eta 0:18:38
epoch [15/50] batch [80/288] time 0.104 (0.107) data 0.000 (0.004) loss 1.0555 (1.0579) ce_loss 0.9614 (0.9495) teacher_loss 0.9644 (0.9497) loss_zs_kd 0.1125 (0.1292) loss_oracle 0.0349 (0.0436) acc 75.0000 (75.2734) kd_loss 0.0188 (0.0248) lr 1.6845e-03 eta 0:18:24
epoch [15/50] batch [100/288] time 0.102 (0.106) data 0.000 (0.003) loss 1.1060 (1.0518) ce_loss 1.0088 (0.9427) teacher_loss 1.0162 (0.9421) loss_zs_kd 0.1010 (0.1295) loss_oracle 0.0394 (0.0450) acc 71.8750 (75.0938) kd_loss 0.0240 (0.0253) lr 1.6845e-03 eta 0:18:12
epoch [15/50] batch [120/288] time 0.110 (0.106) data 0.000 (0.003) loss 1.3791 (1.0549) ce_loss 1.2471 (0.9453) teacher_loss 1.2612 (0.9451) loss_zs_kd 0.1518 (0.1283) loss_oracle 0.0419 (0.0456) acc 75.0000 (74.9740) kd_loss 0.0222 (0.0255) lr 1.6845e-03 eta 0:18:05
epoch [15/50] batch [140/288] time 0.092 (0.105) data 0.000 (0.002) loss 1.1516 (1.0651) ce_loss 1.0479 (0.9545) teacher_loss 1.0451 (0.9542) loss_zs_kd 0.1182 (0.1287) loss_oracle 0.0474 (0.0465) acc 71.8750 (74.5982) kd_loss 0.0254 (0.0260) lr 1.6845e-03 eta 0:17:56
epoch [15/50] batch [160/288] time 0.098 (0.105) data 0.000 (0.002) loss 1.1595 (1.0712) ce_loss 1.0645 (0.9606) teacher_loss 1.0648 (0.9598) loss_zs_kd 0.0873 (0.1296) loss_oracle 0.0510 (0.0467) acc 68.7500 (74.3945) kd_loss 0.0225 (0.0262) lr 1.6845e-03 eta 0:17:49
epoch [15/50] batch [180/288] time 0.102 (0.104) data 0.000 (0.002) loss 1.4911 (1.0787) ce_loss 1.3613 (0.9680) teacher_loss 1.3624 (0.9669) loss_zs_kd 0.1478 (0.1290) loss_oracle 0.0548 (0.0473) acc 75.0000 (74.2708) kd_loss 0.0225 (0.0265) lr 1.6845e-03 eta 0:17:44
epoch [15/50] batch [200/288] time 0.111 (0.104) data 0.000 (0.002) loss 0.8934 (1.0846) ce_loss 0.7686 (0.9735) teacher_loss 0.7404 (0.9723) loss_zs_kd 0.1780 (0.1297) loss_oracle 0.0641 (0.0475) acc 71.8750 (73.9844) kd_loss 0.0328 (0.0268) lr 1.6845e-03 eta 0:17:40
epoch [15/50] batch [220/288] time 0.098 (0.104) data 0.000 (0.002) loss 1.2508 (1.0833) ce_loss 1.1201 (0.9718) teacher_loss 1.1212 (0.9706) loss_zs_kd 0.1323 (0.1304) loss_oracle 0.0635 (0.0475) acc 71.8750 (73.9773) kd_loss 0.0437 (0.0269) lr 1.6845e-03 eta 0:17:36
epoch [15/50] batch [240/288] time 0.110 (0.104) data 0.000 (0.002) loss 0.9554 (1.0779) ce_loss 0.7891 (0.9654) teacher_loss 0.7861 (0.9643) loss_zs_kd 0.2370 (0.1319) loss_oracle 0.0508 (0.0476) acc 71.8750 (74.1536) kd_loss 0.0322 (0.0271) lr 1.6845e-03 eta 0:17:33
epoch [15/50] batch [260/288] time 0.103 (0.104) data 0.000 (0.001) loss 1.1086 (1.0808) ce_loss 1.0254 (0.9684) teacher_loss 1.0221 (0.9671) loss_zs_kd 0.0917 (0.1325) loss_oracle 0.0406 (0.0475) acc 75.0000 (74.1106) kd_loss 0.0234 (0.0271) lr 1.6845e-03 eta 0:17:29
epoch [15/50] batch [280/288] time 0.107 (0.104) data 0.000 (0.001) loss 1.0525 (1.0780) ce_loss 0.9619 (0.9662) teacher_loss 0.9575 (0.9649) loss_zs_kd 0.1032 (0.1312) loss_oracle 0.0434 (0.0475) acc 71.8750 (74.1183) kd_loss 0.0262 (0.0272) lr 1.6845e-03 eta 0:17:27
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,416
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 86.2%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,019
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.8%
******* Domain a best val acc:      86.9%, epoch: 14 *******
******* Domain a best val test acc: 83.1%, epoch: 14 *******
******* Domain a best test acc:     83.7%, epoch: 6 *******
epoch [16/50] batch [20/288] time 0.106 (0.121) data 0.000 (0.013) loss 1.3665 (1.1083) ce_loss 1.2412 (1.0049) teacher_loss 1.2345 (1.0008) loss_zs_kd 0.1510 (0.1249) loss_oracle 0.0564 (0.0450) acc 71.8750 (73.2812) kd_loss 0.0269 (0.0285) lr 1.6374e-03 eta 0:20:21
epoch [16/50] batch [40/288] time 0.099 (0.112) data 0.001 (0.007) loss 1.3396 (1.0761) ce_loss 1.2100 (0.9673) teacher_loss 1.2044 (0.9645) loss_zs_kd 0.1543 (0.1293) loss_oracle 0.0581 (0.0469) acc 68.7500 (73.5156) kd_loss 0.0370 (0.0289) lr 1.6374e-03 eta 0:18:46
epoch [16/50] batch [60/288] time 0.096 (0.109) data 0.000 (0.005) loss 1.2841 (1.0705) ce_loss 1.1641 (0.9628) teacher_loss 1.1416 (0.9605) loss_zs_kd 0.1533 (0.1278) loss_oracle 0.0659 (0.0461) acc 78.1250 (73.9062) kd_loss 0.0468 (0.0284) lr 1.6374e-03 eta 0:18:08
epoch [16/50] batch [80/288] time 0.098 (0.107) data 0.000 (0.004) loss 1.4608 (1.0690) ce_loss 1.3555 (0.9610) teacher_loss 1.3616 (0.9599) loss_zs_kd 0.1367 (0.1280) loss_oracle 0.0309 (0.0451) acc 62.5000 (74.0234) kd_loss 0.0256 (0.0286) lr 1.6374e-03 eta 0:17:48
epoch [16/50] batch [100/288] time 0.100 (0.106) data 0.000 (0.003) loss 1.1649 (1.0806) ce_loss 1.0498 (0.9729) teacher_loss 1.0461 (0.9721) loss_zs_kd 0.1685 (0.1301) loss_oracle 0.0346 (0.0435) acc 68.7500 (73.4688) kd_loss 0.0271 (0.0283) lr 1.6374e-03 eta 0:17:35
epoch [16/50] batch [120/288] time 0.104 (0.105) data 0.000 (0.003) loss 0.9319 (1.0748) ce_loss 0.7900 (0.9682) teacher_loss 0.7927 (0.9671) loss_zs_kd 0.1733 (0.1287) loss_oracle 0.0525 (0.0434) acc 78.1250 (73.4896) kd_loss 0.0281 (0.0283) lr 1.6374e-03 eta 0:17:26
epoch [16/50] batch [140/288] time 0.105 (0.105) data 0.000 (0.002) loss 1.1206 (1.0563) ce_loss 1.0166 (0.9496) teacher_loss 1.0226 (0.9487) loss_zs_kd 0.1209 (0.1281) loss_oracle 0.0376 (0.0435) acc 78.1250 (74.0402) kd_loss 0.0226 (0.0285) lr 1.6374e-03 eta 0:17:23
epoch [16/50] batch [160/288] time 0.104 (0.105) data 0.001 (0.002) loss 1.1671 (1.0556) ce_loss 1.0479 (0.9475) teacher_loss 1.0437 (0.9465) loss_zs_kd 0.1220 (0.1294) loss_oracle 0.0624 (0.0444) acc 71.8750 (74.2773) kd_loss 0.0447 (0.0289) lr 1.6374e-03 eta 0:17:20
epoch [16/50] batch [180/288] time 0.105 (0.105) data 0.000 (0.002) loss 0.8501 (1.0659) ce_loss 0.7612 (0.9572) teacher_loss 0.7666 (0.9566) loss_zs_kd 0.0862 (0.1300) loss_oracle 0.0404 (0.0444) acc 78.1250 (74.2535) kd_loss 0.0396 (0.0293) lr 1.6374e-03 eta 0:17:16
epoch [16/50] batch [200/288] time 0.102 (0.105) data 0.000 (0.002) loss 0.8816 (1.0709) ce_loss 0.7637 (0.9627) teacher_loss 0.7603 (0.9620) loss_zs_kd 0.1378 (0.1290) loss_oracle 0.0524 (0.0444) acc 78.1250 (73.9219) kd_loss 0.0241 (0.0300) lr 1.6374e-03 eta 0:17:13
epoch [16/50] batch [220/288] time 0.104 (0.105) data 0.000 (0.002) loss 0.8177 (1.0686) ce_loss 0.6875 (0.9595) teacher_loss 0.6812 (0.9588) loss_zs_kd 0.1500 (0.1297) loss_oracle 0.0615 (0.0449) acc 84.3750 (73.9773) kd_loss 0.0435 (0.0301) lr 1.6374e-03 eta 0:17:10
epoch [16/50] batch [240/288] time 0.102 (0.104) data 0.000 (0.001) loss 0.9809 (1.0619) ce_loss 0.8408 (0.9519) teacher_loss 0.8450 (0.9512) loss_zs_kd 0.1830 (0.1309) loss_oracle 0.0444 (0.0453) acc 78.1250 (74.2057) kd_loss 0.0197 (0.0302) lr 1.6374e-03 eta 0:17:06
epoch [16/50] batch [260/288] time 0.099 (0.104) data 0.000 (0.001) loss 0.9828 (1.0671) ce_loss 0.8750 (0.9564) teacher_loss 0.8852 (0.9557) loss_zs_kd 0.1088 (0.1313) loss_oracle 0.0432 (0.0457) acc 78.1250 (74.0505) kd_loss 0.0295 (0.0303) lr 1.6374e-03 eta 0:17:03
epoch [16/50] batch [280/288] time 0.110 (0.104) data 0.000 (0.001) loss 1.5409 (1.0753) ce_loss 1.4150 (0.9639) teacher_loss 1.3996 (0.9633) loss_zs_kd 0.1741 (0.1324) loss_oracle 0.0543 (0.0458) acc 62.5000 (73.9397) kd_loss 0.0333 (0.0300) lr 1.6374e-03 eta 0:17:03
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,431
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,034
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 80.7%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      87.1%, epoch: 16 *******
******* Domain a best val test acc: 83.8%, epoch: 16 *******
******* Domain a best test acc:     83.8%, epoch: 16 *******
epoch [17/50] batch [20/288] time 0.089 (0.107) data 0.000 (0.011) loss 1.5220 (0.9393) ce_loss 1.3984 (0.8207) teacher_loss 1.4018 (0.8204) loss_zs_kd 0.1283 (0.1213) loss_oracle 0.0560 (0.0583) acc 75.0000 (78.9062) kd_loss 0.0341 (0.0280) lr 1.5878e-03 eta 0:17:23
epoch [17/50] batch [40/288] time 0.096 (0.101) data 0.000 (0.005) loss 1.0006 (1.0287) ce_loss 0.8726 (0.9102) teacher_loss 0.8667 (0.9079) loss_zs_kd 0.1505 (0.1253) loss_oracle 0.0587 (0.0581) acc 78.1250 (76.4844) kd_loss 0.0277 (0.0277) lr 1.5878e-03 eta 0:16:25
epoch [17/50] batch [60/288] time 0.097 (0.100) data 0.000 (0.004) loss 1.3997 (1.0485) ce_loss 1.2959 (0.9308) teacher_loss 1.3000 (0.9276) loss_zs_kd 0.1008 (0.1270) loss_oracle 0.0493 (0.0574) acc 68.7500 (75.2083) kd_loss 0.0253 (0.0293) lr 1.5878e-03 eta 0:16:12
epoch [17/50] batch [80/288] time 0.099 (0.099) data 0.000 (0.003) loss 0.8505 (1.0438) ce_loss 0.7529 (0.9266) teacher_loss 0.7386 (0.9234) loss_zs_kd 0.1400 (0.1295) loss_oracle 0.0419 (0.0557) acc 78.1250 (75.2344) kd_loss 0.0291 (0.0298) lr 1.5878e-03 eta 0:16:02
epoch [17/50] batch [100/288] time 0.097 (0.098) data 0.000 (0.002) loss 1.1731 (1.0441) ce_loss 1.0605 (0.9272) teacher_loss 1.0577 (0.9250) loss_zs_kd 0.1222 (0.1313) loss_oracle 0.0544 (0.0534) acc 65.6250 (75.1875) kd_loss 0.0335 (0.0301) lr 1.5878e-03 eta 0:15:53
epoch [17/50] batch [120/288] time 0.097 (0.098) data 0.000 (0.002) loss 1.1010 (1.0509) ce_loss 1.0146 (0.9355) teacher_loss 1.0104 (0.9337) loss_zs_kd 0.0888 (0.1315) loss_oracle 0.0462 (0.0514) acc 71.8750 (74.8177) kd_loss 0.0210 (0.0296) lr 1.5878e-03 eta 0:15:46
epoch [17/50] batch [140/288] time 0.097 (0.098) data 0.000 (0.002) loss 1.2697 (1.0748) ce_loss 1.1602 (0.9586) teacher_loss 1.1575 (0.9566) loss_zs_kd 0.1320 (0.1333) loss_oracle 0.0462 (0.0516) acc 65.6250 (74.2411) kd_loss 0.0273 (0.0295) lr 1.5878e-03 eta 0:15:44
epoch [17/50] batch [160/288] time 0.099 (0.098) data 0.000 (0.002) loss 1.1457 (1.0769) ce_loss 1.0264 (0.9598) teacher_loss 1.0333 (0.9577) loss_zs_kd 0.1261 (0.1335) loss_oracle 0.0493 (0.0525) acc 75.0000 (74.1992) kd_loss 0.0287 (0.0299) lr 1.5878e-03 eta 0:15:41
epoch [17/50] batch [180/288] time 0.094 (0.098) data 0.000 (0.001) loss 0.9726 (1.0701) ce_loss 0.8521 (0.9529) teacher_loss 0.8522 (0.9508) loss_zs_kd 0.0920 (0.1315) loss_oracle 0.0744 (0.0536) acc 68.7500 (74.3576) kd_loss 0.0403 (0.0294) lr 1.5878e-03 eta 0:15:39
epoch [17/50] batch [200/288] time 0.098 (0.098) data 0.000 (0.001) loss 0.9615 (1.0695) ce_loss 0.8540 (0.9507) teacher_loss 0.8540 (0.9486) loss_zs_kd 0.0839 (0.1318) loss_oracle 0.0655 (0.0550) acc 68.7500 (74.4844) kd_loss 0.0372 (0.0297) lr 1.5878e-03 eta 0:15:37
epoch [17/50] batch [220/288] time 0.100 (0.098) data 0.000 (0.001) loss 0.9168 (1.0689) ce_loss 0.8203 (0.9493) teacher_loss 0.8287 (0.9475) loss_zs_kd 0.0769 (0.1328) loss_oracle 0.0496 (0.0550) acc 81.2500 (74.5739) kd_loss 0.0278 (0.0298) lr 1.5878e-03 eta 0:15:36
epoch [17/50] batch [240/288] time 0.101 (0.098) data 0.000 (0.001) loss 1.0415 (1.0667) ce_loss 0.9463 (0.9472) teacher_loss 0.9335 (0.9455) loss_zs_kd 0.1061 (0.1321) loss_oracle 0.0550 (0.0552) acc 71.8750 (74.5312) kd_loss 0.0291 (0.0299) lr 1.5878e-03 eta 0:15:35
epoch [17/50] batch [260/288] time 0.110 (0.098) data 0.000 (0.001) loss 1.4672 (1.0705) ce_loss 1.3428 (0.9502) teacher_loss 1.3456 (0.9486) loss_zs_kd 0.1239 (0.1327) loss_oracle 0.0597 (0.0555) acc 68.7500 (74.5072) kd_loss 0.0290 (0.0300) lr 1.5878e-03 eta 0:15:34
epoch [17/50] batch [280/288] time 0.107 (0.099) data 0.000 (0.001) loss 1.3825 (1.0702) ce_loss 1.2295 (0.9493) teacher_loss 1.2233 (0.9478) loss_zs_kd 0.1741 (0.1332) loss_oracle 0.0722 (0.0558) acc 75.0000 (74.5871) kd_loss 0.0366 (0.0301) lr 1.5878e-03 eta 0:15:37
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,421
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,017
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.8%
******* Domain a best val acc:      87.1%, epoch: 16 *******
******* Domain a best val test acc: 83.8%, epoch: 16 *******
******* Domain a best test acc:     83.8%, epoch: 16 *******
epoch [18/50] batch [20/288] time 0.100 (0.112) data 0.000 (0.013) loss 1.3561 (1.0706) ce_loss 1.2168 (0.9394) teacher_loss 1.2181 (0.9390) loss_zs_kd 0.1343 (0.1418) loss_oracle 0.0709 (0.0608) acc 68.7500 (74.8438) kd_loss 0.0291 (0.0329) lr 1.5358e-03 eta 0:17:40
epoch [18/50] batch [40/288] time 0.092 (0.106) data 0.000 (0.007) loss 1.6835 (1.1171) ce_loss 1.5332 (0.9856) teacher_loss 1.5399 (0.9839) loss_zs_kd 0.1773 (0.1416) loss_oracle 0.0549 (0.0624) acc 59.3750 (73.5938) kd_loss 0.0268 (0.0327) lr 1.5358e-03 eta 0:16:39
epoch [18/50] batch [60/288] time 0.107 (0.104) data 0.000 (0.005) loss 0.8101 (1.1128) ce_loss 0.6768 (0.9836) teacher_loss 0.6816 (0.9820) loss_zs_kd 0.1388 (0.1364) loss_oracle 0.0591 (0.0626) acc 81.2500 (73.7500) kd_loss 0.0383 (0.0338) lr 1.5358e-03 eta 0:16:19
epoch [18/50] batch [80/288] time 0.095 (0.102) data 0.000 (0.003) loss 1.9470 (1.1356) ce_loss 1.7969 (1.0074) teacher_loss 1.8156 (1.0051) loss_zs_kd 0.1675 (0.1351) loss_oracle 0.0476 (0.0629) acc 53.1250 (72.8906) kd_loss 0.0285 (0.0340) lr 1.5358e-03 eta 0:16:00
epoch [18/50] batch [100/288] time 0.098 (0.101) data 0.000 (0.003) loss 0.9236 (1.1225) ce_loss 0.8164 (0.9964) teacher_loss 0.8037 (0.9934) loss_zs_kd 0.1044 (0.1332) loss_oracle 0.0678 (0.0625) acc 84.3750 (73.0938) kd_loss 0.0379 (0.0344) lr 1.5358e-03 eta 0:15:48
epoch [18/50] batch [120/288] time 0.095 (0.100) data 0.000 (0.002) loss 1.2339 (1.1080) ce_loss 1.1045 (0.9834) teacher_loss 1.1129 (0.9804) loss_zs_kd 0.1240 (0.1319) loss_oracle 0.0590 (0.0617) acc 75.0000 (73.5156) kd_loss 0.0283 (0.0349) lr 1.5358e-03 eta 0:15:42
epoch [18/50] batch [140/288] time 0.098 (0.100) data 0.000 (0.002) loss 1.1391 (1.1156) ce_loss 1.0273 (0.9918) teacher_loss 1.0275 (0.9889) loss_zs_kd 0.1239 (0.1318) loss_oracle 0.0497 (0.0608) acc 75.0000 (73.1696) kd_loss 0.0284 (0.0347) lr 1.5358e-03 eta 0:15:36
epoch [18/50] batch [160/288] time 0.105 (0.100) data 0.000 (0.002) loss 1.0053 (1.1065) ce_loss 0.8765 (0.9827) teacher_loss 0.8660 (0.9795) loss_zs_kd 0.1653 (0.1326) loss_oracle 0.0566 (0.0606) acc 75.0000 (73.4961) kd_loss 0.0246 (0.0346) lr 1.5358e-03 eta 0:15:33
epoch [18/50] batch [180/288] time 0.096 (0.100) data 0.000 (0.002) loss 0.9521 (1.1009) ce_loss 0.7822 (0.9765) teacher_loss 0.7942 (0.9736) loss_zs_kd 0.1764 (0.1335) loss_oracle 0.0697 (0.0606) acc 71.8750 (73.6458) kd_loss 0.0560 (0.0345) lr 1.5358e-03 eta 0:15:28
epoch [18/50] batch [200/288] time 0.092 (0.100) data 0.000 (0.002) loss 1.4169 (1.0910) ce_loss 1.2969 (0.9675) teacher_loss 1.2914 (0.9649) loss_zs_kd 0.1498 (0.1333) loss_oracle 0.0505 (0.0594) acc 65.6250 (73.7969) kd_loss 0.0287 (0.0341) lr 1.5358e-03 eta 0:15:25
epoch [18/50] batch [220/288] time 0.093 (0.099) data 0.000 (0.001) loss 1.5978 (1.0944) ce_loss 1.4824 (0.9715) teacher_loss 1.4845 (0.9685) loss_zs_kd 0.1137 (0.1331) loss_oracle 0.0565 (0.0593) acc 62.5000 (73.6080) kd_loss 0.0244 (0.0342) lr 1.5358e-03 eta 0:15:21
epoch [18/50] batch [240/288] time 0.098 (0.099) data 0.000 (0.001) loss 0.8871 (1.0955) ce_loss 0.7397 (0.9719) teacher_loss 0.7485 (0.9691) loss_zs_kd 0.1529 (0.1336) loss_oracle 0.0621 (0.0596) acc 81.2500 (73.5417) kd_loss 0.0395 (0.0341) lr 1.5358e-03 eta 0:15:18
epoch [18/50] batch [260/288] time 0.101 (0.099) data 0.000 (0.001) loss 1.0782 (1.0943) ce_loss 0.9956 (0.9710) teacher_loss 0.9866 (0.9682) loss_zs_kd 0.0773 (0.1326) loss_oracle 0.0530 (0.0598) acc 81.2500 (73.7500) kd_loss 0.0371 (0.0339) lr 1.5358e-03 eta 0:15:15
epoch [18/50] batch [280/288] time 0.088 (0.099) data 0.000 (0.001) loss 1.3574 (1.0987) ce_loss 1.2217 (0.9752) teacher_loss 1.2138 (0.9724) loss_zs_kd 0.1523 (0.1326) loss_oracle 0.0674 (0.0600) acc 65.6250 (73.7054) kd_loss 0.0373 (0.0339) lr 1.5358e-03 eta 0:15:10
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,435
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,035
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 80.6%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      87.2%, epoch: 18 *******
******* Domain a best val test acc: 83.8%, epoch: 18 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [19/50] batch [20/288] time 0.091 (0.114) data 0.000 (0.012) loss 1.1036 (1.0333) ce_loss 0.9951 (0.9141) teacher_loss 1.0021 (0.9160) loss_zs_kd 0.1059 (0.1305) loss_oracle 0.0485 (0.0520) acc 75.0000 (76.0938) kd_loss 0.0366 (0.0347) lr 1.4818e-03 eta 0:17:30
epoch [19/50] batch [40/288] time 0.093 (0.105) data 0.000 (0.006) loss 1.1981 (1.0896) ce_loss 1.0811 (0.9705) teacher_loss 1.0670 (0.9705) loss_zs_kd 0.1338 (0.1314) loss_oracle 0.0642 (0.0534) acc 62.5000 (73.9844) kd_loss 0.0362 (0.0333) lr 1.4818e-03 eta 0:16:05
epoch [19/50] batch [60/288] time 0.084 (0.101) data 0.000 (0.004) loss 1.3550 (1.1358) ce_loss 1.2354 (1.0149) teacher_loss 1.2396 (1.0131) loss_zs_kd 0.1474 (0.1354) loss_oracle 0.0417 (0.0550) acc 71.8750 (73.1250) kd_loss 0.0303 (0.0343) lr 1.4818e-03 eta 0:15:25
epoch [19/50] batch [80/288] time 0.106 (0.100) data 0.000 (0.003) loss 0.9698 (1.0959) ce_loss 0.8804 (0.9760) teacher_loss 0.8713 (0.9749) loss_zs_kd 0.1235 (0.1348) loss_oracle 0.0367 (0.0536) acc 68.7500 (73.9062) kd_loss 0.0291 (0.0339) lr 1.4818e-03 eta 0:15:11
epoch [19/50] batch [100/288] time 0.099 (0.099) data 0.000 (0.003) loss 1.1647 (1.0892) ce_loss 1.0615 (0.9699) teacher_loss 1.0664 (0.9683) loss_zs_kd 0.1155 (0.1341) loss_oracle 0.0406 (0.0539) acc 68.7500 (74.1875) kd_loss 0.0251 (0.0342) lr 1.4818e-03 eta 0:15:05
epoch [19/50] batch [120/288] time 0.094 (0.099) data 0.000 (0.002) loss 1.5899 (1.0881) ce_loss 1.4766 (0.9691) teacher_loss 1.4597 (0.9674) loss_zs_kd 0.1322 (0.1338) loss_oracle 0.0641 (0.0538) acc 65.6250 (74.1927) kd_loss 0.0338 (0.0344) lr 1.4818e-03 eta 0:15:00
epoch [19/50] batch [140/288] time 0.096 (0.099) data 0.000 (0.002) loss 1.3914 (1.0866) ce_loss 1.2930 (0.9677) teacher_loss 1.2952 (0.9660) loss_zs_kd 0.1061 (0.1340) loss_oracle 0.0431 (0.0536) acc 78.1250 (74.3080) kd_loss 0.0287 (0.0342) lr 1.4818e-03 eta 0:14:54
epoch [19/50] batch [160/288] time 0.095 (0.098) data 0.000 (0.002) loss 1.0792 (1.0859) ce_loss 0.9639 (0.9685) teacher_loss 0.9524 (0.9665) loss_zs_kd 0.1398 (0.1317) loss_oracle 0.0569 (0.0535) acc 75.0000 (73.9844) kd_loss 0.0291 (0.0344) lr 1.4818e-03 eta 0:14:50
epoch [19/50] batch [180/288] time 0.092 (0.098) data 0.000 (0.002) loss 1.1620 (1.0862) ce_loss 1.0488 (0.9689) teacher_loss 1.0380 (0.9670) loss_zs_kd 0.1222 (0.1319) loss_oracle 0.0628 (0.0532) acc 71.8750 (73.8194) kd_loss 0.0404 (0.0344) lr 1.4818e-03 eta 0:14:45
epoch [19/50] batch [200/288] time 0.098 (0.098) data 0.000 (0.001) loss 0.7671 (1.0800) ce_loss 0.6333 (0.9626) teacher_loss 0.6399 (0.9610) loss_zs_kd 0.1643 (0.1322) loss_oracle 0.0451 (0.0530) acc 81.2500 (73.8125) kd_loss 0.0312 (0.0343) lr 1.4818e-03 eta 0:14:43
epoch [19/50] batch [220/288] time 0.100 (0.098) data 0.000 (0.001) loss 1.0744 (1.0895) ce_loss 0.9126 (0.9699) teacher_loss 0.9244 (0.9685) loss_zs_kd 0.1742 (0.1350) loss_oracle 0.0629 (0.0536) acc 78.1250 (73.7926) kd_loss 0.0369 (0.0344) lr 1.4818e-03 eta 0:14:39
epoch [19/50] batch [240/288] time 0.096 (0.098) data 0.000 (0.001) loss 0.8262 (1.0883) ce_loss 0.6450 (0.9680) teacher_loss 0.6499 (0.9663) loss_zs_kd 0.1896 (0.1349) loss_oracle 0.0816 (0.0545) acc 81.2500 (73.8021) kd_loss 0.0576 (0.0348) lr 1.4818e-03 eta 0:14:36
epoch [19/50] batch [260/288] time 0.089 (0.097) data 0.000 (0.001) loss 1.1565 (1.0851) ce_loss 1.0322 (0.9645) teacher_loss 1.0344 (0.9623) loss_zs_kd 0.1500 (0.1352) loss_oracle 0.0471 (0.0552) acc 75.0000 (73.9183) kd_loss 0.0292 (0.0355) lr 1.4818e-03 eta 0:14:32
epoch [19/50] batch [280/288] time 0.087 (0.097) data 0.000 (0.001) loss 1.5484 (1.0859) ce_loss 1.4121 (0.9654) teacher_loss 1.4153 (0.9631) loss_zs_kd 0.1699 (0.1352) loss_oracle 0.0481 (0.0552) acc 62.5000 (73.9509) kd_loss 0.0298 (0.0359) lr 1.4818e-03 eta 0:14:26
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,441
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.8%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,022
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 80.2%
******* Domain a best val acc:      87.4%, epoch: 19 *******
******* Domain a best val test acc: 83.3%, epoch: 19 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [20/50] batch [20/288] time 0.110 (0.122) data 0.000 (0.013) loss 1.4539 (1.0570) ce_loss 1.3359 (0.9337) teacher_loss 1.3324 (0.9309) loss_zs_kd 0.1346 (0.1390) loss_oracle 0.0542 (0.0566) acc 59.3750 (73.2812) kd_loss 0.0306 (0.0398) lr 1.4258e-03 eta 0:18:03
epoch [20/50] batch [40/288] time 0.104 (0.114) data 0.000 (0.007) loss 1.1081 (1.0670) ce_loss 0.9307 (0.9390) teacher_loss 0.9344 (0.9368) loss_zs_kd 0.2235 (0.1470) loss_oracle 0.0619 (0.0567) acc 78.1250 (73.7500) kd_loss 0.0342 (0.0378) lr 1.4258e-03 eta 0:16:55
epoch [20/50] batch [60/288] time 0.114 (0.111) data 0.000 (0.005) loss 0.8829 (1.0655) ce_loss 0.7974 (0.9349) teacher_loss 0.8026 (0.9330) loss_zs_kd 0.0775 (0.1467) loss_oracle 0.0415 (0.0591) acc 81.2500 (74.1667) kd_loss 0.0278 (0.0379) lr 1.4258e-03 eta 0:16:27
epoch [20/50] batch [80/288] time 0.110 (0.110) data 0.000 (0.004) loss 0.9119 (1.0655) ce_loss 0.7900 (0.9372) teacher_loss 0.7913 (0.9343) loss_zs_kd 0.0988 (0.1439) loss_oracle 0.0712 (0.0592) acc 81.2500 (74.2188) kd_loss 0.0552 (0.0386) lr 1.4258e-03 eta 0:16:14
epoch [20/50] batch [100/288] time 0.103 (0.109) data 0.000 (0.003) loss 1.2705 (1.0571) ce_loss 1.1729 (0.9314) teacher_loss 1.1519 (0.9282) loss_zs_kd 0.1270 (0.1405) loss_oracle 0.0551 (0.0587) acc 62.5000 (74.4688) kd_loss 0.0374 (0.0387) lr 1.4258e-03 eta 0:15:58
epoch [20/50] batch [120/288] time 0.092 (0.107) data 0.000 (0.002) loss 0.6717 (1.0733) ce_loss 0.5850 (0.9488) teacher_loss 0.5865 (0.9446) loss_zs_kd 0.0611 (0.1396) loss_oracle 0.0546 (0.0589) acc 84.3750 (74.0625) kd_loss 0.0236 (0.0385) lr 1.4258e-03 eta 0:15:46
epoch [20/50] batch [140/288] time 0.108 (0.107) data 0.000 (0.002) loss 0.9226 (1.0809) ce_loss 0.7871 (0.9546) teacher_loss 0.7687 (0.9503) loss_zs_kd 0.1390 (0.1409) loss_oracle 0.0844 (0.0601) acc 78.1250 (73.8393) kd_loss 0.0407 (0.0390) lr 1.4258e-03 eta 0:15:38
epoch [20/50] batch [160/288] time 0.115 (0.107) data 0.000 (0.002) loss 1.0764 (1.0766) ce_loss 0.9707 (0.9510) teacher_loss 0.9802 (0.9469) loss_zs_kd 0.1044 (0.1399) loss_oracle 0.0440 (0.0597) acc 75.0000 (73.9844) kd_loss 0.0246 (0.0385) lr 1.4258e-03 eta 0:15:34
epoch [20/50] batch [180/288] time 0.101 (0.107) data 0.000 (0.002) loss 0.8545 (1.0684) ce_loss 0.7417 (0.9433) teacher_loss 0.7499 (0.9397) loss_zs_kd 0.1028 (0.1388) loss_oracle 0.0532 (0.0593) acc 81.2500 (74.2882) kd_loss 0.0326 (0.0381) lr 1.4258e-03 eta 0:15:33
epoch [20/50] batch [200/288] time 0.095 (0.106) data 0.000 (0.002) loss 1.5671 (1.0716) ce_loss 1.3916 (0.9474) teacher_loss 1.3927 (0.9438) loss_zs_kd 0.2264 (0.1380) loss_oracle 0.0612 (0.0588) acc 62.5000 (74.2031) kd_loss 0.0414 (0.0379) lr 1.4258e-03 eta 0:15:26
epoch [20/50] batch [220/288] time 0.099 (0.106) data 0.000 (0.001) loss 0.9890 (1.0603) ce_loss 0.8682 (0.9366) teacher_loss 0.8709 (0.9332) loss_zs_kd 0.1298 (0.1376) loss_oracle 0.0531 (0.0583) acc 78.1250 (74.4318) kd_loss 0.0265 (0.0376) lr 1.4258e-03 eta 0:15:20
epoch [20/50] batch [240/288] time 0.112 (0.106) data 0.000 (0.001) loss 1.1929 (1.0579) ce_loss 1.0898 (0.9341) teacher_loss 1.0841 (0.9310) loss_zs_kd 0.1287 (0.1378) loss_oracle 0.0444 (0.0580) acc 65.6250 (74.5312) kd_loss 0.0333 (0.0374) lr 1.4258e-03 eta 0:15:16
epoch [20/50] batch [260/288] time 0.100 (0.105) data 0.000 (0.001) loss 1.3270 (1.0531) ce_loss 1.2266 (0.9296) teacher_loss 1.2220 (0.9266) loss_zs_kd 0.0935 (0.1375) loss_oracle 0.0582 (0.0578) acc 65.6250 (74.6034) kd_loss 0.0343 (0.0374) lr 1.4258e-03 eta 0:15:13
epoch [20/50] batch [280/288] time 0.108 (0.105) data 0.000 (0.001) loss 0.7947 (1.0510) ce_loss 0.6836 (0.9282) teacher_loss 0.6896 (0.9251) loss_zs_kd 0.1248 (0.1369) loss_oracle 0.0428 (0.0575) acc 84.3750 (74.6875) kd_loss 0.0251 (0.0374) lr 1.4258e-03 eta 0:15:11
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,438
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,031
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 80.4%
******* Domain a best val acc:      87.4%, epoch: 19 *******
******* Domain a best val test acc: 83.3%, epoch: 19 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [21/50] batch [20/288] time 0.090 (0.113) data 0.000 (0.012) loss 0.5642 (1.0064) ce_loss 0.4275 (0.8810) teacher_loss 0.4146 (0.8800) loss_zs_kd 0.1483 (0.1483) loss_oracle 0.0755 (0.0522) acc 90.6250 (75.9375) kd_loss 0.0557 (0.0356) lr 1.3681e-03 eta 0:16:15
epoch [21/50] batch [40/288] time 0.092 (0.105) data 0.000 (0.006) loss 0.7146 (1.0018) ce_loss 0.5850 (0.8779) teacher_loss 0.5768 (0.8764) loss_zs_kd 0.1286 (0.1460) loss_oracle 0.0734 (0.0523) acc 81.2500 (74.9219) kd_loss 0.0672 (0.0385) lr 1.3681e-03 eta 0:15:01
epoch [21/50] batch [60/288] time 0.096 (0.102) data 0.000 (0.004) loss 0.9361 (1.0238) ce_loss 0.8291 (0.9040) teacher_loss 0.8278 (0.9030) loss_zs_kd 0.1393 (0.1404) loss_oracle 0.0386 (0.0506) acc 75.0000 (74.5833) kd_loss 0.0329 (0.0385) lr 1.3681e-03 eta 0:14:31
epoch [21/50] batch [80/288] time 0.091 (0.100) data 0.000 (0.003) loss 0.6666 (1.0513) ce_loss 0.5688 (0.9325) teacher_loss 0.5678 (0.9312) loss_zs_kd 0.0914 (0.1372) loss_oracle 0.0531 (0.0515) acc 81.2500 (74.1016) kd_loss 0.0510 (0.0402) lr 1.3681e-03 eta 0:14:16
epoch [21/50] batch [100/288] time 0.098 (0.099) data 0.000 (0.003) loss 1.0121 (1.0409) ce_loss 0.9155 (0.9219) teacher_loss 0.9134 (0.9199) loss_zs_kd 0.0899 (0.1357) loss_oracle 0.0538 (0.0531) acc 71.8750 (74.4688) kd_loss 0.0288 (0.0425) lr 1.3681e-03 eta 0:14:09
epoch [21/50] batch [120/288] time 0.091 (0.099) data 0.000 (0.002) loss 0.8064 (1.0500) ce_loss 0.7031 (0.9296) teacher_loss 0.7097 (0.9277) loss_zs_kd 0.1158 (0.1373) loss_oracle 0.0388 (0.0536) acc 84.3750 (74.4271) kd_loss 0.0275 (0.0430) lr 1.3681e-03 eta 0:14:01
epoch [21/50] batch [140/288] time 0.095 (0.099) data 0.000 (0.002) loss 1.0965 (1.0632) ce_loss 0.9668 (0.9426) teacher_loss 0.9790 (0.9407) loss_zs_kd 0.1376 (0.1365) loss_oracle 0.0487 (0.0543) acc 81.2500 (74.2411) kd_loss 0.0385 (0.0440) lr 1.3681e-03 eta 0:13:58
epoch [21/50] batch [160/288] time 0.111 (0.100) data 0.000 (0.002) loss 1.0501 (1.0804) ce_loss 0.9336 (0.9575) teacher_loss 0.9320 (0.9557) loss_zs_kd 0.1297 (0.1389) loss_oracle 0.0533 (0.0552) acc 71.8750 (73.9258) kd_loss 0.0591 (0.0456) lr 1.3681e-03 eta 0:14:04
epoch [21/50] batch [180/288] time 0.102 (0.100) data 0.000 (0.002) loss 1.2947 (1.0863) ce_loss 1.1816 (0.9630) teacher_loss 1.1797 (0.9611) loss_zs_kd 0.1096 (0.1398) loss_oracle 0.0602 (0.0553) acc 71.8750 (73.6632) kd_loss 0.0480 (0.0461) lr 1.3681e-03 eta 0:14:05
epoch [21/50] batch [200/288] time 0.102 (0.101) data 0.000 (0.001) loss 1.2922 (1.0787) ce_loss 1.2080 (0.9557) teacher_loss 1.2034 (0.9539) loss_zs_kd 0.1143 (0.1397) loss_oracle 0.0317 (0.0550) acc 68.7500 (73.9219) kd_loss 0.0251 (0.0461) lr 1.3681e-03 eta 0:14:09
epoch [21/50] batch [220/288] time 0.114 (0.101) data 0.000 (0.001) loss 0.9114 (1.0774) ce_loss 0.8066 (0.9545) teacher_loss 0.8005 (0.9526) loss_zs_kd 0.1186 (0.1394) loss_oracle 0.0516 (0.0551) acc 78.1250 (73.9205) kd_loss 0.0472 (0.0467) lr 1.3681e-03 eta 0:14:10
epoch [21/50] batch [240/288] time 0.100 (0.101) data 0.000 (0.001) loss 1.0885 (1.0886) ce_loss 0.9629 (0.9660) teacher_loss 0.9706 (0.9643) loss_zs_kd 0.1707 (0.1391) loss_oracle 0.0325 (0.0548) acc 81.2500 (73.7630) kd_loss 0.0252 (0.0466) lr 1.3681e-03 eta 0:14:12
epoch [21/50] batch [260/288] time 0.107 (0.102) data 0.000 (0.001) loss 0.9682 (1.0846) ce_loss 0.8569 (0.9627) teacher_loss 0.8643 (0.9610) loss_zs_kd 0.1199 (0.1390) loss_oracle 0.0439 (0.0541) acc 81.2500 (73.8702) kd_loss 0.0366 (0.0464) lr 1.3681e-03 eta 0:14:12
epoch [21/50] batch [280/288] time 0.107 (0.102) data 0.000 (0.001) loss 0.9666 (1.0821) ce_loss 0.8770 (0.9608) teacher_loss 0.8815 (0.9593) loss_zs_kd 0.1050 (0.1384) loss_oracle 0.0326 (0.0537) acc 78.1250 (73.9397) kd_loss 0.0322 (0.0466) lr 1.3681e-03 eta 0:14:11
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,432
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.9%
******* Domain a best val acc:      87.4%, epoch: 19 *******
******* Domain a best val test acc: 83.3%, epoch: 19 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [22/50] batch [20/288] time 0.122 (0.126) data 0.000 (0.014) loss 1.5649 (1.0686) ce_loss 1.4219 (0.9416) teacher_loss 1.4200 (0.9404) loss_zs_kd 0.1582 (0.1525) loss_oracle 0.0658 (0.0519) acc 56.2500 (73.1250) kd_loss 0.0650 (0.0509) lr 1.3090e-03 eta 0:17:25
epoch [22/50] batch [40/288] time 0.113 (0.118) data 0.000 (0.007) loss 0.9758 (1.0486) ce_loss 0.8833 (0.9253) teacher_loss 0.8732 (0.9231) loss_zs_kd 0.1254 (0.1455) loss_oracle 0.0399 (0.0527) acc 84.3750 (73.6719) kd_loss 0.0477 (0.0508) lr 1.3090e-03 eta 0:16:18
epoch [22/50] batch [60/288] time 0.109 (0.115) data 0.000 (0.005) loss 0.7874 (1.0672) ce_loss 0.6406 (0.9423) teacher_loss 0.6451 (0.9401) loss_zs_kd 0.2026 (0.1492) loss_oracle 0.0410 (0.0525) acc 81.2500 (74.1146) kd_loss 0.0436 (0.0506) lr 1.3090e-03 eta 0:15:53
epoch [22/50] batch [80/288] time 0.128 (0.115) data 0.000 (0.004) loss 1.3913 (1.0548) ce_loss 1.2812 (0.9299) teacher_loss 1.2851 (0.9289) loss_zs_kd 0.1557 (0.1493) loss_oracle 0.0283 (0.0513) acc 68.7500 (74.2969) kd_loss 0.0417 (0.0502) lr 1.3090e-03 eta 0:15:55
epoch [22/50] batch [100/288] time 0.134 (0.118) data 0.000 (0.003) loss 0.7561 (1.0511) ce_loss 0.6587 (0.9295) teacher_loss 0.6626 (0.9288) loss_zs_kd 0.0853 (0.1439) loss_oracle 0.0508 (0.0503) acc 78.1250 (74.2188) kd_loss 0.0579 (0.0501) lr 1.3090e-03 eta 0:16:14
epoch [22/50] batch [120/288] time 0.128 (0.120) data 0.001 (0.003) loss 1.1064 (1.0603) ce_loss 0.9565 (0.9375) teacher_loss 0.9636 (0.9374) loss_zs_kd 0.1863 (0.1460) loss_oracle 0.0497 (0.0499) acc 71.8750 (74.2969) kd_loss 0.0475 (0.0500) lr 1.3090e-03 eta 0:16:27
epoch [22/50] batch [140/288] time 0.131 (0.121) data 0.000 (0.002) loss 1.0592 (1.0520) ce_loss 0.9307 (0.9305) teacher_loss 0.9367 (0.9306) loss_zs_kd 0.1625 (0.1436) loss_oracle 0.0413 (0.0496) acc 75.0000 (74.5536) kd_loss 0.0444 (0.0495) lr 1.3090e-03 eta 0:16:36
epoch [22/50] batch [160/288] time 0.136 (0.122) data 0.000 (0.002) loss 0.6991 (1.0634) ce_loss 0.5986 (0.9415) teacher_loss 0.5942 (0.9415) loss_zs_kd 0.1055 (0.1439) loss_oracle 0.0521 (0.0499) acc 84.3750 (74.3555) kd_loss 0.0560 (0.0495) lr 1.3090e-03 eta 0:16:41
epoch [22/50] batch [180/288] time 0.130 (0.123) data 0.000 (0.002) loss 0.9649 (1.0596) ce_loss 0.8662 (0.9372) teacher_loss 0.8681 (0.9373) loss_zs_kd 0.0937 (0.1440) loss_oracle 0.0500 (0.0503) acc 81.2500 (74.5660) kd_loss 0.0514 (0.0500) lr 1.3090e-03 eta 0:16:43
epoch [22/50] batch [200/288] time 0.127 (0.123) data 0.000 (0.002) loss 0.9954 (1.0645) ce_loss 0.8940 (0.9425) teacher_loss 0.8789 (0.9426) loss_zs_kd 0.1323 (0.1434) loss_oracle 0.0504 (0.0502) acc 75.0000 (74.5156) kd_loss 0.0595 (0.0503) lr 1.3090e-03 eta 0:16:45
epoch [22/50] batch [220/288] time 0.126 (0.124) data 0.000 (0.002) loss 0.6565 (1.0643) ce_loss 0.5181 (0.9419) teacher_loss 0.5220 (0.9420) loss_zs_kd 0.1481 (0.1447) loss_oracle 0.0604 (0.0500) acc 90.6250 (74.3608) kd_loss 0.0686 (0.0499) lr 1.3090e-03 eta 0:16:46
epoch [22/50] batch [240/288] time 0.103 (0.123) data 0.000 (0.001) loss 1.1337 (1.0672) ce_loss 1.0078 (0.9451) teacher_loss 1.0130 (0.9453) loss_zs_kd 0.1478 (0.1446) loss_oracle 0.0469 (0.0496) acc 71.8750 (74.2839) kd_loss 0.0500 (0.0494) lr 1.3090e-03 eta 0:16:37
epoch [22/50] batch [260/288] time 0.112 (0.122) data 0.000 (0.001) loss 0.9713 (1.0671) ce_loss 0.8452 (0.9454) teacher_loss 0.8438 (0.9458) loss_zs_kd 0.1385 (0.1435) loss_oracle 0.0582 (0.0495) acc 81.2500 (74.3149) kd_loss 0.0495 (0.0485) lr 1.3090e-03 eta 0:16:23
epoch [22/50] batch [280/288] time 0.108 (0.120) data 0.000 (0.001) loss 0.7178 (1.0696) ce_loss 0.5894 (0.9476) teacher_loss 0.5887 (0.9476) loss_zs_kd 0.1351 (0.1434) loss_oracle 0.0615 (0.0503) acc 84.3750 (74.2188) kd_loss 0.0441 (0.0484) lr 1.3090e-03 eta 0:16:11
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,433
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.9%
******* Domain a best val acc:      87.4%, epoch: 19 *******
******* Domain a best val test acc: 83.3%, epoch: 19 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [23/50] batch [20/288] time 0.106 (0.118) data 0.000 (0.015) loss 1.2445 (1.0434) ce_loss 1.1172 (0.9186) teacher_loss 1.1048 (0.9174) loss_zs_kd 0.1277 (0.1318) loss_oracle 0.0759 (0.0602) acc 71.8750 (74.8438) kd_loss 0.0707 (0.0504) lr 1.2487e-03 eta 0:15:51
epoch [23/50] batch [40/288] time 0.095 (0.110) data 0.000 (0.007) loss 1.0048 (1.0409) ce_loss 0.8740 (0.9156) teacher_loss 0.8804 (0.9147) loss_zs_kd 0.1266 (0.1350) loss_oracle 0.0611 (0.0586) acc 75.0000 (74.7656) kd_loss 0.0645 (0.0521) lr 1.2487e-03 eta 0:14:43
epoch [23/50] batch [60/288] time 0.100 (0.108) data 0.000 (0.005) loss 1.3863 (1.0683) ce_loss 1.2354 (0.9407) teacher_loss 1.2376 (0.9398) loss_zs_kd 0.1945 (0.1411) loss_oracle 0.0515 (0.0579) acc 65.6250 (74.1667) kd_loss 0.0439 (0.0540) lr 1.2487e-03 eta 0:14:27
epoch [23/50] batch [80/288] time 0.093 (0.106) data 0.000 (0.004) loss 1.3560 (1.0596) ce_loss 1.2334 (0.9317) teacher_loss 1.2317 (0.9302) loss_zs_kd 0.1694 (0.1448) loss_oracle 0.0395 (0.0570) acc 65.6250 (74.6484) kd_loss 0.0504 (0.0539) lr 1.2487e-03 eta 0:14:09
epoch [23/50] batch [100/288] time 0.099 (0.106) data 0.000 (0.003) loss 0.8299 (1.0487) ce_loss 0.7046 (0.9202) teacher_loss 0.7139 (0.9186) loss_zs_kd 0.1516 (0.1476) loss_oracle 0.0402 (0.0562) acc 84.3750 (75.0000) kd_loss 0.0520 (0.0556) lr 1.2487e-03 eta 0:14:00
epoch [23/50] batch [120/288] time 0.098 (0.105) data 0.000 (0.003) loss 0.7280 (1.0545) ce_loss 0.5908 (0.9259) teacher_loss 0.5827 (0.9247) loss_zs_kd 0.1660 (0.1492) loss_oracle 0.0622 (0.0552) acc 90.6250 (74.9740) kd_loss 0.0781 (0.0560) lr 1.2487e-03 eta 0:13:55
epoch [23/50] batch [140/288] time 0.107 (0.105) data 0.000 (0.002) loss 0.9793 (1.0500) ce_loss 0.8770 (0.9232) teacher_loss 0.8817 (0.9221) loss_zs_kd 0.1074 (0.1473) loss_oracle 0.0438 (0.0543) acc 78.1250 (75.0223) kd_loss 0.0489 (0.0562) lr 1.2487e-03 eta 0:13:51
epoch [23/50] batch [160/288] time 0.102 (0.105) data 0.000 (0.002) loss 1.0565 (1.0590) ce_loss 0.9463 (0.9329) teacher_loss 0.9540 (0.9314) loss_zs_kd 0.1356 (0.1469) loss_oracle 0.0348 (0.0542) acc 71.8750 (74.7070) kd_loss 0.0456 (0.0562) lr 1.2487e-03 eta 0:13:47
epoch [23/50] batch [180/288] time 0.105 (0.105) data 0.000 (0.002) loss 0.9625 (1.0547) ce_loss 0.8750 (0.9292) teacher_loss 0.8621 (0.9280) loss_zs_kd 0.0872 (0.1459) loss_oracle 0.0568 (0.0538) acc 75.0000 (74.8958) kd_loss 0.0623 (0.0563) lr 1.2487e-03 eta 0:13:45
epoch [23/50] batch [200/288] time 0.113 (0.105) data 0.001 (0.002) loss 0.9165 (1.0551) ce_loss 0.7910 (0.9297) teacher_loss 0.7955 (0.9288) loss_zs_kd 0.1541 (0.1456) loss_oracle 0.0439 (0.0536) acc 75.0000 (75.0156) kd_loss 0.0578 (0.0559) lr 1.2487e-03 eta 0:13:43
epoch [23/50] batch [220/288] time 0.100 (0.105) data 0.000 (0.002) loss 1.2721 (1.0565) ce_loss 1.1592 (0.9315) teacher_loss 1.1611 (0.9306) loss_zs_kd 0.1395 (0.1452) loss_oracle 0.0412 (0.0533) acc 68.7500 (74.8864) kd_loss 0.0295 (0.0552) lr 1.2487e-03 eta 0:13:41
epoch [23/50] batch [240/288] time 0.105 (0.105) data 0.000 (0.001) loss 0.9053 (1.0634) ce_loss 0.7725 (0.9394) teacher_loss 0.7592 (0.9385) loss_zs_kd 0.1448 (0.1439) loss_oracle 0.0737 (0.0530) acc 75.0000 (74.7526) kd_loss 0.0750 (0.0549) lr 1.2487e-03 eta 0:13:39
epoch [23/50] batch [260/288] time 0.110 (0.105) data 0.000 (0.001) loss 0.7861 (1.0720) ce_loss 0.6362 (0.9479) teacher_loss 0.6447 (0.9466) loss_zs_kd 0.1489 (0.1443) loss_oracle 0.0670 (0.0533) acc 84.3750 (74.4471) kd_loss 0.0535 (0.0542) lr 1.2487e-03 eta 0:13:38
epoch [23/50] batch [280/288] time 0.106 (0.105) data 0.000 (0.001) loss 1.0421 (1.0653) ce_loss 0.8872 (0.9414) teacher_loss 0.8838 (0.9401) loss_zs_kd 0.1990 (0.1444) loss_oracle 0.0589 (0.0529) acc 71.8750 (74.5759) kd_loss 0.0497 (0.0534) lr 1.2487e-03 eta 0:13:35
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,442
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.8%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,024
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.1%
******* Domain a best val acc:      87.4%, epoch: 23 *******
******* Domain a best val test acc: 83.4%, epoch: 23 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [24/50] batch [20/288] time 0.108 (0.125) data 0.000 (0.016) loss 1.1351 (1.0370) ce_loss 1.0459 (0.9187) teacher_loss 1.0383 (0.9172) loss_zs_kd 0.1239 (0.1308) loss_oracle 0.0349 (0.0544) acc 78.1250 (74.3750) kd_loss 0.0311 (0.0469) lr 1.1874e-03 eta 0:16:06
epoch [24/50] batch [40/288] time 0.102 (0.112) data 0.000 (0.008) loss 1.1243 (1.0824) ce_loss 0.9790 (0.9604) teacher_loss 0.9906 (0.9591) loss_zs_kd 0.1636 (0.1345) loss_oracle 0.0518 (0.0561) acc 71.8750 (73.8281) kd_loss 0.0568 (0.0493) lr 1.1874e-03 eta 0:14:27
epoch [24/50] batch [60/288] time 0.099 (0.107) data 0.000 (0.006) loss 0.9962 (1.0925) ce_loss 0.9014 (0.9686) teacher_loss 0.9023 (0.9676) loss_zs_kd 0.1251 (0.1401) loss_oracle 0.0314 (0.0549) acc 81.2500 (74.0104) kd_loss 0.0371 (0.0496) lr 1.1874e-03 eta 0:13:48
epoch [24/50] batch [80/288] time 0.103 (0.106) data 0.000 (0.004) loss 0.9771 (1.0666) ce_loss 0.8428 (0.9434) teacher_loss 0.8439 (0.9431) loss_zs_kd 0.1622 (0.1396) loss_oracle 0.0522 (0.0537) acc 75.0000 (74.3359) kd_loss 0.0622 (0.0500) lr 1.1874e-03 eta 0:13:39
epoch [24/50] batch [100/288] time 0.095 (0.105) data 0.000 (0.003) loss 0.9436 (1.0647) ce_loss 0.7778 (0.9431) teacher_loss 0.7829 (0.9418) loss_zs_kd 0.1761 (0.1386) loss_oracle 0.0726 (0.0535) acc 81.2500 (74.3125) kd_loss 0.0690 (0.0509) lr 1.1874e-03 eta 0:13:26
epoch [24/50] batch [120/288] time 0.099 (0.104) data 0.000 (0.003) loss 1.0952 (1.0543) ce_loss 0.9697 (0.9334) teacher_loss 0.9806 (0.9317) loss_zs_kd 0.1117 (0.1389) loss_oracle 0.0587 (0.0531) acc 68.7500 (74.6094) kd_loss 0.0588 (0.0513) lr 1.1874e-03 eta 0:13:14
epoch [24/50] batch [140/288] time 0.099 (0.103) data 0.000 (0.003) loss 1.0723 (1.0510) ce_loss 0.9492 (0.9289) teacher_loss 0.9530 (0.9272) loss_zs_kd 0.1251 (0.1413) loss_oracle 0.0567 (0.0531) acc 78.1250 (74.7545) kd_loss 0.0624 (0.0522) lr 1.1874e-03 eta 0:13:05
epoch [24/50] batch [160/288] time 0.095 (0.102) data 0.000 (0.002) loss 1.2133 (1.0574) ce_loss 1.0908 (0.9331) teacher_loss 1.1118 (0.9320) loss_zs_kd 0.1194 (0.1442) loss_oracle 0.0417 (0.0533) acc 62.5000 (74.6289) kd_loss 0.0414 (0.0529) lr 1.1874e-03 eta 0:12:59
epoch [24/50] batch [180/288] time 0.096 (0.102) data 0.000 (0.002) loss 0.9470 (1.0699) ce_loss 0.8389 (0.9458) teacher_loss 0.8303 (0.9441) loss_zs_kd 0.1140 (0.1435) loss_oracle 0.0597 (0.0540) acc 75.0000 (74.3229) kd_loss 0.0640 (0.0540) lr 1.1874e-03 eta 0:12:54
epoch [24/50] batch [200/288] time 0.095 (0.102) data 0.000 (0.002) loss 1.0291 (1.0709) ce_loss 0.8970 (0.9472) teacher_loss 0.8940 (0.9456) loss_zs_kd 0.1362 (0.1429) loss_oracle 0.0670 (0.0539) acc 75.0000 (74.2344) kd_loss 0.0725 (0.0545) lr 1.1874e-03 eta 0:12:50
epoch [24/50] batch [220/288] time 0.099 (0.101) data 0.000 (0.002) loss 0.9289 (1.0707) ce_loss 0.7900 (0.9476) teacher_loss 0.7995 (0.9459) loss_zs_kd 0.1505 (0.1428) loss_oracle 0.0542 (0.0534) acc 78.1250 (74.2756) kd_loss 0.0550 (0.0547) lr 1.1874e-03 eta 0:12:46
epoch [24/50] batch [240/288] time 0.092 (0.101) data 0.000 (0.002) loss 0.8889 (1.0714) ce_loss 0.7607 (0.9482) teacher_loss 0.7697 (0.9462) loss_zs_kd 0.1356 (0.1425) loss_oracle 0.0514 (0.0540) acc 84.3750 (74.2318) kd_loss 0.0468 (0.0552) lr 1.1874e-03 eta 0:12:42
epoch [24/50] batch [260/288] time 0.093 (0.101) data 0.000 (0.001) loss 0.6539 (1.0743) ce_loss 0.5332 (0.9515) teacher_loss 0.5351 (0.9491) loss_zs_kd 0.1502 (0.1420) loss_oracle 0.0437 (0.0542) acc 87.5000 (74.1226) kd_loss 0.0568 (0.0559) lr 1.1874e-03 eta 0:12:38
epoch [24/50] batch [280/288] time 0.089 (0.100) data 0.000 (0.001) loss 0.9769 (1.0769) ce_loss 0.8931 (0.9539) teacher_loss 0.8495 (0.9513) loss_zs_kd 0.1387 (0.1424) loss_oracle 0.0581 (0.0543) acc 75.0000 (74.1183) kd_loss 0.0791 (0.0566) lr 1.1874e-03 eta 0:12:32
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,442
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,026
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 80.3%
******* Domain a best val acc:      87.4%, epoch: 23 *******
******* Domain a best val test acc: 83.4%, epoch: 23 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [25/50] batch [20/288] time 0.131 (0.146) data 0.000 (0.014) loss 1.4025 (1.0822) ce_loss 1.2754 (0.9578) teacher_loss 1.2496 (0.9528) loss_zs_kd 0.1458 (0.1416) loss_oracle 0.0799 (0.0586) acc 65.6250 (73.7500) kd_loss 0.0705 (0.0643) lr 1.1253e-03 eta 0:18:07
epoch [25/50] batch [40/288] time 0.126 (0.136) data 0.000 (0.007) loss 0.8254 (1.0847) ce_loss 0.7017 (0.9615) teacher_loss 0.7034 (0.9569) loss_zs_kd 0.1251 (0.1398) loss_oracle 0.0595 (0.0579) acc 84.3750 (74.1406) kd_loss 0.0715 (0.0623) lr 1.1253e-03 eta 0:16:54
epoch [25/50] batch [60/288] time 0.129 (0.133) data 0.000 (0.005) loss 1.4862 (1.1027) ce_loss 1.3701 (0.9790) teacher_loss 1.3716 (0.9750) loss_zs_kd 0.1366 (0.1392) loss_oracle 0.0463 (0.0581) acc 53.1250 (73.3854) kd_loss 0.0382 (0.0616) lr 1.1253e-03 eta 0:16:25
epoch [25/50] batch [80/288] time 0.123 (0.132) data 0.001 (0.004) loss 1.1788 (1.1027) ce_loss 0.9917 (0.9773) teacher_loss 0.9966 (0.9739) loss_zs_kd 0.2171 (0.1406) loss_oracle 0.0738 (0.0585) acc 78.1250 (73.7109) kd_loss 0.0704 (0.0616) lr 1.1253e-03 eta 0:16:14
epoch [25/50] batch [100/288] time 0.127 (0.130) data 0.000 (0.003) loss 0.9730 (1.1046) ce_loss 0.8442 (0.9737) teacher_loss 0.8475 (0.9707) loss_zs_kd 0.1561 (0.1458) loss_oracle 0.0474 (0.0610) acc 71.8750 (73.8438) kd_loss 0.0665 (0.0630) lr 1.1253e-03 eta 0:16:03
epoch [25/50] batch [120/288] time 0.125 (0.130) data 0.000 (0.003) loss 1.2466 (1.0923) ce_loss 1.1445 (0.9630) teacher_loss 1.1443 (0.9604) loss_zs_kd 0.1242 (0.1437) loss_oracle 0.0402 (0.0599) acc 68.7500 (74.1146) kd_loss 0.0432 (0.0629) lr 1.1253e-03 eta 0:15:56
epoch [25/50] batch [140/288] time 0.128 (0.129) data 0.000 (0.002) loss 0.5326 (1.0924) ce_loss 0.4255 (0.9639) teacher_loss 0.4260 (0.9614) loss_zs_kd 0.1030 (0.1437) loss_oracle 0.0551 (0.0592) acc 87.5000 (74.2857) kd_loss 0.0638 (0.0631) lr 1.1253e-03 eta 0:15:49
epoch [25/50] batch [160/288] time 0.133 (0.129) data 0.000 (0.002) loss 0.9602 (1.0793) ce_loss 0.8501 (0.9517) teacher_loss 0.8351 (0.9492) loss_zs_kd 0.1256 (0.1432) loss_oracle 0.0623 (0.0585) acc 78.1250 (74.5312) kd_loss 0.0685 (0.0627) lr 1.1253e-03 eta 0:15:45
epoch [25/50] batch [180/288] time 0.128 (0.128) data 0.000 (0.002) loss 1.1699 (1.0837) ce_loss 1.0264 (0.9567) teacher_loss 1.0214 (0.9541) loss_zs_kd 0.1441 (0.1428) loss_oracle 0.0764 (0.0582) acc 71.8750 (74.5139) kd_loss 0.0697 (0.0627) lr 1.1253e-03 eta 0:15:38
epoch [25/50] batch [200/288] time 0.129 (0.128) data 0.000 (0.002) loss 0.7660 (1.0794) ce_loss 0.6157 (0.9527) teacher_loss 0.6070 (0.9498) loss_zs_kd 0.1807 (0.1427) loss_oracle 0.0687 (0.0581) acc 84.3750 (74.5625) kd_loss 0.0465 (0.0624) lr 1.1253e-03 eta 0:15:32
epoch [25/50] batch [220/288] time 0.117 (0.127) data 0.000 (0.002) loss 0.9983 (1.0732) ce_loss 0.8276 (0.9468) teacher_loss 0.8319 (0.9438) loss_zs_kd 0.1883 (0.1429) loss_oracle 0.0723 (0.0579) acc 81.2500 (74.6307) kd_loss 0.0666 (0.0620) lr 1.1253e-03 eta 0:15:24
epoch [25/50] batch [240/288] time 0.130 (0.126) data 0.001 (0.002) loss 1.5173 (1.0751) ce_loss 1.3945 (0.9482) teacher_loss 1.3979 (0.9453) loss_zs_kd 0.1457 (0.1430) loss_oracle 0.0466 (0.0582) acc 62.5000 (74.6094) kd_loss 0.0570 (0.0618) lr 1.1253e-03 eta 0:15:16
epoch [25/50] batch [260/288] time 0.117 (0.126) data 0.001 (0.001) loss 0.9637 (1.0741) ce_loss 0.8354 (0.9462) teacher_loss 0.8347 (0.9437) loss_zs_kd 0.1316 (0.1439) loss_oracle 0.0632 (0.0585) acc 81.2500 (74.7356) kd_loss 0.0618 (0.0622) lr 1.1253e-03 eta 0:15:11
epoch [25/50] batch [280/288] time 0.106 (0.125) data 0.000 (0.001) loss 1.1480 (1.0723) ce_loss 1.0322 (0.9442) teacher_loss 1.0332 (0.9420) loss_zs_kd 0.1159 (0.1438) loss_oracle 0.0569 (0.0584) acc 75.0000 (74.8996) kd_loss 0.0669 (0.0627) lr 1.1253e-03 eta 0:15:02
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,433
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,019
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 80.0%
******* Domain a best val acc:      87.4%, epoch: 23 *******
******* Domain a best val test acc: 83.4%, epoch: 23 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [26/50] batch [20/288] time 0.131 (0.144) data 0.000 (0.015) loss 0.7849 (0.9433) ce_loss 0.6895 (0.8127) teacher_loss 0.6920 (0.8178) loss_zs_kd 0.0817 (0.1407) loss_oracle 0.0520 (0.0552) acc 78.1250 (78.1250) kd_loss 0.0632 (0.0647) lr 1.0628e-03 eta 0:17:16
epoch [26/50] batch [40/288] time 0.130 (0.137) data 0.000 (0.008) loss 1.0935 (1.0069) ce_loss 1.0029 (0.8807) teacher_loss 1.0032 (0.8816) loss_zs_kd 0.0860 (0.1395) loss_oracle 0.0472 (0.0556) acc 71.8750 (75.4688) kd_loss 0.0437 (0.0636) lr 1.0628e-03 eta 0:16:20
epoch [26/50] batch [60/288] time 0.125 (0.134) data 0.000 (0.005) loss 1.1185 (1.0196) ce_loss 0.9946 (0.8957) teacher_loss 0.9913 (0.8944) loss_zs_kd 0.1300 (0.1410) loss_oracle 0.0622 (0.0547) acc 65.6250 (75.5208) kd_loss 0.0745 (0.0611) lr 1.0628e-03 eta 0:15:56
epoch [26/50] batch [80/288] time 0.129 (0.133) data 0.000 (0.004) loss 1.4703 (1.0289) ce_loss 1.3457 (0.9047) teacher_loss 1.3414 (0.9030) loss_zs_kd 0.1472 (0.1417) loss_oracle 0.0553 (0.0550) acc 71.8750 (75.4297) kd_loss 0.0817 (0.0609) lr 1.0628e-03 eta 0:15:43
epoch [26/50] batch [100/288] time 0.129 (0.132) data 0.000 (0.003) loss 0.8448 (1.0416) ce_loss 0.7588 (0.9180) teacher_loss 0.7469 (0.9159) loss_zs_kd 0.0969 (0.1414) loss_oracle 0.0495 (0.0550) acc 81.2500 (75.0625) kd_loss 0.0545 (0.0598) lr 1.0628e-03 eta 0:15:38
epoch [26/50] batch [120/288] time 0.131 (0.132) data 0.000 (0.003) loss 1.0209 (1.0447) ce_loss 0.8726 (0.9213) teacher_loss 0.8506 (0.9190) loss_zs_kd 0.2194 (0.1417) loss_oracle 0.0606 (0.0549) acc 75.0000 (75.0000) kd_loss 0.0456 (0.0593) lr 1.0628e-03 eta 0:15:35
epoch [26/50] batch [140/288] time 0.128 (0.131) data 0.001 (0.003) loss 1.1243 (1.0406) ce_loss 0.9834 (0.9167) teacher_loss 0.9922 (0.9145) loss_zs_kd 0.1321 (0.1416) loss_oracle 0.0661 (0.0553) acc 81.2500 (75.3348) kd_loss 0.0558 (0.0590) lr 1.0628e-03 eta 0:15:24
epoch [26/50] batch [160/288] time 0.107 (0.131) data 0.000 (0.002) loss 1.3084 (1.0419) ce_loss 1.1270 (0.9163) teacher_loss 1.1402 (0.9145) loss_zs_kd 0.1866 (0.1426) loss_oracle 0.0749 (0.0561) acc 71.8750 (75.3711) kd_loss 0.0523 (0.0586) lr 1.0628e-03 eta 0:15:20
epoch [26/50] batch [180/288] time 0.126 (0.129) data 0.000 (0.002) loss 0.9111 (1.0417) ce_loss 0.7935 (0.9157) teacher_loss 0.7891 (0.9139) loss_zs_kd 0.1110 (0.1426) loss_oracle 0.0665 (0.0565) acc 78.1250 (75.2257) kd_loss 0.0793 (0.0590) lr 1.0628e-03 eta 0:15:06
epoch [26/50] batch [200/288] time 0.105 (0.128) data 0.001 (0.002) loss 1.0134 (1.0457) ce_loss 0.8682 (0.9191) teacher_loss 0.8877 (0.9175) loss_zs_kd 0.1396 (0.1431) loss_oracle 0.0559 (0.0566) acc 84.3750 (75.1875) kd_loss 0.0529 (0.0594) lr 1.0628e-03 eta 0:14:53
epoch [26/50] batch [220/288] time 0.119 (0.126) data 0.000 (0.002) loss 0.4616 (1.0478) ce_loss 0.3394 (0.9210) teacher_loss 0.3493 (0.9196) loss_zs_kd 0.1059 (0.1434) loss_oracle 0.0594 (0.0564) acc 93.7500 (75.0852) kd_loss 0.0689 (0.0592) lr 1.0628e-03 eta 0:14:41
epoch [26/50] batch [240/288] time 0.100 (0.124) data 0.000 (0.002) loss 1.0708 (1.0533) ce_loss 0.9272 (0.9266) teacher_loss 0.9330 (0.9251) loss_zs_kd 0.1667 (0.1439) loss_oracle 0.0545 (0.0562) acc 75.0000 (74.9219) kd_loss 0.0572 (0.0588) lr 1.0628e-03 eta 0:14:24
epoch [26/50] batch [260/288] time 0.106 (0.123) data 0.000 (0.002) loss 1.0476 (1.0622) ce_loss 0.9258 (0.9351) teacher_loss 0.9123 (0.9332) loss_zs_kd 0.1579 (0.1456) loss_oracle 0.0564 (0.0562) acc 75.0000 (74.5793) kd_loss 0.0676 (0.0584) lr 1.0628e-03 eta 0:14:10
epoch [26/50] batch [280/288] time 0.104 (0.121) data 0.000 (0.001) loss 1.2193 (1.0654) ce_loss 1.0840 (0.9381) teacher_loss 1.0691 (0.9360) loss_zs_kd 0.1758 (0.1467) loss_oracle 0.0624 (0.0561) acc 65.6250 (74.5759) kd_loss 0.0618 (0.0581) lr 1.0628e-03 eta 0:13:57
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,444
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.9%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,028
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.4%
******* Domain a best val acc:      87.4%, epoch: 26 *******
******* Domain a best val test acc: 83.6%, epoch: 26 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [27/50] batch [20/288] time 0.113 (0.127) data 0.000 (0.020) loss 0.7734 (1.0331) ce_loss 0.6274 (0.8924) teacher_loss 0.6268 (0.8885) loss_zs_kd 0.1668 (0.1633) loss_oracle 0.0632 (0.0630) acc 78.1250 (76.5625) kd_loss 0.0779 (0.0672) lr 1.0000e-03 eta 0:14:36
epoch [27/50] batch [40/288] time 0.100 (0.116) data 0.000 (0.010) loss 0.5647 (1.0797) ce_loss 0.4519 (0.9479) teacher_loss 0.4459 (0.9446) loss_zs_kd 0.0860 (0.1503) loss_oracle 0.0758 (0.0600) acc 90.6250 (74.9219) kd_loss 0.0747 (0.0611) lr 1.0000e-03 eta 0:13:14
epoch [27/50] batch [60/288] time 0.103 (0.111) data 0.001 (0.007) loss 1.4658 (1.0606) ce_loss 1.2754 (0.9312) teacher_loss 1.2704 (0.9261) loss_zs_kd 0.2365 (0.1499) loss_oracle 0.0771 (0.0596) acc 62.5000 (74.8438) kd_loss 0.0750 (0.0604) lr 1.0000e-03 eta 0:12:42
epoch [27/50] batch [80/288] time 0.100 (0.109) data 0.000 (0.005) loss 0.8920 (1.0497) ce_loss 0.7793 (0.9231) teacher_loss 0.7641 (0.9189) loss_zs_kd 0.1496 (0.1459) loss_oracle 0.0531 (0.0579) acc 78.1250 (74.7656) kd_loss 0.0601 (0.0584) lr 1.0000e-03 eta 0:12:25
epoch [27/50] batch [100/288] time 0.099 (0.108) data 0.000 (0.004) loss 0.9358 (1.0580) ce_loss 0.7598 (0.9312) teacher_loss 0.7554 (0.9271) loss_zs_kd 0.2052 (0.1462) loss_oracle 0.0778 (0.0578) acc 81.2500 (74.6250) kd_loss 0.0489 (0.0571) lr 1.0000e-03 eta 0:12:18
epoch [27/50] batch [120/288] time 0.099 (0.108) data 0.000 (0.004) loss 0.8712 (1.0363) ce_loss 0.7451 (0.9104) teacher_loss 0.7383 (0.9061) loss_zs_kd 0.1469 (0.1447) loss_oracle 0.0594 (0.0578) acc 87.5000 (75.4688) kd_loss 0.0582 (0.0568) lr 1.0000e-03 eta 0:12:12
epoch [27/50] batch [140/288] time 0.103 (0.107) data 0.000 (0.003) loss 1.0855 (1.0485) ce_loss 0.9072 (0.9214) teacher_loss 0.9037 (0.9170) loss_zs_kd 0.2276 (0.1467) loss_oracle 0.0680 (0.0582) acc 71.8750 (75.3571) kd_loss 0.0515 (0.0563) lr 1.0000e-03 eta 0:12:07
epoch [27/50] batch [160/288] time 0.101 (0.107) data 0.000 (0.003) loss 1.0470 (1.0482) ce_loss 0.8896 (0.9193) teacher_loss 0.8977 (0.9149) loss_zs_kd 0.1679 (0.1473) loss_oracle 0.0654 (0.0597) acc 71.8750 (75.3906) kd_loss 0.0531 (0.0571) lr 1.0000e-03 eta 0:12:03
epoch [27/50] batch [180/288] time 0.110 (0.107) data 0.000 (0.002) loss 0.8724 (1.0527) ce_loss 0.7427 (0.9231) teacher_loss 0.7518 (0.9190) loss_zs_kd 0.1430 (0.1475) loss_oracle 0.0491 (0.0599) acc 75.0000 (75.3819) kd_loss 0.0441 (0.0575) lr 1.0000e-03 eta 0:11:58
epoch [27/50] batch [200/288] time 0.099 (0.106) data 0.000 (0.002) loss 1.1167 (1.0463) ce_loss 0.9736 (0.9164) teacher_loss 0.9724 (0.9122) loss_zs_kd 0.1168 (0.1472) loss_oracle 0.0858 (0.0605) acc 75.0000 (75.5156) kd_loss 0.0706 (0.0579) lr 1.0000e-03 eta 0:11:54
epoch [27/50] batch [220/288] time 0.102 (0.106) data 0.000 (0.002) loss 1.1361 (1.0461) ce_loss 0.8877 (0.9154) teacher_loss 0.8893 (0.9112) loss_zs_kd 0.2750 (0.1469) loss_oracle 0.1094 (0.0615) acc 84.3750 (75.5540) kd_loss 0.1010 (0.0589) lr 1.0000e-03 eta 0:11:50
epoch [27/50] batch [240/288] time 0.104 (0.106) data 0.000 (0.002) loss 0.7423 (1.0593) ce_loss 0.6157 (0.9283) teacher_loss 0.6062 (0.9242) loss_zs_kd 0.0960 (0.1470) loss_oracle 0.0882 (0.0617) acc 81.2500 (75.1302) kd_loss 0.0750 (0.0597) lr 1.0000e-03 eta 0:11:47
epoch [27/50] batch [260/288] time 0.099 (0.106) data 0.000 (0.002) loss 0.8559 (1.0607) ce_loss 0.7158 (0.9294) teacher_loss 0.7192 (0.9255) loss_zs_kd 0.1143 (0.1467) loss_oracle 0.0796 (0.0618) acc 78.1250 (75.1442) kd_loss 0.0948 (0.0607) lr 1.0000e-03 eta 0:11:44
epoch [27/50] batch [280/288] time 0.107 (0.106) data 0.000 (0.002) loss 1.4375 (1.0654) ce_loss 1.2881 (0.9342) teacher_loss 1.2632 (0.9302) loss_zs_kd 0.1991 (0.1466) loss_oracle 0.0748 (0.0619) acc 53.1250 (75.0000) kd_loss 0.0734 (0.0606) lr 1.0000e-03 eta 0:11:41
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,440
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 80.0%
******* Domain a best val acc:      87.4%, epoch: 26 *******
******* Domain a best val test acc: 83.6%, epoch: 26 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [28/50] batch [20/288] time 0.093 (0.122) data 0.000 (0.018) loss 0.8880 (1.0450) ce_loss 0.7593 (0.9051) teacher_loss 0.7581 (0.9016) loss_zs_kd 0.1121 (0.1579) loss_oracle 0.0738 (0.0645) acc 78.1250 (75.6250) kd_loss 0.0766 (0.0696) lr 9.3721e-04 eta 0:13:26
epoch [28/50] batch [40/288] time 0.101 (0.112) data 0.000 (0.009) loss 0.7443 (1.0767) ce_loss 0.6177 (0.9443) teacher_loss 0.6239 (0.9419) loss_zs_kd 0.1164 (0.1409) loss_oracle 0.0621 (0.0643) acc 84.3750 (74.6875) kd_loss 0.0630 (0.0682) lr 9.3721e-04 eta 0:12:17
epoch [28/50] batch [60/288] time 0.097 (0.108) data 0.000 (0.006) loss 0.8904 (1.0883) ce_loss 0.7520 (0.9565) teacher_loss 0.7593 (0.9536) loss_zs_kd 0.1644 (0.1412) loss_oracle 0.0488 (0.0641) acc 78.1250 (74.4271) kd_loss 0.0698 (0.0684) lr 9.3721e-04 eta 0:11:50
epoch [28/50] batch [80/288] time 0.102 (0.107) data 0.000 (0.005) loss 0.8927 (1.0956) ce_loss 0.7769 (0.9643) teacher_loss 0.7856 (0.9617) loss_zs_kd 0.1292 (0.1428) loss_oracle 0.0426 (0.0625) acc 68.7500 (74.1797) kd_loss 0.0509 (0.0667) lr 9.3721e-04 eta 0:11:40
epoch [28/50] batch [100/288] time 0.102 (0.106) data 0.000 (0.004) loss 0.8951 (1.0826) ce_loss 0.7930 (0.9512) teacher_loss 0.7999 (0.9491) loss_zs_kd 0.0937 (0.1431) loss_oracle 0.0483 (0.0620) acc 81.2500 (74.6875) kd_loss 0.0791 (0.0664) lr 9.3721e-04 eta 0:11:32
epoch [28/50] batch [120/288] time 0.102 (0.106) data 0.000 (0.003) loss 0.9690 (1.0677) ce_loss 0.8643 (0.9377) teacher_loss 0.8543 (0.9354) loss_zs_kd 0.1141 (0.1407) loss_oracle 0.0576 (0.0620) acc 78.1250 (74.9479) kd_loss 0.0658 (0.0666) lr 9.3721e-04 eta 0:11:27
epoch [28/50] batch [140/288] time 0.101 (0.105) data 0.000 (0.003) loss 0.5793 (1.0618) ce_loss 0.4424 (0.9308) teacher_loss 0.4464 (0.9290) loss_zs_kd 0.1153 (0.1422) loss_oracle 0.0752 (0.0616) acc 93.7500 (75.2679) kd_loss 0.0700 (0.0654) lr 9.3721e-04 eta 0:11:22
epoch [28/50] batch [160/288] time 0.100 (0.105) data 0.000 (0.003) loss 1.3833 (1.0523) ce_loss 1.2275 (0.9208) teacher_loss 1.2219 (0.9189) loss_zs_kd 0.1703 (0.1425) loss_oracle 0.0762 (0.0622) acc 62.5000 (75.5273) kd_loss 0.0589 (0.0650) lr 9.3721e-04 eta 0:11:20
epoch [28/50] batch [180/288] time 0.105 (0.105) data 0.000 (0.002) loss 0.9124 (1.0487) ce_loss 0.7559 (0.9156) teacher_loss 0.7497 (0.9140) loss_zs_kd 0.2105 (0.1440) loss_oracle 0.0575 (0.0627) acc 75.0000 (75.6597) kd_loss 0.0558 (0.0645) lr 9.3721e-04 eta 0:11:18
epoch [28/50] batch [200/288] time 0.103 (0.105) data 0.001 (0.002) loss 1.4956 (1.0588) ce_loss 1.3262 (0.9241) teacher_loss 1.3182 (0.9221) loss_zs_kd 0.1960 (0.1454) loss_oracle 0.0794 (0.0640) acc 68.7500 (75.6250) kd_loss 0.0669 (0.0645) lr 9.3721e-04 eta 0:11:16
epoch [28/50] batch [220/288] time 0.093 (0.105) data 0.000 (0.002) loss 1.0539 (1.0584) ce_loss 0.9487 (0.9238) teacher_loss 0.9468 (0.9216) loss_zs_kd 0.1159 (0.1458) loss_oracle 0.0492 (0.0639) acc 81.2500 (75.6818) kd_loss 0.0478 (0.0646) lr 9.3721e-04 eta 0:11:12
epoch [28/50] batch [240/288] time 0.108 (0.105) data 0.000 (0.002) loss 0.5373 (1.0591) ce_loss 0.3921 (0.9241) teacher_loss 0.4070 (0.9221) loss_zs_kd 0.1283 (0.1463) loss_oracle 0.0661 (0.0639) acc 93.7500 (75.5990) kd_loss 0.0621 (0.0647) lr 9.3721e-04 eta 0:11:07
epoch [28/50] batch [260/288] time 0.088 (0.104) data 0.000 (0.002) loss 0.8322 (1.0633) ce_loss 0.6963 (0.9278) teacher_loss 0.6895 (0.9255) loss_zs_kd 0.1329 (0.1463) loss_oracle 0.0762 (0.0647) acc 78.1250 (75.6611) kd_loss 0.0644 (0.0654) lr 9.3721e-04 eta 0:11:02
epoch [28/50] batch [280/288] time 0.086 (0.103) data 0.000 (0.002) loss 0.9424 (1.0634) ce_loss 0.7876 (0.9267) teacher_loss 0.7845 (0.9241) loss_zs_kd 0.1419 (0.1473) loss_oracle 0.0870 (0.0656) acc 78.1250 (75.6027) kd_loss 0.0795 (0.0664) lr 9.3721e-04 eta 0:10:54
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,442
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,015
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 79.9%
******* Domain a best val acc:      87.4%, epoch: 26 *******
******* Domain a best val test acc: 83.6%, epoch: 26 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [29/50] batch [20/288] time 0.098 (0.121) data 0.000 (0.015) loss 0.8081 (0.9603) ce_loss 0.6313 (0.8141) teacher_loss 0.6329 (0.8154) loss_zs_kd 0.2114 (0.1504) loss_oracle 0.0694 (0.0697) acc 78.1250 (78.9062) kd_loss 0.0930 (0.0880) lr 8.7467e-04 eta 0:12:44
epoch [29/50] batch [40/288] time 0.112 (0.112) data 0.000 (0.008) loss 0.9507 (1.0586) ce_loss 0.8042 (0.9166) teacher_loss 0.7998 (0.9155) loss_zs_kd 0.1238 (0.1461) loss_oracle 0.0891 (0.0701) acc 78.1250 (76.0156) kd_loss 0.1103 (0.0851) lr 8.7467e-04 eta 0:11:45
epoch [29/50] batch [60/288] time 0.103 (0.108) data 0.000 (0.005) loss 1.8062 (1.0940) ce_loss 1.6602 (0.9538) teacher_loss 1.6623 (0.9506) loss_zs_kd 0.1527 (0.1423) loss_oracle 0.0675 (0.0723) acc 62.5000 (74.6354) kd_loss 0.0831 (0.0864) lr 8.7467e-04 eta 0:11:19
epoch [29/50] batch [80/288] time 0.098 (0.107) data 0.000 (0.004) loss 0.8204 (1.0956) ce_loss 0.6650 (0.9536) teacher_loss 0.6707 (0.9506) loss_zs_kd 0.1815 (0.1470) loss_oracle 0.0589 (0.0714) acc 87.5000 (74.1406) kd_loss 0.0722 (0.0859) lr 8.7467e-04 eta 0:11:11
epoch [29/50] batch [100/288] time 0.103 (0.106) data 0.000 (0.003) loss 1.4853 (1.1134) ce_loss 1.3320 (0.9698) teacher_loss 1.3221 (0.9668) loss_zs_kd 0.1518 (0.1493) loss_oracle 0.0873 (0.0720) acc 71.8750 (74.0312) kd_loss 0.0835 (0.0861) lr 8.7467e-04 eta 0:11:02
epoch [29/50] batch [120/288] time 0.110 (0.105) data 0.000 (0.003) loss 0.9912 (1.0998) ce_loss 0.8379 (0.9562) teacher_loss 0.8405 (0.9534) loss_zs_kd 0.0990 (0.1478) loss_oracle 0.1012 (0.0725) acc 78.1250 (74.5312) kd_loss 0.1435 (0.0872) lr 8.7467e-04 eta 0:10:55
epoch [29/50] batch [140/288] time 0.103 (0.105) data 0.000 (0.002) loss 1.1275 (1.0902) ce_loss 1.0283 (0.9475) teacher_loss 1.0182 (0.9448) loss_zs_kd 0.0901 (0.1458) loss_oracle 0.0642 (0.0725) acc 65.6250 (74.6652) kd_loss 0.1015 (0.0877) lr 8.7467e-04 eta 0:10:50
epoch [29/50] batch [160/288] time 0.103 (0.105) data 0.000 (0.002) loss 0.8908 (1.0880) ce_loss 0.7305 (0.9446) teacher_loss 0.7136 (0.9418) loss_zs_kd 0.1819 (0.1470) loss_oracle 0.0863 (0.0727) acc 78.1250 (74.7852) kd_loss 0.1082 (0.0888) lr 8.7467e-04 eta 0:10:46
epoch [29/50] batch [180/288] time 0.113 (0.105) data 0.000 (0.002) loss 1.3366 (1.0958) ce_loss 1.1641 (0.9520) teacher_loss 1.1804 (0.9491) loss_zs_kd 0.1571 (0.1477) loss_oracle 0.0777 (0.0728) acc 62.5000 (74.7049) kd_loss 0.1016 (0.0900) lr 8.7467e-04 eta 0:10:45
epoch [29/50] batch [200/288] time 0.098 (0.105) data 0.000 (0.002) loss 1.2465 (1.0908) ce_loss 1.1182 (0.9469) teacher_loss 1.1037 (0.9444) loss_zs_kd 0.1329 (0.1478) loss_oracle 0.0764 (0.0726) acc 68.7500 (74.9062) kd_loss 0.1006 (0.0903) lr 8.7467e-04 eta 0:10:41
epoch [29/50] batch [220/288] time 0.098 (0.104) data 0.000 (0.002) loss 1.1345 (1.0939) ce_loss 0.9717 (0.9504) teacher_loss 0.9801 (0.9481) loss_zs_kd 0.1718 (0.1470) loss_oracle 0.0685 (0.0724) acc 71.8750 (74.8722) kd_loss 0.1029 (0.0906) lr 8.7467e-04 eta 0:10:37
epoch [29/50] batch [240/288] time 0.099 (0.104) data 0.000 (0.002) loss 1.0188 (1.0941) ce_loss 0.8911 (0.9509) teacher_loss 0.8935 (0.9487) loss_zs_kd 0.1238 (0.1469) loss_oracle 0.0634 (0.0719) acc 78.1250 (74.8047) kd_loss 0.0738 (0.0902) lr 8.7467e-04 eta 0:10:34
epoch [29/50] batch [260/288] time 0.099 (0.104) data 0.000 (0.001) loss 0.9328 (1.0943) ce_loss 0.7812 (0.9509) teacher_loss 0.7773 (0.9488) loss_zs_kd 0.1769 (0.1481) loss_oracle 0.0670 (0.0715) acc 75.0000 (74.8197) kd_loss 0.0878 (0.0902) lr 8.7467e-04 eta 0:10:31
epoch [29/50] batch [280/288] time 0.104 (0.104) data 0.001 (0.001) loss 1.5853 (1.0949) ce_loss 1.4404 (0.9514) teacher_loss 1.4589 (0.9495) loss_zs_kd 0.1389 (0.1490) loss_oracle 0.0570 (0.0709) acc 59.3750 (74.7210) kd_loss 0.0591 (0.0895) lr 8.7467e-04 eta 0:10:28
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,444
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,024
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.4%
******* Domain a best val acc:      87.4%, epoch: 26 *******
******* Domain a best val test acc: 83.6%, epoch: 26 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [30/50] batch [20/288] time 0.105 (0.122) data 0.000 (0.012) loss 0.8629 (1.0374) ce_loss 0.7036 (0.9044) teacher_loss 0.7077 (0.9021) loss_zs_kd 0.1564 (0.1541) loss_oracle 0.0770 (0.0583) acc 78.1250 (74.0625) kd_loss 0.0878 (0.0739) lr 8.1262e-04 eta 0:12:14
epoch [30/50] batch [40/288] time 0.099 (0.113) data 0.000 (0.006) loss 0.9997 (0.9857) ce_loss 0.8970 (0.8525) teacher_loss 0.9030 (0.8496) loss_zs_kd 0.1163 (0.1479) loss_oracle 0.0386 (0.0621) acc 65.6250 (75.4688) kd_loss 0.0407 (0.0775) lr 8.1262e-04 eta 0:11:21
epoch [30/50] batch [60/288] time 0.113 (0.110) data 0.000 (0.004) loss 1.2742 (1.0233) ce_loss 1.0957 (0.8868) teacher_loss 1.0870 (0.8842) loss_zs_kd 0.2035 (0.1512) loss_oracle 0.0854 (0.0635) acc 68.7500 (75.4167) kd_loss 0.0901 (0.0754) lr 8.1262e-04 eta 0:11:00
epoch [30/50] batch [80/288] time 0.101 (0.108) data 0.000 (0.003) loss 0.9602 (1.0413) ce_loss 0.8164 (0.9046) teacher_loss 0.8047 (0.9021) loss_zs_kd 0.1494 (0.1496) loss_oracle 0.0808 (0.0644) acc 75.0000 (75.0391) kd_loss 0.0777 (0.0745) lr 8.1262e-04 eta 0:10:44
epoch [30/50] batch [100/288] time 0.101 (0.107) data 0.000 (0.003) loss 0.7168 (1.0605) ce_loss 0.5942 (0.9236) teacher_loss 0.5964 (0.9213) loss_zs_kd 0.1069 (0.1479) loss_oracle 0.0669 (0.0653) acc 87.5000 (74.6250) kd_loss 0.0974 (0.0738) lr 8.1262e-04 eta 0:10:36
epoch [30/50] batch [120/288] time 0.111 (0.106) data 0.000 (0.002) loss 1.1636 (1.0717) ce_loss 1.0459 (0.9344) teacher_loss 1.0436 (0.9324) loss_zs_kd 0.1057 (0.1474) loss_oracle 0.0671 (0.0656) acc 71.8750 (74.3750) kd_loss 0.0632 (0.0742) lr 8.1262e-04 eta 0:10:30
epoch [30/50] batch [140/288] time 0.103 (0.106) data 0.000 (0.002) loss 1.3298 (1.0872) ce_loss 1.2617 (0.9499) teacher_loss 1.2215 (0.9473) loss_zs_kd 0.1056 (0.1489) loss_oracle 0.0555 (0.0655) acc 59.3750 (74.1964) kd_loss 0.0579 (0.0744) lr 8.1262e-04 eta 0:10:25
epoch [30/50] batch [160/288] time 0.108 (0.106) data 0.000 (0.002) loss 0.8514 (1.0824) ce_loss 0.7202 (0.9456) teacher_loss 0.6940 (0.9429) loss_zs_kd 0.1392 (0.1486) loss_oracle 0.0878 (0.0651) acc 75.0000 (74.4336) kd_loss 0.0904 (0.0739) lr 8.1262e-04 eta 0:10:24
epoch [30/50] batch [180/288] time 0.115 (0.106) data 0.001 (0.002) loss 1.2320 (1.0924) ce_loss 1.0840 (0.9556) teacher_loss 1.0774 (0.9526) loss_zs_kd 0.1483 (0.1484) loss_oracle 0.0804 (0.0656) acc 71.8750 (74.0625) kd_loss 0.0916 (0.0739) lr 8.1262e-04 eta 0:10:24
epoch [30/50] batch [200/288] time 0.102 (0.106) data 0.000 (0.001) loss 1.3328 (1.0883) ce_loss 1.1963 (0.9514) teacher_loss 1.1855 (0.9489) loss_zs_kd 0.1535 (0.1482) loss_oracle 0.0705 (0.0653) acc 65.6250 (74.2031) kd_loss 0.0671 (0.0738) lr 8.1262e-04 eta 0:10:20
epoch [30/50] batch [220/288] time 0.091 (0.105) data 0.000 (0.001) loss 1.1821 (1.0888) ce_loss 1.0205 (0.9518) teacher_loss 1.0277 (0.9493) loss_zs_kd 0.1542 (0.1485) loss_oracle 0.0772 (0.0652) acc 68.7500 (74.0909) kd_loss 0.0806 (0.0738) lr 8.1262e-04 eta 0:10:13
epoch [30/50] batch [240/288] time 0.104 (0.105) data 0.000 (0.001) loss 0.7521 (1.0899) ce_loss 0.6309 (0.9534) teacher_loss 0.6340 (0.9509) loss_zs_kd 0.1242 (0.1483) loss_oracle 0.0560 (0.0649) acc 84.3750 (74.1276) kd_loss 0.0680 (0.0732) lr 8.1262e-04 eta 0:10:07
epoch [30/50] batch [260/288] time 0.094 (0.104) data 0.000 (0.001) loss 0.7923 (1.0968) ce_loss 0.6680 (0.9609) teacher_loss 0.6688 (0.9583) loss_zs_kd 0.1343 (0.1479) loss_oracle 0.0563 (0.0646) acc 84.3750 (74.0264) kd_loss 0.0517 (0.0723) lr 8.1262e-04 eta 0:10:02
epoch [30/50] batch [280/288] time 0.088 (0.103) data 0.000 (0.001) loss 0.8537 (1.0889) ce_loss 0.6924 (0.9532) teacher_loss 0.6816 (0.9503) loss_zs_kd 0.1290 (0.1473) loss_oracle 0.1077 (0.0650) acc 78.1250 (74.3192) kd_loss 0.1184 (0.0722) lr 8.1262e-04 eta 0:09:56
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,446
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 86.9%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,025
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.2%
******* Domain a best val acc:      87.5%, epoch: 30 *******
******* Domain a best val test acc: 83.4%, epoch: 30 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [31/50] batch [20/288] time 0.113 (0.124) data 0.000 (0.014) loss 0.4689 (1.0079) ce_loss 0.3604 (0.8714) teacher_loss 0.3632 (0.8674) loss_zs_kd 0.1142 (0.1624) loss_oracle 0.0486 (0.0594) acc 90.6250 (76.5625) kd_loss 0.0596 (0.0745) lr 7.5131e-04 eta 0:11:54
epoch [31/50] batch [40/288] time 0.110 (0.115) data 0.000 (0.007) loss 0.7807 (1.0638) ce_loss 0.6357 (0.9331) teacher_loss 0.6434 (0.9306) loss_zs_kd 0.1583 (0.1524) loss_oracle 0.0581 (0.0571) acc 87.5000 (75.6250) kd_loss 0.0903 (0.0725) lr 7.5131e-04 eta 0:10:57
epoch [31/50] batch [60/288] time 0.110 (0.111) data 0.000 (0.005) loss 1.0581 (1.0741) ce_loss 0.9287 (0.9450) teacher_loss 0.9241 (0.9422) loss_zs_kd 0.1486 (0.1486) loss_oracle 0.0597 (0.0577) acc 75.0000 (75.0000) kd_loss 0.0565 (0.0686) lr 7.5131e-04 eta 0:10:32
epoch [31/50] batch [80/288] time 0.099 (0.109) data 0.000 (0.004) loss 0.9861 (1.0563) ce_loss 0.8457 (0.9259) teacher_loss 0.8493 (0.9231) loss_zs_kd 0.1255 (0.1497) loss_oracle 0.0741 (0.0584) acc 81.2500 (75.0391) kd_loss 0.0837 (0.0681) lr 7.5131e-04 eta 0:10:19
epoch [31/50] batch [100/288] time 0.100 (0.109) data 0.000 (0.003) loss 1.1512 (1.0445) ce_loss 0.9810 (0.9140) teacher_loss 0.9703 (0.9105) loss_zs_kd 0.2164 (0.1494) loss_oracle 0.0727 (0.0594) acc 75.0000 (75.4688) kd_loss 0.0869 (0.0680) lr 7.5131e-04 eta 0:10:15
epoch [31/50] batch [120/288] time 0.113 (0.108) data 0.001 (0.003) loss 0.6623 (1.0501) ce_loss 0.5444 (0.9182) teacher_loss 0.5247 (0.9144) loss_zs_kd 0.1282 (0.1521) loss_oracle 0.0736 (0.0597) acc 84.3750 (75.5729) kd_loss 0.0797 (0.0675) lr 7.5131e-04 eta 0:10:10
epoch [31/50] batch [140/288] time 0.099 (0.107) data 0.000 (0.002) loss 0.8343 (1.0488) ce_loss 0.6880 (0.9167) teacher_loss 0.6902 (0.9124) loss_zs_kd 0.1846 (0.1525) loss_oracle 0.0518 (0.0602) acc 81.2500 (75.7589) kd_loss 0.0463 (0.0673) lr 7.5131e-04 eta 0:10:03
epoch [31/50] batch [160/288] time 0.102 (0.107) data 0.000 (0.002) loss 0.9364 (1.0569) ce_loss 0.7866 (0.9241) teacher_loss 0.7856 (0.9200) loss_zs_kd 0.1805 (0.1527) loss_oracle 0.0605 (0.0605) acc 81.2500 (75.5273) kd_loss 0.0727 (0.0675) lr 7.5131e-04 eta 0:09:57
epoch [31/50] batch [180/288] time 0.102 (0.106) data 0.000 (0.002) loss 1.3061 (1.0587) ce_loss 1.2021 (0.9275) teacher_loss 1.1853 (0.9231) loss_zs_kd 0.1441 (0.1510) loss_oracle 0.0487 (0.0601) acc 68.7500 (75.2778) kd_loss 0.0629 (0.0668) lr 7.5131e-04 eta 0:09:52
epoch [31/50] batch [200/288] time 0.099 (0.106) data 0.000 (0.002) loss 1.0042 (1.0598) ce_loss 0.8652 (0.9282) teacher_loss 0.8666 (0.9244) loss_zs_kd 0.1233 (0.1514) loss_oracle 0.0759 (0.0597) acc 81.2500 (75.2344) kd_loss 0.0627 (0.0664) lr 7.5131e-04 eta 0:09:48
epoch [31/50] batch [220/288] time 0.102 (0.105) data 0.000 (0.002) loss 1.1309 (1.0643) ce_loss 0.9775 (0.9327) teacher_loss 0.9751 (0.9292) loss_zs_kd 0.1597 (0.1511) loss_oracle 0.0759 (0.0596) acc 68.7500 (75.1136) kd_loss 0.0692 (0.0658) lr 7.5131e-04 eta 0:09:44
epoch [31/50] batch [240/288] time 0.096 (0.105) data 0.000 (0.001) loss 1.0805 (1.0631) ce_loss 0.9453 (0.9311) teacher_loss 0.9475 (0.9278) loss_zs_kd 0.1504 (0.1511) loss_oracle 0.0579 (0.0598) acc 71.8750 (75.0911) kd_loss 0.0553 (0.0656) lr 7.5131e-04 eta 0:09:40
epoch [31/50] batch [260/288] time 0.098 (0.105) data 0.000 (0.001) loss 0.7210 (1.0639) ce_loss 0.6064 (0.9323) teacher_loss 0.6113 (0.9291) loss_zs_kd 0.0808 (0.1497) loss_oracle 0.0693 (0.0599) acc 87.5000 (75.0841) kd_loss 0.0684 (0.0652) lr 7.5131e-04 eta 0:09:37
epoch [31/50] batch [280/288] time 0.104 (0.105) data 0.000 (0.001) loss 0.9504 (1.0556) ce_loss 0.8262 (0.9242) teacher_loss 0.8242 (0.9212) loss_zs_kd 0.1095 (0.1485) loss_oracle 0.0714 (0.0602) acc 84.3750 (75.4018) kd_loss 0.0761 (0.0653) lr 7.5131e-04 eta 0:09:34
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,451
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.0%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.9%
******* Domain a best val acc:      87.6%, epoch: 31 *******
******* Domain a best val test acc: 83.1%, epoch: 31 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [32/50] batch [20/288] time 0.093 (0.111) data 0.000 (0.013) loss 1.0365 (1.0804) ce_loss 0.9272 (0.9450) teacher_loss 0.9244 (0.9391) loss_zs_kd 0.0922 (0.1441) loss_oracle 0.0660 (0.0693) acc 78.1250 (75.6250) kd_loss 0.0659 (0.0737) lr 6.9098e-04 eta 0:10:02
epoch [32/50] batch [40/288] time 0.103 (0.103) data 0.000 (0.007) loss 0.5656 (1.0822) ce_loss 0.4714 (0.9467) teacher_loss 0.4621 (0.9406) loss_zs_kd 0.0807 (0.1508) loss_oracle 0.0632 (0.0662) acc 87.5000 (75.8594) kd_loss 0.0698 (0.0713) lr 6.9098e-04 eta 0:09:18
epoch [32/50] batch [60/288] time 0.099 (0.100) data 0.000 (0.004) loss 0.9405 (1.1004) ce_loss 0.7817 (0.9605) teacher_loss 0.7804 (0.9538) loss_zs_kd 0.1749 (0.1548) loss_oracle 0.0727 (0.0692) acc 78.1250 (75.0000) kd_loss 0.0796 (0.0729) lr 6.9098e-04 eta 0:09:01
epoch [32/50] batch [80/288] time 0.102 (0.099) data 0.000 (0.003) loss 1.5286 (1.0771) ce_loss 1.4023 (0.9366) teacher_loss 1.3962 (0.9298) loss_zs_kd 0.1238 (0.1542) loss_oracle 0.0705 (0.0702) acc 65.6250 (75.5078) kd_loss 0.0605 (0.0718) lr 6.9098e-04 eta 0:08:52
epoch [32/50] batch [100/288] time 0.095 (0.098) data 0.000 (0.003) loss 0.6425 (1.0793) ce_loss 0.4673 (0.9380) teacher_loss 0.4599 (0.9312) loss_zs_kd 0.1475 (0.1524) loss_oracle 0.1089 (0.0720) acc 87.5000 (75.4688) kd_loss 0.0946 (0.0731) lr 6.9098e-04 eta 0:08:47
epoch [32/50] batch [120/288] time 0.096 (0.098) data 0.000 (0.002) loss 0.7262 (1.0769) ce_loss 0.6289 (0.9358) teacher_loss 0.5937 (0.9295) loss_zs_kd 0.1135 (0.1523) loss_oracle 0.0758 (0.0713) acc 78.1250 (75.3125) kd_loss 0.0872 (0.0725) lr 6.9098e-04 eta 0:08:45
epoch [32/50] batch [140/288] time 0.100 (0.098) data 0.000 (0.002) loss 1.0832 (1.0746) ce_loss 0.9238 (0.9339) teacher_loss 0.9160 (0.9279) loss_zs_kd 0.2109 (0.1520) loss_oracle 0.0619 (0.0707) acc 81.2500 (75.2232) kd_loss 0.0586 (0.0728) lr 6.9098e-04 eta 0:08:44
epoch [32/50] batch [160/288] time 0.101 (0.099) data 0.001 (0.002) loss 0.8206 (1.0695) ce_loss 0.6870 (0.9304) teacher_loss 0.6687 (0.9248) loss_zs_kd 0.1589 (0.1509) loss_oracle 0.0724 (0.0693) acc 81.2500 (75.1758) kd_loss 0.0982 (0.0723) lr 6.9098e-04 eta 0:08:45
epoch [32/50] batch [180/288] time 0.099 (0.099) data 0.000 (0.002) loss 1.0265 (1.0793) ce_loss 0.8848 (0.9400) teacher_loss 0.8944 (0.9346) loss_zs_kd 0.1648 (0.1512) loss_oracle 0.0497 (0.0690) acc 71.8750 (74.6875) kd_loss 0.0709 (0.0725) lr 6.9098e-04 eta 0:08:44
epoch [32/50] batch [200/288] time 0.099 (0.099) data 0.000 (0.002) loss 1.0352 (1.0758) ce_loss 0.8936 (0.9369) teacher_loss 0.8995 (0.9321) loss_zs_kd 0.1643 (0.1506) loss_oracle 0.0535 (0.0683) acc 75.0000 (74.7344) kd_loss 0.0509 (0.0723) lr 6.9098e-04 eta 0:08:44
epoch [32/50] batch [220/288] time 0.098 (0.100) data 0.000 (0.001) loss 0.8996 (1.0796) ce_loss 0.7935 (0.9419) teacher_loss 0.7928 (0.9374) loss_zs_kd 0.0978 (0.1495) loss_oracle 0.0579 (0.0675) acc 71.8750 (74.6165) kd_loss 0.0736 (0.0719) lr 6.9098e-04 eta 0:08:43
epoch [32/50] batch [240/288] time 0.090 (0.099) data 0.000 (0.001) loss 1.0390 (1.0716) ce_loss 0.9097 (0.9347) teacher_loss 0.9211 (0.9302) loss_zs_kd 0.1131 (0.1487) loss_oracle 0.0613 (0.0670) acc 78.1250 (74.8438) kd_loss 0.0806 (0.0722) lr 6.9098e-04 eta 0:08:39
epoch [32/50] batch [260/288] time 0.091 (0.099) data 0.000 (0.001) loss 1.0658 (1.0779) ce_loss 0.9609 (0.9411) teacher_loss 0.9468 (0.9366) loss_zs_kd 0.0967 (0.1488) loss_oracle 0.0706 (0.0669) acc 75.0000 (74.6875) kd_loss 0.0793 (0.0723) lr 6.9098e-04 eta 0:08:36
epoch [32/50] batch [280/288] time 0.096 (0.099) data 0.000 (0.001) loss 0.8685 (1.0766) ce_loss 0.7358 (0.9398) teacher_loss 0.7257 (0.9354) loss_zs_kd 0.1231 (0.1486) loss_oracle 0.0813 (0.0669) acc 71.8750 (74.6875) kd_loss 0.0933 (0.0723) lr 6.9098e-04 eta 0:08:32
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,449
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,026
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 80.1%
******* Domain a best val acc:      87.6%, epoch: 31 *******
******* Domain a best val test acc: 83.1%, epoch: 31 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [33/50] batch [20/288] time 0.095 (0.116) data 0.000 (0.013) loss 1.1535 (1.1251) ce_loss 1.0254 (0.9789) teacher_loss 1.0171 (0.9798) loss_zs_kd 0.1434 (0.1604) loss_oracle 0.0648 (0.0651) acc 81.2500 (74.5312) kd_loss 0.0878 (0.0749) lr 6.3188e-04 eta 0:09:59
epoch [33/50] batch [40/288] time 0.098 (0.106) data 0.000 (0.007) loss 1.1884 (1.1324) ce_loss 1.0391 (0.9928) teacher_loss 1.0443 (0.9903) loss_zs_kd 0.1363 (0.1563) loss_oracle 0.0760 (0.0638) acc 78.1250 (73.7500) kd_loss 0.1020 (0.0768) lr 6.3188e-04 eta 0:09:04
epoch [33/50] batch [60/288] time 0.097 (0.104) data 0.000 (0.005) loss 1.0396 (1.1135) ce_loss 0.9146 (0.9744) teacher_loss 0.9210 (0.9706) loss_zs_kd 0.1496 (0.1553) loss_oracle 0.0438 (0.0652) acc 68.7500 (74.0625) kd_loss 0.0611 (0.0780) lr 6.3188e-04 eta 0:08:55
epoch [33/50] batch [80/288] time 0.104 (0.103) data 0.000 (0.003) loss 0.8997 (1.1097) ce_loss 0.7739 (0.9726) teacher_loss 0.7767 (0.9680) loss_zs_kd 0.1175 (0.1520) loss_oracle 0.0642 (0.0658) acc 81.2500 (74.1797) kd_loss 0.0715 (0.0803) lr 6.3188e-04 eta 0:08:46
epoch [33/50] batch [100/288] time 0.098 (0.102) data 0.000 (0.003) loss 1.0159 (1.0909) ce_loss 0.8867 (0.9523) teacher_loss 0.8718 (0.9481) loss_zs_kd 0.1167 (0.1532) loss_oracle 0.0858 (0.0662) acc 81.2500 (74.7812) kd_loss 0.0986 (0.0809) lr 6.3188e-04 eta 0:08:37
epoch [33/50] batch [120/288] time 0.095 (0.101) data 0.000 (0.002) loss 1.7706 (1.0900) ce_loss 1.6084 (0.9514) teacher_loss 1.6215 (0.9476) loss_zs_kd 0.1306 (0.1527) loss_oracle 0.0838 (0.0661) acc 56.2500 (74.8698) kd_loss 0.0815 (0.0803) lr 6.3188e-04 eta 0:08:33
epoch [33/50] batch [140/288] time 0.105 (0.102) data 0.000 (0.002) loss 1.2104 (1.0867) ce_loss 1.0674 (0.9488) teacher_loss 1.0345 (0.9445) loss_zs_kd 0.1761 (0.1524) loss_oracle 0.0879 (0.0661) acc 75.0000 (74.9330) kd_loss 0.0881 (0.0796) lr 6.3188e-04 eta 0:08:33
epoch [33/50] batch [160/288] time 0.099 (0.102) data 0.000 (0.002) loss 1.1950 (1.0823) ce_loss 1.0352 (0.9449) teacher_loss 1.0412 (0.9411) loss_zs_kd 0.2099 (0.1512) loss_oracle 0.0488 (0.0656) acc 71.8750 (75.0586) kd_loss 0.0633 (0.0784) lr 6.3188e-04 eta 0:08:31
epoch [33/50] batch [180/288] time 0.099 (0.102) data 0.000 (0.002) loss 1.2597 (1.0817) ce_loss 1.1240 (0.9453) teacher_loss 1.1213 (0.9410) loss_zs_kd 0.1554 (0.1496) loss_oracle 0.0607 (0.0659) acc 68.7500 (75.0347) kd_loss 0.0525 (0.0781) lr 6.3188e-04 eta 0:08:30
epoch [33/50] batch [200/288] time 0.102 (0.102) data 0.000 (0.002) loss 1.1145 (1.0774) ce_loss 0.9912 (0.9411) teacher_loss 0.9903 (0.9369) loss_zs_kd 0.1141 (0.1489) loss_oracle 0.0672 (0.0661) acc 71.8750 (75.0781) kd_loss 0.0666 (0.0778) lr 6.3188e-04 eta 0:08:28
epoch [33/50] batch [220/288] time 0.112 (0.102) data 0.001 (0.001) loss 1.1596 (1.0751) ce_loss 1.0820 (0.9393) teacher_loss 1.0870 (0.9351) loss_zs_kd 0.0632 (0.1488) loss_oracle 0.0411 (0.0656) acc 71.8750 (75.1136) kd_loss 0.0461 (0.0769) lr 6.3188e-04 eta 0:08:27
epoch [33/50] batch [240/288] time 0.099 (0.102) data 0.000 (0.001) loss 0.7339 (1.0660) ce_loss 0.5874 (0.9300) teacher_loss 0.5882 (0.9256) loss_zs_kd 0.1545 (0.1489) loss_oracle 0.0685 (0.0660) acc 81.2500 (75.3125) kd_loss 0.0576 (0.0763) lr 6.3188e-04 eta 0:08:25
epoch [33/50] batch [260/288] time 0.102 (0.102) data 0.000 (0.001) loss 1.0753 (1.0722) ce_loss 0.9556 (0.9363) teacher_loss 0.9589 (0.9317) loss_zs_kd 0.0979 (0.1489) loss_oracle 0.0674 (0.0661) acc 81.2500 (75.1683) kd_loss 0.0581 (0.0756) lr 6.3188e-04 eta 0:08:23
epoch [33/50] batch [280/288] time 0.108 (0.102) data 0.000 (0.001) loss 1.0084 (1.0732) ce_loss 0.8843 (0.9368) teacher_loss 0.8825 (0.9323) loss_zs_kd 0.1227 (0.1494) loss_oracle 0.0646 (0.0662) acc 78.1250 (75.1116) kd_loss 0.0436 (0.0749) lr 6.3188e-04 eta 0:08:20
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,453
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 87.1%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 80.0%
******* Domain a best val acc:      87.7%, epoch: 33 *******
******* Domain a best val test acc: 83.3%, epoch: 33 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [34/50] batch [20/288] time 0.095 (0.112) data 0.001 (0.013) loss 1.3189 (0.9833) ce_loss 1.1836 (0.8423) teacher_loss 1.1379 (0.8378) loss_zs_kd 0.1806 (0.1514) loss_oracle 0.0907 (0.0699) acc 65.6250 (77.1875) kd_loss 0.0806 (0.0729) lr 5.7422e-04 eta 0:09:03
epoch [34/50] batch [40/288] time 0.100 (0.104) data 0.000 (0.007) loss 0.9226 (1.0397) ce_loss 0.8071 (0.9028) teacher_loss 0.8082 (0.8983) loss_zs_kd 0.1009 (0.1489) loss_oracle 0.0639 (0.0670) acc 84.3750 (75.5469) kd_loss 0.0687 (0.0723) lr 5.7422e-04 eta 0:08:22
epoch [34/50] batch [60/288] time 0.090 (0.101) data 0.000 (0.004) loss 0.8589 (1.0445) ce_loss 0.7534 (0.9093) teacher_loss 0.7614 (0.9056) loss_zs_kd 0.0937 (0.1475) loss_oracle 0.0506 (0.0652) acc 78.1250 (75.3125) kd_loss 0.0577 (0.0713) lr 5.7422e-04 eta 0:08:07
epoch [34/50] batch [80/288] time 0.105 (0.100) data 0.000 (0.003) loss 1.0317 (1.0498) ce_loss 0.8906 (0.9158) teacher_loss 0.8991 (0.9112) loss_zs_kd 0.1804 (0.1479) loss_oracle 0.0423 (0.0646) acc 75.0000 (75.6250) kd_loss 0.0408 (0.0722) lr 5.7422e-04 eta 0:08:02
epoch [34/50] batch [100/288] time 0.095 (0.099) data 0.000 (0.003) loss 1.2110 (1.0370) ce_loss 1.0723 (0.9034) teacher_loss 1.0593 (0.8989) loss_zs_kd 0.1923 (0.1473) loss_oracle 0.0555 (0.0645) acc 71.8750 (76.0625) kd_loss 0.0687 (0.0723) lr 5.7422e-04 eta 0:07:54
epoch [34/50] batch [120/288] time 0.089 (0.099) data 0.000 (0.002) loss 1.0729 (1.0470) ce_loss 0.9365 (0.9138) teacher_loss 0.9396 (0.9100) loss_zs_kd 0.1263 (0.1474) loss_oracle 0.0702 (0.0633) acc 71.8750 (75.7812) kd_loss 0.0773 (0.0708) lr 5.7422e-04 eta 0:07:50
epoch [34/50] batch [140/288] time 0.093 (0.098) data 0.000 (0.002) loss 1.1553 (1.0430) ce_loss 1.0352 (0.9090) teacher_loss 1.0283 (0.9052) loss_zs_kd 0.1387 (0.1480) loss_oracle 0.0577 (0.0638) acc 65.6250 (75.8482) kd_loss 0.0591 (0.0698) lr 5.7422e-04 eta 0:07:47
epoch [34/50] batch [160/288] time 0.092 (0.098) data 0.000 (0.002) loss 0.7413 (1.0428) ce_loss 0.5923 (0.9078) teacher_loss 0.5934 (0.9037) loss_zs_kd 0.1558 (0.1492) loss_oracle 0.0700 (0.0645) acc 84.3750 (75.6836) kd_loss 0.0670 (0.0698) lr 5.7422e-04 eta 0:07:44
epoch [34/50] batch [180/288] time 0.093 (0.098) data 0.000 (0.002) loss 1.0060 (1.0493) ce_loss 0.8657 (0.9128) teacher_loss 0.8675 (0.9091) loss_zs_kd 0.1597 (0.1508) loss_oracle 0.0586 (0.0647) acc 75.0000 (75.4514) kd_loss 0.0484 (0.0686) lr 5.7422e-04 eta 0:07:41
epoch [34/50] batch [200/288] time 0.092 (0.098) data 0.000 (0.001) loss 1.5135 (1.0618) ce_loss 1.3838 (0.9258) teacher_loss 1.3734 (0.9221) loss_zs_kd 0.1740 (0.1509) loss_oracle 0.0532 (0.0643) acc 65.6250 (75.2188) kd_loss 0.0470 (0.0675) lr 5.7422e-04 eta 0:07:38
epoch [34/50] batch [220/288] time 0.103 (0.097) data 0.000 (0.001) loss 1.1842 (1.0644) ce_loss 1.0459 (0.9279) teacher_loss 1.0391 (0.9242) loss_zs_kd 0.1283 (0.1513) loss_oracle 0.0810 (0.0645) acc 68.7500 (75.1420) kd_loss 0.1014 (0.0671) lr 5.7422e-04 eta 0:07:35
epoch [34/50] batch [240/288] time 0.100 (0.097) data 0.000 (0.001) loss 1.1252 (1.0711) ce_loss 1.0186 (0.9346) teacher_loss 0.9929 (0.9304) loss_zs_kd 0.1586 (0.1517) loss_oracle 0.0531 (0.0649) acc 65.6250 (74.9870) kd_loss 0.0683 (0.0667) lr 5.7422e-04 eta 0:07:32
epoch [34/50] batch [260/288] time 0.094 (0.097) data 0.000 (0.001) loss 0.9444 (1.0687) ce_loss 0.7925 (0.9323) teacher_loss 0.7955 (0.9280) loss_zs_kd 0.1752 (0.1517) loss_oracle 0.0613 (0.0648) acc 84.3750 (75.1082) kd_loss 0.0518 (0.0666) lr 5.7422e-04 eta 0:07:30
epoch [34/50] batch [280/288] time 0.086 (0.097) data 0.000 (0.001) loss 1.2814 (1.0648) ce_loss 1.0869 (0.9284) teacher_loss 1.0884 (0.9243) loss_zs_kd 0.2123 (0.1507) loss_oracle 0.0869 (0.0651) acc 71.8750 (75.1562) kd_loss 0.0964 (0.0670) lr 5.7422e-04 eta 0:07:26
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,447
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,023
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 79.9%
******* Domain a best val acc:      87.7%, epoch: 33 *******
******* Domain a best val test acc: 83.3%, epoch: 33 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [35/50] batch [20/288] time 0.103 (0.125) data 0.000 (0.018) loss 1.3995 (1.1521) ce_loss 1.2383 (1.0048) teacher_loss 1.2326 (0.9974) loss_zs_kd 0.1596 (0.1539) loss_oracle 0.0872 (0.0777) acc 71.8750 (73.1250) kd_loss 0.0960 (0.0803) lr 5.1825e-04 eta 0:09:35
epoch [35/50] batch [40/288] time 0.109 (0.114) data 0.000 (0.009) loss 1.2296 (1.1780) ce_loss 1.1025 (1.0332) teacher_loss 1.0972 (1.0257) loss_zs_kd 0.1226 (0.1537) loss_oracle 0.0710 (0.0754) acc 71.8750 (72.1875) kd_loss 0.0934 (0.0844) lr 5.1825e-04 eta 0:08:40
epoch [35/50] batch [60/288] time 0.104 (0.110) data 0.001 (0.006) loss 1.5726 (1.1481) ce_loss 1.4580 (1.0047) teacher_loss 1.4422 (0.9970) loss_zs_kd 0.1382 (0.1497) loss_oracle 0.0613 (0.0763) acc 71.8750 (73.7500) kd_loss 0.0674 (0.0866) lr 5.1825e-04 eta 0:08:20
epoch [35/50] batch [80/288] time 0.100 (0.108) data 0.000 (0.005) loss 1.1875 (1.1457) ce_loss 1.0166 (1.0007) teacher_loss 1.0257 (0.9941) loss_zs_kd 0.1775 (0.1480) loss_oracle 0.0731 (0.0777) acc 75.0000 (73.9062) kd_loss 0.0767 (0.0874) lr 5.1825e-04 eta 0:08:07
epoch [35/50] batch [100/288] time 0.102 (0.107) data 0.000 (0.004) loss 1.2491 (1.1412) ce_loss 1.1338 (0.9943) teacher_loss 1.1293 (0.9884) loss_zs_kd 0.1374 (0.1489) loss_oracle 0.0512 (0.0783) acc 71.8750 (73.9688) kd_loss 0.0549 (0.0878) lr 5.1825e-04 eta 0:08:01
epoch [35/50] batch [120/288] time 0.102 (0.106) data 0.000 (0.003) loss 1.0115 (1.1268) ce_loss 0.8340 (0.9810) teacher_loss 0.8458 (0.9754) loss_zs_kd 0.1982 (0.1493) loss_oracle 0.0666 (0.0768) acc 75.0000 (74.4010) kd_loss 0.0795 (0.0870) lr 5.1825e-04 eta 0:07:55
epoch [35/50] batch [140/288] time 0.123 (0.106) data 0.000 (0.003) loss 0.6391 (1.1219) ce_loss 0.5283 (0.9755) teacher_loss 0.5252 (0.9704) loss_zs_kd 0.0718 (0.1488) loss_oracle 0.0780 (0.0771) acc 87.5000 (74.6429) kd_loss 0.0766 (0.0865) lr 5.1825e-04 eta 0:07:52
epoch [35/50] batch [160/288] time 0.129 (0.109) data 0.001 (0.002) loss 1.0140 (1.1155) ce_loss 0.8672 (0.9684) teacher_loss 0.8610 (0.9637) loss_zs_kd 0.1442 (0.1494) loss_oracle 0.0809 (0.0771) acc 71.8750 (74.7070) kd_loss 0.0870 (0.0859) lr 5.1825e-04 eta 0:08:03
epoch [35/50] batch [180/288] time 0.124 (0.111) data 0.000 (0.002) loss 0.7755 (1.0982) ce_loss 0.6445 (0.9510) teacher_loss 0.6466 (0.9467) loss_zs_kd 0.0872 (0.1477) loss_oracle 0.0852 (0.0776) acc 78.1250 (75.0521) kd_loss 0.0782 (0.0861) lr 5.1825e-04 eta 0:08:10
epoch [35/50] batch [200/288] time 0.125 (0.112) data 0.000 (0.002) loss 0.7678 (1.0931) ce_loss 0.5786 (0.9455) teacher_loss 0.5828 (0.9409) loss_zs_kd 0.1576 (0.1482) loss_oracle 0.1062 (0.0781) acc 84.3750 (75.1250) kd_loss 0.1296 (0.0866) lr 5.1825e-04 eta 0:08:15
epoch [35/50] batch [220/288] time 0.115 (0.112) data 0.000 (0.002) loss 0.7322 (1.0887) ce_loss 0.5879 (0.9414) teacher_loss 0.5890 (0.9370) loss_zs_kd 0.1095 (0.1479) loss_oracle 0.0885 (0.0778) acc 87.5000 (75.1136) kd_loss 0.0913 (0.0866) lr 5.1825e-04 eta 0:08:09
epoch [35/50] batch [240/288] time 0.098 (0.111) data 0.000 (0.002) loss 0.5979 (1.0823) ce_loss 0.4099 (0.9354) teacher_loss 0.4235 (0.9312) loss_zs_kd 0.2203 (0.1486) loss_oracle 0.0642 (0.0768) acc 87.5000 (75.1562) kd_loss 0.0613 (0.0856) lr 5.1825e-04 eta 0:08:04
epoch [35/50] batch [260/288] time 0.101 (0.110) data 0.000 (0.002) loss 0.8375 (1.0700) ce_loss 0.6841 (0.9231) teacher_loss 0.6886 (0.9189) loss_zs_kd 0.1353 (0.1486) loss_oracle 0.0812 (0.0768) acc 81.2500 (75.4327) kd_loss 0.0967 (0.0854) lr 5.1825e-04 eta 0:07:58
epoch [35/50] batch [280/288] time 0.107 (0.110) data 0.000 (0.002) loss 1.1292 (1.0737) ce_loss 0.9946 (0.9272) teacher_loss 1.0005 (0.9224) loss_zs_kd 0.1183 (0.1497) loss_oracle 0.0695 (0.0765) acc 71.8750 (75.2902) kd_loss 0.0671 (0.0847) lr 5.1825e-04 eta 0:07:54
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,440
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,020
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 79.9%
******* Domain a best val acc:      87.7%, epoch: 33 *******
******* Domain a best val test acc: 83.3%, epoch: 33 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [36/50] batch [20/288] time 0.106 (0.128) data 0.000 (0.019) loss 1.4104 (1.0188) ce_loss 1.3018 (0.8799) teacher_loss 1.2935 (0.8771) loss_zs_kd 0.1186 (0.1512) loss_oracle 0.0576 (0.0661) acc 65.6250 (77.8125) kd_loss 0.0684 (0.0664) lr 4.6417e-04 eta 0:09:09
epoch [36/50] batch [40/288] time 0.133 (0.123) data 0.000 (0.010) loss 1.0365 (1.0813) ce_loss 0.9209 (0.9372) teacher_loss 0.9313 (0.9318) loss_zs_kd 0.1308 (0.1589) loss_oracle 0.0398 (0.0700) acc 78.1250 (76.0938) kd_loss 0.0492 (0.0692) lr 4.6417e-04 eta 0:08:46
epoch [36/50] batch [60/288] time 0.130 (0.126) data 0.001 (0.006) loss 0.8828 (1.0783) ce_loss 0.6978 (0.9338) teacher_loss 0.7118 (0.9289) loss_zs_kd 0.1930 (0.1582) loss_oracle 0.0745 (0.0703) acc 87.5000 (75.9375) kd_loss 0.0852 (0.0716) lr 4.6417e-04 eta 0:08:58
epoch [36/50] batch [80/288] time 0.121 (0.127) data 0.000 (0.005) loss 1.0213 (1.0580) ce_loss 0.8691 (0.9142) teacher_loss 0.8794 (0.9105) loss_zs_kd 0.1373 (0.1543) loss_oracle 0.0733 (0.0704) acc 78.1250 (76.2891) kd_loss 0.0829 (0.0733) lr 4.6417e-04 eta 0:09:00
epoch [36/50] batch [100/288] time 0.129 (0.127) data 0.000 (0.004) loss 1.2763 (1.0338) ce_loss 1.1582 (0.8883) teacher_loss 1.1267 (0.8843) loss_zs_kd 0.1192 (0.1543) loss_oracle 0.0900 (0.0724) acc 71.8750 (76.8750) kd_loss 0.1098 (0.0770) lr 4.6417e-04 eta 0:08:57
epoch [36/50] batch [120/288] time 0.125 (0.128) data 0.001 (0.003) loss 0.7630 (1.0423) ce_loss 0.6382 (0.8998) teacher_loss 0.6325 (0.8956) loss_zs_kd 0.1289 (0.1512) loss_oracle 0.0660 (0.0711) acc 90.6250 (76.6927) kd_loss 0.0648 (0.0764) lr 4.6417e-04 eta 0:08:57
epoch [36/50] batch [140/288] time 0.129 (0.128) data 0.000 (0.003) loss 1.0678 (1.0482) ce_loss 0.9277 (0.9057) teacher_loss 0.9160 (0.9014) loss_zs_kd 0.1342 (0.1510) loss_oracle 0.0846 (0.0713) acc 71.8750 (76.3839) kd_loss 0.0767 (0.0771) lr 4.6417e-04 eta 0:08:54
epoch [36/50] batch [160/288] time 0.123 (0.127) data 0.000 (0.003) loss 0.9673 (1.0420) ce_loss 0.8369 (0.8995) teacher_loss 0.8417 (0.8945) loss_zs_kd 0.1139 (0.1522) loss_oracle 0.0686 (0.0714) acc 78.1250 (76.2695) kd_loss 0.0614 (0.0769) lr 4.6417e-04 eta 0:08:48
epoch [36/50] batch [180/288] time 0.108 (0.126) data 0.001 (0.002) loss 1.3828 (1.0491) ce_loss 1.2578 (0.9061) teacher_loss 1.2571 (0.9015) loss_zs_kd 0.1203 (0.1516) loss_oracle 0.0656 (0.0718) acc 71.8750 (76.0764) kd_loss 0.0602 (0.0770) lr 4.6417e-04 eta 0:08:41
epoch [36/50] batch [200/288] time 0.128 (0.126) data 0.000 (0.002) loss 1.1759 (1.0578) ce_loss 1.0352 (0.9140) teacher_loss 1.0104 (0.9092) loss_zs_kd 0.1549 (0.1519) loss_oracle 0.0881 (0.0726) acc 68.7500 (75.8906) kd_loss 0.0829 (0.0770) lr 4.6417e-04 eta 0:08:37
epoch [36/50] batch [220/288] time 0.108 (0.125) data 0.000 (0.002) loss 1.1651 (1.0560) ce_loss 1.0234 (0.9128) teacher_loss 1.0156 (0.9080) loss_zs_kd 0.1504 (0.1509) loss_oracle 0.0743 (0.0726) acc 71.8750 (75.7955) kd_loss 0.0938 (0.0770) lr 4.6417e-04 eta 0:08:32
epoch [36/50] batch [240/288] time 0.122 (0.125) data 0.001 (0.002) loss 0.8886 (1.0546) ce_loss 0.7559 (0.9108) teacher_loss 0.7583 (0.9061) loss_zs_kd 0.1450 (0.1509) loss_oracle 0.0578 (0.0730) acc 78.1250 (75.8724) kd_loss 0.0409 (0.0773) lr 4.6417e-04 eta 0:08:30
epoch [36/50] batch [260/288] time 0.104 (0.124) data 0.000 (0.002) loss 0.7554 (1.0493) ce_loss 0.6318 (0.9060) teacher_loss 0.6382 (0.9017) loss_zs_kd 0.1431 (0.1504) loss_oracle 0.0456 (0.0724) acc 84.3750 (75.9375) kd_loss 0.0583 (0.0771) lr 4.6417e-04 eta 0:08:25
epoch [36/50] batch [280/288] time 0.106 (0.124) data 0.000 (0.002) loss 0.9416 (1.0539) ce_loss 0.7930 (0.9103) teacher_loss 0.7823 (0.9062) loss_zs_kd 0.1494 (0.1518) loss_oracle 0.0846 (0.0718) acc 84.3750 (75.8594) kd_loss 0.0979 (0.0771) lr 4.6417e-04 eta 0:08:19
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,439
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 79.9%
******* Domain a best val acc:      87.7%, epoch: 33 *******
******* Domain a best val test acc: 83.3%, epoch: 33 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [37/50] batch [20/288] time 0.100 (0.122) data 0.000 (0.017) loss 1.0364 (1.0823) ce_loss 0.9277 (0.9406) teacher_loss 0.9341 (0.9326) loss_zs_kd 0.1196 (0.1625) loss_oracle 0.0425 (0.0684) acc 75.0000 (75.0000) kd_loss 0.0532 (0.0737) lr 4.1221e-04 eta 0:08:09
epoch [37/50] batch [40/288] time 0.111 (0.112) data 0.000 (0.009) loss 1.0704 (1.1127) ce_loss 0.9448 (0.9750) teacher_loss 0.9020 (0.9668) loss_zs_kd 0.1699 (0.1534) loss_oracle 0.0834 (0.0693) acc 75.0000 (73.9844) kd_loss 0.0951 (0.0750) lr 4.1221e-04 eta 0:07:26
epoch [37/50] batch [60/288] time 0.097 (0.108) data 0.001 (0.006) loss 0.9391 (1.0916) ce_loss 0.7910 (0.9562) teacher_loss 0.7896 (0.9501) loss_zs_kd 0.1661 (0.1477) loss_oracle 0.0664 (0.0676) acc 84.3750 (74.3750) kd_loss 0.0675 (0.0728) lr 4.1221e-04 eta 0:07:07
epoch [37/50] batch [80/288] time 0.099 (0.107) data 0.000 (0.004) loss 0.7208 (1.0785) ce_loss 0.5957 (0.9402) teacher_loss 0.5939 (0.9346) loss_zs_kd 0.1091 (0.1510) loss_oracle 0.0723 (0.0684) acc 84.3750 (75.1953) kd_loss 0.0707 (0.0733) lr 4.1221e-04 eta 0:07:01
epoch [37/50] batch [100/288] time 0.101 (0.105) data 0.000 (0.004) loss 0.9366 (1.0608) ce_loss 0.8242 (0.9226) teacher_loss 0.8293 (0.9163) loss_zs_kd 0.1304 (0.1513) loss_oracle 0.0422 (0.0689) acc 81.2500 (75.8125) kd_loss 0.0636 (0.0739) lr 4.1221e-04 eta 0:06:54
epoch [37/50] batch [120/288] time 0.100 (0.105) data 0.000 (0.003) loss 1.4211 (1.0755) ce_loss 1.2939 (0.9364) teacher_loss 1.3002 (0.9302) loss_zs_kd 0.0904 (0.1525) loss_oracle 0.0757 (0.0691) acc 68.7500 (75.1562) kd_loss 0.0703 (0.0742) lr 4.1221e-04 eta 0:06:51
epoch [37/50] batch [140/288] time 0.113 (0.106) data 0.000 (0.003) loss 1.2029 (1.0767) ce_loss 1.0703 (0.9367) teacher_loss 1.0655 (0.9313) loss_zs_kd 0.1090 (0.1531) loss_oracle 0.0829 (0.0689) acc 68.7500 (75.1116) kd_loss 0.0845 (0.0738) lr 4.1221e-04 eta 0:06:51
epoch [37/50] batch [160/288] time 0.108 (0.107) data 0.000 (0.002) loss 0.9681 (1.0710) ce_loss 0.8506 (0.9302) teacher_loss 0.8345 (0.9251) loss_zs_kd 0.1160 (0.1534) loss_oracle 0.0757 (0.0692) acc 78.1250 (75.2344) kd_loss 0.0829 (0.0732) lr 4.1221e-04 eta 0:06:52
epoch [37/50] batch [180/288] time 0.112 (0.108) data 0.000 (0.002) loss 1.0295 (1.0596) ce_loss 0.8877 (0.9193) teacher_loss 0.8809 (0.9139) loss_zs_kd 0.1630 (0.1530) loss_oracle 0.0671 (0.0692) acc 75.0000 (75.4167) kd_loss 0.0885 (0.0731) lr 4.1221e-04 eta 0:06:54
epoch [37/50] batch [200/288] time 0.102 (0.108) data 0.000 (0.002) loss 0.8994 (1.0599) ce_loss 0.7729 (0.9197) teacher_loss 0.7636 (0.9144) loss_zs_kd 0.1421 (0.1531) loss_oracle 0.0647 (0.0690) acc 75.0000 (75.5312) kd_loss 0.0659 (0.0721) lr 4.1221e-04 eta 0:06:53
epoch [37/50] batch [220/288] time 0.108 (0.108) data 0.000 (0.002) loss 1.3528 (1.0628) ce_loss 1.1953 (0.9226) teacher_loss 1.1828 (0.9171) loss_zs_kd 0.1903 (0.1529) loss_oracle 0.0749 (0.0693) acc 68.7500 (75.3835) kd_loss 0.0679 (0.0720) lr 4.1221e-04 eta 0:06:51
epoch [37/50] batch [240/288] time 0.101 (0.108) data 0.000 (0.002) loss 0.8584 (1.0631) ce_loss 0.7319 (0.9231) teacher_loss 0.7229 (0.9177) loss_zs_kd 0.1604 (0.1523) loss_oracle 0.0553 (0.0693) acc 84.3750 (75.3125) kd_loss 0.0589 (0.0714) lr 4.1221e-04 eta 0:06:49
epoch [37/50] batch [260/288] time 0.100 (0.108) data 0.000 (0.002) loss 1.1733 (1.0673) ce_loss 1.0234 (0.9270) teacher_loss 1.0311 (0.9213) loss_zs_kd 0.1747 (0.1523) loss_oracle 0.0548 (0.0698) acc 81.2500 (75.1442) kd_loss 0.0516 (0.0710) lr 4.1221e-04 eta 0:06:46
epoch [37/50] batch [280/288] time 0.108 (0.108) data 0.000 (0.002) loss 0.8179 (1.0620) ce_loss 0.6792 (0.9210) teacher_loss 0.6748 (0.9152) loss_zs_kd 0.1669 (0.1532) loss_oracle 0.0596 (0.0701) acc 87.5000 (75.3683) kd_loss 0.0541 (0.0705) lr 4.1221e-04 eta 0:06:43
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,447
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,028
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.2%
******* Domain a best val acc:      87.7%, epoch: 33 *******
******* Domain a best val test acc: 83.3%, epoch: 33 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [38/50] batch [20/288] time 0.124 (0.144) data 0.000 (0.017) loss 1.2646 (1.1184) ce_loss 1.1553 (0.9733) teacher_loss 1.1481 (0.9657) loss_zs_kd 0.1045 (0.1581) loss_oracle 0.0643 (0.0736) acc 68.7500 (72.9688) kd_loss 0.0591 (0.0723) lr 3.6258e-04 eta 0:08:57
epoch [38/50] batch [40/288] time 0.125 (0.137) data 0.000 (0.009) loss 0.5111 (1.0455) ce_loss 0.3330 (0.9026) teacher_loss 0.3325 (0.8951) loss_zs_kd 0.2351 (0.1562) loss_oracle 0.0610 (0.0723) acc 87.5000 (75.1562) kd_loss 0.0627 (0.0725) lr 3.6258e-04 eta 0:08:26
epoch [38/50] batch [60/288] time 0.131 (0.135) data 0.001 (0.006) loss 0.8336 (1.0492) ce_loss 0.6763 (0.9048) teacher_loss 0.6780 (0.8984) loss_zs_kd 0.1582 (0.1558) loss_oracle 0.0765 (0.0729) acc 78.1250 (75.3125) kd_loss 0.0608 (0.0717) lr 3.6258e-04 eta 0:08:15
epoch [38/50] batch [80/288] time 0.134 (0.134) data 0.000 (0.005) loss 1.0732 (1.0594) ce_loss 0.9785 (0.9167) teacher_loss 0.9770 (0.9113) loss_zs_kd 0.1074 (0.1548) loss_oracle 0.0425 (0.0707) acc 78.1250 (75.2344) kd_loss 0.0420 (0.0677) lr 3.6258e-04 eta 0:08:11
epoch [38/50] batch [100/288] time 0.113 (0.133) data 0.000 (0.004) loss 1.0984 (1.0782) ce_loss 0.9551 (0.9369) teacher_loss 0.9538 (0.9308) loss_zs_kd 0.1261 (0.1537) loss_oracle 0.0816 (0.0705) acc 78.1250 (75.0312) kd_loss 0.0696 (0.0661) lr 3.6258e-04 eta 0:08:04
epoch [38/50] batch [120/288] time 0.103 (0.128) data 0.000 (0.003) loss 1.5538 (1.0847) ce_loss 1.4297 (0.9447) teacher_loss 1.3963 (0.9384) loss_zs_kd 0.1583 (0.1524) loss_oracle 0.0784 (0.0701) acc 65.6250 (74.5573) kd_loss 0.0742 (0.0650) lr 3.6258e-04 eta 0:07:43
epoch [38/50] batch [140/288] time 0.113 (0.125) data 0.000 (0.003) loss 0.9233 (1.0924) ce_loss 0.8164 (0.9515) teacher_loss 0.7742 (0.9457) loss_zs_kd 0.1422 (0.1538) loss_oracle 0.0780 (0.0698) acc 84.3750 (74.2857) kd_loss 0.0663 (0.0641) lr 3.6258e-04 eta 0:07:29
epoch [38/50] batch [160/288] time 0.112 (0.122) data 0.000 (0.002) loss 0.7522 (1.1034) ce_loss 0.6177 (0.9609) teacher_loss 0.6210 (0.9557) loss_zs_kd 0.1241 (0.1551) loss_oracle 0.0691 (0.0701) acc 87.5000 (74.0430) kd_loss 0.0668 (0.0633) lr 3.6258e-04 eta 0:07:17
epoch [38/50] batch [180/288] time 0.104 (0.120) data 0.000 (0.002) loss 1.1727 (1.1106) ce_loss 1.0156 (0.9670) teacher_loss 1.0099 (0.9622) loss_zs_kd 0.1903 (0.1570) loss_oracle 0.0676 (0.0699) acc 78.1250 (74.0104) kd_loss 0.0565 (0.0626) lr 3.6258e-04 eta 0:07:09
epoch [38/50] batch [200/288] time 0.119 (0.120) data 0.000 (0.002) loss 0.8834 (1.0989) ce_loss 0.7563 (0.9559) teacher_loss 0.7610 (0.9512) loss_zs_kd 0.1093 (0.1558) loss_oracle 0.0677 (0.0698) acc 75.0000 (74.3906) kd_loss 0.0423 (0.0622) lr 3.6258e-04 eta 0:07:06
epoch [38/50] batch [220/288] time 0.115 (0.120) data 0.000 (0.002) loss 0.7326 (1.0957) ce_loss 0.5952 (0.9531) teacher_loss 0.5844 (0.9481) loss_zs_kd 0.1491 (0.1549) loss_oracle 0.0736 (0.0701) acc 81.2500 (74.4034) kd_loss 0.0516 (0.0621) lr 3.6258e-04 eta 0:07:01
epoch [38/50] batch [240/288] time 0.095 (0.118) data 0.000 (0.002) loss 0.6374 (1.0950) ce_loss 0.5103 (0.9525) teacher_loss 0.5092 (0.9474) loss_zs_kd 0.1256 (0.1548) loss_oracle 0.0654 (0.0703) acc 81.2500 (74.5052) kd_loss 0.0462 (0.0616) lr 3.6258e-04 eta 0:06:53
epoch [38/50] batch [260/288] time 0.116 (0.117) data 0.000 (0.002) loss 1.0338 (1.0926) ce_loss 0.9131 (0.9506) teacher_loss 0.8997 (0.9457) loss_zs_kd 0.1262 (0.1538) loss_oracle 0.0710 (0.0700) acc 81.2500 (74.5072) kd_loss 0.0732 (0.0611) lr 3.6258e-04 eta 0:06:46
epoch [38/50] batch [280/288] time 0.088 (0.116) data 0.000 (0.002) loss 0.6645 (1.0855) ce_loss 0.5459 (0.9441) teacher_loss 0.5554 (0.9390) loss_zs_kd 0.1287 (0.1529) loss_oracle 0.0447 (0.0701) acc 87.5000 (74.6540) kd_loss 0.0347 (0.0608) lr 3.6258e-04 eta 0:06:41
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,452
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,019
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 80.0%
******* Domain a best val acc:      87.7%, epoch: 33 *******
******* Domain a best val test acc: 83.3%, epoch: 33 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [39/50] batch [20/288] time 0.086 (0.110) data 0.000 (0.012) loss 1.0496 (1.0382) ce_loss 0.9214 (0.8979) teacher_loss 0.9086 (0.8958) loss_zs_kd 0.1313 (0.1466) loss_oracle 0.0754 (0.0691) acc 71.8750 (73.5938) kd_loss 0.0590 (0.0567) lr 3.1545e-04 eta 0:06:17
epoch [39/50] batch [40/288] time 0.086 (0.098) data 0.000 (0.006) loss 1.3086 (1.0715) ce_loss 1.1670 (0.9276) teacher_loss 1.1418 (0.9249) loss_zs_kd 0.1753 (0.1524) loss_oracle 0.0791 (0.0705) acc 59.3750 (73.6719) kd_loss 0.0543 (0.0585) lr 3.1545e-04 eta 0:05:36
epoch [39/50] batch [60/288] time 0.091 (0.095) data 0.000 (0.004) loss 0.9212 (1.0647) ce_loss 0.8174 (0.9233) teacher_loss 0.8191 (0.9205) loss_zs_kd 0.0957 (0.1497) loss_oracle 0.0543 (0.0693) acc 71.8750 (73.7500) kd_loss 0.0452 (0.0575) lr 3.1545e-04 eta 0:05:24
epoch [39/50] batch [80/288] time 0.091 (0.095) data 0.000 (0.003) loss 1.4032 (1.0590) ce_loss 1.2646 (0.9180) teacher_loss 1.2474 (0.9148) loss_zs_kd 0.1313 (0.1508) loss_oracle 0.0902 (0.0688) acc 65.6250 (74.3750) kd_loss 0.0545 (0.0563) lr 3.1545e-04 eta 0:05:21
epoch [39/50] batch [100/288] time 0.095 (0.095) data 0.000 (0.003) loss 1.0088 (1.0629) ce_loss 0.8794 (0.9227) teacher_loss 0.8795 (0.9188) loss_zs_kd 0.1340 (0.1501) loss_oracle 0.0623 (0.0691) acc 75.0000 (74.5000) kd_loss 0.0537 (0.0576) lr 3.1545e-04 eta 0:05:20
epoch [39/50] batch [120/288] time 0.094 (0.096) data 0.001 (0.002) loss 0.7552 (1.0687) ce_loss 0.5938 (0.9292) teacher_loss 0.5996 (0.9250) loss_zs_kd 0.1214 (0.1497) loss_oracle 0.0949 (0.0688) acc 84.3750 (74.4792) kd_loss 0.0633 (0.0582) lr 3.1545e-04 eta 0:05:19
epoch [39/50] batch [140/288] time 0.091 (0.096) data 0.000 (0.002) loss 1.2500 (1.0694) ce_loss 1.1230 (0.9286) teacher_loss 1.1014 (0.9240) loss_zs_kd 0.1819 (0.1526) loss_oracle 0.0576 (0.0690) acc 65.6250 (74.5312) kd_loss 0.0487 (0.0584) lr 3.1545e-04 eta 0:05:17
epoch [39/50] batch [160/288] time 0.093 (0.096) data 0.000 (0.002) loss 1.1634 (1.0646) ce_loss 1.0020 (0.9239) teacher_loss 1.0106 (0.9197) loss_zs_kd 0.1821 (0.1528) loss_oracle 0.0617 (0.0685) acc 75.0000 (74.8633) kd_loss 0.0654 (0.0585) lr 3.1545e-04 eta 0:05:16
epoch [39/50] batch [180/288] time 0.097 (0.096) data 0.000 (0.002) loss 0.9075 (1.0610) ce_loss 0.7393 (0.9207) teacher_loss 0.7406 (0.9161) loss_zs_kd 0.1864 (0.1517) loss_oracle 0.0737 (0.0690) acc 81.2500 (74.8438) kd_loss 0.0678 (0.0590) lr 3.1545e-04 eta 0:05:13
epoch [39/50] batch [200/288] time 0.099 (0.096) data 0.000 (0.001) loss 0.8621 (1.0711) ce_loss 0.6934 (0.9307) teacher_loss 0.6983 (0.9262) loss_zs_kd 0.1637 (0.1518) loss_oracle 0.0820 (0.0690) acc 78.1250 (74.6875) kd_loss 0.0848 (0.0597) lr 3.1545e-04 eta 0:05:12
epoch [39/50] batch [220/288] time 0.099 (0.097) data 0.000 (0.001) loss 1.3778 (1.0694) ce_loss 1.2344 (0.9291) teacher_loss 1.2145 (0.9249) loss_zs_kd 0.1708 (0.1512) loss_oracle 0.0779 (0.0689) acc 75.0000 (74.9290) kd_loss 0.0604 (0.0598) lr 3.1545e-04 eta 0:05:12
epoch [39/50] batch [240/288] time 0.102 (0.097) data 0.000 (0.001) loss 0.9218 (1.0727) ce_loss 0.7646 (0.9317) teacher_loss 0.7525 (0.9274) loss_zs_kd 0.1748 (0.1526) loss_oracle 0.0819 (0.0690) acc 71.8750 (74.7396) kd_loss 0.0797 (0.0603) lr 3.1545e-04 eta 0:05:12
epoch [39/50] batch [260/288] time 0.099 (0.098) data 0.000 (0.001) loss 0.6261 (1.0721) ce_loss 0.5166 (0.9318) teacher_loss 0.5137 (0.9271) loss_zs_kd 0.1026 (0.1516) loss_oracle 0.0611 (0.0692) acc 84.3750 (74.6514) kd_loss 0.0602 (0.0605) lr 3.1545e-04 eta 0:05:12
epoch [39/50] batch [280/288] time 0.102 (0.098) data 0.000 (0.001) loss 0.9145 (1.0707) ce_loss 0.8120 (0.9306) teacher_loss 0.7804 (0.9258) loss_zs_kd 0.1191 (0.1516) loss_oracle 0.0745 (0.0692) acc 78.1250 (74.6205) kd_loss 0.0799 (0.0604) lr 3.1545e-04 eta 0:05:11
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,459
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 87.3%
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 80.1%
******* Domain a best val acc:      87.8%, epoch: 39 *******
******* Domain a best val test acc: 83.3%, epoch: 39 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [40/50] batch [20/288] time 0.140 (0.152) data 0.000 (0.020) loss 0.9809 (1.0532) ce_loss 0.8335 (0.9113) teacher_loss 0.8328 (0.9065) loss_zs_kd 0.1379 (0.1491) loss_oracle 0.0792 (0.0721) acc 75.0000 (75.6250) kd_loss 0.0626 (0.0620) lr 2.7103e-04 eta 0:07:58
epoch [40/50] batch [40/288] time 0.132 (0.142) data 0.000 (0.010) loss 1.3653 (1.0879) ce_loss 1.1963 (0.9432) teacher_loss 1.1994 (0.9404) loss_zs_kd 0.2051 (0.1568) loss_oracle 0.0634 (0.0691) acc 71.8750 (74.3750) kd_loss 0.0445 (0.0596) lr 2.7103e-04 eta 0:07:23
epoch [40/50] batch [60/288] time 0.111 (0.134) data 0.000 (0.007) loss 0.9354 (1.0648) ce_loss 0.7974 (0.9234) teacher_loss 0.7925 (0.9193) loss_zs_kd 0.1589 (0.1529) loss_oracle 0.0635 (0.0691) acc 78.1250 (74.6875) kd_loss 0.0612 (0.0595) lr 2.7103e-04 eta 0:06:55
epoch [40/50] batch [80/288] time 0.123 (0.130) data 0.000 (0.005) loss 1.3143 (1.0728) ce_loss 1.1699 (0.9301) teacher_loss 1.1671 (0.9261) loss_zs_kd 0.1712 (0.1547) loss_oracle 0.0616 (0.0693) acc 65.6250 (74.4531) kd_loss 0.0630 (0.0614) lr 2.7103e-04 eta 0:06:40
epoch [40/50] batch [100/288] time 0.127 (0.129) data 0.000 (0.004) loss 1.0744 (1.0772) ce_loss 0.9668 (0.9369) teacher_loss 0.9412 (0.9318) loss_zs_kd 0.1245 (0.1520) loss_oracle 0.0709 (0.0694) acc 68.7500 (74.3438) kd_loss 0.0774 (0.0619) lr 2.7103e-04 eta 0:06:35
epoch [40/50] batch [120/288] time 0.102 (0.128) data 0.000 (0.004) loss 1.0419 (1.0740) ce_loss 0.8901 (0.9339) teacher_loss 0.8892 (0.9288) loss_zs_kd 0.1723 (0.1523) loss_oracle 0.0666 (0.0690) acc 78.1250 (74.5312) kd_loss 0.0666 (0.0625) lr 2.7103e-04 eta 0:06:29
epoch [40/50] batch [140/288] time 0.107 (0.124) data 0.000 (0.003) loss 1.0855 (1.0743) ce_loss 0.9531 (0.9341) teacher_loss 0.9665 (0.9292) loss_zs_kd 0.1199 (0.1517) loss_oracle 0.0591 (0.0692) acc 68.7500 (74.5312) kd_loss 0.0337 (0.0636) lr 2.7103e-04 eta 0:06:16
epoch [40/50] batch [160/288] time 0.107 (0.122) data 0.000 (0.003) loss 1.4050 (1.0745) ce_loss 1.2578 (0.9341) teacher_loss 1.2692 (0.9294) loss_zs_kd 0.1813 (0.1528) loss_oracle 0.0452 (0.0688) acc 78.1250 (74.7266) kd_loss 0.0533 (0.0638) lr 2.7103e-04 eta 0:06:05
epoch [40/50] batch [180/288] time 0.104 (0.120) data 0.000 (0.003) loss 0.8463 (1.0854) ce_loss 0.7207 (0.9450) teacher_loss 0.7244 (0.9402) loss_zs_kd 0.1402 (0.1531) loss_oracle 0.0518 (0.0686) acc 84.3750 (74.6701) kd_loss 0.0590 (0.0637) lr 2.7103e-04 eta 0:05:57
epoch [40/50] batch [200/288] time 0.116 (0.118) data 0.000 (0.002) loss 1.0921 (1.0772) ce_loss 0.9014 (0.9369) teacher_loss 0.9177 (0.9323) loss_zs_kd 0.1956 (0.1527) loss_oracle 0.0765 (0.0685) acc 68.7500 (74.8438) kd_loss 0.0750 (0.0638) lr 2.7103e-04 eta 0:05:50
epoch [40/50] batch [220/288] time 0.100 (0.117) data 0.000 (0.002) loss 0.8905 (1.0775) ce_loss 0.8042 (0.9371) teacher_loss 0.8027 (0.9328) loss_zs_kd 0.0749 (0.1534) loss_oracle 0.0503 (0.0680) acc 81.2500 (74.8864) kd_loss 0.0700 (0.0634) lr 2.7103e-04 eta 0:05:44
epoch [40/50] batch [240/288] time 0.108 (0.116) data 0.000 (0.002) loss 0.7144 (1.0690) ce_loss 0.5581 (0.9282) teacher_loss 0.5573 (0.9239) loss_zs_kd 0.1755 (0.1531) loss_oracle 0.0693 (0.0686) acc 84.3750 (75.1693) kd_loss 0.0714 (0.0648) lr 2.7103e-04 eta 0:05:39
epoch [40/50] batch [260/288] time 0.100 (0.115) data 0.000 (0.002) loss 1.2512 (1.0650) ce_loss 1.1045 (0.9236) teacher_loss 1.0998 (0.9195) loss_zs_kd 0.1808 (0.1541) loss_oracle 0.0610 (0.0685) acc 68.7500 (75.2163) kd_loss 0.0603 (0.0650) lr 2.7103e-04 eta 0:05:34
epoch [40/50] batch [280/288] time 0.106 (0.114) data 0.000 (0.002) loss 1.2258 (1.0624) ce_loss 1.0938 (0.9215) teacher_loss 1.0770 (0.9172) loss_zs_kd 0.1920 (0.1533) loss_oracle 0.0528 (0.0685) acc 75.0000 (75.2344) kd_loss 0.0381 (0.0653) lr 2.7103e-04 eta 0:05:30
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,449
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,023
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.1%
******* Domain a best val acc:      87.8%, epoch: 39 *******
******* Domain a best val test acc: 83.3%, epoch: 39 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [41/50] batch [20/288] time 0.137 (0.144) data 0.001 (0.014) loss 0.8845 (1.0762) ce_loss 0.7075 (0.9252) teacher_loss 0.7140 (0.9192) loss_zs_kd 0.1740 (0.1720) loss_oracle 0.0835 (0.0709) acc 78.1250 (75.4688) kd_loss 0.0836 (0.0759) lr 2.2949e-04 eta 0:06:52
epoch [41/50] batch [40/288] time 0.131 (0.138) data 0.000 (0.007) loss 0.9324 (1.0696) ce_loss 0.8027 (0.9273) teacher_loss 0.7875 (0.9207) loss_zs_kd 0.1565 (0.1561) loss_oracle 0.0667 (0.0708) acc 78.1250 (75.1562) kd_loss 0.0829 (0.0728) lr 2.2949e-04 eta 0:06:30
epoch [41/50] batch [60/288] time 0.136 (0.135) data 0.000 (0.005) loss 1.2676 (1.0806) ce_loss 1.1201 (0.9401) teacher_loss 1.1262 (0.9338) loss_zs_kd 0.1694 (0.1509) loss_oracle 0.0566 (0.0713) acc 68.7500 (74.6875) kd_loss 0.0443 (0.0717) lr 2.2949e-04 eta 0:06:20
epoch [41/50] batch [80/288] time 0.123 (0.133) data 0.000 (0.004) loss 0.6368 (1.0803) ce_loss 0.5098 (0.9412) teacher_loss 0.5102 (0.9361) loss_zs_kd 0.1239 (0.1486) loss_oracle 0.0647 (0.0699) acc 81.2500 (74.9609) kd_loss 0.0645 (0.0699) lr 2.2949e-04 eta 0:06:11
epoch [41/50] batch [100/288] time 0.134 (0.131) data 0.000 (0.003) loss 1.5583 (1.0847) ce_loss 1.4111 (0.9435) teacher_loss 1.3926 (0.9393) loss_zs_kd 0.1785 (0.1518) loss_oracle 0.0764 (0.0695) acc 65.6250 (74.6562) kd_loss 0.0807 (0.0686) lr 2.2949e-04 eta 0:06:03
epoch [41/50] batch [120/288] time 0.138 (0.131) data 0.000 (0.003) loss 1.4068 (1.0830) ce_loss 1.2480 (0.9416) teacher_loss 1.2415 (0.9370) loss_zs_kd 0.2030 (0.1513) loss_oracle 0.0637 (0.0703) acc 65.6250 (74.6354) kd_loss 0.0747 (0.0691) lr 2.2949e-04 eta 0:06:02
epoch [41/50] batch [140/288] time 0.133 (0.131) data 0.000 (0.002) loss 1.2958 (1.0763) ce_loss 1.1719 (0.9347) teacher_loss 1.1747 (0.9308) loss_zs_kd 0.1295 (0.1511) loss_oracle 0.0563 (0.0699) acc 68.7500 (75.0000) kd_loss 0.0670 (0.0690) lr 2.2949e-04 eta 0:06:00
epoch [41/50] batch [160/288] time 0.126 (0.131) data 0.000 (0.002) loss 0.7493 (1.0658) ce_loss 0.6396 (0.9253) teacher_loss 0.6464 (0.9211) loss_zs_kd 0.0982 (0.1505) loss_oracle 0.0538 (0.0694) acc 84.3750 (75.2148) kd_loss 0.0659 (0.0691) lr 2.2949e-04 eta 0:05:57
epoch [41/50] batch [180/288] time 0.125 (0.131) data 0.000 (0.002) loss 1.8225 (1.0661) ce_loss 1.6309 (0.9249) teacher_loss 1.6205 (0.9207) loss_zs_kd 0.2509 (0.1511) loss_oracle 0.0766 (0.0699) acc 59.3750 (75.3125) kd_loss 0.0682 (0.0697) lr 2.2949e-04 eta 0:05:53
epoch [41/50] batch [200/288] time 0.122 (0.130) data 0.000 (0.002) loss 1.0512 (1.0672) ce_loss 0.9268 (0.9263) teacher_loss 0.9182 (0.9217) loss_zs_kd 0.1423 (0.1516) loss_oracle 0.0618 (0.0697) acc 65.6250 (75.3281) kd_loss 0.0606 (0.0696) lr 2.2949e-04 eta 0:05:48
epoch [41/50] batch [220/288] time 0.121 (0.129) data 0.000 (0.002) loss 1.0895 (1.0670) ce_loss 0.9229 (0.9255) teacher_loss 0.9164 (0.9210) loss_zs_kd 0.2070 (0.1527) loss_oracle 0.0696 (0.0696) acc 81.2500 (75.3551) kd_loss 0.0817 (0.0692) lr 2.2949e-04 eta 0:05:44
epoch [41/50] batch [240/288] time 0.099 (0.128) data 0.000 (0.001) loss 1.0573 (1.0656) ce_loss 0.8789 (0.9247) teacher_loss 0.8757 (0.9202) loss_zs_kd 0.1995 (0.1513) loss_oracle 0.0818 (0.0697) acc 81.2500 (75.4167) kd_loss 0.0585 (0.0693) lr 2.2949e-04 eta 0:05:38
epoch [41/50] batch [260/288] time 0.101 (0.126) data 0.000 (0.001) loss 1.6420 (1.0674) ce_loss 1.4932 (0.9267) teacher_loss 1.4866 (0.9219) loss_zs_kd 0.1805 (0.1516) loss_oracle 0.0651 (0.0698) acc 59.3750 (75.3606) kd_loss 0.0683 (0.0687) lr 2.2949e-04 eta 0:05:31
epoch [41/50] batch [280/288] time 0.105 (0.125) data 0.000 (0.001) loss 0.8199 (1.0679) ce_loss 0.7002 (0.9273) teacher_loss 0.6913 (0.9222) loss_zs_kd 0.1570 (0.1512) loss_oracle 0.0502 (0.0700) acc 81.2500 (75.2679) kd_loss 0.0583 (0.0685) lr 2.2949e-04 eta 0:05:24
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,446
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,025
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.2%
******* Domain a best val acc:      87.8%, epoch: 39 *******
******* Domain a best val test acc: 83.3%, epoch: 39 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [42/50] batch [20/288] time 0.115 (0.127) data 0.000 (0.016) loss 0.9092 (1.0247) ce_loss 0.7959 (0.8909) teacher_loss 0.7869 (0.8868) loss_zs_kd 0.1155 (0.1445) loss_oracle 0.0645 (0.0656) acc 78.1250 (75.6250) kd_loss 0.0516 (0.0607) lr 1.9098e-04 eta 0:05:25
epoch [42/50] batch [40/288] time 0.110 (0.114) data 0.000 (0.008) loss 1.0406 (1.0563) ce_loss 0.9209 (0.9182) teacher_loss 0.9208 (0.9135) loss_zs_kd 0.1321 (0.1491) loss_oracle 0.0537 (0.0682) acc 75.0000 (75.7031) kd_loss 0.0533 (0.0611) lr 1.9098e-04 eta 0:04:51
epoch [42/50] batch [60/288] time 0.102 (0.111) data 0.000 (0.006) loss 1.4297 (1.0828) ce_loss 1.3018 (0.9425) teacher_loss 1.2928 (0.9372) loss_zs_kd 0.1327 (0.1550) loss_oracle 0.0706 (0.0681) acc 68.7500 (75.1562) kd_loss 0.0564 (0.0612) lr 1.9098e-04 eta 0:04:40
epoch [42/50] batch [80/288] time 0.106 (0.109) data 0.000 (0.004) loss 0.8446 (1.0696) ce_loss 0.7051 (0.9283) teacher_loss 0.7125 (0.9225) loss_zs_kd 0.1504 (0.1565) loss_oracle 0.0570 (0.0688) acc 81.2500 (74.9609) kd_loss 0.0519 (0.0617) lr 1.9098e-04 eta 0:04:33
epoch [42/50] batch [100/288] time 0.099 (0.108) data 0.000 (0.004) loss 1.0373 (1.0824) ce_loss 0.8911 (0.9404) teacher_loss 0.8856 (0.9348) loss_zs_kd 0.1679 (0.1582) loss_oracle 0.0678 (0.0685) acc 78.1250 (74.5938) kd_loss 0.0732 (0.0612) lr 1.9098e-04 eta 0:04:28
epoch [42/50] batch [120/288] time 0.110 (0.107) data 0.000 (0.003) loss 0.8358 (1.0562) ce_loss 0.6909 (0.9157) teacher_loss 0.6745 (0.9106) loss_zs_kd 0.1711 (0.1548) loss_oracle 0.0758 (0.0683) acc 75.0000 (75.2083) kd_loss 0.0709 (0.0604) lr 1.9098e-04 eta 0:04:24
epoch [42/50] batch [140/288] time 0.103 (0.106) data 0.001 (0.003) loss 1.2273 (1.0537) ce_loss 1.0996 (0.9124) teacher_loss 1.0894 (0.9074) loss_zs_kd 0.1383 (0.1560) loss_oracle 0.0688 (0.0683) acc 62.5000 (75.3795) kd_loss 0.0481 (0.0597) lr 1.9098e-04 eta 0:04:21
epoch [42/50] batch [160/288] time 0.113 (0.106) data 0.000 (0.002) loss 1.2475 (1.0588) ce_loss 1.0801 (0.9165) teacher_loss 1.0771 (0.9113) loss_zs_kd 0.2331 (0.1573) loss_oracle 0.0538 (0.0688) acc 71.8750 (75.2539) kd_loss 0.0511 (0.0596) lr 1.9098e-04 eta 0:04:17
epoch [42/50] batch [180/288] time 0.106 (0.106) data 0.000 (0.002) loss 1.1714 (1.0552) ce_loss 0.9966 (0.9127) teacher_loss 0.9952 (0.9077) loss_zs_kd 0.2004 (0.1569) loss_oracle 0.0760 (0.0691) acc 75.0000 (75.3299) kd_loss 0.0590 (0.0594) lr 1.9098e-04 eta 0:04:15
epoch [42/50] batch [200/288] time 0.107 (0.105) data 0.000 (0.002) loss 1.0062 (1.0555) ce_loss 0.8823 (0.9135) teacher_loss 0.8914 (0.9082) loss_zs_kd 0.1244 (0.1566) loss_oracle 0.0527 (0.0689) acc 71.8750 (75.4062) kd_loss 0.0389 (0.0588) lr 1.9098e-04 eta 0:04:12
epoch [42/50] batch [220/288] time 0.101 (0.105) data 0.001 (0.002) loss 1.0107 (1.0600) ce_loss 0.8862 (0.9178) teacher_loss 0.8786 (0.9122) loss_zs_kd 0.1317 (0.1561) loss_oracle 0.0662 (0.0697) acc 78.1250 (75.3125) kd_loss 0.0507 (0.0590) lr 1.9098e-04 eta 0:04:09
epoch [42/50] batch [240/288] time 0.107 (0.105) data 0.000 (0.002) loss 1.1286 (1.0587) ce_loss 0.9673 (0.9167) teacher_loss 0.9479 (0.9111) loss_zs_kd 0.1580 (0.1552) loss_oracle 0.1017 (0.0700) acc 78.1250 (75.4427) kd_loss 0.0813 (0.0590) lr 1.9098e-04 eta 0:04:07
epoch [42/50] batch [260/288] time 0.108 (0.105) data 0.000 (0.002) loss 1.2799 (1.0646) ce_loss 1.1318 (0.9225) teacher_loss 1.1294 (0.9164) loss_zs_kd 0.1628 (0.1550) loss_oracle 0.0691 (0.0707) acc 71.8750 (75.2284) kd_loss 0.0681 (0.0593) lr 1.9098e-04 eta 0:04:05
epoch [42/50] batch [280/288] time 0.106 (0.105) data 0.000 (0.001) loss 0.9471 (1.0594) ce_loss 0.8140 (0.9169) teacher_loss 0.8152 (0.9113) loss_zs_kd 0.1362 (0.1540) loss_oracle 0.0639 (0.0710) acc 81.2500 (75.3906) kd_loss 0.0559 (0.0595) lr 1.9098e-04 eta 0:04:03
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,452
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,022
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 80.2%
******* Domain a best val acc:      87.8%, epoch: 39 *******
******* Domain a best val test acc: 83.3%, epoch: 39 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [43/50] batch [20/288] time 0.106 (0.121) data 0.000 (0.012) loss 1.4210 (1.1314) ce_loss 1.2666 (0.9886) teacher_loss 1.2354 (0.9803) loss_zs_kd 0.1401 (0.1535) loss_oracle 0.1156 (0.0744) acc 65.6250 (71.8750) kd_loss 0.0877 (0.0647) lr 1.5567e-04 eta 0:04:36
epoch [43/50] batch [40/288] time 0.106 (0.115) data 0.000 (0.006) loss 1.1458 (1.1043) ce_loss 1.0117 (0.9629) teacher_loss 1.0103 (0.9573) loss_zs_kd 0.1429 (0.1545) loss_oracle 0.0641 (0.0698) acc 68.7500 (73.6719) kd_loss 0.0467 (0.0611) lr 1.5567e-04 eta 0:04:19
epoch [43/50] batch [60/288] time 0.109 (0.113) data 0.000 (0.004) loss 1.8445 (1.1259) ce_loss 1.6973 (0.9815) teacher_loss 1.7014 (0.9754) loss_zs_kd 0.1604 (0.1592) loss_oracle 0.0629 (0.0709) acc 56.2500 (73.3333) kd_loss 0.0360 (0.0627) lr 1.5567e-04 eta 0:04:12
epoch [43/50] batch [80/288] time 0.120 (0.112) data 0.000 (0.003) loss 0.6501 (1.0747) ce_loss 0.5542 (0.9337) teacher_loss 0.5592 (0.9273) loss_zs_kd 0.0732 (0.1509) loss_oracle 0.0543 (0.0719) acc 87.5000 (74.7266) kd_loss 0.0577 (0.0643) lr 1.5567e-04 eta 0:04:08
epoch [43/50] batch [100/288] time 0.125 (0.115) data 0.001 (0.003) loss 1.4688 (1.0814) ce_loss 1.2979 (0.9404) teacher_loss 1.2876 (0.9338) loss_zs_kd 0.1759 (0.1496) loss_oracle 0.0932 (0.0728) acc 65.6250 (74.3438) kd_loss 0.0802 (0.0659) lr 1.5567e-04 eta 0:04:12
epoch [43/50] batch [120/288] time 0.131 (0.117) data 0.000 (0.002) loss 0.8331 (1.0787) ce_loss 0.6973 (0.9364) teacher_loss 0.6950 (0.9305) loss_zs_kd 0.1239 (0.1519) loss_oracle 0.0762 (0.0723) acc 75.0000 (74.5833) kd_loss 0.0534 (0.0654) lr 1.5567e-04 eta 0:04:14
epoch [43/50] batch [140/288] time 0.126 (0.118) data 0.000 (0.002) loss 0.8895 (1.0780) ce_loss 0.7290 (0.9348) teacher_loss 0.7362 (0.9291) loss_zs_kd 0.1617 (0.1521) loss_oracle 0.0725 (0.0729) acc 78.1250 (74.8438) kd_loss 0.0592 (0.0658) lr 1.5567e-04 eta 0:04:15
epoch [43/50] batch [160/288] time 0.125 (0.119) data 0.000 (0.002) loss 0.9792 (1.0718) ce_loss 0.8257 (0.9277) teacher_loss 0.8163 (0.9223) loss_zs_kd 0.1472 (0.1528) loss_oracle 0.0894 (0.0731) acc 75.0000 (74.8828) kd_loss 0.0769 (0.0664) lr 1.5567e-04 eta 0:04:15
epoch [43/50] batch [180/288] time 0.116 (0.120) data 0.000 (0.002) loss 0.8372 (1.0629) ce_loss 0.7207 (0.9188) teacher_loss 0.7261 (0.9143) loss_zs_kd 0.1113 (0.1519) loss_oracle 0.0554 (0.0727) acc 81.2500 (75.0694) kd_loss 0.0510 (0.0668) lr 1.5567e-04 eta 0:04:13
epoch [43/50] batch [200/288] time 0.100 (0.118) data 0.000 (0.001) loss 1.0136 (1.0648) ce_loss 0.8813 (0.9206) teacher_loss 0.8655 (0.9163) loss_zs_kd 0.1534 (0.1518) loss_oracle 0.0714 (0.0727) acc 81.2500 (75.0781) kd_loss 0.0694 (0.0671) lr 1.5567e-04 eta 0:04:08
epoch [43/50] batch [220/288] time 0.099 (0.116) data 0.000 (0.001) loss 1.0385 (1.0659) ce_loss 0.8809 (0.9217) teacher_loss 0.8747 (0.9176) loss_zs_kd 0.1573 (0.1518) loss_oracle 0.0851 (0.0724) acc 68.7500 (75.1136) kd_loss 0.0758 (0.0672) lr 1.5567e-04 eta 0:04:02
epoch [43/50] batch [240/288] time 0.099 (0.115) data 0.000 (0.001) loss 1.1643 (1.0620) ce_loss 0.9570 (0.9179) teacher_loss 0.9633 (0.9136) loss_zs_kd 0.2384 (0.1517) loss_oracle 0.0818 (0.0726) acc 68.7500 (75.1172) kd_loss 0.0859 (0.0680) lr 1.5567e-04 eta 0:03:57
epoch [43/50] batch [260/288] time 0.103 (0.114) data 0.000 (0.001) loss 0.8840 (1.0618) ce_loss 0.7700 (0.9178) teacher_loss 0.7558 (0.9133) loss_zs_kd 0.1461 (0.1521) loss_oracle 0.0552 (0.0725) acc 78.1250 (75.0962) kd_loss 0.0740 (0.0684) lr 1.5567e-04 eta 0:03:52
epoch [43/50] batch [280/288] time 0.106 (0.113) data 0.000 (0.001) loss 1.0729 (1.0612) ce_loss 0.9170 (0.9175) teacher_loss 0.8976 (0.9129) loss_zs_kd 0.1607 (0.1521) loss_oracle 0.0949 (0.0722) acc 78.1250 (75.1228) kd_loss 0.0910 (0.0679) lr 1.5567e-04 eta 0:03:48
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,444
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,025
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.2%
******* Domain a best val acc:      87.8%, epoch: 39 *******
******* Domain a best val test acc: 83.3%, epoch: 39 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [44/50] batch [20/288] time 0.111 (0.140) data 0.000 (0.016) loss 1.2622 (1.0656) ce_loss 1.1416 (0.9231) teacher_loss 1.1488 (0.9205) loss_zs_kd 0.1247 (0.1515) loss_oracle 0.0510 (0.0694) acc 68.7500 (74.8438) kd_loss 0.0458 (0.0651) lr 1.2369e-04 eta 0:04:39
epoch [44/50] batch [40/288] time 0.118 (0.121) data 0.000 (0.008) loss 0.9071 (1.1039) ce_loss 0.7383 (0.9630) teacher_loss 0.7417 (0.9595) loss_zs_kd 0.1500 (0.1491) loss_oracle 0.0904 (0.0699) acc 81.2500 (73.7500) kd_loss 0.0894 (0.0675) lr 1.2369e-04 eta 0:04:00
epoch [44/50] batch [60/288] time 0.100 (0.116) data 0.000 (0.005) loss 0.8171 (1.0853) ce_loss 0.6938 (0.9409) teacher_loss 0.6912 (0.9370) loss_zs_kd 0.0917 (0.1537) loss_oracle 0.0801 (0.0715) acc 87.5000 (74.4792) kd_loss 0.0628 (0.0673) lr 1.2369e-04 eta 0:03:47
epoch [44/50] batch [80/288] time 0.109 (0.114) data 0.000 (0.004) loss 1.2330 (1.0812) ce_loss 1.0479 (0.9360) teacher_loss 1.0632 (0.9323) loss_zs_kd 0.1928 (0.1529) loss_oracle 0.0734 (0.0725) acc 75.0000 (74.5703) kd_loss 0.0738 (0.0688) lr 1.2369e-04 eta 0:03:39
epoch [44/50] batch [100/288] time 0.110 (0.113) data 0.000 (0.003) loss 1.1598 (1.0721) ce_loss 1.0381 (0.9282) teacher_loss 1.0324 (0.9235) loss_zs_kd 0.1282 (0.1524) loss_oracle 0.0633 (0.0724) acc 71.8750 (75.0000) kd_loss 0.0583 (0.0689) lr 1.2369e-04 eta 0:03:35
epoch [44/50] batch [120/288] time 0.112 (0.112) data 0.000 (0.003) loss 1.1113 (1.0626) ce_loss 0.9390 (0.9189) teacher_loss 0.9444 (0.9144) loss_zs_kd 0.2101 (0.1517) loss_oracle 0.0619 (0.0723) acc 71.8750 (75.3906) kd_loss 0.0429 (0.0682) lr 1.2369e-04 eta 0:03:33
epoch [44/50] batch [140/288] time 0.102 (0.112) data 0.000 (0.003) loss 1.0571 (1.0644) ce_loss 0.8906 (0.9214) teacher_loss 0.8846 (0.9164) loss_zs_kd 0.1633 (0.1517) loss_oracle 0.0909 (0.0722) acc 71.8750 (75.4241) kd_loss 0.0735 (0.0674) lr 1.2369e-04 eta 0:03:30
epoch [44/50] batch [160/288] time 0.109 (0.111) data 0.000 (0.002) loss 1.2393 (1.0703) ce_loss 1.0801 (0.9271) teacher_loss 1.0793 (0.9223) loss_zs_kd 0.1482 (0.1519) loss_oracle 0.0859 (0.0721) acc 65.6250 (75.1367) kd_loss 0.0893 (0.0672) lr 1.2369e-04 eta 0:03:26
epoch [44/50] batch [180/288] time 0.102 (0.111) data 0.000 (0.002) loss 0.9275 (1.0785) ce_loss 0.7983 (0.9352) teacher_loss 0.7940 (0.9298) loss_zs_kd 0.1415 (0.1522) loss_oracle 0.0628 (0.0727) acc 81.2500 (75.0174) kd_loss 0.0609 (0.0680) lr 1.2369e-04 eta 0:03:23
epoch [44/50] batch [200/288] time 0.093 (0.110) data 0.000 (0.002) loss 0.9286 (1.0799) ce_loss 0.7817 (0.9355) teacher_loss 0.7818 (0.9302) loss_zs_kd 0.1554 (0.1537) loss_oracle 0.0691 (0.0728) acc 81.2500 (74.9375) kd_loss 0.0561 (0.0683) lr 1.2369e-04 eta 0:03:20
epoch [44/50] batch [220/288] time 0.125 (0.111) data 0.000 (0.002) loss 1.0337 (1.0823) ce_loss 0.8755 (0.9380) teacher_loss 0.8910 (0.9330) loss_zs_kd 0.1414 (0.1530) loss_oracle 0.0719 (0.0728) acc 71.8750 (74.9006) kd_loss 0.0784 (0.0684) lr 1.2369e-04 eta 0:03:19
epoch [44/50] batch [240/288] time 0.130 (0.112) data 0.000 (0.002) loss 1.0198 (1.0939) ce_loss 0.9087 (0.9499) teacher_loss 0.8981 (0.9450) loss_zs_kd 0.1464 (0.1528) loss_oracle 0.0485 (0.0724) acc 68.7500 (74.5182) kd_loss 0.0378 (0.0678) lr 1.2369e-04 eta 0:03:19
epoch [44/50] batch [260/288] time 0.124 (0.113) data 0.000 (0.002) loss 1.4806 (1.0903) ce_loss 1.3574 (0.9471) teacher_loss 1.3501 (0.9420) loss_zs_kd 0.1220 (0.1520) loss_oracle 0.0695 (0.0723) acc 68.7500 (74.5312) kd_loss 0.0696 (0.0680) lr 1.2369e-04 eta 0:03:18
epoch [44/50] batch [280/288] time 0.107 (0.113) data 0.000 (0.001) loss 1.3313 (1.0890) ce_loss 1.2178 (0.9454) teacher_loss 1.2176 (0.9403) loss_zs_kd 0.1125 (0.1527) loss_oracle 0.0574 (0.0723) acc 65.6250 (74.4420) kd_loss 0.0454 (0.0680) lr 1.2369e-04 eta 0:03:16
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,449
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 80.1%
******* Domain a best val acc:      87.8%, epoch: 39 *******
******* Domain a best val test acc: 83.3%, epoch: 39 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [45/50] batch [20/288] time 0.091 (0.108) data 0.000 (0.012) loss 1.2934 (1.0883) ce_loss 1.1680 (0.9395) teacher_loss 1.1727 (0.9334) loss_zs_kd 0.1083 (0.1574) loss_oracle 0.0665 (0.0762) acc 59.3750 (74.8438) kd_loss 0.0737 (0.0773) lr 9.5173e-05 eta 0:03:03
epoch [45/50] batch [40/288] time 0.088 (0.100) data 0.000 (0.006) loss 0.8072 (1.0304) ce_loss 0.6992 (0.8830) teacher_loss 0.6882 (0.8788) loss_zs_kd 0.0805 (0.1539) loss_oracle 0.0788 (0.0746) acc 75.0000 (76.2500) kd_loss 0.0824 (0.0765) lr 9.5173e-05 eta 0:02:49
epoch [45/50] batch [60/288] time 0.092 (0.098) data 0.000 (0.004) loss 0.6189 (1.0273) ce_loss 0.5039 (0.8837) teacher_loss 0.4936 (0.8789) loss_zs_kd 0.1374 (0.1503) loss_oracle 0.0566 (0.0732) acc 87.5000 (76.5104) kd_loss 0.0757 (0.0750) lr 9.5173e-05 eta 0:02:43
epoch [45/50] batch [80/288] time 0.087 (0.098) data 0.000 (0.003) loss 0.7400 (1.0369) ce_loss 0.5981 (0.8944) teacher_loss 0.6079 (0.8899) loss_zs_kd 0.1230 (0.1487) loss_oracle 0.0706 (0.0727) acc 81.2500 (76.1719) kd_loss 0.0789 (0.0750) lr 9.5173e-05 eta 0:02:40
epoch [45/50] batch [100/288] time 0.100 (0.098) data 0.000 (0.003) loss 1.5897 (1.0323) ce_loss 1.4316 (0.8898) teacher_loss 1.4091 (0.8849) loss_zs_kd 0.1354 (0.1484) loss_oracle 0.1129 (0.0732) acc 59.3750 (76.1875) kd_loss 0.0976 (0.0757) lr 9.5173e-05 eta 0:02:38
epoch [45/50] batch [120/288] time 0.088 (0.097) data 0.000 (0.002) loss 0.9307 (1.0421) ce_loss 0.8076 (0.8996) teacher_loss 0.8032 (0.8947) loss_zs_kd 0.1390 (0.1502) loss_oracle 0.0580 (0.0723) acc 78.1250 (75.8854) kd_loss 0.0646 (0.0749) lr 9.5173e-05 eta 0:02:36
epoch [45/50] batch [140/288] time 0.091 (0.097) data 0.000 (0.002) loss 0.4763 (1.0455) ce_loss 0.3423 (0.9035) teacher_loss 0.3456 (0.8983) loss_zs_kd 0.1277 (0.1501) loss_oracle 0.0669 (0.0721) acc 87.5000 (75.8036) kd_loss 0.0972 (0.0743) lr 9.5173e-05 eta 0:02:34
epoch [45/50] batch [160/288] time 0.089 (0.097) data 0.000 (0.002) loss 1.1089 (1.0497) ce_loss 0.9570 (0.9075) teacher_loss 0.9591 (0.9025) loss_zs_kd 0.1826 (0.1517) loss_oracle 0.0585 (0.0713) acc 75.0000 (75.6055) kd_loss 0.0572 (0.0731) lr 9.5173e-05 eta 0:02:31
epoch [45/50] batch [180/288] time 0.108 (0.097) data 0.000 (0.002) loss 1.2627 (1.0544) ce_loss 1.1016 (0.9128) teacher_loss 1.0835 (0.9076) loss_zs_kd 0.2016 (0.1521) loss_oracle 0.0784 (0.0707) acc 68.7500 (75.3299) kd_loss 0.0649 (0.0721) lr 9.5173e-05 eta 0:02:30
epoch [45/50] batch [200/288] time 0.084 (0.097) data 0.000 (0.001) loss 0.7101 (1.0581) ce_loss 0.5781 (0.9161) teacher_loss 0.5801 (0.9110) loss_zs_kd 0.1162 (0.1526) loss_oracle 0.0719 (0.0708) acc 87.5000 (75.4688) kd_loss 0.0659 (0.0722) lr 9.5173e-05 eta 0:02:27
epoch [45/50] batch [220/288] time 0.092 (0.096) data 0.000 (0.001) loss 0.9542 (1.0532) ce_loss 0.7842 (0.9112) teacher_loss 0.7678 (0.9060) loss_zs_kd 0.1948 (0.1525) loss_oracle 0.0890 (0.0710) acc 84.3750 (75.5682) kd_loss 0.0575 (0.0724) lr 9.5173e-05 eta 0:02:24
epoch [45/50] batch [240/288] time 0.087 (0.096) data 0.000 (0.001) loss 0.9787 (1.0443) ce_loss 0.8813 (0.9028) teacher_loss 0.8735 (0.8973) loss_zs_kd 0.1265 (0.1519) loss_oracle 0.0419 (0.0710) acc 71.8750 (75.8594) kd_loss 0.0487 (0.0723) lr 9.5173e-05 eta 0:02:22
epoch [45/50] batch [260/288] time 0.093 (0.095) data 0.000 (0.001) loss 1.3887 (1.0444) ce_loss 1.1758 (0.9019) teacher_loss 1.1670 (0.8967) loss_zs_kd 0.2188 (0.1529) loss_oracle 0.1124 (0.0712) acc 75.0000 (75.9375) kd_loss 0.1254 (0.0724) lr 9.5173e-05 eta 0:02:19
epoch [45/50] batch [280/288] time 0.085 (0.095) data 0.000 (0.001) loss 1.0983 (1.0544) ce_loss 0.9419 (0.9115) teacher_loss 0.9426 (0.9062) loss_zs_kd 0.1589 (0.1538) loss_oracle 0.0762 (0.0713) acc 81.2500 (75.7701) kd_loss 0.0583 (0.0722) lr 9.5173e-05 eta 0:02:17
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,448
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.9%
******* Domain a best val acc:      87.8%, epoch: 39 *******
******* Domain a best val test acc: 83.3%, epoch: 39 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [46/50] batch [20/288] time 0.104 (0.126) data 0.000 (0.017) loss 0.8700 (1.0487) ce_loss 0.7383 (0.9074) teacher_loss 0.7177 (0.8996) loss_zs_kd 0.1350 (0.1501) loss_oracle 0.0847 (0.0741) acc 78.1250 (76.8750) kd_loss 0.0921 (0.0737) lr 7.0224e-05 eta 0:02:58
epoch [46/50] batch [40/288] time 0.096 (0.112) data 0.000 (0.009) loss 1.2096 (1.0916) ce_loss 1.0684 (0.9476) teacher_loss 1.0794 (0.9427) loss_zs_kd 0.1546 (0.1543) loss_oracle 0.0529 (0.0717) acc 71.8750 (75.9375) kd_loss 0.0502 (0.0696) lr 7.0224e-05 eta 0:02:36
epoch [46/50] batch [60/288] time 0.106 (0.108) data 0.000 (0.006) loss 1.0643 (1.1005) ce_loss 0.9106 (0.9555) teacher_loss 0.9076 (0.9505) loss_zs_kd 0.1520 (0.1591) loss_oracle 0.0807 (0.0705) acc 78.1250 (75.1042) kd_loss 0.0853 (0.0681) lr 7.0224e-05 eta 0:02:28
epoch [46/50] batch [80/288] time 0.113 (0.107) data 0.000 (0.004) loss 0.8888 (1.0733) ce_loss 0.7402 (0.9298) teacher_loss 0.7433 (0.9250) loss_zs_kd 0.1196 (0.1548) loss_oracle 0.0857 (0.0708) acc 84.3750 (75.4688) kd_loss 0.0688 (0.0690) lr 7.0224e-05 eta 0:02:25
epoch [46/50] batch [100/288] time 0.101 (0.106) data 0.000 (0.004) loss 0.9226 (1.0628) ce_loss 0.7563 (0.9200) teacher_loss 0.7587 (0.9160) loss_zs_kd 0.1624 (0.1550) loss_oracle 0.0827 (0.0694) acc 75.0000 (75.8438) kd_loss 0.0733 (0.0666) lr 7.0224e-05 eta 0:02:22
epoch [46/50] batch [120/288] time 0.096 (0.106) data 0.000 (0.003) loss 0.6415 (1.0667) ce_loss 0.4817 (0.9239) teacher_loss 0.4870 (0.9195) loss_zs_kd 0.1609 (0.1556) loss_oracle 0.0740 (0.0694) acc 84.3750 (75.4948) kd_loss 0.0834 (0.0665) lr 7.0224e-05 eta 0:02:19
epoch [46/50] batch [140/288] time 0.101 (0.105) data 0.000 (0.003) loss 0.9820 (1.0651) ce_loss 0.8379 (0.9223) teacher_loss 0.8367 (0.9177) loss_zs_kd 0.1440 (0.1549) loss_oracle 0.0733 (0.0701) acc 78.1250 (75.4464) kd_loss 0.0696 (0.0668) lr 7.0224e-05 eta 0:02:16
epoch [46/50] batch [160/288] time 0.112 (0.105) data 0.000 (0.002) loss 1.0883 (1.0580) ce_loss 0.9180 (0.9148) teacher_loss 0.9076 (0.9101) loss_zs_kd 0.2086 (0.1540) loss_oracle 0.0764 (0.0709) acc 75.0000 (75.4297) kd_loss 0.0623 (0.0668) lr 7.0224e-05 eta 0:02:15
epoch [46/50] batch [180/288] time 0.102 (0.105) data 0.000 (0.002) loss 1.1670 (1.0659) ce_loss 0.9839 (0.9225) teacher_loss 0.9793 (0.9173) loss_zs_kd 0.2056 (0.1547) loss_oracle 0.0849 (0.0713) acc 75.0000 (75.2257) kd_loss 0.0845 (0.0667) lr 7.0224e-05 eta 0:02:12
epoch [46/50] batch [200/288] time 0.105 (0.105) data 0.000 (0.002) loss 1.3107 (1.0753) ce_loss 1.2070 (0.9319) teacher_loss 1.2000 (0.9264) loss_zs_kd 0.0959 (0.1546) loss_oracle 0.0627 (0.0715) acc 71.8750 (75.0000) kd_loss 0.0617 (0.0666) lr 7.0224e-05 eta 0:02:10
epoch [46/50] batch [220/288] time 0.100 (0.104) data 0.000 (0.002) loss 1.0205 (1.0768) ce_loss 0.8804 (0.9338) teacher_loss 0.8794 (0.9283) loss_zs_kd 0.1453 (0.1539) loss_oracle 0.0685 (0.0716) acc 75.0000 (74.9716) kd_loss 0.0622 (0.0664) lr 7.0224e-05 eta 0:02:07
epoch [46/50] batch [240/288] time 0.102 (0.104) data 0.000 (0.002) loss 1.0152 (1.0774) ce_loss 0.8848 (0.9341) teacher_loss 0.8826 (0.9282) loss_zs_kd 0.1588 (0.1545) loss_oracle 0.0532 (0.0719) acc 75.0000 (75.0260) kd_loss 0.0643 (0.0666) lr 7.0224e-05 eta 0:02:04
epoch [46/50] batch [260/288] time 0.109 (0.104) data 0.000 (0.002) loss 0.9000 (1.0732) ce_loss 0.7764 (0.9295) teacher_loss 0.7821 (0.9239) loss_zs_kd 0.1148 (0.1550) loss_oracle 0.0605 (0.0718) acc 87.5000 (75.1562) kd_loss 0.0513 (0.0665) lr 7.0224e-05 eta 0:02:02
epoch [46/50] batch [280/288] time 0.106 (0.104) data 0.000 (0.001) loss 1.3804 (1.0767) ce_loss 1.2510 (0.9327) teacher_loss 1.2445 (0.9269) loss_zs_kd 0.1443 (0.1553) loss_oracle 0.0638 (0.0722) acc 65.6250 (75.1451) kd_loss 0.0631 (0.0669) lr 7.0224e-05 eta 0:02:00
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,449
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,024
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.2%
******* Domain a best val acc:      87.8%, epoch: 39 *******
******* Domain a best val test acc: 83.3%, epoch: 39 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [47/50] batch [20/288] time 0.092 (0.110) data 0.000 (0.012) loss 1.3096 (1.0918) ce_loss 1.1826 (0.9522) teacher_loss 1.1842 (0.9474) loss_zs_kd 0.1445 (0.1531) loss_oracle 0.0532 (0.0679) acc 68.7500 (75.3125) kd_loss 0.0687 (0.0647) lr 4.8943e-05 eta 0:02:04
epoch [47/50] batch [40/288] time 0.084 (0.103) data 0.000 (0.006) loss 1.3498 (1.0805) ce_loss 1.2422 (0.9420) teacher_loss 1.1984 (0.9362) loss_zs_kd 0.1250 (0.1458) loss_oracle 0.0888 (0.0714) acc 71.8750 (75.0000) kd_loss 0.0819 (0.0661) lr 4.8943e-05 eta 0:01:54
epoch [47/50] batch [60/288] time 0.115 (0.102) data 0.001 (0.004) loss 1.6498 (1.0852) ce_loss 1.5254 (0.9437) teacher_loss 1.5071 (0.9384) loss_zs_kd 0.1288 (0.1466) loss_oracle 0.0783 (0.0736) acc 62.5000 (75.2083) kd_loss 0.0586 (0.0682) lr 4.8943e-05 eta 0:01:51
epoch [47/50] batch [80/288] time 0.101 (0.102) data 0.000 (0.003) loss 1.1934 (1.0816) ce_loss 1.0332 (0.9391) teacher_loss 1.0286 (0.9331) loss_zs_kd 0.1238 (0.1490) loss_oracle 0.1029 (0.0740) acc 75.0000 (75.4688) kd_loss 0.1112 (0.0696) lr 4.8943e-05 eta 0:01:49
epoch [47/50] batch [100/288] time 0.097 (0.102) data 0.000 (0.003) loss 0.7790 (1.0733) ce_loss 0.6499 (0.9302) teacher_loss 0.6634 (0.9239) loss_zs_kd 0.1051 (0.1506) loss_oracle 0.0631 (0.0741) acc 78.1250 (75.0625) kd_loss 0.0526 (0.0692) lr 4.8943e-05 eta 0:01:47
epoch [47/50] batch [120/288] time 0.113 (0.103) data 0.000 (0.002) loss 1.3771 (1.0628) ce_loss 1.2227 (0.9181) teacher_loss 1.2192 (0.9123) loss_zs_kd 0.1236 (0.1516) loss_oracle 0.0961 (0.0747) acc 75.0000 (75.2865) kd_loss 0.0822 (0.0698) lr 4.8943e-05 eta 0:01:45
epoch [47/50] batch [140/288] time 0.097 (0.103) data 0.000 (0.002) loss 0.8992 (1.0649) ce_loss 0.7290 (0.9192) teacher_loss 0.7289 (0.9138) loss_zs_kd 0.2017 (0.1530) loss_oracle 0.0695 (0.0746) acc 78.1250 (75.3125) kd_loss 0.0593 (0.0688) lr 4.8943e-05 eta 0:01:43
epoch [47/50] batch [160/288] time 0.097 (0.102) data 0.000 (0.002) loss 1.0590 (1.0697) ce_loss 0.8652 (0.9233) teacher_loss 0.8622 (0.9174) loss_zs_kd 0.2356 (0.1546) loss_oracle 0.0790 (0.0750) acc 78.1250 (75.0391) kd_loss 0.0819 (0.0688) lr 4.8943e-05 eta 0:01:41
epoch [47/50] batch [180/288] time 0.092 (0.101) data 0.000 (0.002) loss 1.0033 (1.0709) ce_loss 0.8804 (0.9250) teacher_loss 0.8536 (0.9188) loss_zs_kd 0.1604 (0.1555) loss_oracle 0.0695 (0.0744) acc 71.8750 (74.8264) kd_loss 0.0594 (0.0686) lr 4.8943e-05 eta 0:01:38
epoch [47/50] batch [200/288] time 0.099 (0.101) data 0.000 (0.001) loss 0.5305 (1.0683) ce_loss 0.3899 (0.9237) teacher_loss 0.3971 (0.9183) loss_zs_kd 0.1127 (0.1537) loss_oracle 0.0770 (0.0731) acc 84.3750 (74.9688) kd_loss 0.0706 (0.0679) lr 4.8943e-05 eta 0:01:35
epoch [47/50] batch [220/288] time 0.094 (0.100) data 0.000 (0.001) loss 0.8894 (1.0731) ce_loss 0.7588 (0.9285) teacher_loss 0.7399 (0.9225) loss_zs_kd 0.1549 (0.1547) loss_oracle 0.0721 (0.0733) acc 75.0000 (74.9006) kd_loss 0.0773 (0.0682) lr 4.8943e-05 eta 0:01:33
epoch [47/50] batch [240/288] time 0.094 (0.100) data 0.000 (0.001) loss 0.7717 (1.0725) ce_loss 0.6226 (0.9273) teacher_loss 0.6339 (0.9213) loss_zs_kd 0.1328 (0.1550) loss_oracle 0.0714 (0.0737) acc 84.3750 (74.8568) kd_loss 0.0639 (0.0684) lr 4.8943e-05 eta 0:01:30
epoch [47/50] batch [260/288] time 0.099 (0.100) data 0.000 (0.001) loss 1.5146 (1.0751) ce_loss 1.3428 (0.9295) teacher_loss 1.3388 (0.9237) loss_zs_kd 0.2242 (0.1553) loss_oracle 0.0637 (0.0738) acc 68.7500 (74.8317) kd_loss 0.0719 (0.0688) lr 4.8943e-05 eta 0:01:28
epoch [47/50] batch [280/288] time 0.087 (0.099) data 0.000 (0.001) loss 0.6264 (1.0787) ce_loss 0.5098 (0.9328) teacher_loss 0.4980 (0.9270) loss_zs_kd 0.1344 (0.1555) loss_oracle 0.0612 (0.0739) acc 87.5000 (74.8214) kd_loss 0.0808 (0.0692) lr 4.8943e-05 eta 0:01:26
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,448
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 80.0%
******* Domain a best val acc:      87.8%, epoch: 39 *******
******* Domain a best val test acc: 83.3%, epoch: 39 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [48/50] batch [20/288] time 0.100 (0.112) data 0.000 (0.013) loss 1.1435 (1.1441) ce_loss 1.0137 (0.9912) teacher_loss 0.9969 (0.9879) loss_zs_kd 0.1585 (0.1626) loss_oracle 0.0673 (0.0748) acc 65.6250 (73.1250) kd_loss 0.0638 (0.0697) lr 3.1417e-05 eta 0:01:34
epoch [48/50] batch [40/288] time 0.096 (0.103) data 0.000 (0.007) loss 1.4397 (1.1185) ce_loss 1.2695 (0.9690) teacher_loss 1.2592 (0.9645) loss_zs_kd 0.1818 (0.1582) loss_oracle 0.0895 (0.0749) acc 65.6250 (74.2188) kd_loss 0.0811 (0.0705) lr 3.1417e-05 eta 0:01:24
epoch [48/50] batch [60/288] time 0.091 (0.100) data 0.000 (0.005) loss 1.1844 (1.0971) ce_loss 1.0449 (0.9450) teacher_loss 1.0408 (0.9393) loss_zs_kd 0.1394 (0.1648) loss_oracle 0.0740 (0.0754) acc 71.8750 (74.8438) kd_loss 0.0649 (0.0703) lr 3.1417e-05 eta 0:01:20
epoch [48/50] batch [80/288] time 0.102 (0.101) data 0.000 (0.003) loss 1.2184 (1.0910) ce_loss 1.0771 (0.9418) teacher_loss 1.0594 (0.9355) loss_zs_kd 0.1598 (0.1600) loss_oracle 0.0791 (0.0754) acc 71.8750 (74.5703) kd_loss 0.0800 (0.0705) lr 3.1417e-05 eta 0:01:19
epoch [48/50] batch [100/288] time 0.105 (0.102) data 0.000 (0.003) loss 0.9620 (1.0774) ce_loss 0.8242 (0.9286) teacher_loss 0.8312 (0.9223) loss_zs_kd 0.1188 (0.1587) loss_oracle 0.0715 (0.0757) acc 71.8750 (74.9062) kd_loss 0.0791 (0.0723) lr 3.1417e-05 eta 0:01:17
epoch [48/50] batch [120/288] time 0.096 (0.101) data 0.000 (0.002) loss 1.1862 (1.0790) ce_loss 1.0479 (0.9310) teacher_loss 1.0211 (0.9246) loss_zs_kd 0.1997 (0.1571) loss_oracle 0.0653 (0.0759) acc 68.7500 (74.6094) kd_loss 0.0671 (0.0730) lr 3.1417e-05 eta 0:01:15
epoch [48/50] batch [140/288] time 0.098 (0.101) data 0.000 (0.002) loss 0.9995 (1.0781) ce_loss 0.8208 (0.9306) teacher_loss 0.8246 (0.9246) loss_zs_kd 0.1509 (0.1565) loss_oracle 0.0995 (0.0752) acc 78.1250 (74.7098) kd_loss 0.1025 (0.0723) lr 3.1417e-05 eta 0:01:13
epoch [48/50] batch [160/288] time 0.105 (0.101) data 0.000 (0.002) loss 1.0693 (1.0862) ce_loss 0.9463 (0.9391) teacher_loss 0.9298 (0.9328) loss_zs_kd 0.1171 (0.1569) loss_oracle 0.0809 (0.0750) acc 68.7500 (74.4531) kd_loss 0.0870 (0.0719) lr 3.1417e-05 eta 0:01:11
epoch [48/50] batch [180/288] time 0.099 (0.102) data 0.000 (0.002) loss 0.8712 (1.0784) ce_loss 0.7329 (0.9308) teacher_loss 0.7254 (0.9247) loss_zs_kd 0.1496 (0.1577) loss_oracle 0.0710 (0.0748) acc 81.2500 (74.6528) kd_loss 0.0714 (0.0714) lr 3.1417e-05 eta 0:01:09
epoch [48/50] batch [200/288] time 0.101 (0.102) data 0.000 (0.002) loss 0.9124 (1.0774) ce_loss 0.7646 (0.9308) teacher_loss 0.7719 (0.9241) loss_zs_kd 0.1569 (0.1574) loss_oracle 0.0621 (0.0746) acc 84.3750 (74.7500) kd_loss 0.0553 (0.0710) lr 3.1417e-05 eta 0:01:07
epoch [48/50] batch [220/288] time 0.100 (0.102) data 0.000 (0.001) loss 0.9684 (1.0752) ce_loss 0.8232 (0.9290) teacher_loss 0.8243 (0.9222) loss_zs_kd 0.1671 (0.1574) loss_oracle 0.0606 (0.0744) acc 84.3750 (74.9858) kd_loss 0.0633 (0.0711) lr 3.1417e-05 eta 0:01:05
epoch [48/50] batch [240/288] time 0.110 (0.102) data 0.000 (0.001) loss 1.1241 (1.0757) ce_loss 0.9893 (0.9296) teacher_loss 0.9758 (0.9227) loss_zs_kd 0.1399 (0.1577) loss_oracle 0.0784 (0.0742) acc 75.0000 (74.9740) kd_loss 0.0725 (0.0709) lr 3.1417e-05 eta 0:01:03
epoch [48/50] batch [260/288] time 0.099 (0.102) data 0.000 (0.001) loss 1.0957 (1.0738) ce_loss 0.9619 (0.9278) teacher_loss 0.9557 (0.9213) loss_zs_kd 0.1511 (0.1568) loss_oracle 0.0645 (0.0741) acc 78.1250 (74.9639) kd_loss 0.0943 (0.0710) lr 3.1417e-05 eta 0:01:01
epoch [48/50] batch [280/288] time 0.107 (0.102) data 0.000 (0.001) loss 0.9967 (1.0715) ce_loss 0.8477 (0.9256) teacher_loss 0.8329 (0.9192) loss_zs_kd 0.1570 (0.1568) loss_oracle 0.0854 (0.0739) acc 81.2500 (75.0112) kd_loss 0.0518 (0.0702) lr 3.1417e-05 eta 0:00:59
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,447
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,021
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 80.0%
******* Domain a best val acc:      87.8%, epoch: 39 *******
******* Domain a best val test acc: 83.3%, epoch: 39 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [49/50] batch [20/288] time 0.131 (0.149) data 0.000 (0.019) loss 1.1104 (1.0227) ce_loss 0.9893 (0.8769) teacher_loss 0.9904 (0.8697) loss_zs_kd 0.1355 (0.1582) loss_oracle 0.0522 (0.0739) acc 68.7500 (76.2500) kd_loss 0.0625 (0.0656) lr 1.7713e-05 eta 0:01:22
epoch [49/50] batch [40/288] time 0.131 (0.140) data 0.000 (0.010) loss 1.4788 (1.0431) ce_loss 1.3223 (0.9029) teacher_loss 1.3159 (0.8945) loss_zs_kd 0.1390 (0.1525) loss_oracle 0.0935 (0.0724) acc 62.5000 (75.8594) kd_loss 0.0797 (0.0659) lr 1.7713e-05 eta 0:01:14
epoch [49/50] batch [60/288] time 0.132 (0.136) data 0.001 (0.007) loss 0.6447 (1.0429) ce_loss 0.5112 (0.8999) teacher_loss 0.5134 (0.8924) loss_zs_kd 0.1422 (0.1559) loss_oracle 0.0602 (0.0725) acc 84.3750 (76.2500) kd_loss 0.0542 (0.0667) lr 1.7713e-05 eta 0:01:10
epoch [49/50] batch [80/288] time 0.132 (0.135) data 0.001 (0.005) loss 1.1571 (1.0323) ce_loss 0.9937 (0.8897) teacher_loss 1.0089 (0.8818) loss_zs_kd 0.1342 (0.1561) loss_oracle 0.0811 (0.0725) acc 78.1250 (76.8359) kd_loss 0.0825 (0.0687) lr 1.7713e-05 eta 0:01:06
epoch [49/50] batch [100/288] time 0.126 (0.133) data 0.000 (0.004) loss 0.7122 (1.0467) ce_loss 0.5669 (0.9030) teacher_loss 0.5674 (0.8956) loss_zs_kd 0.1485 (0.1576) loss_oracle 0.0706 (0.0723) acc 87.5000 (76.3438) kd_loss 0.0748 (0.0685) lr 1.7713e-05 eta 0:01:03
epoch [49/50] batch [120/288] time 0.128 (0.132) data 0.001 (0.003) loss 1.1396 (1.0524) ce_loss 1.0049 (0.9090) teacher_loss 1.0024 (0.9020) loss_zs_kd 0.1434 (0.1562) loss_oracle 0.0655 (0.0723) acc 75.0000 (76.0417) kd_loss 0.0601 (0.0687) lr 1.7713e-05 eta 0:01:00
epoch [49/50] batch [140/288] time 0.113 (0.131) data 0.000 (0.003) loss 1.4259 (1.0535) ce_loss 1.2354 (0.9085) teacher_loss 1.2306 (0.9021) loss_zs_kd 0.2007 (0.1573) loss_oracle 0.0950 (0.0728) acc 71.8750 (75.9152) kd_loss 0.0790 (0.0690) lr 1.7713e-05 eta 0:00:56
epoch [49/50] batch [160/288] time 0.127 (0.129) data 0.000 (0.003) loss 0.8544 (1.0494) ce_loss 0.7183 (0.9057) teacher_loss 0.7121 (0.8997) loss_zs_kd 0.1471 (0.1555) loss_oracle 0.0687 (0.0720) acc 78.1250 (75.8789) kd_loss 0.0635 (0.0683) lr 1.7713e-05 eta 0:00:53
epoch [49/50] batch [180/288] time 0.127 (0.129) data 0.000 (0.002) loss 1.3586 (1.0445) ce_loss 1.1582 (0.9009) teacher_loss 1.1743 (0.8951) loss_zs_kd 0.2321 (0.1552) loss_oracle 0.0683 (0.0718) acc 71.8750 (75.9722) kd_loss 0.0497 (0.0676) lr 1.7713e-05 eta 0:00:50
epoch [49/50] batch [200/288] time 0.125 (0.128) data 0.000 (0.002) loss 1.7148 (1.0569) ce_loss 1.5742 (0.9134) teacher_loss 1.5572 (0.9070) loss_zs_kd 0.1509 (0.1554) loss_oracle 0.0821 (0.0722) acc 62.5000 (75.6719) kd_loss 0.0717 (0.0679) lr 1.7713e-05 eta 0:00:48
epoch [49/50] batch [220/288] time 0.122 (0.128) data 0.000 (0.002) loss 1.2919 (1.0638) ce_loss 1.1328 (0.9197) teacher_loss 1.1233 (0.9133) loss_zs_kd 0.1788 (0.1558) loss_oracle 0.0792 (0.0727) acc 68.7500 (75.6108) kd_loss 0.0785 (0.0678) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [240/288] time 0.122 (0.128) data 0.000 (0.002) loss 0.7581 (1.0615) ce_loss 0.6157 (0.9174) teacher_loss 0.6205 (0.9111) loss_zs_kd 0.1437 (0.1555) loss_oracle 0.0657 (0.0726) acc 81.2500 (75.5859) kd_loss 0.0619 (0.0675) lr 1.7713e-05 eta 0:00:42
epoch [49/50] batch [260/288] time 0.121 (0.127) data 0.000 (0.002) loss 1.1582 (1.0529) ce_loss 1.0039 (0.9090) teacher_loss 1.0009 (0.9030) loss_zs_kd 0.1820 (0.1545) loss_oracle 0.0664 (0.0726) acc 81.2500 (75.9495) kd_loss 0.0563 (0.0679) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [280/288] time 0.104 (0.126) data 0.000 (0.002) loss 0.7013 (1.0463) ce_loss 0.5796 (0.9031) teacher_loss 0.5832 (0.8971) loss_zs_kd 0.1198 (0.1538) loss_oracle 0.0582 (0.0723) acc 84.3750 (76.0714) kd_loss 0.0666 (0.0682) lr 1.7713e-05 eta 0:00:37
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,448
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,024
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.2%
******* Domain a best val acc:      87.8%, epoch: 39 *******
******* Domain a best val test acc: 83.3%, epoch: 39 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
epoch [50/50] batch [20/288] time 0.101 (0.122) data 0.000 (0.014) loss 1.2146 (0.9679) ce_loss 1.0869 (0.8254) teacher_loss 1.0832 (0.8186) loss_zs_kd 0.1148 (0.1549) loss_oracle 0.0741 (0.0718) acc 71.8750 (77.3438) kd_loss 0.0770 (0.0702) lr 7.8853e-06 eta 0:00:32
epoch [50/50] batch [40/288] time 0.108 (0.113) data 0.000 (0.007) loss 1.2257 (1.0413) ce_loss 1.0996 (0.8990) teacher_loss 1.0659 (0.8924) loss_zs_kd 0.1666 (0.1550) loss_oracle 0.0766 (0.0714) acc 65.6250 (75.2344) kd_loss 0.0717 (0.0699) lr 7.8853e-06 eta 0:00:27
epoch [50/50] batch [60/288] time 0.114 (0.110) data 0.000 (0.005) loss 1.0029 (1.0422) ce_loss 0.8096 (0.9008) teacher_loss 0.7859 (0.8940) loss_zs_kd 0.1596 (0.1513) loss_oracle 0.1372 (0.0726) acc 78.1250 (75.6250) kd_loss 0.1405 (0.0698) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [80/288] time 0.112 (0.108) data 0.000 (0.004) loss 0.8711 (1.0577) ce_loss 0.7158 (0.9152) teacher_loss 0.7211 (0.9094) loss_zs_kd 0.1565 (0.1525) loss_oracle 0.0717 (0.0720) acc 78.1250 (74.8438) kd_loss 0.0505 (0.0693) lr 7.8853e-06 eta 0:00:22
epoch [50/50] batch [100/288] time 0.098 (0.107) data 0.000 (0.003) loss 1.2941 (1.0751) ce_loss 1.1416 (0.9322) teacher_loss 1.1282 (0.9260) loss_zs_kd 0.1522 (0.1532) loss_oracle 0.0897 (0.0726) acc 71.8750 (74.6562) kd_loss 0.0795 (0.0692) lr 7.8853e-06 eta 0:00:20
epoch [50/50] batch [120/288] time 0.099 (0.106) data 0.000 (0.003) loss 0.9043 (1.0710) ce_loss 0.7817 (0.9276) teacher_loss 0.7779 (0.9216) loss_zs_kd 0.1460 (0.1531) loss_oracle 0.0534 (0.0729) acc 75.0000 (74.6354) kd_loss 0.0774 (0.0696) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [140/288] time 0.099 (0.106) data 0.000 (0.002) loss 1.2874 (1.0659) ce_loss 1.1318 (0.9216) teacher_loss 1.1175 (0.9157) loss_zs_kd 0.1872 (0.1564) loss_oracle 0.0763 (0.0720) acc 75.0000 (75.0000) kd_loss 0.0610 (0.0685) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [160/288] time 0.113 (0.106) data 0.000 (0.002) loss 0.9590 (1.0553) ce_loss 0.8320 (0.9119) teacher_loss 0.8363 (0.9064) loss_zs_kd 0.1119 (0.1547) loss_oracle 0.0668 (0.0716) acc 78.1250 (75.1953) kd_loss 0.0622 (0.0679) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [180/288] time 0.101 (0.106) data 0.000 (0.002) loss 1.1559 (1.0717) ce_loss 0.9990 (0.9279) teacher_loss 0.9939 (0.9219) loss_zs_kd 0.1688 (0.1552) loss_oracle 0.0776 (0.0722) acc 78.1250 (75.1389) kd_loss 0.0863 (0.0681) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [200/288] time 0.111 (0.106) data 0.001 (0.002) loss 1.2034 (1.0761) ce_loss 1.0713 (0.9328) teacher_loss 1.0661 (0.9262) loss_zs_kd 0.1305 (0.1552) loss_oracle 0.0721 (0.0723) acc 59.3750 (75.0469) kd_loss 0.0618 (0.0677) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [220/288] time 0.102 (0.106) data 0.000 (0.002) loss 0.7800 (1.0719) ce_loss 0.6670 (0.9282) teacher_loss 0.6590 (0.9215) loss_zs_kd 0.1247 (0.1561) loss_oracle 0.0586 (0.0723) acc 75.0000 (75.0710) kd_loss 0.0478 (0.0674) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [240/288] time 0.105 (0.106) data 0.000 (0.001) loss 0.8882 (1.0799) ce_loss 0.7822 (0.9363) teacher_loss 0.7790 (0.9299) loss_zs_kd 0.1198 (0.1558) loss_oracle 0.0492 (0.0721) acc 75.0000 (74.9219) kd_loss 0.0545 (0.0672) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [260/288] time 0.101 (0.106) data 0.000 (0.001) loss 0.8294 (1.0860) ce_loss 0.6733 (0.9422) teacher_loss 0.6624 (0.9359) loss_zs_kd 0.1253 (0.1562) loss_oracle 0.1044 (0.0720) acc 78.1250 (74.6875) kd_loss 0.0957 (0.0668) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [280/288] time 0.086 (0.105) data 0.000 (0.001) loss 1.3567 (1.0812) ce_loss 1.2109 (0.9374) teacher_loss 1.1961 (0.9311) loss_zs_kd 0.1541 (0.1560) loss_oracle 0.0836 (0.0721) acc 56.2500 (74.7991) kd_loss 0.0729 (0.0669) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,448
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,023
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.1%
******* Domain a best val acc:      87.8%, epoch: 39 *******
******* Domain a best val test acc: 83.3%, epoch: 39 *******
******* Domain a best test acc:     83.8%, epoch: 18 *******
Checkpoint saved to icml/multi-dg/oracle/03_bootstrap_else_0_ratio0.5/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:30:46

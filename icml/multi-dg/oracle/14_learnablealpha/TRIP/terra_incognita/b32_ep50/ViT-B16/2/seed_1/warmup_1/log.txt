Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_100', 'location_43', 'location_46']
Target     ['location_38']
# classes  10
# train_x  10,216
# val      4,378
# test     9,736
---------  ----------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,196
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/14_learnablealpha/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/319] time 0.076 (0.140) data 0.000 (0.036) loss 1.4583 (2.2155) teacher_loss 1.2534 (2.0155) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.2049 (0.2001) acc 59.3750 (37.0312) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:37:07
epoch [1/50] batch [40/319] time 0.058 (0.108) data 0.000 (0.018) loss 1.7656 (2.1084) teacher_loss 1.5729 (1.9122) loss_zs_kd 0.0015 (0.0003) loss_oracle 0.1926 (0.1962) acc 56.2500 (39.6875) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:28:33
epoch [1/50] batch [60/319] time 0.072 (0.094) data 0.000 (0.012) loss 2.3684 (2.1376) teacher_loss 2.1683 (1.9403) loss_zs_kd 0.0027 (0.0007) loss_oracle 0.2002 (0.1973) acc 31.2500 (39.1667) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:24:50
epoch [1/50] batch [80/319] time 0.087 (0.092) data 0.000 (0.009) loss 2.1675 (2.1187) teacher_loss 1.9720 (1.9217) loss_zs_kd 0.0039 (0.0014) loss_oracle 0.1956 (0.1971) acc 43.7500 (38.7891) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:24:22
epoch [1/50] batch [100/319] time 0.085 (0.090) data 0.000 (0.007) loss 2.3811 (2.0794) teacher_loss 2.1699 (1.8829) loss_zs_kd 0.0077 (0.0024) loss_oracle 0.2112 (0.1965) acc 25.0000 (39.3750) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:23:41
epoch [1/50] batch [120/319] time 0.078 (0.088) data 0.000 (0.006) loss 2.0539 (2.0771) teacher_loss 1.8673 (1.8809) loss_zs_kd 0.0062 (0.0034) loss_oracle 0.1866 (0.1962) acc 40.6250 (39.5573) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:23:09
epoch [1/50] batch [140/319] time 0.076 (0.086) data 0.000 (0.005) loss 2.2260 (2.0767) teacher_loss 2.0537 (1.8810) loss_zs_kd 0.0101 (0.0044) loss_oracle 0.1724 (0.1957) acc 37.5000 (39.5089) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:22:44
epoch [1/50] batch [160/319] time 0.083 (0.086) data 0.000 (0.005) loss 2.0175 (2.0723) teacher_loss 1.8264 (1.8770) loss_zs_kd 0.0138 (0.0057) loss_oracle 0.1911 (0.1953) acc 34.3750 (39.6484) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:22:40
epoch [1/50] batch [180/319] time 0.082 (0.086) data 0.000 (0.004) loss 2.3572 (2.0686) teacher_loss 2.1757 (1.8737) loss_zs_kd 0.0233 (0.0071) loss_oracle 0.1815 (0.1950) acc 28.1250 (39.6007) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:22:33
epoch [1/50] batch [200/319] time 0.080 (0.086) data 0.000 (0.004) loss 2.1996 (2.0640) teacher_loss 1.9921 (1.8691) loss_zs_kd 0.0250 (0.0087) loss_oracle 0.2074 (0.1950) acc 31.2500 (39.5781) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:22:26
epoch [1/50] batch [220/319] time 0.087 (0.085) data 0.000 (0.003) loss 1.9146 (2.0698) teacher_loss 1.7157 (1.8748) loss_zs_kd 0.0308 (0.0105) loss_oracle 0.1989 (0.1950) acc 46.8750 (39.1761) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:22:22
epoch [1/50] batch [240/319] time 0.085 (0.085) data 0.000 (0.003) loss 2.1243 (2.0767) teacher_loss 1.9358 (1.8813) loss_zs_kd 0.0436 (0.0124) loss_oracle 0.1885 (0.1954) acc 28.1250 (38.8932) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:22:19
epoch [1/50] batch [260/319] time 0.081 (0.085) data 0.000 (0.003) loss 2.1666 (2.0740) teacher_loss 1.9776 (1.8785) loss_zs_kd 0.0401 (0.0144) loss_oracle 0.1890 (0.1955) acc 40.6250 (38.8221) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:22:18
epoch [1/50] batch [280/319] time 0.083 (0.085) data 0.000 (0.003) loss 2.2761 (2.0702) teacher_loss 2.0765 (1.8746) loss_zs_kd 0.0583 (0.0166) loss_oracle 0.1996 (0.1956) acc 31.2500 (38.8504) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:22:15
epoch [1/50] batch [300/319] time 0.075 (0.085) data 0.000 (0.003) loss 2.4792 (2.0660) teacher_loss 2.2765 (1.8704) loss_zs_kd 0.0586 (0.0191) loss_oracle 0.2027 (0.1956) acc 31.2500 (38.8333) alaph_mean 0.5000 (0.5000) alpha_val 0.5000 (0.5000) lr 1.0000e-05 eta 0:22:10
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,775
* accuracy: 40.5%
* error: 59.5%
* macro_f1: 26.2%
Checkpoint saved to icml/multi-dg/oracle/14_learnablealpha/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 3,193
* accuracy: 32.8%
* error: 67.2%
* macro_f1: 14.2%
Checkpoint saved to icml/multi-dg/oracle/14_learnablealpha/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     32.8%, epoch: 1 *******
epoch [2/50] batch [20/319] time 0.083 (0.110) data 0.000 (0.029) loss 1.9967 (2.0051) teacher_loss 1.4012 (1.5806) loss_zs_kd 1.1097 (0.5299) loss_oracle 0.5954 (0.4245) acc 56.2500 (44.8438) alaph_mean 0.5010 (0.5002) alpha_val 0.5010 (0.5002) lr 2.0000e-03 eta 0:28:30
epoch [2/50] batch [40/319] time 0.092 (0.097) data 0.000 (0.015) loss 2.4710 (2.0176) teacher_loss 2.0683 (1.4676) loss_zs_kd 0.8346 (1.2990) loss_oracle 0.4028 (0.5500) acc 37.5000 (54.2188) alaph_mean 0.5086 (0.5023) alpha_val 0.5086 (0.5023) lr 2.0000e-03 eta 0:25:05
epoch [2/50] batch [60/319] time 0.076 (0.093) data 0.000 (0.010) loss 1.8842 (1.9869) teacher_loss 1.4235 (1.4614) loss_zs_kd 0.9417 (1.1179) loss_oracle 0.4607 (0.5255) acc 56.2500 (54.0625) alaph_mean 0.5153 (0.5056) alpha_val 0.5153 (0.5056) lr 2.0000e-03 eta 0:24:02
epoch [2/50] batch [80/319] time 0.077 (0.090) data 0.000 (0.007) loss 1.6729 (1.9366) teacher_loss 0.9910 (1.4079) loss_zs_kd 2.2930 (1.2724) loss_oracle 0.6819 (0.5287) acc 75.0000 (57.3438) alaph_mean 0.5225 (0.5089) alpha_val 0.5225 (0.5089) lr 2.0000e-03 eta 0:23:27
epoch [2/50] batch [100/319] time 0.075 (0.091) data 0.001 (0.006) loss 2.0227 (1.9220) teacher_loss 1.3331 (1.3611) loss_zs_kd 2.6195 (1.5385) loss_oracle 0.6896 (0.5609) acc 59.3750 (60.2188) alaph_mean 0.5328 (0.5126) alpha_val 0.5328 (0.5126) lr 2.0000e-03 eta 0:23:36
epoch [2/50] batch [120/319] time 0.077 (0.089) data 0.000 (0.005) loss 1.5530 (1.8919) teacher_loss 0.7110 (1.2972) loss_zs_kd 3.4670 (1.8625) loss_oracle 0.8420 (0.5947) acc 84.3750 (62.8385) alaph_mean 0.5439 (0.5170) alpha_val 0.5439 (0.5170) lr 2.0000e-03 eta 0:22:56
epoch [2/50] batch [140/319] time 0.081 (0.088) data 0.000 (0.004) loss 1.8785 (1.8722) teacher_loss 1.1537 (1.2499) loss_zs_kd 3.1667 (2.1020) loss_oracle 0.7248 (0.6223) acc 68.7500 (64.2411) alaph_mean 0.5529 (0.5215) alpha_val 0.5529 (0.5215) lr 2.0000e-03 eta 0:22:39
epoch [2/50] batch [160/319] time 0.083 (0.087) data 0.000 (0.004) loss 1.7742 (1.8516) teacher_loss 1.0891 (1.2108) loss_zs_kd 5.2630 (2.4013) loss_oracle 0.6851 (0.6407) acc 71.8750 (66.1719) alaph_mean 0.5639 (0.5261) alpha_val 0.5639 (0.5261) lr 2.0000e-03 eta 0:22:28
epoch [2/50] batch [180/319] time 0.082 (0.087) data 0.000 (0.003) loss 1.7429 (1.8386) teacher_loss 0.9324 (1.1829) loss_zs_kd 5.3941 (2.6464) loss_oracle 0.8105 (0.6557) acc 68.7500 (67.1875) alaph_mean 0.5760 (0.5311) alpha_val 0.5760 (0.5311) lr 2.0000e-03 eta 0:22:25
epoch [2/50] batch [200/319] time 0.085 (0.087) data 0.000 (0.003) loss 1.5898 (1.8203) teacher_loss 0.7638 (1.1476) loss_zs_kd 5.6820 (2.8871) loss_oracle 0.8260 (0.6727) acc 87.5000 (68.0938) alaph_mean 0.5845 (0.5360) alpha_val 0.5845 (0.5360) lr 2.0000e-03 eta 0:22:21
epoch [2/50] batch [220/319] time 0.079 (0.086) data 0.000 (0.003) loss 1.8722 (1.8057) teacher_loss 1.1760 (1.1237) loss_zs_kd 5.7315 (3.1632) loss_oracle 0.6962 (0.6820) acc 71.8750 (69.0341) alaph_mean 0.5965 (0.5409) alpha_val 0.5965 (0.5409) lr 2.0000e-03 eta 0:22:11
epoch [2/50] batch [240/319] time 0.079 (0.086) data 0.000 (0.003) loss 1.4903 (1.7894) teacher_loss 0.6711 (1.1020) loss_zs_kd 5.4453 (3.3984) loss_oracle 0.8192 (0.6874) acc 81.2500 (69.7656) alaph_mean 0.6094 (0.5462) alpha_val 0.6094 (0.5462) lr 2.0000e-03 eta 0:22:03
epoch [2/50] batch [260/319] time 0.076 (0.086) data 0.000 (0.002) loss 1.4201 (1.7668) teacher_loss 0.4931 (1.0596) loss_zs_kd 5.9347 (3.6164) loss_oracle 0.9271 (0.7072) acc 87.5000 (70.8413) alaph_mean 0.6167 (0.5513) alpha_val 0.6167 (0.5513) lr 2.0000e-03 eta 0:21:57
epoch [2/50] batch [280/319] time 0.082 (0.086) data 0.000 (0.002) loss 1.4509 (1.7587) teacher_loss 0.6232 (1.0361) loss_zs_kd 5.2068 (3.7658) loss_oracle 0.8277 (0.7226) acc 81.2500 (71.4174) alaph_mean 0.6237 (0.5563) alpha_val 0.6237 (0.5563) lr 2.0000e-03 eta 0:21:58
epoch [2/50] batch [300/319] time 0.085 (0.086) data 0.000 (0.002) loss 1.4904 (1.7526) teacher_loss 0.5976 (1.0223) loss_zs_kd 5.5298 (3.9308) loss_oracle 0.8928 (0.7302) acc 90.6250 (71.9062) alaph_mean 0.6336 (0.5611) alpha_val 0.6336 (0.5611) lr 2.0000e-03 eta 0:21:52
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,269
* accuracy: 29.0%
* error: 71.0%
* macro_f1: 16.3%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 5,397
* accuracy: 55.4%
* error: 44.6%
* macro_f1: 16.8%
Checkpoint saved to icml/multi-dg/oracle/14_learnablealpha/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [3/50] batch [20/319] time 0.083 (0.118) data 0.000 (0.035) loss 1.4202 (1.5651) teacher_loss 0.4622 (0.6734) loss_zs_kd 5.5979 (6.1212) loss_oracle 0.9580 (0.8916) acc 87.5000 (79.8438) alaph_mean 0.6504 (0.6466) alpha_val 0.6504 (0.6466) lr 1.9980e-03 eta 0:30:02
epoch [3/50] batch [40/319] time 0.087 (0.100) data 0.000 (0.018) loss 1.5830 (1.5463) teacher_loss 0.5846 (0.6382) loss_zs_kd 7.9096 (6.0232) loss_oracle 0.9983 (0.9080) acc 84.3750 (80.3906) alaph_mean 0.6564 (0.6501) alpha_val 0.6564 (0.6501) lr 1.9980e-03 eta 0:25:21
epoch [3/50] batch [60/319] time 0.079 (0.096) data 0.000 (0.012) loss 1.4833 (1.5495) teacher_loss 0.6338 (0.6323) loss_zs_kd 6.3941 (6.4957) loss_oracle 0.8495 (0.9171) acc 84.3750 (80.6771) alaph_mean 0.6612 (0.6531) alpha_val 0.6612 (0.6531) lr 1.9980e-03 eta 0:24:20
epoch [3/50] batch [80/319] time 0.074 (0.093) data 0.000 (0.009) loss 1.5046 (1.5540) teacher_loss 0.5861 (0.6317) loss_zs_kd 6.8943 (6.4968) loss_oracle 0.9185 (0.9224) acc 81.2500 (80.6250) alaph_mean 0.6676 (0.6559) alpha_val 0.6676 (0.6559) lr 1.9980e-03 eta 0:23:29
epoch [3/50] batch [100/319] time 0.087 (0.091) data 0.000 (0.007) loss 1.4933 (1.5588) teacher_loss 0.5119 (0.6343) loss_zs_kd 6.9847 (6.5333) loss_oracle 0.9814 (0.9245) acc 90.6250 (80.6250) alaph_mean 0.6731 (0.6588) alpha_val 0.6731 (0.6588) lr 1.9980e-03 eta 0:23:05
epoch [3/50] batch [120/319] time 0.077 (0.090) data 0.001 (0.006) loss 1.6513 (1.5622) teacher_loss 0.7304 (0.6347) loss_zs_kd 6.5274 (6.5639) loss_oracle 0.9209 (0.9275) acc 71.8750 (80.2083) alaph_mean 0.6782 (0.6617) alpha_val 0.6782 (0.6617) lr 1.9980e-03 eta 0:22:50
epoch [3/50] batch [140/319] time 0.085 (0.089) data 0.000 (0.005) loss 1.4409 (1.5605) teacher_loss 0.5333 (0.6334) loss_zs_kd 6.5969 (6.5496) loss_oracle 0.9077 (0.9272) acc 84.3750 (80.2009) alaph_mean 0.6842 (0.6644) alpha_val 0.6842 (0.6644) lr 1.9980e-03 eta 0:22:33
epoch [3/50] batch [160/319] time 0.065 (0.087) data 0.000 (0.005) loss 1.4116 (1.5536) teacher_loss 0.4395 (0.6246) loss_zs_kd 6.7788 (6.5416) loss_oracle 0.9721 (0.9290) acc 90.6250 (80.3711) alaph_mean 0.6903 (0.6673) alpha_val 0.6903 (0.6673) lr 1.9980e-03 eta 0:21:51
epoch [3/50] batch [180/319] time 0.068 (0.085) data 0.000 (0.004) loss 1.5600 (1.5547) teacher_loss 0.6137 (0.6198) loss_zs_kd 7.0246 (6.5848) loss_oracle 0.9463 (0.9348) acc 75.0000 (80.2951) alaph_mean 0.6948 (0.6702) alpha_val 0.6948 (0.6702) lr 1.9980e-03 eta 0:21:19
epoch [3/50] batch [200/319] time 0.062 (0.082) data 0.000 (0.004) loss 1.5123 (1.5505) teacher_loss 0.5908 (0.6130) loss_zs_kd 7.4846 (6.6223) loss_oracle 0.9214 (0.9376) acc 87.5000 (80.3281) alaph_mean 0.6988 (0.6728) alpha_val 0.6988 (0.6728) lr 1.9980e-03 eta 0:20:38
epoch [3/50] batch [220/319] time 0.061 (0.080) data 0.000 (0.003) loss 1.3853 (1.5500) teacher_loss 0.4659 (0.6095) loss_zs_kd 6.4956 (6.6472) loss_oracle 0.9194 (0.9405) acc 78.1250 (80.2983) alaph_mean 0.7025 (0.6754) alpha_val 0.7025 (0.6754) lr 1.9980e-03 eta 0:20:09
epoch [3/50] batch [240/319] time 0.064 (0.079) data 0.000 (0.003) loss 1.8656 (1.5483) teacher_loss 0.9413 (0.6073) loss_zs_kd 6.5330 (6.6514) loss_oracle 0.9243 (0.9410) acc 65.6250 (80.3255) alaph_mean 0.7063 (0.6778) alpha_val 0.7063 (0.6778) lr 1.9980e-03 eta 0:19:48
epoch [3/50] batch [260/319] time 0.058 (0.077) data 0.000 (0.003) loss 1.4917 (1.5492) teacher_loss 0.6046 (0.6087) loss_zs_kd 6.6484 (6.6335) loss_oracle 0.8870 (0.9404) acc 84.3750 (80.1683) alaph_mean 0.7108 (0.6802) alpha_val 0.7108 (0.6802) lr 1.9980e-03 eta 0:19:26
epoch [3/50] batch [280/319] time 0.058 (0.076) data 0.000 (0.003) loss 1.4669 (1.5474) teacher_loss 0.4947 (0.6071) loss_zs_kd 7.0444 (6.6387) loss_oracle 0.9722 (0.9404) acc 87.5000 (80.1004) alaph_mean 0.7154 (0.6825) alpha_val 0.7154 (0.6825) lr 1.9980e-03 eta 0:19:06
epoch [3/50] batch [300/319] time 0.134 (0.076) data 0.001 (0.003) loss 1.5288 (1.5486) teacher_loss 0.5772 (0.6072) loss_zs_kd 6.4449 (6.6412) loss_oracle 0.9517 (0.9414) acc 78.1250 (80.0000) alaph_mean 0.7192 (0.6849) alpha_val 0.7192 (0.6849) lr 1.9980e-03 eta 0:18:54
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,564
* accuracy: 35.7%
* error: 64.3%
* macro_f1: 33.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,977
* accuracy: 20.3%
* error: 79.7%
* macro_f1: 16.4%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [4/50] batch [20/319] time 0.093 (0.109) data 0.000 (0.033) loss 1.6544 (1.5338) teacher_loss 0.7440 (0.6809) loss_zs_kd 3.7081 (3.4374) loss_oracle 0.9104 (0.8528) acc 78.1250 (83.1250) alaph_mean 0.7331 (0.7291) alpha_val 0.7331 (0.7291) lr 1.9921e-03 eta 0:27:06
epoch [4/50] batch [40/319] time 0.075 (0.096) data 0.000 (0.017) loss 1.6810 (1.5521) teacher_loss 0.8470 (0.6950) loss_zs_kd 4.0950 (3.7277) loss_oracle 0.8340 (0.8571) acc 68.7500 (80.7031) alaph_mean 0.7423 (0.7336) alpha_val 0.7423 (0.7336) lr 1.9921e-03 eta 0:23:48
epoch [4/50] batch [60/319] time 0.081 (0.091) data 0.000 (0.011) loss 1.8774 (1.5585) teacher_loss 1.1458 (0.7048) loss_zs_kd 3.7949 (3.8724) loss_oracle 0.7315 (0.8537) acc 65.6250 (81.0417) alaph_mean 0.7525 (0.7381) alpha_val 0.7525 (0.7381) lr 1.9921e-03 eta 0:22:32
epoch [4/50] batch [80/319] time 0.082 (0.088) data 0.000 (0.008) loss 1.6416 (1.5591) teacher_loss 0.8371 (0.7283) loss_zs_kd 4.8884 (4.0009) loss_oracle 0.8045 (0.8308) acc 81.2500 (81.1328) alaph_mean 0.7655 (0.7435) alpha_val 0.7655 (0.7435) lr 1.9921e-03 eta 0:21:56
epoch [4/50] batch [100/319] time 0.073 (0.087) data 0.000 (0.007) loss 1.7612 (1.5553) teacher_loss 0.9425 (0.7266) loss_zs_kd 4.5107 (4.1940) loss_oracle 0.8187 (0.8287) acc 78.1250 (81.0938) alaph_mean 0.7748 (0.7489) alpha_val 0.7748 (0.7489) lr 1.9921e-03 eta 0:21:37
epoch [4/50] batch [120/319] time 0.078 (0.089) data 0.000 (0.006) loss 1.4497 (1.5517) teacher_loss 0.5833 (0.7151) loss_zs_kd 5.8881 (4.3990) loss_oracle 0.8663 (0.8365) acc 81.2500 (80.8073) alaph_mean 0.7817 (0.7538) alpha_val 0.7817 (0.7538) lr 1.9921e-03 eta 0:21:56
epoch [4/50] batch [140/319] time 0.087 (0.087) data 0.000 (0.005) loss 1.7616 (1.5546) teacher_loss 0.7943 (0.7011) loss_zs_kd 5.9545 (4.6033) loss_oracle 0.9673 (0.8535) acc 68.7500 (80.5357) alaph_mean 0.7861 (0.7582) alpha_val 0.7861 (0.7582) lr 1.9921e-03 eta 0:21:37
epoch [4/50] batch [160/319] time 0.081 (0.087) data 0.000 (0.004) loss 1.9994 (1.5557) teacher_loss 1.1013 (0.6923) loss_zs_kd 5.6036 (4.7374) loss_oracle 0.8980 (0.8634) acc 71.8750 (80.6250) alaph_mean 0.7904 (0.7620) alpha_val 0.7904 (0.7620) lr 1.9921e-03 eta 0:21:24
epoch [4/50] batch [180/319] time 0.088 (0.086) data 0.000 (0.004) loss 1.6498 (1.5497) teacher_loss 0.7291 (0.6783) loss_zs_kd 4.6602 (4.8114) loss_oracle 0.9207 (0.8714) acc 75.0000 (80.8507) alaph_mean 0.7952 (0.7654) alpha_val 0.7952 (0.7654) lr 1.9921e-03 eta 0:21:12
epoch [4/50] batch [200/319] time 0.094 (0.086) data 0.000 (0.004) loss 1.4687 (1.5440) teacher_loss 0.4726 (0.6637) loss_zs_kd 5.8681 (4.8924) loss_oracle 0.9961 (0.8803) acc 81.2500 (81.0156) alaph_mean 0.7992 (0.7686) alpha_val 0.7992 (0.7686) lr 1.9921e-03 eta 0:21:07
epoch [4/50] batch [220/319] time 0.080 (0.085) data 0.000 (0.003) loss 1.6918 (1.5421) teacher_loss 0.8469 (0.6571) loss_zs_kd 4.1175 (4.8998) loss_oracle 0.8449 (0.8850) acc 75.0000 (81.1790) alaph_mean 0.8037 (0.7716) alpha_val 0.8037 (0.7716) lr 1.9921e-03 eta 0:20:59
epoch [4/50] batch [240/319] time 0.082 (0.085) data 0.000 (0.003) loss 1.4431 (1.5439) teacher_loss 0.4182 (0.6527) loss_zs_kd 5.6109 (4.8771) loss_oracle 1.0249 (0.8912) acc 90.6250 (81.0677) alaph_mean 0.8085 (0.7745) alpha_val 0.8085 (0.7745) lr 1.9921e-03 eta 0:20:53
epoch [4/50] batch [260/319] time 0.080 (0.085) data 0.000 (0.003) loss 1.5697 (1.5454) teacher_loss 0.6288 (0.6488) loss_zs_kd 4.9181 (4.8770) loss_oracle 0.9409 (0.8966) acc 78.1250 (80.8774) alaph_mean 0.8120 (0.7773) alpha_val 0.8120 (0.7773) lr 1.9921e-03 eta 0:20:45
epoch [4/50] batch [280/319] time 0.075 (0.084) data 0.000 (0.003) loss 1.3746 (1.5407) teacher_loss 0.4100 (0.6422) loss_zs_kd 4.3188 (4.8545) loss_oracle 0.9646 (0.8985) acc 84.3750 (81.1830) alaph_mean 0.8159 (0.7799) alpha_val 0.8159 (0.7799) lr 1.9921e-03 eta 0:20:36
epoch [4/50] batch [300/319] time 0.089 (0.084) data 0.000 (0.002) loss 1.4548 (1.5369) teacher_loss 0.4752 (0.6364) loss_zs_kd 4.2042 (4.8179) loss_oracle 0.9796 (0.9004) acc 87.5000 (81.3438) alaph_mean 0.8195 (0.7824) alpha_val 0.8195 (0.7824) lr 1.9921e-03 eta 0:20:31
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,216
* accuracy: 27.8%
* error: 72.2%
* macro_f1: 28.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 3,296
* accuracy: 33.9%
* error: 66.1%
* macro_f1: 20.6%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [5/50] batch [20/319] time 0.075 (0.111) data 0.000 (0.029) loss 1.4675 (1.4762) teacher_loss 0.5958 (0.5381) loss_zs_kd 4.5894 (4.7561) loss_oracle 0.8717 (0.9381) acc 84.3750 (82.9688) alaph_mean 0.8248 (0.8234) alpha_val 0.8248 (0.8234) lr 1.9823e-03 eta 0:27:11
epoch [5/50] batch [40/319] time 0.083 (0.097) data 0.000 (0.015) loss 1.3080 (1.4738) teacher_loss 0.4076 (0.5243) loss_zs_kd 4.4807 (4.7584) loss_oracle 0.9004 (0.9495) acc 90.6250 (82.7344) alaph_mean 0.8279 (0.8249) alpha_val 0.8279 (0.8249) lr 1.9823e-03 eta 0:23:41
epoch [5/50] batch [60/319] time 0.081 (0.093) data 0.000 (0.010) loss 1.3639 (1.4883) teacher_loss 0.3961 (0.5348) loss_zs_kd 4.5191 (4.7506) loss_oracle 0.9678 (0.9535) acc 87.5000 (83.0208) alaph_mean 0.8312 (0.8265) alpha_val 0.8312 (0.8265) lr 1.9823e-03 eta 0:22:33
epoch [5/50] batch [80/319] time 0.086 (0.090) data 0.000 (0.007) loss 1.3858 (1.4776) teacher_loss 0.4249 (0.5257) loss_zs_kd 5.3117 (4.8148) loss_oracle 0.9609 (0.9519) acc 87.5000 (83.0078) alaph_mean 0.8349 (0.8281) alpha_val 0.8349 (0.8281) lr 1.9823e-03 eta 0:21:58
epoch [5/50] batch [100/319] time 0.081 (0.089) data 0.000 (0.006) loss 1.6023 (1.4812) teacher_loss 0.6067 (0.5286) loss_zs_kd 5.6422 (4.8703) loss_oracle 0.9956 (0.9526) acc 78.1250 (83.1562) alaph_mean 0.8385 (0.8299) alpha_val 0.8385 (0.8299) lr 1.9823e-03 eta 0:21:36
epoch [5/50] batch [120/319] time 0.083 (0.088) data 0.000 (0.005) loss 1.5874 (1.4852) teacher_loss 0.5544 (0.5312) loss_zs_kd 5.4361 (4.8772) loss_oracle 1.0329 (0.9540) acc 75.0000 (83.2292) alaph_mean 0.8418 (0.8316) alpha_val 0.8418 (0.8316) lr 1.9823e-03 eta 0:21:21
epoch [5/50] batch [140/319] time 0.090 (0.087) data 0.000 (0.004) loss 1.6098 (1.4854) teacher_loss 0.7502 (0.5300) loss_zs_kd 4.3522 (4.9313) loss_oracle 0.8596 (0.9553) acc 90.6250 (83.2366) alaph_mean 0.8444 (0.8333) alpha_val 0.8444 (0.8333) lr 1.9823e-03 eta 0:21:06
epoch [5/50] batch [160/319] time 0.077 (0.086) data 0.000 (0.004) loss 1.4102 (1.4793) teacher_loss 0.4634 (0.5224) loss_zs_kd 4.4271 (4.9251) loss_oracle 0.9468 (0.9569) acc 81.2500 (83.5938) alaph_mean 0.8469 (0.8348) alpha_val 0.8469 (0.8348) lr 1.9823e-03 eta 0:20:49
epoch [5/50] batch [180/319] time 0.090 (0.086) data 0.000 (0.003) loss 1.2463 (1.4703) teacher_loss 0.2693 (0.5150) loss_zs_kd 5.3220 (4.9285) loss_oracle 0.9770 (0.9553) acc 90.6250 (83.8715) alaph_mean 0.8494 (0.8363) alpha_val 0.8494 (0.8363) lr 1.9823e-03 eta 0:20:42
epoch [5/50] batch [200/319] time 0.077 (0.085) data 0.000 (0.003) loss 1.4933 (1.4759) teacher_loss 0.5151 (0.5206) loss_zs_kd 4.8563 (4.9320) loss_oracle 0.9782 (0.9553) acc 87.5000 (83.7188) alaph_mean 0.8522 (0.8378) alpha_val 0.8522 (0.8378) lr 1.9823e-03 eta 0:20:37
epoch [5/50] batch [220/319] time 0.073 (0.085) data 0.000 (0.003) loss 1.3028 (1.4761) teacher_loss 0.3466 (0.5216) loss_zs_kd 4.0220 (4.9048) loss_oracle 0.9562 (0.9545) acc 90.6250 (83.7358) alaph_mean 0.8552 (0.8392) alpha_val 0.8552 (0.8392) lr 1.9823e-03 eta 0:20:29
epoch [5/50] batch [240/319] time 0.082 (0.085) data 0.000 (0.003) loss 1.4408 (1.4811) teacher_loss 0.5421 (0.5320) loss_zs_kd 3.7817 (4.8068) loss_oracle 0.8987 (0.9490) acc 84.3750 (83.5677) alaph_mean 0.8597 (0.8407) alpha_val 0.8597 (0.8407) lr 1.9823e-03 eta 0:20:19
epoch [5/50] batch [260/319] time 0.080 (0.085) data 0.000 (0.002) loss 1.6636 (1.4825) teacher_loss 0.6914 (0.5361) loss_zs_kd 4.7991 (4.7527) loss_oracle 0.9722 (0.9465) acc 75.0000 (83.4014) alaph_mean 0.8644 (0.8424) alpha_val 0.8644 (0.8424) lr 1.9823e-03 eta 0:20:18
epoch [5/50] batch [280/319] time 0.086 (0.084) data 0.000 (0.002) loss 1.1622 (1.4814) teacher_loss 0.3038 (0.5373) loss_zs_kd 3.7363 (4.7065) loss_oracle 0.8584 (0.9441) acc 93.7500 (83.3929) alaph_mean 0.8684 (0.8441) alpha_val 0.8684 (0.8441) lr 1.9823e-03 eta 0:20:15
epoch [5/50] batch [300/319] time 0.081 (0.086) data 0.000 (0.002) loss 1.4997 (1.4825) teacher_loss 0.5801 (0.5429) loss_zs_kd 4.3191 (4.6643) loss_oracle 0.9196 (0.9396) acc 84.3750 (83.2500) alaph_mean 0.8730 (0.8459) alpha_val 0.8730 (0.8459) lr 1.9823e-03 eta 0:20:30
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,640
* accuracy: 37.5%
* error: 62.5%
* macro_f1: 28.0%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,258
* accuracy: 12.9%
* error: 87.1%
* macro_f1: 11.6%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [6/50] batch [20/319] time 0.083 (0.104) data 0.000 (0.030) loss 1.6603 (1.4209) teacher_loss 0.6899 (0.4890) loss_zs_kd 4.0863 (4.0287) loss_oracle 0.9704 (0.9319) acc 75.0000 (85.6250) alaph_mean 0.8803 (0.8787) alpha_val 0.8803 (0.8787) lr 1.9686e-03 eta 0:24:52
epoch [6/50] batch [40/319] time 0.075 (0.092) data 0.000 (0.015) loss 1.5060 (1.4039) teacher_loss 0.5947 (0.4704) loss_zs_kd 3.9482 (3.9881) loss_oracle 0.9113 (0.9335) acc 84.3750 (86.3281) alaph_mean 0.8834 (0.8803) alpha_val 0.8834 (0.8803) lr 1.9686e-03 eta 0:21:56
epoch [6/50] batch [60/319] time 0.076 (0.088) data 0.000 (0.010) loss 1.5353 (1.4174) teacher_loss 0.6048 (0.4974) loss_zs_kd 3.5763 (3.9213) loss_oracle 0.9304 (0.9201) acc 75.0000 (85.3125) alaph_mean 0.8869 (0.8819) alpha_val 0.8869 (0.8819) lr 1.9686e-03 eta 0:20:54
epoch [6/50] batch [80/319] time 0.095 (0.087) data 0.000 (0.008) loss 1.5388 (1.4318) teacher_loss 0.5841 (0.5092) loss_zs_kd 4.0174 (3.9345) loss_oracle 0.9547 (0.9226) acc 78.1250 (84.6484) alaph_mean 0.8899 (0.8836) alpha_val 0.8899 (0.8836) lr 1.9686e-03 eta 0:20:36
epoch [6/50] batch [100/319] time 0.076 (0.088) data 0.000 (0.006) loss 1.4631 (1.4391) teacher_loss 0.4414 (0.5091) loss_zs_kd 4.4970 (3.9681) loss_oracle 1.0217 (0.9300) acc 81.2500 (84.3125) alaph_mean 0.8924 (0.8851) alpha_val 0.8924 (0.8851) lr 1.9686e-03 eta 0:20:57
epoch [6/50] batch [120/319] time 0.086 (0.086) data 0.001 (0.005) loss 1.5228 (1.4450) teacher_loss 0.5197 (0.5073) loss_zs_kd 5.0737 (4.0723) loss_oracle 1.0030 (0.9377) acc 84.3750 (84.2188) alaph_mean 0.8945 (0.8865) alpha_val 0.8945 (0.8865) lr 1.9686e-03 eta 0:20:31
epoch [6/50] batch [140/319] time 0.090 (0.086) data 0.000 (0.005) loss 1.4456 (1.4446) teacher_loss 0.4808 (0.5035) loss_zs_kd 4.0357 (4.0971) loss_oracle 0.9649 (0.9411) acc 87.5000 (84.1741) alaph_mean 0.8967 (0.8878) alpha_val 0.8967 (0.8878) lr 1.9686e-03 eta 0:20:17
epoch [6/50] batch [160/319] time 0.090 (0.086) data 0.000 (0.004) loss 1.3829 (1.4465) teacher_loss 0.4428 (0.5014) loss_zs_kd 4.2280 (4.1231) loss_oracle 0.9402 (0.9451) acc 90.6250 (84.1211) alaph_mean 0.8989 (0.8891) alpha_val 0.8989 (0.8891) lr 1.9686e-03 eta 0:20:15
epoch [6/50] batch [180/319] time 0.079 (0.086) data 0.000 (0.004) loss 1.5346 (1.4524) teacher_loss 0.6133 (0.5041) loss_zs_kd 4.1506 (4.1523) loss_oracle 0.9213 (0.9483) acc 84.3750 (83.9757) alaph_mean 0.9009 (0.8903) alpha_val 0.9009 (0.8903) lr 1.9686e-03 eta 0:20:14
epoch [6/50] batch [200/319] time 0.082 (0.086) data 0.000 (0.003) loss 1.5263 (1.4536) teacher_loss 0.5661 (0.5029) loss_zs_kd 3.9267 (4.1585) loss_oracle 0.9602 (0.9507) acc 87.5000 (84.1094) alaph_mean 0.9026 (0.8914) alpha_val 0.9026 (0.8914) lr 1.9686e-03 eta 0:20:12
epoch [6/50] batch [220/319] time 0.078 (0.085) data 0.000 (0.003) loss 1.4297 (1.4554) teacher_loss 0.5312 (0.5019) loss_zs_kd 3.8618 (4.1892) loss_oracle 0.8985 (0.9534) acc 87.5000 (84.0909) alaph_mean 0.9044 (0.8925) alpha_val 0.9044 (0.8925) lr 1.9686e-03 eta 0:20:08
epoch [6/50] batch [240/319] time 0.073 (0.085) data 0.000 (0.003) loss 1.5409 (1.4582) teacher_loss 0.6282 (0.5027) loss_zs_kd 4.2092 (4.2281) loss_oracle 0.9127 (0.9555) acc 78.1250 (83.9844) alaph_mean 0.9063 (0.8936) alpha_val 0.9063 (0.8936) lr 1.9686e-03 eta 0:20:03
epoch [6/50] batch [260/319] time 0.084 (0.085) data 0.000 (0.003) loss 1.4307 (1.4600) teacher_loss 0.4304 (0.5026) loss_zs_kd 4.8144 (4.2653) loss_oracle 1.0003 (0.9574) acc 84.3750 (83.9904) alaph_mean 0.9082 (0.8947) alpha_val 0.9082 (0.8947) lr 1.9686e-03 eta 0:19:59
epoch [6/50] batch [280/319] time 0.082 (0.085) data 0.000 (0.002) loss 1.4109 (1.4622) teacher_loss 0.4582 (0.5033) loss_zs_kd 4.9084 (4.3090) loss_oracle 0.9526 (0.9590) acc 90.6250 (83.8504) alaph_mean 0.9097 (0.8957) alpha_val 0.9097 (0.8957) lr 1.9686e-03 eta 0:19:56
epoch [6/50] batch [300/319] time 0.081 (0.085) data 0.000 (0.002) loss 1.4138 (1.4632) teacher_loss 0.4300 (0.5025) loss_zs_kd 5.1579 (4.3486) loss_oracle 0.9837 (0.9607) acc 84.3750 (83.7292) alaph_mean 0.9111 (0.8967) alpha_val 0.9111 (0.8967) lr 1.9686e-03 eta 0:19:53
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,244
* accuracy: 28.4%
* error: 71.6%
* macro_f1: 24.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,128
* accuracy: 11.6%
* error: 88.4%
* macro_f1: 10.7%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [7/50] batch [20/319] time 0.078 (0.108) data 0.000 (0.026) loss 1.2380 (1.4539) teacher_loss 0.1894 (0.4540) loss_zs_kd 4.9476 (4.8145) loss_oracle 1.0486 (0.9999) acc 93.7500 (84.3750) alaph_mean 0.9128 (0.9124) alpha_val 0.9128 (0.9124) lr 1.9511e-03 eta 0:25:19
epoch [7/50] batch [40/319] time 0.081 (0.093) data 0.000 (0.013) loss 1.6100 (1.4639) teacher_loss 0.5915 (0.4664) loss_zs_kd 4.9416 (4.7863) loss_oracle 1.0185 (0.9974) acc 71.8750 (82.8906) alaph_mean 0.9139 (0.9129) alpha_val 0.9139 (0.9129) lr 1.9511e-03 eta 0:21:48
epoch [7/50] batch [60/319] time 0.075 (0.089) data 0.000 (0.009) loss 1.5145 (1.4580) teacher_loss 0.5040 (0.4559) loss_zs_kd 5.3055 (4.8462) loss_oracle 1.0105 (1.0020) acc 87.5000 (83.3854) alaph_mean 0.9147 (0.9134) alpha_val 0.9147 (0.9134) lr 1.9511e-03 eta 0:20:50
epoch [7/50] batch [80/319] time 0.077 (0.087) data 0.000 (0.007) loss 1.5505 (1.4665) teacher_loss 0.5259 (0.4618) loss_zs_kd 5.4593 (4.9737) loss_oracle 1.0247 (1.0047) acc 81.2500 (83.1641) alaph_mean 0.9157 (0.9138) alpha_val 0.9157 (0.9138) lr 1.9511e-03 eta 0:20:10
epoch [7/50] batch [100/319] time 0.074 (0.086) data 0.000 (0.005) loss 1.5108 (1.4745) teacher_loss 0.5120 (0.4663) loss_zs_kd 5.5472 (5.0410) loss_oracle 0.9988 (1.0082) acc 87.5000 (82.8125) alaph_mean 0.9165 (0.9143) alpha_val 0.9165 (0.9143) lr 1.9511e-03 eta 0:19:54
epoch [7/50] batch [120/319] time 0.078 (0.085) data 0.000 (0.005) loss 1.7315 (1.4719) teacher_loss 0.6739 (0.4624) loss_zs_kd 5.6129 (5.0762) loss_oracle 1.0576 (1.0094) acc 71.8750 (82.8385) alaph_mean 0.9174 (0.9147) alpha_val 0.9174 (0.9147) lr 1.9511e-03 eta 0:19:41
epoch [7/50] batch [140/319] time 0.083 (0.084) data 0.000 (0.004) loss 1.2886 (1.4679) teacher_loss 0.2230 (0.4576) loss_zs_kd 5.3691 (5.0658) loss_oracle 1.0656 (1.0103) acc 100.0000 (83.0804) alaph_mean 0.9182 (0.9152) alpha_val 0.9182 (0.9152) lr 1.9511e-03 eta 0:19:31
epoch [7/50] batch [160/319] time 0.086 (0.084) data 0.000 (0.004) loss 1.3126 (1.4661) teacher_loss 0.3109 (0.4570) loss_zs_kd 4.7203 (5.0156) loss_oracle 1.0017 (1.0091) acc 90.6250 (83.1250) alaph_mean 0.9192 (0.9156) alpha_val 0.9192 (0.9156) lr 1.9511e-03 eta 0:19:29
epoch [7/50] batch [180/319] time 0.078 (0.084) data 0.000 (0.003) loss 1.5394 (1.4666) teacher_loss 0.5503 (0.4564) loss_zs_kd 5.4476 (5.0134) loss_oracle 0.9891 (1.0102) acc 84.3750 (83.2118) alaph_mean 0.9201 (0.9161) alpha_val 0.9201 (0.9161) lr 1.9511e-03 eta 0:19:23
epoch [7/50] batch [200/319] time 0.082 (0.083) data 0.000 (0.003) loss 1.9143 (1.4630) teacher_loss 0.9077 (0.4537) loss_zs_kd 5.0717 (4.9958) loss_oracle 1.0066 (1.0093) acc 68.7500 (83.4688) alaph_mean 0.9212 (0.9165) alpha_val 0.9212 (0.9165) lr 1.9511e-03 eta 0:19:13
epoch [7/50] batch [220/319] time 0.084 (0.083) data 0.000 (0.003) loss 1.5284 (1.4565) teacher_loss 0.5238 (0.4469) loss_zs_kd 5.1765 (5.0028) loss_oracle 1.0046 (1.0095) acc 81.2500 (83.8068) alaph_mean 0.9220 (0.9170) alpha_val 0.9220 (0.9170) lr 1.9511e-03 eta 0:19:11
epoch [7/50] batch [240/319] time 0.086 (0.083) data 0.000 (0.002) loss 1.2754 (1.4552) teacher_loss 0.2461 (0.4460) loss_zs_kd 5.1562 (5.0170) loss_oracle 1.0294 (1.0092) acc 96.8750 (83.6849) alaph_mean 0.9229 (0.9174) alpha_val 0.9229 (0.9174) lr 1.9511e-03 eta 0:19:09
epoch [7/50] batch [260/319] time 0.081 (0.083) data 0.000 (0.002) loss 1.3968 (1.4580) teacher_loss 0.3575 (0.4481) loss_zs_kd 5.2046 (5.0415) loss_oracle 1.0393 (1.0099) acc 87.5000 (83.6659) alaph_mean 0.9239 (0.9179) alpha_val 0.9239 (0.9179) lr 1.9511e-03 eta 0:19:09
epoch [7/50] batch [280/319] time 0.083 (0.083) data 0.000 (0.002) loss 1.3827 (1.4592) teacher_loss 0.3385 (0.4488) loss_zs_kd 4.8728 (5.0482) loss_oracle 1.0442 (1.0104) acc 81.2500 (83.5826) alaph_mean 0.9247 (0.9184) alpha_val 0.9247 (0.9184) lr 1.9511e-03 eta 0:19:05
epoch [7/50] batch [300/319] time 0.070 (0.084) data 0.000 (0.002) loss 1.4926 (1.4580) teacher_loss 0.4249 (0.4474) loss_zs_kd 5.1528 (5.0337) loss_oracle 1.0676 (1.0106) acc 81.2500 (83.6042) alaph_mean 0.9255 (0.9188) alpha_val 0.9255 (0.9188) lr 1.9511e-03 eta 0:19:15
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,141
* accuracy: 26.1%
* error: 73.9%
* macro_f1: 22.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,689
* accuracy: 17.3%
* error: 82.7%
* macro_f1: 10.3%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [8/50] batch [20/319] time 0.078 (0.117) data 0.000 (0.031) loss 1.4666 (1.4808) teacher_loss 0.4717 (0.4835) loss_zs_kd 4.6118 (4.8421) loss_oracle 0.9949 (0.9973) acc 90.6250 (82.0312) alaph_mean 0.9267 (0.9264) alpha_val 0.9267 (0.9264) lr 1.9298e-03 eta 0:26:36
epoch [8/50] batch [40/319] time 0.072 (0.099) data 0.000 (0.016) loss 1.2044 (1.4408) teacher_loss 0.1593 (0.4393) loss_zs_kd 4.8282 (4.7814) loss_oracle 1.0451 (1.0015) acc 100.0000 (83.8281) alaph_mean 0.9275 (0.9268) alpha_val 0.9275 (0.9268) lr 1.9298e-03 eta 0:22:39
epoch [8/50] batch [60/319] time 0.082 (0.092) data 0.000 (0.010) loss 1.3669 (1.4327) teacher_loss 0.3535 (0.4226) loss_zs_kd 5.2470 (4.9004) loss_oracle 1.0134 (1.0101) acc 87.5000 (84.2188) alaph_mean 0.9283 (0.9272) alpha_val 0.9283 (0.9272) lr 1.9298e-03 eta 0:21:02
epoch [8/50] batch [80/319] time 0.207 (0.093) data 0.001 (0.008) loss 1.4778 (1.4327) teacher_loss 0.5264 (0.4272) loss_zs_kd 4.2869 (4.8189) loss_oracle 0.9514 (1.0055) acc 87.5000 (84.6484) alaph_mean 0.9292 (0.9276) alpha_val 0.9292 (0.9276) lr 1.9298e-03 eta 0:21:02
epoch [8/50] batch [100/319] time 0.082 (0.092) data 0.000 (0.006) loss 1.3233 (1.4439) teacher_loss 0.2891 (0.4366) loss_zs_kd 5.5491 (4.8208) loss_oracle 1.0343 (1.0073) acc 96.8750 (84.4375) alaph_mean 0.9301 (0.9280) alpha_val 0.9301 (0.9280) lr 1.9298e-03 eta 0:20:53
epoch [8/50] batch [120/319] time 0.084 (0.090) data 0.000 (0.005) loss 1.5976 (1.4410) teacher_loss 0.5520 (0.4343) loss_zs_kd 5.3216 (4.8473) loss_oracle 1.0456 (1.0067) acc 81.2500 (84.7917) alaph_mean 0.9309 (0.9284) alpha_val 0.9309 (0.9284) lr 1.9298e-03 eta 0:20:23
epoch [8/50] batch [140/319] time 0.077 (0.089) data 0.000 (0.005) loss 1.4515 (1.4440) teacher_loss 0.3881 (0.4380) loss_zs_kd 5.5354 (4.8850) loss_oracle 1.0634 (1.0060) acc 84.3750 (84.4866) alaph_mean 0.9319 (0.9288) alpha_val 0.9319 (0.9288) lr 1.9298e-03 eta 0:20:08
epoch [8/50] batch [160/319] time 0.082 (0.088) data 0.000 (0.004) loss 1.5188 (1.4454) teacher_loss 0.4941 (0.4385) loss_zs_kd 5.0339 (4.9285) loss_oracle 1.0247 (1.0069) acc 75.0000 (84.4336) alaph_mean 0.9330 (0.9293) alpha_val 0.9330 (0.9293) lr 1.9298e-03 eta 0:19:52
epoch [8/50] batch [180/319] time 0.084 (0.087) data 0.000 (0.004) loss 1.6332 (1.4460) teacher_loss 0.5981 (0.4391) loss_zs_kd 5.4936 (4.9694) loss_oracle 1.0351 (1.0068) acc 75.0000 (84.2882) alaph_mean 0.9338 (0.9298) alpha_val 0.9338 (0.9298) lr 1.9298e-03 eta 0:19:44
epoch [8/50] batch [200/319] time 0.081 (0.087) data 0.000 (0.003) loss 1.4487 (1.4455) teacher_loss 0.4676 (0.4378) loss_zs_kd 4.9979 (4.9890) loss_oracle 0.9811 (1.0076) acc 87.5000 (84.4219) alaph_mean 0.9346 (0.9302) alpha_val 0.9346 (0.9302) lr 1.9298e-03 eta 0:19:34
epoch [8/50] batch [220/319] time 0.084 (0.087) data 0.000 (0.003) loss 1.2957 (1.4462) teacher_loss 0.2520 (0.4384) loss_zs_kd 5.2482 (5.0113) loss_oracle 1.0437 (1.0078) acc 93.7500 (84.4176) alaph_mean 0.9354 (0.9306) alpha_val 0.9354 (0.9306) lr 1.9298e-03 eta 0:19:29
epoch [8/50] batch [240/319] time 0.092 (0.086) data 0.000 (0.003) loss 1.6384 (1.4451) teacher_loss 0.6553 (0.4361) loss_zs_kd 4.5969 (5.0404) loss_oracle 0.9832 (1.0089) acc 84.3750 (84.4271) alaph_mean 0.9361 (0.9311) alpha_val 0.9361 (0.9311) lr 1.9298e-03 eta 0:19:25
epoch [8/50] batch [260/319] time 0.085 (0.086) data 0.000 (0.003) loss 1.4702 (1.4455) teacher_loss 0.4153 (0.4363) loss_zs_kd 4.6217 (5.0326) loss_oracle 1.0550 (1.0092) acc 81.2500 (84.4351) alaph_mean 0.9368 (0.9315) alpha_val 0.9368 (0.9315) lr 1.9298e-03 eta 0:19:20
epoch [8/50] batch [280/319] time 0.082 (0.086) data 0.000 (0.002) loss 1.4886 (1.4437) teacher_loss 0.5572 (0.4343) loss_zs_kd 4.6315 (5.0155) loss_oracle 0.9314 (1.0093) acc 78.1250 (84.4866) alaph_mean 0.9373 (0.9319) alpha_val 0.9373 (0.9319) lr 1.9298e-03 eta 0:19:18
epoch [8/50] batch [300/319] time 0.081 (0.086) data 0.000 (0.002) loss 1.6323 (1.4470) teacher_loss 0.5505 (0.4370) loss_zs_kd 5.4216 (5.0213) loss_oracle 1.0818 (1.0101) acc 75.0000 (84.3229) alaph_mean 0.9380 (0.9323) alpha_val 0.9380 (0.9323) lr 1.9298e-03 eta 0:19:11
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,225
* accuracy: 28.0%
* error: 72.0%
* macro_f1: 20.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 910
* accuracy: 9.3%
* error: 90.7%
* macro_f1: 7.9%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [9/50] batch [20/319] time 0.064 (0.105) data 0.000 (0.025) loss 1.2469 (1.4015) teacher_loss 0.2427 (0.3698) loss_zs_kd 5.5881 (5.2403) loss_oracle 1.0043 (1.0317) acc 90.6250 (87.1875) alaph_mean 0.9389 (0.9387) alpha_val 0.9389 (0.9387) lr 1.9048e-03 eta 0:23:26
epoch [9/50] batch [40/319] time 0.085 (0.092) data 0.000 (0.013) loss 1.4681 (1.3939) teacher_loss 0.4859 (0.3694) loss_zs_kd 5.5093 (5.1920) loss_oracle 0.9822 (1.0246) acc 87.5000 (87.7344) alaph_mean 0.9395 (0.9389) alpha_val 0.9395 (0.9389) lr 1.9048e-03 eta 0:20:22
epoch [9/50] batch [60/319] time 0.080 (0.088) data 0.000 (0.008) loss 1.5797 (1.4224) teacher_loss 0.5498 (0.3977) loss_zs_kd 5.4786 (5.3110) loss_oracle 1.0299 (1.0247) acc 71.8750 (85.6771) alaph_mean 0.9400 (0.9392) alpha_val 0.9400 (0.9392) lr 1.9048e-03 eta 0:19:29
epoch [9/50] batch [80/319] time 0.074 (0.086) data 0.000 (0.006) loss 1.2935 (1.4302) teacher_loss 0.4004 (0.4089) loss_zs_kd 4.9797 (5.3333) loss_oracle 0.8932 (1.0213) acc 90.6250 (85.5469) alaph_mean 0.9406 (0.9395) alpha_val 0.9406 (0.9395) lr 1.9048e-03 eta 0:19:02
epoch [9/50] batch [100/319] time 0.080 (0.085) data 0.000 (0.005) loss 1.4919 (1.4315) teacher_loss 0.4557 (0.4099) loss_zs_kd 5.5067 (5.3331) loss_oracle 1.0362 (1.0216) acc 84.3750 (85.4375) alaph_mean 0.9412 (0.9398) alpha_val 0.9412 (0.9398) lr 1.9048e-03 eta 0:18:55
epoch [9/50] batch [120/319] time 0.083 (0.085) data 0.000 (0.004) loss 1.4766 (1.4377) teacher_loss 0.4380 (0.4166) loss_zs_kd 4.9097 (5.2747) loss_oracle 1.0386 (1.0211) acc 87.5000 (85.0781) alaph_mean 0.9416 (0.9401) alpha_val 0.9416 (0.9401) lr 1.9048e-03 eta 0:18:46
epoch [9/50] batch [140/319] time 0.088 (0.084) data 0.000 (0.004) loss 1.7893 (1.4428) teacher_loss 0.7342 (0.4190) loss_zs_kd 5.2389 (5.2653) loss_oracle 1.0551 (1.0238) acc 71.8750 (84.9107) alaph_mean 0.9421 (0.9403) alpha_val 0.9421 (0.9403) lr 1.9048e-03 eta 0:18:35
epoch [9/50] batch [160/319] time 0.075 (0.084) data 0.000 (0.003) loss 1.5351 (1.4369) teacher_loss 0.4786 (0.4123) loss_zs_kd 5.7861 (5.3030) loss_oracle 1.0565 (1.0247) acc 84.3750 (85.2148) alaph_mean 0.9425 (0.9406) alpha_val 0.9425 (0.9406) lr 1.9048e-03 eta 0:18:29
epoch [9/50] batch [180/319] time 0.076 (0.083) data 0.000 (0.003) loss 1.2848 (1.4329) teacher_loss 0.2332 (0.4082) loss_zs_kd 5.5572 (5.3065) loss_oracle 1.0515 (1.0248) acc 90.6250 (85.3819) alaph_mean 0.9431 (0.9408) alpha_val 0.9431 (0.9408) lr 1.9048e-03 eta 0:18:20
epoch [9/50] batch [200/319] time 0.074 (0.083) data 0.000 (0.003) loss 1.5427 (1.4343) teacher_loss 0.5747 (0.4113) loss_zs_kd 4.8520 (5.2792) loss_oracle 0.9680 (1.0230) acc 87.5000 (85.3281) alaph_mean 0.9437 (0.9411) alpha_val 0.9437 (0.9411) lr 1.9048e-03 eta 0:18:10
epoch [9/50] batch [220/319] time 0.085 (0.082) data 0.000 (0.003) loss 1.4193 (1.4333) teacher_loss 0.4670 (0.4118) loss_zs_kd 4.7789 (5.2522) loss_oracle 0.9522 (1.0215) acc 81.2500 (84.9716) alaph_mean 0.9443 (0.9413) alpha_val 0.9443 (0.9413) lr 1.9048e-03 eta 0:18:03
epoch [9/50] batch [240/319] time 0.081 (0.082) data 0.000 (0.002) loss 1.5383 (1.4341) teacher_loss 0.4549 (0.4124) loss_zs_kd 5.6139 (5.2418) loss_oracle 1.0835 (1.0217) acc 78.1250 (84.8307) alaph_mean 0.9447 (0.9416) alpha_val 0.9447 (0.9416) lr 1.9048e-03 eta 0:18:02
epoch [9/50] batch [260/319] time 0.082 (0.082) data 0.000 (0.002) loss 1.5327 (1.4317) teacher_loss 0.5321 (0.4101) loss_zs_kd 5.0369 (5.2432) loss_oracle 1.0006 (1.0216) acc 75.0000 (84.8438) alaph_mean 0.9452 (0.9419) alpha_val 0.9452 (0.9419) lr 1.9048e-03 eta 0:18:01
epoch [9/50] batch [280/319] time 0.085 (0.082) data 0.000 (0.002) loss 1.3580 (1.4352) teacher_loss 0.3282 (0.4134) loss_zs_kd 5.4632 (5.2510) loss_oracle 1.0298 (1.0218) acc 87.5000 (84.5982) alaph_mean 0.9456 (0.9421) alpha_val 0.9456 (0.9421) lr 1.9048e-03 eta 0:18:00
epoch [9/50] batch [300/319] time 0.083 (0.083) data 0.000 (0.002) loss 1.5668 (1.4362) teacher_loss 0.5211 (0.4137) loss_zs_kd 5.7461 (5.2690) loss_oracle 1.0457 (1.0224) acc 81.2500 (84.4062) alaph_mean 0.9460 (0.9424) alpha_val 0.9460 (0.9424) lr 1.9048e-03 eta 0:18:10
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,463
* accuracy: 33.4%
* error: 66.6%
* macro_f1: 26.0%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,136
* accuracy: 11.7%
* error: 88.3%
* macro_f1: 10.4%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [10/50] batch [20/319] time 0.075 (0.115) data 0.000 (0.031) loss 1.4609 (1.4464) teacher_loss 0.3839 (0.4083) loss_zs_kd 5.8516 (5.7149) loss_oracle 1.0770 (1.0380) acc 90.6250 (86.0938) alaph_mean 0.9468 (0.9465) alpha_val 0.9468 (0.9465) lr 1.8763e-03 eta 0:24:56
epoch [10/50] batch [40/319] time 0.085 (0.096) data 0.000 (0.016) loss 1.4288 (1.4291) teacher_loss 0.4069 (0.3922) loss_zs_kd 5.2174 (5.5809) loss_oracle 1.0219 (1.0369) acc 84.3750 (85.7031) alaph_mean 0.9471 (0.9468) alpha_val 0.9471 (0.9468) lr 1.8763e-03 eta 0:20:46
epoch [10/50] batch [60/319] time 0.075 (0.090) data 0.000 (0.010) loss 1.6654 (1.4329) teacher_loss 0.5905 (0.3984) loss_zs_kd 5.4499 (5.4787) loss_oracle 1.0749 (1.0345) acc 90.6250 (85.5208) alaph_mean 0.9476 (0.9470) alpha_val 0.9476 (0.9470) lr 1.8763e-03 eta 0:19:34
epoch [10/50] batch [80/319] time 0.065 (0.085) data 0.000 (0.008) loss 1.2986 (1.4369) teacher_loss 0.2890 (0.4054) loss_zs_kd 5.4313 (5.4620) loss_oracle 1.0097 (1.0315) acc 90.6250 (84.8828) alaph_mean 0.9479 (0.9472) alpha_val 0.9479 (0.9472) lr 1.8763e-03 eta 0:18:29
epoch [10/50] batch [100/319] time 0.088 (0.087) data 0.000 (0.006) loss 1.3357 (1.4356) teacher_loss 0.2996 (0.4042) loss_zs_kd 5.8710 (5.4842) loss_oracle 1.0360 (1.0314) acc 87.5000 (84.8438) alaph_mean 0.9484 (0.9474) alpha_val 0.9484 (0.9474) lr 1.8763e-03 eta 0:18:55
epoch [10/50] batch [120/319] time 0.080 (0.087) data 0.000 (0.005) loss 1.4445 (1.4347) teacher_loss 0.4146 (0.4040) loss_zs_kd 5.4679 (5.5198) loss_oracle 1.0300 (1.0307) acc 84.3750 (84.9219) alaph_mean 0.9489 (0.9476) alpha_val 0.9489 (0.9476) lr 1.8763e-03 eta 0:18:43
epoch [10/50] batch [140/319] time 0.088 (0.086) data 0.000 (0.005) loss 1.4252 (1.4313) teacher_loss 0.3971 (0.4017) loss_zs_kd 5.9093 (5.5381) loss_oracle 1.0281 (1.0296) acc 87.5000 (85.2009) alaph_mean 0.9493 (0.9478) alpha_val 0.9493 (0.9478) lr 1.8763e-03 eta 0:18:37
epoch [10/50] batch [160/319] time 0.074 (0.086) data 0.000 (0.004) loss 1.4555 (1.4259) teacher_loss 0.4242 (0.3980) loss_zs_kd 6.2689 (5.5708) loss_oracle 1.0313 (1.0279) acc 87.5000 (85.2344) alaph_mean 0.9497 (0.9480) alpha_val 0.9497 (0.9480) lr 1.8763e-03 eta 0:18:30
epoch [10/50] batch [180/319] time 0.084 (0.086) data 0.000 (0.004) loss 1.5193 (1.4316) teacher_loss 0.4974 (0.4036) loss_zs_kd 6.0535 (5.5850) loss_oracle 1.0218 (1.0280) acc 78.1250 (85.0694) alaph_mean 0.9501 (0.9482) alpha_val 0.9501 (0.9482) lr 1.8763e-03 eta 0:18:26
epoch [10/50] batch [200/319] time 0.079 (0.085) data 0.000 (0.003) loss 1.2398 (1.4267) teacher_loss 0.1998 (0.3992) loss_zs_kd 6.1618 (5.6011) loss_oracle 1.0400 (1.0275) acc 96.8750 (85.2500) alaph_mean 0.9505 (0.9484) alpha_val 0.9505 (0.9484) lr 1.8763e-03 eta 0:18:19
epoch [10/50] batch [220/319] time 0.076 (0.085) data 0.000 (0.003) loss 1.2444 (1.4256) teacher_loss 0.2287 (0.3986) loss_zs_kd 6.0002 (5.6086) loss_oracle 1.0157 (1.0271) acc 93.7500 (85.3977) alaph_mean 0.9508 (0.9486) alpha_val 0.9508 (0.9486) lr 1.8763e-03 eta 0:18:09
epoch [10/50] batch [240/319] time 0.085 (0.084) data 0.000 (0.003) loss 1.3995 (1.4288) teacher_loss 0.3921 (0.4011) loss_zs_kd 5.7324 (5.6047) loss_oracle 1.0074 (1.0276) acc 87.5000 (85.2474) alaph_mean 0.9512 (0.9488) alpha_val 0.9512 (0.9488) lr 1.8763e-03 eta 0:18:03
epoch [10/50] batch [260/319] time 0.081 (0.084) data 0.000 (0.003) loss 1.5319 (1.4318) teacher_loss 0.4935 (0.4030) loss_zs_kd 5.8368 (5.6152) loss_oracle 1.0384 (1.0288) acc 78.1250 (84.9639) alaph_mean 0.9515 (0.9490) alpha_val 0.9515 (0.9490) lr 1.8763e-03 eta 0:17:58
epoch [10/50] batch [280/319] time 0.082 (0.084) data 0.000 (0.002) loss 1.3315 (1.4291) teacher_loss 0.2650 (0.4005) loss_zs_kd 6.2494 (5.6242) loss_oracle 1.0665 (1.0286) acc 90.6250 (85.1116) alaph_mean 0.9518 (0.9492) alpha_val 0.9518 (0.9492) lr 1.8763e-03 eta 0:17:55
epoch [10/50] batch [300/319] time 0.079 (0.084) data 0.000 (0.002) loss 1.4173 (1.4287) teacher_loss 0.3576 (0.3999) loss_zs_kd 5.1815 (5.6164) loss_oracle 1.0596 (1.0288) acc 90.6250 (85.1875) alaph_mean 0.9522 (0.9494) alpha_val 0.9522 (0.9494) lr 1.8763e-03 eta 0:17:49
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,161
* accuracy: 26.5%
* error: 73.5%
* macro_f1: 24.3%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 2,188
* accuracy: 22.5%
* error: 77.5%
* macro_f1: 14.5%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [11/50] batch [20/319] time 0.083 (0.115) data 0.000 (0.031) loss 1.3869 (1.4363) teacher_loss 0.3353 (0.4046) loss_zs_kd 6.1922 (5.7297) loss_oracle 1.0516 (1.0318) acc 93.7500 (84.3750) alaph_mean 0.9528 (0.9527) alpha_val 0.9528 (0.9527) lr 1.8443e-03 eta 0:24:27
epoch [11/50] batch [40/319] time 0.086 (0.100) data 0.000 (0.015) loss 1.2640 (1.4353) teacher_loss 0.2625 (0.3991) loss_zs_kd 5.5814 (5.8716) loss_oracle 1.0015 (1.0363) acc 90.6250 (84.9219) alaph_mean 0.9531 (0.9528) alpha_val 0.9531 (0.9528) lr 1.8443e-03 eta 0:21:15
epoch [11/50] batch [60/319] time 0.080 (0.096) data 0.001 (0.010) loss 1.4267 (1.4405) teacher_loss 0.3570 (0.3996) loss_zs_kd 6.5219 (5.9887) loss_oracle 1.0698 (1.0410) acc 87.5000 (84.4271) alaph_mean 0.9533 (0.9530) alpha_val 0.9533 (0.9530) lr 1.8443e-03 eta 0:20:14
epoch [11/50] batch [80/319] time 0.083 (0.093) data 0.000 (0.008) loss 1.6498 (1.4428) teacher_loss 0.6003 (0.4030) loss_zs_kd 6.1147 (6.0431) loss_oracle 1.0495 (1.0398) acc 75.0000 (83.9844) alaph_mean 0.9537 (0.9531) alpha_val 0.9537 (0.9531) lr 1.8443e-03 eta 0:19:33
epoch [11/50] batch [100/319] time 0.079 (0.091) data 0.000 (0.006) loss 1.3046 (1.4472) teacher_loss 0.2573 (0.4090) loss_zs_kd 5.4717 (6.0016) loss_oracle 1.0474 (1.0382) acc 90.6250 (83.7500) alaph_mean 0.9541 (0.9532) alpha_val 0.9541 (0.9532) lr 1.8443e-03 eta 0:19:08
epoch [11/50] batch [120/319] time 0.083 (0.089) data 0.000 (0.005) loss 1.3292 (1.4440) teacher_loss 0.2763 (0.4067) loss_zs_kd 5.5808 (5.9221) loss_oracle 1.0529 (1.0373) acc 90.6250 (83.8281) alaph_mean 0.9544 (0.9534) alpha_val 0.9544 (0.9534) lr 1.8443e-03 eta 0:18:48
epoch [11/50] batch [140/319] time 0.083 (0.089) data 0.000 (0.005) loss 1.5222 (1.4393) teacher_loss 0.4584 (0.4025) loss_zs_kd 5.9892 (5.9137) loss_oracle 1.0637 (1.0369) acc 84.3750 (84.2411) alaph_mean 0.9547 (0.9536) alpha_val 0.9547 (0.9536) lr 1.8443e-03 eta 0:18:37
epoch [11/50] batch [160/319] time 0.081 (0.088) data 0.000 (0.004) loss 1.2312 (1.4401) teacher_loss 0.2049 (0.4035) loss_zs_kd 6.1085 (5.9276) loss_oracle 1.0263 (1.0366) acc 93.7500 (84.2383) alaph_mean 0.9550 (0.9537) alpha_val 0.9550 (0.9537) lr 1.8443e-03 eta 0:18:32
epoch [11/50] batch [180/319] time 0.085 (0.088) data 0.000 (0.004) loss 1.4326 (1.4359) teacher_loss 0.4384 (0.4008) loss_zs_kd 5.3637 (5.9156) loss_oracle 0.9942 (1.0351) acc 84.3750 (84.4618) alaph_mean 0.9553 (0.9539) alpha_val 0.9553 (0.9539) lr 1.8443e-03 eta 0:18:22
epoch [11/50] batch [200/319] time 0.075 (0.087) data 0.000 (0.003) loss 1.2656 (1.4316) teacher_loss 0.2678 (0.3980) loss_zs_kd 5.5391 (5.8956) loss_oracle 0.9978 (1.0336) acc 93.7500 (84.7188) alaph_mean 0.9556 (0.9540) alpha_val 0.9556 (0.9540) lr 1.8443e-03 eta 0:18:14
epoch [11/50] batch [220/319] time 0.087 (0.087) data 0.000 (0.003) loss 1.5464 (1.4313) teacher_loss 0.4768 (0.3981) loss_zs_kd 5.9848 (5.9068) loss_oracle 1.0697 (1.0332) acc 81.2500 (84.7159) alaph_mean 0.9558 (0.9542) alpha_val 0.9558 (0.9542) lr 1.8443e-03 eta 0:18:08
epoch [11/50] batch [240/319] time 0.084 (0.087) data 0.000 (0.003) loss 1.2672 (1.4245) teacher_loss 0.2218 (0.3924) loss_zs_kd 6.8540 (5.9105) loss_oracle 1.0454 (1.0322) acc 90.6250 (84.9870) alaph_mean 0.9561 (0.9543) alpha_val 0.9561 (0.9543) lr 1.8443e-03 eta 0:18:07
epoch [11/50] batch [260/319] time 0.082 (0.087) data 0.000 (0.003) loss 1.2782 (1.4237) teacher_loss 0.2098 (0.3912) loss_zs_kd 6.0402 (5.9167) loss_oracle 1.0684 (1.0324) acc 90.6250 (85.0361) alaph_mean 0.9565 (0.9545) alpha_val 0.9565 (0.9545) lr 1.8443e-03 eta 0:18:03
epoch [11/50] batch [280/319] time 0.085 (0.088) data 0.000 (0.002) loss 1.6646 (1.4217) teacher_loss 0.6000 (0.3893) loss_zs_kd 5.7447 (5.9171) loss_oracle 1.0646 (1.0324) acc 78.1250 (85.0223) alaph_mean 0.9568 (0.9546) alpha_val 0.9568 (0.9546) lr 1.8443e-03 eta 0:18:14
epoch [11/50] batch [300/319] time 0.085 (0.088) data 0.000 (0.002) loss 1.9747 (1.4263) teacher_loss 0.9325 (0.3934) loss_zs_kd 6.0523 (5.9209) loss_oracle 1.0422 (1.0329) acc 71.8750 (84.8333) alaph_mean 0.9571 (0.9548) alpha_val 0.9571 (0.9548) lr 1.8443e-03 eta 0:18:10
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,144
* accuracy: 26.1%
* error: 73.9%
* macro_f1: 23.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 2,253
* accuracy: 23.1%
* error: 76.9%
* macro_f1: 14.7%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [12/50] batch [20/319] time 0.078 (0.104) data 0.000 (0.025) loss 1.3339 (1.4305) teacher_loss 0.3211 (0.3928) loss_zs_kd 5.8348 (6.1471) loss_oracle 1.0127 (1.0377) acc 81.2500 (83.5938) alaph_mean 0.9577 (0.9575) alpha_val 0.9577 (0.9575) lr 1.8090e-03 eta 0:21:33
epoch [12/50] batch [40/319] time 0.083 (0.092) data 0.000 (0.013) loss 1.3266 (1.4495) teacher_loss 0.2771 (0.4105) loss_zs_kd 5.7461 (5.9244) loss_oracle 1.0495 (1.0390) acc 90.6250 (82.8125) alaph_mean 0.9579 (0.9577) alpha_val 0.9579 (0.9577) lr 1.8090e-03 eta 0:18:57
epoch [12/50] batch [60/319] time 0.075 (0.087) data 0.001 (0.009) loss 1.4238 (1.4543) teacher_loss 0.4239 (0.4124) loss_zs_kd 5.9195 (5.9544) loss_oracle 0.9999 (1.0419) acc 81.2500 (82.8125) alaph_mean 0.9582 (0.9578) alpha_val 0.9582 (0.9578) lr 1.8090e-03 eta 0:18:00
epoch [12/50] batch [80/319] time 0.078 (0.090) data 0.000 (0.006) loss 1.3628 (1.4558) teacher_loss 0.3489 (0.4143) loss_zs_kd 5.7565 (5.9460) loss_oracle 1.0140 (1.0415) acc 87.5000 (83.0859) alaph_mean 0.9585 (0.9579) alpha_val 0.9585 (0.9579) lr 1.8090e-03 eta 0:18:28
epoch [12/50] batch [100/319] time 0.089 (0.088) data 0.000 (0.005) loss 1.3986 (1.4529) teacher_loss 0.3211 (0.4134) loss_zs_kd 5.9844 (5.8629) loss_oracle 1.0775 (1.0395) acc 87.5000 (83.2812) alaph_mean 0.9588 (0.9581) alpha_val 0.9588 (0.9581) lr 1.8090e-03 eta 0:18:03
epoch [12/50] batch [120/319] time 0.087 (0.087) data 0.000 (0.004) loss 1.5548 (1.4556) teacher_loss 0.4703 (0.4153) loss_zs_kd 5.9018 (5.8359) loss_oracle 1.0845 (1.0404) acc 81.2500 (83.5677) alaph_mean 0.9590 (0.9582) alpha_val 0.9590 (0.9582) lr 1.8090e-03 eta 0:17:51
epoch [12/50] batch [140/319] time 0.082 (0.086) data 0.000 (0.004) loss 1.5264 (1.4419) teacher_loss 0.4341 (0.4003) loss_zs_kd 5.8799 (5.8315) loss_oracle 1.0922 (1.0416) acc 87.5000 (84.3973) alaph_mean 0.9593 (0.9583) alpha_val 0.9593 (0.9583) lr 1.8090e-03 eta 0:17:41
epoch [12/50] batch [160/319] time 0.076 (0.086) data 0.000 (0.003) loss 1.4552 (1.4391) teacher_loss 0.4075 (0.3989) loss_zs_kd 6.0391 (5.8214) loss_oracle 1.0477 (1.0402) acc 81.2500 (84.6094) alaph_mean 0.9595 (0.9585) alpha_val 0.9595 (0.9585) lr 1.8090e-03 eta 0:17:30
epoch [12/50] batch [180/319] time 0.084 (0.085) data 0.001 (0.003) loss 1.4295 (1.4380) teacher_loss 0.3408 (0.3969) loss_zs_kd 6.0681 (5.8452) loss_oracle 1.0887 (1.0411) acc 84.3750 (84.5312) alaph_mean 0.9597 (0.9586) alpha_val 0.9597 (0.9586) lr 1.8090e-03 eta 0:17:18
epoch [12/50] batch [200/319] time 0.083 (0.085) data 0.000 (0.003) loss 1.4585 (1.4358) teacher_loss 0.3754 (0.3951) loss_zs_kd 6.0313 (5.8397) loss_oracle 1.0831 (1.0407) acc 81.2500 (84.6406) alaph_mean 0.9600 (0.9587) alpha_val 0.9600 (0.9587) lr 1.8090e-03 eta 0:17:17
epoch [12/50] batch [220/319] time 0.082 (0.084) data 0.000 (0.003) loss 1.2760 (1.4324) teacher_loss 0.3225 (0.3907) loss_zs_kd 5.3074 (5.8571) loss_oracle 0.9535 (1.0417) acc 90.6250 (84.7585) alaph_mean 0.9602 (0.9588) alpha_val 0.9602 (0.9588) lr 1.8090e-03 eta 0:17:12
epoch [12/50] batch [240/319] time 0.073 (0.084) data 0.000 (0.002) loss 1.4102 (1.4313) teacher_loss 0.3602 (0.3911) loss_zs_kd 5.7913 (5.8401) loss_oracle 1.0500 (1.0403) acc 84.3750 (84.7917) alaph_mean 0.9605 (0.9590) alpha_val 0.9605 (0.9590) lr 1.8090e-03 eta 0:17:10
epoch [12/50] batch [260/319] time 0.076 (0.084) data 0.000 (0.002) loss 1.2884 (1.4275) teacher_loss 0.2180 (0.3876) loss_zs_kd 5.6474 (5.8270) loss_oracle 1.0704 (1.0399) acc 90.6250 (84.8678) alaph_mean 0.9607 (0.9591) alpha_val 0.9607 (0.9591) lr 1.8090e-03 eta 0:17:05
epoch [12/50] batch [280/319] time 0.096 (0.084) data 0.000 (0.002) loss 1.3574 (1.4252) teacher_loss 0.3514 (0.3868) loss_zs_kd 5.5180 (5.8181) loss_oracle 1.0060 (1.0385) acc 87.5000 (84.9777) alaph_mean 0.9609 (0.9592) alpha_val 0.9609 (0.9592) lr 1.8090e-03 eta 0:17:03
epoch [12/50] batch [300/319] time 0.078 (0.084) data 0.000 (0.002) loss 1.4524 (1.4216) teacher_loss 0.4211 (0.3835) loss_zs_kd 6.1377 (5.8343) loss_oracle 1.0314 (1.0381) acc 75.0000 (85.0938) alaph_mean 0.9611 (0.9593) alpha_val 0.9611 (0.9593) lr 1.8090e-03 eta 0:17:00
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,133
* accuracy: 25.9%
* error: 74.1%
* macro_f1: 22.9%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,842
* accuracy: 18.9%
* error: 81.1%
* macro_f1: 12.2%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [13/50] batch [20/319] time 0.082 (0.116) data 0.000 (0.033) loss 1.3319 (1.4242) teacher_loss 0.3432 (0.3786) loss_zs_kd 6.1341 (6.3264) loss_oracle 0.9887 (1.0456) acc 90.6250 (86.7188) alaph_mean 0.9615 (0.9615) alpha_val 0.9615 (0.9615) lr 1.7705e-03 eta 0:23:27
epoch [13/50] batch [40/319] time 0.095 (0.102) data 0.000 (0.017) loss 1.6717 (1.4140) teacher_loss 0.6809 (0.3770) loss_zs_kd 5.5861 (6.0963) loss_oracle 0.9908 (1.0370) acc 75.0000 (85.8594) alaph_mean 0.9617 (0.9615) alpha_val 0.9617 (0.9615) lr 1.7705e-03 eta 0:20:27
epoch [13/50] batch [60/319] time 0.078 (0.096) data 0.001 (0.011) loss 1.7364 (1.4290) teacher_loss 0.6808 (0.3904) loss_zs_kd 5.6240 (5.9482) loss_oracle 1.0556 (1.0386) acc 78.1250 (85.4167) alaph_mean 0.9620 (0.9617) alpha_val 0.9620 (0.9617) lr 1.7705e-03 eta 0:19:16
epoch [13/50] batch [80/319] time 0.077 (0.092) data 0.000 (0.008) loss 1.2432 (1.4322) teacher_loss 0.1903 (0.3939) loss_zs_kd 6.2874 (5.9428) loss_oracle 1.0529 (1.0384) acc 90.6250 (84.7266) alaph_mean 0.9622 (0.9618) alpha_val 0.9622 (0.9618) lr 1.7705e-03 eta 0:18:31
epoch [13/50] batch [100/319] time 0.077 (0.091) data 0.000 (0.007) loss 1.4553 (1.4248) teacher_loss 0.3746 (0.3875) loss_zs_kd 6.7645 (5.9722) loss_oracle 1.0807 (1.0372) acc 87.5000 (85.0625) alaph_mean 0.9624 (0.9619) alpha_val 0.9624 (0.9619) lr 1.7705e-03 eta 0:18:08
epoch [13/50] batch [120/319] time 0.086 (0.090) data 0.000 (0.006) loss 1.3673 (1.4226) teacher_loss 0.3462 (0.3842) loss_zs_kd 5.8493 (6.0024) loss_oracle 1.0212 (1.0383) acc 87.5000 (85.1302) alaph_mean 0.9627 (0.9620) alpha_val 0.9627 (0.9620) lr 1.7705e-03 eta 0:17:56
epoch [13/50] batch [140/319] time 0.082 (0.089) data 0.000 (0.005) loss 1.6161 (1.4234) teacher_loss 0.6098 (0.3866) loss_zs_kd 5.4721 (5.9673) loss_oracle 1.0064 (1.0368) acc 75.0000 (85.1786) alaph_mean 0.9629 (0.9621) alpha_val 0.9629 (0.9621) lr 1.7705e-03 eta 0:17:44
epoch [13/50] batch [160/319] time 0.100 (0.089) data 0.000 (0.004) loss 1.4183 (1.4218) teacher_loss 0.3361 (0.3860) loss_zs_kd 6.1500 (5.9636) loss_oracle 1.0822 (1.0358) acc 87.5000 (84.9805) alaph_mean 0.9631 (0.9622) alpha_val 0.9631 (0.9622) lr 1.7705e-03 eta 0:17:40
epoch [13/50] batch [180/319] time 0.084 (0.088) data 0.000 (0.004) loss 1.4665 (1.4243) teacher_loss 0.4386 (0.3868) loss_zs_kd 6.3182 (6.0161) loss_oracle 1.0279 (1.0376) acc 93.7500 (84.9653) alaph_mean 0.9632 (0.9623) alpha_val 0.9632 (0.9623) lr 1.7705e-03 eta 0:17:32
epoch [13/50] batch [200/319] time 0.085 (0.088) data 0.000 (0.004) loss 1.6343 (1.4267) teacher_loss 0.5967 (0.3882) loss_zs_kd 7.1047 (6.0923) loss_oracle 1.0376 (1.0385) acc 81.2500 (84.8125) alaph_mean 0.9634 (0.9624) alpha_val 0.9634 (0.9624) lr 1.7705e-03 eta 0:17:26
epoch [13/50] batch [220/319] time 0.083 (0.087) data 0.000 (0.003) loss 1.4109 (1.4252) teacher_loss 0.3517 (0.3856) loss_zs_kd 6.3414 (6.1366) loss_oracle 1.0592 (1.0396) acc 84.3750 (84.9716) alaph_mean 0.9636 (0.9625) alpha_val 0.9636 (0.9625) lr 1.7705e-03 eta 0:17:20
epoch [13/50] batch [240/319] time 0.083 (0.087) data 0.000 (0.003) loss 1.3883 (1.4270) teacher_loss 0.3361 (0.3871) loss_zs_kd 6.5954 (6.1605) loss_oracle 1.0522 (1.0399) acc 93.7500 (85.0521) alaph_mean 0.9637 (0.9626) alpha_val 0.9637 (0.9626) lr 1.7705e-03 eta 0:17:16
epoch [13/50] batch [260/319] time 0.079 (0.088) data 0.000 (0.003) loss 1.4074 (1.4267) teacher_loss 0.4244 (0.3876) loss_zs_kd 6.3398 (6.1857) loss_oracle 0.9830 (1.0391) acc 75.0000 (85.0000) alaph_mean 0.9639 (0.9627) alpha_val 0.9639 (0.9627) lr 1.7705e-03 eta 0:17:28
epoch [13/50] batch [280/319] time 0.079 (0.088) data 0.000 (0.003) loss 1.5110 (1.4284) teacher_loss 0.4758 (0.3895) loss_zs_kd 6.5564 (6.2006) loss_oracle 1.0352 (1.0389) acc 75.0000 (84.8549) alaph_mean 0.9641 (0.9628) alpha_val 0.9641 (0.9628) lr 1.7705e-03 eta 0:17:23
epoch [13/50] batch [300/319] time 0.080 (0.088) data 0.000 (0.002) loss 1.3341 (1.4273) teacher_loss 0.2699 (0.3878) loss_zs_kd 7.1004 (6.2352) loss_oracle 1.0642 (1.0395) acc 90.6250 (84.8958) alaph_mean 0.9643 (0.9629) alpha_val 0.9643 (0.9629) lr 1.7705e-03 eta 0:17:18
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,319
* accuracy: 30.1%
* error: 69.9%
* macro_f1: 27.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 2,043
* accuracy: 21.0%
* error: 79.0%
* macro_f1: 14.2%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [14/50] batch [20/319] time 0.077 (0.115) data 0.000 (0.034) loss 1.4308 (1.4324) teacher_loss 0.3905 (0.3865) loss_zs_kd 6.1548 (6.4130) loss_oracle 1.0403 (1.0459) acc 84.3750 (83.9062) alaph_mean 0.9646 (0.9645) alpha_val 0.9646 (0.9645) lr 1.7290e-03 eta 0:22:34
epoch [14/50] batch [40/319] time 0.086 (0.099) data 0.000 (0.017) loss 1.4028 (1.4292) teacher_loss 0.3833 (0.3856) loss_zs_kd 6.6089 (6.4043) loss_oracle 1.0196 (1.0436) acc 84.3750 (85.0781) alaph_mean 0.9648 (0.9646) alpha_val 0.9648 (0.9646) lr 1.7290e-03 eta 0:19:23
epoch [14/50] batch [60/319] time 0.080 (0.099) data 0.000 (0.011) loss 1.3197 (1.4220) teacher_loss 0.3529 (0.3816) loss_zs_kd 6.7678 (6.3649) loss_oracle 0.9668 (1.0403) acc 87.5000 (85.1042) alaph_mean 0.9650 (0.9647) alpha_val 0.9650 (0.9647) lr 1.7290e-03 eta 0:19:18
epoch [14/50] batch [80/319] time 0.082 (0.094) data 0.000 (0.009) loss 1.3859 (1.4213) teacher_loss 0.3317 (0.3793) loss_zs_kd 6.6822 (6.4048) loss_oracle 1.0541 (1.0420) acc 87.5000 (84.7266) alaph_mean 0.9652 (0.9648) alpha_val 0.9652 (0.9648) lr 1.7290e-03 eta 0:18:22
epoch [14/50] batch [100/319] time 0.086 (0.091) data 0.000 (0.007) loss 1.3430 (1.4227) teacher_loss 0.2754 (0.3806) loss_zs_kd 6.3487 (6.3697) loss_oracle 1.0676 (1.0420) acc 87.5000 (85.2188) alaph_mean 0.9654 (0.9649) alpha_val 0.9654 (0.9649) lr 1.7290e-03 eta 0:17:46
epoch [14/50] batch [120/319] time 0.084 (0.090) data 0.000 (0.006) loss 1.3316 (1.4205) teacher_loss 0.3096 (0.3786) loss_zs_kd 6.1003 (6.3439) loss_oracle 1.0220 (1.0419) acc 84.3750 (85.3646) alaph_mean 0.9656 (0.9650) alpha_val 0.9656 (0.9650) lr 1.7290e-03 eta 0:17:27
epoch [14/50] batch [140/319] time 0.089 (0.088) data 0.000 (0.005) loss 1.6495 (1.4224) teacher_loss 0.6005 (0.3794) loss_zs_kd 6.6653 (6.3344) loss_oracle 1.0490 (1.0430) acc 78.1250 (85.4241) alaph_mean 0.9657 (0.9651) alpha_val 0.9657 (0.9651) lr 1.7290e-03 eta 0:17:11
epoch [14/50] batch [160/319] time 0.084 (0.088) data 0.000 (0.004) loss 1.6370 (1.4268) teacher_loss 0.5547 (0.3838) loss_zs_kd 6.2658 (6.3266) loss_oracle 1.0823 (1.0430) acc 75.0000 (85.1953) alaph_mean 0.9659 (0.9652) alpha_val 0.9659 (0.9652) lr 1.7290e-03 eta 0:17:04
epoch [14/50] batch [180/319] time 0.084 (0.088) data 0.000 (0.004) loss 1.5457 (1.4269) teacher_loss 0.5150 (0.3845) loss_zs_kd 6.5399 (6.3293) loss_oracle 1.0307 (1.0424) acc 81.2500 (85.0347) alaph_mean 0.9661 (0.9653) alpha_val 0.9661 (0.9653) lr 1.7290e-03 eta 0:16:58
epoch [14/50] batch [200/319] time 0.088 (0.087) data 0.000 (0.004) loss 1.3821 (1.4256) teacher_loss 0.2825 (0.3836) loss_zs_kd 6.1179 (6.3084) loss_oracle 1.0996 (1.0420) acc 90.6250 (85.1406) alaph_mean 0.9663 (0.9654) alpha_val 0.9663 (0.9654) lr 1.7290e-03 eta 0:16:51
epoch [14/50] batch [220/319] time 0.085 (0.087) data 0.000 (0.003) loss 1.4523 (1.4306) teacher_loss 0.3538 (0.3882) loss_zs_kd 6.1403 (6.2516) loss_oracle 1.0986 (1.0424) acc 87.5000 (84.9148) alaph_mean 0.9664 (0.9655) alpha_val 0.9664 (0.9655) lr 1.7290e-03 eta 0:16:45
epoch [14/50] batch [240/319] time 0.082 (0.087) data 0.000 (0.003) loss 1.3799 (1.4283) teacher_loss 0.3033 (0.3864) loss_zs_kd 6.2347 (6.2010) loss_oracle 1.0766 (1.0419) acc 87.5000 (84.8698) alaph_mean 0.9666 (0.9656) alpha_val 0.9666 (0.9656) lr 1.7290e-03 eta 0:16:40
epoch [14/50] batch [260/319] time 0.089 (0.086) data 0.001 (0.003) loss 1.3598 (1.4247) teacher_loss 0.3116 (0.3833) loss_zs_kd 5.6179 (6.1757) loss_oracle 1.0482 (1.0413) acc 90.6250 (85.0481) alaph_mean 0.9668 (0.9656) alpha_val 0.9668 (0.9656) lr 1.7290e-03 eta 0:16:36
epoch [14/50] batch [280/319] time 0.087 (0.086) data 0.000 (0.003) loss 1.4017 (1.4231) teacher_loss 0.3588 (0.3823) loss_zs_kd 6.4053 (6.1756) loss_oracle 1.0429 (1.0408) acc 78.1250 (85.0223) alaph_mean 0.9669 (0.9657) alpha_val 0.9669 (0.9657) lr 1.7290e-03 eta 0:16:33
epoch [14/50] batch [300/319] time 0.082 (0.086) data 0.000 (0.002) loss 1.4445 (1.4213) teacher_loss 0.4183 (0.3804) loss_zs_kd 6.6549 (6.1907) loss_oracle 1.0262 (1.0409) acc 84.3750 (85.1562) alaph_mean 0.9671 (0.9658) alpha_val 0.9671 (0.9658) lr 1.7290e-03 eta 0:16:27
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,010
* accuracy: 23.1%
* error: 76.9%
* macro_f1: 22.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,075
* accuracy: 11.0%
* error: 89.0%
* macro_f1: 10.9%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [15/50] batch [20/319] time 0.077 (0.112) data 0.000 (0.027) loss 1.7972 (1.4588) teacher_loss 0.7745 (0.4112) loss_zs_kd 6.3198 (6.2287) loss_oracle 1.0227 (1.0475) acc 65.6250 (82.0312) alaph_mean 0.9674 (0.9673) alpha_val 0.9674 (0.9673) lr 1.6845e-03 eta 0:21:29
epoch [15/50] batch [40/319] time 0.082 (0.099) data 0.000 (0.014) loss 1.2386 (1.4252) teacher_loss 0.1885 (0.3770) loss_zs_kd 6.2364 (6.2238) loss_oracle 1.0501 (1.0482) acc 90.6250 (83.8281) alaph_mean 0.9675 (0.9674) alpha_val 0.9675 (0.9674) lr 1.6845e-03 eta 0:18:48
epoch [15/50] batch [60/319] time 0.084 (0.094) data 0.001 (0.009) loss 1.4423 (1.4298) teacher_loss 0.3752 (0.3806) loss_zs_kd 6.9223 (6.2968) loss_oracle 1.0671 (1.0492) acc 81.2500 (83.6979) alaph_mean 0.9676 (0.9674) alpha_val 0.9676 (0.9674) lr 1.6845e-03 eta 0:17:52
epoch [15/50] batch [80/319] time 0.083 (0.092) data 0.000 (0.007) loss 1.2468 (1.4285) teacher_loss 0.2576 (0.3831) loss_zs_kd 5.9688 (6.3261) loss_oracle 0.9892 (1.0454) acc 90.6250 (83.3594) alaph_mean 0.9678 (0.9675) alpha_val 0.9678 (0.9675) lr 1.6845e-03 eta 0:17:25
epoch [15/50] batch [100/319] time 0.080 (0.089) data 0.000 (0.006) loss 1.3267 (1.4207) teacher_loss 0.2982 (0.3757) loss_zs_kd 6.6038 (6.3681) loss_oracle 1.0285 (1.0450) acc 90.6250 (83.8750) alaph_mean 0.9680 (0.9676) alpha_val 0.9680 (0.9676) lr 1.6845e-03 eta 0:16:53
epoch [15/50] batch [120/319] time 0.086 (0.088) data 0.000 (0.005) loss 1.2788 (1.4211) teacher_loss 0.2151 (0.3767) loss_zs_kd 6.5660 (6.3415) loss_oracle 1.0637 (1.0443) acc 93.7500 (84.0365) alaph_mean 0.9681 (0.9677) alpha_val 0.9681 (0.9677) lr 1.6845e-03 eta 0:16:35
epoch [15/50] batch [140/319] time 0.079 (0.087) data 0.000 (0.004) loss 1.5276 (1.4240) teacher_loss 0.4900 (0.3797) loss_zs_kd 6.3407 (6.3207) loss_oracle 1.0376 (1.0442) acc 84.3750 (84.2634) alaph_mean 0.9683 (0.9677) alpha_val 0.9683 (0.9677) lr 1.6845e-03 eta 0:16:21
epoch [15/50] batch [160/319] time 0.084 (0.086) data 0.000 (0.004) loss 1.3656 (1.4165) teacher_loss 0.3379 (0.3735) loss_zs_kd 5.9942 (6.2842) loss_oracle 1.0276 (1.0430) acc 87.5000 (84.5898) alaph_mean 0.9685 (0.9678) alpha_val 0.9685 (0.9678) lr 1.6845e-03 eta 0:16:16
epoch [15/50] batch [180/319] time 0.080 (0.086) data 0.000 (0.003) loss 1.4138 (1.4074) teacher_loss 0.3932 (0.3647) loss_zs_kd 6.6887 (6.2731) loss_oracle 1.0206 (1.0428) acc 75.0000 (85.0694) alaph_mean 0.9686 (0.9679) alpha_val 0.9686 (0.9679) lr 1.6845e-03 eta 0:16:12
epoch [15/50] batch [200/319] time 0.083 (0.086) data 0.000 (0.003) loss 1.5804 (1.4150) teacher_loss 0.5215 (0.3733) loss_zs_kd 6.4017 (6.2837) loss_oracle 1.0589 (1.0417) acc 75.0000 (84.9062) alaph_mean 0.9688 (0.9680) alpha_val 0.9688 (0.9680) lr 1.6845e-03 eta 0:16:09
epoch [15/50] batch [220/319] time 0.075 (0.086) data 0.000 (0.003) loss 1.5115 (1.4179) teacher_loss 0.4376 (0.3756) loss_zs_kd 6.5740 (6.2873) loss_oracle 1.0738 (1.0423) acc 81.2500 (84.8295) alaph_mean 0.9689 (0.9681) alpha_val 0.9689 (0.9681) lr 1.6845e-03 eta 0:16:05
epoch [15/50] batch [240/319] time 0.086 (0.085) data 0.000 (0.002) loss 1.3568 (1.4196) teacher_loss 0.2904 (0.3775) loss_zs_kd 6.4172 (6.2800) loss_oracle 1.0664 (1.0420) acc 84.3750 (84.7786) alaph_mean 0.9690 (0.9681) alpha_val 0.9690 (0.9681) lr 1.6845e-03 eta 0:15:59
epoch [15/50] batch [260/319] time 0.072 (0.087) data 0.000 (0.002) loss 1.3839 (1.4214) teacher_loss 0.3546 (0.3788) loss_zs_kd 6.0301 (6.2884) loss_oracle 1.0293 (1.0426) acc 78.1250 (84.6875) alaph_mean 0.9692 (0.9682) alpha_val 0.9692 (0.9682) lr 1.6845e-03 eta 0:16:12
epoch [15/50] batch [280/319] time 0.077 (0.086) data 0.000 (0.002) loss 1.3762 (1.4234) teacher_loss 0.3294 (0.3803) loss_zs_kd 6.8342 (6.3016) loss_oracle 1.0468 (1.0431) acc 87.5000 (84.6652) alaph_mean 0.9693 (0.9683) alpha_val 0.9693 (0.9683) lr 1.6845e-03 eta 0:16:05
epoch [15/50] batch [300/319] time 0.086 (0.086) data 0.000 (0.002) loss 1.6440 (1.4221) teacher_loss 0.6037 (0.3793) loss_zs_kd 6.2511 (6.2832) loss_oracle 1.0403 (1.0428) acc 68.7500 (84.6771) alaph_mean 0.9695 (0.9684) alpha_val 0.9695 (0.9684) lr 1.6845e-03 eta 0:16:01
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,294
* accuracy: 29.6%
* error: 70.4%
* macro_f1: 26.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,224
* accuracy: 12.6%
* error: 87.4%
* macro_f1: 11.6%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [16/50] batch [20/319] time 0.089 (0.113) data 0.000 (0.024) loss 1.3031 (1.4324) teacher_loss 0.2841 (0.3836) loss_zs_kd 6.1928 (6.2117) loss_oracle 1.0189 (1.0488) acc 90.6250 (85.1562) alaph_mean 0.9698 (0.9697) alpha_val 0.9698 (0.9697) lr 1.6374e-03 eta 0:21:03
epoch [16/50] batch [40/319] time 0.086 (0.108) data 0.000 (0.012) loss 1.5014 (1.4307) teacher_loss 0.4268 (0.3838) loss_zs_kd 6.5923 (6.2265) loss_oracle 1.0746 (1.0469) acc 81.2500 (84.3750) alaph_mean 0.9699 (0.9698) alpha_val 0.9699 (0.9698) lr 1.6374e-03 eta 0:19:58
epoch [16/50] batch [60/319] time 0.087 (0.099) data 0.000 (0.008) loss 1.2280 (1.4250) teacher_loss 0.2192 (0.3757) loss_zs_kd 6.2418 (6.2119) loss_oracle 1.0088 (1.0492) acc 93.7500 (84.6354) alaph_mean 0.9700 (0.9698) alpha_val 0.9700 (0.9698) lr 1.6374e-03 eta 0:18:21
epoch [16/50] batch [80/319] time 0.084 (0.095) data 0.000 (0.006) loss 1.5245 (1.4251) teacher_loss 0.4475 (0.3771) loss_zs_kd 6.6528 (6.2323) loss_oracle 1.0770 (1.0481) acc 71.8750 (84.2578) alaph_mean 0.9702 (0.9699) alpha_val 0.9702 (0.9699) lr 1.6374e-03 eta 0:17:37
epoch [16/50] batch [100/319] time 0.073 (0.092) data 0.000 (0.005) loss 1.5324 (1.4290) teacher_loss 0.4382 (0.3799) loss_zs_kd 5.6998 (6.2262) loss_oracle 1.0942 (1.0491) acc 78.1250 (84.1562) alaph_mean 0.9703 (0.9700) alpha_val 0.9703 (0.9700) lr 1.6374e-03 eta 0:16:59
epoch [16/50] batch [120/319] time 0.089 (0.091) data 0.000 (0.004) loss 1.3379 (1.4193) teacher_loss 0.2515 (0.3726) loss_zs_kd 6.1379 (6.2172) loss_oracle 1.0863 (1.0467) acc 90.6250 (84.6875) alaph_mean 0.9705 (0.9701) alpha_val 0.9705 (0.9701) lr 1.6374e-03 eta 0:16:46
epoch [16/50] batch [140/319] time 0.075 (0.090) data 0.000 (0.004) loss 1.2561 (1.4268) teacher_loss 0.2403 (0.3807) loss_zs_kd 6.0307 (6.2168) loss_oracle 1.0158 (1.0462) acc 90.6250 (84.3750) alaph_mean 0.9706 (0.9701) alpha_val 0.9706 (0.9701) lr 1.6374e-03 eta 0:16:27
epoch [16/50] batch [160/319] time 0.083 (0.088) data 0.000 (0.003) loss 1.2990 (1.4273) teacher_loss 0.2373 (0.3814) loss_zs_kd 6.1648 (6.2181) loss_oracle 1.0617 (1.0459) acc 93.7500 (84.3164) alaph_mean 0.9708 (0.9702) alpha_val 0.9708 (0.9702) lr 1.6374e-03 eta 0:16:13
epoch [16/50] batch [180/319] time 0.088 (0.088) data 0.000 (0.003) loss 1.3390 (1.4224) teacher_loss 0.2867 (0.3781) loss_zs_kd 6.3621 (6.2291) loss_oracle 1.0522 (1.0444) acc 90.6250 (84.6701) alaph_mean 0.9709 (0.9703) alpha_val 0.9709 (0.9703) lr 1.6374e-03 eta 0:16:07
epoch [16/50] batch [200/319] time 0.071 (0.087) data 0.000 (0.003) loss 1.4269 (1.4197) teacher_loss 0.3882 (0.3762) loss_zs_kd 5.8318 (6.2354) loss_oracle 1.0387 (1.0435) acc 87.5000 (84.7188) alaph_mean 0.9710 (0.9703) alpha_val 0.9710 (0.9703) lr 1.6374e-03 eta 0:15:52
epoch [16/50] batch [220/319] time 0.072 (0.086) data 0.000 (0.002) loss 1.3769 (1.4197) teacher_loss 0.3286 (0.3757) loss_zs_kd 5.9675 (6.2493) loss_oracle 1.0483 (1.0441) acc 81.2500 (84.8011) alaph_mean 0.9712 (0.9704) alpha_val 0.9712 (0.9704) lr 1.6374e-03 eta 0:15:40
epoch [16/50] batch [240/319] time 0.085 (0.086) data 0.000 (0.002) loss 1.3434 (1.4225) teacher_loss 0.2769 (0.3774) loss_zs_kd 6.6998 (6.2625) loss_oracle 1.0665 (1.0451) acc 87.5000 (84.7135) alaph_mean 0.9713 (0.9705) alpha_val 0.9713 (0.9705) lr 1.6374e-03 eta 0:15:36
epoch [16/50] batch [260/319] time 0.075 (0.085) data 0.001 (0.002) loss 1.3822 (1.4223) teacher_loss 0.3332 (0.3771) loss_zs_kd 6.4614 (6.2528) loss_oracle 1.0490 (1.0453) acc 84.3750 (84.7957) alaph_mean 0.9714 (0.9705) alpha_val 0.9714 (0.9705) lr 1.6374e-03 eta 0:15:23
epoch [16/50] batch [280/319] time 0.077 (0.084) data 0.000 (0.002) loss 1.4896 (1.4221) teacher_loss 0.4685 (0.3768) loss_zs_kd 5.7541 (6.2406) loss_oracle 1.0211 (1.0452) acc 81.2500 (84.8103) alaph_mean 0.9715 (0.9706) alpha_val 0.9715 (0.9706) lr 1.6374e-03 eta 0:15:17
epoch [16/50] batch [300/319] time 0.087 (0.084) data 0.000 (0.002) loss 1.5124 (1.4224) teacher_loss 0.4299 (0.3771) loss_zs_kd 5.9721 (6.2299) loss_oracle 1.0824 (1.0453) acc 84.3750 (84.7396) alaph_mean 0.9717 (0.9707) alpha_val 0.9717 (0.9707) lr 1.6374e-03 eta 0:15:13
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 978
* accuracy: 22.3%
* error: 77.7%
* macro_f1: 22.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 488
* accuracy: 5.0%
* error: 95.0%
* macro_f1: 7.9%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [17/50] batch [20/319] time 0.062 (0.094) data 0.000 (0.026) loss 1.3675 (1.4065) teacher_loss 0.2963 (0.3651) loss_zs_kd 6.2346 (6.5274) loss_oracle 1.0712 (1.0414) acc 93.7500 (87.0312) alaph_mean 0.9719 (0.9718) alpha_val 0.9719 (0.9718) lr 1.5878e-03 eta 0:17:00
epoch [17/50] batch [40/319] time 0.080 (0.084) data 0.000 (0.013) loss 1.4013 (1.4137) teacher_loss 0.3205 (0.3692) loss_zs_kd 6.8936 (6.3538) loss_oracle 1.0808 (1.0445) acc 84.3750 (86.2500) alaph_mean 0.9720 (0.9719) alpha_val 0.9720 (0.9719) lr 1.5878e-03 eta 0:15:02
epoch [17/50] batch [60/319] time 0.071 (0.081) data 0.001 (0.009) loss 1.4395 (1.4110) teacher_loss 0.3956 (0.3712) loss_zs_kd 5.6905 (6.2224) loss_oracle 1.0439 (1.0398) acc 87.5000 (85.9375) alaph_mean 0.9721 (0.9720) alpha_val 0.9721 (0.9720) lr 1.5878e-03 eta 0:14:36
epoch [17/50] batch [80/319] time 0.075 (0.080) data 0.000 (0.007) loss 1.2035 (1.4051) teacher_loss 0.2535 (0.3639) loss_zs_kd 6.4257 (6.2133) loss_oracle 0.9499 (1.0411) acc 93.7500 (86.2109) alaph_mean 0.9722 (0.9720) alpha_val 0.9722 (0.9720) lr 1.5878e-03 eta 0:14:20
epoch [17/50] batch [100/319] time 0.072 (0.080) data 0.000 (0.005) loss 1.2791 (1.4098) teacher_loss 0.2480 (0.3665) loss_zs_kd 6.4769 (6.2491) loss_oracle 1.0311 (1.0433) acc 90.6250 (85.9062) alaph_mean 0.9723 (0.9721) alpha_val 0.9723 (0.9721) lr 1.5878e-03 eta 0:14:22
epoch [17/50] batch [120/319] time 0.079 (0.080) data 0.000 (0.005) loss 1.3553 (1.4128) teacher_loss 0.2515 (0.3703) loss_zs_kd 6.8860 (6.2707) loss_oracle 1.1038 (1.0426) acc 87.5000 (85.6771) alaph_mean 0.9724 (0.9721) alpha_val 0.9724 (0.9721) lr 1.5878e-03 eta 0:14:22
epoch [17/50] batch [140/319] time 0.086 (0.081) data 0.000 (0.004) loss 1.5290 (1.4136) teacher_loss 0.4867 (0.3699) loss_zs_kd 6.6167 (6.2951) loss_oracle 1.0423 (1.0437) acc 81.2500 (85.5804) alaph_mean 0.9725 (0.9722) alpha_val 0.9725 (0.9722) lr 1.5878e-03 eta 0:14:25
epoch [17/50] batch [160/319] time 0.086 (0.082) data 0.000 (0.003) loss 1.1686 (1.4131) teacher_loss 0.0922 (0.3701) loss_zs_kd 5.5460 (6.2474) loss_oracle 1.0764 (1.0430) acc 100.0000 (85.4297) alaph_mean 0.9727 (0.9722) alpha_val 0.9727 (0.9722) lr 1.5878e-03 eta 0:14:32
epoch [17/50] batch [180/319] time 0.091 (0.082) data 0.000 (0.003) loss 1.3863 (1.4129) teacher_loss 0.3286 (0.3693) loss_zs_kd 6.1720 (6.2447) loss_oracle 1.0577 (1.0436) acc 93.7500 (85.4861) alaph_mean 0.9727 (0.9723) alpha_val 0.9727 (0.9723) lr 1.5878e-03 eta 0:14:33
epoch [17/50] batch [200/319] time 0.080 (0.082) data 0.000 (0.003) loss 1.2343 (1.4133) teacher_loss 0.2182 (0.3690) loss_zs_kd 6.6022 (6.2617) loss_oracle 1.0161 (1.0443) acc 93.7500 (85.4531) alaph_mean 0.9728 (0.9723) alpha_val 0.9728 (0.9723) lr 1.5878e-03 eta 0:14:37
epoch [17/50] batch [220/319] time 0.089 (0.083) data 0.000 (0.003) loss 1.4159 (1.4171) teacher_loss 0.3222 (0.3716) loss_zs_kd 5.9554 (6.2632) loss_oracle 1.0937 (1.0455) acc 90.6250 (85.3977) alaph_mean 0.9729 (0.9724) alpha_val 0.9729 (0.9724) lr 1.5878e-03 eta 0:14:39
epoch [17/50] batch [240/319] time 0.080 (0.084) data 0.000 (0.002) loss 1.5280 (1.4190) teacher_loss 0.4675 (0.3731) loss_zs_kd 6.0434 (6.2549) loss_oracle 1.0605 (1.0459) acc 78.1250 (85.3255) alaph_mean 0.9730 (0.9724) alpha_val 0.9730 (0.9724) lr 1.5878e-03 eta 0:14:52
epoch [17/50] batch [260/319] time 0.083 (0.084) data 0.000 (0.002) loss 1.4764 (1.4193) teacher_loss 0.3965 (0.3726) loss_zs_kd 7.3907 (6.2783) loss_oracle 1.0799 (1.0467) acc 84.3750 (85.3005) alaph_mean 0.9731 (0.9725) alpha_val 0.9731 (0.9725) lr 1.5878e-03 eta 0:14:51
epoch [17/50] batch [280/319] time 0.082 (0.084) data 0.000 (0.002) loss 1.2297 (1.4166) teacher_loss 0.1724 (0.3708) loss_zs_kd 7.7092 (6.3576) loss_oracle 1.0574 (1.0458) acc 96.8750 (85.3460) alaph_mean 0.9732 (0.9725) alpha_val 0.9732 (0.9725) lr 1.5878e-03 eta 0:14:48
epoch [17/50] batch [300/319] time 0.084 (0.084) data 0.000 (0.002) loss 1.5344 (1.4178) teacher_loss 0.4473 (0.3715) loss_zs_kd 7.2458 (6.4157) loss_oracle 1.0871 (1.0463) acc 75.0000 (85.2812) alaph_mean 0.9733 (0.9726) alpha_val 0.9733 (0.9726) lr 1.5878e-03 eta 0:14:46
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 965
* accuracy: 22.0%
* error: 78.0%
* macro_f1: 22.9%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 820
* accuracy: 8.4%
* error: 91.6%
* macro_f1: 10.3%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [18/50] batch [20/319] time 0.083 (0.118) data 0.000 (0.025) loss 1.3000 (1.3925) teacher_loss 0.3133 (0.3609) loss_zs_kd 6.1711 (6.7950) loss_oracle 0.9867 (1.0316) acc 90.6250 (87.0312) alaph_mean 0.9735 (0.9734) alpha_val 0.9735 (0.9734) lr 1.5358e-03 eta 0:20:42
epoch [18/50] batch [40/319] time 0.074 (0.100) data 0.000 (0.013) loss 1.4297 (1.4091) teacher_loss 0.3636 (0.3722) loss_zs_kd 6.7997 (6.9347) loss_oracle 1.0661 (1.0369) acc 81.2500 (85.7812) alaph_mean 0.9736 (0.9735) alpha_val 0.9736 (0.9735) lr 1.5358e-03 eta 0:17:26
epoch [18/50] batch [60/319] time 0.074 (0.093) data 0.001 (0.009) loss 1.4756 (1.4014) teacher_loss 0.4086 (0.3562) loss_zs_kd 7.2406 (7.0200) loss_oracle 1.0671 (1.0453) acc 81.2500 (86.8229) alaph_mean 0.9737 (0.9735) alpha_val 0.9737 (0.9735) lr 1.5358e-03 eta 0:16:09
epoch [18/50] batch [80/319] time 0.084 (0.090) data 0.000 (0.006) loss 1.3735 (1.4100) teacher_loss 0.2973 (0.3641) loss_zs_kd 6.8436 (7.0343) loss_oracle 1.0763 (1.0459) acc 90.6250 (86.3281) alaph_mean 0.9738 (0.9736) alpha_val 0.9738 (0.9736) lr 1.5358e-03 eta 0:15:40
epoch [18/50] batch [100/319] time 0.073 (0.088) data 0.000 (0.005) loss 1.2413 (1.4093) teacher_loss 0.2721 (0.3637) loss_zs_kd 7.5155 (7.0353) loss_oracle 0.9692 (1.0456) acc 87.5000 (86.1250) alaph_mean 0.9739 (0.9736) alpha_val 0.9739 (0.9736) lr 1.5358e-03 eta 0:15:16
epoch [18/50] batch [120/319] time 0.083 (0.087) data 0.000 (0.004) loss 1.3664 (1.4129) teacher_loss 0.2791 (0.3671) loss_zs_kd 7.0363 (7.0189) loss_oracle 1.0873 (1.0458) acc 87.5000 (85.9115) alaph_mean 0.9739 (0.9737) alpha_val 0.9739 (0.9737) lr 1.5358e-03 eta 0:15:02
epoch [18/50] batch [140/319] time 0.069 (0.086) data 0.000 (0.004) loss 1.3217 (1.4123) teacher_loss 0.3130 (0.3677) loss_zs_kd 6.9889 (6.9615) loss_oracle 1.0087 (1.0446) acc 90.6250 (85.9821) alaph_mean 0.9740 (0.9737) alpha_val 0.9740 (0.9737) lr 1.5358e-03 eta 0:14:52
epoch [18/50] batch [160/319] time 0.078 (0.085) data 0.000 (0.003) loss 1.4828 (1.4167) teacher_loss 0.4182 (0.3727) loss_zs_kd 6.7877 (6.8851) loss_oracle 1.0647 (1.0440) acc 84.3750 (85.6641) alaph_mean 0.9741 (0.9738) alpha_val 0.9741 (0.9738) lr 1.5358e-03 eta 0:14:40
epoch [18/50] batch [180/319] time 0.078 (0.084) data 0.000 (0.003) loss 1.5450 (1.4150) teacher_loss 0.5120 (0.3709) loss_zs_kd 6.5069 (6.8368) loss_oracle 1.0330 (1.0441) acc 75.0000 (85.6424) alaph_mean 0.9742 (0.9738) alpha_val 0.9742 (0.9738) lr 1.5358e-03 eta 0:14:29
epoch [18/50] batch [200/319] time 0.085 (0.084) data 0.000 (0.003) loss 1.5181 (1.4172) teacher_loss 0.4273 (0.3730) loss_zs_kd 6.7716 (6.8103) loss_oracle 1.0909 (1.0442) acc 84.3750 (85.6094) alaph_mean 0.9743 (0.9739) alpha_val 0.9743 (0.9739) lr 1.5358e-03 eta 0:14:24
epoch [18/50] batch [220/319] time 0.086 (0.084) data 0.000 (0.003) loss 1.5192 (1.4199) teacher_loss 0.4915 (0.3741) loss_zs_kd 6.4590 (6.7817) loss_oracle 1.0277 (1.0458) acc 78.1250 (85.4972) alaph_mean 0.9744 (0.9739) alpha_val 0.9744 (0.9739) lr 1.5358e-03 eta 0:14:23
epoch [18/50] batch [240/319] time 0.079 (0.084) data 0.000 (0.002) loss 1.5063 (1.4204) teacher_loss 0.4463 (0.3742) loss_zs_kd 6.4448 (6.7655) loss_oracle 1.0600 (1.0462) acc 84.3750 (85.4688) alaph_mean 0.9745 (0.9739) alpha_val 0.9745 (0.9739) lr 1.5358e-03 eta 0:14:18
epoch [18/50] batch [260/319] time 0.093 (0.083) data 0.000 (0.002) loss 1.5677 (1.4186) teacher_loss 0.5235 (0.3719) loss_zs_kd 6.8167 (6.7550) loss_oracle 1.0442 (1.0468) acc 78.1250 (85.6611) alaph_mean 0.9746 (0.9740) alpha_val 0.9746 (0.9740) lr 1.5358e-03 eta 0:14:14
epoch [18/50] batch [280/319] time 0.087 (0.083) data 0.000 (0.002) loss 1.4507 (1.4197) teacher_loss 0.3946 (0.3727) loss_zs_kd 6.5005 (6.7377) loss_oracle 1.0561 (1.0470) acc 90.6250 (85.6808) alaph_mean 0.9746 (0.9740) alpha_val 0.9746 (0.9740) lr 1.5358e-03 eta 0:14:11
epoch [18/50] batch [300/319] time 0.087 (0.083) data 0.000 (0.002) loss 1.1900 (1.4186) teacher_loss 0.1577 (0.3711) loss_zs_kd 6.1319 (6.7213) loss_oracle 1.0323 (1.0475) acc 96.8750 (85.7812) alaph_mean 0.9747 (0.9741) alpha_val 0.9747 (0.9741) lr 1.5358e-03 eta 0:14:09
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,156
* accuracy: 26.4%
* error: 73.6%
* macro_f1: 25.9%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,307
* accuracy: 13.4%
* error: 86.6%
* macro_f1: 12.6%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [19/50] batch [20/319] time 0.081 (0.109) data 0.000 (0.027) loss 1.3883 (1.3945) teacher_loss 0.3987 (0.3399) loss_zs_kd 5.9088 (6.3815) loss_oracle 0.9896 (1.0546) acc 81.2500 (86.0938) alaph_mean 0.9749 (0.9749) alpha_val 0.9749 (0.9749) lr 1.4818e-03 eta 0:18:31
epoch [19/50] batch [40/319] time 0.079 (0.096) data 0.000 (0.014) loss 1.4802 (1.4124) teacher_loss 0.3996 (0.3622) loss_zs_kd 6.6455 (6.4324) loss_oracle 1.0806 (1.0502) acc 84.3750 (86.0156) alaph_mean 0.9750 (0.9749) alpha_val 0.9750 (0.9749) lr 1.4818e-03 eta 0:16:13
epoch [19/50] batch [60/319] time 0.078 (0.092) data 0.001 (0.009) loss 1.5237 (1.4074) teacher_loss 0.4907 (0.3582) loss_zs_kd 6.4808 (6.4794) loss_oracle 1.0331 (1.0492) acc 81.2500 (86.0417) alaph_mean 0.9751 (0.9750) alpha_val 0.9751 (0.9750) lr 1.4818e-03 eta 0:15:31
epoch [19/50] batch [80/319] time 0.080 (0.090) data 0.000 (0.007) loss 1.4906 (1.4061) teacher_loss 0.4840 (0.3583) loss_zs_kd 6.3884 (6.5033) loss_oracle 1.0065 (1.0478) acc 78.1250 (86.0156) alaph_mean 0.9752 (0.9750) alpha_val 0.9752 (0.9750) lr 1.4818e-03 eta 0:15:10
epoch [19/50] batch [100/319] time 0.077 (0.088) data 0.000 (0.006) loss 1.3435 (1.4111) teacher_loss 0.2920 (0.3610) loss_zs_kd 6.8613 (6.5617) loss_oracle 1.0515 (1.0501) acc 90.6250 (85.8125) alaph_mean 0.9752 (0.9750) alpha_val 0.9752 (0.9750) lr 1.4818e-03 eta 0:14:51
epoch [19/50] batch [120/319] time 0.086 (0.088) data 0.000 (0.005) loss 1.5210 (1.4092) teacher_loss 0.4448 (0.3597) loss_zs_kd 6.3916 (6.5813) loss_oracle 1.0762 (1.0495) acc 90.6250 (86.0156) alaph_mean 0.9753 (0.9751) alpha_val 0.9753 (0.9751) lr 1.4818e-03 eta 0:14:49
epoch [19/50] batch [140/319] time 0.080 (0.087) data 0.000 (0.004) loss 1.3685 (1.4123) teacher_loss 0.2774 (0.3624) loss_zs_kd 7.1257 (6.5869) loss_oracle 1.0910 (1.0499) acc 90.6250 (85.9152) alaph_mean 0.9754 (0.9751) alpha_val 0.9754 (0.9751) lr 1.4818e-03 eta 0:14:38
epoch [19/50] batch [160/319] time 0.079 (0.087) data 0.000 (0.004) loss 1.3934 (1.4090) teacher_loss 0.3004 (0.3595) loss_zs_kd 6.6697 (6.5849) loss_oracle 1.0930 (1.0495) acc 93.7500 (85.9766) alaph_mean 0.9755 (0.9752) alpha_val 0.9755 (0.9752) lr 1.4818e-03 eta 0:14:30
epoch [19/50] batch [180/319] time 0.081 (0.086) data 0.000 (0.003) loss 1.2980 (1.4059) teacher_loss 0.3449 (0.3562) loss_zs_kd 6.2063 (6.5798) loss_oracle 0.9531 (1.0498) acc 90.6250 (86.3021) alaph_mean 0.9756 (0.9752) alpha_val 0.9756 (0.9752) lr 1.4818e-03 eta 0:14:20
epoch [19/50] batch [200/319] time 0.082 (0.087) data 0.000 (0.003) loss 1.3508 (1.4053) teacher_loss 0.2289 (0.3545) loss_zs_kd 6.2206 (6.5546) loss_oracle 1.1220 (1.0507) acc 90.6250 (86.3125) alaph_mean 0.9756 (0.9752) alpha_val 0.9756 (0.9752) lr 1.4818e-03 eta 0:14:32
epoch [19/50] batch [220/319] time 0.073 (0.087) data 0.000 (0.003) loss 1.5711 (1.4042) teacher_loss 0.5108 (0.3527) loss_zs_kd 6.9201 (6.5446) loss_oracle 1.0603 (1.0515) acc 84.3750 (86.4915) alaph_mean 0.9757 (0.9753) alpha_val 0.9757 (0.9753) lr 1.4818e-03 eta 0:14:24
epoch [19/50] batch [240/319] time 0.088 (0.086) data 0.000 (0.003) loss 1.5869 (1.4038) teacher_loss 0.5167 (0.3526) loss_zs_kd 5.5605 (6.5337) loss_oracle 1.0702 (1.0513) acc 75.0000 (86.4062) alaph_mean 0.9758 (0.9753) alpha_val 0.9758 (0.9753) lr 1.4818e-03 eta 0:14:20
epoch [19/50] batch [260/319] time 0.068 (0.086) data 0.000 (0.002) loss 1.8008 (1.4093) teacher_loss 0.6490 (0.3574) loss_zs_kd 6.5146 (6.5412) loss_oracle 1.1517 (1.0520) acc 75.0000 (86.2380) alaph_mean 0.9759 (0.9754) alpha_val 0.9759 (0.9754) lr 1.4818e-03 eta 0:14:14
epoch [19/50] batch [280/319] time 0.082 (0.085) data 0.000 (0.002) loss 1.4275 (1.4069) teacher_loss 0.3774 (0.3557) loss_zs_kd 6.1789 (6.5285) loss_oracle 1.0501 (1.0513) acc 81.2500 (86.2277) alaph_mean 0.9760 (0.9754) alpha_val 0.9760 (0.9754) lr 1.4818e-03 eta 0:14:07
epoch [19/50] batch [300/319] time 0.073 (0.085) data 0.000 (0.002) loss 1.5151 (1.4081) teacher_loss 0.4950 (0.3566) loss_zs_kd 6.1009 (6.4939) loss_oracle 1.0201 (1.0515) acc 81.2500 (86.1979) alaph_mean 0.9760 (0.9754) alpha_val 0.9760 (0.9754) lr 1.4818e-03 eta 0:14:03
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,281
* accuracy: 29.3%
* error: 70.7%
* macro_f1: 26.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,046
* accuracy: 10.7%
* error: 89.3%
* macro_f1: 10.8%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [20/50] batch [20/319] time 0.076 (0.121) data 0.000 (0.032) loss 1.3286 (1.3947) teacher_loss 0.3080 (0.3468) loss_zs_kd 6.1663 (6.4425) loss_oracle 1.0206 (1.0479) acc 87.5000 (86.7188) alaph_mean 0.9762 (0.9761) alpha_val 0.9762 (0.9761) lr 1.4258e-03 eta 0:19:54
epoch [20/50] batch [40/319] time 0.082 (0.103) data 0.000 (0.016) loss 1.3767 (1.4006) teacher_loss 0.3319 (0.3508) loss_zs_kd 6.9285 (6.4832) loss_oracle 1.0448 (1.0499) acc 87.5000 (86.3281) alaph_mean 0.9762 (0.9762) alpha_val 0.9762 (0.9762) lr 1.4258e-03 eta 0:16:56
epoch [20/50] batch [60/319] time 0.087 (0.096) data 0.001 (0.011) loss 1.2210 (1.4273) teacher_loss 0.1870 (0.3735) loss_zs_kd 6.7264 (6.5773) loss_oracle 1.0340 (1.0538) acc 93.7500 (85.3125) alaph_mean 0.9763 (0.9762) alpha_val 0.9763 (0.9762) lr 1.4258e-03 eta 0:15:45
epoch [20/50] batch [80/319] time 0.074 (0.092) data 0.000 (0.008) loss 1.3960 (1.4208) teacher_loss 0.2968 (0.3667) loss_zs_kd 7.0788 (6.6636) loss_oracle 1.0992 (1.0542) acc 90.6250 (85.7031) alaph_mean 0.9763 (0.9762) alpha_val 0.9763 (0.9762) lr 1.4258e-03 eta 0:14:57
epoch [20/50] batch [100/319] time 0.085 (0.089) data 0.000 (0.007) loss 1.2912 (1.4167) teacher_loss 0.2460 (0.3629) loss_zs_kd 6.4552 (6.6976) loss_oracle 1.0452 (1.0538) acc 90.6250 (85.7188) alaph_mean 0.9764 (0.9762) alpha_val 0.9764 (0.9762) lr 1.4258e-03 eta 0:14:29
epoch [20/50] batch [120/319] time 0.081 (0.088) data 0.000 (0.006) loss 1.2711 (1.4080) teacher_loss 0.2241 (0.3543) loss_zs_kd 6.9139 (6.6557) loss_oracle 1.0470 (1.0538) acc 90.6250 (85.9115) alaph_mean 0.9765 (0.9763) alpha_val 0.9765 (0.9763) lr 1.4258e-03 eta 0:14:16
epoch [20/50] batch [140/319] time 0.083 (0.087) data 0.000 (0.005) loss 1.3294 (1.4079) teacher_loss 0.2905 (0.3528) loss_zs_kd 5.9406 (6.6115) loss_oracle 1.0389 (1.0551) acc 81.2500 (86.0045) alaph_mean 0.9765 (0.9763) alpha_val 0.9765 (0.9763) lr 1.4258e-03 eta 0:14:10
epoch [20/50] batch [160/319] time 0.082 (0.086) data 0.000 (0.004) loss 1.3113 (1.4088) teacher_loss 0.2850 (0.3539) loss_zs_kd 6.3640 (6.5622) loss_oracle 1.0264 (1.0549) acc 84.3750 (85.8789) alaph_mean 0.9766 (0.9763) alpha_val 0.9766 (0.9763) lr 1.4258e-03 eta 0:14:01
epoch [20/50] batch [180/319] time 0.081 (0.086) data 0.000 (0.004) loss 1.6105 (1.4153) teacher_loss 0.5102 (0.3601) loss_zs_kd 6.9598 (6.5425) loss_oracle 1.1004 (1.0552) acc 68.7500 (85.4167) alaph_mean 0.9767 (0.9764) alpha_val 0.9767 (0.9764) lr 1.4258e-03 eta 0:13:55
epoch [20/50] batch [200/319] time 0.079 (0.086) data 0.000 (0.003) loss 1.3305 (1.4133) teacher_loss 0.3104 (0.3578) loss_zs_kd 6.3215 (6.5290) loss_oracle 1.0201 (1.0555) acc 93.7500 (85.5000) alaph_mean 0.9768 (0.9764) alpha_val 0.9768 (0.9764) lr 1.4258e-03 eta 0:13:51
epoch [20/50] batch [220/319] time 0.077 (0.085) data 0.000 (0.003) loss 1.5009 (1.4145) teacher_loss 0.4319 (0.3586) loss_zs_kd 5.8901 (6.5117) loss_oracle 1.0689 (1.0560) acc 84.3750 (85.3551) alaph_mean 0.9769 (0.9765) alpha_val 0.9769 (0.9765) lr 1.4258e-03 eta 0:13:46
epoch [20/50] batch [240/319] time 0.079 (0.085) data 0.000 (0.003) loss 1.5043 (1.4187) teacher_loss 0.5187 (0.3623) loss_zs_kd 5.7025 (6.4834) loss_oracle 0.9856 (1.0564) acc 87.5000 (85.2995) alaph_mean 0.9769 (0.9765) alpha_val 0.9769 (0.9765) lr 1.4258e-03 eta 0:13:39
epoch [20/50] batch [260/319] time 0.074 (0.085) data 0.000 (0.003) loss 1.4164 (1.4149) teacher_loss 0.3557 (0.3599) loss_zs_kd 6.2033 (6.4579) loss_oracle 1.0607 (1.0550) acc 90.6250 (85.4688) alaph_mean 0.9770 (0.9765) alpha_val 0.9770 (0.9765) lr 1.4258e-03 eta 0:13:34
epoch [20/50] batch [280/319] time 0.078 (0.084) data 0.001 (0.003) loss 1.4999 (1.4144) teacher_loss 0.4151 (0.3594) loss_zs_kd 6.4851 (6.4565) loss_oracle 1.0848 (1.0550) acc 90.6250 (85.5692) alaph_mean 0.9771 (0.9766) alpha_val 0.9771 (0.9766) lr 1.4258e-03 eta 0:13:27
epoch [20/50] batch [300/319] time 0.086 (0.084) data 0.000 (0.002) loss 1.2433 (1.4145) teacher_loss 0.2120 (0.3610) loss_zs_kd 7.0132 (6.4480) loss_oracle 1.0314 (1.0535) acc 90.6250 (85.5208) alaph_mean 0.9772 (0.9766) alpha_val 0.9772 (0.9766) lr 1.4258e-03 eta 0:13:25
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,028
* accuracy: 23.5%
* error: 76.5%
* macro_f1: 22.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,168
* accuracy: 12.0%
* error: 88.0%
* macro_f1: 10.7%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [21/50] batch [20/319] time 0.078 (0.112) data 0.000 (0.029) loss 1.3487 (1.3932) teacher_loss 0.2585 (0.3361) loss_zs_kd 7.1603 (6.5110) loss_oracle 1.0902 (1.0571) acc 90.6250 (85.9375) alaph_mean 0.9773 (0.9773) alpha_val 0.9773 (0.9773) lr 1.3681e-03 eta 0:17:52
epoch [21/50] batch [40/319] time 0.080 (0.097) data 0.000 (0.015) loss 1.4311 (1.4010) teacher_loss 0.3859 (0.3468) loss_zs_kd 6.4103 (6.5505) loss_oracle 1.0452 (1.0543) acc 87.5000 (85.3125) alaph_mean 0.9774 (0.9773) alpha_val 0.9774 (0.9773) lr 1.3681e-03 eta 0:15:19
epoch [21/50] batch [60/319] time 0.077 (0.092) data 0.000 (0.010) loss 1.2670 (1.4060) teacher_loss 0.1511 (0.3484) loss_zs_kd 6.8349 (6.5587) loss_oracle 1.1159 (1.0575) acc 96.8750 (85.6250) alaph_mean 0.9775 (0.9774) alpha_val 0.9775 (0.9774) lr 1.3681e-03 eta 0:14:36
epoch [21/50] batch [80/319] time 0.089 (0.090) data 0.000 (0.008) loss 1.1640 (1.4009) teacher_loss 0.1512 (0.3441) loss_zs_kd 6.4062 (6.5899) loss_oracle 1.0128 (1.0568) acc 96.8750 (85.5859) alaph_mean 0.9775 (0.9774) alpha_val 0.9775 (0.9774) lr 1.3681e-03 eta 0:14:15
epoch [21/50] batch [100/319] time 0.080 (0.089) data 0.000 (0.006) loss 1.2795 (1.4057) teacher_loss 0.2226 (0.3498) loss_zs_kd 6.6974 (6.5994) loss_oracle 1.0569 (1.0559) acc 90.6250 (85.7188) alaph_mean 0.9776 (0.9774) alpha_val 0.9776 (0.9774) lr 1.3681e-03 eta 0:14:00
epoch [21/50] batch [120/319] time 0.076 (0.087) data 0.000 (0.005) loss 1.4464 (1.4047) teacher_loss 0.3515 (0.3483) loss_zs_kd 6.3014 (6.5824) loss_oracle 1.0948 (1.0564) acc 87.5000 (85.9896) alaph_mean 0.9776 (0.9775) alpha_val 0.9776 (0.9775) lr 1.3681e-03 eta 0:13:41
epoch [21/50] batch [140/319] time 0.083 (0.085) data 0.000 (0.004) loss 1.3466 (1.4004) teacher_loss 0.2799 (0.3445) loss_zs_kd 6.5353 (6.5993) loss_oracle 1.0667 (1.0559) acc 93.7500 (86.4062) alaph_mean 0.9777 (0.9775) alpha_val 0.9777 (0.9775) lr 1.3681e-03 eta 0:13:25
epoch [21/50] batch [160/319] time 0.083 (0.085) data 0.000 (0.004) loss 1.3057 (1.4024) teacher_loss 0.2835 (0.3479) loss_zs_kd 6.0479 (6.5957) loss_oracle 1.0222 (1.0545) acc 87.5000 (86.3477) alaph_mean 0.9778 (0.9775) alpha_val 0.9778 (0.9775) lr 1.3681e-03 eta 0:13:21
epoch [21/50] batch [180/319] time 0.116 (0.087) data 0.001 (0.004) loss 1.4688 (1.4016) teacher_loss 0.4235 (0.3485) loss_zs_kd 6.8602 (6.5785) loss_oracle 1.0453 (1.0530) acc 78.1250 (86.3715) alaph_mean 0.9778 (0.9776) alpha_val 0.9778 (0.9776) lr 1.3681e-03 eta 0:13:34
epoch [21/50] batch [200/319] time 0.083 (0.086) data 0.000 (0.003) loss 1.6751 (1.4019) teacher_loss 0.6080 (0.3496) loss_zs_kd 6.6393 (6.5635) loss_oracle 1.0671 (1.0523) acc 81.2500 (86.3594) alaph_mean 0.9779 (0.9776) alpha_val 0.9779 (0.9776) lr 1.3681e-03 eta 0:13:27
epoch [21/50] batch [220/319] time 0.084 (0.086) data 0.000 (0.003) loss 1.4917 (1.4018) teacher_loss 0.4477 (0.3496) loss_zs_kd 5.7353 (6.5419) loss_oracle 1.0439 (1.0522) acc 81.2500 (86.3920) alaph_mean 0.9780 (0.9776) alpha_val 0.9780 (0.9776) lr 1.3681e-03 eta 0:13:25
epoch [21/50] batch [240/319] time 0.083 (0.086) data 0.000 (0.003) loss 1.2804 (1.4027) teacher_loss 0.2312 (0.3507) loss_zs_kd 6.5397 (6.5426) loss_oracle 1.0491 (1.0521) acc 90.6250 (86.3021) alaph_mean 0.9780 (0.9776) alpha_val 0.9780 (0.9776) lr 1.3681e-03 eta 0:13:20
epoch [21/50] batch [260/319] time 0.083 (0.086) data 0.000 (0.003) loss 1.3720 (1.4107) teacher_loss 0.2746 (0.3575) loss_zs_kd 7.0439 (6.5290) loss_oracle 1.0974 (1.0532) acc 84.3750 (85.9375) alaph_mean 0.9781 (0.9777) alpha_val 0.9781 (0.9777) lr 1.3681e-03 eta 0:13:17
epoch [21/50] batch [280/319] time 0.085 (0.086) data 0.000 (0.002) loss 1.3948 (1.4118) teacher_loss 0.3567 (0.3587) loss_zs_kd 6.6344 (6.5220) loss_oracle 1.0381 (1.0531) acc 78.1250 (85.8147) alaph_mean 0.9781 (0.9777) alpha_val 0.9781 (0.9777) lr 1.3681e-03 eta 0:13:15
epoch [21/50] batch [300/319] time 0.085 (0.086) data 0.000 (0.002) loss 1.3373 (1.4089) teacher_loss 0.2844 (0.3562) loss_zs_kd 6.2732 (6.4980) loss_oracle 1.0530 (1.0526) acc 90.6250 (86.0729) alaph_mean 0.9782 (0.9777) alpha_val 0.9782 (0.9777) lr 1.3681e-03 eta 0:13:13
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,414
* accuracy: 32.3%
* error: 67.7%
* macro_f1: 28.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 795
* accuracy: 8.2%
* error: 91.8%
* macro_f1: 8.6%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [22/50] batch [20/319] time 0.080 (0.107) data 0.000 (0.024) loss 1.3627 (1.4159) teacher_loss 0.2553 (0.3671) loss_zs_kd 5.7693 (6.2262) loss_oracle 1.1074 (1.0488) acc 93.7500 (86.8750) alaph_mean 0.9783 (0.9783) alpha_val 0.9783 (0.9783) lr 1.3090e-03 eta 0:16:24
epoch [22/50] batch [40/319] time 0.092 (0.093) data 0.000 (0.012) loss 1.4010 (1.3936) teacher_loss 0.3083 (0.3392) loss_zs_kd 6.6927 (6.2209) loss_oracle 1.0927 (1.0544) acc 87.5000 (87.4219) alaph_mean 0.9784 (0.9783) alpha_val 0.9784 (0.9783) lr 1.3090e-03 eta 0:14:14
epoch [22/50] batch [60/319] time 0.082 (0.090) data 0.001 (0.008) loss 1.2972 (1.3947) teacher_loss 0.2469 (0.3425) loss_zs_kd 6.6310 (6.3362) loss_oracle 1.0503 (1.0521) acc 87.5000 (86.9792) alaph_mean 0.9784 (0.9783) alpha_val 0.9784 (0.9783) lr 1.3090e-03 eta 0:13:45
epoch [22/50] batch [80/319] time 0.085 (0.088) data 0.000 (0.006) loss 1.6837 (1.3942) teacher_loss 0.6277 (0.3414) loss_zs_kd 6.2869 (6.3634) loss_oracle 1.0559 (1.0528) acc 78.1250 (86.9531) alaph_mean 0.9785 (0.9784) alpha_val 0.9785 (0.9784) lr 1.3090e-03 eta 0:13:30
epoch [22/50] batch [100/319] time 0.083 (0.088) data 0.000 (0.005) loss 1.2897 (1.3956) teacher_loss 0.1830 (0.3402) loss_zs_kd 6.5104 (6.3976) loss_oracle 1.1067 (1.0554) acc 90.6250 (86.6250) alaph_mean 0.9785 (0.9784) alpha_val 0.9785 (0.9784) lr 1.3090e-03 eta 0:13:22
epoch [22/50] batch [120/319] time 0.080 (0.086) data 0.000 (0.004) loss 1.4298 (1.3919) teacher_loss 0.3972 (0.3353) loss_zs_kd 6.4428 (6.4427) loss_oracle 1.0326 (1.0566) acc 87.5000 (87.1354) alaph_mean 0.9786 (0.9784) alpha_val 0.9786 (0.9784) lr 1.3090e-03 eta 0:13:09
epoch [22/50] batch [140/319] time 0.082 (0.085) data 0.000 (0.004) loss 1.6005 (1.3993) teacher_loss 0.5149 (0.3413) loss_zs_kd 6.5076 (6.4762) loss_oracle 1.0856 (1.0580) acc 78.1250 (86.7857) alaph_mean 0.9786 (0.9785) alpha_val 0.9786 (0.9785) lr 1.3090e-03 eta 0:12:57
epoch [22/50] batch [160/319] time 0.087 (0.085) data 0.000 (0.003) loss 1.3872 (1.3991) teacher_loss 0.2978 (0.3420) loss_zs_kd 6.1178 (6.4796) loss_oracle 1.0894 (1.0571) acc 90.6250 (86.8945) alaph_mean 0.9787 (0.9785) alpha_val 0.9787 (0.9785) lr 1.3090e-03 eta 0:12:54
epoch [22/50] batch [180/319] time 0.076 (0.085) data 0.000 (0.003) loss 1.4814 (1.3982) teacher_loss 0.4926 (0.3405) loss_zs_kd 6.3546 (6.4806) loss_oracle 0.9889 (1.0577) acc 84.3750 (86.8403) alaph_mean 0.9787 (0.9785) alpha_val 0.9787 (0.9785) lr 1.3090e-03 eta 0:12:50
epoch [22/50] batch [200/319] time 0.085 (0.085) data 0.000 (0.003) loss 1.5291 (1.4003) teacher_loss 0.4495 (0.3431) loss_zs_kd 6.3381 (6.4846) loss_oracle 1.0796 (1.0572) acc 87.5000 (86.7656) alaph_mean 0.9788 (0.9785) alpha_val 0.9788 (0.9785) lr 1.3090e-03 eta 0:12:47
epoch [22/50] batch [220/319] time 0.080 (0.085) data 0.000 (0.002) loss 1.3847 (1.4006) teacher_loss 0.3346 (0.3440) loss_zs_kd 6.1290 (6.4793) loss_oracle 1.0501 (1.0566) acc 87.5000 (86.6619) alaph_mean 0.9788 (0.9786) alpha_val 0.9788 (0.9786) lr 1.3090e-03 eta 0:12:45
epoch [22/50] batch [240/319] time 0.080 (0.085) data 0.000 (0.002) loss 1.4316 (1.3977) teacher_loss 0.3601 (0.3418) loss_zs_kd 6.4513 (6.4626) loss_oracle 1.0715 (1.0560) acc 87.5000 (86.7969) alaph_mean 0.9789 (0.9786) alpha_val 0.9789 (0.9786) lr 1.3090e-03 eta 0:12:43
epoch [22/50] batch [260/319] time 0.082 (0.085) data 0.000 (0.002) loss 1.2932 (1.4018) teacher_loss 0.2607 (0.3454) loss_zs_kd 5.5614 (6.4572) loss_oracle 1.0325 (1.0564) acc 90.6250 (86.7548) alaph_mean 0.9790 (0.9786) alpha_val 0.9790 (0.9786) lr 1.3090e-03 eta 0:12:40
epoch [22/50] batch [280/319] time 0.098 (0.085) data 0.000 (0.002) loss 1.1678 (1.3986) teacher_loss 0.0777 (0.3430) loss_zs_kd 5.8999 (6.4341) loss_oracle 1.0900 (1.0556) acc 96.8750 (86.8973) alaph_mean 0.9790 (0.9786) alpha_val 0.9790 (0.9786) lr 1.3090e-03 eta 0:12:38
epoch [22/50] batch [300/319] time 0.085 (0.084) data 0.000 (0.002) loss 1.4327 (1.4009) teacher_loss 0.3362 (0.3456) loss_zs_kd 6.5017 (6.4132) loss_oracle 1.0965 (1.0553) acc 84.3750 (86.7708) alaph_mean 0.9791 (0.9787) alpha_val 0.9791 (0.9787) lr 1.3090e-03 eta 0:12:35
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,462
* accuracy: 33.4%
* error: 66.6%
* macro_f1: 28.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,433
* accuracy: 14.7%
* error: 85.3%
* macro_f1: 11.6%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [23/50] batch [20/319] time 0.077 (0.116) data 0.000 (0.031) loss 1.4958 (1.3888) teacher_loss 0.4718 (0.3426) loss_zs_kd 5.7686 (6.3648) loss_oracle 1.0240 (1.0462) acc 87.5000 (87.5000) alaph_mean 0.9792 (0.9792) alpha_val 0.9792 (0.9792) lr 1.2487e-03 eta 0:17:12
epoch [23/50] batch [40/319] time 0.084 (0.099) data 0.000 (0.016) loss 1.3115 (1.3919) teacher_loss 0.3000 (0.3476) loss_zs_kd 6.1090 (6.2577) loss_oracle 1.0115 (1.0443) acc 90.6250 (86.2500) alaph_mean 0.9793 (0.9792) alpha_val 0.9793 (0.9792) lr 1.2487e-03 eta 0:14:38
epoch [23/50] batch [60/319] time 0.080 (0.093) data 0.000 (0.011) loss 1.4978 (1.3704) teacher_loss 0.4258 (0.3237) loss_zs_kd 5.6357 (6.2681) loss_oracle 1.0721 (1.0467) acc 75.0000 (87.2917) alaph_mean 0.9794 (0.9793) alpha_val 0.9794 (0.9793) lr 1.2487e-03 eta 0:13:48
epoch [23/50] batch [80/319] time 0.080 (0.091) data 0.000 (0.008) loss 1.2653 (1.3770) teacher_loss 0.1782 (0.3293) loss_zs_kd 6.5534 (6.3544) loss_oracle 1.0871 (1.0477) acc 90.6250 (86.8359) alaph_mean 0.9794 (0.9793) alpha_val 0.9794 (0.9793) lr 1.2487e-03 eta 0:13:23
epoch [23/50] batch [100/319] time 0.073 (0.089) data 0.000 (0.006) loss 1.2378 (1.3807) teacher_loss 0.2255 (0.3320) loss_zs_kd 6.1290 (6.3306) loss_oracle 1.0123 (1.0487) acc 93.7500 (87.0312) alaph_mean 0.9795 (0.9793) alpha_val 0.9795 (0.9793) lr 1.2487e-03 eta 0:13:03
epoch [23/50] batch [120/319] time 0.089 (0.088) data 0.000 (0.005) loss 1.3471 (1.3833) teacher_loss 0.3141 (0.3351) loss_zs_kd 5.6360 (6.3018) loss_oracle 1.0330 (1.0482) acc 90.6250 (86.8750) alaph_mean 0.9795 (0.9794) alpha_val 0.9795 (0.9794) lr 1.2487e-03 eta 0:12:55
epoch [23/50] batch [140/319] time 0.079 (0.087) data 0.000 (0.005) loss 1.3399 (1.3839) teacher_loss 0.2269 (0.3346) loss_zs_kd 6.4503 (6.2658) loss_oracle 1.1131 (1.0493) acc 87.5000 (87.0312) alaph_mean 0.9796 (0.9794) alpha_val 0.9796 (0.9794) lr 1.2487e-03 eta 0:12:48
epoch [23/50] batch [160/319] time 0.094 (0.089) data 0.000 (0.004) loss 1.3807 (1.3882) teacher_loss 0.2725 (0.3359) loss_zs_kd 5.8769 (6.2474) loss_oracle 1.1082 (1.0523) acc 90.6250 (87.1094) alaph_mean 0.9796 (0.9794) alpha_val 0.9796 (0.9794) lr 1.2487e-03 eta 0:13:02
epoch [23/50] batch [180/319] time 0.083 (0.089) data 0.000 (0.004) loss 1.3669 (1.3911) teacher_loss 0.3349 (0.3371) loss_zs_kd 6.3892 (6.2431) loss_oracle 1.0320 (1.0539) acc 87.5000 (87.0486) alaph_mean 0.9797 (0.9794) alpha_val 0.9797 (0.9794) lr 1.2487e-03 eta 0:12:54
epoch [23/50] batch [200/319] time 0.086 (0.088) data 0.000 (0.003) loss 1.2322 (1.3955) teacher_loss 0.1922 (0.3414) loss_zs_kd 5.8644 (6.2418) loss_oracle 1.0401 (1.0542) acc 93.7500 (86.7500) alaph_mean 0.9797 (0.9795) alpha_val 0.9797 (0.9795) lr 1.2487e-03 eta 0:12:48
epoch [23/50] batch [220/319] time 0.089 (0.088) data 0.001 (0.003) loss 1.5706 (1.3958) teacher_loss 0.5251 (0.3414) loss_zs_kd 6.3046 (6.2306) loss_oracle 1.0455 (1.0544) acc 93.7500 (86.8040) alaph_mean 0.9798 (0.9795) alpha_val 0.9798 (0.9795) lr 1.2487e-03 eta 0:12:44
epoch [23/50] batch [240/319] time 0.084 (0.087) data 0.000 (0.003) loss 1.2864 (1.3999) teacher_loss 0.2047 (0.3447) loss_zs_kd 6.0681 (6.2187) loss_oracle 1.0818 (1.0552) acc 96.8750 (86.7188) alaph_mean 0.9798 (0.9795) alpha_val 0.9798 (0.9795) lr 1.2487e-03 eta 0:12:36
epoch [23/50] batch [260/319] time 0.089 (0.087) data 0.000 (0.003) loss 1.4827 (1.3987) teacher_loss 0.3877 (0.3439) loss_zs_kd 6.3784 (6.2142) loss_oracle 1.0951 (1.0548) acc 78.1250 (86.6827) alaph_mean 0.9799 (0.9795) alpha_val 0.9799 (0.9795) lr 1.2487e-03 eta 0:12:32
epoch [23/50] batch [280/319] time 0.080 (0.087) data 0.000 (0.002) loss 1.2486 (1.3983) teacher_loss 0.2135 (0.3432) loss_zs_kd 6.4058 (6.2351) loss_oracle 1.0351 (1.0551) acc 90.6250 (86.7076) alaph_mean 0.9799 (0.9796) alpha_val 0.9799 (0.9796) lr 1.2487e-03 eta 0:12:30
epoch [23/50] batch [300/319] time 0.082 (0.087) data 0.000 (0.002) loss 1.4682 (1.3984) teacher_loss 0.3762 (0.3423) loss_zs_kd 6.3488 (6.2493) loss_oracle 1.0921 (1.0561) acc 84.3750 (86.6979) alaph_mean 0.9799 (0.9796) alpha_val 0.9799 (0.9796) lr 1.2487e-03 eta 0:12:27
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,331
* accuracy: 30.4%
* error: 69.6%
* macro_f1: 25.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 970
* accuracy: 10.0%
* error: 90.0%
* macro_f1: 8.4%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [24/50] batch [20/319] time 0.075 (0.115) data 0.000 (0.030) loss 1.3109 (1.4092) teacher_loss 0.2576 (0.3623) loss_zs_kd 6.0358 (6.4175) loss_oracle 1.0532 (1.0469) acc 84.3750 (85.9375) alaph_mean 0.9800 (0.9800) alpha_val 0.9800 (0.9800) lr 1.1874e-03 eta 0:16:31
epoch [24/50] batch [40/319] time 0.084 (0.096) data 0.000 (0.015) loss 1.7145 (1.4109) teacher_loss 0.6622 (0.3623) loss_zs_kd 6.0714 (6.3771) loss_oracle 1.0523 (1.0486) acc 71.8750 (86.4844) alaph_mean 0.9801 (0.9800) alpha_val 0.9801 (0.9800) lr 1.1874e-03 eta 0:13:44
epoch [24/50] batch [60/319] time 0.083 (0.092) data 0.000 (0.010) loss 1.4253 (1.4190) teacher_loss 0.3399 (0.3646) loss_zs_kd 6.8266 (6.3455) loss_oracle 1.0854 (1.0545) acc 84.3750 (86.0938) alaph_mean 0.9801 (0.9801) alpha_val 0.9801 (0.9801) lr 1.1874e-03 eta 0:13:04
epoch [24/50] batch [80/319] time 0.084 (0.090) data 0.000 (0.008) loss 1.4715 (1.4112) teacher_loss 0.3542 (0.3550) loss_zs_kd 6.8572 (6.3794) loss_oracle 1.1174 (1.0562) acc 90.6250 (86.0938) alaph_mean 0.9802 (0.9801) alpha_val 0.9802 (0.9801) lr 1.1874e-03 eta 0:12:47
epoch [24/50] batch [100/319] time 0.089 (0.089) data 0.000 (0.006) loss 1.7671 (1.4115) teacher_loss 0.6543 (0.3567) loss_zs_kd 6.7952 (6.3915) loss_oracle 1.1128 (1.0549) acc 68.7500 (85.9062) alaph_mean 0.9802 (0.9801) alpha_val 0.9802 (0.9801) lr 1.1874e-03 eta 0:12:37
epoch [24/50] batch [120/319] time 0.081 (0.088) data 0.000 (0.005) loss 1.3517 (1.4175) teacher_loss 0.2816 (0.3623) loss_zs_kd 6.9451 (6.3779) loss_oracle 1.0701 (1.0552) acc 87.5000 (85.5208) alaph_mean 0.9803 (0.9801) alpha_val 0.9803 (0.9801) lr 1.1874e-03 eta 0:12:29
epoch [24/50] batch [140/319] time 0.084 (0.088) data 0.000 (0.004) loss 1.3666 (1.4150) teacher_loss 0.3188 (0.3589) loss_zs_kd 6.4506 (6.3651) loss_oracle 1.0479 (1.0562) acc 81.2500 (85.7366) alaph_mean 0.9803 (0.9801) alpha_val 0.9803 (0.9801) lr 1.1874e-03 eta 0:12:22
epoch [24/50] batch [160/319] time 0.086 (0.087) data 0.000 (0.004) loss 1.4144 (1.4129) teacher_loss 0.2932 (0.3565) loss_zs_kd 6.2657 (6.3834) loss_oracle 1.1212 (1.0564) acc 90.6250 (85.8594) alaph_mean 0.9804 (0.9802) alpha_val 0.9804 (0.9802) lr 1.1874e-03 eta 0:12:16
epoch [24/50] batch [180/319] time 0.085 (0.087) data 0.000 (0.004) loss 1.5874 (1.4144) teacher_loss 0.4853 (0.3578) loss_zs_kd 6.6443 (6.3924) loss_oracle 1.1021 (1.0566) acc 81.2500 (85.7639) alaph_mean 0.9804 (0.9802) alpha_val 0.9804 (0.9802) lr 1.1874e-03 eta 0:12:10
epoch [24/50] batch [200/319] time 0.084 (0.086) data 0.000 (0.003) loss 1.3954 (1.4130) teacher_loss 0.3472 (0.3563) loss_zs_kd 6.0952 (6.3740) loss_oracle 1.0482 (1.0566) acc 87.5000 (85.8906) alaph_mean 0.9805 (0.9802) alpha_val 0.9805 (0.9802) lr 1.1874e-03 eta 0:12:07
epoch [24/50] batch [220/319] time 0.080 (0.086) data 0.000 (0.003) loss 1.5172 (1.4117) teacher_loss 0.4135 (0.3547) loss_zs_kd 6.7159 (6.3725) loss_oracle 1.1037 (1.0570) acc 81.2500 (85.9801) alaph_mean 0.9805 (0.9802) alpha_val 0.9805 (0.9802) lr 1.1874e-03 eta 0:12:03
epoch [24/50] batch [240/319] time 0.085 (0.086) data 0.000 (0.003) loss 1.5080 (1.4095) teacher_loss 0.4281 (0.3530) loss_zs_kd 6.8134 (6.3695) loss_oracle 1.0800 (1.0564) acc 78.1250 (86.1068) alaph_mean 0.9806 (0.9803) alpha_val 0.9806 (0.9803) lr 1.1874e-03 eta 0:11:57
epoch [24/50] batch [260/319] time 0.084 (0.086) data 0.000 (0.003) loss 1.4647 (1.4097) teacher_loss 0.3625 (0.3528) loss_zs_kd 6.3627 (6.3566) loss_oracle 1.1022 (1.0568) acc 87.5000 (86.1418) alaph_mean 0.9806 (0.9803) alpha_val 0.9806 (0.9803) lr 1.1874e-03 eta 0:11:54
epoch [24/50] batch [280/319] time 0.084 (0.085) data 0.000 (0.002) loss 1.4500 (1.4084) teacher_loss 0.4012 (0.3510) loss_zs_kd 6.0093 (6.3395) loss_oracle 1.0488 (1.0574) acc 78.1250 (86.1496) alaph_mean 0.9806 (0.9803) alpha_val 0.9806 (0.9803) lr 1.1874e-03 eta 0:11:51
epoch [24/50] batch [300/319] time 0.099 (0.086) data 0.000 (0.002) loss 1.3136 (1.4097) teacher_loss 0.3363 (0.3525) loss_zs_kd 6.1397 (6.3160) loss_oracle 0.9774 (1.0572) acc 90.6250 (86.1458) alaph_mean 0.9807 (0.9803) alpha_val 0.9807 (0.9803) lr 1.1874e-03 eta 0:11:51
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,326
* accuracy: 30.3%
* error: 69.7%
* macro_f1: 26.3%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 684
* accuracy: 7.0%
* error: 93.0%
* macro_f1: 7.3%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [25/50] batch [20/319] time 0.084 (0.117) data 0.000 (0.030) loss 1.3078 (1.3736) teacher_loss 0.2549 (0.3238) loss_zs_kd 5.6952 (6.3246) loss_oracle 1.0529 (1.0498) acc 90.6250 (87.1875) alaph_mean 0.9808 (0.9807) alpha_val 0.9808 (0.9807) lr 1.1253e-03 eta 0:16:07
epoch [25/50] batch [40/319] time 0.075 (0.099) data 0.000 (0.015) loss 1.4774 (1.3980) teacher_loss 0.4630 (0.3466) loss_zs_kd 6.7029 (6.3008) loss_oracle 1.0144 (1.0513) acc 81.2500 (86.3281) alaph_mean 0.9808 (0.9808) alpha_val 0.9808 (0.9808) lr 1.1253e-03 eta 0:13:33
epoch [25/50] batch [60/319] time 0.079 (0.092) data 0.000 (0.010) loss 1.6531 (1.4044) teacher_loss 0.6060 (0.3492) loss_zs_kd 5.6106 (6.2698) loss_oracle 1.0471 (1.0551) acc 75.0000 (86.4583) alaph_mean 0.9808 (0.9808) alpha_val 0.9808 (0.9808) lr 1.1253e-03 eta 0:12:34
epoch [25/50] batch [80/319] time 0.092 (0.089) data 0.000 (0.008) loss 1.3597 (1.4065) teacher_loss 0.3442 (0.3515) loss_zs_kd 5.3526 (6.2142) loss_oracle 1.0156 (1.0550) acc 84.3750 (86.2891) alaph_mean 0.9809 (0.9808) alpha_val 0.9809 (0.9808) lr 1.1253e-03 eta 0:12:12
epoch [25/50] batch [100/319] time 0.079 (0.087) data 0.000 (0.006) loss 1.3815 (1.3971) teacher_loss 0.3382 (0.3451) loss_zs_kd 6.1274 (6.1564) loss_oracle 1.0434 (1.0520) acc 90.6250 (86.6875) alaph_mean 0.9809 (0.9808) alpha_val 0.9809 (0.9808) lr 1.1253e-03 eta 0:11:52
epoch [25/50] batch [120/319] time 0.089 (0.086) data 0.000 (0.005) loss 1.4232 (1.4036) teacher_loss 0.3367 (0.3501) loss_zs_kd 6.6682 (6.1727) loss_oracle 1.0865 (1.0535) acc 84.3750 (86.4583) alaph_mean 0.9810 (0.9808) alpha_val 0.9810 (0.9808) lr 1.1253e-03 eta 0:11:46
epoch [25/50] batch [140/319] time 0.076 (0.088) data 0.000 (0.004) loss 1.2407 (1.3978) teacher_loss 0.1944 (0.3450) loss_zs_kd 6.8952 (6.1944) loss_oracle 1.0464 (1.0528) acc 96.8750 (87.0089) alaph_mean 0.9810 (0.9809) alpha_val 0.9810 (0.9809) lr 1.1253e-03 eta 0:11:54
epoch [25/50] batch [160/319] time 0.079 (0.087) data 0.000 (0.004) loss 1.4698 (1.4017) teacher_loss 0.3971 (0.3477) loss_zs_kd 6.1903 (6.2195) loss_oracle 1.0727 (1.0540) acc 84.3750 (86.9531) alaph_mean 0.9811 (0.9809) alpha_val 0.9811 (0.9809) lr 1.1253e-03 eta 0:11:44
epoch [25/50] batch [180/319] time 0.079 (0.086) data 0.000 (0.004) loss 1.4836 (1.4016) teacher_loss 0.3956 (0.3463) loss_zs_kd 6.3129 (6.2528) loss_oracle 1.0880 (1.0553) acc 84.3750 (87.1528) alaph_mean 0.9811 (0.9809) alpha_val 0.9811 (0.9809) lr 1.1253e-03 eta 0:11:41
epoch [25/50] batch [200/319] time 0.082 (0.086) data 0.000 (0.003) loss 1.5283 (1.4015) teacher_loss 0.4995 (0.3454) loss_zs_kd 6.3057 (6.2832) loss_oracle 1.0288 (1.0561) acc 81.2500 (87.1875) alaph_mean 0.9811 (0.9809) alpha_val 0.9811 (0.9809) lr 1.1253e-03 eta 0:11:35
epoch [25/50] batch [220/319] time 0.086 (0.086) data 0.000 (0.003) loss 1.3707 (1.4035) teacher_loss 0.3147 (0.3470) loss_zs_kd 6.2825 (6.2861) loss_oracle 1.0560 (1.0565) acc 81.2500 (86.9460) alaph_mean 0.9812 (0.9810) alpha_val 0.9812 (0.9810) lr 1.1253e-03 eta 0:11:32
epoch [25/50] batch [240/319] time 0.081 (0.086) data 0.000 (0.003) loss 1.6608 (1.4039) teacher_loss 0.5654 (0.3467) loss_zs_kd 6.5447 (6.2891) loss_oracle 1.0954 (1.0572) acc 84.3750 (87.0182) alaph_mean 0.9812 (0.9810) alpha_val 0.9812 (0.9810) lr 1.1253e-03 eta 0:11:29
epoch [25/50] batch [260/319] time 0.085 (0.085) data 0.000 (0.003) loss 1.3960 (1.4068) teacher_loss 0.3017 (0.3494) loss_zs_kd 6.8613 (6.2904) loss_oracle 1.0942 (1.0574) acc 81.2500 (86.9591) alaph_mean 0.9813 (0.9810) alpha_val 0.9813 (0.9810) lr 1.1253e-03 eta 0:11:26
epoch [25/50] batch [280/319] time 0.079 (0.085) data 0.000 (0.002) loss 1.4244 (1.4052) teacher_loss 0.4074 (0.3478) loss_zs_kd 6.1621 (6.2856) loss_oracle 1.0170 (1.0574) acc 78.1250 (86.9085) alaph_mean 0.9813 (0.9810) alpha_val 0.9813 (0.9810) lr 1.1253e-03 eta 0:11:22
epoch [25/50] batch [300/319] time 0.093 (0.085) data 0.000 (0.002) loss 1.5475 (1.4084) teacher_loss 0.4269 (0.3512) loss_zs_kd 5.9068 (6.2744) loss_oracle 1.1206 (1.0572) acc 84.3750 (86.7500) alaph_mean 0.9813 (0.9810) alpha_val 0.9813 (0.9810) lr 1.1253e-03 eta 0:11:19
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,377
* accuracy: 31.5%
* error: 68.5%
* macro_f1: 26.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 579
* accuracy: 5.9%
* error: 94.1%
* macro_f1: 6.6%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [26/50] batch [20/319] time 0.081 (0.117) data 0.000 (0.032) loss 1.3963 (1.4378) teacher_loss 0.3386 (0.3743) loss_zs_kd 5.7448 (6.1200) loss_oracle 1.0577 (1.0635) acc 81.2500 (83.4375) alaph_mean 0.9814 (0.9814) alpha_val 0.9814 (0.9814) lr 1.0628e-03 eta 0:15:30
epoch [26/50] batch [40/319] time 0.073 (0.097) data 0.000 (0.016) loss 1.3426 (1.4302) teacher_loss 0.3219 (0.3670) loss_zs_kd 5.6235 (5.9571) loss_oracle 1.0208 (1.0631) acc 90.6250 (84.5312) alaph_mean 0.9815 (0.9814) alpha_val 0.9815 (0.9814) lr 1.0628e-03 eta 0:12:49
epoch [26/50] batch [60/319] time 0.080 (0.092) data 0.000 (0.011) loss 1.3517 (1.4104) teacher_loss 0.2986 (0.3533) loss_zs_kd 6.0265 (5.9777) loss_oracle 1.0531 (1.0571) acc 87.5000 (85.5729) alaph_mean 0.9815 (0.9814) alpha_val 0.9815 (0.9814) lr 1.0628e-03 eta 0:12:04
epoch [26/50] batch [80/319] time 0.082 (0.090) data 0.000 (0.008) loss 1.5335 (1.4161) teacher_loss 0.4357 (0.3575) loss_zs_kd 6.6892 (6.0599) loss_oracle 1.0978 (1.0586) acc 84.3750 (85.5469) alaph_mean 0.9816 (0.9815) alpha_val 0.9816 (0.9815) lr 1.0628e-03 eta 0:11:47
epoch [26/50] batch [100/319] time 0.069 (0.088) data 0.000 (0.007) loss 1.3784 (1.4133) teacher_loss 0.3118 (0.3543) loss_zs_kd 6.8034 (6.1165) loss_oracle 1.0666 (1.0589) acc 87.5000 (85.8750) alaph_mean 0.9816 (0.9815) alpha_val 0.9816 (0.9815) lr 1.0628e-03 eta 0:11:36
epoch [26/50] batch [120/319] time 0.083 (0.086) data 0.000 (0.006) loss 1.4414 (1.4047) teacher_loss 0.3786 (0.3464) loss_zs_kd 6.4140 (6.1946) loss_oracle 1.0628 (1.0583) acc 81.2500 (86.0938) alaph_mean 0.9816 (0.9815) alpha_val 0.9816 (0.9815) lr 1.0628e-03 eta 0:11:19
epoch [26/50] batch [140/319] time 0.089 (0.086) data 0.001 (0.005) loss 1.4167 (1.4033) teacher_loss 0.3795 (0.3468) loss_zs_kd 5.8002 (6.2187) loss_oracle 1.0372 (1.0565) acc 87.5000 (86.2054) alaph_mean 0.9817 (0.9815) alpha_val 0.9817 (0.9815) lr 1.0628e-03 eta 0:11:15
epoch [26/50] batch [160/319] time 0.088 (0.085) data 0.000 (0.004) loss 1.2188 (1.4018) teacher_loss 0.2288 (0.3462) loss_zs_kd 6.6075 (6.2506) loss_oracle 0.9900 (1.0556) acc 90.6250 (86.1328) alaph_mean 0.9817 (0.9816) alpha_val 0.9817 (0.9816) lr 1.0628e-03 eta 0:11:07
epoch [26/50] batch [180/319] time 0.074 (0.085) data 0.000 (0.004) loss 1.3110 (1.4015) teacher_loss 0.2324 (0.3455) loss_zs_kd 6.5158 (6.2781) loss_oracle 1.0787 (1.0560) acc 87.5000 (86.1632) alaph_mean 0.9817 (0.9816) alpha_val 0.9817 (0.9816) lr 1.0628e-03 eta 0:11:01
epoch [26/50] batch [200/319] time 0.078 (0.084) data 0.000 (0.003) loss 1.6950 (1.4011) teacher_loss 0.6775 (0.3453) loss_zs_kd 6.0130 (6.2861) loss_oracle 1.0175 (1.0559) acc 78.1250 (86.2812) alaph_mean 0.9818 (0.9816) alpha_val 0.9818 (0.9816) lr 1.0628e-03 eta 0:10:56
epoch [26/50] batch [220/319] time 0.081 (0.084) data 0.000 (0.003) loss 1.1494 (1.4001) teacher_loss 0.1441 (0.3434) loss_zs_kd 5.6797 (6.2856) loss_oracle 1.0053 (1.0567) acc 96.8750 (86.3920) alaph_mean 0.9818 (0.9816) alpha_val 0.9818 (0.9816) lr 1.0628e-03 eta 0:10:54
epoch [26/50] batch [240/319] time 0.066 (0.084) data 0.000 (0.003) loss 1.2844 (1.3993) teacher_loss 0.2678 (0.3438) loss_zs_kd 6.6303 (6.2918) loss_oracle 1.0166 (1.0555) acc 87.5000 (86.4453) alaph_mean 0.9819 (0.9816) alpha_val 0.9819 (0.9816) lr 1.0628e-03 eta 0:10:46
epoch [26/50] batch [260/319] time 0.078 (0.083) data 0.000 (0.003) loss 1.4282 (1.3979) teacher_loss 0.3496 (0.3429) loss_zs_kd 6.0890 (6.2841) loss_oracle 1.0787 (1.0550) acc 84.3750 (86.4904) alaph_mean 0.9819 (0.9816) alpha_val 0.9819 (0.9816) lr 1.0628e-03 eta 0:10:40
epoch [26/50] batch [280/319] time 0.086 (0.083) data 0.000 (0.003) loss 1.3910 (1.4000) teacher_loss 0.4458 (0.3452) loss_zs_kd 5.5584 (6.2895) loss_oracle 0.9453 (1.0548) acc 84.3750 (86.3616) alaph_mean 0.9819 (0.9817) alpha_val 0.9819 (0.9817) lr 1.0628e-03 eta 0:10:41
epoch [26/50] batch [300/319] time 0.082 (0.083) data 0.000 (0.002) loss 1.8257 (1.4045) teacher_loss 0.7550 (0.3488) loss_zs_kd 6.3963 (6.2876) loss_oracle 1.0707 (1.0557) acc 81.2500 (86.2500) alaph_mean 0.9820 (0.9817) alpha_val 0.9820 (0.9817) lr 1.0628e-03 eta 0:10:40
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,380
* accuracy: 31.5%
* error: 68.5%
* macro_f1: 25.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 778
* accuracy: 8.0%
* error: 92.0%
* macro_f1: 7.3%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [27/50] batch [20/319] time 0.065 (0.104) data 0.000 (0.030) loss 1.1826 (1.4230) teacher_loss 0.1613 (0.3700) loss_zs_kd 6.3209 (6.4533) loss_oracle 1.0213 (1.0530) acc 96.8750 (84.8438) alaph_mean 0.9820 (0.9820) alpha_val 0.9820 (0.9820) lr 1.0000e-03 eta 0:13:12
epoch [27/50] batch [40/319] time 0.085 (0.093) data 0.000 (0.015) loss 1.3537 (1.4117) teacher_loss 0.2559 (0.3586) loss_zs_kd 6.4194 (6.5053) loss_oracle 1.0978 (1.0531) acc 93.7500 (85.7812) alaph_mean 0.9821 (0.9820) alpha_val 0.9821 (0.9820) lr 1.0000e-03 eta 0:11:46
epoch [27/50] batch [60/319] time 0.085 (0.089) data 0.000 (0.010) loss 1.4243 (1.3952) teacher_loss 0.4440 (0.3445) loss_zs_kd 6.2108 (6.4713) loss_oracle 0.9803 (1.0507) acc 81.2500 (86.1979) alaph_mean 0.9821 (0.9820) alpha_val 0.9821 (0.9820) lr 1.0000e-03 eta 0:11:12
epoch [27/50] batch [80/319] time 0.078 (0.087) data 0.000 (0.008) loss 1.4256 (1.3865) teacher_loss 0.3222 (0.3374) loss_zs_kd 6.8701 (6.4379) loss_oracle 1.1034 (1.0491) acc 84.3750 (86.7578) alaph_mean 0.9821 (0.9821) alpha_val 0.9821 (0.9821) lr 1.0000e-03 eta 0:10:59
epoch [27/50] batch [100/319] time 0.086 (0.085) data 0.000 (0.006) loss 1.5410 (1.3858) teacher_loss 0.4800 (0.3358) loss_zs_kd 6.0844 (6.3595) loss_oracle 1.0610 (1.0501) acc 84.3750 (86.9375) alaph_mean 0.9822 (0.9821) alpha_val 0.9822 (0.9821) lr 1.0000e-03 eta 0:10:44
epoch [27/50] batch [120/319] time 0.085 (0.085) data 0.000 (0.005) loss 1.3001 (1.3884) teacher_loss 0.2878 (0.3401) loss_zs_kd 6.3949 (6.3112) loss_oracle 1.0123 (1.0483) acc 84.3750 (86.7708) alaph_mean 0.9822 (0.9821) alpha_val 0.9822 (0.9821) lr 1.0000e-03 eta 0:10:39
epoch [27/50] batch [140/319] time 0.078 (0.087) data 0.000 (0.004) loss 1.3772 (1.3923) teacher_loss 0.3092 (0.3414) loss_zs_kd 6.5536 (6.2813) loss_oracle 1.0680 (1.0509) acc 81.2500 (86.5848) alaph_mean 0.9822 (0.9821) alpha_val 0.9822 (0.9821) lr 1.0000e-03 eta 0:10:52
epoch [27/50] batch [160/319] time 0.079 (0.086) data 0.000 (0.004) loss 1.1150 (1.3913) teacher_loss 0.1165 (0.3395) loss_zs_kd 5.8518 (6.2512) loss_oracle 0.9985 (1.0518) acc 96.8750 (86.7578) alaph_mean 0.9823 (0.9821) alpha_val 0.9823 (0.9821) lr 1.0000e-03 eta 0:10:44
epoch [27/50] batch [180/319] time 0.079 (0.086) data 0.000 (0.004) loss 1.2564 (1.3936) teacher_loss 0.2417 (0.3407) loss_zs_kd 6.3197 (6.2500) loss_oracle 1.0147 (1.0529) acc 90.6250 (86.6840) alaph_mean 0.9823 (0.9822) alpha_val 0.9823 (0.9822) lr 1.0000e-03 eta 0:10:39
epoch [27/50] batch [200/319] time 0.078 (0.085) data 0.000 (0.003) loss 1.2763 (1.3936) teacher_loss 0.2382 (0.3406) loss_zs_kd 6.1585 (6.2326) loss_oracle 1.0381 (1.0530) acc 90.6250 (86.6875) alaph_mean 0.9823 (0.9822) alpha_val 0.9823 (0.9822) lr 1.0000e-03 eta 0:10:36
epoch [27/50] batch [220/319] time 0.085 (0.085) data 0.000 (0.003) loss 1.4348 (1.3933) teacher_loss 0.3625 (0.3403) loss_zs_kd 6.7888 (6.2251) loss_oracle 1.0723 (1.0530) acc 87.5000 (86.6051) alaph_mean 0.9824 (0.9822) alpha_val 0.9824 (0.9822) lr 1.0000e-03 eta 0:10:33
epoch [27/50] batch [240/319] time 0.083 (0.085) data 0.000 (0.003) loss 1.4604 (1.3967) teacher_loss 0.3490 (0.3421) loss_zs_kd 6.0832 (6.2219) loss_oracle 1.1114 (1.0545) acc 87.5000 (86.4974) alaph_mean 0.9824 (0.9822) alpha_val 0.9824 (0.9822) lr 1.0000e-03 eta 0:10:28
epoch [27/50] batch [260/319] time 0.079 (0.084) data 0.000 (0.003) loss 1.4571 (1.3976) teacher_loss 0.3770 (0.3432) loss_zs_kd 5.7989 (6.2040) loss_oracle 1.0801 (1.0544) acc 78.1250 (86.5024) alaph_mean 0.9825 (0.9822) alpha_val 0.9825 (0.9822) lr 1.0000e-03 eta 0:10:22
epoch [27/50] batch [280/319] time 0.083 (0.084) data 0.000 (0.002) loss 1.7373 (1.4012) teacher_loss 0.6562 (0.3468) loss_zs_kd 6.0119 (6.1909) loss_oracle 1.0811 (1.0544) acc 78.1250 (86.4397) alaph_mean 0.9825 (0.9822) alpha_val 0.9825 (0.9822) lr 1.0000e-03 eta 0:10:20
epoch [27/50] batch [300/319] time 0.078 (0.084) data 0.000 (0.002) loss 1.5109 (1.3987) teacher_loss 0.3675 (0.3434) loss_zs_kd 6.2827 (6.1828) loss_oracle 1.1434 (1.0553) acc 90.6250 (86.5417) alaph_mean 0.9826 (0.9823) alpha_val 0.9826 (0.9823) lr 1.0000e-03 eta 0:10:15
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,605
* accuracy: 36.7%
* error: 63.3%
* macro_f1: 24.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 725
* accuracy: 7.4%
* error: 92.6%
* macro_f1: 6.1%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [28/50] batch [20/319] time 0.082 (0.118) data 0.000 (0.030) loss 1.3430 (1.3822) teacher_loss 0.3766 (0.3273) loss_zs_kd 5.5977 (6.0171) loss_oracle 0.9664 (1.0549) acc 93.7500 (88.4375) alaph_mean 0.9826 (0.9826) alpha_val 0.9826 (0.9826) lr 9.3721e-04 eta 0:14:25
epoch [28/50] batch [40/319] time 0.074 (0.100) data 0.000 (0.015) loss 1.3976 (1.3880) teacher_loss 0.3337 (0.3347) loss_zs_kd 6.1620 (5.9619) loss_oracle 1.0640 (1.0533) acc 87.5000 (88.9062) alaph_mean 0.9827 (0.9826) alpha_val 0.9827 (0.9826) lr 9.3721e-04 eta 0:12:11
epoch [28/50] batch [60/319] time 0.076 (0.093) data 0.001 (0.010) loss 1.2225 (1.4008) teacher_loss 0.2248 (0.3479) loss_zs_kd 5.9295 (5.9701) loss_oracle 0.9977 (1.0529) acc 93.7500 (87.9167) alaph_mean 0.9827 (0.9826) alpha_val 0.9827 (0.9826) lr 9.3721e-04 eta 0:11:15
epoch [28/50] batch [80/319] time 0.082 (0.090) data 0.000 (0.008) loss 1.3120 (1.3881) teacher_loss 0.2697 (0.3369) loss_zs_kd 6.0938 (5.9682) loss_oracle 1.0423 (1.0512) acc 90.6250 (87.9297) alaph_mean 0.9827 (0.9827) alpha_val 0.9827 (0.9827) lr 9.3721e-04 eta 0:10:55
epoch [28/50] batch [100/319] time 0.090 (0.089) data 0.000 (0.006) loss 1.2561 (1.3992) teacher_loss 0.1843 (0.3460) loss_zs_kd 6.5454 (6.0200) loss_oracle 1.0718 (1.0533) acc 90.6250 (87.3438) alaph_mean 0.9828 (0.9827) alpha_val 0.9828 (0.9827) lr 9.3721e-04 eta 0:10:41
epoch [28/50] batch [120/319] time 0.089 (0.088) data 0.000 (0.005) loss 1.5715 (1.3951) teacher_loss 0.4633 (0.3405) loss_zs_kd 6.5364 (6.0646) loss_oracle 1.1082 (1.0545) acc 81.2500 (87.1875) alaph_mean 0.9828 (0.9827) alpha_val 0.9828 (0.9827) lr 9.3721e-04 eta 0:10:35
epoch [28/50] batch [140/319] time 0.089 (0.088) data 0.000 (0.005) loss 1.2701 (1.3986) teacher_loss 0.2179 (0.3442) loss_zs_kd 5.9024 (6.0959) loss_oracle 1.0523 (1.0544) acc 87.5000 (86.9866) alaph_mean 0.9828 (0.9827) alpha_val 0.9828 (0.9827) lr 9.3721e-04 eta 0:10:31
epoch [28/50] batch [160/319] time 0.092 (0.087) data 0.000 (0.004) loss 1.3888 (1.3971) teacher_loss 0.3167 (0.3426) loss_zs_kd 5.9305 (6.1046) loss_oracle 1.0721 (1.0545) acc 93.7500 (87.2070) alaph_mean 0.9829 (0.9827) alpha_val 0.9829 (0.9827) lr 9.3721e-04 eta 0:10:27
epoch [28/50] batch [180/319] time 0.086 (0.087) data 0.000 (0.004) loss 1.2483 (1.3899) teacher_loss 0.1702 (0.3362) loss_zs_kd 6.1488 (6.1036) loss_oracle 1.0781 (1.0536) acc 96.8750 (87.5521) alaph_mean 0.9829 (0.9827) alpha_val 0.9829 (0.9827) lr 9.3721e-04 eta 0:10:19
epoch [28/50] batch [200/319] time 0.082 (0.086) data 0.000 (0.003) loss 1.4539 (1.3961) teacher_loss 0.3428 (0.3415) loss_zs_kd 5.9915 (6.1035) loss_oracle 1.1111 (1.0546) acc 87.5000 (87.2500) alaph_mean 0.9829 (0.9828) alpha_val 0.9829 (0.9828) lr 9.3721e-04 eta 0:10:15
epoch [28/50] batch [220/319] time 0.075 (0.086) data 0.000 (0.003) loss 1.6228 (1.3991) teacher_loss 0.5881 (0.3437) loss_zs_kd 5.5908 (6.0951) loss_oracle 1.0347 (1.0554) acc 71.8750 (87.1023) alaph_mean 0.9830 (0.9828) alpha_val 0.9830 (0.9828) lr 9.3721e-04 eta 0:10:12
epoch [28/50] batch [240/319] time 0.085 (0.086) data 0.000 (0.003) loss 1.3042 (1.4004) teacher_loss 0.2692 (0.3449) loss_zs_kd 6.1310 (6.0982) loss_oracle 1.0350 (1.0555) acc 90.6250 (87.0052) alaph_mean 0.9830 (0.9828) alpha_val 0.9830 (0.9828) lr 9.3721e-04 eta 0:10:08
epoch [28/50] batch [260/319] time 0.082 (0.086) data 0.000 (0.003) loss 1.3289 (1.3988) teacher_loss 0.2477 (0.3431) loss_zs_kd 5.9675 (6.0916) loss_oracle 1.0812 (1.0557) acc 90.6250 (87.0312) alaph_mean 0.9830 (0.9828) alpha_val 0.9830 (0.9828) lr 9.3721e-04 eta 0:10:05
epoch [28/50] batch [280/319] time 0.092 (0.085) data 0.000 (0.002) loss 1.3732 (1.3992) teacher_loss 0.3031 (0.3432) loss_zs_kd 6.4306 (6.1040) loss_oracle 1.0701 (1.0560) acc 90.6250 (87.0312) alaph_mean 0.9831 (0.9828) alpha_val 0.9831 (0.9828) lr 9.3721e-04 eta 0:10:02
epoch [28/50] batch [300/319] time 0.080 (0.085) data 0.000 (0.002) loss 1.4557 (1.3964) teacher_loss 0.4088 (0.3409) loss_zs_kd 5.9516 (6.1127) loss_oracle 1.0468 (1.0554) acc 90.6250 (87.1667) alaph_mean 0.9831 (0.9828) alpha_val 0.9831 (0.9828) lr 9.3721e-04 eta 0:09:59
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,301
* accuracy: 29.7%
* error: 70.3%
* macro_f1: 24.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 865
* accuracy: 8.9%
* error: 91.1%
* macro_f1: 7.0%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [29/50] batch [20/319] time 0.066 (0.110) data 0.000 (0.025) loss 1.5379 (1.3812) teacher_loss 0.4358 (0.3233) loss_zs_kd 6.6673 (6.2174) loss_oracle 1.1021 (1.0579) acc 78.1250 (87.8125) alaph_mean 0.9831 (0.9831) alpha_val 0.9831 (0.9831) lr 8.7467e-04 eta 0:12:51
epoch [29/50] batch [40/319] time 0.084 (0.096) data 0.000 (0.013) loss 1.4400 (1.3871) teacher_loss 0.3680 (0.3324) loss_zs_kd 6.7995 (6.3016) loss_oracle 1.0720 (1.0548) acc 84.3750 (87.1094) alaph_mean 0.9832 (0.9831) alpha_val 0.9832 (0.9831) lr 8.7467e-04 eta 0:11:09
epoch [29/50] batch [60/319] time 0.084 (0.092) data 0.000 (0.009) loss 1.3247 (1.3895) teacher_loss 0.2580 (0.3346) loss_zs_kd 5.9849 (6.3398) loss_oracle 1.0667 (1.0548) acc 90.6250 (87.3958) alaph_mean 0.9832 (0.9832) alpha_val 0.9832 (0.9832) lr 8.7467e-04 eta 0:10:38
epoch [29/50] batch [80/319] time 0.083 (0.090) data 0.000 (0.007) loss 1.3640 (1.3979) teacher_loss 0.3128 (0.3422) loss_zs_kd 6.2915 (6.3283) loss_oracle 1.0512 (1.0557) acc 87.5000 (86.9141) alaph_mean 0.9832 (0.9832) alpha_val 0.9832 (0.9832) lr 8.7467e-04 eta 0:10:22
epoch [29/50] batch [100/319] time 0.078 (0.087) data 0.000 (0.005) loss 1.3757 (1.3974) teacher_loss 0.3902 (0.3424) loss_zs_kd 6.0510 (6.3265) loss_oracle 0.9855 (1.0551) acc 75.0000 (86.6875) alaph_mean 0.9833 (0.9832) alpha_val 0.9833 (0.9832) lr 8.7467e-04 eta 0:10:05
epoch [29/50] batch [120/319] time 0.081 (0.086) data 0.000 (0.004) loss 1.3181 (1.3980) teacher_loss 0.3227 (0.3429) loss_zs_kd 5.6044 (6.3252) loss_oracle 0.9954 (1.0551) acc 87.5000 (86.8229) alaph_mean 0.9833 (0.9832) alpha_val 0.9833 (0.9832) lr 8.7467e-04 eta 0:09:55
epoch [29/50] batch [140/319] time 0.075 (0.088) data 0.000 (0.004) loss 1.4157 (1.3955) teacher_loss 0.3768 (0.3412) loss_zs_kd 6.0632 (6.2902) loss_oracle 1.0389 (1.0544) acc 81.2500 (86.9420) alaph_mean 0.9833 (0.9832) alpha_val 0.9833 (0.9832) lr 8.7467e-04 eta 0:10:05
epoch [29/50] batch [160/319] time 0.080 (0.087) data 0.000 (0.003) loss 1.5102 (1.3965) teacher_loss 0.4635 (0.3413) loss_zs_kd 6.1848 (6.2537) loss_oracle 1.0467 (1.0553) acc 87.5000 (86.8945) alaph_mean 0.9834 (0.9832) alpha_val 0.9834 (0.9832) lr 8.7467e-04 eta 0:09:59
epoch [29/50] batch [180/319] time 0.088 (0.087) data 0.000 (0.003) loss 1.4381 (1.3985) teacher_loss 0.4154 (0.3424) loss_zs_kd 5.4701 (6.2317) loss_oracle 1.0226 (1.0561) acc 81.2500 (86.7708) alaph_mean 0.9834 (0.9833) alpha_val 0.9834 (0.9833) lr 8.7467e-04 eta 0:09:53
epoch [29/50] batch [200/319] time 0.083 (0.087) data 0.000 (0.003) loss 1.4301 (1.4016) teacher_loss 0.3369 (0.3447) loss_zs_kd 5.6040 (6.2080) loss_oracle 1.0932 (1.0569) acc 90.6250 (86.7188) alaph_mean 0.9835 (0.9833) alpha_val 0.9835 (0.9833) lr 8.7467e-04 eta 0:09:51
epoch [29/50] batch [220/319] time 0.085 (0.086) data 0.000 (0.003) loss 1.6245 (1.4008) teacher_loss 0.5099 (0.3439) loss_zs_kd 6.3604 (6.1929) loss_oracle 1.1146 (1.0569) acc 71.8750 (86.6335) alaph_mean 0.9835 (0.9833) alpha_val 0.9835 (0.9833) lr 8.7467e-04 eta 0:09:47
epoch [29/50] batch [240/319] time 0.081 (0.086) data 0.000 (0.002) loss 1.2967 (1.4007) teacher_loss 0.2550 (0.3436) loss_zs_kd 6.6661 (6.1866) loss_oracle 1.0417 (1.0570) acc 87.5000 (86.6536) alaph_mean 0.9835 (0.9833) alpha_val 0.9835 (0.9833) lr 8.7467e-04 eta 0:09:44
epoch [29/50] batch [260/319] time 0.080 (0.086) data 0.000 (0.002) loss 1.3165 (1.4048) teacher_loss 0.2756 (0.3473) loss_zs_kd 5.8594 (6.1687) loss_oracle 1.0409 (1.0575) acc 90.6250 (86.5144) alaph_mean 0.9836 (0.9833) alpha_val 0.9836 (0.9833) lr 8.7467e-04 eta 0:09:41
epoch [29/50] batch [280/319] time 0.082 (0.086) data 0.000 (0.002) loss 1.3107 (1.4032) teacher_loss 0.1894 (0.3454) loss_zs_kd 6.4563 (6.1437) loss_oracle 1.1213 (1.0578) acc 93.7500 (86.5848) alaph_mean 0.9836 (0.9833) alpha_val 0.9836 (0.9833) lr 8.7467e-04 eta 0:09:37
epoch [29/50] batch [300/319] time 0.084 (0.086) data 0.000 (0.002) loss 1.3016 (1.4033) teacher_loss 0.2568 (0.3467) loss_zs_kd 5.7274 (6.1127) loss_oracle 1.0448 (1.0566) acc 90.6250 (86.5729) alaph_mean 0.9836 (0.9834) alpha_val 0.9836 (0.9834) lr 8.7467e-04 eta 0:09:34
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,466
* accuracy: 33.5%
* error: 66.5%
* macro_f1: 26.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 529
* accuracy: 5.4%
* error: 94.6%
* macro_f1: 5.5%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [30/50] batch [20/319] time 0.081 (0.108) data 0.000 (0.026) loss 1.2792 (1.4103) teacher_loss 0.2254 (0.3540) loss_zs_kd 5.8157 (5.8017) loss_oracle 1.0539 (1.0563) acc 87.5000 (86.0938) alaph_mean 0.9837 (0.9837) alpha_val 0.9837 (0.9837) lr 8.1262e-04 eta 0:12:04
epoch [30/50] batch [40/319] time 0.090 (0.096) data 0.000 (0.013) loss 1.2449 (1.4071) teacher_loss 0.1964 (0.3484) loss_zs_kd 6.3771 (5.9311) loss_oracle 1.0485 (1.0587) acc 96.8750 (86.8750) alaph_mean 0.9837 (0.9837) alpha_val 0.9837 (0.9837) lr 8.1262e-04 eta 0:10:39
epoch [30/50] batch [60/319] time 0.078 (0.092) data 0.000 (0.009) loss 1.2622 (1.4085) teacher_loss 0.1965 (0.3505) loss_zs_kd 6.0677 (5.9782) loss_oracle 1.0657 (1.0580) acc 93.7500 (86.7708) alaph_mean 0.9838 (0.9837) alpha_val 0.9838 (0.9837) lr 8.1262e-04 eta 0:10:07
epoch [30/50] batch [80/319] time 0.078 (0.088) data 0.000 (0.007) loss 1.4624 (1.4078) teacher_loss 0.3813 (0.3510) loss_zs_kd 5.9751 (6.0156) loss_oracle 1.0811 (1.0568) acc 84.3750 (86.4453) alaph_mean 0.9838 (0.9837) alpha_val 0.9838 (0.9837) lr 8.1262e-04 eta 0:09:42
epoch [30/50] batch [100/319] time 0.085 (0.088) data 0.000 (0.005) loss 1.3776 (1.4103) teacher_loss 0.3460 (0.3531) loss_zs_kd 5.5401 (5.9847) loss_oracle 1.0315 (1.0572) acc 84.3750 (86.4688) alaph_mean 0.9838 (0.9837) alpha_val 0.9838 (0.9837) lr 8.1262e-04 eta 0:09:38
epoch [30/50] batch [120/319] time 0.087 (0.087) data 0.000 (0.004) loss 1.5253 (1.4114) teacher_loss 0.4203 (0.3551) loss_zs_kd 6.2710 (5.9439) loss_oracle 1.1051 (1.0564) acc 81.2500 (86.3281) alaph_mean 0.9838 (0.9838) alpha_val 0.9838 (0.9838) lr 8.1262e-04 eta 0:09:34
epoch [30/50] batch [140/319] time 0.079 (0.086) data 0.000 (0.004) loss 1.3646 (1.4078) teacher_loss 0.3430 (0.3511) loss_zs_kd 5.7254 (5.9640) loss_oracle 1.0216 (1.0567) acc 84.3750 (86.5625) alaph_mean 0.9839 (0.9838) alpha_val 0.9839 (0.9838) lr 8.1262e-04 eta 0:09:24
epoch [30/50] batch [160/319] time 0.077 (0.085) data 0.000 (0.003) loss 1.2639 (1.4043) teacher_loss 0.1762 (0.3476) loss_zs_kd 6.4508 (5.9694) loss_oracle 1.0878 (1.0567) acc 93.7500 (86.6211) alaph_mean 0.9839 (0.9838) alpha_val 0.9839 (0.9838) lr 8.1262e-04 eta 0:09:16
epoch [30/50] batch [180/319] time 0.072 (0.085) data 0.000 (0.003) loss 1.4406 (1.4035) teacher_loss 0.3943 (0.3475) loss_zs_kd 5.8232 (5.9553) loss_oracle 1.0463 (1.0560) acc 81.2500 (86.5625) alaph_mean 0.9839 (0.9838) alpha_val 0.9839 (0.9838) lr 8.1262e-04 eta 0:09:11
epoch [30/50] batch [200/319] time 0.078 (0.084) data 0.000 (0.003) loss 1.4079 (1.3982) teacher_loss 0.3743 (0.3442) loss_zs_kd 6.0420 (5.9494) loss_oracle 1.0335 (1.0540) acc 81.2500 (86.7188) alaph_mean 0.9839 (0.9838) alpha_val 0.9839 (0.9838) lr 8.1262e-04 eta 0:09:07
epoch [30/50] batch [220/319] time 0.074 (0.084) data 0.000 (0.003) loss 1.3490 (1.3984) teacher_loss 0.3418 (0.3430) loss_zs_kd 6.9146 (5.9675) loss_oracle 1.0071 (1.0554) acc 87.5000 (86.8182) alaph_mean 0.9840 (0.9838) alpha_val 0.9840 (0.9838) lr 8.1262e-04 eta 0:09:01
epoch [30/50] batch [240/319] time 0.084 (0.083) data 0.000 (0.002) loss 1.6100 (1.4026) teacher_loss 0.4975 (0.3461) loss_zs_kd 6.1027 (5.9805) loss_oracle 1.1124 (1.0565) acc 84.3750 (86.7578) alaph_mean 0.9840 (0.9838) alpha_val 0.9840 (0.9838) lr 8.1262e-04 eta 0:08:58
epoch [30/50] batch [260/319] time 0.083 (0.083) data 0.000 (0.002) loss 1.3537 (1.4028) teacher_loss 0.3289 (0.3469) loss_zs_kd 5.8849 (5.9808) loss_oracle 1.0248 (1.0559) acc 90.6250 (86.6346) alaph_mean 0.9840 (0.9838) alpha_val 0.9840 (0.9838) lr 8.1262e-04 eta 0:08:56
epoch [30/50] batch [280/319] time 0.075 (0.083) data 0.000 (0.002) loss 1.3666 (1.4004) teacher_loss 0.2670 (0.3448) loss_zs_kd 6.2197 (5.9756) loss_oracle 1.0996 (1.0556) acc 90.6250 (86.7857) alaph_mean 0.9840 (0.9839) alpha_val 0.9840 (0.9839) lr 8.1262e-04 eta 0:08:54
epoch [30/50] batch [300/319] time 0.086 (0.083) data 0.000 (0.002) loss 1.6626 (1.3994) teacher_loss 0.5709 (0.3434) loss_zs_kd 5.9562 (5.9786) loss_oracle 1.0917 (1.0560) acc 78.1250 (86.8438) alaph_mean 0.9841 (0.9839) alpha_val 0.9841 (0.9839) lr 8.1262e-04 eta 0:08:51
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,441
* accuracy: 32.9%
* error: 67.1%
* macro_f1: 23.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 942
* accuracy: 9.7%
* error: 90.3%
* macro_f1: 6.9%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [31/50] batch [20/319] time 0.078 (0.107) data 0.000 (0.024) loss 1.3430 (1.3455) teacher_loss 0.2519 (0.2860) loss_zs_kd 5.4983 (6.1468) loss_oracle 1.0911 (1.0595) acc 90.6250 (90.4688) alaph_mean 0.9841 (0.9841) alpha_val 0.9841 (0.9841) lr 7.5131e-04 eta 0:11:18
epoch [31/50] batch [40/319] time 0.080 (0.093) data 0.000 (0.012) loss 1.2661 (1.3534) teacher_loss 0.2563 (0.2997) loss_zs_kd 5.9678 (6.1058) loss_oracle 1.0097 (1.0537) acc 93.7500 (89.2188) alaph_mean 0.9842 (0.9841) alpha_val 0.9842 (0.9841) lr 7.5131e-04 eta 0:09:51
epoch [31/50] batch [60/319] time 0.077 (0.089) data 0.000 (0.008) loss 1.3622 (1.3675) teacher_loss 0.3201 (0.3168) loss_zs_kd 6.1191 (6.0711) loss_oracle 1.0420 (1.0508) acc 81.2500 (87.8646) alaph_mean 0.9842 (0.9841) alpha_val 0.9842 (0.9841) lr 7.5131e-04 eta 0:09:22
epoch [31/50] batch [80/319] time 0.087 (0.087) data 0.000 (0.006) loss 1.3683 (1.3775) teacher_loss 0.2665 (0.3240) loss_zs_kd 6.1060 (6.0966) loss_oracle 1.1018 (1.0535) acc 87.5000 (87.8516) alaph_mean 0.9842 (0.9842) alpha_val 0.9842 (0.9842) lr 7.5131e-04 eta 0:09:09
epoch [31/50] batch [100/319] time 0.075 (0.087) data 0.000 (0.005) loss 1.3655 (1.3749) teacher_loss 0.2972 (0.3217) loss_zs_kd 6.3451 (6.0796) loss_oracle 1.0683 (1.0532) acc 87.5000 (87.9062) alaph_mean 0.9842 (0.9842) alpha_val 0.9842 (0.9842) lr 7.5131e-04 eta 0:09:04
epoch [31/50] batch [120/319] time 0.080 (0.085) data 0.000 (0.004) loss 1.3385 (1.3804) teacher_loss 0.2548 (0.3262) loss_zs_kd 5.9251 (6.0435) loss_oracle 1.0837 (1.0542) acc 90.6250 (87.6302) alaph_mean 0.9843 (0.9842) alpha_val 0.9843 (0.9842) lr 7.5131e-04 eta 0:08:54
epoch [31/50] batch [140/319] time 0.082 (0.088) data 0.000 (0.004) loss 1.3087 (1.3829) teacher_loss 0.2921 (0.3284) loss_zs_kd 6.3387 (6.0310) loss_oracle 1.0166 (1.0546) acc 87.5000 (87.3438) alaph_mean 0.9843 (0.9842) alpha_val 0.9843 (0.9842) lr 7.5131e-04 eta 0:09:07
epoch [31/50] batch [160/319] time 0.082 (0.087) data 0.000 (0.003) loss 1.6326 (1.3882) teacher_loss 0.5542 (0.3323) loss_zs_kd 5.5612 (6.0495) loss_oracle 1.0784 (1.0560) acc 68.7500 (87.0312) alaph_mean 0.9843 (0.9842) alpha_val 0.9843 (0.9842) lr 7.5131e-04 eta 0:09:04
epoch [31/50] batch [180/319] time 0.084 (0.087) data 0.000 (0.003) loss 1.6539 (1.3933) teacher_loss 0.5739 (0.3377) loss_zs_kd 5.6049 (6.0265) loss_oracle 1.0800 (1.0556) acc 81.2500 (86.8229) alaph_mean 0.9843 (0.9842) alpha_val 0.9843 (0.9842) lr 7.5131e-04 eta 0:09:00
epoch [31/50] batch [200/319] time 0.076 (0.086) data 0.000 (0.003) loss 1.3802 (1.3942) teacher_loss 0.2936 (0.3381) loss_zs_kd 6.6020 (6.0086) loss_oracle 1.0867 (1.0561) acc 87.5000 (86.8438) alaph_mean 0.9844 (0.9842) alpha_val 0.9844 (0.9842) lr 7.5131e-04 eta 0:08:54
epoch [31/50] batch [220/319] time 0.090 (0.086) data 0.000 (0.002) loss 1.2164 (1.3940) teacher_loss 0.1989 (0.3377) loss_zs_kd 5.8773 (6.0116) loss_oracle 1.0175 (1.0563) acc 96.8750 (87.0028) alaph_mean 0.9844 (0.9842) alpha_val 0.9844 (0.9842) lr 7.5131e-04 eta 0:08:48
epoch [31/50] batch [240/319] time 0.081 (0.086) data 0.000 (0.002) loss 1.5744 (1.3957) teacher_loss 0.5643 (0.3394) loss_zs_kd 5.9499 (6.0004) loss_oracle 1.0101 (1.0563) acc 75.0000 (86.8490) alaph_mean 0.9844 (0.9843) alpha_val 0.9844 (0.9843) lr 7.5131e-04 eta 0:08:45
epoch [31/50] batch [260/319] time 0.077 (0.085) data 0.000 (0.002) loss 1.3805 (1.3959) teacher_loss 0.3373 (0.3399) loss_zs_kd 5.8622 (5.9919) loss_oracle 1.0432 (1.0560) acc 90.6250 (86.8269) alaph_mean 0.9844 (0.9843) alpha_val 0.9844 (0.9843) lr 7.5131e-04 eta 0:08:40
epoch [31/50] batch [280/319] time 0.082 (0.085) data 0.000 (0.002) loss 1.3610 (1.4012) teacher_loss 0.3175 (0.3447) loss_zs_kd 5.8582 (5.9703) loss_oracle 1.0435 (1.0565) acc 84.3750 (86.5960) alaph_mean 0.9845 (0.9843) alpha_val 0.9845 (0.9843) lr 7.5131e-04 eta 0:08:38
epoch [31/50] batch [300/319] time 0.083 (0.085) data 0.000 (0.002) loss 1.2392 (1.4014) teacher_loss 0.1989 (0.3442) loss_zs_kd 6.0411 (5.9714) loss_oracle 1.0403 (1.0571) acc 90.6250 (86.6458) alaph_mean 0.9845 (0.9843) alpha_val 0.9845 (0.9843) lr 7.5131e-04 eta 0:08:35
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,658
* accuracy: 37.9%
* error: 62.1%
* macro_f1: 27.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 820
* accuracy: 8.4%
* error: 91.6%
* macro_f1: 6.7%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [32/50] batch [20/319] time 0.089 (0.120) data 0.000 (0.033) loss 1.3619 (1.3943) teacher_loss 0.2689 (0.3385) loss_zs_kd 5.7553 (6.0138) loss_oracle 1.0931 (1.0558) acc 87.5000 (86.5625) alaph_mean 0.9845 (0.9845) alpha_val 0.9845 (0.9845) lr 6.9098e-04 eta 0:12:05
epoch [32/50] batch [40/319] time 0.082 (0.100) data 0.000 (0.016) loss 1.4139 (1.4013) teacher_loss 0.3398 (0.3392) loss_zs_kd 5.8112 (6.0057) loss_oracle 1.0742 (1.0621) acc 87.5000 (86.4844) alaph_mean 0.9846 (0.9845) alpha_val 0.9846 (0.9845) lr 6.9098e-04 eta 0:10:01
epoch [32/50] batch [60/319] time 0.077 (0.095) data 0.000 (0.011) loss 1.3691 (1.3891) teacher_loss 0.3057 (0.3273) loss_zs_kd 5.7566 (5.9915) loss_oracle 1.0634 (1.0618) acc 87.5000 (87.1354) alaph_mean 0.9846 (0.9845) alpha_val 0.9846 (0.9845) lr 6.9098e-04 eta 0:09:27
epoch [32/50] batch [80/319] time 0.090 (0.092) data 0.000 (0.008) loss 1.2844 (1.3873) teacher_loss 0.2686 (0.3275) loss_zs_kd 5.7132 (5.9687) loss_oracle 1.0158 (1.0598) acc 87.5000 (87.1094) alaph_mean 0.9846 (0.9846) alpha_val 0.9846 (0.9846) lr 6.9098e-04 eta 0:09:10
epoch [32/50] batch [100/319] time 0.081 (0.091) data 0.000 (0.007) loss 1.2427 (1.3989) teacher_loss 0.1912 (0.3391) loss_zs_kd 5.7998 (5.9586) loss_oracle 1.0516 (1.0597) acc 96.8750 (86.8125) alaph_mean 0.9846 (0.9846) alpha_val 0.9846 (0.9846) lr 6.9098e-04 eta 0:09:00
epoch [32/50] batch [120/319] time 0.072 (0.089) data 0.000 (0.006) loss 1.3245 (1.3906) teacher_loss 0.2759 (0.3309) loss_zs_kd 6.1282 (5.9721) loss_oracle 1.0486 (1.0597) acc 90.6250 (87.0573) alaph_mean 0.9846 (0.9846) alpha_val 0.9846 (0.9846) lr 6.9098e-04 eta 0:08:47
epoch [32/50] batch [140/319] time 0.078 (0.088) data 0.000 (0.005) loss 1.4352 (1.3911) teacher_loss 0.3710 (0.3317) loss_zs_kd 6.3601 (5.9971) loss_oracle 1.0641 (1.0594) acc 90.6250 (87.0536) alaph_mean 0.9847 (0.9846) alpha_val 0.9847 (0.9846) lr 6.9098e-04 eta 0:08:38
epoch [32/50] batch [160/319] time 0.080 (0.087) data 0.000 (0.004) loss 1.3962 (1.3939) teacher_loss 0.3187 (0.3347) loss_zs_kd 6.2859 (6.0065) loss_oracle 1.0775 (1.0593) acc 87.5000 (86.9141) alaph_mean 0.9847 (0.9846) alpha_val 0.9847 (0.9846) lr 6.9098e-04 eta 0:08:32
epoch [32/50] batch [180/319] time 0.080 (0.086) data 0.000 (0.004) loss 1.4689 (1.3933) teacher_loss 0.3768 (0.3355) loss_zs_kd 5.5940 (5.9973) loss_oracle 1.0921 (1.0578) acc 84.3750 (86.7535) alaph_mean 0.9847 (0.9846) alpha_val 0.9847 (0.9846) lr 6.9098e-04 eta 0:08:26
epoch [32/50] batch [200/319] time 0.082 (0.086) data 0.000 (0.004) loss 1.4005 (1.3940) teacher_loss 0.3216 (0.3362) loss_zs_kd 5.9665 (5.9945) loss_oracle 1.0789 (1.0578) acc 84.3750 (86.6562) alaph_mean 0.9847 (0.9846) alpha_val 0.9847 (0.9846) lr 6.9098e-04 eta 0:08:22
epoch [32/50] batch [220/319] time 0.071 (0.085) data 0.000 (0.003) loss 1.3925 (1.3904) teacher_loss 0.3385 (0.3331) loss_zs_kd 5.8588 (5.9959) loss_oracle 1.0541 (1.0573) acc 84.3750 (86.7614) alaph_mean 0.9847 (0.9846) alpha_val 0.9847 (0.9846) lr 6.9098e-04 eta 0:08:17
epoch [32/50] batch [240/319] time 0.083 (0.085) data 0.000 (0.003) loss 1.1287 (1.3896) teacher_loss 0.1389 (0.3327) loss_zs_kd 5.7719 (6.0144) loss_oracle 0.9899 (1.0569) acc 93.7500 (86.7969) alaph_mean 0.9848 (0.9846) alpha_val 0.9848 (0.9846) lr 6.9098e-04 eta 0:08:15
epoch [32/50] batch [260/319] time 0.083 (0.085) data 0.000 (0.003) loss 1.3892 (1.3915) teacher_loss 0.3728 (0.3349) loss_zs_kd 6.1746 (6.0089) loss_oracle 1.0164 (1.0566) acc 81.2500 (86.6466) alaph_mean 0.9848 (0.9847) alpha_val 0.9848 (0.9847) lr 6.9098e-04 eta 0:08:12
epoch [32/50] batch [280/319] time 0.082 (0.085) data 0.000 (0.003) loss 1.6193 (1.3932) teacher_loss 0.5853 (0.3358) loss_zs_kd 5.7704 (6.0029) loss_oracle 1.0340 (1.0574) acc 81.2500 (86.6741) alaph_mean 0.9848 (0.9847) alpha_val 0.9848 (0.9847) lr 6.9098e-04 eta 0:08:11
epoch [32/50] batch [300/319] time 0.086 (0.085) data 0.000 (0.002) loss 1.3269 (1.3917) teacher_loss 0.2863 (0.3343) loss_zs_kd 6.0314 (5.9976) loss_oracle 1.0405 (1.0574) acc 87.5000 (86.6562) alaph_mean 0.9848 (0.9847) alpha_val 0.9848 (0.9847) lr 6.9098e-04 eta 0:08:08
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,608
* accuracy: 36.7%
* error: 63.3%
* macro_f1: 27.0%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 875
* accuracy: 9.0%
* error: 91.0%
* macro_f1: 7.0%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [33/50] batch [20/319] time 0.081 (0.111) data 0.000 (0.029) loss 1.5444 (1.4196) teacher_loss 0.4393 (0.3573) loss_zs_kd 5.6834 (6.0686) loss_oracle 1.1051 (1.0623) acc 87.5000 (86.8750) alaph_mean 0.9849 (0.9849) alpha_val 0.9849 (0.9849) lr 6.3188e-04 eta 0:10:33
epoch [33/50] batch [40/319] time 0.089 (0.094) data 0.000 (0.015) loss 1.3749 (1.3915) teacher_loss 0.3079 (0.3390) loss_zs_kd 5.6719 (5.9338) loss_oracle 1.0670 (1.0525) acc 90.6250 (88.0469) alaph_mean 0.9849 (0.9849) alpha_val 0.9849 (0.9849) lr 6.3188e-04 eta 0:08:58
epoch [33/50] batch [60/319] time 0.065 (0.088) data 0.001 (0.010) loss 1.1260 (1.3896) teacher_loss 0.0412 (0.3339) loss_zs_kd 5.9396 (5.8835) loss_oracle 1.0849 (1.0558) acc 100.0000 (87.6562) alaph_mean 0.9849 (0.9849) alpha_val 0.9849 (0.9849) lr 6.3188e-04 eta 0:08:20
epoch [33/50] batch [80/319] time 0.072 (0.085) data 0.000 (0.007) loss 1.3705 (1.3827) teacher_loss 0.2758 (0.3292) loss_zs_kd 6.0779 (5.8415) loss_oracle 1.0947 (1.0535) acc 90.6250 (87.8125) alaph_mean 0.9850 (0.9849) alpha_val 0.9850 (0.9849) lr 6.3188e-04 eta 0:08:03
epoch [33/50] batch [100/319] time 0.084 (0.085) data 0.000 (0.006) loss 1.4949 (1.3870) teacher_loss 0.3887 (0.3294) loss_zs_kd 5.6919 (5.8233) loss_oracle 1.1062 (1.0577) acc 84.3750 (87.6562) alaph_mean 0.9850 (0.9849) alpha_val 0.9850 (0.9849) lr 6.3188e-04 eta 0:07:57
epoch [33/50] batch [120/319] time 0.075 (0.087) data 0.000 (0.005) loss 1.5129 (1.3875) teacher_loss 0.4255 (0.3285) loss_zs_kd 5.4701 (5.7930) loss_oracle 1.0875 (1.0590) acc 84.3750 (87.6302) alaph_mean 0.9850 (0.9849) alpha_val 0.9850 (0.9849) lr 6.3188e-04 eta 0:08:09
epoch [33/50] batch [140/319] time 0.074 (0.086) data 0.000 (0.004) loss 1.2988 (1.3831) teacher_loss 0.2331 (0.3254) loss_zs_kd 6.0524 (5.7911) loss_oracle 1.0657 (1.0577) acc 90.6250 (87.9241) alaph_mean 0.9850 (0.9849) alpha_val 0.9850 (0.9849) lr 6.3188e-04 eta 0:07:59
epoch [33/50] batch [160/319] time 0.081 (0.085) data 0.000 (0.004) loss 1.2446 (1.3848) teacher_loss 0.2203 (0.3272) loss_zs_kd 5.6626 (5.7831) loss_oracle 1.0243 (1.0576) acc 90.6250 (87.7539) alaph_mean 0.9850 (0.9850) alpha_val 0.9850 (0.9850) lr 6.3188e-04 eta 0:07:56
epoch [33/50] batch [180/319] time 0.085 (0.085) data 0.000 (0.003) loss 1.5553 (1.3910) teacher_loss 0.4943 (0.3335) loss_zs_kd 5.8204 (5.7808) loss_oracle 1.0610 (1.0575) acc 84.3750 (87.4653) alaph_mean 0.9851 (0.9850) alpha_val 0.9851 (0.9850) lr 6.3188e-04 eta 0:07:54
epoch [33/50] batch [200/319] time 0.081 (0.084) data 0.000 (0.003) loss 1.4072 (1.3904) teacher_loss 0.3284 (0.3331) loss_zs_kd 6.1384 (5.7979) loss_oracle 1.0788 (1.0574) acc 90.6250 (87.4844) alaph_mean 0.9851 (0.9850) alpha_val 0.9851 (0.9850) lr 6.3188e-04 eta 0:07:47
epoch [33/50] batch [220/319] time 0.081 (0.084) data 0.000 (0.003) loss 1.2125 (1.3883) teacher_loss 0.1695 (0.3316) loss_zs_kd 6.1655 (5.8022) loss_oracle 1.0430 (1.0566) acc 93.7500 (87.4290) alaph_mean 0.9851 (0.9850) alpha_val 0.9851 (0.9850) lr 6.3188e-04 eta 0:07:42
epoch [33/50] batch [240/319] time 0.095 (0.084) data 0.000 (0.003) loss 1.3228 (1.3876) teacher_loss 0.2665 (0.3303) loss_zs_kd 5.9211 (5.8258) loss_oracle 1.0563 (1.0573) acc 90.6250 (87.4870) alaph_mean 0.9851 (0.9850) alpha_val 0.9851 (0.9850) lr 6.3188e-04 eta 0:07:42
epoch [33/50] batch [260/319] time 0.081 (0.084) data 0.000 (0.002) loss 1.5265 (1.3917) teacher_loss 0.4352 (0.3340) loss_zs_kd 6.1142 (5.8461) loss_oracle 1.0913 (1.0577) acc 84.3750 (87.3558) alaph_mean 0.9851 (0.9850) alpha_val 0.9851 (0.9850) lr 6.3188e-04 eta 0:07:40
epoch [33/50] batch [280/319] time 0.085 (0.084) data 0.000 (0.002) loss 1.3668 (1.3900) teacher_loss 0.3596 (0.3329) loss_zs_kd 6.0968 (5.8559) loss_oracle 1.0072 (1.0572) acc 84.3750 (87.3103) alaph_mean 0.9852 (0.9850) alpha_val 0.9852 (0.9850) lr 6.3188e-04 eta 0:07:37
epoch [33/50] batch [300/319] time 0.077 (0.083) data 0.000 (0.002) loss 1.3313 (1.3914) teacher_loss 0.2681 (0.3341) loss_zs_kd 5.8515 (5.8598) loss_oracle 1.0632 (1.0573) acc 90.6250 (87.3021) alaph_mean 0.9852 (0.9850) alpha_val 0.9852 (0.9850) lr 6.3188e-04 eta 0:07:33
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,552
* accuracy: 35.4%
* error: 64.6%
* macro_f1: 23.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 961
* accuracy: 9.9%
* error: 90.1%
* macro_f1: 6.9%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [34/50] batch [20/319] time 0.087 (0.116) data 0.000 (0.032) loss 1.6079 (1.4207) teacher_loss 0.5034 (0.3597) loss_zs_kd 6.0886 (6.0183) loss_oracle 1.1045 (1.0610) acc 84.3750 (85.4688) alaph_mean 0.9852 (0.9852) alpha_val 0.9852 (0.9852) lr 5.7422e-04 eta 0:10:29
epoch [34/50] batch [40/319] time 0.083 (0.100) data 0.000 (0.016) loss 1.3625 (1.4020) teacher_loss 0.3439 (0.3395) loss_zs_kd 5.8495 (6.0484) loss_oracle 1.0186 (1.0625) acc 84.3750 (86.3281) alaph_mean 0.9852 (0.9852) alpha_val 0.9852 (0.9852) lr 5.7422e-04 eta 0:08:56
epoch [34/50] batch [60/319] time 0.072 (0.093) data 0.000 (0.011) loss 1.5439 (1.3812) teacher_loss 0.5318 (0.3240) loss_zs_kd 6.2965 (6.0629) loss_oracle 1.0121 (1.0572) acc 68.7500 (86.9792) alaph_mean 0.9852 (0.9852) alpha_val 0.9852 (0.9852) lr 5.7422e-04 eta 0:08:18
epoch [34/50] batch [80/319] time 0.086 (0.090) data 0.000 (0.008) loss 1.5193 (1.3833) teacher_loss 0.4472 (0.3234) loss_zs_kd 6.6132 (6.0959) loss_oracle 1.0720 (1.0599) acc 81.2500 (87.1094) alaph_mean 0.9853 (0.9852) alpha_val 0.9853 (0.9852) lr 5.7422e-04 eta 0:08:02
epoch [34/50] batch [100/319] time 0.084 (0.089) data 0.000 (0.007) loss 1.4023 (1.3871) teacher_loss 0.3066 (0.3266) loss_zs_kd 6.6545 (6.1216) loss_oracle 1.0957 (1.0605) acc 93.7500 (87.1562) alaph_mean 0.9853 (0.9852) alpha_val 0.9853 (0.9852) lr 5.7422e-04 eta 0:07:55
epoch [34/50] batch [120/319] time 0.087 (0.088) data 0.000 (0.006) loss 1.4529 (1.3804) teacher_loss 0.3809 (0.3193) loss_zs_kd 6.1570 (6.1343) loss_oracle 1.0720 (1.0611) acc 84.3750 (87.5260) alaph_mean 0.9853 (0.9852) alpha_val 0.9853 (0.9852) lr 5.7422e-04 eta 0:07:49
epoch [34/50] batch [140/319] time 0.082 (0.088) data 0.000 (0.005) loss 1.3938 (1.3827) teacher_loss 0.3053 (0.3231) loss_zs_kd 6.5188 (6.1166) loss_oracle 1.0886 (1.0596) acc 87.5000 (87.2768) alaph_mean 0.9853 (0.9853) alpha_val 0.9853 (0.9853) lr 5.7422e-04 eta 0:07:43
epoch [34/50] batch [160/319] time 0.085 (0.088) data 0.000 (0.004) loss 1.3783 (1.3847) teacher_loss 0.3341 (0.3248) loss_zs_kd 6.5260 (6.1076) loss_oracle 1.0442 (1.0599) acc 81.2500 (87.3633) alaph_mean 0.9853 (0.9853) alpha_val 0.9853 (0.9853) lr 5.7422e-04 eta 0:07:42
epoch [34/50] batch [180/319] time 0.085 (0.087) data 0.000 (0.004) loss 1.4228 (1.3868) teacher_loss 0.4241 (0.3278) loss_zs_kd 6.4408 (6.0956) loss_oracle 0.9987 (1.0590) acc 84.3750 (87.1007) alaph_mean 0.9854 (0.9853) alpha_val 0.9854 (0.9853) lr 5.7422e-04 eta 0:07:37
epoch [34/50] batch [200/319] time 0.081 (0.087) data 0.000 (0.003) loss 1.2618 (1.3909) teacher_loss 0.1953 (0.3320) loss_zs_kd 6.1378 (6.0877) loss_oracle 1.0665 (1.0589) acc 90.6250 (86.8906) alaph_mean 0.9854 (0.9853) alpha_val 0.9854 (0.9853) lr 5.7422e-04 eta 0:07:33
epoch [34/50] batch [220/319] time 0.077 (0.087) data 0.000 (0.003) loss 1.3013 (1.3932) teacher_loss 0.2241 (0.3328) loss_zs_kd 5.8840 (6.0770) loss_oracle 1.0773 (1.0604) acc 93.7500 (86.8750) alaph_mean 0.9854 (0.9853) alpha_val 0.9854 (0.9853) lr 5.7422e-04 eta 0:07:30
epoch [34/50] batch [240/319] time 0.091 (0.086) data 0.000 (0.003) loss 1.4427 (1.3928) teacher_loss 0.3984 (0.3322) loss_zs_kd 5.8229 (6.0717) loss_oracle 1.0443 (1.0606) acc 93.7500 (86.8880) alaph_mean 0.9854 (0.9853) alpha_val 0.9854 (0.9853) lr 5.7422e-04 eta 0:07:26
epoch [34/50] batch [260/319] time 0.083 (0.086) data 0.000 (0.003) loss 1.2786 (1.3887) teacher_loss 0.2065 (0.3288) loss_zs_kd 5.6565 (6.0561) loss_oracle 1.0721 (1.0599) acc 93.7500 (87.0312) alaph_mean 0.9854 (0.9853) alpha_val 0.9854 (0.9853) lr 5.7422e-04 eta 0:07:23
epoch [34/50] batch [280/319] time 0.074 (0.086) data 0.000 (0.003) loss 1.3083 (1.3888) teacher_loss 0.2575 (0.3289) loss_zs_kd 6.1172 (6.0520) loss_oracle 1.0508 (1.0598) acc 90.6250 (86.9978) alaph_mean 0.9854 (0.9853) alpha_val 0.9854 (0.9853) lr 5.7422e-04 eta 0:07:20
epoch [34/50] batch [300/319] time 0.173 (0.086) data 0.001 (0.002) loss 1.4291 (1.3895) teacher_loss 0.3761 (0.3296) loss_zs_kd 6.3020 (6.0414) loss_oracle 1.0529 (1.0599) acc 87.5000 (86.9167) alaph_mean 0.9855 (0.9853) alpha_val 0.9855 (0.9853) lr 5.7422e-04 eta 0:07:18
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,460
* accuracy: 33.3%
* error: 66.7%
* macro_f1: 22.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 938
* accuracy: 9.6%
* error: 90.4%
* macro_f1: 6.9%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [35/50] batch [20/319] time 0.078 (0.116) data 0.000 (0.026) loss 1.4808 (1.3592) teacher_loss 0.3670 (0.3015) loss_zs_kd 6.7574 (6.2544) loss_oracle 1.1138 (1.0577) acc 81.2500 (88.2812) alaph_mean 0.9855 (0.9855) alpha_val 0.9855 (0.9855) lr 5.1825e-04 eta 0:09:50
epoch [35/50] batch [40/319] time 0.084 (0.099) data 0.000 (0.013) loss 1.3521 (1.3557) teacher_loss 0.3066 (0.3023) loss_zs_kd 5.5541 (6.1993) loss_oracle 1.0454 (1.0534) acc 90.6250 (88.1250) alaph_mean 0.9855 (0.9855) alpha_val 0.9855 (0.9855) lr 5.1825e-04 eta 0:08:23
epoch [35/50] batch [60/319] time 0.083 (0.094) data 0.000 (0.009) loss 1.4662 (1.3795) teacher_loss 0.4340 (0.3255) loss_zs_kd 5.7423 (6.1369) loss_oracle 1.0322 (1.0540) acc 81.2500 (87.3958) alaph_mean 0.9855 (0.9855) alpha_val 0.9855 (0.9855) lr 5.1825e-04 eta 0:07:55
epoch [35/50] batch [80/319] time 0.086 (0.092) data 0.000 (0.007) loss 1.3581 (1.3815) teacher_loss 0.3049 (0.3231) loss_zs_kd 5.9772 (6.0496) loss_oracle 1.0533 (1.0584) acc 90.6250 (87.3438) alaph_mean 0.9855 (0.9855) alpha_val 0.9855 (0.9855) lr 5.1825e-04 eta 0:07:41
epoch [35/50] batch [100/319] time 0.136 (0.091) data 0.000 (0.005) loss 1.5677 (1.3779) teacher_loss 0.4646 (0.3214) loss_zs_kd 6.0840 (6.0148) loss_oracle 1.1031 (1.0565) acc 81.2500 (87.2500) alaph_mean 0.9856 (0.9855) alpha_val 0.9856 (0.9855) lr 5.1825e-04 eta 0:07:36
epoch [35/50] batch [120/319] time 0.088 (0.092) data 0.000 (0.005) loss 1.5569 (1.3780) teacher_loss 0.4957 (0.3208) loss_zs_kd 5.8163 (6.0137) loss_oracle 1.0612 (1.0572) acc 87.5000 (87.1354) alaph_mean 0.9856 (0.9855) alpha_val 0.9856 (0.9855) lr 5.1825e-04 eta 0:07:37
epoch [35/50] batch [140/319] time 0.083 (0.091) data 0.000 (0.004) loss 1.3896 (1.3764) teacher_loss 0.3650 (0.3190) loss_zs_kd 6.6327 (6.0206) loss_oracle 1.0246 (1.0573) acc 84.3750 (87.4107) alaph_mean 0.9856 (0.9855) alpha_val 0.9856 (0.9855) lr 5.1825e-04 eta 0:07:29
epoch [35/50] batch [160/319] time 0.086 (0.090) data 0.000 (0.004) loss 1.6636 (1.3825) teacher_loss 0.6206 (0.3235) loss_zs_kd 6.2192 (6.0426) loss_oracle 1.0429 (1.0590) acc 75.0000 (87.2656) alaph_mean 0.9856 (0.9855) alpha_val 0.9856 (0.9855) lr 5.1825e-04 eta 0:07:24
epoch [35/50] batch [180/319] time 0.071 (0.089) data 0.000 (0.003) loss 1.3691 (1.3868) teacher_loss 0.3653 (0.3278) loss_zs_kd 6.0541 (6.0429) loss_oracle 1.0037 (1.0591) acc 84.3750 (87.1354) alaph_mean 0.9856 (0.9856) alpha_val 0.9856 (0.9856) lr 5.1825e-04 eta 0:07:19
epoch [35/50] batch [200/319] time 0.082 (0.088) data 0.000 (0.003) loss 1.3957 (1.3961) teacher_loss 0.3363 (0.3360) loss_zs_kd 6.0031 (6.0322) loss_oracle 1.0594 (1.0601) acc 81.2500 (86.7969) alaph_mean 0.9856 (0.9856) alpha_val 0.9856 (0.9856) lr 5.1825e-04 eta 0:07:12
epoch [35/50] batch [220/319] time 0.084 (0.088) data 0.000 (0.003) loss 1.4961 (1.3935) teacher_loss 0.3861 (0.3342) loss_zs_kd 5.8014 (6.0154) loss_oracle 1.1100 (1.0593) acc 90.6250 (86.9034) alaph_mean 0.9857 (0.9856) alpha_val 0.9857 (0.9856) lr 5.1825e-04 eta 0:07:07
epoch [35/50] batch [240/319] time 0.077 (0.087) data 0.000 (0.002) loss 1.3847 (1.3947) teacher_loss 0.2973 (0.3353) loss_zs_kd 6.4418 (6.0124) loss_oracle 1.0874 (1.0594) acc 90.6250 (86.9010) alaph_mean 0.9857 (0.9856) alpha_val 0.9857 (0.9856) lr 5.1825e-04 eta 0:07:03
epoch [35/50] batch [260/319] time 0.078 (0.087) data 0.000 (0.002) loss 1.1596 (1.3917) teacher_loss 0.1738 (0.3328) loss_zs_kd 6.1471 (6.0192) loss_oracle 0.9858 (1.0589) acc 93.7500 (86.9351) alaph_mean 0.9857 (0.9856) alpha_val 0.9857 (0.9856) lr 5.1825e-04 eta 0:07:00
epoch [35/50] batch [280/319] time 0.078 (0.086) data 0.000 (0.002) loss 1.4471 (1.3940) teacher_loss 0.3863 (0.3343) loss_zs_kd 6.5644 (6.0318) loss_oracle 1.0608 (1.0598) acc 84.3750 (86.9420) alaph_mean 0.9857 (0.9856) alpha_val 0.9857 (0.9856) lr 5.1825e-04 eta 0:06:56
epoch [35/50] batch [300/319] time 0.080 (0.086) data 0.000 (0.002) loss 1.1939 (1.3934) teacher_loss 0.1675 (0.3344) loss_zs_kd 6.8709 (6.0511) loss_oracle 1.0265 (1.0590) acc 96.8750 (87.0521) alaph_mean 0.9857 (0.9856) alpha_val 0.9857 (0.9856) lr 5.1825e-04 eta 0:06:53
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,428
* accuracy: 32.6%
* error: 67.4%
* macro_f1: 22.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 1,147
* accuracy: 11.8%
* error: 88.2%
* macro_f1: 7.3%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [36/50] batch [20/319] time 0.080 (0.118) data 0.000 (0.031) loss 1.4971 (1.4017) teacher_loss 0.4994 (0.3420) loss_zs_kd 5.5089 (6.2786) loss_oracle 0.9978 (1.0597) acc 90.6250 (87.6562) alaph_mean 0.9857 (0.9857) alpha_val 0.9857 (0.9857) lr 4.6417e-04 eta 0:09:21
epoch [36/50] batch [40/319] time 0.082 (0.101) data 0.000 (0.016) loss 1.4534 (1.4295) teacher_loss 0.3855 (0.3621) loss_zs_kd 5.5603 (6.1865) loss_oracle 1.0680 (1.0673) acc 84.3750 (86.7188) alaph_mean 0.9858 (0.9857) alpha_val 0.9858 (0.9857) lr 4.6417e-04 eta 0:07:56
epoch [36/50] batch [60/319] time 0.083 (0.095) data 0.000 (0.011) loss 1.3477 (1.4052) teacher_loss 0.3260 (0.3436) loss_zs_kd 5.8040 (6.1421) loss_oracle 1.0217 (1.0615) acc 93.7500 (87.1875) alaph_mean 0.9858 (0.9857) alpha_val 0.9858 (0.9857) lr 4.6417e-04 eta 0:07:29
epoch [36/50] batch [80/319] time 0.077 (0.093) data 0.000 (0.008) loss 1.3166 (1.4040) teacher_loss 0.2747 (0.3436) loss_zs_kd 6.3441 (6.1498) loss_oracle 1.0418 (1.0604) acc 84.3750 (87.2656) alaph_mean 0.9858 (0.9858) alpha_val 0.9858 (0.9858) lr 4.6417e-04 eta 0:07:15
epoch [36/50] batch [100/319] time 0.082 (0.091) data 0.000 (0.007) loss 1.3356 (1.3972) teacher_loss 0.2486 (0.3396) loss_zs_kd 6.4909 (6.1489) loss_oracle 1.0870 (1.0576) acc 93.7500 (87.2188) alaph_mean 0.9858 (0.9858) alpha_val 0.9858 (0.9858) lr 4.6417e-04 eta 0:07:05
epoch [36/50] batch [120/319] time 0.090 (0.090) data 0.000 (0.005) loss 1.4507 (1.3970) teacher_loss 0.3639 (0.3402) loss_zs_kd 6.0547 (6.1379) loss_oracle 1.0868 (1.0568) acc 81.2500 (87.0833) alaph_mean 0.9858 (0.9858) alpha_val 0.9858 (0.9858) lr 4.6417e-04 eta 0:06:59
epoch [36/50] batch [140/319] time 0.083 (0.089) data 0.000 (0.005) loss 1.3912 (1.3953) teacher_loss 0.3304 (0.3395) loss_zs_kd 5.9712 (6.1255) loss_oracle 1.0608 (1.0557) acc 87.5000 (86.9866) alaph_mean 0.9858 (0.9858) alpha_val 0.9858 (0.9858) lr 4.6417e-04 eta 0:06:55
epoch [36/50] batch [160/319] time 0.085 (0.088) data 0.000 (0.004) loss 1.3317 (1.3956) teacher_loss 0.3302 (0.3391) loss_zs_kd 6.4205 (6.1387) loss_oracle 1.0015 (1.0565) acc 90.6250 (86.9922) alaph_mean 0.9858 (0.9858) alpha_val 0.9858 (0.9858) lr 4.6417e-04 eta 0:06:49
epoch [36/50] batch [180/319] time 0.088 (0.088) data 0.000 (0.004) loss 1.3698 (1.3930) teacher_loss 0.2824 (0.3360) loss_zs_kd 6.7006 (6.1350) loss_oracle 1.0873 (1.0570) acc 90.6250 (87.2222) alaph_mean 0.9859 (0.9858) alpha_val 0.9859 (0.9858) lr 4.6417e-04 eta 0:06:46
epoch [36/50] batch [200/319] time 0.091 (0.088) data 0.000 (0.003) loss 1.3770 (1.3923) teacher_loss 0.3256 (0.3349) loss_zs_kd 6.3112 (6.1282) loss_oracle 1.0514 (1.0574) acc 90.6250 (87.2344) alaph_mean 0.9859 (0.9858) alpha_val 0.9859 (0.9858) lr 4.6417e-04 eta 0:06:42
epoch [36/50] batch [220/319] time 0.092 (0.088) data 0.000 (0.003) loss 1.2631 (1.3901) teacher_loss 0.2532 (0.3333) loss_zs_kd 6.2984 (6.1053) loss_oracle 1.0098 (1.0568) acc 90.6250 (87.2159) alaph_mean 0.9859 (0.9858) alpha_val 0.9859 (0.9858) lr 4.6417e-04 eta 0:06:39
epoch [36/50] batch [240/319] time 0.083 (0.087) data 0.000 (0.003) loss 1.3239 (1.3905) teacher_loss 0.2155 (0.3330) loss_zs_kd 5.9967 (6.0977) loss_oracle 1.1084 (1.0576) acc 93.7500 (87.2135) alaph_mean 0.9859 (0.9858) alpha_val 0.9859 (0.9858) lr 4.6417e-04 eta 0:06:36
epoch [36/50] batch [260/319] time 0.087 (0.087) data 0.001 (0.003) loss 1.4741 (1.3913) teacher_loss 0.3992 (0.3331) loss_zs_kd 5.9270 (6.0894) loss_oracle 1.0749 (1.0582) acc 84.3750 (87.1635) alaph_mean 0.9859 (0.9858) alpha_val 0.9859 (0.9858) lr 4.6417e-04 eta 0:06:33
epoch [36/50] batch [280/319] time 0.148 (0.088) data 0.001 (0.003) loss 1.4775 (1.3902) teacher_loss 0.3794 (0.3315) loss_zs_kd 6.0637 (6.0938) loss_oracle 1.0980 (1.0587) acc 84.3750 (87.2433) alaph_mean 0.9859 (0.9858) alpha_val 0.9859 (0.9858) lr 4.6417e-04 eta 0:06:34
epoch [36/50] batch [300/319] time 0.083 (0.088) data 0.000 (0.002) loss 1.4142 (1.3889) teacher_loss 0.2944 (0.3299) loss_zs_kd 5.5922 (6.0867) loss_oracle 1.1198 (1.0589) acc 90.6250 (87.3333) alaph_mean 0.9859 (0.9858) alpha_val 0.9859 (0.9858) lr 4.6417e-04 eta 0:06:32
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,447
* accuracy: 33.1%
* error: 66.9%
* macro_f1: 24.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 782
* accuracy: 8.0%
* error: 92.0%
* macro_f1: 6.8%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [37/50] batch [20/319] time 0.079 (0.111) data 0.000 (0.027) loss 1.3851 (1.3925) teacher_loss 0.3298 (0.3341) loss_zs_kd 5.8479 (6.0478) loss_oracle 1.0553 (1.0583) acc 84.3750 (87.5000) alaph_mean 0.9860 (0.9860) alpha_val 0.9860 (0.9860) lr 4.1221e-04 eta 0:08:11
epoch [37/50] batch [40/319] time 0.084 (0.095) data 0.000 (0.014) loss 1.6492 (1.3864) teacher_loss 0.6453 (0.3269) loss_zs_kd 6.1420 (6.1508) loss_oracle 1.0039 (1.0595) acc 75.0000 (87.5000) alaph_mean 0.9860 (0.9860) alpha_val 0.9860 (0.9860) lr 4.1221e-04 eta 0:07:00
epoch [37/50] batch [60/319] time 0.074 (0.091) data 0.000 (0.009) loss 1.3265 (1.3833) teacher_loss 0.2094 (0.3227) loss_zs_kd 6.2272 (6.1369) loss_oracle 1.1171 (1.0606) acc 96.8750 (87.7083) alaph_mean 0.9860 (0.9860) alpha_val 0.9860 (0.9860) lr 4.1221e-04 eta 0:06:39
epoch [37/50] batch [80/319] time 0.084 (0.088) data 0.000 (0.007) loss 1.3128 (1.3855) teacher_loss 0.2788 (0.3269) loss_zs_kd 5.9417 (6.1617) loss_oracle 1.0340 (1.0586) acc 90.6250 (87.2656) alaph_mean 0.9860 (0.9860) alpha_val 0.9860 (0.9860) lr 4.1221e-04 eta 0:06:27
epoch [37/50] batch [100/319] time 0.079 (0.090) data 0.000 (0.006) loss 1.3228 (1.3767) teacher_loss 0.2539 (0.3180) loss_zs_kd 6.9923 (6.2242) loss_oracle 1.0689 (1.0587) acc 90.6250 (87.3750) alaph_mean 0.9860 (0.9860) alpha_val 0.9860 (0.9860) lr 4.1221e-04 eta 0:06:31
epoch [37/50] batch [120/319] time 0.083 (0.089) data 0.000 (0.005) loss 1.5899 (1.3851) teacher_loss 0.5089 (0.3257) loss_zs_kd 5.9523 (6.2263) loss_oracle 1.0810 (1.0595) acc 84.3750 (87.2917) alaph_mean 0.9860 (0.9860) alpha_val 0.9860 (0.9860) lr 4.1221e-04 eta 0:06:25
epoch [37/50] batch [140/319] time 0.073 (0.088) data 0.000 (0.004) loss 1.2338 (1.3829) teacher_loss 0.1522 (0.3220) loss_zs_kd 6.0859 (6.2110) loss_oracle 1.0816 (1.0609) acc 100.0000 (87.3214) alaph_mean 0.9860 (0.9860) alpha_val 0.9860 (0.9860) lr 4.1221e-04 eta 0:06:19
epoch [37/50] batch [160/319] time 0.083 (0.087) data 0.000 (0.004) loss 1.4592 (1.3864) teacher_loss 0.4242 (0.3268) loss_zs_kd 6.1840 (6.2044) loss_oracle 1.0350 (1.0596) acc 84.3750 (87.1680) alaph_mean 0.9861 (0.9860) alpha_val 0.9861 (0.9860) lr 4.1221e-04 eta 0:06:13
epoch [37/50] batch [180/319] time 0.081 (0.086) data 0.000 (0.003) loss 1.5269 (1.3898) teacher_loss 0.4583 (0.3292) loss_zs_kd 6.6030 (6.1964) loss_oracle 1.0686 (1.0606) acc 78.1250 (87.0486) alaph_mean 0.9861 (0.9860) alpha_val 0.9861 (0.9860) lr 4.1221e-04 eta 0:06:10
epoch [37/50] batch [200/319] time 0.083 (0.086) data 0.000 (0.003) loss 1.3336 (1.3901) teacher_loss 0.2969 (0.3304) loss_zs_kd 5.6218 (6.1817) loss_oracle 1.0367 (1.0597) acc 84.3750 (87.0469) alaph_mean 0.9861 (0.9860) alpha_val 0.9861 (0.9860) lr 4.1221e-04 eta 0:06:08
epoch [37/50] batch [220/319] time 0.094 (0.086) data 0.000 (0.003) loss 1.4716 (1.3865) teacher_loss 0.4006 (0.3274) loss_zs_kd 5.8622 (6.1426) loss_oracle 1.0710 (1.0591) acc 84.3750 (87.1591) alaph_mean 0.9861 (0.9860) alpha_val 0.9861 (0.9860) lr 4.1221e-04 eta 0:06:05
epoch [37/50] batch [240/319] time 0.083 (0.086) data 0.000 (0.003) loss 1.5809 (1.3860) teacher_loss 0.5051 (0.3268) loss_zs_kd 5.6226 (6.1309) loss_oracle 1.0758 (1.0592) acc 87.5000 (87.2005) alaph_mean 0.9861 (0.9860) alpha_val 0.9861 (0.9860) lr 4.1221e-04 eta 0:06:04
epoch [37/50] batch [260/319] time 0.081 (0.086) data 0.000 (0.002) loss 1.4444 (1.3918) teacher_loss 0.3124 (0.3314) loss_zs_kd 5.8246 (6.1181) loss_oracle 1.1320 (1.0604) acc 90.6250 (87.1394) alaph_mean 0.9861 (0.9860) alpha_val 0.9861 (0.9860) lr 4.1221e-04 eta 0:06:02
epoch [37/50] batch [280/319] time 0.081 (0.086) data 0.000 (0.002) loss 1.3546 (1.3909) teacher_loss 0.3294 (0.3312) loss_zs_kd 5.9573 (6.1014) loss_oracle 1.0252 (1.0597) acc 81.2500 (87.1429) alaph_mean 0.9861 (0.9860) alpha_val 0.9861 (0.9860) lr 4.1221e-04 eta 0:05:59
epoch [37/50] batch [300/319] time 0.080 (0.086) data 0.000 (0.002) loss 1.2221 (1.3872) teacher_loss 0.1925 (0.3287) loss_zs_kd 6.2355 (6.0910) loss_oracle 1.0296 (1.0585) acc 96.8750 (87.2604) alaph_mean 0.9861 (0.9860) alpha_val 0.9861 (0.9860) lr 4.1221e-04 eta 0:05:56
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,412
* accuracy: 32.3%
* error: 67.7%
* macro_f1: 22.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 994
* accuracy: 10.2%
* error: 89.8%
* macro_f1: 6.9%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [38/50] batch [20/319] time 0.084 (0.109) data 0.000 (0.027) loss 1.2597 (1.4043) teacher_loss 0.1978 (0.3609) loss_zs_kd 6.6115 (6.0787) loss_oracle 1.0620 (1.0433) acc 93.7500 (84.8438) alaph_mean 0.9862 (0.9862) alpha_val 0.9862 (0.9862) lr 3.6258e-04 eta 0:07:30
epoch [38/50] batch [40/319] time 0.087 (0.097) data 0.000 (0.014) loss 1.4980 (1.3948) teacher_loss 0.4378 (0.3481) loss_zs_kd 6.3538 (6.0492) loss_oracle 1.0602 (1.0467) acc 78.1250 (85.8594) alaph_mean 0.9862 (0.9862) alpha_val 0.9862 (0.9862) lr 3.6258e-04 eta 0:06:36
epoch [38/50] batch [60/319] time 0.085 (0.091) data 0.000 (0.009) loss 1.4982 (1.4042) teacher_loss 0.4772 (0.3555) loss_zs_kd 6.1846 (6.0693) loss_oracle 1.0210 (1.0487) acc 90.6250 (85.9375) alaph_mean 0.9862 (0.9862) alpha_val 0.9862 (0.9862) lr 3.6258e-04 eta 0:06:12
epoch [38/50] batch [80/319] time 0.093 (0.089) data 0.000 (0.007) loss 1.5066 (1.3913) teacher_loss 0.3623 (0.3393) loss_zs_kd 6.7282 (6.0991) loss_oracle 1.1443 (1.0520) acc 81.2500 (86.5625) alaph_mean 0.9862 (0.9862) alpha_val 0.9862 (0.9862) lr 3.6258e-04 eta 0:06:02
epoch [38/50] batch [100/319] time 0.083 (0.087) data 0.000 (0.006) loss 1.4355 (1.3860) teacher_loss 0.3847 (0.3323) loss_zs_kd 5.8868 (6.0922) loss_oracle 1.0508 (1.0537) acc 87.5000 (86.9062) alaph_mean 0.9862 (0.9862) alpha_val 0.9862 (0.9862) lr 3.6258e-04 eta 0:05:53
epoch [38/50] batch [120/319] time 0.084 (0.086) data 0.000 (0.005) loss 1.3497 (1.3834) teacher_loss 0.3069 (0.3301) loss_zs_kd 6.1219 (6.0880) loss_oracle 1.0429 (1.0533) acc 84.3750 (87.0573) alaph_mean 0.9862 (0.9862) alpha_val 0.9862 (0.9862) lr 3.6258e-04 eta 0:05:48
epoch [38/50] batch [140/319] time 0.092 (0.086) data 0.000 (0.004) loss 1.3939 (1.3917) teacher_loss 0.2960 (0.3375) loss_zs_kd 6.0272 (6.0830) loss_oracle 1.0979 (1.0542) acc 87.5000 (86.6964) alaph_mean 0.9862 (0.9862) alpha_val 0.9862 (0.9862) lr 3.6258e-04 eta 0:05:45
epoch [38/50] batch [160/319] time 0.083 (0.086) data 0.000 (0.004) loss 1.3980 (1.3911) teacher_loss 0.3269 (0.3363) loss_zs_kd 6.4252 (6.0777) loss_oracle 1.0711 (1.0548) acc 81.2500 (86.7578) alaph_mean 0.9862 (0.9862) alpha_val 0.9862 (0.9862) lr 3.6258e-04 eta 0:05:42
epoch [38/50] batch [180/319] time 0.082 (0.086) data 0.000 (0.003) loss 1.4232 (1.3965) teacher_loss 0.3731 (0.3401) loss_zs_kd 5.4485 (6.0829) loss_oracle 1.0501 (1.0564) acc 84.3750 (86.6146) alaph_mean 0.9863 (0.9862) alpha_val 0.9863 (0.9862) lr 3.6258e-04 eta 0:05:40
epoch [38/50] batch [200/319] time 0.081 (0.086) data 0.000 (0.003) loss 1.3539 (1.3957) teacher_loss 0.2806 (0.3377) loss_zs_kd 5.9573 (6.0879) loss_oracle 1.0733 (1.0580) acc 87.5000 (86.7031) alaph_mean 0.9863 (0.9862) alpha_val 0.9863 (0.9862) lr 3.6258e-04 eta 0:05:37
epoch [38/50] batch [220/319] time 0.082 (0.086) data 0.000 (0.003) loss 1.6422 (1.3955) teacher_loss 0.5408 (0.3381) loss_zs_kd 5.6439 (6.0746) loss_oracle 1.1015 (1.0574) acc 87.5000 (86.7188) alaph_mean 0.9863 (0.9862) alpha_val 0.9863 (0.9862) lr 3.6258e-04 eta 0:05:35
epoch [38/50] batch [240/319] time 0.075 (0.085) data 0.000 (0.003) loss 1.2785 (1.3931) teacher_loss 0.2768 (0.3362) loss_zs_kd 5.6849 (6.0817) loss_oracle 1.0017 (1.0568) acc 90.6250 (86.7839) alaph_mean 0.9863 (0.9862) alpha_val 0.9863 (0.9862) lr 3.6258e-04 eta 0:05:31
epoch [38/50] batch [260/319] time 0.086 (0.086) data 0.000 (0.002) loss 1.5989 (1.3945) teacher_loss 0.5418 (0.3373) loss_zs_kd 6.3519 (6.0760) loss_oracle 1.0571 (1.0572) acc 84.3750 (86.8029) alaph_mean 0.9863 (0.9862) alpha_val 0.9863 (0.9862) lr 3.6258e-04 eta 0:05:35
epoch [38/50] batch [280/319] time 0.076 (0.086) data 0.000 (0.002) loss 1.2426 (1.3906) teacher_loss 0.1939 (0.3337) loss_zs_kd 6.4613 (6.0787) loss_oracle 1.0487 (1.0570) acc 96.8750 (87.0871) alaph_mean 0.9863 (0.9862) alpha_val 0.9863 (0.9862) lr 3.6258e-04 eta 0:05:31
epoch [38/50] batch [300/319] time 0.078 (0.085) data 0.000 (0.002) loss 1.4172 (1.3912) teacher_loss 0.3115 (0.3334) loss_zs_kd 6.3274 (6.0726) loss_oracle 1.1057 (1.0579) acc 84.3750 (87.1042) alaph_mean 0.9863 (0.9862) alpha_val 0.9863 (0.9862) lr 3.6258e-04 eta 0:05:28
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,598
* accuracy: 36.5%
* error: 63.5%
* macro_f1: 24.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 779
* accuracy: 8.0%
* error: 92.0%
* macro_f1: 6.7%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [39/50] batch [20/319] time 0.074 (0.117) data 0.000 (0.033) loss 1.3870 (1.3926) teacher_loss 0.3175 (0.3414) loss_zs_kd 6.1735 (5.9567) loss_oracle 1.0695 (1.0512) acc 84.3750 (86.7188) alaph_mean 0.9863 (0.9863) alpha_val 0.9863 (0.9863) lr 3.1545e-04 eta 0:07:26
epoch [39/50] batch [40/319] time 0.078 (0.098) data 0.000 (0.017) loss 1.6746 (1.4054) teacher_loss 0.6072 (0.3427) loss_zs_kd 6.1909 (5.9280) loss_oracle 1.0674 (1.0627) acc 78.1250 (86.4844) alaph_mean 0.9864 (0.9863) alpha_val 0.9864 (0.9863) lr 3.1545e-04 eta 0:06:09
epoch [39/50] batch [60/319] time 0.074 (0.097) data 0.001 (0.011) loss 1.2551 (1.3957) teacher_loss 0.1989 (0.3359) loss_zs_kd 5.7628 (5.8685) loss_oracle 1.0562 (1.0598) acc 87.5000 (86.6146) alaph_mean 0.9864 (0.9863) alpha_val 0.9864 (0.9863) lr 3.1545e-04 eta 0:06:06
epoch [39/50] batch [80/319] time 0.079 (0.093) data 0.000 (0.008) loss 1.4413 (1.3877) teacher_loss 0.3423 (0.3285) loss_zs_kd 5.8816 (5.8783) loss_oracle 1.0990 (1.0591) acc 87.5000 (86.7578) alaph_mean 0.9864 (0.9864) alpha_val 0.9864 (0.9864) lr 3.1545e-04 eta 0:05:48
epoch [39/50] batch [100/319] time 0.073 (0.090) data 0.000 (0.007) loss 1.4828 (1.3945) teacher_loss 0.3733 (0.3328) loss_zs_kd 6.1107 (5.8790) loss_oracle 1.1095 (1.0617) acc 84.3750 (86.4375) alaph_mean 0.9864 (0.9864) alpha_val 0.9864 (0.9864) lr 3.1545e-04 eta 0:05:36
epoch [39/50] batch [120/319] time 0.087 (0.089) data 0.000 (0.006) loss 1.5483 (1.3858) teacher_loss 0.4686 (0.3248) loss_zs_kd 5.6099 (5.9128) loss_oracle 1.0798 (1.0611) acc 84.3750 (86.8490) alaph_mean 0.9864 (0.9864) alpha_val 0.9864 (0.9864) lr 3.1545e-04 eta 0:05:28
epoch [39/50] batch [140/319] time 0.078 (0.088) data 0.000 (0.005) loss 1.3184 (1.3890) teacher_loss 0.1982 (0.3290) loss_zs_kd 5.8673 (5.9333) loss_oracle 1.1202 (1.0600) acc 90.6250 (86.8973) alaph_mean 0.9864 (0.9864) alpha_val 0.9864 (0.9864) lr 3.1545e-04 eta 0:05:23
epoch [39/50] batch [160/319] time 0.079 (0.087) data 0.000 (0.004) loss 1.4199 (1.3882) teacher_loss 0.3062 (0.3281) loss_zs_kd 6.0627 (5.9461) loss_oracle 1.1137 (1.0601) acc 87.5000 (86.6992) alaph_mean 0.9864 (0.9864) alpha_val 0.9864 (0.9864) lr 3.1545e-04 eta 0:05:18
epoch [39/50] batch [180/319] time 0.083 (0.086) data 0.000 (0.004) loss 1.3626 (1.3881) teacher_loss 0.2568 (0.3278) loss_zs_kd 5.6645 (5.9371) loss_oracle 1.1058 (1.0603) acc 90.6250 (86.7188) alaph_mean 0.9864 (0.9864) alpha_val 0.9864 (0.9864) lr 3.1545e-04 eta 0:05:13
epoch [39/50] batch [200/319] time 0.074 (0.086) data 0.000 (0.004) loss 1.2016 (1.3855) teacher_loss 0.1819 (0.3255) loss_zs_kd 6.0282 (5.9505) loss_oracle 1.0197 (1.0600) acc 93.7500 (86.9219) alaph_mean 0.9864 (0.9864) alpha_val 0.9864 (0.9864) lr 3.1545e-04 eta 0:05:10
epoch [39/50] batch [220/319] time 0.076 (0.085) data 0.000 (0.003) loss 1.4266 (1.3841) teacher_loss 0.3565 (0.3250) loss_zs_kd 5.8071 (5.9503) loss_oracle 1.0701 (1.0591) acc 84.3750 (86.9744) alaph_mean 0.9864 (0.9864) alpha_val 0.9864 (0.9864) lr 3.1545e-04 eta 0:05:07
epoch [39/50] batch [240/319] time 0.078 (0.085) data 0.000 (0.003) loss 1.6609 (1.3877) teacher_loss 0.5995 (0.3287) loss_zs_kd 5.5790 (5.9430) loss_oracle 1.0614 (1.0590) acc 78.1250 (86.8880) alaph_mean 0.9865 (0.9864) alpha_val 0.9865 (0.9864) lr 3.1545e-04 eta 0:05:04
epoch [39/50] batch [260/319] time 0.082 (0.084) data 0.000 (0.003) loss 1.3120 (1.3873) teacher_loss 0.2691 (0.3294) loss_zs_kd 5.6996 (5.9364) loss_oracle 1.0430 (1.0579) acc 90.6250 (86.9712) alaph_mean 0.9865 (0.9864) alpha_val 0.9865 (0.9864) lr 3.1545e-04 eta 0:05:00
epoch [39/50] batch [280/319] time 0.085 (0.084) data 0.000 (0.003) loss 1.6325 (1.3882) teacher_loss 0.5529 (0.3300) loss_zs_kd 6.1534 (5.9260) loss_oracle 1.0796 (1.0582) acc 68.7500 (86.9643) alaph_mean 0.9865 (0.9864) alpha_val 0.9865 (0.9864) lr 3.1545e-04 eta 0:04:59
epoch [39/50] batch [300/319] time 0.069 (0.085) data 0.000 (0.002) loss 1.3332 (1.3886) teacher_loss 0.2577 (0.3299) loss_zs_kd 6.2927 (5.9158) loss_oracle 1.0754 (1.0587) acc 90.6250 (86.9375) alaph_mean 0.9865 (0.9864) alpha_val 0.9865 (0.9864) lr 3.1545e-04 eta 0:04:58
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,596
* accuracy: 36.5%
* error: 63.5%
* macro_f1: 25.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 833
* accuracy: 8.6%
* error: 91.4%
* macro_f1: 7.1%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [40/50] batch [20/319] time 0.071 (0.110) data 0.000 (0.026) loss 1.3113 (1.3483) teacher_loss 0.3134 (0.3095) loss_zs_kd 6.0966 (5.9310) loss_oracle 0.9979 (1.0387) acc 90.6250 (88.1250) alaph_mean 0.9865 (0.9865) alpha_val 0.9865 (0.9865) lr 2.7103e-04 eta 0:06:22
epoch [40/50] batch [40/319] time 0.082 (0.094) data 0.000 (0.013) loss 1.2631 (1.3620) teacher_loss 0.2483 (0.3143) loss_zs_kd 6.1094 (5.9253) loss_oracle 1.0148 (1.0477) acc 90.6250 (88.3594) alaph_mean 0.9865 (0.9865) alpha_val 0.9865 (0.9865) lr 2.7103e-04 eta 0:05:24
epoch [40/50] batch [60/319] time 0.076 (0.090) data 0.000 (0.009) loss 1.3297 (1.3719) teacher_loss 0.2792 (0.3198) loss_zs_kd 5.8106 (5.8945) loss_oracle 1.0505 (1.0522) acc 96.8750 (88.4896) alaph_mean 0.9865 (0.9865) alpha_val 0.9865 (0.9865) lr 2.7103e-04 eta 0:05:10
epoch [40/50] batch [80/319] time 0.097 (0.088) data 0.000 (0.007) loss 1.2724 (1.3663) teacher_loss 0.2495 (0.3145) loss_zs_kd 5.8205 (5.8991) loss_oracle 1.0229 (1.0518) acc 93.7500 (88.7500) alaph_mean 0.9865 (0.9865) alpha_val 0.9865 (0.9865) lr 2.7103e-04 eta 0:05:03
epoch [40/50] batch [100/319] time 0.089 (0.088) data 0.000 (0.005) loss 1.2561 (1.3681) teacher_loss 0.2416 (0.3147) loss_zs_kd 5.4889 (5.9040) loss_oracle 1.0145 (1.0534) acc 93.7500 (88.6250) alaph_mean 0.9865 (0.9865) alpha_val 0.9865 (0.9865) lr 2.7103e-04 eta 0:05:01
epoch [40/50] batch [120/319] time 0.088 (0.088) data 0.000 (0.005) loss 1.2092 (1.3661) teacher_loss 0.1412 (0.3148) loss_zs_kd 6.0805 (5.9005) loss_oracle 1.0679 (1.0513) acc 96.8750 (88.2812) alaph_mean 0.9866 (0.9865) alpha_val 0.9866 (0.9865) lr 2.7103e-04 eta 0:04:58
epoch [40/50] batch [140/319] time 0.078 (0.087) data 0.000 (0.004) loss 1.3724 (1.3697) teacher_loss 0.3013 (0.3170) loss_zs_kd 6.0545 (5.8986) loss_oracle 1.0711 (1.0526) acc 87.5000 (88.1920) alaph_mean 0.9866 (0.9865) alpha_val 0.9866 (0.9865) lr 2.7103e-04 eta 0:04:53
epoch [40/50] batch [160/319] time 0.080 (0.087) data 0.000 (0.004) loss 1.4258 (1.3680) teacher_loss 0.3673 (0.3150) loss_zs_kd 5.6393 (5.8950) loss_oracle 1.0585 (1.0530) acc 81.2500 (88.2617) alaph_mean 0.9866 (0.9865) alpha_val 0.9866 (0.9865) lr 2.7103e-04 eta 0:04:50
epoch [40/50] batch [180/319] time 0.086 (0.086) data 0.000 (0.003) loss 1.5849 (1.3661) teacher_loss 0.5179 (0.3126) loss_zs_kd 5.6805 (5.8865) loss_oracle 1.0670 (1.0535) acc 84.3750 (88.2986) alaph_mean 0.9866 (0.9865) alpha_val 0.9866 (0.9865) lr 2.7103e-04 eta 0:04:47
epoch [40/50] batch [200/319] time 0.086 (0.086) data 0.000 (0.003) loss 1.4129 (1.3778) teacher_loss 0.3347 (0.3220) loss_zs_kd 6.3135 (5.8793) loss_oracle 1.0782 (1.0558) acc 87.5000 (87.8125) alaph_mean 0.9866 (0.9865) alpha_val 0.9866 (0.9865) lr 2.7103e-04 eta 0:04:44
epoch [40/50] batch [220/319] time 0.086 (0.086) data 0.000 (0.003) loss 1.3637 (1.3825) teacher_loss 0.2978 (0.3263) loss_zs_kd 5.4665 (5.8722) loss_oracle 1.0660 (1.0562) acc 90.6250 (87.5142) alaph_mean 0.9866 (0.9866) alpha_val 0.9866 (0.9866) lr 2.7103e-04 eta 0:04:42
epoch [40/50] batch [240/319] time 0.145 (0.086) data 0.000 (0.002) loss 1.6392 (1.3827) teacher_loss 0.5681 (0.3261) loss_zs_kd 6.0129 (5.8690) loss_oracle 1.0711 (1.0566) acc 71.8750 (87.4870) alaph_mean 0.9866 (0.9866) alpha_val 0.9866 (0.9866) lr 2.7103e-04 eta 0:04:40
epoch [40/50] batch [260/319] time 0.078 (0.086) data 0.000 (0.002) loss 1.3789 (1.3847) teacher_loss 0.2934 (0.3274) loss_zs_kd 6.0624 (5.8721) loss_oracle 1.0854 (1.0572) acc 90.6250 (87.4159) alaph_mean 0.9866 (0.9866) alpha_val 0.9866 (0.9866) lr 2.7103e-04 eta 0:04:41
epoch [40/50] batch [280/319] time 0.091 (0.086) data 0.000 (0.002) loss 1.3394 (1.3878) teacher_loss 0.2617 (0.3307) loss_zs_kd 5.8391 (5.8764) loss_oracle 1.0776 (1.0571) acc 93.7500 (87.3214) alaph_mean 0.9866 (0.9866) alpha_val 0.9866 (0.9866) lr 2.7103e-04 eta 0:04:38
epoch [40/50] batch [300/319] time 0.081 (0.086) data 0.000 (0.002) loss 1.5013 (1.3906) teacher_loss 0.4571 (0.3329) loss_zs_kd 5.3700 (5.8839) loss_oracle 1.0441 (1.0578) acc 75.0000 (87.1875) alaph_mean 0.9866 (0.9866) alpha_val 0.9866 (0.9866) lr 2.7103e-04 eta 0:04:36
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,524
* accuracy: 34.8%
* error: 65.2%
* macro_f1: 24.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 732
* accuracy: 7.5%
* error: 92.5%
* macro_f1: 6.6%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [41/50] batch [20/319] time 0.080 (0.117) data 0.000 (0.031) loss 1.4641 (1.4078) teacher_loss 0.3694 (0.3465) loss_zs_kd 5.9230 (5.9283) loss_oracle 1.0946 (1.0612) acc 87.5000 (86.4062) alaph_mean 0.9866 (0.9866) alpha_val 0.9866 (0.9866) lr 2.2949e-04 eta 0:06:11
epoch [41/50] batch [40/319] time 0.078 (0.109) data 0.000 (0.016) loss 1.3659 (1.3959) teacher_loss 0.2845 (0.3336) loss_zs_kd 5.8572 (5.8783) loss_oracle 1.0813 (1.0623) acc 93.7500 (87.0312) alaph_mean 0.9867 (0.9866) alpha_val 0.9867 (0.9866) lr 2.2949e-04 eta 0:05:43
epoch [41/50] batch [60/319] time 0.086 (0.101) data 0.000 (0.011) loss 1.4658 (1.3978) teacher_loss 0.3853 (0.3350) loss_zs_kd 6.3187 (5.8804) loss_oracle 1.0805 (1.0627) acc 84.3750 (86.9792) alaph_mean 0.9867 (0.9867) alpha_val 0.9867 (0.9867) lr 2.2949e-04 eta 0:05:15
epoch [41/50] batch [80/319] time 0.079 (0.097) data 0.000 (0.008) loss 1.3285 (1.3869) teacher_loss 0.2480 (0.3249) loss_zs_kd 5.8349 (5.9379) loss_oracle 1.0805 (1.0620) acc 87.5000 (87.1875) alaph_mean 0.9867 (0.9867) alpha_val 0.9867 (0.9867) lr 2.2949e-04 eta 0:05:01
epoch [41/50] batch [100/319] time 0.083 (0.094) data 0.000 (0.007) loss 1.3076 (1.3873) teacher_loss 0.2990 (0.3264) loss_zs_kd 6.3030 (5.9568) loss_oracle 1.0085 (1.0609) acc 90.6250 (87.1250) alaph_mean 0.9867 (0.9867) alpha_val 0.9867 (0.9867) lr 2.2949e-04 eta 0:04:51
epoch [41/50] batch [120/319] time 0.087 (0.093) data 0.000 (0.005) loss 1.3602 (1.3908) teacher_loss 0.3069 (0.3306) loss_zs_kd 6.4035 (5.9677) loss_oracle 1.0533 (1.0603) acc 90.6250 (86.9271) alaph_mean 0.9867 (0.9867) alpha_val 0.9867 (0.9867) lr 2.2949e-04 eta 0:04:45
epoch [41/50] batch [140/319] time 0.079 (0.092) data 0.000 (0.005) loss 1.3353 (1.3878) teacher_loss 0.3075 (0.3283) loss_zs_kd 5.7569 (5.9661) loss_oracle 1.0279 (1.0595) acc 87.5000 (87.0536) alaph_mean 0.9867 (0.9867) alpha_val 0.9867 (0.9867) lr 2.2949e-04 eta 0:04:40
epoch [41/50] batch [160/319] time 0.084 (0.091) data 0.000 (0.004) loss 1.3865 (1.3891) teacher_loss 0.3313 (0.3285) loss_zs_kd 6.1583 (5.9751) loss_oracle 1.0551 (1.0606) acc 87.5000 (86.9727) alaph_mean 0.9867 (0.9867) alpha_val 0.9867 (0.9867) lr 2.2949e-04 eta 0:04:34
epoch [41/50] batch [180/319] time 0.087 (0.090) data 0.000 (0.004) loss 1.4145 (1.3889) teacher_loss 0.4187 (0.3288) loss_zs_kd 5.5283 (5.9876) loss_oracle 0.9957 (1.0601) acc 90.6250 (87.0833) alaph_mean 0.9867 (0.9867) alpha_val 0.9867 (0.9867) lr 2.2949e-04 eta 0:04:30
epoch [41/50] batch [200/319] time 0.080 (0.089) data 0.000 (0.003) loss 1.1929 (1.3860) teacher_loss 0.1409 (0.3271) loss_zs_kd 6.3904 (5.9968) loss_oracle 1.0520 (1.0588) acc 100.0000 (87.2969) alaph_mean 0.9867 (0.9867) alpha_val 0.9867 (0.9867) lr 2.2949e-04 eta 0:04:26
epoch [41/50] batch [220/319] time 0.081 (0.088) data 0.000 (0.003) loss 1.4935 (1.3860) teacher_loss 0.3537 (0.3278) loss_zs_kd 5.9704 (5.9958) loss_oracle 1.1398 (1.0582) acc 81.2500 (87.3438) alaph_mean 0.9867 (0.9867) alpha_val 0.9867 (0.9867) lr 2.2949e-04 eta 0:04:22
epoch [41/50] batch [240/319] time 0.077 (0.088) data 0.000 (0.003) loss 1.4704 (1.3857) teacher_loss 0.4273 (0.3274) loss_zs_kd 6.3448 (5.9966) loss_oracle 1.0430 (1.0583) acc 90.6250 (87.3698) alaph_mean 0.9867 (0.9867) alpha_val 0.9867 (0.9867) lr 2.2949e-04 eta 0:04:18
epoch [41/50] batch [260/319] time 0.084 (0.087) data 0.000 (0.003) loss 1.5018 (1.3868) teacher_loss 0.4569 (0.3281) loss_zs_kd 5.8544 (5.9904) loss_oracle 1.0448 (1.0587) acc 78.1250 (87.3317) alaph_mean 0.9867 (0.9867) alpha_val 0.9867 (0.9867) lr 2.2949e-04 eta 0:04:15
epoch [41/50] batch [280/319] time 0.095 (0.087) data 0.000 (0.002) loss 1.3379 (1.3868) teacher_loss 0.2461 (0.3282) loss_zs_kd 5.4659 (5.9815) loss_oracle 1.0918 (1.0587) acc 87.5000 (87.2879) alaph_mean 0.9868 (0.9867) alpha_val 0.9868 (0.9867) lr 2.2949e-04 eta 0:04:13
epoch [41/50] batch [300/319] time 0.083 (0.087) data 0.000 (0.002) loss 1.2465 (1.3864) teacher_loss 0.2444 (0.3275) loss_zs_kd 5.5707 (5.9711) loss_oracle 1.0021 (1.0589) acc 90.6250 (87.2812) alaph_mean 0.9868 (0.9867) alpha_val 0.9868 (0.9867) lr 2.2949e-04 eta 0:04:10
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,610
* accuracy: 36.8%
* error: 63.2%
* macro_f1: 24.0%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 748
* accuracy: 7.7%
* error: 92.3%
* macro_f1: 6.6%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [42/50] batch [20/319] time 0.082 (0.120) data 0.000 (0.031) loss 1.4269 (1.3820) teacher_loss 0.3118 (0.3276) loss_zs_kd 6.0850 (5.8419) loss_oracle 1.1151 (1.0544) acc 84.3750 (87.3438) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:05:40
epoch [42/50] batch [40/319] time 0.076 (0.102) data 0.000 (0.016) loss 1.1756 (1.3792) teacher_loss 0.1179 (0.3252) loss_zs_kd 6.0662 (5.8872) loss_oracle 1.0577 (1.0540) acc 93.7500 (87.3438) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:04:49
epoch [42/50] batch [60/319] time 0.082 (0.096) data 0.000 (0.011) loss 1.2974 (1.3727) teacher_loss 0.3026 (0.3204) loss_zs_kd 6.0272 (5.9009) loss_oracle 0.9949 (1.0523) acc 84.3750 (87.7604) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:04:30
epoch [42/50] batch [80/319] time 0.084 (0.093) data 0.000 (0.008) loss 1.4148 (1.3782) teacher_loss 0.3537 (0.3230) loss_zs_kd 5.9526 (5.8970) loss_oracle 1.0611 (1.0552) acc 87.5000 (87.8125) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:04:18
epoch [42/50] batch [100/319] time 0.078 (0.090) data 0.000 (0.006) loss 1.5718 (1.3933) teacher_loss 0.5242 (0.3356) loss_zs_kd 6.0141 (5.8951) loss_oracle 1.0477 (1.0577) acc 78.1250 (87.0938) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:04:10
epoch [42/50] batch [120/319] time 0.092 (0.089) data 0.000 (0.005) loss 1.4460 (1.3863) teacher_loss 0.3908 (0.3305) loss_zs_kd 6.1087 (5.9089) loss_oracle 1.0552 (1.0558) acc 81.2500 (87.3177) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:04:05
epoch [42/50] batch [140/319] time 0.079 (0.088) data 0.000 (0.005) loss 1.3102 (1.3914) teacher_loss 0.2278 (0.3357) loss_zs_kd 5.4607 (5.9019) loss_oracle 1.0824 (1.0557) acc 93.7500 (87.2321) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:03:59
epoch [42/50] batch [160/319] time 0.092 (0.087) data 0.000 (0.004) loss 1.6048 (1.3934) teacher_loss 0.5671 (0.3389) loss_zs_kd 5.7709 (5.8985) loss_oracle 1.0377 (1.0545) acc 71.8750 (86.8945) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:03:56
epoch [42/50] batch [180/319] time 0.082 (0.087) data 0.000 (0.004) loss 1.4493 (1.3928) teacher_loss 0.3916 (0.3374) loss_zs_kd 5.8855 (5.9024) loss_oracle 1.0577 (1.0553) acc 84.3750 (86.8924) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:03:52
epoch [42/50] batch [200/319] time 0.082 (0.086) data 0.000 (0.003) loss 1.3144 (1.3910) teacher_loss 0.2931 (0.3355) loss_zs_kd 5.5710 (5.8889) loss_oracle 1.0212 (1.0556) acc 96.8750 (86.9531) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:03:50
epoch [42/50] batch [220/319] time 0.145 (0.087) data 0.000 (0.003) loss 1.3566 (1.3922) teacher_loss 0.3307 (0.3364) loss_zs_kd 5.6423 (5.8874) loss_oracle 1.0259 (1.0559) acc 87.5000 (87.0312) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:03:50
epoch [42/50] batch [240/319] time 0.081 (0.087) data 0.000 (0.003) loss 1.3863 (1.3897) teacher_loss 0.3077 (0.3335) loss_zs_kd 5.7449 (5.8930) loss_oracle 1.0786 (1.0562) acc 81.2500 (87.0964) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:03:49
epoch [42/50] batch [260/319] time 0.083 (0.087) data 0.000 (0.003) loss 1.4884 (1.3885) teacher_loss 0.3819 (0.3314) loss_zs_kd 6.0836 (5.9061) loss_oracle 1.1065 (1.0570) acc 81.2500 (87.1154) alaph_mean 0.9868 (0.9868) alpha_val 0.9868 (0.9868) lr 1.9098e-04 eta 0:03:45
epoch [42/50] batch [280/319] time 0.086 (0.086) data 0.001 (0.002) loss 1.3789 (1.3882) teacher_loss 0.3746 (0.3308) loss_zs_kd 5.4379 (5.9056) loss_oracle 1.0044 (1.0574) acc 93.7500 (87.2321) alaph_mean 0.9869 (0.9868) alpha_val 0.9869 (0.9868) lr 1.9098e-04 eta 0:03:43
epoch [42/50] batch [300/319] time 0.085 (0.086) data 0.000 (0.002) loss 1.3551 (1.3888) teacher_loss 0.2797 (0.3309) loss_zs_kd 6.2577 (5.9073) loss_oracle 1.0754 (1.0579) acc 87.5000 (87.2708) alaph_mean 0.9869 (0.9868) alpha_val 0.9869 (0.9868) lr 1.9098e-04 eta 0:03:41
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,610
* accuracy: 36.8%
* error: 63.2%
* macro_f1: 24.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 811
* accuracy: 8.3%
* error: 91.7%
* macro_f1: 6.8%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [43/50] batch [20/319] time 0.087 (0.133) data 0.000 (0.031) loss 1.3037 (1.3780) teacher_loss 0.2266 (0.3175) loss_zs_kd 6.3408 (5.9059) loss_oracle 1.0771 (1.0605) acc 96.8750 (86.4062) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:05:37
epoch [43/50] batch [40/319] time 0.076 (0.108) data 0.000 (0.015) loss 1.6546 (1.3862) teacher_loss 0.5598 (0.3250) loss_zs_kd 5.8572 (5.8676) loss_oracle 1.0948 (1.0612) acc 68.7500 (85.6250) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:04:31
epoch [43/50] batch [60/319] time 0.083 (0.099) data 0.001 (0.010) loss 1.4357 (1.3814) teacher_loss 0.3917 (0.3226) loss_zs_kd 5.9735 (5.8479) loss_oracle 1.0440 (1.0588) acc 87.5000 (86.3021) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:04:05
epoch [43/50] batch [80/319] time 0.085 (0.095) data 0.000 (0.008) loss 1.2388 (1.3860) teacher_loss 0.2079 (0.3249) loss_zs_kd 5.8326 (5.8455) loss_oracle 1.0309 (1.0611) acc 90.6250 (86.3672) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:03:55
epoch [43/50] batch [100/319] time 0.089 (0.093) data 0.000 (0.006) loss 1.4123 (1.3904) teacher_loss 0.3007 (0.3273) loss_zs_kd 6.1835 (5.8424) loss_oracle 1.1116 (1.0631) acc 81.2500 (86.2812) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:03:48
epoch [43/50] batch [120/319] time 0.078 (0.091) data 0.000 (0.005) loss 1.3244 (1.3918) teacher_loss 0.3004 (0.3296) loss_zs_kd 5.4014 (5.8410) loss_oracle 1.0241 (1.0621) acc 93.7500 (86.4062) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:03:41
epoch [43/50] batch [140/319] time 0.077 (0.090) data 0.000 (0.005) loss 1.4123 (1.3872) teacher_loss 0.3162 (0.3236) loss_zs_kd 6.3077 (5.8447) loss_oracle 1.0961 (1.0636) acc 90.6250 (86.9420) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:03:36
epoch [43/50] batch [160/319] time 0.081 (0.089) data 0.000 (0.004) loss 1.2770 (1.3853) teacher_loss 0.1475 (0.3217) loss_zs_kd 6.3988 (5.8557) loss_oracle 1.1295 (1.0636) acc 90.6250 (87.3242) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:03:32
epoch [43/50] batch [180/319] time 0.084 (0.088) data 0.000 (0.004) loss 1.4246 (1.3900) teacher_loss 0.3718 (0.3285) loss_zs_kd 5.9610 (5.8408) loss_oracle 1.0528 (1.0615) acc 87.5000 (87.1701) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:03:29
epoch [43/50] batch [200/319] time 0.076 (0.087) data 0.000 (0.003) loss 1.5079 (1.3893) teacher_loss 0.4279 (0.3282) loss_zs_kd 6.1079 (5.8433) loss_oracle 1.0800 (1.0611) acc 78.1250 (87.1719) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:03:25
epoch [43/50] batch [220/319] time 0.079 (0.087) data 0.000 (0.003) loss 1.5559 (1.3907) teacher_loss 0.4774 (0.3306) loss_zs_kd 5.4566 (5.8406) loss_oracle 1.0785 (1.0601) acc 78.1250 (86.9460) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:03:22
epoch [43/50] batch [240/319] time 0.075 (0.086) data 0.000 (0.003) loss 1.3453 (1.3874) teacher_loss 0.2679 (0.3286) loss_zs_kd 6.5600 (5.8456) loss_oracle 1.0775 (1.0589) acc 90.6250 (87.0443) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:03:18
epoch [43/50] batch [260/319] time 0.078 (0.085) data 0.000 (0.003) loss 1.4276 (1.3861) teacher_loss 0.3736 (0.3287) loss_zs_kd 5.6029 (5.8387) loss_oracle 1.0540 (1.0574) acc 90.6250 (87.1274) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:03:15
epoch [43/50] batch [280/319] time 0.081 (0.085) data 0.000 (0.002) loss 1.3209 (1.3840) teacher_loss 0.2803 (0.3257) loss_zs_kd 5.6481 (5.8375) loss_oracle 1.0405 (1.0583) acc 90.6250 (87.3214) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:03:13
epoch [43/50] batch [300/319] time 0.085 (0.085) data 0.000 (0.002) loss 1.4327 (1.3847) teacher_loss 0.3669 (0.3257) loss_zs_kd 5.6360 (5.8408) loss_oracle 1.0658 (1.0590) acc 87.5000 (87.2292) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.5567e-04 eta 0:03:11
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,657
* accuracy: 37.8%
* error: 62.2%
* macro_f1: 24.3%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 792
* accuracy: 8.1%
* error: 91.9%
* macro_f1: 6.7%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [44/50] batch [20/319] time 0.080 (0.116) data 0.000 (0.025) loss 1.4898 (1.3666) teacher_loss 0.4397 (0.3084) loss_zs_kd 5.6517 (5.8389) loss_oracle 1.0501 (1.0582) acc 84.3750 (87.6562) alaph_mean 0.9869 (0.9869) alpha_val 0.9869 (0.9869) lr 1.2369e-04 eta 0:04:15
epoch [44/50] batch [40/319] time 0.079 (0.100) data 0.000 (0.013) loss 1.5756 (1.3849) teacher_loss 0.5015 (0.3248) loss_zs_kd 5.9942 (5.8655) loss_oracle 1.0741 (1.0600) acc 81.2500 (87.5000) alaph_mean 0.9870 (0.9869) alpha_val 0.9870 (0.9869) lr 1.2369e-04 eta 0:03:38
epoch [44/50] batch [60/319] time 0.078 (0.092) data 0.000 (0.009) loss 1.1721 (1.3855) teacher_loss 0.1705 (0.3295) loss_zs_kd 5.6774 (5.8719) loss_oracle 1.0016 (1.0560) acc 93.7500 (86.9792) alaph_mean 0.9870 (0.9869) alpha_val 0.9870 (0.9869) lr 1.2369e-04 eta 0:03:20
epoch [44/50] batch [80/319] time 0.076 (0.089) data 0.000 (0.007) loss 1.4104 (1.3822) teacher_loss 0.4007 (0.3254) loss_zs_kd 5.6755 (5.8806) loss_oracle 1.0097 (1.0568) acc 84.3750 (87.1094) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 1.2369e-04 eta 0:03:12
epoch [44/50] batch [100/319] time 0.085 (0.088) data 0.000 (0.005) loss 1.3803 (1.3774) teacher_loss 0.3232 (0.3208) loss_zs_kd 5.6790 (5.8738) loss_oracle 1.0571 (1.0566) acc 90.6250 (87.5312) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 1.2369e-04 eta 0:03:07
epoch [44/50] batch [120/319] time 0.083 (0.087) data 0.000 (0.004) loss 1.4331 (1.3875) teacher_loss 0.3221 (0.3299) loss_zs_kd 5.7858 (5.8710) loss_oracle 1.1110 (1.0576) acc 87.5000 (87.3958) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 1.2369e-04 eta 0:03:04
epoch [44/50] batch [140/319] time 0.077 (0.086) data 0.000 (0.004) loss 1.4990 (1.3889) teacher_loss 0.3778 (0.3313) loss_zs_kd 5.6060 (5.8521) loss_oracle 1.1212 (1.0576) acc 87.5000 (87.4107) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 1.2369e-04 eta 0:03:00
epoch [44/50] batch [160/319] time 0.083 (0.086) data 0.000 (0.003) loss 1.5155 (1.3926) teacher_loss 0.4104 (0.3347) loss_zs_kd 6.0379 (5.8611) loss_oracle 1.1051 (1.0579) acc 78.1250 (87.2656) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 1.2369e-04 eta 0:02:57
epoch [44/50] batch [180/319] time 0.080 (0.085) data 0.000 (0.003) loss 1.4230 (1.3925) teacher_loss 0.3930 (0.3337) loss_zs_kd 5.4628 (5.8605) loss_oracle 1.0300 (1.0588) acc 84.3750 (86.9965) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 1.2369e-04 eta 0:02:55
epoch [44/50] batch [200/319] time 0.081 (0.085) data 0.000 (0.003) loss 1.1760 (1.3911) teacher_loss 0.1342 (0.3328) loss_zs_kd 5.2471 (5.8576) loss_oracle 1.0418 (1.0583) acc 96.8750 (87.0312) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 1.2369e-04 eta 0:02:52
epoch [44/50] batch [220/319] time 0.081 (0.086) data 0.000 (0.003) loss 1.3543 (1.3880) teacher_loss 0.2957 (0.3294) loss_zs_kd 6.1590 (5.8672) loss_oracle 1.0586 (1.0586) acc 87.5000 (87.2443) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 1.2369e-04 eta 0:02:53
epoch [44/50] batch [240/319] time 0.075 (0.086) data 0.000 (0.002) loss 1.6346 (1.3871) teacher_loss 0.5774 (0.3285) loss_zs_kd 5.9270 (5.8654) loss_oracle 1.0572 (1.0587) acc 84.3750 (87.2917) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 1.2369e-04 eta 0:02:50
epoch [44/50] batch [260/319] time 0.071 (0.085) data 0.000 (0.002) loss 1.4055 (1.3916) teacher_loss 0.3042 (0.3326) loss_zs_kd 5.8145 (5.8603) loss_oracle 1.1013 (1.0590) acc 81.2500 (87.0913) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 1.2369e-04 eta 0:02:47
epoch [44/50] batch [280/319] time 0.083 (0.085) data 0.000 (0.002) loss 1.4209 (1.3913) teacher_loss 0.3704 (0.3329) loss_zs_kd 5.9277 (5.8565) loss_oracle 1.0505 (1.0584) acc 84.3750 (87.0536) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 1.2369e-04 eta 0:02:45
epoch [44/50] batch [300/319] time 0.087 (0.084) data 0.000 (0.002) loss 1.4409 (1.3906) teacher_loss 0.3605 (0.3325) loss_zs_kd 5.9112 (5.8517) loss_oracle 1.0805 (1.0581) acc 90.6250 (87.1771) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 1.2369e-04 eta 0:02:43
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,608
* accuracy: 36.7%
* error: 63.3%
* macro_f1: 24.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 741
* accuracy: 7.6%
* error: 92.4%
* macro_f1: 6.6%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [45/50] batch [20/319] time 0.078 (0.131) data 0.000 (0.032) loss 1.3140 (1.3540) teacher_loss 0.2565 (0.2962) loss_zs_kd 5.2421 (5.7643) loss_oracle 1.0575 (1.0577) acc 90.6250 (87.8125) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:04:08
epoch [45/50] batch [40/319] time 0.080 (0.106) data 0.000 (0.016) loss 1.3110 (1.3777) teacher_loss 0.3487 (0.3208) loss_zs_kd 5.4790 (5.7826) loss_oracle 0.9623 (1.0569) acc 90.6250 (87.3438) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:03:19
epoch [45/50] batch [60/319] time 0.085 (0.098) data 0.000 (0.011) loss 1.3844 (1.3918) teacher_loss 0.3193 (0.3324) loss_zs_kd 5.9168 (5.8270) loss_oracle 1.0651 (1.0595) acc 87.5000 (87.2917) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:03:02
epoch [45/50] batch [80/319] time 0.078 (0.094) data 0.000 (0.008) loss 1.4956 (1.3917) teacher_loss 0.3804 (0.3352) loss_zs_kd 5.7736 (5.7690) loss_oracle 1.1153 (1.0565) acc 84.3750 (86.9531) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:02:52
epoch [45/50] batch [100/319] time 0.085 (0.091) data 0.000 (0.007) loss 1.3468 (1.3840) teacher_loss 0.3082 (0.3268) loss_zs_kd 5.9108 (5.7979) loss_oracle 1.0386 (1.0572) acc 90.6250 (87.2812) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:02:45
epoch [45/50] batch [120/319] time 0.089 (0.090) data 0.000 (0.006) loss 1.5213 (1.3834) teacher_loss 0.4350 (0.3242) loss_zs_kd 5.7339 (5.8016) loss_oracle 1.0864 (1.0592) acc 84.3750 (87.4740) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:02:40
epoch [45/50] batch [140/319] time 0.086 (0.089) data 0.000 (0.005) loss 1.4368 (1.3779) teacher_loss 0.4511 (0.3202) loss_zs_kd 5.1550 (5.8076) loss_oracle 0.9857 (1.0577) acc 81.2500 (87.6562) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:02:37
epoch [45/50] batch [160/319] time 0.083 (0.088) data 0.000 (0.004) loss 1.3211 (1.3763) teacher_loss 0.3132 (0.3180) loss_zs_kd 5.3215 (5.8073) loss_oracle 1.0079 (1.0583) acc 87.5000 (87.5195) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:02:34
epoch [45/50] batch [180/319] time 0.079 (0.088) data 0.000 (0.004) loss 1.3399 (1.3763) teacher_loss 0.2444 (0.3177) loss_zs_kd 6.5354 (5.8348) loss_oracle 1.0955 (1.0586) acc 87.5000 (87.5694) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:02:31
epoch [45/50] batch [200/319] time 0.078 (0.087) data 0.000 (0.003) loss 1.4011 (1.3788) teacher_loss 0.2835 (0.3193) loss_zs_kd 6.1410 (5.8471) loss_oracle 1.1176 (1.0595) acc 87.5000 (87.5781) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:02:29
epoch [45/50] batch [220/319] time 0.080 (0.087) data 0.000 (0.003) loss 1.2741 (1.3813) teacher_loss 0.2036 (0.3219) loss_zs_kd 5.9642 (5.8483) loss_oracle 1.0705 (1.0595) acc 90.6250 (87.3153) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:02:26
epoch [45/50] batch [240/319] time 0.083 (0.086) data 0.000 (0.003) loss 1.4938 (1.3806) teacher_loss 0.3854 (0.3211) loss_zs_kd 6.0141 (5.8517) loss_oracle 1.1084 (1.0595) acc 84.3750 (87.3047) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:02:24
epoch [45/50] batch [260/319] time 0.082 (0.086) data 0.000 (0.003) loss 1.4333 (1.3861) teacher_loss 0.3278 (0.3258) loss_zs_kd 5.8472 (5.8564) loss_oracle 1.1055 (1.0603) acc 87.5000 (87.1274) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:02:21
epoch [45/50] batch [280/319] time 0.088 (0.086) data 0.000 (0.003) loss 1.2807 (1.3871) teacher_loss 0.2700 (0.3276) loss_zs_kd 5.5277 (5.8542) loss_oracle 1.0107 (1.0595) acc 87.5000 (87.0536) alaph_mean 0.9870 (0.9870) alpha_val 0.9870 (0.9870) lr 9.5173e-05 eta 0:02:19
epoch [45/50] batch [300/319] time 0.087 (0.085) data 0.000 (0.002) loss 1.3550 (1.3860) teacher_loss 0.3581 (0.3270) loss_zs_kd 5.1318 (5.8521) loss_oracle 0.9969 (1.0590) acc 84.3750 (87.1250) alaph_mean 0.9871 (0.9870) alpha_val 0.9871 (0.9870) lr 9.5173e-05 eta 0:02:17
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,601
* accuracy: 36.6%
* error: 63.4%
* macro_f1: 24.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 736
* accuracy: 7.6%
* error: 92.4%
* macro_f1: 6.5%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******
epoch [46/50] batch [20/319] time 0.084 (0.110) data 0.000 (0.025) loss 1.3823 (1.3578) teacher_loss 0.2768 (0.3001) loss_zs_kd 5.9297 (5.8704) loss_oracle 1.1056 (1.0578) acc 96.8750 (90.1562) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:02:53
epoch [46/50] batch [40/319] time 0.090 (0.097) data 0.000 (0.013) loss 1.4072 (1.3761) teacher_loss 0.3053 (0.3185) loss_zs_kd 5.4407 (5.8097) loss_oracle 1.1019 (1.0576) acc 90.6250 (88.2812) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:02:30
epoch [46/50] batch [60/319] time 0.079 (0.093) data 0.000 (0.009) loss 1.4805 (1.3767) teacher_loss 0.3819 (0.3200) loss_zs_kd 5.7446 (5.7954) loss_oracle 1.0987 (1.0567) acc 90.6250 (87.9167) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:02:22
epoch [46/50] batch [80/319] time 0.081 (0.090) data 0.000 (0.007) loss 1.2858 (1.3796) teacher_loss 0.2763 (0.3228) loss_zs_kd 5.9951 (5.7909) loss_oracle 1.0095 (1.0568) acc 90.6250 (87.9297) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:02:16
epoch [46/50] batch [100/319] time 0.081 (0.090) data 0.000 (0.005) loss 1.1461 (1.3784) teacher_loss 0.1123 (0.3217) loss_zs_kd 6.0194 (5.7958) loss_oracle 1.0339 (1.0568) acc 96.8750 (88.0938) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:02:13
epoch [46/50] batch [120/319] time 0.082 (0.088) data 0.000 (0.004) loss 1.3300 (1.3740) teacher_loss 0.2653 (0.3188) loss_zs_kd 5.4345 (5.7957) loss_oracle 1.0647 (1.0552) acc 90.6250 (87.9688) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:02:09
epoch [46/50] batch [140/319] time 0.077 (0.086) data 0.000 (0.004) loss 1.3522 (1.3822) teacher_loss 0.3270 (0.3257) loss_zs_kd 5.6263 (5.8167) loss_oracle 1.0252 (1.0565) acc 87.5000 (87.6339) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:02:05
epoch [46/50] batch [160/319] time 0.084 (0.086) data 0.000 (0.003) loss 1.2151 (1.3800) teacher_loss 0.2032 (0.3238) loss_zs_kd 6.1302 (5.8218) loss_oracle 1.0119 (1.0562) acc 93.7500 (87.8125) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:02:03
epoch [46/50] batch [180/319] time 0.076 (0.086) data 0.000 (0.003) loss 1.4612 (1.3815) teacher_loss 0.4165 (0.3257) loss_zs_kd 5.6787 (5.8297) loss_oracle 1.0447 (1.0559) acc 81.2500 (87.5694) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:02:01
epoch [46/50] batch [200/319] time 0.078 (0.087) data 0.000 (0.003) loss 1.3862 (1.3814) teacher_loss 0.2913 (0.3253) loss_zs_kd 6.0010 (5.8237) loss_oracle 1.0949 (1.0561) acc 87.5000 (87.5938) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:02:01
epoch [46/50] batch [220/319] time 0.074 (0.086) data 0.000 (0.003) loss 1.3882 (1.3832) teacher_loss 0.3459 (0.3269) loss_zs_kd 6.1739 (5.8261) loss_oracle 1.0423 (1.0564) acc 87.5000 (87.5710) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:01:58
epoch [46/50] batch [240/319] time 0.088 (0.086) data 0.000 (0.002) loss 1.2664 (1.3836) teacher_loss 0.2101 (0.3266) loss_zs_kd 5.9917 (5.8299) loss_oracle 1.0563 (1.0570) acc 90.6250 (87.5391) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:01:56
epoch [46/50] batch [260/319] time 0.086 (0.086) data 0.000 (0.002) loss 1.2212 (1.3817) teacher_loss 0.1831 (0.3246) loss_zs_kd 5.8801 (5.8311) loss_oracle 1.0381 (1.0571) acc 90.6250 (87.7043) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:01:54
epoch [46/50] batch [280/319] time 0.087 (0.086) data 0.000 (0.002) loss 1.4670 (1.3850) teacher_loss 0.4255 (0.3277) loss_zs_kd 5.7676 (5.8312) loss_oracle 1.0415 (1.0572) acc 78.1250 (87.5223) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:01:52
epoch [46/50] batch [300/319] time 0.082 (0.085) data 0.000 (0.002) loss 1.4694 (1.3842) teacher_loss 0.3809 (0.3267) loss_zs_kd 5.8058 (5.8304) loss_oracle 1.0886 (1.0575) acc 84.3750 (87.5312) alaph_mean 0.9871 (0.9871) alpha_val 0.9871 (0.9871) lr 7.0224e-05 eta 0:01:50
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,617
* accuracy: 36.9%
* error: 63.1%
* macro_f1: 24.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 756
* accuracy: 7.8%
* error: 92.2%
* macro_f1: 6.6%
******* Domain 2 best val acc:      40.5%, epoch: 1 *******
******* Domain 2 best val test acc: 32.8%, epoch: 1 *******
******* Domain 2 best test acc:     55.4%, epoch: 2 *******

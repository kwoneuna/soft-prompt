Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------------
Dataset    SPG_OfficeHome
Source     ['clipart', 'product', 'real_world']
Target     ['art']
# classes  65
# train_x  9,222
# val      3,939
# test     2,427
---------  ------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/288] time 0.116 (0.166) data 0.000 (0.019) loss 1.1822 (1.3112) ce_loss 1.1104 (1.2382) teacher_loss 1.1114 (1.2384) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0707 (0.0729) acc 71.8750 (68.5938) kd_loss 0.3343 (0.3513) lr 1.0000e-05 eta 0:39:54
epoch [1/50] batch [40/288] time 0.115 (0.142) data 0.001 (0.009) loss 1.2971 (1.3305) ce_loss 1.2158 (1.2593) teacher_loss 1.2154 (1.2594) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0817 (0.0710) acc 65.6250 (68.3594) kd_loss 0.3903 (0.3429) lr 1.0000e-05 eta 0:34:06
epoch [1/50] batch [60/288] time 0.098 (0.133) data 0.000 (0.006) loss 1.4836 (1.3404) ce_loss 1.4287 (1.2662) teacher_loss 1.4280 (1.2663) loss_zs_kd 0.0006 (0.0001) loss_oracle 0.0553 (0.0740) acc 59.3750 (67.7083) kd_loss 0.2721 (0.3573) lr 1.0000e-05 eta 0:31:47
epoch [1/50] batch [80/288] time 0.099 (0.126) data 0.000 (0.005) loss 1.3265 (1.3481) ce_loss 1.2559 (1.2701) teacher_loss 1.2562 (1.2703) loss_zs_kd 0.0009 (0.0002) loss_oracle 0.0698 (0.0777) acc 62.5000 (67.4609) kd_loss 0.3348 (0.3746) lr 1.0000e-05 eta 0:30:03
epoch [1/50] batch [100/288] time 0.097 (0.122) data 0.000 (0.004) loss 1.1717 (1.3195) ce_loss 1.0889 (1.2424) teacher_loss 1.0900 (1.2426) loss_zs_kd 0.0006 (0.0003) loss_oracle 0.0815 (0.0768) acc 62.5000 (68.1562) kd_loss 0.3900 (0.3702) lr 1.0000e-05 eta 0:28:58
epoch [1/50] batch [120/288] time 0.100 (0.118) data 0.000 (0.003) loss 1.1184 (1.3142) ce_loss 1.0332 (1.2363) teacher_loss 1.0336 (1.2364) loss_zs_kd 0.0007 (0.0004) loss_oracle 0.0845 (0.0776) acc 75.0000 (68.2552) kd_loss 0.4067 (0.3740) lr 1.0000e-05 eta 0:28:05
epoch [1/50] batch [140/288] time 0.096 (0.115) data 0.000 (0.003) loss 1.5767 (1.3013) ce_loss 1.4883 (1.2224) teacher_loss 1.4878 (1.2224) loss_zs_kd 0.0011 (0.0005) loss_oracle 0.0884 (0.0786) acc 56.2500 (68.3705) kd_loss 0.4234 (0.3786) lr 1.0000e-05 eta 0:27:24
epoch [1/50] batch [160/288] time 0.109 (0.113) data 0.000 (0.003) loss 1.0895 (1.2982) ce_loss 1.0576 (1.2199) teacher_loss 1.0573 (1.2199) loss_zs_kd 0.0018 (0.0006) loss_oracle 0.0312 (0.0780) acc 71.8750 (68.6719) kd_loss 0.1506 (0.3758) lr 1.0000e-05 eta 0:26:50
epoch [1/50] batch [180/288] time 0.100 (0.112) data 0.000 (0.002) loss 1.0623 (1.3013) ce_loss 0.9961 (1.2235) teacher_loss 0.9959 (1.2235) loss_zs_kd 0.0023 (0.0007) loss_oracle 0.0653 (0.0775) acc 71.8750 (68.5069) kd_loss 0.3139 (0.3731) lr 1.0000e-05 eta 0:26:27
epoch [1/50] batch [200/288] time 0.095 (0.110) data 0.000 (0.002) loss 1.4322 (1.2980) ce_loss 1.3379 (1.2203) teacher_loss 1.3377 (1.2203) loss_zs_kd 0.0020 (0.0008) loss_oracle 0.0934 (0.0773) acc 62.5000 (68.3906) kd_loss 0.4514 (0.3721) lr 1.0000e-05 eta 0:26:08
epoch [1/50] batch [220/288] time 0.095 (0.109) data 0.000 (0.002) loss 1.4327 (1.2931) ce_loss 1.4160 (1.2159) teacher_loss 1.4172 (1.2159) loss_zs_kd 0.0022 (0.0010) loss_oracle 0.0144 (0.0767) acc 65.6250 (68.6506) kd_loss 0.0687 (0.3695) lr 1.0000e-05 eta 0:25:50
epoch [1/50] batch [240/288] time 0.095 (0.109) data 0.000 (0.002) loss 1.0546 (1.2903) ce_loss 0.9858 (1.2135) teacher_loss 0.9854 (1.2135) loss_zs_kd 0.0010 (0.0011) loss_oracle 0.0687 (0.0763) acc 81.2500 (68.9062) kd_loss 0.3384 (0.3675) lr 1.0000e-05 eta 0:25:37
epoch [1/50] batch [260/288] time 0.097 (0.108) data 0.000 (0.002) loss 1.4101 (1.2959) ce_loss 1.3018 (1.2190) teacher_loss 1.3018 (1.2190) loss_zs_kd 0.0055 (0.0013) loss_oracle 0.1055 (0.0763) acc 71.8750 (68.7620) kd_loss 0.5066 (0.3674) lr 1.0000e-05 eta 0:25:21
epoch [1/50] batch [280/288] time 0.087 (0.106) data 0.000 (0.002) loss 1.5672 (1.2958) ce_loss 1.5195 (1.2188) teacher_loss 1.5195 (1.2189) loss_zs_kd 0.0052 (0.0015) loss_oracle 0.0451 (0.0762) acc 62.5000 (68.8170) kd_loss 0.2182 (0.3671) lr 1.0000e-05 eta 0:25:03
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,267
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 82.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,963
* accuracy: 80.9%
* error: 19.1%
* macro_f1: 76.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      82.9%, epoch: 1 *******
******* Domain a best val test acc: 80.9%, epoch: 1 *******
******* Domain a best test acc:     80.9%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/ana
epoch [2/50] batch [20/288] time 0.090 (0.110) data 0.000 (0.013) loss 1.2906 (1.4157) ce_loss 1.0723 (1.1981) teacher_loss 1.0488 (1.1978) loss_zs_kd 0.0939 (0.0901) loss_oracle 0.1948 (0.1729) acc 65.6250 (68.9062) kd_loss 0.4813 (0.4858) lr 2.0000e-03 eta 0:25:56
epoch [2/50] batch [40/288] time 0.102 (0.102) data 0.000 (0.007) loss 1.0956 (1.3888) ce_loss 0.7056 (1.1313) teacher_loss 0.6984 (1.1292) loss_zs_kd 0.1071 (0.1109) loss_oracle 0.3437 (0.2042) acc 81.2500 (70.7031) kd_loss 0.5914 (0.5089) lr 2.0000e-03 eta 0:23:52
epoch [2/50] batch [60/288] time 0.098 (0.099) data 0.000 (0.004) loss 1.7216 (1.4322) ce_loss 1.3594 (1.1319) teacher_loss 1.3580 (1.1317) loss_zs_kd 0.1007 (0.1141) loss_oracle 0.3133 (0.2434) acc 65.6250 (71.0417) kd_loss 0.6359 (0.5407) lr 2.0000e-03 eta 0:23:17
epoch [2/50] batch [80/288] time 0.102 (0.098) data 0.000 (0.003) loss 1.1882 (1.4460) ce_loss 0.8008 (1.1152) teacher_loss 0.7801 (1.1131) loss_zs_kd 0.0837 (0.1086) loss_oracle 0.3663 (0.2785) acc 71.8750 (71.1719) kd_loss 0.6712 (0.5720) lr 2.0000e-03 eta 0:22:57
epoch [2/50] batch [100/288] time 0.098 (0.098) data 0.000 (0.003) loss 1.7809 (1.4482) ce_loss 1.5029 (1.1139) teacher_loss 1.5124 (1.1110) loss_zs_kd 0.0832 (0.1079) loss_oracle 0.2269 (0.2833) acc 62.5000 (71.3125) kd_loss 0.4957 (0.5722) lr 2.0000e-03 eta 0:22:47
epoch [2/50] batch [120/288] time 0.093 (0.097) data 0.000 (0.002) loss 1.4314 (1.4448) ce_loss 1.1162 (1.1103) teacher_loss 1.1291 (1.1068) loss_zs_kd 0.0833 (0.1078) loss_oracle 0.2606 (0.2842) acc 75.0000 (71.5365) kd_loss 0.6306 (0.5731) lr 2.0000e-03 eta 0:22:41
epoch [2/50] batch [140/288] time 0.091 (0.097) data 0.000 (0.002) loss 1.6484 (1.4530) ce_loss 1.1650 (1.1148) teacher_loss 1.1822 (1.1104) loss_zs_kd 0.1448 (0.1065) loss_oracle 0.3937 (0.2894) acc 68.7500 (71.3393) kd_loss 0.4908 (0.5762) lr 2.0000e-03 eta 0:22:38
epoch [2/50] batch [160/288] time 0.107 (0.097) data 0.000 (0.002) loss 1.3827 (1.4506) ce_loss 1.1309 (1.1150) teacher_loss 1.0987 (1.1112) loss_zs_kd 0.1908 (0.1061) loss_oracle 0.1886 (0.2864) acc 71.8750 (71.2305) kd_loss 0.4406 (0.5784) lr 2.0000e-03 eta 0:22:32
epoch [2/50] batch [180/288] time 0.093 (0.097) data 0.000 (0.002) loss 1.2766 (1.4394) ce_loss 0.9756 (1.1097) teacher_loss 1.0009 (1.1055) loss_zs_kd 0.1186 (0.1068) loss_oracle 0.2163 (0.2805) acc 78.1250 (71.3715) kd_loss 0.5299 (0.5733) lr 2.0000e-03 eta 0:22:27
epoch [2/50] batch [200/288] time 0.092 (0.097) data 0.000 (0.001) loss 2.0704 (1.4394) ce_loss 1.7500 (1.1112) teacher_loss 1.7300 (1.1070) loss_zs_kd 0.1504 (0.1090) loss_oracle 0.2652 (0.2779) acc 53.1250 (71.0938) kd_loss 0.6149 (0.5698) lr 2.0000e-03 eta 0:22:23
epoch [2/50] batch [220/288] time 0.093 (0.096) data 0.000 (0.001) loss 1.4807 (1.4281) ce_loss 1.1494 (1.1003) teacher_loss 1.1836 (1.0961) loss_zs_kd 0.1085 (0.1093) loss_oracle 0.2429 (0.2774) acc 71.8750 (71.3210) kd_loss 0.5098 (0.5675) lr 2.0000e-03 eta 0:22:18
epoch [2/50] batch [240/288] time 0.100 (0.096) data 0.000 (0.001) loss 1.7569 (1.4247) ce_loss 1.4141 (1.0960) teacher_loss 1.3422 (1.0910) loss_zs_kd 0.1093 (0.1088) loss_oracle 0.3601 (0.2793) acc 65.6250 (71.3411) kd_loss 0.5213 (0.5686) lr 2.0000e-03 eta 0:22:15
epoch [2/50] batch [260/288] time 0.096 (0.096) data 0.000 (0.001) loss 1.4253 (1.4203) ce_loss 1.0703 (1.0921) teacher_loss 1.0837 (1.0868) loss_zs_kd 0.1789 (0.1096) loss_oracle 0.2522 (0.2787) acc 78.1250 (71.3462) kd_loss 0.5735 (0.5689) lr 2.0000e-03 eta 0:22:15
epoch [2/50] batch [280/288] time 0.101 (0.097) data 0.000 (0.001) loss 1.2371 (1.4158) ce_loss 0.8384 (1.0867) teacher_loss 0.8656 (1.0811) loss_zs_kd 0.1466 (0.1106) loss_oracle 0.2982 (0.2794) acc 65.6250 (71.3728) kd_loss 0.6976 (0.5715) lr 2.0000e-03 eta 0:22:18
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,378
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 85.1%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.5%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      85.8%, epoch: 2 *******
******* Domain a best val test acc: 83.1%, epoch: 2 *******
******* Domain a best test acc:     83.1%, epoch: 2 *******
epoch [3/50] batch [20/288] time 0.096 (0.123) data 0.000 (0.016) loss 1.7915 (1.4914) ce_loss 1.4678 (1.0779) teacher_loss 1.4373 (1.0611) loss_zs_kd 0.1338 (0.1127) loss_oracle 0.2873 (0.3740) acc 53.1250 (71.7188) kd_loss 0.4747 (0.6498) lr 1.9980e-03 eta 0:28:17
epoch [3/50] batch [40/288] time 0.109 (0.113) data 0.000 (0.008) loss 1.2779 (1.3988) ce_loss 0.8242 (1.0065) teacher_loss 0.8423 (0.9934) loss_zs_kd 0.0795 (0.1080) loss_oracle 0.3959 (0.3515) acc 78.1250 (73.2812) kd_loss 0.7358 (0.6210) lr 1.9980e-03 eta 0:25:58
epoch [3/50] batch [60/288] time 0.100 (0.110) data 0.000 (0.005) loss 1.3082 (1.4427) ce_loss 0.9385 (1.0536) teacher_loss 0.9507 (1.0417) loss_zs_kd 0.0718 (0.1064) loss_oracle 0.3217 (0.3477) acc 75.0000 (72.2396) kd_loss 0.5562 (0.6350) lr 1.9980e-03 eta 0:25:20
epoch [3/50] batch [80/288] time 0.106 (0.109) data 0.000 (0.004) loss 1.4679 (1.4425) ce_loss 1.0547 (1.0576) teacher_loss 1.0215 (1.0458) loss_zs_kd 0.1073 (0.1063) loss_oracle 0.3928 (0.3436) acc 75.0000 (72.1484) kd_loss 0.6255 (0.6339) lr 1.9980e-03 eta 0:24:52
epoch [3/50] batch [100/288] time 0.099 (0.108) data 0.000 (0.003) loss 1.3652 (1.4480) ce_loss 0.9858 (1.0682) teacher_loss 1.0280 (1.0576) loss_zs_kd 0.0899 (0.1072) loss_oracle 0.2922 (0.3368) acc 75.0000 (72.0625) kd_loss 0.5722 (0.6317) lr 1.9980e-03 eta 0:24:39
epoch [3/50] batch [120/288] time 0.101 (0.107) data 0.000 (0.003) loss 1.0286 (1.4265) ce_loss 0.6870 (1.0577) teacher_loss 0.6642 (1.0465) loss_zs_kd 0.1144 (0.1088) loss_oracle 0.3072 (0.3255) acc 78.1250 (72.3698) kd_loss 0.6009 (0.6186) lr 1.9980e-03 eta 0:24:22
epoch [3/50] batch [140/288] time 0.094 (0.105) data 0.000 (0.002) loss 1.1996 (1.4117) ce_loss 0.9893 (1.0539) teacher_loss 0.9826 (1.0426) loss_zs_kd 0.0643 (0.1085) loss_oracle 0.1849 (0.3149) acc 75.0000 (72.2545) kd_loss 0.5193 (0.6096) lr 1.9980e-03 eta 0:23:59
epoch [3/50] batch [160/288] time 0.102 (0.105) data 0.000 (0.002) loss 1.8497 (1.4111) ce_loss 1.4834 (1.0585) teacher_loss 1.4837 (1.0470) loss_zs_kd 0.1381 (0.1106) loss_oracle 0.2969 (0.3088) acc 62.5000 (71.9922) kd_loss 0.5295 (0.6059) lr 1.9980e-03 eta 0:23:49
epoch [3/50] batch [180/288] time 0.092 (0.104) data 0.000 (0.002) loss 1.4248 (1.4106) ce_loss 1.1074 (1.0582) teacher_loss 1.1359 (1.0468) loss_zs_kd 0.1172 (0.1100) loss_oracle 0.2303 (0.3088) acc 75.0000 (72.0833) kd_loss 0.5326 (0.6070) lr 1.9980e-03 eta 0:23:38
epoch [3/50] batch [200/288] time 0.108 (0.103) data 0.000 (0.002) loss 1.2826 (1.4039) ce_loss 1.0186 (1.0559) teacher_loss 0.9705 (1.0444) loss_zs_kd 0.0873 (0.1101) loss_oracle 0.2684 (0.3045) acc 75.0000 (72.2656) kd_loss 0.5551 (0.6041) lr 1.9980e-03 eta 0:23:28
epoch [3/50] batch [220/288] time 0.097 (0.103) data 0.000 (0.002) loss 1.3306 (1.4136) ce_loss 0.8330 (1.0658) teacher_loss 0.8400 (1.0545) loss_zs_kd 0.1162 (0.1108) loss_oracle 0.4325 (0.3037) acc 75.0000 (72.0312) kd_loss 0.7783 (0.6032) lr 1.9980e-03 eta 0:23:19
epoch [3/50] batch [240/288] time 0.100 (0.102) data 0.001 (0.002) loss 1.7096 (1.4222) ce_loss 1.3467 (1.0702) teacher_loss 1.3559 (1.0603) loss_zs_kd 0.0983 (0.1112) loss_oracle 0.3045 (0.3064) acc 65.6250 (71.9401) kd_loss 0.6401 (0.6047) lr 1.9980e-03 eta 0:23:10
epoch [3/50] batch [260/288] time 0.106 (0.102) data 0.000 (0.001) loss 0.9903 (1.4139) ce_loss 0.7124 (1.0655) teacher_loss 0.7049 (1.0560) loss_zs_kd 0.1026 (0.1109) loss_oracle 0.2341 (0.3024) acc 81.2500 (71.9471) kd_loss 0.4308 (0.5993) lr 1.9980e-03 eta 0:23:06
epoch [3/50] batch [280/288] time 0.087 (0.102) data 0.000 (0.001) loss 1.4656 (1.4078) ce_loss 1.1035 (1.0614) teacher_loss 1.0896 (1.0519) loss_zs_kd 0.2169 (0.1125) loss_oracle 0.2676 (0.2997) acc 62.5000 (72.0536) kd_loss 0.5630 (0.5958) lr 1.9980e-03 eta 0:22:58
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,402
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.6%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.5%
******* Domain a best val acc:      86.4%, epoch: 3 *******
******* Domain a best val test acc: 83.1%, epoch: 3 *******
******* Domain a best test acc:     83.1%, epoch: 2 *******
epoch [4/50] batch [20/288] time 0.109 (0.118) data 0.000 (0.014) loss 1.2370 (1.3618) ce_loss 0.8491 (0.9928) teacher_loss 0.8434 (0.9825) loss_zs_kd 0.1015 (0.1102) loss_oracle 0.3428 (0.3241) acc 81.2500 (72.5000) kd_loss 0.6464 (0.6142) lr 1.9921e-03 eta 0:26:39
epoch [4/50] batch [40/288] time 0.094 (0.109) data 0.000 (0.007) loss 1.4713 (1.3665) ce_loss 1.1084 (1.0084) teacher_loss 1.1148 (1.0026) loss_zs_kd 0.1979 (0.1148) loss_oracle 0.2575 (0.3065) acc 68.7500 (72.7344) kd_loss 0.4954 (0.5963) lr 1.9921e-03 eta 0:24:30
epoch [4/50] batch [60/288] time 0.100 (0.107) data 0.002 (0.005) loss 1.5483 (1.3706) ce_loss 1.2148 (1.0016) teacher_loss 1.2283 (0.9994) loss_zs_kd 0.0888 (0.1143) loss_oracle 0.2755 (0.3141) acc 65.6250 (72.9688) kd_loss 0.6675 (0.6092) lr 1.9921e-03 eta 0:24:01
epoch [4/50] batch [80/288] time 0.104 (0.106) data 0.000 (0.004) loss 1.7589 (1.4037) ce_loss 1.4170 (1.0192) teacher_loss 1.3517 (1.0154) loss_zs_kd 0.1041 (0.1130) loss_oracle 0.3551 (0.3317) acc 65.6250 (72.8906) kd_loss 0.5173 (0.6245) lr 1.9921e-03 eta 0:23:52
epoch [4/50] batch [100/288] time 0.104 (0.106) data 0.000 (0.003) loss 1.2207 (1.4176) ce_loss 0.9268 (1.0399) teacher_loss 0.8732 (1.0353) loss_zs_kd 0.0866 (0.1090) loss_oracle 0.3041 (0.3279) acc 78.1250 (72.4688) kd_loss 0.6103 (0.6172) lr 1.9921e-03 eta 0:23:42
epoch [4/50] batch [120/288] time 0.098 (0.105) data 0.000 (0.003) loss 1.2855 (1.4129) ce_loss 0.9502 (1.0483) teacher_loss 0.9300 (1.0433) loss_zs_kd 0.0940 (0.1070) loss_oracle 0.3085 (0.3162) acc 81.2500 (72.2917) kd_loss 0.7493 (0.6054) lr 1.9921e-03 eta 0:23:32
epoch [4/50] batch [140/288] time 0.099 (0.104) data 0.000 (0.002) loss 1.1610 (1.4144) ce_loss 0.8267 (1.0565) teacher_loss 0.8344 (1.0507) loss_zs_kd 0.0875 (0.1067) loss_oracle 0.2828 (0.3103) acc 78.1250 (72.0982) kd_loss 0.6853 (0.6038) lr 1.9921e-03 eta 0:23:19
epoch [4/50] batch [160/288] time 0.101 (0.104) data 0.000 (0.002) loss 1.5431 (1.4051) ce_loss 1.2373 (1.0501) teacher_loss 1.2089 (1.0425) loss_zs_kd 0.1129 (0.1084) loss_oracle 0.2778 (0.3084) acc 68.7500 (72.1875) kd_loss 0.5024 (0.5998) lr 1.9921e-03 eta 0:23:11
epoch [4/50] batch [180/288] time 0.099 (0.104) data 0.001 (0.002) loss 1.7264 (1.3992) ce_loss 1.3965 (1.0471) teacher_loss 1.3599 (1.0393) loss_zs_kd 0.1509 (0.1094) loss_oracle 0.2911 (0.3052) acc 62.5000 (72.2743) kd_loss 0.5425 (0.5964) lr 1.9921e-03 eta 0:23:03
epoch [4/50] batch [200/288] time 0.095 (0.103) data 0.000 (0.002) loss 1.4765 (1.3938) ce_loss 1.1494 (1.0444) teacher_loss 1.1313 (1.0362) loss_zs_kd 0.0951 (0.1110) loss_oracle 0.2976 (0.3021) acc 71.8750 (72.5000) kd_loss 0.7560 (0.5942) lr 1.9921e-03 eta 0:22:55
epoch [4/50] batch [220/288] time 0.094 (0.103) data 0.000 (0.002) loss 1.4938 (1.3936) ce_loss 1.1592 (1.0448) teacher_loss 1.1683 (1.0380) loss_zs_kd 0.1134 (0.1124) loss_oracle 0.2688 (0.2994) acc 71.8750 (72.3722) kd_loss 0.6331 (0.5931) lr 1.9921e-03 eta 0:22:45
epoch [4/50] batch [240/288] time 0.096 (0.102) data 0.000 (0.001) loss 1.5842 (1.3884) ce_loss 1.2480 (1.0424) teacher_loss 1.2071 (1.0358) loss_zs_kd 0.0971 (0.1117) loss_oracle 0.3286 (0.2968) acc 68.7500 (72.5911) kd_loss 0.7830 (0.5917) lr 1.9921e-03 eta 0:22:36
epoch [4/50] batch [260/288] time 0.092 (0.102) data 0.001 (0.001) loss 1.1513 (1.3910) ce_loss 0.8008 (1.0465) teacher_loss 0.7786 (1.0400) loss_zs_kd 0.1260 (0.1116) loss_oracle 0.3098 (0.2951) acc 71.8750 (72.4519) kd_loss 0.6299 (0.5907) lr 1.9921e-03 eta 0:22:29
epoch [4/50] batch [280/288] time 0.103 (0.101) data 0.001 (0.001) loss 1.1262 (1.3873) ce_loss 0.7578 (1.0420) teacher_loss 0.7379 (1.0348) loss_zs_kd 0.0900 (0.1111) loss_oracle 0.3433 (0.2969) acc 78.1250 (72.7121) kd_loss 0.6957 (0.5940) lr 1.9921e-03 eta 0:22:25
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,395
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,029
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.3%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.4%, epoch: 3 *******
******* Domain a best val test acc: 83.1%, epoch: 3 *******
******* Domain a best test acc:     83.6%, epoch: 4 *******
epoch [5/50] batch [20/288] time 0.093 (0.110) data 0.000 (0.017) loss 1.6837 (1.4766) ce_loss 1.3975 (1.1734) teacher_loss 1.3827 (1.1702) loss_zs_kd 0.1330 (0.1384) loss_oracle 0.2345 (0.2372) acc 68.7500 (69.5312) kd_loss 0.6017 (0.5516) lr 1.9823e-03 eta 0:24:15
epoch [5/50] batch [40/288] time 0.101 (0.101) data 0.000 (0.009) loss 0.8114 (1.3692) ce_loss 0.4714 (1.0703) teacher_loss 0.4827 (1.0692) loss_zs_kd 0.1765 (0.1358) loss_oracle 0.2405 (0.2321) acc 93.7500 (72.1094) kd_loss 0.6333 (0.5465) lr 1.9823e-03 eta 0:22:10
epoch [5/50] batch [60/288] time 0.104 (0.097) data 0.001 (0.006) loss 1.4168 (1.3407) ce_loss 1.1680 (1.0388) teacher_loss 1.1300 (1.0378) loss_zs_kd 0.0880 (0.1302) loss_oracle 0.2428 (0.2378) acc 62.5000 (73.0729) kd_loss 0.3803 (0.5599) lr 1.9823e-03 eta 0:21:18
epoch [5/50] batch [80/288] time 0.083 (0.096) data 0.000 (0.004) loss 1.7542 (1.3248) ce_loss 1.4580 (1.0226) teacher_loss 1.4509 (1.0164) loss_zs_kd 0.1033 (0.1303) loss_oracle 0.2516 (0.2433) acc 68.7500 (73.1250) kd_loss 0.5187 (0.5590) lr 1.9823e-03 eta 0:21:08
epoch [5/50] batch [100/288] time 0.098 (0.097) data 0.000 (0.004) loss 0.9803 (1.3329) ce_loss 0.6963 (1.0332) teacher_loss 0.7066 (1.0272) loss_zs_kd 0.1263 (0.1297) loss_oracle 0.2105 (0.2408) acc 84.3750 (72.9062) kd_loss 0.4960 (0.5511) lr 1.9823e-03 eta 0:21:12
epoch [5/50] batch [120/288] time 0.095 (0.097) data 0.000 (0.003) loss 1.3328 (1.3187) ce_loss 1.0596 (1.0255) teacher_loss 1.0637 (1.0176) loss_zs_kd 0.1423 (0.1270) loss_oracle 0.1980 (0.2376) acc 75.0000 (73.1250) kd_loss 0.5320 (0.5474) lr 1.9823e-03 eta 0:21:07
epoch [5/50] batch [140/288] time 0.104 (0.097) data 0.000 (0.003) loss 1.3536 (1.3245) ce_loss 1.0850 (1.0304) teacher_loss 1.0899 (1.0236) loss_zs_kd 0.0967 (0.1243) loss_oracle 0.2153 (0.2387) acc 68.7500 (73.1250) kd_loss 0.3649 (0.5508) lr 1.9823e-03 eta 0:21:13
epoch [5/50] batch [160/288] time 0.114 (0.098) data 0.000 (0.002) loss 1.6145 (1.3308) ce_loss 1.3008 (1.0342) teacher_loss 1.2633 (1.0270) loss_zs_kd 0.1027 (0.1225) loss_oracle 0.2998 (0.2426) acc 65.6250 (72.8320) kd_loss 0.6457 (0.5522) lr 1.9823e-03 eta 0:21:20
epoch [5/50] batch [180/288] time 0.100 (0.099) data 0.000 (0.002) loss 1.2415 (1.3372) ce_loss 0.9644 (1.0390) teacher_loss 0.9029 (1.0316) loss_zs_kd 0.1083 (0.1228) loss_oracle 0.2844 (0.2442) acc 68.7500 (72.7083) kd_loss 0.6196 (0.5575) lr 1.9823e-03 eta 0:21:37
epoch [5/50] batch [200/288] time 0.111 (0.100) data 0.000 (0.002) loss 1.3484 (1.3450) ce_loss 0.9888 (1.0411) teacher_loss 0.9446 (1.0337) loss_zs_kd 0.1043 (0.1216) loss_oracle 0.3516 (0.2504) acc 78.1250 (72.7031) kd_loss 0.6657 (0.5638) lr 1.9823e-03 eta 0:21:40
epoch [5/50] batch [220/288] time 0.100 (0.100) data 0.000 (0.002) loss 1.5331 (1.3501) ce_loss 1.2168 (1.0435) teacher_loss 1.2108 (1.0371) loss_zs_kd 0.1247 (0.1213) loss_oracle 0.2599 (0.2524) acc 75.0000 (72.4006) kd_loss 0.6903 (0.5675) lr 1.9823e-03 eta 0:21:41
epoch [5/50] batch [240/288] time 0.110 (0.100) data 0.000 (0.002) loss 1.0988 (1.3463) ce_loss 0.8359 (1.0412) teacher_loss 0.8487 (1.0341) loss_zs_kd 0.1094 (0.1208) loss_oracle 0.1954 (0.2518) acc 78.1250 (72.4219) kd_loss 0.5701 (0.5664) lr 1.9823e-03 eta 0:21:43
epoch [5/50] batch [260/288] time 0.098 (0.101) data 0.000 (0.002) loss 1.3990 (1.3398) ce_loss 1.1211 (1.0364) teacher_loss 1.1337 (1.0297) loss_zs_kd 0.0677 (0.1205) loss_oracle 0.2315 (0.2499) acc 65.6250 (72.4519) kd_loss 0.6460 (0.5651) lr 1.9823e-03 eta 0:21:46
epoch [5/50] batch [280/288] time 0.102 (0.101) data 0.000 (0.001) loss 1.1499 (1.3329) ce_loss 0.7183 (1.0269) teacher_loss 0.7285 (1.0200) loss_zs_kd 0.1362 (0.1201) loss_oracle 0.3533 (0.2528) acc 84.3750 (72.7232) kd_loss 0.6213 (0.5649) lr 1.9823e-03 eta 0:21:48
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,387
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,025
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.0%
******* Domain a best val acc:      86.4%, epoch: 3 *******
******* Domain a best val test acc: 83.1%, epoch: 3 *******
******* Domain a best test acc:     83.6%, epoch: 4 *******
epoch [6/50] batch [20/288] time 0.097 (0.130) data 0.000 (0.015) loss 1.3827 (1.2509) ce_loss 1.0977 (0.9337) teacher_loss 1.0617 (0.9244) loss_zs_kd 0.0936 (0.1038) loss_oracle 0.2743 (0.2745) acc 68.7500 (72.8125) kd_loss 0.6701 (0.5973) lr 1.9686e-03 eta 0:28:02
epoch [6/50] batch [40/288] time 0.110 (0.119) data 0.001 (0.008) loss 1.2426 (1.2927) ce_loss 0.9482 (0.9796) teacher_loss 0.9387 (0.9700) loss_zs_kd 0.1198 (0.1120) loss_oracle 0.2440 (0.2667) acc 75.0000 (72.3438) kd_loss 0.6418 (0.5788) lr 1.9686e-03 eta 0:25:34
epoch [6/50] batch [60/288] time 0.116 (0.114) data 0.000 (0.005) loss 1.3852 (1.2806) ce_loss 1.0449 (0.9666) teacher_loss 1.0542 (0.9582) loss_zs_kd 0.1467 (0.1140) loss_oracle 0.2577 (0.2653) acc 68.7500 (72.7083) kd_loss 0.5337 (0.5730) lr 1.9686e-03 eta 0:24:26
epoch [6/50] batch [80/288] time 0.100 (0.111) data 0.000 (0.004) loss 1.3357 (1.2918) ce_loss 1.0195 (0.9738) teacher_loss 0.9760 (0.9638) loss_zs_kd 0.1335 (0.1171) loss_oracle 0.2929 (0.2695) acc 71.8750 (72.7734) kd_loss 0.5523 (0.5755) lr 1.9686e-03 eta 0:23:44
epoch [6/50] batch [100/288] time 0.100 (0.109) data 0.000 (0.003) loss 1.6847 (1.3169) ce_loss 1.2988 (0.9921) teacher_loss 1.3129 (0.9815) loss_zs_kd 0.1413 (0.1174) loss_oracle 0.3012 (0.2767) acc 62.5000 (72.8750) kd_loss 0.7102 (0.5870) lr 1.9686e-03 eta 0:23:19
epoch [6/50] batch [120/288] time 0.093 (0.108) data 0.000 (0.003) loss 1.5256 (1.3207) ce_loss 1.1240 (0.9859) teacher_loss 1.1130 (0.9769) loss_zs_kd 0.1469 (0.1179) loss_oracle 0.3392 (0.2848) acc 75.0000 (73.5417) kd_loss 0.6019 (0.5946) lr 1.9686e-03 eta 0:23:00
epoch [6/50] batch [140/288] time 0.108 (0.106) data 0.001 (0.002) loss 1.1369 (1.3260) ce_loss 0.8350 (0.9870) teacher_loss 0.8219 (0.9783) loss_zs_kd 0.0733 (0.1170) loss_oracle 0.2783 (0.2892) acc 78.1250 (73.4152) kd_loss 0.4925 (0.5908) lr 1.9686e-03 eta 0:22:37
epoch [6/50] batch [160/288] time 0.086 (0.104) data 0.000 (0.002) loss 1.0480 (1.3304) ce_loss 0.7144 (0.9899) teacher_loss 0.6801 (0.9814) loss_zs_kd 0.1337 (0.1194) loss_oracle 0.3010 (0.2893) acc 75.0000 (73.2617) kd_loss 0.6207 (0.5982) lr 1.9686e-03 eta 0:22:12
epoch [6/50] batch [180/288] time 0.097 (0.103) data 0.000 (0.002) loss 1.0969 (1.3312) ce_loss 0.7568 (0.9936) teacher_loss 0.7270 (0.9835) loss_zs_kd 0.1671 (0.1200) loss_oracle 0.2863 (0.2877) acc 81.2500 (73.2118) kd_loss 0.6039 (0.5971) lr 1.9686e-03 eta 0:21:56
epoch [6/50] batch [200/288] time 0.091 (0.102) data 0.000 (0.002) loss 1.3540 (1.3377) ce_loss 1.0391 (0.9985) teacher_loss 0.9856 (0.9901) loss_zs_kd 0.1116 (0.1195) loss_oracle 0.3126 (0.2878) acc 68.7500 (73.1875) kd_loss 0.4521 (0.5980) lr 1.9686e-03 eta 0:21:45
epoch [6/50] batch [220/288] time 0.101 (0.102) data 0.000 (0.002) loss 1.5777 (1.3433) ce_loss 1.2236 (1.0020) teacher_loss 1.1872 (0.9937) loss_zs_kd 0.1481 (0.1205) loss_oracle 0.3164 (0.2894) acc 71.8750 (73.1676) kd_loss 0.6573 (0.6002) lr 1.9686e-03 eta 0:21:37
epoch [6/50] batch [240/288] time 0.091 (0.101) data 0.000 (0.001) loss 1.2852 (1.3485) ce_loss 0.9849 (1.0070) teacher_loss 0.9829 (0.9990) loss_zs_kd 0.0777 (0.1202) loss_oracle 0.2634 (0.2894) acc 75.0000 (73.0469) kd_loss 0.4396 (0.5997) lr 1.9686e-03 eta 0:21:29
epoch [6/50] batch [260/288] time 0.095 (0.101) data 0.000 (0.001) loss 1.6228 (1.3522) ce_loss 1.2705 (1.0102) teacher_loss 1.2557 (1.0017) loss_zs_kd 0.1042 (0.1217) loss_oracle 0.3150 (0.2896) acc 68.7500 (73.0048) kd_loss 0.6899 (0.6031) lr 1.9686e-03 eta 0:21:19
epoch [6/50] batch [280/288] time 0.089 (0.100) data 0.000 (0.001) loss 1.5625 (1.3511) ce_loss 1.2402 (1.0100) teacher_loss 1.2217 (1.0025) loss_zs_kd 0.1515 (0.1220) loss_oracle 0.2651 (0.2876) acc 68.7500 (73.0915) kd_loss 0.5896 (0.6003) lr 1.9686e-03 eta 0:21:09
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,404
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,029
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.0%
******* Domain a best val acc:      86.4%, epoch: 6 *******
******* Domain a best val test acc: 83.6%, epoch: 6 *******
******* Domain a best test acc:     83.6%, epoch: 4 *******
epoch [7/50] batch [20/288] time 0.092 (0.107) data 0.000 (0.013) loss 1.5435 (1.3708) ce_loss 1.2676 (1.0666) teacher_loss 1.2601 (1.0629) loss_zs_kd 0.0923 (0.1122) loss_oracle 0.2373 (0.2518) acc 68.7500 (72.6562) kd_loss 0.6730 (0.5926) lr 1.9511e-03 eta 0:22:38
epoch [7/50] batch [40/288] time 0.091 (0.099) data 0.000 (0.006) loss 1.0435 (1.3039) ce_loss 0.7222 (1.0005) teacher_loss 0.6613 (0.9960) loss_zs_kd 0.1163 (0.1141) loss_oracle 0.3241 (0.2509) acc 90.6250 (74.2188) kd_loss 0.7072 (0.6022) lr 1.9511e-03 eta 0:20:51
epoch [7/50] batch [60/288] time 0.085 (0.096) data 0.000 (0.004) loss 1.4332 (1.2930) ce_loss 1.1680 (0.9819) teacher_loss 1.1087 (0.9776) loss_zs_kd 0.1175 (0.1144) loss_oracle 0.2658 (0.2581) acc 68.7500 (74.5833) kd_loss 0.5177 (0.6027) lr 1.9511e-03 eta 0:20:13
epoch [7/50] batch [80/288] time 0.099 (0.096) data 0.000 (0.003) loss 1.3407 (1.3003) ce_loss 0.9580 (0.9830) teacher_loss 0.9233 (0.9761) loss_zs_kd 0.1404 (0.1176) loss_oracle 0.3472 (0.2653) acc 75.0000 (74.2969) kd_loss 0.6405 (0.6036) lr 1.9511e-03 eta 0:20:10
epoch [7/50] batch [100/288] time 0.097 (0.096) data 0.000 (0.003) loss 0.9089 (1.3025) ce_loss 0.6055 (0.9797) teacher_loss 0.5775 (0.9743) loss_zs_kd 0.1012 (0.1187) loss_oracle 0.2808 (0.2689) acc 87.5000 (73.9375) kd_loss 0.6623 (0.6125) lr 1.9511e-03 eta 0:20:05
epoch [7/50] batch [120/288] time 0.090 (0.096) data 0.000 (0.002) loss 1.5906 (1.2978) ce_loss 1.2969 (0.9757) teacher_loss 1.2797 (0.9693) loss_zs_kd 0.1154 (0.1190) loss_oracle 0.2532 (0.2689) acc 71.8750 (73.9062) kd_loss 0.6267 (0.6226) lr 1.9511e-03 eta 0:20:04
epoch [7/50] batch [140/288] time 0.096 (0.096) data 0.000 (0.002) loss 1.4212 (1.3096) ce_loss 1.0703 (0.9870) teacher_loss 1.0420 (0.9798) loss_zs_kd 0.1161 (0.1210) loss_oracle 0.3211 (0.2694) acc 71.8750 (73.4375) kd_loss 0.7178 (0.6185) lr 1.9511e-03 eta 0:20:07
epoch [7/50] batch [160/288] time 0.104 (0.096) data 0.000 (0.002) loss 1.3501 (1.3269) ce_loss 1.0547 (1.0018) teacher_loss 1.0285 (0.9959) loss_zs_kd 0.1198 (0.1216) loss_oracle 0.2617 (0.2702) acc 68.7500 (73.0469) kd_loss 0.7059 (0.6204) lr 1.9511e-03 eta 0:20:06
epoch [7/50] batch [180/288] time 0.108 (0.097) data 0.000 (0.002) loss 1.4256 (1.3311) ce_loss 1.1211 (1.0068) teacher_loss 1.1289 (1.0001) loss_zs_kd 0.1346 (0.1222) loss_oracle 0.2294 (0.2699) acc 75.0000 (73.1250) kd_loss 0.5264 (0.6176) lr 1.9511e-03 eta 0:20:13
epoch [7/50] batch [200/288] time 0.107 (0.098) data 0.000 (0.001) loss 1.0524 (1.3247) ce_loss 0.6934 (0.9991) teacher_loss 0.6958 (0.9933) loss_zs_kd 0.1417 (0.1234) loss_oracle 0.2858 (0.2697) acc 75.0000 (73.1875) kd_loss 0.5580 (0.6162) lr 1.9511e-03 eta 0:20:18
epoch [7/50] batch [220/288] time 0.100 (0.098) data 0.000 (0.001) loss 1.5318 (1.3224) ce_loss 1.2656 (1.0001) teacher_loss 1.2734 (0.9942) loss_zs_kd 0.1124 (0.1225) loss_oracle 0.2022 (0.2669) acc 68.7500 (73.2244) kd_loss 0.5469 (0.6143) lr 1.9511e-03 eta 0:20:19
epoch [7/50] batch [240/288] time 0.097 (0.098) data 0.000 (0.001) loss 1.7373 (1.3263) ce_loss 1.4492 (1.0064) teacher_loss 1.4296 (1.0005) loss_zs_kd 0.1121 (0.1222) loss_oracle 0.2516 (0.2647) acc 59.3750 (73.1510) kd_loss 0.6306 (0.6126) lr 1.9511e-03 eta 0:20:21
epoch [7/50] batch [260/288] time 0.115 (0.098) data 0.000 (0.001) loss 1.2716 (1.3260) ce_loss 0.9741 (1.0081) teacher_loss 0.9272 (1.0027) loss_zs_kd 0.1071 (0.1213) loss_oracle 0.2908 (0.2627) acc 75.0000 (73.0889) kd_loss 0.6117 (0.6121) lr 1.9511e-03 eta 0:20:22
epoch [7/50] batch [280/288] time 0.101 (0.099) data 0.000 (0.001) loss 0.9650 (1.3188) ce_loss 0.6938 (1.0030) teacher_loss 0.6705 (0.9978) loss_zs_kd 0.1093 (0.1205) loss_oracle 0.2398 (0.2608) acc 78.1250 (73.3371) kd_loss 0.6258 (0.6102) lr 1.9511e-03 eta 0:20:24
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,412
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 85.9%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,031
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 80.1%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.6%, epoch: 7 *******
******* Domain a best val test acc: 83.7%, epoch: 7 *******
******* Domain a best test acc:     83.7%, epoch: 7 *******
epoch [8/50] batch [20/288] time 0.098 (0.115) data 0.000 (0.014) loss 1.2846 (1.3067) ce_loss 0.8989 (0.9911) teacher_loss 0.9316 (0.9876) loss_zs_kd 0.2074 (0.1329) loss_oracle 0.2492 (0.2527) acc 84.3750 (73.5938) kd_loss 0.5915 (0.6102) lr 1.9298e-03 eta 0:23:46
epoch [8/50] batch [40/288] time 0.113 (0.110) data 0.000 (0.007) loss 1.1952 (1.2809) ce_loss 0.8579 (0.9777) teacher_loss 0.8880 (0.9682) loss_zs_kd 0.1547 (0.1278) loss_oracle 0.2299 (0.2488) acc 78.1250 (73.5156) kd_loss 0.5521 (0.5969) lr 1.9298e-03 eta 0:22:34
epoch [8/50] batch [60/288] time 0.096 (0.107) data 0.000 (0.005) loss 1.8432 (1.2738) ce_loss 1.5039 (0.9653) teacher_loss 1.5500 (0.9597) loss_zs_kd 0.0780 (0.1253) loss_oracle 0.2542 (0.2515) acc 62.5000 (73.9583) kd_loss 0.8410 (0.6098) lr 1.9298e-03 eta 0:22:02
epoch [8/50] batch [80/288] time 0.097 (0.107) data 0.000 (0.004) loss 1.3719 (1.2603) ce_loss 1.1133 (0.9585) teacher_loss 1.0993 (0.9515) loss_zs_kd 0.0883 (0.1250) loss_oracle 0.2285 (0.2463) acc 68.7500 (74.2578) kd_loss 0.6907 (0.5912) lr 1.9298e-03 eta 0:21:54
epoch [8/50] batch [100/288] time 0.107 (0.106) data 0.000 (0.003) loss 1.0646 (1.2672) ce_loss 0.7744 (0.9666) teacher_loss 0.7439 (0.9614) loss_zs_kd 0.1647 (0.1251) loss_oracle 0.2383 (0.2433) acc 84.3750 (74.3125) kd_loss 0.4787 (0.5823) lr 1.9298e-03 eta 0:21:45
epoch [8/50] batch [120/288] time 0.100 (0.106) data 0.000 (0.003) loss 1.2808 (1.2564) ce_loss 0.9702 (0.9581) teacher_loss 0.9708 (0.9511) loss_zs_kd 0.1387 (0.1263) loss_oracle 0.2406 (0.2421) acc 75.0000 (74.4792) kd_loss 0.7361 (0.5804) lr 1.9298e-03 eta 0:21:34
epoch [8/50] batch [140/288] time 0.098 (0.105) data 0.000 (0.002) loss 1.2411 (1.2673) ce_loss 0.9067 (0.9682) teacher_loss 0.9016 (0.9620) loss_zs_kd 0.1747 (0.1268) loss_oracle 0.2522 (0.2418) acc 71.8750 (74.1964) kd_loss 0.3930 (0.5813) lr 1.9298e-03 eta 0:21:22
epoch [8/50] batch [160/288] time 0.105 (0.104) data 0.000 (0.002) loss 1.5101 (1.2843) ce_loss 1.2109 (0.9861) teacher_loss 1.2251 (0.9801) loss_zs_kd 0.1568 (0.1272) loss_oracle 0.2067 (0.2406) acc 62.5000 (73.7500) kd_loss 0.4976 (0.5800) lr 1.9298e-03 eta 0:21:12
epoch [8/50] batch [180/288] time 0.099 (0.104) data 0.000 (0.002) loss 1.6731 (1.2835) ce_loss 1.3779 (0.9868) teacher_loss 1.3944 (0.9812) loss_zs_kd 0.1091 (0.1266) loss_oracle 0.2242 (0.2390) acc 68.7500 (73.6111) kd_loss 0.4577 (0.5801) lr 1.9298e-03 eta 0:21:05
epoch [8/50] batch [200/288] time 0.099 (0.103) data 0.000 (0.002) loss 1.5599 (1.2841) ce_loss 1.2900 (0.9895) teacher_loss 1.2597 (0.9832) loss_zs_kd 0.1151 (0.1268) loss_oracle 0.2426 (0.2374) acc 62.5000 (73.5312) kd_loss 0.5830 (0.5782) lr 1.9298e-03 eta 0:21:00
epoch [8/50] batch [220/288] time 0.100 (0.103) data 0.000 (0.002) loss 1.0593 (1.2793) ce_loss 0.7563 (0.9854) teacher_loss 0.7342 (0.9790) loss_zs_kd 0.1161 (0.1266) loss_oracle 0.2671 (0.2370) acc 87.5000 (73.6506) kd_loss 0.5182 (0.5769) lr 1.9298e-03 eta 0:20:57
epoch [8/50] batch [240/288] time 0.113 (0.104) data 0.001 (0.001) loss 1.2939 (1.2831) ce_loss 0.9517 (0.9888) teacher_loss 0.9669 (0.9822) loss_zs_kd 0.1635 (0.1281) loss_oracle 0.2453 (0.2369) acc 75.0000 (73.5286) kd_loss 0.5601 (0.5735) lr 1.9298e-03 eta 0:20:57
epoch [8/50] batch [260/288] time 0.099 (0.103) data 0.000 (0.001) loss 1.2899 (1.2843) ce_loss 0.9438 (0.9890) teacher_loss 0.9676 (0.9825) loss_zs_kd 0.1842 (0.1285) loss_oracle 0.2302 (0.2375) acc 75.0000 (73.5697) kd_loss 0.4995 (0.5746) lr 1.9298e-03 eta 0:20:52
epoch [8/50] batch [280/288] time 0.103 (0.103) data 0.000 (0.001) loss 1.7534 (1.2913) ce_loss 1.4512 (0.9951) teacher_loss 1.4567 (0.9888) loss_zs_kd 0.1329 (0.1281) loss_oracle 0.2302 (0.2385) acc 59.3750 (73.4040) kd_loss 0.5434 (0.5750) lr 1.9298e-03 eta 0:20:48
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,418
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.1%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,033
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 80.3%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.8%, epoch: 8 *******
******* Domain a best val test acc: 83.8%, epoch: 8 *******
******* Domain a best test acc:     83.8%, epoch: 8 *******
epoch [9/50] batch [20/288] time 0.107 (0.117) data 0.000 (0.014) loss 1.2901 (1.3123) ce_loss 1.0850 (1.0075) teacher_loss 1.0373 (0.9961) loss_zs_kd 0.1184 (0.1288) loss_oracle 0.1936 (0.2518) acc 71.8750 (72.1875) kd_loss 0.4314 (0.5926) lr 1.9048e-03 eta 0:23:31
epoch [9/50] batch [40/288] time 0.102 (0.110) data 0.000 (0.007) loss 0.8750 (1.2524) ce_loss 0.6426 (0.9519) teacher_loss 0.6005 (0.9456) loss_zs_kd 0.0835 (0.1274) loss_oracle 0.2328 (0.2431) acc 78.1250 (74.2188) kd_loss 0.4196 (0.5826) lr 1.9048e-03 eta 0:22:09
epoch [9/50] batch [60/288] time 0.101 (0.106) data 0.000 (0.005) loss 1.3702 (1.2590) ce_loss 1.0986 (0.9582) teacher_loss 1.1087 (0.9525) loss_zs_kd 0.1196 (0.1284) loss_oracle 0.2016 (0.2424) acc 68.7500 (73.8542) kd_loss 0.5395 (0.5859) lr 1.9048e-03 eta 0:21:18
epoch [9/50] batch [80/288] time 0.111 (0.105) data 0.000 (0.004) loss 1.1502 (1.2883) ce_loss 0.8218 (0.9872) teacher_loss 0.8284 (0.9837) loss_zs_kd 0.1212 (0.1306) loss_oracle 0.2612 (0.2393) acc 87.5000 (73.5156) kd_loss 0.5544 (0.5728) lr 1.9048e-03 eta 0:21:07
epoch [9/50] batch [100/288] time 0.101 (0.105) data 0.000 (0.003) loss 1.0953 (1.2874) ce_loss 0.7275 (0.9881) teacher_loss 0.7955 (0.9854) loss_zs_kd 0.1298 (0.1288) loss_oracle 0.2348 (0.2376) acc 68.7500 (73.7188) kd_loss 0.5516 (0.5671) lr 1.9048e-03 eta 0:20:55
epoch [9/50] batch [120/288] time 0.100 (0.104) data 0.000 (0.003) loss 1.2262 (1.2912) ce_loss 0.9736 (0.9996) teacher_loss 0.9598 (0.9949) loss_zs_kd 0.1321 (0.1298) loss_oracle 0.2003 (0.2314) acc 71.8750 (73.3073) kd_loss 0.4597 (0.5561) lr 1.9048e-03 eta 0:20:45
epoch [9/50] batch [140/288] time 0.103 (0.103) data 0.000 (0.002) loss 1.1848 (1.2930) ce_loss 0.9653 (1.0068) teacher_loss 0.9748 (1.0017) loss_zs_kd 0.0643 (0.1302) loss_oracle 0.1778 (0.2262) acc 71.8750 (73.4375) kd_loss 0.4342 (0.5477) lr 1.9048e-03 eta 0:20:36
epoch [9/50] batch [160/288] time 0.096 (0.103) data 0.000 (0.002) loss 1.1625 (1.2864) ce_loss 0.7588 (1.0006) teacher_loss 0.7908 (0.9943) loss_zs_kd 0.1575 (0.1330) loss_oracle 0.2930 (0.2257) acc 84.3750 (73.5156) kd_loss 0.8220 (0.5493) lr 1.9048e-03 eta 0:20:31
epoch [9/50] batch [180/288] time 0.098 (0.103) data 0.000 (0.002) loss 1.8077 (1.2866) ce_loss 1.6045 (1.0029) teacher_loss 1.5453 (0.9958) loss_zs_kd 0.1633 (0.1321) loss_oracle 0.1808 (0.2247) acc 65.6250 (73.4201) kd_loss 0.3863 (0.5493) lr 1.9048e-03 eta 0:20:24
epoch [9/50] batch [200/288] time 0.099 (0.103) data 0.000 (0.002) loss 1.5094 (1.2943) ce_loss 1.2373 (1.0104) teacher_loss 1.2595 (1.0043) loss_zs_kd 0.1285 (0.1323) loss_oracle 0.1856 (0.2238) acc 68.7500 (73.1719) kd_loss 0.3969 (0.5484) lr 1.9048e-03 eta 0:20:21
epoch [9/50] batch [220/288] time 0.099 (0.103) data 0.000 (0.001) loss 0.9783 (1.2943) ce_loss 0.6538 (1.0103) teacher_loss 0.6336 (1.0045) loss_zs_kd 0.1826 (0.1322) loss_oracle 0.2534 (0.2237) acc 84.3750 (73.1676) kd_loss 0.6280 (0.5500) lr 1.9048e-03 eta 0:20:20
epoch [9/50] batch [240/288] time 0.109 (0.103) data 0.000 (0.001) loss 1.3667 (1.2919) ce_loss 1.0459 (1.0080) teacher_loss 1.0148 (1.0016) loss_zs_kd 0.1902 (0.1316) loss_oracle 0.2568 (0.2244) acc 71.8750 (73.1901) kd_loss 0.4246 (0.5529) lr 1.9048e-03 eta 0:20:17
epoch [9/50] batch [260/288] time 0.099 (0.103) data 0.000 (0.001) loss 1.1623 (1.2959) ce_loss 0.9370 (1.0115) teacher_loss 0.8689 (1.0052) loss_zs_kd 0.1200 (0.1315) loss_oracle 0.2334 (0.2249) acc 71.8750 (73.0649) kd_loss 0.5135 (0.5544) lr 1.9048e-03 eta 0:20:14
epoch [9/50] batch [280/288] time 0.104 (0.103) data 0.000 (0.001) loss 1.2578 (1.2907) ce_loss 0.9668 (1.0051) teacher_loss 0.9418 (0.9985) loss_zs_kd 0.0711 (0.1319) loss_oracle 0.2804 (0.2262) acc 75.0000 (73.1696) kd_loss 0.5614 (0.5550) lr 1.9048e-03 eta 0:20:14
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,430
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,029
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.0%
******* Domain a best val acc:      87.1%, epoch: 9 *******
******* Domain a best val test acc: 83.6%, epoch: 9 *******
******* Domain a best test acc:     83.8%, epoch: 8 *******
epoch [10/50] batch [20/288] time 0.102 (0.110) data 0.000 (0.013) loss 1.1047 (1.3220) ce_loss 0.7969 (1.0201) teacher_loss 0.7876 (1.0146) loss_zs_kd 0.0897 (0.1322) loss_oracle 0.2722 (0.2413) acc 78.1250 (74.8438) kd_loss 0.6563 (0.5747) lr 1.8763e-03 eta 0:21:32
epoch [10/50] batch [40/288] time 0.088 (0.102) data 0.000 (0.007) loss 1.5027 (1.2798) ce_loss 1.1523 (0.9779) teacher_loss 1.1445 (0.9699) loss_zs_kd 0.1703 (0.1352) loss_oracle 0.2730 (0.2424) acc 65.6250 (75.4688) kd_loss 0.6625 (0.5709) lr 1.8763e-03 eta 0:20:03
epoch [10/50] batch [60/288] time 0.093 (0.100) data 0.000 (0.004) loss 1.1876 (1.2524) ce_loss 0.8677 (0.9471) teacher_loss 0.8607 (0.9414) loss_zs_kd 0.0971 (0.1333) loss_oracle 0.2784 (0.2444) acc 78.1250 (75.6771) kd_loss 0.6067 (0.5837) lr 1.8763e-03 eta 0:19:37
epoch [10/50] batch [80/288] time 0.095 (0.099) data 0.000 (0.003) loss 1.4305 (1.2839) ce_loss 1.1523 (0.9757) teacher_loss 1.1088 (0.9694) loss_zs_kd 0.0961 (0.1359) loss_oracle 0.2736 (0.2466) acc 81.2500 (74.9219) kd_loss 0.5046 (0.5832) lr 1.8763e-03 eta 0:19:19
epoch [10/50] batch [100/288] time 0.090 (0.098) data 0.000 (0.003) loss 1.5998 (1.2709) ce_loss 1.3232 (0.9654) teacher_loss 1.3220 (0.9595) loss_zs_kd 0.1089 (0.1320) loss_oracle 0.2234 (0.2454) acc 68.7500 (74.9375) kd_loss 0.5722 (0.5744) lr 1.8763e-03 eta 0:19:09
epoch [10/50] batch [120/288] time 0.106 (0.098) data 0.000 (0.002) loss 1.2683 (1.2687) ce_loss 0.8979 (0.9644) teacher_loss 0.8967 (0.9587) loss_zs_kd 0.1297 (0.1309) loss_oracle 0.3068 (0.2445) acc 81.2500 (75.1562) kd_loss 0.7325 (0.5753) lr 1.8763e-03 eta 0:19:05
epoch [10/50] batch [140/288] time 0.095 (0.098) data 0.000 (0.002) loss 1.5301 (1.2815) ce_loss 1.2539 (0.9801) teacher_loss 1.2256 (0.9737) loss_zs_kd 0.1308 (0.1325) loss_oracle 0.2391 (0.2415) acc 68.7500 (74.8661) kd_loss 0.4933 (0.5704) lr 1.8763e-03 eta 0:18:59
epoch [10/50] batch [160/288] time 0.099 (0.097) data 0.000 (0.002) loss 0.8914 (1.2769) ce_loss 0.6694 (0.9783) teacher_loss 0.6672 (0.9717) loss_zs_kd 0.1043 (0.1317) loss_oracle 0.1721 (0.2393) acc 87.5000 (74.8047) kd_loss 0.3030 (0.5710) lr 1.8763e-03 eta 0:18:53
epoch [10/50] batch [180/288] time 0.090 (0.097) data 0.000 (0.002) loss 1.3910 (1.2893) ce_loss 1.1143 (0.9881) teacher_loss 1.1072 (0.9835) loss_zs_kd 0.1057 (0.1316) loss_oracle 0.2310 (0.2400) acc 75.0000 (74.3924) kd_loss 0.5206 (0.5739) lr 1.8763e-03 eta 0:18:51
epoch [10/50] batch [200/288] time 0.099 (0.097) data 0.000 (0.001) loss 1.5505 (1.2945) ce_loss 1.2871 (0.9951) teacher_loss 1.2476 (0.9899) loss_zs_kd 0.1077 (0.1307) loss_oracle 0.2490 (0.2393) acc 62.5000 (74.2188) kd_loss 0.7346 (0.5755) lr 1.8763e-03 eta 0:18:46
epoch [10/50] batch [220/288] time 0.091 (0.097) data 0.000 (0.001) loss 1.3572 (1.2918) ce_loss 1.1025 (0.9948) teacher_loss 1.1004 (0.9901) loss_zs_kd 0.1297 (0.1309) loss_oracle 0.1919 (0.2363) acc 65.6250 (74.2614) kd_loss 0.4144 (0.5721) lr 1.8763e-03 eta 0:18:41
epoch [10/50] batch [240/288] time 0.102 (0.097) data 0.000 (0.001) loss 1.1790 (1.2913) ce_loss 0.9346 (0.9970) teacher_loss 0.9146 (0.9917) loss_zs_kd 0.1478 (0.1313) loss_oracle 0.1904 (0.2340) acc 71.8750 (74.1146) kd_loss 0.4785 (0.5730) lr 1.8763e-03 eta 0:18:40
epoch [10/50] batch [260/288] time 0.095 (0.097) data 0.000 (0.001) loss 1.3229 (1.2927) ce_loss 1.1006 (0.9974) teacher_loss 1.0890 (0.9926) loss_zs_kd 0.1349 (0.1325) loss_oracle 0.1665 (0.2338) acc 71.8750 (73.9663) kd_loss 0.2128 (0.5719) lr 1.8763e-03 eta 0:18:36
epoch [10/50] batch [280/288] time 0.102 (0.097) data 0.000 (0.001) loss 1.8033 (1.3008) ce_loss 1.4883 (1.0052) teacher_loss 1.4684 (1.0001) loss_zs_kd 0.1786 (0.1332) loss_oracle 0.2456 (0.2340) acc 65.6250 (73.7835) kd_loss 0.6834 (0.5724) lr 1.8763e-03 eta 0:18:36
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,421
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,028
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.1%
******* Domain a best val acc:      87.1%, epoch: 9 *******
******* Domain a best val test acc: 83.6%, epoch: 9 *******
******* Domain a best test acc:     83.8%, epoch: 8 *******
epoch [11/50] batch [20/288] time 0.101 (0.120) data 0.000 (0.014) loss 1.8795 (1.3361) ce_loss 1.5518 (1.0219) teacher_loss 1.5624 (1.0152) loss_zs_kd 0.1058 (0.1362) loss_oracle 0.2643 (0.2528) acc 62.5000 (72.0312) kd_loss 0.6613 (0.5690) lr 1.8443e-03 eta 0:22:58
epoch [11/50] batch [40/288] time 0.096 (0.113) data 0.000 (0.007) loss 1.4482 (1.3327) ce_loss 1.1758 (1.0172) teacher_loss 1.1750 (1.0104) loss_zs_kd 0.1569 (0.1353) loss_oracle 0.1948 (0.2546) acc 71.8750 (71.7969) kd_loss 0.5930 (0.5979) lr 1.8443e-03 eta 0:21:40
epoch [11/50] batch [60/288] time 0.099 (0.111) data 0.000 (0.005) loss 1.0750 (1.3244) ce_loss 0.8159 (1.0114) teacher_loss 0.8406 (1.0051) loss_zs_kd 0.1591 (0.1349) loss_oracle 0.1548 (0.2518) acc 75.0000 (72.3438) kd_loss 0.3344 (0.6001) lr 1.8443e-03 eta 0:21:11
epoch [11/50] batch [80/288] time 0.107 (0.110) data 0.000 (0.004) loss 1.3312 (1.2992) ce_loss 1.0820 (0.9879) teacher_loss 1.0407 (0.9814) loss_zs_kd 0.0904 (0.1327) loss_oracle 0.2453 (0.2514) acc 65.6250 (73.0078) kd_loss 0.6580 (0.5993) lr 1.8443e-03 eta 0:20:54
epoch [11/50] batch [100/288] time 0.109 (0.109) data 0.000 (0.003) loss 1.5186 (1.2844) ce_loss 1.1924 (0.9754) teacher_loss 1.1805 (0.9687) loss_zs_kd 0.1580 (0.1315) loss_oracle 0.2591 (0.2500) acc 68.7500 (73.3750) kd_loss 0.5370 (0.5998) lr 1.8443e-03 eta 0:20:46
epoch [11/50] batch [120/288] time 0.104 (0.109) data 0.001 (0.003) loss 1.7724 (1.2886) ce_loss 1.4746 (0.9785) teacher_loss 1.4472 (0.9732) loss_zs_kd 0.1197 (0.1320) loss_oracle 0.2654 (0.2494) acc 56.2500 (73.3333) kd_loss 0.6358 (0.5968) lr 1.8443e-03 eta 0:20:40
epoch [11/50] batch [140/288] time 0.103 (0.109) data 0.000 (0.002) loss 1.1639 (1.2883) ce_loss 0.8569 (0.9797) teacher_loss 0.8379 (0.9749) loss_zs_kd 0.0935 (0.1317) loss_oracle 0.2793 (0.2475) acc 81.2500 (73.3482) kd_loss 0.6237 (0.5901) lr 1.8443e-03 eta 0:20:35
epoch [11/50] batch [160/288] time 0.101 (0.108) data 0.000 (0.002) loss 1.5445 (1.2999) ce_loss 1.2793 (0.9933) teacher_loss 1.2649 (0.9876) loss_zs_kd 0.1181 (0.1320) loss_oracle 0.2205 (0.2464) acc 65.6250 (73.1055) kd_loss 0.5673 (0.5891) lr 1.8443e-03 eta 0:20:28
epoch [11/50] batch [180/288] time 0.103 (0.108) data 0.001 (0.002) loss 1.3599 (1.2949) ce_loss 1.0586 (0.9893) teacher_loss 1.0630 (0.9836) loss_zs_kd 0.1449 (0.1325) loss_oracle 0.2244 (0.2450) acc 78.1250 (73.1944) kd_loss 0.5968 (0.5885) lr 1.8443e-03 eta 0:20:21
epoch [11/50] batch [200/288] time 0.110 (0.107) data 0.001 (0.002) loss 1.3583 (1.2892) ce_loss 1.0352 (0.9848) teacher_loss 1.0044 (0.9795) loss_zs_kd 0.1923 (0.1324) loss_oracle 0.2578 (0.2435) acc 75.0000 (73.3125) kd_loss 0.6287 (0.5879) lr 1.8443e-03 eta 0:20:15
epoch [11/50] batch [220/288] time 0.107 (0.107) data 0.000 (0.002) loss 1.2730 (1.2904) ce_loss 0.9775 (0.9849) teacher_loss 0.9548 (0.9798) loss_zs_kd 0.1259 (0.1341) loss_oracle 0.2552 (0.2436) acc 84.3750 (73.2670) kd_loss 0.5623 (0.5924) lr 1.8443e-03 eta 0:20:11
epoch [11/50] batch [240/288] time 0.108 (0.107) data 0.000 (0.001) loss 1.3209 (1.2884) ce_loss 1.0068 (0.9823) teacher_loss 1.0158 (0.9777) loss_zs_kd 0.1269 (0.1345) loss_oracle 0.2416 (0.2434) acc 71.8750 (73.3333) kd_loss 0.7558 (0.5958) lr 1.8443e-03 eta 0:20:09
epoch [11/50] batch [260/288] time 0.106 (0.107) data 0.000 (0.001) loss 1.2201 (1.2899) ce_loss 0.9531 (0.9840) teacher_loss 0.9222 (0.9796) loss_zs_kd 0.1308 (0.1350) loss_oracle 0.2325 (0.2427) acc 75.0000 (73.2812) kd_loss 0.5234 (0.5944) lr 1.8443e-03 eta 0:20:06
epoch [11/50] batch [280/288] time 0.105 (0.107) data 0.000 (0.001) loss 0.9642 (1.2793) ce_loss 0.7402 (0.9755) teacher_loss 0.7166 (0.9705) loss_zs_kd 0.0923 (0.1351) loss_oracle 0.2015 (0.2412) acc 81.2500 (73.5156) kd_loss 0.4907 (0.5918) lr 1.8443e-03 eta 0:20:03
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,429
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,036
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 80.5%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      87.1%, epoch: 9 *******
******* Domain a best val test acc: 83.6%, epoch: 9 *******
******* Domain a best test acc:     83.9%, epoch: 11 *******
epoch [12/50] batch [20/288] time 0.101 (0.114) data 0.000 (0.013) loss 1.2771 (1.3254) ce_loss 0.9609 (1.0086) teacher_loss 0.9671 (0.9984) loss_zs_kd 0.0891 (0.1343) loss_oracle 0.2654 (0.2598) acc 81.2500 (73.1250) kd_loss 0.4335 (0.6175) lr 1.8090e-03 eta 0:21:22
epoch [12/50] batch [40/288] time 0.089 (0.107) data 0.000 (0.007) loss 1.3098 (1.2958) ce_loss 1.0107 (0.9773) teacher_loss 1.0089 (0.9730) loss_zs_kd 0.0911 (0.1356) loss_oracle 0.2553 (0.2550) acc 75.0000 (73.4375) kd_loss 0.7271 (0.6224) lr 1.8090e-03 eta 0:19:52
epoch [12/50] batch [60/288] time 0.101 (0.105) data 0.000 (0.005) loss 1.4294 (1.3117) ce_loss 1.1914 (0.9991) teacher_loss 1.1163 (0.9908) loss_zs_kd 0.1464 (0.1351) loss_oracle 0.2399 (0.2534) acc 75.0000 (73.0208) kd_loss 0.5600 (0.6117) lr 1.8090e-03 eta 0:19:31
epoch [12/50] batch [80/288] time 0.101 (0.104) data 0.000 (0.004) loss 2.2412 (1.3137) ce_loss 1.9531 (1.0036) teacher_loss 1.9275 (0.9960) loss_zs_kd 0.1574 (0.1385) loss_oracle 0.2350 (0.2484) acc 50.0000 (73.2812) kd_loss 0.6164 (0.5995) lr 1.8090e-03 eta 0:19:19
epoch [12/50] batch [100/288] time 0.093 (0.103) data 0.000 (0.003) loss 1.4283 (1.2951) ce_loss 1.0791 (0.9868) teacher_loss 1.0965 (0.9802) loss_zs_kd 0.1291 (0.1358) loss_oracle 0.2673 (0.2469) acc 62.5000 (73.6250) kd_loss 0.5744 (0.5990) lr 1.8090e-03 eta 0:19:01
epoch [12/50] batch [120/288] time 0.104 (0.103) data 0.000 (0.002) loss 1.5473 (1.2871) ce_loss 1.2207 (0.9808) teacher_loss 1.2249 (0.9755) loss_zs_kd 0.1385 (0.1345) loss_oracle 0.2532 (0.2444) acc 65.6250 (73.9062) kd_loss 0.6862 (0.5916) lr 1.8090e-03 eta 0:18:59
epoch [12/50] batch [140/288] time 0.095 (0.102) data 0.001 (0.002) loss 0.8209 (1.2919) ce_loss 0.5205 (0.9866) teacher_loss 0.4945 (0.9818) loss_zs_kd 0.1005 (0.1354) loss_oracle 0.2761 (0.2424) acc 90.6250 (73.7054) kd_loss 0.5736 (0.5851) lr 1.8090e-03 eta 0:18:50
epoch [12/50] batch [160/288] time 0.097 (0.102) data 0.000 (0.002) loss 1.3561 (1.2920) ce_loss 0.9780 (0.9841) teacher_loss 1.0009 (0.9805) loss_zs_kd 0.1940 (0.1364) loss_oracle 0.2582 (0.2433) acc 75.0000 (73.5156) kd_loss 0.5883 (0.5828) lr 1.8090e-03 eta 0:18:45
epoch [12/50] batch [180/288] time 0.098 (0.101) data 0.000 (0.002) loss 1.1358 (1.3050) ce_loss 0.8359 (0.9980) teacher_loss 0.8476 (0.9934) loss_zs_kd 0.1606 (0.1375) loss_oracle 0.2080 (0.2428) acc 84.3750 (73.1771) kd_loss 0.5394 (0.5843) lr 1.8090e-03 eta 0:18:40
epoch [12/50] batch [200/288] time 0.090 (0.101) data 0.000 (0.002) loss 1.4980 (1.3077) ce_loss 1.1025 (0.9995) teacher_loss 1.1363 (0.9948) loss_zs_kd 0.1423 (0.1372) loss_oracle 0.2906 (0.2443) acc 68.7500 (73.2812) kd_loss 0.7323 (0.5889) lr 1.8090e-03 eta 0:18:29
epoch [12/50] batch [220/288] time 0.098 (0.100) data 0.000 (0.001) loss 1.1046 (1.3072) ce_loss 0.7109 (0.9957) teacher_loss 0.7132 (0.9913) loss_zs_kd 0.2057 (0.1388) loss_oracle 0.2886 (0.2465) acc 75.0000 (73.4943) kd_loss 0.7401 (0.5947) lr 1.8090e-03 eta 0:18:19
epoch [12/50] batch [240/288] time 0.093 (0.099) data 0.000 (0.001) loss 1.6785 (1.3095) ce_loss 1.3438 (0.9983) teacher_loss 1.3335 (0.9931) loss_zs_kd 0.1904 (0.1394) loss_oracle 0.2497 (0.2468) acc 62.5000 (73.6198) kd_loss 0.4204 (0.5942) lr 1.8090e-03 eta 0:18:11
epoch [12/50] batch [260/288] time 0.097 (0.099) data 0.000 (0.001) loss 1.2394 (1.3067) ce_loss 0.8481 (0.9948) teacher_loss 0.8703 (0.9901) loss_zs_kd 0.1604 (0.1393) loss_oracle 0.2890 (0.2470) acc 81.2500 (73.6779) kd_loss 0.7311 (0.5933) lr 1.8090e-03 eta 0:18:05
epoch [12/50] batch [280/288] time 0.081 (0.098) data 0.000 (0.001) loss 1.1645 (1.3037) ce_loss 0.8960 (0.9934) teacher_loss 0.9070 (0.9878) loss_zs_kd 0.1129 (0.1392) loss_oracle 0.2010 (0.2463) acc 75.0000 (73.7165) kd_loss 0.5855 (0.5900) lr 1.8090e-03 eta 0:17:57
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,418
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.2%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,030
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.0%
******* Domain a best val acc:      87.1%, epoch: 9 *******
******* Domain a best val test acc: 83.6%, epoch: 9 *******
******* Domain a best test acc:     83.9%, epoch: 11 *******
epoch [13/50] batch [20/288] time 0.091 (0.109) data 0.000 (0.013) loss 1.0859 (1.2443) ce_loss 0.7881 (0.9633) teacher_loss 0.8156 (0.9481) loss_zs_kd 0.1484 (0.1386) loss_oracle 0.1961 (0.2268) acc 78.1250 (74.0625) kd_loss 0.4883 (0.5289) lr 1.7705e-03 eta 0:19:50
epoch [13/50] batch [40/288] time 0.111 (0.100) data 0.000 (0.007) loss 1.0516 (1.3198) ce_loss 0.7417 (1.0241) teacher_loss 0.7339 (1.0128) loss_zs_kd 0.1905 (0.1447) loss_oracle 0.2225 (0.2347) acc 81.2500 (72.4219) kd_loss 0.4739 (0.5427) lr 1.7705e-03 eta 0:18:09
epoch [13/50] batch [60/288] time 0.102 (0.100) data 0.000 (0.005) loss 1.9823 (1.3858) ce_loss 1.5869 (1.0744) teacher_loss 1.6106 (1.0669) loss_zs_kd 0.1531 (0.1427) loss_oracle 0.2951 (0.2476) acc 56.2500 (71.0938) kd_loss 0.8042 (0.5762) lr 1.7705e-03 eta 0:18:06
epoch [13/50] batch [80/288] time 0.101 (0.100) data 0.000 (0.004) loss 1.5663 (1.3598) ce_loss 1.2939 (1.0503) teacher_loss 1.2419 (1.0454) loss_zs_kd 0.2039 (0.1407) loss_oracle 0.2225 (0.2441) acc 68.7500 (71.8750) kd_loss 0.4945 (0.5729) lr 1.7705e-03 eta 0:18:02
epoch [13/50] batch [100/288] time 0.100 (0.100) data 0.000 (0.003) loss 0.9234 (1.3283) ce_loss 0.6187 (1.0163) teacher_loss 0.6220 (1.0117) loss_zs_kd 0.0625 (0.1378) loss_oracle 0.2702 (0.2477) acc 84.3750 (72.8750) kd_loss 0.5267 (0.5794) lr 1.7705e-03 eta 0:18:02
epoch [13/50] batch [120/288] time 0.101 (0.100) data 0.000 (0.002) loss 1.3751 (1.3212) ce_loss 1.0107 (1.0061) teacher_loss 0.9799 (1.0016) loss_zs_kd 0.1491 (0.1389) loss_oracle 0.3207 (0.2502) acc 78.1250 (73.4375) kd_loss 0.7675 (0.5818) lr 1.7705e-03 eta 0:18:01
epoch [13/50] batch [140/288] time 0.100 (0.100) data 0.000 (0.002) loss 1.2694 (1.3293) ce_loss 0.9590 (1.0153) teacher_loss 0.9688 (1.0104) loss_zs_kd 0.1394 (0.1389) loss_oracle 0.2309 (0.2494) acc 75.0000 (73.1250) kd_loss 0.6045 (0.5807) lr 1.7705e-03 eta 0:17:56
epoch [13/50] batch [160/288] time 0.098 (0.100) data 0.000 (0.002) loss 1.2914 (1.3145) ce_loss 1.0967 (1.0023) teacher_loss 0.9979 (0.9958) loss_zs_kd 0.1158 (0.1377) loss_oracle 0.2356 (0.2498) acc 75.0000 (73.5156) kd_loss 0.5521 (0.5814) lr 1.7705e-03 eta 0:17:57
epoch [13/50] batch [180/288] time 0.098 (0.100) data 0.000 (0.002) loss 0.9288 (1.3198) ce_loss 0.6323 (1.0104) teacher_loss 0.6700 (1.0035) loss_zs_kd 0.0935 (0.1386) loss_oracle 0.2121 (0.2470) acc 81.2500 (73.3333) kd_loss 0.4624 (0.5775) lr 1.7705e-03 eta 0:17:53
epoch [13/50] batch [200/288] time 0.108 (0.100) data 0.000 (0.002) loss 1.6624 (1.3156) ce_loss 1.4150 (1.0078) teacher_loss 1.3985 (1.0012) loss_zs_kd 0.1110 (0.1405) loss_oracle 0.2085 (0.2442) acc 62.5000 (73.4062) kd_loss 0.5244 (0.5727) lr 1.7705e-03 eta 0:17:53
epoch [13/50] batch [220/288] time 0.096 (0.100) data 0.000 (0.001) loss 1.1795 (1.3081) ce_loss 0.7954 (1.0020) teacher_loss 0.8168 (0.9953) loss_zs_kd 0.1845 (0.1409) loss_oracle 0.2704 (0.2423) acc 81.2500 (73.4801) kd_loss 0.8405 (0.5719) lr 1.7705e-03 eta 0:17:51
epoch [13/50] batch [240/288] time 0.104 (0.100) data 0.000 (0.001) loss 1.4419 (1.3031) ce_loss 1.1816 (0.9983) teacher_loss 1.1776 (0.9913) loss_zs_kd 0.1422 (0.1392) loss_oracle 0.1931 (0.2422) acc 71.8750 (73.5547) kd_loss 0.4438 (0.5731) lr 1.7705e-03 eta 0:17:47
epoch [13/50] batch [260/288] time 0.102 (0.100) data 0.000 (0.001) loss 1.2424 (1.2890) ce_loss 1.0234 (0.9870) teacher_loss 1.0135 (0.9794) loss_zs_kd 0.1117 (0.1374) loss_oracle 0.1730 (0.2409) acc 75.0000 (73.8702) kd_loss 0.4779 (0.5721) lr 1.7705e-03 eta 0:17:46
epoch [13/50] batch [280/288] time 0.106 (0.100) data 0.000 (0.001) loss 1.0545 (1.2889) ce_loss 0.7373 (0.9877) teacher_loss 0.7315 (0.9813) loss_zs_kd 0.1063 (0.1367) loss_oracle 0.2698 (0.2393) acc 81.2500 (73.8393) kd_loss 0.6216 (0.5700) lr 1.7705e-03 eta 0:17:43
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,417
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 86.2%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,024
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 79.9%
******* Domain a best val acc:      87.1%, epoch: 9 *******
******* Domain a best val test acc: 83.6%, epoch: 9 *******
******* Domain a best test acc:     83.9%, epoch: 11 *******
epoch [14/50] batch [20/288] time 0.088 (0.108) data 0.001 (0.017) loss 1.2659 (1.3021) ce_loss 1.0088 (1.0022) teacher_loss 0.9950 (1.0000) loss_zs_kd 0.1237 (0.1312) loss_oracle 0.2091 (0.2364) acc 71.8750 (73.1250) kd_loss 0.4375 (0.5697) lr 1.7290e-03 eta 0:19:03
epoch [14/50] batch [40/288] time 0.089 (0.098) data 0.000 (0.008) loss 1.1318 (1.2729) ce_loss 0.7539 (0.9737) teacher_loss 0.7181 (0.9702) loss_zs_kd 0.1836 (0.1296) loss_oracle 0.3220 (0.2380) acc 75.0000 (73.8281) kd_loss 0.8327 (0.5798) lr 1.7290e-03 eta 0:17:22
epoch [14/50] batch [60/288] time 0.092 (0.096) data 0.000 (0.006) loss 1.1976 (1.2545) ce_loss 0.8711 (0.9512) teacher_loss 0.8734 (0.9461) loss_zs_kd 0.1165 (0.1319) loss_oracle 0.2660 (0.2425) acc 71.8750 (74.4271) kd_loss 0.4795 (0.5922) lr 1.7290e-03 eta 0:16:54
epoch [14/50] batch [80/288] time 0.098 (0.095) data 0.000 (0.004) loss 1.4348 (1.2794) ce_loss 1.1064 (0.9716) teacher_loss 1.1199 (0.9647) loss_zs_kd 0.1334 (0.1371) loss_oracle 0.2483 (0.2461) acc 78.1250 (73.8281) kd_loss 0.7183 (0.6017) lr 1.7290e-03 eta 0:16:41
epoch [14/50] batch [100/288] time 0.082 (0.094) data 0.000 (0.003) loss 1.4293 (1.2784) ce_loss 1.1699 (0.9690) teacher_loss 1.1423 (0.9622) loss_zs_kd 0.1488 (0.1412) loss_oracle 0.2125 (0.2457) acc 65.6250 (73.7500) kd_loss 0.4568 (0.5996) lr 1.7290e-03 eta 0:16:33
epoch [14/50] batch [120/288] time 0.093 (0.094) data 0.000 (0.003) loss 1.0914 (1.2912) ce_loss 0.7222 (0.9807) teacher_loss 0.7721 (0.9747) loss_zs_kd 0.1492 (0.1407) loss_oracle 0.2447 (0.2462) acc 84.3750 (73.7240) kd_loss 0.4472 (0.5992) lr 1.7290e-03 eta 0:16:28
epoch [14/50] batch [140/288] time 0.085 (0.094) data 0.000 (0.003) loss 1.1268 (1.3024) ce_loss 0.8164 (0.9909) teacher_loss 0.8425 (0.9862) loss_zs_kd 0.1143 (0.1401) loss_oracle 0.2271 (0.2461) acc 81.2500 (73.6830) kd_loss 0.5101 (0.5986) lr 1.7290e-03 eta 0:16:23
epoch [14/50] batch [160/288] time 0.096 (0.093) data 0.000 (0.002) loss 1.0247 (1.2872) ce_loss 0.6841 (0.9781) teacher_loss 0.7066 (0.9739) loss_zs_kd 0.1385 (0.1389) loss_oracle 0.2489 (0.2439) acc 81.2500 (73.9648) kd_loss 0.5939 (0.5963) lr 1.7290e-03 eta 0:16:18
epoch [14/50] batch [180/288] time 0.087 (0.093) data 0.000 (0.002) loss 0.8146 (1.2719) ce_loss 0.6069 (0.9668) teacher_loss 0.5935 (0.9626) loss_zs_kd 0.0928 (0.1373) loss_oracle 0.1747 (0.2407) acc 84.3750 (74.1840) kd_loss 0.3379 (0.5927) lr 1.7290e-03 eta 0:16:11
epoch [14/50] batch [200/288] time 0.090 (0.093) data 0.000 (0.002) loss 1.5574 (1.2748) ce_loss 1.2031 (0.9733) teacher_loss 1.2053 (0.9687) loss_zs_kd 0.1460 (0.1364) loss_oracle 0.2791 (0.2378) acc 71.8750 (74.0938) kd_loss 0.7227 (0.5837) lr 1.7290e-03 eta 0:16:08
epoch [14/50] batch [220/288] time 0.087 (0.093) data 0.000 (0.002) loss 0.7143 (1.2694) ce_loss 0.4543 (0.9677) teacher_loss 0.4294 (0.9638) loss_zs_kd 0.1075 (0.1363) loss_oracle 0.2312 (0.2374) acc 90.6250 (74.3040) kd_loss 0.5466 (0.5828) lr 1.7290e-03 eta 0:16:05
epoch [14/50] batch [240/288] time 0.090 (0.092) data 0.000 (0.002) loss 1.1999 (1.2653) ce_loss 0.8652 (0.9630) teacher_loss 0.8726 (0.9586) loss_zs_kd 0.1704 (0.1369) loss_oracle 0.2422 (0.2383) acc 78.1250 (74.2839) kd_loss 0.6884 (0.5832) lr 1.7290e-03 eta 0:16:02
epoch [14/50] batch [260/288] time 0.082 (0.092) data 0.000 (0.001) loss 1.6728 (1.2671) ce_loss 1.2998 (0.9644) teacher_loss 1.3280 (0.9598) loss_zs_kd 0.1550 (0.1371) loss_oracle 0.2673 (0.2387) acc 68.7500 (74.3389) kd_loss 0.6068 (0.5820) lr 1.7290e-03 eta 0:15:58
epoch [14/50] batch [280/288] time 0.085 (0.092) data 0.000 (0.001) loss 0.9189 (1.2661) ce_loss 0.5776 (0.9635) teacher_loss 0.5556 (0.9585) loss_zs_kd 0.1080 (0.1369) loss_oracle 0.3093 (0.2391) acc 87.5000 (74.4085) kd_loss 0.6262 (0.5800) lr 1.7290e-03 eta 0:15:53
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,423
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,032
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 80.2%
******* Domain a best val acc:      87.1%, epoch: 9 *******
******* Domain a best val test acc: 83.6%, epoch: 9 *******
******* Domain a best test acc:     83.9%, epoch: 11 *******
epoch [15/50] batch [20/288] time 0.094 (0.112) data 0.000 (0.012) loss 1.4429 (1.2820) ce_loss 1.0918 (0.9760) teacher_loss 1.1077 (0.9799) loss_zs_kd 0.1031 (0.1376) loss_oracle 0.2836 (0.2333) acc 78.1250 (75.3125) kd_loss 0.7192 (0.5949) lr 1.6845e-03 eta 0:19:14
epoch [15/50] batch [40/288] time 0.098 (0.104) data 0.000 (0.006) loss 1.4544 (1.3377) ce_loss 1.1133 (1.0365) teacher_loss 1.1262 (1.0350) loss_zs_kd 0.1243 (0.1354) loss_oracle 0.2661 (0.2350) acc 78.1250 (74.0625) kd_loss 0.6951 (0.5680) lr 1.6845e-03 eta 0:17:52
epoch [15/50] batch [60/288] time 0.091 (0.101) data 0.000 (0.004) loss 0.9716 (1.2871) ce_loss 0.6685 (0.9923) teacher_loss 0.6605 (0.9855) loss_zs_kd 0.1247 (0.1365) loss_oracle 0.2488 (0.2333) acc 78.1250 (74.7917) kd_loss 0.5829 (0.5594) lr 1.6845e-03 eta 0:17:17
epoch [15/50] batch [80/288] time 0.092 (0.100) data 0.000 (0.003) loss 1.2876 (1.2538) ce_loss 0.9702 (0.9560) teacher_loss 0.9742 (0.9498) loss_zs_kd 0.1139 (0.1360) loss_oracle 0.2564 (0.2360) acc 81.2500 (75.3516) kd_loss 0.6435 (0.5625) lr 1.6845e-03 eta 0:17:05
epoch [15/50] batch [100/288] time 0.099 (0.100) data 0.000 (0.003) loss 1.2856 (1.2515) ce_loss 1.0430 (0.9487) teacher_loss 1.0067 (0.9420) loss_zs_kd 0.1085 (0.1385) loss_oracle 0.2247 (0.2403) acc 71.8750 (75.1875) kd_loss 0.5517 (0.5643) lr 1.6845e-03 eta 0:17:01
epoch [15/50] batch [120/288] time 0.104 (0.099) data 0.000 (0.002) loss 1.5740 (1.2576) ce_loss 1.2803 (0.9523) teacher_loss 1.2669 (0.9464) loss_zs_kd 0.1597 (0.1370) loss_oracle 0.2273 (0.2427) acc 71.8750 (74.9740) kd_loss 0.5626 (0.5691) lr 1.6845e-03 eta 0:16:53
epoch [15/50] batch [140/288] time 0.095 (0.098) data 0.000 (0.002) loss 1.3387 (1.2665) ce_loss 1.0654 (0.9617) teacher_loss 1.0804 (0.9554) loss_zs_kd 0.1136 (0.1363) loss_oracle 0.2015 (0.2430) acc 71.8750 (74.6205) kd_loss 0.4744 (0.5700) lr 1.6845e-03 eta 0:16:47
epoch [15/50] batch [160/288] time 0.095 (0.098) data 0.000 (0.002) loss 1.4069 (1.2709) ce_loss 1.0801 (0.9672) teacher_loss 1.0627 (0.9602) loss_zs_kd 0.0942 (0.1362) loss_oracle 0.2971 (0.2427) acc 68.7500 (74.4727) kd_loss 0.6011 (0.5688) lr 1.6845e-03 eta 0:16:40
epoch [15/50] batch [180/288] time 0.091 (0.098) data 0.000 (0.002) loss 1.6731 (1.2767) ce_loss 1.3711 (0.9736) teacher_loss 1.3812 (0.9668) loss_zs_kd 0.1439 (0.1356) loss_oracle 0.2199 (0.2420) acc 71.8750 (74.3403) kd_loss 0.5561 (0.5663) lr 1.6845e-03 eta 0:16:35
epoch [15/50] batch [200/288] time 0.099 (0.098) data 0.000 (0.001) loss 1.0825 (1.2821) ce_loss 0.8174 (0.9797) teacher_loss 0.7410 (0.9721) loss_zs_kd 0.1676 (0.1363) loss_oracle 0.2577 (0.2419) acc 68.7500 (74.0156) kd_loss 0.4875 (0.5641) lr 1.6845e-03 eta 0:16:32
epoch [15/50] batch [220/288] time 0.104 (0.097) data 0.000 (0.001) loss 1.4457 (1.2812) ce_loss 1.1055 (0.9788) teacher_loss 1.1391 (0.9707) loss_zs_kd 0.1337 (0.1365) loss_oracle 0.2397 (0.2423) acc 71.8750 (74.0483) kd_loss 0.6436 (0.5668) lr 1.6845e-03 eta 0:16:28
epoch [15/50] batch [240/288] time 0.103 (0.097) data 0.000 (0.001) loss 1.1665 (1.2766) ce_loss 0.8091 (0.9724) teacher_loss 0.7836 (0.9638) loss_zs_kd 0.2274 (0.1379) loss_oracle 0.2693 (0.2439) acc 75.0000 (74.2318) kd_loss 0.6549 (0.5669) lr 1.6845e-03 eta 0:16:27
epoch [15/50] batch [260/288] time 0.108 (0.098) data 0.000 (0.001) loss 1.2513 (1.2805) ce_loss 1.0146 (0.9749) teacher_loss 0.9964 (0.9655) loss_zs_kd 0.1030 (0.1390) loss_oracle 0.2034 (0.2454) acc 78.1250 (74.2188) kd_loss 0.3969 (0.5674) lr 1.6845e-03 eta 0:16:29
epoch [15/50] batch [280/288] time 0.106 (0.098) data 0.000 (0.001) loss 1.2214 (1.2773) ce_loss 0.9517 (0.9724) teacher_loss 0.9606 (0.9632) loss_zs_kd 0.1103 (0.1384) loss_oracle 0.2057 (0.2449) acc 71.8750 (74.1853) kd_loss 0.4673 (0.5678) lr 1.6845e-03 eta 0:16:31
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,421
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.2%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,024
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 79.7%
******* Domain a best val acc:      87.1%, epoch: 9 *******
******* Domain a best val test acc: 83.6%, epoch: 9 *******
******* Domain a best test acc:     83.9%, epoch: 11 *******
epoch [16/50] batch [20/288] time 0.098 (0.116) data 0.000 (0.012) loss 1.6756 (1.3077) ce_loss 1.3203 (1.0169) teacher_loss 1.3097 (1.0071) loss_zs_kd 0.1565 (0.1311) loss_oracle 0.2876 (0.2351) acc 71.8750 (73.2812) kd_loss 0.8232 (0.5643) lr 1.6374e-03 eta 0:19:29
epoch [16/50] batch [40/288] time 0.101 (0.110) data 0.000 (0.006) loss 1.4704 (1.2764) ce_loss 1.1650 (0.9741) teacher_loss 1.1292 (0.9632) loss_zs_kd 0.1587 (0.1380) loss_oracle 0.2619 (0.2442) acc 68.7500 (73.9062) kd_loss 0.6329 (0.5839) lr 1.6374e-03 eta 0:18:19
epoch [16/50] batch [60/288] time 0.094 (0.107) data 0.000 (0.004) loss 1.5494 (1.2766) ce_loss 1.1484 (0.9723) teacher_loss 1.1097 (0.9615) loss_zs_kd 0.1669 (0.1369) loss_oracle 0.3562 (0.2466) acc 78.1250 (73.4896) kd_loss 0.9925 (0.5887) lr 1.6374e-03 eta 0:17:48
epoch [16/50] batch [80/288] time 0.113 (0.105) data 0.000 (0.003) loss 1.6954 (1.2786) ce_loss 1.3740 (0.9709) teacher_loss 1.3920 (0.9627) loss_zs_kd 0.1456 (0.1363) loss_oracle 0.2307 (0.2477) acc 65.6250 (73.3984) kd_loss 0.5732 (0.5946) lr 1.6374e-03 eta 0:17:32
epoch [16/50] batch [100/288] time 0.100 (0.104) data 0.000 (0.003) loss 1.3661 (1.2904) ce_loss 1.0508 (0.9833) teacher_loss 1.0315 (0.9727) loss_zs_kd 0.1744 (0.1389) loss_oracle 0.2473 (0.2483) acc 65.6250 (72.8125) kd_loss 0.4766 (0.5891) lr 1.6374e-03 eta 0:17:18
epoch [16/50] batch [120/288] time 0.095 (0.103) data 0.000 (0.002) loss 1.1306 (1.2804) ce_loss 0.8076 (0.9750) teacher_loss 0.8179 (0.9641) loss_zs_kd 0.1835 (0.1381) loss_oracle 0.2209 (0.2473) acc 75.0000 (73.0208) kd_loss 0.6822 (0.5885) lr 1.6374e-03 eta 0:17:01
epoch [16/50] batch [140/288] time 0.100 (0.102) data 0.000 (0.002) loss 1.3367 (1.2604) ce_loss 1.0586 (0.9568) teacher_loss 1.0742 (0.9475) loss_zs_kd 0.1353 (0.1383) loss_oracle 0.1948 (0.2438) acc 78.1250 (73.5491) kd_loss 0.5052 (0.5798) lr 1.6374e-03 eta 0:16:54
epoch [16/50] batch [160/288] time 0.100 (0.101) data 0.001 (0.002) loss 1.3325 (1.2568) ce_loss 1.0586 (0.9549) teacher_loss 1.0743 (0.9447) loss_zs_kd 0.1081 (0.1392) loss_oracle 0.2041 (0.2425) acc 75.0000 (73.7500) kd_loss 0.4844 (0.5773) lr 1.6374e-03 eta 0:16:45
epoch [16/50] batch [180/288] time 0.110 (0.101) data 0.000 (0.002) loss 1.0283 (1.2671) ce_loss 0.7476 (0.9644) teacher_loss 0.6847 (0.9533) loss_zs_kd 0.1084 (0.1394) loss_oracle 0.2894 (0.2441) acc 81.2500 (73.7847) kd_loss 0.5872 (0.5745) lr 1.6374e-03 eta 0:16:39
epoch [16/50] batch [200/288] time 0.093 (0.100) data 0.000 (0.001) loss 1.1591 (1.2733) ce_loss 0.8164 (0.9694) teacher_loss 0.7996 (0.9580) loss_zs_kd 0.1591 (0.1382) loss_oracle 0.2800 (0.2463) acc 75.0000 (73.5000) kd_loss 0.5662 (0.5753) lr 1.6374e-03 eta 0:16:31
epoch [16/50] batch [220/288] time 0.093 (0.100) data 0.000 (0.001) loss 0.9343 (1.2727) ce_loss 0.6899 (0.9668) teacher_loss 0.6764 (0.9566) loss_zs_kd 0.1380 (0.1385) loss_oracle 0.1888 (0.2469) acc 81.2500 (73.5227) kd_loss 0.4307 (0.5769) lr 1.6374e-03 eta 0:16:23
epoch [16/50] batch [240/288] time 0.092 (0.099) data 0.000 (0.001) loss 1.1009 (1.2646) ce_loss 0.7705 (0.9585) teacher_loss 0.7829 (0.9480) loss_zs_kd 0.1896 (0.1394) loss_oracle 0.2232 (0.2469) acc 81.2500 (73.7630) kd_loss 0.5876 (0.5760) lr 1.6374e-03 eta 0:16:18
epoch [16/50] batch [260/288] time 0.098 (0.099) data 0.000 (0.001) loss 1.2416 (1.2689) ce_loss 0.8994 (0.9627) teacher_loss 0.9357 (0.9527) loss_zs_kd 0.1307 (0.1402) loss_oracle 0.2405 (0.2461) acc 78.1250 (73.5817) kd_loss 0.6091 (0.5740) lr 1.6374e-03 eta 0:16:13
epoch [16/50] batch [280/288] time 0.087 (0.099) data 0.000 (0.001) loss 1.7940 (1.2777) ce_loss 1.4443 (0.9699) teacher_loss 1.4550 (0.9601) loss_zs_kd 0.1711 (0.1412) loss_oracle 0.2534 (0.2470) acc 62.5000 (73.4933) kd_loss 0.6680 (0.5756) lr 1.6374e-03 eta 0:16:06
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,424
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.4%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,038
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 80.6%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      87.1%, epoch: 9 *******
******* Domain a best val test acc: 83.6%, epoch: 9 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [17/50] batch [20/288] time 0.096 (0.109) data 0.000 (0.014) loss 1.7942 (1.1584) ce_loss 1.4365 (0.8328) teacher_loss 1.4514 (0.8187) loss_zs_kd 0.1305 (0.1294) loss_oracle 0.2776 (0.2749) acc 71.8750 (78.5938) kd_loss 0.5652 (0.6362) lr 1.5878e-03 eta 0:17:44
epoch [17/50] batch [40/288] time 0.097 (0.100) data 0.000 (0.007) loss 1.1960 (1.2484) ce_loss 0.9131 (0.9265) teacher_loss 0.8472 (0.9141) loss_zs_kd 0.1499 (0.1321) loss_oracle 0.2739 (0.2682) acc 78.1250 (76.3281) kd_loss 0.5660 (0.6108) lr 1.5878e-03 eta 0:16:12
epoch [17/50] batch [60/288] time 0.088 (0.096) data 0.000 (0.005) loss 1.7422 (1.2733) ce_loss 1.3242 (0.9404) teacher_loss 1.3362 (0.9298) loss_zs_kd 0.1251 (0.1338) loss_oracle 0.3434 (0.2767) acc 65.6250 (75.2083) kd_loss 0.7648 (0.6174) lr 1.5878e-03 eta 0:15:34
epoch [17/50] batch [80/288] time 0.107 (0.096) data 0.000 (0.004) loss 1.1837 (1.2778) ce_loss 0.7803 (0.9371) teacher_loss 0.7674 (0.9276) loss_zs_kd 0.1649 (0.1354) loss_oracle 0.3338 (0.2825) acc 78.1250 (74.9219) kd_loss 0.6397 (0.6272) lr 1.5878e-03 eta 0:15:30
epoch [17/50] batch [100/288] time 0.101 (0.097) data 0.000 (0.003) loss 1.4143 (1.2777) ce_loss 1.0781 (0.9386) teacher_loss 1.0854 (0.9269) loss_zs_kd 0.1247 (0.1345) loss_oracle 0.2665 (0.2835) acc 65.6250 (74.7500) kd_loss 0.5721 (0.6253) lr 1.5878e-03 eta 0:15:37
epoch [17/50] batch [120/288] time 0.102 (0.098) data 0.001 (0.003) loss 1.3061 (1.2857) ce_loss 1.0586 (0.9471) teacher_loss 1.0304 (0.9379) loss_zs_kd 0.0889 (0.1341) loss_oracle 0.2312 (0.2807) acc 75.0000 (74.2969) kd_loss 0.4100 (0.6234) lr 1.5878e-03 eta 0:15:43
epoch [17/50] batch [140/288] time 0.112 (0.099) data 0.000 (0.002) loss 1.4449 (1.3042) ce_loss 1.1680 (0.9701) teacher_loss 1.1322 (0.9591) loss_zs_kd 0.1286 (0.1352) loss_oracle 0.2484 (0.2775) acc 65.6250 (73.8616) kd_loss 0.5443 (0.6125) lr 1.5878e-03 eta 0:15:54
epoch [17/50] batch [160/288] time 0.098 (0.099) data 0.000 (0.002) loss 1.4225 (1.3015) ce_loss 1.0518 (0.9698) teacher_loss 1.0738 (0.9596) loss_zs_kd 0.1302 (0.1357) loss_oracle 0.2835 (0.2741) acc 68.7500 (73.7695) kd_loss 0.6005 (0.6058) lr 1.5878e-03 eta 0:15:57
epoch [17/50] batch [180/288] time 0.099 (0.099) data 0.001 (0.002) loss 1.1388 (1.2900) ce_loss 0.8730 (0.9613) teacher_loss 0.8857 (0.9521) loss_zs_kd 0.1078 (0.1354) loss_oracle 0.1991 (0.2702) acc 75.0000 (73.9236) kd_loss 0.5549 (0.5996) lr 1.5878e-03 eta 0:15:52
epoch [17/50] batch [200/288] time 0.101 (0.099) data 0.000 (0.002) loss 1.1505 (1.2863) ce_loss 0.8516 (0.9590) teacher_loss 0.8569 (0.9500) loss_zs_kd 0.0950 (0.1358) loss_oracle 0.2461 (0.2684) acc 71.8750 (74.0312) kd_loss 0.5105 (0.5976) lr 1.5878e-03 eta 0:15:50
epoch [17/50] batch [220/288] time 0.112 (0.099) data 0.000 (0.001) loss 1.0887 (1.2837) ce_loss 0.8452 (0.9574) teacher_loss 0.8178 (0.9478) loss_zs_kd 0.0815 (0.1364) loss_oracle 0.2301 (0.2677) acc 81.2500 (74.1193) kd_loss 0.5190 (0.6000) lr 1.5878e-03 eta 0:15:49
epoch [17/50] batch [240/288] time 0.099 (0.099) data 0.000 (0.001) loss 1.2131 (1.2783) ce_loss 0.9360 (0.9548) teacher_loss 0.9303 (0.9456) loss_zs_kd 0.1230 (0.1367) loss_oracle 0.2213 (0.2643) acc 71.8750 (74.1667) kd_loss 0.4439 (0.5978) lr 1.5878e-03 eta 0:15:47
epoch [17/50] batch [260/288] time 0.109 (0.099) data 0.000 (0.001) loss 1.6833 (1.2794) ce_loss 1.3389 (0.9569) teacher_loss 1.3450 (0.9490) loss_zs_kd 0.1445 (0.1384) loss_oracle 0.2661 (0.2613) acc 68.7500 (74.1827) kd_loss 0.7774 (0.5965) lr 1.5878e-03 eta 0:15:47
epoch [17/50] batch [280/288] time 0.103 (0.100) data 0.000 (0.001) loss 1.5627 (1.2780) ce_loss 1.2461 (0.9553) teacher_loss 1.1897 (0.9467) loss_zs_kd 0.1802 (0.1397) loss_oracle 0.2830 (0.2615) acc 68.7500 (74.3304) kd_loss 0.6903 (0.5987) lr 1.5878e-03 eta 0:15:47
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,429
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,030
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.2%
******* Domain a best val acc:      87.1%, epoch: 9 *******
******* Domain a best val test acc: 83.6%, epoch: 9 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [18/50] batch [20/288] time 0.093 (0.120) data 0.000 (0.014) loss 1.6088 (1.2678) ce_loss 1.2520 (0.9384) teacher_loss 1.2414 (0.9312) loss_zs_kd 0.1371 (0.1475) loss_oracle 0.2988 (0.2628) acc 65.6250 (75.1562) kd_loss 0.7612 (0.6042) lr 1.5358e-03 eta 0:18:58
epoch [18/50] batch [40/288] time 0.102 (0.111) data 0.001 (0.007) loss 1.8539 (1.3169) ce_loss 1.4902 (0.9870) teacher_loss 1.4788 (0.9782) loss_zs_kd 0.2069 (0.1512) loss_oracle 0.2716 (0.2630) acc 59.3750 (73.5156) kd_loss 0.6002 (0.6023) lr 1.5358e-03 eta 0:17:30
epoch [18/50] batch [60/288] time 0.091 (0.107) data 0.000 (0.005) loss 1.0526 (1.3072) ce_loss 0.7231 (0.9809) teacher_loss 0.6840 (0.9703) loss_zs_kd 0.1679 (0.1495) loss_oracle 0.2846 (0.2622) acc 78.1250 (73.9062) kd_loss 0.6130 (0.6101) lr 1.5358e-03 eta 0:16:51
epoch [18/50] batch [80/288] time 0.098 (0.105) data 0.000 (0.004) loss 2.1082 (1.3255) ce_loss 1.8340 (1.0046) teacher_loss 1.7587 (0.9928) loss_zs_kd 0.1977 (0.1495) loss_oracle 0.2506 (0.2580) acc 53.1250 (73.4766) kd_loss 0.5827 (0.5980) lr 1.5358e-03 eta 0:16:33
epoch [18/50] batch [100/288] time 0.095 (0.104) data 0.000 (0.003) loss 1.1711 (1.3131) ce_loss 0.8032 (0.9934) teacher_loss 0.8822 (0.9838) loss_zs_kd 0.1229 (0.1483) loss_oracle 0.2275 (0.2552) acc 84.3750 (73.6875) kd_loss 0.7367 (0.5932) lr 1.5358e-03 eta 0:16:18
epoch [18/50] batch [120/288] time 0.100 (0.103) data 0.001 (0.003) loss 1.3624 (1.2970) ce_loss 1.0830 (0.9804) teacher_loss 1.0895 (0.9705) loss_zs_kd 0.1309 (0.1463) loss_oracle 0.2075 (0.2534) acc 75.0000 (74.0104) kd_loss 0.4364 (0.5869) lr 1.5358e-03 eta 0:16:05
epoch [18/50] batch [140/288] time 0.098 (0.102) data 0.000 (0.002) loss 1.2866 (1.3050) ce_loss 1.0195 (0.9904) teacher_loss 0.9932 (0.9796) loss_zs_kd 0.1334 (0.1458) loss_oracle 0.2267 (0.2525) acc 75.0000 (73.6161) kd_loss 0.4175 (0.5848) lr 1.5358e-03 eta 0:15:52
epoch [18/50] batch [160/288] time 0.096 (0.101) data 0.000 (0.002) loss 1.3179 (1.2975) ce_loss 0.9067 (0.9817) teacher_loss 0.9021 (0.9722) loss_zs_kd 0.1942 (0.1460) loss_oracle 0.3187 (0.2523) acc 78.1250 (73.8867) kd_loss 0.6787 (0.5856) lr 1.5358e-03 eta 0:15:46
epoch [18/50] batch [180/288] time 0.095 (0.101) data 0.000 (0.002) loss 1.0843 (1.2910) ce_loss 0.7622 (0.9753) teacher_loss 0.7915 (0.9665) loss_zs_kd 0.2020 (0.1469) loss_oracle 0.1918 (0.2510) acc 71.8750 (74.0278) kd_loss 0.5736 (0.5858) lr 1.5358e-03 eta 0:15:41
epoch [18/50] batch [200/288] time 0.100 (0.101) data 0.000 (0.002) loss 1.5800 (1.2820) ce_loss 1.2822 (0.9668) teacher_loss 1.2797 (0.9581) loss_zs_kd 0.1431 (0.1460) loss_oracle 0.2287 (0.2509) acc 68.7500 (74.1875) kd_loss 0.4815 (0.5844) lr 1.5358e-03 eta 0:15:36
epoch [18/50] batch [220/288] time 0.097 (0.101) data 0.000 (0.002) loss 1.8021 (1.2865) ce_loss 1.5293 (0.9726) teacher_loss 1.5093 (0.9636) loss_zs_kd 0.1113 (0.1459) loss_oracle 0.2371 (0.2500) acc 56.2500 (73.9062) kd_loss 0.5718 (0.5835) lr 1.5358e-03 eta 0:15:34
epoch [18/50] batch [240/288] time 0.106 (0.101) data 0.000 (0.001) loss 1.0601 (1.2870) ce_loss 0.7744 (0.9738) teacher_loss 0.7701 (0.9644) loss_zs_kd 0.1480 (0.1463) loss_oracle 0.2160 (0.2494) acc 78.1250 (73.8542) kd_loss 0.4268 (0.5820) lr 1.5358e-03 eta 0:15:35
epoch [18/50] batch [260/288] time 0.094 (0.101) data 0.000 (0.001) loss 1.2992 (1.2867) ce_loss 1.0068 (0.9734) teacher_loss 0.9838 (0.9646) loss_zs_kd 0.0855 (0.1453) loss_oracle 0.2727 (0.2494) acc 78.1250 (73.9904) kd_loss 0.5323 (0.5814) lr 1.5358e-03 eta 0:15:34
epoch [18/50] batch [280/288] time 0.086 (0.100) data 0.000 (0.001) loss 1.5739 (1.2894) ce_loss 1.2471 (0.9775) teacher_loss 1.2225 (0.9676) loss_zs_kd 0.1928 (0.1455) loss_oracle 0.2549 (0.2490) acc 65.6250 (73.9621) kd_loss 0.5911 (0.5796) lr 1.5358e-03 eta 0:15:26
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,430
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,037
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 80.4%
******* Domain a best val acc:      87.1%, epoch: 9 *******
******* Domain a best val test acc: 83.6%, epoch: 9 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [19/50] batch [20/288] time 0.090 (0.106) data 0.000 (0.011) loss 1.2874 (1.2353) ce_loss 1.0166 (0.9185) teacher_loss 0.9659 (0.9078) loss_zs_kd 0.1172 (0.1425) loss_oracle 0.2629 (0.2562) acc 68.7500 (75.9375) kd_loss 0.6358 (0.6080) lr 1.4818e-03 eta 0:16:15
epoch [19/50] batch [40/288] time 0.099 (0.101) data 0.000 (0.005) loss 1.3849 (1.2922) ce_loss 1.0840 (0.9781) teacher_loss 0.9973 (0.9685) loss_zs_kd 0.1612 (0.1431) loss_oracle 0.3070 (0.2522) acc 65.6250 (73.7500) kd_loss 0.6911 (0.6011) lr 1.4818e-03 eta 0:15:22
epoch [19/50] batch [60/288] time 0.100 (0.099) data 0.001 (0.004) loss 1.5073 (1.3397) ce_loss 1.2061 (1.0235) teacher_loss 1.1832 (1.0124) loss_zs_kd 0.1795 (0.1475) loss_oracle 0.2344 (0.2536) acc 71.8750 (72.9688) kd_loss 0.5403 (0.5957) lr 1.4818e-03 eta 0:15:02
epoch [19/50] batch [80/288] time 0.098 (0.098) data 0.000 (0.003) loss 1.1844 (1.2898) ce_loss 0.8657 (0.9787) teacher_loss 0.8672 (0.9663) loss_zs_kd 0.1377 (0.1479) loss_oracle 0.2484 (0.2495) acc 68.7500 (73.7500) kd_loss 0.6193 (0.5851) lr 1.4818e-03 eta 0:14:56
epoch [19/50] batch [100/288] time 0.101 (0.098) data 0.000 (0.002) loss 1.4202 (1.2823) ce_loss 1.0820 (0.9724) teacher_loss 1.0563 (0.9601) loss_zs_kd 0.1337 (0.1488) loss_oracle 0.2971 (0.2478) acc 65.6250 (74.0938) kd_loss 0.4642 (0.5800) lr 1.4818e-03 eta 0:14:51
epoch [19/50] batch [120/288] time 0.106 (0.098) data 0.000 (0.002) loss 1.7947 (1.2825) ce_loss 1.4658 (0.9717) teacher_loss 1.4607 (0.9611) loss_zs_kd 0.1465 (0.1476) loss_oracle 0.2608 (0.2476) acc 65.6250 (74.1927) kd_loss 0.5121 (0.5796) lr 1.4818e-03 eta 0:14:48
epoch [19/50] batch [140/288] time 0.099 (0.098) data 0.000 (0.002) loss 1.5663 (1.2822) ce_loss 1.2666 (0.9709) teacher_loss 1.2743 (0.9616) loss_zs_kd 0.1071 (0.1467) loss_oracle 0.2384 (0.2472) acc 75.0000 (74.3304) kd_loss 0.5810 (0.5818) lr 1.4818e-03 eta 0:14:47
epoch [19/50] batch [160/288] time 0.105 (0.098) data 0.000 (0.001) loss 1.2425 (1.2830) ce_loss 0.9814 (0.9728) teacher_loss 0.9654 (0.9658) loss_zs_kd 0.1395 (0.1431) loss_oracle 0.2073 (0.2457) acc 71.8750 (74.0820) kd_loss 0.5782 (0.5841) lr 1.4818e-03 eta 0:14:45
epoch [19/50] batch [180/288] time 0.089 (0.098) data 0.000 (0.001) loss 1.3359 (1.2824) ce_loss 1.0166 (0.9744) teacher_loss 1.0156 (0.9665) loss_zs_kd 0.1312 (0.1422) loss_oracle 0.2547 (0.2447) acc 71.8750 (73.8194) kd_loss 0.7143 (0.5843) lr 1.4818e-03 eta 0:14:41
epoch [19/50] batch [200/288] time 0.102 (0.097) data 0.000 (0.001) loss 0.9916 (1.2743) ce_loss 0.6396 (0.9674) teacher_loss 0.6294 (0.9591) loss_zs_kd 0.1599 (0.1422) loss_oracle 0.2823 (0.2441) acc 81.2500 (73.8594) kd_loss 0.5266 (0.5815) lr 1.4818e-03 eta 0:14:38
epoch [19/50] batch [220/288] time 0.095 (0.097) data 0.000 (0.001) loss 1.2207 (1.2833) ce_loss 0.9448 (0.9748) teacher_loss 0.9353 (0.9672) loss_zs_kd 0.1683 (0.1450) loss_oracle 0.2013 (0.2437) acc 78.1250 (73.7926) kd_loss 0.3528 (0.5770) lr 1.4818e-03 eta 0:14:35
epoch [19/50] batch [240/288] time 0.106 (0.098) data 0.001 (0.001) loss 1.0601 (1.2825) ce_loss 0.6738 (0.9725) teacher_loss 0.6766 (0.9648) loss_zs_kd 0.2265 (0.1458) loss_oracle 0.2702 (0.2448) acc 84.3750 (73.8281) kd_loss 0.7419 (0.5800) lr 1.4818e-03 eta 0:14:36
epoch [19/50] batch [260/288] time 0.098 (0.098) data 0.001 (0.001) loss 1.3524 (1.2792) ce_loss 1.0420 (0.9692) teacher_loss 1.0084 (0.9603) loss_zs_kd 0.1594 (0.1464) loss_oracle 0.2643 (0.2457) acc 75.0000 (73.9183) kd_loss 0.6072 (0.5822) lr 1.4818e-03 eta 0:14:37
epoch [19/50] batch [280/288] time 0.085 (0.098) data 0.000 (0.001) loss 1.8340 (1.2806) ce_loss 1.4170 (0.9698) teacher_loss 1.4739 (0.9612) loss_zs_kd 0.2092 (0.1467) loss_oracle 0.2555 (0.2460) acc 62.5000 (73.9621) kd_loss 0.6496 (0.5816) lr 1.4818e-03 eta 0:14:33
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,427
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 86.4%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,023
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 80.0%
******* Domain a best val acc:      87.1%, epoch: 9 *******
******* Domain a best val test acc: 83.6%, epoch: 9 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [20/50] batch [20/288] time 0.093 (0.111) data 0.000 (0.013) loss 1.6521 (1.2645) ce_loss 1.3594 (0.9392) teacher_loss 1.2940 (0.9303) loss_zs_kd 0.1519 (0.1500) loss_oracle 0.2821 (0.2592) acc 59.3750 (73.9062) kd_loss 0.8159 (0.6060) lr 1.4258e-03 eta 0:16:33
epoch [20/50] batch [40/288] time 0.103 (0.107) data 0.000 (0.006) loss 1.3251 (1.2832) ce_loss 0.9814 (0.9466) teacher_loss 0.9333 (0.9345) loss_zs_kd 0.2420 (0.1590) loss_oracle 0.2708 (0.2692) acc 78.1250 (74.0625) kd_loss 0.5206 (0.5995) lr 1.4258e-03 eta 0:15:48
epoch [20/50] batch [60/288] time 0.099 (0.105) data 0.000 (0.004) loss 1.1115 (1.2769) ce_loss 0.8218 (0.9414) teacher_loss 0.8333 (0.9296) loss_zs_kd 0.0910 (0.1572) loss_oracle 0.2328 (0.2687) acc 81.2500 (74.5833) kd_loss 0.4715 (0.6096) lr 1.4258e-03 eta 0:15:31
epoch [20/50] batch [80/288] time 0.092 (0.104) data 0.000 (0.003) loss 1.0845 (1.2690) ce_loss 0.7896 (0.9437) teacher_loss 0.7981 (0.9304) loss_zs_kd 0.1072 (0.1541) loss_oracle 0.2328 (0.2616) acc 81.2500 (74.6094) kd_loss 0.5793 (0.5928) lr 1.4258e-03 eta 0:15:19
epoch [20/50] batch [100/288] time 0.102 (0.103) data 0.000 (0.003) loss 1.4152 (1.2609) ce_loss 1.1592 (0.9376) teacher_loss 1.1475 (0.9272) loss_zs_kd 0.1317 (0.1511) loss_oracle 0.2019 (0.2581) acc 62.5000 (74.6562) kd_loss 0.4082 (0.5894) lr 1.4258e-03 eta 0:15:05
epoch [20/50] batch [120/288] time 0.092 (0.102) data 0.000 (0.002) loss 0.8264 (1.2756) ce_loss 0.5698 (0.9562) teacher_loss 0.5671 (0.9476) loss_zs_kd 0.0672 (0.1491) loss_oracle 0.2257 (0.2535) acc 87.5000 (74.0365) kd_loss 0.6611 (0.5872) lr 1.4258e-03 eta 0:14:58
epoch [20/50] batch [140/288] time 0.100 (0.101) data 0.000 (0.002) loss 1.1442 (1.2776) ce_loss 0.8218 (0.9627) teacher_loss 0.8112 (0.9530) loss_zs_kd 0.1517 (0.1493) loss_oracle 0.2571 (0.2500) acc 78.1250 (73.9062) kd_loss 0.5711 (0.5835) lr 1.4258e-03 eta 0:14:50
epoch [20/50] batch [160/288] time 0.090 (0.101) data 0.000 (0.002) loss 1.2921 (1.2731) ce_loss 0.9990 (0.9598) teacher_loss 1.0231 (0.9503) loss_zs_kd 0.1024 (0.1483) loss_oracle 0.2178 (0.2486) acc 71.8750 (74.0430) kd_loss 0.4852 (0.5798) lr 1.4258e-03 eta 0:14:46
epoch [20/50] batch [180/288] time 0.111 (0.101) data 0.000 (0.002) loss 1.0481 (1.2641) ce_loss 0.7603 (0.9514) teacher_loss 0.7618 (0.9417) loss_zs_kd 0.1060 (0.1477) loss_oracle 0.2333 (0.2485) acc 81.2500 (74.3403) kd_loss 0.4680 (0.5783) lr 1.4258e-03 eta 0:14:41
epoch [20/50] batch [200/288] time 0.095 (0.101) data 0.000 (0.001) loss 1.7665 (1.2674) ce_loss 1.4541 (0.9557) teacher_loss 1.4030 (0.9451) loss_zs_kd 0.2644 (0.1477) loss_oracle 0.2313 (0.2484) acc 65.6250 (74.1719) kd_loss 0.5068 (0.5726) lr 1.4258e-03 eta 0:14:37
epoch [20/50] batch [220/288] time 0.099 (0.101) data 0.000 (0.001) loss 1.1760 (1.2591) ce_loss 0.8735 (0.9452) teacher_loss 0.8652 (0.9356) loss_zs_kd 0.1330 (0.1476) loss_oracle 0.2443 (0.2497) acc 75.0000 (74.3182) kd_loss 0.4911 (0.5743) lr 1.4258e-03 eta 0:14:35
epoch [20/50] batch [240/288] time 0.108 (0.101) data 0.000 (0.001) loss 1.3573 (1.2558) ce_loss 1.0625 (0.9425) teacher_loss 1.0545 (0.9327) loss_zs_kd 0.1316 (0.1481) loss_oracle 0.2371 (0.2490) acc 65.6250 (74.4531) kd_loss 0.6334 (0.5750) lr 1.4258e-03 eta 0:14:35
epoch [20/50] batch [260/288] time 0.145 (0.103) data 0.000 (0.001) loss 1.5927 (1.2499) ce_loss 1.2861 (0.9381) teacher_loss 1.2476 (0.9276) loss_zs_kd 0.1108 (0.1477) loss_oracle 0.2897 (0.2485) acc 65.6250 (74.5072) kd_loss 0.5533 (0.5726) lr 1.4258e-03 eta 0:14:54
epoch [20/50] batch [280/288] time 0.153 (0.107) data 0.000 (0.001) loss 1.0064 (1.2474) ce_loss 0.7046 (0.9360) teacher_loss 0.7054 (0.9254) loss_zs_kd 0.1425 (0.1470) loss_oracle 0.2297 (0.2485) acc 87.5000 (74.5312) kd_loss 0.5347 (0.5736) lr 1.4258e-03 eta 0:15:27
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,434
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,032
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 80.3%
******* Domain a best val acc:      87.2%, epoch: 20 *******
******* Domain a best val test acc: 83.7%, epoch: 20 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [21/50] batch [20/288] time 0.158 (0.189) data 0.000 (0.016) loss 0.7848 (1.2211) ce_loss 0.4783 (0.8958) teacher_loss 0.4828 (0.8952) loss_zs_kd 0.1360 (0.1592) loss_oracle 0.2341 (0.2463) acc 87.5000 (75.4688) kd_loss 0.7022 (0.5840) lr 1.3681e-03 eta 0:27:07
epoch [21/50] batch [40/288] time 0.164 (0.177) data 0.000 (0.008) loss 0.9064 (1.2210) ce_loss 0.5669 (0.9004) teacher_loss 0.5754 (0.8944) loss_zs_kd 0.1286 (0.1499) loss_oracle 0.2667 (0.2517) acc 84.3750 (74.6094) kd_loss 0.6041 (0.5945) lr 1.3681e-03 eta 0:25:21
epoch [21/50] batch [60/288] time 0.362 (0.172) data 0.000 (0.006) loss 1.2269 (1.2422) ce_loss 0.8730 (0.9207) teacher_loss 0.8342 (0.9140) loss_zs_kd 0.1563 (0.1459) loss_oracle 0.3145 (0.2552) acc 71.8750 (74.3750) kd_loss 0.7014 (0.5982) lr 1.3681e-03 eta 0:24:32
epoch [21/50] batch [80/288] time 0.087 (0.171) data 0.000 (0.004) loss 0.9065 (1.2712) ce_loss 0.5933 (0.9473) teacher_loss 0.5780 (0.9420) loss_zs_kd 0.0886 (0.1422) loss_oracle 0.2842 (0.2581) acc 78.1250 (73.9062) kd_loss 0.7800 (0.6048) lr 1.3681e-03 eta 0:24:24
epoch [21/50] batch [100/288] time 0.175 (0.165) data 0.000 (0.003) loss 1.2970 (1.2560) ce_loss 0.9717 (0.9349) teacher_loss 0.9741 (0.9261) loss_zs_kd 0.1058 (0.1411) loss_oracle 0.2700 (0.2594) acc 75.0000 (74.3438) kd_loss 0.5290 (0.6012) lr 1.3681e-03 eta 0:23:31
epoch [21/50] batch [120/288] time 0.101 (0.157) data 0.000 (0.003) loss 1.0400 (1.2626) ce_loss 0.7300 (0.9414) teacher_loss 0.6876 (0.9291) loss_zs_kd 0.1187 (0.1427) loss_oracle 0.2931 (0.2621) acc 84.3750 (74.4271) kd_loss 0.8386 (0.6047) lr 1.3681e-03 eta 0:22:20
epoch [21/50] batch [140/288] time 0.105 (0.149) data 0.000 (0.002) loss 1.2377 (1.2723) ce_loss 0.9531 (0.9521) teacher_loss 0.9131 (0.9381) loss_zs_kd 0.1598 (0.1427) loss_oracle 0.2446 (0.2628) acc 78.1250 (74.3080) kd_loss 0.6206 (0.6041) lr 1.3681e-03 eta 0:21:04
epoch [21/50] batch [160/288] time 0.103 (0.142) data 0.000 (0.002) loss 1.3218 (1.2878) ce_loss 0.9473 (0.9664) teacher_loss 0.9420 (0.9523) loss_zs_kd 0.1369 (0.1462) loss_oracle 0.3114 (0.2625) acc 75.0000 (73.9648) kd_loss 0.5880 (0.6031) lr 1.3681e-03 eta 0:20:07
epoch [21/50] batch [180/288] time 0.091 (0.137) data 0.000 (0.002) loss 1.4613 (1.2925) ce_loss 1.1660 (0.9712) teacher_loss 1.1614 (0.9567) loss_zs_kd 0.1183 (0.1476) loss_oracle 0.2407 (0.2619) acc 71.8750 (73.7326) kd_loss 0.7091 (0.6042) lr 1.3681e-03 eta 0:19:21
epoch [21/50] batch [200/288] time 0.105 (0.133) data 0.000 (0.002) loss 1.4994 (1.2850) ce_loss 1.2256 (0.9647) teacher_loss 1.1779 (0.9510) loss_zs_kd 0.1111 (0.1471) loss_oracle 0.2660 (0.2605) acc 68.7500 (73.9375) kd_loss 0.7379 (0.6028) lr 1.3681e-03 eta 0:18:45
epoch [21/50] batch [220/288] time 0.100 (0.130) data 0.000 (0.002) loss 1.1670 (1.2832) ce_loss 0.8574 (0.9631) teacher_loss 0.8347 (0.9493) loss_zs_kd 0.1073 (0.1470) loss_oracle 0.2786 (0.2604) acc 78.1250 (73.9489) kd_loss 0.6283 (0.6040) lr 1.3681e-03 eta 0:18:15
epoch [21/50] batch [240/288] time 0.106 (0.127) data 0.000 (0.002) loss 1.3037 (1.2937) ce_loss 0.9526 (0.9748) teacher_loss 0.9445 (0.9612) loss_zs_kd 0.1768 (0.1466) loss_oracle 0.2708 (0.2592) acc 81.2500 (73.8281) kd_loss 0.5846 (0.6012) lr 1.3681e-03 eta 0:17:50
epoch [21/50] batch [260/288] time 0.103 (0.125) data 0.000 (0.001) loss 1.1655 (1.2880) ce_loss 0.8594 (0.9711) teacher_loss 0.8908 (0.9576) loss_zs_kd 0.1322 (0.1468) loss_oracle 0.2086 (0.2570) acc 78.1250 (73.9062) kd_loss 0.5650 (0.5977) lr 1.3681e-03 eta 0:17:29
epoch [21/50] batch [280/288] time 0.087 (0.123) data 0.000 (0.001) loss 1.1642 (1.2857) ce_loss 0.8877 (0.9688) teacher_loss 0.8744 (0.9562) loss_zs_kd 0.1098 (0.1468) loss_oracle 0.2349 (0.2561) acc 78.1250 (73.9955) kd_loss 0.5797 (0.5981) lr 1.3681e-03 eta 0:17:08
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,424
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,030
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.2%
******* Domain a best val acc:      87.2%, epoch: 20 *******
******* Domain a best val test acc: 83.7%, epoch: 20 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [22/50] batch [20/288] time 0.157 (0.171) data 0.000 (0.012) loss 1.7616 (1.2516) ce_loss 1.4590 (0.9432) teacher_loss 1.4254 (0.9206) loss_zs_kd 0.1476 (0.1637) loss_oracle 0.2624 (0.2491) acc 59.3750 (73.4375) kd_loss 0.7028 (0.5917) lr 1.3090e-03 eta 0:23:45
epoch [22/50] batch [40/288] time 0.149 (0.163) data 0.000 (0.006) loss 1.2186 (1.2464) ce_loss 0.9126 (0.9345) teacher_loss 0.8820 (0.9200) loss_zs_kd 0.1227 (0.1541) loss_oracle 0.2753 (0.2493) acc 81.2500 (73.9844) kd_loss 0.4795 (0.5737) lr 1.3090e-03 eta 0:22:34
epoch [22/50] batch [60/288] time 0.163 (0.161) data 0.001 (0.004) loss 1.0447 (1.2633) ce_loss 0.6807 (0.9535) teacher_loss 0.6597 (0.9402) loss_zs_kd 0.2013 (0.1527) loss_oracle 0.2844 (0.2467) acc 75.0000 (73.8542) kd_loss 0.6351 (0.5659) lr 1.3090e-03 eta 0:22:10
epoch [22/50] batch [80/288] time 0.164 (0.159) data 0.000 (0.003) loss 1.6743 (1.2541) ce_loss 1.3311 (0.9396) teacher_loss 1.3326 (0.9292) loss_zs_kd 0.1735 (0.1544) loss_oracle 0.2550 (0.2477) acc 65.6250 (74.4531) kd_loss 0.7095 (0.5682) lr 1.3090e-03 eta 0:21:54
epoch [22/50] batch [100/288] time 0.167 (0.158) data 0.000 (0.003) loss 0.9244 (1.2507) ce_loss 0.6963 (0.9386) teacher_loss 0.6789 (0.9294) loss_zs_kd 0.0784 (0.1493) loss_oracle 0.2063 (0.2466) acc 78.1250 (74.3750) kd_loss 0.4846 (0.5742) lr 1.3090e-03 eta 0:21:43
epoch [22/50] batch [120/288] time 0.193 (0.153) data 0.000 (0.002) loss 1.3594 (1.2596) ce_loss 1.0146 (0.9454) teacher_loss 1.0069 (0.9384) loss_zs_kd 0.1678 (0.1513) loss_oracle 0.2686 (0.2455) acc 68.7500 (74.5052) kd_loss 0.5762 (0.5732) lr 1.3090e-03 eta 0:21:02
epoch [22/50] batch [140/288] time 0.343 (0.160) data 0.000 (0.002) loss 1.2933 (1.2550) ce_loss 0.9863 (0.9414) teacher_loss 1.0076 (0.9353) loss_zs_kd 0.1537 (0.1481) loss_oracle 0.2089 (0.2457) acc 75.0000 (74.6875) kd_loss 0.5280 (0.5711) lr 1.3090e-03 eta 0:21:52
epoch [22/50] batch [160/288] time 0.148 (0.160) data 0.000 (0.002) loss 0.8837 (1.2670) ce_loss 0.5869 (0.9518) teacher_loss 0.5694 (0.9456) loss_zs_kd 0.1102 (0.1478) loss_oracle 0.2592 (0.2475) acc 84.3750 (74.5312) kd_loss 0.4797 (0.5746) lr 1.3090e-03 eta 0:21:48
epoch [22/50] batch [180/288] time 0.152 (0.159) data 0.000 (0.002) loss 1.1292 (1.2611) ce_loss 0.8755 (0.9475) teacher_loss 0.8697 (0.9414) loss_zs_kd 0.0805 (0.1475) loss_oracle 0.2192 (0.2460) acc 81.2500 (74.6875) kd_loss 0.5070 (0.5737) lr 1.3090e-03 eta 0:21:37
epoch [22/50] batch [200/288] time 0.171 (0.159) data 0.000 (0.001) loss 1.1928 (1.2642) ce_loss 0.8794 (0.9521) teacher_loss 0.8049 (0.9459) loss_zs_kd 0.1444 (0.1473) loss_oracle 0.3157 (0.2447) acc 71.8750 (74.5156) kd_loss 0.7103 (0.5741) lr 1.3090e-03 eta 0:21:37
epoch [22/50] batch [220/288] time 0.160 (0.159) data 0.000 (0.001) loss 0.8201 (1.2630) ce_loss 0.5464 (0.9513) teacher_loss 0.5233 (0.9431) loss_zs_kd 0.1598 (0.1490) loss_oracle 0.2169 (0.2454) acc 84.3750 (74.3182) kd_loss 0.4655 (0.5742) lr 1.3090e-03 eta 0:21:35
epoch [22/50] batch [240/288] time 0.167 (0.159) data 0.000 (0.001) loss 1.3138 (1.2664) ce_loss 1.0176 (0.9537) teacher_loss 1.0442 (0.9450) loss_zs_kd 0.1623 (0.1497) loss_oracle 0.1884 (0.2466) acc 71.8750 (74.2969) kd_loss 0.4637 (0.5731) lr 1.3090e-03 eta 0:21:31
epoch [22/50] batch [260/288] time 0.164 (0.159) data 0.000 (0.001) loss 1.1699 (1.2680) ce_loss 0.8418 (0.9543) teacher_loss 0.8489 (0.9449) loss_zs_kd 0.1509 (0.1492) loss_oracle 0.2456 (0.2485) acc 81.2500 (74.3149) kd_loss 0.6847 (0.5738) lr 1.3090e-03 eta 0:21:27
epoch [22/50] batch [280/288] time 0.348 (0.159) data 0.000 (0.001) loss 0.8864 (1.2700) ce_loss 0.5547 (0.9561) teacher_loss 0.5381 (0.9465) loss_zs_kd 0.1441 (0.1494) loss_oracle 0.2762 (0.2489) acc 90.6250 (74.1853) kd_loss 0.5121 (0.5775) lr 1.3090e-03 eta 0:21:21
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,424
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,029
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.1%
******* Domain a best val acc:      87.2%, epoch: 20 *******
******* Domain a best val test acc: 83.7%, epoch: 20 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [23/50] batch [20/288] time 0.173 (0.181) data 0.000 (0.015) loss 1.4861 (1.2637) ce_loss 1.1084 (0.9249) teacher_loss 1.1351 (0.9226) loss_zs_kd 0.1364 (0.1411) loss_oracle 0.2828 (0.2705) acc 65.6250 (75.0000) kd_loss 0.5021 (0.5796) lr 1.2487e-03 eta 0:24:17
epoch [23/50] batch [40/288] time 0.161 (0.170) data 0.000 (0.007) loss 1.0640 (1.2459) ce_loss 0.8481 (0.9233) teacher_loss 0.7957 (0.9169) loss_zs_kd 0.1357 (0.1438) loss_oracle 0.2004 (0.2572) acc 75.0000 (75.2344) kd_loss 0.3703 (0.5609) lr 1.2487e-03 eta 0:22:46
epoch [23/50] batch [60/288] time 0.154 (0.166) data 0.000 (0.005) loss 1.7037 (1.2742) ce_loss 1.3379 (0.9531) teacher_loss 1.3297 (0.9495) loss_zs_kd 0.1945 (0.1460) loss_oracle 0.2767 (0.2518) acc 65.6250 (74.3750) kd_loss 0.6604 (0.5581) lr 1.2487e-03 eta 0:22:07
epoch [23/50] batch [80/288] time 0.148 (0.164) data 0.000 (0.004) loss 1.5223 (1.2622) ce_loss 1.2568 (0.9456) teacher_loss 1.1546 (0.9383) loss_zs_kd 0.1790 (0.1486) loss_oracle 0.2782 (0.2496) acc 62.5000 (74.1406) kd_loss 0.5884 (0.5562) lr 1.2487e-03 eta 0:21:49
epoch [23/50] batch [100/288] time 0.136 (0.160) data 0.000 (0.003) loss 1.0573 (1.2538) ce_loss 0.7261 (0.9340) teacher_loss 0.7252 (0.9266) loss_zs_kd 0.1561 (0.1506) loss_oracle 0.2541 (0.2519) acc 84.3750 (74.5312) kd_loss 0.5649 (0.5554) lr 1.2487e-03 eta 0:21:12
epoch [23/50] batch [120/288] time 0.345 (0.172) data 0.000 (0.003) loss 0.9615 (1.2646) ce_loss 0.6064 (0.9381) teacher_loss 0.5934 (0.9331) loss_zs_kd 0.1643 (0.1521) loss_oracle 0.2860 (0.2555) acc 90.6250 (74.5312) kd_loss 0.5702 (0.5601) lr 1.2487e-03 eta 0:22:43
epoch [23/50] batch [140/288] time 0.169 (0.169) data 0.000 (0.002) loss 1.1215 (1.2601) ce_loss 0.8696 (0.9343) teacher_loss 0.8584 (0.9283) loss_zs_kd 0.1147 (0.1497) loss_oracle 0.2058 (0.2570) acc 81.2500 (74.7545) kd_loss 0.2450 (0.5617) lr 1.2487e-03 eta 0:22:17
epoch [23/50] batch [160/288] time 0.142 (0.167) data 0.000 (0.002) loss 1.2813 (1.2715) ce_loss 0.9829 (0.9445) teacher_loss 0.9512 (0.9379) loss_zs_kd 0.1328 (0.1496) loss_oracle 0.2637 (0.2588) acc 71.8750 (74.5312) kd_loss 0.6750 (0.5634) lr 1.2487e-03 eta 0:21:57
epoch [23/50] batch [180/288] time 0.146 (0.165) data 0.000 (0.002) loss 1.0805 (1.2657) ce_loss 0.8521 (0.9404) teacher_loss 0.8192 (0.9330) loss_zs_kd 0.0905 (0.1488) loss_oracle 0.2160 (0.2583) acc 78.1250 (74.6701) kd_loss 0.4739 (0.5656) lr 1.2487e-03 eta 0:21:41
epoch [23/50] batch [200/288] time 0.146 (0.164) data 0.000 (0.002) loss 1.0290 (1.2650) ce_loss 0.7959 (0.9415) teacher_loss 0.7517 (0.9339) loss_zs_kd 0.1501 (0.1486) loss_oracle 0.2023 (0.2568) acc 75.0000 (74.7656) kd_loss 0.5735 (0.5673) lr 1.2487e-03 eta 0:21:28
epoch [23/50] batch [220/288] time 0.145 (0.163) data 0.000 (0.002) loss 1.4782 (1.2639) ce_loss 1.1836 (0.9435) teacher_loss 1.1584 (0.9360) loss_zs_kd 0.1379 (0.1486) loss_oracle 0.2508 (0.2535) acc 71.8750 (74.6733) kd_loss 0.5964 (0.5704) lr 1.2487e-03 eta 0:21:18
epoch [23/50] batch [240/288] time 0.150 (0.162) data 0.000 (0.001) loss 1.0683 (1.2697) ce_loss 0.7773 (0.9519) teacher_loss 0.7809 (0.9452) loss_zs_kd 0.1693 (0.1475) loss_oracle 0.2027 (0.2507) acc 78.1250 (74.5833) kd_loss 0.4293 (0.5680) lr 1.2487e-03 eta 0:21:08
epoch [23/50] batch [260/288] time 0.094 (0.161) data 0.000 (0.001) loss 1.0158 (1.2787) ce_loss 0.6440 (0.9606) teacher_loss 0.6183 (0.9536) loss_zs_kd 0.1404 (0.1475) loss_oracle 0.3273 (0.2513) acc 84.3750 (74.2668) kd_loss 0.7095 (0.5729) lr 1.2487e-03 eta 0:20:57
epoch [23/50] batch [280/288] time 0.314 (0.164) data 0.000 (0.001) loss 1.2519 (1.2715) ce_loss 0.9189 (0.9545) teacher_loss 0.8836 (0.9470) loss_zs_kd 0.1733 (0.1468) loss_oracle 0.2817 (0.2511) acc 71.8750 (74.4085) kd_loss 0.6806 (0.5736) lr 1.2487e-03 eta 0:21:16
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,424
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.3%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,035
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 80.4%
******* Domain a best val acc:      87.2%, epoch: 20 *******
******* Domain a best val test acc: 83.7%, epoch: 20 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [24/50] batch [20/288] time 0.155 (0.167) data 0.000 (0.011) loss 1.3056 (1.2470) ce_loss 1.0654 (0.9270) teacher_loss 0.9786 (0.9225) loss_zs_kd 0.1289 (0.1344) loss_oracle 0.2625 (0.2574) acc 78.1250 (74.3750) kd_loss 0.4946 (0.6196) lr 1.1874e-03 eta 0:21:37
epoch [24/50] batch [40/288] time 0.152 (0.161) data 0.000 (0.005) loss 1.2942 (1.2857) ce_loss 0.9814 (0.9698) teacher_loss 0.9761 (0.9617) loss_zs_kd 0.1862 (0.1410) loss_oracle 0.2250 (0.2536) acc 71.8750 (73.8281) kd_loss 0.4251 (0.6009) lr 1.1874e-03 eta 0:20:43
epoch [24/50] batch [60/288] time 0.168 (0.160) data 0.000 (0.004) loss 1.2842 (1.2972) ce_loss 0.9302 (0.9810) teacher_loss 0.9313 (0.9724) loss_zs_kd 0.1271 (0.1469) loss_oracle 0.2894 (0.2514) acc 78.1250 (73.8021) kd_loss 0.6774 (0.5877) lr 1.1874e-03 eta 0:20:33
epoch [24/50] batch [80/288] time 0.175 (0.160) data 0.000 (0.003) loss 1.1888 (1.2703) ce_loss 0.8672 (0.9544) teacher_loss 0.8247 (0.9451) loss_zs_kd 0.1710 (0.1458) loss_oracle 0.2786 (0.2523) acc 75.0000 (74.2969) kd_loss 0.5241 (0.5846) lr 1.1874e-03 eta 0:20:30
epoch [24/50] batch [100/288] time 0.332 (0.164) data 0.000 (0.002) loss 1.1158 (1.2674) ce_loss 0.7773 (0.9536) teacher_loss 0.7670 (0.9431) loss_zs_kd 0.1941 (0.1457) loss_oracle 0.2517 (0.2515) acc 84.3750 (74.4375) kd_loss 0.5023 (0.5833) lr 1.1874e-03 eta 0:20:58
epoch [24/50] batch [120/288] time 0.174 (0.171) data 0.000 (0.002) loss 1.2816 (1.2594) ce_loss 0.9902 (0.9456) teacher_loss 0.9670 (0.9344) loss_zs_kd 0.1144 (0.1462) loss_oracle 0.2574 (0.2519) acc 68.7500 (74.8438) kd_loss 0.5337 (0.5798) lr 1.1874e-03 eta 0:21:48
epoch [24/50] batch [140/288] time 0.155 (0.171) data 0.000 (0.002) loss 1.2592 (1.2518) ce_loss 0.9854 (0.9412) teacher_loss 0.9724 (0.9274) loss_zs_kd 0.1321 (0.1482) loss_oracle 0.2207 (0.2504) acc 78.1250 (74.8438) kd_loss 0.5726 (0.5740) lr 1.1874e-03 eta 0:21:46
epoch [24/50] batch [160/288] time 0.172 (0.171) data 0.000 (0.002) loss 1.3982 (1.2581) ce_loss 1.0752 (0.9461) teacher_loss 1.0939 (0.9328) loss_zs_kd 0.1324 (0.1517) loss_oracle 0.2381 (0.2495) acc 65.6250 (74.5703) kd_loss 0.5283 (0.5685) lr 1.1874e-03 eta 0:21:44
epoch [24/50] batch [180/288] time 0.167 (0.171) data 0.000 (0.001) loss 1.1484 (1.2677) ce_loss 0.8472 (0.9566) teacher_loss 0.8176 (0.9436) loss_zs_kd 0.1051 (0.1504) loss_oracle 0.2782 (0.2489) acc 75.0000 (74.1146) kd_loss 0.7466 (0.5702) lr 1.1874e-03 eta 0:21:37
epoch [24/50] batch [200/288] time 0.169 (0.171) data 0.000 (0.001) loss 1.2712 (1.2682) ce_loss 0.8999 (0.9569) teacher_loss 0.9013 (0.9444) loss_zs_kd 0.1459 (0.1498) loss_oracle 0.2969 (0.2490) acc 71.8750 (73.9844) kd_loss 0.7251 (0.5750) lr 1.1874e-03 eta 0:21:33
epoch [24/50] batch [220/288] time 0.095 (0.171) data 0.000 (0.001) loss 1.0808 (1.2675) ce_loss 0.7734 (0.9564) teacher_loss 0.7563 (0.9434) loss_zs_kd 0.1632 (0.1495) loss_oracle 0.2429 (0.2494) acc 78.1250 (74.0341) kd_loss 0.5310 (0.5733) lr 1.1874e-03 eta 0:21:32
epoch [24/50] batch [240/288] time 0.170 (0.173) data 0.000 (0.001) loss 1.0858 (1.2680) ce_loss 0.7603 (0.9574) teacher_loss 0.7358 (0.9446) loss_zs_kd 0.1536 (0.1488) loss_oracle 0.2731 (0.2490) acc 87.5000 (73.9193) kd_loss 0.7210 (0.5742) lr 1.1874e-03 eta 0:21:46
epoch [24/50] batch [260/288] time 0.176 (0.173) data 0.000 (0.001) loss 0.8909 (1.2708) ce_loss 0.5132 (0.9603) teacher_loss 0.5181 (0.9481) loss_zs_kd 0.1728 (0.1484) loss_oracle 0.2863 (0.2486) acc 87.5000 (73.7380) kd_loss 0.5342 (0.5745) lr 1.1874e-03 eta 0:21:39
epoch [24/50] batch [280/288] time 0.165 (0.173) data 0.000 (0.001) loss 1.1785 (1.2742) ce_loss 0.9204 (0.9630) teacher_loss 0.9014 (0.9505) loss_zs_kd 0.1439 (0.1489) loss_oracle 0.2051 (0.2492) acc 75.0000 (73.7054) kd_loss 0.3722 (0.5742) lr 1.1874e-03 eta 0:21:34
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,431
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.7%
******* Domain a best val acc:      87.2%, epoch: 20 *******
******* Domain a best val test acc: 83.7%, epoch: 20 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [25/50] batch [20/288] time 0.094 (0.211) data 0.000 (0.013) loss 1.5382 (1.2833) ce_loss 1.2705 (0.9724) teacher_loss 1.2266 (0.9564) loss_zs_kd 0.1301 (0.1476) loss_oracle 0.2466 (0.2531) acc 65.6250 (72.6562) kd_loss 0.5315 (0.5415) lr 1.1253e-03 eta 0:26:16
epoch [25/50] batch [40/288] time 0.151 (0.203) data 0.000 (0.007) loss 1.0080 (1.2801) ce_loss 0.7046 (0.9722) teacher_loss 0.7081 (0.9634) loss_zs_kd 0.1184 (0.1447) loss_oracle 0.2406 (0.2444) acc 87.5000 (73.3594) kd_loss 0.6020 (0.5569) lr 1.1253e-03 eta 0:25:15
epoch [25/50] batch [60/288] time 0.172 (0.189) data 0.000 (0.005) loss 1.6350 (1.2950) ce_loss 1.3477 (0.9926) teacher_loss 1.3158 (0.9834) loss_zs_kd 0.1367 (0.1410) loss_oracle 0.2508 (0.2411) acc 62.5000 (72.9167) kd_loss 0.5597 (0.5550) lr 1.1253e-03 eta 0:23:27
epoch [25/50] batch [80/288] time 0.170 (0.183) data 0.000 (0.003) loss 1.2952 (1.2906) ce_loss 0.9746 (0.9912) teacher_loss 0.9460 (0.9784) loss_zs_kd 0.2377 (0.1423) loss_oracle 0.2303 (0.2411) acc 71.8750 (73.2422) kd_loss 0.3999 (0.5563) lr 1.1253e-03 eta 0:22:33
epoch [25/50] batch [100/288] time 0.168 (0.178) data 0.000 (0.003) loss 1.1570 (1.2905) ce_loss 0.8096 (0.9854) teacher_loss 0.8702 (0.9724) loss_zs_kd 0.1733 (0.1486) loss_oracle 0.2003 (0.2439) acc 71.8750 (73.5000) kd_loss 0.4697 (0.5652) lr 1.1253e-03 eta 0:21:56
epoch [25/50] batch [120/288] time 0.144 (0.175) data 0.000 (0.002) loss 1.4701 (1.2795) ce_loss 1.1426 (0.9730) teacher_loss 1.1296 (0.9609) loss_zs_kd 0.1360 (0.1474) loss_oracle 0.2725 (0.2449) acc 65.6250 (73.6979) kd_loss 0.7116 (0.5723) lr 1.1253e-03 eta 0:21:26
epoch [25/50] batch [140/288] time 0.172 (0.173) data 0.000 (0.002) loss 0.6864 (1.2757) ce_loss 0.4182 (0.9725) teacher_loss 0.3968 (0.9587) loss_zs_kd 0.1109 (0.1475) loss_oracle 0.2341 (0.2434) acc 87.5000 (73.8616) kd_loss 0.5316 (0.5728) lr 1.1253e-03 eta 0:21:11
epoch [25/50] batch [160/288] time 0.118 (0.174) data 0.000 (0.002) loss 1.1393 (1.2629) ce_loss 0.8599 (0.9599) teacher_loss 0.8279 (0.9462) loss_zs_kd 0.1297 (0.1476) loss_oracle 0.2466 (0.2429) acc 78.1250 (74.1602) kd_loss 0.5948 (0.5741) lr 1.1253e-03 eta 0:21:13
epoch [25/50] batch [180/288] time 0.196 (0.179) data 0.000 (0.002) loss 1.3412 (1.2653) ce_loss 1.0332 (0.9636) teacher_loss 1.0384 (0.9485) loss_zs_kd 0.1485 (0.1477) loss_oracle 0.2286 (0.2429) acc 71.8750 (74.0972) kd_loss 0.6559 (0.5726) lr 1.1253e-03 eta 0:21:49
epoch [25/50] batch [200/288] time 0.178 (0.179) data 0.000 (0.002) loss 1.0084 (1.2623) ce_loss 0.6865 (0.9599) teacher_loss 0.6430 (0.9438) loss_zs_kd 0.1933 (0.1485) loss_oracle 0.2687 (0.2442) acc 81.2500 (74.0625) kd_loss 0.4997 (0.5690) lr 1.1253e-03 eta 0:21:41
epoch [25/50] batch [220/288] time 0.164 (0.177) data 0.000 (0.001) loss 1.1595 (1.2581) ce_loss 0.8320 (0.9537) teacher_loss 0.8029 (0.9387) loss_zs_kd 0.1837 (0.1488) loss_oracle 0.2647 (0.2450) acc 81.2500 (74.1903) kd_loss 0.7046 (0.5704) lr 1.1253e-03 eta 0:21:26
epoch [25/50] batch [240/288] time 0.143 (0.175) data 0.000 (0.001) loss 1.7635 (1.2610) ce_loss 1.4795 (0.9559) teacher_loss 1.4500 (0.9417) loss_zs_kd 0.1577 (0.1485) loss_oracle 0.2346 (0.2450) acc 62.5000 (74.1797) kd_loss 0.5907 (0.5688) lr 1.1253e-03 eta 0:21:09
epoch [25/50] batch [260/288] time 0.145 (0.173) data 0.000 (0.001) loss 1.1371 (1.2586) ce_loss 0.8438 (0.9532) teacher_loss 0.8297 (0.9390) loss_zs_kd 0.1443 (0.1495) loss_oracle 0.2352 (0.2448) acc 78.1250 (74.3510) kd_loss 0.4757 (0.5693) lr 1.1253e-03 eta 0:20:53
epoch [25/50] batch [280/288] time 0.174 (0.172) data 0.000 (0.001) loss 1.2823 (1.2586) ce_loss 1.0254 (0.9517) teacher_loss 1.0048 (0.9383) loss_zs_kd 0.1114 (0.1495) loss_oracle 0.2218 (0.2456) acc 78.1250 (74.5089) kd_loss 0.4282 (0.5732) lr 1.1253e-03 eta 0:20:41
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,425
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 86.4%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,030
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.2%
******* Domain a best val acc:      87.2%, epoch: 20 *******
******* Domain a best val test acc: 83.7%, epoch: 20 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [26/50] batch [20/288] time 0.162 (0.183) data 0.000 (0.015) loss 1.0586 (1.1459) ce_loss 0.6968 (0.8160) teacher_loss 0.6915 (0.8083) loss_zs_kd 0.0962 (0.1483) loss_oracle 0.3190 (0.2635) acc 81.2500 (79.6875) kd_loss 0.6599 (0.5986) lr 1.0628e-03 eta 0:21:52
epoch [26/50] batch [40/288] time 0.181 (0.171) data 0.000 (0.008) loss 1.2245 (1.2001) ce_loss 0.9790 (0.8818) teacher_loss 0.9476 (0.8671) loss_zs_kd 0.0880 (0.1460) loss_oracle 0.2329 (0.2601) acc 68.7500 (76.2500) kd_loss 0.6262 (0.5911) lr 1.0628e-03 eta 0:20:27
epoch [26/50] batch [60/288] time 0.155 (0.167) data 0.001 (0.005) loss 1.2743 (1.2184) ce_loss 0.9824 (0.8998) teacher_loss 0.9635 (0.8847) loss_zs_kd 0.1274 (0.1485) loss_oracle 0.2470 (0.2594) acc 62.5000 (75.5208) kd_loss 0.4734 (0.5933) lr 1.0628e-03 eta 0:19:50
epoch [26/50] batch [80/288] time 0.151 (0.164) data 0.000 (0.004) loss 1.6371 (1.2298) ce_loss 1.3574 (0.9099) teacher_loss 1.3170 (0.8951) loss_zs_kd 0.1385 (0.1492) loss_oracle 0.2508 (0.2601) acc 75.0000 (75.3906) kd_loss 0.5107 (0.5961) lr 1.0628e-03 eta 0:19:28
epoch [26/50] batch [100/288] time 0.156 (0.163) data 0.000 (0.003) loss 1.0218 (1.2464) ce_loss 0.7451 (0.9236) teacher_loss 0.7232 (0.9093) loss_zs_kd 0.1176 (0.1488) loss_oracle 0.2399 (0.2627) acc 84.3750 (74.7500) kd_loss 0.4489 (0.5980) lr 1.0628e-03 eta 0:19:14
epoch [26/50] batch [120/288] time 0.085 (0.166) data 0.000 (0.003) loss 1.1878 (1.2488) ce_loss 0.8638 (0.9257) teacher_loss 0.8212 (0.9134) loss_zs_kd 0.2208 (0.1482) loss_oracle 0.2562 (0.2613) acc 71.8750 (74.5573) kd_loss 0.5236 (0.5909) lr 1.0628e-03 eta 0:19:32
epoch [26/50] batch [140/288] time 0.166 (0.170) data 0.000 (0.002) loss 1.3431 (1.2431) ce_loss 1.0020 (0.9203) teacher_loss 1.0175 (0.9091) loss_zs_kd 0.1517 (0.1482) loss_oracle 0.2497 (0.2599) acc 81.2500 (75.0223) kd_loss 0.5911 (0.5925) lr 1.0628e-03 eta 0:19:59
epoch [26/50] batch [160/288] time 0.163 (0.169) data 0.000 (0.002) loss 1.4672 (1.2430) ce_loss 1.1387 (0.9207) teacher_loss 1.0962 (0.9099) loss_zs_kd 0.2070 (0.1492) loss_oracle 0.2674 (0.2585) acc 75.0000 (75.1367) kd_loss 0.5913 (0.5859) lr 1.0628e-03 eta 0:19:46
epoch [26/50] batch [180/288] time 0.157 (0.167) data 0.000 (0.002) loss 1.0539 (1.2416) ce_loss 0.8003 (0.9204) teacher_loss 0.7497 (0.9096) loss_zs_kd 0.1106 (0.1487) loss_oracle 0.2489 (0.2576) acc 78.1250 (74.9479) kd_loss 0.5774 (0.5887) lr 1.0628e-03 eta 0:19:33
epoch [26/50] batch [200/288] time 0.150 (0.166) data 0.000 (0.002) loss 1.2229 (1.2450) ce_loss 0.9092 (0.9249) teacher_loss 0.9204 (0.9141) loss_zs_kd 0.1452 (0.1486) loss_oracle 0.2299 (0.2565) acc 81.2500 (74.7969) kd_loss 0.5806 (0.5893) lr 1.0628e-03 eta 0:19:23
epoch [26/50] batch [220/288] time 0.154 (0.165) data 0.000 (0.002) loss 0.6581 (1.2478) ce_loss 0.3125 (0.9271) teacher_loss 0.3471 (0.9171) loss_zs_kd 0.1253 (0.1488) loss_oracle 0.2484 (0.2563) acc 93.7500 (74.7443) kd_loss 0.6419 (0.5910) lr 1.0628e-03 eta 0:19:14
epoch [26/50] batch [240/288] time 0.158 (0.165) data 0.000 (0.001) loss 1.3035 (1.2533) ce_loss 0.9644 (0.9332) teacher_loss 0.9848 (0.9226) loss_zs_kd 0.1701 (0.1493) loss_oracle 0.2336 (0.2560) acc 75.0000 (74.6354) kd_loss 0.5624 (0.5902) lr 1.0628e-03 eta 0:19:10
epoch [26/50] batch [260/288] time 0.346 (0.165) data 0.000 (0.001) loss 1.2226 (1.2616) ce_loss 0.9287 (0.9416) teacher_loss 0.8910 (0.9307) loss_zs_kd 0.1772 (0.1506) loss_oracle 0.2430 (0.2556) acc 75.0000 (74.3029) kd_loss 0.6149 (0.5923) lr 1.0628e-03 eta 0:19:02
epoch [26/50] batch [280/288] time 0.403 (0.167) data 0.000 (0.001) loss 1.4413 (1.2649) ce_loss 1.1240 (0.9451) teacher_loss 1.1203 (0.9339) loss_zs_kd 0.1754 (0.1518) loss_oracle 0.2333 (0.2551) acc 65.6250 (74.2634) kd_loss 0.7833 (0.5925) lr 1.0628e-03 eta 0:19:13
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,431
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,027
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 80.2%
******* Domain a best val acc:      87.2%, epoch: 20 *******
******* Domain a best val test acc: 83.7%, epoch: 20 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [27/50] batch [20/288] time 0.171 (0.172) data 0.000 (0.013) loss 0.9124 (1.2154) ce_loss 0.6245 (0.9100) teacher_loss 0.6090 (0.8932) loss_zs_kd 0.1789 (0.1657) loss_oracle 0.2139 (0.2393) acc 81.2500 (76.4062) kd_loss 0.2533 (0.5360) lr 1.0000e-03 eta 0:19:47
epoch [27/50] batch [40/288] time 0.164 (0.164) data 0.000 (0.007) loss 0.7248 (1.2616) ce_loss 0.4434 (0.9569) teacher_loss 0.4148 (0.9438) loss_zs_kd 0.1123 (0.1553) loss_oracle 0.2539 (0.2402) acc 93.7500 (75.5469) kd_loss 0.6905 (0.5440) lr 1.0000e-03 eta 0:18:47
epoch [27/50] batch [60/288] time 0.167 (0.162) data 0.000 (0.005) loss 1.6601 (1.2415) ce_loss 1.3213 (0.9369) teacher_loss 1.2719 (0.9219) loss_zs_kd 0.2437 (0.1573) loss_oracle 0.2663 (0.2410) acc 62.5000 (75.2083) kd_loss 0.5840 (0.5469) lr 1.0000e-03 eta 0:18:30
epoch [27/50] batch [80/288] time 0.094 (0.160) data 0.000 (0.003) loss 1.1580 (1.2352) ce_loss 0.7954 (0.9287) teacher_loss 0.7927 (0.9136) loss_zs_kd 0.1474 (0.1527) loss_oracle 0.2916 (0.2452) acc 75.0000 (75.1172) kd_loss 0.8086 (0.5665) lr 1.0000e-03 eta 0:18:16
epoch [27/50] batch [100/288] time 0.369 (0.173) data 0.000 (0.003) loss 1.0934 (1.2459) ce_loss 0.7910 (0.9381) teacher_loss 0.7355 (0.9217) loss_zs_kd 0.1953 (0.1529) loss_oracle 0.2603 (0.2477) acc 78.1250 (74.7812) kd_loss 0.5870 (0.5654) lr 1.0000e-03 eta 0:19:38
epoch [27/50] batch [120/288] time 0.166 (0.171) data 0.000 (0.002) loss 1.0228 (1.2275) ce_loss 0.7642 (0.9195) teacher_loss 0.7411 (0.9050) loss_zs_kd 0.1344 (0.1509) loss_oracle 0.2145 (0.2470) acc 87.5000 (75.4948) kd_loss 0.3884 (0.5645) lr 1.0000e-03 eta 0:19:20
epoch [27/50] batch [140/288] time 0.155 (0.169) data 0.000 (0.002) loss 1.3631 (1.2424) ce_loss 0.9355 (0.9308) teacher_loss 0.9571 (0.9191) loss_zs_kd 0.2368 (0.1531) loss_oracle 0.2876 (0.2467) acc 71.8750 (75.2232) kd_loss 0.5567 (0.5644) lr 1.0000e-03 eta 0:19:01
epoch [27/50] batch [160/288] time 0.166 (0.168) data 0.000 (0.002) loss 1.3395 (1.2447) ce_loss 0.9419 (0.9281) teacher_loss 0.9514 (0.9181) loss_zs_kd 0.1667 (0.1534) loss_oracle 0.3048 (0.2499) acc 71.8750 (75.2539) kd_loss 0.7677 (0.5743) lr 1.0000e-03 eta 0:18:57
epoch [27/50] batch [180/288] time 0.176 (0.168) data 0.000 (0.002) loss 1.0006 (1.2494) ce_loss 0.7246 (0.9315) teacher_loss 0.6887 (0.9218) loss_zs_kd 0.1587 (0.1533) loss_oracle 0.2326 (0.2509) acc 75.0000 (75.1562) kd_loss 0.5162 (0.5745) lr 1.0000e-03 eta 0:18:51
epoch [27/50] batch [200/288] time 0.156 (0.168) data 0.000 (0.002) loss 1.2106 (1.2418) ce_loss 0.9766 (0.9237) teacher_loss 0.9519 (0.9141) loss_zs_kd 0.1271 (0.1529) loss_oracle 0.1951 (0.2513) acc 78.1250 (75.2969) kd_loss 0.5445 (0.5741) lr 1.0000e-03 eta 0:18:47
epoch [27/50] batch [220/288] time 0.354 (0.167) data 0.000 (0.001) loss 1.2899 (1.2400) ce_loss 0.9023 (0.9232) teacher_loss 0.9089 (0.9130) loss_zs_kd 0.2747 (0.1518) loss_oracle 0.2436 (0.2512) acc 78.1250 (75.2983) kd_loss 0.5257 (0.5770) lr 1.0000e-03 eta 0:18:38
epoch [27/50] batch [240/288] time 0.087 (0.173) data 0.000 (0.001) loss 0.9015 (1.2518) ce_loss 0.6421 (0.9361) teacher_loss 0.6074 (0.9253) loss_zs_kd 0.1005 (0.1517) loss_oracle 0.2438 (0.2507) acc 81.2500 (74.7917) kd_loss 0.4798 (0.5780) lr 1.0000e-03 eta 0:19:11
epoch [27/50] batch [260/288] time 0.145 (0.171) data 0.000 (0.001) loss 0.9762 (1.2528) ce_loss 0.6890 (0.9375) teacher_loss 0.6961 (0.9267) loss_zs_kd 0.1179 (0.1520) loss_oracle 0.2211 (0.2501) acc 78.1250 (74.8077) kd_loss 0.4693 (0.5788) lr 1.0000e-03 eta 0:18:54
epoch [27/50] batch [280/288] time 0.149 (0.169) data 0.000 (0.001) loss 1.5680 (1.2571) ce_loss 1.2588 (0.9417) teacher_loss 1.2178 (0.9311) loss_zs_kd 0.2146 (0.1525) loss_oracle 0.2429 (0.2497) acc 53.1250 (74.6205) kd_loss 0.6454 (0.5784) lr 1.0000e-03 eta 0:18:42
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,433
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,034
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 80.4%
******* Domain a best val acc:      87.2%, epoch: 20 *******
******* Domain a best val test acc: 83.7%, epoch: 20 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [28/50] batch [20/288] time 0.149 (0.175) data 0.000 (0.012) loss 1.0096 (1.2334) ce_loss 0.7158 (0.9170) teacher_loss 0.7062 (0.8916) loss_zs_kd 0.1299 (0.1655) loss_oracle 0.2384 (0.2591) acc 81.2500 (75.4688) kd_loss 0.4993 (0.5966) lr 9.3721e-04 eta 0:19:13
epoch [28/50] batch [40/288] time 0.412 (0.181) data 0.000 (0.006) loss 0.9309 (1.2630) ce_loss 0.6064 (0.9495) teacher_loss 0.5668 (0.9315) loss_zs_kd 0.1280 (0.1498) loss_oracle 0.3001 (0.2566) acc 87.5000 (74.6875) kd_loss 0.5905 (0.5893) lr 9.3721e-04 eta 0:19:50
epoch [28/50] batch [60/288] time 0.099 (0.184) data 0.000 (0.004) loss 1.0859 (1.2804) ce_loss 0.7290 (0.9636) teacher_loss 0.7049 (0.9475) loss_zs_kd 0.1827 (0.1488) loss_oracle 0.2896 (0.2585) acc 78.1250 (74.1667) kd_loss 0.5980 (0.5922) lr 9.3721e-04 eta 0:20:10
epoch [28/50] batch [80/288] time 0.162 (0.176) data 0.000 (0.003) loss 1.0490 (1.2886) ce_loss 0.7437 (0.9697) teacher_loss 0.7307 (0.9523) loss_zs_kd 0.1246 (0.1515) loss_oracle 0.2561 (0.2605) acc 75.0000 (73.7891) kd_loss 0.4881 (0.5925) lr 9.3721e-04 eta 0:19:13
epoch [28/50] batch [100/288] time 0.153 (0.171) data 0.000 (0.003) loss 1.1398 (1.2781) ce_loss 0.8228 (0.9572) teacher_loss 0.8408 (0.9398) loss_zs_kd 0.0984 (0.1515) loss_oracle 0.2498 (0.2625) acc 81.2500 (74.0938) kd_loss 0.6758 (0.5997) lr 9.3721e-04 eta 0:18:37
epoch [28/50] batch [120/288] time 0.150 (0.168) data 0.000 (0.002) loss 1.1982 (1.2610) ce_loss 0.8828 (0.9439) teacher_loss 0.8541 (0.9256) loss_zs_kd 0.1297 (0.1496) loss_oracle 0.2792 (0.2606) acc 78.1250 (74.3229) kd_loss 0.6101 (0.5976) lr 9.3721e-04 eta 0:18:13
epoch [28/50] batch [140/288] time 0.157 (0.166) data 0.000 (0.002) loss 0.7300 (1.2573) ce_loss 0.4299 (0.9379) teacher_loss 0.4264 (0.9206) loss_zs_kd 0.1183 (0.1510) loss_oracle 0.2445 (0.2613) acc 93.7500 (74.6429) kd_loss 0.4911 (0.5952) lr 9.3721e-04 eta 0:17:56
epoch [28/50] batch [160/288] time 0.150 (0.165) data 0.000 (0.002) loss 1.5866 (1.2467) ce_loss 1.2881 (0.9285) teacher_loss 1.2361 (0.9113) loss_zs_kd 0.1582 (0.1502) loss_oracle 0.2714 (0.2603) acc 65.6250 (75.0000) kd_loss 0.5279 (0.5904) lr 9.3721e-04 eta 0:17:43
epoch [28/50] batch [180/288] time 0.149 (0.164) data 0.000 (0.002) loss 0.9955 (1.2407) ce_loss 0.7637 (0.9232) teacher_loss 0.6373 (0.9057) loss_zs_kd 0.2107 (0.1510) loss_oracle 0.2529 (0.2595) acc 78.1250 (75.1910) kd_loss 0.5437 (0.5883) lr 9.3721e-04 eta 0:17:38
epoch [28/50] batch [200/288] time 0.083 (0.167) data 0.000 (0.001) loss 1.6771 (1.2475) ce_loss 1.3145 (0.9312) teacher_loss 1.3122 (0.9138) loss_zs_kd 0.2051 (0.1517) loss_oracle 0.2624 (0.2578) acc 71.8750 (75.0781) kd_loss 0.6156 (0.5888) lr 9.3721e-04 eta 0:17:53
epoch [28/50] batch [220/288] time 0.145 (0.169) data 0.000 (0.001) loss 1.2517 (1.2455) ce_loss 0.9707 (0.9299) teacher_loss 0.9288 (0.9128) loss_zs_kd 0.1244 (0.1518) loss_oracle 0.2607 (0.2568) acc 81.2500 (75.1705) kd_loss 0.5894 (0.5860) lr 9.3721e-04 eta 0:18:00
epoch [28/50] batch [240/288] time 0.167 (0.168) data 0.000 (0.001) loss 0.6609 (1.2454) ce_loss 0.4006 (0.9301) teacher_loss 0.4055 (0.9127) loss_zs_kd 0.1269 (0.1522) loss_oracle 0.1920 (0.2566) acc 93.7500 (75.1823) kd_loss 0.4734 (0.5866) lr 9.3721e-04 eta 0:17:49
epoch [28/50] batch [260/288] time 0.160 (0.167) data 0.000 (0.001) loss 1.0515 (1.2492) ce_loss 0.7070 (0.9336) teacher_loss 0.7386 (0.9172) loss_zs_kd 0.1260 (0.1521) loss_oracle 0.2499 (0.2560) acc 81.2500 (75.1442) kd_loss 0.6293 (0.5860) lr 9.3721e-04 eta 0:17:40
epoch [28/50] batch [280/288] time 0.145 (0.166) data 0.000 (0.001) loss 1.0996 (1.2491) ce_loss 0.8013 (0.9323) teacher_loss 0.7955 (0.9160) loss_zs_kd 0.1451 (0.1525) loss_oracle 0.2315 (0.2568) acc 75.0000 (75.1339) kd_loss 0.5913 (0.5878) lr 9.3721e-04 eta 0:17:31
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,434
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,027
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 80.1%
******* Domain a best val acc:      87.2%, epoch: 20 *******
******* Domain a best val test acc: 83.7%, epoch: 20 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [29/50] batch [20/288] time 0.343 (0.203) data 0.000 (0.015) loss 0.9737 (1.1452) ce_loss 0.6221 (0.8201) teacher_loss 0.6036 (0.8079) loss_zs_kd 0.1993 (0.1519) loss_oracle 0.2705 (0.2614) acc 78.1250 (77.6562) kd_loss 0.7180 (0.6197) lr 8.7467e-04 eta 0:21:19
epoch [29/50] batch [40/288] time 0.137 (0.197) data 0.000 (0.008) loss 1.0922 (1.2453) ce_loss 0.8486 (0.9292) teacher_loss 0.8419 (0.9196) loss_zs_kd 0.1357 (0.1486) loss_oracle 0.1825 (0.2515) acc 78.1250 (75.0781) kd_loss 0.4430 (0.5929) lr 8.7467e-04 eta 0:20:42
epoch [29/50] batch [60/288] time 0.169 (0.183) data 0.000 (0.005) loss 2.0494 (1.2764) ce_loss 1.7188 (0.9654) teacher_loss 1.7088 (0.9559) loss_zs_kd 0.1522 (0.1435) loss_oracle 0.2645 (0.2488) acc 62.5000 (74.2708) kd_loss 0.5074 (0.5824) lr 8.7467e-04 eta 0:19:05
epoch [29/50] batch [80/288] time 0.168 (0.177) data 0.000 (0.004) loss 1.0362 (1.2760) ce_loss 0.6948 (0.9646) teacher_loss 0.7347 (0.9533) loss_zs_kd 0.1994 (0.1500) loss_oracle 0.2018 (0.2477) acc 87.5000 (73.8281) kd_loss 0.5046 (0.5827) lr 8.7467e-04 eta 0:18:28
epoch [29/50] batch [100/288] time 0.154 (0.173) data 0.000 (0.003) loss 1.6617 (1.2939) ce_loss 1.3203 (0.9791) teacher_loss 1.3310 (0.9693) loss_zs_kd 0.1513 (0.1528) loss_oracle 0.2550 (0.2482) acc 68.7500 (73.6875) kd_loss 0.6049 (0.5844) lr 8.7467e-04 eta 0:18:01
epoch [29/50] batch [120/288] time 0.149 (0.171) data 0.000 (0.003) loss 1.1944 (1.2811) ce_loss 0.8462 (0.9638) teacher_loss 0.8780 (0.9534) loss_zs_kd 0.0922 (0.1515) loss_oracle 0.2702 (0.2519) acc 78.1250 (74.3750) kd_loss 0.6775 (0.5915) lr 8.7467e-04 eta 0:17:44
epoch [29/50] batch [140/288] time 0.154 (0.170) data 0.000 (0.002) loss 1.2854 (1.2690) ce_loss 0.9985 (0.9536) teacher_loss 0.9766 (0.9422) loss_zs_kd 0.0870 (0.1498) loss_oracle 0.2653 (0.2519) acc 68.7500 (74.4643) kd_loss 0.8130 (0.5933) lr 8.7467e-04 eta 0:17:30
epoch [29/50] batch [160/288] time 0.085 (0.168) data 0.000 (0.002) loss 1.1313 (1.2693) ce_loss 0.7388 (0.9512) teacher_loss 0.7478 (0.9396) loss_zs_kd 0.2113 (0.1514) loss_oracle 0.2778 (0.2541) acc 78.1250 (74.6875) kd_loss 0.6320 (0.5937) lr 8.7467e-04 eta 0:17:16
epoch [29/50] batch [180/288] time 0.330 (0.171) data 0.000 (0.002) loss 1.4410 (1.2766) ce_loss 1.1738 (0.9588) teacher_loss 1.1179 (0.9462) loss_zs_kd 0.1627 (0.1523) loss_oracle 0.2418 (0.2542) acc 65.6250 (74.5833) kd_loss 0.5435 (0.5890) lr 8.7467e-04 eta 0:17:35
epoch [29/50] batch [200/288] time 0.176 (0.173) data 0.000 (0.002) loss 1.4324 (1.2730) ce_loss 1.1201 (0.9546) teacher_loss 1.0947 (0.9427) loss_zs_kd 0.1384 (0.1525) loss_oracle 0.2684 (0.2541) acc 68.7500 (74.6875) kd_loss 0.6534 (0.5883) lr 8.7467e-04 eta 0:17:41
epoch [29/50] batch [220/288] time 0.149 (0.172) data 0.000 (0.002) loss 1.3514 (1.2760) ce_loss 0.9824 (0.9573) teacher_loss 1.0023 (0.9464) loss_zs_kd 0.1738 (0.1515) loss_oracle 0.2621 (0.2539) acc 71.8750 (74.6307) kd_loss 0.8651 (0.5942) lr 8.7467e-04 eta 0:17:34
epoch [29/50] batch [240/288] time 0.171 (0.172) data 0.000 (0.001) loss 1.1327 (1.2763) ce_loss 0.8760 (0.9575) teacher_loss 0.8185 (0.9468) loss_zs_kd 0.1287 (0.1511) loss_oracle 0.2499 (0.2540) acc 78.1250 (74.5833) kd_loss 0.5437 (0.5956) lr 8.7467e-04 eta 0:17:28
epoch [29/50] batch [260/288] time 0.163 (0.171) data 0.000 (0.001) loss 1.1212 (1.2755) ce_loss 0.7847 (0.9571) teacher_loss 0.7938 (0.9459) loss_zs_kd 0.1953 (0.1519) loss_oracle 0.2297 (0.2536) acc 75.0000 (74.5913) kd_loss 0.5734 (0.5945) lr 8.7467e-04 eta 0:17:20
epoch [29/50] batch [280/288] time 0.166 (0.170) data 0.000 (0.001) loss 1.8572 (1.2759) ce_loss 1.4912 (0.9580) teacher_loss 1.5303 (0.9469) loss_zs_kd 0.1453 (0.1526) loss_oracle 0.2543 (0.2527) acc 59.3750 (74.5089) kd_loss 0.6162 (0.5941) lr 8.7467e-04 eta 0:17:11
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,434
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,038
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 80.5%
******* Domain a best val acc:      87.2%, epoch: 20 *******
******* Domain a best val test acc: 83.7%, epoch: 20 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [30/50] batch [20/288] time 0.185 (0.191) data 0.000 (0.016) loss 0.9793 (1.2179) ce_loss 0.7383 (0.9210) teacher_loss 0.6620 (0.9057) loss_zs_kd 0.1559 (0.1519) loss_oracle 0.2394 (0.2362) acc 78.1250 (74.0625) kd_loss 0.6005 (0.5652) lr 8.1262e-04 eta 0:19:09
epoch [30/50] batch [40/288] time 0.180 (0.183) data 0.001 (0.008) loss 1.2220 (1.1660) ce_loss 0.9189 (0.8661) teacher_loss 0.9017 (0.8547) loss_zs_kd 0.1238 (0.1483) loss_oracle 0.2584 (0.2373) acc 65.6250 (75.4688) kd_loss 0.6275 (0.5696) lr 8.1262e-04 eta 0:18:17
epoch [30/50] batch [60/288] time 0.177 (0.181) data 0.001 (0.005) loss 1.5325 (1.2004) ce_loss 1.1660 (0.8967) teacher_loss 1.1616 (0.8834) loss_zs_kd 0.2162 (0.1531) loss_oracle 0.2628 (0.2403) acc 65.6250 (75.2604) kd_loss 0.4807 (0.5804) lr 8.1262e-04 eta 0:18:05
epoch [30/50] batch [80/288] time 0.171 (0.182) data 0.000 (0.004) loss 1.1544 (1.2157) ce_loss 0.8188 (0.9124) teacher_loss 0.8392 (0.9023) loss_zs_kd 0.1411 (0.1520) loss_oracle 0.2447 (0.2374) acc 78.1250 (75.0391) kd_loss 0.6720 (0.5816) lr 8.1262e-04 eta 0:18:04
epoch [30/50] batch [100/288] time 0.108 (0.179) data 0.000 (0.003) loss 0.8867 (1.2325) ce_loss 0.5840 (0.9296) teacher_loss 0.5554 (0.9187) loss_zs_kd 0.1128 (0.1502) loss_oracle 0.2749 (0.2387) acc 84.3750 (74.9062) kd_loss 0.7087 (0.5862) lr 8.1262e-04 eta 0:17:41
epoch [30/50] batch [120/288] time 0.400 (0.181) data 0.000 (0.003) loss 1.3229 (1.2404) ce_loss 1.0303 (0.9392) teacher_loss 1.0039 (0.9293) loss_zs_kd 0.1076 (0.1496) loss_oracle 0.2652 (0.2363) acc 71.8750 (74.6615) kd_loss 0.5462 (0.5789) lr 8.1262e-04 eta 0:17:54
epoch [30/50] batch [140/288] time 0.160 (0.183) data 0.000 (0.003) loss 1.5096 (1.2585) ce_loss 1.2881 (0.9570) teacher_loss 1.2592 (0.9454) loss_zs_kd 0.0968 (0.1502) loss_oracle 0.2020 (0.2380) acc 56.2500 (74.3973) kd_loss 0.4274 (0.5767) lr 8.1262e-04 eta 0:18:02
epoch [30/50] batch [160/288] time 0.168 (0.180) data 0.000 (0.002) loss 1.0552 (1.2547) ce_loss 0.7505 (0.9544) teacher_loss 0.7702 (0.9420) loss_zs_kd 0.1464 (0.1499) loss_oracle 0.2117 (0.2377) acc 71.8750 (74.4336) kd_loss 0.5865 (0.5731) lr 8.1262e-04 eta 0:17:40
epoch [30/50] batch [180/288] time 0.153 (0.178) data 0.000 (0.002) loss 1.4318 (1.2654) ce_loss 1.1143 (0.9649) teacher_loss 1.0896 (0.9527) loss_zs_kd 0.1455 (0.1499) loss_oracle 0.2695 (0.2378) acc 71.8750 (74.0972) kd_loss 0.5100 (0.5714) lr 8.1262e-04 eta 0:17:21
epoch [30/50] batch [200/288] time 0.154 (0.176) data 0.000 (0.002) loss 1.4725 (1.2626) ce_loss 1.2051 (0.9608) teacher_loss 1.1665 (0.9474) loss_zs_kd 0.1622 (0.1499) loss_oracle 0.2249 (0.2403) acc 65.6250 (74.1719) kd_loss 0.3984 (0.5739) lr 8.1262e-04 eta 0:17:07
epoch [30/50] batch [220/288] time 0.145 (0.174) data 0.000 (0.002) loss 1.3787 (1.2661) ce_loss 1.0332 (0.9610) teacher_loss 1.0552 (0.9485) loss_zs_kd 0.1414 (0.1504) loss_oracle 0.2527 (0.2424) acc 65.6250 (74.0199) kd_loss 0.7048 (0.5758) lr 8.1262e-04 eta 0:16:54
epoch [30/50] batch [240/288] time 0.152 (0.173) data 0.000 (0.002) loss 0.8989 (1.2695) ce_loss 0.6191 (0.9630) teacher_loss 0.5641 (0.9499) loss_zs_kd 0.1396 (0.1502) loss_oracle 0.2650 (0.2444) acc 84.3750 (74.0495) kd_loss 0.5416 (0.5750) lr 8.1262e-04 eta 0:16:42
epoch [30/50] batch [260/288] time 0.413 (0.175) data 0.000 (0.001) loss 1.1547 (1.2796) ce_loss 0.7354 (0.9699) teacher_loss 0.7644 (0.9571) loss_zs_kd 0.1360 (0.1505) loss_oracle 0.3223 (0.2472) acc 81.2500 (73.9904) kd_loss 0.7792 (0.5778) lr 8.1262e-04 eta 0:16:51
epoch [30/50] batch [280/288] time 0.154 (0.176) data 0.000 (0.001) loss 1.0637 (1.2737) ce_loss 0.7017 (0.9616) teacher_loss 0.6990 (0.9495) loss_zs_kd 0.1192 (0.1501) loss_oracle 0.3051 (0.2491) acc 81.2500 (74.2969) kd_loss 0.7308 (0.5815) lr 8.1262e-04 eta 0:16:53
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,435
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,035
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 80.5%
******* Domain a best val acc:      87.2%, epoch: 30 *******
******* Domain a best val test acc: 83.8%, epoch: 30 *******
******* Domain a best test acc:     84.0%, epoch: 16 *******
epoch [31/50] batch [20/288] time 0.160 (0.186) data 0.000 (0.012) loss 0.6283 (1.2252) ce_loss 0.3621 (0.8797) teacher_loss 0.3530 (0.8778) loss_zs_kd 0.1176 (0.1642) loss_oracle 0.2164 (0.2653) acc 93.7500 (76.8750) kd_loss 0.4616 (0.5951) lr 7.5131e-04 eta 0:17:45
epoch [31/50] batch [40/288] time 0.175 (0.176) data 0.000 (0.006) loss 1.0034 (1.2735) ce_loss 0.6411 (0.9387) teacher_loss 0.6383 (0.9342) loss_zs_kd 0.1570 (0.1546) loss_oracle 0.2866 (0.2620) acc 87.5000 (75.0000) kd_loss 0.5900 (0.5956) lr 7.5131e-04 eta 0:16:48
epoch [31/50] batch [60/288] time 0.127 (0.167) data 0.001 (0.004) loss 1.2815 (1.2774) ce_loss 0.9414 (0.9519) teacher_loss 0.9392 (0.9405) loss_zs_kd 0.1617 (0.1516) loss_oracle 0.2614 (0.2611) acc 78.1250 (74.8958) kd_loss 0.5833 (0.5881) lr 7.5131e-04 eta 0:15:53
epoch [31/50] batch [80/288] time 0.088 (0.188) data 0.000 (0.003) loss 1.1435 (1.2571) ce_loss 0.8608 (0.9314) teacher_loss 0.7994 (0.9204) loss_zs_kd 0.1268 (0.1548) loss_oracle 0.2808 (0.2592) acc 81.2500 (75.1172) kd_loss 0.5640 (0.5881) lr 7.5131e-04 eta 0:17:45
epoch [31/50] batch [100/288] time 0.172 (0.182) data 0.000 (0.003) loss 1.3667 (1.2437) ce_loss 0.9795 (0.9186) teacher_loss 0.9990 (0.9074) loss_zs_kd 0.2168 (0.1548) loss_oracle 0.2593 (0.2588) acc 75.0000 (75.5000) kd_loss 0.6405 (0.5823) lr 7.5131e-04 eta 0:17:10
epoch [31/50] batch [120/288] time 0.165 (0.180) data 0.000 (0.002) loss 0.8755 (1.2519) ce_loss 0.5337 (0.9240) teacher_loss 0.5449 (0.9128) loss_zs_kd 0.1247 (0.1582) loss_oracle 0.2683 (0.2599) acc 87.5000 (75.4427) kd_loss 0.6237 (0.5881) lr 7.5131e-04 eta 0:16:52
epoch [31/50] batch [140/288] time 0.156 (0.177) data 0.000 (0.002) loss 1.0668 (1.2487) ce_loss 0.6499 (0.9216) teacher_loss 0.6908 (0.9096) loss_zs_kd 0.2141 (0.1591) loss_oracle 0.2688 (0.2596) acc 81.2500 (75.5804) kd_loss 0.4795 (0.5854) lr 7.5131e-04 eta 0:16:35
epoch [31/50] batch [160/288] time 0.160 (0.175) data 0.000 (0.002) loss 1.1630 (1.2561) ce_loss 0.7817 (0.9285) teacher_loss 0.7824 (0.9157) loss_zs_kd 0.1746 (0.1595) loss_oracle 0.2933 (0.2606) acc 84.3750 (75.4102) kd_loss 0.7731 (0.5872) lr 7.5131e-04 eta 0:16:22
epoch [31/50] batch [180/288] time 0.160 (0.175) data 0.000 (0.002) loss 1.4686 (1.2570) ce_loss 1.1914 (0.9320) teacher_loss 1.1919 (0.9192) loss_zs_kd 0.1526 (0.1572) loss_oracle 0.2004 (0.2592) acc 68.7500 (75.1042) kd_loss 0.4494 (0.5840) lr 7.5131e-04 eta 0:16:14
epoch [31/50] batch [200/288] time 0.089 (0.176) data 0.000 (0.001) loss 1.2081 (1.2578) ce_loss 0.9082 (0.9343) teacher_loss 0.9304 (0.9213) loss_zs_kd 0.1224 (0.1575) loss_oracle 0.2165 (0.2578) acc 81.2500 (74.9531) kd_loss 0.4379 (0.5805) lr 7.5131e-04 eta 0:16:17
epoch [31/50] batch [220/288] time 0.173 (0.179) data 0.000 (0.001) loss 1.3918 (1.2620) ce_loss 1.0225 (0.9394) teacher_loss 1.0246 (0.9262) loss_zs_kd 0.1570 (0.1569) loss_oracle 0.2887 (0.2574) acc 65.6250 (74.8722) kd_loss 0.6996 (0.5809) lr 7.5131e-04 eta 0:16:31
epoch [31/50] batch [240/288] time 0.160 (0.178) data 0.000 (0.001) loss 1.2549 (1.2608) ce_loss 0.9248 (0.9370) teacher_loss 0.8961 (0.9238) loss_zs_kd 0.1514 (0.1569) loss_oracle 0.2831 (0.2585) acc 78.1250 (74.8047) kd_loss 0.7801 (0.5832) lr 7.5131e-04 eta 0:16:23
epoch [31/50] batch [260/288] time 0.146 (0.177) data 0.000 (0.001) loss 0.9532 (1.2632) ce_loss 0.5972 (0.9382) teacher_loss 0.5977 (0.9255) loss_zs_kd 0.0892 (0.1555) loss_oracle 0.3109 (0.2599) acc 87.5000 (74.7716) kd_loss 0.7044 (0.5869) lr 7.5131e-04 eta 0:16:14
epoch [31/50] batch [280/288] time 0.150 (0.176) data 0.000 (0.001) loss 1.0816 (1.2544) ce_loss 0.7925 (0.9297) teacher_loss 0.7848 (0.9172) loss_zs_kd 0.0978 (0.1543) loss_oracle 0.2479 (0.2601) acc 81.2500 (75.1562) kd_loss 0.6157 (0.5867) lr 7.5131e-04 eta 0:16:03
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,437
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,041
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 80.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      87.3%, epoch: 31 *******
******* Domain a best val test acc: 84.1%, epoch: 31 *******
******* Domain a best test acc:     84.1%, epoch: 31 *******
epoch [32/50] batch [20/288] time 0.142 (0.214) data 0.000 (0.014) loss 1.3001 (1.2857) ce_loss 0.9243 (0.9554) teacher_loss 0.9425 (0.9485) loss_zs_kd 0.0965 (0.1469) loss_oracle 0.3094 (0.2638) acc 75.0000 (76.0938) kd_loss 0.6228 (0.6267) lr 6.9098e-04 eta 0:19:25
epoch [32/50] batch [40/288] time 0.172 (0.189) data 0.000 (0.007) loss 0.7308 (1.2804) ce_loss 0.4988 (0.9580) teacher_loss 0.4936 (0.9445) loss_zs_kd 0.0896 (0.1531) loss_oracle 0.1923 (0.2594) acc 84.3750 (75.8594) kd_loss 0.3804 (0.5976) lr 6.9098e-04 eta 0:17:07
epoch [32/50] batch [60/288] time 0.153 (0.182) data 0.000 (0.005) loss 1.1568 (1.2984) ce_loss 0.8599 (0.9742) teacher_loss 0.8373 (0.9600) loss_zs_kd 0.1632 (0.1549) loss_oracle 0.2379 (0.2610) acc 75.0000 (74.8438) kd_loss 0.5229 (0.6074) lr 6.9098e-04 eta 0:16:22
epoch [32/50] batch [80/288] time 0.169 (0.177) data 0.000 (0.004) loss 1.7216 (1.2753) ce_loss 1.3818 (0.9502) teacher_loss 1.4135 (0.9399) loss_zs_kd 0.1285 (0.1539) loss_oracle 0.2439 (0.2584) acc 65.6250 (75.3125) kd_loss 0.5818 (0.6000) lr 6.9098e-04 eta 0:15:55
epoch [32/50] batch [100/288] time 0.162 (0.174) data 0.000 (0.003) loss 0.8290 (1.2762) ce_loss 0.4731 (0.9505) teacher_loss 0.4449 (0.9410) loss_zs_kd 0.1558 (0.1513) loss_oracle 0.3062 (0.2595) acc 90.6250 (75.3438) kd_loss 0.6383 (0.6022) lr 6.9098e-04 eta 0:15:36
epoch [32/50] batch [120/288] time 0.170 (0.172) data 0.000 (0.002) loss 0.8960 (1.2696) ce_loss 0.6230 (0.9473) teacher_loss 0.5942 (0.9372) loss_zs_kd 0.1201 (0.1517) loss_oracle 0.2417 (0.2566) acc 78.1250 (74.9740) kd_loss 0.5146 (0.5949) lr 6.9098e-04 eta 0:15:19
epoch [32/50] batch [140/288] time 0.110 (0.174) data 0.000 (0.002) loss 1.3339 (1.2677) ce_loss 0.9502 (0.9457) teacher_loss 0.9825 (0.9361) loss_zs_kd 0.2084 (0.1515) loss_oracle 0.2472 (0.2559) acc 78.1250 (74.9554) kd_loss 0.5409 (0.5931) lr 6.9098e-04 eta 0:15:25
epoch [32/50] batch [160/288] time 0.177 (0.180) data 0.000 (0.002) loss 1.0626 (1.2651) ce_loss 0.7173 (0.9411) teacher_loss 0.6745 (0.9324) loss_zs_kd 0.1622 (0.1511) loss_oracle 0.3071 (0.2572) acc 78.1250 (74.8633) kd_loss 0.5930 (0.5979) lr 6.9098e-04 eta 0:15:54
epoch [32/50] batch [180/288] time 0.175 (0.178) data 0.000 (0.002) loss 1.1935 (1.2760) ce_loss 0.8984 (0.9503) teacher_loss 0.8648 (0.9411) loss_zs_kd 0.1627 (0.1519) loss_oracle 0.2473 (0.2590) acc 75.0000 (74.4792) kd_loss 0.5090 (0.5986) lr 6.9098e-04 eta 0:15:43
epoch [32/50] batch [200/288] time 0.171 (0.177) data 0.000 (0.002) loss 1.3135 (1.2704) ce_loss 0.9663 (0.9469) teacher_loss 0.9240 (0.9371) loss_zs_kd 0.1745 (0.1520) loss_oracle 0.3023 (0.2573) acc 75.0000 (74.6094) kd_loss 0.7231 (0.5974) lr 6.9098e-04 eta 0:15:31
epoch [32/50] batch [220/288] time 0.170 (0.175) data 0.000 (0.001) loss 1.0621 (1.2735) ce_loss 0.7700 (0.9524) teacher_loss 0.7558 (0.9419) loss_zs_kd 0.0976 (0.1512) loss_oracle 0.2575 (0.2560) acc 75.0000 (74.5455) kd_loss 0.6887 (0.5910) lr 6.9098e-04 eta 0:15:20
epoch [32/50] batch [240/288] time 0.166 (0.174) data 0.000 (0.001) loss 1.2683 (1.2654) ce_loss 0.9546 (0.9453) teacher_loss 0.9791 (0.9345) loss_zs_kd 0.1223 (0.1503) loss_oracle 0.2281 (0.2556) acc 78.1250 (74.7917) kd_loss 0.5155 (0.5896) lr 6.9098e-04 eta 0:15:08
epoch [32/50] batch [260/288] time 0.167 (0.172) data 0.000 (0.001) loss 1.3243 (1.2719) ce_loss 0.9790 (0.9514) teacher_loss 0.9806 (0.9413) loss_zs_kd 0.0964 (0.1504) loss_oracle 0.2956 (0.2554) acc 75.0000 (74.6034) kd_loss 0.5628 (0.5883) lr 6.9098e-04 eta 0:14:58
epoch [32/50] batch [280/288] time 0.085 (0.173) data 0.000 (0.001) loss 1.0599 (1.2697) ce_loss 0.7471 (0.9491) teacher_loss 0.7595 (0.9393) loss_zs_kd 0.1303 (0.1505) loss_oracle 0.2352 (0.2552) acc 71.8750 (74.6652) kd_loss 0.4071 (0.5874) lr 6.9098e-04 eta 0:14:58
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,433
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,041
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 80.8%
******* Domain a best val acc:      87.3%, epoch: 31 *******
******* Domain a best val test acc: 84.1%, epoch: 31 *******
******* Domain a best test acc:     84.1%, epoch: 31 *******
epoch [33/50] batch [20/288] time 0.180 (0.189) data 0.000 (0.015) loss 1.2203 (1.3096) ce_loss 1.0283 (0.9950) teacher_loss 1.0282 (0.9859) loss_zs_kd 0.1383 (0.1572) loss_oracle 0.1229 (0.2450) acc 81.2500 (73.5938) kd_loss 0.2812 (0.5683) lr 6.3188e-04 eta 0:16:14
epoch [33/50] batch [40/288] time 0.174 (0.177) data 0.001 (0.008) loss 1.3145 (1.3186) ce_loss 1.0293 (1.0074) teacher_loss 1.0357 (0.9993) loss_zs_kd 0.1236 (0.1511) loss_oracle 0.2170 (0.2438) acc 71.8750 (73.2812) kd_loss 0.5552 (0.5934) lr 6.3188e-04 eta 0:15:10
epoch [33/50] batch [60/288] time 0.153 (0.171) data 0.000 (0.005) loss 1.2690 (1.3019) ce_loss 0.9048 (0.9891) teacher_loss 0.9368 (0.9789) loss_zs_kd 0.1653 (0.1519) loss_oracle 0.2496 (0.2471) acc 68.7500 (73.4375) kd_loss 0.6297 (0.6030) lr 6.3188e-04 eta 0:14:38
epoch [33/50] batch [80/288] time 0.084 (0.180) data 0.000 (0.004) loss 1.0759 (1.2993) ce_loss 0.7832 (0.9862) teacher_loss 0.7569 (0.9759) loss_zs_kd 0.1147 (0.1493) loss_oracle 0.2617 (0.2487) acc 81.2500 (73.7109) kd_loss 0.6348 (0.5990) lr 6.3188e-04 eta 0:15:16
epoch [33/50] batch [100/288] time 0.155 (0.183) data 0.000 (0.003) loss 1.1965 (1.2719) ce_loss 0.8906 (0.9633) teacher_loss 0.9054 (0.9515) loss_zs_kd 0.1217 (0.1515) loss_oracle 0.2303 (0.2446) acc 81.2500 (74.2500) kd_loss 0.5806 (0.5859) lr 6.3188e-04 eta 0:15:28
epoch [33/50] batch [120/288] time 0.182 (0.181) data 0.000 (0.003) loss 1.8786 (1.2680) ce_loss 1.6484 (0.9619) teacher_loss 1.5726 (0.9487) loss_zs_kd 0.1365 (0.1518) loss_oracle 0.2377 (0.2435) acc 59.3750 (74.5833) kd_loss 0.4572 (0.5811) lr 6.3188e-04 eta 0:15:15
epoch [33/50] batch [140/288] time 0.171 (0.178) data 0.000 (0.002) loss 1.3712 (1.2617) ce_loss 1.0449 (0.9575) teacher_loss 1.0503 (0.9438) loss_zs_kd 0.1825 (0.1525) loss_oracle 0.2297 (0.2417) acc 71.8750 (74.6429) kd_loss 0.3969 (0.5772) lr 6.3188e-04 eta 0:14:58
epoch [33/50] batch [160/288] time 0.148 (0.176) data 0.000 (0.002) loss 1.3661 (1.2565) ce_loss 1.0098 (0.9524) teacher_loss 1.0087 (0.9388) loss_zs_kd 0.1943 (0.1524) loss_oracle 0.2603 (0.2414) acc 65.6250 (74.7266) kd_loss 0.6273 (0.5799) lr 6.3188e-04 eta 0:14:43
epoch [33/50] batch [180/288] time 0.151 (0.174) data 0.000 (0.002) loss 1.3961 (1.2555) ce_loss 1.1211 (0.9521) teacher_loss 1.0873 (0.9386) loss_zs_kd 0.1543 (0.1520) loss_oracle 0.2316 (0.2408) acc 68.7500 (74.7222) kd_loss 0.5433 (0.5819) lr 6.3188e-04 eta 0:14:29
epoch [33/50] batch [200/288] time 0.172 (0.172) data 0.000 (0.002) loss 1.2838 (1.2514) ce_loss 0.9673 (0.9484) teacher_loss 0.9783 (0.9346) loss_zs_kd 0.1184 (0.1513) loss_oracle 0.2464 (0.2411) acc 71.8750 (74.7500) kd_loss 0.5220 (0.5824) lr 6.3188e-04 eta 0:14:18
epoch [33/50] batch [220/288] time 0.117 (0.175) data 0.000 (0.002) loss 1.2872 (1.2489) ce_loss 1.0684 (0.9460) teacher_loss 1.0161 (0.9324) loss_zs_kd 0.0704 (0.1514) loss_oracle 0.2359 (0.2408) acc 68.7500 (74.7443) kd_loss 0.5007 (0.5818) lr 6.3188e-04 eta 0:14:26
epoch [33/50] batch [240/288] time 0.155 (0.176) data 0.000 (0.001) loss 0.9049 (1.2394) ce_loss 0.6284 (0.9364) teacher_loss 0.6121 (0.9226) loss_zs_kd 0.1435 (0.1519) loss_oracle 0.2210 (0.2409) acc 81.2500 (74.8828) kd_loss 0.5809 (0.5810) lr 6.3188e-04 eta 0:14:28
epoch [33/50] batch [260/288] time 0.166 (0.175) data 0.000 (0.001) loss 1.1862 (1.2442) ce_loss 0.9375 (0.9420) teacher_loss 0.9249 (0.9282) loss_zs_kd 0.1077 (0.1521) loss_oracle 0.2074 (0.2398) acc 84.3750 (74.7957) kd_loss 0.5012 (0.5766) lr 6.3188e-04 eta 0:14:20
epoch [33/50] batch [280/288] time 0.152 (0.173) data 0.000 (0.001) loss 1.1667 (1.2444) ce_loss 0.8906 (0.9430) teacher_loss 0.8782 (0.9287) loss_zs_kd 0.1291 (0.1527) loss_oracle 0.2239 (0.2393) acc 75.0000 (74.7098) kd_loss 0.4281 (0.5757) lr 6.3188e-04 eta 0:14:10
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,435
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,039
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 80.8%
******* Domain a best val acc:      87.3%, epoch: 31 *******
******* Domain a best val test acc: 84.1%, epoch: 31 *******
******* Domain a best test acc:     84.1%, epoch: 31 *******
epoch [34/50] batch [20/288] time 0.167 (0.169) data 0.000 (0.011) loss 1.4278 (1.1541) ce_loss 1.1699 (0.8499) teacher_loss 1.1238 (0.8388) loss_zs_kd 0.1752 (0.1554) loss_oracle 0.2164 (0.2376) acc 68.7500 (76.4062) kd_loss 0.4732 (0.5706) lr 5.7422e-04 eta 0:13:45
epoch [34/50] batch [40/288] time 0.086 (0.179) data 0.000 (0.006) loss 1.1931 (1.2166) ce_loss 0.8262 (0.9130) teacher_loss 0.9178 (0.9051) loss_zs_kd 0.1066 (0.1533) loss_oracle 0.2219 (0.2348) acc 78.1250 (74.6875) kd_loss 0.6828 (0.5660) lr 5.7422e-04 eta 0:14:28
epoch [34/50] batch [60/288] time 0.173 (0.188) data 0.000 (0.004) loss 1.1027 (1.2184) ce_loss 0.8218 (0.9202) teacher_loss 0.7686 (0.9057) loss_zs_kd 0.0951 (0.1515) loss_oracle 0.2866 (0.2370) acc 71.8750 (74.4271) kd_loss 0.6708 (0.5643) lr 5.7422e-04 eta 0:15:07
epoch [34/50] batch [80/288] time 0.152 (0.180) data 0.000 (0.003) loss 1.1820 (1.2236) ce_loss 0.8677 (0.9241) teacher_loss 0.8647 (0.9106) loss_zs_kd 0.1870 (0.1514) loss_oracle 0.2237 (0.2373) acc 78.1250 (74.9609) kd_loss 0.5036 (0.5604) lr 5.7422e-04 eta 0:14:27
epoch [34/50] batch [100/288] time 0.164 (0.175) data 0.000 (0.002) loss 1.4055 (1.2113) ce_loss 1.0801 (0.9106) teacher_loss 1.0924 (0.8980) loss_zs_kd 0.1804 (0.1496) loss_oracle 0.2229 (0.2385) acc 65.6250 (75.3438) kd_loss 0.5819 (0.5688) lr 5.7422e-04 eta 0:13:59
epoch [34/50] batch [120/288] time 0.169 (0.172) data 0.000 (0.002) loss 1.2686 (1.2237) ce_loss 0.9575 (0.9222) teacher_loss 0.9539 (0.9096) loss_zs_kd 0.1338 (0.1491) loss_oracle 0.2478 (0.2395) acc 71.8750 (74.9740) kd_loss 0.7291 (0.5722) lr 5.7422e-04 eta 0:13:39
epoch [34/50] batch [140/288] time 0.163 (0.169) data 0.000 (0.002) loss 1.3833 (1.2199) ce_loss 1.0459 (0.9191) teacher_loss 0.9950 (0.9060) loss_zs_kd 0.1476 (0.1501) loss_oracle 0.3145 (0.2389) acc 65.6250 (75.3348) kd_loss 0.7590 (0.5709) lr 5.7422e-04 eta 0:13:23
epoch [34/50] batch [160/288] time 0.167 (0.167) data 0.000 (0.002) loss 0.8197 (1.2196) ce_loss 0.5645 (0.9177) teacher_loss 0.5551 (0.9046) loss_zs_kd 0.1648 (0.1516) loss_oracle 0.1822 (0.2392) acc 81.2500 (75.0977) kd_loss 0.2300 (0.5719) lr 5.7422e-04 eta 0:13:10
epoch [34/50] batch [180/288] time 0.135 (0.166) data 0.000 (0.001) loss 1.2356 (1.2270) ce_loss 0.8638 (0.9224) teacher_loss 0.8841 (0.9108) loss_zs_kd 0.1530 (0.1536) loss_oracle 0.2750 (0.2394) acc 75.0000 (74.9479) kd_loss 0.6938 (0.5705) lr 5.7422e-04 eta 0:13:00
epoch [34/50] batch [200/288] time 0.104 (0.166) data 0.000 (0.001) loss 1.8672 (1.2412) ce_loss 1.4297 (0.9355) teacher_loss 1.5054 (0.9231) loss_zs_kd 0.1814 (0.1539) loss_oracle 0.2711 (0.2413) acc 59.3750 (74.5938) kd_loss 0.7544 (0.5746) lr 5.7422e-04 eta 0:13:00
epoch [34/50] batch [220/288] time 0.172 (0.170) data 0.000 (0.001) loss 1.3902 (1.2451) ce_loss 1.0625 (0.9377) teacher_loss 1.0318 (0.9252) loss_zs_kd 0.1294 (0.1544) loss_oracle 0.2937 (0.2427) acc 68.7500 (74.6165) kd_loss 0.6013 (0.5752) lr 5.7422e-04 eta 0:13:14
epoch [34/50] batch [240/288] time 0.167 (0.169) data 0.000 (0.001) loss 1.3213 (1.2527) ce_loss 1.0156 (0.9447) teacher_loss 0.9485 (0.9311) loss_zs_kd 0.1614 (0.1544) loss_oracle 0.2921 (0.2444) acc 68.7500 (74.5052) kd_loss 0.7674 (0.5753) lr 5.7422e-04 eta 0:13:08
epoch [34/50] batch [260/288] time 0.174 (0.170) data 0.000 (0.001) loss 1.1069 (1.2513) ce_loss 0.7603 (0.9416) teacher_loss 0.7504 (0.9286) loss_zs_kd 0.1773 (0.1543) loss_oracle 0.2679 (0.2455) acc 87.5000 (74.7356) kd_loss 0.4932 (0.5760) lr 5.7422e-04 eta 0:13:05
epoch [34/50] batch [280/288] time 0.150 (0.169) data 0.000 (0.001) loss 1.5202 (1.2491) ce_loss 1.1143 (0.9383) teacher_loss 1.0978 (0.9253) loss_zs_kd 0.2113 (0.1537) loss_oracle 0.3168 (0.2469) acc 68.7500 (74.8103) kd_loss 0.7792 (0.5761) lr 5.7422e-04 eta 0:13:00
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,433
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,029
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.3%
******* Domain a best val acc:      87.3%, epoch: 31 *******
******* Domain a best val test acc: 84.1%, epoch: 31 *******
******* Domain a best test acc:     84.1%, epoch: 31 *******
epoch [35/50] batch [20/288] time 0.169 (0.218) data 0.000 (0.015) loss 1.5786 (1.3313) ce_loss 1.2295 (1.0124) teacher_loss 1.2537 (1.0041) loss_zs_kd 0.1803 (0.1592) loss_oracle 0.2348 (0.2476) acc 71.8750 (74.0625) kd_loss 0.4469 (0.5632) lr 5.1825e-04 eta 0:16:38
epoch [35/50] batch [40/288] time 0.147 (0.189) data 0.000 (0.008) loss 1.3781 (1.3599) ce_loss 1.1191 (1.0377) teacher_loss 1.0822 (1.0293) loss_zs_kd 0.1229 (0.1596) loss_oracle 0.2344 (0.2508) acc 68.7500 (72.7344) kd_loss 0.5157 (0.5738) lr 5.1825e-04 eta 0:14:24
epoch [35/50] batch [60/288] time 0.139 (0.180) data 0.000 (0.005) loss 1.7434 (1.3295) ce_loss 1.4814 (1.0085) teacher_loss 1.3643 (0.9973) loss_zs_kd 0.1118 (0.1537) loss_oracle 0.3232 (0.2554) acc 71.8750 (74.1667) kd_loss 0.7204 (0.5879) lr 5.1825e-04 eta 0:13:37
epoch [35/50] batch [80/288] time 0.168 (0.175) data 0.000 (0.004) loss 1.3533 (1.3252) ce_loss 1.0488 (1.0042) teacher_loss 1.0240 (0.9957) loss_zs_kd 0.1660 (0.1515) loss_oracle 0.2463 (0.2537) acc 68.7500 (74.0234) kd_loss 0.5937 (0.5869) lr 5.1825e-04 eta 0:13:10
epoch [35/50] batch [100/288] time 0.172 (0.172) data 0.000 (0.003) loss 1.3529 (1.3152) ce_loss 1.1250 (0.9972) teacher_loss 1.0671 (0.9866) loss_zs_kd 0.1287 (0.1531) loss_oracle 0.2214 (0.2520) acc 71.8750 (74.0625) kd_loss 0.4436 (0.5796) lr 5.1825e-04 eta 0:12:54
epoch [35/50] batch [120/288] time 0.164 (0.170) data 0.000 (0.003) loss 1.1758 (1.3029) ce_loss 0.8486 (0.9842) teacher_loss 0.8410 (0.9739) loss_zs_kd 0.1962 (0.1536) loss_oracle 0.2367 (0.2522) acc 78.1250 (74.3229) kd_loss 0.5083 (0.5797) lr 5.1825e-04 eta 0:12:43
epoch [35/50] batch [140/288] time 0.314 (0.174) data 0.000 (0.002) loss 0.7268 (1.3005) ce_loss 0.5127 (0.9799) teacher_loss 0.5030 (0.9705) loss_zs_kd 0.0786 (0.1534) loss_oracle 0.1845 (0.2534) acc 84.3750 (74.4196) kd_loss 0.5217 (0.5874) lr 5.1825e-04 eta 0:12:56
epoch [35/50] batch [160/288] time 0.170 (0.175) data 0.000 (0.002) loss 1.2015 (1.2958) ce_loss 0.8882 (0.9737) teacher_loss 0.8666 (0.9654) loss_zs_kd 0.1399 (0.1533) loss_oracle 0.2649 (0.2537) acc 71.8750 (74.3555) kd_loss 0.5741 (0.5873) lr 5.1825e-04 eta 0:12:59
epoch [35/50] batch [180/288] time 0.151 (0.173) data 0.000 (0.002) loss 0.8644 (1.2802) ce_loss 0.6479 (0.9573) teacher_loss 0.6095 (0.9490) loss_zs_kd 0.0841 (0.1511) loss_oracle 0.2129 (0.2556) acc 81.2500 (74.7917) kd_loss 0.5151 (0.5943) lr 5.1825e-04 eta 0:12:44
epoch [35/50] batch [200/288] time 0.155 (0.171) data 0.000 (0.002) loss 0.8363 (1.2752) ce_loss 0.5381 (0.9527) teacher_loss 0.5005 (0.9432) loss_zs_kd 0.1512 (0.1514) loss_oracle 0.2602 (0.2563) acc 81.2500 (74.8438) kd_loss 0.5106 (0.5971) lr 5.1825e-04 eta 0:12:33
epoch [35/50] batch [220/288] time 0.143 (0.169) data 0.000 (0.002) loss 0.9318 (1.2693) ce_loss 0.6064 (0.9485) teacher_loss 0.5831 (0.9389) loss_zs_kd 0.1201 (0.1510) loss_oracle 0.2886 (0.2550) acc 87.5000 (74.8864) kd_loss 0.6623 (0.5937) lr 5.1825e-04 eta 0:12:23
epoch [35/50] batch [240/288] time 0.146 (0.168) data 0.000 (0.001) loss 0.7678 (1.2642) ce_loss 0.4373 (0.9427) teacher_loss 0.4323 (0.9327) loss_zs_kd 0.2094 (0.1516) loss_oracle 0.2309 (0.2556) acc 87.5000 (74.9349) kd_loss 0.6922 (0.5930) lr 5.1825e-04 eta 0:12:13
epoch [35/50] batch [260/288] time 0.151 (0.167) data 0.000 (0.001) loss 1.0274 (1.2527) ce_loss 0.7056 (0.9307) teacher_loss 0.7023 (0.9207) loss_zs_kd 0.1314 (0.1517) loss_oracle 0.2594 (0.2562) acc 90.6250 (75.1683) kd_loss 0.5546 (0.5941) lr 5.1825e-04 eta 0:12:05
epoch [35/50] batch [280/288] time 0.152 (0.166) data 0.000 (0.001) loss 1.3192 (1.2560) ce_loss 0.9834 (0.9344) teacher_loss 0.9913 (0.9235) loss_zs_kd 0.1331 (0.1526) loss_oracle 0.2613 (0.2561) acc 75.0000 (74.9777) kd_loss 0.4887 (0.5918) lr 5.1825e-04 eta 0:11:57
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,433
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,034
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 80.3%
******* Domain a best val acc:      87.3%, epoch: 31 *******
******* Domain a best val test acc: 84.1%, epoch: 31 *******
******* Domain a best test acc:     84.1%, epoch: 31 *******
epoch [36/50] batch [20/288] time 0.164 (0.178) data 0.000 (0.017) loss 1.6095 (1.2121) ce_loss 1.3076 (0.8843) teacher_loss 1.3360 (0.8713) loss_zs_kd 0.1218 (0.1526) loss_oracle 0.2126 (0.2645) acc 68.7500 (77.3438) kd_loss 0.6031 (0.6084) lr 4.6417e-04 eta 0:12:47
epoch [36/50] batch [40/288] time 0.150 (0.167) data 0.000 (0.008) loss 1.1486 (1.2592) ce_loss 0.8770 (0.9413) teacher_loss 0.8705 (0.9210) loss_zs_kd 0.1256 (0.1573) loss_oracle 0.2153 (0.2596) acc 78.1250 (76.0156) kd_loss 0.4300 (0.5944) lr 4.6417e-04 eta 0:11:54
epoch [36/50] batch [60/288] time 0.163 (0.164) data 0.000 (0.006) loss 1.1166 (1.2638) ce_loss 0.7251 (0.9431) teacher_loss 0.7281 (0.9290) loss_zs_kd 0.1934 (0.1562) loss_oracle 0.2918 (0.2567) acc 78.1250 (75.5729) kd_loss 0.6137 (0.5803) lr 4.6417e-04 eta 0:11:37
epoch [36/50] batch [80/288] time 0.146 (0.162) data 0.000 (0.004) loss 1.1644 (1.2389) ce_loss 0.8789 (0.9234) teacher_loss 0.8302 (0.9083) loss_zs_kd 0.1360 (0.1531) loss_oracle 0.2662 (0.2540) acc 78.1250 (75.8984) kd_loss 0.5865 (0.5740) lr 4.6417e-04 eta 0:11:28
epoch [36/50] batch [100/288] time 0.145 (0.160) data 0.000 (0.003) loss 1.4394 (1.2156) ce_loss 1.1006 (0.8967) teacher_loss 1.1210 (0.8836) loss_zs_kd 0.1190 (0.1531) loss_oracle 0.2588 (0.2554) acc 71.8750 (76.3438) kd_loss 0.6485 (0.5812) lr 4.6417e-04 eta 0:11:16
epoch [36/50] batch [120/288] time 0.346 (0.159) data 0.000 (0.003) loss 0.9092 (1.2230) ce_loss 0.6421 (0.9068) teacher_loss 0.6173 (0.8923) loss_zs_kd 0.1275 (0.1500) loss_oracle 0.2281 (0.2557) acc 87.5000 (75.9896) kd_loss 0.5153 (0.5814) lr 4.6417e-04 eta 0:11:07
epoch [36/50] batch [140/288] time 0.085 (0.169) data 0.000 (0.003) loss 1.2129 (1.2307) ce_loss 0.9580 (0.9127) teacher_loss 0.9530 (0.9002) loss_zs_kd 0.1477 (0.1504) loss_oracle 0.1860 (0.2554) acc 71.8750 (75.6473) kd_loss 0.4047 (0.5857) lr 4.6417e-04 eta 0:11:46
epoch [36/50] batch [160/288] time 0.148 (0.167) data 0.000 (0.002) loss 1.1004 (1.2254) ce_loss 0.7935 (0.9070) teacher_loss 0.8028 (0.8952) loss_zs_kd 0.1335 (0.1524) loss_oracle 0.2309 (0.2540) acc 81.2500 (75.7227) kd_loss 0.5163 (0.5822) lr 4.6417e-04 eta 0:11:35
epoch [36/50] batch [180/288] time 0.141 (0.166) data 0.000 (0.002) loss 1.4760 (1.2319) ce_loss 1.2051 (0.9125) teacher_loss 1.1602 (0.9017) loss_zs_kd 0.1346 (0.1521) loss_oracle 0.2485 (0.2542) acc 75.0000 (75.6076) kd_loss 0.6344 (0.5833) lr 4.6417e-04 eta 0:11:27
epoch [36/50] batch [200/288] time 0.153 (0.164) data 0.000 (0.002) loss 1.3464 (1.2393) ce_loss 1.0059 (0.9213) teacher_loss 1.0020 (0.9100) loss_zs_kd 0.1597 (0.1527) loss_oracle 0.2646 (0.2530) acc 71.8750 (75.4688) kd_loss 0.5649 (0.5869) lr 4.6417e-04 eta 0:11:17
epoch [36/50] batch [220/288] time 0.160 (0.163) data 0.000 (0.002) loss 1.3674 (1.2360) ce_loss 1.0908 (0.9202) teacher_loss 0.9970 (0.9088) loss_zs_kd 0.1485 (0.1519) loss_oracle 0.2961 (0.2512) acc 71.8750 (75.4403) kd_loss 0.6834 (0.5854) lr 4.6417e-04 eta 0:11:09
epoch [36/50] batch [240/288] time 0.149 (0.162) data 0.000 (0.002) loss 1.1470 (1.2335) ce_loss 0.7681 (0.9186) teacher_loss 0.7905 (0.9067) loss_zs_kd 0.1638 (0.1514) loss_oracle 0.2746 (0.2511) acc 78.1250 (75.5339) kd_loss 0.8103 (0.5864) lr 4.6417e-04 eta 0:11:02
epoch [36/50] batch [260/288] time 0.144 (0.161) data 0.000 (0.001) loss 0.9386 (1.2283) ce_loss 0.6377 (0.9136) teacher_loss 0.6298 (0.9022) loss_zs_kd 0.1507 (0.1507) loss_oracle 0.2335 (0.2508) acc 84.3750 (75.6250) kd_loss 0.6070 (0.5856) lr 4.6417e-04 eta 0:10:55
epoch [36/50] batch [280/288] time 0.326 (0.161) data 0.000 (0.001) loss 1.1191 (1.2335) ce_loss 0.7764 (0.9187) teacher_loss 0.7633 (0.9066) loss_zs_kd 0.1271 (0.1519) loss_oracle 0.2923 (0.2510) acc 84.3750 (75.4353) kd_loss 0.7238 (0.5849) lr 4.6417e-04 eta 0:10:49
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,439
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,032
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 80.3%
******* Domain a best val acc:      87.3%, epoch: 36 *******
******* Domain a best val test acc: 83.7%, epoch: 36 *******
******* Domain a best test acc:     84.1%, epoch: 31 *******
epoch [37/50] batch [20/288] time 0.144 (0.167) data 0.000 (0.012) loss 1.1785 (1.2677) ce_loss 0.8975 (0.9351) teacher_loss 0.8673 (0.9306) loss_zs_kd 0.1341 (0.1648) loss_oracle 0.2442 (0.2547) acc 75.0000 (75.7812) kd_loss 0.5328 (0.5962) lr 4.1221e-04 eta 0:11:09
epoch [37/50] batch [40/288] time 0.183 (0.163) data 0.000 (0.006) loss 1.2625 (1.2971) ce_loss 0.9062 (0.9759) teacher_loss 0.9208 (0.9663) loss_zs_kd 0.1870 (0.1543) loss_oracle 0.2482 (0.2536) acc 78.1250 (74.2188) kd_loss 0.5857 (0.5972) lr 4.1221e-04 eta 0:10:51
epoch [37/50] batch [60/288] time 0.164 (0.160) data 0.000 (0.004) loss 1.1063 (1.2746) ce_loss 0.7832 (0.9570) teacher_loss 0.7400 (0.9478) loss_zs_kd 0.1664 (0.1484) loss_oracle 0.2832 (0.2525) acc 84.3750 (74.5312) kd_loss 0.6551 (0.5918) lr 4.1221e-04 eta 0:10:36
epoch [37/50] batch [80/288] time 0.148 (0.158) data 0.000 (0.003) loss 0.8388 (1.2601) ce_loss 0.6118 (0.9414) teacher_loss 0.5893 (0.9315) loss_zs_kd 0.0991 (0.1508) loss_oracle 0.1999 (0.2532) acc 81.2500 (75.0781) kd_loss 0.4743 (0.5957) lr 4.1221e-04 eta 0:10:25
epoch [37/50] batch [100/288] time 0.099 (0.157) data 0.000 (0.003) loss 1.1104 (1.2394) ce_loss 0.8481 (0.9244) teacher_loss 0.8148 (0.9095) loss_zs_kd 0.1258 (0.1520) loss_oracle 0.2327 (0.2539) acc 81.2500 (75.6875) kd_loss 0.5341 (0.5913) lr 4.1221e-04 eta 0:10:17
epoch [37/50] batch [120/288] time 0.362 (0.165) data 0.000 (0.002) loss 1.4890 (1.2574) ce_loss 1.2734 (0.9395) teacher_loss 1.2115 (0.9263) loss_zs_kd 0.0931 (0.1534) loss_oracle 0.2309 (0.2544) acc 68.7500 (75.0260) kd_loss 0.4858 (0.5939) lr 4.1221e-04 eta 0:10:46
epoch [37/50] batch [140/288] time 0.141 (0.166) data 0.000 (0.002) loss 1.3863 (1.2596) ce_loss 1.0996 (0.9405) teacher_loss 1.0881 (0.9282) loss_zs_kd 0.1196 (0.1543) loss_oracle 0.2384 (0.2543) acc 75.0000 (74.9554) kd_loss 0.6952 (0.5950) lr 4.1221e-04 eta 0:10:47
epoch [37/50] batch [160/288] time 0.144 (0.165) data 0.000 (0.002) loss 1.2189 (1.2533) ce_loss 0.8638 (0.9348) teacher_loss 0.9065 (0.9222) loss_zs_kd 0.1225 (0.1545) loss_oracle 0.2512 (0.2539) acc 78.1250 (75.0977) kd_loss 0.6984 (0.5935) lr 4.1221e-04 eta 0:10:37
epoch [37/50] batch [180/288] time 0.162 (0.163) data 0.000 (0.002) loss 1.2156 (1.2407) ce_loss 0.9111 (0.9242) teacher_loss 0.8660 (0.9114) loss_zs_kd 0.1631 (0.1542) loss_oracle 0.2680 (0.2522) acc 78.1250 (75.3472) kd_loss 0.6280 (0.5908) lr 4.1221e-04 eta 0:10:28
epoch [37/50] batch [200/288] time 0.159 (0.162) data 0.000 (0.001) loss 1.0776 (1.2429) ce_loss 0.7856 (0.9254) teacher_loss 0.7736 (0.9141) loss_zs_kd 0.1411 (0.1543) loss_oracle 0.2335 (0.2516) acc 71.8750 (75.3906) kd_loss 0.4861 (0.5925) lr 4.1221e-04 eta 0:10:22
epoch [37/50] batch [220/288] time 0.170 (0.162) data 0.000 (0.001) loss 1.5220 (1.2458) ce_loss 1.2256 (0.9286) teacher_loss 1.2163 (0.9176) loss_zs_kd 0.1818 (0.1537) loss_oracle 0.2148 (0.2513) acc 68.7500 (75.2699) kd_loss 0.5250 (0.5911) lr 4.1221e-04 eta 0:10:17
epoch [37/50] batch [240/288] time 0.173 (0.162) data 0.001 (0.001) loss 0.9948 (1.2445) ce_loss 0.7021 (0.9288) teacher_loss 0.6782 (0.9174) loss_zs_kd 0.1446 (0.1529) loss_oracle 0.2444 (0.2507) acc 81.2500 (75.2214) kd_loss 0.4619 (0.5912) lr 4.1221e-04 eta 0:10:15
epoch [37/50] batch [260/288] time 0.405 (0.164) data 0.000 (0.001) loss 1.3585 (1.2484) ce_loss 1.0576 (0.9340) teacher_loss 1.0434 (0.9220) loss_zs_kd 0.1765 (0.1527) loss_oracle 0.2269 (0.2501) acc 75.0000 (75.0240) kd_loss 0.5922 (0.5905) lr 4.1221e-04 eta 0:10:20
epoch [37/50] batch [280/288] time 0.149 (0.167) data 0.000 (0.001) loss 0.9897 (1.2452) ce_loss 0.6948 (0.9290) teacher_loss 0.6807 (0.9173) loss_zs_kd 0.1657 (0.1535) loss_oracle 0.2261 (0.2512) acc 87.5000 (75.1674) kd_loss 0.5957 (0.5934) lr 4.1221e-04 eta 0:10:24
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,435
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,040
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 80.6%
******* Domain a best val acc:      87.3%, epoch: 36 *******
******* Domain a best val test acc: 83.7%, epoch: 36 *******
******* Domain a best test acc:     84.1%, epoch: 31 *******
epoch [38/50] batch [20/288] time 0.152 (0.175) data 0.000 (0.012) loss 1.3850 (1.3034) ce_loss 1.1777 (0.9925) teacher_loss 1.1165 (0.9841) loss_zs_kd 0.1165 (0.1573) loss_oracle 0.2103 (0.2407) acc 65.6250 (73.2812) kd_loss 0.5048 (0.5897) lr 3.6258e-04 eta 0:10:49
epoch [38/50] batch [40/288] time 0.156 (0.169) data 0.000 (0.006) loss 0.6672 (1.2242) ce_loss 0.3350 (0.9152) teacher_loss 0.2996 (0.8991) loss_zs_kd 0.2304 (0.1550) loss_oracle 0.2525 (0.2476) acc 90.6250 (75.1562) kd_loss 0.6111 (0.5999) lr 3.6258e-04 eta 0:10:24
epoch [38/50] batch [60/288] time 0.090 (0.166) data 0.000 (0.004) loss 1.0163 (1.2317) ce_loss 0.6895 (0.9197) teacher_loss 0.7220 (0.9057) loss_zs_kd 0.1685 (0.1553) loss_oracle 0.2101 (0.2484) acc 81.2500 (75.2083) kd_loss 0.5151 (0.6031) lr 3.6258e-04 eta 0:10:11
epoch [38/50] batch [80/288] time 0.402 (0.181) data 0.000 (0.003) loss 1.3207 (1.2424) ce_loss 0.9854 (0.9304) teacher_loss 1.0173 (0.9177) loss_zs_kd 0.1148 (0.1544) loss_oracle 0.2460 (0.2475) acc 78.1250 (74.9219) kd_loss 0.5828 (0.6002) lr 3.6258e-04 eta 0:11:04
epoch [38/50] batch [100/288] time 0.148 (0.178) data 0.000 (0.002) loss 1.2926 (1.2606) ce_loss 0.9541 (0.9493) teacher_loss 0.9507 (0.9351) loss_zs_kd 0.1321 (0.1542) loss_oracle 0.2758 (0.2485) acc 84.3750 (74.6875) kd_loss 0.7059 (0.5931) lr 3.6258e-04 eta 0:10:48
epoch [38/50] batch [120/288] time 0.172 (0.175) data 0.000 (0.002) loss 1.6502 (1.2693) ce_loss 1.4053 (0.9593) teacher_loss 1.3370 (0.9449) loss_zs_kd 0.1719 (0.1533) loss_oracle 0.2273 (0.2478) acc 65.6250 (74.1667) kd_loss 0.4389 (0.5953) lr 3.6258e-04 eta 0:10:34
epoch [38/50] batch [140/288] time 0.165 (0.173) data 0.000 (0.002) loss 1.0613 (1.2759) ce_loss 0.8135 (0.9667) teacher_loss 0.7369 (0.9511) loss_zs_kd 0.1484 (0.1552) loss_oracle 0.2502 (0.2471) acc 87.5000 (73.8616) kd_loss 0.5957 (0.5936) lr 3.6258e-04 eta 0:10:24
epoch [38/50] batch [160/288] time 0.172 (0.172) data 0.001 (0.002) loss 0.9158 (1.2843) ce_loss 0.5820 (0.9750) teacher_loss 0.5667 (0.9600) loss_zs_kd 0.1196 (0.1564) loss_oracle 0.2892 (0.2461) acc 84.3750 (73.7500) kd_loss 0.6053 (0.5877) lr 3.6258e-04 eta 0:10:17
epoch [38/50] batch [180/288] time 0.167 (0.171) data 0.000 (0.001) loss 1.3651 (1.2912) ce_loss 1.0254 (0.9804) teacher_loss 0.9897 (0.9660) loss_zs_kd 0.1961 (0.1587) loss_oracle 0.2773 (0.2459) acc 81.2500 (73.7153) kd_loss 0.7656 (0.5864) lr 3.6258e-04 eta 0:10:09
epoch [38/50] batch [200/288] time 0.379 (0.169) data 0.000 (0.001) loss 1.0598 (1.2773) ce_loss 0.7100 (0.9679) teacher_loss 0.6909 (0.9529) loss_zs_kd 0.1158 (0.1578) loss_oracle 0.3110 (0.2456) acc 75.0000 (74.0312) kd_loss 0.6612 (0.5839) lr 3.6258e-04 eta 0:10:00
epoch [38/50] batch [220/288] time 0.081 (0.176) data 0.000 (0.001) loss 0.9477 (1.2739) ce_loss 0.6099 (0.9642) teacher_loss 0.5926 (0.9495) loss_zs_kd 0.1632 (0.1576) loss_oracle 0.2735 (0.2456) acc 81.2500 (74.1193) kd_loss 0.7332 (0.5820) lr 3.6258e-04 eta 0:10:19
epoch [38/50] batch [240/288] time 0.144 (0.173) data 0.000 (0.001) loss 0.8204 (1.2742) ce_loss 0.4917 (0.9639) teacher_loss 0.5188 (0.9499) loss_zs_kd 0.1371 (0.1583) loss_oracle 0.2330 (0.2451) acc 84.3750 (74.2448) kd_loss 0.6887 (0.5817) lr 3.6258e-04 eta 0:10:07
epoch [38/50] batch [260/288] time 0.166 (0.172) data 0.000 (0.001) loss 1.2640 (1.2728) ce_loss 0.9478 (0.9613) teacher_loss 0.9713 (0.9480) loss_zs_kd 0.1108 (0.1577) loss_oracle 0.2373 (0.2459) acc 81.2500 (74.3269) kd_loss 0.6691 (0.5857) lr 3.6258e-04 eta 0:09:58
epoch [38/50] batch [280/288] time 0.167 (0.170) data 0.000 (0.001) loss 0.9192 (1.2664) ce_loss 0.5898 (0.9553) teacher_loss 0.5749 (0.9418) loss_zs_kd 0.1208 (0.1567) loss_oracle 0.2840 (0.2463) acc 87.5000 (74.4196) kd_loss 0.6246 (0.5856) lr 3.6258e-04 eta 0:09:50
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,436
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,033
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 80.3%
******* Domain a best val acc:      87.3%, epoch: 36 *******
******* Domain a best val test acc: 83.7%, epoch: 36 *******
******* Domain a best test acc:     84.1%, epoch: 31 *******
epoch [39/50] batch [20/288] time 0.407 (0.199) data 0.000 (0.015) loss 1.2759 (1.2291) ce_loss 0.9175 (0.9029) teacher_loss 0.9290 (0.8936) loss_zs_kd 0.1312 (0.1470) loss_oracle 0.2813 (0.2620) acc 71.8750 (74.0625) kd_loss 0.6604 (0.6100) lr 3.1545e-04 eta 0:11:23
epoch [39/50] batch [40/288] time 0.152 (0.210) data 0.000 (0.008) loss 1.4310 (1.2509) ce_loss 1.1045 (0.9345) teacher_loss 1.0959 (0.9227) loss_zs_kd 0.1945 (0.1553) loss_oracle 0.2379 (0.2505) acc 65.6250 (74.3750) kd_loss 0.6227 (0.5857) lr 3.1545e-04 eta 0:11:55
epoch [39/50] batch [60/288] time 0.153 (0.194) data 0.000 (0.005) loss 1.1205 (1.2482) ce_loss 0.8364 (0.9295) teacher_loss 0.8103 (0.9187) loss_zs_kd 0.0961 (0.1529) loss_oracle 0.2622 (0.2530) acc 71.8750 (74.3750) kd_loss 0.6186 (0.5864) lr 3.1545e-04 eta 0:10:58
epoch [39/50] batch [80/288] time 0.176 (0.187) data 0.000 (0.004) loss 1.4484 (1.2447) ce_loss 1.2500 (0.9266) teacher_loss 1.1746 (0.9162) loss_zs_kd 0.1351 (0.1540) loss_oracle 0.2062 (0.2515) acc 65.6250 (74.8047) kd_loss 0.4397 (0.5900) lr 3.1545e-04 eta 0:10:32
epoch [39/50] batch [100/288] time 0.174 (0.183) data 0.000 (0.003) loss 1.1936 (1.2482) ce_loss 0.9307 (0.9301) teacher_loss 0.8898 (0.9199) loss_zs_kd 0.1397 (0.1542) loss_oracle 0.2340 (0.2512) acc 71.8750 (74.6250) kd_loss 0.3936 (0.5865) lr 3.1545e-04 eta 0:10:14
epoch [39/50] batch [120/288] time 0.174 (0.181) data 0.001 (0.003) loss 0.9151 (1.2562) ce_loss 0.5981 (0.9371) teacher_loss 0.6212 (0.9283) loss_zs_kd 0.1192 (0.1545) loss_oracle 0.2343 (0.2507) acc 84.3750 (74.6094) kd_loss 0.5839 (0.5862) lr 3.1545e-04 eta 0:10:05
epoch [39/50] batch [140/288] time 0.120 (0.178) data 0.000 (0.002) loss 1.3059 (1.2561) ce_loss 1.0762 (0.9369) teacher_loss 0.9606 (0.9278) loss_zs_kd 0.1861 (0.1575) loss_oracle 0.2523 (0.2496) acc 68.7500 (74.6875) kd_loss 0.5789 (0.5792) lr 3.1545e-04 eta 0:09:48
epoch [39/50] batch [160/288] time 0.081 (0.186) data 0.000 (0.002) loss 1.3651 (1.2491) ce_loss 1.0088 (0.9328) teacher_loss 1.0525 (0.9218) loss_zs_kd 0.1705 (0.1572) loss_oracle 0.2274 (0.2488) acc 75.0000 (74.9219) kd_loss 0.6341 (0.5719) lr 3.1545e-04 eta 0:10:13
epoch [39/50] batch [180/288] time 0.177 (0.182) data 0.000 (0.002) loss 0.9997 (1.2470) ce_loss 0.6997 (0.9297) teacher_loss 0.6911 (0.9183) loss_zs_kd 0.1923 (0.1562) loss_oracle 0.2125 (0.2506) acc 87.5000 (74.9479) kd_loss 0.4623 (0.5745) lr 3.1545e-04 eta 0:09:57
epoch [39/50] batch [200/288] time 0.172 (0.181) data 0.000 (0.002) loss 1.0823 (1.2589) ce_loss 0.7314 (0.9405) teacher_loss 0.7029 (0.9291) loss_zs_kd 0.1806 (0.1563) loss_oracle 0.2891 (0.2517) acc 81.2500 (74.6562) kd_loss 0.8006 (0.5819) lr 3.1545e-04 eta 0:09:50
epoch [39/50] batch [220/288] time 0.174 (0.181) data 0.000 (0.002) loss 1.5177 (1.2553) ce_loss 1.2490 (0.9384) teacher_loss 1.1790 (0.9272) loss_zs_kd 0.1753 (0.1557) loss_oracle 0.2511 (0.2502) acc 75.0000 (74.8438) kd_loss 0.5300 (0.5786) lr 3.1545e-04 eta 0:09:44
epoch [39/50] batch [240/288] time 0.152 (0.180) data 0.000 (0.001) loss 1.1515 (1.2581) ce_loss 0.8022 (0.9408) teacher_loss 0.7961 (0.9299) loss_zs_kd 0.1912 (0.1572) loss_oracle 0.2598 (0.2496) acc 62.5000 (74.5833) kd_loss 0.7944 (0.5791) lr 3.1545e-04 eta 0:09:38
epoch [39/50] batch [260/288] time 0.081 (0.178) data 0.000 (0.001) loss 0.8362 (1.2568) ce_loss 0.5093 (0.9411) teacher_loss 0.5255 (0.9290) loss_zs_kd 0.0993 (0.1557) loss_oracle 0.2610 (0.2499) acc 87.5000 (74.5072) kd_loss 0.6007 (0.5780) lr 3.1545e-04 eta 0:09:28
epoch [39/50] batch [280/288] time 0.135 (0.183) data 0.000 (0.001) loss 1.2505 (1.2554) ce_loss 0.8984 (0.9402) teacher_loss 0.8795 (0.9281) loss_zs_kd 0.1114 (0.1554) loss_oracle 0.3153 (0.2496) acc 78.1250 (74.5201) kd_loss 0.7203 (0.5774) lr 3.1545e-04 eta 0:09:41
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,433
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,030
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 80.2%
******* Domain a best val acc:      87.3%, epoch: 36 *******
******* Domain a best val test acc: 83.7%, epoch: 36 *******
******* Domain a best test acc:     84.1%, epoch: 31 *******
epoch [40/50] batch [20/288] time 0.169 (0.189) data 0.000 (0.017) loss 1.1443 (1.2481) ce_loss 0.8472 (0.9298) teacher_loss 0.8106 (0.9113) loss_zs_kd 0.1337 (0.1465) loss_oracle 0.2668 (0.2636) acc 68.7500 (75.0000) kd_loss 0.7654 (0.6450) lr 2.7103e-04 eta 0:09:56
epoch [40/50] batch [40/288] time 0.167 (0.177) data 0.000 (0.009) loss 1.5342 (1.2754) ce_loss 1.1875 (0.9526) teacher_loss 1.1824 (0.9398) loss_zs_kd 0.2118 (0.1558) loss_oracle 0.2460 (0.2578) acc 68.7500 (74.0625) kd_loss 0.7220 (0.6243) lr 2.7103e-04 eta 0:09:12
epoch [40/50] batch [60/288] time 0.099 (0.171) data 0.000 (0.006) loss 1.1045 (1.2512) ce_loss 0.7690 (0.9288) teacher_loss 0.7497 (0.9189) loss_zs_kd 0.1694 (0.1528) loss_oracle 0.2701 (0.2558) acc 81.2500 (74.8958) kd_loss 0.8099 (0.6159) lr 2.7103e-04 eta 0:08:51
epoch [40/50] batch [80/288] time 0.343 (0.182) data 0.000 (0.004) loss 1.5997 (1.2601) ce_loss 1.2305 (0.9388) teacher_loss 1.2163 (0.9291) loss_zs_kd 0.1725 (0.1551) loss_oracle 0.2972 (0.2535) acc 68.7500 (74.8438) kd_loss 0.6298 (0.6100) lr 2.7103e-04 eta 0:09:23
epoch [40/50] batch [100/288] time 0.154 (0.179) data 0.000 (0.004) loss 1.2149 (1.2667) ce_loss 0.9199 (0.9450) teacher_loss 0.8694 (0.9356) loss_zs_kd 0.1304 (0.1530) loss_oracle 0.2803 (0.2546) acc 75.0000 (74.5312) kd_loss 0.6390 (0.6095) lr 2.7103e-04 eta 0:09:09
epoch [40/50] batch [120/288] time 0.156 (0.176) data 0.000 (0.003) loss 1.2227 (1.2623) ce_loss 0.9375 (0.9429) teacher_loss 0.9002 (0.9334) loss_zs_kd 0.1769 (0.1536) loss_oracle 0.2341 (0.2521) acc 81.2500 (74.6615) kd_loss 0.5680 (0.6004) lr 2.7103e-04 eta 0:08:55
epoch [40/50] batch [140/288] time 0.170 (0.173) data 0.000 (0.003) loss 1.3352 (1.2649) ce_loss 0.9697 (0.9429) teacher_loss 0.9716 (0.9367) loss_zs_kd 0.1274 (0.1532) loss_oracle 0.2999 (0.2516) acc 68.7500 (74.5982) kd_loss 0.7438 (0.6022) lr 2.7103e-04 eta 0:08:44
epoch [40/50] batch [160/288] time 0.144 (0.172) data 0.000 (0.002) loss 1.5890 (1.2636) ce_loss 1.2930 (0.9438) teacher_loss 1.2303 (0.9368) loss_zs_kd 0.1754 (0.1538) loss_oracle 0.2711 (0.2499) acc 75.0000 (74.7070) kd_loss 0.6207 (0.5947) lr 2.7103e-04 eta 0:08:36
epoch [40/50] batch [180/288] time 0.182 (0.171) data 0.000 (0.002) loss 1.0876 (1.2750) ce_loss 0.6836 (0.9546) teacher_loss 0.7464 (0.9473) loss_zs_kd 0.1563 (0.1542) loss_oracle 0.2631 (0.2505) acc 87.5000 (74.5312) kd_loss 0.6433 (0.5959) lr 2.7103e-04 eta 0:08:31
epoch [40/50] batch [200/288] time 0.097 (0.170) data 0.000 (0.002) loss 1.3232 (1.2666) ce_loss 0.9502 (0.9476) teacher_loss 0.9411 (0.9400) loss_zs_kd 0.1900 (0.1536) loss_oracle 0.2872 (0.2498) acc 65.6250 (74.6562) kd_loss 0.5778 (0.5929) lr 2.7103e-04 eta 0:08:25
epoch [40/50] batch [220/288] time 0.362 (0.172) data 0.000 (0.002) loss 0.9981 (1.2669) ce_loss 0.7510 (0.9484) teacher_loss 0.7158 (0.9390) loss_zs_kd 0.0783 (0.1546) loss_oracle 0.2431 (0.2506) acc 81.2500 (74.7159) kd_loss 0.5522 (0.5910) lr 2.7103e-04 eta 0:08:26
epoch [40/50] batch [240/288] time 0.163 (0.174) data 0.000 (0.002) loss 0.9134 (1.2558) ce_loss 0.5645 (0.9390) teacher_loss 0.5771 (0.9287) loss_zs_kd 0.1761 (0.1543) loss_oracle 0.2483 (0.2500) acc 84.3750 (74.9349) kd_loss 0.6427 (0.5878) lr 2.7103e-04 eta 0:08:28
epoch [40/50] batch [260/288] time 0.160 (0.172) data 0.000 (0.002) loss 1.4177 (1.2508) ce_loss 1.1094 (0.9340) teacher_loss 1.0934 (0.9233) loss_zs_kd 0.1847 (0.1555) loss_oracle 0.2319 (0.2498) acc 75.0000 (75.0000) kd_loss 0.6395 (0.5872) lr 2.7103e-04 eta 0:08:20
epoch [40/50] batch [280/288] time 0.141 (0.171) data 0.000 (0.001) loss 1.3999 (1.2486) ce_loss 1.0703 (0.9316) teacher_loss 1.0547 (0.9212) loss_zs_kd 0.2135 (0.1550) loss_oracle 0.2384 (0.2499) acc 78.1250 (75.0446) kd_loss 0.6475 (0.5894) lr 2.7103e-04 eta 0:08:13
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,437
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,036
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 80.5%
******* Domain a best val acc:      87.3%, epoch: 36 *******
******* Domain a best val test acc: 83.7%, epoch: 36 *******
******* Domain a best test acc:     84.1%, epoch: 31 *******
epoch [41/50] batch [20/288] time 0.166 (0.171) data 0.000 (0.015) loss 1.0809 (1.2502) ce_loss 0.6953 (0.9235) teacher_loss 0.7109 (0.9186) loss_zs_kd 0.1807 (0.1727) loss_oracle 0.2797 (0.2452) acc 78.1250 (75.6250) kd_loss 0.6159 (0.6196) lr 2.2949e-04 eta 0:08:07
epoch [41/50] batch [40/288] time 0.086 (0.178) data 0.000 (0.007) loss 1.2108 (1.2491) ce_loss 0.8662 (0.9303) teacher_loss 0.8744 (0.9263) loss_zs_kd 0.1603 (0.1586) loss_oracle 0.2563 (0.2435) acc 78.1250 (75.0781) kd_loss 0.7132 (0.5960) lr 2.2949e-04 eta 0:08:26
epoch [41/50] batch [60/288] time 0.157 (0.184) data 0.000 (0.005) loss 1.4006 (1.2497) ce_loss 1.0996 (0.9418) teacher_loss 1.1201 (0.9298) loss_zs_kd 0.1648 (0.1526) loss_oracle 0.1981 (0.2436) acc 71.8750 (74.6354) kd_loss 0.2831 (0.5834) lr 2.2949e-04 eta 0:08:38
epoch [41/50] batch [80/288] time 0.166 (0.177) data 0.000 (0.004) loss 0.7784 (1.2560) ce_loss 0.5137 (0.9460) teacher_loss 0.4928 (0.9321) loss_zs_kd 0.1218 (0.1504) loss_oracle 0.2248 (0.2487) acc 78.1250 (74.9219) kd_loss 0.4995 (0.5901) lr 2.2949e-04 eta 0:08:15
epoch [41/50] batch [100/288] time 0.154 (0.174) data 0.000 (0.003) loss 1.7411 (1.2606) ce_loss 1.4238 (0.9506) teacher_loss 1.3790 (0.9353) loss_zs_kd 0.1857 (0.1539) loss_oracle 0.2693 (0.2484) acc 59.3750 (74.4688) kd_loss 0.8107 (0.5888) lr 2.2949e-04 eta 0:08:03
epoch [41/50] batch [120/288] time 0.164 (0.171) data 0.000 (0.003) loss 1.5485 (1.2620) ce_loss 1.2451 (0.9502) teacher_loss 1.2188 (0.9346) loss_zs_kd 0.2062 (0.1541) loss_oracle 0.2266 (0.2503) acc 65.6250 (74.4792) kd_loss 0.4992 (0.5905) lr 2.2949e-04 eta 0:07:52
epoch [41/50] batch [140/288] time 0.157 (0.169) data 0.000 (0.002) loss 1.4137 (1.2559) ce_loss 1.1719 (0.9448) teacher_loss 1.1327 (0.9286) loss_zs_kd 0.1223 (0.1539) loss_oracle 0.2198 (0.2505) acc 68.7500 (74.7098) kd_loss 0.4481 (0.5923) lr 2.2949e-04 eta 0:07:42
epoch [41/50] batch [160/288] time 0.148 (0.167) data 0.000 (0.002) loss 0.9249 (1.2456) ce_loss 0.6396 (0.9351) teacher_loss 0.6262 (0.9186) loss_zs_kd 0.0986 (0.1531) loss_oracle 0.2493 (0.2505) acc 84.3750 (74.8438) kd_loss 0.7432 (0.5925) lr 2.2949e-04 eta 0:07:32
epoch [41/50] batch [180/288] time 0.091 (0.164) data 0.000 (0.002) loss 1.9870 (1.2449) ce_loss 1.6045 (0.9338) teacher_loss 1.5996 (0.9170) loss_zs_kd 0.2585 (0.1540) loss_oracle 0.2582 (0.2509) acc 62.5000 (75.0521) kd_loss 0.6340 (0.5932) lr 2.2949e-04 eta 0:07:23
epoch [41/50] batch [200/288] time 0.342 (0.170) data 0.000 (0.002) loss 1.3667 (1.2479) ce_loss 0.9927 (0.9360) teacher_loss 1.0010 (0.9199) loss_zs_kd 0.1610 (0.1545) loss_oracle 0.2852 (0.2507) acc 62.5000 (75.0781) kd_loss 0.6590 (0.5944) lr 2.2949e-04 eta 0:07:34
epoch [41/50] batch [220/288] time 0.150 (0.169) data 0.000 (0.001) loss 1.2751 (1.2480) ce_loss 0.9121 (0.9347) teacher_loss 0.9579 (0.9202) loss_zs_kd 0.1919 (0.1559) loss_oracle 0.2212 (0.2498) acc 78.1250 (75.1705) kd_loss 0.5247 (0.5939) lr 2.2949e-04 eta 0:07:30
epoch [41/50] batch [240/288] time 0.170 (0.168) data 0.000 (0.001) loss 1.1841 (1.2444) ce_loss 0.8735 (0.9328) teacher_loss 0.8273 (0.9188) loss_zs_kd 0.1959 (0.1546) loss_oracle 0.2588 (0.2483) acc 81.2500 (75.1953) kd_loss 0.5923 (0.5914) lr 2.2949e-04 eta 0:07:23
epoch [41/50] batch [260/288] time 0.144 (0.167) data 0.000 (0.001) loss 1.8668 (1.2465) ce_loss 1.5195 (0.9344) teacher_loss 1.5376 (0.9202) loss_zs_kd 0.1830 (0.1550) loss_oracle 0.2377 (0.2487) acc 68.7500 (75.0721) kd_loss 0.5291 (0.5924) lr 2.2949e-04 eta 0:07:18
epoch [41/50] batch [280/288] time 0.145 (0.166) data 0.000 (0.001) loss 1.0013 (1.2473) ce_loss 0.6958 (0.9348) teacher_loss 0.6913 (0.9214) loss_zs_kd 0.1574 (0.1547) loss_oracle 0.2312 (0.2485) acc 81.2500 (75.0000) kd_loss 0.6642 (0.5909) lr 2.2949e-04 eta 0:07:12
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,440
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,040
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 80.7%
******* Domain a best val acc:      87.3%, epoch: 41 *******
******* Domain a best val test acc: 84.1%, epoch: 41 *******
******* Domain a best test acc:     84.1%, epoch: 31 *******
epoch [42/50] batch [20/288] time 0.084 (0.185) data 0.000 (0.012) loss 1.0815 (1.2117) ce_loss 0.7876 (0.9089) teacher_loss 0.7424 (0.8947) loss_zs_kd 0.1319 (0.1433) loss_oracle 0.2732 (0.2453) acc 81.2500 (76.8750) kd_loss 0.5276 (0.5524) lr 1.9098e-04 eta 0:07:56
epoch [42/50] batch [40/288] time 0.172 (0.197) data 0.000 (0.006) loss 1.2043 (1.2346) ce_loss 0.9282 (0.9351) teacher_loss 0.8623 (0.9163) loss_zs_kd 0.1501 (0.1474) loss_oracle 0.2669 (0.2446) acc 75.0000 (76.0156) kd_loss 0.5967 (0.5567) lr 1.9098e-04 eta 0:08:22
epoch [42/50] batch [60/288] time 0.178 (0.187) data 0.000 (0.004) loss 1.6626 (1.2683) ce_loss 1.2920 (0.9582) teacher_loss 1.3315 (0.9426) loss_zs_kd 0.1381 (0.1557) loss_oracle 0.2621 (0.2478) acc 71.8750 (75.2604) kd_loss 0.5676 (0.5695) lr 1.9098e-04 eta 0:07:52
epoch [42/50] batch [80/288] time 0.145 (0.180) data 0.000 (0.003) loss 1.0901 (1.2556) ce_loss 0.7568 (0.9408) teacher_loss 0.7639 (0.9285) loss_zs_kd 0.1542 (0.1559) loss_oracle 0.2491 (0.2492) acc 81.2500 (75.1562) kd_loss 0.5935 (0.5889) lr 1.9098e-04 eta 0:07:32
epoch [42/50] batch [100/288] time 0.167 (0.177) data 0.000 (0.003) loss 1.2430 (1.2678) ce_loss 0.9238 (0.9535) teacher_loss 0.9013 (0.9401) loss_zs_kd 0.1710 (0.1575) loss_oracle 0.2562 (0.2490) acc 75.0000 (74.6562) kd_loss 0.6511 (0.5828) lr 1.9098e-04 eta 0:07:20
epoch [42/50] batch [120/288] time 0.152 (0.175) data 0.000 (0.002) loss 1.0058 (1.2408) ce_loss 0.6597 (0.9269) teacher_loss 0.6115 (0.9143) loss_zs_kd 0.1777 (0.1543) loss_oracle 0.3054 (0.2493) acc 75.0000 (75.2604) kd_loss 0.6867 (0.5866) lr 1.9098e-04 eta 0:07:13
epoch [42/50] batch [140/288] time 0.098 (0.173) data 0.000 (0.002) loss 1.3968 (1.2378) ce_loss 1.0498 (0.9231) teacher_loss 1.0875 (0.9108) loss_zs_kd 0.1569 (0.1561) loss_oracle 0.2309 (0.2490) acc 62.5000 (75.3348) kd_loss 0.6580 (0.5844) lr 1.9098e-04 eta 0:07:04
epoch [42/50] batch [160/288] time 0.380 (0.182) data 0.000 (0.002) loss 1.4187 (1.2420) ce_loss 1.0889 (0.9273) teacher_loss 1.0419 (0.9141) loss_zs_kd 0.2057 (0.1579) loss_oracle 0.2740 (0.2490) acc 71.8750 (75.1758) kd_loss 0.5472 (0.5867) lr 1.9098e-04 eta 0:07:23
epoch [42/50] batch [180/288] time 0.175 (0.180) data 0.000 (0.002) loss 1.3467 (1.2387) ce_loss 1.0205 (0.9245) teacher_loss 1.0211 (0.9104) loss_zs_kd 0.2191 (0.1581) loss_oracle 0.2160 (0.2492) acc 75.0000 (75.2257) kd_loss 0.5091 (0.5853) lr 1.9098e-04 eta 0:07:14
epoch [42/50] batch [200/288] time 0.167 (0.179) data 0.000 (0.001) loss 1.2791 (1.2400) ce_loss 0.9395 (0.9259) teacher_loss 0.9295 (0.9112) loss_zs_kd 0.1188 (0.1580) loss_oracle 0.2901 (0.2498) acc 75.0000 (75.3594) kd_loss 0.8644 (0.5865) lr 1.9098e-04 eta 0:07:06
epoch [42/50] batch [220/288] time 0.177 (0.177) data 0.000 (0.001) loss 1.1731 (1.2436) ce_loss 0.9209 (0.9298) teacher_loss 0.9151 (0.9157) loss_zs_kd 0.1364 (0.1576) loss_oracle 0.1898 (0.2491) acc 78.1250 (75.2415) kd_loss 0.2834 (0.5846) lr 1.9098e-04 eta 0:07:00
epoch [42/50] batch [240/288] time 0.144 (0.176) data 0.000 (0.001) loss 1.3185 (1.2421) ce_loss 0.9707 (0.9287) teacher_loss 0.9832 (0.9145) loss_zs_kd 0.1661 (0.1569) loss_oracle 0.2522 (0.2491) acc 75.0000 (75.3255) kd_loss 0.5388 (0.5845) lr 1.9098e-04 eta 0:06:54
epoch [42/50] batch [260/288] time 0.167 (0.175) data 0.001 (0.001) loss 1.5144 (1.2476) ce_loss 1.1641 (0.9336) teacher_loss 1.1191 (0.9189) loss_zs_kd 0.1684 (0.1570) loss_oracle 0.3111 (0.2502) acc 71.8750 (75.1082) kd_loss 0.7681 (0.5864) lr 1.9098e-04 eta 0:06:47
epoch [42/50] batch [280/288] time 0.162 (0.173) data 0.000 (0.001) loss 1.2025 (1.2425) ce_loss 0.8301 (0.9284) teacher_loss 0.8570 (0.9148) loss_zs_kd 0.1264 (0.1562) loss_oracle 0.2823 (0.2496) acc 75.0000 (75.3125) kd_loss 0.7662 (0.5863) lr 1.9098e-04 eta 0:06:39
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,438
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,042
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 80.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      87.3%, epoch: 41 *******
******* Domain a best val test acc: 84.1%, epoch: 41 *******
******* Domain a best test acc:     84.1%, epoch: 42 *******
epoch [43/50] batch [20/288] time 0.149 (0.168) data 0.000 (0.013) loss 1.5264 (1.3122) ce_loss 1.2764 (1.0080) teacher_loss 1.1842 (0.9888) loss_zs_kd 0.1487 (0.1556) loss_oracle 0.2679 (0.2455) acc 68.7500 (71.8750) kd_loss 0.7037 (0.6288) lr 1.5567e-04 eta 0:06:23
epoch [43/50] batch [40/288] time 0.165 (0.162) data 0.000 (0.007) loss 1.3358 (1.2840) ce_loss 1.0352 (0.9773) teacher_loss 1.0332 (0.9612) loss_zs_kd 0.1459 (0.1585) loss_oracle 0.2297 (0.2437) acc 71.8750 (73.2812) kd_loss 0.5805 (0.5827) lr 1.5567e-04 eta 0:06:06
epoch [43/50] batch [60/288] time 0.138 (0.159) data 0.000 (0.005) loss 2.0031 (1.3046) ce_loss 1.6865 (0.9911) teacher_loss 1.6582 (0.9743) loss_zs_kd 0.1804 (0.1632) loss_oracle 0.2546 (0.2488) acc 56.2500 (72.7083) kd_loss 0.7033 (0.5842) lr 1.5567e-04 eta 0:05:56
epoch [43/50] batch [80/288] time 0.160 (0.157) data 0.000 (0.004) loss 0.8089 (1.2579) ce_loss 0.5454 (0.9448) teacher_loss 0.5333 (0.9313) loss_zs_kd 0.0695 (0.1546) loss_oracle 0.2408 (0.2493) acc 87.5000 (74.1406) kd_loss 0.5608 (0.5967) lr 1.5567e-04 eta 0:05:49
epoch [43/50] batch [100/288] time 0.147 (0.156) data 0.000 (0.003) loss 1.5171 (1.2635) ce_loss 1.2549 (0.9497) teacher_loss 1.2721 (0.9386) loss_zs_kd 0.1840 (0.1531) loss_oracle 0.1529 (0.2484) acc 68.7500 (73.7188) kd_loss 0.2937 (0.5935) lr 1.5567e-04 eta 0:05:44
epoch [43/50] batch [120/288] time 0.092 (0.154) data 0.000 (0.002) loss 1.0025 (1.2587) ce_loss 0.7188 (0.9437) teacher_loss 0.7005 (0.9325) loss_zs_kd 0.1338 (0.1560) loss_oracle 0.2351 (0.2482) acc 75.0000 (74.0885) kd_loss 0.6384 (0.5908) lr 1.5567e-04 eta 0:05:35
epoch [43/50] batch [140/288] time 0.352 (0.167) data 0.000 (0.002) loss 0.9792 (1.2561) ce_loss 0.6841 (0.9431) teacher_loss 0.6511 (0.9307) loss_zs_kd 0.1689 (0.1563) loss_oracle 0.2437 (0.2472) acc 87.5000 (74.3080) kd_loss 0.4900 (0.5841) lr 1.5567e-04 eta 0:06:01
epoch [43/50] batch [160/288] time 0.175 (0.165) data 0.000 (0.002) loss 1.1727 (1.2512) ce_loss 0.8481 (0.9374) teacher_loss 0.8535 (0.9235) loss_zs_kd 0.1480 (0.1571) loss_oracle 0.2452 (0.2491) acc 75.0000 (74.3359) kd_loss 0.5315 (0.5838) lr 1.5567e-04 eta 0:05:53
epoch [43/50] batch [180/288] time 0.172 (0.165) data 0.000 (0.002) loss 0.9744 (1.2423) ce_loss 0.7290 (0.9285) teacher_loss 0.6949 (0.9152) loss_zs_kd 0.1214 (0.1557) loss_oracle 0.2188 (0.2492) acc 78.1250 (74.5486) kd_loss 0.4186 (0.5836) lr 1.5567e-04 eta 0:05:49
epoch [43/50] batch [200/288] time 0.178 (0.165) data 0.000 (0.002) loss 1.1783 (1.2443) ce_loss 0.8711 (0.9311) teacher_loss 0.8595 (0.9179) loss_zs_kd 0.1793 (0.1560) loss_oracle 0.2291 (0.2484) acc 81.2500 (74.5625) kd_loss 0.3703 (0.5792) lr 1.5567e-04 eta 0:05:47
epoch [43/50] batch [220/288] time 0.167 (0.165) data 0.000 (0.001) loss 1.1263 (1.2442) ce_loss 0.8682 (0.9318) teacher_loss 0.8529 (0.9181) loss_zs_kd 0.1892 (0.1561) loss_oracle 0.1787 (0.2481) acc 68.7500 (74.6307) kd_loss 0.4582 (0.5786) lr 1.5567e-04 eta 0:05:43
epoch [43/50] batch [240/288] time 0.152 (0.165) data 0.000 (0.001) loss 1.3001 (1.2404) ce_loss 0.9541 (0.9275) teacher_loss 0.9571 (0.9138) loss_zs_kd 0.2357 (0.1561) loss_oracle 0.2252 (0.2486) acc 68.7500 (74.6745) kd_loss 0.4536 (0.5785) lr 1.5567e-04 eta 0:05:40
epoch [43/50] batch [260/288] time 0.089 (0.167) data 0.000 (0.001) loss 1.1108 (1.2395) ce_loss 0.7583 (0.9276) teacher_loss 0.7873 (0.9132) loss_zs_kd 0.1630 (0.1566) loss_oracle 0.2421 (0.2480) acc 81.2500 (74.6995) kd_loss 0.6504 (0.5759) lr 1.5567e-04 eta 0:05:41
epoch [43/50] batch [280/288] time 0.086 (0.167) data 0.000 (0.001) loss 1.2428 (1.2391) ce_loss 0.9482 (0.9274) teacher_loss 0.9204 (0.9125) loss_zs_kd 0.1535 (0.1567) loss_oracle 0.2457 (0.2483) acc 78.1250 (74.7991) kd_loss 0.7397 (0.5774) lr 1.5567e-04 eta 0:05:38
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,440
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,037
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 80.5%
******* Domain a best val acc:      87.3%, epoch: 41 *******
******* Domain a best val test acc: 84.1%, epoch: 41 *******
******* Domain a best test acc:     84.1%, epoch: 42 *******
epoch [44/50] batch [20/288] time 0.157 (0.168) data 0.000 (0.017) loss 1.3893 (1.2247) ce_loss 1.0967 (0.9241) teacher_loss 1.0904 (0.8948) loss_zs_kd 0.1352 (0.1576) loss_oracle 0.2313 (0.2510) acc 68.7500 (73.9062) kd_loss 0.4598 (0.5639) lr 1.2369e-04 eta 0:05:34
epoch [44/50] batch [40/288] time 0.145 (0.162) data 0.000 (0.008) loss 1.0592 (1.2686) ce_loss 0.7192 (0.9602) teacher_loss 0.7161 (0.9373) loss_zs_kd 0.1592 (0.1559) loss_oracle 0.2636 (0.2533) acc 81.2500 (73.6719) kd_loss 0.6094 (0.5783) lr 1.2369e-04 eta 0:05:19
epoch [44/50] batch [60/288] time 0.168 (0.163) data 0.000 (0.006) loss 0.9906 (1.2551) ce_loss 0.7412 (0.9434) teacher_loss 0.7433 (0.9234) loss_zs_kd 0.1019 (0.1610) loss_oracle 0.1963 (0.2512) acc 84.3750 (74.0625) kd_loss 0.6306 (0.5754) lr 1.2369e-04 eta 0:05:18
epoch [44/50] batch [80/288] time 0.164 (0.162) data 0.000 (0.004) loss 1.4431 (1.2534) ce_loss 1.1016 (0.9411) teacher_loss 1.0886 (0.9245) loss_zs_kd 0.2021 (0.1597) loss_oracle 0.2535 (0.2491) acc 71.8750 (74.0234) kd_loss 0.6538 (0.5744) lr 1.2369e-04 eta 0:05:12
epoch [44/50] batch [100/288] time 0.167 (0.161) data 0.000 (0.003) loss 1.3703 (1.2463) ce_loss 1.0469 (0.9337) teacher_loss 1.0355 (0.9203) loss_zs_kd 0.1348 (0.1587) loss_oracle 0.2674 (0.2467) acc 75.0000 (74.4688) kd_loss 0.6271 (0.5746) lr 1.2369e-04 eta 0:05:08
epoch [44/50] batch [120/288] time 0.390 (0.159) data 0.000 (0.003) loss 1.3088 (1.2378) ce_loss 0.9590 (0.9239) teacher_loss 0.9533 (0.9105) loss_zs_kd 0.2146 (0.1581) loss_oracle 0.2482 (0.2483) acc 71.8750 (74.9740) kd_loss 0.6681 (0.5775) lr 1.2369e-04 eta 0:05:01
epoch [44/50] batch [140/288] time 0.356 (0.169) data 0.000 (0.003) loss 1.1884 (1.2386) ce_loss 0.8525 (0.9257) teacher_loss 0.8444 (0.9118) loss_zs_kd 0.1873 (0.1580) loss_oracle 0.2504 (0.2477) acc 78.1250 (75.1116) kd_loss 0.7208 (0.5820) lr 1.2369e-04 eta 0:05:17
epoch [44/50] batch [160/288] time 0.143 (0.163) data 0.000 (0.002) loss 1.4090 (1.2416) ce_loss 1.0771 (0.9303) teacher_loss 1.0556 (0.9157) loss_zs_kd 0.1539 (0.1581) loss_oracle 0.2765 (0.2469) acc 68.7500 (75.0391) kd_loss 0.6220 (0.5794) lr 1.2369e-04 eta 0:05:03
epoch [44/50] batch [180/288] time 0.146 (0.162) data 0.000 (0.002) loss 1.1212 (1.2493) ce_loss 0.8047 (0.9379) teacher_loss 0.8009 (0.9218) loss_zs_kd 0.1295 (0.1580) loss_oracle 0.2555 (0.2484) acc 78.1250 (74.8785) kd_loss 0.7646 (0.5812) lr 1.2369e-04 eta 0:04:58
epoch [44/50] batch [200/288] time 0.166 (0.161) data 0.000 (0.002) loss 1.0598 (1.2514) ce_loss 0.7925 (0.9391) teacher_loss 0.7807 (0.9219) loss_zs_kd 0.1459 (0.1597) loss_oracle 0.2062 (0.2497) acc 81.2500 (74.7812) kd_loss 0.5009 (0.5852) lr 1.2369e-04 eta 0:04:53
epoch [44/50] batch [220/288] time 0.161 (0.160) data 0.000 (0.002) loss 1.1898 (1.2542) ce_loss 0.8730 (0.9426) teacher_loss 0.8290 (0.9253) loss_zs_kd 0.1571 (0.1590) loss_oracle 0.2822 (0.2493) acc 78.1250 (74.7869) kd_loss 0.7246 (0.5857) lr 1.2369e-04 eta 0:04:48
epoch [44/50] batch [240/288] time 0.143 (0.160) data 0.000 (0.002) loss 1.2752 (1.2671) ce_loss 0.9224 (0.9549) teacher_loss 0.9346 (0.9385) loss_zs_kd 0.1567 (0.1586) loss_oracle 0.2622 (0.2494) acc 75.0000 (74.4792) kd_loss 0.6027 (0.5848) lr 1.2369e-04 eta 0:04:44
epoch [44/50] batch [260/288] time 0.161 (0.160) data 0.000 (0.001) loss 1.6877 (1.2639) ce_loss 1.3838 (0.9516) teacher_loss 1.3407 (0.9353) loss_zs_kd 0.1237 (0.1577) loss_oracle 0.2852 (0.2497) acc 68.7500 (74.4952) kd_loss 0.6596 (0.5845) lr 1.2369e-04 eta 0:04:40
epoch [44/50] batch [280/288] time 0.082 (0.161) data 0.000 (0.001) loss 1.5082 (1.2627) ce_loss 1.2207 (0.9510) teacher_loss 1.2106 (0.9346) loss_zs_kd 0.1227 (0.1582) loss_oracle 0.2362 (0.2490) acc 65.6250 (74.4308) kd_loss 0.4749 (0.5816) lr 1.2369e-04 eta 0:04:39
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,443
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 86.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,041
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 80.8%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 84.1%, epoch: 44 *******
******* Domain a best test acc:     84.1%, epoch: 42 *******
epoch [45/50] batch [20/288] time 0.163 (0.173) data 0.000 (0.015) loss 1.5124 (1.2680) ce_loss 1.2061 (0.9475) teacher_loss 1.1969 (0.9326) loss_zs_kd 0.1137 (0.1607) loss_oracle 0.2587 (0.2551) acc 62.5000 (74.8438) kd_loss 0.6832 (0.5946) lr 9.5173e-05 eta 0:04:54
epoch [45/50] batch [40/288] time 0.159 (0.168) data 0.000 (0.008) loss 0.9721 (1.2125) ce_loss 0.7144 (0.8918) teacher_loss 0.6832 (0.8779) loss_zs_kd 0.0808 (0.1572) loss_oracle 0.2484 (0.2560) acc 71.8750 (75.7031) kd_loss 0.5482 (0.5985) lr 9.5173e-05 eta 0:04:44
epoch [45/50] batch [60/288] time 0.166 (0.170) data 0.001 (0.005) loss 0.8153 (1.2078) ce_loss 0.5088 (0.8950) teacher_loss 0.5044 (0.8775) loss_zs_kd 0.1427 (0.1528) loss_oracle 0.2396 (0.2539) acc 87.5000 (76.1979) kd_loss 0.6541 (0.5827) lr 9.5173e-05 eta 0:04:43
epoch [45/50] batch [80/288] time 0.115 (0.170) data 0.000 (0.004) loss 0.8419 (1.2138) ce_loss 0.5835 (0.9067) teacher_loss 0.5902 (0.8887) loss_zs_kd 0.1254 (0.1509) loss_oracle 0.1890 (0.2497) acc 84.3750 (75.6250) kd_loss 0.3378 (0.5674) lr 9.5173e-05 eta 0:04:40
epoch [45/50] batch [100/288] time 0.105 (0.171) data 0.000 (0.003) loss 1.7791 (1.2095) ce_loss 1.4365 (0.9012) teacher_loss 1.3998 (0.8847) loss_zs_kd 0.1369 (0.1506) loss_oracle 0.3109 (0.2495) acc 62.5000 (75.7188) kd_loss 0.7342 (0.5685) lr 9.5173e-05 eta 0:04:37
epoch [45/50] batch [120/288] time 0.151 (0.179) data 0.000 (0.003) loss 1.1063 (1.2200) ce_loss 0.8130 (0.9090) teacher_loss 0.7951 (0.8931) loss_zs_kd 0.1368 (0.1527) loss_oracle 0.2428 (0.2505) acc 78.1250 (75.5208) kd_loss 0.5801 (0.5747) lr 9.5173e-05 eta 0:04:47
epoch [45/50] batch [140/288] time 0.161 (0.175) data 0.001 (0.002) loss 0.6779 (1.2242) ce_loss 0.3303 (0.9119) teacher_loss 0.3566 (0.8973) loss_zs_kd 0.1291 (0.1524) loss_oracle 0.2568 (0.2507) acc 90.6250 (75.6027) kd_loss 0.7280 (0.5773) lr 9.5173e-05 eta 0:04:38
epoch [45/50] batch [160/288] time 0.146 (0.174) data 0.000 (0.002) loss 1.2313 (1.2287) ce_loss 0.9390 (0.9162) teacher_loss 0.8540 (0.9018) loss_zs_kd 0.1809 (0.1544) loss_oracle 0.2869 (0.2497) acc 71.8750 (75.2734) kd_loss 0.5416 (0.5766) lr 9.5173e-05 eta 0:04:32
epoch [45/50] batch [180/288] time 0.164 (0.172) data 0.000 (0.002) loss 1.4412 (1.2335) ce_loss 1.1436 (0.9219) teacher_loss 1.0755 (0.9059) loss_zs_kd 0.2122 (0.1550) loss_oracle 0.2595 (0.2501) acc 62.5000 (74.9653) kd_loss 0.5522 (0.5740) lr 9.5173e-05 eta 0:04:26
epoch [45/50] batch [200/288] time 0.143 (0.171) data 0.000 (0.002) loss 0.9196 (1.2368) ce_loss 0.5854 (0.9251) teacher_loss 0.5922 (0.9089) loss_zs_kd 0.1224 (0.1555) loss_oracle 0.2662 (0.2502) acc 90.6250 (75.1094) kd_loss 0.6450 (0.5747) lr 9.5173e-05 eta 0:04:21
epoch [45/50] batch [220/288] time 0.106 (0.169) data 0.000 (0.002) loss 1.1444 (1.2324) ce_loss 0.7441 (0.9204) teacher_loss 0.7725 (0.9040) loss_zs_kd 0.2240 (0.1556) loss_oracle 0.2599 (0.2506) acc 84.3750 (75.2131) kd_loss 0.5645 (0.5758) lr 9.5173e-05 eta 0:04:15
epoch [45/50] batch [240/288] time 0.362 (0.173) data 0.000 (0.002) loss 1.1597 (1.2238) ce_loss 0.9092 (0.9121) teacher_loss 0.9161 (0.8958) loss_zs_kd 0.1358 (0.1552) loss_oracle 0.1757 (0.2503) acc 71.8750 (75.4557) kd_loss 0.5367 (0.5785) lr 9.5173e-05 eta 0:04:17
epoch [45/50] batch [260/288] time 0.178 (0.174) data 0.000 (0.001) loss 1.5216 (1.2237) ce_loss 1.2207 (0.9113) teacher_loss 1.1779 (0.8952) loss_zs_kd 0.2385 (0.1562) loss_oracle 0.2244 (0.2503) acc 68.7500 (75.5288) kd_loss 0.3680 (0.5778) lr 9.5173e-05 eta 0:04:14
epoch [45/50] batch [280/288] time 0.146 (0.173) data 0.000 (0.001) loss 1.2637 (1.2341) ce_loss 0.9722 (0.9204) teacher_loss 0.9590 (0.9049) loss_zs_kd 0.1716 (0.1571) loss_oracle 0.2189 (0.2506) acc 81.2500 (75.4353) kd_loss 0.5313 (0.5795) lr 9.5173e-05 eta 0:04:10
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,437
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,038
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 80.5%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 84.1%, epoch: 44 *******
******* Domain a best test acc:     84.1%, epoch: 42 *******
epoch [46/50] batch [20/288] time 0.102 (0.183) data 0.000 (0.021) loss 1.0658 (1.2326) ce_loss 0.7334 (0.9141) teacher_loss 0.7553 (0.9084) loss_zs_kd 0.1467 (0.1533) loss_oracle 0.2371 (0.2476) acc 78.1250 (75.9375) kd_loss 0.5569 (0.5806) lr 7.0224e-05 eta 0:04:19
epoch [46/50] batch [40/288] time 0.438 (0.223) data 0.000 (0.011) loss 1.3205 (1.2721) ce_loss 1.0400 (0.9539) teacher_loss 0.9981 (0.9415) loss_zs_kd 0.1724 (0.1582) loss_oracle 0.2362 (0.2515) acc 71.8750 (75.2344) kd_loss 0.4705 (0.5917) lr 7.0224e-05 eta 0:05:12
epoch [46/50] batch [60/288] time 0.175 (0.199) data 0.000 (0.007) loss 1.1814 (1.2815) ce_loss 0.8545 (0.9604) teacher_loss 0.8342 (0.9479) loss_zs_kd 0.1580 (0.1633) loss_oracle 0.2682 (0.2520) acc 75.0000 (74.5312) kd_loss 0.7061 (0.5904) lr 7.0224e-05 eta 0:04:34
epoch [46/50] batch [80/288] time 0.178 (0.193) data 0.000 (0.006) loss 1.0694 (1.2546) ce_loss 0.7505 (0.9349) teacher_loss 0.7488 (0.9222) loss_zs_kd 0.1272 (0.1594) loss_oracle 0.2571 (0.2527) acc 81.2500 (75.1953) kd_loss 0.5361 (0.5933) lr 7.0224e-05 eta 0:04:21
epoch [46/50] batch [100/288] time 0.146 (0.187) data 0.000 (0.005) loss 1.1131 (1.2406) ce_loss 0.7793 (0.9249) teacher_loss 0.7498 (0.9124) loss_zs_kd 0.1703 (0.1591) loss_oracle 0.2781 (0.2486) acc 71.8750 (75.6250) kd_loss 0.5990 (0.5798) lr 7.0224e-05 eta 0:04:10
epoch [46/50] batch [120/288] time 0.150 (0.181) data 0.000 (0.004) loss 0.7799 (1.2423) ce_loss 0.4766 (0.9276) teacher_loss 0.4373 (0.9149) loss_zs_kd 0.1523 (0.1593) loss_oracle 0.2665 (0.2477) acc 84.3750 (75.2865) kd_loss 0.5975 (0.5794) lr 7.0224e-05 eta 0:03:59
epoch [46/50] batch [140/288] time 0.160 (0.178) data 0.000 (0.003) loss 1.2479 (1.2427) ce_loss 0.8389 (0.9284) teacher_loss 0.8527 (0.9154) loss_zs_kd 0.1630 (0.1587) loss_oracle 0.3137 (0.2480) acc 75.0000 (75.1786) kd_loss 0.5895 (0.5811) lr 7.0224e-05 eta 0:03:51
epoch [46/50] batch [160/288] time 0.108 (0.179) data 0.000 (0.003) loss 1.2097 (1.2354) ce_loss 0.9321 (0.9223) teacher_loss 0.8979 (0.9103) loss_zs_kd 0.2051 (0.1580) loss_oracle 0.2093 (0.2461) acc 75.0000 (75.2539) kd_loss 0.4927 (0.5777) lr 7.0224e-05 eta 0:03:48
epoch [46/50] batch [180/288] time 0.206 (0.182) data 0.000 (0.003) loss 1.3263 (1.2437) ce_loss 0.9668 (0.9296) teacher_loss 0.9196 (0.9175) loss_zs_kd 0.1920 (0.1588) loss_oracle 0.3106 (0.2468) acc 71.8750 (74.9306) kd_loss 0.5521 (0.5819) lr 7.0224e-05 eta 0:03:49
epoch [46/50] batch [200/288] time 0.176 (0.181) data 0.000 (0.002) loss 1.4881 (1.2528) ce_loss 1.2002 (0.9387) teacher_loss 1.2080 (0.9270) loss_zs_kd 0.1008 (0.1586) loss_oracle 0.2296 (0.2464) acc 71.8750 (74.7812) kd_loss 0.5938 (0.5807) lr 7.0224e-05 eta 0:03:44
epoch [46/50] batch [220/288] time 0.150 (0.180) data 0.000 (0.002) loss 1.1957 (1.2544) ce_loss 0.8770 (0.9409) teacher_loss 0.8356 (0.9281) loss_zs_kd 0.1376 (0.1575) loss_oracle 0.2913 (0.2475) acc 75.0000 (74.7301) kd_loss 0.7408 (0.5810) lr 7.0224e-05 eta 0:03:39
epoch [46/50] batch [240/288] time 0.143 (0.178) data 0.000 (0.002) loss 1.1760 (1.2545) ce_loss 0.8901 (0.9412) teacher_loss 0.8120 (0.9272) loss_zs_kd 0.1589 (0.1578) loss_oracle 0.2845 (0.2483) acc 75.0000 (74.7266) kd_loss 0.7333 (0.5820) lr 7.0224e-05 eta 0:03:33
epoch [46/50] batch [260/288] time 0.146 (0.176) data 0.000 (0.002) loss 1.0736 (1.2490) ce_loss 0.7739 (0.9367) teacher_loss 0.7606 (0.9227) loss_zs_kd 0.1278 (0.1579) loss_oracle 0.2490 (0.2474) acc 87.5000 (74.8798) kd_loss 0.5887 (0.5797) lr 7.0224e-05 eta 0:03:28
epoch [46/50] batch [280/288] time 0.088 (0.174) data 0.000 (0.002) loss 1.6892 (1.2527) ce_loss 1.2598 (0.9401) teacher_loss 1.3258 (0.9263) loss_zs_kd 0.1634 (0.1583) loss_oracle 0.2817 (0.2472) acc 68.7500 (74.8438) kd_loss 0.7980 (0.5811) lr 7.0224e-05 eta 0:03:22
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,436
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,036
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 80.4%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 84.1%, epoch: 44 *******
******* Domain a best test acc:     84.1%, epoch: 42 *******
epoch [47/50] batch [20/288] time 0.151 (0.179) data 0.000 (0.011) loss 1.4656 (1.2655) ce_loss 1.1729 (0.9578) teacher_loss 1.1749 (0.9481) loss_zs_kd 0.1486 (0.1564) loss_oracle 0.2164 (0.2393) acc 71.8750 (75.9375) kd_loss 0.5340 (0.5762) lr 4.8943e-05 eta 0:03:22
epoch [47/50] batch [40/288] time 0.176 (0.176) data 0.000 (0.005) loss 1.4676 (1.2516) ce_loss 1.2109 (0.9503) teacher_loss 1.1682 (0.9357) loss_zs_kd 0.1329 (0.1485) loss_oracle 0.2329 (0.2416) acc 71.8750 (75.5469) kd_loss 0.5217 (0.5747) lr 4.8943e-05 eta 0:03:16
epoch [47/50] batch [60/288] time 0.188 (0.175) data 0.000 (0.004) loss 1.8376 (1.2573) ce_loss 1.5693 (0.9526) teacher_loss 1.5729 (0.9415) loss_zs_kd 0.1411 (0.1486) loss_oracle 0.1941 (0.2415) acc 65.6250 (75.5208) kd_loss 0.5145 (0.5696) lr 4.8943e-05 eta 0:03:11
epoch [47/50] batch [80/288] time 0.081 (0.182) data 0.000 (0.003) loss 1.3633 (1.2514) ce_loss 1.0381 (0.9452) teacher_loss 1.0615 (0.9330) loss_zs_kd 0.1310 (0.1517) loss_oracle 0.2362 (0.2425) acc 71.8750 (75.5469) kd_loss 0.7778 (0.5681) lr 4.8943e-05 eta 0:03:14
epoch [47/50] batch [100/288] time 0.147 (0.187) data 0.000 (0.002) loss 0.9675 (1.2448) ce_loss 0.6641 (0.9368) teacher_loss 0.6176 (0.9250) loss_zs_kd 0.1095 (0.1537) loss_oracle 0.2951 (0.2429) acc 78.1250 (75.2812) kd_loss 0.8375 (0.5642) lr 4.8943e-05 eta 0:03:17
epoch [47/50] batch [120/288] time 0.150 (0.182) data 0.000 (0.002) loss 1.5393 (1.2336) ce_loss 1.2334 (0.9265) teacher_loss 1.2329 (0.9136) loss_zs_kd 0.1240 (0.1541) loss_oracle 0.2444 (0.2429) acc 71.8750 (75.4948) kd_loss 0.5810 (0.5661) lr 4.8943e-05 eta 0:03:08
epoch [47/50] batch [140/288] time 0.149 (0.178) data 0.000 (0.002) loss 1.1021 (1.2395) ce_loss 0.7578 (0.9276) teacher_loss 0.7838 (0.9169) loss_zs_kd 0.1942 (0.1560) loss_oracle 0.2212 (0.2446) acc 75.0000 (75.2902) kd_loss 0.5509 (0.5690) lr 4.8943e-05 eta 0:03:00
epoch [47/50] batch [160/288] time 0.148 (0.175) data 0.000 (0.002) loss 1.2624 (1.2445) ce_loss 0.8892 (0.9314) teacher_loss 0.8593 (0.9208) loss_zs_kd 0.2647 (0.1575) loss_oracle 0.2707 (0.2450) acc 75.0000 (75.0781) kd_loss 0.7374 (0.5737) lr 4.8943e-05 eta 0:02:53
epoch [47/50] batch [180/288] time 0.162 (0.174) data 0.000 (0.001) loss 1.1839 (1.2481) ce_loss 0.8833 (0.9343) teacher_loss 0.8565 (0.9241) loss_zs_kd 0.1505 (0.1581) loss_oracle 0.2522 (0.2449) acc 68.7500 (74.7743) kd_loss 0.5956 (0.5764) lr 4.8943e-05 eta 0:02:48
epoch [47/50] batch [200/288] time 0.179 (0.173) data 0.000 (0.001) loss 0.6415 (1.2475) ce_loss 0.3970 (0.9337) teacher_loss 0.4065 (0.9236) loss_zs_kd 0.1061 (0.1564) loss_oracle 0.1820 (0.2457) acc 84.3750 (74.9062) kd_loss 0.3979 (0.5810) lr 4.8943e-05 eta 0:02:44
epoch [47/50] batch [220/288] time 0.343 (0.173) data 0.000 (0.001) loss 1.0838 (1.2516) ce_loss 0.7681 (0.9381) teacher_loss 0.7890 (0.9266) loss_zs_kd 0.1554 (0.1573) loss_oracle 0.2171 (0.2463) acc 75.0000 (74.8864) kd_loss 0.6617 (0.5807) lr 4.8943e-05 eta 0:02:40
epoch [47/50] batch [240/288] time 0.097 (0.176) data 0.000 (0.001) loss 0.8864 (1.2511) ce_loss 0.6001 (0.9370) teacher_loss 0.6215 (0.9260) loss_zs_kd 0.1385 (0.1581) loss_oracle 0.1957 (0.2460) acc 84.3750 (74.8307) kd_loss 0.5134 (0.5804) lr 4.8943e-05 eta 0:02:40
epoch [47/50] batch [260/288] time 0.163 (0.175) data 0.000 (0.001) loss 1.7225 (1.2520) ce_loss 1.3447 (0.9379) teacher_loss 1.3510 (0.9264) loss_zs_kd 0.2364 (0.1585) loss_oracle 0.2533 (0.2463) acc 68.7500 (74.8197) kd_loss 0.6402 (0.5786) lr 4.8943e-05 eta 0:02:35
epoch [47/50] batch [280/288] time 0.163 (0.173) data 0.000 (0.001) loss 0.8253 (1.2554) ce_loss 0.5166 (0.9419) teacher_loss 0.4868 (0.9297) loss_zs_kd 0.1249 (0.1588) loss_oracle 0.2761 (0.2463) acc 87.5000 (74.7321) kd_loss 0.5952 (0.5780) lr 4.8943e-05 eta 0:02:31
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,438
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,037
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 80.5%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 84.1%, epoch: 44 *******
******* Domain a best test acc:     84.1%, epoch: 42 *******
epoch [48/50] batch [20/288] time 0.095 (0.170) data 0.000 (0.015) loss 1.3486 (1.3078) ce_loss 1.0322 (1.0073) teacher_loss 1.0145 (0.9830) loss_zs_kd 0.1528 (0.1646) loss_oracle 0.2577 (0.2426) acc 65.6250 (71.5625) kd_loss 0.5735 (0.5479) lr 3.1417e-05 eta 0:02:23
epoch [48/50] batch [40/288] time 0.091 (0.165) data 0.000 (0.008) loss 1.5510 (1.2843) ce_loss 1.2598 (0.9806) teacher_loss 1.2001 (0.9578) loss_zs_kd 0.1788 (0.1594) loss_oracle 0.2616 (0.2469) acc 65.6250 (73.2031) kd_loss 0.7498 (0.5637) lr 3.1417e-05 eta 0:02:15
epoch [48/50] batch [60/288] time 0.166 (0.182) data 0.000 (0.005) loss 1.2692 (1.2663) ce_loss 1.0264 (0.9580) teacher_loss 0.9833 (0.9372) loss_zs_kd 0.1417 (0.1668) loss_oracle 0.2152 (0.2457) acc 71.8750 (74.0104) kd_loss 0.5931 (0.5580) lr 3.1417e-05 eta 0:02:25
epoch [48/50] batch [80/288] time 0.143 (0.174) data 0.000 (0.004) loss 1.4127 (1.2592) ce_loss 1.0596 (0.9540) teacher_loss 1.0681 (0.9333) loss_zs_kd 0.1537 (0.1629) loss_oracle 0.2677 (0.2445) acc 71.8750 (73.9844) kd_loss 0.5621 (0.5600) lr 3.1417e-05 eta 0:02:16
epoch [48/50] batch [100/288] time 0.168 (0.170) data 0.000 (0.003) loss 1.1700 (1.2456) ce_loss 0.9009 (0.9405) teacher_loss 0.8862 (0.9201) loss_zs_kd 0.1132 (0.1613) loss_oracle 0.2272 (0.2448) acc 71.8750 (74.1875) kd_loss 0.5988 (0.5627) lr 3.1417e-05 eta 0:02:09
epoch [48/50] batch [120/288] time 0.148 (0.167) data 0.000 (0.003) loss 1.3241 (1.2489) ce_loss 1.0117 (0.9410) teacher_loss 0.9419 (0.9208) loss_zs_kd 0.2156 (0.1606) loss_oracle 0.2744 (0.2479) acc 68.7500 (74.1146) kd_loss 0.6685 (0.5792) lr 3.1417e-05 eta 0:02:04
epoch [48/50] batch [140/288] time 0.166 (0.166) data 0.000 (0.002) loss 1.1798 (1.2508) ce_loss 0.8442 (0.9402) teacher_loss 0.8623 (0.9218) loss_zs_kd 0.1602 (0.1602) loss_oracle 0.2374 (0.2490) acc 75.0000 (74.1741) kd_loss 0.6574 (0.5847) lr 3.1417e-05 eta 0:02:00
epoch [48/50] batch [160/288] time 0.153 (0.166) data 0.000 (0.002) loss 1.2318 (1.2597) ce_loss 0.9297 (0.9479) teacher_loss 0.9137 (0.9292) loss_zs_kd 0.1314 (0.1609) loss_oracle 0.2524 (0.2500) acc 68.7500 (74.0234) kd_loss 0.5982 (0.5839) lr 3.1417e-05 eta 0:01:56
epoch [48/50] batch [180/288] time 0.345 (0.167) data 0.000 (0.002) loss 1.0734 (1.2527) ce_loss 0.7524 (0.9398) teacher_loss 0.7866 (0.9226) loss_zs_kd 0.1583 (0.1618) loss_oracle 0.2077 (0.2492) acc 84.3750 (74.3403) kd_loss 0.5908 (0.5837) lr 3.1417e-05 eta 0:01:54
epoch [48/50] batch [200/288] time 0.158 (0.171) data 0.000 (0.002) loss 1.1607 (1.2532) ce_loss 0.7402 (0.9405) teacher_loss 0.7648 (0.9231) loss_zs_kd 0.1709 (0.1616) loss_oracle 0.3104 (0.2493) acc 84.3750 (74.4219) kd_loss 0.8290 (0.5843) lr 3.1417e-05 eta 0:01:53
epoch [48/50] batch [220/288] time 0.160 (0.170) data 0.000 (0.002) loss 1.1337 (1.2512) ce_loss 0.8306 (0.9385) teacher_loss 0.8045 (0.9211) loss_zs_kd 0.1697 (0.1616) loss_oracle 0.2443 (0.2493) acc 84.3750 (74.6165) kd_loss 0.5043 (0.5822) lr 3.1417e-05 eta 0:01:49
epoch [48/50] batch [240/288] time 0.178 (0.169) data 0.000 (0.001) loss 1.3053 (1.2537) ce_loss 1.0049 (0.9404) teacher_loss 0.9950 (0.9238) loss_zs_kd 0.1453 (0.1617) loss_oracle 0.2376 (0.2491) acc 78.1250 (74.5573) kd_loss 0.5578 (0.5831) lr 3.1417e-05 eta 0:01:45
epoch [48/50] batch [260/288] time 0.165 (0.168) data 0.000 (0.001) loss 1.3527 (1.2515) ce_loss 0.9766 (0.9385) teacher_loss 0.9760 (0.9225) loss_zs_kd 0.1530 (0.1609) loss_oracle 0.3002 (0.2486) acc 75.0000 (74.6034) kd_loss 0.7072 (0.5823) lr 3.1417e-05 eta 0:01:41
epoch [48/50] batch [280/288] time 0.153 (0.166) data 0.000 (0.001) loss 1.1407 (1.2494) ce_loss 0.8237 (0.9355) teacher_loss 0.8572 (0.9203) loss_zs_kd 0.1464 (0.1612) loss_oracle 0.2103 (0.2485) acc 81.2500 (74.6763) kd_loss 0.5250 (0.5824) lr 3.1417e-05 eta 0:01:37
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,439
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,038
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 80.6%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 84.1%, epoch: 44 *******
******* Domain a best test acc:     84.1%, epoch: 42 *******
epoch [49/50] batch [20/288] time 0.163 (0.217) data 0.000 (0.016) loss 1.2924 (1.2036) ce_loss 0.9946 (0.8910) teacher_loss 1.0079 (0.8808) loss_zs_kd 0.1430 (0.1581) loss_oracle 0.2130 (0.2437) acc 68.7500 (75.3125) kd_loss 0.5026 (0.5531) lr 1.7713e-05 eta 0:02:00
epoch [49/50] batch [40/288] time 0.144 (0.189) data 0.000 (0.008) loss 1.6389 (1.2254) ce_loss 1.3076 (0.9129) teacher_loss 1.2885 (0.9008) loss_zs_kd 0.1426 (0.1547) loss_oracle 0.2791 (0.2472) acc 59.3750 (74.7656) kd_loss 0.6358 (0.5476) lr 1.7713e-05 eta 0:01:41
epoch [49/50] batch [60/288] time 0.150 (0.177) data 0.000 (0.005) loss 0.9118 (1.2310) ce_loss 0.5278 (0.9089) teacher_loss 0.5173 (0.8974) loss_zs_kd 0.1470 (0.1582) loss_oracle 0.3211 (0.2544) acc 84.3750 (75.4688) kd_loss 0.6271 (0.5640) lr 1.7713e-05 eta 0:01:31
epoch [49/50] batch [80/288] time 0.164 (0.172) data 0.000 (0.004) loss 1.2937 (1.2206) ce_loss 0.9863 (0.8963) teacher_loss 0.9845 (0.8858) loss_zs_kd 0.1532 (0.1579) loss_oracle 0.2327 (0.2559) acc 81.2500 (76.2891) kd_loss 0.5262 (0.5694) lr 1.7713e-05 eta 0:01:25
epoch [49/50] batch [100/288] time 0.145 (0.168) data 0.000 (0.003) loss 0.8698 (1.2309) ce_loss 0.5386 (0.9098) teacher_loss 0.5300 (0.8980) loss_zs_kd 0.1415 (0.1600) loss_oracle 0.2691 (0.2529) acc 90.6250 (75.8750) kd_loss 0.5372 (0.5663) lr 1.7713e-05 eta 0:01:20
epoch [49/50] batch [120/288] time 0.090 (0.165) data 0.000 (0.003) loss 1.2582 (1.2355) ce_loss 0.9814 (0.9169) teacher_loss 0.9597 (0.9041) loss_zs_kd 0.1646 (0.1587) loss_oracle 0.2162 (0.2521) acc 81.2500 (75.7552) kd_loss 0.5621 (0.5655) lr 1.7713e-05 eta 0:01:15
epoch [49/50] batch [140/288] time 0.364 (0.170) data 0.000 (0.002) loss 1.5012 (1.2355) ce_loss 1.2539 (0.9165) teacher_loss 1.2244 (0.9038) loss_zs_kd 0.1962 (0.1599) loss_oracle 0.1788 (0.2517) acc 68.7500 (75.6250) kd_loss 0.4777 (0.5698) lr 1.7713e-05 eta 0:01:14
epoch [49/50] batch [160/288] time 0.152 (0.173) data 0.000 (0.002) loss 1.0329 (1.2330) ce_loss 0.7422 (0.9136) teacher_loss 0.7397 (0.9006) loss_zs_kd 0.1511 (0.1584) loss_oracle 0.2176 (0.2531) acc 81.2500 (75.6250) kd_loss 0.3971 (0.5735) lr 1.7713e-05 eta 0:01:11
epoch [49/50] batch [180/288] time 0.146 (0.171) data 0.000 (0.002) loss 1.5054 (1.2266) ce_loss 1.1338 (0.9080) teacher_loss 1.1706 (0.8954) loss_zs_kd 0.2497 (0.1579) loss_oracle 0.2099 (0.2523) acc 71.8750 (75.7812) kd_loss 0.4406 (0.5713) lr 1.7713e-05 eta 0:01:07
epoch [49/50] batch [200/288] time 0.172 (0.169) data 0.000 (0.002) loss 1.8674 (1.2393) ce_loss 1.5479 (0.9202) teacher_loss 1.5588 (0.9093) loss_zs_kd 0.1511 (0.1582) loss_oracle 0.2331 (0.2510) acc 59.3750 (75.5469) kd_loss 0.4650 (0.5730) lr 1.7713e-05 eta 0:01:03
epoch [49/50] batch [220/288] time 0.143 (0.168) data 0.000 (0.002) loss 1.4311 (1.2452) ce_loss 1.1455 (0.9267) teacher_loss 1.0939 (0.9152) loss_zs_kd 0.1806 (0.1589) loss_oracle 0.2469 (0.2505) acc 68.7500 (75.4545) kd_loss 0.6700 (0.5746) lr 1.7713e-05 eta 0:00:59
epoch [49/50] batch [240/288] time 0.166 (0.167) data 0.000 (0.001) loss 0.9462 (1.2439) ce_loss 0.6069 (0.9251) teacher_loss 0.6185 (0.9136) loss_zs_kd 0.1561 (0.1587) loss_oracle 0.2496 (0.2509) acc 84.3750 (75.5339) kd_loss 0.6742 (0.5775) lr 1.7713e-05 eta 0:00:55
epoch [49/50] batch [260/288] time 0.173 (0.166) data 0.000 (0.001) loss 1.3391 (1.2360) ce_loss 1.0059 (0.9173) teacher_loss 1.0035 (0.9060) loss_zs_kd 0.2045 (0.1578) loss_oracle 0.2333 (0.2511) acc 78.1250 (75.8293) kd_loss 0.4965 (0.5788) lr 1.7713e-05 eta 0:00:52
epoch [49/50] batch [280/288] time 0.082 (0.166) data 0.000 (0.001) loss 0.8747 (1.2283) ce_loss 0.5454 (0.9111) teacher_loss 0.5521 (0.8993) loss_zs_kd 0.1278 (0.1571) loss_oracle 0.2588 (0.2505) acc 87.5000 (75.9040) kd_loss 0.7173 (0.5768) lr 1.7713e-05 eta 0:00:49
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,436
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,037
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 80.5%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 84.1%, epoch: 44 *******
******* Domain a best test acc:     84.1%, epoch: 42 *******
epoch [50/50] batch [20/288] time 0.153 (0.172) data 0.000 (0.012) loss 1.3093 (1.1478) ce_loss 1.0625 (0.8446) teacher_loss 1.0549 (0.8209) loss_zs_kd 0.1163 (0.1578) loss_oracle 0.1962 (0.2479) acc 68.7500 (75.4688) kd_loss 0.4456 (0.5300) lr 7.8853e-06 eta 0:00:46
epoch [50/50] batch [40/288] time 0.153 (0.166) data 0.000 (0.006) loss 1.3821 (1.2217) ce_loss 1.0488 (0.9081) teacher_loss 1.0541 (0.8933) loss_zs_kd 0.1782 (0.1592) loss_oracle 0.2389 (0.2488) acc 68.7500 (74.4531) kd_loss 0.5593 (0.5597) lr 7.8853e-06 eta 0:00:41
epoch [50/50] batch [60/288] time 0.170 (0.164) data 0.000 (0.004) loss 1.0990 (1.2205) ce_loss 0.8521 (0.9069) teacher_loss 0.8462 (0.8940) loss_zs_kd 0.1390 (0.1546) loss_oracle 0.1832 (0.2492) acc 78.1250 (75.1562) kd_loss 0.4284 (0.5682) lr 7.8853e-06 eta 0:00:37
epoch [50/50] batch [80/288] time 0.245 (0.171) data 0.000 (0.003) loss 1.0897 (1.2350) ce_loss 0.7803 (0.9218) teacher_loss 0.7993 (0.9077) loss_zs_kd 0.1393 (0.1563) loss_oracle 0.2207 (0.2491) acc 75.0000 (74.6094) kd_loss 0.5284 (0.5625) lr 7.8853e-06 eta 0:00:35
epoch [50/50] batch [100/288] time 0.178 (0.180) data 0.000 (0.003) loss 1.4526 (1.2520) ce_loss 1.1943 (0.9410) teacher_loss 1.1703 (0.9241) loss_zs_kd 0.1594 (0.1571) loss_oracle 0.2027 (0.2493) acc 68.7500 (74.2812) kd_loss 0.4592 (0.5600) lr 7.8853e-06 eta 0:00:33
epoch [50/50] batch [120/288] time 0.145 (0.176) data 0.000 (0.002) loss 1.1200 (1.2472) ce_loss 0.7642 (0.9367) teacher_loss 0.7574 (0.9192) loss_zs_kd 0.1364 (0.1569) loss_oracle 0.2944 (0.2496) acc 78.1250 (74.4010) kd_loss 0.6801 (0.5611) lr 7.8853e-06 eta 0:00:29
epoch [50/50] batch [140/288] time 0.174 (0.174) data 0.000 (0.002) loss 1.4457 (1.2447) ce_loss 1.1621 (0.9320) teacher_loss 1.1033 (0.9144) loss_zs_kd 0.1857 (0.1599) loss_oracle 0.2495 (0.2503) acc 71.8750 (74.7991) kd_loss 0.5364 (0.5693) lr 7.8853e-06 eta 0:00:25
epoch [50/50] batch [160/288] time 0.168 (0.173) data 0.000 (0.002) loss 1.1490 (1.2332) ce_loss 0.8379 (0.9215) teacher_loss 0.7699 (0.9032) loss_zs_kd 0.1255 (0.1585) loss_oracle 0.3164 (0.2507) acc 75.0000 (75.0000) kd_loss 0.8187 (0.5689) lr 7.8853e-06 eta 0:00:22
epoch [50/50] batch [180/288] time 0.179 (0.172) data 0.000 (0.002) loss 1.3126 (1.2496) ce_loss 1.0469 (0.9372) teacher_loss 0.9836 (0.9194) loss_zs_kd 0.1553 (0.1591) loss_oracle 0.2513 (0.2506) acc 68.7500 (74.8611) kd_loss 0.6692 (0.5683) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [200/288] time 0.088 (0.174) data 0.000 (0.001) loss 1.4810 (1.2551) ce_loss 1.1729 (0.9415) teacher_loss 1.1070 (0.9234) loss_zs_kd 0.1272 (0.1595) loss_oracle 0.3104 (0.2520) acc 59.3750 (74.8125) kd_loss 0.6100 (0.5726) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [220/288] time 0.154 (0.178) data 0.000 (0.001) loss 0.9554 (1.2510) ce_loss 0.6943 (0.9373) teacher_loss 0.6719 (0.9186) loss_zs_kd 0.1199 (0.1601) loss_oracle 0.2234 (0.2523) acc 71.8750 (74.8438) kd_loss 0.3789 (0.5757) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [240/288] time 0.179 (0.177) data 0.000 (0.001) loss 1.0857 (1.2589) ce_loss 0.7295 (0.9449) teacher_loss 0.7184 (0.9264) loss_zs_kd 0.1283 (0.1597) loss_oracle 0.3032 (0.2526) acc 78.1250 (74.7656) kd_loss 0.7230 (0.5797) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [260/288] time 0.163 (0.177) data 0.000 (0.001) loss 0.9936 (1.2651) ce_loss 0.7158 (0.9517) teacher_loss 0.6959 (0.9337) loss_zs_kd 0.1294 (0.1601) loss_oracle 0.2330 (0.2514) acc 75.0000 (74.5433) kd_loss 0.5662 (0.5782) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [280/288] time 0.148 (0.176) data 0.000 (0.001) loss 1.5300 (1.2601) ce_loss 1.2275 (0.9461) teacher_loss 1.1846 (0.9284) loss_zs_kd 0.1625 (0.1598) loss_oracle 0.2642 (0.2518) acc 56.2500 (74.6875) kd_loss 0.7708 (0.5816) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,438
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,037
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 80.5%
******* Domain a best val acc:      87.4%, epoch: 44 *******
******* Domain a best val test acc: 84.1%, epoch: 44 *******
******* Domain a best test acc:     84.1%, epoch: 42 *******
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:39:59

Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'clipart', 'real_world']
Target     ['product']
# classes  65
# train_x  7,815
# val      3,334
# test     4,439
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/244] time 0.149 (0.196) data 0.000 (0.020) loss 1.4956 (1.4971) ce_loss 1.4287 (1.4243) teacher_loss 1.4284 (1.4244) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0672 (0.0727) acc 62.5000 (65.0000) kd_loss 0.3216 (0.3505) lr 1.0000e-05 eta 0:39:53
epoch [1/50] batch [40/244] time 0.169 (0.177) data 0.000 (0.010) loss 1.5712 (1.4670) ce_loss 1.5000 (1.3939) teacher_loss 1.4994 (1.3940) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0718 (0.0729) acc 56.2500 (65.2344) kd_loss 0.3477 (0.3522) lr 1.0000e-05 eta 0:35:56
epoch [1/50] batch [60/244] time 0.150 (0.173) data 0.000 (0.007) loss 1.3884 (1.5011) ce_loss 1.3174 (1.4275) teacher_loss 1.3174 (1.4276) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0709 (0.0735) acc 65.6250 (64.0104) kd_loss 0.3508 (0.3546) lr 1.0000e-05 eta 0:35:00
epoch [1/50] batch [80/244] time 0.150 (0.168) data 0.000 (0.005) loss 1.6601 (1.5068) ce_loss 1.5645 (1.4335) teacher_loss 1.5642 (1.4336) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0958 (0.0731) acc 59.3750 (63.9844) kd_loss 0.4632 (0.3529) lr 1.0000e-05 eta 0:33:57
epoch [1/50] batch [100/244] time 0.151 (0.165) data 0.000 (0.004) loss 1.6192 (1.4865) ce_loss 1.5576 (1.4142) teacher_loss 1.5567 (1.4142) loss_zs_kd 0.0006 (0.0002) loss_oracle 0.0621 (0.0722) acc 62.5000 (64.1562) kd_loss 0.2999 (0.3485) lr 1.0000e-05 eta 0:33:12
epoch [1/50] batch [120/244] time 0.152 (0.163) data 0.000 (0.003) loss 0.9957 (1.4718) ce_loss 0.9585 (1.3999) teacher_loss 0.9581 (1.4000) loss_zs_kd 0.0005 (0.0002) loss_oracle 0.0374 (0.0717) acc 75.0000 (64.5573) kd_loss 0.1794 (0.3456) lr 1.0000e-05 eta 0:32:44
epoch [1/50] batch [140/244] time 0.151 (0.161) data 0.000 (0.003) loss 1.1518 (1.4538) ce_loss 1.0928 (1.3812) teacher_loss 1.0924 (1.3813) loss_zs_kd 0.0008 (0.0003) loss_oracle 0.0590 (0.0723) acc 75.0000 (65.0000) kd_loss 0.2835 (0.3484) lr 1.0000e-05 eta 0:32:22
epoch [1/50] batch [160/244] time 0.148 (0.160) data 0.000 (0.003) loss 1.5695 (1.4461) ce_loss 1.4805 (1.3728) teacher_loss 1.4822 (1.3729) loss_zs_kd 0.0017 (0.0004) loss_oracle 0.0865 (0.0729) acc 56.2500 (65.1562) kd_loss 0.4155 (0.3514) lr 1.0000e-05 eta 0:32:06
epoch [1/50] batch [180/244] time 0.151 (0.159) data 0.000 (0.002) loss 1.0550 (1.4449) ce_loss 0.9810 (1.3721) teacher_loss 0.9823 (1.3722) loss_zs_kd 0.0011 (0.0005) loss_oracle 0.0722 (0.0724) acc 81.2500 (65.1910) kd_loss 0.3433 (0.3488) lr 1.0000e-05 eta 0:31:53
epoch [1/50] batch [200/244] time 0.153 (0.158) data 0.000 (0.002) loss 1.5389 (1.4450) ce_loss 1.4844 (1.3713) teacher_loss 1.4853 (1.3714) loss_zs_kd 0.0013 (0.0007) loss_oracle 0.0529 (0.0732) acc 62.5000 (65.2344) kd_loss 0.2529 (0.3528) lr 1.0000e-05 eta 0:31:41
epoch [1/50] batch [220/244] time 0.148 (0.158) data 0.000 (0.002) loss 1.2836 (1.4423) ce_loss 1.2207 (1.3679) teacher_loss 1.2210 (1.3680) loss_zs_kd 0.0066 (0.0008) loss_oracle 0.0593 (0.0739) acc 68.7500 (65.2557) kd_loss 0.2843 (0.3558) lr 1.0000e-05 eta 0:31:34
epoch [1/50] batch [240/244] time 0.150 (0.158) data 0.000 (0.002) loss 1.3837 (1.4389) ce_loss 1.3125 (1.3645) teacher_loss 1.3130 (1.3646) loss_zs_kd 0.0017 (0.0010) loss_oracle 0.0698 (0.0738) acc 75.0000 (65.4427) kd_loss 0.3364 (0.3556) lr 1.0000e-05 eta 0:31:25
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,674
* accuracy: 80.2%
* error: 19.8%
* macro_f1: 78.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,944
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 87.9%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      80.2%, epoch: 1 *******
******* Domain p best val test acc: 88.8%, epoch: 1 *******
******* Domain p best test acc:     88.8%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/ana
epoch [2/50] batch [20/244] time 0.153 (0.190) data 0.000 (0.021) loss 1.2618 (1.5707) ce_loss 1.0107 (1.3772) teacher_loss 1.0396 (1.3838) loss_zs_kd 0.0955 (0.0926) loss_oracle 0.1745 (0.1406) acc 75.0000 (64.2188) kd_loss 0.3756 (0.4364) lr 2.0000e-03 eta 0:37:47
epoch [2/50] batch [40/244] time 0.225 (0.171) data 0.000 (0.011) loss 1.4020 (1.5271) ce_loss 1.1133 (1.2990) teacher_loss 1.1299 (1.3037) loss_zs_kd 0.0707 (0.0976) loss_oracle 0.2368 (0.1747) acc 71.8750 (66.7969) kd_loss 0.6901 (0.4762) lr 2.0000e-03 eta 0:33:57
epoch [2/50] batch [60/244] time 0.399 (0.168) data 0.001 (0.007) loss 1.5766 (1.5628) ce_loss 1.3750 (1.3328) teacher_loss 1.3133 (1.3337) loss_zs_kd 0.1024 (0.0983) loss_oracle 0.2121 (0.1799) acc 65.6250 (65.8854) kd_loss 0.4411 (0.4887) lr 2.0000e-03 eta 0:33:23
epoch [2/50] batch [80/244] time 0.134 (0.173) data 0.000 (0.006) loss 1.4488 (1.5265) ce_loss 1.1279 (1.2853) teacher_loss 1.1036 (1.2842) loss_zs_kd 0.1175 (0.1020) loss_oracle 0.2864 (0.1913) acc 68.7500 (66.7578) kd_loss 0.4727 (0.4882) lr 2.0000e-03 eta 0:34:11
epoch [2/50] batch [100/244] time 0.092 (0.172) data 0.000 (0.004) loss 1.1730 (1.5166) ce_loss 0.9150 (1.2702) teacher_loss 0.9217 (1.2687) loss_zs_kd 0.0721 (0.1024) loss_oracle 0.2153 (0.1967) acc 71.8750 (67.4062) kd_loss 0.5476 (0.4974) lr 2.0000e-03 eta 0:34:01
epoch [2/50] batch [120/244] time 0.160 (0.168) data 0.000 (0.004) loss 1.9034 (1.4952) ce_loss 1.6318 (1.2485) teacher_loss 1.6024 (1.2449) loss_zs_kd 0.1125 (0.1017) loss_oracle 0.2448 (0.1994) acc 62.5000 (68.1250) kd_loss 0.5901 (0.5044) lr 2.0000e-03 eta 0:33:06
epoch [2/50] batch [140/244] time 0.154 (0.166) data 0.000 (0.003) loss 1.2326 (1.4884) ce_loss 0.9805 (1.2419) teacher_loss 0.9714 (1.2377) loss_zs_kd 0.1138 (0.1044) loss_oracle 0.2043 (0.1985) acc 75.0000 (68.3929) kd_loss 0.5480 (0.5012) lr 2.0000e-03 eta 0:32:37
epoch [2/50] batch [160/244] time 0.147 (0.164) data 0.000 (0.003) loss 1.4458 (1.4928) ce_loss 1.2090 (1.2483) teacher_loss 1.1873 (1.2433) loss_zs_kd 0.0896 (0.1049) loss_oracle 0.2137 (0.1970) acc 68.7500 (68.1250) kd_loss 0.4166 (0.5009) lr 2.0000e-03 eta 0:32:13
epoch [2/50] batch [180/244] time 0.151 (0.163) data 0.000 (0.003) loss 1.3201 (1.4774) ce_loss 1.0537 (1.2337) teacher_loss 1.0462 (1.2284) loss_zs_kd 0.0889 (0.1053) loss_oracle 0.2294 (0.1963) acc 65.6250 (68.4549) kd_loss 0.6230 (0.4972) lr 2.0000e-03 eta 0:32:02
epoch [2/50] batch [200/244] time 0.171 (0.163) data 0.000 (0.002) loss 1.6836 (1.4905) ce_loss 1.3945 (1.2432) teacher_loss 1.3681 (1.2375) loss_zs_kd 0.0811 (0.1075) loss_oracle 0.2750 (0.1993) acc 65.6250 (68.1250) kd_loss 0.5357 (0.4971) lr 2.0000e-03 eta 0:31:56
epoch [2/50] batch [220/244] time 0.156 (0.163) data 0.000 (0.002) loss 1.4042 (1.4912) ce_loss 1.0586 (1.2379) teacher_loss 1.0062 (1.2319) loss_zs_kd 0.1336 (0.1072) loss_oracle 0.3311 (0.2057) acc 75.0000 (68.1250) kd_loss 0.5904 (0.5044) lr 2.0000e-03 eta 0:31:50
epoch [2/50] batch [240/244] time 0.152 (0.162) data 0.000 (0.002) loss 1.7600 (1.4908) ce_loss 1.4307 (1.2369) teacher_loss 1.4798 (1.2303) loss_zs_kd 0.1688 (0.1070) loss_oracle 0.1957 (0.2070) acc 65.6250 (67.9818) kd_loss 0.3739 (0.5027) lr 2.0000e-03 eta 0:31:36
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,769
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 81.9%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.1%, epoch: 2 *******
******* Domain p best val test acc: 91.0%, epoch: 2 *******
******* Domain p best test acc:     91.0%, epoch: 2 *******
epoch [3/50] batch [20/244] time 0.152 (0.175) data 0.000 (0.014) loss 1.4871 (1.5171) ce_loss 1.1631 (1.2063) teacher_loss 1.2056 (1.2022) loss_zs_kd 0.1407 (0.1344) loss_oracle 0.2112 (0.2477) acc 62.5000 (68.7500) kd_loss 0.5251 (0.5450) lr 1.9980e-03 eta 0:34:09
epoch [3/50] batch [40/244] time 0.146 (0.164) data 0.000 (0.007) loss 1.0537 (1.4980) ce_loss 0.7847 (1.2162) teacher_loss 0.7822 (1.2109) loss_zs_kd 0.1358 (0.1218) loss_oracle 0.2035 (0.2262) acc 75.0000 (68.7500) kd_loss 0.6072 (0.5395) lr 1.9980e-03 eta 0:31:53
epoch [3/50] batch [60/244] time 0.153 (0.160) data 0.000 (0.005) loss 0.9770 (1.4660) ce_loss 0.6904 (1.1851) teacher_loss 0.6617 (1.1792) loss_zs_kd 0.1092 (0.1166) loss_oracle 0.2607 (0.2286) acc 81.2500 (69.1146) kd_loss 0.5817 (0.5450) lr 1.9980e-03 eta 0:31:02
epoch [3/50] batch [80/244] time 0.102 (0.159) data 0.000 (0.004) loss 1.8363 (1.5083) ce_loss 1.5137 (1.2254) teacher_loss 1.5312 (1.2199) loss_zs_kd 0.0764 (0.1182) loss_oracle 0.2669 (0.2293) acc 65.6250 (68.2422) kd_loss 0.7464 (0.5393) lr 1.9980e-03 eta 0:30:44
epoch [3/50] batch [100/244] time 0.095 (0.146) data 0.000 (0.003) loss 1.8558 (1.4949) ce_loss 1.6084 (1.2154) teacher_loss 1.6080 (1.2106) loss_zs_kd 0.1482 (0.1141) loss_oracle 0.1737 (0.2272) acc 59.3750 (68.7188) kd_loss 0.4357 (0.5317) lr 1.9980e-03 eta 0:28:13
epoch [3/50] batch [120/244] time 0.090 (0.145) data 0.000 (0.002) loss 1.1573 (1.4861) ce_loss 0.8599 (1.2154) teacher_loss 0.8535 (1.2098) loss_zs_kd 0.1481 (0.1140) loss_oracle 0.2298 (0.2192) acc 68.7500 (68.6198) kd_loss 0.6446 (0.5293) lr 1.9980e-03 eta 0:27:58
epoch [3/50] batch [140/244] time 0.082 (0.148) data 0.000 (0.002) loss 1.5715 (1.4709) ce_loss 1.2979 (1.2044) teacher_loss 1.2785 (1.1996) loss_zs_kd 0.0986 (0.1138) loss_oracle 0.2437 (0.2144) acc 71.8750 (69.0402) kd_loss 0.7433 (0.5275) lr 1.9980e-03 eta 0:28:28
epoch [3/50] batch [160/244] time 0.088 (0.141) data 0.000 (0.002) loss 1.3980 (1.4789) ce_loss 1.1680 (1.2140) teacher_loss 1.1466 (1.2092) loss_zs_kd 0.1179 (0.1133) loss_oracle 0.1924 (0.2131) acc 71.8750 (68.7695) kd_loss 0.6126 (0.5280) lr 1.9980e-03 eta 0:27:12
epoch [3/50] batch [180/244] time 0.102 (0.140) data 0.000 (0.002) loss 1.1631 (1.4702) ce_loss 0.9014 (1.2075) teacher_loss 0.8774 (1.2036) loss_zs_kd 0.1295 (0.1126) loss_oracle 0.2210 (0.2103) acc 75.0000 (68.9583) kd_loss 0.5895 (0.5233) lr 1.9980e-03 eta 0:26:52
epoch [3/50] batch [200/244] time 0.083 (0.143) data 0.000 (0.002) loss 1.7292 (1.4692) ce_loss 1.3438 (1.2037) teacher_loss 1.3917 (1.1994) loss_zs_kd 0.1300 (0.1143) loss_oracle 0.2725 (0.2127) acc 68.7500 (69.0312) kd_loss 0.6398 (0.5215) lr 1.9980e-03 eta 0:27:22
epoch [3/50] batch [220/244] time 0.098 (0.145) data 0.000 (0.001) loss 1.5778 (1.4734) ce_loss 1.3379 (1.2084) teacher_loss 1.3131 (1.2028) loss_zs_kd 0.1434 (0.1162) loss_oracle 0.1930 (0.2125) acc 68.7500 (68.9489) kd_loss 0.3792 (0.5170) lr 1.9980e-03 eta 0:27:42
epoch [3/50] batch [240/244] time 0.084 (0.146) data 0.000 (0.001) loss 1.0962 (1.4677) ce_loss 0.8994 (1.2051) teacher_loss 0.8823 (1.1986) loss_zs_kd 0.0762 (0.1164) loss_oracle 0.1758 (0.2109) acc 71.8750 (68.9844) kd_loss 0.3072 (0.5134) lr 1.9980e-03 eta 0:27:59
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,784
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.3%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,047
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.6%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.5%, epoch: 3 *******
******* Domain p best val test acc: 91.2%, epoch: 3 *******
******* Domain p best test acc:     91.2%, epoch: 3 *******
epoch [4/50] batch [20/244] time 0.175 (0.194) data 0.000 (0.018) loss 1.8782 (1.5411) ce_loss 1.5557 (1.2200) teacher_loss 1.5110 (1.2183) loss_zs_kd 0.0914 (0.1330) loss_oracle 0.3216 (0.2563) acc 59.3750 (66.8750) kd_loss 0.5914 (0.5365) lr 1.9921e-03 eta 0:37:06
epoch [4/50] batch [40/244] time 0.151 (0.180) data 0.000 (0.009) loss 1.0583 (1.5072) ce_loss 0.7896 (1.1938) teacher_loss 0.7776 (1.1910) loss_zs_kd 0.1189 (0.1204) loss_oracle 0.2213 (0.2560) acc 81.2500 (68.1250) kd_loss 0.6191 (0.5492) lr 1.9921e-03 eta 0:34:19
epoch [4/50] batch [60/244] time 0.178 (0.176) data 0.001 (0.006) loss 1.6902 (1.4560) ce_loss 1.4502 (1.1692) teacher_loss 1.4277 (1.1646) loss_zs_kd 0.1458 (0.1176) loss_oracle 0.1896 (0.2326) acc 53.1250 (69.2708) kd_loss 0.5032 (0.5332) lr 1.9921e-03 eta 0:33:31
epoch [4/50] batch [80/244] time 0.152 (0.172) data 0.000 (0.005) loss 2.1278 (1.4453) ce_loss 1.8545 (1.1694) teacher_loss 1.8368 (1.1629) loss_zs_kd 0.1554 (0.1228) loss_oracle 0.2133 (0.2210) acc 46.8750 (69.5312) kd_loss 0.5267 (0.5153) lr 1.9921e-03 eta 0:32:34
epoch [4/50] batch [100/244] time 0.151 (0.168) data 0.000 (0.004) loss 1.6086 (1.4662) ce_loss 1.3467 (1.1927) teacher_loss 1.3299 (1.1854) loss_zs_kd 0.1126 (0.1257) loss_oracle 0.2224 (0.2180) acc 65.6250 (68.6875) kd_loss 0.5565 (0.5211) lr 1.9921e-03 eta 0:31:44
epoch [4/50] batch [120/244] time 0.156 (0.165) data 0.000 (0.003) loss 1.2755 (1.4752) ce_loss 1.0410 (1.2034) teacher_loss 1.0320 (1.1958) loss_zs_kd 0.0983 (0.1269) loss_oracle 0.1943 (0.2159) acc 75.0000 (68.6979) kd_loss 0.5112 (0.5182) lr 1.9921e-03 eta 0:31:12
epoch [4/50] batch [140/244] time 0.175 (0.165) data 0.000 (0.003) loss 1.1309 (1.4577) ce_loss 0.8613 (1.1889) teacher_loss 0.8294 (1.1795) loss_zs_kd 0.0977 (0.1260) loss_oracle 0.2527 (0.2152) acc 75.0000 (69.1295) kd_loss 0.5515 (0.5164) lr 1.9921e-03 eta 0:31:09
epoch [4/50] batch [160/244] time 0.150 (0.164) data 0.000 (0.002) loss 1.2290 (1.4597) ce_loss 0.9692 (1.1906) teacher_loss 0.9613 (1.1787) loss_zs_kd 0.1098 (0.1283) loss_oracle 0.2127 (0.2168) acc 68.7500 (68.7305) kd_loss 0.5696 (0.5171) lr 1.9921e-03 eta 0:30:49
epoch [4/50] batch [180/244] time 0.152 (0.162) data 0.000 (0.002) loss 0.9595 (1.4494) ce_loss 0.6440 (1.1746) teacher_loss 0.6641 (1.1635) loss_zs_kd 0.1268 (0.1291) loss_oracle 0.2319 (0.2214) acc 78.1250 (69.2361) kd_loss 0.5292 (0.5238) lr 1.9921e-03 eta 0:30:32
epoch [4/50] batch [200/244] time 0.184 (0.161) data 0.000 (0.002) loss 1.6033 (1.4480) ce_loss 1.3359 (1.1715) teacher_loss 1.3518 (1.1610) loss_zs_kd 0.1136 (0.1297) loss_oracle 0.1947 (0.2221) acc 71.8750 (69.2500) kd_loss 0.5379 (0.5234) lr 1.9921e-03 eta 0:30:19
epoch [4/50] batch [220/244] time 0.111 (0.158) data 0.000 (0.002) loss 1.9997 (1.4354) ce_loss 1.7666 (1.1609) teacher_loss 1.7739 (1.1511) loss_zs_kd 0.1290 (0.1304) loss_oracle 0.1614 (0.2190) acc 59.3750 (69.4176) kd_loss 0.4118 (0.5204) lr 1.9921e-03 eta 0:29:36
epoch [4/50] batch [240/244] time 0.087 (0.159) data 0.000 (0.002) loss 1.6706 (1.4340) ce_loss 1.4502 (1.1608) teacher_loss 1.4268 (1.1504) loss_zs_kd 0.0965 (0.1308) loss_oracle 0.1955 (0.2182) acc 59.3750 (69.4271) kd_loss 0.6507 (0.5194) lr 1.9921e-03 eta 0:29:40
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,781
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 82.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      83.5%, epoch: 3 *******
******* Domain p best val test acc: 91.2%, epoch: 3 *******
******* Domain p best test acc:     91.2%, epoch: 3 *******
epoch [5/50] batch [20/244] time 0.124 (0.181) data 0.000 (0.017) loss 1.5523 (1.4916) ce_loss 1.3564 (1.2120) teacher_loss 1.3023 (1.1908) loss_zs_kd 0.0952 (0.1383) loss_oracle 0.2024 (0.2316) acc 62.5000 (66.5625) kd_loss 0.5101 (0.5404) lr 1.9823e-03 eta 0:33:46
epoch [5/50] batch [40/244] time 0.127 (0.176) data 0.000 (0.009) loss 1.3150 (1.3858) ce_loss 1.0771 (1.1208) teacher_loss 1.0649 (1.1057) loss_zs_kd 0.1358 (0.1304) loss_oracle 0.1822 (0.2149) acc 68.7500 (69.4531) kd_loss 0.4824 (0.5264) lr 1.9823e-03 eta 0:32:51
epoch [5/50] batch [60/244] time 0.152 (0.164) data 0.001 (0.006) loss 1.3563 (1.3900) ce_loss 1.0654 (1.1229) teacher_loss 1.0537 (1.1101) loss_zs_kd 0.1541 (0.1336) loss_oracle 0.2255 (0.2132) acc 68.7500 (69.2188) kd_loss 0.4953 (0.5164) lr 1.9823e-03 eta 0:30:31
epoch [5/50] batch [80/244] time 0.172 (0.163) data 0.000 (0.005) loss 1.6008 (1.3870) ce_loss 1.3125 (1.1168) teacher_loss 1.3181 (1.1048) loss_zs_kd 0.1579 (0.1386) loss_oracle 0.2038 (0.2129) acc 68.7500 (70.1953) kd_loss 0.3780 (0.5105) lr 1.9823e-03 eta 0:30:20
epoch [5/50] batch [100/244] time 0.156 (0.162) data 0.000 (0.004) loss 1.7459 (1.3927) ce_loss 1.5303 (1.1241) teacher_loss 1.4583 (1.1104) loss_zs_kd 0.1161 (0.1390) loss_oracle 0.2296 (0.2128) acc 59.3750 (69.8438) kd_loss 0.4274 (0.5135) lr 1.9823e-03 eta 0:29:57
epoch [5/50] batch [120/244] time 0.152 (0.160) data 0.000 (0.003) loss 1.3333 (1.4125) ce_loss 1.0518 (1.1396) teacher_loss 1.0461 (1.1272) loss_zs_kd 0.1260 (0.1397) loss_oracle 0.2242 (0.2155) acc 71.8750 (69.3750) kd_loss 0.5069 (0.5190) lr 1.9823e-03 eta 0:29:33
epoch [5/50] batch [140/244] time 0.148 (0.159) data 0.000 (0.003) loss 1.5685 (1.4129) ce_loss 1.2539 (1.1394) teacher_loss 1.2451 (1.1277) loss_zs_kd 0.1205 (0.1372) loss_oracle 0.2632 (0.2165) acc 68.7500 (69.6875) kd_loss 0.5503 (0.5134) lr 1.9823e-03 eta 0:29:25
epoch [5/50] batch [160/244] time 0.152 (0.159) data 0.000 (0.002) loss 1.3648 (1.4265) ce_loss 1.0127 (1.1499) teacher_loss 1.0359 (1.1388) loss_zs_kd 0.1118 (0.1339) loss_oracle 0.2729 (0.2207) acc 78.1250 (69.3164) kd_loss 0.5993 (0.5111) lr 1.9823e-03 eta 0:29:14
epoch [5/50] batch [180/244] time 0.156 (0.158) data 0.000 (0.002) loss 1.8296 (1.4306) ce_loss 1.4424 (1.1507) teacher_loss 1.4490 (1.1392) loss_zs_kd 0.1530 (0.1323) loss_oracle 0.3041 (0.2253) acc 68.7500 (69.4965) kd_loss 0.5217 (0.5167) lr 1.9823e-03 eta 0:29:04
epoch [5/50] batch [200/244] time 0.148 (0.158) data 0.000 (0.002) loss 1.4797 (1.4323) ce_loss 1.1553 (1.1502) teacher_loss 1.1607 (1.1386) loss_zs_kd 0.1060 (0.1313) loss_oracle 0.2660 (0.2280) acc 75.0000 (69.5469) kd_loss 0.7627 (0.5208) lr 1.9823e-03 eta 0:28:56
epoch [5/50] batch [220/244] time 0.149 (0.157) data 0.000 (0.002) loss 1.8095 (1.4378) ce_loss 1.4473 (1.1513) teacher_loss 1.4484 (1.1399) loss_zs_kd 0.2092 (0.1320) loss_oracle 0.2566 (0.2319) acc 56.2500 (69.5028) kd_loss 0.5214 (0.5240) lr 1.9823e-03 eta 0:28:47
epoch [5/50] batch [240/244] time 0.172 (0.157) data 0.000 (0.002) loss 1.7737 (1.4367) ce_loss 1.4336 (1.1509) teacher_loss 1.4264 (1.1394) loss_zs_kd 0.2392 (0.1311) loss_oracle 0.2277 (0.2317) acc 62.5000 (69.6094) kd_loss 0.5239 (0.5208) lr 1.9823e-03 eta 0:28:46
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,782
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 82.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,057
* accuracy: 91.4%
* error: 8.6%
* macro_f1: 91.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.5%, epoch: 3 *******
******* Domain p best val test acc: 91.2%, epoch: 3 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [6/50] batch [20/244] time 0.158 (0.174) data 0.000 (0.016) loss 1.6256 (1.4069) ce_loss 1.3281 (1.1218) teacher_loss 1.3030 (1.0998) loss_zs_kd 0.1179 (0.1279) loss_oracle 0.2636 (0.2431) acc 75.0000 (70.9375) kd_loss 0.5095 (0.5510) lr 1.9686e-03 eta 0:31:48
epoch [6/50] batch [40/244] time 0.093 (0.149) data 0.000 (0.008) loss 1.5687 (1.4497) ce_loss 1.3242 (1.1509) teacher_loss 1.2773 (1.1355) loss_zs_kd 0.1297 (0.1317) loss_oracle 0.2266 (0.2484) acc 65.6250 (70.4688) kd_loss 0.5796 (0.5544) lr 1.9686e-03 eta 0:27:07
epoch [6/50] batch [60/244] time 0.396 (0.156) data 0.001 (0.006) loss 1.7075 (1.4402) ce_loss 1.3936 (1.1522) teacher_loss 1.3973 (1.1366) loss_zs_kd 0.1915 (0.1282) loss_oracle 0.2144 (0.2395) acc 62.5000 (70.5208) kd_loss 0.4380 (0.5363) lr 1.9686e-03 eta 0:28:24
epoch [6/50] batch [80/244] time 0.100 (0.156) data 0.000 (0.004) loss 1.3067 (1.4316) ce_loss 1.0557 (1.1508) teacher_loss 1.0885 (1.1341) loss_zs_kd 0.1170 (0.1287) loss_oracle 0.1598 (0.2332) acc 71.8750 (70.1172) kd_loss 0.5186 (0.5313) lr 1.9686e-03 eta 0:28:25
epoch [6/50] batch [100/244] time 0.102 (0.152) data 0.000 (0.004) loss 1.7438 (1.4247) ce_loss 1.4795 (1.1479) teacher_loss 1.4332 (1.1328) loss_zs_kd 0.1273 (0.1282) loss_oracle 0.2469 (0.2278) acc 53.1250 (69.8750) kd_loss 0.5743 (0.5270) lr 1.9686e-03 eta 0:27:34
epoch [6/50] batch [120/244] time 0.142 (0.153) data 0.000 (0.003) loss 1.6135 (1.4246) ce_loss 1.2881 (1.1500) teacher_loss 1.3482 (1.1370) loss_zs_kd 0.1545 (0.1284) loss_oracle 0.1881 (0.2234) acc 59.3750 (69.8177) kd_loss 0.4335 (0.5256) lr 1.9686e-03 eta 0:27:37
epoch [6/50] batch [140/244] time 0.294 (0.159) data 0.000 (0.003) loss 1.7186 (1.4412) ce_loss 1.4189 (1.1625) teacher_loss 1.4263 (1.1505) loss_zs_kd 0.1059 (0.1301) loss_oracle 0.2394 (0.2256) acc 65.6250 (69.5089) kd_loss 0.4158 (0.5262) lr 1.9686e-03 eta 0:28:39
epoch [6/50] batch [160/244] time 0.389 (0.159) data 0.000 (0.002) loss 1.2034 (1.4456) ce_loss 0.7891 (1.1613) teacher_loss 0.7868 (1.1486) loss_zs_kd 0.1541 (0.1301) loss_oracle 0.3395 (0.2319) acc 75.0000 (69.5508) kd_loss 0.7784 (0.5335) lr 1.9686e-03 eta 0:28:38
epoch [6/50] batch [180/244] time 0.116 (0.159) data 0.000 (0.002) loss 1.3059 (1.4498) ce_loss 0.9980 (1.1608) teacher_loss 0.9771 (1.1473) loss_zs_kd 0.1416 (0.1314) loss_oracle 0.2580 (0.2368) acc 71.8750 (69.5486) kd_loss 0.6701 (0.5370) lr 1.9686e-03 eta 0:28:33
epoch [6/50] batch [200/244] time 0.154 (0.155) data 0.000 (0.002) loss 1.5071 (1.4513) ce_loss 1.2148 (1.1619) teacher_loss 1.2189 (1.1489) loss_zs_kd 0.1560 (0.1318) loss_oracle 0.2102 (0.2364) acc 71.8750 (69.5781) kd_loss 0.5331 (0.5363) lr 1.9686e-03 eta 0:27:48
epoch [6/50] batch [220/244] time 0.155 (0.154) data 0.000 (0.002) loss 1.5026 (1.4549) ce_loss 1.2432 (1.1660) teacher_loss 1.2398 (1.1534) loss_zs_kd 0.1313 (0.1321) loss_oracle 0.1972 (0.2355) acc 68.7500 (69.4460) kd_loss 0.4505 (0.5330) lr 1.9686e-03 eta 0:27:42
epoch [6/50] batch [240/244] time 0.148 (0.155) data 0.000 (0.002) loss 1.6481 (1.4498) ce_loss 1.3604 (1.1599) teacher_loss 1.3108 (1.1469) loss_zs_kd 0.1358 (0.1316) loss_oracle 0.2694 (0.2371) acc 59.3750 (69.5312) kd_loss 0.5649 (0.5349) lr 1.9686e-03 eta 0:27:42
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,794
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,033
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.2%
******* Domain p best val acc:      83.8%, epoch: 6 *******
******* Domain p best val test acc: 90.9%, epoch: 6 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [7/50] batch [20/244] time 0.159 (0.179) data 0.000 (0.016) loss 1.3852 (1.5815) ce_loss 1.0918 (1.2646) teacher_loss 1.0932 (1.2494) loss_zs_kd 0.1179 (0.1347) loss_oracle 0.2331 (0.2647) acc 62.5000 (65.9375) kd_loss 0.4599 (0.5232) lr 1.9511e-03 eta 0:31:53
epoch [7/50] batch [40/244] time 0.151 (0.164) data 0.000 (0.008) loss 1.3622 (1.5035) ce_loss 0.9497 (1.1845) teacher_loss 0.9538 (1.1707) loss_zs_kd 0.1513 (0.1313) loss_oracle 0.3327 (0.2672) acc 68.7500 (68.2031) kd_loss 0.6555 (0.5382) lr 1.9511e-03 eta 0:29:17
epoch [7/50] batch [60/244] time 0.152 (0.160) data 0.000 (0.005) loss 1.2251 (1.5190) ce_loss 0.8428 (1.1913) teacher_loss 0.8356 (1.1768) loss_zs_kd 0.1038 (0.1308) loss_oracle 0.3376 (0.2768) acc 75.0000 (67.4479) kd_loss 0.5783 (0.5580) lr 1.9511e-03 eta 0:28:30
epoch [7/50] batch [80/244] time 0.155 (0.158) data 0.000 (0.004) loss 1.4779 (1.5044) ce_loss 1.1045 (1.1745) teacher_loss 1.0857 (1.1584) loss_zs_kd 0.2292 (0.1337) loss_oracle 0.2776 (0.2791) acc 68.7500 (67.9688) kd_loss 0.4997 (0.5599) lr 1.9511e-03 eta 0:28:07
epoch [7/50] batch [100/244] time 0.175 (0.158) data 0.000 (0.003) loss 1.8762 (1.5033) ce_loss 1.4287 (1.1646) teacher_loss 1.3965 (1.1489) loss_zs_kd 0.2066 (0.1351) loss_oracle 0.3765 (0.2868) acc 56.2500 (68.4688) kd_loss 0.7360 (0.5701) lr 1.9511e-03 eta 0:27:55
epoch [7/50] batch [120/244] time 0.153 (0.156) data 0.000 (0.003) loss 1.4391 (1.5102) ce_loss 1.1699 (1.1676) teacher_loss 1.1891 (1.1540) loss_zs_kd 0.1110 (0.1357) loss_oracle 0.1945 (0.2883) acc 68.7500 (68.7760) kd_loss 0.2953 (0.5676) lr 1.9511e-03 eta 0:27:41
epoch [7/50] batch [140/244] time 0.154 (0.156) data 0.000 (0.002) loss 1.0249 (1.4957) ce_loss 0.7534 (1.1570) teacher_loss 0.7445 (1.1432) loss_zs_kd 0.1379 (0.1348) loss_oracle 0.2114 (0.2850) acc 75.0000 (69.0179) kd_loss 0.4615 (0.5663) lr 1.9511e-03 eta 0:27:29
epoch [7/50] batch [160/244] time 0.145 (0.156) data 0.000 (0.002) loss 1.8719 (1.4914) ce_loss 1.5889 (1.1608) teacher_loss 1.5510 (1.1448) loss_zs_kd 0.1853 (0.1342) loss_oracle 0.2282 (0.2795) acc 65.6250 (69.1211) kd_loss 0.6489 (0.5674) lr 1.9511e-03 eta 0:27:30
epoch [7/50] batch [180/244] time 0.101 (0.155) data 0.000 (0.002) loss 1.2188 (1.4911) ce_loss 1.0059 (1.1661) teacher_loss 0.9571 (1.1492) loss_zs_kd 0.1404 (0.1358) loss_oracle 0.1915 (0.2741) acc 75.0000 (69.0972) kd_loss 0.5337 (0.5629) lr 1.9511e-03 eta 0:27:18
epoch [7/50] batch [200/244] time 0.103 (0.152) data 0.000 (0.002) loss 1.3059 (1.4804) ce_loss 1.0342 (1.1599) teacher_loss 1.0659 (1.1437) loss_zs_kd 0.1424 (0.1359) loss_oracle 0.1688 (0.2687) acc 71.8750 (69.3438) kd_loss 0.3756 (0.5608) lr 1.9511e-03 eta 0:26:38
epoch [7/50] batch [220/244] time 0.087 (0.153) data 0.000 (0.002) loss 1.5001 (1.4801) ce_loss 1.1963 (1.1640) teacher_loss 1.2264 (1.1482) loss_zs_kd 0.1543 (0.1378) loss_oracle 0.1966 (0.2629) acc 75.0000 (69.2898) kd_loss 0.6444 (0.5575) lr 1.9511e-03 eta 0:26:50
epoch [7/50] batch [240/244] time 0.085 (0.151) data 0.000 (0.002) loss 1.2812 (1.4684) ce_loss 0.9521 (1.1552) teacher_loss 0.9864 (1.1408) loss_zs_kd 0.2073 (0.1366) loss_oracle 0.1912 (0.2593) acc 65.6250 (69.5703) kd_loss 0.4923 (0.5526) lr 1.9511e-03 eta 0:26:26
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,780
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 82.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,027
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.3%
******* Domain p best val acc:      83.8%, epoch: 6 *******
******* Domain p best val test acc: 90.9%, epoch: 6 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [8/50] batch [20/244] time 0.176 (0.174) data 0.000 (0.014) loss 1.5752 (1.5232) ce_loss 1.2900 (1.2360) teacher_loss 1.2816 (1.2265) loss_zs_kd 0.1225 (0.1337) loss_oracle 0.2324 (0.2299) acc 65.6250 (66.8750) kd_loss 0.6482 (0.5359) lr 1.9298e-03 eta 0:30:27
epoch [8/50] batch [40/244] time 0.176 (0.175) data 0.000 (0.007) loss 1.3116 (1.4558) ce_loss 1.0127 (1.1583) teacher_loss 1.0239 (1.1489) loss_zs_kd 0.1290 (0.1452) loss_oracle 0.2231 (0.2343) acc 75.0000 (69.2969) kd_loss 0.5754 (0.5480) lr 1.9298e-03 eta 0:30:28
epoch [8/50] batch [60/244] time 0.155 (0.174) data 0.000 (0.005) loss 1.2611 (1.4405) ce_loss 1.0166 (1.1493) teacher_loss 0.9486 (1.1371) loss_zs_kd 0.1515 (0.1431) loss_oracle 0.2367 (0.2318) acc 75.0000 (69.6354) kd_loss 0.5796 (0.5461) lr 1.9298e-03 eta 0:30:15
epoch [8/50] batch [80/244] time 0.155 (0.171) data 0.000 (0.004) loss 1.5494 (1.4300) ce_loss 1.2061 (1.1381) teacher_loss 1.2248 (1.1263) loss_zs_kd 0.2051 (0.1448) loss_oracle 0.2221 (0.2313) acc 75.0000 (69.7266) kd_loss 0.5753 (0.5421) lr 1.9298e-03 eta 0:29:37
epoch [8/50] batch [100/244] time 0.180 (0.169) data 0.000 (0.003) loss 1.1734 (1.4434) ce_loss 0.9390 (1.1506) teacher_loss 0.9384 (1.1379) loss_zs_kd 0.1274 (0.1451) loss_oracle 0.1713 (0.2330) acc 78.1250 (69.2500) kd_loss 0.5626 (0.5424) lr 1.9298e-03 eta 0:29:14
epoch [8/50] batch [120/244] time 0.150 (0.168) data 0.000 (0.003) loss 1.3312 (1.4349) ce_loss 1.0566 (1.1408) teacher_loss 1.0323 (1.1300) loss_zs_kd 0.1168 (0.1462) loss_oracle 0.2405 (0.2319) acc 75.0000 (69.6094) kd_loss 0.7111 (0.5464) lr 1.9298e-03 eta 0:28:58
epoch [8/50] batch [140/244] time 0.154 (0.165) data 0.000 (0.002) loss 1.7645 (1.4503) ce_loss 1.4775 (1.1572) teacher_loss 1.4203 (1.1462) loss_zs_kd 0.1457 (0.1440) loss_oracle 0.2713 (0.2321) acc 65.6250 (69.3527) kd_loss 0.5382 (0.5459) lr 1.9298e-03 eta 0:28:31
epoch [8/50] batch [160/244] time 0.152 (0.164) data 0.000 (0.002) loss 1.7717 (1.4407) ce_loss 1.4023 (1.1473) teacher_loss 1.4229 (1.1360) loss_zs_kd 0.1576 (0.1435) loss_oracle 0.2701 (0.2331) acc 65.6250 (69.7070) kd_loss 0.5613 (0.5470) lr 1.9298e-03 eta 0:28:12
epoch [8/50] batch [180/244] time 0.153 (0.163) data 0.000 (0.002) loss 1.2179 (1.4333) ce_loss 0.9214 (1.1429) teacher_loss 0.8520 (1.1296) loss_zs_kd 0.1925 (0.1425) loss_oracle 0.2696 (0.2324) acc 78.1250 (69.9306) kd_loss 0.5618 (0.5440) lr 1.9298e-03 eta 0:27:57
epoch [8/50] batch [200/244] time 0.150 (0.162) data 0.000 (0.002) loss 1.4100 (1.4321) ce_loss 1.1592 (1.1441) teacher_loss 1.1579 (1.1308) loss_zs_kd 0.1204 (0.1418) loss_oracle 0.1919 (0.2305) acc 71.8750 (70.2500) kd_loss 0.5576 (0.5420) lr 1.9298e-03 eta 0:27:43
epoch [8/50] batch [220/244] time 0.162 (0.161) data 0.000 (0.002) loss 1.4265 (1.4295) ce_loss 1.1602 (1.1421) teacher_loss 1.1496 (1.1278) loss_zs_kd 0.1319 (0.1417) loss_oracle 0.2110 (0.2308) acc 65.6250 (70.1136) kd_loss 0.5569 (0.5413) lr 1.9298e-03 eta 0:27:38
epoch [8/50] batch [240/244] time 0.172 (0.162) data 0.000 (0.001) loss 1.6623 (1.4338) ce_loss 1.3828 (1.1460) teacher_loss 1.3714 (1.1318) loss_zs_kd 0.1409 (0.1411) loss_oracle 0.2205 (0.2314) acc 65.6250 (70.0000) kd_loss 0.4518 (0.5420) lr 1.9298e-03 eta 0:27:36
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,798
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 82.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,046
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      83.9%, epoch: 8 *******
******* Domain p best val test acc: 91.1%, epoch: 8 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [9/50] batch [20/244] time 0.100 (0.161) data 0.000 (0.014) loss 1.7211 (1.5771) ce_loss 1.4385 (1.2784) teacher_loss 1.4478 (1.2639) loss_zs_kd 0.1203 (0.1484) loss_oracle 0.2132 (0.2390) acc 62.5000 (69.0625) kd_loss 0.5259 (0.5318) lr 1.9048e-03 eta 0:27:30
epoch [9/50] batch [40/244] time 0.084 (0.152) data 0.000 (0.007) loss 1.5738 (1.4736) ce_loss 1.3105 (1.1833) teacher_loss 1.2845 (1.1691) loss_zs_kd 0.0951 (0.1347) loss_oracle 0.2417 (0.2372) acc 62.5000 (70.6250) kd_loss 0.4687 (0.5370) lr 1.9048e-03 eta 0:25:47
epoch [9/50] batch [60/244] time 0.084 (0.155) data 0.001 (0.005) loss 2.0249 (1.4641) ce_loss 1.6855 (1.1757) teacher_loss 1.7080 (1.1597) loss_zs_kd 0.1752 (0.1380) loss_oracle 0.2292 (0.2354) acc 62.5000 (70.6250) kd_loss 0.6249 (0.5336) lr 1.9048e-03 eta 0:26:22
epoch [9/50] batch [80/244] time 0.097 (0.158) data 0.000 (0.004) loss 1.9000 (1.4824) ce_loss 1.6064 (1.1856) teacher_loss 1.6097 (1.1702) loss_zs_kd 0.1093 (0.1420) loss_oracle 0.2356 (0.2412) acc 56.2500 (69.8828) kd_loss 0.6360 (0.5436) lr 1.9048e-03 eta 0:26:49
epoch [9/50] batch [100/244] time 0.089 (0.160) data 0.000 (0.003) loss 1.1499 (1.4753) ce_loss 0.8882 (1.1726) teacher_loss 0.8335 (1.1582) loss_zs_kd 0.1159 (0.1401) loss_oracle 0.2585 (0.2471) acc 71.8750 (69.9688) kd_loss 0.5084 (0.5485) lr 1.9048e-03 eta 0:27:02
epoch [9/50] batch [120/244] time 0.160 (0.157) data 0.000 (0.003) loss 1.8614 (1.4763) ce_loss 1.5850 (1.1718) teacher_loss 1.5891 (1.1572) loss_zs_kd 0.1142 (0.1405) loss_oracle 0.2152 (0.2488) acc 59.3750 (69.8177) kd_loss 0.3655 (0.5454) lr 1.9048e-03 eta 0:26:27
epoch [9/50] batch [140/244] time 0.174 (0.158) data 0.000 (0.002) loss 1.2114 (1.4825) ce_loss 0.9814 (1.1816) teacher_loss 0.9711 (1.1672) loss_zs_kd 0.0894 (0.1407) loss_oracle 0.1956 (0.2449) acc 71.8750 (69.5536) kd_loss 0.4631 (0.5404) lr 1.9048e-03 eta 0:26:32
epoch [9/50] batch [160/244] time 0.151 (0.157) data 0.000 (0.002) loss 0.9952 (1.4704) ce_loss 0.7485 (1.1709) teacher_loss 0.6997 (1.1563) loss_zs_kd 0.1348 (0.1417) loss_oracle 0.2282 (0.2432) acc 84.3750 (69.8242) kd_loss 0.4192 (0.5358) lr 1.9048e-03 eta 0:26:27
epoch [9/50] batch [180/244] time 0.153 (0.157) data 0.000 (0.002) loss 1.5455 (1.4633) ce_loss 1.2812 (1.1665) teacher_loss 1.2520 (1.1509) loss_zs_kd 0.1562 (0.1418) loss_oracle 0.2154 (0.2415) acc 68.7500 (69.7049) kd_loss 0.4579 (0.5335) lr 1.9048e-03 eta 0:26:18
epoch [9/50] batch [200/244] time 0.153 (0.157) data 0.000 (0.002) loss 1.4523 (1.4590) ce_loss 1.1924 (1.1658) teacher_loss 1.1797 (1.1493) loss_zs_kd 0.1187 (0.1423) loss_oracle 0.2131 (0.2386) acc 68.7500 (69.7188) kd_loss 0.6021 (0.5311) lr 1.9048e-03 eta 0:26:12
epoch [9/50] batch [220/244] time 0.150 (0.156) data 0.000 (0.002) loss 1.7683 (1.4574) ce_loss 1.4297 (1.1653) teacher_loss 1.4115 (1.1483) loss_zs_kd 0.1906 (0.1424) loss_oracle 0.2615 (0.2379) acc 75.0000 (69.8438) kd_loss 0.5989 (0.5296) lr 1.9048e-03 eta 0:26:07
epoch [9/50] batch [240/244] time 0.150 (0.156) data 0.000 (0.001) loss 1.7485 (1.4579) ce_loss 1.4385 (1.1637) teacher_loss 1.4332 (1.1473) loss_zs_kd 0.1635 (0.1427) loss_oracle 0.2335 (0.2392) acc 65.6250 (69.9349) kd_loss 0.4694 (0.5329) lr 1.9048e-03 eta 0:26:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,798
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 82.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,046
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      83.9%, epoch: 8 *******
******* Domain p best val test acc: 91.1%, epoch: 8 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [10/50] batch [20/244] time 0.179 (0.180) data 0.000 (0.013) loss 1.3415 (1.3990) ce_loss 1.0713 (1.1012) teacher_loss 1.0053 (1.0832) loss_zs_kd 0.1195 (0.1224) loss_oracle 0.2765 (0.2546) acc 65.6250 (71.2500) kd_loss 0.4810 (0.5638) lr 1.8763e-03 eta 0:30:01
epoch [10/50] batch [40/244] time 0.180 (0.175) data 0.000 (0.007) loss 1.3672 (1.3971) ce_loss 1.0254 (1.1032) teacher_loss 1.0488 (1.0894) loss_zs_kd 0.1714 (0.1354) loss_oracle 0.2327 (0.2400) acc 81.2500 (71.3281) kd_loss 0.5613 (0.5301) lr 1.8763e-03 eta 0:29:02
epoch [10/50] batch [60/244] time 0.183 (0.176) data 0.000 (0.004) loss 1.4226 (1.4042) ce_loss 1.2080 (1.1087) teacher_loss 1.1768 (1.0964) loss_zs_kd 0.1240 (0.1344) loss_oracle 0.1839 (0.2405) acc 68.7500 (70.7292) kd_loss 0.3321 (0.5332) lr 1.8763e-03 eta 0:29:09
epoch [10/50] batch [80/244] time 0.091 (0.161) data 0.000 (0.003) loss 1.4852 (1.4268) ce_loss 1.1436 (1.1310) teacher_loss 1.1529 (1.1202) loss_zs_kd 0.1041 (0.1323) loss_oracle 0.2803 (0.2405) acc 59.3750 (69.9609) kd_loss 0.6226 (0.5373) lr 1.8763e-03 eta 0:26:42
epoch [10/50] batch [100/244] time 0.094 (0.163) data 0.000 (0.003) loss 1.5336 (1.4343) ce_loss 1.2764 (1.1389) teacher_loss 1.2017 (1.1274) loss_zs_kd 0.1540 (0.1347) loss_oracle 0.2549 (0.2396) acc 59.3750 (69.6562) kd_loss 0.5956 (0.5377) lr 1.8763e-03 eta 0:26:56
epoch [10/50] batch [120/244] time 0.091 (0.161) data 0.000 (0.002) loss 1.7010 (1.4445) ce_loss 1.3945 (1.1472) teacher_loss 1.3770 (1.1345) loss_zs_kd 0.1345 (0.1399) loss_oracle 0.2568 (0.2401) acc 65.6250 (69.4792) kd_loss 0.5274 (0.5345) lr 1.8763e-03 eta 0:26:33
epoch [10/50] batch [140/244] time 0.198 (0.159) data 0.000 (0.002) loss 1.3058 (1.4510) ce_loss 1.0293 (1.1513) teacher_loss 0.9990 (1.1368) loss_zs_kd 0.1288 (0.1415) loss_oracle 0.2424 (0.2434) acc 75.0000 (69.1741) kd_loss 0.4938 (0.5353) lr 1.8763e-03 eta 0:26:09
epoch [10/50] batch [160/244] time 0.225 (0.162) data 0.000 (0.002) loss 1.1467 (1.4400) ce_loss 0.8496 (1.1363) teacher_loss 0.8141 (1.1216) loss_zs_kd 0.0827 (0.1413) loss_oracle 0.2913 (0.2478) acc 75.0000 (69.7070) kd_loss 0.4450 (0.5398) lr 1.8763e-03 eta 0:26:34
epoch [10/50] batch [180/244] time 0.100 (0.161) data 0.000 (0.002) loss 1.5386 (1.4396) ce_loss 1.2646 (1.1334) teacher_loss 1.1880 (1.1188) loss_zs_kd 0.1423 (0.1421) loss_oracle 0.2794 (0.2497) acc 68.7500 (69.8438) kd_loss 0.5696 (0.5439) lr 1.8763e-03 eta 0:26:20
epoch [10/50] batch [200/244] time 0.084 (0.162) data 0.000 (0.002) loss 1.4725 (1.4538) ce_loss 1.1699 (1.1443) teacher_loss 1.1671 (1.1301) loss_zs_kd 0.1507 (0.1438) loss_oracle 0.2301 (0.2518) acc 68.7500 (69.5938) kd_loss 0.4502 (0.5409) lr 1.8763e-03 eta 0:26:23
epoch [10/50] batch [220/244] time 0.099 (0.159) data 0.000 (0.001) loss 1.3524 (1.4616) ce_loss 1.0000 (1.1517) teacher_loss 0.9920 (1.1376) loss_zs_kd 0.1889 (0.1438) loss_oracle 0.2660 (0.2521) acc 75.0000 (69.5028) kd_loss 0.6218 (0.5435) lr 1.8763e-03 eta 0:25:57
epoch [10/50] batch [240/244] time 0.154 (0.158) data 0.000 (0.001) loss 2.0189 (1.4669) ce_loss 1.6289 (1.1549) teacher_loss 1.6693 (1.1425) loss_zs_kd 0.1862 (0.1447) loss_oracle 0.2565 (0.2521) acc 56.2500 (69.3490) kd_loss 0.5679 (0.5459) lr 1.8763e-03 eta 0:25:44
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,796
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 82.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,052
* accuracy: 91.3%
* error: 8.7%
* macro_f1: 90.8%
******* Domain p best val acc:      83.9%, epoch: 8 *******
******* Domain p best val test acc: 91.1%, epoch: 8 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [11/50] batch [20/244] time 0.171 (0.189) data 0.000 (0.013) loss 1.0226 (1.3934) ce_loss 0.8101 (1.1175) teacher_loss 0.7896 (1.1094) loss_zs_kd 0.1078 (0.1312) loss_oracle 0.1791 (0.2184) acc 75.0000 (70.3125) kd_loss 0.3032 (0.5050) lr 1.8443e-03 eta 0:30:41
epoch [11/50] batch [40/244] time 0.174 (0.177) data 0.000 (0.007) loss 1.4613 (1.4031) ce_loss 1.1201 (1.1247) teacher_loss 1.1307 (1.1115) loss_zs_kd 0.1405 (0.1353) loss_oracle 0.2603 (0.2240) acc 71.8750 (70.2344) kd_loss 0.5201 (0.5101) lr 1.8443e-03 eta 0:28:36
epoch [11/50] batch [60/244] time 0.176 (0.174) data 0.000 (0.005) loss 1.1559 (1.4097) ce_loss 0.9307 (1.1295) teacher_loss 0.9236 (1.1170) loss_zs_kd 0.1195 (0.1399) loss_oracle 0.1725 (0.2228) acc 75.0000 (70.2604) kd_loss 0.4630 (0.5166) lr 1.8443e-03 eta 0:28:03
epoch [11/50] batch [80/244] time 0.160 (0.172) data 0.000 (0.003) loss 1.3680 (1.4076) ce_loss 1.1172 (1.1287) teacher_loss 1.1017 (1.1156) loss_zs_kd 0.1253 (0.1404) loss_oracle 0.2036 (0.2218) acc 71.8750 (70.2344) kd_loss 0.4938 (0.5211) lr 1.8443e-03 eta 0:27:40
epoch [11/50] batch [100/244] time 0.167 (0.171) data 0.000 (0.003) loss 1.4582 (1.3926) ce_loss 1.1201 (1.1125) teacher_loss 1.1175 (1.0989) loss_zs_kd 0.1712 (0.1407) loss_oracle 0.2551 (0.2234) acc 65.6250 (70.3750) kd_loss 0.6597 (0.5213) lr 1.8443e-03 eta 0:27:30
epoch [11/50] batch [120/244] time 0.149 (0.170) data 0.000 (0.002) loss 1.2097 (1.4085) ce_loss 0.9707 (1.1265) teacher_loss 0.9668 (1.1113) loss_zs_kd 0.0969 (0.1427) loss_oracle 0.1944 (0.2258) acc 75.0000 (70.2865) kd_loss 0.5485 (0.5238) lr 1.8443e-03 eta 0:27:23
epoch [11/50] batch [140/244] time 0.145 (0.170) data 0.000 (0.002) loss 0.9268 (1.4140) ce_loss 0.6387 (1.1333) teacher_loss 0.6504 (1.1182) loss_zs_kd 0.0751 (0.1402) loss_oracle 0.2389 (0.2257) acc 84.3750 (70.1786) kd_loss 0.6424 (0.5248) lr 1.8443e-03 eta 0:27:18
epoch [11/50] batch [160/244] time 0.090 (0.165) data 0.000 (0.002) loss 1.4091 (1.4223) ce_loss 1.0928 (1.1443) teacher_loss 1.1061 (1.1294) loss_zs_kd 0.1517 (0.1395) loss_oracle 0.2271 (0.2231) acc 78.1250 (69.9609) kd_loss 0.5711 (0.5220) lr 1.8443e-03 eta 0:26:24
epoch [11/50] batch [180/244] time 0.088 (0.163) data 0.000 (0.002) loss 1.2712 (1.4168) ce_loss 1.0078 (1.1387) teacher_loss 0.9952 (1.1243) loss_zs_kd 0.1243 (0.1386) loss_oracle 0.2139 (0.2232) acc 75.0000 (70.0521) kd_loss 0.5722 (0.5199) lr 1.8443e-03 eta 0:26:00
epoch [11/50] batch [200/244] time 0.083 (0.163) data 0.000 (0.002) loss 1.4861 (1.4155) ce_loss 1.2256 (1.1368) teacher_loss 1.2140 (1.1209) loss_zs_kd 0.0792 (0.1383) loss_oracle 0.2325 (0.2255) acc 68.7500 (69.9688) kd_loss 0.4726 (0.5194) lr 1.8443e-03 eta 0:25:57
epoch [11/50] batch [220/244] time 0.334 (0.158) data 0.000 (0.001) loss 0.8920 (1.4037) ce_loss 0.5962 (1.1229) teacher_loss 0.5637 (1.1077) loss_zs_kd 0.1033 (0.1378) loss_oracle 0.2767 (0.2271) acc 90.6250 (70.4261) kd_loss 0.7058 (0.5221) lr 1.8443e-03 eta 0:25:06
epoch [11/50] batch [240/244] time 0.292 (0.158) data 0.000 (0.001) loss 1.2802 (1.4056) ce_loss 0.8735 (1.1229) teacher_loss 0.8997 (1.1075) loss_zs_kd 0.1531 (0.1376) loss_oracle 0.3039 (0.2293) acc 78.1250 (70.5859) kd_loss 0.6695 (0.5265) lr 1.8443e-03 eta 0:25:06
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,804
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.1%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,048
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.7%
******* Domain p best val acc:      84.1%, epoch: 11 *******
******* Domain p best val test acc: 91.2%, epoch: 11 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [12/50] batch [20/244] time 0.152 (0.187) data 0.000 (0.016) loss 1.5465 (1.3548) ce_loss 1.2383 (1.0548) teacher_loss 1.2278 (1.0344) loss_zs_kd 0.1873 (0.1449) loss_oracle 0.2251 (0.2479) acc 68.7500 (72.0312) kd_loss 0.6173 (0.5180) lr 1.8090e-03 eta 0:29:31
epoch [12/50] batch [40/244] time 0.141 (0.172) data 0.000 (0.008) loss 1.3033 (1.3904) ce_loss 1.0088 (1.0862) teacher_loss 0.9863 (1.0661) loss_zs_kd 0.1300 (0.1451) loss_oracle 0.2519 (0.2517) acc 75.0000 (71.2500) kd_loss 0.6846 (0.5264) lr 1.8090e-03 eta 0:27:11
epoch [12/50] batch [60/244] time 0.154 (0.165) data 0.001 (0.005) loss 1.3989 (1.4097) ce_loss 1.0781 (1.1078) teacher_loss 1.0727 (1.0905) loss_zs_kd 0.1028 (0.1412) loss_oracle 0.2748 (0.2486) acc 71.8750 (71.4583) kd_loss 0.6499 (0.5376) lr 1.8090e-03 eta 0:26:04
epoch [12/50] batch [80/244] time 0.184 (0.163) data 0.000 (0.004) loss 1.1418 (1.4341) ce_loss 0.9038 (1.1307) teacher_loss 0.8623 (1.1149) loss_zs_kd 0.1124 (0.1432) loss_oracle 0.2233 (0.2476) acc 78.1250 (70.8594) kd_loss 0.3877 (0.5317) lr 1.8090e-03 eta 0:25:40
epoch [12/50] batch [100/244] time 0.168 (0.163) data 0.000 (0.003) loss 1.5941 (1.4311) ce_loss 1.2998 (1.1294) teacher_loss 1.2822 (1.1155) loss_zs_kd 0.1536 (0.1435) loss_oracle 0.2352 (0.2439) acc 59.3750 (70.6250) kd_loss 0.5881 (0.5351) lr 1.8090e-03 eta 0:25:38
epoch [12/50] batch [120/244] time 0.153 (0.162) data 0.000 (0.003) loss 1.3389 (1.4306) ce_loss 0.9883 (1.1318) teacher_loss 0.9985 (1.1170) loss_zs_kd 0.2127 (0.1430) loss_oracle 0.2340 (0.2420) acc 71.8750 (70.5208) kd_loss 0.5303 (0.5358) lr 1.8090e-03 eta 0:25:26
epoch [12/50] batch [140/244] time 0.150 (0.162) data 0.000 (0.002) loss 1.7094 (1.4430) ce_loss 1.4336 (1.1460) teacher_loss 1.4047 (1.1289) loss_zs_kd 0.1494 (0.1453) loss_oracle 0.2300 (0.2414) acc 62.5000 (70.2902) kd_loss 0.5507 (0.5352) lr 1.8090e-03 eta 0:25:15
epoch [12/50] batch [160/244] time 0.156 (0.161) data 0.000 (0.002) loss 1.5644 (1.4334) ce_loss 1.2832 (1.1380) teacher_loss 1.2543 (1.1202) loss_zs_kd 0.1524 (0.1454) loss_oracle 0.2338 (0.2405) acc 68.7500 (70.4102) kd_loss 0.4703 (0.5310) lr 1.8090e-03 eta 0:25:01
epoch [12/50] batch [180/244] time 0.176 (0.160) data 0.000 (0.002) loss 1.5220 (1.4347) ce_loss 1.2637 (1.1397) teacher_loss 1.2042 (1.1217) loss_zs_kd 0.2480 (0.1474) loss_oracle 0.1938 (0.2393) acc 71.8750 (70.5556) kd_loss 0.3984 (0.5324) lr 1.8090e-03 eta 0:24:55
epoch [12/50] batch [200/244] time 0.156 (0.160) data 0.000 (0.002) loss 1.5888 (1.4284) ce_loss 1.2334 (1.1334) teacher_loss 1.2092 (1.1157) loss_zs_kd 0.1886 (0.1473) loss_oracle 0.2852 (0.2390) acc 68.7500 (70.6719) kd_loss 0.5690 (0.5323) lr 1.8090e-03 eta 0:24:53
epoch [12/50] batch [220/244] time 0.156 (0.160) data 0.000 (0.002) loss 1.6705 (1.4307) ce_loss 1.3281 (1.1333) teacher_loss 1.3089 (1.1157) loss_zs_kd 0.1175 (0.1482) loss_oracle 0.3028 (0.2409) acc 65.6250 (70.6960) kd_loss 0.6500 (0.5348) lr 1.8090e-03 eta 0:24:46
epoch [12/50] batch [240/244] time 0.152 (0.159) data 0.000 (0.002) loss 1.2019 (1.4238) ce_loss 0.9277 (1.1264) teacher_loss 0.8898 (1.1090) loss_zs_kd 0.1147 (0.1483) loss_oracle 0.2547 (0.2406) acc 78.1250 (70.8333) kd_loss 0.6017 (0.5344) lr 1.8090e-03 eta 0:24:38
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,803
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,045
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      84.1%, epoch: 11 *******
******* Domain p best val test acc: 91.2%, epoch: 11 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [13/50] batch [20/244] time 0.103 (0.160) data 0.000 (0.013) loss 1.0312 (1.3334) ce_loss 0.7046 (1.0395) teacher_loss 0.6833 (1.0237) loss_zs_kd 0.1355 (0.1401) loss_oracle 0.2801 (0.2397) acc 84.3750 (72.3438) kd_loss 0.5339 (0.5223) lr 1.7705e-03 eta 0:24:37
epoch [13/50] batch [40/244] time 0.110 (0.170) data 0.000 (0.007) loss 1.2864 (1.3575) ce_loss 1.0146 (1.0719) teacher_loss 0.9517 (1.0501) loss_zs_kd 0.1962 (0.1484) loss_oracle 0.2366 (0.2332) acc 75.0000 (70.6250) kd_loss 0.6081 (0.5145) lr 1.7705e-03 eta 0:26:11
epoch [13/50] batch [60/244] time 0.277 (0.172) data 0.001 (0.005) loss 1.3007 (1.3766) ce_loss 1.0410 (1.0944) teacher_loss 1.0049 (1.0682) loss_zs_kd 0.1887 (0.1492) loss_oracle 0.2015 (0.2337) acc 71.8750 (70.6250) kd_loss 0.3993 (0.5175) lr 1.7705e-03 eta 0:26:22
epoch [13/50] batch [80/244] time 0.376 (0.173) data 0.001 (0.004) loss 2.0187 (1.4082) ce_loss 1.6816 (1.1247) teacher_loss 1.7312 (1.1024) loss_zs_kd 0.1375 (0.1498) loss_oracle 0.2188 (0.2308) acc 46.8750 (70.0000) kd_loss 0.5825 (0.5167) lr 1.7705e-03 eta 0:26:26
epoch [13/50] batch [100/244] time 0.181 (0.166) data 0.000 (0.003) loss 1.8281 (1.4125) ce_loss 1.5732 (1.1303) teacher_loss 1.5715 (1.1084) loss_zs_kd 0.1242 (0.1496) loss_oracle 0.1945 (0.2293) acc 59.3750 (69.6875) kd_loss 0.4102 (0.5234) lr 1.7705e-03 eta 0:25:21
epoch [13/50] batch [120/244] time 0.163 (0.166) data 0.000 (0.002) loss 1.5639 (1.4090) ce_loss 1.2803 (1.1250) teacher_loss 1.2658 (1.1028) loss_zs_kd 0.1446 (0.1497) loss_oracle 0.2258 (0.2313) acc 71.8750 (70.0260) kd_loss 0.5059 (0.5354) lr 1.7705e-03 eta 0:25:18
epoch [13/50] batch [140/244] time 0.178 (0.167) data 0.000 (0.002) loss 1.7879 (1.4228) ce_loss 1.5176 (1.1357) teacher_loss 1.4742 (1.1158) loss_zs_kd 0.1938 (0.1529) loss_oracle 0.2168 (0.2305) acc 65.6250 (70.1562) kd_loss 0.4342 (0.5366) lr 1.7705e-03 eta 0:25:26
epoch [13/50] batch [160/244] time 0.160 (0.167) data 0.000 (0.002) loss 1.8025 (1.4108) ce_loss 1.5352 (1.1256) teacher_loss 1.5088 (1.1075) loss_zs_kd 0.1431 (0.1507) loss_oracle 0.2221 (0.2280) acc 62.5000 (70.4102) kd_loss 0.3678 (0.5336) lr 1.7705e-03 eta 0:25:22
epoch [13/50] batch [180/244] time 0.158 (0.167) data 0.000 (0.002) loss 1.5759 (1.4125) ce_loss 1.2285 (1.1299) teacher_loss 1.2316 (1.1103) loss_zs_kd 0.1806 (0.1503) loss_oracle 0.2540 (0.2271) acc 75.0000 (70.3819) kd_loss 0.6541 (0.5331) lr 1.7705e-03 eta 0:25:17
epoch [13/50] batch [200/244] time 0.149 (0.167) data 0.000 (0.002) loss 1.4208 (1.4134) ce_loss 1.1240 (1.1321) teacher_loss 1.1062 (1.1120) loss_zs_kd 0.1513 (0.1494) loss_oracle 0.2389 (0.2268) acc 65.6250 (70.2344) kd_loss 0.4873 (0.5309) lr 1.7705e-03 eta 0:25:12
epoch [13/50] batch [220/244] time 0.158 (0.167) data 0.000 (0.001) loss 0.9422 (1.4028) ce_loss 0.5977 (1.1232) teacher_loss 0.6254 (1.1028) loss_zs_kd 0.1759 (0.1490) loss_oracle 0.2288 (0.2255) acc 90.6250 (70.5540) kd_loss 0.6330 (0.5293) lr 1.7705e-03 eta 0:25:07
epoch [13/50] batch [240/244] time 0.150 (0.166) data 0.000 (0.001) loss 1.6152 (1.3998) ce_loss 1.3457 (1.1205) teacher_loss 1.3492 (1.1009) loss_zs_kd 0.1529 (0.1487) loss_oracle 0.1895 (0.2246) acc 65.6250 (70.6250) kd_loss 0.4362 (0.5263) lr 1.7705e-03 eta 0:25:03
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,794
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      84.1%, epoch: 11 *******
******* Domain p best val test acc: 91.2%, epoch: 11 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [14/50] batch [20/244] time 0.158 (0.182) data 0.000 (0.015) loss 1.2928 (1.3926) ce_loss 0.9868 (1.1180) teacher_loss 0.9516 (1.1045) loss_zs_kd 0.2016 (0.1519) loss_oracle 0.2404 (0.2122) acc 68.7500 (69.2188) kd_loss 0.5268 (0.5016) lr 1.7290e-03 eta 0:27:16
epoch [14/50] batch [40/244] time 0.389 (0.152) data 0.000 (0.008) loss 1.2332 (1.3998) ce_loss 0.9448 (1.1239) teacher_loss 0.9471 (1.1100) loss_zs_kd 0.1471 (0.1543) loss_oracle 0.2125 (0.2126) acc 81.2500 (69.6875) kd_loss 0.5159 (0.5063) lr 1.7290e-03 eta 0:22:45
epoch [14/50] batch [60/244] time 0.092 (0.152) data 0.001 (0.005) loss 1.3475 (1.3997) ce_loss 1.0254 (1.1153) teacher_loss 1.0280 (1.1055) loss_zs_kd 0.1280 (0.1538) loss_oracle 0.2555 (0.2173) acc 84.3750 (70.3125) kd_loss 0.5720 (0.5250) lr 1.7290e-03 eta 0:22:45
epoch [14/50] batch [80/244] time 0.091 (0.150) data 0.000 (0.004) loss 1.2890 (1.3740) ce_loss 0.9951 (1.0868) teacher_loss 1.0061 (1.0789) loss_zs_kd 0.1181 (0.1531) loss_oracle 0.2238 (0.2185) acc 75.0000 (71.0938) kd_loss 0.4907 (0.5343) lr 1.7290e-03 eta 0:22:24
epoch [14/50] batch [100/244] time 0.097 (0.146) data 0.000 (0.003) loss 1.5067 (1.3620) ce_loss 1.2285 (1.0782) teacher_loss 1.2046 (1.0698) loss_zs_kd 0.1281 (0.1503) loss_oracle 0.2381 (0.2170) acc 65.6250 (71.4062) kd_loss 0.6317 (0.5263) lr 1.7290e-03 eta 0:21:47
epoch [14/50] batch [120/244] time 0.096 (0.150) data 0.000 (0.003) loss 1.2464 (1.3472) ce_loss 0.9458 (1.0637) teacher_loss 0.9511 (1.0526) loss_zs_kd 0.1061 (0.1489) loss_oracle 0.2423 (0.2202) acc 81.2500 (71.7708) kd_loss 0.6295 (0.5264) lr 1.7290e-03 eta 0:22:17
epoch [14/50] batch [140/244] time 0.379 (0.156) data 0.001 (0.002) loss 1.6745 (1.3548) ce_loss 1.3838 (1.0707) teacher_loss 1.3379 (1.0591) loss_zs_kd 0.1725 (0.1502) loss_oracle 0.2503 (0.2207) acc 62.5000 (71.6741) kd_loss 0.5244 (0.5254) lr 1.7290e-03 eta 0:23:09
epoch [14/50] batch [160/244] time 0.097 (0.160) data 0.000 (0.002) loss 1.6185 (1.3639) ce_loss 1.2842 (1.0780) teacher_loss 1.2860 (1.0669) loss_zs_kd 0.1911 (0.1519) loss_oracle 0.2370 (0.2211) acc 71.8750 (71.5234) kd_loss 0.5666 (0.5262) lr 1.7290e-03 eta 0:23:40
epoch [14/50] batch [180/244] time 0.164 (0.159) data 0.000 (0.002) loss 1.4705 (1.3541) ce_loss 1.1943 (1.0685) teacher_loss 1.1494 (1.0565) loss_zs_kd 0.0924 (0.1504) loss_oracle 0.2750 (0.2224) acc 68.7500 (71.7188) kd_loss 0.5637 (0.5214) lr 1.7290e-03 eta 0:23:24
epoch [14/50] batch [200/244] time 0.167 (0.160) data 0.000 (0.002) loss 1.2630 (1.3542) ce_loss 0.9795 (1.0702) teacher_loss 0.9476 (1.0562) loss_zs_kd 0.1346 (0.1491) loss_oracle 0.2481 (0.2235) acc 71.8750 (71.6875) kd_loss 0.5810 (0.5197) lr 1.7290e-03 eta 0:23:29
epoch [14/50] batch [220/244] time 0.145 (0.160) data 0.000 (0.002) loss 1.0124 (1.3492) ce_loss 0.7476 (1.0642) teacher_loss 0.6951 (1.0504) loss_zs_kd 0.1365 (0.1498) loss_oracle 0.2490 (0.2239) acc 84.3750 (71.9034) kd_loss 0.6218 (0.5206) lr 1.7290e-03 eta 0:23:30
epoch [14/50] batch [240/244] time 0.150 (0.159) data 0.000 (0.002) loss 1.4785 (1.3616) ce_loss 1.1582 (1.0747) teacher_loss 1.1457 (1.0614) loss_zs_kd 0.1596 (0.1489) loss_oracle 0.2530 (0.2258) acc 65.6250 (71.5625) kd_loss 0.6110 (0.5258) lr 1.7290e-03 eta 0:23:20
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,810
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.2%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,032
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
******* Domain p best val acc:      84.3%, epoch: 14 *******
******* Domain p best val test acc: 90.8%, epoch: 14 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [15/50] batch [20/244] time 0.168 (0.175) data 0.000 (0.014) loss 1.1072 (1.3984) ce_loss 0.8218 (1.1004) teacher_loss 0.7952 (1.0817) loss_zs_kd 0.1048 (0.1340) loss_oracle 0.2596 (0.2496) acc 81.2500 (71.7188) kd_loss 0.5383 (0.5601) lr 1.6845e-03 eta 0:25:37
epoch [15/50] batch [40/244] time 0.147 (0.165) data 0.000 (0.007) loss 1.1037 (1.4146) ce_loss 0.8027 (1.1277) teacher_loss 0.8084 (1.1012) loss_zs_kd 0.1288 (0.1423) loss_oracle 0.2308 (0.2423) acc 71.8750 (70.2344) kd_loss 0.6205 (0.5649) lr 1.6845e-03 eta 0:23:59
epoch [15/50] batch [60/244] time 0.167 (0.162) data 0.000 (0.005) loss 0.8332 (1.3910) ce_loss 0.5601 (1.1175) teacher_loss 0.5172 (1.0864) loss_zs_kd 0.1389 (0.1442) loss_oracle 0.2466 (0.2324) acc 81.2500 (70.6250) kd_loss 0.6504 (0.5466) lr 1.6845e-03 eta 0:23:34
epoch [15/50] batch [80/244] time 0.163 (0.162) data 0.000 (0.004) loss 1.6595 (1.3844) ce_loss 1.3926 (1.1106) teacher_loss 1.3869 (1.0843) loss_zs_kd 0.1387 (0.1453) loss_oracle 0.2033 (0.2274) acc 68.7500 (70.7422) kd_loss 0.5537 (0.5384) lr 1.6845e-03 eta 0:23:30
epoch [15/50] batch [100/244] time 0.156 (0.161) data 0.000 (0.003) loss 1.6412 (1.3721) ce_loss 1.2949 (1.0943) teacher_loss 1.3102 (1.0721) loss_zs_kd 0.1836 (0.1479) loss_oracle 0.2392 (0.2261) acc 59.3750 (70.9688) kd_loss 0.5396 (0.5397) lr 1.6845e-03 eta 0:23:21
epoch [15/50] batch [120/244] time 0.093 (0.159) data 0.000 (0.002) loss 1.2843 (1.3660) ce_loss 1.0029 (1.0852) teacher_loss 0.9235 (1.0625) loss_zs_kd 0.1455 (0.1488) loss_oracle 0.2881 (0.2291) acc 65.6250 (71.0417) kd_loss 0.5522 (0.5406) lr 1.6845e-03 eta 0:22:59
epoch [15/50] batch [140/244] time 0.332 (0.155) data 0.000 (0.002) loss 1.1219 (1.3722) ce_loss 0.7183 (1.0881) teacher_loss 0.7121 (1.0658) loss_zs_kd 0.2285 (0.1501) loss_oracle 0.2956 (0.2313) acc 84.3750 (71.0938) kd_loss 0.7234 (0.5469) lr 1.6845e-03 eta 0:22:22
epoch [15/50] batch [160/244] time 0.393 (0.158) data 0.000 (0.002) loss 1.1684 (1.3771) ce_loss 0.9414 (1.0946) teacher_loss 0.9023 (1.0707) loss_zs_kd 0.1549 (0.1506) loss_oracle 0.1886 (0.2311) acc 78.1250 (71.0352) kd_loss 0.3401 (0.5457) lr 1.6845e-03 eta 0:22:45
epoch [15/50] batch [180/244] time 0.101 (0.153) data 0.000 (0.002) loss 1.0322 (1.3708) ce_loss 0.7222 (1.0876) teacher_loss 0.7321 (1.0648) loss_zs_kd 0.1404 (0.1516) loss_oracle 0.2300 (0.2303) acc 81.2500 (71.1285) kd_loss 0.6603 (0.5427) lr 1.6845e-03 eta 0:21:58
epoch [15/50] batch [200/244] time 0.089 (0.155) data 0.000 (0.002) loss 1.0716 (1.3672) ce_loss 0.7510 (1.0842) teacher_loss 0.7429 (1.0619) loss_zs_kd 0.1729 (0.1521) loss_oracle 0.2423 (0.2292) acc 84.3750 (71.2812) kd_loss 0.4860 (0.5403) lr 1.6845e-03 eta 0:22:08
epoch [15/50] batch [220/244] time 0.288 (0.157) data 0.000 (0.001) loss 1.2578 (1.3737) ce_loss 0.9902 (1.0924) teacher_loss 0.9658 (1.0704) loss_zs_kd 0.1523 (0.1517) loss_oracle 0.2158 (0.2274) acc 87.5000 (71.0938) kd_loss 0.5571 (0.5352) lr 1.6845e-03 eta 0:22:23
epoch [15/50] batch [240/244] time 0.328 (0.156) data 0.000 (0.001) loss 1.3983 (1.3776) ce_loss 1.0117 (1.0965) teacher_loss 0.9997 (1.0748) loss_zs_kd 0.2662 (0.1526) loss_oracle 0.2655 (0.2266) acc 71.8750 (70.9896) kd_loss 0.8160 (0.5361) lr 1.6845e-03 eta 0:22:16
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,802
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 82.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,025
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.1%
******* Domain p best val acc:      84.3%, epoch: 14 *******
******* Domain p best val test acc: 90.8%, epoch: 14 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [16/50] batch [20/244] time 0.149 (0.170) data 0.000 (0.013) loss 1.0321 (1.4267) ce_loss 0.7251 (1.1347) teacher_loss 0.6426 (1.1269) loss_zs_kd 0.1758 (0.1580) loss_oracle 0.3017 (0.2208) acc 75.0000 (69.0625) kd_loss 0.5563 (0.5280) lr 1.6374e-03 eta 0:24:06
epoch [16/50] batch [40/244] time 0.154 (0.163) data 0.000 (0.007) loss 0.9719 (1.4178) ce_loss 0.6929 (1.1338) teacher_loss 0.6751 (1.1166) loss_zs_kd 0.1127 (0.1574) loss_oracle 0.2404 (0.2226) acc 84.3750 (70.3906) kd_loss 0.5578 (0.5123) lr 1.6374e-03 eta 0:23:02
epoch [16/50] batch [60/244] time 0.150 (0.159) data 0.000 (0.004) loss 1.2399 (1.4139) ce_loss 0.9248 (1.1294) teacher_loss 0.9369 (1.1132) loss_zs_kd 0.1741 (0.1558) loss_oracle 0.2159 (0.2228) acc 71.8750 (70.2083) kd_loss 0.5948 (0.5199) lr 1.6374e-03 eta 0:22:27
epoch [16/50] batch [80/244] time 0.155 (0.158) data 0.000 (0.003) loss 1.3027 (1.4248) ce_loss 1.0449 (1.1434) teacher_loss 1.0092 (1.1284) loss_zs_kd 0.2227 (0.1548) loss_oracle 0.1822 (0.2190) acc 65.6250 (70.1172) kd_loss 0.3768 (0.5223) lr 1.6374e-03 eta 0:22:12
epoch [16/50] batch [100/244] time 0.150 (0.157) data 0.000 (0.003) loss 1.2208 (1.4205) ce_loss 0.9224 (1.1395) teacher_loss 0.9201 (1.1248) loss_zs_kd 0.1651 (0.1535) loss_oracle 0.2181 (0.2189) acc 75.0000 (70.1875) kd_loss 0.5842 (0.5189) lr 1.6374e-03 eta 0:22:07
epoch [16/50] batch [120/244] time 0.145 (0.157) data 0.000 (0.002) loss 1.8722 (1.4215) ce_loss 1.6143 (1.1408) teacher_loss 1.5915 (1.1265) loss_zs_kd 0.1150 (0.1517) loss_oracle 0.2232 (0.2191) acc 62.5000 (70.2604) kd_loss 0.6679 (0.5236) lr 1.6374e-03 eta 0:21:57
epoch [16/50] batch [140/244] time 0.146 (0.156) data 0.000 (0.002) loss 0.9365 (1.4062) ce_loss 0.6797 (1.1257) teacher_loss 0.6524 (1.1105) loss_zs_kd 0.1304 (0.1511) loss_oracle 0.2189 (0.2202) acc 84.3750 (70.7143) kd_loss 0.5131 (0.5219) lr 1.6374e-03 eta 0:21:52
epoch [16/50] batch [160/244] time 0.159 (0.156) data 0.000 (0.002) loss 0.9435 (1.3922) ce_loss 0.6875 (1.1133) teacher_loss 0.7045 (1.0978) loss_zs_kd 0.1040 (0.1492) loss_oracle 0.1869 (0.2198) acc 81.2500 (70.8203) kd_loss 0.4335 (0.5225) lr 1.6374e-03 eta 0:21:45
epoch [16/50] batch [180/244] time 0.155 (0.155) data 0.000 (0.002) loss 1.1109 (1.3921) ce_loss 0.8696 (1.1128) teacher_loss 0.8170 (1.0973) loss_zs_kd 0.1592 (0.1492) loss_oracle 0.2143 (0.2202) acc 81.2500 (70.8854) kd_loss 0.4310 (0.5210) lr 1.6374e-03 eta 0:21:38
epoch [16/50] batch [200/244] time 0.147 (0.155) data 0.000 (0.001) loss 1.5009 (1.3978) ce_loss 1.2314 (1.1180) teacher_loss 1.2017 (1.1026) loss_zs_kd 0.1664 (0.1488) loss_oracle 0.2161 (0.2208) acc 71.8750 (70.7812) kd_loss 0.6734 (0.5224) lr 1.6374e-03 eta 0:21:33
epoch [16/50] batch [220/244] time 0.143 (0.155) data 0.000 (0.001) loss 1.9877 (1.3906) ce_loss 1.6738 (1.1123) teacher_loss 1.6390 (1.0967) loss_zs_kd 0.2435 (0.1495) loss_oracle 0.2269 (0.2191) acc 53.1250 (70.7955) kd_loss 0.7082 (0.5192) lr 1.6374e-03 eta 0:21:31
epoch [16/50] batch [240/244] time 0.153 (0.155) data 0.000 (0.001) loss 0.9822 (1.3893) ce_loss 0.6631 (1.1124) teacher_loss 0.6809 (1.0960) loss_zs_kd 0.1195 (0.1498) loss_oracle 0.2415 (0.2184) acc 84.3750 (70.7422) kd_loss 0.5124 (0.5203) lr 1.6374e-03 eta 0:21:25
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,793
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,021
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 90.1%
******* Domain p best val acc:      84.3%, epoch: 14 *******
******* Domain p best val test acc: 90.8%, epoch: 14 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [17/50] batch [20/244] time 0.104 (0.133) data 0.000 (0.016) loss 1.3729 (1.4328) ce_loss 1.1309 (1.1576) teacher_loss 1.1357 (1.1311) loss_zs_kd 0.1262 (0.1522) loss_oracle 0.1741 (0.2256) acc 75.0000 (69.0625) kd_loss 0.5094 (0.5536) lr 1.5878e-03 eta 0:18:24
epoch [17/50] batch [40/244] time 0.135 (0.156) data 0.000 (0.008) loss 1.4531 (1.4462) ce_loss 1.2422 (1.1692) teacher_loss 1.2230 (1.1509) loss_zs_kd 0.1216 (0.1493) loss_oracle 0.1693 (0.2207) acc 62.5000 (68.4375) kd_loss 0.4150 (0.5429) lr 1.5878e-03 eta 0:21:28
epoch [17/50] batch [60/244] time 0.185 (0.170) data 0.001 (0.005) loss 1.6381 (1.4143) ce_loss 1.4170 (1.1369) teacher_loss 1.3451 (1.1188) loss_zs_kd 0.1558 (0.1472) loss_oracle 0.2152 (0.2219) acc 56.2500 (68.8021) kd_loss 0.5260 (0.5434) lr 1.5878e-03 eta 0:23:19
epoch [17/50] batch [80/244] time 0.093 (0.172) data 0.000 (0.004) loss 1.0430 (1.4230) ce_loss 0.7666 (1.1464) teacher_loss 0.7555 (1.1264) loss_zs_kd 0.1130 (0.1470) loss_oracle 0.2310 (0.2230) acc 78.1250 (68.5547) kd_loss 0.5068 (0.5413) lr 1.5878e-03 eta 0:23:29
epoch [17/50] batch [100/244] time 0.147 (0.167) data 0.000 (0.003) loss 1.0782 (1.4067) ce_loss 0.8413 (1.1287) teacher_loss 0.7821 (1.1086) loss_zs_kd 0.1586 (0.1482) loss_oracle 0.2168 (0.2241) acc 75.0000 (69.3125) kd_loss 0.5143 (0.5374) lr 1.5878e-03 eta 0:22:47
epoch [17/50] batch [120/244] time 0.148 (0.164) data 0.000 (0.003) loss 1.2137 (1.4036) ce_loss 0.8911 (1.1228) teacher_loss 0.9161 (1.1029) loss_zs_kd 0.1734 (0.1495) loss_oracle 0.2109 (0.2259) acc 75.0000 (69.8958) kd_loss 0.5261 (0.5387) lr 1.5878e-03 eta 0:22:21
epoch [17/50] batch [140/244] time 0.154 (0.162) data 0.000 (0.002) loss 1.1801 (1.4005) ce_loss 0.9297 (1.1196) teacher_loss 0.9240 (1.0977) loss_zs_kd 0.1045 (0.1506) loss_oracle 0.2038 (0.2275) acc 81.2500 (70.0446) kd_loss 0.4095 (0.5405) lr 1.5878e-03 eta 0:22:04
epoch [17/50] batch [160/244] time 0.153 (0.161) data 0.000 (0.002) loss 1.1897 (1.4059) ce_loss 0.9434 (1.1215) teacher_loss 0.9080 (1.0999) loss_zs_kd 0.1551 (0.1501) loss_oracle 0.2042 (0.2310) acc 78.1250 (69.9805) kd_loss 0.4654 (0.5466) lr 1.5878e-03 eta 0:21:51
epoch [17/50] batch [180/244] time 0.152 (0.160) data 0.000 (0.002) loss 0.9953 (1.4017) ce_loss 0.6553 (1.1148) teacher_loss 0.6643 (1.0932) loss_zs_kd 0.1373 (0.1514) loss_oracle 0.2625 (0.2328) acc 81.2500 (70.1389) kd_loss 0.7357 (0.5480) lr 1.5878e-03 eta 0:21:40
epoch [17/50] batch [200/244] time 0.163 (0.160) data 0.000 (0.002) loss 1.0809 (1.4123) ce_loss 0.7920 (1.1239) teacher_loss 0.7895 (1.1030) loss_zs_kd 0.1167 (0.1506) loss_oracle 0.2330 (0.2340) acc 68.7500 (69.9688) kd_loss 0.6093 (0.5505) lr 1.5878e-03 eta 0:21:31
epoch [17/50] batch [220/244] time 0.151 (0.160) data 0.000 (0.002) loss 1.2961 (1.4114) ce_loss 0.9561 (1.1207) teacher_loss 0.9488 (1.0998) loss_zs_kd 0.1343 (0.1507) loss_oracle 0.2802 (0.2362) acc 65.6250 (70.1278) kd_loss 0.6588 (0.5521) lr 1.5878e-03 eta 0:21:28
epoch [17/50] batch [240/244] time 0.147 (0.159) data 0.000 (0.002) loss 1.2247 (1.4111) ce_loss 0.8862 (1.1193) teacher_loss 0.8747 (1.0988) loss_zs_kd 0.1545 (0.1509) loss_oracle 0.2728 (0.2369) acc 81.2500 (70.3255) kd_loss 0.6004 (0.5502) lr 1.5878e-03 eta 0:21:19
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,805
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,040
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.3%, epoch: 14 *******
******* Domain p best val test acc: 90.8%, epoch: 14 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [18/50] batch [20/244] time 0.151 (0.167) data 0.000 (0.014) loss 1.5174 (1.4185) ce_loss 1.2510 (1.0932) teacher_loss 1.1956 (1.0761) loss_zs_kd 0.1248 (0.1544) loss_oracle 0.2594 (0.2652) acc 71.8750 (71.7188) kd_loss 0.6358 (0.5712) lr 1.5358e-03 eta 0:22:23
epoch [18/50] batch [40/244] time 0.148 (0.160) data 0.000 (0.007) loss 1.5284 (1.4433) ce_loss 1.1553 (1.1127) teacher_loss 1.1597 (1.0951) loss_zs_kd 0.1336 (0.1477) loss_oracle 0.3020 (0.2744) acc 59.3750 (70.7812) kd_loss 0.5378 (0.5813) lr 1.5358e-03 eta 0:21:20
epoch [18/50] batch [60/244] time 0.148 (0.158) data 0.001 (0.005) loss 1.3670 (1.4479) ce_loss 1.0801 (1.1140) teacher_loss 1.0297 (1.0985) loss_zs_kd 0.1346 (0.1450) loss_oracle 0.2700 (0.2769) acc 75.0000 (71.1979) kd_loss 0.5239 (0.5911) lr 1.5358e-03 eta 0:20:59
epoch [18/50] batch [80/244] time 0.176 (0.158) data 0.000 (0.004) loss 1.3447 (1.4697) ce_loss 1.0527 (1.1406) teacher_loss 1.0445 (1.1284) loss_zs_kd 0.1320 (0.1469) loss_oracle 0.2342 (0.2679) acc 75.0000 (70.4297) kd_loss 0.4185 (0.5764) lr 1.5358e-03 eta 0:20:56
epoch [18/50] batch [100/244] time 0.082 (0.147) data 0.000 (0.003) loss 1.8490 (1.4694) ce_loss 1.5352 (1.1447) teacher_loss 1.4908 (1.1320) loss_zs_kd 0.1809 (0.1482) loss_oracle 0.2678 (0.2633) acc 59.3750 (70.0000) kd_loss 0.6220 (0.5703) lr 1.5358e-03 eta 0:19:31
epoch [18/50] batch [120/244] time 0.123 (0.147) data 0.000 (0.003) loss 1.9455 (1.4734) ce_loss 1.6387 (1.1496) teacher_loss 1.6692 (1.1377) loss_zs_kd 0.1324 (0.1502) loss_oracle 0.2101 (0.2606) acc 56.2500 (70.0000) kd_loss 0.4959 (0.5653) lr 1.5358e-03 eta 0:19:23
epoch [18/50] batch [140/244] time 0.147 (0.150) data 0.000 (0.002) loss 1.0696 (1.4610) ce_loss 0.7744 (1.1394) teacher_loss 0.7494 (1.1273) loss_zs_kd 0.1041 (0.1500) loss_oracle 0.2682 (0.2587) acc 71.8750 (70.1562) kd_loss 0.6595 (0.5613) lr 1.5358e-03 eta 0:19:46
epoch [18/50] batch [160/244] time 0.093 (0.146) data 0.000 (0.002) loss 1.5206 (1.4565) ce_loss 1.1416 (1.1374) teacher_loss 1.1349 (1.1243) loss_zs_kd 0.2231 (0.1510) loss_oracle 0.2741 (0.2568) acc 75.0000 (70.0391) kd_loss 0.4993 (0.5572) lr 1.5358e-03 eta 0:19:11
epoch [18/50] batch [180/244] time 0.102 (0.148) data 0.000 (0.002) loss 0.8193 (1.4543) ce_loss 0.5361 (1.1348) teacher_loss 0.4939 (1.1218) loss_zs_kd 0.0918 (0.1510) loss_oracle 0.2795 (0.2570) acc 84.3750 (70.1042) kd_loss 0.5535 (0.5604) lr 1.5358e-03 eta 0:19:28
epoch [18/50] batch [200/244] time 0.165 (0.151) data 0.000 (0.002) loss 1.2739 (1.4424) ce_loss 0.9639 (1.1225) teacher_loss 0.9574 (1.1086) loss_zs_kd 0.1478 (0.1503) loss_oracle 0.2425 (0.2587) acc 75.0000 (70.5938) kd_loss 0.4508 (0.5590) lr 1.5358e-03 eta 0:19:43
epoch [18/50] batch [220/244] time 0.125 (0.151) data 0.000 (0.001) loss 1.4077 (1.4373) ce_loss 1.1074 (1.1176) teacher_loss 1.0567 (1.1025) loss_zs_kd 0.1673 (0.1502) loss_oracle 0.2674 (0.2597) acc 75.0000 (70.7244) kd_loss 0.5569 (0.5622) lr 1.5358e-03 eta 0:19:39
epoch [18/50] batch [240/244] time 0.082 (0.152) data 0.000 (0.001) loss 1.4669 (1.4402) ce_loss 1.1719 (1.1201) teacher_loss 1.1066 (1.1052) loss_zs_kd 0.1813 (0.1507) loss_oracle 0.2696 (0.2596) acc 59.3750 (70.6250) kd_loss 0.5471 (0.5650) lr 1.5358e-03 eta 0:19:43
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,809
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.4%
******* Domain p best val acc:      84.3%, epoch: 14 *******
******* Domain p best val test acc: 90.8%, epoch: 14 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [19/50] batch [20/244] time 0.151 (0.169) data 0.000 (0.014) loss 1.1591 (1.4646) ce_loss 0.9307 (1.1737) teacher_loss 0.8950 (1.1679) loss_zs_kd 0.1240 (0.1466) loss_oracle 0.2022 (0.2234) acc 75.0000 (68.4375) kd_loss 0.4446 (0.5283) lr 1.4818e-03 eta 0:21:55
epoch [19/50] batch [40/244] time 0.158 (0.163) data 0.000 (0.007) loss 1.4741 (1.4497) ce_loss 1.1963 (1.1549) teacher_loss 1.1517 (1.1433) loss_zs_kd 0.1652 (0.1507) loss_oracle 0.2398 (0.2310) acc 75.0000 (69.2969) kd_loss 0.4074 (0.5432) lr 1.4818e-03 eta 0:21:06
epoch [19/50] batch [60/244] time 0.154 (0.162) data 0.000 (0.005) loss 0.8858 (1.4650) ce_loss 0.6348 (1.1672) teacher_loss 0.6480 (1.1543) loss_zs_kd 0.1041 (0.1559) loss_oracle 0.1857 (0.2327) acc 84.3750 (69.1667) kd_loss 0.3428 (0.5542) lr 1.4818e-03 eta 0:20:52
epoch [19/50] batch [80/244] time 0.171 (0.160) data 0.000 (0.004) loss 1.4582 (1.4403) ce_loss 1.1729 (1.1425) teacher_loss 1.1691 (1.1289) loss_zs_kd 0.1306 (0.1558) loss_oracle 0.2238 (0.2334) acc 59.3750 (69.6484) kd_loss 0.4966 (0.5512) lr 1.4818e-03 eta 0:20:37
epoch [19/50] batch [100/244] time 0.165 (0.160) data 0.000 (0.003) loss 1.8181 (1.4314) ce_loss 1.5107 (1.1384) teacher_loss 1.5327 (1.1239) loss_zs_kd 0.2012 (0.1526) loss_oracle 0.1847 (0.2312) acc 62.5000 (69.8125) kd_loss 0.5357 (0.5489) lr 1.4818e-03 eta 0:20:34
epoch [19/50] batch [120/244] time 0.149 (0.160) data 0.000 (0.003) loss 1.7238 (1.4373) ce_loss 1.3877 (1.1456) teacher_loss 1.3659 (1.1308) loss_zs_kd 0.1800 (0.1521) loss_oracle 0.2678 (0.2304) acc 59.3750 (69.2708) kd_loss 0.6297 (0.5494) lr 1.4818e-03 eta 0:20:28
epoch [19/50] batch [140/244] time 0.153 (0.159) data 0.000 (0.002) loss 1.5485 (1.4293) ce_loss 1.2295 (1.1381) teacher_loss 1.1903 (1.1239) loss_zs_kd 0.1894 (0.1501) loss_oracle 0.2634 (0.2303) acc 71.8750 (69.7321) kd_loss 0.4703 (0.5481) lr 1.4818e-03 eta 0:20:17
epoch [19/50] batch [160/244] time 0.149 (0.159) data 0.000 (0.002) loss 1.4556 (1.4259) ce_loss 1.0957 (1.1348) teacher_loss 1.1101 (1.1193) loss_zs_kd 0.1487 (0.1503) loss_oracle 0.2711 (0.2314) acc 78.1250 (69.8633) kd_loss 0.5803 (0.5465) lr 1.4818e-03 eta 0:20:17
epoch [19/50] batch [180/244] time 0.148 (0.159) data 0.000 (0.002) loss 1.0790 (1.4240) ce_loss 0.7759 (1.1305) teacher_loss 0.7113 (1.1158) loss_zs_kd 0.1471 (0.1501) loss_oracle 0.2942 (0.2331) acc 84.3750 (70.0174) kd_loss 0.6065 (0.5472) lr 1.4818e-03 eta 0:20:12
epoch [19/50] batch [200/244] time 0.171 (0.159) data 0.000 (0.002) loss 1.2633 (1.4091) ce_loss 0.9785 (1.1137) teacher_loss 0.9820 (1.1001) loss_zs_kd 0.1930 (0.1508) loss_oracle 0.1848 (0.2337) acc 68.7500 (70.4062) kd_loss 0.5916 (0.5486) lr 1.4818e-03 eta 0:20:11
epoch [19/50] batch [220/244] time 0.091 (0.153) data 0.000 (0.001) loss 1.4189 (1.4105) ce_loss 1.1455 (1.1149) teacher_loss 1.1004 (1.1009) loss_zs_kd 0.0850 (0.1500) loss_oracle 0.2760 (0.2346) acc 75.0000 (70.5398) kd_loss 0.7037 (0.5524) lr 1.4818e-03 eta 0:19:23
epoch [19/50] batch [240/244] time 0.087 (0.152) data 0.000 (0.001) loss 1.4415 (1.3981) ce_loss 1.1934 (1.1037) teacher_loss 1.1283 (1.0897) loss_zs_kd 0.1577 (0.1489) loss_oracle 0.2344 (0.2340) acc 71.8750 (70.7552) kd_loss 0.4343 (0.5492) lr 1.4818e-03 eta 0:19:12
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,812
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.3%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,040
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.4%
******* Domain p best val acc:      84.3%, epoch: 19 *******
******* Domain p best val test acc: 91.0%, epoch: 19 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [20/50] batch [20/244] time 0.093 (0.189) data 0.000 (0.014) loss 1.3827 (1.3705) ce_loss 1.1641 (1.0762) teacher_loss 1.0825 (1.0575) loss_zs_kd 0.1468 (0.1481) loss_oracle 0.2268 (0.2390) acc 65.6250 (71.2500) kd_loss 0.3802 (0.5678) lr 1.4258e-03 eta 0:23:46
epoch [20/50] batch [40/244] time 0.091 (0.180) data 0.000 (0.007) loss 1.3585 (1.3774) ce_loss 1.0840 (1.0846) teacher_loss 1.0222 (1.0630) loss_zs_kd 0.1101 (0.1469) loss_oracle 0.2812 (0.2410) acc 81.2500 (71.8750) kd_loss 0.6938 (0.5807) lr 1.4258e-03 eta 0:22:37
epoch [20/50] batch [60/244] time 0.186 (0.170) data 0.001 (0.005) loss 1.3924 (1.3670) ce_loss 1.1123 (1.0731) teacher_loss 1.0763 (1.0556) loss_zs_kd 0.1797 (0.1506) loss_oracle 0.2263 (0.2361) acc 71.8750 (72.0312) kd_loss 0.5272 (0.5615) lr 1.4258e-03 eta 0:21:14
epoch [20/50] batch [80/244] time 0.174 (0.173) data 0.000 (0.004) loss 1.4310 (1.3650) ce_loss 1.0850 (1.0729) teacher_loss 1.1333 (1.0549) loss_zs_kd 0.1576 (0.1501) loss_oracle 0.2189 (0.2351) acc 65.6250 (72.2266) kd_loss 0.5013 (0.5555) lr 1.4258e-03 eta 0:21:32
epoch [20/50] batch [100/244] time 0.176 (0.172) data 0.000 (0.003) loss 1.6202 (1.3953) ce_loss 1.3486 (1.1053) teacher_loss 1.3557 (1.0871) loss_zs_kd 0.1102 (0.1494) loss_oracle 0.2095 (0.2336) acc 71.8750 (71.3750) kd_loss 0.5298 (0.5503) lr 1.4258e-03 eta 0:21:20
epoch [20/50] batch [120/244] time 0.175 (0.170) data 0.000 (0.003) loss 1.2999 (1.4008) ce_loss 1.0234 (1.1125) teacher_loss 1.0092 (1.0929) loss_zs_kd 0.1537 (0.1508) loss_oracle 0.2139 (0.2324) acc 78.1250 (71.5365) kd_loss 0.6139 (0.5484) lr 1.4258e-03 eta 0:21:05
epoch [20/50] batch [140/244] time 0.153 (0.168) data 0.000 (0.002) loss 1.6685 (1.4038) ce_loss 1.4424 (1.1153) teacher_loss 1.4062 (1.0969) loss_zs_kd 0.1537 (0.1522) loss_oracle 0.1854 (0.2308) acc 59.3750 (71.3616) kd_loss 0.3526 (0.5469) lr 1.4258e-03 eta 0:20:48
epoch [20/50] batch [160/244] time 0.172 (0.167) data 0.000 (0.002) loss 0.9314 (1.3986) ce_loss 0.6694 (1.1110) teacher_loss 0.6723 (1.0931) loss_zs_kd 0.0806 (0.1515) loss_oracle 0.2188 (0.2297) acc 84.3750 (71.4062) kd_loss 0.3641 (0.5400) lr 1.4258e-03 eta 0:20:38
epoch [20/50] batch [180/244] time 0.174 (0.167) data 0.000 (0.002) loss 1.5457 (1.3918) ce_loss 1.2207 (1.1037) teacher_loss 1.2097 (1.0861) loss_zs_kd 0.2012 (0.1503) loss_oracle 0.2355 (0.2306) acc 68.7500 (71.3715) kd_loss 0.6224 (0.5391) lr 1.4258e-03 eta 0:20:32
epoch [20/50] batch [200/244] time 0.183 (0.168) data 0.000 (0.002) loss 1.0420 (1.3957) ce_loss 0.7139 (1.1052) teacher_loss 0.6980 (1.0875) loss_zs_kd 0.1430 (0.1519) loss_oracle 0.2726 (0.2323) acc 78.1250 (71.2031) kd_loss 0.6120 (0.5389) lr 1.4258e-03 eta 0:20:39
epoch [20/50] batch [220/244] time 0.160 (0.168) data 0.000 (0.002) loss 1.3803 (1.3911) ce_loss 1.0801 (1.0994) teacher_loss 0.9873 (1.0804) loss_zs_kd 0.2274 (0.1528) loss_oracle 0.2793 (0.2344) acc 75.0000 (71.3636) kd_loss 0.4932 (0.5420) lr 1.4258e-03 eta 0:20:35
epoch [20/50] batch [240/244] time 0.162 (0.168) data 0.000 (0.001) loss 1.1080 (1.3900) ce_loss 0.8174 (1.0980) teacher_loss 0.8233 (1.0782) loss_zs_kd 0.1413 (0.1534) loss_oracle 0.2141 (0.2351) acc 71.8750 (71.2500) kd_loss 0.7116 (0.5467) lr 1.4258e-03 eta 0:20:29
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,810
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.3%, epoch: 19 *******
******* Domain p best val test acc: 91.0%, epoch: 19 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [21/50] batch [20/244] time 0.086 (0.150) data 0.000 (0.019) loss 1.0985 (1.3647) ce_loss 0.7427 (1.0505) teacher_loss 0.7836 (1.0459) loss_zs_kd 0.1258 (0.1552) loss_oracle 0.2520 (0.2412) acc 81.2500 (71.8750) kd_loss 0.7599 (0.5755) lr 1.3681e-03 eta 0:18:14
epoch [21/50] batch [40/244] time 0.098 (0.133) data 0.000 (0.009) loss 0.9725 (1.3595) ce_loss 0.7441 (1.0596) teacher_loss 0.6325 (1.0394) loss_zs_kd 0.1759 (0.1594) loss_oracle 0.2521 (0.2404) acc 81.2500 (72.1094) kd_loss 0.5116 (0.5545) lr 1.3681e-03 eta 0:16:08
epoch [21/50] batch [60/244] time 0.129 (0.144) data 0.001 (0.006) loss 1.1635 (1.3855) ce_loss 0.8823 (1.0881) teacher_loss 0.8930 (1.0691) loss_zs_kd 0.1259 (0.1592) loss_oracle 0.2076 (0.2368) acc 75.0000 (70.9896) kd_loss 0.4205 (0.5450) lr 1.3681e-03 eta 0:17:27
epoch [21/50] batch [80/244] time 0.233 (0.153) data 0.000 (0.005) loss 1.1198 (1.4000) ce_loss 0.8496 (1.1013) teacher_loss 0.8046 (1.0845) loss_zs_kd 0.2013 (0.1604) loss_oracle 0.2146 (0.2352) acc 78.1250 (70.9375) kd_loss 0.4509 (0.5492) lr 1.3681e-03 eta 0:18:30
epoch [21/50] batch [100/244] time 0.103 (0.160) data 0.000 (0.004) loss 1.0996 (1.4118) ce_loss 0.7998 (1.1131) teacher_loss 0.7981 (1.0985) loss_zs_kd 0.1601 (0.1603) loss_oracle 0.2215 (0.2331) acc 78.1250 (70.5312) kd_loss 0.4407 (0.5491) lr 1.3681e-03 eta 0:19:18
epoch [21/50] batch [120/244] time 0.193 (0.157) data 0.000 (0.003) loss 1.2342 (1.4187) ce_loss 0.9077 (1.1225) teacher_loss 0.8744 (1.1060) loss_zs_kd 0.1459 (0.1586) loss_oracle 0.2868 (0.2334) acc 71.8750 (70.3125) kd_loss 0.6928 (0.5482) lr 1.3681e-03 eta 0:18:48
epoch [21/50] batch [140/244] time 0.173 (0.158) data 0.000 (0.003) loss 1.5596 (1.4211) ce_loss 1.2617 (1.1270) teacher_loss 1.2693 (1.1108) loss_zs_kd 0.1466 (0.1568) loss_oracle 0.2171 (0.2320) acc 65.6250 (70.2679) kd_loss 0.5248 (0.5446) lr 1.3681e-03 eta 0:18:54
epoch [21/50] batch [160/244] time 0.182 (0.160) data 0.000 (0.003) loss 1.7662 (1.4155) ce_loss 1.4824 (1.1227) teacher_loss 1.5143 (1.1069) loss_zs_kd 0.1093 (0.1550) loss_oracle 0.1973 (0.2311) acc 62.5000 (70.5859) kd_loss 0.6894 (0.5444) lr 1.3681e-03 eta 0:19:04
epoch [21/50] batch [180/244] time 0.175 (0.162) data 0.000 (0.002) loss 1.0348 (1.4027) ce_loss 0.7017 (1.1118) teacher_loss 0.7232 (1.0950) loss_zs_kd 0.1332 (0.1541) loss_oracle 0.2450 (0.2307) acc 81.2500 (71.0243) kd_loss 0.6022 (0.5431) lr 1.3681e-03 eta 0:19:14
epoch [21/50] batch [200/244] time 0.159 (0.163) data 0.000 (0.002) loss 1.2813 (1.4006) ce_loss 0.9673 (1.1086) teacher_loss 0.9431 (1.0917) loss_zs_kd 0.1954 (0.1535) loss_oracle 0.2405 (0.2322) acc 68.7500 (70.9531) kd_loss 0.5700 (0.5469) lr 1.3681e-03 eta 0:19:21
epoch [21/50] batch [220/244] time 0.164 (0.164) data 0.000 (0.002) loss 1.3477 (1.4022) ce_loss 1.0615 (1.1098) teacher_loss 0.9911 (1.0927) loss_zs_kd 0.1831 (0.1534) loss_oracle 0.2651 (0.2328) acc 71.8750 (70.8239) kd_loss 0.5448 (0.5470) lr 1.3681e-03 eta 0:19:21
epoch [21/50] batch [240/244] time 0.150 (0.163) data 0.000 (0.002) loss 1.4143 (1.4115) ce_loss 1.0244 (1.1187) teacher_loss 1.0596 (1.1006) loss_zs_kd 0.1966 (0.1539) loss_oracle 0.2563 (0.2339) acc 71.8750 (70.8073) kd_loss 0.5971 (0.5485) lr 1.3681e-03 eta 0:19:15
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,805
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,014
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.8%
******* Domain p best val acc:      84.3%, epoch: 19 *******
******* Domain p best val test acc: 91.0%, epoch: 19 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [22/50] batch [20/244] time 0.179 (0.188) data 0.000 (0.016) loss 1.2707 (1.3744) ce_loss 1.0674 (1.0997) teacher_loss 1.0325 (1.0738) loss_zs_kd 0.1409 (0.1574) loss_oracle 0.1678 (0.2219) acc 78.1250 (70.7812) kd_loss 0.4688 (0.4988) lr 1.3090e-03 eta 0:22:04
epoch [22/50] batch [40/244] time 0.169 (0.174) data 0.000 (0.008) loss 1.0366 (1.4039) ce_loss 0.7622 (1.1220) teacher_loss 0.7332 (1.0985) loss_zs_kd 0.1179 (0.1560) loss_oracle 0.2445 (0.2274) acc 71.8750 (69.9219) kd_loss 0.6247 (0.5274) lr 1.3090e-03 eta 0:20:24
epoch [22/50] batch [60/244] time 0.384 (0.155) data 0.001 (0.006) loss 1.1078 (1.3787) ce_loss 0.8286 (1.0939) teacher_loss 0.7894 (1.0725) loss_zs_kd 0.1430 (0.1568) loss_oracle 0.2469 (0.2278) acc 81.2500 (70.7812) kd_loss 0.6707 (0.5225) lr 1.3090e-03 eta 0:18:10
epoch [22/50] batch [80/244] time 0.163 (0.156) data 0.000 (0.004) loss 1.9747 (1.3811) ce_loss 1.7002 (1.0940) teacher_loss 1.6877 (1.0750) loss_zs_kd 0.1518 (0.1548) loss_oracle 0.2111 (0.2287) acc 53.1250 (71.3672) kd_loss 0.5223 (0.5276) lr 1.3090e-03 eta 0:18:08
epoch [22/50] batch [100/244] time 0.097 (0.154) data 0.000 (0.003) loss 1.1502 (1.3618) ce_loss 0.7871 (1.0711) teacher_loss 0.7764 (1.0517) loss_zs_kd 0.1513 (0.1542) loss_oracle 0.2982 (0.2329) acc 71.8750 (71.9688) kd_loss 0.6613 (0.5305) lr 1.3090e-03 eta 0:17:57
epoch [22/50] batch [120/244] time 0.092 (0.153) data 0.000 (0.003) loss 1.2361 (1.3589) ce_loss 0.9082 (1.0638) teacher_loss 0.9180 (1.0448) loss_zs_kd 0.1571 (0.1573) loss_oracle 0.2396 (0.2355) acc 78.1250 (72.2917) kd_loss 0.6663 (0.5343) lr 1.3090e-03 eta 0:17:41
epoch [22/50] batch [140/244] time 0.173 (0.156) data 0.000 (0.003) loss 1.8201 (1.3698) ce_loss 1.5488 (1.0694) teacher_loss 1.4754 (1.0514) loss_zs_kd 0.1500 (0.1567) loss_oracle 0.2698 (0.2400) acc 56.2500 (71.7634) kd_loss 0.6575 (0.5361) lr 1.3090e-03 eta 0:18:00
epoch [22/50] batch [160/244] time 0.102 (0.156) data 0.000 (0.002) loss 1.4014 (1.3853) ce_loss 1.0684 (1.0827) teacher_loss 1.0603 (1.0638) loss_zs_kd 0.1642 (0.1587) loss_oracle 0.2590 (0.2422) acc 75.0000 (71.6211) kd_loss 0.5444 (0.5403) lr 1.3090e-03 eta 0:17:55
epoch [22/50] batch [180/244] time 0.121 (0.157) data 0.000 (0.002) loss 1.5454 (1.3891) ce_loss 1.2559 (1.0861) teacher_loss 1.2383 (1.0671) loss_zs_kd 0.1543 (0.1578) loss_oracle 0.2299 (0.2430) acc 59.3750 (71.5104) kd_loss 0.4579 (0.5440) lr 1.3090e-03 eta 0:18:02
epoch [22/50] batch [200/244] time 0.146 (0.156) data 0.000 (0.002) loss 1.3443 (1.3878) ce_loss 1.0693 (1.0812) teacher_loss 1.0828 (1.0627) loss_zs_kd 0.1206 (0.1606) loss_oracle 0.2012 (0.2447) acc 75.0000 (71.6719) kd_loss 0.4905 (0.5465) lr 1.3090e-03 eta 0:17:53
epoch [22/50] batch [220/244] time 0.152 (0.156) data 0.000 (0.002) loss 1.1762 (1.3836) ce_loss 0.8330 (1.0776) teacher_loss 0.8064 (1.0581) loss_zs_kd 0.1652 (0.1605) loss_oracle 0.2872 (0.2452) acc 78.1250 (71.7472) kd_loss 0.5552 (0.5481) lr 1.3090e-03 eta 0:17:47
epoch [22/50] batch [240/244] time 0.147 (0.155) data 0.000 (0.002) loss 1.6289 (1.3970) ce_loss 1.2305 (1.0898) teacher_loss 1.2739 (1.0712) loss_zs_kd 0.1928 (0.1613) loss_oracle 0.2587 (0.2452) acc 68.7500 (71.3542) kd_loss 0.5993 (0.5488) lr 1.3090e-03 eta 0:17:42
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,815
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.4%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      84.4%, epoch: 22 *******
******* Domain p best val test acc: 91.1%, epoch: 22 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [23/50] batch [20/244] time 0.146 (0.181) data 0.000 (0.014) loss 1.3739 (1.4519) ce_loss 1.1299 (1.1508) teacher_loss 1.1276 (1.1359) loss_zs_kd 0.1118 (0.1545) loss_oracle 0.1903 (0.2387) acc 68.7500 (69.8438) kd_loss 0.4756 (0.5277) lr 1.2487e-03 eta 0:20:30
epoch [23/50] batch [40/244] time 0.159 (0.166) data 0.000 (0.007) loss 1.3308 (1.4338) ce_loss 1.0645 (1.1360) teacher_loss 1.0058 (1.1234) loss_zs_kd 0.1907 (0.1562) loss_oracle 0.2296 (0.2323) acc 68.7500 (70.0000) kd_loss 0.3469 (0.5239) lr 1.2487e-03 eta 0:18:48
epoch [23/50] batch [60/244] time 0.155 (0.161) data 0.000 (0.005) loss 1.3415 (1.4259) ce_loss 1.0684 (1.1306) teacher_loss 1.0135 (1.1157) loss_zs_kd 0.1598 (0.1563) loss_oracle 0.2481 (0.2321) acc 75.0000 (70.6250) kd_loss 0.6411 (0.5331) lr 1.2487e-03 eta 0:18:09
epoch [23/50] batch [80/244] time 0.151 (0.159) data 0.000 (0.004) loss 1.2657 (1.4039) ce_loss 0.9780 (1.1029) teacher_loss 0.9606 (1.0906) loss_zs_kd 0.1525 (0.1575) loss_oracle 0.2288 (0.2346) acc 68.7500 (71.4062) kd_loss 0.5487 (0.5426) lr 1.2487e-03 eta 0:17:51
epoch [23/50] batch [100/244] time 0.165 (0.158) data 0.000 (0.003) loss 1.6417 (1.3936) ce_loss 1.4043 (1.0912) teacher_loss 1.3726 (1.0808) loss_zs_kd 0.1581 (0.1586) loss_oracle 0.1900 (0.2336) acc 62.5000 (71.3125) kd_loss 0.5150 (0.5436) lr 1.2487e-03 eta 0:17:44
epoch [23/50] batch [120/244] time 0.179 (0.157) data 0.000 (0.002) loss 1.5777 (1.3926) ce_loss 1.2725 (1.0896) teacher_loss 1.2716 (1.0778) loss_zs_kd 0.1429 (0.1579) loss_oracle 0.2346 (0.2358) acc 62.5000 (71.0938) kd_loss 0.4397 (0.5434) lr 1.2487e-03 eta 0:17:34
epoch [23/50] batch [140/244] time 0.148 (0.157) data 0.000 (0.002) loss 1.2995 (1.3950) ce_loss 1.0361 (1.0915) teacher_loss 1.0226 (1.0795) loss_zs_kd 0.1153 (0.1575) loss_oracle 0.2192 (0.2367) acc 84.3750 (71.0714) kd_loss 0.4638 (0.5427) lr 1.2487e-03 eta 0:17:31
epoch [23/50] batch [160/244] time 0.152 (0.156) data 0.000 (0.002) loss 1.6127 (1.3940) ce_loss 1.3242 (1.0911) teacher_loss 1.2961 (1.0794) loss_zs_kd 0.1748 (0.1567) loss_oracle 0.2292 (0.2362) acc 62.5000 (70.8594) kd_loss 0.5084 (0.5425) lr 1.2487e-03 eta 0:17:23
epoch [23/50] batch [180/244] time 0.177 (0.156) data 0.000 (0.002) loss 1.2355 (1.3946) ce_loss 0.9619 (1.0914) teacher_loss 0.9502 (1.0789) loss_zs_kd 0.1187 (0.1565) loss_oracle 0.2259 (0.2375) acc 78.1250 (71.0243) kd_loss 0.5328 (0.5444) lr 1.2487e-03 eta 0:17:18
epoch [23/50] batch [200/244] time 0.206 (0.152) data 0.000 (0.002) loss 1.0537 (1.3855) ce_loss 0.7490 (1.0823) teacher_loss 0.6811 (1.0693) loss_zs_kd 0.1746 (0.1550) loss_oracle 0.2853 (0.2387) acc 81.2500 (71.1250) kd_loss 0.6803 (0.5445) lr 1.2487e-03 eta 0:16:47
epoch [23/50] batch [220/244] time 0.089 (0.152) data 0.000 (0.001) loss 1.5975 (1.3919) ce_loss 1.3359 (1.0870) teacher_loss 1.3226 (1.0730) loss_zs_kd 0.1742 (0.1561) loss_oracle 0.1878 (0.2409) acc 65.6250 (70.8949) kd_loss 0.3383 (0.5448) lr 1.2487e-03 eta 0:16:47
epoch [23/50] batch [240/244] time 0.083 (0.152) data 0.000 (0.001) loss 0.9980 (1.3954) ce_loss 0.6758 (1.0898) teacher_loss 0.6451 (1.0747) loss_zs_kd 0.1741 (0.1571) loss_oracle 0.2658 (0.2422) acc 87.5000 (70.8203) kd_loss 0.4916 (0.5477) lr 1.2487e-03 eta 0:16:39
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,818
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.5%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.5%, epoch: 23 *******
******* Domain p best val test acc: 90.9%, epoch: 23 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [24/50] batch [20/244] time 0.152 (0.177) data 0.000 (0.014) loss 1.5698 (1.3366) ce_loss 1.2920 (1.0307) teacher_loss 1.2783 (1.0183) loss_zs_kd 0.1698 (0.1650) loss_oracle 0.2066 (0.2358) acc 65.6250 (71.7188) kd_loss 0.5005 (0.5493) lr 1.1874e-03 eta 0:19:19
epoch [24/50] batch [40/244] time 0.177 (0.169) data 0.000 (0.007) loss 2.0303 (1.4212) ce_loss 1.7588 (1.1264) teacher_loss 1.7092 (1.1101) loss_zs_kd 0.1421 (0.1585) loss_oracle 0.2500 (0.2319) acc 50.0000 (69.7656) kd_loss 0.5570 (0.5418) lr 1.1874e-03 eta 0:18:23
epoch [24/50] batch [60/244] time 0.147 (0.164) data 0.001 (0.005) loss 1.6661 (1.4343) ce_loss 1.4824 (1.1474) teacher_loss 1.3521 (1.1248) loss_zs_kd 0.1929 (0.1601) loss_oracle 0.2175 (0.2294) acc 62.5000 (69.3750) kd_loss 0.5148 (0.5379) lr 1.1874e-03 eta 0:17:47
epoch [24/50] batch [80/244] time 0.154 (0.161) data 0.000 (0.004) loss 1.4447 (1.4257) ce_loss 1.1777 (1.1393) teacher_loss 1.1875 (1.1184) loss_zs_kd 0.1296 (0.1622) loss_oracle 0.1925 (0.2262) acc 65.6250 (69.6875) kd_loss 0.4731 (0.5404) lr 1.1874e-03 eta 0:17:27
epoch [24/50] batch [100/244] time 0.153 (0.159) data 0.000 (0.003) loss 1.2633 (1.3960) ce_loss 0.9521 (1.1096) teacher_loss 0.9349 (1.0887) loss_zs_kd 0.1745 (0.1610) loss_oracle 0.2411 (0.2267) acc 71.8750 (70.3750) kd_loss 0.5898 (0.5412) lr 1.1874e-03 eta 0:17:12
epoch [24/50] batch [120/244] time 0.156 (0.158) data 0.000 (0.002) loss 1.5302 (1.3988) ce_loss 1.2744 (1.1144) teacher_loss 1.2369 (1.0933) loss_zs_kd 0.1596 (0.1597) loss_oracle 0.2136 (0.2257) acc 68.7500 (70.5208) kd_loss 0.5643 (0.5371) lr 1.1874e-03 eta 0:17:02
epoch [24/50] batch [140/244] time 0.151 (0.157) data 0.000 (0.002) loss 1.1683 (1.4026) ce_loss 0.8374 (1.1152) teacher_loss 0.7775 (1.0934) loss_zs_kd 0.1761 (0.1601) loss_oracle 0.3027 (0.2291) acc 84.3750 (70.6473) kd_loss 0.6813 (0.5391) lr 1.1874e-03 eta 0:16:54
epoch [24/50] batch [160/244] time 0.154 (0.157) data 0.000 (0.002) loss 1.5005 (1.3877) ce_loss 1.1523 (1.0972) teacher_loss 1.1318 (1.0762) loss_zs_kd 0.1726 (0.1590) loss_oracle 0.2825 (0.2320) acc 68.7500 (70.8008) kd_loss 0.5586 (0.5386) lr 1.1874e-03 eta 0:16:47
epoch [24/50] batch [180/244] time 0.172 (0.157) data 0.000 (0.002) loss 1.5517 (1.4009) ce_loss 1.2002 (1.1076) teacher_loss 1.1884 (1.0868) loss_zs_kd 0.1778 (0.1581) loss_oracle 0.2744 (0.2350) acc 62.5000 (70.5556) kd_loss 0.3874 (0.5390) lr 1.1874e-03 eta 0:16:43
epoch [24/50] batch [200/244] time 0.152 (0.156) data 0.000 (0.002) loss 1.4237 (1.3968) ce_loss 1.1602 (1.0987) teacher_loss 1.1092 (1.0783) loss_zs_kd 0.1344 (0.1590) loss_oracle 0.2473 (0.2391) acc 78.1250 (70.7656) kd_loss 0.4286 (0.5453) lr 1.1874e-03 eta 0:16:38
epoch [24/50] batch [220/244] time 0.172 (0.157) data 0.000 (0.001) loss 1.7094 (1.3862) ce_loss 1.3301 (1.0867) teacher_loss 1.3775 (1.0666) loss_zs_kd 0.1654 (0.1591) loss_oracle 0.2492 (0.2400) acc 62.5000 (71.0085) kd_loss 0.5812 (0.5439) lr 1.1874e-03 eta 0:16:39
epoch [24/50] batch [240/244] time 0.156 (0.157) data 0.000 (0.001) loss 1.6679 (1.3897) ce_loss 1.3516 (1.0889) teacher_loss 1.3170 (1.0678) loss_zs_kd 0.1681 (0.1592) loss_oracle 0.2670 (0.2422) acc 62.5000 (71.0286) kd_loss 0.5893 (0.5484) lr 1.1874e-03 eta 0:16:35
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,827
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [25/50] batch [20/244] time 0.112 (0.144) data 0.000 (0.014) loss 1.1684 (1.3650) ce_loss 0.8896 (1.0874) teacher_loss 0.8360 (1.0655) loss_zs_kd 0.1364 (0.1363) loss_oracle 0.2642 (0.2314) acc 71.8750 (70.3125) kd_loss 0.5337 (0.5338) lr 1.1253e-03 eta 0:15:09
epoch [25/50] batch [40/244] time 0.155 (0.160) data 0.000 (0.007) loss 1.2152 (1.3513) ce_loss 0.9668 (1.0761) teacher_loss 0.8780 (1.0524) loss_zs_kd 0.1445 (0.1391) loss_oracle 0.2650 (0.2293) acc 68.7500 (70.0781) kd_loss 0.6638 (0.5389) lr 1.1253e-03 eta 0:16:50
epoch [25/50] batch [60/244] time 0.112 (0.151) data 0.001 (0.005) loss 1.2179 (1.3403) ce_loss 0.9155 (1.0577) teacher_loss 0.9302 (1.0402) loss_zs_kd 0.1487 (0.1441) loss_oracle 0.2133 (0.2280) acc 75.0000 (71.4583) kd_loss 0.6850 (0.5366) lr 1.1253e-03 eta 0:15:50
epoch [25/50] batch [80/244] time 0.083 (0.155) data 0.000 (0.004) loss 1.3066 (1.3652) ce_loss 0.9331 (1.0826) teacher_loss 0.9383 (1.0634) loss_zs_kd 0.2408 (0.1498) loss_oracle 0.2480 (0.2269) acc 78.1250 (71.1328) kd_loss 0.6376 (0.5399) lr 1.1253e-03 eta 0:16:12
epoch [25/50] batch [100/244] time 0.105 (0.156) data 0.000 (0.003) loss 1.5426 (1.3711) ce_loss 1.2881 (1.0832) teacher_loss 1.2374 (1.0637) loss_zs_kd 0.1285 (0.1559) loss_oracle 0.2410 (0.2294) acc 65.6250 (71.2812) kd_loss 0.3823 (0.5387) lr 1.1253e-03 eta 0:16:11
epoch [25/50] batch [120/244] time 0.087 (0.154) data 0.000 (0.003) loss 1.8186 (1.3716) ce_loss 1.4961 (1.0801) teacher_loss 1.5098 (1.0616) loss_zs_kd 0.1423 (0.1588) loss_oracle 0.2376 (0.2306) acc 59.3750 (71.2500) kd_loss 0.6114 (0.5412) lr 1.1253e-03 eta 0:15:55
epoch [25/50] batch [140/244] time 0.084 (0.155) data 0.000 (0.002) loss 1.3990 (1.3808) ce_loss 1.0986 (1.0893) teacher_loss 1.0487 (1.0703) loss_zs_kd 0.2026 (0.1593) loss_oracle 0.2490 (0.2309) acc 68.7500 (71.0045) kd_loss 0.6693 (0.5403) lr 1.1253e-03 eta 0:16:01
epoch [25/50] batch [160/244] time 0.148 (0.153) data 0.000 (0.002) loss 1.5793 (1.3867) ce_loss 1.2520 (1.0932) teacher_loss 1.2668 (1.0742) loss_zs_kd 0.1610 (0.1592) loss_oracle 0.2321 (0.2328) acc 71.8750 (71.1523) kd_loss 0.5927 (0.5444) lr 1.1253e-03 eta 0:15:44
epoch [25/50] batch [180/244] time 0.162 (0.154) data 0.000 (0.002) loss 1.6681 (1.3852) ce_loss 1.3428 (1.0900) teacher_loss 1.2936 (1.0710) loss_zs_kd 0.1359 (0.1587) loss_oracle 0.3066 (0.2349) acc 62.5000 (71.1111) kd_loss 0.6385 (0.5451) lr 1.1253e-03 eta 0:15:47
epoch [25/50] batch [200/244] time 0.150 (0.154) data 0.000 (0.002) loss 1.3499 (1.3901) ce_loss 0.9819 (1.0933) teacher_loss 0.9962 (1.0747) loss_zs_kd 0.2049 (0.1585) loss_oracle 0.2512 (0.2362) acc 75.0000 (71.0938) kd_loss 0.6025 (0.5470) lr 1.1253e-03 eta 0:15:48
epoch [25/50] batch [220/244] time 0.151 (0.155) data 0.000 (0.002) loss 1.0317 (1.3879) ce_loss 0.7065 (1.0914) teacher_loss 0.7053 (1.0719) loss_zs_kd 0.1850 (0.1581) loss_oracle 0.2339 (0.2369) acc 71.8750 (71.0938) kd_loss 0.6089 (0.5472) lr 1.1253e-03 eta 0:15:46
epoch [25/50] batch [240/244] time 0.156 (0.155) data 0.000 (0.001) loss 1.2066 (1.3894) ce_loss 0.9243 (1.0910) teacher_loss 0.8833 (1.0714) loss_zs_kd 0.1710 (0.1594) loss_oracle 0.2377 (0.2383) acc 78.1250 (71.2370) kd_loss 0.4018 (0.5478) lr 1.1253e-03 eta 0:15:44
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,822
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [26/50] batch [20/244] time 0.155 (0.170) data 0.000 (0.014) loss 1.2067 (1.3450) ce_loss 0.9546 (1.0415) teacher_loss 0.9316 (1.0325) loss_zs_kd 0.1572 (0.1665) loss_oracle 0.1965 (0.2293) acc 75.0000 (72.5000) kd_loss 0.5380 (0.5063) lr 1.0628e-03 eta 0:17:14
epoch [26/50] batch [40/244] time 0.148 (0.161) data 0.000 (0.007) loss 1.5398 (1.3189) ce_loss 1.2168 (1.0118) teacher_loss 1.1989 (0.9996) loss_zs_kd 0.1324 (0.1663) loss_oracle 0.2748 (0.2361) acc 65.6250 (72.8125) kd_loss 0.6580 (0.5364) lr 1.0628e-03 eta 0:16:13
epoch [26/50] batch [60/244] time 0.156 (0.158) data 0.000 (0.005) loss 1.0153 (1.3421) ce_loss 0.7949 (1.0480) teacher_loss 0.7308 (1.0328) loss_zs_kd 0.1266 (0.1615) loss_oracle 0.2212 (0.2285) acc 75.0000 (71.6146) kd_loss 0.4262 (0.5262) lr 1.0628e-03 eta 0:15:56
epoch [26/50] batch [80/244] time 0.157 (0.157) data 0.000 (0.004) loss 1.2089 (1.3474) ce_loss 0.9175 (1.0541) teacher_loss 0.9222 (1.0371) loss_zs_kd 0.1624 (0.1635) loss_oracle 0.2055 (0.2285) acc 84.3750 (71.6406) kd_loss 0.4972 (0.5301) lr 1.0628e-03 eta 0:15:45
epoch [26/50] batch [100/244] time 0.169 (0.156) data 0.000 (0.003) loss 1.6777 (1.3477) ce_loss 1.3643 (1.0546) teacher_loss 1.3088 (1.0387) loss_zs_kd 0.1559 (0.1645) loss_oracle 0.2910 (0.2267) acc 62.5000 (71.4375) kd_loss 0.6420 (0.5277) lr 1.0628e-03 eta 0:15:38
epoch [26/50] batch [120/244] time 0.140 (0.155) data 0.000 (0.003) loss 1.1700 (1.3509) ce_loss 0.8794 (1.0594) teacher_loss 0.8332 (1.0430) loss_zs_kd 0.1721 (0.1628) loss_oracle 0.2508 (0.2265) acc 84.3750 (71.5365) kd_loss 0.7214 (0.5313) lr 1.0628e-03 eta 0:15:27
epoch [26/50] batch [140/244] time 0.092 (0.150) data 0.000 (0.002) loss 1.8548 (1.3653) ce_loss 1.5840 (1.0739) teacher_loss 1.5261 (1.0566) loss_zs_kd 0.1247 (0.1618) loss_oracle 0.2664 (0.2278) acc 62.5000 (71.5402) kd_loss 0.5221 (0.5331) lr 1.0628e-03 eta 0:14:53
epoch [26/50] batch [160/244] time 0.088 (0.149) data 0.000 (0.002) loss 1.6357 (1.3741) ce_loss 1.3818 (1.0839) teacher_loss 1.3438 (1.0657) loss_zs_kd 0.1716 (0.1625) loss_oracle 0.2061 (0.2271) acc 65.6250 (71.2695) kd_loss 0.3882 (0.5346) lr 1.0628e-03 eta 0:14:46
epoch [26/50] batch [180/244] time 0.100 (0.150) data 0.000 (0.002) loss 1.1327 (1.3615) ce_loss 0.7329 (1.0706) teacher_loss 0.7608 (1.0542) loss_zs_kd 0.2155 (0.1616) loss_oracle 0.2642 (0.2265) acc 78.1250 (71.7188) kd_loss 0.6139 (0.5358) lr 1.0628e-03 eta 0:14:47
epoch [26/50] batch [200/244] time 0.093 (0.148) data 0.000 (0.002) loss 1.0527 (1.3654) ce_loss 0.7964 (1.0747) teacher_loss 0.7637 (1.0567) loss_zs_kd 0.1472 (0.1616) loss_oracle 0.2154 (0.2279) acc 84.3750 (71.6094) kd_loss 0.3487 (0.5375) lr 1.0628e-03 eta 0:14:31
epoch [26/50] batch [220/244] time 0.093 (0.143) data 0.000 (0.001) loss 1.2722 (1.3727) ce_loss 1.0098 (1.0832) teacher_loss 0.9959 (1.0640) loss_zs_kd 0.1195 (0.1618) loss_oracle 0.2165 (0.2278) acc 75.0000 (71.4205) kd_loss 0.5259 (0.5398) lr 1.0628e-03 eta 0:14:00
epoch [26/50] batch [240/244] time 0.085 (0.139) data 0.000 (0.001) loss 1.2488 (1.3735) ce_loss 0.9678 (1.0839) teacher_loss 0.9669 (1.0649) loss_zs_kd 0.0836 (0.1613) loss_oracle 0.2401 (0.2279) acc 75.0000 (71.4193) kd_loss 0.5867 (0.5400) lr 1.0628e-03 eta 0:13:32
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,819
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [27/50] batch [20/244] time 0.098 (0.130) data 0.000 (0.013) loss 1.3687 (1.3068) ce_loss 1.0703 (0.9930) teacher_loss 1.0517 (0.9902) loss_zs_kd 0.1803 (0.1530) loss_oracle 0.2269 (0.2402) acc 68.7500 (72.5000) kd_loss 0.5137 (0.5667) lr 1.0000e-03 eta 0:12:37
epoch [27/50] batch [40/244] time 0.091 (0.113) data 0.000 (0.007) loss 1.0049 (1.3274) ce_loss 0.7007 (1.0245) teacher_loss 0.7292 (1.0122) loss_zs_kd 0.1163 (0.1623) loss_oracle 0.2175 (0.2340) acc 78.1250 (73.4375) kd_loss 0.4926 (0.5720) lr 1.0000e-03 eta 0:10:55
epoch [27/50] batch [60/244] time 0.101 (0.107) data 0.000 (0.005) loss 1.5112 (1.3633) ce_loss 1.1514 (1.0591) teacher_loss 1.1849 (1.0450) loss_zs_kd 0.1610 (0.1663) loss_oracle 0.2457 (0.2351) acc 71.8750 (72.4479) kd_loss 0.6406 (0.5760) lr 1.0000e-03 eta 0:10:17
epoch [27/50] batch [80/244] time 0.096 (0.104) data 0.000 (0.004) loss 1.6642 (1.3745) ce_loss 1.4844 (1.0732) teacher_loss 1.3693 (1.0568) loss_zs_kd 0.1845 (0.1692) loss_oracle 0.2026 (0.2331) acc 56.2500 (71.7188) kd_loss 0.3732 (0.5667) lr 1.0000e-03 eta 0:09:58
epoch [27/50] batch [100/244] time 0.094 (0.102) data 0.000 (0.003) loss 1.2795 (1.3685) ce_loss 0.9873 (1.0646) teacher_loss 0.9603 (1.0481) loss_zs_kd 0.1450 (0.1716) loss_oracle 0.2467 (0.2346) acc 71.8750 (72.0312) kd_loss 0.4475 (0.5646) lr 1.0000e-03 eta 0:09:47
epoch [27/50] batch [120/244] time 0.100 (0.101) data 0.001 (0.002) loss 1.0024 (1.3711) ce_loss 0.6401 (1.0660) teacher_loss 0.6379 (1.0466) loss_zs_kd 0.1932 (0.1728) loss_oracle 0.2678 (0.2380) acc 84.3750 (71.9010) kd_loss 0.6735 (0.5666) lr 1.0000e-03 eta 0:09:39
epoch [27/50] batch [140/244] time 0.096 (0.100) data 0.000 (0.002) loss 1.2046 (1.3582) ce_loss 0.8604 (1.0544) teacher_loss 0.9028 (1.0371) loss_zs_kd 0.1431 (0.1703) loss_oracle 0.2302 (0.2359) acc 75.0000 (72.0982) kd_loss 0.5022 (0.5592) lr 1.0000e-03 eta 0:09:33
epoch [27/50] batch [160/244] time 0.089 (0.100) data 0.000 (0.002) loss 1.2551 (1.3482) ce_loss 0.9292 (1.0468) teacher_loss 0.8876 (1.0288) loss_zs_kd 0.1811 (0.1713) loss_oracle 0.2769 (0.2337) acc 75.0000 (72.3438) kd_loss 0.6282 (0.5528) lr 1.0000e-03 eta 0:09:28
epoch [27/50] batch [180/244] time 0.102 (0.099) data 0.001 (0.002) loss 1.3071 (1.3469) ce_loss 0.9634 (1.0470) teacher_loss 0.9543 (1.0294) loss_zs_kd 0.1635 (0.1700) loss_oracle 0.2711 (0.2325) acc 75.0000 (72.5521) kd_loss 0.6564 (0.5533) lr 1.0000e-03 eta 0:09:24
epoch [27/50] batch [200/244] time 0.094 (0.099) data 0.000 (0.002) loss 1.5832 (1.3506) ce_loss 1.3838 (1.0535) teacher_loss 1.3342 (1.0349) loss_zs_kd 0.1391 (0.1679) loss_oracle 0.1794 (0.2317) acc 65.6250 (72.4219) kd_loss 0.4792 (0.5542) lr 1.0000e-03 eta 0:09:20
epoch [27/50] batch [220/244] time 0.091 (0.099) data 0.000 (0.001) loss 1.3144 (1.3478) ce_loss 1.0225 (1.0502) teacher_loss 0.9663 (1.0314) loss_zs_kd 0.1756 (0.1677) loss_oracle 0.2603 (0.2326) acc 71.8750 (72.5994) kd_loss 0.5438 (0.5530) lr 1.0000e-03 eta 0:09:15
epoch [27/50] batch [240/244] time 0.087 (0.098) data 0.000 (0.001) loss 1.4680 (1.3533) ce_loss 1.1338 (1.0555) teacher_loss 1.1641 (1.0356) loss_zs_kd 0.1292 (0.1656) loss_oracle 0.2393 (0.2349) acc 71.8750 (72.4740) kd_loss 0.6419 (0.5542) lr 1.0000e-03 eta 0:09:10
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,814
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,032
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [28/50] batch [20/244] time 0.096 (0.125) data 0.000 (0.017) loss 1.6774 (1.3293) ce_loss 1.2725 (1.0186) teacher_loss 1.3045 (0.9960) loss_zs_kd 0.2000 (0.1570) loss_oracle 0.2729 (0.2548) acc 71.8750 (73.5938) kd_loss 0.7961 (0.5933) lr 9.3721e-04 eta 0:11:41
epoch [28/50] batch [40/244] time 0.102 (0.118) data 0.000 (0.008) loss 1.5341 (1.3661) ce_loss 1.1641 (1.0603) teacher_loss 1.2026 (1.0375) loss_zs_kd 0.1922 (0.1654) loss_oracle 0.2353 (0.2459) acc 68.7500 (71.7969) kd_loss 0.6662 (0.5693) lr 9.3721e-04 eta 0:10:58
epoch [28/50] batch [60/244] time 0.116 (0.115) data 0.001 (0.006) loss 1.5102 (1.3535) ce_loss 1.2119 (1.0541) teacher_loss 1.1618 (1.0310) loss_zs_kd 0.1825 (0.1622) loss_oracle 0.2572 (0.2414) acc 68.7500 (71.7188) kd_loss 0.6450 (0.5581) lr 9.3721e-04 eta 0:10:37
epoch [28/50] batch [80/244] time 0.108 (0.113) data 0.000 (0.004) loss 1.8263 (1.3876) ce_loss 1.4941 (1.0902) teacher_loss 1.5070 (1.0693) loss_zs_kd 0.1947 (0.1618) loss_oracle 0.2220 (0.2374) acc 65.6250 (71.0547) kd_loss 0.4689 (0.5561) lr 9.3721e-04 eta 0:10:24
epoch [28/50] batch [100/244] time 0.105 (0.112) data 0.000 (0.003) loss 1.5488 (1.3867) ce_loss 1.2871 (1.0900) teacher_loss 1.2351 (1.0694) loss_zs_kd 0.1488 (0.1616) loss_oracle 0.2392 (0.2366) acc 62.5000 (71.2500) kd_loss 0.5226 (0.5508) lr 9.3721e-04 eta 0:10:14
epoch [28/50] batch [120/244] time 0.110 (0.111) data 0.000 (0.003) loss 1.4270 (1.3966) ce_loss 1.0723 (1.0986) teacher_loss 1.1117 (1.0795) loss_zs_kd 0.1397 (0.1630) loss_oracle 0.2455 (0.2357) acc 81.2500 (71.0677) kd_loss 0.5147 (0.5496) lr 9.3721e-04 eta 0:10:08
epoch [28/50] batch [140/244] time 0.105 (0.110) data 0.000 (0.003) loss 1.6244 (1.3851) ce_loss 1.3330 (1.0867) teacher_loss 1.3144 (1.0675) loss_zs_kd 0.1683 (0.1626) loss_oracle 0.2259 (0.2363) acc 59.3750 (71.5179) kd_loss 0.6169 (0.5515) lr 9.3721e-04 eta 0:10:03
epoch [28/50] batch [160/244] time 0.108 (0.110) data 0.000 (0.002) loss 1.6389 (1.3788) ce_loss 1.3018 (1.0823) teacher_loss 1.2888 (1.0625) loss_zs_kd 0.2433 (0.1629) loss_oracle 0.2285 (0.2349) acc 59.3750 (71.5625) kd_loss 0.4542 (0.5485) lr 9.3721e-04 eta 0:09:58
epoch [28/50] batch [180/244] time 0.103 (0.110) data 0.000 (0.002) loss 1.1259 (1.3717) ce_loss 0.8203 (1.0751) teacher_loss 0.8536 (1.0565) loss_zs_kd 0.1812 (0.1618) loss_oracle 0.1817 (0.2343) acc 78.1250 (71.7188) kd_loss 0.5878 (0.5481) lr 9.3721e-04 eta 0:09:54
epoch [28/50] batch [200/244] time 0.104 (0.109) data 0.000 (0.002) loss 1.3155 (1.3621) ce_loss 1.0049 (1.0666) teacher_loss 0.9885 (1.0481) loss_zs_kd 0.2115 (0.1615) loss_oracle 0.2213 (0.2332) acc 68.7500 (71.8281) kd_loss 0.4991 (0.5467) lr 9.3721e-04 eta 0:09:51
epoch [28/50] batch [220/244] time 0.105 (0.109) data 0.000 (0.002) loss 1.1942 (1.3556) ce_loss 0.9009 (1.0610) teacher_loss 0.9013 (1.0431) loss_zs_kd 0.1860 (0.1610) loss_oracle 0.1999 (0.2320) acc 75.0000 (71.8750) kd_loss 0.5415 (0.5463) lr 9.3721e-04 eta 0:09:48
epoch [28/50] batch [240/244] time 0.091 (0.108) data 0.000 (0.002) loss 1.2858 (1.3530) ce_loss 0.9980 (1.0589) teacher_loss 1.0022 (1.0405) loss_zs_kd 0.1195 (0.1604) loss_oracle 0.2239 (0.2323) acc 71.8750 (71.8359) kd_loss 0.4679 (0.5493) lr 9.3721e-04 eta 0:09:40
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,815
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [29/50] batch [20/244] time 0.093 (0.110) data 0.000 (0.012) loss 1.1814 (1.3228) ce_loss 0.8594 (1.0382) teacher_loss 0.8574 (1.0085) loss_zs_kd 0.1647 (0.1634) loss_oracle 0.2417 (0.2326) acc 81.2500 (74.2188) kd_loss 0.4961 (0.5629) lr 8.7467e-04 eta 0:09:47
epoch [29/50] batch [40/244] time 0.098 (0.107) data 0.000 (0.006) loss 1.5865 (1.3701) ce_loss 1.3018 (1.0746) teacher_loss 1.2921 (1.0506) loss_zs_kd 0.1485 (0.1640) loss_oracle 0.2201 (0.2375) acc 68.7500 (72.0312) kd_loss 0.5121 (0.5654) lr 8.7467e-04 eta 0:09:31
epoch [29/50] batch [60/244] time 0.105 (0.104) data 0.001 (0.004) loss 1.7319 (1.3748) ce_loss 1.4707 (1.0819) teacher_loss 1.4409 (1.0572) loss_zs_kd 0.1396 (0.1582) loss_oracle 0.2212 (0.2385) acc 59.3750 (71.5625) kd_loss 0.5865 (0.5650) lr 8.7467e-04 eta 0:09:09
epoch [29/50] batch [80/244] time 0.102 (0.104) data 0.000 (0.003) loss 0.7907 (1.3849) ce_loss 0.4946 (1.0888) teacher_loss 0.4924 (1.0687) loss_zs_kd 0.1417 (0.1587) loss_oracle 0.2274 (0.2368) acc 87.5000 (71.6797) kd_loss 0.6052 (0.5682) lr 8.7467e-04 eta 0:09:11
epoch [29/50] batch [100/244] time 0.106 (0.105) data 0.000 (0.003) loss 1.5183 (1.3935) ce_loss 1.2588 (1.1021) teacher_loss 1.2210 (1.0789) loss_zs_kd 0.1192 (0.1600) loss_oracle 0.2377 (0.2347) acc 71.8750 (71.2188) kd_loss 0.6218 (0.5585) lr 8.7467e-04 eta 0:09:10
epoch [29/50] batch [120/244] time 0.112 (0.105) data 0.000 (0.002) loss 1.5135 (1.4021) ce_loss 1.1650 (1.1106) teacher_loss 1.1493 (1.0871) loss_zs_kd 0.2174 (0.1617) loss_oracle 0.2555 (0.2341) acc 68.7500 (71.0156) kd_loss 0.5298 (0.5550) lr 8.7467e-04 eta 0:09:10
epoch [29/50] batch [140/244] time 0.110 (0.105) data 0.000 (0.002) loss 2.1955 (1.4001) ce_loss 1.8926 (1.1086) teacher_loss 1.9046 (1.0860) loss_zs_kd 0.1958 (0.1615) loss_oracle 0.1930 (0.2334) acc 56.2500 (71.1161) kd_loss 0.3430 (0.5534) lr 8.7467e-04 eta 0:09:10
epoch [29/50] batch [160/244] time 0.108 (0.106) data 0.000 (0.002) loss 1.3053 (1.3914) ce_loss 1.0371 (1.0998) teacher_loss 0.9905 (1.0770) loss_zs_kd 0.1831 (0.1616) loss_oracle 0.2232 (0.2336) acc 75.0000 (71.3672) kd_loss 0.4604 (0.5484) lr 8.7467e-04 eta 0:09:11
epoch [29/50] batch [180/244] time 0.110 (0.106) data 0.000 (0.002) loss 2.0537 (1.4018) ce_loss 1.8398 (1.1089) teacher_loss 1.7581 (1.0870) loss_zs_kd 0.1516 (0.1610) loss_oracle 0.2198 (0.2343) acc 53.1250 (71.3368) kd_loss 0.5479 (0.5508) lr 8.7467e-04 eta 0:09:09
epoch [29/50] batch [200/244] time 0.108 (0.106) data 0.000 (0.001) loss 1.3918 (1.3957) ce_loss 1.1055 (1.1018) teacher_loss 1.0981 (1.0795) loss_zs_kd 0.1824 (0.1611) loss_oracle 0.2025 (0.2356) acc 68.7500 (71.3750) kd_loss 0.4237 (0.5515) lr 8.7467e-04 eta 0:09:07
epoch [29/50] batch [220/244] time 0.104 (0.106) data 0.000 (0.001) loss 1.0058 (1.3920) ce_loss 0.7163 (1.0984) teacher_loss 0.6737 (1.0757) loss_zs_kd 0.1252 (0.1606) loss_oracle 0.2695 (0.2360) acc 81.2500 (71.4915) kd_loss 0.5890 (0.5483) lr 8.7467e-04 eta 0:09:06
epoch [29/50] batch [240/244] time 0.104 (0.106) data 0.000 (0.001) loss 1.0316 (1.3831) ce_loss 0.7041 (1.0888) teacher_loss 0.7040 (1.0663) loss_zs_kd 0.1351 (0.1603) loss_oracle 0.2600 (0.2366) acc 81.2500 (71.6797) kd_loss 0.5815 (0.5501) lr 8.7467e-04 eta 0:09:04
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,819
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,042
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [30/50] batch [20/244] time 0.099 (0.137) data 0.000 (0.017) loss 1.0740 (1.3275) ce_loss 0.8008 (1.0164) teacher_loss 0.7668 (1.0021) loss_zs_kd 0.1382 (0.1585) loss_oracle 0.2381 (0.2462) acc 75.0000 (73.1250) kd_loss 0.4967 (0.5485) lr 8.1262e-04 eta 0:11:40
epoch [30/50] batch [40/244] time 0.098 (0.121) data 0.000 (0.009) loss 0.9984 (1.3253) ce_loss 0.7505 (1.0256) teacher_loss 0.6943 (1.0077) loss_zs_kd 0.1377 (0.1547) loss_oracle 0.2352 (0.2403) acc 81.2500 (72.8125) kd_loss 0.4759 (0.5523) lr 8.1262e-04 eta 0:10:13
epoch [30/50] batch [60/244] time 0.106 (0.116) data 0.001 (0.006) loss 1.1604 (1.3515) ce_loss 0.7896 (1.0497) teacher_loss 0.7977 (1.0316) loss_zs_kd 0.1769 (0.1564) loss_oracle 0.2742 (0.2416) acc 84.3750 (71.9792) kd_loss 0.5581 (0.5560) lr 8.1262e-04 eta 0:09:48
epoch [30/50] batch [80/244] time 0.105 (0.115) data 0.000 (0.005) loss 1.1471 (1.3587) ce_loss 0.7812 (1.0611) teacher_loss 0.7622 (1.0416) loss_zs_kd 0.1962 (0.1571) loss_oracle 0.2868 (0.2385) acc 75.0000 (71.5625) kd_loss 0.6522 (0.5502) lr 8.1262e-04 eta 0:09:39
epoch [30/50] batch [100/244] time 0.176 (0.117) data 0.000 (0.004) loss 0.8102 (1.3720) ce_loss 0.5435 (1.0752) teacher_loss 0.5453 (1.0551) loss_zs_kd 0.1343 (0.1599) loss_oracle 0.1977 (0.2369) acc 87.5000 (71.4688) kd_loss 0.4776 (0.5472) lr 8.1262e-04 eta 0:09:48
epoch [30/50] batch [120/244] time 0.173 (0.125) data 0.000 (0.003) loss 1.2883 (1.3671) ce_loss 1.0020 (1.0701) teacher_loss 0.9844 (1.0491) loss_zs_kd 0.1330 (0.1601) loss_oracle 0.2374 (0.2380) acc 65.6250 (71.3281) kd_loss 0.4779 (0.5511) lr 8.1262e-04 eta 0:10:26
epoch [30/50] batch [140/244] time 0.146 (0.129) data 0.000 (0.003) loss 1.1115 (1.3517) ce_loss 0.7568 (1.0534) teacher_loss 0.7185 (1.0314) loss_zs_kd 0.2427 (0.1605) loss_oracle 0.2717 (0.2401) acc 78.1250 (71.8750) kd_loss 0.6183 (0.5574) lr 8.1262e-04 eta 0:10:44
epoch [30/50] batch [160/244] time 0.152 (0.133) data 0.000 (0.002) loss 0.9525 (1.3570) ce_loss 0.7080 (1.0599) teacher_loss 0.6180 (1.0365) loss_zs_kd 0.1839 (0.1622) loss_oracle 0.2425 (0.2394) acc 75.0000 (71.6602) kd_loss 0.4491 (0.5540) lr 8.1262e-04 eta 0:10:58
epoch [30/50] batch [180/244] time 0.148 (0.135) data 0.000 (0.002) loss 1.4653 (1.3553) ce_loss 1.0996 (1.0579) teacher_loss 1.1218 (1.0347) loss_zs_kd 0.1895 (0.1626) loss_oracle 0.2488 (0.2393) acc 75.0000 (71.7882) kd_loss 0.7380 (0.5548) lr 8.1262e-04 eta 0:11:09
epoch [30/50] batch [200/244] time 0.167 (0.138) data 0.000 (0.002) loss 1.2395 (1.3545) ce_loss 0.9331 (1.0562) teacher_loss 0.9408 (1.0324) loss_zs_kd 0.1585 (0.1635) loss_oracle 0.2195 (0.2404) acc 65.6250 (71.8281) kd_loss 0.5008 (0.5552) lr 8.1262e-04 eta 0:11:17
epoch [30/50] batch [220/244] time 0.152 (0.139) data 0.000 (0.002) loss 1.4221 (1.3610) ce_loss 1.0781 (1.0607) teacher_loss 1.1030 (1.0384) loss_zs_kd 0.1762 (0.1646) loss_oracle 0.2310 (0.2403) acc 65.6250 (71.7045) kd_loss 0.5652 (0.5561) lr 8.1262e-04 eta 0:11:20
epoch [30/50] batch [240/244] time 0.155 (0.140) data 0.000 (0.002) loss 1.2489 (1.3680) ce_loss 0.9297 (1.0681) teacher_loss 0.9314 (1.0460) loss_zs_kd 0.1651 (0.1639) loss_oracle 0.2350 (0.2400) acc 71.8750 (71.5365) kd_loss 0.5042 (0.5570) lr 8.1262e-04 eta 0:11:23
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,813
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [31/50] batch [20/244] time 0.176 (0.187) data 0.000 (0.015) loss 0.9767 (1.3296) ce_loss 0.6914 (1.0250) teacher_loss 0.6259 (1.0104) loss_zs_kd 0.1686 (0.1559) loss_oracle 0.2665 (0.2412) acc 75.0000 (70.6250) kd_loss 0.4892 (0.5915) lr 7.5131e-04 eta 0:15:07
epoch [31/50] batch [40/244] time 0.176 (0.176) data 0.000 (0.007) loss 1.3086 (1.3488) ce_loss 0.9990 (1.0385) teacher_loss 1.0286 (1.0324) loss_zs_kd 0.1621 (0.1617) loss_oracle 0.1989 (0.2356) acc 71.8750 (70.8594) kd_loss 0.4553 (0.5815) lr 7.5131e-04 eta 0:14:11
epoch [31/50] batch [60/244] time 0.106 (0.157) data 0.001 (0.005) loss 1.7419 (1.3783) ce_loss 1.4346 (1.0750) teacher_loss 1.4706 (1.0674) loss_zs_kd 0.1522 (0.1586) loss_oracle 0.1952 (0.2316) acc 59.3750 (69.8438) kd_loss 0.5110 (0.5538) lr 7.5131e-04 eta 0:12:35
epoch [31/50] batch [80/244] time 0.387 (0.152) data 0.000 (0.004) loss 1.5445 (1.3532) ce_loss 1.2344 (1.0517) teacher_loss 1.2648 (1.0395) loss_zs_kd 0.1549 (0.1586) loss_oracle 0.2023 (0.2344) acc 68.7500 (71.0938) kd_loss 0.5299 (0.5622) lr 7.5131e-04 eta 0:12:10
epoch [31/50] batch [100/244] time 0.124 (0.148) data 0.000 (0.003) loss 1.6016 (1.3346) ce_loss 1.2275 (1.0330) teacher_loss 1.2469 (1.0194) loss_zs_kd 0.2370 (0.1592) loss_oracle 0.2362 (0.2356) acc 68.7500 (71.6250) kd_loss 0.5383 (0.5618) lr 7.5131e-04 eta 0:11:48
epoch [31/50] batch [120/244] time 0.095 (0.149) data 0.000 (0.003) loss 1.5365 (1.3563) ce_loss 1.1738 (1.0564) teacher_loss 1.1600 (1.0395) loss_zs_kd 0.3006 (0.1612) loss_oracle 0.2261 (0.2363) acc 65.6250 (71.0156) kd_loss 0.6050 (0.5649) lr 7.5131e-04 eta 0:11:51
epoch [31/50] batch [140/244] time 0.116 (0.149) data 0.000 (0.002) loss 0.9431 (1.3671) ce_loss 0.6904 (1.0682) teacher_loss 0.6310 (1.0517) loss_zs_kd 0.1695 (0.1615) loss_oracle 0.2273 (0.2347) acc 84.3750 (71.0491) kd_loss 0.5548 (0.5639) lr 7.5131e-04 eta 0:11:48
epoch [31/50] batch [160/244] time 0.395 (0.154) data 0.001 (0.002) loss 1.4120 (1.3523) ce_loss 1.1328 (1.0551) teacher_loss 1.1338 (1.0385) loss_zs_kd 0.1552 (0.1607) loss_oracle 0.2006 (0.2335) acc 71.8750 (71.5625) kd_loss 0.4508 (0.5639) lr 7.5131e-04 eta 0:12:07
epoch [31/50] batch [180/244] time 0.167 (0.156) data 0.000 (0.002) loss 1.1523 (1.3455) ce_loss 0.8218 (1.0489) teacher_loss 0.8025 (1.0328) loss_zs_kd 0.1647 (0.1612) loss_oracle 0.2675 (0.2320) acc 78.1250 (71.9792) kd_loss 0.7314 (0.5625) lr 7.5131e-04 eta 0:12:14
epoch [31/50] batch [200/244] time 0.086 (0.157) data 0.000 (0.002) loss 1.6913 (1.3515) ce_loss 1.3496 (1.0568) teacher_loss 1.2786 (1.0388) loss_zs_kd 0.2324 (0.1621) loss_oracle 0.2965 (0.2316) acc 75.0000 (71.7500) kd_loss 0.7549 (0.5599) lr 7.5131e-04 eta 0:12:16
epoch [31/50] batch [220/244] time 0.107 (0.153) data 0.000 (0.002) loss 1.2076 (1.3554) ce_loss 0.9175 (1.0616) teacher_loss 0.8980 (1.0430) loss_zs_kd 0.1271 (0.1621) loss_oracle 0.2461 (0.2314) acc 68.7500 (71.6619) kd_loss 0.5196 (0.5594) lr 7.5131e-04 eta 0:11:54
epoch [31/50] batch [240/244] time 0.176 (0.154) data 0.000 (0.001) loss 1.1058 (1.3572) ce_loss 0.8120 (1.0635) teacher_loss 0.8088 (1.0442) loss_zs_kd 0.1693 (0.1630) loss_oracle 0.2124 (0.2315) acc 81.2500 (71.6927) kd_loss 0.5089 (0.5586) lr 7.5131e-04 eta 0:11:54
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,818
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [32/50] batch [20/244] time 0.162 (0.184) data 0.000 (0.015) loss 1.6937 (1.3124) ce_loss 1.3955 (1.0216) teacher_loss 1.3874 (0.9955) loss_zs_kd 0.1556 (0.1653) loss_oracle 0.2285 (0.2343) acc 56.2500 (72.5000) kd_loss 0.5857 (0.5711) lr 6.9098e-04 eta 0:14:09
epoch [32/50] batch [40/244] time 0.145 (0.171) data 0.000 (0.007) loss 1.3569 (1.3358) ce_loss 1.0967 (1.0466) teacher_loss 1.0434 (1.0192) loss_zs_kd 0.1499 (0.1611) loss_oracle 0.2385 (0.2360) acc 75.0000 (73.3594) kd_loss 0.7791 (0.5625) lr 6.9098e-04 eta 0:13:08
epoch [32/50] batch [60/244] time 0.154 (0.165) data 0.000 (0.005) loss 1.4428 (1.3608) ce_loss 1.0898 (1.0634) teacher_loss 1.0558 (1.0407) loss_zs_kd 0.2250 (0.1676) loss_oracle 0.2746 (0.2363) acc 71.8750 (72.9167) kd_loss 0.6187 (0.5647) lr 6.9098e-04 eta 0:12:32
epoch [32/50] batch [80/244] time 0.148 (0.162) data 0.000 (0.004) loss 1.1679 (1.3603) ce_loss 0.8276 (1.0585) teacher_loss 0.8156 (1.0353) loss_zs_kd 0.2073 (0.1682) loss_oracle 0.2486 (0.2409) acc 81.2500 (72.5781) kd_loss 0.5113 (0.5654) lr 6.9098e-04 eta 0:12:17
epoch [32/50] batch [100/244] time 0.149 (0.160) data 0.000 (0.003) loss 1.5803 (1.3881) ce_loss 1.2256 (1.0830) teacher_loss 1.2021 (1.0598) loss_zs_kd 0.1869 (0.1707) loss_oracle 0.2847 (0.2430) acc 68.7500 (71.9062) kd_loss 0.8508 (0.5662) lr 6.9098e-04 eta 0:12:05
epoch [32/50] batch [120/244] time 0.176 (0.159) data 0.000 (0.003) loss 1.0469 (1.3970) ce_loss 0.7275 (1.0891) teacher_loss 0.7117 (1.0674) loss_zs_kd 0.1999 (0.1688) loss_oracle 0.2352 (0.2451) acc 78.1250 (71.7448) kd_loss 0.4643 (0.5721) lr 6.9098e-04 eta 0:11:56
epoch [32/50] batch [140/244] time 0.150 (0.158) data 0.000 (0.002) loss 1.4719 (1.3851) ce_loss 1.1787 (1.0754) teacher_loss 1.1309 (1.0530) loss_zs_kd 0.1724 (0.1681) loss_oracle 0.2547 (0.2481) acc 62.5000 (72.1429) kd_loss 0.5063 (0.5682) lr 6.9098e-04 eta 0:11:48
epoch [32/50] batch [160/244] time 0.147 (0.157) data 0.000 (0.002) loss 1.3687 (1.3820) ce_loss 1.0166 (1.0699) teacher_loss 0.9860 (1.0484) loss_zs_kd 0.2214 (0.1679) loss_oracle 0.2719 (0.2497) acc 78.1250 (72.3242) kd_loss 0.5930 (0.5703) lr 6.9098e-04 eta 0:11:41
epoch [32/50] batch [180/244] time 0.148 (0.156) data 0.000 (0.002) loss 1.0563 (1.3896) ce_loss 0.7305 (1.0781) teacher_loss 0.7242 (1.0578) loss_zs_kd 0.2273 (0.1657) loss_oracle 0.2185 (0.2490) acc 90.6250 (72.3611) kd_loss 0.4129 (0.5711) lr 6.9098e-04 eta 0:11:34
epoch [32/50] batch [200/244] time 0.130 (0.152) data 0.000 (0.002) loss 1.4227 (1.3934) ce_loss 1.1279 (1.0834) teacher_loss 1.1374 (1.0629) loss_zs_kd 0.1454 (0.1656) loss_oracle 0.2126 (0.2477) acc 68.7500 (72.0938) kd_loss 0.5754 (0.5651) lr 6.9098e-04 eta 0:11:13
epoch [32/50] batch [220/244] time 0.179 (0.153) data 0.000 (0.002) loss 1.7016 (1.3936) ce_loss 1.3818 (1.0848) teacher_loss 1.3496 (1.0646) loss_zs_kd 0.1866 (0.1641) loss_oracle 0.2587 (0.2469) acc 59.3750 (71.8608) kd_loss 0.6075 (0.5645) lr 6.9098e-04 eta 0:11:16
epoch [32/50] batch [240/244] time 0.084 (0.152) data 0.000 (0.001) loss 1.1351 (1.3999) ce_loss 0.8315 (1.0910) teacher_loss 0.8112 (1.0718) loss_zs_kd 0.1307 (0.1629) loss_oracle 0.2585 (0.2466) acc 75.0000 (71.7057) kd_loss 0.6562 (0.5651) lr 6.9098e-04 eta 0:11:09
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,815
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [33/50] batch [20/244] time 0.099 (0.179) data 0.000 (0.018) loss 1.3392 (1.3919) ce_loss 1.0908 (1.0868) teacher_loss 1.0473 (1.0715) loss_zs_kd 0.1205 (0.1522) loss_oracle 0.2317 (0.2442) acc 78.1250 (72.8125) kd_loss 0.5026 (0.5671) lr 6.3188e-04 eta 0:13:02
epoch [33/50] batch [40/244] time 0.095 (0.163) data 0.000 (0.009) loss 1.0885 (1.3372) ce_loss 0.8184 (1.0378) teacher_loss 0.7813 (1.0167) loss_zs_kd 0.1416 (0.1545) loss_oracle 0.2364 (0.2432) acc 78.1250 (73.9844) kd_loss 0.5961 (0.5816) lr 6.3188e-04 eta 0:11:48
epoch [33/50] batch [60/244] time 0.154 (0.161) data 0.001 (0.006) loss 2.2136 (1.3640) ce_loss 1.8828 (1.0713) teacher_loss 1.8896 (1.0507) loss_zs_kd 0.1723 (0.1552) loss_oracle 0.2377 (0.2357) acc 56.2500 (72.1354) kd_loss 0.5540 (0.5552) lr 6.3188e-04 eta 0:11:39
epoch [33/50] batch [80/244] time 0.178 (0.164) data 0.000 (0.005) loss 1.3747 (1.3884) ce_loss 1.0283 (1.0946) teacher_loss 1.0418 (1.0728) loss_zs_kd 0.1932 (0.1591) loss_oracle 0.2363 (0.2360) acc 75.0000 (71.7969) kd_loss 0.4677 (0.5563) lr 6.3188e-04 eta 0:11:49
epoch [33/50] batch [100/244] time 0.165 (0.167) data 0.000 (0.004) loss 1.2035 (1.3700) ce_loss 0.9478 (1.0759) teacher_loss 0.8728 (1.0555) loss_zs_kd 0.1678 (0.1572) loss_oracle 0.2468 (0.2359) acc 71.8750 (72.4062) kd_loss 0.4782 (0.5550) lr 6.3188e-04 eta 0:11:55
epoch [33/50] batch [120/244] time 0.152 (0.165) data 0.000 (0.003) loss 1.6143 (1.3763) ce_loss 1.2715 (1.0794) teacher_loss 1.2366 (1.0578) loss_zs_kd 0.2067 (0.1597) loss_oracle 0.2744 (0.2387) acc 59.3750 (72.2135) kd_loss 0.4389 (0.5559) lr 6.3188e-04 eta 0:11:43
epoch [33/50] batch [140/244] time 0.149 (0.163) data 0.000 (0.003) loss 1.2687 (1.3714) ce_loss 1.0059 (1.0758) teacher_loss 0.9975 (1.0547) loss_zs_kd 0.1399 (0.1592) loss_oracle 0.2012 (0.2370) acc 68.7500 (72.3884) kd_loss 0.5369 (0.5531) lr 6.3188e-04 eta 0:11:32
epoch [33/50] batch [160/244] time 0.149 (0.162) data 0.000 (0.002) loss 0.9491 (1.3635) ce_loss 0.6284 (1.0680) teacher_loss 0.6556 (1.0470) loss_zs_kd 0.2018 (0.1607) loss_oracle 0.1927 (0.2361) acc 90.6250 (72.6562) kd_loss 0.5244 (0.5507) lr 6.3188e-04 eta 0:11:27
epoch [33/50] batch [180/244] time 0.146 (0.162) data 0.000 (0.002) loss 1.8461 (1.3687) ce_loss 1.4854 (1.0751) teacher_loss 1.5046 (1.0538) loss_zs_kd 0.1803 (0.1597) loss_oracle 0.2513 (0.2351) acc 68.7500 (72.3611) kd_loss 0.6428 (0.5474) lr 6.3188e-04 eta 0:11:20
epoch [33/50] batch [200/244] time 0.152 (0.161) data 0.000 (0.002) loss 1.0556 (1.3734) ce_loss 0.7520 (1.0806) teacher_loss 0.7476 (1.0595) loss_zs_kd 0.1483 (0.1601) loss_oracle 0.2339 (0.2338) acc 81.2500 (72.1406) kd_loss 0.6281 (0.5476) lr 6.3188e-04 eta 0:11:15
epoch [33/50] batch [220/244] time 0.150 (0.160) data 0.000 (0.002) loss 1.5568 (1.3729) ce_loss 1.2139 (1.0812) teacher_loss 1.1907 (1.0595) loss_zs_kd 0.1727 (0.1604) loss_oracle 0.2798 (0.2332) acc 65.6250 (71.9886) kd_loss 0.6530 (0.5482) lr 6.3188e-04 eta 0:11:08
epoch [33/50] batch [240/244] time 0.148 (0.159) data 0.000 (0.002) loss 0.9472 (1.3700) ce_loss 0.6685 (1.0786) teacher_loss 0.6170 (1.0567) loss_zs_kd 0.1554 (0.1612) loss_oracle 0.2525 (0.2327) acc 75.0000 (71.9922) kd_loss 0.5641 (0.5464) lr 6.3188e-04 eta 0:11:02
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,820
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,027
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.2%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [34/50] batch [20/244] time 0.102 (0.138) data 0.000 (0.013) loss 1.2193 (1.3771) ce_loss 0.9521 (1.0903) teacher_loss 0.8982 (1.0604) loss_zs_kd 0.1689 (0.1621) loss_oracle 0.2368 (0.2357) acc 75.0000 (72.1875) kd_loss 0.5734 (0.5550) lr 5.7422e-04 eta 0:09:28
epoch [34/50] batch [40/244] time 0.084 (0.150) data 0.000 (0.007) loss 1.7659 (1.3571) ce_loss 1.5049 (1.0597) teacher_loss 1.4727 (1.0378) loss_zs_kd 0.1706 (0.1674) loss_oracle 0.2079 (0.2356) acc 65.6250 (72.1094) kd_loss 0.5546 (0.5513) lr 5.7422e-04 eta 0:10:16
epoch [34/50] batch [60/244] time 0.293 (0.145) data 0.000 (0.004) loss 1.5557 (1.3453) ce_loss 1.2979 (1.0491) teacher_loss 1.2683 (1.0279) loss_zs_kd 0.1765 (0.1651) loss_oracle 0.1992 (0.2348) acc 62.5000 (72.0833) kd_loss 0.5082 (0.5495) lr 5.7422e-04 eta 0:09:51
epoch [34/50] batch [80/244] time 0.188 (0.135) data 0.000 (0.003) loss 1.5695 (1.3328) ce_loss 1.3027 (1.0362) teacher_loss 1.3059 (1.0168) loss_zs_kd 0.1855 (0.1665) loss_oracle 0.1709 (0.2327) acc 71.8750 (72.5000) kd_loss 0.2672 (0.5422) lr 5.7422e-04 eta 0:09:10
epoch [34/50] batch [100/244] time 0.161 (0.141) data 0.000 (0.003) loss 1.2152 (1.3406) ce_loss 0.9556 (1.0464) teacher_loss 0.9131 (1.0271) loss_zs_kd 0.1760 (0.1654) loss_oracle 0.2141 (0.2307) acc 81.2500 (72.2500) kd_loss 0.5088 (0.5429) lr 5.7422e-04 eta 0:09:30
epoch [34/50] batch [120/244] time 0.094 (0.145) data 0.000 (0.002) loss 1.0218 (1.3396) ce_loss 0.7129 (1.0473) teacher_loss 0.7255 (1.0299) loss_zs_kd 0.1459 (0.1636) loss_oracle 0.2233 (0.2279) acc 78.1250 (72.2656) kd_loss 0.6436 (0.5384) lr 5.7422e-04 eta 0:09:45
epoch [34/50] batch [140/244] time 0.229 (0.149) data 0.000 (0.002) loss 1.0109 (1.3288) ce_loss 0.7441 (1.0383) teacher_loss 0.7250 (1.0208) loss_zs_kd 0.1470 (0.1615) loss_oracle 0.2124 (0.2272) acc 81.2500 (72.3661) kd_loss 0.3901 (0.5398) lr 5.7422e-04 eta 0:09:56
epoch [34/50] batch [160/244] time 0.084 (0.151) data 0.000 (0.002) loss 1.4093 (1.3326) ce_loss 1.1494 (1.0415) teacher_loss 1.1593 (1.0242) loss_zs_kd 0.1566 (0.1628) loss_oracle 0.1717 (0.2269) acc 71.8750 (72.3828) kd_loss 0.4412 (0.5399) lr 5.7422e-04 eta 0:10:02
epoch [34/50] batch [180/244] time 0.154 (0.148) data 0.000 (0.002) loss 1.6028 (1.3445) ce_loss 1.3311 (1.0526) teacher_loss 1.2972 (1.0363) loss_zs_kd 0.1722 (0.1632) loss_oracle 0.2195 (0.2265) acc 65.6250 (71.9097) kd_loss 0.4638 (0.5377) lr 5.7422e-04 eta 0:09:46
epoch [34/50] batch [200/244] time 0.149 (0.148) data 0.000 (0.002) loss 1.3492 (1.3405) ce_loss 1.0459 (1.0497) teacher_loss 1.0425 (1.0317) loss_zs_kd 0.1613 (0.1627) loss_oracle 0.2260 (0.2274) acc 71.8750 (72.1719) kd_loss 0.6044 (0.5369) lr 5.7422e-04 eta 0:09:45
epoch [34/50] batch [220/244] time 0.149 (0.149) data 0.000 (0.001) loss 1.3733 (1.3387) ce_loss 1.1211 (1.0477) teacher_loss 1.0769 (1.0294) loss_zs_kd 0.1102 (0.1623) loss_oracle 0.2413 (0.2281) acc 71.8750 (72.3864) kd_loss 0.6863 (0.5363) lr 5.7422e-04 eta 0:09:43
epoch [34/50] batch [240/244] time 0.177 (0.149) data 0.000 (0.001) loss 1.1489 (1.3376) ce_loss 0.8931 (1.0463) teacher_loss 0.8585 (1.0277) loss_zs_kd 0.1894 (0.1623) loss_oracle 0.1957 (0.2288) acc 78.1250 (72.4870) kd_loss 0.3568 (0.5366) lr 5.7422e-04 eta 0:09:42
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,814
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,032
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.4%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [35/50] batch [20/244] time 0.154 (0.168) data 0.000 (0.016) loss 1.3037 (1.3769) ce_loss 1.0664 (1.0861) teacher_loss 1.0500 (1.0697) loss_zs_kd 0.1546 (0.1692) loss_oracle 0.1764 (0.2226) acc 68.7500 (70.0000) kd_loss 0.3645 (0.5252) lr 5.1825e-04 eta 0:10:54
epoch [35/50] batch [40/244] time 0.150 (0.163) data 0.000 (0.008) loss 1.3597 (1.3968) ce_loss 1.0957 (1.1063) teacher_loss 1.0466 (1.0888) loss_zs_kd 0.1207 (0.1678) loss_oracle 0.2527 (0.2242) acc 62.5000 (69.8438) kd_loss 0.6402 (0.5502) lr 5.1825e-04 eta 0:10:30
epoch [35/50] batch [60/244] time 0.154 (0.160) data 0.001 (0.005) loss 1.1523 (1.3694) ce_loss 0.8696 (1.0889) teacher_loss 0.8555 (1.0626) loss_zs_kd 0.1348 (0.1668) loss_oracle 0.2294 (0.2233) acc 78.1250 (70.5729) kd_loss 0.6130 (0.5444) lr 5.1825e-04 eta 0:10:16
epoch [35/50] batch [80/244] time 0.157 (0.160) data 0.000 (0.004) loss 1.1694 (1.3677) ce_loss 0.8975 (1.0822) teacher_loss 0.8434 (1.0589) loss_zs_kd 0.1776 (0.1680) loss_oracle 0.2372 (0.2248) acc 81.2500 (70.8984) kd_loss 0.6459 (0.5440) lr 5.1825e-04 eta 0:10:12
epoch [35/50] batch [100/244] time 0.177 (0.161) data 0.000 (0.003) loss 1.0731 (1.3603) ce_loss 0.8262 (1.0704) teacher_loss 0.8118 (1.0487) loss_zs_kd 0.1641 (0.1705) loss_oracle 0.1792 (0.2263) acc 78.1250 (71.5938) kd_loss 0.2830 (0.5434) lr 5.1825e-04 eta 0:10:11
epoch [35/50] batch [120/244] time 0.169 (0.161) data 0.000 (0.003) loss 1.2989 (1.3522) ce_loss 0.9941 (1.0616) teacher_loss 1.0201 (1.0405) loss_zs_kd 0.1066 (0.1700) loss_oracle 0.2255 (0.2267) acc 81.2500 (71.9271) kd_loss 0.6299 (0.5446) lr 5.1825e-04 eta 0:10:07
epoch [35/50] batch [140/244] time 0.096 (0.160) data 0.000 (0.002) loss 1.2142 (1.3411) ce_loss 0.9473 (1.0499) teacher_loss 0.9217 (1.0291) loss_zs_kd 0.1604 (0.1687) loss_oracle 0.2122 (0.2277) acc 81.2500 (72.2321) kd_loss 0.6321 (0.5438) lr 5.1825e-04 eta 0:10:02
epoch [35/50] batch [160/244] time 0.085 (0.154) data 0.000 (0.002) loss 1.6554 (1.3406) ce_loss 1.3564 (1.0500) teacher_loss 1.3371 (1.0272) loss_zs_kd 0.2045 (0.1701) loss_oracle 0.2160 (0.2284) acc 53.1250 (72.2266) kd_loss 0.6143 (0.5468) lr 5.1825e-04 eta 0:09:36
epoch [35/50] batch [180/244] time 0.124 (0.154) data 0.000 (0.002) loss 1.7114 (1.3558) ce_loss 1.4307 (1.0648) teacher_loss 1.4368 (1.0433) loss_zs_kd 0.1531 (0.1684) loss_oracle 0.1980 (0.2283) acc 56.2500 (71.7708) kd_loss 0.4010 (0.5423) lr 5.1825e-04 eta 0:09:34
epoch [35/50] batch [200/244] time 0.103 (0.154) data 0.000 (0.002) loss 0.8885 (1.3652) ce_loss 0.5571 (1.0729) teacher_loss 0.5622 (1.0521) loss_zs_kd 0.1525 (0.1675) loss_oracle 0.2500 (0.2294) acc 90.6250 (71.4531) kd_loss 0.6386 (0.5441) lr 5.1825e-04 eta 0:09:29
epoch [35/50] batch [220/244] time 0.159 (0.154) data 0.000 (0.002) loss 1.4580 (1.3678) ce_loss 1.1729 (1.0755) teacher_loss 1.0962 (1.0536) loss_zs_kd 0.1738 (0.1678) loss_oracle 0.2749 (0.2303) acc 62.5000 (71.4062) kd_loss 0.5586 (0.5436) lr 5.1825e-04 eta 0:09:28
epoch [35/50] batch [240/244] time 0.103 (0.156) data 0.000 (0.002) loss 1.2391 (1.3771) ce_loss 0.9653 (1.0840) teacher_loss 0.9353 (1.0625) loss_zs_kd 0.1039 (0.1664) loss_oracle 0.2519 (0.2314) acc 78.1250 (71.2370) kd_loss 0.6497 (0.5467) lr 5.1825e-04 eta 0:09:31
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,813
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [36/50] batch [20/244] time 0.157 (0.184) data 0.000 (0.013) loss 1.7686 (1.5426) ce_loss 1.4658 (1.2503) teacher_loss 1.4531 (1.2309) loss_zs_kd 0.1465 (0.1636) loss_oracle 0.2422 (0.2299) acc 62.5000 (66.4062) kd_loss 0.7132 (0.5504) lr 4.6417e-04 eta 0:11:10
epoch [36/50] batch [40/244] time 0.154 (0.171) data 0.000 (0.007) loss 1.6148 (1.4586) ce_loss 1.3154 (1.1642) teacher_loss 1.3166 (1.1456) loss_zs_kd 0.1674 (0.1655) loss_oracle 0.2146 (0.2302) acc 56.2500 (68.5938) kd_loss 0.4903 (0.5505) lr 4.6417e-04 eta 0:10:17
epoch [36/50] batch [60/244] time 0.149 (0.164) data 0.000 (0.005) loss 0.9858 (1.4288) ce_loss 0.6934 (1.1329) teacher_loss 0.6539 (1.1146) loss_zs_kd 0.1144 (0.1590) loss_oracle 0.2747 (0.2346) acc 87.5000 (69.7396) kd_loss 0.7585 (0.5578) lr 4.6417e-04 eta 0:09:50
epoch [36/50] batch [80/244] time 0.152 (0.161) data 0.000 (0.004) loss 1.2997 (1.3986) ce_loss 0.9570 (1.1049) teacher_loss 0.9017 (1.0835) loss_zs_kd 0.2055 (0.1565) loss_oracle 0.2952 (0.2368) acc 78.1250 (70.3906) kd_loss 0.6296 (0.5558) lr 4.6417e-04 eta 0:09:36
epoch [36/50] batch [100/244] time 0.157 (0.159) data 0.000 (0.003) loss 1.3047 (1.3826) ce_loss 1.0039 (1.0857) teacher_loss 0.9842 (1.0645) loss_zs_kd 0.2169 (0.1602) loss_oracle 0.2120 (0.2380) acc 75.0000 (70.9062) kd_loss 0.4342 (0.5552) lr 4.6417e-04 eta 0:09:25
epoch [36/50] batch [120/244] time 0.158 (0.158) data 0.000 (0.002) loss 1.2060 (1.3846) ce_loss 0.9692 (1.0871) teacher_loss 0.9499 (1.0652) loss_zs_kd 0.1244 (0.1632) loss_oracle 0.1938 (0.2378) acc 78.1250 (71.2760) kd_loss 0.3371 (0.5534) lr 4.6417e-04 eta 0:09:18
epoch [36/50] batch [140/244] time 0.150 (0.157) data 0.000 (0.002) loss 1.2007 (1.3786) ce_loss 0.9028 (1.0793) teacher_loss 0.8546 (1.0592) loss_zs_kd 0.1831 (0.1638) loss_oracle 0.2545 (0.2375) acc 78.1250 (71.4286) kd_loss 0.6033 (0.5546) lr 4.6417e-04 eta 0:09:12
epoch [36/50] batch [160/244] time 0.151 (0.157) data 0.000 (0.002) loss 1.3133 (1.3843) ce_loss 0.9424 (1.0857) teacher_loss 0.9453 (1.0657) loss_zs_kd 0.2316 (0.1639) loss_oracle 0.2522 (0.2367) acc 78.1250 (71.5039) kd_loss 0.5993 (0.5566) lr 4.6417e-04 eta 0:09:08
epoch [36/50] batch [180/244] time 0.150 (0.156) data 0.000 (0.002) loss 1.1894 (1.3808) ce_loss 0.8794 (1.0823) teacher_loss 0.8623 (1.0607) loss_zs_kd 0.1514 (0.1628) loss_oracle 0.2514 (0.2387) acc 78.1250 (71.5104) kd_loss 0.6294 (0.5601) lr 4.6417e-04 eta 0:09:04
epoch [36/50] batch [200/244] time 0.143 (0.156) data 0.000 (0.002) loss 1.5252 (1.3815) ce_loss 1.1982 (1.0815) teacher_loss 1.1584 (1.0603) loss_zs_kd 0.1848 (0.1627) loss_oracle 0.2744 (0.2398) acc 65.6250 (71.5312) kd_loss 0.5371 (0.5650) lr 4.6417e-04 eta 0:08:58
epoch [36/50] batch [220/244] time 0.148 (0.156) data 0.000 (0.001) loss 1.5409 (1.3771) ce_loss 1.2090 (1.0775) teacher_loss 1.1617 (1.0569) loss_zs_kd 0.2519 (0.1625) loss_oracle 0.2532 (0.2390) acc 62.5000 (71.7188) kd_loss 0.6698 (0.5652) lr 4.6417e-04 eta 0:08:55
epoch [36/50] batch [240/244] time 0.153 (0.155) data 0.000 (0.001) loss 1.4061 (1.3688) ce_loss 1.1465 (1.0702) teacher_loss 1.1163 (1.0498) loss_zs_kd 0.1049 (0.1619) loss_oracle 0.2374 (0.2380) acc 59.3750 (71.8490) kd_loss 0.5638 (0.5635) lr 4.6417e-04 eta 0:08:51
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,813
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.6%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [37/50] batch [20/244] time 0.102 (0.185) data 0.000 (0.017) loss 0.7212 (1.3787) ce_loss 0.4697 (1.0768) teacher_loss 0.4793 (1.0632) loss_zs_kd 0.0942 (0.1565) loss_oracle 0.1948 (0.2372) acc 93.7500 (72.1875) kd_loss 0.4355 (0.5449) lr 4.1221e-04 eta 0:10:26
epoch [37/50] batch [40/244] time 0.115 (0.156) data 0.000 (0.009) loss 1.3020 (1.3683) ce_loss 1.0527 (1.0754) teacher_loss 1.0287 (1.0537) loss_zs_kd 0.1353 (0.1526) loss_oracle 0.2056 (0.2383) acc 75.0000 (72.0312) kd_loss 0.5611 (0.5679) lr 4.1221e-04 eta 0:08:45
epoch [37/50] batch [60/244] time 0.096 (0.166) data 0.001 (0.006) loss 1.3361 (1.3779) ce_loss 1.1006 (1.0895) teacher_loss 0.9795 (1.0635) loss_zs_kd 0.1650 (0.1569) loss_oracle 0.2741 (0.2360) acc 71.8750 (71.2500) kd_loss 0.5409 (0.5599) lr 4.1221e-04 eta 0:09:17
epoch [37/50] batch [80/244] time 0.092 (0.166) data 0.000 (0.005) loss 1.4214 (1.3862) ce_loss 1.1367 (1.1015) teacher_loss 1.1473 (1.0755) loss_zs_kd 0.1751 (0.1549) loss_oracle 0.1865 (0.2333) acc 68.7500 (70.8594) kd_loss 0.5660 (0.5547) lr 4.1221e-04 eta 0:09:13
epoch [37/50] batch [100/244] time 0.105 (0.167) data 0.000 (0.004) loss 1.1452 (1.3952) ce_loss 0.9062 (1.1079) teacher_loss 0.8149 (1.0812) loss_zs_kd 0.1865 (0.1602) loss_oracle 0.2370 (0.2339) acc 75.0000 (70.1250) kd_loss 0.4890 (0.5535) lr 4.1221e-04 eta 0:09:12
epoch [37/50] batch [120/244] time 0.109 (0.162) data 0.000 (0.003) loss 1.2079 (1.3933) ce_loss 0.8896 (1.1015) teacher_loss 0.8834 (1.0736) loss_zs_kd 0.1738 (0.1662) loss_oracle 0.2375 (0.2366) acc 75.0000 (70.5990) kd_loss 0.5475 (0.5514) lr 4.1221e-04 eta 0:08:55
epoch [37/50] batch [140/244] time 0.151 (0.161) data 0.000 (0.003) loss 1.6341 (1.3991) ce_loss 1.3115 (1.1053) teacher_loss 1.3107 (1.0788) loss_zs_kd 0.1878 (0.1677) loss_oracle 0.2295 (0.2365) acc 68.7500 (70.6473) kd_loss 0.5114 (0.5554) lr 4.1221e-04 eta 0:08:47
epoch [37/50] batch [160/244] time 0.152 (0.160) data 0.000 (0.002) loss 1.6473 (1.3936) ce_loss 1.3174 (1.0999) teacher_loss 1.3830 (1.0741) loss_zs_kd 0.1404 (0.1677) loss_oracle 0.1942 (0.2356) acc 65.6250 (70.9766) kd_loss 0.5838 (0.5545) lr 4.1221e-04 eta 0:08:39
epoch [37/50] batch [180/244] time 0.152 (0.159) data 0.000 (0.002) loss 1.8524 (1.3885) ce_loss 1.5312 (1.0939) teacher_loss 1.4915 (1.0686) loss_zs_kd 0.1743 (0.1669) loss_oracle 0.2737 (0.2364) acc 62.5000 (71.3021) kd_loss 0.7985 (0.5606) lr 4.1221e-04 eta 0:08:34
epoch [37/50] batch [200/244] time 0.154 (0.160) data 0.000 (0.002) loss 1.2862 (1.3851) ce_loss 0.9521 (1.0901) teacher_loss 0.9548 (1.0665) loss_zs_kd 0.1924 (0.1659) loss_oracle 0.2352 (0.2356) acc 75.0000 (71.3281) kd_loss 0.5595 (0.5582) lr 4.1221e-04 eta 0:08:33
epoch [37/50] batch [220/244] time 0.155 (0.160) data 0.000 (0.002) loss 1.4513 (1.3832) ce_loss 1.1426 (1.0889) teacher_loss 1.1722 (1.0657) loss_zs_kd 0.1533 (0.1660) loss_oracle 0.2024 (0.2346) acc 68.7500 (71.3494) kd_loss 0.4352 (0.5567) lr 4.1221e-04 eta 0:08:29
epoch [37/50] batch [240/244] time 0.150 (0.159) data 0.000 (0.002) loss 1.5676 (1.3838) ce_loss 1.2939 (1.0887) teacher_loss 1.2725 (1.0666) loss_zs_kd 0.1296 (0.1661) loss_oracle 0.2303 (0.2341) acc 68.7500 (71.3802) kd_loss 0.5499 (0.5584) lr 4.1221e-04 eta 0:08:24
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,824
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [38/50] batch [20/244] time 0.171 (0.174) data 0.000 (0.014) loss 1.7345 (1.4208) ce_loss 1.3525 (1.1290) teacher_loss 1.4049 (1.1036) loss_zs_kd 0.1219 (0.1618) loss_oracle 0.2686 (0.2363) acc 71.8750 (70.1562) kd_loss 0.6786 (0.5511) lr 3.6258e-04 eta 0:09:09
epoch [38/50] batch [40/244] time 0.176 (0.168) data 0.000 (0.007) loss 1.3640 (1.3426) ce_loss 1.1572 (1.0556) teacher_loss 1.0990 (1.0336) loss_zs_kd 0.1574 (0.1582) loss_oracle 0.1863 (0.2298) acc 75.0000 (72.5000) kd_loss 0.4805 (0.5325) lr 3.6258e-04 eta 0:08:46
epoch [38/50] batch [60/244] time 0.153 (0.163) data 0.001 (0.005) loss 1.6353 (1.3202) ce_loss 1.3721 (1.0343) teacher_loss 1.3576 (1.0090) loss_zs_kd 0.1194 (0.1579) loss_oracle 0.2180 (0.2322) acc 59.3750 (73.1771) kd_loss 0.4505 (0.5351) lr 3.6258e-04 eta 0:08:28
epoch [38/50] batch [80/244] time 0.153 (0.160) data 0.000 (0.004) loss 1.8058 (1.3521) ce_loss 1.4775 (1.0581) teacher_loss 1.4855 (1.0355) loss_zs_kd 0.1776 (0.1621) loss_oracle 0.2314 (0.2355) acc 59.3750 (72.3828) kd_loss 0.6328 (0.5486) lr 3.6258e-04 eta 0:08:15
epoch [38/50] batch [100/244] time 0.100 (0.158) data 0.000 (0.003) loss 2.0055 (1.3573) ce_loss 1.7354 (1.0605) teacher_loss 1.7214 (1.0399) loss_zs_kd 0.1796 (0.1642) loss_oracle 0.1943 (0.2353) acc 43.7500 (72.0938) kd_loss 0.4830 (0.5484) lr 3.6258e-04 eta 0:08:04
epoch [38/50] batch [120/244] time 0.192 (0.152) data 0.000 (0.003) loss 1.1112 (1.3587) ce_loss 0.8174 (1.0643) teacher_loss 0.8062 (1.0440) loss_zs_kd 0.1697 (0.1626) loss_oracle 0.2202 (0.2334) acc 81.2500 (72.0312) kd_loss 0.4892 (0.5449) lr 3.6258e-04 eta 0:07:44
epoch [38/50] batch [140/244] time 0.227 (0.151) data 0.000 (0.002) loss 1.4972 (1.3641) ce_loss 1.1777 (1.0684) teacher_loss 1.1648 (1.0489) loss_zs_kd 0.1658 (0.1628) loss_oracle 0.2495 (0.2339) acc 68.7500 (71.9420) kd_loss 0.7362 (0.5506) lr 3.6258e-04 eta 0:07:38
epoch [38/50] batch [160/244] time 0.104 (0.151) data 0.000 (0.002) loss 1.3520 (1.3636) ce_loss 1.0605 (1.0673) teacher_loss 1.0267 (1.0481) loss_zs_kd 0.1412 (0.1635) loss_oracle 0.2546 (0.2338) acc 75.0000 (71.9336) kd_loss 0.5283 (0.5521) lr 3.6258e-04 eta 0:07:34
epoch [38/50] batch [180/244] time 0.362 (0.147) data 0.000 (0.002) loss 1.4694 (1.3679) ce_loss 1.1934 (1.0736) teacher_loss 1.1443 (1.0542) loss_zs_kd 0.1867 (0.1628) loss_oracle 0.2318 (0.2323) acc 71.8750 (71.8056) kd_loss 0.5574 (0.5505) lr 3.6258e-04 eta 0:07:20
epoch [38/50] batch [200/244] time 0.393 (0.149) data 0.000 (0.002) loss 1.2581 (1.3730) ce_loss 0.9692 (1.0773) teacher_loss 0.9826 (1.0585) loss_zs_kd 0.1166 (0.1638) loss_oracle 0.2172 (0.2326) acc 78.1250 (71.8281) kd_loss 0.5718 (0.5532) lr 3.6258e-04 eta 0:07:23
epoch [38/50] batch [220/244] time 0.158 (0.151) data 0.000 (0.002) loss 1.0660 (1.3779) ce_loss 0.8135 (1.0821) teacher_loss 0.8175 (1.0636) loss_zs_kd 0.1484 (0.1640) loss_oracle 0.1743 (0.2322) acc 81.2500 (71.7472) kd_loss 0.4847 (0.5491) lr 3.6258e-04 eta 0:07:26
epoch [38/50] batch [240/244] time 0.099 (0.151) data 0.000 (0.001) loss 1.5804 (1.3730) ce_loss 1.2373 (1.0781) teacher_loss 1.2328 (1.0597) loss_zs_kd 0.2031 (0.1643) loss_oracle 0.2461 (0.2312) acc 65.6250 (71.8490) kd_loss 0.6786 (0.5492) lr 3.6258e-04 eta 0:07:21
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,817
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [39/50] batch [20/244] time 0.152 (0.171) data 0.000 (0.017) loss 1.8679 (1.4140) ce_loss 1.5449 (1.1059) teacher_loss 1.4959 (1.0964) loss_zs_kd 0.1651 (0.1534) loss_oracle 0.2894 (0.2409) acc 62.5000 (72.9688) kd_loss 0.6449 (0.5935) lr 3.1545e-04 eta 0:08:17
epoch [39/50] batch [40/244] time 0.149 (0.162) data 0.000 (0.008) loss 1.4989 (1.3794) ce_loss 1.2588 (1.0845) teacher_loss 1.2106 (1.0715) loss_zs_kd 0.1482 (0.1599) loss_oracle 0.2142 (0.2280) acc 65.6250 (72.0312) kd_loss 0.3732 (0.5474) lr 3.1545e-04 eta 0:07:46
epoch [39/50] batch [60/244] time 0.155 (0.159) data 0.000 (0.006) loss 1.0455 (1.3582) ce_loss 0.7905 (1.0671) teacher_loss 0.7475 (1.0493) loss_zs_kd 0.1529 (0.1630) loss_oracle 0.2216 (0.2274) acc 84.3750 (72.2396) kd_loss 0.5102 (0.5416) lr 3.1545e-04 eta 0:07:34
epoch [39/50] batch [80/244] time 0.150 (0.157) data 0.000 (0.004) loss 1.4159 (1.3653) ce_loss 1.0693 (1.0791) teacher_loss 1.0873 (1.0580) loss_zs_kd 0.1403 (0.1607) loss_oracle 0.2584 (0.2269) acc 71.8750 (71.9531) kd_loss 0.7316 (0.5475) lr 3.1545e-04 eta 0:07:27
epoch [39/50] batch [100/244] time 0.151 (0.156) data 0.000 (0.003) loss 1.3940 (1.3525) ce_loss 1.1445 (1.0662) teacher_loss 1.0697 (1.0445) loss_zs_kd 0.1655 (0.1621) loss_oracle 0.2415 (0.2270) acc 65.6250 (71.7188) kd_loss 0.4000 (0.5436) lr 3.1545e-04 eta 0:07:22
epoch [39/50] batch [120/244] time 0.145 (0.157) data 0.000 (0.003) loss 1.1906 (1.3583) ce_loss 0.8486 (1.0683) teacher_loss 0.8444 (1.0468) loss_zs_kd 0.1954 (0.1650) loss_oracle 0.2486 (0.2290) acc 78.1250 (71.7448) kd_loss 0.6299 (0.5449) lr 3.1545e-04 eta 0:07:19
epoch [39/50] batch [140/244] time 0.159 (0.157) data 0.000 (0.003) loss 1.4767 (1.3586) ce_loss 1.2549 (1.0682) teacher_loss 1.2283 (1.0454) loss_zs_kd 0.1487 (0.1680) loss_oracle 0.1740 (0.2292) acc 68.7500 (71.7188) kd_loss 0.4977 (0.5455) lr 3.1545e-04 eta 0:07:17
epoch [39/50] batch [160/244] time 0.153 (0.157) data 0.000 (0.002) loss 1.4562 (1.3697) ce_loss 1.1553 (1.0790) teacher_loss 1.1171 (1.0566) loss_zs_kd 0.1999 (0.1681) loss_oracle 0.2391 (0.2290) acc 68.7500 (71.6602) kd_loss 0.6757 (0.5502) lr 3.1545e-04 eta 0:07:15
epoch [39/50] batch [180/244] time 0.151 (0.157) data 0.000 (0.002) loss 1.0937 (1.3719) ce_loss 0.7505 (1.0819) teacher_loss 0.7582 (1.0593) loss_zs_kd 0.1513 (0.1687) loss_oracle 0.2599 (0.2282) acc 75.0000 (71.4757) kd_loss 0.5823 (0.5485) lr 3.1545e-04 eta 0:07:11
epoch [39/50] batch [200/244] time 0.151 (0.157) data 0.000 (0.002) loss 1.3959 (1.3749) ce_loss 1.1787 (1.0848) teacher_loss 1.0967 (1.0624) loss_zs_kd 0.1378 (0.1686) loss_oracle 0.2303 (0.2283) acc 71.8750 (71.4844) kd_loss 0.5100 (0.5472) lr 3.1545e-04 eta 0:07:07
epoch [39/50] batch [220/244] time 0.169 (0.157) data 0.000 (0.002) loss 2.0945 (1.3798) ce_loss 1.8271 (1.0900) teacher_loss 1.8291 (1.0682) loss_zs_kd 0.1199 (0.1676) loss_oracle 0.2055 (0.2279) acc 50.0000 (71.2642) kd_loss 0.5893 (0.5461) lr 3.1545e-04 eta 0:07:05
epoch [39/50] batch [240/244] time 0.157 (0.157) data 0.000 (0.002) loss 1.1712 (1.3815) ce_loss 0.9502 (1.0901) teacher_loss 0.9035 (1.0690) loss_zs_kd 0.1563 (0.1675) loss_oracle 0.1896 (0.2288) acc 68.7500 (71.1589) kd_loss 0.3918 (0.5473) lr 3.1545e-04 eta 0:07:02
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,819
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,039
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [40/50] batch [20/244] time 0.095 (0.188) data 0.000 (0.020) loss 1.2658 (1.3879) ce_loss 0.9790 (1.1161) teacher_loss 0.9100 (1.0874) loss_zs_kd 0.1952 (0.1645) loss_oracle 0.2582 (0.2183) acc 71.8750 (70.0000) kd_loss 0.6909 (0.5322) lr 2.7103e-04 eta 0:08:19
epoch [40/50] batch [40/244] time 0.086 (0.178) data 0.000 (0.010) loss 1.3919 (1.3905) ce_loss 1.0449 (1.1029) teacher_loss 1.0273 (1.0834) loss_zs_kd 0.1837 (0.1660) loss_oracle 0.2727 (0.2242) acc 78.1250 (71.4062) kd_loss 0.5589 (0.5519) lr 2.7103e-04 eta 0:07:49
epoch [40/50] batch [60/244] time 0.098 (0.174) data 0.001 (0.007) loss 1.2861 (1.3819) ce_loss 1.0254 (1.0931) teacher_loss 0.9886 (1.0750) loss_zs_kd 0.1010 (0.1689) loss_oracle 0.2470 (0.2224) acc 71.8750 (72.0312) kd_loss 0.5965 (0.5445) lr 2.7103e-04 eta 0:07:37
epoch [40/50] batch [80/244] time 0.098 (0.168) data 0.000 (0.005) loss 1.2016 (1.4054) ce_loss 0.9639 (1.1089) teacher_loss 0.8864 (1.0922) loss_zs_kd 0.1318 (0.1744) loss_oracle 0.2493 (0.2260) acc 71.8750 (71.3672) kd_loss 0.5108 (0.5484) lr 2.7103e-04 eta 0:07:16
epoch [40/50] batch [100/244] time 0.159 (0.165) data 0.000 (0.004) loss 1.0690 (1.3807) ce_loss 0.7554 (1.0857) teacher_loss 0.7240 (1.0659) loss_zs_kd 0.1521 (0.1725) loss_oracle 0.2690 (0.2285) acc 75.0000 (71.8750) kd_loss 0.6884 (0.5511) lr 2.7103e-04 eta 0:07:07
epoch [40/50] batch [120/244] time 0.152 (0.164) data 0.000 (0.004) loss 1.2747 (1.3763) ce_loss 0.9922 (1.0835) teacher_loss 1.0170 (1.0637) loss_zs_kd 0.0962 (0.1697) loss_oracle 0.2096 (0.2277) acc 78.1250 (71.9531) kd_loss 0.4463 (0.5470) lr 2.7103e-04 eta 0:07:00
epoch [40/50] batch [140/244] time 0.152 (0.162) data 0.000 (0.003) loss 0.9542 (1.3684) ce_loss 0.6650 (1.0756) teacher_loss 0.6700 (1.0552) loss_zs_kd 0.1147 (0.1718) loss_oracle 0.2270 (0.2272) acc 81.2500 (72.0312) kd_loss 0.5336 (0.5443) lr 2.7103e-04 eta 0:06:53
epoch [40/50] batch [160/244] time 0.176 (0.162) data 0.000 (0.003) loss 1.5365 (1.3559) ce_loss 1.1699 (1.0619) teacher_loss 1.1777 (1.0412) loss_zs_kd 0.1984 (0.1717) loss_oracle 0.2596 (0.2289) acc 81.2500 (72.4219) kd_loss 0.6113 (0.5478) lr 2.7103e-04 eta 0:06:47
epoch [40/50] batch [180/244] time 0.172 (0.163) data 0.000 (0.002) loss 1.1939 (1.3654) ce_loss 0.8530 (1.0696) teacher_loss 0.8394 (1.0483) loss_zs_kd 0.2025 (0.1734) loss_oracle 0.2533 (0.2304) acc 75.0000 (72.2396) kd_loss 0.5500 (0.5491) lr 2.7103e-04 eta 0:06:47
epoch [40/50] batch [200/244] time 0.149 (0.161) data 0.000 (0.002) loss 0.8654 (1.3630) ce_loss 0.5508 (1.0694) teacher_loss 0.5629 (1.0469) loss_zs_kd 0.1952 (0.1716) loss_oracle 0.2049 (0.2302) acc 90.6250 (72.2344) kd_loss 0.5534 (0.5489) lr 2.7103e-04 eta 0:06:40
epoch [40/50] batch [220/244] time 0.158 (0.161) data 0.000 (0.002) loss 1.0180 (1.3527) ce_loss 0.7798 (1.0586) teacher_loss 0.7316 (1.0360) loss_zs_kd 0.1242 (0.1711) loss_oracle 0.2243 (0.2312) acc 75.0000 (72.5284) kd_loss 0.6276 (0.5494) lr 2.7103e-04 eta 0:06:37
epoch [40/50] batch [240/244] time 0.170 (0.161) data 0.000 (0.002) loss 1.1449 (1.3502) ce_loss 0.8818 (1.0557) teacher_loss 0.8871 (1.0334) loss_zs_kd 0.1618 (0.1707) loss_oracle 0.1770 (0.2314) acc 84.3750 (72.6302) kd_loss 0.4276 (0.5477) lr 2.7103e-04 eta 0:06:34
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,819
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,034
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [41/50] batch [20/244] time 0.149 (0.172) data 0.000 (0.014) loss 1.1420 (1.3431) ce_loss 0.8447 (1.0359) teacher_loss 0.8186 (1.0270) loss_zs_kd 0.1387 (0.1723) loss_oracle 0.2541 (0.2299) acc 75.0000 (72.8125) kd_loss 0.6160 (0.5504) lr 2.2949e-04 eta 0:06:56
epoch [41/50] batch [40/244] time 0.152 (0.164) data 0.000 (0.007) loss 1.1766 (1.3239) ce_loss 0.9141 (1.0257) teacher_loss 0.8969 (1.0119) loss_zs_kd 0.1491 (0.1694) loss_oracle 0.2052 (0.2274) acc 81.2500 (73.6719) kd_loss 0.4852 (0.5310) lr 2.2949e-04 eta 0:06:33
epoch [41/50] batch [60/244] time 0.368 (0.147) data 0.000 (0.005) loss 1.0550 (1.3297) ce_loss 0.7778 (1.0359) teacher_loss 0.7439 (1.0162) loss_zs_kd 0.1129 (0.1664) loss_oracle 0.2547 (0.2303) acc 75.0000 (72.6562) kd_loss 0.4648 (0.5386) lr 2.2949e-04 eta 0:05:50
epoch [41/50] batch [80/244] time 0.094 (0.150) data 0.000 (0.004) loss 1.2520 (1.3338) ce_loss 0.9541 (1.0360) teacher_loss 0.9287 (1.0199) loss_zs_kd 0.2137 (0.1705) loss_oracle 0.2164 (0.2287) acc 62.5000 (72.2266) kd_loss 0.5399 (0.5393) lr 2.2949e-04 eta 0:05:54
epoch [41/50] batch [100/244] time 0.095 (0.151) data 0.000 (0.003) loss 1.0957 (1.3485) ce_loss 0.7632 (1.0478) teacher_loss 0.7940 (1.0313) loss_zs_kd 0.1658 (0.1738) loss_oracle 0.2188 (0.2303) acc 78.1250 (71.8750) kd_loss 0.6943 (0.5447) lr 2.2949e-04 eta 0:05:52
epoch [41/50] batch [120/244] time 0.123 (0.146) data 0.000 (0.003) loss 0.8126 (1.3456) ce_loss 0.4922 (1.0440) teacher_loss 0.5037 (1.0282) loss_zs_kd 0.1516 (0.1732) loss_oracle 0.2331 (0.2308) acc 90.6250 (72.0573) kd_loss 0.6393 (0.5482) lr 2.2949e-04 eta 0:05:38
epoch [41/50] batch [140/244] time 0.352 (0.153) data 0.000 (0.002) loss 1.5782 (1.3358) ce_loss 1.2471 (1.0332) teacher_loss 1.1919 (1.0173) loss_zs_kd 0.1921 (0.1712) loss_oracle 0.2902 (0.2329) acc 65.6250 (72.6116) kd_loss 0.6922 (0.5553) lr 2.2949e-04 eta 0:05:52
epoch [41/50] batch [160/244] time 0.094 (0.154) data 0.000 (0.002) loss 0.7868 (1.3286) ce_loss 0.4858 (1.0280) teacher_loss 0.5025 (1.0120) loss_zs_kd 0.1799 (0.1702) loss_oracle 0.1943 (0.2315) acc 90.6250 (72.7930) kd_loss 0.5433 (0.5540) lr 2.2949e-04 eta 0:05:50
epoch [41/50] batch [180/244] time 0.101 (0.156) data 0.000 (0.002) loss 1.2525 (1.3330) ce_loss 0.8940 (1.0315) teacher_loss 0.9190 (1.0153) loss_zs_kd 0.1909 (0.1716) loss_oracle 0.2381 (0.2318) acc 71.8750 (72.6910) kd_loss 0.5354 (0.5554) lr 2.2949e-04 eta 0:05:51
epoch [41/50] batch [200/244] time 0.152 (0.155) data 0.000 (0.002) loss 1.2405 (1.3305) ce_loss 1.0000 (1.0302) teacher_loss 0.9353 (1.0136) loss_zs_kd 0.1273 (0.1708) loss_oracle 0.2416 (0.2315) acc 75.0000 (72.7344) kd_loss 0.6082 (0.5544) lr 2.2949e-04 eta 0:05:47
epoch [41/50] batch [220/244] time 0.158 (0.155) data 0.000 (0.002) loss 1.5608 (1.3288) ce_loss 1.2686 (1.0287) teacher_loss 1.2824 (1.0117) loss_zs_kd 0.1925 (0.1699) loss_oracle 0.1821 (0.2321) acc 65.6250 (72.8977) kd_loss 0.5178 (0.5544) lr 2.2949e-04 eta 0:05:43
epoch [41/50] batch [240/244] time 0.148 (0.155) data 0.000 (0.001) loss 1.4003 (1.3300) ce_loss 1.1104 (1.0300) teacher_loss 1.0647 (1.0122) loss_zs_kd 0.1951 (0.1703) loss_oracle 0.2382 (0.2327) acc 65.6250 (72.8385) kd_loss 0.6306 (0.5541) lr 2.2949e-04 eta 0:05:39
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,044
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.7%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [42/50] batch [20/244] time 0.149 (0.180) data 0.000 (0.015) loss 1.1891 (1.3383) ce_loss 0.9224 (1.0578) teacher_loss 0.9126 (1.0375) loss_zs_kd 0.1599 (0.1514) loss_oracle 0.1966 (0.2250) acc 78.1250 (71.4062) kd_loss 0.4229 (0.5614) lr 1.9098e-04 eta 0:06:31
epoch [42/50] batch [40/244] time 0.148 (0.169) data 0.000 (0.007) loss 1.3905 (1.3532) ce_loss 1.1123 (1.0672) teacher_loss 1.1132 (1.0479) loss_zs_kd 0.1527 (0.1603) loss_oracle 0.2010 (0.2252) acc 71.8750 (71.4062) kd_loss 0.4939 (0.5459) lr 1.9098e-04 eta 0:06:04
epoch [42/50] batch [60/244] time 0.152 (0.163) data 0.001 (0.005) loss 1.1164 (1.3532) ce_loss 0.8076 (1.0605) teacher_loss 0.7417 (1.0421) loss_zs_kd 0.2128 (0.1658) loss_oracle 0.2682 (0.2282) acc 81.2500 (71.4583) kd_loss 0.6093 (0.5507) lr 1.9098e-04 eta 0:05:48
epoch [42/50] batch [80/244] time 0.148 (0.161) data 0.000 (0.004) loss 1.4183 (1.3564) ce_loss 1.1445 (1.0660) teacher_loss 1.1165 (1.0443) loss_zs_kd 0.1558 (0.1664) loss_oracle 0.2239 (0.2289) acc 81.2500 (71.6016) kd_loss 0.4631 (0.5499) lr 1.9098e-04 eta 0:05:40
epoch [42/50] batch [100/244] time 0.163 (0.160) data 0.000 (0.003) loss 1.8160 (1.3494) ce_loss 1.5830 (1.0633) teacher_loss 1.5568 (1.0396) loss_zs_kd 0.1615 (0.1630) loss_oracle 0.1784 (0.2283) acc 59.3750 (71.8125) kd_loss 0.4136 (0.5477) lr 1.9098e-04 eta 0:05:35
epoch [42/50] batch [120/244] time 0.174 (0.161) data 0.000 (0.003) loss 1.4506 (1.3583) ce_loss 1.1748 (1.0724) teacher_loss 1.0901 (1.0461) loss_zs_kd 0.1661 (0.1658) loss_oracle 0.2774 (0.2293) acc 65.6250 (71.6406) kd_loss 0.6774 (0.5472) lr 1.9098e-04 eta 0:05:35
epoch [42/50] batch [140/244] time 0.159 (0.163) data 0.000 (0.002) loss 0.7888 (1.3506) ce_loss 0.5063 (1.0651) teacher_loss 0.4659 (1.0374) loss_zs_kd 0.1272 (0.1642) loss_oracle 0.2594 (0.2310) acc 87.5000 (71.9643) kd_loss 0.5880 (0.5488) lr 1.9098e-04 eta 0:05:34
epoch [42/50] batch [160/244] time 0.106 (0.162) data 0.000 (0.002) loss 1.2517 (1.3517) ce_loss 0.9443 (1.0638) teacher_loss 0.9233 (1.0373) loss_zs_kd 0.1889 (0.1669) loss_oracle 0.2340 (0.2310) acc 78.1250 (72.1484) kd_loss 0.4304 (0.5431) lr 1.9098e-04 eta 0:05:30
epoch [42/50] batch [180/244] time 0.091 (0.161) data 0.000 (0.002) loss 1.5044 (1.3477) ce_loss 1.1807 (1.0571) teacher_loss 1.1777 (1.0326) loss_zs_kd 0.1698 (0.1679) loss_oracle 0.2418 (0.2311) acc 71.8750 (72.3264) kd_loss 0.6528 (0.5440) lr 1.9098e-04 eta 0:05:24
epoch [42/50] batch [200/244] time 0.094 (0.161) data 0.000 (0.002) loss 1.1117 (1.3413) ce_loss 0.8613 (1.0507) teacher_loss 0.7779 (1.0266) loss_zs_kd 0.1318 (0.1666) loss_oracle 0.2679 (0.2314) acc 78.1250 (72.5312) kd_loss 0.6691 (0.5452) lr 1.9098e-04 eta 0:05:22
epoch [42/50] batch [220/244] time 0.103 (0.157) data 0.000 (0.002) loss 1.5200 (1.3432) ce_loss 1.1904 (1.0526) teacher_loss 1.2225 (1.0277) loss_zs_kd 0.1769 (0.1657) loss_oracle 0.2091 (0.2326) acc 71.8750 (72.4290) kd_loss 0.4101 (0.5475) lr 1.9098e-04 eta 0:05:10
epoch [42/50] batch [240/244] time 0.113 (0.156) data 0.000 (0.001) loss 1.0016 (1.3527) ce_loss 0.7510 (1.0605) teacher_loss 0.7347 (1.0366) loss_zs_kd 0.1972 (0.1666) loss_oracle 0.1683 (0.2329) acc 81.2500 (72.3307) kd_loss 0.3962 (0.5469) lr 1.9098e-04 eta 0:05:05
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,817
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,041
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.6%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [43/50] batch [20/244] time 0.149 (0.165) data 0.000 (0.014) loss 1.4008 (1.2826) ce_loss 0.9785 (0.9687) teacher_loss 1.0537 (0.9549) loss_zs_kd 0.1636 (0.1786) loss_oracle 0.2653 (0.2383) acc 71.8750 (73.7500) kd_loss 0.6312 (0.5634) lr 1.5567e-04 eta 0:05:19
epoch [43/50] batch [40/244] time 0.152 (0.159) data 0.000 (0.007) loss 1.0373 (1.3327) ce_loss 0.7051 (1.0259) teacher_loss 0.7048 (1.0015) loss_zs_kd 0.1503 (0.1786) loss_oracle 0.2573 (0.2419) acc 78.1250 (72.2656) kd_loss 0.6108 (0.5529) lr 1.5567e-04 eta 0:05:03
epoch [43/50] batch [60/244] time 0.157 (0.158) data 0.001 (0.005) loss 1.3315 (1.3368) ce_loss 1.0498 (1.0294) teacher_loss 1.0351 (1.0083) loss_zs_kd 0.1426 (0.1794) loss_oracle 0.2251 (0.2388) acc 65.6250 (72.7083) kd_loss 0.5077 (0.5410) lr 1.5567e-04 eta 0:04:59
epoch [43/50] batch [80/244] time 0.144 (0.158) data 0.000 (0.004) loss 1.0391 (1.3541) ce_loss 0.7427 (1.0440) teacher_loss 0.6574 (1.0215) loss_zs_kd 0.1602 (0.1788) loss_oracle 0.3016 (0.2432) acc 75.0000 (72.3047) kd_loss 0.7514 (0.5585) lr 1.5567e-04 eta 0:04:55
epoch [43/50] batch [100/244] time 0.154 (0.157) data 0.000 (0.003) loss 1.4616 (1.3521) ce_loss 1.0811 (1.0440) teacher_loss 1.0940 (1.0220) loss_zs_kd 0.1658 (0.1760) loss_oracle 0.2847 (0.2421) acc 71.8750 (72.3438) kd_loss 0.6101 (0.5538) lr 1.5567e-04 eta 0:04:49
epoch [43/50] batch [120/244] time 0.162 (0.157) data 0.000 (0.003) loss 1.6847 (1.3670) ce_loss 1.2344 (1.0582) teacher_loss 1.2497 (1.0375) loss_zs_kd 0.2783 (0.1734) loss_oracle 0.2958 (0.2428) acc 68.7500 (72.1094) kd_loss 0.7171 (0.5588) lr 1.5567e-04 eta 0:04:47
epoch [43/50] batch [140/244] time 0.173 (0.158) data 0.000 (0.002) loss 1.2729 (1.3615) ce_loss 1.0029 (1.0537) teacher_loss 0.9568 (1.0320) loss_zs_kd 0.1608 (0.1739) loss_oracle 0.2357 (0.2425) acc 71.8750 (72.2098) kd_loss 0.5300 (0.5591) lr 1.5567e-04 eta 0:04:46
epoch [43/50] batch [160/244] time 0.182 (0.159) data 0.000 (0.002) loss 1.0308 (1.3555) ce_loss 0.7495 (1.0495) teacher_loss 0.7996 (1.0279) loss_zs_kd 0.1065 (0.1708) loss_oracle 0.1780 (0.2423) acc 78.1250 (72.4609) kd_loss 0.5906 (0.5587) lr 1.5567e-04 eta 0:04:45
epoch [43/50] batch [180/244] time 0.162 (0.161) data 0.000 (0.002) loss 1.2540 (1.3554) ce_loss 0.9614 (1.0512) teacher_loss 0.8738 (1.0286) loss_zs_kd 0.1936 (0.1705) loss_oracle 0.2834 (0.2415) acc 65.6250 (72.4826) kd_loss 0.4467 (0.5576) lr 1.5567e-04 eta 0:04:44
epoch [43/50] batch [200/244] time 0.179 (0.162) data 0.000 (0.002) loss 1.6226 (1.3573) ce_loss 1.3281 (1.0536) teacher_loss 1.2791 (1.0308) loss_zs_kd 0.1501 (0.1694) loss_oracle 0.2685 (0.2418) acc 62.5000 (72.3125) kd_loss 0.5929 (0.5588) lr 1.5567e-04 eta 0:04:43
epoch [43/50] batch [220/244] time 0.150 (0.162) data 0.000 (0.001) loss 1.2076 (1.3633) ce_loss 0.8999 (1.0597) teacher_loss 0.8895 (1.0381) loss_zs_kd 0.1700 (0.1698) loss_oracle 0.2331 (0.2403) acc 81.2500 (72.1591) kd_loss 0.5450 (0.5585) lr 1.5567e-04 eta 0:04:40
epoch [43/50] batch [240/244] time 0.086 (0.159) data 0.000 (0.001) loss 1.8330 (1.3634) ce_loss 1.4717 (1.0602) teacher_loss 1.5023 (1.0382) loss_zs_kd 0.1812 (0.1690) loss_oracle 0.2401 (0.2407) acc 59.3750 (71.9922) kd_loss 0.6464 (0.5592) lr 1.5567e-04 eta 0:04:32
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,822
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,031
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.4%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [44/50] batch [20/244] time 0.396 (0.179) data 0.000 (0.014) loss 1.7542 (1.3829) ce_loss 1.3887 (1.0841) teacher_loss 1.3912 (1.0712) loss_zs_kd 0.2376 (0.1650) loss_oracle 0.2442 (0.2293) acc 59.3750 (70.4688) kd_loss 0.5705 (0.5588) lr 1.2369e-04 eta 0:05:02
epoch [44/50] batch [40/244] time 0.408 (0.177) data 0.000 (0.007) loss 1.4231 (1.3139) ce_loss 1.1348 (1.0133) teacher_loss 1.1367 (1.0053) loss_zs_kd 0.1865 (0.1651) loss_oracle 0.1931 (0.2261) acc 71.8750 (73.5938) kd_loss 0.5739 (0.5501) lr 1.2369e-04 eta 0:04:56
epoch [44/50] batch [60/244] time 0.396 (0.171) data 0.001 (0.005) loss 1.3009 (1.2987) ce_loss 0.9746 (0.9994) teacher_loss 0.9772 (0.9897) loss_zs_kd 0.1621 (0.1617) loss_oracle 0.2426 (0.2281) acc 81.2500 (74.0104) kd_loss 0.4699 (0.5546) lr 1.2369e-04 eta 0:04:42
epoch [44/50] batch [80/244] time 0.108 (0.161) data 0.000 (0.004) loss 1.6242 (1.3067) ce_loss 1.3369 (1.0114) teacher_loss 1.3263 (0.9949) loss_zs_kd 0.1499 (0.1619) loss_oracle 0.2230 (0.2308) acc 65.6250 (73.8281) kd_loss 0.6198 (0.5591) lr 1.2369e-04 eta 0:04:22
epoch [44/50] batch [100/244] time 0.150 (0.159) data 0.000 (0.003) loss 1.3795 (1.3123) ce_loss 1.0635 (1.0206) teacher_loss 1.0761 (1.0003) loss_zs_kd 0.1234 (0.1612) loss_oracle 0.2417 (0.2315) acc 81.2500 (73.5625) kd_loss 0.6917 (0.5570) lr 1.2369e-04 eta 0:04:15
epoch [44/50] batch [120/244] time 0.152 (0.158) data 0.000 (0.003) loss 1.4077 (1.3304) ce_loss 1.1426 (1.0388) teacher_loss 1.0977 (1.0155) loss_zs_kd 0.1513 (0.1631) loss_oracle 0.2343 (0.2333) acc 65.6250 (72.9427) kd_loss 0.5456 (0.5523) lr 1.2369e-04 eta 0:04:10
epoch [44/50] batch [140/244] time 0.167 (0.158) data 0.000 (0.002) loss 1.2610 (1.3390) ce_loss 0.9697 (1.0461) teacher_loss 0.9433 (1.0224) loss_zs_kd 0.1344 (0.1644) loss_oracle 0.2505 (0.2345) acc 75.0000 (72.7009) kd_loss 0.6046 (0.5566) lr 1.2369e-04 eta 0:04:08
epoch [44/50] batch [160/244] time 0.148 (0.159) data 0.000 (0.002) loss 1.2672 (1.3442) ce_loss 0.8809 (1.0511) teacher_loss 0.8870 (1.0286) loss_zs_kd 0.2681 (0.1652) loss_oracle 0.2461 (0.2330) acc 71.8750 (72.3828) kd_loss 0.6558 (0.5564) lr 1.2369e-04 eta 0:04:05
epoch [44/50] batch [180/244] time 0.162 (0.159) data 0.000 (0.002) loss 1.7402 (1.3529) ce_loss 1.5039 (1.0567) teacher_loss 1.4276 (1.0360) loss_zs_kd 0.1770 (0.1685) loss_oracle 0.2241 (0.2326) acc 56.2500 (72.2569) kd_loss 0.5122 (0.5576) lr 1.2369e-04 eta 0:04:02
epoch [44/50] batch [200/244] time 0.156 (0.159) data 0.000 (0.002) loss 1.5108 (1.3552) ce_loss 1.2490 (1.0602) teacher_loss 1.2591 (1.0395) loss_zs_kd 0.1486 (0.1682) loss_oracle 0.1774 (0.2315) acc 65.6250 (72.2344) kd_loss 0.4423 (0.5510) lr 1.2369e-04 eta 0:03:59
epoch [44/50] batch [220/244] time 0.155 (0.158) data 0.000 (0.001) loss 1.8757 (1.3589) ce_loss 1.5693 (1.0639) teacher_loss 1.5167 (1.0428) loss_zs_kd 0.2025 (0.1687) loss_oracle 0.2578 (0.2318) acc 68.7500 (72.2017) kd_loss 0.6229 (0.5488) lr 1.2369e-04 eta 0:03:55
epoch [44/50] batch [240/244] time 0.148 (0.159) data 0.000 (0.001) loss 1.4956 (1.3587) ce_loss 1.1270 (1.0625) teacher_loss 1.1192 (1.0423) loss_zs_kd 0.2123 (0.1696) loss_oracle 0.2703 (0.2316) acc 65.6250 (72.0964) kd_loss 0.7035 (0.5458) lr 1.2369e-04 eta 0:03:53
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [45/50] batch [20/244] time 0.157 (0.182) data 0.000 (0.017) loss 1.1656 (1.3602) ce_loss 0.9155 (1.0575) teacher_loss 0.8931 (1.0469) loss_zs_kd 0.1466 (0.1686) loss_oracle 0.1992 (0.2290) acc 75.0000 (71.5625) kd_loss 0.4252 (0.5601) lr 9.5173e-05 eta 0:04:23
epoch [45/50] batch [40/244] time 0.088 (0.162) data 0.000 (0.009) loss 1.4470 (1.3314) ce_loss 1.1602 (1.0219) teacher_loss 1.1534 (1.0153) loss_zs_kd 0.1293 (0.1704) loss_oracle 0.2290 (0.2309) acc 59.3750 (72.2656) kd_loss 0.5368 (0.5645) lr 9.5173e-05 eta 0:03:51
epoch [45/50] batch [60/244] time 0.229 (0.155) data 0.001 (0.006) loss 1.6671 (1.3447) ce_loss 1.3311 (1.0421) teacher_loss 1.3263 (1.0280) loss_zs_kd 0.1513 (0.1692) loss_oracle 0.2652 (0.2321) acc 65.6250 (71.7708) kd_loss 0.6934 (0.5462) lr 9.5173e-05 eta 0:03:38
epoch [45/50] batch [80/244] time 0.384 (0.155) data 0.000 (0.004) loss 1.0195 (1.3602) ce_loss 0.6914 (1.0605) teacher_loss 0.7237 (1.0458) loss_zs_kd 0.1507 (0.1667) loss_oracle 0.2205 (0.2310) acc 84.3750 (71.5234) kd_loss 0.6147 (0.5484) lr 9.5173e-05 eta 0:03:34
epoch [45/50] batch [100/244] time 0.097 (0.147) data 0.000 (0.004) loss 1.5757 (1.3705) ce_loss 1.2188 (1.0696) teacher_loss 1.2609 (1.0554) loss_zs_kd 0.2183 (0.1673) loss_oracle 0.2057 (0.2314) acc 68.7500 (71.4062) kd_loss 0.6243 (0.5502) lr 9.5173e-05 eta 0:03:21
epoch [45/50] batch [120/244] time 0.098 (0.148) data 0.000 (0.003) loss 0.9124 (1.3600) ce_loss 0.6182 (1.0586) teacher_loss 0.5964 (1.0444) loss_zs_kd 0.1964 (0.1689) loss_oracle 0.2178 (0.2312) acc 81.2500 (71.8229) kd_loss 0.5674 (0.5501) lr 9.5173e-05 eta 0:03:19
epoch [45/50] batch [140/244] time 0.087 (0.152) data 0.000 (0.003) loss 0.8581 (1.3670) ce_loss 0.5596 (1.0679) teacher_loss 0.5449 (1.0516) loss_zs_kd 0.1541 (0.1696) loss_oracle 0.2361 (0.2305) acc 81.2500 (71.5848) kd_loss 0.6041 (0.5459) lr 9.5173e-05 eta 0:03:20
epoch [45/50] batch [160/244] time 0.109 (0.154) data 0.001 (0.002) loss 1.0594 (1.3611) ce_loss 0.8281 (1.0635) teacher_loss 0.7768 (1.0458) loss_zs_kd 0.1406 (0.1701) loss_oracle 0.2122 (0.2302) acc 75.0000 (71.6797) kd_loss 0.5363 (0.5427) lr 9.5173e-05 eta 0:03:20
epoch [45/50] batch [180/244] time 0.090 (0.155) data 0.000 (0.002) loss 1.4889 (1.3679) ce_loss 1.2578 (1.0714) teacher_loss 1.1639 (1.0532) loss_zs_kd 0.1673 (0.1696) loss_oracle 0.2414 (0.2299) acc 68.7500 (71.5972) kd_loss 0.5040 (0.5412) lr 9.5173e-05 eta 0:03:18
epoch [45/50] batch [200/244] time 0.151 (0.153) data 0.001 (0.002) loss 1.0915 (1.3604) ce_loss 0.7856 (1.0646) teacher_loss 0.7440 (1.0462) loss_zs_kd 0.1688 (0.1693) loss_oracle 0.2631 (0.2295) acc 81.2500 (71.7656) kd_loss 0.5706 (0.5416) lr 9.5173e-05 eta 0:03:13
epoch [45/50] batch [220/244] time 0.148 (0.153) data 0.000 (0.002) loss 1.2633 (1.3586) ce_loss 0.8511 (1.0625) teacher_loss 0.9440 (1.0438) loss_zs_kd 0.2381 (0.1687) loss_oracle 0.2003 (0.2305) acc 68.7500 (71.6761) kd_loss 0.6681 (0.5486) lr 9.5173e-05 eta 0:03:10
epoch [45/50] batch [240/244] time 0.150 (0.153) data 0.000 (0.002) loss 1.5122 (1.3569) ce_loss 1.1230 (1.0592) teacher_loss 1.1643 (1.0402) loss_zs_kd 0.2053 (0.1696) loss_oracle 0.2453 (0.2318) acc 75.0000 (71.8099) kd_loss 0.6369 (0.5538) lr 9.5173e-05 eta 0:03:06
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,822
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [46/50] batch [20/244] time 0.182 (0.188) data 0.000 (0.017) loss 1.6261 (1.3505) ce_loss 1.3887 (1.0529) teacher_loss 1.3313 (1.0353) loss_zs_kd 0.2081 (0.1695) loss_oracle 0.1907 (0.2305) acc 62.5000 (71.2500) kd_loss 0.3744 (0.5398) lr 7.0224e-05 eta 0:03:45
epoch [46/50] batch [40/244] time 0.155 (0.178) data 0.000 (0.009) loss 1.2188 (1.3798) ce_loss 0.9297 (1.0785) teacher_loss 0.9107 (1.0622) loss_zs_kd 0.1629 (0.1743) loss_oracle 0.2267 (0.2304) acc 75.0000 (70.7031) kd_loss 0.5164 (0.5431) lr 7.0224e-05 eta 0:03:30
epoch [46/50] batch [60/244] time 0.150 (0.171) data 0.000 (0.006) loss 1.1256 (1.3807) ce_loss 0.7183 (1.0725) teacher_loss 0.7716 (1.0567) loss_zs_kd 0.1879 (0.1779) loss_oracle 0.2601 (0.2351) acc 78.1250 (71.0417) kd_loss 0.6299 (0.5583) lr 7.0224e-05 eta 0:03:18
epoch [46/50] batch [80/244] time 0.169 (0.168) data 0.000 (0.005) loss 1.4807 (1.3750) ce_loss 1.1885 (1.0710) teacher_loss 1.2206 (1.0534) loss_zs_kd 0.1522 (0.1744) loss_oracle 0.1840 (0.2344) acc 65.6250 (71.3281) kd_loss 0.4404 (0.5508) lr 7.0224e-05 eta 0:03:11
epoch [46/50] batch [100/244] time 0.153 (0.165) data 0.000 (0.004) loss 1.3487 (1.3580) ce_loss 1.1133 (1.0553) teacher_loss 1.0411 (1.0355) loss_zs_kd 0.1659 (0.1722) loss_oracle 0.2246 (0.2364) acc 75.0000 (72.0000) kd_loss 0.5298 (0.5581) lr 7.0224e-05 eta 0:03:04
epoch [46/50] batch [120/244] time 0.150 (0.162) data 0.000 (0.003) loss 1.2274 (1.3610) ce_loss 0.9302 (1.0627) teacher_loss 0.8844 (1.0411) loss_zs_kd 0.1167 (0.1711) loss_oracle 0.2846 (0.2343) acc 81.2500 (71.7448) kd_loss 0.5690 (0.5571) lr 7.0224e-05 eta 0:02:58
epoch [46/50] batch [140/244] time 0.150 (0.161) data 0.000 (0.003) loss 0.9885 (1.3576) ce_loss 0.7280 (1.0571) teacher_loss 0.7020 (1.0376) loss_zs_kd 0.1310 (0.1705) loss_oracle 0.2210 (0.2348) acc 78.1250 (71.7411) kd_loss 0.5342 (0.5553) lr 7.0224e-05 eta 0:02:53
epoch [46/50] batch [160/244] time 0.173 (0.162) data 0.000 (0.002) loss 1.5250 (1.3500) ce_loss 1.1738 (1.0498) teacher_loss 1.1771 (1.0296) loss_zs_kd 0.1391 (0.1689) loss_oracle 0.2784 (0.2359) acc 75.0000 (71.8945) kd_loss 0.7068 (0.5573) lr 7.0224e-05 eta 0:02:52
epoch [46/50] batch [180/244] time 0.096 (0.158) data 0.000 (0.002) loss 1.7660 (1.3512) ce_loss 1.5430 (1.0503) teacher_loss 1.4651 (1.0302) loss_zs_kd 0.1381 (0.1689) loss_oracle 0.2319 (0.2366) acc 65.6250 (71.8750) kd_loss 0.4398 (0.5592) lr 7.0224e-05 eta 0:02:44
epoch [46/50] batch [200/244] time 0.103 (0.160) data 0.000 (0.002) loss 2.2044 (1.3598) ce_loss 1.7666 (1.0578) teacher_loss 1.8052 (1.0382) loss_zs_kd 0.2477 (0.1698) loss_oracle 0.2754 (0.2367) acc 53.1250 (71.6875) kd_loss 0.6296 (0.5600) lr 7.0224e-05 eta 0:02:43
epoch [46/50] batch [220/244] time 0.107 (0.158) data 0.000 (0.002) loss 1.3250 (1.3616) ce_loss 1.0137 (1.0584) teacher_loss 0.9422 (1.0389) loss_zs_kd 0.1631 (0.1706) loss_oracle 0.3012 (0.2375) acc 78.1250 (71.7756) kd_loss 0.6549 (0.5595) lr 7.0224e-05 eta 0:02:38
epoch [46/50] batch [240/244] time 0.092 (0.157) data 0.000 (0.002) loss 1.3019 (1.3685) ce_loss 1.0244 (1.0641) teacher_loss 0.9453 (1.0449) loss_zs_kd 0.1532 (0.1715) loss_oracle 0.2800 (0.2378) acc 68.7500 (71.5755) kd_loss 0.6015 (0.5603) lr 7.0224e-05 eta 0:02:34
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,038
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.5%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [47/50] batch [20/244] time 0.152 (0.162) data 0.000 (0.012) loss 1.0879 (1.2985) ce_loss 0.8354 (0.9911) teacher_loss 0.8595 (0.9786) loss_zs_kd 0.1463 (0.1653) loss_oracle 0.1552 (0.2372) acc 75.0000 (72.1875) kd_loss 0.3812 (0.5535) lr 4.8943e-05 eta 0:02:35
epoch [47/50] batch [40/244] time 0.146 (0.157) data 0.000 (0.006) loss 0.8987 (1.2977) ce_loss 0.6978 (1.0002) teacher_loss 0.6623 (0.9822) loss_zs_kd 0.1390 (0.1633) loss_oracle 0.1669 (0.2339) acc 78.1250 (73.4375) kd_loss 0.4796 (0.5311) lr 4.8943e-05 eta 0:02:26
epoch [47/50] batch [60/244] time 0.153 (0.156) data 0.000 (0.004) loss 1.0867 (1.3573) ce_loss 0.8027 (1.0595) teacher_loss 0.7496 (1.0418) loss_zs_kd 0.2212 (0.1650) loss_oracle 0.2265 (0.2330) acc 75.0000 (71.4062) kd_loss 0.4179 (0.5375) lr 4.8943e-05 eta 0:02:22
epoch [47/50] batch [80/244] time 0.168 (0.156) data 0.000 (0.003) loss 1.3246 (1.3503) ce_loss 0.9644 (1.0538) teacher_loss 0.9851 (1.0345) loss_zs_kd 0.1798 (0.1649) loss_oracle 0.2496 (0.2334) acc 78.1250 (71.8359) kd_loss 0.6644 (0.5479) lr 4.8943e-05 eta 0:02:19
epoch [47/50] batch [100/244] time 0.165 (0.158) data 0.000 (0.003) loss 1.8025 (1.3656) ce_loss 1.5225 (1.0700) teacher_loss 1.4462 (1.0495) loss_zs_kd 0.2330 (0.1645) loss_oracle 0.2399 (0.2338) acc 59.3750 (71.4062) kd_loss 0.5469 (0.5435) lr 4.8943e-05 eta 0:02:18
epoch [47/50] batch [120/244] time 0.149 (0.158) data 0.000 (0.002) loss 1.4218 (1.3534) ce_loss 1.1445 (1.0607) teacher_loss 1.1342 (1.0396) loss_zs_kd 0.1549 (0.1649) loss_oracle 0.2102 (0.2314) acc 71.8750 (71.7708) kd_loss 0.4631 (0.5425) lr 4.8943e-05 eta 0:02:15
epoch [47/50] batch [140/244] time 0.151 (0.158) data 0.000 (0.002) loss 1.7538 (1.3583) ce_loss 1.4238 (1.0664) teacher_loss 1.3931 (1.0456) loss_zs_kd 0.2204 (0.1652) loss_oracle 0.2505 (0.2301) acc 68.7500 (71.6964) kd_loss 0.5339 (0.5427) lr 4.8943e-05 eta 0:02:11
epoch [47/50] batch [160/244] time 0.169 (0.158) data 0.000 (0.002) loss 1.1552 (1.3593) ce_loss 0.8853 (1.0667) teacher_loss 0.8887 (1.0464) loss_zs_kd 0.1461 (0.1636) loss_oracle 0.1934 (0.2311) acc 84.3750 (71.9922) kd_loss 0.6743 (0.5527) lr 4.8943e-05 eta 0:02:08
epoch [47/50] batch [180/244] time 0.158 (0.158) data 0.000 (0.002) loss 1.4186 (1.3498) ce_loss 1.0781 (1.0565) teacher_loss 1.0566 (1.0366) loss_zs_kd 0.2233 (0.1640) loss_oracle 0.2503 (0.2312) acc 65.6250 (72.2743) kd_loss 0.5400 (0.5551) lr 4.8943e-05 eta 0:02:05
epoch [47/50] batch [200/244] time 0.152 (0.158) data 0.000 (0.001) loss 1.1560 (1.3452) ce_loss 0.8423 (1.0523) teacher_loss 0.8235 (1.0313) loss_zs_kd 0.1778 (0.1651) loss_oracle 0.2436 (0.2313) acc 81.2500 (72.3750) kd_loss 0.5835 (0.5516) lr 4.8943e-05 eta 0:02:02
epoch [47/50] batch [220/244] time 0.153 (0.158) data 0.000 (0.001) loss 1.5934 (1.3560) ce_loss 1.2520 (1.0620) teacher_loss 1.2732 (1.0410) loss_zs_kd 0.2361 (0.1663) loss_oracle 0.2021 (0.2319) acc 68.7500 (72.1023) kd_loss 0.4917 (0.5494) lr 4.8943e-05 eta 0:01:59
epoch [47/50] batch [240/244] time 0.169 (0.158) data 0.000 (0.001) loss 1.3745 (1.3427) ce_loss 1.0498 (1.0496) teacher_loss 1.0460 (1.0279) loss_zs_kd 0.2358 (0.1675) loss_oracle 0.2106 (0.2310) acc 78.1250 (72.3958) kd_loss 0.5913 (0.5451) lr 4.8943e-05 eta 0:01:56
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [48/50] batch [20/244] time 0.332 (0.144) data 0.000 (0.014) loss 1.1498 (1.4316) ce_loss 0.8149 (1.1329) teacher_loss 0.6982 (1.0924) loss_zs_kd 0.2976 (0.1819) loss_oracle 0.3029 (0.2482) acc 71.8750 (70.3125) kd_loss 0.5901 (0.5708) lr 3.1417e-05 eta 0:01:42
epoch [48/50] batch [40/244] time 0.295 (0.162) data 0.000 (0.007) loss 1.3334 (1.3946) ce_loss 1.0742 (1.0940) teacher_loss 1.0398 (1.0585) loss_zs_kd 0.0855 (0.1791) loss_oracle 0.2509 (0.2466) acc 68.7500 (71.3281) kd_loss 0.6561 (0.5673) lr 3.1417e-05 eta 0:01:52
epoch [48/50] batch [60/244] time 0.084 (0.164) data 0.001 (0.005) loss 1.2773 (1.3881) ce_loss 0.9844 (1.0891) teacher_loss 0.9750 (1.0601) loss_zs_kd 0.1480 (0.1739) loss_oracle 0.2284 (0.2410) acc 71.8750 (71.4583) kd_loss 0.5534 (0.5550) lr 3.1417e-05 eta 0:01:49
epoch [48/50] batch [80/244] time 0.339 (0.165) data 0.000 (0.004) loss 1.4690 (1.3894) ce_loss 1.1807 (1.0939) teacher_loss 1.0947 (1.0629) loss_zs_kd 0.1884 (0.1713) loss_oracle 0.2800 (0.2409) acc 65.6250 (71.2891) kd_loss 0.6465 (0.5600) lr 3.1417e-05 eta 0:01:47
epoch [48/50] batch [100/244] time 0.148 (0.157) data 0.000 (0.003) loss 1.2123 (1.3799) ce_loss 0.9722 (1.0846) teacher_loss 0.9007 (1.0548) loss_zs_kd 0.1499 (0.1696) loss_oracle 0.2366 (0.2404) acc 71.8750 (71.0625) kd_loss 0.4571 (0.5605) lr 3.1417e-05 eta 0:01:39
epoch [48/50] batch [120/244] time 0.155 (0.156) data 0.000 (0.002) loss 1.0741 (1.3837) ce_loss 0.7725 (1.0907) teacher_loss 0.7675 (1.0613) loss_zs_kd 0.1893 (0.1692) loss_oracle 0.2120 (0.2378) acc 75.0000 (71.1458) kd_loss 0.4565 (0.5559) lr 3.1417e-05 eta 0:01:35
epoch [48/50] batch [140/244] time 0.152 (0.156) data 0.000 (0.002) loss 1.5030 (1.3903) ce_loss 1.1133 (1.0968) teacher_loss 1.1480 (1.0678) loss_zs_kd 0.1880 (0.1711) loss_oracle 0.2611 (0.2370) acc 75.0000 (70.9598) kd_loss 0.6352 (0.5528) lr 3.1417e-05 eta 0:01:32
epoch [48/50] batch [160/244] time 0.143 (0.156) data 0.000 (0.002) loss 1.7604 (1.3796) ce_loss 1.5068 (1.0862) teacher_loss 1.4445 (1.0588) loss_zs_kd 0.1255 (0.1693) loss_oracle 0.2531 (0.2362) acc 65.6250 (71.3086) kd_loss 0.5715 (0.5514) lr 3.1417e-05 eta 0:01:29
epoch [48/50] batch [180/244] time 0.181 (0.156) data 0.000 (0.002) loss 1.1790 (1.3718) ce_loss 0.8813 (1.0773) teacher_loss 0.8558 (1.0503) loss_zs_kd 0.1713 (0.1703) loss_oracle 0.2375 (0.2363) acc 81.2500 (71.4236) kd_loss 0.4797 (0.5488) lr 3.1417e-05 eta 0:01:26
epoch [48/50] batch [200/244] time 0.149 (0.158) data 0.000 (0.002) loss 1.2548 (1.3763) ce_loss 0.9287 (1.0815) teacher_loss 0.8864 (1.0550) loss_zs_kd 0.1991 (0.1707) loss_oracle 0.2689 (0.2360) acc 84.3750 (71.4688) kd_loss 0.6253 (0.5487) lr 3.1417e-05 eta 0:01:23
epoch [48/50] batch [220/244] time 0.152 (0.157) data 0.000 (0.001) loss 1.3665 (1.3797) ce_loss 1.0225 (1.0838) teacher_loss 1.0550 (1.0580) loss_zs_kd 0.1543 (0.1701) loss_oracle 0.2343 (0.2367) acc 71.8750 (71.4205) kd_loss 0.6762 (0.5510) lr 3.1417e-05 eta 0:01:20
epoch [48/50] batch [240/244] time 0.173 (0.157) data 0.000 (0.001) loss 1.2726 (1.3714) ce_loss 0.9932 (1.0747) teacher_loss 0.9960 (1.0493) loss_zs_kd 0.1363 (0.1706) loss_oracle 0.2085 (0.2368) acc 68.7500 (71.7188) kd_loss 0.4619 (0.5506) lr 3.1417e-05 eta 0:01:17
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [49/50] batch [20/244] time 0.178 (0.179) data 0.000 (0.015) loss 1.3146 (1.3541) ce_loss 1.0713 (1.0478) teacher_loss 1.0249 (1.0282) loss_zs_kd 0.1548 (0.1862) loss_oracle 0.2123 (0.2327) acc 68.7500 (72.8125) kd_loss 0.5246 (0.5535) lr 1.7713e-05 eta 0:01:23
epoch [49/50] batch [40/244] time 0.153 (0.169) data 0.000 (0.008) loss 1.3765 (1.3262) ce_loss 1.0225 (1.0360) teacher_loss 1.0179 (1.0131) loss_zs_kd 0.1833 (0.1725) loss_oracle 0.2670 (0.2269) acc 68.7500 (72.8906) kd_loss 0.5776 (0.5268) lr 1.7713e-05 eta 0:01:15
epoch [49/50] batch [60/244] time 0.136 (0.167) data 0.000 (0.005) loss 1.0334 (1.3342) ce_loss 0.7490 (1.0394) teacher_loss 0.7130 (1.0214) loss_zs_kd 0.2233 (0.1709) loss_oracle 0.2088 (0.2274) acc 78.1250 (72.9167) kd_loss 0.3888 (0.5315) lr 1.7713e-05 eta 0:01:11
epoch [49/50] batch [80/244] time 0.336 (0.153) data 0.000 (0.004) loss 0.9090 (1.3468) ce_loss 0.6948 (1.0496) teacher_loss 0.6426 (1.0311) loss_zs_kd 0.1574 (0.1726) loss_oracle 0.1877 (0.2293) acc 84.3750 (72.6172) kd_loss 0.3920 (0.5435) lr 1.7713e-05 eta 0:01:02
epoch [49/50] batch [100/244] time 0.099 (0.154) data 0.000 (0.003) loss 1.1427 (1.3662) ce_loss 0.8452 (1.0686) teacher_loss 0.8311 (1.0487) loss_zs_kd 0.1622 (0.1718) loss_oracle 0.2305 (0.2316) acc 71.8750 (72.0000) kd_loss 0.6254 (0.5485) lr 1.7713e-05 eta 0:00:59
epoch [49/50] batch [120/244] time 0.089 (0.154) data 0.000 (0.003) loss 1.2520 (1.3460) ce_loss 0.9180 (1.0492) teacher_loss 0.9260 (1.0285) loss_zs_kd 0.1995 (0.1710) loss_oracle 0.2263 (0.2320) acc 78.1250 (72.5521) kd_loss 0.7160 (0.5502) lr 1.7713e-05 eta 0:00:56
epoch [49/50] batch [140/244] time 0.163 (0.153) data 0.000 (0.002) loss 1.4477 (1.3276) ce_loss 1.2139 (1.0300) teacher_loss 1.1931 (1.0108) loss_zs_kd 0.1753 (0.1709) loss_oracle 0.1669 (0.2313) acc 65.6250 (73.2589) kd_loss 0.3204 (0.5455) lr 1.7713e-05 eta 0:00:53
epoch [49/50] batch [160/244] time 0.089 (0.155) data 0.000 (0.002) loss 1.1873 (1.3404) ce_loss 0.9390 (1.0435) teacher_loss 0.9047 (1.0238) loss_zs_kd 0.1277 (0.1702) loss_oracle 0.2188 (0.2316) acc 78.1250 (73.1250) kd_loss 0.4480 (0.5477) lr 1.7713e-05 eta 0:00:50
epoch [49/50] batch [180/244] time 0.093 (0.156) data 0.000 (0.002) loss 1.1748 (1.3370) ce_loss 0.9346 (1.0372) teacher_loss 0.9112 (1.0197) loss_zs_kd 0.1996 (0.1691) loss_oracle 0.1638 (0.2327) acc 78.1250 (73.0382) kd_loss 0.3329 (0.5522) lr 1.7713e-05 eta 0:00:47
epoch [49/50] batch [200/244] time 0.148 (0.156) data 0.000 (0.002) loss 1.1714 (1.3465) ce_loss 0.9214 (1.0474) teacher_loss 0.8845 (1.0302) loss_zs_kd 0.1333 (0.1686) loss_oracle 0.2202 (0.2319) acc 71.8750 (72.7500) kd_loss 0.5540 (0.5469) lr 1.7713e-05 eta 0:00:44
epoch [49/50] batch [220/244] time 0.148 (0.155) data 0.000 (0.002) loss 2.2270 (1.3541) ce_loss 1.8301 (1.0549) teacher_loss 1.9266 (1.0383) loss_zs_kd 0.2181 (0.1688) loss_oracle 0.1914 (0.2314) acc 59.3750 (72.5142) kd_loss 0.4960 (0.5472) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [240/244] time 0.153 (0.155) data 0.000 (0.001) loss 1.5329 (1.3533) ce_loss 1.2490 (1.0546) teacher_loss 1.2382 (1.0380) loss_zs_kd 0.1435 (0.1683) loss_oracle 0.2230 (0.2311) acc 62.5000 (72.4740) kd_loss 0.4303 (0.5475) lr 1.7713e-05 eta 0:00:38
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [50/50] batch [20/244] time 0.160 (0.195) data 0.000 (0.016) loss 1.4656 (1.3689) ce_loss 1.1738 (1.0700) teacher_loss 1.1692 (1.0498) loss_zs_kd 0.1425 (0.1687) loss_oracle 0.2251 (0.2347) acc 68.7500 (71.8750) kd_loss 0.5343 (0.5705) lr 7.8853e-06 eta 0:00:43
epoch [50/50] batch [40/244] time 0.159 (0.183) data 0.000 (0.008) loss 1.5288 (1.3504) ce_loss 1.2402 (1.0445) teacher_loss 1.2325 (1.0275) loss_zs_kd 0.1892 (0.1680) loss_oracle 0.2017 (0.2389) acc 62.5000 (72.4219) kd_loss 0.5617 (0.5778) lr 7.8853e-06 eta 0:00:37
epoch [50/50] batch [60/244] time 0.151 (0.177) data 0.001 (0.006) loss 0.7336 (1.3229) ce_loss 0.4387 (1.0227) teacher_loss 0.4484 (1.0070) loss_zs_kd 0.1113 (0.1702) loss_oracle 0.2296 (0.2308) acc 87.5000 (73.1771) kd_loss 0.6184 (0.5583) lr 7.8853e-06 eta 0:00:32
epoch [50/50] batch [80/244] time 0.148 (0.174) data 0.000 (0.004) loss 1.5194 (1.3177) ce_loss 1.2549 (1.0199) teacher_loss 1.2521 (1.0035) loss_zs_kd 0.1460 (0.1665) loss_oracle 0.1943 (0.2310) acc 68.7500 (72.8906) kd_loss 0.4967 (0.5540) lr 7.8853e-06 eta 0:00:28
epoch [50/50] batch [100/244] time 0.160 (0.172) data 0.000 (0.003) loss 1.6662 (1.3399) ce_loss 1.3525 (1.0426) teacher_loss 1.3517 (1.0260) loss_zs_kd 0.1487 (0.1662) loss_oracle 0.2402 (0.2308) acc 65.6250 (72.5938) kd_loss 0.5592 (0.5455) lr 7.8853e-06 eta 0:00:24
epoch [50/50] batch [120/244] time 0.172 (0.172) data 0.000 (0.003) loss 1.3239 (1.3308) ce_loss 0.9741 (1.0338) teacher_loss 0.9346 (1.0173) loss_zs_kd 0.1749 (0.1658) loss_oracle 0.3018 (0.2306) acc 71.8750 (72.8646) kd_loss 0.6319 (0.5448) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [140/244] time 0.180 (0.171) data 0.000 (0.003) loss 1.3152 (1.3393) ce_loss 1.0674 (1.0428) teacher_loss 1.0419 (1.0248) loss_zs_kd 0.1345 (0.1657) loss_oracle 0.2061 (0.2316) acc 71.8750 (72.4554) kd_loss 0.5421 (0.5462) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [160/244] time 0.206 (0.164) data 0.000 (0.002) loss 0.9969 (1.3305) ce_loss 0.6343 (1.0346) teacher_loss 0.6795 (1.0166) loss_zs_kd 0.1587 (0.1662) loss_oracle 0.2381 (0.2309) acc 87.5000 (72.5391) kd_loss 0.6865 (0.5420) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [180/244] time 0.096 (0.162) data 0.000 (0.002) loss 1.8135 (1.3369) ce_loss 1.5615 (1.0403) teacher_loss 1.4897 (1.0219) loss_zs_kd 0.1344 (0.1686) loss_oracle 0.2566 (0.2307) acc 56.2500 (72.3438) kd_loss 0.4880 (0.5400) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [200/244] time 0.088 (0.163) data 0.000 (0.002) loss 1.2086 (1.3399) ce_loss 0.9165 (1.0417) teacher_loss 0.8987 (1.0246) loss_zs_kd 0.2781 (0.1690) loss_oracle 0.1709 (0.2308) acc 78.1250 (72.3438) kd_loss 0.3918 (0.5431) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [220/244] time 0.130 (0.159) data 0.000 (0.002) loss 1.8476 (1.3364) ce_loss 1.5449 (1.0376) teacher_loss 1.4845 (1.0208) loss_zs_kd 0.2104 (0.1694) loss_oracle 0.2579 (0.2309) acc 50.0000 (72.4574) kd_loss 0.5431 (0.5434) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [240/244] time 0.083 (0.159) data 0.000 (0.002) loss 0.9470 (1.3444) ce_loss 0.6411 (1.0445) teacher_loss 0.6162 (1.0279) loss_zs_kd 0.1274 (0.1705) loss_oracle 0.2670 (0.2312) acc 81.2500 (72.2266) kd_loss 0.6120 (0.5471) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,037
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.5%
******* Domain p best val acc:      84.8%, epoch: 24 *******
******* Domain p best val test acc: 91.1%, epoch: 24 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:38:53

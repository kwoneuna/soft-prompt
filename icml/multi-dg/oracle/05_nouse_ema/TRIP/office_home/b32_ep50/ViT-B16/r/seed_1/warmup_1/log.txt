Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'clipart', 'product']
Target     ['real_world']
# classes  65
# train_x  7,877
# val      3,354
# test     4,357
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/246] time 0.159 (0.208) data 0.000 (0.019) loss 1.6788 (1.5611) ce_loss 1.6025 (1.4863) teacher_loss 1.6043 (1.4864) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0745 (0.0747) acc 59.3750 (61.0938) kd_loss 0.3548 (0.3549) lr 1.0000e-05 eta 0:42:31
epoch [1/50] batch [40/246] time 0.148 (0.180) data 0.000 (0.010) loss 1.0997 (1.4884) ce_loss 1.0205 (1.4154) teacher_loss 1.0204 (1.4158) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0793 (0.0727) acc 75.0000 (63.1250) kd_loss 0.3818 (0.3463) lr 1.0000e-05 eta 0:36:48
epoch [1/50] batch [60/246] time 0.153 (0.171) data 0.000 (0.007) loss 1.1940 (1.4876) ce_loss 1.1289 (1.4164) teacher_loss 1.1292 (1.4166) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0648 (0.0710) acc 78.1250 (63.4375) kd_loss 0.3002 (0.3369) lr 1.0000e-05 eta 0:34:48
epoch [1/50] batch [80/246] time 0.171 (0.166) data 0.000 (0.005) loss 2.0126 (1.4812) ce_loss 1.9307 (1.4091) teacher_loss 1.9278 (1.4094) loss_zs_kd 0.0006 (0.0002) loss_oracle 0.0848 (0.0718) acc 50.0000 (63.5547) kd_loss 0.3952 (0.3395) lr 1.0000e-05 eta 0:33:53
epoch [1/50] batch [100/246] time 0.168 (0.168) data 0.000 (0.004) loss 1.5456 (1.4639) ce_loss 1.4580 (1.3916) teacher_loss 1.4568 (1.3918) loss_zs_kd 0.0011 (0.0002) loss_oracle 0.0887 (0.0721) acc 59.3750 (63.8438) kd_loss 0.4046 (0.3400) lr 1.0000e-05 eta 0:34:05
epoch [1/50] batch [120/246] time 0.158 (0.168) data 0.000 (0.003) loss 1.5570 (1.4654) ce_loss 1.5068 (1.3922) teacher_loss 1.5072 (1.3924) loss_zs_kd 0.0012 (0.0003) loss_oracle 0.0496 (0.0729) acc 59.3750 (63.9844) kd_loss 0.2184 (0.3425) lr 1.0000e-05 eta 0:34:07
epoch [1/50] batch [140/246] time 0.172 (0.169) data 0.000 (0.003) loss 1.8177 (1.4651) ce_loss 1.7402 (1.3916) teacher_loss 1.7417 (1.3918) loss_zs_kd 0.0007 (0.0005) loss_oracle 0.0758 (0.0733) acc 53.1250 (64.0402) kd_loss 0.3483 (0.3430) lr 1.0000e-05 eta 0:34:09
epoch [1/50] batch [160/246] time 0.094 (0.164) data 0.000 (0.003) loss 1.7186 (1.4784) ce_loss 1.5986 (1.4026) teacher_loss 1.5998 (1.4027) loss_zs_kd 0.0012 (0.0006) loss_oracle 0.1187 (0.0757) acc 65.6250 (63.5547) kd_loss 0.5474 (0.3519) lr 1.0000e-05 eta 0:33:16
epoch [1/50] batch [180/246] time 0.086 (0.163) data 0.000 (0.002) loss 1.7132 (1.4728) ce_loss 1.6123 (1.3962) teacher_loss 1.6118 (1.3963) loss_zs_kd 0.0018 (0.0007) loss_oracle 0.1013 (0.0764) acc 56.2500 (63.9236) kd_loss 0.4371 (0.3542) lr 1.0000e-05 eta 0:32:50
epoch [1/50] batch [200/246] time 0.279 (0.164) data 0.000 (0.002) loss 2.1937 (1.4742) ce_loss 2.1250 (1.3970) teacher_loss 2.1248 (1.3971) loss_zs_kd 0.0056 (0.0009) loss_oracle 0.0683 (0.0771) acc 40.6250 (63.8281) kd_loss 0.2874 (0.3559) lr 1.0000e-05 eta 0:33:04
epoch [1/50] batch [220/246] time 0.092 (0.160) data 0.000 (0.002) loss 1.3296 (1.4751) ce_loss 1.2725 (1.3973) teacher_loss 1.2724 (1.3974) loss_zs_kd 0.0042 (0.0012) loss_oracle 0.0568 (0.0776) acc 71.8750 (63.9915) kd_loss 0.2608 (0.3579) lr 1.0000e-05 eta 0:32:15
epoch [1/50] batch [240/246] time 0.323 (0.160) data 0.000 (0.002) loss 1.6867 (1.4746) ce_loss 1.5811 (1.3960) teacher_loss 1.5827 (1.3961) loss_zs_kd 0.0031 (0.0013) loss_oracle 0.1037 (0.0784) acc 59.3750 (63.9323) kd_loss 0.4713 (0.3609) lr 1.0000e-05 eta 0:32:04
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,683
* accuracy: 80.0%
* error: 20.0%
* macro_f1: 78.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,893
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 87.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      80.0%, epoch: 1 *******
******* Domain r best val test acc: 89.4%, epoch: 1 *******
******* Domain r best test acc:     89.4%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/ana
epoch [2/50] batch [20/246] time 0.153 (0.173) data 0.000 (0.016) loss 2.1362 (1.8347) ce_loss 1.6104 (1.4385) teacher_loss 1.6470 (1.4397) loss_zs_kd 0.1520 (0.0864) loss_oracle 0.4740 (0.3863) acc 68.7500 (63.9062) kd_loss 0.5136 (0.4640) lr 2.0000e-03 eta 0:34:37
epoch [2/50] batch [40/246] time 0.153 (0.163) data 0.000 (0.008) loss 1.9563 (1.8350) ce_loss 1.4248 (1.3699) teacher_loss 1.4488 (1.3773) loss_zs_kd 0.1502 (0.1221) loss_oracle 0.4925 (0.4454) acc 62.5000 (64.9219) kd_loss 0.5714 (0.5328) lr 2.0000e-03 eta 0:32:33
epoch [2/50] batch [60/246] time 0.161 (0.164) data 0.000 (0.006) loss 1.8277 (1.7776) ce_loss 1.3008 (1.2978) teacher_loss 1.3257 (1.3033) loss_zs_kd 0.1889 (0.1330) loss_oracle 0.4831 (0.4610) acc 65.6250 (66.4062) kd_loss 0.4942 (0.5444) lr 2.0000e-03 eta 0:32:46
epoch [2/50] batch [80/246] time 0.154 (0.165) data 0.000 (0.004) loss 1.7832 (1.7493) ce_loss 1.2256 (1.2637) teacher_loss 1.2192 (1.2668) loss_zs_kd 0.2360 (0.1482) loss_oracle 0.5403 (0.4677) acc 59.3750 (67.2266) kd_loss 0.5076 (0.5384) lr 2.0000e-03 eta 0:33:00
epoch [2/50] batch [100/246] time 0.156 (0.163) data 0.000 (0.003) loss 1.5748 (1.7497) ce_loss 1.0371 (1.2539) teacher_loss 1.0539 (1.2581) loss_zs_kd 0.1333 (0.1571) loss_oracle 0.5075 (0.4759) acc 68.7500 (67.0938) kd_loss 0.5046 (0.5427) lr 2.0000e-03 eta 0:32:33
epoch [2/50] batch [120/246] time 0.149 (0.161) data 0.000 (0.003) loss 1.6114 (1.7504) ce_loss 1.0469 (1.2403) teacher_loss 1.0405 (1.2433) loss_zs_kd 0.1401 (0.1649) loss_oracle 0.5569 (0.4906) acc 68.7500 (67.7865) kd_loss 0.5966 (0.5503) lr 2.0000e-03 eta 0:32:04
epoch [2/50] batch [140/246] time 0.151 (0.160) data 0.000 (0.003) loss 1.8648 (1.7492) ce_loss 1.2910 (1.2285) teacher_loss 1.2388 (1.2304) loss_zs_kd 0.1402 (0.1722) loss_oracle 0.6119 (0.5016) acc 68.7500 (67.9241) kd_loss 0.6224 (0.5571) lr 2.0000e-03 eta 0:31:43
epoch [2/50] batch [160/246] time 0.154 (0.159) data 0.000 (0.002) loss 1.5164 (1.7406) ce_loss 0.9438 (1.2196) teacher_loss 0.9377 (1.2208) loss_zs_kd 0.1634 (0.1758) loss_oracle 0.5623 (0.5022) acc 71.8750 (68.1250) kd_loss 0.5937 (0.5563) lr 2.0000e-03 eta 0:31:29
epoch [2/50] batch [180/246] time 0.150 (0.158) data 0.000 (0.002) loss 1.8594 (1.7352) ce_loss 1.2188 (1.2100) teacher_loss 1.2453 (1.2106) loss_zs_kd 0.2522 (0.1792) loss_oracle 0.5889 (0.5067) acc 78.1250 (68.4722) kd_loss 0.4841 (0.5597) lr 2.0000e-03 eta 0:31:18
epoch [2/50] batch [200/246] time 0.174 (0.158) data 0.000 (0.002) loss 2.2001 (1.7460) ce_loss 1.5674 (1.2114) teacher_loss 1.5872 (1.2116) loss_zs_kd 0.1929 (0.1848) loss_oracle 0.5936 (0.5160) acc 62.5000 (68.5312) kd_loss 0.6237 (0.5718) lr 2.0000e-03 eta 0:31:08
epoch [2/50] batch [220/246] time 0.145 (0.158) data 0.000 (0.002) loss 1.6886 (1.7449) ce_loss 1.1670 (1.2059) teacher_loss 1.1712 (1.2058) loss_zs_kd 0.2445 (0.1878) loss_oracle 0.4929 (0.5204) acc 68.7500 (68.6364) kd_loss 0.6204 (0.5762) lr 2.0000e-03 eta 0:31:05
epoch [2/50] batch [240/246] time 0.152 (0.157) data 0.000 (0.002) loss 1.8915 (1.7526) ce_loss 1.1602 (1.2085) teacher_loss 1.1844 (1.2082) loss_zs_kd 0.3654 (0.1916) loss_oracle 0.6706 (0.5252) acc 68.7500 (68.5938) kd_loss 0.7235 (0.5845) lr 2.0000e-03 eta 0:30:57
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,811
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,953
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      83.8%, epoch: 2 *******
******* Domain r best val test acc: 90.7%, epoch: 2 *******
******* Domain r best test acc:     90.7%, epoch: 2 *******
epoch [3/50] batch [20/246] time 0.114 (0.136) data 0.000 (0.013) loss 2.0448 (1.7965) ce_loss 1.3613 (1.1670) teacher_loss 1.4109 (1.1722) loss_zs_kd 0.1798 (0.2419) loss_oracle 0.6159 (0.6002) acc 62.5000 (69.8438) kd_loss 0.8838 (0.6767) lr 1.9980e-03 eta 0:26:43
epoch [3/50] batch [40/246] time 0.147 (0.157) data 0.000 (0.006) loss 1.3285 (1.7863) ce_loss 0.7051 (1.1670) teacher_loss 0.6947 (1.1687) loss_zs_kd 0.1391 (0.2314) loss_oracle 0.6198 (0.5945) acc 84.3750 (70.7812) kd_loss 0.6881 (0.6774) lr 1.9980e-03 eta 0:30:47
epoch [3/50] batch [60/246] time 0.099 (0.165) data 0.000 (0.004) loss 2.3212 (1.7844) ce_loss 1.7793 (1.1801) teacher_loss 1.8050 (1.1816) loss_zs_kd 0.2024 (0.2250) loss_oracle 0.4960 (0.5803) acc 46.8750 (69.2708) kd_loss 0.6346 (0.6754) lr 1.9980e-03 eta 0:32:15
epoch [3/50] batch [80/246] time 0.086 (0.164) data 0.000 (0.003) loss 2.3115 (1.7822) ce_loss 1.8311 (1.1984) teacher_loss 1.7704 (1.1963) loss_zs_kd 0.2371 (0.2283) loss_oracle 0.5175 (0.5630) acc 62.5000 (69.2969) kd_loss 0.6386 (0.6583) lr 1.9980e-03 eta 0:32:02
epoch [3/50] batch [100/246] time 0.125 (0.165) data 0.000 (0.003) loss 1.5799 (1.7708) ce_loss 1.0176 (1.1959) teacher_loss 1.0017 (1.1933) loss_zs_kd 0.1427 (0.2289) loss_oracle 0.5639 (0.5546) acc 68.7500 (69.2500) kd_loss 0.5863 (0.6512) lr 1.9980e-03 eta 0:32:10
epoch [3/50] batch [120/246] time 0.175 (0.160) data 0.000 (0.002) loss 1.7085 (1.7554) ce_loss 1.0518 (1.1850) teacher_loss 1.1037 (1.1818) loss_zs_kd 0.1527 (0.2290) loss_oracle 0.5895 (0.5507) acc 78.1250 (69.4010) kd_loss 0.7227 (0.6495) lr 1.9980e-03 eta 0:31:12
epoch [3/50] batch [140/246] time 0.175 (0.161) data 0.000 (0.002) loss 2.1414 (1.7595) ce_loss 1.5908 (1.1871) teacher_loss 1.6065 (1.1867) loss_zs_kd 0.2365 (0.2299) loss_oracle 0.5113 (0.5498) acc 53.1250 (69.1071) kd_loss 0.6770 (0.6525) lr 1.9980e-03 eta 0:31:21
epoch [3/50] batch [160/246] time 0.170 (0.162) data 0.000 (0.002) loss 1.5934 (1.7582) ce_loss 1.0098 (1.1883) teacher_loss 1.0107 (1.1865) loss_zs_kd 0.2367 (0.2294) loss_oracle 0.5590 (0.5488) acc 75.0000 (69.1992) kd_loss 0.6069 (0.6484) lr 1.9980e-03 eta 0:31:23
epoch [3/50] batch [180/246] time 0.176 (0.162) data 0.000 (0.002) loss 1.8114 (1.7531) ce_loss 1.2598 (1.1797) teacher_loss 1.1968 (1.1764) loss_zs_kd 0.2534 (0.2308) loss_oracle 0.5893 (0.5537) acc 71.8750 (69.2882) kd_loss 0.6341 (0.6453) lr 1.9980e-03 eta 0:31:19
epoch [3/50] batch [200/246] time 0.176 (0.162) data 0.000 (0.001) loss 1.6149 (1.7528) ce_loss 1.1016 (1.1784) teacher_loss 1.0780 (1.1746) loss_zs_kd 0.1887 (0.2332) loss_oracle 0.5180 (0.5549) acc 78.1250 (69.1719) kd_loss 0.5819 (0.6435) lr 1.9980e-03 eta 0:31:22
epoch [3/50] batch [220/246] time 0.150 (0.163) data 0.000 (0.001) loss 1.6016 (1.7611) ce_loss 0.8354 (1.1794) teacher_loss 0.8502 (1.1747) loss_zs_kd 0.1982 (0.2344) loss_oracle 0.7316 (0.5630) acc 75.0000 (69.0341) kd_loss 0.7905 (0.6457) lr 1.9980e-03 eta 0:31:24
epoch [3/50] batch [240/246] time 0.181 (0.163) data 0.000 (0.001) loss 1.2934 (1.7568) ce_loss 0.8140 (1.1730) teacher_loss 0.7729 (1.1676) loss_zs_kd 0.1817 (0.2344) loss_oracle 0.5023 (0.5657) acc 78.1250 (69.2057) kd_loss 0.4488 (0.6427) lr 1.9980e-03 eta 0:31:23
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,826
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.4%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,960
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.3%, epoch: 3 *******
******* Domain r best val test acc: 90.9%, epoch: 3 *******
******* Domain r best test acc:     90.9%, epoch: 3 *******
epoch [4/50] batch [20/246] time 0.184 (0.195) data 0.000 (0.015) loss 1.5700 (1.6692) ce_loss 1.0684 (1.0980) teacher_loss 1.0292 (1.0884) loss_zs_kd 0.1675 (0.2329) loss_oracle 0.5241 (0.5575) acc 71.8750 (71.5625) kd_loss 0.6257 (0.6497) lr 1.9921e-03 eta 0:37:28
epoch [4/50] batch [40/246] time 0.089 (0.165) data 0.000 (0.008) loss 1.7374 (1.6381) ce_loss 1.1348 (1.0709) teacher_loss 1.1532 (1.0586) loss_zs_kd 0.2287 (0.2344) loss_oracle 0.5613 (0.5561) acc 78.1250 (72.0312) kd_loss 0.6883 (0.6280) lr 1.9921e-03 eta 0:31:44
epoch [4/50] batch [60/246] time 0.104 (0.158) data 0.000 (0.005) loss 1.7616 (1.6546) ce_loss 1.2881 (1.0903) teacher_loss 1.3138 (1.0772) loss_zs_kd 0.2543 (0.2447) loss_oracle 0.4224 (0.5529) acc 62.5000 (71.0417) kd_loss 0.5979 (0.6198) lr 1.9921e-03 eta 0:30:19
epoch [4/50] batch [80/246] time 0.290 (0.157) data 0.000 (0.004) loss 1.3838 (1.6551) ce_loss 0.7524 (1.0843) teacher_loss 0.7924 (1.0762) loss_zs_kd 0.1836 (0.2456) loss_oracle 0.5730 (0.5544) acc 78.1250 (71.2891) kd_loss 0.6489 (0.6139) lr 1.9921e-03 eta 0:29:59
epoch [4/50] batch [100/246] time 0.087 (0.149) data 0.000 (0.003) loss 1.5879 (1.6641) ce_loss 1.0498 (1.0896) teacher_loss 1.0187 (1.0776) loss_zs_kd 0.2014 (0.2459) loss_oracle 0.5490 (0.5619) acc 68.7500 (71.0938) kd_loss 0.6528 (0.6227) lr 1.9921e-03 eta 0:28:22
epoch [4/50] batch [120/246] time 0.100 (0.148) data 0.000 (0.003) loss 2.2034 (1.6824) ce_loss 1.4932 (1.0952) teacher_loss 1.5002 (1.0843) loss_zs_kd 0.3106 (0.2494) loss_oracle 0.6722 (0.5731) acc 59.3750 (70.6771) kd_loss 0.6503 (0.6301) lr 1.9921e-03 eta 0:28:12
epoch [4/50] batch [140/246] time 0.091 (0.147) data 0.000 (0.002) loss 1.6792 (1.6762) ce_loss 1.0029 (1.0806) teacher_loss 0.9876 (1.0674) loss_zs_kd 0.2776 (0.2526) loss_oracle 0.6638 (0.5835) acc 71.8750 (71.0045) kd_loss 0.7026 (0.6364) lr 1.9921e-03 eta 0:28:00
epoch [4/50] batch [160/246] time 0.083 (0.150) data 0.000 (0.002) loss 1.6487 (1.6966) ce_loss 1.0801 (1.0958) teacher_loss 1.0520 (1.0831) loss_zs_kd 0.3140 (0.2626) loss_oracle 0.5653 (0.5872) acc 65.6250 (70.7422) kd_loss 0.6237 (0.6358) lr 1.9921e-03 eta 0:28:28
epoch [4/50] batch [180/246] time 0.162 (0.152) data 0.000 (0.002) loss 1.6430 (1.7095) ce_loss 0.8984 (1.1015) teacher_loss 0.9075 (1.0898) loss_zs_kd 0.1892 (0.2657) loss_oracle 0.7166 (0.5931) acc 71.8750 (70.4167) kd_loss 0.7795 (0.6399) lr 1.9921e-03 eta 0:28:52
epoch [4/50] batch [200/246] time 0.166 (0.150) data 0.001 (0.002) loss 2.2464 (1.7182) ce_loss 1.5312 (1.1068) teacher_loss 1.5478 (1.0961) loss_zs_kd 0.3699 (0.2663) loss_oracle 0.6617 (0.5955) acc 68.7500 (70.2031) kd_loss 0.6211 (0.6410) lr 1.9921e-03 eta 0:28:27
epoch [4/50] batch [220/246] time 0.156 (0.151) data 0.000 (0.002) loss 1.4126 (1.7120) ce_loss 0.6938 (1.0992) teacher_loss 0.6809 (1.0884) loss_zs_kd 0.2697 (0.2665) loss_oracle 0.7048 (0.5969) acc 78.1250 (70.2983) kd_loss 0.8380 (0.6420) lr 1.9921e-03 eta 0:28:31
epoch [4/50] batch [240/246] time 0.165 (0.152) data 0.000 (0.002) loss 1.9066 (1.7238) ce_loss 1.1846 (1.1051) teacher_loss 1.1688 (1.0948) loss_zs_kd 0.1690 (0.2680) loss_oracle 0.7209 (0.6022) acc 75.0000 (70.2734) kd_loss 0.7249 (0.6436) lr 1.9921e-03 eta 0:28:41
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,833
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.6%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      84.5%, epoch: 4 *******
******* Domain r best val test acc: 90.8%, epoch: 4 *******
******* Domain r best test acc:     90.9%, epoch: 3 *******
epoch [5/50] batch [20/246] time 0.172 (0.183) data 0.000 (0.015) loss 1.7461 (1.7820) ce_loss 1.0752 (1.1036) teacher_loss 1.0933 (1.0914) loss_zs_kd 0.2170 (0.2439) loss_oracle 0.6311 (0.6662) acc 71.8750 (71.5625) kd_loss 0.7762 (0.6999) lr 1.9823e-03 eta 0:34:29
epoch [5/50] batch [40/246] time 0.170 (0.174) data 0.000 (0.007) loss 2.2352 (1.7698) ce_loss 1.5947 (1.1077) teacher_loss 1.6055 (1.0971) loss_zs_kd 0.2937 (0.2403) loss_oracle 0.6004 (0.6486) acc 53.1250 (72.1875) kd_loss 0.6567 (0.6953) lr 1.9823e-03 eta 0:32:43
epoch [5/50] batch [60/246] time 0.168 (0.171) data 0.001 (0.005) loss 1.4173 (1.7552) ce_loss 0.7998 (1.1102) teacher_loss 0.8272 (1.0947) loss_zs_kd 0.2090 (0.2487) loss_oracle 0.5692 (0.6356) acc 78.1250 (71.4062) kd_loss 0.7357 (0.6945) lr 1.9823e-03 eta 0:32:07
epoch [5/50] batch [80/246] time 0.178 (0.170) data 0.000 (0.004) loss 1.4471 (1.7527) ce_loss 0.9365 (1.1163) teacher_loss 0.9020 (1.0974) loss_zs_kd 0.2247 (0.2512) loss_oracle 0.5226 (0.6301) acc 71.8750 (70.8203) kd_loss 0.6327 (0.6911) lr 1.9823e-03 eta 0:31:45
epoch [5/50] batch [100/246] time 0.166 (0.169) data 0.000 (0.003) loss 1.5351 (1.7378) ce_loss 0.9429 (1.1136) teacher_loss 0.9390 (1.0914) loss_zs_kd 0.4551 (0.2596) loss_oracle 0.5506 (0.6204) acc 68.7500 (70.6562) kd_loss 0.6393 (0.6825) lr 1.9823e-03 eta 0:31:40
epoch [5/50] batch [120/246] time 0.181 (0.170) data 0.000 (0.003) loss 1.4767 (1.7465) ce_loss 0.8140 (1.1289) teacher_loss 0.8492 (1.1062) loss_zs_kd 0.3166 (0.2672) loss_oracle 0.5959 (0.6136) acc 78.1250 (70.3385) kd_loss 0.6182 (0.6700) lr 1.9823e-03 eta 0:31:41
epoch [5/50] batch [140/246] time 0.086 (0.159) data 0.000 (0.002) loss 2.1522 (1.7462) ce_loss 1.6006 (1.1328) teacher_loss 1.5007 (1.1096) loss_zs_kd 0.3191 (0.2690) loss_oracle 0.6195 (0.6097) acc 62.5000 (70.4464) kd_loss 0.5169 (0.6658) lr 1.9823e-03 eta 0:29:42
epoch [5/50] batch [160/246] time 0.091 (0.158) data 0.000 (0.002) loss 1.9423 (1.7511) ce_loss 1.2852 (1.1382) teacher_loss 1.3329 (1.1160) loss_zs_kd 0.2225 (0.2699) loss_oracle 0.5872 (0.6081) acc 59.3750 (70.2148) kd_loss 0.5879 (0.6640) lr 1.9823e-03 eta 0:29:27
epoch [5/50] batch [180/246] time 0.099 (0.157) data 0.000 (0.002) loss 1.8072 (1.7456) ce_loss 1.1533 (1.1360) teacher_loss 1.1177 (1.1136) loss_zs_kd 0.2982 (0.2688) loss_oracle 0.6596 (0.6052) acc 68.7500 (70.0868) kd_loss 0.5887 (0.6612) lr 1.9823e-03 eta 0:29:12
epoch [5/50] batch [200/246] time 0.110 (0.153) data 0.000 (0.002) loss 1.6528 (1.7470) ce_loss 1.1357 (1.1403) teacher_loss 1.0186 (1.1178) loss_zs_kd 0.3544 (0.2705) loss_oracle 0.5987 (0.6022) acc 71.8750 (69.8906) kd_loss 0.6826 (0.6572) lr 1.9823e-03 eta 0:28:24
epoch [5/50] batch [220/246] time 0.304 (0.155) data 0.000 (0.002) loss 1.9615 (1.7378) ce_loss 1.4385 (1.1331) teacher_loss 1.4519 (1.1120) loss_zs_kd 0.2449 (0.2710) loss_oracle 0.4851 (0.5987) acc 65.6250 (70.0000) kd_loss 0.6335 (0.6536) lr 1.9823e-03 eta 0:28:38
epoch [5/50] batch [240/246] time 0.152 (0.156) data 0.000 (0.001) loss 1.6966 (1.7343) ce_loss 1.1211 (1.1305) teacher_loss 1.1115 (1.1098) loss_zs_kd 0.2359 (0.2722) loss_oracle 0.5615 (0.5973) acc 71.8750 (70.0130) kd_loss 0.6403 (0.6509) lr 1.9823e-03 eta 0:28:49
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,833
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,960
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
******* Domain r best val acc:      84.5%, epoch: 4 *******
******* Domain r best val test acc: 90.8%, epoch: 4 *******
******* Domain r best test acc:     90.9%, epoch: 3 *******
epoch [6/50] batch [20/246] time 0.168 (0.189) data 0.000 (0.015) loss 1.6020 (1.7537) ce_loss 1.0166 (1.1469) teacher_loss 1.1160 (1.1481) loss_zs_kd 0.2797 (0.3029) loss_oracle 0.4580 (0.5753) acc 75.0000 (72.3438) kd_loss 0.6713 (0.6494) lr 1.9686e-03 eta 0:34:46
epoch [6/50] batch [40/246] time 0.162 (0.177) data 0.000 (0.007) loss 1.8855 (1.7109) ce_loss 1.3350 (1.1119) teacher_loss 1.3214 (1.1042) loss_zs_kd 0.3016 (0.2945) loss_oracle 0.5339 (0.5772) acc 62.5000 (72.3438) kd_loss 0.6808 (0.6501) lr 1.9686e-03 eta 0:32:29
epoch [6/50] batch [60/246] time 0.149 (0.173) data 0.001 (0.005) loss 1.6696 (1.6800) ce_loss 1.0996 (1.0941) teacher_loss 1.0814 (1.0782) loss_zs_kd 0.1989 (0.2959) loss_oracle 0.5683 (0.5722) acc 78.1250 (72.5000) kd_loss 0.6214 (0.6516) lr 1.9686e-03 eta 0:31:42
epoch [6/50] batch [80/246] time 0.177 (0.172) data 0.000 (0.004) loss 1.7431 (1.6865) ce_loss 1.1143 (1.1038) teacher_loss 1.1347 (1.0840) loss_zs_kd 0.2485 (0.2910) loss_oracle 0.5835 (0.5734) acc 78.1250 (71.7578) kd_loss 0.6232 (0.6392) lr 1.9686e-03 eta 0:31:29
epoch [6/50] batch [100/246] time 0.177 (0.172) data 0.000 (0.003) loss 1.8304 (1.6724) ce_loss 1.2969 (1.0920) teacher_loss 1.2933 (1.0727) loss_zs_kd 0.2718 (0.2959) loss_oracle 0.5099 (0.5702) acc 68.7500 (72.2812) kd_loss 0.5795 (0.6264) lr 1.9686e-03 eta 0:31:27
epoch [6/50] batch [120/246] time 0.176 (0.171) data 0.000 (0.003) loss 1.4866 (1.6600) ce_loss 0.8452 (1.0727) teacher_loss 0.8795 (1.0525) loss_zs_kd 0.4199 (0.3046) loss_oracle 0.5651 (0.5771) acc 78.1250 (72.5260) kd_loss 0.5938 (0.6292) lr 1.9686e-03 eta 0:31:15
epoch [6/50] batch [140/246] time 0.179 (0.172) data 0.000 (0.002) loss 1.6505 (1.6691) ce_loss 1.0078 (1.0796) teacher_loss 1.0217 (1.0592) loss_zs_kd 0.2410 (0.3018) loss_oracle 0.6046 (0.5797) acc 65.6250 (72.1205) kd_loss 0.6982 (0.6295) lr 1.9686e-03 eta 0:31:15
epoch [6/50] batch [160/246] time 0.176 (0.171) data 0.000 (0.002) loss 1.5447 (1.6860) ce_loss 1.0713 (1.0994) teacher_loss 1.0356 (1.0786) loss_zs_kd 0.2647 (0.3024) loss_oracle 0.4826 (0.5771) acc 65.6250 (71.6016) kd_loss 0.5174 (0.6252) lr 1.9686e-03 eta 0:31:06
epoch [6/50] batch [180/246] time 0.154 (0.170) data 0.000 (0.002) loss 1.9689 (1.6790) ce_loss 1.3574 (1.0946) teacher_loss 1.3664 (1.0737) loss_zs_kd 0.3588 (0.3020) loss_oracle 0.5667 (0.5751) acc 68.7500 (71.6667) kd_loss 0.6476 (0.6249) lr 1.9686e-03 eta 0:30:53
epoch [6/50] batch [200/246] time 0.088 (0.168) data 0.000 (0.002) loss 1.4244 (1.6729) ce_loss 0.9399 (1.0884) teacher_loss 0.8980 (1.0685) loss_zs_kd 0.2279 (0.3019) loss_oracle 0.5036 (0.5741) acc 78.1250 (71.8125) kd_loss 0.3691 (0.6224) lr 1.9686e-03 eta 0:30:28
epoch [6/50] batch [220/246] time 0.085 (0.166) data 0.000 (0.002) loss 1.8575 (1.6730) ce_loss 1.2832 (1.0886) teacher_loss 1.2847 (1.0697) loss_zs_kd 0.4071 (0.3015) loss_oracle 0.5321 (0.5732) acc 68.7500 (71.6193) kd_loss 0.6724 (0.6230) lr 1.9686e-03 eta 0:30:03
epoch [6/50] batch [240/246] time 0.164 (0.166) data 0.000 (0.001) loss 1.6534 (1.6704) ce_loss 1.1436 (1.0869) teacher_loss 1.1129 (1.0677) loss_zs_kd 0.1950 (0.2985) loss_oracle 0.5210 (0.5728) acc 68.7500 (71.6016) kd_loss 0.7291 (0.6256) lr 1.9686e-03 eta 0:29:53
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,838
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,961
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.6%, epoch: 6 *******
******* Domain r best val test acc: 90.9%, epoch: 6 *******
******* Domain r best test acc:     90.9%, epoch: 6 *******
epoch [7/50] batch [20/246] time 0.190 (0.204) data 0.000 (0.017) loss 1.8981 (1.7767) ce_loss 1.3828 (1.1900) teacher_loss 1.3270 (1.1699) loss_zs_kd 0.3034 (0.2870) loss_oracle 0.5407 (0.5781) acc 56.2500 (68.4375) kd_loss 0.6793 (0.6881) lr 1.9511e-03 eta 0:36:43
epoch [7/50] batch [40/246] time 0.178 (0.175) data 0.000 (0.009) loss 1.4002 (1.7056) ce_loss 0.7065 (1.0987) teacher_loss 0.7378 (1.0883) loss_zs_kd 0.2504 (0.2943) loss_oracle 0.6374 (0.5879) acc 78.1250 (71.1719) kd_loss 0.7731 (0.6988) lr 1.9511e-03 eta 0:31:29
epoch [7/50] batch [60/246] time 0.166 (0.172) data 0.001 (0.006) loss 1.1480 (1.6990) ce_loss 0.5654 (1.0843) teacher_loss 0.5472 (1.0762) loss_zs_kd 0.2810 (0.3037) loss_oracle 0.5727 (0.5924) acc 87.5000 (71.4062) kd_loss 0.8117 (0.6861) lr 1.9511e-03 eta 0:30:51
epoch [7/50] batch [80/246] time 0.174 (0.169) data 0.000 (0.004) loss 1.5875 (1.7044) ce_loss 0.9844 (1.0886) teacher_loss 0.9412 (1.0793) loss_zs_kd 0.2553 (0.3064) loss_oracle 0.6208 (0.5945) acc 71.8750 (71.0547) kd_loss 0.7265 (0.6821) lr 1.9511e-03 eta 0:30:15
epoch [7/50] batch [100/246] time 0.158 (0.168) data 0.000 (0.004) loss 1.5466 (1.7073) ce_loss 0.8555 (1.0881) teacher_loss 0.8758 (1.0764) loss_zs_kd 0.2582 (0.3078) loss_oracle 0.6449 (0.6001) acc 78.1250 (71.0625) kd_loss 0.7095 (0.6834) lr 1.9511e-03 eta 0:29:58
epoch [7/50] batch [120/246] time 0.150 (0.167) data 0.000 (0.003) loss 1.2683 (1.6880) ce_loss 0.6460 (1.0668) teacher_loss 0.6233 (1.0544) loss_zs_kd 0.3581 (0.3059) loss_oracle 0.6092 (0.6030) acc 81.2500 (71.9271) kd_loss 0.7548 (0.6903) lr 1.9511e-03 eta 0:29:46
epoch [7/50] batch [140/246] time 0.147 (0.165) data 0.000 (0.003) loss 1.1672 (1.6867) ce_loss 0.5044 (1.0631) teacher_loss 0.5096 (1.0513) loss_zs_kd 0.1577 (0.3046) loss_oracle 0.6418 (0.6050) acc 87.5000 (72.1652) kd_loss 0.6696 (0.6885) lr 1.9511e-03 eta 0:29:28
epoch [7/50] batch [160/246] time 0.149 (0.164) data 0.000 (0.002) loss 1.9851 (1.7058) ce_loss 1.4014 (1.0804) teacher_loss 1.3793 (1.0679) loss_zs_kd 0.3992 (0.3041) loss_oracle 0.5659 (0.6075) acc 59.3750 (71.7578) kd_loss 0.5909 (0.6866) lr 1.9511e-03 eta 0:29:04
epoch [7/50] batch [180/246] time 0.173 (0.163) data 0.000 (0.002) loss 1.7936 (1.7050) ce_loss 1.2480 (1.0827) teacher_loss 1.2140 (1.0698) loss_zs_kd 0.3098 (0.3013) loss_oracle 0.5486 (0.6051) acc 62.5000 (71.5972) kd_loss 0.7037 (0.6832) lr 1.9511e-03 eta 0:28:57
epoch [7/50] batch [200/246] time 0.157 (0.163) data 0.000 (0.002) loss 1.3902 (1.7015) ce_loss 0.7271 (1.0815) teacher_loss 0.7303 (1.0689) loss_zs_kd 0.3240 (0.2977) loss_oracle 0.6275 (0.6029) acc 75.0000 (71.5625) kd_loss 0.6365 (0.6776) lr 1.9511e-03 eta 0:28:48
epoch [7/50] batch [220/246] time 0.158 (0.162) data 0.000 (0.002) loss 2.0104 (1.6964) ce_loss 1.4668 (1.0806) teacher_loss 1.3646 (1.0673) loss_zs_kd 0.2945 (0.2961) loss_oracle 0.6163 (0.5996) acc 65.6250 (71.5199) kd_loss 0.7308 (0.6731) lr 1.9511e-03 eta 0:28:39
epoch [7/50] batch [240/246] time 0.165 (0.162) data 0.000 (0.002) loss 1.3802 (1.6899) ce_loss 0.8740 (1.0789) teacher_loss 0.7790 (1.0642) loss_zs_kd 0.2879 (0.2970) loss_oracle 0.5724 (0.5960) acc 81.2500 (71.4714) kd_loss 0.6553 (0.6688) lr 1.9511e-03 eta 0:28:32
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,842
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
******* Domain r best val acc:      84.7%, epoch: 7 *******
******* Domain r best val test acc: 90.9%, epoch: 7 *******
******* Domain r best test acc:     90.9%, epoch: 6 *******
epoch [8/50] batch [20/246] time 0.101 (0.135) data 0.000 (0.015) loss 1.6208 (1.6549) ce_loss 1.1123 (1.0999) teacher_loss 1.0498 (1.0769) loss_zs_kd 0.4154 (0.3141) loss_oracle 0.5295 (0.5466) acc 68.7500 (70.9375) kd_loss 0.5297 (0.6314) lr 1.9298e-03 eta 0:23:43
epoch [8/50] batch [40/246] time 0.218 (0.144) data 0.000 (0.008) loss 1.6833 (1.6795) ce_loss 1.1143 (1.1020) teacher_loss 1.0900 (1.0830) loss_zs_kd 0.3319 (0.3152) loss_oracle 0.5601 (0.5649) acc 68.7500 (71.1719) kd_loss 0.6765 (0.6362) lr 1.9298e-03 eta 0:25:19
epoch [8/50] batch [60/246] time 0.084 (0.152) data 0.001 (0.005) loss 1.8866 (1.6670) ce_loss 1.2783 (1.0825) teacher_loss 1.2736 (1.0632) loss_zs_kd 0.3930 (0.3161) loss_oracle 0.5737 (0.5722) acc 65.6250 (71.7708) kd_loss 0.7326 (0.6493) lr 1.9298e-03 eta 0:26:35
epoch [8/50] batch [80/246] time 0.084 (0.156) data 0.000 (0.004) loss 1.2411 (1.6685) ce_loss 0.6353 (1.0768) teacher_loss 0.6576 (1.0569) loss_zs_kd 0.1893 (0.3125) loss_oracle 0.5645 (0.5804) acc 81.2500 (72.0703) kd_loss 0.6086 (0.6464) lr 1.9298e-03 eta 0:27:13
epoch [8/50] batch [100/246] time 0.092 (0.158) data 0.000 (0.003) loss 1.6972 (1.6925) ce_loss 1.0029 (1.0946) teacher_loss 0.9916 (1.0747) loss_zs_kd 0.4751 (0.3135) loss_oracle 0.6581 (0.5865) acc 71.8750 (71.5000) kd_loss 0.7288 (0.6524) lr 1.9298e-03 eta 0:27:38
epoch [8/50] batch [120/246] time 0.164 (0.157) data 0.000 (0.003) loss 1.9693 (1.6866) ce_loss 1.4072 (1.0854) teacher_loss 1.3451 (1.0682) loss_zs_kd 0.3211 (0.3126) loss_oracle 0.5921 (0.5871) acc 62.5000 (71.8750) kd_loss 0.6181 (0.6542) lr 1.9298e-03 eta 0:27:26
epoch [8/50] batch [140/246] time 0.174 (0.159) data 0.000 (0.002) loss 1.6620 (1.6939) ce_loss 1.0732 (1.0932) teacher_loss 1.0429 (1.0754) loss_zs_kd 0.2536 (0.3123) loss_oracle 0.5937 (0.5872) acc 68.7500 (71.6964) kd_loss 0.6597 (0.6533) lr 1.9298e-03 eta 0:27:40
epoch [8/50] batch [160/246] time 0.150 (0.159) data 0.000 (0.002) loss 2.0116 (1.6929) ce_loss 1.3311 (1.0955) teacher_loss 1.4436 (1.0772) loss_zs_kd 0.3902 (0.3122) loss_oracle 0.5289 (0.5845) acc 62.5000 (71.5820) kd_loss 0.5959 (0.6512) lr 1.9298e-03 eta 0:27:31
epoch [8/50] batch [180/246] time 0.154 (0.158) data 0.000 (0.002) loss 1.9674 (1.6831) ce_loss 1.3799 (1.0898) teacher_loss 1.4469 (1.0727) loss_zs_kd 0.3059 (0.3102) loss_oracle 0.4899 (0.5794) acc 62.5000 (71.6146) kd_loss 0.5187 (0.6459) lr 1.9298e-03 eta 0:27:20
epoch [8/50] batch [200/246] time 0.149 (0.157) data 0.000 (0.002) loss 1.5771 (1.6840) ce_loss 0.9863 (1.0919) teacher_loss 0.8933 (1.0745) loss_zs_kd 0.3200 (0.3101) loss_oracle 0.6518 (0.5785) acc 75.0000 (71.5469) kd_loss 0.6725 (0.6444) lr 1.9298e-03 eta 0:27:10
epoch [8/50] batch [220/246] time 0.146 (0.157) data 0.000 (0.002) loss 1.5137 (1.6846) ce_loss 1.0371 (1.0944) teacher_loss 0.9463 (1.0765) loss_zs_kd 0.2166 (0.3119) loss_oracle 0.5457 (0.5769) acc 75.0000 (71.3920) kd_loss 0.8961 (0.6437) lr 1.9298e-03 eta 0:27:06
epoch [8/50] batch [240/246] time 0.152 (0.157) data 0.000 (0.002) loss 1.4318 (1.6837) ce_loss 0.8784 (1.0941) teacher_loss 0.8703 (1.0764) loss_zs_kd 0.3963 (0.3127) loss_oracle 0.5219 (0.5760) acc 78.1250 (71.3151) kd_loss 0.5724 (0.6441) lr 1.9298e-03 eta 0:26:58
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,840
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      84.7%, epoch: 7 *******
******* Domain r best val test acc: 90.9%, epoch: 7 *******
******* Domain r best test acc:     90.9%, epoch: 6 *******
epoch [9/50] batch [20/246] time 0.164 (0.174) data 0.000 (0.014) loss 1.3269 (1.6745) ce_loss 0.7388 (1.1065) teacher_loss 0.7410 (1.0864) loss_zs_kd 0.3533 (0.3169) loss_oracle 0.5506 (0.5564) acc 81.2500 (71.2500) kd_loss 0.6695 (0.6363) lr 1.9048e-03 eta 0:29:58
epoch [9/50] batch [40/246] time 0.147 (0.164) data 0.000 (0.007) loss 1.9594 (1.6994) ce_loss 1.3105 (1.1228) teacher_loss 1.3129 (1.0955) loss_zs_kd 0.2406 (0.3255) loss_oracle 0.6224 (0.5713) acc 68.7500 (70.2344) kd_loss 0.6505 (0.6626) lr 1.9048e-03 eta 0:28:05
epoch [9/50] batch [60/246] time 0.147 (0.159) data 0.000 (0.005) loss 1.8660 (1.7003) ce_loss 1.2891 (1.1272) teacher_loss 1.2191 (1.0961) loss_zs_kd 0.4045 (0.3274) loss_oracle 0.6064 (0.5715) acc 75.0000 (70.7292) kd_loss 0.6141 (0.6557) lr 1.9048e-03 eta 0:27:17
epoch [9/50] batch [80/246] time 0.160 (0.159) data 0.000 (0.004) loss 1.9176 (1.7074) ce_loss 1.2051 (1.1290) teacher_loss 1.2181 (1.1003) loss_zs_kd 0.3834 (0.3231) loss_oracle 0.6611 (0.5748) acc 65.6250 (70.5469) kd_loss 0.5876 (0.6509) lr 1.9048e-03 eta 0:27:05
epoch [9/50] batch [100/246] time 0.405 (0.153) data 0.000 (0.003) loss 1.3257 (1.6845) ce_loss 0.6699 (1.1079) teacher_loss 0.6766 (1.0793) loss_zs_kd 0.2130 (0.3145) loss_oracle 0.6278 (0.5738) acc 84.3750 (70.9688) kd_loss 0.6052 (0.6446) lr 1.9048e-03 eta 0:26:10
epoch [9/50] batch [120/246] time 0.097 (0.156) data 0.000 (0.003) loss 1.7135 (1.7120) ce_loss 1.1230 (1.1342) teacher_loss 1.1104 (1.1073) loss_zs_kd 0.2461 (0.3174) loss_oracle 0.5785 (0.5730) acc 68.7500 (70.3385) kd_loss 0.7233 (0.6456) lr 1.9048e-03 eta 0:26:31
epoch [9/50] batch [140/246] time 0.092 (0.153) data 0.000 (0.002) loss 2.0333 (1.7161) ce_loss 1.3779 (1.1390) teacher_loss 1.3943 (1.1112) loss_zs_kd 0.2744 (0.3181) loss_oracle 0.6116 (0.5731) acc 65.6250 (69.9554) kd_loss 0.6940 (0.6474) lr 1.9048e-03 eta 0:25:54
epoch [9/50] batch [160/246] time 0.373 (0.148) data 0.000 (0.002) loss 1.6707 (1.7166) ce_loss 1.1035 (1.1364) teacher_loss 1.1065 (1.1099) loss_zs_kd 0.2808 (0.3144) loss_oracle 0.5361 (0.5752) acc 71.8750 (69.9219) kd_loss 0.6859 (0.6513) lr 1.9048e-03 eta 0:25:06
epoch [9/50] batch [180/246] time 0.091 (0.149) data 0.000 (0.002) loss 1.6478 (1.7129) ce_loss 1.0488 (1.1310) teacher_loss 1.0682 (1.1069) loss_zs_kd 0.2622 (0.3121) loss_oracle 0.5534 (0.5748) acc 68.7500 (70.1215) kd_loss 0.6241 (0.6490) lr 1.9048e-03 eta 0:25:07
epoch [9/50] batch [200/246] time 0.313 (0.152) data 0.000 (0.002) loss 1.7701 (1.7134) ce_loss 1.1143 (1.1297) teacher_loss 1.0617 (1.1064) loss_zs_kd 0.3136 (0.3090) loss_oracle 0.6770 (0.5761) acc 62.5000 (70.1875) kd_loss 0.6251 (0.6478) lr 1.9048e-03 eta 0:25:42
epoch [9/50] batch [220/246] time 0.425 (0.154) data 0.000 (0.002) loss 1.5685 (1.7085) ce_loss 0.9819 (1.1241) teacher_loss 0.9784 (1.1007) loss_zs_kd 0.3123 (0.3103) loss_oracle 0.5588 (0.5768) acc 78.1250 (70.3977) kd_loss 0.7257 (0.6464) lr 1.9048e-03 eta 0:25:56
epoch [9/50] batch [240/246] time 0.092 (0.153) data 0.000 (0.001) loss 1.5838 (1.7098) ce_loss 0.9502 (1.1238) teacher_loss 0.9589 (1.1009) loss_zs_kd 0.3031 (0.3108) loss_oracle 0.5946 (0.5779) acc 78.1250 (70.3906) kd_loss 0.6893 (0.6465) lr 1.9048e-03 eta 0:25:49
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,842
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,963
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.7%, epoch: 7 *******
******* Domain r best val test acc: 90.9%, epoch: 7 *******
******* Domain r best test acc:     91.0%, epoch: 9 *******
epoch [10/50] batch [20/246] time 0.178 (0.186) data 0.000 (0.017) loss 1.5922 (1.7358) ce_loss 1.0605 (1.1446) teacher_loss 0.9229 (1.1113) loss_zs_kd 0.2341 (0.3258) loss_oracle 0.6459 (0.5920) acc 65.6250 (70.4688) kd_loss 0.6402 (0.6662) lr 1.8763e-03 eta 0:31:14
epoch [10/50] batch [40/246] time 0.161 (0.175) data 0.000 (0.008) loss 1.9135 (1.7224) ce_loss 1.4316 (1.1248) teacher_loss 1.3229 (1.0950) loss_zs_kd 0.2778 (0.3120) loss_oracle 0.5629 (0.5962) acc 68.7500 (69.9219) kd_loss 0.6389 (0.6594) lr 1.8763e-03 eta 0:29:22
epoch [10/50] batch [60/246] time 0.160 (0.172) data 0.000 (0.006) loss 1.4375 (1.6849) ce_loss 0.8472 (1.0826) teacher_loss 0.8601 (1.0592) loss_zs_kd 0.2705 (0.3087) loss_oracle 0.5503 (0.5949) acc 71.8750 (70.2604) kd_loss 0.5562 (0.6659) lr 1.8763e-03 eta 0:28:46
epoch [10/50] batch [80/246] time 0.178 (0.171) data 0.000 (0.004) loss 1.7991 (1.6744) ce_loss 1.2432 (1.0824) teacher_loss 1.2408 (1.0551) loss_zs_kd 0.4977 (0.3153) loss_oracle 0.5085 (0.5877) acc 56.2500 (70.6250) kd_loss 0.5887 (0.6628) lr 1.8763e-03 eta 0:28:28
epoch [10/50] batch [100/246] time 0.173 (0.170) data 0.000 (0.003) loss 1.9970 (1.6846) ce_loss 1.3779 (1.0904) teacher_loss 1.3844 (1.0654) loss_zs_kd 0.2905 (0.3211) loss_oracle 0.5835 (0.5870) acc 68.7500 (70.4375) kd_loss 0.7594 (0.6621) lr 1.8763e-03 eta 0:28:12
epoch [10/50] batch [120/246] time 0.149 (0.168) data 0.000 (0.003) loss 2.3131 (1.7059) ce_loss 1.8262 (1.1060) teacher_loss 1.7102 (1.0833) loss_zs_kd 0.2818 (0.3230) loss_oracle 0.5747 (0.5902) acc 65.6250 (70.5469) kd_loss 0.7239 (0.6662) lr 1.8763e-03 eta 0:27:58
epoch [10/50] batch [140/246] time 0.156 (0.167) data 0.000 (0.003) loss 1.3626 (1.7122) ce_loss 0.7168 (1.1113) teacher_loss 0.7025 (1.0884) loss_zs_kd 0.2756 (0.3200) loss_oracle 0.6326 (0.5918) acc 81.2500 (70.2455) kd_loss 0.7003 (0.6708) lr 1.8763e-03 eta 0:27:45
epoch [10/50] batch [160/246] time 0.173 (0.166) data 0.000 (0.002) loss 1.9039 (1.7160) ce_loss 1.2822 (1.1134) teacher_loss 1.2953 (1.0918) loss_zs_kd 0.3400 (0.3189) loss_oracle 0.5746 (0.5923) acc 65.6250 (70.1953) kd_loss 0.6663 (0.6714) lr 1.8763e-03 eta 0:27:29
epoch [10/50] batch [180/246] time 0.099 (0.163) data 0.000 (0.002) loss 1.4540 (1.7210) ce_loss 0.9297 (1.1164) teacher_loss 0.9190 (1.0978) loss_zs_kd 0.1615 (0.3185) loss_oracle 0.5188 (0.5913) acc 75.0000 (70.3125) kd_loss 0.6059 (0.6720) lr 1.8763e-03 eta 0:26:52
epoch [10/50] batch [200/246] time 0.093 (0.158) data 0.000 (0.002) loss 1.5157 (1.7146) ce_loss 0.9941 (1.1132) teacher_loss 0.9248 (1.0945) loss_zs_kd 0.2945 (0.3158) loss_oracle 0.5614 (0.5885) acc 75.0000 (70.4531) kd_loss 0.5482 (0.6701) lr 1.8763e-03 eta 0:26:02
epoch [10/50] batch [220/246] time 0.084 (0.156) data 0.000 (0.002) loss 1.9649 (1.7037) ce_loss 1.4014 (1.1067) teacher_loss 1.3492 (1.0861) loss_zs_kd 0.4936 (0.3147) loss_oracle 0.5663 (0.5861) acc 59.3750 (70.5966) kd_loss 0.6848 (0.6680) lr 1.8763e-03 eta 0:25:43
epoch [10/50] batch [240/246] time 0.085 (0.156) data 0.000 (0.002) loss 1.2361 (1.6970) ce_loss 0.6528 (1.1043) teacher_loss 0.5886 (1.0814) loss_zs_kd 0.2620 (0.3164) loss_oracle 0.6213 (0.5839) acc 81.2500 (70.6120) kd_loss 0.6367 (0.6658) lr 1.8763e-03 eta 0:25:34
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,843
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,966
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.8%, epoch: 10 *******
******* Domain r best val test acc: 91.0%, epoch: 10 *******
******* Domain r best test acc:     91.0%, epoch: 10 *******
epoch [11/50] batch [20/246] time 0.091 (0.133) data 0.000 (0.017) loss 1.3267 (1.7031) ce_loss 0.6812 (1.1101) teacher_loss 0.6445 (1.0842) loss_zs_kd 0.5985 (0.3493) loss_oracle 0.6223 (0.5840) acc 81.2500 (70.6250) kd_loss 0.6799 (0.6645) lr 1.8443e-03 eta 0:21:46
epoch [11/50] batch [40/246] time 0.161 (0.141) data 0.000 (0.008) loss 1.6475 (1.6687) ce_loss 1.1143 (1.0825) teacher_loss 1.0090 (1.0502) loss_zs_kd 0.3552 (0.3355) loss_oracle 0.6029 (0.5849) acc 75.0000 (71.7188) kd_loss 0.5736 (0.6465) lr 1.8443e-03 eta 0:23:05
epoch [11/50] batch [60/246] time 0.179 (0.151) data 0.000 (0.006) loss 1.6988 (1.6642) ce_loss 1.0752 (1.0781) teacher_loss 0.9944 (1.0430) loss_zs_kd 0.4028 (0.3396) loss_oracle 0.6641 (0.5873) acc 68.7500 (71.0938) kd_loss 0.7372 (0.6505) lr 1.8443e-03 eta 0:24:32
epoch [11/50] batch [80/246] time 0.163 (0.156) data 0.000 (0.004) loss 1.4676 (1.6573) ce_loss 0.9116 (1.0711) teacher_loss 0.8979 (1.0341) loss_zs_kd 0.2989 (0.3368) loss_oracle 0.5398 (0.5896) acc 81.2500 (71.3281) kd_loss 0.5359 (0.6512) lr 1.8443e-03 eta 0:25:20
epoch [11/50] batch [100/246] time 0.171 (0.159) data 0.000 (0.003) loss 1.8205 (1.6718) ce_loss 1.1992 (1.0833) teacher_loss 1.2346 (1.0486) loss_zs_kd 0.3142 (0.3418) loss_oracle 0.5544 (0.5891) acc 68.7500 (70.9062) kd_loss 0.6168 (0.6443) lr 1.8443e-03 eta 0:25:51
epoch [11/50] batch [120/246] time 0.171 (0.160) data 0.000 (0.003) loss 1.3745 (1.6499) ce_loss 0.7422 (1.0658) teacher_loss 0.7283 (1.0302) loss_zs_kd 0.2997 (0.3402) loss_oracle 0.6163 (0.5857) acc 78.1250 (71.5104) kd_loss 0.5406 (0.6365) lr 1.8443e-03 eta 0:25:59
epoch [11/50] batch [140/246] time 0.164 (0.161) data 0.000 (0.003) loss 1.6681 (1.6576) ce_loss 1.0068 (1.0711) teacher_loss 1.0176 (1.0376) loss_zs_kd 0.3231 (0.3429) loss_oracle 0.6182 (0.5857) acc 81.2500 (71.4062) kd_loss 0.6805 (0.6424) lr 1.8443e-03 eta 0:25:58
epoch [11/50] batch [160/246] time 0.184 (0.161) data 0.000 (0.002) loss 1.9568 (1.6571) ce_loss 1.3887 (1.0703) teacher_loss 1.3352 (1.0389) loss_zs_kd 0.2952 (0.3400) loss_oracle 0.5921 (0.5841) acc 65.6250 (71.3281) kd_loss 0.6565 (0.6457) lr 1.8443e-03 eta 0:25:58
epoch [11/50] batch [180/246] time 0.190 (0.163) data 0.000 (0.002) loss 1.6468 (1.6484) ce_loss 0.9844 (1.0616) teacher_loss 0.9636 (1.0299) loss_zs_kd 0.2790 (0.3368) loss_oracle 0.6553 (0.5848) acc 65.6250 (71.4931) kd_loss 0.7190 (0.6432) lr 1.8443e-03 eta 0:26:09
epoch [11/50] batch [200/246] time 0.176 (0.164) data 0.000 (0.002) loss 1.5780 (1.6490) ce_loss 1.0020 (1.0625) teacher_loss 0.9955 (1.0333) loss_zs_kd 0.1982 (0.3327) loss_oracle 0.5626 (0.5824) acc 68.7500 (71.5156) kd_loss 0.6318 (0.6395) lr 1.8443e-03 eta 0:26:18
epoch [11/50] batch [220/246] time 0.186 (0.165) data 0.000 (0.002) loss 1.5333 (1.6381) ce_loss 1.0225 (1.0534) teacher_loss 0.8681 (1.0236) loss_zs_kd 0.3349 (0.3312) loss_oracle 0.6318 (0.5813) acc 68.7500 (71.8182) kd_loss 0.5791 (0.6356) lr 1.8443e-03 eta 0:26:25
epoch [11/50] batch [240/246] time 0.092 (0.160) data 0.000 (0.002) loss 1.5166 (1.6426) ce_loss 0.8354 (1.0599) teacher_loss 0.8383 (1.0302) loss_zs_kd 0.2778 (0.3312) loss_oracle 0.6506 (0.5793) acc 81.2500 (71.7318) kd_loss 0.7893 (0.6328) lr 1.8443e-03 eta 0:25:34
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,847
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,965
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.0%
******* Domain r best val acc:      84.9%, epoch: 11 *******
******* Domain r best val test acc: 91.0%, epoch: 11 *******
******* Domain r best test acc:     91.0%, epoch: 10 *******
epoch [12/50] batch [20/246] time 0.091 (0.194) data 0.000 (0.019) loss 1.5019 (1.5553) ce_loss 0.9233 (1.0002) teacher_loss 0.8987 (0.9561) loss_zs_kd 0.2614 (0.3455) loss_oracle 0.5770 (0.5646) acc 71.8750 (73.1250) kd_loss 0.7090 (0.6249) lr 1.8090e-03 eta 0:31:00
epoch [12/50] batch [40/246] time 0.090 (0.184) data 0.000 (0.010) loss 2.1610 (1.5999) ce_loss 1.6465 (1.0410) teacher_loss 1.6130 (1.0029) loss_zs_kd 0.3669 (0.3548) loss_oracle 0.5112 (0.5615) acc 56.2500 (72.1875) kd_loss 0.6141 (0.6147) lr 1.8090e-03 eta 0:29:17
epoch [12/50] batch [60/246] time 0.164 (0.170) data 0.001 (0.007) loss 1.9733 (1.6098) ce_loss 1.4883 (1.0542) teacher_loss 1.3490 (1.0137) loss_zs_kd 0.3297 (0.3543) loss_oracle 0.5913 (0.5606) acc 56.2500 (71.0417) kd_loss 0.6640 (0.6267) lr 1.8090e-03 eta 0:26:58
epoch [12/50] batch [80/246] time 0.182 (0.172) data 0.000 (0.005) loss 1.4937 (1.6265) ce_loss 0.9048 (1.0651) teacher_loss 0.9056 (1.0254) loss_zs_kd 0.3376 (0.3534) loss_oracle 0.5543 (0.5658) acc 65.6250 (70.8984) kd_loss 0.7306 (0.6326) lr 1.8090e-03 eta 0:27:15
epoch [12/50] batch [100/246] time 0.187 (0.173) data 0.000 (0.004) loss 1.8635 (1.6028) ce_loss 1.2988 (1.0421) teacher_loss 1.2660 (1.0058) loss_zs_kd 0.3938 (0.3520) loss_oracle 0.5582 (0.5618) acc 65.6250 (71.3750) kd_loss 0.7065 (0.6311) lr 1.8090e-03 eta 0:27:26
epoch [12/50] batch [120/246] time 0.160 (0.173) data 0.000 (0.003) loss 1.1572 (1.5884) ce_loss 0.6675 (1.0285) teacher_loss 0.6490 (0.9962) loss_zs_kd 0.2265 (0.3533) loss_oracle 0.4855 (0.5569) acc 87.5000 (71.7448) kd_loss 0.5870 (0.6306) lr 1.8090e-03 eta 0:27:15
epoch [12/50] batch [140/246] time 0.179 (0.171) data 0.000 (0.003) loss 1.7982 (1.6027) ce_loss 1.3223 (1.0423) teacher_loss 1.2006 (1.0098) loss_zs_kd 0.2715 (0.3481) loss_oracle 0.5705 (0.5582) acc 75.0000 (71.6741) kd_loss 0.5467 (0.6335) lr 1.8090e-03 eta 0:26:58
epoch [12/50] batch [160/246] time 0.152 (0.170) data 0.000 (0.003) loss 1.9608 (1.6114) ce_loss 1.3916 (1.0506) teacher_loss 1.4387 (1.0194) loss_zs_kd 0.3448 (0.3436) loss_oracle 0.4876 (0.5576) acc 62.5000 (71.3477) kd_loss 0.5802 (0.6391) lr 1.8090e-03 eta 0:26:45
epoch [12/50] batch [180/246] time 0.179 (0.168) data 0.000 (0.002) loss 1.3602 (1.6174) ce_loss 0.8477 (1.0580) teacher_loss 0.8491 (1.0275) loss_zs_kd 0.2924 (0.3441) loss_oracle 0.4818 (0.5555) acc 75.0000 (71.3542) kd_loss 0.5911 (0.6379) lr 1.8090e-03 eta 0:26:25
epoch [12/50] batch [200/246] time 0.167 (0.168) data 0.000 (0.002) loss 1.5657 (1.6098) ce_loss 0.9590 (1.0514) teacher_loss 0.9505 (1.0209) loss_zs_kd 0.4763 (0.3436) loss_oracle 0.5675 (0.5544) acc 78.1250 (71.4062) kd_loss 0.7871 (0.6375) lr 1.8090e-03 eta 0:26:20
epoch [12/50] batch [220/246] time 0.175 (0.168) data 0.000 (0.002) loss 1.3569 (1.6133) ce_loss 0.8477 (1.0567) teacher_loss 0.8102 (1.0251) loss_zs_kd 0.3106 (0.3416) loss_oracle 0.5157 (0.5541) acc 78.1250 (71.3778) kd_loss 0.4574 (0.6379) lr 1.8090e-03 eta 0:26:14
epoch [12/50] batch [240/246] time 0.173 (0.168) data 0.000 (0.002) loss 1.4088 (1.6221) ce_loss 0.8926 (1.0646) teacher_loss 0.9078 (1.0339) loss_zs_kd 0.2619 (0.3417) loss_oracle 0.4748 (0.5541) acc 75.0000 (71.1979) kd_loss 0.6324 (0.6379) lr 1.8090e-03 eta 0:26:08
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,845
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,966
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.0%
******* Domain r best val acc:      84.9%, epoch: 11 *******
******* Domain r best val test acc: 91.0%, epoch: 11 *******
******* Domain r best test acc:     91.0%, epoch: 10 *******
epoch [13/50] batch [20/246] time 0.219 (0.170) data 0.000 (0.015) loss 1.5718 (1.6139) ce_loss 0.9351 (1.0437) teacher_loss 0.9519 (1.0182) loss_zs_kd 0.3726 (0.3480) loss_oracle 0.5827 (0.5609) acc 84.3750 (71.5625) kd_loss 0.7750 (0.6735) lr 1.7705e-03 eta 0:26:22
epoch [13/50] batch [40/246] time 0.094 (0.132) data 0.000 (0.008) loss 1.6239 (1.6215) ce_loss 1.0801 (1.0439) teacher_loss 1.0636 (1.0265) loss_zs_kd 0.2654 (0.3315) loss_oracle 0.5337 (0.5618) acc 78.1250 (72.1094) kd_loss 0.6769 (0.6739) lr 1.7705e-03 eta 0:20:28
epoch [13/50] batch [60/246] time 0.303 (0.145) data 0.000 (0.005) loss 1.8755 (1.6219) ce_loss 1.3730 (1.0499) teacher_loss 1.2936 (1.0296) loss_zs_kd 0.3214 (0.3300) loss_oracle 0.5497 (0.5593) acc 62.5000 (71.8229) kd_loss 0.6495 (0.6795) lr 1.7705e-03 eta 0:22:25
epoch [13/50] batch [80/246] time 0.103 (0.151) data 0.000 (0.004) loss 1.5605 (1.6226) ce_loss 1.0186 (1.0495) teacher_loss 0.9640 (1.0348) loss_zs_kd 0.3204 (0.3313) loss_oracle 0.5645 (0.5546) acc 78.1250 (71.7969) kd_loss 0.5929 (0.6874) lr 1.7705e-03 eta 0:23:21
epoch [13/50] batch [100/246] time 0.084 (0.155) data 0.000 (0.003) loss 1.3349 (1.6186) ce_loss 0.7271 (1.0469) teacher_loss 0.7026 (1.0309) loss_zs_kd 0.4761 (0.3375) loss_oracle 0.5847 (0.5540) acc 87.5000 (72.0000) kd_loss 0.6215 (0.6877) lr 1.7705e-03 eta 0:23:57
epoch [13/50] batch [120/246] time 0.084 (0.157) data 0.000 (0.003) loss 1.2399 (1.6065) ce_loss 0.5874 (1.0314) teacher_loss 0.5971 (1.0182) loss_zs_kd 0.3461 (0.3365) loss_oracle 0.6082 (0.5546) acc 84.3750 (72.4219) kd_loss 0.7718 (0.6915) lr 1.7705e-03 eta 0:24:12
epoch [13/50] batch [140/246] time 0.151 (0.153) data 0.000 (0.002) loss 1.7243 (1.6170) ce_loss 1.0977 (1.0437) teacher_loss 1.1577 (1.0296) loss_zs_kd 0.2713 (0.3368) loss_oracle 0.5394 (0.5537) acc 75.0000 (72.1652) kd_loss 0.8365 (0.6957) lr 1.7705e-03 eta 0:23:27
epoch [13/50] batch [160/246] time 0.148 (0.153) data 0.000 (0.002) loss 2.1603 (1.6314) ce_loss 1.5635 (1.0598) teacher_loss 1.5205 (1.0423) loss_zs_kd 0.4395 (0.3386) loss_oracle 0.5958 (0.5553) acc 56.2500 (71.4648) kd_loss 0.6037 (0.6907) lr 1.7705e-03 eta 0:23:26
epoch [13/50] batch [180/246] time 0.155 (0.153) data 0.000 (0.002) loss 2.3222 (1.6345) ce_loss 1.8135 (1.0627) teacher_loss 1.7323 (1.0450) loss_zs_kd 0.2776 (0.3373) loss_oracle 0.5621 (0.5558) acc 59.3750 (71.3542) kd_loss 0.5378 (0.6924) lr 1.7705e-03 eta 0:23:22
epoch [13/50] batch [200/246] time 0.168 (0.153) data 0.000 (0.002) loss 1.9020 (1.6440) ce_loss 1.2949 (1.0690) teacher_loss 1.2372 (1.0521) loss_zs_kd 0.4379 (0.3396) loss_oracle 0.6210 (0.5579) acc 71.8750 (71.3750) kd_loss 0.7075 (0.6965) lr 1.7705e-03 eta 0:23:24
epoch [13/50] batch [220/246] time 0.145 (0.154) data 0.000 (0.002) loss 1.4191 (1.6310) ce_loss 0.9121 (1.0570) teacher_loss 0.8523 (1.0393) loss_zs_kd 0.3356 (0.3376) loss_oracle 0.5332 (0.5580) acc 81.2500 (71.7045) kd_loss 0.8542 (0.6979) lr 1.7705e-03 eta 0:23:22
epoch [13/50] batch [240/246] time 0.151 (0.154) data 0.000 (0.001) loss 1.5574 (1.6242) ce_loss 0.9761 (1.0524) teacher_loss 0.9610 (1.0331) loss_zs_kd 0.3587 (0.3358) loss_oracle 0.5605 (0.5575) acc 78.1250 (71.7839) kd_loss 0.6274 (0.6974) lr 1.7705e-03 eta 0:23:24
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,853
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.2%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,967
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.1%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      85.1%, epoch: 13 *******
******* Domain r best val test acc: 91.0%, epoch: 13 *******
******* Domain r best test acc:     91.0%, epoch: 13 *******
epoch [14/50] batch [20/246] time 0.173 (0.182) data 0.000 (0.018) loss 1.1273 (1.6451) ce_loss 0.5830 (1.0792) teacher_loss 0.5856 (1.0465) loss_zs_kd 0.2208 (0.3284) loss_oracle 0.5196 (0.5657) acc 81.2500 (70.4688) kd_loss 0.7563 (0.6891) lr 1.7290e-03 eta 0:27:34
epoch [14/50] batch [40/246] time 0.179 (0.177) data 0.000 (0.009) loss 1.9988 (1.5980) ce_loss 1.4893 (1.0302) teacher_loss 1.4821 (0.9992) loss_zs_kd 0.3134 (0.3277) loss_oracle 0.4854 (0.5660) acc 65.6250 (72.3438) kd_loss 0.5873 (0.6725) lr 1.7290e-03 eta 0:26:39
epoch [14/50] batch [60/246] time 0.174 (0.173) data 0.001 (0.006) loss 2.1566 (1.6433) ce_loss 1.7080 (1.0746) teacher_loss 1.6112 (1.0494) loss_zs_kd 0.5066 (0.3341) loss_oracle 0.4948 (0.5605) acc 56.2500 (71.5625) kd_loss 0.4771 (0.6674) lr 1.7290e-03 eta 0:26:08
epoch [14/50] batch [80/246] time 0.083 (0.159) data 0.000 (0.005) loss 1.4469 (1.6298) ce_loss 0.9009 (1.0621) teacher_loss 0.8665 (1.0415) loss_zs_kd 0.2965 (0.3276) loss_oracle 0.5508 (0.5556) acc 81.2500 (72.1484) kd_loss 0.5269 (0.6634) lr 1.7290e-03 eta 0:23:52
epoch [14/50] batch [100/246] time 0.297 (0.156) data 0.000 (0.004) loss 1.5413 (1.6334) ce_loss 0.8735 (1.0698) teacher_loss 0.8918 (1.0485) loss_zs_kd 0.4513 (0.3291) loss_oracle 0.6043 (0.5520) acc 68.7500 (71.6250) kd_loss 0.7082 (0.6615) lr 1.7290e-03 eta 0:23:22
epoch [14/50] batch [120/246] time 0.226 (0.158) data 0.000 (0.003) loss 1.3490 (1.6335) ce_loss 0.8213 (1.0734) teacher_loss 0.7791 (1.0500) loss_zs_kd 0.4093 (0.3257) loss_oracle 0.5290 (0.5509) acc 75.0000 (71.4844) kd_loss 0.6867 (0.6602) lr 1.7290e-03 eta 0:23:37
epoch [14/50] batch [140/246] time 0.107 (0.150) data 0.000 (0.003) loss 2.1789 (1.6382) ce_loss 1.6152 (1.0800) teacher_loss 1.5506 (1.0550) loss_zs_kd 0.3676 (0.3264) loss_oracle 0.5915 (0.5506) acc 62.5000 (71.4062) kd_loss 0.6513 (0.6607) lr 1.7290e-03 eta 0:22:23
epoch [14/50] batch [160/246] time 0.092 (0.152) data 0.000 (0.002) loss 1.6534 (1.6361) ce_loss 1.0342 (1.0806) teacher_loss 0.9872 (1.0548) loss_zs_kd 0.2852 (0.3259) loss_oracle 0.6377 (0.5487) acc 71.8750 (71.3477) kd_loss 0.7337 (0.6616) lr 1.7290e-03 eta 0:22:38
epoch [14/50] batch [180/246] time 0.098 (0.155) data 0.000 (0.002) loss 2.0404 (1.6310) ce_loss 1.4795 (1.0746) teacher_loss 1.5157 (1.0503) loss_zs_kd 0.3202 (0.3256) loss_oracle 0.4927 (0.5481) acc 65.6250 (71.7708) kd_loss 0.5095 (0.6598) lr 1.7290e-03 eta 0:23:01
epoch [14/50] batch [200/246] time 0.291 (0.157) data 0.000 (0.002) loss 1.5575 (1.6328) ce_loss 1.0332 (1.0760) teacher_loss 0.9653 (1.0521) loss_zs_kd 0.3761 (0.3242) loss_oracle 0.5546 (0.5483) acc 65.6250 (71.7969) kd_loss 0.7815 (0.6595) lr 1.7290e-03 eta 0:23:13
epoch [14/50] batch [220/246] time 0.094 (0.157) data 0.000 (0.002) loss 1.4548 (1.6245) ce_loss 0.8457 (1.0666) teacher_loss 0.9147 (1.0441) loss_zs_kd 0.3708 (0.3254) loss_oracle 0.5031 (0.5479) acc 71.8750 (72.0170) kd_loss 0.7354 (0.6636) lr 1.7290e-03 eta 0:23:18
epoch [14/50] batch [240/246] time 0.148 (0.157) data 0.000 (0.002) loss 1.5975 (1.6172) ce_loss 1.0732 (1.0592) teacher_loss 1.0291 (1.0369) loss_zs_kd 0.4594 (0.3275) loss_oracle 0.5225 (0.5476) acc 68.7500 (72.2135) kd_loss 0.7917 (0.6673) lr 1.7290e-03 eta 0:23:08
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,844
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.1%, epoch: 13 *******
******* Domain r best val test acc: 91.0%, epoch: 13 *******
******* Domain r best test acc:     91.0%, epoch: 13 *******
epoch [15/50] batch [20/246] time 0.149 (0.176) data 0.000 (0.014) loss 1.7254 (1.6178) ce_loss 1.0850 (1.0455) teacher_loss 1.1047 (1.0497) loss_zs_kd 0.2714 (0.3317) loss_oracle 0.5936 (0.5349) acc 65.6250 (72.1875) kd_loss 0.8816 (0.6806) lr 1.6845e-03 eta 0:25:56
epoch [15/50] batch [40/246] time 0.148 (0.168) data 0.000 (0.007) loss 1.4975 (1.6059) ce_loss 0.9385 (1.0419) teacher_loss 0.9724 (1.0436) loss_zs_kd 0.3330 (0.3283) loss_oracle 0.4917 (0.5294) acc 78.1250 (72.0312) kd_loss 0.7368 (0.6830) lr 1.6845e-03 eta 0:24:44
epoch [15/50] batch [60/246] time 0.170 (0.166) data 0.001 (0.005) loss 1.3000 (1.6147) ce_loss 0.7393 (1.0486) teacher_loss 0.7559 (1.0406) loss_zs_kd 0.3713 (0.3386) loss_oracle 0.5070 (0.5402) acc 84.3750 (72.0312) kd_loss 0.6231 (0.6739) lr 1.6845e-03 eta 0:24:19
epoch [15/50] batch [80/246] time 0.146 (0.164) data 0.000 (0.004) loss 1.3249 (1.6068) ce_loss 0.8013 (1.0428) teacher_loss 0.8026 (1.0310) loss_zs_kd 0.3312 (0.3468) loss_oracle 0.4891 (0.5411) acc 75.0000 (72.2656) kd_loss 0.8059 (0.6725) lr 1.6845e-03 eta 0:24:01
epoch [15/50] batch [100/246] time 0.150 (0.163) data 0.000 (0.003) loss 1.5270 (1.6051) ce_loss 0.8779 (1.0407) teacher_loss 0.8783 (1.0280) loss_zs_kd 0.2968 (0.3435) loss_oracle 0.6190 (0.5428) acc 81.2500 (72.3438) kd_loss 0.6467 (0.6704) lr 1.6845e-03 eta 0:23:49
epoch [15/50] batch [120/246] time 0.152 (0.163) data 0.000 (0.003) loss 2.0643 (1.6088) ce_loss 1.3701 (1.0424) teacher_loss 1.4540 (1.0269) loss_zs_kd 0.2559 (0.3427) loss_oracle 0.5847 (0.5476) acc 65.6250 (72.3177) kd_loss 0.7835 (0.6665) lr 1.6845e-03 eta 0:23:43
epoch [15/50] batch [140/246] time 0.147 (0.161) data 0.000 (0.002) loss 1.8455 (1.6225) ce_loss 1.2412 (1.0496) teacher_loss 1.2977 (1.0358) loss_zs_kd 0.3296 (0.3416) loss_oracle 0.5148 (0.5525) acc 68.7500 (72.2321) kd_loss 0.7085 (0.6660) lr 1.6845e-03 eta 0:23:26
epoch [15/50] batch [160/246] time 0.156 (0.160) data 0.000 (0.002) loss 1.8852 (1.6280) ce_loss 1.3379 (1.0596) teacher_loss 1.3008 (1.0435) loss_zs_kd 0.3490 (0.3384) loss_oracle 0.5495 (0.5507) acc 65.6250 (72.1289) kd_loss 0.6325 (0.6682) lr 1.6845e-03 eta 0:23:13
epoch [15/50] batch [180/246] time 0.170 (0.159) data 0.000 (0.002) loss 2.0165 (1.6116) ce_loss 1.3975 (1.0445) teacher_loss 1.4234 (1.0283) loss_zs_kd 0.3645 (0.3344) loss_oracle 0.5567 (0.5499) acc 56.2500 (72.3785) kd_loss 0.7095 (0.6745) lr 1.6845e-03 eta 0:23:02
epoch [15/50] batch [200/246] time 0.229 (0.156) data 0.000 (0.002) loss 1.5232 (1.6168) ce_loss 0.8789 (1.0492) teacher_loss 0.8941 (1.0333) loss_zs_kd 0.2638 (0.3326) loss_oracle 0.6028 (0.5502) acc 68.7500 (72.2500) kd_loss 0.7706 (0.6767) lr 1.6845e-03 eta 0:22:27
epoch [15/50] batch [220/246] time 0.109 (0.155) data 0.000 (0.001) loss 2.0103 (1.6215) ce_loss 1.4873 (1.0530) teacher_loss 1.4101 (1.0367) loss_zs_kd 0.3699 (0.3326) loss_oracle 0.5632 (0.5516) acc 59.3750 (72.0170) kd_loss 0.6643 (0.6760) lr 1.6845e-03 eta 0:22:18
epoch [15/50] batch [240/246] time 0.087 (0.155) data 0.000 (0.001) loss 1.3977 (1.6233) ce_loss 0.8271 (1.0563) teacher_loss 0.8270 (1.0401) loss_zs_kd 0.3234 (0.3329) loss_oracle 0.5383 (0.5499) acc 78.1250 (71.9922) kd_loss 0.6631 (0.6721) lr 1.6845e-03 eta 0:22:11
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,845
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,971
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.2%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      85.1%, epoch: 13 *******
******* Domain r best val test acc: 91.0%, epoch: 13 *******
******* Domain r best test acc:     91.1%, epoch: 15 *******
epoch [16/50] batch [20/246] time 0.100 (0.170) data 0.000 (0.016) loss 1.0306 (1.6177) ce_loss 0.4832 (1.0545) teacher_loss 0.4534 (1.0392) loss_zs_kd 0.4066 (0.3536) loss_oracle 0.5365 (0.5431) acc 90.6250 (71.5625) kd_loss 0.7401 (0.6537) lr 1.6374e-03 eta 0:24:16
epoch [16/50] batch [40/246] time 0.153 (0.152) data 0.000 (0.008) loss 1.3027 (1.6075) ce_loss 0.8247 (1.0534) teacher_loss 0.8118 (1.0368) loss_zs_kd 0.4371 (0.3540) loss_oracle 0.4472 (0.5353) acc 81.2500 (71.8750) kd_loss 0.7144 (0.6590) lr 1.6374e-03 eta 0:21:39
epoch [16/50] batch [60/246] time 0.155 (0.155) data 0.001 (0.005) loss 2.0319 (1.6190) ce_loss 1.5215 (1.0738) teacher_loss 1.4387 (1.0509) loss_zs_kd 0.3400 (0.3603) loss_oracle 0.5591 (0.5321) acc 59.3750 (71.7708) kd_loss 0.5466 (0.6469) lr 1.6374e-03 eta 0:22:05
epoch [16/50] batch [80/246] time 0.155 (0.156) data 0.000 (0.004) loss 1.7978 (1.6375) ce_loss 1.2861 (1.1006) teacher_loss 1.2949 (1.0717) loss_zs_kd 0.4836 (0.3576) loss_oracle 0.4545 (0.5301) acc 68.7500 (71.2109) kd_loss 0.7530 (0.6518) lr 1.6374e-03 eta 0:22:14
epoch [16/50] batch [100/246] time 0.153 (0.157) data 0.000 (0.003) loss 1.5580 (1.6259) ce_loss 0.9189 (1.0848) teacher_loss 0.9602 (1.0601) loss_zs_kd 0.4590 (0.3598) loss_oracle 0.5519 (0.5298) acc 78.1250 (71.7500) kd_loss 0.6121 (0.6529) lr 1.6374e-03 eta 0:22:14
epoch [16/50] batch [120/246] time 0.153 (0.156) data 0.000 (0.003) loss 1.3632 (1.6223) ce_loss 0.8794 (1.0809) teacher_loss 0.7488 (1.0546) loss_zs_kd 0.3526 (0.3585) loss_oracle 0.5791 (0.5319) acc 75.0000 (71.6406) kd_loss 0.7101 (0.6550) lr 1.6374e-03 eta 0:22:04
epoch [16/50] batch [140/246] time 0.143 (0.157) data 0.000 (0.002) loss 1.5003 (1.6284) ce_loss 0.8862 (1.0822) teacher_loss 0.8680 (1.0582) loss_zs_kd 0.2624 (0.3522) loss_oracle 0.6061 (0.5349) acc 75.0000 (71.6964) kd_loss 0.8302 (0.6604) lr 1.6374e-03 eta 0:22:09
epoch [16/50] batch [160/246] time 0.144 (0.157) data 0.000 (0.002) loss 2.1395 (1.6261) ce_loss 1.5898 (1.0797) teacher_loss 1.4709 (1.0537) loss_zs_kd 0.3751 (0.3487) loss_oracle 0.6311 (0.5375) acc 62.5000 (71.5820) kd_loss 0.7652 (0.6613) lr 1.6374e-03 eta 0:22:08
epoch [16/50] batch [180/246] time 0.150 (0.157) data 0.000 (0.002) loss 1.6775 (1.6168) ce_loss 1.1260 (1.0687) teacher_loss 1.0836 (1.0438) loss_zs_kd 0.2892 (0.3470) loss_oracle 0.5649 (0.5383) acc 75.0000 (71.9792) kd_loss 0.8028 (0.6643) lr 1.6374e-03 eta 0:22:02
epoch [16/50] batch [200/246] time 0.147 (0.157) data 0.000 (0.002) loss 1.4078 (1.6213) ce_loss 0.8110 (1.0733) teacher_loss 0.8011 (1.0494) loss_zs_kd 0.3033 (0.3493) loss_oracle 0.5763 (0.5369) acc 78.1250 (71.8750) kd_loss 0.8814 (0.6642) lr 1.6374e-03 eta 0:22:01
epoch [16/50] batch [220/246] time 0.188 (0.157) data 0.000 (0.002) loss 1.7092 (1.6155) ce_loss 1.1348 (1.0670) teacher_loss 1.0906 (1.0433) loss_zs_kd 0.3265 (0.3493) loss_oracle 0.5859 (0.5372) acc 78.1250 (72.1591) kd_loss 0.6354 (0.6630) lr 1.6374e-03 eta 0:22:00
epoch [16/50] batch [240/246] time 0.147 (0.158) data 0.000 (0.001) loss 1.6798 (1.6113) ce_loss 1.2607 (1.0644) teacher_loss 1.1383 (1.0400) loss_zs_kd 0.2478 (0.3474) loss_oracle 0.5167 (0.5366) acc 65.6250 (72.1354) kd_loss 0.7491 (0.6658) lr 1.6374e-03 eta 0:21:59
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,853
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.1%, epoch: 13 *******
******* Domain r best val test acc: 91.0%, epoch: 13 *******
******* Domain r best test acc:     91.1%, epoch: 15 *******
epoch [17/50] batch [20/246] time 0.102 (0.192) data 0.000 (0.017) loss 1.4919 (1.6252) ce_loss 0.9771 (1.0722) teacher_loss 0.9136 (1.0548) loss_zs_kd 0.1751 (0.3322) loss_oracle 0.5608 (0.5372) acc 75.0000 (72.1875) kd_loss 0.6222 (0.6641) lr 1.5878e-03 eta 0:26:38
epoch [17/50] batch [40/246] time 0.105 (0.157) data 0.000 (0.008) loss 1.1616 (1.5838) ce_loss 0.6196 (1.0495) teacher_loss 0.6040 (1.0196) loss_zs_kd 0.2525 (0.3344) loss_oracle 0.5323 (0.5308) acc 81.2500 (72.1875) kd_loss 0.7208 (0.6939) lr 1.5878e-03 eta 0:21:47
epoch [17/50] batch [60/246] time 0.333 (0.165) data 0.001 (0.006) loss 1.2388 (1.5740) ce_loss 0.7153 (1.0385) teacher_loss 0.6771 (1.0074) loss_zs_kd 0.4992 (0.3385) loss_oracle 0.5118 (0.5327) acc 81.2500 (72.5521) kd_loss 0.8537 (0.7010) lr 1.5878e-03 eta 0:22:50
epoch [17/50] batch [80/246] time 0.407 (0.169) data 0.000 (0.004) loss 1.4804 (1.5951) ce_loss 0.9395 (1.0590) teacher_loss 0.9515 (1.0322) loss_zs_kd 0.2987 (0.3354) loss_oracle 0.4990 (0.5294) acc 75.0000 (72.1094) kd_loss 0.6726 (0.7026) lr 1.5878e-03 eta 0:23:16
epoch [17/50] batch [100/246] time 0.398 (0.167) data 0.000 (0.004) loss 1.6626 (1.6021) ce_loss 1.0635 (1.0601) teacher_loss 1.0554 (1.0370) loss_zs_kd 0.2972 (0.3393) loss_oracle 0.5774 (0.5312) acc 71.8750 (72.2812) kd_loss 0.5910 (0.7008) lr 1.5878e-03 eta 0:23:03
epoch [17/50] batch [120/246] time 0.100 (0.162) data 0.000 (0.003) loss 1.3350 (1.5869) ce_loss 0.7700 (1.0449) teacher_loss 0.8157 (1.0220) loss_zs_kd 0.4353 (0.3403) loss_oracle 0.4758 (0.5309) acc 84.3750 (72.6042) kd_loss 0.6070 (0.7009) lr 1.5878e-03 eta 0:22:13
epoch [17/50] batch [140/246] time 0.151 (0.160) data 0.000 (0.003) loss 1.6716 (1.5925) ce_loss 1.0664 (1.0492) teacher_loss 1.1237 (1.0258) loss_zs_kd 0.2966 (0.3430) loss_oracle 0.5182 (0.5324) acc 71.8750 (72.6116) kd_loss 0.7321 (0.6980) lr 1.5878e-03 eta 0:21:52
epoch [17/50] batch [160/246] time 0.169 (0.159) data 0.000 (0.002) loss 1.2333 (1.5913) ce_loss 0.7319 (1.0491) teacher_loss 0.7240 (1.0257) loss_zs_kd 0.3578 (0.3427) loss_oracle 0.4735 (0.5314) acc 71.8750 (72.5000) kd_loss 0.8086 (0.6959) lr 1.5878e-03 eta 0:21:44
epoch [17/50] batch [180/246] time 0.156 (0.159) data 0.000 (0.002) loss 2.1951 (1.5952) ce_loss 1.5742 (1.0501) teacher_loss 1.5254 (1.0264) loss_zs_kd 0.4827 (0.3456) loss_oracle 0.6214 (0.5342) acc 62.5000 (72.4653) kd_loss 0.6919 (0.6952) lr 1.5878e-03 eta 0:21:38
epoch [17/50] batch [200/246] time 0.154 (0.158) data 0.000 (0.002) loss 1.5300 (1.5972) ce_loss 0.9185 (1.0484) teacher_loss 0.9224 (1.0239) loss_zs_kd 0.2531 (0.3452) loss_oracle 0.5823 (0.5388) acc 78.1250 (72.6406) kd_loss 0.6535 (0.6952) lr 1.5878e-03 eta 0:21:29
epoch [17/50] batch [220/246] time 0.156 (0.157) data 0.000 (0.002) loss 1.3955 (1.6027) ce_loss 0.8682 (1.0524) teacher_loss 0.8678 (1.0271) loss_zs_kd 0.3805 (0.3460) loss_oracle 0.4897 (0.5410) acc 78.1250 (72.5852) kd_loss 0.5374 (0.6953) lr 1.5878e-03 eta 0:21:22
epoch [17/50] batch [240/246] time 0.147 (0.157) data 0.000 (0.002) loss 1.3989 (1.5931) ce_loss 0.8062 (1.0431) teacher_loss 0.7971 (1.0179) loss_zs_kd 0.3442 (0.3490) loss_oracle 0.5674 (0.5403) acc 78.1250 (72.8255) kd_loss 0.7398 (0.6934) lr 1.5878e-03 eta 0:21:15
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,857
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.2%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.2%, epoch: 17 *******
******* Domain r best val test acc: 90.9%, epoch: 17 *******
******* Domain r best test acc:     91.1%, epoch: 15 *******
epoch [18/50] batch [20/246] time 0.154 (0.166) data 0.000 (0.014) loss 1.3538 (1.6171) ce_loss 0.8442 (1.0715) teacher_loss 0.8405 (1.0522) loss_zs_kd 0.4273 (0.3840) loss_oracle 0.4705 (0.5265) acc 84.3750 (72.0312) kd_loss 0.5755 (0.6524) lr 1.5358e-03 eta 0:22:23
epoch [18/50] batch [40/246] time 0.147 (0.163) data 0.000 (0.007) loss 1.6473 (1.6276) ce_loss 1.1445 (1.0795) teacher_loss 1.0847 (1.0613) loss_zs_kd 0.3196 (0.3654) loss_oracle 0.5306 (0.5298) acc 71.8750 (71.5625) kd_loss 0.6882 (0.6533) lr 1.5358e-03 eta 0:21:57
epoch [18/50] batch [60/246] time 0.150 (0.160) data 0.001 (0.005) loss 1.5005 (1.5816) ce_loss 0.9575 (1.0376) teacher_loss 1.0007 (1.0136) loss_zs_kd 0.3659 (0.3716) loss_oracle 0.4632 (0.5307) acc 68.7500 (73.1771) kd_loss 0.6832 (0.6423) lr 1.5358e-03 eta 0:21:28
epoch [18/50] batch [80/246] time 0.146 (0.158) data 0.000 (0.004) loss 1.8091 (1.5900) ce_loss 1.2520 (1.0502) teacher_loss 1.2137 (1.0255) loss_zs_kd 0.3467 (0.3659) loss_oracle 0.5608 (0.5280) acc 68.7500 (73.0469) kd_loss 0.6301 (0.6468) lr 1.5358e-03 eta 0:21:07
epoch [18/50] batch [100/246] time 0.171 (0.157) data 0.000 (0.003) loss 1.7728 (1.5870) ce_loss 1.1768 (1.0423) teacher_loss 1.2189 (1.0189) loss_zs_kd 0.3048 (0.3621) loss_oracle 0.5235 (0.5318) acc 68.7500 (72.9688) kd_loss 0.7715 (0.6554) lr 1.5358e-03 eta 0:20:59
epoch [18/50] batch [120/246] time 0.118 (0.150) data 0.000 (0.002) loss 1.9460 (1.6050) ce_loss 1.3379 (1.0563) teacher_loss 1.3936 (1.0338) loss_zs_kd 0.4100 (0.3655) loss_oracle 0.5113 (0.5347) acc 71.8750 (72.6823) kd_loss 0.8363 (0.6621) lr 1.5358e-03 eta 0:19:56
epoch [18/50] batch [140/246] time 0.098 (0.152) data 0.000 (0.002) loss 1.2116 (1.6012) ce_loss 0.6978 (1.0534) teacher_loss 0.6188 (1.0293) loss_zs_kd 0.3283 (0.3654) loss_oracle 0.5599 (0.5354) acc 81.2500 (72.7455) kd_loss 0.6847 (0.6607) lr 1.5358e-03 eta 0:20:13
epoch [18/50] batch [160/246] time 0.105 (0.153) data 0.000 (0.002) loss 0.9713 (1.5907) ce_loss 0.4775 (1.0433) teacher_loss 0.4444 (1.0205) loss_zs_kd 0.3049 (0.3635) loss_oracle 0.4964 (0.5338) acc 87.5000 (72.8125) kd_loss 0.6241 (0.6640) lr 1.5358e-03 eta 0:20:15
epoch [18/50] batch [180/246] time 0.096 (0.152) data 0.000 (0.002) loss 1.2468 (1.5943) ce_loss 0.7397 (1.0440) teacher_loss 0.6820 (1.0218) loss_zs_kd 0.2240 (0.3589) loss_oracle 0.5424 (0.5366) acc 78.1250 (72.5694) kd_loss 0.5279 (0.6649) lr 1.5358e-03 eta 0:20:04
epoch [18/50] batch [200/246] time 0.098 (0.154) data 0.000 (0.002) loss 1.4989 (1.6009) ce_loss 0.9351 (1.0482) teacher_loss 0.9243 (1.0250) loss_zs_kd 0.3903 (0.3590) loss_oracle 0.5355 (0.5399) acc 71.8750 (72.3125) kd_loss 0.5763 (0.6680) lr 1.5358e-03 eta 0:20:16
epoch [18/50] batch [220/246] time 0.103 (0.155) data 0.000 (0.002) loss 1.3980 (1.6060) ce_loss 0.8574 (1.0512) teacher_loss 0.8068 (1.0288) loss_zs_kd 0.2010 (0.3587) loss_oracle 0.5711 (0.5413) acc 78.1250 (72.3438) kd_loss 0.6550 (0.6725) lr 1.5358e-03 eta 0:20:26
epoch [18/50] batch [240/246] time 0.085 (0.156) data 0.000 (0.001) loss 1.2357 (1.6122) ce_loss 0.7241 (1.0569) teacher_loss 0.6667 (1.0345) loss_zs_kd 0.4099 (0.3592) loss_oracle 0.5280 (0.5418) acc 78.1250 (72.1615) kd_loss 0.7432 (0.6737) lr 1.5358e-03 eta 0:20:30
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,856
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,960
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.2%, epoch: 17 *******
******* Domain r best val test acc: 90.9%, epoch: 17 *******
******* Domain r best test acc:     91.1%, epoch: 15 *******
epoch [19/50] batch [20/246] time 0.169 (0.186) data 0.000 (0.017) loss 1.3953 (1.5488) ce_loss 0.7539 (0.9892) teacher_loss 0.7598 (0.9728) loss_zs_kd 0.3369 (0.3367) loss_oracle 0.6018 (0.5423) acc 78.1250 (73.5938) kd_loss 0.6086 (0.6837) lr 1.4818e-03 eta 0:24:21
epoch [19/50] batch [40/246] time 0.150 (0.170) data 0.000 (0.009) loss 1.5312 (1.5855) ce_loss 0.9062 (1.0154) teacher_loss 0.8994 (0.9889) loss_zs_kd 0.2909 (0.3383) loss_oracle 0.6026 (0.5628) acc 75.0000 (72.0312) kd_loss 0.7349 (0.6947) lr 1.4818e-03 eta 0:22:13
epoch [19/50] batch [60/246] time 0.152 (0.165) data 0.001 (0.006) loss 1.6879 (1.5994) ce_loss 1.0703 (1.0236) teacher_loss 1.0743 (0.9974) loss_zs_kd 0.2394 (0.3409) loss_oracle 0.5897 (0.5679) acc 71.8750 (72.0833) kd_loss 0.8109 (0.6826) lr 1.4818e-03 eta 0:21:27
epoch [19/50] batch [80/246] time 0.149 (0.161) data 0.000 (0.004) loss 1.8018 (1.5896) ce_loss 1.2686 (1.0203) teacher_loss 1.2361 (0.9939) loss_zs_kd 0.4363 (0.3489) loss_oracle 0.5220 (0.5608) acc 65.6250 (72.8125) kd_loss 0.6601 (0.6810) lr 1.4818e-03 eta 0:20:57
epoch [19/50] batch [100/246] time 0.153 (0.160) data 0.000 (0.004) loss 1.5438 (1.5962) ce_loss 1.0020 (1.0292) teacher_loss 0.9870 (0.9963) loss_zs_kd 0.3901 (0.3462) loss_oracle 0.5178 (0.5652) acc 75.0000 (72.5625) kd_loss 0.7833 (0.6798) lr 1.4818e-03 eta 0:20:40
epoch [19/50] batch [120/246] time 0.162 (0.161) data 0.000 (0.003) loss 1.5276 (1.6005) ce_loss 0.9683 (1.0348) teacher_loss 0.9349 (1.0013) loss_zs_kd 0.3972 (0.3518) loss_oracle 0.5529 (0.5640) acc 78.1250 (72.4219) kd_loss 0.5463 (0.6831) lr 1.4818e-03 eta 0:20:50
epoch [19/50] batch [140/246] time 0.150 (0.161) data 0.000 (0.003) loss 1.4733 (1.6129) ce_loss 0.9336 (1.0529) teacher_loss 0.9354 (1.0167) loss_zs_kd 0.3219 (0.3529) loss_oracle 0.5057 (0.5609) acc 81.2500 (72.0536) kd_loss 0.7368 (0.6842) lr 1.4818e-03 eta 0:20:48
epoch [19/50] batch [160/246] time 0.156 (0.162) data 0.000 (0.002) loss 1.4197 (1.6078) ce_loss 0.8330 (1.0476) teacher_loss 0.8342 (1.0148) loss_zs_kd 0.4168 (0.3531) loss_oracle 0.5438 (0.5577) acc 75.0000 (72.0703) kd_loss 0.6702 (0.6838) lr 1.4818e-03 eta 0:20:49
epoch [19/50] batch [180/246] time 0.142 (0.162) data 0.000 (0.002) loss 1.6136 (1.6085) ce_loss 1.0420 (1.0486) teacher_loss 1.0408 (1.0179) loss_zs_kd 0.5154 (0.3528) loss_oracle 0.5213 (0.5553) acc 75.0000 (72.0139) kd_loss 0.8888 (0.6815) lr 1.4818e-03 eta 0:20:48
epoch [19/50] batch [200/246] time 0.098 (0.162) data 0.000 (0.002) loss 1.5351 (1.6051) ce_loss 1.1172 (1.0489) teacher_loss 1.1099 (1.0176) loss_zs_kd 0.2767 (0.3522) loss_oracle 0.3975 (0.5523) acc 75.0000 (72.0156) kd_loss 0.6013 (0.6795) lr 1.4818e-03 eta 0:20:45
epoch [19/50] batch [220/246] time 0.178 (0.159) data 0.000 (0.002) loss 1.3109 (1.6135) ce_loss 0.7729 (1.0577) teacher_loss 0.7343 (1.0278) loss_zs_kd 0.3780 (0.3532) loss_oracle 0.5387 (0.5503) acc 78.1250 (71.8040) kd_loss 0.6269 (0.6759) lr 1.4818e-03 eta 0:20:16
epoch [19/50] batch [240/246] time 0.117 (0.159) data 0.000 (0.002) loss 1.6737 (1.6164) ce_loss 1.1318 (1.0594) teacher_loss 0.9895 (1.0306) loss_zs_kd 0.4067 (0.3550) loss_oracle 0.6435 (0.5504) acc 68.7500 (71.7708) kd_loss 0.5064 (0.6732) lr 1.4818e-03 eta 0:20:16
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,867
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.5%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,955
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.5%, epoch: 19 *******
******* Domain r best val test acc: 90.8%, epoch: 19 *******
******* Domain r best test acc:     91.1%, epoch: 15 *******
epoch [20/50] batch [20/246] time 0.092 (0.169) data 0.000 (0.018) loss 1.6671 (1.6561) ce_loss 1.0850 (1.0849) teacher_loss 1.0208 (1.0563) loss_zs_kd 0.3694 (0.3716) loss_oracle 0.6093 (0.5626) acc 75.0000 (72.5000) kd_loss 0.6491 (0.6463) lr 1.4258e-03 eta 0:21:24
epoch [20/50] batch [40/246] time 0.135 (0.158) data 0.000 (0.009) loss 1.3802 (1.6329) ce_loss 0.8340 (1.0626) teacher_loss 0.7531 (1.0383) loss_zs_kd 0.4354 (0.3607) loss_oracle 0.5836 (0.5585) acc 84.3750 (73.1250) kd_loss 0.7568 (0.6486) lr 1.4258e-03 eta 0:20:01
epoch [20/50] batch [60/246] time 0.175 (0.161) data 0.001 (0.006) loss 1.7016 (1.6352) ce_loss 1.1260 (1.0749) teacher_loss 1.0157 (1.0502) loss_zs_kd 0.4972 (0.3609) loss_oracle 0.6362 (0.5489) acc 68.7500 (72.0312) kd_loss 0.7168 (0.6462) lr 1.4258e-03 eta 0:20:19
epoch [20/50] batch [80/246] time 0.149 (0.161) data 0.000 (0.005) loss 1.4810 (1.6271) ce_loss 0.9995 (1.0722) teacher_loss 0.9950 (1.0492) loss_zs_kd 0.4098 (0.3623) loss_oracle 0.4451 (0.5416) acc 78.1250 (72.0312) kd_loss 0.6982 (0.6531) lr 1.4258e-03 eta 0:20:14
epoch [20/50] batch [100/246] time 0.150 (0.160) data 0.000 (0.004) loss 1.1736 (1.6272) ce_loss 0.6592 (1.0804) teacher_loss 0.6475 (1.0550) loss_zs_kd 0.3433 (0.3594) loss_oracle 0.4917 (0.5362) acc 87.5000 (71.9062) kd_loss 0.5700 (0.6523) lr 1.4258e-03 eta 0:20:01
epoch [20/50] batch [120/246] time 0.146 (0.158) data 0.000 (0.003) loss 1.6898 (1.6062) ce_loss 1.0898 (1.0626) teacher_loss 1.0635 (1.0375) loss_zs_kd 0.5527 (0.3610) loss_oracle 0.5710 (0.5326) acc 71.8750 (72.3958) kd_loss 0.7710 (0.6485) lr 1.4258e-03 eta 0:19:48
epoch [20/50] batch [140/246] time 0.153 (0.158) data 0.000 (0.003) loss 1.5381 (1.5970) ce_loss 1.0225 (1.0559) teacher_loss 1.0095 (1.0294) loss_zs_kd 0.3127 (0.3610) loss_oracle 0.4973 (0.5315) acc 75.0000 (72.5000) kd_loss 0.6893 (0.6466) lr 1.4258e-03 eta 0:19:40
epoch [20/50] batch [160/246] time 0.175 (0.157) data 0.000 (0.002) loss 1.0922 (1.5930) ce_loss 0.5869 (1.0476) teacher_loss 0.6271 (1.0246) loss_zs_kd 0.2944 (0.3629) loss_oracle 0.4357 (0.5321) acc 81.2500 (72.7344) kd_loss 0.6543 (0.6540) lr 1.4258e-03 eta 0:19:34
epoch [20/50] batch [180/246] time 0.151 (0.157) data 0.000 (0.002) loss 1.3159 (1.5752) ce_loss 0.8193 (1.0314) teacher_loss 0.8015 (1.0077) loss_zs_kd 0.3824 (0.3608) loss_oracle 0.4761 (0.5313) acc 78.1250 (73.1424) kd_loss 0.7490 (0.6557) lr 1.4258e-03 eta 0:19:28
epoch [20/50] batch [200/246] time 0.155 (0.157) data 0.000 (0.002) loss 1.5404 (1.5739) ce_loss 0.8584 (1.0314) teacher_loss 0.9594 (1.0080) loss_zs_kd 0.4587 (0.3640) loss_oracle 0.5351 (0.5295) acc 78.1250 (73.2656) kd_loss 0.6441 (0.6575) lr 1.4258e-03 eta 0:19:23
epoch [20/50] batch [220/246] time 0.152 (0.156) data 0.000 (0.002) loss 1.9429 (1.5727) ce_loss 1.3799 (1.0300) teacher_loss 1.3327 (1.0065) loss_zs_kd 0.3203 (0.3638) loss_oracle 0.5782 (0.5298) acc 62.5000 (72.9830) kd_loss 0.6309 (0.6591) lr 1.4258e-03 eta 0:19:16
epoch [20/50] batch [240/246] time 0.155 (0.156) data 0.000 (0.002) loss 1.6486 (1.5764) ce_loss 1.1113 (1.0337) teacher_loss 1.0188 (1.0104) loss_zs_kd 0.3269 (0.3642) loss_oracle 0.5971 (0.5296) acc 75.0000 (72.9427) kd_loss 0.5961 (0.6592) lr 1.4258e-03 eta 0:19:11
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,869
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.6%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.9%
******* Domain r best val acc:      85.5%, epoch: 20 *******
******* Domain r best val test acc: 90.9%, epoch: 20 *******
******* Domain r best test acc:     91.1%, epoch: 15 *******
epoch [21/50] batch [20/246] time 0.100 (0.152) data 0.000 (0.016) loss 1.1589 (1.5725) ce_loss 0.5259 (1.0202) teacher_loss 0.5169 (0.9809) loss_zs_kd 0.2421 (0.3769) loss_oracle 0.6178 (0.5539) acc 87.5000 (72.6562) kd_loss 0.7063 (0.6397) lr 1.3681e-03 eta 0:18:42
epoch [21/50] batch [40/246] time 0.221 (0.150) data 0.000 (0.008) loss 1.5044 (1.5928) ce_loss 0.8628 (1.0506) teacher_loss 0.8841 (1.0099) loss_zs_kd 0.4197 (0.3615) loss_oracle 0.5783 (0.5468) acc 71.8750 (72.1094) kd_loss 0.6894 (0.6540) lr 1.3681e-03 eta 0:18:18
epoch [21/50] batch [60/246] time 0.152 (0.157) data 0.001 (0.006) loss 1.5452 (1.5929) ce_loss 0.9946 (1.0449) teacher_loss 0.9979 (1.0122) loss_zs_kd 0.4435 (0.3728) loss_oracle 0.5029 (0.5434) acc 81.2500 (72.2917) kd_loss 0.5378 (0.6588) lr 1.3681e-03 eta 0:19:09
epoch [21/50] batch [80/246] time 0.117 (0.145) data 0.000 (0.004) loss 1.8336 (1.5841) ce_loss 1.2314 (1.0318) teacher_loss 1.2269 (1.0010) loss_zs_kd 0.3377 (0.3719) loss_oracle 0.5730 (0.5459) acc 68.7500 (72.7734) kd_loss 0.6025 (0.6596) lr 1.3681e-03 eta 0:17:34
epoch [21/50] batch [100/246] time 0.374 (0.153) data 0.000 (0.003) loss 1.6217 (1.5871) ce_loss 1.0645 (1.0347) teacher_loss 1.0651 (1.0028) loss_zs_kd 0.3092 (0.3730) loss_oracle 0.5257 (0.5470) acc 75.0000 (72.9062) kd_loss 0.7182 (0.6622) lr 1.3681e-03 eta 0:18:34
epoch [21/50] batch [120/246] time 0.124 (0.157) data 0.000 (0.003) loss 1.0659 (1.5976) ce_loss 0.6450 (1.0477) teacher_loss 0.5486 (1.0146) loss_zs_kd 0.3301 (0.3728) loss_oracle 0.4843 (0.5457) acc 81.2500 (72.5781) kd_loss 0.5802 (0.6589) lr 1.3681e-03 eta 0:19:01
epoch [21/50] batch [140/246] time 0.126 (0.156) data 0.000 (0.003) loss 1.2093 (1.5943) ce_loss 0.8320 (1.0450) teacher_loss 0.7628 (1.0109) loss_zs_kd 0.3684 (0.3721) loss_oracle 0.4097 (0.5462) acc 81.2500 (72.6562) kd_loss 0.6766 (0.6618) lr 1.3681e-03 eta 0:18:49
epoch [21/50] batch [160/246] time 0.094 (0.157) data 0.000 (0.002) loss 1.2980 (1.5871) ce_loss 0.6748 (1.0386) teacher_loss 0.6491 (1.0062) loss_zs_kd 0.4022 (0.3705) loss_oracle 0.6087 (0.5438) acc 81.2500 (72.7734) kd_loss 0.7107 (0.6623) lr 1.3681e-03 eta 0:18:53
epoch [21/50] batch [180/246] time 0.162 (0.156) data 0.000 (0.002) loss 1.7081 (1.5985) ce_loss 1.1982 (1.0532) teacher_loss 1.1652 (1.0209) loss_zs_kd 0.4265 (0.3683) loss_oracle 0.5002 (0.5408) acc 65.6250 (72.3785) kd_loss 0.4156 (0.6613) lr 1.3681e-03 eta 0:18:40
epoch [21/50] batch [200/246] time 0.174 (0.157) data 0.000 (0.002) loss 1.7122 (1.5979) ce_loss 1.0635 (1.0531) teacher_loss 1.0802 (1.0212) loss_zs_kd 0.4330 (0.3651) loss_oracle 0.5887 (0.5402) acc 75.0000 (72.4062) kd_loss 0.7455 (0.6612) lr 1.3681e-03 eta 0:18:46
epoch [21/50] batch [220/246] time 0.151 (0.157) data 0.000 (0.002) loss 1.4197 (1.6006) ce_loss 0.7993 (1.0571) teacher_loss 0.7932 (1.0242) loss_zs_kd 0.3721 (0.3637) loss_oracle 0.5892 (0.5400) acc 71.8750 (72.2443) kd_loss 0.6327 (0.6602) lr 1.3681e-03 eta 0:18:43
epoch [21/50] batch [240/246] time 0.155 (0.156) data 0.000 (0.002) loss 1.5211 (1.6071) ce_loss 1.0381 (1.0578) teacher_loss 0.9338 (1.0263) loss_zs_kd 0.3251 (0.3621) loss_oracle 0.5548 (0.5446) acc 71.8750 (72.1745) kd_loss 0.6234 (0.6625) lr 1.3681e-03 eta 0:18:36
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,864
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,963
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.0%
******* Domain r best val acc:      85.5%, epoch: 20 *******
******* Domain r best val test acc: 90.9%, epoch: 20 *******
******* Domain r best test acc:     91.1%, epoch: 15 *******
epoch [22/50] batch [20/246] time 0.178 (0.178) data 0.000 (0.014) loss 1.4384 (1.5782) ce_loss 0.8228 (0.9995) teacher_loss 0.8541 (0.9947) loss_zs_kd 0.2917 (0.3589) loss_oracle 0.5552 (0.5476) acc 75.0000 (74.2188) kd_loss 0.7654 (0.6670) lr 1.3090e-03 eta 0:21:05
epoch [22/50] batch [40/246] time 0.177 (0.171) data 0.000 (0.007) loss 1.7931 (1.6429) ce_loss 1.2734 (1.0734) teacher_loss 1.2359 (1.0541) loss_zs_kd 0.3795 (0.3659) loss_oracle 0.5193 (0.5522) acc 68.7500 (71.7188) kd_loss 0.5742 (0.6649) lr 1.3090e-03 eta 0:20:10
epoch [22/50] batch [60/246] time 0.156 (0.168) data 0.001 (0.005) loss 1.3884 (1.6351) ce_loss 0.8989 (1.0689) teacher_loss 0.8746 (1.0469) loss_zs_kd 0.3675 (0.3708) loss_oracle 0.4771 (0.5511) acc 75.0000 (70.9896) kd_loss 0.5484 (0.6673) lr 1.3090e-03 eta 0:19:51
epoch [22/50] batch [80/246] time 0.160 (0.168) data 0.000 (0.004) loss 1.9907 (1.6143) ce_loss 1.3262 (1.0536) teacher_loss 1.3792 (1.0291) loss_zs_kd 0.4425 (0.3687) loss_oracle 0.5673 (0.5483) acc 56.2500 (71.4062) kd_loss 0.5668 (0.6588) lr 1.3090e-03 eta 0:19:48
epoch [22/50] batch [100/246] time 0.184 (0.168) data 0.000 (0.003) loss 1.1852 (1.5984) ce_loss 0.6099 (1.0364) teacher_loss 0.6244 (1.0137) loss_zs_kd 0.2906 (0.3653) loss_oracle 0.5317 (0.5482) acc 87.5000 (71.8125) kd_loss 0.5928 (0.6642) lr 1.3090e-03 eta 0:19:45
epoch [22/50] batch [120/246] time 0.094 (0.160) data 0.000 (0.003) loss 1.6705 (1.5873) ce_loss 1.0527 (1.0291) teacher_loss 1.0606 (1.0059) loss_zs_kd 0.3473 (0.3623) loss_oracle 0.5752 (0.5452) acc 68.7500 (72.2135) kd_loss 0.7663 (0.6667) lr 1.3090e-03 eta 0:18:43
epoch [22/50] batch [140/246] time 0.105 (0.160) data 0.001 (0.002) loss 1.5370 (1.5797) ce_loss 0.9194 (1.0275) teacher_loss 0.9194 (1.0003) loss_zs_kd 0.4304 (0.3639) loss_oracle 0.5746 (0.5430) acc 81.2500 (72.3884) kd_loss 0.6291 (0.6661) lr 1.3090e-03 eta 0:18:36
epoch [22/50] batch [160/246] time 0.135 (0.161) data 0.000 (0.002) loss 1.2690 (1.5784) ce_loss 0.7627 (1.0270) teacher_loss 0.6636 (0.9987) loss_zs_kd 0.2770 (0.3564) loss_oracle 0.5777 (0.5441) acc 75.0000 (72.5586) kd_loss 0.7624 (0.6662) lr 1.3090e-03 eta 0:18:42
epoch [22/50] batch [180/246] time 0.096 (0.157) data 0.000 (0.002) loss 1.8797 (1.5786) ce_loss 1.2490 (1.0269) teacher_loss 1.1614 (0.9992) loss_zs_kd 0.4237 (0.3575) loss_oracle 0.6759 (0.5436) acc 59.3750 (72.6042) kd_loss 0.6623 (0.6661) lr 1.3090e-03 eta 0:18:09
epoch [22/50] batch [200/246] time 0.098 (0.156) data 0.000 (0.002) loss 1.5872 (1.5790) ce_loss 1.0820 (1.0282) teacher_loss 1.0673 (0.9993) loss_zs_kd 0.5074 (0.3590) loss_oracle 0.4691 (0.5439) acc 71.8750 (72.4219) kd_loss 0.4504 (0.6607) lr 1.3090e-03 eta 0:17:58
epoch [22/50] batch [220/246] time 0.368 (0.158) data 0.000 (0.002) loss 1.8337 (1.5832) ce_loss 1.2412 (1.0321) teacher_loss 1.2128 (1.0030) loss_zs_kd 0.5021 (0.3607) loss_oracle 0.5707 (0.5441) acc 68.7500 (72.4148) kd_loss 0.6531 (0.6600) lr 1.3090e-03 eta 0:18:13
epoch [22/50] batch [240/246] time 0.083 (0.158) data 0.000 (0.001) loss 1.2754 (1.5900) ce_loss 0.7061 (1.0374) teacher_loss 0.7255 (1.0079) loss_zs_kd 0.3556 (0.3630) loss_oracle 0.5144 (0.5458) acc 81.2500 (72.2656) kd_loss 0.5870 (0.6595) lr 1.3090e-03 eta 0:18:06
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,865
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,970
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.1%
******* Domain r best val acc:      85.5%, epoch: 20 *******
******* Domain r best val test acc: 90.9%, epoch: 20 *******
******* Domain r best test acc:     91.1%, epoch: 15 *******
epoch [23/50] batch [20/246] time 0.150 (0.172) data 0.000 (0.015) loss 1.4512 (1.6063) ce_loss 0.9419 (1.0407) teacher_loss 0.8944 (1.0300) loss_zs_kd 0.3163 (0.3711) loss_oracle 0.5252 (0.5392) acc 71.8750 (71.2500) kd_loss 0.6093 (0.6691) lr 1.2487e-03 eta 0:19:40
epoch [23/50] batch [40/246] time 0.151 (0.162) data 0.000 (0.007) loss 1.9489 (1.6448) ce_loss 1.3369 (1.0732) teacher_loss 1.3091 (1.0643) loss_zs_kd 0.3555 (0.3783) loss_oracle 0.6043 (0.5427) acc 62.5000 (71.0938) kd_loss 0.7072 (0.6647) lr 1.2487e-03 eta 0:18:29
epoch [23/50] batch [60/246] time 0.158 (0.160) data 0.001 (0.005) loss 1.5994 (1.6235) ce_loss 1.0264 (1.0607) teacher_loss 1.0151 (1.0432) loss_zs_kd 0.4597 (0.3803) loss_oracle 0.5384 (0.5423) acc 71.8750 (71.5625) kd_loss 0.5661 (0.6651) lr 1.2487e-03 eta 0:18:11
epoch [23/50] batch [80/246] time 0.171 (0.160) data 0.000 (0.004) loss 1.2977 (1.6446) ce_loss 0.8115 (1.0857) teacher_loss 0.7712 (1.0701) loss_zs_kd 0.3421 (0.3683) loss_oracle 0.4923 (0.5376) acc 84.3750 (70.7812) kd_loss 0.5933 (0.6631) lr 1.2487e-03 eta 0:18:09
epoch [23/50] batch [100/246] time 0.145 (0.161) data 0.000 (0.003) loss 1.4628 (1.6197) ce_loss 0.9141 (1.0653) teacher_loss 0.8846 (1.0489) loss_zs_kd 0.4153 (0.3630) loss_oracle 0.5367 (0.5345) acc 81.2500 (71.4062) kd_loss 0.7678 (0.6647) lr 1.2487e-03 eta 0:18:09
epoch [23/50] batch [120/246] time 0.151 (0.160) data 0.000 (0.003) loss 1.3325 (1.5972) ce_loss 0.8110 (1.0451) teacher_loss 0.8199 (1.0259) loss_zs_kd 0.3588 (0.3606) loss_oracle 0.4767 (0.5353) acc 78.1250 (71.8750) kd_loss 0.7459 (0.6736) lr 1.2487e-03 eta 0:18:00
epoch [23/50] batch [140/246] time 0.175 (0.159) data 0.000 (0.002) loss 1.4010 (1.5925) ce_loss 0.8110 (1.0432) teacher_loss 0.7756 (1.0205) loss_zs_kd 0.2905 (0.3621) loss_oracle 0.5964 (0.5358) acc 78.1250 (72.1875) kd_loss 0.6219 (0.6716) lr 1.2487e-03 eta 0:17:52
epoch [23/50] batch [160/246] time 0.169 (0.159) data 0.000 (0.002) loss 1.8030 (1.5876) ce_loss 1.2471 (1.0407) teacher_loss 1.2049 (1.0176) loss_zs_kd 0.3645 (0.3611) loss_oracle 0.5617 (0.5339) acc 65.6250 (72.0508) kd_loss 0.6717 (0.6719) lr 1.2487e-03 eta 0:17:52
epoch [23/50] batch [180/246] time 0.163 (0.160) data 0.000 (0.002) loss 1.4084 (1.5765) ce_loss 0.7788 (1.0311) teacher_loss 0.8349 (1.0073) loss_zs_kd 0.4145 (0.3619) loss_oracle 0.5321 (0.5330) acc 81.2500 (72.2569) kd_loss 0.6864 (0.6685) lr 1.2487e-03 eta 0:17:50
epoch [23/50] batch [200/246] time 0.175 (0.160) data 0.000 (0.002) loss 1.9187 (1.5697) ce_loss 1.3633 (1.0249) teacher_loss 1.3367 (1.0007) loss_zs_kd 0.3690 (0.3620) loss_oracle 0.5451 (0.5328) acc 59.3750 (72.4062) kd_loss 0.6546 (0.6690) lr 1.2487e-03 eta 0:17:50
epoch [23/50] batch [220/246] time 0.099 (0.158) data 0.000 (0.002) loss 1.5892 (1.5726) ce_loss 1.0986 (1.0275) teacher_loss 1.0702 (1.0041) loss_zs_kd 0.3557 (0.3645) loss_oracle 0.4834 (0.5321) acc 71.8750 (72.3153) kd_loss 0.6527 (0.6672) lr 1.2487e-03 eta 0:17:36
epoch [23/50] batch [240/246] time 0.083 (0.156) data 0.000 (0.001) loss 1.3239 (1.5747) ce_loss 0.7041 (1.0302) teacher_loss 0.7008 (1.0051) loss_zs_kd 0.2601 (0.3648) loss_oracle 0.5971 (0.5332) acc 78.1250 (72.2917) kd_loss 0.6866 (0.6678) lr 1.2487e-03 eta 0:17:13
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,869
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,962
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.0%
******* Domain r best val acc:      85.5%, epoch: 20 *******
******* Domain r best val test acc: 90.9%, epoch: 20 *******
******* Domain r best test acc:     91.1%, epoch: 15 *******
epoch [24/50] batch [20/246] time 0.106 (0.169) data 0.000 (0.017) loss 1.7086 (1.5489) ce_loss 1.0898 (0.9990) teacher_loss 1.1155 (0.9573) loss_zs_kd 0.3618 (0.4003) loss_oracle 0.5569 (0.5516) acc 78.1250 (73.9062) kd_loss 0.6742 (0.7060) lr 1.1874e-03 eta 0:18:40
epoch [24/50] batch [40/246] time 0.098 (0.151) data 0.000 (0.009) loss 1.7008 (1.5792) ce_loss 1.1123 (1.0284) teacher_loss 1.0900 (0.9946) loss_zs_kd 0.5097 (0.3985) loss_oracle 0.5598 (0.5447) acc 68.7500 (73.0469) kd_loss 0.7093 (0.6854) lr 1.1874e-03 eta 0:16:34

Loading trainer: TRIP
Loading dataset: SPG_TerraIncognita
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------------------------
Dataset    SPG_TerraIncognita
Source     ['location_100', 'location_43', 'location_46']
Target     ['location_38']
# classes  10
# train_x  10,216
# val      4,378
# test     9,736
---------  ----------------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/319] time 0.076 (0.238) data 0.000 (0.035) loss 1.4584 (2.2158) ce_loss 1.2539 (2.0156) teacher_loss 1.2543 (2.0156) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.2040 (0.2001) acc 59.3750 (37.0312) kd_loss 0.9672 (0.9474) lr 1.0000e-05 eta 1:03:04
epoch [1/50] batch [40/319] time 0.147 (0.178) data 0.000 (0.018) loss 1.7694 (2.1090) ce_loss 1.5771 (1.9126) teacher_loss 1.5755 (1.9125) loss_zs_kd 0.0015 (0.0003) loss_oracle 0.1932 (0.1963) acc 56.2500 (39.8438) kd_loss 0.9092 (0.9290) lr 1.0000e-05 eta 0:47:08
epoch [1/50] batch [60/319] time 0.157 (0.169) data 0.000 (0.012) loss 2.3766 (2.1386) ce_loss 2.1738 (1.9407) teacher_loss 2.1752 (1.9408) loss_zs_kd 0.0024 (0.0007) loss_oracle 0.2002 (0.1974) acc 31.2500 (39.2708) kd_loss 0.9495 (0.9341) lr 1.0000e-05 eta 0:44:41
epoch [1/50] batch [80/319] time 0.139 (0.161) data 0.000 (0.009) loss 2.1677 (2.1201) ce_loss 1.9727 (1.9223) teacher_loss 1.9690 (1.9222) loss_zs_kd 0.0035 (0.0014) loss_oracle 0.1969 (0.1973) acc 43.7500 (38.8281) kd_loss 0.9256 (0.9328) lr 1.0000e-05 eta 0:42:33
epoch [1/50] batch [100/319] time 0.159 (0.158) data 0.000 (0.007) loss 2.3890 (2.0816) ce_loss 2.1738 (1.8838) teacher_loss 2.1760 (1.8836) loss_zs_kd 0.0068 (0.0023) loss_oracle 0.2095 (0.1969) acc 25.0000 (39.4375) kd_loss 1.0047 (0.9305) lr 1.0000e-05 eta 0:41:40
epoch [1/50] batch [120/319] time 0.154 (0.157) data 0.000 (0.006) loss 2.0630 (2.0801) ce_loss 1.8721 (1.8820) teacher_loss 1.8736 (1.8820) loss_zs_kd 0.0055 (0.0031) loss_oracle 0.1866 (0.1966) acc 40.6250 (39.6094) kd_loss 0.8694 (0.9287) lr 1.0000e-05 eta 0:41:19
epoch [1/50] batch [140/319] time 0.166 (0.156) data 0.000 (0.005) loss 2.2385 (2.0806) ce_loss 2.0625 (1.8824) teacher_loss 2.0619 (1.8826) loss_zs_kd 0.0083 (0.0039) loss_oracle 0.1724 (0.1961) acc 37.5000 (39.5312) kd_loss 0.8187 (0.9265) lr 1.0000e-05 eta 0:41:05
epoch [1/50] batch [160/319] time 0.142 (0.155) data 0.000 (0.005) loss 2.0340 (2.0773) ce_loss 1.8389 (1.8790) teacher_loss 1.8368 (1.8792) loss_zs_kd 0.0106 (0.0049) loss_oracle 0.1918 (0.1956) acc 34.3750 (39.6484) kd_loss 0.9076 (0.9246) lr 1.0000e-05 eta 0:40:53
epoch [1/50] batch [180/319] time 0.142 (0.155) data 0.000 (0.004) loss 2.3722 (2.0746) ce_loss 2.1816 (1.8761) teacher_loss 2.1810 (1.8763) loss_zs_kd 0.0183 (0.0060) loss_oracle 0.1820 (0.1953) acc 28.1250 (39.5660) kd_loss 0.8548 (0.9231) lr 1.0000e-05 eta 0:40:45
epoch [1/50] batch [200/319] time 0.150 (0.154) data 0.000 (0.004) loss 2.2089 (2.0711) ce_loss 1.9951 (1.8722) teacher_loss 1.9937 (1.8723) loss_zs_kd 0.0186 (0.0071) loss_oracle 0.2059 (0.1952) acc 31.2500 (39.5625) kd_loss 0.9784 (0.9230) lr 1.0000e-05 eta 0:40:32
epoch [1/50] batch [220/319] time 0.154 (0.154) data 0.000 (0.003) loss 1.9521 (2.0784) ce_loss 1.7402 (1.8787) teacher_loss 1.7372 (1.8789) loss_zs_kd 0.0228 (0.0084) loss_oracle 0.2035 (0.1953) acc 40.6250 (39.1761) kd_loss 0.9453 (0.9233) lr 1.0000e-05 eta 0:40:23
epoch [1/50] batch [240/319] time 0.128 (0.154) data 0.000 (0.003) loss 2.1476 (2.0867) ce_loss 1.9443 (1.8859) teacher_loss 1.9421 (1.8861) loss_zs_kd 0.0310 (0.0097) loss_oracle 0.1900 (0.1957) acc 28.1250 (38.8411) kd_loss 0.8968 (0.9251) lr 1.0000e-05 eta 0:40:14
epoch [1/50] batch [260/319] time 0.147 (0.152) data 0.000 (0.003) loss 2.1792 (2.0854) ce_loss 1.9717 (1.8839) teacher_loss 1.9766 (1.8841) loss_zs_kd 0.0258 (0.0109) loss_oracle 0.1896 (0.1958) acc 37.5000 (38.7500) kd_loss 0.8921 (0.9252) lr 1.0000e-05 eta 0:39:44
epoch [1/50] batch [280/319] time 0.083 (0.151) data 0.000 (0.003) loss 2.2963 (2.0832) ce_loss 2.0703 (1.8810) teacher_loss 2.0843 (1.8813) loss_zs_kd 0.0348 (0.0122) loss_oracle 0.1946 (0.1958) acc 31.2500 (38.7500) kd_loss 0.9418 (0.9249) lr 1.0000e-05 eta 0:39:33
epoch [1/50] batch [300/319] time 0.192 (0.152) data 0.000 (0.003) loss 2.5332 (2.0806) ce_loss 2.3203 (1.8777) teacher_loss 2.3236 (1.8780) loss_zs_kd 0.0322 (0.0135) loss_oracle 0.1935 (0.1958) acc 28.1250 (38.6979) kd_loss 0.9110 (0.9248) lr 1.0000e-05 eta 0:39:40
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 1,748
* accuracy: 39.9%
* error: 60.1%
* macro_f1: 24.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 2,832
* accuracy: 29.1%
* error: 70.9%
* macro_f1: 11.2%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      39.9%, epoch: 1 *******
******* Domain 2 best val test acc: 29.1%, epoch: 1 *******
******* Domain 2 best test acc:     29.1%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/ana
epoch [2/50] batch [20/319] time 0.117 (0.149) data 0.000 (0.027) loss 2.2806 (2.0404) ce_loss 1.7959 (1.6333) teacher_loss 1.7909 (1.6257) loss_zs_kd 0.1437 (0.1665) loss_oracle 0.4179 (0.3314) acc 37.5000 (39.3750) kd_loss 0.9589 (0.9674) lr 2.0000e-03 eta 0:38:39
epoch [2/50] batch [40/319] time 0.150 (0.135) data 0.000 (0.014) loss 2.7915 (2.0446) ce_loss 2.0957 (1.6232) teacher_loss 2.1021 (1.6023) loss_zs_kd 0.2159 (0.1679) loss_oracle 0.5815 (0.3583) acc 28.1250 (40.7812) kd_loss 1.0057 (0.9804) lr 2.0000e-03 eta 0:35:04
epoch [2/50] batch [60/319] time 0.141 (0.136) data 0.000 (0.009) loss 2.0332 (2.0674) ce_loss 1.6025 (1.6069) teacher_loss 1.4628 (1.5787) loss_zs_kd 0.1560 (0.1652) loss_oracle 0.4924 (0.4060) acc 34.3750 (41.3021) kd_loss 1.0580 (0.9892) lr 2.0000e-03 eta 0:35:16
epoch [2/50] batch [80/319] time 0.113 (0.138) data 0.000 (0.007) loss 1.9791 (2.0422) ce_loss 1.5527 (1.5835) teacher_loss 1.4751 (1.5391) loss_zs_kd 0.2318 (0.1703) loss_oracle 0.3880 (0.4180) acc 37.5000 (42.1875) kd_loss 1.0070 (0.9962) lr 2.0000e-03 eta 0:35:39
epoch [2/50] batch [100/319] time 0.150 (0.138) data 0.000 (0.006) loss 1.9583 (2.0217) ce_loss 1.6631 (1.5823) teacher_loss 1.4508 (1.5218) loss_zs_kd 0.1782 (0.1736) loss_oracle 0.4184 (0.4132) acc 37.5000 (42.2812) kd_loss 0.9666 (1.0016) lr 2.0000e-03 eta 0:35:48
epoch [2/50] batch [120/319] time 0.173 (0.136) data 0.000 (0.005) loss 1.5836 (2.0024) ce_loss 1.2393 (1.5666) teacher_loss 1.0624 (1.4982) loss_zs_kd 0.2151 (0.1818) loss_oracle 0.4137 (0.4134) acc 56.2500 (42.3438) kd_loss 1.0712 (1.0028) lr 2.0000e-03 eta 0:35:06
epoch [2/50] batch [140/319] time 0.084 (0.140) data 0.000 (0.004) loss 2.1445 (1.9946) ce_loss 1.7061 (1.5580) teacher_loss 1.6403 (1.4895) loss_zs_kd 0.2402 (0.1884) loss_oracle 0.3842 (0.4108) acc 43.7500 (42.6562) kd_loss 1.0228 (1.0023) lr 2.0000e-03 eta 0:36:02
epoch [2/50] batch [160/319] time 0.190 (0.145) data 0.000 (0.004) loss 1.8626 (1.9733) ce_loss 1.4277 (1.5479) teacher_loss 1.3614 (1.4690) loss_zs_kd 0.1737 (0.1924) loss_oracle 0.4144 (0.4081) acc 53.1250 (43.1445) kd_loss 1.0639 (1.0060) lr 2.0000e-03 eta 0:37:18
epoch [2/50] batch [180/319] time 0.095 (0.141) data 0.000 (0.003) loss 2.1112 (1.9646) ce_loss 1.5020 (1.5444) teacher_loss 1.5304 (1.4607) loss_zs_kd 0.3875 (0.1949) loss_oracle 0.3870 (0.4064) acc 53.1250 (43.2465) kd_loss 1.0166 (1.0053) lr 2.0000e-03 eta 0:36:23
epoch [2/50] batch [200/319] time 0.130 (0.138) data 0.000 (0.003) loss 1.7817 (1.9575) ce_loss 1.3838 (1.5440) teacher_loss 1.3286 (1.4551) loss_zs_kd 0.1649 (0.1950) loss_oracle 0.3706 (0.4048) acc 53.1250 (43.3281) kd_loss 1.0342 (1.0070) lr 2.0000e-03 eta 0:35:28
epoch [2/50] batch [220/319] time 0.082 (0.136) data 0.000 (0.003) loss 2.1585 (1.9480) ce_loss 1.7910 (1.5439) teacher_loss 1.6777 (1.4479) loss_zs_kd 0.2178 (0.1977) loss_oracle 0.3719 (0.4013) acc 21.8750 (42.8693) kd_loss 0.9951 (1.0075) lr 2.0000e-03 eta 0:34:54
epoch [2/50] batch [240/319] time 0.140 (0.136) data 0.000 (0.002) loss 1.5002 (1.9340) ce_loss 1.2295 (1.5361) teacher_loss 1.0060 (1.4360) loss_zs_kd 0.2231 (0.1988) loss_oracle 0.3827 (0.3985) acc 53.1250 (43.1250) kd_loss 1.0101 (1.0074) lr 2.0000e-03 eta 0:34:52
epoch [2/50] batch [260/319] time 0.123 (0.137) data 0.000 (0.002) loss 1.6842 (1.9130) ce_loss 1.4189 (1.5240) teacher_loss 1.2253 (1.4172) loss_zs_kd 0.2033 (0.1996) loss_oracle 0.3571 (0.3960) acc 43.7500 (43.4856) kd_loss 1.0082 (1.0057) lr 2.0000e-03 eta 0:35:05
epoch [2/50] batch [280/319] time 0.117 (0.135) data 0.000 (0.002) loss 1.7796 (1.9113) ce_loss 1.3867 (1.5223) teacher_loss 1.2933 (1.4153) loss_zs_kd 0.2250 (0.2008) loss_oracle 0.3737 (0.3956) acc 43.7500 (43.4710) kd_loss 1.0376 (1.0048) lr 2.0000e-03 eta 0:34:30
epoch [2/50] batch [300/319] time 0.124 (0.134) data 0.000 (0.002) loss 1.7849 (1.9102) ce_loss 1.3955 (1.5198) teacher_loss 1.2889 (1.4163) loss_zs_kd 0.2243 (0.2035) loss_oracle 0.3839 (0.3922) acc 40.6250 (43.3542) kd_loss 0.9381 (1.0025) lr 2.0000e-03 eta 0:34:06
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,115
* accuracy: 48.3%
* error: 51.7%
* macro_f1: 34.5%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 3,608
* accuracy: 37.1%
* error: 62.9%
* macro_f1: 17.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      48.3%, epoch: 2 *******
******* Domain 2 best val test acc: 37.1%, epoch: 2 *******
******* Domain 2 best test acc:     37.1%, epoch: 2 *******
epoch [3/50] batch [20/319] time 0.199 (0.207) data 0.000 (0.032) loss 1.5790 (1.7583) ce_loss 1.0635 (1.3331) teacher_loss 1.0634 (1.2831) loss_zs_kd 0.2222 (0.2316) loss_oracle 0.4045 (0.3594) acc 53.1250 (46.7188) kd_loss 1.0058 (0.9904) lr 1.9980e-03 eta 0:52:46
epoch [3/50] batch [40/319] time 0.152 (0.167) data 0.000 (0.016) loss 1.5976 (1.7829) ce_loss 1.2881 (1.3573) teacher_loss 1.1080 (1.3040) loss_zs_kd 0.3108 (0.2431) loss_oracle 0.3342 (0.3573) acc 59.3750 (45.7031) kd_loss 0.9785 (0.9980) lr 1.9980e-03 eta 0:42:32
epoch [3/50] batch [60/319] time 0.135 (0.149) data 0.000 (0.011) loss 1.5082 (1.7709) ce_loss 1.1094 (1.3545) teacher_loss 1.0833 (1.3021) loss_zs_kd 0.2294 (0.2520) loss_oracle 0.3102 (0.3428) acc 65.6250 (46.9271) kd_loss 1.0115 (0.9936) lr 1.9980e-03 eta 0:37:54
epoch [3/50] batch [80/319] time 0.092 (0.138) data 0.000 (0.008) loss 1.6508 (1.7827) ce_loss 1.3047 (1.3666) teacher_loss 1.2277 (1.3219) loss_zs_kd 0.2094 (0.2463) loss_oracle 0.3184 (0.3377) acc 50.0000 (46.7188) kd_loss 0.9770 (0.9934) lr 1.9980e-03 eta 0:34:54
epoch [3/50] batch [100/319] time 0.137 (0.130) data 0.000 (0.007) loss 1.7545 (1.7934) ce_loss 1.2822 (1.3730) teacher_loss 1.2254 (1.3256) loss_zs_kd 0.2407 (0.2424) loss_oracle 0.4088 (0.3465) acc 53.1250 (46.6562) kd_loss 0.9503 (0.9837) lr 1.9980e-03 eta 0:33:03
epoch [3/50] batch [120/319] time 0.093 (0.129) data 0.000 (0.006) loss 1.9752 (1.8024) ce_loss 1.4756 (1.3739) teacher_loss 1.4306 (1.3270) loss_zs_kd 0.2054 (0.2398) loss_oracle 0.4420 (0.3555) acc 43.7500 (46.7708) kd_loss 1.0314 (0.9843) lr 1.9980e-03 eta 0:32:44
epoch [3/50] batch [140/319] time 0.114 (0.125) data 0.000 (0.005) loss 1.7415 (1.8077) ce_loss 1.1611 (1.3749) teacher_loss 1.1626 (1.3232) loss_zs_kd 0.1903 (0.2375) loss_oracle 0.4837 (0.3657) acc 56.2500 (46.9643) kd_loss 0.9786 (0.9829) lr 1.9980e-03 eta 0:31:39
epoch [3/50] batch [160/319] time 0.092 (0.123) data 0.000 (0.004) loss 1.8514 (1.8190) ce_loss 1.2715 (1.3745) teacher_loss 1.1809 (1.3144) loss_zs_kd 0.2603 (0.2406) loss_oracle 0.5404 (0.3843) acc 59.3750 (47.0508) kd_loss 0.9827 (0.9836) lr 1.9980e-03 eta 0:30:56
epoch [3/50] batch [180/319] time 0.127 (0.121) data 0.000 (0.004) loss 1.8147 (1.8300) ce_loss 1.3896 (1.3807) teacher_loss 1.3265 (1.3159) loss_zs_kd 0.2410 (0.2450) loss_oracle 0.3676 (0.3916) acc 46.8750 (46.5451) kd_loss 0.9763 (0.9825) lr 1.9980e-03 eta 0:30:34
epoch [3/50] batch [200/319] time 0.080 (0.120) data 0.000 (0.003) loss 1.8787 (1.8270) ce_loss 1.4355 (1.3788) teacher_loss 1.3556 (1.3145) loss_zs_kd 0.2493 (0.2450) loss_oracle 0.3984 (0.3900) acc 37.5000 (46.5938) kd_loss 1.0565 (0.9838) lr 1.9980e-03 eta 0:30:19
epoch [3/50] batch [220/319] time 0.089 (0.119) data 0.000 (0.003) loss 1.9074 (1.8223) ce_loss 1.4395 (1.3800) teacher_loss 1.3795 (1.3070) loss_zs_kd 0.2790 (0.2491) loss_oracle 0.3884 (0.3907) acc 31.2500 (46.5625) kd_loss 1.0194 (0.9849) lr 1.9980e-03 eta 0:29:56
epoch [3/50] batch [240/319] time 0.123 (0.118) data 0.000 (0.003) loss 2.2877 (1.8178) ce_loss 1.8076 (1.3790) teacher_loss 1.8158 (1.3056) loss_zs_kd 0.2933 (0.2503) loss_oracle 0.3253 (0.3871) acc 31.2500 (46.6667) kd_loss 0.9369 (0.9852) lr 1.9980e-03 eta 0:29:38
epoch [3/50] batch [260/319] time 0.139 (0.117) data 0.000 (0.003) loss 1.8694 (1.8160) ce_loss 1.3926 (1.3822) teacher_loss 1.3946 (1.3075) loss_zs_kd 0.2638 (0.2515) loss_oracle 0.3428 (0.3827) acc 46.8750 (46.7067) kd_loss 1.0829 (0.9875) lr 1.9980e-03 eta 0:29:24
epoch [3/50] batch [280/319] time 0.108 (0.116) data 0.000 (0.002) loss 1.7308 (1.8082) ce_loss 1.3926 (1.3799) teacher_loss 1.3242 (1.3053) loss_zs_kd 0.2370 (0.2538) loss_oracle 0.2880 (0.3761) acc 46.8750 (46.7076) kd_loss 1.0674 (0.9931) lr 1.9980e-03 eta 0:29:06
epoch [3/50] batch [300/319] time 0.088 (0.116) data 0.000 (0.002) loss 1.4890 (1.8052) ce_loss 1.2168 (1.3812) teacher_loss 1.0819 (1.3081) loss_zs_kd 0.1799 (0.2533) loss_oracle 0.3171 (0.3705) acc 53.1250 (46.7604) kd_loss 1.0471 (0.9963) lr 1.9980e-03 eta 0:28:58
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,147
* accuracy: 49.0%
* error: 51.0%
* macro_f1: 36.5%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,165
* accuracy: 42.8%
* error: 57.2%
* macro_f1: 19.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      49.0%, epoch: 3 *******
******* Domain 2 best val test acc: 42.8%, epoch: 3 *******
******* Domain 2 best test acc:     42.8%, epoch: 3 *******
epoch [4/50] batch [20/319] time 0.094 (0.144) data 0.000 (0.032) loss 1.8298 (1.7802) ce_loss 1.4404 (1.3764) teacher_loss 1.3654 (1.3201) loss_zs_kd 0.2555 (0.2473) loss_oracle 0.3367 (0.3364) acc 40.6250 (46.0938) kd_loss 0.9713 (1.0421) lr 1.9921e-03 eta 0:36:01
epoch [4/50] batch [40/319] time 0.094 (0.129) data 0.000 (0.016) loss 1.7430 (1.7674) ce_loss 1.2676 (1.3563) teacher_loss 1.3097 (1.3112) loss_zs_kd 0.2016 (0.2419) loss_oracle 0.3325 (0.3352) acc 50.0000 (46.1719) kd_loss 1.1070 (1.0413) lr 1.9921e-03 eta 0:32:13
epoch [4/50] batch [60/319] time 0.127 (0.123) data 0.000 (0.011) loss 1.9479 (1.7474) ce_loss 1.4824 (1.3365) teacher_loss 1.4705 (1.2858) loss_zs_kd 0.3176 (0.2499) loss_oracle 0.3185 (0.3367) acc 53.1250 (47.7083) kd_loss 1.0410 (1.0279) lr 1.9921e-03 eta 0:30:33
epoch [4/50] batch [80/319] time 0.117 (0.119) data 0.000 (0.008) loss 1.6782 (1.7422) ce_loss 1.3213 (1.3517) teacher_loss 1.2195 (1.2861) loss_zs_kd 0.2440 (0.2571) loss_oracle 0.3367 (0.3275) acc 56.2500 (47.2656) kd_loss 1.1282 (1.0382) lr 1.9921e-03 eta 0:29:33
epoch [4/50] batch [100/319] time 0.129 (0.123) data 0.000 (0.007) loss 1.7258 (1.7544) ce_loss 1.2656 (1.3587) teacher_loss 1.2919 (1.2992) loss_zs_kd 0.2620 (0.2571) loss_oracle 0.3028 (0.3266) acc 50.0000 (47.1875) kd_loss 1.0284 (1.0314) lr 1.9921e-03 eta 0:30:33
epoch [4/50] batch [120/319] time 0.134 (0.120) data 0.000 (0.005) loss 1.9629 (1.7585) ce_loss 1.4141 (1.3597) teacher_loss 1.3779 (1.2937) loss_zs_kd 0.3177 (0.2637) loss_oracle 0.4262 (0.3330) acc 43.7500 (47.1094) kd_loss 0.9505 (1.0229) lr 1.9921e-03 eta 0:29:51
epoch [4/50] batch [140/319] time 0.143 (0.119) data 0.000 (0.005) loss 1.9707 (1.7644) ce_loss 1.5781 (1.3582) teacher_loss 1.4842 (1.2899) loss_zs_kd 0.2905 (0.2685) loss_oracle 0.3413 (0.3403) acc 43.7500 (47.3661) kd_loss 0.9596 (1.0190) lr 1.9921e-03 eta 0:29:34
epoch [4/50] batch [160/319] time 0.083 (0.119) data 0.000 (0.004) loss 2.0356 (1.7609) ce_loss 1.7891 (1.3551) teacher_loss 1.5456 (1.2879) loss_zs_kd 0.3506 (0.2689) loss_oracle 0.3147 (0.3386) acc 31.2500 (47.6953) kd_loss 1.1053 (1.0186) lr 1.9921e-03 eta 0:29:24
epoch [4/50] batch [180/319] time 0.144 (0.118) data 0.000 (0.004) loss 1.7994 (1.7608) ce_loss 1.3652 (1.3536) teacher_loss 1.3618 (1.2880) loss_zs_kd 0.2415 (0.2723) loss_oracle 0.3169 (0.3366) acc 46.8750 (47.6042) kd_loss 0.9875 (1.0191) lr 1.9921e-03 eta 0:29:09
epoch [4/50] batch [200/319] time 0.149 (0.118) data 0.000 (0.003) loss 1.7230 (1.7568) ce_loss 1.3467 (1.3513) teacher_loss 1.3168 (1.2861) loss_zs_kd 0.2426 (0.2706) loss_oracle 0.2849 (0.3353) acc 43.7500 (47.9531) kd_loss 0.9946 (1.0191) lr 1.9921e-03 eta 0:29:00
epoch [4/50] batch [220/319] time 0.104 (0.118) data 0.000 (0.003) loss 1.6105 (1.7527) ce_loss 1.2959 (1.3492) teacher_loss 1.1548 (1.2833) loss_zs_kd 0.2892 (0.2704) loss_oracle 0.3111 (0.3342) acc 62.5000 (48.0966) kd_loss 1.0167 (1.0195) lr 1.9921e-03 eta 0:29:05
epoch [4/50] batch [240/319] time 0.131 (0.118) data 0.000 (0.003) loss 1.7603 (1.7522) ce_loss 1.3203 (1.3498) teacher_loss 1.3137 (1.2842) loss_zs_kd 0.2461 (0.2696) loss_oracle 0.3235 (0.3332) acc 50.0000 (48.1380) kd_loss 0.9353 (1.0214) lr 1.9921e-03 eta 0:28:54
epoch [4/50] batch [260/319] time 0.135 (0.117) data 0.000 (0.003) loss 1.7703 (1.7542) ce_loss 1.4531 (1.3526) teacher_loss 1.2787 (1.2881) loss_zs_kd 0.3320 (0.2700) loss_oracle 0.3257 (0.3311) acc 34.3750 (48.0649) kd_loss 1.0437 (1.0251) lr 1.9921e-03 eta 0:28:46
epoch [4/50] batch [280/319] time 0.111 (0.118) data 0.000 (0.002) loss 1.6181 (1.7440) ce_loss 1.2471 (1.3449) teacher_loss 1.1721 (1.2810) loss_zs_kd 0.2846 (0.2701) loss_oracle 0.3037 (0.3280) acc 53.1250 (48.4263) kd_loss 1.0245 (1.0279) lr 1.9921e-03 eta 0:28:57
epoch [4/50] batch [300/319] time 0.166 (0.118) data 0.000 (0.002) loss 1.6753 (1.7404) ce_loss 1.2842 (1.3412) teacher_loss 1.2086 (1.2789) loss_zs_kd 0.3086 (0.2700) loss_oracle 0.3124 (0.3264) acc 59.3750 (48.6667) kd_loss 0.9551 (1.0276) lr 1.9921e-03 eta 0:28:47
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,222
* accuracy: 50.8%
* error: 49.2%
* macro_f1: 37.5%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,277
* accuracy: 43.9%
* error: 56.1%
* macro_f1: 17.9%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      50.8%, epoch: 4 *******
******* Domain 2 best val test acc: 43.9%, epoch: 4 *******
******* Domain 2 best test acc:     43.9%, epoch: 4 *******
epoch [5/50] batch [20/319] time 0.142 (0.169) data 0.000 (0.032) loss 1.8190 (1.7324) ce_loss 1.3652 (1.3316) teacher_loss 1.3455 (1.2404) loss_zs_kd 0.2479 (0.2836) loss_oracle 0.3495 (0.3502) acc 40.6250 (47.8125) kd_loss 1.0710 (1.0249) lr 1.9823e-03 eta 0:41:13
epoch [5/50] batch [40/319] time 0.149 (0.154) data 0.000 (0.016) loss 1.5428 (1.7318) ce_loss 1.0938 (1.3299) teacher_loss 1.1209 (1.2522) loss_zs_kd 0.2850 (0.2895) loss_oracle 0.2795 (0.3348) acc 59.3750 (49.0625) kd_loss 0.9631 (1.0196) lr 1.9823e-03 eta 0:37:40
epoch [5/50] batch [60/319] time 0.148 (0.153) data 0.001 (0.011) loss 1.5185 (1.7279) ce_loss 1.1934 (1.3314) teacher_loss 1.0179 (1.2616) loss_zs_kd 0.3554 (0.2837) loss_oracle 0.3229 (0.3244) acc 59.3750 (49.0625) kd_loss 1.0530 (1.0309) lr 1.9823e-03 eta 0:37:20
epoch [5/50] batch [80/319] time 0.143 (0.153) data 0.000 (0.008) loss 1.3484 (1.7067) ce_loss 1.0732 (1.3190) teacher_loss 0.9801 (1.2405) loss_zs_kd 0.2344 (0.2843) loss_oracle 0.2511 (0.3241) acc 53.1250 (49.4141) kd_loss 1.0421 (1.0384) lr 1.9823e-03 eta 0:37:10
epoch [5/50] batch [100/319] time 0.135 (0.151) data 0.000 (0.007) loss 1.8093 (1.6987) ce_loss 1.4492 (1.3149) teacher_loss 1.3205 (1.2353) loss_zs_kd 0.3126 (0.2857) loss_oracle 0.3325 (0.3206) acc 46.8750 (49.7500) kd_loss 1.1079 (1.0422) lr 1.9823e-03 eta 0:36:43
epoch [5/50] batch [120/319] time 0.190 (0.147) data 0.000 (0.006) loss 1.6365 (1.7080) ce_loss 1.1895 (1.3233) teacher_loss 1.1799 (1.2457) loss_zs_kd 0.2405 (0.2842) loss_oracle 0.3363 (0.3202) acc 50.0000 (48.8802) kd_loss 1.0445 (1.0437) lr 1.9823e-03 eta 0:35:40
epoch [5/50] batch [140/319] time 0.080 (0.148) data 0.000 (0.005) loss 1.8180 (1.7072) ce_loss 1.4355 (1.3178) teacher_loss 1.3182 (1.2406) loss_zs_kd 0.2786 (0.2862) loss_oracle 0.3606 (0.3236) acc 46.8750 (49.3080) kd_loss 1.0340 (1.0427) lr 1.9823e-03 eta 0:35:47
epoch [5/50] batch [160/319] time 0.190 (0.152) data 0.000 (0.004) loss 1.7237 (1.7024) ce_loss 1.3535 (1.3135) teacher_loss 1.3138 (1.2374) loss_zs_kd 0.3010 (0.2873) loss_oracle 0.2594 (0.3214) acc 43.7500 (49.4727) kd_loss 1.0179 (1.0436) lr 1.9823e-03 eta 0:36:44
epoch [5/50] batch [180/319] time 0.081 (0.147) data 0.000 (0.004) loss 1.3700 (1.6951) ce_loss 1.0439 (1.3059) teacher_loss 0.9058 (1.2286) loss_zs_kd 0.2787 (0.2887) loss_oracle 0.3248 (0.3221) acc 59.3750 (49.9306) kd_loss 1.0707 (1.0446) lr 1.9823e-03 eta 0:35:26
epoch [5/50] batch [200/319] time 0.140 (0.143) data 0.000 (0.003) loss 1.8260 (1.6958) ce_loss 1.2939 (1.3039) teacher_loss 1.2363 (1.2293) loss_zs_kd 0.3355 (0.2869) loss_oracle 0.4220 (0.3230) acc 56.2500 (50.0469) kd_loss 1.0259 (1.0418) lr 1.9823e-03 eta 0:34:28
epoch [5/50] batch [220/319] time 0.132 (0.139) data 0.000 (0.003) loss 1.5327 (1.6944) ce_loss 1.0586 (1.3039) teacher_loss 1.0310 (1.2294) loss_zs_kd 0.2346 (0.2849) loss_oracle 0.3844 (0.3226) acc 65.6250 (50.0852) kd_loss 0.9998 (1.0399) lr 1.9823e-03 eta 0:33:32
epoch [5/50] batch [240/319] time 0.154 (0.138) data 0.001 (0.003) loss 1.4626 (1.6994) ce_loss 1.1006 (1.3087) teacher_loss 0.9720 (1.2324) loss_zs_kd 0.2679 (0.2852) loss_oracle 0.3567 (0.3244) acc 53.1250 (49.7917) kd_loss 0.9449 (1.0410) lr 1.9823e-03 eta 0:33:05
epoch [5/50] batch [260/319] time 0.130 (0.136) data 0.000 (0.003) loss 1.9334 (1.7033) ce_loss 1.4600 (1.3101) teacher_loss 1.3933 (1.2341) loss_zs_kd 0.3192 (0.2847) loss_oracle 0.3804 (0.3269) acc 43.7500 (49.6274) kd_loss 1.0066 (1.0384) lr 1.9823e-03 eta 0:32:42
epoch [5/50] batch [280/319] time 0.125 (0.134) data 0.000 (0.003) loss 1.3606 (1.7031) ce_loss 0.9009 (1.3077) teacher_loss 0.9111 (1.2319) loss_zs_kd 0.1800 (0.2847) loss_oracle 0.3595 (0.3289) acc 59.3750 (49.7656) kd_loss 1.0473 (1.0367) lr 1.9823e-03 eta 0:32:14
epoch [5/50] batch [300/319] time 0.119 (0.133) data 0.000 (0.002) loss 1.7515 (1.7038) ce_loss 1.2588 (1.3077) teacher_loss 1.2447 (1.2323) loss_zs_kd 0.2979 (0.2852) loss_oracle 0.3579 (0.3289) acc 43.7500 (49.7500) kd_loss 1.0477 (1.0368) lr 1.9823e-03 eta 0:31:48
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,247
* accuracy: 51.3%
* error: 48.7%
* macro_f1: 39.4%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 3,910
* accuracy: 40.2%
* error: 59.8%
* macro_f1: 19.0%
******* Domain 2 best val acc:      51.3%, epoch: 5 *******
******* Domain 2 best val test acc: 40.2%, epoch: 5 *******
******* Domain 2 best test acc:     43.9%, epoch: 4 *******
epoch [6/50] batch [20/319] time 0.070 (0.197) data 0.000 (0.035) loss 2.0131 (1.7308) ce_loss 1.5049 (1.2604) teacher_loss 1.4502 (1.2076) loss_zs_kd 0.3115 (0.2842) loss_oracle 0.4072 (0.3810) acc 34.3750 (52.1875) kd_loss 0.9911 (0.9844) lr 1.9686e-03 eta 0:47:04
epoch [6/50] batch [40/319] time 0.189 (0.186) data 0.000 (0.018) loss 1.8726 (1.7000) ce_loss 1.3574 (1.2455) teacher_loss 1.4134 (1.1853) loss_zs_kd 0.3157 (0.2962) loss_oracle 0.3014 (0.3666) acc 53.1250 (53.3594) kd_loss 1.0009 (0.9941) lr 1.9686e-03 eta 0:44:26
epoch [6/50] batch [60/319] time 0.085 (0.159) data 0.000 (0.012) loss 1.7032 (1.7020) ce_loss 1.3467 (1.2658) teacher_loss 1.2387 (1.2006) loss_zs_kd 0.2860 (0.2924) loss_oracle 0.3216 (0.3553) acc 40.6250 (51.5104) kd_loss 1.0399 (1.0002) lr 1.9686e-03 eta 0:37:48
epoch [6/50] batch [80/319] time 0.080 (0.143) data 0.000 (0.009) loss 1.8719 (1.7094) ce_loss 1.3203 (1.2710) teacher_loss 1.3027 (1.2060) loss_zs_kd 0.2900 (0.2901) loss_oracle 0.4243 (0.3584) acc 59.3750 (50.8203) kd_loss 0.9668 (0.9988) lr 1.9686e-03 eta 0:34:06
epoch [6/50] batch [100/319] time 0.102 (0.135) data 0.000 (0.007) loss 1.5896 (1.7152) ce_loss 1.1328 (1.2860) teacher_loss 1.1032 (1.2159) loss_zs_kd 0.2859 (0.2866) loss_oracle 0.3435 (0.3560) acc 59.3750 (50.2812) kd_loss 1.0113 (1.0030) lr 1.9686e-03 eta 0:32:05
epoch [6/50] batch [120/319] time 0.096 (0.130) data 0.000 (0.006) loss 1.7786 (1.7098) ce_loss 1.2451 (1.2854) teacher_loss 1.2221 (1.2116) loss_zs_kd 0.3671 (0.2896) loss_oracle 0.3729 (0.3534) acc 59.3750 (50.3906) kd_loss 1.0203 (1.0071) lr 1.9686e-03 eta 0:30:47
epoch [6/50] batch [140/319] time 0.084 (0.126) data 0.000 (0.005) loss 1.8162 (1.7048) ce_loss 1.3486 (1.2816) teacher_loss 1.2414 (1.2082) loss_zs_kd 0.2737 (0.2884) loss_oracle 0.4380 (0.3524) acc 46.8750 (50.8036) kd_loss 0.9946 (1.0100) lr 1.9686e-03 eta 0:29:46
epoch [6/50] batch [160/319] time 0.085 (0.125) data 0.000 (0.005) loss 1.5633 (1.7059) ce_loss 1.2295 (1.2835) teacher_loss 1.1513 (1.2103) loss_zs_kd 0.2007 (0.2894) loss_oracle 0.3116 (0.3510) acc 53.1250 (50.7617) kd_loss 1.1173 (1.0129) lr 1.9686e-03 eta 0:29:33
epoch [6/50] batch [180/319] time 0.103 (0.123) data 0.000 (0.004) loss 1.8331 (1.7101) ce_loss 1.4316 (1.2912) teacher_loss 1.4153 (1.2170) loss_zs_kd 0.2949 (0.2882) loss_oracle 0.2703 (0.3490) acc 46.8750 (50.3299) kd_loss 1.0207 (1.0175) lr 1.9686e-03 eta 0:29:01
epoch [6/50] batch [200/319] time 0.147 (0.121) data 0.000 (0.004) loss 1.7463 (1.7077) ce_loss 1.2461 (1.2892) teacher_loss 1.2707 (1.2169) loss_zs_kd 0.2649 (0.2849) loss_oracle 0.3431 (0.3483) acc 50.0000 (50.5312) kd_loss 1.0398 (1.0174) lr 1.9686e-03 eta 0:28:39
epoch [6/50] batch [220/319] time 0.093 (0.121) data 0.000 (0.003) loss 1.6645 (1.7087) ce_loss 1.2051 (1.2897) teacher_loss 1.1725 (1.2161) loss_zs_kd 0.2915 (0.2864) loss_oracle 0.3462 (0.3495) acc 59.3750 (50.3267) kd_loss 1.0426 (1.0189) lr 1.9686e-03 eta 0:28:27
epoch [6/50] batch [240/319] time 0.129 (0.120) data 0.000 (0.003) loss 2.0255 (1.7151) ce_loss 1.4941 (1.2928) teacher_loss 1.4634 (1.2195) loss_zs_kd 0.2958 (0.2865) loss_oracle 0.4143 (0.3524) acc 40.6250 (50.0521) kd_loss 0.9784 (1.0186) lr 1.9686e-03 eta 0:28:16
epoch [6/50] batch [260/319] time 0.117 (0.119) data 0.000 (0.003) loss 1.5401 (1.7183) ce_loss 1.1113 (1.2937) teacher_loss 1.0598 (1.2221) loss_zs_kd 0.3132 (0.2872) loss_oracle 0.3237 (0.3526) acc 50.0000 (50.0361) kd_loss 1.0046 (1.0167) lr 1.9686e-03 eta 0:28:04
epoch [6/50] batch [280/319] time 0.087 (0.119) data 0.000 (0.003) loss 1.7309 (1.7190) ce_loss 1.2871 (1.2937) teacher_loss 1.2757 (1.2219) loss_zs_kd 0.2862 (0.2892) loss_oracle 0.3122 (0.3525) acc 40.6250 (49.8996) kd_loss 1.0865 (1.0190) lr 1.9686e-03 eta 0:27:53
epoch [6/50] batch [300/319] time 0.148 (0.119) data 0.000 (0.003) loss 1.6599 (1.7183) ce_loss 1.3340 (1.2956) teacher_loss 1.1727 (1.2220) loss_zs_kd 0.3074 (0.2882) loss_oracle 0.3335 (0.3522) acc 53.1250 (49.8542) kd_loss 1.0068 (1.0208) lr 1.9686e-03 eta 0:27:58
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,396
* accuracy: 54.7%
* error: 45.3%
* macro_f1: 41.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,573
* accuracy: 47.0%
* error: 53.0%
* macro_f1: 19.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      54.7%, epoch: 6 *******
******* Domain 2 best val test acc: 47.0%, epoch: 6 *******
******* Domain 2 best test acc:     47.0%, epoch: 6 *******
epoch [7/50] batch [20/319] time 0.139 (0.167) data 0.000 (0.036) loss 1.4289 (1.6676) ce_loss 0.9658 (1.2478) teacher_loss 0.9265 (1.1673) loss_zs_kd 0.2978 (0.2986) loss_oracle 0.3535 (0.3510) acc 59.3750 (52.9688) kd_loss 0.9848 (1.0364) lr 1.9511e-03 eta 0:38:59
epoch [7/50] batch [40/319] time 0.125 (0.156) data 0.000 (0.018) loss 2.1688 (1.7192) ce_loss 1.5566 (1.2801) teacher_loss 1.5726 (1.2021) loss_zs_kd 0.3211 (0.3004) loss_oracle 0.4356 (0.3669) acc 50.0000 (51.7969) kd_loss 1.0465 (1.0185) lr 1.9511e-03 eta 0:36:25
epoch [7/50] batch [60/319] time 0.144 (0.144) data 0.001 (0.012) loss 1.7781 (1.7081) ce_loss 1.2295 (1.2646) teacher_loss 1.1843 (1.1857) loss_zs_kd 0.3261 (0.3009) loss_oracle 0.4307 (0.3719) acc 53.1250 (51.9792) kd_loss 1.0332 (1.0253) lr 1.9511e-03 eta 0:33:37
epoch [7/50] batch [80/319] time 0.157 (0.143) data 0.000 (0.009) loss 1.7036 (1.7220) ce_loss 1.1855 (1.2769) teacher_loss 1.1854 (1.1989) loss_zs_kd 0.2743 (0.2954) loss_oracle 0.3811 (0.3754) acc 59.3750 (51.6797) kd_loss 0.8974 (1.0237) lr 1.9511e-03 eta 0:33:21
epoch [7/50] batch [100/319] time 0.146 (0.143) data 0.000 (0.007) loss 1.6746 (1.7381) ce_loss 1.3203 (1.2960) teacher_loss 1.2072 (1.2197) loss_zs_kd 0.2848 (0.2917) loss_oracle 0.3249 (0.3726) acc 53.1250 (50.6250) kd_loss 1.0708 (1.0262) lr 1.9511e-03 eta 0:33:07
epoch [7/50] batch [120/319] time 0.088 (0.138) data 0.000 (0.006) loss 1.9786 (1.7362) ce_loss 1.6582 (1.2958) teacher_loss 1.4476 (1.2156) loss_zs_kd 0.3160 (0.2959) loss_oracle 0.3730 (0.3727) acc 43.7500 (50.7812) kd_loss 1.0656 (1.0260) lr 1.9511e-03 eta 0:32:02
epoch [7/50] batch [140/319] time 0.129 (0.134) data 0.000 (0.005) loss 1.7599 (1.7331) ce_loss 1.2314 (1.2964) teacher_loss 1.1697 (1.2111) loss_zs_kd 0.3168 (0.2986) loss_oracle 0.4317 (0.3727) acc 46.8750 (50.4241) kd_loss 0.9961 (1.0253) lr 1.9511e-03 eta 0:31:06
epoch [7/50] batch [160/319] time 0.115 (0.133) data 0.000 (0.005) loss 1.6974 (1.7321) ce_loss 1.1621 (1.2953) teacher_loss 1.1833 (1.2073) loss_zs_kd 0.2545 (0.2996) loss_oracle 0.3868 (0.3750) acc 50.0000 (50.4102) kd_loss 1.0051 (1.0215) lr 1.9511e-03 eta 0:30:50
epoch [7/50] batch [180/319] time 0.145 (0.132) data 0.001 (0.004) loss 1.6393 (1.7315) ce_loss 1.2891 (1.2985) teacher_loss 1.1379 (1.2066) loss_zs_kd 0.3382 (0.3017) loss_oracle 0.3323 (0.3741) acc 46.8750 (50.1736) kd_loss 1.1213 (1.0223) lr 1.9511e-03 eta 0:30:27
epoch [7/50] batch [200/319] time 0.160 (0.132) data 0.000 (0.004) loss 2.1476 (1.7254) ce_loss 1.6143 (1.2924) teacher_loss 1.5447 (1.2008) loss_zs_kd 0.3909 (0.3041) loss_oracle 0.4075 (0.3726) acc 43.7500 (50.4219) kd_loss 1.0801 (1.0219) lr 1.9511e-03 eta 0:30:20
epoch [7/50] batch [220/319] time 0.151 (0.133) data 0.000 (0.004) loss 1.6950 (1.7123) ce_loss 1.3125 (1.2847) teacher_loss 1.1379 (1.1868) loss_zs_kd 0.3427 (0.3042) loss_oracle 0.3858 (0.3735) acc 40.6250 (50.6818) kd_loss 1.0628 (1.0230) lr 1.9511e-03 eta 0:30:43
epoch [7/50] batch [240/319] time 0.161 (0.134) data 0.000 (0.003) loss 1.8648 (1.7107) ce_loss 1.4619 (1.2867) teacher_loss 1.3254 (1.1835) loss_zs_kd 0.2896 (0.3057) loss_oracle 0.3946 (0.3743) acc 46.8750 (50.6510) kd_loss 1.0437 (1.0227) lr 1.9511e-03 eta 0:30:54
epoch [7/50] batch [260/319] time 0.188 (0.134) data 0.000 (0.003) loss 1.6961 (1.7098) ce_loss 1.2441 (1.2914) teacher_loss 1.1672 (1.1853) loss_zs_kd 0.3141 (0.3050) loss_oracle 0.3719 (0.3721) acc 56.2500 (50.4928) kd_loss 1.1393 (1.0267) lr 1.9511e-03 eta 0:30:43
epoch [7/50] batch [280/319] time 0.081 (0.135) data 0.000 (0.003) loss 1.5353 (1.7080) ce_loss 1.1562 (1.2902) teacher_loss 1.0338 (1.1869) loss_zs_kd 0.3067 (0.3045) loss_oracle 0.3481 (0.3689) acc 65.6250 (50.6920) kd_loss 1.0685 (1.0319) lr 1.9511e-03 eta 0:31:01
epoch [7/50] batch [300/319] time 0.176 (0.137) data 0.000 (0.003) loss 1.8519 (1.7059) ce_loss 1.5703 (1.2904) teacher_loss 1.3862 (1.1871) loss_zs_kd 0.3116 (0.3028) loss_oracle 0.3099 (0.3674) acc 34.3750 (50.6354) kd_loss 0.9787 (1.0324) lr 1.9511e-03 eta 0:31:20
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,309
* accuracy: 52.7%
* error: 47.3%
* macro_f1: 41.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,303
* accuracy: 44.2%
* error: 55.8%
* macro_f1: 20.0%
******* Domain 2 best val acc:      54.7%, epoch: 6 *******
******* Domain 2 best val test acc: 47.0%, epoch: 6 *******
******* Domain 2 best test acc:     47.0%, epoch: 6 *******
epoch [8/50] batch [20/319] time 0.083 (0.133) data 0.000 (0.031) loss 1.8995 (1.7311) ce_loss 1.5234 (1.3373) teacher_loss 1.3689 (1.2040) loss_zs_kd 0.3186 (0.2863) loss_oracle 0.3713 (0.3839) acc 37.5000 (48.1250) kd_loss 1.0984 (1.0360) lr 1.9298e-03 eta 0:30:18
epoch [8/50] batch [40/319] time 0.098 (0.116) data 0.000 (0.016) loss 1.4662 (1.6908) ce_loss 1.1162 (1.2975) teacher_loss 0.9318 (1.1710) loss_zs_kd 0.2928 (0.3071) loss_oracle 0.3880 (0.3663) acc 53.1250 (51.6406) kd_loss 1.0325 (1.0507) lr 1.9298e-03 eta 0:26:23
epoch [8/50] batch [60/319] time 0.098 (0.113) data 0.001 (0.010) loss 1.8054 (1.6800) ce_loss 1.3633 (1.2774) teacher_loss 1.2589 (1.1603) loss_zs_kd 0.3369 (0.3063) loss_oracle 0.3781 (0.3665) acc 43.7500 (52.1354) kd_loss 1.0369 (1.0417) lr 1.9298e-03 eta 0:25:42
epoch [8/50] batch [80/319] time 0.084 (0.111) data 0.000 (0.008) loss 1.5652 (1.6712) ce_loss 1.3115 (1.2661) teacher_loss 1.1097 (1.1521) loss_zs_kd 0.2304 (0.3036) loss_oracle 0.3402 (0.3672) acc 50.0000 (51.9531) kd_loss 1.0944 (1.0460) lr 1.9298e-03 eta 0:25:10
epoch [8/50] batch [100/319] time 0.155 (0.115) data 0.000 (0.006) loss 1.7429 (1.6880) ce_loss 1.2061 (1.2791) teacher_loss 1.1363 (1.1646) loss_zs_kd 0.3400 (0.3044) loss_oracle 0.4366 (0.3713) acc 56.2500 (51.5625) kd_loss 0.9710 (1.0393) lr 1.9298e-03 eta 0:26:05
epoch [8/50] batch [120/319] time 0.158 (0.121) data 0.000 (0.005) loss 1.9146 (1.6796) ce_loss 1.4736 (1.2736) teacher_loss 1.2306 (1.1490) loss_zs_kd 0.4083 (0.3061) loss_oracle 0.4798 (0.3775) acc 43.7500 (51.7708) kd_loss 1.0207 (1.0315) lr 1.9298e-03 eta 0:27:29
epoch [8/50] batch [140/319] time 0.191 (0.125) data 0.000 (0.005) loss 1.8601 (1.6893) ce_loss 1.3672 (1.2783) teacher_loss 1.2547 (1.1524) loss_zs_kd 0.3826 (0.3060) loss_oracle 0.4141 (0.3839) acc 50.0000 (51.7188) kd_loss 1.0002 (1.0279) lr 1.9298e-03 eta 0:28:12
epoch [8/50] batch [160/319] time 0.187 (0.127) data 0.000 (0.004) loss 1.8163 (1.6998) ce_loss 1.3506 (1.2815) teacher_loss 1.2693 (1.1606) loss_zs_kd 0.2826 (0.3060) loss_oracle 0.4057 (0.3863) acc 43.7500 (51.8359) kd_loss 1.0608 (1.0237) lr 1.9298e-03 eta 0:28:41
epoch [8/50] batch [180/319] time 0.064 (0.132) data 0.000 (0.004) loss 1.8889 (1.7109) ce_loss 1.4053 (1.2857) teacher_loss 1.2654 (1.1669) loss_zs_kd 0.3110 (0.3078) loss_oracle 0.4679 (0.3901) acc 46.8750 (51.7014) kd_loss 0.8498 (1.0207) lr 1.9298e-03 eta 0:29:45
epoch [8/50] batch [200/319] time 0.140 (0.129) data 0.000 (0.003) loss 1.8457 (1.7080) ce_loss 1.2637 (1.2790) teacher_loss 1.3236 (1.1618) loss_zs_kd 0.3868 (0.3090) loss_oracle 0.3287 (0.3917) acc 46.8750 (51.6250) kd_loss 1.0359 (1.0193) lr 1.9298e-03 eta 0:29:06
epoch [8/50] batch [220/319] time 0.084 (0.127) data 0.000 (0.003) loss 1.5234 (1.7108) ce_loss 1.0322 (1.2780) teacher_loss 0.9860 (1.1659) loss_zs_kd 0.3486 (0.3097) loss_oracle 0.3631 (0.3901) acc 65.6250 (51.7188) kd_loss 1.0321 (1.0213) lr 1.9298e-03 eta 0:28:37
epoch [8/50] batch [240/319] time 0.090 (0.125) data 0.000 (0.003) loss 1.6838 (1.7044) ce_loss 1.3545 (1.2731) teacher_loss 1.1812 (1.1617) loss_zs_kd 0.2901 (0.3109) loss_oracle 0.3576 (0.3873) acc 50.0000 (51.8359) kd_loss 1.0217 (1.0245) lr 1.9298e-03 eta 0:28:03
epoch [8/50] batch [260/319] time 0.083 (0.123) data 0.000 (0.003) loss 1.9210 (1.7049) ce_loss 1.5215 (1.2728) teacher_loss 1.4067 (1.1617) loss_zs_kd 0.3331 (0.3114) loss_oracle 0.3478 (0.3876) acc 43.7500 (51.7788) kd_loss 1.0579 (1.0239) lr 1.9298e-03 eta 0:27:39
epoch [8/50] batch [280/319] time 0.081 (0.121) data 0.000 (0.002) loss 1.7517 (1.7011) ce_loss 1.3809 (1.2701) teacher_loss 1.2425 (1.1568) loss_zs_kd 0.2803 (0.3110) loss_oracle 0.3690 (0.3888) acc 43.7500 (51.6741) kd_loss 0.9404 (1.0234) lr 1.9298e-03 eta 0:27:08
epoch [8/50] batch [300/319] time 0.134 (0.120) data 0.000 (0.002) loss 1.7149 (1.7050) ce_loss 1.4229 (1.2756) teacher_loss 1.2177 (1.1620) loss_zs_kd 0.2848 (0.3106) loss_oracle 0.3549 (0.3876) acc 43.7500 (51.3750) kd_loss 1.0990 (1.0259) lr 1.9298e-03 eta 0:26:52
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,328
* accuracy: 53.2%
* error: 46.8%
* macro_f1: 41.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,360
* accuracy: 44.8%
* error: 55.2%
* macro_f1: 19.7%
******* Domain 2 best val acc:      54.7%, epoch: 6 *******
******* Domain 2 best val test acc: 47.0%, epoch: 6 *******
******* Domain 2 best test acc:     47.0%, epoch: 6 *******
epoch [9/50] batch [20/319] time 0.138 (0.133) data 0.000 (0.027) loss 1.6445 (1.6855) ce_loss 1.1719 (1.2256) teacher_loss 1.1023 (1.1240) loss_zs_kd 0.3178 (0.3362) loss_oracle 0.3833 (0.3934) acc 50.0000 (50.9375) kd_loss 1.0711 (1.0376) lr 1.9048e-03 eta 0:29:39
epoch [9/50] batch [40/319] time 0.066 (0.149) data 0.000 (0.014) loss 1.5329 (1.6376) ce_loss 1.1709 (1.2160) teacher_loss 1.0368 (1.1045) loss_zs_kd 0.3430 (0.3272) loss_oracle 0.3246 (0.3694) acc 50.0000 (51.6406) kd_loss 1.0868 (1.0520) lr 1.9048e-03 eta 0:33:12
epoch [9/50] batch [60/319] time 0.194 (0.153) data 0.000 (0.009) loss 1.6725 (1.6450) ce_loss 1.4854 (1.2532) teacher_loss 1.2390 (1.1401) loss_zs_kd 0.2608 (0.3089) loss_oracle 0.3031 (0.3505) acc 37.5000 (50.2604) kd_loss 1.0341 (1.0751) lr 1.9048e-03 eta 0:33:56
epoch [9/50] batch [80/319] time 0.080 (0.146) data 0.000 (0.007) loss 1.6993 (1.6581) ce_loss 1.2109 (1.2670) teacher_loss 1.1242 (1.1545) loss_zs_kd 0.3126 (0.3049) loss_oracle 0.4188 (0.3511) acc 65.6250 (50.7031) kd_loss 1.0292 (1.0733) lr 1.9048e-03 eta 0:32:27
epoch [9/50] batch [100/319] time 0.145 (0.139) data 0.000 (0.006) loss 1.7036 (1.6618) ce_loss 1.4404 (1.2638) teacher_loss 1.2820 (1.1598) loss_zs_kd 0.2241 (0.3024) loss_oracle 0.3095 (0.3508) acc 43.7500 (51.3438) kd_loss 1.1317 (1.0700) lr 1.9048e-03 eta 0:30:41
epoch [9/50] batch [120/319] time 0.092 (0.134) data 0.000 (0.005) loss 1.5924 (1.6617) ce_loss 1.4414 (1.2795) teacher_loss 1.1956 (1.1687) loss_zs_kd 0.2176 (0.2947) loss_oracle 0.2881 (0.3457) acc 34.3750 (50.2604) kd_loss 1.1779 (1.0823) lr 1.9048e-03 eta 0:29:36
epoch [9/50] batch [140/319] time 0.086 (0.130) data 0.000 (0.004) loss 2.1599 (1.6724) ce_loss 1.6436 (1.2903) teacher_loss 1.5968 (1.1794) loss_zs_kd 0.3196 (0.2937) loss_oracle 0.4033 (0.3461) acc 34.3750 (49.6875) kd_loss 1.0936 (1.0796) lr 1.9048e-03 eta 0:28:40
epoch [9/50] batch [160/319] time 0.150 (0.130) data 0.000 (0.004) loss 1.7719 (1.6697) ce_loss 1.3174 (1.2835) teacher_loss 1.3454 (1.1747) loss_zs_kd 0.3076 (0.2981) loss_oracle 0.2727 (0.3459) acc 53.1250 (50.2148) kd_loss 1.0523 (1.0776) lr 1.9048e-03 eta 0:28:40
epoch [9/50] batch [180/319] time 0.151 (0.132) data 0.000 (0.003) loss 1.6986 (1.6692) ce_loss 1.2881 (1.2805) teacher_loss 1.2155 (1.1724) loss_zs_kd 0.3535 (0.3002) loss_oracle 0.3064 (0.3466) acc 53.1250 (50.1215) kd_loss 0.9855 (1.0739) lr 1.9048e-03 eta 0:29:10
epoch [9/50] batch [200/319] time 0.144 (0.132) data 0.000 (0.003) loss 1.5708 (1.6743) ce_loss 1.1855 (1.2817) teacher_loss 1.0823 (1.1733) loss_zs_kd 0.2571 (0.3014) loss_oracle 0.3600 (0.3502) acc 43.7500 (50.2031) kd_loss 1.0726 (1.0678) lr 1.9048e-03 eta 0:29:04
epoch [9/50] batch [220/319] time 0.161 (0.133) data 0.000 (0.003) loss 1.6077 (1.6757) ce_loss 1.1787 (1.2786) teacher_loss 1.0941 (1.1737) loss_zs_kd 0.2416 (0.2990) loss_oracle 0.3928 (0.3526) acc 59.3750 (50.3267) kd_loss 1.0542 (1.0629) lr 1.9048e-03 eta 0:29:09
epoch [9/50] batch [240/319] time 0.157 (0.134) data 0.000 (0.003) loss 1.7201 (1.6764) ce_loss 1.2900 (1.2750) teacher_loss 1.1418 (1.1721) loss_zs_kd 0.3820 (0.2992) loss_oracle 0.3873 (0.3546) acc 46.8750 (50.4818) kd_loss 1.0828 (1.0594) lr 1.9048e-03 eta 0:29:28
epoch [9/50] batch [260/319] time 0.156 (0.136) data 0.000 (0.002) loss 1.7082 (1.6729) ce_loss 1.3330 (1.2717) teacher_loss 1.1760 (1.1661) loss_zs_kd 0.3194 (0.3006) loss_oracle 0.3725 (0.3566) acc 46.8750 (50.5288) kd_loss 1.0475 (1.0554) lr 1.9048e-03 eta 0:29:42
epoch [9/50] batch [280/319] time 0.086 (0.135) data 0.000 (0.002) loss 1.5893 (1.6807) ce_loss 1.0840 (1.2758) teacher_loss 1.0210 (1.1706) loss_zs_kd 0.3885 (0.3029) loss_oracle 0.3741 (0.3587) acc 59.3750 (50.4799) kd_loss 1.0296 (1.0530) lr 1.9048e-03 eta 0:29:29
epoch [9/50] batch [300/319] time 0.150 (0.134) data 0.000 (0.002) loss 1.9639 (1.6805) ce_loss 1.5547 (1.2768) teacher_loss 1.4585 (1.1703) loss_zs_kd 0.2955 (0.3032) loss_oracle 0.3576 (0.3586) acc 43.7500 (50.2812) kd_loss 0.9787 (1.0536) lr 1.9048e-03 eta 0:29:11
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,335
* accuracy: 53.3%
* error: 46.7%
* macro_f1: 41.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,092
* accuracy: 42.0%
* error: 58.0%
* macro_f1: 19.4%
******* Domain 2 best val acc:      54.7%, epoch: 6 *******
******* Domain 2 best val test acc: 47.0%, epoch: 6 *******
******* Domain 2 best test acc:     47.0%, epoch: 6 *******
epoch [10/50] batch [20/319] time 0.087 (0.150) data 0.000 (0.026) loss 1.9398 (1.7353) ce_loss 1.4121 (1.2800) teacher_loss 1.3642 (1.2028) loss_zs_kd 0.3076 (0.3028) loss_oracle 0.4219 (0.3811) acc 37.5000 (51.2500) kd_loss 1.0338 (1.0355) lr 1.8763e-03 eta 0:32:42
epoch [10/50] batch [40/319] time 0.136 (0.134) data 0.000 (0.013) loss 1.6280 (1.7054) ce_loss 1.3291 (1.2867) teacher_loss 1.1268 (1.1727) loss_zs_kd 0.2895 (0.3040) loss_oracle 0.3564 (0.3807) acc 50.0000 (49.4531) kd_loss 1.0769 (1.0513) lr 1.8763e-03 eta 0:29:11
epoch [10/50] batch [60/319] time 0.107 (0.127) data 0.001 (0.009) loss 1.7815 (1.6849) ce_loss 1.4697 (1.2793) teacher_loss 1.2079 (1.1538) loss_zs_kd 0.2935 (0.2987) loss_oracle 0.4269 (0.3817) acc 50.0000 (49.5833) kd_loss 1.0967 (1.0552) lr 1.8763e-03 eta 0:27:32
epoch [10/50] batch [80/319] time 0.095 (0.124) data 0.000 (0.007) loss 1.4219 (1.6848) ce_loss 1.0088 (1.2833) teacher_loss 0.9059 (1.1612) loss_zs_kd 0.2695 (0.2916) loss_oracle 0.3812 (0.3778) acc 65.6250 (49.3359) kd_loss 0.8656 (1.0409) lr 1.8763e-03 eta 0:26:53
epoch [10/50] batch [100/319] time 0.154 (0.128) data 0.000 (0.005) loss 1.5439 (1.7034) ce_loss 1.0244 (1.2960) teacher_loss 1.0517 (1.1756) loss_zs_kd 0.2388 (0.2893) loss_oracle 0.3727 (0.3831) acc 68.7500 (49.0938) kd_loss 0.9902 (1.0293) lr 1.8763e-03 eta 0:27:46
epoch [10/50] batch [120/319] time 0.148 (0.132) data 0.000 (0.004) loss 1.7027 (1.7127) ce_loss 1.2725 (1.2946) teacher_loss 1.2041 (1.1799) loss_zs_kd 0.2739 (0.2882) loss_oracle 0.3616 (0.3887) acc 46.8750 (49.1146) kd_loss 0.9975 (1.0234) lr 1.8763e-03 eta 0:28:29
epoch [10/50] batch [140/319] time 0.154 (0.135) data 0.000 (0.004) loss 1.6812 (1.7053) ce_loss 1.1895 (1.2806) teacher_loss 1.0623 (1.1710) loss_zs_kd 0.3052 (0.2911) loss_oracle 0.4664 (0.3888) acc 46.8750 (49.9554) kd_loss 0.9639 (1.0243) lr 1.8763e-03 eta 0:29:06
epoch [10/50] batch [160/319] time 0.157 (0.137) data 0.000 (0.003) loss 1.7965 (1.7022) ce_loss 1.4492 (1.2732) teacher_loss 1.2787 (1.1699) loss_zs_kd 0.3135 (0.2924) loss_oracle 0.3611 (0.3861) acc 34.3750 (50.4883) kd_loss 1.0068 (1.0225) lr 1.8763e-03 eta 0:29:31
epoch [10/50] batch [180/319] time 0.153 (0.139) data 0.000 (0.003) loss 1.5649 (1.7087) ce_loss 1.1992 (1.2783) teacher_loss 1.0953 (1.1751) loss_zs_kd 0.2973 (0.2951) loss_oracle 0.3210 (0.3861) acc 53.1250 (50.5903) kd_loss 1.0808 (1.0238) lr 1.8763e-03 eta 0:29:50
epoch [10/50] batch [200/319] time 0.156 (0.140) data 0.000 (0.003) loss 1.3836 (1.7077) ce_loss 0.8647 (1.2756) teacher_loss 0.8389 (1.1753) loss_zs_kd 0.2925 (0.2953) loss_oracle 0.3985 (0.3847) acc 71.8750 (50.7656) kd_loss 1.0364 (1.0288) lr 1.8763e-03 eta 0:30:04
epoch [10/50] batch [220/319] time 0.143 (0.140) data 0.000 (0.003) loss 1.5787 (1.7080) ce_loss 1.1084 (1.2745) teacher_loss 0.9949 (1.1768) loss_zs_kd 0.2814 (0.2963) loss_oracle 0.4431 (0.3830) acc 50.0000 (50.9091) kd_loss 1.0448 (1.0288) lr 1.8763e-03 eta 0:30:06
epoch [10/50] batch [240/319] time 0.088 (0.139) data 0.000 (0.002) loss 1.6530 (1.7116) ce_loss 1.2832 (1.2798) teacher_loss 1.1415 (1.1816) loss_zs_kd 0.2963 (0.2977) loss_oracle 0.3634 (0.3812) acc 59.3750 (50.8333) kd_loss 1.0841 (1.0316) lr 1.8763e-03 eta 0:29:40
epoch [10/50] batch [260/319] time 0.147 (0.138) data 0.000 (0.002) loss 1.7172 (1.7125) ce_loss 1.3301 (1.2811) teacher_loss 1.1799 (1.1823) loss_zs_kd 0.3292 (0.2986) loss_oracle 0.3727 (0.3809) acc 46.8750 (50.7812) kd_loss 1.1038 (1.0358) lr 1.8763e-03 eta 0:29:28
epoch [10/50] batch [280/319] time 0.083 (0.137) data 0.000 (0.002) loss 1.7386 (1.7087) ce_loss 1.3516 (1.2776) teacher_loss 1.1673 (1.1785) loss_zs_kd 0.3227 (0.2999) loss_oracle 0.4100 (0.3803) acc 46.8750 (50.9152) kd_loss 1.0841 (1.0376) lr 1.8763e-03 eta 0:29:11
epoch [10/50] batch [300/319] time 0.184 (0.137) data 0.000 (0.002) loss 1.8264 (1.7054) ce_loss 1.4355 (1.2761) teacher_loss 1.3488 (1.1769) loss_zs_kd 0.3153 (0.3013) loss_oracle 0.3200 (0.3779) acc 37.5000 (51.0938) kd_loss 1.0836 (1.0403) lr 1.8763e-03 eta 0:29:14
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,441
* accuracy: 55.8%
* error: 44.2%
* macro_f1: 45.4%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,515
* accuracy: 46.4%
* error: 53.6%
* macro_f1: 19.0%
******* Domain 2 best val acc:      55.8%, epoch: 10 *******
******* Domain 2 best val test acc: 46.4%, epoch: 10 *******
******* Domain 2 best test acc:     47.0%, epoch: 6 *******
epoch [11/50] batch [20/319] time 0.152 (0.184) data 0.000 (0.034) loss 1.6700 (1.6344) ce_loss 1.2998 (1.2369) teacher_loss 1.1571 (1.1263) loss_zs_kd 0.3214 (0.3110) loss_oracle 0.3523 (0.3526) acc 40.6250 (51.7188) kd_loss 1.0946 (1.0727) lr 1.8443e-03 eta 0:38:59
epoch [11/50] batch [40/319] time 0.150 (0.168) data 0.000 (0.017) loss 1.5214 (1.6789) ce_loss 1.0410 (1.2510) teacher_loss 0.9210 (1.1353) loss_zs_kd 0.2992 (0.3103) loss_oracle 0.4507 (0.3884) acc 59.3750 (51.0156) kd_loss 1.0300 (1.0351) lr 1.8443e-03 eta 0:35:35
epoch [11/50] batch [60/319] time 0.121 (0.155) data 0.001 (0.011) loss 1.8300 (1.6911) ce_loss 1.3115 (1.2504) teacher_loss 1.1896 (1.1413) loss_zs_kd 0.4410 (0.3222) loss_oracle 0.4199 (0.3887) acc 43.7500 (51.5625) kd_loss 0.9500 (1.0229) lr 1.8443e-03 eta 0:32:47
epoch [11/50] batch [80/319] time 0.108 (0.148) data 0.000 (0.009) loss 1.9436 (1.6994) ce_loss 1.4766 (1.2555) teacher_loss 1.3876 (1.1490) loss_zs_kd 0.3656 (0.3245) loss_oracle 0.3733 (0.3881) acc 43.7500 (51.7578) kd_loss 1.0788 (1.0247) lr 1.8443e-03 eta 0:31:16
epoch [11/50] batch [100/319] time 0.143 (0.141) data 0.000 (0.007) loss 1.5577 (1.6988) ce_loss 1.1025 (1.2569) teacher_loss 1.0955 (1.1544) loss_zs_kd 0.2603 (0.3210) loss_oracle 0.3320 (0.3839) acc 71.8750 (52.0625) kd_loss 1.1270 (1.0331) lr 1.8443e-03 eta 0:29:44
epoch [11/50] batch [120/319] time 0.108 (0.136) data 0.000 (0.006) loss 1.8636 (1.7044) ce_loss 1.4023 (1.2631) teacher_loss 1.3454 (1.1634) loss_zs_kd 0.2761 (0.3207) loss_oracle 0.3801 (0.3807) acc 43.7500 (51.9531) kd_loss 0.9474 (1.0315) lr 1.8443e-03 eta 0:28:41
epoch [11/50] batch [140/319] time 0.151 (0.135) data 0.000 (0.005) loss 2.0157 (1.7057) ce_loss 1.5176 (1.2632) teacher_loss 1.4351 (1.1689) loss_zs_kd 0.3645 (0.3185) loss_oracle 0.3983 (0.3775) acc 56.2500 (52.2545) kd_loss 0.9784 (1.0302) lr 1.8443e-03 eta 0:28:21
epoch [11/50] batch [160/319] time 0.100 (0.134) data 0.000 (0.004) loss 1.3222 (1.7089) ce_loss 0.9438 (1.2665) teacher_loss 0.8308 (1.1745) loss_zs_kd 0.2957 (0.3178) loss_oracle 0.3435 (0.3755) acc 59.3750 (52.0117) kd_loss 1.1801 (1.0357) lr 1.8443e-03 eta 0:28:12
epoch [11/50] batch [180/319] time 0.189 (0.138) data 0.000 (0.004) loss 1.6653 (1.7044) ce_loss 1.3047 (1.2632) teacher_loss 1.2000 (1.1748) loss_zs_kd 0.2707 (0.3155) loss_oracle 0.3299 (0.3719) acc 50.0000 (52.2049) kd_loss 1.0955 (1.0412) lr 1.8443e-03 eta 0:28:51
epoch [11/50] batch [200/319] time 0.191 (0.134) data 0.000 (0.004) loss 1.6892 (1.6994) ce_loss 1.2764 (1.2598) teacher_loss 1.1661 (1.1745) loss_zs_kd 0.3389 (0.3151) loss_oracle 0.3537 (0.3674) acc 46.8750 (52.4531) kd_loss 1.1351 (1.0486) lr 1.8443e-03 eta 0:28:08
epoch [11/50] batch [220/319] time 0.070 (0.139) data 0.000 (0.003) loss 1.7570 (1.6928) ce_loss 1.3877 (1.2546) teacher_loss 1.2346 (1.1691) loss_zs_kd 0.3405 (0.3134) loss_oracle 0.3522 (0.3670) acc 43.7500 (52.5710) kd_loss 1.0230 (1.0454) lr 1.8443e-03 eta 0:29:06
epoch [11/50] batch [240/319] time 0.130 (0.136) data 0.000 (0.003) loss 1.5703 (1.6841) ce_loss 1.1963 (1.2465) teacher_loss 0.9387 (1.1590) loss_zs_kd 0.3202 (0.3134) loss_oracle 0.4716 (0.3683) acc 53.1250 (52.9818) kd_loss 1.1012 (1.0430) lr 1.8443e-03 eta 0:28:24
epoch [11/50] batch [260/319] time 0.094 (0.136) data 0.000 (0.003) loss 1.5175 (1.6834) ce_loss 1.2373 (1.2458) teacher_loss 0.9998 (1.1563) loss_zs_kd 0.4013 (0.3169) loss_oracle 0.3171 (0.3686) acc 40.6250 (52.8726) kd_loss 1.1131 (1.0450) lr 1.8443e-03 eta 0:28:14
epoch [11/50] batch [280/319] time 0.144 (0.137) data 0.000 (0.003) loss 1.7635 (1.6794) ce_loss 1.4033 (1.2432) teacher_loss 1.3051 (1.1538) loss_zs_kd 0.2723 (0.3161) loss_oracle 0.3222 (0.3676) acc 50.0000 (53.0469) kd_loss 1.1147 (1.0478) lr 1.8443e-03 eta 0:28:23
epoch [11/50] batch [300/319] time 0.142 (0.138) data 0.000 (0.002) loss 2.1603 (1.6821) ce_loss 1.6436 (1.2456) teacher_loss 1.5884 (1.1576) loss_zs_kd 0.2949 (0.3145) loss_oracle 0.4245 (0.3672) acc 43.7500 (52.9062) kd_loss 0.9780 (1.0502) lr 1.8443e-03 eta 0:28:33
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,296
* accuracy: 52.4%
* error: 47.6%
* macro_f1: 42.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,039
* accuracy: 41.5%
* error: 58.5%
* macro_f1: 19.6%
******* Domain 2 best val acc:      55.8%, epoch: 10 *******
******* Domain 2 best val test acc: 46.4%, epoch: 10 *******
******* Domain 2 best test acc:     47.0%, epoch: 6 *******
epoch [12/50] batch [20/319] time 0.070 (0.142) data 0.000 (0.026) loss 1.7847 (1.7325) ce_loss 1.1484 (1.2519) teacher_loss 1.2163 (1.1531) loss_zs_kd 0.2757 (0.3091) loss_oracle 0.4305 (0.4248) acc 53.1250 (51.2500) kd_loss 1.0198 (0.9709) lr 1.8090e-03 eta 0:29:19
epoch [12/50] batch [40/319] time 0.190 (0.159) data 0.000 (0.013) loss 1.4821 (1.7350) ce_loss 1.0947 (1.2590) teacher_loss 0.9399 (1.1566) loss_zs_kd 0.3181 (0.3010) loss_oracle 0.3832 (0.4279) acc 65.6250 (50.7031) kd_loss 0.9645 (0.9556) lr 1.8090e-03 eta 0:32:54
epoch [12/50] batch [60/319] time 0.109 (0.142) data 0.000 (0.009) loss 1.6136 (1.7480) ce_loss 1.3008 (1.2734) teacher_loss 1.0992 (1.1719) loss_zs_kd 0.3152 (0.3148) loss_oracle 0.3568 (0.4187) acc 56.2500 (50.9375) kd_loss 0.9762 (0.9715) lr 1.8090e-03 eta 0:29:22
epoch [12/50] batch [80/319] time 0.098 (0.133) data 0.000 (0.007) loss 1.4475 (1.7240) ce_loss 1.0596 (1.2576) teacher_loss 1.0168 (1.1626) loss_zs_kd 0.3035 (0.3219) loss_oracle 0.2789 (0.4005) acc 56.2500 (51.9531) kd_loss 1.0870 (1.0091) lr 1.8090e-03 eta 0:27:20
epoch [12/50] batch [100/319] time 0.090 (0.127) data 0.000 (0.005) loss 1.8417 (1.7256) ce_loss 1.3125 (1.2662) teacher_loss 1.2425 (1.1771) loss_zs_kd 0.3663 (0.3189) loss_oracle 0.4160 (0.3891) acc 43.7500 (51.6250) kd_loss 1.0780 (1.0256) lr 1.8090e-03 eta 0:26:06
epoch [12/50] batch [120/319] time 0.112 (0.124) data 0.000 (0.005) loss 1.8430 (1.7243) ce_loss 1.4268 (1.2714) teacher_loss 1.3949 (1.1857) loss_zs_kd 0.2538 (0.3146) loss_oracle 0.3212 (0.3813) acc 43.7500 (51.4844) kd_loss 1.1206 (1.0310) lr 1.8090e-03 eta 0:25:32
epoch [12/50] batch [140/319] time 0.137 (0.122) data 0.000 (0.004) loss 1.7074 (1.7082) ce_loss 1.3057 (1.2605) teacher_loss 1.2092 (1.1770) loss_zs_kd 0.3177 (0.3123) loss_oracle 0.3393 (0.3751) acc 59.3750 (52.0982) kd_loss 1.1018 (1.0343) lr 1.8090e-03 eta 0:25:04
epoch [12/50] batch [160/319] time 0.138 (0.121) data 0.000 (0.003) loss 1.8055 (1.6991) ce_loss 1.3613 (1.2558) teacher_loss 1.2640 (1.1715) loss_zs_kd 0.3710 (0.3116) loss_oracle 0.3560 (0.3717) acc 53.1250 (52.4414) kd_loss 0.9050 (1.0318) lr 1.8090e-03 eta 0:24:42
epoch [12/50] batch [180/319] time 0.154 (0.123) data 0.000 (0.003) loss 1.6312 (1.6941) ce_loss 1.2861 (1.2539) teacher_loss 1.0490 (1.1638) loss_zs_kd 0.3041 (0.3142) loss_oracle 0.4302 (0.3731) acc 40.6250 (52.4826) kd_loss 1.0427 (1.0316) lr 1.8090e-03 eta 0:25:06
epoch [12/50] batch [200/319] time 0.156 (0.126) data 0.000 (0.003) loss 1.9415 (1.6881) ce_loss 1.4385 (1.2505) teacher_loss 1.3995 (1.1592) loss_zs_kd 0.2828 (0.3127) loss_oracle 0.4007 (0.3725) acc 34.3750 (52.5000) kd_loss 1.0389 (1.0301) lr 1.8090e-03 eta 0:25:37
epoch [12/50] batch [220/319] time 0.118 (0.127) data 0.000 (0.003) loss 1.5417 (1.6876) ce_loss 1.0234 (1.2480) teacher_loss 1.0466 (1.1566) loss_zs_kd 0.2766 (0.3152) loss_oracle 0.3567 (0.3734) acc 59.3750 (52.3864) kd_loss 1.0337 (1.0313) lr 1.8090e-03 eta 0:25:55
epoch [12/50] batch [240/319] time 0.109 (0.126) data 0.000 (0.002) loss 1.7367 (1.6870) ce_loss 1.2773 (1.2474) teacher_loss 1.1654 (1.1547) loss_zs_kd 0.3688 (0.3157) loss_oracle 0.3869 (0.3744) acc 53.1250 (52.3568) kd_loss 1.0683 (1.0338) lr 1.8090e-03 eta 0:25:39
epoch [12/50] batch [260/319] time 0.157 (0.126) data 0.000 (0.002) loss 1.6129 (1.6787) ce_loss 1.1572 (1.2412) teacher_loss 1.1251 (1.1475) loss_zs_kd 0.3022 (0.3152) loss_oracle 0.3366 (0.3735) acc 56.2500 (52.6683) kd_loss 1.0779 (1.0386) lr 1.8090e-03 eta 0:25:40
epoch [12/50] batch [280/319] time 0.152 (0.128) data 0.000 (0.002) loss 1.3898 (1.6737) ce_loss 1.0059 (1.2394) teacher_loss 0.8966 (1.1439) loss_zs_kd 0.2906 (0.3149) loss_oracle 0.3479 (0.3723) acc 65.6250 (52.7790) kd_loss 1.1091 (1.0421) lr 1.8090e-03 eta 0:25:59
epoch [12/50] batch [300/319] time 0.153 (0.130) data 0.000 (0.002) loss 1.6556 (1.6707) ce_loss 1.2744 (1.2379) teacher_loss 1.1420 (1.1418) loss_zs_kd 0.3349 (0.3151) loss_oracle 0.3462 (0.3713) acc 46.8750 (52.7604) kd_loss 1.1132 (1.0459) lr 1.8090e-03 eta 0:26:15
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,442
* accuracy: 55.8%
* error: 44.2%
* macro_f1: 46.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,670
* accuracy: 48.0%
* error: 52.0%
* macro_f1: 20.3%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      55.8%, epoch: 12 *******
******* Domain 2 best val test acc: 48.0%, epoch: 12 *******
******* Domain 2 best test acc:     48.0%, epoch: 12 *******
epoch [13/50] batch [20/319] time 0.142 (0.161) data 0.000 (0.035) loss 1.5653 (1.6887) ce_loss 1.2031 (1.2970) teacher_loss 1.0250 (1.1928) loss_zs_kd 0.3322 (0.3303) loss_oracle 0.3743 (0.3307) acc 59.3750 (51.7188) kd_loss 1.1972 (1.1477) lr 1.7705e-03 eta 0:32:31
epoch [13/50] batch [40/319] time 0.144 (0.137) data 0.000 (0.017) loss 2.0230 (1.6368) ce_loss 1.4385 (1.2306) teacher_loss 1.4564 (1.1217) loss_zs_kd 0.3116 (0.3263) loss_oracle 0.4108 (0.3519) acc 46.8750 (53.6719) kd_loss 1.0384 (1.1247) lr 1.7705e-03 eta 0:27:37
epoch [13/50] batch [60/319] time 0.144 (0.138) data 0.000 (0.012) loss 1.8749 (1.6600) ce_loss 1.5332 (1.2473) teacher_loss 1.3618 (1.1393) loss_zs_kd 0.3286 (0.3234) loss_oracle 0.3487 (0.3590) acc 43.7500 (52.9167) kd_loss 1.0101 (1.1111) lr 1.7705e-03 eta 0:27:40
epoch [13/50] batch [80/319] time 0.158 (0.141) data 0.000 (0.009) loss 1.3962 (1.6626) ce_loss 1.0195 (1.2505) teacher_loss 0.9679 (1.1470) loss_zs_kd 0.2721 (0.3259) loss_oracle 0.2922 (0.3527) acc 65.6250 (52.8906) kd_loss 1.1281 (1.1138) lr 1.7705e-03 eta 0:28:17
epoch [13/50] batch [100/319] time 0.090 (0.139) data 0.000 (0.007) loss 1.6482 (1.6572) ce_loss 1.3086 (1.2446) teacher_loss 1.1920 (1.1425) loss_zs_kd 0.3265 (0.3255) loss_oracle 0.2930 (0.3519) acc 43.7500 (53.1875) kd_loss 1.0438 (1.1038) lr 1.7705e-03 eta 0:27:45
epoch [13/50] batch [120/319] time 0.153 (0.138) data 0.000 (0.006) loss 1.5998 (1.6530) ce_loss 1.2725 (1.2389) teacher_loss 1.1134 (1.1388) loss_zs_kd 0.2761 (0.3261) loss_oracle 0.3484 (0.3512) acc 40.6250 (53.3594) kd_loss 1.0378 (1.0983) lr 1.7705e-03 eta 0:27:39
epoch [13/50] batch [140/319] time 0.158 (0.140) data 0.000 (0.005) loss 1.8947 (1.6534) ce_loss 1.4365 (1.2415) teacher_loss 1.3694 (1.1406) loss_zs_kd 0.3410 (0.3239) loss_oracle 0.3548 (0.3508) acc 40.6250 (53.0804) kd_loss 1.0570 (1.0942) lr 1.7705e-03 eta 0:28:00
epoch [13/50] batch [160/319] time 0.161 (0.142) data 0.000 (0.005) loss 1.7295 (1.6503) ce_loss 1.3135 (1.2403) teacher_loss 1.2136 (1.1395) loss_zs_kd 0.3727 (0.3230) loss_oracle 0.3295 (0.3493) acc 56.2500 (52.9297) kd_loss 1.0748 (1.0904) lr 1.7705e-03 eta 0:28:17
epoch [13/50] batch [180/319] time 0.147 (0.143) data 0.000 (0.004) loss 1.4974 (1.6563) ce_loss 1.0898 (1.2440) teacher_loss 0.9557 (1.1472) loss_zs_kd 0.2982 (0.3235) loss_oracle 0.3926 (0.3473) acc 53.1250 (53.0382) kd_loss 1.0747 (1.0930) lr 1.7705e-03 eta 0:28:28
epoch [13/50] batch [200/319] time 0.100 (0.141) data 0.000 (0.004) loss 1.8456 (1.6622) ce_loss 1.4492 (1.2508) teacher_loss 1.3706 (1.1553) loss_zs_kd 0.2721 (0.3216) loss_oracle 0.3390 (0.3461) acc 40.6250 (52.8281) kd_loss 1.0124 (1.0924) lr 1.7705e-03 eta 0:28:02
epoch [13/50] batch [220/319] time 0.069 (0.138) data 0.000 (0.003) loss 1.8999 (1.6616) ce_loss 1.4023 (1.2476) teacher_loss 1.3499 (1.1533) loss_zs_kd 0.3380 (0.3203) loss_oracle 0.3811 (0.3482) acc 46.8750 (52.7983) kd_loss 1.0240 (1.0885) lr 1.7705e-03 eta 0:27:25
epoch [13/50] batch [240/319] time 0.185 (0.140) data 0.000 (0.003) loss 1.6256 (1.6671) ce_loss 1.2051 (1.2507) teacher_loss 1.0832 (1.1549) loss_zs_kd 0.2946 (0.3209) loss_oracle 0.3950 (0.3518) acc 62.5000 (52.4870) kd_loss 0.9853 (1.0852) lr 1.7705e-03 eta 0:27:43
epoch [13/50] batch [260/319] time 0.178 (0.140) data 0.000 (0.003) loss 1.6562 (1.6712) ce_loss 1.2432 (1.2500) teacher_loss 1.1860 (1.1573) loss_zs_kd 0.3386 (0.3201) loss_oracle 0.3009 (0.3538) acc 56.2500 (52.5240) kd_loss 1.0368 (1.0786) lr 1.7705e-03 eta 0:27:41
epoch [13/50] batch [280/319] time 0.087 (0.141) data 0.000 (0.003) loss 1.6555 (1.6704) ce_loss 1.3281 (1.2495) teacher_loss 1.1876 (1.1574) loss_zs_kd 0.3774 (0.3188) loss_oracle 0.2792 (0.3536) acc 28.1250 (52.4665) kd_loss 1.0112 (1.0771) lr 1.7705e-03 eta 0:27:44
epoch [13/50] batch [300/319] time 0.147 (0.139) data 0.000 (0.003) loss 1.6432 (1.6691) ce_loss 1.1299 (1.2466) teacher_loss 1.0984 (1.1546) loss_zs_kd 0.3369 (0.3184) loss_oracle 0.3763 (0.3553) acc 65.6250 (52.4271) kd_loss 1.0222 (1.0750) lr 1.7705e-03 eta 0:27:24
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,419
* accuracy: 55.3%
* error: 44.7%
* macro_f1: 45.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,478
* accuracy: 46.0%
* error: 54.0%
* macro_f1: 20.7%
******* Domain 2 best val acc:      55.8%, epoch: 12 *******
******* Domain 2 best val test acc: 48.0%, epoch: 12 *******
******* Domain 2 best test acc:     48.0%, epoch: 12 *******
epoch [14/50] batch [20/319] time 0.157 (0.181) data 0.000 (0.032) loss 1.5951 (1.6687) ce_loss 1.1436 (1.2428) teacher_loss 1.0482 (1.1622) loss_zs_kd 0.3702 (0.3153) loss_oracle 0.3618 (0.3489) acc 62.5000 (51.8750) kd_loss 1.2343 (1.1249) lr 1.7290e-03 eta 0:35:31
epoch [14/50] batch [40/319] time 0.089 (0.161) data 0.000 (0.016) loss 1.6373 (1.6790) ce_loss 1.1484 (1.2332) teacher_loss 1.1208 (1.1623) loss_zs_kd 0.2641 (0.3246) loss_oracle 0.3845 (0.3544) acc 50.0000 (52.3438) kd_loss 1.0765 (1.0861) lr 1.7290e-03 eta 0:31:36
epoch [14/50] batch [60/319] time 0.078 (0.145) data 0.000 (0.011) loss 1.6800 (1.6974) ce_loss 1.2080 (1.2423) teacher_loss 1.1295 (1.1773) loss_zs_kd 0.3951 (0.3218) loss_oracle 0.3529 (0.3592) acc 46.8750 (51.5625) kd_loss 0.9637 (1.0682) lr 1.7290e-03 eta 0:28:22
epoch [14/50] batch [80/319] time 0.131 (0.152) data 0.000 (0.008) loss 1.7970 (1.6910) ce_loss 1.4248 (1.2452) teacher_loss 1.2448 (1.1739) loss_zs_kd 0.3507 (0.3163) loss_oracle 0.3768 (0.3590) acc 43.7500 (51.0547) kd_loss 1.0492 (1.0715) lr 1.7290e-03 eta 0:29:40
epoch [14/50] batch [100/319] time 0.192 (0.144) data 0.000 (0.007) loss 1.6414 (1.6980) ce_loss 1.1113 (1.2526) teacher_loss 1.1122 (1.1765) loss_zs_kd 0.2917 (0.3180) loss_oracle 0.3834 (0.3625) acc 59.3750 (51.0938) kd_loss 1.1529 (1.0723) lr 1.7290e-03 eta 0:28:08
epoch [14/50] batch [120/319] time 0.090 (0.148) data 0.001 (0.005) loss 1.5091 (1.6965) ce_loss 1.0059 (1.2458) teacher_loss 0.8894 (1.1689) loss_zs_kd 0.3415 (0.3204) loss_oracle 0.4489 (0.3673) acc 71.8750 (51.5625) kd_loss 1.0179 (1.0671) lr 1.7290e-03 eta 0:28:47
epoch [14/50] batch [140/319] time 0.118 (0.143) data 0.000 (0.005) loss 1.8951 (1.7006) ce_loss 1.3994 (1.2465) teacher_loss 1.3697 (1.1668) loss_zs_kd 0.3209 (0.3206) loss_oracle 0.3650 (0.3735) acc 53.1250 (51.1607) kd_loss 0.9010 (1.0557) lr 1.7290e-03 eta 0:27:44
epoch [14/50] batch [160/319] time 0.151 (0.141) data 0.000 (0.004) loss 1.8190 (1.7092) ce_loss 1.3359 (1.2518) teacher_loss 1.3184 (1.1743) loss_zs_kd 0.3200 (0.3218) loss_oracle 0.3407 (0.3740) acc 46.8750 (51.0352) kd_loss 1.0847 (1.0540) lr 1.7290e-03 eta 0:27:18
epoch [14/50] batch [180/319] time 0.143 (0.142) data 0.001 (0.004) loss 1.5686 (1.7031) ce_loss 1.1826 (1.2467) teacher_loss 1.0223 (1.1711) loss_zs_kd 0.2972 (0.3227) loss_oracle 0.3976 (0.3707) acc 46.8750 (51.6493) kd_loss 1.0320 (1.0581) lr 1.7290e-03 eta 0:27:28
epoch [14/50] batch [200/319] time 0.161 (0.143) data 0.000 (0.003) loss 1.6977 (1.6987) ce_loss 1.1729 (1.2408) teacher_loss 1.1354 (1.1667) loss_zs_kd 0.3730 (0.3231) loss_oracle 0.3759 (0.3705) acc 65.6250 (51.9844) kd_loss 1.0663 (1.0590) lr 1.7290e-03 eta 0:27:37
epoch [14/50] batch [220/319] time 0.136 (0.144) data 0.000 (0.003) loss 1.6893 (1.6973) ce_loss 1.2168 (1.2413) teacher_loss 1.1611 (1.1677) loss_zs_kd 0.2900 (0.3211) loss_oracle 0.3832 (0.3691) acc 59.3750 (51.9460) kd_loss 1.0159 (1.0595) lr 1.7290e-03 eta 0:27:43
epoch [14/50] batch [240/319] time 0.151 (0.143) data 0.000 (0.003) loss 1.6799 (1.6933) ce_loss 1.2891 (1.2394) teacher_loss 1.1395 (1.1646) loss_zs_kd 0.3528 (0.3201) loss_oracle 0.3640 (0.3687) acc 56.2500 (52.1094) kd_loss 1.0048 (1.0582) lr 1.7290e-03 eta 0:27:36
epoch [14/50] batch [260/319] time 0.141 (0.144) data 0.000 (0.003) loss 1.5408 (1.6875) ce_loss 1.1475 (1.2375) teacher_loss 1.0858 (1.1607) loss_zs_kd 0.2854 (0.3189) loss_oracle 0.3123 (0.3674) acc 53.1250 (52.1875) kd_loss 1.0414 (1.0588) lr 1.7290e-03 eta 0:27:40
epoch [14/50] batch [280/319] time 0.143 (0.143) data 0.000 (0.003) loss 1.6533 (1.6847) ce_loss 1.2012 (1.2358) teacher_loss 1.0859 (1.1582) loss_zs_kd 0.3268 (0.3197) loss_oracle 0.4040 (0.3667) acc 53.1250 (52.3661) kd_loss 0.9987 (1.0571) lr 1.7290e-03 eta 0:27:33
epoch [14/50] batch [300/319] time 0.156 (0.142) data 0.000 (0.002) loss 1.7424 (1.6835) ce_loss 1.3037 (1.2352) teacher_loss 1.2269 (1.1569) loss_zs_kd 0.2795 (0.3180) loss_oracle 0.3757 (0.3676) acc 50.0000 (52.3438) kd_loss 1.0249 (1.0552) lr 1.7290e-03 eta 0:27:17
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,427
* accuracy: 55.4%
* error: 44.6%
* macro_f1: 45.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,635
* accuracy: 47.6%
* error: 52.4%
* macro_f1: 21.0%
******* Domain 2 best val acc:      55.8%, epoch: 12 *******
******* Domain 2 best val test acc: 48.0%, epoch: 12 *******
******* Domain 2 best test acc:     48.0%, epoch: 12 *******
epoch [15/50] batch [20/319] time 0.083 (0.134) data 0.000 (0.025) loss 1.8431 (1.6766) ce_loss 1.4814 (1.2702) teacher_loss 1.4131 (1.1690) loss_zs_kd 0.2876 (0.3106) loss_oracle 0.2862 (0.3523) acc 40.6250 (50.3125) kd_loss 1.1193 (1.0449) lr 1.6845e-03 eta 0:25:39
epoch [15/50] batch [40/319] time 0.120 (0.118) data 0.000 (0.013) loss 1.4956 (1.6613) ce_loss 1.1719 (1.2651) teacher_loss 1.0299 (1.1480) loss_zs_kd 0.2660 (0.3145) loss_oracle 0.3327 (0.3561) acc 46.8750 (49.6875) kd_loss 1.0914 (1.0495) lr 1.6845e-03 eta 0:22:27
epoch [15/50] batch [60/319] time 0.105 (0.112) data 0.000 (0.008) loss 1.8910 (1.6775) ce_loss 1.2891 (1.2555) teacher_loss 1.3631 (1.1593) loss_zs_kd 0.3540 (0.3251) loss_oracle 0.3509 (0.3557) acc 40.6250 (50.6771) kd_loss 1.0255 (1.0420) lr 1.6845e-03 eta 0:21:15
epoch [15/50] batch [80/319] time 0.076 (0.111) data 0.000 (0.006) loss 1.5387 (1.6828) ce_loss 1.0732 (1.2476) teacher_loss 0.9729 (1.1477) loss_zs_kd 0.3367 (0.3332) loss_oracle 0.3974 (0.3686) acc 59.3750 (51.4844) kd_loss 1.0461 (1.0328) lr 1.6845e-03 eta 0:21:08
epoch [15/50] batch [100/319] time 0.159 (0.114) data 0.000 (0.005) loss 1.5228 (1.6780) ce_loss 1.1172 (1.2444) teacher_loss 0.9689 (1.1390) loss_zs_kd 0.2698 (0.3313) loss_oracle 0.4190 (0.3733) acc 59.3750 (51.5000) kd_loss 1.0934 (1.0337) lr 1.6845e-03 eta 0:21:40
epoch [15/50] batch [120/319] time 0.092 (0.118) data 0.000 (0.004) loss 1.5648 (1.6770) ce_loss 1.0654 (1.2406) teacher_loss 0.9838 (1.1352) loss_zs_kd 0.3459 (0.3324) loss_oracle 0.4081 (0.3756) acc 65.6250 (51.5885) kd_loss 1.0149 (1.0306) lr 1.6845e-03 eta 0:22:17
epoch [15/50] batch [140/319] time 0.153 (0.118) data 0.000 (0.004) loss 1.8332 (1.6790) ce_loss 1.3018 (1.2385) teacher_loss 1.2680 (1.1365) loss_zs_kd 0.4171 (0.3314) loss_oracle 0.3567 (0.3768) acc 46.8750 (51.9196) kd_loss 1.0024 (1.0324) lr 1.6845e-03 eta 0:22:15
epoch [15/50] batch [160/319] time 0.156 (0.122) data 0.000 (0.003) loss 1.5038 (1.6695) ce_loss 1.0098 (1.2291) teacher_loss 0.9405 (1.1281) loss_zs_kd 0.3403 (0.3334) loss_oracle 0.3932 (0.3747) acc 71.8750 (52.5195) kd_loss 1.1125 (1.0352) lr 1.6845e-03 eta 0:23:02
epoch [15/50] batch [180/319] time 0.157 (0.125) data 0.000 (0.003) loss 1.5597 (1.6560) ce_loss 1.1670 (1.2158) teacher_loss 1.0886 (1.1151) loss_zs_kd 0.2960 (0.3355) loss_oracle 0.3231 (0.3731) acc 53.1250 (53.1944) kd_loss 0.8243 (1.0315) lr 1.6845e-03 eta 0:23:37
epoch [15/50] batch [200/319] time 0.159 (0.128) data 0.000 (0.003) loss 1.9367 (1.6727) ce_loss 1.3975 (1.2274) teacher_loss 1.3295 (1.1295) loss_zs_kd 0.2899 (0.3343) loss_oracle 0.4623 (0.3760) acc 50.0000 (52.9844) kd_loss 0.9621 (1.0259) lr 1.6845e-03 eta 0:24:07
epoch [15/50] batch [220/319] time 0.148 (0.130) data 0.000 (0.003) loss 1.7466 (1.6779) ce_loss 1.2715 (1.2307) teacher_loss 1.1853 (1.1334) loss_zs_kd 0.3161 (0.3329) loss_oracle 0.4032 (0.3781) acc 46.8750 (52.6989) kd_loss 1.0579 (1.0242) lr 1.6845e-03 eta 0:24:29
epoch [15/50] batch [240/319] time 0.094 (0.131) data 0.000 (0.002) loss 1.5562 (1.6769) ce_loss 1.1680 (1.2283) teacher_loss 1.0267 (1.1321) loss_zs_kd 0.3521 (0.3329) loss_oracle 0.3534 (0.3783) acc 59.3750 (52.8385) kd_loss 1.0167 (1.0233) lr 1.6845e-03 eta 0:24:34
epoch [15/50] batch [260/319] time 0.138 (0.130) data 0.000 (0.002) loss 1.7556 (1.6840) ce_loss 1.1895 (1.2328) teacher_loss 1.2442 (1.1386) loss_zs_kd 0.3108 (0.3339) loss_oracle 0.3560 (0.3785) acc 46.8750 (52.6562) kd_loss 1.0901 (1.0263) lr 1.6845e-03 eta 0:24:16
epoch [15/50] batch [280/319] time 0.078 (0.128) data 0.000 (0.002) loss 1.5539 (1.6848) ce_loss 1.1387 (1.2343) teacher_loss 1.0423 (1.1400) loss_zs_kd 0.3490 (0.3342) loss_oracle 0.3370 (0.3777) acc 56.2500 (52.6228) kd_loss 1.1087 (1.0300) lr 1.6845e-03 eta 0:23:56
epoch [15/50] batch [300/319] time 0.213 (0.127) data 0.000 (0.002) loss 1.7319 (1.6785) ce_loss 1.3447 (1.2308) teacher_loss 1.1738 (1.1347) loss_zs_kd 0.3335 (0.3340) loss_oracle 0.3913 (0.3768) acc 46.8750 (52.8958) kd_loss 1.0622 (1.0354) lr 1.6845e-03 eta 0:23:42
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,460
* accuracy: 56.2%
* error: 43.8%
* macro_f1: 46.2%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,610
* accuracy: 47.4%
* error: 52.6%
* macro_f1: 19.9%
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.0%, epoch: 12 *******
epoch [16/50] batch [20/319] time 0.138 (0.143) data 0.000 (0.032) loss 1.4513 (1.6780) ce_loss 0.9668 (1.2386) teacher_loss 0.9038 (1.1713) loss_zs_kd 0.2925 (0.3099) loss_oracle 0.4013 (0.3518) acc 65.6250 (51.5625) kd_loss 1.0355 (1.0975) lr 1.6374e-03 eta 0:26:32
epoch [16/50] batch [40/319] time 0.143 (0.134) data 0.000 (0.016) loss 1.9037 (1.6574) ce_loss 1.5273 (1.2337) teacher_loss 1.4147 (1.1463) loss_zs_kd 0.3047 (0.3113) loss_oracle 0.3367 (0.3554) acc 46.8750 (53.6719) kd_loss 1.0263 (1.0859) lr 1.6374e-03 eta 0:24:51
epoch [16/50] batch [60/319] time 0.149 (0.134) data 0.000 (0.011) loss 1.4244 (1.6519) ce_loss 0.9546 (1.2253) teacher_loss 0.9290 (1.1379) loss_zs_kd 0.3331 (0.3146) loss_oracle 0.3288 (0.3567) acc 68.7500 (53.5938) kd_loss 1.0581 (1.0707) lr 1.6374e-03 eta 0:24:47
epoch [16/50] batch [80/319] time 0.160 (0.139) data 0.000 (0.008) loss 1.4787 (1.6451) ce_loss 1.1777 (1.2203) teacher_loss 0.9758 (1.1328) loss_zs_kd 0.3321 (0.3166) loss_oracle 0.3368 (0.3540) acc 50.0000 (54.3750) kd_loss 1.0975 (1.0742) lr 1.6374e-03 eta 0:25:36
epoch [16/50] batch [100/319] time 0.156 (0.142) data 0.000 (0.007) loss 1.7069 (1.6587) ce_loss 1.3086 (1.2313) teacher_loss 1.2753 (1.1463) loss_zs_kd 0.2411 (0.3195) loss_oracle 0.3110 (0.3526) acc 50.0000 (53.8125) kd_loss 1.1096 (1.0731) lr 1.6374e-03 eta 0:26:07
epoch [16/50] batch [120/319] time 0.151 (0.144) data 0.000 (0.005) loss 1.5258 (1.6478) ce_loss 1.1230 (1.2188) teacher_loss 1.0330 (1.1372) loss_zs_kd 0.3525 (0.3172) loss_oracle 0.3166 (0.3521) acc 59.3750 (54.2708) kd_loss 1.0957 (1.0777) lr 1.6374e-03 eta 0:26:26
epoch [16/50] batch [140/319] time 0.154 (0.145) data 0.000 (0.005) loss 1.4725 (1.6606) ce_loss 1.0791 (1.2312) teacher_loss 0.9498 (1.1527) loss_zs_kd 0.3583 (0.3162) loss_oracle 0.3435 (0.3498) acc 62.5000 (53.6830) kd_loss 1.0127 (1.0883) lr 1.6374e-03 eta 0:26:36
epoch [16/50] batch [160/319] time 0.148 (0.143) data 0.000 (0.004) loss 1.6024 (1.6699) ce_loss 1.0742 (1.2404) teacher_loss 1.0893 (1.1655) loss_zs_kd 0.3060 (0.3140) loss_oracle 0.3601 (0.3473) acc 65.6250 (53.3008) kd_loss 1.1385 (1.0972) lr 1.6374e-03 eta 0:26:13
epoch [16/50] batch [180/319] time 0.149 (0.140) data 0.000 (0.004) loss 1.5733 (1.6626) ce_loss 1.1602 (1.2341) teacher_loss 1.0428 (1.1596) loss_zs_kd 0.2887 (0.3114) loss_oracle 0.3862 (0.3473) acc 50.0000 (53.4549) kd_loss 1.1103 (1.0988) lr 1.6374e-03 eta 0:25:36
epoch [16/50] batch [200/319] time 0.189 (0.145) data 0.000 (0.003) loss 1.5776 (1.6586) ce_loss 1.1475 (1.2336) teacher_loss 1.0719 (1.1545) loss_zs_kd 0.2762 (0.3125) loss_oracle 0.3676 (0.3478) acc 62.5000 (53.3906) kd_loss 1.0009 (1.0939) lr 1.6374e-03 eta 0:26:31
epoch [16/50] batch [220/319] time 0.092 (0.141) data 0.000 (0.003) loss 1.6617 (1.6590) ce_loss 1.1611 (1.2337) teacher_loss 1.0748 (1.1508) loss_zs_kd 0.3392 (0.3163) loss_oracle 0.4173 (0.3501) acc 53.1250 (53.3239) kd_loss 1.0663 (1.0920) lr 1.6374e-03 eta 0:25:42
epoch [16/50] batch [240/319] time 0.117 (0.138) data 0.000 (0.003) loss 1.7572 (1.6613) ce_loss 1.2520 (1.2359) teacher_loss 1.1437 (1.1480) loss_zs_kd 0.3931 (0.3204) loss_oracle 0.4169 (0.3531) acc 62.5000 (53.2422) kd_loss 0.8932 (1.0827) lr 1.6374e-03 eta 0:25:11
epoch [16/50] batch [260/319] time 0.123 (0.136) data 0.000 (0.003) loss 1.4866 (1.6636) ce_loss 1.0771 (1.2366) teacher_loss 0.9651 (1.1490) loss_zs_kd 0.2892 (0.3195) loss_oracle 0.3769 (0.3548) acc 53.1250 (53.0769) kd_loss 0.9437 (1.0776) lr 1.6374e-03 eta 0:24:42
epoch [16/50] batch [280/319] time 0.089 (0.133) data 0.000 (0.002) loss 1.9094 (1.6667) ce_loss 1.4463 (1.2385) teacher_loss 1.4361 (1.1520) loss_zs_kd 0.3396 (0.3191) loss_oracle 0.3035 (0.3552) acc 46.8750 (53.0246) kd_loss 1.1301 (1.0755) lr 1.6374e-03 eta 0:24:06
epoch [16/50] batch [300/319] time 0.100 (0.130) data 0.000 (0.002) loss 1.6705 (1.6627) ce_loss 1.2139 (1.2358) teacher_loss 1.1605 (1.1495) loss_zs_kd 0.3429 (0.3192) loss_oracle 0.3386 (0.3537) acc 53.1250 (53.0208) kd_loss 0.9800 (1.0743) lr 1.6374e-03 eta 0:23:34
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,342
* accuracy: 53.5%
* error: 46.5%
* macro_f1: 43.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,378
* accuracy: 45.0%
* error: 55.0%
* macro_f1: 19.9%
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.0%, epoch: 12 *******
epoch [17/50] batch [20/319] time 0.138 (0.184) data 0.000 (0.034) loss 1.5343 (1.6108) ce_loss 1.0918 (1.2086) teacher_loss 0.9403 (1.0815) loss_zs_kd 0.4319 (0.3143) loss_oracle 0.3781 (0.3722) acc 65.6250 (55.0000) kd_loss 1.0784 (1.0509) lr 1.5878e-03 eta 0:33:12
epoch [17/50] batch [40/319] time 0.200 (0.163) data 0.000 (0.017) loss 1.6696 (1.6365) ce_loss 1.2803 (1.2189) teacher_loss 1.0883 (1.1024) loss_zs_kd 0.3988 (0.3353) loss_oracle 0.3819 (0.3664) acc 50.0000 (54.5312) kd_loss 1.1052 (1.0690) lr 1.5878e-03 eta 0:29:20
epoch [17/50] batch [60/319] time 0.195 (0.156) data 0.001 (0.011) loss 1.9118 (1.6371) ce_loss 1.5068 (1.2203) teacher_loss 1.4530 (1.1098) loss_zs_kd 0.2933 (0.3374) loss_oracle 0.3122 (0.3586) acc 46.8750 (54.0625) kd_loss 1.0802 (1.0779) lr 1.5878e-03 eta 0:28:01
epoch [17/50] batch [80/319] time 0.067 (0.160) data 0.000 (0.009) loss 1.5084 (1.6215) ce_loss 1.0537 (1.2116) teacher_loss 0.9761 (1.0999) loss_zs_kd 0.3533 (0.3301) loss_oracle 0.3557 (0.3566) acc 59.3750 (54.2188) kd_loss 1.0652 (1.0842) lr 1.5878e-03 eta 0:28:39
epoch [17/50] batch [100/319] time 0.090 (0.147) data 0.000 (0.007) loss 1.6679 (1.6293) ce_loss 1.2764 (1.2207) teacher_loss 1.1195 (1.1077) loss_zs_kd 0.3890 (0.3245) loss_oracle 0.3540 (0.3593) acc 56.2500 (53.5938) kd_loss 1.0703 (1.0840) lr 1.5878e-03 eta 0:26:23
epoch [17/50] batch [120/319] time 0.137 (0.141) data 0.000 (0.006) loss 1.6329 (1.6467) ce_loss 1.2490 (1.2368) teacher_loss 1.1389 (1.1283) loss_zs_kd 0.3153 (0.3184) loss_oracle 0.3363 (0.3591) acc 46.8750 (53.1250) kd_loss 1.0663 (1.0798) lr 1.5878e-03 eta 0:25:07
epoch [17/50] batch [140/319] time 0.088 (0.136) data 0.000 (0.005) loss 1.7550 (1.6509) ce_loss 1.2998 (1.2412) teacher_loss 1.2373 (1.1334) loss_zs_kd 0.3836 (0.3187) loss_oracle 0.3259 (0.3581) acc 50.0000 (52.8795) kd_loss 0.9346 (1.0749) lr 1.5878e-03 eta 0:24:20
epoch [17/50] batch [160/319] time 0.084 (0.133) data 0.000 (0.004) loss 1.3947 (1.6513) ce_loss 1.0303 (1.2413) teacher_loss 0.8766 (1.1329) loss_zs_kd 0.2951 (0.3205) loss_oracle 0.3705 (0.3582) acc 59.3750 (52.9102) kd_loss 1.0458 (1.0745) lr 1.5878e-03 eta 0:23:40
epoch [17/50] batch [180/319] time 0.137 (0.131) data 0.000 (0.004) loss 1.5018 (1.6511) ce_loss 1.1211 (1.2414) teacher_loss 1.0120 (1.1316) loss_zs_kd 0.3287 (0.3234) loss_oracle 0.3254 (0.3579) acc 62.5000 (52.8646) kd_loss 1.0544 (1.0735) lr 1.5878e-03 eta 0:23:12
epoch [17/50] batch [200/319] time 0.103 (0.128) data 0.000 (0.004) loss 1.4257 (1.6518) ce_loss 0.9502 (1.2432) teacher_loss 0.8182 (1.1299) loss_zs_kd 0.3641 (0.3246) loss_oracle 0.4255 (0.3596) acc 62.5000 (52.7500) kd_loss 1.0638 (1.0729) lr 1.5878e-03 eta 0:22:43
epoch [17/50] batch [220/319] time 0.096 (0.126) data 0.000 (0.003) loss 1.6978 (1.6616) ce_loss 1.1816 (1.2502) teacher_loss 1.1458 (1.1378) loss_zs_kd 0.3925 (0.3245) loss_oracle 0.3558 (0.3615) acc 59.3750 (52.4432) kd_loss 1.0542 (1.0725) lr 1.5878e-03 eta 0:22:17
epoch [17/50] batch [240/319] time 0.085 (0.125) data 0.000 (0.003) loss 1.7706 (1.6605) ce_loss 1.4170 (1.2512) teacher_loss 1.1979 (1.1372) loss_zs_kd 0.4021 (0.3236) loss_oracle 0.3716 (0.3615) acc 46.8750 (52.2656) kd_loss 1.1164 (1.0733) lr 1.5878e-03 eta 0:22:01
epoch [17/50] batch [260/319] time 0.108 (0.123) data 0.000 (0.003) loss 1.7750 (1.6621) ce_loss 1.4121 (1.2529) teacher_loss 1.1083 (1.1343) loss_zs_kd 0.3845 (0.3271) loss_oracle 0.4745 (0.3643) acc 40.6250 (52.0913) kd_loss 1.0161 (1.0705) lr 1.5878e-03 eta 0:21:42
epoch [17/50] batch [280/319] time 0.088 (0.122) data 0.001 (0.003) loss 1.3063 (1.6583) ce_loss 0.9697 (1.2506) teacher_loss 0.7558 (1.1297) loss_zs_kd 0.3660 (0.3263) loss_oracle 0.3676 (0.3654) acc 59.3750 (52.0871) kd_loss 1.0594 (1.0669) lr 1.5878e-03 eta 0:21:27
epoch [17/50] batch [300/319] time 0.106 (0.120) data 0.000 (0.002) loss 1.8141 (1.6600) ce_loss 1.2598 (1.2495) teacher_loss 1.2853 (1.1307) loss_zs_kd 0.3784 (0.3274) loss_oracle 0.3396 (0.3656) acc 50.0000 (52.0938) kd_loss 1.1418 (1.0686) lr 1.5878e-03 eta 0:21:09
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,341
* accuracy: 53.5%
* error: 46.5%
* macro_f1: 43.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,021
* accuracy: 41.3%
* error: 58.7%
* macro_f1: 19.7%
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.0%, epoch: 12 *******
epoch [18/50] batch [20/319] time 0.119 (0.144) data 0.000 (0.031) loss 1.5492 (1.6177) ce_loss 1.1074 (1.1948) teacher_loss 0.9979 (1.0670) loss_zs_kd 0.3237 (0.3264) loss_oracle 0.3895 (0.3874) acc 59.3750 (56.4062) kd_loss 1.1437 (1.0600) lr 1.5358e-03 eta 0:25:13
epoch [18/50] batch [40/319] time 0.082 (0.121) data 0.000 (0.016) loss 1.5258 (1.6266) ce_loss 1.0947 (1.1982) teacher_loss 0.9851 (1.0832) loss_zs_kd 0.3605 (0.3269) loss_oracle 0.3604 (0.3800) acc 53.1250 (54.4531) kd_loss 1.0569 (1.0566) lr 1.5358e-03 eta 0:21:10
epoch [18/50] batch [60/319] time 0.149 (0.122) data 0.001 (0.011) loss 1.7969 (1.6380) ce_loss 1.2666 (1.2019) teacher_loss 1.2611 (1.0911) loss_zs_kd 0.3401 (0.3290) loss_oracle 0.3657 (0.3824) acc 53.1250 (54.1146) kd_loss 0.9786 (1.0546) lr 1.5358e-03 eta 0:21:19
epoch [18/50] batch [80/319] time 0.146 (0.126) data 0.000 (0.008) loss 1.5835 (1.6479) ce_loss 1.1992 (1.2160) teacher_loss 1.0181 (1.1092) loss_zs_kd 0.3533 (0.3262) loss_oracle 0.3887 (0.3756) acc 56.2500 (53.6328) kd_loss 1.0367 (1.0506) lr 1.5358e-03 eta 0:22:01
epoch [18/50] batch [100/319] time 0.142 (0.131) data 0.000 (0.006) loss 1.2529 (1.6547) ce_loss 0.8838 (1.2167) teacher_loss 0.7943 (1.1190) loss_zs_kd 0.2963 (0.3241) loss_oracle 0.3105 (0.3736) acc 71.8750 (53.7812) kd_loss 1.0506 (1.0422) lr 1.5358e-03 eta 0:22:50
epoch [18/50] batch [120/319] time 0.088 (0.129) data 0.000 (0.005) loss 1.8939 (1.6670) ce_loss 1.3428 (1.2243) teacher_loss 1.2915 (1.1311) loss_zs_kd 0.4417 (0.3256) loss_oracle 0.3815 (0.3731) acc 40.6250 (53.5156) kd_loss 1.0957 (1.0376) lr 1.5358e-03 eta 0:22:25
epoch [18/50] batch [140/319] time 0.138 (0.127) data 0.000 (0.005) loss 1.5260 (1.6648) ce_loss 1.1465 (1.2203) teacher_loss 0.9783 (1.1277) loss_zs_kd 0.3204 (0.3263) loss_oracle 0.3875 (0.3739) acc 56.2500 (53.7277) kd_loss 1.0457 (1.0408) lr 1.5358e-03 eta 0:21:55
epoch [18/50] batch [160/319] time 0.150 (0.126) data 0.000 (0.004) loss 1.7562 (1.6687) ce_loss 1.3496 (1.2254) teacher_loss 1.2454 (1.1341) loss_zs_kd 0.3179 (0.3243) loss_oracle 0.3518 (0.3725) acc 50.0000 (53.5156) kd_loss 1.0720 (1.0457) lr 1.5358e-03 eta 0:21:44
epoch [18/50] batch [180/319] time 0.147 (0.128) data 0.000 (0.004) loss 1.7266 (1.6657) ce_loss 1.2734 (1.2275) teacher_loss 1.2084 (1.1338) loss_zs_kd 0.3487 (0.3239) loss_oracle 0.3439 (0.3699) acc 50.0000 (53.3854) kd_loss 1.1264 (1.0532) lr 1.5358e-03 eta 0:22:06
epoch [18/50] batch [200/319] time 0.150 (0.129) data 0.000 (0.003) loss 1.6609 (1.6648) ce_loss 1.2373 (1.2282) teacher_loss 1.1348 (1.1361) loss_zs_kd 0.3065 (0.3226) loss_oracle 0.3729 (0.3673) acc 53.1250 (53.3438) kd_loss 1.0248 (1.0511) lr 1.5358e-03 eta 0:22:15
epoch [18/50] batch [220/319] time 0.102 (0.130) data 0.000 (0.003) loss 1.7674 (1.6652) ce_loss 1.2949 (1.2308) teacher_loss 1.2650 (1.1366) loss_zs_kd 0.3396 (0.3229) loss_oracle 0.3326 (0.3672) acc 46.8750 (53.2102) kd_loss 0.9987 (1.0490) lr 1.5358e-03 eta 0:22:22
epoch [18/50] batch [240/319] time 0.116 (0.129) data 0.000 (0.003) loss 1.6315 (1.6627) ce_loss 1.2031 (1.2292) teacher_loss 1.0577 (1.1316) loss_zs_kd 0.3161 (0.3246) loss_oracle 0.4158 (0.3688) acc 53.1250 (53.2031) kd_loss 1.1203 (1.0498) lr 1.5358e-03 eta 0:22:10
epoch [18/50] batch [260/319] time 0.105 (0.128) data 0.000 (0.003) loss 1.8150 (1.6620) ce_loss 1.3232 (1.2302) teacher_loss 1.3286 (1.1321) loss_zs_kd 0.3862 (0.3269) loss_oracle 0.2933 (0.3665) acc 43.7500 (52.9327) kd_loss 1.1059 (1.0554) lr 1.5358e-03 eta 0:21:58
epoch [18/50] batch [280/319] time 0.159 (0.129) data 0.000 (0.002) loss 1.8675 (1.6631) ce_loss 1.3232 (1.2351) teacher_loss 1.2464 (1.1349) loss_zs_kd 0.3115 (0.3270) loss_oracle 0.4653 (0.3647) acc 46.8750 (52.6228) kd_loss 1.1139 (1.0605) lr 1.5358e-03 eta 0:21:57
epoch [18/50] batch [300/319] time 0.143 (0.130) data 0.000 (0.002) loss 1.5756 (1.6623) ce_loss 1.1875 (1.2399) teacher_loss 1.0228 (1.1369) loss_zs_kd 0.3730 (0.3262) loss_oracle 0.3663 (0.3623) acc 59.3750 (52.3646) kd_loss 1.0493 (1.0638) lr 1.5358e-03 eta 0:22:10
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,359
* accuracy: 53.9%
* error: 46.1%
* macro_f1: 43.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 3,971
* accuracy: 40.8%
* error: 59.2%
* macro_f1: 20.1%
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.0%, epoch: 12 *******
epoch [19/50] batch [20/319] time 0.097 (0.137) data 0.000 (0.026) loss 1.3709 (1.6277) ce_loss 1.0166 (1.2174) teacher_loss 0.8853 (1.0918) loss_zs_kd 0.3034 (0.3297) loss_oracle 0.3339 (0.3711) acc 59.3750 (52.6562) kd_loss 1.0437 (1.0315) lr 1.4818e-03 eta 0:23:19
epoch [19/50] batch [40/319] time 0.141 (0.123) data 0.000 (0.013) loss 1.5267 (1.6418) ce_loss 1.1963 (1.2295) teacher_loss 0.9837 (1.1169) loss_zs_kd 0.2919 (0.3201) loss_oracle 0.3971 (0.3648) acc 46.8750 (52.6562) kd_loss 0.9500 (1.0420) lr 1.4818e-03 eta 0:20:49
epoch [19/50] batch [60/319] time 0.086 (0.115) data 0.000 (0.009) loss 1.4655 (1.6356) ce_loss 1.0205 (1.2310) teacher_loss 0.9896 (1.1035) loss_zs_kd 0.2677 (0.3260) loss_oracle 0.3421 (0.3691) acc 62.5000 (51.9792) kd_loss 1.0152 (1.0508) lr 1.4818e-03 eta 0:19:23
epoch [19/50] batch [80/319] time 0.142 (0.110) data 0.001 (0.007) loss 1.7775 (1.6315) ce_loss 1.2832 (1.2322) teacher_loss 1.2688 (1.1077) loss_zs_kd 0.3552 (0.3214) loss_oracle 0.3312 (0.3631) acc 56.2500 (52.1094) kd_loss 1.1393 (1.0554) lr 1.4818e-03 eta 0:18:29
epoch [19/50] batch [100/319] time 0.137 (0.110) data 0.000 (0.005) loss 1.6488 (1.6382) ce_loss 1.2607 (1.2402) teacher_loss 1.1337 (1.1169) loss_zs_kd 0.3427 (0.3248) loss_oracle 0.3438 (0.3590) acc 56.2500 (52.0000) kd_loss 1.0383 (1.0615) lr 1.4818e-03 eta 0:18:34
epoch [19/50] batch [120/319] time 0.140 (0.110) data 0.000 (0.005) loss 1.9152 (1.6379) ce_loss 1.5127 (1.2416) teacher_loss 1.4538 (1.1225) loss_zs_kd 0.2338 (0.3203) loss_oracle 0.3445 (0.3552) acc 31.2500 (51.8750) kd_loss 1.2189 (1.0688) lr 1.4818e-03 eta 0:18:28
epoch [19/50] batch [140/319] time 0.100 (0.109) data 0.000 (0.004) loss 1.4087 (1.6397) ce_loss 1.1318 (1.2445) teacher_loss 0.9177 (1.1280) loss_zs_kd 0.2804 (0.3167) loss_oracle 0.3508 (0.3534) acc 53.1250 (51.6071) kd_loss 1.0738 (1.0748) lr 1.4818e-03 eta 0:18:14
epoch [19/50] batch [160/319] time 0.145 (0.109) data 0.000 (0.003) loss 1.8532 (1.6392) ce_loss 1.3730 (1.2420) teacher_loss 1.3948 (1.1276) loss_zs_kd 0.2861 (0.3155) loss_oracle 0.3153 (0.3538) acc 46.8750 (51.8945) kd_loss 1.0157 (1.0719) lr 1.4818e-03 eta 0:18:19
epoch [19/50] batch [180/319] time 0.081 (0.111) data 0.000 (0.003) loss 1.5196 (1.6318) ce_loss 1.0635 (1.2353) teacher_loss 0.9494 (1.1189) loss_zs_kd 0.3013 (0.3161) loss_oracle 0.4195 (0.3550) acc 62.5000 (52.3958) kd_loss 1.0542 (1.0716) lr 1.4818e-03 eta 0:18:31
epoch [19/50] batch [200/319] time 0.100 (0.110) data 0.000 (0.003) loss 1.5899 (1.6322) ce_loss 1.2549 (1.2339) teacher_loss 1.0021 (1.1146) loss_zs_kd 0.3158 (0.3194) loss_oracle 0.4299 (0.3579) acc 46.8750 (52.3438) kd_loss 1.0690 (1.0679) lr 1.4818e-03 eta 0:18:18
epoch [19/50] batch [220/319] time 0.144 (0.110) data 0.000 (0.003) loss 1.6462 (1.6321) ce_loss 1.2217 (1.2290) teacher_loss 1.1257 (1.1127) loss_zs_kd 0.3089 (0.3211) loss_oracle 0.3660 (0.3589) acc 53.1250 (52.6562) kd_loss 1.1255 (1.0682) lr 1.4818e-03 eta 0:18:21
epoch [19/50] batch [240/319] time 0.190 (0.112) data 0.000 (0.002) loss 1.6409 (1.6341) ce_loss 1.3154 (1.2301) teacher_loss 1.1121 (1.1154) loss_zs_kd 0.2969 (0.3198) loss_oracle 0.3803 (0.3587) acc 46.8750 (52.7214) kd_loss 1.0410 (1.0685) lr 1.4818e-03 eta 0:18:36
epoch [19/50] batch [260/319] time 0.196 (0.114) data 0.000 (0.002) loss 1.7467 (1.6351) ce_loss 1.4131 (1.2314) teacher_loss 1.2544 (1.1181) loss_zs_kd 0.2643 (0.3186) loss_oracle 0.3602 (0.3577) acc 59.3750 (52.7163) kd_loss 1.0299 (1.0707) lr 1.4818e-03 eta 0:18:55
epoch [19/50] batch [280/319] time 0.187 (0.119) data 0.000 (0.002) loss 1.4849 (1.6343) ce_loss 1.1172 (1.2312) teacher_loss 1.0263 (1.1188) loss_zs_kd 0.3259 (0.3181) loss_oracle 0.2957 (0.3565) acc 53.1250 (52.5893) kd_loss 1.1306 (1.0716) lr 1.4818e-03 eta 0:19:45
epoch [19/50] batch [300/319] time 0.100 (0.118) data 0.000 (0.002) loss 1.7093 (1.6375) ce_loss 1.3760 (1.2320) teacher_loss 1.1330 (1.1196) loss_zs_kd 0.3021 (0.3188) loss_oracle 0.4253 (0.3585) acc 46.8750 (52.5729) kd_loss 1.0971 (1.0706) lr 1.4818e-03 eta 0:19:32
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,444
* accuracy: 55.8%
* error: 44.2%
* macro_f1: 46.6%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,585
* accuracy: 47.1%
* error: 52.9%
* macro_f1: 21.6%
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.0%, epoch: 12 *******
epoch [20/50] batch [20/319] time 0.093 (0.142) data 0.000 (0.030) loss 1.6170 (1.6572) ce_loss 1.2285 (1.2541) teacher_loss 1.0568 (1.1279) loss_zs_kd 0.3226 (0.3382) loss_oracle 0.3989 (0.3602) acc 46.8750 (50.7812) kd_loss 1.0571 (1.0932) lr 1.4258e-03 eta 0:23:17
epoch [20/50] batch [40/319] time 0.086 (0.123) data 0.000 (0.015) loss 1.4454 (1.6193) ce_loss 1.1387 (1.2369) teacher_loss 0.9770 (1.1062) loss_zs_kd 0.2699 (0.3258) loss_oracle 0.3334 (0.3502) acc 53.1250 (52.4219) kd_loss 1.1474 (1.0962) lr 1.4258e-03 eta 0:20:12
epoch [20/50] batch [60/319] time 0.108 (0.117) data 0.000 (0.010) loss 1.2692 (1.6360) ce_loss 0.9829 (1.2582) teacher_loss 0.8097 (1.1273) loss_zs_kd 0.2115 (0.3168) loss_oracle 0.3537 (0.3503) acc 59.3750 (51.1979) kd_loss 1.0248 (1.0732) lr 1.4258e-03 eta 0:19:10
epoch [20/50] batch [80/319] time 0.162 (0.120) data 0.000 (0.008) loss 1.5667 (1.6312) ce_loss 1.1221 (1.2513) teacher_loss 1.0030 (1.1224) loss_zs_kd 0.4027 (0.3186) loss_oracle 0.3624 (0.3495) acc 53.1250 (51.2109) kd_loss 1.1410 (1.0749) lr 1.4258e-03 eta 0:19:34
epoch [20/50] batch [100/319] time 0.085 (0.125) data 0.000 (0.006) loss 1.6417 (1.6241) ce_loss 1.2568 (1.2377) teacher_loss 1.0511 (1.1116) loss_zs_kd 0.2976 (0.3186) loss_oracle 0.4418 (0.3532) acc 50.0000 (51.3750) kd_loss 1.0496 (1.0650) lr 1.4258e-03 eta 0:20:24
epoch [20/50] batch [120/319] time 0.192 (0.130) data 0.000 (0.005) loss 1.5673 (1.6220) ce_loss 1.2363 (1.2279) teacher_loss 0.9848 (1.1038) loss_zs_kd 0.3321 (0.3221) loss_oracle 0.4164 (0.3571) acc 50.0000 (51.8750) kd_loss 0.9134 (1.0543) lr 1.4258e-03 eta 0:21:07
epoch [20/50] batch [140/319] time 0.174 (0.129) data 0.000 (0.005) loss 1.3927 (1.6222) ce_loss 1.0342 (1.2253) teacher_loss 0.8582 (1.1022) loss_zs_kd 0.3080 (0.3259) loss_oracle 0.3805 (0.3570) acc 59.3750 (52.0982) kd_loss 1.0385 (1.0501) lr 1.4258e-03 eta 0:20:57
epoch [20/50] batch [160/319] time 0.071 (0.135) data 0.000 (0.004) loss 1.5255 (1.6181) ce_loss 1.0664 (1.2226) teacher_loss 0.9469 (1.0970) loss_zs_kd 0.3914 (0.3267) loss_oracle 0.3830 (0.3577) acc 65.6250 (52.2070) kd_loss 1.0550 (1.0517) lr 1.4258e-03 eta 0:21:51
epoch [20/50] batch [180/319] time 0.080 (0.132) data 0.000 (0.004) loss 1.7120 (1.6287) ce_loss 1.3545 (1.2329) teacher_loss 1.2017 (1.1041) loss_zs_kd 0.3851 (0.3274) loss_oracle 0.3177 (0.3609) acc 40.6250 (51.5799) kd_loss 1.1040 (1.0538) lr 1.4258e-03 eta 0:21:22
epoch [20/50] batch [200/319] time 0.111 (0.130) data 0.000 (0.003) loss 1.7437 (1.6285) ce_loss 1.3721 (1.2351) teacher_loss 1.2366 (1.1039) loss_zs_kd 0.3801 (0.3265) loss_oracle 0.3170 (0.3614) acc 56.2500 (51.5469) kd_loss 1.0687 (1.0566) lr 1.4258e-03 eta 0:20:59
epoch [20/50] batch [220/319] time 0.119 (0.131) data 0.000 (0.003) loss 1.6129 (1.6258) ce_loss 1.1875 (1.2332) teacher_loss 1.0919 (1.1002) loss_zs_kd 0.3245 (0.3264) loss_oracle 0.3587 (0.3624) acc 62.5000 (51.8182) kd_loss 1.0165 (1.0538) lr 1.4258e-03 eta 0:21:07
epoch [20/50] batch [240/319] time 0.116 (0.130) data 0.000 (0.003) loss 1.6204 (1.6302) ce_loss 1.1406 (1.2379) teacher_loss 1.1243 (1.1037) loss_zs_kd 0.3123 (0.3268) loss_oracle 0.3400 (0.3631) acc 53.1250 (51.7188) kd_loss 1.0867 (1.0546) lr 1.4258e-03 eta 0:20:55
epoch [20/50] batch [260/319] time 0.099 (0.129) data 0.000 (0.003) loss 1.5650 (1.6279) ce_loss 1.1631 (1.2341) teacher_loss 1.0378 (1.1011) loss_zs_kd 0.2762 (0.3261) loss_oracle 0.3891 (0.3638) acc 46.8750 (51.9111) kd_loss 1.0895 (1.0567) lr 1.4258e-03 eta 0:20:38
epoch [20/50] batch [280/319] time 0.144 (0.128) data 0.000 (0.002) loss 1.6062 (1.6284) ce_loss 1.2217 (1.2341) teacher_loss 0.9881 (1.0993) loss_zs_kd 0.3788 (0.3273) loss_oracle 0.4287 (0.3655) acc 56.2500 (52.0424) kd_loss 1.0465 (1.0576) lr 1.4258e-03 eta 0:20:26
epoch [20/50] batch [300/319] time 0.099 (0.127) data 0.000 (0.002) loss 1.6559 (1.6302) ce_loss 1.2627 (1.2350) teacher_loss 1.1766 (1.1004) loss_zs_kd 0.3206 (0.3272) loss_oracle 0.3190 (0.3661) acc 53.1250 (52.1250) kd_loss 1.0626 (1.0584) lr 1.4258e-03 eta 0:20:14
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,452
* accuracy: 56.0%
* error: 44.0%
* macro_f1: 45.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,696
* accuracy: 48.2%
* error: 51.8%
* macro_f1: 20.6%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/terra_incognita/b32_ep50/ViT-B16/2/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.2%, epoch: 20 *******
epoch [21/50] batch [20/319] time 0.194 (0.206) data 0.000 (0.031) loss 1.8167 (1.6463) ce_loss 1.2705 (1.2160) teacher_loss 1.1592 (1.1081) loss_zs_kd 0.3819 (0.3545) loss_oracle 0.4666 (0.3609) acc 50.0000 (52.5000) kd_loss 1.1005 (1.0701) lr 1.3681e-03 eta 0:32:51
epoch [21/50] batch [40/319] time 0.152 (0.172) data 0.000 (0.015) loss 1.5403 (1.6418) ce_loss 1.2217 (1.2222) teacher_loss 1.0686 (1.1200) loss_zs_kd 0.2825 (0.3435) loss_oracle 0.3305 (0.3501) acc 56.2500 (52.6562) kd_loss 1.1464 (1.0729) lr 1.3681e-03 eta 0:27:15
epoch [21/50] batch [60/319] time 0.086 (0.154) data 0.000 (0.010) loss 1.5507 (1.6396) ce_loss 1.0830 (1.2197) teacher_loss 0.9692 (1.1091) loss_zs_kd 0.4001 (0.3441) loss_oracle 0.3814 (0.3584) acc 53.1250 (52.3438) kd_loss 1.1102 (1.0783) lr 1.3681e-03 eta 0:24:27
epoch [21/50] batch [80/319] time 0.147 (0.150) data 0.000 (0.008) loss 1.5102 (1.6495) ce_loss 0.9644 (1.2218) teacher_loss 0.9794 (1.1129) loss_zs_kd 0.2738 (0.3399) loss_oracle 0.3939 (0.3667) acc 68.7500 (51.9531) kd_loss 1.0354 (1.0650) lr 1.3681e-03 eta 0:23:43
epoch [21/50] batch [100/319] time 0.157 (0.150) data 0.000 (0.006) loss 1.6037 (1.6517) ce_loss 1.2090 (1.2238) teacher_loss 1.0434 (1.1157) loss_zs_kd 0.3292 (0.3370) loss_oracle 0.3957 (0.3676) acc 53.1250 (52.0625) kd_loss 1.0694 (1.0653) lr 1.3681e-03 eta 0:23:44
epoch [21/50] batch [120/319] time 0.154 (0.151) data 0.000 (0.005) loss 1.4240 (1.6409) ce_loss 1.1045 (1.2185) teacher_loss 0.9002 (1.1078) loss_zs_kd 0.3518 (0.3372) loss_oracle 0.3479 (0.3645) acc 50.0000 (52.3177) kd_loss 1.0845 (1.0660) lr 1.3681e-03 eta 0:23:45
epoch [21/50] batch [140/319] time 0.088 (0.147) data 0.000 (0.005) loss 1.7828 (1.6315) ce_loss 1.3281 (1.2098) teacher_loss 1.1639 (1.0982) loss_zs_kd 0.4086 (0.3387) loss_oracle 0.4147 (0.3640) acc 43.7500 (52.8795) kd_loss 1.0640 (1.0659) lr 1.3681e-03 eta 0:23:09
epoch [21/50] batch [160/319] time 0.150 (0.146) data 0.000 (0.004) loss 1.3927 (1.6290) ce_loss 1.0918 (1.2090) teacher_loss 0.8888 (1.0962) loss_zs_kd 0.3216 (0.3360) loss_oracle 0.3431 (0.3647) acc 65.6250 (53.2812) kd_loss 1.1039 (1.0634) lr 1.3681e-03 eta 0:22:55
epoch [21/50] batch [180/319] time 0.143 (0.145) data 0.000 (0.004) loss 1.7790 (1.6288) ce_loss 1.2734 (1.2075) teacher_loss 1.1686 (1.0914) loss_zs_kd 0.4114 (0.3389) loss_oracle 0.4047 (0.3680) acc 46.8750 (53.3854) kd_loss 1.0001 (1.0564) lr 1.3681e-03 eta 0:22:37
epoch [21/50] batch [200/319] time 0.154 (0.145) data 0.000 (0.003) loss 1.9877 (1.6394) ce_loss 1.5254 (1.2131) teacher_loss 1.4102 (1.0978) loss_zs_kd 0.3916 (0.3398) loss_oracle 0.3817 (0.3716) acc 53.1250 (53.3125) kd_loss 0.9408 (1.0522) lr 1.3681e-03 eta 0:22:41
epoch [21/50] batch [220/319] time 0.157 (0.146) data 0.000 (0.003) loss 1.5492 (1.6378) ce_loss 1.2061 (1.2118) teacher_loss 0.9986 (1.0964) loss_zs_kd 0.2942 (0.3389) loss_oracle 0.4035 (0.3719) acc 56.2500 (53.4233) kd_loss 1.0935 (1.0516) lr 1.3681e-03 eta 0:22:43
epoch [21/50] batch [240/319] time 0.153 (0.146) data 0.000 (0.003) loss 1.4776 (1.6361) ce_loss 1.0518 (1.2111) teacher_loss 0.9165 (1.0943) loss_zs_kd 0.3394 (0.3390) loss_oracle 0.3914 (0.3724) acc 53.1250 (53.4375) kd_loss 1.0505 (1.0495) lr 1.3681e-03 eta 0:22:45
epoch [21/50] batch [260/319] time 0.129 (0.144) data 0.000 (0.003) loss 1.7517 (1.6458) ce_loss 1.2852 (1.2193) teacher_loss 1.2124 (1.1006) loss_zs_kd 0.4005 (0.3403) loss_oracle 0.3390 (0.3750) acc 43.7500 (53.0409) kd_loss 0.9776 (1.0467) lr 1.3681e-03 eta 0:22:21
epoch [21/50] batch [280/319] time 0.161 (0.144) data 0.000 (0.002) loss 1.6526 (1.6488) ce_loss 1.2041 (1.2222) teacher_loss 1.1086 (1.1041) loss_zs_kd 0.3060 (0.3393) loss_oracle 0.3911 (0.3751) acc 56.2500 (52.7121) kd_loss 1.1058 (1.0470) lr 1.3681e-03 eta 0:22:15
epoch [21/50] batch [300/319] time 0.074 (0.144) data 0.000 (0.002) loss 1.3993 (1.6453) ce_loss 1.0283 (1.2189) teacher_loss 0.8165 (1.0994) loss_zs_kd 0.3276 (0.3380) loss_oracle 0.4191 (0.3769) acc 62.5000 (52.8958) kd_loss 0.9290 (1.0467) lr 1.3681e-03 eta 0:22:14
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,427
* accuracy: 55.4%
* error: 44.6%
* macro_f1: 46.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,302
* accuracy: 44.2%
* error: 55.8%
* macro_f1: 20.5%
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.2%, epoch: 20 *******
epoch [22/50] batch [20/319] time 0.155 (0.173) data 0.000 (0.023) loss 1.6334 (1.6166) ce_loss 1.2061 (1.1662) teacher_loss 1.0182 (1.0265) loss_zs_kd 0.4566 (0.3609) loss_oracle 0.3869 (0.4097) acc 56.2500 (55.6250) kd_loss 1.0635 (0.9902) lr 1.3090e-03 eta 0:26:34
epoch [22/50] batch [40/319] time 0.140 (0.162) data 0.000 (0.012) loss 1.5668 (1.6083) ce_loss 1.1875 (1.1715) teacher_loss 0.9660 (1.0196) loss_zs_kd 0.4085 (0.3632) loss_oracle 0.3965 (0.4071) acc 46.8750 (55.0000) kd_loss 1.1151 (1.0063) lr 1.3090e-03 eta 0:24:56
epoch [22/50] batch [60/319] time 0.151 (0.159) data 0.000 (0.008) loss 1.5060 (1.6167) ce_loss 1.0850 (1.1953) teacher_loss 0.8517 (1.0314) loss_zs_kd 0.3453 (0.3563) loss_oracle 0.4816 (0.4072) acc 50.0000 (53.6979) kd_loss 0.9737 (1.0069) lr 1.3090e-03 eta 0:24:22
epoch [22/50] batch [80/319] time 0.162 (0.158) data 0.000 (0.006) loss 2.0067 (1.6233) ce_loss 1.5439 (1.1968) teacher_loss 1.4577 (1.0422) loss_zs_kd 0.3692 (0.3549) loss_oracle 0.3644 (0.4036) acc 40.6250 (54.1406) kd_loss 0.9701 (1.0069) lr 1.3090e-03 eta 0:24:06
epoch [22/50] batch [100/319] time 0.102 (0.154) data 0.000 (0.005) loss 1.4634 (1.6254) ce_loss 1.1025 (1.2003) teacher_loss 0.9062 (1.0496) loss_zs_kd 0.3441 (0.3508) loss_oracle 0.3851 (0.4004) acc 56.2500 (53.4688) kd_loss 1.0170 (1.0069) lr 1.3090e-03 eta 0:23:31
epoch [22/50] batch [120/319] time 0.132 (0.148) data 0.000 (0.004) loss 1.8960 (1.6229) ce_loss 1.5107 (1.2003) teacher_loss 1.4516 (1.0468) loss_zs_kd 0.3387 (0.3506) loss_oracle 0.2750 (0.4008) acc 43.7500 (53.4115) kd_loss 0.9854 (1.0091) lr 1.3090e-03 eta 0:22:27
epoch [22/50] batch [140/319] time 0.152 (0.144) data 0.000 (0.004) loss 1.6362 (1.6286) ce_loss 1.2764 (1.2037) teacher_loss 1.0930 (1.0519) loss_zs_kd 0.3128 (0.3556) loss_oracle 0.3868 (0.3988) acc 43.7500 (53.3929) kd_loss 1.1113 (1.0115) lr 1.3090e-03 eta 0:21:56
epoch [22/50] batch [160/319] time 0.072 (0.144) data 0.000 (0.003) loss 1.6059 (1.6284) ce_loss 1.2861 (1.2087) teacher_loss 1.0337 (1.0535) loss_zs_kd 0.2675 (0.3529) loss_oracle 0.4385 (0.3985) acc 50.0000 (53.1055) kd_loss 0.9582 (1.0186) lr 1.3090e-03 eta 0:21:50
epoch [22/50] batch [180/319] time 0.191 (0.146) data 0.000 (0.003) loss 1.8538 (1.6236) ce_loss 1.4717 (1.2056) teacher_loss 1.3648 (1.0516) loss_zs_kd 0.3487 (0.3515) loss_oracle 0.3147 (0.3962) acc 46.8750 (53.2639) kd_loss 1.0562 (1.0218) lr 1.3090e-03 eta 0:22:03
epoch [22/50] batch [200/319] time 0.193 (0.145) data 0.000 (0.003) loss 1.6494 (1.6244) ce_loss 1.2031 (1.2112) teacher_loss 1.0632 (1.0541) loss_zs_kd 0.3395 (0.3487) loss_oracle 0.4164 (0.3959) acc 59.3750 (53.0000) kd_loss 1.0875 (1.0226) lr 1.3090e-03 eta 0:21:55
epoch [22/50] batch [220/319] time 0.092 (0.146) data 0.000 (0.002) loss 1.4783 (1.6246) ce_loss 1.0166 (1.2134) teacher_loss 0.9794 (1.0547) loss_zs_kd 0.2941 (0.3483) loss_oracle 0.3518 (0.3958) acc 62.5000 (52.9119) kd_loss 1.0144 (1.0247) lr 1.3090e-03 eta 0:21:56
epoch [22/50] batch [240/319] time 0.152 (0.145) data 0.000 (0.002) loss 1.8797 (1.6246) ce_loss 1.4346 (1.2126) teacher_loss 1.2974 (1.0554) loss_zs_kd 0.3685 (0.3487) loss_oracle 0.3981 (0.3948) acc 43.7500 (52.8516) kd_loss 1.0949 (1.0280) lr 1.3090e-03 eta 0:21:45
epoch [22/50] batch [260/319] time 0.155 (0.145) data 0.000 (0.002) loss 1.5863 (1.6274) ce_loss 1.3145 (1.2168) teacher_loss 1.0177 (1.0594) loss_zs_kd 0.3240 (0.3486) loss_oracle 0.4066 (0.3938) acc 46.8750 (52.6803) kd_loss 1.0906 (1.0277) lr 1.3090e-03 eta 0:21:47
epoch [22/50] batch [280/319] time 0.139 (0.145) data 0.000 (0.002) loss 1.3666 (1.6245) ce_loss 0.9966 (1.2148) teacher_loss 0.8367 (1.0575) loss_zs_kd 0.3194 (0.3479) loss_oracle 0.3701 (0.3931) acc 68.7500 (52.9464) kd_loss 1.1414 (1.0297) lr 1.3090e-03 eta 0:21:38
epoch [22/50] batch [300/319] time 0.118 (0.143) data 0.000 (0.002) loss 1.7891 (1.6255) ce_loss 1.3018 (1.2169) teacher_loss 1.1552 (1.0583) loss_zs_kd 0.4131 (0.3480) loss_oracle 0.4273 (0.3932) acc 50.0000 (52.8125) kd_loss 1.0443 (1.0314) lr 1.3090e-03 eta 0:21:22
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,347
* accuracy: 53.6%
* error: 46.4%
* macro_f1: 44.5%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 3,895
* accuracy: 40.0%
* error: 60.0%
* macro_f1: 19.4%
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.2%, epoch: 20 *******
epoch [23/50] batch [20/319] time 0.210 (0.169) data 0.000 (0.024) loss 1.9106 (1.6223) ce_loss 1.4053 (1.2360) teacher_loss 1.4357 (1.1137) loss_zs_kd 0.2739 (0.3202) loss_oracle 0.3379 (0.3485) acc 40.6250 (50.0000) kd_loss 1.0461 (1.1170) lr 1.2487e-03 eta 0:25:06
epoch [23/50] batch [40/319] time 0.198 (0.159) data 0.000 (0.012) loss 1.5906 (1.6091) ce_loss 1.2236 (1.2420) teacher_loss 1.0297 (1.1098) loss_zs_kd 0.3562 (0.3010) loss_oracle 0.3828 (0.3488) acc 59.3750 (51.1719) kd_loss 1.0900 (1.1117) lr 1.2487e-03 eta 0:23:36
epoch [23/50] batch [60/319] time 0.069 (0.162) data 0.000 (0.008) loss 1.8098 (1.5968) ce_loss 1.2441 (1.2266) teacher_loss 1.2568 (1.0797) loss_zs_kd 0.3662 (0.3140) loss_oracle 0.3699 (0.3601) acc 53.1250 (52.2396) kd_loss 1.0364 (1.0985) lr 1.2487e-03 eta 0:23:58
epoch [23/50] batch [80/319] time 0.162 (0.157) data 0.001 (0.006) loss 1.4718 (1.6059) ce_loss 1.1396 (1.2274) teacher_loss 0.9036 (1.0768) loss_zs_kd 0.3706 (0.3270) loss_oracle 0.3830 (0.3656) acc 56.2500 (52.2656) kd_loss 1.0434 (1.0897) lr 1.2487e-03 eta 0:23:10
epoch [23/50] batch [100/319] time 0.135 (0.152) data 0.000 (0.005) loss 1.5110 (1.6061) ce_loss 1.1768 (1.2389) teacher_loss 0.9917 (1.0803) loss_zs_kd 0.3423 (0.3267) loss_oracle 0.3481 (0.3624) acc 62.5000 (51.6875) kd_loss 0.9977 (1.0900) lr 1.2487e-03 eta 0:22:19
epoch [23/50] batch [120/319] time 0.128 (0.145) data 0.000 (0.004) loss 1.6190 (1.6062) ce_loss 1.2451 (1.2382) teacher_loss 1.0782 (1.0776) loss_zs_kd 0.3035 (0.3248) loss_oracle 0.3891 (0.3661) acc 50.0000 (51.6667) kd_loss 1.0731 (1.0895) lr 1.2487e-03 eta 0:21:19
epoch [23/50] batch [140/319] time 0.155 (0.143) data 0.000 (0.004) loss 1.4662 (1.6089) ce_loss 1.1699 (1.2383) teacher_loss 0.9444 (1.0809) loss_zs_kd 0.2966 (0.3247) loss_oracle 0.3734 (0.3657) acc 46.8750 (51.8750) kd_loss 1.0409 (1.0856) lr 1.2487e-03 eta 0:21:01
epoch [23/50] batch [160/319] time 0.138 (0.141) data 0.000 (0.003) loss 1.5053 (1.6149) ce_loss 1.0029 (1.2386) teacher_loss 0.9196 (1.0852) loss_zs_kd 0.3387 (0.3260) loss_oracle 0.4164 (0.3667) acc 59.3750 (51.9531) kd_loss 1.0541 (1.0819) lr 1.2487e-03 eta 0:20:37
epoch [23/50] batch [180/319] time 0.110 (0.138) data 0.000 (0.003) loss 1.7814 (1.6138) ce_loss 1.3174 (1.2359) teacher_loss 1.2515 (1.0826) loss_zs_kd 0.3117 (0.3282) loss_oracle 0.3740 (0.3671) acc 46.8750 (51.9792) kd_loss 1.0653 (1.0775) lr 1.2487e-03 eta 0:20:10
epoch [23/50] batch [200/319] time 0.105 (0.136) data 0.000 (0.003) loss 1.2489 (1.6142) ce_loss 0.8599 (1.2335) teacher_loss 0.7709 (1.0821) loss_zs_kd 0.2546 (0.3293) loss_oracle 0.3507 (0.3674) acc 59.3750 (52.0156) kd_loss 1.0381 (1.0729) lr 1.2487e-03 eta 0:19:44
epoch [23/50] batch [220/319] time 0.146 (0.136) data 0.000 (0.002) loss 1.7684 (1.6175) ce_loss 1.4297 (1.2338) teacher_loss 1.2036 (1.0822) loss_zs_kd 0.4012 (0.3317) loss_oracle 0.3642 (0.3694) acc 56.2500 (51.9460) kd_loss 0.9529 (1.0691) lr 1.2487e-03 eta 0:19:48
epoch [23/50] batch [240/319] time 0.096 (0.137) data 0.000 (0.002) loss 1.4897 (1.6226) ce_loss 1.2861 (1.2391) teacher_loss 0.9586 (1.0857) loss_zs_kd 0.3501 (0.3321) loss_oracle 0.3561 (0.3709) acc 46.8750 (51.9141) kd_loss 1.0704 (1.0670) lr 1.2487e-03 eta 0:19:47
epoch [23/50] batch [260/319] time 0.141 (0.134) data 0.000 (0.002) loss 1.5584 (1.6234) ce_loss 1.2529 (1.2401) teacher_loss 1.0393 (1.0846) loss_zs_kd 0.3501 (0.3326) loss_oracle 0.3440 (0.3725) acc 56.2500 (51.9591) kd_loss 1.0100 (1.0654) lr 1.2487e-03 eta 0:19:25
epoch [23/50] batch [280/319] time 0.124 (0.134) data 0.000 (0.002) loss 1.4386 (1.6259) ce_loss 1.0479 (1.2395) teacher_loss 0.8602 (1.0844) loss_zs_kd 0.4112 (0.3348) loss_oracle 0.3728 (0.3741) acc 53.1250 (52.0312) kd_loss 0.9870 (1.0625) lr 1.2487e-03 eta 0:19:15
epoch [23/50] batch [300/319] time 0.108 (0.132) data 0.000 (0.002) loss 1.6977 (1.6226) ce_loss 1.2432 (1.2395) teacher_loss 1.1511 (1.0807) loss_zs_kd 0.3615 (0.3352) loss_oracle 0.3659 (0.3743) acc 53.1250 (51.9688) kd_loss 1.1274 (1.0624) lr 1.2487e-03 eta 0:19:00
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,370
* accuracy: 54.1%
* error: 45.9%
* macro_f1: 46.8%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,445
* accuracy: 45.7%
* error: 54.3%
* macro_f1: 21.5%
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.2%, epoch: 20 *******
epoch [24/50] batch [20/319] time 0.105 (0.124) data 0.000 (0.028) loss 1.5331 (1.7199) ce_loss 1.0732 (1.2599) teacher_loss 0.9657 (1.1238) loss_zs_kd 0.3814 (0.3625) loss_oracle 0.3767 (0.4149) acc 59.3750 (51.7188) kd_loss 0.9890 (0.9840) lr 1.1874e-03 eta 0:17:43
epoch [24/50] batch [40/319] time 0.094 (0.109) data 0.000 (0.014) loss 1.7790 (1.6851) ce_loss 1.4121 (1.2292) teacher_loss 1.2631 (1.0876) loss_zs_kd 0.3307 (0.3560) loss_oracle 0.3505 (0.4195) acc 46.8750 (53.2031) kd_loss 0.9960 (1.0085) lr 1.1874e-03 eta 0:15:31
epoch [24/50] batch [60/319] time 0.138 (0.107) data 0.000 (0.009) loss 1.7924 (1.6952) ce_loss 1.3096 (1.2415) teacher_loss 1.2112 (1.1119) loss_zs_kd 0.4487 (0.3541) loss_oracle 0.3569 (0.4062) acc 37.5000 (52.8646) kd_loss 1.0859 (1.0205) lr 1.1874e-03 eta 0:15:12
epoch [24/50] batch [80/319] time 0.139 (0.106) data 0.000 (0.007) loss 1.9111 (1.6843) ce_loss 1.3506 (1.2355) teacher_loss 1.2591 (1.1032) loss_zs_kd 0.4323 (0.3527) loss_oracle 0.4359 (0.4047) acc 43.7500 (52.8516) kd_loss 0.9935 (1.0254) lr 1.1874e-03 eta 0:15:02
epoch [24/50] batch [100/319] time 0.146 (0.108) data 0.000 (0.006) loss 2.1746 (1.6808) ce_loss 1.5068 (1.2277) teacher_loss 1.5860 (1.0993) loss_zs_kd 0.4318 (0.3550) loss_oracle 0.3727 (0.4040) acc 37.5000 (53.0625) kd_loss 1.0182 (1.0257) lr 1.1874e-03 eta 0:15:15
epoch [24/50] batch [120/319] time 0.133 (0.109) data 0.000 (0.005) loss 1.7312 (1.6957) ce_loss 1.2061 (1.2325) teacher_loss 1.1392 (1.1152) loss_zs_kd 0.3713 (0.3536) loss_oracle 0.4064 (0.4037) acc 53.1250 (52.6562) kd_loss 1.0596 (1.0275) lr 1.1874e-03 eta 0:15:21
epoch [24/50] batch [140/319] time 0.155 (0.112) data 0.000 (0.004) loss 1.5312 (1.6906) ce_loss 1.1006 (1.2278) teacher_loss 0.9868 (1.1175) loss_zs_kd 0.3498 (0.3485) loss_oracle 0.3694 (0.3989) acc 62.5000 (52.9464) kd_loss 1.0038 (1.0270) lr 1.1874e-03 eta 0:15:50
epoch [24/50] batch [160/319] time 0.089 (0.114) data 0.000 (0.004) loss 1.6546 (1.6774) ce_loss 1.3291 (1.2207) teacher_loss 1.1834 (1.1106) loss_zs_kd 0.2699 (0.3449) loss_oracle 0.3363 (0.3943) acc 40.6250 (53.2227) kd_loss 0.9497 (1.0292) lr 1.1874e-03 eta 0:16:05
epoch [24/50] batch [180/319] time 0.090 (0.114) data 0.000 (0.003) loss 1.6929 (1.6756) ce_loss 1.4326 (1.2247) teacher_loss 1.2388 (1.1127) loss_zs_kd 0.2955 (0.3446) loss_oracle 0.3064 (0.3907) acc 46.8750 (52.9167) kd_loss 0.9995 (1.0289) lr 1.1874e-03 eta 0:16:02
epoch [24/50] batch [200/319] time 0.095 (0.113) data 0.000 (0.003) loss 1.5806 (1.6707) ce_loss 1.2041 (1.2230) teacher_loss 1.0668 (1.1103) loss_zs_kd 0.3061 (0.3433) loss_oracle 0.3608 (0.3887) acc 56.2500 (53.0000) kd_loss 1.0637 (1.0285) lr 1.1874e-03 eta 0:15:54
epoch [24/50] batch [220/319] time 0.083 (0.113) data 0.000 (0.003) loss 1.5921 (1.6671) ce_loss 1.1748 (1.2206) teacher_loss 1.0329 (1.1078) loss_zs_kd 0.3641 (0.3422) loss_oracle 0.3772 (0.3883) acc 59.3750 (52.9972) kd_loss 1.0514 (1.0273) lr 1.1874e-03 eta 0:15:44
epoch [24/50] batch [240/319] time 0.102 (0.112) data 0.000 (0.002) loss 1.7781 (1.6632) ce_loss 1.3564 (1.2178) teacher_loss 1.2319 (1.1023) loss_zs_kd 0.4071 (0.3435) loss_oracle 0.3426 (0.3891) acc 40.6250 (52.9297) kd_loss 0.9548 (1.0269) lr 1.1874e-03 eta 0:15:39
epoch [24/50] batch [260/319] time 0.097 (0.112) data 0.000 (0.002) loss 1.9175 (1.6636) ce_loss 1.5527 (1.2195) teacher_loss 1.3019 (1.0993) loss_zs_kd 0.2956 (0.3453) loss_oracle 0.4677 (0.3917) acc 31.2500 (52.9567) kd_loss 0.9992 (1.0242) lr 1.1874e-03 eta 0:15:36
epoch [24/50] batch [280/319] time 0.132 (0.112) data 0.000 (0.002) loss 1.6163 (1.6653) ce_loss 1.3271 (1.2211) teacher_loss 1.1051 (1.0998) loss_zs_kd 0.2683 (0.3453) loss_oracle 0.3771 (0.3928) acc 40.6250 (52.8460) kd_loss 1.0548 (1.0216) lr 1.1874e-03 eta 0:15:30
epoch [24/50] batch [300/319] time 0.069 (0.111) data 0.000 (0.002) loss 1.5288 (1.6625) ce_loss 1.0498 (1.2199) teacher_loss 0.9771 (1.0991) loss_zs_kd 0.3571 (0.3433) loss_oracle 0.3731 (0.3918) acc 62.5000 (53.0417) kd_loss 1.0742 (1.0203) lr 1.1874e-03 eta 0:15:26
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,386
* accuracy: 54.5%
* error: 45.5%
* macro_f1: 46.2%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,108
* accuracy: 42.2%
* error: 57.8%
* macro_f1: 20.5%
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.2%, epoch: 20 *******
epoch [25/50] batch [20/319] time 0.156 (0.145) data 0.000 (0.032) loss 1.6819 (1.6695) ce_loss 1.2236 (1.2377) teacher_loss 1.0588 (1.1044) loss_zs_kd 0.3284 (0.3381) loss_oracle 0.4589 (0.3961) acc 56.2500 (52.9688) kd_loss 1.0683 (1.0228) lr 1.1253e-03 eta 0:20:00
epoch [25/50] batch [40/319] time 0.081 (0.131) data 0.000 (0.016) loss 1.6641 (1.6643) ce_loss 1.2988 (1.2367) teacher_loss 1.1032 (1.0985) loss_zs_kd 0.3433 (0.3393) loss_oracle 0.3892 (0.3962) acc 56.2500 (52.9688) kd_loss 0.9821 (1.0203) lr 1.1253e-03 eta 0:18:03
epoch [25/50] batch [60/319] time 0.103 (0.124) data 0.000 (0.011) loss 1.8936 (1.6493) ce_loss 1.4238 (1.2287) teacher_loss 1.3453 (1.0808) loss_zs_kd 0.3841 (0.3414) loss_oracle 0.3563 (0.3978) acc 46.8750 (52.5521) kd_loss 1.0553 (1.0205) lr 1.1253e-03 eta 0:17:02
epoch [25/50] batch [80/319] time 0.096 (0.118) data 0.000 (0.008) loss 1.4959 (1.6468) ce_loss 1.0684 (1.2274) teacher_loss 0.9123 (1.0795) loss_zs_kd 0.3415 (0.3437) loss_oracle 0.4128 (0.3954) acc 56.2500 (52.5000) kd_loss 1.0108 (1.0203) lr 1.1253e-03 eta 0:16:07
epoch [25/50] batch [100/319] time 0.140 (0.115) data 0.000 (0.007) loss 1.8325 (1.6325) ce_loss 1.3721 (1.2145) teacher_loss 1.2495 (1.0665) loss_zs_kd 0.3541 (0.3447) loss_oracle 0.4060 (0.3936) acc 50.0000 (53.2812) kd_loss 1.0453 (1.0263) lr 1.1253e-03 eta 0:15:43
epoch [25/50] batch [120/319] time 0.110 (0.113) data 0.000 (0.006) loss 1.6387 (1.6400) ce_loss 1.1855 (1.2230) teacher_loss 1.0510 (1.0736) loss_zs_kd 0.4279 (0.3436) loss_oracle 0.3738 (0.3946) acc 56.2500 (53.1771) kd_loss 1.0681 (1.0311) lr 1.1253e-03 eta 0:15:19
epoch [25/50] batch [140/319] time 0.112 (0.112) data 0.000 (0.005) loss 1.5920 (1.6364) ce_loss 1.2256 (1.2194) teacher_loss 1.0080 (1.0737) loss_zs_kd 0.3988 (0.3410) loss_oracle 0.3846 (0.3922) acc 40.6250 (53.1696) kd_loss 1.1111 (1.0312) lr 1.1253e-03 eta 0:15:11
epoch [25/50] batch [160/319] time 0.110 (0.111) data 0.000 (0.004) loss 1.7507 (1.6399) ce_loss 1.3037 (1.2227) teacher_loss 1.1448 (1.0805) loss_zs_kd 0.3885 (0.3395) loss_oracle 0.4116 (0.3896) acc 50.0000 (53.1836) kd_loss 1.0037 (1.0309) lr 1.1253e-03 eta 0:14:59
epoch [25/50] batch [180/319] time 0.092 (0.110) data 0.000 (0.004) loss 1.5750 (1.6360) ce_loss 1.1680 (1.2188) teacher_loss 0.9758 (1.0769) loss_zs_kd 0.3288 (0.3410) loss_oracle 0.4348 (0.3886) acc 50.0000 (53.2118) kd_loss 1.0186 (1.0296) lr 1.1253e-03 eta 0:14:52
epoch [25/50] batch [200/319] time 0.084 (0.112) data 0.000 (0.003) loss 1.6838 (1.6361) ce_loss 1.3291 (1.2161) teacher_loss 1.0882 (1.0753) loss_zs_kd 0.3692 (0.3444) loss_oracle 0.4109 (0.3886) acc 46.8750 (53.2969) kd_loss 0.9263 (1.0288) lr 1.1253e-03 eta 0:15:05
epoch [25/50] batch [220/319] time 0.189 (0.116) data 0.000 (0.003) loss 1.4609 (1.6414) ce_loss 1.1055 (1.2198) teacher_loss 0.9650 (1.0809) loss_zs_kd 0.3449 (0.3449) loss_oracle 0.3235 (0.3881) acc 50.0000 (53.1818) kd_loss 1.0047 (1.0287) lr 1.1253e-03 eta 0:15:39
epoch [25/50] batch [240/319] time 0.187 (0.119) data 0.000 (0.003) loss 1.8270 (1.6371) ce_loss 1.3281 (1.2138) teacher_loss 1.3200 (1.0776) loss_zs_kd 0.3781 (0.3449) loss_oracle 0.3179 (0.3870) acc 40.6250 (53.3594) kd_loss 0.9978 (1.0289) lr 1.1253e-03 eta 0:15:55
epoch [25/50] batch [260/319] time 0.133 (0.120) data 0.000 (0.003) loss 1.7273 (1.6402) ce_loss 1.2930 (1.2144) teacher_loss 1.1469 (1.0814) loss_zs_kd 0.3754 (0.3461) loss_oracle 0.3928 (0.3857) acc 43.7500 (53.3053) kd_loss 1.0351 (1.0298) lr 1.1253e-03 eta 0:16:07
epoch [25/50] batch [280/319] time 0.134 (0.120) data 0.000 (0.003) loss 1.7705 (1.6392) ce_loss 1.2900 (1.2146) teacher_loss 1.2463 (1.0816) loss_zs_kd 0.3235 (0.3451) loss_oracle 0.3624 (0.3850) acc 56.2500 (53.2478) kd_loss 1.0294 (1.0316) lr 1.1253e-03 eta 0:15:58
epoch [25/50] batch [300/319] time 0.119 (0.119) data 0.000 (0.002) loss 1.6425 (1.6424) ce_loss 1.2402 (1.2163) teacher_loss 1.1340 (1.0852) loss_zs_kd 0.2988 (0.3429) loss_oracle 0.3591 (0.3857) acc 56.2500 (53.1458) kd_loss 0.9860 (1.0307) lr 1.1253e-03 eta 0:15:50
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,449
* accuracy: 55.9%
* error: 44.1%
* macro_f1: 48.1%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,340
* accuracy: 44.6%
* error: 55.4%
* macro_f1: 21.2%
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.2%, epoch: 20 *******
epoch [26/50] batch [20/319] time 0.162 (0.177) data 0.000 (0.028) loss 1.7199 (1.7008) ce_loss 1.2920 (1.2660) teacher_loss 1.1833 (1.1380) loss_zs_kd 0.2910 (0.3577) loss_oracle 0.3911 (0.3840) acc 50.0000 (50.4688) kd_loss 1.1182 (1.0484) lr 1.0628e-03 eta 0:23:28
epoch [26/50] batch [40/319] time 0.156 (0.164) data 0.000 (0.014) loss 1.6172 (1.6670) ce_loss 1.1182 (1.2447) teacher_loss 1.1052 (1.1072) loss_zs_kd 0.3660 (0.3505) loss_oracle 0.3290 (0.3846) acc 53.1250 (50.7031) kd_loss 1.0381 (1.0493) lr 1.0628e-03 eta 0:21:42
epoch [26/50] batch [60/319] time 0.215 (0.156) data 0.001 (0.009) loss 1.6891 (1.6377) ce_loss 1.2549 (1.2218) teacher_loss 1.1126 (1.0814) loss_zs_kd 0.3231 (0.3521) loss_oracle 0.4149 (0.3802) acc 40.6250 (52.8125) kd_loss 0.9753 (1.0473) lr 1.0628e-03 eta 0:20:36
epoch [26/50] batch [80/319] time 0.089 (0.154) data 0.000 (0.007) loss 1.5847 (1.6369) ce_loss 1.2646 (1.2287) teacher_loss 1.0508 (1.0825) loss_zs_kd 0.4300 (0.3532) loss_oracle 0.3189 (0.3777) acc 53.1250 (52.5781) kd_loss 1.0520 (1.0513) lr 1.0628e-03 eta 0:20:15
epoch [26/50] batch [100/319] time 0.187 (0.158) data 0.000 (0.006) loss 1.5547 (1.6310) ce_loss 1.1670 (1.2294) teacher_loss 1.0061 (1.0763) loss_zs_kd 0.3419 (0.3522) loss_oracle 0.3777 (0.3786) acc 50.0000 (52.4062) kd_loss 1.0393 (1.0526) lr 1.0628e-03 eta 0:20:42
epoch [26/50] batch [120/319] time 0.139 (0.153) data 0.000 (0.005) loss 1.6890 (1.6274) ce_loss 1.3135 (1.2255) teacher_loss 1.1669 (1.0713) loss_zs_kd 0.3393 (0.3531) loss_oracle 0.3525 (0.3796) acc 40.6250 (52.6302) kd_loss 1.0968 (1.0540) lr 1.0628e-03 eta 0:20:02
epoch [26/50] batch [140/319] time 0.141 (0.148) data 0.000 (0.004) loss 1.6532 (1.6202) ce_loss 1.2539 (1.2226) teacher_loss 1.0839 (1.0658) loss_zs_kd 0.3324 (0.3490) loss_oracle 0.4030 (0.3799) acc 50.0000 (52.6116) kd_loss 1.0255 (1.0537) lr 1.0628e-03 eta 0:19:17
epoch [26/50] batch [160/319] time 0.147 (0.147) data 0.000 (0.004) loss 1.3793 (1.6149) ce_loss 1.0430 (1.2197) teacher_loss 0.8588 (1.0611) loss_zs_kd 0.3295 (0.3446) loss_oracle 0.3558 (0.3815) acc 53.1250 (52.4609) kd_loss 1.0468 (1.0507) lr 1.0628e-03 eta 0:19:11
epoch [26/50] batch [180/319] time 0.150 (0.148) data 0.000 (0.003) loss 1.5369 (1.6180) ce_loss 1.0762 (1.2206) teacher_loss 0.9478 (1.0615) loss_zs_kd 0.3015 (0.3446) loss_oracle 0.4384 (0.3842) acc 53.1250 (52.4306) kd_loss 0.9931 (1.0468) lr 1.0628e-03 eta 0:19:11
epoch [26/50] batch [200/319] time 0.161 (0.148) data 0.000 (0.003) loss 2.0682 (1.6231) ce_loss 1.4639 (1.2202) teacher_loss 1.4939 (1.0627) loss_zs_kd 0.3436 (0.3438) loss_oracle 0.4025 (0.3885) acc 46.8750 (52.4375) kd_loss 0.9529 (1.0413) lr 1.0628e-03 eta 0:19:12
epoch [26/50] batch [220/319] time 0.116 (0.146) data 0.000 (0.003) loss 1.2823 (1.6298) ce_loss 0.9038 (1.2209) teacher_loss 0.7706 (1.0647) loss_zs_kd 0.2478 (0.3445) loss_oracle 0.3877 (0.3928) acc 62.5000 (52.4006) kd_loss 0.9430 (1.0367) lr 1.0628e-03 eta 0:18:55
epoch [26/50] batch [240/319] time 0.144 (0.144) data 0.000 (0.003) loss 1.5428 (1.6309) ce_loss 1.1533 (1.2199) teacher_loss 0.9338 (1.0652) loss_zs_kd 0.3543 (0.3427) loss_oracle 0.4318 (0.3943) acc 71.8750 (52.5651) kd_loss 0.9391 (1.0339) lr 1.0628e-03 eta 0:18:37
epoch [26/50] batch [260/319] time 0.103 (0.143) data 0.000 (0.002) loss 1.6013 (1.6314) ce_loss 1.1172 (1.2175) teacher_loss 1.0939 (1.0644) loss_zs_kd 0.2999 (0.3435) loss_oracle 0.3575 (0.3953) acc 56.2500 (52.7404) kd_loss 1.0415 (1.0337) lr 1.0628e-03 eta 0:18:23
epoch [26/50] batch [280/319] time 0.143 (0.143) data 0.000 (0.002) loss 1.5881 (1.6341) ce_loss 1.0293 (1.2186) teacher_loss 1.0836 (1.0668) loss_zs_kd 0.3167 (0.3443) loss_oracle 0.3462 (0.3952) acc 59.3750 (52.7232) kd_loss 1.0565 (1.0346) lr 1.0628e-03 eta 0:18:18
epoch [26/50] batch [300/319] time 0.146 (0.143) data 0.000 (0.002) loss 2.1137 (1.6375) ce_loss 1.7197 (1.2206) teacher_loss 1.6024 (1.0707) loss_zs_kd 0.3824 (0.3442) loss_oracle 0.3201 (0.3947) acc 31.2500 (52.6042) kd_loss 0.9603 (1.0342) lr 1.0628e-03 eta 0:18:20
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,418
* accuracy: 55.2%
* error: 44.8%
* macro_f1: 47.7%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,196
* accuracy: 43.1%
* error: 56.9%
* macro_f1: 20.8%
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.2%, epoch: 20 *******
epoch [27/50] batch [20/319] time 0.116 (0.137) data 0.000 (0.028) loss 1.5058 (1.6629) ce_loss 1.0615 (1.2163) teacher_loss 0.8929 (1.0711) loss_zs_kd 0.2733 (0.3478) loss_oracle 0.4762 (0.4179) acc 59.3750 (54.0625) kd_loss 0.9746 (1.0241) lr 1.0000e-03 eta 0:17:24
epoch [27/50] batch [40/319] time 0.147 (0.136) data 0.000 (0.014) loss 1.5275 (1.6625) ce_loss 1.1016 (1.2256) teacher_loss 0.9573 (1.0666) loss_zs_kd 0.4007 (0.3476) loss_oracle 0.3698 (0.4221) acc 59.3750 (53.2812) kd_loss 0.9948 (1.0133) lr 1.0000e-03 eta 0:17:16
epoch [27/50] batch [60/319] time 0.153 (0.142) data 0.001 (0.010) loss 1.4907 (1.6360) ce_loss 1.1084 (1.1991) teacher_loss 0.9278 (1.0568) loss_zs_kd 0.3882 (0.3426) loss_oracle 0.3688 (0.4079) acc 56.2500 (54.7917) kd_loss 1.0730 (1.0226) lr 1.0000e-03 eta 0:17:58
epoch [27/50] batch [80/319] time 0.145 (0.144) data 0.000 (0.007) loss 1.8392 (1.6265) ce_loss 1.4570 (1.1895) teacher_loss 1.3500 (1.0635) loss_zs_kd 0.3276 (0.3368) loss_oracle 0.3254 (0.3946) acc 43.7500 (55.6250) kd_loss 1.0068 (1.0270) lr 1.0000e-03 eta 0:18:13
epoch [27/50] batch [100/319] time 0.146 (0.146) data 0.000 (0.006) loss 1.6386 (1.6277) ce_loss 1.1348 (1.1883) teacher_loss 1.1434 (1.0715) loss_zs_kd 0.3476 (0.3346) loss_oracle 0.3214 (0.3889) acc 53.1250 (55.2812) kd_loss 1.1012 (1.0309) lr 1.0000e-03 eta 0:18:22
epoch [27/50] batch [120/319] time 0.139 (0.142) data 0.000 (0.005) loss 1.5663 (1.6358) ce_loss 1.1299 (1.1940) teacher_loss 0.9923 (1.0825) loss_zs_kd 0.3717 (0.3365) loss_oracle 0.3882 (0.3850) acc 62.5000 (55.0521) kd_loss 0.9224 (1.0299) lr 1.0000e-03 eta 0:17:53
epoch [27/50] batch [140/319] time 0.150 (0.144) data 0.000 (0.004) loss 1.4981 (1.6331) ce_loss 1.0762 (1.1940) teacher_loss 0.9586 (1.0806) loss_zs_kd 0.3280 (0.3353) loss_oracle 0.3755 (0.3849) acc 62.5000 (54.8214) kd_loss 1.0162 (1.0293) lr 1.0000e-03 eta 0:17:59
epoch [27/50] batch [160/319] time 0.118 (0.144) data 0.000 (0.004) loss 1.4227 (1.6348) ce_loss 0.9658 (1.1914) teacher_loss 0.8477 (1.0796) loss_zs_kd 0.3311 (0.3385) loss_oracle 0.4094 (0.3860) acc 59.3750 (54.9219) kd_loss 1.0335 (1.0252) lr 1.0000e-03 eta 0:18:02
epoch [27/50] batch [180/319] time 0.134 (0.141) data 0.000 (0.003) loss 1.3277 (1.6356) ce_loss 0.9458 (1.1923) teacher_loss 0.8154 (1.0777) loss_zs_kd 0.3358 (0.3397) loss_oracle 0.3444 (0.3880) acc 62.5000 (54.7222) kd_loss 1.0441 (1.0258) lr 1.0000e-03 eta 0:17:33
epoch [27/50] batch [200/319] time 0.118 (0.140) data 0.000 (0.003) loss 1.4370 (1.6365) ce_loss 1.0781 (1.1944) teacher_loss 0.8520 (1.0766) loss_zs_kd 0.4159 (0.3424) loss_oracle 0.3769 (0.3886) acc 59.3750 (54.6094) kd_loss 1.0455 (1.0272) lr 1.0000e-03 eta 0:17:23
epoch [27/50] batch [220/319] time 0.091 (0.137) data 0.000 (0.003) loss 1.7734 (1.6359) ce_loss 1.2637 (1.1957) teacher_loss 1.1282 (1.0752) loss_zs_kd 0.3731 (0.3440) loss_oracle 0.4586 (0.3887) acc 46.8750 (54.4886) kd_loss 1.0060 (1.0281) lr 1.0000e-03 eta 0:16:59
epoch [27/50] batch [240/319] time 0.146 (0.135) data 0.000 (0.003) loss 1.7451 (1.6408) ce_loss 1.3027 (1.1996) teacher_loss 1.1550 (1.0775) loss_zs_kd 0.3774 (0.3453) loss_oracle 0.4014 (0.3907) acc 50.0000 (54.2969) kd_loss 1.0644 (1.0265) lr 1.0000e-03 eta 0:16:43
epoch [27/50] batch [260/319] time 0.078 (0.134) data 0.000 (0.002) loss 1.7156 (1.6411) ce_loss 1.1240 (1.1979) teacher_loss 1.1382 (1.0750) loss_zs_kd 0.3895 (0.3476) loss_oracle 0.3826 (0.3922) acc 56.2500 (54.4952) kd_loss 1.0366 (1.0250) lr 1.0000e-03 eta 0:16:32
epoch [27/50] batch [280/319] time 0.192 (0.137) data 0.000 (0.002) loss 1.9205 (1.6458) ce_loss 1.4121 (1.2006) teacher_loss 1.3275 (1.0771) loss_zs_kd 0.4007 (0.3478) loss_oracle 0.3926 (0.3948) acc 43.7500 (54.2857) kd_loss 1.0576 (1.0252) lr 1.0000e-03 eta 0:16:46
epoch [27/50] batch [300/319] time 0.222 (0.136) data 0.000 (0.002) loss 2.0485 (1.6427) ce_loss 1.5332 (1.1994) teacher_loss 1.4349 (1.0742) loss_zs_kd 0.4435 (0.3473) loss_oracle 0.3917 (0.3948) acc 40.6250 (54.1042) kd_loss 1.0658 (1.0262) lr 1.0000e-03 eta 0:16:39
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,399
* accuracy: 54.8%
* error: 45.2%
* macro_f1: 46.4%
Evaluate on the *test* set
=> result
* total: 9,736
* correct: 4,200
* accuracy: 43.1%
* error: 56.9%
* macro_f1: 20.9%
******* Domain 2 best val acc:      56.2%, epoch: 15 *******
******* Domain 2 best val test acc: 47.4%, epoch: 15 *******
******* Domain 2 best test acc:     48.2%, epoch: 20 *******
epoch [28/50] batch [20/319] time 0.139 (0.148) data 0.000 (0.025) loss 1.6606 (1.6056) ce_loss 1.1504 (1.2076) teacher_loss 1.0549 (1.0227) loss_zs_kd 0.4033 (0.3598) loss_oracle 0.4040 (0.4030) acc 53.1250 (53.7500) kd_loss 1.0747 (1.0905) lr 9.3721e-04 eta 0:18:01
epoch [28/50] batch [40/319] time 0.107 (0.129) data 0.000 (0.013) loss 1.6404 (1.6083) ce_loss 1.3223 (1.2070) teacher_loss 1.0979 (1.0391) loss_zs_kd 0.3929 (0.3468) loss_oracle 0.3460 (0.3957) acc 53.1250 (53.4375) kd_loss 1.1434 (1.0883) lr 9.3721e-04 eta 0:15:44
epoch [28/50] batch [60/319] time 0.146 (0.125) data 0.001 (0.008) loss 1.5261 (1.6339) ce_loss 1.1221 (1.2317) teacher_loss 0.9722 (1.0611) loss_zs_kd 0.3662 (0.3520) loss_oracle 0.3708 (0.3969) acc 68.7500 (52.3958) kd_loss 0.9733 (1.0801) lr 9.3721e-04 eta 0:15:08
epoch [28/50] batch [80/319] time 0.143 (0.125) data 0.000 (0.006) loss 1.7558 (1.6207) ce_loss 1.3252 (1.2154) teacher_loss 1.1469 (1.0475) loss_zs_kd 0.3108 (0.3476) loss_oracle 0.4535 (0.3995) acc 40.6250 (52.8516) kd_loss 1.0554 (1.0702) lr 9.3721e-04 eta 0:15:08
epoch [28/50] batch [100/319] time 0.138 (0.125) data 0.000 (0.005) loss 1.6458 (1.6266) ce_loss 1.2744 (1.2172) teacher_loss 1.0037 (1.0536) loss_zs_kd 0.3769 (0.3500) loss_oracle 0.4536 (0.3980) acc 56.2500 (53.0000) kd_loss 0.9932 (1.0617) lr 9.3721e-04 eta 0:15:03
epoch [28/50] batch [120/319] time 0.075 (0.122) data 0.000 (0.004) loss 1.7018 (1.6193) ce_loss 1.3018 (1.2117) teacher_loss 1.0856 (1.0480) loss_zs_kd 0.3816 (0.3487) loss_oracle 0.4253 (0.3970) acc 40.6250 (52.9688) kd_loss 1.0475 (1.0618) lr 9.3721e-04 eta 0:14:40
epoch [28/50] batch [140/319] time 0.190 (0.127) data 0.000 (0.004) loss 1.6997 (1.6199) ce_loss 1.2051 (1.2156) teacher_loss 1.1239 (1.0501) loss_zs_kd 0.3805 (0.3479) loss_oracle 0.3856 (0.3958) acc 53.1250 (53.1250) kd_loss 1.0002 (1.0597) lr 9.3721e-04 eta 0:15:17
epoch [28/50] batch [160/319] time 0.195 (0.130) data 0.000 (0.003) loss 1.3588 (1.6134) ce_loss 0.9624 (1.2145) teacher_loss 0.8391 (1.0469) loss_zs_kd 0.4026 (0.3462) loss_oracle 0.3184 (0.3934) acc 65.6250 (53.1445) kd_loss 1.0022 (1.0558) lr 9.3721e-04 eta 0:15:29
epoch [28/50] batch [180/319] time 0.090 (0.132) data 0.000 (0.003) loss 1.5080 (1.6033) ce_loss 1.1133 (1.2052) teacher_loss 0.9797 (1.0362) loss_zs_kd 0.3191 (0.3465) loss_oracle 0.3688 (0.3938) acc 56.2500 (53.5069) kd_loss 1.1310 (1.0565) lr 9.3721e-04 eta 0:15:43
epoch [28/50] batch [200/319] time 0.153 (0.132) data 0.000 (0.003) loss 1.8961 (1.6067) ce_loss 1.4473 (1.2084) teacher_loss 1.3122 (1.0406) loss_zs_kd 0.3453 (0.3461) loss_oracle 0.4112 (0.3930) acc 40.6250 (53.4062) kd_loss 1.0973 (1.0590) lr 9.3721e-04 eta 0:15:38
epoch [28/50] batch [220/319] time 0.155 (0.133) data 0.000 (0.002) loss 1.7388 (1.6115) ce_loss 1.2393 (1.2146) teacher_loss 1.2058 (1.0477) loss_zs_kd 0.3114 (0.3456) loss_oracle 0.3773 (0.3910) acc 50.0000 (53.1676) kd_loss 1.1120 (1.0639) lr 9.3721e-04 eta 0:15:49
epoch [28/50] batch [240/319] time 0.155 (0.135) data 0.000 (0.002) loss 1.5404 (1.6093) ce_loss 1.1338 (1.2155) teacher_loss 1.0011 (1.0468) loss_zs_kd 0.3363 (0.3455) loss_oracle 0.3712 (0.3897) acc 56.2500 (53.1120) kd_loss 1.0350 (1.0635) lr 9.3721e-04 eta 0:15:58
epoch [28/50] batch [260/319] time 0.152 (0.135) data 0.000 (0.002) loss 1.4339 (1.6084) ce_loss 1.0957 (1.2155) teacher_loss 0.8597 (1.0460) loss_zs_kd 0.3666 (0.3455) loss_oracle 0.3909 (0.3896) acc 59.3750 (53.1370) kd_loss 1.0781 (1.0616) lr 9.3721e-04 eta 0:15:52
epoch [28/50] batch [280/319] time 0.163 (0.135) data 0.000 (0.002) loss 1.5909 (1.6109) ce_loss 1.2295 (1.2139) teacher_loss 1.0649 (1.0473) loss_zs_kd 0.3141 (0.3450) loss_oracle 0.3690 (0.3911) acc 56.2500 (53.2143) kd_loss 0.9771 (1.0569) lr 9.3721e-04 eta 0:15:51
epoch [28/50] batch [300/319] time 0.140 (0.134) data 0.000 (0.002) loss 1.9201 (1.6125) ce_loss 1.3018 (1.2137) teacher_loss 1.3098 (1.0483) loss_zs_kd 0.3226 (0.3439) loss_oracle 0.4490 (0.3923) acc 53.1250 (53.3229) kd_loss 1.0562 (1.0555) lr 9.3721e-04 eta 0:15:46
Evaluate on the *val* set
=> result
* total: 4,378
* correct: 2,457
* accuracy: 56.1%
* error: 43.9%
* macro_f1: 47.9%
Evaluate on the *test* set

Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'pascal']
Target     ['sun']
# classes  5
# train_x  5,213
# val      2,234
# test     3,282
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/162] time 0.130 (0.151) data 0.000 (0.022) loss 1.1934 (0.8258) ce_loss 1.0020 (0.6216) teacher_loss 1.0017 (0.6215) loss_zs_kd 0.0005 (0.0001) loss_oracle 0.1915 (0.2042) acc 65.6250 (79.0625) kd_loss 0.9118 (0.9640) lr 1.0000e-05 eta 0:20:19
epoch [1/50] batch [40/162] time 0.126 (0.125) data 0.000 (0.011) loss 1.1206 (0.8330) ce_loss 0.9326 (0.6303) teacher_loss 0.9296 (0.6301) loss_zs_kd 0.0020 (0.0008) loss_oracle 0.1900 (0.2024) acc 68.7500 (78.9844) kd_loss 0.9029 (0.9565) lr 1.0000e-05 eta 0:16:48
epoch [1/50] batch [60/162] time 0.116 (0.113) data 0.000 (0.007) loss 0.7998 (0.8285) ce_loss 0.5747 (0.6244) teacher_loss 0.5789 (0.6248) loss_zs_kd 0.0056 (0.0020) loss_oracle 0.2180 (0.2027) acc 84.3750 (78.6458) kd_loss 1.0365 (0.9573) lr 1.0000e-05 eta 0:15:09
epoch [1/50] batch [80/162] time 0.097 (0.107) data 0.000 (0.006) loss 0.8353 (0.8214) ce_loss 0.6279 (0.6158) teacher_loss 0.6283 (0.6159) loss_zs_kd 0.0088 (0.0034) loss_oracle 0.2026 (0.2038) acc 75.0000 (78.8672) kd_loss 0.9566 (0.9627) lr 1.0000e-05 eta 0:14:15
epoch [1/50] batch [100/162] time 0.119 (0.105) data 0.000 (0.004) loss 0.7123 (0.8145) ce_loss 0.4932 (0.6085) teacher_loss 0.4920 (0.6087) loss_zs_kd 0.0069 (0.0047) loss_oracle 0.2168 (0.2035) acc 84.3750 (79.2188) kd_loss 1.0234 (0.9616) lr 1.0000e-05 eta 0:13:58
epoch [1/50] batch [120/162] time 0.116 (0.104) data 0.000 (0.004) loss 1.0220 (0.7992) ce_loss 0.8145 (0.5924) teacher_loss 0.8131 (0.5926) loss_zs_kd 0.0074 (0.0056) loss_oracle 0.2052 (0.2038) acc 65.6250 (79.5052) kd_loss 0.9686 (0.9629) lr 1.0000e-05 eta 0:13:50
epoch [1/50] batch [140/162] time 0.077 (0.103) data 0.000 (0.003) loss 0.5492 (0.7906) ce_loss 0.3506 (0.5840) teacher_loss 0.3473 (0.5840) loss_zs_kd 0.0155 (0.0065) loss_oracle 0.1941 (0.2034) acc 87.5000 (79.9554) kd_loss 0.9144 (0.9610) lr 1.0000e-05 eta 0:13:41
epoch [1/50] batch [160/162] time 0.065 (0.101) data 0.000 (0.003) loss 0.5511 (0.7956) ce_loss 0.3354 (0.5888) teacher_loss 0.3338 (0.5889) loss_zs_kd 0.0140 (0.0077) loss_oracle 0.2102 (0.2029) acc 84.3750 (79.6484) kd_loss 0.9901 (0.9589) lr 1.0000e-05 eta 0:13:18
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,902
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 87.1%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,366
* accuracy: 72.1%
* error: 27.9%
* macro_f1: 66.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      85.1%, epoch: 1 *******
******* Domain s best val test acc: 72.1%, epoch: 1 *******
******* Domain s best test acc:     72.1%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/ana
epoch [2/50] batch [20/162] time 0.100 (0.113) data 0.000 (0.016) loss 0.9547 (0.8680) ce_loss 0.6294 (0.5639) teacher_loss 0.5484 (0.5577) loss_zs_kd 0.0788 (0.0601) loss_oracle 0.3669 (0.2803) acc 81.2500 (81.0938) kd_loss 1.0469 (0.9746) lr 2.0000e-03 eta 0:14:58
epoch [2/50] batch [40/162] time 0.090 (0.103) data 0.000 (0.008) loss 0.7671 (0.8689) ce_loss 0.4846 (0.5370) teacher_loss 0.3234 (0.5086) loss_zs_kd 0.1442 (0.0778) loss_oracle 0.3716 (0.3214) acc 78.1250 (81.4844) kd_loss 1.0587 (0.9949) lr 2.0000e-03 eta 0:13:32
epoch [2/50] batch [60/162] time 0.122 (0.105) data 0.000 (0.006) loss 0.8538 (0.8762) ce_loss 0.5024 (0.5368) teacher_loss 0.4040 (0.4996) loss_zs_kd 0.1258 (0.0844) loss_oracle 0.3869 (0.3345) acc 81.2500 (81.5104) kd_loss 1.0359 (1.0000) lr 2.0000e-03 eta 0:13:48
epoch [2/50] batch [80/162] time 0.087 (0.104) data 0.000 (0.004) loss 0.8040 (0.8589) ce_loss 0.4253 (0.5175) teacher_loss 0.4398 (0.4872) loss_zs_kd 0.1035 (0.0812) loss_oracle 0.3124 (0.3311) acc 81.2500 (81.9922) kd_loss 1.0017 (0.9935) lr 2.0000e-03 eta 0:13:37
epoch [2/50] batch [100/162] time 0.126 (0.105) data 0.000 (0.003) loss 0.7771 (0.8496) ce_loss 0.5068 (0.5145) teacher_loss 0.4634 (0.4892) loss_zs_kd 0.0770 (0.0801) loss_oracle 0.2752 (0.3203) acc 87.5000 (81.8750) kd_loss 1.0214 (0.9935) lr 2.0000e-03 eta 0:13:43
epoch [2/50] batch [120/162] time 0.081 (0.104) data 0.000 (0.003) loss 0.9156 (0.8479) ce_loss 0.6411 (0.5135) teacher_loss 0.5913 (0.4926) loss_zs_kd 0.0540 (0.0770) loss_oracle 0.2973 (0.3167) acc 78.1250 (81.7188) kd_loss 0.9989 (0.9938) lr 2.0000e-03 eta 0:13:36
epoch [2/50] batch [140/162] time 0.117 (0.105) data 0.000 (0.003) loss 0.6469 (0.8402) ce_loss 0.3728 (0.5062) teacher_loss 0.3437 (0.4871) loss_zs_kd 0.0776 (0.0764) loss_oracle 0.2644 (0.3150) acc 90.6250 (81.8527) kd_loss 0.9105 (0.9917) lr 2.0000e-03 eta 0:13:38
epoch [2/50] batch [160/162] time 0.097 (0.104) data 0.000 (0.002) loss 0.7520 (0.8392) ce_loss 0.3843 (0.5049) teacher_loss 0.3820 (0.4880) loss_zs_kd 0.0991 (0.0765) loss_oracle 0.3205 (0.3130) acc 84.3750 (81.7188) kd_loss 1.0156 (0.9929) lr 2.0000e-03 eta 0:13:31
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,944
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 88.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,448
* accuracy: 74.6%
* error: 25.4%
* macro_f1: 71.6%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      87.0%, epoch: 2 *******
******* Domain s best val test acc: 74.6%, epoch: 2 *******
******* Domain s best test acc:     74.6%, epoch: 2 *******
epoch [3/50] batch [20/162] time 0.098 (0.117) data 0.000 (0.015) loss 0.7850 (0.8360) ce_loss 0.5127 (0.4875) teacher_loss 0.5022 (0.4786) loss_zs_kd 0.0351 (0.0727) loss_oracle 0.2653 (0.3210) acc 84.3750 (81.8750) kd_loss 1.0314 (0.9935) lr 1.9980e-03 eta 0:15:06
epoch [3/50] batch [40/162] time 0.085 (0.108) data 0.000 (0.007) loss 0.8769 (0.8296) ce_loss 0.6279 (0.4989) teacher_loss 0.5128 (0.4866) loss_zs_kd 0.0853 (0.0762) loss_oracle 0.3215 (0.3049) acc 75.0000 (81.9531) kd_loss 0.9215 (0.9934) lr 1.9980e-03 eta 0:13:52
epoch [3/50] batch [60/162] time 0.136 (0.106) data 0.000 (0.005) loss 0.8128 (0.8452) ce_loss 0.4209 (0.5134) teacher_loss 0.3766 (0.4938) loss_zs_kd 0.1021 (0.0786) loss_oracle 0.3852 (0.3121) acc 84.3750 (81.6146) kd_loss 1.0083 (0.9987) lr 1.9980e-03 eta 0:13:36
epoch [3/50] batch [80/162] time 0.092 (0.106) data 0.000 (0.004) loss 0.8477 (0.8406) ce_loss 0.4468 (0.5020) teacher_loss 0.4751 (0.4828) loss_zs_kd 0.0612 (0.0780) loss_oracle 0.3419 (0.3189) acc 78.1250 (81.2891) kd_loss 0.9896 (0.9988) lr 1.9980e-03 eta 0:13:32
epoch [3/50] batch [100/162] time 0.088 (0.106) data 0.000 (0.003) loss 0.6051 (0.8405) ce_loss 0.2161 (0.5005) teacher_loss 0.1830 (0.4796) loss_zs_kd 0.0761 (0.0778) loss_oracle 0.3841 (0.3220) acc 93.7500 (81.7188) kd_loss 1.0372 (0.9998) lr 1.9980e-03 eta 0:13:30
epoch [3/50] batch [120/162] time 0.137 (0.107) data 0.000 (0.003) loss 0.7617 (0.8282) ce_loss 0.4653 (0.4955) teacher_loss 0.3909 (0.4654) loss_zs_kd 0.0940 (0.0808) loss_oracle 0.3239 (0.3224) acc 81.2500 (81.9271) kd_loss 1.0161 (1.0020) lr 1.9980e-03 eta 0:13:37
epoch [3/50] batch [140/162] time 0.120 (0.107) data 0.000 (0.002) loss 0.6289 (0.8196) ce_loss 0.3928 (0.4907) teacher_loss 0.3303 (0.4602) loss_zs_kd 0.0449 (0.0798) loss_oracle 0.2762 (0.3195) acc 84.3750 (81.9196) kd_loss 1.0116 (1.0015) lr 1.9980e-03 eta 0:13:38
epoch [3/50] batch [160/162] time 0.073 (0.105) data 0.000 (0.002) loss 0.6033 (0.8103) ce_loss 0.2622 (0.4870) teacher_loss 0.2849 (0.4577) loss_zs_kd 0.0475 (0.0777) loss_oracle 0.2946 (0.3137) acc 90.6250 (82.1680) kd_loss 1.0222 (1.0012) lr 1.9980e-03 eta 0:13:20
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,946
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 89.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,558
* accuracy: 77.9%
* error: 22.1%
* macro_f1: 72.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      87.1%, epoch: 3 *******
******* Domain s best val test acc: 77.9%, epoch: 3 *******
******* Domain s best test acc:     77.9%, epoch: 3 *******
epoch [4/50] batch [20/162] time 0.132 (0.151) data 0.000 (0.017) loss 0.9732 (0.7681) ce_loss 0.6270 (0.4548) teacher_loss 0.6331 (0.4277) loss_zs_kd 0.1126 (0.0868) loss_oracle 0.2838 (0.2969) acc 78.1250 (83.7500) kd_loss 0.9639 (1.0065) lr 1.9921e-03 eta 0:19:06
epoch [4/50] batch [40/162] time 0.105 (0.144) data 0.000 (0.009) loss 0.7887 (0.7909) ce_loss 0.4412 (0.4618) teacher_loss 0.4465 (0.4433) loss_zs_kd 0.0576 (0.0796) loss_oracle 0.3134 (0.3078) acc 87.5000 (84.2188) kd_loss 1.0620 (1.0080) lr 1.9921e-03 eta 0:18:13
epoch [4/50] batch [60/162] time 0.141 (0.135) data 0.001 (0.006) loss 0.6669 (0.8079) ce_loss 0.3652 (0.4708) teacher_loss 0.3626 (0.4567) loss_zs_kd 0.0561 (0.0729) loss_oracle 0.2762 (0.3147) acc 90.6250 (83.5938) kd_loss 0.9896 (1.0047) lr 1.9921e-03 eta 0:16:57
epoch [4/50] batch [80/162] time 0.133 (0.130) data 0.000 (0.004) loss 0.7673 (0.7953) ce_loss 0.4851 (0.4619) teacher_loss 0.3140 (0.4343) loss_zs_kd 0.0979 (0.0758) loss_oracle 0.4043 (0.3230) acc 81.2500 (83.8281) kd_loss 1.0812 (1.0066) lr 1.9921e-03 eta 0:16:18
epoch [4/50] batch [100/162] time 0.099 (0.127) data 0.001 (0.004) loss 0.6872 (0.8095) ce_loss 0.4084 (0.4736) teacher_loss 0.3076 (0.4352) loss_zs_kd 0.0650 (0.0821) loss_oracle 0.3471 (0.3333) acc 84.3750 (83.3438) kd_loss 0.9530 (1.0068) lr 1.9921e-03 eta 0:15:52
epoch [4/50] batch [120/162] time 0.135 (0.125) data 0.000 (0.003) loss 1.0904 (0.8285) ce_loss 0.7485 (0.4796) teacher_loss 0.6174 (0.4384) loss_zs_kd 0.0993 (0.0836) loss_oracle 0.4233 (0.3483) acc 75.0000 (82.8906) kd_loss 1.0188 (1.0064) lr 1.9921e-03 eta 0:15:35
epoch [4/50] batch [140/162] time 0.085 (0.124) data 0.000 (0.003) loss 0.7640 (0.8346) ce_loss 0.4321 (0.4786) teacher_loss 0.4097 (0.4396) loss_zs_kd 0.0450 (0.0815) loss_oracle 0.3318 (0.3543) acc 81.2500 (82.9911) kd_loss 1.0016 (1.0049) lr 1.9921e-03 eta 0:15:25
epoch [4/50] batch [160/162] time 0.127 (0.122) data 0.000 (0.002) loss 1.1068 (0.8361) ce_loss 0.8203 (0.4863) teacher_loss 0.7218 (0.4441) loss_zs_kd 0.0955 (0.0829) loss_oracle 0.3373 (0.3505) acc 71.8750 (82.6562) kd_loss 0.9660 (1.0048) lr 1.9921e-03 eta 0:15:07
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,894
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 87.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,698
* accuracy: 82.2%
* error: 17.8%
* macro_f1: 74.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      87.1%, epoch: 3 *******
******* Domain s best val test acc: 77.9%, epoch: 3 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [5/50] batch [20/162] time 0.077 (0.117) data 0.000 (0.012) loss 0.8629 (0.8533) ce_loss 0.5522 (0.5214) teacher_loss 0.4309 (0.4629) loss_zs_kd 0.0732 (0.0728) loss_oracle 0.3954 (0.3541) acc 81.2500 (80.1562) kd_loss 1.0694 (1.0114) lr 1.9823e-03 eta 0:14:27
epoch [5/50] batch [40/162] time 0.079 (0.110) data 0.000 (0.006) loss 0.8128 (0.8182) ce_loss 0.4797 (0.4647) teacher_loss 0.4784 (0.4138) loss_zs_kd 0.0593 (0.0871) loss_oracle 0.3048 (0.3609) acc 84.3750 (82.5781) kd_loss 0.9445 (1.0073) lr 1.9823e-03 eta 0:13:35
epoch [5/50] batch [60/162] time 0.098 (0.105) data 0.001 (0.004) loss 0.5865 (0.8159) ce_loss 0.2656 (0.4711) teacher_loss 0.2416 (0.4261) loss_zs_kd 0.0584 (0.0808) loss_oracle 0.3157 (0.3494) acc 87.5000 (82.9167) kd_loss 0.9958 (1.0064) lr 1.9823e-03 eta 0:12:58
epoch [5/50] batch [80/162] time 0.133 (0.105) data 0.000 (0.003) loss 1.0898 (0.8167) ce_loss 0.6602 (0.4707) teacher_loss 0.6785 (0.4278) loss_zs_kd 0.0894 (0.0821) loss_oracle 0.3666 (0.3479) acc 78.1250 (82.9688) kd_loss 0.9765 (1.0051) lr 1.9823e-03 eta 0:12:53
epoch [5/50] batch [100/162] time 0.081 (0.104) data 0.000 (0.003) loss 0.8488 (0.8203) ce_loss 0.5225 (0.4717) teacher_loss 0.4485 (0.4308) loss_zs_kd 0.1025 (0.0815) loss_oracle 0.3490 (0.3487) acc 75.0000 (82.4688) kd_loss 1.0202 (1.0040) lr 1.9823e-03 eta 0:12:42
epoch [5/50] batch [120/162] time 0.098 (0.102) data 0.000 (0.002) loss 0.9662 (0.8286) ce_loss 0.6479 (0.4716) teacher_loss 0.5867 (0.4266) loss_zs_kd 0.0856 (0.0830) loss_oracle 0.3367 (0.3605) acc 84.3750 (82.5781) kd_loss 0.9465 (1.0042) lr 1.9823e-03 eta 0:12:28
epoch [5/50] batch [140/162] time 0.089 (0.101) data 0.000 (0.002) loss 0.6886 (0.8336) ce_loss 0.2690 (0.4746) teacher_loss 0.2625 (0.4255) loss_zs_kd 0.0878 (0.0847) loss_oracle 0.3822 (0.3658) acc 87.5000 (82.7902) kd_loss 0.9858 (1.0032) lr 1.9823e-03 eta 0:12:21
epoch [5/50] batch [160/162] time 0.077 (0.100) data 0.000 (0.002) loss 0.6685 (0.8395) ce_loss 0.3208 (0.4734) teacher_loss 0.3427 (0.4292) loss_zs_kd 0.0373 (0.0836) loss_oracle 0.3071 (0.3685) acc 93.7500 (82.7930) kd_loss 1.0058 (1.0020) lr 1.9823e-03 eta 0:12:11
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,954
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 89.1%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,517
* accuracy: 76.7%
* error: 23.3%
* macro_f1: 73.8%
******* Domain s best val acc:      87.5%, epoch: 5 *******
******* Domain s best val test acc: 76.7%, epoch: 5 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [6/50] batch [20/162] time 0.164 (0.145) data 0.000 (0.014) loss 0.8778 (0.8555) ce_loss 0.4917 (0.4917) teacher_loss 0.4569 (0.4699) loss_zs_kd 0.0762 (0.0873) loss_oracle 0.3828 (0.3420) acc 84.3750 (81.4062) kd_loss 1.0316 (1.0070) lr 1.9686e-03 eta 0:17:31
epoch [6/50] batch [40/162] time 0.076 (0.141) data 0.000 (0.007) loss 0.6597 (0.8034) ce_loss 0.3076 (0.4495) teacher_loss 0.2762 (0.4196) loss_zs_kd 0.0965 (0.0875) loss_oracle 0.3353 (0.3401) acc 84.3750 (83.2031) kd_loss 1.0034 (1.0099) lr 1.9686e-03 eta 0:16:59
epoch [6/50] batch [60/162] time 0.108 (0.129) data 0.000 (0.005) loss 0.7444 (0.8074) ce_loss 0.3564 (0.4554) teacher_loss 0.3802 (0.4278) loss_zs_kd 0.0583 (0.0820) loss_oracle 0.3351 (0.3386) acc 87.5000 (83.3854) kd_loss 1.0097 (1.0078) lr 1.9686e-03 eta 0:15:31
epoch [6/50] batch [80/162] time 0.088 (0.124) data 0.000 (0.004) loss 0.7378 (0.8069) ce_loss 0.4136 (0.4592) teacher_loss 0.3831 (0.4305) loss_zs_kd 0.0757 (0.0817) loss_oracle 0.3169 (0.3356) acc 84.3750 (83.5547) kd_loss 1.0237 (1.0094) lr 1.9686e-03 eta 0:14:50
epoch [6/50] batch [100/162] time 0.088 (0.120) data 0.000 (0.003) loss 0.7424 (0.8024) ce_loss 0.3938 (0.4592) teacher_loss 0.3423 (0.4282) loss_zs_kd 0.0855 (0.0808) loss_oracle 0.3573 (0.3337) acc 87.5000 (83.3438) kd_loss 1.0525 (1.0110) lr 1.9686e-03 eta 0:14:19
epoch [6/50] batch [120/162] time 0.121 (0.117) data 0.000 (0.002) loss 0.6928 (0.8063) ce_loss 0.3726 (0.4627) teacher_loss 0.3291 (0.4319) loss_zs_kd 0.0571 (0.0827) loss_oracle 0.3352 (0.3330) acc 84.3750 (83.3333) kd_loss 1.0365 (1.0116) lr 1.9686e-03 eta 0:13:59
epoch [6/50] batch [140/162] time 0.098 (0.115) data 0.000 (0.002) loss 1.2614 (0.8103) ce_loss 0.9004 (0.4666) teacher_loss 0.8282 (0.4348) loss_zs_kd 0.1012 (0.0832) loss_oracle 0.3827 (0.3339) acc 71.8750 (83.0804) kd_loss 0.9565 (1.0100) lr 1.9686e-03 eta 0:13:40
epoch [6/50] batch [160/162] time 0.108 (0.112) data 0.000 (0.002) loss 0.8743 (0.8177) ce_loss 0.4790 (0.4712) teacher_loss 0.4484 (0.4384) loss_zs_kd 0.1227 (0.0861) loss_oracle 0.3645 (0.3363) acc 81.2500 (82.9102) kd_loss 1.0495 (1.0085) lr 1.9686e-03 eta 0:13:20
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,951
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,558
* accuracy: 77.9%
* error: 22.1%
* macro_f1: 73.9%
******* Domain s best val acc:      87.5%, epoch: 5 *******
******* Domain s best val test acc: 76.7%, epoch: 5 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [7/50] batch [20/162] time 0.135 (0.121) data 0.000 (0.013) loss 0.9004 (0.7679) ce_loss 0.5908 (0.4359) teacher_loss 0.5748 (0.4193) loss_zs_kd 0.0686 (0.0633) loss_oracle 0.2913 (0.3170) acc 78.1250 (84.2188) kd_loss 1.0370 (1.0044) lr 1.9511e-03 eta 0:14:16
epoch [7/50] batch [40/162] time 0.077 (0.115) data 0.000 (0.007) loss 0.5504 (0.7586) ce_loss 0.2666 (0.4460) teacher_loss 0.2302 (0.4121) loss_zs_kd 0.0628 (0.0701) loss_oracle 0.2888 (0.3114) acc 90.6250 (83.6719) kd_loss 0.9780 (1.0059) lr 1.9511e-03 eta 0:13:35
epoch [7/50] batch [60/162] time 0.085 (0.113) data 0.001 (0.005) loss 1.1584 (0.7838) ce_loss 0.6743 (0.4747) teacher_loss 0.7370 (0.4299) loss_zs_kd 0.1043 (0.0763) loss_oracle 0.3692 (0.3157) acc 75.0000 (82.2396) kd_loss 1.0034 (1.0040) lr 1.9511e-03 eta 0:13:20
epoch [7/50] batch [80/162] time 0.080 (0.113) data 0.000 (0.004) loss 0.8368 (0.7861) ce_loss 0.5742 (0.4757) teacher_loss 0.5161 (0.4342) loss_zs_kd 0.0769 (0.0774) loss_oracle 0.2823 (0.3132) acc 75.0000 (82.3047) kd_loss 1.0747 (1.0051) lr 1.9511e-03 eta 0:13:14
epoch [7/50] batch [100/162] time 0.115 (0.112) data 0.001 (0.003) loss 0.7943 (0.7790) ce_loss 0.5156 (0.4641) teacher_loss 0.4720 (0.4266) loss_zs_kd 0.0869 (0.0780) loss_oracle 0.2789 (0.3133) acc 75.0000 (82.8125) kd_loss 0.9745 (1.0066) lr 1.9511e-03 eta 0:13:06
epoch [7/50] batch [120/162] time 0.081 (0.111) data 0.000 (0.002) loss 1.0209 (0.7875) ce_loss 0.6274 (0.4683) teacher_loss 0.6120 (0.4340) loss_zs_kd 0.1115 (0.0802) loss_oracle 0.3531 (0.3135) acc 81.2500 (83.0208) kd_loss 0.9855 (1.0082) lr 1.9511e-03 eta 0:12:58
epoch [7/50] batch [140/162] time 0.082 (0.111) data 0.000 (0.002) loss 0.7246 (0.7906) ce_loss 0.3926 (0.4687) teacher_loss 0.3421 (0.4337) loss_zs_kd 0.1055 (0.0809) loss_oracle 0.3298 (0.3165) acc 81.2500 (83.0134) kd_loss 1.0178 (1.0089) lr 1.9511e-03 eta 0:12:52
epoch [7/50] batch [160/162] time 0.095 (0.109) data 0.001 (0.002) loss 0.6558 (0.7921) ce_loss 0.3792 (0.4686) teacher_loss 0.2947 (0.4299) loss_zs_kd 0.0945 (0.0818) loss_oracle 0.3138 (0.3213) acc 81.2500 (82.9102) kd_loss 0.9633 (1.0115) lr 1.9511e-03 eta 0:12:42
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,947
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,619
* accuracy: 79.8%
* error: 20.2%
* macro_f1: 75.1%
******* Domain s best val acc:      87.5%, epoch: 5 *******
******* Domain s best val test acc: 76.7%, epoch: 5 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [8/50] batch [20/162] time 0.175 (0.142) data 0.000 (0.015) loss 0.8748 (0.8395) ce_loss 0.4722 (0.4859) teacher_loss 0.4596 (0.4079) loss_zs_kd 0.0623 (0.0838) loss_oracle 0.3841 (0.3896) acc 81.2500 (81.5625) kd_loss 1.0167 (1.0031) lr 1.9298e-03 eta 0:16:29
epoch [8/50] batch [40/162] time 0.175 (0.137) data 0.000 (0.008) loss 1.0874 (0.8764) ce_loss 0.6133 (0.5152) teacher_loss 0.6086 (0.4417) loss_zs_kd 0.1146 (0.0936) loss_oracle 0.4215 (0.3879) acc 75.0000 (81.5625) kd_loss 0.9896 (1.0050) lr 1.9298e-03 eta 0:15:46
epoch [8/50] batch [60/162] time 0.175 (0.144) data 0.000 (0.005) loss 0.9001 (0.8508) ce_loss 0.5771 (0.4840) teacher_loss 0.5390 (0.4196) loss_zs_kd 0.0870 (0.0889) loss_oracle 0.3176 (0.3868) acc 75.0000 (82.4479) kd_loss 1.0099 (1.0000) lr 1.9298e-03 eta 0:16:33
epoch [8/50] batch [80/162] time 0.092 (0.133) data 0.000 (0.004) loss 1.1214 (0.8521) ce_loss 0.7720 (0.4778) teacher_loss 0.7028 (0.4227) loss_zs_kd 0.0602 (0.0851) loss_oracle 0.3885 (0.3868) acc 75.0000 (82.6562) kd_loss 1.0014 (0.9993) lr 1.9298e-03 eta 0:15:12
epoch [8/50] batch [100/162] time 0.131 (0.129) data 0.000 (0.003) loss 1.0134 (0.8502) ce_loss 0.6104 (0.4759) teacher_loss 0.5581 (0.4225) loss_zs_kd 0.0950 (0.0855) loss_oracle 0.4078 (0.3850) acc 75.0000 (82.6250) kd_loss 0.9819 (0.9993) lr 1.9298e-03 eta 0:14:43
epoch [8/50] batch [120/162] time 0.129 (0.126) data 0.000 (0.003) loss 1.1079 (0.8699) ce_loss 0.7266 (0.4788) teacher_loss 0.6179 (0.4265) loss_zs_kd 0.1146 (0.0872) loss_oracle 0.4327 (0.3998) acc 75.0000 (82.3177) kd_loss 1.0430 (0.9944) lr 1.9298e-03 eta 0:14:19
epoch [8/50] batch [140/162] time 0.120 (0.124) data 0.000 (0.002) loss 0.6885 (0.8611) ce_loss 0.4348 (0.4764) teacher_loss 0.3214 (0.4200) loss_zs_kd 0.0696 (0.0880) loss_oracle 0.3323 (0.3971) acc 84.3750 (82.2545) kd_loss 1.0303 (0.9948) lr 1.9298e-03 eta 0:14:07
epoch [8/50] batch [160/162] time 0.094 (0.120) data 0.000 (0.002) loss 0.9953 (0.8523) ce_loss 0.6978 (0.4719) teacher_loss 0.6001 (0.4132) loss_zs_kd 0.0777 (0.0898) loss_oracle 0.3563 (0.3942) acc 71.8750 (82.2266) kd_loss 0.9453 (0.9959) lr 1.9298e-03 eta 0:13:38
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,941
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,629
* accuracy: 80.1%
* error: 19.9%
* macro_f1: 75.3%
******* Domain s best val acc:      87.5%, epoch: 5 *******
******* Domain s best val test acc: 76.7%, epoch: 5 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [9/50] batch [20/162] time 0.088 (0.121) data 0.000 (0.014) loss 0.9920 (0.8925) ce_loss 0.6362 (0.4959) teacher_loss 0.6183 (0.4809) loss_zs_kd 0.1179 (0.0893) loss_oracle 0.3147 (0.3669) acc 81.2500 (80.7812) kd_loss 0.9852 (0.9933) lr 1.9048e-03 eta 0:13:40
epoch [9/50] batch [40/162] time 0.105 (0.114) data 0.000 (0.007) loss 0.8131 (0.8564) ce_loss 0.4543 (0.4746) teacher_loss 0.3999 (0.4505) loss_zs_kd 0.0808 (0.0922) loss_oracle 0.3728 (0.3598) acc 81.2500 (82.0312) kd_loss 1.0372 (0.9929) lr 1.9048e-03 eta 0:12:48
epoch [9/50] batch [60/162] time 0.085 (0.111) data 0.001 (0.005) loss 0.7820 (0.8434) ce_loss 0.4500 (0.4661) teacher_loss 0.3848 (0.4374) loss_zs_kd 0.0845 (0.0925) loss_oracle 0.3549 (0.3598) acc 87.5000 (82.5521) kd_loss 1.0115 (0.9935) lr 1.9048e-03 eta 0:12:29
epoch [9/50] batch [80/162] time 0.107 (0.110) data 0.000 (0.004) loss 0.9188 (0.8514) ce_loss 0.5786 (0.4702) teacher_loss 0.5184 (0.4421) loss_zs_kd 0.0781 (0.0926) loss_oracle 0.3614 (0.3631) acc 78.1250 (82.6172) kd_loss 0.9755 (0.9882) lr 1.9048e-03 eta 0:12:20
epoch [9/50] batch [100/162] time 0.097 (0.109) data 0.000 (0.003) loss 0.6963 (0.8455) ce_loss 0.3691 (0.4680) teacher_loss 0.3763 (0.4402) loss_zs_kd 0.0715 (0.0902) loss_oracle 0.2842 (0.3602) acc 81.2500 (82.5625) kd_loss 1.0303 (0.9889) lr 1.9048e-03 eta 0:12:11
epoch [9/50] batch [120/162] time 0.097 (0.108) data 0.000 (0.003) loss 0.7260 (0.8419) ce_loss 0.3586 (0.4675) teacher_loss 0.3489 (0.4397) loss_zs_kd 0.0419 (0.0882) loss_oracle 0.3561 (0.3581) acc 90.6250 (82.7083) kd_loss 0.9316 (0.9895) lr 1.9048e-03 eta 0:12:02
epoch [9/50] batch [140/162] time 0.121 (0.109) data 0.000 (0.002) loss 0.8441 (0.8397) ce_loss 0.3813 (0.4667) teacher_loss 0.3915 (0.4379) loss_zs_kd 0.0630 (0.0872) loss_oracle 0.4212 (0.3581) acc 81.2500 (82.8571) kd_loss 0.9943 (0.9872) lr 1.9048e-03 eta 0:12:08
epoch [9/50] batch [160/162] time 0.097 (0.108) data 0.000 (0.002) loss 1.0095 (0.8358) ce_loss 0.5781 (0.4624) teacher_loss 0.5104 (0.4324) loss_zs_kd 0.0964 (0.0877) loss_oracle 0.4509 (0.3596) acc 71.8750 (83.0664) kd_loss 1.0123 (0.9858) lr 1.9048e-03 eta 0:12:00
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,941
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,644
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 75.1%
******* Domain s best val acc:      87.5%, epoch: 5 *******
******* Domain s best val test acc: 76.7%, epoch: 5 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [10/50] batch [20/162] time 0.126 (0.123) data 0.000 (0.015) loss 1.0877 (0.8517) ce_loss 0.7803 (0.5068) teacher_loss 0.6943 (0.4611) loss_zs_kd 0.1006 (0.0904) loss_oracle 0.3431 (0.3453) acc 65.6250 (79.3750) kd_loss 1.0251 (0.9949) lr 1.8763e-03 eta 0:13:33
epoch [10/50] batch [40/162] time 0.171 (0.115) data 0.000 (0.008) loss 0.7658 (0.8207) ce_loss 0.4429 (0.4840) teacher_loss 0.4034 (0.4389) loss_zs_kd 0.0677 (0.0901) loss_oracle 0.3285 (0.3367) acc 84.3750 (80.8594) kd_loss 1.0224 (0.9998) lr 1.8763e-03 eta 0:12:41
epoch [10/50] batch [60/162] time 0.074 (0.120) data 0.001 (0.005) loss 0.8080 (0.8115) ce_loss 0.4895 (0.4694) teacher_loss 0.4212 (0.4193) loss_zs_kd 0.0911 (0.0885) loss_oracle 0.3412 (0.3479) acc 75.0000 (81.7188) kd_loss 0.9442 (0.9990) lr 1.8763e-03 eta 0:13:07
epoch [10/50] batch [80/162] time 0.176 (0.124) data 0.000 (0.004) loss 0.7397 (0.8129) ce_loss 0.3333 (0.4673) teacher_loss 0.3116 (0.4172) loss_zs_kd 0.0980 (0.0876) loss_oracle 0.3791 (0.3518) acc 90.6250 (81.9531) kd_loss 1.0062 (0.9988) lr 1.8763e-03 eta 0:13:30
epoch [10/50] batch [100/162] time 0.105 (0.124) data 0.000 (0.003) loss 1.0151 (0.8168) ce_loss 0.6553 (0.4693) teacher_loss 0.6166 (0.4218) loss_zs_kd 0.1027 (0.0873) loss_oracle 0.3471 (0.3513) acc 78.1250 (81.9688) kd_loss 0.9744 (0.9984) lr 1.8763e-03 eta 0:13:30
epoch [10/50] batch [120/162] time 0.115 (0.121) data 0.000 (0.003) loss 0.9841 (0.8173) ce_loss 0.6113 (0.4699) teacher_loss 0.5828 (0.4224) loss_zs_kd 0.0886 (0.0884) loss_oracle 0.3571 (0.3507) acc 71.8750 (82.0573) kd_loss 0.9438 (0.9978) lr 1.8763e-03 eta 0:13:08
epoch [10/50] batch [140/162] time 0.074 (0.119) data 0.000 (0.002) loss 0.8167 (0.8183) ce_loss 0.5151 (0.4699) teacher_loss 0.4559 (0.4252) loss_zs_kd 0.0866 (0.0863) loss_oracle 0.3175 (0.3500) acc 78.1250 (82.0759) kd_loss 0.9695 (0.9973) lr 1.8763e-03 eta 0:12:52
epoch [10/50] batch [160/162] time 0.098 (0.116) data 0.000 (0.002) loss 0.7650 (0.8160) ce_loss 0.4048 (0.4668) teacher_loss 0.3373 (0.4223) loss_zs_kd 0.1134 (0.0862) loss_oracle 0.3710 (0.3507) acc 81.2500 (82.2461) kd_loss 0.9733 (0.9975) lr 1.8763e-03 eta 0:12:31
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,949
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 89.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,634
* accuracy: 80.3%
* error: 19.7%
* macro_f1: 75.2%
******* Domain s best val acc:      87.5%, epoch: 5 *******
******* Domain s best val test acc: 76.7%, epoch: 5 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [11/50] batch [20/162] time 0.090 (0.128) data 0.000 (0.012) loss 0.5966 (0.7574) ce_loss 0.3071 (0.4083) teacher_loss 0.2419 (0.3576) loss_zs_kd 0.0939 (0.0878) loss_oracle 0.3077 (0.3559) acc 90.6250 (86.7188) kd_loss 0.9056 (0.9927) lr 1.8443e-03 eta 0:13:49
epoch [11/50] batch [40/162] time 0.142 (0.120) data 0.000 (0.006) loss 0.5742 (0.7742) ce_loss 0.2805 (0.4108) teacher_loss 0.2024 (0.3641) loss_zs_kd 0.1258 (0.0910) loss_oracle 0.3089 (0.3646) acc 90.6250 (85.4688) kd_loss 0.9744 (0.9942) lr 1.8443e-03 eta 0:12:51
epoch [11/50] batch [60/162] time 0.097 (0.117) data 0.001 (0.004) loss 0.9724 (0.7881) ce_loss 0.5532 (0.4258) teacher_loss 0.5187 (0.3810) loss_zs_kd 0.1212 (0.0933) loss_oracle 0.3932 (0.3605) acc 84.3750 (85.2083) kd_loss 1.0259 (0.9912) lr 1.8443e-03 eta 0:12:29
epoch [11/50] batch [80/162] time 0.117 (0.115) data 0.000 (0.003) loss 0.6907 (0.7949) ce_loss 0.3252 (0.4332) teacher_loss 0.2979 (0.3922) loss_zs_kd 0.0939 (0.0931) loss_oracle 0.3458 (0.3562) acc 90.6250 (84.8047) kd_loss 0.9997 (0.9886) lr 1.8443e-03 eta 0:12:13
epoch [11/50] batch [100/162] time 0.133 (0.113) data 0.000 (0.003) loss 0.8856 (0.8075) ce_loss 0.4465 (0.4458) teacher_loss 0.4745 (0.4083) loss_zs_kd 0.0792 (0.0910) loss_oracle 0.3715 (0.3537) acc 81.2500 (84.1562) kd_loss 1.0019 (0.9874) lr 1.8443e-03 eta 0:12:02
epoch [11/50] batch [120/162] time 0.102 (0.113) data 0.000 (0.002) loss 0.6085 (0.8053) ce_loss 0.3054 (0.4466) teacher_loss 0.2430 (0.4091) loss_zs_kd 0.0767 (0.0904) loss_oracle 0.3272 (0.3510) acc 90.6250 (83.9844) kd_loss 1.0310 (0.9900) lr 1.8443e-03 eta 0:11:57
epoch [11/50] batch [140/162] time 0.135 (0.112) data 0.000 (0.002) loss 0.6818 (0.8029) ce_loss 0.3535 (0.4498) teacher_loss 0.3139 (0.4094) loss_zs_kd 0.0702 (0.0913) loss_oracle 0.3328 (0.3479) acc 93.7500 (83.7723) kd_loss 0.9262 (0.9918) lr 1.8443e-03 eta 0:11:52
epoch [11/50] batch [160/162] time 0.093 (0.111) data 0.000 (0.002) loss 0.6357 (0.8004) ce_loss 0.2423 (0.4515) teacher_loss 0.2328 (0.4095) loss_zs_kd 0.1091 (0.0903) loss_oracle 0.3484 (0.3457) acc 90.6250 (83.5938) kd_loss 1.0282 (0.9917) lr 1.8443e-03 eta 0:11:39
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,949
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 89.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,625
* accuracy: 80.0%
* error: 20.0%
* macro_f1: 75.0%
******* Domain s best val acc:      87.5%, epoch: 5 *******
******* Domain s best val test acc: 76.7%, epoch: 5 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [12/50] batch [20/162] time 0.099 (0.112) data 0.000 (0.011) loss 0.8214 (0.9072) ce_loss 0.4036 (0.4862) teacher_loss 0.4043 (0.4591) loss_zs_kd 0.0621 (0.1029) loss_oracle 0.3861 (0.3967) acc 81.2500 (81.5625) kd_loss 0.9855 (0.9847) lr 1.8090e-03 eta 0:11:47
epoch [12/50] batch [40/162] time 0.114 (0.107) data 0.000 (0.006) loss 0.9125 (0.9140) ce_loss 0.4827 (0.4910) teacher_loss 0.4012 (0.4586) loss_zs_kd 0.1237 (0.1038) loss_oracle 0.4495 (0.4035) acc 78.1250 (81.6406) kd_loss 1.0331 (1.0066) lr 1.8090e-03 eta 0:11:13
epoch [12/50] batch [60/162] time 0.079 (0.103) data 0.001 (0.004) loss 1.1113 (0.8929) ce_loss 0.6724 (0.4882) teacher_loss 0.7127 (0.4569) loss_zs_kd 0.1041 (0.1030) loss_oracle 0.3465 (0.3845) acc 71.8750 (81.8750) kd_loss 1.0171 (1.0212) lr 1.8090e-03 eta 0:10:46
epoch [12/50] batch [80/162] time 0.131 (0.111) data 0.000 (0.003) loss 0.7793 (0.8679) ce_loss 0.4822 (0.4791) teacher_loss 0.3646 (0.4416) loss_zs_kd 0.1109 (0.1017) loss_oracle 0.3592 (0.3754) acc 84.3750 (82.3438) kd_loss 1.0556 (1.0283) lr 1.8090e-03 eta 0:11:29
epoch [12/50] batch [100/162] time 0.132 (0.110) data 0.000 (0.002) loss 0.8605 (0.8579) ce_loss 0.5029 (0.4800) teacher_loss 0.4655 (0.4382) loss_zs_kd 0.1034 (0.1033) loss_oracle 0.3433 (0.3681) acc 84.3750 (82.4375) kd_loss 1.0567 (1.0343) lr 1.8090e-03 eta 0:11:24
epoch [12/50] batch [120/162] time 0.134 (0.115) data 0.000 (0.002) loss 0.7079 (0.8449) ce_loss 0.3821 (0.4715) teacher_loss 0.3802 (0.4288) loss_zs_kd 0.0524 (0.1010) loss_oracle 0.3015 (0.3656) acc 84.3750 (82.9688) kd_loss 0.9573 (1.0316) lr 1.8090e-03 eta 0:11:52
epoch [12/50] batch [140/162] time 0.088 (0.114) data 0.000 (0.002) loss 0.6502 (0.8420) ce_loss 0.3613 (0.4728) teacher_loss 0.3110 (0.4309) loss_zs_kd 0.0889 (0.0990) loss_oracle 0.2947 (0.3617) acc 84.3750 (82.7009) kd_loss 1.0021 (1.0271) lr 1.8090e-03 eta 0:11:46
epoch [12/50] batch [160/162] time 0.085 (0.113) data 0.000 (0.002) loss 1.0696 (0.8280) ce_loss 0.6650 (0.4625) teacher_loss 0.6314 (0.4202) loss_zs_kd 0.1142 (0.0990) loss_oracle 0.3811 (0.3583) acc 75.0000 (83.1055) kd_loss 1.1083 (1.0245) lr 1.8090e-03 eta 0:11:33
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,949
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 89.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,603
* accuracy: 79.3%
* error: 20.7%
* macro_f1: 74.8%
******* Domain s best val acc:      87.5%, epoch: 5 *******
******* Domain s best val test acc: 76.7%, epoch: 5 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [13/50] batch [20/162] time 0.092 (0.107) data 0.000 (0.012) loss 0.8619 (0.8386) ce_loss 0.4241 (0.4694) teacher_loss 0.4093 (0.4367) loss_zs_kd 0.0896 (0.0931) loss_oracle 0.4078 (0.3553) acc 87.5000 (82.5000) kd_loss 1.0417 (1.0060) lr 1.7705e-03 eta 0:10:55
epoch [13/50] batch [40/162] time 0.078 (0.103) data 0.000 (0.006) loss 0.9260 (0.8322) ce_loss 0.5508 (0.4686) teacher_loss 0.4779 (0.4330) loss_zs_kd 0.1223 (0.0937) loss_oracle 0.3870 (0.3524) acc 78.1250 (82.4219) kd_loss 1.1165 (1.0103) lr 1.7705e-03 eta 0:10:29
epoch [13/50] batch [60/162] time 0.084 (0.100) data 0.000 (0.004) loss 0.9034 (0.8264) ce_loss 0.5850 (0.4576) teacher_loss 0.5213 (0.4212) loss_zs_kd 0.0966 (0.0951) loss_oracle 0.3338 (0.3577) acc 84.3750 (83.1771) kd_loss 1.0109 (1.0182) lr 1.7705e-03 eta 0:10:07
epoch [13/50] batch [80/162] time 0.129 (0.100) data 0.000 (0.003) loss 1.3192 (0.8398) ce_loss 0.9087 (0.4668) teacher_loss 0.9254 (0.4313) loss_zs_kd 0.1103 (0.0944) loss_oracle 0.3386 (0.3613) acc 75.0000 (82.8125) kd_loss 1.0287 (1.0244) lr 1.7705e-03 eta 0:10:08
epoch [13/50] batch [100/162] time 0.131 (0.101) data 0.000 (0.002) loss 0.6092 (0.8243) ce_loss 0.3284 (0.4579) teacher_loss 0.2676 (0.4200) loss_zs_kd 0.1014 (0.0933) loss_oracle 0.2909 (0.3577) acc 90.6250 (83.1250) kd_loss 1.0436 (1.0272) lr 1.7705e-03 eta 0:10:13
epoch [13/50] batch [120/162] time 0.084 (0.101) data 0.000 (0.002) loss 0.7751 (0.8196) ce_loss 0.4360 (0.4571) teacher_loss 0.3987 (0.4193) loss_zs_kd 0.0728 (0.0921) loss_oracle 0.3400 (0.3542) acc 78.1250 (83.0729) kd_loss 1.0230 (1.0240) lr 1.7705e-03 eta 0:10:11
epoch [13/50] batch [140/162] time 0.118 (0.101) data 0.000 (0.002) loss 0.7011 (0.8154) ce_loss 0.3198 (0.4566) teacher_loss 0.2879 (0.4146) loss_zs_kd 0.1142 (0.0937) loss_oracle 0.3561 (0.3540) acc 90.6250 (83.3259) kd_loss 0.9858 (1.0253) lr 1.7705e-03 eta 0:10:08
epoch [13/50] batch [160/162] time 0.074 (0.100) data 0.000 (0.002) loss 0.6726 (0.8167) ce_loss 0.3315 (0.4579) teacher_loss 0.2496 (0.4146) loss_zs_kd 0.0792 (0.0952) loss_oracle 0.3834 (0.3545) acc 84.3750 (83.1445) kd_loss 0.9554 (1.0220) lr 1.7705e-03 eta 0:09:58
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,947
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,619
* accuracy: 79.8%
* error: 20.2%
* macro_f1: 74.9%
******* Domain s best val acc:      87.5%, epoch: 5 *******
******* Domain s best val test acc: 76.7%, epoch: 5 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [14/50] batch [20/162] time 0.076 (0.113) data 0.000 (0.013) loss 0.8435 (0.8327) ce_loss 0.5293 (0.4460) teacher_loss 0.4814 (0.4185) loss_zs_kd 0.0819 (0.0995) loss_oracle 0.3212 (0.3644) acc 84.3750 (83.1250) kd_loss 0.9634 (0.9902) lr 1.7290e-03 eta 0:11:16
epoch [14/50] batch [40/162] time 0.124 (0.108) data 0.000 (0.007) loss 0.8934 (0.8383) ce_loss 0.4890 (0.4496) teacher_loss 0.5126 (0.4278) loss_zs_kd 0.0776 (0.0907) loss_oracle 0.3421 (0.3652) acc 84.3750 (82.8125) kd_loss 0.9946 (0.9831) lr 1.7290e-03 eta 0:10:43
epoch [14/50] batch [60/162] time 0.113 (0.105) data 0.001 (0.005) loss 0.7294 (0.8361) ce_loss 0.4441 (0.4537) teacher_loss 0.3263 (0.4229) loss_zs_kd 0.1384 (0.0969) loss_oracle 0.3339 (0.3648) acc 84.3750 (82.9167) kd_loss 0.9664 (0.9961) lr 1.7290e-03 eta 0:10:21
epoch [14/50] batch [80/162] time 0.108 (0.103) data 0.000 (0.003) loss 0.8552 (0.8363) ce_loss 0.4282 (0.4644) teacher_loss 0.4598 (0.4236) loss_zs_kd 0.1004 (0.0991) loss_oracle 0.3451 (0.3631) acc 90.6250 (82.8125) kd_loss 0.9718 (1.0043) lr 1.7290e-03 eta 0:10:11
epoch [14/50] batch [100/162] time 0.088 (0.103) data 0.000 (0.003) loss 0.8783 (0.8357) ce_loss 0.5898 (0.4650) teacher_loss 0.4457 (0.4186) loss_zs_kd 0.1235 (0.1026) loss_oracle 0.3708 (0.3658) acc 81.2500 (82.4688) kd_loss 1.0280 (1.0099) lr 1.7290e-03 eta 0:10:07
epoch [14/50] batch [120/162] time 0.124 (0.102) data 0.000 (0.002) loss 0.6288 (0.8249) ce_loss 0.2603 (0.4561) teacher_loss 0.2619 (0.4108) loss_zs_kd 0.0782 (0.1023) loss_oracle 0.3277 (0.3629) acc 90.6250 (82.9167) kd_loss 0.9367 (1.0093) lr 1.7290e-03 eta 0:10:01
epoch [14/50] batch [140/162] time 0.170 (0.104) data 0.000 (0.002) loss 0.8032 (0.8237) ce_loss 0.4199 (0.4555) teacher_loss 0.3573 (0.4082) loss_zs_kd 0.1313 (0.1022) loss_oracle 0.3803 (0.3644) acc 87.5000 (83.0580) kd_loss 0.9444 (1.0075) lr 1.7290e-03 eta 0:10:10
epoch [14/50] batch [160/162] time 0.072 (0.105) data 0.000 (0.002) loss 1.0402 (0.8274) ce_loss 0.5781 (0.4594) teacher_loss 0.6069 (0.4124) loss_zs_kd 0.1183 (0.1016) loss_oracle 0.3741 (0.3641) acc 78.1250 (82.8711) kd_loss 1.0712 (1.0070) lr 1.7290e-03 eta 0:10:13
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,960
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 89.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,591
* accuracy: 78.9%
* error: 21.1%
* macro_f1: 74.0%
******* Domain s best val acc:      87.7%, epoch: 14 *******
******* Domain s best val test acc: 78.9%, epoch: 14 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [15/50] batch [20/162] time 0.140 (0.131) data 0.000 (0.012) loss 1.0476 (0.8062) ce_loss 0.6812 (0.4303) teacher_loss 0.6851 (0.4123) loss_zs_kd 0.0643 (0.0828) loss_oracle 0.3304 (0.3524) acc 75.0000 (85.4688) kd_loss 0.9655 (1.0024) lr 1.6845e-03 eta 0:12:43
epoch [15/50] batch [40/162] time 0.088 (0.124) data 0.000 (0.006) loss 0.7944 (0.7901) ce_loss 0.4028 (0.4218) teacher_loss 0.3752 (0.3957) loss_zs_kd 0.0788 (0.0801) loss_oracle 0.3798 (0.3543) acc 81.2500 (84.7656) kd_loss 1.0085 (0.9949) lr 1.6845e-03 eta 0:11:59
epoch [15/50] batch [60/162] time 0.133 (0.119) data 0.001 (0.004) loss 0.6547 (0.8062) ce_loss 0.2781 (0.4409) teacher_loss 0.2346 (0.4020) loss_zs_kd 0.0767 (0.0915) loss_oracle 0.3818 (0.3584) acc 93.7500 (84.1146) kd_loss 1.0234 (1.0068) lr 1.6845e-03 eta 0:11:24
epoch [15/50] batch [80/162] time 0.114 (0.116) data 0.000 (0.003) loss 0.9407 (0.8057) ce_loss 0.5913 (0.4449) teacher_loss 0.5496 (0.3983) loss_zs_kd 0.1048 (0.0993) loss_oracle 0.3387 (0.3577) acc 75.0000 (83.8281) kd_loss 1.0645 (1.0138) lr 1.6845e-03 eta 0:11:07
epoch [15/50] batch [100/162] time 0.116 (0.114) data 0.000 (0.003) loss 0.7660 (0.8162) ce_loss 0.3984 (0.4558) teacher_loss 0.3633 (0.4088) loss_zs_kd 0.0717 (0.0982) loss_oracle 0.3668 (0.3583) acc 87.5000 (83.7188) kd_loss 0.9548 (1.0187) lr 1.6845e-03 eta 0:10:55
epoch [15/50] batch [120/162] time 0.082 (0.112) data 0.000 (0.002) loss 1.0173 (0.8193) ce_loss 0.6777 (0.4592) teacher_loss 0.6163 (0.4103) loss_zs_kd 0.1201 (0.0988) loss_oracle 0.3410 (0.3596) acc 84.3750 (83.3073) kd_loss 1.0767 (1.0184) lr 1.6845e-03 eta 0:10:41
epoch [15/50] batch [140/162] time 0.099 (0.112) data 0.000 (0.002) loss 0.6802 (0.8162) ce_loss 0.3972 (0.4599) teacher_loss 0.3065 (0.4084) loss_zs_kd 0.0999 (0.1008) loss_oracle 0.3238 (0.3574) acc 75.0000 (83.2589) kd_loss 0.9478 (1.0187) lr 1.6845e-03 eta 0:10:37
epoch [15/50] batch [160/162] time 0.094 (0.110) data 0.000 (0.002) loss 0.7883 (0.8066) ce_loss 0.4346 (0.4512) teacher_loss 0.3952 (0.3988) loss_zs_kd 0.0917 (0.1009) loss_oracle 0.3472 (0.3573) acc 87.5000 (83.4961) kd_loss 0.9777 (1.0180) lr 1.6845e-03 eta 0:10:24
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,947
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,640
* accuracy: 80.4%
* error: 19.6%
* macro_f1: 75.0%
******* Domain s best val acc:      87.7%, epoch: 14 *******
******* Domain s best val test acc: 78.9%, epoch: 14 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [16/50] batch [20/162] time 0.113 (0.112) data 0.000 (0.013) loss 0.8124 (0.8397) ce_loss 0.4307 (0.4749) teacher_loss 0.4023 (0.4472) loss_zs_kd 0.1075 (0.0913) loss_oracle 0.3563 (0.3468) acc 81.2500 (81.8750) kd_loss 1.0587 (1.0113) lr 1.6374e-03 eta 0:10:33
epoch [16/50] batch [40/162] time 0.096 (0.109) data 0.000 (0.006) loss 0.6149 (0.8351) ce_loss 0.2119 (0.4663) teacher_loss 0.1892 (0.4312) loss_zs_kd 0.0667 (0.0905) loss_oracle 0.3923 (0.3586) acc 96.8750 (82.4219) kd_loss 1.0508 (1.0194) lr 1.6374e-03 eta 0:10:12
epoch [16/50] batch [60/162] time 0.132 (0.109) data 0.001 (0.004) loss 0.8465 (0.8359) ce_loss 0.5186 (0.4814) teacher_loss 0.3858 (0.4322) loss_zs_kd 0.1655 (0.0910) loss_oracle 0.3780 (0.3582) acc 81.2500 (81.5625) kd_loss 0.9740 (1.0147) lr 1.6374e-03 eta 0:10:12
epoch [16/50] batch [80/162] time 0.114 (0.108) data 0.000 (0.003) loss 1.0186 (0.8214) ce_loss 0.6831 (0.4681) teacher_loss 0.6071 (0.4187) loss_zs_kd 0.0914 (0.0911) loss_oracle 0.3657 (0.3572) acc 75.0000 (82.2266) kd_loss 0.9800 (1.0165) lr 1.6374e-03 eta 0:10:04
epoch [16/50] batch [100/162] time 0.108 (0.107) data 0.000 (0.003) loss 0.9074 (0.8200) ce_loss 0.6499 (0.4713) teacher_loss 0.5346 (0.4186) loss_zs_kd 0.1040 (0.0917) loss_oracle 0.3208 (0.3556) acc 81.2500 (82.3438) kd_loss 1.0255 (1.0183) lr 1.6374e-03 eta 0:09:55
epoch [16/50] batch [120/162] time 0.071 (0.106) data 0.000 (0.002) loss 0.7988 (0.8254) ce_loss 0.4692 (0.4795) teacher_loss 0.4195 (0.4261) loss_zs_kd 0.0851 (0.0920) loss_oracle 0.3368 (0.3533) acc 84.3750 (82.1875) kd_loss 0.9803 (1.0216) lr 1.6374e-03 eta 0:09:48
epoch [16/50] batch [140/162] time 0.082 (0.105) data 0.000 (0.002) loss 0.5957 (0.8090) ce_loss 0.2493 (0.4637) teacher_loss 0.2192 (0.4103) loss_zs_kd 0.0897 (0.0935) loss_oracle 0.3317 (0.3521) acc 96.8750 (82.9911) kd_loss 1.0480 (1.0187) lr 1.6374e-03 eta 0:09:41
epoch [16/50] batch [160/162] time 0.073 (0.103) data 0.000 (0.002) loss 0.7236 (0.8058) ce_loss 0.4568 (0.4615) teacher_loss 0.3705 (0.4087) loss_zs_kd 0.1164 (0.0933) loss_oracle 0.2949 (0.3504) acc 75.0000 (83.0859) kd_loss 1.0079 (1.0159) lr 1.6374e-03 eta 0:09:29
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,937
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 88.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,645
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 76.2%
******* Domain s best val acc:      87.7%, epoch: 14 *******
******* Domain s best val test acc: 78.9%, epoch: 14 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [17/50] batch [20/162] time 0.079 (0.148) data 0.000 (0.014) loss 0.7547 (0.7575) ce_loss 0.4861 (0.4212) teacher_loss 0.3792 (0.3710) loss_zs_kd 0.0760 (0.0934) loss_oracle 0.3375 (0.3397) acc 81.2500 (85.7812) kd_loss 0.9578 (0.9820) lr 1.5878e-03 eta 0:13:29
epoch [17/50] batch [40/162] time 0.087 (0.124) data 0.000 (0.007) loss 0.7706 (0.7596) ce_loss 0.4097 (0.4055) teacher_loss 0.3936 (0.3700) loss_zs_kd 0.1155 (0.0929) loss_oracle 0.3193 (0.3431) acc 78.1250 (85.2344) kd_loss 0.9736 (0.9696) lr 1.5878e-03 eta 0:11:16
epoch [17/50] batch [60/162] time 0.120 (0.116) data 0.001 (0.005) loss 0.7670 (0.7836) ce_loss 0.4092 (0.4194) teacher_loss 0.3551 (0.3931) loss_zs_kd 0.0776 (0.0903) loss_oracle 0.3731 (0.3454) acc 81.2500 (84.3229) kd_loss 0.9826 (0.9685) lr 1.5878e-03 eta 0:10:30
epoch [17/50] batch [80/162] time 0.107 (0.113) data 0.000 (0.003) loss 0.7271 (0.7978) ce_loss 0.4492 (0.4350) teacher_loss 0.3956 (0.4080) loss_zs_kd 0.0721 (0.0898) loss_oracle 0.2955 (0.3449) acc 75.0000 (83.7109) kd_loss 1.0013 (0.9749) lr 1.5878e-03 eta 0:10:12
epoch [17/50] batch [100/162] time 0.078 (0.111) data 0.000 (0.003) loss 0.9075 (0.8084) ce_loss 0.5303 (0.4523) teacher_loss 0.5562 (0.4205) loss_zs_kd 0.0948 (0.0908) loss_oracle 0.3040 (0.3425) acc 78.1250 (83.3125) kd_loss 1.0112 (0.9821) lr 1.5878e-03 eta 0:10:02
epoch [17/50] batch [120/162] time 0.100 (0.111) data 0.000 (0.002) loss 0.7350 (0.8078) ce_loss 0.3147 (0.4497) teacher_loss 0.2875 (0.4134) loss_zs_kd 0.0929 (0.0934) loss_oracle 0.4010 (0.3478) acc 90.6250 (83.4115) kd_loss 1.0342 (0.9894) lr 1.5878e-03 eta 0:09:56
epoch [17/50] batch [140/162] time 0.135 (0.110) data 0.001 (0.002) loss 0.6222 (0.8091) ce_loss 0.2544 (0.4501) teacher_loss 0.1851 (0.4117) loss_zs_kd 0.0708 (0.0953) loss_oracle 0.4017 (0.3497) acc 90.6250 (83.1473) kd_loss 1.0683 (0.9966) lr 1.5878e-03 eta 0:09:52
epoch [17/50] batch [160/162] time 0.092 (0.109) data 0.000 (0.002) loss 0.6558 (0.8044) ce_loss 0.3906 (0.4501) teacher_loss 0.3193 (0.4112) loss_zs_kd 0.0895 (0.0946) loss_oracle 0.2918 (0.3459) acc 81.2500 (83.2812) kd_loss 0.9443 (1.0000) lr 1.5878e-03 eta 0:09:42
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,961
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 89.5%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,579
* accuracy: 78.6%
* error: 21.4%
* macro_f1: 73.8%
******* Domain s best val acc:      87.8%, epoch: 17 *******
******* Domain s best val test acc: 78.6%, epoch: 17 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [18/50] batch [20/162] time 0.083 (0.109) data 0.000 (0.013) loss 0.6137 (0.7802) ce_loss 0.2927 (0.4484) teacher_loss 0.2418 (0.4048) loss_zs_kd 0.0878 (0.0865) loss_oracle 0.3281 (0.3321) acc 90.6250 (83.4375) kd_loss 1.0643 (1.0082) lr 1.5358e-03 eta 0:09:39
epoch [18/50] batch [40/162] time 0.108 (0.106) data 0.000 (0.006) loss 0.6814 (0.7772) ce_loss 0.4124 (0.4450) teacher_loss 0.3138 (0.3966) loss_zs_kd 0.0825 (0.0901) loss_oracle 0.3264 (0.3356) acc 81.2500 (84.5312) kd_loss 0.9644 (1.0187) lr 1.5358e-03 eta 0:09:21
epoch [18/50] batch [60/162] time 0.079 (0.106) data 0.001 (0.004) loss 0.7389 (0.7772) ce_loss 0.4714 (0.4448) teacher_loss 0.3399 (0.3930) loss_zs_kd 0.1289 (0.0956) loss_oracle 0.3345 (0.3364) acc 78.1250 (83.9583) kd_loss 0.9998 (1.0295) lr 1.5358e-03 eta 0:09:17
epoch [18/50] batch [80/162] time 0.125 (0.106) data 0.000 (0.003) loss 0.7576 (0.7818) ce_loss 0.4624 (0.4496) teacher_loss 0.4183 (0.3977) loss_zs_kd 0.1002 (0.0997) loss_oracle 0.2892 (0.3342) acc 81.2500 (83.9844) kd_loss 1.0649 (1.0309) lr 1.5358e-03 eta 0:09:16
epoch [18/50] batch [100/162] time 0.082 (0.106) data 0.000 (0.003) loss 0.8152 (0.7859) ce_loss 0.5039 (0.4533) teacher_loss 0.4067 (0.4007) loss_zs_kd 0.1158 (0.0995) loss_oracle 0.3506 (0.3354) acc 78.1250 (83.4688) kd_loss 0.9954 (1.0297) lr 1.5358e-03 eta 0:09:14
epoch [18/50] batch [120/162] time 0.122 (0.105) data 0.000 (0.002) loss 1.1669 (0.7824) ce_loss 0.7700 (0.4472) teacher_loss 0.7589 (0.3959) loss_zs_kd 0.1125 (0.0975) loss_oracle 0.3518 (0.3378) acc 71.8750 (83.5156) kd_loss 1.0658 (1.0298) lr 1.5358e-03 eta 0:09:10
epoch [18/50] batch [140/162] time 0.081 (0.105) data 0.000 (0.002) loss 0.5637 (0.7859) ce_loss 0.1992 (0.4495) teacher_loss 0.1697 (0.3999) loss_zs_kd 0.0667 (0.0963) loss_oracle 0.3607 (0.3378) acc 93.7500 (83.6830) kd_loss 0.9633 (1.0287) lr 1.5358e-03 eta 0:09:06
epoch [18/50] batch [160/162] time 0.071 (0.104) data 0.000 (0.002) loss 0.6188 (0.8024) ce_loss 0.2742 (0.4601) teacher_loss 0.2369 (0.4141) loss_zs_kd 0.0654 (0.0965) loss_oracle 0.3492 (0.3401) acc 96.8750 (83.2422) kd_loss 1.0765 (1.0273) lr 1.5358e-03 eta 0:08:57
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,961
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 89.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,591
* accuracy: 78.9%
* error: 21.1%
* macro_f1: 74.3%
******* Domain s best val acc:      87.8%, epoch: 17 *******
******* Domain s best val test acc: 78.6%, epoch: 17 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [19/50] batch [20/162] time 0.120 (0.137) data 0.000 (0.011) loss 1.1434 (0.8215) ce_loss 0.7432 (0.4326) teacher_loss 0.6904 (0.4211) loss_zs_kd 0.1194 (0.0883) loss_oracle 0.3933 (0.3562) acc 59.3750 (83.5938) kd_loss 1.1405 (1.0738) lr 1.4818e-03 eta 0:11:48
epoch [19/50] batch [40/162] time 0.140 (0.142) data 0.000 (0.006) loss 0.8406 (0.8270) ce_loss 0.4844 (0.4550) teacher_loss 0.4850 (0.4364) loss_zs_kd 0.0575 (0.0939) loss_oracle 0.3268 (0.3436) acc 84.3750 (83.2031) kd_loss 1.0173 (1.0543) lr 1.4818e-03 eta 0:12:11
epoch [19/50] batch [60/162] time 0.085 (0.127) data 0.001 (0.004) loss 0.8780 (0.8088) ce_loss 0.4861 (0.4506) teacher_loss 0.4817 (0.4213) loss_zs_kd 0.0991 (0.1001) loss_oracle 0.3468 (0.3375) acc 75.0000 (83.1250) kd_loss 1.0069 (1.0431) lr 1.4818e-03 eta 0:10:48
epoch [19/50] batch [80/162] time 0.096 (0.122) data 0.000 (0.003) loss 0.7746 (0.7967) ce_loss 0.4707 (0.4472) teacher_loss 0.3842 (0.4071) loss_zs_kd 0.0981 (0.1003) loss_oracle 0.3413 (0.3395) acc 87.5000 (83.3203) kd_loss 1.0356 (1.0384) lr 1.4818e-03 eta 0:10:20
epoch [19/50] batch [100/162] time 0.143 (0.120) data 0.000 (0.002) loss 0.7322 (0.8002) ce_loss 0.4761 (0.4552) teacher_loss 0.3516 (0.4113) loss_zs_kd 0.1337 (0.1031) loss_oracle 0.3137 (0.3374) acc 81.2500 (83.0000) kd_loss 1.0206 (1.0363) lr 1.4818e-03 eta 0:10:07
epoch [19/50] batch [120/162] time 0.097 (0.118) data 0.000 (0.002) loss 0.7008 (0.7942) ce_loss 0.3005 (0.4492) teacher_loss 0.2654 (0.4077) loss_zs_kd 0.0955 (0.1001) loss_oracle 0.3877 (0.3365) acc 93.7500 (83.4635) kd_loss 0.9444 (1.0329) lr 1.4818e-03 eta 0:09:56
epoch [19/50] batch [140/162] time 0.128 (0.117) data 0.000 (0.002) loss 0.7346 (0.7988) ce_loss 0.3467 (0.4522) teacher_loss 0.3020 (0.4122) loss_zs_kd 0.1293 (0.0980) loss_oracle 0.3679 (0.3376) acc 87.5000 (83.3705) kd_loss 1.0341 (1.0337) lr 1.4818e-03 eta 0:09:48
epoch [19/50] batch [160/162] time 0.089 (0.113) data 0.000 (0.002) loss 0.6707 (0.8005) ce_loss 0.2971 (0.4543) teacher_loss 0.2791 (0.4151) loss_zs_kd 0.1039 (0.0969) loss_oracle 0.3396 (0.3369) acc 93.7500 (83.4375) kd_loss 0.9569 (1.0296) lr 1.4818e-03 eta 0:09:29
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 89.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,622
* accuracy: 79.9%
* error: 20.1%
* macro_f1: 74.6%
******* Domain s best val acc:      87.8%, epoch: 17 *******
******* Domain s best val test acc: 78.6%, epoch: 17 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [20/50] batch [20/162] time 0.122 (0.122) data 0.000 (0.017) loss 0.8875 (0.7956) ce_loss 0.5005 (0.4699) teacher_loss 0.4457 (0.4073) loss_zs_kd 0.1475 (0.1098) loss_oracle 0.3681 (0.3334) acc 84.3750 (83.2812) kd_loss 0.9500 (1.0355) lr 1.4258e-03 eta 0:10:12
epoch [20/50] batch [40/162] time 0.086 (0.111) data 0.000 (0.009) loss 0.6910 (0.7955) ce_loss 0.3645 (0.4577) teacher_loss 0.2694 (0.4000) loss_zs_kd 0.1147 (0.1103) loss_oracle 0.3642 (0.3403) acc 90.6250 (84.2188) kd_loss 1.0561 (1.0197) lr 1.4258e-03 eta 0:09:14
epoch [20/50] batch [60/162] time 0.134 (0.110) data 0.001 (0.006) loss 0.7147 (0.8095) ce_loss 0.3464 (0.4740) teacher_loss 0.3493 (0.4198) loss_zs_kd 0.0792 (0.1038) loss_oracle 0.3259 (0.3378) acc 87.5000 (83.2292) kd_loss 0.9987 (1.0223) lr 1.4258e-03 eta 0:09:07
epoch [20/50] batch [80/162] time 0.135 (0.109) data 0.000 (0.004) loss 0.8330 (0.7990) ce_loss 0.5103 (0.4605) teacher_loss 0.4348 (0.4084) loss_zs_kd 0.1286 (0.1064) loss_oracle 0.3338 (0.3374) acc 78.1250 (83.5938) kd_loss 1.1001 (1.0256) lr 1.4258e-03 eta 0:08:57
epoch [20/50] batch [100/162] time 0.117 (0.110) data 0.000 (0.004) loss 0.7889 (0.8009) ce_loss 0.4299 (0.4598) teacher_loss 0.3713 (0.4097) loss_zs_kd 0.0877 (0.1052) loss_oracle 0.3737 (0.3386) acc 81.2500 (83.1250) kd_loss 1.0594 (1.0341) lr 1.4258e-03 eta 0:09:00
epoch [20/50] batch [120/162] time 0.161 (0.110) data 0.000 (0.003) loss 0.6246 (0.7950) ce_loss 0.3225 (0.4554) teacher_loss 0.2375 (0.4055) loss_zs_kd 0.0721 (0.1019) loss_oracle 0.3511 (0.3385) acc 93.7500 (83.4375) kd_loss 1.0820 (1.0374) lr 1.4258e-03 eta 0:08:57
epoch [20/50] batch [140/162] time 0.118 (0.110) data 0.000 (0.003) loss 0.9664 (0.7911) ce_loss 0.5635 (0.4535) teacher_loss 0.5294 (0.4023) loss_zs_kd 0.1171 (0.1010) loss_oracle 0.3785 (0.3383) acc 87.5000 (83.5938) kd_loss 1.0881 (1.0410) lr 1.4258e-03 eta 0:08:55
epoch [20/50] batch [160/162] time 0.094 (0.107) data 0.000 (0.002) loss 0.6827 (0.7923) ce_loss 0.3145 (0.4542) teacher_loss 0.3031 (0.4043) loss_zs_kd 0.0858 (0.1009) loss_oracle 0.3367 (0.3375) acc 93.7500 (83.4570) kd_loss 0.9939 (1.0394) lr 1.4258e-03 eta 0:08:40
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,962
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 89.6%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,576
* accuracy: 78.5%
* error: 21.5%
* macro_f1: 73.6%
******* Domain s best val acc:      87.8%, epoch: 20 *******
******* Domain s best val test acc: 78.5%, epoch: 20 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [21/50] batch [20/162] time 0.175 (0.135) data 0.000 (0.013) loss 0.8527 (0.7979) ce_loss 0.4922 (0.4569) teacher_loss 0.4362 (0.4232) loss_zs_kd 0.1077 (0.0987) loss_oracle 0.3627 (0.3253) acc 81.2500 (84.0625) kd_loss 1.0522 (1.0480) lr 1.3681e-03 eta 0:10:52
epoch [21/50] batch [40/162] time 0.158 (0.133) data 0.000 (0.007) loss 0.9058 (0.7805) ce_loss 0.5625 (0.4438) teacher_loss 0.5401 (0.4152) loss_zs_kd 0.0750 (0.0897) loss_oracle 0.3282 (0.3204) acc 78.1250 (83.9844) kd_loss 0.9954 (1.0393) lr 1.3681e-03 eta 0:10:40
epoch [21/50] batch [60/162] time 0.119 (0.135) data 0.000 (0.005) loss 0.6469 (0.7842) ce_loss 0.3662 (0.4458) teacher_loss 0.2602 (0.4103) loss_zs_kd 0.1237 (0.0910) loss_oracle 0.3249 (0.3284) acc 87.5000 (83.4375) kd_loss 1.0317 (1.0328) lr 1.3681e-03 eta 0:10:48
epoch [21/50] batch [80/162] time 0.065 (0.126) data 0.000 (0.003) loss 0.9269 (0.7908) ce_loss 0.5728 (0.4554) teacher_loss 0.5770 (0.4132) loss_zs_kd 0.1012 (0.0949) loss_oracle 0.2993 (0.3301) acc 78.1250 (83.2422) kd_loss 1.0973 (1.0324) lr 1.3681e-03 eta 0:10:03
epoch [21/50] batch [100/162] time 0.126 (0.122) data 0.000 (0.003) loss 1.1848 (0.7955) ce_loss 0.8638 (0.4588) teacher_loss 0.7479 (0.4143) loss_zs_kd 0.1123 (0.0987) loss_oracle 0.3807 (0.3318) acc 68.7500 (83.1875) kd_loss 1.1379 (1.0364) lr 1.3681e-03 eta 0:09:39
epoch [21/50] batch [120/162] time 0.119 (0.118) data 0.000 (0.002) loss 0.8716 (0.7964) ce_loss 0.4922 (0.4602) teacher_loss 0.4852 (0.4146) loss_zs_kd 0.0887 (0.0981) loss_oracle 0.3421 (0.3327) acc 78.1250 (83.2812) kd_loss 1.1235 (1.0346) lr 1.3681e-03 eta 0:09:19
epoch [21/50] batch [140/162] time 0.111 (0.117) data 0.000 (0.002) loss 0.6951 (0.8006) ce_loss 0.3467 (0.4612) teacher_loss 0.3099 (0.4178) loss_zs_kd 0.0857 (0.0990) loss_oracle 0.3423 (0.3333) acc 87.5000 (83.3036) kd_loss 1.0481 (1.0338) lr 1.3681e-03 eta 0:09:10
epoch [21/50] batch [160/162] time 0.076 (0.113) data 0.000 (0.002) loss 0.6762 (0.7974) ce_loss 0.2976 (0.4576) teacher_loss 0.3056 (0.4154) loss_zs_kd 0.0810 (0.0974) loss_oracle 0.3301 (0.3333) acc 87.5000 (83.4180) kd_loss 1.0663 (1.0340) lr 1.3681e-03 eta 0:08:52
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 89.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,613
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 74.9%
******* Domain s best val acc:      87.8%, epoch: 20 *******
******* Domain s best val test acc: 78.5%, epoch: 20 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [22/50] batch [20/162] time 0.090 (0.121) data 0.000 (0.014) loss 0.8289 (0.7468) ce_loss 0.4097 (0.3982) teacher_loss 0.3769 (0.3586) loss_zs_kd 0.1367 (0.1023) loss_oracle 0.3837 (0.3370) acc 81.2500 (85.9375) kd_loss 0.9836 (1.0174) lr 1.3090e-03 eta 0:09:24
epoch [22/50] batch [40/162] time 0.119 (0.113) data 0.000 (0.007) loss 0.7576 (0.7661) ce_loss 0.4058 (0.4222) teacher_loss 0.3634 (0.3726) loss_zs_kd 0.1110 (0.1078) loss_oracle 0.3387 (0.3396) acc 84.3750 (85.0781) kd_loss 0.9401 (1.0129) lr 1.3090e-03 eta 0:08:45
epoch [22/50] batch [60/162] time 0.098 (0.109) data 0.000 (0.005) loss 0.8863 (0.7837) ce_loss 0.5581 (0.4450) teacher_loss 0.4131 (0.3898) loss_zs_kd 0.0868 (0.1063) loss_oracle 0.4298 (0.3407) acc 75.0000 (83.8021) kd_loss 1.0087 (1.0195) lr 1.3090e-03 eta 0:08:27
epoch [22/50] batch [80/162] time 0.122 (0.107) data 0.000 (0.004) loss 0.8975 (0.7826) ce_loss 0.5127 (0.4461) teacher_loss 0.4860 (0.3933) loss_zs_kd 0.0914 (0.1035) loss_oracle 0.3658 (0.3376) acc 84.3750 (83.3984) kd_loss 1.0744 (1.0295) lr 1.3090e-03 eta 0:08:13
epoch [22/50] batch [100/162] time 0.077 (0.106) data 0.000 (0.003) loss 0.7173 (0.7823) ce_loss 0.2917 (0.4429) teacher_loss 0.2819 (0.3960) loss_zs_kd 0.1026 (0.1018) loss_oracle 0.3840 (0.3355) acc 90.6250 (83.7500) kd_loss 1.0324 (1.0329) lr 1.3090e-03 eta 0:08:06
epoch [22/50] batch [120/162] time 0.076 (0.105) data 0.001 (0.003) loss 0.8065 (0.7864) ce_loss 0.4253 (0.4448) teacher_loss 0.4121 (0.4016) loss_zs_kd 0.1238 (0.1006) loss_oracle 0.3325 (0.3345) acc 84.3750 (83.2812) kd_loss 1.0553 (1.0302) lr 1.3090e-03 eta 0:07:59
epoch [22/50] batch [140/162] time 0.075 (0.104) data 0.000 (0.002) loss 0.8414 (0.7955) ce_loss 0.4155 (0.4515) teacher_loss 0.4133 (0.4117) loss_zs_kd 0.0579 (0.0982) loss_oracle 0.3991 (0.3346) acc 87.5000 (83.2589) kd_loss 0.9515 (1.0288) lr 1.3090e-03 eta 0:07:55
epoch [22/50] batch [160/162] time 0.073 (0.102) data 0.000 (0.002) loss 0.6768 (0.8036) ce_loss 0.3103 (0.4558) teacher_loss 0.3083 (0.4193) loss_zs_kd 0.0930 (0.0960) loss_oracle 0.3221 (0.3363) acc 87.5000 (83.2227) kd_loss 1.0478 (1.0298) lr 1.3090e-03 eta 0:07:45
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,959
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 89.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,606
* accuracy: 79.4%
* error: 20.6%
* macro_f1: 74.5%
******* Domain s best val acc:      87.8%, epoch: 20 *******
******* Domain s best val test acc: 78.5%, epoch: 20 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [23/50] batch [20/162] time 0.077 (0.115) data 0.000 (0.013) loss 0.7996 (0.8372) ce_loss 0.5073 (0.4834) teacher_loss 0.3662 (0.4251) loss_zs_kd 0.1259 (0.1047) loss_oracle 0.3705 (0.3598) acc 84.3750 (82.1875) kd_loss 1.1260 (1.0836) lr 1.2487e-03 eta 0:08:38
epoch [23/50] batch [40/162] time 0.102 (0.106) data 0.000 (0.007) loss 0.6805 (0.8178) ce_loss 0.2681 (0.4527) teacher_loss 0.2379 (0.3896) loss_zs_kd 0.0802 (0.1109) loss_oracle 0.4025 (0.3727) acc 90.6250 (83.2812) kd_loss 1.0646 (1.0660) lr 1.2487e-03 eta 0:07:55
epoch [23/50] batch [60/162] time 0.092 (0.104) data 0.000 (0.004) loss 0.9733 (0.8105) ce_loss 0.5708 (0.4448) teacher_loss 0.5356 (0.3887) loss_zs_kd 0.0863 (0.1056) loss_oracle 0.3945 (0.3689) acc 78.1250 (83.7500) kd_loss 1.0681 (1.0590) lr 1.2487e-03 eta 0:07:45
epoch [23/50] batch [80/162] time 0.151 (0.106) data 0.000 (0.003) loss 0.7840 (0.8144) ce_loss 0.4656 (0.4490) teacher_loss 0.3984 (0.4004) loss_zs_kd 0.1097 (0.1040) loss_oracle 0.3308 (0.3620) acc 93.7500 (83.7891) kd_loss 1.0693 (1.0535) lr 1.2487e-03 eta 0:07:52
epoch [23/50] batch [100/162] time 0.070 (0.108) data 0.000 (0.003) loss 0.8302 (0.8198) ce_loss 0.4895 (0.4562) teacher_loss 0.4572 (0.4113) loss_zs_kd 0.0939 (0.1034) loss_oracle 0.3260 (0.3568) acc 81.2500 (83.5312) kd_loss 1.0739 (1.0554) lr 1.2487e-03 eta 0:07:59
epoch [23/50] batch [120/162] time 0.116 (0.113) data 0.000 (0.002) loss 0.7328 (0.8194) ce_loss 0.3748 (0.4537) teacher_loss 0.2945 (0.4105) loss_zs_kd 0.0805 (0.1010) loss_oracle 0.3980 (0.3584) acc 84.3750 (83.6198) kd_loss 1.1492 (1.0666) lr 1.2487e-03 eta 0:08:17
epoch [23/50] batch [140/162] time 0.111 (0.113) data 0.000 (0.002) loss 0.9730 (0.8120) ce_loss 0.5889 (0.4516) teacher_loss 0.5770 (0.4076) loss_zs_kd 0.1254 (0.0986) loss_oracle 0.3333 (0.3551) acc 81.2500 (83.7723) kd_loss 0.9558 (1.0712) lr 1.2487e-03 eta 0:08:15
epoch [23/50] batch [160/162] time 0.097 (0.110) data 0.000 (0.002) loss 0.6935 (0.8170) ce_loss 0.3494 (0.4582) teacher_loss 0.3178 (0.4142) loss_zs_kd 0.0621 (0.0975) loss_oracle 0.3447 (0.3540) acc 93.7500 (83.5547) kd_loss 1.0588 (1.0678) lr 1.2487e-03 eta 0:08:00
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,939
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,678
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 75.4%
******* Domain s best val acc:      87.8%, epoch: 20 *******
******* Domain s best val test acc: 78.5%, epoch: 20 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [24/50] batch [20/162] time 0.082 (0.112) data 0.000 (0.012) loss 0.9062 (0.7795) ce_loss 0.5869 (0.4556) teacher_loss 0.5112 (0.3898) loss_zs_kd 0.1065 (0.1027) loss_oracle 0.3417 (0.3383) acc 84.3750 (84.0625) kd_loss 1.0720 (1.0476) lr 1.1874e-03 eta 0:08:05
epoch [24/50] batch [40/162] time 0.129 (0.106) data 0.000 (0.006) loss 0.6975 (0.7886) ce_loss 0.3616 (0.4600) teacher_loss 0.3097 (0.3942) loss_zs_kd 0.0900 (0.1064) loss_oracle 0.3428 (0.3412) acc 87.5000 (83.2812) kd_loss 0.9998 (1.0523) lr 1.1874e-03 eta 0:07:41
epoch [24/50] batch [60/162] time 0.133 (0.107) data 0.000 (0.004) loss 0.9766 (0.7826) ce_loss 0.6279 (0.4482) teacher_loss 0.6323 (0.3871) loss_zs_kd 0.0820 (0.1022) loss_oracle 0.3033 (0.3444) acc 78.1250 (83.3854) kd_loss 1.0492 (1.0511) lr 1.1874e-03 eta 0:07:43
epoch [24/50] batch [80/162] time 0.121 (0.109) data 0.000 (0.003) loss 0.8616 (0.7887) ce_loss 0.6152 (0.4555) teacher_loss 0.5146 (0.3927) loss_zs_kd 0.0814 (0.0984) loss_oracle 0.3064 (0.3468) acc 78.1250 (83.1641) kd_loss 1.1126 (1.0542) lr 1.1874e-03 eta 0:07:46
epoch [24/50] batch [100/162] time 0.137 (0.110) data 0.000 (0.003) loss 0.8095 (0.7982) ce_loss 0.4373 (0.4652) teacher_loss 0.3688 (0.4017) loss_zs_kd 0.0836 (0.0973) loss_oracle 0.3989 (0.3479) acc 84.3750 (82.8438) kd_loss 1.0137 (1.0528) lr 1.1874e-03 eta 0:07:48
epoch [24/50] batch [120/162] time 0.099 (0.110) data 0.000 (0.002) loss 0.8100 (0.7939) ce_loss 0.4146 (0.4582) teacher_loss 0.4167 (0.3937) loss_zs_kd 0.1303 (0.0976) loss_oracle 0.3282 (0.3515) acc 90.6250 (82.9948) kd_loss 0.9885 (1.0526) lr 1.1874e-03 eta 0:07:46
epoch [24/50] batch [140/162] time 0.129 (0.110) data 0.000 (0.002) loss 0.7793 (0.7971) ce_loss 0.3613 (0.4564) teacher_loss 0.3855 (0.3964) loss_zs_kd 0.1352 (0.0992) loss_oracle 0.3262 (0.3511) acc 90.6250 (82.9464) kd_loss 1.0459 (1.0474) lr 1.1874e-03 eta 0:07:47
epoch [24/50] batch [160/162] time 0.096 (0.109) data 0.000 (0.002) loss 0.8790 (0.7994) ce_loss 0.5547 (0.4541) teacher_loss 0.5207 (0.3992) loss_zs_kd 0.0955 (0.0984) loss_oracle 0.3106 (0.3510) acc 75.0000 (83.0469) kd_loss 1.0540 (1.0434) lr 1.1874e-03 eta 0:07:41
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,960
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 89.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,623
* accuracy: 79.9%
* error: 20.1%
* macro_f1: 75.1%
******* Domain s best val acc:      87.8%, epoch: 20 *******
******* Domain s best val test acc: 78.5%, epoch: 20 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [25/50] batch [20/162] time 0.097 (0.125) data 0.000 (0.015) loss 0.7203 (0.8635) ce_loss 0.4211 (0.5125) teacher_loss 0.3604 (0.4735) loss_zs_kd 0.0742 (0.0933) loss_oracle 0.3228 (0.3433) acc 87.5000 (79.8438) kd_loss 1.1163 (1.0534) lr 1.1253e-03 eta 0:08:42
epoch [25/50] batch [40/162] time 0.106 (0.116) data 0.000 (0.007) loss 0.7116 (0.8196) ce_loss 0.3567 (0.4668) teacher_loss 0.2664 (0.4224) loss_zs_kd 0.0798 (0.1002) loss_oracle 0.4053 (0.3470) acc 84.3750 (82.0312) kd_loss 1.0851 (1.0500) lr 1.1253e-03 eta 0:08:03
epoch [25/50] batch [60/162] time 0.098 (0.114) data 0.001 (0.005) loss 0.8749 (0.8088) ce_loss 0.3862 (0.4594) teacher_loss 0.4673 (0.4057) loss_zs_kd 0.1024 (0.1017) loss_oracle 0.3563 (0.3522) acc 87.5000 (82.8125) kd_loss 1.0514 (1.0578) lr 1.1253e-03 eta 0:07:51
epoch [25/50] batch [80/162] time 0.133 (0.113) data 0.000 (0.004) loss 0.7801 (0.8032) ce_loss 0.3174 (0.4515) teacher_loss 0.3935 (0.3980) loss_zs_kd 0.0857 (0.1029) loss_oracle 0.3438 (0.3537) acc 87.5000 (83.1641) kd_loss 1.0371 (1.0574) lr 1.1253e-03 eta 0:07:45
epoch [25/50] batch [100/162] time 0.063 (0.111) data 0.000 (0.003) loss 0.7457 (0.8017) ce_loss 0.3894 (0.4476) teacher_loss 0.3227 (0.3978) loss_zs_kd 0.0730 (0.0991) loss_oracle 0.3865 (0.3544) acc 87.5000 (83.3438) kd_loss 1.0607 (1.0560) lr 1.1253e-03 eta 0:07:34
epoch [25/50] batch [120/162] time 0.130 (0.116) data 0.000 (0.003) loss 0.8598 (0.8045) ce_loss 0.5073 (0.4530) teacher_loss 0.4547 (0.4014) loss_zs_kd 0.0770 (0.0992) loss_oracle 0.3666 (0.3536) acc 84.3750 (82.9688) kd_loss 1.0847 (1.0592) lr 1.1253e-03 eta 0:07:55
epoch [25/50] batch [140/162] time 0.179 (0.120) data 0.000 (0.002) loss 0.6853 (0.8055) ce_loss 0.2751 (0.4523) teacher_loss 0.2317 (0.3999) loss_zs_kd 0.0655 (0.0991) loss_oracle 0.4208 (0.3561) acc 93.7500 (83.1250) kd_loss 1.0015 (1.0551) lr 1.1253e-03 eta 0:08:09
epoch [25/50] batch [160/162] time 0.064 (0.122) data 0.000 (0.002) loss 0.7502 (0.8096) ce_loss 0.3962 (0.4543) teacher_loss 0.3342 (0.4013) loss_zs_kd 0.0658 (0.0996) loss_oracle 0.3831 (0.3584) acc 84.3750 (83.0469) kd_loss 1.0621 (1.0553) lr 1.1253e-03 eta 0:08:12
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,953
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 89.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,651
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 75.4%
******* Domain s best val acc:      87.8%, epoch: 20 *******
******* Domain s best val test acc: 78.5%, epoch: 20 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [26/50] batch [20/162] time 0.080 (0.121) data 0.000 (0.012) loss 0.8468 (0.8045) ce_loss 0.3669 (0.4526) teacher_loss 0.3671 (0.3968) loss_zs_kd 0.1384 (0.0999) loss_oracle 0.4105 (0.3578) acc 90.6250 (82.3438) kd_loss 1.1169 (1.0802) lr 1.0628e-03 eta 0:08:08
epoch [26/50] batch [40/162] time 0.126 (0.118) data 0.000 (0.006) loss 0.7966 (0.8190) ce_loss 0.4387 (0.4675) teacher_loss 0.3443 (0.4047) loss_zs_kd 0.1331 (0.1023) loss_oracle 0.3857 (0.3632) acc 78.1250 (82.0312) kd_loss 1.0865 (1.0901) lr 1.0628e-03 eta 0:07:55
epoch [26/50] batch [60/162] time 0.089 (0.117) data 0.001 (0.004) loss 0.6663 (0.8218) ce_loss 0.2578 (0.4632) teacher_loss 0.2649 (0.4073) loss_zs_kd 0.1138 (0.1026) loss_oracle 0.3446 (0.3633) acc 87.5000 (82.3438) kd_loss 1.0721 (1.0769) lr 1.0628e-03 eta 0:07:45
epoch [26/50] batch [80/162] time 0.130 (0.117) data 0.000 (0.003) loss 0.7633 (0.8253) ce_loss 0.3645 (0.4639) teacher_loss 0.3431 (0.4172) loss_zs_kd 0.0738 (0.0987) loss_oracle 0.3834 (0.3587) acc 81.2500 (82.2266) kd_loss 1.1111 (1.0696) lr 1.0628e-03 eta 0:07:45
epoch [26/50] batch [100/162] time 0.141 (0.117) data 0.000 (0.003) loss 0.8335 (0.8225) ce_loss 0.4741 (0.4594) teacher_loss 0.4477 (0.4169) loss_zs_kd 0.1061 (0.0963) loss_oracle 0.3327 (0.3575) acc 87.5000 (82.5312) kd_loss 1.1307 (1.0655) lr 1.0628e-03 eta 0:07:40
epoch [26/50] batch [120/162] time 0.136 (0.116) data 0.000 (0.002) loss 0.7089 (0.8224) ce_loss 0.3606 (0.4582) teacher_loss 0.3555 (0.4161) loss_zs_kd 0.0772 (0.0963) loss_oracle 0.3148 (0.3582) acc 87.5000 (82.6823) kd_loss 0.9630 (1.0634) lr 1.0628e-03 eta 0:07:37
epoch [26/50] batch [140/162] time 0.133 (0.116) data 0.000 (0.002) loss 0.7483 (0.8133) ce_loss 0.3186 (0.4492) teacher_loss 0.2991 (0.4081) loss_zs_kd 0.1224 (0.0961) loss_oracle 0.3880 (0.3571) acc 93.7500 (83.1027) kd_loss 1.0719 (1.0621) lr 1.0628e-03 eta 0:07:34
epoch [26/50] batch [160/162] time 0.085 (0.114) data 0.000 (0.002) loss 0.8611 (0.8085) ce_loss 0.4536 (0.4491) teacher_loss 0.4630 (0.4047) loss_zs_kd 0.0735 (0.0978) loss_oracle 0.3613 (0.3549) acc 87.5000 (83.0859) kd_loss 1.0681 (1.0603) lr 1.0628e-03 eta 0:07:24
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,952
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 89.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,679
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 76.2%
******* Domain s best val acc:      87.8%, epoch: 20 *******
******* Domain s best val test acc: 78.5%, epoch: 20 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [27/50] batch [20/162] time 0.113 (0.118) data 0.000 (0.013) loss 0.7911 (0.7993) ce_loss 0.4309 (0.4695) teacher_loss 0.3352 (0.3905) loss_zs_kd 0.1229 (0.0989) loss_oracle 0.3945 (0.3594) acc 84.3750 (81.5625) kd_loss 1.0289 (1.0665) lr 1.0000e-03 eta 0:07:36
epoch [27/50] batch [40/162] time 0.072 (0.111) data 0.000 (0.006) loss 0.5998 (0.7953) ce_loss 0.3066 (0.4758) teacher_loss 0.1977 (0.3924) loss_zs_kd 0.0982 (0.1029) loss_oracle 0.3530 (0.3515) acc 90.6250 (82.7344) kd_loss 0.9811 (1.0710) lr 1.0000e-03 eta 0:07:06
epoch [27/50] batch [60/162] time 0.134 (0.108) data 0.000 (0.004) loss 0.6147 (0.8002) ce_loss 0.3362 (0.4769) teacher_loss 0.2253 (0.3964) loss_zs_kd 0.1069 (0.1046) loss_oracle 0.3360 (0.3515) acc 84.3750 (82.7604) kd_loss 1.0531 (1.0744) lr 1.0000e-03 eta 0:06:55
epoch [27/50] batch [80/162] time 0.128 (0.110) data 0.000 (0.003) loss 1.0293 (0.8060) ce_loss 0.6533 (0.4740) teacher_loss 0.6514 (0.4008) loss_zs_kd 0.0933 (0.1029) loss_oracle 0.3313 (0.3538) acc 81.2500 (82.4219) kd_loss 1.0662 (1.0656) lr 1.0000e-03 eta 0:06:58
epoch [27/50] batch [100/162] time 0.101 (0.111) data 0.000 (0.003) loss 0.6271 (0.7938) ce_loss 0.3118 (0.4585) teacher_loss 0.2420 (0.3911) loss_zs_kd 0.0652 (0.1006) loss_oracle 0.3526 (0.3523) acc 87.5000 (83.1250) kd_loss 1.0209 (1.0574) lr 1.0000e-03 eta 0:06:59
epoch [27/50] batch [120/162] time 0.166 (0.114) data 0.000 (0.002) loss 0.8179 (0.7872) ce_loss 0.4597 (0.4509) teacher_loss 0.4118 (0.3857) loss_zs_kd 0.0902 (0.0993) loss_oracle 0.3610 (0.3518) acc 84.3750 (83.4375) kd_loss 1.0272 (1.0570) lr 1.0000e-03 eta 0:07:10
epoch [27/50] batch [140/162] time 0.172 (0.117) data 0.000 (0.002) loss 0.6974 (0.7897) ce_loss 0.3496 (0.4533) teacher_loss 0.3718 (0.3907) loss_zs_kd 0.0594 (0.0988) loss_oracle 0.2960 (0.3496) acc 87.5000 (83.0804) kd_loss 1.0588 (1.0580) lr 1.0000e-03 eta 0:07:18
epoch [27/50] batch [160/162] time 0.172 (0.122) data 0.000 (0.002) loss 0.5385 (0.7847) ce_loss 0.3105 (0.4495) teacher_loss 0.2050 (0.3882) loss_zs_kd 0.0672 (0.0981) loss_oracle 0.2998 (0.3475) acc 84.3750 (83.1055) kd_loss 1.1067 (1.0583) lr 1.0000e-03 eta 0:07:34
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,952
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 89.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,662
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 75.9%
******* Domain s best val acc:      87.8%, epoch: 20 *******
******* Domain s best val test acc: 78.5%, epoch: 20 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [28/50] batch [20/162] time 0.093 (0.110) data 0.000 (0.014) loss 0.9326 (0.8172) ce_loss 0.4880 (0.4714) teacher_loss 0.5003 (0.4170) loss_zs_kd 0.1311 (0.1069) loss_oracle 0.3668 (0.3467) acc 78.1250 (81.5625) kd_loss 0.9847 (1.0624) lr 9.3721e-04 eta 0:06:46
epoch [28/50] batch [40/162] time 0.082 (0.100) data 0.000 (0.007) loss 1.0400 (0.8387) ce_loss 0.6870 (0.4967) teacher_loss 0.5953 (0.4323) loss_zs_kd 0.1370 (0.1072) loss_oracle 0.3762 (0.3528) acc 71.8750 (81.0156) kd_loss 1.0637 (1.0590) lr 9.3721e-04 eta 0:06:09
epoch [28/50] batch [60/162] time 0.116 (0.098) data 0.000 (0.005) loss 0.7222 (0.8229) ce_loss 0.4111 (0.4825) teacher_loss 0.3631 (0.4190) loss_zs_kd 0.0948 (0.1021) loss_oracle 0.3117 (0.3529) acc 84.3750 (81.9271) kd_loss 1.0508 (1.0581) lr 9.3721e-04 eta 0:06:01
epoch [28/50] batch [80/162] time 0.100 (0.100) data 0.000 (0.004) loss 0.7349 (0.8139) ce_loss 0.3779 (0.4775) teacher_loss 0.2962 (0.4094) loss_zs_kd 0.0802 (0.1041) loss_oracle 0.3986 (0.3524) acc 81.2500 (81.7969) kd_loss 1.0235 (1.0564) lr 9.3721e-04 eta 0:06:05
epoch [28/50] batch [100/162] time 0.099 (0.100) data 0.000 (0.003) loss 0.9351 (0.7933) ce_loss 0.6177 (0.4596) teacher_loss 0.5540 (0.3908) loss_zs_kd 0.1320 (0.1063) loss_oracle 0.3151 (0.3493) acc 81.2500 (82.6250) kd_loss 1.1168 (1.0589) lr 9.3721e-04 eta 0:06:03
epoch [28/50] batch [120/162] time 0.076 (0.102) data 0.000 (0.002) loss 1.0776 (0.7885) ce_loss 0.7310 (0.4538) teacher_loss 0.6736 (0.3863) loss_zs_kd 0.1050 (0.1069) loss_oracle 0.3515 (0.3488) acc 71.8750 (83.0729) kd_loss 1.1578 (1.0631) lr 9.3721e-04 eta 0:06:06
epoch [28/50] batch [140/162] time 0.122 (0.101) data 0.000 (0.002) loss 1.0108 (0.7905) ce_loss 0.6885 (0.4550) teacher_loss 0.5953 (0.3878) loss_zs_kd 0.1147 (0.1065) loss_oracle 0.3581 (0.3494) acc 68.7500 (83.2366) kd_loss 1.1297 (1.0650) lr 9.3721e-04 eta 0:06:03
epoch [28/50] batch [160/162] time 0.079 (0.101) data 0.000 (0.002) loss 0.7457 (0.7833) ce_loss 0.4492 (0.4509) teacher_loss 0.3932 (0.3819) loss_zs_kd 0.0616 (0.1060) loss_oracle 0.3218 (0.3484) acc 87.5000 (83.4375) kd_loss 1.0154 (1.0654) lr 9.3721e-04 eta 0:05:59
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,941
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,675
* accuracy: 81.5%
* error: 18.5%
* macro_f1: 76.0%
******* Domain s best val acc:      87.8%, epoch: 20 *******
******* Domain s best val test acc: 78.5%, epoch: 20 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [29/50] batch [20/162] time 0.085 (0.106) data 0.000 (0.014) loss 0.8672 (0.7755) ce_loss 0.4929 (0.4488) teacher_loss 0.4808 (0.3734) loss_zs_kd 0.0832 (0.1095) loss_oracle 0.3448 (0.3473) acc 84.3750 (84.2188) kd_loss 1.0378 (1.0695) lr 8.7467e-04 eta 0:06:16
epoch [29/50] batch [40/162] time 0.109 (0.101) data 0.000 (0.007) loss 0.9928 (0.7976) ce_loss 0.7183 (0.4689) teacher_loss 0.6240 (0.3991) loss_zs_kd 0.0791 (0.1087) loss_oracle 0.3292 (0.3442) acc 71.8750 (82.7344) kd_loss 1.1454 (1.0749) lr 8.7467e-04 eta 0:05:56
epoch [29/50] batch [60/162] time 0.089 (0.097) data 0.000 (0.005) loss 0.6498 (0.7905) ce_loss 0.3430 (0.4565) teacher_loss 0.2459 (0.3913) loss_zs_kd 0.1077 (0.1045) loss_oracle 0.3501 (0.3470) acc 84.3750 (82.9688) kd_loss 1.1458 (1.0765) lr 8.7467e-04 eta 0:05:38
epoch [29/50] batch [80/162] time 0.095 (0.094) data 0.000 (0.004) loss 0.6394 (0.7826) ce_loss 0.3450 (0.4537) teacher_loss 0.2744 (0.3876) loss_zs_kd 0.0631 (0.1009) loss_oracle 0.3335 (0.3445) acc 84.3750 (83.0469) kd_loss 1.1086 (1.0770) lr 8.7467e-04 eta 0:05:28
epoch [29/50] batch [100/162] time 0.077 (0.094) data 0.000 (0.003) loss 0.6908 (0.7859) ce_loss 0.3674 (0.4537) teacher_loss 0.3865 (0.3899) loss_zs_kd 0.0840 (0.1022) loss_oracle 0.2623 (0.3449) acc 96.8750 (83.4375) kd_loss 0.9191 (1.0662) lr 8.7467e-04 eta 0:05:27
epoch [29/50] batch [120/162] time 0.129 (0.096) data 0.000 (0.002) loss 1.0181 (0.7984) ce_loss 0.6167 (0.4613) teacher_loss 0.5984 (0.4004) loss_zs_kd 0.0968 (0.1021) loss_oracle 0.3712 (0.3469) acc 78.1250 (83.2031) kd_loss 1.0976 (1.0633) lr 8.7467e-04 eta 0:05:30
epoch [29/50] batch [140/162] time 0.076 (0.097) data 0.000 (0.002) loss 0.6890 (0.7978) ce_loss 0.3442 (0.4600) teacher_loss 0.3133 (0.4007) loss_zs_kd 0.0717 (0.1008) loss_oracle 0.3398 (0.3466) acc 90.6250 (83.3929) kd_loss 1.0791 (1.0639) lr 8.7467e-04 eta 0:05:32
epoch [29/50] batch [160/162] time 0.067 (0.097) data 0.000 (0.002) loss 0.8298 (0.7919) ce_loss 0.4846 (0.4535) teacher_loss 0.4148 (0.3945) loss_zs_kd 0.0897 (0.0995) loss_oracle 0.3701 (0.3476) acc 84.3750 (83.5156) kd_loss 1.0166 (1.0654) lr 8.7467e-04 eta 0:05:29
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,951
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 89.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,687
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 76.4%
******* Domain s best val acc:      87.8%, epoch: 20 *******
******* Domain s best val test acc: 78.5%, epoch: 20 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [30/50] batch [20/162] time 0.137 (0.136) data 0.000 (0.015) loss 0.6521 (0.7744) ce_loss 0.3318 (0.4589) teacher_loss 0.2296 (0.3834) loss_zs_kd 0.0989 (0.0907) loss_oracle 0.3731 (0.3456) acc 87.5000 (82.5000) kd_loss 1.0873 (1.1027) lr 8.1262e-04 eta 0:07:41
epoch [30/50] batch [40/162] time 0.112 (0.117) data 0.000 (0.007) loss 0.5845 (0.7574) ce_loss 0.2146 (0.4383) teacher_loss 0.1662 (0.3632) loss_zs_kd 0.1286 (0.0920) loss_oracle 0.3540 (0.3482) acc 93.7500 (84.1406) kd_loss 1.0841 (1.0952) lr 8.1262e-04 eta 0:06:33
epoch [30/50] batch [60/162] time 0.080 (0.111) data 0.000 (0.005) loss 0.8329 (0.7719) ce_loss 0.5557 (0.4529) teacher_loss 0.3716 (0.3756) loss_zs_kd 0.1668 (0.0958) loss_oracle 0.3779 (0.3484) acc 75.0000 (83.2292) kd_loss 1.0371 (1.0837) lr 8.1262e-04 eta 0:06:11
epoch [30/50] batch [80/162] time 0.104 (0.110) data 0.000 (0.004) loss 0.9866 (0.7950) ce_loss 0.6396 (0.4663) teacher_loss 0.5571 (0.3995) loss_zs_kd 0.1148 (0.0962) loss_oracle 0.3721 (0.3474) acc 75.0000 (82.9688) kd_loss 1.0513 (1.0710) lr 8.1262e-04 eta 0:06:04
epoch [30/50] batch [100/162] time 0.112 (0.110) data 0.000 (0.003) loss 0.6999 (0.7898) ce_loss 0.3711 (0.4549) teacher_loss 0.2826 (0.3927) loss_zs_kd 0.0795 (0.0951) loss_oracle 0.3776 (0.3496) acc 84.3750 (83.3125) kd_loss 1.0580 (1.0660) lr 8.1262e-04 eta 0:06:02
epoch [30/50] batch [120/162] time 0.074 (0.109) data 0.000 (0.003) loss 0.7199 (0.7877) ce_loss 0.4377 (0.4480) teacher_loss 0.3054 (0.3890) loss_zs_kd 0.1029 (0.0959) loss_oracle 0.3630 (0.3508) acc 87.5000 (83.5677) kd_loss 1.0757 (1.0611) lr 8.1262e-04 eta 0:05:58
epoch [30/50] batch [140/162] time 0.109 (0.109) data 0.000 (0.002) loss 0.7654 (0.7947) ce_loss 0.4600 (0.4515) teacher_loss 0.3466 (0.3927) loss_zs_kd 0.1159 (0.0965) loss_oracle 0.3608 (0.3537) acc 84.3750 (83.4152) kd_loss 1.0202 (1.0584) lr 8.1262e-04 eta 0:05:56
epoch [30/50] batch [160/162] time 0.069 (0.108) data 0.000 (0.002) loss 0.6594 (0.7984) ce_loss 0.3003 (0.4520) teacher_loss 0.2756 (0.3945) loss_zs_kd 0.1059 (0.0966) loss_oracle 0.3308 (0.3555) acc 84.3750 (83.1445) kd_loss 0.9842 (1.0545) lr 8.1262e-04 eta 0:05:49
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,963
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,629
* accuracy: 80.1%
* error: 19.9%
* macro_f1: 75.2%
******* Domain s best val acc:      87.9%, epoch: 30 *******
******* Domain s best val test acc: 80.1%, epoch: 30 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [31/50] batch [20/162] time 0.125 (0.129) data 0.000 (0.017) loss 0.9324 (0.8428) ce_loss 0.6099 (0.4856) teacher_loss 0.5363 (0.4207) loss_zs_kd 0.0978 (0.0966) loss_oracle 0.3472 (0.3738) acc 78.1250 (82.8125) kd_loss 1.0539 (1.0335) lr 7.5131e-04 eta 0:06:54
epoch [31/50] batch [40/162] time 0.084 (0.121) data 0.000 (0.009) loss 0.6799 (0.8137) ce_loss 0.2379 (0.4549) teacher_loss 0.2720 (0.3943) loss_zs_kd 0.0816 (0.1000) loss_oracle 0.3671 (0.3694) acc 96.8750 (83.5156) kd_loss 1.0651 (1.0379) lr 7.5131e-04 eta 0:06:26
epoch [31/50] batch [60/162] time 0.134 (0.116) data 0.000 (0.006) loss 0.5628 (0.8065) ce_loss 0.1609 (0.4408) teacher_loss 0.1693 (0.3934) loss_zs_kd 0.0631 (0.0972) loss_oracle 0.3620 (0.3646) acc 93.7500 (83.6979) kd_loss 1.0595 (1.0314) lr 7.5131e-04 eta 0:06:09
epoch [31/50] batch [80/162] time 0.105 (0.115) data 0.000 (0.005) loss 0.6922 (0.8067) ce_loss 0.3953 (0.4434) teacher_loss 0.2443 (0.3936) loss_zs_kd 0.1391 (0.0969) loss_oracle 0.3783 (0.3646) acc 87.5000 (83.0859) kd_loss 1.0538 (1.0349) lr 7.5131e-04 eta 0:06:04
epoch [31/50] batch [100/162] time 0.130 (0.115) data 0.000 (0.004) loss 0.7178 (0.8065) ce_loss 0.3992 (0.4461) teacher_loss 0.3168 (0.3959) loss_zs_kd 0.0702 (0.0969) loss_oracle 0.3659 (0.3622) acc 87.5000 (83.3750) kd_loss 1.0177 (1.0397) lr 7.5131e-04 eta 0:06:01
epoch [31/50] batch [120/162] time 0.101 (0.114) data 0.000 (0.003) loss 0.7455 (0.8062) ce_loss 0.2754 (0.4448) teacher_loss 0.3151 (0.3957) loss_zs_kd 0.0858 (0.0964) loss_oracle 0.3876 (0.3623) acc 90.6250 (83.3073) kd_loss 0.9702 (1.0452) lr 7.5131e-04 eta 0:05:55
epoch [31/50] batch [140/162] time 0.105 (0.113) data 0.000 (0.003) loss 0.8550 (0.8082) ce_loss 0.4783 (0.4445) teacher_loss 0.4714 (0.3977) loss_zs_kd 0.1113 (0.0958) loss_oracle 0.3279 (0.3626) acc 75.0000 (83.3482) kd_loss 1.0105 (1.0431) lr 7.5131e-04 eta 0:05:51
epoch [31/50] batch [160/162] time 0.075 (0.111) data 0.000 (0.002) loss 0.8455 (0.8071) ce_loss 0.4907 (0.4393) teacher_loss 0.4730 (0.3965) loss_zs_kd 0.1230 (0.0946) loss_oracle 0.3110 (0.3633) acc 78.1250 (83.6133) kd_loss 0.9578 (1.0384) lr 7.5131e-04 eta 0:05:41
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,971
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 90.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,600
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 74.7%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [32/50] batch [20/162] time 0.073 (0.148) data 0.000 (0.013) loss 0.9344 (0.8265) ce_loss 0.4834 (0.4313) teacher_loss 0.4572 (0.4253) loss_zs_kd 0.0919 (0.0822) loss_oracle 0.4313 (0.3601) acc 81.2500 (84.6875) kd_loss 1.0575 (0.9933) lr 6.9098e-04 eta 0:07:32
epoch [32/50] batch [40/162] time 0.090 (0.125) data 0.000 (0.006) loss 0.7702 (0.8290) ce_loss 0.3823 (0.4414) teacher_loss 0.3872 (0.4312) loss_zs_kd 0.0834 (0.0809) loss_oracle 0.3413 (0.3574) acc 81.2500 (83.8281) kd_loss 1.0241 (1.0023) lr 6.9098e-04 eta 0:06:20
epoch [32/50] batch [60/162] time 0.096 (0.114) data 0.000 (0.004) loss 0.9893 (0.8143) ce_loss 0.6084 (0.4321) teacher_loss 0.6200 (0.4180) loss_zs_kd 0.0673 (0.0858) loss_oracle 0.3357 (0.3533) acc 75.0000 (83.8542) kd_loss 1.0423 (1.0064) lr 6.9098e-04 eta 0:05:44
epoch [32/50] batch [80/162] time 0.079 (0.108) data 0.000 (0.003) loss 0.6888 (0.8005) ce_loss 0.3457 (0.4287) teacher_loss 0.3732 (0.4081) loss_zs_kd 0.0625 (0.0871) loss_oracle 0.2844 (0.3489) acc 87.5000 (84.3359) kd_loss 1.0478 (1.0156) lr 6.9098e-04 eta 0:05:22
epoch [32/50] batch [100/162] time 0.096 (0.104) data 0.000 (0.003) loss 0.8240 (0.7894) ce_loss 0.5464 (0.4255) teacher_loss 0.4295 (0.3939) loss_zs_kd 0.0877 (0.0912) loss_oracle 0.3506 (0.3499) acc 75.0000 (84.3125) kd_loss 1.0898 (1.0232) lr 6.9098e-04 eta 0:05:10
epoch [32/50] batch [120/162] time 0.080 (0.103) data 0.000 (0.002) loss 0.8631 (0.7989) ce_loss 0.4536 (0.4358) teacher_loss 0.4265 (0.4012) loss_zs_kd 0.1159 (0.0924) loss_oracle 0.3786 (0.3515) acc 84.3750 (84.0104) kd_loss 1.1019 (1.0277) lr 6.9098e-04 eta 0:05:04
epoch [32/50] batch [140/162] time 0.077 (0.101) data 0.000 (0.002) loss 0.6425 (0.7934) ce_loss 0.3455 (0.4335) teacher_loss 0.2816 (0.3946) loss_zs_kd 0.0967 (0.0934) loss_oracle 0.3125 (0.3521) acc 84.3750 (83.8616) kd_loss 0.9930 (1.0294) lr 6.9098e-04 eta 0:04:57
epoch [32/50] batch [160/162] time 0.097 (0.100) data 0.000 (0.002) loss 1.0138 (0.7972) ce_loss 0.8442 (0.4372) teacher_loss 0.6663 (0.3949) loss_zs_kd 0.1071 (0.0950) loss_oracle 0.2940 (0.3548) acc 59.3750 (83.8086) kd_loss 0.9424 (1.0303) lr 6.9098e-04 eta 0:04:51
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,961
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 89.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,653
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 75.5%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [33/50] batch [20/162] time 0.124 (0.117) data 0.000 (0.013) loss 1.1012 (0.8704) ce_loss 0.7148 (0.4727) teacher_loss 0.6623 (0.4514) loss_zs_kd 0.0834 (0.1049) loss_oracle 0.3971 (0.3666) acc 68.7500 (80.7812) kd_loss 0.9952 (1.0226) lr 6.3188e-04 eta 0:05:38
epoch [33/50] batch [40/162] time 0.107 (0.109) data 0.000 (0.007) loss 0.9888 (0.8381) ce_loss 0.5991 (0.4502) teacher_loss 0.5579 (0.4286) loss_zs_kd 0.0542 (0.0974) loss_oracle 0.4038 (0.3608) acc 75.0000 (82.2656) kd_loss 1.0612 (1.0258) lr 6.3188e-04 eta 0:05:14
epoch [33/50] batch [60/162] time 0.081 (0.108) data 0.000 (0.005) loss 0.7251 (0.8174) ce_loss 0.3779 (0.4375) teacher_loss 0.3522 (0.4098) loss_zs_kd 0.0833 (0.0964) loss_oracle 0.3313 (0.3594) acc 87.5000 (83.0729) kd_loss 0.9986 (1.0190) lr 6.3188e-04 eta 0:05:08
epoch [33/50] batch [80/162] time 0.096 (0.107) data 0.000 (0.003) loss 0.9551 (0.8150) ce_loss 0.5527 (0.4388) teacher_loss 0.5116 (0.4053) loss_zs_kd 0.0906 (0.0982) loss_oracle 0.3982 (0.3606) acc 75.0000 (82.9297) kd_loss 1.0573 (1.0261) lr 6.3188e-04 eta 0:05:02
epoch [33/50] batch [100/162] time 0.120 (0.106) data 0.000 (0.003) loss 0.8731 (0.8081) ce_loss 0.5327 (0.4365) teacher_loss 0.4283 (0.3974) loss_zs_kd 0.1334 (0.0993) loss_oracle 0.3781 (0.3611) acc 78.1250 (83.1250) kd_loss 1.1366 (1.0351) lr 6.3188e-04 eta 0:04:58
epoch [33/50] batch [120/162] time 0.082 (0.105) data 0.000 (0.002) loss 0.8327 (0.8064) ce_loss 0.5220 (0.4386) teacher_loss 0.4768 (0.3951) loss_zs_kd 0.0830 (0.0986) loss_oracle 0.3144 (0.3621) acc 75.0000 (83.1510) kd_loss 0.9737 (1.0352) lr 6.3188e-04 eta 0:04:54
epoch [33/50] batch [140/162] time 0.084 (0.104) data 0.000 (0.002) loss 0.6866 (0.8045) ce_loss 0.2910 (0.4410) teacher_loss 0.3098 (0.3943) loss_zs_kd 0.1277 (0.0983) loss_oracle 0.3129 (0.3611) acc 90.6250 (83.1250) kd_loss 0.9843 (1.0388) lr 6.3188e-04 eta 0:04:49
epoch [33/50] batch [160/162] time 0.078 (0.103) data 0.000 (0.002) loss 0.5004 (0.8025) ce_loss 0.1631 (0.4388) teacher_loss 0.1163 (0.3912) loss_zs_kd 0.0830 (0.0992) loss_oracle 0.3426 (0.3617) acc 93.7500 (83.1836) kd_loss 1.0526 (1.0393) lr 6.3188e-04 eta 0:04:43
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,958
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 89.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,664
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 75.6%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [34/50] batch [20/162] time 0.065 (0.117) data 0.000 (0.015) loss 0.6496 (0.8122) ce_loss 0.2472 (0.4422) teacher_loss 0.2238 (0.3948) loss_zs_kd 0.0933 (0.1132) loss_oracle 0.3792 (0.3608) acc 100.0000 (85.1562) kd_loss 1.0294 (1.0296) lr 5.7422e-04 eta 0:05:18
epoch [34/50] batch [40/162] time 0.149 (0.123) data 0.000 (0.008) loss 0.7320 (0.7986) ce_loss 0.3484 (0.4316) teacher_loss 0.3321 (0.3897) loss_zs_kd 0.0998 (0.1038) loss_oracle 0.3500 (0.3569) acc 84.3750 (83.9844) kd_loss 1.0300 (1.0255) lr 5.7422e-04 eta 0:05:33
epoch [34/50] batch [60/162] time 0.128 (0.125) data 0.000 (0.005) loss 0.7757 (0.7983) ce_loss 0.4326 (0.4308) teacher_loss 0.3384 (0.3881) loss_zs_kd 0.1073 (0.1015) loss_oracle 0.3836 (0.3595) acc 84.3750 (84.0104) kd_loss 1.0349 (1.0237) lr 5.7422e-04 eta 0:05:36
epoch [34/50] batch [80/162] time 0.126 (0.129) data 0.000 (0.004) loss 0.8172 (0.7995) ce_loss 0.4526 (0.4321) teacher_loss 0.4090 (0.3868) loss_zs_kd 0.1021 (0.1010) loss_oracle 0.3571 (0.3622) acc 81.2500 (83.6719) kd_loss 1.0110 (1.0244) lr 5.7422e-04 eta 0:05:46
epoch [34/50] batch [100/162] time 0.089 (0.124) data 0.000 (0.003) loss 0.8088 (0.8010) ce_loss 0.5264 (0.4339) teacher_loss 0.3900 (0.3871) loss_zs_kd 0.0824 (0.0998) loss_oracle 0.3775 (0.3640) acc 81.2500 (83.6562) kd_loss 1.0355 (1.0207) lr 5.7422e-04 eta 0:05:28
epoch [34/50] batch [120/162] time 0.094 (0.120) data 0.000 (0.003) loss 0.8097 (0.7981) ce_loss 0.4170 (0.4334) teacher_loss 0.3527 (0.3857) loss_zs_kd 0.1071 (0.0999) loss_oracle 0.4035 (0.3625) acc 87.5000 (84.0625) kd_loss 1.0375 (1.0225) lr 5.7422e-04 eta 0:05:16
epoch [34/50] batch [140/162] time 0.133 (0.118) data 0.000 (0.002) loss 0.8748 (0.8037) ce_loss 0.4468 (0.4351) teacher_loss 0.4288 (0.3911) loss_zs_kd 0.0953 (0.0998) loss_oracle 0.3984 (0.3627) acc 90.6250 (84.1518) kd_loss 1.0478 (1.0210) lr 5.7422e-04 eta 0:05:09
epoch [34/50] batch [160/162] time 0.093 (0.115) data 0.000 (0.002) loss 0.6684 (0.7999) ce_loss 0.3472 (0.4343) teacher_loss 0.2884 (0.3897) loss_zs_kd 0.0980 (0.0990) loss_oracle 0.3311 (0.3607) acc 87.5000 (84.0039) kd_loss 1.0040 (1.0196) lr 5.7422e-04 eta 0:04:58
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,962
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 89.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,616
* accuracy: 79.7%
* error: 20.3%
* macro_f1: 75.0%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [35/50] batch [20/162] time 0.144 (0.135) data 0.000 (0.015) loss 0.6319 (0.8086) ce_loss 0.2625 (0.4467) teacher_loss 0.2641 (0.4008) loss_zs_kd 0.0959 (0.1020) loss_oracle 0.3199 (0.3567) acc 87.5000 (85.0000) kd_loss 1.0165 (1.0441) lr 5.1825e-04 eta 0:05:48
epoch [35/50] batch [40/162] time 0.084 (0.121) data 0.000 (0.008) loss 0.7021 (0.8279) ce_loss 0.2893 (0.4532) teacher_loss 0.2606 (0.4184) loss_zs_kd 0.0970 (0.0976) loss_oracle 0.3930 (0.3607) acc 87.5000 (83.9062) kd_loss 1.0349 (1.0227) lr 5.1825e-04 eta 0:05:07
epoch [35/50] batch [60/162] time 0.096 (0.111) data 0.000 (0.005) loss 0.9356 (0.8160) ce_loss 0.6250 (0.4479) teacher_loss 0.5366 (0.4072) loss_zs_kd 0.1021 (0.0967) loss_oracle 0.3480 (0.3604) acc 84.3750 (83.6458) kd_loss 1.0176 (1.0272) lr 5.1825e-04 eta 0:04:42
epoch [35/50] batch [80/162] time 0.119 (0.109) data 0.000 (0.004) loss 0.7797 (0.8136) ce_loss 0.4407 (0.4483) teacher_loss 0.4152 (0.4101) loss_zs_kd 0.1076 (0.1014) loss_oracle 0.3107 (0.3528) acc 78.1250 (83.7109) kd_loss 1.0903 (1.0334) lr 5.1825e-04 eta 0:04:32
epoch [35/50] batch [100/162] time 0.125 (0.108) data 0.000 (0.003) loss 0.7774 (0.8118) ce_loss 0.3940 (0.4512) teacher_loss 0.3337 (0.4097) loss_zs_kd 0.1051 (0.1023) loss_oracle 0.3912 (0.3510) acc 87.5000 (83.3750) kd_loss 1.0395 (1.0320) lr 5.1825e-04 eta 0:04:28
epoch [35/50] batch [120/162] time 0.137 (0.107) data 0.000 (0.003) loss 0.6329 (0.8068) ce_loss 0.2751 (0.4515) teacher_loss 0.2018 (0.4048) loss_zs_kd 0.0760 (0.1024) loss_oracle 0.3930 (0.3507) acc 87.5000 (83.3854) kd_loss 1.0299 (1.0338) lr 5.1825e-04 eta 0:04:24
epoch [35/50] batch [140/162] time 0.128 (0.107) data 0.000 (0.002) loss 0.6487 (0.7984) ce_loss 0.3135 (0.4431) teacher_loss 0.2437 (0.3953) loss_zs_kd 0.0772 (0.1024) loss_oracle 0.3664 (0.3519) acc 87.5000 (83.8839) kd_loss 1.1450 (1.0388) lr 5.1825e-04 eta 0:04:21
epoch [35/50] batch [160/162] time 0.094 (0.105) data 0.000 (0.002) loss 0.6918 (0.7973) ce_loss 0.3550 (0.4432) teacher_loss 0.3194 (0.3944) loss_zs_kd 0.1033 (0.1030) loss_oracle 0.3207 (0.3514) acc 84.3750 (84.0039) kd_loss 1.0080 (1.0413) lr 5.1825e-04 eta 0:04:16
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,954
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 89.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,653
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 75.5%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [36/50] batch [20/162] time 0.103 (0.132) data 0.000 (0.015) loss 0.7589 (0.7396) ce_loss 0.3787 (0.4016) teacher_loss 0.3427 (0.3488) loss_zs_kd 0.0794 (0.1010) loss_oracle 0.3765 (0.3402) acc 90.6250 (85.1562) kd_loss 1.0613 (1.0521) lr 4.6417e-04 eta 0:05:17
epoch [36/50] batch [40/162] time 0.124 (0.123) data 0.000 (0.007) loss 0.8974 (0.7754) ce_loss 0.6670 (0.4328) teacher_loss 0.5427 (0.3738) loss_zs_kd 0.1427 (0.1051) loss_oracle 0.2834 (0.3491) acc 71.8750 (83.1250) kd_loss 0.9700 (1.0391) lr 4.6417e-04 eta 0:04:54
epoch [36/50] batch [60/162] time 0.062 (0.114) data 0.000 (0.005) loss 0.6557 (0.7861) ce_loss 0.2854 (0.4317) teacher_loss 0.2568 (0.3851) loss_zs_kd 0.0707 (0.1014) loss_oracle 0.3636 (0.3502) acc 90.6250 (83.4375) kd_loss 1.0146 (1.0328) lr 4.6417e-04 eta 0:04:30
epoch [36/50] batch [80/162] time 0.158 (0.119) data 0.000 (0.004) loss 0.7781 (0.7892) ce_loss 0.3611 (0.4342) teacher_loss 0.3355 (0.3846) loss_zs_kd 0.1620 (0.1009) loss_oracle 0.3617 (0.3542) acc 84.3750 (83.6328) kd_loss 1.0244 (1.0267) lr 4.6417e-04 eta 0:04:39
epoch [36/50] batch [100/162] time 0.142 (0.118) data 0.000 (0.003) loss 0.8524 (0.7814) ce_loss 0.4600 (0.4220) teacher_loss 0.4373 (0.3758) loss_zs_kd 0.0794 (0.1013) loss_oracle 0.3753 (0.3550) acc 84.3750 (84.5000) kd_loss 0.9781 (1.0250) lr 4.6417e-04 eta 0:04:34
epoch [36/50] batch [120/162] time 0.169 (0.125) data 0.000 (0.003) loss 0.8438 (0.7935) ce_loss 0.4749 (0.4350) teacher_loss 0.4661 (0.3887) loss_zs_kd 0.0878 (0.1011) loss_oracle 0.3338 (0.3543) acc 90.6250 (84.1406) kd_loss 1.0746 (1.0230) lr 4.6417e-04 eta 0:04:47
epoch [36/50] batch [140/162] time 0.129 (0.121) data 0.000 (0.002) loss 1.0040 (0.8010) ce_loss 0.5659 (0.4373) teacher_loss 0.5506 (0.3934) loss_zs_kd 0.1350 (0.1025) loss_oracle 0.3859 (0.3563) acc 78.1250 (84.0179) kd_loss 1.0312 (1.0208) lr 4.6417e-04 eta 0:04:37
epoch [36/50] batch [160/162] time 0.123 (0.119) data 0.000 (0.002) loss 0.9042 (0.8074) ce_loss 0.5547 (0.4420) teacher_loss 0.5416 (0.4001) loss_zs_kd 0.1269 (0.1024) loss_oracle 0.2992 (0.3561) acc 71.8750 (83.7891) kd_loss 0.9083 (1.0197) lr 4.6417e-04 eta 0:04:30
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,963
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,644
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 75.3%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [37/50] batch [20/162] time 0.099 (0.123) data 0.000 (0.017) loss 0.8337 (0.8450) ce_loss 0.4250 (0.4851) teacher_loss 0.4244 (0.4531) loss_zs_kd 0.1115 (0.0914) loss_oracle 0.3535 (0.3462) acc 84.3750 (82.1875) kd_loss 1.0051 (0.9842) lr 4.1221e-04 eta 0:04:35
epoch [37/50] batch [40/162] time 0.083 (0.113) data 0.000 (0.009) loss 1.0328 (0.8480) ce_loss 0.6235 (0.4878) teacher_loss 0.5819 (0.4542) loss_zs_kd 0.1161 (0.0944) loss_oracle 0.3928 (0.3466) acc 75.0000 (81.8750) kd_loss 1.0532 (1.0005) lr 4.1221e-04 eta 0:04:11
epoch [37/50] batch [60/162] time 0.128 (0.109) data 0.000 (0.006) loss 0.7474 (0.8270) ce_loss 0.3640 (0.4640) teacher_loss 0.3020 (0.4316) loss_zs_kd 0.1095 (0.0961) loss_oracle 0.3907 (0.3473) acc 90.6250 (82.7083) kd_loss 0.9858 (0.9962) lr 4.1221e-04 eta 0:04:01
epoch [37/50] batch [80/162] time 0.068 (0.107) data 0.000 (0.004) loss 0.7677 (0.8129) ce_loss 0.4236 (0.4494) teacher_loss 0.3638 (0.4175) loss_zs_kd 0.1045 (0.0978) loss_oracle 0.3517 (0.3465) acc 78.1250 (83.2422) kd_loss 0.9341 (0.9937) lr 4.1221e-04 eta 0:03:53
epoch [37/50] batch [100/162] time 0.089 (0.107) data 0.000 (0.004) loss 0.9083 (0.8059) ce_loss 0.5669 (0.4442) teacher_loss 0.5327 (0.4107) loss_zs_kd 0.1026 (0.0976) loss_oracle 0.3243 (0.3464) acc 71.8750 (83.2188) kd_loss 1.0255 (1.0004) lr 4.1221e-04 eta 0:03:51
epoch [37/50] batch [120/162] time 0.087 (0.108) data 0.000 (0.003) loss 1.0457 (0.8116) ce_loss 0.6509 (0.4499) teacher_loss 0.6142 (0.4148) loss_zs_kd 0.1016 (0.0995) loss_oracle 0.3807 (0.3471) acc 78.1250 (82.9427) kd_loss 1.0309 (1.0053) lr 4.1221e-04 eta 0:03:52
epoch [37/50] batch [140/162] time 0.127 (0.109) data 0.000 (0.003) loss 0.7662 (0.8036) ce_loss 0.4438 (0.4444) teacher_loss 0.3996 (0.4055) loss_zs_kd 0.0752 (0.0993) loss_oracle 0.3290 (0.3485) acc 87.5000 (83.2812) kd_loss 1.0782 (1.0098) lr 4.1221e-04 eta 0:03:51
epoch [37/50] batch [160/162] time 0.098 (0.108) data 0.000 (0.002) loss 0.6371 (0.8014) ce_loss 0.3567 (0.4443) teacher_loss 0.2355 (0.4004) loss_zs_kd 0.1026 (0.1016) loss_oracle 0.3503 (0.3503) acc 90.6250 (83.3789) kd_loss 1.1363 (1.0207) lr 4.1221e-04 eta 0:03:47
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,949
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,674
* accuracy: 81.5%
* error: 18.5%
* macro_f1: 75.8%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [38/50] batch [20/162] time 0.110 (0.112) data 0.000 (0.014) loss 0.6986 (0.8170) ce_loss 0.4111 (0.4807) teacher_loss 0.3164 (0.3945) loss_zs_kd 0.0879 (0.1158) loss_oracle 0.3383 (0.3646) acc 81.2500 (80.9375) kd_loss 1.0907 (1.0608) lr 3.6258e-04 eta 0:03:53
epoch [38/50] batch [40/162] time 0.077 (0.101) data 0.000 (0.007) loss 0.7967 (0.8142) ce_loss 0.4385 (0.4660) teacher_loss 0.4076 (0.3988) loss_zs_kd 0.0591 (0.1065) loss_oracle 0.3595 (0.3622) acc 90.6250 (82.4219) kd_loss 1.0781 (1.0527) lr 3.6258e-04 eta 0:03:28
epoch [38/50] batch [60/162] time 0.134 (0.100) data 0.001 (0.005) loss 0.6803 (0.8190) ce_loss 0.3750 (0.4730) teacher_loss 0.2721 (0.4052) loss_zs_kd 0.1043 (0.1038) loss_oracle 0.3560 (0.3618) acc 87.5000 (82.2917) kd_loss 1.0858 (1.0604) lr 3.6258e-04 eta 0:03:25
epoch [38/50] batch [80/162] time 0.103 (0.103) data 0.000 (0.004) loss 0.7361 (0.8029) ce_loss 0.3384 (0.4550) teacher_loss 0.3197 (0.3889) loss_zs_kd 0.0894 (0.1045) loss_oracle 0.3717 (0.3618) acc 90.6250 (83.2031) kd_loss 1.0209 (1.0593) lr 3.6258e-04 eta 0:03:28
epoch [38/50] batch [100/162] time 0.148 (0.107) data 0.000 (0.003) loss 0.6873 (0.8009) ce_loss 0.3120 (0.4546) teacher_loss 0.2434 (0.3869) loss_zs_kd 0.1010 (0.1044) loss_oracle 0.3933 (0.3618) acc 90.6250 (83.0312) kd_loss 1.0880 (1.0606) lr 3.6258e-04 eta 0:03:33
epoch [38/50] batch [120/162] time 0.073 (0.111) data 0.000 (0.002) loss 1.0431 (0.7977) ce_loss 0.6133 (0.4523) teacher_loss 0.5495 (0.3835) loss_zs_kd 0.1331 (0.1032) loss_oracle 0.4271 (0.3625) acc 71.8750 (83.1771) kd_loss 1.0651 (1.0617) lr 3.6258e-04 eta 0:03:40
epoch [38/50] batch [140/162] time 0.187 (0.116) data 0.000 (0.002) loss 0.7213 (0.7997) ce_loss 0.3489 (0.4527) teacher_loss 0.2896 (0.3838) loss_zs_kd 0.1014 (0.1040) loss_oracle 0.3811 (0.3639) acc 81.2500 (83.1473) kd_loss 1.1347 (1.0599) lr 3.6258e-04 eta 0:03:47
epoch [38/50] batch [160/162] time 0.093 (0.115) data 0.000 (0.002) loss 0.8678 (0.8041) ce_loss 0.5625 (0.4556) teacher_loss 0.4892 (0.3887) loss_zs_kd 0.0954 (0.1040) loss_oracle 0.3309 (0.3634) acc 78.1250 (82.9492) kd_loss 1.0737 (1.0581) lr 3.6258e-04 eta 0:03:44
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,965
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 89.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,638
* accuracy: 80.4%
* error: 19.6%
* macro_f1: 74.9%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [39/50] batch [20/162] time 0.090 (0.114) data 0.000 (0.013) loss 0.7316 (0.7618) ce_loss 0.4360 (0.4262) teacher_loss 0.3278 (0.3552) loss_zs_kd 0.1288 (0.1086) loss_oracle 0.3394 (0.3523) acc 87.5000 (84.0625) kd_loss 1.0454 (1.0341) lr 3.1545e-04 eta 0:03:39
epoch [39/50] batch [40/162] time 0.078 (0.104) data 0.000 (0.006) loss 0.9518 (0.7894) ce_loss 0.6445 (0.4415) teacher_loss 0.5402 (0.3744) loss_zs_kd 0.1483 (0.1122) loss_oracle 0.3375 (0.3589) acc 71.8750 (83.3594) kd_loss 1.0518 (1.0293) lr 3.1545e-04 eta 0:03:18
epoch [39/50] batch [60/162] time 0.091 (0.100) data 0.001 (0.004) loss 0.6770 (0.7875) ce_loss 0.3896 (0.4455) teacher_loss 0.3069 (0.3789) loss_zs_kd 0.0917 (0.1088) loss_oracle 0.3243 (0.3542) acc 81.2500 (83.3333) kd_loss 1.0332 (1.0341) lr 3.1545e-04 eta 0:03:07
epoch [39/50] batch [80/162] time 0.081 (0.097) data 0.000 (0.003) loss 1.1534 (0.7959) ce_loss 0.6924 (0.4531) teacher_loss 0.6878 (0.3836) loss_zs_kd 0.0874 (0.1070) loss_oracle 0.4218 (0.3588) acc 71.8750 (83.2812) kd_loss 0.9925 (1.0416) lr 3.1545e-04 eta 0:03:00
epoch [39/50] batch [100/162] time 0.082 (0.096) data 0.000 (0.003) loss 0.8282 (0.7976) ce_loss 0.5903 (0.4553) teacher_loss 0.4468 (0.3837) loss_zs_kd 0.1022 (0.1075) loss_oracle 0.3303 (0.3601) acc 75.0000 (83.0625) kd_loss 1.1242 (1.0447) lr 3.1545e-04 eta 0:02:57
epoch [39/50] batch [120/162] time 0.084 (0.095) data 0.000 (0.002) loss 0.9989 (0.7930) ce_loss 0.6338 (0.4518) teacher_loss 0.5288 (0.3790) loss_zs_kd 0.0864 (0.1070) loss_oracle 0.4269 (0.3605) acc 78.1250 (83.1771) kd_loss 0.9820 (1.0472) lr 3.1545e-04 eta 0:02:52
epoch [39/50] batch [140/162] time 0.077 (0.094) data 0.000 (0.002) loss 0.9275 (0.7858) ce_loss 0.5151 (0.4457) teacher_loss 0.4188 (0.3726) loss_zs_kd 0.1424 (0.1079) loss_oracle 0.4374 (0.3592) acc 87.5000 (83.6607) kd_loss 1.1306 (1.0515) lr 3.1545e-04 eta 0:02:49
epoch [39/50] batch [160/162] time 0.095 (0.094) data 0.000 (0.002) loss 0.7821 (0.7883) ce_loss 0.4238 (0.4496) teacher_loss 0.3978 (0.3759) loss_zs_kd 0.1079 (0.1075) loss_oracle 0.3303 (0.3586) acc 84.3750 (83.6133) kd_loss 1.0562 (1.0535) lr 3.1545e-04 eta 0:02:46
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,959
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 89.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,663
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 75.4%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [40/50] batch [20/162] time 0.136 (0.125) data 0.000 (0.015) loss 0.7139 (0.7793) ce_loss 0.3547 (0.4529) teacher_loss 0.3165 (0.3717) loss_zs_kd 0.1096 (0.1040) loss_oracle 0.3426 (0.3556) acc 81.2500 (83.7500) kd_loss 1.0423 (1.0645) lr 2.7103e-04 eta 0:03:40
epoch [40/50] batch [40/162] time 0.089 (0.111) data 0.000 (0.007) loss 0.8025 (0.7812) ce_loss 0.4868 (0.4571) teacher_loss 0.3851 (0.3691) loss_zs_kd 0.1212 (0.1089) loss_oracle 0.3568 (0.3577) acc 78.1250 (82.8125) kd_loss 1.0532 (1.0734) lr 2.7103e-04 eta 0:03:14
epoch [40/50] batch [60/162] time 0.092 (0.108) data 0.001 (0.005) loss 0.8247 (0.7872) ce_loss 0.4878 (0.4609) teacher_loss 0.4815 (0.3757) loss_zs_kd 0.0780 (0.1089) loss_oracle 0.3042 (0.3571) acc 78.1250 (83.5417) kd_loss 1.1183 (1.0758) lr 2.7103e-04 eta 0:03:06
epoch [40/50] batch [80/162] time 0.092 (0.107) data 0.000 (0.004) loss 0.8161 (0.7986) ce_loss 0.4661 (0.4737) teacher_loss 0.3794 (0.3878) loss_zs_kd 0.1077 (0.1100) loss_oracle 0.3828 (0.3558) acc 81.2500 (83.0859) kd_loss 1.1241 (1.0747) lr 2.7103e-04 eta 0:03:01
epoch [40/50] batch [100/162] time 0.133 (0.108) data 0.000 (0.003) loss 0.6286 (0.7928) ce_loss 0.2566 (0.4637) teacher_loss 0.2172 (0.3811) loss_zs_kd 0.0658 (0.1089) loss_oracle 0.3785 (0.3573) acc 93.7500 (83.3438) kd_loss 1.0249 (1.0717) lr 2.7103e-04 eta 0:03:02
epoch [40/50] batch [120/162] time 0.098 (0.110) data 0.000 (0.003) loss 0.9391 (0.7967) ce_loss 0.5767 (0.4662) teacher_loss 0.4727 (0.3822) loss_zs_kd 0.1114 (0.1082) loss_oracle 0.4106 (0.3604) acc 78.1250 (82.9167) kd_loss 1.0840 (1.0742) lr 2.7103e-04 eta 0:03:02
epoch [40/50] batch [140/162] time 0.082 (0.110) data 0.000 (0.002) loss 0.6910 (0.7957) ce_loss 0.3066 (0.4649) teacher_loss 0.2728 (0.3807) loss_zs_kd 0.1181 (0.1082) loss_oracle 0.3591 (0.3608) acc 87.5000 (82.9911) kd_loss 1.0474 (1.0753) lr 2.7103e-04 eta 0:03:00
epoch [40/50] batch [160/162] time 0.116 (0.115) data 0.000 (0.002) loss 0.5859 (0.7912) ce_loss 0.2318 (0.4609) teacher_loss 0.2009 (0.3765) loss_zs_kd 0.0964 (0.1082) loss_oracle 0.3368 (0.3606) acc 93.7500 (83.2227) kd_loss 1.0697 (1.0721) lr 2.7103e-04 eta 0:03:06
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,953
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 89.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,678
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 75.7%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [41/50] batch [20/162] time 0.085 (0.126) data 0.000 (0.015) loss 0.9084 (0.7685) ce_loss 0.6230 (0.4396) teacher_loss 0.4470 (0.3616) loss_zs_kd 0.1520 (0.1066) loss_oracle 0.3854 (0.3535) acc 75.0000 (82.8125) kd_loss 1.0972 (1.0688) lr 2.2949e-04 eta 0:03:21
epoch [41/50] batch [40/162] time 0.142 (0.117) data 0.000 (0.008) loss 0.8087 (0.7828) ce_loss 0.4241 (0.4550) teacher_loss 0.3732 (0.3726) loss_zs_kd 0.1462 (0.1096) loss_oracle 0.3624 (0.3553) acc 75.0000 (82.6562) kd_loss 1.0479 (1.0731) lr 2.2949e-04 eta 0:03:05
epoch [41/50] batch [60/162] time 0.109 (0.114) data 0.001 (0.005) loss 1.3316 (0.7930) ce_loss 1.0293 (0.4679) teacher_loss 0.9302 (0.3802) loss_zs_kd 0.1208 (0.1082) loss_oracle 0.3410 (0.3588) acc 62.5000 (82.2396) kd_loss 1.1256 (1.0804) lr 2.2949e-04 eta 0:02:57
epoch [41/50] batch [80/162] time 0.088 (0.114) data 0.000 (0.004) loss 0.9982 (0.7826) ce_loss 0.5425 (0.4551) teacher_loss 0.5189 (0.3672) loss_zs_kd 0.0744 (0.1089) loss_oracle 0.4421 (0.3610) acc 81.2500 (82.7344) kd_loss 1.1326 (1.0770) lr 2.2949e-04 eta 0:02:55
epoch [41/50] batch [100/162] time 0.081 (0.113) data 0.000 (0.003) loss 0.7418 (0.7871) ce_loss 0.4092 (0.4551) teacher_loss 0.3035 (0.3689) loss_zs_kd 0.0894 (0.1103) loss_oracle 0.3936 (0.3631) acc 87.5000 (82.8438) kd_loss 1.0790 (1.0740) lr 2.2949e-04 eta 0:02:51
epoch [41/50] batch [120/162] time 0.124 (0.112) data 0.000 (0.003) loss 0.7701 (0.7896) ce_loss 0.4578 (0.4585) teacher_loss 0.2665 (0.3692) loss_zs_kd 0.1375 (0.1104) loss_oracle 0.4348 (0.3652) acc 84.3750 (82.8125) kd_loss 1.0224 (1.0686) lr 2.2949e-04 eta 0:02:47
epoch [41/50] batch [140/162] time 0.136 (0.111) data 0.000 (0.002) loss 0.8411 (0.7933) ce_loss 0.5947 (0.4568) teacher_loss 0.4352 (0.3695) loss_zs_kd 0.0755 (0.1104) loss_oracle 0.3682 (0.3687) acc 75.0000 (82.7232) kd_loss 0.9891 (1.0699) lr 2.2949e-04 eta 0:02:44
epoch [41/50] batch [160/162] time 0.076 (0.108) data 0.000 (0.002) loss 0.6837 (0.7921) ce_loss 0.3149 (0.4563) teacher_loss 0.2932 (0.3710) loss_zs_kd 0.0823 (0.1087) loss_oracle 0.3494 (0.3668) acc 93.7500 (82.9297) kd_loss 1.0740 (1.0685) lr 2.2949e-04 eta 0:02:38
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,956
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 89.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,676
* accuracy: 81.5%
* error: 18.5%
* macro_f1: 75.6%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [42/50] batch [20/162] time 0.096 (0.117) data 0.000 (0.015) loss 1.0107 (0.7802) ce_loss 0.6460 (0.4496) teacher_loss 0.6377 (0.3579) loss_zs_kd 0.1116 (0.1019) loss_oracle 0.3172 (0.3713) acc 84.3750 (82.1875) kd_loss 0.9893 (1.0576) lr 1.9098e-04 eta 0:02:47
epoch [42/50] batch [40/162] time 0.094 (0.104) data 0.000 (0.008) loss 0.7863 (0.7726) ce_loss 0.5107 (0.4263) teacher_loss 0.4175 (0.3510) loss_zs_kd 0.0840 (0.1041) loss_oracle 0.3268 (0.3696) acc 81.2500 (83.0469) kd_loss 0.9847 (1.0463) lr 1.9098e-04 eta 0:02:28
epoch [42/50] batch [60/162] time 0.078 (0.101) data 0.001 (0.005) loss 0.7275 (0.7846) ce_loss 0.3247 (0.4400) teacher_loss 0.2608 (0.3640) loss_zs_kd 0.1091 (0.1021) loss_oracle 0.4122 (0.3695) acc 84.3750 (82.4479) kd_loss 0.9077 (1.0475) lr 1.9098e-04 eta 0:02:21
epoch [42/50] batch [80/162] time 0.083 (0.100) data 0.000 (0.004) loss 0.8017 (0.7892) ce_loss 0.5786 (0.4479) teacher_loss 0.3945 (0.3691) loss_zs_kd 0.0902 (0.1026) loss_oracle 0.3621 (0.3688) acc 81.2500 (82.1875) kd_loss 0.9844 (1.0500) lr 1.9098e-04 eta 0:02:18
epoch [42/50] batch [100/162] time 0.086 (0.099) data 0.000 (0.003) loss 0.8651 (0.7837) ce_loss 0.5488 (0.4419) teacher_loss 0.4833 (0.3670) loss_zs_kd 0.1326 (0.1014) loss_oracle 0.3155 (0.3661) acc 65.6250 (82.4375) kd_loss 0.9683 (1.0441) lr 1.9098e-04 eta 0:02:14
epoch [42/50] batch [120/162] time 0.115 (0.101) data 0.000 (0.003) loss 0.8995 (0.7870) ce_loss 0.5171 (0.4451) teacher_loss 0.4767 (0.3718) loss_zs_kd 0.0723 (0.1016) loss_oracle 0.3867 (0.3644) acc 78.1250 (82.6042) kd_loss 1.0415 (1.0421) lr 1.9098e-04 eta 0:02:14
epoch [42/50] batch [140/162] time 0.083 (0.104) data 0.000 (0.002) loss 0.9566 (0.7885) ce_loss 0.5278 (0.4439) teacher_loss 0.5413 (0.3742) loss_zs_kd 0.1217 (0.1025) loss_oracle 0.3545 (0.3631) acc 78.1250 (82.8125) kd_loss 1.0279 (1.0433) lr 1.9098e-04 eta 0:02:16
epoch [42/50] batch [160/162] time 0.117 (0.104) data 0.000 (0.002) loss 0.7534 (0.7949) ce_loss 0.3340 (0.4515) teacher_loss 0.3154 (0.3799) loss_zs_kd 0.1276 (0.1030) loss_oracle 0.3741 (0.3636) acc 87.5000 (82.5391) kd_loss 0.9633 (1.0423) lr 1.9098e-04 eta 0:02:14
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 89.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,657
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 75.3%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [43/50] batch [20/162] time 0.121 (0.155) data 0.000 (0.014) loss 0.7842 (0.8136) ce_loss 0.3774 (0.4480) teacher_loss 0.3704 (0.4014) loss_zs_kd 0.1154 (0.1010) loss_oracle 0.3562 (0.3617) acc 93.7500 (84.0625) kd_loss 1.1128 (1.0309) lr 1.5567e-04 eta 0:03:17
epoch [43/50] batch [40/162] time 0.141 (0.135) data 0.000 (0.007) loss 0.8064 (0.8136) ce_loss 0.4812 (0.4654) teacher_loss 0.4170 (0.4070) loss_zs_kd 0.0800 (0.1004) loss_oracle 0.3494 (0.3564) acc 81.2500 (82.8125) kd_loss 1.0042 (1.0309) lr 1.5567e-04 eta 0:02:50
epoch [43/50] batch [60/162] time 0.123 (0.129) data 0.000 (0.005) loss 1.1321 (0.7974) ce_loss 0.7744 (0.4507) teacher_loss 0.6673 (0.3890) loss_zs_kd 0.1422 (0.1021) loss_oracle 0.3937 (0.3573) acc 65.6250 (83.2292) kd_loss 1.0808 (1.0377) lr 1.5567e-04 eta 0:02:39
epoch [43/50] batch [80/162] time 0.118 (0.125) data 0.000 (0.004) loss 0.8358 (0.7884) ce_loss 0.5703 (0.4405) teacher_loss 0.4244 (0.3800) loss_zs_kd 0.0890 (0.1016) loss_oracle 0.3669 (0.3575) acc 78.1250 (83.0859) kd_loss 1.0235 (1.0335) lr 1.5567e-04 eta 0:02:32
epoch [43/50] batch [100/162] time 0.143 (0.123) data 0.000 (0.003) loss 0.6789 (0.7883) ce_loss 0.2969 (0.4394) teacher_loss 0.2411 (0.3793) loss_zs_kd 0.0820 (0.1005) loss_oracle 0.3969 (0.3588) acc 96.8750 (83.4062) kd_loss 0.9890 (1.0318) lr 1.5567e-04 eta 0:02:27
epoch [43/50] batch [120/162] time 0.129 (0.123) data 0.000 (0.003) loss 0.8765 (0.7916) ce_loss 0.5835 (0.4462) teacher_loss 0.4798 (0.3843) loss_zs_kd 0.1162 (0.1010) loss_oracle 0.3386 (0.3569) acc 71.8750 (83.4115) kd_loss 1.0407 (1.0328) lr 1.5567e-04 eta 0:02:24
epoch [43/50] batch [140/162] time 0.133 (0.121) data 0.000 (0.002) loss 0.8250 (0.7893) ce_loss 0.4783 (0.4405) teacher_loss 0.4131 (0.3800) loss_zs_kd 0.1049 (0.1021) loss_oracle 0.3594 (0.3583) acc 75.0000 (83.7277) kd_loss 1.1278 (1.0351) lr 1.5567e-04 eta 0:02:19
epoch [43/50] batch [160/162] time 0.120 (0.119) data 0.000 (0.002) loss 0.6889 (0.7851) ce_loss 0.3467 (0.4401) teacher_loss 0.2427 (0.3775) loss_zs_kd 0.1083 (0.1020) loss_oracle 0.3921 (0.3566) acc 87.5000 (83.7305) kd_loss 1.0139 (1.0347) lr 1.5567e-04 eta 0:02:15
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,961
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 89.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,650
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 75.1%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [44/50] batch [20/162] time 0.106 (0.116) data 0.000 (0.013) loss 0.8819 (0.7690) ce_loss 0.4731 (0.4075) teacher_loss 0.4524 (0.3552) loss_zs_kd 0.1273 (0.1042) loss_oracle 0.3658 (0.3616) acc 81.2500 (85.0000) kd_loss 1.0370 (1.0361) lr 1.2369e-04 eta 0:02:09
epoch [44/50] batch [40/162] time 0.089 (0.108) data 0.000 (0.006) loss 0.6947 (0.7591) ce_loss 0.3542 (0.4097) teacher_loss 0.3404 (0.3478) loss_zs_kd 0.0826 (0.1052) loss_oracle 0.3130 (0.3587) acc 84.3750 (85.0781) kd_loss 1.0502 (1.0390) lr 1.2369e-04 eta 0:01:58
epoch [44/50] batch [60/162] time 0.111 (0.106) data 0.000 (0.004) loss 0.6592 (0.7822) ce_loss 0.3447 (0.4359) teacher_loss 0.2735 (0.3703) loss_zs_kd 0.1076 (0.1042) loss_oracle 0.3319 (0.3598) acc 84.3750 (84.1667) kd_loss 1.0122 (1.0418) lr 1.2369e-04 eta 0:01:53
epoch [44/50] batch [80/162] time 0.078 (0.106) data 0.000 (0.003) loss 0.6883 (0.7883) ce_loss 0.4082 (0.4459) teacher_loss 0.3515 (0.3795) loss_zs_kd 0.0771 (0.1038) loss_oracle 0.2983 (0.3569) acc 90.6250 (84.0625) kd_loss 0.9581 (1.0390) lr 1.2369e-04 eta 0:01:51
epoch [44/50] batch [100/162] time 0.130 (0.106) data 0.000 (0.003) loss 0.8563 (0.7814) ce_loss 0.4744 (0.4375) teacher_loss 0.4452 (0.3704) loss_zs_kd 0.1148 (0.1024) loss_oracle 0.3536 (0.3598) acc 81.2500 (84.2812) kd_loss 1.0867 (1.0402) lr 1.2369e-04 eta 0:01:49
epoch [44/50] batch [120/162] time 0.132 (0.106) data 0.000 (0.002) loss 0.8086 (0.7839) ce_loss 0.4746 (0.4372) teacher_loss 0.4341 (0.3710) loss_zs_kd 0.1214 (0.1025) loss_oracle 0.3138 (0.3617) acc 84.3750 (84.5833) kd_loss 1.0686 (1.0409) lr 1.2369e-04 eta 0:01:47
epoch [44/50] batch [140/162] time 0.132 (0.106) data 0.000 (0.002) loss 0.8978 (0.7919) ce_loss 0.5176 (0.4490) teacher_loss 0.4824 (0.3793) loss_zs_kd 0.0950 (0.1031) loss_oracle 0.3679 (0.3610) acc 81.2500 (83.8839) kd_loss 0.9989 (1.0400) lr 1.2369e-04 eta 0:01:44
epoch [44/50] batch [160/162] time 0.096 (0.104) data 0.000 (0.002) loss 1.1271 (0.7922) ce_loss 0.8086 (0.4496) teacher_loss 0.7167 (0.3792) loss_zs_kd 0.1082 (0.1037) loss_oracle 0.3563 (0.3611) acc 62.5000 (83.8281) kd_loss 1.0440 (1.0393) lr 1.2369e-04 eta 0:01:41
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,961
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 89.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,649
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 75.1%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [45/50] batch [20/162] time 0.064 (0.155) data 0.000 (0.015) loss 0.9886 (0.7933) ce_loss 0.6323 (0.4509) teacher_loss 0.5795 (0.3782) loss_zs_kd 0.0994 (0.1098) loss_oracle 0.3594 (0.3603) acc 78.1250 (84.0625) kd_loss 1.0480 (1.0441) lr 9.5173e-05 eta 0:02:27
epoch [45/50] batch [40/162] time 0.114 (0.124) data 0.000 (0.008) loss 0.7666 (0.8087) ce_loss 0.4304 (0.4604) teacher_loss 0.4108 (0.3980) loss_zs_kd 0.0658 (0.1051) loss_oracle 0.3229 (0.3582) acc 90.6250 (83.1250) kd_loss 1.0851 (1.0426) lr 9.5173e-05 eta 0:01:55
epoch [45/50] batch [60/162] time 0.078 (0.117) data 0.000 (0.005) loss 0.5937 (0.7905) ce_loss 0.1682 (0.4377) teacher_loss 0.1391 (0.3801) loss_zs_kd 0.0939 (0.1049) loss_oracle 0.4077 (0.3580) acc 96.8750 (83.8021) kd_loss 1.0313 (1.0384) lr 9.5173e-05 eta 0:01:46
epoch [45/50] batch [80/162] time 0.070 (0.113) data 0.000 (0.004) loss 0.6528 (0.7814) ce_loss 0.3191 (0.4294) teacher_loss 0.2956 (0.3685) loss_zs_kd 0.0832 (0.1054) loss_oracle 0.3157 (0.3602) acc 87.5000 (84.1406) kd_loss 0.9874 (1.0357) lr 9.5173e-05 eta 0:01:41
epoch [45/50] batch [100/162] time 0.075 (0.112) data 0.000 (0.003) loss 0.6965 (0.7851) ce_loss 0.3438 (0.4285) teacher_loss 0.3076 (0.3717) loss_zs_kd 0.0984 (0.1036) loss_oracle 0.3397 (0.3616) acc 90.6250 (83.9062) kd_loss 0.9536 (1.0341) lr 9.5173e-05 eta 0:01:37
epoch [45/50] batch [120/162] time 0.098 (0.110) data 0.000 (0.003) loss 0.6728 (0.7913) ce_loss 0.3318 (0.4340) teacher_loss 0.3205 (0.3802) loss_zs_kd 0.0836 (0.1036) loss_oracle 0.3105 (0.3593) acc 87.5000 (83.9323) kd_loss 0.9560 (1.0292) lr 9.5173e-05 eta 0:01:33
epoch [45/50] batch [140/162] time 0.087 (0.110) data 0.000 (0.002) loss 0.6062 (0.7884) ce_loss 0.2812 (0.4355) teacher_loss 0.2405 (0.3793) loss_zs_kd 0.1159 (0.1038) loss_oracle 0.3077 (0.3572) acc 90.6250 (83.9955) kd_loss 1.0205 (1.0297) lr 9.5173e-05 eta 0:01:31
epoch [45/50] batch [160/162] time 0.079 (0.108) data 0.000 (0.002) loss 0.9361 (0.7895) ce_loss 0.5762 (0.4370) teacher_loss 0.5267 (0.3812) loss_zs_kd 0.1202 (0.1033) loss_oracle 0.3492 (0.3566) acc 81.2500 (83.8086) kd_loss 0.9778 (1.0313) lr 9.5173e-05 eta 0:01:27
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,964
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,646
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 75.1%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [46/50] batch [20/162] time 0.090 (0.119) data 0.000 (0.014) loss 0.7553 (0.8469) ce_loss 0.4133 (0.4881) teacher_loss 0.3573 (0.4278) loss_zs_kd 0.0655 (0.1002) loss_oracle 0.3652 (0.3689) acc 81.2500 (82.1875) kd_loss 1.0897 (1.0450) lr 7.0224e-05 eta 0:01:33
epoch [46/50] batch [40/162] time 0.087 (0.114) data 0.000 (0.007) loss 0.8677 (0.8216) ce_loss 0.5742 (0.4689) teacher_loss 0.4073 (0.4077) loss_zs_kd 0.1238 (0.1029) loss_oracle 0.3985 (0.3625) acc 81.2500 (83.0469) kd_loss 1.0236 (1.0362) lr 7.0224e-05 eta 0:01:27
epoch [46/50] batch [60/162] time 0.082 (0.111) data 0.000 (0.005) loss 0.7593 (0.8123) ce_loss 0.3503 (0.4550) teacher_loss 0.3604 (0.3972) loss_zs_kd 0.0947 (0.1052) loss_oracle 0.3517 (0.3626) acc 87.5000 (83.2292) kd_loss 0.9790 (1.0363) lr 7.0224e-05 eta 0:01:23
epoch [46/50] batch [80/162] time 0.106 (0.112) data 0.000 (0.004) loss 0.6637 (0.7978) ce_loss 0.3850 (0.4363) teacher_loss 0.3224 (0.3827) loss_zs_kd 0.0781 (0.1040) loss_oracle 0.3022 (0.3631) acc 87.5000 (84.2969) kd_loss 0.9962 (1.0368) lr 7.0224e-05 eta 0:01:21
epoch [46/50] batch [100/162] time 0.118 (0.111) data 0.000 (0.003) loss 0.9003 (0.7942) ce_loss 0.4602 (0.4338) teacher_loss 0.4515 (0.3820) loss_zs_kd 0.1165 (0.1019) loss_oracle 0.3905 (0.3613) acc 75.0000 (84.0625) kd_loss 0.9464 (1.0351) lr 7.0224e-05 eta 0:01:18
epoch [46/50] batch [120/162] time 0.080 (0.110) data 0.000 (0.003) loss 0.7167 (0.7996) ce_loss 0.3743 (0.4433) teacher_loss 0.3069 (0.3889) loss_zs_kd 0.0959 (0.1020) loss_oracle 0.3618 (0.3597) acc 87.5000 (83.7760) kd_loss 1.0531 (1.0354) lr 7.0224e-05 eta 0:01:15
epoch [46/50] batch [140/162] time 0.115 (0.110) data 0.000 (0.002) loss 0.8282 (0.7980) ce_loss 0.4858 (0.4425) teacher_loss 0.4005 (0.3872) loss_zs_kd 0.0796 (0.1020) loss_oracle 0.3879 (0.3598) acc 78.1250 (83.6161) kd_loss 1.0471 (1.0342) lr 7.0224e-05 eta 0:01:13
epoch [46/50] batch [160/162] time 0.093 (0.108) data 0.000 (0.002) loss 0.7848 (0.7978) ce_loss 0.4375 (0.4435) teacher_loss 0.3408 (0.3866) loss_zs_kd 0.0987 (0.1011) loss_oracle 0.3947 (0.3607) acc 75.0000 (83.6133) kd_loss 1.0884 (1.0350) lr 7.0224e-05 eta 0:01:09
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,964
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,649
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 75.1%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [47/50] batch [20/162] time 0.164 (0.174) data 0.000 (0.016) loss 0.7401 (0.7742) ce_loss 0.3345 (0.4150) teacher_loss 0.2641 (0.3622) loss_zs_kd 0.0987 (0.0984) loss_oracle 0.4267 (0.3629) acc 78.1250 (83.2812) kd_loss 1.0662 (1.0217) lr 4.8943e-05 eta 0:01:49
epoch [47/50] batch [40/162] time 0.151 (0.148) data 0.000 (0.008) loss 0.9768 (0.7824) ce_loss 0.5586 (0.4234) teacher_loss 0.5071 (0.3649) loss_zs_kd 0.1640 (0.1019) loss_oracle 0.3877 (0.3665) acc 81.2500 (83.4375) kd_loss 1.0122 (1.0267) lr 4.8943e-05 eta 0:01:30
epoch [47/50] batch [60/162] time 0.113 (0.147) data 0.000 (0.006) loss 0.9954 (0.8167) ce_loss 0.5674 (0.4624) teacher_loss 0.5491 (0.4030) loss_zs_kd 0.0996 (0.1017) loss_oracle 0.3965 (0.3628) acc 81.2500 (82.8646) kd_loss 1.0266 (1.0294) lr 4.8943e-05 eta 0:01:26
epoch [47/50] batch [80/162] time 0.085 (0.134) data 0.000 (0.004) loss 0.7378 (0.8028) ce_loss 0.3911 (0.4479) teacher_loss 0.3712 (0.3900) loss_zs_kd 0.1064 (0.1016) loss_oracle 0.3134 (0.3620) acc 87.5000 (83.5938) kd_loss 1.0563 (1.0292) lr 4.8943e-05 eta 0:01:16
epoch [47/50] batch [100/162] time 0.135 (0.129) data 0.000 (0.003) loss 0.7867 (0.7958) ce_loss 0.4888 (0.4396) teacher_loss 0.3795 (0.3833) loss_zs_kd 0.1001 (0.1018) loss_oracle 0.3571 (0.3616) acc 81.2500 (83.8438) kd_loss 0.9053 (1.0271) lr 4.8943e-05 eta 0:01:10
epoch [47/50] batch [120/162] time 0.084 (0.125) data 0.000 (0.003) loss 0.7305 (0.7949) ce_loss 0.3193 (0.4403) teacher_loss 0.3259 (0.3827) loss_zs_kd 0.0995 (0.1016) loss_oracle 0.3548 (0.3614) acc 90.6250 (83.9583) kd_loss 1.0914 (1.0289) lr 4.8943e-05 eta 0:01:06
epoch [47/50] batch [140/162] time 0.085 (0.124) data 0.001 (0.003) loss 0.9395 (0.7958) ce_loss 0.5278 (0.4416) teacher_loss 0.4861 (0.3828) loss_zs_kd 0.1469 (0.1015) loss_oracle 0.3799 (0.3622) acc 81.2500 (83.8839) kd_loss 1.0974 (1.0306) lr 4.8943e-05 eta 0:01:02
epoch [47/50] batch [160/162] time 0.072 (0.120) data 0.000 (0.002) loss 0.8417 (0.7959) ce_loss 0.4290 (0.4409) teacher_loss 0.4131 (0.3846) loss_zs_kd 0.1065 (0.1014) loss_oracle 0.3754 (0.3606) acc 87.5000 (84.0039) kd_loss 1.0689 (1.0320) lr 4.8943e-05 eta 0:00:58
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,964
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,647
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 75.1%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [48/50] batch [20/162] time 0.087 (0.116) data 0.000 (0.011) loss 0.6900 (0.7957) ce_loss 0.3723 (0.4360) teacher_loss 0.2672 (0.3853) loss_zs_kd 0.0837 (0.1058) loss_oracle 0.3810 (0.3575) acc 87.5000 (83.2812) kd_loss 0.9806 (1.0275) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [40/162] time 0.117 (0.114) data 0.000 (0.006) loss 0.8781 (0.7672) ce_loss 0.4319 (0.4134) teacher_loss 0.4595 (0.3601) loss_zs_kd 0.0709 (0.1031) loss_oracle 0.3832 (0.3556) acc 90.6250 (84.5312) kd_loss 1.0586 (1.0434) lr 3.1417e-05 eta 0:00:50
epoch [48/50] batch [60/162] time 0.105 (0.111) data 0.001 (0.004) loss 0.9523 (0.7776) ce_loss 0.5322 (0.4246) teacher_loss 0.5406 (0.3674) loss_zs_kd 0.0994 (0.1010) loss_oracle 0.3620 (0.3597) acc 78.1250 (84.4792) kd_loss 1.0710 (1.0364) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [80/162] time 0.143 (0.111) data 0.000 (0.003) loss 0.8299 (0.7835) ce_loss 0.4395 (0.4374) teacher_loss 0.4007 (0.3763) loss_zs_kd 0.0923 (0.1014) loss_oracle 0.3830 (0.3564) acc 81.2500 (83.6328) kd_loss 1.0643 (1.0387) lr 3.1417e-05 eta 0:00:45
epoch [48/50] batch [100/162] time 0.122 (0.111) data 0.000 (0.002) loss 0.9818 (0.7896) ce_loss 0.6309 (0.4426) teacher_loss 0.6130 (0.3835) loss_zs_kd 0.1159 (0.1021) loss_oracle 0.3108 (0.3551) acc 78.1250 (83.4688) kd_loss 1.0858 (1.0396) lr 3.1417e-05 eta 0:00:42
epoch [48/50] batch [120/162] time 0.090 (0.111) data 0.000 (0.002) loss 0.8250 (0.7957) ce_loss 0.3896 (0.4477) teacher_loss 0.4131 (0.3904) loss_zs_kd 0.0871 (0.1022) loss_oracle 0.3683 (0.3542) acc 87.5000 (83.5156) kd_loss 1.0612 (1.0407) lr 3.1417e-05 eta 0:00:40
epoch [48/50] batch [140/162] time 0.100 (0.110) data 0.000 (0.002) loss 0.8425 (0.7928) ce_loss 0.4092 (0.4411) teacher_loss 0.3510 (0.3879) loss_zs_kd 0.0744 (0.1018) loss_oracle 0.4543 (0.3540) acc 84.3750 (83.7946) kd_loss 0.9998 (1.0398) lr 3.1417e-05 eta 0:00:38
epoch [48/50] batch [160/162] time 0.077 (0.109) data 0.000 (0.002) loss 0.6107 (0.7990) ce_loss 0.2717 (0.4465) teacher_loss 0.2434 (0.3920) loss_zs_kd 0.1123 (0.1024) loss_oracle 0.3112 (0.3558) acc 93.7500 (83.6133) kd_loss 1.0399 (1.0387) lr 3.1417e-05 eta 0:00:35
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,964
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,648
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 75.1%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [49/50] batch [20/162] time 0.067 (0.112) data 0.000 (0.015) loss 0.6555 (0.8325) ce_loss 0.2986 (0.4795) teacher_loss 0.2458 (0.4144) loss_zs_kd 0.1155 (0.1071) loss_oracle 0.3519 (0.3646) acc 93.7500 (81.5625) kd_loss 1.0660 (1.0505) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [40/162] time 0.145 (0.128) data 0.000 (0.008) loss 0.8403 (0.8119) ce_loss 0.4841 (0.4566) teacher_loss 0.4262 (0.3980) loss_zs_kd 0.0824 (0.1008) loss_oracle 0.3729 (0.3636) acc 75.0000 (83.2031) kd_loss 1.0104 (1.0465) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [60/162] time 0.141 (0.126) data 0.001 (0.005) loss 0.6546 (0.8036) ce_loss 0.4001 (0.4494) teacher_loss 0.3657 (0.3955) loss_zs_kd 0.0857 (0.1004) loss_oracle 0.2460 (0.3578) acc 84.3750 (83.5417) kd_loss 1.0907 (1.0396) lr 1.7713e-05 eta 0:00:33
epoch [49/50] batch [80/162] time 0.076 (0.132) data 0.000 (0.004) loss 0.8799 (0.7989) ce_loss 0.5430 (0.4500) teacher_loss 0.4690 (0.3941) loss_zs_kd 0.1326 (0.1001) loss_oracle 0.3446 (0.3548) acc 84.3750 (83.6719) kd_loss 1.0333 (1.0397) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [100/162] time 0.109 (0.126) data 0.001 (0.003) loss 0.9334 (0.7953) ce_loss 0.5625 (0.4457) teacher_loss 0.5378 (0.3892) loss_zs_kd 0.1069 (0.1011) loss_oracle 0.3421 (0.3555) acc 81.2500 (83.8750) kd_loss 1.1043 (1.0407) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [120/162] time 0.091 (0.123) data 0.000 (0.003) loss 0.7192 (0.7949) ce_loss 0.3909 (0.4506) teacher_loss 0.3171 (0.3886) loss_zs_kd 0.1118 (0.1020) loss_oracle 0.3462 (0.3553) acc 90.6250 (83.6719) kd_loss 1.0581 (1.0401) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [140/162] time 0.124 (0.122) data 0.000 (0.002) loss 0.8155 (0.7924) ce_loss 0.4446 (0.4458) teacher_loss 0.3487 (0.3859) loss_zs_kd 0.1037 (0.1015) loss_oracle 0.4149 (0.3558) acc 78.1250 (83.5938) kd_loss 1.0928 (1.0395) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [160/162] time 0.082 (0.119) data 0.000 (0.002) loss 0.9401 (0.8013) ce_loss 0.6528 (0.4521) teacher_loss 0.5601 (0.3930) loss_zs_kd 0.0939 (0.1028) loss_oracle 0.3330 (0.3570) acc 81.2500 (83.4570) kd_loss 1.0474 (1.0405) lr 1.7713e-05 eta 0:00:19
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,965
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 89.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,647
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 75.1%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
epoch [50/50] batch [20/162] time 0.086 (0.107) data 0.000 (0.012) loss 0.8102 (0.7604) ce_loss 0.5337 (0.4105) teacher_loss 0.4153 (0.3608) loss_zs_kd 0.1219 (0.1064) loss_oracle 0.3339 (0.3464) acc 75.0000 (85.0000) kd_loss 1.0440 (1.0365) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [40/162] time 0.097 (0.103) data 0.000 (0.006) loss 0.8133 (0.7929) ce_loss 0.4622 (0.4431) teacher_loss 0.3773 (0.3896) loss_zs_kd 0.0991 (0.1048) loss_oracle 0.3865 (0.3509) acc 78.1250 (83.3594) kd_loss 1.0590 (1.0363) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [60/162] time 0.125 (0.101) data 0.000 (0.004) loss 0.7030 (0.7761) ce_loss 0.3215 (0.4250) teacher_loss 0.2709 (0.3700) loss_zs_kd 0.0853 (0.1025) loss_oracle 0.3895 (0.3548) acc 84.3750 (84.4792) kd_loss 1.0722 (1.0418) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [80/162] time 0.095 (0.100) data 0.000 (0.003) loss 0.7758 (0.7828) ce_loss 0.5063 (0.4286) teacher_loss 0.4194 (0.3738) loss_zs_kd 0.1140 (0.1026) loss_oracle 0.2994 (0.3577) acc 84.3750 (84.1406) kd_loss 1.0496 (1.0407) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [100/162] time 0.135 (0.100) data 0.000 (0.003) loss 0.9593 (0.7838) ce_loss 0.6528 (0.4323) teacher_loss 0.5440 (0.3745) loss_zs_kd 0.1568 (0.1035) loss_oracle 0.3369 (0.3575) acc 71.8750 (84.0938) kd_loss 1.0758 (1.0410) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [120/162] time 0.079 (0.099) data 0.000 (0.002) loss 0.8332 (0.7860) ce_loss 0.4077 (0.4324) teacher_loss 0.3854 (0.3760) loss_zs_kd 0.1046 (0.1025) loss_oracle 0.3956 (0.3588) acc 81.2500 (84.0365) kd_loss 1.0694 (1.0439) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [140/162] time 0.118 (0.099) data 0.000 (0.002) loss 1.1239 (0.7886) ce_loss 0.8804 (0.4360) teacher_loss 0.7932 (0.3786) loss_zs_kd 0.0948 (0.1020) loss_oracle 0.2833 (0.3590) acc 75.0000 (84.1518) kd_loss 1.0086 (1.0434) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [160/162] time 0.090 (0.098) data 0.000 (0.002) loss 0.7817 (0.7906) ce_loss 0.3772 (0.4365) teacher_loss 0.3790 (0.3798) loss_zs_kd 0.1016 (0.1021) loss_oracle 0.3520 (0.3598) acc 90.6250 (84.1992) kd_loss 1.0623 (1.0426) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,965
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 89.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,646
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 75.1%
******* Domain s best val acc:      88.2%, epoch: 31 *******
******* Domain s best val test acc: 79.2%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 4 *******
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:20:00

Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'sun']
Target     ['pascal']
# classes  5
# train_x  5,147
# val      2,206
# test     3,376
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/160] time 0.094 (0.139) data 0.000 (0.017) loss 1.0081 (0.8793) ce_loss 0.8037 (0.6804) teacher_loss 0.8000 (0.6797) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.2079 (0.1996) acc 71.8750 (75.3125) kd_loss 0.9876 (0.9425) lr 1.0000e-05 eta 0:18:28
epoch [1/50] batch [40/160] time 0.083 (0.128) data 0.000 (0.009) loss 0.8898 (0.8704) ce_loss 0.6816 (0.6687) teacher_loss 0.6802 (0.6690) loss_zs_kd 0.0011 (0.0005) loss_oracle 0.2090 (0.2011) acc 75.0000 (75.3125) kd_loss 0.9908 (0.9498) lr 1.0000e-05 eta 0:17:00
epoch [1/50] batch [60/160] time 0.080 (0.123) data 0.000 (0.006) loss 0.7389 (0.8977) ce_loss 0.5381 (0.6966) teacher_loss 0.5388 (0.6969) loss_zs_kd 0.0023 (0.0009) loss_oracle 0.1989 (0.2004) acc 78.1250 (74.9479) kd_loss 0.9340 (0.9460) lr 1.0000e-05 eta 0:16:17
epoch [1/50] batch [80/160] time 0.078 (0.115) data 0.000 (0.005) loss 1.1224 (0.9087) ce_loss 0.9204 (0.7072) teacher_loss 0.9225 (0.7074) loss_zs_kd 0.0032 (0.0015) loss_oracle 0.1983 (0.2006) acc 75.0000 (74.1406) kd_loss 0.9435 (0.9470) lr 1.0000e-05 eta 0:15:12
epoch [1/50] batch [100/160] time 0.091 (0.114) data 0.000 (0.004) loss 0.8160 (0.9059) ce_loss 0.6265 (0.7039) teacher_loss 0.6266 (0.7042) loss_zs_kd 0.0043 (0.0020) loss_oracle 0.1873 (0.2008) acc 81.2500 (74.3438) kd_loss 0.8785 (0.9479) lr 1.0000e-05 eta 0:14:57
epoch [1/50] batch [120/160] time 0.090 (0.111) data 0.000 (0.003) loss 0.9118 (0.8965) ce_loss 0.7153 (0.6942) teacher_loss 0.7151 (0.6945) loss_zs_kd 0.0063 (0.0026) loss_oracle 0.1936 (0.2007) acc 71.8750 (74.6875) kd_loss 0.9160 (0.9475) lr 1.0000e-05 eta 0:14:33
epoch [1/50] batch [140/160] time 0.089 (0.109) data 0.000 (0.003) loss 0.7221 (0.8943) ce_loss 0.5088 (0.6909) teacher_loss 0.5089 (0.6910) loss_zs_kd 0.0067 (0.0033) loss_oracle 0.2098 (0.2018) acc 87.5000 (74.7545) kd_loss 0.9922 (0.9525) lr 1.0000e-05 eta 0:14:15
epoch [1/50] batch [160/160] time 0.126 (0.108) data 0.000 (0.002) loss 1.1793 (0.8984) ce_loss 0.9785 (0.6945) teacher_loss 0.9798 (0.6947) loss_zs_kd 0.0104 (0.0039) loss_oracle 0.1943 (0.2018) acc 65.6250 (74.6680) kd_loss 0.9127 (0.9527) lr 2.0000e-03 eta 0:14:05
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,727
* accuracy: 78.3%
* error: 21.7%
* macro_f1: 80.2%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,925
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.3%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      78.3%, epoch: 1 *******
******* Domain p best val test acc: 86.6%, epoch: 1 *******
******* Domain p best test acc:     86.6%, epoch: 1 *******
[TensorBoard] Initialized writer in: icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/ana
epoch [2/50] batch [20/160] time 0.114 (0.138) data 0.000 (0.020) loss 0.9408 (0.9336) ce_loss 0.7046 (0.6272) teacher_loss 0.6661 (0.6280) loss_zs_kd 0.0436 (0.0652) loss_oracle 0.2529 (0.2730) acc 68.7500 (76.5625) kd_loss 1.0483 (0.9770) lr 2.0000e-03 eta 0:17:59
epoch [2/50] batch [40/160] time 0.116 (0.123) data 0.000 (0.010) loss 1.0451 (0.9076) ce_loss 0.8008 (0.6169) teacher_loss 0.7007 (0.6069) loss_zs_kd 0.0668 (0.0634) loss_oracle 0.3109 (0.2690) acc 75.0000 (77.2656) kd_loss 1.0044 (0.9926) lr 2.0000e-03 eta 0:15:58
epoch [2/50] batch [60/160] time 0.085 (0.119) data 0.000 (0.007) loss 0.7864 (0.9252) ce_loss 0.4802 (0.6193) teacher_loss 0.3805 (0.6069) loss_zs_kd 0.1112 (0.0660) loss_oracle 0.3504 (0.2853) acc 84.3750 (77.7083) kd_loss 1.0175 (0.9996) lr 2.0000e-03 eta 0:15:24
epoch [2/50] batch [80/160] time 0.117 (0.117) data 0.000 (0.005) loss 0.8238 (0.9164) ce_loss 0.4309 (0.6124) teacher_loss 0.4306 (0.5840) loss_zs_kd 0.0551 (0.0768) loss_oracle 0.3656 (0.2940) acc 87.5000 (77.8516) kd_loss 1.0548 (1.0033) lr 2.0000e-03 eta 0:15:08
epoch [2/50] batch [100/160] time 0.131 (0.117) data 0.001 (0.004) loss 0.7438 (0.9305) ce_loss 0.3474 (0.6074) teacher_loss 0.3512 (0.5817) loss_zs_kd 0.1396 (0.0769) loss_oracle 0.3229 (0.3103) acc 93.7500 (77.8438) kd_loss 0.9360 (1.0001) lr 2.0000e-03 eta 0:15:09
epoch [2/50] batch [120/160] time 0.091 (0.116) data 0.000 (0.004) loss 0.8360 (0.9395) ce_loss 0.5566 (0.6086) teacher_loss 0.5604 (0.5869) loss_zs_kd 0.0570 (0.0781) loss_oracle 0.2471 (0.3135) acc 84.3750 (77.8125) kd_loss 0.9228 (0.9976) lr 2.0000e-03 eta 0:14:51
epoch [2/50] batch [140/160] time 0.094 (0.115) data 0.000 (0.003) loss 0.5858 (0.9244) ce_loss 0.2988 (0.5930) teacher_loss 0.2340 (0.5730) loss_zs_kd 0.0826 (0.0785) loss_oracle 0.3105 (0.3122) acc 87.5000 (78.2143) kd_loss 0.9974 (0.9975) lr 2.0000e-03 eta 0:14:48
epoch [2/50] batch [160/160] time 0.097 (0.114) data 0.000 (0.003) loss 0.8837 (0.9161) ce_loss 0.5483 (0.5836) teacher_loss 0.5428 (0.5640) loss_zs_kd 0.0798 (0.0793) loss_oracle 0.3010 (0.3125) acc 81.2500 (78.3984) kd_loss 0.9036 (0.9944) lr 1.9980e-03 eta 0:14:32
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,815
* accuracy: 82.3%
* error: 17.7%
* macro_f1: 84.0%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,965
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.3%, epoch: 2 *******
******* Domain p best val test acc: 87.8%, epoch: 2 *******
******* Domain p best test acc:     87.8%, epoch: 2 *******
epoch [3/50] batch [20/160] time 0.139 (0.125) data 0.000 (0.015) loss 0.8118 (0.8877) ce_loss 0.5049 (0.5296) teacher_loss 0.4666 (0.5211) loss_zs_kd 0.1066 (0.0907) loss_oracle 0.2918 (0.3212) acc 84.3750 (80.4688) kd_loss 0.9444 (0.9917) lr 1.9980e-03 eta 0:16:00
epoch [3/50] batch [40/160] time 0.143 (0.127) data 0.000 (0.008) loss 0.7142 (0.8919) ce_loss 0.4399 (0.5444) teacher_loss 0.3648 (0.5335) loss_zs_kd 0.0564 (0.0872) loss_oracle 0.3212 (0.3148) acc 81.2500 (80.3906) kd_loss 0.9724 (0.9867) lr 1.9980e-03 eta 0:16:13
epoch [3/50] batch [60/160] time 0.135 (0.121) data 0.001 (0.005) loss 1.0955 (0.9034) ce_loss 0.6519 (0.5608) teacher_loss 0.7061 (0.5411) loss_zs_kd 0.0969 (0.0891) loss_oracle 0.3409 (0.3178) acc 81.2500 (79.5833) kd_loss 0.9801 (0.9913) lr 1.9980e-03 eta 0:15:24
epoch [3/50] batch [80/160] time 0.088 (0.118) data 0.000 (0.004) loss 1.0386 (0.9171) ce_loss 0.5811 (0.5624) teacher_loss 0.5701 (0.5367) loss_zs_kd 0.1263 (0.0941) loss_oracle 0.4053 (0.3334) acc 81.2500 (79.1797) kd_loss 1.0100 (0.9932) lr 1.9980e-03 eta 0:14:57
epoch [3/50] batch [100/160] time 0.092 (0.115) data 0.000 (0.003) loss 0.8855 (0.9137) ce_loss 0.4292 (0.5421) teacher_loss 0.3876 (0.5140) loss_zs_kd 0.0755 (0.0949) loss_oracle 0.4602 (0.3523) acc 90.6250 (79.8438) kd_loss 0.9850 (0.9937) lr 1.9980e-03 eta 0:14:33
epoch [3/50] batch [120/160] time 0.108 (0.113) data 0.001 (0.003) loss 0.8683 (0.9121) ce_loss 0.4424 (0.5380) teacher_loss 0.3685 (0.5065) loss_zs_kd 0.1205 (0.0965) loss_oracle 0.4396 (0.3573) acc 87.5000 (79.8698) kd_loss 1.0417 (0.9971) lr 1.9980e-03 eta 0:14:17
epoch [3/50] batch [140/160] time 0.124 (0.113) data 0.001 (0.002) loss 0.7727 (0.9108) ce_loss 0.3997 (0.5371) teacher_loss 0.3477 (0.5021) loss_zs_kd 0.1124 (0.0972) loss_oracle 0.3688 (0.3601) acc 84.3750 (79.6875) kd_loss 1.0298 (0.9959) lr 1.9980e-03 eta 0:14:10
epoch [3/50] batch [160/160] time 0.095 (0.111) data 0.000 (0.002) loss 1.4776 (0.9159) ce_loss 1.0879 (0.5423) teacher_loss 1.0688 (0.5059) loss_zs_kd 0.1128 (0.0984) loss_oracle 0.3523 (0.3608) acc 62.5000 (79.6289) kd_loss 0.9850 (0.9954) lr 1.9921e-03 eta 0:13:56
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,822
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 84.1%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,935
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.1%
******* Domain p best val acc:      82.6%, epoch: 3 *******
******* Domain p best val test acc: 86.9%, epoch: 3 *******
******* Domain p best test acc:     87.8%, epoch: 2 *******
epoch [4/50] batch [20/160] time 0.137 (0.138) data 0.000 (0.018) loss 0.8275 (0.9350) ce_loss 0.4487 (0.5641) teacher_loss 0.4027 (0.5038) loss_zs_kd 0.0781 (0.1075) loss_oracle 0.3858 (0.3774) acc 81.2500 (79.2188) kd_loss 1.0312 (0.9898) lr 1.9921e-03 eta 0:17:15
epoch [4/50] batch [40/160] time 0.087 (0.122) data 0.000 (0.009) loss 0.7955 (0.8776) ce_loss 0.4004 (0.5054) teacher_loss 0.3529 (0.4666) loss_zs_kd 0.1046 (0.1019) loss_oracle 0.3903 (0.3600) acc 87.5000 (81.5625) kd_loss 1.0658 (0.9973) lr 1.9921e-03 eta 0:15:12
epoch [4/50] batch [60/160] time 0.113 (0.114) data 0.000 (0.006) loss 0.8286 (0.8736) ce_loss 0.4895 (0.5076) teacher_loss 0.4137 (0.4712) loss_zs_kd 0.1401 (0.1001) loss_oracle 0.3449 (0.3523) acc 84.3750 (81.6146) kd_loss 0.9744 (0.9932) lr 1.9921e-03 eta 0:14:13
epoch [4/50] batch [80/160] time 0.114 (0.112) data 0.000 (0.005) loss 0.9304 (0.8855) ce_loss 0.6182 (0.5252) teacher_loss 0.5089 (0.4820) loss_zs_kd 0.0904 (0.1040) loss_oracle 0.3763 (0.3514) acc 75.0000 (80.8594) kd_loss 1.0696 (0.9984) lr 1.9921e-03 eta 0:13:55
epoch [4/50] batch [100/160] time 0.097 (0.110) data 0.000 (0.004) loss 0.9492 (0.9053) ce_loss 0.5820 (0.5397) teacher_loss 0.5377 (0.4965) loss_zs_kd 0.0577 (0.1011) loss_oracle 0.3827 (0.3583) acc 78.1250 (80.1875) kd_loss 1.0290 (1.0006) lr 1.9921e-03 eta 0:13:37
epoch [4/50] batch [120/160] time 0.074 (0.107) data 0.000 (0.003) loss 1.1028 (0.9100) ce_loss 0.7549 (0.5420) teacher_loss 0.7315 (0.4999) loss_zs_kd 0.0785 (0.0981) loss_oracle 0.3321 (0.3611) acc 78.1250 (80.2344) kd_loss 1.0727 (1.0035) lr 1.9921e-03 eta 0:13:15
epoch [4/50] batch [140/160] time 0.120 (0.107) data 0.000 (0.003) loss 0.9504 (0.9107) ce_loss 0.6006 (0.5429) teacher_loss 0.5718 (0.5007) loss_zs_kd 0.0556 (0.0983) loss_oracle 0.3508 (0.3609) acc 78.1250 (80.1562) kd_loss 1.0114 (1.0015) lr 1.9921e-03 eta 0:13:13
epoch [4/50] batch [160/160] time 0.075 (0.105) data 0.000 (0.003) loss 0.7020 (0.9030) ce_loss 0.2959 (0.5387) teacher_loss 0.2927 (0.4975) loss_zs_kd 0.0844 (0.0979) loss_oracle 0.3671 (0.3566) acc 93.7500 (80.4102) kd_loss 1.0498 (1.0011) lr 1.9823e-03 eta 0:12:54
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,832
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,968
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.0%, epoch: 4 *******
******* Domain p best val test acc: 87.9%, epoch: 4 *******
******* Domain p best test acc:     87.9%, epoch: 4 *******
epoch [5/50] batch [20/160] time 0.077 (0.110) data 0.000 (0.013) loss 0.7541 (0.9066) ce_loss 0.3245 (0.5548) teacher_loss 0.3324 (0.5196) loss_zs_kd 0.0839 (0.0890) loss_oracle 0.3798 (0.3424) acc 93.7500 (81.8750) kd_loss 0.9688 (0.9912) lr 1.9823e-03 eta 0:13:26
epoch [5/50] batch [40/160] time 0.103 (0.103) data 0.000 (0.007) loss 0.7417 (0.8820) ce_loss 0.3167 (0.5462) teacher_loss 0.3266 (0.5073) loss_zs_kd 0.0858 (0.0909) loss_oracle 0.3722 (0.3293) acc 93.7500 (81.3281) kd_loss 0.9948 (0.9869) lr 1.9823e-03 eta 0:12:33
epoch [5/50] batch [60/160] time 0.080 (0.101) data 0.000 (0.005) loss 1.1145 (0.8845) ce_loss 0.7988 (0.5426) teacher_loss 0.7452 (0.5100) loss_zs_kd 0.0996 (0.0963) loss_oracle 0.3195 (0.3264) acc 75.0000 (80.7812) kd_loss 0.9751 (0.9832) lr 1.9823e-03 eta 0:12:19
epoch [5/50] batch [80/160] time 0.175 (0.104) data 0.000 (0.003) loss 1.0035 (0.8975) ce_loss 0.5703 (0.5406) teacher_loss 0.5395 (0.5115) loss_zs_kd 0.0997 (0.1005) loss_oracle 0.4142 (0.3357) acc 84.3750 (81.2891) kd_loss 1.0251 (0.9819) lr 1.9823e-03 eta 0:12:36
epoch [5/50] batch [100/160] time 0.079 (0.109) data 0.000 (0.003) loss 0.8611 (0.8915) ce_loss 0.5039 (0.5265) teacher_loss 0.4461 (0.5012) loss_zs_kd 0.0672 (0.0971) loss_oracle 0.3814 (0.3418) acc 81.2500 (81.3125) kd_loss 1.0270 (0.9868) lr 1.9823e-03 eta 0:13:10
epoch [5/50] batch [120/160] time 0.135 (0.112) data 0.000 (0.002) loss 0.8279 (0.8897) ce_loss 0.5474 (0.5272) teacher_loss 0.4404 (0.4993) loss_zs_kd 0.1068 (0.0996) loss_oracle 0.3341 (0.3405) acc 75.0000 (81.0156) kd_loss 0.9768 (0.9906) lr 1.9823e-03 eta 0:13:32
epoch [5/50] batch [140/160] time 0.085 (0.110) data 0.000 (0.002) loss 1.2760 (0.8905) ce_loss 0.8428 (0.5273) teacher_loss 0.8037 (0.4921) loss_zs_kd 0.1375 (0.1030) loss_oracle 0.4035 (0.3469) acc 78.1250 (80.9375) kd_loss 1.0460 (0.9932) lr 1.9823e-03 eta 0:13:12
epoch [5/50] batch [160/160] time 0.095 (0.107) data 0.000 (0.002) loss 1.1528 (0.8917) ce_loss 0.8633 (0.5249) teacher_loss 0.6963 (0.4885) loss_zs_kd 0.0856 (0.1036) loss_oracle 0.4137 (0.3514) acc 75.0000 (81.0352) kd_loss 0.9731 (0.9925) lr 1.9686e-03 eta 0:12:51
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,823
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,979
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 88.9%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.0%, epoch: 4 *******
******* Domain p best val test acc: 87.9%, epoch: 4 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [6/50] batch [20/160] time 0.088 (0.108) data 0.000 (0.014) loss 0.8085 (0.9021) ce_loss 0.4495 (0.5313) teacher_loss 0.3775 (0.4854) loss_zs_kd 0.1104 (0.0972) loss_oracle 0.3758 (0.3682) acc 81.2500 (79.6875) kd_loss 1.0470 (0.9989) lr 1.9686e-03 eta 0:12:52
epoch [6/50] batch [40/160] time 0.082 (0.099) data 0.000 (0.007) loss 0.7716 (0.8928) ce_loss 0.4045 (0.5150) teacher_loss 0.4187 (0.4737) loss_zs_kd 0.0873 (0.1086) loss_oracle 0.3093 (0.3648) acc 78.1250 (80.1562) kd_loss 1.0133 (0.9988) lr 1.9686e-03 eta 0:11:49
epoch [6/50] batch [60/160] time 0.075 (0.097) data 0.001 (0.005) loss 0.8866 (0.8783) ce_loss 0.4426 (0.5122) teacher_loss 0.4359 (0.4772) loss_zs_kd 0.1180 (0.1037) loss_oracle 0.3918 (0.3492) acc 81.2500 (80.9375) kd_loss 1.0172 (0.9955) lr 1.9686e-03 eta 0:11:33
epoch [6/50] batch [80/160] time 0.080 (0.100) data 0.000 (0.004) loss 0.8804 (0.8930) ce_loss 0.4639 (0.5198) teacher_loss 0.4917 (0.4911) loss_zs_kd 0.1248 (0.1045) loss_oracle 0.3263 (0.3497) acc 81.2500 (80.8594) kd_loss 1.0068 (0.9915) lr 1.9686e-03 eta 0:11:50
epoch [6/50] batch [100/160] time 0.115 (0.103) data 0.000 (0.003) loss 0.9281 (0.8852) ce_loss 0.5854 (0.5155) teacher_loss 0.5814 (0.4915) loss_zs_kd 0.0707 (0.1025) loss_oracle 0.3114 (0.3425) acc 81.2500 (80.9375) kd_loss 1.0101 (0.9884) lr 1.9686e-03 eta 0:12:10
epoch [6/50] batch [120/160] time 0.104 (0.104) data 0.000 (0.003) loss 1.0353 (0.8839) ce_loss 0.6372 (0.5145) teacher_loss 0.6269 (0.4924) loss_zs_kd 0.1448 (0.1044) loss_oracle 0.3360 (0.3393) acc 75.0000 (81.0677) kd_loss 0.9739 (0.9879) lr 1.9686e-03 eta 0:12:16
epoch [6/50] batch [140/160] time 0.117 (0.104) data 0.000 (0.002) loss 0.8844 (0.8759) ce_loss 0.4614 (0.5050) teacher_loss 0.4719 (0.4853) loss_zs_kd 0.0779 (0.1043) loss_oracle 0.3736 (0.3384) acc 71.8750 (81.4732) kd_loss 0.9894 (0.9869) lr 1.9686e-03 eta 0:12:17
epoch [6/50] batch [160/160] time 0.087 (0.104) data 0.000 (0.002) loss 1.0293 (0.8893) ce_loss 0.6426 (0.5135) teacher_loss 0.6115 (0.4950) loss_zs_kd 0.1130 (0.1064) loss_oracle 0.3614 (0.3411) acc 81.2500 (81.1719) kd_loss 0.8909 (0.9850) lr 1.9511e-03 eta 0:12:10
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,830
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,972
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 88.9%
******* Domain p best val acc:      83.0%, epoch: 4 *******
******* Domain p best val test acc: 87.9%, epoch: 4 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [7/50] batch [20/160] time 0.078 (0.121) data 0.000 (0.015) loss 1.0411 (0.8607) ce_loss 0.6870 (0.4738) teacher_loss 0.6884 (0.4785) loss_zs_kd 0.0847 (0.0867) loss_oracle 0.3103 (0.3388) acc 65.6250 (83.5938) kd_loss 1.0261 (0.9835) lr 1.9511e-03 eta 0:14:12
epoch [7/50] batch [40/160] time 0.087 (0.108) data 0.000 (0.008) loss 0.9580 (0.8890) ce_loss 0.5332 (0.5091) teacher_loss 0.5214 (0.5021) loss_zs_kd 0.0991 (0.0969) loss_oracle 0.3870 (0.3384) acc 84.3750 (82.0312) kd_loss 1.0168 (0.9782) lr 1.9511e-03 eta 0:12:35
epoch [7/50] batch [60/160] time 0.106 (0.102) data 0.001 (0.005) loss 0.9564 (0.8878) ce_loss 0.5977 (0.5045) teacher_loss 0.5460 (0.4987) loss_zs_kd 0.1097 (0.0990) loss_oracle 0.3555 (0.3396) acc 75.0000 (82.2917) kd_loss 1.0304 (0.9762) lr 1.9511e-03 eta 0:11:48
epoch [7/50] batch [80/160] time 0.100 (0.104) data 0.000 (0.004) loss 1.0025 (0.8886) ce_loss 0.5898 (0.5112) teacher_loss 0.5461 (0.4980) loss_zs_kd 0.1384 (0.1034) loss_oracle 0.3872 (0.3389) acc 84.3750 (81.7578) kd_loss 1.0163 (0.9760) lr 1.9511e-03 eta 0:12:04
epoch [7/50] batch [100/160] time 0.116 (0.105) data 0.000 (0.003) loss 0.7938 (0.8936) ce_loss 0.4146 (0.5141) teacher_loss 0.4021 (0.5024) loss_zs_kd 0.1054 (0.1054) loss_oracle 0.3390 (0.3384) acc 81.2500 (81.4688) kd_loss 0.9260 (0.9780) lr 1.9511e-03 eta 0:12:09
epoch [7/50] batch [120/160] time 0.088 (0.106) data 0.000 (0.003) loss 0.8881 (0.9025) ce_loss 0.3757 (0.5186) teacher_loss 0.4169 (0.5072) loss_zs_kd 0.0692 (0.1070) loss_oracle 0.4367 (0.3417) acc 87.5000 (81.3281) kd_loss 1.0073 (0.9802) lr 1.9511e-03 eta 0:12:11
epoch [7/50] batch [140/160] time 0.085 (0.105) data 0.000 (0.002) loss 0.8326 (0.8946) ce_loss 0.4539 (0.5093) teacher_loss 0.4650 (0.4993) loss_zs_kd 0.0854 (0.1054) loss_oracle 0.3249 (0.3427) acc 84.3750 (81.4955) kd_loss 0.9950 (0.9791) lr 1.9511e-03 eta 0:12:01
epoch [7/50] batch [160/160] time 0.088 (0.103) data 0.000 (0.002) loss 1.0128 (0.8964) ce_loss 0.7090 (0.5130) teacher_loss 0.6147 (0.5023) loss_zs_kd 0.1382 (0.1056) loss_oracle 0.3291 (0.3413) acc 75.0000 (81.4062) kd_loss 1.0509 (0.9813) lr 1.9298e-03 eta 0:11:46
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,832
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,964
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.7%
******* Domain p best val acc:      83.0%, epoch: 4 *******
******* Domain p best val test acc: 87.9%, epoch: 4 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [8/50] batch [20/160] time 0.173 (0.135) data 0.000 (0.013) loss 0.9964 (0.8981) ce_loss 0.5723 (0.5313) teacher_loss 0.5939 (0.5249) loss_zs_kd 0.1059 (0.0995) loss_oracle 0.3495 (0.3235) acc 87.5000 (81.4062) kd_loss 0.9736 (0.9826) lr 1.9298e-03 eta 0:15:28
epoch [8/50] batch [40/160] time 0.081 (0.121) data 0.000 (0.007) loss 1.0370 (0.8843) ce_loss 0.6748 (0.5221) teacher_loss 0.6516 (0.5111) loss_zs_kd 0.1053 (0.0988) loss_oracle 0.3327 (0.3237) acc 65.6250 (80.8594) kd_loss 0.9964 (0.9799) lr 1.9298e-03 eta 0:13:45
epoch [8/50] batch [60/160] time 0.096 (0.113) data 0.001 (0.005) loss 0.9295 (0.8779) ce_loss 0.5293 (0.5158) teacher_loss 0.5097 (0.5013) loss_zs_kd 0.1133 (0.1014) loss_oracle 0.3631 (0.3259) acc 75.0000 (80.6250) kd_loss 0.9548 (0.9808) lr 1.9298e-03 eta 0:12:52
epoch [8/50] batch [80/160] time 0.101 (0.109) data 0.000 (0.003) loss 0.6325 (0.8650) ce_loss 0.2878 (0.5042) teacher_loss 0.2537 (0.4858) loss_zs_kd 0.1199 (0.1019) loss_oracle 0.3188 (0.3283) acc 90.6250 (81.0547) kd_loss 0.9195 (0.9786) lr 1.9298e-03 eta 0:12:22
epoch [8/50] batch [100/160] time 0.105 (0.105) data 0.000 (0.003) loss 0.8593 (0.8740) ce_loss 0.4900 (0.5040) teacher_loss 0.4668 (0.4902) loss_zs_kd 0.1085 (0.1024) loss_oracle 0.3382 (0.3326) acc 84.3750 (81.2812) kd_loss 0.9430 (0.9806) lr 1.9298e-03 eta 0:11:53
epoch [8/50] batch [120/160] time 0.099 (0.102) data 0.000 (0.002) loss 0.7833 (0.8780) ce_loss 0.3953 (0.5027) teacher_loss 0.3413 (0.4864) loss_zs_kd 0.1749 (0.1053) loss_oracle 0.3546 (0.3389) acc 93.7500 (81.5104) kd_loss 1.0046 (0.9841) lr 1.9298e-03 eta 0:11:31
epoch [8/50] batch [140/160] time 0.100 (0.100) data 0.000 (0.002) loss 0.7489 (0.8785) ce_loss 0.4089 (0.5037) teacher_loss 0.3983 (0.4880) loss_zs_kd 0.0814 (0.1067) loss_oracle 0.3099 (0.3372) acc 84.3750 (81.3393) kd_loss 0.9781 (0.9863) lr 1.9298e-03 eta 0:11:13
epoch [8/50] batch [160/160] time 0.077 (0.099) data 0.000 (0.002) loss 0.7691 (0.8743) ce_loss 0.4521 (0.5020) teacher_loss 0.4099 (0.4862) loss_zs_kd 0.0858 (0.1084) loss_oracle 0.3162 (0.3339) acc 68.7500 (81.2695) kd_loss 0.9534 (0.9854) lr 1.9048e-03 eta 0:11:04
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,848
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 84.8%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,971
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 89.0%
******* Domain p best val acc:      83.8%, epoch: 8 *******
******* Domain p best val test acc: 88.0%, epoch: 8 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [9/50] batch [20/160] time 0.132 (0.135) data 0.000 (0.015) loss 0.6809 (0.8475) ce_loss 0.3381 (0.4652) teacher_loss 0.3298 (0.4605) loss_zs_kd 0.0938 (0.1179) loss_oracle 0.3041 (0.3281) acc 84.3750 (82.0312) kd_loss 1.0263 (1.0013) lr 1.9048e-03 eta 0:15:01
epoch [9/50] batch [40/160] time 0.103 (0.122) data 0.000 (0.008) loss 0.8802 (0.8513) ce_loss 0.5034 (0.4764) teacher_loss 0.4976 (0.4734) loss_zs_kd 0.1107 (0.1101) loss_oracle 0.3273 (0.3229) acc 84.3750 (82.8125) kd_loss 0.8493 (0.9781) lr 1.9048e-03 eta 0:13:37
epoch [9/50] batch [60/160] time 0.116 (0.119) data 0.001 (0.005) loss 0.9313 (0.8896) ce_loss 0.4668 (0.5031) teacher_loss 0.4959 (0.4994) loss_zs_kd 0.1001 (0.1111) loss_oracle 0.3853 (0.3347) acc 84.3750 (81.7188) kd_loss 0.9978 (0.9775) lr 1.9048e-03 eta 0:13:15
epoch [9/50] batch [80/160] time 0.124 (0.118) data 0.000 (0.004) loss 0.7671 (0.8935) ce_loss 0.3782 (0.4993) teacher_loss 0.3832 (0.4962) loss_zs_kd 0.1166 (0.1124) loss_oracle 0.3256 (0.3411) acc 90.6250 (81.6797) kd_loss 1.0231 (0.9800) lr 1.9048e-03 eta 0:13:06
epoch [9/50] batch [100/160] time 0.097 (0.117) data 0.000 (0.003) loss 0.8145 (0.8825) ce_loss 0.4331 (0.4911) teacher_loss 0.4034 (0.4879) loss_zs_kd 0.0884 (0.1112) loss_oracle 0.3668 (0.3390) acc 93.7500 (82.1250) kd_loss 0.9915 (0.9819) lr 1.9048e-03 eta 0:12:54
epoch [9/50] batch [120/160] time 0.119 (0.115) data 0.000 (0.003) loss 1.0275 (0.8851) ce_loss 0.6611 (0.4987) teacher_loss 0.6342 (0.4932) loss_zs_kd 0.1120 (0.1098) loss_oracle 0.3373 (0.3370) acc 65.6250 (81.7188) kd_loss 1.0512 (0.9872) lr 1.9048e-03 eta 0:12:40
epoch [9/50] batch [140/160] time 0.095 (0.114) data 0.000 (0.002) loss 0.8470 (0.8773) ce_loss 0.4832 (0.4940) teacher_loss 0.4450 (0.4887) loss_zs_kd 0.1822 (0.1127) loss_oracle 0.3109 (0.3322) acc 87.5000 (81.5848) kd_loss 1.0835 (0.9940) lr 1.9048e-03 eta 0:12:28
epoch [9/50] batch [160/160] time 0.077 (0.111) data 0.000 (0.002) loss 0.7667 (0.8729) ce_loss 0.4126 (0.4913) teacher_loss 0.4526 (0.4856) loss_zs_kd 0.0910 (0.1134) loss_oracle 0.2687 (0.3306) acc 81.2500 (81.6602) kd_loss 0.9685 (0.9963) lr 1.8763e-03 eta 0:12:05
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,844
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,963
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.9%
******* Domain p best val acc:      83.8%, epoch: 8 *******
******* Domain p best val test acc: 88.0%, epoch: 8 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [10/50] batch [20/160] time 0.138 (0.135) data 0.000 (0.015) loss 0.7159 (0.8360) ce_loss 0.3386 (0.4929) teacher_loss 0.3544 (0.4856) loss_zs_kd 0.0750 (0.0963) loss_oracle 0.3240 (0.3022) acc 87.5000 (82.5000) kd_loss 1.0089 (1.0286) lr 1.8763e-03 eta 0:14:40
epoch [10/50] batch [40/160] time 0.089 (0.118) data 0.000 (0.008) loss 0.7837 (0.8297) ce_loss 0.4409 (0.4832) teacher_loss 0.3816 (0.4709) loss_zs_kd 0.0995 (0.0998) loss_oracle 0.3523 (0.3089) acc 84.3750 (82.4219) kd_loss 0.9685 (1.0112) lr 1.8763e-03 eta 0:12:48
epoch [10/50] batch [60/160] time 0.130 (0.115) data 0.001 (0.005) loss 0.7546 (0.8459) ce_loss 0.4082 (0.4969) teacher_loss 0.3806 (0.4846) loss_zs_kd 0.1234 (0.1044) loss_oracle 0.3123 (0.3091) acc 87.5000 (81.6146) kd_loss 1.0819 (1.0102) lr 1.8763e-03 eta 0:12:28
epoch [10/50] batch [80/160] time 0.141 (0.115) data 0.000 (0.004) loss 1.0400 (0.8498) ce_loss 0.6533 (0.5008) teacher_loss 0.7181 (0.4901) loss_zs_kd 0.1122 (0.1082) loss_oracle 0.2658 (0.3056) acc 81.2500 (81.3672) kd_loss 1.0335 (1.0169) lr 1.8763e-03 eta 0:12:22
epoch [10/50] batch [100/160] time 0.074 (0.122) data 0.000 (0.003) loss 0.9050 (0.8516) ce_loss 0.4919 (0.4985) teacher_loss 0.4953 (0.4869) loss_zs_kd 0.1616 (0.1108) loss_oracle 0.3289 (0.3093) acc 78.1250 (81.6875) kd_loss 0.9464 (1.0112) lr 1.8763e-03 eta 0:13:06
epoch [10/50] batch [120/160] time 0.162 (0.122) data 0.000 (0.003) loss 1.0402 (0.8534) ce_loss 0.7197 (0.5008) teacher_loss 0.6180 (0.4873) loss_zs_kd 0.2002 (0.1125) loss_oracle 0.3221 (0.3099) acc 62.5000 (81.4844) kd_loss 1.0575 (1.0132) lr 1.8763e-03 eta 0:13:08
epoch [10/50] batch [140/160] time 0.098 (0.118) data 0.000 (0.002) loss 0.8061 (0.8519) ce_loss 0.4033 (0.4952) teacher_loss 0.4017 (0.4806) loss_zs_kd 0.1086 (0.1152) loss_oracle 0.3501 (0.3137) acc 87.5000 (81.6295) kd_loss 1.0329 (1.0153) lr 1.8763e-03 eta 0:12:36
epoch [10/50] batch [160/160] time 0.091 (0.114) data 0.001 (0.002) loss 1.0153 (0.8647) ce_loss 0.6079 (0.5043) teacher_loss 0.6449 (0.4899) loss_zs_kd 0.1185 (0.1179) loss_oracle 0.3111 (0.3159) acc 75.0000 (81.2109) kd_loss 0.9774 (1.0172) lr 1.8443e-03 eta 0:12:07
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,854
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.1%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,940
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 88.4%
******* Domain p best val acc:      84.0%, epoch: 10 *******
******* Domain p best val test acc: 87.1%, epoch: 10 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [11/50] batch [20/160] time 0.104 (0.133) data 0.000 (0.018) loss 0.7006 (0.8559) ce_loss 0.3386 (0.4794) teacher_loss 0.2921 (0.4560) loss_zs_kd 0.1190 (0.1069) loss_oracle 0.3490 (0.3465) acc 87.5000 (82.5000) kd_loss 1.0349 (1.0062) lr 1.8443e-03 eta 0:14:08
epoch [11/50] batch [40/160] time 0.134 (0.123) data 0.000 (0.009) loss 0.6503 (0.8545) ce_loss 0.3298 (0.4928) teacher_loss 0.3090 (0.4625) loss_zs_kd 0.1021 (0.1075) loss_oracle 0.2902 (0.3383) acc 93.7500 (82.2656) kd_loss 1.0104 (1.0105) lr 1.8443e-03 eta 0:13:05
epoch [11/50] batch [60/160] time 0.087 (0.119) data 0.000 (0.006) loss 0.8037 (0.8691) ce_loss 0.4404 (0.5006) teacher_loss 0.4414 (0.4762) loss_zs_kd 0.0999 (0.1075) loss_oracle 0.3123 (0.3391) acc 84.3750 (82.3438) kd_loss 1.0776 (1.0053) lr 1.8443e-03 eta 0:12:36
epoch [11/50] batch [80/160] time 0.061 (0.117) data 0.000 (0.005) loss 0.9390 (0.8756) ce_loss 0.5200 (0.5051) teacher_loss 0.5097 (0.4857) loss_zs_kd 0.1204 (0.1093) loss_oracle 0.3690 (0.3352) acc 84.3750 (81.9141) kd_loss 1.0600 (1.0019) lr 1.8443e-03 eta 0:12:20
epoch [11/50] batch [100/160] time 0.082 (0.113) data 0.000 (0.004) loss 0.7880 (0.8590) ce_loss 0.4031 (0.4923) teacher_loss 0.4356 (0.4759) loss_zs_kd 0.1158 (0.1087) loss_oracle 0.2945 (0.3287) acc 81.2500 (82.2812) kd_loss 1.0108 (1.0128) lr 1.8443e-03 eta 0:11:52
epoch [11/50] batch [120/160] time 0.117 (0.112) data 0.000 (0.003) loss 0.9221 (0.8533) ce_loss 0.5220 (0.4914) teacher_loss 0.5231 (0.4746) loss_zs_kd 0.1154 (0.1107) loss_oracle 0.3413 (0.3232) acc 75.0000 (82.0833) kd_loss 0.9799 (1.0146) lr 1.8443e-03 eta 0:11:42
epoch [11/50] batch [140/160] time 0.069 (0.108) data 0.000 (0.003) loss 0.9125 (0.8531) ce_loss 0.4934 (0.4903) teacher_loss 0.4802 (0.4738) loss_zs_kd 0.1025 (0.1103) loss_oracle 0.3811 (0.3241) acc 75.0000 (82.0982) kd_loss 1.0232 (1.0100) lr 1.8443e-03 eta 0:11:16
epoch [11/50] batch [160/160] time 0.061 (0.105) data 0.000 (0.002) loss 0.7248 (0.8494) ce_loss 0.3616 (0.4875) teacher_loss 0.3503 (0.4712) loss_zs_kd 0.1269 (0.1097) loss_oracle 0.3111 (0.3233) acc 87.5000 (82.2461) kd_loss 1.1325 (1.0103) lr 1.8090e-03 eta 0:10:54
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,849
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,951
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.7%
******* Domain p best val acc:      84.0%, epoch: 10 *******
******* Domain p best val test acc: 87.1%, epoch: 10 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [12/50] batch [20/160] time 0.095 (0.127) data 0.001 (0.016) loss 0.7654 (0.8141) ce_loss 0.3845 (0.4543) teacher_loss 0.3561 (0.4383) loss_zs_kd 0.1106 (0.1155) loss_oracle 0.3540 (0.3181) acc 90.6250 (82.8125) kd_loss 0.9872 (1.0006) lr 1.8090e-03 eta 0:13:12
epoch [12/50] batch [40/160] time 0.117 (0.119) data 0.000 (0.008) loss 0.9280 (0.7968) ce_loss 0.4465 (0.4353) teacher_loss 0.5048 (0.4174) loss_zs_kd 0.1150 (0.1150) loss_oracle 0.3657 (0.3220) acc 84.3750 (84.5312) kd_loss 1.0237 (0.9915) lr 1.8090e-03 eta 0:12:18
epoch [12/50] batch [60/160] time 0.135 (0.118) data 0.000 (0.006) loss 0.8787 (0.8357) ce_loss 0.4575 (0.4674) teacher_loss 0.4989 (0.4505) loss_zs_kd 0.1212 (0.1192) loss_oracle 0.3192 (0.3256) acc 78.1250 (83.1771) kd_loss 0.9414 (0.9876) lr 1.8090e-03 eta 0:12:10
epoch [12/50] batch [80/160] time 0.131 (0.118) data 0.000 (0.004) loss 0.7716 (0.8454) ce_loss 0.3806 (0.4752) teacher_loss 0.3986 (0.4615) loss_zs_kd 0.0982 (0.1161) loss_oracle 0.3239 (0.3259) acc 84.3750 (82.6172) kd_loss 1.0907 (0.9914) lr 1.8090e-03 eta 0:12:04
epoch [12/50] batch [100/160] time 0.120 (0.116) data 0.000 (0.003) loss 0.7855 (0.8542) ce_loss 0.3503 (0.4795) teacher_loss 0.3548 (0.4663) loss_zs_kd 0.1068 (0.1156) loss_oracle 0.3773 (0.3301) acc 84.3750 (82.3438) kd_loss 0.9256 (0.9951) lr 1.8090e-03 eta 0:11:52
epoch [12/50] batch [120/160] time 0.118 (0.117) data 0.000 (0.003) loss 0.7764 (0.8569) ce_loss 0.4500 (0.4834) teacher_loss 0.4036 (0.4686) loss_zs_kd 0.0756 (0.1136) loss_oracle 0.3350 (0.3315) acc 81.2500 (82.0312) kd_loss 1.1430 (1.0053) lr 1.8090e-03 eta 0:11:53
epoch [12/50] batch [140/160] time 0.146 (0.115) data 0.000 (0.003) loss 0.7300 (0.8590) ce_loss 0.4177 (0.4861) teacher_loss 0.3177 (0.4694) loss_zs_kd 0.1080 (0.1133) loss_oracle 0.3583 (0.3330) acc 81.2500 (81.9420) kd_loss 1.0125 (1.0131) lr 1.8090e-03 eta 0:11:43
epoch [12/50] batch [160/160] time 0.164 (0.119) data 0.000 (0.002) loss 0.9524 (0.8642) ce_loss 0.6084 (0.4879) teacher_loss 0.5883 (0.4700) loss_zs_kd 0.1029 (0.1159) loss_oracle 0.3127 (0.3363) acc 75.0000 (81.7773) kd_loss 0.9563 (1.0112) lr 1.7705e-03 eta 0:12:04
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,854
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,951
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.7%
******* Domain p best val acc:      84.0%, epoch: 10 *******
******* Domain p best val test acc: 87.1%, epoch: 10 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [13/50] batch [20/160] time 0.139 (0.121) data 0.000 (0.014) loss 0.6928 (0.8772) ce_loss 0.2817 (0.4985) teacher_loss 0.3035 (0.4831) loss_zs_kd 0.0781 (0.1228) loss_oracle 0.3502 (0.3327) acc 93.7500 (80.1562) kd_loss 1.0708 (1.0119) lr 1.7705e-03 eta 0:12:11
epoch [13/50] batch [40/160] time 0.088 (0.112) data 0.000 (0.007) loss 0.8022 (0.8649) ce_loss 0.4265 (0.4931) teacher_loss 0.4236 (0.4785) loss_zs_kd 0.0872 (0.1223) loss_oracle 0.3350 (0.3252) acc 87.5000 (81.0156) kd_loss 0.9381 (1.0046) lr 1.7705e-03 eta 0:11:15
epoch [13/50] batch [60/160] time 0.100 (0.110) data 0.001 (0.005) loss 0.9290 (0.8530) ce_loss 0.6030 (0.4893) teacher_loss 0.5793 (0.4791) loss_zs_kd 0.0902 (0.1198) loss_oracle 0.3046 (0.3139) acc 84.3750 (81.6146) kd_loss 1.0594 (1.0139) lr 1.7705e-03 eta 0:11:00
epoch [13/50] batch [80/160] time 0.088 (0.108) data 0.001 (0.004) loss 0.6201 (0.8452) ce_loss 0.3391 (0.4892) teacher_loss 0.3149 (0.4788) loss_zs_kd 0.1362 (0.1204) loss_oracle 0.2371 (0.3062) acc 87.5000 (81.6016) kd_loss 1.0440 (1.0166) lr 1.7705e-03 eta 0:10:48
epoch [13/50] batch [100/160] time 0.098 (0.107) data 0.000 (0.003) loss 0.6454 (0.8433) ce_loss 0.3132 (0.4899) teacher_loss 0.2905 (0.4781) loss_zs_kd 0.0761 (0.1203) loss_oracle 0.3169 (0.3051) acc 90.6250 (81.5938) kd_loss 0.9516 (1.0249) lr 1.7705e-03 eta 0:10:42
epoch [13/50] batch [120/160] time 0.138 (0.107) data 0.000 (0.003) loss 0.7998 (0.8424) ce_loss 0.4424 (0.4894) teacher_loss 0.4305 (0.4771) loss_zs_kd 0.0842 (0.1183) loss_oracle 0.3272 (0.3061) acc 81.2500 (81.6927) kd_loss 1.0233 (1.0267) lr 1.7705e-03 eta 0:10:40
epoch [13/50] batch [140/160] time 0.089 (0.107) data 0.000 (0.002) loss 0.7987 (0.8418) ce_loss 0.4539 (0.4846) teacher_loss 0.4545 (0.4721) loss_zs_kd 0.0950 (0.1187) loss_oracle 0.2968 (0.3104) acc 78.1250 (81.9643) kd_loss 0.9855 (1.0277) lr 1.7705e-03 eta 0:10:36
epoch [13/50] batch [160/160] time 0.109 (0.107) data 0.000 (0.002) loss 0.9626 (0.8417) ce_loss 0.6021 (0.4842) teacher_loss 0.5581 (0.4713) loss_zs_kd 0.1027 (0.1165) loss_oracle 0.3532 (0.3122) acc 75.0000 (82.0898) kd_loss 1.0275 (1.0311) lr 1.7290e-03 eta 0:10:31
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,853
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,964
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 89.0%
******* Domain p best val acc:      84.0%, epoch: 10 *******
******* Domain p best val test acc: 87.1%, epoch: 10 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [14/50] batch [20/160] time 0.075 (0.118) data 0.000 (0.013) loss 0.7167 (0.8528) ce_loss 0.3708 (0.4841) teacher_loss 0.3121 (0.4663) loss_zs_kd 0.1199 (0.1118) loss_oracle 0.3446 (0.3306) acc 87.5000 (81.8750) kd_loss 0.9887 (1.0447) lr 1.7290e-03 eta 0:11:33
epoch [14/50] batch [40/160] time 0.107 (0.113) data 0.000 (0.006) loss 1.0088 (0.8734) ce_loss 0.5776 (0.4919) teacher_loss 0.6012 (0.4747) loss_zs_kd 0.1392 (0.1128) loss_oracle 0.3381 (0.3423) acc 75.0000 (81.0938) kd_loss 1.0122 (1.0341) lr 1.7290e-03 eta 0:11:03
epoch [14/50] batch [60/160] time 0.131 (0.112) data 0.001 (0.004) loss 0.7325 (0.8626) ce_loss 0.3442 (0.4774) teacher_loss 0.3377 (0.4618) loss_zs_kd 0.0991 (0.1147) loss_oracle 0.3452 (0.3435) acc 87.5000 (81.6667) kd_loss 0.9890 (1.0228) lr 1.7290e-03 eta 0:10:53
epoch [14/50] batch [80/160] time 0.122 (0.112) data 0.000 (0.003) loss 1.0452 (0.8850) ce_loss 0.6714 (0.4963) teacher_loss 0.6580 (0.4818) loss_zs_kd 0.1119 (0.1172) loss_oracle 0.3312 (0.3447) acc 71.8750 (80.9375) kd_loss 0.9977 (1.0161) lr 1.7290e-03 eta 0:10:55
epoch [14/50] batch [100/160] time 0.134 (0.113) data 0.000 (0.003) loss 0.9383 (0.8805) ce_loss 0.4917 (0.4903) teacher_loss 0.4907 (0.4748) loss_zs_kd 0.1322 (0.1183) loss_oracle 0.3815 (0.3465) acc 78.1250 (81.2188) kd_loss 0.9915 (1.0199) lr 1.7290e-03 eta 0:10:55
epoch [14/50] batch [120/160] time 0.099 (0.113) data 0.000 (0.002) loss 0.9263 (0.8772) ce_loss 0.5137 (0.4882) teacher_loss 0.5201 (0.4726) loss_zs_kd 0.1194 (0.1181) loss_oracle 0.3465 (0.3456) acc 81.2500 (81.6927) kd_loss 1.0702 (1.0227) lr 1.7290e-03 eta 0:10:57
epoch [14/50] batch [140/160] time 0.089 (0.114) data 0.000 (0.002) loss 0.8059 (0.8707) ce_loss 0.4456 (0.4867) teacher_loss 0.4627 (0.4695) loss_zs_kd 0.1317 (0.1179) loss_oracle 0.2774 (0.3423) acc 87.5000 (81.7634) kd_loss 1.0567 (1.0231) lr 1.7290e-03 eta 0:10:58
epoch [14/50] batch [160/160] time 0.092 (0.111) data 0.000 (0.002) loss 0.6161 (0.8658) ce_loss 0.2556 (0.4859) teacher_loss 0.2527 (0.4660) loss_zs_kd 0.0826 (0.1195) loss_oracle 0.3220 (0.3400) acc 93.7500 (81.6992) kd_loss 0.9806 (1.0215) lr 1.6845e-03 eta 0:10:41
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,846
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,971
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 89.0%
******* Domain p best val acc:      84.0%, epoch: 10 *******
******* Domain p best val test acc: 87.1%, epoch: 10 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [15/50] batch [20/160] time 0.137 (0.165) data 0.000 (0.018) loss 0.8074 (0.8314) ce_loss 0.3970 (0.4732) teacher_loss 0.4144 (0.4636) loss_zs_kd 0.1163 (0.0980) loss_oracle 0.3349 (0.3188) acc 84.3750 (81.7188) kd_loss 1.0532 (1.0230) lr 1.6845e-03 eta 0:15:49
epoch [15/50] batch [40/160] time 0.137 (0.141) data 0.001 (0.009) loss 0.7644 (0.8439) ce_loss 0.4238 (0.4896) teacher_loss 0.4024 (0.4756) loss_zs_kd 0.1802 (0.1068) loss_oracle 0.2719 (0.3149) acc 84.3750 (81.4062) kd_loss 1.0420 (1.0310) lr 1.6845e-03 eta 0:13:24
epoch [15/50] batch [60/160] time 0.138 (0.136) data 0.001 (0.006) loss 0.9661 (0.8289) ce_loss 0.5166 (0.4742) teacher_loss 0.5187 (0.4571) loss_zs_kd 0.1546 (0.1116) loss_oracle 0.3701 (0.3160) acc 93.7500 (81.8229) kd_loss 1.1017 (1.0324) lr 1.6845e-03 eta 0:12:54
epoch [15/50] batch [80/160] time 0.102 (0.128) data 0.001 (0.005) loss 0.8444 (0.8359) ce_loss 0.5063 (0.4772) teacher_loss 0.5185 (0.4608) loss_zs_kd 0.1081 (0.1145) loss_oracle 0.2719 (0.3178) acc 75.0000 (81.7188) kd_loss 1.0238 (1.0308) lr 1.6845e-03 eta 0:12:07
epoch [15/50] batch [100/160] time 0.097 (0.123) data 0.000 (0.004) loss 0.8526 (0.8308) ce_loss 0.4290 (0.4740) teacher_loss 0.4050 (0.4574) loss_zs_kd 0.1514 (0.1123) loss_oracle 0.3718 (0.3173) acc 78.1250 (82.0625) kd_loss 1.0009 (1.0360) lr 1.6845e-03 eta 0:11:37
epoch [15/50] batch [120/160] time 0.093 (0.120) data 0.000 (0.003) loss 0.7376 (0.8317) ce_loss 0.3511 (0.4753) teacher_loss 0.3154 (0.4562) loss_zs_kd 0.1438 (0.1150) loss_oracle 0.3503 (0.3180) acc 81.2500 (81.9792) kd_loss 0.9825 (1.0380) lr 1.6845e-03 eta 0:11:16
epoch [15/50] batch [140/160] time 0.133 (0.119) data 0.000 (0.003) loss 0.8358 (0.8363) ce_loss 0.5225 (0.4767) teacher_loss 0.4863 (0.4592) loss_zs_kd 0.1426 (0.1161) loss_oracle 0.2782 (0.3191) acc 81.2500 (82.0089) kd_loss 0.9588 (1.0367) lr 1.6845e-03 eta 0:11:06
epoch [15/50] batch [160/160] time 0.085 (0.116) data 0.000 (0.002) loss 0.9684 (0.8486) ce_loss 0.5425 (0.4865) teacher_loss 0.5785 (0.4696) loss_zs_kd 0.1187 (0.1173) loss_oracle 0.3305 (0.3203) acc 84.3750 (81.6406) kd_loss 0.9940 (1.0354) lr 1.6374e-03 eta 0:10:47
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,852
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,979
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 89.3%
******* Domain p best val acc:      84.0%, epoch: 10 *******
******* Domain p best val test acc: 87.1%, epoch: 10 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [16/50] batch [20/160] time 0.085 (0.113) data 0.000 (0.015) loss 0.8840 (0.8739) ce_loss 0.4551 (0.4736) teacher_loss 0.4880 (0.4711) loss_zs_kd 0.0724 (0.1088) loss_oracle 0.3597 (0.3485) acc 81.2500 (82.1875) kd_loss 1.0287 (0.9760) lr 1.6374e-03 eta 0:10:31
epoch [16/50] batch [40/160] time 0.082 (0.108) data 0.000 (0.007) loss 0.6991 (0.8665) ce_loss 0.3699 (0.4721) teacher_loss 0.3194 (0.4616) loss_zs_kd 0.0524 (0.1065) loss_oracle 0.3535 (0.3517) acc 87.5000 (82.7344) kd_loss 0.8880 (0.9733) lr 1.6374e-03 eta 0:09:58
epoch [16/50] batch [60/160] time 0.107 (0.105) data 0.001 (0.005) loss 0.7396 (0.8578) ce_loss 0.3625 (0.4633) teacher_loss 0.3575 (0.4519) loss_zs_kd 0.0904 (0.1136) loss_oracle 0.3369 (0.3491) acc 90.6250 (83.1250) kd_loss 0.9739 (0.9760) lr 1.6374e-03 eta 0:09:41
epoch [16/50] batch [80/160] time 0.076 (0.101) data 0.000 (0.004) loss 0.8672 (0.8579) ce_loss 0.4600 (0.4643) teacher_loss 0.4816 (0.4537) loss_zs_kd 0.1259 (0.1152) loss_oracle 0.3227 (0.3466) acc 90.6250 (82.9297) kd_loss 1.0489 (0.9798) lr 1.6374e-03 eta 0:09:14
epoch [16/50] batch [100/160] time 0.102 (0.098) data 0.000 (0.003) loss 0.8366 (0.8638) ce_loss 0.4199 (0.4696) teacher_loss 0.4235 (0.4592) loss_zs_kd 0.1593 (0.1186) loss_oracle 0.3335 (0.3453) acc 81.2500 (82.9062) kd_loss 0.9235 (0.9792) lr 1.6374e-03 eta 0:08:58
epoch [16/50] batch [120/160] time 0.102 (0.098) data 0.000 (0.003) loss 0.8916 (0.8711) ce_loss 0.4419 (0.4766) teacher_loss 0.4703 (0.4667) loss_zs_kd 0.1142 (0.1174) loss_oracle 0.3641 (0.3457) acc 81.2500 (82.4219) kd_loss 0.9981 (0.9786) lr 1.6374e-03 eta 0:08:54
epoch [16/50] batch [140/160] time 0.087 (0.096) data 0.000 (0.002) loss 1.3312 (0.8718) ce_loss 0.9307 (0.4781) teacher_loss 0.9661 (0.4703) loss_zs_kd 0.1027 (0.1169) loss_oracle 0.3137 (0.3430) acc 56.2500 (82.5000) kd_loss 1.0205 (0.9842) lr 1.6374e-03 eta 0:08:43
epoch [16/50] batch [160/160] time 0.096 (0.094) data 0.000 (0.002) loss 0.7104 (0.8695) ce_loss 0.3174 (0.4789) teacher_loss 0.3278 (0.4701) loss_zs_kd 0.0874 (0.1169) loss_oracle 0.3388 (0.3409) acc 90.6250 (82.6953) kd_loss 1.0198 (0.9877) lr 1.5878e-03 eta 0:08:33
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,853
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,970
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 89.1%
******* Domain p best val acc:      84.0%, epoch: 10 *******
******* Domain p best val test acc: 87.1%, epoch: 10 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [17/50] batch [20/160] time 0.084 (0.110) data 0.000 (0.015) loss 0.8755 (0.8449) ce_loss 0.4846 (0.4498) teacher_loss 0.4994 (0.4442) loss_zs_kd 0.1056 (0.1080) loss_oracle 0.3233 (0.3467) acc 81.2500 (83.5938) kd_loss 1.0692 (0.9837) lr 1.5878e-03 eta 0:09:53
epoch [17/50] batch [40/160] time 0.075 (0.101) data 0.000 (0.008) loss 0.6790 (0.8375) ce_loss 0.3477 (0.4501) teacher_loss 0.2703 (0.4331) loss_zs_kd 0.1111 (0.1158) loss_oracle 0.3531 (0.3465) acc 90.6250 (83.4375) kd_loss 1.0804 (1.0082) lr 1.5878e-03 eta 0:09:03
epoch [17/50] batch [60/160] time 0.080 (0.097) data 0.001 (0.005) loss 0.7574 (0.8451) ce_loss 0.3831 (0.4588) teacher_loss 0.4146 (0.4439) loss_zs_kd 0.1367 (0.1154) loss_oracle 0.2745 (0.3435) acc 81.2500 (82.7604) kd_loss 1.1599 (1.0278) lr 1.5878e-03 eta 0:08:39
epoch [17/50] batch [80/160] time 0.105 (0.095) data 0.000 (0.004) loss 1.0193 (0.8563) ce_loss 0.6768 (0.4735) teacher_loss 0.6610 (0.4556) loss_zs_kd 0.1155 (0.1180) loss_oracle 0.3006 (0.3418) acc 65.6250 (81.8359) kd_loss 1.0117 (1.0297) lr 1.5878e-03 eta 0:08:28
epoch [17/50] batch [100/160] time 0.127 (0.095) data 0.000 (0.003) loss 0.9516 (0.8627) ce_loss 0.5449 (0.4757) teacher_loss 0.5529 (0.4586) loss_zs_kd 0.1159 (0.1200) loss_oracle 0.3408 (0.3441) acc 78.1250 (81.5312) kd_loss 0.8875 (1.0237) lr 1.5878e-03 eta 0:08:26
epoch [17/50] batch [120/160] time 0.105 (0.095) data 0.000 (0.003) loss 0.9559 (0.8617) ce_loss 0.5942 (0.4777) teacher_loss 0.6106 (0.4606) loss_zs_kd 0.1338 (0.1208) loss_oracle 0.2784 (0.3407) acc 78.1250 (81.6146) kd_loss 1.0712 (1.0232) lr 1.5878e-03 eta 0:08:27
epoch [17/50] batch [140/160] time 0.147 (0.095) data 0.000 (0.002) loss 0.8731 (0.8643) ce_loss 0.5063 (0.4828) teacher_loss 0.4599 (0.4665) loss_zs_kd 0.1350 (0.1211) loss_oracle 0.3457 (0.3372) acc 75.0000 (81.5848) kd_loss 1.1397 (1.0278) lr 1.5878e-03 eta 0:08:25
epoch [17/50] batch [160/160] time 0.141 (0.101) data 0.000 (0.002) loss 0.9399 (0.8624) ce_loss 0.6060 (0.4820) teacher_loss 0.5615 (0.4645) loss_zs_kd 0.0952 (0.1220) loss_oracle 0.3308 (0.3369) acc 75.0000 (81.9336) kd_loss 0.9640 (1.0288) lr 1.5358e-03 eta 0:08:51
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,864
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 85.5%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,954
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 88.7%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [18/50] batch [20/160] time 0.090 (0.097) data 0.000 (0.014) loss 0.8584 (0.9095) ce_loss 0.5508 (0.5284) teacher_loss 0.4671 (0.4929) loss_zs_kd 0.1491 (0.1315) loss_oracle 0.3167 (0.3508) acc 68.7500 (78.7500) kd_loss 1.0743 (1.0409) lr 1.5358e-03 eta 0:08:30
epoch [18/50] batch [40/160] time 0.086 (0.093) data 0.000 (0.007) loss 0.8695 (0.8624) ce_loss 0.5361 (0.4875) teacher_loss 0.4941 (0.4542) loss_zs_kd 0.1363 (0.1357) loss_oracle 0.3073 (0.3403) acc 84.3750 (80.6250) kd_loss 1.0397 (1.0446) lr 1.5358e-03 eta 0:08:09
epoch [18/50] batch [60/160] time 0.088 (0.092) data 0.000 (0.005) loss 1.0210 (0.8392) ce_loss 0.5859 (0.4703) teacher_loss 0.5968 (0.4358) loss_zs_kd 0.1305 (0.1323) loss_oracle 0.3590 (0.3372) acc 81.2500 (81.9792) kd_loss 1.0673 (1.0470) lr 1.5358e-03 eta 0:08:00
epoch [18/50] batch [80/160] time 0.094 (0.092) data 0.001 (0.004) loss 0.7234 (0.8377) ce_loss 0.3601 (0.4703) teacher_loss 0.3247 (0.4340) loss_zs_kd 0.1977 (0.1329) loss_oracle 0.2998 (0.3372) acc 93.7500 (82.2656) kd_loss 1.0207 (1.0446) lr 1.5358e-03 eta 0:07:58
epoch [18/50] batch [100/160] time 0.087 (0.091) data 0.000 (0.003) loss 1.1903 (0.8402) ce_loss 0.7832 (0.4718) teacher_loss 0.7982 (0.4362) loss_zs_kd 0.1282 (0.1321) loss_oracle 0.3280 (0.3379) acc 78.1250 (82.1250) kd_loss 1.0691 (1.0454) lr 1.5358e-03 eta 0:07:53
epoch [18/50] batch [120/160] time 0.092 (0.091) data 0.000 (0.003) loss 0.8353 (0.8489) ce_loss 0.4634 (0.4780) teacher_loss 0.4196 (0.4444) loss_zs_kd 0.1762 (0.1301) loss_oracle 0.3276 (0.3395) acc 81.2500 (81.9010) kd_loss 1.0429 (1.0467) lr 1.5358e-03 eta 0:07:49
epoch [18/50] batch [140/160] time 0.098 (0.090) data 0.001 (0.002) loss 1.0702 (0.8452) ce_loss 0.6992 (0.4738) teacher_loss 0.6951 (0.4419) loss_zs_kd 0.1179 (0.1286) loss_oracle 0.3162 (0.3390) acc 68.7500 (82.0312) kd_loss 0.9794 (1.0465) lr 1.5358e-03 eta 0:07:41
epoch [18/50] batch [160/160] time 0.074 (0.088) data 0.000 (0.002) loss 1.2554 (0.8488) ce_loss 0.8003 (0.4742) teacher_loss 0.8410 (0.4452) loss_zs_kd 0.1532 (0.1280) loss_oracle 0.3378 (0.3396) acc 71.8750 (81.9922) kd_loss 1.0292 (1.0441) lr 1.4818e-03 eta 0:07:29
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,854
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,946
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.5%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [19/50] batch [20/160] time 0.076 (0.111) data 0.000 (0.016) loss 0.8804 (0.8483) ce_loss 0.4712 (0.4592) teacher_loss 0.4832 (0.4618) loss_zs_kd 0.1188 (0.1121) loss_oracle 0.3378 (0.3304) acc 78.1250 (83.1250) kd_loss 0.9998 (1.0275) lr 1.4818e-03 eta 0:09:24
epoch [19/50] batch [40/160] time 0.086 (0.097) data 0.000 (0.008) loss 1.0484 (0.8753) ce_loss 0.6362 (0.4807) teacher_loss 0.6355 (0.4738) loss_zs_kd 0.1555 (0.1184) loss_oracle 0.3352 (0.3423) acc 78.1250 (82.6562) kd_loss 1.0064 (1.0187) lr 1.4818e-03 eta 0:08:13
epoch [19/50] batch [60/160] time 0.075 (0.091) data 0.001 (0.006) loss 0.8196 (0.8957) ce_loss 0.3684 (0.4875) teacher_loss 0.3473 (0.4809) loss_zs_kd 0.0959 (0.1183) loss_oracle 0.4243 (0.3557) acc 84.3750 (81.6667) kd_loss 0.9090 (0.9992) lr 1.4818e-03 eta 0:07:40
epoch [19/50] batch [80/160] time 0.078 (0.087) data 0.000 (0.004) loss 1.0543 (0.8897) ce_loss 0.6816 (0.4773) teacher_loss 0.6314 (0.4714) loss_zs_kd 0.1097 (0.1195) loss_oracle 0.3680 (0.3585) acc 78.1250 (82.1875) kd_loss 0.9592 (0.9895) lr 1.4818e-03 eta 0:07:20
epoch [19/50] batch [100/160] time 0.075 (0.085) data 0.000 (0.003) loss 0.9651 (0.9058) ce_loss 0.5146 (0.4930) teacher_loss 0.5203 (0.4872) loss_zs_kd 0.1454 (0.1178) loss_oracle 0.3721 (0.3598) acc 78.1250 (81.8438) kd_loss 1.0336 (0.9825) lr 1.4818e-03 eta 0:07:07
epoch [19/50] batch [120/160] time 0.076 (0.084) data 0.001 (0.003) loss 1.1427 (0.9027) ce_loss 0.6201 (0.4871) teacher_loss 0.6047 (0.4807) loss_zs_kd 0.2055 (0.1179) loss_oracle 0.4352 (0.3631) acc 75.0000 (82.2396) kd_loss 0.9047 (0.9783) lr 1.4818e-03 eta 0:06:58
epoch [19/50] batch [140/160] time 0.062 (0.082) data 0.000 (0.003) loss 0.8501 (0.9052) ce_loss 0.4055 (0.4856) teacher_loss 0.4107 (0.4798) loss_zs_kd 0.1021 (0.1167) loss_oracle 0.3883 (0.3671) acc 81.2500 (82.3661) kd_loss 0.9867 (0.9811) lr 1.4818e-03 eta 0:06:45
epoch [19/50] batch [160/160] time 0.093 (0.081) data 0.000 (0.002) loss 0.8655 (0.9015) ce_loss 0.4617 (0.4833) teacher_loss 0.4502 (0.4773) loss_zs_kd 0.1261 (0.1173) loss_oracle 0.3522 (0.3655) acc 84.3750 (82.4023) kd_loss 1.0985 (0.9829) lr 1.4258e-03 eta 0:06:42
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,854
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,953
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 88.7%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [20/50] batch [20/160] time 0.098 (0.112) data 0.000 (0.014) loss 0.8901 (0.8692) ce_loss 0.5405 (0.4834) teacher_loss 0.5180 (0.4713) loss_zs_kd 0.0925 (0.1134) loss_oracle 0.3259 (0.3412) acc 81.2500 (81.8750) kd_loss 1.0174 (0.9973) lr 1.4258e-03 eta 0:09:13
epoch [20/50] batch [40/160] time 0.103 (0.100) data 0.000 (0.007) loss 0.9550 (0.8737) ce_loss 0.5664 (0.4761) teacher_loss 0.5342 (0.4685) loss_zs_kd 0.0874 (0.1110) loss_oracle 0.3771 (0.3496) acc 75.0000 (82.3438) kd_loss 1.0659 (0.9858) lr 1.4258e-03 eta 0:08:14
epoch [20/50] batch [60/160] time 0.069 (0.098) data 0.001 (0.005) loss 0.8814 (0.8814) ce_loss 0.4568 (0.4752) teacher_loss 0.4170 (0.4678) loss_zs_kd 0.1015 (0.1089) loss_oracle 0.4136 (0.3592) acc 75.0000 (82.1354) kd_loss 1.0007 (0.9854) lr 1.4258e-03 eta 0:07:58
epoch [20/50] batch [80/160] time 0.084 (0.098) data 0.000 (0.004) loss 0.8939 (0.8945) ce_loss 0.5166 (0.4850) teacher_loss 0.4641 (0.4755) loss_zs_kd 0.1054 (0.1110) loss_oracle 0.3771 (0.3635) acc 90.6250 (81.9922) kd_loss 1.0190 (0.9847) lr 1.4258e-03 eta 0:07:56
epoch [20/50] batch [100/160] time 0.084 (0.098) data 0.000 (0.003) loss 0.7778 (0.8898) ce_loss 0.4263 (0.4844) teacher_loss 0.3077 (0.4697) loss_zs_kd 0.1217 (0.1111) loss_oracle 0.4093 (0.3646) acc 84.3750 (81.5625) kd_loss 0.9349 (0.9879) lr 1.4258e-03 eta 0:07:57
epoch [20/50] batch [120/160] time 0.080 (0.098) data 0.000 (0.003) loss 0.8705 (0.8940) ce_loss 0.4839 (0.4901) teacher_loss 0.4566 (0.4726) loss_zs_kd 0.0951 (0.1127) loss_oracle 0.3663 (0.3650) acc 87.5000 (81.5104) kd_loss 0.9685 (0.9885) lr 1.4258e-03 eta 0:07:53
epoch [20/50] batch [140/160] time 0.093 (0.098) data 0.000 (0.002) loss 0.6699 (0.8808) ce_loss 0.3242 (0.4785) teacher_loss 0.3120 (0.4603) loss_zs_kd 0.0955 (0.1144) loss_oracle 0.3101 (0.3633) acc 90.6250 (81.9643) kd_loss 0.9890 (0.9933) lr 1.4258e-03 eta 0:07:50
epoch [20/50] batch [160/160] time 0.075 (0.097) data 0.000 (0.002) loss 0.8108 (0.8777) ce_loss 0.4470 (0.4770) teacher_loss 0.4350 (0.4592) loss_zs_kd 0.0805 (0.1161) loss_oracle 0.3356 (0.3605) acc 84.3750 (82.0312) kd_loss 0.9692 (0.9978) lr 1.3681e-03 eta 0:07:44
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,857
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,930
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 88.2%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [21/50] batch [20/160] time 0.089 (0.123) data 0.000 (0.014) loss 0.8211 (0.8117) ce_loss 0.4231 (0.4349) teacher_loss 0.4377 (0.4205) loss_zs_kd 0.1511 (0.1192) loss_oracle 0.3078 (0.3315) acc 81.2500 (84.0625) kd_loss 1.0348 (1.0079) lr 1.3681e-03 eta 0:09:48
epoch [21/50] batch [40/160] time 0.125 (0.116) data 0.000 (0.007) loss 0.6317 (0.8276) ce_loss 0.2659 (0.4580) teacher_loss 0.2453 (0.4441) loss_zs_kd 0.0947 (0.1158) loss_oracle 0.3391 (0.3255) acc 90.6250 (82.7344) kd_loss 1.1005 (1.0299) lr 1.3681e-03 eta 0:09:13
epoch [21/50] batch [60/160] time 0.118 (0.114) data 0.001 (0.005) loss 0.8462 (0.8368) ce_loss 0.4321 (0.4673) teacher_loss 0.4009 (0.4524) loss_zs_kd 0.1387 (0.1148) loss_oracle 0.3759 (0.3270) acc 84.3750 (82.9167) kd_loss 1.0386 (1.0228) lr 1.3681e-03 eta 0:08:58
epoch [21/50] batch [80/160] time 0.080 (0.112) data 0.000 (0.004) loss 0.8129 (0.8393) ce_loss 0.4688 (0.4692) teacher_loss 0.4278 (0.4525) loss_zs_kd 0.0921 (0.1154) loss_oracle 0.3390 (0.3291) acc 81.2500 (82.6953) kd_loss 1.0375 (1.0256) lr 1.3681e-03 eta 0:08:49
epoch [21/50] batch [100/160] time 0.087 (0.111) data 0.000 (0.003) loss 0.8987 (0.8402) ce_loss 0.4763 (0.4678) teacher_loss 0.4524 (0.4501) loss_zs_kd 0.1230 (0.1172) loss_oracle 0.3848 (0.3315) acc 87.5000 (82.7500) kd_loss 1.0799 (1.0281) lr 1.3681e-03 eta 0:08:43
epoch [21/50] batch [120/160] time 0.083 (0.112) data 0.000 (0.003) loss 0.8110 (0.8448) ce_loss 0.4504 (0.4712) teacher_loss 0.4305 (0.4521) loss_zs_kd 0.1228 (0.1187) loss_oracle 0.3190 (0.3334) acc 81.2500 (82.5521) kd_loss 1.1059 (1.0278) lr 1.3681e-03 eta 0:08:43
epoch [21/50] batch [140/160] time 0.102 (0.110) data 0.000 (0.002) loss 0.9983 (0.8483) ce_loss 0.5854 (0.4743) teacher_loss 0.5252 (0.4547) loss_zs_kd 0.1760 (0.1201) loss_oracle 0.3851 (0.3335) acc 75.0000 (82.3661) kd_loss 1.0935 (1.0282) lr 1.3681e-03 eta 0:08:30
epoch [21/50] batch [160/160] time 0.180 (0.114) data 0.000 (0.002) loss 0.8361 (0.8515) ce_loss 0.4995 (0.4776) teacher_loss 0.4570 (0.4581) loss_zs_kd 0.1227 (0.1199) loss_oracle 0.3177 (0.3335) acc 84.3750 (82.1875) kd_loss 1.1382 (1.0301) lr 1.3090e-03 eta 0:08:51
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,862
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,926
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 88.2%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [22/50] batch [20/160] time 0.128 (0.127) data 0.000 (0.017) loss 0.8775 (0.8640) ce_loss 0.4497 (0.4811) teacher_loss 0.4337 (0.4552) loss_zs_kd 0.1586 (0.1232) loss_oracle 0.3646 (0.3472) acc 78.1250 (82.9688) kd_loss 0.9947 (1.0050) lr 1.3090e-03 eta 0:09:46
epoch [22/50] batch [40/160] time 0.098 (0.115) data 0.000 (0.009) loss 0.7560 (0.8647) ce_loss 0.3721 (0.4863) teacher_loss 0.3836 (0.4629) loss_zs_kd 0.0843 (0.1162) loss_oracle 0.3302 (0.3437) acc 87.5000 (82.8906) kd_loss 1.0826 (1.0135) lr 1.3090e-03 eta 0:08:51
epoch [22/50] batch [60/160] time 0.123 (0.113) data 0.001 (0.006) loss 0.6377 (0.8750) ce_loss 0.2542 (0.4865) teacher_loss 0.2287 (0.4664) loss_zs_kd 0.0820 (0.1194) loss_oracle 0.3679 (0.3489) acc 90.6250 (82.3958) kd_loss 1.0259 (1.0112) lr 1.3090e-03 eta 0:08:36
epoch [22/50] batch [80/160] time 0.133 (0.113) data 0.000 (0.004) loss 0.7833 (0.8734) ce_loss 0.3352 (0.4818) teacher_loss 0.3639 (0.4628) loss_zs_kd 0.1946 (0.1218) loss_oracle 0.3221 (0.3497) acc 87.5000 (82.3438) kd_loss 1.0720 (1.0124) lr 1.3090e-03 eta 0:08:36
epoch [22/50] batch [100/160] time 0.137 (0.114) data 0.000 (0.004) loss 0.9473 (0.8664) ce_loss 0.5845 (0.4763) teacher_loss 0.5426 (0.4585) loss_zs_kd 0.1045 (0.1222) loss_oracle 0.3524 (0.3468) acc 84.3750 (82.2500) kd_loss 0.9714 (1.0222) lr 1.3090e-03 eta 0:08:37
epoch [22/50] batch [120/160] time 0.115 (0.114) data 0.000 (0.003) loss 0.9053 (0.8700) ce_loss 0.5117 (0.4752) teacher_loss 0.4754 (0.4580) loss_zs_kd 0.1201 (0.1213) loss_oracle 0.3699 (0.3514) acc 87.5000 (82.7083) kd_loss 0.9683 (1.0182) lr 1.3090e-03 eta 0:08:33
epoch [22/50] batch [140/160] time 0.082 (0.113) data 0.000 (0.003) loss 0.7856 (0.8652) ce_loss 0.3608 (0.4716) teacher_loss 0.3683 (0.4578) loss_zs_kd 0.1392 (0.1192) loss_oracle 0.3478 (0.3479) acc 90.6250 (82.8348) kd_loss 1.0783 (1.0176) lr 1.3090e-03 eta 0:08:29
epoch [22/50] batch [160/160] time 0.095 (0.112) data 0.000 (0.002) loss 0.9256 (0.8646) ce_loss 0.5024 (0.4717) teacher_loss 0.5229 (0.4584) loss_zs_kd 0.1259 (0.1200) loss_oracle 0.3397 (0.3463) acc 78.1250 (82.6953) kd_loss 1.0845 (1.0185) lr 1.2487e-03 eta 0:08:22
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,856
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,973
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 89.2%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [23/50] batch [20/160] time 0.079 (0.118) data 0.000 (0.016) loss 0.9026 (0.8436) ce_loss 0.4592 (0.4587) teacher_loss 0.4975 (0.4593) loss_zs_kd 0.1842 (0.1103) loss_oracle 0.3130 (0.3292) acc 93.7500 (83.5938) kd_loss 1.0317 (1.0114) lr 1.2487e-03 eta 0:08:45
epoch [23/50] batch [40/160] time 0.111 (0.108) data 0.000 (0.008) loss 0.8160 (0.8503) ce_loss 0.4517 (0.4717) teacher_loss 0.4120 (0.4618) loss_zs_kd 0.1523 (0.1138) loss_oracle 0.3279 (0.3316) acc 81.2500 (83.2812) kd_loss 1.0065 (1.0106) lr 1.2487e-03 eta 0:08:00
epoch [23/50] batch [60/160] time 0.098 (0.105) data 0.001 (0.005) loss 1.0320 (0.8724) ce_loss 0.7017 (0.4885) teacher_loss 0.6765 (0.4792) loss_zs_kd 0.0975 (0.1189) loss_oracle 0.3067 (0.3337) acc 71.8750 (82.3438) kd_loss 1.0022 (1.0152) lr 1.2487e-03 eta 0:07:45
epoch [23/50] batch [80/160] time 0.103 (0.103) data 0.000 (0.004) loss 0.9332 (0.8538) ce_loss 0.5225 (0.4726) teacher_loss 0.5291 (0.4638) loss_zs_kd 0.1262 (0.1145) loss_oracle 0.3409 (0.3328) acc 84.3750 (83.1641) kd_loss 1.0043 (1.0149) lr 1.2487e-03 eta 0:07:33
epoch [23/50] batch [100/160] time 0.130 (0.103) data 0.000 (0.003) loss 0.8451 (0.8632) ce_loss 0.4504 (0.4796) teacher_loss 0.4036 (0.4701) loss_zs_kd 0.1301 (0.1148) loss_oracle 0.3764 (0.3357) acc 84.3750 (82.6875) kd_loss 0.9299 (1.0143) lr 1.2487e-03 eta 0:07:31
epoch [23/50] batch [120/160] time 0.128 (0.103) data 0.000 (0.003) loss 0.7049 (0.8645) ce_loss 0.3042 (0.4820) teacher_loss 0.3036 (0.4715) loss_zs_kd 0.0815 (0.1168) loss_oracle 0.3605 (0.3346) acc 90.6250 (82.5781) kd_loss 1.0182 (1.0142) lr 1.2487e-03 eta 0:07:30
epoch [23/50] batch [140/160] time 0.086 (0.103) data 0.000 (0.002) loss 0.9718 (0.8654) ce_loss 0.4912 (0.4806) teacher_loss 0.4887 (0.4698) loss_zs_kd 0.1579 (0.1183) loss_oracle 0.4042 (0.3365) acc 84.3750 (82.4330) kd_loss 1.0032 (1.0158) lr 1.2487e-03 eta 0:07:25
epoch [23/50] batch [160/160] time 0.062 (0.101) data 0.000 (0.002) loss 0.8334 (0.8610) ce_loss 0.4583 (0.4763) teacher_loss 0.4649 (0.4661) loss_zs_kd 0.1191 (0.1191) loss_oracle 0.3091 (0.3354) acc 84.3750 (82.6367) kd_loss 1.0209 (1.0201) lr 1.1874e-03 eta 0:07:14
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,864
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,958
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.8%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [24/50] batch [20/160] time 0.064 (0.139) data 0.000 (0.014) loss 0.9536 (0.8596) ce_loss 0.5610 (0.4828) teacher_loss 0.5361 (0.4710) loss_zs_kd 0.0849 (0.1149) loss_oracle 0.3751 (0.3312) acc 78.1250 (81.7188) kd_loss 1.0562 (1.0305) lr 1.1874e-03 eta 0:09:58
epoch [24/50] batch [40/160] time 0.131 (0.116) data 0.000 (0.007) loss 0.9490 (0.8613) ce_loss 0.5078 (0.4821) teacher_loss 0.5308 (0.4691) loss_zs_kd 0.1193 (0.1140) loss_oracle 0.3585 (0.3352) acc 78.1250 (82.1094) kd_loss 1.0423 (1.0303) lr 1.1874e-03 eta 0:08:15
epoch [24/50] batch [60/160] time 0.109 (0.112) data 0.001 (0.005) loss 0.9929 (0.8584) ce_loss 0.5908 (0.4763) teacher_loss 0.5969 (0.4665) loss_zs_kd 0.1052 (0.1110) loss_oracle 0.3434 (0.3365) acc 90.6250 (82.4479) kd_loss 1.1393 (1.0284) lr 1.1874e-03 eta 0:07:56
epoch [24/50] batch [80/160] time 0.096 (0.110) data 0.000 (0.004) loss 1.0674 (0.8507) ce_loss 0.7026 (0.4734) teacher_loss 0.6757 (0.4639) loss_zs_kd 0.1121 (0.1079) loss_oracle 0.3356 (0.3328) acc 68.7500 (82.5781) kd_loss 0.9842 (1.0355) lr 1.1874e-03 eta 0:07:44
epoch [24/50] batch [100/160] time 0.086 (0.110) data 0.000 (0.003) loss 0.8822 (0.8536) ce_loss 0.4885 (0.4747) teacher_loss 0.4261 (0.4656) loss_zs_kd 0.1660 (0.1091) loss_oracle 0.3732 (0.3334) acc 71.8750 (82.6250) kd_loss 1.0743 (1.0341) lr 1.1874e-03 eta 0:07:43
epoch [24/50] batch [120/160] time 0.129 (0.110) data 0.000 (0.003) loss 0.9128 (0.8533) ce_loss 0.5640 (0.4760) teacher_loss 0.5447 (0.4657) loss_zs_kd 0.1233 (0.1102) loss_oracle 0.3065 (0.3325) acc 87.5000 (82.2135) kd_loss 0.9683 (1.0346) lr 1.1874e-03 eta 0:07:43
epoch [24/50] batch [140/160] time 0.089 (0.111) data 0.000 (0.002) loss 1.0090 (0.8601) ce_loss 0.6177 (0.4790) teacher_loss 0.6015 (0.4690) loss_zs_kd 0.1041 (0.1120) loss_oracle 0.3554 (0.3351) acc 78.1250 (82.0536) kd_loss 1.0854 (1.0319) lr 1.1874e-03 eta 0:07:42
epoch [24/50] batch [160/160] time 0.086 (0.110) data 0.000 (0.002) loss 0.8997 (0.8599) ce_loss 0.4463 (0.4753) teacher_loss 0.4384 (0.4656) loss_zs_kd 0.1210 (0.1151) loss_oracle 0.4008 (0.3368) acc 78.1250 (82.2070) kd_loss 0.9835 (1.0288) lr 1.1253e-03 eta 0:07:36
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,861
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,939
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 88.5%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [25/50] batch [20/160] time 0.080 (0.128) data 0.000 (0.015) loss 0.9391 (0.8458) ce_loss 0.4985 (0.4547) teacher_loss 0.5462 (0.4385) loss_zs_kd 0.0912 (0.1219) loss_oracle 0.3473 (0.3464) acc 84.3750 (83.9062) kd_loss 1.0616 (1.0230) lr 1.1253e-03 eta 0:08:51
epoch [25/50] batch [40/160] time 0.117 (0.121) data 0.000 (0.008) loss 0.7823 (0.8434) ce_loss 0.3796 (0.4550) teacher_loss 0.3971 (0.4454) loss_zs_kd 0.1423 (0.1182) loss_oracle 0.3140 (0.3389) acc 84.3750 (83.7500) kd_loss 1.0787 (1.0386) lr 1.1253e-03 eta 0:08:19
epoch [25/50] batch [60/160] time 0.102 (0.116) data 0.001 (0.005) loss 0.6458 (0.8403) ce_loss 0.3010 (0.4542) teacher_loss 0.2840 (0.4434) loss_zs_kd 0.0983 (0.1212) loss_oracle 0.3126 (0.3363) acc 90.6250 (83.3333) kd_loss 1.0167 (1.0365) lr 1.1253e-03 eta 0:07:56
epoch [25/50] batch [80/160] time 0.096 (0.110) data 0.000 (0.004) loss 0.7622 (0.8247) ce_loss 0.3628 (0.4416) teacher_loss 0.3459 (0.4247) loss_zs_kd 0.1516 (0.1225) loss_oracle 0.3405 (0.3387) acc 78.1250 (84.0234) kd_loss 0.8907 (1.0322) lr 1.1253e-03 eta 0:07:30
epoch [25/50] batch [100/160] time 0.078 (0.107) data 0.000 (0.003) loss 0.8032 (0.8431) ce_loss 0.4712 (0.4613) teacher_loss 0.4267 (0.4369) loss_zs_kd 0.1103 (0.1256) loss_oracle 0.3212 (0.3433) acc 81.2500 (82.8750) kd_loss 1.0041 (1.0336) lr 1.1253e-03 eta 0:07:14
epoch [25/50] batch [120/160] time 0.084 (0.104) data 0.000 (0.003) loss 0.9589 (0.8563) ce_loss 0.5703 (0.4743) teacher_loss 0.5418 (0.4466) loss_zs_kd 0.1254 (0.1276) loss_oracle 0.3544 (0.3459) acc 84.3750 (82.2135) kd_loss 1.0335 (1.0366) lr 1.1253e-03 eta 0:07:02
epoch [25/50] batch [140/160] time 0.096 (0.103) data 0.000 (0.002) loss 0.7550 (0.8585) ce_loss 0.4016 (0.4765) teacher_loss 0.3935 (0.4500) loss_zs_kd 0.0706 (0.1242) loss_oracle 0.3262 (0.3464) acc 81.2500 (82.1652) kd_loss 1.0553 (1.0396) lr 1.1253e-03 eta 0:06:53
epoch [25/50] batch [160/160] time 0.094 (0.101) data 0.000 (0.002) loss 0.8719 (0.8582) ce_loss 0.5400 (0.4770) teacher_loss 0.5035 (0.4511) loss_zs_kd 0.1092 (0.1234) loss_oracle 0.3137 (0.3454) acc 75.0000 (82.1484) kd_loss 1.0277 (1.0396) lr 1.0628e-03 eta 0:06:42
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,859
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,962
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.9%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [26/50] batch [20/160] time 0.161 (0.144) data 0.000 (0.016) loss 0.8490 (0.8789) ce_loss 0.4797 (0.4997) teacher_loss 0.4174 (0.4717) loss_zs_kd 0.1369 (0.1226) loss_oracle 0.3631 (0.3458) acc 81.2500 (79.5312) kd_loss 0.9950 (1.0601) lr 1.0628e-03 eta 0:09:31
epoch [26/50] batch [40/160] time 0.212 (0.130) data 0.000 (0.008) loss 0.9222 (0.8788) ce_loss 0.5122 (0.5014) teacher_loss 0.5377 (0.4656) loss_zs_kd 0.1433 (0.1257) loss_oracle 0.3129 (0.3504) acc 81.2500 (80.0000) kd_loss 1.0908 (1.0618) lr 1.0628e-03 eta 0:08:36
epoch [26/50] batch [60/160] time 0.161 (0.137) data 0.001 (0.006) loss 0.8722 (0.8815) ce_loss 0.4062 (0.5027) teacher_loss 0.3970 (0.4669) loss_zs_kd 0.1178 (0.1228) loss_oracle 0.4163 (0.3532) acc 84.3750 (80.4688) kd_loss 1.0954 (1.0535) lr 1.0628e-03 eta 0:08:59
epoch [26/50] batch [80/160] time 0.107 (0.129) data 0.000 (0.004) loss 0.8772 (0.8707) ce_loss 0.4465 (0.4908) teacher_loss 0.4044 (0.4568) loss_zs_kd 0.1719 (0.1251) loss_oracle 0.3869 (0.3514) acc 81.2500 (81.3672) kd_loss 1.0451 (1.0490) lr 1.0628e-03 eta 0:08:25
epoch [26/50] batch [100/160] time 0.090 (0.125) data 0.000 (0.003) loss 0.7557 (0.8623) ce_loss 0.3674 (0.4858) teacher_loss 0.3548 (0.4523) loss_zs_kd 0.0893 (0.1212) loss_oracle 0.3563 (0.3495) acc 81.2500 (81.7812) kd_loss 0.9899 (1.0501) lr 1.0628e-03 eta 0:08:08
epoch [26/50] batch [120/160] time 0.124 (0.123) data 0.000 (0.003) loss 0.9911 (0.8513) ce_loss 0.5640 (0.4738) teacher_loss 0.5422 (0.4418) loss_zs_kd 0.1680 (0.1232) loss_oracle 0.3650 (0.3478) acc 78.1250 (82.5521) kd_loss 0.9927 (1.0504) lr 1.0628e-03 eta 0:07:55
epoch [26/50] batch [140/160] time 0.079 (0.121) data 0.000 (0.003) loss 0.9255 (0.8521) ce_loss 0.5527 (0.4755) teacher_loss 0.5249 (0.4453) loss_zs_kd 0.1227 (0.1248) loss_oracle 0.3392 (0.3445) acc 78.1250 (82.5000) kd_loss 1.0270 (1.0488) lr 1.0628e-03 eta 0:07:45
epoch [26/50] batch [160/160] time 0.098 (0.118) data 0.000 (0.002) loss 0.8179 (0.8535) ce_loss 0.5273 (0.4768) teacher_loss 0.4179 (0.4470) loss_zs_kd 0.1314 (0.1256) loss_oracle 0.3343 (0.3437) acc 75.0000 (82.4805) kd_loss 1.0754 (1.0498) lr 1.0000e-03 eta 0:07:34
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,860
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,952
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.7%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [27/50] batch [20/160] time 0.116 (0.123) data 0.000 (0.015) loss 0.7093 (0.8345) ce_loss 0.2830 (0.4529) teacher_loss 0.2745 (0.4466) loss_zs_kd 0.1617 (0.1172) loss_oracle 0.3540 (0.3294) acc 90.6250 (83.1250) kd_loss 1.1190 (1.0331) lr 1.0000e-03 eta 0:07:51
epoch [27/50] batch [40/160] time 0.125 (0.113) data 0.000 (0.008) loss 1.0053 (0.8420) ce_loss 0.6104 (0.4611) teacher_loss 0.5337 (0.4455) loss_zs_kd 0.1304 (0.1195) loss_oracle 0.4064 (0.3368) acc 75.0000 (82.8906) kd_loss 1.0632 (1.0523) lr 1.0000e-03 eta 0:07:10
epoch [27/50] batch [60/160] time 0.075 (0.110) data 0.001 (0.005) loss 0.7049 (0.8568) ce_loss 0.2876 (0.4673) teacher_loss 0.2680 (0.4527) loss_zs_kd 0.1400 (0.1220) loss_oracle 0.3670 (0.3432) acc 93.7500 (82.4479) kd_loss 1.0719 (1.0421) lr 1.0000e-03 eta 0:06:56
epoch [27/50] batch [80/160] time 0.075 (0.108) data 0.000 (0.004) loss 0.7817 (0.8559) ce_loss 0.4272 (0.4660) teacher_loss 0.4036 (0.4544) loss_zs_kd 0.1091 (0.1216) loss_oracle 0.3236 (0.3407) acc 81.2500 (82.4219) kd_loss 1.0516 (1.0302) lr 1.0000e-03 eta 0:06:47
epoch [27/50] batch [100/160] time 0.113 (0.108) data 0.000 (0.003) loss 0.8577 (0.8596) ce_loss 0.4412 (0.4722) teacher_loss 0.4717 (0.4612) loss_zs_kd 0.1444 (0.1182) loss_oracle 0.3138 (0.3393) acc 81.2500 (82.3125) kd_loss 1.0331 (1.0261) lr 1.0000e-03 eta 0:06:42
epoch [27/50] batch [120/160] time 0.105 (0.107) data 0.000 (0.003) loss 0.7904 (0.8596) ce_loss 0.3708 (0.4725) teacher_loss 0.4075 (0.4604) loss_zs_kd 0.1033 (0.1189) loss_oracle 0.3313 (0.3397) acc 87.5000 (82.4479) kd_loss 1.0278 (1.0220) lr 1.0000e-03 eta 0:06:39
epoch [27/50] batch [140/160] time 0.118 (0.107) data 0.000 (0.002) loss 0.7638 (0.8607) ce_loss 0.3906 (0.4744) teacher_loss 0.3485 (0.4629) loss_zs_kd 0.1286 (0.1200) loss_oracle 0.3511 (0.3378) acc 90.6250 (82.3661) kd_loss 1.0310 (1.0239) lr 1.0000e-03 eta 0:06:34
epoch [27/50] batch [160/160] time 0.077 (0.105) data 0.000 (0.002) loss 1.1908 (0.8559) ce_loss 0.7959 (0.4710) teacher_loss 0.7779 (0.4589) loss_zs_kd 0.1446 (0.1202) loss_oracle 0.3405 (0.3369) acc 65.6250 (82.5977) kd_loss 1.0612 (1.0258) lr 9.3721e-04 eta 0:06:28
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,858
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,951
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.6%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [28/50] batch [20/160] time 0.124 (0.116) data 0.000 (0.013) loss 0.7786 (0.8318) ce_loss 0.3682 (0.4542) teacher_loss 0.3463 (0.4320) loss_zs_kd 0.1004 (0.1308) loss_oracle 0.3820 (0.3344) acc 87.5000 (83.2812) kd_loss 1.2080 (1.0834) lr 9.3721e-04 eta 0:07:05
epoch [28/50] batch [40/160] time 0.079 (0.106) data 0.000 (0.006) loss 0.9132 (0.8345) ce_loss 0.5254 (0.4654) teacher_loss 0.5269 (0.4418) loss_zs_kd 0.1139 (0.1250) loss_oracle 0.3294 (0.3301) acc 78.1250 (82.8125) kd_loss 1.0099 (1.0701) lr 9.3721e-04 eta 0:06:27
epoch [28/50] batch [60/160] time 0.163 (0.115) data 0.001 (0.004) loss 0.6547 (0.8314) ce_loss 0.2717 (0.4680) teacher_loss 0.2437 (0.4405) loss_zs_kd 0.1332 (0.1255) loss_oracle 0.3444 (0.3282) acc 90.6250 (82.3438) kd_loss 1.0601 (1.0722) lr 9.3721e-04 eta 0:06:56
epoch [28/50] batch [80/160] time 0.158 (0.110) data 0.000 (0.003) loss 0.8033 (0.8241) ce_loss 0.3953 (0.4650) teacher_loss 0.4119 (0.4378) loss_zs_kd 0.1442 (0.1259) loss_oracle 0.3192 (0.3234) acc 84.3750 (82.7734) kd_loss 1.1696 (1.0852) lr 9.3721e-04 eta 0:06:37
epoch [28/50] batch [100/160] time 0.180 (0.116) data 0.000 (0.003) loss 0.7914 (0.8314) ce_loss 0.4033 (0.4737) teacher_loss 0.3965 (0.4466) loss_zs_kd 0.1248 (0.1250) loss_oracle 0.3325 (0.3223) acc 78.1250 (82.6562) kd_loss 1.1232 (1.0916) lr 9.3721e-04 eta 0:06:55
epoch [28/50] batch [120/160] time 0.097 (0.116) data 0.000 (0.002) loss 0.8370 (0.8316) ce_loss 0.5298 (0.4773) teacher_loss 0.4674 (0.4469) loss_zs_kd 0.0874 (0.1250) loss_oracle 0.3259 (0.3222) acc 78.1250 (82.3698) kd_loss 1.0340 (1.0916) lr 9.3721e-04 eta 0:06:52
epoch [28/50] batch [140/160] time 0.119 (0.114) data 0.000 (0.002) loss 0.7693 (0.8323) ce_loss 0.4170 (0.4758) teacher_loss 0.3393 (0.4453) loss_zs_kd 0.1684 (0.1269) loss_oracle 0.3458 (0.3236) acc 84.3750 (82.5670) kd_loss 1.1407 (1.0915) lr 9.3721e-04 eta 0:06:42
epoch [28/50] batch [160/160] time 0.076 (0.110) data 0.000 (0.002) loss 0.7981 (0.8367) ce_loss 0.4124 (0.4798) teacher_loss 0.4233 (0.4508) loss_zs_kd 0.0843 (0.1265) loss_oracle 0.3326 (0.3226) acc 84.3750 (82.4805) kd_loss 1.0042 (1.0824) lr 8.7467e-04 eta 0:06:28
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,860
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,973
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 89.2%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [29/50] batch [20/160] time 0.109 (0.134) data 0.000 (0.016) loss 0.8979 (0.8644) ce_loss 0.4756 (0.4958) teacher_loss 0.4723 (0.4774) loss_zs_kd 0.2242 (0.1225) loss_oracle 0.3134 (0.3258) acc 81.2500 (81.5625) kd_loss 0.9509 (1.0196) lr 8.7467e-04 eta 0:07:49
epoch [29/50] batch [40/160] time 0.118 (0.123) data 0.000 (0.008) loss 0.8337 (0.8389) ce_loss 0.4238 (0.4654) teacher_loss 0.4443 (0.4458) loss_zs_kd 0.1063 (0.1255) loss_oracle 0.3362 (0.3303) acc 87.5000 (82.8906) kd_loss 1.0469 (1.0323) lr 8.7467e-04 eta 0:07:08
epoch [29/50] batch [60/160] time 0.133 (0.120) data 0.001 (0.006) loss 0.8885 (0.8250) ce_loss 0.5132 (0.4494) teacher_loss 0.5128 (0.4298) loss_zs_kd 0.1163 (0.1265) loss_oracle 0.3175 (0.3319) acc 78.1250 (83.5938) kd_loss 1.1059 (1.0463) lr 8.7467e-04 eta 0:06:55
epoch [29/50] batch [80/160] time 0.108 (0.119) data 0.000 (0.004) loss 0.6252 (0.8228) ce_loss 0.3286 (0.4545) teacher_loss 0.2822 (0.4303) loss_zs_kd 0.1027 (0.1257) loss_oracle 0.2916 (0.3297) acc 84.3750 (83.2031) kd_loss 1.0973 (1.0496) lr 8.7467e-04 eta 0:06:49
epoch [29/50] batch [100/160] time 0.132 (0.118) data 0.000 (0.003) loss 0.8871 (0.8246) ce_loss 0.5308 (0.4610) teacher_loss 0.4900 (0.4336) loss_zs_kd 0.1459 (0.1249) loss_oracle 0.3242 (0.3286) acc 81.2500 (83.1562) kd_loss 1.1436 (1.0555) lr 8.7467e-04 eta 0:06:43
epoch [29/50] batch [120/160] time 0.111 (0.116) data 0.000 (0.003) loss 0.9209 (0.8369) ce_loss 0.5293 (0.4701) teacher_loss 0.5190 (0.4436) loss_zs_kd 0.1440 (0.1256) loss_oracle 0.3298 (0.3306) acc 75.0000 (82.5000) kd_loss 1.0432 (1.0551) lr 8.7467e-04 eta 0:06:35
epoch [29/50] batch [140/160] time 0.105 (0.114) data 0.000 (0.002) loss 0.9763 (0.8467) ce_loss 0.6519 (0.4757) teacher_loss 0.6215 (0.4510) loss_zs_kd 0.0806 (0.1257) loss_oracle 0.3145 (0.3329) acc 78.1250 (82.3661) kd_loss 0.9594 (1.0504) lr 8.7467e-04 eta 0:06:24
epoch [29/50] batch [160/160] time 0.091 (0.110) data 0.000 (0.002) loss 0.8689 (0.8505) ce_loss 0.4575 (0.4775) teacher_loss 0.4453 (0.4538) loss_zs_kd 0.1097 (0.1240) loss_oracle 0.3688 (0.3347) acc 81.2500 (82.3242) kd_loss 1.0993 (1.0473) lr 8.1262e-04 eta 0:06:10
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,859
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,945
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 88.5%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [30/50] batch [20/160] time 0.143 (0.131) data 0.000 (0.016) loss 0.9912 (0.9029) ce_loss 0.6353 (0.5109) teacher_loss 0.6123 (0.5035) loss_zs_kd 0.1466 (0.1118) loss_oracle 0.3057 (0.3436) acc 75.0000 (80.1562) kd_loss 1.0937 (1.0240) lr 8.1262e-04 eta 0:07:18
epoch [30/50] batch [40/160] time 0.134 (0.120) data 0.000 (0.008) loss 0.8410 (0.8543) ce_loss 0.5137 (0.4658) teacher_loss 0.5095 (0.4588) loss_zs_kd 0.0962 (0.1150) loss_oracle 0.2834 (0.3380) acc 75.0000 (82.9688) kd_loss 0.9572 (1.0307) lr 8.1262e-04 eta 0:06:39
epoch [30/50] batch [60/160] time 0.133 (0.119) data 0.001 (0.006) loss 0.7865 (0.8550) ce_loss 0.3635 (0.4658) teacher_loss 0.3433 (0.4572) loss_zs_kd 0.1062 (0.1157) loss_oracle 0.3902 (0.3400) acc 90.6250 (83.1771) kd_loss 1.0137 (1.0315) lr 8.1262e-04 eta 0:06:31
epoch [30/50] batch [80/160] time 0.159 (0.118) data 0.000 (0.004) loss 1.1265 (0.8679) ce_loss 0.6270 (0.4775) teacher_loss 0.6854 (0.4670) loss_zs_kd 0.1384 (0.1203) loss_oracle 0.3719 (0.3408) acc 71.8750 (82.7344) kd_loss 0.9732 (1.0277) lr 8.1262e-04 eta 0:06:26
epoch [30/50] batch [100/160] time 0.076 (0.122) data 0.000 (0.003) loss 0.8555 (0.8621) ce_loss 0.4453 (0.4724) teacher_loss 0.4630 (0.4605) loss_zs_kd 0.1439 (0.1217) loss_oracle 0.3206 (0.3407) acc 84.3750 (82.7500) kd_loss 0.9429 (1.0261) lr 8.1262e-04 eta 0:06:36
epoch [30/50] batch [120/160] time 0.194 (0.122) data 0.000 (0.003) loss 0.6085 (0.8583) ce_loss 0.2419 (0.4702) teacher_loss 0.2326 (0.4575) loss_zs_kd 0.0904 (0.1219) loss_oracle 0.3307 (0.3398) acc 93.7500 (82.9948) kd_loss 1.0181 (1.0292) lr 8.1262e-04 eta 0:06:36
epoch [30/50] batch [140/160] time 0.087 (0.124) data 0.000 (0.003) loss 0.9211 (0.8550) ce_loss 0.5093 (0.4705) teacher_loss 0.5163 (0.4561) loss_zs_kd 0.1323 (0.1214) loss_oracle 0.3386 (0.3383) acc 87.5000 (83.0580) kd_loss 1.0479 (1.0295) lr 8.1262e-04 eta 0:06:40
epoch [30/50] batch [160/160] time 0.075 (0.122) data 0.000 (0.002) loss 1.0882 (0.8579) ce_loss 0.7300 (0.4751) teacher_loss 0.6794 (0.4594) loss_zs_kd 0.1130 (0.1215) loss_oracle 0.3523 (0.3377) acc 71.8750 (82.8516) kd_loss 1.1408 (1.0303) lr 7.5131e-04 eta 0:06:31
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,860
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,966
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.0%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [31/50] batch [20/160] time 0.083 (0.129) data 0.000 (0.015) loss 1.1190 (0.8603) ce_loss 0.7212 (0.4843) teacher_loss 0.7078 (0.4641) loss_zs_kd 0.1501 (0.1120) loss_oracle 0.3361 (0.3402) acc 81.2500 (82.8125) kd_loss 1.0533 (1.0374) lr 7.5131e-04 eta 0:06:49
epoch [31/50] batch [40/160] time 0.135 (0.121) data 0.000 (0.008) loss 0.7507 (0.8870) ce_loss 0.3662 (0.5047) teacher_loss 0.3587 (0.4898) loss_zs_kd 0.1138 (0.1213) loss_oracle 0.3350 (0.3365) acc 87.5000 (81.4062) kd_loss 1.0713 (1.0367) lr 7.5131e-04 eta 0:06:21
epoch [31/50] batch [60/160] time 0.127 (0.119) data 0.001 (0.005) loss 0.9052 (0.8686) ce_loss 0.4944 (0.4845) teacher_loss 0.4588 (0.4709) loss_zs_kd 0.1434 (0.1215) loss_oracle 0.3746 (0.3370) acc 78.1250 (81.8229) kd_loss 1.1060 (1.0400) lr 7.5131e-04 eta 0:06:12
epoch [31/50] batch [80/160] time 0.135 (0.118) data 0.000 (0.004) loss 0.8544 (0.8736) ce_loss 0.3928 (0.4830) teacher_loss 0.3536 (0.4704) loss_zs_kd 0.1571 (0.1233) loss_oracle 0.4223 (0.3415) acc 84.3750 (81.8359) kd_loss 0.9482 (1.0334) lr 7.5131e-04 eta 0:06:07
epoch [31/50] batch [100/160] time 0.140 (0.117) data 0.000 (0.003) loss 0.7166 (0.8690) ce_loss 0.2842 (0.4768) teacher_loss 0.2622 (0.4640) loss_zs_kd 0.1082 (0.1248) loss_oracle 0.4003 (0.3427) acc 87.5000 (82.1875) kd_loss 1.0046 (1.0286) lr 7.5131e-04 eta 0:06:02
epoch [31/50] batch [120/160] time 0.101 (0.116) data 0.000 (0.003) loss 1.0621 (0.8719) ce_loss 0.7090 (0.4793) teacher_loss 0.6437 (0.4666) loss_zs_kd 0.1116 (0.1243) loss_oracle 0.3626 (0.3431) acc 78.1250 (82.2917) kd_loss 0.9823 (1.0229) lr 7.5131e-04 eta 0:05:57
epoch [31/50] batch [140/160] time 0.101 (0.114) data 0.001 (0.002) loss 0.8124 (0.8728) ce_loss 0.4666 (0.4797) teacher_loss 0.3931 (0.4674) loss_zs_kd 0.0912 (0.1229) loss_oracle 0.3737 (0.3439) acc 87.5000 (82.1429) kd_loss 1.0325 (1.0236) lr 7.5131e-04 eta 0:05:49
epoch [31/50] batch [160/160] time 0.076 (0.112) data 0.000 (0.002) loss 0.7713 (0.8683) ce_loss 0.3452 (0.4731) teacher_loss 0.3211 (0.4614) loss_zs_kd 0.1919 (0.1239) loss_oracle 0.3542 (0.3450) acc 87.5000 (82.4219) kd_loss 1.0110 (1.0196) lr 6.9098e-04 eta 0:05:40
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,863
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,959
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.9%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [32/50] batch [20/160] time 0.133 (0.125) data 0.000 (0.015) loss 0.7954 (0.8467) ce_loss 0.3435 (0.4389) teacher_loss 0.3507 (0.4307) loss_zs_kd 0.1133 (0.1147) loss_oracle 0.3880 (0.3587) acc 84.3750 (85.0000) kd_loss 1.0676 (1.0318) lr 6.9098e-04 eta 0:06:17
epoch [32/50] batch [40/160] time 0.085 (0.115) data 0.000 (0.008) loss 0.9658 (0.8922) ce_loss 0.5610 (0.4901) teacher_loss 0.5478 (0.4809) loss_zs_kd 0.1495 (0.1190) loss_oracle 0.3432 (0.3518) acc 78.1250 (82.3438) kd_loss 1.0721 (1.0315) lr 6.9098e-04 eta 0:05:44
epoch [32/50] batch [60/160] time 0.079 (0.113) data 0.001 (0.005) loss 0.7876 (0.8954) ce_loss 0.3752 (0.4906) teacher_loss 0.3664 (0.4853) loss_zs_kd 0.1280 (0.1217) loss_oracle 0.3572 (0.3493) acc 81.2500 (82.0833) kd_loss 1.1213 (1.0398) lr 6.9098e-04 eta 0:05:35
epoch [32/50] batch [80/160] time 0.077 (0.112) data 0.000 (0.004) loss 0.8479 (0.8690) ce_loss 0.4365 (0.4657) teacher_loss 0.4218 (0.4608) loss_zs_kd 0.1288 (0.1224) loss_oracle 0.3616 (0.3470) acc 87.5000 (83.1641) kd_loss 1.0819 (1.0449) lr 6.9098e-04 eta 0:05:31
epoch [32/50] batch [100/160] time 0.178 (0.118) data 0.000 (0.003) loss 0.7738 (0.8721) ce_loss 0.3855 (0.4720) teacher_loss 0.3388 (0.4658) loss_zs_kd 0.1515 (0.1240) loss_oracle 0.3593 (0.3443) acc 90.6250 (82.7500) kd_loss 0.9740 (1.0461) lr 6.9098e-04 eta 0:05:48
epoch [32/50] batch [120/160] time 0.116 (0.119) data 0.000 (0.003) loss 0.9284 (0.8694) ce_loss 0.5420 (0.4727) teacher_loss 0.5498 (0.4663) loss_zs_kd 0.1087 (0.1223) loss_oracle 0.3242 (0.3420) acc 78.1250 (82.9167) kd_loss 0.9631 (1.0504) lr 6.9098e-04 eta 0:05:47
epoch [32/50] batch [140/160] time 0.148 (0.123) data 0.000 (0.002) loss 0.8572 (0.8629) ce_loss 0.4963 (0.4674) teacher_loss 0.4456 (0.4600) loss_zs_kd 0.1904 (0.1228) loss_oracle 0.3163 (0.3415) acc 84.3750 (83.1920) kd_loss 1.0458 (1.0512) lr 6.9098e-04 eta 0:05:56
epoch [32/50] batch [160/160] time 0.076 (0.118) data 0.000 (0.002) loss 0.7851 (0.8631) ce_loss 0.4031 (0.4696) teacher_loss 0.4007 (0.4616) loss_zs_kd 0.1668 (0.1232) loss_oracle 0.3010 (0.3400) acc 84.3750 (82.8516) kd_loss 0.9747 (1.0516) lr 6.3188e-04 eta 0:05:39
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,862
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,955
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 88.8%
******* Domain p best val acc:      84.5%, epoch: 17 *******
******* Domain p best val test acc: 87.5%, epoch: 17 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [33/50] batch [20/160] time 0.090 (0.127) data 0.000 (0.017) loss 0.7757 (0.8275) ce_loss 0.4690 (0.4564) teacher_loss 0.4068 (0.4338) loss_zs_kd 0.1142 (0.1333) loss_oracle 0.3118 (0.3270) acc 81.2500 (83.1250) kd_loss 1.0496 (1.0816) lr 6.3188e-04 eta 0:06:03
epoch [33/50] batch [40/160] time 0.125 (0.117) data 0.000 (0.008) loss 0.8975 (0.8425) ce_loss 0.5874 (0.4718) teacher_loss 0.4902 (0.4476) loss_zs_kd 0.1395 (0.1274) loss_oracle 0.3375 (0.3312) acc 81.2500 (81.6406) kd_loss 1.0607 (1.0595) lr 6.3188e-04 eta 0:05:32
epoch [33/50] batch [60/160] time 0.133 (0.113) data 0.001 (0.006) loss 1.0661 (0.8552) ce_loss 0.6641 (0.4821) teacher_loss 0.6987 (0.4589) loss_zs_kd 0.1270 (0.1272) loss_oracle 0.3038 (0.3327) acc 84.3750 (82.0312) kd_loss 1.0428 (1.0520) lr 6.3188e-04 eta 0:05:18
epoch [33/50] batch [80/160] time 0.116 (0.112) data 0.000 (0.004) loss 0.8498 (0.8480) ce_loss 0.4519 (0.4732) teacher_loss 0.4514 (0.4543) loss_zs_kd 0.0993 (0.1218) loss_oracle 0.3487 (0.3327) acc 84.3750 (81.8359) kd_loss 1.0286 (1.0516) lr 6.3188e-04 eta 0:05:12
epoch [33/50] batch [100/160] time 0.086 (0.111) data 0.000 (0.004) loss 0.7247 (0.8468) ce_loss 0.3845 (0.4716) teacher_loss 0.3642 (0.4541) loss_zs_kd 0.0803 (0.1194) loss_oracle 0.3204 (0.3330) acc 90.6250 (82.0312) kd_loss 1.0422 (1.0495) lr 6.3188e-04 eta 0:05:07
epoch [33/50] batch [120/160] time 0.114 (0.110) data 0.000 (0.003) loss 0.9591 (0.8492) ce_loss 0.5278 (0.4756) teacher_loss 0.5582 (0.4574) loss_zs_kd 0.1916 (0.1205) loss_oracle 0.3051 (0.3316) acc 71.8750 (82.1875) kd_loss 1.0386 (1.0472) lr 6.3188e-04 eta 0:05:03
epoch [33/50] batch [140/160] time 0.089 (0.110) data 0.000 (0.003) loss 0.9539 (0.8513) ce_loss 0.6060 (0.4774) teacher_loss 0.5555 (0.4583) loss_zs_kd 0.1035 (0.1206) loss_oracle 0.3467 (0.3327) acc 87.5000 (82.2545) kd_loss 1.0274 (1.0474) lr 6.3188e-04 eta 0:05:00
epoch [33/50] batch [160/160] time 0.082 (0.109) data 0.000 (0.002) loss 0.6241 (0.8472) ce_loss 0.2397 (0.4731) teacher_loss 0.2295 (0.4541) loss_zs_kd 0.0929 (0.1216) loss_oracle 0.3481 (0.3324) acc 93.7500 (82.5000) kd_loss 1.0287 (1.0523) lr 5.7422e-04 eta 0:04:55
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,868
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 85.7%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,951
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.7%
******* Domain p best val acc:      84.7%, epoch: 33 *******
******* Domain p best val test acc: 87.4%, epoch: 33 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [34/50] batch [20/160] time 0.137 (0.128) data 0.000 (0.013) loss 0.7705 (0.7993) ce_loss 0.3677 (0.4400) teacher_loss 0.3663 (0.4255) loss_zs_kd 0.1197 (0.1128) loss_oracle 0.3444 (0.3174) acc 87.5000 (83.4375) kd_loss 1.1627 (1.0778) lr 5.7422e-04 eta 0:05:45
epoch [34/50] batch [40/160] time 0.108 (0.117) data 0.000 (0.006) loss 0.7938 (0.8365) ce_loss 0.3569 (0.4677) teacher_loss 0.3576 (0.4560) loss_zs_kd 0.1715 (0.1188) loss_oracle 0.3505 (0.3211) acc 93.7500 (82.3438) kd_loss 1.0173 (1.0568) lr 5.7422e-04 eta 0:05:14
epoch [34/50] batch [60/160] time 0.132 (0.115) data 0.001 (0.004) loss 0.9979 (0.8504) ce_loss 0.6050 (0.4828) teacher_loss 0.6166 (0.4705) loss_zs_kd 0.1273 (0.1210) loss_oracle 0.3176 (0.3194) acc 78.1250 (82.2917) kd_loss 1.0373 (1.0586) lr 5.7422e-04 eta 0:05:06
epoch [34/50] batch [80/160] time 0.110 (0.113) data 0.000 (0.003) loss 0.9834 (0.8503) ce_loss 0.5933 (0.4818) teacher_loss 0.6342 (0.4711) loss_zs_kd 0.1055 (0.1218) loss_oracle 0.2965 (0.3183) acc 71.8750 (82.1094) kd_loss 1.1418 (1.0623) lr 5.7422e-04 eta 0:04:59
epoch [34/50] batch [100/160] time 0.107 (0.111) data 0.001 (0.003) loss 0.6451 (0.8487) ce_loss 0.2917 (0.4831) teacher_loss 0.3019 (0.4698) loss_zs_kd 0.0943 (0.1210) loss_oracle 0.2961 (0.3184) acc 96.8750 (82.3750) kd_loss 1.0321 (1.0634) lr 5.7422e-04 eta 0:04:51
epoch [34/50] batch [120/160] time 0.151 (0.116) data 0.000 (0.002) loss 0.8248 (0.8487) ce_loss 0.5410 (0.4869) teacher_loss 0.4521 (0.4705) loss_zs_kd 0.1242 (0.1210) loss_oracle 0.3107 (0.3177) acc 68.7500 (82.1094) kd_loss 1.0106 (1.0629) lr 5.7422e-04 eta 0:05:00
epoch [34/50] batch [140/160] time 0.143 (0.115) data 0.000 (0.002) loss 1.0789 (0.8372) ce_loss 0.7090 (0.4755) teacher_loss 0.6725 (0.4574) loss_zs_kd 0.1561 (0.1203) loss_oracle 0.3283 (0.3196) acc 75.0000 (82.6116) kd_loss 1.0016 (1.0655) lr 5.7422e-04 eta 0:04:55
epoch [34/50] batch [160/160] time 0.170 (0.117) data 0.000 (0.002) loss 0.9406 (0.8377) ce_loss 0.5342 (0.4725) teacher_loss 0.5263 (0.4555) loss_zs_kd 0.1200 (0.1203) loss_oracle 0.3542 (0.3220) acc 78.1250 (82.7734) kd_loss 1.0820 (1.0664) lr 5.1825e-04 eta 0:05:00
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,860
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,956
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.8%
******* Domain p best val acc:      84.7%, epoch: 33 *******
******* Domain p best val test acc: 87.4%, epoch: 33 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [35/50] batch [20/160] time 0.125 (0.117) data 0.000 (0.014) loss 0.6163 (0.8669) ce_loss 0.2463 (0.4979) teacher_loss 0.2493 (0.4854) loss_zs_kd 0.1036 (0.1189) loss_oracle 0.3152 (0.3220) acc 93.7500 (81.7188) kd_loss 1.0789 (1.0401) lr 5.1825e-04 eta 0:04:56
epoch [35/50] batch [40/160] time 0.081 (0.112) data 0.000 (0.007) loss 0.6647 (0.8390) ce_loss 0.3857 (0.4758) teacher_loss 0.3382 (0.4587) loss_zs_kd 0.0811 (0.1142) loss_oracle 0.2860 (0.3233) acc 87.5000 (82.4219) kd_loss 1.0742 (1.0498) lr 5.1825e-04 eta 0:04:41
epoch [35/50] batch [60/160] time 0.101 (0.110) data 0.001 (0.005) loss 0.7541 (0.8142) ce_loss 0.3984 (0.4463) teacher_loss 0.3927 (0.4289) loss_zs_kd 0.0987 (0.1149) loss_oracle 0.3121 (0.3278) acc 84.3750 (84.2708) kd_loss 1.2031 (1.0476) lr 5.1825e-04 eta 0:04:35
epoch [35/50] batch [80/160] time 0.126 (0.110) data 0.000 (0.004) loss 1.0360 (0.8434) ce_loss 0.6592 (0.4719) teacher_loss 0.6234 (0.4532) loss_zs_kd 0.1394 (0.1174) loss_oracle 0.3429 (0.3315) acc 75.0000 (83.0859) kd_loss 1.0142 (1.0536) lr 5.1825e-04 eta 0:04:33
epoch [35/50] batch [100/160] time 0.092 (0.111) data 0.000 (0.003) loss 0.8709 (0.8435) ce_loss 0.5430 (0.4708) teacher_loss 0.5537 (0.4527) loss_zs_kd 0.0688 (0.1182) loss_oracle 0.2828 (0.3317) acc 87.5000 (83.4062) kd_loss 1.1379 (1.0601) lr 5.1825e-04 eta 0:04:32
epoch [35/50] batch [120/160] time 0.089 (0.111) data 0.000 (0.003) loss 0.8369 (0.8473) ce_loss 0.4329 (0.4709) teacher_loss 0.4309 (0.4524) loss_zs_kd 0.1642 (0.1210) loss_oracle 0.3239 (0.3344) acc 84.3750 (83.2292) kd_loss 1.0307 (1.0565) lr 5.1825e-04 eta 0:04:29
epoch [35/50] batch [140/160] time 0.117 (0.111) data 0.000 (0.002) loss 1.0326 (0.8470) ce_loss 0.6836 (0.4694) teacher_loss 0.6558 (0.4519) loss_zs_kd 0.1394 (0.1202) loss_oracle 0.3071 (0.3350) acc 71.8750 (83.0804) kd_loss 0.9724 (1.0535) lr 5.1825e-04 eta 0:04:28
epoch [35/50] batch [160/160] time 0.093 (0.109) data 0.000 (0.002) loss 0.8207 (0.8490) ce_loss 0.4265 (0.4708) teacher_loss 0.4129 (0.4535) loss_zs_kd 0.1424 (0.1208) loss_oracle 0.3366 (0.3351) acc 87.5000 (82.9102) kd_loss 1.0269 (1.0541) lr 4.6417e-04 eta 0:04:22
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,867
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,960
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.9%
******* Domain p best val acc:      84.7%, epoch: 33 *******
******* Domain p best val test acc: 87.4%, epoch: 33 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [36/50] batch [20/160] time 0.111 (0.107) data 0.000 (0.013) loss 0.8113 (0.8322) ce_loss 0.4590 (0.4531) teacher_loss 0.4550 (0.4325) loss_zs_kd 0.1129 (0.1257) loss_oracle 0.2998 (0.3368) acc 78.1250 (82.8125) kd_loss 1.0208 (1.0420) lr 4.6417e-04 eta 0:04:14
epoch [36/50] batch [40/160] time 0.106 (0.106) data 0.000 (0.007) loss 0.8421 (0.8447) ce_loss 0.4512 (0.4593) teacher_loss 0.4217 (0.4481) loss_zs_kd 0.0991 (0.1233) loss_oracle 0.3709 (0.3349) acc 90.6250 (83.0469) kd_loss 1.0677 (1.0498) lr 4.6417e-04 eta 0:04:09
epoch [36/50] batch [60/160] time 0.112 (0.105) data 0.001 (0.005) loss 0.6623 (0.8436) ce_loss 0.3472 (0.4659) teacher_loss 0.3079 (0.4532) loss_zs_kd 0.1053 (0.1202) loss_oracle 0.3018 (0.3303) acc 87.5000 (82.4479) kd_loss 1.0478 (1.0500) lr 4.6417e-04 eta 0:04:04
epoch [36/50] batch [80/160] time 0.118 (0.108) data 0.000 (0.004) loss 0.6874 (0.8485) ce_loss 0.3538 (0.4700) teacher_loss 0.3467 (0.4576) loss_zs_kd 0.1313 (0.1187) loss_oracle 0.2751 (0.3315) acc 84.3750 (82.4219) kd_loss 1.0159 (1.0520) lr 4.6417e-04 eta 0:04:11
epoch [36/50] batch [100/160] time 0.145 (0.111) data 0.000 (0.003) loss 0.7975 (0.8455) ce_loss 0.4580 (0.4702) teacher_loss 0.4343 (0.4549) loss_zs_kd 0.0975 (0.1194) loss_oracle 0.3144 (0.3308) acc 84.3750 (82.5000) kd_loss 1.1248 (1.0551) lr 4.6417e-04 eta 0:04:14
epoch [36/50] batch [120/160] time 0.081 (0.111) data 0.000 (0.002) loss 0.7335 (0.8454) ce_loss 0.3159 (0.4690) teacher_loss 0.3032 (0.4529) loss_zs_kd 0.1339 (0.1210) loss_oracle 0.3633 (0.3320) acc 87.5000 (82.6042) kd_loss 1.0212 (1.0561) lr 4.6417e-04 eta 0:04:14
epoch [36/50] batch [140/160] time 0.149 (0.114) data 0.000 (0.002) loss 0.7824 (0.8416) ce_loss 0.4097 (0.4677) teacher_loss 0.3684 (0.4512) loss_zs_kd 0.1527 (0.1203) loss_oracle 0.3376 (0.3302) acc 87.5000 (82.7009) kd_loss 1.1274 (1.0555) lr 4.6417e-04 eta 0:04:17
epoch [36/50] batch [160/160] time 0.124 (0.114) data 0.000 (0.002) loss 0.9131 (0.8375) ce_loss 0.4968 (0.4615) teacher_loss 0.4920 (0.4441) loss_zs_kd 0.1435 (0.1224) loss_oracle 0.3494 (0.3322) acc 81.2500 (82.9492) kd_loss 1.0519 (1.0546) lr 4.1221e-04 eta 0:04:16
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,861
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,961
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.9%
******* Domain p best val acc:      84.7%, epoch: 33 *******
******* Domain p best val test acc: 87.4%, epoch: 33 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [37/50] batch [20/160] time 0.080 (0.124) data 0.000 (0.017) loss 0.8087 (0.8513) ce_loss 0.4446 (0.4757) teacher_loss 0.4016 (0.4574) loss_zs_kd 0.1620 (0.1401) loss_oracle 0.3261 (0.3239) acc 84.3750 (82.9688) kd_loss 1.0370 (1.0336) lr 4.1221e-04 eta 0:04:35
epoch [37/50] batch [40/160] time 0.142 (0.114) data 0.000 (0.009) loss 0.8624 (0.8204) ce_loss 0.4424 (0.4446) teacher_loss 0.4340 (0.4289) loss_zs_kd 0.1089 (0.1255) loss_oracle 0.3740 (0.3287) acc 84.3750 (84.1406) kd_loss 1.0229 (1.0335) lr 4.1221e-04 eta 0:04:10
epoch [37/50] batch [60/160] time 0.097 (0.108) data 0.001 (0.006) loss 0.8477 (0.8237) ce_loss 0.4644 (0.4415) teacher_loss 0.4667 (0.4290) loss_zs_kd 0.1130 (0.1269) loss_oracle 0.3245 (0.3313) acc 84.3750 (84.1146) kd_loss 1.0110 (1.0388) lr 4.1221e-04 eta 0:03:55
epoch [37/50] batch [80/160] time 0.085 (0.104) data 0.000 (0.005) loss 0.8803 (0.8331) ce_loss 0.5293 (0.4489) teacher_loss 0.5337 (0.4366) loss_zs_kd 0.1138 (0.1267) loss_oracle 0.2897 (0.3332) acc 78.1250 (83.9062) kd_loss 0.9896 (1.0388) lr 4.1221e-04 eta 0:03:45
epoch [37/50] batch [100/160] time 0.117 (0.104) data 0.000 (0.004) loss 1.2358 (0.8290) ce_loss 0.7886 (0.4458) teacher_loss 0.8484 (0.4328) loss_zs_kd 0.1985 (0.1255) loss_oracle 0.2881 (0.3335) acc 75.0000 (84.0938) kd_loss 1.0163 (1.0374) lr 4.1221e-04 eta 0:03:43
epoch [37/50] batch [120/160] time 0.080 (0.106) data 0.000 (0.003) loss 0.7618 (0.8441) ce_loss 0.3120 (0.4578) teacher_loss 0.3202 (0.4458) loss_zs_kd 0.1510 (0.1285) loss_oracle 0.3661 (0.3340) acc 90.6250 (83.4115) kd_loss 1.1162 (1.0362) lr 4.1221e-04 eta 0:03:44
epoch [37/50] batch [140/160] time 0.113 (0.106) data 0.000 (0.003) loss 0.9239 (0.8410) ce_loss 0.5156 (0.4558) teacher_loss 0.4745 (0.4424) loss_zs_kd 0.1240 (0.1279) loss_oracle 0.3873 (0.3346) acc 81.2500 (83.5714) kd_loss 1.0888 (1.0357) lr 4.1221e-04 eta 0:03:42
epoch [37/50] batch [160/160] time 0.080 (0.104) data 0.000 (0.002) loss 0.8584 (0.8494) ce_loss 0.4990 (0.4633) teacher_loss 0.4927 (0.4503) loss_zs_kd 0.0859 (0.1269) loss_oracle 0.3227 (0.3356) acc 84.3750 (83.3594) kd_loss 1.0153 (1.0362) lr 3.6258e-04 eta 0:03:36
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,859
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.8%
******* Domain p best val acc:      84.7%, epoch: 33 *******
******* Domain p best val test acc: 87.4%, epoch: 33 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [38/50] batch [20/160] time 0.098 (0.124) data 0.000 (0.016) loss 0.9595 (0.8825) ce_loss 0.5859 (0.4877) teacher_loss 0.5310 (0.4803) loss_zs_kd 0.1464 (0.1183) loss_oracle 0.3553 (0.3430) acc 78.1250 (82.0312) kd_loss 0.9324 (1.0047) lr 3.6258e-04 eta 0:04:15
epoch [38/50] batch [40/160] time 0.079 (0.108) data 0.000 (0.008) loss 0.9515 (0.8908) ce_loss 0.5098 (0.4938) teacher_loss 0.5295 (0.4880) loss_zs_kd 0.1640 (0.1237) loss_oracle 0.3400 (0.3410) acc 78.1250 (82.5781) kd_loss 0.9121 (1.0062) lr 3.6258e-04 eta 0:03:39
epoch [38/50] batch [60/160] time 0.078 (0.103) data 0.001 (0.006) loss 0.8651 (0.8744) ce_loss 0.4490 (0.4784) teacher_loss 0.4559 (0.4686) loss_zs_kd 0.1154 (0.1240) loss_oracle 0.3515 (0.3438) acc 87.5000 (82.8646) kd_loss 1.0307 (1.0135) lr 3.6258e-04 eta 0:03:28
epoch [38/50] batch [80/160] time 0.081 (0.103) data 0.000 (0.004) loss 0.9648 (0.8649) ce_loss 0.5908 (0.4730) teacher_loss 0.5756 (0.4633) loss_zs_kd 0.1114 (0.1245) loss_oracle 0.3336 (0.3394) acc 71.8750 (82.4219) kd_loss 1.0197 (1.0164) lr 3.6258e-04 eta 0:03:25
epoch [38/50] batch [100/160] time 0.097 (0.100) data 0.000 (0.003) loss 0.8107 (0.8606) ce_loss 0.4504 (0.4695) teacher_loss 0.4517 (0.4597) loss_zs_kd 0.0935 (0.1225) loss_oracle 0.3122 (0.3397) acc 78.1250 (82.5000) kd_loss 1.0872 (1.0172) lr 3.6258e-04 eta 0:03:18
epoch [38/50] batch [120/160] time 0.097 (0.101) data 0.001 (0.003) loss 0.8602 (0.8554) ce_loss 0.4937 (0.4668) teacher_loss 0.4776 (0.4575) loss_zs_kd 0.1332 (0.1205) loss_oracle 0.3160 (0.3377) acc 84.3750 (82.6562) kd_loss 0.9862 (1.0169) lr 3.6258e-04 eta 0:03:17
epoch [38/50] batch [140/160] time 0.094 (0.101) data 0.000 (0.003) loss 0.7476 (0.8565) ce_loss 0.3193 (0.4672) teacher_loss 0.3073 (0.4576) loss_zs_kd 0.1258 (0.1211) loss_oracle 0.3774 (0.3383) acc 87.5000 (82.7232) kd_loss 1.0531 (1.0178) lr 3.6258e-04 eta 0:03:15
epoch [38/50] batch [160/160] time 0.093 (0.101) data 0.000 (0.002) loss 0.7469 (0.8550) ce_loss 0.4114 (0.4695) teacher_loss 0.3623 (0.4580) loss_zs_kd 0.0907 (0.1208) loss_oracle 0.3393 (0.3366) acc 87.5000 (82.6758) kd_loss 0.9972 (1.0171) lr 3.1545e-04 eta 0:03:14
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,866
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,953
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 88.7%
******* Domain p best val acc:      84.7%, epoch: 33 *******
******* Domain p best val test acc: 87.4%, epoch: 33 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [39/50] batch [20/160] time 0.174 (0.162) data 0.000 (0.017) loss 0.6049 (0.8516) ce_loss 0.2394 (0.4583) teacher_loss 0.2544 (0.4492) loss_zs_kd 0.0711 (0.1261) loss_oracle 0.3150 (0.3393) acc 93.7500 (83.7500) kd_loss 0.9844 (1.0208) lr 3.1545e-04 eta 0:05:08
epoch [39/50] batch [40/160] time 0.133 (0.134) data 0.000 (0.009) loss 0.8154 (0.8685) ce_loss 0.4514 (0.4727) teacher_loss 0.4332 (0.4625) loss_zs_kd 0.1172 (0.1263) loss_oracle 0.3236 (0.3429) acc 87.5000 (82.8906) kd_loss 1.0661 (1.0208) lr 3.1545e-04 eta 0:04:11
epoch [39/50] batch [60/160] time 0.086 (0.125) data 0.001 (0.006) loss 0.7477 (0.8610) ce_loss 0.3862 (0.4650) teacher_loss 0.3757 (0.4533) loss_zs_kd 0.0855 (0.1290) loss_oracle 0.3292 (0.3432) acc 87.5000 (83.0729) kd_loss 1.0308 (1.0184) lr 3.1545e-04 eta 0:03:51
epoch [39/50] batch [80/160] time 0.088 (0.116) data 0.000 (0.004) loss 0.8138 (0.8650) ce_loss 0.4592 (0.4705) teacher_loss 0.4152 (0.4563) loss_zs_kd 0.1344 (0.1274) loss_oracle 0.3314 (0.3449) acc 87.5000 (82.9297) kd_loss 1.0147 (1.0231) lr 3.1545e-04 eta 0:03:34
epoch [39/50] batch [100/160] time 0.105 (0.112) data 0.000 (0.004) loss 0.6923 (0.8673) ce_loss 0.2520 (0.4701) teacher_loss 0.2650 (0.4584) loss_zs_kd 0.1150 (0.1280) loss_oracle 0.3699 (0.3449) acc 90.6250 (83.0625) kd_loss 1.0575 (1.0255) lr 3.1545e-04 eta 0:03:23
epoch [39/50] batch [120/160] time 0.105 (0.108) data 0.000 (0.003) loss 0.8407 (0.8694) ce_loss 0.5161 (0.4734) teacher_loss 0.4794 (0.4621) loss_zs_kd 0.1327 (0.1284) loss_oracle 0.2949 (0.3431) acc 87.5000 (82.5260) kd_loss 0.9568 (1.0260) lr 3.1545e-04 eta 0:03:15
epoch [39/50] batch [140/160] time 0.077 (0.106) data 0.000 (0.003) loss 0.5712 (0.8669) ce_loss 0.2180 (0.4709) teacher_loss 0.2157 (0.4612) loss_zs_kd 0.0713 (0.1263) loss_oracle 0.3199 (0.3425) acc 90.6250 (82.4330) kd_loss 1.0665 (1.0290) lr 3.1545e-04 eta 0:03:07
epoch [39/50] batch [160/160] time 0.077 (0.103) data 0.000 (0.002) loss 0.7690 (0.8642) ce_loss 0.3464 (0.4677) teacher_loss 0.3558 (0.4583) loss_zs_kd 0.1792 (0.1267) loss_oracle 0.3236 (0.3426) acc 90.6250 (82.7930) kd_loss 1.0593 (1.0297) lr 2.7103e-04 eta 0:03:01
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,864
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,956
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.7%
******* Domain p best val acc:      84.7%, epoch: 33 *******
******* Domain p best val test acc: 87.4%, epoch: 33 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [40/50] batch [20/160] time 0.089 (0.110) data 0.000 (0.015) loss 0.6980 (0.8156) ce_loss 0.3345 (0.4249) teacher_loss 0.3172 (0.4168) loss_zs_kd 0.1236 (0.1202) loss_oracle 0.3190 (0.3387) acc 87.5000 (84.6875) kd_loss 0.9991 (1.0305) lr 2.7103e-04 eta 0:03:11
epoch [40/50] batch [40/160] time 0.071 (0.100) data 0.000 (0.008) loss 0.8744 (0.8131) ce_loss 0.5210 (0.4327) teacher_loss 0.4637 (0.4197) loss_zs_kd 0.1093 (0.1167) loss_oracle 0.3560 (0.3351) acc 78.1250 (83.9062) kd_loss 0.9725 (1.0377) lr 2.7103e-04 eta 0:02:51
epoch [40/50] batch [60/160] time 0.117 (0.096) data 0.001 (0.005) loss 0.5564 (0.8042) ce_loss 0.2433 (0.4251) teacher_loss 0.2214 (0.4115) loss_zs_kd 0.1023 (0.1196) loss_oracle 0.2839 (0.3328) acc 93.7500 (84.6354) kd_loss 1.0616 (1.0360) lr 2.7103e-04 eta 0:02:43
epoch [40/50] batch [80/160] time 0.086 (0.097) data 0.000 (0.004) loss 0.7354 (0.8226) ce_loss 0.3687 (0.4453) teacher_loss 0.3708 (0.4308) loss_zs_kd 0.1288 (0.1214) loss_oracle 0.3001 (0.3312) acc 87.5000 (83.7500) kd_loss 1.0260 (1.0365) lr 2.7103e-04 eta 0:02:42
epoch [40/50] batch [100/160] time 0.089 (0.097) data 0.000 (0.003) loss 1.1219 (0.8310) ce_loss 0.7075 (0.4554) teacher_loss 0.7235 (0.4397) loss_zs_kd 0.0878 (0.1199) loss_oracle 0.3545 (0.3313) acc 75.0000 (83.4375) kd_loss 1.0343 (1.0347) lr 2.7103e-04 eta 0:02:40
epoch [40/50] batch [120/160] time 0.079 (0.096) data 0.000 (0.003) loss 0.8243 (0.8332) ce_loss 0.4580 (0.4574) teacher_loss 0.4668 (0.4409) loss_zs_kd 0.1222 (0.1215) loss_oracle 0.2963 (0.3315) acc 87.5000 (83.2552) kd_loss 1.0780 (1.0355) lr 2.7103e-04 eta 0:02:37
epoch [40/50] batch [140/160] time 0.082 (0.097) data 0.000 (0.002) loss 0.7049 (0.8389) ce_loss 0.3035 (0.4619) teacher_loss 0.2910 (0.4465) loss_zs_kd 0.1537 (0.1217) loss_oracle 0.3371 (0.3315) acc 96.8750 (83.0580) kd_loss 1.0046 (1.0349) lr 2.7103e-04 eta 0:02:36
epoch [40/50] batch [160/160] time 0.076 (0.096) data 0.000 (0.002) loss 0.7890 (0.8443) ce_loss 0.4092 (0.4670) teacher_loss 0.4159 (0.4514) loss_zs_kd 0.1053 (0.1230) loss_oracle 0.3204 (0.3314) acc 84.3750 (82.8125) kd_loss 0.9882 (1.0356) lr 2.2949e-04 eta 0:02:33
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,867
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.8%
******* Domain p best val acc:      84.7%, epoch: 33 *******
******* Domain p best val test acc: 87.4%, epoch: 33 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [41/50] batch [20/160] time 0.086 (0.120) data 0.000 (0.016) loss 0.8435 (0.8371) ce_loss 0.4702 (0.4677) teacher_loss 0.4451 (0.4453) loss_zs_kd 0.0972 (0.1207) loss_oracle 0.3497 (0.3315) acc 84.3750 (83.5938) kd_loss 0.9367 (1.0561) lr 2.2949e-04 eta 0:03:09
epoch [41/50] batch [40/160] time 0.087 (0.109) data 0.000 (0.008) loss 0.8881 (0.8590) ce_loss 0.4929 (0.4844) teacher_loss 0.4699 (0.4669) loss_zs_kd 0.1260 (0.1178) loss_oracle 0.3552 (0.3332) acc 78.1250 (82.9688) kd_loss 1.0916 (1.0323) lr 2.2949e-04 eta 0:02:50
epoch [41/50] batch [60/160] time 0.150 (0.111) data 0.001 (0.005) loss 0.7400 (0.8489) ce_loss 0.3792 (0.4734) teacher_loss 0.3912 (0.4580) loss_zs_kd 0.0863 (0.1159) loss_oracle 0.3056 (0.3330) acc 90.6250 (83.2812) kd_loss 1.1012 (1.0315) lr 2.2949e-04 eta 0:02:50
epoch [41/50] batch [80/160] time 0.074 (0.113) data 0.000 (0.004) loss 0.7001 (0.8500) ce_loss 0.3042 (0.4735) teacher_loss 0.3305 (0.4592) loss_zs_kd 0.1060 (0.1157) loss_oracle 0.3167 (0.3330) acc 90.6250 (83.1250) kd_loss 1.0297 (1.0362) lr 2.2949e-04 eta 0:02:52
epoch [41/50] batch [100/160] time 0.106 (0.116) data 0.000 (0.003) loss 0.8815 (0.8509) ce_loss 0.4858 (0.4702) teacher_loss 0.4567 (0.4583) loss_zs_kd 0.1428 (0.1169) loss_oracle 0.3534 (0.3342) acc 78.1250 (83.1875) kd_loss 1.0486 (1.0409) lr 2.2949e-04 eta 0:02:53
epoch [41/50] batch [120/160] time 0.064 (0.116) data 0.000 (0.003) loss 0.9353 (0.8516) ce_loss 0.5312 (0.4687) teacher_loss 0.5097 (0.4584) loss_zs_kd 0.1161 (0.1163) loss_oracle 0.3675 (0.3350) acc 75.0000 (83.2812) kd_loss 1.0393 (1.0409) lr 2.2949e-04 eta 0:02:52
epoch [41/50] batch [140/160] time 0.105 (0.112) data 0.000 (0.002) loss 0.9313 (0.8560) ce_loss 0.5659 (0.4727) teacher_loss 0.5761 (0.4632) loss_zs_kd 0.0993 (0.1168) loss_oracle 0.3055 (0.3344) acc 78.1250 (83.0134) kd_loss 1.0231 (1.0359) lr 2.2949e-04 eta 0:02:43
epoch [41/50] batch [160/160] time 0.093 (0.109) data 0.000 (0.002) loss 0.8327 (0.8539) ce_loss 0.4790 (0.4707) teacher_loss 0.4521 (0.4607) loss_zs_kd 0.1513 (0.1174) loss_oracle 0.3049 (0.3345) acc 78.1250 (82.8906) kd_loss 1.0181 (1.0364) lr 1.9098e-04 eta 0:02:37
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,866
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,955
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 88.8%
******* Domain p best val acc:      84.7%, epoch: 33 *******
******* Domain p best val test acc: 87.4%, epoch: 33 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [42/50] batch [20/160] time 0.094 (0.131) data 0.000 (0.014) loss 1.0461 (0.8568) ce_loss 0.5820 (0.4587) teacher_loss 0.6347 (0.4518) loss_zs_kd 0.1360 (0.1368) loss_oracle 0.3435 (0.3366) acc 78.1250 (84.2188) kd_loss 1.0310 (1.0264) lr 1.9098e-04 eta 0:03:05
epoch [42/50] batch [40/160] time 0.083 (0.123) data 0.000 (0.007) loss 0.7071 (0.8687) ce_loss 0.3687 (0.4810) teacher_loss 0.3430 (0.4690) loss_zs_kd 0.1036 (0.1318) loss_oracle 0.3123 (0.3338) acc 84.3750 (82.1875) kd_loss 1.0524 (1.0253) lr 1.9098e-04 eta 0:02:52
epoch [42/50] batch [60/160] time 0.130 (0.120) data 0.001 (0.005) loss 0.9545 (0.8568) ce_loss 0.5366 (0.4675) teacher_loss 0.5008 (0.4563) loss_zs_kd 0.1120 (0.1259) loss_oracle 0.3977 (0.3376) acc 81.2500 (82.9688) kd_loss 1.0058 (1.0265) lr 1.9098e-04 eta 0:02:45
epoch [42/50] batch [80/160] time 0.139 (0.117) data 0.000 (0.004) loss 0.7346 (0.8366) ce_loss 0.3079 (0.4492) teacher_loss 0.3030 (0.4361) loss_zs_kd 0.1029 (0.1249) loss_oracle 0.3802 (0.3380) acc 84.3750 (83.6328) kd_loss 1.0074 (1.0199) lr 1.9098e-04 eta 0:02:39
epoch [42/50] batch [100/160] time 0.141 (0.117) data 0.000 (0.003) loss 0.7717 (0.8419) ce_loss 0.3884 (0.4523) teacher_loss 0.3709 (0.4408) loss_zs_kd 0.1043 (0.1228) loss_oracle 0.3486 (0.3396) acc 84.3750 (83.5938) kd_loss 0.9797 (1.0187) lr 1.9098e-04 eta 0:02:36
epoch [42/50] batch [120/160] time 0.124 (0.115) data 0.000 (0.003) loss 0.7063 (0.8389) ce_loss 0.3384 (0.4501) teacher_loss 0.3350 (0.4378) loss_zs_kd 0.1007 (0.1213) loss_oracle 0.3210 (0.3404) acc 84.3750 (83.5677) kd_loss 1.0452 (1.0215) lr 1.9098e-04 eta 0:02:32
epoch [42/50] batch [140/160] time 0.146 (0.114) data 0.000 (0.002) loss 1.0264 (0.8495) ce_loss 0.5859 (0.4624) teacher_loss 0.6004 (0.4503) loss_zs_kd 0.0887 (0.1216) loss_oracle 0.3817 (0.3385) acc 78.1250 (83.2366) kd_loss 0.9629 (1.0185) lr 1.9098e-04 eta 0:02:27
epoch [42/50] batch [160/160] time 0.115 (0.113) data 0.000 (0.002) loss 0.7474 (0.8469) ce_loss 0.3647 (0.4597) teacher_loss 0.3763 (0.4484) loss_zs_kd 0.1180 (0.1218) loss_oracle 0.3122 (0.3376) acc 87.5000 (83.0469) kd_loss 1.0405 (1.0173) lr 1.5567e-04 eta 0:02:24
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,867
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.8%
******* Domain p best val acc:      84.7%, epoch: 33 *******
******* Domain p best val test acc: 87.4%, epoch: 33 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [43/50] batch [20/160] time 0.085 (0.112) data 0.000 (0.013) loss 1.0062 (0.8287) ce_loss 0.5854 (0.4434) teacher_loss 0.5605 (0.4251) loss_zs_kd 0.1547 (0.1244) loss_oracle 0.3683 (0.3414) acc 81.2500 (84.2188) kd_loss 1.0186 (1.0336) lr 1.5567e-04 eta 0:02:21
epoch [43/50] batch [40/160] time 0.071 (0.103) data 0.000 (0.007) loss 0.7703 (0.8172) ce_loss 0.4590 (0.4389) teacher_loss 0.4080 (0.4224) loss_zs_kd 0.1190 (0.1240) loss_oracle 0.3027 (0.3328) acc 87.5000 (84.8438) kd_loss 1.0319 (1.0322) lr 1.5567e-04 eta 0:02:08
epoch [43/50] batch [60/160] time 0.090 (0.099) data 0.001 (0.004) loss 0.9212 (0.8300) ce_loss 0.4995 (0.4447) teacher_loss 0.4505 (0.4304) loss_zs_kd 0.1792 (0.1265) loss_oracle 0.3811 (0.3364) acc 78.1250 (84.3750) kd_loss 1.0557 (1.0224) lr 1.5567e-04 eta 0:02:01
epoch [43/50] batch [80/160] time 0.133 (0.100) data 0.000 (0.003) loss 0.7963 (0.8475) ce_loss 0.3582 (0.4580) teacher_loss 0.3598 (0.4470) loss_zs_kd 0.1773 (0.1274) loss_oracle 0.3479 (0.3368) acc 90.6250 (84.0625) kd_loss 1.0065 (1.0254) lr 1.5567e-04 eta 0:02:00
epoch [43/50] batch [100/160] time 0.154 (0.097) data 0.000 (0.003) loss 0.7456 (0.8393) ce_loss 0.2888 (0.4514) teacher_loss 0.2682 (0.4409) loss_zs_kd 0.1382 (0.1247) loss_oracle 0.4083 (0.3360) acc 87.5000 (84.0000) kd_loss 1.1131 (1.0278) lr 1.5567e-04 eta 0:01:54
epoch [43/50] batch [120/160] time 0.153 (0.104) data 0.000 (0.002) loss 0.6535 (0.8411) ce_loss 0.2218 (0.4537) teacher_loss 0.2144 (0.4429) loss_zs_kd 0.1314 (0.1252) loss_oracle 0.3735 (0.3356) acc 93.7500 (83.9062) kd_loss 0.9997 (1.0278) lr 1.5567e-04 eta 0:02:00
epoch [43/50] batch [140/160] time 0.112 (0.106) data 0.000 (0.002) loss 0.7368 (0.8345) ce_loss 0.3591 (0.4487) teacher_loss 0.3447 (0.4374) loss_zs_kd 0.1011 (0.1252) loss_oracle 0.3415 (0.3345) acc 90.6250 (83.8839) kd_loss 1.0322 (1.0264) lr 1.5567e-04 eta 0:02:00
epoch [43/50] batch [160/160] time 0.061 (0.110) data 0.000 (0.002) loss 0.7675 (0.8416) ce_loss 0.3789 (0.4559) teacher_loss 0.3824 (0.4448) loss_zs_kd 0.1257 (0.1250) loss_oracle 0.3223 (0.3344) acc 87.5000 (83.6523) kd_loss 1.0018 (1.0256) lr 1.2369e-04 eta 0:02:03
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,869
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 85.6%
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,951
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.7%
******* Domain p best val acc:      84.7%, epoch: 43 *******
******* Domain p best val test acc: 87.4%, epoch: 43 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [44/50] batch [20/160] time 0.084 (0.122) data 0.000 (0.016) loss 0.9038 (0.8382) ce_loss 0.4634 (0.4475) teacher_loss 0.4615 (0.4302) loss_zs_kd 0.1275 (0.1247) loss_oracle 0.3785 (0.3456) acc 78.1250 (83.2812) kd_loss 1.0953 (1.0286) lr 1.2369e-04 eta 0:02:13
epoch [44/50] batch [40/160] time 0.134 (0.114) data 0.001 (0.008) loss 0.9381 (0.8438) ce_loss 0.4893 (0.4530) teacher_loss 0.5392 (0.4404) loss_zs_kd 0.1416 (0.1240) loss_oracle 0.3282 (0.3414) acc 84.3750 (83.9062) kd_loss 0.9802 (1.0408) lr 1.2369e-04 eta 0:02:03
epoch [44/50] batch [60/160] time 0.150 (0.113) data 0.001 (0.005) loss 0.9480 (0.8477) ce_loss 0.5469 (0.4583) teacher_loss 0.5224 (0.4464) loss_zs_kd 0.0946 (0.1242) loss_oracle 0.3783 (0.3392) acc 75.0000 (83.3333) kd_loss 1.0168 (1.0373) lr 1.2369e-04 eta 0:01:59
epoch [44/50] batch [80/160] time 0.138 (0.114) data 0.000 (0.004) loss 0.7407 (0.8456) ce_loss 0.3518 (0.4595) teacher_loss 0.3609 (0.4479) loss_zs_kd 0.1449 (0.1248) loss_oracle 0.3073 (0.3353) acc 87.5000 (83.0859) kd_loss 1.0157 (1.0345) lr 1.2369e-04 eta 0:01:58
epoch [44/50] batch [100/160] time 0.120 (0.115) data 0.000 (0.003) loss 0.9134 (0.8461) ce_loss 0.5371 (0.4584) teacher_loss 0.5123 (0.4480) loss_zs_kd 0.1205 (0.1258) loss_oracle 0.3409 (0.3351) acc 75.0000 (82.8750) kd_loss 1.0828 (1.0315) lr 1.2369e-04 eta 0:01:57
epoch [44/50] batch [120/160] time 0.115 (0.114) data 0.000 (0.003) loss 0.8247 (0.8460) ce_loss 0.4871 (0.4591) teacher_loss 0.4540 (0.4487) loss_zs_kd 0.0869 (0.1237) loss_oracle 0.3273 (0.3354) acc 78.1250 (82.9948) kd_loss 0.9727 (1.0294) lr 1.2369e-04 eta 0:01:53
epoch [44/50] batch [140/160] time 0.098 (0.113) data 0.001 (0.003) loss 0.9666 (0.8443) ce_loss 0.5508 (0.4576) teacher_loss 0.5281 (0.4460) loss_zs_kd 0.1881 (0.1243) loss_oracle 0.3445 (0.3361) acc 78.1250 (83.1027) kd_loss 1.0894 (1.0287) lr 1.2369e-04 eta 0:01:50
epoch [44/50] batch [160/160] time 0.078 (0.112) data 0.000 (0.002) loss 0.9205 (0.8464) ce_loss 0.5010 (0.4599) teacher_loss 0.5085 (0.4482) loss_zs_kd 0.1447 (0.1243) loss_oracle 0.3397 (0.3361) acc 87.5000 (82.9297) kd_loss 1.1297 (1.0306) lr 9.5173e-05 eta 0:01:47
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,865
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,953
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 88.7%
******* Domain p best val acc:      84.7%, epoch: 43 *******
******* Domain p best val test acc: 87.4%, epoch: 43 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [45/50] batch [20/160] time 0.083 (0.129) data 0.000 (0.016) loss 0.7680 (0.8450) ce_loss 0.3816 (0.4693) teacher_loss 0.3766 (0.4515) loss_zs_kd 0.0990 (0.1153) loss_oracle 0.3419 (0.3358) acc 84.3750 (82.5000) kd_loss 0.9510 (1.0321) lr 9.5173e-05 eta 0:02:00
epoch [45/50] batch [40/160] time 0.136 (0.117) data 0.000 (0.008) loss 0.7955 (0.8467) ce_loss 0.4778 (0.4631) teacher_loss 0.4644 (0.4543) loss_zs_kd 0.0747 (0.1194) loss_oracle 0.2937 (0.3327) acc 87.5000 (82.7344) kd_loss 1.0597 (1.0287) lr 9.5173e-05 eta 0:01:48
epoch [45/50] batch [60/160] time 0.120 (0.115) data 0.001 (0.005) loss 0.7423 (0.8608) ce_loss 0.3545 (0.4727) teacher_loss 0.3756 (0.4654) loss_zs_kd 0.1159 (0.1224) loss_oracle 0.3088 (0.3342) acc 93.7500 (83.0208) kd_loss 1.0447 (1.0335) lr 9.5173e-05 eta 0:01:43
epoch [45/50] batch [80/160] time 0.095 (0.114) data 0.000 (0.004) loss 0.8064 (0.8601) ce_loss 0.4189 (0.4705) teacher_loss 0.3996 (0.4617) loss_zs_kd 0.1343 (0.1238) loss_oracle 0.3397 (0.3365) acc 78.1250 (82.6953) kd_loss 1.0810 (1.0340) lr 9.5173e-05 eta 0:01:40
epoch [45/50] batch [100/160] time 0.077 (0.113) data 0.000 (0.003) loss 0.8064 (0.8555) ce_loss 0.4451 (0.4669) teacher_loss 0.4335 (0.4573) loss_zs_kd 0.1187 (0.1246) loss_oracle 0.3136 (0.3358) acc 84.3750 (82.8438) kd_loss 1.0453 (1.0307) lr 9.5173e-05 eta 0:01:37
epoch [45/50] batch [120/160] time 0.155 (0.116) data 0.000 (0.003) loss 0.7045 (0.8519) ce_loss 0.3369 (0.4630) teacher_loss 0.3387 (0.4539) loss_zs_kd 0.1513 (0.1249) loss_oracle 0.2902 (0.3355) acc 87.5000 (82.9948) kd_loss 0.9976 (1.0307) lr 9.5173e-05 eta 0:01:37
epoch [45/50] batch [140/160] time 0.179 (0.119) data 0.000 (0.002) loss 0.9406 (0.8451) ce_loss 0.5186 (0.4569) teacher_loss 0.5219 (0.4475) loss_zs_kd 0.1216 (0.1239) loss_oracle 0.3579 (0.3357) acc 75.0000 (83.1696) kd_loss 1.0411 (1.0340) lr 9.5173e-05 eta 0:01:37
epoch [45/50] batch [160/160] time 0.158 (0.123) data 0.000 (0.002) loss 0.8232 (0.8435) ce_loss 0.4648 (0.4588) teacher_loss 0.4365 (0.4480) loss_zs_kd 0.1351 (0.1228) loss_oracle 0.3192 (0.3342) acc 81.2500 (83.0469) kd_loss 0.9599 (1.0352) lr 7.0224e-05 eta 0:01:38
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,865
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,947
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.6%
******* Domain p best val acc:      84.7%, epoch: 43 *******
******* Domain p best val test acc: 87.4%, epoch: 43 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [46/50] batch [20/160] time 0.120 (0.131) data 0.000 (0.012) loss 1.2191 (0.8331) ce_loss 0.8540 (0.4488) teacher_loss 0.8279 (0.4366) loss_zs_kd 0.1236 (0.1352) loss_oracle 0.3295 (0.3289) acc 71.8750 (84.6875) kd_loss 0.9289 (1.0354) lr 7.0224e-05 eta 0:01:42
epoch [46/50] batch [40/160] time 0.076 (0.116) data 0.000 (0.006) loss 0.8179 (0.8741) ce_loss 0.4346 (0.4872) teacher_loss 0.3976 (0.4747) loss_zs_kd 0.1567 (0.1316) loss_oracle 0.3420 (0.3336) acc 87.5000 (83.0469) kd_loss 1.0185 (1.0337) lr 7.0224e-05 eta 0:01:28
epoch [46/50] batch [60/160] time 0.079 (0.110) data 0.000 (0.004) loss 0.8220 (0.8537) ce_loss 0.4136 (0.4689) teacher_loss 0.4041 (0.4550) loss_zs_kd 0.1002 (0.1293) loss_oracle 0.3678 (0.3340) acc 81.2500 (83.1250) kd_loss 1.0123 (1.0302) lr 7.0224e-05 eta 0:01:21
epoch [46/50] batch [80/160] time 0.099 (0.109) data 0.000 (0.003) loss 0.7398 (0.8498) ce_loss 0.3828 (0.4655) teacher_loss 0.3913 (0.4524) loss_zs_kd 0.1115 (0.1281) loss_oracle 0.2927 (0.3334) acc 84.3750 (83.0469) kd_loss 1.0806 (1.0334) lr 7.0224e-05 eta 0:01:18
epoch [46/50] batch [100/160] time 0.085 (0.105) data 0.000 (0.003) loss 0.6533 (0.8442) ce_loss 0.3096 (0.4616) teacher_loss 0.3053 (0.4483) loss_zs_kd 0.0973 (0.1269) loss_oracle 0.2993 (0.3324) acc 84.3750 (83.0312) kd_loss 0.9567 (1.0357) lr 7.0224e-05 eta 0:01:13
epoch [46/50] batch [120/160] time 0.083 (0.102) data 0.000 (0.002) loss 0.9035 (0.8516) ce_loss 0.5078 (0.4675) teacher_loss 0.4904 (0.4557) loss_zs_kd 0.1389 (0.1283) loss_oracle 0.3436 (0.3318) acc 84.3750 (82.5521) kd_loss 0.9643 (1.0344) lr 7.0224e-05 eta 0:01:09
epoch [46/50] batch [140/160] time 0.110 (0.101) data 0.000 (0.002) loss 0.6220 (0.8545) ce_loss 0.2561 (0.4704) teacher_loss 0.2737 (0.4602) loss_zs_kd 0.0978 (0.1267) loss_oracle 0.2995 (0.3310) acc 90.6250 (82.5000) kd_loss 0.9310 (1.0317) lr 7.0224e-05 eta 0:01:06
epoch [46/50] batch [160/160] time 0.086 (0.101) data 0.000 (0.002) loss 0.7122 (0.8526) ce_loss 0.3281 (0.4677) teacher_loss 0.3236 (0.4575) loss_zs_kd 0.1391 (0.1257) loss_oracle 0.3191 (0.3323) acc 90.6250 (82.4219) kd_loss 0.9826 (1.0312) lr 4.8943e-05 eta 0:01:04
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,867
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,948
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.6%
******* Domain p best val acc:      84.7%, epoch: 43 *******
******* Domain p best val test acc: 87.4%, epoch: 43 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [47/50] batch [20/160] time 0.124 (0.111) data 0.000 (0.014) loss 0.8853 (0.8344) ce_loss 0.5161 (0.4511) teacher_loss 0.5201 (0.4376) loss_zs_kd 0.0811 (0.1191) loss_oracle 0.3246 (0.3373) acc 81.2500 (83.4375) kd_loss 1.0250 (1.0353) lr 4.8943e-05 eta 0:01:09
epoch [47/50] batch [40/160] time 0.092 (0.107) data 0.000 (0.007) loss 0.9444 (0.8382) ce_loss 0.5923 (0.4579) teacher_loss 0.5674 (0.4466) loss_zs_kd 0.1136 (0.1191) loss_oracle 0.3202 (0.3321) acc 75.0000 (82.9688) kd_loss 1.0518 (1.0415) lr 4.8943e-05 eta 0:01:04
epoch [47/50] batch [60/160] time 0.079 (0.102) data 0.001 (0.005) loss 0.8383 (0.8408) ce_loss 0.4680 (0.4565) teacher_loss 0.4493 (0.4446) loss_zs_kd 0.1074 (0.1189) loss_oracle 0.3353 (0.3367) acc 84.3750 (82.9167) kd_loss 0.9600 (1.0427) lr 4.8943e-05 eta 0:00:59
epoch [47/50] batch [80/160] time 0.086 (0.107) data 0.000 (0.004) loss 0.7518 (0.8383) ce_loss 0.3892 (0.4532) teacher_loss 0.3822 (0.4407) loss_zs_kd 0.0916 (0.1188) loss_oracle 0.3238 (0.3382) acc 84.3750 (83.3984) kd_loss 0.9154 (1.0355) lr 4.8943e-05 eta 0:00:59
epoch [47/50] batch [100/160] time 0.090 (0.105) data 0.000 (0.003) loss 0.8749 (0.8455) ce_loss 0.5352 (0.4591) teacher_loss 0.4899 (0.4472) loss_zs_kd 0.0921 (0.1221) loss_oracle 0.3390 (0.3373) acc 71.8750 (83.0938) kd_loss 0.9378 (1.0364) lr 4.8943e-05 eta 0:00:56
epoch [47/50] batch [120/160] time 0.084 (0.105) data 0.000 (0.003) loss 0.9911 (0.8462) ce_loss 0.6372 (0.4598) teacher_loss 0.5913 (0.4479) loss_zs_kd 0.1511 (0.1230) loss_oracle 0.3242 (0.3368) acc 78.1250 (83.1250) kd_loss 1.0030 (1.0307) lr 4.8943e-05 eta 0:00:54
epoch [47/50] batch [140/160] time 0.080 (0.103) data 0.000 (0.002) loss 0.9213 (0.8449) ce_loss 0.4746 (0.4585) teacher_loss 0.4792 (0.4445) loss_zs_kd 0.1718 (0.1241) loss_oracle 0.3562 (0.3383) acc 75.0000 (83.0804) kd_loss 1.0125 (1.0334) lr 4.8943e-05 eta 0:00:51
epoch [47/50] batch [160/160] time 0.063 (0.100) data 0.000 (0.002) loss 0.9984 (0.8506) ce_loss 0.6045 (0.4644) teacher_loss 0.6055 (0.4497) loss_zs_kd 0.1380 (0.1249) loss_oracle 0.3240 (0.3385) acc 81.2500 (82.8906) kd_loss 1.0151 (1.0327) lr 3.1417e-05 eta 0:00:47
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,866
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,948
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.6%
******* Domain p best val acc:      84.7%, epoch: 43 *******
******* Domain p best val test acc: 87.4%, epoch: 43 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [48/50] batch [20/160] time 0.069 (0.148) data 0.000 (0.013) loss 0.8703 (0.8918) ce_loss 0.4661 (0.4868) teacher_loss 0.4453 (0.4789) loss_zs_kd 0.1207 (0.1292) loss_oracle 0.3646 (0.3483) acc 87.5000 (82.9688) kd_loss 1.0870 (1.0465) lr 3.1417e-05 eta 0:01:08
epoch [48/50] batch [40/160] time 0.090 (0.119) data 0.000 (0.007) loss 0.8009 (0.8664) ce_loss 0.4106 (0.4707) teacher_loss 0.4340 (0.4598) loss_zs_kd 0.1029 (0.1290) loss_oracle 0.3154 (0.3421) acc 84.3750 (83.2812) kd_loss 1.0201 (1.0396) lr 3.1417e-05 eta 0:00:52
epoch [48/50] batch [60/160] time 0.127 (0.113) data 0.001 (0.005) loss 0.9121 (0.8672) ce_loss 0.5010 (0.4729) teacher_loss 0.5000 (0.4663) loss_zs_kd 0.1490 (0.1278) loss_oracle 0.3377 (0.3370) acc 81.2500 (83.0729) kd_loss 0.9163 (1.0367) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [80/160] time 0.083 (0.112) data 0.000 (0.004) loss 0.9613 (0.8573) ce_loss 0.6226 (0.4715) teacher_loss 0.6002 (0.4622) loss_zs_kd 0.1331 (0.1256) loss_oracle 0.2946 (0.3324) acc 71.8750 (82.7344) kd_loss 1.1008 (1.0331) lr 3.1417e-05 eta 0:00:44
epoch [48/50] batch [100/160] time 0.132 (0.110) data 0.000 (0.003) loss 0.9424 (0.8469) ce_loss 0.5532 (0.4596) teacher_loss 0.5074 (0.4501) loss_zs_kd 0.1095 (0.1258) loss_oracle 0.3802 (0.3339) acc 87.5000 (83.6562) kd_loss 1.1105 (1.0320) lr 3.1417e-05 eta 0:00:41
epoch [48/50] batch [120/160] time 0.091 (0.106) data 0.000 (0.002) loss 0.6442 (0.8405) ce_loss 0.3682 (0.4544) teacher_loss 0.2980 (0.4446) loss_zs_kd 0.0950 (0.1244) loss_oracle 0.2987 (0.3337) acc 78.1250 (83.5156) kd_loss 1.0832 (1.0335) lr 3.1417e-05 eta 0:00:38
epoch [48/50] batch [140/160] time 0.073 (0.104) data 0.000 (0.002) loss 0.8073 (0.8361) ce_loss 0.3953 (0.4508) teacher_loss 0.3558 (0.4399) loss_zs_kd 0.1701 (0.1245) loss_oracle 0.3664 (0.3339) acc 90.6250 (83.5491) kd_loss 1.0199 (1.0340) lr 3.1417e-05 eta 0:00:35
epoch [48/50] batch [160/160] time 0.074 (0.101) data 0.000 (0.002) loss 1.0568 (0.8422) ce_loss 0.7095 (0.4588) teacher_loss 0.6750 (0.4470) loss_zs_kd 0.1211 (0.1241) loss_oracle 0.3212 (0.3332) acc 78.1250 (83.2031) kd_loss 1.0316 (1.0340) lr 1.7713e-05 eta 0:00:32
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,866
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,948
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.6%
******* Domain p best val acc:      84.7%, epoch: 43 *******
******* Domain p best val test acc: 87.4%, epoch: 43 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [49/50] batch [20/160] time 0.085 (0.103) data 0.000 (0.012) loss 1.1230 (0.8451) ce_loss 0.7715 (0.4625) teacher_loss 0.7408 (0.4467) loss_zs_kd 0.1397 (0.1214) loss_oracle 0.3124 (0.3377) acc 62.5000 (81.7188) kd_loss 1.0340 (1.0345) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [40/160] time 0.097 (0.099) data 0.000 (0.006) loss 0.7879 (0.8750) ce_loss 0.4448 (0.4913) teacher_loss 0.3966 (0.4750) loss_zs_kd 0.1627 (0.1213) loss_oracle 0.3099 (0.3394) acc 87.5000 (80.7812) kd_loss 1.0722 (1.0398) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [60/160] time 0.085 (0.095) data 0.001 (0.004) loss 1.1183 (0.8495) ce_loss 0.7324 (0.4631) teacher_loss 0.7387 (0.4508) loss_zs_kd 0.1257 (0.1226) loss_oracle 0.3168 (0.3374) acc 65.6250 (82.5521) kd_loss 1.0254 (1.0324) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [80/160] time 0.087 (0.095) data 0.000 (0.003) loss 0.7380 (0.8504) ce_loss 0.3757 (0.4637) teacher_loss 0.3565 (0.4514) loss_zs_kd 0.1051 (0.1252) loss_oracle 0.3289 (0.3364) acc 90.6250 (82.5391) kd_loss 0.9773 (1.0261) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [100/160] time 0.096 (0.095) data 0.000 (0.003) loss 0.9106 (0.8591) ce_loss 0.4839 (0.4744) teacher_loss 0.4651 (0.4605) loss_zs_kd 0.1345 (0.1255) loss_oracle 0.3782 (0.3358) acc 75.0000 (81.9688) kd_loss 1.0031 (1.0290) lr 1.7713e-05 eta 0:00:20
epoch [49/50] batch [120/160] time 0.106 (0.095) data 0.000 (0.002) loss 1.0108 (0.8604) ce_loss 0.6021 (0.4768) teacher_loss 0.6282 (0.4615) loss_zs_kd 0.1212 (0.1255) loss_oracle 0.3221 (0.3361) acc 87.5000 (82.0573) kd_loss 1.1155 (1.0353) lr 1.7713e-05 eta 0:00:19
epoch [49/50] batch [140/160] time 0.099 (0.096) data 0.000 (0.002) loss 0.8320 (0.8603) ce_loss 0.4956 (0.4780) teacher_loss 0.4946 (0.4634) loss_zs_kd 0.1058 (0.1235) loss_oracle 0.2845 (0.3351) acc 81.2500 (82.1652) kd_loss 1.0671 (1.0336) lr 1.7713e-05 eta 0:00:17
epoch [49/50] batch [160/160] time 0.093 (0.096) data 0.000 (0.002) loss 0.8734 (0.8555) ce_loss 0.4756 (0.4734) teacher_loss 0.4345 (0.4592) loss_zs_kd 0.1680 (0.1230) loss_oracle 0.3549 (0.3347) acc 78.1250 (82.4023) kd_loss 1.0170 (1.0299) lr 7.8853e-06 eta 0:00:15
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,866
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,949
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.7%
******* Domain p best val acc:      84.7%, epoch: 43 *******
******* Domain p best val test acc: 87.4%, epoch: 43 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
epoch [50/50] batch [20/160] time 0.113 (0.126) data 0.000 (0.011) loss 0.9591 (0.8535) ce_loss 0.5464 (0.4720) teacher_loss 0.5751 (0.4574) loss_zs_kd 0.1176 (0.1286) loss_oracle 0.3252 (0.3317) acc 84.3750 (83.1250) kd_loss 1.0695 (0.9948) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [40/160] time 0.122 (0.122) data 0.000 (0.006) loss 0.9801 (0.8392) ce_loss 0.5513 (0.4538) teacher_loss 0.5579 (0.4421) loss_zs_kd 0.1396 (0.1296) loss_oracle 0.3524 (0.3323) acc 84.3750 (83.4375) kd_loss 0.9870 (1.0142) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [60/160] time 0.164 (0.125) data 0.001 (0.004) loss 0.8606 (0.8251) ce_loss 0.5063 (0.4442) teacher_loss 0.4849 (0.4299) loss_zs_kd 0.1180 (0.1258) loss_oracle 0.3167 (0.3323) acc 78.1250 (84.0625) kd_loss 1.0997 (1.0238) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [80/160] time 0.177 (0.134) data 0.001 (0.003) loss 0.8623 (0.8338) ce_loss 0.4670 (0.4506) teacher_loss 0.4534 (0.4385) loss_zs_kd 0.1484 (0.1251) loss_oracle 0.3347 (0.3328) acc 81.2500 (83.7109) kd_loss 0.9539 (1.0257) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [100/160] time 0.097 (0.128) data 0.000 (0.002) loss 0.8812 (0.8344) ce_loss 0.5195 (0.4528) teacher_loss 0.5019 (0.4401) loss_zs_kd 0.0770 (0.1231) loss_oracle 0.3409 (0.3327) acc 87.5000 (83.7500) kd_loss 0.9941 (1.0234) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [120/160] time 0.093 (0.124) data 0.000 (0.002) loss 0.7257 (0.8363) ce_loss 0.3601 (0.4511) teacher_loss 0.3593 (0.4385) loss_zs_kd 0.1067 (0.1240) loss_oracle 0.3130 (0.3358) acc 84.3750 (83.5677) kd_loss 1.0775 (1.0244) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [140/160] time 0.110 (0.121) data 0.000 (0.002) loss 0.7064 (0.8389) ce_loss 0.2856 (0.4535) teacher_loss 0.2740 (0.4413) loss_zs_kd 0.1349 (0.1248) loss_oracle 0.3649 (0.3352) acc 93.7500 (83.4598) kd_loss 1.0983 (1.0249) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [160/160] time 0.120 (0.119) data 0.000 (0.002) loss 0.7385 (0.8385) ce_loss 0.3201 (0.4547) teacher_loss 0.3371 (0.4423) loss_zs_kd 0.1208 (0.1235) loss_oracle 0.3410 (0.3344) acc 87.5000 (83.6133) kd_loss 1.0387 (1.0218) lr 1.9733e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,865
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,947
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.6%
******* Domain p best val acc:      84.7%, epoch: 43 *******
******* Domain p best val test acc: 87.4%, epoch: 43 *******
******* Domain p best test acc:     88.2%, epoch: 5 *******
Checkpoint saved to icml/multi-dg/oracle/05_nouse_ema/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:19:32

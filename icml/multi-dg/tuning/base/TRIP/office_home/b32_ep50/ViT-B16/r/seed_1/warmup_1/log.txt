Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'clipart', 'product']
Target     ['real_world']
# classes  65
# train_x  7,877
# val      3,354
# test     4,357
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/246] time 0.474 (0.522) data 0.000 (0.022) loss 1.6467 (1.5171) teacher_loss 1.6035 (1.4864) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0000 (-0.0001) kd_loss 0.0433 (0.0307) acc 59.3750 (61.0938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0015 (0.0014) teacher/entropy 1.0553 (1.0679) teacher/usage_max 0.3720 (0.3480) teacher/usage_min 0.3083 (0.3203) teacher/usage_std 0.0277 (0.0119) nleep/row_max_mean 1152.2839 (1162.5371) nleep/row_max_std 54.6331 (75.2292) nleep/row_min_mean 1151.7649 (1162.1512) lr 1.0000e-05 eta 1:46:52
epoch [1/50] batch [40/246] time 0.438 (0.510) data 0.000 (0.011) loss 1.0897 (1.4423) teacher_loss 1.0212 (1.4157) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0000 (-0.0001) kd_loss 0.0685 (0.0266) acc 75.0000 (63.0469) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3314 (0.3315) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0300 (1.0720) teacher/usage_max 0.3868 (0.3495) teacher/usage_min 0.3036 (0.3198) teacher/usage_std 0.0379 (0.0129) nleep/row_max_mean 1188.7045 (1161.3579) nleep/row_max_std 97.1310 (60.1572) nleep/row_min_mean 1188.1919 (1161.0194) lr 1.0000e-05 eta 1:44:11
epoch [1/50] batch [60/246] time 0.079 (0.475) data 0.000 (0.007) loss 1.1686 (1.4391) teacher_loss 1.1303 (1.4165) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0000 (-0.0001) kd_loss 0.0382 (0.0226) acc 78.1250 (63.4375) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3348) gate/usage_min 0.3314 (0.3315) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0604 (1.0761) teacher/usage_max 0.3426 (0.3482) teacher/usage_min 0.3226 (0.3209) teacher/usage_std 0.0082 (0.0118) nleep/row_max_mean 1163.9082 (1162.4738) nleep/row_max_std 50.4386 (56.6435) nleep/row_min_mean 1163.5449 (1162.1697) lr 1.0000e-05 eta 1:36:56
epoch [1/50] batch [80/246] time 0.492 (0.431) data 0.000 (0.006) loss 1.9313 (1.4302) teacher_loss 1.9279 (1.4093) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0000 (-0.0000) kd_loss 0.0034 (0.0209) acc 50.0000 (63.5938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3315 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0952 (1.0777) teacher/usage_max 0.3386 (0.3481) teacher/usage_min 0.3268 (0.3207) teacher/usage_std 0.0049 (0.0118) nleep/row_max_mean 1174.1348 (1164.8189) nleep/row_max_std 52.0622 (56.0256) nleep/row_min_mean 1173.9934 (1164.5371) lr 1.0000e-05 eta 1:27:52
epoch [1/50] batch [100/246] time 0.397 (0.392) data 0.000 (0.005) loss 1.4915 (1.4107) teacher_loss 1.4570 (1.3918) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0000 (-0.0000) kd_loss 0.0343 (0.0189) acc 59.3750 (63.8750) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3315 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0643 (1.0797) teacher/usage_max 0.3540 (0.3469) teacher/usage_min 0.3177 (0.3216) teacher/usage_std 0.0153 (0.0109) nleep/row_max_mean 1170.8738 (1165.8754) nleep/row_max_std 40.0585 (53.0326) nleep/row_min_mean 1170.5895 (1165.6149) lr 1.0000e-05 eta 1:19:39
epoch [1/50] batch [120/246] time 0.511 (0.387) data 0.000 (0.004) loss 1.5118 (1.4098) teacher_loss 1.5079 (1.3925) loss_zs_kd 0.0004 (0.0000) loss_oracle 0.0002 (0.0000) kd_loss 0.0036 (0.0173) acc 59.3750 (64.0365) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3348) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0015 (0.0014) teacher/entropy 1.0949 (1.0813) teacher/usage_max 0.3387 (0.3464) teacher/usage_min 0.3268 (0.3224) teacher/usage_std 0.0049 (0.0104) nleep/row_max_mean 1164.3119 (1167.0707) nleep/row_max_std 9.5785 (50.4112) nleep/row_min_mean 1164.1594 (1166.8252) lr 1.0000e-05 eta 1:18:33
epoch [1/50] batch [140/246] time 0.540 (0.404) data 0.000 (0.003) loss 1.7440 (1.4089) teacher_loss 1.7422 (1.3919) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0003 (0.0000) kd_loss 0.0017 (0.0170) acc 53.1250 (64.1295) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3350 (0.3348) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0015 (0.0014) teacher/entropy 1.0970 (1.0817) teacher/usage_max 0.3397 (0.3466) teacher/usage_min 0.3263 (0.3224) teacher/usage_std 0.0055 (0.0105) nleep/row_max_mean 1179.1912 (1168.2832) nleep/row_max_std 38.3111 (47.7491) nleep/row_min_mean 1179.0862 (1168.0459) lr 1.0000e-05 eta 1:21:53
epoch [1/50] batch [160/246] time 0.471 (0.418) data 0.000 (0.003) loss 1.6010 (1.4188) teacher_loss 1.5993 (1.4029) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0002 (0.0001) kd_loss 0.0015 (0.0159) acc 65.6250 (63.6523) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3315 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0971 (1.0827) teacher/usage_max 0.3395 (0.3463) teacher/usage_min 0.3277 (0.3228) teacher/usage_std 0.0048 (0.0102) nleep/row_max_mean 1176.2114 (1169.4135) nleep/row_max_std 24.3996 (45.4156) nleep/row_min_mean 1176.1118 (1169.1877) lr 1.0000e-05 eta 1:24:29
epoch [1/50] batch [180/246] time 0.078 (0.420) data 0.000 (0.003) loss 1.6134 (1.4121) teacher_loss 1.6122 (1.3964) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0003 (0.0001) kd_loss 0.0010 (0.0156) acc 56.2500 (64.0104) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0977 (1.0830) teacher/usage_max 0.3380 (0.3464) teacher/usage_min 0.3302 (0.3230) teacher/usage_std 0.0033 (0.0102) nleep/row_max_mean 1179.1884 (1170.5883) nleep/row_max_std 21.6227 (43.4491) nleep/row_min_mean 1179.1005 (1170.3705) lr 1.0000e-05 eta 1:24:55
epoch [1/50] batch [200/246] time 0.436 (0.404) data 0.000 (0.002) loss 2.1303 (1.4124) teacher_loss 2.1287 (1.3973) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0004 (0.0001) kd_loss 0.0013 (0.0150) acc 40.6250 (63.8906) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3315 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0973 (1.0836) teacher/usage_max 0.3383 (0.3465) teacher/usage_min 0.3306 (0.3231) teacher/usage_std 0.0035 (0.0102) nleep/row_max_mean 1175.6943 (1171.7664) nleep/row_max_std 11.4989 (41.9354) nleep/row_min_mean 1175.5912 (1171.5563) lr 1.0000e-05 eta 1:21:28
epoch [1/50] batch [220/246] time 0.482 (0.394) data 0.000 (0.002) loss 1.2841 (1.4125) teacher_loss 1.2721 (1.3976) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0005 (0.0001) kd_loss 0.0117 (0.0148) acc 71.8750 (64.0483) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3315 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0869 (1.0839) teacher/usage_max 0.3546 (0.3468) teacher/usage_min 0.3207 (0.3231) teacher/usage_std 0.0151 (0.0103) nleep/row_max_mean 1185.1117 (1172.8206) nleep/row_max_std 24.5428 (40.3766) nleep/row_min_mean 1184.9602 (1172.6166) lr 1.0000e-05 eta 1:19:23
epoch [1/50] batch [240/246] time 0.498 (0.393) data 0.000 (0.002) loss 1.5843 (1.4106) teacher_loss 1.5828 (1.3963) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0004 (0.0002) kd_loss 0.0012 (0.0142) acc 59.3750 (63.9714) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3348) gate/usage_min 0.3313 (0.3314) gate/usage_std 0.0015 (0.0014) teacher/entropy 1.0975 (1.0844) teacher/usage_max 0.3425 (0.3469) teacher/usage_min 0.3282 (0.3233) teacher/usage_std 0.0065 (0.0103) nleep/row_max_mean 1181.5537 (1174.0660) nleep/row_max_std 13.3401 (39.1527) nleep/row_min_mean 1181.4557 (1173.8677) lr 1.0000e-05 eta 1:18:53
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,683
* accuracy: 80.0%
* error: 20.0%
* macro_f1: 78.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,893
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 87.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      80.0%, epoch: 1 *******
******* Domain r best val test acc: 89.4%, epoch: 1 *******
******* Domain r best test acc:     89.4%, epoch: 1 *******
epoch [2/50] batch [20/246] time 0.496 (0.515) data 0.000 (0.013) loss 1.7872 (1.4951) teacher_loss 1.6765 (1.4409) loss_zs_kd 0.0091 (0.0094) loss_oracle 0.2080 (0.0816) kd_loss 0.0021 (0.0087) acc 65.6250 (64.0625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3347) gate/usage_min 0.3312 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 1.0965 (1.0899) teacher/usage_max 0.3484 (0.3518) teacher/usage_min 0.3252 (0.3225) teacher/usage_std 0.0107 (0.0132) nleep/row_max_mean 1192.3989 (1189.3994) nleep/row_max_std 21.5475 (24.7452) nleep/row_min_mean 1192.2739 (1189.2547) lr 2.0000e-03 eta 1:43:22
epoch [2/50] batch [40/246] time 0.443 (0.400) data 0.001 (0.007) loss 1.6638 (1.5139) teacher_loss 1.4472 (1.3864) loss_zs_kd 0.0110 (0.0127) loss_oracle 0.4161 (0.2272) kd_loss 0.0031 (0.0075) acc 59.3750 (64.6875) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3356 (0.3348) gate/usage_min 0.3306 (0.3311) gate/usage_std 0.0021 (0.0016) teacher/entropy 1.0955 (1.0910) teacher/usage_max 0.3455 (0.3528) teacher/usage_min 0.3219 (0.3211) teacher/usage_std 0.0096 (0.0140) nleep/row_max_mean 1186.7107 (1189.5953) nleep/row_max_std 12.7023 (22.6913) nleep/row_min_mean 1186.5540 (1189.4447) lr 2.0000e-03 eta 1:20:11
epoch [2/50] batch [60/246] time 0.079 (0.387) data 0.000 (0.005) loss 1.4662 (1.4561) teacher_loss 1.2860 (1.3142) loss_zs_kd 0.0222 (0.0133) loss_oracle 0.3141 (0.2515) kd_loss 0.0121 (0.0095) acc 65.6250 (66.4062) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3373 (0.3354) gate/usage_min 0.3293 (0.3307) gate/usage_std 0.0033 (0.0020) teacher/entropy 1.0858 (1.0890) teacher/usage_max 0.3776 (0.3554) teacher/usage_min 0.3098 (0.3187) teacher/usage_std 0.0313 (0.0161) nleep/row_max_mean 1193.6666 (1190.9129) nleep/row_max_std 20.5890 (22.9361) nleep/row_min_mean 1193.3918 (1190.7325) lr 2.0000e-03 eta 1:17:17
epoch [2/50] batch [80/246] time 0.080 (0.344) data 0.000 (0.003) loss 1.4022 (1.4220) teacher_loss 1.2567 (1.2767) loss_zs_kd 0.0216 (0.0135) loss_oracle 0.2518 (0.2581) kd_loss 0.0089 (0.0095) acc 62.5000 (67.4609) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3384 (0.3360) gate/usage_min 0.3281 (0.3302) gate/usage_std 0.0042 (0.0024) teacher/entropy 1.0898 (1.0890) teacher/usage_max 0.3522 (0.3558) teacher/usage_min 0.3012 (0.3155) teacher/usage_std 0.0228 (0.0175) nleep/row_max_mean 1190.0356 (1191.1327) nleep/row_max_std 20.8973 (22.4411) nleep/row_min_mean 1189.7522 (1190.9305) lr 2.0000e-03 eta 1:08:42
epoch [2/50] batch [100/246] time 0.495 (0.368) data 0.000 (0.003) loss 1.1769 (1.4117) teacher_loss 1.0273 (1.2659) loss_zs_kd 0.0116 (0.0147) loss_oracle 0.2571 (0.2555) kd_loss 0.0152 (0.0107) acc 68.7500 (67.3750) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3393 (0.3366) gate/usage_min 0.3271 (0.3297) gate/usage_std 0.0050 (0.0029) teacher/entropy 1.0836 (1.0878) teacher/usage_max 0.3516 (0.3565) teacher/usage_min 0.3015 (0.3121) teacher/usage_std 0.0226 (0.0192) nleep/row_max_mean 1192.6284 (1191.6675) nleep/row_max_std 18.0529 (21.9148) nleep/row_min_mean 1192.2683 (1191.4380) lr 2.0000e-03 eta 1:13:14
epoch [2/50] batch [120/246] time 0.496 (0.387) data 0.000 (0.002) loss 1.1172 (1.3967) teacher_loss 1.0058 (1.2499) loss_zs_kd 0.0124 (0.0155) loss_oracle 0.1840 (0.2535) kd_loss 0.0132 (0.0123) acc 75.0000 (68.2552) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3402 (0.3371) gate/usage_min 0.3260 (0.3291) gate/usage_std 0.0058 (0.0033) teacher/entropy 1.0848 (1.0861) teacher/usage_max 0.3653 (0.3578) teacher/usage_min 0.3074 (0.3095) teacher/usage_std 0.0240 (0.0208) nleep/row_max_mean 1192.8983 (1192.0944) nleep/row_max_std 16.0913 (21.5400) nleep/row_min_mean 1192.5519 (1191.8381) lr 2.0000e-03 eta 1:17:04
epoch [2/50] batch [140/246] time 0.450 (0.402) data 0.000 (0.002) loss 1.5263 (1.3866) teacher_loss 1.3121 (1.2375) loss_zs_kd 0.0051 (0.0162) loss_oracle 0.3602 (0.2543) kd_loss 0.0315 (0.0139) acc 71.8750 (68.3036) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3410 (0.3376) gate/usage_min 0.3252 (0.3286) gate/usage_std 0.0065 (0.0037) teacher/entropy 1.0668 (1.0846) teacher/usage_max 0.3676 (0.3587) teacher/usage_min 0.2878 (0.3075) teacher/usage_std 0.0335 (0.0220) nleep/row_max_mean 1201.5759 (1192.5653) nleep/row_max_std 18.4886 (21.2316) nleep/row_min_mean 1201.1187 (1192.2855) lr 2.0000e-03 eta 1:19:46
epoch [2/50] batch [160/246] time 0.087 (0.392) data 0.000 (0.002) loss 1.1153 (1.3800) teacher_loss 0.9528 (1.2262) loss_zs_kd 0.0179 (0.0166) loss_oracle 0.2654 (0.2606) kd_loss 0.0209 (0.0152) acc 68.7500 (68.4961) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3410 (0.3380) gate/usage_min 0.3240 (0.3281) gate/usage_std 0.0070 (0.0041) teacher/entropy 1.0767 (1.0833) teacher/usage_max 0.3714 (0.3589) teacher/usage_min 0.3126 (0.3068) teacher/usage_std 0.0270 (0.0224) nleep/row_max_mean 1197.6614 (1192.9712) nleep/row_max_std 18.1141 (20.8345) nleep/row_min_mean 1197.2112 (1192.6713) lr 2.0000e-03 eta 1:17:39
epoch [2/50] batch [180/246] time 0.485 (0.385) data 0.000 (0.002) loss 1.3770 (1.3716) teacher_loss 1.1948 (1.2157) loss_zs_kd 0.0316 (0.0172) loss_oracle 0.2640 (0.2622) kd_loss 0.0343 (0.0162) acc 75.0000 (68.8368) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3419 (0.3384) gate/usage_min 0.3230 (0.3276) gate/usage_std 0.0078 (0.0044) teacher/entropy 1.0635 (1.0823) teacher/usage_max 0.3693 (0.3586) teacher/usage_min 0.3051 (0.3073) teacher/usage_std 0.0268 (0.0220) nleep/row_max_mean 1199.5582 (1193.3962) nleep/row_max_std 20.0687 (20.4450) nleep/row_min_mean 1199.0815 (1193.0799) lr 2.0000e-03 eta 1:16:11
epoch [2/50] batch [200/246] time 0.540 (0.371) data 0.000 (0.002) loss 1.7334 (1.3733) teacher_loss 1.5444 (1.2164) loss_zs_kd 0.0265 (0.0182) loss_oracle 0.2696 (0.2606) kd_loss 0.0409 (0.0175) acc 56.2500 (68.8594) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3425 (0.3388) gate/usage_min 0.3219 (0.3271) gate/usage_std 0.0086 (0.0048) teacher/entropy 1.0549 (1.0808) teacher/usage_max 0.3822 (0.3588) teacher/usage_min 0.2819 (0.3065) teacher/usage_std 0.0410 (0.0225) nleep/row_max_mean 1198.1273 (1193.8563) nleep/row_max_std 18.9993 (20.1194) nleep/row_min_mean 1197.5553 (1193.5210) lr 2.0000e-03 eta 1:13:12
epoch [2/50] batch [220/246] time 0.470 (0.371) data 0.000 (0.001) loss 1.3681 (1.3724) teacher_loss 1.1478 (1.2105) loss_zs_kd 0.0230 (0.0188) loss_oracle 0.3673 (0.2669) kd_loss 0.0251 (0.0191) acc 65.6250 (68.9915) gate/entropy 1.0982 (1.0985) gate/usage_max 0.3435 (0.3392) gate/usage_min 0.3205 (0.3266) gate/usage_std 0.0096 (0.0052) teacher/entropy 1.0717 (1.0791) teacher/usage_max 0.3548 (0.3592) teacher/usage_min 0.2959 (0.3059) teacher/usage_std 0.0266 (0.0229) nleep/row_max_mean 1197.6493 (1194.3135) nleep/row_max_std 13.4367 (19.7992) nleep/row_min_mean 1197.1562 (1193.9575) lr 2.0000e-03 eta 1:13:05
epoch [2/50] batch [240/246] time 0.467 (0.379) data 0.000 (0.001) loss 1.4593 (1.3789) teacher_loss 1.2100 (1.2126) loss_zs_kd 0.0329 (0.0193) loss_oracle 0.4016 (0.2719) kd_loss 0.0321 (0.0207) acc 68.7500 (69.0365) gate/entropy 1.0981 (1.0984) gate/usage_max 0.3450 (0.3396) gate/usage_min 0.3192 (0.3260) gate/usage_std 0.0107 (0.0056) teacher/entropy 1.0638 (1.0774) teacher/usage_max 0.3655 (0.3593) teacher/usage_min 0.2867 (0.3052) teacher/usage_std 0.0338 (0.0232) nleep/row_max_mean 1198.9705 (1194.6354) nleep/row_max_std 14.0417 (19.5268) nleep/row_min_mean 1198.3975 (1194.2588) lr 2.0000e-03 eta 1:14:38
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,825
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,953
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.2%, epoch: 2 *******
******* Domain r best val test acc: 90.7%, epoch: 2 *******
******* Domain r best test acc:     90.7%, epoch: 2 *******
epoch [3/50] batch [20/246] time 0.087 (0.333) data 0.000 (0.015) loss 1.5770 (1.4118) teacher_loss 1.3982 (1.1649) loss_zs_kd 0.0098 (0.0246) loss_oracle 0.2681 (0.3755) kd_loss 0.0398 (0.0469) acc 62.5000 (70.3125) gate/entropy 1.0979 (1.0980) gate/usage_max 0.3474 (0.3466) gate/usage_min 0.3173 (0.3180) gate/usage_std 0.0124 (0.0118) teacher/entropy 1.0542 (1.0487) teacher/usage_max 0.3742 (0.3698) teacher/usage_min 0.2594 (0.2792) teacher/usage_std 0.0524 (0.0396) nleep/row_max_mean 1198.0630 (1199.7620) nleep/row_max_std 15.1424 (15.9881) nleep/row_min_mean 1197.4062 (1199.0708) lr 1.9980e-03 eta 1:05:29
epoch [3/50] batch [40/246] time 0.080 (0.357) data 0.000 (0.008) loss 0.8711 (1.3814) teacher_loss 0.6933 (1.1633) loss_zs_kd 0.0151 (0.0239) loss_oracle 0.2568 (0.3109) kd_loss 0.0418 (0.0507) acc 84.3750 (70.7812) gate/entropy 1.0978 (1.0979) gate/usage_max 0.3490 (0.3474) gate/usage_min 0.3157 (0.3173) gate/usage_std 0.0136 (0.0124) teacher/entropy 1.0535 (1.0442) teacher/usage_max 0.3759 (0.3782) teacher/usage_min 0.2756 (0.2705) teacher/usage_std 0.0423 (0.0465) nleep/row_max_mean 1203.3965 (1199.7172) nleep/row_max_std 16.9713 (16.0829) nleep/row_min_mean 1202.7610 (1198.9963) lr 1.9980e-03 eta 1:10:01
epoch [3/50] batch [60/246] time 0.080 (0.311) data 0.000 (0.005) loss 1.9938 (1.3927) teacher_loss 1.6894 (1.1675) loss_zs_kd 0.0367 (0.0241) loss_oracle 0.4171 (0.3117) kd_loss 0.0775 (0.0573) acc 50.0000 (69.5833) gate/entropy 1.0976 (1.0978) gate/usage_max 0.3500 (0.3481) gate/usage_min 0.3140 (0.3165) gate/usage_std 0.0148 (0.0130) teacher/entropy 1.0141 (1.0368) teacher/usage_max 0.4011 (0.3862) teacher/usage_min 0.2344 (0.2602) teacher/usage_std 0.0715 (0.0541) nleep/row_max_mean 1201.9491 (1200.5233) nleep/row_max_std 15.2948 (16.1580) nleep/row_min_mean 1200.9631 (1199.7430) lr 1.9980e-03 eta 1:00:56
epoch [3/50] batch [80/246] time 0.517 (0.347) data 0.000 (0.004) loss 2.1105 (1.4192) teacher_loss 1.7995 (1.1833) loss_zs_kd 0.0256 (0.0254) loss_oracle 0.4131 (0.3263) kd_loss 0.0917 (0.0600) acc 62.5000 (69.8047) gate/entropy 1.0974 (1.0978) gate/usage_max 0.3517 (0.3488) gate/usage_min 0.3121 (0.3156) gate/usage_std 0.0163 (0.0136) teacher/entropy 0.9983 (1.0336) teacher/usage_max 0.4370 (0.3916) teacher/usage_min 0.2116 (0.2550) teacher/usage_std 0.0929 (0.0584) nleep/row_max_mean 1203.3301 (1200.8295) nleep/row_max_std 16.3717 (16.3319) nleep/row_min_mean 1202.2377 (1200.0227) lr 1.9980e-03 eta 1:07:54
epoch [3/50] batch [100/246] time 0.495 (0.380) data 0.000 (0.003) loss 1.2140 (1.4215) teacher_loss 0.9851 (1.1812) loss_zs_kd 0.0058 (0.0257) loss_oracle 0.2811 (0.3295) kd_loss 0.0855 (0.0628) acc 68.7500 (69.8125) gate/entropy 1.0972 (1.0977) gate/usage_max 0.3533 (0.3495) gate/usage_min 0.3106 (0.3148) gate/usage_std 0.0175 (0.0143) teacher/entropy 1.0070 (1.0305) teacher/usage_max 0.3901 (0.3936) teacher/usage_min 0.2535 (0.2524) teacher/usage_std 0.0581 (0.0603) nleep/row_max_mean 1201.6121 (1200.9156) nleep/row_max_std 23.1920 (16.5323) nleep/row_min_mean 1200.6772 (1200.0888) lr 1.9980e-03 eta 1:14:03
epoch [3/50] batch [120/246] time 0.518 (0.401) data 0.000 (0.003) loss 1.1826 (1.4055) teacher_loss 1.0242 (1.1719) loss_zs_kd 0.0146 (0.0252) loss_oracle 0.2034 (0.3156) kd_loss 0.0494 (0.0632) acc 75.0000 (70.0000) gate/entropy 1.0970 (1.0976) gate/usage_max 0.3546 (0.3503) gate/usage_min 0.3092 (0.3139) gate/usage_std 0.0187 (0.0149) teacher/entropy 1.0445 (1.0299) teacher/usage_max 0.3640 (0.3959) teacher/usage_min 0.2799 (0.2514) teacher/usage_std 0.0379 (0.0614) nleep/row_max_mean 1202.2516 (1201.0872) nleep/row_max_std 15.3134 (16.4443) nleep/row_min_mean 1201.5530 (1200.2558) lr 1.9980e-03 eta 1:18:06
epoch [3/50] batch [140/246] time 0.225 (0.386) data 0.000 (0.002) loss 1.7929 (1.4029) teacher_loss 1.5593 (1.1737) loss_zs_kd 0.0131 (0.0249) loss_oracle 0.2558 (0.3023) kd_loss 0.0992 (0.0657) acc 53.1250 (69.7321) gate/entropy 1.0968 (1.0975) gate/usage_max 0.3555 (0.3510) gate/usage_min 0.3075 (0.3131) gate/usage_std 0.0198 (0.0156) teacher/entropy 0.9887 (1.0271) teacher/usage_max 0.3878 (0.3981) teacher/usage_min 0.2291 (0.2492) teacher/usage_std 0.0737 (0.0632) nleep/row_max_mean 1204.7030 (1201.2393) nleep/row_max_std 17.3812 (16.3824) nleep/row_min_mean 1203.6106 (1200.3868) lr 1.9980e-03 eta 1:15:07
epoch [3/50] batch [160/246] time 0.079 (0.384) data 0.000 (0.002) loss 1.1995 (1.4015) teacher_loss 0.9955 (1.1732) loss_zs_kd 0.0285 (0.0251) loss_oracle 0.2385 (0.2944) kd_loss 0.0705 (0.0686) acc 75.0000 (69.8633) gate/entropy 1.0967 (1.0974) gate/usage_max 0.3552 (0.3515) gate/usage_min 0.3062 (0.3123) gate/usage_std 0.0204 (0.0161) teacher/entropy 1.0209 (1.0240) teacher/usage_max 0.4093 (0.4018) teacher/usage_min 0.2466 (0.2478) teacher/usage_std 0.0669 (0.0653) nleep/row_max_mean 1202.7827 (1201.3358) nleep/row_max_std 18.5488 (16.3956) nleep/row_min_mean 1201.8760 (1200.4629) lr 1.9980e-03 eta 1:14:37
epoch [3/50] batch [180/246] time 0.079 (0.366) data 0.000 (0.002) loss 1.4228 (1.3910) teacher_loss 1.2494 (1.1639) loss_zs_kd 0.0169 (0.0249) loss_oracle 0.1769 (0.2860) kd_loss 0.0765 (0.0716) acc 68.7500 (69.9306) gate/entropy 1.0966 (1.0973) gate/usage_max 0.3546 (0.3519) gate/usage_min 0.3050 (0.3116) gate/usage_std 0.0208 (0.0166) teacher/entropy 1.0177 (1.0211) teacher/usage_max 0.4385 (0.4046) teacher/usage_min 0.2627 (0.2494) teacher/usage_std 0.0758 (0.0658) nleep/row_max_mean 1201.6355 (1201.4092) nleep/row_max_std 12.9806 (16.2003) nleep/row_min_mean 1200.7014 (1200.5189) lr 1.9980e-03 eta 1:10:51
epoch [3/50] batch [200/246] time 0.465 (0.373) data 0.000 (0.002) loss 1.2864 (1.3898) teacher_loss 1.0768 (1.1627) loss_zs_kd 0.0164 (0.0251) loss_oracle 0.2406 (0.2818) kd_loss 0.0810 (0.0737) acc 75.0000 (69.8750) gate/entropy 1.0965 (1.0972) gate/usage_max 0.3541 (0.3521) gate/usage_min 0.3039 (0.3109) gate/usage_std 0.0214 (0.0171) teacher/entropy 1.0127 (1.0191) teacher/usage_max 0.4403 (0.4075) teacher/usage_min 0.2637 (0.2506) teacher/usage_std 0.0768 (0.0667) nleep/row_max_mean 1197.1770 (1201.3635) nleep/row_max_std 14.5040 (16.0039) nleep/row_min_mean 1196.2424 (1200.4621) lr 1.9980e-03 eta 1:12:12
epoch [3/50] batch [220/246] time 0.472 (0.381) data 0.000 (0.002) loss 1.0809 (1.3923) teacher_loss 0.8145 (1.1627) loss_zs_kd 0.0123 (0.0253) loss_oracle 0.3103 (0.2812) kd_loss 0.1051 (0.0764) acc 75.0000 (69.7869) gate/entropy 1.0964 (1.0972) gate/usage_max 0.3543 (0.3523) gate/usage_min 0.3027 (0.3102) gate/usage_std 0.0221 (0.0175) teacher/entropy 0.9881 (1.0165) teacher/usage_max 0.4307 (0.4093) teacher/usage_min 0.2642 (0.2518) teacher/usage_std 0.0708 (0.0670) nleep/row_max_mean 1203.5638 (1201.4242) nleep/row_max_std 13.5917 (15.7788) nleep/row_min_mean 1202.4180 (1200.5079) lr 1.9980e-03 eta 1:13:37
epoch [3/50] batch [240/246] time 0.474 (0.389) data 0.000 (0.001) loss 1.1380 (1.3941) teacher_loss 0.8105 (1.1564) loss_zs_kd 0.0143 (0.0257) loss_oracle 0.3675 (0.2921) kd_loss 0.1365 (0.0787) acc 78.1250 (70.0260) gate/entropy 1.0962 (1.0971) gate/usage_max 0.3553 (0.3525) gate/usage_min 0.3016 (0.3095) gate/usage_std 0.0230 (0.0179) teacher/entropy 0.9566 (1.0142) teacher/usage_max 0.4057 (0.4102) teacher/usage_min 0.2698 (0.2528) teacher/usage_std 0.0558 (0.0669) nleep/row_max_mean 1204.5381 (1201.4571) nleep/row_max_std 14.4352 (15.6419) nleep/row_min_mean 1203.2590 (1200.5281) lr 1.9980e-03 eta 1:14:56
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,841
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,967
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 89.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.7%, epoch: 3 *******
******* Domain r best val test acc: 91.0%, epoch: 3 *******
******* Domain r best test acc:     91.0%, epoch: 3 *******
epoch [4/50] batch [20/246] time 0.451 (0.270) data 0.000 (0.011) loss 1.2143 (1.3307) teacher_loss 1.0446 (1.0892) loss_zs_kd 0.0162 (0.0249) loss_oracle 0.1471 (0.2611) kd_loss 0.0880 (0.0984) acc 71.8750 (72.1875) gate/entropy 1.0960 (1.0961) gate/usage_max 0.3568 (0.3562) gate/usage_min 0.3006 (0.3009) gate/usage_std 0.0239 (0.0236) teacher/entropy 1.0123 (0.9967) teacher/usage_max 0.3519 (0.3887) teacher/usage_min 0.3234 (0.2835) teacher/usage_std 0.0131 (0.0453) nleep/row_max_mean 1202.8927 (1201.8368) nleep/row_max_std 16.4342 (13.6207) nleep/row_min_mean 1201.9861 (1200.8001) lr 1.9921e-03 eta 0:51:58
epoch [4/50] batch [40/246] time 0.441 (0.313) data 0.000 (0.006) loss 1.3466 (1.2884) teacher_loss 1.1074 (1.0577) loss_zs_kd 0.0115 (0.0244) loss_oracle 0.2530 (0.2352) kd_loss 0.1070 (0.1008) acc 78.1250 (73.0469) gate/entropy 1.0959 (1.0960) gate/usage_max 0.3570 (0.3566) gate/usage_min 0.3001 (0.3005) gate/usage_std 0.0242 (0.0239) teacher/entropy 0.9878 (0.9947) teacher/usage_max 0.3562 (0.3840) teacher/usage_min 0.2921 (0.2849) teacher/usage_std 0.0292 (0.0423) nleep/row_max_mean 1208.5018 (1203.2041) nleep/row_max_std 15.9232 (13.7831) nleep/row_min_mean 1207.4314 (1202.1567) lr 1.9921e-03 eta 1:00:07
epoch [4/50] batch [60/246] time 0.498 (0.379) data 0.000 (0.004) loss 1.5396 (1.3079) teacher_loss 1.2701 (1.0717) loss_zs_kd 0.0265 (0.0259) loss_oracle 0.3172 (0.2394) kd_loss 0.0977 (0.1035) acc 62.5000 (72.2396) gate/entropy 1.0959 (1.0960) gate/usage_max 0.3576 (0.3569) gate/usage_min 0.2997 (0.3003) gate/usage_std 0.0246 (0.0240) teacher/entropy 0.9985 (0.9931) teacher/usage_max 0.3903 (0.3824) teacher/usage_min 0.2904 (0.2869) teacher/usage_std 0.0420 (0.0408) nleep/row_max_mean 1202.6544 (1202.9685) nleep/row_max_std 14.0561 (13.6678) nleep/row_min_mean 1201.6649 (1201.9165) lr 1.9921e-03 eta 1:12:39
epoch [4/50] batch [80/246] time 0.497 (0.405) data 0.000 (0.003) loss 1.0923 (1.3232) teacher_loss 0.7756 (1.0665) loss_zs_kd 0.0210 (0.0267) loss_oracle 0.4498 (0.2779) kd_loss 0.0814 (0.1044) acc 78.1250 (72.1094) gate/entropy 1.0957 (1.0959) gate/usage_max 0.3588 (0.3572) gate/usage_min 0.2989 (0.3001) gate/usage_std 0.0253 (0.0242) teacher/entropy 1.0174 (0.9919) teacher/usage_max 0.3435 (0.3831) teacher/usage_min 0.3161 (0.2863) teacher/usage_std 0.0122 (0.0412) nleep/row_max_mean 1204.2722 (1202.8153) nleep/row_max_std 13.0378 (13.6488) nleep/row_min_mean 1203.3805 (1201.7571) lr 1.9921e-03 eta 1:17:30
epoch [4/50] batch [100/246] time 0.086 (0.415) data 0.000 (0.002) loss 1.3323 (1.3362) teacher_loss 1.0309 (1.0703) loss_zs_kd 0.0231 (0.0265) loss_oracle 0.2929 (0.2925) kd_loss 0.1434 (0.1064) acc 65.6250 (71.9062) gate/entropy 1.0955 (1.0959) gate/usage_max 0.3600 (0.3576) gate/usage_min 0.2977 (0.2997) gate/usage_std 0.0262 (0.0245) teacher/entropy 0.9471 (0.9899) teacher/usage_max 0.4150 (0.3836) teacher/usage_min 0.2522 (0.2861) teacher/usage_std 0.0664 (0.0414) nleep/row_max_mean 1208.8954 (1202.8049) nleep/row_max_std 13.6748 (13.6738) nleep/row_min_mean 1207.6339 (1201.7391) lr 1.9921e-03 eta 1:19:12
epoch [4/50] batch [120/246] time 0.485 (0.395) data 0.000 (0.002) loss 1.7793 (1.3430) teacher_loss 1.4629 (1.0750) loss_zs_kd 0.0276 (0.0268) loss_oracle 0.2913 (0.2891) kd_loss 0.1570 (0.1101) acc 59.3750 (71.5625) gate/entropy 1.0954 (1.0958) gate/usage_max 0.3603 (0.3580) gate/usage_min 0.2970 (0.2993) gate/usage_std 0.0267 (0.0249) teacher/entropy 0.9487 (0.9870) teacher/usage_max 0.4089 (0.3831) teacher/usage_min 0.2566 (0.2871) teacher/usage_std 0.0622 (0.0408) nleep/row_max_mean 1203.1194 (1202.9546) nleep/row_max_std 17.6155 (13.7816) nleep/row_min_mean 1201.8436 (1201.8729) lr 1.9921e-03 eta 1:15:17
epoch [4/50] batch [140/246] time 0.519 (0.376) data 0.000 (0.002) loss 1.2506 (1.3312) teacher_loss 0.9931 (1.0592) loss_zs_kd 0.0162 (0.0267) loss_oracle 0.2531 (0.2894) kd_loss 0.1229 (0.1140) acc 71.8750 (71.9643) gate/entropy 1.0953 (1.0957) gate/usage_max 0.3604 (0.3584) gate/usage_min 0.2963 (0.2990) gate/usage_std 0.0271 (0.0251) teacher/entropy 0.9752 (0.9840) teacher/usage_max 0.4153 (0.3843) teacher/usage_min 0.2919 (0.2868) teacher/usage_std 0.0579 (0.0416) nleep/row_max_mean 1200.6157 (1202.8720) nleep/row_max_std 12.2832 (13.6705) nleep/row_min_mean 1199.4946 (1201.7769) lr 1.9921e-03 eta 1:11:39
epoch [4/50] batch [160/246] time 0.472 (0.378) data 0.000 (0.002) loss 1.2940 (1.3499) teacher_loss 1.0305 (1.0732) loss_zs_kd 0.0141 (0.0274) loss_oracle 0.2179 (0.2880) kd_loss 0.1475 (0.1190) acc 68.7500 (71.7969) gate/entropy 1.0952 (1.0957) gate/usage_max 0.3603 (0.3586) gate/usage_min 0.2957 (0.2986) gate/usage_std 0.0274 (0.0254) teacher/entropy 0.9652 (0.9795) teacher/usage_max 0.3971 (0.3857) teacher/usage_min 0.2917 (0.2854) teacher/usage_std 0.0458 (0.0429) nleep/row_max_mean 1208.1475 (1202.7546) nleep/row_max_std 15.0625 (13.7091) nleep/row_min_mean 1206.9927 (1201.6393) lr 1.9921e-03 eta 1:11:50
epoch [4/50] batch [180/246] time 0.452 (0.387) data 0.000 (0.001) loss 1.1699 (1.3588) teacher_loss 0.8113 (1.0775) loss_zs_kd 0.0127 (0.0277) loss_oracle 0.2284 (0.2850) kd_loss 0.2380 (0.1250) acc 71.8750 (71.5625) gate/entropy 1.0952 (1.0956) gate/usage_max 0.3598 (0.3588) gate/usage_min 0.2954 (0.2982) gate/usage_std 0.0275 (0.0256) teacher/entropy 0.8784 (0.9745) teacher/usage_max 0.4065 (0.3847) teacher/usage_min 0.2560 (0.2850) teacher/usage_std 0.0615 (0.0428) nleep/row_max_mean 1205.7312 (1202.7662) nleep/row_max_std 13.5885 (13.6105) nleep/row_min_mean 1204.2600 (1201.6255) lr 1.9921e-03 eta 1:13:21
epoch [4/50] batch [200/246] time 0.495 (0.396) data 0.000 (0.001) loss 1.7498 (1.3663) teacher_loss 1.4128 (1.0821) loss_zs_kd 0.0470 (0.0276) loss_oracle 0.3275 (0.2859) kd_loss 0.1497 (0.1275) acc 71.8750 (71.4062) gate/entropy 1.0951 (1.0956) gate/usage_max 0.3594 (0.3589) gate/usage_min 0.2949 (0.2979) gate/usage_std 0.0277 (0.0258) teacher/entropy 0.9581 (0.9723) teacher/usage_max 0.3629 (0.3856) teacher/usage_min 0.3074 (0.2849) teacher/usage_std 0.0228 (0.0431) nleep/row_max_mean 1198.4812 (1202.8202) nleep/row_max_std 12.2957 (13.6467) nleep/row_min_mean 1197.2876 (1201.6693) lr 1.9921e-03 eta 1:14:57
epoch [4/50] batch [220/246] time 0.463 (0.404) data 0.000 (0.001) loss 1.0197 (1.3641) teacher_loss 0.6418 (1.0723) loss_zs_kd 0.0223 (0.0278) loss_oracle 0.3169 (0.2931) kd_loss 0.2084 (0.1314) acc 81.2500 (71.5625) gate/entropy 1.0950 (1.0955) gate/usage_max 0.3588 (0.3589) gate/usage_min 0.2945 (0.2977) gate/usage_std 0.0279 (0.0260) teacher/entropy 0.9012 (0.9689) teacher/usage_max 0.3678 (0.3853) teacher/usage_min 0.2721 (0.2850) teacher/usage_std 0.0434 (0.0429) nleep/row_max_mean 1203.5793 (1202.8850) nleep/row_max_std 16.7880 (13.6466) nleep/row_min_mean 1202.1145 (1201.7156) lr 1.9921e-03 eta 1:16:19
epoch [4/50] batch [240/246] time 0.461 (0.387) data 0.000 (0.001) loss 1.4571 (1.3751) teacher_loss 1.1456 (1.0774) loss_zs_kd 0.0113 (0.0281) loss_oracle 0.2985 (0.2959) kd_loss 0.1565 (0.1358) acc 75.0000 (71.5234) gate/entropy 1.0950 (1.0955) gate/usage_max 0.3575 (0.3588) gate/usage_min 0.2942 (0.2974) gate/usage_std 0.0279 (0.0262) teacher/entropy 0.9577 (0.9651) teacher/usage_max 0.3907 (0.3859) teacher/usage_min 0.2386 (0.2833) teacher/usage_std 0.0675 (0.0439) nleep/row_max_mean 1200.3386 (1202.8531) nleep/row_max_std 13.7930 (13.6338) nleep/row_min_mean 1199.1353 (1201.6650) lr 1.9921e-03 eta 1:12:56
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,839
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,969
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.7%, epoch: 3 *******
******* Domain r best val test acc: 91.0%, epoch: 3 *******
******* Domain r best test acc:     91.1%, epoch: 4 *******
epoch [5/50] batch [20/246] time 0.451 (0.539) data 0.000 (0.011) loss 1.4752 (1.4317) teacher_loss 1.1331 (1.0788) loss_zs_kd 0.0374 (0.0315) loss_oracle 0.3076 (0.3085) kd_loss 0.1695 (0.1829) acc 71.8750 (72.6562) gate/entropy 1.0950 (1.0950) gate/usage_max 0.3558 (0.3564) gate/usage_min 0.2940 (0.2941) gate/usage_std 0.0279 (0.0279) teacher/entropy 0.9469 (0.9278) teacher/usage_max 0.4074 (0.4008) teacher/usage_min 0.2452 (0.2565) teacher/usage_std 0.0669 (0.0609) nleep/row_max_mean 1201.1031 (1201.3897) nleep/row_max_std 11.2490 (13.2089) nleep/row_min_mean 1199.8015 (1200.0096) lr 1.9823e-03 eta 1:41:26
epoch [5/50] batch [40/246] time 0.496 (0.511) data 0.000 (0.006) loss 1.9016 (1.4497) teacher_loss 1.4911 (1.0785) loss_zs_kd 0.0410 (0.0287) loss_oracle 0.3812 (0.3171) kd_loss 0.1993 (0.1984) acc 62.5000 (72.8125) gate/entropy 1.0950 (1.0950) gate/usage_max 0.3543 (0.3557) gate/usage_min 0.2940 (0.2940) gate/usage_std 0.0279 (0.0279) teacher/entropy 0.9050 (0.9141) teacher/usage_max 0.4334 (0.4127) teacher/usage_min 0.2257 (0.2353) teacher/usage_std 0.0850 (0.0753) nleep/row_max_mean 1197.6433 (1201.5205) nleep/row_max_std 12.1336 (13.4305) nleep/row_min_mean 1196.2251 (1200.0803) lr 1.9823e-03 eta 1:35:57
epoch [5/50] batch [60/246] time 0.462 (0.501) data 0.000 (0.004) loss 1.1926 (1.4472) teacher_loss 0.7780 (1.0769) loss_zs_kd 0.0098 (0.0283) loss_oracle 0.2934 (0.3076) kd_loss 0.2630 (0.2023) acc 78.1250 (71.9271) gate/entropy 1.0950 (1.0950) gate/usage_max 0.3535 (0.3551) gate/usage_min 0.2940 (0.2940) gate/usage_std 0.0278 (0.0279) teacher/entropy 0.8600 (0.9102) teacher/usage_max 0.4456 (0.4131) teacher/usage_min 0.1977 (0.2308) teacher/usage_std 0.1026 (0.0777) nleep/row_max_mean 1205.6971 (1201.9367) nleep/row_max_std 15.0299 (13.6031) nleep/row_min_mean 1203.9541 (1200.4735) lr 1.9823e-03 eta 1:34:02
epoch [5/50] batch [80/246] time 0.423 (0.424) data 0.000 (0.003) loss 1.3783 (1.4533) teacher_loss 0.9682 (1.0760) loss_zs_kd 0.0199 (0.0275) loss_oracle 0.3677 (0.3103) kd_loss 0.2163 (0.2084) acc 71.8750 (72.1875) gate/entropy 1.0951 (1.0951) gate/usage_max 0.3536 (0.3546) gate/usage_min 0.2943 (0.2940) gate/usage_std 0.0276 (0.0278) teacher/entropy 0.8968 (0.9046) teacher/usage_max 0.3961 (0.4142) teacher/usage_min 0.2417 (0.2286) teacher/usage_std 0.0662 (0.0792) nleep/row_max_mean 1203.4221 (1201.9650) nleep/row_max_std 15.5290 (13.7853) nleep/row_min_mean 1201.8767 (1200.4790) lr 1.9823e-03 eta 1:19:19
epoch [5/50] batch [100/246] time 0.101 (0.402) data 0.000 (0.002) loss 1.3954 (1.4641) teacher_loss 0.9470 (1.0742) loss_zs_kd 0.0569 (0.0298) loss_oracle 0.3381 (0.3172) kd_loss 0.2509 (0.2165) acc 68.7500 (72.0625) gate/entropy 1.0951 (1.0951) gate/usage_max 0.3543 (0.3545) gate/usage_min 0.2945 (0.2941) gate/usage_std 0.0275 (0.0278) teacher/entropy 0.8722 (0.8971) teacher/usage_max 0.4535 (0.4158) teacher/usage_min 0.2141 (0.2262) teacher/usage_std 0.0977 (0.0808) nleep/row_max_mean 1201.2231 (1202.0063) nleep/row_max_std 12.5123 (13.8483) nleep/row_min_mean 1199.6023 (1200.4905) lr 1.9823e-03 eta 1:15:08
epoch [5/50] batch [120/246] time 0.495 (0.392) data 0.000 (0.002) loss 1.2351 (1.4854) teacher_loss 0.8330 (1.0920) loss_zs_kd 0.0384 (0.0304) loss_oracle 0.3175 (0.3152) kd_loss 0.2242 (0.2205) acc 81.2500 (71.7708) gate/entropy 1.0952 (1.0951) gate/usage_max 0.3551 (0.3545) gate/usage_min 0.2947 (0.2942) gate/usage_std 0.0274 (0.0277) teacher/entropy 0.8868 (0.8937) teacher/usage_max 0.3876 (0.4182) teacher/usage_min 0.2464 (0.2254) teacher/usage_std 0.0621 (0.0821) nleep/row_max_mean 1196.2155 (1202.0039) nleep/row_max_std 12.7185 (13.9235) nleep/row_min_mean 1194.6453 (1200.4698) lr 1.9823e-03 eta 1:13:07
epoch [5/50] batch [140/246] time 0.468 (0.405) data 0.000 (0.002) loss 2.0156 (1.4931) teacher_loss 1.5418 (1.0963) loss_zs_kd 0.0522 (0.0301) loss_oracle 0.3388 (0.3126) kd_loss 0.2783 (0.2255) acc 65.6250 (71.7857) gate/entropy 1.0952 (1.0951) gate/usage_max 0.3559 (0.3546) gate/usage_min 0.2952 (0.2943) gate/usage_std 0.0271 (0.0276) teacher/entropy 0.8346 (0.8895) teacher/usage_max 0.4425 (0.4228) teacher/usage_min 0.1444 (0.2204) teacher/usage_std 0.1342 (0.0861) nleep/row_max_mean 1204.1555 (1201.9093) nleep/row_max_std 16.2117 (13.9338) nleep/row_min_mean 1202.2061 (1200.3517) lr 1.9823e-03 eta 1:15:25
epoch [5/50] batch [160/246] time 0.484 (0.414) data 0.000 (0.002) loss 1.7311 (1.5015) teacher_loss 1.2855 (1.1002) loss_zs_kd 0.0258 (0.0303) loss_oracle 0.2824 (0.3077) kd_loss 0.2915 (0.2323) acc 62.5000 (71.5625) gate/entropy 1.0953 (1.0951) gate/usage_max 0.3568 (0.3549) gate/usage_min 0.2960 (0.2945) gate/usage_std 0.0267 (0.0275) teacher/entropy 0.8310 (0.8832) teacher/usage_max 0.4714 (0.4269) teacher/usage_min 0.1542 (0.2146) teacher/usage_std 0.1327 (0.0903) nleep/row_max_mean 1204.0282 (1201.9650) nleep/row_max_std 16.3313 (13.9928) nleep/row_min_mean 1202.0157 (1200.3741) lr 1.9823e-03 eta 1:16:54
epoch [5/50] batch [180/246] time 0.498 (0.421) data 0.000 (0.001) loss 1.6717 (1.5049) teacher_loss 1.1211 (1.0965) loss_zs_kd 0.0394 (0.0304) loss_oracle 0.3109 (0.3073) kd_loss 0.3755 (0.2396) acc 71.8750 (71.5799) gate/entropy 1.0955 (1.0952) gate/usage_max 0.3572 (0.3551) gate/usage_min 0.2972 (0.2947) gate/usage_std 0.0260 (0.0274) teacher/entropy 0.7542 (0.8767) teacher/usage_max 0.5225 (0.4325) teacher/usage_min 0.1315 (0.2084) teacher/usage_std 0.1599 (0.0951) nleep/row_max_mean 1204.2461 (1201.9856) nleep/row_max_std 14.6253 (14.0732) nleep/row_min_mean 1201.9728 (1200.3560) lr 1.9823e-03 eta 1:18:10
epoch [5/50] batch [200/246] time 0.214 (0.403) data 0.000 (0.001) loss 1.6026 (1.5184) teacher_loss 1.0928 (1.1013) loss_zs_kd 0.0313 (0.0307) loss_oracle 0.2908 (0.3067) kd_loss 0.3488 (0.2484) acc 71.8750 (71.3281) gate/entropy 1.0957 (1.0952) gate/usage_max 0.3576 (0.3553) gate/usage_min 0.2987 (0.2950) gate/usage_std 0.0251 (0.0272) teacher/entropy 0.7714 (0.8685) teacher/usage_max 0.4835 (0.4382) teacher/usage_min 0.1271 (0.2020) teacher/usage_std 0.1508 (0.1001) nleep/row_max_mean 1205.3018 (1202.0266) nleep/row_max_std 18.1758 (14.1411) nleep/row_min_mean 1203.0459 (1200.3506) lr 1.9823e-03 eta 1:14:40
epoch [5/50] batch [220/246] time 0.100 (0.397) data 0.000 (0.001) loss 1.9724 (1.5210) teacher_loss 1.4540 (1.0950) loss_zs_kd 0.0309 (0.0307) loss_oracle 0.2762 (0.3054) kd_loss 0.3649 (0.2579) acc 68.7500 (71.4631) gate/entropy 1.0959 (1.0953) gate/usage_max 0.3577 (0.3555) gate/usage_min 0.3001 (0.2954) gate/usage_std 0.0244 (0.0270) teacher/entropy 0.7616 (0.8601) teacher/usage_max 0.5314 (0.4473) teacher/usage_min 0.1218 (0.1953) teacher/usage_std 0.1675 (0.1064) nleep/row_max_mean 1204.7124 (1202.1106) nleep/row_max_std 13.4627 (14.2248) nleep/row_min_mean 1202.4553 (1200.3873) lr 1.9823e-03 eta 1:13:29
epoch [5/50] batch [240/246] time 0.497 (0.390) data 0.000 (0.001) loss 1.7534 (1.5276) teacher_loss 1.1063 (1.0914) loss_zs_kd 0.0259 (0.0309) loss_oracle 0.3385 (0.3094) kd_loss 0.4648 (0.2661) acc 71.8750 (71.5755) gate/entropy 1.0961 (1.0953) gate/usage_max 0.3574 (0.3557) gate/usage_min 0.3015 (0.2959) gate/usage_std 0.0235 (0.0267) teacher/entropy 0.6695 (0.8525) teacher/usage_max 0.5856 (0.4534) teacher/usage_min 0.1325 (0.1916) teacher/usage_std 0.1885 (0.1103) nleep/row_max_mean 1207.2263 (1202.1231) nleep/row_max_std 15.3190 (14.2524) nleep/row_min_mean 1204.8022 (1200.3642) lr 1.9823e-03 eta 1:12:01
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,847
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,968
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.1%
******* Domain r best val acc:      84.9%, epoch: 5 *******
******* Domain r best val test acc: 91.1%, epoch: 5 *******
******* Domain r best test acc:     91.1%, epoch: 4 *******
epoch [6/50] batch [20/246] time 0.452 (0.501) data 0.000 (0.013) loss 1.5208 (1.6149) teacher_loss 1.0001 (1.0944) loss_zs_kd 0.0309 (0.0341) loss_oracle 0.2996 (0.3261) kd_loss 0.3554 (0.3403) acc 75.0000 (75.0000) gate/entropy 1.0964 (1.0963) gate/usage_max 0.3566 (0.3569) gate/usage_min 0.3035 (0.3027) gate/usage_std 0.0222 (0.0227) teacher/entropy 0.7640 (0.7823) teacher/usage_max 0.5055 (0.5150) teacher/usage_min 0.1437 (0.1637) teacher/usage_std 0.1482 (0.1458) nleep/row_max_mean 1205.6865 (1201.2647) nleep/row_max_std 15.7575 (13.7775) nleep/row_min_mean 1203.5156 (1199.1447) lr 1.9686e-03 eta 1:32:10
epoch [6/50] batch [40/246] time 0.258 (0.481) data 0.000 (0.006) loss 1.8210 (1.5975) teacher_loss 1.3152 (1.0656) loss_zs_kd 0.0232 (0.0316) loss_oracle 0.2629 (0.3111) kd_loss 0.3628 (0.3605) acc 62.5000 (74.8438) gate/entropy 1.0966 (1.0964) gate/usage_max 0.3557 (0.3565) gate/usage_min 0.3051 (0.3035) gate/usage_std 0.0211 (0.0221) teacher/entropy 0.7711 (0.7655) teacher/usage_max 0.6068 (0.5434) teacher/usage_min 0.1532 (0.1584) teacher/usage_std 0.1966 (0.1618) nleep/row_max_mean 1203.2822 (1202.0762) nleep/row_max_std 14.2852 (14.4294) nleep/row_min_mean 1201.1116 (1199.8983) lr 1.9686e-03 eta 1:28:27
epoch [6/50] batch [60/246] time 0.408 (0.379) data 0.000 (0.004) loss 1.6371 (1.5768) teacher_loss 1.0422 (1.0453) loss_zs_kd 0.0309 (0.0317) loss_oracle 0.3638 (0.3025) kd_loss 0.3975 (0.3644) acc 78.1250 (74.8438) gate/entropy 1.0969 (1.0965) gate/usage_max 0.3549 (0.3561) gate/usage_min 0.3074 (0.3045) gate/usage_std 0.0196 (0.0215) teacher/entropy 0.7255 (0.7617) teacher/usage_max 0.5609 (0.5510) teacher/usage_min 0.1381 (0.1573) teacher/usage_std 0.1741 (0.1657) nleep/row_max_mean 1199.3923 (1202.1297) nleep/row_max_std 12.8961 (14.5601) nleep/row_min_mean 1197.0774 (1199.9388) lr 1.9686e-03 eta 1:09:33
epoch [6/50] batch [80/246] time 0.119 (0.356) data 0.000 (0.003) loss 1.7135 (1.5930) teacher_loss 1.0814 (1.0539) loss_zs_kd 0.0272 (0.0310) loss_oracle 0.3487 (0.3079) kd_loss 0.4441 (0.3696) acc 81.2500 (74.2969) gate/entropy 1.0971 (1.0966) gate/usage_max 0.3541 (0.3557) gate/usage_min 0.3096 (0.3055) gate/usage_std 0.0183 (0.0209) teacher/entropy 0.6862 (0.7563) teacher/usage_max 0.6361 (0.5586) teacher/usage_min 0.1319 (0.1571) teacher/usage_std 0.2179 (0.1696) nleep/row_max_mean 1202.2471 (1202.0433) nleep/row_max_std 15.5520 (14.2897) nleep/row_min_mean 1199.7032 (1199.8409) lr 1.9686e-03 eta 1:05:17
epoch [6/50] batch [100/246] time 0.497 (0.365) data 0.000 (0.003) loss 1.7248 (1.5857) teacher_loss 1.2722 (1.0422) loss_zs_kd 0.0470 (0.0324) loss_oracle 0.3831 (0.3167) kd_loss 0.2376 (0.3689) acc 75.0000 (74.5000) gate/entropy 1.0973 (1.0967) gate/usage_max 0.3530 (0.3553) gate/usage_min 0.3114 (0.3065) gate/usage_std 0.0171 (0.0202) teacher/entropy 0.8734 (0.7563) teacher/usage_max 0.4556 (0.5615) teacher/usage_min 0.2500 (0.1582) teacher/usage_std 0.0884 (0.1709) nleep/row_max_mean 1199.4161 (1201.7763) nleep/row_max_std 14.6163 (14.3436) nleep/row_min_mean 1197.7179 (1199.5740) lr 1.9686e-03 eta 1:06:44
epoch [6/50] batch [120/246] time 0.495 (0.386) data 0.000 (0.002) loss 1.4021 (1.5760) teacher_loss 0.8405 (1.0253) loss_zs_kd 0.0614 (0.0335) loss_oracle 0.3358 (0.3164) kd_loss 0.3630 (0.3758) acc 71.8750 (74.8438) gate/entropy 1.0975 (1.0968) gate/usage_max 0.3520 (0.3548) gate/usage_min 0.3132 (0.3075) gate/usage_std 0.0159 (0.0196) teacher/entropy 0.7584 (0.7493) teacher/usage_max 0.5676 (0.5694) teacher/usage_min 0.2065 (0.1582) teacher/usage_std 0.1658 (0.1754) nleep/row_max_mean 1200.2227 (1201.6317) nleep/row_max_std 14.8582 (14.4227) nleep/row_min_mean 1198.0374 (1199.3992) lr 1.9686e-03 eta 1:10:22
epoch [6/50] batch [140/246] time 0.494 (0.401) data 0.000 (0.002) loss 1.6310 (1.5833) teacher_loss 0.9587 (1.0290) loss_zs_kd 0.0197 (0.0328) loss_oracle 0.3402 (0.3138) kd_loss 0.4923 (0.3810) acc 71.8750 (74.6205) gate/entropy 1.0977 (1.0970) gate/usage_max 0.3508 (0.3543) gate/usage_min 0.3160 (0.3085) gate/usage_std 0.0142 (0.0189) teacher/entropy 0.6324 (0.7434) teacher/usage_max 0.6853 (0.5741) teacher/usage_min 0.1126 (0.1582) teacher/usage_std 0.2515 (0.1782) nleep/row_max_mean 1200.8662 (1201.7005) nleep/row_max_std 13.3879 (14.4708) nleep/row_min_mean 1197.9758 (1199.4394) lr 1.9686e-03 eta 1:12:58
epoch [6/50] batch [160/246] time 0.548 (0.414) data 0.000 (0.002) loss 1.5971 (1.6108) teacher_loss 1.0498 (1.0498) loss_zs_kd 0.0263 (0.0331) loss_oracle 0.3413 (0.3131) kd_loss 0.3635 (0.3879) acc 71.8750 (74.2188) gate/entropy 1.0979 (1.0971) gate/usage_max 0.3500 (0.3538) gate/usage_min 0.3186 (0.3096) gate/usage_std 0.0129 (0.0183) teacher/entropy 0.7492 (0.7359) teacher/usage_max 0.5661 (0.5829) teacher/usage_min 0.1814 (0.1565) teacher/usage_std 0.1671 (0.1836) nleep/row_max_mean 1203.5122 (1201.6499) nleep/row_max_std 16.1972 (14.5883) nleep/row_min_mean 1201.2224 (1199.3508) lr 1.9686e-03 eta 1:15:18
epoch [6/50] batch [180/246] time 0.496 (0.396) data 0.000 (0.002) loss 1.9436 (1.6129) teacher_loss 1.3201 (1.0449) loss_zs_kd 0.0333 (0.0328) loss_oracle 0.3425 (0.3166) kd_loss 0.4356 (0.3933) acc 68.7500 (74.2708) gate/entropy 1.0980 (1.0972) gate/usage_max 0.3493 (0.3534) gate/usage_min 0.3210 (0.3108) gate/usage_std 0.0118 (0.0176) teacher/entropy 0.6812 (0.7295) teacher/usage_max 0.6532 (0.5874) teacher/usage_min 0.1713 (0.1558) teacher/usage_std 0.2262 (0.1864) nleep/row_max_mean 1199.0557 (1201.5205) nleep/row_max_std 9.9371 (14.5479) nleep/row_min_mean 1196.4816 (1199.1896) lr 1.9686e-03 eta 1:11:55
epoch [6/50] batch [200/246] time 0.430 (0.381) data 0.000 (0.001) loss 1.5107 (1.6069) teacher_loss 0.8407 (1.0347) loss_zs_kd 0.0358 (0.0334) loss_oracle 0.3162 (0.3206) kd_loss 0.4940 (0.3952) acc 81.2500 (74.4844) gate/entropy 1.0981 (1.0972) gate/usage_max 0.3486 (0.3529) gate/usage_min 0.3233 (0.3119) gate/usage_std 0.0110 (0.0170) teacher/entropy 0.6190 (0.7263) teacher/usage_max 0.6640 (0.5889) teacher/usage_min 0.1559 (0.1564) teacher/usage_std 0.2340 (0.1871) nleep/row_max_mean 1202.8699 (1201.4462) nleep/row_max_std 17.5910 (14.5502) nleep/row_min_mean 1200.1360 (1199.0981) lr 1.9686e-03 eta 1:09:01
epoch [6/50] batch [220/246] time 0.465 (0.379) data 0.000 (0.001) loss 1.7471 (1.6072) teacher_loss 1.2189 (1.0355) loss_zs_kd 0.0385 (0.0336) loss_oracle 0.4065 (0.3193) kd_loss 0.3058 (0.3952) acc 68.7500 (74.2330) gate/entropy 1.0981 (1.0973) gate/usage_max 0.3480 (0.3525) gate/usage_min 0.3253 (0.3130) gate/usage_std 0.0104 (0.0164) teacher/entropy 0.7950 (0.7250) teacher/usage_max 0.4573 (0.5889) teacher/usage_min 0.2304 (0.1576) teacher/usage_std 0.0938 (0.1869) nleep/row_max_mean 1201.0212 (1201.3411) nleep/row_max_std 14.2774 (14.5603) nleep/row_min_mean 1198.9883 (1198.9863) lr 1.9686e-03 eta 1:08:37
epoch [6/50] batch [240/246] time 0.466 (0.387) data 0.000 (0.001) loss 1.8108 (1.6097) teacher_loss 1.1019 (1.0338) loss_zs_kd 0.0092 (0.0334) loss_oracle 0.3963 (0.3220) kd_loss 0.5061 (0.3983) acc 71.8750 (74.2057) gate/entropy 1.0982 (1.0974) gate/usage_max 0.3467 (0.3521) gate/usage_min 0.3256 (0.3141) gate/usage_std 0.0095 (0.0159) teacher/entropy 0.5983 (0.7208) teacher/usage_max 0.6848 (0.5918) teacher/usage_min 0.1033 (0.1573) teacher/usage_std 0.2525 (0.1887) nleep/row_max_mean 1198.9673 (1201.2498) nleep/row_max_std 14.4041 (14.5626) nleep/row_min_mean 1195.9490 (1198.8736) lr 1.9686e-03 eta 1:09:48
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,835
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,972
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.9%, epoch: 5 *******
******* Domain r best val test acc: 91.1%, epoch: 5 *******
******* Domain r best test acc:     91.2%, epoch: 6 *******
epoch [7/50] batch [20/246] time 0.078 (0.421) data 0.000 (0.015) loss 1.8259 (1.7588) teacher_loss 1.3396 (1.1394) loss_zs_kd 0.0312 (0.0359) loss_oracle 0.3401 (0.3689) kd_loss 0.3007 (0.4169) acc 65.6250 (70.3125) gate/entropy 1.0983 (1.0982) gate/usage_max 0.3455 (0.3460) gate/usage_min 0.3242 (0.3246) gate/usage_std 0.0090 (0.0092) teacher/entropy 0.8010 (0.6855) teacher/usage_max 0.5863 (0.6116) teacher/usage_min 0.1990 (0.1695) teacher/usage_std 0.1790 (0.1984) nleep/row_max_mean 1197.1476 (1200.3810) nleep/row_max_std 12.4913 (14.6134) nleep/row_min_mean 1195.1842 (1197.7738) lr 1.9511e-03 eta 1:15:53
epoch [7/50] batch [40/246] time 0.416 (0.372) data 0.000 (0.008) loss 1.2980 (1.6754) teacher_loss 0.6768 (1.0471) loss_zs_kd 0.0249 (0.0360) loss_oracle 0.3550 (0.3599) kd_loss 0.4312 (0.4303) acc 81.2500 (73.3594) gate/entropy 1.0983 (1.0983) gate/usage_max 0.3439 (0.3454) gate/usage_min 0.3233 (0.3241) gate/usage_std 0.0084 (0.0089) teacher/entropy 0.6679 (0.6716) teacher/usage_max 0.6262 (0.6300) teacher/usage_min 0.1809 (0.1640) teacher/usage_std 0.2072 (0.2109) nleep/row_max_mean 1199.5593 (1200.6387) nleep/row_max_std 15.6724 (14.2517) nleep/row_min_mean 1196.9629 (1197.9976) lr 1.9511e-03 eta 1:06:49
epoch [7/50] batch [60/246] time 0.428 (0.334) data 0.000 (0.005) loss 1.2190 (1.6603) teacher_loss 0.5483 (1.0313) loss_zs_kd 0.0132 (0.0355) loss_oracle 0.3832 (0.3564) kd_loss 0.4725 (0.4331) acc 84.3750 (73.5938) gate/entropy 1.0983 (1.0983) gate/usage_max 0.3423 (0.3446) gate/usage_min 0.3226 (0.3237) gate/usage_std 0.0081 (0.0087) teacher/entropy 0.6259 (0.6675) teacher/usage_max 0.6308 (0.6373) teacher/usage_min 0.1524 (0.1607) teacher/usage_std 0.2120 (0.2160) nleep/row_max_mean 1199.5902 (1200.7522) nleep/row_max_std 12.9088 (14.1541) nleep/row_min_mean 1196.8027 (1198.0812) lr 1.9511e-03 eta 0:59:50
epoch [7/50] batch [80/246] time 0.437 (0.341) data 0.000 (0.004) loss 1.6242 (1.6682) teacher_loss 0.8796 (1.0324) loss_zs_kd 0.0176 (0.0360) loss_oracle 0.4175 (0.3555) kd_loss 0.5270 (0.4401) acc 75.0000 (73.2031) gate/entropy 1.0983 (1.0983) gate/usage_max 0.3407 (0.3438) gate/usage_min 0.3214 (0.3233) gate/usage_std 0.0085 (0.0086) teacher/entropy 0.5662 (0.6587) teacher/usage_max 0.6528 (0.6425) teacher/usage_min 0.1581 (0.1578) teacher/usage_std 0.2262 (0.2197) nleep/row_max_mean 1199.0945 (1200.4914) nleep/row_max_std 16.8918 (14.1014) nleep/row_min_mean 1196.0295 (1197.7830) lr 1.9511e-03 eta 1:01:06
epoch [7/50] batch [100/246] time 0.519 (0.370) data 0.000 (0.003) loss 1.4536 (1.6697) teacher_loss 0.7888 (1.0290) loss_zs_kd 0.0458 (0.0361) loss_oracle 0.3224 (0.3558) kd_loss 0.4806 (0.4448) acc 81.2500 (73.3750) gate/entropy 1.0982 (1.0983) gate/usage_max 0.3406 (0.3431) gate/usage_min 0.3204 (0.3228) gate/usage_std 0.0091 (0.0087) teacher/entropy 0.6089 (0.6524) teacher/usage_max 0.6891 (0.6449) teacher/usage_min 0.1143 (0.1558) teacher/usage_std 0.2538 (0.2214) nleep/row_max_mean 1202.4623 (1200.5217) nleep/row_max_std 14.3198 (14.1041) nleep/row_min_mean 1199.7319 (1197.7713) lr 1.9511e-03 eta 1:06:04
epoch [7/50] batch [120/246] time 0.479 (0.389) data 0.000 (0.003) loss 1.3563 (1.6531) teacher_loss 0.5901 (1.0073) loss_zs_kd 0.0329 (0.0359) loss_oracle 0.3779 (0.3555) kd_loss 0.5608 (0.4501) acc 87.5000 (74.0104) gate/entropy 1.0981 (1.0983) gate/usage_max 0.3437 (0.3430) gate/usage_min 0.3196 (0.3223) gate/usage_std 0.0102 (0.0088) teacher/entropy 0.5231 (0.6450) teacher/usage_max 0.6937 (0.6520) teacher/usage_min 0.1204 (0.1534) teacher/usage_std 0.2562 (0.2263) nleep/row_max_mean 1204.1597 (1200.4678) nleep/row_max_std 14.9624 (14.1380) nleep/row_min_mean 1200.7942 (1197.6806) lr 1.9511e-03 eta 1:09:26
epoch [7/50] batch [140/246] time 0.079 (0.396) data 0.000 (0.002) loss 1.2176 (1.6545) teacher_loss 0.4095 (1.0046) loss_zs_kd 0.0172 (0.0357) loss_oracle 0.3808 (0.3540) kd_loss 0.6091 (0.4550) acc 90.6250 (74.1295) gate/entropy 1.0980 (1.0982) gate/usage_max 0.3469 (0.3433) gate/usage_min 0.3187 (0.3218) gate/usage_std 0.0116 (0.0091) teacher/entropy 0.4687 (0.6383) teacher/usage_max 0.7074 (0.6549) teacher/usage_min 0.1140 (0.1504) teacher/usage_std 0.2658 (0.2285) nleep/row_max_mean 1200.3567 (1200.4160) nleep/row_max_std 15.4535 (14.2173) nleep/row_min_mean 1196.5957 (1197.5941) lr 1.9511e-03 eta 1:10:33
epoch [7/50] batch [160/246] time 0.446 (0.382) data 0.000 (0.002) loss 2.0602 (1.6741) teacher_loss 1.3996 (1.0179) loss_zs_kd 0.0554 (0.0363) loss_oracle 0.4490 (0.3604) kd_loss 0.4084 (0.4579) acc 62.5000 (73.8867) gate/entropy 1.0979 (1.0982) gate/usage_max 0.3497 (0.3439) gate/usage_min 0.3180 (0.3214) gate/usage_std 0.0129 (0.0095) teacher/entropy 0.6741 (0.6334) teacher/usage_max 0.6126 (0.6572) teacher/usage_min 0.1104 (0.1488) teacher/usage_std 0.2089 (0.2302) nleep/row_max_mean 1196.4764 (1200.2036) nleep/row_max_std 15.5796 (14.2049) nleep/row_min_mean 1193.6299 (1197.3512) lr 1.9511e-03 eta 1:07:51
epoch [7/50] batch [180/246] time 0.482 (0.372) data 0.000 (0.002) loss 1.9460 (1.6854) teacher_loss 1.1970 (1.0196) loss_zs_kd 0.0583 (0.0361) loss_oracle 0.3761 (0.3666) kd_loss 0.5318 (0.4645) acc 65.6250 (73.7326) gate/entropy 1.0976 (1.0981) gate/usage_max 0.3532 (0.3447) gate/usage_min 0.3169 (0.3210) gate/usage_std 0.0150 (0.0100) teacher/entropy 0.5323 (0.6244) teacher/usage_max 0.7324 (0.6631) teacher/usage_min 0.1272 (0.1459) teacher/usage_std 0.2822 (0.2343) nleep/row_max_mean 1200.7990 (1200.1978) nleep/row_max_std 12.2800 (14.0916) nleep/row_min_mean 1197.6807 (1197.3015) lr 1.9511e-03 eta 1:05:58
epoch [7/50] batch [200/246] time 0.464 (0.372) data 0.000 (0.002) loss 1.4002 (1.6907) teacher_loss 0.7172 (1.0183) loss_zs_kd 0.0312 (0.0356) loss_oracle 0.3572 (0.3698) kd_loss 0.4888 (0.4697) acc 81.2500 (73.6562) gate/entropy 1.0973 (1.0981) gate/usage_max 0.3570 (0.3458) gate/usage_min 0.3158 (0.3205) gate/usage_std 0.0174 (0.0106) teacher/entropy 0.5759 (0.6167) teacher/usage_max 0.6760 (0.6682) teacher/usage_min 0.1350 (0.1437) teacher/usage_std 0.2433 (0.2379) nleep/row_max_mean 1199.3469 (1200.1830) nleep/row_max_std 16.2818 (14.0747) nleep/row_min_mean 1196.2773 (1197.2463) lr 1.9511e-03 eta 1:05:54
epoch [7/50] batch [220/246] time 0.463 (0.382) data 0.000 (0.002) loss 2.1624 (1.7000) teacher_loss 1.4522 (1.0183) loss_zs_kd 0.0453 (0.0355) loss_oracle 0.4209 (0.3744) kd_loss 0.4771 (0.4768) acc 65.6250 (73.5227) gate/entropy 1.0968 (1.0980) gate/usage_max 0.3613 (0.3470) gate/usage_min 0.3144 (0.3200) gate/usage_std 0.0202 (0.0114) teacher/entropy 0.5755 (0.6066) teacher/usage_max 0.7200 (0.6746) teacher/usage_min 0.1364 (0.1408) teacher/usage_std 0.2734 (0.2424) nleep/row_max_mean 1198.5000 (1200.2877) nleep/row_max_std 13.0623 (14.1139) nleep/row_min_mean 1195.3960 (1197.2928) lr 1.9511e-03 eta 1:07:25
epoch [7/50] batch [240/246] time 0.472 (0.390) data 0.000 (0.001) loss 1.5890 (1.7044) teacher_loss 0.8714 (1.0160) loss_zs_kd 0.0252 (0.0358) loss_oracle 0.4734 (0.3799) kd_loss 0.4683 (0.4806) acc 84.3750 (73.5026) gate/entropy 1.0964 (1.0979) gate/usage_max 0.3647 (0.3483) gate/usage_min 0.3132 (0.3195) gate/usage_std 0.0225 (0.0122) teacher/entropy 0.5931 (0.6001) teacher/usage_max 0.6262 (0.6786) teacher/usage_min 0.1513 (0.1382) teacher/usage_std 0.2091 (0.2452) nleep/row_max_mean 1196.3799 (1200.3373) nleep/row_max_std 14.1536 (14.1568) nleep/row_min_mean 1193.2598 (1197.2979) lr 1.9511e-03 eta 1:08:46
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,844
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,971
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.2%
******* Domain r best val acc:      84.9%, epoch: 5 *******
******* Domain r best val test acc: 91.1%, epoch: 5 *******
******* Domain r best test acc:     91.2%, epoch: 6 *******
epoch [8/50] batch [20/246] time 0.451 (0.304) data 0.000 (0.015) loss 1.7719 (1.7588) teacher_loss 1.0255 (1.0228) loss_zs_kd 0.0302 (0.0372) loss_oracle 0.3831 (0.4193) kd_loss 0.5397 (0.5078) acc 68.7500 (73.7500) gate/entropy 1.0959 (1.0960) gate/usage_max 0.3683 (0.3671) gate/usage_min 0.3123 (0.3125) gate/usage_std 0.0249 (0.0241) teacher/entropy 0.5006 (0.5394) teacher/usage_max 0.7354 (0.7021) teacher/usage_min 0.0997 (0.1172) teacher/usage_std 0.2856 (0.2627) nleep/row_max_mean 1197.4990 (1200.5066) nleep/row_max_std 14.7963 (15.6368) nleep/row_min_mean 1193.9668 (1197.0048) lr 1.9298e-03 eta 0:53:32
epoch [8/50] batch [40/246] time 0.461 (0.283) data 0.000 (0.008) loss 1.8174 (1.7583) teacher_loss 1.0797 (1.0254) loss_zs_kd 0.0423 (0.0376) loss_oracle 0.4100 (0.4225) kd_loss 0.5116 (0.5029) acc 68.7500 (73.4375) gate/entropy 1.0955 (1.0958) gate/usage_max 0.3709 (0.3684) gate/usage_min 0.3116 (0.3122) gate/usage_std 0.0267 (0.0250) teacher/entropy 0.5353 (0.5436) teacher/usage_max 0.6735 (0.6949) teacher/usage_min 0.0947 (0.1149) teacher/usage_std 0.2470 (0.2587) nleep/row_max_mean 1201.7827 (1200.6934) nleep/row_max_std 14.6943 (15.6133) nleep/row_min_mean 1197.9167 (1197.1699) lr 1.9298e-03 eta 0:49:39
epoch [8/50] batch [60/246] time 0.108 (0.240) data 0.001 (0.005) loss 2.0061 (1.7375) teacher_loss 1.1815 (0.9999) loss_zs_kd 0.0587 (0.0375) loss_oracle 0.3862 (0.4010) kd_loss 0.6022 (0.5183) acc 68.7500 (74.3750) gate/entropy 1.0948 (1.0956) gate/usage_max 0.3747 (0.3699) gate/usage_min 0.3105 (0.3119) gate/usage_std 0.0293 (0.0260) teacher/entropy 0.4185 (0.5227) teacher/usage_max 0.7879 (0.7136) teacher/usage_min 0.0710 (0.1051) teacher/usage_std 0.3227 (0.2717) nleep/row_max_mean 1204.7080 (1201.2340) nleep/row_max_std 14.5255 (15.2856) nleep/row_min_mean 1200.3790 (1197.5798) lr 1.9298e-03 eta 0:42:08
epoch [8/50] batch [80/246] time 0.110 (0.207) data 0.000 (0.004) loss 1.3298 (1.7417) teacher_loss 0.6840 (1.0042) loss_zs_kd 0.0227 (0.0368) loss_oracle 0.3677 (0.4033) kd_loss 0.4506 (0.5174) acc 81.2500 (74.6875) gate/entropy 1.0942 (1.0953) gate/usage_max 0.3780 (0.3716) gate/usage_min 0.3099 (0.3114) gate/usage_std 0.0316 (0.0271) teacher/entropy 0.5803 (0.5210) teacher/usage_max 0.7042 (0.7151) teacher/usage_min 0.0832 (0.0986) teacher/usage_std 0.2675 (0.2733) nleep/row_max_mean 1203.1208 (1201.1383) nleep/row_max_std 16.4827 (15.5270) nleep/row_min_mean 1199.7523 (1197.4437) lr 1.9298e-03 eta 0:36:14
epoch [8/50] batch [100/246] time 0.102 (0.187) data 0.000 (0.003) loss 1.8922 (1.7657) teacher_loss 1.0586 (1.0240) loss_zs_kd 0.0760 (0.0371) loss_oracle 0.3705 (0.4041) kd_loss 0.6103 (0.5211) acc 71.8750 (74.0000) gate/entropy 1.0934 (1.0950) gate/usage_max 0.3818 (0.3733) gate/usage_min 0.3090 (0.3110) gate/usage_std 0.0343 (0.0283) teacher/entropy 0.3929 (0.5139) teacher/usage_max 0.8099 (0.7193) teacher/usage_min 0.0528 (0.0956) teacher/usage_std 0.3387 (0.2763) nleep/row_max_mean 1201.7202 (1200.9969) nleep/row_max_std 14.0607 (15.4702) nleep/row_min_mean 1197.2983 (1197.2511) lr 1.9298e-03 eta 0:32:37
epoch [8/50] batch [120/246] time 0.526 (0.211) data 0.000 (0.003) loss 2.1995 (1.7670) teacher_loss 1.4058 (1.0171) loss_zs_kd 0.0544 (0.0365) loss_oracle 0.4703 (0.4101) kd_loss 0.5314 (0.5265) acc 65.6250 (74.1406) gate/entropy 1.0927 (1.0947) gate/usage_max 0.3853 (0.3750) gate/usage_min 0.3068 (0.3105) gate/usage_std 0.0368 (0.0295) teacher/entropy 0.4766 (0.5044) teacher/usage_max 0.7595 (0.7258) teacher/usage_min 0.0814 (0.0907) teacher/usage_std 0.3030 (0.2810) nleep/row_max_mean 1198.4949 (1201.1467) nleep/row_max_std 14.8244 (15.4317) nleep/row_min_mean 1194.6565 (1197.3178) lr 1.9298e-03 eta 0:36:42
epoch [8/50] batch [140/246] time 0.472 (0.249) data 0.000 (0.002) loss 1.7735 (1.7878) teacher_loss 0.9737 (1.0278) loss_zs_kd 0.0173 (0.0366) loss_oracle 0.5285 (0.4265) kd_loss 0.5268 (0.5284) acc 68.7500 (73.7723) gate/entropy 1.0921 (1.0944) gate/usage_max 0.3879 (0.3767) gate/usage_min 0.3043 (0.3098) gate/usage_std 0.0386 (0.0307) teacher/entropy 0.4822 (0.4997) teacher/usage_max 0.7350 (0.7274) teacher/usage_min 0.0593 (0.0877) teacher/usage_std 0.2903 (0.2824) nleep/row_max_mean 1198.1672 (1200.9714) nleep/row_max_std 17.2749 (15.4333) nleep/row_min_mean 1193.8159 (1197.0926) lr 1.9298e-03 eta 0:43:14
epoch [8/50] batch [160/246] time 0.472 (0.278) data 0.000 (0.002) loss 1.9914 (1.7931) teacher_loss 1.1834 (1.0286) loss_zs_kd 0.0589 (0.0368) loss_oracle 0.5678 (0.4276) kd_loss 0.4946 (0.5323) acc 68.7500 (73.9062) gate/entropy 1.0913 (1.0940) gate/usage_max 0.3911 (0.3783) gate/usage_min 0.3017 (0.3089) gate/usage_std 0.0409 (0.0318) teacher/entropy 0.5225 (0.4923) teacher/usage_max 0.6809 (0.7318) teacher/usage_min 0.0600 (0.0843) teacher/usage_std 0.2589 (0.2856) nleep/row_max_mean 1200.2527 (1201.0170) nleep/row_max_std 15.9927 (15.4434) nleep/row_min_mean 1195.9701 (1197.0774) lr 1.9298e-03 eta 0:48:14
epoch [8/50] batch [180/246] time 0.108 (0.277) data 0.000 (0.002) loss 2.0134 (1.7897) teacher_loss 1.2176 (1.0213) loss_zs_kd 0.0371 (0.0367) loss_oracle 0.4286 (0.4278) kd_loss 0.5630 (0.5361) acc 71.8750 (74.0104) gate/entropy 1.0904 (1.0937) gate/usage_max 0.3944 (0.3799) gate/usage_min 0.2988 (0.3080) gate/usage_std 0.0433 (0.0330) teacher/entropy 0.4241 (0.4856) teacher/usage_max 0.7776 (0.7331) teacher/usage_min 0.0354 (0.0817) teacher/usage_std 0.3202 (0.2868) nleep/row_max_mean 1195.5249 (1200.9810) nleep/row_max_std 14.7216 (15.4100) nleep/row_min_mean 1190.9497 (1196.9684) lr 1.9298e-03 eta 0:47:57
epoch [8/50] batch [200/246] time 0.079 (0.282) data 0.000 (0.002) loss 1.7573 (1.7950) teacher_loss 0.9782 (1.0246) loss_zs_kd 0.0332 (0.0366) loss_oracle 0.3497 (0.4242) kd_loss 0.5876 (0.5400) acc 75.0000 (73.6875) gate/entropy 1.0894 (1.0933) gate/usage_max 0.3980 (0.3815) gate/usage_min 0.2962 (0.3069) gate/usage_std 0.0459 (0.0342) teacher/entropy 0.3754 (0.4780) teacher/usage_max 0.8484 (0.7373) teacher/usage_min 0.0494 (0.0788) teacher/usage_std 0.3648 (0.2898) nleep/row_max_mean 1201.9121 (1200.9686) nleep/row_max_std 14.8022 (15.3798) nleep/row_min_mean 1196.9331 (1196.8708) lr 1.9298e-03 eta 0:48:51
epoch [8/50] batch [220/246] time 0.127 (0.288) data 0.000 (0.002) loss 1.7839 (1.8047) teacher_loss 0.9999 (1.0286) loss_zs_kd 0.0361 (0.0369) loss_oracle 0.5247 (0.4283) kd_loss 0.5036 (0.5435) acc 75.0000 (73.4233) gate/entropy 1.0882 (1.0929) gate/usage_max 0.4019 (0.3832) gate/usage_min 0.2932 (0.3058) gate/usage_std 0.0487 (0.0354) teacher/entropy 0.4928 (0.4707) teacher/usage_max 0.7000 (0.7415) teacher/usage_min 0.0491 (0.0754) teacher/usage_std 0.2720 (0.2929) nleep/row_max_mean 1201.4841 (1200.8628) nleep/row_max_std 17.4654 (15.3834) nleep/row_min_mean 1197.1345 (1196.6830) lr 1.9298e-03 eta 0:49:42
epoch [8/50] batch [240/246] time 0.462 (0.296) data 0.000 (0.001) loss 1.6107 (1.8068) teacher_loss 0.7893 (1.0276) loss_zs_kd 0.0436 (0.0369) loss_oracle 0.3516 (0.4276) kd_loss 0.6239 (0.5470) acc 78.1250 (73.3724) gate/entropy 1.0871 (1.0924) gate/usage_max 0.4054 (0.3849) gate/usage_min 0.2900 (0.3046) gate/usage_std 0.0513 (0.0366) teacher/entropy 0.3289 (0.4634) teacher/usage_max 0.8293 (0.7457) teacher/usage_min 0.0212 (0.0725) teacher/usage_std 0.3546 (0.2959) nleep/row_max_mean 1199.6334 (1200.9158) nleep/row_max_std 16.3788 (15.3840) nleep/row_min_mean 1194.5674 (1196.6482) lr 1.9298e-03 eta 0:50:58
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,841
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,981
* accuracy: 91.4%
* error: 8.6%
* macro_f1: 90.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain r best val acc:      84.9%, epoch: 5 *******
******* Domain r best val test acc: 91.1%, epoch: 5 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [9/50] batch [20/246] time 0.079 (0.463) data 0.000 (0.013) loss 1.5010 (1.8411) teacher_loss 0.6946 (0.9986) loss_zs_kd 0.0614 (0.0408) loss_oracle 0.4014 (0.4707) kd_loss 0.5751 (0.5868) acc 81.2500 (75.1562) gate/entropy 1.0857 (1.0862) gate/usage_max 0.4094 (0.4080) gate/usage_min 0.2865 (0.2878) gate/usage_std 0.0543 (0.0532) teacher/entropy 0.3609 (0.3747) teacher/usage_max 0.8623 (0.7861) teacher/usage_min 0.0318 (0.0387) teacher/usage_std 0.3753 (0.3259) nleep/row_max_mean 1201.8339 (1201.0541) nleep/row_max_std 11.8514 (15.3229) nleep/row_min_mean 1196.5481 (1195.7216) lr 1.9048e-03 eta 1:19:29
epoch [9/50] batch [40/246] time 0.469 (0.359) data 0.000 (0.006) loss 2.0426 (1.8529) teacher_loss 1.2690 (1.0187) loss_zs_kd 0.0342 (0.0425) loss_oracle 0.4566 (0.4660) kd_loss 0.5282 (0.5800) acc 71.8750 (73.9844) gate/entropy 1.0846 (1.0857) gate/usage_max 0.4127 (0.4096) gate/usage_min 0.2835 (0.2863) gate/usage_std 0.0567 (0.0544) teacher/entropy 0.4144 (0.3770) teacher/usage_max 0.8206 (0.7906) teacher/usage_min 0.0369 (0.0354) teacher/usage_std 0.3472 (0.3291) nleep/row_max_mean 1196.5562 (1201.0689) nleep/row_max_std 15.5034 (15.2587) nleep/row_min_mean 1191.3872 (1195.7242) lr 1.9048e-03 eta 1:01:35
epoch [9/50] batch [60/246] time 0.458 (0.350) data 0.000 (0.004) loss 2.1076 (1.8799) teacher_loss 1.2246 (1.0358) loss_zs_kd 0.0432 (0.0420) loss_oracle 0.4752 (0.4940) kd_loss 0.6237 (0.5761) acc 75.0000 (74.0625) gate/entropy 1.0832 (1.0851) gate/usage_max 0.4162 (0.4113) gate/usage_min 0.2804 (0.2848) gate/usage_std 0.0593 (0.0557) teacher/entropy 0.3143 (0.3800) teacher/usage_max 0.8129 (0.7846) teacher/usage_min 0.0281 (0.0367) teacher/usage_std 0.3433 (0.3251) nleep/row_max_mean 1204.2336 (1201.1559) nleep/row_max_std 17.8853 (15.1083) nleep/row_min_mean 1198.1704 (1195.8005) lr 1.9048e-03 eta 0:59:55
epoch [9/50] batch [80/246] time 0.506 (0.352) data 0.000 (0.003) loss 1.8965 (1.8699) teacher_loss 1.1355 (1.0419) loss_zs_kd 0.0553 (0.0399) loss_oracle 0.4044 (0.4743) kd_loss 0.5311 (0.5709) acc 59.3750 (73.5938) gate/entropy 1.0819 (1.0844) gate/usage_max 0.4197 (0.4129) gate/usage_min 0.2777 (0.2834) gate/usage_std 0.0619 (0.0569) teacher/entropy 0.4039 (0.3828) teacher/usage_max 0.8041 (0.7835) teacher/usage_min 0.0320 (0.0371) teacher/usage_std 0.3372 (0.3243) nleep/row_max_mean 1200.7075 (1201.0636) nleep/row_max_std 14.3922 (15.3532) nleep/row_min_mean 1195.3127 (1195.6828) lr 1.9048e-03 eta 1:00:10
epoch [9/50] batch [100/246] time 0.451 (0.375) data 0.000 (0.003) loss 1.4230 (1.8522) teacher_loss 0.5752 (1.0249) loss_zs_kd 0.0247 (0.0388) loss_oracle 0.5324 (0.4682) kd_loss 0.5692 (0.5739) acc 84.3750 (73.8438) gate/entropy 1.0805 (1.0838) gate/usage_max 0.4231 (0.4146) gate/usage_min 0.2749 (0.2819) gate/usage_std 0.0644 (0.0582) teacher/entropy 0.3926 (0.3753) teacher/usage_max 0.7112 (0.7882) teacher/usage_min 0.0427 (0.0362) teacher/usage_std 0.2798 (0.3273) nleep/row_max_mean 1197.4666 (1201.0049) nleep/row_max_std 14.0475 (15.3233) nleep/row_min_mean 1192.1238 (1195.5613) lr 1.9048e-03 eta 1:03:59
epoch [9/50] batch [120/246] time 0.479 (0.390) data 0.000 (0.002) loss 1.9152 (1.8756) teacher_loss 1.0887 (1.0500) loss_zs_kd 0.0333 (0.0395) loss_oracle 0.4453 (0.4665) kd_loss 0.5871 (0.5726) acc 71.8750 (73.1510) gate/entropy 1.0791 (1.0831) gate/usage_max 0.4266 (0.4164) gate/usage_min 0.2724 (0.2806) gate/usage_std 0.0669 (0.0594) teacher/entropy 0.3193 (0.3732) teacher/usage_max 0.8499 (0.7894) teacher/usage_min 0.0207 (0.0351) teacher/usage_std 0.3680 (0.3283) nleep/row_max_mean 1199.3781 (1201.0241) nleep/row_max_std 16.6977 (15.3060) nleep/row_min_mean 1193.1611 (1195.5401) lr 1.9048e-03 eta 1:06:25
epoch [9/50] batch [140/246] time 0.081 (0.382) data 0.000 (0.002) loss 2.0749 (1.8795) teacher_loss 1.2527 (1.0532) loss_zs_kd 0.0146 (0.0391) loss_oracle 0.4468 (0.4673) kd_loss 0.5915 (0.5731) acc 65.6250 (72.7902) gate/entropy 1.0776 (1.0824) gate/usage_max 0.4299 (0.4180) gate/usage_min 0.2699 (0.2792) gate/usage_std 0.0694 (0.0607) teacher/entropy 0.2996 (0.3690) teacher/usage_max 0.8815 (0.7918) teacher/usage_min 0.0400 (0.0347) teacher/usage_std 0.3879 (0.3299) nleep/row_max_mean 1200.7241 (1200.9490) nleep/row_max_std 13.2148 (15.3513) nleep/row_min_mean 1194.6643 (1195.4241) lr 1.9048e-03 eta 1:04:54
epoch [9/50] batch [160/246] time 0.078 (0.377) data 0.000 (0.002) loss 1.9544 (1.8820) teacher_loss 1.0955 (1.0550) loss_zs_kd 0.0311 (0.0386) loss_oracle 0.5638 (0.4689) kd_loss 0.5615 (0.5731) acc 65.6250 (72.6562) gate/entropy 1.0764 (1.0818) gate/usage_max 0.4327 (0.4197) gate/usage_min 0.2676 (0.2779) gate/usage_std 0.0714 (0.0619) teacher/entropy 0.3864 (0.3653) teacher/usage_max 0.7125 (0.7944) teacher/usage_min 0.0363 (0.0337) teacher/usage_std 0.2821 (0.3316) nleep/row_max_mean 1200.3765 (1200.9494) nleep/row_max_std 18.4152 (15.3459) nleep/row_min_mean 1194.6284 (1195.3804) lr 1.9048e-03 eta 1:03:55
epoch [9/50] batch [180/246] time 0.078 (0.373) data 0.000 (0.002) loss 1.7777 (1.8754) teacher_loss 0.9095 (1.0511) loss_zs_kd 0.0354 (0.0380) loss_oracle 0.4693 (0.4652) kd_loss 0.6159 (0.5726) acc 75.0000 (72.7778) gate/entropy 1.0748 (1.0811) gate/usage_max 0.4361 (0.4213) gate/usage_min 0.2651 (0.2766) gate/usage_std 0.0739 (0.0631) teacher/entropy 0.2907 (0.3628) teacher/usage_max 0.8038 (0.7949) teacher/usage_min 0.0203 (0.0327) teacher/usage_std 0.3387 (0.3320) nleep/row_max_mean 1202.1060 (1200.9960) nleep/row_max_std 15.6788 (15.3966) nleep/row_min_mean 1195.9990 (1195.3870) lr 1.9048e-03 eta 1:03:09
epoch [9/50] batch [200/246] time 0.494 (0.377) data 0.000 (0.001) loss 1.8589 (1.8731) teacher_loss 1.0274 (1.0518) loss_zs_kd 0.0416 (0.0375) loss_oracle 0.4268 (0.4619) kd_loss 0.5973 (0.5716) acc 75.0000 (72.7969) gate/entropy 1.0730 (1.0804) gate/usage_max 0.4399 (0.4230) gate/usage_min 0.2624 (0.2753) gate/usage_std 0.0767 (0.0643) teacher/entropy 0.3106 (0.3605) teacher/usage_max 0.7842 (0.7962) teacher/usage_min 0.0193 (0.0320) teacher/usage_std 0.3269 (0.3329) nleep/row_max_mean 1200.4280 (1200.9635) nleep/row_max_std 13.9202 (15.3989) nleep/row_min_mean 1194.7114 (1195.3085) lr 1.9048e-03 eta 1:03:39
epoch [9/50] batch [220/246] time 0.467 (0.387) data 0.000 (0.001) loss 1.8028 (1.8708) teacher_loss 0.9537 (1.0502) loss_zs_kd 0.0381 (0.0374) loss_oracle 0.4960 (0.4608) kd_loss 0.5821 (0.5715) acc 78.1250 (72.8693) gate/entropy 1.0718 (1.0796) gate/usage_max 0.4423 (0.4247) gate/usage_min 0.2604 (0.2740) gate/usage_std 0.0785 (0.0655) teacher/entropy 0.3026 (0.3570) teacher/usage_max 0.8328 (0.7986) teacher/usage_min 0.0199 (0.0311) teacher/usage_std 0.3570 (0.3345) nleep/row_max_mean 1198.0142 (1200.9878) nleep/row_max_std 15.8569 (15.4339) nleep/row_min_mean 1191.8621 (1195.2728) lr 1.9048e-03 eta 1:05:14
epoch [9/50] batch [240/246] time 0.496 (0.394) data 0.000 (0.001) loss 1.7691 (1.8700) teacher_loss 0.9524 (1.0490) loss_zs_kd 0.0435 (0.0375) loss_oracle 0.4693 (0.4582) kd_loss 0.5603 (0.5731) acc 78.1250 (72.8125) gate/entropy 1.0698 (1.0789) gate/usage_max 0.4464 (0.4263) gate/usage_min 0.2578 (0.2728) gate/usage_std 0.0815 (0.0668) teacher/entropy 0.3276 (0.3513) teacher/usage_max 0.8099 (0.8017) teacher/usage_min 0.0247 (0.0306) teacher/usage_std 0.3419 (0.3366) nleep/row_max_mean 1199.9226 (1201.0330) nleep/row_max_std 12.9454 (15.5054) nleep/row_min_mean 1193.8959 (1195.2484) lr 1.9048e-03 eta 1:06:14
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,834
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,973
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.1%
******* Domain r best val acc:      84.9%, epoch: 5 *******
******* Domain r best val test acc: 91.1%, epoch: 5 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [10/50] batch [20/246] time 0.496 (0.406) data 0.000 (0.013) loss 1.8262 (1.9369) teacher_loss 0.9109 (1.0827) loss_zs_kd 0.0340 (0.0330) loss_oracle 0.5681 (0.5074) kd_loss 0.6143 (0.5841) acc 71.8750 (73.2812) gate/entropy 1.0679 (1.0685) gate/usage_max 0.4501 (0.4490) gate/usage_min 0.2551 (0.2559) gate/usage_std 0.0841 (0.0833) teacher/entropy 0.2916 (0.2924) teacher/usage_max 0.7512 (0.8279) teacher/usage_min 0.0137 (0.0227) teacher/usage_std 0.3090 (0.3540) nleep/row_max_mean 1199.0571 (1201.0266) nleep/row_max_std 17.0343 (16.5190) nleep/row_min_mean 1191.8094 (1194.3793) lr 1.8763e-03 eta 1:08:11
epoch [10/50] batch [40/246] time 0.465 (0.438) data 0.000 (0.007) loss 2.1081 (1.8946) teacher_loss 1.3171 (1.0563) loss_zs_kd 0.0379 (0.0349) loss_oracle 0.3795 (0.4768) kd_loss 0.5823 (0.5825) acc 68.7500 (72.7344) gate/entropy 1.0662 (1.0677) gate/usage_max 0.4531 (0.4504) gate/usage_min 0.2526 (0.2548) gate/usage_std 0.0864 (0.0843) teacher/entropy 0.2752 (0.2896) teacher/usage_max 0.8534 (0.8321) teacher/usage_min 0.0178 (0.0212) teacher/usage_std 0.3705 (0.3568) nleep/row_max_mean 1201.3608 (1200.8524) nleep/row_max_std 18.5343 (16.3192) nleep/row_min_mean 1194.4167 (1194.1539) lr 1.8763e-03 eta 1:13:22
epoch [10/50] batch [60/246] time 0.486 (0.448) data 0.000 (0.004) loss 1.6265 (1.8460) teacher_loss 0.7843 (1.0189) loss_zs_kd 0.0291 (0.0345) loss_oracle 0.4862 (0.4650) kd_loss 0.5846 (0.5774) acc 78.1250 (73.2812) gate/entropy 1.0644 (1.0669) gate/usage_max 0.4566 (0.4519) gate/usage_min 0.2505 (0.2537) gate/usage_std 0.0889 (0.0855) teacher/entropy 0.2864 (0.2912) teacher/usage_max 0.8103 (0.8339) teacher/usage_min 0.0150 (0.0200) teacher/usage_std 0.3435 (0.3582) nleep/row_max_mean 1194.9456 (1200.1582) nleep/row_max_std 14.4495 (16.1558) nleep/row_min_mean 1188.5861 (1193.4085) lr 1.8763e-03 eta 1:14:51
epoch [10/50] batch [80/246] time 0.081 (0.428) data 0.000 (0.003) loss 1.9806 (1.8462) teacher_loss 1.1160 (1.0202) loss_zs_kd 0.0636 (0.0357) loss_oracle 0.4689 (0.4599) kd_loss 0.5983 (0.5782) acc 59.3750 (73.3203) gate/entropy 1.0624 (1.0660) gate/usage_max 0.4602 (0.4535) gate/usage_min 0.2483 (0.2526) gate/usage_std 0.0914 (0.0866) teacher/entropy 0.2496 (0.2844) teacher/usage_max 0.8465 (0.8408) teacher/usage_min 0.0099 (0.0188) teacher/usage_std 0.3670 (0.3628) nleep/row_max_mean 1201.7570 (1200.2161) nleep/row_max_std 15.9632 (15.8289) nleep/row_min_mean 1194.1989 (1193.3941) lr 1.8763e-03 eta 1:11:20
epoch [10/50] batch [100/246] time 0.088 (0.410) data 0.000 (0.003) loss 2.1532 (1.8509) teacher_loss 1.3218 (1.0276) loss_zs_kd 0.0364 (0.0356) loss_oracle 0.5278 (0.4551) kd_loss 0.5493 (0.5780) acc 71.8750 (73.2188) gate/entropy 1.0606 (1.0651) gate/usage_max 0.4635 (0.4552) gate/usage_min 0.2465 (0.2516) gate/usage_std 0.0937 (0.0878) teacher/entropy 0.3374 (0.2812) teacher/usage_max 0.7565 (0.8427) teacher/usage_min 0.0199 (0.0192) teacher/usage_std 0.3106 (0.3640) nleep/row_max_mean 1199.6899 (1200.2449) nleep/row_max_std 14.3142 (15.7015) nleep/row_min_mean 1193.3599 (1193.4001) lr 1.8763e-03 eta 1:08:17
epoch [10/50] batch [120/246] time 0.098 (0.400) data 0.000 (0.002) loss 2.4907 (1.8657) teacher_loss 1.7034 (1.0439) loss_zs_kd 0.0254 (0.0357) loss_oracle 0.4337 (0.4553) kd_loss 0.5578 (0.5763) acc 65.6250 (73.1771) gate/entropy 1.0589 (1.0642) gate/usage_max 0.4664 (0.4568) gate/usage_min 0.2447 (0.2506) gate/usage_std 0.0958 (0.0890) teacher/entropy 0.2818 (0.2805) teacher/usage_max 0.8457 (0.8424) teacher/usage_min 0.0158 (0.0197) teacher/usage_std 0.3658 (0.3637) nleep/row_max_mean 1201.4305 (1200.3432) nleep/row_max_std 16.2881 (15.7202) nleep/row_min_mean 1194.2207 (1193.4964) lr 1.8763e-03 eta 1:06:21
epoch [10/50] batch [140/246] time 0.442 (0.410) data 0.000 (0.002) loss 1.4053 (1.8632) teacher_loss 0.6410 (1.0461) loss_zs_kd 0.0205 (0.0356) loss_oracle 0.3855 (0.4517) kd_loss 0.5613 (0.5734) acc 81.2500 (72.8348) gate/entropy 1.0574 (1.0634) gate/usage_max 0.4690 (0.4584) gate/usage_min 0.2432 (0.2496) gate/usage_std 0.0976 (0.0901) teacher/entropy 0.2725 (0.2808) teacher/usage_max 0.8517 (0.8425) teacher/usage_min 0.0231 (0.0194) teacher/usage_std 0.3689 (0.3638) nleep/row_max_mean 1207.2716 (1200.4395) nleep/row_max_std 18.1008 (15.7698) nleep/row_min_mean 1200.1909 (1193.6046) lr 1.8763e-03 eta 1:08:01
epoch [10/50] batch [160/246] time 0.468 (0.419) data 0.000 (0.002) loss 2.0276 (1.8609) teacher_loss 1.1852 (1.0484) loss_zs_kd 0.0572 (0.0356) loss_oracle 0.4727 (0.4455) kd_loss 0.5774 (0.5720) acc 68.7500 (72.7539) gate/entropy 1.0554 (1.0625) gate/usage_max 0.4724 (0.4599) gate/usage_min 0.2414 (0.2487) gate/usage_std 0.1000 (0.0912) teacher/entropy 0.2699 (0.2797) teacher/usage_max 0.8145 (0.8427) teacher/usage_min 0.0245 (0.0193) teacher/usage_std 0.3447 (0.3639) nleep/row_max_mean 1198.1165 (1200.3670) nleep/row_max_std 12.0175 (15.7603) nleep/row_min_mean 1191.6361 (1193.5470) lr 1.8763e-03 eta 1:09:23
epoch [10/50] batch [180/246] time 0.537 (0.427) data 0.000 (0.002) loss 1.6444 (1.8631) teacher_loss 0.8567 (1.0524) loss_zs_kd 0.0208 (0.0359) loss_oracle 0.5122 (0.4474) kd_loss 0.5212 (0.5690) acc 75.0000 (72.7431) gate/entropy 1.0537 (1.0616) gate/usage_max 0.4752 (0.4614) gate/usage_min 0.2397 (0.2478) gate/usage_std 0.1020 (0.0923) teacher/entropy 0.3015 (0.2797) teacher/usage_max 0.8506 (0.8437) teacher/usage_min 0.0142 (0.0190) teacher/usage_std 0.3691 (0.3646) nleep/row_max_mean 1201.7959 (1200.3361) nleep/row_max_std 16.7382 (15.7609) nleep/row_min_mean 1195.3496 (1193.5247) lr 1.8763e-03 eta 1:10:25
epoch [10/50] batch [200/246] time 0.131 (0.401) data 0.000 (0.001) loss 1.7641 (1.8594) teacher_loss 0.9835 (1.0497) loss_zs_kd 0.0448 (0.0358) loss_oracle 0.4389 (0.4492) kd_loss 0.5387 (0.5672) acc 78.1250 (72.8594) gate/entropy 1.0521 (1.0608) gate/usage_max 0.4777 (0.4629) gate/usage_min 0.2380 (0.2469) gate/usage_std 0.1038 (0.0933) teacher/entropy 0.2567 (0.2786) teacher/usage_max 0.8977 (0.8451) teacher/usage_min 0.0195 (0.0191) teacher/usage_std 0.3999 (0.3654) nleep/row_max_mean 1200.6736 (1200.1839) nleep/row_max_std 15.8126 (15.7506) nleep/row_min_mean 1193.2759 (1193.3716) lr 1.8763e-03 eta 1:06:01
epoch [10/50] batch [220/246] time 0.448 (0.393) data 0.000 (0.001) loss 2.0419 (1.8528) teacher_loss 1.2679 (1.0447) loss_zs_kd 0.0511 (0.0359) loss_oracle 0.3634 (0.4482) kd_loss 0.5667 (0.5661) acc 62.5000 (72.8693) gate/entropy 1.0506 (1.0599) gate/usage_max 0.4802 (0.4644) gate/usage_min 0.2367 (0.2461) gate/usage_std 0.1056 (0.0943) teacher/entropy 0.2253 (0.2771) teacher/usage_max 0.8954 (0.8456) teacher/usage_min 0.0180 (0.0189) teacher/usage_std 0.3984 (0.3658) nleep/row_max_mean 1199.3494 (1200.1796) nleep/row_max_std 15.4734 (15.6605) nleep/row_min_mean 1192.3014 (1193.3696) lr 1.8763e-03 eta 1:04:39
epoch [10/50] batch [240/246] time 0.480 (0.390) data 0.000 (0.001) loss 1.3817 (1.8480) teacher_loss 0.6181 (1.0408) loss_zs_kd 0.0120 (0.0362) loss_oracle 0.3997 (0.4455) kd_loss 0.5578 (0.5664) acc 84.3750 (72.9427) gate/entropy 1.0488 (1.0591) gate/usage_max 0.4830 (0.4658) gate/usage_min 0.2353 (0.2452) gate/usage_std 0.1075 (0.0954) teacher/entropy 0.2243 (0.2732) teacher/usage_max 0.9025 (0.8480) teacher/usage_min 0.0106 (0.0185) teacher/usage_std 0.4037 (0.3674) nleep/row_max_mean 1200.9371 (1200.0981) nleep/row_max_std 16.0753 (15.6367) nleep/row_min_mean 1193.6643 (1193.2724) lr 1.8763e-03 eta 1:03:59
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,819
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,969
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.1%
******* Domain r best val acc:      84.9%, epoch: 5 *******
******* Domain r best val test acc: 91.1%, epoch: 5 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [11/50] batch [20/246] time 0.464 (0.481) data 0.000 (0.014) loss 1.4247 (1.8060) teacher_loss 0.6307 (1.0291) loss_zs_kd 0.0533 (0.0360) loss_oracle 0.4092 (0.4057) kd_loss 0.5626 (0.5561) acc 84.3750 (72.9688) gate/entropy 1.0467 (1.0473) gate/usage_max 0.4864 (0.4854) gate/usage_min 0.2339 (0.2342) gate/usage_std 0.1098 (0.1092) teacher/entropy 0.2085 (0.2363) teacher/usage_max 0.9108 (0.8783) teacher/usage_min 0.0063 (0.0152) teacher/usage_std 0.4095 (0.3874) nleep/row_max_mean 1201.6667 (1199.4729) nleep/row_max_std 15.0049 (15.1200) nleep/row_min_mean 1193.2716 (1192.4784) lr 1.8443e-03 eta 1:18:47
epoch [11/50] batch [40/246] time 0.086 (0.390) data 0.000 (0.007) loss 1.8110 (1.8000) teacher_loss 1.0079 (1.0179) loss_zs_kd 0.0547 (0.0352) loss_oracle 0.3678 (0.4125) kd_loss 0.5918 (0.5583) acc 78.1250 (73.3594) gate/entropy 1.0446 (1.0464) gate/usage_max 0.4898 (0.4869) gate/usage_min 0.2325 (0.2336) gate/usage_std 0.1122 (0.1102) teacher/entropy 0.1960 (0.2353) teacher/usage_max 0.8707 (0.8723) teacher/usage_min 0.0041 (0.0160) teacher/usage_std 0.3831 (0.3834) nleep/row_max_mean 1198.4344 (1198.7409) nleep/row_max_std 14.6862 (14.8467) nleep/row_min_mean 1191.0477 (1191.7444) lr 1.8443e-03 eta 1:03:45
epoch [11/50] batch [60/246] time 0.089 (0.373) data 0.000 (0.005) loss 1.8229 (1.7918) teacher_loss 1.0065 (1.0082) loss_zs_kd 0.0507 (0.0360) loss_oracle 0.4221 (0.4114) kd_loss 0.5801 (0.5599) acc 71.8750 (73.2292) gate/entropy 1.0426 (1.0454) gate/usage_max 0.4928 (0.4884) gate/usage_min 0.2315 (0.2330) gate/usage_std 0.1142 (0.1112) teacher/entropy 0.1940 (0.2286) teacher/usage_max 0.8892 (0.8771) teacher/usage_min 0.0103 (0.0158) teacher/usage_std 0.3948 (0.3866) nleep/row_max_mean 1200.6499 (1198.9506) nleep/row_max_std 16.0102 (14.7387) nleep/row_min_mean 1193.1393 (1191.8547) lr 1.8443e-03 eta 1:00:49
epoch [11/50] batch [80/246] time 0.483 (0.362) data 0.000 (0.004) loss 1.5352 (1.7813) teacher_loss 0.8043 (1.0038) loss_zs_kd 0.0351 (0.0363) loss_oracle 0.4130 (0.4042) kd_loss 0.5069 (0.5573) acc 84.3750 (73.2422) gate/entropy 1.0409 (1.0444) gate/usage_max 0.4955 (0.4900) gate/usage_min 0.2305 (0.2325) gate/usage_std 0.1161 (0.1123) teacher/entropy 0.2754 (0.2289) teacher/usage_max 0.8722 (0.8772) teacher/usage_min 0.0233 (0.0162) teacher/usage_std 0.3825 (0.3866) nleep/row_max_mean 1198.3606 (1198.9086) nleep/row_max_std 14.9961 (14.8602) nleep/row_min_mean 1191.4172 (1191.8635) lr 1.8443e-03 eta 0:58:48
epoch [11/50] batch [100/246] time 0.494 (0.366) data 0.000 (0.003) loss 1.7576 (1.7908) teacher_loss 1.0543 (1.0126) loss_zs_kd 0.0419 (0.0373) loss_oracle 0.3381 (0.4043) kd_loss 0.5133 (0.5574) acc 75.0000 (73.2812) gate/entropy 1.0389 (1.0435) gate/usage_max 0.4985 (0.4915) gate/usage_min 0.2294 (0.2319) gate/usage_std 0.1181 (0.1133) teacher/entropy 0.2664 (0.2270) teacher/usage_max 0.8693 (0.8766) teacher/usage_min 0.0244 (0.0166) teacher/usage_std 0.3805 (0.3862) nleep/row_max_mean 1193.7671 (1198.7719) nleep/row_max_std 17.0257 (14.8596) nleep/row_min_mean 1187.3247 (1191.7096) lr 1.8443e-03 eta 0:59:24
epoch [11/50] batch [120/246] time 0.483 (0.386) data 0.000 (0.003) loss 1.3973 (1.7755) teacher_loss 0.6730 (0.9953) loss_zs_kd 0.0296 (0.0372) loss_oracle 0.3988 (0.4060) kd_loss 0.5100 (0.5587) acc 81.2500 (73.8542) gate/entropy 1.0369 (1.0425) gate/usage_max 0.5016 (0.4929) gate/usage_min 0.2283 (0.2314) gate/usage_std 0.1202 (0.1143) teacher/entropy 0.2375 (0.2215) teacher/usage_max 0.9108 (0.8797) teacher/usage_min 0.0128 (0.0159) teacher/usage_std 0.4091 (0.3883) nleep/row_max_mean 1197.1531 (1198.7517) nleep/row_max_std 15.2206 (14.9492) nleep/row_min_mean 1189.9602 (1191.6412) lr 1.8443e-03 eta 1:02:30
epoch [11/50] batch [140/246] time 0.472 (0.402) data 0.000 (0.002) loss 1.6835 (1.7814) teacher_loss 0.8677 (0.9990) loss_zs_kd 0.0426 (0.0377) loss_oracle 0.4114 (0.4095) kd_loss 0.5888 (0.5589) acc 84.3750 (73.8839) gate/entropy 1.0354 (1.0416) gate/usage_max 0.5037 (0.4943) gate/usage_min 0.2277 (0.2309) gate/usage_std 0.1216 (0.1153) teacher/entropy 0.1490 (0.2185) teacher/usage_max 0.9197 (0.8807) teacher/usage_min 0.0099 (0.0158) teacher/usage_std 0.4154 (0.3890) nleep/row_max_mean 1203.1953 (1198.6515) nleep/row_max_std 13.0541 (14.8873) nleep/row_min_mean 1195.5278 (1191.5396) lr 1.8443e-03 eta 1:04:56
epoch [11/50] batch [160/246] time 0.086 (0.379) data 0.000 (0.002) loss 2.1165 (1.7830) teacher_loss 1.3715 (1.0027) loss_zs_kd 0.0464 (0.0377) loss_oracle 0.3917 (0.4081) kd_loss 0.5259 (0.5575) acc 62.5000 (73.7695) gate/entropy 1.0332 (1.0407) gate/usage_max 0.5070 (0.4957) gate/usage_min 0.2268 (0.2304) gate/usage_std 0.1238 (0.1162) teacher/entropy 0.2007 (0.2156) teacher/usage_max 0.9309 (0.8843) teacher/usage_min 0.0164 (0.0159) teacher/usage_std 0.4228 (0.3914) nleep/row_max_mean 1202.0244 (1198.8104) nleep/row_max_std 15.7659 (14.8635) nleep/row_min_mean 1194.5254 (1191.6800) lr 1.8443e-03 eta 1:01:08
epoch [11/50] batch [180/246] time 0.424 (0.372) data 0.000 (0.002) loss 1.6686 (1.7760) teacher_loss 0.8916 (0.9947) loss_zs_kd 0.0184 (0.0371) loss_oracle 0.4881 (0.4112) kd_loss 0.5237 (0.5572) acc 68.7500 (73.8194) gate/entropy 1.0314 (1.0398) gate/usage_max 0.5096 (0.4971) gate/usage_min 0.2261 (0.2300) gate/usage_std 0.1256 (0.1171) teacher/entropy 0.2147 (0.2119) teacher/usage_max 0.9056 (0.8874) teacher/usage_min 0.0162 (0.0161) teacher/usage_std 0.4054 (0.3934) nleep/row_max_mean 1198.7898 (1198.9270) nleep/row_max_std 14.5298 (15.0351) nleep/row_min_mean 1191.9321 (1191.7704) lr 1.8443e-03 eta 0:59:52
epoch [11/50] batch [200/246] time 0.454 (0.370) data 0.000 (0.002) loss 1.7395 (1.7779) teacher_loss 0.9613 (0.9988) loss_zs_kd 0.0228 (0.0367) loss_oracle 0.4373 (0.4102) kd_loss 0.5482 (0.5556) acc 71.8750 (73.7812) gate/entropy 1.0299 (1.0389) gate/usage_max 0.5117 (0.4985) gate/usage_min 0.2254 (0.2296) gate/usage_std 0.1270 (0.1181) teacher/entropy 0.1862 (0.2105) teacher/usage_max 0.9058 (0.8889) teacher/usage_min 0.0098 (0.0162) teacher/usage_std 0.4059 (0.3945) nleep/row_max_mean 1203.8036 (1199.1076) nleep/row_max_std 15.9042 (15.0996) nleep/row_min_mean 1196.5896 (1191.9583) lr 1.8443e-03 eta 0:59:30
epoch [11/50] batch [220/246] time 0.441 (0.380) data 0.000 (0.001) loss 1.7144 (1.7677) teacher_loss 0.9178 (0.9900) loss_zs_kd 0.0372 (0.0364) loss_oracle 0.3968 (0.4091) kd_loss 0.5796 (0.5550) acc 71.8750 (74.1051) gate/entropy 1.0285 (1.0380) gate/usage_max 0.5136 (0.4998) gate/usage_min 0.2249 (0.2292) gate/usage_std 0.1283 (0.1189) teacher/entropy 0.1407 (0.2086) teacher/usage_max 0.9217 (0.8898) teacher/usage_min 0.0067 (0.0161) teacher/usage_std 0.4169 (0.3951) nleep/row_max_mean 1200.7903 (1199.1966) nleep/row_max_std 18.3089 (15.1748) nleep/row_min_mean 1193.0977 (1192.0361) lr 1.8443e-03 eta 1:00:52
epoch [11/50] batch [240/246] time 0.441 (0.387) data 0.000 (0.001) loss 1.5182 (1.7737) teacher_loss 0.7585 (0.9973) loss_zs_kd 0.0389 (0.0367) loss_oracle 0.3909 (0.4081) kd_loss 0.5448 (0.5540) acc 81.2500 (73.8411) gate/entropy 1.0265 (1.0371) gate/usage_max 0.5165 (0.5010) gate/usage_min 0.2240 (0.2288) gate/usage_std 0.1303 (0.1198) teacher/entropy 0.1976 (0.2066) teacher/usage_max 0.8840 (0.8914) teacher/usage_min 0.0131 (0.0159) teacher/usage_std 0.3911 (0.3962) nleep/row_max_mean 1200.3262 (1199.2692) nleep/row_max_std 17.4052 (15.2202) nleep/row_min_mean 1193.5901 (1192.1032) lr 1.8443e-03 eta 1:01:59
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,821
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,975
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.2%
******* Domain r best val acc:      84.9%, epoch: 5 *******
******* Domain r best val test acc: 91.1%, epoch: 5 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [12/50] batch [20/246] time 0.408 (0.319) data 0.000 (0.015) loss 1.5823 (1.7190) teacher_loss 0.8025 (0.9552) loss_zs_kd 0.0295 (0.0341) loss_oracle 0.4512 (0.4218) kd_loss 0.5394 (0.5359) acc 68.7500 (75.1562) gate/entropy 1.0246 (1.0253) gate/usage_max 0.5190 (0.5180) gate/usage_min 0.2235 (0.2237) gate/usage_std 0.1320 (0.1314) teacher/entropy 0.2034 (0.1871) teacher/usage_max 0.8779 (0.9098) teacher/usage_min 0.0091 (0.0161) teacher/usage_std 0.3874 (0.4086) nleep/row_max_mean 1204.9575 (1199.3998) nleep/row_max_std 18.4822 (15.8147) nleep/row_min_mean 1197.3075 (1192.1712) lr 1.8090e-03 eta 0:50:57
epoch [12/50] batch [40/246] time 0.439 (0.339) data 0.000 (0.007) loss 2.1809 (1.7528) teacher_loss 1.4537 (0.9932) loss_zs_kd 0.0758 (0.0369) loss_oracle 0.4125 (0.4078) kd_loss 0.4830 (0.5372) acc 59.3750 (73.5938) gate/entropy 1.0227 (1.0245) gate/usage_max 0.5216 (0.5192) gate/usage_min 0.2227 (0.2234) gate/usage_std 0.1338 (0.1321) teacher/entropy 0.2468 (0.1836) teacher/usage_max 0.8928 (0.9101) teacher/usage_min 0.0181 (0.0145) teacher/usage_std 0.3967 (0.4089) nleep/row_max_mean 1194.6853 (1199.6354) nleep/row_max_std 11.1949 (15.6650) nleep/row_min_mean 1188.3783 (1192.3992) lr 1.8090e-03 eta 0:54:03
epoch [12/50] batch [60/246] time 0.526 (0.393) data 0.000 (0.005) loss 2.2312 (1.7725) teacher_loss 1.5025 (1.0048) loss_zs_kd 0.0390 (0.0363) loss_oracle 0.4062 (0.4185) kd_loss 0.5060 (0.5403) acc 56.2500 (73.0729) gate/entropy 1.0212 (1.0237) gate/usage_max 0.5235 (0.5203) gate/usage_min 0.2222 (0.2231) gate/usage_std 0.1351 (0.1329) teacher/entropy 0.1878 (0.1796) teacher/usage_max 0.9376 (0.9089) teacher/usage_min 0.0113 (0.0141) teacher/usage_std 0.4276 (0.4080) nleep/row_max_mean 1203.2804 (1199.5779) nleep/row_max_std 14.4060 (15.2566) nleep/row_min_mean 1196.6194 (1192.3306) lr 1.8090e-03 eta 1:02:27
epoch [12/50] batch [80/246] time 0.466 (0.412) data 0.000 (0.004) loss 1.6363 (1.7875) teacher_loss 0.8731 (1.0139) loss_zs_kd 0.0296 (0.0357) loss_oracle 0.4185 (0.4358) kd_loss 0.5390 (0.5378) acc 68.7500 (73.0859) gate/entropy 1.0199 (1.0229) gate/usage_max 0.5253 (0.5212) gate/usage_min 0.2215 (0.2228) gate/usage_std 0.1363 (0.1336) teacher/entropy 0.1630 (0.1816) teacher/usage_max 0.9230 (0.9077) teacher/usage_min 0.0148 (0.0148) teacher/usage_std 0.4174 (0.4072) nleep/row_max_mean 1199.7058 (1199.7326) nleep/row_max_std 12.8351 (15.1488) nleep/row_min_mean 1192.1648 (1192.4844) lr 1.8090e-03 eta 1:05:20
epoch [12/50] batch [100/246] time 0.083 (0.410) data 0.000 (0.003) loss 2.0710 (1.7633) teacher_loss 1.2568 (0.9905) loss_zs_kd 0.0386 (0.0358) loss_oracle 0.4790 (0.4383) kd_loss 0.5554 (0.5357) acc 62.5000 (73.8438) gate/entropy 1.0191 (1.0223) gate/usage_max 0.5263 (0.5221) gate/usage_min 0.2213 (0.2226) gate/usage_std 0.1370 (0.1341) teacher/entropy 0.1463 (0.1819) teacher/usage_max 0.9220 (0.9085) teacher/usage_min 0.0195 (0.0154) teacher/usage_std 0.4166 (0.4076) nleep/row_max_mean 1202.3262 (1199.7679) nleep/row_max_std 16.0081 (15.0975) nleep/row_min_mean 1194.6896 (1192.5213) lr 1.8090e-03 eta 1:04:55
epoch [12/50] batch [120/246] time 0.483 (0.387) data 0.000 (0.003) loss 1.3421 (1.7563) teacher_loss 0.5529 (0.9786) loss_zs_kd 0.0301 (0.0353) loss_oracle 0.3665 (0.4517) kd_loss 0.5908 (0.5343) acc 84.3750 (73.9844) gate/entropy 1.0183 (1.0217) gate/usage_max 0.5273 (0.5229) gate/usage_min 0.2209 (0.2223) gate/usage_std 0.1378 (0.1347) teacher/entropy 0.1165 (0.1817) teacher/usage_max 0.9092 (0.9090) teacher/usage_min 0.0036 (0.0149) teacher/usage_std 0.4087 (0.4080) nleep/row_max_mean 1204.3225 (1199.8123) nleep/row_max_std 17.6883 (15.0018) nleep/row_min_mean 1196.8755 (1192.5618) lr 1.8090e-03 eta 1:01:03
epoch [12/50] batch [140/246] time 0.490 (0.379) data 0.000 (0.002) loss 1.9971 (1.7629) teacher_loss 1.2421 (0.9895) loss_zs_kd 0.0293 (0.0348) loss_oracle 0.4365 (0.4489) kd_loss 0.5220 (0.5316) acc 71.8750 (73.7500) gate/entropy 1.0170 (1.0211) gate/usage_max 0.5289 (0.5237) gate/usage_min 0.2202 (0.2221) gate/usage_std 0.1389 (0.1352) teacher/entropy 0.2012 (0.1844) teacher/usage_max 0.8906 (0.9076) teacher/usage_min 0.0353 (0.0158) teacher/usage_std 0.3944 (0.4070) nleep/row_max_mean 1199.6053 (1199.7621) nleep/row_max_std 16.1699 (15.0475) nleep/row_min_mean 1192.1129 (1192.5588) lr 1.8090e-03 eta 0:59:47
epoch [12/50] batch [160/246] time 0.473 (0.377) data 0.000 (0.002) loss 2.0248 (1.7630) teacher_loss 1.2953 (0.9943) loss_zs_kd 0.0258 (0.0347) loss_oracle 0.3889 (0.4425) kd_loss 0.5221 (0.5301) acc 68.7500 (73.5156) gate/entropy 1.0161 (1.0205) gate/usage_max 0.5301 (0.5244) gate/usage_min 0.2201 (0.2218) gate/usage_std 0.1397 (0.1357) teacher/entropy 0.1798 (0.1855) teacher/usage_max 0.9142 (0.9066) teacher/usage_min 0.0169 (0.0161) teacher/usage_std 0.4113 (0.4063) nleep/row_max_mean 1198.3508 (1199.7095) nleep/row_max_std 13.5494 (15.0456) nleep/row_min_mean 1190.8557 (1192.5052) lr 1.8090e-03 eta 0:59:17
epoch [12/50] batch [180/246] time 0.499 (0.388) data 0.000 (0.002) loss 1.4673 (1.7640) teacher_loss 0.7185 (0.9977) loss_zs_kd 0.0268 (0.0355) loss_oracle 0.4689 (0.4387) kd_loss 0.5009 (0.5291) acc 81.2500 (73.3333) gate/entropy 1.0148 (1.0199) gate/usage_max 0.5318 (0.5252) gate/usage_min 0.2198 (0.2216) gate/usage_std 0.1408 (0.1363) teacher/entropy 0.2213 (0.1865) teacher/usage_max 0.8839 (0.9051) teacher/usage_min 0.0176 (0.0161) teacher/usage_std 0.3907 (0.4053) nleep/row_max_mean 1202.5242 (1199.7117) nleep/row_max_std 16.2944 (15.0094) nleep/row_min_mean 1195.2959 (1192.5245) lr 1.8090e-03 eta 1:00:50
epoch [12/50] batch [200/246] time 0.410 (0.396) data 0.000 (0.002) loss 1.7599 (1.7579) teacher_loss 0.9455 (0.9917) loss_zs_kd 0.0546 (0.0360) loss_oracle 0.5470 (0.4395) kd_loss 0.5136 (0.5284) acc 81.2500 (73.5312) gate/entropy 1.0133 (1.0193) gate/usage_max 0.5336 (0.5259) gate/usage_min 0.2193 (0.2214) gate/usage_std 0.1421 (0.1368) teacher/entropy 0.1703 (0.1858) teacher/usage_max 0.9282 (0.9055) teacher/usage_min 0.0047 (0.0161) teacher/usage_std 0.4214 (0.4056) nleep/row_max_mean 1198.9979 (1199.7768) nleep/row_max_std 12.0079 (15.0603) nleep/row_min_mean 1191.3790 (1192.6065) lr 1.8090e-03 eta 1:01:55
epoch [12/50] batch [220/246] time 0.083 (0.388) data 0.000 (0.001) loss 1.5986 (1.7643) teacher_loss 0.8039 (0.9970) loss_zs_kd 0.0197 (0.0357) loss_oracle 0.4622 (0.4433) kd_loss 0.5538 (0.5278) acc 78.1250 (73.3097) gate/entropy 1.0126 (1.0187) gate/usage_max 0.5345 (0.5267) gate/usage_min 0.2191 (0.2212) gate/usage_std 0.1427 (0.1373) teacher/entropy 0.1451 (0.1841) teacher/usage_max 0.9076 (0.9071) teacher/usage_min 0.0080 (0.0159) teacher/usage_std 0.4072 (0.4066) nleep/row_max_mean 1202.0974 (1199.8994) nleep/row_max_std 18.2872 (15.0733) nleep/row_min_mean 1195.0784 (1192.7204) lr 1.8090e-03 eta 1:00:34
epoch [12/50] batch [240/246] time 0.077 (0.384) data 0.000 (0.001) loss 1.5922 (1.7689) teacher_loss 0.8623 (1.0011) loss_zs_kd 0.0453 (0.0360) loss_oracle 0.4198 (0.4450) kd_loss 0.4974 (0.5273) acc 78.1250 (73.1771) gate/entropy 1.0118 (1.0182) gate/usage_max 0.5355 (0.5274) gate/usage_min 0.2188 (0.2210) gate/usage_std 0.1433 (0.1378) teacher/entropy 0.2042 (0.1855) teacher/usage_max 0.9023 (0.9046) teacher/usage_min 0.0126 (0.0161) teacher/usage_std 0.4034 (0.4050) nleep/row_max_mean 1197.6417 (1199.7663) nleep/row_max_std 15.7288 (15.0960) nleep/row_min_mean 1190.3914 (1192.6024) lr 1.8090e-03 eta 0:59:47
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,841
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,963
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.0%
******* Domain r best val acc:      84.9%, epoch: 5 *******
******* Domain r best val test acc: 91.1%, epoch: 5 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [13/50] batch [20/246] time 0.495 (0.512) data 0.000 (0.013) loss 1.7079 (1.7348) teacher_loss 0.9137 (0.9818) loss_zs_kd 0.0390 (0.0358) loss_oracle 0.4938 (0.4443) kd_loss 0.5278 (0.5129) acc 71.8750 (72.8125) gate/entropy 1.0103 (1.0107) gate/usage_max 0.5374 (0.5368) gate/usage_min 0.2184 (0.2185) gate/usage_std 0.1447 (0.1443) teacher/entropy 0.1382 (0.1885) teacher/usage_max 0.9443 (0.9017) teacher/usage_min 0.0098 (0.0168) teacher/usage_std 0.4323 (0.4031) nleep/row_max_mean 1201.2189 (1199.5801) nleep/row_max_std 12.2330 (15.1444) nleep/row_min_mean 1193.5524 (1192.5930) lr 1.7705e-03 eta 1:19:36
epoch [13/50] batch [40/246] time 0.452 (0.492) data 0.000 (0.006) loss 1.7122 (1.7456) teacher_loss 0.9846 (0.9788) loss_zs_kd 0.0418 (0.0352) loss_oracle 0.3749 (0.4787) kd_loss 0.5192 (0.5098) acc 81.2500 (73.7500) gate/entropy 1.0096 (1.0103) gate/usage_max 0.5383 (0.5374) gate/usage_min 0.2180 (0.2183) gate/usage_std 0.1453 (0.1447) teacher/entropy 0.1560 (0.1977) teacher/usage_max 0.9311 (0.8930) teacher/usage_min 0.0093 (0.0175) teacher/usage_std 0.4232 (0.3973) nleep/row_max_mean 1198.5383 (1199.8470) nleep/row_max_std 14.0735 (15.0198) nleep/row_min_mean 1191.5364 (1192.9036) lr 1.7705e-03 eta 1:16:22
epoch [13/50] batch [60/246] time 0.102 (0.441) data 0.000 (0.004) loss 1.9923 (1.7356) teacher_loss 1.1977 (0.9777) loss_zs_kd 0.0360 (0.0353) loss_oracle 0.5429 (0.4594) kd_loss 0.5051 (0.5106) acc 62.5000 (74.1146) gate/entropy 1.0087 (1.0099) gate/usage_max 0.5393 (0.5378) gate/usage_min 0.2178 (0.2182) gate/usage_std 0.1460 (0.1450) teacher/entropy 0.2736 (0.2002) teacher/usage_max 0.8057 (0.8883) teacher/usage_min 0.0555 (0.0175) teacher/usage_std 0.3358 (0.3940) nleep/row_max_mean 1200.5359 (1199.9689) nleep/row_max_std 17.4116 (14.8854) nleep/row_min_mean 1193.9009 (1193.0443) lr 1.7705e-03 eta 1:08:20
epoch [13/50] batch [80/246] time 0.460 (0.416) data 0.000 (0.003) loss 1.7205 (1.7258) teacher_loss 0.9224 (0.9742) loss_zs_kd 0.0428 (0.0353) loss_oracle 0.4445 (0.4477) kd_loss 0.5545 (0.5101) acc 78.1250 (74.1797) gate/entropy 1.0082 (1.0096) gate/usage_max 0.5400 (0.5382) gate/usage_min 0.2176 (0.2181) gate/usage_std 0.1465 (0.1453) teacher/entropy 0.1742 (0.2002) teacher/usage_max 0.8610 (0.8883) teacher/usage_min 0.0116 (0.0189) teacher/usage_std 0.3761 (0.3939) nleep/row_max_mean 1202.2922 (1200.3354) nleep/row_max_std 17.1399 (14.8909) nleep/row_min_mean 1195.0430 (1193.4182) lr 1.7705e-03 eta 1:04:17
epoch [13/50] batch [100/246] time 0.463 (0.395) data 0.000 (0.003) loss 1.3468 (1.7211) teacher_loss 0.6066 (0.9733) loss_zs_kd 0.0360 (0.0360) loss_oracle 0.4510 (0.4425) kd_loss 0.4967 (0.5085) acc 90.6250 (74.4062) gate/entropy 1.0077 (1.0092) gate/usage_max 0.5405 (0.5387) gate/usage_min 0.2176 (0.2180) gate/usage_std 0.1468 (0.1456) teacher/entropy 0.2097 (0.2007) teacher/usage_max 0.8887 (0.8887) teacher/usage_min 0.0135 (0.0183) teacher/usage_std 0.3942 (0.3943) nleep/row_max_mean 1200.8384 (1200.4334) nleep/row_max_std 17.3508 (14.8402) nleep/row_min_mean 1193.4701 (1193.5282) lr 1.7705e-03 eta 1:00:49
epoch [13/50] batch [120/246] time 0.481 (0.385) data 0.000 (0.002) loss 1.3202 (1.7066) teacher_loss 0.5954 (0.9605) loss_zs_kd 0.0200 (0.0358) loss_oracle 0.4082 (0.4401) kd_loss 0.5107 (0.5082) acc 84.3750 (74.6615) gate/entropy 1.0064 (1.0088) gate/usage_max 0.5421 (0.5392) gate/usage_min 0.2172 (0.2179) gate/usage_std 0.1479 (0.1459) teacher/entropy 0.2019 (0.2006) teacher/usage_max 0.8785 (0.8885) teacher/usage_min 0.0161 (0.0184) teacher/usage_std 0.3872 (0.3941) nleep/row_max_mean 1197.1171 (1200.5053) nleep/row_max_std 17.2349 (15.0305) nleep/row_min_mean 1190.7273 (1193.6234) lr 1.7705e-03 eta 0:59:14
epoch [13/50] batch [140/246] time 0.455 (0.400) data 0.000 (0.002) loss 1.7959 (1.7152) teacher_loss 1.0517 (0.9699) loss_zs_kd 0.0395 (0.0358) loss_oracle 0.4546 (0.4408) kd_loss 0.4971 (0.5071) acc 75.0000 (74.1518) gate/entropy 1.0056 (1.0084) gate/usage_max 0.5430 (0.5396) gate/usage_min 0.2170 (0.2178) gate/usage_std 0.1485 (0.1462) teacher/entropy 0.1782 (0.2006) teacher/usage_max 0.9238 (0.8891) teacher/usage_min 0.0268 (0.0189) teacher/usage_std 0.4176 (0.3944) nleep/row_max_mean 1204.6849 (1200.5659) nleep/row_max_std 16.3673 (14.9090) nleep/row_min_mean 1197.5465 (1193.7007) lr 1.7705e-03 eta 1:01:21
epoch [13/50] batch [160/246] time 0.521 (0.412) data 0.000 (0.002) loss 2.1604 (1.7297) teacher_loss 1.3324 (0.9828) loss_zs_kd 0.0645 (0.0363) loss_oracle 0.5001 (0.4445) kd_loss 0.5457 (0.5065) acc 62.5000 (73.7305) gate/entropy 1.0053 (1.0081) gate/usage_max 0.5434 (0.5401) gate/usage_min 0.2169 (0.2177) gate/usage_std 0.1488 (0.1465) teacher/entropy 0.2158 (0.2023) teacher/usage_max 0.8184 (0.8872) teacher/usage_min 0.0266 (0.0196) teacher/usage_std 0.3470 (0.3932) nleep/row_max_mean 1201.3044 (1200.4144) nleep/row_max_std 17.8001 (14.8382) nleep/row_min_mean 1195.0278 (1193.5822) lr 1.7705e-03 eta 1:03:05
epoch [13/50] batch [180/246] time 0.545 (0.398) data 0.000 (0.002) loss 2.4019 (1.7295) teacher_loss 1.7320 (0.9859) loss_zs_kd 0.0369 (0.0361) loss_oracle 0.3866 (0.4409) kd_loss 0.4581 (0.5051) acc 53.1250 (73.6285) gate/entropy 1.0047 (1.0077) gate/usage_max 0.5441 (0.5405) gate/usage_min 0.2167 (0.2175) gate/usage_std 0.1493 (0.1468) teacher/entropy 0.2353 (0.2018) teacher/usage_max 0.9004 (0.8888) teacher/usage_min 0.0270 (0.0196) teacher/usage_std 0.4014 (0.3942) nleep/row_max_mean 1198.0686 (1200.3748) nleep/row_max_std 15.8781 (14.8251) nleep/row_min_mean 1192.1199 (1193.5531) lr 1.7705e-03 eta 1:00:51
epoch [13/50] batch [200/246] time 0.082 (0.389) data 0.000 (0.001) loss 1.9428 (1.7364) teacher_loss 1.1616 (0.9897) loss_zs_kd 0.0645 (0.0366) loss_oracle 0.4763 (0.4488) kd_loss 0.5108 (0.5041) acc 75.0000 (73.7656) gate/entropy 1.0041 (1.0074) gate/usage_max 0.5448 (0.5409) gate/usage_min 0.2165 (0.2175) gate/usage_std 0.1498 (0.1471) teacher/entropy 0.1792 (0.2032) teacher/usage_max 0.9021 (0.8878) teacher/usage_min 0.0148 (0.0204) teacher/usage_std 0.4031 (0.3935) nleep/row_max_mean 1199.0969 (1200.3062) nleep/row_max_std 13.1712 (14.8008) nleep/row_min_mean 1192.3582 (1193.5133) lr 1.7705e-03 eta 0:59:16
epoch [13/50] batch [220/246] time 0.118 (0.385) data 0.000 (0.001) loss 1.5575 (1.7266) teacher_loss 0.8199 (0.9782) loss_zs_kd 0.0299 (0.0365) loss_oracle 0.4574 (0.4535) kd_loss 0.4939 (0.5035) acc 78.1250 (74.0483) gate/entropy 1.0039 (1.0071) gate/usage_max 0.5450 (0.5413) gate/usage_min 0.2164 (0.2174) gate/usage_std 0.1499 (0.1474) teacher/entropy 0.1764 (0.2035) teacher/usage_max 0.9258 (0.8876) teacher/usage_min 0.0194 (0.0204) teacher/usage_std 0.4192 (0.3934) nleep/row_max_mean 1202.1683 (1200.3350) nleep/row_max_std 9.5475 (14.7328) nleep/row_min_mean 1195.3936 (1193.5638) lr 1.7705e-03 eta 0:58:31
epoch [13/50] batch [240/246] time 0.524 (0.394) data 0.000 (0.001) loss 1.5594 (1.7187) teacher_loss 0.7908 (0.9714) loss_zs_kd 0.0418 (0.0364) loss_oracle 0.4874 (0.4542) kd_loss 0.5041 (0.5020) acc 81.2500 (74.2188) gate/entropy 1.0030 (1.0068) gate/usage_max 0.5461 (0.5416) gate/usage_min 0.2160 (0.2173) gate/usage_std 0.1507 (0.1476) teacher/entropy 0.2494 (0.2050) teacher/usage_max 0.8242 (0.8870) teacher/usage_min 0.0205 (0.0207) teacher/usage_std 0.3514 (0.3929) nleep/row_max_mean 1197.8765 (1200.2784) nleep/row_max_std 13.4222 (14.6275) nleep/row_min_mean 1191.7408 (1193.5251) lr 1.7705e-03 eta 0:59:44
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,840
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,980
* accuracy: 91.3%
* error: 8.7%
* macro_f1: 90.4%
******* Domain r best val acc:      84.9%, epoch: 5 *******
******* Domain r best val test acc: 91.1%, epoch: 5 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [14/50] batch [20/246] time 0.083 (0.358) data 0.000 (0.013) loss 1.2648 (1.7383) teacher_loss 0.5159 (0.9839) loss_zs_kd 0.0216 (0.0377) loss_oracle 0.5579 (0.4858) kd_loss 0.4591 (0.4926) acc 84.3750 (73.7500) gate/entropy 1.0025 (1.0026) gate/usage_max 0.5467 (0.5465) gate/usage_min 0.2159 (0.2159) gate/usage_std 0.1511 (0.1510) teacher/entropy 0.2234 (0.2247) teacher/usage_max 0.9062 (0.8665) teacher/usage_min 0.0052 (0.0179) teacher/usage_std 0.4065 (0.3794) nleep/row_max_mean 1198.1810 (1199.7219) nleep/row_max_std 13.3492 (13.6964) nleep/row_min_mean 1191.3199 (1193.1390) lr 1.7290e-03 eta 0:54:12
epoch [14/50] batch [40/246] time 0.483 (0.325) data 0.000 (0.007) loss 2.1788 (1.7019) teacher_loss 1.4277 (0.9500) loss_zs_kd 0.0239 (0.0359) loss_oracle 0.5022 (0.4945) kd_loss 0.4880 (0.4868) acc 65.6250 (75.3906) gate/entropy 1.0019 (1.0024) gate/usage_max 0.5473 (0.5468) gate/usage_min 0.2156 (0.2158) gate/usage_std 0.1516 (0.1512) teacher/entropy 0.2390 (0.2246) teacher/usage_max 0.8559 (0.8736) teacher/usage_min 0.0349 (0.0214) teacher/usage_std 0.3708 (0.3839) nleep/row_max_mean 1199.9941 (1200.0117) nleep/row_max_std 14.0233 (13.7339) nleep/row_min_mean 1193.5769 (1193.5192) lr 1.7290e-03 eta 0:49:02
epoch [14/50] batch [60/246] time 0.481 (0.321) data 0.000 (0.004) loss 2.3928 (1.7386) teacher_loss 1.5716 (0.9889) loss_zs_kd 0.0585 (0.0354) loss_oracle 0.5341 (0.4968) kd_loss 0.5249 (0.4837) acc 62.5000 (74.5312) gate/entropy 1.0015 (1.0022) gate/usage_max 0.5478 (0.5470) gate/usage_min 0.2155 (0.2158) gate/usage_std 0.1519 (0.1514) teacher/entropy 0.2327 (0.2266) teacher/usage_max 0.8164 (0.8746) teacher/usage_min 0.0123 (0.0209) teacher/usage_std 0.3477 (0.3845) nleep/row_max_mean 1197.6223 (1200.0441) nleep/row_max_std 13.8810 (13.8016) nleep/row_min_mean 1190.8679 (1193.5811) lr 1.7290e-03 eta 0:48:20
epoch [14/50] batch [80/246] time 0.474 (0.330) data 0.000 (0.003) loss 1.4614 (1.7162) teacher_loss 0.7399 (0.9746) loss_zs_kd 0.0426 (0.0350) loss_oracle 0.4385 (0.4869) kd_loss 0.4809 (0.4806) acc 81.2500 (74.7266) gate/entropy 1.0011 (1.0020) gate/usage_max 0.5482 (0.5472) gate/usage_min 0.2153 (0.2157) gate/usage_std 0.1522 (0.1515) teacher/entropy 0.2837 (0.2364) teacher/usage_max 0.8077 (0.8663) teacher/usage_min 0.0211 (0.0225) teacher/usage_std 0.3410 (0.3789) nleep/row_max_mean 1197.8643 (1200.0483) nleep/row_max_std 9.9830 (13.8733) nleep/row_min_mean 1191.8972 (1193.6633) lr 1.7290e-03 eta 0:49:38
epoch [14/50] batch [100/246] time 0.378 (0.359) data 0.000 (0.003) loss 1.6155 (1.7137) teacher_loss 0.9771 (0.9827) loss_zs_kd 0.0410 (0.0356) loss_oracle 0.4073 (0.4697) kd_loss 0.4143 (0.4783) acc 65.6250 (74.5000) gate/entropy 1.0008 (1.0018) gate/usage_max 0.5486 (0.5474) gate/usage_min 0.2152 (0.2156) gate/usage_std 0.1524 (0.1516) teacher/entropy 0.3385 (0.2409) teacher/usage_max 0.8234 (0.8634) teacher/usage_min 0.0405 (0.0223) teacher/usage_std 0.3487 (0.3770) nleep/row_max_mean 1198.7756 (1199.4657) nleep/row_max_std 13.3823 (13.7387) nleep/row_min_mean 1193.0967 (1193.1475) lr 1.7290e-03 eta 0:53:47
epoch [14/50] batch [120/246] time 0.495 (0.380) data 0.000 (0.002) loss 1.5876 (1.7110) teacher_loss 0.8692 (0.9854) loss_zs_kd 0.0471 (0.0355) loss_oracle 0.4571 (0.4590) kd_loss 0.4662 (0.4783) acc 78.1250 (74.4792) gate/entropy 1.0005 (1.0017) gate/usage_max 0.5490 (0.5476) gate/usage_min 0.2151 (0.2155) gate/usage_std 0.1527 (0.1518) teacher/entropy 0.2534 (0.2398) teacher/usage_max 0.8599 (0.8643) teacher/usage_min 0.0191 (0.0216) teacher/usage_std 0.3747 (0.3777) nleep/row_max_mean 1196.7942 (1199.5038) nleep/row_max_std 13.8450 (13.8134) nleep/row_min_mean 1190.6273 (1193.1919) lr 1.7290e-03 eta 0:56:53
epoch [14/50] batch [140/246] time 0.098 (0.367) data 0.001 (0.002) loss 2.2989 (1.7161) teacher_loss 1.5850 (0.9904) loss_zs_kd 0.0482 (0.0356) loss_oracle 0.4371 (0.4584) kd_loss 0.4712 (0.4787) acc 59.3750 (74.2857) gate/entropy 1.0002 (1.0015) gate/usage_max 0.5493 (0.5479) gate/usage_min 0.2150 (0.2154) gate/usage_std 0.1530 (0.1519) teacher/entropy 0.2144 (0.2406) teacher/usage_max 0.8987 (0.8627) teacher/usage_min 0.0079 (0.0226) teacher/usage_std 0.4013 (0.3766) nleep/row_max_mean 1200.4822 (1199.4844) nleep/row_max_std 15.2581 (14.1135) nleep/row_min_mean 1193.6698 (1193.1863) lr 1.7290e-03 eta 0:54:51
epoch [14/50] batch [160/246] time 0.091 (0.364) data 0.000 (0.002) loss 1.6292 (1.7131) teacher_loss 0.8822 (0.9871) loss_zs_kd 0.0316 (0.0351) loss_oracle 0.4454 (0.4584) kd_loss 0.5085 (0.4792) acc 78.1250 (74.1992) gate/entropy 0.9995 (1.0012) gate/usage_max 0.5501 (0.5481) gate/usage_min 0.2148 (0.2154) gate/usage_std 0.1535 (0.1521) teacher/entropy 0.2289 (0.2428) teacher/usage_max 0.8391 (0.8593) teacher/usage_min 0.0296 (0.0239) teacher/usage_std 0.3600 (0.3743) nleep/row_max_mean 1195.4036 (1199.3701) nleep/row_max_std 16.7667 (14.3461) nleep/row_min_mean 1189.1655 (1193.0985) lr 1.7290e-03 eta 0:54:11
epoch [14/50] batch [180/246] time 0.084 (0.361) data 0.000 (0.002) loss 2.1192 (1.7053) teacher_loss 1.3777 (0.9823) loss_zs_kd 0.0437 (0.0353) loss_oracle 0.5238 (0.4542) kd_loss 0.4577 (0.4784) acc 71.8750 (74.4271) gate/entropy 0.9993 (1.0011) gate/usage_max 0.5503 (0.5483) gate/usage_min 0.2148 (0.2153) gate/usage_std 0.1536 (0.1523) teacher/entropy 0.3054 (0.2431) teacher/usage_max 0.8086 (0.8597) teacher/usage_min 0.0316 (0.0242) teacher/usage_std 0.3401 (0.3745) nleep/row_max_mean 1194.8394 (1199.3097) nleep/row_max_std 16.0214 (14.4456) nleep/row_min_mean 1188.7463 (1193.0494) lr 1.7290e-03 eta 0:53:43
epoch [14/50] batch [200/246] time 0.494 (0.369) data 0.000 (0.001) loss 1.5793 (1.7044) teacher_loss 0.8881 (0.9835) loss_zs_kd 0.0469 (0.0350) loss_oracle 0.4931 (0.4558) kd_loss 0.4211 (0.4756) acc 71.8750 (74.3594) gate/entropy 0.9986 (1.0008) gate/usage_max 0.5512 (0.5486) gate/usage_min 0.2146 (0.2153) gate/usage_std 0.1542 (0.1524) teacher/entropy 0.3554 (0.2451) teacher/usage_max 0.7935 (0.8603) teacher/usage_min 0.0424 (0.0251) teacher/usage_std 0.3292 (0.3748) nleep/row_max_mean 1198.5718 (1199.2011) nleep/row_max_std 15.5700 (14.4752) nleep/row_min_mean 1193.1470 (1192.9891) lr 1.7290e-03 eta 0:54:42
epoch [14/50] batch [220/246] time 0.465 (0.381) data 0.000 (0.001) loss 1.5814 (1.6955) teacher_loss 0.7573 (0.9726) loss_zs_kd 0.0430 (0.0353) loss_oracle 0.5889 (0.4585) kd_loss 0.5081 (0.4760) acc 78.1250 (74.6307) gate/entropy 0.9990 (1.0006) gate/usage_max 0.5507 (0.5488) gate/usage_min 0.2147 (0.2152) gate/usage_std 0.1539 (0.1526) teacher/entropy 0.2745 (0.2462) teacher/usage_max 0.7875 (0.8584) teacher/usage_min 0.0505 (0.0259) teacher/usage_std 0.3244 (0.3735) nleep/row_max_mean 1196.5601 (1199.1710) nleep/row_max_std 15.7301 (14.5035) nleep/row_min_mean 1190.4329 (1192.9838) lr 1.7290e-03 eta 0:56:20
epoch [14/50] batch [240/246] time 0.494 (0.390) data 0.000 (0.001) loss 1.7295 (1.6887) teacher_loss 0.9628 (0.9679) loss_zs_kd 0.0426 (0.0353) loss_oracle 0.4293 (0.4580) kd_loss 0.5307 (0.4742) acc 75.0000 (74.7396) gate/entropy 0.9981 (1.0005) gate/usage_max 0.5517 (0.5490) gate/usage_min 0.2144 (0.2152) gate/usage_std 0.1546 (0.1527) teacher/entropy 0.2173 (0.2474) teacher/usage_max 0.8256 (0.8588) teacher/usage_min 0.0406 (0.0262) teacher/usage_std 0.3501 (0.3737) nleep/row_max_mean 1198.9634 (1199.1611) nleep/row_max_std 13.6788 (14.5405) nleep/row_min_mean 1192.7314 (1192.9965) lr 1.7290e-03 eta 0:57:36
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,845
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,965
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.1%
******* Domain r best val acc:      84.9%, epoch: 5 *******
******* Domain r best val test acc: 91.1%, epoch: 5 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [15/50] batch [20/246] time 0.436 (0.366) data 0.000 (0.013) loss 1.7322 (1.6694) teacher_loss 0.9908 (0.9781) loss_zs_kd 0.0422 (0.0363) loss_oracle 0.5476 (0.4469) kd_loss 0.4466 (0.4497) acc 68.7500 (72.9688) gate/entropy 0.9977 (0.9980) gate/usage_max 0.5521 (0.5518) gate/usage_min 0.2143 (0.2144) gate/usage_std 0.1549 (0.1547) teacher/entropy 0.3532 (0.2808) teacher/usage_max 0.7693 (0.8456) teacher/usage_min 0.0815 (0.0357) teacher/usage_std 0.3095 (0.3640) nleep/row_max_mean 1207.3599 (1199.3441) nleep/row_max_std 15.5707 (15.1173) nleep/row_min_mean 1201.7147 (1193.4656) lr 1.6845e-03 eta 0:53:50
epoch [15/50] batch [40/246] time 0.461 (0.418) data 0.000 (0.007) loss 1.5508 (1.6473) teacher_loss 0.8102 (0.9598) loss_zs_kd 0.0410 (0.0351) loss_oracle 0.4861 (0.4423) kd_loss 0.4770 (0.4487) acc 84.3750 (74.4531) gate/entropy 0.9973 (0.9979) gate/usage_max 0.5526 (0.5520) gate/usage_min 0.2142 (0.2144) gate/usage_std 0.1552 (0.1548) teacher/entropy 0.2221 (0.2857) teacher/usage_max 0.8799 (0.8408) teacher/usage_min 0.0295 (0.0357) teacher/usage_std 0.3873 (0.3609) nleep/row_max_mean 1203.8146 (1198.9606) nleep/row_max_std 12.7654 (14.7798) nleep/row_min_mean 1197.7971 (1193.1534) lr 1.6845e-03 eta 1:01:23
epoch [15/50] batch [60/246] time 0.496 (0.436) data 0.001 (0.004) loss 1.4490 (1.6613) teacher_loss 0.6136 (0.9616) loss_zs_kd 0.0492 (0.0374) loss_oracle 0.5885 (0.4543) kd_loss 0.5165 (0.4538) acc 87.5000 (74.6354) gate/entropy 0.9974 (0.9977) gate/usage_max 0.5525 (0.5521) gate/usage_min 0.2142 (0.2143) gate/usage_std 0.1552 (0.1549) teacher/entropy 0.2089 (0.2782) teacher/usage_max 0.8484 (0.8431) teacher/usage_min 0.0178 (0.0333) teacher/usage_std 0.3673 (0.3627) nleep/row_max_mean 1204.8348 (1198.8179) nleep/row_max_std 17.2765 (14.4384) nleep/row_min_mean 1198.0386 (1192.9516) lr 1.6845e-03 eta 1:03:52
epoch [15/50] batch [80/246] time 0.093 (0.423) data 0.000 (0.003) loss 1.4480 (1.6681) teacher_loss 0.7136 (0.9552) loss_zs_kd 0.0235 (0.0372) loss_oracle 0.5114 (0.4765) kd_loss 0.4670 (0.4561) acc 75.0000 (75.0000) gate/entropy 0.9974 (0.9976) gate/usage_max 0.5525 (0.5523) gate/usage_min 0.2141 (0.2143) gate/usage_std 0.1552 (0.1550) teacher/entropy 0.2849 (0.2803) teacher/usage_max 0.8221 (0.8379) teacher/usage_min 0.0584 (0.0331) teacher/usage_std 0.3465 (0.3594) nleep/row_max_mean 1197.4532 (1198.7565) nleep/row_max_std 14.3829 (14.2790) nleep/row_min_mean 1191.9172 (1192.8597) lr 1.6845e-03 eta 1:01:48
epoch [15/50] batch [100/246] time 0.459 (0.403) data 0.000 (0.003) loss 1.5554 (1.6645) teacher_loss 0.8476 (0.9564) loss_zs_kd 0.0352 (0.0365) loss_oracle 0.4552 (0.4664) kd_loss 0.4626 (0.4567) acc 84.3750 (75.0938) gate/entropy 0.9971 (0.9975) gate/usage_max 0.5529 (0.5524) gate/usage_min 0.2140 (0.2142) gate/usage_std 0.1554 (0.1551) teacher/entropy 0.3023 (0.2758) teacher/usage_max 0.8041 (0.8421) teacher/usage_min 0.0304 (0.0312) teacher/usage_std 0.3374 (0.3624) nleep/row_max_mean 1194.7817 (1198.7149) nleep/row_max_std 14.4635 (14.2331) nleep/row_min_mean 1188.7427 (1192.7979) lr 1.6845e-03 eta 0:58:50
epoch [15/50] batch [120/246] time 0.460 (0.388) data 0.000 (0.002) loss 2.0767 (1.6624) teacher_loss 1.2726 (0.9568) loss_zs_kd 0.0443 (0.0362) loss_oracle 0.5621 (0.4618) kd_loss 0.5009 (0.4566) acc 65.6250 (74.9740) gate/entropy 0.9965 (0.9974) gate/usage_max 0.5535 (0.5525) gate/usage_min 0.2138 (0.2142) gate/usage_std 0.1559 (0.1552) teacher/entropy 0.2985 (0.2740) teacher/usage_max 0.7628 (0.8440) teacher/usage_min 0.0270 (0.0306) teacher/usage_std 0.3128 (0.3637) nleep/row_max_mean 1193.0845 (1198.7138) nleep/row_max_std 12.7747 (14.3203) nleep/row_min_mean 1187.8982 (1192.7895) lr 1.6845e-03 eta 0:56:32
epoch [15/50] batch [140/246] time 0.441 (0.380) data 0.000 (0.002) loss 1.8424 (1.6757) teacher_loss 1.2272 (0.9661) loss_zs_kd 0.0289 (0.0364) loss_oracle 0.4175 (0.4663) kd_loss 0.3920 (0.4582) acc 71.8750 (74.6875) gate/entropy 0.9968 (0.9973) gate/usage_max 0.5532 (0.5526) gate/usage_min 0.2139 (0.2141) gate/usage_std 0.1556 (0.1553) teacher/entropy 0.3032 (0.2738) teacher/usage_max 0.8836 (0.8423) teacher/usage_min 0.0267 (0.0309) teacher/usage_std 0.3899 (0.3625) nleep/row_max_mean 1198.9792 (1198.6265) nleep/row_max_std 16.0521 (14.3492) nleep/row_min_mean 1193.5736 (1192.7018) lr 1.6845e-03 eta 0:55:15
epoch [15/50] batch [160/246] time 0.523 (0.391) data 0.000 (0.002) loss 2.0321 (1.6861) teacher_loss 1.2316 (0.9761) loss_zs_kd 0.0510 (0.0362) loss_oracle 0.5562 (0.4676) kd_loss 0.4969 (0.4582) acc 59.3750 (74.4141) gate/entropy 0.9962 (0.9972) gate/usage_max 0.5539 (0.5528) gate/usage_min 0.2136 (0.2141) gate/usage_std 0.1561 (0.1553) teacher/entropy 0.2458 (0.2738) teacher/usage_max 0.8286 (0.8420) teacher/usage_min 0.0328 (0.0306) teacher/usage_std 0.3528 (0.3623) nleep/row_max_mean 1199.6993 (1198.6819) nleep/row_max_std 15.9345 (14.5056) nleep/row_min_mean 1193.3500 (1192.7290) lr 1.6845e-03 eta 0:56:43
epoch [15/50] batch [180/246] time 0.508 (0.403) data 0.000 (0.002) loss 1.9992 (1.6704) teacher_loss 1.2889 (0.9603) loss_zs_kd 0.0479 (0.0359) loss_oracle 0.4531 (0.4655) kd_loss 0.4598 (0.4593) acc 65.6250 (74.8090) gate/entropy 0.9959 (0.9971) gate/usage_max 0.5542 (0.5529) gate/usage_min 0.2135 (0.2140) gate/usage_std 0.1564 (0.1554) teacher/entropy 0.2857 (0.2712) teacher/usage_max 0.8270 (0.8435) teacher/usage_min 0.0512 (0.0298) teacher/usage_std 0.3503 (0.3634) nleep/row_max_mean 1198.8140 (1198.8545) nleep/row_max_std 15.0730 (14.6048) nleep/row_min_mean 1193.0820 (1192.8621) lr 1.6845e-03 eta 0:58:12
epoch [15/50] batch [200/246] time 0.110 (0.391) data 0.000 (0.001) loss 1.5232 (1.6731) teacher_loss 0.8555 (0.9646) loss_zs_kd 0.0164 (0.0358) loss_oracle 0.4003 (0.4626) kd_loss 0.4594 (0.4593) acc 68.7500 (74.6406) gate/entropy 0.9960 (0.9970) gate/usage_max 0.5541 (0.5530) gate/usage_min 0.2136 (0.2140) gate/usage_std 0.1563 (0.1555) teacher/entropy 0.2601 (0.2724) teacher/usage_max 0.8534 (0.8420) teacher/usage_min 0.0147 (0.0298) teacher/usage_std 0.3708 (0.3624) nleep/row_max_mean 1198.7664 (1198.9681) nleep/row_max_std 14.4001 (14.7289) nleep/row_min_mean 1192.6787 (1192.9587) lr 1.6845e-03 eta 0:56:22
epoch [15/50] batch [220/246] time 0.082 (0.386) data 0.000 (0.001) loss 2.1620 (1.6761) teacher_loss 1.4125 (0.9686) loss_zs_kd 0.0466 (0.0359) loss_oracle 0.4618 (0.4589) kd_loss 0.4953 (0.4602) acc 62.5000 (74.5170) gate/entropy 0.9956 (0.9968) gate/usage_max 0.5545 (0.5531) gate/usage_min 0.2134 (0.2139) gate/usage_std 0.1566 (0.1556) teacher/entropy 0.2180 (0.2703) teacher/usage_max 0.8638 (0.8433) teacher/usage_min 0.0543 (0.0294) teacher/usage_std 0.3753 (0.3632) nleep/row_max_mean 1201.4082 (1199.1144) nleep/row_max_std 14.8182 (14.7426) nleep/row_min_mean 1194.5706 (1193.0833) lr 1.6845e-03 eta 0:55:32
epoch [15/50] batch [240/246] time 0.081 (0.382) data 0.000 (0.001) loss 1.4608 (1.6780) teacher_loss 0.7665 (0.9714) loss_zs_kd 0.0365 (0.0361) loss_oracle 0.4241 (0.4568) kd_loss 0.4640 (0.4602) acc 75.0000 (74.5182) gate/entropy 0.9952 (0.9967) gate/usage_max 0.5549 (0.5533) gate/usage_min 0.2134 (0.2139) gate/usage_std 0.1569 (0.1557) teacher/entropy 0.2344 (0.2688) teacher/usage_max 0.8771 (0.8447) teacher/usage_min 0.0262 (0.0291) teacher/usage_std 0.3856 (0.3642) nleep/row_max_mean 1200.2695 (1199.2129) nleep/row_max_std 14.3656 (14.7266) nleep/row_min_mean 1194.3739 (1193.1840) lr 1.6845e-03 eta 0:54:55
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,851
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,970
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.1%
******* Domain r best val acc:      85.0%, epoch: 15 *******
******* Domain r best val test acc: 91.1%, epoch: 15 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [16/50] batch [20/246] time 0.492 (0.534) data 0.000 (0.016) loss 1.1162 (1.7221) teacher_loss 0.4392 (0.9745) loss_zs_kd 0.0298 (0.0388) loss_oracle 0.4391 (0.5181) kd_loss 0.4426 (0.4692) acc 90.6250 (75.7812) gate/entropy 0.9952 (0.9952) gate/usage_max 0.5549 (0.5550) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1569 (0.1569) teacher/entropy 0.2513 (0.2686) teacher/usage_max 0.8819 (0.8325) teacher/usage_min 0.0227 (0.0290) teacher/usage_std 0.3891 (0.3565) nleep/row_max_mean 1203.3185 (1199.4175) nleep/row_max_std 17.2431 (14.3714) nleep/row_min_mean 1197.0034 (1193.4054) lr 1.6374e-03 eta 1:16:25
epoch [16/50] batch [40/246] time 0.096 (0.445) data 0.000 (0.008) loss 1.4328 (1.6989) teacher_loss 0.7005 (0.9663) loss_zs_kd 0.0454 (0.0379) loss_oracle 0.4793 (0.4909) kd_loss 0.4699 (0.4681) acc 90.6250 (75.3906) gate/entropy 0.9951 (0.9951) gate/usage_max 0.5551 (0.5550) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1570 (0.1570) teacher/entropy 0.2777 (0.2653) teacher/usage_max 0.8260 (0.8376) teacher/usage_min 0.0791 (0.0315) teacher/usage_std 0.3484 (0.3594) nleep/row_max_mean 1203.7340 (1199.9002) nleep/row_max_std 16.1187 (14.3925) nleep/row_min_mean 1197.5132 (1193.8978) lr 1.6374e-03 eta 1:03:37
epoch [16/50] batch [60/246] time 0.079 (0.410) data 0.000 (0.005) loss 2.1191 (1.7112) teacher_loss 1.4473 (0.9851) loss_zs_kd 0.0330 (0.0388) loss_oracle 0.3957 (0.4747) kd_loss 0.4575 (0.4693) acc 62.5000 (74.8438) gate/entropy 0.9945 (0.9950) gate/usage_max 0.5558 (0.5551) gate/usage_min 0.2131 (0.2133) gate/usage_std 0.1575 (0.1570) teacher/entropy 0.2468 (0.2564) teacher/usage_max 0.8696 (0.8461) teacher/usage_min 0.0271 (0.0302) teacher/usage_std 0.3804 (0.3651) nleep/row_max_mean 1201.5364 (1200.1203) nleep/row_max_std 13.2073 (14.4659) nleep/row_min_mean 1195.3916 (1194.0039) lr 1.6374e-03 eta 0:58:26
epoch [16/50] batch [80/246] time 0.079 (0.394) data 0.000 (0.004) loss 1.8721 (1.7389) teacher_loss 1.1059 (1.0116) loss_zs_kd 0.0422 (0.0394) loss_oracle 0.5274 (0.4756) kd_loss 0.4813 (0.4698) acc 71.8750 (74.0625) gate/entropy 0.9942 (0.9949) gate/usage_max 0.5560 (0.5553) gate/usage_min 0.2131 (0.2133) gate/usage_std 0.1576 (0.1571) teacher/entropy 0.2350 (0.2574) teacher/usage_max 0.8563 (0.8443) teacher/usage_min 0.0341 (0.0311) teacher/usage_std 0.3711 (0.3639) nleep/row_max_mean 1206.2144 (1200.1280) nleep/row_max_std 14.3687 (14.6346) nleep/row_min_mean 1199.5862 (1194.0255) lr 1.6374e-03 eta 0:55:57
epoch [16/50] batch [100/246] time 0.492 (0.398) data 0.000 (0.003) loss 1.4429 (1.7151) teacher_loss 0.8356 (0.9970) loss_zs_kd 0.0252 (0.0395) loss_oracle 0.3726 (0.4625) kd_loss 0.4084 (0.4671) acc 78.1250 (74.5000) gate/entropy 0.9942 (0.9948) gate/usage_max 0.5561 (0.5554) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1577 (0.1572) teacher/entropy 0.3132 (0.2559) teacher/usage_max 0.8532 (0.8492) teacher/usage_min 0.0672 (0.0322) teacher/usage_std 0.3676 (0.3670) nleep/row_max_mean 1200.3579 (1200.2000) nleep/row_max_std 16.9370 (14.7069) nleep/row_min_mean 1194.5715 (1194.0841) lr 1.6374e-03 eta 0:56:24
epoch [16/50] batch [120/246] time 0.464 (0.412) data 0.000 (0.003) loss 1.4607 (1.7055) teacher_loss 0.6942 (0.9908) loss_zs_kd 0.0314 (0.0397) loss_oracle 0.4903 (0.4571) kd_loss 0.5058 (0.4663) acc 87.5000 (74.2969) gate/entropy 0.9938 (0.9947) gate/usage_max 0.5565 (0.5555) gate/usage_min 0.2130 (0.2132) gate/usage_std 0.1580 (0.1573) teacher/entropy 0.2346 (0.2567) teacher/usage_max 0.8276 (0.8490) teacher/usage_min 0.0240 (0.0322) teacher/usage_std 0.3532 (0.3668) nleep/row_max_mean 1199.3872 (1200.0284) nleep/row_max_std 13.5687 (14.8720) nleep/row_min_mean 1193.5786 (1193.9420) lr 1.6374e-03 eta 0:58:18
epoch [16/50] batch [140/246] time 0.496 (0.423) data 0.000 (0.002) loss 1.5604 (1.7015) teacher_loss 0.8612 (0.9897) loss_zs_kd 0.0231 (0.0393) loss_oracle 0.5161 (0.4571) kd_loss 0.4295 (0.4636) acc 71.8750 (74.3527) gate/entropy 0.9939 (0.9946) gate/usage_max 0.5565 (0.5556) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1579 (0.1574) teacher/entropy 0.3093 (0.2611) teacher/usage_max 0.8328 (0.8470) teacher/usage_min 0.0624 (0.0332) teacher/usage_std 0.3536 (0.3654) nleep/row_max_mean 1197.9409 (1199.9961) nleep/row_max_std 15.7815 (14.9624) nleep/row_min_mean 1192.3870 (1193.9741) lr 1.6374e-03 eta 0:59:41
epoch [16/50] batch [160/246] time 0.429 (0.398) data 0.000 (0.002) loss 2.1427 (1.6979) teacher_loss 1.4722 (0.9896) loss_zs_kd 0.0453 (0.0385) loss_oracle 0.4457 (0.4566) kd_loss 0.4250 (0.4608) acc 65.6250 (74.2188) gate/entropy 0.9937 (0.9945) gate/usage_max 0.5567 (0.5558) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1581 (0.1575) teacher/entropy 0.2741 (0.2621) teacher/usage_max 0.8760 (0.8489) teacher/usage_min 0.0476 (0.0337) teacher/usage_std 0.3839 (0.3667) nleep/row_max_mean 1200.7932 (1200.1153) nleep/row_max_std 16.9676 (15.0407) nleep/row_min_mean 1194.9199 (1194.1201) lr 1.6374e-03 eta 0:56:00
epoch [16/50] batch [180/246] time 0.409 (0.390) data 0.000 (0.002) loss 1.7333 (1.6905) teacher_loss 1.0302 (0.9804) loss_zs_kd 0.0235 (0.0380) loss_oracle 0.5766 (0.4652) kd_loss 0.4031 (0.4584) acc 75.0000 (74.3924) gate/entropy 0.9932 (0.9944) gate/usage_max 0.5572 (0.5559) gate/usage_min 0.2129 (0.2132) gate/usage_std 0.1585 (0.1575) teacher/entropy 0.3267 (0.2665) teacher/usage_max 0.8401 (0.8466) teacher/usage_min 0.0430 (0.0348) teacher/usage_std 0.3596 (0.3650) nleep/row_max_mean 1201.5459 (1200.0350) nleep/row_max_std 15.6273 (15.0559) nleep/row_min_mean 1195.6843 (1194.0903) lr 1.6374e-03 eta 0:54:45
epoch [16/50] batch [200/246] time 0.467 (0.387) data 0.000 (0.002) loss 1.4775 (1.6964) teacher_loss 0.7704 (0.9852) loss_zs_kd 0.0330 (0.0385) loss_oracle 0.5061 (0.4722) kd_loss 0.4375 (0.4558) acc 81.2500 (74.3750) gate/entropy 0.9932 (0.9943) gate/usage_max 0.5572 (0.5560) gate/usage_min 0.2129 (0.2131) gate/usage_std 0.1584 (0.1576) teacher/entropy 0.2877 (0.2703) teacher/usage_max 0.8450 (0.8452) teacher/usage_min 0.0390 (0.0359) teacher/usage_std 0.3632 (0.3640) nleep/row_max_mean 1200.3724 (1199.9443) nleep/row_max_std 12.5435 (14.9943) nleep/row_min_mean 1195.1995 (1194.0486) lr 1.6374e-03 eta 0:54:14
epoch [16/50] batch [220/246] time 0.519 (0.396) data 0.000 (0.002) loss 1.7269 (1.6905) teacher_loss 1.0609 (0.9800) loss_zs_kd 0.0328 (0.0384) loss_oracle 0.4890 (0.4746) kd_loss 0.4051 (0.4540) acc 71.8750 (74.6307) gate/entropy 0.9933 (0.9942) gate/usage_max 0.5570 (0.5561) gate/usage_min 0.2129 (0.2131) gate/usage_std 0.1583 (0.1577) teacher/entropy 0.3381 (0.2733) teacher/usage_max 0.8279 (0.8438) teacher/usage_min 0.0776 (0.0371) teacher/usage_std 0.3498 (0.3630) nleep/row_max_mean 1203.6182 (1199.9696) nleep/row_max_std 16.6396 (15.0144) nleep/row_min_mean 1198.5679 (1194.1249) lr 1.6374e-03 eta 0:55:22
epoch [16/50] batch [240/246] time 0.494 (0.405) data 0.000 (0.002) loss 1.8115 (1.6883) teacher_loss 1.0094 (0.9762) loss_zs_kd 0.0292 (0.0380) loss_oracle 0.6727 (0.4832) kd_loss 0.4511 (0.4514) acc 75.0000 (74.7005) gate/entropy 0.9932 (0.9941) gate/usage_max 0.5572 (0.5562) gate/usage_min 0.2128 (0.2131) gate/usage_std 0.1585 (0.1577) teacher/entropy 0.3865 (0.2789) teacher/usage_max 0.7229 (0.8405) teacher/usage_min 0.0908 (0.0388) teacher/usage_std 0.2782 (0.3606) nleep/row_max_mean 1200.7009 (1199.9538) nleep/row_max_std 16.8971 (15.0597) nleep/row_min_mean 1196.0095 (1194.1685) lr 1.6374e-03 eta 0:56:29
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,846
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,964
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 89.9%
******* Domain r best val acc:      85.0%, epoch: 15 *******
******* Domain r best val test acc: 91.1%, epoch: 15 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [17/50] batch [20/246] time 0.439 (0.345) data 0.000 (0.015) loss 1.6002 (1.6983) teacher_loss 0.7766 (0.9739) loss_zs_kd 0.0222 (0.0368) loss_oracle 0.5849 (0.5446) kd_loss 0.5201 (0.4337) acc 78.1250 (74.6875) gate/entropy 0.9934 (0.9933) gate/usage_max 0.5570 (0.5571) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1583 (0.1584) teacher/entropy 0.2670 (0.3409) teacher/usage_max 0.7780 (0.7912) teacher/usage_min 0.0697 (0.0596) teacher/usage_std 0.3162 (0.3263) nleep/row_max_mean 1198.0746 (1199.1781) nleep/row_max_std 14.6046 (15.1749) nleep/row_min_mean 1192.6472 (1194.0624) lr 1.5878e-03 eta 0:48:02
epoch [17/50] batch [40/246] time 0.472 (0.355) data 0.000 (0.007) loss 1.2508 (1.6650) teacher_loss 0.5857 (0.9407) loss_zs_kd 0.0305 (0.0380) loss_oracle 0.5178 (0.5490) kd_loss 0.3909 (0.4307) acc 81.2500 (75.4688) gate/entropy 0.9932 (0.9932) gate/usage_max 0.5572 (0.5571) gate/usage_min 0.2126 (0.2127) gate/usage_std 0.1585 (0.1584) teacher/entropy 0.3432 (0.3454) teacher/usage_max 0.8351 (0.7892) teacher/usage_min 0.0432 (0.0589) teacher/usage_std 0.3562 (0.3254) nleep/row_max_mean 1204.3235 (1199.8366) nleep/row_max_std 17.1434 (15.4405) nleep/row_min_mean 1199.5621 (1194.7562) lr 1.5878e-03 eta 0:49:13
epoch [17/50] batch [60/246] time 0.431 (0.395) data 0.000 (0.005) loss 1.4289 (1.6600) teacher_loss 0.6889 (0.9250) loss_zs_kd 0.0493 (0.0398) loss_oracle 0.6343 (0.5762) kd_loss 0.3982 (0.4270) acc 84.3750 (76.0938) gate/entropy 0.9934 (0.9933) gate/usage_max 0.5570 (0.5571) gate/usage_min 0.2126 (0.2127) gate/usage_std 0.1583 (0.1584) teacher/entropy 0.3468 (0.3475) teacher/usage_max 0.8228 (0.7908) teacher/usage_min 0.0407 (0.0557) teacher/usage_std 0.3483 (0.3268) nleep/row_max_mean 1204.7649 (1199.7969) nleep/row_max_std 19.1825 (15.6857) nleep/row_min_mean 1199.2676 (1194.7061) lr 1.5878e-03 eta 0:54:43
epoch [17/50] batch [80/246] time 0.423 (0.410) data 0.000 (0.004) loss 1.5700 (1.6941) teacher_loss 0.8370 (0.9427) loss_zs_kd 0.0432 (0.0398) loss_oracle 0.4901 (0.6011) kd_loss 0.4664 (0.4310) acc 78.1250 (75.4297) gate/entropy 0.9934 (0.9933) gate/usage_max 0.5570 (0.5571) gate/usage_min 0.2124 (0.2126) gate/usage_std 0.1583 (0.1584) teacher/entropy 0.2722 (0.3544) teacher/usage_max 0.8294 (0.7785) teacher/usage_min 0.0309 (0.0560) teacher/usage_std 0.3535 (0.3190) nleep/row_max_mean 1203.5271 (1199.7510) nleep/row_max_std 16.7014 (15.7164) nleep/row_min_mean 1198.2340 (1194.7091) lr 1.5878e-03 eta 0:56:38
epoch [17/50] batch [100/246] time 0.087 (0.393) data 0.000 (0.003) loss 1.8407 (1.6912) teacher_loss 1.0270 (0.9467) loss_zs_kd 0.0379 (0.0399) loss_oracle 0.5931 (0.5915) kd_loss 0.4982 (0.4288) acc 75.0000 (75.5938) gate/entropy 0.9937 (0.9934) gate/usage_max 0.5566 (0.5570) gate/usage_min 0.2123 (0.2126) gate/usage_std 0.1580 (0.1583) teacher/entropy 0.3784 (0.3623) teacher/usage_max 0.6741 (0.7722) teacher/usage_min 0.0489 (0.0576) teacher/usage_std 0.2583 (0.3149) nleep/row_max_mean 1200.5719 (1199.5891) nleep/row_max_std 15.1308 (15.5451) nleep/row_min_mean 1196.0197 (1194.6244) lr 1.5878e-03 eta 0:54:08
epoch [17/50] batch [120/246] time 0.083 (0.384) data 0.000 (0.003) loss 1.5437 (1.6717) teacher_loss 0.7022 (0.9315) loss_zs_kd 0.0342 (0.0397) loss_oracle 0.6386 (0.5816) kd_loss 0.5051 (0.4296) acc 87.5000 (76.1719) gate/entropy 0.9937 (0.9934) gate/usage_max 0.5565 (0.5569) gate/usage_min 0.2122 (0.2125) gate/usage_std 0.1580 (0.1583) teacher/entropy 0.3410 (0.3653) teacher/usage_max 0.7084 (0.7680) teacher/usage_min 0.0457 (0.0586) teacher/usage_std 0.2775 (0.3121) nleep/row_max_mean 1203.0051 (1199.8296) nleep/row_max_std 20.2091 (15.7078) nleep/row_min_mean 1197.4807 (1194.8907) lr 1.5878e-03 eta 0:52:45
epoch [17/50] batch [140/246] time 0.078 (0.378) data 0.000 (0.002) loss 1.8044 (1.6791) teacher_loss 1.0209 (0.9364) loss_zs_kd 0.0276 (0.0402) loss_oracle 0.6775 (0.5899) kd_loss 0.4310 (0.4276) acc 75.0000 (76.1830) gate/entropy 0.9940 (0.9935) gate/usage_max 0.5562 (0.5568) gate/usage_min 0.2121 (0.2125) gate/usage_std 0.1578 (0.1582) teacher/entropy 0.4214 (0.3741) teacher/usage_max 0.7014 (0.7604) teacher/usage_min 0.0477 (0.0596) teacher/usage_std 0.2731 (0.3073) nleep/row_max_mean 1200.6818 (1199.8097) nleep/row_max_std 21.8494 (15.8847) nleep/row_min_mean 1196.0128 (1194.9297) lr 1.5878e-03 eta 0:51:49
epoch [17/50] batch [160/246] time 0.461 (0.381) data 0.000 (0.002) loss 1.3284 (1.6784) teacher_loss 0.7333 (0.9376) loss_zs_kd 0.0281 (0.0402) loss_oracle 0.4182 (0.5875) kd_loss 0.3719 (0.4271) acc 81.2500 (76.0547) gate/entropy 0.9939 (0.9935) gate/usage_max 0.5563 (0.5567) gate/usage_min 0.2119 (0.2124) gate/usage_std 0.1579 (0.1582) teacher/entropy 0.3766 (0.3789) teacher/usage_max 0.8190 (0.7556) teacher/usage_min 0.0437 (0.0604) teacher/usage_std 0.3456 (0.3043) nleep/row_max_mean 1198.1108 (1199.7599) nleep/row_max_std 13.8569 (15.9095) nleep/row_min_mean 1193.2898 (1194.9160) lr 1.5878e-03 eta 0:52:05
epoch [17/50] batch [180/246] time 0.496 (0.392) data 0.000 (0.002) loss 2.2043 (1.6797) teacher_loss 1.4348 (0.9398) loss_zs_kd 0.0671 (0.0402) loss_oracle 0.6607 (0.5849) kd_loss 0.4056 (0.4273) acc 68.7500 (75.8681) gate/entropy 0.9944 (0.9936) gate/usage_max 0.5557 (0.5566) gate/usage_min 0.2118 (0.2123) gate/usage_std 0.1575 (0.1581) teacher/entropy 0.4592 (0.3830) teacher/usage_max 0.6884 (0.7506) teacher/usage_min 0.0546 (0.0603) teacher/usage_std 0.2643 (0.3013) nleep/row_max_mean 1196.2891 (1199.6149) nleep/row_max_std 12.6410 (15.7683) nleep/row_min_mean 1191.8163 (1194.7954) lr 1.5878e-03 eta 0:53:26
epoch [17/50] batch [200/246] time 0.495 (0.402) data 0.000 (0.002) loss 1.5432 (1.6793) teacher_loss 0.8798 (0.9401) loss_zs_kd 0.0254 (0.0398) loss_oracle 0.5798 (0.5871) kd_loss 0.3608 (0.4258) acc 78.1250 (75.9062) gate/entropy 0.9946 (0.9937) gate/usage_max 0.5555 (0.5565) gate/usage_min 0.2117 (0.2123) gate/usage_std 0.1573 (0.1580) teacher/entropy 0.4425 (0.3873) teacher/usage_max 0.7611 (0.7476) teacher/usage_min 0.0790 (0.0607) teacher/usage_std 0.3043 (0.2994) nleep/row_max_mean 1199.0040 (1199.7171) nleep/row_max_std 17.5660 (15.7987) nleep/row_min_mean 1194.5470 (1194.9272) lr 1.5878e-03 eta 0:54:40
epoch [17/50] batch [220/246] time 0.089 (0.383) data 0.000 (0.001) loss 1.5140 (1.6814) teacher_loss 0.7943 (0.9441) loss_zs_kd 0.0601 (0.0400) loss_oracle 0.5187 (0.5837) kd_loss 0.4302 (0.4254) acc 81.2500 (75.8097) gate/entropy 0.9949 (0.9938) gate/usage_max 0.5551 (0.5564) gate/usage_min 0.2116 (0.2122) gate/usage_std 0.1571 (0.1579) teacher/entropy 0.4069 (0.3906) teacher/usage_max 0.7200 (0.7443) teacher/usage_min 0.0555 (0.0615) teacher/usage_std 0.2820 (0.2972) nleep/row_max_mean 1196.9447 (1199.5674) nleep/row_max_std 16.5384 (15.6278) nleep/row_min_mean 1191.9359 (1194.7993) lr 1.5878e-03 eta 0:52:02
epoch [17/50] batch [240/246] time 0.459 (0.379) data 0.000 (0.001) loss 1.5299 (1.6747) teacher_loss 0.7275 (0.9374) loss_zs_kd 0.0369 (0.0402) loss_oracle 0.5869 (0.5813) kd_loss 0.4905 (0.4265) acc 81.2500 (76.0417) gate/entropy 0.9953 (0.9939) gate/usage_max 0.5547 (0.5563) gate/usage_min 0.2114 (0.2122) gate/usage_std 0.1568 (0.1579) teacher/entropy 0.3634 (0.3919) teacher/usage_max 0.6997 (0.7416) teacher/usage_min 0.0467 (0.0607) teacher/usage_std 0.2725 (0.2957) nleep/row_max_mean 1203.8921 (1199.6396) nleep/row_max_std 18.1434 (15.6292) nleep/row_min_mean 1198.7764 (1194.8688) lr 1.5878e-03 eta 0:51:18
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,859
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,964
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 90.0%
******* Domain r best val acc:      85.2%, epoch: 17 *******
******* Domain r best val test acc: 91.0%, epoch: 17 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [18/50] batch [20/246] time 0.497 (0.503) data 0.000 (0.015) loss 1.6291 (1.7303) teacher_loss 0.8267 (0.9523) loss_zs_kd 0.0503 (0.0433) loss_oracle 0.6427 (0.6170) kd_loss 0.4559 (0.4478) acc 84.3750 (74.8438) gate/entropy 0.9955 (0.9954) gate/usage_max 0.5544 (0.5544) gate/usage_min 0.2112 (0.2113) gate/usage_std 0.1566 (0.1566) teacher/entropy 0.4049 (0.4031) teacher/usage_max 0.6901 (0.7037) teacher/usage_min 0.0371 (0.0546) teacher/usage_std 0.2700 (0.2740) nleep/row_max_mean 1200.5962 (1200.1763) nleep/row_max_std 14.9429 (15.0227) nleep/row_min_mean 1195.8712 (1195.4424) lr 1.5358e-03 eta 1:07:49
epoch [18/50] batch [40/246] time 0.465 (0.489) data 0.000 (0.008) loss 1.9110 (1.7312) teacher_loss 1.2026 (0.9488) loss_zs_kd 0.0461 (0.0432) loss_oracle 0.4869 (0.6253) kd_loss 0.4419 (0.4481) acc 71.8750 (75.5469) gate/entropy 0.9960 (0.9956) gate/usage_max 0.5538 (0.5543) gate/usage_min 0.2110 (0.2112) gate/usage_std 0.1562 (0.1565) teacher/entropy 0.3633 (0.4225) teacher/usage_max 0.7564 (0.6813) teacher/usage_min 0.0497 (0.0590) teacher/usage_std 0.3049 (0.2615) nleep/row_max_mean 1201.0304 (1199.9341) nleep/row_max_std 16.2721 (14.7921) nleep/row_min_mean 1195.7883 (1195.3164) lr 1.5358e-03 eta 1:05:52
epoch [18/50] batch [60/246] time 0.228 (0.414) data 0.000 (0.005) loss 1.6933 (1.6796) teacher_loss 0.8783 (0.9145) loss_zs_kd 0.0401 (0.0442) loss_oracle 0.5500 (0.5916) kd_loss 0.5199 (0.4472) acc 78.1250 (76.8750) gate/entropy 0.9963 (0.9958) gate/usage_max 0.5533 (0.5541) gate/usage_min 0.2108 (0.2111) gate/usage_std 0.1559 (0.1564) teacher/entropy 0.3352 (0.4230) teacher/usage_max 0.6973 (0.6817) teacher/usage_min 0.0407 (0.0589) teacher/usage_std 0.2728 (0.2614) nleep/row_max_mean 1203.0397 (1199.6178) nleep/row_max_std 14.9892 (14.4751) nleep/row_min_mean 1197.5181 (1194.9927) lr 1.5358e-03 eta 0:55:39
epoch [18/50] batch [80/246] time 0.434 (0.384) data 0.000 (0.004) loss 1.8249 (1.6981) teacher_loss 1.0946 (0.9393) loss_zs_kd 0.0405 (0.0435) loss_oracle 0.5038 (0.5838) kd_loss 0.4582 (0.4451) acc 75.0000 (76.4062) gate/entropy 0.9967 (0.9959) gate/usage_max 0.5529 (0.5538) gate/usage_min 0.2106 (0.2110) gate/usage_std 0.1556 (0.1562) teacher/entropy 0.3662 (0.4315) teacher/usage_max 0.7316 (0.6745) teacher/usage_min 0.0303 (0.0615) teacher/usage_std 0.2942 (0.2570) nleep/row_max_mean 1200.6821 (1199.7054) nleep/row_max_std 14.9403 (14.3069) nleep/row_min_mean 1195.9364 (1195.1099) lr 1.5358e-03 eta 0:51:30
epoch [18/50] batch [100/246] time 0.456 (0.376) data 0.000 (0.003) loss 2.0077 (1.6920) teacher_loss 1.1080 (0.9378) loss_zs_kd 0.0524 (0.0428) loss_oracle 0.7231 (0.5784) kd_loss 0.5120 (0.4436) acc 68.7500 (76.1875) gate/entropy 0.9970 (0.9961) gate/usage_max 0.5525 (0.5536) gate/usage_min 0.2104 (0.2109) gate/usage_std 0.1554 (0.1561) teacher/entropy 0.4743 (0.4350) teacher/usage_max 0.5458 (0.6720) teacher/usage_min 0.0699 (0.0606) teacher/usage_std 0.1976 (0.2559) nleep/row_max_mean 1197.6335 (1199.6559) nleep/row_max_std 18.5833 (14.2989) nleep/row_min_mean 1193.5276 (1195.0958) lr 1.5358e-03 eta 0:50:17
epoch [18/50] batch [120/246] time 0.469 (0.394) data 0.000 (0.003) loss 1.8986 (1.7047) teacher_loss 1.1100 (0.9450) loss_zs_kd 0.0575 (0.0437) loss_oracle 0.5721 (0.5779) kd_loss 0.4737 (0.4490) acc 78.1250 (76.0156) gate/entropy 0.9977 (0.9963) gate/usage_max 0.5517 (0.5534) gate/usage_min 0.2102 (0.2108) gate/usage_std 0.1548 (0.1559) teacher/entropy 0.4959 (0.4407) teacher/usage_max 0.5604 (0.6590) teacher/usage_min 0.0436 (0.0625) teacher/usage_std 0.2156 (0.2492) nleep/row_max_mean 1199.3204 (1199.6040) nleep/row_max_std 13.1300 (14.2929) nleep/row_min_mean 1194.8777 (1195.0965) lr 1.5358e-03 eta 0:52:27
epoch [18/50] batch [140/246] time 0.495 (0.409) data 0.000 (0.002) loss 1.3280 (1.6959) teacher_loss 0.5958 (0.9414) loss_zs_kd 0.0393 (0.0440) loss_oracle 0.5860 (0.5725) kd_loss 0.4196 (0.4463) acc 84.3750 (76.0045) gate/entropy 0.9980 (0.9966) gate/usage_max 0.5512 (0.5531) gate/usage_min 0.2099 (0.2107) gate/usage_std 0.1545 (0.1557) teacher/entropy 0.4765 (0.4452) teacher/usage_max 0.6529 (0.6571) teacher/usage_min 0.0768 (0.0644) teacher/usage_std 0.2393 (0.2477) nleep/row_max_mean 1201.1721 (1199.5456) nleep/row_max_std 13.4409 (14.1679) nleep/row_min_mean 1196.9910 (1195.0760) lr 1.5358e-03 eta 0:54:20
epoch [18/50] batch [160/246] time 0.079 (0.414) data 0.000 (0.002) loss 1.0821 (1.6928) teacher_loss 0.4904 (0.9364) loss_zs_kd 0.0325 (0.0436) loss_oracle 0.5089 (0.5803) kd_loss 0.3211 (0.4445) acc 90.6250 (75.9570) gate/entropy 0.9989 (0.9968) gate/usage_max 0.5502 (0.5528) gate/usage_min 0.2097 (0.2106) gate/usage_std 0.1538 (0.1555) teacher/entropy 0.5070 (0.4466) teacher/usage_max 0.7350 (0.6575) teacher/usage_min 0.0788 (0.0645) teacher/usage_std 0.2874 (0.2480) nleep/row_max_mean 1196.1262 (1199.4795) nleep/row_max_std 13.0968 (14.1217) nleep/row_min_mean 1192.4318 (1195.0261) lr 1.5358e-03 eta 0:54:53
epoch [18/50] batch [180/246] time 0.511 (0.393) data 0.000 (0.002) loss 1.4418 (1.6951) teacher_loss 0.5539 (0.9355) loss_zs_kd 0.0219 (0.0432) loss_oracle 0.7915 (0.5866) kd_loss 0.4812 (0.4447) acc 84.3750 (75.8507) gate/entropy 0.9992 (0.9971) gate/usage_max 0.5497 (0.5524) gate/usage_min 0.2094 (0.2105) gate/usage_std 0.1535 (0.1553) teacher/entropy 0.5251 (0.4518) teacher/usage_max 0.5207 (0.6515) teacher/usage_min 0.0874 (0.0658) teacher/usage_std 0.1817 (0.2450) nleep/row_max_mean 1197.2904 (1199.4473) nleep/row_max_std 13.7417 (14.1371) nleep/row_min_mean 1193.2983 (1195.0284) lr 1.5358e-03 eta 0:52:01
epoch [18/50] batch [200/246] time 0.511 (0.390) data 0.000 (0.002) loss 1.7781 (1.7029) teacher_loss 0.9197 (0.9389) loss_zs_kd 0.0410 (0.0435) loss_oracle 0.6689 (0.5901) kd_loss 0.5034 (0.4472) acc 75.0000 (75.5938) gate/entropy 1.0003 (0.9973) gate/usage_max 0.5483 (0.5521) gate/usage_min 0.2092 (0.2104) gate/usage_std 0.1526 (0.1551) teacher/entropy 0.4958 (0.4533) teacher/usage_max 0.5257 (0.6465) teacher/usage_min 0.0736 (0.0668) teacher/usage_std 0.1906 (0.2423) nleep/row_max_mean 1199.3041 (1199.3528) nleep/row_max_std 12.7842 (14.1244) nleep/row_min_mean 1195.2069 (1194.9490) lr 1.5358e-03 eta 0:51:25
epoch [18/50] batch [220/246] time 0.466 (0.389) data 0.000 (0.002) loss 1.4316 (1.7038) teacher_loss 0.6774 (0.9403) loss_zs_kd 0.0260 (0.0435) loss_oracle 0.5669 (0.5870) kd_loss 0.4578 (0.4482) acc 81.2500 (75.5966) gate/entropy 1.0009 (0.9976) gate/usage_max 0.5475 (0.5517) gate/usage_min 0.2088 (0.2102) gate/usage_std 0.1521 (0.1549) teacher/entropy 0.4548 (0.4571) teacher/usage_max 0.6274 (0.6409) teacher/usage_min 0.0569 (0.0681) teacher/usage_std 0.2333 (0.2394) nleep/row_max_mean 1201.9856 (1199.3320) nleep/row_max_std 14.2751 (14.1125) nleep/row_min_mean 1198.0540 (1194.9593) lr 1.5358e-03 eta 0:51:15
epoch [18/50] batch [240/246] time 0.493 (0.395) data 0.000 (0.001) loss 1.4035 (1.7091) teacher_loss 0.6747 (0.9458) loss_zs_kd 0.0492 (0.0438) loss_oracle 0.5472 (0.5864) kd_loss 0.4306 (0.4483) acc 78.1250 (75.4688) gate/entropy 1.0017 (0.9979) gate/usage_max 0.5465 (0.5514) gate/usage_min 0.2085 (0.2101) gate/usage_std 0.1514 (0.1546) teacher/entropy 0.5196 (0.4600) teacher/usage_max 0.5890 (0.6373) teacher/usage_min 0.1005 (0.0701) teacher/usage_std 0.2001 (0.2370) nleep/row_max_mean 1199.9529 (1199.3526) nleep/row_max_std 16.5175 (14.2008) nleep/row_min_mean 1195.8868 (1195.0126) lr 1.5358e-03 eta 0:51:55
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,854
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,960
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.8%
******* Domain r best val acc:      85.2%, epoch: 17 *******
******* Domain r best val test acc: 91.0%, epoch: 17 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [19/50] batch [20/246] time 0.465 (0.255) data 0.000 (0.015) loss 1.5494 (1.6483) teacher_loss 0.6421 (0.8660) loss_zs_kd 0.0539 (0.0398) loss_oracle 0.6799 (0.6177) kd_loss 0.5404 (0.4536) acc 84.3750 (78.4375) gate/entropy 1.0023 (1.0022) gate/usage_max 0.5456 (0.5458) gate/usage_min 0.2079 (0.2081) gate/usage_std 0.1509 (0.1511) teacher/entropy 0.4477 (0.5117) teacher/usage_max 0.5375 (0.5678) teacher/usage_min 0.0847 (0.0914) teacher/usage_std 0.1875 (0.1988) nleep/row_max_mean 1202.1119 (1198.8939) nleep/row_max_std 12.4597 (15.0032) nleep/row_min_mean 1197.8855 (1195.0889) lr 1.4818e-03 eta 0:33:24
epoch [19/50] batch [40/246] time 0.486 (0.305) data 0.000 (0.008) loss 1.7320 (1.6598) teacher_loss 0.7837 (0.8930) loss_zs_kd 0.0465 (0.0436) loss_oracle 0.6593 (0.5757) kd_loss 0.5955 (0.4571) acc 81.2500 (76.3281) gate/entropy 1.0035 (1.0026) gate/usage_max 0.5440 (0.5452) gate/usage_min 0.2076 (0.2079) gate/usage_std 0.1499 (0.1507) teacher/entropy 0.3840 (0.4969) teacher/usage_max 0.5392 (0.5809) teacher/usage_min 0.0490 (0.0860) teacher/usage_std 0.2077 (0.2064) nleep/row_max_mean 1198.6383 (1199.0021) nleep/row_max_std 13.2769 (14.8452) nleep/row_min_mean 1193.9667 (1195.0719) lr 1.4818e-03 eta 0:39:46
epoch [19/50] batch [60/246] time 0.410 (0.323) data 0.000 (0.005) loss 1.6961 (1.6679) teacher_loss 0.8938 (0.9063) loss_zs_kd 0.0217 (0.0448) loss_oracle 0.5400 (0.5688) kd_loss 0.5215 (0.4549) acc 78.1250 (76.6667) gate/entropy 1.0044 (1.0030) gate/usage_max 0.5428 (0.5447) gate/usage_min 0.2071 (0.2077) gate/usage_std 0.1492 (0.1503) teacher/entropy 0.4278 (0.5060) teacher/usage_max 0.5823 (0.5719) teacher/usage_min 0.0744 (0.0875) teacher/usage_std 0.2075 (0.2021) nleep/row_max_mean 1196.9272 (1198.4588) nleep/row_max_std 12.3479 (14.5808) nleep/row_min_mean 1192.4459 (1194.5610) lr 1.4818e-03 eta 0:42:01
epoch [19/50] batch [80/246] time 0.495 (0.359) data 0.000 (0.004) loss 1.9574 (1.6687) teacher_loss 1.1200 (0.9083) loss_zs_kd 0.0692 (0.0456) loss_oracle 0.6454 (0.5628) kd_loss 0.4802 (0.4562) acc 68.7500 (76.7969) gate/entropy 1.0050 (1.0034) gate/usage_max 0.5419 (0.5441) gate/usage_min 0.2066 (0.2075) gate/usage_std 0.1486 (0.1499) teacher/entropy 0.5009 (0.5024) teacher/usage_max 0.5390 (0.5739) teacher/usage_min 0.0724 (0.0855) teacher/usage_std 0.1945 (0.2034) nleep/row_max_mean 1197.9807 (1198.2019) nleep/row_max_std 14.1438 (14.3402) nleep/row_min_mean 1194.0338 (1194.2547) lr 1.4818e-03 eta 0:46:34
epoch [19/50] batch [100/246] time 0.412 (0.382) data 0.000 (0.003) loss 1.7801 (1.6881) teacher_loss 0.9616 (0.9188) loss_zs_kd 0.0505 (0.0460) loss_oracle 0.6096 (0.5728) kd_loss 0.4884 (0.4599) acc 75.0000 (76.5625) gate/entropy 1.0064 (1.0039) gate/usage_max 0.5399 (0.5434) gate/usage_min 0.2062 (0.2073) gate/usage_std 0.1474 (0.1496) teacher/entropy 0.4881 (0.5039) teacher/usage_max 0.5474 (0.5669) teacher/usage_min 0.0878 (0.0862) teacher/usage_std 0.1890 (0.2007) nleep/row_max_mean 1199.8096 (1198.2175) nleep/row_max_std 15.9107 (14.4246) nleep/row_min_mean 1195.6367 (1194.2565) lr 1.4818e-03 eta 0:49:27
epoch [19/50] batch [120/246] time 0.079 (0.388) data 0.000 (0.003) loss 1.7106 (1.7025) teacher_loss 0.8759 (0.9270) loss_zs_kd 0.0479 (0.0469) loss_oracle 0.6031 (0.5765) kd_loss 0.5092 (0.4638) acc 81.2500 (76.3802) gate/entropy 1.0075 (1.0044) gate/usage_max 0.5383 (0.5427) gate/usage_min 0.2055 (0.2070) gate/usage_std 0.1464 (0.1491) teacher/entropy 0.4913 (0.5071) teacher/usage_max 0.5028 (0.5588) teacher/usage_min 0.0525 (0.0863) teacher/usage_std 0.2000 (0.1980) nleep/row_max_mean 1198.1250 (1198.0376) nleep/row_max_std 12.3152 (14.3840) nleep/row_min_mean 1193.9729 (1194.0727) lr 1.4818e-03 eta 0:50:04
epoch [19/50] batch [140/246] time 0.406 (0.366) data 0.000 (0.002) loss 1.6232 (1.7259) teacher_loss 0.7891 (0.9468) loss_zs_kd 0.0356 (0.0466) loss_oracle 0.6210 (0.5735) kd_loss 0.5058 (0.4690) acc 87.5000 (75.8929) gate/entropy 1.0087 (1.0049) gate/usage_max 0.5363 (0.5420) gate/usage_min 0.2048 (0.2068) gate/usage_std 0.1452 (0.1487) teacher/entropy 0.5391 (0.5044) teacher/usage_max 0.4576 (0.5556) teacher/usage_min 0.0920 (0.0852) teacher/usage_std 0.1707 (0.1975) nleep/row_max_mean 1195.9451 (1198.0320) nleep/row_max_std 15.8745 (14.3401) nleep/row_min_mean 1192.3413 (1194.0357) lr 1.4818e-03 eta 0:47:09
epoch [19/50] batch [160/246] time 0.406 (0.359) data 0.000 (0.002) loss 1.5883 (1.7239) teacher_loss 0.8219 (0.9446) loss_zs_kd 0.0364 (0.0459) loss_oracle 0.5795 (0.5732) kd_loss 0.4585 (0.4698) acc 78.1250 (75.9180) gate/entropy 1.0102 (1.0055) gate/usage_max 0.5341 (0.5411) gate/usage_min 0.2041 (0.2065) gate/usage_std 0.1439 (0.1482) teacher/entropy 0.4983 (0.5055) teacher/usage_max 0.5588 (0.5538) teacher/usage_min 0.0581 (0.0846) teacher/usage_std 0.2074 (0.1972) nleep/row_max_mean 1201.8257 (1198.0433) nleep/row_max_std 14.3146 (14.3026) nleep/row_min_mean 1197.4253 (1194.0458) lr 1.4818e-03 eta 0:46:10
epoch [19/50] batch [180/246] time 0.416 (0.362) data 0.000 (0.002) loss 1.8881 (1.7341) teacher_loss 0.8984 (0.9486) loss_zs_kd 0.0636 (0.0458) loss_oracle 0.6327 (0.5765) kd_loss 0.6416 (0.4743) acc 84.3750 (75.8507) gate/entropy 1.0115 (1.0060) gate/usage_max 0.5319 (0.5402) gate/usage_min 0.2033 (0.2062) gate/usage_std 0.1426 (0.1476) teacher/entropy 0.3958 (0.5047) teacher/usage_max 0.4855 (0.5493) teacher/usage_min 0.0702 (0.0842) teacher/usage_std 0.1868 (0.1960) nleep/row_max_mean 1198.8505 (1198.1053) nleep/row_max_std 13.0646 (14.3606) nleep/row_min_mean 1194.1392 (1194.1036) lr 1.4818e-03 eta 0:46:21
epoch [19/50] batch [200/246] time 0.497 (0.373) data 0.000 (0.002) loss 1.9945 (1.7430) teacher_loss 1.0345 (0.9509) loss_zs_kd 0.0356 (0.0451) loss_oracle 0.6843 (0.5825) kd_loss 0.6001 (0.4783) acc 75.0000 (75.7656) gate/entropy 1.0131 (1.0067) gate/usage_max 0.5291 (0.5393) gate/usage_min 0.2023 (0.2058) gate/usage_std 0.1411 (0.1471) teacher/entropy 0.4244 (0.5037) teacher/usage_max 0.4744 (0.5466) teacher/usage_min 0.0684 (0.0833) teacher/usage_std 0.1875 (0.1956) nleep/row_max_mean 1202.0669 (1198.1117) nleep/row_max_std 17.3500 (14.4392) nleep/row_min_mean 1197.5691 (1194.0904) lr 1.4818e-03 eta 0:47:41
epoch [19/50] batch [220/246] time 0.473 (0.383) data 0.000 (0.002) loss 1.5053 (1.7570) teacher_loss 0.6558 (0.9598) loss_zs_kd 0.0333 (0.0452) loss_oracle 0.6181 (0.5876) kd_loss 0.5238 (0.4807) acc 84.3750 (75.4119) gate/entropy 1.0146 (1.0073) gate/usage_max 0.5264 (0.5382) gate/usage_min 0.2010 (0.2054) gate/usage_std 0.1396 (0.1464) teacher/entropy 0.4928 (0.5042) teacher/usage_max 0.4727 (0.5439) teacher/usage_min 0.0918 (0.0829) teacher/usage_std 0.1714 (0.1950) nleep/row_max_mean 1194.8040 (1198.1599) nleep/row_max_std 14.9929 (14.5027) nleep/row_min_mean 1190.6927 (1194.1378) lr 1.4818e-03 eta 0:48:51
epoch [19/50] batch [240/246] time 0.086 (0.378) data 0.000 (0.001) loss 1.7138 (1.7568) teacher_loss 0.8834 (0.9602) loss_zs_kd 0.0742 (0.0456) loss_oracle 0.5630 (0.5837) kd_loss 0.5118 (0.4819) acc 75.0000 (75.4297) gate/entropy 1.0165 (1.0080) gate/usage_max 0.5229 (0.5371) gate/usage_min 0.1999 (0.2050) gate/usage_std 0.1377 (0.1458) teacher/entropy 0.5220 (0.5048) teacher/usage_max 0.4922 (0.5403) teacher/usage_min 0.0759 (0.0823) teacher/usage_std 0.1837 (0.1943) nleep/row_max_mean 1192.3470 (1198.0771) nleep/row_max_std 13.4552 (14.5531) nleep/row_min_mean 1188.3337 (1194.0499) lr 1.4818e-03 eta 0:48:07
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,856
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,958
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.2%, epoch: 17 *******
******* Domain r best val test acc: 91.0%, epoch: 17 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [20/50] batch [20/246] time 0.465 (0.412) data 0.000 (0.015) loss 1.8085 (1.7803) teacher_loss 0.9838 (0.9503) loss_zs_kd 0.0782 (0.0515) loss_oracle 0.6071 (0.5932) kd_loss 0.4821 (0.5077) acc 75.0000 (76.7188) gate/entropy 1.0186 (1.0178) gate/usage_max 0.5186 (0.5203) gate/usage_min 0.1982 (0.1989) gate/usage_std 0.1355 (0.1364) teacher/entropy 0.5692 (0.5170) teacher/usage_max 0.4396 (0.5019) teacher/usage_min 0.1335 (0.0924) teacher/usage_std 0.1414 (0.1773) nleep/row_max_mean 1196.3164 (1196.3578) nleep/row_max_std 14.1222 (14.0267) nleep/row_min_mean 1192.5608 (1192.2281) lr 1.4258e-03 eta 0:52:10
epoch [20/50] batch [40/246] time 0.442 (0.446) data 0.000 (0.008) loss 1.6857 (1.7671) teacher_loss 0.8186 (0.9354) loss_zs_kd 0.0747 (0.0502) loss_oracle 0.6310 (0.6019) kd_loss 0.5143 (0.5056) acc 78.1250 (76.1719) gate/entropy 1.0202 (1.0186) gate/usage_max 0.5150 (0.5185) gate/usage_min 0.1969 (0.1982) gate/usage_std 0.1338 (0.1355) teacher/entropy 0.5086 (0.5202) teacher/usage_max 0.4748 (0.5016) teacher/usage_min 0.0869 (0.0962) teacher/usage_std 0.1749 (0.1752) nleep/row_max_mean 1197.9004 (1196.9718) nleep/row_max_std 15.6834 (13.9624) nleep/row_min_mean 1194.1315 (1192.9704) lr 1.4258e-03 eta 0:56:24
epoch [20/50] batch [60/246] time 0.464 (0.456) data 0.001 (0.005) loss 1.8044 (1.7941) teacher_loss 1.0156 (0.9565) loss_zs_kd 0.0679 (0.0488) loss_oracle 0.5458 (0.6085) kd_loss 0.4820 (0.5089) acc 78.1250 (75.5729) gate/entropy 1.0220 (1.0195) gate/usage_max 0.5107 (0.5166) gate/usage_min 0.1953 (0.1975) gate/usage_std 0.1317 (0.1345) teacher/entropy 0.5748 (0.5195) teacher/usage_max 0.4959 (0.5048) teacher/usage_min 0.1154 (0.0941) teacher/usage_std 0.1602 (0.1770) nleep/row_max_mean 1196.3440 (1196.8052) nleep/row_max_std 13.6710 (13.6931) nleep/row_min_mean 1192.7612 (1192.8127) lr 1.4258e-03 eta 0:57:33
epoch [20/50] batch [80/246] time 0.489 (0.416) data 0.000 (0.004) loss 1.5023 (1.7868) teacher_loss 0.7491 (0.9626) loss_zs_kd 0.0400 (0.0479) loss_oracle 0.4992 (0.5903) kd_loss 0.4836 (0.5051) acc 87.5000 (75.7812) gate/entropy 1.0236 (1.0203) gate/usage_max 0.5064 (0.5146) gate/usage_min 0.1936 (0.1967) gate/usage_std 0.1298 (0.1336) teacher/entropy 0.4884 (0.5211) teacher/usage_max 0.5099 (0.5043) teacher/usage_min 0.0802 (0.0911) teacher/usage_std 0.1836 (0.1787) nleep/row_max_mean 1195.9255 (1196.6855) nleep/row_max_std 17.8304 (13.6514) nleep/row_min_mean 1191.7799 (1192.7100) lr 1.4258e-03 eta 0:52:22
epoch [20/50] batch [100/246] time 0.083 (0.393) data 0.000 (0.003) loss 1.2359 (1.7907) teacher_loss 0.5283 (0.9682) loss_zs_kd 0.0523 (0.0475) loss_oracle 0.4901 (0.5855) kd_loss 0.4365 (0.5059) acc 90.6250 (75.5938) gate/entropy 1.0251 (1.0212) gate/usage_max 0.5022 (0.5125) gate/usage_min 0.1921 (0.1959) gate/usage_std 0.1281 (0.1327) teacher/entropy 0.6122 (0.5200) teacher/usage_max 0.4536 (0.5056) teacher/usage_min 0.1403 (0.0919) teacher/usage_std 0.1379 (0.1786) nleep/row_max_mean 1199.7853 (1196.6587) nleep/row_max_std 12.9268 (13.8341) nleep/row_min_mean 1196.5149 (1192.6813) lr 1.4258e-03 eta 0:49:17
epoch [20/50] batch [120/246] time 0.082 (0.384) data 0.000 (0.003) loss 1.7550 (1.7730) teacher_loss 0.9188 (0.9516) loss_zs_kd 0.0579 (0.0479) loss_oracle 0.5879 (0.5799) kd_loss 0.5133 (0.5075) acc 75.0000 (76.0417) gate/entropy 1.0264 (1.0219) gate/usage_max 0.4979 (0.5104) gate/usage_min 0.1904 (0.1951) gate/usage_std 0.1265 (0.1318) teacher/entropy 0.5268 (0.5171) teacher/usage_max 0.5755 (0.5079) teacher/usage_min 0.0765 (0.0903) teacher/usage_std 0.2040 (0.1802) nleep/row_max_mean 1194.7288 (1196.8445) nleep/row_max_std 15.9080 (13.9996) nleep/row_min_mean 1190.8694 (1192.8541) lr 1.4258e-03 eta 0:48:05
epoch [20/50] batch [140/246] time 0.498 (0.396) data 0.000 (0.002) loss 1.8710 (1.7681) teacher_loss 1.0066 (0.9456) loss_zs_kd 0.0472 (0.0480) loss_oracle 0.6154 (0.5771) kd_loss 0.5331 (0.5099) acc 81.2500 (76.2946) gate/entropy 1.0274 (1.0226) gate/usage_max 0.4933 (0.5083) gate/usage_min 0.1884 (0.1943) gate/usage_std 0.1250 (0.1309) teacher/entropy 0.5117 (0.5143) teacher/usage_max 0.5718 (0.5110) teacher/usage_min 0.0914 (0.0898) teacher/usage_std 0.1962 (0.1811) nleep/row_max_mean 1195.8928 (1196.8556) nleep/row_max_std 15.9858 (14.1696) nleep/row_min_mean 1191.8818 (1192.8504) lr 1.4258e-03 eta 0:49:24
epoch [20/50] batch [160/246] time 0.514 (0.408) data 0.000 (0.002) loss 1.1896 (1.7650) teacher_loss 0.4916 (0.9425) loss_zs_kd 0.0196 (0.0478) loss_oracle 0.5448 (0.5779) kd_loss 0.4158 (0.5097) acc 90.6250 (76.3867) gate/entropy 1.0285 (1.0233) gate/usage_max 0.4888 (0.5061) gate/usage_min 0.1868 (0.1935) gate/usage_std 0.1234 (0.1300) teacher/entropy 0.5595 (0.5122) teacher/usage_max 0.5323 (0.5125) teacher/usage_min 0.0430 (0.0887) teacher/usage_std 0.2100 (0.1820) nleep/row_max_mean 1200.0261 (1196.9569) nleep/row_max_std 13.4276 (14.2509) nleep/row_min_mean 1196.2126 (1192.9362) lr 1.4258e-03 eta 0:50:47
epoch [20/50] batch [180/246] time 0.427 (0.418) data 0.000 (0.002) loss 1.5459 (1.7475) teacher_loss 0.7732 (0.9284) loss_zs_kd 0.0429 (0.0474) loss_oracle 0.5348 (0.5752) kd_loss 0.4839 (0.5078) acc 84.3750 (76.6667) gate/entropy 1.0293 (1.0239) gate/usage_max 0.4837 (0.5039) gate/usage_min 0.1846 (0.1926) gate/usage_std 0.1221 (0.1292) teacher/entropy 0.5128 (0.5129) teacher/usage_max 0.5469 (0.5148) teacher/usage_min 0.0669 (0.0883) teacher/usage_std 0.1995 (0.1828) nleep/row_max_mean 1200.8171 (1197.0690) nleep/row_max_std 15.4168 (14.3467) nleep/row_min_mean 1196.8069 (1193.0599) lr 1.4258e-03 eta 0:51:51
epoch [20/50] batch [200/246] time 0.463 (0.396) data 0.000 (0.002) loss 1.7485 (1.7510) teacher_loss 0.7866 (0.9311) loss_zs_kd 0.0784 (0.0477) loss_oracle 0.6387 (0.5749) kd_loss 0.6033 (0.5086) acc 75.0000 (76.7812) gate/entropy 1.0299 (1.0245) gate/usage_max 0.4792 (0.5016) gate/usage_min 0.1830 (0.1917) gate/usage_std 0.1210 (0.1285) teacher/entropy 0.3924 (0.5109) teacher/usage_max 0.5736 (0.5179) teacher/usage_min 0.0622 (0.0881) teacher/usage_std 0.2099 (0.1839) nleep/row_max_mean 1197.3706 (1197.0955) nleep/row_max_std 15.6941 (14.4682) nleep/row_min_mean 1192.4691 (1193.0716) lr 1.4258e-03 eta 0:49:00
epoch [20/50] batch [220/246] time 0.484 (0.388) data 0.000 (0.002) loss 2.1897 (1.7510) teacher_loss 1.2662 (0.9296) loss_zs_kd 0.0636 (0.0481) loss_oracle 0.5890 (0.5743) kd_loss 0.5971 (0.5102) acc 68.7500 (76.5199) gate/entropy 1.0303 (1.0250) gate/usage_max 0.4747 (0.4994) gate/usage_min 0.1811 (0.1908) gate/usage_std 0.1201 (0.1277) teacher/entropy 0.4181 (0.5083) teacher/usage_max 0.5182 (0.5209) teacher/usage_min 0.1086 (0.0880) teacher/usage_std 0.1696 (0.1848) nleep/row_max_mean 1196.8264 (1197.2183) nleep/row_max_std 15.0023 (14.4265) nleep/row_min_mean 1192.4589 (1193.1755) lr 1.4258e-03 eta 0:47:53
epoch [20/50] batch [240/246] time 0.472 (0.385) data 0.000 (0.001) loss 1.9514 (1.7539) teacher_loss 1.0533 (0.9334) loss_zs_kd 0.0511 (0.0485) loss_oracle 0.6085 (0.5718) kd_loss 0.5684 (0.5103) acc 71.8750 (76.5104) gate/entropy 1.0304 (1.0254) gate/usage_max 0.4705 (0.4971) gate/usage_min 0.1794 (0.1899) gate/usage_std 0.1194 (0.1271) teacher/entropy 0.4780 (0.5063) teacher/usage_max 0.5582 (0.5226) teacher/usage_min 0.1319 (0.0876) teacher/usage_std 0.1748 (0.1854) nleep/row_max_mean 1195.8015 (1197.3360) nleep/row_max_std 14.0822 (14.4377) nleep/row_min_mean 1191.5868 (1193.2896) lr 1.4258e-03 eta 0:47:23
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,845
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,947
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.5%
******* Domain r best val acc:      85.2%, epoch: 17 *******
******* Domain r best val test acc: 91.0%, epoch: 17 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [21/50] batch [20/246] time 0.529 (0.519) data 0.000 (0.013) loss 1.2341 (1.7506) teacher_loss 0.4255 (0.9194) loss_zs_kd 0.0320 (0.0534) loss_oracle 0.5700 (0.5717) kd_loss 0.5076 (0.5186) acc 93.7500 (76.5625) gate/entropy 1.0305 (1.0304) gate/usage_max 0.4659 (0.4675) gate/usage_min 0.1777 (0.1782) gate/usage_std 0.1188 (0.1190) teacher/entropy 0.4802 (0.4849) teacher/usage_max 0.5291 (0.5744) teacher/usage_min 0.0851 (0.0889) teacher/usage_std 0.1850 (0.2034) nleep/row_max_mean 1201.1174 (1198.8508) nleep/row_max_std 16.2854 (15.4839) nleep/row_min_mean 1196.9542 (1194.7386) lr 1.3681e-03 eta 1:03:41
epoch [21/50] batch [40/246] time 0.086 (0.410) data 0.000 (0.007) loss 1.5671 (1.7724) teacher_loss 0.7548 (0.9378) loss_zs_kd 0.0468 (0.0500) loss_oracle 0.5295 (0.5938) kd_loss 0.5242 (0.5127) acc 75.0000 (76.2500) gate/entropy 1.0304 (1.0304) gate/usage_max 0.4620 (0.4656) gate/usage_min 0.1760 (0.1774) gate/usage_std 0.1185 (0.1188) teacher/entropy 0.4605 (0.4968) teacher/usage_max 0.5435 (0.5825) teacher/usage_min 0.0838 (0.0947) teacher/usage_std 0.1898 (0.2031) nleep/row_max_mean 1196.0398 (1197.9009) nleep/row_max_std 17.5433 (15.0040) nleep/row_min_mean 1191.5332 (1193.8571) lr 1.3681e-03 eta 0:50:07
epoch [21/50] batch [60/246] time 0.451 (0.380) data 0.001 (0.005) loss 1.7018 (1.7759) teacher_loss 0.8854 (0.9423) loss_zs_kd 0.0484 (0.0515) loss_oracle 0.5655 (0.5889) kd_loss 0.5094 (0.5134) acc 78.1250 (75.7292) gate/entropy 1.0301 (1.0303) gate/usage_max 0.4583 (0.4637) gate/usage_min 0.1745 (0.1767) gate/usage_std 0.1183 (0.1187) teacher/entropy 0.4905 (0.5012) teacher/usage_max 0.5992 (0.5837) teacher/usage_min 0.0907 (0.1020) teacher/usage_std 0.2082 (0.2011) nleep/row_max_mean 1197.8197 (1197.8369) nleep/row_max_std 20.4018 (15.1942) nleep/row_min_mean 1193.4713 (1193.8379) lr 1.3681e-03 eta 0:46:20
epoch [21/50] batch [80/246] time 0.480 (0.372) data 0.000 (0.004) loss 1.8187 (1.7581) teacher_loss 1.1543 (0.9284) loss_zs_kd 0.0477 (0.0513) loss_oracle 0.4220 (0.5768) kd_loss 0.4296 (0.5156) acc 78.1250 (76.7188) gate/entropy 1.0297 (1.0302) gate/usage_max 0.4551 (0.4620) gate/usage_min 0.1730 (0.1760) gate/usage_std 0.1183 (0.1186) teacher/entropy 0.5943 (0.5003) teacher/usage_max 0.5655 (0.5814) teacher/usage_min 0.1268 (0.1061) teacher/usage_std 0.1801 (0.1985) nleep/row_max_mean 1196.8218 (1198.1010) nleep/row_max_std 15.9217 (15.0940) nleep/row_min_mean 1193.5137 (1194.1024) lr 1.3681e-03 eta 0:45:18
epoch [21/50] batch [100/246] time 0.454 (0.396) data 0.000 (0.003) loss 1.7670 (1.7607) teacher_loss 1.0115 (0.9353) loss_zs_kd 0.0417 (0.0501) loss_oracle 0.5264 (0.5734) kd_loss 0.4714 (0.5137) acc 68.7500 (76.5312) gate/entropy 1.0295 (1.0301) gate/usage_max 0.4527 (0.4603) gate/usage_min 0.1722 (0.1753) gate/usage_std 0.1183 (0.1185) teacher/entropy 0.5436 (0.5032) teacher/usage_max 0.5597 (0.5820) teacher/usage_min 0.1212 (0.1092) teacher/usage_std 0.1793 (0.1980) nleep/row_max_mean 1196.9531 (1197.8879) nleep/row_max_std 12.9681 (14.8934) nleep/row_min_mean 1193.2725 (1193.9126) lr 1.3681e-03 eta 0:48:05
epoch [21/50] batch [120/246] time 0.478 (0.409) data 0.000 (0.002) loss 1.3280 (1.7651) teacher_loss 0.6492 (0.9460) loss_zs_kd 0.0494 (0.0501) loss_oracle 0.4442 (0.5656) kd_loss 0.4320 (0.5113) acc 84.3750 (76.1458) gate/entropy 1.0292 (1.0300) gate/usage_max 0.4504 (0.4589) gate/usage_min 0.1713 (0.1747) gate/usage_std 0.1183 (0.1185) teacher/entropy 0.5651 (0.5031) teacher/usage_max 0.5616 (0.5820) teacher/usage_min 0.1056 (0.1086) teacher/usage_std 0.1862 (0.1982) nleep/row_max_mean 1197.7402 (1197.7786) nleep/row_max_std 13.1398 (14.6619) nleep/row_min_mean 1194.3258 (1193.8107) lr 1.3681e-03 eta 0:49:28
epoch [21/50] batch [140/246] time 0.078 (0.415) data 0.000 (0.002) loss 1.5646 (1.7610) teacher_loss 0.8172 (0.9453) loss_zs_kd 0.0317 (0.0494) loss_oracle 0.4985 (0.5625) kd_loss 0.4823 (0.5098) acc 81.2500 (76.0491) gate/entropy 1.0289 (1.0298) gate/usage_max 0.4484 (0.4575) gate/usage_min 0.1704 (0.1741) gate/usage_std 0.1184 (0.1185) teacher/entropy 0.4633 (0.5045) teacher/usage_max 0.5224 (0.5805) teacher/usage_min 0.0606 (0.1104) teacher/usage_std 0.1976 (0.1969) nleep/row_max_mean 1198.8524 (1197.5723) nleep/row_max_std 13.3280 (14.4068) nleep/row_min_mean 1194.6298 (1193.6249) lr 1.3681e-03 eta 0:50:05
epoch [21/50] batch [160/246] time 0.463 (0.388) data 0.000 (0.002) loss 1.4711 (1.7538) teacher_loss 0.5446 (0.9420) loss_zs_kd 0.0590 (0.0494) loss_oracle 0.5958 (0.5610) kd_loss 0.5991 (0.5067) acc 81.2500 (76.0352) gate/entropy 1.0285 (1.0297) gate/usage_max 0.4464 (0.4562) gate/usage_min 0.1696 (0.1736) gate/usage_std 0.1185 (0.1185) teacher/entropy 0.3953 (0.5058) teacher/usage_max 0.6527 (0.5813) teacher/usage_min 0.0925 (0.1101) teacher/usage_std 0.2353 (0.1972) nleep/row_max_mean 1195.1936 (1197.6119) nleep/row_max_std 11.4656 (14.1980) nleep/row_min_mean 1190.4799 (1193.6755) lr 1.3681e-03 eta 0:46:38
epoch [21/50] batch [180/246] time 0.428 (0.380) data 0.000 (0.002) loss 2.1144 (1.7749) teacher_loss 1.1557 (0.9585) loss_zs_kd 0.0577 (0.0502) loss_oracle 0.5792 (0.5624) kd_loss 0.6403 (0.5102) acc 78.1250 (75.6424) gate/entropy 1.0281 (1.0295) gate/usage_max 0.4444 (0.4550) gate/usage_min 0.1688 (0.1731) gate/usage_std 0.1187 (0.1185) teacher/entropy 0.3202 (0.5014) teacher/usage_max 0.7023 (0.5873) teacher/usage_min 0.0539 (0.1099) teacher/usage_std 0.2722 (0.2003) nleep/row_max_mean 1197.2509 (1197.6543) nleep/row_max_std 15.0608 (14.1300) nleep/row_min_mean 1192.4679 (1193.6926) lr 1.3681e-03 eta 0:45:32
epoch [21/50] batch [200/246] time 0.509 (0.379) data 0.000 (0.002) loss 1.9240 (1.7757) teacher_loss 1.0756 (0.9590) loss_zs_kd 0.0549 (0.0502) loss_oracle 0.5522 (0.5590) kd_loss 0.5450 (0.5121) acc 71.8750 (75.6719) gate/entropy 1.0277 (1.0294) gate/usage_max 0.4426 (0.4538) gate/usage_min 0.1681 (0.1726) gate/usage_std 0.1189 (0.1185) teacher/entropy 0.4548 (0.4972) teacher/usage_max 0.6986 (0.5929) teacher/usage_min 0.0984 (0.1082) teacher/usage_std 0.2618 (0.2035) nleep/row_max_mean 1199.3536 (1197.6652) nleep/row_max_std 17.8122 (14.1427) nleep/row_min_mean 1194.7484 (1193.6652) lr 1.3681e-03 eta 0:45:19
epoch [21/50] batch [220/246] time 0.478 (0.388) data 0.000 (0.001) loss 1.5661 (1.7852) teacher_loss 0.7501 (0.9629) loss_zs_kd 0.0692 (0.0508) loss_oracle 0.5151 (0.5608) kd_loss 0.5239 (0.5166) acc 78.1250 (75.5540) gate/entropy 1.0273 (1.0292) gate/usage_max 0.4408 (0.4527) gate/usage_min 0.1673 (0.1722) gate/usage_std 0.1191 (0.1186) teacher/entropy 0.4605 (0.4919) teacher/usage_max 0.5926 (0.5992) teacher/usage_min 0.0991 (0.1080) teacher/usage_std 0.2022 (0.2069) nleep/row_max_mean 1198.1587 (1197.6868) nleep/row_max_std 15.1077 (14.1000) nleep/row_min_mean 1193.8201 (1193.6529) lr 1.3681e-03 eta 0:46:21
epoch [21/50] batch [240/246] time 0.466 (0.395) data 0.000 (0.001) loss 1.8377 (1.7889) teacher_loss 1.0146 (0.9635) loss_zs_kd 0.0471 (0.0510) loss_oracle 0.6129 (0.5640) kd_loss 0.4931 (0.5179) acc 68.7500 (75.5208) gate/entropy 1.0268 (1.0290) gate/usage_max 0.4391 (0.4516) gate/usage_min 0.1665 (0.1717) gate/usage_std 0.1194 (0.1186) teacher/entropy 0.5337 (0.4902) teacher/usage_max 0.6754 (0.6051) teacher/usage_min 0.1356 (0.1083) teacher/usage_std 0.2428 (0.2099) nleep/row_max_mean 1196.0095 (1197.6011) nleep/row_max_std 11.8049 (14.0725) nleep/row_min_mean 1192.3110 (1193.5616) lr 1.3681e-03 eta 0:47:00
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,859
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,949
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      85.2%, epoch: 17 *******
******* Domain r best val test acc: 91.0%, epoch: 17 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [22/50] batch [20/246] time 0.435 (0.305) data 0.000 (0.014) loss 1.4316 (1.7739) teacher_loss 0.6415 (0.9194) loss_zs_kd 0.0305 (0.0537) loss_oracle 0.6005 (0.6263) kd_loss 0.4745 (0.5145) acc 90.6250 (77.0312) gate/entropy 1.0264 (1.0265) gate/usage_max 0.4373 (0.4379) gate/usage_min 0.1658 (0.1660) gate/usage_std 0.1196 (0.1195) teacher/entropy 0.5197 (0.4785) teacher/usage_max 0.6325 (0.6440) teacher/usage_min 0.1084 (0.1055) teacher/usage_std 0.2203 (0.2296) nleep/row_max_mean 1197.3926 (1197.9662) nleep/row_max_std 14.2216 (12.9490) nleep/row_min_mean 1193.5317 (1193.7317) lr 1.3090e-03 eta 0:36:08
epoch [22/50] batch [40/246] time 0.527 (0.338) data 0.000 (0.007) loss 1.9837 (1.8619) teacher_loss 1.0888 (0.9974) loss_zs_kd 0.0674 (0.0546) loss_oracle 0.6104 (0.6130) kd_loss 0.5560 (0.5308) acc 75.0000 (74.3750) gate/entropy 1.0260 (1.0264) gate/usage_max 0.4359 (0.4372) gate/usage_min 0.1652 (0.1657) gate/usage_std 0.1198 (0.1196) teacher/entropy 0.4531 (0.4590) teacher/usage_max 0.6845 (0.6619) teacher/usage_min 0.1212 (0.1018) teacher/usage_std 0.2501 (0.2408) nleep/row_max_mean 1198.0594 (1198.0579) nleep/row_max_std 13.2971 (13.9702) nleep/row_min_mean 1193.6403 (1193.7264) lr 1.3090e-03 eta 0:40:00
epoch [22/50] batch [60/246] time 0.519 (0.396) data 0.001 (0.005) loss 1.7667 (1.8709) teacher_loss 0.8633 (0.9907) loss_zs_kd 0.0443 (0.0542) loss_oracle 0.6691 (0.6285) kd_loss 0.5467 (0.5388) acc 81.2500 (74.0625) gate/entropy 1.0256 (1.0262) gate/usage_max 0.4346 (0.4365) gate/usage_min 0.1647 (0.1654) gate/usage_std 0.1201 (0.1198) teacher/entropy 0.4112 (0.4477) teacher/usage_max 0.6964 (0.6811) teacher/usage_min 0.0700 (0.0976) teacher/usage_std 0.2652 (0.2531) nleep/row_max_mean 1200.7582 (1198.0079) nleep/row_max_std 15.3958 (14.1849) nleep/row_min_mean 1195.9114 (1193.5994) lr 1.3090e-03 eta 0:46:37
epoch [22/50] batch [80/246] time 0.524 (0.422) data 0.000 (0.004) loss 2.2654 (1.8665) teacher_loss 1.2357 (0.9728) loss_zs_kd 0.0715 (0.0540) loss_oracle 0.7166 (0.6366) kd_loss 0.6356 (0.5484) acc 59.3750 (74.4922) gate/entropy 1.0251 (1.0260) gate/usage_max 0.4333 (0.4359) gate/usage_min 0.1640 (0.1652) gate/usage_std 0.1204 (0.1199) teacher/entropy 0.3193 (0.4347) teacher/usage_max 0.8333 (0.6939) teacher/usage_min 0.0595 (0.0941) teacher/usage_std 0.3540 (0.2614) nleep/row_max_mean 1198.1816 (1198.0873) nleep/row_max_std 11.9555 (14.1361) nleep/row_min_mean 1193.0020 (1193.5969) lr 1.3090e-03 eta 0:49:38
epoch [22/50] batch [100/246] time 0.360 (0.394) data 0.000 (0.003) loss 1.5006 (1.8616) teacher_loss 0.6356 (0.9597) loss_zs_kd 0.0444 (0.0527) loss_oracle 0.6635 (0.6450) kd_loss 0.5110 (0.5530) acc 84.3750 (74.9062) gate/entropy 1.0249 (1.0258) gate/usage_max 0.4323 (0.4353) gate/usage_min 0.1637 (0.1649) gate/usage_std 0.1205 (0.1200) teacher/entropy 0.4608 (0.4268) teacher/usage_max 0.7121 (0.7045) teacher/usage_min 0.0876 (0.0910) teacher/usage_std 0.2718 (0.2684) nleep/row_max_mean 1197.0293 (1198.1561) nleep/row_max_std 13.3657 (13.9758) nleep/row_min_mean 1192.8129 (1193.6278) lr 1.3090e-03 eta 0:46:10
epoch [22/50] batch [120/246] time 0.084 (0.382) data 0.000 (0.002) loss 1.7216 (1.8627) teacher_loss 0.8817 (0.9513) loss_zs_kd 0.0465 (0.0512) loss_oracle 0.6106 (0.6510) kd_loss 0.5114 (0.5603) acc 71.8750 (75.2083) gate/entropy 1.0247 (1.0256) gate/usage_max 0.4314 (0.4347) gate/usage_min 0.1633 (0.1646) gate/usage_std 0.1207 (0.1201) teacher/entropy 0.4778 (0.4178) teacher/usage_max 0.6643 (0.7127) teacher/usage_min 0.1105 (0.0899) teacher/usage_std 0.2387 (0.2736) nleep/row_max_mean 1193.6360 (1198.1611) nleep/row_max_std 10.8500 (14.0530) nleep/row_min_mean 1189.3901 (1193.5737) lr 1.3090e-03 eta 0:44:41
epoch [22/50] batch [140/246] time 0.079 (0.377) data 0.000 (0.002) loss 1.9134 (1.8753) teacher_loss 0.8421 (0.9555) loss_zs_kd 0.0556 (0.0514) loss_oracle 0.7561 (0.6580) kd_loss 0.6655 (0.5651) acc 78.1250 (75.2902) gate/entropy 1.0243 (1.0254) gate/usage_max 0.4304 (0.4341) gate/usage_min 0.1629 (0.1644) gate/usage_std 0.1209 (0.1202) teacher/entropy 0.3073 (0.4120) teacher/usage_max 0.7909 (0.7196) teacher/usage_min 0.0876 (0.0891) teacher/usage_std 0.3238 (0.2779) nleep/row_max_mean 1196.2185 (1198.2017) nleep/row_max_std 11.8465 (13.9988) nleep/row_min_mean 1191.0098 (1193.5729) lr 1.3090e-03 eta 0:43:53
epoch [22/50] batch [160/246] time 0.468 (0.387) data 0.000 (0.002) loss 1.6659 (1.8828) teacher_loss 0.7346 (0.9559) loss_zs_kd 0.0128 (0.0503) loss_oracle 0.6555 (0.6615) kd_loss 0.5971 (0.5710) acc 75.0000 (75.3516) gate/entropy 1.0240 (1.0253) gate/usage_max 0.4296 (0.4336) gate/usage_min 0.1625 (0.1642) gate/usage_std 0.1211 (0.1203) teacher/entropy 0.3508 (0.4040) teacher/usage_max 0.8219 (0.7300) teacher/usage_min 0.0623 (0.0870) teacher/usage_std 0.3461 (0.2849) nleep/row_max_mean 1200.5034 (1198.2241) nleep/row_max_std 12.5039 (13.9565) nleep/row_min_mean 1195.4351 (1193.5335) lr 1.3090e-03 eta 0:44:58
epoch [22/50] batch [180/246] time 0.496 (0.397) data 0.000 (0.002) loss 2.2089 (1.8908) teacher_loss 1.2058 (0.9612) loss_zs_kd 0.0434 (0.0499) loss_oracle 0.6560 (0.6591) kd_loss 0.6534 (0.5752) acc 59.3750 (75.1736) gate/entropy 1.0236 (1.0251) gate/usage_max 0.4287 (0.4331) gate/usage_min 0.1620 (0.1640) gate/usage_std 0.1214 (0.1204) teacher/entropy 0.2982 (0.3978) teacher/usage_max 0.8702 (0.7386) teacher/usage_min 0.0638 (0.0850) teacher/usage_std 0.3797 (0.2906) nleep/row_max_mean 1197.2889 (1198.2729) nleep/row_max_std 14.0267 (13.8902) nleep/row_min_mean 1191.7013 (1193.5357) lr 1.3090e-03 eta 0:45:59
epoch [22/50] batch [200/246] time 0.552 (0.405) data 0.000 (0.002) loss 1.9810 (1.8947) teacher_loss 1.0753 (0.9631) loss_zs_kd 0.0570 (0.0498) loss_oracle 0.6286 (0.6559) kd_loss 0.5628 (0.5788) acc 71.8750 (75.0469) gate/entropy 1.0235 (1.0249) gate/usage_max 0.4281 (0.4326) gate/usage_min 0.1618 (0.1637) gate/usage_std 0.1215 (0.1205) teacher/entropy 0.3769 (0.3932) teacher/usage_max 0.7905 (0.7419) teacher/usage_min 0.0593 (0.0849) teacher/usage_std 0.3254 (0.2927) nleep/row_max_mean 1197.3735 (1198.2846) nleep/row_max_std 15.1518 (13.8937) nleep/row_min_mean 1192.0903 (1193.5019) lr 1.3090e-03 eta 0:46:47
epoch [22/50] batch [220/246] time 0.484 (0.387) data 0.000 (0.001) loss 2.0981 (1.9035) teacher_loss 1.1735 (0.9681) loss_zs_kd 0.0726 (0.0501) loss_oracle 0.6440 (0.6569) kd_loss 0.5664 (0.5819) acc 75.0000 (75.0142) gate/entropy 1.0232 (1.0248) gate/usage_max 0.4275 (0.4322) gate/usage_min 0.1615 (0.1636) gate/usage_std 0.1217 (0.1206) teacher/entropy 0.4070 (0.3895) teacher/usage_max 0.7733 (0.7467) teacher/usage_min 0.0961 (0.0844) teacher/usage_std 0.3114 (0.2958) nleep/row_max_mean 1197.8706 (1198.1825) nleep/row_max_std 14.6312 (13.8582) nleep/row_min_mean 1192.7839 (1193.3628) lr 1.3090e-03 eta 0:44:37
epoch [22/50] batch [240/246] time 0.437 (0.382) data 0.000 (0.001) loss 1.7204 (1.9137) teacher_loss 0.7406 (0.9749) loss_zs_kd 0.0531 (0.0506) loss_oracle 0.6481 (0.6571) kd_loss 0.6292 (0.5850) acc 84.3750 (74.8828) gate/entropy 1.0230 (1.0246) gate/usage_max 0.4269 (0.4317) gate/usage_min 0.1613 (0.1634) gate/usage_std 0.1218 (0.1207) teacher/entropy 0.3273 (0.3857) teacher/usage_max 0.8224 (0.7520) teacher/usage_min 0.0778 (0.0842) teacher/usage_std 0.3459 (0.2993) nleep/row_max_mean 1193.9866 (1198.0261) nleep/row_max_std 12.8899 (13.8944) nleep/row_min_mean 1188.6215 (1193.1827) lr 1.3090e-03 eta 0:43:50
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,848
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,949
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      85.2%, epoch: 17 *******
******* Domain r best val test acc: 91.0%, epoch: 17 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [23/50] batch [20/246] time 0.467 (0.476) data 0.000 (0.012) loss 1.9113 (1.9632) teacher_loss 0.9494 (0.9945) loss_zs_kd 0.0397 (0.0543) loss_oracle 0.6303 (0.6488) kd_loss 0.6270 (0.6173) acc 71.8750 (74.0625) gate/entropy 1.0230 (1.0229) gate/usage_max 0.4265 (0.4265) gate/usage_min 0.1612 (0.1611) gate/usage_std 0.1218 (0.1219) teacher/entropy 0.2801 (0.3321) teacher/usage_max 0.8353 (0.8071) teacher/usage_min 0.0278 (0.0664) teacher/usage_std 0.3577 (0.3364) nleep/row_max_mean 1196.9324 (1197.9825) nleep/row_max_std 16.0718 (14.4171) nleep/row_min_mean 1191.0286 (1192.5092) lr 1.2487e-03 eta 0:54:30
epoch [23/50] batch [40/246] time 0.471 (0.476) data 0.000 (0.006) loss 2.2782 (2.0271) teacher_loss 1.2659 (1.0332) loss_zs_kd 0.0557 (0.0515) loss_oracle 0.6931 (0.6737) kd_loss 0.6379 (0.6313) acc 68.7500 (73.9062) gate/entropy 1.0226 (1.0228) gate/usage_max 0.4259 (0.4263) gate/usage_min 0.1609 (0.1610) gate/usage_std 0.1221 (0.1220) teacher/entropy 0.3209 (0.3215) teacher/usage_max 0.8703 (0.8175) teacher/usage_min 0.0485 (0.0661) teacher/usage_std 0.3799 (0.3433) nleep/row_max_mean 1199.3049 (1197.7111) nleep/row_max_std 15.0343 (14.3071) nleep/row_min_mean 1193.6063 (1192.1922) lr 1.2487e-03 eta 0:54:20
epoch [23/50] batch [60/246] time 0.186 (0.412) data 0.001 (0.004) loss 1.8523 (2.0225) teacher_loss 0.8956 (1.0181) loss_zs_kd 0.0646 (0.0501) loss_oracle 0.6749 (0.6815) kd_loss 0.5869 (0.6386) acc 75.0000 (74.0104) gate/entropy 1.0225 (1.0227) gate/usage_max 0.4255 (0.4261) gate/usage_min 0.1607 (0.1609) gate/usage_std 0.1221 (0.1220) teacher/entropy 0.3627 (0.3118) teacher/usage_max 0.7947 (0.8253) teacher/usage_min 0.0750 (0.0652) teacher/usage_std 0.3270 (0.3486) nleep/row_max_mean 1194.4043 (1198.0878) nleep/row_max_std 16.3370 (14.8224) nleep/row_min_mean 1189.2932 (1192.5028) lr 1.2487e-03 eta 0:46:54
epoch [23/50] batch [80/246] time 0.514 (0.395) data 0.000 (0.003) loss 1.9134 (2.0542) teacher_loss 0.8282 (1.0436) loss_zs_kd 0.0443 (0.0497) loss_oracle 0.7165 (0.6822) kd_loss 0.7048 (0.6446) acc 78.1250 (72.8906) gate/entropy 1.0223 (1.0226) gate/usage_max 0.4251 (0.4259) gate/usage_min 0.1605 (0.1608) gate/usage_std 0.1223 (0.1221) teacher/entropy 0.2043 (0.3018) teacher/usage_max 0.9027 (0.8329) teacher/usage_min 0.0316 (0.0613) teacher/usage_std 0.4029 (0.3540) nleep/row_max_mean 1200.9384 (1198.1506) nleep/row_max_std 15.1834 (14.9437) nleep/row_min_mean 1194.6115 (1192.4530) lr 1.2487e-03 eta 0:44:47
epoch [23/50] batch [100/246] time 0.467 (0.391) data 0.000 (0.003) loss 1.8796 (2.0527) teacher_loss 0.8732 (1.0335) loss_zs_kd 0.0361 (0.0496) loss_oracle 0.7160 (0.6872) kd_loss 0.6304 (0.6509) acc 84.3750 (73.0312) gate/entropy 1.0222 (1.0226) gate/usage_max 0.4247 (0.4257) gate/usage_min 0.1603 (0.1608) gate/usage_std 0.1224 (0.1221) teacher/entropy 0.3068 (0.2937) teacher/usage_max 0.8364 (0.8418) teacher/usage_min 0.0630 (0.0590) teacher/usage_std 0.3561 (0.3602) nleep/row_max_mean 1198.1799 (1197.9836) nleep/row_max_std 15.6413 (14.8800) nleep/row_min_mean 1192.6064 (1192.2018) lr 1.2487e-03 eta 0:44:16
epoch [23/50] batch [120/246] time 0.460 (0.405) data 0.000 (0.002) loss 1.9319 (2.0358) teacher_loss 0.8354 (1.0106) loss_zs_kd 0.0478 (0.0492) loss_oracle 0.7188 (0.6907) kd_loss 0.7132 (0.6552) acc 71.8750 (73.8281) gate/entropy 1.0220 (1.0225) gate/usage_max 0.4244 (0.4255) gate/usage_min 0.1602 (0.1607) gate/usage_std 0.1225 (0.1222) teacher/entropy 0.2173 (0.2891) teacher/usage_max 0.9251 (0.8459) teacher/usage_min 0.0197 (0.0578) teacher/usage_std 0.4187 (0.3630) nleep/row_max_mean 1200.6204 (1198.1336) nleep/row_max_std 11.9273 (14.7349) nleep/row_min_mean 1194.4302 (1192.3089) lr 1.2487e-03 eta 0:45:41
epoch [23/50] batch [140/246] time 0.497 (0.415) data 0.000 (0.002) loss 1.7226 (2.0440) teacher_loss 0.6962 (1.0149) loss_zs_kd 0.0148 (0.0494) loss_oracle 0.6978 (0.6936) kd_loss 0.6700 (0.6577) acc 84.3750 (73.8170) gate/entropy 1.0220 (1.0224) gate/usage_max 0.4241 (0.4253) gate/usage_min 0.1601 (0.1606) gate/usage_std 0.1225 (0.1222) teacher/entropy 0.2921 (0.2848) teacher/usage_max 0.8466 (0.8496) teacher/usage_min 0.0637 (0.0565) teacher/usage_std 0.3631 (0.3656) nleep/row_max_mean 1198.9762 (1198.3115) nleep/row_max_std 13.4030 (14.7569) nleep/row_min_mean 1192.8497 (1192.4453) lr 1.2487e-03 eta 0:46:42
epoch [23/50] batch [160/246] time 0.081 (0.414) data 0.000 (0.002) loss 2.2714 (2.0466) teacher_loss 1.2802 (1.0132) loss_zs_kd 0.0310 (0.0483) loss_oracle 0.6848 (0.6962) kd_loss 0.6333 (0.6611) acc 68.7500 (73.6523) gate/entropy 1.0219 (1.0223) gate/usage_max 0.4238 (0.4251) gate/usage_min 0.1600 (0.1605) gate/usage_std 0.1226 (0.1223) teacher/entropy 0.2617 (0.2805) teacher/usage_max 0.8491 (0.8529) teacher/usage_min 0.0219 (0.0550) teacher/usage_std 0.3673 (0.3679) nleep/row_max_mean 1199.5442 (1198.4873) nleep/row_max_std 19.0021 (14.7825) nleep/row_min_mean 1193.3569 (1192.5608) lr 1.2487e-03 eta 0:46:22
epoch [23/50] batch [180/246] time 0.486 (0.403) data 0.000 (0.002) loss 1.8074 (2.0427) teacher_loss 0.7477 (1.0056) loss_zs_kd 0.0585 (0.0481) loss_oracle 0.7110 (0.6984) kd_loss 0.6750 (0.6639) acc 81.2500 (73.7326) gate/entropy 1.0218 (1.0223) gate/usage_max 0.4235 (0.4250) gate/usage_min 0.1600 (0.1605) gate/usage_std 0.1226 (0.1223) teacher/entropy 0.2649 (0.2765) teacher/usage_max 0.8948 (0.8568) teacher/usage_min 0.0375 (0.0535) teacher/usage_std 0.3972 (0.3706) nleep/row_max_mean 1189.6704 (1198.4092) nleep/row_max_std 10.0417 (14.7335) nleep/row_min_mean 1184.0583 (1192.4504) lr 1.2487e-03 eta 0:45:06
epoch [23/50] batch [200/246] time 0.482 (0.398) data 0.000 (0.001) loss 2.3195 (2.0419) teacher_loss 1.2954 (1.0024) loss_zs_kd 0.0419 (0.0474) loss_oracle 0.7199 (0.6998) kd_loss 0.6432 (0.6659) acc 59.3750 (73.7812) gate/entropy 1.0216 (1.0222) gate/usage_max 0.4232 (0.4248) gate/usage_min 0.1597 (0.1604) gate/usage_std 0.1228 (0.1224) teacher/entropy 0.2569 (0.2725) teacher/usage_max 0.8907 (0.8604) teacher/usage_min 0.0279 (0.0521) teacher/usage_std 0.3947 (0.3732) nleep/row_max_mean 1195.2876 (1198.4439) nleep/row_max_std 13.0625 (14.6468) nleep/row_min_mean 1188.6514 (1192.4433) lr 1.2487e-03 eta 0:44:25
epoch [23/50] batch [220/246] time 0.469 (0.396) data 0.000 (0.001) loss 2.1941 (2.0499) teacher_loss 1.1175 (1.0079) loss_zs_kd 0.0307 (0.0474) loss_oracle 0.6953 (0.6999) kd_loss 0.7136 (0.6683) acc 68.7500 (73.4659) gate/entropy 1.0216 (1.0222) gate/usage_max 0.4230 (0.4246) gate/usage_min 0.1597 (0.1603) gate/usage_std 0.1228 (0.1224) teacher/entropy 0.1898 (0.2685) teacher/usage_max 0.9237 (0.8636) teacher/usage_min 0.0315 (0.0508) teacher/usage_std 0.4175 (0.3754) nleep/row_max_mean 1196.8188 (1198.3615) nleep/row_max_std 16.3974 (14.5886) nleep/row_min_mean 1190.1987 (1192.3257) lr 1.2487e-03 eta 0:43:58
epoch [23/50] batch [240/246] time 0.464 (0.402) data 0.000 (0.001) loss 1.6783 (2.0537) teacher_loss 0.6286 (1.0104) loss_zs_kd 0.0097 (0.0473) loss_oracle 0.6863 (0.6987) kd_loss 0.7017 (0.6703) acc 81.2500 (73.4115) gate/entropy 1.0215 (1.0221) gate/usage_max 0.4228 (0.4245) gate/usage_min 0.1596 (0.1603) gate/usage_std 0.1228 (0.1224) teacher/entropy 0.2234 (0.2654) teacher/usage_max 0.8927 (0.8662) teacher/usage_min 0.0529 (0.0501) teacher/usage_std 0.3955 (0.3772) nleep/row_max_mean 1198.9940 (1198.2845) nleep/row_max_std 14.5713 (14.6081) nleep/row_min_mean 1192.5347 (1192.2230) lr 1.2487e-03 eta 0:44:33
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,858
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,949
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      85.2%, epoch: 17 *******
******* Domain r best val test acc: 91.0%, epoch: 17 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [24/50] batch [20/246] time 0.526 (0.265) data 0.000 (0.016) loss 2.2045 (2.0449) teacher_loss 1.1475 (1.0093) loss_zs_kd 0.0295 (0.0432) loss_oracle 0.6448 (0.6647) kd_loss 0.7198 (0.6817) acc 75.0000 (72.1875) gate/entropy 1.0214 (1.0214) gate/usage_max 0.4225 (0.4226) gate/usage_min 0.1595 (0.1595) gate/usage_std 0.1230 (0.1229) teacher/entropy 0.1893 (0.2410) teacher/usage_max 0.9215 (0.8899) teacher/usage_min 0.0387 (0.0429) teacher/usage_std 0.4159 (0.3938) nleep/row_max_mean 1200.3062 (1198.0924) nleep/row_max_std 16.1064 (14.8253) nleep/row_min_mean 1193.8130 (1191.7400) lr 1.1874e-03 eta 0:29:14
epoch [24/50] batch [40/246] time 0.481 (0.335) data 0.000 (0.008) loss 2.3329 (2.0836) teacher_loss 1.1809 (1.0395) loss_zs_kd 0.0660 (0.0422) loss_oracle 0.7102 (0.6717) kd_loss 0.7639 (0.6871) acc 65.6250 (72.6562) gate/entropy 1.0212 (1.0214) gate/usage_max 0.4223 (0.4225) gate/usage_min 0.1592 (0.1595) gate/usage_std 0.1231 (0.1230) teacher/entropy 0.1210 (0.2326) teacher/usage_max 0.9679 (0.8942) teacher/usage_min 0.0145 (0.0416) teacher/usage_std 0.4487 (0.3968) nleep/row_max_mean 1200.4966 (1198.1913) nleep/row_max_std 15.4885 (14.9370) nleep/row_min_mean 1193.6152 (1191.8501) lr 1.1874e-03 eta 0:36:49
epoch [24/50] batch [60/246] time 0.520 (0.347) data 0.000 (0.006) loss 2.3208 (2.0755) teacher_loss 1.1990 (1.0306) loss_zs_kd 0.0334 (0.0417) loss_oracle 0.7715 (0.6802) kd_loss 0.7194 (0.6840) acc 71.8750 (72.9167) gate/entropy 1.0213 (1.0214) gate/usage_max 0.4221 (0.4224) gate/usage_min 0.1594 (0.1594) gate/usage_std 0.1230 (0.1230) teacher/entropy 0.2314 (0.2357) teacher/usage_max 0.8777 (0.8917) teacher/usage_min 0.0394 (0.0425) teacher/usage_std 0.3853 (0.3950) nleep/row_max_mean 1195.4688 (1198.3305) nleep/row_max_std 11.1088 (14.7320) nleep/row_min_mean 1188.8818 (1191.9777) lr 1.1874e-03 eta 0:38:06
epoch [24/50] batch [80/246] time 0.514 (0.385) data 0.000 (0.004) loss 2.0815 (2.0996) teacher_loss 1.0223 (1.0473) loss_zs_kd 0.0460 (0.0432) loss_oracle 0.7621 (0.6918) kd_loss 0.6551 (0.6847) acc 78.1250 (72.6172) gate/entropy 1.0213 (1.0213) gate/usage_max 0.4220 (0.4223) gate/usage_min 0.1593 (0.1594) gate/usage_std 0.1230 (0.1230) teacher/entropy 0.2729 (0.2354) teacher/usage_max 0.8786 (0.8914) teacher/usage_min 0.0600 (0.0423) teacher/usage_std 0.3855 (0.3948) nleep/row_max_mean 1192.7939 (1198.2570) nleep/row_max_std 13.6934 (14.8562) nleep/row_min_mean 1186.9421 (1191.9186) lr 1.1874e-03 eta 0:42:03
epoch [24/50] batch [100/246] time 0.496 (0.407) data 0.000 (0.003) loss 2.2068 (2.1055) teacher_loss 1.0991 (1.0527) loss_zs_kd 0.0276 (0.0433) loss_oracle 0.7265 (0.6959) kd_loss 0.7305 (0.6832) acc 75.0000 (72.4688) gate/entropy 1.0212 (1.0213) gate/usage_max 0.4218 (0.4222) gate/usage_min 0.1593 (0.1594) gate/usage_std 0.1231 (0.1230) teacher/entropy 0.1790 (0.2365) teacher/usage_max 0.9329 (0.8924) teacher/usage_min 0.0261 (0.0419) teacher/usage_std 0.4240 (0.3956) nleep/row_max_mean 1198.4728 (1198.1517) nleep/row_max_std 16.4350 (14.7614) nleep/row_min_mean 1192.1201 (1191.8537) lr 1.1874e-03 eta 0:44:24
epoch [24/50] batch [120/246] time 0.083 (0.383) data 0.000 (0.003) loss 2.0117 (2.0686) teacher_loss 0.9271 (1.0175) loss_zs_kd 0.0465 (0.0432) loss_oracle 0.7017 (0.6982) kd_loss 0.7105 (0.6803) acc 78.1250 (73.2552) gate/entropy 1.0211 (1.0213) gate/usage_max 0.4216 (0.4221) gate/usage_min 0.1592 (0.1593) gate/usage_std 0.1231 (0.1230) teacher/entropy 0.2487 (0.2397) teacher/usage_max 0.8562 (0.8903) teacher/usage_min 0.0510 (0.0426) teacher/usage_std 0.3701 (0.3940) nleep/row_max_mean 1190.6331 (1197.7188) nleep/row_max_std 10.5489 (14.6347) nleep/row_min_mean 1184.7323 (1191.4678) lr 1.1874e-03 eta 0:41:38
epoch [24/50] batch [140/246] time 0.485 (0.373) data 0.000 (0.002) loss 1.9380 (2.0731) teacher_loss 0.7797 (1.0209) loss_zs_kd 0.0324 (0.0427) loss_oracle 0.7640 (0.7005) kd_loss 0.7601 (0.6805) acc 81.2500 (73.1696) gate/entropy 1.0210 (1.0212) gate/usage_max 0.4214 (0.4220) gate/usage_min 0.1591 (0.1593) gate/usage_std 0.1232 (0.1231) teacher/entropy 0.1477 (0.2394) teacher/usage_max 0.9420 (0.8908) teacher/usage_min 0.0177 (0.0420) teacher/usage_std 0.4305 (0.3944) nleep/row_max_mean 1203.8722 (1197.7851) nleep/row_max_std 13.8773 (14.4497) nleep/row_min_mean 1196.8982 (1191.5310) lr 1.1874e-03 eta 0:40:26
epoch [24/50] batch [160/246] time 0.512 (0.374) data 0.000 (0.002) loss 1.9480 (2.0755) teacher_loss 0.9557 (1.0234) loss_zs_kd 0.0567 (0.0425) loss_oracle 0.6838 (0.7001) kd_loss 0.6221 (0.6807) acc 75.0000 (73.1055) gate/entropy 1.0211 (1.0212) gate/usage_max 0.4213 (0.4220) gate/usage_min 0.1592 (0.1593) gate/usage_std 0.1232 (0.1231) teacher/entropy 0.3203 (0.2387) teacher/usage_max 0.8174 (0.8913) teacher/usage_min 0.0764 (0.0416) teacher/usage_std 0.3425 (0.3947) nleep/row_max_mean 1197.0172 (1197.7658) nleep/row_max_std 16.0032 (14.3539) nleep/row_min_mean 1190.3889 (1191.5055) lr 1.1874e-03 eta 0:40:27
epoch [24/50] batch [180/246] time 0.471 (0.387) data 0.000 (0.002) loss 2.5275 (2.0764) teacher_loss 1.4436 (1.0215) loss_zs_kd 0.0508 (0.0429) loss_oracle 0.7127 (0.7017) kd_loss 0.7022 (0.6826) acc 71.8750 (73.1597) gate/entropy 1.0210 (1.0212) gate/usage_max 0.4211 (0.4219) gate/usage_min 0.1591 (0.1593) gate/usage_std 0.1232 (0.1231) teacher/entropy 0.2147 (0.2363) teacher/usage_max 0.9148 (0.8928) teacher/usage_min 0.0349 (0.0406) teacher/usage_std 0.4112 (0.3959) nleep/row_max_mean 1193.2502 (1197.8455) nleep/row_max_std 12.0731 (14.3809) nleep/row_min_mean 1187.4303 (1191.5767) lr 1.1874e-03 eta 0:41:42
epoch [24/50] batch [200/246] time 0.495 (0.398) data 0.000 (0.002) loss 2.5104 (2.0915) teacher_loss 1.5222 (1.0375) loss_zs_kd 0.0378 (0.0426) loss_oracle 0.7214 (0.7034) kd_loss 0.6086 (0.6809) acc 53.1250 (72.5938) gate/entropy 1.0209 (1.0212) gate/usage_max 0.4210 (0.4218) gate/usage_min 0.1590 (0.1592) gate/usage_std 0.1233 (0.1231) teacher/entropy 0.2968 (0.2381) teacher/usage_max 0.8840 (0.8913) teacher/usage_min 0.0393 (0.0412) teacher/usage_std 0.3897 (0.3948) nleep/row_max_mean 1196.6761 (1197.7913) nleep/row_max_std 16.0451 (14.3914) nleep/row_min_mean 1190.7283 (1191.5453) lr 1.1874e-03 eta 0:42:41
epoch [24/50] batch [220/246] time 0.081 (0.398) data 0.000 (0.002) loss 2.2998 (2.0935) teacher_loss 1.2016 (1.0363) loss_zs_kd 0.0415 (0.0424) loss_oracle 0.7455 (0.7078) kd_loss 0.7047 (0.6820) acc 59.3750 (72.6278) gate/entropy 1.0209 (1.0212) gate/usage_max 0.4208 (0.4217) gate/usage_min 0.1590 (0.1592) gate/usage_std 0.1233 (0.1231) teacher/entropy 0.1922 (0.2362) teacher/usage_max 0.9374 (0.8920) teacher/usage_min 0.0308 (0.0410) teacher/usage_std 0.4272 (0.3953) nleep/row_max_mean 1200.2083 (1197.9064) nleep/row_max_std 18.8181 (14.4475) nleep/row_min_mean 1193.6696 (1191.6496) lr 1.1874e-03 eta 0:42:38
epoch [24/50] batch [240/246] time 0.414 (0.393) data 0.000 (0.002) loss 2.1549 (2.0903) teacher_loss 1.0372 (1.0324) loss_zs_kd 0.0415 (0.0426) loss_oracle 0.7320 (0.7082) kd_loss 0.7310 (0.6825) acc 75.0000 (72.5651) gate/entropy 1.0209 (1.0211) gate/usage_max 0.4207 (0.4216) gate/usage_min 0.1589 (0.1592) gate/usage_std 0.1233 (0.1231) teacher/entropy 0.1783 (0.2348) teacher/usage_max 0.9003 (0.8928) teacher/usage_min 0.0439 (0.0406) teacher/usage_std 0.4009 (0.3958) nleep/row_max_mean 1199.3823 (1197.9712) nleep/row_max_std 14.6319 (14.5387) nleep/row_min_mean 1192.6355 (1191.7057) lr 1.1874e-03 eta 0:41:57
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,850
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,949
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 89.6%
******* Domain r best val acc:      85.2%, epoch: 17 *******
******* Domain r best val test acc: 91.0%, epoch: 17 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [25/50] batch [20/246] time 0.465 (0.484) data 0.000 (0.013) loss 1.8860 (2.0645) teacher_loss 0.8488 (1.0098) loss_zs_kd 0.0282 (0.0408) loss_oracle 0.6585 (0.6914) kd_loss 0.6939 (0.6887) acc 78.1250 (73.2812) gate/entropy 1.0208 (1.0209) gate/usage_max 0.4206 (0.4206) gate/usage_min 0.1588 (0.1589) gate/usage_std 0.1234 (0.1233) teacher/entropy 0.2067 (0.2142) teacher/usage_max 0.9333 (0.9062) teacher/usage_min 0.0312 (0.0322) teacher/usage_std 0.4242 (0.4055) nleep/row_max_mean 1203.8324 (1199.2111) nleep/row_max_std 15.8555 (15.7040) nleep/row_min_mean 1197.2609 (1192.7048) lr 1.1253e-03 eta 0:51:24
epoch [25/50] batch [40/246] time 0.480 (0.482) data 0.000 (0.006) loss 1.9712 (2.0219) teacher_loss 0.9121 (0.9666) loss_zs_kd 0.0347 (0.0411) loss_oracle 0.7116 (0.6983) kd_loss 0.6859 (0.6855) acc 71.8750 (73.0469) gate/entropy 1.0209 (1.0209) gate/usage_max 0.4207 (0.4206) gate/usage_min 0.1589 (0.1589) gate/usage_std 0.1233 (0.1233) teacher/entropy 0.2225 (0.2203) teacher/usage_max 0.9297 (0.9030) teacher/usage_min 0.0266 (0.0341) teacher/usage_std 0.4217 (0.4031) nleep/row_max_mean 1201.1819 (1198.7794) nleep/row_max_std 17.2139 (15.1202) nleep/row_min_mean 1195.1200 (1192.4553) lr 1.1253e-03 eta 0:51:06
epoch [25/50] batch [60/246] time 0.095 (0.447) data 0.000 (0.004) loss 2.6528 (2.0535) teacher_loss 1.5646 (1.0065) loss_zs_kd 0.0576 (0.0408) loss_oracle 0.6822 (0.6940) kd_loss 0.7183 (0.6796) acc 56.2500 (72.3958) gate/entropy 1.0208 (1.0209) gate/usage_max 0.4208 (0.4207) gate/usage_min 0.1589 (0.1589) gate/usage_std 0.1233 (0.1233) teacher/entropy 0.2239 (0.2276) teacher/usage_max 0.8516 (0.8979) teacher/usage_min 0.0698 (0.0367) teacher/usage_std 0.3665 (0.3995) nleep/row_max_mean 1199.3955 (1198.3850) nleep/row_max_std 14.9545 (15.0289) nleep/row_min_mean 1192.6624 (1192.1337) lr 1.1253e-03 eta 0:47:15
epoch [25/50] batch [80/246] time 0.487 (0.421) data 0.000 (0.003) loss 2.0730 (2.0516) teacher_loss 1.0241 (1.0082) loss_zs_kd 0.0201 (0.0410) loss_oracle 0.7230 (0.6946) kd_loss 0.6774 (0.6757) acc 68.7500 (72.3047) gate/entropy 1.0208 (1.0208) gate/usage_max 0.4210 (0.4207) gate/usage_min 0.1589 (0.1589) gate/usage_std 0.1234 (0.1233) teacher/entropy 0.2323 (0.2371) teacher/usage_max 0.8589 (0.8918) teacher/usage_min 0.0455 (0.0395) teacher/usage_std 0.3722 (0.3952) nleep/row_max_mean 1198.2610 (1198.3812) nleep/row_max_std 13.4188 (14.9267) nleep/row_min_mean 1192.4683 (1192.2413) lr 1.1253e-03 eta 0:44:18
epoch [25/50] batch [100/246] time 0.529 (0.406) data 0.000 (0.003) loss 1.7515 (2.0551) teacher_loss 0.7250 (1.0122) loss_zs_kd 0.0269 (0.0420) loss_oracle 0.7380 (0.6965) kd_loss 0.6440 (0.6737) acc 81.2500 (72.5938) gate/entropy 1.0208 (1.0208) gate/usage_max 0.4211 (0.4208) gate/usage_min 0.1589 (0.1589) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.2870 (0.2399) teacher/usage_max 0.8794 (0.8895) teacher/usage_min 0.0530 (0.0403) teacher/usage_std 0.3862 (0.3936) nleep/row_max_mean 1194.5479 (1198.2773) nleep/row_max_std 14.2507 (14.8345) nleep/row_min_mean 1188.8640 (1192.1629) lr 1.1253e-03 eta 0:42:37
epoch [25/50] batch [120/246] time 0.441 (0.402) data 0.000 (0.002) loss 2.2387 (2.0743) teacher_loss 1.0812 (1.0300) loss_zs_kd 0.0404 (0.0424) loss_oracle 0.7774 (0.6985) kd_loss 0.7485 (0.6738) acc 75.0000 (72.2396) gate/entropy 1.0207 (1.0208) gate/usage_max 0.4213 (0.4209) gate/usage_min 0.1588 (0.1589) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.2053 (0.2400) teacher/usage_max 0.8961 (0.8892) teacher/usage_min 0.0123 (0.0410) teacher/usage_std 0.3993 (0.3934) nleep/row_max_mean 1201.1250 (1198.2994) nleep/row_max_std 15.8546 (14.9517) nleep/row_min_mean 1194.7568 (1192.1908) lr 1.1253e-03 eta 0:42:00
epoch [25/50] batch [140/246] time 0.496 (0.411) data 0.000 (0.002) loss 2.0448 (2.0719) teacher_loss 1.0154 (1.0256) loss_zs_kd 0.0508 (0.0413) loss_oracle 0.7243 (0.6997) kd_loss 0.6419 (0.6758) acc 68.7500 (72.6562) gate/entropy 1.0207 (1.0208) gate/usage_max 0.4214 (0.4209) gate/usage_min 0.1588 (0.1589) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.2766 (0.2373) teacher/usage_max 0.8517 (0.8910) teacher/usage_min 0.0552 (0.0405) teacher/usage_std 0.3668 (0.3946) nleep/row_max_mean 1201.8644 (1198.4059) nleep/row_max_std 15.4836 (14.9615) nleep/row_min_mean 1195.4377 (1192.2865) lr 1.1253e-03 eta 0:42:50
epoch [25/50] batch [160/246] time 0.495 (0.421) data 0.000 (0.002) loss 2.2998 (2.0796) teacher_loss 1.2437 (1.0338) loss_zs_kd 0.0483 (0.0413) loss_oracle 0.7048 (0.7004) kd_loss 0.6796 (0.6749) acc 68.7500 (72.5977) gate/entropy 1.0208 (1.0208) gate/usage_max 0.4215 (0.4210) gate/usage_min 0.1588 (0.1589) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.2235 (0.2375) teacher/usage_max 0.9200 (0.8913) teacher/usage_min 0.0399 (0.0405) teacher/usage_std 0.4148 (0.3949) nleep/row_max_mean 1198.0442 (1198.3682) nleep/row_max_std 13.8187 (15.0220) nleep/row_min_mean 1192.5005 (1192.2535) lr 1.1253e-03 eta 0:43:42
epoch [25/50] batch [180/246] time 0.340 (0.400) data 0.000 (0.002) loss 1.9927 (2.0843) teacher_loss 0.8942 (1.0382) loss_zs_kd 0.0333 (0.0411) loss_oracle 0.7419 (0.7006) kd_loss 0.7109 (0.6752) acc 78.1250 (72.5174) gate/entropy 1.0207 (1.0208) gate/usage_max 0.4217 (0.4211) gate/usage_min 0.1588 (0.1589) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.2110 (0.2372) teacher/usage_max 0.9207 (0.8925) teacher/usage_min 0.0197 (0.0402) teacher/usage_std 0.4157 (0.3957) nleep/row_max_mean 1198.5519 (1198.4773) nleep/row_max_std 14.2586 (15.1768) nleep/row_min_mean 1192.1917 (1192.3620) lr 1.1253e-03 eta 0:41:28
epoch [25/50] batch [200/246] time 0.081 (0.390) data 0.000 (0.001) loss 1.8348 (2.0749) teacher_loss 0.8144 (1.0296) loss_zs_kd 0.0567 (0.0404) loss_oracle 0.6644 (0.7008) kd_loss 0.6599 (0.6747) acc 81.2500 (72.6562) gate/entropy 1.0208 (1.0208) gate/usage_max 0.4218 (0.4211) gate/usage_min 0.1588 (0.1589) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.2744 (0.2381) teacher/usage_max 0.8516 (0.8932) teacher/usage_min 0.0722 (0.0401) teacher/usage_std 0.3665 (0.3961) nleep/row_max_mean 1199.9406 (1198.4241) nleep/row_max_std 16.4474 (15.2979) nleep/row_min_mean 1193.8505 (1192.3287) lr 1.1253e-03 eta 0:40:16
epoch [25/50] batch [220/246] time 0.090 (0.386) data 0.000 (0.001) loss 2.1053 (2.0676) teacher_loss 1.0311 (1.0232) loss_zs_kd 0.0391 (0.0401) loss_oracle 0.7452 (0.7000) kd_loss 0.6821 (0.6743) acc 75.0000 (73.0540) gate/entropy 1.0207 (1.0208) gate/usage_max 0.4219 (0.4212) gate/usage_min 0.1588 (0.1589) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.2281 (0.2394) teacher/usage_max 0.8825 (0.8917) teacher/usage_min 0.0480 (0.0408) teacher/usage_std 0.3884 (0.3951) nleep/row_max_mean 1198.9144 (1198.3988) nleep/row_max_std 16.9204 (15.2944) nleep/row_min_mean 1192.8351 (1192.3192) lr 1.1253e-03 eta 0:39:42
epoch [25/50] batch [240/246] time 0.481 (0.393) data 0.000 (0.001) loss 1.9046 (2.0684) teacher_loss 0.8973 (1.0243) loss_zs_kd 0.0409 (0.0402) loss_oracle 0.7074 (0.7010) kd_loss 0.6331 (0.6736) acc 71.8750 (73.0078) gate/entropy 1.0207 (1.0208) gate/usage_max 0.4220 (0.4213) gate/usage_min 0.1588 (0.1588) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.2679 (0.2398) teacher/usage_max 0.8872 (0.8917) teacher/usage_min 0.0387 (0.0407) teacher/usage_std 0.3919 (0.3951) nleep/row_max_mean 1197.0747 (1198.3968) nleep/row_max_std 16.1833 (15.3288) nleep/row_min_mean 1191.5767 (1192.3247) lr 1.1253e-03 eta 0:40:21
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,854
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,944
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.4%
******* Domain r best val acc:      85.2%, epoch: 17 *******
******* Domain r best val test acc: 91.0%, epoch: 17 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [26/50] batch [20/246] time 0.086 (0.363) data 0.000 (0.012) loss 1.9682 (2.0755) teacher_loss 0.9465 (1.0343) loss_zs_kd 0.0516 (0.0383) loss_oracle 0.7146 (0.7102) kd_loss 0.6386 (0.6669) acc 68.7500 (72.5000) gate/entropy 1.0207 (1.0207) gate/usage_max 0.4222 (0.4222) gate/usage_min 0.1587 (0.1588) gate/usage_std 0.1235 (0.1234) teacher/entropy 0.2489 (0.2479) teacher/usage_max 0.8671 (0.8879) teacher/usage_min 0.0251 (0.0449) teacher/usage_std 0.3789 (0.3923) nleep/row_max_mean 1196.5786 (1198.1197) nleep/row_max_std 14.0225 (15.5776) nleep/row_min_mean 1190.7726 (1192.1819) lr 1.0628e-03 eta 0:37:06
epoch [26/50] batch [40/246] time 0.510 (0.347) data 0.000 (0.006) loss 1.9910 (1.9976) teacher_loss 0.9614 (0.9534) loss_zs_kd 0.0400 (0.0385) loss_oracle 0.7101 (0.7074) kd_loss 0.6546 (0.6713) acc 75.0000 (74.2188) gate/entropy 1.0208 (1.0207) gate/usage_max 0.4223 (0.4222) gate/usage_min 0.1589 (0.1588) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.2582 (0.2411) teacher/usage_max 0.8743 (0.8935) teacher/usage_min 0.0514 (0.0425) teacher/usage_std 0.3826 (0.3963) nleep/row_max_mean 1194.1755 (1198.9624) nleep/row_max_std 19.1502 (15.9606) nleep/row_min_mean 1188.0586 (1192.9875) lr 1.0628e-03 eta 0:35:20
epoch [26/50] batch [60/246] time 0.456 (0.345) data 0.000 (0.004) loss 1.9712 (1.9968) teacher_loss 0.9169 (0.9560) loss_zs_kd 0.0561 (0.0383) loss_oracle 0.6468 (0.7031) kd_loss 0.7029 (0.6701) acc 71.8750 (74.3229) gate/entropy 1.0207 (1.0207) gate/usage_max 0.4225 (0.4223) gate/usage_min 0.1588 (0.1588) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.1912 (0.2424) teacher/usage_max 0.9227 (0.8910) teacher/usage_min 0.0327 (0.0434) teacher/usage_std 0.4168 (0.3945) nleep/row_max_mean 1207.7100 (1198.9147) nleep/row_max_std 15.0391 (16.1183) nleep/row_min_mean 1201.4271 (1192.9311) lr 1.0628e-03 eta 0:34:59
epoch [26/50] batch [80/246] time 0.444 (0.353) data 0.000 (0.003) loss 2.0514 (2.0150) teacher_loss 1.0517 (0.9799) loss_zs_kd 0.0214 (0.0386) loss_oracle 0.6546 (0.6922) kd_loss 0.6616 (0.6697) acc 71.8750 (73.7109) gate/entropy 1.0208 (1.0207) gate/usage_max 0.4226 (0.4223) gate/usage_min 0.1589 (0.1588) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.2512 (0.2424) teacher/usage_max 0.9008 (0.8898) teacher/usage_min 0.0470 (0.0427) teacher/usage_std 0.4012 (0.3937) nleep/row_max_mean 1197.7317 (1198.7553) nleep/row_max_std 18.4042 (16.0657) nleep/row_min_mean 1192.0208 (1192.7902) lr 1.0628e-03 eta 0:35:44
epoch [26/50] batch [100/246] time 0.495 (0.380) data 0.000 (0.003) loss 2.2501 (2.0272) teacher_loss 1.2086 (0.9965) loss_zs_kd 0.0386 (0.0393) loss_oracle 0.6964 (0.6860) kd_loss 0.6740 (0.6681) acc 71.8750 (73.5000) gate/entropy 1.0207 (1.0207) gate/usage_max 0.4227 (0.4224) gate/usage_min 0.1588 (0.1588) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.2261 (0.2432) teacher/usage_max 0.9149 (0.8910) teacher/usage_min 0.0394 (0.0418) teacher/usage_std 0.4113 (0.3945) nleep/row_max_mean 1200.8888 (1198.6983) nleep/row_max_std 16.6868 (16.1335) nleep/row_min_mean 1194.9167 (1192.7415) lr 1.0628e-03 eta 0:38:21
epoch [26/50] batch [120/246] time 0.474 (0.401) data 0.000 (0.002) loss 2.5189 (2.0464) teacher_loss 1.4482 (1.0211) loss_zs_kd 0.0560 (0.0397) loss_oracle 0.6951 (0.6781) kd_loss 0.6952 (0.6664) acc 62.5000 (73.0469) gate/entropy 1.0207 (1.0208) gate/usage_max 0.4229 (0.4225) gate/usage_min 0.1587 (0.1588) gate/usage_std 0.1235 (0.1234) teacher/entropy 0.2505 (0.2454) teacher/usage_max 0.8475 (0.8889) teacher/usage_min 0.0666 (0.0416) teacher/usage_std 0.3637 (0.3931) nleep/row_max_mean 1197.9711 (1198.2805) nleep/row_max_std 15.9264 (16.0250) nleep/row_min_mean 1191.8398 (1192.3442) lr 1.0628e-03 eta 0:40:19
epoch [26/50] batch [140/246] time 0.485 (0.382) data 0.000 (0.002) loss 2.0613 (2.0504) teacher_loss 0.9710 (1.0287) loss_zs_kd 0.0170 (0.0397) loss_oracle 0.6980 (0.6739) kd_loss 0.7328 (0.6649) acc 75.0000 (72.7679) gate/entropy 1.0209 (1.0208) gate/usage_max 0.4229 (0.4225) gate/usage_min 0.1590 (0.1588) gate/usage_std 0.1233 (0.1234) teacher/entropy 0.1640 (0.2470) teacher/usage_max 0.9283 (0.8865) teacher/usage_min 0.0352 (0.0422) teacher/usage_std 0.4207 (0.3914) nleep/row_max_mean 1198.6235 (1198.1784) nleep/row_max_std 16.6635 (15.8874) nleep/row_min_mean 1192.6711 (1192.2564) lr 1.0628e-03 eta 0:38:17
epoch [26/50] batch [160/246] time 0.461 (0.372) data 0.000 (0.002) loss 1.9341 (2.0406) teacher_loss 0.9776 (1.0243) loss_zs_kd 0.0454 (0.0393) loss_oracle 0.6695 (0.6731) kd_loss 0.5990 (0.6601) acc 68.7500 (72.7539) gate/entropy 1.0208 (1.0208) gate/usage_max 0.4231 (0.4226) gate/usage_min 0.1588 (0.1588) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.3203 (0.2518) teacher/usage_max 0.8515 (0.8835) teacher/usage_min 0.0592 (0.0427) teacher/usage_std 0.3666 (0.3894) nleep/row_max_mean 1198.9132 (1198.1810) nleep/row_max_std 15.2694 (15.8116) nleep/row_min_mean 1193.1228 (1192.2924) lr 1.0628e-03 eta 0:37:09
epoch [26/50] batch [180/246] time 0.442 (0.366) data 0.000 (0.002) loss 1.9722 (2.0289) teacher_loss 1.0225 (1.0142) loss_zs_kd 0.0306 (0.0393) loss_oracle 0.6488 (0.6740) kd_loss 0.6100 (0.6580) acc 65.6250 (73.0035) gate/entropy 1.0209 (1.0208) gate/usage_max 0.4231 (0.4226) gate/usage_min 0.1590 (0.1588) gate/usage_std 0.1233 (0.1234) teacher/entropy 0.3648 (0.2553) teacher/usage_max 0.6999 (0.8805) teacher/usage_min 0.1148 (0.0438) teacher/usage_std 0.2608 (0.3873) nleep/row_max_mean 1191.6914 (1198.0441) nleep/row_max_std 11.0295 (15.7797) nleep/row_min_mean 1186.9148 (1192.1949) lr 1.0628e-03 eta 0:36:26
epoch [26/50] batch [200/246] time 0.549 (0.377) data 0.000 (0.001) loss 1.6673 (2.0175) teacher_loss 0.6963 (1.0065) loss_zs_kd 0.0242 (0.0392) loss_oracle 0.6646 (0.6738) kd_loss 0.6266 (0.6545) acc 81.2500 (73.3438) gate/entropy 1.0209 (1.0208) gate/usage_max 0.4233 (0.4227) gate/usage_min 0.1590 (0.1588) gate/usage_std 0.1233 (0.1234) teacher/entropy 0.2848 (0.2596) teacher/usage_max 0.8333 (0.8772) teacher/usage_min 0.0512 (0.0451) teacher/usage_std 0.3545 (0.3849) nleep/row_max_mean 1202.9117 (1198.0070) nleep/row_max_std 15.9854 (15.7185) nleep/row_min_mean 1197.2975 (1192.2037) lr 1.0628e-03 eta 0:37:24
epoch [26/50] batch [220/246] time 0.498 (0.389) data 0.000 (0.001) loss 2.5433 (2.0354) teacher_loss 1.5883 (1.0243) loss_zs_kd 0.0550 (0.0395) loss_oracle 0.6686 (0.6755) kd_loss 0.5932 (0.6536) acc 62.5000 (72.9972) gate/entropy 1.0208 (1.0208) gate/usage_max 0.4235 (0.4228) gate/usage_min 0.1588 (0.1588) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.3565 (0.2615) teacher/usage_max 0.8369 (0.8747) teacher/usage_min 0.0721 (0.0458) teacher/usage_std 0.3561 (0.3832) nleep/row_max_mean 1198.1207 (1198.0184) nleep/row_max_std 17.5278 (15.6863) nleep/row_min_mean 1192.6812 (1192.2352) lr 1.0628e-03 eta 0:38:28
epoch [26/50] batch [240/246] time 0.078 (0.393) data 0.000 (0.001) loss 1.9756 (2.0334) teacher_loss 0.9920 (1.0227) loss_zs_kd 0.0335 (0.0395) loss_oracle 0.6787 (0.6767) kd_loss 0.6275 (0.6526) acc 71.8750 (73.0859) gate/entropy 1.0209 (1.0208) gate/usage_max 0.4236 (0.4228) gate/usage_min 0.1590 (0.1589) gate/usage_std 0.1233 (0.1234) teacher/entropy 0.3230 (0.2629) teacher/usage_max 0.8253 (0.8728) teacher/usage_min 0.0827 (0.0465) teacher/usage_std 0.3479 (0.3819) nleep/row_max_mean 1195.3353 (1198.0415) nleep/row_max_std 16.2757 (15.6694) nleep/row_min_mean 1189.9598 (1192.2770) lr 1.0628e-03 eta 0:38:42
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,852
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,957
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.2%, epoch: 17 *******
******* Domain r best val test acc: 91.0%, epoch: 17 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [27/50] batch [20/246] time 0.496 (0.379) data 0.000 (0.012) loss 1.6302 (1.9548) teacher_loss 0.5940 (0.9392) loss_zs_kd 0.0249 (0.0391) loss_oracle 0.7189 (0.7020) kd_loss 0.6642 (0.6451) acc 81.2500 (75.0000) gate/entropy 1.0209 (1.0209) gate/usage_max 0.4237 (0.4237) gate/usage_min 0.1589 (0.1590) gate/usage_std 0.1233 (0.1233) teacher/entropy 0.2417 (0.2656) teacher/usage_max 0.8949 (0.8666) teacher/usage_min 0.0473 (0.0476) teacher/usage_std 0.3971 (0.3776) nleep/row_max_mean 1198.6918 (1199.3455) nleep/row_max_std 12.5728 (14.3411) nleep/row_min_mean 1192.7418 (1193.5513) lr 1.0000e-03 eta 0:37:09
epoch [27/50] batch [40/246] time 0.455 (0.426) data 0.000 (0.006) loss 1.6179 (1.9550) teacher_loss 0.6986 (0.9356) loss_zs_kd 0.0260 (0.0386) loss_oracle 0.6505 (0.6942) kd_loss 0.5810 (0.6530) acc 81.2500 (75.2344) gate/entropy 1.0209 (1.0209) gate/usage_max 0.4239 (0.4237) gate/usage_min 0.1590 (0.1590) gate/usage_std 0.1233 (0.1233) teacher/entropy 0.3299 (0.2558) teacher/usage_max 0.8255 (0.8675) teacher/usage_min 0.0517 (0.0469) teacher/usage_std 0.3492 (0.3782) nleep/row_max_mean 1199.5374 (1199.4158) nleep/row_max_std 13.0551 (14.3873) nleep/row_min_mean 1193.9781 (1193.5448) lr 1.0000e-03 eta 0:41:38
epoch [27/50] batch [60/246] time 0.495 (0.447) data 0.000 (0.004) loss 1.9836 (1.9795) teacher_loss 0.9552 (0.9596) loss_zs_kd 0.0415 (0.0400) loss_oracle 0.6648 (0.6907) kd_loss 0.6752 (0.6545) acc 75.0000 (74.5312) gate/entropy 1.0208 (1.0209) gate/usage_max 0.4240 (0.4238) gate/usage_min 0.1589 (0.1590) gate/usage_std 0.1234 (0.1233) teacher/entropy 0.2590 (0.2536) teacher/usage_max 0.8735 (0.8701) teacher/usage_min 0.0498 (0.0455) teacher/usage_std 0.3821 (0.3801) nleep/row_max_mean 1202.5797 (1199.1451) nleep/row_max_std 13.6058 (14.8440) nleep/row_min_mean 1196.6260 (1193.2680) lr 1.0000e-03 eta 0:43:31
epoch [27/50] batch [80/246] time 0.084 (0.424) data 0.000 (0.003) loss 1.9042 (2.0070) teacher_loss 0.9363 (0.9853) loss_zs_kd 0.0393 (0.0413) loss_oracle 0.6994 (0.6906) kd_loss 0.5986 (0.6557) acc 68.7500 (73.8281) gate/entropy 1.0209 (1.0209) gate/usage_max 0.4241 (0.4239) gate/usage_min 0.1590 (0.1590) gate/usage_std 0.1233 (0.1233) teacher/entropy 0.3415 (0.2544) teacher/usage_max 0.8426 (0.8714) teacher/usage_min 0.0748 (0.0455) teacher/usage_std 0.3601 (0.3810) nleep/row_max_mean 1197.5729 (1198.8513) nleep/row_max_std 13.8960 (14.8278) nleep/row_min_mean 1192.2218 (1192.9815) lr 1.0000e-03 eta 0:41:08
epoch [27/50] batch [100/246] time 0.507 (0.407) data 0.000 (0.003) loss 1.9303 (2.0001) teacher_loss 0.9843 (0.9789) loss_zs_kd 0.0519 (0.0417) loss_oracle 0.6680 (0.6913) kd_loss 0.5860 (0.6547) acc 71.8750 (73.8750) gate/entropy 1.0210 (1.0209) gate/usage_max 0.4243 (0.4239) gate/usage_min 0.1591 (0.1590) gate/usage_std 0.1233 (0.1233) teacher/entropy 0.3432 (0.2585) teacher/usage_max 0.7878 (0.8686) teacher/usage_min 0.0705 (0.0472) teacher/usage_std 0.3227 (0.3789) nleep/row_max_mean 1197.4998 (1198.7540) nleep/row_max_std 10.4034 (14.6785) nleep/row_min_mean 1192.2655 (1192.9096) lr 1.0000e-03 eta 0:39:21
epoch [27/50] batch [120/246] time 0.482 (0.394) data 0.000 (0.002) loss 2.0503 (2.0129) teacher_loss 1.0093 (0.9909) loss_zs_kd 0.0376 (0.0423) loss_oracle 0.7129 (0.6934) kd_loss 0.6658 (0.6542) acc 75.0000 (73.6198) gate/entropy 1.0210 (1.0209) gate/usage_max 0.4244 (0.4240) gate/usage_min 0.1591 (0.1590) gate/usage_std 0.1233 (0.1233) teacher/entropy 0.2745 (0.2597) teacher/usage_max 0.8656 (0.8674) teacher/usage_min 0.0506 (0.0482) teacher/usage_std 0.3766 (0.3781) nleep/row_max_mean 1199.0793 (1198.3047) nleep/row_max_std 10.6218 (14.4972) nleep/row_min_mean 1193.4235 (1192.4820) lr 1.0000e-03 eta 0:37:58
epoch [27/50] batch [140/246] time 0.409 (0.387) data 0.000 (0.002) loss 2.0967 (2.0134) teacher_loss 1.0199 (0.9920) loss_zs_kd 0.0257 (0.0421) loss_oracle 0.6879 (0.6913) kd_loss 0.7201 (0.6547) acc 65.6250 (73.4598) gate/entropy 1.0210 (1.0210) gate/usage_max 0.4246 (0.4241) gate/usage_min 0.1591 (0.1590) gate/usage_std 0.1232 (0.1233) teacher/entropy 0.1728 (0.2589) teacher/usage_max 0.8930 (0.8685) teacher/usage_min 0.0354 (0.0480) teacher/usage_std 0.3960 (0.3789) nleep/row_max_mean 1202.9845 (1198.2730) nleep/row_max_std 15.9548 (14.4320) nleep/row_min_mean 1196.6595 (1192.4421) lr 1.0000e-03 eta 0:37:11
epoch [27/50] batch [160/246] time 0.495 (0.398) data 0.000 (0.002) loss 2.0295 (1.9957) teacher_loss 1.0442 (0.9757) loss_zs_kd 0.0218 (0.0419) loss_oracle 0.6400 (0.6897) kd_loss 0.6545 (0.6543) acc 71.8750 (73.8477) gate/entropy 1.0210 (1.0210) gate/usage_max 0.4247 (0.4241) gate/usage_min 0.1591 (0.1591) gate/usage_std 0.1232 (0.1233) teacher/entropy 0.2541 (0.2611) teacher/usage_max 0.8768 (0.8672) teacher/usage_min 0.0518 (0.0490) teacher/usage_std 0.3844 (0.3780) nleep/row_max_mean 1202.7711 (1198.2156) nleep/row_max_std 16.7152 (14.3740) nleep/row_min_mean 1196.7334 (1192.4125) lr 1.0000e-03 eta 0:38:08
epoch [27/50] batch [180/246] time 0.494 (0.407) data 0.000 (0.001) loss 2.1198 (1.9970) teacher_loss 1.1620 (0.9774) loss_zs_kd 0.0364 (0.0423) loss_oracle 0.6828 (0.6920) kd_loss 0.5982 (0.6524) acc 68.7500 (73.9236) gate/entropy 1.0212 (1.0210) gate/usage_max 0.4249 (0.4242) gate/usage_min 0.1593 (0.1591) gate/usage_std 0.1231 (0.1233) teacher/entropy 0.3023 (0.2633) teacher/usage_max 0.8816 (0.8665) teacher/usage_min 0.0438 (0.0496) teacher/usage_std 0.3879 (0.3774) nleep/row_max_mean 1196.8805 (1198.1687) nleep/row_max_std 15.1645 (14.3609) nleep/row_min_mean 1191.4803 (1192.3787) lr 1.0000e-03 eta 0:38:48
epoch [27/50] batch [200/246] time 0.120 (0.391) data 0.000 (0.001) loss 1.8240 (1.9977) teacher_loss 0.8573 (0.9781) loss_zs_kd 0.0473 (0.0427) loss_oracle 0.6890 (0.6951) kd_loss 0.5985 (0.6508) acc 78.1250 (73.9062) gate/entropy 1.0212 (1.0210) gate/usage_max 0.4250 (0.4243) gate/usage_min 0.1593 (0.1591) gate/usage_std 0.1231 (0.1232) teacher/entropy 0.3147 (0.2651) teacher/usage_max 0.8625 (0.8662) teacher/usage_min 0.0570 (0.0497) teacher/usage_std 0.3743 (0.3772) nleep/row_max_mean 1194.5210 (1198.0585) nleep/row_max_std 16.6611 (14.3430) nleep/row_min_mean 1189.1426 (1192.2820) lr 1.0000e-03 eta 0:37:12
epoch [27/50] batch [220/246] time 0.080 (0.386) data 0.000 (0.001) loss 1.8507 (1.9999) teacher_loss 0.8555 (0.9788) loss_zs_kd 0.0507 (0.0427) loss_oracle 0.7170 (0.6989) kd_loss 0.6114 (0.6503) acc 78.1250 (73.8210) gate/entropy 1.0213 (1.0210) gate/usage_max 0.4252 (0.4244) gate/usage_min 0.1594 (0.1591) gate/usage_std 0.1230 (0.1232) teacher/entropy 0.3313 (0.2659) teacher/usage_max 0.8212 (0.8665) teacher/usage_min 0.0869 (0.0500) teacher/usage_std 0.3450 (0.3774) nleep/row_max_mean 1195.1505 (1198.0527) nleep/row_max_std 13.5352 (14.4080) nleep/row_min_mean 1189.5900 (1192.2790) lr 1.0000e-03 eta 0:36:35
epoch [27/50] batch [240/246] time 0.077 (0.383) data 0.000 (0.001) loss 1.5871 (2.0020) teacher_loss 0.6367 (0.9794) loss_zs_kd 0.0318 (0.0429) loss_oracle 0.6922 (0.7019) kd_loss 0.5885 (0.6502) acc 84.3750 (73.7891) gate/entropy 1.0213 (1.0210) gate/usage_max 0.4254 (0.4244) gate/usage_min 0.1595 (0.1591) gate/usage_std 0.1230 (0.1232) teacher/entropy 0.3649 (0.2666) teacher/usage_max 0.8506 (0.8665) teacher/usage_min 0.0501 (0.0499) teacher/usage_std 0.3663 (0.3774) nleep/row_max_mean 1192.4556 (1197.9784) nleep/row_max_std 11.0430 (14.4509) nleep/row_min_mean 1187.7725 (1192.2004) lr 1.0000e-03 eta 0:36:06
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,861
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,952
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.6%
******* Domain r best val acc:      85.3%, epoch: 27 *******
******* Domain r best val test acc: 90.7%, epoch: 27 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [28/50] batch [20/246] time 0.467 (0.507) data 0.000 (0.012) loss 1.9584 (2.0055) teacher_loss 0.9404 (0.9725) loss_zs_kd 0.0487 (0.0438) loss_oracle 0.7057 (0.7239) kd_loss 0.6408 (0.6492) acc 78.1250 (75.1562) gate/entropy 1.0214 (1.0213) gate/usage_max 0.4256 (0.4255) gate/usage_min 0.1595 (0.1594) gate/usage_std 0.1230 (0.1230) teacher/entropy 0.2673 (0.2697) teacher/usage_max 0.8352 (0.8695) teacher/usage_min 0.0520 (0.0541) teacher/usage_std 0.3558 (0.3793) nleep/row_max_mean 1194.4294 (1197.1395) nleep/row_max_std 13.8647 (13.8319) nleep/row_min_mean 1188.2856 (1191.3570) lr 9.3721e-04 eta 0:47:39
epoch [28/50] batch [40/246] time 0.080 (0.442) data 0.000 (0.006) loss 1.8981 (2.0195) teacher_loss 0.8699 (0.9711) loss_zs_kd 0.0425 (0.0442) loss_oracle 0.7318 (0.7345) kd_loss 0.6410 (0.6591) acc 75.0000 (75.0000) gate/entropy 1.0214 (1.0213) gate/usage_max 0.4258 (0.4256) gate/usage_min 0.1595 (0.1594) gate/usage_std 0.1230 (0.1230) teacher/entropy 0.2608 (0.2607) teacher/usage_max 0.8888 (0.8751) teacher/usage_min 0.0473 (0.0498) teacher/usage_std 0.3928 (0.3834) nleep/row_max_mean 1199.3160 (1197.7129) nleep/row_max_std 14.5132 (14.0301) nleep/row_min_mean 1193.4109 (1191.8269) lr 9.3721e-04 eta 0:41:25
epoch [28/50] batch [60/246] time 0.517 (0.391) data 0.000 (0.004) loss 1.9747 (2.0204) teacher_loss 0.9801 (0.9731) loss_zs_kd 0.0204 (0.0442) loss_oracle 0.7562 (0.7370) kd_loss 0.6062 (0.6568) acc 78.1250 (74.8958) gate/entropy 1.0214 (1.0213) gate/usage_max 0.4260 (0.4257) gate/usage_min 0.1595 (0.1595) gate/usage_std 0.1230 (0.1230) teacher/entropy 0.2990 (0.2619) teacher/usage_max 0.9043 (0.8749) teacher/usage_min 0.0440 (0.0497) teacher/usage_std 0.4037 (0.3832) nleep/row_max_mean 1197.3250 (1197.7428) nleep/row_max_std 14.9080 (13.8808) nleep/row_min_mean 1192.1470 (1191.8445) lr 9.3721e-04 eta 0:36:29
epoch [28/50] batch [80/246] time 0.458 (0.375) data 0.000 (0.003) loss 2.6343 (2.0398) teacher_loss 1.5792 (0.9886) loss_zs_kd 0.0410 (0.0433) loss_oracle 0.7486 (0.7381) kd_loss 0.6603 (0.6605) acc 62.5000 (73.8672) gate/entropy 1.0215 (1.0214) gate/usage_max 0.4262 (0.4258) gate/usage_min 0.1596 (0.1595) gate/usage_std 0.1229 (0.1230) teacher/entropy 0.2208 (0.2569) teacher/usage_max 0.9020 (0.8773) teacher/usage_min 0.0267 (0.0481) teacher/usage_std 0.4026 (0.3849) nleep/row_max_mean 1198.7346 (1197.7706) nleep/row_max_std 14.9885 (14.0405) nleep/row_min_mean 1192.6079 (1191.8444) lr 9.3721e-04 eta 0:34:54
epoch [28/50] batch [100/246] time 0.498 (0.370) data 0.000 (0.003) loss 1.9372 (2.0330) teacher_loss 0.9452 (0.9793) loss_zs_kd 0.0414 (0.0422) loss_oracle 0.6937 (0.7383) kd_loss 0.6245 (0.6635) acc 81.2500 (74.0312) gate/entropy 1.0216 (1.0214) gate/usage_max 0.4264 (0.4259) gate/usage_min 0.1597 (0.1595) gate/usage_std 0.1229 (0.1230) teacher/entropy 0.2780 (0.2536) teacher/usage_max 0.9045 (0.8787) teacher/usage_min 0.0457 (0.0474) teacher/usage_std 0.4039 (0.3859) nleep/row_max_mean 1197.6567 (1197.6942) nleep/row_max_std 12.0801 (14.0640) nleep/row_min_mean 1191.6775 (1191.7289) lr 9.3721e-04 eta 0:34:17
epoch [28/50] batch [120/246] time 0.445 (0.389) data 0.000 (0.002) loss 1.7465 (2.0476) teacher_loss 0.6822 (0.9958) loss_zs_kd 0.0346 (0.0422) loss_oracle 0.6683 (0.7324) kd_loss 0.7128 (0.6645) acc 84.3750 (73.6719) gate/entropy 1.0216 (1.0214) gate/usage_max 0.4267 (0.4260) gate/usage_min 0.1598 (0.1596) gate/usage_std 0.1228 (0.1230) teacher/entropy 0.1767 (0.2520) teacher/usage_max 0.9215 (0.8785) teacher/usage_min 0.0371 (0.0474) teacher/usage_std 0.4159 (0.3857) nleep/row_max_mean 1197.5542 (1197.5723) nleep/row_max_std 12.6918 (14.1116) nleep/row_min_mean 1190.7205 (1191.5642) lr 9.3721e-04 eta 0:35:56
epoch [28/50] batch [140/246] time 0.430 (0.401) data 0.000 (0.002) loss 1.7383 (2.0409) teacher_loss 0.6672 (0.9923) loss_zs_kd 0.0265 (0.0421) loss_oracle 0.7242 (0.7255) kd_loss 0.6958 (0.6648) acc 81.2500 (73.8393) gate/entropy 1.0217 (1.0214) gate/usage_max 0.4269 (0.4262) gate/usage_min 0.1599 (0.1596) gate/usage_std 0.1228 (0.1229) teacher/entropy 0.2398 (0.2534) teacher/usage_max 0.8885 (0.8774) teacher/usage_min 0.0265 (0.0474) teacher/usage_std 0.3933 (0.3850) nleep/row_max_mean 1198.7983 (1197.4948) nleep/row_max_std 16.9048 (14.2575) nleep/row_min_mean 1192.3103 (1191.4789) lr 9.3721e-04 eta 0:36:55
epoch [28/50] batch [160/246] time 0.105 (0.388) data 0.000 (0.002) loss 2.3447 (2.0439) teacher_loss 1.2935 (0.9940) loss_zs_kd 0.0500 (0.0420) loss_oracle 0.6853 (0.7232) kd_loss 0.6836 (0.6673) acc 71.8750 (73.6523) gate/entropy 1.0218 (1.0215) gate/usage_max 0.4272 (0.4263) gate/usage_min 0.1600 (0.1596) gate/usage_std 0.1227 (0.1229) teacher/entropy 0.2284 (0.2518) teacher/usage_max 0.8928 (0.8775) teacher/usage_min 0.0464 (0.0465) teacher/usage_std 0.3956 (0.3851) nleep/row_max_mean 1195.2012 (1197.6658) nleep/row_max_std 15.4168 (14.3475) nleep/row_min_mean 1188.5623 (1191.6331) lr 9.3721e-04 eta 0:35:30
epoch [28/50] batch [180/246] time 0.079 (0.382) data 0.000 (0.001) loss 1.9925 (2.0462) teacher_loss 0.9371 (0.9971) loss_zs_kd 0.0346 (0.0420) loss_oracle 0.7163 (0.7210) kd_loss 0.6799 (0.6676) acc 81.2500 (73.6285) gate/entropy 1.0218 (1.0215) gate/usage_max 0.4274 (0.4264) gate/usage_min 0.1600 (0.1597) gate/usage_std 0.1227 (0.1229) teacher/entropy 0.2356 (0.2510) teacher/usage_max 0.8466 (0.8772) teacher/usage_min 0.0634 (0.0462) teacher/usage_std 0.3631 (0.3849) nleep/row_max_mean 1199.5820 (1197.6145) nleep/row_max_std 15.0777 (14.3230) nleep/row_min_mean 1193.3445 (1191.5826) lr 9.3721e-04 eta 0:34:52
epoch [28/50] batch [200/246] time 0.078 (0.378) data 0.000 (0.001) loss 2.2609 (2.0463) teacher_loss 1.1730 (0.9964) loss_zs_kd 0.0650 (0.0420) loss_oracle 0.7371 (0.7213) kd_loss 0.6868 (0.6682) acc 65.6250 (73.5469) gate/entropy 1.0219 (1.0215) gate/usage_max 0.4277 (0.4265) gate/usage_min 0.1601 (0.1597) gate/usage_std 0.1227 (0.1229) teacher/entropy 0.1965 (0.2498) teacher/usage_max 0.9386 (0.8790) teacher/usage_min 0.0278 (0.0453) teacher/usage_std 0.4280 (0.3862) nleep/row_max_mean 1196.9620 (1197.6866) nleep/row_max_std 15.5377 (14.2708) nleep/row_min_mean 1190.3425 (1191.6280) lr 9.3721e-04 eta 0:34:23
epoch [28/50] batch [220/246] time 0.511 (0.380) data 0.000 (0.001) loss 1.9286 (2.0491) teacher_loss 0.8708 (0.9967) loss_zs_kd 0.0256 (0.0419) loss_oracle 0.7078 (0.7224) kd_loss 0.6911 (0.6703) acc 78.1250 (73.4233) gate/entropy 1.0220 (1.0216) gate/usage_max 0.4280 (0.4266) gate/usage_min 0.1602 (0.1598) gate/usage_std 0.1226 (0.1229) teacher/entropy 0.2111 (0.2462) teacher/usage_max 0.9083 (0.8812) teacher/usage_min 0.0388 (0.0445) teacher/usage_std 0.4066 (0.3877) nleep/row_max_mean 1195.1716 (1197.8230) nleep/row_max_std 12.3705 (14.2310) nleep/row_min_mean 1188.7024 (1191.7172) lr 9.3721e-04 eta 0:34:26
epoch [28/50] batch [240/246] time 0.472 (0.388) data 0.000 (0.001) loss 2.0294 (2.0573) teacher_loss 0.9413 (1.0045) loss_zs_kd 0.0343 (0.0421) loss_oracle 0.7799 (0.7231) kd_loss 0.6810 (0.6702) acc 71.8750 (73.2161) gate/entropy 1.0220 (1.0216) gate/usage_max 0.4283 (0.4267) gate/usage_min 0.1603 (0.1598) gate/usage_std 0.1226 (0.1228) teacher/entropy 0.2623 (0.2457) teacher/usage_max 0.8734 (0.8819) teacher/usage_min 0.0308 (0.0443) teacher/usage_std 0.3828 (0.3882) nleep/row_max_mean 1197.1484 (1197.9167) nleep/row_max_std 12.8169 (14.2147) nleep/row_min_mean 1191.1340 (1191.7936) lr 9.3721e-04 eta 0:35:02
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,860
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,956
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.8%
******* Domain r best val acc:      85.3%, epoch: 27 *******
******* Domain r best val test acc: 90.7%, epoch: 27 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [29/50] batch [20/246] time 0.212 (0.352) data 0.000 (0.012) loss 2.1186 (2.1179) teacher_loss 1.1062 (1.0417) loss_zs_kd 0.0308 (0.0444) loss_oracle 0.7089 (0.7329) kd_loss 0.6426 (0.6876) acc 65.6250 (72.6562) gate/entropy 1.0221 (1.0221) gate/usage_max 0.4287 (0.4286) gate/usage_min 0.1604 (0.1604) gate/usage_std 0.1225 (0.1225) teacher/entropy 0.2681 (0.2198) teacher/usage_max 0.8969 (0.8914) teacher/usage_min 0.0400 (0.0398) teacher/usage_std 0.3986 (0.3949) nleep/row_max_mean 1199.2502 (1198.6677) nleep/row_max_std 14.6989 (14.3777) nleep/row_min_mean 1193.0529 (1192.2734) lr 8.7467e-04 eta 0:31:37
epoch [29/50] batch [40/246] time 0.482 (0.330) data 0.000 (0.006) loss 1.9260 (2.0479) teacher_loss 0.8482 (0.9777) loss_zs_kd 0.0426 (0.0445) loss_oracle 0.7247 (0.7291) kd_loss 0.6942 (0.6834) acc 75.0000 (74.4531) gate/entropy 1.0223 (1.0222) gate/usage_max 0.4291 (0.4288) gate/usage_min 0.1606 (0.1605) gate/usage_std 0.1224 (0.1224) teacher/entropy 0.1995 (0.2234) teacher/usage_max 0.9010 (0.8906) teacher/usage_min 0.0459 (0.0414) teacher/usage_std 0.4014 (0.3943) nleep/row_max_mean 1200.2922 (1198.1089) nleep/row_max_std 13.3825 (14.0474) nleep/row_min_mean 1193.0957 (1191.6737) lr 8.7467e-04 eta 0:29:31
epoch [29/50] batch [60/246] time 0.415 (0.322) data 0.000 (0.004) loss 2.7588 (2.0592) teacher_loss 1.6490 (0.9945) loss_zs_kd 0.0543 (0.0435) loss_oracle 0.7478 (0.7296) kd_loss 0.7088 (0.6781) acc 56.2500 (73.9062) gate/entropy 1.0223 (1.0222) gate/usage_max 0.4294 (0.4289) gate/usage_min 0.1606 (0.1605) gate/usage_std 0.1224 (0.1224) teacher/entropy 0.2432 (0.2312) teacher/usage_max 0.8488 (0.8883) teacher/usage_min 0.0449 (0.0428) teacher/usage_std 0.3653 (0.3926) nleep/row_max_mean 1197.9980 (1198.2259) nleep/row_max_std 15.3727 (13.8463) nleep/row_min_mean 1190.8845 (1191.8260) lr 8.7467e-04 eta 0:28:43
epoch [29/50] batch [80/246] time 0.109 (0.280) data 0.000 (0.003) loss 1.6537 (2.0604) teacher_loss 0.5862 (0.9925) loss_zs_kd 0.0373 (0.0430) loss_oracle 0.7299 (0.7300) kd_loss 0.6840 (0.6813) acc 84.3750 (73.8672) gate/entropy 1.0225 (1.0223) gate/usage_max 0.4298 (0.4291) gate/usage_min 0.1608 (0.1606) gate/usage_std 0.1223 (0.1224) teacher/entropy 0.2089 (0.2273) teacher/usage_max 0.9279 (0.8898) teacher/usage_min 0.0240 (0.0415) teacher/usage_std 0.4205 (0.3937) nleep/row_max_mean 1196.7491 (1198.3020) nleep/row_max_std 12.7706 (13.8644) nleep/row_min_mean 1190.2595 (1191.8605) lr 8.7467e-04 eta 0:24:54
epoch [29/50] batch [100/246] time 0.096 (0.244) data 0.000 (0.003) loss 2.1696 (2.0677) teacher_loss 1.1303 (1.0025) loss_zs_kd 0.0294 (0.0428) loss_oracle 0.7109 (0.7279) kd_loss 0.6691 (0.6797) acc 71.8750 (73.4062) gate/entropy 1.0226 (1.0223) gate/usage_max 0.4302 (0.4293) gate/usage_min 0.1610 (0.1607) gate/usage_std 0.1222 (0.1224) teacher/entropy 0.2662 (0.2298) teacher/usage_max 0.8929 (0.8899) teacher/usage_min 0.0144 (0.0408) teacher/usage_std 0.3970 (0.3938) nleep/row_max_mean 1195.5449 (1197.9939) nleep/row_max_std 12.7617 (13.7313) nleep/row_min_mean 1189.5350 (1191.6010) lr 8.7467e-04 eta 0:21:36
epoch [29/50] batch [120/246] time 0.098 (0.220) data 0.000 (0.002) loss 2.1335 (2.0553) teacher_loss 1.0417 (0.9930) loss_zs_kd 0.0475 (0.0424) loss_oracle 0.7673 (0.7280) kd_loss 0.6844 (0.6771) acc 75.0000 (73.6198) gate/entropy 1.0227 (1.0224) gate/usage_max 0.4307 (0.4295) gate/usage_min 0.1611 (0.1607) gate/usage_std 0.1221 (0.1223) teacher/entropy 0.2465 (0.2335) teacher/usage_max 0.8554 (0.8871) teacher/usage_min 0.0577 (0.0414) teacher/usage_std 0.3693 (0.3919) nleep/row_max_mean 1201.1383 (1197.9379) nleep/row_max_std 13.4302 (13.5761) nleep/row_min_mean 1194.8715 (1191.5680) lr 8.7467e-04 eta 0:19:25
epoch [29/50] batch [140/246] time 0.108 (0.202) data 0.000 (0.002) loss 2.4111 (2.0477) teacher_loss 1.3478 (0.9869) loss_zs_kd 0.0432 (0.0421) loss_oracle 0.7500 (0.7297) kd_loss 0.6667 (0.6749) acc 56.2500 (73.8616) gate/entropy 1.0228 (1.0224) gate/usage_max 0.4311 (0.4297) gate/usage_min 0.1613 (0.1608) gate/usage_std 0.1220 (0.1223) teacher/entropy 0.2315 (0.2359) teacher/usage_max 0.9149 (0.8853) teacher/usage_min 0.0290 (0.0423) teacher/usage_std 0.4114 (0.3906) nleep/row_max_mean 1194.4738 (1197.6203) nleep/row_max_std 12.5262 (13.5178) nleep/row_min_mean 1188.2241 (1191.2805) lr 8.7467e-04 eta 0:17:47
epoch [29/50] batch [160/246] time 0.496 (0.232) data 0.000 (0.002) loss 1.8828 (2.0438) teacher_loss 0.8379 (0.9857) loss_zs_kd 0.0294 (0.0417) loss_oracle 0.7103 (0.7280) kd_loss 0.6750 (0.6733) acc 75.0000 (73.8672) gate/entropy 1.0231 (1.0225) gate/usage_max 0.4317 (0.4299) gate/usage_min 0.1616 (0.1609) gate/usage_std 0.1219 (0.1222) teacher/entropy 0.2224 (0.2375) teacher/usage_max 0.8901 (0.8839) teacher/usage_min 0.0548 (0.0427) teacher/usage_std 0.3937 (0.3896) nleep/row_max_mean 1194.8728 (1197.5656) nleep/row_max_std 13.0301 (13.4484) nleep/row_min_mean 1188.0696 (1191.2281) lr 8.7467e-04 eta 0:20:20
epoch [29/50] batch [180/246] time 0.453 (0.258) data 0.000 (0.002) loss 2.6894 (2.0485) teacher_loss 1.6196 (0.9915) loss_zs_kd 0.0625 (0.0415) loss_oracle 0.7160 (0.7264) kd_loss 0.6806 (0.6731) acc 59.3750 (73.7674) gate/entropy 1.0231 (1.0226) gate/usage_max 0.4322 (0.4301) gate/usage_min 0.1617 (0.1610) gate/usage_std 0.1218 (0.1222) teacher/entropy 0.2144 (0.2393) teacher/usage_max 0.9107 (0.8825) teacher/usage_min 0.0344 (0.0426) teacher/usage_std 0.4084 (0.3887) nleep/row_max_mean 1196.8425 (1197.4290) nleep/row_max_std 17.0758 (13.4958) nleep/row_min_mean 1189.7460 (1191.0879) lr 8.7467e-04 eta 0:22:32
epoch [29/50] batch [200/246] time 0.494 (0.280) data 0.000 (0.001) loss 1.7448 (2.0421) teacher_loss 0.6611 (0.9856) loss_zs_kd 0.0485 (0.0416) loss_oracle 0.7555 (0.7252) kd_loss 0.6818 (0.6731) acc 81.2500 (73.8281) gate/entropy 1.0232 (1.0226) gate/usage_max 0.4327 (0.4304) gate/usage_min 0.1618 (0.1610) gate/usage_std 0.1218 (0.1222) teacher/entropy 0.2250 (0.2391) teacher/usage_max 0.9090 (0.8826) teacher/usage_min 0.0221 (0.0419) teacher/usage_std 0.4075 (0.3888) nleep/row_max_mean 1195.0974 (1197.4467) nleep/row_max_std 14.7990 (13.5391) nleep/row_min_mean 1188.9175 (1191.0985) lr 8.7467e-04 eta 0:24:18
epoch [29/50] batch [220/246] time 0.437 (0.271) data 0.000 (0.001) loss 2.0140 (2.0376) teacher_loss 0.9173 (0.9817) loss_zs_kd 0.0344 (0.0415) loss_oracle 0.7406 (0.7230) kd_loss 0.7092 (0.6736) acc 75.0000 (73.8210) gate/entropy 1.0235 (1.0227) gate/usage_max 0.4334 (0.4306) gate/usage_min 0.1622 (0.1611) gate/usage_std 0.1216 (0.1221) teacher/entropy 0.1939 (0.2390) teacher/usage_max 0.8992 (0.8821) teacher/usage_min 0.0351 (0.0417) teacher/usage_std 0.4003 (0.3884) nleep/row_max_mean 1197.4473 (1197.3504) nleep/row_max_std 11.8314 (13.5220) nleep/row_min_mean 1190.7687 (1191.0011) lr 8.7467e-04 eta 0:23:28
epoch [29/50] batch [240/246] time 0.079 (0.271) data 0.000 (0.001) loss 1.8584 (2.0283) teacher_loss 0.8711 (0.9731) loss_zs_kd 0.0296 (0.0410) loss_oracle 0.6710 (0.7214) kd_loss 0.6370 (0.6740) acc 78.1250 (73.9974) gate/entropy 1.0236 (1.0228) gate/usage_max 0.4341 (0.4309) gate/usage_min 0.1624 (0.1612) gate/usage_std 0.1215 (0.1221) teacher/entropy 0.2975 (0.2383) teacher/usage_max 0.8461 (0.8825) teacher/usage_min 0.0563 (0.0416) teacher/usage_std 0.3630 (0.3887) nleep/row_max_mean 1200.4314 (1197.3825) nleep/row_max_std 13.9808 (13.4555) nleep/row_min_mean 1194.4098 (1191.0232) lr 8.7467e-04 eta 0:23:23
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,856
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,963
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 89.9%
******* Domain r best val acc:      85.3%, epoch: 27 *******
******* Domain r best val test acc: 90.7%, epoch: 27 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [30/50] batch [20/246] time 0.498 (0.492) data 0.000 (0.011) loss 1.7920 (2.0537) teacher_loss 0.7427 (1.0051) loss_zs_kd 0.0656 (0.0472) loss_oracle 0.7412 (0.7152) kd_loss 0.6460 (0.6674) acc 75.0000 (72.9688) gate/entropy 1.0239 (1.0238) gate/usage_max 0.4350 (0.4347) gate/usage_min 0.1627 (0.1626) gate/usage_std 0.1214 (0.1214) teacher/entropy 0.2481 (0.2417) teacher/usage_max 0.8900 (0.8856) teacher/usage_min 0.0513 (0.0381) teacher/usage_std 0.3936 (0.3910) nleep/row_max_mean 1194.4180 (1197.7509) nleep/row_max_std 14.1015 (14.6443) nleep/row_min_mean 1188.7200 (1191.4094) lr 8.1262e-04 eta 0:42:10
epoch [30/50] batch [40/246] time 0.497 (0.482) data 0.000 (0.006) loss 1.7488 (1.9936) teacher_loss 0.7262 (0.9580) loss_zs_kd 0.0273 (0.0440) loss_oracle 0.7130 (0.7079) kd_loss 0.6524 (0.6597) acc 78.1250 (74.2188) gate/entropy 1.0240 (1.0239) gate/usage_max 0.4358 (0.4350) gate/usage_min 0.1630 (0.1627) gate/usage_std 0.1213 (0.1214) teacher/entropy 0.2425 (0.2547) teacher/usage_max 0.8872 (0.8740) teacher/usage_min 0.0518 (0.0428) teacher/usage_std 0.3917 (0.3828) nleep/row_max_mean 1200.5237 (1197.8984) nleep/row_max_std 16.1565 (14.7132) nleep/row_min_mean 1194.6527 (1191.6463) lr 8.1262e-04 eta 0:41:08
epoch [30/50] batch [60/246] time 0.084 (0.423) data 0.000 (0.004) loss 2.0090 (2.0149) teacher_loss 1.0254 (0.9841) loss_zs_kd 0.0439 (0.0442) loss_oracle 0.6649 (0.7077) kd_loss 0.6292 (0.6549) acc 71.8750 (73.9062) gate/entropy 1.0242 (1.0240) gate/usage_max 0.4366 (0.4354) gate/usage_min 0.1633 (0.1629) gate/usage_std 0.1212 (0.1213) teacher/entropy 0.2837 (0.2633) teacher/usage_max 0.8817 (0.8645) teacher/usage_min 0.0360 (0.0479) teacher/usage_std 0.3882 (0.3762) nleep/row_max_mean 1200.6885 (1197.8778) nleep/row_max_std 13.7892 (14.2948) nleep/row_min_mean 1194.5045 (1191.6736) lr 8.1262e-04 eta 0:36:01
epoch [30/50] batch [80/246] time 0.086 (0.401) data 0.000 (0.003) loss 1.9003 (2.0094) teacher_loss 0.8327 (0.9881) loss_zs_kd 0.0447 (0.0440) loss_oracle 0.6743 (0.6984) kd_loss 0.7081 (0.6501) acc 71.8750 (73.7109) gate/entropy 1.0244 (1.0241) gate/usage_max 0.4374 (0.4358) gate/usage_min 0.1636 (0.1630) gate/usage_std 0.1211 (0.1213) teacher/entropy 0.2144 (0.2712) teacher/usage_max 0.8720 (0.8614) teacher/usage_min 0.0340 (0.0474) teacher/usage_std 0.3817 (0.3740) nleep/row_max_mean 1201.7567 (1197.6992) nleep/row_max_std 14.1845 (14.3045) nleep/row_min_mean 1194.9045 (1191.5500) lr 8.1262e-04 eta 0:34:00
epoch [30/50] batch [100/246] time 0.444 (0.392) data 0.000 (0.002) loss 1.5526 (2.0128) teacher_loss 0.5401 (0.9967) loss_zs_kd 0.0371 (0.0434) loss_oracle 0.6617 (0.6930) kd_loss 0.6632 (0.6479) acc 87.5000 (73.8438) gate/entropy 1.0248 (1.0242) gate/usage_max 0.4385 (0.4363) gate/usage_min 0.1641 (0.1632) gate/usage_std 0.1208 (0.1212) teacher/entropy 0.2987 (0.2759) teacher/usage_max 0.8369 (0.8591) teacher/usage_min 0.0260 (0.0464) teacher/usage_std 0.3590 (0.3726) nleep/row_max_mean 1202.5557 (1197.6521) nleep/row_max_std 16.4033 (14.3151) nleep/row_min_mean 1196.6238 (1191.5308) lr 8.1262e-04 eta 0:33:07
epoch [30/50] batch [120/246] time 0.497 (0.390) data 0.000 (0.002) loss 1.7098 (2.0276) teacher_loss 0.7783 (1.0160) loss_zs_kd 0.0249 (0.0428) loss_oracle 0.6530 (0.6902) kd_loss 0.5926 (0.6452) acc 84.3750 (73.3073) gate/entropy 1.0250 (1.0243) gate/usage_max 0.4395 (0.4367) gate/usage_min 0.1644 (0.1634) gate/usage_std 0.1208 (0.1211) teacher/entropy 0.3057 (0.2797) teacher/usage_max 0.8601 (0.8561) teacher/usage_min 0.0699 (0.0480) teacher/usage_std 0.3725 (0.3704) nleep/row_max_mean 1199.4326 (1197.5657) nleep/row_max_std 11.7752 (14.4103) nleep/row_min_mean 1193.4580 (1191.4727) lr 8.1262e-04 eta 0:32:46
epoch [30/50] batch [140/246] time 0.497 (0.401) data 0.000 (0.002) loss 1.6264 (2.0143) teacher_loss 0.6927 (1.0046) loss_zs_kd 0.0542 (0.0425) loss_oracle 0.6483 (0.6893) kd_loss 0.5824 (0.6438) acc 87.5000 (73.7277) gate/entropy 1.0253 (1.0244) gate/usage_max 0.4407 (0.4372) gate/usage_min 0.1649 (0.1635) gate/usage_std 0.1206 (0.1211) teacher/entropy 0.3565 (0.2806) teacher/usage_max 0.8312 (0.8551) teacher/usage_min 0.0533 (0.0483) teacher/usage_std 0.3529 (0.3697) nleep/row_max_mean 1198.8894 (1197.6614) nleep/row_max_std 10.9147 (14.3374) nleep/row_min_mean 1193.3379 (1191.5870) lr 8.1262e-04 eta 0:33:37
epoch [30/50] batch [160/246] time 0.495 (0.410) data 0.000 (0.002) loss 1.8339 (2.0090) teacher_loss 0.8055 (1.0013) loss_zs_kd 0.0152 (0.0421) loss_oracle 0.7055 (0.6888) kd_loss 0.6680 (0.6422) acc 81.2500 (73.9062) gate/entropy 1.0255 (1.0245) gate/usage_max 0.4419 (0.4377) gate/usage_min 0.1653 (0.1637) gate/usage_std 0.1205 (0.1210) teacher/entropy 0.1856 (0.2815) teacher/usage_max 0.9501 (0.8547) teacher/usage_min 0.0140 (0.0482) teacher/usage_std 0.4362 (0.3695) nleep/row_max_mean 1201.2744 (1197.7826) nleep/row_max_std 15.1472 (14.4248) nleep/row_min_mean 1194.8900 (1191.6966) lr 8.1262e-04 eta 0:34:13
epoch [30/50] batch [180/246] time 0.108 (0.391) data 0.000 (0.001) loss 1.5112 (2.0068) teacher_loss 0.5778 (0.9984) loss_zs_kd 0.0239 (0.0425) loss_oracle 0.6474 (0.6889) kd_loss 0.5978 (0.6427) acc 81.2500 (74.0972) gate/entropy 1.0257 (1.0246) gate/usage_max 0.4433 (0.4382) gate/usage_min 0.1658 (0.1639) gate/usage_std 0.1204 (0.1209) teacher/entropy 0.3477 (0.2819) teacher/usage_max 0.7881 (0.8525) teacher/usage_min 0.0894 (0.0486) teacher/usage_std 0.3219 (0.3680) nleep/row_max_mean 1199.6013 (1197.7502) nleep/row_max_std 14.6822 (14.3323) nleep/row_min_mean 1193.7185 (1191.6696) lr 8.1262e-04 eta 0:32:28
epoch [30/50] batch [200/246] time 0.084 (0.381) data 0.000 (0.001) loss 1.9079 (1.9997) teacher_loss 0.8439 (0.9924) loss_zs_kd 0.0481 (0.0425) loss_oracle 0.7032 (0.6870) kd_loss 0.6883 (0.6425) acc 75.0000 (74.2812) gate/entropy 1.0260 (1.0248) gate/usage_max 0.4448 (0.4388) gate/usage_min 0.1664 (0.1642) gate/usage_std 0.1203 (0.1209) teacher/entropy 0.2364 (0.2820) teacher/usage_max 0.8408 (0.8508) teacher/usage_min 0.0495 (0.0491) teacher/usage_std 0.3597 (0.3668) nleep/row_max_mean 1200.3477 (1197.8112) nleep/row_max_std 11.0824 (14.2262) nleep/row_min_mean 1193.8937 (1191.7349) lr 8.1262e-04 eta 0:31:30
epoch [30/50] batch [220/246] time 0.078 (0.379) data 0.000 (0.001) loss 2.2254 (2.0000) teacher_loss 1.2445 (0.9953) loss_zs_kd 0.0383 (0.0420) loss_oracle 0.6671 (0.6848) kd_loss 0.6282 (0.6413) acc 65.6250 (74.2898) gate/entropy 1.0263 (1.0249) gate/usage_max 0.4465 (0.4394) gate/usage_min 0.1669 (0.1644) gate/usage_std 0.1202 (0.1208) teacher/entropy 0.2885 (0.2829) teacher/usage_max 0.8266 (0.8498) teacher/usage_min 0.0718 (0.0493) teacher/usage_std 0.3490 (0.3661) nleep/row_max_mean 1194.9615 (1197.8169) nleep/row_max_std 10.8321 (14.1098) nleep/row_min_mean 1189.1594 (1191.7601) lr 8.1262e-04 eta 0:31:16
epoch [30/50] batch [240/246] time 0.520 (0.385) data 0.000 (0.001) loss 1.4784 (1.9927) teacher_loss 0.5116 (0.9927) loss_zs_kd 0.0231 (0.0421) loss_oracle 0.6548 (0.6814) kd_loss 0.6278 (0.6382) acc 87.5000 (74.2969) gate/entropy 1.0266 (1.0250) gate/usage_max 0.4482 (0.4401) gate/usage_min 0.1676 (0.1646) gate/usage_std 0.1201 (0.1208) teacher/entropy 0.3505 (0.2861) teacher/usage_max 0.7525 (0.8476) teacher/usage_min 0.0818 (0.0504) teacher/usage_std 0.2984 (0.3646) nleep/row_max_mean 1198.9817 (1197.9057) nleep/row_max_std 10.4791 (14.0451) nleep/row_min_mean 1193.5601 (1191.8680) lr 8.1262e-04 eta 0:31:37
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,859
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.7%
******* Domain r best val acc:      85.3%, epoch: 27 *******
******* Domain r best val test acc: 90.7%, epoch: 27 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [31/50] batch [20/246] time 0.082 (0.385) data 0.000 (0.012) loss 1.6316 (1.8316) teacher_loss 0.6375 (0.8724) loss_zs_kd 0.0441 (0.0417) loss_oracle 0.6874 (0.6488) kd_loss 0.6284 (0.6139) acc 84.3750 (77.3438) gate/entropy 1.0270 (1.0268) gate/usage_max 0.4506 (0.4497) gate/usage_min 0.1686 (0.1682) gate/usage_std 0.1199 (0.1200) teacher/entropy 0.3325 (0.3035) teacher/usage_max 0.8001 (0.8275) teacher/usage_min 0.0401 (0.0611) teacher/usage_std 0.3336 (0.3503) nleep/row_max_mean 1198.0979 (1199.1054) nleep/row_max_std 12.4405 (13.5063) nleep/row_min_mean 1192.4922 (1193.1971) lr 7.5131e-04 eta 0:31:25
epoch [31/50] batch [40/246] time 0.475 (0.340) data 0.000 (0.006) loss 1.9741 (1.9046) teacher_loss 1.0735 (0.9419) loss_zs_kd 0.0412 (0.0452) loss_oracle 0.6281 (0.6580) kd_loss 0.5660 (0.6111) acc 75.0000 (75.7812) gate/entropy 1.0272 (1.0270) gate/usage_max 0.4528 (0.4507) gate/usage_min 0.1693 (0.1686) gate/usage_std 0.1199 (0.1200) teacher/entropy 0.3816 (0.3062) teacher/usage_max 0.8171 (0.8314) teacher/usage_min 0.0309 (0.0550) teacher/usage_std 0.3456 (0.3533) nleep/row_max_mean 1196.5419 (1198.9150) nleep/row_max_std 13.5580 (13.4841) nleep/row_min_mean 1191.3966 (1192.9740) lr 7.5131e-04 eta 0:27:40
epoch [31/50] batch [60/246] time 0.476 (0.323) data 0.000 (0.004) loss 1.9688 (1.9211) teacher_loss 0.9564 (0.9654) loss_zs_kd 0.0549 (0.0437) loss_oracle 0.6299 (0.6548) kd_loss 0.6700 (0.6065) acc 71.8750 (74.8438) gate/entropy 1.0274 (1.0271) gate/usage_max 0.4551 (0.4518) gate/usage_min 0.1701 (0.1690) gate/usage_std 0.1200 (0.1199) teacher/entropy 0.2905 (0.3100) teacher/usage_max 0.7534 (0.8285) teacher/usage_min 0.0881 (0.0560) teacher/usage_std 0.2984 (0.3513) nleep/row_max_mean 1201.5376 (1198.9135) nleep/row_max_std 15.5975 (13.7179) nleep/row_min_mean 1195.1743 (1193.0077) lr 7.5131e-04 eta 0:26:08
epoch [31/50] batch [80/246] time 0.516 (0.351) data 0.000 (0.003) loss 1.4435 (1.9010) teacher_loss 0.5612 (0.9516) loss_zs_kd 0.0520 (0.0433) loss_oracle 0.6114 (0.6508) kd_loss 0.5506 (0.6024) acc 87.5000 (75.3906) gate/entropy 1.0278 (1.0272) gate/usage_max 0.4574 (0.4529) gate/usage_min 0.1712 (0.1694) gate/usage_std 0.1199 (0.1199) teacher/entropy 0.3489 (0.3154) teacher/usage_max 0.8037 (0.8237) teacher/usage_min 0.0973 (0.0581) teacher/usage_std 0.3326 (0.3480) nleep/row_max_mean 1193.9120 (1198.6263) nleep/row_max_std 12.9891 (13.6574) nleep/row_min_mean 1188.5566 (1192.7615) lr 7.5131e-04 eta 0:28:19
epoch [31/50] batch [100/246] time 0.509 (0.377) data 0.000 (0.003) loss 1.3961 (1.9029) teacher_loss 0.4819 (0.9543) loss_zs_kd 0.0357 (0.0432) loss_oracle 0.6363 (0.6502) kd_loss 0.5782 (0.6019) acc 90.6250 (75.1875) gate/entropy 1.0280 (1.0273) gate/usage_max 0.4600 (0.4541) gate/usage_min 0.1722 (0.1699) gate/usage_std 0.1200 (0.1200) teacher/entropy 0.3816 (0.3189) teacher/usage_max 0.7026 (0.8174) teacher/usage_min 0.1428 (0.0596) teacher/usage_std 0.2612 (0.3437) nleep/row_max_mean 1197.2006 (1198.4851) nleep/row_max_std 21.1237 (13.9887) nleep/row_min_mean 1192.0388 (1192.6504) lr 7.5131e-04 eta 0:30:15
epoch [31/50] batch [120/246] time 0.498 (0.395) data 0.000 (0.002) loss 1.6940 (1.9046) teacher_loss 0.8100 (0.9615) loss_zs_kd 0.0342 (0.0426) loss_oracle 0.5934 (0.6473) kd_loss 0.5701 (0.5981) acc 68.7500 (74.7656) gate/entropy 1.0281 (1.0274) gate/usage_max 0.4629 (0.4554) gate/usage_min 0.1732 (0.1703) gate/usage_std 0.1202 (0.1200) teacher/entropy 0.3595 (0.3270) teacher/usage_max 0.7784 (0.8115) teacher/usage_min 0.0784 (0.0578) teacher/usage_std 0.3158 (0.3401) nleep/row_max_mean 1196.5016 (1198.4245) nleep/row_max_std 17.7345 (14.1382) nleep/row_min_mean 1191.0822 (1192.6366) lr 7.5131e-04 eta 0:31:37
epoch [31/50] batch [140/246] time 0.430 (0.375) data 0.000 (0.002) loss 2.0369 (1.9114) teacher_loss 1.1031 (0.9750) loss_zs_kd 0.0760 (0.0430) loss_oracle 0.6255 (0.6426) kd_loss 0.5830 (0.5936) acc 68.7500 (74.2857) gate/entropy 1.0281 (1.0275) gate/usage_max 0.4663 (0.4567) gate/usage_min 0.1743 (0.1708) gate/usage_std 0.1206 (0.1201) teacher/entropy 0.3285 (0.3318) teacher/usage_max 0.8110 (0.8079) teacher/usage_min 0.0518 (0.0588) teacher/usage_std 0.3395 (0.3376) nleep/row_max_mean 1200.8298 (1198.4306) nleep/row_max_std 13.2982 (14.1009) nleep/row_min_mean 1195.0525 (1192.6753) lr 7.5131e-04 eta 0:29:51
epoch [31/50] batch [160/246] time 0.090 (0.365) data 0.000 (0.002) loss 1.5549 (1.8939) teacher_loss 0.6061 (0.9617) loss_zs_kd 0.0287 (0.0431) loss_oracle 0.6761 (0.6395) kd_loss 0.5965 (0.5909) acc 87.5000 (74.6289) gate/entropy 1.0280 (1.0276) gate/usage_max 0.4697 (0.4581) gate/usage_min 0.1755 (0.1713) gate/usage_std 0.1211 (0.1202) teacher/entropy 0.3177 (0.3340) teacher/usage_max 0.7964 (0.8051) teacher/usage_min 0.0594 (0.0594) teacher/usage_std 0.3293 (0.3356) nleep/row_max_mean 1202.9648 (1198.5112) nleep/row_max_std 14.1702 (14.2026) nleep/row_min_mean 1197.2090 (1192.7504) lr 7.5131e-04 eta 0:28:56
epoch [31/50] batch [180/246] time 0.462 (0.364) data 0.000 (0.001) loss 2.1151 (1.8746) teacher_loss 1.2332 (0.9509) loss_zs_kd 0.0363 (0.0430) loss_oracle 0.6118 (0.6349) kd_loss 0.5578 (0.5847) acc 68.7500 (74.8611) gate/entropy 1.0279 (1.0276) gate/usage_max 0.4732 (0.4596) gate/usage_min 0.1769 (0.1719) gate/usage_std 0.1215 (0.1203) teacher/entropy 0.3727 (0.3396) teacher/usage_max 0.7709 (0.8016) teacher/usage_min 0.0631 (0.0610) teacher/usage_std 0.3123 (0.3331) nleep/row_max_mean 1195.0903 (1198.4512) nleep/row_max_std 16.1551 (14.2434) nleep/row_min_mean 1189.9270 (1192.7404) lr 7.5131e-04 eta 0:28:45
epoch [31/50] batch [200/246] time 0.478 (0.365) data 0.000 (0.001) loss 1.8492 (1.8758) teacher_loss 0.9790 (0.9544) loss_zs_kd 0.0176 (0.0431) loss_oracle 0.6049 (0.6322) kd_loss 0.5589 (0.5836) acc 68.7500 (74.7031) gate/entropy 1.0277 (1.0277) gate/usage_max 0.4768 (0.4612) gate/usage_min 0.1783 (0.1725) gate/usage_std 0.1221 (0.1204) teacher/entropy 0.4079 (0.3407) teacher/usage_max 0.7503 (0.7988) teacher/usage_min 0.0293 (0.0609) teacher/usage_std 0.3050 (0.3314) nleep/row_max_mean 1196.0310 (1198.4051) nleep/row_max_std 12.0435 (14.1956) nleep/row_min_mean 1190.8252 (1192.7027) lr 7.5131e-04 eta 0:28:40
epoch [31/50] batch [220/246] time 0.511 (0.375) data 0.000 (0.001) loss 1.7234 (1.8803) teacher_loss 0.8993 (0.9633) loss_zs_kd 0.0506 (0.0430) loss_oracle 0.5793 (0.6290) kd_loss 0.5091 (0.5810) acc 78.1250 (74.4886) gate/entropy 1.0272 (1.0276) gate/usage_max 0.4811 (0.4628) gate/usage_min 0.1798 (0.1731) gate/usage_std 0.1231 (0.1206) teacher/entropy 0.4112 (0.3426) teacher/usage_max 0.7855 (0.7972) teacher/usage_min 0.0350 (0.0603) teacher/usage_std 0.3251 (0.3304) nleep/row_max_mean 1194.0269 (1198.4183) nleep/row_max_std 14.8586 (14.2414) nleep/row_min_mean 1188.8022 (1192.7290) lr 7.5131e-04 eta 0:29:23
epoch [31/50] batch [240/246] time 0.466 (0.385) data 0.000 (0.001) loss 1.9235 (1.8779) teacher_loss 1.0912 (0.9657) loss_zs_kd 0.0262 (0.0428) loss_oracle 0.5992 (0.6263) kd_loss 0.5196 (0.5777) acc 71.8750 (74.4531) gate/entropy 1.0267 (1.0276) gate/usage_max 0.4855 (0.4645) gate/usage_min 0.1814 (0.1737) gate/usage_std 0.1241 (0.1209) teacher/entropy 0.3557 (0.3449) teacher/usage_max 0.8081 (0.7955) teacher/usage_min 0.0593 (0.0598) teacher/usage_std 0.3371 (0.3294) nleep/row_max_mean 1198.0737 (1198.4335) nleep/row_max_std 19.1876 (14.3668) nleep/row_min_mean 1192.1934 (1192.7535) lr 7.5131e-04 eta 0:30:02
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,862
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 84.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,963
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 89.9%
******* Domain r best val acc:      85.3%, epoch: 31 *******
******* Domain r best val test acc: 91.0%, epoch: 31 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [32/50] batch [20/246] time 0.481 (0.399) data 0.000 (0.015) loss 1.5429 (1.7909) teacher_loss 0.6864 (0.9351) loss_zs_kd 0.0458 (0.0470) loss_oracle 0.5855 (0.5857) kd_loss 0.5409 (0.5395) acc 78.1250 (74.5312) gate/entropy 1.0256 (1.0261) gate/usage_max 0.4912 (0.4890) gate/usage_min 0.1834 (0.1827) gate/usage_std 0.1258 (0.1251) teacher/entropy 0.3227 (0.3901) teacher/usage_max 0.8208 (0.7453) teacher/usage_min 0.0408 (0.0621) teacher/usage_std 0.3470 (0.2972) nleep/row_max_mean 1196.6317 (1197.1702) nleep/row_max_std 10.8755 (14.5935) nleep/row_min_mean 1190.5132 (1191.6432) lr 6.9098e-04 eta 0:30:57
epoch [32/50] batch [40/246] time 0.562 (0.448) data 0.000 (0.007) loss 1.5206 (1.8303) teacher_loss 0.7167 (0.9818) loss_zs_kd 0.0422 (0.0451) loss_oracle 0.5677 (0.5805) kd_loss 0.4990 (0.5356) acc 75.0000 (74.2188) gate/entropy 1.0248 (1.0257) gate/usage_max 0.4952 (0.4910) gate/usage_min 0.1850 (0.1835) gate/usage_std 0.1270 (0.1257) teacher/entropy 0.3353 (0.3838) teacher/usage_max 0.8408 (0.7542) teacher/usage_min 0.0455 (0.0582) teacher/usage_std 0.3599 (0.3034) nleep/row_max_mean 1199.9312 (1197.0015) nleep/row_max_std 13.8906 (14.4823) nleep/row_min_mean 1194.0725 (1191.3489) lr 6.9098e-04 eta 0:34:33
epoch [32/50] batch [60/246] time 0.442 (0.459) data 0.000 (0.005) loss 1.7665 (1.8337) teacher_loss 0.9442 (0.9844) loss_zs_kd 0.0320 (0.0469) loss_oracle 0.5397 (0.5772) kd_loss 0.5365 (0.5372) acc 75.0000 (74.0625) gate/entropy 1.0237 (1.0252) gate/usage_max 0.4995 (0.4932) gate/usage_min 0.1865 (0.1842) gate/usage_std 0.1285 (0.1264) teacher/entropy 0.3997 (0.3826) teacher/usage_max 0.7009 (0.7503) teacher/usage_min 0.0996 (0.0582) teacher/usage_std 0.2631 (0.3007) nleep/row_max_mean 1197.5707 (1197.0181) nleep/row_max_std 10.8756 (14.1615) nleep/row_min_mean 1192.1233 (1191.3427) lr 6.9098e-04 eta 0:35:16
epoch [32/50] batch [80/246] time 0.087 (0.421) data 0.000 (0.004) loss 1.6336 (1.8020) teacher_loss 0.8098 (0.9627) loss_zs_kd 0.0312 (0.0474) loss_oracle 0.5987 (0.5701) kd_loss 0.5089 (0.5305) acc 78.1250 (74.6875) gate/entropy 1.0225 (1.0246) gate/usage_max 0.5036 (0.4953) gate/usage_min 0.1881 (0.1850) gate/usage_std 0.1300 (0.1271) teacher/entropy 0.4386 (0.3890) teacher/usage_max 0.7182 (0.7470) teacher/usage_min 0.0320 (0.0584) teacher/usage_std 0.2863 (0.2987) nleep/row_max_mean 1194.9731 (1196.8371) nleep/row_max_std 14.7183 (13.9712) nleep/row_min_mean 1189.6587 (1191.2132) lr 6.9098e-04 eta 0:32:13
epoch [32/50] batch [100/246] time 0.079 (0.403) data 0.000 (0.003) loss 1.8307 (1.8143) teacher_loss 0.9900 (0.9808) loss_zs_kd 0.0548 (0.0465) loss_oracle 0.5245 (0.5631) kd_loss 0.5511 (0.5288) acc 81.2500 (74.2812) gate/entropy 1.0211 (1.0241) gate/usage_max 0.5077 (0.4974) gate/usage_min 0.1895 (0.1858) gate/usage_std 0.1317 (0.1279) teacher/entropy 0.2843 (0.3890) teacher/usage_max 0.8187 (0.7455) teacher/usage_min 0.0447 (0.0581) teacher/usage_std 0.3452 (0.2980) nleep/row_max_mean 1197.8558 (1196.8019) nleep/row_max_std 10.9005 (13.8739) nleep/row_min_mean 1191.4739 (1191.1687) lr 6.9098e-04 eta 0:30:43
epoch [32/50] batch [120/246] time 0.475 (0.391) data 0.000 (0.003) loss 1.4903 (1.8106) teacher_loss 0.5824 (0.9786) loss_zs_kd 0.0448 (0.0464) loss_oracle 0.5692 (0.5602) kd_loss 0.6010 (0.5287) acc 81.2500 (74.0625) gate/entropy 1.0197 (1.0234) gate/usage_max 0.5116 (0.4995) gate/usage_min 0.1910 (0.1865) gate/usage_std 0.1333 (0.1287) teacher/entropy 0.2831 (0.3905) teacher/usage_max 0.7644 (0.7412) teacher/usage_min 0.0411 (0.0569) teacher/usage_std 0.3112 (0.2957) nleep/row_max_mean 1199.7935 (1196.6974) nleep/row_max_std 13.0988 (13.7297) nleep/row_min_mean 1194.2109 (1191.0654) lr 6.9098e-04 eta 0:29:38
epoch [32/50] batch [140/246] time 0.474 (0.389) data 0.000 (0.002) loss 2.2163 (1.8008) teacher_loss 1.3054 (0.9671) loss_zs_kd 0.0621 (0.0464) loss_oracle 0.6348 (0.5602) kd_loss 0.5624 (0.5305) acc 62.5000 (74.3750) gate/entropy 1.0179 (1.0228) gate/usage_max 0.5160 (0.5016) gate/usage_min 0.1925 (0.1873) gate/usage_std 0.1353 (0.1295) teacher/entropy 0.3834 (0.3920) teacher/usage_max 0.7051 (0.7353) teacher/usage_min 0.0160 (0.0552) teacher/usage_std 0.2839 (0.2927) nleep/row_max_mean 1193.8785 (1196.7038) nleep/row_max_std 12.8167 (13.6356) nleep/row_min_mean 1188.3408 (1191.0769) lr 6.9098e-04 eta 0:29:22
epoch [32/50] batch [160/246] time 0.496 (0.399) data 0.000 (0.002) loss 1.5947 (1.8024) teacher_loss 0.8415 (0.9722) loss_zs_kd 0.0319 (0.0463) loss_oracle 0.4936 (0.5560) kd_loss 0.4904 (0.5291) acc 81.2500 (74.3750) gate/entropy 1.0162 (1.0221) gate/usage_max 0.5199 (0.5036) gate/usage_min 0.1939 (0.1880) gate/usage_std 0.1372 (0.1303) teacher/entropy 0.3513 (0.3942) teacher/usage_max 0.7946 (0.7317) teacher/usage_min 0.0382 (0.0539) teacher/usage_std 0.3304 (0.2909) nleep/row_max_mean 1200.5977 (1196.7462) nleep/row_max_std 15.5441 (13.6680) nleep/row_min_mean 1194.0155 (1191.0988) lr 6.9098e-04 eta 0:29:59
epoch [32/50] batch [180/246] time 0.508 (0.409) data 0.000 (0.002) loss 1.7640 (1.7970) teacher_loss 0.9269 (0.9664) loss_zs_kd 0.0538 (0.0459) loss_oracle 0.5024 (0.5542) kd_loss 0.5589 (0.5305) acc 78.1250 (74.7396) gate/entropy 1.0147 (1.0213) gate/usage_max 0.5232 (0.5056) gate/usage_min 0.1952 (0.1888) gate/usage_std 0.1388 (0.1312) teacher/entropy 0.4698 (0.3948) teacher/usage_max 0.5942 (0.7273) teacher/usage_min 0.0512 (0.0517) teacher/usage_std 0.2222 (0.2890) nleep/row_max_mean 1197.2891 (1196.8163) nleep/row_max_std 15.8598 (13.6176) nleep/row_min_mean 1192.1302 (1191.1432) lr 6.9098e-04 eta 0:30:38
epoch [32/50] batch [200/246] time 0.115 (0.392) data 0.000 (0.002) loss 1.9596 (1.7961) teacher_loss 1.0566 (0.9668) loss_zs_kd 0.0600 (0.0461) loss_oracle 0.5263 (0.5515) kd_loss 0.6098 (0.5305) acc 71.8750 (74.6562) gate/entropy 1.0129 (1.0206) gate/usage_max 0.5268 (0.5076) gate/usage_min 0.1964 (0.1895) gate/usage_std 0.1407 (0.1321) teacher/entropy 0.3775 (0.3958) teacher/usage_max 0.6423 (0.7232) teacher/usage_min 0.0194 (0.0515) teacher/usage_std 0.2543 (0.2869) nleep/row_max_mean 1195.6584 (1196.8403) nleep/row_max_std 13.0555 (13.6427) nleep/row_min_mean 1188.9541 (1191.1334) lr 6.9098e-04 eta 0:29:15
epoch [32/50] batch [220/246] time 0.080 (0.383) data 0.000 (0.001) loss 1.6408 (1.7856) teacher_loss 0.7781 (0.9591) loss_zs_kd 0.0751 (0.0459) loss_oracle 0.5583 (0.5490) kd_loss 0.5460 (0.5290) acc 81.2500 (74.9148) gate/entropy 1.0113 (1.0198) gate/usage_max 0.5297 (0.5095) gate/usage_min 0.1975 (0.1902) gate/usage_std 0.1422 (0.1329) teacher/entropy 0.4431 (0.3980) teacher/usage_max 0.6131 (0.7197) teacher/usage_min 0.0862 (0.0509) teacher/usage_std 0.2164 (0.2851) nleep/row_max_mean 1193.8821 (1196.8177) nleep/row_max_std 15.5485 (13.6808) nleep/row_min_mean 1188.4749 (1191.1013) lr 6.9098e-04 eta 0:28:26
epoch [32/50] batch [240/246] time 0.412 (0.381) data 0.000 (0.001) loss 1.3936 (1.7901) teacher_loss 0.5313 (0.9640) loss_zs_kd 0.0241 (0.0456) loss_oracle 0.5259 (0.5474) kd_loss 0.5874 (0.5296) acc 87.5000 (74.7656) gate/entropy 1.0095 (1.0190) gate/usage_max 0.5328 (0.5113) gate/usage_min 0.1986 (0.1908) gate/usage_std 0.1439 (0.1338) teacher/entropy 0.4164 (0.3998) teacher/usage_max 0.6029 (0.7145) teacher/usage_min 0.0565 (0.0504) teacher/usage_std 0.2231 (0.2824) nleep/row_max_mean 1194.8325 (1196.8036) nleep/row_max_std 13.7356 (13.7269) nleep/row_min_mean 1188.7791 (1191.0719) lr 6.9098e-04 eta 0:28:11
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,866
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 84.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,959
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.7%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [33/50] batch [20/246] time 0.466 (0.488) data 0.000 (0.013) loss 2.0443 (1.7449) teacher_loss 1.1926 (0.9417) loss_zs_kd 0.0370 (0.0393) loss_oracle 0.5380 (0.5085) kd_loss 0.5643 (0.5293) acc 75.0000 (75.3125) gate/entropy 1.0074 (1.0083) gate/usage_max 0.5363 (0.5350) gate/usage_min 0.1998 (0.1994) gate/usage_std 0.1459 (0.1451) teacher/entropy 0.4257 (0.4417) teacher/usage_max 0.6124 (0.6369) teacher/usage_min 0.0558 (0.0441) teacher/usage_std 0.2272 (0.2459) nleep/row_max_mean 1198.1743 (1196.6364) nleep/row_max_std 12.3260 (13.6922) nleep/row_min_mean 1192.8794 (1190.9210) lr 6.3188e-04 eta 0:35:51
epoch [33/50] batch [40/246] time 0.082 (0.458) data 0.000 (0.007) loss 1.3289 (1.7715) teacher_loss 0.5288 (0.9681) loss_zs_kd 0.0342 (0.0421) loss_oracle 0.4813 (0.4996) kd_loss 0.5423 (0.5326) acc 81.2500 (74.8438) gate/entropy 1.0063 (1.0076) gate/usage_max 0.5382 (0.5361) gate/usage_min 0.2005 (0.1998) gate/usage_std 0.1470 (0.1458) teacher/entropy 0.4686 (0.4385) teacher/usage_max 0.5992 (0.6350) teacher/usage_min 0.0158 (0.0439) teacher/usage_std 0.2410 (0.2443) nleep/row_max_mean 1192.9539 (1197.1525) nleep/row_max_std 14.4420 (13.6849) nleep/row_min_mean 1187.5259 (1191.2732) lr 6.3188e-04 eta 0:33:29
epoch [33/50] batch [60/246] time 0.485 (0.413) data 0.000 (0.004) loss 1.9266 (1.7634) teacher_loss 1.1193 (0.9562) loss_zs_kd 0.0303 (0.0425) loss_oracle 0.4811 (0.4967) kd_loss 0.5516 (0.5376) acc 71.8750 (75.3125) gate/entropy 1.0049 (1.0069) gate/usage_max 0.5403 (0.5372) gate/usage_min 0.2013 (0.2002) gate/usage_std 0.1482 (0.1464) teacher/entropy 0.4303 (0.4380) teacher/usage_max 0.6178 (0.6290) teacher/usage_min 0.0438 (0.0432) teacher/usage_std 0.2344 (0.2422) nleep/row_max_mean 1199.4611 (1197.1275) nleep/row_max_std 13.8466 (13.7570) nleep/row_min_mean 1192.9822 (1191.1940) lr 6.3188e-04 eta 0:30:02
epoch [33/50] batch [80/246] time 0.442 (0.374) data 0.000 (0.003) loss 1.4477 (1.7661) teacher_loss 0.6219 (0.9509) loss_zs_kd 0.0512 (0.0418) loss_oracle 0.5326 (0.4995) kd_loss 0.5340 (0.5446) acc 81.2500 (75.0781) gate/entropy 1.0036 (1.0063) gate/usage_max 0.5424 (0.5382) gate/usage_min 0.2020 (0.2005) gate/usage_std 0.1494 (0.1470) teacher/entropy 0.4505 (0.4385) teacher/usage_max 0.6133 (0.6203) teacher/usage_min 0.0382 (0.0411) teacher/usage_std 0.2350 (0.2398) nleep/row_max_mean 1195.3848 (1196.9364) nleep/row_max_std 13.4014 (13.6487) nleep/row_min_mean 1189.3704 (1190.9860) lr 6.3188e-04 eta 0:27:04
epoch [33/50] batch [100/246] time 0.463 (0.372) data 0.000 (0.003) loss 1.7093 (1.7671) teacher_loss 0.8316 (0.9484) loss_zs_kd 0.0402 (0.0417) loss_oracle 0.5244 (0.5002) kd_loss 0.5954 (0.5477) acc 75.0000 (75.1875) gate/entropy 1.0023 (1.0056) gate/usage_max 0.5443 (0.5392) gate/usage_min 0.2026 (0.2009) gate/usage_std 0.1506 (0.1476) teacher/entropy 0.4370 (0.4416) teacher/usage_max 0.5591 (0.6129) teacher/usage_min 0.0498 (0.0391) teacher/usage_std 0.2119 (0.2381) nleep/row_max_mean 1197.1860 (1197.0916) nleep/row_max_std 16.3665 (13.7494) nleep/row_min_mean 1191.4678 (1191.1289) lr 6.3188e-04 eta 0:26:50
epoch [33/50] batch [120/246] time 0.348 (0.394) data 0.000 (0.002) loss 2.3694 (1.7689) teacher_loss 1.4879 (0.9425) loss_zs_kd 0.0340 (0.0413) loss_oracle 0.4911 (0.5000) kd_loss 0.6190 (0.5557) acc 68.7500 (75.1562) gate/entropy 1.0011 (1.0050) gate/usage_max 0.5459 (0.5402) gate/usage_min 0.2032 (0.2012) gate/usage_std 0.1516 (0.1482) teacher/entropy 0.4282 (0.4402) teacher/usage_max 0.5343 (0.6059) teacher/usage_min 0.0808 (0.0394) teacher/usage_std 0.1887 (0.2356) nleep/row_max_mean 1197.5363 (1197.1993) nleep/row_max_std 12.2316 (13.7527) nleep/row_min_mean 1191.0027 (1191.2037) lr 6.3188e-04 eta 0:28:18
epoch [33/50] batch [140/246] time 0.512 (0.410) data 0.000 (0.002) loss 2.0388 (1.7786) teacher_loss 1.1233 (0.9439) loss_zs_kd 0.0450 (0.0415) loss_oracle 0.5131 (0.5007) kd_loss 0.6364 (0.5636) acc 65.6250 (75.1562) gate/entropy 0.9999 (1.0044) gate/usage_max 0.5476 (0.5411) gate/usage_min 0.2038 (0.2015) gate/usage_std 0.1526 (0.1487) teacher/entropy 0.3871 (0.4389) teacher/usage_max 0.5702 (0.6004) teacher/usage_min 0.0164 (0.0384) teacher/usage_std 0.2331 (0.2344) nleep/row_max_mean 1200.2606 (1197.1900) nleep/row_max_std 13.2033 (13.7958) nleep/row_min_mean 1193.3755 (1191.1632) lr 6.3188e-04 eta 0:29:17
epoch [33/50] batch [160/246] time 0.429 (0.393) data 0.000 (0.002) loss 1.6244 (1.7653) teacher_loss 0.7669 (0.9224) loss_zs_kd 0.0564 (0.0419) loss_oracle 0.4701 (0.5006) kd_loss 0.5942 (0.5716) acc 75.0000 (75.5078) gate/entropy 0.9994 (1.0038) gate/usage_max 0.5483 (0.5419) gate/usage_min 0.2042 (0.2018) gate/usage_std 0.1531 (0.1492) teacher/entropy 0.4381 (0.4398) teacher/usage_max 0.5590 (0.5911) teacher/usage_min 0.0211 (0.0384) teacher/usage_std 0.2280 (0.2318) nleep/row_max_mean 1191.9651 (1197.0162) nleep/row_max_std 15.5248 (13.8102) nleep/row_min_mean 1186.1285 (1190.9952) lr 6.3188e-04 eta 0:27:56
epoch [33/50] batch [180/246] time 0.082 (0.384) data 0.000 (0.002) loss 1.9844 (1.7774) teacher_loss 1.0613 (0.9296) loss_zs_kd 0.0521 (0.0423) loss_oracle 0.5757 (0.5027) kd_loss 0.6092 (0.5753) acc 71.8750 (75.4514) gate/entropy 0.9986 (1.0032) gate/usage_max 0.5495 (0.5428) gate/usage_min 0.2046 (0.2021) gate/usage_std 0.1538 (0.1497) teacher/entropy 0.4735 (0.4423) teacher/usage_max 0.4942 (0.5850) teacher/usage_min 0.0771 (0.0384) teacher/usage_std 0.1832 (0.2300) nleep/row_max_mean 1193.4910 (1196.9593) nleep/row_max_std 12.9177 (13.8110) nleep/row_min_mean 1187.8450 (1190.9514) lr 6.3188e-04 eta 0:27:10
epoch [33/50] batch [200/246] time 0.205 (0.382) data 0.000 (0.001) loss 1.7139 (1.7914) teacher_loss 0.8639 (0.9376) loss_zs_kd 0.0368 (0.0424) loss_oracle 0.4989 (0.5044) kd_loss 0.5821 (0.5803) acc 75.0000 (75.3906) gate/entropy 0.9977 (1.0027) gate/usage_max 0.5506 (0.5435) gate/usage_min 0.2050 (0.2024) gate/usage_std 0.1545 (0.1502) teacher/entropy 0.5122 (0.4442) teacher/usage_max 0.4875 (0.5784) teacher/usage_min 0.0469 (0.0379) teacher/usage_std 0.2028 (0.2285) nleep/row_max_mean 1190.0264 (1196.8149) nleep/row_max_std 12.3140 (13.7588) nleep/row_min_mean 1184.8608 (1190.8046) lr 6.3188e-04 eta 0:26:54
epoch [33/50] batch [220/246] time 0.465 (0.383) data 0.000 (0.001) loss 2.1612 (1.8029) teacher_loss 1.1828 (0.9379) loss_zs_kd 0.0445 (0.0422) loss_oracle 0.4850 (0.5057) kd_loss 0.7137 (0.5911) acc 71.8750 (75.2841) gate/entropy 0.9966 (1.0022) gate/usage_max 0.5521 (0.5443) gate/usage_min 0.2055 (0.2027) gate/usage_std 0.1554 (0.1506) teacher/entropy 0.4595 (0.4456) teacher/usage_max 0.5736 (0.5765) teacher/usage_min 0.0151 (0.0374) teacher/usage_std 0.2346 (0.2280) nleep/row_max_mean 1193.3809 (1196.7031) nleep/row_max_std 12.1187 (13.6611) nleep/row_min_mean 1187.4066 (1190.6956) lr 6.3188e-04 eta 0:26:51
epoch [33/50] batch [240/246] time 0.495 (0.391) data 0.000 (0.001) loss 1.9276 (1.8085) teacher_loss 0.8698 (0.9327) loss_zs_kd 0.0531 (0.0424) loss_oracle 0.5661 (0.5062) kd_loss 0.7482 (0.6015) acc 78.1250 (75.4557) gate/entropy 0.9957 (1.0017) gate/usage_max 0.5533 (0.5450) gate/usage_min 0.2059 (0.2029) gate/usage_std 0.1562 (0.1511) teacher/entropy 0.3872 (0.4446) teacher/usage_max 0.5219 (0.5747) teacher/usage_min 0.0337 (0.0366) teacher/usage_std 0.2142 (0.2278) nleep/row_max_mean 1198.0916 (1196.6534) nleep/row_max_std 15.8662 (13.6259) nleep/row_min_mean 1191.5244 (1190.6244) lr 6.3188e-04 eta 0:27:19
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,847
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,954
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 89.6%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [34/50] batch [20/246] time 0.082 (0.343) data 0.000 (0.014) loss 1.4287 (1.9099) teacher_loss 0.5714 (0.8627) loss_zs_kd 0.0507 (0.0437) loss_oracle 0.5219 (0.5547) kd_loss 0.5710 (0.7480) acc 87.5000 (78.1250) gate/entropy 0.9948 (0.9951) gate/usage_max 0.5544 (0.5541) gate/usage_min 0.2063 (0.2061) gate/usage_std 0.1569 (0.1567) teacher/entropy 0.4699 (0.4379) teacher/usage_max 0.5419 (0.5926) teacher/usage_min 0.0112 (0.0229) teacher/usage_std 0.2310 (0.2380) nleep/row_max_mean 1194.2227 (1195.8958) nleep/row_max_std 13.2304 (13.0366) nleep/row_min_mean 1188.3326 (1189.6996) lr 5.7422e-04 eta 0:23:49
epoch [34/50] batch [40/246] time 0.102 (0.354) data 0.000 (0.007) loss 2.1529 (2.0200) teacher_loss 1.0450 (0.9431) loss_zs_kd 0.0383 (0.0432) loss_oracle 0.5180 (0.5586) kd_loss 0.8298 (0.7759) acc 75.0000 (75.7812) gate/entropy 0.9941 (0.9948) gate/usage_max 0.5554 (0.5544) gate/usage_min 0.2066 (0.2063) gate/usage_std 0.1575 (0.1569) teacher/entropy 0.4508 (0.4293) teacher/usage_max 0.6808 (0.6030) teacher/usage_min 0.0230 (0.0288) teacher/usage_std 0.2698 (0.2389) nleep/row_max_mean 1198.7366 (1196.5336) nleep/row_max_std 13.2110 (13.4953) nleep/row_min_mean 1192.2578 (1190.1397) lr 5.7422e-04 eta 0:24:25
epoch [34/50] batch [60/246] time 0.480 (0.369) data 0.000 (0.005) loss 1.6805 (1.9780) teacher_loss 0.6210 (0.9007) loss_zs_kd 0.0335 (0.0414) loss_oracle 0.5233 (0.5417) kd_loss 0.7811 (0.7857) acc 87.5000 (77.5521) gate/entropy 0.9941 (0.9945) gate/usage_max 0.5553 (0.5548) gate/usage_min 0.2067 (0.2064) gate/usage_std 0.1575 (0.1572) teacher/entropy 0.4252 (0.4264) teacher/usage_max 0.5830 (0.6094) teacher/usage_min 0.0502 (0.0283) teacher/usage_std 0.2188 (0.2414) nleep/row_max_mean 1194.4419 (1196.7178) nleep/row_max_std 14.8695 (13.8717) nleep/row_min_mean 1188.5520 (1190.3638) lr 5.7422e-04 eta 0:25:21
epoch [34/50] batch [80/246] time 0.495 (0.399) data 0.000 (0.004) loss 2.1222 (2.0400) teacher_loss 0.9783 (0.9282) loss_zs_kd 0.0312 (0.0406) loss_oracle 0.5552 (0.5513) kd_loss 0.8508 (0.8159) acc 68.7500 (77.0703) gate/entropy 0.9928 (0.9942) gate/usage_max 0.5570 (0.5552) gate/usage_min 0.2071 (0.2065) gate/usage_std 0.1586 (0.1574) teacher/entropy 0.3995 (0.4145) teacher/usage_max 0.6673 (0.6286) teacher/usage_min 0.0058 (0.0271) teacher/usage_std 0.2701 (0.2495) nleep/row_max_mean 1198.7207 (1196.6351) nleep/row_max_std 16.0573 (13.8158) nleep/row_min_mean 1192.3661 (1190.2365) lr 5.7422e-04 eta 0:27:15
epoch [34/50] batch [100/246] time 0.552 (0.415) data 0.000 (0.003) loss 2.3276 (2.0717) teacher_loss 1.1181 (0.9372) loss_zs_kd 0.0364 (0.0418) loss_oracle 0.5777 (0.5636) kd_loss 0.9024 (0.8319) acc 71.8750 (76.4688) gate/entropy 0.9925 (0.9939) gate/usage_max 0.5573 (0.5556) gate/usage_min 0.2073 (0.2067) gate/usage_std 0.1588 (0.1577) teacher/entropy 0.3731 (0.4104) teacher/usage_max 0.6904 (0.6418) teacher/usage_min 0.0093 (0.0258) teacher/usage_std 0.2790 (0.2553) nleep/row_max_mean 1195.0597 (1196.5374) nleep/row_max_std 15.0190 (13.7385) nleep/row_min_mean 1188.2754 (1190.1024) lr 5.7422e-04 eta 0:28:14
epoch [34/50] batch [120/246] time 0.486 (0.384) data 0.000 (0.002) loss 2.3049 (2.0757) teacher_loss 0.9574 (0.9204) loss_zs_kd 0.0188 (0.0407) loss_oracle 0.5966 (0.5695) kd_loss 1.0397 (0.8502) acc 75.0000 (76.8750) gate/entropy 0.9915 (0.9936) gate/usage_max 0.5585 (0.5559) gate/usage_min 0.2076 (0.2068) gate/usage_std 0.1596 (0.1579) teacher/entropy 0.3663 (0.4051) teacher/usage_max 0.8199 (0.6557) teacher/usage_min 0.0140 (0.0253) teacher/usage_std 0.3496 (0.2616) nleep/row_max_mean 1197.3730 (1196.4969) nleep/row_max_std 12.2908 (13.7101) nleep/row_min_mean 1190.2466 (1190.0320) lr 5.7422e-04 eta 0:25:58
epoch [34/50] batch [140/246] time 0.472 (0.370) data 0.000 (0.002) loss 2.1835 (2.1168) teacher_loss 0.9825 (0.9376) loss_zs_kd 0.0367 (0.0413) loss_oracle 0.6335 (0.5748) kd_loss 0.8658 (0.8711) acc 78.1250 (76.5402) gate/entropy 0.9913 (0.9933) gate/usage_max 0.5588 (0.5563) gate/usage_min 0.2078 (0.2069) gate/usage_std 0.1598 (0.1581) teacher/entropy 0.4498 (0.3989) teacher/usage_max 0.7027 (0.6716) teacher/usage_min 0.0445 (0.0246) teacher/usage_std 0.2747 (0.2697) nleep/row_max_mean 1198.8035 (1196.3336) nleep/row_max_std 14.6552 (13.5792) nleep/row_min_mean 1192.4375 (1189.8364) lr 5.7422e-04 eta 0:24:56
epoch [34/50] batch [160/246] time 0.498 (0.369) data 0.000 (0.002) loss 2.0430 (2.1393) teacher_loss 0.6526 (0.9443) loss_zs_kd 0.0326 (0.0418) loss_oracle 0.6211 (0.5723) kd_loss 1.0636 (0.8879) acc 81.2500 (76.1914) gate/entropy 0.9915 (0.9931) gate/usage_max 0.5586 (0.5566) gate/usage_min 0.2078 (0.2070) gate/usage_std 0.1596 (0.1583) teacher/entropy 0.3238 (0.3921) teacher/usage_max 0.7947 (0.6825) teacher/usage_min 0.0222 (0.0239) teacher/usage_std 0.3328 (0.2752) nleep/row_max_mean 1194.7866 (1196.4500) nleep/row_max_std 13.5280 (13.6006) nleep/row_min_mean 1187.8824 (1189.8881) lr 5.7422e-04 eta 0:24:45
epoch [34/50] batch [180/246] time 0.495 (0.383) data 0.000 (0.002) loss 2.0447 (2.1692) teacher_loss 0.6201 (0.9505) loss_zs_kd 0.0310 (0.0419) loss_oracle 0.7586 (0.5783) kd_loss 1.0298 (0.9086) acc 81.2500 (75.8854) gate/entropy 0.9904 (0.9928) gate/usage_max 0.5598 (0.5569) gate/usage_min 0.2081 (0.2071) gate/usage_std 0.1604 (0.1585) teacher/entropy 0.2945 (0.3834) teacher/usage_max 0.7484 (0.6956) teacher/usage_min 0.0044 (0.0232) teacher/usage_std 0.3098 (0.2821) nleep/row_max_mean 1199.6101 (1196.4222) nleep/row_max_std 12.4754 (13.5461) nleep/row_min_mean 1191.6047 (1189.7907) lr 5.7422e-04 eta 0:25:33
epoch [34/50] batch [200/246] time 0.515 (0.396) data 0.000 (0.002) loss 2.5426 (2.2136) teacher_loss 1.0515 (0.9673) loss_zs_kd 0.0265 (0.0423) loss_oracle 0.7344 (0.5950) kd_loss 1.1107 (0.9277) acc 65.6250 (75.3125) gate/entropy 0.9902 (0.9926) gate/usage_max 0.5601 (0.5572) gate/usage_min 0.2083 (0.2072) gate/usage_std 0.1606 (0.1587) teacher/entropy 0.2830 (0.3749) teacher/usage_max 0.8116 (0.7073) teacher/usage_min 0.0125 (0.0226) teacher/usage_std 0.3447 (0.2885) nleep/row_max_mean 1196.3354 (1196.4187) nleep/row_max_std 14.6675 (13.5032) nleep/row_min_mean 1189.5378 (1189.7421) lr 5.7422e-04 eta 0:26:15
epoch [34/50] batch [220/246] time 0.080 (0.394) data 0.000 (0.001) loss 2.6189 (2.2411) teacher_loss 1.1608 (0.9721) loss_zs_kd 0.0300 (0.0426) loss_oracle 0.5668 (0.6051) kd_loss 1.1597 (0.9452) acc 68.7500 (75.1136) gate/entropy 0.9900 (0.9924) gate/usage_max 0.5604 (0.5575) gate/usage_min 0.2084 (0.2073) gate/usage_std 0.1608 (0.1589) teacher/entropy 0.2724 (0.3670) teacher/usage_max 0.8550 (0.7183) teacher/usage_min 0.0083 (0.0215) teacher/usage_std 0.3726 (0.2946) nleep/row_max_mean 1199.0671 (1196.4044) nleep/row_max_std 17.1540 (13.5029) nleep/row_min_mean 1191.3623 (1189.6784) lr 5.7422e-04 eta 0:26:02
epoch [34/50] batch [240/246] time 0.482 (0.388) data 0.000 (0.001) loss 2.8543 (2.2686) teacher_loss 1.3150 (0.9781) loss_zs_kd 0.0520 (0.0424) loss_oracle 0.6945 (0.6101) kd_loss 1.1661 (0.9643) acc 59.3750 (74.8568) gate/entropy 0.9891 (0.9921) gate/usage_max 0.5614 (0.5578) gate/usage_min 0.2087 (0.2074) gate/usage_std 0.1615 (0.1591) teacher/entropy 0.2572 (0.3580) teacher/usage_max 0.8517 (0.7295) teacher/usage_min 0.0034 (0.0207) teacher/usage_std 0.3711 (0.3010) nleep/row_max_mean 1204.5664 (1196.4281) nleep/row_max_std 14.3018 (13.4903) nleep/row_min_mean 1196.9187 (1189.6439) lr 5.7422e-04 eta 0:25:27
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,826
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,940
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.2%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [35/50] batch [20/246] time 0.496 (0.500) data 0.000 (0.012) loss 2.9401 (2.4851) teacher_loss 1.3491 (0.9251) loss_zs_kd 0.0331 (0.0450) loss_oracle 0.6900 (0.6938) kd_loss 1.2295 (1.1906) acc 62.5000 (75.3125) gate/entropy 0.9886 (0.9891) gate/usage_max 0.5619 (0.5613) gate/usage_min 0.2088 (0.2087) gate/usage_std 0.1618 (0.1615) teacher/entropy 0.2407 (0.2529) teacher/usage_max 0.8947 (0.8657) teacher/usage_min 0.0092 (0.0108) teacher/usage_std 0.3985 (0.3794) nleep/row_max_mean 1197.3590 (1196.6174) nleep/row_max_std 12.2182 (12.3550) nleep/row_min_mean 1188.8763 (1189.1499) lr 5.1825e-04 eta 0:32:37
epoch [35/50] batch [40/246] time 0.497 (0.485) data 0.000 (0.006) loss 2.9112 (2.5936) teacher_loss 1.1855 (0.9840) loss_zs_kd 0.0461 (0.0470) loss_oracle 0.8926 (0.7468) kd_loss 1.2563 (1.2128) acc 68.7500 (74.6875) gate/entropy 0.9891 (0.9890) gate/usage_max 0.5614 (0.5615) gate/usage_min 0.2089 (0.2088) gate/usage_std 0.1615 (0.1616) teacher/entropy 0.1928 (0.2342) teacher/usage_max 0.8782 (0.8704) teacher/usage_min 0.0039 (0.0099) teacher/usage_std 0.3881 (0.3826) nleep/row_max_mean 1194.5452 (1196.8399) nleep/row_max_std 14.0796 (12.3623) nleep/row_min_mean 1186.1316 (1189.1079) lr 5.1825e-04 eta 0:31:30
epoch [35/50] batch [60/246] time 0.097 (0.448) data 0.001 (0.004) loss 2.4046 (2.6298) teacher_loss 0.7535 (0.9962) loss_zs_kd 0.0663 (0.0464) loss_oracle 0.8781 (0.7665) kd_loss 1.1789 (1.2271) acc 78.1250 (74.2188) gate/entropy 0.9886 (0.9888) gate/usage_max 0.5619 (0.5617) gate/usage_min 0.2090 (0.2089) gate/usage_std 0.1619 (0.1617) teacher/entropy 0.2663 (0.2252) teacher/usage_max 0.8639 (0.8761) teacher/usage_min 0.0162 (0.0099) teacher/usage_std 0.3775 (0.3864) nleep/row_max_mean 1193.1135 (1197.0967) nleep/row_max_std 12.0675 (12.4618) nleep/row_min_mean 1186.3966 (1189.2836) lr 5.1825e-04 eta 0:28:57
epoch [35/50] batch [80/246] time 0.079 (0.420) data 0.000 (0.003) loss 3.7948 (2.6689) teacher_loss 2.1275 (1.0123) loss_zs_kd 0.0399 (0.0458) loss_oracle 0.7095 (0.7849) kd_loss 1.2926 (1.2413) acc 53.1250 (73.7891) gate/entropy 0.9880 (0.9887) gate/usage_max 0.5627 (0.5619) gate/usage_min 0.2092 (0.2089) gate/usage_std 0.1623 (0.1618) teacher/entropy 0.1914 (0.2177) teacher/usage_max 0.9165 (0.8833) teacher/usage_min 0.0023 (0.0097) teacher/usage_std 0.4136 (0.3912) nleep/row_max_mean 1200.3679 (1197.4362) nleep/row_max_std 14.4228 (12.7103) nleep/row_min_mean 1192.1692 (1189.5262) lr 5.1825e-04 eta 0:27:00
epoch [35/50] batch [100/246] time 0.484 (0.398) data 0.000 (0.002) loss 2.9244 (2.6832) teacher_loss 1.1702 (1.0130) loss_zs_kd 0.0422 (0.0444) loss_oracle 0.8033 (0.7948) kd_loss 1.3314 (1.2506) acc 68.7500 (73.8125) gate/entropy 0.9878 (0.9885) gate/usage_max 0.5629 (0.5620) gate/usage_min 0.2093 (0.2090) gate/usage_std 0.1625 (0.1619) teacher/entropy 0.1651 (0.2118) teacher/usage_max 0.9263 (0.8870) teacher/usage_min 0.0059 (0.0096) teacher/usage_std 0.4201 (0.3937) nleep/row_max_mean 1196.4348 (1197.5246) nleep/row_max_std 12.6390 (12.9733) nleep/row_min_mean 1187.3738 (1189.5344) lr 5.1825e-04 eta 0:25:25
epoch [35/50] batch [120/246] time 0.441 (0.397) data 0.000 (0.002) loss 2.4363 (2.6988) teacher_loss 0.8991 (1.0128) loss_zs_kd 0.0243 (0.0441) loss_oracle 0.7008 (0.8013) kd_loss 1.1747 (1.2632) acc 75.0000 (74.0104) gate/entropy 0.9878 (0.9884) gate/usage_max 0.5629 (0.5622) gate/usage_min 0.2094 (0.2090) gate/usage_std 0.1625 (0.1620) teacher/entropy 0.2566 (0.2037) teacher/usage_max 0.8586 (0.8923) teacher/usage_min 0.0083 (0.0093) teacher/usage_std 0.3749 (0.3972) nleep/row_max_mean 1196.4708 (1197.6463) nleep/row_max_std 14.4144 (13.1032) nleep/row_min_mean 1188.7803 (1189.5561) lr 5.1825e-04 eta 0:25:16
epoch [35/50] batch [140/246] time 0.491 (0.409) data 0.000 (0.002) loss 2.5733 (2.7164) teacher_loss 0.8088 (1.0178) loss_zs_kd 0.0306 (0.0442) loss_oracle 0.8076 (0.8068) kd_loss 1.3454 (1.2730) acc 78.1250 (73.7946) gate/entropy 0.9874 (0.9883) gate/usage_max 0.5634 (0.5624) gate/usage_min 0.2095 (0.2091) gate/usage_std 0.1628 (0.1621) teacher/entropy 0.1556 (0.1980) teacher/usage_max 0.9202 (0.8968) teacher/usage_min 0.0187 (0.0092) teacher/usage_std 0.4153 (0.4002) nleep/row_max_mean 1195.7428 (1197.6756) nleep/row_max_std 10.0888 (13.0912) nleep/row_min_mean 1187.4385 (1189.5175) lr 5.1825e-04 eta 0:25:52
epoch [35/50] batch [160/246] time 0.463 (0.415) data 0.000 (0.002) loss 2.3722 (2.7349) teacher_loss 0.5571 (1.0208) loss_zs_kd 0.0384 (0.0435) loss_oracle 0.8393 (0.8162) kd_loss 1.3763 (1.2843) acc 84.3750 (73.7109) gate/entropy 0.9871 (0.9881) gate/usage_max 0.5636 (0.5625) gate/usage_min 0.2096 (0.2092) gate/usage_std 0.1630 (0.1622) teacher/entropy 0.1424 (0.1907) teacher/usage_max 0.9491 (0.9013) teacher/usage_min 0.0071 (0.0089) teacher/usage_std 0.4357 (0.4033) nleep/row_max_mean 1203.8772 (1197.7150) nleep/row_max_std 15.0146 (13.2846) nleep/row_min_mean 1194.4745 (1189.4828) lr 5.1825e-04 eta 0:26:08
epoch [35/50] batch [180/246] time 0.461 (0.398) data 0.000 (0.001) loss 3.3890 (2.7446) teacher_loss 1.5241 (1.0200) loss_zs_kd 0.0392 (0.0432) loss_oracle 0.8736 (0.8204) kd_loss 1.4085 (1.2928) acc 65.6250 (73.7500) gate/entropy 0.9868 (0.9880) gate/usage_max 0.5640 (0.5626) gate/usage_min 0.2097 (0.2092) gate/usage_std 0.1633 (0.1623) teacher/entropy 0.1152 (0.1854) teacher/usage_max 0.9555 (0.9052) teacher/usage_min 0.0062 (0.0085) teacher/usage_std 0.4401 (0.4060) nleep/row_max_mean 1198.9812 (1197.8379) nleep/row_max_std 12.9916 (13.3643) nleep/row_min_mean 1190.1743 (1189.5421) lr 5.1825e-04 eta 0:24:55
epoch [35/50] batch [200/246] time 0.081 (0.388) data 0.000 (0.001) loss 2.7504 (2.7606) teacher_loss 0.9346 (1.0260) loss_zs_kd 0.0322 (0.0426) loss_oracle 0.8539 (0.8241) kd_loss 1.3728 (1.3013) acc 75.0000 (73.5000) gate/entropy 0.9871 (0.9879) gate/usage_max 0.5637 (0.5628) gate/usage_min 0.2097 (0.2093) gate/usage_std 0.1630 (0.1624) teacher/entropy 0.1433 (0.1800) teacher/usage_max 0.9497 (0.9089) teacher/usage_min 0.0043 (0.0080) teacher/usage_std 0.4362 (0.4085) nleep/row_max_mean 1192.0842 (1197.9053) nleep/row_max_std 13.5879 (13.4534) nleep/row_min_mean 1183.9518 (1189.5479) lr 5.1825e-04 eta 0:24:08
epoch [35/50] batch [220/246] time 0.081 (0.385) data 0.000 (0.001) loss 3.1323 (2.7773) teacher_loss 1.3100 (1.0317) loss_zs_kd 0.0471 (0.0424) loss_oracle 0.8734 (0.8315) kd_loss 1.3620 (1.3087) acc 62.5000 (73.4091) gate/entropy 0.9869 (0.9878) gate/usage_max 0.5639 (0.5629) gate/usage_min 0.2098 (0.2093) gate/usage_std 0.1632 (0.1625) teacher/entropy 0.1468 (0.1751) teacher/usage_max 0.9401 (0.9119) teacher/usage_min 0.0072 (0.0078) teacher/usage_std 0.4295 (0.4105) nleep/row_max_mean 1196.8147 (1197.8736) nleep/row_max_std 15.9579 (13.4698) nleep/row_min_mean 1188.2738 (1189.4642) lr 5.1825e-04 eta 0:23:52
epoch [35/50] batch [240/246] time 0.490 (0.391) data 0.000 (0.001) loss 2.8377 (2.7921) teacher_loss 0.9302 (1.0357) loss_zs_kd 0.0359 (0.0425) loss_oracle 0.8998 (0.8346) kd_loss 1.4397 (1.3178) acc 75.0000 (73.2552) gate/entropy 0.9863 (0.9876) gate/usage_max 0.5646 (0.5631) gate/usage_min 0.2099 (0.2094) gate/usage_std 0.1637 (0.1626) teacher/entropy 0.0756 (0.1689) teacher/usage_max 0.9526 (0.9155) teacher/usage_min 0.0013 (0.0074) teacher/usage_std 0.4383 (0.4129) nleep/row_max_mean 1199.4673 (1197.9780) nleep/row_max_std 16.2927 (13.5214) nleep/row_min_mean 1189.7542 (1189.4957) lr 5.1825e-04 eta 0:24:04
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,815
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,924
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 88.8%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [36/50] batch [20/246] time 0.088 (0.381) data 0.000 (0.012) loss 3.0464 (2.9988) teacher_loss 1.1226 (1.1347) loss_zs_kd 0.0629 (0.0377) loss_oracle 0.9119 (0.8757) kd_loss 1.4364 (1.4074) acc 68.7500 (69.2188) gate/entropy 0.9863 (0.9861) gate/usage_max 0.5646 (0.5648) gate/usage_min 0.2100 (0.2100) gate/usage_std 0.1637 (0.1638) teacher/entropy 0.0902 (0.1064) teacher/usage_max 0.9599 (0.9501) teacher/usage_min 0.0063 (0.0028) teacher/usage_std 0.4432 (0.4366) nleep/row_max_mean 1202.5714 (1200.4726) nleep/row_max_std 15.1777 (15.2103) nleep/row_min_mean 1193.4767 (1190.9911) lr 4.6417e-04 eta 0:23:20
epoch [36/50] batch [40/246] time 0.079 (0.357) data 0.000 (0.006) loss 3.3542 (2.9450) teacher_loss 1.5367 (1.0699) loss_zs_kd 0.0508 (0.0404) loss_oracle 0.8141 (0.8875) kd_loss 1.3850 (1.4112) acc 53.1250 (71.0938) gate/entropy 0.9855 (0.9860) gate/usage_max 0.5655 (0.5649) gate/usage_min 0.2102 (0.2101) gate/usage_std 0.1642 (0.1639) teacher/entropy 0.1141 (0.1048) teacher/usage_max 0.9347 (0.9523) teacher/usage_min 0.0042 (0.0030) teacher/usage_std 0.4259 (0.4381) nleep/row_max_mean 1200.4434 (1200.7873) nleep/row_max_std 18.8828 (15.6308) nleep/row_min_mean 1190.8754 (1191.2058) lr 4.6417e-04 eta 0:21:44
epoch [36/50] batch [60/246] time 0.524 (0.350) data 0.000 (0.004) loss 2.5599 (2.9292) teacher_loss 0.8025 (1.0660) loss_zs_kd 0.0452 (0.0419) loss_oracle 0.7453 (0.8572) kd_loss 1.3622 (1.4136) acc 71.8750 (71.0938) gate/entropy 0.9855 (0.9859) gate/usage_max 0.5655 (0.5650) gate/usage_min 0.2102 (0.2101) gate/usage_std 0.1643 (0.1639) teacher/entropy 0.1462 (0.1038) teacher/usage_max 0.9432 (0.9535) teacher/usage_min 0.0053 (0.0034) teacher/usage_std 0.4316 (0.4389) nleep/row_max_mean 1200.8572 (1200.4669) nleep/row_max_std 18.3413 (15.6524) nleep/row_min_mean 1192.0455 (1190.9128) lr 4.6417e-04 eta 0:21:09
epoch [36/50] batch [80/246] time 0.497 (0.354) data 0.000 (0.003) loss 3.1212 (2.9670) teacher_loss 1.2023 (1.0938) loss_zs_kd 0.0419 (0.0431) loss_oracle 0.9372 (0.8656) kd_loss 1.4294 (1.4189) acc 62.5000 (70.4297) gate/entropy 0.9854 (0.9859) gate/usage_max 0.5656 (0.5651) gate/usage_min 0.2103 (0.2101) gate/usage_std 0.1644 (0.1640) teacher/entropy 0.1034 (0.1005) teacher/usage_max 0.9679 (0.9555) teacher/usage_min 0.0056 (0.0037) teacher/usage_std 0.4488 (0.4403) nleep/row_max_mean 1198.1707 (1200.3634) nleep/row_max_std 15.7567 (15.5264) nleep/row_min_mean 1188.7700 (1190.7874) lr 4.6417e-04 eta 0:21:17
epoch [36/50] batch [100/246] time 0.442 (0.378) data 0.000 (0.003) loss 3.2906 (2.9650) teacher_loss 1.3430 (1.0839) loss_zs_kd 0.0632 (0.0430) loss_oracle 0.9119 (0.8870) kd_loss 1.4600 (1.4161) acc 53.1250 (70.6562) gate/entropy 0.9855 (0.9858) gate/usage_max 0.5655 (0.5652) gate/usage_min 0.2103 (0.2102) gate/usage_std 0.1643 (0.1640) teacher/entropy 0.0803 (0.1019) teacher/usage_max 0.9794 (0.9540) teacher/usage_min 0.0017 (0.0040) teacher/usage_std 0.4569 (0.4392) nleep/row_max_mean 1197.0754 (1200.1072) nleep/row_max_std 17.6834 (15.6488) nleep/row_min_mean 1187.2137 (1190.5449) lr 4.6417e-04 eta 0:22:38
epoch [36/50] batch [120/246] time 0.520 (0.397) data 0.000 (0.002) loss 2.7101 (2.9723) teacher_loss 0.7741 (1.0786) loss_zs_kd 0.0141 (0.0423) loss_oracle 1.0159 (0.9036) kd_loss 1.4210 (1.4207) acc 84.3750 (70.9375) gate/entropy 0.9855 (0.9857) gate/usage_max 0.5655 (0.5652) gate/usage_min 0.2104 (0.2102) gate/usage_std 0.1643 (0.1641) teacher/entropy 0.1084 (0.0989) teacher/usage_max 0.9583 (0.9558) teacher/usage_min 0.0128 (0.0039) teacher/usage_std 0.4420 (0.4405) nleep/row_max_mean 1197.6147 (1199.9858) nleep/row_max_std 12.2604 (15.5236) nleep/row_min_mean 1188.3636 (1190.4161) lr 4.6417e-04 eta 0:23:36
epoch [36/50] batch [140/246] time 0.079 (0.375) data 0.000 (0.002) loss 3.1792 (2.9711) teacher_loss 1.1761 (1.0725) loss_zs_kd 0.0274 (0.0417) loss_oracle 0.9113 (0.9063) kd_loss 1.5337 (1.4246) acc 75.0000 (71.4509) gate/entropy 0.9850 (0.9857) gate/usage_max 0.5660 (0.5653) gate/usage_min 0.2104 (0.2102) gate/usage_std 0.1646 (0.1641) teacher/entropy 0.0218 (0.0967) teacher/usage_max 0.9963 (0.9577) teacher/usage_min 0.0007 (0.0038) teacher/usage_std 0.4688 (0.4418) nleep/row_max_mean 1205.4299 (1199.9300) nleep/row_max_std 13.8015 (15.3986) nleep/row_min_mean 1194.4836 (1190.3621) lr 4.6417e-04 eta 0:22:11
epoch [36/50] batch [160/246] time 0.100 (0.365) data 0.000 (0.002) loss 2.3345 (2.9604) teacher_loss 0.4506 (1.0557) loss_zs_kd 0.0335 (0.0412) loss_oracle 0.8592 (0.9102) kd_loss 1.4376 (1.4289) acc 87.5000 (71.9336) gate/entropy 0.9851 (0.9856) gate/usage_max 0.5659 (0.5654) gate/usage_min 0.2105 (0.2102) gate/usage_std 0.1645 (0.1642) teacher/entropy 0.0846 (0.0939) teacher/usage_max 0.9620 (0.9596) teacher/usage_min 0.0016 (0.0037) teacher/usage_std 0.4447 (0.4431) nleep/row_max_mean 1198.3542 (1199.9621) nleep/row_max_std 11.1068 (15.1819) nleep/row_min_mean 1189.2319 (1190.3785) lr 4.6417e-04 eta 0:21:27
epoch [36/50] batch [180/246] time 0.078 (0.365) data 0.000 (0.002) loss 2.9168 (2.9557) teacher_loss 1.0056 (1.0517) loss_zs_kd 0.0405 (0.0410) loss_oracle 0.8532 (0.9079) kd_loss 1.4643 (1.4296) acc 71.8750 (72.3264) gate/entropy 0.9850 (0.9855) gate/usage_max 0.5660 (0.5655) gate/usage_min 0.2105 (0.2103) gate/usage_std 0.1646 (0.1642) teacher/entropy 0.0686 (0.0932) teacher/usage_max 0.9729 (0.9598) teacher/usage_min 0.0018 (0.0036) teacher/usage_std 0.4523 (0.4433) nleep/row_max_mean 1199.8790 (1199.6821) nleep/row_max_std 11.8131 (15.0158) nleep/row_min_mean 1189.7493 (1190.0909) lr 4.6417e-04 eta 0:21:21
epoch [36/50] batch [200/246] time 0.495 (0.375) data 0.000 (0.001) loss 2.9202 (2.9632) teacher_loss 1.0402 (1.0557) loss_zs_kd 0.0396 (0.0411) loss_oracle 0.9722 (0.9117) kd_loss 1.3740 (1.4311) acc 71.8750 (72.1094) gate/entropy 0.9846 (0.9854) gate/usage_max 0.5665 (0.5656) gate/usage_min 0.2106 (0.2103) gate/usage_std 0.1649 (0.1643) teacher/entropy 0.1130 (0.0915) teacher/usage_max 0.9274 (0.9597) teacher/usage_min 0.0013 (0.0035) teacher/usage_std 0.4210 (0.4432) nleep/row_max_mean 1195.1418 (1199.5994) nleep/row_max_std 14.3026 (14.9053) nleep/row_min_mean 1185.4590 (1189.9833) lr 4.6417e-04 eta 0:21:48
epoch [36/50] batch [220/246] time 0.495 (0.384) data 0.000 (0.001) loss 2.4823 (2.9603) teacher_loss 0.5939 (1.0505) loss_zs_kd 0.0254 (0.0412) loss_oracle 0.8402 (0.9109) kd_loss 1.4556 (1.4337) acc 81.2500 (72.2443) gate/entropy 0.9846 (0.9854) gate/usage_max 0.5664 (0.5656) gate/usage_min 0.2107 (0.2103) gate/usage_std 0.1649 (0.1643) teacher/entropy 0.0661 (0.0898) teacher/usage_max 0.9634 (0.9609) teacher/usage_min 0.0004 (0.0034) teacher/usage_std 0.4458 (0.4441) nleep/row_max_mean 1198.3479 (1199.4511) nleep/row_max_std 14.4809 (14.7334) nleep/row_min_mean 1188.3765 (1189.8227) lr 4.6417e-04 eta 0:22:12
epoch [36/50] batch [240/246] time 0.427 (0.392) data 0.000 (0.001) loss 3.0398 (2.9523) teacher_loss 1.0337 (1.0392) loss_zs_kd 0.0538 (0.0414) loss_oracle 0.9676 (0.9123) kd_loss 1.4954 (1.4363) acc 68.7500 (72.6432) gate/entropy 0.9846 (0.9853) gate/usage_max 0.5665 (0.5657) gate/usage_min 0.2107 (0.2104) gate/usage_std 0.1650 (0.1644) teacher/entropy 0.0526 (0.0882) teacher/usage_max 0.9868 (0.9620) teacher/usage_min 0.0041 (0.0034) teacher/usage_std 0.4621 (0.4448) nleep/row_max_mean 1201.0803 (1199.3258) nleep/row_max_std 12.7382 (14.5685) nleep/row_min_mean 1191.3767 (1189.6876) lr 4.6417e-04 eta 0:22:32
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,804
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,922
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 88.8%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [37/50] batch [20/246] time 0.522 (0.392) data 0.000 (0.012) loss 3.1592 (3.0673) teacher_loss 1.1827 (1.1077) loss_zs_kd 0.0333 (0.0421) loss_oracle 0.9600 (0.9756) kd_loss 1.4799 (1.4508) acc 68.7500 (71.0938) gate/entropy 0.9846 (0.9844) gate/usage_max 0.5665 (0.5667) gate/usage_min 0.2108 (0.2108) gate/usage_std 0.1650 (0.1651) teacher/entropy 0.0548 (0.0780) teacher/usage_max 0.9765 (0.9692) teacher/usage_min 0.0009 (0.0023) teacher/usage_std 0.4549 (0.4498) nleep/row_max_mean 1196.7637 (1198.6764) nleep/row_max_std 14.7653 (13.3307) nleep/row_min_mean 1186.8386 (1189.0806) lr 4.1221e-04 eta 0:22:20
epoch [37/50] batch [40/246] time 0.490 (0.450) data 0.000 (0.006) loss 3.3347 (3.0321) teacher_loss 1.4179 (1.0609) loss_zs_kd 0.0205 (0.0392) loss_oracle 1.0347 (0.9955) kd_loss 1.3892 (1.4539) acc 65.6250 (72.0312) gate/entropy 0.9844 (0.9844) gate/usage_max 0.5667 (0.5667) gate/usage_min 0.2108 (0.2108) gate/usage_std 0.1651 (0.1651) teacher/entropy 0.1103 (0.0745) teacher/usage_max 0.9335 (0.9689) teacher/usage_min 0.0091 (0.0024) teacher/usage_std 0.4248 (0.4496) nleep/row_max_mean 1196.5920 (1198.6418) nleep/row_max_std 13.4422 (13.1684) nleep/row_min_mean 1187.2050 (1188.9069) lr 4.1221e-04 eta 0:25:30
epoch [37/50] batch [60/246] time 0.470 (0.468) data 0.000 (0.004) loss 2.8496 (3.0164) teacher_loss 0.8821 (1.0477) loss_zs_kd 0.0309 (0.0400) loss_oracle 0.9743 (0.9850) kd_loss 1.4649 (1.4562) acc 68.7500 (72.6042) gate/entropy 0.9842 (0.9844) gate/usage_max 0.5669 (0.5667) gate/usage_min 0.2109 (0.2108) gate/usage_std 0.1652 (0.1651) teacher/entropy 0.0728 (0.0738) teacher/usage_max 0.9791 (0.9701) teacher/usage_min 0.0019 (0.0029) teacher/usage_std 0.4567 (0.4504) nleep/row_max_mean 1203.9159 (1199.3555) nleep/row_max_std 14.4869 (13.4825) nleep/row_min_mean 1194.0864 (1189.5449) lr 4.1221e-04 eta 0:26:22
epoch [37/50] batch [80/246] time 0.129 (0.418) data 0.000 (0.003) loss 2.8306 (3.0112) teacher_loss 0.8764 (1.0390) loss_zs_kd 0.0585 (0.0408) loss_oracle 0.9474 (0.9821) kd_loss 1.4513 (1.4608) acc 75.0000 (72.5391) gate/entropy 0.9843 (0.9843) gate/usage_max 0.5668 (0.5668) gate/usage_min 0.2109 (0.2108) gate/usage_std 0.1652 (0.1651) teacher/entropy 0.0679 (0.0706) teacher/usage_max 0.9591 (0.9720) teacher/usage_min 0.0034 (0.0026) teacher/usage_std 0.4427 (0.4517) nleep/row_max_mean 1199.5941 (1199.5718) nleep/row_max_std 12.4506 (13.4733) nleep/row_min_mean 1189.7535 (1189.7275) lr 4.1221e-04 eta 0:23:26
epoch [37/50] batch [100/246] time 0.082 (0.401) data 0.000 (0.003) loss 3.5934 (3.0096) teacher_loss 1.6920 (1.0383) loss_zs_kd 0.0453 (0.0409) loss_oracle 0.9301 (0.9757) kd_loss 1.4137 (1.4630) acc 62.5000 (72.4688) gate/entropy 0.9838 (0.9843) gate/usage_max 0.5673 (0.5668) gate/usage_min 0.2110 (0.2108) gate/usage_std 0.1655 (0.1652) teacher/entropy 0.1043 (0.0688) teacher/usage_max 0.9578 (0.9722) teacher/usage_min 0.0040 (0.0027) teacher/usage_std 0.4418 (0.4519) nleep/row_max_mean 1196.6035 (1199.3881) nleep/row_max_std 13.8064 (13.4373) nleep/row_min_mean 1186.6888 (1189.5145) lr 4.1221e-04 eta 0:22:19
epoch [37/50] batch [120/246] time 0.456 (0.388) data 0.000 (0.002) loss 3.2182 (3.0186) teacher_loss 1.1892 (1.0469) loss_zs_kd 0.0437 (0.0410) loss_oracle 0.9617 (0.9699) kd_loss 1.5262 (1.4662) acc 65.6250 (72.2135) gate/entropy 0.9840 (0.9842) gate/usage_max 0.5672 (0.5669) gate/usage_min 0.2110 (0.2109) gate/usage_std 0.1654 (0.1652) teacher/entropy 0.0259 (0.0667) teacher/usage_max 0.9952 (0.9735) teacher/usage_min 0.0009 (0.0026) teacher/usage_std 0.4680 (0.4528) nleep/row_max_mean 1202.3743 (1199.4134) nleep/row_max_std 11.3708 (13.5078) nleep/row_min_mean 1191.8564 (1189.5008) lr 4.1221e-04 eta 0:21:30
epoch [37/50] batch [140/246] time 0.465 (0.386) data 0.000 (0.002) loss 2.7751 (3.0250) teacher_loss 0.6766 (1.0527) loss_zs_kd 0.0508 (0.0410) loss_oracle 1.1423 (0.9718) kd_loss 1.5020 (1.4658) acc 84.3750 (72.0982) gate/entropy 0.9839 (0.9842) gate/usage_max 0.5672 (0.5669) gate/usage_min 0.2110 (0.2109) gate/usage_std 0.1655 (0.1652) teacher/entropy 0.0445 (0.0666) teacher/usage_max 0.9894 (0.9732) teacher/usage_min 0.0012 (0.0026) teacher/usage_std 0.4639 (0.4526) nleep/row_max_mean 1199.4338 (1199.5265) nleep/row_max_std 13.3030 (13.5935) nleep/row_min_mean 1189.7314 (1189.5870) lr 4.1221e-04 eta 0:21:16
epoch [37/50] batch [160/246] time 0.496 (0.398) data 0.000 (0.002) loss 3.3156 (3.0182) teacher_loss 1.3107 (1.0419) loss_zs_kd 0.0333 (0.0405) loss_oracle 1.0161 (0.9798) kd_loss 1.4801 (1.4661) acc 71.8750 (72.4609) gate/entropy 0.9838 (0.9842) gate/usage_max 0.5673 (0.5670) gate/usage_min 0.2111 (0.2109) gate/usage_std 0.1655 (0.1653) teacher/entropy 0.0679 (0.0664) teacher/usage_max 0.9773 (0.9732) teacher/usage_min 0.0066 (0.0027) teacher/usage_std 0.4554 (0.4526) nleep/row_max_mean 1200.0105 (1199.6070) nleep/row_max_std 16.7436 (13.7607) nleep/row_min_mean 1189.8120 (1189.6278) lr 4.1221e-04 eta 0:21:48
epoch [37/50] batch [180/246] time 0.529 (0.410) data 0.000 (0.002) loss 3.0333 (3.0213) teacher_loss 0.9538 (1.0414) loss_zs_kd 0.0328 (0.0397) loss_oracle 1.0864 (0.9845) kd_loss 1.5199 (1.4678) acc 75.0000 (72.3611) gate/entropy 0.9840 (0.9841) gate/usage_max 0.5672 (0.5670) gate/usage_min 0.2111 (0.2109) gate/usage_std 0.1654 (0.1653) teacher/entropy 0.0307 (0.0650) teacher/usage_max 0.9943 (0.9737) teacher/usage_min 0.0008 (0.0026) teacher/usage_std 0.4674 (0.4529) nleep/row_max_mean 1197.2153 (1199.6168) nleep/row_max_std 15.3602 (13.7960) nleep/row_min_mean 1187.0710 (1189.6355) lr 4.1221e-04 eta 0:22:17
epoch [37/50] batch [200/246] time 0.187 (0.392) data 0.000 (0.001) loss 2.7425 (3.0212) teacher_loss 0.7826 (1.0377) loss_zs_kd 0.0274 (0.0397) loss_oracle 0.9421 (0.9884) kd_loss 1.4751 (1.4694) acc 81.2500 (72.4062) gate/entropy 0.9836 (0.9841) gate/usage_max 0.5675 (0.5671) gate/usage_min 0.2111 (0.2109) gate/usage_std 0.1657 (0.1653) teacher/entropy 0.0644 (0.0640) teacher/usage_max 0.9831 (0.9744) teacher/usage_min 0.0010 (0.0024) teacher/usage_std 0.4595 (0.4535) nleep/row_max_mean 1197.4115 (1199.6049) nleep/row_max_std 11.9126 (13.7931) nleep/row_min_mean 1188.0737 (1189.6123) lr 4.1221e-04 eta 0:21:10
epoch [37/50] batch [220/246] time 0.088 (0.382) data 0.000 (0.001) loss 3.6562 (3.0259) teacher_loss 1.6679 (1.0400) loss_zs_kd 0.0558 (0.0397) loss_oracle 0.9103 (0.9897) kd_loss 1.5053 (1.4712) acc 62.5000 (72.4148) gate/entropy 0.9836 (0.9840) gate/usage_max 0.5676 (0.5671) gate/usage_min 0.2112 (0.2110) gate/usage_std 0.1657 (0.1654) teacher/entropy 0.0429 (0.0625) teacher/usage_max 0.9914 (0.9750) teacher/usage_min 0.0018 (0.0023) teacher/usage_std 0.4653 (0.4539) nleep/row_max_mean 1198.0922 (1199.6854) nleep/row_max_std 16.2354 (13.7849) nleep/row_min_mean 1187.8782 (1189.6611) lr 4.1221e-04 eta 0:20:31
epoch [37/50] batch [240/246] time 0.080 (0.381) data 0.000 (0.001) loss 2.9616 (3.0286) teacher_loss 0.9361 (1.0399) loss_zs_kd 0.0407 (0.0396) loss_oracle 1.0396 (0.9921) kd_loss 1.4854 (1.4729) acc 75.0000 (72.4349) gate/entropy 0.9833 (0.9840) gate/usage_max 0.5679 (0.5672) gate/usage_min 0.2112 (0.2110) gate/usage_std 0.1659 (0.1654) teacher/entropy 0.0528 (0.0613) teacher/usage_max 0.9820 (0.9757) teacher/usage_min 0.0013 (0.0022) teacher/usage_std 0.4587 (0.4543) nleep/row_max_mean 1201.8527 (1199.7253) nleep/row_max_std 11.5678 (13.7528) nleep/row_min_mean 1191.8171 (1189.6789) lr 4.1221e-04 eta 0:20:19
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,806
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 82.8%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,935
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.1%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [38/50] batch [20/246] time 0.509 (0.545) data 0.000 (0.013) loss 3.1512 (3.1123) teacher_loss 1.1275 (1.1134) loss_zs_kd 0.0304 (0.0469) loss_oracle 0.9928 (0.9904) kd_loss 1.5121 (1.4803) acc 65.6250 (70.3125) gate/entropy 0.9836 (0.9834) gate/usage_max 0.5676 (0.5677) gate/usage_min 0.2112 (0.2112) gate/usage_std 0.1657 (0.1658) teacher/entropy 0.0364 (0.0523) teacher/usage_max 0.9922 (0.9765) teacher/usage_min 0.0015 (0.0012) teacher/usage_std 0.4659 (0.4549) nleep/row_max_mean 1200.0416 (1200.1885) nleep/row_max_std 12.9396 (14.2692) nleep/row_min_mean 1189.7258 (1189.8455) lr 3.6258e-04 eta 0:28:53
epoch [38/50] batch [40/246] time 0.085 (0.438) data 0.000 (0.007) loss 2.7561 (3.1078) teacher_loss 0.7100 (1.1067) loss_zs_kd 0.0422 (0.0436) loss_oracle 1.1538 (0.9931) kd_loss 1.4480 (1.4827) acc 84.3750 (71.3281) gate/entropy 0.9833 (0.9834) gate/usage_max 0.5679 (0.5678) gate/usage_min 0.2113 (0.2113) gate/usage_std 0.1659 (0.1658) teacher/entropy 0.0621 (0.0525) teacher/usage_max 0.9534 (0.9788) teacher/usage_min 0.0018 (0.0016) teacher/usage_std 0.4388 (0.4565) nleep/row_max_mean 1202.0293 (1199.9440) nleep/row_max_std 13.5201 (14.3568) nleep/row_min_mean 1192.0071 (1189.6449) lr 3.6258e-04 eta 0:23:02
epoch [38/50] batch [60/246] time 0.087 (0.403) data 0.000 (0.005) loss 3.3166 (3.0941) teacher_loss 1.3607 (1.0818) loss_zs_kd 0.0500 (0.0432) loss_oracle 0.9589 (1.0065) kd_loss 1.4514 (1.4874) acc 65.6250 (71.9271) gate/entropy 0.9829 (0.9834) gate/usage_max 0.5683 (0.5678) gate/usage_min 0.2113 (0.2113) gate/usage_std 0.1662 (0.1658) teacher/entropy 0.0567 (0.0497) teacher/usage_max 0.9521 (0.9809) teacher/usage_min 0.0013 (0.0014) teacher/usage_std 0.4379 (0.4580) nleep/row_max_mean 1200.6050 (1200.0493) nleep/row_max_std 12.3899 (14.3678) nleep/row_min_mean 1190.5383 (1189.7411) lr 3.6258e-04 eta 0:21:03
epoch [38/50] batch [80/246] time 0.461 (0.379) data 0.000 (0.004) loss 3.4909 (3.0924) teacher_loss 1.4792 (1.0750) loss_zs_kd 0.0505 (0.0432) loss_oracle 1.0005 (1.0141) kd_loss 1.4862 (1.4887) acc 65.6250 (71.9922) gate/entropy 0.9836 (0.9834) gate/usage_max 0.5676 (0.5678) gate/usage_min 0.2113 (0.2113) gate/usage_std 0.1657 (0.1659) teacher/entropy 0.0547 (0.0492) teacher/usage_max 0.9848 (0.9817) teacher/usage_min 0.0017 (0.0014) teacher/usage_std 0.4607 (0.4586) nleep/row_max_mean 1193.5994 (1199.9360) nleep/row_max_std 16.5404 (14.4202) nleep/row_min_mean 1184.3779 (1189.6097) lr 3.6258e-04 eta 0:19:41
epoch [38/50] batch [100/246] time 0.495 (0.381) data 0.000 (0.003) loss 3.6124 (3.0953) teacher_loss 1.6195 (1.0784) loss_zs_kd 0.0376 (0.0429) loss_oracle 0.9644 (1.0149) kd_loss 1.4919 (1.4880) acc 53.1250 (71.9062) gate/entropy 0.9829 (0.9833) gate/usage_max 0.5683 (0.5678) gate/usage_min 0.2114 (0.2113) gate/usage_std 0.1662 (0.1659) teacher/entropy 0.0522 (0.0501) teacher/usage_max 0.9882 (0.9820) teacher/usage_min 0.0018 (0.0016) teacher/usage_std 0.4630 (0.4587) nleep/row_max_mean 1201.3784 (1199.7326) nleep/row_max_std 11.6647 (14.3699) nleep/row_min_mean 1191.3976 (1189.4554) lr 3.6258e-04 eta 0:19:40
epoch [38/50] batch [120/246] time 0.437 (0.395) data 0.000 (0.002) loss 2.7642 (3.0903) teacher_loss 0.7243 (1.0750) loss_zs_kd 0.0518 (0.0420) loss_oracle 0.9928 (1.0126) kd_loss 1.5175 (1.4880) acc 81.2500 (71.9531) gate/entropy 0.9831 (0.9833) gate/usage_max 0.5681 (0.5679) gate/usage_min 0.2114 (0.2113) gate/usage_std 0.1660 (0.1659) teacher/entropy 0.0296 (0.0502) teacher/usage_max 0.9925 (0.9821) teacher/usage_min 0.0006 (0.0016) teacher/usage_std 0.4661 (0.4588) nleep/row_max_mean 1203.3054 (1199.8339) nleep/row_max_std 14.6808 (14.2601) nleep/row_min_mean 1192.1919 (1189.5421) lr 3.6258e-04 eta 0:20:14
epoch [38/50] batch [140/246] time 0.462 (0.406) data 0.000 (0.002) loss 2.7004 (3.0711) teacher_loss 0.6591 (1.0585) loss_zs_kd 0.0304 (0.0417) loss_oracle 1.0658 (1.0073) kd_loss 1.4932 (1.4881) acc 78.1250 (72.1205) gate/entropy 0.9830 (0.9833) gate/usage_max 0.5682 (0.5679) gate/usage_min 0.2114 (0.2113) gate/usage_std 0.1661 (0.1659) teacher/entropy 0.0486 (0.0500) teacher/usage_max 0.9864 (0.9821) teacher/usage_min 0.0014 (0.0017) teacher/usage_std 0.4618 (0.4588) nleep/row_max_mean 1202.4968 (1199.8955) nleep/row_max_std 15.4657 (14.4103) nleep/row_min_mean 1191.4978 (1189.5971) lr 3.6258e-04 eta 0:20:41
epoch [38/50] batch [160/246] time 0.450 (0.389) data 0.000 (0.002) loss 2.9171 (3.0758) teacher_loss 0.9367 (1.0696) loss_zs_kd 0.0239 (0.0409) loss_oracle 0.9655 (0.9974) kd_loss 1.4857 (1.4870) acc 71.8750 (71.8164) gate/entropy 0.9829 (0.9833) gate/usage_max 0.5683 (0.5679) gate/usage_min 0.2115 (0.2113) gate/usage_std 0.1662 (0.1659) teacher/entropy 0.0564 (0.0510) teacher/usage_max 0.9855 (0.9818) teacher/usage_min 0.0030 (0.0018) teacher/usage_std 0.4612 (0.4586) nleep/row_max_mean 1204.4053 (1199.9809) nleep/row_max_std 14.3164 (14.4380) nleep/row_min_mean 1193.8657 (1189.6923) lr 3.6258e-04 eta 0:19:43
epoch [38/50] batch [180/246] time 0.093 (0.378) data 0.000 (0.002) loss 2.9708 (3.0693) teacher_loss 0.8641 (1.0633) loss_zs_kd 0.0415 (0.0413) loss_oracle 1.1318 (0.9972) kd_loss 1.5201 (1.4867) acc 78.1250 (72.1875) gate/entropy 0.9829 (0.9832) gate/usage_max 0.5683 (0.5680) gate/usage_min 0.2115 (0.2114) gate/usage_std 0.1662 (0.1660) teacher/entropy 0.0294 (0.0512) teacher/usage_max 0.9937 (0.9815) teacher/usage_min 0.0023 (0.0020) teacher/usage_std 0.4669 (0.4584) nleep/row_max_mean 1202.1150 (1200.0216) nleep/row_max_std 13.8685 (14.4642) nleep/row_min_mean 1190.8026 (1189.7346) lr 3.6258e-04 eta 0:19:01
epoch [38/50] batch [200/246] time 0.081 (0.377) data 0.000 (0.002) loss 2.8893 (3.0668) teacher_loss 0.8620 (1.0583) loss_zs_kd 0.0186 (0.0409) loss_oracle 1.0376 (1.0022) kd_loss 1.4991 (1.4870) acc 78.1250 (72.3594) gate/entropy 0.9831 (0.9832) gate/usage_max 0.5682 (0.5680) gate/usage_min 0.2115 (0.2114) gate/usage_std 0.1661 (0.1660) teacher/entropy 0.0414 (0.0508) teacher/usage_max 0.9866 (0.9815) teacher/usage_min 0.0003 (0.0020) teacher/usage_std 0.4619 (0.4584) nleep/row_max_mean 1201.4592 (1200.1682) nleep/row_max_std 16.2539 (14.4682) nleep/row_min_mean 1190.6296 (1189.8654) lr 3.6258e-04 eta 0:18:49
epoch [38/50] batch [220/246] time 0.464 (0.382) data 0.000 (0.001) loss 2.8134 (3.0671) teacher_loss 0.8711 (1.0574) loss_zs_kd 0.0245 (0.0400) loss_oracle 0.8401 (1.0031) kd_loss 1.5100 (1.4881) acc 81.2500 (72.3438) gate/entropy 0.9830 (0.9832) gate/usage_max 0.5682 (0.5680) gate/usage_min 0.2115 (0.2114) gate/usage_std 0.1661 (0.1660) teacher/entropy 0.0372 (0.0500) teacher/usage_max 0.9917 (0.9820) teacher/usage_min 0.0021 (0.0019) teacher/usage_std 0.4656 (0.4588) nleep/row_max_mean 1203.7104 (1200.2671) nleep/row_max_std 13.4915 (14.4938) nleep/row_min_mean 1193.2734 (1189.9452) lr 3.6258e-04 eta 0:18:59
epoch [38/50] batch [240/246] time 0.472 (0.390) data 0.000 (0.001) loss 3.3072 (3.0642) teacher_loss 1.2853 (1.0565) loss_zs_kd 0.0597 (0.0400) loss_oracle 0.9386 (0.9988) kd_loss 1.5227 (1.4884) acc 65.6250 (72.3958) gate/entropy 0.9827 (0.9831) gate/usage_max 0.5685 (0.5681) gate/usage_min 0.2116 (0.2114) gate/usage_std 0.1663 (0.1660) teacher/entropy 0.0254 (0.0498) teacher/usage_max 0.9945 (0.9821) teacher/usage_min 0.0004 (0.0019) teacher/usage_std 0.4675 (0.4588) nleep/row_max_mean 1201.6403 (1200.3525) nleep/row_max_std 13.4714 (14.6186) nleep/row_min_mean 1191.2245 (1190.0277) lr 3.6258e-04 eta 0:19:14
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,813
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,941
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.3%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [39/50] batch [20/246] time 0.089 (0.308) data 0.000 (0.011) loss 2.5769 (2.9660) teacher_loss 0.6968 (0.9902) loss_zs_kd 0.0222 (0.0350) loss_oracle 0.7880 (0.9429) kd_loss 1.4750 (1.4868) acc 87.5000 (73.1250) gate/entropy 0.9827 (0.9829) gate/usage_max 0.5685 (0.5684) gate/usage_min 0.2116 (0.2116) gate/usage_std 0.1664 (0.1662) teacher/entropy 0.0614 (0.0508) teacher/usage_max 0.9825 (0.9822) teacher/usage_min 0.0006 (0.0022) teacher/usage_std 0.4591 (0.4588) nleep/row_max_mean 1202.5046 (1201.1467) nleep/row_max_std 12.5722 (14.0521) nleep/row_min_mean 1192.0068 (1190.8862) lr 3.1545e-04 eta 0:15:01
epoch [39/50] batch [40/246] time 0.083 (0.336) data 0.000 (0.006) loss 2.6933 (2.9821) teacher_loss 0.7527 (1.0018) loss_zs_kd 0.0245 (0.0379) loss_oracle 0.8397 (0.9535) kd_loss 1.5084 (1.4847) acc 71.8750 (72.1875) gate/entropy 0.9826 (0.9828) gate/usage_max 0.5687 (0.5684) gate/usage_min 0.2116 (0.2116) gate/usage_std 0.1665 (0.1663) teacher/entropy 0.0385 (0.0511) teacher/usage_max 0.9919 (0.9797) teacher/usage_min 0.0021 (0.0025) teacher/usage_std 0.4657 (0.4571) nleep/row_max_mean 1202.6012 (1201.1366) nleep/row_max_std 16.2609 (14.8873) nleep/row_min_mean 1192.4990 (1190.9599) lr 3.1545e-04 eta 0:16:18
epoch [39/50] batch [60/246] time 0.518 (0.369) data 0.000 (0.004) loss 2.8742 (2.9953) teacher_loss 0.9250 (1.0126) loss_zs_kd 0.0247 (0.0381) loss_oracle 0.9032 (0.9508) kd_loss 1.4852 (1.4883) acc 78.1250 (72.3438) gate/entropy 0.9827 (0.9828) gate/usage_max 0.5686 (0.5684) gate/usage_min 0.2116 (0.2116) gate/usage_std 0.1664 (0.1663) teacher/entropy 0.0572 (0.0488) teacher/usage_max 0.9866 (0.9815) teacher/usage_min 0.0030 (0.0022) teacher/usage_std 0.4619 (0.4584) nleep/row_max_mean 1199.5769 (1201.0119) nleep/row_max_std 16.0687 (15.0625) nleep/row_min_mean 1189.7780 (1190.8685) lr 3.1545e-04 eta 0:17:48
epoch [39/50] batch [80/246] time 0.492 (0.402) data 0.000 (0.003) loss 3.5599 (2.9975) teacher_loss 1.5504 (1.0157) loss_zs_kd 0.0320 (0.0372) loss_oracle 0.9397 (0.9480) kd_loss 1.5237 (1.4892) acc 62.5000 (72.5000) gate/entropy 0.9829 (0.9828) gate/usage_max 0.5684 (0.5685) gate/usage_min 0.2117 (0.2116) gate/usage_std 0.1662 (0.1663) teacher/entropy 0.0251 (0.0484) teacher/usage_max 0.9950 (0.9822) teacher/usage_min 0.0010 (0.0021) teacher/usage_std 0.4679 (0.4589) nleep/row_max_mean 1204.4993 (1200.7384) nleep/row_max_std 18.0967 (14.8390) nleep/row_min_mean 1194.4641 (1190.5904) lr 3.1545e-04 eta 0:19:15
epoch [39/50] batch [100/246] time 0.200 (0.418) data 0.000 (0.002) loss 3.0219 (3.0149) teacher_loss 0.9884 (1.0325) loss_zs_kd 0.0508 (0.0385) loss_oracle 0.9635 (0.9478) kd_loss 1.5264 (1.4893) acc 71.8750 (72.1562) gate/entropy 0.9826 (0.9828) gate/usage_max 0.5687 (0.5685) gate/usage_min 0.2117 (0.2116) gate/usage_std 0.1665 (0.1663) teacher/entropy 0.0222 (0.0485) teacher/usage_max 0.9957 (0.9826) teacher/usage_min 0.0002 (0.0020) teacher/usage_std 0.4684 (0.4592) nleep/row_max_mean 1199.9899 (1200.6080) nleep/row_max_std 14.9244 (14.7503) nleep/row_min_mean 1189.8885 (1190.4536) lr 3.1545e-04 eta 0:19:50
epoch [39/50] batch [120/246] time 0.568 (0.383) data 0.000 (0.002) loss 2.8749 (3.0108) teacher_loss 0.9970 (1.0318) loss_zs_kd 0.0291 (0.0389) loss_oracle 0.8519 (0.9457) kd_loss 1.4375 (1.4867) acc 71.8750 (72.1615) gate/entropy 0.9824 (0.9827) gate/usage_max 0.5688 (0.5685) gate/usage_min 0.2117 (0.2116) gate/usage_std 0.1665 (0.1663) teacher/entropy 0.0879 (0.0504) teacher/usage_max 0.9680 (0.9819) teacher/usage_min 0.0046 (0.0022) teacher/usage_std 0.4489 (0.4587) nleep/row_max_mean 1199.5090 (1200.2116) nleep/row_max_std 14.2106 (14.6300) nleep/row_min_mean 1189.7849 (1190.1170) lr 3.1545e-04 eta 0:18:04
epoch [39/50] batch [140/246] time 0.461 (0.363) data 0.000 (0.002) loss 3.6052 (3.0268) teacher_loss 1.6563 (1.0486) loss_zs_kd 0.0547 (0.0399) loss_oracle 0.8962 (0.9470) kd_loss 1.4735 (1.4848) acc 59.3750 (71.8527) gate/entropy 0.9824 (0.9827) gate/usage_max 0.5689 (0.5685) gate/usage_min 0.2117 (0.2117) gate/usage_std 0.1666 (0.1663) teacher/entropy 0.0612 (0.0517) teacher/usage_max 0.9793 (0.9811) teacher/usage_min 0.0028 (0.0023) teacher/usage_std 0.4568 (0.4581) nleep/row_max_mean 1201.0339 (1200.0989) nleep/row_max_std 13.9239 (14.5037) nleep/row_min_mean 1191.2329 (1190.0273) lr 3.1545e-04 eta 0:17:00
epoch [39/50] batch [160/246] time 0.466 (0.363) data 0.000 (0.002) loss 3.0272 (3.0357) teacher_loss 1.0145 (1.0571) loss_zs_kd 0.0331 (0.0397) loss_oracle 1.0269 (0.9471) kd_loss 1.4827 (1.4852) acc 75.0000 (71.6016) gate/entropy 0.9828 (0.9827) gate/usage_max 0.5685 (0.5686) gate/usage_min 0.2118 (0.2117) gate/usage_std 0.1663 (0.1664) teacher/entropy 0.0561 (0.0514) teacher/usage_max 0.9818 (0.9814) teacher/usage_min 0.0046 (0.0023) teacher/usage_std 0.4586 (0.4583) nleep/row_max_mean 1201.1465 (1200.0085) nleep/row_max_std 17.4435 (14.5143) nleep/row_min_mean 1191.4655 (1189.9602) lr 3.1545e-04 eta 0:16:53
epoch [39/50] batch [180/246] time 0.495 (0.376) data 0.000 (0.001) loss 2.8893 (3.0317) teacher_loss 0.8661 (1.0493) loss_zs_kd 0.0641 (0.0397) loss_oracle 1.0059 (0.9532) kd_loss 1.4883 (1.4859) acc 68.7500 (71.7708) gate/entropy 0.9825 (0.9827) gate/usage_max 0.5688 (0.5686) gate/usage_min 0.2118 (0.2117) gate/usage_std 0.1665 (0.1664) teacher/entropy 0.0400 (0.0508) teacher/usage_max 0.9753 (0.9816) teacher/usage_min 0.0004 (0.0022) teacher/usage_std 0.4541 (0.4585) nleep/row_max_mean 1202.5806 (1200.0648) nleep/row_max_std 13.9807 (14.5049) nleep/row_min_mean 1191.9106 (1190.0085) lr 3.1545e-04 eta 0:17:21
epoch [39/50] batch [200/246] time 0.478 (0.386) data 0.000 (0.001) loss 3.0640 (3.0328) teacher_loss 1.0244 (1.0497) loss_zs_kd 0.0585 (0.0401) loss_oracle 1.0753 (0.9578) kd_loss 1.4727 (1.4843) acc 68.7500 (71.7500) gate/entropy 0.9825 (0.9827) gate/usage_max 0.5688 (0.5686) gate/usage_min 0.2118 (0.2117) gate/usage_std 0.1665 (0.1664) teacher/entropy 0.0612 (0.0520) teacher/usage_max 0.9804 (0.9811) teacher/usage_min 0.0012 (0.0022) teacher/usage_std 0.4576 (0.4581) nleep/row_max_mean 1199.4077 (1200.0240) nleep/row_max_std 18.1931 (14.5477) nleep/row_min_mean 1189.2856 (1189.9767) lr 3.1545e-04 eta 0:17:43
epoch [39/50] batch [220/246] time 0.079 (0.390) data 0.000 (0.001) loss 3.0763 (3.0393) teacher_loss 1.0661 (1.0553) loss_zs_kd 0.0337 (0.0398) loss_oracle 1.0350 (0.9613) kd_loss 1.4759 (1.4835) acc 78.1250 (71.6619) gate/entropy 0.9823 (0.9826) gate/usage_max 0.5690 (0.5686) gate/usage_min 0.2118 (0.2117) gate/usage_std 0.1666 (0.1664) teacher/entropy 0.0593 (0.0525) teacher/usage_max 0.9775 (0.9810) teacher/usage_min 0.0056 (0.0022) teacher/usage_std 0.4555 (0.4580) nleep/row_max_mean 1198.9746 (1199.9921) nleep/row_max_std 13.8244 (14.6003) nleep/row_min_mean 1188.9263 (1189.9580) lr 3.1545e-04 eta 0:17:44
epoch [39/50] batch [240/246] time 0.467 (0.382) data 0.000 (0.001) loss 2.8286 (3.0398) teacher_loss 0.8258 (1.0550) loss_zs_kd 0.0429 (0.0397) loss_oracle 1.0552 (0.9653) kd_loss 1.4538 (1.4824) acc 81.2500 (71.6797) gate/entropy 0.9825 (0.9826) gate/usage_max 0.5688 (0.5686) gate/usage_min 0.2118 (0.2117) gate/usage_std 0.1665 (0.1664) teacher/entropy 0.0773 (0.0533) teacher/usage_max 0.9772 (0.9807) teacher/usage_min 0.0018 (0.0022) teacher/usage_std 0.4553 (0.4578) nleep/row_max_mean 1195.4668 (1199.8942) nleep/row_max_std 14.2336 (14.5853) nleep/row_min_mean 1185.5642 (1189.8780) lr 3.1545e-04 eta 0:17:14
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,817
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,936
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.2%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [40/50] batch [20/246] time 0.498 (0.493) data 0.000 (0.014) loss 2.5435 (3.1291) teacher_loss 0.5499 (1.1038) loss_zs_kd 0.0583 (0.0394) loss_oracle 0.9767 (1.0552) kd_loss 1.4760 (1.4780) acc 78.1250 (71.0938) gate/entropy 0.9825 (0.9824) gate/usage_max 0.5688 (0.5688) gate/usage_min 0.2119 (0.2119) gate/usage_std 0.1665 (0.1666) teacher/entropy 0.0585 (0.0562) teacher/usage_max 0.9800 (0.9781) teacher/usage_min 0.0025 (0.0037) teacher/usage_std 0.4573 (0.4560) nleep/row_max_mean 1202.3958 (1199.0997) nleep/row_max_std 12.3347 (14.3082) nleep/row_min_mean 1192.6986 (1189.1718) lr 2.7103e-04 eta 0:22:02
epoch [40/50] batch [40/246] time 0.496 (0.488) data 0.000 (0.007) loss 3.3822 (3.0894) teacher_loss 1.3579 (1.0585) loss_zs_kd 0.0414 (0.0402) loss_oracle 0.9964 (1.0610) kd_loss 1.5053 (1.4803) acc 62.5000 (72.4219) gate/entropy 0.9823 (0.9824) gate/usage_max 0.5689 (0.5689) gate/usage_min 0.2119 (0.2119) gate/usage_std 0.1666 (0.1666) teacher/entropy 0.0390 (0.0546) teacher/usage_max 0.9916 (0.9797) teacher/usage_min 0.0009 (0.0029) teacher/usage_std 0.4655 (0.4571) nleep/row_max_mean 1196.8164 (1199.0829) nleep/row_max_std 13.2366 (14.6103) nleep/row_min_mean 1187.4969 (1189.1614) lr 2.7103e-04 eta 0:21:41
epoch [40/50] batch [60/246] time 0.085 (0.449) data 0.000 (0.005) loss 2.8063 (3.0681) teacher_loss 0.7189 (1.0406) loss_zs_kd 0.0559 (0.0399) loss_oracle 1.1115 (1.0520) kd_loss 1.5037 (1.4815) acc 81.2500 (72.5000) gate/entropy 0.9824 (0.9824) gate/usage_max 0.5689 (0.5689) gate/usage_min 0.2119 (0.2119) gate/usage_std 0.1666 (0.1666) teacher/entropy 0.0385 (0.0530) teacher/usage_max 0.9900 (0.9797) teacher/usage_min 0.0006 (0.0026) teacher/usage_std 0.4643 (0.4571) nleep/row_max_mean 1198.8418 (1198.9829) nleep/row_max_std 12.9972 (14.4262) nleep/row_min_mean 1188.3896 (1189.0102) lr 2.7103e-04 eta 0:19:49
epoch [40/50] batch [80/246] time 0.495 (0.420) data 0.000 (0.004) loss 3.1052 (3.0598) teacher_loss 1.0547 (1.0322) loss_zs_kd 0.0497 (0.0396) loss_oracle 1.0410 (1.0529) kd_loss 1.5052 (1.4814) acc 68.7500 (72.8906) gate/entropy 0.9822 (0.9824) gate/usage_max 0.5691 (0.5689) gate/usage_min 0.2119 (0.2119) gate/usage_std 0.1667 (0.1666) teacher/entropy 0.0355 (0.0530) teacher/usage_max 0.9888 (0.9796) teacher/usage_min 0.0002 (0.0026) teacher/usage_std 0.4635 (0.4570) nleep/row_max_mean 1203.7502 (1199.0530) nleep/row_max_std 14.0083 (14.4543) nleep/row_min_mean 1192.7568 (1189.0294) lr 2.7103e-04 eta 0:18:23
epoch [40/50] batch [100/246] time 0.492 (0.386) data 0.000 (0.003) loss 3.0816 (3.0417) teacher_loss 1.1488 (1.0141) loss_zs_kd 0.0388 (0.0390) loss_oracle 0.9140 (1.0511) kd_loss 1.4564 (1.4825) acc 62.5000 (73.2812) gate/entropy 0.9823 (0.9824) gate/usage_max 0.5690 (0.5689) gate/usage_min 0.2119 (0.2119) gate/usage_std 0.1667 (0.1666) teacher/entropy 0.0793 (0.0526) teacher/usage_max 0.9762 (0.9804) teacher/usage_min 0.0081 (0.0026) teacher/usage_std 0.4546 (0.4576) nleep/row_max_mean 1197.5464 (1199.1115) nleep/row_max_std 14.0966 (14.4854) nleep/row_min_mean 1187.8068 (1189.0699) lr 2.7103e-04 eta 0:16:46
epoch [40/50] batch [120/246] time 0.475 (0.383) data 0.000 (0.002) loss 3.0527 (3.0271) teacher_loss 1.0204 (0.9985) loss_zs_kd 0.0465 (0.0382) loss_oracle 1.0322 (1.0524) kd_loss 1.4929 (1.4833) acc 75.0000 (73.6458) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5689) gate/usage_min 0.2119 (0.2119) gate/usage_std 0.1667 (0.1666) teacher/entropy 0.0495 (0.0519) teacher/usage_max 0.9872 (0.9806) teacher/usage_min 0.0038 (0.0027) teacher/usage_std 0.4623 (0.4577) nleep/row_max_mean 1196.1885 (1199.3666) nleep/row_max_std 11.3299 (14.4039) nleep/row_min_mean 1186.6664 (1189.3135) lr 2.7103e-04 eta 0:16:29
epoch [40/50] batch [140/246] time 0.453 (0.398) data 0.000 (0.002) loss 3.2799 (3.0102) teacher_loss 1.2371 (0.9808) loss_zs_kd 0.0547 (0.0374) loss_oracle 1.0580 (1.0506) kd_loss 1.4864 (1.4854) acc 62.5000 (74.0848) gate/entropy 0.9825 (0.9823) gate/usage_max 0.5688 (0.5689) gate/usage_min 0.2120 (0.2119) gate/usage_std 0.1665 (0.1666) teacher/entropy 0.0485 (0.0505) teacher/usage_max 0.9819 (0.9814) teacher/usage_min 0.0016 (0.0025) teacher/usage_std 0.4586 (0.4583) nleep/row_max_mean 1199.2478 (1199.4758) nleep/row_max_std 15.2656 (14.3427) nleep/row_min_mean 1188.4116 (1189.4178) lr 2.7103e-04 eta 0:17:00
epoch [40/50] batch [160/246] time 0.496 (0.409) data 0.000 (0.002) loss 3.2145 (3.0182) teacher_loss 1.1481 (0.9933) loss_zs_kd 0.0531 (0.0377) loss_oracle 1.0359 (1.0425) kd_loss 1.5219 (1.4849) acc 75.0000 (73.7305) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2120 (0.2119) gate/usage_std 0.1667 (0.1666) teacher/entropy 0.0277 (0.0511) teacher/usage_max 0.9920 (0.9815) teacher/usage_min 0.0015 (0.0026) teacher/usage_std 0.4658 (0.4584) nleep/row_max_mean 1202.0989 (1199.4465) nleep/row_max_std 16.3044 (14.4702) nleep/row_min_mean 1192.0670 (1189.4251) lr 2.7103e-04 eta 0:17:20
epoch [40/50] batch [180/246] time 0.303 (0.397) data 0.000 (0.002) loss 2.8196 (3.0234) teacher_loss 0.8273 (1.0031) loss_zs_kd 0.0444 (0.0380) loss_oracle 0.9680 (1.0336) kd_loss 1.4861 (1.4844) acc 68.7500 (73.3507) gate/entropy 0.9824 (0.9823) gate/usage_max 0.5689 (0.5690) gate/usage_min 0.2120 (0.2119) gate/usage_std 0.1666 (0.1666) teacher/entropy 0.0529 (0.0514) teacher/usage_max 0.9869 (0.9814) teacher/usage_min 0.0009 (0.0025) teacher/usage_std 0.4621 (0.4583) nleep/row_max_mean 1200.1934 (1199.4326) nleep/row_max_std 17.3759 (14.5041) nleep/row_min_mean 1189.8774 (1189.4212) lr 2.7103e-04 eta 0:16:42
epoch [40/50] batch [200/246] time 0.080 (0.389) data 0.000 (0.002) loss 3.0100 (3.0286) teacher_loss 0.9083 (1.0072) loss_zs_kd 0.0363 (0.0379) loss_oracle 1.1945 (1.0346) kd_loss 1.4864 (1.4851) acc 75.0000 (73.2812) gate/entropy 0.9821 (0.9823) gate/usage_max 0.5692 (0.5690) gate/usage_min 0.2120 (0.2119) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0478 (0.0508) teacher/usage_max 0.9825 (0.9818) teacher/usage_min 0.0003 (0.0023) teacher/usage_std 0.4591 (0.4586) nleep/row_max_mean 1207.9912 (1199.5667) nleep/row_max_std 15.1684 (14.5241) nleep/row_min_mean 1196.6876 (1189.5509) lr 2.7103e-04 eta 0:16:15
epoch [40/50] batch [220/246] time 0.511 (0.387) data 0.000 (0.001) loss 3.2950 (3.0314) teacher_loss 1.2935 (1.0099) loss_zs_kd 0.0559 (0.0381) loss_oracle 0.9695 (1.0337) kd_loss 1.4888 (1.4855) acc 68.7500 (73.1108) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2120 (0.2119) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0488 (0.0505) teacher/usage_max 0.9860 (0.9820) teacher/usage_min 0.0005 (0.0023) teacher/usage_std 0.4615 (0.4587) nleep/row_max_mean 1199.3810 (1199.5633) nleep/row_max_std 18.5610 (14.5888) nleep/row_min_mean 1189.0554 (1189.5501) lr 2.7103e-04 eta 0:16:03
epoch [40/50] batch [240/246] time 0.434 (0.388) data 0.000 (0.001) loss 3.3178 (3.0359) teacher_loss 1.2734 (1.0149) loss_zs_kd 0.0497 (0.0382) loss_oracle 1.0924 (1.0331) kd_loss 1.4734 (1.4853) acc 71.8750 (72.9818) gate/entropy 0.9820 (0.9823) gate/usage_max 0.5692 (0.5690) gate/usage_min 0.2120 (0.2119) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0463 (0.0506) teacher/usage_max 0.9678 (0.9819) teacher/usage_min 0.0006 (0.0023) teacher/usage_std 0.4488 (0.4587) nleep/row_max_mean 1202.8391 (1199.6384) nleep/row_max_std 16.2481 (14.7223) nleep/row_min_mean 1192.5278 (1189.6089) lr 2.7103e-04 eta 0:15:55
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,814
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,935
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.2%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [41/50] batch [20/246] time 0.081 (0.438) data 0.000 (0.013) loss 3.2818 (3.0044) teacher_loss 1.3209 (0.9872) loss_zs_kd 0.0681 (0.0376) loss_oracle 0.9401 (1.0165) kd_loss 1.4567 (1.4902) acc 65.6250 (72.9688) gate/entropy 0.9821 (0.9821) gate/usage_max 0.5692 (0.5692) gate/usage_min 0.2121 (0.2121) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0771 (0.0463) teacher/usage_max 0.9807 (0.9835) teacher/usage_min 0.0022 (0.0020) teacher/usage_std 0.4578 (0.4598) nleep/row_max_mean 1195.7031 (1201.9378) nleep/row_max_std 15.7389 (16.2777) nleep/row_min_mean 1186.2654 (1191.6470) lr 2.2949e-04 eta 0:17:48
epoch [41/50] batch [40/246] time 0.475 (0.353) data 0.000 (0.007) loss 3.7642 (3.0449) teacher_loss 1.7499 (1.0191) loss_zs_kd 0.0517 (0.0404) loss_oracle 0.9565 (1.0262) kd_loss 1.5102 (1.4925) acc 65.6250 (73.7500) gate/entropy 0.9822 (0.9821) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2121 (0.2121) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0354 (0.0461) teacher/usage_max 0.9924 (0.9853) teacher/usage_min 0.0026 (0.0022) teacher/usage_std 0.4660 (0.4610) nleep/row_max_mean 1199.0466 (1200.6547) nleep/row_max_std 15.6004 (16.5751) nleep/row_min_mean 1188.8447 (1190.3841) lr 2.2949e-04 eta 0:14:15
epoch [41/50] batch [60/246] time 0.464 (0.317) data 0.001 (0.005) loss 2.9734 (3.0219) teacher_loss 0.9827 (1.0020) loss_zs_kd 0.0297 (0.0374) loss_oracle 0.9346 (1.0174) kd_loss 1.5086 (1.4925) acc 75.0000 (72.6042) gate/entropy 0.9820 (0.9821) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2121 (0.2121) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.0364 (0.0461) teacher/usage_max 0.9912 (0.9855) teacher/usage_min 0.0031 (0.0020) teacher/usage_std 0.4652 (0.4612) nleep/row_max_mean 1197.9966 (1200.3707) nleep/row_max_std 12.9174 (16.4212) nleep/row_min_mean 1187.5730 (1190.1541) lr 2.2949e-04 eta 0:12:40
epoch [41/50] batch [80/246] time 0.522 (0.331) data 0.000 (0.003) loss 2.7680 (3.0209) teacher_loss 0.7937 (1.0013) loss_zs_kd 0.0372 (0.0373) loss_oracle 0.9444 (1.0221) kd_loss 1.4834 (1.4899) acc 78.1250 (72.2656) gate/entropy 0.9822 (0.9821) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2121 (0.2121) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0549 (0.0474) teacher/usage_max 0.9863 (0.9840) teacher/usage_min 0.0013 (0.0022) teacher/usage_std 0.4617 (0.4602) nleep/row_max_mean 1201.0588 (1200.3330) nleep/row_max_std 15.6924 (16.4239) nleep/row_min_mean 1191.2869 (1190.1307) lr 2.2949e-04 eta 0:13:07
epoch [41/50] batch [100/246] time 0.497 (0.361) data 0.000 (0.003) loss 2.9530 (3.0551) teacher_loss 0.8467 (1.0318) loss_zs_kd 0.0238 (0.0378) loss_oracle 1.1400 (1.0302) kd_loss 1.5244 (1.4894) acc 68.7500 (71.6875) gate/entropy 0.9819 (0.9821) gate/usage_max 0.5694 (0.5692) gate/usage_min 0.2121 (0.2121) gate/usage_std 0.1670 (0.1668) teacher/entropy 0.0222 (0.0476) teacher/usage_max 0.9958 (0.9838) teacher/usage_min 0.0002 (0.0022) teacher/usage_std 0.4684 (0.4600) nleep/row_max_mean 1200.5239 (1200.0576) nleep/row_max_std 12.1133 (16.1384) nleep/row_min_mean 1190.2048 (1189.8888) lr 2.2949e-04 eta 0:14:12
epoch [41/50] batch [120/246] time 0.551 (0.383) data 0.000 (0.002) loss 3.0557 (3.0735) teacher_loss 1.0426 (1.0469) loss_zs_kd 0.0465 (0.0387) loss_oracle 1.0295 (1.0384) kd_loss 1.4751 (1.4881) acc 62.5000 (71.4323) gate/entropy 0.9821 (0.9821) gate/usage_max 0.5692 (0.5692) gate/usage_min 0.2121 (0.2121) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0578 (0.0482) teacher/usage_max 0.9811 (0.9831) teacher/usage_min 0.0012 (0.0022) teacher/usage_std 0.4581 (0.4595) nleep/row_max_mean 1198.1085 (1199.8194) nleep/row_max_std 15.4740 (16.0245) nleep/row_min_mean 1187.6531 (1189.6731) lr 2.2949e-04 eta 0:14:55
epoch [41/50] batch [140/246] time 0.079 (0.377) data 0.000 (0.002) loss 2.8118 (3.0651) teacher_loss 0.8425 (1.0366) loss_zs_kd 0.0330 (0.0387) loss_oracle 1.0521 (1.0427) kd_loss 1.4268 (1.4878) acc 78.1250 (71.9643) gate/entropy 0.9822 (0.9821) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2122 (0.2121) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0837 (0.0484) teacher/usage_max 0.9507 (0.9830) teacher/usage_min 0.0092 (0.0022) teacher/usage_std 0.4367 (0.4594) nleep/row_max_mean 1197.2161 (1199.8024) nleep/row_max_std 17.8336 (16.0304) nleep/row_min_mean 1187.0901 (1189.6464) lr 2.2949e-04 eta 0:14:33
epoch [41/50] batch [160/246] time 0.082 (0.371) data 0.000 (0.002) loss 3.0546 (3.0567) teacher_loss 1.0691 (1.0272) loss_zs_kd 0.0552 (0.0385) loss_oracle 0.9472 (1.0459) kd_loss 1.4843 (1.4873) acc 68.7500 (72.1289) gate/entropy 0.9823 (0.9821) gate/usage_max 0.5690 (0.5692) gate/usage_min 0.2122 (0.2121) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0461 (0.0488) teacher/usage_max 0.9796 (0.9830) teacher/usage_min 0.0004 (0.0022) teacher/usage_std 0.4570 (0.4594) nleep/row_max_mean 1194.5928 (1199.5846) nleep/row_max_std 11.6044 (15.9013) nleep/row_min_mean 1184.3588 (1189.4580) lr 2.2949e-04 eta 0:14:13
epoch [41/50] batch [180/246] time 0.129 (0.370) data 0.000 (0.002) loss 2.7720 (3.0645) teacher_loss 0.7826 (1.0353) loss_zs_kd 0.0498 (0.0389) loss_oracle 0.8898 (1.0423) kd_loss 1.5197 (1.4886) acc 78.1250 (72.1007) gate/entropy 0.9820 (0.9821) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2122 (0.2121) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.0262 (0.0480) teacher/usage_max 0.9951 (0.9835) teacher/usage_min 0.0004 (0.0021) teacher/usage_std 0.4680 (0.4598) nleep/row_max_mean 1201.6958 (1199.5484) nleep/row_max_std 12.5286 (15.8040) nleep/row_min_mean 1191.6508 (1189.4138) lr 2.2949e-04 eta 0:14:04
epoch [41/50] batch [200/246] time 0.495 (0.372) data 0.000 (0.002) loss 3.0506 (3.0543) teacher_loss 1.0776 (1.0278) loss_zs_kd 0.0353 (0.0387) loss_oracle 0.9766 (1.0370) kd_loss 1.4670 (1.4886) acc 75.0000 (72.2656) gate/entropy 0.9820 (0.9821) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2122 (0.2121) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.0639 (0.0479) teacher/usage_max 0.9791 (0.9835) teacher/usage_min 0.0014 (0.0021) teacher/usage_std 0.4567 (0.4598) nleep/row_max_mean 1199.3616 (1199.5439) nleep/row_max_std 13.3768 (15.6146) nleep/row_min_mean 1188.9351 (1189.4066) lr 2.2949e-04 eta 0:14:01
epoch [41/50] batch [220/246] time 0.497 (0.382) data 0.000 (0.001) loss 3.5155 (3.0521) teacher_loss 1.4069 (1.0245) loss_zs_kd 0.0427 (0.0385) loss_oracle 1.1423 (1.0378) kd_loss 1.5161 (1.4895) acc 65.6250 (72.3722) gate/entropy 0.9819 (0.9820) gate/usage_max 0.5694 (0.5692) gate/usage_min 0.2122 (0.2121) gate/usage_std 0.1670 (0.1668) teacher/entropy 0.0280 (0.0473) teacher/usage_max 0.9933 (0.9839) teacher/usage_min 0.0005 (0.0020) teacher/usage_std 0.4667 (0.4601) nleep/row_max_mean 1199.6146 (1199.5584) nleep/row_max_std 14.0538 (15.5114) nleep/row_min_mean 1189.2476 (1189.4112) lr 2.2949e-04 eta 0:14:16
epoch [41/50] batch [240/246] time 0.493 (0.390) data 0.000 (0.001) loss 2.9888 (3.0557) teacher_loss 0.9388 (1.0284) loss_zs_kd 0.0570 (0.0388) loss_oracle 1.1643 (1.0377) kd_loss 1.4394 (1.4891) acc 75.0000 (72.2917) gate/entropy 0.9822 (0.9820) gate/usage_max 0.5691 (0.5693) gate/usage_min 0.2122 (0.2121) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0727 (0.0474) teacher/usage_max 0.9585 (0.9836) teacher/usage_min 0.0030 (0.0021) teacher/usage_std 0.4423 (0.4598) nleep/row_max_mean 1199.5895 (1199.6243) nleep/row_max_std 17.3060 (15.4011) nleep/row_min_mean 1189.4933 (1189.4602) lr 2.2949e-04 eta 0:14:26
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,815
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,937
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.2%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [42/50] batch [20/246] time 0.471 (0.426) data 0.000 (0.014) loss 2.4639 (3.0498) teacher_loss 0.4606 (0.9869) loss_zs_kd 0.0229 (0.0349) loss_oracle 1.0673 (1.0894) kd_loss 1.4582 (1.5008) acc 87.5000 (73.5938) gate/entropy 0.9820 (0.9819) gate/usage_max 0.5693 (0.5694) gate/usage_min 0.2122 (0.2122) gate/usage_std 0.1669 (0.1669) teacher/entropy 0.0678 (0.0378) teacher/usage_max 0.9746 (0.9870) teacher/usage_min 0.0011 (0.0014) teacher/usage_std 0.4536 (0.4623) nleep/row_max_mean 1201.8124 (1201.1178) nleep/row_max_std 14.1307 (13.8882) nleep/row_min_mean 1191.7201 (1190.5835) lr 1.9098e-04 eta 0:15:35
epoch [42/50] batch [40/246] time 0.417 (0.462) data 0.000 (0.007) loss 3.0367 (3.0386) teacher_loss 0.8913 (0.9813) loss_zs_kd 0.0566 (0.0389) loss_oracle 1.1889 (1.0761) kd_loss 1.5226 (1.4998) acc 78.1250 (73.9844) gate/entropy 0.9822 (0.9819) gate/usage_max 0.5691 (0.5694) gate/usage_min 0.2123 (0.2122) gate/usage_std 0.1667 (0.1669) teacher/entropy 0.0242 (0.0398) teacher/usage_max 0.9955 (0.9880) teacher/usage_min 0.0013 (0.0015) teacher/usage_std 0.4682 (0.4629) nleep/row_max_mean 1199.0054 (1200.0908) nleep/row_max_std 15.2787 (14.1239) nleep/row_min_mean 1188.3413 (1189.7576) lr 1.9098e-04 eta 0:16:43
epoch [42/50] batch [60/246] time 0.494 (0.470) data 0.000 (0.005) loss 3.4620 (3.0429) teacher_loss 1.4303 (0.9919) loss_zs_kd 0.0476 (0.0386) loss_oracle 1.0165 (1.0665) kd_loss 1.4996 (1.4984) acc 65.6250 (73.7500) gate/entropy 0.9816 (0.9819) gate/usage_max 0.5698 (0.5694) gate/usage_min 0.2122 (0.2122) gate/usage_std 0.1672 (0.1669) teacher/entropy 0.0417 (0.0397) teacher/usage_max 0.9908 (0.9865) teacher/usage_min 0.0004 (0.0015) teacher/usage_std 0.4649 (0.4619) nleep/row_max_mean 1203.3264 (1200.1504) nleep/row_max_std 14.8139 (14.0789) nleep/row_min_mean 1193.0386 (1189.8551) lr 1.9098e-04 eta 0:16:52
epoch [42/50] batch [80/246] time 0.086 (0.429) data 0.000 (0.004) loss 3.0453 (3.0639) teacher_loss 1.0667 (1.0132) loss_zs_kd 0.0284 (0.0391) loss_oracle 0.9654 (1.0645) kd_loss 1.4817 (1.4989) acc 75.0000 (72.9297) gate/entropy 0.9819 (0.9819) gate/usage_max 0.5695 (0.5694) gate/usage_min 0.2123 (0.2122) gate/usage_std 0.1670 (0.1669) teacher/entropy 0.0577 (0.0396) teacher/usage_max 0.9869 (0.9867) teacher/usage_min 0.0026 (0.0016) teacher/usage_std 0.4621 (0.4620) nleep/row_max_mean 1195.9180 (1200.1775) nleep/row_max_std 13.5465 (14.2286) nleep/row_min_mean 1186.4785 (1189.8951) lr 1.9098e-04 eta 0:15:15
epoch [42/50] batch [100/246] time 0.086 (0.409) data 0.000 (0.003) loss 3.5507 (3.0622) teacher_loss 1.4796 (1.0133) loss_zs_kd 0.0462 (0.0396) loss_oracle 1.0390 (1.0617) kd_loss 1.5285 (1.4982) acc 53.1250 (72.8750) gate/entropy 0.9819 (0.9819) gate/usage_max 0.5695 (0.5694) gate/usage_min 0.2123 (0.2123) gate/usage_std 0.1670 (0.1669) teacher/entropy 0.0181 (0.0403) teacher/usage_max 0.9964 (0.9865) teacher/usage_min 0.0002 (0.0018) teacher/usage_std 0.4689 (0.4619) nleep/row_max_mean 1203.3245 (1200.0042) nleep/row_max_std 15.4345 (14.3535) nleep/row_min_mean 1192.7314 (1189.7506) lr 1.9098e-04 eta 0:14:25
epoch [42/50] batch [120/246] time 0.485 (0.400) data 0.000 (0.002) loss 3.4207 (3.0589) teacher_loss 1.5248 (1.0109) loss_zs_kd 0.0421 (0.0398) loss_oracle 0.8995 (1.0608) kd_loss 1.4251 (1.4977) acc 62.5000 (72.8906) gate/entropy 0.9818 (0.9819) gate/usage_max 0.5695 (0.5694) gate/usage_min 0.2123 (0.2123) gate/usage_std 0.1670 (0.1669) teacher/entropy 0.0991 (0.0408) teacher/usage_max 0.9688 (0.9866) teacher/usage_min 0.0055 (0.0018) teacher/usage_std 0.4494 (0.4619) nleep/row_max_mean 1195.1802 (1199.8766) nleep/row_max_std 12.4073 (14.4002) nleep/row_min_mean 1186.0623 (1189.6366) lr 1.9098e-04 eta 0:13:57
epoch [42/50] batch [140/246] time 0.439 (0.395) data 0.000 (0.002) loss 2.5462 (3.0665) teacher_loss 0.4708 (1.0200) loss_zs_kd 0.0322 (0.0402) loss_oracle 1.1031 (1.0583) kd_loss 1.5077 (1.4973) acc 87.5000 (72.7455) gate/entropy 0.9819 (0.9819) gate/usage_max 0.5694 (0.5694) gate/usage_min 0.2123 (0.2123) gate/usage_std 0.1670 (0.1669) teacher/entropy 0.0354 (0.0412) teacher/usage_max 0.9926 (0.9865) teacher/usage_min 0.0007 (0.0018) teacher/usage_std 0.4662 (0.4619) nleep/row_max_mean 1196.8754 (1199.7447) nleep/row_max_std 12.1181 (14.3794) nleep/row_min_mean 1187.0630 (1189.5317) lr 1.9098e-04 eta 0:13:39
epoch [42/50] batch [160/246] time 0.472 (0.407) data 0.000 (0.002) loss 3.1376 (3.0682) teacher_loss 1.1106 (1.0230) loss_zs_kd 0.0374 (0.0399) loss_oracle 1.1253 (1.0590) kd_loss 1.4456 (1.4958) acc 65.6250 (72.6172) gate/entropy 0.9820 (0.9819) gate/usage_max 0.5693 (0.5694) gate/usage_min 0.2123 (0.2123) gate/usage_std 0.1669 (0.1669) teacher/entropy 0.0800 (0.0423) teacher/usage_max 0.9657 (0.9860) teacher/usage_min 0.0102 (0.0019) teacher/usage_std 0.4472 (0.4616) nleep/row_max_mean 1197.2067 (1199.6913) nleep/row_max_std 17.9411 (14.3920) nleep/row_min_mean 1187.7683 (1189.5108) lr 1.9098e-04 eta 0:13:55
epoch [42/50] batch [180/246] time 0.519 (0.415) data 0.000 (0.002) loss 2.9781 (3.0701) teacher_loss 0.9570 (1.0279) loss_zs_kd 0.0187 (0.0399) loss_oracle 1.0873 (1.0576) kd_loss 1.4680 (1.4934) acc 81.2500 (72.4653) gate/entropy 0.9819 (0.9819) gate/usage_max 0.5694 (0.5694) gate/usage_min 0.2123 (0.2123) gate/usage_std 0.1669 (0.1670) teacher/entropy 0.0619 (0.0438) teacher/usage_max 0.9784 (0.9852) teacher/usage_min 0.0017 (0.0020) teacher/usage_std 0.4562 (0.4609) nleep/row_max_mean 1197.3149 (1199.5172) nleep/row_max_std 14.8605 (14.3398) nleep/row_min_mean 1187.4973 (1189.3734) lr 1.9098e-04 eta 0:14:04
epoch [42/50] batch [200/246] time 0.150 (0.395) data 0.000 (0.002) loss 3.1755 (3.0780) teacher_loss 1.0909 (1.0361) loss_zs_kd 0.0649 (0.0398) loss_oracle 1.1952 (1.0583) kd_loss 1.4545 (1.4929) acc 62.5000 (72.1562) gate/entropy 0.9818 (0.9819) gate/usage_max 0.5695 (0.5694) gate/usage_min 0.2123 (0.2123) gate/usage_std 0.1670 (0.1670) teacher/entropy 0.0728 (0.0442) teacher/usage_max 0.9698 (0.9850) teacher/usage_min 0.0079 (0.0020) teacher/usage_std 0.4501 (0.4608) nleep/row_max_mean 1197.8672 (1199.4040) nleep/row_max_std 16.0141 (14.3108) nleep/row_min_mean 1188.0504 (1189.2694) lr 1.9098e-04 eta 0:13:16
epoch [42/50] batch [220/246] time 0.082 (0.386) data 0.000 (0.001) loss 2.8530 (3.0690) teacher_loss 0.8185 (1.0279) loss_zs_kd 0.0398 (0.0399) loss_oracle 1.0535 (1.0575) kd_loss 1.4879 (1.4923) acc 81.2500 (72.3438) gate/entropy 0.9817 (0.9819) gate/usage_max 0.5697 (0.5694) gate/usage_min 0.2123 (0.2123) gate/usage_std 0.1671 (0.1670) teacher/entropy 0.0518 (0.0445) teacher/usage_max 0.9861 (0.9846) teacher/usage_min 0.0040 (0.0021) teacher/usage_std 0.4616 (0.4606) nleep/row_max_mean 1199.6226 (1199.3254) nleep/row_max_std 17.1554 (14.2640) nleep/row_min_mean 1189.6296 (1189.1884) lr 1.9098e-04 eta 0:12:49
epoch [42/50] batch [240/246] time 0.079 (0.384) data 0.000 (0.001) loss 3.0203 (3.0682) teacher_loss 1.0082 (1.0288) loss_zs_kd 0.0550 (0.0397) loss_oracle 0.9905 (1.0539) kd_loss 1.4894 (1.4926) acc 78.1250 (72.3698) gate/entropy 0.9817 (0.9819) gate/usage_max 0.5697 (0.5694) gate/usage_min 0.2124 (0.2123) gate/usage_std 0.1671 (0.1670) teacher/entropy 0.0525 (0.0442) teacher/usage_max 0.9891 (0.9847) teacher/usage_min 0.0033 (0.0021) teacher/usage_std 0.4637 (0.4606) nleep/row_max_mean 1194.1367 (1199.3174) nleep/row_max_std 10.2738 (14.2264) nleep/row_min_mean 1184.7662 (1189.1835) lr 1.9098e-04 eta 0:12:37
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,819
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,935
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.2%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [43/50] batch [20/246] time 0.495 (0.519) data 0.000 (0.019) loss 2.6990 (3.0551) teacher_loss 0.6696 (1.0160) loss_zs_kd 0.0446 (0.0443) loss_oracle 1.0391 (1.0537) kd_loss 1.4875 (1.4901) acc 84.3750 (72.5000) gate/entropy 0.9817 (0.9818) gate/usage_max 0.5696 (0.5695) gate/usage_min 0.2124 (0.2124) gate/usage_std 0.1671 (0.1670) teacher/entropy 0.0475 (0.0453) teacher/usage_max 0.9850 (0.9847) teacher/usage_min 0.0004 (0.0012) teacher/usage_std 0.4608 (0.4606) nleep/row_max_mean 1201.6699 (1198.8279) nleep/row_max_std 13.7555 (13.7850) nleep/row_min_mean 1191.1989 (1188.6504) lr 1.5567e-04 eta 0:16:51
epoch [43/50] batch [40/246] time 0.091 (0.453) data 0.000 (0.009) loss 3.4084 (2.9992) teacher_loss 1.4402 (0.9712) loss_zs_kd 0.0347 (0.0430) loss_oracle 0.9956 (1.0439) kd_loss 1.4530 (1.4845) acc 59.3750 (74.1406) gate/entropy 0.9819 (0.9818) gate/usage_max 0.5694 (0.5695) gate/usage_min 0.2124 (0.2124) gate/usage_std 0.1669 (0.1670) teacher/entropy 0.0799 (0.0490) teacher/usage_max 0.9706 (0.9818) teacher/usage_min 0.0132 (0.0021) teacher/usage_std 0.4506 (0.4586) nleep/row_max_mean 1198.4586 (1198.5616) nleep/row_max_std 14.1345 (13.9663) nleep/row_min_mean 1188.5844 (1188.4985) lr 1.5567e-04 eta 0:14:32
epoch [43/50] batch [60/246] time 0.080 (0.413) data 0.000 (0.006) loss 3.8017 (3.0460) teacher_loss 1.8509 (1.0233) loss_zs_kd 0.0580 (0.0431) loss_oracle 0.8934 (1.0292) kd_loss 1.4752 (1.4866) acc 56.2500 (72.7604) gate/entropy 0.9815 (0.9818) gate/usage_max 0.5698 (0.5695) gate/usage_min 0.2124 (0.2124) gate/usage_std 0.1672 (0.1670) teacher/entropy 0.0545 (0.0482) teacher/usage_max 0.9788 (0.9827) teacher/usage_min 0.0012 (0.0026) teacher/usage_std 0.4565 (0.4592) nleep/row_max_mean 1197.8484 (1198.7806) nleep/row_max_std 15.9249 (14.3136) nleep/row_min_mean 1188.2423 (1188.7363) lr 1.5567e-04 eta 0:13:08
epoch [43/50] batch [80/246] time 0.478 (0.385) data 0.000 (0.005) loss 2.7084 (3.0210) teacher_loss 0.7906 (1.0098) loss_zs_kd 0.0525 (0.0407) loss_oracle 0.8411 (1.0110) kd_loss 1.4710 (1.4853) acc 81.2500 (72.8125) gate/entropy 0.9818 (0.9818) gate/usage_max 0.5696 (0.5695) gate/usage_min 0.2124 (0.2124) gate/usage_std 0.1671 (0.1670) teacher/entropy 0.0589 (0.0493) teacher/usage_max 0.9784 (0.9827) teacher/usage_min 0.0020 (0.0025) teacher/usage_std 0.4562 (0.4592) nleep/row_max_mean 1194.9435 (1198.5813) nleep/row_max_std 13.5619 (14.0995) nleep/row_min_mean 1185.5942 (1188.6074) lr 1.5567e-04 eta 0:12:07
epoch [43/50] batch [100/246] time 0.471 (0.384) data 0.000 (0.004) loss 3.2323 (3.0370) teacher_loss 1.2516 (1.0323) loss_zs_kd 0.0579 (0.0399) loss_oracle 1.0609 (1.0032) kd_loss 1.4212 (1.4832) acc 71.8750 (72.0625) gate/entropy 0.9818 (0.9818) gate/usage_max 0.5696 (0.5695) gate/usage_min 0.2124 (0.2124) gate/usage_std 0.1671 (0.1670) teacher/entropy 0.0971 (0.0510) teacher/usage_max 0.9337 (0.9819) teacher/usage_min 0.0303 (0.0028) teacher/usage_std 0.4246 (0.4587) nleep/row_max_mean 1201.6282 (1198.6191) nleep/row_max_std 14.9340 (14.0076) nleep/row_min_mean 1191.4646 (1188.6950) lr 1.5567e-04 eta 0:11:58
epoch [43/50] batch [120/246] time 0.471 (0.400) data 0.000 (0.003) loss 2.6473 (3.0261) teacher_loss 0.6110 (1.0198) loss_zs_kd 0.0378 (0.0389) loss_oracle 1.0200 (1.0045) kd_loss 1.5073 (1.4847) acc 84.3750 (72.4479) gate/entropy 0.9820 (0.9818) gate/usage_max 0.5693 (0.5695) gate/usage_min 0.2124 (0.2124) gate/usage_std 0.1669 (0.1670) teacher/entropy 0.0363 (0.0501) teacher/usage_max 0.9923 (0.9825) teacher/usage_min 0.0022 (0.0028) teacher/usage_std 0.4660 (0.4591) nleep/row_max_mean 1195.3516 (1198.6186) nleep/row_max_std 11.7763 (13.9858) nleep/row_min_mean 1185.4138 (1188.7090) lr 1.5567e-04 eta 0:12:19
epoch [43/50] batch [140/246] time 0.496 (0.412) data 0.000 (0.003) loss 3.0398 (3.0358) teacher_loss 1.0381 (1.0279) loss_zs_kd 0.0274 (0.0388) loss_oracle 1.0546 (1.0087) kd_loss 1.4607 (1.4843) acc 75.0000 (72.3661) gate/entropy 0.9818 (0.9818) gate/usage_max 0.5695 (0.5695) gate/usage_min 0.2124 (0.2124) gate/usage_std 0.1670 (0.1670) teacher/entropy 0.0772 (0.0503) teacher/usage_max 0.9736 (0.9821) teacher/usage_min 0.0109 (0.0029) teacher/usage_std 0.4527 (0.4588) nleep/row_max_mean 1201.2727 (1198.6936) nleep/row_max_std 12.9484 (14.0198) nleep/row_min_mean 1191.3627 (1188.7790) lr 1.5567e-04 eta 0:12:33
epoch [43/50] batch [160/246] time 0.083 (0.394) data 0.000 (0.002) loss 3.1360 (3.0393) teacher_loss 1.1655 (1.0257) loss_zs_kd 0.0416 (0.0386) loss_oracle 0.9587 (1.0181) kd_loss 1.4704 (1.4854) acc 71.8750 (72.5391) gate/entropy 0.9817 (0.9818) gate/usage_max 0.5696 (0.5695) gate/usage_min 0.2124 (0.2124) gate/usage_std 0.1671 (0.1670) teacher/entropy 0.0634 (0.0498) teacher/usage_max 0.9832 (0.9827) teacher/usage_min 0.0014 (0.0029) teacher/usage_std 0.4595 (0.4592) nleep/row_max_mean 1197.8113 (1198.7175) nleep/row_max_std 14.5355 (13.9736) nleep/row_min_mean 1188.4950 (1188.8050) lr 1.5567e-04 eta 0:11:52
epoch [43/50] batch [180/246] time 0.084 (0.382) data 0.000 (0.002) loss 2.6746 (3.0457) teacher_loss 0.6959 (1.0276) loss_zs_kd 0.0228 (0.0384) loss_oracle 1.0726 (1.0276) kd_loss 1.4310 (1.4851) acc 81.2500 (72.5000) gate/entropy 0.9819 (0.9818) gate/usage_max 0.5694 (0.5695) gate/usage_min 0.2125 (0.2124) gate/usage_std 0.1669 (0.1670) teacher/entropy 0.0971 (0.0501) teacher/usage_max 0.9701 (0.9828) teacher/usage_min 0.0090 (0.0029) teacher/usage_std 0.4503 (0.4592) nleep/row_max_mean 1199.1394 (1198.7699) nleep/row_max_std 13.3255 (13.9453) nleep/row_min_mean 1190.0635 (1188.8643) lr 1.5567e-04 eta 0:11:22
epoch [43/50] batch [200/246] time 0.078 (0.380) data 0.000 (0.002) loss 2.8143 (3.0499) teacher_loss 0.7605 (1.0284) loss_zs_kd 0.0212 (0.0379) loss_oracle 1.0996 (1.0349) kd_loss 1.4934 (1.4851) acc 75.0000 (72.5312) gate/entropy 0.9818 (0.9818) gate/usage_max 0.5695 (0.5695) gate/usage_min 0.2125 (0.2124) gate/usage_std 0.1670 (0.1670) teacher/entropy 0.0485 (0.0501) teacher/usage_max 0.9883 (0.9827) teacher/usage_min 0.0047 (0.0029) teacher/usage_std 0.4631 (0.4592) nleep/row_max_mean 1200.5542 (1198.7510) nleep/row_max_std 14.6034 (13.9104) nleep/row_min_mean 1190.4728 (1188.8497) lr 1.5567e-04 eta 0:11:12
epoch [43/50] batch [220/246] time 0.464 (0.382) data 0.000 (0.002) loss 2.8233 (3.0517) teacher_loss 0.7919 (1.0249) loss_zs_kd 0.0246 (0.0383) loss_oracle 1.0954 (1.0439) kd_loss 1.4713 (1.4856) acc 84.3750 (72.6562) gate/entropy 0.9818 (0.9818) gate/usage_max 0.5695 (0.5695) gate/usage_min 0.2125 (0.2124) gate/usage_std 0.1670 (0.1670) teacher/entropy 0.0590 (0.0497) teacher/usage_max 0.9790 (0.9828) teacher/usage_min 0.0021 (0.0030) teacher/usage_std 0.4566 (0.4593) nleep/row_max_mean 1199.7683 (1198.8157) nleep/row_max_std 13.5831 (13.9012) nleep/row_min_mean 1190.3882 (1188.8935) lr 1.5567e-04 eta 0:11:07
epoch [43/50] batch [240/246] time 0.497 (0.391) data 0.000 (0.002) loss 3.3656 (3.0567) teacher_loss 1.3640 (1.0266) loss_zs_kd 0.0461 (0.0383) loss_oracle 1.0686 (1.0506) kd_loss 1.4442 (1.4857) acc 68.7500 (72.4740) gate/entropy 0.9816 (0.9818) gate/usage_max 0.5698 (0.5695) gate/usage_min 0.2125 (0.2124) gate/usage_std 0.1672 (0.1670) teacher/entropy 0.0662 (0.0496) teacher/usage_max 0.9601 (0.9828) teacher/usage_min 0.0008 (0.0030) teacher/usage_std 0.4435 (0.4593) nleep/row_max_mean 1197.3214 (1198.8838) nleep/row_max_std 13.3179 (13.8985) nleep/row_min_mean 1187.5337 (1188.9723) lr 1.5567e-04 eta 0:11:14
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,815
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,936
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.2%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [44/50] batch [20/246] time 0.082 (0.345) data 0.000 (0.016) loss 3.1056 (3.0966) teacher_loss 0.9871 (1.0208) loss_zs_kd 0.0406 (0.0434) loss_oracle 1.2055 (1.1206) kd_loss 1.4955 (1.4937) acc 68.7500 (71.4062) gate/entropy 0.9815 (0.9817) gate/usage_max 0.5698 (0.5696) gate/usage_min 0.2125 (0.2125) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0211 (0.0439) teacher/usage_max 0.9667 (0.9864) teacher/usage_min 0.0003 (0.0020) teacher/usage_std 0.4481 (0.4618) nleep/row_max_mean 1203.8210 (1198.8841) nleep/row_max_std 15.9005 (13.8738) nleep/row_min_mean 1193.1250 (1188.9504) lr 1.2369e-04 eta 0:09:46
epoch [44/50] batch [40/246] time 0.206 (0.354) data 0.000 (0.008) loss 2.9561 (3.0828) teacher_loss 0.8405 (1.0214) loss_zs_kd 0.0156 (0.0397) loss_oracle 1.1697 (1.1108) kd_loss 1.5230 (1.4862) acc 71.8750 (72.4219) gate/entropy 0.9819 (0.9818) gate/usage_max 0.5694 (0.5695) gate/usage_min 0.2125 (0.2125) gate/usage_std 0.1670 (0.1670) teacher/entropy 0.0234 (0.0493) teacher/usage_max 0.9956 (0.9822) teacher/usage_min 0.0021 (0.0038) teacher/usage_std 0.4683 (0.4589) nleep/row_max_mean 1199.7263 (1198.3125) nleep/row_max_std 15.1476 (14.0965) nleep/row_min_mean 1189.4951 (1188.4608) lr 1.2369e-04 eta 0:09:55
epoch [44/50] batch [60/246] time 0.519 (0.365) data 0.000 (0.006) loss 3.0232 (3.0897) teacher_loss 0.9762 (1.0359) loss_zs_kd 0.0344 (0.0403) loss_oracle 1.0432 (1.1004) kd_loss 1.5081 (1.4835) acc 68.7500 (71.9271) gate/entropy 0.9818 (0.9818) gate/usage_max 0.5695 (0.5696) gate/usage_min 0.2125 (0.2125) gate/usage_std 0.1670 (0.1670) teacher/entropy 0.0346 (0.0505) teacher/usage_max 0.9930 (0.9811) teacher/usage_min 0.0008 (0.0034) teacher/usage_std 0.4665 (0.4581) nleep/row_max_mean 1199.4946 (1198.6753) nleep/row_max_std 13.2345 (14.0151) nleep/row_min_mean 1189.6035 (1188.7838) lr 1.2369e-04 eta 0:10:06
epoch [44/50] batch [80/246] time 0.496 (0.393) data 0.000 (0.004) loss 2.9340 (3.0706) teacher_loss 0.9436 (1.0277) loss_zs_kd 0.0577 (0.0408) loss_oracle 0.9354 (1.0882) kd_loss 1.4938 (1.4784) acc 71.8750 (72.5000) gate/entropy 0.9815 (0.9818) gate/usage_max 0.5699 (0.5696) gate/usage_min 0.2125 (0.2125) gate/usage_std 0.1673 (0.1671) teacher/entropy 0.0449 (0.0537) teacher/usage_max 0.9892 (0.9793) teacher/usage_min 0.0005 (0.0036) teacher/usage_std 0.4638 (0.4568) nleep/row_max_mean 1198.4601 (1198.5035) nleep/row_max_std 12.6074 (14.1906) nleep/row_min_mean 1188.7495 (1188.6847) lr 1.2369e-04 eta 0:10:45
epoch [44/50] batch [100/246] time 0.496 (0.410) data 0.000 (0.003) loss 3.0913 (3.0668) teacher_loss 1.0621 (1.0254) loss_zs_kd 0.0400 (0.0414) loss_oracle 1.0726 (1.0801) kd_loss 1.4729 (1.4807) acc 71.8750 (72.6875) gate/entropy 0.9818 (0.9818) gate/usage_max 0.5695 (0.5696) gate/usage_min 0.2125 (0.2125) gate/usage_std 0.1670 (0.1671) teacher/entropy 0.0623 (0.0525) teacher/usage_max 0.9805 (0.9805) teacher/usage_min 0.0059 (0.0034) teacher/usage_std 0.4577 (0.4577) nleep/row_max_mean 1198.1289 (1198.6425) nleep/row_max_std 18.6264 (14.2724) nleep/row_min_mean 1188.4459 (1188.8317) lr 1.2369e-04 eta 0:11:05
epoch [44/50] batch [120/246] time 0.486 (0.386) data 0.000 (0.003) loss 3.0501 (3.0593) teacher_loss 0.9425 (1.0207) loss_zs_kd 0.0235 (0.0403) loss_oracle 1.1536 (1.0750) kd_loss 1.5190 (1.4809) acc 75.0000 (72.6302) gate/entropy 0.9816 (0.9817) gate/usage_max 0.5698 (0.5696) gate/usage_min 0.2125 (0.2125) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0257 (0.0524) teacher/usage_max 0.9954 (0.9805) teacher/usage_min 0.0006 (0.0035) teacher/usage_std 0.4681 (0.4577) nleep/row_max_mean 1199.7761 (1198.8565) nleep/row_max_std 11.9955 (14.4125) nleep/row_min_mean 1189.9563 (1189.0632) lr 1.2369e-04 eta 0:10:18
epoch [44/50] batch [140/246] time 0.486 (0.378) data 0.000 (0.003) loss 2.8459 (3.0494) teacher_loss 0.7722 (1.0104) loss_zs_kd 0.0355 (0.0395) loss_oracle 1.0964 (1.0778) kd_loss 1.5077 (1.4803) acc 75.0000 (72.9018) gate/entropy 0.9817 (0.9817) gate/usage_max 0.5696 (0.5696) gate/usage_min 0.2125 (0.2125) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0347 (0.0528) teacher/usage_max 0.9931 (0.9805) teacher/usage_min 0.0006 (0.0034) teacher/usage_std 0.4665 (0.4576) nleep/row_max_mean 1197.3179 (1198.7874) nleep/row_max_std 13.3814 (14.4746) nleep/row_min_mean 1187.2280 (1189.0137) lr 1.2369e-04 eta 0:09:58
epoch [44/50] batch [160/246] time 0.471 (0.380) data 0.000 (0.002) loss 2.9575 (3.0547) teacher_loss 1.0170 (1.0155) loss_zs_kd 0.0334 (0.0388) loss_oracle 0.9887 (1.0785) kd_loss 1.4295 (1.4806) acc 71.8750 (72.8320) gate/entropy 0.9817 (0.9817) gate/usage_max 0.5697 (0.5696) gate/usage_min 0.2125 (0.2125) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0824 (0.0527) teacher/usage_max 0.9603 (0.9807) teacher/usage_min 0.0025 (0.0033) teacher/usage_std 0.4436 (0.4578) nleep/row_max_mean 1199.0396 (1198.8286) nleep/row_max_std 14.3825 (14.4615) nleep/row_min_mean 1189.7111 (1189.0445) lr 1.2369e-04 eta 0:09:53
epoch [44/50] batch [180/246] time 0.475 (0.390) data 0.000 (0.002) loss 3.0447 (3.0572) teacher_loss 1.0284 (1.0166) loss_zs_kd 0.0206 (0.0387) loss_oracle 1.0924 (1.0834) kd_loss 1.4598 (1.4795) acc 68.7500 (72.6562) gate/entropy 0.9816 (0.9817) gate/usage_max 0.5697 (0.5696) gate/usage_min 0.2125 (0.2125) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0678 (0.0534) teacher/usage_max 0.9758 (0.9804) teacher/usage_min 0.0030 (0.0033) teacher/usage_std 0.4543 (0.4576) nleep/row_max_mean 1195.6506 (1198.7553) nleep/row_max_std 12.6206 (14.4967) nleep/row_min_mean 1186.6316 (1188.9916) lr 1.2369e-04 eta 0:10:01
epoch [44/50] batch [200/246] time 0.472 (0.400) data 0.000 (0.002) loss 3.0700 (3.0529) teacher_loss 1.1277 (1.0099) loss_zs_kd 0.0322 (0.0385) loss_oracle 0.9892 (1.0874) kd_loss 1.4316 (1.4801) acc 68.7500 (72.7344) gate/entropy 0.9815 (0.9817) gate/usage_max 0.5698 (0.5696) gate/usage_min 0.2125 (0.2125) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0784 (0.0531) teacher/usage_max 0.9584 (0.9809) teacher/usage_min 0.0025 (0.0031) teacher/usage_std 0.4422 (0.4579) nleep/row_max_mean 1197.0164 (1198.7731) nleep/row_max_std 16.4139 (14.4761) nleep/row_min_mean 1188.3656 (1189.0153) lr 1.2369e-04 eta 0:10:09
epoch [44/50] batch [220/246] time 0.080 (0.394) data 0.000 (0.002) loss 3.3369 (3.0490) teacher_loss 1.2360 (1.0030) loss_zs_kd 0.0128 (0.0379) loss_oracle 1.1370 (1.0934) kd_loss 1.5260 (1.4804) acc 68.7500 (73.0256) gate/entropy 0.9815 (0.9817) gate/usage_max 0.5699 (0.5696) gate/usage_min 0.2125 (0.2125) gate/usage_std 0.1673 (0.1671) teacher/entropy 0.0198 (0.0531) teacher/usage_max 0.9967 (0.9810) teacher/usage_min 0.0005 (0.0032) teacher/usage_std 0.4690 (0.4580) nleep/row_max_mean 1203.3536 (1198.8752) nleep/row_max_std 19.5566 (14.5419) nleep/row_min_mean 1192.9469 (1189.1136) lr 1.2369e-04 eta 0:09:51
epoch [44/50] batch [240/246] time 0.484 (0.386) data 0.000 (0.002) loss 2.8412 (3.0536) teacher_loss 0.7508 (1.0053) loss_zs_kd 0.0340 (0.0378) loss_oracle 1.1484 (1.0968) kd_loss 1.4992 (1.4810) acc 75.0000 (73.0339) gate/entropy 0.9816 (0.9817) gate/usage_max 0.5697 (0.5696) gate/usage_min 0.2126 (0.2125) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0448 (0.0528) teacher/usage_max 0.9878 (0.9812) teacher/usage_min 0.0045 (0.0032) teacher/usage_std 0.4628 (0.4582) nleep/row_max_mean 1199.9783 (1198.8278) nleep/row_max_std 11.8770 (14.5606) nleep/row_min_mean 1190.1105 (1189.0754) lr 1.2369e-04 eta 0:09:32
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,815
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,939
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.3%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [45/50] batch [20/246] time 0.485 (0.499) data 0.000 (0.011) loss 2.9117 (3.1265) teacher_loss 0.8659 (1.0842) loss_zs_kd 0.0343 (0.0385) loss_oracle 1.1332 (1.0876) kd_loss 1.4620 (1.4793) acc 75.0000 (72.8125) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0659 (0.0546) teacher/usage_max 0.9777 (0.9829) teacher/usage_min 0.0013 (0.0023) teacher/usage_std 0.4557 (0.4594) nleep/row_max_mean 1197.0013 (1198.3264) nleep/row_max_std 13.5867 (13.8808) nleep/row_min_mean 1187.8584 (1188.8214) lr 9.5173e-05 eta 0:12:05
epoch [45/50] batch [40/246] time 0.497 (0.504) data 0.000 (0.006) loss 3.8091 (3.0654) teacher_loss 1.6350 (1.0145) loss_zs_kd 0.0664 (0.0384) loss_oracle 1.2577 (1.1073) kd_loss 1.5120 (1.4781) acc 59.3750 (74.2969) gate/entropy 0.9817 (0.9817) gate/usage_max 0.5696 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0341 (0.0552) teacher/usage_max 0.9776 (0.9811) teacher/usage_min 0.0017 (0.0031) teacher/usage_std 0.4556 (0.4581) nleep/row_max_mean 1197.8425 (1198.9372) nleep/row_max_std 15.6827 (14.2816) nleep/row_min_mean 1187.7783 (1189.3808) lr 9.5173e-05 eta 0:12:03
epoch [45/50] batch [60/246] time 0.101 (0.448) data 0.000 (0.004) loss 3.1660 (3.0556) teacher_loss 1.0634 (1.0007) loss_zs_kd 0.0470 (0.0392) loss_oracle 1.1701 (1.1129) kd_loss 1.4940 (1.4789) acc 78.1250 (74.7396) gate/entropy 0.9817 (0.9817) gate/usage_max 0.5696 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0448 (0.0546) teacher/usage_max 0.9885 (0.9817) teacher/usage_min 0.0018 (0.0029) teacher/usage_std 0.4633 (0.4585) nleep/row_max_mean 1195.6534 (1198.8288) nleep/row_max_std 14.5348 (14.5572) nleep/row_min_mean 1185.9203 (1189.2569) lr 9.5173e-05 eta 0:10:34
epoch [45/50] batch [80/246] time 0.366 (0.420) data 0.000 (0.003) loss 2.8905 (3.0910) teacher_loss 0.8337 (1.0370) loss_zs_kd 0.0407 (0.0395) loss_oracle 1.0480 (1.1129) kd_loss 1.5125 (1.4779) acc 78.1250 (73.6328) gate/entropy 0.9816 (0.9817) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0300 (0.0557) teacher/usage_max 0.9935 (0.9815) teacher/usage_min 0.0005 (0.0031) teacher/usage_std 0.4668 (0.4584) nleep/row_max_mean 1200.7329 (1198.5346) nleep/row_max_std 12.9562 (14.4561) nleep/row_min_mean 1190.6938 (1188.9795) lr 9.5173e-05 eta 0:09:45
epoch [45/50] batch [100/246] time 0.483 (0.399) data 0.000 (0.002) loss 3.0566 (3.0764) teacher_loss 0.9614 (1.0215) loss_zs_kd 0.0575 (0.0397) loss_oracle 1.1168 (1.1140) kd_loss 1.5080 (1.4781) acc 78.1250 (73.8750) gate/entropy 0.9816 (0.9817) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0340 (0.0552) teacher/usage_max 0.9929 (0.9811) teacher/usage_min 0.0006 (0.0034) teacher/usage_std 0.4664 (0.4581) nleep/row_max_mean 1202.9358 (1198.8218) nleep/row_max_std 15.1051 (14.6294) nleep/row_min_mean 1192.5624 (1189.2328) lr 9.5173e-05 eta 0:09:09
epoch [45/50] batch [120/246] time 0.495 (0.395) data 0.000 (0.002) loss 3.2226 (3.0717) teacher_loss 1.1841 (1.0130) loss_zs_kd 0.0280 (0.0391) loss_oracle 1.1309 (1.1185) kd_loss 1.4590 (1.4799) acc 71.8750 (73.9323) gate/entropy 0.9818 (0.9817) gate/usage_max 0.5695 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1670 (0.1671) teacher/entropy 0.0618 (0.0537) teacher/usage_max 0.9675 (0.9815) teacher/usage_min 0.0047 (0.0032) teacher/usage_std 0.4485 (0.4584) nleep/row_max_mean 1201.4352 (1199.0090) nleep/row_max_std 20.2462 (14.7714) nleep/row_min_mean 1191.8608 (1189.4096) lr 9.5173e-05 eta 0:08:55
epoch [45/50] batch [140/246] time 0.496 (0.407) data 0.000 (0.002) loss 2.5733 (3.0662) teacher_loss 0.6271 (1.0082) loss_zs_kd 0.0328 (0.0388) loss_oracle 1.0589 (1.1196) kd_loss 1.4003 (1.4788) acc 81.2500 (73.9955) gate/entropy 0.9818 (0.9817) gate/usage_max 0.5695 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1670 (0.1671) teacher/entropy 0.1065 (0.0548) teacher/usage_max 0.9543 (0.9813) teacher/usage_min 0.0038 (0.0034) teacher/usage_std 0.4394 (0.4582) nleep/row_max_mean 1195.5654 (1199.0354) nleep/row_max_std 13.0645 (14.9373) nleep/row_min_mean 1187.0376 (1189.4392) lr 9.5173e-05 eta 0:09:04
epoch [45/50] batch [160/246] time 0.482 (0.417) data 0.000 (0.002) loss 3.4181 (3.0640) teacher_loss 1.4175 (1.0076) loss_zs_kd 0.0291 (0.0388) loss_oracle 0.9944 (1.1157) kd_loss 1.4888 (1.4791) acc 62.5000 (73.9062) gate/entropy 0.9815 (0.9817) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0499 (0.0545) teacher/usage_max 0.9885 (0.9814) teacher/usage_min 0.0018 (0.0033) teacher/usage_std 0.4633 (0.4583) nleep/row_max_mean 1198.0935 (1199.0346) nleep/row_max_std 12.6333 (14.8918) nleep/row_min_mean 1188.6946 (1189.4521) lr 9.5173e-05 eta 0:09:08
epoch [45/50] batch [180/246] time 0.147 (0.399) data 0.000 (0.001) loss 3.3309 (3.0647) teacher_loss 1.3033 (1.0121) loss_zs_kd 0.0470 (0.0383) loss_oracle 1.0709 (1.1105) kd_loss 1.4687 (1.4782) acc 68.7500 (73.7326) gate/entropy 0.9816 (0.9817) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0434 (0.0550) teacher/usage_max 0.9627 (0.9811) teacher/usage_min 0.0007 (0.0032) teacher/usage_std 0.4453 (0.4581) nleep/row_max_mean 1198.4441 (1198.9543) nleep/row_max_std 14.5047 (14.8051) nleep/row_min_mean 1188.6375 (1189.3979) lr 9.5173e-05 eta 0:08:37
epoch [45/50] batch [200/246] time 0.096 (0.389) data 0.000 (0.001) loss 2.8814 (3.0622) teacher_loss 0.7939 (1.0120) loss_zs_kd 0.0507 (0.0381) loss_oracle 1.1465 (1.1083) kd_loss 1.4889 (1.4770) acc 78.1250 (73.7188) gate/entropy 0.9815 (0.9817) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0475 (0.0561) teacher/usage_max 0.9868 (0.9808) teacher/usage_min 0.0011 (0.0034) teacher/usage_std 0.4621 (0.4579) nleep/row_max_mean 1202.4806 (1198.9056) nleep/row_max_std 13.9990 (14.7071) nleep/row_min_mean 1192.5508 (1189.3752) lr 9.5173e-05 eta 0:08:15
epoch [45/50] batch [220/246] time 0.080 (0.386) data 0.000 (0.001) loss 3.2683 (3.0606) teacher_loss 1.2029 (1.0127) loss_zs_kd 0.0253 (0.0383) loss_oracle 1.1273 (1.1057) kd_loss 1.4891 (1.4758) acc 71.8750 (73.6790) gate/entropy 0.9815 (0.9817) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1673 (0.1671) teacher/entropy 0.0487 (0.0568) teacher/usage_max 0.9877 (0.9804) teacher/usage_min 0.0018 (0.0034) teacher/usage_std 0.4627 (0.4576) nleep/row_max_mean 1198.7451 (1198.8277) nleep/row_max_std 14.6716 (14.6921) nleep/row_min_mean 1189.5387 (1189.3232) lr 9.5173e-05 eta 0:08:05
epoch [45/50] batch [240/246] time 0.521 (0.390) data 0.000 (0.001) loss 3.1456 (3.0591) teacher_loss 1.0780 (1.0129) loss_zs_kd 0.0289 (0.0382) loss_oracle 1.0957 (1.1046) kd_loss 1.5053 (1.4748) acc 75.0000 (73.6849) gate/entropy 0.9818 (0.9817) gate/usage_max 0.5695 (0.5697) gate/usage_min 0.2127 (0.2126) gate/usage_std 0.1670 (0.1671) teacher/entropy 0.0369 (0.0574) teacher/usage_max 0.9928 (0.9800) teacher/usage_min 0.0012 (0.0034) teacher/usage_std 0.4663 (0.4573) nleep/row_max_mean 1195.6067 (1198.8025) nleep/row_max_std 18.1056 (14.6964) nleep/row_min_mean 1186.3019 (1189.3069) lr 9.5173e-05 eta 0:08:02
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,819
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,936
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.2%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [46/50] batch [20/246] time 0.087 (0.411) data 0.000 (0.013) loss 2.9225 (3.1291) teacher_loss 0.8853 (1.0994) loss_zs_kd 0.0271 (0.0405) loss_oracle 1.1362 (1.0961) kd_loss 1.4555 (1.4613) acc 71.8750 (72.3438) gate/entropy 0.9816 (0.9817) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0598 (0.0663) teacher/usage_max 0.9639 (0.9755) teacher/usage_min 0.0027 (0.0038) teacher/usage_std 0.4461 (0.4541) nleep/row_max_mean 1198.0322 (1198.1035) nleep/row_max_std 16.4700 (14.8267) nleep/row_min_mean 1188.4526 (1188.7623) lr 7.0224e-05 eta 0:08:17
epoch [46/50] batch [40/246] time 0.086 (0.373) data 0.000 (0.007) loss 3.0386 (3.1321) teacher_loss 0.9339 (1.0934) loss_zs_kd 0.0340 (0.0391) loss_oracle 1.1961 (1.1084) kd_loss 1.4897 (1.4650) acc 68.7500 (71.0938) gate/entropy 0.9817 (0.9816) gate/usage_max 0.5696 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0474 (0.0644) teacher/usage_max 0.9882 (0.9771) teacher/usage_min 0.0006 (0.0040) teacher/usage_std 0.4631 (0.4552) nleep/row_max_mean 1197.8201 (1197.9662) nleep/row_max_std 16.1248 (14.5983) nleep/row_min_mean 1187.9298 (1188.5934) lr 7.0224e-05 eta 0:07:23
epoch [46/50] batch [60/246] time 0.081 (0.371) data 0.000 (0.005) loss 2.8039 (3.1139) teacher_loss 0.8204 (1.0788) loss_zs_kd 0.0547 (0.0397) loss_oracle 1.0250 (1.0981) kd_loss 1.4437 (1.4662) acc 75.0000 (71.3542) gate/entropy 0.9819 (0.9817) gate/usage_max 0.5695 (0.5697) gate/usage_min 0.2127 (0.2126) gate/usage_std 0.1670 (0.1671) teacher/entropy 0.0785 (0.0631) teacher/usage_max 0.9703 (0.9765) teacher/usage_min 0.0035 (0.0044) teacher/usage_std 0.4505 (0.4548) nleep/row_max_mean 1197.1973 (1198.0115) nleep/row_max_std 18.3032 (14.4941) nleep/row_min_mean 1188.0463 (1188.6131) lr 7.0224e-05 eta 0:07:13
epoch [46/50] batch [80/246] time 0.475 (0.376) data 0.000 (0.003) loss 2.9991 (3.0952) teacher_loss 0.9891 (1.0671) loss_zs_kd 0.0402 (0.0403) loss_oracle 1.0378 (1.0869) kd_loss 1.4710 (1.4646) acc 71.8750 (71.7578) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0642 (0.0644) teacher/usage_max 0.9841 (0.9764) teacher/usage_min 0.0029 (0.0042) teacher/usage_std 0.4602 (0.4548) nleep/row_max_mean 1199.4752 (1197.9625) nleep/row_max_std 15.3446 (14.4923) nleep/row_min_mean 1190.0752 (1188.5850) lr 7.0224e-05 eta 0:07:12
epoch [46/50] batch [100/246] time 0.485 (0.395) data 0.000 (0.003) loss 2.8922 (3.0891) teacher_loss 0.7766 (1.0618) loss_zs_kd 0.0311 (0.0409) loss_oracle 1.1834 (1.0854) kd_loss 1.5084 (1.4641) acc 75.0000 (72.0625) gate/entropy 0.9816 (0.9817) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2127 (0.2126) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0330 (0.0645) teacher/usage_max 0.9926 (0.9759) teacher/usage_min 0.0007 (0.0042) teacher/usage_std 0.4662 (0.4545) nleep/row_max_mean 1195.6132 (1198.0300) nleep/row_max_std 16.1848 (14.6093) nleep/row_min_mean 1185.4175 (1188.6376) lr 7.0224e-05 eta 0:07:26
epoch [46/50] batch [120/246] time 0.497 (0.409) data 0.000 (0.002) loss 2.6166 (3.0847) teacher_loss 0.5967 (1.0530) loss_zs_kd 0.0154 (0.0403) loss_oracle 1.0555 (1.0881) kd_loss 1.4845 (1.4674) acc 84.3750 (72.2917) gate/entropy 0.9818 (0.9816) gate/usage_max 0.5695 (0.5697) gate/usage_min 0.2127 (0.2126) gate/usage_std 0.1670 (0.1671) teacher/entropy 0.0549 (0.0622) teacher/usage_max 0.9827 (0.9773) teacher/usage_min 0.0085 (0.0039) teacher/usage_std 0.4592 (0.4554) nleep/row_max_mean 1200.4354 (1198.2266) nleep/row_max_std 17.2751 (14.5588) nleep/row_min_mean 1191.0159 (1188.7942) lr 7.0224e-05 eta 0:07:33
epoch [46/50] batch [140/246] time 0.462 (0.388) data 0.000 (0.002) loss 2.4536 (3.0551) teacher_loss 0.4415 (1.0239) loss_zs_kd 0.0641 (0.0390) loss_oracle 1.0773 (1.0892) kd_loss 1.4414 (1.4672) acc 87.5000 (73.0357) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2127 (0.2126) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0669 (0.0617) teacher/usage_max 0.9570 (0.9768) teacher/usage_min 0.0028 (0.0037) teacher/usage_std 0.4412 (0.4550) nleep/row_max_mean 1198.7507 (1198.3960) nleep/row_max_std 15.7346 (14.6023) nleep/row_min_mean 1189.4570 (1188.9439) lr 7.0224e-05 eta 0:07:02
epoch [46/50] batch [160/246] time 0.454 (0.374) data 0.000 (0.002) loss 3.3477 (3.0479) teacher_loss 1.3161 (1.0148) loss_zs_kd 0.0442 (0.0389) loss_oracle 1.0856 (1.0913) kd_loss 1.4667 (1.4680) acc 62.5000 (73.0469) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0665 (0.0614) teacher/usage_max 0.9808 (0.9774) teacher/usage_min 0.0043 (0.0035) teacher/usage_std 0.4578 (0.4555) nleep/row_max_mean 1197.3524 (1198.4754) nleep/row_max_std 14.4371 (14.5886) nleep/row_min_mean 1187.9124 (1189.0136) lr 7.0224e-05 eta 0:06:39
epoch [46/50] batch [180/246] time 0.504 (0.372) data 0.000 (0.002) loss 2.9781 (3.0440) teacher_loss 0.9374 (1.0115) loss_zs_kd 0.0266 (0.0392) loss_oracle 1.0859 (1.0894) kd_loss 1.4845 (1.4682) acc 68.7500 (72.9861) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5699 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1673 (0.1671) teacher/entropy 0.0536 (0.0613) teacher/usage_max 0.9884 (0.9775) teacher/usage_min 0.0014 (0.0036) teacher/usage_std 0.4632 (0.4556) nleep/row_max_mean 1195.6418 (1198.5169) nleep/row_max_std 15.1687 (14.6160) nleep/row_min_mean 1186.4843 (1189.0584) lr 7.0224e-05 eta 0:06:30
epoch [46/50] batch [200/246] time 0.472 (0.381) data 0.000 (0.001) loss 3.4428 (3.0529) teacher_loss 1.3621 (1.0191) loss_zs_kd 0.0738 (0.0392) loss_oracle 1.0970 (1.0886) kd_loss 1.4953 (1.4699) acc 62.5000 (72.8750) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0441 (0.0603) teacher/usage_max 0.9902 (0.9782) teacher/usage_min 0.0011 (0.0036) teacher/usage_std 0.4645 (0.4561) nleep/row_max_mean 1198.2700 (1198.7485) nleep/row_max_std 16.2848 (14.7313) nleep/row_min_mean 1188.6692 (1189.2742) lr 7.0224e-05 eta 0:06:32
epoch [46/50] batch [220/246] time 0.518 (0.392) data 0.000 (0.001) loss 3.3244 (3.0478) teacher_loss 1.3413 (1.0126) loss_zs_kd 0.0223 (0.0385) loss_oracle 1.0685 (1.0897) kd_loss 1.4378 (1.4711) acc 59.3750 (73.0114) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0746 (0.0596) teacher/usage_max 0.9565 (0.9787) teacher/usage_min 0.0075 (0.0036) teacher/usage_std 0.4408 (0.4564) nleep/row_max_mean 1204.4697 (1198.8504) nleep/row_max_std 18.3689 (14.7376) nleep/row_min_mean 1194.7300 (1189.3664) lr 7.0224e-05 eta 0:06:35
epoch [46/50] batch [240/246] time 0.081 (0.395) data 0.000 (0.001) loss 2.8640 (3.0495) teacher_loss 0.8579 (1.0141) loss_zs_kd 0.0364 (0.0383) loss_oracle 1.0360 (1.0900) kd_loss 1.4698 (1.4713) acc 84.3750 (73.0859) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0672 (0.0595) teacher/usage_max 0.9850 (0.9788) teacher/usage_min 0.0040 (0.0036) teacher/usage_std 0.4608 (0.4564) nleep/row_max_mean 1196.4680 (1198.9141) nleep/row_max_std 16.8250 (14.8075) nleep/row_min_mean 1187.8740 (1189.4181) lr 7.0224e-05 eta 0:06:31
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,819
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,937
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.2%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [47/50] batch [20/246] time 0.474 (0.380) data 0.000 (0.015) loss 3.0988 (3.0224) teacher_loss 1.0718 (0.9695) loss_zs_kd 0.0369 (0.0385) loss_oracle 1.1346 (1.1299) kd_loss 1.4413 (1.4687) acc 68.7500 (73.2812) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0693 (0.0601) teacher/usage_max 0.9593 (0.9765) teacher/usage_min 0.0028 (0.0035) teacher/usage_std 0.4429 (0.4549) nleep/row_max_mean 1197.3796 (1198.9113) nleep/row_max_std 15.4651 (15.4768) nleep/row_min_mean 1188.2927 (1189.2841) lr 4.8943e-05 eta 0:06:06
epoch [47/50] batch [40/246] time 0.471 (0.427) data 0.000 (0.008) loss 3.1854 (3.0300) teacher_loss 1.1355 (0.9900) loss_zs_kd 0.0311 (0.0387) loss_oracle 1.0818 (1.1102) kd_loss 1.4935 (1.4655) acc 62.5000 (72.8906) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0443 (0.0631) teacher/usage_max 0.9893 (0.9756) teacher/usage_min 0.0004 (0.0046) teacher/usage_std 0.4639 (0.4542) nleep/row_max_mean 1197.9464 (1198.7917) nleep/row_max_std 13.6860 (15.4309) nleep/row_min_mean 1188.4252 (1189.3427) lr 4.8943e-05 eta 0:06:43
epoch [47/50] batch [60/246] time 0.521 (0.445) data 0.000 (0.005) loss 2.6374 (3.0339) teacher_loss 0.5654 (0.9950) loss_zs_kd 0.0301 (0.0395) loss_oracle 1.1311 (1.1037) kd_loss 1.4915 (1.4673) acc 84.3750 (72.9688) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0475 (0.0620) teacher/usage_max 0.9893 (0.9768) teacher/usage_min 0.0017 (0.0041) teacher/usage_std 0.4638 (0.4550) nleep/row_max_mean 1202.0739 (1199.1465) nleep/row_max_std 14.0249 (15.4655) nleep/row_min_mean 1192.0082 (1189.6529) lr 4.8943e-05 eta 0:06:51
epoch [47/50] batch [80/246] time 0.081 (0.420) data 0.000 (0.004) loss 2.6369 (3.0159) teacher_loss 0.6244 (0.9843) loss_zs_kd 0.0197 (0.0379) loss_oracle 1.0796 (1.0935) kd_loss 1.4628 (1.4659) acc 84.3750 (73.4375) gate/entropy 0.9818 (0.9816) gate/usage_max 0.5696 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1671 (0.1672) teacher/entropy 0.0698 (0.0631) teacher/usage_max 0.9800 (0.9769) teacher/usage_min 0.0048 (0.0038) teacher/usage_std 0.4572 (0.4552) nleep/row_max_mean 1194.1422 (1199.0891) nleep/row_max_std 13.1562 (15.4938) nleep/row_min_mean 1185.2015 (1189.6229) lr 4.8943e-05 eta 0:06:20
epoch [47/50] batch [100/246] time 0.078 (0.403) data 0.000 (0.003) loss 3.1419 (3.0240) teacher_loss 0.9835 (0.9864) loss_zs_kd 0.0545 (0.0378) loss_oracle 1.2271 (1.0969) kd_loss 1.5176 (1.4703) acc 75.0000 (73.6250) gate/entropy 0.9818 (0.9816) gate/usage_max 0.5696 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1670 (0.1671) teacher/entropy 0.0263 (0.0601) teacher/usage_max 0.9950 (0.9786) teacher/usage_min 0.0011 (0.0034) teacher/usage_std 0.4679 (0.4564) nleep/row_max_mean 1199.9065 (1199.2715) nleep/row_max_std 14.1844 (15.5184) nleep/row_min_mean 1190.5337 (1189.7647) lr 4.8943e-05 eta 0:05:55
epoch [47/50] batch [120/246] time 0.490 (0.388) data 0.000 (0.003) loss 2.9020 (3.0391) teacher_loss 0.8698 (1.0045) loss_zs_kd 0.0396 (0.0393) loss_oracle 1.0831 (1.0921) kd_loss 1.4709 (1.4689) acc 78.1250 (73.1510) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0626 (0.0614) teacher/usage_max 0.9826 (0.9783) teacher/usage_min 0.0029 (0.0036) teacher/usage_std 0.4592 (0.4561) nleep/row_max_mean 1195.9034 (1199.0261) nleep/row_max_std 15.5186 (15.4757) nleep/row_min_mean 1186.9590 (1189.5594) lr 4.8943e-05 eta 0:05:35
epoch [47/50] batch [140/246] time 0.522 (0.388) data 0.000 (0.002) loss 2.8024 (3.0340) teacher_loss 0.7676 (0.9993) loss_zs_kd 0.0245 (0.0393) loss_oracle 1.0801 (1.0920) kd_loss 1.4825 (1.4691) acc 81.2500 (73.2812) gate/entropy 0.9817 (0.9816) gate/usage_max 0.5696 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1671 (0.1672) teacher/entropy 0.0525 (0.0614) teacher/usage_max 0.9862 (0.9784) teacher/usage_min 0.0008 (0.0036) teacher/usage_std 0.4616 (0.4562) nleep/row_max_mean 1195.3547 (1198.8712) nleep/row_max_std 17.7811 (15.4296) nleep/row_min_mean 1185.8787 (1189.4186) lr 4.8943e-05 eta 0:05:27
epoch [47/50] batch [160/246] time 0.478 (0.400) data 0.000 (0.002) loss 2.7899 (3.0279) teacher_loss 0.7380 (0.9944) loss_zs_kd 0.0337 (0.0399) loss_oracle 1.0742 (1.0908) kd_loss 1.4980 (1.4681) acc 81.2500 (73.4961) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5699 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1673 (0.1672) teacher/entropy 0.0427 (0.0622) teacher/usage_max 0.9909 (0.9781) teacher/usage_min 0.0018 (0.0038) teacher/usage_std 0.4649 (0.4560) nleep/row_max_mean 1200.6489 (1198.8862) nleep/row_max_std 14.7830 (15.3635) nleep/row_min_mean 1191.3130 (1189.4377) lr 4.8943e-05 eta 0:05:29
epoch [47/50] batch [180/246] time 0.495 (0.410) data 0.000 (0.002) loss 2.8451 (3.0264) teacher_loss 0.7290 (0.9928) loss_zs_kd 0.0454 (0.0395) loss_oracle 1.1746 (1.0902) kd_loss 1.5061 (1.4688) acc 78.1250 (73.5417) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0366 (0.0618) teacher/usage_max 0.9905 (0.9785) teacher/usage_min 0.0044 (0.0037) teacher/usage_std 0.4647 (0.4563) nleep/row_max_mean 1202.9547 (1198.8366) nleep/row_max_std 16.9650 (15.4452) nleep/row_min_mean 1192.7867 (1189.4012) lr 4.8943e-05 eta 0:05:29
epoch [47/50] batch [200/246] time 0.462 (0.396) data 0.000 (0.002) loss 2.9047 (3.0243) teacher_loss 0.7662 (0.9884) loss_zs_kd 0.0320 (0.0391) loss_oracle 1.2216 (1.0940) kd_loss 1.5118 (1.4693) acc 81.2500 (73.6562) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1671 (0.1672) teacher/entropy 0.0302 (0.0612) teacher/usage_max 0.9937 (0.9785) teacher/usage_min 0.0004 (0.0036) teacher/usage_std 0.4670 (0.4563) nleep/row_max_mean 1199.1787 (1198.7578) nleep/row_max_std 10.6279 (15.4121) nleep/row_min_mean 1189.4745 (1189.3258) lr 4.8943e-05 eta 0:05:10
epoch [47/50] batch [220/246] time 0.096 (0.383) data 0.000 (0.002) loss 2.8372 (3.0328) teacher_loss 0.7687 (0.9993) loss_zs_kd 0.0369 (0.0389) loss_oracle 1.0966 (1.0924) kd_loss 1.5017 (1.4678) acc 81.2500 (73.4943) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0387 (0.0622) teacher/usage_max 0.9919 (0.9778) teacher/usage_min 0.0006 (0.0038) teacher/usage_std 0.4657 (0.4558) nleep/row_max_mean 1201.3596 (1198.6108) nleep/row_max_std 17.0221 (15.4580) nleep/row_min_mean 1191.9114 (1189.1997) lr 4.8943e-05 eta 0:04:52
epoch [47/50] batch [240/246] time 0.281 (0.383) data 0.000 (0.001) loss 3.3073 (3.0410) teacher_loss 1.2624 (1.0044) loss_zs_kd 0.0575 (0.0392) loss_oracle 1.0605 (1.0957) kd_loss 1.4858 (1.4691) acc 62.5000 (73.3333) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0554 (0.0614) teacher/usage_max 0.9877 (0.9783) teacher/usage_min 0.0058 (0.0039) teacher/usage_std 0.4627 (0.4561) nleep/row_max_mean 1196.6827 (1198.5204) nleep/row_max_std 14.2144 (15.5015) nleep/row_min_mean 1187.6765 (1189.1047) lr 4.8943e-05 eta 0:04:44
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,813
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,937
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.2%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [48/50] batch [20/246] time 0.496 (0.525) data 0.000 (0.013) loss 2.6145 (2.9897) teacher_loss 0.5560 (0.9352) loss_zs_kd 0.0284 (0.0377) loss_oracle 1.1609 (1.1186) kd_loss 1.4638 (1.4763) acc 81.2500 (74.8438) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1673 (0.1672) teacher/entropy 0.0667 (0.0576) teacher/usage_max 0.9813 (0.9815) teacher/usage_min 0.0012 (0.0039) teacher/usage_std 0.4582 (0.4584) nleep/row_max_mean 1194.8639 (1198.3235) nleep/row_max_std 17.6029 (15.2283) nleep/row_min_mean 1186.0916 (1188.8304) lr 3.1417e-05 eta 0:06:16
epoch [48/50] batch [40/246] time 0.087 (0.410) data 0.001 (0.007) loss 3.2129 (2.9686) teacher_loss 1.1500 (0.9279) loss_zs_kd 0.0413 (0.0390) loss_oracle 1.1144 (1.0948) kd_loss 1.4850 (1.4739) acc 62.5000 (73.9062) gate/entropy 0.9814 (0.9816) gate/usage_max 0.5699 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1673 (0.1671) teacher/entropy 0.0519 (0.0582) teacher/usage_max 0.9881 (0.9804) teacher/usage_min 0.0008 (0.0033) teacher/usage_std 0.4630 (0.4576) nleep/row_max_mean 1197.1477 (1198.7210) nleep/row_max_std 13.8989 (15.5197) nleep/row_min_mean 1188.1483 (1189.3094) lr 3.1417e-05 eta 0:04:46
epoch [48/50] batch [60/246] time 0.081 (0.384) data 0.000 (0.005) loss 2.9651 (2.9478) teacher_loss 0.9047 (0.9107) loss_zs_kd 0.0458 (0.0380) loss_oracle 1.0686 (1.0924) kd_loss 1.5031 (1.4718) acc 81.2500 (74.8438) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0384 (0.0590) teacher/usage_max 0.9913 (0.9790) teacher/usage_min 0.0024 (0.0035) teacher/usage_std 0.4652 (0.4566) nleep/row_max_mean 1203.5262 (1198.8528) nleep/row_max_std 15.8775 (15.4848) nleep/row_min_mean 1193.4873 (1189.4782) lr 3.1417e-05 eta 0:04:20
epoch [48/50] batch [80/246] time 0.482 (0.367) data 0.000 (0.003) loss 2.9785 (2.9717) teacher_loss 0.9358 (0.9420) loss_zs_kd 0.0452 (0.0373) loss_oracle 1.0895 (1.0873) kd_loss 1.4754 (1.4674) acc 68.7500 (74.0625) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1671 (0.1672) teacher/entropy 0.0595 (0.0624) teacher/usage_max 0.9859 (0.9776) teacher/usage_min 0.0010 (0.0039) teacher/usage_std 0.4615 (0.4556) nleep/row_max_mean 1200.6857 (1198.8056) nleep/row_max_std 17.8710 (15.7044) nleep/row_min_mean 1190.9491 (1189.5046) lr 3.1417e-05 eta 0:04:01
epoch [48/50] batch [100/246] time 0.500 (0.370) data 0.000 (0.003) loss 3.2814 (2.9881) teacher_loss 1.1599 (0.9578) loss_zs_kd 0.0469 (0.0380) loss_oracle 1.1897 (1.0876) kd_loss 1.5031 (1.4674) acc 71.8750 (74.0312) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0388 (0.0626) teacher/usage_max 0.9921 (0.9779) teacher/usage_min 0.0021 (0.0040) teacher/usage_std 0.4658 (0.4558) nleep/row_max_mean 1200.9148 (1198.7950) nleep/row_max_std 13.4179 (15.4812) nleep/row_min_mean 1191.6161 (1189.5099) lr 3.1417e-05 eta 0:03:56
epoch [48/50] batch [120/246] time 0.471 (0.392) data 0.000 (0.002) loss 3.2605 (3.0167) teacher_loss 1.1707 (0.9846) loss_zs_kd 0.0196 (0.0386) loss_oracle 1.1861 (1.0889) kd_loss 1.4870 (1.4683) acc 71.8750 (73.4375) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0517 (0.0621) teacher/usage_max 0.9878 (0.9786) teacher/usage_min 0.0031 (0.0037) teacher/usage_std 0.4628 (0.4563) nleep/row_max_mean 1196.9862 (1198.8496) nleep/row_max_std 13.0256 (15.4204) nleep/row_min_mean 1187.7346 (1189.5696) lr 3.1417e-05 eta 0:04:02
epoch [48/50] batch [140/246] time 0.465 (0.406) data 0.000 (0.002) loss 3.2171 (3.0226) teacher_loss 1.2499 (0.9931) loss_zs_kd 0.0344 (0.0391) loss_oracle 1.0909 (1.0871) kd_loss 1.4046 (1.4664) acc 62.5000 (73.0580) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.1019 (0.0635) teacher/usage_max 0.9532 (0.9779) teacher/usage_min 0.0051 (0.0039) teacher/usage_std 0.4385 (0.4558) nleep/row_max_mean 1196.2394 (1198.6525) nleep/row_max_std 11.8987 (15.3632) nleep/row_min_mean 1187.4241 (1189.3988) lr 3.1417e-05 eta 0:04:02
epoch [48/50] batch [160/246] time 0.427 (0.387) data 0.000 (0.002) loss 2.7280 (3.0376) teacher_loss 0.6370 (1.0088) loss_zs_kd 0.0274 (0.0390) loss_oracle 1.1267 (1.0867) kd_loss 1.5140 (1.4660) acc 84.3750 (72.8125) gate/entropy 0.9818 (0.9816) gate/usage_max 0.5695 (0.5697) gate/usage_min 0.2128 (0.2127) gate/usage_std 0.1670 (0.1672) teacher/entropy 0.0300 (0.0637) teacher/usage_max 0.9945 (0.9776) teacher/usage_min 0.0019 (0.0041) teacher/usage_std 0.4675 (0.4556) nleep/row_max_mean 1202.0833 (1198.5018) nleep/row_max_std 13.3401 (15.2773) nleep/row_min_mean 1192.8893 (1189.2618) lr 3.1417e-05 eta 0:03:43
epoch [48/50] batch [180/246] time 0.465 (0.377) data 0.000 (0.002) loss 3.4643 (3.0336) teacher_loss 1.3609 (1.0035) loss_zs_kd 0.0408 (0.0390) loss_oracle 1.1462 (1.0876) kd_loss 1.5098 (1.4668) acc 59.3750 (72.9514) gate/entropy 0.9814 (0.9816) gate/usage_max 0.5700 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1673 (0.1672) teacher/entropy 0.0323 (0.0632) teacher/usage_max 0.9937 (0.9779) teacher/usage_min 0.0005 (0.0039) teacher/usage_std 0.4670 (0.4558) nleep/row_max_mean 1198.7405 (1198.5304) nleep/row_max_std 11.8939 (15.1706) nleep/row_min_mean 1189.1968 (1189.2934) lr 3.1417e-05 eta 0:03:30
epoch [48/50] batch [200/246] time 0.472 (0.376) data 0.000 (0.001) loss 3.3679 (3.0484) teacher_loss 1.2801 (1.0185) loss_zs_kd 0.0306 (0.0392) loss_oracle 1.1799 (1.0874) kd_loss 1.4825 (1.4666) acc 65.6250 (72.5312) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1673 (0.1672) teacher/entropy 0.0538 (0.0633) teacher/usage_max 0.9867 (0.9779) teacher/usage_min 0.0018 (0.0039) teacher/usage_std 0.4620 (0.4558) nleep/row_max_mean 1199.0891 (1198.4554) nleep/row_max_std 11.3201 (15.0537) nleep/row_min_mean 1189.5471 (1189.2324) lr 3.1417e-05 eta 0:03:22
epoch [48/50] batch [220/246] time 0.479 (0.385) data 0.000 (0.001) loss 3.1794 (3.0539) teacher_loss 1.1272 (1.0249) loss_zs_kd 0.0354 (0.0395) loss_oracle 1.0988 (1.0867) kd_loss 1.4851 (1.4659) acc 71.8750 (72.4574) gate/entropy 0.9817 (0.9816) gate/usage_max 0.5696 (0.5697) gate/usage_min 0.2128 (0.2127) gate/usage_std 0.1671 (0.1672) teacher/entropy 0.0535 (0.0639) teacher/usage_max 0.9877 (0.9776) teacher/usage_min 0.0033 (0.0040) teacher/usage_std 0.4627 (0.4556) nleep/row_max_mean 1196.8000 (1198.4831) nleep/row_max_std 15.2344 (14.9709) nleep/row_min_mean 1187.9933 (1189.2641) lr 3.1417e-05 eta 0:03:19
epoch [48/50] batch [240/246] time 0.472 (0.391) data 0.000 (0.001) loss 3.3807 (3.0607) teacher_loss 1.4107 (1.0319) loss_zs_kd 0.0336 (0.0395) loss_oracle 1.1018 (1.0860) kd_loss 1.4022 (1.4661) acc 65.6250 (72.2917) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0989 (0.0637) teacher/usage_max 0.9453 (0.9777) teacher/usage_min 0.0075 (0.0039) teacher/usage_std 0.4330 (0.4557) nleep/row_max_mean 1193.9487 (1198.5455) nleep/row_max_std 12.8678 (14.9236) nleep/row_min_mean 1185.9974 (1189.3321) lr 3.1417e-05 eta 0:03:14
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,816
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,936
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.2%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [49/50] batch [20/246] time 0.488 (0.332) data 0.000 (0.015) loss 3.0470 (3.0240) teacher_loss 1.0022 (0.9790) loss_zs_kd 0.0427 (0.0383) loss_oracle 1.1092 (1.1071) kd_loss 1.4689 (1.4723) acc 78.1250 (74.6875) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0628 (0.0585) teacher/usage_max 0.9810 (0.9791) teacher/usage_min 0.0030 (0.0037) teacher/usage_std 0.4580 (0.4567) nleep/row_max_mean 1194.8864 (1198.8585) nleep/row_max_std 13.4011 (14.5404) nleep/row_min_mean 1186.0363 (1189.6392) lr 1.7713e-05 eta 0:02:36
epoch [49/50] batch [40/246] time 0.495 (0.377) data 0.000 (0.008) loss 2.8206 (2.9738) teacher_loss 0.8588 (0.9380) loss_zs_kd 0.0409 (0.0371) loss_oracle 1.0571 (1.0999) kd_loss 1.4128 (1.4674) acc 71.8750 (75.2344) gate/entropy 0.9817 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2128 (0.2127) gate/usage_std 0.1671 (0.1672) teacher/entropy 0.0862 (0.0629) teacher/usage_max 0.9473 (0.9785) teacher/usage_min 0.0034 (0.0037) teacher/usage_std 0.4345 (0.4563) nleep/row_max_mean 1199.6385 (1198.8006) nleep/row_max_std 13.5035 (14.2697) nleep/row_min_mean 1190.7069 (1189.5852) lr 1.7713e-05 eta 0:02:50
epoch [49/50] batch [60/246] time 0.496 (0.413) data 0.000 (0.005) loss 2.9450 (3.0127) teacher_loss 0.8704 (0.9807) loss_zs_kd 0.0740 (0.0384) loss_oracle 1.1180 (1.0977) kd_loss 1.4786 (1.4639) acc 84.3750 (73.9583) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0554 (0.0657) teacher/usage_max 0.9850 (0.9773) teacher/usage_min 0.0011 (0.0039) teacher/usage_std 0.4608 (0.4554) nleep/row_max_mean 1199.4486 (1198.6224) nleep/row_max_std 12.7279 (14.1920) nleep/row_min_mean 1189.9854 (1189.4465) lr 1.7713e-05 eta 0:02:58
epoch [49/50] batch [80/246] time 0.441 (0.432) data 0.000 (0.004) loss 3.2162 (3.0148) teacher_loss 1.0327 (0.9801) loss_zs_kd 0.0540 (0.0388) loss_oracle 1.2868 (1.1005) kd_loss 1.5132 (1.4650) acc 75.0000 (74.0625) gate/entropy 0.9814 (0.9816) gate/usage_max 0.5699 (0.5697) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1673 (0.1672) teacher/entropy 0.0290 (0.0654) teacher/usage_max 0.9941 (0.9780) teacher/usage_min 0.0004 (0.0039) teacher/usage_std 0.4672 (0.4560) nleep/row_max_mean 1199.9587 (1198.6768) nleep/row_max_std 12.2970 (14.1475) nleep/row_min_mean 1189.7542 (1189.5130) lr 1.7713e-05 eta 0:02:58
epoch [49/50] batch [100/246] time 0.140 (0.400) data 0.000 (0.003) loss 3.0971 (3.0498) teacher_loss 1.1792 (1.0152) loss_zs_kd 0.0412 (0.0387) loss_oracle 0.9513 (1.1014) kd_loss 1.4217 (1.4646) acc 59.3750 (73.1562) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2128 (0.2127) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0904 (0.0656) teacher/usage_max 0.9611 (0.9781) teacher/usage_min 0.0029 (0.0038) teacher/usage_std 0.4441 (0.4560) nleep/row_max_mean 1195.1621 (1198.5086) nleep/row_max_std 13.4318 (14.0790) nleep/row_min_mean 1185.9753 (1189.3550) lr 1.7713e-05 eta 0:02:36
epoch [49/50] batch [120/246] time 0.080 (0.389) data 0.000 (0.003) loss 2.4921 (3.0369) teacher_loss 0.4820 (1.0054) loss_zs_kd 0.0512 (0.0374) loss_oracle 1.0934 (1.0987) kd_loss 1.4379 (1.4635) acc 90.6250 (73.2552) gate/entropy 0.9819 (0.9816) gate/usage_max 0.5694 (0.5697) gate/usage_min 0.2128 (0.2127) gate/usage_std 0.1670 (0.1672) teacher/entropy 0.0888 (0.0666) teacher/usage_max 0.9714 (0.9780) teacher/usage_min 0.0077 (0.0038) teacher/usage_std 0.4512 (0.4559) nleep/row_max_mean 1193.1787 (1198.1868) nleep/row_max_std 14.2114 (14.0005) nleep/row_min_mean 1184.8911 (1189.0824) lr 1.7713e-05 eta 0:02:24
epoch [49/50] batch [140/246] time 0.509 (0.385) data 0.000 (0.002) loss 3.2169 (3.0302) teacher_loss 1.2955 (1.0013) loss_zs_kd 0.0433 (0.0375) loss_oracle 0.9649 (1.0967) kd_loss 1.4173 (1.4618) acc 68.7500 (73.4152) gate/entropy 0.9814 (0.9816) gate/usage_max 0.5699 (0.5697) gate/usage_min 0.2127 (0.2128) gate/usage_std 0.1673 (0.1672) teacher/entropy 0.1009 (0.0679) teacher/usage_max 0.9670 (0.9773) teacher/usage_min 0.0031 (0.0040) teacher/usage_std 0.4482 (0.4554) nleep/row_max_mean 1197.9436 (1198.0269) nleep/row_max_std 13.5030 (14.0314) nleep/row_min_mean 1189.6589 (1188.9407) lr 1.7713e-05 eta 0:02:15
epoch [49/50] batch [160/246] time 0.492 (0.389) data 0.000 (0.002) loss 3.5388 (3.0293) teacher_loss 1.4363 (1.0004) loss_zs_kd 0.0443 (0.0378) loss_oracle 1.2008 (1.0976) kd_loss 1.4799 (1.4612) acc 59.3750 (73.4180) gate/entropy 0.9817 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1671 (0.1672) teacher/entropy 0.0552 (0.0678) teacher/usage_max 0.9866 (0.9766) teacher/usage_min 0.0007 (0.0040) teacher/usage_std 0.4620 (0.4550) nleep/row_max_mean 1193.3545 (1197.8840) nleep/row_max_std 13.4343 (14.0536) nleep/row_min_mean 1183.9319 (1188.8014) lr 1.7713e-05 eta 0:02:09
epoch [49/50] batch [180/246] time 0.531 (0.401) data 0.000 (0.002) loss 2.9214 (3.0263) teacher_loss 0.8925 (1.0000) loss_zs_kd 0.0387 (0.0381) loss_oracle 1.1360 (1.0959) kd_loss 1.4416 (1.4594) acc 75.0000 (73.5069) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0806 (0.0694) teacher/usage_max 0.9730 (0.9762) teacher/usage_min 0.0012 (0.0041) teacher/usage_std 0.4524 (0.4547) nleep/row_max_mean 1195.5905 (1197.7102) nleep/row_max_std 15.8692 (14.0961) nleep/row_min_mean 1186.5273 (1188.6596) lr 1.7713e-05 eta 0:02:05
epoch [49/50] batch [200/246] time 0.507 (0.409) data 0.000 (0.002) loss 3.5772 (3.0316) teacher_loss 1.5416 (1.0082) loss_zs_kd 0.0506 (0.0385) loss_oracle 1.0717 (1.0929) kd_loss 1.4744 (1.4578) acc 50.0000 (73.3906) gate/entropy 0.9814 (0.9816) gate/usage_max 0.5699 (0.5697) gate/usage_min 0.2127 (0.2128) gate/usage_std 0.1673 (0.1672) teacher/entropy 0.0644 (0.0707) teacher/usage_max 0.9723 (0.9756) teacher/usage_min 0.0084 (0.0044) teacher/usage_std 0.4518 (0.4543) nleep/row_max_mean 1195.8555 (1197.6437) nleep/row_max_std 14.4743 (14.1924) nleep/row_min_mean 1186.6921 (1188.6168) lr 1.7713e-05 eta 0:01:59
epoch [49/50] batch [220/246] time 0.461 (0.389) data 0.000 (0.002) loss 2.8941 (3.0245) teacher_loss 0.8942 (1.0020) loss_zs_kd 0.0363 (0.0387) loss_oracle 1.0884 (1.0942) kd_loss 1.4376 (1.4561) acc 81.2500 (73.4801) gate/entropy 0.9817 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1671 (0.1672) teacher/entropy 0.0815 (0.0718) teacher/usage_max 0.9653 (0.9749) teacher/usage_min 0.0060 (0.0045) teacher/usage_std 0.4469 (0.4537) nleep/row_max_mean 1199.1281 (1197.6435) nleep/row_max_std 15.9772 (14.2675) nleep/row_min_mean 1189.8036 (1188.6214) lr 1.7713e-05 eta 0:01:45
epoch [49/50] batch [240/246] time 0.227 (0.378) data 0.000 (0.001) loss 2.9360 (3.0157) teacher_loss 0.9174 (0.9948) loss_zs_kd 0.0350 (0.0381) loss_oracle 1.1064 (1.0937) kd_loss 1.4479 (1.4550) acc 81.2500 (73.5417) gate/entropy 0.9817 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1671 (0.1672) teacher/entropy 0.0889 (0.0726) teacher/usage_max 0.9689 (0.9746) teacher/usage_min 0.0103 (0.0045) teacher/usage_std 0.4494 (0.4535) nleep/row_max_mean 1194.1177 (1197.5346) nleep/row_max_std 11.5219 (14.2423) nleep/row_min_mean 1185.6128 (1188.5295) lr 1.7713e-05 eta 0:01:35
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,812
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.9%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,935
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.2%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
epoch [50/50] batch [20/246] time 0.518 (0.514) data 0.000 (0.014) loss 3.0667 (2.9527) teacher_loss 1.0771 (0.9290) loss_zs_kd 0.0377 (0.0377) loss_oracle 1.0536 (1.1154) kd_loss 1.4439 (1.4471) acc 68.7500 (74.8438) gate/entropy 0.9814 (0.9816) gate/usage_max 0.5700 (0.5697) gate/usage_min 0.2127 (0.2128) gate/usage_std 0.1673 (0.1672) teacher/entropy 0.0882 (0.0770) teacher/usage_max 0.9757 (0.9695) teacher/usage_min 0.0086 (0.0068) teacher/usage_std 0.4542 (0.4499) nleep/row_max_mean 1195.8625 (1197.1916) nleep/row_max_std 13.4481 (15.3701) nleep/row_min_mean 1187.2976 (1188.2563) lr 7.8853e-06 eta 0:01:56
epoch [50/50] batch [40/246] time 0.498 (0.499) data 0.000 (0.007) loss 3.0981 (2.9654) teacher_loss 1.0349 (0.9279) loss_zs_kd 0.0544 (0.0394) loss_oracle 1.1919 (1.1215) kd_loss 1.4400 (1.4570) acc 78.1250 (75.8594) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0841 (0.0717) teacher/usage_max 0.9721 (0.9742) teacher/usage_min 0.0042 (0.0061) teacher/usage_std 0.4517 (0.4532) nleep/row_max_mean 1195.4890 (1197.4013) nleep/row_max_std 13.3727 (15.3029) nleep/row_min_mean 1186.4041 (1188.4495) lr 7.8853e-06 eta 0:01:42
epoch [50/50] batch [60/246] time 0.210 (0.424) data 0.001 (0.005) loss 3.6159 (2.9985) teacher_loss 1.4943 (0.9602) loss_zs_kd 0.0514 (0.0399) loss_oracle 1.1843 (1.1175) kd_loss 1.5038 (1.4595) acc 59.3750 (74.8438) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1671 (0.1672) teacher/entropy 0.0392 (0.0694) teacher/usage_max 0.9925 (0.9756) teacher/usage_min 0.0029 (0.0051) teacher/usage_std 0.4661 (0.4542) nleep/row_max_mean 1198.8606 (1197.3543) nleep/row_max_std 13.1353 (14.7755) nleep/row_min_mean 1189.8926 (1188.3918) lr 7.8853e-06 eta 0:01:18
epoch [50/50] batch [80/246] time 0.085 (0.389) data 0.001 (0.004) loss 2.9347 (3.0164) teacher_loss 1.0493 (0.9883) loss_zs_kd 0.0348 (0.0390) loss_oracle 0.9292 (1.1093) kd_loss 1.4034 (1.4539) acc 78.1250 (73.9062) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.1142 (0.0737) teacher/usage_max 0.9634 (0.9743) teacher/usage_min 0.0063 (0.0052) teacher/usage_std 0.4457 (0.4533) nleep/row_max_mean 1194.0670 (1197.1209) nleep/row_max_std 11.2269 (14.6123) nleep/row_min_mean 1185.9238 (1188.2128) lr 7.8853e-06 eta 0:01:04
epoch [50/50] batch [100/246] time 0.079 (0.384) data 0.000 (0.003) loss 3.7284 (3.0311) teacher_loss 1.7955 (1.0045) loss_zs_kd 0.0339 (0.0385) loss_oracle 1.0319 (1.1077) kd_loss 1.4000 (1.4535) acc 65.6250 (73.4062) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.1073 (0.0734) teacher/usage_max 0.9561 (0.9734) teacher/usage_min 0.0030 (0.0053) teacher/usage_std 0.4406 (0.4527) nleep/row_max_mean 1195.0146 (1197.0208) nleep/row_max_std 13.5588 (14.5513) nleep/row_min_mean 1186.3508 (1188.1091) lr 7.8853e-06 eta 0:00:56
epoch [50/50] batch [120/246] time 0.485 (0.375) data 0.000 (0.003) loss 2.5993 (3.0210) teacher_loss 0.6456 (0.9979) loss_zs_kd 0.0505 (0.0389) loss_oracle 1.0328 (1.1024) kd_loss 1.4121 (1.4525) acc 84.3750 (73.5938) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0927 (0.0741) teacher/usage_max 0.9524 (0.9734) teacher/usage_min 0.0042 (0.0051) teacher/usage_std 0.4380 (0.4526) nleep/row_max_mean 1198.1946 (1196.9922) nleep/row_max_std 15.6941 (14.3587) nleep/row_min_mean 1189.1096 (1188.0771) lr 7.8853e-06 eta 0:00:47
epoch [50/50] batch [140/246] time 0.103 (0.339) data 0.000 (0.002) loss 2.8831 (3.0149) teacher_loss 0.8157 (0.9894) loss_zs_kd 0.0376 (0.0387) loss_oracle 1.0871 (1.1042) kd_loss 1.5050 (1.4540) acc 81.2500 (73.7723) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0366 (0.0731) teacher/usage_max 0.9925 (0.9737) teacher/usage_min 0.0014 (0.0052) teacher/usage_std 0.4661 (0.4529) nleep/row_max_mean 1201.4580 (1196.9843) nleep/row_max_std 13.8173 (14.3366) nleep/row_min_mean 1191.8511 (1188.0640) lr 7.8853e-06 eta 0:00:35
epoch [50/50] batch [160/246] time 0.110 (0.309) data 0.000 (0.002) loss 2.7989 (3.0218) teacher_loss 0.7821 (0.9964) loss_zs_kd 0.0400 (0.0382) loss_oracle 1.0135 (1.1028) kd_loss 1.4901 (1.4549) acc 78.1250 (73.7305) gate/entropy 0.9816 (0.9816) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0511 (0.0727) teacher/usage_max 0.9882 (0.9743) teacher/usage_min 0.0054 (0.0052) teacher/usage_std 0.4631 (0.4533) nleep/row_max_mean 1201.2253 (1197.0531) nleep/row_max_std 15.1312 (14.4272) nleep/row_min_mean 1191.5398 (1188.1342) lr 7.8853e-06 eta 0:00:26
epoch [50/50] batch [180/246] time 0.097 (0.287) data 0.000 (0.002) loss 2.9356 (3.0184) teacher_loss 0.8791 (0.9924) loss_zs_kd 0.0309 (0.0385) loss_oracle 1.1348 (1.1049) kd_loss 1.4736 (1.4543) acc 81.2500 (73.8194) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0625 (0.0732) teacher/usage_max 0.9856 (0.9741) teacher/usage_min 0.0028 (0.0053) teacher/usage_std 0.4612 (0.4531) nleep/row_max_mean 1199.0652 (1196.9441) nleep/row_max_std 15.9893 (14.3822) nleep/row_min_mean 1190.0477 (1188.0295) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [200/246] time 0.472 (0.292) data 0.000 (0.002) loss 3.1345 (3.0150) teacher_loss 1.1361 (0.9913) loss_zs_kd 0.0427 (0.0385) loss_oracle 1.0837 (1.1029) kd_loss 1.4352 (1.4531) acc 65.6250 (73.8594) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0903 (0.0741) teacher/usage_max 0.9750 (0.9736) teacher/usage_min 0.0027 (0.0055) teacher/usage_std 0.4538 (0.4528) nleep/row_max_mean 1192.2250 (1196.9223) nleep/row_max_std 13.3758 (14.3757) nleep/row_min_mean 1183.5455 (1188.0208) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [220/246] time 0.487 (0.307) data 0.000 (0.001) loss 3.6007 (3.0262) teacher_loss 1.5215 (1.0050) loss_zs_kd 0.0413 (0.0390) loss_oracle 1.1559 (1.0997) kd_loss 1.4807 (1.4518) acc 62.5000 (73.5085) gate/entropy 0.9813 (0.9816) gate/usage_max 0.5701 (0.5697) gate/usage_min 0.2127 (0.2128) gate/usage_std 0.1674 (0.1672) teacher/entropy 0.0561 (0.0750) teacher/usage_max 0.9863 (0.9733) teacher/usage_min 0.0026 (0.0055) teacher/usage_std 0.4617 (0.4526) nleep/row_max_mean 1196.6056 (1196.8628) nleep/row_max_std 14.6854 (14.3785) nleep/row_min_mean 1187.6897 (1187.9727) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [240/246] time 0.493 (0.324) data 0.000 (0.001) loss 2.9780 (3.0270) teacher_loss 1.1037 (1.0055) loss_zs_kd 0.0388 (0.0388) loss_oracle 0.9668 (1.1003) kd_loss 1.3715 (1.4519) acc 65.6250 (73.3464) gate/entropy 0.9817 (0.9816) gate/usage_max 0.5696 (0.5697) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1671 (0.1672) teacher/entropy 0.1164 (0.0749) teacher/usage_max 0.9326 (0.9733) teacher/usage_min 0.0070 (0.0055) teacher/usage_std 0.4243 (0.4526) nleep/row_max_mean 1195.2413 (1196.9709) nleep/row_max_std 16.8775 (14.4197) nleep/row_min_mean 1186.6803 (1188.0758) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 3,354
* correct: 2,816
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 3,933
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.1%
******* Domain r best val acc:      85.5%, epoch: 32 *******
******* Domain r best val test acc: 90.9%, epoch: 32 *******
******* Domain r best test acc:     91.4%, epoch: 8 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/r/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 1:30:02

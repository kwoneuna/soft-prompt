Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'product', 'real_world']
Target     ['clipart']
# classes  65
# train_x  7,870
# val      3,353
# test     4,365
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
alpha_logit                                        1
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,196
[Info] Hyperparameters saved to: icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/245] time 0.086 (0.162) data 0.000 (0.025) loss 0.8604 (0.9711) teacher_loss 0.8486 (0.9444) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0032 (0.0032) kd_loss 0.0202 (0.0500) acc 75.0000 (76.5625) lr 1.0000e-05 eta 0:33:02
epoch [1/50] batch [40/245] time 0.342 (0.148) data 0.000 (0.013) loss 0.8833 (0.9636) teacher_loss 0.8582 (0.9404) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0071 (0.0038) kd_loss 0.0429 (0.0425) acc 75.0000 (75.3906) lr 1.0000e-05 eta 0:30:12
epoch [1/50] batch [60/245] time 0.092 (0.147) data 0.001 (0.009) loss 0.9711 (0.9721) teacher_loss 0.9570 (0.9519) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0053 (0.0043) kd_loss 0.0224 (0.0358) acc 75.0000 (75.2083) lr 1.0000e-05 eta 0:29:52
epoch [1/50] batch [80/245] time 0.098 (0.147) data 0.000 (0.006) loss 1.1642 (0.9856) teacher_loss 1.1421 (0.9671) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0060 (0.0049) kd_loss 0.0380 (0.0320) acc 71.8750 (74.9609) lr 1.0000e-05 eta 0:29:44
epoch [1/50] batch [100/245] time 0.140 (0.143) data 0.000 (0.005) loss 0.7910 (0.9552) teacher_loss 0.7704 (0.9381) loss_zs_kd 0.0008 (0.0002) loss_oracle 0.0147 (0.0055) kd_loss 0.0257 (0.0284) acc 81.2500 (75.5625) lr 1.0000e-05 eta 0:28:58
epoch [1/50] batch [120/245] time 0.135 (0.142) data 0.000 (0.004) loss 0.8172 (0.9409) teacher_loss 0.8099 (0.9249) loss_zs_kd 0.0006 (0.0003) loss_oracle 0.0063 (0.0061) kd_loss 0.0077 (0.0255) acc 75.0000 (75.6250) lr 1.0000e-05 eta 0:28:45
epoch [1/50] batch [140/245] time 0.134 (0.142) data 0.000 (0.004) loss 0.3397 (0.9304) teacher_loss 0.3277 (0.9154) loss_zs_kd 0.0007 (0.0004) loss_oracle 0.0107 (0.0065) kd_loss 0.0126 (0.0231) acc 93.7500 (75.6920) lr 1.0000e-05 eta 0:28:33
epoch [1/50] batch [160/245] time 0.140 (0.141) data 0.000 (0.003) loss 0.9990 (0.9269) teacher_loss 0.9909 (0.9125) loss_zs_kd 0.0016 (0.0006) loss_oracle 0.0073 (0.0069) kd_loss 0.0072 (0.0213) acc 71.8750 (75.6836) lr 1.0000e-05 eta 0:28:23
epoch [1/50] batch [180/245] time 0.134 (0.140) data 0.000 (0.003) loss 0.5664 (0.9213) teacher_loss 0.5473 (0.9073) loss_zs_kd 0.0018 (0.0007) loss_oracle 0.0187 (0.0075) kd_loss 0.0178 (0.0198) acc 84.3750 (75.5556) lr 1.0000e-05 eta 0:28:14
epoch [1/50] batch [200/245] time 0.141 (0.140) data 0.000 (0.003) loss 0.5922 (0.9262) teacher_loss 0.5838 (0.9127) loss_zs_kd 0.0008 (0.0008) loss_oracle 0.0142 (0.0079) kd_loss 0.0017 (0.0183) acc 84.3750 (75.4062) lr 1.0000e-05 eta 0:28:10
epoch [1/50] batch [220/245] time 0.136 (0.141) data 0.000 (0.003) loss 1.4263 (0.9181) teacher_loss 1.4171 (0.9049) loss_zs_kd 0.0038 (0.0009) loss_oracle 0.0109 (0.0084) kd_loss 0.0037 (0.0172) acc 56.2500 (75.6108) lr 1.0000e-05 eta 0:28:10
epoch [1/50] batch [240/245] time 0.137 (0.140) data 0.000 (0.002) loss 0.9007 (0.9191) teacher_loss 0.8926 (0.9061) loss_zs_kd 0.0014 (0.0011) loss_oracle 0.0098 (0.0089) kd_loss 0.0051 (0.0161) acc 75.0000 (75.5208) lr 1.0000e-05 eta 0:28:03
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 2,922
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 85.8%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,073
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 69.0%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      87.1%, epoch: 1 *******
******* Domain c best val test acc: 70.4%, epoch: 1 *******
******* Domain c best test acc:     70.4%, epoch: 1 *******
epoch [2/50] batch [20/245] time 0.130 (0.153) data 0.000 (0.016) loss 1.1698 (1.0330) teacher_loss 0.9171 (0.9005) loss_zs_kd 0.1042 (0.0788) loss_oracle 0.3979 (0.1829) kd_loss 0.0033 (0.0033) acc 75.0000 (75.4688) lr 2.0000e-03 eta 0:30:32
epoch [2/50] batch [40/245] time 0.137 (0.145) data 0.000 (0.008) loss 1.2583 (1.0680) teacher_loss 1.0655 (0.8791) loss_zs_kd 0.0476 (0.0838) loss_oracle 0.3364 (0.2910) kd_loss 0.0017 (0.0031) acc 68.7500 (75.8594) lr 2.0000e-03 eta 0:28:56
epoch [2/50] batch [60/245] time 0.138 (0.143) data 0.000 (0.005) loss 1.0186 (1.0738) teacher_loss 0.6980 (0.8589) loss_zs_kd 0.0840 (0.0801) loss_oracle 0.5543 (0.3465) kd_loss 0.0030 (0.0031) acc 84.3750 (76.9271) lr 2.0000e-03 eta 0:28:23
epoch [2/50] batch [80/245] time 0.147 (0.141) data 0.000 (0.004) loss 0.8680 (1.0804) teacher_loss 0.6100 (0.8517) loss_zs_kd 0.0659 (0.0806) loss_oracle 0.4481 (0.3737) kd_loss 0.0019 (0.0030) acc 81.2500 (77.0703) lr 2.0000e-03 eta 0:28:00
epoch [2/50] batch [100/245] time 0.136 (0.140) data 0.000 (0.003) loss 0.8118 (1.0490) teacher_loss 0.5401 (0.8226) loss_zs_kd 0.1202 (0.0797) loss_oracle 0.4195 (0.3700) kd_loss 0.0036 (0.0030) acc 84.3750 (77.7188) lr 2.0000e-03 eta 0:27:45
epoch [2/50] batch [120/245] time 0.136 (0.139) data 0.000 (0.003) loss 1.0755 (1.0628) teacher_loss 0.8161 (0.8331) loss_zs_kd 0.0674 (0.0773) loss_oracle 0.4477 (0.3790) kd_loss 0.0037 (0.0030) acc 71.8750 (77.6302) lr 2.0000e-03 eta 0:27:32
epoch [2/50] batch [140/245] time 0.142 (0.138) data 0.000 (0.002) loss 1.3678 (1.0677) teacher_loss 0.9722 (0.8171) loss_zs_kd 0.0886 (0.0763) loss_oracle 0.6999 (0.4221) kd_loss 0.0028 (0.0029) acc 68.7500 (77.7902) lr 2.0000e-03 eta 0:27:22
epoch [2/50] batch [160/245] time 0.133 (0.139) data 0.000 (0.002) loss 1.6531 (1.0805) teacher_loss 1.3134 (0.8196) loss_zs_kd 0.0643 (0.0743) loss_oracle 0.6123 (0.4445) kd_loss 0.0029 (0.0030) acc 68.7500 (77.8320) lr 2.0000e-03 eta 0:27:22
epoch [2/50] batch [180/245] time 0.136 (0.138) data 0.000 (0.002) loss 1.6823 (1.0982) teacher_loss 1.1838 (0.8200) loss_zs_kd 0.0752 (0.0759) loss_oracle 0.9151 (0.4774) kd_loss 0.0067 (0.0031) acc 75.0000 (77.9861) lr 2.0000e-03 eta 0:27:15
epoch [2/50] batch [200/245] time 0.094 (0.135) data 0.000 (0.002) loss 1.3148 (1.1167) teacher_loss 0.8817 (0.8196) loss_zs_kd 0.0730 (0.0771) loss_oracle 0.7847 (0.5137) kd_loss 0.0084 (0.0033) acc 78.1250 (77.9375) lr 2.0000e-03 eta 0:26:34
epoch [2/50] batch [220/245] time 0.339 (0.137) data 0.000 (0.002) loss 1.1347 (1.1258) teacher_loss 0.6984 (0.8204) loss_zs_kd 0.1989 (0.0784) loss_oracle 0.6678 (0.5289) kd_loss 0.0058 (0.0036) acc 75.0000 (77.9545) lr 2.0000e-03 eta 0:26:58
epoch [2/50] batch [240/245] time 0.079 (0.136) data 0.000 (0.001) loss 0.9971 (1.1215) teacher_loss 0.6360 (0.8113) loss_zs_kd 0.1102 (0.0787) loss_oracle 0.6021 (0.5377) kd_loss 0.0098 (0.0039) acc 84.3750 (78.1120) lr 2.0000e-03 eta 0:26:41
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,017
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.0%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,198
* accuracy: 73.3%
* error: 26.7%
* macro_f1: 72.0%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      90.0%, epoch: 2 *******
******* Domain c best val test acc: 73.3%, epoch: 2 *******
******* Domain c best test acc:     73.3%, epoch: 2 *******
epoch [3/50] batch [20/245] time 0.140 (0.139) data 0.000 (0.015) loss 0.8373 (1.1056) teacher_loss 0.5390 (0.7050) loss_zs_kd 0.0855 (0.0946) loss_oracle 0.5059 (0.7002) kd_loss 0.0052 (0.0065) acc 90.6250 (80.6250) lr 1.9980e-03 eta 0:27:17
epoch [3/50] batch [40/245] time 0.135 (0.137) data 0.000 (0.007) loss 0.9333 (1.1010) teacher_loss 0.6063 (0.7523) loss_zs_kd 0.0432 (0.0804) loss_oracle 0.6038 (0.6104) kd_loss 0.0069 (0.0066) acc 84.3750 (79.6875) lr 1.9980e-03 eta 0:26:46
epoch [3/50] batch [60/245] time 0.133 (0.136) data 0.000 (0.005) loss 1.4305 (1.1019) teacher_loss 1.0340 (0.7561) loss_zs_kd 0.0622 (0.0783) loss_oracle 0.7211 (0.6064) kd_loss 0.0096 (0.0069) acc 71.8750 (79.1146) lr 1.9980e-03 eta 0:26:36
epoch [3/50] batch [80/245] time 0.136 (0.136) data 0.000 (0.004) loss 1.0527 (1.1066) teacher_loss 0.6361 (0.7570) loss_zs_kd 0.1599 (0.0793) loss_oracle 0.6668 (0.6130) kd_loss 0.0067 (0.0070) acc 84.3750 (79.0625) lr 1.9980e-03 eta 0:26:32
epoch [3/50] batch [100/245] time 0.138 (0.136) data 0.000 (0.003) loss 1.3265 (1.1224) teacher_loss 0.9357 (0.7649) loss_zs_kd 0.1017 (0.0862) loss_oracle 0.6719 (0.6214) kd_loss 0.0081 (0.0074) acc 78.1250 (78.6562) lr 1.9980e-03 eta 0:26:28
epoch [3/50] batch [120/245] time 0.133 (0.136) data 0.000 (0.003) loss 0.6803 (1.1212) teacher_loss 0.2719 (0.7552) loss_zs_kd 0.0708 (0.0863) loss_oracle 0.7334 (0.6376) kd_loss 0.0127 (0.0079) acc 93.7500 (78.9323) lr 1.9980e-03 eta 0:26:19
epoch [3/50] batch [140/245] time 0.137 (0.136) data 0.000 (0.002) loss 1.0167 (1.1348) teacher_loss 0.6127 (0.7635) loss_zs_kd 0.0762 (0.0872) loss_oracle 0.7203 (0.6468) kd_loss 0.0115 (0.0086) acc 78.1250 (78.7500) lr 1.9980e-03 eta 0:26:18
epoch [3/50] batch [160/245] time 0.137 (0.136) data 0.000 (0.002) loss 0.9462 (1.1328) teacher_loss 0.5853 (0.7588) loss_zs_kd 0.0781 (0.0849) loss_oracle 0.6305 (0.6539) kd_loss 0.0131 (0.0093) acc 81.2500 (78.8867) lr 1.9980e-03 eta 0:26:15
epoch [3/50] batch [180/245] time 0.138 (0.136) data 0.000 (0.002) loss 0.9818 (1.1359) teacher_loss 0.6297 (0.7621) loss_zs_kd 0.0364 (0.0833) loss_oracle 0.6512 (0.6541) kd_loss 0.0164 (0.0102) acc 81.2500 (78.8194) lr 1.9980e-03 eta 0:26:13
epoch [3/50] batch [200/245] time 0.135 (0.136) data 0.000 (0.002) loss 1.2722 (1.1408) teacher_loss 0.8424 (0.7670) loss_zs_kd 0.1252 (0.0832) loss_oracle 0.7152 (0.6534) kd_loss 0.0193 (0.0110) acc 75.0000 (78.6719) lr 1.9980e-03 eta 0:26:10
epoch [3/50] batch [220/245] time 0.134 (0.136) data 0.000 (0.002) loss 1.3682 (1.1473) teacher_loss 0.9696 (0.7712) loss_zs_kd 0.1235 (0.0857) loss_oracle 0.6492 (0.6546) kd_loss 0.0246 (0.0118) acc 78.1250 (78.5795) lr 1.9980e-03 eta 0:26:09
epoch [3/50] batch [240/245] time 0.135 (0.136) data 0.000 (0.001) loss 0.6792 (1.1505) teacher_loss 0.2454 (0.7703) loss_zs_kd 0.1411 (0.0878) loss_oracle 0.7059 (0.6600) kd_loss 0.0208 (0.0126) acc 93.7500 (78.6458) lr 1.9980e-03 eta 0:26:07
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,017
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,187
* accuracy: 73.0%
* error: 27.0%
* macro_f1: 71.6%
******* Domain c best val acc:      90.0%, epoch: 2 *******
******* Domain c best val test acc: 73.3%, epoch: 2 *******
******* Domain c best test acc:     73.3%, epoch: 2 *******
epoch [4/50] batch [20/245] time 0.137 (0.157) data 0.000 (0.015) loss 1.4036 (1.2245) teacher_loss 0.9455 (0.8059) loss_zs_kd 0.1648 (0.0960) loss_oracle 0.7266 (0.7162) kd_loss 0.0249 (0.0251) acc 68.7500 (77.8125) lr 1.9921e-03 eta 0:30:09
epoch [4/50] batch [40/245] time 0.135 (0.147) data 0.000 (0.007) loss 1.2965 (1.2049) teacher_loss 0.9159 (0.7940) loss_zs_kd 0.0967 (0.0966) loss_oracle 0.6443 (0.7003) kd_loss 0.0201 (0.0250) acc 75.0000 (77.2656) lr 1.9921e-03 eta 0:28:02
epoch [4/50] batch [60/245] time 0.137 (0.143) data 0.000 (0.005) loss 0.9176 (1.1732) teacher_loss 0.5269 (0.7772) loss_zs_kd 0.1132 (0.0906) loss_oracle 0.6431 (0.6765) kd_loss 0.0250 (0.0248) acc 87.5000 (77.8646) lr 1.9921e-03 eta 0:27:19
epoch [4/50] batch [80/245] time 0.136 (0.142) data 0.000 (0.004) loss 1.0676 (1.1871) teacher_loss 0.6788 (0.7884) loss_zs_kd 0.0745 (0.0896) loss_oracle 0.6724 (0.6826) kd_loss 0.0309 (0.0251) acc 81.2500 (77.6172) lr 1.9921e-03 eta 0:26:59
epoch [4/50] batch [100/245] time 0.137 (0.141) data 0.000 (0.003) loss 1.1407 (1.1818) teacher_loss 0.7138 (0.7768) loss_zs_kd 0.1208 (0.0910) loss_oracle 0.7010 (0.6929) kd_loss 0.0320 (0.0261) acc 87.5000 (78.4062) lr 1.9921e-03 eta 0:26:46
epoch [4/50] batch [120/245] time 0.134 (0.140) data 0.000 (0.003) loss 1.4958 (1.1911) teacher_loss 1.0805 (0.7845) loss_zs_kd 0.0773 (0.0918) loss_oracle 0.7187 (0.6943) kd_loss 0.0347 (0.0270) acc 75.0000 (78.1510) lr 1.9921e-03 eta 0:26:34
epoch [4/50] batch [140/245] time 0.080 (0.135) data 0.000 (0.002) loss 1.0854 (1.1920) teacher_loss 0.7105 (0.7826) loss_zs_kd 0.0876 (0.0914) loss_oracle 0.6279 (0.6994) kd_loss 0.0341 (0.0279) acc 81.2500 (78.4821) lr 1.9921e-03 eta 0:25:36
epoch [4/50] batch [160/245] time 0.088 (0.132) data 0.000 (0.002) loss 0.8122 (1.1920) teacher_loss 0.4193 (0.7798) loss_zs_kd 0.0744 (0.0907) loss_oracle 0.6745 (0.7047) kd_loss 0.0368 (0.0290) acc 90.6250 (78.7695) lr 1.9921e-03 eta 0:25:02
epoch [4/50] batch [180/245] time 0.128 (0.136) data 0.000 (0.002) loss 0.7986 (1.1889) teacher_loss 0.3378 (0.7689) loss_zs_kd 0.0700 (0.0907) loss_oracle 0.8110 (0.7191) kd_loss 0.0406 (0.0301) acc 93.7500 (79.0799) lr 1.9921e-03 eta 0:25:37
epoch [4/50] batch [200/245] time 0.144 (0.138) data 0.000 (0.002) loss 0.9875 (1.1880) teacher_loss 0.5568 (0.7644) loss_zs_kd 0.1081 (0.0927) loss_oracle 0.7158 (0.7235) kd_loss 0.0376 (0.0309) acc 78.1250 (79.1094) lr 1.9921e-03 eta 0:26:03
epoch [4/50] batch [220/245] time 0.088 (0.134) data 0.000 (0.002) loss 1.0687 (1.1927) teacher_loss 0.5796 (0.7676) loss_zs_kd 0.1297 (0.0932) loss_oracle 0.8061 (0.7254) kd_loss 0.0424 (0.0316) acc 84.3750 (79.1619) lr 1.9921e-03 eta 0:25:11
epoch [4/50] batch [240/245] time 0.079 (0.132) data 0.000 (0.001) loss 1.3672 (1.1994) teacher_loss 0.9418 (0.7707) loss_zs_kd 0.0792 (0.0939) loss_oracle 0.7255 (0.7307) kd_loss 0.0461 (0.0327) acc 68.7500 (79.0104) lr 1.9921e-03 eta 0:24:52
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,024
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.2%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,200
* accuracy: 73.3%
* error: 26.7%
* macro_f1: 72.1%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      90.2%, epoch: 4 *******
******* Domain c best val test acc: 73.3%, epoch: 4 *******
******* Domain c best test acc:     73.3%, epoch: 4 *******
epoch [5/50] batch [20/245] time 0.140 (0.152) data 0.000 (0.014) loss 1.5679 (1.2944) teacher_loss 1.1258 (0.8523) loss_zs_kd 0.1528 (0.1026) loss_oracle 0.6951 (0.7384) kd_loss 0.0363 (0.0433) acc 75.0000 (77.3438) lr 1.9823e-03 eta 0:28:24
epoch [5/50] batch [40/245] time 0.136 (0.144) data 0.000 (0.007) loss 1.3513 (1.2606) teacher_loss 0.8954 (0.8224) loss_zs_kd 0.1041 (0.1032) loss_oracle 0.7514 (0.7308) kd_loss 0.0561 (0.0424) acc 78.1250 (77.2656) lr 1.9823e-03 eta 0:26:55
epoch [5/50] batch [60/245] time 0.136 (0.141) data 0.000 (0.005) loss 1.2203 (1.2323) teacher_loss 0.8332 (0.7987) loss_zs_kd 0.0640 (0.0985) loss_oracle 0.6640 (0.7259) kd_loss 0.0460 (0.0427) acc 71.8750 (78.0729) lr 1.9823e-03 eta 0:26:21
epoch [5/50] batch [80/245] time 0.136 (0.140) data 0.000 (0.004) loss 1.0384 (1.2224) teacher_loss 0.6119 (0.7869) loss_zs_kd 0.1345 (0.1009) loss_oracle 0.6702 (0.7270) kd_loss 0.0482 (0.0431) acc 84.3750 (78.5547) lr 1.9823e-03 eta 0:26:02
epoch [5/50] batch [100/245] time 0.139 (0.139) data 0.000 (0.003) loss 0.7287 (1.2000) teacher_loss 0.3227 (0.7650) loss_zs_kd 0.0762 (0.0987) loss_oracle 0.6932 (0.7280) kd_loss 0.0425 (0.0432) acc 87.5000 (79.0625) lr 1.9823e-03 eta 0:25:52
epoch [5/50] batch [120/245] time 0.134 (0.139) data 0.000 (0.002) loss 1.0340 (1.1954) teacher_loss 0.6460 (0.7591) loss_zs_kd 0.1042 (0.0973) loss_oracle 0.6163 (0.7320) kd_loss 0.0555 (0.0433) acc 75.0000 (79.1667) lr 1.9823e-03 eta 0:25:45
epoch [5/50] batch [140/245] time 0.139 (0.139) data 0.000 (0.002) loss 0.9648 (1.1872) teacher_loss 0.5200 (0.7500) loss_zs_kd 0.1116 (0.0955) loss_oracle 0.7340 (0.7351) kd_loss 0.0441 (0.0436) acc 84.3750 (79.4643) lr 1.9823e-03 eta 0:25:42
epoch [5/50] batch [160/245] time 0.137 (0.138) data 0.000 (0.002) loss 1.0924 (1.1908) teacher_loss 0.6381 (0.7493) loss_zs_kd 0.1063 (0.0965) loss_oracle 0.7665 (0.7425) kd_loss 0.0358 (0.0440) acc 84.3750 (79.6094) lr 1.9823e-03 eta 0:25:33
epoch [5/50] batch [180/245] time 0.132 (0.138) data 0.000 (0.002) loss 1.3202 (1.2007) teacher_loss 0.8019 (0.7571) loss_zs_kd 0.1825 (0.0982) loss_oracle 0.7856 (0.7452) kd_loss 0.0685 (0.0439) acc 84.3750 (79.2882) lr 1.9823e-03 eta 0:25:28
epoch [5/50] batch [200/245] time 0.135 (0.138) data 0.000 (0.002) loss 1.1245 (1.2008) teacher_loss 0.7278 (0.7574) loss_zs_kd 0.1008 (0.0993) loss_oracle 0.6517 (0.7435) kd_loss 0.0409 (0.0441) acc 75.0000 (79.1875) lr 1.9823e-03 eta 0:25:26
epoch [5/50] batch [220/245] time 0.135 (0.138) data 0.000 (0.001) loss 1.5772 (1.2005) teacher_loss 1.1711 (0.7604) loss_zs_kd 0.0798 (0.0984) loss_oracle 0.6833 (0.7377) kd_loss 0.0493 (0.0440) acc 68.7500 (79.1903) lr 1.9823e-03 eta 0:25:20
epoch [5/50] batch [240/245] time 0.133 (0.137) data 0.000 (0.001) loss 1.5153 (1.2022) teacher_loss 1.0649 (0.7634) loss_zs_kd 0.1076 (0.0989) loss_oracle 0.7487 (0.7350) kd_loss 0.0445 (0.0437) acc 65.6250 (78.9062) lr 1.9823e-03 eta 0:25:16
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,029
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.5%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,172
* accuracy: 72.7%
* error: 27.3%
* macro_f1: 71.4%
******* Domain c best val acc:      90.3%, epoch: 5 *******
******* Domain c best val test acc: 72.7%, epoch: 5 *******
******* Domain c best test acc:     73.3%, epoch: 4 *******
epoch [6/50] batch [20/245] time 0.136 (0.154) data 0.000 (0.016) loss 1.1952 (1.1330) teacher_loss 0.7919 (0.6931) loss_zs_kd 0.0748 (0.0917) loss_oracle 0.6981 (0.7419) kd_loss 0.0336 (0.0463) acc 81.2500 (81.8750) lr 1.9686e-03 eta 0:28:15
epoch [6/50] batch [40/245] time 0.133 (0.144) data 0.000 (0.008) loss 1.4483 (1.1659) teacher_loss 1.0290 (0.7194) loss_zs_kd 0.1013 (0.0909) loss_oracle 0.7047 (0.7580) kd_loss 0.0328 (0.0442) acc 65.6250 (79.8438) lr 1.9686e-03 eta 0:26:26
epoch [6/50] batch [60/245] time 0.135 (0.141) data 0.000 (0.005) loss 1.2223 (1.1740) teacher_loss 0.8083 (0.7253) loss_zs_kd 0.0976 (0.0943) loss_oracle 0.6717 (0.7576) kd_loss 0.0587 (0.0454) acc 71.8750 (79.6354) lr 1.9686e-03 eta 0:25:49
epoch [6/50] batch [80/245] time 0.080 (0.139) data 0.000 (0.004) loss 1.1240 (1.1730) teacher_loss 0.6645 (0.7242) loss_zs_kd 0.0926 (0.0960) loss_oracle 0.7655 (0.7556) kd_loss 0.0610 (0.0461) acc 78.1250 (79.8438) lr 1.9686e-03 eta 0:25:19
epoch [6/50] batch [100/245] time 0.080 (0.133) data 0.000 (0.003) loss 1.7462 (1.1693) teacher_loss 1.2726 (0.7145) loss_zs_kd 0.1091 (0.0955) loss_oracle 0.7926 (0.7677) kd_loss 0.0453 (0.0462) acc 68.7500 (80.4062) lr 1.9686e-03 eta 0:24:15
epoch [6/50] batch [120/245] time 0.355 (0.136) data 0.000 (0.003) loss 1.4511 (1.1666) teacher_loss 0.9482 (0.7078) loss_zs_kd 0.1327 (0.0964) loss_oracle 0.8259 (0.7744) kd_loss 0.0472 (0.0468) acc 75.0000 (80.6250) lr 1.9686e-03 eta 0:24:42
epoch [6/50] batch [140/245] time 0.164 (0.139) data 0.001 (0.002) loss 1.3938 (1.1740) teacher_loss 0.9086 (0.7150) loss_zs_kd 0.1136 (0.0977) loss_oracle 0.8054 (0.7737) kd_loss 0.0513 (0.0467) acc 78.1250 (80.5580) lr 1.9686e-03 eta 0:25:10
epoch [6/50] batch [160/245] time 0.089 (0.136) data 0.000 (0.002) loss 1.0227 (1.1782) teacher_loss 0.5753 (0.7157) loss_zs_kd 0.0772 (0.0991) loss_oracle 0.7728 (0.7793) kd_loss 0.0447 (0.0466) acc 84.3750 (80.3711) lr 1.9686e-03 eta 0:24:33
epoch [6/50] batch [180/245] time 0.094 (0.135) data 0.000 (0.002) loss 1.0876 (1.1783) teacher_loss 0.5886 (0.7129) loss_zs_kd 0.0926 (0.0992) loss_oracle 0.8491 (0.7843) kd_loss 0.0563 (0.0473) acc 87.5000 (80.4340) lr 1.9686e-03 eta 0:24:20
epoch [6/50] batch [200/245] time 0.086 (0.136) data 0.000 (0.002) loss 0.8824 (1.1845) teacher_loss 0.4168 (0.7163) loss_zs_kd 0.1286 (0.0999) loss_oracle 0.7563 (0.7891) kd_loss 0.0463 (0.0474) acc 87.5000 (80.3125) lr 1.9686e-03 eta 0:24:27
epoch [6/50] batch [220/245] time 0.134 (0.135) data 0.000 (0.002) loss 1.1769 (1.1950) teacher_loss 0.7145 (0.7274) loss_zs_kd 0.0674 (0.1008) loss_oracle 0.8347 (0.7867) kd_loss 0.0226 (0.0477) acc 84.3750 (80.0852) lr 1.9686e-03 eta 0:24:23
epoch [6/50] batch [240/245] time 0.134 (0.136) data 0.000 (0.002) loss 1.1889 (1.1913) teacher_loss 0.6821 (0.7196) loss_zs_kd 0.0823 (0.0998) loss_oracle 0.8818 (0.7956) kd_loss 0.0496 (0.0479) acc 78.1250 (80.1953) lr 1.9686e-03 eta 0:24:21
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,024
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.3%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,183
* accuracy: 72.9%
* error: 27.1%
* macro_f1: 71.6%
******* Domain c best val acc:      90.3%, epoch: 5 *******
******* Domain c best val test acc: 72.7%, epoch: 5 *******
******* Domain c best test acc:     73.3%, epoch: 4 *******
epoch [7/50] batch [20/245] time 0.136 (0.151) data 0.000 (0.013) loss 1.6746 (1.2958) teacher_loss 1.2405 (0.8283) loss_zs_kd 0.0937 (0.0963) loss_oracle 0.7216 (0.7880) kd_loss 0.0528 (0.0508) acc 68.7500 (78.2812) lr 1.9511e-03 eta 0:27:04
epoch [7/50] batch [40/245] time 0.119 (0.143) data 0.000 (0.007) loss 0.9941 (1.2591) teacher_loss 0.5200 (0.7900) loss_zs_kd 0.0829 (0.1080) loss_oracle 0.8024 (0.7780) kd_loss 0.0629 (0.0521) acc 87.5000 (78.4375) lr 1.9511e-03 eta 0:25:35
epoch [7/50] batch [60/245] time 0.124 (0.141) data 0.000 (0.005) loss 1.3360 (1.2280) teacher_loss 0.9038 (0.7597) loss_zs_kd 0.1040 (0.1041) loss_oracle 0.7172 (0.7808) kd_loss 0.0431 (0.0517) acc 71.8750 (80.0000) lr 1.9511e-03 eta 0:25:11
epoch [7/50] batch [80/245] time 0.132 (0.141) data 0.000 (0.003) loss 1.3236 (1.2135) teacher_loss 0.8373 (0.7423) loss_zs_kd 0.0597 (0.1011) loss_oracle 0.8630 (0.7893) kd_loss 0.0498 (0.0521) acc 78.1250 (80.2344) lr 1.9511e-03 eta 0:25:03
epoch [7/50] batch [100/245] time 0.136 (0.140) data 0.000 (0.003) loss 1.0889 (1.2191) teacher_loss 0.6668 (0.7451) loss_zs_kd 0.0593 (0.1018) loss_oracle 0.7378 (0.7933) kd_loss 0.0472 (0.0528) acc 81.2500 (80.2188) lr 1.9511e-03 eta 0:24:50
epoch [7/50] batch [120/245] time 0.136 (0.139) data 0.000 (0.002) loss 1.2132 (1.2206) teacher_loss 0.7695 (0.7440) loss_zs_kd 0.0744 (0.1017) loss_oracle 0.7518 (0.7977) kd_loss 0.0612 (0.0538) acc 81.2500 (80.2344) lr 1.9511e-03 eta 0:24:40
epoch [7/50] batch [140/245] time 0.146 (0.138) data 0.000 (0.002) loss 1.3143 (1.2247) teacher_loss 0.8143 (0.7483) loss_zs_kd 0.0707 (0.1025) loss_oracle 0.8256 (0.7945) kd_loss 0.1038 (0.0558) acc 84.3750 (80.0670) lr 1.9511e-03 eta 0:24:31
epoch [7/50] batch [160/245] time 0.138 (0.139) data 0.000 (0.002) loss 1.2565 (1.2336) teacher_loss 0.7835 (0.7563) loss_zs_kd 0.0909 (0.1035) loss_oracle 0.7893 (0.7945) kd_loss 0.0657 (0.0567) acc 81.2500 (79.8828) lr 1.9511e-03 eta 0:24:35
epoch [7/50] batch [180/245] time 0.135 (0.139) data 0.000 (0.002) loss 1.0433 (1.2339) teacher_loss 0.5327 (0.7523) loss_zs_kd 0.1534 (0.1039) loss_oracle 0.8083 (0.8022) kd_loss 0.0595 (0.0571) acc 84.3750 (80.0000) lr 1.9511e-03 eta 0:24:31
epoch [7/50] batch [200/245] time 0.134 (0.138) data 0.000 (0.002) loss 1.3612 (1.2271) teacher_loss 0.8700 (0.7424) loss_zs_kd 0.0627 (0.1032) loss_oracle 0.8625 (0.8085) kd_loss 0.0573 (0.0577) acc 78.1250 (80.2812) lr 1.9511e-03 eta 0:24:25
epoch [7/50] batch [220/245] time 0.140 (0.138) data 0.000 (0.001) loss 1.0802 (1.2244) teacher_loss 0.5897 (0.7371) loss_zs_kd 0.1239 (0.1036) loss_oracle 0.7973 (0.8130) kd_loss 0.0598 (0.0579) acc 81.2500 (80.3693) lr 1.9511e-03 eta 0:24:19
epoch [7/50] batch [240/245] time 0.134 (0.138) data 0.000 (0.001) loss 0.7918 (1.2147) teacher_loss 0.3009 (0.7279) loss_zs_kd 0.0730 (0.1027) loss_oracle 0.8203 (0.8125) kd_loss 0.0886 (0.0586) acc 93.7500 (80.6771) lr 1.9511e-03 eta 0:24:14
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,034
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.6%
Checkpoint saved to icml/multi-dg/tuning/19_ema_teacherupdate/TRIP/office_home/b32_ep50/ViT-B16/c/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,184
* accuracy: 72.9%
* error: 27.1%
* macro_f1: 71.7%
******* Domain c best val acc:      90.5%, epoch: 7 *******
******* Domain c best val test acc: 72.9%, epoch: 7 *******
******* Domain c best test acc:     73.3%, epoch: 4 *******
epoch [8/50] batch [20/245] time 0.137 (0.154) data 0.000 (0.012) loss 1.5022 (1.2842) teacher_loss 1.0294 (0.7793) loss_zs_kd 0.0818 (0.1066) loss_oracle 0.8118 (0.8369) kd_loss 0.0519 (0.0662) acc 68.7500 (79.8438) lr 1.9298e-03 eta 0:27:00
epoch [8/50] batch [40/245] time 0.102 (0.133) data 0.000 (0.006) loss 0.9626 (1.2543) teacher_loss 0.4819 (0.7360) loss_zs_kd 0.0564 (0.0998) loss_oracle 0.8540 (0.8686) kd_loss 0.0510 (0.0682) acc 78.1250 (80.3125) lr 1.9298e-03 eta 0:23:16
epoch [8/50] batch [60/245] time 0.080 (0.135) data 0.000 (0.004) loss 1.3655 (1.2368) teacher_loss 0.8543 (0.7204) loss_zs_kd 0.0777 (0.0980) loss_oracle 0.8810 (0.8675) kd_loss 0.0639 (0.0673) acc 78.1250 (80.9896) lr 1.9298e-03 eta 0:23:35
epoch [8/50] batch [80/245] time 0.115 (0.131) data 0.000 (0.003) loss 0.8858 (1.2479) teacher_loss 0.4081 (0.7341) loss_zs_kd 0.0729 (0.0973) loss_oracle 0.8311 (0.8624) kd_loss 0.0514 (0.0679) acc 90.6250 (80.2344) lr 1.9298e-03 eta 0:22:54
epoch [8/50] batch [100/245] time 0.090 (0.133) data 0.000 (0.003) loss 1.3067 (1.2542) teacher_loss 0.7604 (0.7419) loss_zs_kd 0.1493 (0.0967) loss_oracle 0.8496 (0.8586) kd_loss 0.0938 (0.0693) acc 78.1250 (80.0625) lr 1.9298e-03 eta 0:23:04
epoch [8/50] batch [120/245] time 0.098 (0.133) data 0.000 (0.002) loss 1.1346 (1.2355) teacher_loss 0.6190 (0.7252) loss_zs_kd 0.1584 (0.0972) loss_oracle 0.7737 (0.8539) kd_loss 0.0992 (0.0695) acc 71.8750 (80.1302) lr 1.9298e-03 eta 0:23:03
epoch [8/50] batch [140/245] time 0.101 (0.135) data 0.000 (0.002) loss 0.9230 (1.2262) teacher_loss 0.4779 (0.7195) loss_zs_kd 0.0736 (0.0969) loss_oracle 0.7564 (0.8470) kd_loss 0.0601 (0.0697) acc 87.5000 (80.2679) lr 1.9298e-03 eta 0:23:19
epoch [8/50] batch [160/245] time 0.093 (0.139) data 0.000 (0.002) loss 1.4201 (1.2315) teacher_loss 1.0034 (0.7276) loss_zs_kd 0.0708 (0.0993) loss_oracle 0.7146 (0.8398) kd_loss 0.0479 (0.0687) acc 78.1250 (80.2344) lr 1.9298e-03 eta 0:24:00
epoch [8/50] batch [180/245] time 0.139 (0.139) data 0.000 (0.002) loss 0.9989 (1.2227) teacher_loss 0.5505 (0.7216) loss_zs_kd 0.0838 (0.1003) loss_oracle 0.7409 (0.8328) kd_loss 0.0722 (0.0693) acc 84.3750 (80.3819) lr 1.9298e-03 eta 0:23:54
epoch [8/50] batch [200/245] time 0.138 (0.138) data 0.000 (0.001) loss 1.5704 (1.2232) teacher_loss 1.0843 (0.7229) loss_zs_kd 0.0898 (0.1006) loss_oracle 0.8066 (0.8307) kd_loss 0.0758 (0.0693) acc 68.7500 (80.3906) lr 1.9298e-03 eta 0:23:49
epoch [8/50] batch [220/245] time 0.139 (0.138) data 0.000 (0.001) loss 1.1834 (1.2204) teacher_loss 0.6269 (0.7187) loss_zs_kd 0.1472 (0.1017) loss_oracle 0.8549 (0.8321) kd_loss 0.1109 (0.0696) acc 87.5000 (80.4261) lr 1.9298e-03 eta 0:23:45
epoch [8/50] batch [240/245] time 0.130 (0.138) data 0.000 (0.001) loss 1.1450 (1.2235) teacher_loss 0.6153 (0.7223) loss_zs_kd 0.1018 (0.1012) loss_oracle 0.8626 (0.8314) kd_loss 0.0949 (0.0699) acc 84.3750 (80.3776) lr 1.9298e-03 eta 0:23:39
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,030
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.5%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,185
* accuracy: 73.0%
* error: 27.0%
* macro_f1: 71.6%
******* Domain c best val acc:      90.5%, epoch: 7 *******
******* Domain c best val test acc: 72.9%, epoch: 7 *******
******* Domain c best test acc:     73.3%, epoch: 4 *******
epoch [9/50] batch [20/245] time 0.136 (0.153) data 0.000 (0.014) loss 1.3452 (1.1916) teacher_loss 0.8184 (0.6736) loss_zs_kd 0.1200 (0.1065) loss_oracle 0.8616 (0.8545) kd_loss 0.0720 (0.0749) acc 81.2500 (81.2500) lr 1.9048e-03 eta 0:26:08
epoch [9/50] batch [40/245] time 0.135 (0.144) data 0.000 (0.007) loss 1.0184 (1.1847) teacher_loss 0.4717 (0.6640) loss_zs_kd 0.1507 (0.1089) loss_oracle 0.8602 (0.8570) kd_loss 0.0824 (0.0755) acc 84.3750 (81.0938) lr 1.9048e-03 eta 0:24:41
epoch [9/50] batch [60/245] time 0.134 (0.142) data 0.000 (0.005) loss 1.7284 (1.2347) teacher_loss 1.2951 (0.7179) loss_zs_kd 0.1043 (0.1124) loss_oracle 0.7188 (0.8440) kd_loss 0.0434 (0.0770) acc 62.5000 (79.4792) lr 1.9048e-03 eta 0:24:07
epoch [9/50] batch [80/245] time 0.133 (0.140) data 0.000 (0.004) loss 1.2992 (1.2513) teacher_loss 0.8435 (0.7390) loss_zs_kd 0.0812 (0.1115) loss_oracle 0.7715 (0.8368) kd_loss 0.0588 (0.0762) acc 75.0000 (79.6484) lr 1.9048e-03 eta 0:23:49
epoch [9/50] batch [100/245] time 0.140 (0.139) data 0.000 (0.003) loss 0.6499 (1.2487) teacher_loss 0.1200 (0.7369) loss_zs_kd 0.0965 (0.1106) loss_oracle 0.8836 (0.8353) kd_loss 0.0797 (0.0776) acc 100.0000 (79.9375) lr 1.9048e-03 eta 0:23:39
epoch [9/50] batch [120/245] time 0.133 (0.139) data 0.000 (0.002) loss 1.0281 (1.2463) teacher_loss 0.5249 (0.7354) loss_zs_kd 0.0987 (0.1083) loss_oracle 0.8358 (0.8358) kd_loss 0.0719 (0.0777) acc 84.3750 (80.0000) lr 1.9048e-03 eta 0:23:30
epoch [9/50] batch [140/245] time 0.136 (0.138) data 0.000 (0.002) loss 0.7941 (1.2552) teacher_loss 0.3263 (0.7432) loss_zs_kd 0.0615 (0.1080) loss_oracle 0.8108 (0.8378) kd_loss 0.0633 (0.0784) acc 87.5000 (79.9107) lr 1.9048e-03 eta 0:23:23
epoch [9/50] batch [160/245] time 0.136 (0.138) data 0.000 (0.002) loss 1.1199 (1.2514) teacher_loss 0.5881 (0.7403) loss_zs_kd 0.1336 (0.1090) loss_oracle 0.8606 (0.8346) kd_loss 0.0694 (0.0788) acc 81.2500 (79.9609) lr 1.9048e-03 eta 0:23:18
epoch [9/50] batch [180/245] time 0.135 (0.138) data 0.000 (0.002) loss 1.6238 (1.2463) teacher_loss 1.1849 (0.7364) loss_zs_kd 0.1509 (0.1096) loss_oracle 0.6628 (0.8313) kd_loss 0.0642 (0.0787) acc 62.5000 (79.9306) lr 1.9048e-03 eta 0:23:13
epoch [9/50] batch [200/245] time 0.145 (0.138) data 0.000 (0.002) loss 1.2078 (1.2432) teacher_loss 0.7503 (0.7352) loss_zs_kd 0.0494 (0.1091) loss_oracle 0.8191 (0.8282) kd_loss 0.0465 (0.0786) acc 78.1250 (80.0625) lr 1.9048e-03 eta 0:23:12
epoch [9/50] batch [220/245] time 0.136 (0.138) data 0.000 (0.001) loss 1.4647 (1.2403) teacher_loss 0.9755 (0.7347) loss_zs_kd 0.1056 (0.1077) loss_oracle 0.8116 (0.8254) kd_loss 0.0612 (0.0779) acc 75.0000 (80.0426) lr 1.9048e-03 eta 0:23:10
epoch [9/50] batch [240/245] time 0.136 (0.138) data 0.000 (0.001) loss 1.3667 (1.2379) teacher_loss 0.8697 (0.7326) loss_zs_kd 0.1327 (0.1085) loss_oracle 0.7872 (0.8244) kd_loss 0.0742 (0.0777) acc 75.0000 (80.1172) lr 1.9048e-03 eta 0:23:04
Evaluate on the *val* set
=> result
* total: 3,353
* correct: 3,033
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.6%
Evaluate on the *test* set
=> result
* total: 4,365
* correct: 3,196
* accuracy: 73.2%
* error: 26.8%
* macro_f1: 72.0%
******* Domain c best val acc:      90.5%, epoch: 7 *******
******* Domain c best val test acc: 72.9%, epoch: 7 *******
******* Domain c best test acc:     73.3%, epoch: 4 *******
epoch [10/50] batch [20/245] time 0.327 (0.177) data 0.000 (0.013) loss 1.1234 (1.2292) teacher_loss 0.6364 (0.7194) loss_zs_kd 0.1191 (0.1163) loss_oracle 0.7686 (0.8217) kd_loss 0.0863 (0.0816) acc 78.1250 (81.5625) lr 1.8763e-03 eta 0:29:31
epoch [10/50] batch [40/245] time 0.125 (0.158) data 0.000 (0.007) loss 0.7664 (1.2034) teacher_loss 0.2988 (0.7002) loss_zs_kd 0.0855 (0.1063) loss_oracle 0.7556 (0.8189) kd_loss 0.0942 (0.0812) acc 96.8750 (81.6406) lr 1.8763e-03 eta 0:26:21
epoch [10/50] batch [60/245] time 0.086 (0.153) data 0.000 (0.005) loss 1.3948 (1.1864) teacher_loss 0.9095 (0.6850) loss_zs_kd 0.1000 (0.1082) loss_oracle 0.8000 (0.8141) kd_loss 0.0708 (0.0804) acc 81.2500 (81.9792) lr 1.8763e-03 eta 0:25:24
epoch [10/50] batch [80/245] time 0.086 (0.144) data 0.000 (0.003) loss 1.1123 (1.1885) teacher_loss 0.5983 (0.6881) loss_zs_kd 0.1171 (0.1083) loss_oracle 0.8421 (0.8112) kd_loss 0.0689 (0.0814) acc 81.2500 (81.7188) lr 1.8763e-03 eta 0:23:52

Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------------
Dataset    SPG_OfficeHome
Source     ['clipart', 'product', 'real_world']
Target     ['art']
# classes  65
# train_x  9,222
# val      3,939
# test     2,427
---------  ------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/288] time 0.467 (0.533) data 0.000 (0.021) loss 1.1167 (1.2879) teacher_loss 1.1098 (1.2378) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0001 (-0.0001) kd_loss 0.0069 (0.0502) acc 68.7500 (68.2812) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3348) gate/usage_min 0.3315 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0918 (1.0484) teacher/usage_max 0.3352 (0.3499) teacher/usage_min 0.3316 (0.3194) teacher/usage_std 0.0015 (0.0131) nleep/row_max_mean 1156.2565 (1178.1177) nleep/row_max_std 63.8988 (98.0715) nleep/row_min_mean 1156.0933 (1177.5763) lr 1.0000e-05 eta 2:07:40
epoch [1/50] batch [40/288] time 0.496 (0.511) data 0.000 (0.010) loss 1.2686 (1.2999) teacher_loss 1.2147 (1.2591) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0000 (-0.0001) kd_loss 0.0539 (0.0409) acc 65.6250 (68.2031) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3313 (0.3314) gate/usage_std 0.0015 (0.0014) teacher/entropy 1.0448 (1.0577) teacher/usage_max 0.3585 (0.3494) teacher/usage_min 0.3094 (0.3203) teacher/usage_std 0.0201 (0.0125) nleep/row_max_mean 1207.3020 (1179.3626) nleep/row_max_std 115.5063 (92.0513) nleep/row_min_mean 1206.8174 (1178.9243) lr 1.0000e-05 eta 2:02:17
epoch [1/50] batch [60/288] time 0.442 (0.492) data 0.001 (0.007) loss 1.4307 (1.3009) teacher_loss 1.4284 (1.2659) loss_zs_kd 0.0001 (0.0000) loss_oracle -0.0000 (-0.0001) kd_loss 0.0023 (0.0350) acc 59.3750 (67.6042) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3315 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0964 (1.0636) teacher/usage_max 0.3389 (0.3482) teacher/usage_min 0.3269 (0.3210) teacher/usage_std 0.0050 (0.0116) nleep/row_max_mean 1165.7383 (1180.5173) nleep/row_max_std 43.8657 (88.6978) nleep/row_min_mean 1165.6168 (1180.1305) lr 1.0000e-05 eta 1:57:29
epoch [1/50] batch [80/288] time 0.080 (0.451) data 0.000 (0.005) loss 1.2751 (1.3014) teacher_loss 1.2566 (1.2699) loss_zs_kd 0.0002 (0.0000) loss_oracle 0.0001 (-0.0000) kd_loss 0.0183 (0.0315) acc 62.5000 (67.3828) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0804 (1.0671) teacher/usage_max 0.3417 (0.3478) teacher/usage_min 0.3242 (0.3207) teacher/usage_std 0.0072 (0.0116) nleep/row_max_mean 1173.1747 (1181.9226) nleep/row_max_std 39.7126 (85.0966) nleep/row_min_mean 1172.8936 (1181.5654) lr 1.0000e-05 eta 1:47:33
epoch [1/50] batch [100/288] time 0.482 (0.427) data 0.000 (0.004) loss 1.1180 (1.2709) teacher_loss 1.0901 (1.2421) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0002 (0.0000) kd_loss 0.0277 (0.0287) acc 62.5000 (68.0938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3348) gate/usage_min 0.3313 (0.3314) gate/usage_std 0.0015 (0.0014) teacher/entropy 1.0708 (1.0699) teacher/usage_max 0.3537 (0.3470) teacher/usage_min 0.3190 (0.3213) teacher/usage_std 0.0148 (0.0110) nleep/row_max_mean 1189.2476 (1182.6634) nleep/row_max_std 78.6352 (81.3684) nleep/row_min_mean 1188.9678 (1182.3316) lr 1.0000e-05 eta 1:41:45
epoch [1/50] batch [120/288] time 0.178 (0.398) data 0.000 (0.004) loss 1.0365 (1.2619) teacher_loss 1.0323 (1.2358) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0004 (0.0000) kd_loss 0.0039 (0.0260) acc 75.0000 (68.2031) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0947 (1.0726) teacher/usage_max 0.3358 (0.3464) teacher/usage_min 0.3301 (0.3219) teacher/usage_std 0.0024 (0.0105) nleep/row_max_mean 1177.5294 (1183.3774) nleep/row_max_std 30.4362 (77.2602) nleep/row_min_mean 1177.3967 (1183.0690) lr 1.0000e-05 eta 1:34:48
epoch [1/50] batch [140/288] time 0.446 (0.394) data 0.000 (0.003) loss 1.4889 (1.2454) teacher_loss 1.4840 (1.2219) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0005 (0.0001) kd_loss 0.0046 (0.0234) acc 56.2500 (68.3036) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3348) gate/usage_min 0.3313 (0.3314) gate/usage_std 0.0015 (0.0014) teacher/entropy 1.0941 (1.0752) teacher/usage_max 0.3390 (0.3461) teacher/usage_min 0.3258 (0.3224) teacher/usage_std 0.0056 (0.0102) nleep/row_max_mean 1200.1587 (1183.9142) nleep/row_max_std 66.2393 (73.1137) nleep/row_min_mean 1199.9946 (1183.6258) lr 1.0000e-05 eta 1:33:43
epoch [1/50] batch [160/288] time 0.494 (0.401) data 0.000 (0.003) loss 1.0590 (1.2410) teacher_loss 1.0564 (1.2193) loss_zs_kd 0.0007 (0.0001) loss_oracle 0.0003 (0.0001) kd_loss 0.0021 (0.0216) acc 71.8750 (68.6328) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3315 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0965 (1.0770) teacher/usage_max 0.3386 (0.3459) teacher/usage_min 0.3279 (0.3227) teacher/usage_std 0.0044 (0.0099) nleep/row_max_mean 1190.6964 (1184.8667) nleep/row_max_std 51.6011 (70.0783) nleep/row_min_mean 1190.5803 (1184.5924) lr 1.0000e-05 eta 1:35:14
epoch [1/50] batch [180/288] time 0.496 (0.410) data 0.000 (0.002) loss 0.9970 (1.2429) teacher_loss 0.9954 (1.2228) loss_zs_kd 0.0004 (0.0001) loss_oracle 0.0005 (0.0002) kd_loss 0.0012 (0.0200) acc 71.8750 (68.4549) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3348) gate/usage_min 0.3315 (0.3314) gate/usage_std 0.0013 (0.0014) teacher/entropy 1.0974 (1.0786) teacher/usage_max 0.3388 (0.3455) teacher/usage_min 0.3272 (0.3229) teacher/usage_std 0.0048 (0.0096) nleep/row_max_mean 1186.5303 (1185.2930) nleep/row_max_std 34.4179 (66.8251) nleep/row_min_mean 1186.4399 (1185.0314) lr 1.0000e-05 eta 1:37:07
epoch [1/50] batch [200/288] time 0.145 (0.417) data 0.000 (0.002) loss 1.3405 (1.2382) teacher_loss 1.3381 (1.2196) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0004 (0.0002) kd_loss 0.0022 (0.0184) acc 62.5000 (68.3438) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0965 (1.0802) teacher/usage_max 0.3359 (0.3450) teacher/usage_min 0.3291 (0.3233) teacher/usage_std 0.0030 (0.0093) nleep/row_max_mean 1200.3540 (1185.7504) nleep/row_max_std 44.2532 (63.8273) nleep/row_min_mean 1200.2390 (1185.5012) lr 1.0000e-05 eta 1:38:34
epoch [1/50] batch [220/288] time 0.489 (0.396) data 0.000 (0.002) loss 1.4174 (1.2324) teacher_loss 1.4143 (1.2152) loss_zs_kd 0.0004 (0.0001) loss_oracle 0.0006 (0.0002) kd_loss 0.0026 (0.0171) acc 65.6250 (68.6080) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3315 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0960 (1.0815) teacher/usage_max 0.3363 (0.3446) teacher/usage_min 0.3301 (0.3236) teacher/usage_std 0.0025 (0.0090) nleep/row_max_mean 1189.9635 (1186.0663) nleep/row_max_std 38.7558 (61.0763) nleep/row_min_mean 1189.8386 (1185.8284) lr 1.0000e-05 eta 1:33:39
epoch [1/50] batch [240/288] time 0.082 (0.386) data 0.000 (0.002) loss 0.9886 (1.2288) teacher_loss 0.9837 (1.2127) loss_zs_kd 0.0000 (0.0001) loss_oracle 0.0005 (0.0003) kd_loss 0.0046 (0.0160) acc 81.2500 (68.8672) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0940 (1.0827) teacher/usage_max 0.3395 (0.3442) teacher/usage_min 0.3261 (0.3239) teacher/usage_std 0.0055 (0.0087) nleep/row_max_mean 1195.1687 (1186.4125) nleep/row_max_std 35.0863 (58.4591) nleep/row_min_mean 1195.0177 (1186.1838) lr 1.0000e-05 eta 1:31:00
epoch [1/50] batch [260/288] time 0.462 (0.379) data 0.000 (0.002) loss 1.3016 (1.2333) teacher_loss 1.2965 (1.2181) loss_zs_kd 0.0000 (0.0002) loss_oracle 0.0009 (0.0003) kd_loss 0.0046 (0.0150) acc 71.8750 (68.7139) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0014) teacher/entropy 1.0940 (1.0836) teacher/usage_max 0.3449 (0.3439) teacher/usage_min 0.3241 (0.3241) teacher/usage_std 0.0087 (0.0085) nleep/row_max_mean 1193.5247 (1186.8911) nleep/row_max_std 31.3263 (56.2796) nleep/row_min_mean 1193.3823 (1186.6704) lr 1.0000e-05 eta 1:29:25
epoch [1/50] batch [280/288] time 0.496 (0.387) data 0.000 (0.002) loss 1.5221 (1.2323) teacher_loss 1.5168 (1.2179) loss_zs_kd 0.0020 (0.0002) loss_oracle 0.0008 (0.0003) kd_loss 0.0039 (0.0141) acc 65.6250 (68.7835) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3315 (0.3314) gate/usage_std 0.0013 (0.0014) teacher/entropy 1.0948 (1.0845) teacher/usage_max 0.3410 (0.3436) teacher/usage_min 0.3211 (0.3243) teacher/usage_std 0.0087 (0.0083) nleep/row_max_mean 1193.7395 (1187.3455) nleep/row_max_std 29.5313 (54.2361) nleep/row_min_mean 1193.5955 (1187.1320) lr 1.0000e-05 eta 1:30:58
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,269
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 82.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,965
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 76.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      83.0%, epoch: 1 *******
******* Domain a best val test acc: 81.0%, epoch: 1 *******
******* Domain a best test acc:     81.0%, epoch: 1 *******
epoch [2/50] batch [20/288] time 0.285 (0.497) data 0.000 (0.012) loss 1.0232 (1.1917) teacher_loss 1.0058 (1.1781) loss_zs_kd 0.0031 (0.0105) loss_oracle 0.0272 (0.0118) kd_loss 0.0023 (0.0025) acc 68.7500 (69.3750) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3347) gate/usage_min 0.3315 (0.3315) gate/usage_std 0.0013 (0.0014) teacher/entropy 1.0964 (1.0962) teacher/usage_max 0.3437 (0.3408) teacher/usage_min 0.3199 (0.3241) teacher/usage_std 0.0100 (0.0072) nleep/row_max_mean 1196.0383 (1195.4221) nleep/row_max_std 23.0410 (26.8994) nleep/row_min_mean 1195.9269 (1195.3086) lr 2.0000e-03 eta 1:56:45
epoch [2/50] batch [40/288] time 0.461 (0.363) data 0.000 (0.006) loss 0.7529 (1.1487) teacher_loss 0.7127 (1.1175) loss_zs_kd 0.0164 (0.0135) loss_oracle 0.0581 (0.0440) kd_loss 0.0029 (0.0024) acc 81.2500 (70.9375) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3344 (0.3346) gate/usage_min 0.3316 (0.3315) gate/usage_std 0.0013 (0.0013) teacher/entropy 1.0957 (1.0962) teacher/usage_max 0.3410 (0.3409) teacher/usage_min 0.3227 (0.3240) teacher/usage_std 0.0078 (0.0072) nleep/row_max_mean 1205.9998 (1196.0187) nleep/row_max_std 32.8611 (26.3518) nleep/row_min_mean 1205.8529 (1195.9009) lr 2.0000e-03 eta 1:25:12
epoch [2/50] batch [60/288] time 0.212 (0.322) data 0.001 (0.004) loss 1.5016 (1.1723) teacher_loss 1.4079 (1.1209) loss_zs_kd 0.0145 (0.0153) loss_oracle 0.1644 (0.0822) kd_loss 0.0043 (0.0027) acc 71.8750 (71.6146) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3341 (0.3345) gate/usage_min 0.3319 (0.3316) gate/usage_std 0.0010 (0.0013) teacher/entropy 1.0944 (1.0960) teacher/usage_max 0.3503 (0.3427) teacher/usage_min 0.3237 (0.3232) teacher/usage_std 0.0120 (0.0084) nleep/row_max_mean 1195.7070 (1195.7011) nleep/row_max_std 23.7907 (24.9553) nleep/row_min_mean 1195.5192 (1195.5711) lr 2.0000e-03 eta 1:15:29
epoch [2/50] batch [80/288] time 0.478 (0.346) data 0.000 (0.003) loss 0.9530 (1.1757) teacher_loss 0.8231 (1.1048) loss_zs_kd 0.0106 (0.0155) loss_oracle 0.2344 (0.1188) kd_loss 0.0074 (0.0038) acc 71.8750 (71.9141) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3336 (0.3344) gate/usage_min 0.3328 (0.3318) gate/usage_std 0.0004 (0.0011) teacher/entropy 1.0913 (1.0949) teacher/usage_max 0.3580 (0.3464) teacher/usage_min 0.3147 (0.3199) teacher/usage_std 0.0182 (0.0113) nleep/row_max_mean 1191.0134 (1196.0028) nleep/row_max_std 16.4077 (23.7981) nleep/row_min_mean 1190.7681 (1195.8463) lr 2.0000e-03 eta 1:20:53
epoch [2/50] batch [100/288] time 0.522 (0.374) data 0.000 (0.003) loss 1.5800 (1.1823) teacher_loss 1.4249 (1.0998) loss_zs_kd 0.0245 (0.0159) loss_oracle 0.2552 (0.1382) kd_loss 0.0152 (0.0055) acc 68.7500 (72.0938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3342 (0.3342) gate/usage_min 0.3325 (0.3320) gate/usage_std 0.0007 (0.0010) teacher/entropy 1.0832 (1.0932) teacher/usage_max 0.3611 (0.3493) teacher/usage_min 0.2891 (0.3148) teacher/usage_std 0.0316 (0.0148) nleep/row_max_mean 1197.3582 (1196.1847) nleep/row_max_std 13.9911 (22.8767) nleep/row_min_mean 1197.0155 (1195.9970) lr 2.0000e-03 eta 1:27:23
epoch [2/50] batch [120/288] time 0.464 (0.392) data 0.000 (0.002) loss 1.3110 (1.1951) teacher_loss 1.1372 (1.0925) loss_zs_kd 0.0029 (0.0164) loss_oracle 0.3058 (0.1725) kd_loss 0.0194 (0.0081) acc 71.8750 (72.1354) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3355 (0.3343) gate/usage_min 0.3319 (0.3321) gate/usage_std 0.0016 (0.0010) teacher/entropy 1.0787 (1.0905) teacher/usage_max 0.3710 (0.3527) teacher/usage_min 0.2766 (0.3081) teacher/usage_std 0.0409 (0.0193) nleep/row_max_mean 1194.6145 (1196.7299) nleep/row_max_std 17.1093 (22.5310) nleep/row_min_mean 1194.2075 (1196.5032) lr 2.0000e-03 eta 1:31:30
epoch [2/50] batch [140/288] time 0.548 (0.406) data 0.000 (0.002) loss 1.3166 (1.2048) teacher_loss 1.1666 (1.0957) loss_zs_kd 0.0230 (0.0166) loss_oracle 0.2056 (0.1798) kd_loss 0.0357 (0.0109) acc 75.0000 (72.1652) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3370 (0.3346) gate/usage_min 0.3308 (0.3320) gate/usage_std 0.0027 (0.0011) teacher/entropy 1.0617 (1.0876) teacher/usage_max 0.3902 (0.3564) teacher/usage_min 0.2382 (0.3012) teacher/usage_std 0.0677 (0.0241) nleep/row_max_mean 1200.6066 (1197.0275) nleep/row_max_std 19.9264 (22.0110) nleep/row_min_mean 1200.0024 (1196.7619) lr 2.0000e-03 eta 1:34:39
epoch [2/50] batch [160/288] time 0.195 (0.384) data 0.000 (0.002) loss 1.2188 (1.2093) teacher_loss 1.0981 (1.0968) loss_zs_kd 0.0517 (0.0168) loss_oracle 0.1175 (0.1800) kd_loss 0.0362 (0.0141) acc 71.8750 (71.9727) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3382 (0.3350) gate/usage_min 0.3299 (0.3318) gate/usage_std 0.0036 (0.0014) teacher/entropy 1.0606 (1.0842) teacher/usage_max 0.3983 (0.3613) teacher/usage_min 0.2366 (0.2943) teacher/usage_std 0.0697 (0.0291) nleep/row_max_mean 1196.4731 (1197.3363) nleep/row_max_std 14.2112 (21.4071) nleep/row_min_mean 1195.8608 (1197.0286) lr 2.0000e-03 eta 1:29:18
epoch [2/50] batch [180/288] time 0.481 (0.373) data 0.000 (0.002) loss 1.1611 (1.2058) teacher_loss 0.9949 (1.0908) loss_zs_kd 0.0132 (0.0167) loss_oracle 0.2098 (0.1781) kd_loss 0.0547 (0.0177) acc 78.1250 (72.0139) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3395 (0.3354) gate/usage_min 0.3286 (0.3315) gate/usage_std 0.0046 (0.0017) teacher/entropy 1.0407 (1.0804) teacher/usage_max 0.4249 (0.3667) teacher/usage_min 0.2193 (0.2878) teacher/usage_std 0.0855 (0.0339) nleep/row_max_mean 1194.9454 (1197.5712) nleep/row_max_std 11.8572 (20.9440) nleep/row_min_mean 1194.1758 (1197.2205) lr 2.0000e-03 eta 1:26:42
epoch [2/50] batch [200/288] time 0.443 (0.375) data 0.000 (0.001) loss 1.9061 (1.2091) teacher_loss 1.7442 (1.0916) loss_zs_kd 0.0277 (0.0174) loss_oracle 0.1683 (0.1752) kd_loss 0.0639 (0.0213) acc 56.2500 (71.7500) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3410 (0.3359) gate/usage_min 0.3271 (0.3311) gate/usage_std 0.0058 (0.0020) teacher/entropy 1.0299 (1.0765) teacher/usage_max 0.4496 (0.3731) teacher/usage_min 0.2131 (0.2815) teacher/usage_std 0.0966 (0.0390) nleep/row_max_mean 1195.3364 (1197.8168) nleep/row_max_std 14.0906 (20.4243) nleep/row_min_mean 1194.4823 (1197.4235) lr 2.0000e-03 eta 1:27:01
epoch [2/50] batch [220/288] time 0.518 (0.385) data 0.000 (0.001) loss 1.3888 (1.2033) teacher_loss 1.1741 (1.0806) loss_zs_kd 0.0101 (0.0173) loss_oracle 0.2659 (0.1779) kd_loss 0.0767 (0.0251) acc 71.8750 (71.8608) gate/entropy 1.0984 (1.0986) gate/usage_max 0.3419 (0.3364) gate/usage_min 0.3256 (0.3307) gate/usage_std 0.0067 (0.0024) teacher/entropy 1.0162 (1.0723) teacher/usage_max 0.4415 (0.3791) teacher/usage_min 0.1923 (0.2753) teacher/usage_std 0.1044 (0.0440) nleep/row_max_mean 1202.7336 (1198.0413) nleep/row_max_std 15.2301 (20.0486) nleep/row_min_mean 1201.7448 (1197.6059) lr 2.0000e-03 eta 1:29:07
epoch [2/50] batch [240/288] time 0.541 (0.393) data 0.000 (0.001) loss 1.5183 (1.2053) teacher_loss 1.2947 (1.0750) loss_zs_kd 0.0242 (0.0174) loss_oracle 0.2404 (0.1834) kd_loss 0.0913 (0.0298) acc 65.6250 (72.0443) gate/entropy 1.0983 (1.0986) gate/usage_max 0.3430 (0.3369) gate/usage_min 0.3235 (0.3302) gate/usage_std 0.0079 (0.0028) teacher/entropy 0.9995 (1.0671) teacher/usage_max 0.4566 (0.3852) teacher/usage_min 0.1818 (0.2685) teacher/usage_std 0.1139 (0.0493) nleep/row_max_mean 1200.8235 (1198.3264) nleep/row_max_std 18.6300 (19.6827) nleep/row_min_mean 1199.7169 (1197.8434) lr 2.0000e-03 eta 1:30:56
epoch [2/50] batch [260/288] time 0.519 (0.400) data 0.000 (0.001) loss 1.1698 (1.2056) teacher_loss 0.9669 (1.0691) loss_zs_kd 0.0372 (0.0177) loss_oracle 0.2073 (0.1858) kd_loss 0.0806 (0.0347) acc 81.2500 (72.0793) gate/entropy 1.0982 (1.0985) gate/usage_max 0.3443 (0.3374) gate/usage_min 0.3217 (0.3296) gate/usage_std 0.0092 (0.0033) teacher/entropy 1.0092 (1.0617) teacher/usage_max 0.4582 (0.3908) teacher/usage_min 0.1906 (0.2617) teacher/usage_std 0.1100 (0.0544) nleep/row_max_mean 1203.4934 (1198.5053) nleep/row_max_std 16.6011 (19.4814) nleep/row_min_mean 1202.4647 (1197.9740) lr 2.0000e-03 eta 1:32:21
epoch [2/50] batch [280/288] time 0.421 (0.387) data 0.000 (0.001) loss 1.0641 (1.2092) teacher_loss 0.8190 (1.0647) loss_zs_kd 0.0186 (0.0179) loss_oracle 0.2442 (0.1912) kd_loss 0.1138 (0.0399) acc 71.8750 (72.1429) gate/entropy 1.0981 (1.0985) gate/usage_max 0.3456 (0.3380) gate/usage_min 0.3197 (0.3289) gate/usage_std 0.0106 (0.0038) teacher/entropy 0.9728 (1.0559) teacher/usage_max 0.4721 (0.3957) teacher/usage_min 0.1559 (0.2547) teacher/usage_std 0.1320 (0.0595) nleep/row_max_mean 1199.7620 (1198.7219) nleep/row_max_std 17.4632 (19.2689) nleep/row_min_mean 1198.4575 (1198.1405) lr 2.0000e-03 eta 1:29:10
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,403
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,023
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 79.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain a best val acc:      86.4%, epoch: 2 *******
******* Domain a best val test acc: 83.4%, epoch: 2 *******
******* Domain a best test acc:     83.4%, epoch: 2 *******
epoch [3/50] batch [20/288] time 0.492 (0.507) data 0.000 (0.011) loss 1.7551 (1.3200) teacher_loss 1.4428 (1.0346) loss_zs_kd 0.0405 (0.0229) loss_oracle 0.3010 (0.2973) kd_loss 0.1415 (0.1253) acc 56.2500 (72.8125) gate/entropy 1.0979 (1.0979) gate/usage_max 0.3475 (0.3469) gate/usage_min 0.3163 (0.3175) gate/usage_std 0.0129 (0.0121) teacher/entropy 0.9405 (0.9596) teacher/usage_max 0.5003 (0.4597) teacher/usage_min 0.1409 (0.1491) teacher/usage_std 0.1478 (0.1339) nleep/row_max_mean 1201.7224 (1201.7828) nleep/row_max_std 18.6563 (15.5747) nleep/row_min_mean 1200.2153 (1200.3965) lr 1.9980e-03 eta 1:56:33
epoch [3/50] batch [40/288] time 0.413 (0.495) data 0.000 (0.006) loss 1.0726 (1.2556) teacher_loss 0.8256 (0.9715) loss_zs_kd 0.0099 (0.0194) loss_oracle 0.2188 (0.2854) kd_loss 0.1327 (0.1317) acc 78.1250 (74.2188) gate/entropy 1.0977 (1.0979) gate/usage_max 0.3486 (0.3475) gate/usage_min 0.3137 (0.3162) gate/usage_std 0.0146 (0.0129) teacher/entropy 0.9479 (0.9519) teacher/usage_max 0.4673 (0.4593) teacher/usage_min 0.1343 (0.1430) teacher/usage_std 0.1435 (0.1376) nleep/row_max_mean 1202.2271 (1201.8956) nleep/row_max_std 18.1450 (15.1943) nleep/row_min_mean 1200.7328 (1200.4494) lr 1.9980e-03 eta 1:53:39
epoch [3/50] batch [60/288] time 0.464 (0.484) data 0.000 (0.004) loss 1.2620 (1.3177) teacher_loss 0.9645 (1.0242) loss_zs_kd 0.0120 (0.0192) loss_oracle 0.3461 (0.2952) kd_loss 0.1184 (0.1363) acc 75.0000 (73.0729) gate/entropy 1.0974 (1.0977) gate/usage_max 0.3497 (0.3480) gate/usage_min 0.3110 (0.3149) gate/usage_std 0.0164 (0.0138) teacher/entropy 0.9605 (0.9459) teacher/usage_max 0.4502 (0.4589) teacher/usage_min 0.1335 (0.1388) teacher/usage_std 0.1420 (0.1402) nleep/row_max_mean 1208.0967 (1202.0824) nleep/row_max_std 15.9382 (15.4234) nleep/row_min_mean 1206.6528 (1200.5876) lr 1.9980e-03 eta 1:51:03
epoch [3/50] batch [80/288] time 0.211 (0.419) data 0.000 (0.003) loss 1.3461 (1.3333) teacher_loss 0.9588 (1.0209) loss_zs_kd 0.0167 (0.0194) loss_oracle 0.3924 (0.3186) kd_loss 0.1827 (0.1434) acc 75.0000 (73.0859) gate/entropy 1.0971 (1.0976) gate/usage_max 0.3500 (0.3485) gate/usage_min 0.3082 (0.3136) gate/usage_std 0.0181 (0.0146) teacher/entropy 0.8908 (0.9374) teacher/usage_max 0.4694 (0.4583) teacher/usage_min 0.0991 (0.1335) teacher/usage_std 0.1663 (0.1434) nleep/row_max_mean 1201.3278 (1202.0346) nleep/row_max_std 12.0512 (15.3590) nleep/row_min_mean 1199.4089 (1200.4747) lr 1.9980e-03 eta 1:35:53
epoch [3/50] batch [100/288] time 0.080 (0.403) data 0.000 (0.002) loss 1.2575 (1.3488) teacher_loss 0.9239 (1.0282) loss_zs_kd 0.0118 (0.0195) loss_oracle 0.2897 (0.3217) kd_loss 0.1829 (0.1500) acc 75.0000 (73.1562) gate/entropy 1.0968 (1.0975) gate/usage_max 0.3501 (0.3488) gate/usage_min 0.3054 (0.3122) gate/usage_std 0.0199 (0.0155) teacher/entropy 0.8898 (0.9295) teacher/usage_max 0.4617 (0.4604) teacher/usage_min 0.1150 (0.1294) teacher/usage_std 0.1552 (0.1464) nleep/row_max_mean 1204.3967 (1202.1893) nleep/row_max_std 15.5849 (15.1797) nleep/row_min_mean 1202.4602 (1200.5745) lr 1.9980e-03 eta 1:32:11
epoch [3/50] batch [120/288] time 0.464 (0.381) data 0.000 (0.002) loss 0.9809 (1.3380) teacher_loss 0.6787 (1.0186) loss_zs_kd 0.0212 (0.0201) loss_oracle 0.2590 (0.3120) kd_loss 0.1621 (0.1534) acc 81.2500 (73.2812) gate/entropy 1.0965 (1.0973) gate/usage_max 0.3505 (0.3491) gate/usage_min 0.3029 (0.3109) gate/usage_std 0.0216 (0.0164) teacher/entropy 0.9088 (0.9248) teacher/usage_max 0.4789 (0.4629) teacher/usage_min 0.1170 (0.1269) teacher/usage_std 0.1560 (0.1483) nleep/row_max_mean 1202.1306 (1202.3238) nleep/row_max_std 11.6825 (14.9559) nleep/row_min_mean 1200.4080 (1200.6780) lr 1.9980e-03 eta 1:27:02
epoch [3/50] batch [140/288] time 0.479 (0.397) data 0.000 (0.002) loss 1.3751 (1.3357) teacher_loss 1.0341 (1.0154) loss_zs_kd 0.0061 (0.0201) loss_oracle 0.3300 (0.3055) kd_loss 0.1729 (0.1575) acc 75.0000 (73.1696) gate/entropy 1.0961 (1.0972) gate/usage_max 0.3510 (0.3493) gate/usage_min 0.3002 (0.3095) gate/usage_std 0.0234 (0.0173) teacher/entropy 0.8959 (0.9193) teacher/usage_max 0.4554 (0.4649) teacher/usage_min 0.1217 (0.1247) teacher/usage_std 0.1502 (0.1500) nleep/row_max_mean 1207.6111 (1202.5000) nleep/row_max_std 12.4835 (14.8366) nleep/row_min_mean 1205.8298 (1200.8199) lr 1.9980e-03 eta 1:30:27
epoch [3/50] batch [160/288] time 0.496 (0.409) data 0.000 (0.002) loss 1.8509 (1.3445) teacher_loss 1.5253 (1.0192) loss_zs_kd 0.0342 (0.0207) loss_oracle 0.2858 (0.3074) kd_loss 0.1657 (0.1614) acc 62.5000 (72.9883) gate/entropy 1.0957 (1.0970) gate/usage_max 0.3517 (0.3495) gate/usage_min 0.2975 (0.3082) gate/usage_std 0.0254 (0.0182) teacher/entropy 0.8980 (0.9139) teacher/usage_max 0.4798 (0.4694) teacher/usage_min 0.1053 (0.1224) teacher/usage_std 0.1634 (0.1522) nleep/row_max_mean 1198.7242 (1202.4905) nleep/row_max_std 13.4184 (14.6804) nleep/row_min_mean 1196.8547 (1200.7765) lr 1.9980e-03 eta 1:33:10
epoch [3/50] batch [180/288] time 0.516 (0.419) data 0.000 (0.001) loss 1.5006 (1.3488) teacher_loss 1.0580 (1.0164) loss_zs_kd 0.0286 (0.0207) loss_oracle 0.3859 (0.3118) kd_loss 0.2354 (0.1661) acc 71.8750 (73.1250) gate/entropy 1.0952 (1.0969) gate/usage_max 0.3546 (0.3499) gate/usage_min 0.2950 (0.3068) gate/usage_std 0.0271 (0.0191) teacher/entropy 0.8227 (0.9076) teacher/usage_max 0.5312 (0.4744) teacher/usage_min 0.0903 (0.1197) teacher/usage_std 0.1828 (0.1547) nleep/row_max_mean 1198.0146 (1202.5894) nleep/row_max_std 13.4070 (14.4289) nleep/row_min_mean 1195.7483 (1200.8332) lr 1.9980e-03 eta 1:35:22
epoch [3/50] batch [200/288] time 0.411 (0.403) data 0.000 (0.001) loss 1.3912 (1.3506) teacher_loss 0.9996 (1.0119) loss_zs_kd 0.0121 (0.0211) loss_oracle 0.3658 (0.3158) kd_loss 0.2026 (0.1703) acc 81.2500 (73.2812) gate/entropy 1.0947 (1.0967) gate/usage_max 0.3578 (0.3506) gate/usage_min 0.2924 (0.3055) gate/usage_std 0.0291 (0.0200) teacher/entropy 0.8526 (0.9019) teacher/usage_max 0.5299 (0.4798) teacher/usage_min 0.0941 (0.1178) teacher/usage_std 0.1805 (0.1570) nleep/row_max_mean 1199.9460 (1202.7883) nleep/row_max_std 12.3335 (14.3314) nleep/row_min_mean 1197.7654 (1201.0003) lr 1.9980e-03 eta 1:31:36
epoch [3/50] batch [220/288] time 0.080 (0.398) data 0.000 (0.001) loss 1.2455 (1.3675) teacher_loss 0.7907 (1.0220) loss_zs_kd 0.0042 (0.0214) loss_oracle 0.3684 (0.3185) kd_loss 0.2685 (0.1756) acc 75.0000 (73.0824) gate/entropy 1.0941 (1.0965) gate/usage_max 0.3612 (0.3514) gate/usage_min 0.2898 (0.3042) gate/usage_std 0.0312 (0.0209) teacher/entropy 0.7773 (0.8948) teacher/usage_max 0.5823 (0.4860) teacher/usage_min 0.0698 (0.1155) teacher/usage_std 0.2095 (0.1598) nleep/row_max_mean 1206.0059 (1202.8609) nleep/row_max_std 14.5588 (14.2513) nleep/row_min_mean 1203.5657 (1201.0333) lr 1.9980e-03 eta 1:30:19
epoch [3/50] batch [240/288] time 0.460 (0.386) data 0.000 (0.001) loss 1.7554 (1.3777) teacher_loss 1.3731 (1.0266) loss_zs_kd 0.0199 (0.0213) loss_oracle 0.2781 (0.3202) kd_loss 0.2333 (0.1803) acc 62.5000 (73.0078) gate/entropy 1.0935 (1.0962) gate/usage_max 0.3646 (0.3524) gate/usage_min 0.2871 (0.3029) gate/usage_std 0.0334 (0.0219) teacher/entropy 0.8150 (0.8881) teacher/usage_max 0.4897 (0.4920) teacher/usage_min 0.0841 (0.1130) teacher/usage_std 0.1781 (0.1628) nleep/row_max_mean 1203.7197 (1202.9528) nleep/row_max_std 14.2120 (14.2931) nleep/row_min_mean 1201.4277 (1201.0819) lr 1.9980e-03 eta 1:27:23
epoch [3/50] batch [260/288] time 0.528 (0.396) data 0.000 (0.001) loss 0.9938 (1.3764) teacher_loss 0.6069 (1.0211) loss_zs_kd 0.0306 (0.0213) loss_oracle 0.3264 (0.3198) kd_loss 0.2085 (0.1847) acc 87.5000 (73.1611) gate/entropy 1.0928 (1.0960) gate/usage_max 0.3679 (0.3534) gate/usage_min 0.2846 (0.3016) gate/usage_std 0.0354 (0.0228) teacher/entropy 0.8378 (0.8817) teacher/usage_max 0.5754 (0.4972) teacher/usage_min 0.1104 (0.1105) teacher/usage_std 0.1903 (0.1655) nleep/row_max_mean 1204.5811 (1203.0323) nleep/row_max_std 14.7806 (14.2588) nleep/row_min_mean 1202.4125 (1201.1179) lr 1.9980e-03 eta 1:29:25
epoch [3/50] batch [280/288] time 0.488 (0.403) data 0.000 (0.001) loss 1.4762 (1.3756) teacher_loss 1.0137 (1.0161) loss_zs_kd 0.0492 (0.0218) loss_oracle 0.3341 (0.3193) kd_loss 0.2708 (0.1889) acc 68.7500 (73.3147) gate/entropy 1.0921 (1.0957) gate/usage_max 0.3714 (0.3546) gate/usage_min 0.2820 (0.3002) gate/usage_std 0.0377 (0.0238) teacher/entropy 0.7602 (0.8755) teacher/usage_max 0.6282 (0.5022) teacher/usage_min 0.0728 (0.1081) teacher/usage_std 0.2280 (0.1681) nleep/row_max_mean 1205.9337 (1203.1406) nleep/row_max_std 14.9010 (14.2158) nleep/row_min_mean 1203.2043 (1201.1864) lr 1.9980e-03 eta 1:30:53
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,413
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 86.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.6%
******* Domain a best val acc:      86.6%, epoch: 3 *******
******* Domain a best val test acc: 83.1%, epoch: 3 *******
******* Domain a best test acc:     83.4%, epoch: 2 *******
epoch [4/50] batch [20/288] time 0.445 (0.277) data 0.000 (0.013) loss 1.1530 (1.3750) teacher_loss 0.7300 (0.9311) loss_zs_kd 0.0326 (0.0212) loss_oracle 0.3634 (0.4005) kd_loss 0.2250 (0.2330) acc 84.3750 (73.9062) gate/entropy 1.0910 (1.0913) gate/usage_max 0.3764 (0.3746) gate/usage_min 0.2785 (0.2797) gate/usage_std 0.0408 (0.0398) teacher/entropy 0.8095 (0.8018) teacher/usage_max 0.5822 (0.5616) teacher/usage_min 0.0993 (0.0842) teacher/usage_std 0.1974 (0.1969) nleep/row_max_mean 1202.6648 (1203.0430) nleep/row_max_std 14.7308 (13.7278) nleep/row_min_mean 1200.3184 (1200.6439) lr 1.9921e-03 eta 1:02:27
epoch [4/50] batch [40/288] time 0.524 (0.285) data 0.000 (0.007) loss 1.4197 (1.3755) teacher_loss 1.0736 (0.9601) loss_zs_kd 0.0433 (0.0216) loss_oracle 0.2422 (0.3585) kd_loss 0.2033 (0.2253) acc 75.0000 (74.3750) gate/entropy 1.0901 (1.0909) gate/usage_max 0.3798 (0.3765) gate/usage_min 0.2760 (0.2784) gate/usage_std 0.0431 (0.0409) teacher/entropy 0.8325 (0.8093) teacher/usage_max 0.5459 (0.5528) teacher/usage_min 0.1043 (0.0874) teacher/usage_std 0.1807 (0.1921) nleep/row_max_mean 1204.4648 (1202.8396) nleep/row_max_std 14.1534 (13.4052) nleep/row_min_mean 1202.2810 (1200.4866) lr 1.9921e-03 eta 1:04:01
epoch [4/50] batch [60/288] time 0.471 (0.319) data 0.000 (0.005) loss 1.5069 (1.3672) teacher_loss 1.1350 (0.9569) loss_zs_kd 0.0286 (0.0228) loss_oracle 0.2564 (0.3418) kd_loss 0.2294 (0.2280) acc 65.6250 (74.6875) gate/entropy 1.0893 (1.0905) gate/usage_max 0.3829 (0.3781) gate/usage_min 0.2736 (0.2772) gate/usage_std 0.0452 (0.0419) teacher/entropy 0.8028 (0.8051) teacher/usage_max 0.4991 (0.5522) teacher/usage_min 0.0783 (0.0872) teacher/usage_std 0.1830 (0.1920) nleep/row_max_mean 1205.9966 (1203.2265) nleep/row_max_std 17.3148 (13.8124) nleep/row_min_mean 1203.5043 (1200.8523) lr 1.9921e-03 eta 1:11:43
epoch [4/50] batch [80/288] time 0.496 (0.359) data 0.000 (0.003) loss 1.8062 (1.3862) teacher_loss 1.4340 (0.9739) loss_zs_kd 0.0163 (0.0225) loss_oracle 0.3044 (0.3420) kd_loss 0.2119 (0.2300) acc 65.6250 (74.6484) gate/entropy 1.0883 (1.0901) gate/usage_max 0.3862 (0.3796) gate/usage_min 0.2713 (0.2761) gate/usage_std 0.0473 (0.0430) teacher/entropy 0.8112 (0.8014) teacher/usage_max 0.5681 (0.5542) teacher/usage_min 0.0847 (0.0873) teacher/usage_std 0.1976 (0.1926) nleep/row_max_mean 1199.7654 (1203.4087) nleep/row_max_std 14.3593 (13.7654) nleep/row_min_mean 1197.4623 (1201.0146) lr 1.9921e-03 eta 1:20:32
epoch [4/50] batch [100/288] time 0.499 (0.383) data 0.000 (0.003) loss 1.2757 (1.3941) teacher_loss 0.8474 (0.9889) loss_zs_kd 0.0111 (0.0222) loss_oracle 0.3147 (0.3311) kd_loss 0.2654 (0.2285) acc 84.3750 (74.3750) gate/entropy 1.0875 (1.0897) gate/usage_max 0.3890 (0.3812) gate/usage_min 0.2694 (0.2749) gate/usage_std 0.0492 (0.0441) teacher/entropy 0.7433 (0.8015) teacher/usage_max 0.6242 (0.5557) teacher/usage_min 0.0659 (0.0887) teacher/usage_std 0.2285 (0.1926) nleep/row_max_mean 1202.9299 (1203.2952) nleep/row_max_std 10.9671 (13.7018) nleep/row_min_mean 1200.2190 (1200.9137) lr 1.9921e-03 eta 1:25:47
epoch [4/50] batch [120/288] time 0.495 (0.400) data 0.000 (0.002) loss 1.2212 (1.3940) teacher_loss 0.8858 (0.9968) loss_zs_kd 0.0217 (0.0222) loss_oracle 0.2174 (0.3170) kd_loss 0.2159 (0.2276) acc 81.2500 (74.2708) gate/entropy 1.0867 (1.0892) gate/usage_max 0.3919 (0.3828) gate/usage_min 0.2674 (0.2738) gate/usage_std 0.0511 (0.0451) teacher/entropy 0.8048 (0.8014) teacher/usage_max 0.5554 (0.5539) teacher/usage_min 0.0889 (0.0893) teacher/usage_std 0.1911 (0.1917) nleep/row_max_mean 1207.4697 (1203.4083) nleep/row_max_std 13.0960 (13.7119) nleep/row_min_mean 1205.2314 (1201.0301) lr 1.9921e-03 eta 1:29:25
epoch [4/50] batch [140/288] time 0.437 (0.374) data 0.000 (0.002) loss 1.1907 (1.3918) teacher_loss 0.7522 (1.0011) loss_zs_kd 0.0222 (0.0217) loss_oracle 0.3351 (0.3062) kd_loss 0.2599 (0.2268) acc 81.2500 (73.9062) gate/entropy 1.0860 (1.0888) gate/usage_max 0.3939 (0.3843) gate/usage_min 0.2659 (0.2728) gate/usage_std 0.0525 (0.0461) teacher/entropy 0.7543 (0.8015) teacher/usage_max 0.5708 (0.5501) teacher/usage_min 0.0797 (0.0898) teacher/usage_std 0.2008 (0.1903) nleep/row_max_mean 1201.8638 (1203.6072) nleep/row_max_std 13.3480 (13.7526) nleep/row_min_mean 1199.2061 (1201.2269) lr 1.9921e-03 eta 1:23:28
epoch [4/50] batch [160/288] time 0.478 (0.365) data 0.000 (0.002) loss 1.5787 (1.3840) teacher_loss 1.1362 (0.9940) loss_zs_kd 0.0239 (0.0222) loss_oracle 0.3571 (0.3056) kd_loss 0.2520 (0.2261) acc 71.8750 (74.0234) gate/entropy 1.0852 (1.0884) gate/usage_max 0.3958 (0.3856) gate/usage_min 0.2639 (0.2718) gate/usage_std 0.0541 (0.0470) teacher/entropy 0.7697 (0.8013) teacher/usage_max 0.5246 (0.5493) teacher/usage_min 0.0914 (0.0906) teacher/usage_std 0.1805 (0.1897) nleep/row_max_mean 1201.3702 (1203.6899) nleep/row_max_std 14.6861 (13.7429) nleep/row_min_mean 1198.8638 (1201.3107) lr 1.9921e-03 eta 1:21:23
epoch [4/50] batch [180/288] time 0.478 (0.370) data 0.000 (0.002) loss 1.7009 (1.3792) teacher_loss 1.3278 (0.9900) loss_zs_kd 0.0267 (0.0222) loss_oracle 0.3098 (0.3041) kd_loss 0.2049 (0.2261) acc 56.2500 (74.0278) gate/entropy 1.0845 (1.0880) gate/usage_max 0.3978 (0.3869) gate/usage_min 0.2624 (0.2708) gate/usage_std 0.0555 (0.0478) teacher/entropy 0.8264 (0.8005) teacher/usage_max 0.4940 (0.5500) teacher/usage_min 0.1156 (0.0920) teacher/usage_std 0.1597 (0.1895) nleep/row_max_mean 1203.8062 (1203.7622) nleep/row_max_std 15.3008 (13.7677) nleep/row_min_mean 1201.6932 (1201.3902) lr 1.9921e-03 eta 1:22:26
epoch [4/50] batch [200/288] time 0.442 (0.381) data 0.000 (0.002) loss 1.3430 (1.3743) teacher_loss 1.0496 (0.9873) loss_zs_kd 0.0091 (0.0224) loss_oracle 0.2283 (0.3026) kd_loss 0.1747 (0.2245) acc 71.8750 (74.1562) gate/entropy 1.0837 (1.0876) gate/usage_max 0.4002 (0.3881) gate/usage_min 0.2606 (0.2699) gate/usage_std 0.0572 (0.0487) teacher/entropy 0.8544 (0.8019) teacher/usage_max 0.5093 (0.5489) teacher/usage_min 0.1224 (0.0951) teacher/usage_std 0.1598 (0.1877) nleep/row_max_mean 1207.5250 (1203.7373) nleep/row_max_std 12.4336 (13.7538) nleep/row_min_mean 1205.4333 (1201.3847) lr 1.9921e-03 eta 1:24:34
epoch [4/50] batch [220/288] time 0.496 (0.390) data 0.000 (0.001) loss 1.4539 (1.3706) teacher_loss 1.1706 (0.9874) loss_zs_kd 0.0212 (0.0227) loss_oracle 0.2136 (0.2981) kd_loss 0.1659 (0.2228) acc 68.7500 (74.0199) gate/entropy 1.0830 (1.0872) gate/usage_max 0.4021 (0.3893) gate/usage_min 0.2593 (0.2690) gate/usage_std 0.0584 (0.0495) teacher/entropy 0.8809 (0.8036) teacher/usage_max 0.4645 (0.5476) teacher/usage_min 0.1651 (0.0984) teacher/usage_std 0.1250 (0.1857) nleep/row_max_mean 1202.6743 (1203.7323) nleep/row_max_std 14.6118 (13.7117) nleep/row_min_mean 1200.9648 (1201.4020) lr 1.9921e-03 eta 1:26:29
epoch [4/50] batch [240/288] time 0.494 (0.398) data 0.000 (0.001) loss 1.6055 (1.3664) teacher_loss 1.2002 (0.9847) loss_zs_kd 0.0162 (0.0225) loss_oracle 0.3592 (0.2993) kd_loss 0.2176 (0.2208) acc 68.7500 (74.1146) gate/entropy 1.0821 (1.0868) gate/usage_max 0.4047 (0.3904) gate/usage_min 0.2578 (0.2681) gate/usage_std 0.0600 (0.0503) teacher/entropy 0.8190 (0.8060) teacher/usage_max 0.5232 (0.5455) teacher/usage_min 0.1695 (0.1024) teacher/usage_std 0.1455 (0.1832) nleep/row_max_mean 1205.1726 (1203.7064) nleep/row_max_std 13.7319 (13.6078) nleep/row_min_mean 1203.1772 (1201.4010) lr 1.9921e-03 eta 1:28:13
epoch [4/50] batch [260/288] time 0.448 (0.381) data 0.000 (0.001) loss 1.1618 (1.3719) teacher_loss 0.7620 (0.9887) loss_zs_kd 0.0224 (0.0227) loss_oracle 0.3671 (0.3052) kd_loss 0.2050 (0.2193) acc 75.0000 (73.9663) gate/entropy 1.0812 (1.0864) gate/usage_max 0.4071 (0.3916) gate/usage_min 0.2560 (0.2672) gate/usage_std 0.0617 (0.0511) teacher/entropy 0.8170 (0.8080) teacher/usage_max 0.5238 (0.5430) teacher/usage_min 0.1218 (0.1063) teacher/usage_std 0.1648 (0.1806) nleep/row_max_mean 1205.7800 (1203.6750) nleep/row_max_std 10.3943 (13.5677) nleep/row_min_mean 1203.6895 (1201.3930) lr 1.9921e-03 eta 1:24:19
epoch [4/50] batch [280/288] time 0.078 (0.376) data 0.000 (0.001) loss 1.1098 (1.3666) teacher_loss 0.7163 (0.9827) loss_zs_kd 0.0190 (0.0229) loss_oracle 0.3371 (0.3091) kd_loss 0.2154 (0.2179) acc 81.2500 (74.2634) gate/entropy 1.0804 (1.0860) gate/usage_max 0.4098 (0.3928) gate/usage_min 0.2548 (0.2664) gate/usage_std 0.0633 (0.0520) teacher/entropy 0.8138 (0.8094) teacher/usage_max 0.5041 (0.5430) teacher/usage_min 0.1377 (0.1099) teacher/usage_std 0.1506 (0.1792) nleep/row_max_mean 1201.9009 (1203.5576) nleep/row_max_std 13.0083 (13.5211) nleep/row_min_mean 1199.9396 (1201.2964) lr 1.9921e-03 eta 1:22:58
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,422
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,018
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 79.7%
******* Domain a best val acc:      86.9%, epoch: 4 *******
******* Domain a best val test acc: 83.1%, epoch: 4 *******
******* Domain a best test acc:     83.4%, epoch: 2 *******
epoch [5/50] batch [20/288] time 0.496 (0.493) data 0.000 (0.011) loss 1.6912 (1.4690) teacher_loss 1.3225 (1.0974) loss_zs_kd 0.0260 (0.0288) loss_oracle 0.3021 (0.3120) kd_loss 0.2047 (0.2012) acc 71.8750 (71.5625) gate/entropy 1.0792 (1.0795) gate/usage_max 0.4131 (0.4122) gate/usage_min 0.2531 (0.2535) gate/usage_std 0.0653 (0.0648) teacher/entropy 0.8390 (0.8318) teacher/usage_max 0.5106 (0.5225) teacher/usage_min 0.2004 (0.1695) teacher/usage_std 0.1305 (0.1467) nleep/row_max_mean 1199.1497 (1202.4472) nleep/row_max_std 13.7560 (12.7155) nleep/row_min_mean 1197.4473 (1200.4612) lr 1.9823e-03 eta 1:48:37
epoch [5/50] batch [40/288] time 0.466 (0.485) data 0.000 (0.006) loss 0.8403 (1.3657) teacher_loss 0.4673 (1.0004) loss_zs_kd 0.0382 (0.0285) loss_oracle 0.2952 (0.3093) kd_loss 0.2063 (0.1964) acc 90.6250 (73.2812) gate/entropy 1.0786 (1.0792) gate/usage_max 0.4146 (0.4131) gate/usage_min 0.2521 (0.2530) gate/usage_std 0.0663 (0.0653) teacher/entropy 0.8120 (0.8435) teacher/usage_max 0.5945 (0.5131) teacher/usage_min 0.1776 (0.1891) teacher/usage_std 0.1858 (0.1364) nleep/row_max_mean 1207.0939 (1202.7673) nleep/row_max_std 11.6132 (12.1515) nleep/row_min_mean 1205.0090 (1200.8392) lr 1.9823e-03 eta 1:46:46
epoch [5/50] batch [60/288] time 0.081 (0.459) data 0.000 (0.004) loss 1.4830 (1.3323) teacher_loss 1.1235 (0.9654) loss_zs_kd 0.0107 (0.0269) loss_oracle 0.3049 (0.3116) kd_loss 0.2016 (0.1976) acc 68.7500 (74.4792) gate/entropy 1.0781 (1.0789) gate/usage_max 0.4162 (0.4139) gate/usage_min 0.2515 (0.2526) gate/usage_std 0.0672 (0.0659) teacher/entropy 0.8619 (0.8445) teacher/usage_max 0.4686 (0.5115) teacher/usage_min 0.2432 (0.1965) teacher/usage_std 0.0974 (0.1340) nleep/row_max_mean 1203.6005 (1202.8648) nleep/row_max_std 9.2996 (11.6989) nleep/row_min_mean 1201.7705 (1200.9461) lr 1.9823e-03 eta 1:40:54
epoch [5/50] batch [80/288] time 0.401 (0.422) data 0.000 (0.003) loss 1.7772 (1.3252) teacher_loss 1.4222 (0.9504) loss_zs_kd 0.0244 (0.0271) loss_oracle 0.3649 (0.3284) kd_loss 0.1603 (0.1970) acc 71.8750 (74.9219) gate/entropy 1.0774 (1.0786) gate/usage_max 0.4182 (0.4147) gate/usage_min 0.2505 (0.2522) gate/usage_std 0.0685 (0.0664) teacher/entropy 0.9208 (0.8484) teacher/usage_max 0.4396 (0.5059) teacher/usage_min 0.2773 (0.2047) teacher/usage_std 0.0752 (0.1289) nleep/row_max_mean 1203.3594 (1202.8120) nleep/row_max_std 9.7311 (11.5128) nleep/row_min_mean 1201.9583 (1200.9217) lr 1.9823e-03 eta 1:32:36
epoch [5/50] batch [100/288] time 0.484 (0.387) data 0.000 (0.002) loss 0.9642 (1.3403) teacher_loss 0.5957 (0.9615) loss_zs_kd 0.0224 (0.0279) loss_oracle 0.3121 (0.3322) kd_loss 0.2013 (0.1987) acc 81.2500 (74.8750) gate/entropy 1.0768 (1.0783) gate/usage_max 0.4199 (0.4156) gate/usage_min 0.2501 (0.2518) gate/usage_std 0.0694 (0.0669) teacher/entropy 0.8464 (0.8493) teacher/usage_max 0.4786 (0.5019) teacher/usage_min 0.1964 (0.2107) teacher/usage_std 0.1154 (0.1253) nleep/row_max_mean 1204.3104 (1202.8863) nleep/row_max_std 9.2988 (11.4005) nleep/row_min_mean 1202.4685 (1201.0063) lr 1.9823e-03 eta 1:24:51
epoch [5/50] batch [120/288] time 0.463 (0.383) data 0.000 (0.002) loss 1.3931 (1.3358) teacher_loss 0.9884 (0.9558) loss_zs_kd 0.0294 (0.0277) loss_oracle 0.3539 (0.3321) kd_loss 0.2130 (0.2002) acc 75.0000 (75.0000) gate/entropy 1.0760 (1.0780) gate/usage_max 0.4220 (0.4165) gate/usage_min 0.2491 (0.2514) gate/usage_std 0.0706 (0.0674) teacher/entropy 0.8496 (0.8500) teacher/usage_max 0.4603 (0.4979) teacher/usage_min 0.2355 (0.2143) teacher/usage_std 0.0940 (0.1223) nleep/row_max_mean 1205.9065 (1202.8692) nleep/row_max_std 11.4819 (11.2992) nleep/row_min_mean 1204.0300 (1200.9937) lr 1.9823e-03 eta 1:23:51
epoch [5/50] batch [140/288] time 0.540 (0.397) data 0.000 (0.002) loss 1.4220 (1.3393) teacher_loss 1.0704 (0.9571) loss_zs_kd 0.0328 (0.0275) loss_oracle 0.2894 (0.3306) kd_loss 0.1905 (0.2031) acc 68.7500 (75.0446) gate/entropy 1.0756 (1.0777) gate/usage_max 0.4235 (0.4174) gate/usage_min 0.2488 (0.2511) gate/usage_std 0.0714 (0.0679) teacher/entropy 0.8869 (0.8494) teacher/usage_max 0.4564 (0.4944) teacher/usage_min 0.2560 (0.2186) teacher/usage_std 0.0880 (0.1192) nleep/row_max_mean 1200.9238 (1202.7569) nleep/row_max_std 10.5398 (11.2560) nleep/row_min_mean 1199.2450 (1200.8769) lr 1.9823e-03 eta 1:26:44
epoch [5/50] batch [160/288] time 0.478 (0.408) data 0.000 (0.002) loss 1.6706 (1.3430) teacher_loss 1.2204 (0.9581) loss_zs_kd 0.0251 (0.0271) loss_oracle 0.3973 (0.3325) kd_loss 0.2390 (0.2051) acc 68.7500 (74.9023) gate/entropy 1.0748 (1.0773) gate/usage_max 0.4258 (0.4183) gate/usage_min 0.2482 (0.2507) gate/usage_std 0.0727 (0.0685) teacher/entropy 0.7881 (0.8487) teacher/usage_max 0.5579 (0.4941) teacher/usage_min 0.2048 (0.2198) teacher/usage_std 0.1593 (0.1189) nleep/row_max_mean 1204.4866 (1202.6707) nleep/row_max_std 13.4239 (11.3238) nleep/row_min_mean 1202.3618 (1200.7848) lr 1.9823e-03 eta 1:29:03
epoch [5/50] batch [180/288] time 0.399 (0.416) data 0.000 (0.001) loss 1.3042 (1.3566) teacher_loss 0.8691 (0.9646) loss_zs_kd 0.0328 (0.0270) loss_oracle 0.3383 (0.3378) kd_loss 0.2496 (0.2096) acc 81.2500 (74.6354) gate/entropy 1.0741 (1.0770) gate/usage_max 0.4281 (0.4193) gate/usage_min 0.2479 (0.2504) gate/usage_std 0.0739 (0.0690) teacher/entropy 0.8471 (0.8451) teacher/usage_max 0.4321 (0.4961) teacher/usage_min 0.2282 (0.2176) teacher/usage_std 0.0834 (0.1205) nleep/row_max_mean 1203.0676 (1202.6721) nleep/row_max_std 12.1182 (11.3990) nleep/row_min_mean 1201.0284 (1200.7655) lr 1.9823e-03 eta 1:30:33
epoch [5/50] batch [200/288] time 0.510 (0.409) data 0.000 (0.001) loss 1.3336 (1.3672) teacher_loss 0.8772 (0.9681) loss_zs_kd 0.0185 (0.0267) loss_oracle 0.3588 (0.3434) kd_loss 0.2678 (0.2140) acc 81.2500 (74.7969) gate/entropy 1.0733 (1.0767) gate/usage_max 0.4307 (0.4203) gate/usage_min 0.2475 (0.2502) gate/usage_std 0.0752 (0.0696) teacher/entropy 0.7711 (0.8405) teacher/usage_max 0.5391 (0.4990) teacher/usage_min 0.2207 (0.2157) teacher/usage_std 0.1457 (0.1227) nleep/row_max_mean 1203.0629 (1202.7189) nleep/row_max_std 14.7996 (11.4163) nleep/row_min_mean 1200.7007 (1200.7895) lr 1.9823e-03 eta 1:28:57
epoch [5/50] batch [220/288] time 0.099 (0.395) data 0.000 (0.001) loss 1.6249 (1.3758) teacher_loss 1.1923 (0.9717) loss_zs_kd 0.0324 (0.0269) loss_oracle 0.3416 (0.3439) kd_loss 0.2456 (0.2187) acc 75.0000 (74.6591) gate/entropy 1.0726 (1.0763) gate/usage_max 0.4329 (0.4214) gate/usage_min 0.2475 (0.2499) gate/usage_std 0.0763 (0.0701) teacher/entropy 0.8498 (0.8366) teacher/usage_max 0.4513 (0.4999) teacher/usage_min 0.1899 (0.2133) teacher/usage_std 0.1082 (0.1237) nleep/row_max_mean 1202.1992 (1202.7241) nleep/row_max_std 13.5185 (11.5350) nleep/row_min_mean 1200.2087 (1200.7731) lr 1.9823e-03 eta 1:25:51
epoch [5/50] batch [240/288] time 0.474 (0.395) data 0.001 (0.001) loss 1.1670 (1.3764) teacher_loss 0.7053 (0.9689) loss_zs_kd 0.0238 (0.0267) loss_oracle 0.3005 (0.3436) kd_loss 0.2996 (0.2224) acc 81.2500 (74.5964) gate/entropy 1.0721 (1.0760) gate/usage_max 0.4344 (0.4224) gate/usage_min 0.2474 (0.2497) gate/usage_std 0.0771 (0.0707) teacher/entropy 0.8157 (0.8343) teacher/usage_max 0.4279 (0.4992) teacher/usage_min 0.1578 (0.2117) teacher/usage_std 0.1243 (0.1239) nleep/row_max_mean 1201.0250 (1202.7018) nleep/row_max_std 14.3821 (11.5852) nleep/row_min_mean 1199.0471 (1200.7403) lr 1.9823e-03 eta 1:25:40
epoch [5/50] batch [260/288] time 0.480 (0.404) data 0.000 (0.001) loss 1.4887 (1.3776) teacher_loss 1.0820 (0.9649) loss_zs_kd 0.0152 (0.0265) loss_oracle 0.3704 (0.3482) kd_loss 0.2139 (0.2253) acc 65.6250 (74.6394) gate/entropy 1.0714 (1.0757) gate/usage_max 0.4365 (0.4234) gate/usage_min 0.2473 (0.2495) gate/usage_std 0.0782 (0.0712) teacher/entropy 0.8503 (0.8322) teacher/usage_max 0.4890 (0.4990) teacher/usage_min 0.2228 (0.2099) teacher/usage_std 0.1133 (0.1244) nleep/row_max_mean 1205.6902 (1202.7483) nleep/row_max_std 12.4505 (11.5512) nleep/row_min_mean 1203.8926 (1200.7771) lr 1.9823e-03 eta 1:27:24
epoch [5/50] batch [280/288] time 0.513 (0.411) data 0.000 (0.001) loss 1.0377 (1.3712) teacher_loss 0.6710 (0.9552) loss_zs_kd 0.0362 (0.0265) loss_oracle 0.2844 (0.3481) kd_loss 0.2064 (0.2287) acc 78.1250 (74.8438) gate/entropy 1.0709 (1.0753) gate/usage_max 0.4383 (0.4244) gate/usage_min 0.2476 (0.2494) gate/usage_std 0.0790 (0.0718) teacher/entropy 0.8759 (0.8308) teacher/usage_max 0.4550 (0.4959) teacher/usage_min 0.2241 (0.2099) teacher/usage_std 0.0947 (0.1229) nleep/row_max_mean 1202.6282 (1202.7004) nleep/row_max_std 9.1306 (11.6467) nleep/row_min_mean 1200.8453 (1200.7200) lr 1.9823e-03 eta 1:28:50
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,411
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 85.9%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,007
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 79.2%
******* Domain a best val acc:      86.9%, epoch: 4 *******
******* Domain a best val test acc: 83.1%, epoch: 4 *******
******* Domain a best test acc:     83.4%, epoch: 2 *******
epoch [6/50] batch [20/288] time 0.432 (0.285) data 0.000 (0.013) loss 1.6235 (1.3873) teacher_loss 1.0323 (0.8563) loss_zs_kd 0.0223 (0.0258) loss_oracle 0.4673 (0.4315) kd_loss 0.3463 (0.3024) acc 71.8750 (75.3125) gate/entropy 1.0699 (1.0703) gate/usage_max 0.4412 (0.4401) gate/usage_min 0.2478 (0.2477) gate/usage_std 0.0805 (0.0800) teacher/entropy 0.7190 (0.7818) teacher/usage_max 0.5021 (0.4691) teacher/usage_min 0.1719 (0.1796) teacher/usage_std 0.1349 (0.1223) nleep/row_max_mean 1205.1709 (1202.9776) nleep/row_max_std 13.4815 (11.7981) nleep/row_min_mean 1202.4717 (1200.6804) lr 1.9686e-03 eta 1:01:23
epoch [6/50] batch [40/288] time 0.465 (0.329) data 0.000 (0.006) loss 1.3529 (1.4162) teacher_loss 0.8590 (0.9053) loss_zs_kd 0.0277 (0.0262) loss_oracle 0.3761 (0.4058) kd_loss 0.2919 (0.2949) acc 78.1250 (75.4688) gate/entropy 1.0691 (1.0699) gate/usage_max 0.4437 (0.4413) gate/usage_min 0.2477 (0.2478) gate/usage_std 0.0819 (0.0806) teacher/entropy 0.7860 (0.7893) teacher/usage_max 0.4741 (0.4680) teacher/usage_min 0.1847 (0.1797) teacher/usage_std 0.1183 (0.1218) nleep/row_max_mean 1199.6111 (1202.7237) nleep/row_max_std 10.8044 (11.9493) nleep/row_min_mean 1197.3124 (1200.4456) lr 1.9686e-03 eta 1:10:55
epoch [6/50] batch [60/288] time 0.496 (0.377) data 0.000 (0.004) loss 1.5578 (1.4006) teacher_loss 1.0067 (0.8932) loss_zs_kd 0.0411 (0.0269) loss_oracle 0.4122 (0.3946) kd_loss 0.3244 (0.2967) acc 68.7500 (75.8854) gate/entropy 1.0686 (1.0696) gate/usage_max 0.4452 (0.4423) gate/usage_min 0.2482 (0.2479) gate/usage_std 0.0826 (0.0811) teacher/entropy 0.7896 (0.7887) teacher/usage_max 0.4052 (0.4658) teacher/usage_min 0.1977 (0.1782) teacher/usage_std 0.0960 (0.1215) nleep/row_max_mean 1203.3047 (1202.8320) nleep/row_max_std 12.9669 (12.1275) nleep/row_min_mean 1200.9800 (1200.5514) lr 1.9686e-03 eta 1:21:09
epoch [6/50] batch [80/288] time 0.465 (0.400) data 0.000 (0.003) loss 1.5582 (1.4154) teacher_loss 0.9493 (0.9010) loss_zs_kd 0.0466 (0.0274) loss_oracle 0.4668 (0.4069) kd_loss 0.3522 (0.2972) acc 75.0000 (75.8594) gate/entropy 1.0678 (1.0692) gate/usage_max 0.4473 (0.4433) gate/usage_min 0.2484 (0.2480) gate/usage_std 0.0838 (0.0817) teacher/entropy 0.7435 (0.7891) teacher/usage_max 0.4458 (0.4648) teacher/usage_min 0.1643 (0.1771) teacher/usage_std 0.1217 (0.1214) nleep/row_max_mean 1201.7190 (1202.7981) nleep/row_max_std 13.1406 (12.4370) nleep/row_min_mean 1199.3859 (1200.5093) lr 1.9686e-03 eta 1:25:51
epoch [6/50] batch [100/288] time 0.442 (0.412) data 0.000 (0.003) loss 1.7316 (1.4391) teacher_loss 1.1493 (0.9157) loss_zs_kd 0.0255 (0.0276) loss_oracle 0.4616 (0.4209) kd_loss 0.3387 (0.2992) acc 71.8750 (75.8125) gate/entropy 1.0667 (1.0688) gate/usage_max 0.4502 (0.4444) gate/usage_min 0.2484 (0.2481) gate/usage_std 0.0854 (0.0822) teacher/entropy 0.6774 (0.7818) teacher/usage_max 0.5945 (0.4747) teacher/usage_min 0.1142 (0.1708) teacher/usage_std 0.1983 (0.1280) nleep/row_max_mean 1203.9891 (1202.7315) nleep/row_max_std 13.6570 (12.5855) nleep/row_min_mean 1201.3748 (1200.4000) lr 1.9686e-03 eta 1:28:23
epoch [6/50] batch [120/288] time 0.094 (0.382) data 0.000 (0.002) loss 1.6606 (1.4391) teacher_loss 1.0867 (0.9137) loss_zs_kd 0.0418 (0.0275) loss_oracle 0.4749 (0.4216) kd_loss 0.3155 (0.3008) acc 71.8750 (76.0938) gate/entropy 1.0656 (1.0684) gate/usage_max 0.4530 (0.4456) gate/usage_min 0.2485 (0.2482) gate/usage_std 0.0871 (0.0829) teacher/entropy 0.7082 (0.7766) teacher/usage_max 0.5825 (0.4818) teacher/usage_min 0.1019 (0.1653) teacher/usage_std 0.1966 (0.1331) nleep/row_max_mean 1202.5027 (1202.6359) nleep/row_max_std 10.9262 (12.7632) nleep/row_min_mean 1199.7273 (1200.2680) lr 1.9686e-03 eta 1:21:47
epoch [6/50] batch [140/288] time 0.085 (0.377) data 0.000 (0.002) loss 1.1988 (1.4410) teacher_loss 0.7090 (0.9122) loss_zs_kd 0.0258 (0.0275) loss_oracle 0.4287 (0.4243) kd_loss 0.2625 (0.3029) acc 84.3750 (76.1161) gate/entropy 1.0644 (1.0679) gate/usage_max 0.4558 (0.4469) gate/usage_min 0.2486 (0.2482) gate/usage_std 0.0887 (0.0836) teacher/entropy 0.7570 (0.7693) teacher/usage_max 0.5713 (0.4910) teacher/usage_min 0.1491 (0.1591) teacher/usage_std 0.1765 (0.1392) nleep/row_max_mean 1200.8569 (1202.5668) nleep/row_max_std 13.6139 (12.8070) nleep/row_min_mean 1198.2954 (1200.1441) lr 1.9686e-03 eta 1:20:31
epoch [6/50] batch [160/288] time 0.467 (0.364) data 0.000 (0.002) loss 1.2272 (1.4426) teacher_loss 0.5652 (0.9118) loss_zs_kd 0.0362 (0.0282) loss_oracle 0.4912 (0.4238) kd_loss 0.3983 (0.3049) acc 84.3750 (76.0352) gate/entropy 1.0632 (1.0674) gate/usage_max 0.4586 (0.4482) gate/usage_min 0.2486 (0.2483) gate/usage_std 0.0904 (0.0844) teacher/entropy 0.6090 (0.7627) teacher/usage_max 0.6068 (0.4985) teacher/usage_min 0.0771 (0.1540) teacher/usage_std 0.2166 (0.1441) nleep/row_max_mean 1203.2305 (1202.4860) nleep/row_max_std 15.0576 (12.8333) nleep/row_min_mean 1199.9175 (1200.0128) lr 1.9686e-03 eta 1:17:44
epoch [6/50] batch [180/288] time 0.498 (0.375) data 0.000 (0.002) loss 1.2358 (1.4471) teacher_loss 0.6607 (0.9142) loss_zs_kd 0.0426 (0.0289) loss_oracle 0.4022 (0.4243) kd_loss 0.3527 (0.3063) acc 84.3750 (76.0069) gate/entropy 1.0617 (1.0668) gate/usage_max 0.4618 (0.4495) gate/usage_min 0.2484 (0.2483) gate/usage_std 0.0924 (0.0852) teacher/entropy 0.7104 (0.7575) teacher/usage_max 0.5052 (0.5042) teacher/usage_min 0.1043 (0.1506) teacher/usage_std 0.1686 (0.1478) nleep/row_max_mean 1203.6162 (1202.5188) nleep/row_max_std 10.2412 (12.9385) nleep/row_min_mean 1200.4562 (1200.0094) lr 1.9686e-03 eta 1:19:52
epoch [6/50] batch [200/288] time 0.495 (0.386) data 0.000 (0.001) loss 1.3901 (1.4505) teacher_loss 0.8718 (0.9199) loss_zs_kd 0.0205 (0.0289) loss_oracle 0.3563 (0.4174) kd_loss 0.3299 (0.3075) acc 68.7500 (75.9219) gate/entropy 1.0602 (1.0662) gate/usage_max 0.4649 (0.4509) gate/usage_min 0.2482 (0.2483) gate/usage_std 0.0944 (0.0860) teacher/entropy 0.7196 (0.7541) teacher/usage_max 0.5211 (0.5071) teacher/usage_min 0.1138 (0.1475) teacher/usage_std 0.1678 (0.1501) nleep/row_max_mean 1202.4711 (1202.4580) nleep/row_max_std 12.2517 (12.9774) nleep/row_min_mean 1199.6200 (1199.9173) lr 1.9686e-03 eta 1:22:02
epoch [6/50] batch [220/288] time 0.495 (0.396) data 0.000 (0.001) loss 1.6017 (1.4510) teacher_loss 1.0926 (0.9228) loss_zs_kd 0.0398 (0.0291) loss_oracle 0.3061 (0.4094) kd_loss 0.3362 (0.3090) acc 81.2500 (75.8949) gate/entropy 1.0592 (1.0656) gate/usage_max 0.4669 (0.4523) gate/usage_min 0.2485 (0.2483) gate/usage_std 0.0956 (0.0868) teacher/entropy 0.7229 (0.7497) teacher/usage_max 0.5021 (0.5112) teacher/usage_min 0.1160 (0.1443) teacher/usage_std 0.1614 (0.1531) nleep/row_max_mean 1201.4563 (1202.4575) nleep/row_max_std 15.3966 (13.1221) nleep/row_min_mean 1198.7405 (1199.8893) lr 1.9686e-03 eta 1:24:05
epoch [6/50] batch [240/288] time 0.256 (0.385) data 0.000 (0.001) loss 1.3746 (1.4553) teacher_loss 0.8930 (0.9288) loss_zs_kd 0.0193 (0.0292) loss_oracle 0.3461 (0.4047) kd_loss 0.2990 (0.3096) acc 75.0000 (75.6380) gate/entropy 1.0578 (1.0650) gate/usage_max 0.4697 (0.4536) gate/usage_min 0.2484 (0.2483) gate/usage_std 0.0974 (0.0876) teacher/entropy 0.7218 (0.7464) teacher/usage_max 0.5599 (0.5146) teacher/usage_min 0.1153 (0.1412) teacher/usage_std 0.1816 (0.1556) nleep/row_max_mean 1199.9780 (1202.3698) nleep/row_max_std 11.1625 (13.1073) nleep/row_min_mean 1197.2234 (1199.7741) lr 1.9686e-03 eta 1:21:42
epoch [6/50] batch [260/288] time 0.384 (0.384) data 0.000 (0.001) loss 1.6062 (1.4564) teacher_loss 1.1807 (0.9299) loss_zs_kd 0.0202 (0.0295) loss_oracle 0.2978 (0.4009) kd_loss 0.2664 (0.3113) acc 75.0000 (75.6130) gate/entropy 1.0563 (1.0644) gate/usage_max 0.4726 (0.4550) gate/usage_min 0.2484 (0.2483) gate/usage_std 0.0992 (0.0884) teacher/entropy 0.7383 (0.7415) teacher/usage_max 0.5802 (0.5190) teacher/usage_min 0.1240 (0.1377) teacher/usage_std 0.1882 (0.1588) nleep/row_max_mean 1204.1190 (1202.4073) nleep/row_max_std 16.5905 (13.0708) nleep/row_min_mean 1201.5051 (1199.7671) lr 1.9686e-03 eta 1:21:22
epoch [6/50] batch [280/288] time 0.078 (0.372) data 0.000 (0.001) loss 1.6640 (1.4574) teacher_loss 1.1533 (0.9309) loss_zs_kd 0.0769 (0.0299) loss_oracle 0.2820 (0.3957) kd_loss 0.3313 (0.3136) acc 75.0000 (75.5804) gate/entropy 1.0554 (1.0638) gate/usage_max 0.4744 (0.4563) gate/usage_min 0.2489 (0.2483) gate/usage_std 0.1004 (0.0892) teacher/entropy 0.7306 (0.7366) teacher/usage_max 0.4938 (0.5225) teacher/usage_min 0.0950 (0.1340) teacher/usage_std 0.1718 (0.1617) nleep/row_max_mean 1201.7228 (1202.4246) nleep/row_max_std 13.5655 (13.1599) nleep/row_min_mean 1198.6301 (1199.7382) lr 1.9686e-03 eta 1:18:31
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,424
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/a/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,998
* accuracy: 82.3%
* error: 17.7%
* macro_f1: 78.9%
******* Domain a best val acc:      86.9%, epoch: 6 *******
******* Domain a best val test acc: 82.3%, epoch: 6 *******
******* Domain a best test acc:     83.4%, epoch: 2 *******
epoch [7/50] batch [20/288] time 0.465 (0.484) data 0.000 (0.016) loss 1.5614 (1.5008) teacher_loss 1.0592 (0.9621) loss_zs_kd 0.0300 (0.0317) loss_oracle 0.3004 (0.3430) kd_loss 0.3370 (0.3514) acc 71.8750 (75.6250) gate/entropy 1.0539 (1.0543) gate/usage_max 0.4773 (0.4764) gate/usage_min 0.2493 (0.2491) gate/usage_std 0.1023 (0.1017) teacher/entropy 0.7183 (0.6643) teacher/usage_max 0.4979 (0.5630) teacher/usage_min 0.1090 (0.0869) teacher/usage_std 0.1643 (0.1966) nleep/row_max_mean 1203.2820 (1202.2954) nleep/row_max_std 14.4917 (12.3816) nleep/row_min_mean 1199.6919 (1198.9282) lr 1.9511e-03 eta 1:42:00
epoch [7/50] batch [40/288] time 0.516 (0.473) data 0.000 (0.008) loss 1.2053 (1.4513) teacher_loss 0.6155 (0.9070) loss_zs_kd 0.0131 (0.0301) loss_oracle 0.3764 (0.3469) kd_loss 0.3951 (0.3558) acc 81.2500 (76.5625) gate/entropy 1.0531 (1.0538) gate/usage_max 0.4788 (0.4774) gate/usage_min 0.2499 (0.2493) gate/usage_std 0.1032 (0.1023) teacher/entropy 0.6299 (0.6636) teacher/usage_max 0.5455 (0.5561) teacher/usage_min 0.0699 (0.0858) teacher/usage_std 0.1975 (0.1953) nleep/row_max_mean 1202.1230 (1202.7017) nleep/row_max_std 12.6937 (12.6668) nleep/row_min_mean 1198.3774 (1199.2931) lr 1.9511e-03 eta 1:39:30
epoch [7/50] batch [60/288] time 0.084 (0.407) data 0.000 (0.005) loss 1.7733 (1.4414) teacher_loss 1.1258 (0.8883) loss_zs_kd 0.0451 (0.0304) loss_oracle 0.4466 (0.3625) kd_loss 0.4017 (0.3567) acc 71.8750 (76.8750) gate/entropy 1.0514 (1.0532) gate/usage_max 0.4816 (0.4784) gate/usage_min 0.2499 (0.2494) gate/usage_std 0.1051 (0.1030) teacher/entropy 0.6411 (0.6643) teacher/usage_max 0.5118 (0.5526) teacher/usage_min 0.1030 (0.0826) teacher/usage_std 0.1709 (0.1959) nleep/row_max_mean 1198.4634 (1202.6963) nleep/row_max_std 11.6585 (12.5110) nleep/row_min_mean 1195.1211 (1199.2737) lr 1.9511e-03 eta 1:25:36
epoch [7/50] batch [80/288] time 0.474 (0.400) data 0.000 (0.004) loss 1.4156 (1.4564) teacher_loss 0.7877 (0.8910) loss_zs_kd 0.0384 (0.0307) loss_oracle 0.4123 (0.3791) kd_loss 0.4026 (0.3605) acc 78.1250 (76.5625) gate/entropy 1.0502 (1.0526) gate/usage_max 0.4838 (0.4795) gate/usage_min 0.2503 (0.2496) gate/usage_std 0.1066 (0.1037) teacher/entropy 0.6056 (0.6604) teacher/usage_max 0.5633 (0.5512) teacher/usage_min 0.0799 (0.0801) teacher/usage_std 0.1980 (0.1968) nleep/row_max_mean 1201.9974 (1202.7866) nleep/row_max_std 11.7253 (12.4492) nleep/row_min_mean 1198.4580 (1199.3034) lr 1.9511e-03 eta 1:23:54
epoch [7/50] batch [100/288] time 0.085 (0.362) data 0.000 (0.003) loss 1.1482 (1.4598) teacher_loss 0.5486 (0.8929) loss_zs_kd 0.0163 (0.0305) loss_oracle 0.2942 (0.3777) kd_loss 0.4443 (0.3628) acc 87.5000 (76.4688) gate/entropy 1.0487 (1.0519) gate/usage_max 0.4862 (0.4807) gate/usage_min 0.2503 (0.2497) gate/usage_std 0.1083 (0.1045) teacher/entropy 0.6521 (0.6559) teacher/usage_max 0.5238 (0.5540) teacher/usage_min 0.0464 (0.0777) teacher/usage_std 0.2065 (0.1987) nleep/row_max_mean 1205.1416 (1202.8756) nleep/row_max_std 10.3492 (12.4129) nleep/row_min_mean 1201.3185 (1199.3390) lr 1.9511e-03 eta 1:15:53
epoch [7/50] batch [120/288] time 0.479 (0.374) data 0.000 (0.003) loss 1.9594 (1.4635) teacher_loss 1.4166 (0.8932) loss_zs_kd 0.0263 (0.0302) loss_oracle 0.3253 (0.3761) kd_loss 0.3670 (0.3672) acc 75.0000 (76.5365) gate/entropy 1.0470 (1.0513) gate/usage_max 0.4889 (0.4818) gate/usage_min 0.2502 (0.2498) gate/usage_std 0.1101 (0.1053) teacher/entropy 0.6853 (0.6503) teacher/usage_max 0.4923 (0.5541) teacher/usage_min 0.0792 (0.0759) teacher/usage_std 0.1816 (0.1997) nleep/row_max_mean 1199.2980 (1202.9280) nleep/row_max_std 11.9616 (12.4304) nleep/row_min_mean 1195.8053 (1199.3434) lr 1.9511e-03 eta 1:18:18
epoch [7/50] batch [140/288] time 0.467 (0.389) data 0.000 (0.002) loss 1.5535 (1.4716) teacher_loss 1.0026 (0.9021) loss_zs_kd 0.0315 (0.0308) loss_oracle 0.3014 (0.3703) kd_loss 0.3845 (0.3689) acc 71.8750 (76.4509) gate/entropy 1.0468 (1.0507) gate/usage_max 0.4894 (0.4828) gate/usage_min 0.2512 (0.2500) gate/usage_std 0.1104 (0.1060) teacher/entropy 0.6313 (0.6487) teacher/usage_max 0.5454 (0.5524) teacher/usage_min 0.0386 (0.0749) teacher/usage_std 0.2150 (0.1998) nleep/row_max_mean 1197.1328 (1202.8958) nleep/row_max_std 14.5876 (12.5313) nleep/row_min_mean 1193.2095 (1199.2802) lr 1.9511e-03 eta 1:21:14
epoch [7/50] batch [160/288] time 0.463 (0.399) data 0.000 (0.002) loss 1.4569 (1.4826) teacher_loss 0.8665 (0.9164) loss_zs_kd 0.0280 (0.0307) loss_oracle 0.3487 (0.3623) kd_loss 0.4021 (0.3697) acc 78.1250 (76.0938) gate/entropy 1.0454 (1.0501) gate/usage_max 0.4915 (0.4838) gate/usage_min 0.2515 (0.2501) gate/usage_std 0.1118 (0.1066) teacher/entropy 0.5575 (0.6484) teacher/usage_max 0.6252 (0.5507) teacher/usage_min 0.0339 (0.0734) teacher/usage_std 0.2414 (0.2000) nleep/row_max_mean 1204.6053 (1202.8302) nleep/row_max_std 13.3691 (12.5703) nleep/row_min_mean 1200.6011 (1199.2007) lr 1.9511e-03 eta 1:23:11
epoch [7/50] batch [180/288] time 0.091 (0.399) data 0.000 (0.002) loss 1.5807 (1.4888) teacher_loss 0.9377 (0.9227) loss_zs_kd 0.0371 (0.0307) loss_oracle 0.3747 (0.3612) kd_loss 0.4371 (0.3702) acc 75.0000 (76.0417) gate/entropy 1.0442 (1.0495) gate/usage_max 0.4934 (0.4848) gate/usage_min 0.2517 (0.2503) gate/usage_std 0.1132 (0.1073) teacher/entropy 0.6085 (0.6477) teacher/usage_max 0.4948 (0.5497) teacher/usage_min 0.0630 (0.0726) teacher/usage_std 0.1924 (0.2001) nleep/row_max_mean 1203.0315 (1202.7690) nleep/row_max_std 11.1058 (12.5308) nleep/row_min_mean 1199.0884 (1199.1056) lr 1.9511e-03 eta 1:23:01
epoch [7/50] batch [200/288] time 0.490 (0.392) data 0.000 (0.002) loss 1.1558 (1.4841) teacher_loss 0.5679 (0.9140) loss_zs_kd 0.0365 (0.0310) loss_oracle 0.3984 (0.3646) kd_loss 0.3705 (0.3724) acc 84.3750 (76.1719) gate/entropy 1.0431 (1.0489) gate/usage_max 0.4951 (0.4857) gate/usage_min 0.2523 (0.2505) gate/usage_std 0.1144 (0.1079) teacher/entropy 0.6466 (0.6464) teacher/usage_max 0.5337 (0.5476) teacher/usage_min 0.0678 (0.0712) teacher/usage_std 0.1957 (0.2002) nleep/row_max_mean 1203.4163 (1202.7592) nleep/row_max_std 11.9564 (12.4470) nleep/row_min_mean 1199.3009 (1199.0559) lr 1.9511e-03 eta 1:21:31
epoch [7/50] batch [220/288] time 0.523 (0.378) data 0.000 (0.002) loss 1.8459 (1.4948) teacher_loss 1.2124 (0.9183) loss_zs_kd 0.0205 (0.0308) loss_oracle 0.4385 (0.3693) kd_loss 0.4040 (0.3764) acc 71.8750 (76.0085) gate/entropy 1.0422 (1.0483) gate/usage_max 0.4963 (0.4866) gate/usage_min 0.2507 (0.2506) gate/usage_std 0.1153 (0.1086) teacher/entropy 0.6151 (0.6434) teacher/usage_max 0.5268 (0.5457) teacher/usage_min 0.0665 (0.0692) teacher/usage_std 0.1950 (0.2009) nleep/row_max_mean 1199.9489 (1202.7613) nleep/row_max_std 11.2923 (12.4184) nleep/row_min_mean 1195.6038 (1199.0058) lr 1.9511e-03 eta 1:18:28
epoch [7/50] batch [240/288] time 0.499 (0.377) data 0.000 (0.001) loss 2.0061 (1.5088) teacher_loss 1.2906 (0.9262) loss_zs_kd 0.0424 (0.0311) loss_oracle 0.3122 (0.3734) kd_loss 0.5382 (0.3803) acc 68.7500 (75.9505) gate/entropy 1.0410 (1.0478) gate/usage_max 0.4980 (0.4875) gate/usage_min 0.2485 (0.2505) gate/usage_std 0.1165 (0.1092) teacher/entropy 0.5647 (0.6398) teacher/usage_max 0.5744 (0.5449) teacher/usage_min 0.0263 (0.0672) teacher/usage_std 0.2286 (0.2017) nleep/row_max_mean 1201.7952 (1202.7425) nleep/row_max_std 10.7716 (12.3989) nleep/row_min_mean 1197.2875 (1198.9340) lr 1.9511e-03 eta 1:18:11
epoch [7/50] batch [260/288] time 0.472 (0.386) data 0.000 (0.001) loss 1.5353 (1.5164) teacher_loss 0.9551 (0.9281) loss_zs_kd 0.0170 (0.0309) loss_oracle 0.3330 (0.3749) kd_loss 0.4051 (0.3854) acc 78.1250 (75.8894) gate/entropy 1.0402 (1.0472) gate/usage_max 0.4992 (0.4884) gate/usage_min 0.2465 (0.2502) gate/usage_std 0.1173 (0.1098) teacher/entropy 0.6434 (0.6352) teacher/usage_max 0.4762 (0.5433) teacher/usage_min 0.0482 (0.0651) teacher/usage_std 0.2017 (0.2025) nleep/row_max_mean 1204.4500 (1202.8003) nleep/row_max_std 16.0896 (12.3943) nleep/row_min_mean 1199.9174 (1198.9192) lr 1.9511e-03 eta 1:19:47
epoch [7/50] batch [280/288] time 0.452 (0.391) data 0.000 (0.001) loss 1.2776 (1.5142) teacher_loss 0.6253 (0.9224) loss_zs_kd 0.0416 (0.0306) loss_oracle 0.4107 (0.3772) kd_loss 0.4261 (0.3880) acc 84.3750 (76.0268) gate/entropy 1.0393 (1.0467) gate/usage_max 0.5005 (0.4892) gate/usage_min 0.2447 (0.2499) gate/usage_std 0.1182 (0.1104) teacher/entropy 0.5419 (0.6318) teacher/usage_max 0.5916 (0.5427) teacher/usage_min 0.0168 (0.0632) teacher/usage_std 0.2382 (0.2034) nleep/row_max_mean 1204.8156 (1202.8360) nleep/row_max_std 13.0343 (12.4052) nleep/row_min_mean 1199.9990 (1198.9026) lr 1.9511e-03 eta 1:20:50
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,406
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 85.8%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,004
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 79.2%
******* Domain a best val acc:      86.9%, epoch: 6 *******
******* Domain a best val test acc: 82.3%, epoch: 6 *******
******* Domain a best test acc:     83.4%, epoch: 2 *******
epoch [8/50] batch [20/288] time 0.082 (0.347) data 0.000 (0.019) loss 1.4741 (1.5607) teacher_loss 0.8180 (0.8946) loss_zs_kd 0.0537 (0.0332) loss_oracle 0.4404 (0.4334) kd_loss 0.4090 (0.4328) acc 87.5000 (76.5625) gate/entropy 1.0375 (1.0381) gate/usage_max 0.5029 (0.5021) gate/usage_min 0.2419 (0.2428) gate/usage_std 0.1200 (0.1194) teacher/entropy 0.6077 (0.5749) teacher/usage_max 0.5175 (0.5475) teacher/usage_min 0.0552 (0.0361) teacher/usage_std 0.2001 (0.2193) nleep/row_max_mean 1206.0149 (1203.9119) nleep/row_max_std 15.1089 (12.6832) nleep/row_min_mean 1201.8190 (1199.1266) lr 1.9298e-03 eta 1:11:27
epoch [8/50] batch [40/288] time 0.468 (0.327) data 0.000 (0.010) loss 1.4891 (1.5419) teacher_loss 0.7641 (0.8924) loss_zs_kd 0.0410 (0.0303) loss_oracle 0.3967 (0.4240) kd_loss 0.5061 (0.4224) acc 81.2500 (76.3281) gate/entropy 1.0368 (1.0376) gate/usage_max 0.5038 (0.5028) gate/usage_min 0.2403 (0.2419) gate/usage_std 0.1207 (0.1199) teacher/entropy 0.5512 (0.5904) teacher/usage_max 0.5245 (0.5374) teacher/usage_min 0.0243 (0.0395) teacher/usage_std 0.2206 (0.2151) nleep/row_max_mean 1200.5378 (1203.4938) nleep/row_max_std 12.6649 (12.4558) nleep/row_min_mean 1195.7010 (1198.8398) lr 1.9298e-03 eta 1:07:19
epoch [8/50] batch [60/288] time 0.444 (0.367) data 0.000 (0.006) loss 2.1174 (1.5281) teacher_loss 1.4905 (0.8765) loss_zs_kd 0.0287 (0.0300) loss_oracle 0.3968 (0.4230) kd_loss 0.4141 (0.4251) acc 56.2500 (76.2500) gate/entropy 1.0354 (1.0372) gate/usage_max 0.5056 (0.5033) gate/usage_min 0.2382 (0.2410) gate/usage_std 0.1221 (0.1204) teacher/entropy 0.6239 (0.5912) teacher/usage_max 0.4843 (0.5335) teacher/usage_min 0.0833 (0.0398) teacher/usage_std 0.1781 (0.2140) nleep/row_max_mean 1203.3428 (1203.2656) nleep/row_max_std 12.2763 (12.4587) nleep/row_min_mean 1199.3738 (1198.6191) lr 1.9298e-03 eta 1:15:22
epoch [8/50] batch [80/288] time 0.457 (0.395) data 0.000 (0.005) loss 1.6332 (1.5171) teacher_loss 1.0278 (0.8677) loss_zs_kd 0.0147 (0.0302) loss_oracle 0.3343 (0.4130) kd_loss 0.4310 (0.4278) acc 71.8750 (76.9531) gate/entropy 1.0353 (1.0367) gate/usage_max 0.5057 (0.5039) gate/usage_min 0.2372 (0.2402) gate/usage_std 0.1221 (0.1208) teacher/entropy 0.6225 (0.5868) teacher/usage_max 0.4987 (0.5344) teacher/usage_min 0.0463 (0.0391) teacher/usage_std 0.2037 (0.2146) nleep/row_max_mean 1203.1240 (1203.1999) nleep/row_max_std 10.2059 (12.3400) nleep/row_min_mean 1198.6899 (1198.5390) lr 1.9298e-03 eta 1:20:57
epoch [8/50] batch [100/288] time 0.479 (0.412) data 0.000 (0.004) loss 1.3351 (1.5192) teacher_loss 0.7177 (0.8760) loss_zs_kd 0.0298 (0.0304) loss_oracle 0.4020 (0.4034) kd_loss 0.4015 (0.4263) acc 84.3750 (76.9375) gate/entropy 1.0341 (1.0363) gate/usage_max 0.5072 (0.5044) gate/usage_min 0.2354 (0.2394) gate/usage_std 0.1233 (0.1212) teacher/entropy 0.5852 (0.5902) teacher/usage_max 0.5525 (0.5316) teacher/usage_min 0.0507 (0.0412) teacher/usage_std 0.2097 (0.2130) nleep/row_max_mean 1204.7590 (1202.9540) nleep/row_max_std 10.9678 (12.3605) nleep/row_min_mean 1199.8516 (1198.3053) lr 1.9298e-03 eta 1:24:22
epoch [8/50] batch [120/288] time 0.080 (0.388) data 0.000 (0.003) loss 1.4066 (1.5157) teacher_loss 0.7760 (0.8684) loss_zs_kd 0.0373 (0.0309) loss_oracle 0.4004 (0.4033) kd_loss 0.4118 (0.4302) acc 81.2500 (77.1615) gate/entropy 1.0338 (1.0360) gate/usage_max 0.5075 (0.5048) gate/usage_min 0.2340 (0.2386) gate/usage_std 0.1235 (0.1215) teacher/entropy 0.6188 (0.5883) teacher/usage_max 0.4824 (0.5300) teacher/usage_min 0.0393 (0.0401) teacher/usage_std 0.2079 (0.2132) nleep/row_max_mean 1203.5646 (1202.9188) nleep/row_max_std 15.2884 (12.4653) nleep/row_min_mean 1198.9673 (1198.2251) lr 1.9298e-03 eta 1:19:18
epoch [8/50] batch [140/288] time 0.085 (0.387) data 0.000 (0.003) loss 1.5647 (1.5324) teacher_loss 0.9071 (0.8794) loss_zs_kd 0.0613 (0.0316) loss_oracle 0.3873 (0.4073) kd_loss 0.4334 (0.4336) acc 68.7500 (76.8527) gate/entropy 1.0335 (1.0357) gate/usage_max 0.5077 (0.5052) gate/usage_min 0.2327 (0.2379) gate/usage_std 0.1238 (0.1218) teacher/entropy 0.5922 (0.5871) teacher/usage_max 0.4862 (0.5285) teacher/usage_min 0.0322 (0.0403) teacher/usage_std 0.2129 (0.2128) nleep/row_max_mean 1196.3762 (1202.7507) nleep/row_max_std 8.9134 (12.5473) nleep/row_min_mean 1191.4430 (1198.0354) lr 1.9298e-03 eta 1:19:03
epoch [8/50] batch [160/288] time 0.530 (0.371) data 0.000 (0.003) loss 1.7037 (1.5577) teacher_loss 1.0828 (0.8992) loss_zs_kd 0.0550 (0.0322) loss_oracle 0.4305 (0.4115) kd_loss 0.3781 (0.4366) acc 62.5000 (76.2695) gate/entropy 1.0331 (1.0354) gate/usage_max 0.5081 (0.5055) gate/usage_min 0.2313 (0.2371) gate/usage_std 0.1241 (0.1221) teacher/entropy 0.6640 (0.5835) teacher/usage_max 0.4665 (0.5273) teacher/usage_min 0.0788 (0.0403) teacher/usage_std 0.1800 (0.2125) nleep/row_max_mean 1196.6442 (1202.7360) nleep/row_max_std 11.4752 (12.5879) nleep/row_min_mean 1192.4729 (1197.9997) lr 1.9298e-03 eta 1:15:35
epoch [8/50] batch [180/288] time 0.477 (0.385) data 0.000 (0.002) loss 1.9331 (1.5619) teacher_loss 1.2098 (0.9002) loss_zs_kd 0.0190 (0.0318) loss_oracle 0.4506 (0.4115) kd_loss 0.4885 (0.4400) acc 65.6250 (76.2153) gate/entropy 1.0323 (1.0351) gate/usage_max 0.5089 (0.5058) gate/usage_min 0.2297 (0.2364) gate/usage_std 0.1248 (0.1223) teacher/entropy 0.5080 (0.5814) teacher/usage_max 0.5232 (0.5255) teacher/usage_min 0.0298 (0.0399) teacher/usage_std 0.2169 (0.2125) nleep/row_max_mean 1198.1818 (1202.7428) nleep/row_max_std 12.9315 (12.7001) nleep/row_min_mean 1193.3181 (1197.9744) lr 1.9298e-03 eta 1:18:20
epoch [8/50] batch [200/288] time 0.495 (0.396) data 0.000 (0.002) loss 1.9482 (1.5710) teacher_loss 1.2268 (0.9035) loss_zs_kd 0.0197 (0.0317) loss_oracle 0.4176 (0.4124) kd_loss 0.5027 (0.4455) acc 68.7500 (76.1250) gate/entropy 1.0323 (1.0349) gate/usage_max 0.5088 (0.5061) gate/usage_min 0.2286 (0.2357) gate/usage_std 0.1248 (0.1225) teacher/entropy 0.5700 (0.5795) teacher/usage_max 0.5020 (0.5266) teacher/usage_min 0.0820 (0.0394) teacher/usage_std 0.1811 (0.2130) nleep/row_max_mean 1203.1438 (1202.8122) nleep/row_max_std 15.2095 (12.8738) nleep/row_min_mean 1198.4780 (1198.0197) lr 1.9298e-03 eta 1:20:26
epoch [8/50] batch [220/288] time 0.515 (0.403) data 0.000 (0.002) loss 1.2527 (1.5664) teacher_loss 0.6336 (0.8972) loss_zs_kd 0.0281 (0.0320) loss_oracle 0.4201 (0.4111) kd_loss 0.3950 (0.4476) acc 87.5000 (76.3636) gate/entropy 1.0326 (1.0346) gate/usage_max 0.5081 (0.5063) gate/usage_min 0.2275 (0.2350) gate/usage_std 0.1245 (0.1227) teacher/entropy 0.6010 (0.5786) teacher/usage_max 0.5156 (0.5263) teacher/usage_min 0.0230 (0.0397) teacher/usage_std 0.2206 (0.2127) nleep/row_max_mean 1204.8798 (1202.8209) nleep/row_max_std 12.3905 (12.9579) nleep/row_min_mean 1200.1096 (1198.0120) lr 1.9298e-03 eta 1:21:42
epoch [8/50] batch [240/288] time 0.124 (0.392) data 0.000 (0.002) loss 1.5994 (1.5748) teacher_loss 0.8397 (0.9012) loss_zs_kd 0.0453 (0.0326) loss_oracle 0.3876 (0.4089) kd_loss 0.5432 (0.4528) acc 78.1250 (76.1458) gate/entropy 1.0327 (1.0345) gate/usage_max 0.5076 (0.5064) gate/usage_min 0.2263 (0.2343) gate/usage_std 0.1243 (0.1229) teacher/entropy 0.5103 (0.5763) teacher/usage_max 0.5564 (0.5282) teacher/usage_min 0.0215 (0.0393) teacher/usage_std 0.2272 (0.2133) nleep/row_max_mean 1202.4639 (1202.7466) nleep/row_max_std 10.3320 (13.0221) nleep/row_min_mean 1196.7725 (1197.8995) lr 1.9298e-03 eta 1:19:14
epoch [8/50] batch [260/288] time 0.079 (0.391) data 0.000 (0.002) loss 1.5538 (1.5763) teacher_loss 0.7837 (0.8997) loss_zs_kd 0.0355 (0.0325) loss_oracle 0.4008 (0.4079) kd_loss 0.5520 (0.4563) acc 81.2500 (76.2740) gate/entropy 1.0331 (1.0343) gate/usage_max 0.5067 (0.5065) gate/usage_min 0.2251 (0.2337) gate/usage_std 0.1238 (0.1230) teacher/entropy 0.4967 (0.5734) teacher/usage_max 0.5682 (0.5292) teacher/usage_min 0.0095 (0.0384) teacher/usage_std 0.2366 (0.2140) nleep/row_max_mean 1202.1675 (1202.7089) nleep/row_max_std 12.7468 (13.0660) nleep/row_min_mean 1196.0369 (1197.8202) lr 1.9298e-03 eta 1:18:56
epoch [8/50] batch [280/288] time 0.078 (0.377) data 0.000 (0.002) loss 2.0199 (1.5888) teacher_loss 1.3305 (0.9086) loss_zs_kd 0.0484 (0.0324) loss_oracle 0.3804 (0.4054) kd_loss 0.4750 (0.4613) acc 59.3750 (76.0938) gate/entropy 1.0327 (1.0342) gate/usage_max 0.5068 (0.5065) gate/usage_min 0.2232 (0.2330) gate/usage_std 0.1242 (0.1230) teacher/entropy 0.5830 (0.5707) teacher/usage_max 0.5650 (0.5322) teacher/usage_min 0.0284 (0.0377) teacher/usage_std 0.2251 (0.2151) nleep/row_max_mean 1203.5323 (1202.7110) nleep/row_max_std 16.7893 (13.0909) nleep/row_min_mean 1198.3352 (1197.7884) lr 1.9298e-03 eta 1:16:07
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,415
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 86.1%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 2,015
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 79.5%
******* Domain a best val acc:      86.9%, epoch: 6 *******
******* Domain a best val test acc: 82.3%, epoch: 6 *******
******* Domain a best test acc:     83.4%, epoch: 2 *******
epoch [9/50] batch [20/288] time 0.443 (0.493) data 0.000 (0.012) loss 1.6659 (1.6627) teacher_loss 1.0100 (0.9098) loss_zs_kd 0.0344 (0.0316) loss_oracle 0.4005 (0.3740) kd_loss 0.4385 (0.5501) acc 71.8750 (76.2500) gate/entropy 1.0333 (1.0334) gate/usage_max 0.5053 (0.5054) gate/usage_min 0.2214 (0.2223) gate/usage_std 0.1234 (0.1234) teacher/entropy 0.5558 (0.5171) teacher/usage_max 0.5011 (0.5936) teacher/usage_min 0.0256 (0.0232) teacher/usage_std 0.2179 (0.2391) nleep/row_max_mean 1201.9425 (1203.1132) nleep/row_max_std 15.1667 (13.8990) nleep/row_min_mean 1196.8405 (1197.5207) lr 1.9048e-03 eta 1:39:17
epoch [9/50] batch [40/288] time 0.496 (0.482) data 0.000 (0.006) loss 1.3525 (1.6145) teacher_loss 0.6066 (0.8660) loss_zs_kd 0.0240 (0.0310) loss_oracle 0.4182 (0.3812) kd_loss 0.5248 (0.5424) acc 84.3750 (78.5938) gate/entropy 1.0341 (1.0336) gate/usage_max 0.5034 (0.5048) gate/usage_min 0.2203 (0.2216) gate/usage_std 0.1224 (0.1231) teacher/entropy 0.5181 (0.5202) teacher/usage_max 0.5794 (0.5876) teacher/usage_min 0.0117 (0.0244) teacher/usage_std 0.2378 (0.2367) nleep/row_max_mean 1202.9171 (1202.9213) nleep/row_max_std 14.9021 (13.9291) nleep/row_min_mean 1197.3873 (1197.3305) lr 1.9048e-03 eta 1:36:52
epoch [9/50] batch [60/288] time 0.094 (0.419) data 0.000 (0.004) loss 1.7561 (1.6254) teacher_loss 1.0118 (0.8637) loss_zs_kd 0.0314 (0.0320) loss_oracle 0.4097 (0.3957) kd_loss 0.5238 (0.5479) acc 71.8750 (78.1250) gate/entropy 1.0346 (1.0339) gate/usage_max 0.5021 (0.5041) gate/usage_min 0.2189 (0.2209) gate/usage_std 0.1219 (0.1228) teacher/entropy 0.5013 (0.5129) teacher/usage_max 0.5564 (0.5895) teacher/usage_min 0.0117 (0.0239) teacher/usage_std 0.2331 (0.2378) nleep/row_max_mean 1206.4481 (1203.0564) nleep/row_max_std 13.8359 (13.9024) nleep/row_min_mean 1200.4431 (1197.4162) lr 1.9048e-03 eta 1:23:59
epoch [9/50] batch [80/288] time 0.079 (0.410) data 0.000 (0.003) loss 1.5373 (1.6625) teacher_loss 0.7899 (0.9015) loss_zs_kd 0.0268 (0.0325) loss_oracle 0.3818 (0.3984) kd_loss 0.5431 (0.5456) acc 84.3750 (77.2266) gate/entropy 1.0351 (1.0340) gate/usage_max 0.5008 (0.5035) gate/usage_min 0.2178 (0.2202) gate/usage_std 0.1212 (0.1225) teacher/entropy 0.5091 (0.5124) teacher/usage_max 0.6030 (0.5893) teacher/usage_min 0.0160 (0.0240) teacher/usage_std 0.2420 (0.2372) nleep/row_max_mean 1204.7770 (1202.9750) nleep/row_max_std 10.6374 (13.8202) nleep/row_min_mean 1198.8542 (1197.3487) lr 1.9048e-03 eta 1:22:06
epoch [9/50] batch [100/288] time 0.082 (0.369) data 0.000 (0.003) loss 1.4280 (1.6605) teacher_loss 0.6661 (0.9009) loss_zs_kd 0.0219 (0.0318) loss_oracle 0.4523 (0.4053) kd_loss 0.5248 (0.5412) acc 75.0000 (77.1562) gate/entropy 1.0351 (1.0342) gate/usage_max 0.4999 (0.5029) gate/usage_min 0.2161 (0.2195) gate/usage_std 0.1210 (0.1223) teacher/entropy 0.4760 (0.5109) teacher/usage_max 0.5295 (0.5838) teacher/usage_min 0.0103 (0.0230) teacher/usage_std 0.2302 (0.2362) nleep/row_max_mean 1200.3325 (1202.7744) nleep/row_max_std 13.7056 (13.6834) nleep/row_min_mean 1194.8396 (1197.1102) lr 1.9048e-03 eta 1:13:47
epoch [9/50] batch [120/288] time 0.519 (0.389) data 0.000 (0.002) loss 1.6844 (1.6704) teacher_loss 0.9548 (0.9115) loss_zs_kd 0.0406 (0.0324) loss_oracle 0.4361 (0.4136) kd_loss 0.4913 (0.5360) acc 68.7500 (76.5104) gate/entropy 1.0354 (1.0344) gate/usage_max 0.4988 (0.5023) gate/usage_min 0.2148 (0.2188) gate/usage_std 0.1206 (0.1220) teacher/entropy 0.5517 (0.5114) teacher/usage_max 0.5974 (0.5795) teacher/usage_min 0.0198 (0.0236) teacher/usage_std 0.2384 (0.2348) nleep/row_max_mean 1200.5621 (1202.5680) nleep/row_max_std 12.3087 (13.6206) nleep/row_min_mean 1195.2745 (1196.8812) lr 1.9048e-03 eta 1:17:43
epoch [9/50] batch [140/288] time 0.511 (0.405) data 0.000 (0.002) loss 1.6294 (1.6723) teacher_loss 0.9199 (0.9168) loss_zs_kd 0.0149 (0.0326) loss_oracle 0.3852 (0.4140) kd_loss 0.5095 (0.5323) acc 75.0000 (76.5179) gate/entropy 1.0357 (1.0346) gate/usage_max 0.4975 (0.5017) gate/usage_min 0.2135 (0.2181) gate/usage_std 0.1201 (0.1218) teacher/entropy 0.5401 (0.5112) teacher/usage_max 0.5947 (0.5760) teacher/usage_min 0.0334 (0.0238) teacher/usage_std 0.2308 (0.2336) nleep/row_max_mean 1203.1362 (1202.4394) nleep/row_max_std 11.7065 (13.4969) nleep/row_min_mean 1197.6178 (1196.7439) lr 1.9048e-03 eta 1:20:39
epoch [9/50] batch [160/288] time 0.461 (0.414) data 0.000 (0.002) loss 1.3764 (1.6618) teacher_loss 0.6406 (0.9078) loss_zs_kd 0.0216 (0.0331) loss_oracle 0.3638 (0.4145) kd_loss 0.5430 (0.5302) acc 84.3750 (76.5430) gate/entropy 1.0356 (1.0347) gate/usage_max 0.4968 (0.5012) gate/usage_min 0.2121 (0.2175) gate/usage_std 0.1200 (0.1216) teacher/entropy 0.4757 (0.5108) teacher/usage_max 0.5851 (0.5739) teacher/usage_min 0.0080 (0.0245) teacher/usage_std 0.2412 (0.2327) nleep/row_max_mean 1201.7827 (1202.3201) nleep/row_max_std 12.0854 (13.3212) nleep/row_min_mean 1195.6846 (1196.6198) lr 1.9048e-03 eta 1:22:26
epoch [9/50] batch [180/288] time 0.087 (0.402) data 0.000 (0.002) loss 2.4332 (1.6587) teacher_loss 1.6378 (0.9086) loss_zs_kd 0.0573 (0.0329) loss_oracle 0.4078 (0.4120) kd_loss 0.5628 (0.5276) acc 71.8750 (76.5625) gate/entropy 1.0360 (1.0349) gate/usage_max 0.4954 (0.5006) gate/usage_min 0.2109 (0.2168) gate/usage_std 0.1195 (0.1214) teacher/entropy 0.4443 (0.5104) teacher/usage_max 0.5394 (0.5722) teacher/usage_min 0.0266 (0.0250) teacher/usage_std 0.2211 (0.2318) nleep/row_max_mean 1201.1567 (1202.1123) nleep/row_max_std 10.5309 (13.1864) nleep/row_min_mean 1195.4656 (1196.4354) lr 1.9048e-03 eta 1:19:54
epoch [9/50] batch [200/288] time 0.495 (0.400) data 0.000 (0.001) loss 1.9295 (1.6670) teacher_loss 1.2437 (0.9182) loss_zs_kd 0.0202 (0.0332) loss_oracle 0.3682 (0.4137) kd_loss 0.4915 (0.5253) acc 71.8750 (76.2812) gate/entropy 1.0365 (1.0350) gate/usage_max 0.4938 (0.5000) gate/usage_min 0.2097 (0.2161) gate/usage_std 0.1189 (0.1211) teacher/entropy 0.5379 (0.5112) teacher/usage_max 0.5987 (0.5721) teacher/usage_min 0.0216 (0.0254) teacher/usage_std 0.2379 (0.2317) nleep/row_max_mean 1200.1471 (1201.8986) nleep/row_max_std 11.1469 (12.9850) nleep/row_min_mean 1194.8154 (1196.2431) lr 1.9048e-03 eta 1:19:18
epoch [9/50] batch [220/288] time 0.081 (0.383) data 0.000 (0.001) loss 1.1723 (1.6635) teacher_loss 0.5407 (0.9166) loss_zs_kd 0.0422 (0.0331) loss_oracle 0.4594 (0.4155) kd_loss 0.3808 (0.5226) acc 84.3750 (76.1506) gate/entropy 1.0365 (1.0351) gate/usage_max 0.4928 (0.4994) gate/usage_min 0.2082 (0.2155) gate/usage_std 0.1187 (0.1209) teacher/entropy 0.5792 (0.5107) teacher/usage_max 0.5261 (0.5711) teacher/usage_min 0.0441 (0.0254) teacher/usage_std 0.2083 (0.2313) nleep/row_max_mean 1200.4294 (1201.8336) nleep/row_max_std 11.0113 (12.8527) nleep/row_min_mean 1194.9792 (1196.1761) lr 1.9048e-03 eta 1:15:46
epoch [9/50] batch [240/288] time 0.497 (0.390) data 0.000 (0.001) loss 1.6852 (1.6607) teacher_loss 0.9270 (0.9146) loss_zs_kd 0.0567 (0.0331) loss_oracle 0.4043 (0.4174) kd_loss 0.5277 (0.5209) acc 75.0000 (76.2760) gate/entropy 1.0370 (1.0353) gate/usage_max 0.4910 (0.4987) gate/usage_min 0.2073 (0.2148) gate/usage_std 0.1179 (0.1207) teacher/entropy 0.5075 (0.5105) teacher/usage_max 0.6179 (0.5702) teacher/usage_min 0.0269 (0.0260) teacher/usage_std 0.2418 (0.2306) nleep/row_max_mean 1198.5198 (1201.7880) nleep/row_max_std 10.9901 (12.7579) nleep/row_min_mean 1192.8533 (1196.1234) lr 1.9048e-03 eta 1:16:59
epoch [9/50] batch [260/288] time 0.481 (0.396) data 0.000 (0.001) loss 1.6768 (1.6627) teacher_loss 0.8627 (0.9160) loss_zs_kd 0.0226 (0.0333) loss_oracle 0.3773 (0.4172) kd_loss 0.6142 (0.5215) acc 71.8750 (76.1178) gate/entropy 1.0371 (1.0354) gate/usage_max 0.4896 (0.4981) gate/usage_min 0.2059 (0.2142) gate/usage_std 0.1176 (0.1205) teacher/entropy 0.4247 (0.5081) teacher/usage_max 0.6584 (0.5705) teacher/usage_min 0.0142 (0.0259) teacher/usage_std 0.2630 (0.2307) nleep/row_max_mean 1204.1357 (1201.7832) nleep/row_max_std 8.8308 (12.7500) nleep/row_min_mean 1198.3743 (1196.1005) lr 1.9048e-03 eta 1:18:07
epoch [9/50] batch [280/288] time 0.486 (0.402) data 0.000 (0.001) loss 1.6451 (1.6547) teacher_loss 0.7954 (0.9080) loss_zs_kd 0.0151 (0.0332) loss_oracle 0.4218 (0.4178) kd_loss 0.6313 (0.5212) acc 81.2500 (76.2165) gate/entropy 1.0375 (1.0355) gate/usage_max 0.4876 (0.4974) gate/usage_min 0.2045 (0.2135) gate/usage_std 0.1169 (0.1203) teacher/entropy 0.4158 (0.5072) teacher/usage_max 0.7017 (0.5709) teacher/usage_min 0.0075 (0.0264) teacher/usage_std 0.2850 (0.2307) nleep/row_max_mean 1201.3911 (1201.7190) nleep/row_max_std 10.4668 (12.7453) nleep/row_min_mean 1195.1614 (1196.0335) lr 1.9048e-03 eta 1:19:09
Evaluate on the *val* set
=> result
* total: 3,939
* correct: 3,408
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 86.0%
Evaluate on the *test* set
=> result
* total: 2,427
* correct: 1,998
* accuracy: 82.3%
* error: 17.7%
* macro_f1: 78.8%
******* Domain a best val acc:      86.9%, epoch: 6 *******
******* Domain a best val test acc: 82.3%, epoch: 6 *******
******* Domain a best test acc:     83.4%, epoch: 2 *******

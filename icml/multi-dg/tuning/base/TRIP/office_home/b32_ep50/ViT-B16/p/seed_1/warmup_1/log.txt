Loading trainer: TRIP
Loading dataset: SPG_OfficeHome
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_OfficeHome
Source     ['art', 'clipart', 'real_world']
Target     ['product']
# classes  65
# train_x  7,815
# val      3,334
# test     4,439
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/244] time 0.536 (0.417) data 0.000 (0.025) loss 1.4458 (1.4578) teacher_loss 1.4285 (1.4241) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0001 (-0.0001) kd_loss 0.0173 (0.0338) acc 62.5000 (65.0000) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3349) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0015) teacher/entropy 1.0813 (1.0648) teacher/usage_max 0.3489 (0.3519) teacher/usage_min 0.3196 (0.3186) teacher/usage_std 0.0120 (0.0147) nleep/row_max_mean 1152.6627 (1159.2144) nleep/row_max_std 48.7192 (67.0122) nleep/row_min_mean 1152.4353 (1158.7290) lr 1.0000e-05 eta 1:24:37
epoch [1/50] batch [40/244] time 0.479 (0.437) data 0.000 (0.013) loss 1.5029 (1.4214) teacher_loss 1.4985 (1.3937) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0001 (-0.0001) kd_loss 0.0045 (0.0277) acc 56.2500 (65.2344) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3349) gate/usage_min 0.3313 (0.3314) gate/usage_std 0.0015 (0.0015) teacher/entropy 1.0941 (1.0709) teacher/usage_max 0.3390 (0.3522) teacher/usage_min 0.3281 (0.3191) teacher/usage_std 0.0045 (0.0145) nleep/row_max_mean 1153.4546 (1161.3941) nleep/row_max_std 8.8329 (60.7088) nleep/row_min_mean 1153.2700 (1160.9991) lr 1.0000e-05 eta 1:28:38
epoch [1/50] batch [60/244] time 0.496 (0.451) data 0.000 (0.009) loss 1.3255 (1.4500) teacher_loss 1.3190 (1.4276) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0000 (-0.0001) kd_loss 0.0065 (0.0224) acc 65.6250 (63.9583) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3349) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0015) teacher/entropy 1.0921 (1.0762) teacher/usage_max 0.3401 (0.3498) teacher/usage_min 0.3290 (0.3209) teacher/usage_std 0.0049 (0.0126) nleep/row_max_mean 1166.8645 (1162.6622) nleep/row_max_std 44.2512 (56.7003) nleep/row_min_mean 1166.7058 (1162.3260) lr 1.0000e-05 eta 1:31:20
epoch [1/50] batch [80/244] time 0.444 (0.460) data 0.000 (0.006) loss 1.5662 (1.4538) teacher_loss 1.5640 (1.4336) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0000 (-0.0001) kd_loss 0.0021 (0.0203) acc 59.3750 (63.9453) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3349) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0015) teacher/entropy 1.0966 (1.0784) teacher/usage_max 0.3359 (0.3486) teacher/usage_min 0.3303 (0.3213) teacher/usage_std 0.0023 (0.0118) nleep/row_max_mean 1157.6450 (1163.9523) nleep/row_max_std 7.6532 (53.1577) nleep/row_min_mean 1157.5272 (1163.6456) lr 1.0000e-05 eta 1:32:56
epoch [1/50] batch [100/244] time 0.082 (0.410) data 0.000 (0.005) loss 1.5716 (1.4325) teacher_loss 1.5561 (1.4142) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0000 (-0.0001) kd_loss 0.0154 (0.0183) acc 62.5000 (64.1562) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3349) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0015 (0.0015) teacher/entropy 1.0832 (1.0803) teacher/usage_max 0.3481 (0.3478) teacher/usage_min 0.3191 (0.3217) teacher/usage_std 0.0118 (0.0112) nleep/row_max_mean 1180.3440 (1165.8628) nleep/row_max_std 58.3292 (51.4383) nleep/row_min_mean 1180.0795 (1165.5796) lr 1.0000e-05 eta 1:22:38
epoch [1/50] batch [120/244] time 0.465 (0.403) data 0.000 (0.004) loss 0.9594 (1.4164) teacher_loss 0.9569 (1.3999) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0000 (-0.0001) kd_loss 0.0025 (0.0165) acc 75.0000 (64.5052) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3349) gate/usage_min 0.3313 (0.3314) gate/usage_std 0.0015 (0.0015) teacher/entropy 1.0962 (1.0821) teacher/usage_max 0.3395 (0.3468) teacher/usage_min 0.3253 (0.3222) teacher/usage_std 0.0060 (0.0105) nleep/row_max_mean 1183.6016 (1167.2552) nleep/row_max_std 49.4199 (49.0799) nleep/row_min_mean 1183.4786 (1166.9928) lr 1.0000e-05 eta 1:21:09
epoch [1/50] batch [140/244] time 0.078 (0.374) data 0.000 (0.004) loss 1.0942 (1.3965) teacher_loss 1.0922 (1.3812) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0001 (-0.0000) kd_loss 0.0020 (0.0153) acc 75.0000 (64.9554) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3349) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0015) teacher/entropy 1.0967 (1.0833) teacher/usage_max 0.3381 (0.3462) teacher/usage_min 0.3295 (0.3224) teacher/usage_std 0.0036 (0.0102) nleep/row_max_mean 1167.4757 (1168.5078) nleep/row_max_std 9.1000 (46.7994) nleep/row_min_mean 1167.3562 (1168.2599) lr 1.0000e-05 eta 1:15:10
epoch [1/50] batch [160/244] time 0.428 (0.378) data 0.000 (0.003) loss 1.4834 (1.3869) teacher_loss 1.4823 (1.3728) loss_zs_kd 0.0001 (0.0000) loss_oracle -0.0000 (-0.0000) kd_loss 0.0011 (0.0141) acc 56.2500 (65.0977) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3349) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0015) teacher/entropy 1.0975 (1.0846) teacher/usage_max 0.3356 (0.3454) teacher/usage_min 0.3316 (0.3228) teacher/usage_std 0.0017 (0.0097) nleep/row_max_mean 1170.2822 (1169.5798) nleep/row_max_std 10.8366 (44.4516) nleep/row_min_mean 1170.1960 (1169.3453) lr 1.0000e-05 eta 1:15:55
epoch [1/50] batch [180/244] time 0.435 (0.387) data 0.000 (0.003) loss 0.9845 (1.3851) teacher_loss 0.9822 (1.3721) loss_zs_kd 0.0000 (0.0001) loss_oracle -0.0000 (-0.0000) kd_loss 0.0023 (0.0130) acc 81.2500 (65.1562) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3349) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0015) teacher/entropy 1.0964 (1.0857) teacher/usage_max 0.3365 (0.3447) teacher/usage_min 0.3298 (0.3233) teacher/usage_std 0.0027 (0.0092) nleep/row_max_mean 1177.4716 (1170.4346) nleep/row_max_std 22.5360 (42.1885) nleep/row_min_mean 1177.3660 (1170.2121) lr 1.0000e-05 eta 1:17:31
epoch [1/50] batch [200/244] time 0.445 (0.392) data 0.000 (0.003) loss 1.4933 (1.3837) teacher_loss 1.4858 (1.3712) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0000 (-0.0000) kd_loss 0.0075 (0.0125) acc 62.5000 (65.2188) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3349) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0015 (0.0015) teacher/entropy 1.0911 (1.0862) teacher/usage_max 0.3441 (0.3444) teacher/usage_min 0.3250 (0.3234) teacher/usage_std 0.0080 (0.0090) nleep/row_max_mean 1181.4473 (1171.7380) nleep/row_max_std 24.8547 (40.9737) nleep/row_min_mean 1181.2778 (1171.5220) lr 1.0000e-05 eta 1:18:20
epoch [1/50] batch [220/244] time 0.497 (0.398) data 0.000 (0.002) loss 1.2223 (1.3796) teacher_loss 1.2206 (1.3678) loss_zs_kd 0.0011 (0.0001) loss_oracle 0.0001 (-0.0000) kd_loss 0.0012 (0.0118) acc 68.7500 (65.2273) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3349) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0015 (0.0015) teacher/entropy 1.0974 (1.0869) teacher/usage_max 0.3364 (0.3441) teacher/usage_min 0.3302 (0.3236) teacher/usage_std 0.0025 (0.0087) nleep/row_max_mean 1200.0417 (1173.0647) nleep/row_max_std 43.8194 (39.8242) nleep/row_min_mean 1199.9434 (1172.8565) lr 1.0000e-05 eta 1:19:28
epoch [1/50] batch [240/244] time 0.087 (0.378) data 0.000 (0.002) loss 1.3183 (1.3754) teacher_loss 1.3129 (1.3643) loss_zs_kd 0.0002 (0.0001) loss_oracle -0.0001 (-0.0000) kd_loss 0.0054 (0.0110) acc 75.0000 (65.4167) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3349) gate/usage_min 0.3314 (0.3314) gate/usage_std 0.0014 (0.0015) teacher/entropy 1.0933 (1.0876) teacher/usage_max 0.3419 (0.3436) teacher/usage_min 0.3203 (0.3239) teacher/usage_std 0.0094 (0.0084) nleep/row_max_mean 1183.9885 (1173.9111) nleep/row_max_std 25.6649 (38.2710) nleep/row_min_mean 1183.8354 (1173.7110) lr 1.0000e-05 eta 1:15:25
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,678
* accuracy: 80.3%
* error: 19.7%
* macro_f1: 78.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,945
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 87.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      80.3%, epoch: 1 *******
******* Domain p best val test acc: 88.9%, epoch: 1 *******
******* Domain p best test acc:     88.9%, epoch: 1 *******
epoch [2/50] batch [20/244] time 0.444 (0.474) data 0.000 (0.013) loss 1.0152 (1.3744) teacher_loss 0.9948 (1.3597) loss_zs_kd 0.0154 (0.0137) loss_oracle 0.0130 (0.0054) kd_loss 0.0063 (0.0051) acc 75.0000 (65.3125) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3348) gate/usage_min 0.3315 (0.3314) gate/usage_std 0.0013 (0.0014) teacher/entropy 1.0924 (1.0936) teacher/usage_max 0.3463 (0.3423) teacher/usage_min 0.3202 (0.3242) teacher/usage_std 0.0107 (0.0076) nleep/row_max_mean 1189.7678 (1187.9345) nleep/row_max_std 24.6080 (24.1893) nleep/row_min_mean 1189.6218 (1187.8016) lr 2.0000e-03 eta 1:34:15
epoch [2/50] batch [40/244] time 0.437 (0.463) data 0.000 (0.007) loss 1.1855 (1.3214) teacher_loss 1.1391 (1.2855) loss_zs_kd 0.0100 (0.0150) loss_oracle 0.0802 (0.0490) kd_loss 0.0013 (0.0038) acc 71.8750 (66.8750) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3352 (0.3349) gate/usage_min 0.3313 (0.3314) gate/usage_std 0.0016 (0.0015) teacher/entropy 1.0974 (1.0948) teacher/usage_max 0.3458 (0.3426) teacher/usage_min 0.3245 (0.3237) teacher/usage_std 0.0090 (0.0080) nleep/row_max_mean 1187.3315 (1188.0177) nleep/row_max_std 13.8714 (22.6890) nleep/row_min_mean 1187.2245 (1187.8928) lr 2.0000e-03 eta 1:31:53
epoch [2/50] batch [60/244] time 0.500 (0.460) data 0.000 (0.004) loss 1.3586 (1.3552) teacher_loss 1.3129 (1.3173) loss_zs_kd 0.0212 (0.0158) loss_oracle 0.0670 (0.0529) kd_loss 0.0017 (0.0036) acc 68.7500 (66.1979) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3357 (0.3351) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0018 (0.0016) teacher/entropy 1.0971 (1.0950) teacher/usage_max 0.3389 (0.3421) teacher/usage_min 0.3254 (0.3241) teacher/usage_std 0.0057 (0.0076) nleep/row_max_mean 1189.0509 (1188.7383) nleep/row_max_std 18.7407 (22.0036) nleep/row_min_mean 1188.9373 (1188.6143) lr 2.0000e-03 eta 1:31:11
epoch [2/50] batch [80/244] time 0.086 (0.445) data 0.000 (0.003) loss 1.1675 (1.3067) teacher_loss 1.1290 (1.2681) loss_zs_kd 0.0200 (0.0161) loss_oracle 0.0537 (0.0537) kd_loss 0.0017 (0.0038) acc 65.6250 (67.3047) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3357 (0.3353) gate/usage_min 0.3317 (0.3314) gate/usage_std 0.0017 (0.0016) teacher/entropy 1.0971 (1.0949) teacher/usage_max 0.3389 (0.3421) teacher/usage_min 0.3241 (0.3238) teacher/usage_std 0.0066 (0.0078) nleep/row_max_mean 1194.7778 (1189.7289) nleep/row_max_std 23.8756 (22.1869) nleep/row_min_mean 1194.6643 (1189.6023) lr 2.0000e-03 eta 1:28:07
epoch [2/50] batch [100/244] time 0.487 (0.409) data 0.000 (0.003) loss 0.9010 (1.2985) teacher_loss 0.8429 (1.2550) loss_zs_kd 0.0136 (0.0168) loss_oracle 0.0974 (0.0629) kd_loss 0.0027 (0.0037) acc 81.2500 (67.5625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3359 (0.3354) gate/usage_min 0.3318 (0.3314) gate/usage_std 0.0019 (0.0016) teacher/entropy 1.0960 (1.0950) teacher/usage_max 0.3565 (0.3431) teacher/usage_min 0.3216 (0.3233) teacher/usage_std 0.0164 (0.0084) nleep/row_max_mean 1194.7722 (1190.2579) nleep/row_max_std 18.6792 (21.8633) nleep/row_min_mean 1194.6272 (1190.1289) lr 2.0000e-03 eta 1:20:44
epoch [2/50] batch [120/244] time 0.448 (0.385) data 0.000 (0.002) loss 1.6319 (1.2755) teacher_loss 1.5476 (1.2294) loss_zs_kd 0.0181 (0.0166) loss_oracle 0.1317 (0.0673) kd_loss 0.0094 (0.0041) acc 71.8750 (68.2552) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3360 (0.3355) gate/usage_min 0.3316 (0.3315) gate/usage_std 0.0019 (0.0017) teacher/entropy 1.0894 (1.0946) teacher/usage_max 0.3751 (0.3473) teacher/usage_min 0.3101 (0.3216) teacher/usage_std 0.0296 (0.0111) nleep/row_max_mean 1193.5654 (1190.5946) nleep/row_max_std 19.0907 (21.3358) nleep/row_min_mean 1193.3081 (1190.4524) lr 2.0000e-03 eta 1:15:55
epoch [2/50] batch [140/244] time 0.447 (0.381) data 0.000 (0.002) loss 1.1629 (1.2757) teacher_loss 0.9928 (1.2205) loss_zs_kd 0.0291 (0.0170) loss_oracle 0.2919 (0.0840) kd_loss 0.0096 (0.0047) acc 71.8750 (68.4821) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3366 (0.3356) gate/usage_min 0.3307 (0.3314) gate/usage_std 0.0025 (0.0018) teacher/entropy 1.0888 (1.0940) teacher/usage_max 0.3728 (0.3509) teacher/usage_min 0.2937 (0.3188) teacher/usage_std 0.0323 (0.0138) nleep/row_max_mean 1196.9049 (1191.1604) nleep/row_max_std 18.8294 (20.7836) nleep/row_min_mean 1196.6344 (1191.0023) lr 2.0000e-03 eta 1:15:05
epoch [2/50] batch [160/244] time 0.455 (0.390) data 0.000 (0.002) loss 1.3368 (1.2930) teacher_loss 1.1910 (1.2260) loss_zs_kd 0.0116 (0.0176) loss_oracle 0.2486 (0.1055) kd_loss 0.0158 (0.0054) acc 75.0000 (68.1250) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3382 (0.3358) gate/usage_min 0.3296 (0.3313) gate/usage_std 0.0036 (0.0019) teacher/entropy 1.0824 (1.0932) teacher/usage_max 0.3920 (0.3540) teacher/usage_min 0.2731 (0.3150) teacher/usage_std 0.0486 (0.0165) nleep/row_max_mean 1200.2979 (1191.5315) nleep/row_max_std 20.3968 (20.2877) nleep/row_min_mean 1199.9071 (1191.3547) lr 2.0000e-03 eta 1:16:36
epoch [2/50] batch [180/244] time 0.436 (0.395) data 0.000 (0.002) loss 1.1025 (1.2813) teacher_loss 1.0152 (1.2107) loss_zs_kd 0.0221 (0.0180) loss_oracle 0.1100 (0.1105) kd_loss 0.0212 (0.0064) acc 62.5000 (68.4896) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3393 (0.3361) gate/usage_min 0.3287 (0.3310) gate/usage_std 0.0044 (0.0022) teacher/entropy 1.0771 (1.0922) teacher/usage_max 0.3902 (0.3567) teacher/usage_min 0.2818 (0.3110) teacher/usage_std 0.0444 (0.0193) nleep/row_max_mean 1199.3232 (1192.0963) nleep/row_max_std 23.0829 (20.1517) nleep/row_min_mean 1198.9211 (1191.8987) lr 2.0000e-03 eta 1:17:27
epoch [2/50] batch [200/244] time 0.453 (0.402) data 0.000 (0.001) loss 1.4798 (1.2930) teacher_loss 1.4129 (1.2201) loss_zs_kd 0.0063 (0.0187) loss_oracle 0.0850 (0.1119) kd_loss 0.0212 (0.0076) acc 62.5000 (68.2969) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3398 (0.3365) gate/usage_min 0.3276 (0.3307) gate/usage_std 0.0050 (0.0024) teacher/entropy 1.0765 (1.0909) teacher/usage_max 0.3986 (0.3601) teacher/usage_min 0.2670 (0.3070) teacher/usage_std 0.0537 (0.0223) nleep/row_max_mean 1194.7104 (1192.3082) nleep/row_max_std 13.7750 (19.8284) nleep/row_min_mean 1194.2646 (1192.0888) lr 2.0000e-03 eta 1:18:46
epoch [2/50] batch [220/244] time 0.112 (0.390) data 0.000 (0.001) loss 1.0778 (1.2875) teacher_loss 0.9985 (1.2144) loss_zs_kd 0.0423 (0.0187) loss_oracle 0.0701 (0.1092) kd_loss 0.0231 (0.0091) acc 78.1250 (68.3949) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3402 (0.3368) gate/usage_min 0.3263 (0.3304) gate/usage_std 0.0057 (0.0027) teacher/entropy 1.0740 (1.0893) teacher/usage_max 0.4064 (0.3640) teacher/usage_min 0.2591 (0.3025) teacher/usage_std 0.0601 (0.0257) nleep/row_max_mean 1197.0706 (1192.6798) nleep/row_max_std 18.3390 (19.5644) nleep/row_min_mean 1196.5750 (1192.4353) lr 2.0000e-03 eta 1:16:11
epoch [2/50] batch [240/244] time 0.371 (0.390) data 0.000 (0.001) loss 1.4624 (1.2866) teacher_loss 1.3443 (1.2119) loss_zs_kd 0.0330 (0.0187) loss_oracle 0.1374 (0.1088) kd_loss 0.0329 (0.0110) acc 65.6250 (68.2943) gate/entropy 1.0984 (1.0986) gate/usage_max 0.3408 (0.3371) gate/usage_min 0.3253 (0.3300) gate/usage_std 0.0063 (0.0030) teacher/entropy 1.0635 (1.0873) teacher/usage_max 0.4118 (0.3682) teacher/usage_min 0.2471 (0.2980) teacher/usage_std 0.0675 (0.0293) nleep/row_max_mean 1192.7439 (1193.0720) nleep/row_max_std 19.0136 (19.3360) nleep/row_min_mean 1192.1705 (1192.8008) lr 2.0000e-03 eta 1:16:09
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,801
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,050
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      84.0%, epoch: 2 *******
******* Domain p best val test acc: 91.2%, epoch: 2 *******
******* Domain p best test acc:     91.2%, epoch: 2 *******
epoch [3/50] batch [20/244] time 0.454 (0.475) data 0.000 (0.013) loss 1.2921 (1.2855) teacher_loss 1.1832 (1.1733) loss_zs_kd 0.0246 (0.0250) loss_oracle 0.1090 (0.1151) kd_loss 0.0421 (0.0421) acc 62.5000 (69.6875) gate/entropy 1.0984 (1.0984) gate/usage_max 0.3411 (0.3410) gate/usage_min 0.3237 (0.3244) gate/usage_std 0.0072 (0.0069) teacher/entropy 1.0533 (1.0538) teacher/usage_max 0.4319 (0.4363) teacher/usage_min 0.2371 (0.2370) teacher/usage_std 0.0795 (0.0818) nleep/row_max_mean 1195.4897 (1197.3195) nleep/row_max_std 17.0923 (16.0905) nleep/row_min_mean 1194.8444 (1196.6684) lr 1.9980e-03 eta 1:32:36
epoch [3/50] batch [40/244] time 0.440 (0.471) data 0.000 (0.007) loss 0.8286 (1.2908) teacher_loss 0.7381 (1.1835) loss_zs_kd 0.0089 (0.0232) loss_oracle 0.0730 (0.0978) kd_loss 0.0495 (0.0467) acc 78.1250 (70.0000) gate/entropy 1.0983 (1.0984) gate/usage_max 0.3413 (0.3411) gate/usage_min 0.3225 (0.3237) gate/usage_std 0.0079 (0.0072) teacher/entropy 1.0454 (1.0487) teacher/usage_max 0.4503 (0.4421) teacher/usage_min 0.2312 (0.2329) teacher/usage_std 0.0901 (0.0859) nleep/row_max_mean 1195.2397 (1197.6841) nleep/row_max_std 16.0706 (16.0479) nleep/row_min_mean 1194.5349 (1196.9981) lr 1.9980e-03 eta 1:31:39
epoch [3/50] batch [60/244] time 0.444 (0.465) data 0.001 (0.005) loss 0.8758 (1.2645) teacher_loss 0.7356 (1.1527) loss_zs_kd 0.0239 (0.0208) loss_oracle 0.1588 (0.1024) kd_loss 0.0488 (0.0502) acc 81.2500 (69.8958) gate/entropy 1.0983 (1.0984) gate/usage_max 0.3415 (0.3412) gate/usage_min 0.3214 (0.3231) gate/usage_std 0.0086 (0.0076) teacher/entropy 1.0454 (1.0449) teacher/usage_max 0.4452 (0.4465) teacher/usage_min 0.2304 (0.2306) teacher/usage_std 0.0879 (0.0887) nleep/row_max_mean 1195.7252 (1197.9992) nleep/row_max_std 16.1235 (16.3031) nleep/row_min_mean 1195.0208 (1197.2912) lr 1.9980e-03 eta 1:30:22
epoch [3/50] batch [80/244] time 0.368 (0.390) data 0.000 (0.003) loss 1.6262 (1.3110) teacher_loss 1.5045 (1.1916) loss_zs_kd 0.0136 (0.0224) loss_oracle 0.1260 (0.1073) kd_loss 0.0518 (0.0545) acc 65.6250 (69.2578) gate/entropy 1.0982 (1.0983) gate/usage_max 0.3416 (0.3413) gate/usage_min 0.3203 (0.3225) gate/usage_std 0.0093 (0.0079) teacher/entropy 1.0418 (1.0401) teacher/usage_max 0.4602 (0.4529) teacher/usage_min 0.2292 (0.2268) teacher/usage_std 0.0956 (0.0930) nleep/row_max_mean 1193.3638 (1197.8001) nleep/row_max_std 11.7461 (15.7937) nleep/row_min_mean 1192.6266 (1197.0602) lr 1.9980e-03 eta 1:15:34
epoch [3/50] batch [100/244] time 0.083 (0.388) data 0.000 (0.003) loss 1.7835 (1.3106) teacher_loss 1.6038 (1.1798) loss_zs_kd 0.0473 (0.0220) loss_oracle 0.2132 (0.1275) kd_loss 0.0494 (0.0561) acc 53.1250 (69.5312) gate/entropy 1.0981 (1.0983) gate/usage_max 0.3423 (0.3415) gate/usage_min 0.3186 (0.3219) gate/usage_std 0.0105 (0.0084) teacher/entropy 1.0443 (1.0383) teacher/usage_max 0.4465 (0.4555) teacher/usage_min 0.2443 (0.2269) teacher/usage_std 0.0843 (0.0943) nleep/row_max_mean 1199.1046 (1198.0001) nleep/row_max_std 14.9186 (15.5858) nleep/row_min_mean 1198.3813 (1197.2510) lr 1.9980e-03 eta 1:15:00
epoch [3/50] batch [120/244] time 0.510 (0.365) data 0.000 (0.002) loss 0.9771 (1.3179) teacher_loss 0.7911 (1.1784) loss_zs_kd 0.0282 (0.0225) loss_oracle 0.2325 (0.1451) kd_loss 0.0557 (0.0557) acc 78.1250 (69.4792) gate/entropy 1.0980 (1.0982) gate/usage_max 0.3429 (0.3417) gate/usage_min 0.3171 (0.3212) gate/usage_std 0.0116 (0.0088) teacher/entropy 1.0401 (1.0386) teacher/usage_max 0.4521 (0.4544) teacher/usage_min 0.2716 (0.2315) teacher/usage_std 0.0840 (0.0926) nleep/row_max_mean 1202.0663 (1198.2375) nleep/row_max_std 16.1598 (15.5693) nleep/row_min_mean 1201.3292 (1197.4948) lr 1.9980e-03 eta 1:10:27
epoch [3/50] batch [140/244] time 0.435 (0.379) data 0.000 (0.002) loss 1.3844 (1.3128) teacher_loss 1.2476 (1.1693) loss_zs_kd 0.0096 (0.0220) loss_oracle 0.1585 (0.1535) kd_loss 0.0528 (0.0557) acc 68.7500 (69.7991) gate/entropy 1.0979 (1.0982) gate/usage_max 0.3436 (0.3419) gate/usage_min 0.3159 (0.3205) gate/usage_std 0.0124 (0.0093) teacher/entropy 1.0445 (1.0388) teacher/usage_max 0.4427 (0.4535) teacher/usage_min 0.2576 (0.2364) teacher/usage_std 0.0792 (0.0910) nleep/row_max_mean 1204.6941 (1198.6452) nleep/row_max_std 15.2731 (15.5343) nleep/row_min_mean 1203.9973 (1197.9073) lr 1.9980e-03 eta 1:13:06
epoch [3/50] batch [160/244] time 0.468 (0.388) data 0.000 (0.002) loss 1.3032 (1.3249) teacher_loss 1.1478 (1.1801) loss_zs_kd 0.0199 (0.0218) loss_oracle 0.1692 (0.1548) kd_loss 0.0608 (0.0565) acc 71.8750 (69.5508) gate/entropy 1.0978 (1.0982) gate/usage_max 0.3438 (0.3421) gate/usage_min 0.3148 (0.3199) gate/usage_std 0.0132 (0.0097) teacher/entropy 1.0343 (1.0381) teacher/usage_max 0.4335 (0.4536) teacher/usage_min 0.2767 (0.2400) teacher/usage_std 0.0710 (0.0904) nleep/row_max_mean 1202.8176 (1198.9470) nleep/row_max_std 17.0931 (15.5895) nleep/row_min_mean 1202.0474 (1198.2071) lr 1.9980e-03 eta 1:14:36
epoch [3/50] batch [180/244] time 0.479 (0.397) data 0.000 (0.002) loss 1.1463 (1.3179) teacher_loss 0.9877 (1.1722) loss_zs_kd 0.0318 (0.0217) loss_oracle 0.1268 (0.1545) kd_loss 0.0793 (0.0576) acc 68.7500 (69.8438) gate/entropy 1.0978 (1.0981) gate/usage_max 0.3436 (0.3423) gate/usage_min 0.3142 (0.3193) gate/usage_std 0.0136 (0.0101) teacher/entropy 1.0152 (1.0370) teacher/usage_max 0.4816 (0.4536) teacher/usage_min 0.2467 (0.2424) teacher/usage_std 0.1053 (0.0899) nleep/row_max_mean 1203.8004 (1199.2075) nleep/row_max_std 18.8738 (15.5696) nleep/row_min_mean 1202.9583 (1198.4638) lr 1.9980e-03 eta 1:16:14
epoch [3/50] batch [200/244] time 0.091 (0.396) data 0.000 (0.001) loss 1.4225 (1.3165) teacher_loss 1.2239 (1.1695) loss_zs_kd 0.0196 (0.0216) loss_oracle 0.2077 (0.1539) kd_loss 0.0850 (0.0592) acc 71.8750 (69.8594) gate/entropy 1.0977 (1.0981) gate/usage_max 0.3434 (0.3424) gate/usage_min 0.3136 (0.3187) gate/usage_std 0.0140 (0.0105) teacher/entropy 1.0097 (1.0355) teacher/usage_max 0.4663 (0.4545) teacher/usage_min 0.2527 (0.2436) teacher/usage_std 0.0947 (0.0902) nleep/row_max_mean 1198.7936 (1199.2685) nleep/row_max_std 18.0152 (15.5033) nleep/row_min_mean 1197.9081 (1198.5160) lr 1.9980e-03 eta 1:15:53
epoch [3/50] batch [220/244] time 0.509 (0.384) data 0.000 (0.001) loss 1.4066 (1.3241) teacher_loss 1.2474 (1.1732) loss_zs_kd 0.0166 (0.0217) loss_oracle 0.1057 (0.1563) kd_loss 0.0980 (0.0619) acc 71.8750 (69.8153) gate/entropy 1.0976 (1.0981) gate/usage_max 0.3454 (0.3426) gate/usage_min 0.3129 (0.3182) gate/usage_std 0.0146 (0.0108) teacher/entropy 0.9954 (1.0327) teacher/usage_max 0.5018 (0.4573) teacher/usage_min 0.2143 (0.2427) teacher/usage_std 0.1225 (0.0919) nleep/row_max_mean 1200.2869 (1199.2903) nleep/row_max_std 14.0347 (15.4069) nleep/row_min_mean 1199.2717 (1198.5217) lr 1.9980e-03 eta 1:13:27
epoch [3/50] batch [240/244] time 0.488 (0.374) data 0.000 (0.001) loss 0.9754 (1.3229) teacher_loss 0.8174 (1.1700) loss_zs_kd 0.0165 (0.0218) loss_oracle 0.0774 (0.1528) kd_loss 0.1111 (0.0656) acc 71.8750 (69.7917) gate/entropy 1.0976 (1.0980) gate/usage_max 0.3472 (0.3429) gate/usage_min 0.3122 (0.3178) gate/usage_std 0.0152 (0.0112) teacher/entropy 0.9796 (1.0288) teacher/usage_max 0.5252 (0.4616) teacher/usage_min 0.2021 (0.2409) teacher/usage_std 0.1387 (0.0948) nleep/row_max_mean 1202.9342 (1199.3151) nleep/row_max_std 15.4259 (15.3269) nleep/row_min_mean 1201.8044 (1198.5247) lr 1.9980e-03 eta 1:11:31
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,804
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 82.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,056
* accuracy: 91.4%
* error: 8.6%
* macro_f1: 91.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      84.1%, epoch: 3 *******
******* Domain p best val test acc: 91.4%, epoch: 3 *******
******* Domain p best test acc:     91.4%, epoch: 3 *******
epoch [4/50] batch [20/244] time 0.502 (0.497) data 0.000 (0.016) loss 1.5925 (1.4002) teacher_loss 1.4344 (1.1994) loss_zs_kd 0.0230 (0.0242) loss_oracle 0.1124 (0.1591) kd_loss 0.0904 (0.1091) acc 59.3750 (68.1250) gate/entropy 1.0974 (1.0975) gate/usage_max 0.3490 (0.3483) gate/usage_min 0.3112 (0.3118) gate/usage_std 0.0161 (0.0156) teacher/entropy 1.0008 (0.9807) teacher/usage_max 0.4839 (0.5116) teacher/usage_min 0.2349 (0.2194) teacher/usage_std 0.1081 (0.1279) nleep/row_max_mean 1198.4196 (1198.4920) nleep/row_max_std 14.5773 (14.1308) nleep/row_min_mean 1197.4580 (1197.4285) lr 1.9921e-03 eta 1:34:54
epoch [4/50] batch [40/244] time 0.496 (0.482) data 0.000 (0.008) loss 0.9408 (1.3513) teacher_loss 0.7363 (1.1527) loss_zs_kd 0.0200 (0.0224) loss_oracle 0.1112 (0.1462) kd_loss 0.1389 (0.1144) acc 87.5000 (69.2188) gate/entropy 1.0973 (1.0974) gate/usage_max 0.3507 (0.3491) gate/usage_min 0.3105 (0.3113) gate/usage_std 0.0169 (0.0160) teacher/entropy 0.9442 (0.9742) teacher/usage_max 0.5655 (0.5201) teacher/usage_min 0.2014 (0.2155) teacher/usage_std 0.1647 (0.1339) nleep/row_max_mean 1202.0193 (1199.6020) nleep/row_max_std 14.9575 (14.1182) nleep/row_min_mean 1200.7991 (1198.5062) lr 1.9921e-03 eta 1:31:47
epoch [4/50] batch [60/244] time 0.082 (0.444) data 0.000 (0.005) loss 1.5725 (1.3420) teacher_loss 1.3555 (1.1269) loss_zs_kd 0.0386 (0.0229) loss_oracle 0.1237 (0.1533) kd_loss 0.1358 (0.1270) acc 59.3750 (70.3125) gate/entropy 1.0972 (1.0974) gate/usage_max 0.3528 (0.3500) gate/usage_min 0.3096 (0.3109) gate/usage_std 0.0179 (0.0165) teacher/entropy 0.9454 (0.9592) teacher/usage_max 0.5567 (0.5365) teacher/usage_min 0.2131 (0.2110) teacher/usage_std 0.1581 (0.1450) nleep/row_max_mean 1199.3999 (1199.7836) nleep/row_max_std 16.4329 (14.5277) nleep/row_min_mean 1198.1476 (1198.6229) lr 1.9921e-03 eta 1:24:22
epoch [4/50] batch [80/244] time 0.452 (0.396) data 0.000 (0.004) loss 2.0256 (1.3578) teacher_loss 1.7167 (1.1292) loss_zs_kd 0.0319 (0.0243) loss_oracle 0.1201 (0.1499) kd_loss 0.2329 (0.1414) acc 53.1250 (70.5469) gate/entropy 1.0970 (1.0973) gate/usage_max 0.3554 (0.3511) gate/usage_min 0.3089 (0.3105) gate/usage_std 0.0191 (0.0170) teacher/entropy 0.8373 (0.9421) teacher/usage_max 0.6453 (0.5535) teacher/usage_min 0.1696 (0.2050) teacher/usage_std 0.2207 (0.1568) nleep/row_max_mean 1201.5941 (1199.6751) nleep/row_max_std 14.6361 (14.6137) nleep/row_min_mean 1199.9641 (1198.4452) lr 1.9921e-03 eta 1:15:08
epoch [4/50] batch [100/244] time 0.449 (0.373) data 0.000 (0.003) loss 1.6293 (1.3914) teacher_loss 1.3689 (1.1520) loss_zs_kd 0.0235 (0.0246) loss_oracle 0.1506 (0.1474) kd_loss 0.1733 (0.1533) acc 71.8750 (69.8750) gate/entropy 1.0967 (1.0972) gate/usage_max 0.3581 (0.3522) gate/usage_min 0.3078 (0.3101) gate/usage_std 0.0205 (0.0176) teacher/entropy 0.8972 (0.9277) teacher/usage_max 0.6108 (0.5671) teacher/usage_min 0.1874 (0.1995) teacher/usage_std 0.1963 (0.1662) nleep/row_max_mean 1200.1995 (1199.7635) nleep/row_max_std 15.9834 (14.6252) nleep/row_min_mean 1198.8335 (1198.4750) lr 1.9921e-03 eta 1:10:40
epoch [4/50] batch [120/244] time 0.494 (0.374) data 0.000 (0.003) loss 1.3034 (1.4067) teacher_loss 1.0524 (1.1596) loss_zs_kd 0.0179 (0.0252) loss_oracle 0.0962 (0.1458) kd_loss 0.1940 (0.1616) acc 75.0000 (69.8177) gate/entropy 1.0965 (1.0971) gate/usage_max 0.3601 (0.3533) gate/usage_min 0.3070 (0.3096) gate/usage_std 0.0217 (0.0182) teacher/entropy 0.8722 (0.9173) teacher/usage_max 0.6288 (0.5767) teacher/usage_min 0.1779 (0.1957) teacher/usage_std 0.2090 (0.1729) nleep/row_max_mean 1198.7651 (1199.8725) nleep/row_max_std 16.8594 (14.7644) nleep/row_min_mean 1197.2034 (1198.5379) lr 1.9921e-03 eta 1:10:44
epoch [4/50] batch [140/244] time 0.461 (0.383) data 0.000 (0.002) loss 1.1339 (1.3965) teacher_loss 0.8149 (1.1448) loss_zs_kd 0.0213 (0.0251) loss_oracle 0.1438 (0.1415) kd_loss 0.2365 (0.1684) acc 78.1250 (70.2455) gate/entropy 1.0962 (1.0970) gate/usage_max 0.3626 (0.3545) gate/usage_min 0.3062 (0.3092) gate/usage_std 0.0231 (0.0188) teacher/entropy 0.8265 (0.9084) teacher/usage_max 0.6291 (0.5844) teacher/usage_min 0.1790 (0.1925) teacher/usage_std 0.2092 (0.1783) nleep/row_max_mean 1200.6174 (1199.9661) nleep/row_max_std 14.8651 (14.9908) nleep/row_min_mean 1198.9491 (1198.5970) lr 1.9921e-03 eta 1:12:18
epoch [4/50] batch [160/244] time 0.485 (0.397) data 0.000 (0.002) loss 1.2573 (1.4042) teacher_loss 0.9922 (1.1473) loss_zs_kd 0.0264 (0.0251) loss_oracle 0.1533 (0.1388) kd_loss 0.1753 (0.1750) acc 68.7500 (69.8828) gate/entropy 1.0958 (1.0969) gate/usage_max 0.3657 (0.3557) gate/usage_min 0.3051 (0.3087) gate/usage_std 0.0249 (0.0194) teacher/entropy 0.8864 (0.8997) teacher/usage_max 0.6096 (0.5917) teacher/usage_min 0.1923 (0.1890) teacher/usage_std 0.1953 (0.1834) nleep/row_max_mean 1199.7639 (1200.0272) nleep/row_max_std 16.7003 (15.0773) nleep/row_min_mean 1198.3826 (1198.6240) lr 1.9921e-03 eta 1:14:48
epoch [4/50] batch [180/244] time 0.470 (0.406) data 0.000 (0.002) loss 0.9805 (1.3944) teacher_loss 0.6110 (1.1327) loss_zs_kd 0.0103 (0.0248) loss_oracle 0.1374 (0.1375) kd_loss 0.2956 (0.1805) acc 81.2500 (70.3646) gate/entropy 1.0955 (1.0967) gate/usage_max 0.3683 (0.3570) gate/usage_min 0.3043 (0.3083) gate/usage_std 0.0265 (0.0201) teacher/entropy 0.7523 (0.8921) teacher/usage_max 0.6885 (0.5978) teacher/usage_min 0.1423 (0.1857) teacher/usage_std 0.2514 (0.1877) nleep/row_max_mean 1205.0596 (1200.2585) nleep/row_max_std 16.4825 (15.2518) nleep/row_min_mean 1203.0481 (1198.8220) lr 1.9921e-03 eta 1:16:28
epoch [4/50] batch [200/244] time 0.104 (0.384) data 0.000 (0.002) loss 1.5857 (1.3938) teacher_loss 1.2346 (1.1287) loss_zs_kd 0.0253 (0.0246) loss_oracle 0.1776 (0.1369) kd_loss 0.2497 (0.1843) acc 78.1250 (70.4531) gate/entropy 1.0951 (1.0966) gate/usage_max 0.3707 (0.3582) gate/usage_min 0.3036 (0.3078) gate/usage_std 0.0279 (0.0208) teacher/entropy 0.8005 (0.8864) teacher/usage_max 0.6622 (0.6027) teacher/usage_min 0.1381 (0.1828) teacher/usage_std 0.2339 (0.1911) nleep/row_max_mean 1202.5349 (1200.2811) nleep/row_max_std 18.0208 (15.3257) nleep/row_min_mean 1200.5354 (1198.8166) lr 1.9921e-03 eta 1:12:09
epoch [4/50] batch [220/244] time 0.080 (0.385) data 0.000 (0.002) loss 2.1167 (1.3850) teacher_loss 1.7363 (1.1183) loss_zs_kd 0.0172 (0.0245) loss_oracle 0.1285 (0.1345) kd_loss 0.3075 (0.1872) acc 62.5000 (70.6818) gate/entropy 1.0947 (1.0964) gate/usage_max 0.3732 (0.3595) gate/usage_min 0.3026 (0.3074) gate/usage_std 0.0295 (0.0216) teacher/entropy 0.7324 (0.8817) teacher/usage_max 0.7053 (0.6061) teacher/usage_min 0.1099 (0.1808) teacher/usage_std 0.2648 (0.1936) nleep/row_max_mean 1202.1790 (1200.3186) nleep/row_max_std 17.2640 (15.3062) nleep/row_min_mean 1200.0093 (1198.8328) lr 1.9921e-03 eta 1:12:13
epoch [4/50] batch [240/244] time 0.440 (0.372) data 0.000 (0.001) loss 1.6123 (1.3868) teacher_loss 1.2702 (1.1168) loss_zs_kd 0.0280 (0.0246) loss_oracle 0.1406 (0.1350) kd_loss 0.2578 (0.1903) acc 65.6250 (70.6250) gate/entropy 1.0943 (1.0963) gate/usage_max 0.3757 (0.3608) gate/usage_min 0.3017 (0.3069) gate/usage_std 0.0312 (0.0223) teacher/entropy 0.7841 (0.8767) teacher/usage_max 0.6651 (0.6099) teacher/usage_min 0.1563 (0.1789) teacher/usage_std 0.2348 (0.1962) nleep/row_max_mean 1204.1317 (1200.3422) nleep/row_max_std 18.8200 (15.2827) nleep/row_min_mean 1202.1909 (1198.8342) lr 1.9921e-03 eta 1:09:39
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,812
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,043
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 90.6%
******* Domain p best val acc:      84.3%, epoch: 4 *******
******* Domain p best val test acc: 91.1%, epoch: 4 *******
******* Domain p best test acc:     91.4%, epoch: 3 *******
epoch [5/50] batch [20/244] time 0.477 (0.452) data 0.000 (0.014) loss 1.7682 (1.5042) teacher_loss 1.4375 (1.1589) loss_zs_kd 0.0145 (0.0285) loss_oracle 0.1619 (0.1484) kd_loss 0.2425 (0.2568) acc 68.7500 (69.5312) gate/entropy 1.0936 (1.0939) gate/usage_max 0.3792 (0.3778) gate/usage_min 0.3000 (0.3007) gate/usage_std 0.0335 (0.0326) teacher/entropy 0.7953 (0.7802) teacher/usage_max 0.6645 (0.6787) teacher/usage_min 0.1555 (0.1462) teacher/usage_std 0.2344 (0.2446) nleep/row_max_mean 1199.4138 (1200.6879) nleep/row_max_std 17.2318 (15.8754) nleep/row_min_mean 1197.5880 (1198.7825) lr 1.9823e-03 eta 1:24:29
epoch [5/50] batch [40/244] time 0.475 (0.456) data 0.000 (0.007) loss 1.3489 (1.4220) teacher_loss 1.0327 (1.0674) loss_zs_kd 0.0312 (0.0265) loss_oracle 0.1499 (0.1522) kd_loss 0.2256 (0.2653) acc 71.8750 (72.2656) gate/entropy 1.0929 (1.0936) gate/usage_max 0.3825 (0.3793) gate/usage_min 0.2984 (0.2999) gate/usage_std 0.0358 (0.0336) teacher/entropy 0.8084 (0.7676) teacher/usage_max 0.6590 (0.6879) teacher/usage_min 0.1697 (0.1438) teacher/usage_std 0.2303 (0.2510) nleep/row_max_mean 1198.3091 (1201.5275) nleep/row_max_std 13.1332 (15.9795) nleep/row_min_mean 1196.5768 (1199.5876) lr 1.9823e-03 eta 1:25:01
epoch [5/50] batch [60/244] time 0.110 (0.404) data 0.001 (0.005) loss 1.4778 (1.4335) teacher_loss 1.0221 (1.0667) loss_zs_kd 0.0490 (0.0265) loss_oracle 0.2252 (0.1606) kd_loss 0.3186 (0.2732) acc 68.7500 (71.3542) gate/entropy 1.0922 (1.0933) gate/usage_max 0.3858 (0.3810) gate/usage_min 0.2968 (0.2991) gate/usage_std 0.0381 (0.0347) teacher/entropy 0.6978 (0.7558) teacher/usage_max 0.7208 (0.6950) teacher/usage_min 0.1377 (0.1419) teacher/usage_std 0.2740 (0.2559) nleep/row_max_mean 1199.2479 (1201.5174) nleep/row_max_std 16.6414 (16.1137) nleep/row_min_mean 1196.9724 (1199.5378) lr 1.9823e-03 eta 1:15:14
epoch [5/50] batch [80/244] time 0.472 (0.398) data 0.000 (0.004) loss 1.7917 (1.4501) teacher_loss 1.3206 (1.0674) loss_zs_kd 0.0340 (0.0274) loss_oracle 0.2165 (0.1653) kd_loss 0.3459 (0.2864) acc 68.7500 (71.7188) gate/entropy 1.0913 (1.0929) gate/usage_max 0.3899 (0.3827) gate/usage_min 0.2950 (0.2983) gate/usage_std 0.0408 (0.0359) teacher/entropy 0.6615 (0.7379) teacher/usage_max 0.7381 (0.7052) teacher/usage_min 0.1156 (0.1378) teacher/usage_std 0.2865 (0.2632) nleep/row_max_mean 1205.8837 (1201.5866) nleep/row_max_std 20.2044 (16.2024) nleep/row_min_mean 1203.5005 (1199.5395) lr 1.9823e-03 eta 1:13:57
epoch [5/50] batch [100/244] time 0.085 (0.358) data 0.000 (0.003) loss 1.8377 (1.4653) teacher_loss 1.4604 (1.0732) loss_zs_kd 0.0319 (0.0277) loss_oracle 0.1902 (0.1692) kd_loss 0.2663 (0.2936) acc 71.8750 (71.7812) gate/entropy 1.0902 (1.0924) gate/usage_max 0.3941 (0.3846) gate/usage_min 0.2933 (0.2975) gate/usage_std 0.0437 (0.0372) teacher/entropy 0.7444 (0.7265) teacher/usage_max 0.6973 (0.7111) teacher/usage_min 0.1506 (0.1359) teacher/usage_std 0.2574 (0.2673) nleep/row_max_mean 1197.4481 (1201.3102) nleep/row_max_std 15.6087 (16.3953) nleep/row_min_mean 1195.4143 (1199.2190) lr 1.9823e-03 eta 1:06:24
epoch [5/50] batch [120/244] time 0.502 (0.368) data 0.000 (0.003) loss 1.4643 (1.4945) teacher_loss 1.0181 (1.0896) loss_zs_kd 0.0413 (0.0276) loss_oracle 0.1717 (0.1730) kd_loss 0.3397 (0.3045) acc 71.8750 (71.1198) gate/entropy 1.0892 (1.0920) gate/usage_max 0.3978 (0.3865) gate/usage_min 0.2917 (0.2966) gate/usage_std 0.0462 (0.0385) teacher/entropy 0.6511 (0.7106) teacher/usage_max 0.7505 (0.7201) teacher/usage_min 0.1167 (0.1316) teacher/usage_std 0.2951 (0.2736) nleep/row_max_mean 1199.5203 (1201.3434) nleep/row_max_std 14.4626 (16.3677) nleep/row_min_mean 1197.1201 (1199.1884) lr 1.9823e-03 eta 1:08:11
epoch [5/50] batch [140/244] time 0.478 (0.387) data 0.000 (0.002) loss 1.7357 (1.5062) teacher_loss 1.2152 (1.0894) loss_zs_kd 0.0274 (0.0269) loss_oracle 0.2303 (0.1725) kd_loss 0.3917 (0.3171) acc 62.5000 (71.0714) gate/entropy 1.0881 (1.0915) gate/usage_max 0.4019 (0.3884) gate/usage_min 0.2900 (0.2958) gate/usage_std 0.0490 (0.0398) teacher/entropy 0.5872 (0.6925) teacher/usage_max 0.7718 (0.7304) teacher/usage_min 0.1107 (0.1269) teacher/usage_std 0.3100 (0.2809) nleep/row_max_mean 1207.7952 (1201.4157) nleep/row_max_std 19.1965 (16.4642) nleep/row_min_mean 1205.1313 (1199.1889) lr 1.9823e-03 eta 1:11:30
epoch [5/50] batch [160/244] time 0.495 (0.400) data 0.000 (0.002) loss 1.3268 (1.5239) teacher_loss 0.8967 (1.1003) loss_zs_kd 0.0194 (0.0262) loss_oracle 0.3335 (0.1767) kd_loss 0.2537 (0.3221) acc 78.1250 (70.6641) gate/entropy 1.0870 (1.0910) gate/usage_max 0.4053 (0.3904) gate/usage_min 0.2883 (0.2950) gate/usage_std 0.0514 (0.0411) teacher/entropy 0.7397 (0.6834) teacher/usage_max 0.7068 (0.7355) teacher/usage_min 0.1380 (0.1247) teacher/usage_std 0.2642 (0.2845) nleep/row_max_mean 1197.8292 (1201.0475) nleep/row_max_std 14.7462 (16.4182) nleep/row_min_mean 1195.7632 (1198.7818) lr 1.9823e-03 eta 1:13:51
epoch [5/50] batch [180/244] time 0.082 (0.403) data 0.000 (0.002) loss 1.8980 (1.5302) teacher_loss 1.3635 (1.1013) loss_zs_kd 0.0343 (0.0259) loss_oracle 0.1722 (0.1770) kd_loss 0.4313 (0.3274) acc 65.6250 (70.8160) gate/entropy 1.0858 (1.0905) gate/usage_max 0.4090 (0.3922) gate/usage_min 0.2864 (0.2941) gate/usage_std 0.0540 (0.0424) teacher/entropy 0.5246 (0.6737) teacher/usage_max 0.8112 (0.7411) teacher/usage_min 0.0880 (0.1219) teacher/usage_std 0.3380 (0.2884) nleep/row_max_mean 1204.7910 (1200.9023) nleep/row_max_std 15.3228 (16.3057) nleep/row_min_mean 1201.8970 (1198.5956) lr 1.9823e-03 eta 1:14:09
epoch [5/50] batch [200/244] time 0.490 (0.386) data 0.000 (0.002) loss 1.6582 (1.5339) teacher_loss 1.1570 (1.0991) loss_zs_kd 0.0182 (0.0259) loss_oracle 0.2366 (0.1783) kd_loss 0.3738 (0.3327) acc 75.0000 (70.8906) gate/entropy 1.0845 (1.0900) gate/usage_max 0.4129 (0.3941) gate/usage_min 0.2844 (0.2932) gate/usage_std 0.0568 (0.0437) teacher/entropy 0.5815 (0.6642) teacher/usage_max 0.7927 (0.7462) teacher/usage_min 0.1024 (0.1196) teacher/usage_std 0.3248 (0.2920) nleep/row_max_mean 1200.1519 (1200.7078) nleep/row_max_std 13.9533 (16.1494) nleep/row_min_mean 1197.4476 (1198.3610) lr 1.9823e-03 eta 1:10:58
epoch [5/50] batch [220/244] time 0.125 (0.374) data 0.000 (0.001) loss 1.9655 (1.5418) teacher_loss 1.4032 (1.0980) loss_zs_kd 0.0362 (0.0262) loss_oracle 0.1962 (0.1791) kd_loss 0.4461 (0.3412) acc 62.5000 (71.0369) gate/entropy 1.0833 (1.0894) gate/usage_max 0.4167 (0.3960) gate/usage_min 0.2827 (0.2923) gate/usage_std 0.0594 (0.0451) teacher/entropy 0.4876 (0.6507) teacher/usage_max 0.8356 (0.7529) teacher/usage_min 0.0753 (0.1164) teacher/usage_std 0.3552 (0.2968) nleep/row_max_mean 1198.1433 (1200.7109) nleep/row_max_std 17.1984 (16.1267) nleep/row_min_mean 1194.9075 (1198.3047) lr 1.9823e-03 eta 1:08:36
epoch [5/50] batch [240/244] time 0.465 (0.376) data 0.000 (0.001) loss 1.9131 (1.5468) teacher_loss 1.3017 (1.0958) loss_zs_kd 0.0540 (0.0263) loss_oracle 0.2512 (0.1805) kd_loss 0.4587 (0.3477) acc 71.8750 (71.1719) gate/entropy 1.0817 (1.0888) gate/usage_max 0.4210 (0.3979) gate/usage_min 0.2803 (0.2914) gate/usage_std 0.0624 (0.0464) teacher/entropy 0.4665 (0.6395) teacher/usage_max 0.8400 (0.7589) teacher/usage_min 0.0787 (0.1134) teacher/usage_std 0.3583 (0.3010) nleep/row_max_mean 1199.5792 (1200.6208) nleep/row_max_std 16.3340 (16.0490) nleep/row_min_mean 1196.1831 (1198.1695) lr 1.9823e-03 eta 1:08:46
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,809
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,058
* accuracy: 91.4%
* error: 8.6%
* macro_f1: 91.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      84.3%, epoch: 4 *******
******* Domain p best val test acc: 91.1%, epoch: 4 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [6/50] batch [20/244] time 0.469 (0.520) data 0.000 (0.012) loss 1.7919 (1.5937) teacher_loss 1.2445 (1.0589) loss_zs_kd 0.0272 (0.0270) loss_oracle 0.1778 (0.2162) kd_loss 0.4449 (0.4132) acc 75.0000 (72.0312) gate/entropy 1.0797 (1.0805) gate/usage_max 0.4260 (0.4239) gate/usage_min 0.2777 (0.2788) gate/usage_std 0.0660 (0.0645) teacher/entropy 0.4752 (0.5135) teacher/usage_max 0.8312 (0.8225) teacher/usage_min 0.0836 (0.0835) teacher/usage_std 0.3520 (0.3459) nleep/row_max_mean 1199.1980 (1199.7941) nleep/row_max_std 16.6272 (14.9780) nleep/row_min_mean 1196.0322 (1196.7649) lr 1.9686e-03 eta 1:34:56
epoch [6/50] batch [40/244] time 0.078 (0.479) data 0.000 (0.006) loss 1.8308 (1.6262) teacher_loss 1.3327 (1.1010) loss_zs_kd 0.0308 (0.0293) loss_oracle 0.2224 (0.2077) kd_loss 0.3714 (0.4068) acc 62.5000 (71.2500) gate/entropy 1.0779 (1.0797) gate/usage_max 0.4304 (0.4260) gate/usage_min 0.2753 (0.2777) gate/usage_std 0.0690 (0.0660) teacher/entropy 0.5564 (0.5167) teacher/usage_max 0.7934 (0.8217) teacher/usage_min 0.0951 (0.0830) teacher/usage_std 0.3254 (0.3453) nleep/row_max_mean 1197.8125 (1199.4105) nleep/row_max_std 15.0045 (15.0908) nleep/row_min_mean 1194.9584 (1196.4288) lr 1.9686e-03 eta 1:27:16
epoch [6/50] batch [60/244] time 0.485 (0.395) data 0.001 (0.004) loss 1.9419 (1.6273) teacher_loss 1.3619 (1.0972) loss_zs_kd 0.0577 (0.0287) loss_oracle 0.2849 (0.2048) kd_loss 0.4088 (0.4134) acc 62.5000 (71.4583) gate/entropy 1.0763 (1.0788) gate/usage_max 0.4343 (0.4282) gate/usage_min 0.2734 (0.2765) gate/usage_std 0.0718 (0.0675) teacher/entropy 0.4967 (0.5043) teacher/usage_max 0.8321 (0.8271) teacher/usage_min 0.0772 (0.0798) teacher/usage_std 0.3528 (0.3492) nleep/row_max_mean 1196.8851 (1199.6702) nleep/row_max_std 11.8884 (14.7690) nleep/row_min_mean 1193.7416 (1196.6352) lr 1.9686e-03 eta 1:11:56
epoch [6/50] batch [80/244] time 0.438 (0.368) data 0.000 (0.003) loss 1.5055 (1.6316) teacher_loss 0.9341 (1.0955) loss_zs_kd 0.0262 (0.0273) loss_oracle 0.2906 (0.2063) kd_loss 0.4131 (0.4192) acc 78.1250 (70.7812) gate/entropy 1.0743 (1.0779) gate/usage_max 0.4388 (0.4303) gate/usage_min 0.2711 (0.2754) gate/usage_std 0.0750 (0.0690) teacher/entropy 0.4812 (0.4927) teacher/usage_max 0.8407 (0.8322) teacher/usage_min 0.0692 (0.0766) teacher/usage_std 0.3589 (0.3528) nleep/row_max_mean 1198.9219 (1199.6855) nleep/row_max_std 12.7098 (14.7764) nleep/row_min_mean 1195.7490 (1196.5911) lr 1.9686e-03 eta 1:06:47
epoch [6/50] batch [100/244] time 0.464 (0.359) data 0.000 (0.003) loss 1.9636 (1.6385) teacher_loss 1.3852 (1.0901) loss_zs_kd 0.0284 (0.0272) loss_oracle 0.2772 (0.2180) kd_loss 0.4255 (0.4258) acc 59.3750 (70.8125) gate/entropy 1.0723 (1.0770) gate/usage_max 0.4432 (0.4325) gate/usage_min 0.2687 (0.2743) gate/usage_std 0.0781 (0.0705) teacher/entropy 0.4625 (0.4805) teacher/usage_max 0.8365 (0.8369) teacher/usage_min 0.0555 (0.0738) teacher/usage_std 0.3564 (0.3561) nleep/row_max_mean 1200.8094 (1199.6584) nleep/row_max_std 17.0498 (14.9030) nleep/row_min_mean 1197.5576 (1196.4988) lr 1.9686e-03 eta 1:05:05
epoch [6/50] batch [120/244] time 0.477 (0.380) data 0.000 (0.002) loss 1.8785 (1.6491) teacher_loss 1.2183 (1.0903) loss_zs_kd 0.0409 (0.0270) loss_oracle 0.2916 (0.2265) kd_loss 0.4939 (0.4320) acc 65.6250 (70.9115) gate/entropy 1.0702 (1.0760) gate/usage_max 0.4477 (0.4347) gate/usage_min 0.2664 (0.2732) gate/usage_std 0.0812 (0.0721) teacher/entropy 0.3722 (0.4690) teacher/usage_max 0.8669 (0.8406) teacher/usage_min 0.0407 (0.0710) teacher/usage_std 0.3779 (0.3588) nleep/row_max_mean 1199.8159 (1199.6913) nleep/row_max_std 18.8801 (14.9514) nleep/row_min_mean 1196.1086 (1196.4712) lr 1.9686e-03 eta 1:08:44
epoch [6/50] batch [140/244] time 0.521 (0.396) data 0.000 (0.002) loss 2.0239 (1.6677) teacher_loss 1.4384 (1.1045) loss_zs_kd 0.0230 (0.0273) loss_oracle 0.1850 (0.2240) kd_loss 0.4815 (0.4376) acc 68.7500 (70.7812) gate/entropy 1.0679 (1.0750) gate/usage_max 0.4522 (0.4369) gate/usage_min 0.2643 (0.2721) gate/usage_std 0.0844 (0.0736) teacher/entropy 0.3680 (0.4575) teacher/usage_max 0.8882 (0.8455) teacher/usage_min 0.0526 (0.0686) teacher/usage_std 0.3924 (0.3622) nleep/row_max_mean 1199.3096 (1199.6716) nleep/row_max_std 13.4371 (15.1331) nleep/row_min_mean 1195.5591 (1196.3892) lr 1.9686e-03 eta 1:11:30
epoch [6/50] batch [160/244] time 0.474 (0.406) data 0.000 (0.002) loss 1.3793 (1.6723) teacher_loss 0.7773 (1.1039) loss_zs_kd 0.0397 (0.0270) loss_oracle 0.2580 (0.2228) kd_loss 0.4531 (0.4435) acc 75.0000 (70.8594) gate/entropy 1.0656 (1.0740) gate/usage_max 0.4568 (0.4391) gate/usage_min 0.2622 (0.2709) gate/usage_std 0.0877 (0.0752) teacher/entropy 0.3980 (0.4454) teacher/usage_max 0.8674 (0.8505) teacher/usage_min 0.0485 (0.0663) teacher/usage_std 0.3779 (0.3658) nleep/row_max_mean 1197.8065 (1199.8816) nleep/row_max_std 15.3433 (15.3392) nleep/row_min_mean 1193.9983 (1196.5257) lr 1.9686e-03 eta 1:13:13
epoch [6/50] batch [180/244] time 0.104 (0.384) data 0.000 (0.001) loss 1.5741 (1.6792) teacher_loss 0.8900 (1.1051) loss_zs_kd 0.0302 (0.0266) loss_oracle 0.2755 (0.2254) kd_loss 0.5312 (0.4481) acc 75.0000 (70.8160) gate/entropy 1.0631 (1.0729) gate/usage_max 0.4615 (0.4413) gate/usage_min 0.2601 (0.2698) gate/usage_std 0.0909 (0.0768) teacher/entropy 0.2882 (0.4351) teacher/usage_max 0.9129 (0.8547) teacher/usage_min 0.0311 (0.0646) teacher/usage_std 0.4099 (0.3687) nleep/row_max_mean 1203.4563 (1199.9159) nleep/row_max_std 19.2966 (15.3278) nleep/row_min_mean 1199.0790 (1196.4996) lr 1.9686e-03 eta 1:09:08
epoch [6/50] batch [200/244] time 0.080 (0.385) data 0.000 (0.001) loss 1.6412 (1.6828) teacher_loss 1.0339 (1.1042) loss_zs_kd 0.0441 (0.0268) loss_oracle 0.2254 (0.2285) kd_loss 0.4726 (0.4510) acc 68.7500 (70.8438) gate/entropy 1.0610 (1.0718) gate/usage_max 0.4654 (0.4436) gate/usage_min 0.2580 (0.2687) gate/usage_std 0.0937 (0.0783) teacher/entropy 0.3537 (0.4270) teacher/usage_max 0.8895 (0.8577) teacher/usage_min 0.0546 (0.0632) teacher/usage_std 0.3933 (0.3709) nleep/row_max_mean 1198.5374 (1199.9786) nleep/row_max_std 19.9594 (15.4066) nleep/row_min_mean 1194.3621 (1196.5118) lr 1.9686e-03 eta 1:09:14
epoch [6/50] batch [220/244] time 0.522 (0.374) data 0.000 (0.001) loss 1.9006 (1.6870) teacher_loss 1.3128 (1.1077) loss_zs_kd 0.0218 (0.0273) loss_oracle 0.2096 (0.2272) kd_loss 0.4721 (0.4521) acc 71.8750 (70.7386) gate/entropy 1.0586 (1.0707) gate/usage_max 0.4696 (0.4458) gate/usage_min 0.2560 (0.2677) gate/usage_std 0.0967 (0.0799) teacher/entropy 0.3569 (0.4212) teacher/usage_max 0.8707 (0.8599) teacher/usage_min 0.0576 (0.0624) teacher/usage_std 0.3800 (0.3724) nleep/row_max_mean 1201.0925 (1199.9849) nleep/row_max_std 17.5422 (15.3742) nleep/row_min_mean 1197.2660 (1196.4880) lr 1.9686e-03 eta 1:07:02
epoch [6/50] batch [240/244] time 0.429 (0.383) data 0.000 (0.001) loss 1.9085 (1.6821) teacher_loss 1.3134 (1.1022) loss_zs_kd 0.0276 (0.0270) loss_oracle 0.2406 (0.2278) kd_loss 0.4610 (0.4524) acc 56.2500 (70.8464) gate/entropy 1.0560 (1.0696) gate/usage_max 0.4742 (0.4480) gate/usage_min 0.2539 (0.2666) gate/usage_std 0.0999 (0.0814) teacher/entropy 0.3481 (0.4165) teacher/usage_max 0.8933 (0.8616) teacher/usage_min 0.0529 (0.0618) teacher/usage_std 0.3959 (0.3736) nleep/row_max_mean 1196.9933 (1199.9372) nleep/row_max_std 15.0363 (15.4063) nleep/row_min_mean 1193.3037 (1196.4128) lr 1.9686e-03 eta 1:08:35
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,807
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,050
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 90.7%
******* Domain p best val acc:      84.3%, epoch: 4 *******
******* Domain p best val test acc: 91.1%, epoch: 4 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [7/50] batch [20/244] time 0.483 (0.474) data 0.000 (0.013) loss 1.5259 (1.7689) teacher_loss 0.9610 (1.1706) loss_zs_kd 0.0280 (0.0282) loss_oracle 0.2235 (0.2478) kd_loss 0.4392 (0.4603) acc 68.7500 (70.4688) gate/entropy 1.0531 (1.0542) gate/usage_max 0.4789 (0.4771) gate/usage_min 0.2518 (0.2526) gate/usage_std 0.1032 (0.1019) teacher/entropy 0.3650 (0.3461) teacher/usage_max 0.8874 (0.8896) teacher/usage_min 0.0455 (0.0490) teacher/usage_std 0.3919 (0.3934) nleep/row_max_mean 1197.1738 (1198.8128) nleep/row_max_std 15.9265 (15.4835) nleep/row_min_mean 1193.3744 (1194.8865) lr 1.9511e-03 eta 1:24:37
epoch [7/50] batch [40/244] time 0.128 (0.359) data 0.000 (0.007) loss 1.5415 (1.7050) teacher_loss 0.8989 (1.1132) loss_zs_kd 0.0415 (0.0276) loss_oracle 0.2095 (0.2413) kd_loss 0.5171 (0.4574) acc 71.8750 (71.2500) gate/entropy 1.0504 (1.0529) gate/usage_max 0.4833 (0.4792) gate/usage_min 0.2500 (0.2517) gate/usage_std 0.1063 (0.1034) teacher/entropy 0.2542 (0.3447) teacher/usage_max 0.9299 (0.8908) teacher/usage_min 0.0323 (0.0491) teacher/usage_std 0.4218 (0.3943) nleep/row_max_mean 1203.7253 (1199.1625) nleep/row_max_std 13.7725 (15.0027) nleep/row_min_mean 1199.2759 (1195.2202) lr 1.9511e-03 eta 1:04:03
epoch [7/50] batch [60/244] time 0.502 (0.369) data 0.000 (0.005) loss 1.3449 (1.7087) teacher_loss 0.6650 (1.1192) loss_zs_kd 0.0224 (0.0260) loss_oracle 0.3588 (0.2369) kd_loss 0.4893 (0.4580) acc 75.0000 (70.4167) gate/entropy 1.0485 (1.0517) gate/usage_max 0.4865 (0.4813) gate/usage_min 0.2487 (0.2508) gate/usage_std 0.1085 (0.1048) teacher/entropy 0.3067 (0.3397) teacher/usage_max 0.8822 (0.8924) teacher/usage_min 0.0549 (0.0480) teacher/usage_std 0.3881 (0.3954) nleep/row_max_mean 1202.7698 (1199.4866) nleep/row_max_std 17.5386 (15.0464) nleep/row_min_mean 1198.4727 (1195.4950) lr 1.9511e-03 eta 1:05:36
epoch [7/50] batch [80/244] time 0.446 (0.329) data 0.000 (0.004) loss 1.6404 (1.6959) teacher_loss 1.0560 (1.1020) loss_zs_kd 0.0391 (0.0263) loss_oracle 0.3677 (0.2507) kd_loss 0.3810 (0.4554) acc 71.8750 (70.4688) gate/entropy 1.0462 (1.0505) gate/usage_max 0.4901 (0.4832) gate/usage_min 0.2472 (0.2500) gate/usage_std 0.1110 (0.1062) teacher/entropy 0.4388 (0.3397) teacher/usage_max 0.8366 (0.8918) teacher/usage_min 0.0810 (0.0482) teacher/usage_std 0.3559 (0.3949) nleep/row_max_mean 1198.2510 (1199.6500) nleep/row_max_std 16.6939 (15.1659) nleep/row_min_mean 1194.5774 (1195.6443) lr 1.9511e-03 eta 0:58:26
epoch [7/50] batch [100/244] time 0.434 (0.356) data 0.000 (0.003) loss 1.9136 (1.6855) teacher_loss 1.3720 (1.0931) loss_zs_kd 0.0381 (0.0265) loss_oracle 0.2379 (0.2570) kd_loss 0.4037 (0.4506) acc 65.6250 (70.8750) gate/entropy 1.0442 (1.0494) gate/usage_max 0.4930 (0.4849) gate/usage_min 0.2458 (0.2493) gate/usage_std 0.1131 (0.1074) teacher/entropy 0.3833 (0.3428) teacher/usage_max 0.8806 (0.8902) teacher/usage_min 0.0517 (0.0492) teacher/usage_std 0.3870 (0.3938) nleep/row_max_mean 1200.1199 (1199.8861) nleep/row_max_std 15.2961 (15.4854) nleep/row_min_mean 1196.3611 (1195.8819) lr 1.9511e-03 eta 1:03:07
epoch [7/50] batch [120/244] time 0.523 (0.379) data 0.000 (0.002) loss 1.6552 (1.6895) teacher_loss 1.1442 (1.1023) loss_zs_kd 0.0188 (0.0270) loss_oracle 0.2104 (0.2544) kd_loss 0.3964 (0.4466) acc 68.7500 (70.9635) gate/entropy 1.0421 (1.0484) gate/usage_max 0.4962 (0.4865) gate/usage_min 0.2444 (0.2486) gate/usage_std 0.1153 (0.1085) teacher/entropy 0.3981 (0.3452) teacher/usage_max 0.8621 (0.8887) teacher/usage_min 0.0665 (0.0499) teacher/usage_std 0.3739 (0.3928) nleep/row_max_mean 1199.2737 (1199.9332) nleep/row_max_std 18.1725 (15.6102) nleep/row_min_mean 1195.7039 (1195.9332) lr 1.9511e-03 eta 1:07:05
epoch [7/50] batch [140/244] time 0.444 (0.394) data 0.000 (0.002) loss 1.2133 (1.6703) teacher_loss 0.6724 (1.0910) loss_zs_kd 0.0381 (0.0268) loss_oracle 0.2571 (0.2518) kd_loss 0.3933 (0.4400) acc 78.1250 (71.1607) gate/entropy 1.0403 (1.0474) gate/usage_max 0.4988 (0.4881) gate/usage_min 0.2432 (0.2479) gate/usage_std 0.1172 (0.1096) teacher/entropy 0.3915 (0.3508) teacher/usage_max 0.8706 (0.8865) teacher/usage_min 0.0606 (0.0507) teacher/usage_std 0.3800 (0.3912) nleep/row_max_mean 1201.2587 (1199.9266) nleep/row_max_std 19.0939 (15.8947) nleep/row_min_mean 1197.4165 (1195.9535) lr 1.9511e-03 eta 1:09:33
epoch [7/50] batch [160/244] time 0.082 (0.391) data 0.000 (0.002) loss 2.1179 (1.6670) teacher_loss 1.5325 (1.0931) loss_zs_kd 0.0301 (0.0268) loss_oracle 0.2911 (0.2490) kd_loss 0.4248 (0.4360) acc 62.5000 (70.9961) gate/entropy 1.0382 (1.0463) gate/usage_max 0.5018 (0.4896) gate/usage_min 0.2420 (0.2472) gate/usage_std 0.1193 (0.1107) teacher/entropy 0.3638 (0.3537) teacher/usage_max 0.8588 (0.8846) teacher/usage_min 0.0633 (0.0511) teacher/usage_std 0.3716 (0.3899) nleep/row_max_mean 1195.8606 (1199.8472) nleep/row_max_std 15.3731 (16.0597) nleep/row_min_mean 1191.7859 (1195.8778) lr 1.9511e-03 eta 1:08:55
epoch [7/50] batch [180/244] time 0.463 (0.381) data 0.000 (0.002) loss 1.5250 (1.6696) teacher_loss 0.9635 (1.0983) loss_zs_kd 0.0213 (0.0269) loss_oracle 0.2861 (0.2490) kd_loss 0.4078 (0.4333) acc 78.1250 (71.0417) gate/entropy 1.0360 (1.0453) gate/usage_max 0.5050 (0.4912) gate/usage_min 0.2408 (0.2466) gate/usage_std 0.1215 (0.1118) teacher/entropy 0.3606 (0.3543) teacher/usage_max 0.8797 (0.8841) teacher/usage_min 0.0523 (0.0506) teacher/usage_std 0.3864 (0.3895) nleep/row_max_mean 1200.3683 (1199.8984) nleep/row_max_std 17.1013 (16.0523) nleep/row_min_mean 1196.3499 (1195.9191) lr 1.9511e-03 eta 1:06:56
epoch [7/50] batch [200/244] time 0.465 (0.367) data 0.000 (0.002) loss 1.4906 (1.6611) teacher_loss 0.9024 (1.0906) loss_zs_kd 0.0194 (0.0269) loss_oracle 0.3058 (0.2515) kd_loss 0.4256 (0.4314) acc 71.8750 (71.3125) gate/entropy 1.0342 (1.0442) gate/usage_max 0.5076 (0.4927) gate/usage_min 0.2400 (0.2459) gate/usage_std 0.1234 (0.1129) teacher/entropy 0.3475 (0.3544) teacher/usage_max 0.8697 (0.8835) teacher/usage_min 0.0429 (0.0504) teacher/usage_std 0.3797 (0.3891) nleep/row_max_mean 1196.8560 (1200.0209) nleep/row_max_std 18.6374 (16.1499) nleep/row_min_mean 1192.6604 (1196.0171) lr 1.9511e-03 eta 1:04:25
epoch [7/50] batch [220/244] time 0.442 (0.370) data 0.000 (0.001) loss 1.6446 (1.6636) teacher_loss 1.1398 (1.0943) loss_zs_kd 0.0432 (0.0270) loss_oracle 0.2240 (0.2526) kd_loss 0.3712 (0.4295) acc 75.0000 (71.1648) gate/entropy 1.0314 (1.0432) gate/usage_max 0.5114 (0.4943) gate/usage_min 0.2386 (0.2453) gate/usage_std 0.1260 (0.1140) teacher/entropy 0.4058 (0.3541) teacher/usage_max 0.8566 (0.8833) teacher/usage_min 0.0588 (0.0499) teacher/usage_std 0.3701 (0.3890) nleep/row_max_mean 1199.8748 (1200.0686) nleep/row_max_std 14.9164 (16.1984) nleep/row_min_mean 1196.0110 (1196.0460) lr 1.9511e-03 eta 1:04:53
epoch [7/50] batch [240/244] time 0.460 (0.377) data 0.000 (0.001) loss 1.4672 (1.6539) teacher_loss 0.8479 (1.0868) loss_zs_kd 0.0392 (0.0265) loss_oracle 0.3259 (0.2509) kd_loss 0.4367 (0.4284) acc 78.1250 (71.4453) gate/entropy 1.0295 (1.0421) gate/usage_max 0.5140 (0.4958) gate/usage_min 0.2376 (0.2447) gate/usage_std 0.1278 (0.1150) teacher/entropy 0.3079 (0.3527) teacher/usage_max 0.8943 (0.8836) teacher/usage_min 0.0486 (0.0491) teacher/usage_std 0.3966 (0.3892) nleep/row_max_mean 1199.1724 (1200.1662) nleep/row_max_std 13.9210 (16.2874) nleep/row_min_mean 1194.6323 (1196.1238) lr 1.9511e-03 eta 1:05:57
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,812
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.3%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,036
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 90.4%
******* Domain p best val acc:      84.3%, epoch: 4 *******
******* Domain p best val test acc: 91.1%, epoch: 4 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [8/50] batch [20/244] time 0.077 (0.467) data 0.000 (0.013) loss 1.7233 (1.6947) teacher_loss 1.1598 (1.1403) loss_zs_kd 0.0300 (0.0288) loss_oracle 0.3372 (0.2639) kd_loss 0.3799 (0.4081) acc 65.6250 (69.3750) gate/entropy 1.0278 (1.0282) gate/usage_max 0.5163 (0.5157) gate/usage_min 0.2369 (0.2370) gate/usage_std 0.1295 (0.1290) teacher/entropy 0.3739 (0.3448) teacher/usage_max 0.8781 (0.8808) teacher/usage_min 0.0527 (0.0447) teacher/usage_std 0.3853 (0.3874) nleep/row_max_mean 1197.5669 (1199.9094) nleep/row_max_std 13.5703 (15.7644) nleep/row_min_mean 1193.2286 (1195.6041) lr 1.9298e-03 eta 1:21:27
epoch [8/50] batch [40/244] time 0.454 (0.337) data 0.000 (0.007) loss 1.5665 (1.6367) teacher_loss 1.0315 (1.0808) loss_zs_kd 0.0256 (0.0294) loss_oracle 0.2671 (0.2758) kd_loss 0.3886 (0.4034) acc 75.0000 (72.0312) gate/entropy 1.0254 (1.0273) gate/usage_max 0.5195 (0.5169) gate/usage_min 0.2356 (0.2366) gate/usage_std 0.1317 (0.1299) teacher/entropy 0.3454 (0.3473) teacher/usage_max 0.8978 (0.8814) teacher/usage_min 0.0423 (0.0439) teacher/usage_std 0.3992 (0.3878) nleep/row_max_mean 1200.7756 (1199.7657) nleep/row_max_std 16.7275 (15.8807) nleep/row_min_mean 1196.4254 (1195.4741) lr 1.9298e-03 eta 0:58:43
epoch [8/50] batch [60/244] time 0.183 (0.320) data 0.001 (0.004) loss 1.4649 (1.6266) teacher_loss 0.9332 (1.0708) loss_zs_kd 0.0348 (0.0287) loss_oracle 0.2573 (0.2830) kd_loss 0.3856 (0.4000) acc 81.2500 (72.3438) gate/entropy 1.0237 (1.0263) gate/usage_max 0.5217 (0.5182) gate/usage_min 0.2347 (0.2361) gate/usage_std 0.1332 (0.1308) teacher/entropy 0.3528 (0.3506) teacher/usage_max 0.8883 (0.8791) teacher/usage_min 0.0383 (0.0435) teacher/usage_std 0.3927 (0.3862) nleep/row_max_mean 1197.6658 (1199.9905) nleep/row_max_std 15.8382 (16.0018) nleep/row_min_mean 1193.5083 (1195.7000) lr 1.9298e-03 eta 0:55:33
epoch [8/50] batch [80/244] time 0.450 (0.327) data 0.000 (0.003) loss 1.7157 (1.6163) teacher_loss 1.1841 (1.0596) loss_zs_kd 0.0425 (0.0292) loss_oracle 0.2817 (0.2898) kd_loss 0.3695 (0.3973) acc 71.8750 (72.3438) gate/entropy 1.0222 (1.0254) gate/usage_max 0.5236 (0.5194) gate/usage_min 0.2339 (0.2356) gate/usage_std 0.1346 (0.1316) teacher/entropy 0.3754 (0.3524) teacher/usage_max 0.8771 (0.8781) teacher/usage_min 0.0299 (0.0434) teacher/usage_std 0.3853 (0.3856) nleep/row_max_mean 1202.4438 (1200.0995) nleep/row_max_std 16.1929 (15.7497) nleep/row_min_mean 1198.3525 (1195.8255) lr 1.9298e-03 eta 0:56:48
epoch [8/50] batch [100/244] time 0.472 (0.357) data 0.000 (0.003) loss 1.4173 (1.6221) teacher_loss 0.9236 (1.0723) loss_zs_kd 0.0175 (0.0293) loss_oracle 0.2371 (0.2869) kd_loss 0.3665 (0.3917) acc 78.1250 (72.0312) gate/entropy 1.0207 (1.0246) gate/usage_max 0.5255 (0.5205) gate/usage_min 0.2331 (0.2352) gate/usage_std 0.1359 (0.1324) teacher/entropy 0.3746 (0.3591) teacher/usage_max 0.8780 (0.8747) teacher/usage_min 0.0366 (0.0433) teacher/usage_std 0.3857 (0.3832) nleep/row_max_mean 1201.0464 (1200.2016) nleep/row_max_std 15.1651 (15.6459) nleep/row_min_mean 1196.8137 (1195.9645) lr 1.9298e-03 eta 1:01:50
epoch [8/50] batch [120/244] time 0.454 (0.376) data 0.000 (0.002) loss 1.5341 (1.6022) teacher_loss 1.1156 (1.0639) loss_zs_kd 0.0209 (0.0294) loss_oracle 0.1989 (0.2753) kd_loss 0.3086 (0.3860) acc 68.7500 (72.0312) gate/entropy 1.0193 (1.0238) gate/usage_max 0.5273 (0.5214) gate/usage_min 0.2324 (0.2348) gate/usage_std 0.1372 (0.1331) teacher/entropy 0.4656 (0.3660) teacher/usage_max 0.8339 (0.8715) teacher/usage_min 0.0524 (0.0446) teacher/usage_std 0.3548 (0.3810) nleep/row_max_mean 1199.7561 (1200.2556) nleep/row_max_std 13.0798 (15.5586) nleep/row_min_mean 1196.1348 (1196.0556) lr 1.9298e-03 eta 1:04:58
epoch [8/50] batch [140/244] time 0.471 (0.388) data 0.000 (0.002) loss 1.8648 (1.6130) teacher_loss 1.4282 (1.0832) loss_zs_kd 0.0258 (0.0291) loss_oracle 0.1581 (0.2691) kd_loss 0.3447 (0.3806) acc 71.8750 (71.6518) gate/entropy 1.0180 (1.0231) gate/usage_max 0.5289 (0.5224) gate/usage_min 0.2319 (0.2344) gate/usage_std 0.1383 (0.1337) teacher/entropy 0.4186 (0.3742) teacher/usage_max 0.8455 (0.8663) teacher/usage_min 0.0347 (0.0462) teacher/usage_std 0.3639 (0.3774) nleep/row_max_mean 1203.9263 (1200.3281) nleep/row_max_std 13.8777 (15.4685) nleep/row_min_mean 1200.1652 (1196.1704) lr 1.9298e-03 eta 1:06:52
epoch [8/50] batch [160/244] time 0.116 (0.371) data 0.000 (0.002) loss 1.7957 (1.5992) teacher_loss 1.2787 (1.0734) loss_zs_kd 0.0494 (0.0289) loss_oracle 0.2906 (0.2642) kd_loss 0.3469 (0.3792) acc 68.7500 (71.9922) gate/entropy 1.0168 (1.0223) gate/usage_max 0.5304 (0.5233) gate/usage_min 0.2314 (0.2340) gate/usage_std 0.1393 (0.1344) teacher/entropy 0.4422 (0.3755) teacher/usage_max 0.8110 (0.8649) teacher/usage_min 0.0475 (0.0461) teacher/usage_std 0.3399 (0.3764) nleep/row_max_mean 1200.2001 (1200.6810) nleep/row_max_std 16.1333 (15.5808) nleep/row_min_mean 1196.3328 (1196.5292) lr 1.9298e-03 eta 1:03:52
epoch [8/50] batch [180/244] time 0.480 (0.372) data 0.000 (0.002) loss 1.4323 (1.5912) teacher_loss 0.9130 (1.0677) loss_zs_kd 0.0438 (0.0289) loss_oracle 0.2464 (0.2630) kd_loss 0.3742 (0.3775) acc 75.0000 (72.1181) gate/entropy 1.0154 (1.0216) gate/usage_max 0.5321 (0.5243) gate/usage_min 0.2309 (0.2337) gate/usage_std 0.1405 (0.1350) teacher/entropy 0.3535 (0.3767) teacher/usage_max 0.8831 (0.8640) teacher/usage_min 0.0293 (0.0455) teacher/usage_std 0.3895 (0.3758) nleep/row_max_mean 1203.7029 (1200.8671) nleep/row_max_std 16.5467 (15.5784) nleep/row_min_mean 1199.0986 (1196.7073) lr 1.9298e-03 eta 1:03:53
epoch [8/50] batch [200/244] time 0.448 (0.356) data 0.000 (0.001) loss 1.5538 (1.5901) teacher_loss 1.1184 (1.0712) loss_zs_kd 0.0163 (0.0285) loss_oracle 0.2678 (0.2635) kd_loss 0.2933 (0.3730) acc 71.8750 (72.2188) gate/entropy 1.0140 (1.0209) gate/usage_max 0.5338 (0.5251) gate/usage_min 0.2304 (0.2334) gate/usage_std 0.1418 (0.1357) teacher/entropy 0.5102 (0.3822) teacher/usage_max 0.7888 (0.8613) teacher/usage_min 0.0640 (0.0459) teacher/usage_std 0.3238 (0.3740) nleep/row_max_mean 1200.2211 (1200.8919) nleep/row_max_std 20.5187 (15.6199) nleep/row_min_mean 1196.5300 (1196.7462) lr 1.9298e-03 eta 1:01:01
epoch [8/50] batch [220/244] time 0.441 (0.367) data 0.000 (0.001) loss 1.5358 (1.5846) teacher_loss 1.0970 (1.0694) loss_zs_kd 0.0250 (0.0283) loss_oracle 0.1987 (0.2612) kd_loss 0.3270 (0.3704) acc 68.7500 (72.1733) gate/entropy 1.0123 (1.0202) gate/usage_max 0.5358 (0.5260) gate/usage_min 0.2298 (0.2331) gate/usage_std 0.1432 (0.1363) teacher/entropy 0.4342 (0.3852) teacher/usage_max 0.8370 (0.8594) teacher/usage_min 0.0428 (0.0457) teacher/usage_std 0.3576 (0.3727) nleep/row_max_mean 1198.5974 (1200.7969) nleep/row_max_std 12.7663 (15.6130) nleep/row_min_mean 1194.4045 (1196.6497) lr 1.9298e-03 eta 1:02:51
epoch [8/50] batch [240/244] time 0.451 (0.372) data 0.000 (0.001) loss 1.8330 (1.5855) teacher_loss 1.3829 (1.0742) loss_zs_kd 0.0373 (0.0282) loss_oracle 0.2270 (0.2578) kd_loss 0.3179 (0.3683) acc 62.5000 (72.1224) gate/entropy 1.0114 (1.0195) gate/usage_max 0.5369 (0.5269) gate/usage_min 0.2295 (0.2328) gate/usage_std 0.1439 (0.1369) teacher/entropy 0.4397 (0.3869) teacher/usage_max 0.8393 (0.8584) teacher/usage_min 0.0371 (0.0452) teacher/usage_std 0.3595 (0.3721) nleep/row_max_mean 1198.9155 (1200.8263) nleep/row_max_std 17.0513 (15.5614) nleep/row_min_mean 1194.6340 (1196.6705) lr 1.9298e-03 eta 1:03:29
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,820
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,026
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.2%
******* Domain p best val acc:      84.6%, epoch: 8 *******
******* Domain p best val test acc: 90.7%, epoch: 8 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [9/50] batch [20/244] time 0.086 (0.350) data 0.000 (0.014) loss 1.9218 (1.6697) teacher_loss 1.4836 (1.2041) loss_zs_kd 0.0204 (0.0269) loss_oracle 0.1979 (0.2409) kd_loss 0.3291 (0.3317) acc 65.6250 (70.7812) gate/entropy 1.0099 (1.0105) gate/usage_max 0.5387 (0.5380) gate/usage_min 0.2289 (0.2291) gate/usage_std 0.1452 (0.1447) teacher/entropy 0.4141 (0.4333) teacher/usage_max 0.8539 (0.8291) teacher/usage_min 0.0314 (0.0445) teacher/usage_std 0.3697 (0.3523) nleep/row_max_mean 1202.6995 (1199.7947) nleep/row_max_std 17.0952 (15.0804) nleep/row_min_mean 1198.2478 (1195.5618) lr 1.9048e-03 eta 0:59:43
epoch [9/50] batch [40/244] time 0.463 (0.322) data 0.000 (0.007) loss 1.5871 (1.5808) teacher_loss 1.1070 (1.1132) loss_zs_kd 0.0132 (0.0251) loss_oracle 0.2140 (0.2427) kd_loss 0.3665 (0.3337) acc 75.0000 (72.2656) gate/entropy 1.0094 (1.0101) gate/usage_max 0.5393 (0.5385) gate/usage_min 0.2288 (0.2290) gate/usage_std 0.1456 (0.1451) teacher/entropy 0.3902 (0.4258) teacher/usage_max 0.8370 (0.8349) teacher/usage_min 0.0393 (0.0415) teacher/usage_std 0.3578 (0.3564) nleep/row_max_mean 1203.1062 (1200.8550) nleep/row_max_std 17.9452 (15.5169) nleep/row_min_mean 1198.6074 (1196.5922) lr 1.9048e-03 eta 0:54:45
epoch [9/50] batch [60/244] time 0.460 (0.304) data 0.000 (0.005) loss 2.0870 (1.5605) teacher_loss 1.6572 (1.0968) loss_zs_kd 0.0433 (0.0270) loss_oracle 0.2272 (0.2408) kd_loss 0.2945 (0.3298) acc 65.6250 (72.3438) gate/entropy 1.0084 (1.0097) gate/usage_max 0.5404 (0.5390) gate/usage_min 0.2283 (0.2289) gate/usage_std 0.1464 (0.1454) teacher/entropy 0.4676 (0.4314) teacher/usage_max 0.8289 (0.8322) teacher/usage_min 0.0479 (0.0416) teacher/usage_std 0.3517 (0.3546) nleep/row_max_mean 1195.1553 (1200.3137) nleep/row_max_std 14.0165 (15.2728) nleep/row_min_mean 1191.1379 (1196.0833) lr 1.9048e-03 eta 0:51:36
epoch [9/50] batch [80/244] time 0.435 (0.315) data 0.000 (0.004) loss 2.0033 (1.5618) teacher_loss 1.5642 (1.1020) loss_zs_kd 0.0224 (0.0277) loss_oracle 0.2181 (0.2344) kd_loss 0.3188 (0.3288) acc 59.3750 (71.8359) gate/entropy 1.0074 (1.0092) gate/usage_max 0.5416 (0.5395) gate/usage_min 0.2279 (0.2287) gate/usage_std 0.1472 (0.1458) teacher/entropy 0.4198 (0.4308) teacher/usage_max 0.8540 (0.8332) teacher/usage_min 0.0561 (0.0415) teacher/usage_std 0.3685 (0.3553) nleep/row_max_mean 1201.3770 (1200.4018) nleep/row_max_std 14.9069 (15.2924) nleep/row_min_mean 1197.1975 (1196.1950) lr 1.9048e-03 eta 0:53:25
epoch [9/50] batch [100/244] time 0.501 (0.349) data 0.000 (0.003) loss 1.3006 (1.5486) teacher_loss 0.8746 (1.0941) loss_zs_kd 0.0203 (0.0271) loss_oracle 0.1638 (0.2268) kd_loss 0.3339 (0.3276) acc 62.5000 (71.8125) gate/entropy 1.0066 (1.0087) gate/usage_max 0.5425 (0.5400) gate/usage_min 0.2276 (0.2285) gate/usage_std 0.1479 (0.1462) teacher/entropy 0.4029 (0.4306) teacher/usage_max 0.8547 (0.8340) teacher/usage_min 0.0406 (0.0415) teacher/usage_std 0.3696 (0.3558) nleep/row_max_mean 1201.2474 (1200.7117) nleep/row_max_std 14.1058 (15.2591) nleep/row_min_mean 1197.2012 (1196.5292) lr 1.9048e-03 eta 0:58:59
epoch [9/50] batch [120/244] time 0.497 (0.366) data 0.000 (0.002) loss 1.8983 (1.5459) teacher_loss 1.5067 (1.0957) loss_zs_kd 0.0202 (0.0271) loss_oracle 0.2289 (0.2276) kd_loss 0.2670 (0.3229) acc 59.3750 (71.4583) gate/entropy 1.0054 (1.0083) gate/usage_max 0.5439 (0.5406) gate/usage_min 0.2271 (0.2283) gate/usage_std 0.1489 (0.1465) teacher/entropy 0.5320 (0.4387) teacher/usage_max 0.7816 (0.8294) teacher/usage_min 0.0535 (0.0428) teacher/usage_std 0.3202 (0.3527) nleep/row_max_mean 1196.1597 (1200.7180) nleep/row_max_std 12.9376 (15.4904) nleep/row_min_mean 1192.5767 (1196.5793) lr 1.9048e-03 eta 1:01:42
epoch [9/50] batch [140/244] time 0.474 (0.380) data 0.000 (0.002) loss 1.3810 (1.5553) teacher_loss 0.9459 (1.1046) loss_zs_kd 0.0287 (0.0273) loss_oracle 0.2661 (0.2334) kd_loss 0.2877 (0.3204) acc 71.8750 (71.2500) gate/entropy 1.0053 (1.0079) gate/usage_max 0.5441 (0.5410) gate/usage_min 0.2271 (0.2281) gate/usage_std 0.1490 (0.1469) teacher/entropy 0.4824 (0.4430) teacher/usage_max 0.8143 (0.8267) teacher/usage_min 0.0591 (0.0435) teacher/usage_std 0.3412 (0.3508) nleep/row_max_mean 1200.4407 (1200.5444) nleep/row_max_std 15.6116 (15.5085) nleep/row_min_mean 1196.6737 (1196.4375) lr 1.9048e-03 eta 1:04:01
epoch [9/50] batch [160/244] time 0.086 (0.355) data 0.000 (0.002) loss 1.1241 (1.5424) teacher_loss 0.5977 (1.0922) loss_zs_kd 0.0277 (0.0277) loss_oracle 0.2756 (0.2354) kd_loss 0.3748 (0.3187) acc 87.5000 (71.5234) gate/entropy 1.0043 (1.0075) gate/usage_max 0.5452 (0.5415) gate/usage_min 0.2268 (0.2280) gate/usage_std 0.1498 (0.1472) teacher/entropy 0.3723 (0.4451) teacher/usage_max 0.8397 (0.8254) teacher/usage_min 0.0320 (0.0440) teacher/usage_std 0.3602 (0.3500) nleep/row_max_mean 1200.9685 (1200.4861) nleep/row_max_std 17.5393 (15.5082) nleep/row_min_mean 1196.7334 (1196.4083) lr 1.9048e-03 eta 0:59:46
epoch [9/50] batch [180/244] time 0.079 (0.360) data 0.000 (0.002) loss 1.5805 (1.5353) teacher_loss 1.1279 (1.0832) loss_zs_kd 0.0282 (0.0277) loss_oracle 0.3777 (0.2429) kd_loss 0.2496 (0.3168) acc 71.8750 (71.4931) gate/entropy 1.0036 (1.0071) gate/usage_max 0.5460 (0.5420) gate/usage_min 0.2266 (0.2278) gate/usage_std 0.1504 (0.1475) teacher/entropy 0.5628 (0.4478) teacher/usage_max 0.7639 (0.8239) teacher/usage_min 0.0662 (0.0446) teacher/usage_std 0.3074 (0.3489) nleep/row_max_mean 1194.2179 (1200.4333) nleep/row_max_std 13.3303 (15.6013) nleep/row_min_mean 1190.9646 (1196.3756) lr 1.9048e-03 eta 1:00:21
epoch [9/50] batch [200/244] time 0.466 (0.343) data 0.000 (0.002) loss 1.5063 (1.5347) teacher_loss 1.1136 (1.0821) loss_zs_kd 0.0274 (0.0282) loss_oracle 0.1878 (0.2464) kd_loss 0.2851 (0.3153) acc 71.8750 (71.5312) gate/entropy 1.0030 (1.0067) gate/usage_max 0.5467 (0.5424) gate/usage_min 0.2265 (0.2277) gate/usage_std 0.1509 (0.1478) teacher/entropy 0.4836 (0.4513) teacher/usage_max 0.8128 (0.8211) teacher/usage_min 0.0299 (0.0448) teacher/usage_std 0.3430 (0.3470) nleep/row_max_mean 1199.8613 (1200.2711) nleep/row_max_std 14.9082 (15.6758) nleep/row_min_mean 1195.8872 (1196.2326) lr 1.9048e-03 eta 0:57:29
epoch [9/50] batch [220/244] time 0.434 (0.352) data 0.000 (0.001) loss 1.8859 (1.5289) teacher_loss 1.4129 (1.0801) loss_zs_kd 0.0348 (0.0279) loss_oracle 0.2304 (0.2427) kd_loss 0.3403 (0.3135) acc 71.8750 (71.6761) gate/entropy 1.0027 (1.0064) gate/usage_max 0.5470 (0.5428) gate/usage_min 0.2264 (0.2276) gate/usage_std 0.1511 (0.1481) teacher/entropy 0.3917 (0.4538) teacher/usage_max 0.8539 (0.8197) teacher/usage_min 0.0347 (0.0450) teacher/usage_std 0.3694 (0.3461) nleep/row_max_mean 1199.9905 (1200.2249) nleep/row_max_std 12.7746 (15.5734) nleep/row_min_mean 1195.3235 (1196.1926) lr 1.9048e-03 eta 0:58:52
epoch [9/50] batch [240/244] time 0.498 (0.362) data 0.000 (0.001) loss 1.7847 (1.5257) teacher_loss 1.2761 (1.0780) loss_zs_kd 0.0450 (0.0281) loss_oracle 0.2798 (0.2424) kd_loss 0.3461 (0.3124) acc 71.8750 (71.7839) gate/entropy 1.0018 (1.0060) gate/usage_max 0.5480 (0.5432) gate/usage_min 0.2259 (0.2275) gate/usage_std 0.1518 (0.1484) teacher/entropy 0.4537 (0.4563) teacher/usage_max 0.7757 (0.8175) teacher/usage_min 0.0621 (0.0452) teacher/usage_std 0.3155 (0.3447) nleep/row_max_mean 1197.8301 (1200.1123) nleep/row_max_std 11.9077 (15.4577) nleep/row_min_mean 1193.8716 (1196.0843) lr 1.9048e-03 eta 1:00:18
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,822
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,030
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.3%
******* Domain p best val acc:      84.6%, epoch: 9 *******
******* Domain p best val test acc: 90.8%, epoch: 9 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [10/50] batch [20/244] time 0.080 (0.334) data 0.000 (0.013) loss 1.3738 (1.4318) teacher_loss 0.9525 (1.0025) loss_zs_kd 0.0395 (0.0264) loss_oracle 0.2098 (0.2458) kd_loss 0.2966 (0.2931) acc 68.7500 (73.2812) gate/entropy 1.0012 (1.0015) gate/usage_max 0.5487 (0.5484) gate/usage_min 0.2254 (0.2256) gate/usage_std 0.1523 (0.1521) teacher/entropy 0.4792 (0.4973) teacher/usage_max 0.8022 (0.7859) teacher/usage_min 0.0361 (0.0464) teacher/usage_std 0.3355 (0.3242) nleep/row_max_mean 1201.2214 (1200.3617) nleep/row_max_std 12.3978 (14.3981) nleep/row_min_mean 1197.3157 (1196.4167) lr 1.8763e-03 eta 0:55:31
epoch [10/50] batch [40/244] time 0.453 (0.300) data 0.000 (0.007) loss 1.4000 (1.4472) teacher_loss 0.9959 (1.0171) loss_zs_kd 0.0536 (0.0291) loss_oracle 0.1747 (0.2473) kd_loss 0.2899 (0.2920) acc 71.8750 (73.5156) gate/entropy 1.0005 (1.0012) gate/usage_max 0.5495 (0.5487) gate/usage_min 0.2249 (0.2254) gate/usage_std 0.1529 (0.1523) teacher/entropy 0.4607 (0.4969) teacher/usage_max 0.8292 (0.7873) teacher/usage_min 0.0356 (0.0480) teacher/usage_std 0.3529 (0.3249) nleep/row_max_mean 1201.0946 (1200.5091) nleep/row_max_std 15.6662 (14.7097) nleep/row_min_mean 1197.1542 (1196.5673) lr 1.8763e-03 eta 0:49:50
epoch [10/50] batch [60/244] time 0.517 (0.292) data 0.001 (0.005) loss 1.4593 (1.4464) teacher_loss 0.9998 (1.0163) loss_zs_kd 0.0403 (0.0293) loss_oracle 0.2580 (0.2464) kd_loss 0.3103 (0.2922) acc 68.7500 (73.1771) gate/entropy 1.0002 (1.0009) gate/usage_max 0.5498 (0.5491) gate/usage_min 0.2247 (0.2251) gate/usage_std 0.1531 (0.1526) teacher/entropy 0.5280 (0.5013) teacher/usage_max 0.7306 (0.7817) teacher/usage_min 0.0914 (0.0511) teacher/usage_std 0.2831 (0.3210) nleep/row_max_mean 1196.7090 (1200.0658) nleep/row_max_std 15.7624 (14.7373) nleep/row_min_mean 1192.9397 (1196.1530) lr 1.8763e-03 eta 0:48:18
epoch [10/50] batch [80/244] time 0.414 (0.315) data 0.000 (0.004) loss 1.4315 (1.4653) teacher_loss 1.0527 (1.0377) loss_zs_kd 0.0212 (0.0285) loss_oracle 0.2063 (0.2456) kd_loss 0.2651 (0.2906) acc 65.6250 (72.5781) gate/entropy 0.9993 (1.0006) gate/usage_max 0.5509 (0.5494) gate/usage_min 0.2240 (0.2249) gate/usage_std 0.1538 (0.1528) teacher/entropy 0.5069 (0.5044) teacher/usage_max 0.8034 (0.7796) teacher/usage_min 0.0449 (0.0510) teacher/usage_std 0.3352 (0.3196) nleep/row_max_mean 1200.8882 (1200.1960) nleep/row_max_std 13.7470 (14.7484) nleep/row_min_mean 1197.0267 (1196.2999) lr 1.8763e-03 eta 0:52:03
epoch [10/50] batch [100/244] time 0.455 (0.345) data 0.000 (0.003) loss 1.5441 (1.4716) teacher_loss 1.1039 (1.0428) loss_zs_kd 0.0433 (0.0282) loss_oracle 0.3054 (0.2484) kd_loss 0.2659 (0.2906) acc 68.7500 (72.6875) gate/entropy 0.9991 (1.0003) gate/usage_max 0.5511 (0.5498) gate/usage_min 0.2238 (0.2247) gate/usage_std 0.1540 (0.1530) teacher/entropy 0.5757 (0.5055) teacher/usage_max 0.7254 (0.7780) teacher/usage_min 0.0675 (0.0521) teacher/usage_std 0.2830 (0.3185) nleep/row_max_mean 1197.9006 (1200.0183) nleep/row_max_std 17.8617 (14.8107) nleep/row_min_mean 1194.3579 (1196.1364) lr 1.8763e-03 eta 0:57:00
epoch [10/50] batch [120/244] time 0.442 (0.364) data 0.000 (0.002) loss 1.6121 (1.4793) teacher_loss 1.1989 (1.0493) loss_zs_kd 0.0350 (0.0294) loss_oracle 0.2533 (0.2514) kd_loss 0.2691 (0.2895) acc 68.7500 (72.3698) gate/entropy 0.9987 (1.0000) gate/usage_max 0.5516 (0.5500) gate/usage_min 0.2235 (0.2245) gate/usage_std 0.1543 (0.1532) teacher/entropy 0.5487 (0.5098) teacher/usage_max 0.7518 (0.7741) teacher/usage_min 0.0504 (0.0523) teacher/usage_std 0.3020 (0.3161) nleep/row_max_mean 1196.4706 (1199.8044) nleep/row_max_std 12.9863 (14.8300) nleep/row_min_mean 1192.8940 (1195.9439) lr 1.8763e-03 eta 0:59:59
epoch [10/50] batch [140/244] time 0.463 (0.380) data 0.000 (0.002) loss 1.3652 (1.4811) teacher_loss 0.9609 (1.0498) loss_zs_kd 0.0128 (0.0293) loss_oracle 0.2825 (0.2551) kd_loss 0.2567 (0.2891) acc 78.1250 (72.2321) gate/entropy 0.9982 (0.9998) gate/usage_max 0.5521 (0.5503) gate/usage_min 0.2231 (0.2243) gate/usage_std 0.1547 (0.1534) teacher/entropy 0.5663 (0.5119) teacher/usage_max 0.7454 (0.7719) teacher/usage_min 0.0673 (0.0525) teacher/usage_std 0.2955 (0.3146) nleep/row_max_mean 1202.4817 (1199.7099) nleep/row_max_std 15.5168 (14.8481) nleep/row_min_mean 1199.1101 (1195.8703) lr 1.8763e-03 eta 1:02:25
epoch [10/50] batch [160/244] time 0.203 (0.355) data 0.000 (0.002) loss 1.2172 (1.4686) teacher_loss 0.7611 (1.0411) loss_zs_kd 0.0203 (0.0292) loss_oracle 0.2974 (0.2550) kd_loss 0.2972 (0.2854) acc 75.0000 (72.6172) gate/entropy 0.9976 (0.9995) gate/usage_max 0.5527 (0.5506) gate/usage_min 0.2227 (0.2241) gate/usage_std 0.1551 (0.1536) teacher/entropy 0.5474 (0.5187) teacher/usage_max 0.7208 (0.7681) teacher/usage_min 0.0585 (0.0540) teacher/usage_std 0.2818 (0.3120) nleep/row_max_mean 1198.4567 (1199.6278) nleep/row_max_std 14.6105 (14.8725) nleep/row_min_mean 1194.8308 (1195.8297) lr 1.8763e-03 eta 0:58:15
epoch [10/50] batch [180/244] time 0.077 (0.359) data 0.000 (0.002) loss 1.6475 (1.4627) teacher_loss 1.2871 (1.0357) loss_zs_kd 0.0402 (0.0292) loss_oracle 0.2407 (0.2580) kd_loss 0.2200 (0.2834) acc 71.8750 (72.7604) gate/entropy 0.9972 (0.9993) gate/usage_max 0.5531 (0.5509) gate/usage_min 0.2225 (0.2240) gate/usage_std 0.1554 (0.1538) teacher/entropy 0.6623 (0.5247) teacher/usage_max 0.6791 (0.7635) teacher/usage_min 0.0937 (0.0564) teacher/usage_std 0.2505 (0.3088) nleep/row_max_mean 1197.3762 (1199.5262) nleep/row_max_std 17.7890 (14.9535) nleep/row_min_mean 1194.4160 (1195.7599) lr 1.8763e-03 eta 0:58:45
epoch [10/50] batch [200/244] time 0.091 (0.341) data 0.000 (0.002) loss 1.4708 (1.4724) teacher_loss 1.0559 (1.0449) loss_zs_kd 0.0176 (0.0298) loss_oracle 0.2809 (0.2607) kd_loss 0.2656 (0.2822) acc 68.7500 (72.6250) gate/entropy 0.9968 (0.9991) gate/usage_max 0.5536 (0.5511) gate/usage_min 0.2222 (0.2238) gate/usage_std 0.1557 (0.1540) teacher/entropy 0.5209 (0.5294) teacher/usage_max 0.7844 (0.7593) teacher/usage_min 0.0649 (0.0577) teacher/usage_std 0.3209 (0.3060) nleep/row_max_mean 1202.1621 (1199.3607) nleep/row_max_std 20.4860 (15.0318) nleep/row_min_mean 1198.3046 (1195.6130) lr 1.8763e-03 eta 0:55:39
epoch [10/50] batch [220/244] time 0.098 (0.326) data 0.000 (0.001) loss 1.3642 (1.4801) teacher_loss 0.9715 (1.0517) loss_zs_kd 0.0308 (0.0297) loss_oracle 0.3082 (0.2635) kd_loss 0.2231 (0.2818) acc 75.0000 (72.5852) gate/entropy 0.9965 (0.9988) gate/usage_max 0.5539 (0.5513) gate/usage_min 0.2219 (0.2236) gate/usage_std 0.1560 (0.1542) teacher/entropy 0.6625 (0.5331) teacher/usage_max 0.6748 (0.7553) teacher/usage_min 0.0780 (0.0585) teacher/usage_std 0.2511 (0.3034) nleep/row_max_mean 1193.0764 (1199.3571) nleep/row_max_std 12.4118 (15.1788) nleep/row_min_mean 1189.9512 (1195.6234) lr 1.8763e-03 eta 0:53:12
epoch [10/50] batch [240/244] time 0.084 (0.307) data 0.000 (0.001) loss 1.8199 (1.4837) teacher_loss 1.4592 (1.0553) loss_zs_kd 0.0346 (0.0299) loss_oracle 0.2516 (0.2659) kd_loss 0.2176 (0.2805) acc 62.5000 (72.4349) gate/entropy 0.9962 (0.9986) gate/usage_max 0.5543 (0.5516) gate/usage_min 0.2216 (0.2235) gate/usage_std 0.1563 (0.1543) teacher/entropy 0.6883 (0.5359) teacher/usage_max 0.6519 (0.7535) teacher/usage_min 0.0764 (0.0585) teacher/usage_std 0.2390 (0.3023) nleep/row_max_mean 1193.9336 (1199.3421) nleep/row_max_std 12.3725 (15.1576) nleep/row_min_mean 1190.8090 (1195.6188) lr 1.8763e-03 eta 0:50:01
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,831
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,028
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.1%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [11/50] batch [20/244] time 0.507 (0.487) data 0.000 (0.014) loss 1.1948 (1.4648) teacher_loss 0.8324 (1.0398) loss_zs_kd 0.0255 (0.0295) loss_oracle 0.2455 (0.2803) kd_loss 0.2269 (0.2701) acc 78.1250 (73.4375) gate/entropy 0.9959 (0.9960) gate/usage_max 0.5546 (0.5545) gate/usage_min 0.2214 (0.2214) gate/usage_std 0.1564 (0.1564) teacher/entropy 0.6743 (0.5715) teacher/usage_max 0.6565 (0.7224) teacher/usage_min 0.0795 (0.0649) teacher/usage_std 0.2406 (0.2829) nleep/row_max_mean 1196.3030 (1199.5329) nleep/row_max_std 15.0430 (16.9357) nleep/row_min_mean 1193.3083 (1196.0134) lr 1.8443e-03 eta 1:19:01
epoch [11/50] batch [40/244] time 0.399 (0.456) data 0.000 (0.007) loss 1.5198 (1.4620) teacher_loss 1.0389 (1.0325) loss_zs_kd 0.0270 (0.0296) loss_oracle 0.3304 (0.2828) kd_loss 0.3021 (0.2733) acc 68.7500 (73.2031) gate/entropy 0.9952 (0.9958) gate/usage_max 0.5553 (0.5547) gate/usage_min 0.2209 (0.2213) gate/usage_std 0.1570 (0.1565) teacher/entropy 0.5246 (0.5630) teacher/usage_max 0.7384 (0.7280) teacher/usage_min 0.0726 (0.0655) teacher/usage_std 0.2903 (0.2857) nleep/row_max_mean 1199.3599 (1199.3600) nleep/row_max_std 15.0503 (16.0917) nleep/row_min_mean 1195.6201 (1195.7701) lr 1.8443e-03 eta 1:13:55
epoch [11/50] batch [60/244] time 0.455 (0.460) data 0.000 (0.005) loss 1.2832 (1.4627) teacher_loss 0.8260 (1.0291) loss_zs_kd 0.0330 (0.0315) loss_oracle 0.2874 (0.2851) kd_loss 0.2971 (0.2753) acc 78.1250 (73.2812) gate/entropy 0.9953 (0.9956) gate/usage_max 0.5552 (0.5549) gate/usage_min 0.2209 (0.2212) gate/usage_std 0.1569 (0.1567) teacher/entropy 0.5997 (0.5583) teacher/usage_max 0.6613 (0.7309) teacher/usage_min 0.0833 (0.0644) teacher/usage_std 0.2423 (0.2877) nleep/row_max_mean 1197.5525 (1199.0864) nleep/row_max_std 15.0048 (15.9212) nleep/row_min_mean 1193.8762 (1195.4404) lr 1.8443e-03 eta 1:14:25
epoch [11/50] batch [80/244] time 0.119 (0.417) data 0.000 (0.004) loss 1.3983 (1.4566) teacher_loss 0.9825 (1.0223) loss_zs_kd 0.0306 (0.0311) loss_oracle 0.2877 (0.2852) kd_loss 0.2566 (0.2761) acc 78.1250 (73.3203) gate/entropy 0.9949 (0.9954) gate/usage_max 0.5557 (0.5551) gate/usage_min 0.2206 (0.2210) gate/usage_std 0.1572 (0.1568) teacher/entropy 0.5918 (0.5535) teacher/usage_max 0.7146 (0.7351) teacher/usage_min 0.1012 (0.0638) teacher/usage_std 0.2717 (0.2903) nleep/row_max_mean 1193.9454 (1199.1558) nleep/row_max_std 12.1348 (15.9726) nleep/row_min_mean 1190.7205 (1195.4978) lr 1.8443e-03 eta 1:07:12
epoch [11/50] batch [100/244] time 0.260 (0.411) data 0.000 (0.003) loss 1.3728 (1.4425) teacher_loss 0.9211 (1.0112) loss_zs_kd 0.0388 (0.0304) loss_oracle 0.2699 (0.2780) kd_loss 0.2974 (0.2770) acc 75.0000 (73.1875) gate/entropy 0.9947 (0.9953) gate/usage_max 0.5559 (0.5553) gate/usage_min 0.2204 (0.2209) gate/usage_std 0.1574 (0.1569) teacher/entropy 0.5288 (0.5506) teacher/usage_max 0.7385 (0.7372) teacher/usage_min 0.0821 (0.0636) teacher/usage_std 0.2892 (0.2915) nleep/row_max_mean 1198.3005 (1199.0404) nleep/row_max_std 17.0639 (15.7821) nleep/row_min_mean 1194.5061 (1195.3818) lr 1.8443e-03 eta 1:06:13
epoch [11/50] batch [120/244] time 0.186 (0.359) data 0.000 (0.003) loss 1.3206 (1.4563) teacher_loss 0.9657 (1.0257) loss_zs_kd 0.0197 (0.0307) loss_oracle 0.1937 (0.2737) kd_loss 0.2482 (0.2784) acc 75.0000 (73.0208) gate/entropy 0.9939 (0.9951) gate/usage_max 0.5568 (0.5554) gate/usage_min 0.2199 (0.2208) gate/usage_std 0.1580 (0.1571) teacher/entropy 0.5770 (0.5486) teacher/usage_max 0.7384 (0.7376) teacher/usage_min 0.0504 (0.0628) teacher/usage_std 0.2938 (0.2918) nleep/row_max_mean 1198.8345 (1199.0861) nleep/row_max_std 15.7014 (15.8921) nleep/row_min_mean 1195.3391 (1195.4216) lr 1.8443e-03 eta 0:57:36
epoch [11/50] batch [140/244] time 0.376 (0.334) data 0.000 (0.002) loss 0.8980 (1.4602) teacher_loss 0.5455 (1.0303) loss_zs_kd 0.0206 (0.0298) loss_oracle 0.2394 (0.2736) kd_loss 0.2224 (0.2782) acc 81.2500 (72.9464) gate/entropy 0.9944 (0.9950) gate/usage_max 0.5562 (0.5556) gate/usage_min 0.2202 (0.2207) gate/usage_std 0.1576 (0.1572) teacher/entropy 0.6775 (0.5522) teacher/usage_max 0.6570 (0.7338) teacher/usage_min 0.0728 (0.0631) teacher/usage_std 0.2427 (0.2895) nleep/row_max_mean 1196.6235 (1199.0695) nleep/row_max_std 12.4620 (15.8712) nleep/row_min_mean 1193.6826 (1195.4132) lr 1.8443e-03 eta 0:53:30
epoch [11/50] batch [160/244] time 0.472 (0.351) data 0.000 (0.002) loss 1.3958 (1.4723) teacher_loss 0.9141 (1.0385) loss_zs_kd 0.0438 (0.0302) loss_oracle 0.3043 (0.2773) kd_loss 0.3077 (0.2800) acc 78.1250 (72.9883) gate/entropy 0.9936 (0.9948) gate/usage_max 0.5571 (0.5558) gate/usage_min 0.2196 (0.2205) gate/usage_std 0.1582 (0.1573) teacher/entropy 0.5357 (0.5550) teacher/usage_max 0.7180 (0.7285) teacher/usage_min 0.0551 (0.0632) teacher/usage_std 0.2809 (0.2864) nleep/row_max_mean 1206.0850 (1199.0247) nleep/row_max_std 17.9397 (15.8894) nleep/row_min_mean 1202.0630 (1195.3685) lr 1.8443e-03 eta 0:56:08
epoch [11/50] batch [180/244] time 0.495 (0.367) data 0.000 (0.002) loss 1.3686 (1.4722) teacher_loss 0.9369 (1.0339) loss_zs_kd 0.0283 (0.0305) loss_oracle 0.2531 (0.2834) kd_loss 0.2910 (0.2813) acc 78.1250 (72.9340) gate/entropy 0.9934 (0.9947) gate/usage_max 0.5572 (0.5559) gate/usage_min 0.2194 (0.2204) gate/usage_std 0.1583 (0.1574) teacher/entropy 0.6349 (0.5592) teacher/usage_max 0.6274 (0.7223) teacher/usage_min 0.0465 (0.0625) teacher/usage_std 0.2372 (0.2831) nleep/row_max_mean 1200.5984 (1198.9798) nleep/row_max_std 14.0868 (15.8110) nleep/row_min_mean 1197.2258 (1195.3198) lr 1.8443e-03 eta 0:58:32
epoch [11/50] batch [200/244] time 0.499 (0.379) data 0.000 (0.002) loss 1.6367 (1.4715) teacher_loss 1.2024 (1.0313) loss_zs_kd 0.0115 (0.0306) loss_oracle 0.2538 (0.2829) kd_loss 0.3016 (0.2834) acc 71.8750 (72.8438) gate/entropy 0.9936 (0.9946) gate/usage_max 0.5571 (0.5560) gate/usage_min 0.2193 (0.2203) gate/usage_std 0.1583 (0.1575) teacher/entropy 0.6307 (0.5633) teacher/usage_max 0.6206 (0.7154) teacher/usage_min 0.0841 (0.0627) teacher/usage_std 0.2207 (0.2791) nleep/row_max_mean 1198.3491 (1198.9200) nleep/row_max_std 14.7087 (15.7192) nleep/row_min_mean 1194.9667 (1195.2650) lr 1.8443e-03 eta 1:00:19
epoch [11/50] batch [220/244] time 0.089 (0.376) data 0.000 (0.001) loss 0.9382 (1.4616) teacher_loss 0.4715 (1.0193) loss_zs_kd 0.0185 (0.0300) loss_oracle 0.2605 (0.2832) kd_loss 0.3272 (0.2858) acc 93.7500 (73.1960) gate/entropy 0.9936 (0.9945) gate/usage_max 0.5571 (0.5561) gate/usage_min 0.2192 (0.2202) gate/usage_std 0.1582 (0.1575) teacher/entropy 0.6086 (0.5691) teacher/usage_max 0.6173 (0.7064) teacher/usage_min 0.0887 (0.0643) teacher/usage_std 0.2176 (0.2739) nleep/row_max_mean 1200.2280 (1198.9550) nleep/row_max_std 12.8240 (15.6954) nleep/row_min_mean 1197.0562 (1195.3242) lr 1.8443e-03 eta 0:59:51
epoch [11/50] batch [240/244] time 0.267 (0.378) data 0.000 (0.001) loss 1.1931 (1.4638) teacher_loss 0.7406 (1.0199) loss_zs_kd 0.0311 (0.0298) loss_oracle 0.2829 (0.2833) kd_loss 0.2955 (0.2874) acc 78.1250 (73.3073) gate/entropy 0.9937 (0.9944) gate/usage_max 0.5570 (0.5562) gate/usage_min 0.2191 (0.2201) gate/usage_std 0.1582 (0.1576) teacher/entropy 0.6406 (0.5743) teacher/usage_max 0.6159 (0.6988) teacher/usage_min 0.0709 (0.0645) teacher/usage_std 0.2230 (0.2698) nleep/row_max_mean 1204.2473 (1199.0404) nleep/row_max_std 16.2628 (15.6757) nleep/row_min_mean 1200.8850 (1195.4291) lr 1.8443e-03 eta 0:59:56
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,824
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,020
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 90.0%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [12/50] batch [20/244] time 0.467 (0.489) data 0.000 (0.013) loss 1.5249 (1.4024) teacher_loss 1.1388 (0.9117) loss_zs_kd 0.0234 (0.0308) loss_oracle 0.2572 (0.3150) kd_loss 0.2458 (0.3179) acc 68.7500 (76.0938) gate/entropy 0.9933 (0.9935) gate/usage_max 0.5574 (0.5572) gate/usage_min 0.2187 (0.2189) gate/usage_std 0.1585 (0.1583) teacher/entropy 0.6324 (0.6531) teacher/usage_max 0.6794 (0.5779) teacher/usage_min 0.0682 (0.0814) teacher/usage_std 0.2560 (0.2051) nleep/row_max_mean 1197.1082 (1199.1062) nleep/row_max_std 13.0053 (15.4943) nleep/row_min_mean 1193.5891 (1195.8872) lr 1.8090e-03 eta 1:17:26
epoch [12/50] batch [40/244] time 0.439 (0.475) data 0.000 (0.007) loss 1.3335 (1.4395) teacher_loss 0.9116 (0.9467) loss_zs_kd 0.0402 (0.0332) loss_oracle 0.2861 (0.3039) kd_loss 0.2588 (0.3243) acc 81.2500 (75.9375) gate/entropy 0.9935 (0.9935) gate/usage_max 0.5572 (0.5572) gate/usage_min 0.2186 (0.2188) gate/usage_std 0.1583 (0.1583) teacher/entropy 0.7202 (0.6565) teacher/usage_max 0.5691 (0.5671) teacher/usage_min 0.0870 (0.0842) teacher/usage_std 0.1969 (0.2005) nleep/row_max_mean 1199.6755 (1198.8935) nleep/row_max_std 11.8938 (15.5007) nleep/row_min_mean 1196.9194 (1195.6848) lr 1.8090e-03 eta 1:14:58
epoch [12/50] batch [60/244] time 0.455 (0.471) data 0.000 (0.004) loss 1.4041 (1.4744) teacher_loss 0.9921 (0.9904) loss_zs_kd 0.0184 (0.0308) loss_oracle 0.2087 (0.2907) kd_loss 0.2985 (0.3233) acc 71.8750 (75.1042) gate/entropy 0.9935 (0.9936) gate/usage_max 0.5572 (0.5571) gate/usage_min 0.2185 (0.2187) gate/usage_std 0.1583 (0.1583) teacher/entropy 0.6851 (0.6642) teacher/usage_max 0.5632 (0.5608) teacher/usage_min 0.0534 (0.0842) teacher/usage_std 0.2111 (0.1987) nleep/row_max_mean 1203.9351 (1198.7081) nleep/row_max_std 16.3383 (15.3706) nleep/row_min_mean 1200.8354 (1195.5494) lr 1.8090e-03 eta 1:14:09
epoch [12/50] batch [80/244] time 0.474 (0.418) data 0.000 (0.003) loss 1.3311 (1.4885) teacher_loss 0.8119 (1.0066) loss_zs_kd 0.0169 (0.0308) loss_oracle 0.3551 (0.2922) kd_loss 0.3332 (0.3204) acc 78.1250 (74.4141) gate/entropy 0.9940 (0.9936) gate/usage_max 0.5566 (0.5571) gate/usage_min 0.2186 (0.2187) gate/usage_std 0.1579 (0.1582) teacher/entropy 0.7078 (0.6665) teacher/usage_max 0.5009 (0.5611) teacher/usage_min 0.1186 (0.0883) teacher/usage_std 0.1596 (0.1968) nleep/row_max_mean 1195.7576 (1198.5699) nleep/row_max_std 15.1909 (15.4471) nleep/row_min_mean 1193.0244 (1195.4463) lr 1.8090e-03 eta 1:05:40
epoch [12/50] batch [100/244] time 0.083 (0.395) data 0.000 (0.003) loss 1.6259 (1.4927) teacher_loss 1.1560 (1.0107) loss_zs_kd 0.0416 (0.0307) loss_oracle 0.2387 (0.2988) kd_loss 0.3298 (0.3172) acc 65.6250 (74.1562) gate/entropy 0.9936 (0.9936) gate/usage_max 0.5571 (0.5570) gate/usage_min 0.2182 (0.2186) gate/usage_std 0.1582 (0.1582) teacher/entropy 0.6179 (0.6692) teacher/usage_max 0.6028 (0.5613) teacher/usage_min 0.0782 (0.0894) teacher/usage_std 0.2144 (0.1963) nleep/row_max_mean 1202.1956 (1198.5567) nleep/row_max_std 14.6713 (15.2938) nleep/row_min_mean 1198.8328 (1195.4577) lr 1.8090e-03 eta 1:01:57
epoch [12/50] batch [120/244] time 0.102 (0.360) data 0.000 (0.002) loss 1.3849 (1.4939) teacher_loss 0.9416 (1.0163) loss_zs_kd 0.0593 (0.0306) loss_oracle 0.2505 (0.2929) kd_loss 0.2884 (0.3158) acc 75.0000 (74.0104) gate/entropy 0.9937 (0.9937) gate/usage_max 0.5569 (0.5570) gate/usage_min 0.2181 (0.2186) gate/usage_std 0.1581 (0.1582) teacher/entropy 0.7248 (0.6701) teacher/usage_max 0.5318 (0.5617) teacher/usage_min 0.1220 (0.0894) teacher/usage_std 0.1676 (0.1963) nleep/row_max_mean 1198.5908 (1198.6701) nleep/row_max_std 14.7889 (15.1972) nleep/row_min_mean 1195.7629 (1195.5855) lr 1.8090e-03 eta 0:56:19
epoch [12/50] batch [140/244] time 0.451 (0.356) data 0.000 (0.002) loss 1.7206 (1.5045) teacher_loss 1.2349 (1.0268) loss_zs_kd 0.0343 (0.0311) loss_oracle 0.2760 (0.2913) kd_loss 0.3306 (0.3165) acc 71.8750 (73.7723) gate/entropy 0.9940 (0.9937) gate/usage_max 0.5566 (0.5570) gate/usage_min 0.2181 (0.2185) gate/usage_std 0.1579 (0.1582) teacher/entropy 0.6447 (0.6717) teacher/usage_max 0.5715 (0.5591) teacher/usage_min 0.0800 (0.0916) teacher/usage_std 0.2009 (0.1940) nleep/row_max_mean 1203.0828 (1198.7118) nleep/row_max_std 13.7967 (15.1209) nleep/row_min_mean 1199.9634 (1195.6422) lr 1.8090e-03 eta 0:55:41
epoch [12/50] batch [160/244] time 0.501 (0.373) data 0.000 (0.002) loss 1.6198 (1.4966) teacher_loss 1.1666 (1.0205) loss_zs_kd 0.0326 (0.0311) loss_oracle 0.2710 (0.2906) kd_loss 0.3014 (0.3153) acc 68.7500 (73.7695) gate/entropy 0.9941 (0.9937) gate/usage_max 0.5565 (0.5569) gate/usage_min 0.2180 (0.2184) gate/usage_std 0.1578 (0.1581) teacher/entropy 0.7284 (0.6738) teacher/usage_max 0.5131 (0.5580) teacher/usage_min 0.1380 (0.0947) teacher/usage_std 0.1535 (0.1922) nleep/row_max_mean 1195.6405 (1198.5836) nleep/row_max_std 15.0875 (15.1061) nleep/row_min_mean 1193.0498 (1195.5404) lr 1.8090e-03 eta 0:58:11
epoch [12/50] batch [180/244] time 0.445 (0.384) data 0.000 (0.002) loss 1.5795 (1.4962) teacher_loss 1.1318 (1.0222) loss_zs_kd 0.0648 (0.0314) loss_oracle 0.2759 (0.2891) kd_loss 0.2773 (0.3138) acc 71.8750 (73.8021) gate/entropy 0.9943 (0.9938) gate/usage_max 0.5563 (0.5569) gate/usage_min 0.2180 (0.2184) gate/usage_std 0.1577 (0.1581) teacher/entropy 0.7392 (0.6768) teacher/usage_max 0.5289 (0.5563) teacher/usage_min 0.1566 (0.0976) teacher/usage_std 0.1526 (0.1901) nleep/row_max_mean 1192.0186 (1198.4657) nleep/row_max_std 14.6711 (15.0609) nleep/row_min_mean 1189.3744 (1195.4487) lr 1.8090e-03 eta 0:59:42
epoch [12/50] batch [200/244] time 0.471 (0.390) data 0.000 (0.001) loss 1.5470 (1.4867) teacher_loss 1.0850 (1.0154) loss_zs_kd 0.0537 (0.0316) loss_oracle 0.3216 (0.2888) kd_loss 0.2744 (0.3111) acc 65.6250 (73.8906) gate/entropy 0.9940 (0.9938) gate/usage_max 0.5566 (0.5568) gate/usage_min 0.2177 (0.2183) gate/usage_std 0.1579 (0.1581) teacher/entropy 0.7203 (0.6795) teacher/usage_max 0.5533 (0.5565) teacher/usage_min 0.1669 (0.1004) teacher/usage_std 0.1622 (0.1891) nleep/row_max_mean 1198.4614 (1198.5305) nleep/row_max_std 13.3738 (15.0433) nleep/row_min_mean 1195.7463 (1195.5414) lr 1.8090e-03 eta 1:00:30
epoch [12/50] batch [220/244] time 0.420 (0.379) data 0.000 (0.001) loss 1.5892 (1.4875) teacher_loss 1.1266 (1.0170) loss_zs_kd 0.0310 (0.0318) loss_oracle 0.3573 (0.2906) kd_loss 0.2685 (0.3092) acc 68.7500 (73.9915) gate/entropy 0.9941 (0.9938) gate/usage_max 0.5564 (0.5568) gate/usage_min 0.2177 (0.2183) gate/usage_std 0.1578 (0.1580) teacher/entropy 0.6765 (0.6810) teacher/usage_max 0.6061 (0.5573) teacher/usage_min 0.1216 (0.1036) teacher/usage_std 0.2025 (0.1882) nleep/row_max_mean 1200.9816 (1198.4449) nleep/row_max_std 16.9937 (15.0051) nleep/row_min_mean 1198.1422 (1195.4745) lr 1.8090e-03 eta 0:58:46
epoch [12/50] batch [240/244] time 0.080 (0.372) data 0.000 (0.001) loss 1.2602 (1.4810) teacher_loss 0.8747 (1.0119) loss_zs_kd 0.0331 (0.0318) loss_oracle 0.2743 (0.2916) kd_loss 0.2319 (0.3074) acc 75.0000 (74.1016) gate/entropy 0.9939 (0.9939) gate/usage_max 0.5567 (0.5568) gate/usage_min 0.2175 (0.2182) gate/usage_std 0.1580 (0.1580) teacher/entropy 0.6864 (0.6802) teacher/usage_max 0.6349 (0.5601) teacher/usage_min 0.0997 (0.1041) teacher/usage_std 0.2237 (0.1891) nleep/row_max_mean 1197.9559 (1198.3380) nleep/row_max_std 13.6766 (14.9400) nleep/row_min_mean 1195.0654 (1195.3735) lr 1.8090e-03 eta 0:57:26
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,826
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,013
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.7%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [13/50] batch [20/244] time 0.468 (0.494) data 0.000 (0.015) loss 1.1585 (1.3837) teacher_loss 0.6270 (0.9363) loss_zs_kd 0.0208 (0.0273) loss_oracle 0.3500 (0.2900) kd_loss 0.3460 (0.2888) acc 90.6250 (76.8750) gate/entropy 0.9942 (0.9942) gate/usage_max 0.5564 (0.5564) gate/usage_min 0.2175 (0.2175) gate/usage_std 0.1578 (0.1577) teacher/entropy 0.6078 (0.6837) teacher/usage_max 0.5968 (0.5756) teacher/usage_min 0.1357 (0.1197) teacher/usage_std 0.1939 (0.1895) nleep/row_max_mean 1198.2976 (1198.0119) nleep/row_max_std 15.6360 (14.5429) nleep/row_min_mean 1195.4197 (1195.1958) lr 1.7705e-03 eta 1:16:07
epoch [13/50] batch [40/244] time 0.498 (0.481) data 0.000 (0.007) loss 1.4233 (1.4082) teacher_loss 0.9450 (0.9590) loss_zs_kd 0.0232 (0.0301) loss_oracle 0.3115 (0.2894) kd_loss 0.3110 (0.2895) acc 81.2500 (75.3125) gate/entropy 0.9946 (0.9942) gate/usage_max 0.5559 (0.5563) gate/usage_min 0.2176 (0.2175) gate/usage_std 0.1574 (0.1577) teacher/entropy 0.6901 (0.6881) teacher/usage_max 0.5440 (0.5701) teacher/usage_min 0.1316 (0.1235) teacher/usage_std 0.1685 (0.1861) nleep/row_max_mean 1199.7295 (1198.0119) nleep/row_max_std 15.1347 (14.9114) nleep/row_min_mean 1196.9135 (1195.2235) lr 1.7705e-03 eta 1:14:00
epoch [13/50] batch [60/244] time 0.527 (0.484) data 0.000 (0.005) loss 1.3078 (1.4342) teacher_loss 0.8282 (0.9746) loss_zs_kd 0.0521 (0.0325) loss_oracle 0.3128 (0.2991) kd_loss 0.2971 (0.2938) acc 75.0000 (74.8958) gate/entropy 0.9943 (0.9942) gate/usage_max 0.5563 (0.5563) gate/usage_min 0.2173 (0.2174) gate/usage_std 0.1577 (0.1577) teacher/entropy 0.6381 (0.6772) teacher/usage_max 0.6155 (0.5772) teacher/usage_min 0.0850 (0.1204) teacher/usage_std 0.2179 (0.1905) nleep/row_max_mean 1197.6323 (1197.6754) nleep/row_max_std 15.3886 (15.1261) nleep/row_min_mean 1194.4943 (1194.8263) lr 1.7705e-03 eta 1:14:18
epoch [13/50] batch [80/244] time 0.463 (0.426) data 0.000 (0.004) loss 2.0765 (1.4661) teacher_loss 1.4968 (1.0049) loss_zs_kd 0.0199 (0.0329) loss_oracle 0.4035 (0.3022) kd_loss 0.3680 (0.2936) acc 56.2500 (74.2188) gate/entropy 0.9942 (0.9942) gate/usage_max 0.5564 (0.5563) gate/usage_min 0.2171 (0.2174) gate/usage_std 0.1578 (0.1577) teacher/entropy 0.5621 (0.6776) teacher/usage_max 0.6225 (0.5770) teacher/usage_min 0.1407 (0.1211) teacher/usage_std 0.2082 (0.1900) nleep/row_max_mean 1192.2825 (1197.1997) nleep/row_max_std 12.9455 (14.7090) nleep/row_min_mean 1188.8457 (1194.3695) lr 1.7705e-03 eta 1:05:14
epoch [13/50] batch [100/244] time 0.109 (0.394) data 0.000 (0.003) loss 2.0322 (1.4740) teacher_loss 1.5317 (1.0114) loss_zs_kd 0.0277 (0.0328) loss_oracle 0.3539 (0.3003) kd_loss 0.3097 (0.2960) acc 53.1250 (73.9688) gate/entropy 0.9941 (0.9942) gate/usage_max 0.5564 (0.5563) gate/usage_min 0.2171 (0.2173) gate/usage_std 0.1578 (0.1577) teacher/entropy 0.6580 (0.6763) teacher/usage_max 0.5804 (0.5757) teacher/usage_min 0.1241 (0.1221) teacher/usage_std 0.1882 (0.1889) nleep/row_max_mean 1194.2795 (1197.0012) nleep/row_max_std 13.1787 (14.5980) nleep/row_min_mean 1191.4801 (1194.1728) lr 1.7705e-03 eta 1:00:18
epoch [13/50] batch [120/244] time 0.086 (0.357) data 0.000 (0.003) loss 1.5623 (1.4779) teacher_loss 1.0639 (1.0057) loss_zs_kd 0.0292 (0.0325) loss_oracle 0.3305 (0.3078) kd_loss 0.3186 (0.3021) acc 68.7500 (74.2188) gate/entropy 0.9939 (0.9942) gate/usage_max 0.5567 (0.5563) gate/usage_min 0.2169 (0.2173) gate/usage_std 0.1580 (0.1577) teacher/entropy 0.6113 (0.6702) teacher/usage_max 0.6217 (0.5758) teacher/usage_min 0.1013 (0.1234) teacher/usage_std 0.2161 (0.1884) nleep/row_max_mean 1199.4152 (1197.2810) nleep/row_max_std 18.2877 (14.5609) nleep/row_min_mean 1196.4692 (1194.4229) lr 1.7705e-03 eta 0:54:30
epoch [13/50] batch [140/244] time 0.477 (0.365) data 0.000 (0.002) loss 1.9623 (1.4944) teacher_loss 1.5019 (1.0205) loss_zs_kd 0.0487 (0.0331) loss_oracle 0.3154 (0.3121) kd_loss 0.2783 (0.3014) acc 65.6250 (73.9955) gate/entropy 0.9941 (0.9942) gate/usage_max 0.5565 (0.5563) gate/usage_min 0.2168 (0.2172) gate/usage_std 0.1578 (0.1577) teacher/entropy 0.6896 (0.6697) teacher/usage_max 0.5806 (0.5771) teacher/usage_min 0.1235 (0.1235) teacher/usage_std 0.1885 (0.1891) nleep/row_max_mean 1199.7183 (1197.3945) nleep/row_max_std 16.3626 (14.6016) nleep/row_min_mean 1196.6826 (1194.5345) lr 1.7705e-03 eta 0:55:28
epoch [13/50] batch [160/244] time 0.470 (0.376) data 0.000 (0.002) loss 1.9256 (1.4861) teacher_loss 1.4510 (1.0110) loss_zs_kd 0.0325 (0.0327) loss_oracle 0.3339 (0.3140) kd_loss 0.2914 (0.3017) acc 62.5000 (74.2188) gate/entropy 0.9943 (0.9942) gate/usage_max 0.5563 (0.5563) gate/usage_min 0.2168 (0.2172) gate/usage_std 0.1577 (0.1577) teacher/entropy 0.7076 (0.6715) teacher/usage_max 0.5446 (0.5746) teacher/usage_min 0.1128 (0.1239) teacher/usage_std 0.1764 (0.1878) nleep/row_max_mean 1193.6140 (1197.4000) nleep/row_max_std 13.9848 (14.5223) nleep/row_min_mean 1190.9111 (1194.5451) lr 1.7705e-03 eta 0:57:03
epoch [13/50] batch [180/244] time 0.462 (0.385) data 0.000 (0.002) loss 1.6184 (1.4941) teacher_loss 1.1122 (1.0146) loss_zs_kd 0.0415 (0.0331) loss_oracle 0.2893 (0.3151) kd_loss 0.3408 (0.3054) acc 84.3750 (74.1493) gate/entropy 0.9942 (0.9942) gate/usage_max 0.5563 (0.5563) gate/usage_min 0.2166 (0.2171) gate/usage_std 0.1577 (0.1577) teacher/entropy 0.6486 (0.6692) teacher/usage_max 0.5570 (0.5730) teacher/usage_min 0.1505 (0.1240) teacher/usage_std 0.1685 (0.1870) nleep/row_max_mean 1196.8708 (1197.5722) nleep/row_max_std 13.6097 (14.4714) nleep/row_min_mean 1193.8893 (1194.7061) lr 1.7705e-03 eta 0:58:24
epoch [13/50] batch [200/244] time 0.538 (0.395) data 0.000 (0.002) loss 1.4756 (1.4995) teacher_loss 1.0154 (1.0180) loss_zs_kd 0.0291 (0.0332) loss_oracle 0.3084 (0.3156) kd_loss 0.2914 (0.3071) acc 68.7500 (74.0469) gate/entropy 0.9946 (0.9943) gate/usage_max 0.5559 (0.5563) gate/usage_min 0.2166 (0.2171) gate/usage_std 0.1575 (0.1577) teacher/entropy 0.7450 (0.6721) teacher/usage_max 0.5027 (0.5684) teacher/usage_min 0.1183 (0.1258) teacher/usage_std 0.1602 (0.1843) nleep/row_max_mean 1198.8572 (1197.5860) nleep/row_max_std 13.4371 (14.4308) nleep/row_min_mean 1196.2656 (1194.7308) lr 1.7705e-03 eta 0:59:47
epoch [13/50] batch [220/244] time 0.415 (0.384) data 0.000 (0.002) loss 1.1550 (1.4938) teacher_loss 0.5726 (1.0088) loss_zs_kd 0.0362 (0.0333) loss_oracle 0.4048 (0.3173) kd_loss 0.3619 (0.3096) acc 87.5000 (74.2756) gate/entropy 0.9952 (0.9943) gate/usage_max 0.5552 (0.5562) gate/usage_min 0.2168 (0.2171) gate/usage_std 0.1569 (0.1577) teacher/entropy 0.7500 (0.6745) teacher/usage_max 0.4279 (0.5630) teacher/usage_min 0.1532 (0.1274) teacher/usage_std 0.1274 (0.1816) nleep/row_max_mean 1193.4241 (1197.5548) nleep/row_max_std 15.5651 (14.4775) nleep/row_min_mean 1190.9553 (1194.7044) lr 1.7705e-03 eta 0:57:54
epoch [13/50] batch [240/244] time 0.083 (0.371) data 0.000 (0.001) loss 1.8189 (1.4976) teacher_loss 1.1849 (1.0067) loss_zs_kd 0.0410 (0.0334) loss_oracle 0.4054 (0.3205) kd_loss 0.4108 (0.3139) acc 68.7500 (74.2969) gate/entropy 0.9953 (0.9944) gate/usage_max 0.5551 (0.5562) gate/usage_min 0.2166 (0.2170) gate/usage_std 0.1569 (0.1576) teacher/entropy 0.7098 (0.6751) teacher/usage_max 0.4283 (0.5579) teacher/usage_min 0.1615 (0.1286) teacher/usage_std 0.1217 (0.1791) nleep/row_max_mean 1197.6194 (1197.5900) nleep/row_max_std 16.7662 (14.5493) nleep/row_min_mean 1194.8500 (1194.7422) lr 1.7705e-03 eta 0:55:48
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,828
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,012
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.7%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [14/50] batch [20/244] time 0.467 (0.494) data 0.000 (0.013) loss 1.4459 (1.5206) teacher_loss 0.7975 (0.9822) loss_zs_kd 0.0491 (0.0343) loss_oracle 0.4251 (0.3551) kd_loss 0.4113 (0.3437) acc 84.3750 (74.3750) gate/entropy 0.9955 (0.9951) gate/usage_max 0.5549 (0.5553) gate/usage_min 0.2164 (0.2163) gate/usage_std 0.1567 (0.1570) teacher/entropy 0.6856 (0.6840) teacher/usage_max 0.4354 (0.5148) teacher/usage_min 0.1512 (0.1283) teacher/usage_std 0.1291 (0.1619) nleep/row_max_mean 1193.0410 (1197.2967) nleep/row_max_std 15.8717 (14.3414) nleep/row_min_mean 1190.2587 (1194.4231) lr 1.7290e-03 eta 1:14:09
epoch [14/50] batch [40/244] time 0.468 (0.484) data 0.000 (0.007) loss 1.2905 (1.5222) teacher_loss 0.8059 (0.9819) loss_zs_kd 0.0257 (0.0338) loss_oracle 0.3272 (0.3562) kd_loss 0.3082 (0.3452) acc 84.3750 (74.9219) gate/entropy 0.9952 (0.9952) gate/usage_max 0.5551 (0.5552) gate/usage_min 0.2161 (0.2163) gate/usage_std 0.1569 (0.1570) teacher/entropy 0.7033 (0.6834) teacher/usage_max 0.5319 (0.5150) teacher/usage_min 0.1471 (0.1348) teacher/usage_std 0.1573 (0.1586) nleep/row_max_mean 1193.6138 (1197.2853) nleep/row_max_std 11.1618 (14.6657) nleep/row_min_mean 1190.8816 (1194.4570) lr 1.7290e-03 eta 1:12:32
epoch [14/50] batch [60/244] time 0.497 (0.478) data 0.000 (0.005) loss 1.6132 (1.5193) teacher_loss 0.9663 (0.9725) loss_zs_kd 0.0338 (0.0341) loss_oracle 0.4520 (0.3658) kd_loss 0.4040 (0.3469) acc 78.1250 (74.8438) gate/entropy 0.9955 (0.9953) gate/usage_max 0.5548 (0.5551) gate/usage_min 0.2160 (0.2162) gate/usage_std 0.1567 (0.1569) teacher/entropy 0.6491 (0.6853) teacher/usage_max 0.4852 (0.5111) teacher/usage_min 0.1609 (0.1444) teacher/usage_std 0.1332 (0.1526) nleep/row_max_mean 1197.5518 (1197.5338) nleep/row_max_std 13.4777 (14.7333) nleep/row_min_mean 1194.8195 (1194.7289) lr 1.7290e-03 eta 1:11:25
epoch [14/50] batch [80/244] time 0.406 (0.424) data 0.000 (0.003) loss 1.5052 (1.5089) teacher_loss 0.8809 (0.9487) loss_zs_kd 0.0227 (0.0337) loss_oracle 0.4198 (0.3878) kd_loss 0.4030 (0.3495) acc 78.1250 (75.4297) gate/entropy 0.9962 (0.9954) gate/usage_max 0.5540 (0.5549) gate/usage_min 0.2160 (0.2162) gate/usage_std 0.1562 (0.1568) teacher/entropy 0.6558 (0.6921) teacher/usage_max 0.4753 (0.5015) teacher/usage_min 0.1259 (0.1475) teacher/usage_std 0.1500 (0.1480) nleep/row_max_mean 1196.8467 (1197.8472) nleep/row_max_std 14.3918 (14.7620) nleep/row_min_mean 1193.8893 (1195.0727) lr 1.7290e-03 eta 1:03:16
epoch [14/50] batch [100/244] time 0.099 (0.391) data 0.000 (0.003) loss 1.5926 (1.5065) teacher_loss 1.1251 (0.9421) loss_zs_kd 0.0289 (0.0334) loss_oracle 0.3191 (0.3886) kd_loss 0.2934 (0.3534) acc 75.0000 (75.6250) gate/entropy 0.9963 (0.9956) gate/usage_max 0.5539 (0.5547) gate/usage_min 0.2157 (0.2161) gate/usage_std 0.1561 (0.1567) teacher/entropy 0.7335 (0.6936) teacher/usage_max 0.5150 (0.4960) teacher/usage_min 0.1685 (0.1464) teacher/usage_std 0.1420 (0.1470) nleep/row_max_mean 1203.0500 (1198.1698) nleep/row_max_std 16.9922 (14.8914) nleep/row_min_mean 1200.4191 (1195.3879) lr 1.7290e-03 eta 0:58:11
epoch [14/50] batch [120/244] time 0.087 (0.357) data 0.000 (0.002) loss 1.4084 (1.5074) teacher_loss 0.8915 (0.9372) loss_zs_kd 0.0263 (0.0330) loss_oracle 0.3308 (0.3877) kd_loss 0.3384 (0.3599) acc 81.2500 (75.8594) gate/entropy 0.9971 (0.9958) gate/usage_max 0.5529 (0.5545) gate/usage_min 0.2157 (0.2160) gate/usage_std 0.1554 (0.1565) teacher/entropy 0.8078 (0.6968) teacher/usage_max 0.4665 (0.4916) teacher/usage_min 0.1568 (0.1464) teacher/usage_std 0.1301 (0.1457) nleep/row_max_mean 1197.0007 (1198.0340) nleep/row_max_std 13.3783 (14.8444) nleep/row_min_mean 1194.5693 (1195.2652) lr 1.7290e-03 eta 0:52:58
epoch [14/50] batch [140/244] time 0.465 (0.370) data 0.000 (0.002) loss 1.9163 (1.5137) teacher_loss 1.2522 (0.9434) loss_zs_kd 0.0390 (0.0331) loss_oracle 0.3778 (0.3803) kd_loss 0.4557 (0.3636) acc 68.7500 (75.8482) gate/entropy 0.9977 (0.9960) gate/usage_max 0.5523 (0.5543) gate/usage_min 0.2156 (0.2160) gate/usage_std 0.1550 (0.1563) teacher/entropy 0.5966 (0.6944) teacher/usage_max 0.4805 (0.4909) teacher/usage_min 0.1301 (0.1445) teacher/usage_std 0.1484 (0.1464) nleep/row_max_mean 1198.0372 (1198.1874) nleep/row_max_std 15.7020 (14.8431) nleep/row_min_mean 1194.5398 (1195.3960) lr 1.7290e-03 eta 0:54:44
epoch [14/50] batch [160/244] time 0.449 (0.382) data 0.000 (0.002) loss 1.7956 (1.5212) teacher_loss 1.2531 (0.9509) loss_zs_kd 0.0420 (0.0341) loss_oracle 0.3518 (0.3753) kd_loss 0.3456 (0.3656) acc 71.8750 (75.6641) gate/entropy 0.9980 (0.9962) gate/usage_max 0.5520 (0.5540) gate/usage_min 0.2154 (0.2159) gate/usage_std 0.1548 (0.1561) teacher/entropy 0.6339 (0.6946) teacher/usage_max 0.5625 (0.4883) teacher/usage_min 0.1035 (0.1447) teacher/usage_std 0.1874 (0.1454) nleep/row_max_mean 1201.6152 (1198.2047) nleep/row_max_std 18.7543 (14.8153) nleep/row_min_mean 1198.3481 (1195.4066) lr 1.7290e-03 eta 0:56:25
epoch [14/50] batch [180/244] time 0.461 (0.388) data 0.000 (0.002) loss 1.7925 (1.5142) teacher_loss 1.2065 (0.9437) loss_zs_kd 0.0192 (0.0340) loss_oracle 0.3345 (0.3728) kd_loss 0.4092 (0.3670) acc 68.7500 (75.8160) gate/entropy 0.9982 (0.9964) gate/usage_max 0.5517 (0.5538) gate/usage_min 0.2151 (0.2158) gate/usage_std 0.1546 (0.1560) teacher/entropy 0.6678 (0.6943) teacher/usage_max 0.4538 (0.4873) teacher/usage_min 0.1599 (0.1435) teacher/usage_std 0.1257 (0.1457) nleep/row_max_mean 1198.7914 (1198.3178) nleep/row_max_std 12.9635 (14.8854) nleep/row_min_mean 1196.1169 (1195.5122) lr 1.7290e-03 eta 0:57:17
epoch [14/50] batch [200/244] time 0.450 (0.396) data 0.000 (0.001) loss 1.5575 (1.5185) teacher_loss 0.8440 (0.9479) loss_zs_kd 0.0336 (0.0338) loss_oracle 0.3710 (0.3700) kd_loss 0.5112 (0.3687) acc 71.8750 (75.5781) gate/entropy 0.9987 (0.9966) gate/usage_max 0.5510 (0.5535) gate/usage_min 0.2151 (0.2157) gate/usage_std 0.1541 (0.1558) teacher/entropy 0.6975 (0.6939) teacher/usage_max 0.4851 (0.4857) teacher/usage_min 0.2103 (0.1432) teacher/usage_std 0.1140 (0.1454) nleep/row_max_mean 1196.9165 (1198.2709) nleep/row_max_std 11.3760 (14.8445) nleep/row_min_mean 1194.2122 (1195.4618) lr 1.7290e-03 eta 0:58:14
epoch [14/50] batch [220/244] time 0.404 (0.384) data 0.000 (0.001) loss 1.2013 (1.5138) teacher_loss 0.5640 (0.9413) loss_zs_kd 0.0341 (0.0340) loss_oracle 0.3878 (0.3686) kd_loss 0.4263 (0.3712) acc 87.5000 (75.7386) gate/entropy 0.9992 (0.9968) gate/usage_max 0.5504 (0.5533) gate/usage_min 0.2148 (0.2157) gate/usage_std 0.1537 (0.1557) teacher/entropy 0.7057 (0.6930) teacher/usage_max 0.4480 (0.4855) teacher/usage_min 0.1637 (0.1422) teacher/usage_std 0.1224 (0.1458) nleep/row_max_mean 1197.9214 (1198.2206) nleep/row_max_std 14.9863 (14.7889) nleep/row_min_mean 1195.0758 (1195.4030) lr 1.7290e-03 eta 0:56:18
epoch [14/50] batch [240/244] time 0.081 (0.369) data 0.000 (0.001) loss 1.6003 (1.5285) teacher_loss 1.0653 (0.9544) loss_zs_kd 0.0311 (0.0340) loss_oracle 0.3449 (0.3676) kd_loss 0.3470 (0.3733) acc 71.8750 (75.5599) gate/entropy 0.9994 (0.9970) gate/usage_max 0.5502 (0.5530) gate/usage_min 0.2143 (0.2156) gate/usage_std 0.1536 (0.1555) teacher/entropy 0.7297 (0.6927) teacher/usage_max 0.4507 (0.4844) teacher/usage_min 0.1433 (0.1416) teacher/usage_std 0.1356 (0.1458) nleep/row_max_mean 1197.0940 (1198.1439) nleep/row_max_std 15.0318 (14.7033) nleep/row_min_mean 1194.6539 (1195.3224) lr 1.7290e-03 eta 0:54:04
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,824
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,017
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.9%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [15/50] batch [20/244] time 0.481 (0.501) data 0.000 (0.014) loss 1.2382 (1.5945) teacher_loss 0.7183 (0.9892) loss_zs_kd 0.0147 (0.0310) loss_oracle 0.3558 (0.4107) kd_loss 0.3347 (0.3845) acc 84.3750 (75.1562) gate/entropy 1.0006 (1.0002) gate/usage_max 0.5487 (0.5492) gate/usage_min 0.2142 (0.2143) gate/usage_std 0.1526 (0.1529) teacher/entropy 0.7574 (0.6986) teacher/usage_max 0.4316 (0.4708) teacher/usage_min 0.1541 (0.1416) teacher/usage_std 0.1269 (0.1415) nleep/row_max_mean 1196.9907 (1199.1418) nleep/row_max_std 17.3454 (14.7689) nleep/row_min_mean 1194.5897 (1196.2866) lr 1.6845e-03 eta 1:13:11
epoch [15/50] batch [40/244] time 0.501 (0.487) data 0.000 (0.007) loss 1.4161 (1.6187) teacher_loss 0.6576 (0.9989) loss_zs_kd 0.0310 (0.0345) loss_oracle 0.4409 (0.3921) kd_loss 0.5225 (0.4065) acc 84.3750 (75.1562) gate/entropy 1.0015 (1.0007) gate/usage_max 0.5477 (0.5487) gate/usage_min 0.2139 (0.2142) gate/usage_std 0.1519 (0.1525) teacher/entropy 0.6161 (0.6923) teacher/usage_max 0.4927 (0.4638) teacher/usage_min 0.1356 (0.1476) teacher/usage_std 0.1483 (0.1374) nleep/row_max_mean 1203.1599 (1198.5778) nleep/row_max_std 17.2474 (14.8473) nleep/row_min_mean 1199.8888 (1195.6944) lr 1.6845e-03 eta 1:10:54
epoch [15/50] batch [60/244] time 0.335 (0.481) data 0.001 (0.005) loss 1.0427 (1.6073) teacher_loss 0.5554 (0.9828) loss_zs_kd 0.0200 (0.0351) loss_oracle 0.3008 (0.3822) kd_loss 0.3270 (0.4158) acc 81.2500 (75.2604) gate/entropy 1.0020 (1.0011) gate/usage_max 0.5469 (0.5482) gate/usage_min 0.2135 (0.2140) gate/usage_std 0.1514 (0.1522) teacher/entropy 0.6973 (0.6858) teacher/usage_max 0.5057 (0.4660) teacher/usage_min 0.1149 (0.1470) teacher/usage_std 0.1628 (0.1378) nleep/row_max_mean 1200.7271 (1198.7074) nleep/row_max_std 14.4200 (15.1300) nleep/row_min_mean 1197.9220 (1195.8060) lr 1.6845e-03 eta 1:09:53
epoch [15/50] batch [80/244] time 0.496 (0.431) data 0.000 (0.004) loss 1.8929 (1.6106) teacher_loss 1.2888 (0.9768) loss_zs_kd 0.0366 (0.0345) loss_oracle 0.3414 (0.3804) kd_loss 0.4151 (0.4263) acc 75.0000 (75.0781) gate/entropy 1.0031 (1.0015) gate/usage_max 0.5456 (0.5476) gate/usage_min 0.2133 (0.2139) gate/usage_std 0.1505 (0.1519) teacher/entropy 0.6975 (0.6847) teacher/usage_max 0.4868 (0.4669) teacher/usage_min 0.1173 (0.1507) teacher/usage_std 0.1572 (0.1360) nleep/row_max_mean 1197.6160 (1198.6461) nleep/row_max_std 17.4110 (15.2842) nleep/row_min_mean 1194.7305 (1195.7552) lr 1.6845e-03 eta 1:02:33
epoch [15/50] batch [100/244] time 0.102 (0.392) data 0.000 (0.003) loss 1.7802 (1.6026) teacher_loss 1.1555 (0.9666) loss_zs_kd 0.0530 (0.0347) loss_oracle 0.4180 (0.3849) kd_loss 0.3893 (0.4262) acc 65.6250 (75.3125) gate/entropy 1.0038 (1.0019) gate/usage_max 0.5446 (0.5471) gate/usage_min 0.2129 (0.2138) gate/usage_std 0.1499 (0.1515) teacher/entropy 0.6828 (0.6870) teacher/usage_max 0.4430 (0.4666) teacher/usage_min 0.1149 (0.1510) teacher/usage_std 0.1544 (0.1359) nleep/row_max_mean 1198.5873 (1198.5602) nleep/row_max_std 15.8083 (15.2998) nleep/row_min_mean 1195.5625 (1195.6722) lr 1.6845e-03 eta 0:56:42
epoch [15/50] batch [120/244] time 0.109 (0.358) data 0.000 (0.003) loss 1.4497 (1.5912) teacher_loss 0.8345 (0.9602) loss_zs_kd 0.0290 (0.0346) loss_oracle 0.3973 (0.3834) kd_loss 0.4020 (0.4221) acc 65.6250 (75.2604) gate/entropy 1.0049 (1.0023) gate/usage_max 0.5433 (0.5466) gate/usage_min 0.2126 (0.2136) gate/usage_std 0.1490 (0.1512) teacher/entropy 0.6877 (0.6884) teacher/usage_max 0.4310 (0.4659) teacher/usage_min 0.1449 (0.1499) teacher/usage_std 0.1333 (0.1362) nleep/row_max_mean 1195.3530 (1198.3470) nleep/row_max_std 12.8425 (15.1419) nleep/row_min_mean 1192.3385 (1195.4647) lr 1.6845e-03 eta 0:51:37
epoch [15/50] batch [140/244] time 0.451 (0.373) data 0.000 (0.002) loss 1.3143 (1.5936) teacher_loss 0.6435 (0.9660) loss_zs_kd 0.0396 (0.0344) loss_oracle 0.4396 (0.3828) kd_loss 0.4312 (0.4191) acc 84.3750 (75.2679) gate/entropy 1.0058 (1.0028) gate/usage_max 0.5420 (0.5460) gate/usage_min 0.2122 (0.2134) gate/usage_std 0.1482 (0.1508) teacher/entropy 0.6677 (0.6894) teacher/usage_max 0.4164 (0.4649) teacher/usage_min 0.1747 (0.1496) teacher/usage_std 0.1122 (0.1360) nleep/row_max_mean 1197.5591 (1198.3752) nleep/row_max_std 15.0015 (15.0688) nleep/row_min_mean 1194.7014 (1195.5008) lr 1.6845e-03 eta 0:53:44
epoch [15/50] batch [160/244] time 0.420 (0.382) data 0.000 (0.002) loss 1.4841 (1.6012) teacher_loss 0.9171 (0.9706) loss_zs_kd 0.0246 (0.0347) loss_oracle 0.3344 (0.3843) kd_loss 0.3875 (0.4211) acc 81.2500 (75.3906) gate/entropy 1.0069 (1.0032) gate/usage_max 0.5406 (0.5454) gate/usage_min 0.2118 (0.2132) gate/usage_std 0.1473 (0.1504) teacher/entropy 0.7703 (0.6873) teacher/usage_max 0.4992 (0.4663) teacher/usage_min 0.1641 (0.1485) teacher/usage_std 0.1368 (0.1369) nleep/row_max_mean 1196.9517 (1198.4600) nleep/row_max_std 13.8472 (15.0523) nleep/row_min_mean 1194.6460 (1195.5875) lr 1.6845e-03 eta 0:54:57
epoch [15/50] batch [180/244] time 0.431 (0.390) data 0.000 (0.002) loss 1.2201 (1.5945) teacher_loss 0.6602 (0.9634) loss_zs_kd 0.0379 (0.0346) loss_oracle 0.3749 (0.3843) kd_loss 0.3535 (0.4217) acc 84.3750 (75.5729) gate/entropy 1.0078 (1.0036) gate/usage_max 0.5393 (0.5448) gate/usage_min 0.2114 (0.2130) gate/usage_std 0.1464 (0.1500) teacher/entropy 0.7448 (0.6869) teacher/usage_max 0.4350 (0.4656) teacher/usage_min 0.1557 (0.1508) teacher/usage_std 0.1261 (0.1356) nleep/row_max_mean 1199.2888 (1198.4115) nleep/row_max_std 13.7190 (14.9282) nleep/row_min_mean 1196.7664 (1195.5390) lr 1.6845e-03 eta 0:55:58
epoch [15/50] batch [200/244] time 0.079 (0.396) data 0.000 (0.002) loss 1.2849 (1.5896) teacher_loss 0.6332 (0.9590) loss_zs_kd 0.0231 (0.0350) loss_oracle 0.4034 (0.3832) kd_loss 0.4385 (0.4215) acc 81.2500 (75.7656) gate/entropy 1.0082 (1.0041) gate/usage_max 0.5386 (0.5443) gate/usage_min 0.2108 (0.2128) gate/usage_std 0.1461 (0.1497) teacher/entropy 0.6877 (0.6870) teacher/usage_max 0.4908 (0.4651) teacher/usage_min 0.1414 (0.1516) teacher/usage_std 0.1447 (0.1350) nleep/row_max_mean 1200.9697 (1198.3131) nleep/row_max_std 16.2681 (14.8936) nleep/row_min_mean 1198.1190 (1195.4464) lr 1.6845e-03 eta 0:56:42
epoch [15/50] batch [220/244] time 0.427 (0.388) data 0.000 (0.001) loss 1.5356 (1.5993) teacher_loss 0.9120 (0.9663) loss_zs_kd 0.0319 (0.0353) loss_oracle 0.3875 (0.3831) kd_loss 0.4139 (0.4238) acc 84.3750 (75.6676) gate/entropy 1.0092 (1.0045) gate/usage_max 0.5372 (0.5437) gate/usage_min 0.2104 (0.2126) gate/usage_std 0.1452 (0.1493) teacher/entropy 0.7284 (0.6852) teacher/usage_max 0.5043 (0.4659) teacher/usage_min 0.1502 (0.1517) teacher/usage_std 0.1448 (0.1353) nleep/row_max_mean 1199.1913 (1198.2459) nleep/row_max_std 14.0858 (14.8761) nleep/row_min_mean 1196.3269 (1195.3696) lr 1.6845e-03 eta 0:55:27
epoch [15/50] batch [240/244] time 0.082 (0.370) data 0.000 (0.001) loss 1.5593 (1.6071) teacher_loss 0.9559 (0.9711) loss_zs_kd 0.0562 (0.0353) loss_oracle 0.3922 (0.3836) kd_loss 0.3791 (0.4266) acc 71.8750 (75.5078) gate/entropy 1.0105 (1.0050) gate/usage_max 0.5354 (0.5430) gate/usage_min 0.2100 (0.2124) gate/usage_std 0.1440 (0.1489) teacher/entropy 0.7013 (0.6837) teacher/usage_max 0.4263 (0.4664) teacher/usage_min 0.1566 (0.1530) teacher/usage_std 0.1250 (0.1348) nleep/row_max_mean 1199.0859 (1198.1571) nleep/row_max_std 19.2308 (14.8255) nleep/row_min_mean 1196.1318 (1195.2747) lr 1.6845e-03 eta 0:52:44
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,809
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,999
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 89.3%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [16/50] batch [20/244] time 0.426 (0.487) data 0.000 (0.012) loss 1.2918 (1.6383) teacher_loss 0.5011 (0.9785) loss_zs_kd 0.0307 (0.0356) loss_oracle 0.4352 (0.3906) kd_loss 0.5577 (0.4467) acc 84.3750 (74.5312) gate/entropy 1.0115 (1.0111) gate/usage_max 0.5339 (0.5345) gate/usage_min 0.2093 (0.2096) gate/usage_std 0.1432 (0.1435) teacher/entropy 0.6239 (0.6693) teacher/usage_max 0.5060 (0.4659) teacher/usage_min 0.1963 (0.1712) teacher/usage_std 0.1289 (0.1242) nleep/row_max_mean 1199.6135 (1198.2667) nleep/row_max_std 15.8547 (13.8433) nleep/row_min_mean 1196.2908 (1195.2878) lr 1.6374e-03 eta 1:09:09
epoch [16/50] batch [40/244] time 0.490 (0.476) data 0.000 (0.006) loss 1.1899 (1.6442) teacher_loss 0.5861 (0.9890) loss_zs_kd 0.0443 (0.0391) loss_oracle 0.3940 (0.3871) kd_loss 0.3847 (0.4421) acc 84.3750 (74.7656) gate/entropy 1.0126 (1.0116) gate/usage_max 0.5323 (0.5337) gate/usage_min 0.2089 (0.2094) gate/usage_std 0.1422 (0.1430) teacher/entropy 0.7063 (0.6717) teacher/usage_max 0.4173 (0.4656) teacher/usage_min 0.1711 (0.1673) teacher/usage_std 0.1147 (0.1267) nleep/row_max_mean 1199.3202 (1197.8303) nleep/row_max_std 13.3747 (13.9480) nleep/row_min_mean 1196.8062 (1194.8880) lr 1.6374e-03 eta 1:07:26
epoch [16/50] batch [60/244] time 0.459 (0.470) data 0.000 (0.004) loss 1.3314 (1.6485) teacher_loss 0.8110 (0.9866) loss_zs_kd 0.0309 (0.0392) loss_oracle 0.3556 (0.3876) kd_loss 0.3271 (0.4485) acc 75.0000 (74.3229) gate/entropy 1.0136 (1.0122) gate/usage_max 0.5306 (0.5329) gate/usage_min 0.2083 (0.2091) gate/usage_std 0.1412 (0.1425) teacher/entropy 0.6782 (0.6704) teacher/usage_max 0.5142 (0.4646) teacher/usage_min 0.1237 (0.1729) teacher/usage_std 0.1607 (0.1235) nleep/row_max_mean 1196.4758 (1197.2823) nleep/row_max_std 11.2078 (13.6657) nleep/row_min_mean 1193.6501 (1194.3495) lr 1.6374e-03 eta 1:06:21
epoch [16/50] batch [80/244] time 0.492 (0.424) data 0.000 (0.003) loss 1.7671 (1.6685) teacher_loss 0.9060 (1.0043) loss_zs_kd 0.0526 (0.0390) loss_oracle 0.5408 (0.3799) kd_loss 0.5643 (0.4547) acc 71.8750 (73.9844) gate/entropy 1.0150 (1.0127) gate/usage_max 0.5285 (0.5321) gate/usage_min 0.2077 (0.2088) gate/usage_std 0.1399 (0.1420) teacher/entropy 0.6135 (0.6672) teacher/usage_max 0.4616 (0.4705) teacher/usage_min 0.2356 (0.1707) teacher/usage_std 0.0948 (0.1265) nleep/row_max_mean 1196.0117 (1197.2398) nleep/row_max_std 13.2480 (13.5689) nleep/row_min_mean 1192.4919 (1194.2736) lr 1.6374e-03 eta 0:59:44
epoch [16/50] batch [100/244] time 0.090 (0.394) data 0.000 (0.002) loss 1.5527 (1.6651) teacher_loss 0.8516 (1.0092) loss_zs_kd 0.0375 (0.0384) loss_oracle 0.3805 (0.3770) kd_loss 0.4921 (0.4483) acc 75.0000 (73.8125) gate/entropy 1.0160 (1.0133) gate/usage_max 0.5269 (0.5312) gate/usage_min 0.2072 (0.2086) gate/usage_std 0.1390 (0.1415) teacher/entropy 0.5940 (0.6680) teacher/usage_max 0.4890 (0.4667) teacher/usage_min 0.1198 (0.1703) teacher/usage_std 0.1562 (0.1257) nleep/row_max_mean 1196.1250 (1197.2177) nleep/row_max_std 8.9982 (13.4299) nleep/row_min_mean 1193.0280 (1194.2581) lr 1.6374e-03 eta 0:55:24
epoch [16/50] batch [120/244] time 0.085 (0.360) data 0.000 (0.002) loss 1.8493 (1.6589) teacher_loss 1.3764 (1.0059) loss_zs_kd 0.0246 (0.0380) loss_oracle 0.3147 (0.3781) kd_loss 0.3033 (0.4450) acc 59.3750 (73.9323) gate/entropy 1.0165 (1.0138) gate/usage_max 0.5258 (0.5304) gate/usage_min 0.2064 (0.2083) gate/usage_std 0.1384 (0.1410) teacher/entropy 0.7706 (0.6684) teacher/usage_max 0.4384 (0.4675) teacher/usage_min 0.2022 (0.1696) teacher/usage_std 0.0982 (0.1262) nleep/row_max_mean 1196.6482 (1197.2674) nleep/row_max_std 11.8409 (13.2732) nleep/row_min_mean 1194.2419 (1194.3136) lr 1.6374e-03 eta 0:50:27
epoch [16/50] batch [140/244] time 0.464 (0.375) data 0.000 (0.002) loss 1.2743 (1.6448) teacher_loss 0.6636 (0.9905) loss_zs_kd 0.0296 (0.0378) loss_oracle 0.3456 (0.3806) kd_loss 0.4231 (0.4451) acc 84.3750 (74.2188) gate/entropy 1.0180 (1.0143) gate/usage_max 0.5235 (0.5296) gate/usage_min 0.2063 (0.2080) gate/usage_std 0.1370 (0.1406) teacher/entropy 0.7298 (0.6708) teacher/usage_max 0.5119 (0.4669) teacher/usage_min 0.1798 (0.1736) teacher/usage_std 0.1367 (0.1244) nleep/row_max_mean 1198.5059 (1197.2031) nleep/row_max_std 13.0292 (13.2965) nleep/row_min_mean 1195.6660 (1194.2564) lr 1.6374e-03 eta 0:52:30
epoch [16/50] batch [160/244] time 0.464 (0.383) data 0.000 (0.002) loss 1.1672 (1.6313) teacher_loss 0.6348 (0.9812) loss_zs_kd 0.0152 (0.0371) loss_oracle 0.2447 (0.3783) kd_loss 0.4025 (0.4425) acc 81.2500 (74.3164) gate/entropy 1.0188 (1.0148) gate/usage_max 0.5219 (0.5287) gate/usage_min 0.2055 (0.2077) gate/usage_std 0.1361 (0.1401) teacher/entropy 0.7289 (0.6725) teacher/usage_max 0.5045 (0.4670) teacher/usage_min 0.1650 (0.1754) teacher/usage_std 0.1386 (0.1235) nleep/row_max_mean 1199.9116 (1197.2280) nleep/row_max_std 12.4762 (13.3188) nleep/row_min_mean 1197.3906 (1194.2932) lr 1.6374e-03 eta 0:53:33
epoch [16/50] batch [180/244] time 0.475 (0.393) data 0.000 (0.001) loss 1.2657 (1.6261) teacher_loss 0.8160 (0.9819) loss_zs_kd 0.0449 (0.0370) loss_oracle 0.2929 (0.3764) kd_loss 0.2807 (0.4375) acc 81.2500 (74.2882) gate/entropy 1.0195 (1.0153) gate/usage_max 0.5207 (0.5279) gate/usage_min 0.2049 (0.2074) gate/usage_std 0.1355 (0.1396) teacher/entropy 0.7934 (0.6772) teacher/usage_max 0.4386 (0.4637) teacher/usage_min 0.2131 (0.1792) teacher/usage_std 0.0927 (0.1207) nleep/row_max_mean 1195.8395 (1197.2079) nleep/row_max_std 14.6437 (13.3159) nleep/row_min_mean 1193.5759 (1194.2890) lr 1.6374e-03 eta 0:54:42
epoch [16/50] batch [200/244] time 0.368 (0.399) data 0.000 (0.001) loss 1.7542 (1.6309) teacher_loss 1.0489 (0.9896) loss_zs_kd 0.0338 (0.0366) loss_oracle 0.4120 (0.3769) kd_loss 0.4824 (0.4345) acc 78.1250 (74.0938) gate/entropy 1.0203 (1.0157) gate/usage_max 0.5192 (0.5271) gate/usage_min 0.2044 (0.2072) gate/usage_std 0.1347 (0.1391) teacher/entropy 0.6576 (0.6803) teacher/usage_max 0.4908 (0.4596) teacher/usage_min 0.1884 (0.1829) teacher/usage_std 0.1237 (0.1175) nleep/row_max_mean 1202.4158 (1197.2094) nleep/row_max_std 13.3110 (13.3670) nleep/row_min_mean 1199.4141 (1194.3110) lr 1.6374e-03 eta 0:55:24
epoch [16/50] batch [220/244] time 0.446 (0.387) data 0.000 (0.001) loss 1.8933 (1.6252) teacher_loss 1.1979 (0.9824) loss_zs_kd 0.0787 (0.0368) loss_oracle 0.4619 (0.3796) kd_loss 0.4251 (0.4346) acc 62.5000 (74.2898) gate/entropy 1.0210 (1.0162) gate/usage_max 0.5177 (0.5263) gate/usage_min 0.2037 (0.2069) gate/usage_std 0.1339 (0.1387) teacher/entropy 0.5793 (0.6804) teacher/usage_max 0.5359 (0.4581) teacher/usage_min 0.1884 (0.1856) teacher/usage_std 0.1476 (0.1159) nleep/row_max_mean 1202.1140 (1197.2248) nleep/row_max_std 15.4562 (13.4561) nleep/row_min_mean 1198.9763 (1194.3263) lr 1.6374e-03 eta 0:53:36
epoch [16/50] batch [240/244] time 0.086 (0.372) data 0.000 (0.001) loss 1.3924 (1.6283) teacher_loss 0.6967 (0.9837) loss_zs_kd 0.0145 (0.0369) loss_oracle 0.4972 (0.3811) kd_loss 0.4398 (0.4356) acc 81.2500 (74.2969) gate/entropy 1.0222 (1.0167) gate/usage_max 0.5155 (0.5255) gate/usage_min 0.2034 (0.2066) gate/usage_std 0.1327 (0.1382) teacher/entropy 0.6831 (0.6806) teacher/usage_max 0.3752 (0.4577) teacher/usage_min 0.2510 (0.1877) teacher/usage_std 0.0582 (0.1149) nleep/row_max_mean 1194.2185 (1197.1626) nleep/row_max_std 12.7700 (13.4991) nleep/row_min_mean 1191.3459 (1194.2628) lr 1.6374e-03 eta 0:51:26
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,809
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,013
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.6%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [17/50] batch [20/244] time 0.437 (0.498) data 0.000 (0.015) loss 1.6530 (1.6891) teacher_loss 1.0585 (1.0149) loss_zs_kd 0.0332 (0.0392) loss_oracle 0.3939 (0.4206) kd_loss 0.3809 (0.4443) acc 71.8750 (73.2812) gate/entropy 1.0233 (1.0228) gate/usage_max 0.5132 (0.5143) gate/usage_min 0.2025 (0.2028) gate/usage_std 0.1315 (0.1320) teacher/entropy 0.7416 (0.6936) teacher/usage_max 0.4187 (0.4403) teacher/usage_min 0.2239 (0.2228) teacher/usage_std 0.0813 (0.0928) nleep/row_max_mean 1197.5287 (1197.1836) nleep/row_max_std 11.7526 (15.3857) nleep/row_min_mean 1195.1294 (1194.3475) lr 1.5878e-03 eta 1:08:37
epoch [17/50] batch [40/244] time 0.483 (0.476) data 0.000 (0.008) loss 1.8402 (1.6990) teacher_loss 0.9231 (1.0215) loss_zs_kd 0.0247 (0.0383) loss_oracle 0.5045 (0.4136) kd_loss 0.6525 (0.4515) acc 75.0000 (72.7344) gate/entropy 1.0244 (1.0233) gate/usage_max 0.5110 (0.5132) gate/usage_min 0.2019 (0.2025) gate/usage_std 0.1303 (0.1315) teacher/entropy 0.5868 (0.6882) teacher/usage_max 0.5521 (0.4438) teacher/usage_min 0.1790 (0.2233) teacher/usage_std 0.1590 (0.0937) nleep/row_max_mean 1195.8630 (1197.3257) nleep/row_max_std 15.4410 (15.1162) nleep/row_min_mean 1192.3369 (1194.4248) lr 1.5878e-03 eta 1:05:29
epoch [17/50] batch [60/244] time 0.468 (0.474) data 0.001 (0.005) loss 1.7899 (1.6575) teacher_loss 1.1343 (0.9867) loss_zs_kd 0.0466 (0.0390) loss_oracle 0.4002 (0.4034) kd_loss 0.4322 (0.4496) acc 62.5000 (73.2812) gate/entropy 1.0251 (1.0238) gate/usage_max 0.5091 (0.5122) gate/usage_min 0.2009 (0.2021) gate/usage_std 0.1295 (0.1310) teacher/entropy 0.6900 (0.6942) teacher/usage_max 0.4414 (0.4474) teacher/usage_min 0.2142 (0.2265) teacher/usage_std 0.0931 (0.0941) nleep/row_max_mean 1198.9397 (1197.5420) nleep/row_max_std 12.2805 (14.6101) nleep/row_min_mean 1196.0646 (1194.6675) lr 1.5878e-03 eta 1:05:03
epoch [17/50] batch [80/244] time 0.404 (0.417) data 0.000 (0.004) loss 1.4233 (1.6805) teacher_loss 0.5897 (1.0007) loss_zs_kd 0.0358 (0.0393) loss_oracle 0.5064 (0.4058) kd_loss 0.5625 (0.4573) acc 84.3750 (73.3594) gate/entropy 1.0260 (1.0242) gate/usage_max 0.5071 (0.5111) gate/usage_min 0.2004 (0.2017) gate/usage_std 0.1285 (0.1305) teacher/entropy 0.6023 (0.6886) teacher/usage_max 0.4237 (0.4487) teacher/usage_min 0.2729 (0.2287) teacher/usage_std 0.0651 (0.0942) nleep/row_max_mean 1201.9591 (1197.6349) nleep/row_max_std 16.1442 (14.7492) nleep/row_min_mean 1198.4615 (1194.7291) lr 1.5878e-03 eta 0:57:05
epoch [17/50] batch [100/244] time 0.104 (0.391) data 0.000 (0.003) loss 1.4381 (1.6756) teacher_loss 0.7016 (0.9891) loss_zs_kd 0.0219 (0.0389) loss_oracle 0.4752 (0.4118) kd_loss 0.4880 (0.4611) acc 84.3750 (73.6875) gate/entropy 1.0272 (1.0247) gate/usage_max 0.5046 (0.5101) gate/usage_min 0.2000 (0.2014) gate/usage_std 0.1272 (0.1300) teacher/entropy 0.6657 (0.6880) teacher/usage_max 0.5252 (0.4514) teacher/usage_min 0.2041 (0.2286) teacher/usage_std 0.1384 (0.0953) nleep/row_max_mean 1196.2100 (1197.6860) nleep/row_max_std 17.4131 (14.9720) nleep/row_min_mean 1193.1283 (1194.7656) lr 1.5878e-03 eta 0:53:20
epoch [17/50] batch [120/244] time 0.111 (0.358) data 0.000 (0.003) loss 1.5323 (1.6669) teacher_loss 0.8441 (0.9812) loss_zs_kd 0.0447 (0.0389) loss_oracle 0.4035 (0.4109) kd_loss 0.4641 (0.4608) acc 84.3750 (74.2708) gate/entropy 1.0278 (1.0252) gate/usage_max 0.5029 (0.5090) gate/usage_min 0.1991 (0.2010) gate/usage_std 0.1265 (0.1294) teacher/entropy 0.7508 (0.6914) teacher/usage_max 0.5385 (0.4497) teacher/usage_min 0.1961 (0.2311) teacher/usage_std 0.1478 (0.0936) nleep/row_max_mean 1196.5803 (1197.7740) nleep/row_max_std 13.7482 (14.9853) nleep/row_min_mean 1194.0468 (1194.8600) lr 1.5878e-03 eta 0:48:44
epoch [17/50] batch [140/244] time 0.460 (0.372) data 0.000 (0.002) loss 1.6011 (1.6743) teacher_loss 0.7906 (0.9793) loss_zs_kd 0.0402 (0.0389) loss_oracle 0.4401 (0.4180) kd_loss 0.5704 (0.4665) acc 78.1250 (74.3527) gate/entropy 1.0285 (1.0256) gate/usage_max 0.5015 (0.5080) gate/usage_min 0.1990 (0.2008) gate/usage_std 0.1258 (0.1290) teacher/entropy 0.6737 (0.6911) teacher/usage_max 0.3964 (0.4460) teacher/usage_min 0.2241 (0.2346) teacher/usage_std 0.0776 (0.0905) nleep/row_max_mean 1200.4165 (1197.6885) nleep/row_max_std 13.4674 (14.9633) nleep/row_min_mean 1197.1556 (1194.7676) lr 1.5878e-03 eta 0:50:33
epoch [17/50] batch [160/244] time 0.490 (0.384) data 0.000 (0.002) loss 1.4676 (1.6760) teacher_loss 0.7495 (0.9807) loss_zs_kd 0.0485 (0.0382) loss_oracle 0.4175 (0.4183) kd_loss 0.4851 (0.4670) acc 81.2500 (74.5312) gate/entropy 1.0290 (1.0260) gate/usage_max 0.4999 (0.5071) gate/usage_min 0.1983 (0.2005) gate/usage_std 0.1251 (0.1285) teacher/entropy 0.7064 (0.6902) teacher/usage_max 0.4357 (0.4448) teacher/usage_min 0.2626 (0.2360) teacher/usage_std 0.0741 (0.0894) nleep/row_max_mean 1198.8013 (1197.8086) nleep/row_max_std 17.4695 (15.0087) nleep/row_min_mean 1196.0310 (1194.8883) lr 1.5878e-03 eta 0:52:04
epoch [17/50] batch [180/244] time 0.495 (0.394) data 0.000 (0.002) loss 1.2413 (1.6719) teacher_loss 0.5821 (0.9746) loss_zs_kd 0.0374 (0.0390) loss_oracle 0.4065 (0.4192) kd_loss 0.4373 (0.4682) acc 78.1250 (74.7917) gate/entropy 1.0296 (1.0263) gate/usage_max 0.4984 (0.5062) gate/usage_min 0.1979 (0.2002) gate/usage_std 0.1245 (0.1281) teacher/entropy 0.7047 (0.6903) teacher/usage_max 0.5074 (0.4434) teacher/usage_min 0.2110 (0.2379) teacher/usage_std 0.1264 (0.0879) nleep/row_max_mean 1202.9624 (1197.8932) nleep/row_max_std 14.8218 (15.0059) nleep/row_min_mean 1199.9567 (1194.9700) lr 1.5878e-03 eta 0:53:20
epoch [17/50] batch [200/244] time 0.080 (0.396) data 0.000 (0.002) loss 1.4175 (1.6837) teacher_loss 0.6988 (0.9849) loss_zs_kd 0.0407 (0.0390) loss_oracle 0.5113 (0.4209) kd_loss 0.4428 (0.4688) acc 81.2500 (74.5469) gate/entropy 1.0302 (1.0267) gate/usage_max 0.4967 (0.5053) gate/usage_min 0.1975 (0.1999) gate/usage_std 0.1237 (0.1277) teacher/entropy 0.7359 (0.6896) teacher/usage_max 0.3943 (0.4432) teacher/usage_min 0.2928 (0.2389) teacher/usage_std 0.0439 (0.0874) nleep/row_max_mean 1194.9727 (1197.9769) nleep/row_max_std 15.1633 (15.1015) nleep/row_min_mean 1192.0814 (1195.0501) lr 1.5878e-03 eta 0:53:25
epoch [17/50] batch [220/244] time 0.459 (0.387) data 0.000 (0.002) loss 1.5871 (1.6819) teacher_loss 0.8240 (0.9809) loss_zs_kd 0.0285 (0.0389) loss_oracle 0.4531 (0.4236) kd_loss 0.5222 (0.4697) acc 75.0000 (74.7869) gate/entropy 1.0309 (1.0270) gate/usage_max 0.4951 (0.5045) gate/usage_min 0.1973 (0.1997) gate/usage_std 0.1229 (0.1273) teacher/entropy 0.6448 (0.6884) teacher/usage_max 0.4861 (0.4434) teacher/usage_min 0.2538 (0.2401) teacher/usage_std 0.1081 (0.0872) nleep/row_max_mean 1206.4321 (1198.1572) nleep/row_max_std 16.7789 (15.1364) nleep/row_min_mean 1203.2756 (1195.2209) lr 1.5878e-03 eta 0:52:08
epoch [17/50] batch [240/244] time 0.087 (0.369) data 0.000 (0.001) loss 1.5443 (1.6819) teacher_loss 0.8710 (0.9816) loss_zs_kd 0.0280 (0.0388) loss_oracle 0.4337 (0.4237) kd_loss 0.4425 (0.4691) acc 78.1250 (74.8047) gate/entropy 1.0312 (1.0274) gate/usage_max 0.4933 (0.5036) gate/usage_min 0.1961 (0.1994) gate/usage_std 0.1224 (0.1269) teacher/entropy 0.7043 (0.6884) teacher/usage_max 0.4914 (0.4448) teacher/usage_min 0.2309 (0.2404) teacher/usage_std 0.1134 (0.0877) nleep/row_max_mean 1200.4922 (1198.2149) nleep/row_max_std 14.5039 (15.2295) nleep/row_min_mean 1197.6802 (1195.2785) lr 1.5878e-03 eta 0:49:35
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,795
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,000
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 89.4%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [18/50] batch [20/244] time 0.443 (0.490) data 0.000 (0.014) loss 1.8718 (1.6828) teacher_loss 0.9819 (0.9499) loss_zs_kd 0.0292 (0.0375) loss_oracle 0.5948 (0.4602) kd_loss 0.5779 (0.4840) acc 75.0000 (75.9375) gate/entropy 1.0320 (1.0317) gate/usage_max 0.4914 (0.4921) gate/usage_min 0.1958 (0.1960) gate/usage_std 0.1215 (0.1218) teacher/entropy 0.6261 (0.6800) teacher/usage_max 0.3732 (0.4364) teacher/usage_min 0.2926 (0.2564) teacher/usage_std 0.0329 (0.0781) nleep/row_max_mean 1199.4456 (1198.4354) nleep/row_max_std 14.3760 (15.7440) nleep/row_min_mean 1196.0900 (1195.3910) lr 1.5358e-03 eta 1:05:34
epoch [18/50] batch [40/244] time 0.445 (0.485) data 0.000 (0.007) loss 1.7175 (1.6839) teacher_loss 1.0025 (0.9730) loss_zs_kd 0.0545 (0.0379) loss_oracle 0.4105 (0.4419) kd_loss 0.4825 (0.4711) acc 71.8750 (75.3125) gate/entropy 1.0323 (1.0319) gate/usage_max 0.4902 (0.4915) gate/usage_min 0.1954 (0.1958) gate/usage_std 0.1211 (0.1216) teacher/entropy 0.6864 (0.6805) teacher/usage_max 0.5072 (0.4297) teacher/usage_min 0.2421 (0.2546) teacher/usage_std 0.1230 (0.0759) nleep/row_max_mean 1197.6321 (1198.4125) nleep/row_max_std 14.6463 (15.7833) nleep/row_min_mean 1194.9038 (1195.4402) lr 1.5358e-03 eta 1:04:44
epoch [18/50] batch [60/244] time 0.500 (0.473) data 0.000 (0.005) loss 1.6702 (1.6885) teacher_loss 0.8622 (0.9650) loss_zs_kd 0.0366 (0.0394) loss_oracle 0.5089 (0.4451) kd_loss 0.5353 (0.4814) acc 81.2500 (75.7292) gate/entropy 1.0328 (1.0321) gate/usage_max 0.4888 (0.4908) gate/usage_min 0.1952 (0.1956) gate/usage_std 0.1205 (0.1213) teacher/entropy 0.5896 (0.6686) teacher/usage_max 0.4372 (0.4350) teacher/usage_min 0.2385 (0.2509) teacher/usage_std 0.0813 (0.0792) nleep/row_max_mean 1201.1796 (1198.9000) nleep/row_max_std 15.1757 (15.8181) nleep/row_min_mean 1197.5814 (1195.8387) lr 1.5358e-03 eta 1:03:02
epoch [18/50] batch [80/244] time 0.558 (0.423) data 0.000 (0.004) loss 1.7470 (1.7154) teacher_loss 0.8696 (0.9902) loss_zs_kd 0.0407 (0.0407) loss_oracle 0.5853 (0.4482) kd_loss 0.5643 (0.4808) acc 84.3750 (75.0391) gate/entropy 1.0331 (1.0323) gate/usage_max 0.4870 (0.4901) gate/usage_min 0.1942 (0.1954) gate/usage_std 0.1200 (0.1210) teacher/entropy 0.5969 (0.6633) teacher/usage_max 0.4330 (0.4370) teacher/usage_min 0.2814 (0.2479) teacher/usage_std 0.0705 (0.0814) nleep/row_max_mean 1195.8049 (1199.0298) nleep/row_max_std 14.5116 (15.6778) nleep/row_min_mean 1192.3915 (1195.9583) lr 1.5358e-03 eta 0:56:14
epoch [18/50] batch [100/244] time 0.110 (0.390) data 0.000 (0.003) loss 2.1836 (1.7194) teacher_loss 1.3384 (0.9915) loss_zs_kd 0.0584 (0.0408) loss_oracle 0.5955 (0.4521) kd_loss 0.5182 (0.4815) acc 68.7500 (74.7812) gate/entropy 1.0337 (1.0326) gate/usage_max 0.4855 (0.4893) gate/usage_min 0.1941 (0.1952) gate/usage_std 0.1193 (0.1208) teacher/entropy 0.6572 (0.6598) teacher/usage_max 0.4812 (0.4386) teacher/usage_min 0.2422 (0.2459) teacher/usage_std 0.1055 (0.0828) nleep/row_max_mean 1196.3649 (1199.0078) nleep/row_max_std 13.4932 (15.7002) nleep/row_min_mean 1193.2080 (1195.9020) lr 1.5358e-03 eta 0:51:37
epoch [18/50] batch [120/244] time 0.256 (0.357) data 0.000 (0.003) loss 1.9574 (1.7211) teacher_loss 1.3650 (0.9959) loss_zs_kd 0.0414 (0.0417) loss_oracle 0.3599 (0.4517) kd_loss 0.3917 (0.4786) acc 53.1250 (74.3490) gate/entropy 1.0337 (1.0328) gate/usage_max 0.4845 (0.4886) gate/usage_min 0.1934 (0.1949) gate/usage_std 0.1191 (0.1205) teacher/entropy 0.6997 (0.6598) teacher/usage_max 0.4235 (0.4394) teacher/usage_min 0.2118 (0.2444) teacher/usage_std 0.0892 (0.0839) nleep/row_max_mean 1195.7190 (1198.8910) nleep/row_max_std 15.3265 (15.7930) nleep/row_min_mean 1192.9843 (1195.7915) lr 1.5358e-03 eta 0:47:10
epoch [18/50] batch [140/244] time 0.498 (0.364) data 0.000 (0.002) loss 1.3821 (1.7139) teacher_loss 0.6773 (0.9841) loss_zs_kd 0.0289 (0.0413) loss_oracle 0.4728 (0.4571) kd_loss 0.4540 (0.4806) acc 78.1250 (74.6429) gate/entropy 1.0342 (1.0330) gate/usage_max 0.4833 (0.4879) gate/usage_min 0.1934 (0.1947) gate/usage_std 0.1186 (0.1202) teacher/entropy 0.6817 (0.6577) teacher/usage_max 0.4526 (0.4421) teacher/usage_min 0.2481 (0.2428) teacher/usage_std 0.0869 (0.0856) nleep/row_max_mean 1197.1614 (1198.9990) nleep/row_max_std 12.9605 (15.6733) nleep/row_min_mean 1194.0220 (1195.8760) lr 1.5358e-03 eta 0:47:58
epoch [18/50] batch [160/244] time 0.497 (0.378) data 0.000 (0.002) loss 1.8597 (1.7200) teacher_loss 1.0218 (0.9819) loss_zs_kd 0.0821 (0.0414) loss_oracle 0.5054 (0.4610) kd_loss 0.5442 (0.4869) acc 71.8750 (74.6484) gate/entropy 1.0346 (1.0331) gate/usage_max 0.4818 (0.4872) gate/usage_min 0.1930 (0.1946) gate/usage_std 0.1180 (0.1200) teacher/entropy 0.6361 (0.6533) teacher/usage_max 0.4232 (0.4463) teacher/usage_min 0.2672 (0.2414) teacher/usage_std 0.0659 (0.0883) nleep/row_max_mean 1195.2358 (1198.7663) nleep/row_max_std 14.4469 (15.5976) nleep/row_min_mean 1191.7695 (1195.6127) lr 1.5358e-03 eta 0:49:42
epoch [18/50] batch [180/244] time 0.481 (0.387) data 0.000 (0.002) loss 1.1126 (1.7214) teacher_loss 0.3564 (0.9790) loss_zs_kd 0.0146 (0.0414) loss_oracle 0.4629 (0.4651) kd_loss 0.5175 (0.4892) acc 87.5000 (74.7049) gate/entropy 1.0351 (1.0333) gate/usage_max 0.4804 (0.4865) gate/usage_min 0.1929 (0.1944) gate/usage_std 0.1174 (0.1197) teacher/entropy 0.6226 (0.6520) teacher/usage_max 0.4820 (0.4484) teacher/usage_min 0.2426 (0.2415) teacher/usage_std 0.1060 (0.0892) nleep/row_max_mean 1198.1096 (1198.7168) nleep/row_max_std 16.6472 (15.6000) nleep/row_min_mean 1195.0199 (1195.5570) lr 1.5358e-03 eta 0:50:48
epoch [18/50] batch [200/244] time 0.428 (0.396) data 0.000 (0.002) loss 1.5047 (1.7122) teacher_loss 0.8239 (0.9688) loss_zs_kd 0.0448 (0.0412) loss_oracle 0.3544 (0.4620) kd_loss 0.4812 (0.4919) acc 87.5000 (75.0000) gate/entropy 1.0353 (1.0335) gate/usage_max 0.4792 (0.4859) gate/usage_min 0.1923 (0.1942) gate/usage_std 0.1171 (0.1195) teacher/entropy 0.6706 (0.6514) teacher/usage_max 0.5508 (0.4510) teacher/usage_min 0.2213 (0.2401) teacher/usage_std 0.1538 (0.0909) nleep/row_max_mean 1199.5691 (1198.6829) nleep/row_max_std 16.7957 (15.5990) nleep/row_min_mean 1196.6021 (1195.5187) lr 1.5358e-03 eta 0:51:50
epoch [18/50] batch [220/244] time 0.439 (0.389) data 0.000 (0.001) loss 1.5708 (1.7112) teacher_loss 0.7895 (0.9647) loss_zs_kd 0.0709 (0.0407) loss_oracle 0.4360 (0.4638) kd_loss 0.5279 (0.4943) acc 75.0000 (75.0142) gate/entropy 1.0355 (1.0337) gate/usage_max 0.4783 (0.4852) gate/usage_min 0.1922 (0.1941) gate/usage_std 0.1168 (0.1193) teacher/entropy 0.6520 (0.6516) teacher/usage_max 0.4722 (0.4513) teacher/usage_min 0.2346 (0.2406) teacher/usage_std 0.1011 (0.0909) nleep/row_max_mean 1201.6620 (1198.6443) nleep/row_max_std 17.0429 (15.6310) nleep/row_min_mean 1198.4163 (1195.4773) lr 1.5358e-03 eta 0:50:45
epoch [18/50] batch [240/244] time 0.084 (0.371) data 0.000 (0.001) loss 1.6786 (1.7154) teacher_loss 0.9946 (0.9697) loss_zs_kd 0.0529 (0.0407) loss_oracle 0.3604 (0.4605) kd_loss 0.4774 (0.4951) acc 68.7500 (74.9219) gate/entropy 1.0359 (1.0339) gate/usage_max 0.4777 (0.4846) gate/usage_min 0.1925 (0.1939) gate/usage_std 0.1164 (0.1190) teacher/entropy 0.6510 (0.6512) teacher/usage_max 0.5547 (0.4511) teacher/usage_min 0.2024 (0.2410) teacher/usage_std 0.1574 (0.0907) nleep/row_max_mean 1197.7971 (1198.5950) nleep/row_max_std 17.8058 (15.6218) nleep/row_min_mean 1194.5436 (1195.4275) lr 1.5358e-03 eta 0:48:14
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,794
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,008
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.3%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [19/50] batch [20/244] time 0.325 (0.483) data 0.000 (0.012) loss 1.6363 (1.7438) teacher_loss 0.7556 (1.0042) loss_zs_kd 0.0306 (0.0401) loss_oracle 0.5727 (0.4635) kd_loss 0.5790 (0.4878) acc 78.1250 (73.7500) gate/entropy 1.0361 (1.0360) gate/usage_max 0.4768 (0.4771) gate/usage_min 0.1922 (0.1922) gate/usage_std 0.1162 (0.1163) teacher/entropy 0.5917 (0.6624) teacher/usage_max 0.3416 (0.4225) teacher/usage_min 0.3274 (0.2682) teacher/usage_std 0.0060 (0.0662) nleep/row_max_mean 1198.0200 (1197.7733) nleep/row_max_std 13.9654 (15.2727) nleep/row_min_mean 1194.5437 (1194.6833) lr 1.4818e-03 eta 1:02:45
epoch [19/50] batch [40/244] time 0.468 (0.478) data 0.000 (0.006) loss 1.7999 (1.7494) teacher_loss 1.0545 (0.9864) loss_zs_kd 0.0406 (0.0413) loss_oracle 0.4748 (0.4824) kd_loss 0.4877 (0.5012) acc 78.1250 (74.0625) gate/entropy 1.0362 (1.0361) gate/usage_max 0.4767 (0.4769) gate/usage_min 0.1924 (0.1923) gate/usage_std 0.1161 (0.1162) teacher/entropy 0.6519 (0.6524) teacher/usage_max 0.3740 (0.4210) teacher/usage_min 0.2890 (0.2636) teacher/usage_std 0.0348 (0.0669) nleep/row_max_mean 1201.1711 (1197.8719) nleep/row_max_std 16.0336 (15.3064) nleep/row_min_mean 1197.6663 (1194.6800) lr 1.4818e-03 eta 1:01:52
epoch [19/50] batch [60/244] time 0.528 (0.472) data 0.000 (0.004) loss 1.2780 (1.7661) teacher_loss 0.5085 (1.0075) loss_zs_kd 0.0298 (0.0425) loss_oracle 0.5170 (0.4675) kd_loss 0.4961 (0.5036) acc 84.3750 (73.4375) gate/entropy 1.0367 (1.0362) gate/usage_max 0.4758 (0.4767) gate/usage_min 0.1926 (0.1923) gate/usage_std 0.1156 (0.1161) teacher/entropy 0.7129 (0.6439) teacher/usage_max 0.4032 (0.4374) teacher/usage_min 0.2425 (0.2490) teacher/usage_std 0.0673 (0.0800) nleep/row_max_mean 1199.1597 (1198.0460) nleep/row_max_std 14.1826 (15.6124) nleep/row_min_mean 1195.7966 (1194.7816) lr 1.4818e-03 eta 1:01:00
epoch [19/50] batch [80/244] time 0.450 (0.417) data 0.000 (0.003) loss 1.9178 (1.7515) teacher_loss 0.9792 (0.9819) loss_zs_kd 0.0444 (0.0423) loss_oracle 0.5573 (0.4762) kd_loss 0.6378 (0.5104) acc 59.3750 (74.2578) gate/entropy 1.0368 (1.0363) gate/usage_max 0.4746 (0.4763) gate/usage_min 0.1921 (0.1923) gate/usage_std 0.1153 (0.1160) teacher/entropy 0.5122 (0.6385) teacher/usage_max 0.5317 (0.4403) teacher/usage_min 0.2264 (0.2456) teacher/usage_std 0.1404 (0.0832) nleep/row_max_mean 1200.7661 (1198.1806) nleep/row_max_std 14.0068 (15.7827) nleep/row_min_mean 1196.8833 (1194.8814) lr 1.4818e-03 eta 0:53:44
epoch [19/50] batch [100/244] time 0.110 (0.381) data 0.000 (0.002) loss 2.1622 (1.7489) teacher_loss 1.4436 (0.9842) loss_zs_kd 0.0468 (0.0413) loss_oracle 0.4028 (0.4677) kd_loss 0.4938 (0.5102) acc 59.3750 (74.2188) gate/entropy 1.0369 (1.0364) gate/usage_max 0.4732 (0.4758) gate/usage_min 0.1914 (0.1922) gate/usage_std 0.1150 (0.1158) teacher/entropy 0.6192 (0.6364) teacher/usage_max 0.5365 (0.4489) teacher/usage_min 0.1987 (0.2385) teacher/usage_std 0.1462 (0.0897) nleep/row_max_mean 1199.3730 (1198.3157) nleep/row_max_std 18.3185 (15.8471) nleep/row_min_mean 1196.0005 (1195.0163) lr 1.4818e-03 eta 0:48:53
epoch [19/50] batch [120/244] time 0.250 (0.347) data 0.000 (0.002) loss 2.1426 (1.7537) teacher_loss 1.3185 (0.9905) loss_zs_kd 0.0442 (0.0417) loss_oracle 0.4465 (0.4645) kd_loss 0.5787 (0.5102) acc 68.7500 (74.1667) gate/entropy 1.0373 (1.0365) gate/usage_max 0.4718 (0.4753) gate/usage_min 0.1912 (0.1920) gate/usage_std 0.1146 (0.1156) teacher/entropy 0.5012 (0.6313) teacher/usage_max 0.5787 (0.4552) teacher/usage_min 0.1495 (0.2336) teacher/usage_std 0.1805 (0.0945) nleep/row_max_mean 1199.3644 (1198.4113) nleep/row_max_std 18.9644 (15.7648) nleep/row_min_mean 1195.0378 (1195.0840) lr 1.4818e-03 eta 0:44:30
epoch [19/50] batch [140/244] time 0.523 (0.352) data 0.000 (0.002) loss 1.6638 (1.7512) teacher_loss 0.9602 (0.9805) loss_zs_kd 0.0512 (0.0411) loss_oracle 0.3809 (0.4678) kd_loss 0.4875 (0.5163) acc 71.8750 (74.6205) gate/entropy 1.0374 (1.0367) gate/usage_max 0.4704 (0.4747) gate/usage_min 0.1906 (0.1919) gate/usage_std 0.1143 (0.1155) teacher/entropy 0.6245 (0.6258) teacher/usage_max 0.5146 (0.4581) teacher/usage_min 0.2100 (0.2336) teacher/usage_std 0.1309 (0.0962) nleep/row_max_mean 1194.8579 (1198.2476) nleep/row_max_std 15.0092 (15.7066) nleep/row_min_mean 1191.5349 (1194.8826) lr 1.4818e-03 eta 0:44:58
epoch [19/50] batch [160/244] time 0.451 (0.368) data 0.000 (0.002) loss 1.4835 (1.7501) teacher_loss 0.8770 (0.9755) loss_zs_kd 0.0549 (0.0416) loss_oracle 0.4216 (0.4687) kd_loss 0.3683 (0.5195) acc 78.1250 (74.9023) gate/entropy 1.0374 (1.0368) gate/usage_max 0.4689 (0.4740) gate/usage_min 0.1897 (0.1917) gate/usage_std 0.1141 (0.1153) teacher/entropy 0.6999 (0.6222) teacher/usage_max 0.4612 (0.4635) teacher/usage_min 0.1815 (0.2317) teacher/usage_std 0.1154 (0.0995) nleep/row_max_mean 1197.1392 (1198.1421) nleep/row_max_std 12.0017 (15.6024) nleep/row_min_mean 1194.1592 (1194.7500) lr 1.4818e-03 eta 0:46:53
epoch [19/50] batch [180/244] time 0.452 (0.378) data 0.000 (0.001) loss 1.2964 (1.7446) teacher_loss 0.5889 (0.9682) loss_zs_kd 0.0234 (0.0416) loss_oracle 0.3460 (0.4656) kd_loss 0.5228 (0.5228) acc 84.3750 (75.0521) gate/entropy 1.0378 (1.0369) gate/usage_max 0.4677 (0.4734) gate/usage_min 0.1898 (0.1915) gate/usage_std 0.1136 (0.1151) teacher/entropy 0.5879 (0.6181) teacher/usage_max 0.5792 (0.4686) teacher/usage_min 0.1892 (0.2312) teacher/usage_std 0.1747 (0.1025) nleep/row_max_mean 1199.7930 (1198.0289) nleep/row_max_std 16.8335 (15.5050) nleep/row_min_mean 1196.3389 (1194.6137) lr 1.4818e-03 eta 0:48:02
epoch [19/50] batch [200/244] time 0.494 (0.386) data 0.000 (0.001) loss 1.6385 (1.7333) teacher_loss 0.6974 (0.9533) loss_zs_kd 0.0452 (0.0417) loss_oracle 0.5905 (0.4659) kd_loss 0.6233 (0.5262) acc 75.0000 (75.5781) gate/entropy 1.0379 (1.0370) gate/usage_max 0.4662 (0.4727) gate/usage_min 0.1892 (0.1914) gate/usage_std 0.1133 (0.1149) teacher/entropy 0.5201 (0.6148) teacher/usage_max 0.4556 (0.4728) teacher/usage_min 0.2697 (0.2294) teacher/usage_std 0.0865 (0.1053) nleep/row_max_mean 1202.7158 (1198.0588) nleep/row_max_std 13.9353 (15.3765) nleep/row_min_mean 1198.1998 (1194.6150) lr 1.4818e-03 eta 0:48:55
epoch [19/50] batch [220/244] time 0.459 (0.374) data 0.000 (0.001) loss 1.9004 (1.7405) teacher_loss 0.9683 (0.9543) loss_zs_kd 0.0206 (0.0416) loss_oracle 0.6303 (0.4726) kd_loss 0.6066 (0.5291) acc 78.1250 (75.5966) gate/entropy 1.0383 (1.0371) gate/usage_max 0.4654 (0.4721) gate/usage_min 0.1894 (0.1912) gate/usage_std 0.1130 (0.1148) teacher/entropy 0.6026 (0.6136) teacher/usage_max 0.4811 (0.4740) teacher/usage_min 0.1838 (0.2287) teacher/usage_std 0.1214 (0.1062) nleep/row_max_mean 1199.7457 (1198.1334) nleep/row_max_std 14.8814 (15.3163) nleep/row_min_mean 1196.1218 (1194.6771) lr 1.4818e-03 eta 0:47:16
epoch [19/50] batch [240/244] time 0.083 (0.365) data 0.000 (0.001) loss 1.7608 (1.7346) teacher_loss 1.0249 (0.9433) loss_zs_kd 0.0545 (0.0417) loss_oracle 0.4632 (0.4790) kd_loss 0.4771 (0.5309) acc 75.0000 (75.7812) gate/entropy 1.0384 (1.0372) gate/usage_max 0.4647 (0.4715) gate/usage_min 0.1892 (0.1910) gate/usage_std 0.1128 (0.1146) teacher/entropy 0.6432 (0.6124) teacher/usage_max 0.4975 (0.4745) teacher/usage_min 0.2305 (0.2296) teacher/usage_std 0.1173 (0.1062) nleep/row_max_mean 1195.7991 (1198.2547) nleep/row_max_std 15.6053 (15.3083) nleep/row_min_mean 1192.3774 (1194.7826) lr 1.4818e-03 eta 0:45:59
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,801
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,993
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.1%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [20/50] batch [20/244] time 0.534 (0.519) data 0.001 (0.012) loss 1.7279 (1.7970) teacher_loss 0.9545 (0.9270) loss_zs_kd 0.0351 (0.0471) loss_oracle 0.5261 (0.5193) kd_loss 0.4928 (0.5869) acc 78.1250 (76.0938) gate/entropy 1.0387 (1.0387) gate/usage_max 0.4633 (0.4639) gate/usage_min 0.1890 (0.1895) gate/usage_std 0.1124 (0.1125) teacher/entropy 0.6520 (0.5932) teacher/usage_max 0.4197 (0.4821) teacher/usage_min 0.2860 (0.2097) teacher/usage_std 0.0611 (0.1152) nleep/row_max_mean 1198.0006 (1199.4210) nleep/row_max_std 12.0731 (14.9332) nleep/row_min_mean 1194.3000 (1195.5676) lr 1.4258e-03 eta 1:05:13
epoch [20/50] batch [40/244] time 0.476 (0.493) data 0.000 (0.006) loss 1.7441 (1.7696) teacher_loss 0.8445 (0.9288) loss_zs_kd 0.0290 (0.0461) loss_oracle 0.5353 (0.5065) kd_loss 0.6174 (0.5645) acc 84.3750 (76.7188) gate/entropy 1.0389 (1.0388) gate/usage_max 0.4625 (0.4635) gate/usage_min 0.1890 (0.1894) gate/usage_std 0.1121 (0.1123) teacher/entropy 0.4898 (0.6108) teacher/usage_max 0.4627 (0.4745) teacher/usage_min 0.2302 (0.2183) teacher/usage_std 0.0967 (0.1085) nleep/row_max_mean 1206.6975 (1199.5925) nleep/row_max_std 18.0687 (14.9938) nleep/row_min_mean 1202.3152 (1195.8952) lr 1.4258e-03 eta 1:01:53
epoch [20/50] batch [60/244] time 0.086 (0.495) data 0.000 (0.004) loss 1.9621 (1.7566) teacher_loss 0.9021 (0.9117) loss_zs_kd 0.0609 (0.0452) loss_oracle 0.6221 (0.5084) kd_loss 0.7185 (0.5681) acc 78.1250 (76.9271) gate/entropy 1.0392 (1.0389) gate/usage_max 0.4611 (0.4629) gate/usage_min 0.1889 (0.1893) gate/usage_std 0.1118 (0.1122) teacher/entropy 0.5229 (0.6026) teacher/usage_max 0.4348 (0.4735) teacher/usage_min 0.1747 (0.2222) teacher/usage_std 0.1136 (0.1073) nleep/row_max_mean 1198.4219 (1199.4337) nleep/row_max_std 16.4159 (14.9126) nleep/row_min_mean 1194.1299 (1195.7262) lr 1.4258e-03 eta 1:01:50
epoch [20/50] batch [80/244] time 0.464 (0.457) data 0.000 (0.003) loss 1.6052 (1.7597) teacher_loss 0.7671 (0.9049) loss_zs_kd 0.0670 (0.0446) loss_oracle 0.5012 (0.5163) kd_loss 0.5540 (0.5743) acc 78.1250 (77.3047) gate/entropy 1.0395 (1.0390) gate/usage_max 0.4605 (0.4623) gate/usage_min 0.1892 (0.1892) gate/usage_std 0.1114 (0.1120) teacher/entropy 0.6182 (0.6008) teacher/usage_max 0.5131 (0.4678) teacher/usage_min 0.1971 (0.2208) teacher/usage_std 0.1326 (0.1050) nleep/row_max_mean 1202.0508 (1199.1876) nleep/row_max_std 14.9780 (14.7216) nleep/row_min_mean 1198.5317 (1195.4717) lr 1.4258e-03 eta 0:56:56
epoch [20/50] batch [100/244] time 0.508 (0.414) data 0.000 (0.003) loss 1.9643 (1.7893) teacher_loss 1.0756 (0.9312) loss_zs_kd 0.0369 (0.0442) loss_oracle 0.5539 (0.5262) kd_loss 0.5933 (0.5729) acc 81.2500 (76.5625) gate/entropy 1.0398 (1.0391) gate/usage_max 0.4601 (0.4619) gate/usage_min 0.1894 (0.1892) gate/usage_std 0.1112 (0.1119) teacher/entropy 0.5850 (0.6019) teacher/usage_max 0.4198 (0.4633) teacher/usage_min 0.2573 (0.2221) teacher/usage_std 0.0668 (0.1025) nleep/row_max_mean 1197.1035 (1199.0072) nleep/row_max_std 13.4849 (14.7995) nleep/row_min_mean 1193.5120 (1195.3153) lr 1.4258e-03 eta 0:51:30
epoch [20/50] batch [120/244] time 0.495 (0.413) data 0.000 (0.002) loss 1.6181 (1.8008) teacher_loss 0.8529 (0.9372) loss_zs_kd 0.0462 (0.0451) loss_oracle 0.4877 (0.5331) kd_loss 0.4982 (0.5744) acc 75.0000 (76.3281) gate/entropy 1.0401 (1.0393) gate/usage_max 0.4597 (0.4616) gate/usage_min 0.1897 (0.1892) gate/usage_std 0.1109 (0.1118) teacher/entropy 0.6556 (0.6009) teacher/usage_max 0.3728 (0.4620) teacher/usage_min 0.3114 (0.2229) teacher/usage_std 0.0280 (0.1014) nleep/row_max_mean 1194.6172 (1198.9349) nleep/row_max_std 17.1974 (14.9199) nleep/row_min_mean 1191.4485 (1195.2220) lr 1.4258e-03 eta 0:51:17
epoch [20/50] batch [140/244] time 0.497 (0.426) data 0.000 (0.002) loss 2.2962 (1.8162) teacher_loss 1.2776 (0.9439) loss_zs_kd 0.0347 (0.0454) loss_oracle 0.6451 (0.5381) kd_loss 0.6787 (0.5805) acc 62.5000 (76.2723) gate/entropy 1.0404 (1.0394) gate/usage_max 0.4592 (0.4613) gate/usage_min 0.1901 (0.1893) gate/usage_std 0.1105 (0.1116) teacher/entropy 0.5330 (0.6004) teacher/usage_max 0.3918 (0.4582) teacher/usage_min 0.2355 (0.2213) teacher/usage_std 0.0696 (0.1006) nleep/row_max_mean 1198.0220 (1198.7998) nleep/row_max_std 14.5743 (14.9978) nleep/row_min_mean 1193.7671 (1195.0689) lr 1.4258e-03 eta 0:52:41
epoch [20/50] batch [160/244] time 0.512 (0.434) data 0.000 (0.002) loss 1.4229 (1.8191) teacher_loss 0.5628 (0.9402) loss_zs_kd 0.0220 (0.0454) loss_oracle 0.5882 (0.5461) kd_loss 0.5550 (0.5831) acc 87.5000 (76.4648) gate/entropy 1.0410 (1.0395) gate/usage_max 0.4595 (0.4610) gate/usage_min 0.1911 (0.1894) gate/usage_std 0.1101 (0.1115) teacher/entropy 0.6555 (0.6007) teacher/usage_max 0.4154 (0.4542) teacher/usage_min 0.2206 (0.2232) teacher/usage_std 0.0824 (0.0983) nleep/row_max_mean 1196.8186 (1198.7052) nleep/row_max_std 17.7016 (15.1110) nleep/row_min_mean 1193.2300 (1194.9681) lr 1.4258e-03 eta 0:53:35
epoch [20/50] batch [180/244] time 0.089 (0.434) data 0.000 (0.002) loss 1.9995 (1.8225) teacher_loss 1.1433 (0.9349) loss_zs_kd 0.0753 (0.0448) loss_oracle 0.4952 (0.5561) kd_loss 0.5710 (0.5871) acc 71.8750 (76.5278) gate/entropy 1.0412 (1.0397) gate/usage_max 0.4593 (0.4608) gate/usage_min 0.1913 (0.1896) gate/usage_std 0.1100 (0.1113) teacher/entropy 0.7038 (0.6035) teacher/usage_max 0.4484 (0.4529) teacher/usage_min 0.1665 (0.2209) teacher/usage_std 0.1208 (0.0987) nleep/row_max_mean 1194.4912 (1198.4132) nleep/row_max_std 13.0627 (14.9978) nleep/row_min_mean 1191.3870 (1194.6839) lr 1.4258e-03 eta 0:53:20
epoch [20/50] batch [200/244] time 0.485 (0.426) data 0.000 (0.001) loss 1.5902 (1.8325) teacher_loss 0.4405 (0.9360) loss_zs_kd 0.0550 (0.0453) loss_oracle 0.7514 (0.5638) kd_loss 0.7466 (0.5919) acc 84.3750 (76.2031) gate/entropy 1.0416 (1.0399) gate/usage_max 0.4590 (0.4607) gate/usage_min 0.1918 (0.1898) gate/usage_std 0.1096 (0.1112) teacher/entropy 0.5348 (0.6027) teacher/usage_max 0.4826 (0.4515) teacher/usage_min 0.2176 (0.2198) teacher/usage_std 0.1108 (0.0986) nleep/row_max_mean 1200.4049 (1198.2118) nleep/row_max_std 13.0565 (14.8276) nleep/row_min_mean 1195.3870 (1194.4664) lr 1.4258e-03 eta 0:52:20
epoch [20/50] batch [220/244] time 0.206 (0.400) data 0.000 (0.001) loss 1.9855 (1.8350) teacher_loss 0.9323 (0.9318) loss_zs_kd 0.0801 (0.0453) loss_oracle 0.6702 (0.5693) kd_loss 0.6780 (0.5959) acc 81.2500 (76.3068) gate/entropy 1.0422 (1.0401) gate/usage_max 0.4590 (0.4605) gate/usage_min 0.1928 (0.1901) gate/usage_std 0.1092 (0.1110) teacher/entropy 0.6167 (0.6039) teacher/usage_max 0.4906 (0.4512) teacher/usage_min 0.1759 (0.2187) teacher/usage_std 0.1285 (0.0989) nleep/row_max_mean 1195.9849 (1198.0859) nleep/row_max_std 14.8541 (14.8263) nleep/row_min_mean 1192.2401 (1194.3362) lr 1.4258e-03 eta 0:48:58
epoch [20/50] batch [240/244] time 0.448 (0.385) data 0.000 (0.001) loss 1.7104 (1.8384) teacher_loss 0.6489 (0.9310) loss_zs_kd 0.0453 (0.0450) loss_oracle 0.6511 (0.5704) kd_loss 0.7133 (0.5997) acc 81.2500 (76.2630) gate/entropy 1.0429 (1.0403) gate/usage_max 0.4585 (0.4604) gate/usage_min 0.1939 (0.1903) gate/usage_std 0.1085 (0.1108) teacher/entropy 0.5654 (0.6041) teacher/usage_max 0.4931 (0.4503) teacher/usage_min 0.2327 (0.2163) teacher/usage_std 0.1142 (0.0997) nleep/row_max_mean 1201.3228 (1198.1711) nleep/row_max_std 15.8678 (14.8982) nleep/row_min_mean 1197.4929 (1194.4084) lr 1.4258e-03 eta 0:47:01
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,791
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 82.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,003
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.4%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [21/50] batch [20/244] time 0.525 (0.517) data 0.000 (0.014) loss 1.7515 (1.9559) teacher_loss 0.6304 (0.8987) loss_zs_kd 0.0273 (0.0458) loss_oracle 0.7244 (0.6794) kd_loss 0.7453 (0.6946) acc 81.2500 (76.7188) gate/entropy 1.0436 (1.0432) gate/usage_max 0.4580 (0.4581) gate/usage_min 0.1948 (0.1942) gate/usage_std 0.1079 (0.1082) teacher/entropy 0.5415 (0.5775) teacher/usage_max 0.4590 (0.4652) teacher/usage_min 0.1257 (0.1714) teacher/usage_std 0.1479 (0.1250) nleep/row_max_mean 1197.9241 (1198.9622) nleep/row_max_std 12.1381 (14.8727) nleep/row_min_mean 1193.6560 (1194.7873) lr 1.3681e-03 eta 1:02:52
epoch [21/50] batch [40/244] time 0.497 (0.518) data 0.000 (0.007) loss 1.8091 (1.9493) teacher_loss 0.4576 (0.8944) loss_zs_kd 0.0669 (0.0501) loss_oracle 0.8986 (0.6813) kd_loss 0.8687 (0.6892) acc 87.5000 (77.5000) gate/entropy 1.0444 (1.0435) gate/usage_max 0.4577 (0.4580) gate/usage_min 0.1962 (0.1947) gate/usage_std 0.1072 (0.1079) teacher/entropy 0.4790 (0.5803) teacher/usage_max 0.5465 (0.4615) teacher/usage_min 0.0841 (0.1697) teacher/usage_std 0.1905 (0.1249) nleep/row_max_mean 1198.8884 (1198.5352) nleep/row_max_std 12.3099 (14.8039) nleep/row_min_mean 1193.9983 (1194.3796) lr 1.3681e-03 eta 1:02:47
epoch [21/50] batch [60/244] time 0.489 (0.433) data 0.001 (0.005) loss 1.8829 (1.9822) teacher_loss 0.8316 (0.9282) loss_zs_kd 0.0454 (0.0504) loss_oracle 0.6399 (0.6837) kd_loss 0.7087 (0.6869) acc 75.0000 (76.2500) gate/entropy 1.0448 (1.0439) gate/usage_max 0.4574 (0.4578) gate/usage_min 0.1967 (0.1952) gate/usage_std 0.1068 (0.1076) teacher/entropy 0.5901 (0.5833) teacher/usage_max 0.4915 (0.4637) teacher/usage_min 0.1372 (0.1705) teacher/usage_std 0.1471 (0.1253) nleep/row_max_mean 1197.8218 (1198.1215) nleep/row_max_std 12.5419 (14.5478) nleep/row_min_mean 1194.4270 (1194.0225) lr 1.3681e-03 eta 0:52:22
epoch [21/50] batch [80/244] time 0.097 (0.402) data 0.000 (0.004) loss 2.0868 (2.0096) teacher_loss 0.7591 (0.9405) loss_zs_kd 0.0398 (0.0511) loss_oracle 0.9026 (0.6950) kd_loss 0.8564 (0.6959) acc 84.3750 (76.1719) gate/entropy 1.0459 (1.0442) gate/usage_max 0.4570 (0.4576) gate/usage_min 0.1985 (0.1958) gate/usage_std 0.1059 (0.1073) teacher/entropy 0.5300 (0.5792) teacher/usage_max 0.6301 (0.4715) teacher/usage_min 0.0917 (0.1665) teacher/usage_std 0.2232 (0.1304) nleep/row_max_mean 1198.1530 (1198.0775) nleep/row_max_std 16.6878 (14.5330) nleep/row_min_mean 1192.8477 (1193.8967) lr 1.3681e-03 eta 0:48:29
epoch [21/50] batch [100/244] time 0.483 (0.365) data 0.000 (0.003) loss 1.7782 (2.0127) teacher_loss 0.7492 (0.9526) loss_zs_kd 0.0367 (0.0499) loss_oracle 0.6859 (0.6894) kd_loss 0.6677 (0.6904) acc 78.1250 (75.6875) gate/entropy 1.0463 (1.0446) gate/usage_max 0.4569 (0.4575) gate/usage_min 0.1991 (0.1964) gate/usage_std 0.1055 (0.1070) teacher/entropy 0.5991 (0.5833) teacher/usage_max 0.4505 (0.4698) teacher/usage_min 0.1647 (0.1676) teacher/usage_std 0.1222 (0.1292) nleep/row_max_mean 1196.9056 (1198.0980) nleep/row_max_std 13.9698 (14.4861) nleep/row_min_mean 1192.7391 (1193.9314) lr 1.3681e-03 eta 0:43:52
epoch [21/50] batch [120/244] time 0.472 (0.388) data 0.000 (0.002) loss 1.8320 (2.0270) teacher_loss 0.7390 (0.9614) loss_zs_kd 0.0596 (0.0502) loss_oracle 0.7707 (0.6958) kd_loss 0.6779 (0.6925) acc 81.2500 (75.4948) gate/entropy 1.0476 (1.0450) gate/usage_max 0.4565 (0.4574) gate/usage_min 0.2013 (0.1971) gate/usage_std 0.1044 (0.1066) teacher/entropy 0.5588 (0.5824) teacher/usage_max 0.4633 (0.4719) teacher/usage_min 0.1464 (0.1642) teacher/usage_std 0.1355 (0.1314) nleep/row_max_mean 1201.0730 (1198.3633) nleep/row_max_std 17.5449 (14.6695) nleep/row_min_mean 1196.2803 (1194.1587) lr 1.3681e-03 eta 0:46:30
epoch [21/50] batch [140/244] time 0.497 (0.402) data 0.000 (0.002) loss 2.2576 (2.0392) teacher_loss 1.1479 (0.9650) loss_zs_kd 0.0395 (0.0504) loss_oracle 0.6990 (0.7010) kd_loss 0.7405 (0.6985) acc 68.7500 (75.4464) gate/entropy 1.0485 (1.0455) gate/usage_max 0.4560 (0.4572) gate/usage_min 0.2027 (0.1978) gate/usage_std 0.1036 (0.1063) teacher/entropy 0.5604 (0.5782) teacher/usage_max 0.5247 (0.4739) teacher/usage_min 0.1580 (0.1605) teacher/usage_std 0.1501 (0.1337) nleep/row_max_mean 1195.2043 (1198.4623) nleep/row_max_std 13.0797 (14.7669) nleep/row_min_mean 1191.0824 (1194.2036) lr 1.3681e-03 eta 0:48:06
epoch [21/50] batch [160/244] time 0.496 (0.410) data 0.000 (0.002) loss 2.3425 (2.0447) teacher_loss 1.3195 (0.9612) loss_zs_kd 0.0354 (0.0499) loss_oracle 0.6810 (0.7077) kd_loss 0.6648 (0.7048) acc 68.7500 (75.6055) gate/entropy 1.0496 (1.0459) gate/usage_max 0.4554 (0.4570) gate/usage_min 0.2046 (0.1985) gate/usage_std 0.1025 (0.1059) teacher/entropy 0.6263 (0.5737) teacher/usage_max 0.4990 (0.4777) teacher/usage_min 0.1385 (0.1588) teacher/usage_std 0.1486 (0.1357) nleep/row_max_mean 1199.5933 (1198.4461) nleep/row_max_std 13.8499 (14.8184) nleep/row_min_mean 1194.7415 (1194.1256) lr 1.3681e-03 eta 0:48:57
epoch [21/50] batch [180/244] time 0.083 (0.403) data 0.000 (0.002) loss 1.4696 (2.0329) teacher_loss 0.5755 (0.9512) loss_zs_kd 0.0410 (0.0495) loss_oracle 0.6262 (0.7019) kd_loss 0.5605 (0.7060) acc 81.2500 (75.8160) gate/entropy 1.0506 (1.0463) gate/usage_max 0.4547 (0.4568) gate/usage_min 0.2061 (0.1992) gate/usage_std 0.1016 (0.1054) teacher/entropy 0.6465 (0.5713) teacher/usage_max 0.3891 (0.4771) teacher/usage_min 0.2292 (0.1574) teacher/usage_std 0.0737 (0.1364) nleep/row_max_mean 1202.5979 (1198.5755) nleep/row_max_std 17.4218 (14.8903) nleep/row_min_mean 1196.7676 (1194.2100) lr 1.3681e-03 eta 0:47:54
epoch [21/50] batch [200/244] time 0.080 (0.402) data 0.000 (0.002) loss 1.9977 (2.0351) teacher_loss 0.6880 (0.9469) loss_zs_kd 0.0576 (0.0493) loss_oracle 0.8094 (0.7006) kd_loss 0.8762 (0.7133) acc 84.3750 (75.8594) gate/entropy 1.0516 (1.0468) gate/usage_max 0.4539 (0.4566) gate/usage_min 0.2076 (0.2000) gate/usage_std 0.1006 (0.1050) teacher/entropy 0.4767 (0.5663) teacher/usage_max 0.5985 (0.4808) teacher/usage_min 0.0792 (0.1531) teacher/usage_std 0.2121 (0.1398) nleep/row_max_mean 1202.1946 (1198.6484) nleep/row_max_std 18.7131 (14.9788) nleep/row_min_mean 1197.1689 (1194.2311) lr 1.3681e-03 eta 0:47:39
epoch [21/50] batch [220/244] time 0.113 (0.377) data 0.000 (0.001) loss 2.1295 (2.0359) teacher_loss 0.9592 (0.9474) loss_zs_kd 0.0334 (0.0490) loss_oracle 0.7667 (0.6967) kd_loss 0.7703 (0.7156) acc 75.0000 (75.9375) gate/entropy 1.0529 (1.0473) gate/usage_max 0.4525 (0.4563) gate/usage_min 0.2095 (0.2007) gate/usage_std 0.0993 (0.1046) teacher/entropy 0.5351 (0.5637) teacher/usage_max 0.5318 (0.4816) teacher/usage_min 0.1112 (0.1500) teacher/usage_std 0.1725 (0.1416) nleep/row_max_mean 1198.1813 (1198.7083) nleep/row_max_std 15.0629 (15.0423) nleep/row_min_mean 1193.4193 (1194.2498) lr 1.3681e-03 eta 0:44:36
epoch [21/50] batch [240/244] time 0.498 (0.374) data 0.000 (0.001) loss 2.0492 (2.0510) teacher_loss 0.9703 (0.9575) loss_zs_kd 0.0512 (0.0490) loss_oracle 0.6407 (0.6999) kd_loss 0.7329 (0.7191) acc 75.0000 (75.7943) gate/entropy 1.0538 (1.0478) gate/usage_max 0.4511 (0.4559) gate/usage_min 0.2105 (0.2015) gate/usage_std 0.0983 (0.1041) teacher/entropy 0.5235 (0.5601) teacher/usage_max 0.4564 (0.4821) teacher/usage_min 0.1119 (0.1467) teacher/usage_std 0.1569 (0.1436) nleep/row_max_mean 1203.3480 (1198.8181) nleep/row_max_std 16.4182 (15.1772) nleep/row_min_mean 1198.4590 (1194.3094) lr 1.3681e-03 eta 0:44:08
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,802
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 82.9%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,988
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 88.9%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [22/50] batch [20/244] time 0.496 (0.512) data 0.000 (0.016) loss 1.9163 (2.0824) teacher_loss 0.9364 (0.9471) loss_zs_kd 0.0567 (0.0506) loss_oracle 0.5700 (0.7042) kd_loss 0.6666 (0.7579) acc 78.1250 (74.6875) gate/entropy 1.0552 (1.0549) gate/usage_max 0.4491 (0.4498) gate/usage_min 0.2122 (0.2120) gate/usage_std 0.0968 (0.0971) teacher/entropy 0.5728 (0.5124) teacher/usage_max 0.4347 (0.4954) teacher/usage_min 0.1619 (0.1096) teacher/usage_std 0.1219 (0.1654) nleep/row_max_mean 1200.8916 (1200.2486) nleep/row_max_std 14.4828 (16.3544) nleep/row_min_mean 1196.4238 (1195.0341) lr 1.3090e-03 eta 1:00:11
epoch [22/50] batch [40/244] time 0.080 (0.486) data 0.000 (0.008) loss 1.7591 (2.0911) teacher_loss 0.5401 (0.9428) loss_zs_kd 0.0486 (0.0494) loss_oracle 0.7539 (0.7053) kd_loss 0.8177 (0.7709) acc 84.3750 (76.0156) gate/entropy 1.0569 (1.0555) gate/usage_max 0.4471 (0.4489) gate/usage_min 0.2147 (0.2128) gate/usage_std 0.0949 (0.0965) teacher/entropy 0.4714 (0.5011) teacher/usage_max 0.4822 (0.4978) teacher/usage_min 0.0482 (0.1079) teacher/usage_std 0.2017 (0.1683) nleep/row_max_mean 1200.1702 (1200.0452) nleep/row_max_std 15.2760 (16.2737) nleep/row_min_mean 1194.8937 (1194.8185) lr 1.3090e-03 eta 0:57:01
epoch [22/50] batch [60/244] time 0.462 (0.423) data 0.001 (0.005) loss 1.7594 (2.0997) teacher_loss 0.7154 (0.9279) loss_zs_kd 0.0547 (0.0491) loss_oracle 0.6611 (0.7547) kd_loss 0.6861 (0.7699) acc 81.2500 (76.1979) gate/entropy 1.0579 (1.0561) gate/usage_max 0.4459 (0.4481) gate/usage_min 0.2162 (0.2137) gate/usage_std 0.0938 (0.0957) teacher/entropy 0.5764 (0.5074) teacher/usage_max 0.4597 (0.5059) teacher/usage_min 0.0983 (0.1080) teacher/usage_std 0.1663 (0.1701) nleep/row_max_mean 1199.0625 (1199.7880) nleep/row_max_std 17.4440 (16.2794) nleep/row_min_mean 1195.1278 (1194.6250) lr 1.3090e-03 eta 0:49:27
epoch [22/50] batch [80/244] time 0.292 (0.367) data 0.000 (0.004) loss 2.5309 (2.0832) teacher_loss 1.4619 (0.9221) loss_zs_kd 0.0703 (0.0495) loss_oracle 0.6305 (0.7416) kd_loss 0.7186 (0.7656) acc 56.2500 (76.6016) gate/entropy 1.0593 (1.0568) gate/usage_max 0.4442 (0.4473) gate/usage_min 0.2184 (0.2147) gate/usage_std 0.0922 (0.0950) teacher/entropy 0.5588 (0.5112) teacher/usage_max 0.4890 (0.5071) teacher/usage_min 0.0811 (0.1070) teacher/usage_std 0.1800 (0.1712) nleep/row_max_mean 1198.3274 (1199.5429) nleep/row_max_std 13.2778 (16.3179) nleep/row_min_mean 1194.1174 (1194.4369) lr 1.3090e-03 eta 0:42:44
epoch [22/50] batch [100/244] time 0.472 (0.342) data 0.000 (0.003) loss 2.0102 (2.0693) teacher_loss 0.5777 (0.8990) loss_zs_kd 0.0559 (0.0495) loss_oracle 0.9981 (0.7515) kd_loss 0.9055 (0.7698) acc 84.3750 (77.2188) gate/entropy 1.0611 (1.0575) gate/usage_max 0.4422 (0.4464) gate/usage_min 0.2212 (0.2158) gate/usage_std 0.0902 (0.0942) teacher/entropy 0.4372 (0.5074) teacher/usage_max 0.6471 (0.5135) teacher/usage_min 0.0637 (0.1057) teacher/usage_std 0.2402 (0.1737) nleep/row_max_mean 1195.0825 (1199.3342) nleep/row_max_std 14.3798 (16.3504) nleep/row_min_mean 1190.0403 (1194.2038) lr 1.3090e-03 eta 0:39:48
epoch [22/50] batch [120/244] time 0.468 (0.366) data 0.000 (0.003) loss 1.9251 (2.0773) teacher_loss 0.7709 (0.8929) loss_zs_kd 0.0376 (0.0510) loss_oracle 0.8815 (0.7792) kd_loss 0.6947 (0.7693) acc 78.1250 (77.3177) gate/entropy 1.0625 (1.0582) gate/usage_max 0.4402 (0.4455) gate/usage_min 0.2234 (0.2169) gate/usage_std 0.0885 (0.0934) teacher/entropy 0.5687 (0.5059) teacher/usage_max 0.4966 (0.5132) teacher/usage_min 0.1080 (0.1054) teacher/usage_std 0.1646 (0.1736) nleep/row_max_mean 1196.0288 (1198.9938) nleep/row_max_std 15.6347 (16.2760) nleep/row_min_mean 1191.3704 (1193.8185) lr 1.3090e-03 eta 0:42:24
epoch [22/50] batch [140/244] time 0.438 (0.382) data 0.000 (0.002) loss 2.6666 (2.0973) teacher_loss 1.3825 (0.8985) loss_zs_kd 0.0753 (0.0503) loss_oracle 0.9206 (0.8067) kd_loss 0.7861 (0.7703) acc 68.7500 (77.0312) gate/entropy 1.0642 (1.0590) gate/usage_max 0.4384 (0.4446) gate/usage_min 0.2264 (0.2181) gate/usage_std 0.0866 (0.0925) teacher/entropy 0.5162 (0.5056) teacher/usage_max 0.6203 (0.5178) teacher/usage_min 0.1292 (0.1039) teacher/usage_std 0.2089 (0.1761) nleep/row_max_mean 1195.8853 (1198.7193) nleep/row_max_std 15.2727 (16.0456) nleep/row_min_mean 1191.2618 (1193.5325) lr 1.3090e-03 eta 0:44:08
epoch [22/50] batch [160/244] time 0.469 (0.394) data 0.000 (0.002) loss 2.0979 (2.1211) teacher_loss 0.9084 (0.9171) loss_zs_kd 0.0517 (0.0502) loss_oracle 0.7937 (0.8146) kd_loss 0.7668 (0.7716) acc 78.1250 (76.7578) gate/entropy 1.0663 (1.0598) gate/usage_max 0.4361 (0.4437) gate/usage_min 0.2303 (0.2194) gate/usage_std 0.0840 (0.0916) teacher/entropy 0.4886 (0.5044) teacher/usage_max 0.5117 (0.5212) teacher/usage_min 0.1163 (0.1016) teacher/usage_std 0.1637 (0.1782) nleep/row_max_mean 1193.4417 (1198.6332) nleep/row_max_std 12.8174 (15.8525) nleep/row_min_mean 1188.3568 (1193.4145) lr 1.3090e-03 eta 0:45:27
epoch [22/50] batch [180/244] time 0.088 (0.385) data 0.000 (0.002) loss 2.2717 (2.1265) teacher_loss 1.1715 (0.9212) loss_zs_kd 0.0469 (0.0496) loss_oracle 0.7757 (0.8191) kd_loss 0.6889 (0.7709) acc 59.3750 (76.5799) gate/entropy 1.0680 (1.0606) gate/usage_max 0.4337 (0.4427) gate/usage_min 0.2333 (0.2208) gate/usage_std 0.0818 (0.0906) teacher/entropy 0.5451 (0.5042) teacher/usage_max 0.4849 (0.5235) teacher/usage_min 0.0780 (0.1001) teacher/usage_std 0.1816 (0.1798) nleep/row_max_mean 1198.2036 (1198.4706) nleep/row_max_std 12.7202 (15.6898) nleep/row_min_mean 1193.3840 (1193.2372) lr 1.3090e-03 eta 0:44:11
epoch [22/50] batch [200/244] time 0.081 (0.385) data 0.000 (0.002) loss 2.0998 (2.1207) teacher_loss 0.9337 (0.9160) loss_zs_kd 0.0461 (0.0500) loss_oracle 0.7878 (0.8188) kd_loss 0.7491 (0.7703) acc 75.0000 (76.7188) gate/entropy 1.0699 (1.0615) gate/usage_max 0.4313 (0.4417) gate/usage_min 0.2367 (0.2222) gate/usage_std 0.0794 (0.0896) teacher/entropy 0.5133 (0.5033) teacher/usage_max 0.5380 (0.5246) teacher/usage_min 0.0812 (0.1001) teacher/usage_std 0.1895 (0.1801) nleep/row_max_mean 1196.8353 (1198.4895) nleep/row_max_std 15.1383 (15.6980) nleep/row_min_mean 1191.3446 (1193.2257) lr 1.3090e-03 eta 0:44:09
epoch [22/50] batch [220/244] time 0.093 (0.363) data 0.000 (0.002) loss 1.7695 (2.1133) teacher_loss 0.6894 (0.9132) loss_zs_kd 0.0442 (0.0496) loss_oracle 0.6515 (0.8108) kd_loss 0.7323 (0.7699) acc 75.0000 (76.7756) gate/entropy 1.0716 (1.0623) gate/usage_max 0.4288 (0.4406) gate/usage_min 0.2401 (0.2237) gate/usage_std 0.0771 (0.0886) teacher/entropy 0.5114 (0.5023) teacher/usage_max 0.4957 (0.5259) teacher/usage_min 0.0784 (0.0992) teacher/usage_std 0.1825 (0.1811) nleep/row_max_mean 1200.3221 (1198.5461) nleep/row_max_std 16.4243 (15.6781) nleep/row_min_mean 1194.9260 (1193.2551) lr 1.3090e-03 eta 0:41:31
epoch [22/50] batch [240/244] time 0.453 (0.359) data 0.000 (0.002) loss 2.2020 (2.1206) teacher_loss 0.9674 (0.9220) loss_zs_kd 0.0635 (0.0498) loss_oracle 0.8021 (0.8051) kd_loss 0.8018 (0.7711) acc 75.0000 (76.3932) gate/entropy 1.0731 (1.0631) gate/usage_max 0.4264 (0.4395) gate/usage_min 0.2427 (0.2252) gate/usage_std 0.0750 (0.0875) teacher/entropy 0.4426 (0.4988) teacher/usage_max 0.4883 (0.5253) teacher/usage_min 0.0328 (0.0975) teacher/usage_std 0.2125 (0.1818) nleep/row_max_mean 1200.6942 (1198.6152) nleep/row_max_std 12.2155 (15.6317) nleep/row_min_mean 1194.2571 (1193.2885) lr 1.3090e-03 eta 0:40:54
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,801
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 82.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,973
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 88.7%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [23/50] batch [20/244] time 0.496 (0.543) data 0.000 (0.019) loss 2.2497 (2.1869) teacher_loss 0.9652 (0.9791) loss_zs_kd 0.0314 (0.0547) loss_oracle 0.8445 (0.8206) kd_loss 0.8465 (0.7702) acc 75.0000 (75.7812) gate/entropy 1.0751 (1.0742) gate/usage_max 0.4233 (0.4245) gate/usage_min 0.2469 (0.2451) gate/usage_std 0.0720 (0.0733) teacher/entropy 0.4284 (0.4713) teacher/usage_max 0.6267 (0.5303) teacher/usage_min 0.0596 (0.0899) teacher/usage_std 0.2319 (0.1868) nleep/row_max_mean 1199.0498 (1198.3340) nleep/row_max_std 14.9000 (15.2238) nleep/row_min_mean 1193.5281 (1192.7089) lr 1.2487e-03 eta 1:01:37
epoch [23/50] batch [40/244] time 0.093 (0.505) data 0.000 (0.010) loss 2.0804 (2.1799) teacher_loss 0.9011 (0.9687) loss_zs_kd 0.0604 (0.0549) loss_oracle 0.7496 (0.8108) kd_loss 0.7743 (0.7784) acc 71.8750 (75.3125) gate/entropy 1.0767 (1.0751) gate/usage_max 0.4207 (0.4233) gate/usage_min 0.2503 (0.2468) gate/usage_std 0.0697 (0.0721) teacher/entropy 0.4228 (0.4705) teacher/usage_max 0.4806 (0.5616) teacher/usage_min 0.1072 (0.0813) teacher/usage_std 0.1623 (0.2012) nleep/row_max_mean 1196.8989 (1198.6350) nleep/row_max_std 16.3032 (15.0096) nleep/row_min_mean 1191.0992 (1193.0538) lr 1.2487e-03 eta 0:57:10
epoch [23/50] batch [60/244] time 0.485 (0.434) data 0.000 (0.006) loss 2.1964 (2.1631) teacher_loss 1.0644 (0.9538) loss_zs_kd 0.0533 (0.0553) loss_oracle 0.7575 (0.8097) kd_loss 0.7266 (0.7768) acc 78.1250 (75.9375) gate/entropy 1.0782 (1.0759) gate/usage_max 0.4183 (0.4220) gate/usage_min 0.2538 (0.2486) gate/usage_std 0.0673 (0.0708) teacher/entropy 0.5056 (0.4669) teacher/usage_max 0.5339 (0.5560) teacher/usage_min 0.0788 (0.0846) teacher/usage_std 0.1897 (0.1980) nleep/row_max_mean 1197.8342 (1198.4600) nleep/row_max_std 14.2582 (14.9710) nleep/row_min_mean 1192.8588 (1192.8608) lr 1.2487e-03 eta 0:48:58
epoch [23/50] batch [80/244] time 0.145 (0.375) data 0.000 (0.005) loss 2.0226 (2.1370) teacher_loss 0.8492 (0.9339) loss_zs_kd 0.0444 (0.0535) loss_oracle 0.7510 (0.7986) kd_loss 0.7756 (0.7771) acc 71.8750 (76.2500) gate/entropy 1.0798 (1.0767) gate/usage_max 0.4155 (0.4207) gate/usage_min 0.2576 (0.2505) gate/usage_std 0.0646 (0.0696) teacher/entropy 0.4691 (0.4652) teacher/usage_max 0.5958 (0.5570) teacher/usage_min 0.0612 (0.0799) teacher/usage_std 0.2183 (0.2004) nleep/row_max_mean 1197.1617 (1198.7484) nleep/row_max_std 14.7911 (15.0561) nleep/row_min_mean 1191.5978 (1193.0637) lr 1.2487e-03 eta 0:42:14
epoch [23/50] batch [100/244] time 0.155 (0.337) data 0.000 (0.004) loss 2.5112 (2.1224) teacher_loss 1.2138 (0.9213) loss_zs_kd 0.0479 (0.0524) loss_oracle 0.8847 (0.7975) kd_loss 0.8311 (0.7761) acc 68.7500 (76.2500) gate/entropy 1.0814 (1.0775) gate/usage_max 0.4127 (0.4194) gate/usage_min 0.2614 (0.2523) gate/usage_std 0.0620 (0.0683) teacher/entropy 0.4272 (0.4647) teacher/usage_max 0.6497 (0.5617) teacher/usage_min 0.0203 (0.0784) teacher/usage_std 0.2569 (0.2024) nleep/row_max_mean 1197.2244 (1198.8831) nleep/row_max_std 11.9840 (14.9047) nleep/row_min_mean 1191.0831 (1193.1948) lr 1.2487e-03 eta 0:37:49
epoch [23/50] batch [120/244] time 0.497 (0.364) data 0.000 (0.003) loss 2.2396 (2.1181) teacher_loss 1.1354 (0.9202) loss_zs_kd 0.0591 (0.0522) loss_oracle 0.7018 (0.7923) kd_loss 0.7237 (0.7756) acc 71.8750 (76.1719) gate/entropy 1.0827 (1.0782) gate/usage_max 0.4098 (0.4180) gate/usage_min 0.2647 (0.2541) gate/usage_std 0.0595 (0.0670) teacher/entropy 0.4930 (0.4628) teacher/usage_max 0.5462 (0.5639) teacher/usage_min 0.0797 (0.0778) teacher/usage_std 0.1926 (0.2034) nleep/row_max_mean 1202.2798 (1198.9020) nleep/row_max_std 13.6697 (14.8217) nleep/row_min_mean 1196.5425 (1193.1581) lr 1.2487e-03 eta 0:40:45
epoch [23/50] batch [140/244] time 0.496 (0.380) data 0.000 (0.003) loss 2.1769 (2.1206) teacher_loss 0.9604 (0.9229) loss_zs_kd 0.0335 (0.0519) loss_oracle 0.8653 (0.7953) kd_loss 0.7671 (0.7741) acc 81.2500 (75.9598) gate/entropy 1.0843 (1.0790) gate/usage_max 0.4068 (0.4166) gate/usage_min 0.2690 (0.2559) gate/usage_std 0.0566 (0.0657) teacher/entropy 0.4537 (0.4621) teacher/usage_max 0.5283 (0.5668) teacher/usage_min 0.0173 (0.0763) teacher/usage_std 0.2255 (0.2049) nleep/row_max_mean 1200.6754 (1198.9563) nleep/row_max_std 13.1954 (14.8121) nleep/row_min_mean 1194.5874 (1193.1943) lr 1.2487e-03 eta 0:42:21
epoch [23/50] batch [160/244] time 0.495 (0.393) data 0.000 (0.003) loss 2.4831 (2.1190) teacher_loss 1.2101 (0.9250) loss_zs_kd 0.0399 (0.0515) loss_oracle 0.8477 (0.7923) kd_loss 0.8292 (0.7721) acc 65.6250 (75.8008) gate/entropy 1.0857 (1.0797) gate/usage_max 0.4039 (0.4152) gate/usage_min 0.2735 (0.2578) gate/usage_std 0.0538 (0.0644) teacher/entropy 0.4045 (0.4612) teacher/usage_max 0.6956 (0.5695) teacher/usage_min 0.0535 (0.0771) teacher/usage_std 0.2686 (0.2054) nleep/row_max_mean 1196.0239 (1198.9175) nleep/row_max_std 14.5837 (14.7357) nleep/row_min_mean 1190.0615 (1193.1437) lr 1.2487e-03 eta 0:43:40
epoch [23/50] batch [180/244] time 0.097 (0.389) data 0.000 (0.002) loss 1.9481 (2.1170) teacher_loss 0.8523 (0.9283) loss_zs_kd 0.0318 (0.0514) loss_oracle 0.7693 (0.7856) kd_loss 0.6953 (0.7702) acc 78.1250 (75.8160) gate/entropy 1.0869 (1.0805) gate/usage_max 0.4011 (0.4138) gate/usage_min 0.2770 (0.2597) gate/usage_std 0.0513 (0.0631) teacher/entropy 0.5085 (0.4606) teacher/usage_max 0.5813 (0.5724) teacher/usage_min 0.0741 (0.0763) teacher/usage_std 0.2072 (0.2068) nleep/row_max_mean 1194.2451 (1198.8226) nleep/row_max_std 12.3555 (14.6774) nleep/row_min_mean 1189.3912 (1193.0341) lr 1.2487e-03 eta 0:43:09
epoch [23/50] batch [200/244] time 0.457 (0.390) data 0.000 (0.002) loss 1.7853 (2.1080) teacher_loss 0.6405 (0.9200) loss_zs_kd 0.0538 (0.0510) loss_oracle 0.7330 (0.7843) kd_loss 0.7514 (0.7704) acc 81.2500 (75.9375) gate/entropy 1.0881 (1.0812) gate/usage_max 0.3981 (0.4124) gate/usage_min 0.2812 (0.2616) gate/usage_std 0.0485 (0.0618) teacher/entropy 0.4367 (0.4579) teacher/usage_max 0.5663 (0.5763) teacher/usage_min 0.1116 (0.0758) teacher/usage_std 0.1858 (0.2087) nleep/row_max_mean 1195.5160 (1198.8184) nleep/row_max_std 12.7374 (14.6360) nleep/row_min_mean 1189.5022 (1192.9921) lr 1.2487e-03 eta 0:43:05
epoch [23/50] batch [220/244] time 0.082 (0.367) data 0.000 (0.002) loss 2.4206 (2.1110) teacher_loss 1.2368 (0.9260) loss_zs_kd 0.0509 (0.0513) loss_oracle 0.7680 (0.7799) kd_loss 0.7744 (0.7694) acc 65.6250 (75.7102) gate/entropy 1.0892 (1.0819) gate/usage_max 0.3952 (0.4109) gate/usage_min 0.2849 (0.2636) gate/usage_std 0.0460 (0.0605) teacher/entropy 0.4448 (0.4563) teacher/usage_max 0.7788 (0.5797) teacher/usage_min 0.0491 (0.0745) teacher/usage_std 0.3189 (0.2105) nleep/row_max_mean 1195.6423 (1198.8152) nleep/row_max_std 14.7892 (14.5930) nleep/row_min_mean 1190.5896 (1192.9600) lr 1.2487e-03 eta 0:40:27
epoch [23/50] batch [240/244] time 0.495 (0.360) data 0.000 (0.002) loss 1.8322 (2.1134) teacher_loss 0.5239 (0.9283) loss_zs_kd 0.0582 (0.0518) loss_oracle 0.8706 (0.7790) kd_loss 0.8438 (0.7697) acc 90.6250 (75.7292) gate/entropy 1.0903 (1.0825) gate/usage_max 0.3921 (0.4095) gate/usage_min 0.2894 (0.2656) gate/usage_std 0.0432 (0.0592) teacher/entropy 0.3492 (0.4533) teacher/usage_max 0.6065 (0.5823) teacher/usage_min 0.0390 (0.0735) teacher/usage_std 0.2322 (0.2119) nleep/row_max_mean 1199.7344 (1198.7918) nleep/row_max_std 14.0355 (14.5877) nleep/row_min_mean 1192.5322 (1192.8972) lr 1.2487e-03 eta 0:39:36
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,812
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,984
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 88.9%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [24/50] batch [20/244] time 0.523 (0.524) data 0.000 (0.013) loss 2.2531 (2.0234) teacher_loss 1.0425 (0.8771) loss_zs_kd 0.0637 (0.0502) loss_oracle 0.8112 (0.7674) kd_loss 0.7732 (0.7375) acc 68.7500 (77.3438) gate/entropy 1.0914 (1.0910) gate/usage_max 0.3886 (0.3900) gate/usage_min 0.2938 (0.2920) gate/usage_std 0.0403 (0.0414) teacher/entropy 0.4074 (0.4453) teacher/usage_max 0.6255 (0.5817) teacher/usage_min 0.0723 (0.0595) teacher/usage_std 0.2269 (0.2176) nleep/row_max_mean 1195.5098 (1199.6088) nleep/row_max_std 13.8038 (14.9235) nleep/row_min_mean 1189.0554 (1193.4761) lr 1.1874e-03 eta 0:57:20
epoch [24/50] batch [40/244] time 0.496 (0.504) data 0.000 (0.007) loss 2.7581 (2.1070) teacher_loss 1.6094 (0.9571) loss_zs_kd 0.0715 (0.0525) loss_oracle 0.7341 (0.7541) kd_loss 0.7459 (0.7466) acc 59.3750 (74.9219) gate/entropy 1.0923 (1.0915) gate/usage_max 0.3856 (0.3885) gate/usage_min 0.2974 (0.2939) gate/usage_std 0.0378 (0.0402) teacher/entropy 0.4333 (0.4338) teacher/usage_max 0.6649 (0.5984) teacher/usage_min 0.0580 (0.0615) teacher/usage_std 0.2509 (0.2236) nleep/row_max_mean 1194.1021 (1198.9337) nleep/row_max_std 16.5848 (15.2704) nleep/row_min_mean 1188.3682 (1192.8207) lr 1.1874e-03 eta 0:54:57
epoch [24/50] batch [60/244] time 0.486 (0.421) data 0.000 (0.005) loss 2.4440 (2.1165) teacher_loss 1.3155 (0.9709) loss_zs_kd 0.0883 (0.0538) loss_oracle 0.7377 (0.7428) kd_loss 0.7155 (0.7473) acc 71.8750 (75.0000) gate/entropy 1.0930 (1.0919) gate/usage_max 0.3829 (0.3871) gate/usage_min 0.3011 (0.2957) gate/usage_std 0.0356 (0.0390) teacher/entropy 0.4536 (0.4303) teacher/usage_max 0.6252 (0.6024) teacher/usage_min 0.0648 (0.0615) teacher/usage_std 0.2294 (0.2246) nleep/row_max_mean 1192.6024 (1198.5197) nleep/row_max_std 16.4683 (15.2606) nleep/row_min_mean 1186.8540 (1192.3434) lr 1.1874e-03 eta 0:45:49
epoch [24/50] batch [80/244] time 0.203 (0.378) data 0.000 (0.003) loss 2.2528 (2.1096) teacher_loss 1.1285 (0.9651) loss_zs_kd 0.0310 (0.0534) loss_oracle 0.7505 (0.7414) kd_loss 0.7336 (0.7471) acc 65.6250 (75.2344) gate/entropy 1.0937 (1.0922) gate/usage_max 0.3800 (0.3856) gate/usage_min 0.3049 (0.2975) gate/usage_std 0.0333 (0.0379) teacher/entropy 0.4346 (0.4278) teacher/usage_max 0.7239 (0.6102) teacher/usage_min 0.0542 (0.0620) teacher/usage_std 0.2845 (0.2278) nleep/row_max_mean 1195.8324 (1198.5267) nleep/row_max_std 15.7652 (15.3041) nleep/row_min_mean 1189.5068 (1192.3286) lr 1.1874e-03 eta 0:41:01
epoch [24/50] batch [100/244] time 0.473 (0.352) data 0.000 (0.003) loss 2.1052 (2.0817) teacher_loss 0.8486 (0.9395) loss_zs_kd 0.0719 (0.0525) loss_oracle 0.7680 (0.7350) kd_loss 0.8367 (0.7485) acc 75.0000 (75.8750) gate/entropy 1.0943 (1.0926) gate/usage_max 0.3772 (0.3842) gate/usage_min 0.3089 (0.2994) gate/usage_std 0.0311 (0.0367) teacher/entropy 0.3223 (0.4232) teacher/usage_max 0.7457 (0.6163) teacher/usage_min 0.0596 (0.0635) teacher/usage_std 0.2967 (0.2296) nleep/row_max_mean 1198.6895 (1198.5098) nleep/row_max_std 12.6923 (15.3819) nleep/row_min_mean 1191.5165 (1192.2464) lr 1.1874e-03 eta 0:38:02
epoch [24/50] batch [120/244] time 0.302 (0.372) data 0.000 (0.002) loss 2.2101 (2.0834) teacher_loss 1.0841 (0.9499) loss_zs_kd 0.0406 (0.0520) loss_oracle 0.7259 (0.7232) kd_loss 0.7428 (0.7458) acc 71.8750 (75.8854) gate/entropy 1.0949 (1.0929) gate/usage_max 0.3746 (0.3828) gate/usage_min 0.3121 (0.3012) gate/usage_std 0.0292 (0.0356) teacher/entropy 0.4092 (0.4228) teacher/usage_max 0.6524 (0.6163) teacher/usage_min 0.0612 (0.0635) teacher/usage_std 0.2436 (0.2296) nleep/row_max_mean 1196.9059 (1198.5469) nleep/row_max_std 16.3844 (15.2685) nleep/row_min_mean 1190.2397 (1192.3061) lr 1.1874e-03 eta 0:40:05
epoch [24/50] batch [140/244] time 0.468 (0.387) data 0.000 (0.002) loss 1.8021 (2.0736) teacher_loss 0.6311 (0.9450) loss_zs_kd 0.0330 (0.0521) loss_oracle 0.7757 (0.7158) kd_loss 0.7666 (0.7446) acc 84.3750 (76.2277) gate/entropy 1.0953 (1.0933) gate/usage_max 0.3719 (0.3814) gate/usage_min 0.3128 (0.3029) gate/usage_std 0.0273 (0.0345) teacher/entropy 0.3745 (0.4210) teacher/usage_max 0.6563 (0.6179) teacher/usage_min 0.0907 (0.0647) teacher/usage_std 0.2378 (0.2297) nleep/row_max_mean 1199.4097 (1198.3642) nleep/row_max_std 17.4748 (15.2687) nleep/row_min_mean 1192.4192 (1192.1103) lr 1.1874e-03 eta 0:41:35
epoch [24/50] batch [160/244] time 0.497 (0.399) data 0.000 (0.002) loss 1.9378 (2.0552) teacher_loss 0.9328 (0.9280) loss_zs_kd 0.0592 (0.0515) loss_oracle 0.6388 (0.7177) kd_loss 0.6559 (0.7427) acc 71.8750 (76.4648) gate/entropy 1.0957 (1.0935) gate/usage_max 0.3692 (0.3801) gate/usage_min 0.3119 (0.3040) gate/usage_std 0.0255 (0.0335) teacher/entropy 0.4764 (0.4201) teacher/usage_max 0.6059 (0.6211) teacher/usage_min 0.1109 (0.0638) teacher/usage_std 0.2052 (0.2315) nleep/row_max_mean 1197.7480 (1198.3032) nleep/row_max_std 15.7372 (15.2371) nleep/row_min_mean 1192.6799 (1192.0482) lr 1.1874e-03 eta 0:42:47
epoch [24/50] batch [180/244] time 0.084 (0.391) data 0.000 (0.002) loss 2.0673 (2.0638) teacher_loss 0.9325 (0.9394) loss_zs_kd 0.0623 (0.0516) loss_oracle 0.8053 (0.7172) kd_loss 0.7010 (0.7401) acc 71.8750 (76.0243) gate/entropy 1.0961 (1.0938) gate/usage_max 0.3663 (0.3787) gate/usage_min 0.3109 (0.3048) gate/usage_std 0.0238 (0.0325) teacher/entropy 0.4323 (0.4199) teacher/usage_max 0.6163 (0.6201) teacher/usage_min 0.0686 (0.0640) teacher/usage_std 0.2240 (0.2309) nleep/row_max_mean 1195.9026 (1198.2013) nleep/row_max_std 13.1357 (15.1093) nleep/row_min_mean 1189.4126 (1191.9533) lr 1.1874e-03 eta 0:41:43
epoch [24/50] batch [200/244] time 0.505 (0.391) data 0.000 (0.001) loss 1.8897 (2.0553) teacher_loss 0.7047 (0.9300) loss_zs_kd 0.0477 (0.0517) loss_oracle 0.7330 (0.7204) kd_loss 0.7947 (0.7392) acc 81.2500 (76.1094) gate/entropy 1.0964 (1.0940) gate/usage_max 0.3635 (0.3773) gate/usage_min 0.3105 (0.3054) gate/usage_std 0.0223 (0.0316) teacher/entropy 0.3352 (0.4180) teacher/usage_max 0.5974 (0.6195) teacher/usage_min 0.0674 (0.0628) teacher/usage_std 0.2164 (0.2311) nleep/row_max_mean 1201.0851 (1198.2490) nleep/row_max_std 14.3049 (14.9570) nleep/row_min_mean 1194.0065 (1191.9782) lr 1.1874e-03 eta 0:41:35
epoch [24/50] batch [220/244] time 0.140 (0.364) data 0.000 (0.001) loss 2.3866 (2.0461) teacher_loss 1.1970 (0.9195) loss_zs_kd 0.0552 (0.0513) loss_oracle 0.8994 (0.7262) kd_loss 0.7123 (0.7378) acc 68.7500 (76.3352) gate/entropy 1.0966 (1.0943) gate/usage_max 0.3608 (0.3759) gate/usage_min 0.3095 (0.3058) gate/usage_std 0.0211 (0.0307) teacher/entropy 0.4074 (0.4167) teacher/usage_max 0.6637 (0.6192) teacher/usage_min 0.0732 (0.0627) teacher/usage_std 0.2461 (0.2310) nleep/row_max_mean 1195.2168 (1198.2644) nleep/row_max_std 14.6863 (14.9633) nleep/row_min_mean 1187.6504 (1191.9626) lr 1.1874e-03 eta 0:38:38
epoch [24/50] batch [240/244] time 0.481 (0.364) data 0.000 (0.001) loss 2.3209 (2.0445) teacher_loss 1.1654 (0.9181) loss_zs_kd 0.0492 (0.0517) loss_oracle 0.7864 (0.7285) kd_loss 0.7377 (0.7362) acc 75.0000 (76.3542) gate/entropy 1.0968 (1.0945) gate/usage_max 0.3580 (0.3745) gate/usage_min 0.3086 (0.3061) gate/usage_std 0.0202 (0.0298) teacher/entropy 0.3757 (0.4153) teacher/usage_max 0.7171 (0.6202) teacher/usage_min 0.0450 (0.0635) teacher/usage_std 0.2825 (0.2310) nleep/row_max_mean 1195.4502 (1198.3024) nleep/row_max_std 15.7272 (14.9199) nleep/row_min_mean 1188.1965 (1191.9856) lr 1.1874e-03 eta 0:38:33
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,804
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,992
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 89.2%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [25/50] batch [20/244] time 0.498 (0.490) data 0.000 (0.011) loss 1.7672 (2.0664) teacher_loss 0.6157 (0.9369) loss_zs_kd 0.0442 (0.0432) loss_oracle 0.7779 (0.7747) kd_loss 0.7403 (0.7205) acc 84.3750 (75.9375) gate/entropy 1.0969 (1.0969) gate/usage_max 0.3549 (0.3561) gate/usage_min 0.3079 (0.3082) gate/usage_std 0.0193 (0.0197) teacher/entropy 0.3765 (0.3950) teacher/usage_max 0.6047 (0.6258) teacher/usage_min 0.0434 (0.0532) teacher/usage_std 0.2295 (0.2366) nleep/row_max_mean 1200.1567 (1198.1143) nleep/row_max_std 15.9217 (14.4320) nleep/row_min_mean 1193.6804 (1191.7979) lr 1.1253e-03 eta 0:51:36
epoch [25/50] batch [40/244] time 0.484 (0.490) data 0.000 (0.006) loss 1.8975 (2.0466) teacher_loss 0.7490 (0.9246) loss_zs_kd 0.0536 (0.0441) loss_oracle 0.7912 (0.7863) kd_loss 0.7262 (0.7068) acc 71.8750 (76.0938) gate/entropy 1.0969 (1.0969) gate/usage_max 0.3524 (0.3548) gate/usage_min 0.3070 (0.3078) gate/usage_std 0.0193 (0.0195) teacher/entropy 0.3798 (0.4045) teacher/usage_max 0.6428 (0.6276) teacher/usage_min 0.0548 (0.0644) teacher/usage_std 0.2410 (0.2340) nleep/row_max_mean 1199.2761 (1197.8899) nleep/row_max_std 15.2972 (14.0444) nleep/row_min_mean 1192.5339 (1191.6361) lr 1.1253e-03 eta 0:51:29
epoch [25/50] batch [60/244] time 0.458 (0.417) data 0.000 (0.004) loss 1.8182 (2.0143) teacher_loss 0.7628 (0.9066) loss_zs_kd 0.0482 (0.0444) loss_oracle 0.6778 (0.7609) kd_loss 0.6924 (0.7051) acc 87.5000 (76.9271) gate/entropy 1.0969 (1.0969) gate/usage_max 0.3498 (0.3535) gate/usage_min 0.3061 (0.3074) gate/usage_std 0.0194 (0.0194) teacher/entropy 0.3988 (0.4032) teacher/usage_max 0.7296 (0.6347) teacher/usage_min 0.0537 (0.0620) teacher/usage_std 0.2880 (0.2381) nleep/row_max_mean 1199.0393 (1197.9745) nleep/row_max_std 14.9290 (14.3256) nleep/row_min_mean 1192.4827 (1191.6488) lr 1.1253e-03 eta 0:43:41
epoch [25/50] batch [80/244] time 0.106 (0.365) data 0.000 (0.003) loss 1.8474 (2.0272) teacher_loss 0.7191 (0.9331) loss_zs_kd 0.0517 (0.0458) loss_oracle 0.7116 (0.7373) kd_loss 0.7466 (0.7025) acc 81.2500 (76.2891) gate/entropy 1.0968 (1.0969) gate/usage_max 0.3473 (0.3522) gate/usage_min 0.3055 (0.3071) gate/usage_std 0.0197 (0.0194) teacher/entropy 0.3543 (0.4041) teacher/usage_max 0.6101 (0.6341) teacher/usage_min 0.0518 (0.0570) teacher/usage_std 0.2279 (0.2401) nleep/row_max_mean 1198.9292 (1198.0161) nleep/row_max_std 15.6055 (14.5063) nleep/row_min_mean 1191.0026 (1191.6228) lr 1.1253e-03 eta 0:38:09
epoch [25/50] batch [100/244] time 0.529 (0.354) data 0.000 (0.002) loss 2.1068 (2.0217) teacher_loss 1.0108 (0.9314) loss_zs_kd 0.0371 (0.0469) loss_oracle 0.7198 (0.7271) kd_loss 0.7175 (0.7033) acc 68.7500 (75.8750) gate/entropy 1.0968 (1.0969) gate/usage_max 0.3501 (0.3515) gate/usage_min 0.3053 (0.3067) gate/usage_std 0.0199 (0.0194) teacher/entropy 0.3861 (0.4017) teacher/usage_max 0.5828 (0.6302) teacher/usage_min 0.0237 (0.0551) teacher/usage_std 0.2322 (0.2393) nleep/row_max_mean 1197.1990 (1197.9752) nleep/row_max_std 12.3754 (14.4503) nleep/row_min_mean 1190.6392 (1191.5590) lr 1.1253e-03 eta 0:36:52
epoch [25/50] batch [120/244] time 0.525 (0.378) data 0.000 (0.002) loss 2.3063 (2.0187) teacher_loss 1.2671 (0.9270) loss_zs_kd 0.0326 (0.0479) loss_oracle 0.7515 (0.7284) kd_loss 0.6471 (0.7035) acc 62.5000 (75.9635) gate/entropy 1.0967 (1.0969) gate/usage_max 0.3531 (0.3516) gate/usage_min 0.3050 (0.3065) gate/usage_std 0.0206 (0.0196) teacher/entropy 0.4426 (0.3994) teacher/usage_max 0.6463 (0.6290) teacher/usage_min 0.0256 (0.0534) teacher/usage_std 0.2534 (0.2396) nleep/row_max_mean 1193.4368 (1197.9063) nleep/row_max_std 13.6415 (14.4891) nleep/row_min_mean 1187.4415 (1191.4405) lr 1.1253e-03 eta 0:39:15
epoch [25/50] batch [140/244] time 0.462 (0.400) data 0.000 (0.002) loss 1.9492 (2.0271) teacher_loss 0.7907 (0.9333) loss_zs_kd 0.0329 (0.0478) loss_oracle 0.7607 (0.7275) kd_loss 0.7616 (0.7061) acc 87.5000 (75.8929) gate/entropy 1.0965 (1.0968) gate/usage_max 0.3562 (0.3520) gate/usage_min 0.3044 (0.3062) gate/usage_std 0.0216 (0.0198) teacher/entropy 0.3303 (0.3949) teacher/usage_max 0.5903 (0.6267) teacher/usage_min 0.0390 (0.0523) teacher/usage_std 0.2266 (0.2387) nleep/row_max_mean 1204.2056 (1197.9809) nleep/row_max_std 14.4073 (14.3612) nleep/row_min_mean 1196.4080 (1191.4833) lr 1.1253e-03 eta 0:41:19
epoch [25/50] batch [160/244] time 0.495 (0.412) data 0.000 (0.002) loss 2.2043 (2.0238) teacher_loss 1.1170 (0.9364) loss_zs_kd 0.0438 (0.0478) loss_oracle 0.6468 (0.7192) kd_loss 0.7420 (0.7039) acc 75.0000 (75.8789) gate/entropy 1.0963 (1.0968) gate/usage_max 0.3591 (0.3527) gate/usage_min 0.3044 (0.3060) gate/usage_std 0.0224 (0.0201) teacher/entropy 0.3552 (0.3955) teacher/usage_max 0.5377 (0.6234) teacher/usage_min 0.0274 (0.0519) teacher/usage_std 0.2203 (0.2375) nleep/row_max_mean 1200.6174 (1198.0798) nleep/row_max_std 15.0059 (14.2938) nleep/row_min_mean 1193.4718 (1191.5317) lr 1.1253e-03 eta 0:42:29
epoch [25/50] batch [180/244] time 0.564 (0.398) data 0.000 (0.001) loss 2.2778 (2.0154) teacher_loss 1.2884 (0.9354) loss_zs_kd 0.0416 (0.0477) loss_oracle 0.7123 (0.7109) kd_loss 0.6124 (0.7007) acc 65.6250 (75.8854) gate/entropy 1.0961 (1.0967) gate/usage_max 0.3617 (0.3536) gate/usage_min 0.3041 (0.3058) gate/usage_std 0.0235 (0.0204) teacher/entropy 0.4711 (0.3971) teacher/usage_max 0.6022 (0.6191) teacher/usage_min 0.0248 (0.0519) teacher/usage_std 0.2374 (0.2356) nleep/row_max_mean 1194.0546 (1198.0408) nleep/row_max_std 12.8153 (14.3175) nleep/row_min_mean 1187.9546 (1191.4829) lr 1.1253e-03 eta 0:40:53
epoch [25/50] batch [200/244] time 0.093 (0.387) data 0.000 (0.001) loss 1.9272 (2.0169) teacher_loss 0.7897 (0.9375) loss_zs_kd 0.0509 (0.0476) loss_oracle 0.7319 (0.7138) kd_loss 0.7461 (0.6987) acc 78.1250 (75.9062) gate/entropy 1.0959 (1.0966) gate/usage_max 0.3645 (0.3545) gate/usage_min 0.3039 (0.3056) gate/usage_std 0.0248 (0.0208) teacher/entropy 0.3232 (0.3968) teacher/usage_max 0.6480 (0.6193) teacher/usage_min 0.0365 (0.0524) teacher/usage_std 0.2500 (0.2355) nleep/row_max_mean 1199.7036 (1197.9160) nleep/row_max_std 14.8012 (14.2392) nleep/row_min_mean 1192.3320 (1191.3497) lr 1.1253e-03 eta 0:39:37
epoch [25/50] batch [220/244] time 0.082 (0.369) data 0.000 (0.001) loss 1.5867 (2.0112) teacher_loss 0.5252 (0.9340) loss_zs_kd 0.0579 (0.0480) loss_oracle 0.6912 (0.7140) kd_loss 0.6869 (0.6962) acc 87.5000 (75.9517) gate/entropy 1.0956 (1.0966) gate/usage_max 0.3672 (0.3556) gate/usage_min 0.3038 (0.3055) gate/usage_std 0.0261 (0.0212) teacher/entropy 0.3853 (0.3975) teacher/usage_max 0.5951 (0.6172) teacher/usage_min 0.0757 (0.0526) teacher/usage_std 0.2120 (0.2349) nleep/row_max_mean 1196.8118 (1197.8532) nleep/row_max_std 12.3761 (14.2592) nleep/row_min_mean 1190.1097 (1191.2711) lr 1.1253e-03 eta 0:37:37
epoch [25/50] batch [240/244] time 0.521 (0.374) data 0.000 (0.001) loss 1.8077 (2.0094) teacher_loss 0.7824 (0.9342) loss_zs_kd 0.0478 (0.0488) loss_oracle 0.6045 (0.7109) kd_loss 0.6992 (0.6954) acc 84.3750 (75.8594) gate/entropy 1.0952 (1.0965) gate/usage_max 0.3701 (0.3567) gate/usage_min 0.3034 (0.3053) gate/usage_std 0.0277 (0.0217) teacher/entropy 0.3819 (0.3962) teacher/usage_max 0.5423 (0.6179) teacher/usage_min 0.0486 (0.0515) teacher/usage_std 0.2085 (0.2356) nleep/row_max_mean 1197.1077 (1197.8685) nleep/row_max_std 15.3808 (14.2745) nleep/row_min_mean 1190.0198 (1191.2496) lr 1.1253e-03 eta 0:38:01
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,804
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.1%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,996
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.4%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [26/50] batch [20/244] time 0.540 (0.514) data 0.000 (0.014) loss 1.8711 (1.9083) teacher_loss 0.8526 (0.8662) loss_zs_kd 0.0417 (0.0494) loss_oracle 0.6387 (0.6635) kd_loss 0.6782 (0.6856) acc 75.0000 (77.1875) gate/entropy 1.0948 (1.0949) gate/usage_max 0.3732 (0.3721) gate/usage_min 0.3034 (0.3032) gate/usage_std 0.0293 (0.0288) teacher/entropy 0.3678 (0.3732) teacher/usage_max 0.6975 (0.6408) teacher/usage_min 0.0370 (0.0454) teacher/usage_std 0.2738 (0.2484) nleep/row_max_mean 1199.0447 (1196.0745) nleep/row_max_std 14.0797 (13.8596) nleep/row_min_mean 1192.4224 (1189.3935) lr 1.0628e-03 eta 0:52:03
epoch [26/50] batch [40/244] time 0.083 (0.411) data 0.000 (0.007) loss 2.0628 (1.8564) teacher_loss 1.0089 (0.8281) loss_zs_kd 0.0431 (0.0478) loss_oracle 0.6351 (0.6505) kd_loss 0.7149 (0.6791) acc 65.6250 (78.4375) gate/entropy 1.0944 (1.0947) gate/usage_max 0.3756 (0.3733) gate/usage_min 0.3029 (0.3031) gate/usage_std 0.0309 (0.0295) teacher/entropy 0.3543 (0.3839) teacher/usage_max 0.5766 (0.6158) teacher/usage_min 0.0093 (0.0468) teacher/usage_std 0.2385 (0.2371) nleep/row_max_mean 1196.1597 (1196.3396) nleep/row_max_std 14.1901 (13.6163) nleep/row_min_mean 1189.8500 (1189.6845) lr 1.0628e-03 eta 0:41:29
epoch [26/50] batch [60/244] time 0.081 (0.404) data 0.000 (0.005) loss 1.8345 (1.9037) teacher_loss 0.7833 (0.8709) loss_zs_kd 0.0402 (0.0492) loss_oracle 0.7871 (0.6689) kd_loss 0.6376 (0.6738) acc 87.5000 (77.6562) gate/entropy 1.0939 (1.0945) gate/usage_max 0.3784 (0.3746) gate/usage_min 0.3024 (0.3030) gate/usage_std 0.0326 (0.0302) teacher/entropy 0.3943 (0.3866) teacher/usage_max 0.7220 (0.6178) teacher/usage_min 0.0325 (0.0491) teacher/usage_std 0.2883 (0.2365) nleep/row_max_mean 1194.4945 (1196.6035) nleep/row_max_std 12.7658 (13.5570) nleep/row_min_mean 1188.2286 (1189.9546) lr 1.0628e-03 eta 0:40:43
epoch [26/50] batch [80/244] time 0.090 (0.338) data 0.000 (0.004) loss 1.9038 (1.9166) teacher_loss 0.8954 (0.8816) loss_zs_kd 0.0368 (0.0494) loss_oracle 0.6606 (0.6766) kd_loss 0.6598 (0.6721) acc 78.1250 (77.3047) gate/entropy 1.0934 (1.0943) gate/usage_max 0.3810 (0.3759) gate/usage_min 0.3022 (0.3029) gate/usage_std 0.0343 (0.0310) teacher/entropy 0.3943 (0.3858) teacher/usage_max 0.6085 (0.6204) teacher/usage_min 0.0271 (0.0480) teacher/usage_std 0.2384 (0.2376) nleep/row_max_mean 1200.0403 (1196.6679) nleep/row_max_std 13.5354 (13.5759) nleep/row_min_mean 1192.4875 (1189.9461) lr 1.0628e-03 eta 0:33:54
epoch [26/50] batch [100/244] time 0.523 (0.337) data 0.000 (0.003) loss 2.1159 (1.9164) teacher_loss 1.0285 (0.8847) loss_zs_kd 0.0644 (0.0497) loss_oracle 0.6713 (0.6743) kd_loss 0.7195 (0.6696) acc 78.1250 (77.1562) gate/entropy 1.0930 (1.0941) gate/usage_max 0.3835 (0.3771) gate/usage_min 0.3021 (0.3028) gate/usage_std 0.0358 (0.0318) teacher/entropy 0.3486 (0.3864) teacher/usage_max 0.5287 (0.6201) teacher/usage_min 0.0480 (0.0476) teacher/usage_std 0.2063 (0.2376) nleep/row_max_mean 1200.8269 (1196.8475) nleep/row_max_std 17.0782 (13.8232) nleep/row_min_mean 1193.0635 (1190.1037) lr 1.0628e-03 eta 0:33:41
epoch [26/50] batch [120/244] time 0.464 (0.367) data 0.000 (0.003) loss 1.8092 (1.9247) teacher_loss 0.7353 (0.8918) loss_zs_kd 0.0532 (0.0500) loss_oracle 0.6707 (0.6783) kd_loss 0.7120 (0.6688) acc 78.1250 (77.0573) gate/entropy 1.0924 (1.0939) gate/usage_max 0.3859 (0.3784) gate/usage_min 0.3019 (0.3027) gate/usage_std 0.0374 (0.0326) teacher/entropy 0.3467 (0.3852) teacher/usage_max 0.5565 (0.6209) teacher/usage_min 0.0640 (0.0478) teacher/usage_std 0.2037 (0.2377) nleep/row_max_mean 1200.0491 (1196.8241) nleep/row_max_std 13.8799 (13.9047) nleep/row_min_mean 1193.0620 (1190.0814) lr 1.0628e-03 eta 0:36:31
epoch [26/50] batch [140/244] time 0.521 (0.385) data 0.000 (0.002) loss 2.2909 (1.9401) teacher_loss 1.3161 (0.9095) loss_zs_kd 0.0312 (0.0496) loss_oracle 0.5919 (0.6793) kd_loss 0.6632 (0.6661) acc 68.7500 (76.8080) gate/entropy 1.0918 (1.0936) gate/usage_max 0.3886 (0.3797) gate/usage_min 0.3016 (0.3026) gate/usage_std 0.0392 (0.0335) teacher/entropy 0.4029 (0.3867) teacher/usage_max 0.5170 (0.6181) teacher/usage_min 0.0476 (0.0477) teacher/usage_std 0.2048 (0.2365) nleep/row_max_mean 1196.6306 (1196.7772) nleep/row_max_std 15.8242 (13.8186) nleep/row_min_mean 1190.0068 (1190.0553) lr 1.0628e-03 eta 0:38:15
epoch [26/50] batch [160/244] time 0.506 (0.399) data 0.000 (0.002) loss 2.0259 (1.9446) teacher_loss 0.9997 (0.9163) loss_zs_kd 0.0552 (0.0492) loss_oracle 0.6237 (0.6773) kd_loss 0.6868 (0.6651) acc 78.1250 (76.6211) gate/entropy 1.0912 (1.0934) gate/usage_max 0.3912 (0.3810) gate/usage_min 0.3015 (0.3024) gate/usage_std 0.0410 (0.0343) teacher/entropy 0.3671 (0.3855) teacher/usage_max 0.5488 (0.6201) teacher/usage_min 0.1040 (0.0479) teacher/usage_std 0.1819 (0.2373) nleep/row_max_mean 1197.9285 (1196.6709) nleep/row_max_std 16.3833 (13.7838) nleep/row_min_mean 1190.5813 (1189.9401) lr 1.0628e-03 eta 0:39:28
epoch [26/50] batch [180/244] time 0.463 (0.390) data 0.000 (0.002) loss 1.6559 (1.9330) teacher_loss 0.6494 (0.9059) loss_zs_kd 0.0593 (0.0486) loss_oracle 0.5636 (0.6742) kd_loss 0.6951 (0.6656) acc 78.1250 (76.9097) gate/entropy 1.0907 (1.0931) gate/usage_max 0.3936 (0.3823) gate/usage_min 0.3012 (0.3023) gate/usage_std 0.0426 (0.0351) teacher/entropy 0.3628 (0.3835) teacher/usage_max 0.5288 (0.6191) teacher/usage_min 0.0174 (0.0461) teacher/usage_std 0.2255 (0.2376) nleep/row_max_mean 1200.4790 (1196.8265) nleep/row_max_std 17.1178 (13.9353) nleep/row_min_mean 1193.2173 (1190.0381) lr 1.0628e-03 eta 0:38:31
epoch [26/50] batch [200/244] time 0.182 (0.375) data 0.000 (0.002) loss 1.5020 (1.9325) teacher_loss 0.5243 (0.9090) loss_zs_kd 0.0363 (0.0488) loss_oracle 0.6474 (0.6715) kd_loss 0.6358 (0.6633) acc 90.6250 (76.6875) gate/entropy 1.0900 (1.0928) gate/usage_max 0.3961 (0.3835) gate/usage_min 0.3011 (0.3022) gate/usage_std 0.0444 (0.0360) teacher/entropy 0.4020 (0.3838) teacher/usage_max 0.5899 (0.6199) teacher/usage_min 0.0661 (0.0451) teacher/usage_std 0.2140 (0.2385) nleep/row_max_mean 1195.2754 (1196.8117) nleep/row_max_std 12.4259 (14.0185) nleep/row_min_mean 1187.9946 (1190.0052) lr 1.0628e-03 eta 0:36:50
epoch [26/50] batch [220/244] time 0.429 (0.362) data 0.000 (0.001) loss 1.9078 (1.9400) teacher_loss 0.9066 (0.9178) loss_zs_kd 0.0409 (0.0489) loss_oracle 0.6239 (0.6725) kd_loss 0.6688 (0.6615) acc 78.1250 (76.4773) gate/entropy 1.0893 (1.0925) gate/usage_max 0.3985 (0.3848) gate/usage_min 0.3004 (0.3021) gate/usage_std 0.0461 (0.0368) teacher/entropy 0.3645 (0.3833) teacher/usage_max 0.5944 (0.6223) teacher/usage_min 0.0511 (0.0451) teacher/usage_std 0.2223 (0.2397) nleep/row_max_mean 1200.8702 (1196.8062) nleep/row_max_std 14.0463 (14.0403) nleep/row_min_mean 1194.0631 (1190.0066) lr 1.0628e-03 eta 0:35:30
epoch [26/50] batch [240/244] time 0.497 (0.372) data 0.000 (0.001) loss 1.7878 (1.9420) teacher_loss 0.8622 (0.9196) loss_zs_kd 0.0422 (0.0490) loss_oracle 0.6168 (0.6736) kd_loss 0.5961 (0.6611) acc 78.1250 (76.4453) gate/entropy 1.0885 (1.0922) gate/usage_max 0.4013 (0.3861) gate/usage_min 0.2981 (0.3019) gate/usage_std 0.0481 (0.0377) teacher/entropy 0.4392 (0.3814) teacher/usage_max 0.5757 (0.6242) teacher/usage_min 0.0144 (0.0452) teacher/usage_std 0.2355 (0.2404) nleep/row_max_mean 1200.9380 (1196.9398) nleep/row_max_std 13.1268 (14.1012) nleep/row_min_mean 1193.3452 (1190.1150) lr 1.0628e-03 eta 0:36:19
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,809
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,989
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 89.1%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [27/50] batch [20/244] time 0.497 (0.530) data 0.000 (0.014) loss 1.9757 (1.8587) teacher_loss 0.9791 (0.8539) loss_zs_kd 0.0492 (0.0458) loss_oracle 0.6762 (0.6692) kd_loss 0.6340 (0.6474) acc 59.3750 (76.4062) gate/entropy 1.0876 (1.0880) gate/usage_max 0.4042 (0.4031) gate/usage_min 0.2959 (0.2967) gate/usage_std 0.0501 (0.0493) teacher/entropy 0.3730 (0.3642) teacher/usage_max 0.6639 (0.6516) teacher/usage_min 0.0579 (0.0414) teacher/usage_std 0.2504 (0.2525) nleep/row_max_mean 1196.4744 (1198.0838) nleep/row_max_std 10.2113 (13.9821) nleep/row_min_mean 1189.5159 (1191.1752) lr 1.0000e-03 eta 0:51:34
epoch [27/50] batch [40/244] time 0.513 (0.410) data 0.000 (0.007) loss 1.4467 (1.8808) teacher_loss 0.4984 (0.8686) loss_zs_kd 0.0441 (0.0485) loss_oracle 0.6596 (0.6678) kd_loss 0.5964 (0.6541) acc 87.5000 (77.9688) gate/entropy 1.0869 (1.0876) gate/usage_max 0.4064 (0.4042) gate/usage_min 0.2941 (0.2957) gate/usage_std 0.0517 (0.0502) teacher/entropy 0.3995 (0.3594) teacher/usage_max 0.6892 (0.6399) teacher/usage_min 0.0559 (0.0413) teacher/usage_std 0.2645 (0.2477) nleep/row_max_mean 1198.9590 (1198.5623) nleep/row_max_std 12.2325 (14.1667) nleep/row_min_mean 1191.8232 (1191.5902) lr 1.0000e-03 eta 0:39:45
epoch [27/50] batch [60/244] time 0.082 (0.370) data 0.001 (0.005) loss 2.1749 (1.9047) teacher_loss 1.1304 (0.8946) loss_zs_kd 0.0616 (0.0505) loss_oracle 0.6622 (0.6643) kd_loss 0.6826 (0.6528) acc 68.7500 (76.6667) gate/entropy 1.0862 (1.0872) gate/usage_max 0.4088 (0.4054) gate/usage_min 0.2917 (0.2947) gate/usage_std 0.0535 (0.0510) teacher/entropy 0.3193 (0.3558) teacher/usage_max 0.6582 (0.6510) teacher/usage_min 0.0381 (0.0430) teacher/usage_std 0.2541 (0.2519) nleep/row_max_mean 1203.4889 (1198.4674) nleep/row_max_std 17.2700 (14.5246) nleep/row_min_mean 1195.8867 (1191.4519) lr 1.0000e-03 eta 0:35:43
epoch [27/50] batch [80/244] time 0.503 (0.344) data 0.001 (0.004) loss 2.2177 (1.9222) teacher_loss 1.1820 (0.9109) loss_zs_kd 0.0547 (0.0512) loss_oracle 0.7062 (0.6721) kd_loss 0.6552 (0.6498) acc 68.7500 (75.8984) gate/entropy 1.0853 (1.0869) gate/usage_max 0.4113 (0.4066) gate/usage_min 0.2897 (0.2937) gate/usage_std 0.0553 (0.0519) teacher/entropy 0.3412 (0.3546) teacher/usage_max 0.6672 (0.6595) teacher/usage_min 0.0541 (0.0419) teacher/usage_std 0.2533 (0.2562) nleep/row_max_mean 1197.3535 (1198.3899) nleep/row_max_std 16.4896 (14.5150) nleep/row_min_mean 1189.6340 (1191.3596) lr 1.0000e-03 eta 0:33:07
epoch [27/50] batch [100/244] time 0.526 (0.376) data 0.000 (0.003) loss 1.8414 (1.9141) teacher_loss 0.7781 (0.8993) loss_zs_kd 0.0637 (0.0504) loss_oracle 0.7343 (0.6777) kd_loss 0.6643 (0.6507) acc 81.2500 (76.3750) gate/entropy 1.0844 (1.0865) gate/usage_max 0.4139 (0.4078) gate/usage_min 0.2878 (0.2927) gate/usage_std 0.0571 (0.0527) teacher/entropy 0.3222 (0.3506) teacher/usage_max 0.6857 (0.6638) teacher/usage_min 0.0401 (0.0410) teacher/usage_std 0.2669 (0.2583) nleep/row_max_mean 1198.1487 (1198.4503) nleep/row_max_std 12.7622 (14.4731) nleep/row_min_mean 1190.8582 (1191.3910) lr 1.0000e-03 eta 0:36:07
epoch [27/50] batch [120/244] time 0.480 (0.396) data 0.000 (0.003) loss 1.5369 (1.9149) teacher_loss 0.5586 (0.9022) loss_zs_kd 0.0530 (0.0511) loss_oracle 0.6632 (0.6760) kd_loss 0.6202 (0.6491) acc 87.5000 (76.4062) gate/entropy 1.0835 (1.0860) gate/usage_max 0.4164 (0.4091) gate/usage_min 0.2858 (0.2917) gate/usage_std 0.0589 (0.0536) teacher/entropy 0.3764 (0.3511) teacher/usage_max 0.6465 (0.6624) teacher/usage_min 0.0537 (0.0411) teacher/usage_std 0.2432 (0.2576) nleep/row_max_mean 1196.9297 (1198.4570) nleep/row_max_std 13.6969 (14.2522) nleep/row_min_mean 1190.6360 (1191.4269) lr 1.0000e-03 eta 0:37:51
epoch [27/50] batch [140/244] time 0.324 (0.408) data 0.000 (0.002) loss 1.6817 (1.8988) teacher_loss 0.7354 (0.8907) loss_zs_kd 0.0324 (0.0505) loss_oracle 0.6205 (0.6721) kd_loss 0.6198 (0.6468) acc 78.1250 (76.6518) gate/entropy 1.0826 (1.0856) gate/usage_max 0.4187 (0.4103) gate/usage_min 0.2838 (0.2907) gate/usage_std 0.0606 (0.0545) teacher/entropy 0.3555 (0.3506) teacher/usage_max 0.6986 (0.6659) teacher/usage_min 0.0358 (0.0406) teacher/usage_std 0.2748 (0.2592) nleep/row_max_mean 1199.1277 (1198.5374) nleep/row_max_std 12.7859 (14.1465) nleep/row_min_mean 1192.7355 (1191.4999) lr 1.0000e-03 eta 0:38:50
epoch [27/50] batch [160/244] time 0.092 (0.390) data 0.000 (0.002) loss 1.7500 (1.8877) teacher_loss 0.6751 (0.8875) loss_zs_kd 0.0473 (0.0504) loss_oracle 0.6615 (0.6631) kd_loss 0.7204 (0.6435) acc 84.3750 (76.7188) gate/entropy 1.0819 (1.0852) gate/usage_max 0.4207 (0.4115) gate/usage_min 0.2824 (0.2897) gate/usage_std 0.0620 (0.0554) teacher/entropy 0.2546 (0.3519) teacher/usage_max 0.6877 (0.6673) teacher/usage_min 0.0161 (0.0409) teacher/usage_std 0.2754 (0.2597) nleep/row_max_mean 1197.5476 (1198.4339) nleep/row_max_std 10.3620 (14.0027) nleep/row_min_mean 1189.8528 (1191.4167) lr 1.0000e-03 eta 0:37:04
epoch [27/50] batch [180/244] time 0.083 (0.391) data 0.000 (0.002) loss 1.7014 (1.8829) teacher_loss 0.7662 (0.8865) loss_zs_kd 0.0330 (0.0500) loss_oracle 0.5515 (0.6571) kd_loss 0.6430 (0.6428) acc 78.1250 (76.8750) gate/entropy 1.0807 (1.0847) gate/usage_max 0.4235 (0.4127) gate/usage_min 0.2796 (0.2887) gate/usage_std 0.0641 (0.0563) teacher/entropy 0.3785 (0.3516) teacher/usage_max 0.5469 (0.6661) teacher/usage_min 0.0284 (0.0413) teacher/usage_std 0.2213 (0.2592) nleep/row_max_mean 1198.2748 (1198.3783) nleep/row_max_std 14.9213 (13.9478) nleep/row_min_mean 1190.8766 (1191.3709) lr 1.0000e-03 eta 0:36:57
epoch [27/50] batch [200/244] time 0.101 (0.366) data 0.000 (0.002) loss 2.1758 (1.8837) teacher_loss 1.1868 (0.8916) loss_zs_kd 0.0396 (0.0501) loss_oracle 0.6529 (0.6531) kd_loss 0.6427 (0.6406) acc 68.7500 (76.7969) gate/entropy 1.0801 (1.0843) gate/usage_max 0.4252 (0.4138) gate/usage_min 0.2785 (0.2878) gate/usage_std 0.0653 (0.0571) teacher/entropy 0.3195 (0.3528) teacher/usage_max 0.7046 (0.6648) teacher/usage_min 0.0083 (0.0421) teacher/usage_std 0.2861 (0.2584) nleep/row_max_mean 1199.1815 (1198.3390) nleep/row_max_std 12.1037 (13.9140) nleep/row_min_mean 1192.0444 (1191.3599) lr 1.0000e-03 eta 0:34:32
epoch [27/50] batch [220/244] time 0.508 (0.364) data 0.000 (0.001) loss 1.8547 (1.8786) teacher_loss 0.8723 (0.8864) loss_zs_kd 0.0564 (0.0505) loss_oracle 0.6829 (0.6541) kd_loss 0.6128 (0.6398) acc 81.2500 (77.0455) gate/entropy 1.0791 (1.0839) gate/usage_max 0.4275 (0.4150) gate/usage_min 0.2766 (0.2868) gate/usage_std 0.0671 (0.0579) teacher/entropy 0.3472 (0.3521) teacher/usage_max 0.7040 (0.6645) teacher/usage_min 0.0250 (0.0414) teacher/usage_std 0.2807 (0.2584) nleep/row_max_mean 1195.9834 (1198.3531) nleep/row_max_std 12.8775 (13.8917) nleep/row_min_mean 1188.6720 (1191.3601) lr 1.0000e-03 eta 0:34:10
epoch [27/50] batch [240/244] time 0.341 (0.374) data 0.000 (0.001) loss 1.9698 (1.8815) teacher_loss 1.0098 (0.8920) loss_zs_kd 0.0327 (0.0501) loss_oracle 0.6051 (0.6511) kd_loss 0.6411 (0.6389) acc 81.2500 (77.0833) gate/entropy 1.0781 (1.0834) gate/usage_max 0.4298 (0.4161) gate/usage_min 0.2745 (0.2859) gate/usage_std 0.0687 (0.0588) teacher/entropy 0.3374 (0.3512) teacher/usage_max 0.6500 (0.6653) teacher/usage_min 0.0453 (0.0411) teacher/usage_std 0.2477 (0.2589) nleep/row_max_mean 1197.7717 (1198.3095) nleep/row_max_std 15.8731 (13.8692) nleep/row_min_mean 1190.5811 (1191.3281) lr 1.0000e-03 eta 0:35:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,810
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,999
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 89.4%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [28/50] batch [20/244] time 0.080 (0.508) data 0.000 (0.017) loss 2.1395 (1.8406) teacher_loss 1.1248 (0.8934) loss_zs_kd 0.0680 (0.0463) loss_oracle 0.6162 (0.6089) kd_loss 0.6726 (0.6195) acc 71.8750 (76.5625) gate/entropy 1.0771 (1.0775) gate/usage_max 0.4321 (0.4311) gate/usage_min 0.2727 (0.2735) gate/usage_std 0.0705 (0.0697) teacher/entropy 0.3056 (0.3534) teacher/usage_max 0.6431 (0.6612) teacher/usage_min 0.0410 (0.0447) teacher/usage_std 0.2461 (0.2564) nleep/row_max_mean 1200.2727 (1199.0851) nleep/row_max_std 14.4332 (13.7457) nleep/row_min_mean 1193.6833 (1192.2354) lr 9.3721e-04 eta 0:47:18
epoch [28/50] batch [40/244] time 0.482 (0.401) data 0.000 (0.009) loss 1.9700 (1.8539) teacher_loss 1.0462 (0.9028) loss_zs_kd 0.0448 (0.0490) loss_oracle 0.6139 (0.6097) kd_loss 0.5944 (0.6218) acc 75.0000 (75.9375) gate/entropy 1.0762 (1.0771) gate/usage_max 0.4341 (0.4321) gate/usage_min 0.2708 (0.2726) gate/usage_std 0.0719 (0.0705) teacher/entropy 0.3560 (0.3504) teacher/usage_max 0.7075 (0.6592) teacher/usage_min 0.0357 (0.0430) teacher/usage_std 0.2795 (0.2562) nleep/row_max_mean 1200.2562 (1199.2397) nleep/row_max_std 13.8811 (13.9765) nleep/row_min_mean 1193.0979 (1192.3279) lr 9.3721e-04 eta 0:37:15
epoch [28/50] batch [60/244] time 0.093 (0.336) data 0.000 (0.006) loss 1.9662 (1.8378) teacher_loss 1.0142 (0.8935) loss_zs_kd 0.0570 (0.0482) loss_oracle 0.6226 (0.6054) kd_loss 0.6122 (0.6175) acc 75.0000 (76.2500) gate/entropy 1.0754 (1.0766) gate/usage_max 0.4357 (0.4331) gate/usage_min 0.2696 (0.2718) gate/usage_std 0.0731 (0.0712) teacher/entropy 0.3344 (0.3570) teacher/usage_max 0.7064 (0.6508) teacher/usage_min 0.0154 (0.0447) teacher/usage_std 0.2848 (0.2518) nleep/row_max_mean 1196.9385 (1199.0333) nleep/row_max_std 15.2100 (14.2105) nleep/row_min_mean 1190.0490 (1192.2078) lr 9.3721e-04 eta 0:31:06
epoch [28/50] batch [80/244] time 0.497 (0.309) data 0.000 (0.004) loss 2.1804 (1.8729) teacher_loss 1.1321 (0.9243) loss_zs_kd 0.0654 (0.0495) loss_oracle 0.5860 (0.6037) kd_loss 0.7227 (0.6220) acc 75.0000 (75.7031) gate/entropy 1.0745 (1.0762) gate/usage_max 0.4378 (0.4340) gate/usage_min 0.2678 (0.2710) gate/usage_std 0.0746 (0.0718) teacher/entropy 0.2791 (0.3504) teacher/usage_max 0.5779 (0.6535) teacher/usage_min 0.0902 (0.0456) teacher/usage_std 0.1991 (0.2525) nleep/row_max_mean 1201.9558 (1198.9050) nleep/row_max_std 17.5594 (14.4995) nleep/row_min_mean 1194.5217 (1192.0885) lr 9.3721e-04 eta 0:28:30
epoch [28/50] batch [100/244] time 0.473 (0.344) data 0.000 (0.004) loss 1.9758 (1.8683) teacher_loss 1.1424 (0.9233) loss_zs_kd 0.0678 (0.0496) loss_oracle 0.6058 (0.6033) kd_loss 0.4966 (0.6186) acc 75.0000 (75.8125) gate/entropy 1.0736 (1.0758) gate/usage_max 0.4396 (0.4349) gate/usage_min 0.2662 (0.2702) gate/usage_std 0.0760 (0.0725) teacher/entropy 0.4823 (0.3527) teacher/usage_max 0.6219 (0.6533) teacher/usage_min 0.0514 (0.0445) teacher/usage_std 0.2330 (0.2527) nleep/row_max_mean 1195.4380 (1198.7473) nleep/row_max_std 13.2745 (14.6123) nleep/row_min_mean 1190.0985 (1191.9927) lr 9.3721e-04 eta 0:31:35
epoch [28/50] batch [120/244] time 0.488 (0.372) data 0.000 (0.003) loss 1.8359 (1.8703) teacher_loss 0.8710 (0.9235) loss_zs_kd 0.0453 (0.0500) loss_oracle 0.6075 (0.6039) kd_loss 0.6385 (0.6199) acc 81.2500 (76.0417) gate/entropy 1.0727 (1.0754) gate/usage_max 0.4414 (0.4358) gate/usage_min 0.2648 (0.2695) gate/usage_std 0.0773 (0.0732) teacher/entropy 0.3416 (0.3517) teacher/usage_max 0.6046 (0.6502) teacher/usage_min 0.0167 (0.0468) teacher/usage_std 0.2421 (0.2504) nleep/row_max_mean 1203.2205 (1198.5440) nleep/row_max_std 16.0018 (14.7751) nleep/row_min_mean 1196.5295 (1191.7959) lr 9.3721e-04 eta 0:34:02
epoch [28/50] batch [140/244] time 0.471 (0.388) data 0.000 (0.003) loss 1.8652 (1.8617) teacher_loss 0.8915 (0.9144) loss_zs_kd 0.0597 (0.0497) loss_oracle 0.5827 (0.6047) kd_loss 0.6524 (0.6201) acc 78.1250 (76.3170) gate/entropy 1.0718 (1.0749) gate/usage_max 0.4431 (0.4367) gate/usage_min 0.2630 (0.2687) gate/usage_std 0.0787 (0.0739) teacher/entropy 0.3354 (0.3513) teacher/usage_max 0.5852 (0.6480) teacher/usage_min 0.0366 (0.0466) teacher/usage_std 0.2262 (0.2495) nleep/row_max_mean 1197.3718 (1198.3455) nleep/row_max_std 12.2080 (14.8234) nleep/row_min_mean 1190.9056 (1191.6074) lr 9.3721e-04 eta 0:35:24
epoch [28/50] batch [160/244] time 0.085 (0.375) data 0.000 (0.002) loss 2.0701 (1.8565) teacher_loss 1.1283 (0.9090) loss_zs_kd 0.0694 (0.0499) loss_oracle 0.5844 (0.6040) kd_loss 0.6148 (0.6206) acc 65.6250 (76.4453) gate/entropy 1.0711 (1.0745) gate/usage_max 0.4446 (0.4376) gate/usage_min 0.2620 (0.2680) gate/usage_std 0.0797 (0.0745) teacher/entropy 0.3266 (0.3497) teacher/usage_max 0.6911 (0.6482) teacher/usage_min 0.0243 (0.0469) teacher/usage_std 0.2744 (0.2493) nleep/row_max_mean 1192.4814 (1198.3179) nleep/row_max_std 12.1045 (14.9541) nleep/row_min_mean 1186.5432 (1191.5590) lr 9.3721e-04 eta 0:34:02
epoch [28/50] batch [180/244] time 0.084 (0.377) data 0.000 (0.002) loss 1.6560 (1.8481) teacher_loss 0.7509 (0.9021) loss_zs_kd 0.0401 (0.0500) loss_oracle 0.6208 (0.6020) kd_loss 0.5747 (0.6201) acc 81.2500 (76.6667) gate/entropy 1.0702 (1.0741) gate/usage_max 0.4462 (0.4384) gate/usage_min 0.2605 (0.2672) gate/usage_std 0.0809 (0.0751) teacher/entropy 0.3587 (0.3491) teacher/usage_max 0.7028 (0.6484) teacher/usage_min 0.0171 (0.0466) teacher/usage_std 0.2825 (0.2495) nleep/row_max_mean 1199.6023 (1198.3393) nleep/row_max_std 16.6688 (15.1517) nleep/row_min_mean 1193.4080 (1191.5767) lr 9.3721e-04 eta 0:34:05
epoch [28/50] batch [200/244] time 0.081 (0.353) data 0.000 (0.002) loss 1.7821 (1.8368) teacher_loss 0.9030 (0.8933) loss_zs_kd 0.0896 (0.0504) loss_oracle 0.5656 (0.6011) kd_loss 0.5515 (0.6178) acc 75.0000 (76.7031) gate/entropy 1.0694 (1.0737) gate/usage_max 0.4479 (0.4393) gate/usage_min 0.2592 (0.2665) gate/usage_std 0.0822 (0.0758) teacher/entropy 0.4102 (0.3511) teacher/usage_max 0.6366 (0.6468) teacher/usage_min 0.0379 (0.0469) teacher/usage_std 0.2445 (0.2489) nleep/row_max_mean 1191.4026 (1198.0990) nleep/row_max_std 16.8883 (15.2406) nleep/row_min_mean 1186.0742 (1191.3812) lr 9.3721e-04 eta 0:31:48
epoch [28/50] batch [220/244] time 0.475 (0.347) data 0.000 (0.002) loss 1.7021 (1.8303) teacher_loss 0.7466 (0.8881) loss_zs_kd 0.0540 (0.0502) loss_oracle 0.6341 (0.6031) kd_loss 0.6114 (0.6156) acc 78.1250 (76.8040) gate/entropy 1.0686 (1.0732) gate/usage_max 0.4494 (0.4401) gate/usage_min 0.2580 (0.2658) gate/usage_std 0.0833 (0.0764) teacher/entropy 0.3715 (0.3527) teacher/usage_max 0.5893 (0.6462) teacher/usage_min 0.0553 (0.0480) teacher/usage_std 0.2186 (0.2482) nleep/row_max_mean 1202.9313 (1198.0927) nleep/row_max_std 19.4198 (15.3293) nleep/row_min_mean 1196.0795 (1191.3906) lr 9.3721e-04 eta 0:31:11
epoch [28/50] batch [240/244] time 0.512 (0.359) data 0.000 (0.002) loss 1.7481 (1.8259) teacher_loss 0.7821 (0.8855) loss_zs_kd 0.0336 (0.0501) loss_oracle 0.5872 (0.6009) kd_loss 0.6556 (0.6149) acc 75.0000 (76.9792) gate/entropy 1.0678 (1.0728) gate/usage_max 0.4508 (0.4410) gate/usage_min 0.2569 (0.2651) gate/usage_std 0.0843 (0.0770) teacher/entropy 0.3131 (0.3529) teacher/usage_max 0.6064 (0.6451) teacher/usage_min 0.0151 (0.0479) teacher/usage_std 0.2435 (0.2477) nleep/row_max_mean 1200.1284 (1198.0066) nleep/row_max_std 16.1094 (15.2974) nleep/row_min_mean 1193.2427 (1191.3200) lr 9.3721e-04 eta 0:32:07
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,805
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,995
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.2%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [29/50] batch [20/244] time 0.526 (0.521) data 0.000 (0.017) loss 1.6616 (1.7855) teacher_loss 0.8019 (0.8695) loss_zs_kd 0.0511 (0.0523) loss_oracle 0.6203 (0.5865) kd_loss 0.5239 (0.5966) acc 81.2500 (78.1250) gate/entropy 1.0667 (1.0671) gate/usage_max 0.4529 (0.4521) gate/usage_min 0.2549 (0.2557) gate/usage_std 0.0859 (0.0853) teacher/entropy 0.4041 (0.3535) teacher/usage_max 0.7153 (0.6559) teacher/usage_min 0.0820 (0.0471) teacher/usage_std 0.2745 (0.2534) nleep/row_max_mean 1197.3286 (1197.6051) nleep/row_max_std 14.3298 (14.8072) nleep/row_min_mean 1191.8605 (1191.1278) lr 8.7467e-04 eta 0:46:26
epoch [29/50] batch [40/244] time 0.473 (0.385) data 0.000 (0.009) loss 2.0634 (1.8123) teacher_loss 1.1439 (0.8951) loss_zs_kd 0.0439 (0.0486) loss_oracle 0.6425 (0.5953) kd_loss 0.5763 (0.5952) acc 65.6250 (76.6406) gate/entropy 1.0659 (1.0667) gate/usage_max 0.4542 (0.4529) gate/usage_min 0.2541 (0.2552) gate/usage_std 0.0869 (0.0858) teacher/entropy 0.3823 (0.3505) teacher/usage_max 0.6399 (0.6639) teacher/usage_min 0.0680 (0.0456) teacher/usage_std 0.2353 (0.2579) nleep/row_max_mean 1199.7607 (1198.3288) nleep/row_max_std 15.4853 (15.2570) nleep/row_min_mean 1193.1930 (1191.6886) lr 8.7467e-04 eta 0:34:11
epoch [29/50] batch [60/244] time 0.103 (0.339) data 0.000 (0.006) loss 2.1797 (1.8236) teacher_loss 1.2024 (0.9117) loss_zs_kd 0.0516 (0.0477) loss_oracle 0.6014 (0.6002) kd_loss 0.6509 (0.5880) acc 65.6250 (75.8333) gate/entropy 1.0650 (1.0663) gate/usage_max 0.4560 (0.4537) gate/usage_min 0.2530 (0.2546) gate/usage_std 0.0881 (0.0864) teacher/entropy 0.2701 (0.3530) teacher/usage_max 0.7179 (0.6735) teacher/usage_min 0.0641 (0.0484) teacher/usage_std 0.2791 (0.2615) nleep/row_max_mean 1198.7086 (1198.1263) nleep/row_max_std 16.3163 (15.2782) nleep/row_min_mean 1192.0028 (1191.5387) lr 8.7467e-04 eta 0:29:59
epoch [29/50] batch [80/244] time 0.354 (0.302) data 0.000 (0.004) loss 1.2900 (1.8274) teacher_loss 0.3366 (0.9135) loss_zs_kd 0.0255 (0.0487) loss_oracle 0.6162 (0.5971) kd_loss 0.6325 (0.5911) acc 96.8750 (75.8594) gate/entropy 1.0642 (1.0658) gate/usage_max 0.4576 (0.4545) gate/usage_min 0.2521 (0.2540) gate/usage_std 0.0892 (0.0870) teacher/entropy 0.2789 (0.3474) teacher/usage_max 0.7289 (0.6774) teacher/usage_min 0.0434 (0.0484) teacher/usage_std 0.2896 (0.2633) nleep/row_max_mean 1198.3768 (1198.4199) nleep/row_max_std 12.8609 (15.1541) nleep/row_min_mean 1191.7864 (1191.8001) lr 8.7467e-04 eta 0:26:35
epoch [29/50] batch [100/244] time 0.495 (0.323) data 0.000 (0.004) loss 1.8992 (1.8389) teacher_loss 0.9791 (0.9306) loss_zs_kd 0.0583 (0.0499) loss_oracle 0.5314 (0.5901) kd_loss 0.6252 (0.5883) acc 71.8750 (75.6250) gate/entropy 1.0632 (1.0654) gate/usage_max 0.4592 (0.4553) gate/usage_min 0.2508 (0.2534) gate/usage_std 0.0904 (0.0876) teacher/entropy 0.3251 (0.3476) teacher/usage_max 0.6477 (0.6818) teacher/usage_min 0.0692 (0.0503) teacher/usage_std 0.2388 (0.2649) nleep/row_max_mean 1199.7511 (1198.1940) nleep/row_max_std 18.0484 (15.1595) nleep/row_min_mean 1192.8730 (1191.5833) lr 8.7467e-04 eta 0:28:24
epoch [29/50] batch [120/244] time 0.522 (0.352) data 0.000 (0.003) loss 1.9789 (1.8380) teacher_loss 1.0432 (0.9295) loss_zs_kd 0.0726 (0.0510) loss_oracle 0.5981 (0.5863) kd_loss 0.6003 (0.5899) acc 75.0000 (75.6510) gate/entropy 1.0622 (1.0649) gate/usage_max 0.4610 (0.4561) gate/usage_min 0.2496 (0.2529) gate/usage_std 0.0917 (0.0882) teacher/entropy 0.3009 (0.3439) teacher/usage_max 0.7480 (0.6846) teacher/usage_min 0.0638 (0.0504) teacher/usage_std 0.2976 (0.2664) nleep/row_max_mean 1194.6132 (1198.1566) nleep/row_max_std 12.3846 (15.2663) nleep/row_min_mean 1187.9167 (1191.4957) lr 8.7467e-04 eta 0:30:47
epoch [29/50] batch [140/244] time 0.546 (0.373) data 0.000 (0.003) loss 2.5691 (1.8368) teacher_loss 1.6402 (0.9306) loss_zs_kd 0.0663 (0.0516) loss_oracle 0.6142 (0.5836) kd_loss 0.5886 (0.5886) acc 53.1250 (75.6027) gate/entropy 1.0613 (1.0645) gate/usage_max 0.4626 (0.4569) gate/usage_min 0.2485 (0.2523) gate/usage_std 0.0929 (0.0888) teacher/entropy 0.2986 (0.3429) teacher/usage_max 0.7658 (0.6875) teacher/usage_min 0.0406 (0.0505) teacher/usage_std 0.3121 (0.2677) nleep/row_max_mean 1195.2542 (1198.1226) nleep/row_max_std 13.9790 (15.1420) nleep/row_min_mean 1188.2535 (1191.4586) lr 8.7467e-04 eta 0:32:30
epoch [29/50] batch [160/244] time 0.084 (0.379) data 0.000 (0.002) loss 1.6502 (1.8272) teacher_loss 0.7270 (0.9246) loss_zs_kd 0.0628 (0.0517) loss_oracle 0.5796 (0.5807) kd_loss 0.6020 (0.5864) acc 78.1250 (76.0352) gate/entropy 1.0605 (1.0640) gate/usage_max 0.4640 (0.4577) gate/usage_min 0.2475 (0.2518) gate/usage_std 0.0939 (0.0893) teacher/entropy 0.3217 (0.3448) teacher/usage_max 0.6941 (0.6863) teacher/usage_min 0.0667 (0.0502) teacher/usage_std 0.2646 (0.2672) nleep/row_max_mean 1198.0614 (1198.0150) nleep/row_max_std 14.8619 (15.1344) nleep/row_min_mean 1190.7732 (1191.3478) lr 8.7467e-04 eta 0:32:53
epoch [29/50] batch [180/244] time 0.497 (0.380) data 0.000 (0.002) loss 2.6790 (1.8325) teacher_loss 1.7861 (0.9340) loss_zs_kd 0.0520 (0.0520) loss_oracle 0.5357 (0.5754) kd_loss 0.5991 (0.5848) acc 59.3750 (75.8333) gate/entropy 1.0596 (1.0636) gate/usage_max 0.4655 (0.4585) gate/usage_min 0.2466 (0.2513) gate/usage_std 0.0950 (0.0899) teacher/entropy 0.3183 (0.3449) teacher/usage_max 0.6955 (0.6878) teacher/usage_min 0.0412 (0.0500) teacher/usage_std 0.2717 (0.2681) nleep/row_max_mean 1194.6677 (1197.8881) nleep/row_max_std 14.2862 (15.0787) nleep/row_min_mean 1187.9773 (1191.2214) lr 8.7467e-04 eta 0:32:49
epoch [29/50] batch [200/244] time 0.152 (0.357) data 0.000 (0.002) loss 1.8982 (1.8243) teacher_loss 0.9690 (0.9269) loss_zs_kd 0.0631 (0.0517) loss_oracle 0.5559 (0.5730) kd_loss 0.6196 (0.5851) acc 75.0000 (75.9844) gate/entropy 1.0590 (1.0632) gate/usage_max 0.4666 (0.4592) gate/usage_min 0.2461 (0.2508) gate/usage_std 0.0957 (0.0905) teacher/entropy 0.2831 (0.3420) teacher/usage_max 0.7341 (0.6913) teacher/usage_min 0.0741 (0.0493) teacher/usage_std 0.2874 (0.2702) nleep/row_max_mean 1196.0221 (1197.9111) nleep/row_max_std 13.0454 (15.0819) nleep/row_min_mean 1188.7057 (1191.2244) lr 8.7467e-04 eta 0:30:44
epoch [29/50] batch [220/244] time 0.539 (0.351) data 0.000 (0.002) loss 1.3931 (1.8199) teacher_loss 0.5854 (0.9237) loss_zs_kd 0.0303 (0.0515) loss_oracle 0.5459 (0.5710) kd_loss 0.5196 (0.5850) acc 84.3750 (76.0938) gate/entropy 1.0581 (1.0627) gate/usage_max 0.4682 (0.4600) gate/usage_min 0.2449 (0.2503) gate/usage_std 0.0969 (0.0910) teacher/entropy 0.3778 (0.3413) teacher/usage_max 0.7298 (0.6914) teacher/usage_min 0.0405 (0.0499) teacher/usage_std 0.2908 (0.2699) nleep/row_max_mean 1193.3525 (1197.7661) nleep/row_max_std 12.8283 (15.0425) nleep/row_min_mean 1187.2146 (1191.0729) lr 8.7467e-04 eta 0:30:05
epoch [29/50] batch [240/244] time 0.437 (0.360) data 0.000 (0.002) loss 1.5957 (1.8103) teacher_loss 0.6525 (0.9130) loss_zs_kd 0.0348 (0.0514) loss_oracle 0.6469 (0.5724) kd_loss 0.6024 (0.5854) acc 78.1250 (76.3411) gate/entropy 1.0573 (1.0623) gate/usage_max 0.4696 (0.4608) gate/usage_min 0.2443 (0.2498) gate/usage_std 0.0979 (0.0916) teacher/entropy 0.2839 (0.3397) teacher/usage_max 0.7435 (0.6920) teacher/usage_min 0.0219 (0.0492) teacher/usage_std 0.3027 (0.2704) nleep/row_max_mean 1195.6492 (1197.7317) nleep/row_max_std 13.8325 (14.9816) nleep/row_min_mean 1188.0764 (1191.0187) lr 8.7467e-04 eta 0:30:44
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,799
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,009
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.8%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [30/50] batch [20/244] time 0.496 (0.489) data 0.000 (0.010) loss 1.5360 (1.7531) teacher_loss 0.6591 (0.8498) loss_zs_kd 0.0470 (0.0547) loss_oracle 0.5608 (0.5882) kd_loss 0.5730 (0.5819) acc 78.1250 (77.1875) gate/entropy 1.0560 (1.0565) gate/usage_max 0.4716 (0.4709) gate/usage_min 0.2428 (0.2432) gate/usage_std 0.0993 (0.0988) teacher/entropy 0.3360 (0.3248) teacher/usage_max 0.7085 (0.7075) teacher/usage_min 0.0682 (0.0474) teacher/usage_std 0.2727 (0.2793) nleep/row_max_mean 1201.6284 (1197.9283) nleep/row_max_std 14.9073 (14.9648) nleep/row_min_mean 1194.4373 (1191.0113) lr 8.1262e-04 eta 0:41:34
epoch [30/50] batch [40/244] time 0.484 (0.394) data 0.000 (0.005) loss 1.5197 (1.7565) teacher_loss 0.5966 (0.8576) loss_zs_kd 0.0361 (0.0536) loss_oracle 0.6519 (0.5771) kd_loss 0.5791 (0.5835) acc 87.5000 (77.0312) gate/entropy 1.0553 (1.0560) gate/usage_max 0.4729 (0.4716) gate/usage_min 0.2421 (0.2428) gate/usage_std 0.1002 (0.0993) teacher/entropy 0.2725 (0.3207) teacher/usage_max 0.8112 (0.7111) teacher/usage_min 0.0425 (0.0479) teacher/usage_std 0.3405 (0.2803) nleep/row_max_mean 1197.8326 (1197.5717) nleep/row_max_std 12.3198 (14.8509) nleep/row_min_mean 1190.4297 (1190.6879) lr 8.1262e-04 eta 0:33:22
epoch [30/50] batch [60/244] time 0.102 (0.351) data 0.000 (0.004) loss 1.6179 (1.7822) teacher_loss 0.7229 (0.8846) loss_zs_kd 0.0411 (0.0534) loss_oracle 0.6069 (0.5794) kd_loss 0.5710 (0.5812) acc 78.1250 (75.9896) gate/entropy 1.0545 (1.0556) gate/usage_max 0.4743 (0.4723) gate/usage_min 0.2415 (0.2424) gate/usage_std 0.1012 (0.0998) teacher/entropy 0.3632 (0.3224) teacher/usage_max 0.6552 (0.7107) teacher/usage_min 0.0742 (0.0470) teacher/usage_std 0.2413 (0.2802) nleep/row_max_mean 1198.0515 (1197.4140) nleep/row_max_std 13.2571 (14.9298) nleep/row_min_mean 1191.1891 (1190.5199) lr 8.1262e-04 eta 0:29:35
epoch [30/50] batch [80/244] time 0.082 (0.310) data 0.000 (0.003) loss 1.6199 (1.7909) teacher_loss 0.6351 (0.8962) loss_zs_kd 0.0430 (0.0524) loss_oracle 0.6367 (0.5797) kd_loss 0.6450 (0.5787) acc 75.0000 (75.7031) gate/entropy 1.0538 (1.0552) gate/usage_max 0.4754 (0.4730) gate/usage_min 0.2408 (0.2420) gate/usage_std 0.1020 (0.1003) teacher/entropy 0.1852 (0.3244) teacher/usage_max 0.8342 (0.7100) teacher/usage_min 0.0067 (0.0467) teacher/usage_std 0.3596 (0.2802) nleep/row_max_mean 1203.6240 (1197.5076) nleep/row_max_std 15.0261 (15.1032) nleep/row_min_mean 1195.4508 (1190.6332) lr 8.1262e-04 eta 0:26:04
epoch [30/50] batch [100/244] time 0.521 (0.334) data 0.000 (0.002) loss 1.4439 (1.7996) teacher_loss 0.5784 (0.9053) loss_zs_kd 0.0395 (0.0525) loss_oracle 0.5468 (0.5756) kd_loss 0.5723 (0.5803) acc 87.5000 (75.5938) gate/entropy 1.0529 (1.0548) gate/usage_max 0.4769 (0.4737) gate/usage_min 0.2399 (0.2416) gate/usage_std 0.1030 (0.1008) teacher/entropy 0.3446 (0.3222) teacher/usage_max 0.6815 (0.7103) teacher/usage_min 0.0640 (0.0473) teacher/usage_std 0.2582 (0.2801) nleep/row_max_mean 1198.3169 (1197.2019) nleep/row_max_std 16.4505 (15.0404) nleep/row_min_mean 1191.4272 (1190.3574) lr 8.1262e-04 eta 0:27:59
epoch [30/50] batch [120/244] time 0.473 (0.358) data 0.000 (0.002) loss 1.6820 (1.7955) teacher_loss 0.7819 (0.8967) loss_zs_kd 0.0531 (0.0522) loss_oracle 0.5456 (0.5769) kd_loss 0.6007 (0.5842) acc 78.1250 (75.9375) gate/entropy 1.0522 (1.0544) gate/usage_max 0.4781 (0.4744) gate/usage_min 0.2393 (0.2412) gate/usage_std 0.1039 (0.1013) teacher/entropy 0.3121 (0.3181) teacher/usage_max 0.6805 (0.7091) teacher/usage_min 0.0434 (0.0468) teacher/usage_std 0.2632 (0.2796) nleep/row_max_mean 1197.6626 (1197.1682) nleep/row_max_std 15.4610 (15.0298) nleep/row_min_mean 1191.0203 (1190.2990) lr 8.1262e-04 eta 0:29:50
epoch [30/50] batch [140/244] time 0.472 (0.376) data 0.000 (0.002) loss 1.4808 (1.7797) teacher_loss 0.4843 (0.8820) loss_zs_kd 0.0610 (0.0515) loss_oracle 0.6311 (0.5783) kd_loss 0.6505 (0.5829) acc 87.5000 (76.4062) gate/entropy 1.0514 (1.0540) gate/usage_max 0.4793 (0.4750) gate/usage_min 0.2386 (0.2408) gate/usage_std 0.1048 (0.1017) teacher/entropy 0.2746 (0.3179) teacher/usage_max 0.6565 (0.7103) teacher/usage_min 0.0463 (0.0455) teacher/usage_std 0.2504 (0.2808) nleep/row_max_mean 1201.3555 (1197.1834) nleep/row_max_std 17.7390 (14.9426) nleep/row_min_mean 1193.3749 (1190.3253) lr 8.1262e-04 eta 0:31:13
epoch [30/50] batch [160/244] time 0.087 (0.383) data 0.000 (0.001) loss 1.5288 (1.7822) teacher_loss 0.6101 (0.8832) loss_zs_kd 0.0582 (0.0516) loss_oracle 0.6234 (0.5797) kd_loss 0.5779 (0.5833) acc 84.3750 (76.4062) gate/entropy 1.0503 (1.0535) gate/usage_max 0.4809 (0.4757) gate/usage_min 0.2375 (0.2404) gate/usage_std 0.1059 (0.1022) teacher/entropy 0.3024 (0.3180) teacher/usage_max 0.7596 (0.7085) teacher/usage_min 0.1149 (0.0471) teacher/usage_std 0.3015 (0.2796) nleep/row_max_mean 1195.7748 (1197.2578) nleep/row_max_std 14.1993 (14.8026) nleep/row_min_mean 1189.4431 (1190.4017) lr 8.1262e-04 eta 0:31:40
epoch [30/50] batch [180/244] time 0.489 (0.382) data 0.000 (0.001) loss 1.8140 (1.7845) teacher_loss 0.8021 (0.8827) loss_zs_kd 0.0678 (0.0515) loss_oracle 0.6370 (0.5815) kd_loss 0.6595 (0.5853) acc 75.0000 (76.4062) gate/entropy 1.0497 (1.0531) gate/usage_max 0.4820 (0.4764) gate/usage_min 0.2372 (0.2401) gate/usage_std 0.1066 (0.1027) teacher/entropy 0.2174 (0.3133) teacher/usage_max 0.7308 (0.7120) teacher/usage_min 0.0108 (0.0460) teacher/usage_std 0.2987 (0.2818) nleep/row_max_mean 1197.7217 (1197.2137) nleep/row_max_std 14.8842 (14.6755) nleep/row_min_mean 1190.3499 (1190.3531) lr 8.1262e-04 eta 0:31:28
epoch [30/50] batch [200/244] time 0.455 (0.359) data 0.000 (0.001) loss 1.6245 (1.7802) teacher_loss 0.7672 (0.8784) loss_zs_kd 0.0505 (0.0516) loss_oracle 0.5216 (0.5791) kd_loss 0.5711 (0.5864) acc 87.5000 (76.6094) gate/entropy 1.0484 (1.0527) gate/usage_max 0.4840 (0.4770) gate/usage_min 0.2358 (0.2397) gate/usage_std 0.1081 (0.1032) teacher/entropy 0.3708 (0.3129) teacher/usage_max 0.6208 (0.7096) teacher/usage_min 0.0523 (0.0463) teacher/usage_std 0.2321 (0.2804) nleep/row_max_mean 1198.9342 (1197.1869) nleep/row_max_std 16.9753 (14.7280) nleep/row_min_mean 1192.2776 (1190.3263) lr 8.1262e-04 eta 0:29:25
epoch [30/50] batch [220/244] time 0.474 (0.344) data 0.000 (0.001) loss 1.9111 (1.7845) teacher_loss 0.9845 (0.8829) loss_zs_kd 0.0576 (0.0522) loss_oracle 0.5724 (0.5791) kd_loss 0.6115 (0.5859) acc 75.0000 (76.4489) gate/entropy 1.0480 (1.0523) gate/usage_max 0.4847 (0.4777) gate/usage_min 0.2355 (0.2393) gate/usage_std 0.1085 (0.1036) teacher/entropy 0.2972 (0.3126) teacher/usage_max 0.6897 (0.7098) teacher/usage_min 0.0798 (0.0461) teacher/usage_std 0.2594 (0.2806) nleep/row_max_mean 1197.5405 (1197.2505) nleep/row_max_std 11.7994 (14.6318) nleep/row_min_mean 1190.9175 (1190.3886) lr 8.1262e-04 eta 0:28:05
epoch [30/50] batch [240/244] time 0.472 (0.355) data 0.000 (0.001) loss 1.6205 (1.7920) teacher_loss 0.7647 (0.8921) loss_zs_kd 0.0533 (0.0524) loss_oracle 0.5483 (0.5770) kd_loss 0.5550 (0.5852) acc 71.8750 (76.1068) gate/entropy 1.0471 (1.0519) gate/usage_max 0.4860 (0.4783) gate/usage_min 0.2349 (0.2390) gate/usage_std 0.1094 (0.1041) teacher/entropy 0.3126 (0.3135) teacher/usage_max 0.7504 (0.7084) teacher/usage_min 0.0435 (0.0466) teacher/usage_std 0.3023 (0.2797) nleep/row_max_mean 1196.9795 (1197.2731) nleep/row_max_std 15.1453 (14.5998) nleep/row_min_mean 1189.9036 (1190.4188) lr 8.1262e-04 eta 0:28:53
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,803
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.0%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,004
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.6%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [31/50] batch [20/244] time 0.495 (0.478) data 0.000 (0.014) loss 1.4732 (1.7466) teacher_loss 0.5582 (0.8563) loss_zs_kd 0.0496 (0.0518) loss_oracle 0.5299 (0.5503) kd_loss 0.6253 (0.5893) acc 81.2500 (76.4062) gate/entropy 1.0463 (1.0466) gate/usage_max 0.4873 (0.4867) gate/usage_min 0.2341 (0.2344) gate/usage_std 0.1103 (0.1100) teacher/entropy 0.2240 (0.2968) teacher/usage_max 0.7701 (0.7155) teacher/usage_min 0.0115 (0.0438) teacher/usage_std 0.3202 (0.2850) nleep/row_max_mean 1200.6035 (1198.7534) nleep/row_max_std 15.6369 (14.9065) nleep/row_min_mean 1193.2780 (1191.8901) lr 7.5131e-04 eta 0:38:43
epoch [31/50] batch [40/244] time 0.088 (0.372) data 0.000 (0.007) loss 1.9327 (1.7470) teacher_loss 1.0027 (0.8567) loss_zs_kd 0.0711 (0.0536) loss_oracle 0.5351 (0.5443) kd_loss 0.6268 (0.5914) acc 78.1250 (76.6406) gate/entropy 1.0455 (1.0463) gate/usage_max 0.4885 (0.4873) gate/usage_min 0.2334 (0.2341) gate/usage_std 0.1112 (0.1104) teacher/entropy 0.2378 (0.3020) teacher/usage_max 0.7392 (0.7024) teacher/usage_min 0.0075 (0.0465) teacher/usage_std 0.3040 (0.2770) nleep/row_max_mean 1199.5359 (1199.3594) nleep/row_max_std 12.4605 (14.5803) nleep/row_min_mean 1192.1686 (1192.3643) lr 7.5131e-04 eta 0:30:01
epoch [31/50] batch [60/244] time 0.081 (0.379) data 0.000 (0.005) loss 2.0819 (1.7815) teacher_loss 1.3109 (0.8981) loss_zs_kd 0.0524 (0.0521) loss_oracle 0.5040 (0.5464) kd_loss 0.4928 (0.5841) acc 71.8750 (75.8333) gate/entropy 1.0449 (1.0459) gate/usage_max 0.4894 (0.4878) gate/usage_min 0.2329 (0.2338) gate/usage_std 0.1119 (0.1107) teacher/entropy 0.4464 (0.3047) teacher/usage_max 0.6317 (0.7097) teacher/usage_min 0.0897 (0.0470) teacher/usage_std 0.2246 (0.2806) nleep/row_max_mean 1196.9907 (1198.6714) nleep/row_max_std 16.4310 (14.4772) nleep/row_min_mean 1191.1273 (1191.7560) lr 7.5131e-04 eta 0:30:26
epoch [31/50] batch [80/244] time 0.082 (0.330) data 0.000 (0.004) loss 1.8740 (1.7511) teacher_loss 0.9618 (0.8672) loss_zs_kd 0.0558 (0.0515) loss_oracle 0.5779 (0.5481) kd_loss 0.5954 (0.5842) acc 71.8750 (77.1094) gate/entropy 1.0439 (1.0456) gate/usage_max 0.4908 (0.4884) gate/usage_min 0.2320 (0.2335) gate/usage_std 0.1128 (0.1111) teacher/entropy 0.2539 (0.3034) teacher/usage_max 0.7694 (0.7112) teacher/usage_min 0.0328 (0.0473) teacher/usage_std 0.3156 (0.2813) nleep/row_max_mean 1198.1604 (1198.5652) nleep/row_max_std 12.4881 (14.3251) nleep/row_min_mean 1191.2162 (1191.6701) lr 7.5131e-04 eta 0:26:25
epoch [31/50] batch [100/244] time 0.496 (0.349) data 0.000 (0.003) loss 1.9082 (1.7391) teacher_loss 0.9752 (0.8553) loss_zs_kd 0.0736 (0.0517) loss_oracle 0.5891 (0.5528) kd_loss 0.6016 (0.5815) acc 71.8750 (77.2500) gate/entropy 1.0434 (1.0452) gate/usage_max 0.4917 (0.4889) gate/usage_min 0.2319 (0.2333) gate/usage_std 0.1134 (0.1115) teacher/entropy 0.2700 (0.3040) teacher/usage_max 0.7261 (0.7137) teacher/usage_min 0.0228 (0.0463) teacher/usage_std 0.2930 (0.2827) nleep/row_max_mean 1196.5133 (1198.5934) nleep/row_max_std 15.9492 (14.3417) nleep/row_min_mean 1189.4336 (1191.7315) lr 7.5131e-04 eta 0:27:49
epoch [31/50] batch [120/244] time 0.465 (0.369) data 0.000 (0.002) loss 1.8773 (1.7589) teacher_loss 0.9983 (0.8770) loss_zs_kd 0.0674 (0.0514) loss_oracle 0.4561 (0.5517) kd_loss 0.6172 (0.5804) acc 71.8750 (76.7448) gate/entropy 1.0428 (1.0449) gate/usage_max 0.4926 (0.4894) gate/usage_min 0.2315 (0.2331) gate/usage_std 0.1140 (0.1119) teacher/entropy 0.2583 (0.3059) teacher/usage_max 0.7153 (0.7118) teacher/usage_min 0.0136 (0.0471) teacher/usage_std 0.2899 (0.2814) nleep/row_max_mean 1202.2329 (1198.4403) nleep/row_max_std 12.3725 (14.1745) nleep/row_min_mean 1195.1245 (1191.5806) lr 7.5131e-04 eta 0:29:16
epoch [31/50] batch [140/244] time 0.495 (0.385) data 0.000 (0.002) loss 1.3867 (1.7723) teacher_loss 0.3949 (0.8908) loss_zs_kd 0.0605 (0.0511) loss_oracle 0.4722 (0.5490) kd_loss 0.7253 (0.5815) acc 93.7500 (76.6741) gate/entropy 1.0421 (1.0445) gate/usage_max 0.4936 (0.4899) gate/usage_min 0.2308 (0.2328) gate/usage_std 0.1148 (0.1122) teacher/entropy 0.1928 (0.3058) teacher/usage_max 0.6473 (0.7097) teacher/usage_min 0.0390 (0.0487) teacher/usage_std 0.2487 (0.2801) nleep/row_max_mean 1205.6801 (1198.4806) nleep/row_max_std 15.4736 (14.2760) nleep/row_min_mean 1197.8062 (1191.6116) lr 7.5131e-04 eta 0:30:25
epoch [31/50] batch [160/244] time 0.092 (0.393) data 0.000 (0.002) loss 1.8429 (1.7613) teacher_loss 0.8611 (0.8774) loss_zs_kd 0.0406 (0.0506) loss_oracle 0.5658 (0.5498) kd_loss 0.6786 (0.5836) acc 71.8750 (77.0508) gate/entropy 1.0417 (1.0442) gate/usage_max 0.4943 (0.4904) gate/usage_min 0.2306 (0.2325) gate/usage_std 0.1152 (0.1126) teacher/entropy 0.2036 (0.3029) teacher/usage_max 0.7012 (0.7098) teacher/usage_min 0.0136 (0.0472) teacher/usage_std 0.2828 (0.2806) nleep/row_max_mean 1199.1331 (1198.6449) nleep/row_max_std 18.0545 (14.3402) nleep/row_min_mean 1191.3262 (1191.7379) lr 7.5131e-04 eta 0:30:53
epoch [31/50] batch [180/244] time 0.461 (0.388) data 0.000 (0.002) loss 1.4490 (1.7562) teacher_loss 0.6694 (0.8739) loss_zs_kd 0.0500 (0.0503) loss_oracle 0.5012 (0.5472) kd_loss 0.5041 (0.5835) acc 87.5000 (77.1875) gate/entropy 1.0411 (1.0439) gate/usage_max 0.4951 (0.4909) gate/usage_min 0.2303 (0.2323) gate/usage_std 0.1158 (0.1129) teacher/entropy 0.3896 (0.3026) teacher/usage_max 0.7038 (0.7099) teacher/usage_min 0.0929 (0.0477) teacher/usage_std 0.2658 (0.2805) nleep/row_max_mean 1200.1807 (1198.7158) nleep/row_max_std 15.7685 (14.4772) nleep/row_min_mean 1194.1912 (1191.7964) lr 7.5131e-04 eta 0:30:24
epoch [31/50] batch [200/244] time 0.483 (0.367) data 0.000 (0.002) loss 2.1075 (1.7597) teacher_loss 1.1886 (0.8776) loss_zs_kd 0.0672 (0.0507) loss_oracle 0.5628 (0.5462) kd_loss 0.6039 (0.5836) acc 71.8750 (76.7969) gate/entropy 1.0404 (1.0436) gate/usage_max 0.4962 (0.4914) gate/usage_min 0.2299 (0.2321) gate/usage_std 0.1165 (0.1132) teacher/entropy 0.2483 (0.2999) teacher/usage_max 0.7470 (0.7134) teacher/usage_min 0.0076 (0.0472) teacher/usage_std 0.3082 (0.2826) nleep/row_max_mean 1193.9580 (1198.6557) nleep/row_max_std 14.9531 (14.5290) nleep/row_min_mean 1187.1508 (1191.7336) lr 7.5131e-04 eta 0:28:38
epoch [31/50] batch [220/244] time 0.501 (0.359) data 0.000 (0.001) loss 1.6188 (1.7644) teacher_loss 0.7494 (0.8828) loss_zs_kd 0.0478 (0.0504) loss_oracle 0.5582 (0.5481) kd_loss 0.5664 (0.5824) acc 68.7500 (76.7045) gate/entropy 1.0396 (1.0432) gate/usage_max 0.4974 (0.4919) gate/usage_min 0.2293 (0.2318) gate/usage_std 0.1174 (0.1136) teacher/entropy 0.3085 (0.2983) teacher/usage_max 0.7164 (0.7174) teacher/usage_min 0.0380 (0.0466) teacher/usage_std 0.2838 (0.2848) nleep/row_max_mean 1198.8281 (1198.6327) nleep/row_max_std 12.6640 (14.5808) nleep/row_min_mean 1192.0048 (1191.6960) lr 7.5131e-04 eta 0:27:54
epoch [31/50] batch [240/244] time 0.495 (0.370) data 0.000 (0.001) loss 1.6069 (1.7649) teacher_loss 0.7209 (0.8829) loss_zs_kd 0.0245 (0.0507) loss_oracle 0.5334 (0.5477) kd_loss 0.6070 (0.5828) acc 84.3750 (76.6927) gate/entropy 1.0389 (1.0429) gate/usage_max 0.4985 (0.4924) gate/usage_min 0.2291 (0.2316) gate/usage_std 0.1181 (0.1139) teacher/entropy 0.2811 (0.2964) teacher/usage_max 0.7004 (0.7191) teacher/usage_min 0.0609 (0.0465) teacher/usage_std 0.2695 (0.2857) nleep/row_max_mean 1200.7292 (1198.5549) nleep/row_max_std 16.9190 (14.6166) nleep/row_min_mean 1193.0051 (1191.5965) lr 7.5131e-04 eta 0:28:35
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,816
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,011
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.8%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [32/50] batch [20/244] time 0.522 (0.512) data 0.000 (0.012) loss 2.0183 (1.7046) teacher_loss 1.2242 (0.8464) loss_zs_kd 0.0648 (0.0519) loss_oracle 0.5212 (0.5525) kd_loss 0.5010 (0.5560) acc 59.3750 (77.6562) gate/entropy 1.0380 (1.0384) gate/usage_max 0.4998 (0.4992) gate/usage_min 0.2282 (0.2286) gate/usage_std 0.1190 (0.1186) teacher/entropy 0.3348 (0.2865) teacher/usage_max 0.7786 (0.7678) teacher/usage_min 0.0420 (0.0397) teacher/usage_std 0.3198 (0.3148) nleep/row_max_mean 1192.2379 (1198.5661) nleep/row_max_std 12.2823 (14.7181) nleep/row_min_mean 1185.8799 (1191.3316) lr 6.9098e-04 eta 0:39:22
epoch [32/50] batch [40/244] time 0.438 (0.407) data 0.000 (0.006) loss 1.8242 (1.7274) teacher_loss 0.9004 (0.8597) loss_zs_kd 0.0511 (0.0513) loss_oracle 0.5134 (0.5432) kd_loss 0.6415 (0.5704) acc 81.2500 (77.7344) gate/entropy 1.0375 (1.0381) gate/usage_max 0.5005 (0.4997) gate/usage_min 0.2281 (0.2284) gate/usage_std 0.1195 (0.1189) teacher/entropy 0.2681 (0.2771) teacher/usage_max 0.6472 (0.7582) teacher/usage_min 0.0077 (0.0376) teacher/usage_std 0.2612 (0.3096) nleep/row_max_mean 1197.0315 (1198.6124) nleep/row_max_std 14.8756 (15.0137) nleep/row_min_mean 1190.4507 (1191.3997) lr 6.9098e-04 eta 0:31:12
epoch [32/50] batch [60/244] time 0.109 (0.350) data 0.001 (0.004) loss 1.7634 (1.7435) teacher_loss 0.8350 (0.8701) loss_zs_kd 0.0698 (0.0528) loss_oracle 0.5622 (0.5420) kd_loss 0.6124 (0.5760) acc 81.2500 (77.7604) gate/entropy 1.0370 (1.0377) gate/usage_max 0.5013 (0.5001) gate/usage_min 0.2280 (0.2282) gate/usage_std 0.1200 (0.1193) teacher/entropy 0.2505 (0.2796) teacher/usage_max 0.7252 (0.7454) teacher/usage_min 0.0164 (0.0416) teacher/usage_std 0.2942 (0.3012) nleep/row_max_mean 1197.7419 (1198.6772) nleep/row_max_std 16.6361 (15.3073) nleep/row_min_mean 1190.3772 (1191.4927) lr 6.9098e-04 eta 0:26:39
epoch [32/50] batch [80/244] time 0.454 (0.322) data 0.000 (0.003) loss 1.7360 (1.7427) teacher_loss 0.8857 (0.8701) loss_zs_kd 0.0775 (0.0523) loss_oracle 0.5146 (0.5388) kd_loss 0.5542 (0.5771) acc 81.2500 (77.4219) gate/entropy 1.0363 (1.0374) gate/usage_max 0.5022 (0.5006) gate/usage_min 0.2274 (0.2281) gate/usage_std 0.1207 (0.1196) teacher/entropy 0.2813 (0.2829) teacher/usage_max 0.7731 (0.7381) teacher/usage_min 0.0356 (0.0434) teacher/usage_std 0.3174 (0.2967) nleep/row_max_mean 1202.4377 (1199.0048) nleep/row_max_std 16.2393 (15.4721) nleep/row_min_mean 1194.6409 (1191.8374) lr 6.9098e-04 eta 0:24:28
epoch [32/50] batch [100/244] time 0.435 (0.349) data 0.000 (0.003) loss 1.9418 (1.7631) teacher_loss 1.1044 (0.8901) loss_zs_kd 0.0801 (0.0536) loss_oracle 0.5189 (0.5347) kd_loss 0.5379 (0.5789) acc 65.6250 (76.8438) gate/entropy 1.0359 (1.0371) gate/usage_max 0.5029 (0.5010) gate/usage_min 0.2274 (0.2279) gate/usage_std 0.1211 (0.1199) teacher/entropy 0.3215 (0.2851) teacher/usage_max 0.7360 (0.7314) teacher/usage_min 0.0454 (0.0448) teacher/usage_std 0.2934 (0.2926) nleep/row_max_mean 1198.9910 (1198.9512) nleep/row_max_std 16.1446 (15.5161) nleep/row_min_mean 1191.6375 (1191.8470) lr 6.9098e-04 eta 0:26:22
epoch [32/50] batch [120/244] time 0.496 (0.372) data 0.000 (0.002) loss 1.4840 (1.7655) teacher_loss 0.5517 (0.8877) loss_zs_kd 0.0649 (0.0538) loss_oracle 0.5393 (0.5361) kd_loss 0.6302 (0.5827) acc 87.5000 (76.9010) gate/entropy 1.0355 (1.0369) gate/usage_max 0.5034 (0.5014) gate/usage_min 0.2271 (0.2277) gate/usage_std 0.1215 (0.1202) teacher/entropy 0.2376 (0.2858) teacher/usage_max 0.7310 (0.7241) teacher/usage_min 0.0774 (0.0464) teacher/usage_std 0.2850 (0.2887) nleep/row_max_mean 1199.8302 (1199.0536) nleep/row_max_std 13.7214 (15.4615) nleep/row_min_mean 1192.5153 (1191.9676) lr 6.9098e-04 eta 0:27:59
epoch [32/50] batch [140/244] time 0.496 (0.390) data 0.000 (0.002) loss 1.7351 (1.7513) teacher_loss 0.8958 (0.8743) loss_zs_kd 0.0473 (0.0530) loss_oracle 0.5299 (0.5347) kd_loss 0.5506 (0.5831) acc 68.7500 (77.2545) gate/entropy 1.0345 (1.0366) gate/usage_max 0.5047 (0.5018) gate/usage_min 0.2261 (0.2276) gate/usage_std 0.1225 (0.1204) teacher/entropy 0.3030 (0.2881) teacher/usage_max 0.7387 (0.7195) teacher/usage_min 0.0318 (0.0471) teacher/usage_std 0.2978 (0.2861) nleep/row_max_mean 1196.4663 (1199.0451) nleep/row_max_std 14.0584 (15.4276) nleep/row_min_mean 1190.3044 (1191.9787) lr 6.9098e-04 eta 0:29:14
epoch [32/50] batch [160/244] time 0.089 (0.382) data 0.000 (0.002) loss 1.7725 (1.7504) teacher_loss 0.9123 (0.8756) loss_zs_kd 0.0456 (0.0524) loss_oracle 0.5709 (0.5350) kd_loss 0.5520 (0.5811) acc 78.1250 (77.3047) gate/entropy 1.0342 (1.0363) gate/usage_max 0.5052 (0.5022) gate/usage_min 0.2261 (0.2274) gate/usage_std 0.1228 (0.1207) teacher/entropy 0.3146 (0.2909) teacher/usage_max 0.7262 (0.7176) teacher/usage_min 0.0627 (0.0474) teacher/usage_std 0.2843 (0.2852) nleep/row_max_mean 1196.5251 (1199.0118) nleep/row_max_std 14.6869 (15.3204) nleep/row_min_mean 1189.6672 (1191.9877) lr 6.9098e-04 eta 0:28:29
epoch [32/50] batch [180/244] time 0.081 (0.383) data 0.000 (0.001) loss 1.5516 (1.7578) teacher_loss 0.6476 (0.8825) loss_zs_kd 0.0544 (0.0521) loss_oracle 0.5598 (0.5359) kd_loss 0.5969 (0.5813) acc 90.6250 (77.1701) gate/entropy 1.0339 (1.0361) gate/usage_max 0.5057 (0.5026) gate/usage_min 0.2262 (0.2273) gate/usage_std 0.1231 (0.1209) teacher/entropy 0.2449 (0.2914) teacher/usage_max 0.7577 (0.7160) teacher/usage_min 0.0385 (0.0474) teacher/usage_std 0.3076 (0.2843) nleep/row_max_mean 1199.0914 (1199.0393) nleep/row_max_std 14.8735 (15.1567) nleep/row_min_mean 1191.4697 (1192.0423) lr 6.9098e-04 eta 0:28:26
epoch [32/50] batch [200/244] time 0.084 (0.359) data 0.000 (0.001) loss 1.8949 (1.7646) teacher_loss 1.0666 (0.8917) loss_zs_kd 0.0464 (0.0523) loss_oracle 0.4733 (0.5345) kd_loss 0.5685 (0.5795) acc 65.6250 (76.9844) gate/entropy 1.0332 (1.0358) gate/usage_max 0.5067 (0.5029) gate/usage_min 0.2256 (0.2271) gate/usage_std 0.1238 (0.1212) teacher/entropy 0.3812 (0.2931) teacher/usage_max 0.5873 (0.7160) teacher/usage_min 0.0381 (0.0483) teacher/usage_std 0.2261 (0.2841) nleep/row_max_mean 1198.7053 (1198.9208) nleep/row_max_std 13.0154 (15.0531) nleep/row_min_mean 1191.8777 (1191.9599) lr 6.9098e-04 eta 0:26:32
epoch [32/50] batch [220/244] time 0.466 (0.362) data 0.000 (0.001) loss 2.1397 (1.7636) teacher_loss 1.2945 (0.8931) loss_zs_kd 0.0624 (0.0523) loss_oracle 0.4348 (0.5337) kd_loss 0.5966 (0.5774) acc 65.6250 (76.9176) gate/entropy 1.0326 (1.0355) gate/usage_max 0.5075 (0.5033) gate/usage_min 0.2252 (0.2269) gate/usage_std 0.1244 (0.1215) teacher/entropy 0.2525 (0.2930) teacher/usage_max 0.7363 (0.7187) teacher/usage_min 0.0113 (0.0479) teacher/usage_std 0.3014 (0.2856) nleep/row_max_mean 1199.0868 (1198.8314) nleep/row_max_std 13.0798 (14.9665) nleep/row_min_mean 1192.6957 (1191.8952) lr 6.9098e-04 eta 0:26:37
epoch [32/50] batch [240/244] time 0.480 (0.373) data 0.000 (0.001) loss 1.5639 (1.7706) teacher_loss 0.7420 (0.9008) loss_zs_kd 0.0429 (0.0524) loss_oracle 0.5317 (0.5338) kd_loss 0.5346 (0.5767) acc 81.2500 (76.6667) gate/entropy 1.0322 (1.0353) gate/usage_max 0.5081 (0.5037) gate/usage_min 0.2253 (0.2268) gate/usage_std 0.1247 (0.1217) teacher/entropy 0.2944 (0.2932) teacher/usage_max 0.7740 (0.7192) teacher/usage_min 0.0382 (0.0485) teacher/usage_std 0.3175 (0.2858) nleep/row_max_mean 1194.7307 (1198.7325) nleep/row_max_std 13.7480 (14.8918) nleep/row_min_mean 1187.9526 (1191.8042) lr 6.9098e-04 eta 0:27:17
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,812
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.2%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,008
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.6%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [33/50] batch [20/244] time 0.082 (0.423) data 0.000 (0.013) loss 1.6366 (1.7547) teacher_loss 0.8334 (0.8871) loss_zs_kd 0.0444 (0.0485) loss_oracle 0.4818 (0.5351) kd_loss 0.5401 (0.5758) acc 78.1250 (77.9688) gate/entropy 1.0311 (1.0316) gate/usage_max 0.5096 (0.5089) gate/usage_min 0.2244 (0.2248) gate/usage_std 0.1258 (0.1253) teacher/entropy 0.3649 (0.2920) teacher/usage_max 0.6601 (0.7173) teacher/usage_min 0.0599 (0.0541) teacher/usage_std 0.2479 (0.2821) nleep/row_max_mean 1196.1399 (1199.0563) nleep/row_max_std 14.2289 (15.3808) nleep/row_min_mean 1190.4048 (1191.9771) lr 6.3188e-04 eta 0:30:47
epoch [33/50] batch [40/244] time 0.483 (0.383) data 0.000 (0.007) loss 1.6435 (1.7206) teacher_loss 0.6582 (0.8493) loss_zs_kd 0.0551 (0.0510) loss_oracle 0.6288 (0.5391) kd_loss 0.6433 (0.5763) acc 84.3750 (78.7500) gate/entropy 1.0307 (1.0314) gate/usage_max 0.5102 (0.5093) gate/usage_min 0.2243 (0.2247) gate/usage_std 0.1262 (0.1255) teacher/entropy 0.2223 (0.2834) teacher/usage_max 0.7346 (0.7309) teacher/usage_min 0.1112 (0.0597) teacher/usage_std 0.2842 (0.2891) nleep/row_max_mean 1201.2065 (1199.0417) nleep/row_max_std 13.8637 (15.1722) nleep/row_min_mean 1193.4973 (1191.9639) lr 6.3188e-04 eta 0:27:46
epoch [33/50] batch [60/244] time 0.450 (0.310) data 0.001 (0.005) loss 2.4815 (1.7453) teacher_loss 1.6609 (0.8831) loss_zs_kd 0.0711 (0.0523) loss_oracle 0.5035 (0.5321) kd_loss 0.5332 (0.5700) acc 62.5000 (77.1354) gate/entropy 1.0302 (1.0311) gate/usage_max 0.5109 (0.5096) gate/usage_min 0.2241 (0.2246) gate/usage_std 0.1267 (0.1258) teacher/entropy 0.3059 (0.2871) teacher/usage_max 0.7559 (0.7343) teacher/usage_min 0.0449 (0.0592) teacher/usage_std 0.3053 (0.2911) nleep/row_max_mean 1197.5547 (1198.7745) nleep/row_max_std 13.5169 (14.9100) nleep/row_min_mean 1191.1685 (1191.8054) lr 6.3188e-04 eta 0:22:24
epoch [33/50] batch [80/244] time 0.506 (0.292) data 0.000 (0.003) loss 1.6620 (1.7605) teacher_loss 0.6918 (0.8993) loss_zs_kd 0.0652 (0.0548) loss_oracle 0.5564 (0.5292) kd_loss 0.6593 (0.5692) acc 81.2500 (76.3672) gate/entropy 1.0300 (1.0309) gate/usage_max 0.5113 (0.5100) gate/usage_min 0.2241 (0.2245) gate/usage_std 0.1269 (0.1260) teacher/entropy 0.2512 (0.2886) teacher/usage_max 0.6625 (0.7325) teacher/usage_min 0.0993 (0.0582) teacher/usage_std 0.2396 (0.2901) nleep/row_max_mean 1195.1051 (1198.5179) nleep/row_max_std 14.1926 (14.8102) nleep/row_min_mean 1188.2173 (1191.5727) lr 6.3188e-04 eta 0:21:00
epoch [33/50] batch [100/244] time 0.520 (0.331) data 0.000 (0.003) loss 1.5618 (1.7458) teacher_loss 0.7063 (0.8849) loss_zs_kd 0.0579 (0.0543) loss_oracle 0.5958 (0.5335) kd_loss 0.5287 (0.5670) acc 84.3750 (76.9688) gate/entropy 1.0295 (1.0306) gate/usage_max 0.5120 (0.5104) gate/usage_min 0.2240 (0.2244) gate/usage_std 0.1274 (0.1263) teacher/entropy 0.2698 (0.2895) teacher/usage_max 0.8138 (0.7338) teacher/usage_min 0.0337 (0.0574) teacher/usage_std 0.3432 (0.2910) nleep/row_max_mean 1197.1162 (1198.3833) nleep/row_max_std 15.2695 (14.8318) nleep/row_min_mean 1189.3396 (1191.4636) lr 6.3188e-04 eta 0:23:39
epoch [33/50] batch [120/244] time 0.549 (0.358) data 0.000 (0.002) loss 2.0267 (1.7475) teacher_loss 1.1560 (0.8877) loss_zs_kd 0.0924 (0.0557) loss_oracle 0.5261 (0.5372) kd_loss 0.5614 (0.5634) acc 65.6250 (77.0052) gate/entropy 1.0290 (1.0304) gate/usage_max 0.5126 (0.5107) gate/usage_min 0.2238 (0.2243) gate/usage_std 0.1278 (0.1265) teacher/entropy 0.2639 (0.2914) teacher/usage_max 0.7784 (0.7360) teacher/usage_min 0.0581 (0.0569) teacher/usage_std 0.3176 (0.2924) nleep/row_max_mean 1193.6812 (1198.0684) nleep/row_max_std 13.8358 (14.7442) nleep/row_min_mean 1186.9352 (1191.1725) lr 6.3188e-04 eta 0:25:30
epoch [33/50] batch [140/244] time 0.520 (0.377) data 0.000 (0.002) loss 1.7288 (1.7463) teacher_loss 0.8799 (0.8888) loss_zs_kd 0.0468 (0.0551) loss_oracle 0.5467 (0.5383) kd_loss 0.5521 (0.5608) acc 75.0000 (77.0982) gate/entropy 1.0284 (1.0301) gate/usage_max 0.5135 (0.5111) gate/usage_min 0.2236 (0.2242) gate/usage_std 0.1284 (0.1268) teacher/entropy 0.3321 (0.2910) teacher/usage_max 0.7061 (0.7401) teacher/usage_min 0.1255 (0.0567) teacher/usage_std 0.2642 (0.2949) nleep/row_max_mean 1199.3401 (1197.8815) nleep/row_max_std 13.8244 (14.7258) nleep/row_min_mean 1192.9839 (1190.9897) lr 6.3188e-04 eta 0:26:44
epoch [33/50] batch [160/244] time 0.085 (0.364) data 0.000 (0.002) loss 1.4214 (1.7384) teacher_loss 0.5467 (0.8797) loss_zs_kd 0.0615 (0.0544) loss_oracle 0.5213 (0.5401) kd_loss 0.5833 (0.5615) acc 87.5000 (77.4414) gate/entropy 1.0276 (1.0299) gate/usage_max 0.5146 (0.5114) gate/usage_min 0.2231 (0.2241) gate/usage_std 0.1292 (0.1270) teacher/entropy 0.2300 (0.2887) teacher/usage_max 0.7872 (0.7418) teacher/usage_min 0.0353 (0.0566) teacher/usage_std 0.3261 (0.2960) nleep/row_max_mean 1202.2649 (1197.8885) nleep/row_max_std 13.9147 (14.7558) nleep/row_min_mean 1194.7328 (1190.9763) lr 6.3188e-04 eta 0:25:38
epoch [33/50] batch [180/244] time 0.082 (0.367) data 0.000 (0.002) loss 2.0939 (1.7402) teacher_loss 1.2648 (0.8839) loss_zs_kd 0.0524 (0.0544) loss_oracle 0.5177 (0.5375) kd_loss 0.5441 (0.5603) acc 71.8750 (77.1701) gate/entropy 1.0276 (1.0296) gate/usage_max 0.5147 (0.5118) gate/usage_min 0.2234 (0.2240) gate/usage_std 0.1292 (0.1273) teacher/entropy 0.3034 (0.2897) teacher/usage_max 0.7304 (0.7415) teacher/usage_min 0.0092 (0.0558) teacher/usage_std 0.2989 (0.2960) nleep/row_max_mean 1198.8137 (1197.7406) nleep/row_max_std 13.1420 (14.7332) nleep/row_min_mean 1191.8119 (1190.8238) lr 6.3188e-04 eta 0:25:44
epoch [33/50] batch [200/244] time 0.114 (0.347) data 0.000 (0.001) loss 1.5658 (1.7449) teacher_loss 0.6929 (0.8881) loss_zs_kd 0.0529 (0.0549) loss_oracle 0.4773 (0.5365) kd_loss 0.6078 (0.5611) acc 81.2500 (76.9531) gate/entropy 1.0266 (1.0293) gate/usage_max 0.5160 (0.5122) gate/usage_min 0.2227 (0.2239) gate/usage_std 0.1301 (0.1275) teacher/entropy 0.2541 (0.2874) teacher/usage_max 0.7152 (0.7432) teacher/usage_min 0.0396 (0.0551) teacher/usage_std 0.2828 (0.2972) nleep/row_max_mean 1200.8560 (1197.7016) nleep/row_max_std 14.4606 (14.7843) nleep/row_min_mean 1193.9050 (1190.7708) lr 6.3188e-04 eta 0:24:13
epoch [33/50] batch [220/244] time 0.464 (0.350) data 0.000 (0.001) loss 1.8718 (1.7469) teacher_loss 0.9212 (0.8896) loss_zs_kd 0.0584 (0.0552) loss_oracle 0.5823 (0.5362) kd_loss 0.6302 (0.5615) acc 75.0000 (76.9034) gate/entropy 1.0262 (1.0291) gate/usage_max 0.5165 (0.5125) gate/usage_min 0.2227 (0.2238) gate/usage_std 0.1304 (0.1278) teacher/entropy 0.2500 (0.2867) teacher/usage_max 0.6920 (0.7431) teacher/usage_min 0.0539 (0.0548) teacher/usage_std 0.2665 (0.2972) nleep/row_max_mean 1197.8579 (1197.7647) nleep/row_max_std 16.0976 (14.8732) nleep/row_min_mean 1190.4547 (1190.8155) lr 6.3188e-04 eta 0:24:20
epoch [33/50] batch [240/244] time 0.495 (0.361) data 0.000 (0.001) loss 1.2671 (1.7431) teacher_loss 0.3969 (0.8856) loss_zs_kd 0.0548 (0.0552) loss_oracle 0.5710 (0.5359) kd_loss 0.5573 (0.5619) acc 84.3750 (76.9531) gate/entropy 1.0265 (1.0288) gate/usage_max 0.5163 (0.5129) gate/usage_min 0.2232 (0.2237) gate/usage_std 0.1303 (0.1280) teacher/entropy 0.2677 (0.2859) teacher/usage_max 0.7703 (0.7429) teacher/usage_min 0.0411 (0.0534) teacher/usage_std 0.3148 (0.2974) nleep/row_max_mean 1197.8806 (1197.7918) nleep/row_max_std 17.1669 (14.9283) nleep/row_min_mean 1190.1609 (1190.8311) lr 6.3188e-04 eta 0:25:00
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,822
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,012
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.8%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [34/50] batch [20/244] time 0.102 (0.411) data 0.000 (0.015) loss 1.4852 (1.7277) teacher_loss 0.7341 (0.8800) loss_zs_kd 0.0457 (0.0514) loss_oracle 0.4852 (0.5193) kd_loss 0.4857 (0.5624) acc 84.3750 (75.9375) gate/entropy 1.0252 (1.0255) gate/usage_max 0.5179 (0.5175) gate/usage_min 0.2222 (0.2223) gate/usage_std 0.1314 (0.1311) teacher/entropy 0.3703 (0.2816) teacher/usage_max 0.7231 (0.7424) teacher/usage_min 0.0440 (0.0508) teacher/usage_std 0.2862 (0.2978) nleep/row_max_mean 1191.4136 (1196.7606) nleep/row_max_std 15.0840 (15.5216) nleep/row_min_mean 1185.5149 (1189.8752) lr 5.7422e-04 eta 0:28:15
epoch [34/50] batch [40/244] time 0.080 (0.405) data 0.000 (0.008) loss 2.1155 (1.7166) teacher_loss 1.2597 (0.8657) loss_zs_kd 0.0559 (0.0540) loss_oracle 0.5143 (0.5197) kd_loss 0.5707 (0.5641) acc 65.6250 (76.6406) gate/entropy 1.0248 (1.0253) gate/usage_max 0.5184 (0.5178) gate/usage_min 0.2221 (0.2223) gate/usage_std 0.1317 (0.1314) teacher/entropy 0.2457 (0.2869) teacher/usage_max 0.7738 (0.7325) teacher/usage_min 0.0164 (0.0530) teacher/usage_std 0.3213 (0.2926) nleep/row_max_mean 1193.3250 (1197.4805) nleep/row_max_std 16.3077 (16.1059) nleep/row_min_mean 1185.9812 (1190.5100) lr 5.7422e-04 eta 0:27:42
epoch [34/50] batch [60/244] time 0.307 (0.335) data 0.000 (0.005) loss 1.8295 (1.7068) teacher_loss 0.9460 (0.8580) loss_zs_kd 0.0531 (0.0543) loss_oracle 0.5504 (0.5245) kd_loss 0.5817 (0.5594) acc 71.8750 (76.9271) gate/entropy 1.0244 (1.0251) gate/usage_max 0.5190 (0.5181) gate/usage_min 0.2220 (0.2222) gate/usage_std 0.1321 (0.1315) teacher/entropy 0.2348 (0.2832) teacher/usage_max 0.7853 (0.7434) teacher/usage_min 0.0722 (0.0494) teacher/usage_std 0.3209 (0.2995) nleep/row_max_mean 1196.6071 (1197.5036) nleep/row_max_std 14.6144 (16.0693) nleep/row_min_mean 1189.4353 (1190.4800) lr 5.7422e-04 eta 0:22:47
epoch [34/50] batch [80/244] time 0.547 (0.352) data 0.000 (0.004) loss 1.9899 (1.6977) teacher_loss 1.1830 (0.8470) loss_zs_kd 0.0505 (0.0546) loss_oracle 0.5107 (0.5263) kd_loss 0.5263 (0.5602) acc 75.0000 (77.3828) gate/entropy 1.0240 (1.0248) gate/usage_max 0.5196 (0.5184) gate/usage_min 0.2218 (0.2221) gate/usage_std 0.1326 (0.1318) teacher/entropy 0.3350 (0.2826) teacher/usage_max 0.7173 (0.7432) teacher/usage_min 0.0596 (0.0513) teacher/usage_std 0.2796 (0.2987) nleep/row_max_mean 1193.4641 (1197.4608) nleep/row_max_std 14.2035 (16.0057) nleep/row_min_mean 1186.9155 (1190.4227) lr 5.7422e-04 eta 0:23:52
epoch [34/50] batch [100/244] time 0.527 (0.382) data 0.000 (0.003) loss 1.6774 (1.7096) teacher_loss 0.8598 (0.8593) loss_zs_kd 0.0451 (0.0540) loss_oracle 0.5472 (0.5256) kd_loss 0.5214 (0.5605) acc 81.2500 (77.1562) gate/entropy 1.0233 (1.0246) gate/usage_max 0.5204 (0.5187) gate/usage_min 0.2215 (0.2220) gate/usage_std 0.1331 (0.1320) teacher/entropy 0.2162 (0.2820) teacher/usage_max 0.8861 (0.7432) teacher/usage_min 0.0296 (0.0508) teacher/usage_std 0.3915 (0.2987) nleep/row_max_mean 1198.4949 (1197.6275) nleep/row_max_std 18.5901 (16.0457) nleep/row_min_mean 1191.1256 (1190.5745) lr 5.7422e-04 eta 0:25:45
epoch [34/50] batch [120/244] time 0.472 (0.403) data 0.000 (0.003) loss 1.4409 (1.7110) teacher_loss 0.5087 (0.8563) loss_zs_kd 0.0506 (0.0545) loss_oracle 0.5452 (0.5283) kd_loss 0.6343 (0.5633) acc 90.6250 (77.2656) gate/entropy 1.0230 (1.0244) gate/usage_max 0.5209 (0.5190) gate/usage_min 0.2214 (0.2220) gate/usage_std 0.1335 (0.1322) teacher/entropy 0.2326 (0.2779) teacher/usage_max 0.7043 (0.7445) teacher/usage_min 0.0432 (0.0498) teacher/usage_std 0.2759 (0.2995) nleep/row_max_mean 1207.2883 (1197.7022) nleep/row_max_std 18.2799 (16.1537) nleep/row_min_mean 1199.2422 (1190.6001) lr 5.7422e-04 eta 0:27:02
epoch [34/50] batch [140/244] time 0.083 (0.403) data 0.000 (0.002) loss 1.4617 (1.7047) teacher_loss 0.7154 (0.8524) loss_zs_kd 0.0479 (0.0535) loss_oracle 0.5493 (0.5278) kd_loss 0.4478 (0.5617) acc 81.2500 (77.3438) gate/entropy 1.0227 (1.0242) gate/usage_max 0.5213 (0.5193) gate/usage_min 0.2215 (0.2219) gate/usage_std 0.1337 (0.1324) teacher/entropy 0.3714 (0.2788) teacher/usage_max 0.7737 (0.7453) teacher/usage_min 0.0532 (0.0503) teacher/usage_std 0.3152 (0.2999) nleep/row_max_mean 1193.0325 (1197.7624) nleep/row_max_std 17.7619 (16.0122) nleep/row_min_mean 1186.6667 (1190.6482) lr 5.7422e-04 eta 0:26:57
epoch [34/50] batch [160/244] time 0.512 (0.401) data 0.000 (0.002) loss 1.7249 (1.7085) teacher_loss 0.8964 (0.8525) loss_zs_kd 0.0568 (0.0541) loss_oracle 0.4825 (0.5284) kd_loss 0.5589 (0.5648) acc 84.3750 (77.3242) gate/entropy 1.0225 (1.0240) gate/usage_max 0.5216 (0.5196) gate/usage_min 0.2214 (0.2218) gate/usage_std 0.1339 (0.1325) teacher/entropy 0.3370 (0.2770) teacher/usage_max 0.6693 (0.7434) teacher/usage_min 0.0736 (0.0510) teacher/usage_std 0.2491 (0.2986) nleep/row_max_mean 1197.0759 (1197.7378) nleep/row_max_std 17.9505 (16.0199) nleep/row_min_mean 1189.8276 (1190.5974) lr 5.7422e-04 eta 0:26:37
epoch [34/50] batch [180/244] time 0.086 (0.372) data 0.000 (0.002) loss 1.9411 (1.7188) teacher_loss 1.1618 (0.8620) loss_zs_kd 0.0682 (0.0549) loss_oracle 0.4776 (0.5279) kd_loss 0.5063 (0.5653) acc 68.7500 (77.1701) gate/entropy 1.0217 (1.0238) gate/usage_max 0.5226 (0.5199) gate/usage_min 0.2209 (0.2217) gate/usage_std 0.1346 (0.1327) teacher/entropy 0.3324 (0.2764) teacher/usage_max 0.7430 (0.7431) teacher/usage_min 0.0428 (0.0513) teacher/usage_std 0.2980 (0.2985) nleep/row_max_mean 1193.0774 (1197.6140) nleep/row_max_std 16.3353 (15.9752) nleep/row_min_mean 1187.0288 (1190.4993) lr 5.7422e-04 eta 0:24:35
epoch [34/50] batch [200/244] time 0.472 (0.371) data 0.000 (0.002) loss 1.6049 (1.7183) teacher_loss 0.7222 (0.8652) loss_zs_kd 0.0429 (0.0547) loss_oracle 0.5627 (0.5251) kd_loss 0.5798 (0.5632) acc 84.3750 (77.1094) gate/entropy 1.0214 (1.0235) gate/usage_max 0.5230 (0.5201) gate/usage_min 0.2208 (0.2217) gate/usage_std 0.1349 (0.1329) teacher/entropy 0.3565 (0.2790) teacher/usage_max 0.6151 (0.7424) teacher/usage_min 0.0878 (0.0524) teacher/usage_std 0.2168 (0.2979) nleep/row_max_mean 1197.2070 (1197.4577) nleep/row_max_std 15.0019 (16.0362) nleep/row_min_mean 1190.6375 (1190.3731) lr 5.7422e-04 eta 0:24:26
epoch [34/50] batch [220/244] time 0.497 (0.382) data 0.000 (0.002) loss 1.8224 (1.7144) teacher_loss 0.9483 (0.8634) loss_zs_kd 0.0541 (0.0542) loss_oracle 0.4566 (0.5242) kd_loss 0.6187 (0.5619) acc 68.7500 (77.2585) gate/entropy 1.0208 (1.0233) gate/usage_max 0.5237 (0.5204) gate/usage_min 0.2206 (0.2216) gate/usage_std 0.1354 (0.1331) teacher/entropy 0.2754 (0.2797) teacher/usage_max 0.6572 (0.7431) teacher/usage_min 0.0092 (0.0527) teacher/usage_std 0.2646 (0.2983) nleep/row_max_mean 1203.7424 (1197.4149) nleep/row_max_std 17.7746 (16.0278) nleep/row_min_mean 1196.1514 (1190.3445) lr 5.7422e-04 eta 0:25:00
epoch [34/50] batch [240/244] time 0.497 (0.390) data 0.000 (0.001) loss 1.5323 (1.7103) teacher_loss 0.7736 (0.8602) loss_zs_kd 0.0755 (0.0538) loss_oracle 0.4520 (0.5234) kd_loss 0.4949 (0.5616) acc 75.0000 (77.3698) gate/entropy 1.0208 (1.0231) gate/usage_max 0.5239 (0.5207) gate/usage_min 0.2207 (0.2215) gate/usage_std 0.1355 (0.1333) teacher/entropy 0.3034 (0.2798) teacher/usage_max 0.7929 (0.7431) teacher/usage_min 0.0198 (0.0530) teacher/usage_std 0.3321 (0.2982) nleep/row_max_mean 1197.7192 (1197.2775) nleep/row_max_std 14.6399 (16.0157) nleep/row_min_mean 1190.9185 (1190.2078) lr 5.7422e-04 eta 0:25:25
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,817
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,995
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.3%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [35/50] batch [20/244] time 0.085 (0.408) data 0.000 (0.012) loss 1.6569 (1.7224) teacher_loss 0.9037 (0.8905) loss_zs_kd 0.0540 (0.0534) loss_oracle 0.4554 (0.5109) kd_loss 0.4985 (0.5498) acc 68.7500 (76.5625) gate/entropy 1.0199 (1.0204) gate/usage_max 0.5249 (0.5243) gate/usage_min 0.2202 (0.2206) gate/usage_std 0.1362 (0.1358) teacher/entropy 0.2915 (0.2965) teacher/usage_max 0.8071 (0.7337) teacher/usage_min 0.0423 (0.0595) teacher/usage_std 0.3379 (0.2916) nleep/row_max_mean 1196.8180 (1195.8939) nleep/row_max_std 15.3629 (15.5740) nleep/row_min_mean 1190.0858 (1188.9422) lr 5.1825e-04 eta 0:26:24
epoch [35/50] batch [40/244] time 0.090 (0.275) data 0.000 (0.006) loss 1.5968 (1.7453) teacher_loss 0.7986 (0.9087) loss_zs_kd 0.0469 (0.0561) loss_oracle 0.4685 (0.5076) kd_loss 0.5405 (0.5548) acc 78.1250 (75.8594) gate/entropy 1.0202 (1.0203) gate/usage_max 0.5246 (0.5245) gate/usage_min 0.2206 (0.2205) gate/usage_std 0.1360 (0.1359) teacher/entropy 0.2937 (0.2953) teacher/usage_max 0.7466 (0.7280) teacher/usage_min 0.0398 (0.0582) teacher/usage_std 0.3007 (0.2879) nleep/row_max_mean 1194.5807 (1196.0596) nleep/row_max_std 12.8253 (15.6596) nleep/row_min_mean 1188.0427 (1189.0866) lr 5.1825e-04 eta 0:17:44
epoch [35/50] batch [60/244] time 0.468 (0.296) data 0.000 (0.004) loss 1.3913 (1.7351) teacher_loss 0.6347 (0.8932) loss_zs_kd 0.0433 (0.0560) loss_oracle 0.5015 (0.5083) kd_loss 0.4843 (0.5597) acc 87.5000 (76.4062) gate/entropy 1.0194 (1.0201) gate/usage_max 0.5256 (0.5247) gate/usage_min 0.2202 (0.2205) gate/usage_std 0.1367 (0.1361) teacher/entropy 0.3787 (0.2937) teacher/usage_max 0.7189 (0.7232) teacher/usage_min 0.1051 (0.0582) teacher/usage_std 0.2741 (0.2850) nleep/row_max_mean 1192.0784 (1196.2644) nleep/row_max_std 13.8324 (15.4778) nleep/row_min_mean 1186.5552 (1189.3825) lr 5.1825e-04 eta 0:18:58
epoch [35/50] batch [80/244] time 0.483 (0.344) data 0.000 (0.003) loss 1.5317 (1.7256) teacher_loss 0.7074 (0.8859) loss_zs_kd 0.0553 (0.0565) loss_oracle 0.5220 (0.5094) kd_loss 0.5357 (0.5567) acc 81.2500 (76.3672) gate/entropy 1.0193 (1.0199) gate/usage_max 0.5258 (0.5250) gate/usage_min 0.2202 (0.2204) gate/usage_std 0.1368 (0.1362) teacher/entropy 0.2631 (0.2894) teacher/usage_max 0.7994 (0.7331) teacher/usage_min 0.0707 (0.0583) teacher/usage_std 0.3305 (0.2909) nleep/row_max_mean 1198.9883 (1196.1395) nleep/row_max_std 15.3298 (15.1198) nleep/row_min_mean 1191.3734 (1189.2625) lr 5.1825e-04 eta 0:21:54
epoch [35/50] batch [100/244] time 0.514 (0.375) data 0.000 (0.003) loss 1.5219 (1.7196) teacher_loss 0.7839 (0.8784) loss_zs_kd 0.0487 (0.0561) loss_oracle 0.5019 (0.5136) kd_loss 0.4627 (0.5563) acc 75.0000 (76.6875) gate/entropy 1.0190 (1.0198) gate/usage_max 0.5262 (0.5252) gate/usage_min 0.2202 (0.2204) gate/usage_std 0.1371 (0.1364) teacher/entropy 0.3306 (0.2881) teacher/usage_max 0.8119 (0.7355) teacher/usage_min 0.0914 (0.0596) teacher/usage_std 0.3384 (0.2923) nleep/row_max_mean 1195.3977 (1196.2262) nleep/row_max_std 14.9229 (14.9161) nleep/row_min_mean 1188.9050 (1189.3635) lr 5.1825e-04 eta 0:23:46
epoch [35/50] batch [120/244] time 0.444 (0.392) data 0.000 (0.002) loss 1.8469 (1.7132) teacher_loss 0.9416 (0.8729) loss_zs_kd 0.0438 (0.0555) loss_oracle 0.5016 (0.5138) kd_loss 0.6326 (0.5556) acc 84.3750 (76.8490) gate/entropy 1.0186 (1.0196) gate/usage_max 0.5268 (0.5254) gate/usage_min 0.2200 (0.2203) gate/usage_std 0.1375 (0.1365) teacher/entropy 0.2462 (0.2854) teacher/usage_max 0.6859 (0.7398) teacher/usage_min 0.0570 (0.0587) teacher/usage_std 0.2623 (0.2950) nleep/row_max_mean 1197.9219 (1196.3223) nleep/row_max_std 14.0952 (14.9098) nleep/row_min_mean 1190.9983 (1189.4279) lr 5.1825e-04 eta 0:24:43
epoch [35/50] batch [140/244] time 0.474 (0.371) data 0.000 (0.002) loss 1.4971 (1.7055) teacher_loss 0.6828 (0.8640) loss_zs_kd 0.0432 (0.0545) loss_oracle 0.5344 (0.5144) kd_loss 0.5254 (0.5571) acc 81.2500 (76.9866) gate/entropy 1.0180 (1.0194) gate/usage_max 0.5275 (0.5256) gate/usage_min 0.2197 (0.2203) gate/usage_std 0.1379 (0.1367) teacher/entropy 0.2976 (0.2840) teacher/usage_max 0.7715 (0.7395) teacher/usage_min 0.1061 (0.0588) teacher/usage_std 0.3099 (0.2949) nleep/row_max_mean 1198.7397 (1196.3499) nleep/row_max_std 15.0549 (14.7811) nleep/row_min_mean 1191.7528 (1189.4476) lr 5.1825e-04 eta 0:23:14
epoch [35/50] batch [160/244] time 0.085 (0.362) data 0.000 (0.002) loss 1.9877 (1.7063) teacher_loss 1.1092 (0.8623) loss_zs_kd 0.0620 (0.0546) loss_oracle 0.5229 (0.5165) kd_loss 0.5861 (0.5585) acc 62.5000 (76.9531) gate/entropy 1.0179 (1.0193) gate/usage_max 0.5276 (0.5258) gate/usage_min 0.2198 (0.2202) gate/usage_std 0.1380 (0.1368) teacher/entropy 0.1991 (0.2809) teacher/usage_max 0.8045 (0.7414) teacher/usage_min 0.0158 (0.0582) teacher/usage_std 0.3398 (0.2960) nleep/row_max_mean 1196.7606 (1196.4607) nleep/row_max_std 13.2260 (14.7405) nleep/row_min_mean 1189.4858 (1189.5401) lr 5.1825e-04 eta 0:22:33
epoch [35/50] batch [180/244] time 0.081 (0.342) data 0.000 (0.002) loss 1.9997 (1.7174) teacher_loss 1.0993 (0.8721) loss_zs_kd 0.0679 (0.0547) loss_oracle 0.5506 (0.5181) kd_loss 0.5912 (0.5589) acc 75.0000 (76.7361) gate/entropy 1.0176 (1.0191) gate/usage_max 0.5280 (0.5261) gate/usage_min 0.2198 (0.2202) gate/usage_std 0.1383 (0.1370) teacher/entropy 0.1590 (0.2783) teacher/usage_max 0.8510 (0.7441) teacher/usage_min 0.0105 (0.0572) teacher/usage_std 0.3697 (0.2978) nleep/row_max_mean 1197.9128 (1196.4981) nleep/row_max_std 13.3060 (14.6347) nleep/row_min_mean 1190.2598 (1189.5757) lr 5.1825e-04 eta 0:21:14
epoch [35/50] batch [200/244] time 0.457 (0.324) data 0.001 (0.001) loss 1.3147 (1.7247) teacher_loss 0.4451 (0.8806) loss_zs_kd 0.0448 (0.0557) loss_oracle 0.5257 (0.5173) kd_loss 0.5843 (0.5576) acc 93.7500 (76.5000) gate/entropy 1.0174 (1.0189) gate/usage_max 0.5284 (0.5263) gate/usage_min 0.2199 (0.2201) gate/usage_std 0.1385 (0.1371) teacher/entropy 0.2386 (0.2783) teacher/usage_max 0.7594 (0.7456) teacher/usage_min 0.0466 (0.0574) teacher/usage_std 0.3072 (0.2986) nleep/row_max_mean 1195.7324 (1196.4586) nleep/row_max_std 16.0846 (14.5896) nleep/row_min_mean 1188.6093 (1189.5588) lr 5.1825e-04 eta 0:19:58
epoch [35/50] batch [220/244] time 0.117 (0.307) data 0.000 (0.001) loss 1.7677 (1.7237) teacher_loss 0.9630 (0.8795) loss_zs_kd 0.0596 (0.0557) loss_oracle 0.5188 (0.5171) kd_loss 0.5155 (0.5578) acc 75.0000 (76.5909) gate/entropy 1.0169 (1.0188) gate/usage_max 0.5290 (0.5265) gate/usage_min 0.2197 (0.2201) gate/usage_std 0.1389 (0.1373) teacher/entropy 0.2777 (0.2775) teacher/usage_max 0.7973 (0.7460) teacher/usage_min 0.0402 (0.0567) teacher/usage_std 0.3318 (0.2990) nleep/row_max_mean 1195.4620 (1196.3902) nleep/row_max_std 10.5931 (14.5925) nleep/row_min_mean 1188.3435 (1189.4828) lr 5.1825e-04 eta 0:18:49
epoch [35/50] batch [240/244] time 0.090 (0.290) data 0.000 (0.001) loss 1.7147 (1.7316) teacher_loss 0.8970 (0.8885) loss_zs_kd 0.0375 (0.0554) loss_oracle 0.5205 (0.5163) kd_loss 0.5387 (0.5572) acc 78.1250 (76.3802) gate/entropy 1.0166 (1.0186) gate/usage_max 0.5293 (0.5267) gate/usage_min 0.2196 (0.2201) gate/usage_std 0.1392 (0.1374) teacher/entropy 0.2754 (0.2772) teacher/usage_max 0.7664 (0.7470) teacher/usage_min 0.0250 (0.0570) teacher/usage_std 0.3153 (0.2996) nleep/row_max_mean 1196.6754 (1196.3996) nleep/row_max_std 14.8163 (14.6461) nleep/row_min_mean 1190.0386 (1189.4895) lr 5.1825e-04 eta 0:17:41
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,819
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,005
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.5%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [36/50] batch [20/244] time 0.443 (0.517) data 0.000 (0.013) loss 1.8797 (1.8295) teacher_loss 1.1255 (1.0069) loss_zs_kd 0.0458 (0.0609) loss_oracle 0.4724 (0.4943) kd_loss 0.4951 (0.5450) acc 71.8750 (73.7500) gate/entropy 1.0161 (1.0162) gate/usage_max 0.5299 (0.5299) gate/usage_min 0.2195 (0.2194) gate/usage_std 0.1396 (0.1396) teacher/entropy 0.2815 (0.2829) teacher/usage_max 0.8167 (0.7533) teacher/usage_min 0.0340 (0.0599) teacher/usage_std 0.3450 (0.3029) nleep/row_max_mean 1191.0146 (1195.2564) nleep/row_max_std 13.6103 (13.9383) nleep/row_min_mean 1184.4099 (1188.5782) lr 4.6417e-04 eta 0:31:20
epoch [36/50] batch [40/244] time 0.471 (0.503) data 0.000 (0.007) loss 1.8369 (1.7680) teacher_loss 1.0309 (0.9490) loss_zs_kd 0.0644 (0.0583) loss_oracle 0.5073 (0.4923) kd_loss 0.5201 (0.5437) acc 68.7500 (75.0000) gate/entropy 1.0157 (1.0161) gate/usage_max 0.5306 (0.5300) gate/usage_min 0.2192 (0.2194) gate/usage_std 0.1400 (0.1397) teacher/entropy 0.2705 (0.2823) teacher/usage_max 0.8012 (0.7554) teacher/usage_min 0.0529 (0.0578) teacher/usage_std 0.3330 (0.3048) nleep/row_max_mean 1194.4211 (1195.8125) nleep/row_max_std 13.1276 (14.3011) nleep/row_min_mean 1187.8350 (1189.1160) lr 4.6417e-04 eta 0:30:19
epoch [36/50] batch [60/244] time 0.080 (0.485) data 0.000 (0.004) loss 1.3156 (1.7500) teacher_loss 0.5728 (0.9326) loss_zs_kd 0.0416 (0.0548) loss_oracle 0.4790 (0.4937) kd_loss 0.4825 (0.5432) acc 81.2500 (75.2083) gate/entropy 1.0158 (1.0159) gate/usage_max 0.5305 (0.5302) gate/usage_min 0.2196 (0.2194) gate/usage_std 0.1399 (0.1398) teacher/entropy 0.3071 (0.2769) teacher/usage_max 0.8068 (0.7634) teacher/usage_min 0.0777 (0.0590) teacher/usage_std 0.3351 (0.3096) nleep/row_max_mean 1194.9017 (1196.1702) nleep/row_max_std 11.2322 (14.4193) nleep/row_min_mean 1188.5615 (1189.4100) lr 4.6417e-04 eta 0:29:07
epoch [36/50] batch [80/244] time 0.486 (0.425) data 0.000 (0.003) loss 1.7430 (1.7286) teacher_loss 0.9045 (0.9109) loss_zs_kd 0.0776 (0.0534) loss_oracle 0.5064 (0.4944) kd_loss 0.5465 (0.5438) acc 81.2500 (75.9766) gate/entropy 1.0154 (1.0158) gate/usage_max 0.5310 (0.5304) gate/usage_min 0.2194 (0.2194) gate/usage_std 0.1403 (0.1399) teacher/entropy 0.2583 (0.2786) teacher/usage_max 0.7761 (0.7605) teacher/usage_min 0.0238 (0.0607) teacher/usage_std 0.3212 (0.3074) nleep/row_max_mean 1196.1492 (1196.2645) nleep/row_max_std 13.8487 (14.3819) nleep/row_min_mean 1188.5011 (1189.4628) lr 4.6417e-04 eta 0:25:20
epoch [36/50] batch [100/244] time 0.090 (0.386) data 0.000 (0.003) loss 1.6887 (1.7123) teacher_loss 0.8335 (0.8943) loss_zs_kd 0.0482 (0.0542) loss_oracle 0.5201 (0.4938) kd_loss 0.5711 (0.5440) acc 78.1250 (76.4062) gate/entropy 1.0151 (1.0157) gate/usage_max 0.5314 (0.5305) gate/usage_min 0.2193 (0.2194) gate/usage_std 0.1406 (0.1400) teacher/entropy 0.2094 (0.2768) teacher/usage_max 0.8065 (0.7616) teacher/usage_min 0.0143 (0.0565) teacher/usage_std 0.3413 (0.3087) nleep/row_max_mean 1196.7285 (1196.3375) nleep/row_max_std 13.6030 (14.3233) nleep/row_min_mean 1189.1138 (1189.4533) lr 4.6417e-04 eta 0:22:54
epoch [36/50] batch [120/244] time 0.559 (0.379) data 0.000 (0.002) loss 1.5856 (1.7207) teacher_loss 0.7270 (0.8980) loss_zs_kd 0.0486 (0.0550) loss_oracle 0.5292 (0.4953) kd_loss 0.5697 (0.5475) acc 84.3750 (76.6927) gate/entropy 1.0146 (1.0155) gate/usage_max 0.5320 (0.5307) gate/usage_min 0.2190 (0.2193) gate/usage_std 0.1410 (0.1401) teacher/entropy 0.2701 (0.2731) teacher/usage_max 0.7354 (0.7616) teacher/usage_min 0.0569 (0.0567) teacher/usage_std 0.2909 (0.3086) nleep/row_max_mean 1200.9514 (1196.2707) nleep/row_max_std 15.4901 (14.2281) nleep/row_min_mean 1193.4672 (1189.3489) lr 4.6417e-04 eta 0:22:21
epoch [36/50] batch [140/244] time 0.536 (0.398) data 0.000 (0.002) loss 1.5845 (1.7192) teacher_loss 0.7461 (0.8968) loss_zs_kd 0.0613 (0.0545) loss_oracle 0.5128 (0.4950) kd_loss 0.5513 (0.5476) acc 84.3750 (76.8527) gate/entropy 1.0145 (1.0154) gate/usage_max 0.5320 (0.5309) gate/usage_min 0.2191 (0.2193) gate/usage_std 0.1410 (0.1403) teacher/entropy 0.2723 (0.2757) teacher/usage_max 0.7510 (0.7578) teacher/usage_min 0.0230 (0.0559) teacher/usage_std 0.3068 (0.3064) nleep/row_max_mean 1195.8965 (1196.3188) nleep/row_max_std 10.6492 (14.2982) nleep/row_min_mean 1188.8896 (1189.4005) lr 4.6417e-04 eta 0:23:22
epoch [36/50] batch [160/244] time 0.496 (0.410) data 0.000 (0.002) loss 1.6697 (1.7277) teacher_loss 0.8330 (0.9036) loss_zs_kd 0.0519 (0.0539) loss_oracle 0.4958 (0.4968) kd_loss 0.5628 (0.5487) acc 78.1250 (76.7383) gate/entropy 1.0142 (1.0152) gate/usage_max 0.5325 (0.5311) gate/usage_min 0.2190 (0.2192) gate/usage_std 0.1413 (0.1404) teacher/entropy 0.2478 (0.2757) teacher/usage_max 0.7720 (0.7564) teacher/usage_min 0.0526 (0.0573) teacher/usage_std 0.3142 (0.3054) nleep/row_max_mean 1198.1260 (1196.3688) nleep/row_max_std 13.3018 (14.3011) nleep/row_min_mean 1190.7395 (1189.4333) lr 4.6417e-04 eta 0:23:54
epoch [36/50] batch [180/244] time 0.472 (0.419) data 0.000 (0.002) loss 1.6761 (1.7265) teacher_loss 0.8938 (0.9020) loss_zs_kd 0.0423 (0.0536) loss_oracle 0.4726 (0.4965) kd_loss 0.5249 (0.5495) acc 75.0000 (76.5799) gate/entropy 1.0138 (1.0151) gate/usage_max 0.5330 (0.5313) gate/usage_min 0.2189 (0.2192) gate/usage_std 0.1417 (0.1405) teacher/entropy 0.2909 (0.2721) teacher/usage_max 0.7635 (0.7595) teacher/usage_min 0.0433 (0.0550) teacher/usage_std 0.3103 (0.3076) nleep/row_max_mean 1200.3325 (1196.4971) nleep/row_max_std 15.9317 (14.2922) nleep/row_min_mean 1193.7190 (1189.5422) lr 4.6417e-04 eta 0:24:16
epoch [36/50] batch [200/244] time 0.440 (0.401) data 0.000 (0.001) loss 1.8572 (1.7280) teacher_loss 1.0091 (0.9046) loss_zs_kd 0.0758 (0.0535) loss_oracle 0.4772 (0.4960) kd_loss 0.5717 (0.5487) acc 71.8750 (76.5312) gate/entropy 1.0136 (1.0150) gate/usage_max 0.5332 (0.5315) gate/usage_min 0.2189 (0.2192) gate/usage_std 0.1418 (0.1406) teacher/entropy 0.3081 (0.2714) teacher/usage_max 0.6788 (0.7613) teacher/usage_min 0.0397 (0.0552) teacher/usage_std 0.2635 (0.3086) nleep/row_max_mean 1195.1136 (1196.6631) nleep/row_max_std 14.5030 (14.3078) nleep/row_min_mean 1187.8142 (1189.6541) lr 4.6417e-04 eta 0:23:06
epoch [36/50] batch [220/244] time 0.089 (0.390) data 0.000 (0.001) loss 1.8256 (1.7239) teacher_loss 0.8537 (0.8998) loss_zs_kd 0.0761 (0.0532) loss_oracle 0.5288 (0.4967) kd_loss 0.6695 (0.5491) acc 71.8750 (76.5625) gate/entropy 1.0129 (1.0148) gate/usage_max 0.5340 (0.5316) gate/usage_min 0.2186 (0.2192) gate/usage_std 0.1424 (0.1408) teacher/entropy 0.1984 (0.2696) teacher/usage_max 0.7016 (0.7628) teacher/usage_min 0.0848 (0.0544) teacher/usage_std 0.2657 (0.3097) nleep/row_max_mean 1197.7910 (1196.8448) nleep/row_max_std 12.8893 (14.3607) nleep/row_min_mean 1190.3652 (1189.7921) lr 4.6417e-04 eta 0:22:20
epoch [36/50] batch [240/244] time 0.468 (0.387) data 0.000 (0.001) loss 1.7644 (1.7188) teacher_loss 0.9617 (0.8941) loss_zs_kd 0.0678 (0.0530) loss_oracle 0.4458 (0.4966) kd_loss 0.5459 (0.5498) acc 68.7500 (76.6797) gate/entropy 1.0129 (1.0147) gate/usage_max 0.5341 (0.5318) gate/usage_min 0.2188 (0.2191) gate/usage_std 0.1424 (0.1409) teacher/entropy 0.2972 (0.2686) teacher/usage_max 0.7289 (0.7630) teacher/usage_min 0.0528 (0.0544) teacher/usage_std 0.2877 (0.3098) nleep/row_max_mean 1203.8538 (1197.0339) nleep/row_max_std 16.6555 (14.4010) nleep/row_min_mean 1196.6100 (1189.9683) lr 4.6417e-04 eta 0:22:05
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,825
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,997
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.3%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [37/50] batch [20/244] time 0.496 (0.521) data 0.000 (0.016) loss 1.3249 (1.7178) teacher_loss 0.4156 (0.9034) loss_zs_kd 0.0174 (0.0534) loss_oracle 0.5477 (0.4897) kd_loss 0.6267 (0.5428) acc 93.7500 (76.0938) gate/entropy 1.0128 (1.0128) gate/usage_max 0.5342 (0.5342) gate/usage_min 0.2188 (0.2187) gate/usage_std 0.1425 (0.1425) teacher/entropy 0.2354 (0.2760) teacher/usage_max 0.7109 (0.7615) teacher/usage_min 0.0957 (0.0642) teacher/usage_std 0.2699 (0.3070) nleep/row_max_mean 1203.5499 (1197.4338) nleep/row_max_std 17.4101 (14.5111) nleep/row_min_mean 1195.7109 (1190.4235) lr 4.1221e-04 eta 0:29:29
epoch [37/50] batch [40/244] time 0.081 (0.485) data 0.000 (0.008) loss 1.5767 (1.7012) teacher_loss 0.8430 (0.8882) loss_zs_kd 0.0298 (0.0530) loss_oracle 0.4818 (0.4928) kd_loss 0.4779 (0.5401) acc 81.2500 (76.7188) gate/entropy 1.0120 (1.0126) gate/usage_max 0.5352 (0.5344) gate/usage_min 0.2183 (0.2186) gate/usage_std 0.1432 (0.1427) teacher/entropy 0.3295 (0.2792) teacher/usage_max 0.7751 (0.7609) teacher/usage_min 0.0658 (0.0654) teacher/usage_std 0.3147 (0.3064) nleep/row_max_mean 1196.8606 (1197.1723) nleep/row_max_std 12.3733 (14.1021) nleep/row_min_mean 1190.6550 (1190.1564) lr 4.1221e-04 eta 0:27:16
epoch [37/50] batch [60/244] time 0.547 (0.413) data 0.001 (0.005) loss 1.5011 (1.7135) teacher_loss 0.6919 (0.8908) loss_zs_kd 0.0489 (0.0532) loss_oracle 0.4993 (0.4964) kd_loss 0.5352 (0.5479) acc 81.2500 (76.8229) gate/entropy 1.0120 (1.0125) gate/usage_max 0.5352 (0.5346) gate/usage_min 0.2185 (0.2186) gate/usage_std 0.1432 (0.1428) teacher/entropy 0.2892 (0.2691) teacher/usage_max 0.7560 (0.7635) teacher/usage_min 0.0818 (0.0635) teacher/usage_std 0.3007 (0.3087) nleep/row_max_mean 1195.3198 (1197.2715) nleep/row_max_std 14.7872 (14.2609) nleep/row_min_mean 1188.9502 (1190.2145) lr 4.1221e-04 eta 0:23:06
epoch [37/50] batch [80/244] time 0.483 (0.382) data 0.000 (0.004) loss 1.8022 (1.7252) teacher_loss 0.9793 (0.9055) loss_zs_kd 0.0454 (0.0532) loss_oracle 0.4561 (0.4904) kd_loss 0.5722 (0.5479) acc 78.1250 (76.6797) gate/entropy 1.0119 (1.0124) gate/usage_max 0.5353 (0.5348) gate/usage_min 0.2185 (0.2186) gate/usage_std 0.1433 (0.1429) teacher/entropy 0.2310 (0.2676) teacher/usage_max 0.7755 (0.7647) teacher/usage_min 0.0313 (0.0604) teacher/usage_std 0.3195 (0.3099) nleep/row_max_mean 1196.9614 (1197.4199) nleep/row_max_std 16.2135 (14.0884) nleep/row_min_mean 1189.1636 (1190.3431) lr 4.1221e-04 eta 0:21:14
epoch [37/50] batch [100/244] time 0.497 (0.385) data 0.000 (0.003) loss 1.4207 (1.7376) teacher_loss 0.5823 (0.9173) loss_zs_kd 0.0503 (0.0547) loss_oracle 0.4806 (0.4908) kd_loss 0.5729 (0.5476) acc 78.1250 (76.0312) gate/entropy 1.0116 (1.0122) gate/usage_max 0.5357 (0.5349) gate/usage_min 0.2184 (0.2186) gate/usage_std 0.1435 (0.1430) teacher/entropy 0.2611 (0.2656) teacher/usage_max 0.7386 (0.7674) teacher/usage_min 0.0539 (0.0590) teacher/usage_std 0.2934 (0.3117) nleep/row_max_mean 1198.3938 (1197.5413) nleep/row_max_std 13.8300 (14.2933) nleep/row_min_mean 1190.6477 (1190.4356) lr 4.1221e-04 eta 0:21:17
epoch [37/50] batch [120/244] time 0.496 (0.402) data 0.000 (0.003) loss 1.5081 (1.7326) teacher_loss 0.6889 (0.9102) loss_zs_kd 0.0750 (0.0557) loss_oracle 0.4724 (0.4921) kd_loss 0.5455 (0.5485) acc 81.2500 (76.3021) gate/entropy 1.0116 (1.0121) gate/usage_max 0.5357 (0.5351) gate/usage_min 0.2186 (0.2186) gate/usage_std 0.1435 (0.1431) teacher/entropy 0.3136 (0.2632) teacher/usage_max 0.7053 (0.7689) teacher/usage_min 0.0407 (0.0566) teacher/usage_std 0.2771 (0.3131) nleep/row_max_mean 1193.1962 (1197.3235) nleep/row_max_std 15.6455 (14.3334) nleep/row_min_mean 1186.3918 (1190.2048) lr 4.1221e-04 eta 0:22:03
epoch [37/50] batch [140/244] time 0.499 (0.413) data 0.000 (0.002) loss 1.8640 (1.7383) teacher_loss 0.9774 (0.9154) loss_zs_kd 0.0591 (0.0549) loss_oracle 0.5395 (0.4959) kd_loss 0.5874 (0.5476) acc 71.8750 (76.1607) gate/entropy 1.0111 (1.0120) gate/usage_max 0.5363 (0.5352) gate/usage_min 0.2183 (0.2185) gate/usage_std 0.1439 (0.1432) teacher/entropy 0.1969 (0.2605) teacher/usage_max 0.8015 (0.7731) teacher/usage_min 0.0479 (0.0550) teacher/usage_std 0.3337 (0.3160) nleep/row_max_mean 1196.2822 (1197.3679) nleep/row_max_std 13.1832 (14.2862) nleep/row_min_mean 1188.9597 (1190.2044) lr 4.1221e-04 eta 0:22:31
epoch [37/50] batch [160/244] time 0.080 (0.416) data 0.000 (0.002) loss 2.0174 (1.7338) teacher_loss 1.1979 (0.9081) loss_zs_kd 0.0553 (0.0554) loss_oracle 0.5289 (0.4992) kd_loss 0.5274 (0.5484) acc 71.8750 (76.4844) gate/entropy 1.0108 (1.0119) gate/usage_max 0.5367 (0.5354) gate/usage_min 0.2184 (0.2185) gate/usage_std 0.1442 (0.1433) teacher/entropy 0.1821 (0.2583) teacher/usage_max 0.8939 (0.7748) teacher/usage_min 0.0322 (0.0550) teacher/usage_std 0.3968 (0.3171) nleep/row_max_mean 1196.5162 (1197.3688) nleep/row_max_std 12.3184 (14.2787) nleep/row_min_mean 1188.8567 (1190.1835) lr 4.1221e-04 eta 0:22:34
epoch [37/50] batch [180/244] time 0.442 (0.398) data 0.000 (0.002) loss 2.2048 (1.7323) teacher_loss 1.3385 (0.9054) loss_zs_kd 0.0611 (0.0552) loss_oracle 0.5247 (0.5017) kd_loss 0.5735 (0.5484) acc 65.6250 (76.4931) gate/entropy 1.0105 (1.0118) gate/usage_max 0.5370 (0.5355) gate/usage_min 0.2182 (0.2185) gate/usage_std 0.1445 (0.1434) teacher/entropy 0.2979 (0.2568) teacher/usage_max 0.6896 (0.7765) teacher/usage_min 0.0490 (0.0546) teacher/usage_std 0.2664 (0.3182) nleep/row_max_mean 1202.3401 (1197.5419) nleep/row_max_std 15.3195 (14.2993) nleep/row_min_mean 1194.2898 (1190.2988) lr 4.1221e-04 eta 0:21:29
epoch [37/50] batch [200/244] time 0.487 (0.387) data 0.000 (0.002) loss 1.5369 (1.7267) teacher_loss 0.7028 (0.9006) loss_zs_kd 0.0599 (0.0549) loss_oracle 0.5060 (0.5012) kd_loss 0.5511 (0.5481) acc 84.3750 (76.5625) gate/entropy 1.0105 (1.0116) gate/usage_max 0.5371 (0.5357) gate/usage_min 0.2184 (0.2185) gate/usage_std 0.1445 (0.1435) teacher/entropy 0.1921 (0.2554) teacher/usage_max 0.8516 (0.7784) teacher/usage_min 0.0413 (0.0542) teacher/usage_std 0.3675 (0.3194) nleep/row_max_mean 1198.5417 (1197.5802) nleep/row_max_std 14.3371 (14.2817) nleep/row_min_mean 1190.7312 (1190.3287) lr 4.1221e-04 eta 0:20:44
epoch [37/50] batch [220/244] time 0.495 (0.387) data 0.000 (0.002) loss 1.7708 (1.7277) teacher_loss 0.9621 (0.9018) loss_zs_kd 0.0678 (0.0546) loss_oracle 0.4230 (0.5007) kd_loss 0.5633 (0.5483) acc 75.0000 (76.6335) gate/entropy 1.0099 (1.0115) gate/usage_max 0.5378 (0.5358) gate/usage_min 0.2180 (0.2184) gate/usage_std 0.1450 (0.1436) teacher/entropy 0.3004 (0.2542) teacher/usage_max 0.6963 (0.7794) teacher/usage_min 0.0326 (0.0541) teacher/usage_std 0.2745 (0.3201) nleep/row_max_mean 1197.1343 (1197.5677) nleep/row_max_std 12.6912 (14.2044) nleep/row_min_mean 1190.5039 (1190.3342) lr 4.1221e-04 eta 0:20:37
epoch [37/50] batch [240/244] time 0.494 (0.396) data 0.000 (0.001) loss 1.9474 (1.7298) teacher_loss 1.1775 (0.9028) loss_zs_kd 0.0488 (0.0549) loss_oracle 0.4736 (0.5008) kd_loss 0.5087 (0.5491) acc 71.8750 (76.6927) gate/entropy 1.0095 (1.0114) gate/usage_max 0.5383 (0.5360) gate/usage_min 0.2179 (0.2184) gate/usage_std 0.1453 (0.1437) teacher/entropy 0.2515 (0.2535) teacher/usage_max 0.8267 (0.7791) teacher/usage_min 0.0306 (0.0542) teacher/usage_std 0.3518 (0.3199) nleep/row_max_mean 1196.6610 (1197.5861) nleep/row_max_std 11.9618 (14.2531) nleep/row_min_mean 1189.9802 (1190.3442) lr 4.1221e-04 eta 0:20:57
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,826
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,006
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.5%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [38/50] batch [20/244] time 0.082 (0.381) data 0.000 (0.018) loss 1.8349 (1.7554) teacher_loss 0.9665 (0.9279) loss_zs_kd 0.0398 (0.0564) loss_oracle 0.5562 (0.4975) kd_loss 0.5703 (0.5505) acc 75.0000 (75.0000) gate/entropy 1.0097 (1.0097) gate/usage_max 0.5380 (0.5381) gate/usage_min 0.2182 (0.2181) gate/usage_std 0.1451 (0.1451) teacher/entropy 0.2208 (0.2525) teacher/usage_max 0.7900 (0.7764) teacher/usage_min 0.0446 (0.0540) teacher/usage_std 0.3267 (0.3175) nleep/row_max_mean 1200.3739 (1197.8635) nleep/row_max_std 16.3704 (14.7570) nleep/row_min_mean 1193.4678 (1190.7461) lr 3.6258e-04 eta 0:20:02
epoch [38/50] batch [40/244] time 0.511 (0.360) data 0.000 (0.009) loss 1.7234 (1.7097) teacher_loss 0.8045 (0.8851) loss_zs_kd 0.0393 (0.0519) loss_oracle 0.5160 (0.4983) kd_loss 0.6412 (0.5495) acc 75.0000 (76.6406) gate/entropy 1.0099 (1.0096) gate/usage_max 0.5379 (0.5382) gate/usage_min 0.2184 (0.2181) gate/usage_std 0.1450 (0.1452) teacher/entropy 0.2165 (0.2469) teacher/usage_max 0.7073 (0.7845) teacher/usage_min 0.0463 (0.0534) teacher/usage_std 0.2767 (0.3229) nleep/row_max_mean 1195.9166 (1198.1984) nleep/row_max_std 15.2934 (14.8371) nleep/row_min_mean 1188.5592 (1190.9601) lr 3.6258e-04 eta 0:18:47
epoch [38/50] batch [60/244] time 0.080 (0.326) data 0.000 (0.006) loss 1.9009 (1.6948) teacher_loss 1.1268 (0.8715) loss_zs_kd 0.0554 (0.0513) loss_oracle 0.4427 (0.5009) kd_loss 0.5251 (0.5473) acc 68.7500 (77.3958) gate/entropy 1.0092 (1.0095) gate/usage_max 0.5387 (0.5383) gate/usage_min 0.2180 (0.2181) gate/usage_std 0.1456 (0.1453) teacher/entropy 0.3219 (0.2507) teacher/usage_max 0.7264 (0.7826) teacher/usage_min 0.1003 (0.0542) teacher/usage_std 0.2795 (0.3216) nleep/row_max_mean 1196.0730 (1198.1795) nleep/row_max_std 15.4726 (14.5385) nleep/row_min_mean 1188.8904 (1190.9554) lr 3.6258e-04 eta 0:16:54
epoch [38/50] batch [80/244] time 0.495 (0.353) data 0.000 (0.005) loss 2.2873 (1.7135) teacher_loss 1.4008 (0.8853) loss_zs_kd 0.0441 (0.0527) loss_oracle 0.5566 (0.5034) kd_loss 0.5861 (0.5501) acc 65.6250 (76.8750) gate/entropy 1.0091 (1.0094) gate/usage_max 0.5388 (0.5385) gate/usage_min 0.2181 (0.2181) gate/usage_std 0.1457 (0.1454) teacher/entropy 0.2023 (0.2475) teacher/usage_max 0.8006 (0.7829) teacher/usage_min 0.0986 (0.0538) teacher/usage_std 0.3304 (0.3220) nleep/row_max_mean 1199.2711 (1198.3966) nleep/row_max_std 15.6620 (14.5706) nleep/row_min_mean 1191.6809 (1191.1730) lr 3.6258e-04 eta 0:18:12
epoch [38/50] batch [100/244] time 0.494 (0.380) data 0.000 (0.004) loss 2.3109 (1.7113) teacher_loss 1.4141 (0.8849) loss_zs_kd 0.0848 (0.0533) loss_oracle 0.5319 (0.5037) kd_loss 0.5884 (0.5478) acc 53.1250 (76.7500) gate/entropy 1.0086 (1.0093) gate/usage_max 0.5394 (0.5386) gate/usage_min 0.2178 (0.2181) gate/usage_std 0.1460 (0.1455) teacher/entropy 0.2690 (0.2502) teacher/usage_max 0.7069 (0.7825) teacher/usage_min 0.0519 (0.0559) teacher/usage_std 0.2752 (0.3215) nleep/row_max_mean 1199.5062 (1198.1176) nleep/row_max_std 14.8953 (14.3812) nleep/row_min_mean 1191.9362 (1190.9162) lr 3.6258e-04 eta 0:19:28
epoch [38/50] batch [120/244] time 0.467 (0.398) data 0.000 (0.003) loss 1.4489 (1.7134) teacher_loss 0.7165 (0.8886) loss_zs_kd 0.0460 (0.0536) loss_oracle 0.4900 (0.5028) kd_loss 0.4645 (0.5466) acc 84.3750 (76.7448) gate/entropy 1.0086 (1.0092) gate/usage_max 0.5394 (0.5387) gate/usage_min 0.2179 (0.2180) gate/usage_std 0.1461 (0.1456) teacher/entropy 0.2983 (0.2524) teacher/usage_max 0.8225 (0.7810) teacher/usage_min 0.0317 (0.0553) teacher/usage_std 0.3490 (0.3207) nleep/row_max_mean 1198.4735 (1198.0978) nleep/row_max_std 16.8034 (14.3839) nleep/row_min_mean 1191.1636 (1190.9037) lr 3.6258e-04 eta 0:20:14
epoch [38/50] batch [140/244] time 0.095 (0.391) data 0.000 (0.003) loss 1.6537 (1.7164) teacher_loss 0.8093 (0.8882) loss_zs_kd 0.0497 (0.0539) loss_oracle 0.5019 (0.5065) kd_loss 0.5686 (0.5480) acc 75.0000 (76.8973) gate/entropy 1.0084 (1.0091) gate/usage_max 0.5397 (0.5389) gate/usage_min 0.2179 (0.2180) gate/usage_std 0.1463 (0.1457) teacher/entropy 0.1779 (0.2483) teacher/usage_max 0.8452 (0.7843) teacher/usage_min 0.0535 (0.0553) teacher/usage_std 0.3625 (0.3228) nleep/row_max_mean 1202.3390 (1198.1006) nleep/row_max_std 17.7879 (14.4753) nleep/row_min_mean 1194.2599 (1190.8759) lr 3.6258e-04 eta 0:19:45
epoch [38/50] batch [160/244] time 0.498 (0.388) data 0.000 (0.002) loss 1.6010 (1.7110) teacher_loss 0.8006 (0.8840) loss_zs_kd 0.0618 (0.0543) loss_oracle 0.5083 (0.5067) kd_loss 0.5153 (0.5465) acc 78.1250 (76.8750) gate/entropy 1.0078 (1.0090) gate/usage_max 0.5404 (0.5390) gate/usage_min 0.2176 (0.2180) gate/usage_std 0.1467 (0.1458) teacher/entropy 0.3881 (0.2466) teacher/usage_max 0.6623 (0.7883) teacher/usage_min 0.1542 (0.0550) teacher/usage_std 0.2329 (0.3254) nleep/row_max_mean 1197.5093 (1198.0931) nleep/row_max_std 15.0159 (14.5312) nleep/row_min_mean 1190.9292 (1190.8244) lr 3.6258e-04 eta 0:19:30
epoch [38/50] batch [180/244] time 0.094 (0.371) data 0.000 (0.002) loss 1.7280 (1.7138) teacher_loss 0.9530 (0.8901) loss_zs_kd 0.0744 (0.0549) loss_oracle 0.4502 (0.5050) kd_loss 0.5126 (0.5437) acc 75.0000 (76.6667) gate/entropy 1.0081 (1.0089) gate/usage_max 0.5401 (0.5391) gate/usage_min 0.2179 (0.2180) gate/usage_std 0.1465 (0.1459) teacher/entropy 0.2173 (0.2482) teacher/usage_max 0.8637 (0.7896) teacher/usage_min 0.0393 (0.0552) teacher/usage_std 0.3758 (0.3262) nleep/row_max_mean 1198.3828 (1198.0966) nleep/row_max_std 14.0048 (14.5596) nleep/row_min_mean 1191.1309 (1190.8427) lr 3.6258e-04 eta 0:18:29
epoch [38/50] batch [200/244] time 0.519 (0.381) data 0.000 (0.002) loss 1.6990 (1.7176) teacher_loss 0.9250 (0.8945) loss_zs_kd 0.0479 (0.0547) loss_oracle 0.5098 (0.5057) kd_loss 0.4952 (0.5429) acc 81.2500 (76.5938) gate/entropy 1.0078 (1.0088) gate/usage_max 0.5404 (0.5392) gate/usage_min 0.2180 (0.2180) gate/usage_std 0.1467 (0.1460) teacher/entropy 0.2504 (0.2471) teacher/usage_max 0.8428 (0.7917) teacher/usage_min 0.0367 (0.0549) teacher/usage_std 0.3618 (0.3276) nleep/row_max_mean 1201.8400 (1198.0985) nleep/row_max_std 15.5712 (14.5898) nleep/row_min_mean 1194.6331 (1190.8374) lr 3.6258e-04 eta 0:18:50
epoch [38/50] batch [220/244] time 0.496 (0.391) data 0.000 (0.002) loss 1.4514 (1.7224) teacher_loss 0.6418 (0.9004) loss_zs_kd 0.0523 (0.0546) loss_oracle 0.4902 (0.5049) kd_loss 0.5383 (0.5423) acc 84.3750 (76.4773) gate/entropy 1.0076 (1.0087) gate/usage_max 0.5407 (0.5394) gate/usage_min 0.2178 (0.2180) gate/usage_std 0.1469 (0.1460) teacher/entropy 0.2163 (0.2465) teacher/usage_max 0.8340 (0.7931) teacher/usage_min 0.0596 (0.0547) teacher/usage_std 0.3546 (0.3285) nleep/row_max_mean 1199.3545 (1198.0516) nleep/row_max_std 13.0073 (14.5817) nleep/row_min_mean 1191.8567 (1190.7975) lr 3.6258e-04 eta 0:19:14
epoch [38/50] batch [240/244] time 0.479 (0.399) data 0.000 (0.002) loss 1.7148 (1.7194) teacher_loss 0.9829 (0.8980) loss_zs_kd 0.0750 (0.0552) loss_oracle 0.4399 (0.5055) kd_loss 0.4744 (0.5411) acc 78.1250 (76.5885) gate/entropy 1.0071 (1.0085) gate/usage_max 0.5413 (0.5395) gate/usage_min 0.2176 (0.2179) gate/usage_std 0.1473 (0.1461) teacher/entropy 0.3637 (0.2476) teacher/usage_max 0.7310 (0.7932) teacher/usage_min 0.0672 (0.0553) teacher/usage_std 0.2865 (0.3285) nleep/row_max_mean 1194.4792 (1197.9605) nleep/row_max_std 12.2323 (14.5179) nleep/row_min_mean 1188.2068 (1190.7270) lr 3.6258e-04 eta 0:19:29
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,826
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,998
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 89.4%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [39/50] batch [20/244] time 0.081 (0.308) data 0.000 (0.013) loss 2.2892 (1.7407) teacher_loss 1.4111 (0.9109) loss_zs_kd 0.0616 (0.0530) loss_oracle 0.5455 (0.5093) kd_loss 0.5745 (0.5487) acc 71.8750 (78.1250) gate/entropy 1.0073 (1.0071) gate/usage_max 0.5410 (0.5412) gate/usage_min 0.2179 (0.2177) gate/usage_std 0.1472 (0.1473) teacher/entropy 0.2116 (0.2476) teacher/usage_max 0.7926 (0.7819) teacher/usage_min 0.0396 (0.0572) teacher/usage_std 0.3289 (0.3212) nleep/row_max_mean 1197.1646 (1199.3768) nleep/row_max_std 12.7863 (14.1374) nleep/row_min_mean 1189.5959 (1192.0734) lr 3.1545e-04 eta 0:14:56
epoch [39/50] batch [40/244] time 0.538 (0.371) data 0.000 (0.006) loss 1.8788 (1.7162) teacher_loss 0.9969 (0.8940) loss_zs_kd 0.0537 (0.0557) loss_oracle 0.5015 (0.5103) kd_loss 0.6043 (0.5392) acc 71.8750 (77.8125) gate/entropy 1.0072 (1.0071) gate/usage_max 0.5412 (0.5413) gate/usage_min 0.2179 (0.2177) gate/usage_std 0.1473 (0.1474) teacher/entropy 0.1809 (0.2507) teacher/usage_max 0.7931 (0.7898) teacher/usage_min 0.0347 (0.0577) teacher/usage_std 0.3299 (0.3260) nleep/row_max_mean 1193.6648 (1198.6932) nleep/row_max_std 13.0052 (14.5252) nleep/row_min_mean 1186.6094 (1191.4792) lr 3.1545e-04 eta 0:17:52
epoch [39/50] batch [60/244] time 0.517 (0.411) data 0.001 (0.004) loss 1.5066 (1.7030) teacher_loss 0.6482 (0.8786) loss_zs_kd 0.0554 (0.0561) loss_oracle 0.4996 (0.5100) kd_loss 0.5809 (0.5413) acc 87.5000 (77.1354) gate/entropy 1.0069 (1.0070) gate/usage_max 0.5415 (0.5415) gate/usage_min 0.2179 (0.2177) gate/usage_std 0.1475 (0.1475) teacher/entropy 0.1725 (0.2422) teacher/usage_max 0.8315 (0.7974) teacher/usage_min 0.0335 (0.0551) teacher/usage_std 0.3547 (0.3312) nleep/row_max_mean 1200.1221 (1198.2063) nleep/row_max_std 12.8901 (14.3017) nleep/row_min_mean 1192.4675 (1190.9015) lr 3.1545e-04 eta 0:19:38
epoch [39/50] batch [80/244] time 0.471 (0.430) data 0.000 (0.003) loss 1.7161 (1.7126) teacher_loss 0.9589 (0.8908) loss_zs_kd 0.0461 (0.0547) loss_oracle 0.4830 (0.5076) kd_loss 0.4927 (0.5406) acc 75.0000 (76.5234) gate/entropy 1.0069 (1.0069) gate/usage_max 0.5415 (0.5416) gate/usage_min 0.2179 (0.2177) gate/usage_std 0.1475 (0.1475) teacher/entropy 0.2422 (0.2396) teacher/usage_max 0.8612 (0.8013) teacher/usage_min 0.0503 (0.0553) teacher/usage_std 0.3736 (0.3337) nleep/row_max_mean 1195.0635 (1198.0370) nleep/row_max_std 12.5615 (13.9694) nleep/row_min_mean 1187.9407 (1190.7447) lr 3.1545e-04 eta 0:20:24
epoch [39/50] batch [100/244] time 0.083 (0.414) data 0.000 (0.003) loss 1.7634 (1.7020) teacher_loss 0.9784 (0.8861) loss_zs_kd 0.0307 (0.0547) loss_oracle 0.4946 (0.5042) kd_loss 0.5224 (0.5365) acc 75.0000 (76.5625) gate/entropy 1.0062 (1.0068) gate/usage_max 0.5423 (0.5417) gate/usage_min 0.2176 (0.2177) gate/usage_std 0.1481 (0.1476) teacher/entropy 0.2156 (0.2418) teacher/usage_max 0.8541 (0.8035) teacher/usage_min 0.0728 (0.0550) teacher/usage_std 0.3682 (0.3351) nleep/row_max_mean 1194.0068 (1198.0107) nleep/row_max_std 12.0828 (13.9868) nleep/row_min_mean 1186.4376 (1190.7121) lr 3.1545e-04 eta 0:19:29
epoch [39/50] batch [120/244] time 0.485 (0.401) data 0.000 (0.002) loss 1.4257 (1.7042) teacher_loss 0.5956 (0.8880) loss_zs_kd 0.0438 (0.0544) loss_oracle 0.4640 (0.5019) kd_loss 0.5763 (0.5381) acc 78.1250 (76.4323) gate/entropy 1.0062 (1.0067) gate/usage_max 0.5424 (0.5418) gate/usage_min 0.2177 (0.2177) gate/usage_std 0.1481 (0.1477) teacher/entropy 0.2572 (0.2425) teacher/usage_max 0.7388 (0.8006) teacher/usage_min 0.0865 (0.0545) teacher/usage_std 0.2890 (0.3334) nleep/row_max_mean 1196.4368 (1197.9360) nleep/row_max_std 14.9144 (14.0005) nleep/row_min_mean 1189.2734 (1190.6307) lr 3.1545e-04 eta 0:18:46
epoch [39/50] batch [140/244] time 0.492 (0.380) data 0.000 (0.002) loss 1.9492 (1.7069) teacher_loss 1.1986 (0.8931) loss_zs_kd 0.0507 (0.0541) loss_oracle 0.5127 (0.5012) kd_loss 0.4689 (0.5361) acc 65.6250 (76.1161) gate/entropy 1.0062 (1.0066) gate/usage_max 0.5424 (0.5419) gate/usage_min 0.2177 (0.2177) gate/usage_std 0.1481 (0.1478) teacher/entropy 0.3044 (0.2420) teacher/usage_max 0.8140 (0.8032) teacher/usage_min 0.0871 (0.0530) teacher/usage_std 0.3399 (0.3353) nleep/row_max_mean 1195.0570 (1197.8903) nleep/row_max_std 16.2932 (14.0128) nleep/row_min_mean 1187.7747 (1190.5685) lr 3.1545e-04 eta 0:17:39
epoch [39/50] batch [160/244] time 0.467 (0.381) data 0.000 (0.002) loss 1.8115 (1.7173) teacher_loss 0.9668 (0.9036) loss_zs_kd 0.0419 (0.0539) loss_oracle 0.4652 (0.5005) kd_loss 0.5912 (0.5365) acc 71.8750 (75.9961) gate/entropy 1.0056 (1.0065) gate/usage_max 0.5430 (0.5420) gate/usage_min 0.2174 (0.2176) gate/usage_std 0.1486 (0.1478) teacher/entropy 0.2508 (0.2410) teacher/usage_max 0.7252 (0.8039) teacher/usage_min 0.0656 (0.0529) teacher/usage_std 0.2832 (0.3358) nleep/row_max_mean 1195.6954 (1197.8354) nleep/row_max_std 15.0069 (14.1749) nleep/row_min_mean 1189.3523 (1190.5208) lr 3.1545e-04 eta 0:17:35
epoch [39/50] batch [180/244] time 0.495 (0.394) data 0.000 (0.002) loss 1.3440 (1.7201) teacher_loss 0.4945 (0.9058) loss_zs_kd 0.0546 (0.0540) loss_oracle 0.4947 (0.5013) kd_loss 0.5748 (0.5366) acc 87.5000 (76.0243) gate/entropy 1.0056 (1.0064) gate/usage_max 0.5431 (0.5421) gate/usage_min 0.2175 (0.2176) gate/usage_std 0.1486 (0.1479) teacher/entropy 0.2371 (0.2402) teacher/usage_max 0.7636 (0.8046) teacher/usage_min 0.0769 (0.0535) teacher/usage_std 0.3061 (0.3361) nleep/row_max_mean 1198.9922 (1197.8690) nleep/row_max_std 17.1973 (14.2143) nleep/row_min_mean 1191.0261 (1190.5335) lr 3.1545e-04 eta 0:18:03
epoch [39/50] batch [200/244] time 0.496 (0.405) data 0.000 (0.001) loss 1.6949 (1.7209) teacher_loss 0.8694 (0.9068) loss_zs_kd 0.0305 (0.0539) loss_oracle 0.5063 (0.5011) kd_loss 0.5571 (0.5366) acc 75.0000 (76.0625) gate/entropy 1.0055 (1.0063) gate/usage_max 0.5432 (0.5422) gate/usage_min 0.2175 (0.2176) gate/usage_std 0.1487 (0.1480) teacher/entropy 0.2513 (0.2383) teacher/usage_max 0.7671 (0.8067) teacher/usage_min 0.0717 (0.0530) teacher/usage_std 0.3089 (0.3376) nleep/row_max_mean 1193.4724 (1197.8698) nleep/row_max_std 14.3743 (14.2681) nleep/row_min_mean 1186.7991 (1190.5145) lr 3.1545e-04 eta 0:18:23
epoch [39/50] batch [220/244] time 0.081 (0.402) data 0.000 (0.001) loss 2.2738 (1.7237) teacher_loss 1.4059 (0.9092) loss_zs_kd 0.0438 (0.0536) loss_oracle 0.5485 (0.5014) kd_loss 0.5716 (0.5369) acc 59.3750 (75.7955) gate/entropy 1.0048 (1.0062) gate/usage_max 0.5441 (0.5424) gate/usage_min 0.2172 (0.2176) gate/usage_std 0.1493 (0.1481) teacher/entropy 0.1874 (0.2390) teacher/usage_max 0.8314 (0.8056) teacher/usage_min 0.0466 (0.0540) teacher/usage_std 0.3535 (0.3367) nleep/row_max_mean 1202.2020 (1197.8302) nleep/row_max_std 13.5864 (14.2879) nleep/row_min_mean 1194.2510 (1190.4722) lr 3.1545e-04 eta 0:18:09
epoch [39/50] batch [240/244] time 0.486 (0.394) data 0.000 (0.001) loss 1.6611 (1.7253) teacher_loss 0.9217 (0.9104) loss_zs_kd 0.0466 (0.0541) loss_oracle 0.4594 (0.5019) kd_loss 0.4863 (0.5368) acc 75.0000 (75.8464) gate/entropy 1.0050 (1.0061) gate/usage_max 0.5438 (0.5425) gate/usage_min 0.2174 (0.2176) gate/usage_std 0.1491 (0.1482) teacher/entropy 0.2548 (0.2370) teacher/usage_max 0.8442 (0.8080) teacher/usage_min 0.0422 (0.0535) teacher/usage_std 0.3624 (0.3383) nleep/row_max_mean 1193.8821 (1197.7970) nleep/row_max_std 14.3778 (14.2659) nleep/row_min_mean 1187.2759 (1190.4205) lr 3.1545e-04 eta 0:17:38
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,822
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,002
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.4%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [40/50] batch [20/244] time 0.440 (0.503) data 0.000 (0.016) loss 1.4187 (1.7281) teacher_loss 0.7008 (0.9220) loss_zs_kd 0.0709 (0.0624) loss_oracle 0.4732 (0.4890) kd_loss 0.4458 (0.5305) acc 90.6250 (76.4062) gate/entropy 1.0050 (1.0049) gate/usage_max 0.5439 (0.5439) gate/usage_min 0.2175 (0.2174) gate/usage_std 0.1491 (0.1491) teacher/entropy 0.2654 (0.2268) teacher/usage_max 0.8839 (0.8264) teacher/usage_min 0.0479 (0.0527) teacher/usage_std 0.3894 (0.3503) nleep/row_max_mean 1191.4241 (1197.5261) nleep/row_max_std 13.3142 (15.5930) nleep/row_min_mean 1184.3346 (1189.9060) lr 2.7103e-04 eta 0:22:19
epoch [40/50] batch [40/244] time 0.521 (0.489) data 0.000 (0.008) loss 1.5757 (1.7165) teacher_loss 0.7868 (0.9050) loss_zs_kd 0.0576 (0.0619) loss_oracle 0.4792 (0.4920) kd_loss 0.5205 (0.5345) acc 78.1250 (76.2500) gate/entropy 1.0047 (1.0048) gate/usage_max 0.5442 (0.5440) gate/usage_min 0.2174 (0.2174) gate/usage_std 0.1493 (0.1492) teacher/entropy 0.3287 (0.2346) teacher/usage_max 0.7158 (0.8116) teacher/usage_min 0.0669 (0.0511) teacher/usage_std 0.2773 (0.3408) nleep/row_max_mean 1195.1448 (1197.7287) nleep/row_max_std 11.6645 (15.3515) nleep/row_min_mean 1188.4912 (1190.3277) lr 2.7103e-04 eta 0:21:33
epoch [40/50] batch [60/244] time 0.328 (0.487) data 0.000 (0.006) loss 1.7392 (1.7132) teacher_loss 0.9889 (0.8977) loss_zs_kd 0.0271 (0.0614) loss_oracle 0.4908 (0.4969) kd_loss 0.4914 (0.5363) acc 75.0000 (76.6667) gate/entropy 1.0045 (1.0048) gate/usage_max 0.5444 (0.5441) gate/usage_min 0.2174 (0.2174) gate/usage_std 0.1495 (0.1493) teacher/entropy 0.2028 (0.2316) teacher/usage_max 0.9006 (0.8128) teacher/usage_min 0.0423 (0.0493) teacher/usage_std 0.4011 (0.3419) nleep/row_max_mean 1200.7855 (1197.6272) nleep/row_max_std 16.2939 (15.2664) nleep/row_min_mean 1192.8833 (1190.1931) lr 2.7103e-04 eta 0:21:19
epoch [40/50] batch [80/244] time 0.491 (0.421) data 0.000 (0.004) loss 1.4780 (1.7204) teacher_loss 0.7177 (0.9015) loss_zs_kd 0.0381 (0.0623) loss_oracle 0.4737 (0.4984) kd_loss 0.5043 (0.5385) acc 81.2500 (76.1328) gate/entropy 1.0045 (1.0047) gate/usage_max 0.5444 (0.5442) gate/usage_min 0.2174 (0.2174) gate/usage_std 0.1495 (0.1493) teacher/entropy 0.2699 (0.2296) teacher/usage_max 0.8078 (0.8126) teacher/usage_min 0.0780 (0.0513) teacher/usage_std 0.3358 (0.3416) nleep/row_max_mean 1195.2686 (1197.7103) nleep/row_max_std 16.4086 (15.2589) nleep/row_min_mean 1188.8250 (1190.2516) lr 2.7103e-04 eta 0:18:15
epoch [40/50] batch [100/244] time 0.483 (0.396) data 0.000 (0.003) loss 1.3084 (1.7007) teacher_loss 0.4651 (0.8814) loss_zs_kd 0.0266 (0.0603) loss_oracle 0.4883 (0.5002) kd_loss 0.5859 (0.5390) acc 84.3750 (76.6875) gate/entropy 1.0042 (1.0047) gate/usage_max 0.5447 (0.5442) gate/usage_min 0.2173 (0.2174) gate/usage_std 0.1497 (0.1494) teacher/entropy 0.2161 (0.2324) teacher/usage_max 0.7707 (0.8087) teacher/usage_min 0.0531 (0.0534) teacher/usage_std 0.3133 (0.3389) nleep/row_max_mean 1200.4465 (1197.8022) nleep/row_max_std 16.7768 (15.1447) nleep/row_min_mean 1192.5135 (1190.3415) lr 2.7103e-04 eta 0:17:02
epoch [40/50] batch [120/244] time 0.521 (0.401) data 0.000 (0.003) loss 1.5946 (1.7001) teacher_loss 0.7680 (0.8862) loss_zs_kd 0.0390 (0.0584) loss_oracle 0.5262 (0.4990) kd_loss 0.5440 (0.5352) acc 75.0000 (76.5625) gate/entropy 1.0041 (1.0046) gate/usage_max 0.5449 (0.5443) gate/usage_min 0.2173 (0.2174) gate/usage_std 0.1498 (0.1494) teacher/entropy 0.2174 (0.2344) teacher/usage_max 0.8243 (0.8107) teacher/usage_min 0.0849 (0.0533) teacher/usage_std 0.3472 (0.3402) nleep/row_max_mean 1199.1128 (1197.7562) nleep/row_max_std 15.1265 (15.0868) nleep/row_min_mean 1191.9342 (1190.3197) lr 2.7103e-04 eta 0:17:07
epoch [40/50] batch [140/244] time 0.481 (0.415) data 0.000 (0.002) loss 1.3622 (1.7016) teacher_loss 0.5766 (0.8839) loss_zs_kd 0.0406 (0.0579) loss_oracle 0.5211 (0.5004) kd_loss 0.5048 (0.5385) acc 87.5000 (76.5179) gate/entropy 1.0043 (1.0045) gate/usage_max 0.5447 (0.5444) gate/usage_min 0.2175 (0.2174) gate/usage_std 0.1497 (0.1495) teacher/entropy 0.1960 (0.2320) teacher/usage_max 0.8911 (0.8098) teacher/usage_min 0.0329 (0.0545) teacher/usage_std 0.3948 (0.3394) nleep/row_max_mean 1198.8325 (1197.8570) nleep/row_max_std 16.4951 (15.1638) nleep/row_min_mean 1190.9406 (1190.4057) lr 2.7103e-04 eta 0:17:34
epoch [40/50] batch [160/244] time 0.518 (0.423) data 0.000 (0.002) loss 1.8604 (1.6908) teacher_loss 1.0227 (0.8753) loss_zs_kd 0.1021 (0.0571) loss_oracle 0.4924 (0.5001) kd_loss 0.5405 (0.5369) acc 84.3750 (76.7383) gate/entropy 1.0039 (1.0044) gate/usage_max 0.5451 (0.5445) gate/usage_min 0.2173 (0.2174) gate/usage_std 0.1500 (0.1495) teacher/entropy 0.2488 (0.2319) teacher/usage_max 0.7847 (0.8116) teacher/usage_min 0.0434 (0.0536) teacher/usage_std 0.3235 (0.3407) nleep/row_max_mean 1195.0337 (1197.7955) nleep/row_max_std 12.4474 (15.1528) nleep/row_min_mean 1187.7395 (1190.3346) lr 2.7103e-04 eta 0:17:46
epoch [40/50] batch [180/244] time 0.079 (0.424) data 0.000 (0.002) loss 1.5953 (1.6950) teacher_loss 0.8061 (0.8807) loss_zs_kd 0.0694 (0.0576) loss_oracle 0.4880 (0.4983) kd_loss 0.5105 (0.5363) acc 78.1250 (76.6493) gate/entropy 1.0040 (1.0044) gate/usage_max 0.5451 (0.5446) gate/usage_min 0.2174 (0.2174) gate/usage_std 0.1499 (0.1496) teacher/entropy 0.1902 (0.2323) teacher/usage_max 0.8905 (0.8117) teacher/usage_min 0.0300 (0.0531) teacher/usage_std 0.3945 (0.3407) nleep/row_max_mean 1196.7051 (1197.8132) nleep/row_max_std 16.3549 (15.1104) nleep/row_min_mean 1188.7167 (1190.3524) lr 2.7103e-04 eta 0:17:41
epoch [40/50] batch [200/244] time 0.488 (0.409) data 0.000 (0.002) loss 1.2085 (1.6947) teacher_loss 0.4434 (0.8817) loss_zs_kd 0.0639 (0.0575) loss_oracle 0.4658 (0.4972) kd_loss 0.5003 (0.5356) acc 90.6250 (76.5781) gate/entropy 1.0036 (1.0043) gate/usage_max 0.5455 (0.5447) gate/usage_min 0.2173 (0.2173) gate/usage_std 0.1503 (0.1497) teacher/entropy 0.2178 (0.2323) teacher/usage_max 0.8676 (0.8124) teacher/usage_min 0.0222 (0.0524) teacher/usage_std 0.3795 (0.3413) nleep/row_max_mean 1198.1206 (1197.8599) nleep/row_max_std 14.6413 (15.0809) nleep/row_min_mean 1190.5232 (1190.4200) lr 2.7103e-04 eta 0:16:55
epoch [40/50] batch [220/244] time 0.461 (0.395) data 0.000 (0.002) loss 1.4825 (1.6838) teacher_loss 0.6752 (0.8723) loss_zs_kd 0.0405 (0.0572) loss_oracle 0.5046 (0.4958) kd_loss 0.5348 (0.5349) acc 71.8750 (76.7472) gate/entropy 1.0037 (1.0042) gate/usage_max 0.5454 (0.5447) gate/usage_min 0.2174 (0.2173) gate/usage_std 0.1502 (0.1497) teacher/entropy 0.1845 (0.2320) teacher/usage_max 0.8685 (0.8134) teacher/usage_min 0.0377 (0.0522) teacher/usage_std 0.3791 (0.3420) nleep/row_max_mean 1199.0498 (1197.8362) nleep/row_max_std 14.4800 (15.0803) nleep/row_min_mean 1191.6064 (1190.3906) lr 2.7103e-04 eta 0:16:13
epoch [40/50] batch [240/244] time 0.496 (0.395) data 0.000 (0.002) loss 1.5008 (1.6817) teacher_loss 0.7137 (0.8711) loss_zs_kd 0.0392 (0.0569) loss_oracle 0.4887 (0.4959) kd_loss 0.5232 (0.5342) acc 84.3750 (76.7708) gate/entropy 1.0031 (1.0042) gate/usage_max 0.5461 (0.5448) gate/usage_min 0.2170 (0.2173) gate/usage_std 0.1507 (0.1498) teacher/entropy 0.2214 (0.2329) teacher/usage_max 0.8386 (0.8131) teacher/usage_min 0.0527 (0.0527) teacher/usage_std 0.3580 (0.3417) nleep/row_max_mean 1198.6000 (1197.7900) nleep/row_max_std 12.9931 (15.0871) nleep/row_min_mean 1191.6367 (1190.3567) lr 2.7103e-04 eta 0:16:05
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,824
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.6%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,007
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.5%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [41/50] batch [20/244] time 0.496 (0.518) data 0.000 (0.012) loss 1.4848 (1.6467) teacher_loss 0.7081 (0.8307) loss_zs_kd 0.0454 (0.0571) loss_oracle 0.5427 (0.4988) kd_loss 0.4826 (0.5380) acc 84.3750 (78.1250) gate/entropy 1.0034 (1.0032) gate/usage_max 0.5457 (0.5459) gate/usage_min 0.2174 (0.2172) gate/usage_std 0.1504 (0.1506) teacher/entropy 0.2721 (0.2238) teacher/usage_max 0.8281 (0.8193) teacher/usage_min 0.0600 (0.0600) teacher/usage_std 0.3505 (0.3448) nleep/row_max_mean 1194.3148 (1197.2130) nleep/row_max_std 13.4469 (14.9342) nleep/row_min_mean 1187.3433 (1189.7231) lr 2.2949e-04 eta 0:20:53
epoch [41/50] batch [40/244] time 0.099 (0.432) data 0.000 (0.006) loss 1.4920 (1.6317) teacher_loss 0.6882 (0.8247) loss_zs_kd 0.0438 (0.0544) loss_oracle 0.4844 (0.4946) kd_loss 0.5397 (0.5325) acc 87.5000 (79.3750) gate/entropy 1.0032 (1.0032) gate/usage_max 0.5460 (0.5460) gate/usage_min 0.2172 (0.2172) gate/usage_std 0.1506 (0.1506) teacher/entropy 0.2551 (0.2349) teacher/usage_max 0.7813 (0.8124) teacher/usage_min 0.0723 (0.0598) teacher/usage_std 0.3182 (0.3402) nleep/row_max_mean 1194.3186 (1197.4082) nleep/row_max_std 16.2869 (14.9540) nleep/row_min_mean 1186.9037 (1190.0377) lr 2.2949e-04 eta 0:17:17
epoch [41/50] batch [60/244] time 0.088 (0.415) data 0.001 (0.004) loss 1.4281 (1.6507) teacher_loss 0.6860 (0.8423) loss_zs_kd 0.0613 (0.0554) loss_oracle 0.4274 (0.4959) kd_loss 0.4977 (0.5327) acc 81.2500 (78.0729) gate/entropy 1.0027 (1.0031) gate/usage_max 0.5466 (0.5461) gate/usage_min 0.2170 (0.2172) gate/usage_std 0.1510 (0.1506) teacher/entropy 0.2950 (0.2374) teacher/usage_max 0.7808 (0.8088) teacher/usage_min 0.0580 (0.0579) teacher/usage_std 0.3192 (0.3383) nleep/row_max_mean 1198.0619 (1197.7185) nleep/row_max_std 14.0071 (15.2029) nleep/row_min_mean 1191.2959 (1190.3468) lr 2.2949e-04 eta 0:16:27
epoch [41/50] batch [80/244] time 0.519 (0.382) data 0.000 (0.003) loss 1.5870 (1.6597) teacher_loss 0.7630 (0.8477) loss_zs_kd 0.0831 (0.0554) loss_oracle 0.5511 (0.4979) kd_loss 0.5068 (0.5354) acc 71.8750 (77.3438) gate/entropy 1.0030 (1.0031) gate/usage_max 0.5463 (0.5461) gate/usage_min 0.2173 (0.2172) gate/usage_std 0.1508 (0.1507) teacher/entropy 0.2821 (0.2359) teacher/usage_max 0.7883 (0.8072) teacher/usage_min 0.0803 (0.0564) teacher/usage_std 0.3224 (0.3375) nleep/row_max_mean 1198.7666 (1197.9431) nleep/row_max_std 14.2599 (15.3998) nleep/row_min_mean 1191.4270 (1190.5855) lr 2.2949e-04 eta 0:15:02
epoch [41/50] batch [100/244] time 0.477 (0.403) data 0.000 (0.003) loss 1.3449 (1.6655) teacher_loss 0.4923 (0.8498) loss_zs_kd 0.0508 (0.0577) loss_oracle 0.5677 (0.4993) kd_loss 0.5433 (0.5372) acc 81.2500 (77.0938) gate/entropy 1.0029 (1.0030) gate/usage_max 0.5464 (0.5462) gate/usage_min 0.2172 (0.2172) gate/usage_std 0.1509 (0.1507) teacher/entropy 0.2166 (0.2367) teacher/usage_max 0.8230 (0.8041) teacher/usage_min 0.0836 (0.0576) teacher/usage_std 0.3463 (0.3353) nleep/row_max_mean 1201.5859 (1197.8268) nleep/row_max_std 16.4381 (15.4284) nleep/row_min_mean 1193.3613 (1190.4935) lr 2.2949e-04 eta 0:15:43
epoch [41/50] batch [120/244] time 0.472 (0.419) data 0.000 (0.002) loss 1.1067 (1.6608) teacher_loss 0.2963 (0.8418) loss_zs_kd 0.0436 (0.0575) loss_oracle 0.4513 (0.5013) kd_loss 0.5629 (0.5396) acc 93.7500 (77.3438) gate/entropy 1.0029 (1.0029) gate/usage_max 0.5464 (0.5463) gate/usage_min 0.2172 (0.2171) gate/usage_std 0.1508 (0.1508) teacher/entropy 0.2441 (0.2363) teacher/usage_max 0.7615 (0.8017) teacher/usage_min 0.0425 (0.0581) teacher/usage_std 0.3092 (0.3337) nleep/row_max_mean 1198.4097 (1197.8100) nleep/row_max_std 16.0466 (15.4782) nleep/row_min_mean 1191.3563 (1190.4993) lr 2.2949e-04 eta 0:16:12
epoch [41/50] batch [140/244] time 0.478 (0.430) data 0.000 (0.002) loss 1.9304 (1.6516) teacher_loss 1.0928 (0.8314) loss_zs_kd 0.0569 (0.0567) loss_oracle 0.5239 (0.5014) kd_loss 0.5472 (0.5411) acc 75.0000 (77.7009) gate/entropy 1.0024 (1.0029) gate/usage_max 0.5469 (0.5464) gate/usage_min 0.2170 (0.2171) gate/usage_std 0.1512 (0.1508) teacher/entropy 0.2409 (0.2359) teacher/usage_max 0.7868 (0.8003) teacher/usage_min 0.0623 (0.0584) teacher/usage_std 0.3227 (0.3327) nleep/row_max_mean 1197.9834 (1197.8835) nleep/row_max_std 12.9335 (15.4245) nleep/row_min_mean 1190.7646 (1190.6029) lr 2.2949e-04 eta 0:16:29
epoch [41/50] batch [160/244] time 0.094 (0.409) data 0.000 (0.002) loss 1.1322 (1.6486) teacher_loss 0.3330 (0.8304) loss_zs_kd 0.0527 (0.0568) loss_oracle 0.4989 (0.5009) kd_loss 0.5234 (0.5394) acc 93.7500 (77.8516) gate/entropy 1.0023 (1.0028) gate/usage_max 0.5471 (0.5464) gate/usage_min 0.2170 (0.2171) gate/usage_std 0.1513 (0.1509) teacher/entropy 0.2107 (0.2373) teacher/usage_max 0.8519 (0.8006) teacher/usage_min 0.0721 (0.0586) teacher/usage_std 0.3667 (0.3330) nleep/row_max_mean 1200.7227 (1198.0331) nleep/row_max_std 16.4702 (15.5181) nleep/row_min_mean 1193.3750 (1190.7639) lr 2.2949e-04 eta 0:15:33
epoch [41/50] batch [180/244] time 0.084 (0.402) data 0.000 (0.001) loss 1.5607 (1.6529) teacher_loss 0.8237 (0.8351) loss_zs_kd 0.0467 (0.0569) loss_oracle 0.4762 (0.4999) kd_loss 0.4756 (0.5394) acc 75.0000 (77.8125) gate/entropy 1.0023 (1.0028) gate/usage_max 0.5470 (0.5465) gate/usage_min 0.2171 (0.2171) gate/usage_std 0.1513 (0.1509) teacher/entropy 0.2613 (0.2391) teacher/usage_max 0.8463 (0.7984) teacher/usage_min 0.0506 (0.0580) teacher/usage_std 0.3634 (0.3316) nleep/row_max_mean 1196.1311 (1198.1572) nleep/row_max_std 14.1431 (15.5788) nleep/row_min_mean 1189.3057 (1190.8950) lr 2.2949e-04 eta 0:15:07
epoch [41/50] batch [200/244] time 0.451 (0.393) data 0.000 (0.001) loss 1.5855 (1.6529) teacher_loss 0.8956 (0.8370) loss_zs_kd 0.0436 (0.0567) loss_oracle 0.4330 (0.5004) kd_loss 0.4516 (0.5373) acc 78.1250 (77.9688) gate/entropy 1.0022 (1.0027) gate/usage_max 0.5471 (0.5465) gate/usage_min 0.2170 (0.2171) gate/usage_std 0.1514 (0.1510) teacher/entropy 0.3553 (0.2398) teacher/usage_max 0.7698 (0.8000) teacher/usage_min 0.1121 (0.0584) teacher/usage_std 0.3086 (0.3326) nleep/row_max_mean 1195.4915 (1198.0896) nleep/row_max_std 15.5514 (15.5673) nleep/row_min_mean 1189.1343 (1190.8399) lr 2.2949e-04 eta 0:14:40
epoch [41/50] batch [220/244] time 0.468 (0.401) data 0.000 (0.001) loss 2.0216 (1.6523) teacher_loss 1.1411 (0.8379) loss_zs_kd 0.0518 (0.0563) loss_oracle 0.5222 (0.4999) kd_loss 0.5935 (0.5364) acc 65.6250 (77.8267) gate/entropy 1.0019 (1.0027) gate/usage_max 0.5475 (0.5466) gate/usage_min 0.2169 (0.2171) gate/usage_std 0.1516 (0.1510) teacher/entropy 0.2342 (0.2417) teacher/usage_max 0.7421 (0.7988) teacher/usage_min 0.0901 (0.0594) teacher/usage_std 0.2908 (0.3318) nleep/row_max_mean 1201.8119 (1198.0637) nleep/row_max_std 20.8782 (15.6142) nleep/row_min_mean 1193.9821 (1190.8328) lr 2.2949e-04 eta 0:14:51
epoch [41/50] batch [240/244] time 0.483 (0.408) data 0.000 (0.001) loss 1.6617 (1.6558) teacher_loss 0.8362 (0.8422) loss_zs_kd 0.0634 (0.0563) loss_oracle 0.4719 (0.4987) kd_loss 0.5578 (0.5361) acc 78.1250 (77.6693) gate/entropy 1.0021 (1.0026) gate/usage_max 0.5473 (0.5467) gate/usage_min 0.2171 (0.2171) gate/usage_std 0.1515 (0.1511) teacher/entropy 0.2172 (0.2421) teacher/usage_max 0.8013 (0.7986) teacher/usage_min 0.0557 (0.0591) teacher/usage_std 0.3328 (0.3317) nleep/row_max_mean 1198.8262 (1198.0276) nleep/row_max_std 17.6816 (15.6202) nleep/row_min_mean 1191.5173 (1190.8002) lr 2.2949e-04 eta 0:14:57
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,820
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,000
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 89.4%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [42/50] batch [20/244] time 0.523 (0.293) data 0.000 (0.012) loss 1.4955 (1.6484) teacher_loss 0.6427 (0.8467) loss_zs_kd 0.0454 (0.0527) loss_oracle 0.5120 (0.4933) kd_loss 0.5741 (0.5288) acc 78.1250 (78.2812) gate/entropy 1.0022 (1.0018) gate/usage_max 0.5472 (0.5476) gate/usage_min 0.2172 (0.2170) gate/usage_std 0.1514 (0.1517) teacher/entropy 0.1978 (0.2493) teacher/usage_max 0.8038 (0.7986) teacher/usage_min 0.0496 (0.0677) teacher/usage_std 0.3350 (0.3304) nleep/row_max_mean 1196.0199 (1197.4878) nleep/row_max_std 16.6277 (15.3531) nleep/row_min_mean 1188.4395 (1190.6164) lr 1.9098e-04 eta 0:10:37
epoch [42/50] batch [40/244] time 0.484 (0.301) data 0.000 (0.006) loss 1.5548 (1.6621) teacher_loss 0.7069 (0.8533) loss_zs_kd 0.0657 (0.0569) loss_oracle 0.4990 (0.4938) kd_loss 0.5655 (0.5335) acc 84.3750 (77.6562) gate/entropy 1.0018 (1.0018) gate/usage_max 0.5476 (0.5476) gate/usage_min 0.2170 (0.2170) gate/usage_std 0.1517 (0.1517) teacher/entropy 0.1978 (0.2470) teacher/usage_max 0.8107 (0.7952) teacher/usage_min 0.0133 (0.0629) teacher/usage_std 0.3440 (0.3287) nleep/row_max_mean 1199.8846 (1197.4138) nleep/row_max_std 16.5316 (15.0724) nleep/row_min_mean 1191.9250 (1190.4081) lr 1.9098e-04 eta 0:10:49
epoch [42/50] batch [60/244] time 0.467 (0.329) data 0.000 (0.004) loss 1.4294 (1.6628) teacher_loss 0.6677 (0.8557) loss_zs_kd 0.0554 (0.0576) loss_oracle 0.4957 (0.4899) kd_loss 0.4862 (0.5333) acc 81.2500 (77.2396) gate/entropy 1.0017 (1.0018) gate/usage_max 0.5478 (0.5476) gate/usage_min 0.2170 (0.2170) gate/usage_std 0.1518 (0.1517) teacher/entropy 0.2066 (0.2491) teacher/usage_max 0.8950 (0.7930) teacher/usage_min 0.0265 (0.0634) teacher/usage_std 0.3977 (0.3273) nleep/row_max_mean 1200.2609 (1197.3449) nleep/row_max_std 13.7761 (14.9445) nleep/row_min_mean 1193.0681 (1190.3412) lr 1.9098e-04 eta 0:11:43
epoch [42/50] batch [80/244] time 0.520 (0.369) data 0.000 (0.003) loss 1.8480 (1.6633) teacher_loss 1.1305 (0.8565) loss_zs_kd 0.0277 (0.0576) loss_oracle 0.4840 (0.4873) kd_loss 0.4616 (0.5343) acc 81.2500 (77.1094) gate/entropy 1.0016 (1.0018) gate/usage_max 0.5478 (0.5477) gate/usage_min 0.2169 (0.2170) gate/usage_std 0.1518 (0.1517) teacher/entropy 0.2893 (0.2539) teacher/usage_max 0.8302 (0.7863) teacher/usage_min 0.0650 (0.0650) teacher/usage_std 0.3517 (0.3228) nleep/row_max_mean 1199.0387 (1197.6236) nleep/row_max_std 12.8027 (15.0794) nleep/row_min_mean 1192.1575 (1190.6355) lr 1.9098e-04 eta 0:12:59
epoch [42/50] batch [100/244] time 0.496 (0.391) data 0.000 (0.002) loss 2.1529 (1.6618) teacher_loss 1.3241 (0.8569) loss_zs_kd 0.0641 (0.0561) loss_oracle 0.4983 (0.4860) kd_loss 0.5476 (0.5338) acc 65.6250 (77.2188) gate/entropy 1.0015 (1.0017) gate/usage_max 0.5479 (0.5477) gate/usage_min 0.2169 (0.2170) gate/usage_std 0.1519 (0.1518) teacher/entropy 0.3244 (0.2553) teacher/usage_max 0.6918 (0.7854) teacher/usage_min 0.1171 (0.0663) teacher/usage_std 0.2553 (0.3221) nleep/row_max_mean 1193.1692 (1197.2330) nleep/row_max_std 15.1874 (15.0126) nleep/row_min_mean 1187.2571 (1190.2890) lr 1.9098e-04 eta 0:13:38
epoch [42/50] batch [120/244] time 0.081 (0.403) data 0.000 (0.002) loss 1.7728 (1.6714) teacher_loss 0.9886 (0.8659) loss_zs_kd 0.0601 (0.0566) loss_oracle 0.4930 (0.4864) kd_loss 0.5077 (0.5340) acc 75.0000 (76.7708) gate/entropy 1.0013 (1.0017) gate/usage_max 0.5482 (0.5477) gate/usage_min 0.2169 (0.2170) gate/usage_std 0.1521 (0.1518) teacher/entropy 0.3090 (0.2545) teacher/usage_max 0.7518 (0.7860) teacher/usage_min 0.0576 (0.0651) teacher/usage_std 0.3008 (0.3227) nleep/row_max_mean 1199.4889 (1197.2081) nleep/row_max_std 13.5210 (14.9741) nleep/row_min_mean 1193.1682 (1190.2761) lr 1.9098e-04 eta 0:13:56
epoch [42/50] batch [140/244] time 0.484 (0.387) data 0.000 (0.002) loss 1.1471 (1.6682) teacher_loss 0.3386 (0.8573) loss_zs_kd 0.0344 (0.0561) loss_oracle 0.4664 (0.4890) kd_loss 0.5581 (0.5383) acc 90.6250 (77.2768) gate/entropy 1.0012 (1.0016) gate/usage_max 0.5483 (0.5478) gate/usage_min 0.2168 (0.2170) gate/usage_std 0.1521 (0.1518) teacher/entropy 0.1664 (0.2536) teacher/usage_max 0.8551 (0.7820) teacher/usage_min 0.0111 (0.0665) teacher/usage_std 0.3723 (0.3199) nleep/row_max_mean 1203.5586 (1197.2975) nleep/row_max_std 16.2007 (15.1256) nleep/row_min_mean 1196.0864 (1190.3613) lr 1.9098e-04 eta 0:13:15
epoch [42/50] batch [160/244] time 0.543 (0.371) data 0.000 (0.002) loss 1.5952 (1.6683) teacher_loss 0.8085 (0.8586) loss_zs_kd 0.0515 (0.0569) loss_oracle 0.5012 (0.4890) kd_loss 0.5104 (0.5368) acc 81.2500 (77.5195) gate/entropy 1.0015 (1.0016) gate/usage_max 0.5480 (0.5478) gate/usage_min 0.2170 (0.2169) gate/usage_std 0.1520 (0.1519) teacher/entropy 0.2755 (0.2549) teacher/usage_max 0.7930 (0.7822) teacher/usage_min 0.0931 (0.0666) teacher/usage_std 0.3251 (0.3201) nleep/row_max_mean 1192.1665 (1197.1250) nleep/row_max_std 15.0575 (15.0601) nleep/row_min_mean 1185.1394 (1190.1983) lr 1.9098e-04 eta 0:12:34
epoch [42/50] batch [180/244] time 0.453 (0.377) data 0.000 (0.001) loss 1.9140 (1.6662) teacher_loss 1.0621 (0.8564) loss_zs_kd 0.0611 (0.0572) loss_oracle 0.5103 (0.4896) kd_loss 0.5662 (0.5365) acc 78.1250 (77.6215) gate/entropy 1.0013 (1.0016) gate/usage_max 0.5482 (0.5479) gate/usage_min 0.2169 (0.2169) gate/usage_std 0.1521 (0.1519) teacher/entropy 0.2674 (0.2568) teacher/usage_max 0.7373 (0.7803) teacher/usage_min 0.1300 (0.0672) teacher/usage_std 0.2856 (0.3188) nleep/row_max_mean 1193.6953 (1197.0538) nleep/row_max_std 15.7460 (15.0743) nleep/row_min_mean 1186.7269 (1190.1439) lr 1.9098e-04 eta 0:12:40
epoch [42/50] batch [200/244] time 0.495 (0.391) data 0.000 (0.001) loss 1.3903 (1.6595) teacher_loss 0.5574 (0.8491) loss_zs_kd 0.0414 (0.0572) loss_oracle 0.4735 (0.4903) kd_loss 0.5754 (0.5367) acc 81.2500 (77.7500) gate/entropy 1.0009 (1.0015) gate/usage_max 0.5487 (0.5479) gate/usage_min 0.2167 (0.2169) gate/usage_std 0.1525 (0.1519) teacher/entropy 0.2655 (0.2573) teacher/usage_max 0.7205 (0.7795) teacher/usage_min 0.0367 (0.0683) teacher/usage_std 0.2864 (0.3182) nleep/row_max_mean 1197.7921 (1196.9306) nleep/row_max_std 12.3455 (15.1357) nleep/row_min_mean 1191.4812 (1190.0292) lr 1.9098e-04 eta 0:13:00
epoch [42/50] batch [220/244] time 0.496 (0.400) data 0.000 (0.001) loss 1.7354 (1.6640) teacher_loss 0.9495 (0.8549) loss_zs_kd 0.0453 (0.0569) loss_oracle 0.4752 (0.4908) kd_loss 0.5257 (0.5353) acc 75.0000 (77.5852) gate/entropy 1.0012 (1.0015) gate/usage_max 0.5483 (0.5480) gate/usage_min 0.2169 (0.2169) gate/usage_std 0.1522 (0.1520) teacher/entropy 0.3098 (0.2584) teacher/usage_max 0.7322 (0.7799) teacher/usage_min 0.0863 (0.0682) teacher/usage_std 0.2847 (0.3184) nleep/row_max_mean 1195.7250 (1196.8791) nleep/row_max_std 14.3986 (15.1763) nleep/row_min_mean 1188.5339 (1189.9889) lr 1.9098e-04 eta 0:13:09
epoch [42/50] batch [240/244] time 0.080 (0.398) data 0.000 (0.001) loss 1.2956 (1.6686) teacher_loss 0.5489 (0.8600) loss_zs_kd 0.0553 (0.0573) loss_oracle 0.5065 (0.4913) kd_loss 0.4658 (0.5343) acc 81.2500 (77.4349) gate/entropy 1.0011 (1.0015) gate/usage_max 0.5484 (0.5480) gate/usage_min 0.2169 (0.2169) gate/usage_std 0.1523 (0.1520) teacher/entropy 0.2310 (0.2598) teacher/usage_max 0.8894 (0.7794) teacher/usage_min 0.0279 (0.0681) teacher/usage_std 0.3939 (0.3181) nleep/row_max_mean 1194.9624 (1196.8062) nleep/row_max_std 15.7977 (15.1627) nleep/row_min_mean 1188.3123 (1189.9230) lr 1.9098e-04 eta 0:12:58
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,821
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.5%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,006
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.5%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [43/50] batch [20/244] time 0.461 (0.394) data 0.000 (0.016) loss 1.5816 (1.5984) teacher_loss 0.7439 (0.7953) loss_zs_kd 0.0596 (0.0562) loss_oracle 0.5156 (0.4993) kd_loss 0.5501 (0.5253) acc 75.0000 (78.9062) gate/entropy 1.0009 (1.0010) gate/usage_max 0.5487 (0.5486) gate/usage_min 0.2168 (0.2169) gate/usage_std 0.1525 (0.1524) teacher/entropy 0.2714 (0.2561) teacher/usage_max 0.7470 (0.7936) teacher/usage_min 0.0790 (0.0664) teacher/usage_std 0.2950 (0.3279) nleep/row_max_mean 1195.1157 (1196.9081) nleep/row_max_std 16.5108 (14.9342) nleep/row_min_mean 1188.7173 (1189.8300) lr 1.5567e-04 eta 0:12:40
epoch [43/50] batch [40/244] time 0.532 (0.446) data 0.000 (0.008) loss 1.4083 (1.6386) teacher_loss 0.5569 (0.8250) loss_zs_kd 0.0731 (0.0566) loss_oracle 0.5212 (0.4992) kd_loss 0.5543 (0.5356) acc 81.2500 (78.2812) gate/entropy 1.0008 (1.0009) gate/usage_max 0.5488 (0.5487) gate/usage_min 0.2168 (0.2168) gate/usage_std 0.1525 (0.1524) teacher/entropy 0.1815 (0.2531) teacher/usage_max 0.8481 (0.7854) teacher/usage_min 0.0668 (0.0723) teacher/usage_std 0.3641 (0.3219) nleep/row_max_mean 1197.1984 (1197.0413) nleep/row_max_std 12.3733 (15.0114) nleep/row_min_mean 1189.9053 (1189.9954) lr 1.5567e-04 eta 0:14:12
epoch [43/50] batch [60/244] time 0.520 (0.461) data 0.001 (0.006) loss 1.8698 (1.6412) teacher_loss 0.9891 (0.8201) loss_zs_kd 0.0641 (0.0587) loss_oracle 0.5421 (0.5007) kd_loss 0.5776 (0.5414) acc 78.1250 (78.8542) gate/entropy 1.0009 (1.0009) gate/usage_max 0.5487 (0.5487) gate/usage_min 0.2169 (0.2168) gate/usage_std 0.1524 (0.1525) teacher/entropy 0.1769 (0.2515) teacher/usage_max 0.8193 (0.7801) teacher/usage_min 0.0074 (0.0683) teacher/usage_std 0.3503 (0.3189) nleep/row_max_mean 1201.1157 (1197.0119) nleep/row_max_std 14.3342 (14.9248) nleep/row_min_mean 1193.9937 (1189.9917) lr 1.5567e-04 eta 0:14:31
epoch [43/50] batch [80/244] time 0.080 (0.462) data 0.000 (0.004) loss 1.3134 (1.6576) teacher_loss 0.5060 (0.8394) loss_zs_kd 0.0448 (0.0592) loss_oracle 0.4951 (0.5010) kd_loss 0.5374 (0.5380) acc 87.5000 (78.4766) gate/entropy 1.0006 (1.0008) gate/usage_max 0.5490 (0.5487) gate/usage_min 0.2168 (0.2168) gate/usage_std 0.1527 (0.1525) teacher/entropy 0.2476 (0.2530) teacher/usage_max 0.7858 (0.7823) teacher/usage_min 0.0327 (0.0683) teacher/usage_std 0.3257 (0.3203) nleep/row_max_mean 1202.6068 (1196.7850) nleep/row_max_std 18.5324 (14.7515) nleep/row_min_mean 1194.8419 (1189.7999) lr 1.5567e-04 eta 0:14:25
epoch [43/50] batch [100/244] time 0.460 (0.414) data 0.000 (0.003) loss 1.6687 (1.6616) teacher_loss 0.8667 (0.8442) loss_zs_kd 0.0667 (0.0579) loss_oracle 0.4801 (0.5031) kd_loss 0.5287 (0.5369) acc 78.1250 (78.3125) gate/entropy 1.0006 (1.0008) gate/usage_max 0.5490 (0.5488) gate/usage_min 0.2169 (0.2168) gate/usage_std 0.1526 (0.1525) teacher/entropy 0.2638 (0.2541) teacher/usage_max 0.7775 (0.7825) teacher/usage_min 0.0376 (0.0689) teacher/usage_std 0.3198 (0.3202) nleep/row_max_mean 1198.2468 (1196.8413) nleep/row_max_std 14.5108 (14.9242) nleep/row_min_mean 1190.9360 (1189.8485) lr 1.5567e-04 eta 0:12:46
epoch [43/50] batch [120/244] time 0.090 (0.385) data 0.000 (0.003) loss 1.6863 (1.6761) teacher_loss 0.9067 (0.8596) loss_zs_kd 0.0473 (0.0567) loss_oracle 0.4696 (0.5029) kd_loss 0.5212 (0.5366) acc 68.7500 (77.7865) gate/entropy 1.0005 (1.0008) gate/usage_max 0.5491 (0.5488) gate/usage_min 0.2168 (0.2168) gate/usage_std 0.1527 (0.1525) teacher/entropy 0.3019 (0.2530) teacher/usage_max 0.7455 (0.7839) teacher/usage_min 0.0824 (0.0685) teacher/usage_std 0.2937 (0.3212) nleep/row_max_mean 1196.0874 (1196.9212) nleep/row_max_std 14.8965 (14.8236) nleep/row_min_mean 1189.1091 (1189.9255) lr 1.5567e-04 eta 0:11:45
epoch [43/50] batch [140/244] time 0.496 (0.381) data 0.000 (0.002) loss 1.5925 (1.6705) teacher_loss 0.8423 (0.8586) loss_zs_kd 0.0865 (0.0570) loss_oracle 0.4566 (0.5007) kd_loss 0.4786 (0.5331) acc 84.3750 (77.8571) gate/entropy 1.0006 (1.0007) gate/usage_max 0.5490 (0.5488) gate/usage_min 0.2168 (0.2168) gate/usage_std 0.1526 (0.1526) teacher/entropy 0.3098 (0.2560) teacher/usage_max 0.7862 (0.7846) teacher/usage_min 0.0825 (0.0695) teacher/usage_std 0.3208 (0.3215) nleep/row_max_mean 1194.0032 (1196.7563) nleep/row_max_std 14.7400 (14.7263) nleep/row_min_mean 1187.3394 (1189.7875) lr 1.5567e-04 eta 0:11:30
epoch [43/50] batch [160/244] time 0.468 (0.397) data 0.000 (0.002) loss 1.4833 (1.6693) teacher_loss 0.6627 (0.8594) loss_zs_kd 0.0246 (0.0564) loss_oracle 0.5031 (0.4996) kd_loss 0.5568 (0.5319) acc 81.2500 (78.0273) gate/entropy 1.0003 (1.0007) gate/usage_max 0.5494 (0.5489) gate/usage_min 0.2167 (0.2168) gate/usage_std 0.1529 (0.1526) teacher/entropy 0.1849 (0.2543) teacher/usage_max 0.8352 (0.7879) teacher/usage_min 0.0213 (0.0681) teacher/usage_std 0.3584 (0.3238) nleep/row_max_mean 1202.4197 (1196.8322) nleep/row_max_std 13.2377 (14.6543) nleep/row_min_mean 1194.5750 (1189.8538) lr 1.5567e-04 eta 0:11:51
epoch [43/50] batch [180/244] time 0.556 (0.408) data 0.000 (0.002) loss 1.5872 (1.6699) teacher_loss 0.8242 (0.8600) loss_zs_kd 0.0568 (0.0565) loss_oracle 0.4836 (0.4992) kd_loss 0.4928 (0.5321) acc 71.8750 (77.8125) gate/entropy 1.0003 (1.0007) gate/usage_max 0.5493 (0.5489) gate/usage_min 0.2167 (0.2168) gate/usage_std 0.1529 (0.1526) teacher/entropy 0.2674 (0.2526) teacher/usage_max 0.8190 (0.7896) teacher/usage_min 0.0857 (0.0680) teacher/usage_std 0.3435 (0.3249) nleep/row_max_mean 1195.5234 (1196.8637) nleep/row_max_std 13.8094 (14.6601) nleep/row_min_mean 1188.3607 (1189.8549) lr 1.5567e-04 eta 0:12:03
epoch [43/50] batch [200/244] time 0.490 (0.416) data 0.000 (0.002) loss 2.0162 (1.6718) teacher_loss 1.1873 (0.8640) loss_zs_kd 0.0546 (0.0560) loss_oracle 0.5260 (0.4983) kd_loss 0.5387 (0.5306) acc 68.7500 (77.6875) gate/entropy 1.0002 (1.0006) gate/usage_max 0.5495 (0.5490) gate/usage_min 0.2168 (0.2168) gate/usage_std 0.1530 (0.1526) teacher/entropy 0.2106 (0.2519) teacher/usage_max 0.8304 (0.7921) teacher/usage_min 0.0685 (0.0679) teacher/usage_std 0.3517 (0.3266) nleep/row_max_mean 1190.1647 (1196.8199) nleep/row_max_std 12.2861 (14.6354) nleep/row_min_mean 1183.5189 (1189.7903) lr 1.5567e-04 eta 0:12:08
epoch [43/50] batch [220/244] time 0.462 (0.395) data 0.000 (0.002) loss 1.5397 (1.6762) teacher_loss 0.6903 (0.8686) loss_zs_kd 0.0300 (0.0560) loss_oracle 0.5008 (0.4971) kd_loss 0.5840 (0.5311) acc 81.2500 (77.4148) gate/entropy 1.0001 (1.0006) gate/usage_max 0.5495 (0.5490) gate/usage_min 0.2167 (0.2168) gate/usage_std 0.1530 (0.1527) teacher/entropy 0.1834 (0.2513) teacher/usage_max 0.8080 (0.7922) teacher/usage_min 0.0592 (0.0676) teacher/usage_std 0.3370 (0.3266) nleep/row_max_mean 1196.8391 (1196.8268) nleep/row_max_std 13.3397 (14.6470) nleep/row_min_mean 1189.7837 (1189.7880) lr 1.5567e-04 eta 0:11:24
epoch [43/50] batch [240/244] time 0.080 (0.389) data 0.000 (0.002) loss 2.0560 (1.6764) teacher_loss 1.2889 (0.8710) loss_zs_kd 0.0413 (0.0558) loss_oracle 0.4688 (0.4966) kd_loss 0.5120 (0.5293) acc 68.7500 (77.1875) gate/entropy 1.0000 (1.0006) gate/usage_max 0.5497 (0.5491) gate/usage_min 0.2167 (0.2168) gate/usage_std 0.1531 (0.1527) teacher/entropy 0.2194 (0.2523) teacher/usage_max 0.8471 (0.7931) teacher/usage_min 0.0286 (0.0682) teacher/usage_std 0.3654 (0.3272) nleep/row_max_mean 1201.4441 (1196.8122) nleep/row_max_std 16.8633 (14.6722) nleep/row_min_mean 1193.8577 (1189.7701) lr 1.5567e-04 eta 0:11:05
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,827
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,001
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 89.4%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [44/50] batch [20/244] time 0.493 (0.505) data 0.000 (0.014) loss 2.0835 (1.6769) teacher_loss 1.2081 (0.8718) loss_zs_kd 0.0865 (0.0537) loss_oracle 0.5030 (0.4879) kd_loss 0.5808 (0.5343) acc 62.5000 (75.9375) gate/entropy 1.0002 (1.0001) gate/usage_max 0.5495 (0.5495) gate/usage_min 0.2168 (0.2168) gate/usage_std 0.1530 (0.1530) teacher/entropy 0.1514 (0.2286) teacher/usage_max 0.8471 (0.8137) teacher/usage_min 0.0289 (0.0598) teacher/usage_std 0.3654 (0.3412) nleep/row_max_mean 1198.3491 (1198.3261) nleep/row_max_std 14.7589 (15.6854) nleep/row_min_mean 1190.2921 (1191.0282) lr 1.2369e-04 eta 0:14:12
epoch [44/50] batch [40/244] time 0.474 (0.498) data 0.000 (0.007) loss 1.7428 (1.6264) teacher_loss 0.9652 (0.8242) loss_zs_kd 0.0528 (0.0539) loss_oracle 0.4678 (0.4908) kd_loss 0.5173 (0.5298) acc 75.0000 (77.6562) gate/entropy 0.9999 (1.0001) gate/usage_max 0.5498 (0.5496) gate/usage_min 0.2167 (0.2168) gate/usage_std 0.1532 (0.1531) teacher/entropy 0.2699 (0.2336) teacher/usage_max 0.7856 (0.8132) teacher/usage_min 0.0705 (0.0598) teacher/usage_std 0.3212 (0.3410) nleep/row_max_mean 1202.1636 (1197.5072) nleep/row_max_std 17.5879 (15.0579) nleep/row_min_mean 1194.1487 (1190.2711) lr 1.2369e-04 eta 0:13:50
epoch [44/50] batch [60/244] time 0.083 (0.477) data 0.000 (0.005) loss 1.5566 (1.6037) teacher_loss 0.7831 (0.8056) loss_zs_kd 0.0490 (0.0520) loss_oracle 0.4886 (0.4902) kd_loss 0.5048 (0.5270) acc 84.3750 (78.4896) gate/entropy 1.0001 (1.0001) gate/usage_max 0.5496 (0.5496) gate/usage_min 0.2168 (0.2168) gate/usage_std 0.1531 (0.1531) teacher/entropy 0.1948 (0.2372) teacher/usage_max 0.8879 (0.8124) teacher/usage_min 0.0448 (0.0615) teacher/usage_std 0.3923 (0.3403) nleep/row_max_mean 1198.2705 (1197.7713) nleep/row_max_std 17.9044 (15.2230) nleep/row_min_mean 1190.5845 (1190.5381) lr 1.2369e-04 eta 0:13:06
epoch [44/50] batch [80/244] time 0.465 (0.437) data 0.000 (0.004) loss 1.8389 (1.6155) teacher_loss 1.0989 (0.8199) loss_zs_kd 0.0484 (0.0526) loss_oracle 0.4679 (0.4877) kd_loss 0.4819 (0.5254) acc 68.7500 (78.3203) gate/entropy 0.9996 (1.0000) gate/usage_max 0.5502 (0.5497) gate/usage_min 0.2166 (0.2167) gate/usage_std 0.1535 (0.1531) teacher/entropy 0.2624 (0.2437) teacher/usage_max 0.8339 (0.8067) teacher/usage_min 0.0550 (0.0620) teacher/usage_std 0.3547 (0.3364) nleep/row_max_mean 1198.3149 (1197.6786) nleep/row_max_std 15.4210 (15.1207) nleep/row_min_mean 1190.8094 (1190.5004) lr 1.2369e-04 eta 0:11:51
epoch [44/50] batch [100/244] time 0.485 (0.401) data 0.000 (0.003) loss 1.7071 (1.6289) teacher_loss 0.9379 (0.8375) loss_zs_kd 0.0504 (0.0530) loss_oracle 0.4395 (0.4842) kd_loss 0.5242 (0.5228) acc 84.3750 (77.8438) gate/entropy 0.9998 (1.0000) gate/usage_max 0.5499 (0.5497) gate/usage_min 0.2167 (0.2167) gate/usage_std 0.1533 (0.1531) teacher/entropy 0.2717 (0.2491) teacher/usage_max 0.7751 (0.8033) teacher/usage_min 0.0715 (0.0617) teacher/usage_std 0.3142 (0.3342) nleep/row_max_mean 1199.6748 (1197.7057) nleep/row_max_std 17.0706 (15.3071) nleep/row_min_mean 1192.6884 (1190.5658) lr 1.2369e-04 eta 0:10:44
epoch [44/50] batch [120/244] time 0.497 (0.398) data 0.000 (0.002) loss 1.6371 (1.6439) teacher_loss 0.8946 (0.8551) loss_zs_kd 0.0572 (0.0541) loss_oracle 0.4418 (0.4834) kd_loss 0.4929 (0.5201) acc 78.1250 (77.6302) gate/entropy 0.9994 (1.0000) gate/usage_max 0.5503 (0.5497) gate/usage_min 0.2165 (0.2167) gate/usage_std 0.1536 (0.1532) teacher/entropy 0.2721 (0.2517) teacher/usage_max 0.8111 (0.8035) teacher/usage_min 0.0733 (0.0626) teacher/usage_std 0.3383 (0.3343) nleep/row_max_mean 1197.3113 (1197.4687) nleep/row_max_std 13.6844 (15.2603) nleep/row_min_mean 1191.4907 (1190.3796) lr 1.2369e-04 eta 0:10:31
epoch [44/50] batch [140/244] time 0.443 (0.410) data 0.000 (0.002) loss 1.6158 (1.6489) teacher_loss 0.8312 (0.8557) loss_zs_kd 0.0603 (0.0547) loss_oracle 0.5220 (0.4866) kd_loss 0.4934 (0.5225) acc 75.0000 (77.4330) gate/entropy 0.9999 (0.9999) gate/usage_max 0.5498 (0.5498) gate/usage_min 0.2168 (0.2167) gate/usage_std 0.1532 (0.1532) teacher/entropy 0.2896 (0.2503) teacher/usage_max 0.7940 (0.8023) teacher/usage_min 0.0952 (0.0631) teacher/usage_std 0.3258 (0.3335) nleep/row_max_mean 1193.4346 (1197.4328) nleep/row_max_std 14.5109 (15.1347) nleep/row_min_mean 1186.5258 (1190.3273) lr 1.2369e-04 eta 0:10:42
epoch [44/50] batch [160/244] time 0.472 (0.420) data 0.000 (0.002) loss 1.3927 (1.6534) teacher_loss 0.5641 (0.8590) loss_zs_kd 0.1033 (0.0552) loss_oracle 0.5112 (0.4873) kd_loss 0.5214 (0.5232) acc 90.6250 (77.4023) gate/entropy 0.9996 (0.9999) gate/usage_max 0.5502 (0.5498) gate/usage_min 0.2166 (0.2167) gate/usage_std 0.1535 (0.1532) teacher/entropy 0.1993 (0.2490) teacher/usage_max 0.8626 (0.8029) teacher/usage_min 0.0618 (0.0626) teacher/usage_std 0.3743 (0.3339) nleep/row_max_mean 1197.3326 (1197.2890) nleep/row_max_std 11.0160 (14.9036) nleep/row_min_mean 1189.1653 (1190.1749) lr 1.2369e-04 eta 0:10:50
epoch [44/50] batch [180/244] time 0.092 (0.421) data 0.001 (0.002) loss 2.0582 (1.6591) teacher_loss 1.1803 (0.8627) loss_zs_kd 0.0686 (0.0559) loss_oracle 0.5292 (0.4882) kd_loss 0.5790 (0.5244) acc 68.7500 (77.3090) gate/entropy 0.9996 (0.9999) gate/usage_max 0.5502 (0.5498) gate/usage_min 0.2167 (0.2167) gate/usage_std 0.1535 (0.1532) teacher/entropy 0.1967 (0.2468) teacher/usage_max 0.7983 (0.8041) teacher/usage_min 0.0646 (0.0626) teacher/usage_std 0.3301 (0.3347) nleep/row_max_mean 1199.0032 (1197.2211) nleep/row_max_std 12.1725 (14.7805) nleep/row_min_mean 1191.4497 (1190.0793) lr 1.2369e-04 eta 0:10:43
epoch [44/50] batch [200/244] time 0.439 (0.411) data 0.000 (0.002) loss 1.8357 (1.6620) teacher_loss 1.0737 (0.8658) loss_zs_kd 0.0751 (0.0563) loss_oracle 0.4627 (0.4878) kd_loss 0.4931 (0.5242) acc 75.0000 (77.2812) gate/entropy 0.9996 (0.9999) gate/usage_max 0.5501 (0.5499) gate/usage_min 0.2167 (0.2167) gate/usage_std 0.1535 (0.1533) teacher/entropy 0.3826 (0.2478) teacher/usage_max 0.6874 (0.8034) teacher/usage_min 0.1312 (0.0638) teacher/usage_std 0.2512 (0.3341) nleep/row_max_mean 1193.0796 (1197.0993) nleep/row_max_std 12.1980 (14.6712) nleep/row_min_mean 1187.2703 (1189.9671) lr 1.2369e-04 eta 0:10:20
epoch [44/50] batch [220/244] time 0.487 (0.399) data 0.000 (0.001) loss 1.9508 (1.6687) teacher_loss 1.1436 (0.8704) loss_zs_kd 0.0763 (0.0567) loss_oracle 0.5082 (0.4890) kd_loss 0.5149 (0.5255) acc 75.0000 (77.2727) gate/entropy 0.9998 (0.9998) gate/usage_max 0.5500 (0.5499) gate/usage_min 0.2168 (0.2167) gate/usage_std 0.1533 (0.1533) teacher/entropy 0.2543 (0.2468) teacher/usage_max 0.8094 (0.8031) teacher/usage_min 0.0790 (0.0646) teacher/usage_std 0.3369 (0.3339) nleep/row_max_mean 1196.3203 (1197.0406) nleep/row_max_std 13.1038 (14.6491) nleep/row_min_mean 1188.5256 (1189.8988) lr 1.2369e-04 eta 0:09:53
epoch [44/50] batch [240/244] time 0.464 (0.400) data 0.000 (0.001) loss 1.7457 (1.6672) teacher_loss 0.9282 (0.8666) loss_zs_kd 0.0761 (0.0572) loss_oracle 0.5215 (0.4901) kd_loss 0.5187 (0.5270) acc 71.8750 (77.3828) gate/entropy 0.9995 (0.9998) gate/usage_max 0.5503 (0.5499) gate/usage_min 0.2167 (0.2167) gate/usage_std 0.1536 (0.1533) teacher/entropy 0.1625 (0.2459) teacher/usage_max 0.9055 (0.8024) teacher/usage_min 0.0359 (0.0651) teacher/usage_std 0.4047 (0.3334) nleep/row_max_mean 1195.4330 (1196.9719) nleep/row_max_std 12.5318 (14.6574) nleep/row_min_mean 1187.9476 (1189.8346) lr 1.2369e-04 eta 0:09:46
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,829
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 3,997
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.2%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [45/50] batch [20/244] time 0.493 (0.524) data 0.000 (0.012) loss 1.5306 (1.6599) teacher_loss 0.6718 (0.8707) loss_zs_kd 0.0298 (0.0546) loss_oracle 0.5265 (0.4956) kd_loss 0.5806 (0.5141) acc 78.1250 (75.4688) gate/entropy 0.9996 (0.9995) gate/usage_max 0.5502 (0.5503) gate/usage_min 0.2167 (0.2167) gate/usage_std 0.1535 (0.1536) teacher/entropy 0.2321 (0.2478) teacher/usage_max 0.7594 (0.8155) teacher/usage_min 0.1137 (0.0650) teacher/usage_std 0.3013 (0.3420) nleep/row_max_mean 1196.5090 (1196.5224) nleep/row_max_std 18.1080 (15.1069) nleep/row_min_mean 1189.0742 (1189.3999) lr 9.5173e-05 eta 0:12:36
epoch [45/50] batch [40/244] time 0.088 (0.400) data 0.000 (0.006) loss 1.6820 (1.6379) teacher_loss 0.7939 (0.8420) loss_zs_kd 0.0550 (0.0541) loss_oracle 0.5067 (0.4984) kd_loss 0.6072 (0.5197) acc 81.2500 (76.8750) gate/entropy 0.9996 (0.9995) gate/usage_max 0.5502 (0.5503) gate/usage_min 0.2168 (0.2167) gate/usage_std 0.1535 (0.1536) teacher/entropy 0.2278 (0.2475) teacher/usage_max 0.7292 (0.8089) teacher/usage_min 0.0594 (0.0673) teacher/usage_std 0.2867 (0.3375) nleep/row_max_mean 1197.3853 (1196.3812) nleep/row_max_std 17.3263 (15.0610) nleep/row_min_mean 1190.5248 (1189.2835) lr 9.5173e-05 eta 0:09:29
epoch [45/50] batch [60/244] time 0.194 (0.394) data 0.000 (0.004) loss 1.9386 (1.6539) teacher_loss 1.0932 (0.8620) loss_zs_kd 0.0454 (0.0551) loss_oracle 0.5087 (0.4938) kd_loss 0.5684 (0.5174) acc 71.8750 (76.4583) gate/entropy 0.9992 (0.9994) gate/usage_max 0.5506 (0.5504) gate/usage_min 0.2165 (0.2167) gate/usage_std 0.1538 (0.1536) teacher/entropy 0.2176 (0.2510) teacher/usage_max 0.7877 (0.8073) teacher/usage_min 0.0866 (0.0665) teacher/usage_std 0.3217 (0.3365) nleep/row_max_mean 1197.6873 (1196.4262) nleep/row_max_std 13.7665 (15.1022) nleep/row_min_mean 1191.0966 (1189.3557) lr 9.5173e-05 eta 0:09:12
epoch [45/50] batch [80/244] time 0.082 (0.350) data 0.000 (0.003) loss 1.3115 (1.6711) teacher_loss 0.5813 (0.8776) loss_zs_kd 0.0321 (0.0548) loss_oracle 0.4501 (0.4935) kd_loss 0.4890 (0.5193) acc 84.3750 (76.3672) gate/entropy 0.9990 (0.9994) gate/usage_max 0.5508 (0.5504) gate/usage_min 0.2165 (0.2167) gate/usage_std 0.1539 (0.1536) teacher/entropy 0.2208 (0.2461) teacher/usage_max 0.8737 (0.8105) teacher/usage_min 0.0613 (0.0656) teacher/usage_std 0.3821 (0.3388) nleep/row_max_mean 1197.7332 (1196.1700) nleep/row_max_std 17.5963 (14.9773) nleep/row_min_mean 1191.2745 (1189.1034) lr 9.5173e-05 eta 0:08:04
epoch [45/50] batch [100/244] time 0.474 (0.362) data 0.000 (0.003) loss 1.9194 (1.6815) teacher_loss 1.0880 (0.8860) loss_zs_kd 0.0671 (0.0549) loss_oracle 0.5109 (0.4932) kd_loss 0.5424 (0.5215) acc 65.6250 (76.0938) gate/entropy 0.9992 (0.9994) gate/usage_max 0.5507 (0.5504) gate/usage_min 0.2166 (0.2167) gate/usage_std 0.1538 (0.1536) teacher/entropy 0.1862 (0.2466) teacher/usage_max 0.8488 (0.8077) teacher/usage_min 0.0235 (0.0673) teacher/usage_std 0.3670 (0.3367) nleep/row_max_mean 1198.8315 (1196.0268) nleep/row_max_std 15.2928 (15.1252) nleep/row_min_mean 1191.6021 (1188.9659) lr 9.5173e-05 eta 0:08:13
epoch [45/50] batch [120/244] time 0.495 (0.384) data 0.000 (0.002) loss 1.3233 (1.6665) teacher_loss 0.5676 (0.8687) loss_zs_kd 0.0441 (0.0549) loss_oracle 0.4940 (0.4939) kd_loss 0.4867 (0.5234) acc 84.3750 (76.7188) gate/entropy 0.9994 (0.9994) gate/usage_max 0.5504 (0.5504) gate/usage_min 0.2168 (0.2167) gate/usage_std 0.1536 (0.1537) teacher/entropy 0.2230 (0.2467) teacher/usage_max 0.8733 (0.8054) teacher/usage_min 0.0514 (0.0679) teacher/usage_std 0.3819 (0.3352) nleep/row_max_mean 1197.3738 (1196.0227) nleep/row_max_std 17.1453 (15.0355) nleep/row_min_mean 1190.1484 (1188.9671) lr 9.5173e-05 eta 0:08:36
epoch [45/50] batch [140/244] time 0.498 (0.399) data 0.000 (0.002) loss 1.1741 (1.6749) teacher_loss 0.4332 (0.8783) loss_zs_kd 0.0305 (0.0554) loss_oracle 0.4910 (0.4934) kd_loss 0.4801 (0.5222) acc 90.6250 (76.3393) gate/entropy 0.9997 (0.9994) gate/usage_max 0.5500 (0.5505) gate/usage_min 0.2169 (0.2167) gate/usage_std 0.1534 (0.1537) teacher/entropy 0.2130 (0.2485) teacher/usage_max 0.8934 (0.8047) teacher/usage_min 0.0485 (0.0690) teacher/usage_std 0.3960 (0.3347) nleep/row_max_mean 1197.3931 (1195.8906) nleep/row_max_std 15.6916 (14.9852) nleep/row_min_mean 1190.3589 (1188.8365) lr 9.5173e-05 eta 0:08:48
epoch [45/50] batch [160/244] time 0.082 (0.395) data 0.000 (0.002) loss 1.5118 (1.6752) teacher_loss 0.7708 (0.8795) loss_zs_kd 0.0147 (0.0549) loss_oracle 0.4906 (0.4933) kd_loss 0.4883 (0.5216) acc 87.5000 (76.3867) gate/entropy 0.9991 (0.9993) gate/usage_max 0.5507 (0.5505) gate/usage_min 0.2167 (0.2167) gate/usage_std 0.1538 (0.1537) teacher/entropy 0.2123 (0.2482) teacher/usage_max 0.8835 (0.8056) teacher/usage_min 0.0500 (0.0687) teacher/usage_std 0.3891 (0.3352) nleep/row_max_mean 1195.4946 (1195.9965) nleep/row_max_std 15.6835 (15.0750) nleep/row_min_mean 1188.9856 (1188.9310) lr 9.5173e-05 eta 0:08:35
epoch [45/50] batch [180/244] time 0.483 (0.388) data 0.000 (0.002) loss 1.8983 (1.6817) teacher_loss 1.1457 (0.8845) loss_zs_kd 0.0427 (0.0549) loss_oracle 0.4644 (0.4934) kd_loss 0.4991 (0.5231) acc 71.8750 (76.3368) gate/entropy 0.9992 (0.9993) gate/usage_max 0.5507 (0.5505) gate/usage_min 0.2167 (0.2167) gate/usage_std 0.1538 (0.1537) teacher/entropy 0.2909 (0.2469) teacher/usage_max 0.7818 (0.8054) teacher/usage_min 0.0736 (0.0684) teacher/usage_std 0.3184 (0.3352) nleep/row_max_mean 1194.4414 (1196.0358) nleep/row_max_std 17.3416 (15.0741) nleep/row_min_mean 1187.8665 (1188.9718) lr 9.5173e-05 eta 0:08:18
epoch [45/50] batch [200/244] time 0.080 (0.376) data 0.000 (0.001) loss 1.3815 (1.6718) teacher_loss 0.6833 (0.8751) loss_zs_kd 0.0431 (0.0549) loss_oracle 0.5062 (0.4935) kd_loss 0.4235 (0.5226) acc 87.5000 (76.6250) gate/entropy 0.9993 (0.9993) gate/usage_max 0.5505 (0.5505) gate/usage_min 0.2167 (0.2166) gate/usage_std 0.1537 (0.1537) teacher/entropy 0.3221 (0.2502) teacher/usage_max 0.8309 (0.8023) teacher/usage_min 0.0446 (0.0695) teacher/usage_std 0.3533 (0.3330) nleep/row_max_mean 1193.3303 (1196.0269) nleep/row_max_std 15.1431 (15.0812) nleep/row_min_mean 1186.8176 (1188.9894) lr 9.5173e-05 eta 0:07:55
epoch [45/50] batch [220/244] time 0.455 (0.376) data 0.000 (0.001) loss 1.5722 (1.6696) teacher_loss 0.7664 (0.8710) loss_zs_kd 0.0779 (0.0548) loss_oracle 0.4842 (0.4937) kd_loss 0.5248 (0.5243) acc 81.2500 (76.6761) gate/entropy 0.9991 (0.9993) gate/usage_max 0.5508 (0.5506) gate/usage_min 0.2166 (0.2166) gate/usage_std 0.1539 (0.1537) teacher/entropy 0.2821 (0.2490) teacher/usage_max 0.7657 (0.8016) teacher/usage_min 0.1091 (0.0692) teacher/usage_std 0.3058 (0.3326) nleep/row_max_mean 1198.7750 (1196.0997) nleep/row_max_std 16.6679 (15.1011) nleep/row_min_mean 1191.2092 (1189.0520) lr 9.5173e-05 eta 0:07:48
epoch [45/50] batch [240/244] time 0.470 (0.386) data 0.000 (0.001) loss 1.6788 (1.6673) teacher_loss 0.9460 (0.8680) loss_zs_kd 0.0733 (0.0555) loss_oracle 0.4897 (0.4940) kd_loss 0.4513 (0.5245) acc 78.1250 (76.7839) gate/entropy 0.9991 (0.9993) gate/usage_max 0.5508 (0.5506) gate/usage_min 0.2166 (0.2167) gate/usage_std 0.1539 (0.1538) teacher/entropy 0.3502 (0.2493) teacher/usage_max 0.7694 (0.8009) teacher/usage_min 0.0899 (0.0691) teacher/usage_std 0.3091 (0.3322) nleep/row_max_mean 1202.4358 (1196.1895) nleep/row_max_std 22.3616 (15.1834) nleep/row_min_mean 1195.1194 (1189.1323) lr 9.5173e-05 eta 0:07:52
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,831
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,007
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 89.6%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [46/50] batch [20/244] time 0.099 (0.353) data 0.000 (0.015) loss 1.9406 (1.6608) teacher_loss 1.1585 (0.8588) loss_zs_kd 0.0657 (0.0549) loss_oracle 0.4328 (0.4942) kd_loss 0.5329 (0.5275) acc 68.7500 (77.0312) gate/entropy 0.9988 (0.9990) gate/usage_max 0.5511 (0.5509) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.1541 (0.1540) teacher/entropy 0.2948 (0.2456) teacher/usage_max 0.7385 (0.8016) teacher/usage_min 0.0827 (0.0666) teacher/usage_std 0.2892 (0.3328) nleep/row_max_mean 1200.0632 (1198.6329) nleep/row_max_std 19.5808 (17.5240) nleep/row_min_mean 1193.5493 (1191.5179) lr 7.0224e-05 eta 0:07:03
epoch [46/50] batch [40/244] time 0.080 (0.366) data 0.000 (0.008) loss 1.4508 (1.6848) teacher_loss 0.6634 (0.8778) loss_zs_kd 0.0595 (0.0557) loss_oracle 0.4824 (0.4967) kd_loss 0.5164 (0.5308) acc 84.3750 (76.4844) gate/entropy 0.9992 (0.9990) gate/usage_max 0.5507 (0.5509) gate/usage_min 0.2167 (0.2166) gate/usage_std 0.1538 (0.1540) teacher/entropy 0.2123 (0.2476) teacher/usage_max 0.8512 (0.7957) teacher/usage_min 0.0487 (0.0722) teacher/usage_std 0.3668 (0.3284) nleep/row_max_mean 1197.9415 (1197.7642) nleep/row_max_std 20.7417 (17.1728) nleep/row_min_mean 1190.5837 (1190.7094) lr 7.0224e-05 eta 0:07:12
epoch [46/50] batch [60/244] time 0.110 (0.317) data 0.000 (0.005) loss 1.3663 (1.6741) teacher_loss 0.5931 (0.8654) loss_zs_kd 0.0554 (0.0576) loss_oracle 0.4940 (0.4912) kd_loss 0.4985 (0.5343) acc 81.2500 (76.9271) gate/entropy 0.9992 (0.9990) gate/usage_max 0.5507 (0.5509) gate/usage_min 0.2168 (0.2166) gate/usage_std 0.1538 (0.1540) teacher/entropy 0.1932 (0.2518) teacher/usage_max 0.8928 (0.7867) teacher/usage_min 0.0355 (0.0729) teacher/usage_std 0.3959 (0.3228) nleep/row_max_mean 1199.4700 (1197.8031) nleep/row_max_std 16.3292 (17.1981) nleep/row_min_mean 1191.3530 (1190.7296) lr 7.0224e-05 eta 0:06:07
epoch [46/50] batch [80/244] time 0.523 (0.360) data 0.000 (0.004) loss 1.7950 (1.6767) teacher_loss 0.9452 (0.8650) loss_zs_kd 0.0565 (0.0572) loss_oracle 0.5276 (0.4948) kd_loss 0.5578 (0.5357) acc 78.1250 (76.6406) gate/entropy 0.9987 (0.9990) gate/usage_max 0.5512 (0.5509) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.1542 (0.1540) teacher/entropy 0.2643 (0.2484) teacher/usage_max 0.7458 (0.7889) teacher/usage_min 0.0990 (0.0726) teacher/usage_std 0.2926 (0.3243) nleep/row_max_mean 1201.9465 (1198.0439) nleep/row_max_std 17.0930 (17.2458) nleep/row_min_mean 1194.5709 (1190.9193) lr 7.0224e-05 eta 0:06:50
epoch [46/50] batch [100/244] time 0.471 (0.386) data 0.000 (0.003) loss 1.6631 (1.6602) teacher_loss 0.8516 (0.8525) loss_zs_kd 0.0580 (0.0571) loss_oracle 0.4921 (0.4948) kd_loss 0.5365 (0.5318) acc 81.2500 (77.2812) gate/entropy 0.9987 (0.9989) gate/usage_max 0.5512 (0.5509) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.1542 (0.1540) teacher/entropy 0.2239 (0.2527) teacher/usage_max 0.8113 (0.7886) teacher/usage_min 0.0241 (0.0739) teacher/usage_std 0.3428 (0.3239) nleep/row_max_mean 1201.0378 (1198.2160) nleep/row_max_std 19.6289 (17.1258) nleep/row_min_mean 1193.4600 (1191.0576) lr 7.0224e-05 eta 0:07:12
epoch [46/50] batch [120/244] time 0.414 (0.400) data 0.000 (0.003) loss 1.5754 (1.6656) teacher_loss 0.8233 (0.8569) loss_zs_kd 0.0286 (0.0573) loss_oracle 0.4877 (0.4945) kd_loss 0.4939 (0.5328) acc 81.2500 (77.2396) gate/entropy 0.9991 (0.9989) gate/usage_max 0.5508 (0.5510) gate/usage_min 0.2168 (0.2166) gate/usage_std 0.1539 (0.1540) teacher/entropy 0.2703 (0.2513) teacher/usage_max 0.8113 (0.7887) teacher/usage_min 0.0697 (0.0719) teacher/usage_std 0.3386 (0.3242) nleep/row_max_mean 1200.1337 (1198.2443) nleep/row_max_std 16.6202 (17.0642) nleep/row_min_mean 1192.1580 (1191.0918) lr 7.0224e-05 eta 0:07:20
epoch [46/50] batch [140/244] time 0.098 (0.387) data 0.000 (0.002) loss 1.3347 (1.6571) teacher_loss 0.4160 (0.8502) loss_zs_kd 0.0476 (0.0572) loss_oracle 0.5689 (0.4943) kd_loss 0.6105 (0.5311) acc 87.5000 (77.2768) gate/entropy 0.9990 (0.9989) gate/usage_max 0.5509 (0.5510) gate/usage_min 0.2167 (0.2166) gate/usage_std 0.1540 (0.1540) teacher/entropy 0.2290 (0.2541) teacher/usage_max 0.7269 (0.7874) teacher/usage_min 0.0980 (0.0724) teacher/usage_std 0.2801 (0.3233) nleep/row_max_mean 1201.9644 (1198.2402) nleep/row_max_std 20.3110 (16.8731) nleep/row_min_mean 1194.5734 (1191.1320) lr 7.0224e-05 eta 0:06:58
epoch [46/50] batch [160/244] time 0.098 (0.386) data 0.000 (0.002) loss 1.9009 (1.6526) teacher_loss 1.0023 (0.8451) loss_zs_kd 0.0388 (0.0568) loss_oracle 0.5550 (0.4949) kd_loss 0.6017 (0.5316) acc 78.1250 (77.4805) gate/entropy 0.9988 (0.9989) gate/usage_max 0.5511 (0.5510) gate/usage_min 0.2166 (0.2166) gate/usage_std 0.1542 (0.1540) teacher/entropy 0.1809 (0.2529) teacher/usage_max 0.7900 (0.7883) teacher/usage_min 0.0764 (0.0719) teacher/usage_std 0.3238 (0.3239) nleep/row_max_mean 1197.4937 (1198.2608) nleep/row_max_std 17.4575 (16.8618) nleep/row_min_mean 1189.2689 (1191.1300) lr 7.0224e-05 eta 0:06:49
epoch [46/50] batch [180/244] time 0.141 (0.369) data 0.000 (0.002) loss 1.9799 (1.6522) teacher_loss 1.1866 (0.8467) loss_zs_kd 0.0704 (0.0571) loss_oracle 0.5028 (0.4941) kd_loss 0.5067 (0.5299) acc 75.0000 (77.5868) gate/entropy 0.9987 (0.9989) gate/usage_max 0.5512 (0.5510) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.1542 (0.1540) teacher/entropy 0.2266 (0.2530) teacher/usage_max 0.8464 (0.7901) teacher/usage_min 0.0638 (0.0716) teacher/usage_std 0.3629 (0.3251) nleep/row_max_mean 1192.9686 (1198.2228) nleep/row_max_std 12.7589 (16.7484) nleep/row_min_mean 1186.0029 (1191.0895) lr 7.0224e-05 eta 0:06:23
epoch [46/50] batch [200/244] time 0.496 (0.381) data 0.000 (0.002) loss 2.3431 (1.6600) teacher_loss 1.4514 (0.8551) loss_zs_kd 0.1014 (0.0576) loss_oracle 0.5370 (0.4932) kd_loss 0.5725 (0.5296) acc 62.5000 (77.3281) gate/entropy 0.9986 (0.9989) gate/usage_max 0.5513 (0.5510) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.1542 (0.1541) teacher/entropy 0.2553 (0.2531) teacher/usage_max 0.7364 (0.7903) teacher/usage_min 0.0688 (0.0720) teacher/usage_std 0.2896 (0.3252) nleep/row_max_mean 1194.9148 (1198.2391) nleep/row_max_std 13.3164 (16.7523) nleep/row_min_mean 1188.3462 (1191.1123) lr 7.0224e-05 eta 0:06:29
epoch [46/50] batch [220/244] time 0.496 (0.392) data 0.000 (0.002) loss 1.5843 (1.6632) teacher_loss 0.7401 (0.8582) loss_zs_kd 0.0381 (0.0572) loss_oracle 0.5386 (0.4940) kd_loss 0.5558 (0.5293) acc 81.2500 (77.2727) gate/entropy 0.9990 (0.9989) gate/usage_max 0.5509 (0.5510) gate/usage_min 0.2167 (0.2166) gate/usage_std 0.1540 (0.1541) teacher/entropy 0.2053 (0.2516) teacher/usage_max 0.8160 (0.7924) teacher/usage_min 0.0829 (0.0723) teacher/usage_std 0.3414 (0.3265) nleep/row_max_mean 1199.6615 (1198.0772) nleep/row_max_std 14.3558 (16.6103) nleep/row_min_mean 1192.1368 (1190.9569) lr 7.0224e-05 eta 0:06:32
epoch [46/50] batch [240/244] time 0.524 (0.401) data 0.000 (0.001) loss 1.4669 (1.6702) teacher_loss 0.5646 (0.8622) loss_zs_kd 0.0843 (0.0579) loss_oracle 0.4775 (0.4955) kd_loss 0.6215 (0.5313) acc 78.1250 (77.0573) gate/entropy 0.9988 (0.9988) gate/usage_max 0.5511 (0.5510) gate/usage_min 0.2167 (0.2166) gate/usage_std 0.1541 (0.1541) teacher/entropy 0.2036 (0.2510) teacher/usage_max 0.7396 (0.7909) teacher/usage_min 0.0603 (0.0724) teacher/usage_std 0.2929 (0.3255) nleep/row_max_mean 1198.0325 (1198.0048) nleep/row_max_std 16.9696 (16.5215) nleep/row_min_mean 1191.0254 (1190.8903) lr 7.0224e-05 eta 0:06:33
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,830
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,003
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.5%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [47/50] batch [20/244] time 0.537 (0.289) data 0.000 (0.015) loss 1.4164 (1.5992) teacher_loss 0.6748 (0.7938) loss_zs_kd 0.0562 (0.0544) loss_oracle 0.4556 (0.4971) kd_loss 0.4857 (0.5297) acc 81.2500 (79.5312) gate/entropy 0.9985 (0.9987) gate/usage_max 0.5514 (0.5512) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.1543 (0.1542) teacher/entropy 0.2764 (0.2419) teacher/usage_max 0.8153 (0.8028) teacher/usage_min 0.0899 (0.0757) teacher/usage_std 0.3408 (0.3329) nleep/row_max_mean 1199.1151 (1198.6843) nleep/row_max_std 16.2356 (15.9257) nleep/row_min_mean 1192.5322 (1191.5057) lr 4.8943e-05 eta 0:04:36
epoch [47/50] batch [40/244] time 0.494 (0.398) data 0.000 (0.008) loss 1.3432 (1.6080) teacher_loss 0.5709 (0.8014) loss_zs_kd 0.0300 (0.0537) loss_oracle 0.4925 (0.4970) kd_loss 0.5110 (0.5312) acc 78.1250 (78.3594) gate/entropy 0.9988 (0.9986) gate/usage_max 0.5511 (0.5513) gate/usage_min 0.2167 (0.2166) gate/usage_std 0.1541 (0.1542) teacher/entropy 0.1726 (0.2426) teacher/usage_max 0.9009 (0.8006) teacher/usage_min 0.0250 (0.0779) teacher/usage_std 0.4018 (0.3312) nleep/row_max_mean 1202.7186 (1198.2859) nleep/row_max_std 13.8791 (16.0767) nleep/row_min_mean 1194.9082 (1191.1171) lr 4.8943e-05 eta 0:06:12
epoch [47/50] batch [60/244] time 0.511 (0.429) data 0.000 (0.005) loss 1.4266 (1.6679) teacher_loss 0.6035 (0.8632) loss_zs_kd 0.0708 (0.0557) loss_oracle 0.4812 (0.4962) kd_loss 0.5472 (0.5288) acc 84.3750 (76.4062) gate/entropy 0.9989 (0.9986) gate/usage_max 0.5510 (0.5513) gate/usage_min 0.2168 (0.2166) gate/usage_std 0.1540 (0.1542) teacher/entropy 0.3076 (0.2485) teacher/usage_max 0.7115 (0.7964) teacher/usage_min 0.1315 (0.0763) teacher/usage_std 0.2676 (0.3286) nleep/row_max_mean 1198.7661 (1198.2882) nleep/row_max_std 19.5724 (16.0681) nleep/row_min_mean 1190.6210 (1191.1563) lr 4.8943e-05 eta 0:06:33
epoch [47/50] batch [80/244] time 0.499 (0.446) data 0.000 (0.004) loss 1.6066 (1.6589) teacher_loss 0.8506 (0.8545) loss_zs_kd 0.0358 (0.0543) loss_oracle 0.4633 (0.4963) kd_loss 0.5064 (0.5290) acc 78.1250 (76.9531) gate/entropy 0.9988 (0.9986) gate/usage_max 0.5511 (0.5513) gate/usage_min 0.2166 (0.2166) gate/usage_std 0.1541 (0.1542) teacher/entropy 0.2142 (0.2471) teacher/usage_max 0.8589 (0.7977) teacher/usage_min 0.0403 (0.0738) teacher/usage_std 0.3725 (0.3296) nleep/row_max_mean 1196.9219 (1198.1547) nleep/row_max_std 15.0793 (16.2418) nleep/row_min_mean 1189.4343 (1190.9919) lr 4.8943e-05 eta 0:06:39
epoch [47/50] batch [100/244] time 0.097 (0.410) data 0.000 (0.003) loss 2.1170 (1.6689) teacher_loss 1.2225 (0.8682) loss_zs_kd 0.0773 (0.0544) loss_oracle 0.4984 (0.4926) kd_loss 0.6066 (0.5271) acc 68.7500 (77.0938) gate/entropy 0.9983 (0.9986) gate/usage_max 0.5517 (0.5513) gate/usage_min 0.2164 (0.2166) gate/usage_std 0.1545 (0.1543) teacher/entropy 0.2290 (0.2519) teacher/usage_max 0.7300 (0.7946) teacher/usage_min 0.0945 (0.0744) teacher/usage_std 0.2825 (0.3274) nleep/row_max_mean 1197.8579 (1198.0706) nleep/row_max_std 17.4889 (16.2318) nleep/row_min_mean 1190.1708 (1190.9205) lr 4.8943e-05 eta 0:05:59
epoch [47/50] batch [120/244] time 0.094 (0.399) data 0.000 (0.003) loss 1.6879 (1.6612) teacher_loss 0.9123 (0.8593) loss_zs_kd 0.0589 (0.0546) loss_oracle 0.4429 (0.4919) kd_loss 0.5248 (0.5286) acc 75.0000 (77.3698) gate/entropy 0.9983 (0.9986) gate/usage_max 0.5516 (0.5513) gate/usage_min 0.2164 (0.2166) gate/usage_std 0.1545 (0.1543) teacher/entropy 0.3615 (0.2509) teacher/usage_max 0.6735 (0.7940) teacher/usage_min 0.1252 (0.0748) teacher/usage_std 0.2425 (0.3270) nleep/row_max_mean 1198.1885 (1198.0641) nleep/row_max_std 19.5846 (16.2032) nleep/row_min_mean 1191.3478 (1190.9457) lr 4.8943e-05 eta 0:05:41
epoch [47/50] batch [140/244] time 0.512 (0.396) data 0.000 (0.002) loss 1.9017 (1.6627) teacher_loss 1.0833 (0.8600) loss_zs_kd 0.0825 (0.0558) loss_oracle 0.4977 (0.4928) kd_loss 0.5282 (0.5284) acc 75.0000 (77.3214) gate/entropy 0.9986 (0.9986) gate/usage_max 0.5513 (0.5513) gate/usage_min 0.2166 (0.2166) gate/usage_std 0.1542 (0.1543) teacher/entropy 0.1943 (0.2485) teacher/usage_max 0.8552 (0.7967) teacher/usage_min 0.0225 (0.0733) teacher/usage_std 0.3713 (0.3289) nleep/row_max_mean 1193.7021 (1197.8880) nleep/row_max_std 15.4346 (16.1329) nleep/row_min_mean 1186.6354 (1190.7601) lr 4.8943e-05 eta 0:05:30
epoch [47/50] batch [160/244] time 0.469 (0.408) data 0.000 (0.002) loss 1.5485 (1.6646) teacher_loss 0.8450 (0.8612) loss_zs_kd 0.0435 (0.0553) loss_oracle 0.4348 (0.4918) kd_loss 0.4644 (0.5299) acc 87.5000 (77.5195) gate/entropy 0.9981 (0.9986) gate/usage_max 0.5518 (0.5513) gate/usage_min 0.2164 (0.2166) gate/usage_std 0.1546 (0.1543) teacher/entropy 0.3357 (0.2498) teacher/usage_max 0.7713 (0.7936) teacher/usage_min 0.1056 (0.0745) teacher/usage_std 0.3098 (0.3268) nleep/row_max_mean 1198.8461 (1197.9879) nleep/row_max_std 16.8440 (16.1302) nleep/row_min_mean 1192.2979 (1190.8625) lr 4.8943e-05 eta 0:05:32
epoch [47/50] batch [180/244] time 0.520 (0.417) data 0.000 (0.002) loss 1.4795 (1.6531) teacher_loss 0.7161 (0.8480) loss_zs_kd 0.0718 (0.0554) loss_oracle 0.4471 (0.4923) kd_loss 0.5040 (0.5313) acc 87.5000 (77.9167) gate/entropy 0.9987 (0.9986) gate/usage_max 0.5512 (0.5513) gate/usage_min 0.2167 (0.2166) gate/usage_std 0.1542 (0.1543) teacher/entropy 0.3330 (0.2496) teacher/usage_max 0.7310 (0.7923) teacher/usage_min 0.1281 (0.0745) teacher/usage_std 0.2812 (0.3259) nleep/row_max_mean 1190.1957 (1197.9145) nleep/row_max_std 14.9156 (16.1035) nleep/row_min_mean 1183.8352 (1190.8033) lr 4.8943e-05 eta 0:05:32
epoch [47/50] batch [200/244] time 0.469 (0.425) data 0.000 (0.002) loss 1.6077 (1.6518) teacher_loss 0.7812 (0.8469) loss_zs_kd 0.0606 (0.0558) loss_oracle 0.5154 (0.4927) kd_loss 0.5386 (0.5306) acc 78.1250 (77.9375) gate/entropy 0.9985 (0.9986) gate/usage_max 0.5514 (0.5514) gate/usage_min 0.2166 (0.2166) gate/usage_std 0.1544 (0.1543) teacher/entropy 0.2825 (0.2504) teacher/usage_max 0.7519 (0.7921) teacher/usage_min 0.0927 (0.0739) teacher/usage_std 0.2971 (0.3259) nleep/row_max_mean 1197.6573 (1197.8277) nleep/row_max_std 12.6492 (15.9900) nleep/row_min_mean 1190.2075 (1190.7296) lr 4.8943e-05 eta 0:05:30
epoch [47/50] batch [220/244] time 0.470 (0.408) data 0.000 (0.002) loss 1.9522 (1.6616) teacher_loss 1.1752 (0.8571) loss_zs_kd 0.0504 (0.0565) loss_oracle 0.4566 (0.4917) kd_loss 0.5235 (0.5304) acc 71.8750 (77.7557) gate/entropy 0.9983 (0.9986) gate/usage_max 0.5516 (0.5514) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.1545 (0.1543) teacher/entropy 0.3115 (0.2503) teacher/usage_max 0.7329 (0.7925) teacher/usage_min 0.1203 (0.0745) teacher/usage_std 0.2827 (0.3261) nleep/row_max_mean 1197.0911 (1197.6966) nleep/row_max_std 17.8927 (15.8122) nleep/row_min_mean 1190.1194 (1190.6191) lr 4.8943e-05 eta 0:05:08
epoch [47/50] batch [240/244] time 0.082 (0.397) data 0.000 (0.001) loss 1.6402 (1.6508) teacher_loss 0.7574 (0.8466) loss_zs_kd 0.0984 (0.0570) loss_oracle 0.5254 (0.4921) kd_loss 0.5709 (0.5296) acc 87.5000 (78.0729) gate/entropy 0.9982 (0.9985) gate/usage_max 0.5518 (0.5514) gate/usage_min 0.2164 (0.2166) gate/usage_std 0.1546 (0.1543) teacher/entropy 0.2168 (0.2510) teacher/usage_max 0.7827 (0.7926) teacher/usage_min 0.0617 (0.0744) teacher/usage_std 0.3200 (0.3262) nleep/row_max_mean 1200.1824 (1197.5437) nleep/row_max_std 16.0908 (15.7282) nleep/row_min_mean 1192.6458 (1190.4651) lr 4.8943e-05 eta 0:04:52
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,830
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,003
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.4%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [48/50] batch [20/244] time 0.521 (0.514) data 0.000 (0.015) loss 1.4065 (1.7179) teacher_loss 0.5871 (0.9136) loss_zs_kd 0.0968 (0.0693) loss_oracle 0.5016 (0.4901) kd_loss 0.5201 (0.5246) acc 84.3750 (75.9375) gate/entropy 0.9985 (0.9984) gate/usage_max 0.5515 (0.5516) gate/usage_min 0.2166 (0.2165) gate/usage_std 0.1544 (0.1545) teacher/entropy 0.1911 (0.2475) teacher/usage_max 0.8724 (0.8018) teacher/usage_min 0.0507 (0.0676) teacher/usage_std 0.3813 (0.3331) nleep/row_max_mean 1196.4729 (1196.4415) nleep/row_max_std 13.6554 (13.9244) nleep/row_min_mean 1188.5532 (1189.3763) lr 3.1417e-05 eta 0:06:05
epoch [48/50] batch [40/244] time 0.524 (0.508) data 0.000 (0.007) loss 1.7129 (1.6970) teacher_loss 1.0202 (0.8872) loss_zs_kd 0.0347 (0.0637) loss_oracle 0.4844 (0.4978) kd_loss 0.4332 (0.5290) acc 71.8750 (77.0312) gate/entropy 0.9983 (0.9984) gate/usage_max 0.5516 (0.5515) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.1545 (0.1544) teacher/entropy 0.3605 (0.2434) teacher/usage_max 0.7837 (0.8014) teacher/usage_min 0.0585 (0.0655) teacher/usage_std 0.3210 (0.3329) nleep/row_max_mean 1194.8669 (1195.9325) nleep/row_max_std 12.2167 (13.9478) nleep/row_min_mean 1188.6938 (1188.8532) lr 3.1417e-05 eta 0:05:51
epoch [48/50] batch [60/244] time 0.082 (0.465) data 0.000 (0.005) loss 1.5917 (1.6926) teacher_loss 0.8385 (0.8926) loss_zs_kd 0.0579 (0.0614) loss_oracle 0.4353 (0.4946) kd_loss 0.5067 (0.5220) acc 75.0000 (76.8229) gate/entropy 0.9981 (0.9984) gate/usage_max 0.5519 (0.5516) gate/usage_min 0.2164 (0.2165) gate/usage_std 0.1547 (0.1544) teacher/entropy 0.2885 (0.2485) teacher/usage_max 0.7720 (0.8035) teacher/usage_min 0.0433 (0.0661) teacher/usage_std 0.3155 (0.3342) nleep/row_max_mean 1196.2856 (1195.8930) nleep/row_max_std 11.4316 (13.8758) nleep/row_min_mean 1189.8765 (1188.9028) lr 3.1417e-05 eta 0:05:12
epoch [48/50] batch [80/244] time 0.432 (0.413) data 0.000 (0.004) loss 1.7564 (1.6928) teacher_loss 0.9247 (0.8879) loss_zs_kd 0.0583 (0.0608) loss_oracle 0.5195 (0.4944) kd_loss 0.5428 (0.5273) acc 75.0000 (76.7188) gate/entropy 0.9986 (0.9984) gate/usage_max 0.5514 (0.5516) gate/usage_min 0.2167 (0.2165) gate/usage_std 0.1543 (0.1544) teacher/entropy 0.2254 (0.2475) teacher/usage_max 0.8082 (0.7986) teacher/usage_min 0.0929 (0.0676) teacher/usage_std 0.3358 (0.3310) nleep/row_max_mean 1195.4731 (1196.1091) nleep/row_max_std 14.5058 (13.9508) nleep/row_min_mean 1188.9604 (1189.0841) lr 3.1417e-05 eta 0:04:29
epoch [48/50] batch [100/244] time 0.548 (0.386) data 0.000 (0.003) loss 1.5518 (1.6831) teacher_loss 0.7141 (0.8790) loss_zs_kd 0.0590 (0.0601) loss_oracle 0.4973 (0.4945) kd_loss 0.5596 (0.5268) acc 75.0000 (76.6562) gate/entropy 0.9985 (0.9984) gate/usage_max 0.5514 (0.5516) gate/usage_min 0.2167 (0.2165) gate/usage_std 0.1543 (0.1544) teacher/entropy 0.2629 (0.2476) teacher/usage_max 0.7478 (0.7990) teacher/usage_min 0.1202 (0.0678) teacher/usage_std 0.2931 (0.3311) nleep/row_max_mean 1192.9302 (1196.2200) nleep/row_max_std 13.8651 (14.1979) nleep/row_min_mean 1185.7603 (1189.1913) lr 3.1417e-05 eta 0:04:03
epoch [48/50] batch [120/244] time 0.497 (0.392) data 0.000 (0.003) loss 1.3592 (1.6915) teacher_loss 0.6113 (0.8862) loss_zs_kd 0.0423 (0.0593) loss_oracle 0.4641 (0.4948) kd_loss 0.4948 (0.5282) acc 81.2500 (76.5104) gate/entropy 0.9982 (0.9984) gate/usage_max 0.5517 (0.5516) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1546 (0.1545) teacher/entropy 0.2948 (0.2484) teacher/usage_max 0.7814 (0.7966) teacher/usage_min 0.0739 (0.0696) teacher/usage_std 0.3182 (0.3294) nleep/row_max_mean 1200.3000 (1196.4204) nleep/row_max_std 17.2822 (14.5043) nleep/row_min_mean 1193.5876 (1189.3728) lr 3.1417e-05 eta 0:03:59
epoch [48/50] batch [140/244] time 0.460 (0.403) data 0.000 (0.002) loss 1.7079 (1.6952) teacher_loss 0.8017 (0.8909) loss_zs_kd 0.0668 (0.0602) loss_oracle 0.4624 (0.4932) kd_loss 0.6415 (0.5276) acc 81.2500 (76.3616) gate/entropy 0.9985 (0.9984) gate/usage_max 0.5515 (0.5516) gate/usage_min 0.2166 (0.2165) gate/usage_std 0.1544 (0.1545) teacher/entropy 0.2011 (0.2491) teacher/usage_max 0.7226 (0.7966) teacher/usage_min 0.1029 (0.0689) teacher/usage_std 0.2768 (0.3294) nleep/row_max_mean 1195.5822 (1196.4092) nleep/row_max_std 16.4051 (14.8078) nleep/row_min_mean 1187.6656 (1189.3620) lr 3.1417e-05 eta 0:03:58
epoch [48/50] batch [160/244] time 0.459 (0.411) data 0.000 (0.002) loss 2.1273 (1.6887) teacher_loss 1.2709 (0.8848) loss_zs_kd 0.0596 (0.0590) loss_oracle 0.5607 (0.4937) kd_loss 0.5463 (0.5275) acc 65.6250 (76.5234) gate/entropy 0.9983 (0.9984) gate/usage_max 0.5517 (0.5516) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1545 (0.1545) teacher/entropy 0.2662 (0.2504) teacher/usage_max 0.7609 (0.7952) teacher/usage_min 0.0891 (0.0692) teacher/usage_std 0.3034 (0.3284) nleep/row_max_mean 1191.3604 (1196.4757) nleep/row_max_std 13.7909 (15.0487) nleep/row_min_mean 1185.3699 (1189.4526) lr 3.1417e-05 eta 0:03:55
epoch [48/50] batch [180/244] time 0.081 (0.418) data 0.000 (0.002) loss 1.4011 (1.6772) teacher_loss 0.7252 (0.8738) loss_zs_kd 0.0502 (0.0590) loss_oracle 0.4453 (0.4933) kd_loss 0.4282 (0.5272) acc 81.2500 (76.7188) gate/entropy 0.9979 (0.9984) gate/usage_max 0.5521 (0.5516) gate/usage_min 0.2163 (0.2165) gate/usage_std 0.1548 (0.1545) teacher/entropy 0.3066 (0.2508) teacher/usage_max 0.8465 (0.7952) teacher/usage_min 0.0439 (0.0705) teacher/usage_std 0.3639 (0.3283) nleep/row_max_mean 1194.6211 (1196.3716) nleep/row_max_std 15.3886 (15.2254) nleep/row_min_mean 1188.2445 (1189.3566) lr 3.1417e-05 eta 0:03:50
epoch [48/50] batch [200/244] time 0.526 (0.402) data 0.000 (0.002) loss 1.4424 (1.6841) teacher_loss 0.6943 (0.8798) loss_zs_kd 0.0572 (0.0593) loss_oracle 0.4503 (0.4938) kd_loss 0.4944 (0.5277) acc 84.3750 (76.7031) gate/entropy 0.9982 (0.9984) gate/usage_max 0.5518 (0.5516) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1546 (0.1545) teacher/entropy 0.2403 (0.2494) teacher/usage_max 0.8428 (0.7962) teacher/usage_min 0.0522 (0.0707) teacher/usage_std 0.3609 (0.3289) nleep/row_max_mean 1201.1383 (1196.3225) nleep/row_max_std 15.9588 (15.3078) nleep/row_min_mean 1193.9503 (1189.3029) lr 3.1417e-05 eta 0:03:33
epoch [48/50] batch [220/244] time 0.466 (0.386) data 0.000 (0.002) loss 1.7482 (1.6881) teacher_loss 0.9360 (0.8829) loss_zs_kd 0.0475 (0.0587) loss_oracle 0.5313 (0.4945) kd_loss 0.5228 (0.5285) acc 81.2500 (76.6903) gate/entropy 0.9983 (0.9983) gate/usage_max 0.5517 (0.5516) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1545 (0.1545) teacher/entropy 0.2077 (0.2501) teacher/usage_max 0.8514 (0.7946) teacher/usage_min 0.0541 (0.0717) teacher/usage_std 0.3667 (0.3278) nleep/row_max_mean 1193.1255 (1196.3521) nleep/row_max_std 12.9415 (15.4671) nleep/row_min_mean 1186.2544 (1189.3361) lr 3.1417e-05 eta 0:03:17
epoch [48/50] batch [240/244] time 0.478 (0.384) data 0.000 (0.001) loss 1.5508 (1.6795) teacher_loss 0.7195 (0.8744) loss_zs_kd 0.0439 (0.0587) loss_oracle 0.5231 (0.4947) kd_loss 0.5478 (0.5284) acc 81.2500 (76.9271) gate/entropy 0.9983 (0.9983) gate/usage_max 0.5517 (0.5516) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1545 (0.1545) teacher/entropy 0.2496 (0.2510) teacher/usage_max 0.7772 (0.7937) teacher/usage_min 0.0844 (0.0725) teacher/usage_std 0.3146 (0.3271) nleep/row_max_mean 1198.7758 (1196.4303) nleep/row_max_std 16.4371 (15.5426) nleep/row_min_mean 1191.0837 (1189.4112) lr 3.1417e-05 eta 0:03:09
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,829
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,003
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.5%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [49/50] batch [20/244] time 0.496 (0.511) data 0.000 (0.015) loss 1.6147 (1.6631) teacher_loss 0.7843 (0.8470) loss_zs_kd 0.0645 (0.0612) loss_oracle 0.4838 (0.4947) kd_loss 0.5562 (0.5382) acc 75.0000 (78.5938) gate/entropy 0.9980 (0.9983) gate/usage_max 0.5520 (0.5517) gate/usage_min 0.2164 (0.2166) gate/usage_std 0.1547 (0.1545) teacher/entropy 0.1614 (0.2481) teacher/usage_max 0.8606 (0.7860) teacher/usage_min 0.0353 (0.0741) teacher/usage_std 0.3739 (0.3216) nleep/row_max_mean 1193.4696 (1196.9631) nleep/row_max_std 14.8911 (17.1019) nleep/row_min_mean 1186.1509 (1189.6333) lr 1.7713e-05 eta 0:03:59
epoch [49/50] batch [40/244] time 0.106 (0.481) data 0.000 (0.007) loss 1.6319 (1.6422) teacher_loss 0.7306 (0.8333) loss_zs_kd 0.0823 (0.0566) loss_oracle 0.4744 (0.4933) kd_loss 0.6230 (0.5340) acc 75.0000 (78.5938) gate/entropy 0.9984 (0.9983) gate/usage_max 0.5515 (0.5517) gate/usage_min 0.2166 (0.2166) gate/usage_std 0.1544 (0.1545) teacher/entropy 0.2447 (0.2485) teacher/usage_max 0.6940 (0.7899) teacher/usage_min 0.1092 (0.0714) teacher/usage_std 0.2575 (0.3245) nleep/row_max_mean 1195.0923 (1196.6263) nleep/row_max_std 13.6016 (16.9008) nleep/row_min_mean 1188.2506 (1189.4086) lr 1.7713e-05 eta 0:03:35
epoch [49/50] batch [60/244] time 0.541 (0.426) data 0.001 (0.005) loss 1.3887 (1.6393) teacher_loss 0.5757 (0.8366) loss_zs_kd 0.0403 (0.0561) loss_oracle 0.5164 (0.4903) kd_loss 0.5346 (0.5295) acc 78.1250 (78.4896) gate/entropy 0.9983 (0.9983) gate/usage_max 0.5517 (0.5517) gate/usage_min 0.2166 (0.2165) gate/usage_std 0.1545 (0.1545) teacher/entropy 0.2108 (0.2513) teacher/usage_max 0.8362 (0.7918) teacher/usage_min 0.0444 (0.0706) teacher/usage_std 0.3569 (0.3258) nleep/row_max_mean 1193.3899 (1196.0156) nleep/row_max_std 13.8652 (16.6008) nleep/row_min_mean 1186.3387 (1188.8993) lr 1.7713e-05 eta 0:03:02
epoch [49/50] batch [80/244] time 0.177 (0.394) data 0.000 (0.004) loss 1.3408 (1.6486) teacher_loss 0.5129 (0.8435) loss_zs_kd 0.0475 (0.0571) loss_oracle 0.5038 (0.4922) kd_loss 0.5523 (0.5303) acc 90.6250 (78.1641) gate/entropy 0.9983 (0.9983) gate/usage_max 0.5517 (0.5517) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1545 (0.1545) teacher/entropy 0.2248 (0.2467) teacher/usage_max 0.7974 (0.7960) teacher/usage_min 0.0942 (0.0705) teacher/usage_std 0.3282 (0.3286) nleep/row_max_mean 1192.6385 (1196.0169) nleep/row_max_std 15.1165 (16.3015) nleep/row_min_mean 1186.1643 (1188.9112) lr 1.7713e-05 eta 0:02:40
epoch [49/50] batch [100/244] time 0.480 (0.393) data 0.000 (0.003) loss 1.4623 (1.6658) teacher_loss 0.6682 (0.8622) loss_zs_kd 0.0396 (0.0577) loss_oracle 0.4727 (0.4912) kd_loss 0.5379 (0.5292) acc 81.2500 (77.5625) gate/entropy 0.9985 (0.9983) gate/usage_max 0.5515 (0.5517) gate/usage_min 0.2167 (0.2165) gate/usage_std 0.1544 (0.1545) teacher/entropy 0.2877 (0.2495) teacher/usage_max 0.7383 (0.7940) teacher/usage_min 0.0444 (0.0696) teacher/usage_std 0.2949 (0.3275) nleep/row_max_mean 1198.0507 (1196.2017) nleep/row_max_std 19.8463 (16.3229) nleep/row_min_mean 1191.7749 (1189.1418) lr 1.7713e-05 eta 0:02:32
epoch [49/50] batch [120/244] time 0.473 (0.408) data 0.000 (0.003) loss 1.6411 (1.6465) teacher_loss 0.7314 (0.8427) loss_zs_kd 0.0481 (0.0574) loss_oracle 0.5107 (0.4910) kd_loss 0.6303 (0.5296) acc 84.3750 (78.1771) gate/entropy 0.9982 (0.9983) gate/usage_max 0.5518 (0.5517) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1546 (0.1545) teacher/entropy 0.1621 (0.2514) teacher/usage_max 0.7734 (0.7916) teacher/usage_min 0.0097 (0.0717) teacher/usage_std 0.3225 (0.3258) nleep/row_max_mean 1202.4709 (1196.3822) nleep/row_max_std 19.3265 (16.3093) nleep/row_min_mean 1194.4102 (1189.3341) lr 1.7713e-05 eta 0:02:30
epoch [49/50] batch [140/244] time 0.539 (0.419) data 0.000 (0.002) loss 1.6934 (1.6307) teacher_loss 0.8427 (0.8244) loss_zs_kd 0.0746 (0.0569) loss_oracle 0.5329 (0.4927) kd_loss 0.5469 (0.5314) acc 87.5000 (78.8393) gate/entropy 0.9983 (0.9983) gate/usage_max 0.5517 (0.5517) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1545 (0.1545) teacher/entropy 0.2056 (0.2500) teacher/usage_max 0.8214 (0.7913) teacher/usage_min 0.0404 (0.0726) teacher/usage_std 0.3474 (0.3255) nleep/row_max_mean 1196.3597 (1196.4260) nleep/row_max_std 17.4218 (16.4301) nleep/row_min_mean 1189.2290 (1189.3428) lr 1.7713e-05 eta 0:02:25
epoch [49/50] batch [160/244] time 0.082 (0.417) data 0.000 (0.002) loss 1.6653 (1.6367) teacher_loss 0.8896 (0.8327) loss_zs_kd 0.0449 (0.0571) loss_oracle 0.5047 (0.4915) kd_loss 0.5009 (0.5297) acc 81.2500 (78.6719) gate/entropy 0.9982 (0.9983) gate/usage_max 0.5518 (0.5517) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1546 (0.1545) teacher/entropy 0.2004 (0.2529) teacher/usage_max 0.8814 (0.7900) teacher/usage_min 0.0557 (0.0746) teacher/usage_std 0.3876 (0.3245) nleep/row_max_mean 1196.2249 (1196.2769) nleep/row_max_std 14.8257 (16.3800) nleep/row_min_mean 1189.4277 (1189.2194) lr 1.7713e-05 eta 0:02:16
epoch [49/50] batch [180/244] time 0.509 (0.410) data 0.000 (0.002) loss 1.6365 (1.6339) teacher_loss 0.8666 (0.8284) loss_zs_kd 0.0775 (0.0567) loss_oracle 0.4952 (0.4928) kd_loss 0.4835 (0.5307) acc 78.1250 (78.5243) gate/entropy 0.9979 (0.9983) gate/usage_max 0.5521 (0.5517) gate/usage_min 0.2163 (0.2165) gate/usage_std 0.1548 (0.1545) teacher/entropy 0.3120 (0.2534) teacher/usage_max 0.7742 (0.7883) teacher/usage_min 0.0803 (0.0749) teacher/usage_std 0.3129 (0.3234) nleep/row_max_mean 1198.3850 (1196.3093) nleep/row_max_std 16.9082 (16.3503) nleep/row_min_mean 1191.4052 (1189.2631) lr 1.7713e-05 eta 0:02:06
epoch [49/50] batch [200/244] time 0.357 (0.393) data 0.000 (0.002) loss 1.6534 (1.6463) teacher_loss 0.8507 (0.8417) loss_zs_kd 0.0628 (0.0567) loss_oracle 0.4602 (0.4911) kd_loss 0.5413 (0.5307) acc 71.8750 (78.1719) gate/entropy 0.9983 (0.9983) gate/usage_max 0.5517 (0.5517) gate/usage_min 0.2166 (0.2165) gate/usage_std 0.1545 (0.1545) teacher/entropy 0.3353 (0.2545) teacher/usage_max 0.6845 (0.7870) teacher/usage_min 0.1189 (0.0749) teacher/usage_std 0.2504 (0.3225) nleep/row_max_mean 1193.9446 (1196.3494) nleep/row_max_std 19.3046 (16.4051) nleep/row_min_mean 1187.2852 (1189.3228) lr 1.7713e-05 eta 0:01:53
epoch [49/50] batch [220/244] time 0.494 (0.393) data 0.000 (0.002) loss 2.4378 (1.6536) teacher_loss 1.6575 (0.8505) loss_zs_kd 0.0648 (0.0567) loss_oracle 0.4500 (0.4901) kd_loss 0.5228 (0.5297) acc 59.3750 (77.9545) gate/entropy 0.9980 (0.9982) gate/usage_max 0.5519 (0.5517) gate/usage_min 0.2164 (0.2165) gate/usage_std 0.1547 (0.1546) teacher/entropy 0.2519 (0.2551) teacher/usage_max 0.7957 (0.7874) teacher/usage_min 0.0365 (0.0748) teacher/usage_std 0.3313 (0.3227) nleep/row_max_mean 1191.3723 (1196.3824) nleep/row_max_std 17.1412 (16.4240) nleep/row_min_mean 1184.5852 (1189.3599) lr 1.7713e-05 eta 0:01:45
epoch [49/50] batch [240/244] time 0.520 (0.401) data 0.000 (0.001) loss 1.8158 (1.6543) teacher_loss 1.0147 (0.8511) loss_zs_kd 0.0462 (0.0567) loss_oracle 0.4809 (0.4905) kd_loss 0.5376 (0.5297) acc 65.6250 (77.9036) gate/entropy 0.9982 (0.9982) gate/usage_max 0.5517 (0.5517) gate/usage_min 0.2166 (0.2165) gate/usage_std 0.1546 (0.1546) teacher/entropy 0.2052 (0.2549) teacher/usage_max 0.8322 (0.7877) teacher/usage_min 0.0416 (0.0747) teacher/usage_std 0.3544 (0.3229) nleep/row_max_mean 1195.3354 (1196.3485) nleep/row_max_std 15.7083 (16.4470) nleep/row_min_mean 1188.2786 (1189.3312) lr 1.7713e-05 eta 0:01:39
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,831
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.8%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,004
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.5%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
epoch [50/50] batch [20/244] time 0.471 (0.333) data 0.000 (0.015) loss 1.7230 (1.6458) teacher_loss 0.9991 (0.8501) loss_zs_kd 0.0571 (0.0538) loss_oracle 0.4950 (0.4856) kd_loss 0.4478 (0.5260) acc 71.8750 (76.8750) gate/entropy 0.9983 (0.9982) gate/usage_max 0.5516 (0.5517) gate/usage_min 0.2166 (0.2166) gate/usage_std 0.1545 (0.1546) teacher/entropy 0.2473 (0.2707) teacher/usage_max 0.8872 (0.7740) teacher/usage_min 0.0378 (0.0801) teacher/usage_std 0.3919 (0.3138) nleep/row_max_mean 1197.1150 (1197.4693) nleep/row_max_std 18.3333 (17.0831) nleep/row_min_mean 1190.4539 (1190.4657) lr 7.8853e-06 eta 0:01:14
epoch [50/50] batch [40/244] time 0.082 (0.345) data 0.000 (0.008) loss 1.9482 (1.6352) teacher_loss 1.1717 (0.8279) loss_zs_kd 0.0712 (0.0551) loss_oracle 0.4950 (0.4921) kd_loss 0.4935 (0.5336) acc 68.7500 (78.2031) gate/entropy 0.9981 (0.9982) gate/usage_max 0.5519 (0.5517) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.1547 (0.1546) teacher/entropy 0.2804 (0.2588) teacher/usage_max 0.7997 (0.7786) teacher/usage_min 0.0773 (0.0765) teacher/usage_std 0.3303 (0.3170) nleep/row_max_mean 1196.5693 (1196.7710) nleep/row_max_std 19.0703 (16.4591) nleep/row_min_mean 1190.2188 (1189.7939) lr 7.8853e-06 eta 0:01:10
epoch [50/50] batch [60/244] time 0.497 (0.330) data 0.000 (0.005) loss 1.1299 (1.6110) teacher_loss 0.3625 (0.8078) loss_zs_kd 0.0233 (0.0559) loss_oracle 0.4221 (0.4887) kd_loss 0.5447 (0.5310) acc 90.6250 (78.6979) gate/entropy 0.9982 (0.9982) gate/usage_max 0.5518 (0.5518) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1546 (0.1546) teacher/entropy 0.3201 (0.2652) teacher/usage_max 0.7016 (0.7744) teacher/usage_min 0.1338 (0.0768) teacher/usage_std 0.2607 (0.3142) nleep/row_max_mean 1196.3904 (1197.0712) nleep/row_max_std 20.7324 (16.6350) nleep/row_min_mean 1189.4741 (1190.1122) lr 7.8853e-06 eta 0:01:00
epoch [50/50] batch [80/244] time 0.469 (0.372) data 0.000 (0.004) loss 1.8848 (1.6133) teacher_loss 0.9974 (0.8111) loss_zs_kd 0.0448 (0.0562) loss_oracle 0.5271 (0.4902) kd_loss 0.6013 (0.5290) acc 65.6250 (78.5547) gate/entropy 0.9981 (0.9982) gate/usage_max 0.5519 (0.5518) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1547 (0.1546) teacher/entropy 0.2054 (0.2611) teacher/usage_max 0.7638 (0.7812) teacher/usage_min 0.1024 (0.0755) teacher/usage_std 0.3046 (0.3187) nleep/row_max_mean 1196.2172 (1196.8236) nleep/row_max_std 13.3268 (16.4048) nleep/row_min_mean 1189.4490 (1189.8871) lr 7.8853e-06 eta 0:01:00
epoch [50/50] batch [100/244] time 0.466 (0.396) data 0.000 (0.003) loss 1.9306 (1.6348) teacher_loss 1.1247 (0.8319) loss_zs_kd 0.0568 (0.0558) loss_oracle 0.4818 (0.4917) kd_loss 0.5367 (0.5292) acc 71.8750 (78.1875) gate/entropy 0.9979 (0.9982) gate/usage_max 0.5521 (0.5518) gate/usage_min 0.2164 (0.2165) gate/usage_std 0.1548 (0.1546) teacher/entropy 0.2071 (0.2628) teacher/usage_max 0.8317 (0.7792) teacher/usage_min 0.0456 (0.0769) teacher/usage_std 0.3538 (0.3172) nleep/row_max_mean 1196.1667 (1196.5858) nleep/row_max_std 16.9430 (16.3925) nleep/row_min_mean 1189.5266 (1189.6847) lr 7.8853e-06 eta 0:00:57
epoch [50/50] batch [120/244] time 0.498 (0.413) data 0.000 (0.003) loss 1.6258 (1.6328) teacher_loss 0.7221 (0.8251) loss_zs_kd 0.0453 (0.0554) loss_oracle 0.5017 (0.4935) kd_loss 0.6301 (0.5332) acc 81.2500 (78.3073) gate/entropy 0.9985 (0.9982) gate/usage_max 0.5514 (0.5518) gate/usage_min 0.2167 (0.2165) gate/usage_std 0.1543 (0.1546) teacher/entropy 0.2184 (0.2602) teacher/usage_max 0.7156 (0.7776) teacher/usage_min 0.0933 (0.0786) teacher/usage_std 0.2732 (0.3159) nleep/row_max_mean 1194.9945 (1196.6149) nleep/row_max_std 12.3885 (16.3652) nleep/row_min_mean 1187.1726 (1189.6861) lr 7.8853e-06 eta 0:00:51
epoch [50/50] batch [140/244] time 0.500 (0.391) data 0.000 (0.002) loss 1.4932 (1.6379) teacher_loss 0.7146 (0.8324) loss_zs_kd 0.0413 (0.0558) loss_oracle 0.4769 (0.4924) kd_loss 0.5195 (0.5313) acc 75.0000 (78.0804) gate/entropy 0.9983 (0.9982) gate/usage_max 0.5517 (0.5518) gate/usage_min 0.2166 (0.2165) gate/usage_std 0.1545 (0.1546) teacher/entropy 0.2602 (0.2607) teacher/usage_max 0.7950 (0.7793) teacher/usage_min 0.0982 (0.0779) teacher/usage_std 0.3265 (0.3171) nleep/row_max_mean 1197.7545 (1196.4821) nleep/row_max_std 18.3439 (16.3461) nleep/row_min_mean 1191.0574 (1189.5749) lr 7.8853e-06 eta 0:00:40
epoch [50/50] batch [160/244] time 0.102 (0.382) data 0.001 (0.002) loss 1.3008 (1.6354) teacher_loss 0.5319 (0.8292) loss_zs_kd 0.0440 (0.0560) loss_oracle 0.5100 (0.4928) kd_loss 0.4918 (0.5318) acc 87.5000 (78.2812) gate/entropy 0.9981 (0.9982) gate/usage_max 0.5519 (0.5518) gate/usage_min 0.2164 (0.2165) gate/usage_std 0.1547 (0.1546) teacher/entropy 0.2465 (0.2583) teacher/usage_max 0.8365 (0.7814) teacher/usage_min 0.0289 (0.0773) teacher/usage_std 0.3584 (0.3186) nleep/row_max_mean 1203.3510 (1196.3690) nleep/row_max_std 14.8058 (16.1488) nleep/row_min_mean 1196.5359 (1189.4332) lr 7.8853e-06 eta 0:00:32
epoch [50/50] batch [180/244] time 0.473 (0.382) data 0.000 (0.002) loss 1.9999 (1.6423) teacher_loss 1.1586 (0.8354) loss_zs_kd 0.0653 (0.0569) loss_oracle 0.5146 (0.4926) kd_loss 0.5514 (0.5322) acc 68.7500 (78.0208) gate/entropy 0.9984 (0.9982) gate/usage_max 0.5515 (0.5518) gate/usage_min 0.2167 (0.2165) gate/usage_std 0.1544 (0.1546) teacher/entropy 0.2414 (0.2578) teacher/usage_max 0.7812 (0.7816) teacher/usage_min 0.0975 (0.0780) teacher/usage_std 0.3168 (0.3186) nleep/row_max_mean 1191.9343 (1196.1812) nleep/row_max_std 10.8040 (15.9773) nleep/row_min_mean 1184.8682 (1189.2526) lr 7.8853e-06 eta 0:00:24
epoch [50/50] batch [200/244] time 0.498 (0.391) data 0.000 (0.002) loss 1.4576 (1.6392) teacher_loss 0.5928 (0.8346) loss_zs_kd 0.0465 (0.0567) loss_oracle 0.5110 (0.4917) kd_loss 0.5861 (0.5305) acc 84.3750 (77.8594) gate/entropy 0.9982 (0.9982) gate/usage_max 0.5518 (0.5518) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1546 (0.1546) teacher/entropy 0.1527 (0.2580) teacher/usage_max 0.8357 (0.7833) teacher/usage_min 0.0246 (0.0774) teacher/usage_std 0.3583 (0.3197) nleep/row_max_mean 1196.8860 (1196.2093) nleep/row_max_std 16.1420 (15.8537) nleep/row_min_mean 1189.1138 (1189.2983) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [220/244] time 0.495 (0.400) data 0.000 (0.002) loss 2.0434 (1.6352) teacher_loss 1.2007 (0.8313) loss_zs_kd 0.0883 (0.0567) loss_oracle 0.4986 (0.4919) kd_loss 0.5492 (0.5297) acc 59.3750 (77.9119) gate/entropy 0.9981 (0.9982) gate/usage_max 0.5519 (0.5518) gate/usage_min 0.2165 (0.2165) gate/usage_std 0.1547 (0.1546) teacher/entropy 0.2169 (0.2560) teacher/usage_max 0.8066 (0.7865) teacher/usage_min 0.0540 (0.0761) teacher/usage_std 0.3364 (0.3220) nleep/row_max_mean 1191.7920 (1196.1279) nleep/row_max_std 14.6591 (15.7492) nleep/row_min_mean 1185.1689 (1189.2137) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [240/244] time 0.469 (0.407) data 0.000 (0.001) loss 1.3407 (1.6440) teacher_loss 0.5372 (0.8389) loss_zs_kd 0.0222 (0.0569) loss_oracle 0.5024 (0.4931) kd_loss 0.5412 (0.5301) acc 78.1250 (77.7865) gate/entropy 0.9985 (0.9982) gate/usage_max 0.5514 (0.5518) gate/usage_min 0.2167 (0.2165) gate/usage_std 0.1543 (0.1546) teacher/entropy 0.1984 (0.2549) teacher/usage_max 0.8391 (0.7872) teacher/usage_min 0.0750 (0.0763) teacher/usage_std 0.3576 (0.3224) nleep/row_max_mean 1197.4674 (1196.0087) nleep/row_max_std 13.4828 (15.5683) nleep/row_min_mean 1189.5454 (1189.0845) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 3,334
* correct: 2,827
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 4,439
* correct: 4,003
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 89.5%
******* Domain p best val acc:      84.9%, epoch: 10 *******
******* Domain p best val test acc: 90.7%, epoch: 10 *******
******* Domain p best test acc:     91.4%, epoch: 5 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/office_home/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 1:28:05

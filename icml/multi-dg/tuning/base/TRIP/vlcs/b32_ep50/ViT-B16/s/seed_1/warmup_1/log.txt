Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'pascal']
Target     ['sun']
# classes  5
# train_x  5,213
# val      2,234
# test     3,282
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/162] time 0.086 (0.119) data 0.000 (0.020) loss 1.3825 (1.0362) teacher_loss 0.9910 (0.6201) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0004 (0.0001) kd_loss 0.3913 (0.4161) acc 65.6250 (79.2188) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3349) gate/usage_min 0.3314 (0.3313) gate/usage_std 0.0014 (0.0015) teacher/entropy 0.7075 (0.6830) teacher/usage_max 0.4285 (0.4053) teacher/usage_min 0.2412 (0.2563) teacher/usage_std 0.0765 (0.0636) nleep/row_max_mean 1449.9375 (1476.6494) nleep/row_max_std 142.8322 (128.2335) nleep/row_min_mean 1447.4000 (1473.7135) lr 1.0000e-05 eta 0:15:59
epoch [1/50] batch [40/162] time 0.091 (0.105) data 0.000 (0.010) loss 1.2306 (0.9957) teacher_loss 0.9110 (0.6261) loss_zs_kd 0.0004 (0.0001) loss_oracle 0.0023 (0.0007) kd_loss 0.3183 (0.3692) acc 68.7500 (79.0625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3349) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.7807 (0.7298) teacher/usage_max 0.3924 (0.4039) teacher/usage_min 0.2196 (0.2567) teacher/usage_std 0.0804 (0.0632) nleep/row_max_mean 1473.1802 (1480.8971) nleep/row_max_std 126.4980 (122.8953) nleep/row_min_mean 1471.0984 (1478.3475) lr 1.0000e-05 eta 0:14:05
epoch [1/50] batch [60/162] time 0.088 (0.101) data 0.000 (0.007) loss 0.7673 (0.9434) teacher_loss 0.5671 (0.6177) loss_zs_kd 0.0002 (0.0003) loss_oracle 0.0047 (0.0016) kd_loss 0.1977 (0.3247) acc 84.3750 (78.7500) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.9011 (0.7743) teacher/usage_max 0.3621 (0.3967) teacher/usage_min 0.2953 (0.2621) teacher/usage_std 0.0281 (0.0577) nleep/row_max_mean 1461.4631 (1481.3682) nleep/row_max_std 128.6868 (119.1139) nleep/row_min_mean 1460.0271 (1479.1101) lr 1.0000e-05 eta 0:13:30
epoch [1/50] batch [80/162] time 0.097 (0.099) data 0.000 (0.005) loss 0.8106 (0.9028) teacher_loss 0.6109 (0.6076) loss_zs_kd 0.0013 (0.0006) loss_oracle 0.0071 (0.0029) kd_loss 0.1955 (0.2934) acc 78.1250 (79.0625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3314 (0.3313) gate/usage_std 0.0014 (0.0015) teacher/entropy 0.9027 (0.8055) teacher/usage_max 0.4299 (0.3941) teacher/usage_min 0.2621 (0.2687) teacher/usage_std 0.0708 (0.0539) nleep/row_max_mean 1496.6680 (1482.7904) nleep/row_max_std 108.1867 (116.4748) nleep/row_min_mean 1495.2839 (1480.7210) lr 1.0000e-05 eta 0:13:12
epoch [1/50] batch [100/162] time 0.096 (0.097) data 0.000 (0.004) loss 0.6329 (0.8694) teacher_loss 0.4849 (0.5987) loss_zs_kd 0.0005 (0.0008) loss_oracle 0.0085 (0.0041) kd_loss 0.1434 (0.2682) acc 84.3750 (79.4688) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.9556 (0.8306) teacher/usage_max 0.3761 (0.3912) teacher/usage_min 0.3053 (0.2741) teacher/usage_std 0.0307 (0.0504) nleep/row_max_mean 1493.6482 (1484.8954) nleep/row_max_std 98.0905 (112.0855) nleep/row_min_mean 1492.4255 (1482.9752) lr 1.0000e-05 eta 0:12:59
epoch [1/50] batch [120/162] time 0.088 (0.097) data 0.000 (0.003) loss 0.8951 (0.8305) teacher_loss 0.7862 (0.5815) loss_zs_kd 0.0009 (0.0009) loss_oracle 0.0110 (0.0053) kd_loss 0.1030 (0.2458) acc 65.6250 (79.7656) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.9952 (0.8530) teacher/usage_max 0.3596 (0.3874) teacher/usage_min 0.2952 (0.2782) teacher/usage_std 0.0276 (0.0470) nleep/row_max_mean 1480.5503 (1487.2611) nleep/row_max_std 92.8777 (108.5993) nleep/row_min_mean 1479.5381 (1485.4707) lr 1.0000e-05 eta 0:12:50
epoch [1/50] batch [140/162] time 0.096 (0.097) data 0.000 (0.003) loss 0.4528 (0.8030) teacher_loss 0.3359 (0.5712) loss_zs_kd 0.0035 (0.0011) loss_oracle 0.0166 (0.0064) kd_loss 0.1069 (0.2281) acc 87.5000 (80.2679) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.9914 (0.8706) teacher/usage_max 0.3636 (0.3851) teacher/usage_min 0.3168 (0.2815) teacher/usage_std 0.0215 (0.0446) nleep/row_max_mean 1530.8710 (1489.7039) nleep/row_max_std 63.4920 (105.0450) nleep/row_min_mean 1529.9070 (1488.0200) lr 1.0000e-05 eta 0:12:50
epoch [1/50] batch [160/162] time 0.090 (0.096) data 0.000 (0.003) loss 0.4140 (0.7914) teacher_loss 0.3112 (0.5725) loss_zs_kd 0.0011 (0.0013) loss_oracle 0.0192 (0.0081) kd_loss 0.0927 (0.2141) acc 84.3750 (80.0391) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 1.0055 (0.8846) teacher/usage_max 0.3657 (0.3835) teacher/usage_min 0.3110 (0.2838) teacher/usage_std 0.0235 (0.0428) nleep/row_max_mean 1488.6346 (1491.6723) nleep/row_max_std 83.1854 (102.3381) nleep/row_min_mean 1487.7404 (1490.0709) lr 1.0000e-05 eta 0:12:41
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,904
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 87.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,331
* accuracy: 71.0%
* error: 29.0%
* macro_f1: 67.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      85.2%, epoch: 1 *******
******* Domain s best val test acc: 71.0%, epoch: 1 *******
******* Domain s best test acc:     71.0%, epoch: 1 *******
epoch [2/50] batch [20/162] time 0.087 (0.114) data 0.000 (0.022) loss 1.0711 (0.8938) teacher_loss 0.5307 (0.4994) loss_zs_kd 0.0175 (0.0148) loss_oracle 0.2810 (0.2096) kd_loss 0.3911 (0.2823) acc 90.6250 (86.5625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3351 (0.3350) gate/usage_min 0.3308 (0.3311) gate/usage_std 0.0018 (0.0016) teacher/entropy 0.7061 (0.8156) teacher/usage_max 0.6101 (0.5239) teacher/usage_min 0.1635 (0.2182) teacher/usage_std 0.1974 (0.1369) nleep/row_max_mean 1500.9895 (1504.4711) nleep/row_max_std 81.4422 (81.2052) nleep/row_min_mean 1498.8137 (1502.7831) lr 2.0000e-03 eta 0:15:04
epoch [2/50] batch [40/162] time 0.090 (0.108) data 0.000 (0.011) loss 0.9819 (0.9701) teacher_loss 0.3210 (0.4365) loss_zs_kd 0.0283 (0.0204) loss_oracle 0.4059 (0.2756) kd_loss 0.4438 (0.3857) acc 93.7500 (88.2031) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3362 (0.3352) gate/usage_min 0.3292 (0.3305) gate/usage_std 0.0030 (0.0020) teacher/entropy 0.6521 (0.7112) teacher/usage_max 0.5471 (0.5831) teacher/usage_min 0.2088 (0.1902) teacher/usage_std 0.1518 (0.1780) nleep/row_max_mean 1523.5089 (1506.1210) nleep/row_max_std 83.3713 (80.4652) nleep/row_min_mean 1520.6622 (1503.8013) lr 2.0000e-03 eta 0:14:13
epoch [2/50] batch [60/162] time 0.071 (0.102) data 0.000 (0.007) loss 1.0128 (1.0092) teacher_loss 0.3325 (0.4180) loss_zs_kd 0.0292 (0.0214) loss_oracle 0.3018 (0.2901) kd_loss 0.5148 (0.4354) acc 90.6250 (88.5938) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3385 (0.3359) gate/usage_min 0.3273 (0.3298) gate/usage_std 0.0046 (0.0026) teacher/entropy 0.5785 (0.6602) teacher/usage_max 0.5499 (0.5934) teacher/usage_min 0.2201 (0.1870) teacher/usage_std 0.1532 (0.1850) nleep/row_max_mean 1527.1609 (1508.5303) nleep/row_max_std 70.3443 (78.5749) nleep/row_min_mean 1523.6033 (1505.7680) lr 2.0000e-03 eta 0:13:26
epoch [2/50] batch [80/162] time 0.093 (0.098) data 0.000 (0.006) loss 1.0599 (1.0179) teacher_loss 0.1939 (0.3887) loss_zs_kd 0.0301 (0.0210) loss_oracle 0.2880 (0.2856) kd_loss 0.7070 (0.4759) acc 90.6250 (89.1406) gate/entropy 1.0984 (1.0986) gate/usage_max 0.3411 (0.3369) gate/usage_min 0.3263 (0.3290) gate/usage_std 0.0061 (0.0033) teacher/entropy 0.3795 (0.6184) teacher/usage_max 0.7107 (0.6038) teacher/usage_min 0.0988 (0.1805) teacher/usage_std 0.2695 (0.1925) nleep/row_max_mean 1521.1056 (1511.8860) nleep/row_max_std 71.6522 (76.2559) nleep/row_min_mean 1515.4619 (1508.7023) lr 2.0000e-03 eta 0:12:51
epoch [2/50] batch [100/162] time 0.076 (0.096) data 0.000 (0.005) loss 1.0458 (1.0270) teacher_loss 0.2542 (0.3671) loss_zs_kd 0.0269 (0.0225) loss_oracle 0.2845 (0.2871) kd_loss 0.6360 (0.5051) acc 93.7500 (89.9375) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3431 (0.3380) gate/usage_min 0.3259 (0.3284) gate/usage_std 0.0072 (0.0040) teacher/entropy 0.4595 (0.5888) teacher/usage_max 0.4486 (0.5891) teacher/usage_min 0.1752 (0.1746) teacher/usage_std 0.1156 (0.1860) nleep/row_max_mean 1511.7518 (1512.5142) nleep/row_max_std 80.5577 (76.0319) nleep/row_min_mean 1506.3103 (1508.9597) lr 2.0000e-03 eta 0:12:30
epoch [2/50] batch [120/162] time 0.087 (0.094) data 0.000 (0.004) loss 1.3952 (1.0528) teacher_loss 0.3374 (0.3504) loss_zs_kd 0.0410 (0.0250) loss_oracle 0.4757 (0.3045) kd_loss 0.7994 (0.5377) acc 93.7500 (90.5208) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3439 (0.3389) gate/usage_min 0.3264 (0.3280) gate/usage_std 0.0076 (0.0046) teacher/entropy 0.2955 (0.5565) teacher/usage_max 0.4541 (0.5731) teacher/usage_min 0.1166 (0.1712) teacher/usage_std 0.1536 (0.1791) nleep/row_max_mean 1518.7908 (1513.3492) nleep/row_max_std 67.4188 (75.1339) nleep/row_min_mean 1510.9940 (1509.3729) lr 2.0000e-03 eta 0:12:13
epoch [2/50] batch [140/162] time 0.101 (0.093) data 0.000 (0.003) loss 1.2953 (1.0781) teacher_loss 0.2123 (0.3268) loss_zs_kd 0.0488 (0.0284) loss_oracle 0.4947 (0.3299) kd_loss 0.8113 (0.5721) acc 96.8750 (91.2500) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3438 (0.3396) gate/usage_min 0.3277 (0.3279) gate/usage_std 0.0074 (0.0050) teacher/entropy 0.2887 (0.5228) teacher/usage_max 0.3786 (0.5533) teacher/usage_min 0.3075 (0.1823) teacher/usage_std 0.0321 (0.1649) nleep/row_max_mean 1536.5470 (1514.3994) nleep/row_max_std 59.9961 (74.1348) nleep/row_min_mean 1528.6204 (1509.9049) lr 2.0000e-03 eta 0:12:07
epoch [2/50] batch [160/162] time 0.082 (0.093) data 0.000 (0.003) loss 1.4055 (1.1142) teacher_loss 0.1202 (0.3094) loss_zs_kd 0.0765 (0.0334) loss_oracle 0.7383 (0.3662) kd_loss 0.8779 (0.6050) acc 100.0000 (91.7578) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3428 (0.3401) gate/usage_min 0.3278 (0.3279) gate/usage_std 0.0068 (0.0053) teacher/entropy 0.2239 (0.4910) teacher/usage_max 0.4071 (0.5373) teacher/usage_min 0.2583 (0.1878) teacher/usage_std 0.0608 (0.1550) nleep/row_max_mean 1531.6414 (1515.1750) nleep/row_max_std 61.0796 (72.9736) nleep/row_min_mean 1520.3667 (1510.1018) lr 2.0000e-03 eta 0:12:04
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,906
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 86.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,017
* accuracy: 61.5%
* error: 38.5%
* macro_f1: 64.3%
******* Domain s best val acc:      85.3%, epoch: 2 *******
******* Domain s best val test acc: 61.5%, epoch: 2 *******
******* Domain s best test acc:     71.0%, epoch: 1 *******
epoch [3/50] batch [20/162] time 0.086 (0.107) data 0.000 (0.012) loss 1.3847 (1.3957) teacher_loss 0.1596 (0.1867) loss_zs_kd 0.0558 (0.0664) loss_oracle 0.6406 (0.6694) kd_loss 0.8769 (0.8410) acc 96.8750 (95.0000) gate/entropy 1.0985 (1.0984) gate/usage_max 0.3407 (0.3417) gate/usage_min 0.3268 (0.3273) gate/usage_std 0.0057 (0.0062) teacher/entropy 0.2203 (0.2610) teacher/usage_max 0.5601 (0.4958) teacher/usage_min 0.1618 (0.2004) teacher/usage_std 0.1672 (0.1281) nleep/row_max_mean 1529.6566 (1524.3401) nleep/row_max_std 63.5730 (60.9714) nleep/row_min_mean 1518.8064 (1513.3128) lr 1.9980e-03 eta 0:13:48
epoch [3/50] batch [40/162] time 0.093 (0.100) data 0.000 (0.006) loss 1.5930 (1.4437) teacher_loss 0.3030 (0.2290) loss_zs_kd 0.0382 (0.0621) loss_oracle 0.6606 (0.6713) kd_loss 0.9406 (0.8480) acc 87.5000 (93.9062) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3390 (0.3408) gate/usage_min 0.3247 (0.3266) gate/usage_std 0.0062 (0.0060) teacher/entropy 0.1527 (0.2518) teacher/usage_max 0.6319 (0.5451) teacher/usage_min 0.1429 (0.1824) teacher/usage_std 0.2138 (0.1588) nleep/row_max_mean 1529.0198 (1522.2951) nleep/row_max_std 61.4715 (63.7592) nleep/row_min_mean 1514.0260 (1510.6300) lr 1.9980e-03 eta 0:12:49
epoch [3/50] batch [60/162] time 0.091 (0.099) data 0.000 (0.004) loss 1.5490 (1.5091) teacher_loss 0.3283 (0.2814) loss_zs_kd 0.0397 (0.0576) loss_oracle 0.5465 (0.6505) kd_loss 0.9276 (0.8737) acc 90.6250 (92.3438) gate/entropy 1.0983 (1.0984) gate/usage_max 0.3413 (0.3403) gate/usage_min 0.3219 (0.3255) gate/usage_std 0.0083 (0.0063) teacher/entropy 0.1517 (0.2215) teacher/usage_max 0.8021 (0.6188) teacher/usage_min 0.0388 (0.1460) teacher/usage_std 0.3351 (0.2088) nleep/row_max_mean 1506.3591 (1522.4610) nleep/row_max_std 68.5286 (62.8667) nleep/row_min_mean 1492.6199 (1509.6879) lr 1.9980e-03 eta 0:12:41
epoch [3/50] batch [80/162] time 0.096 (0.098) data 0.000 (0.003) loss 1.7232 (1.5564) teacher_loss 0.4623 (0.3163) loss_zs_kd 0.0223 (0.0520) loss_oracle 0.5118 (0.6237) kd_loss 0.9938 (0.9023) acc 78.1250 (90.2344) gate/entropy 1.0980 (1.0984) gate/usage_max 0.3478 (0.3414) gate/usage_min 0.3182 (0.3241) gate/usage_std 0.0121 (0.0073) teacher/entropy 0.0668 (0.1861) teacher/usage_max 0.8934 (0.6900) teacher/usage_min 0.0092 (0.1131) teacher/usage_std 0.3977 (0.2578) nleep/row_max_mean 1505.2070 (1523.7369) nleep/row_max_std 60.1830 (62.3661) nleep/row_min_mean 1487.6366 (1509.4918) lr 1.9980e-03 eta 0:12:34
epoch [3/50] batch [100/162] time 0.096 (0.098) data 0.000 (0.003) loss 1.4401 (1.5881) teacher_loss 0.2041 (0.3469) loss_zs_kd 0.0226 (0.0466) loss_oracle 0.3968 (0.5965) kd_loss 1.0263 (0.9197) acc 93.7500 (89.0000) gate/entropy 1.0973 (1.0982) gate/usage_max 0.3552 (0.3434) gate/usage_min 0.3142 (0.3225) gate/usage_std 0.0168 (0.0088) teacher/entropy 0.0089 (0.1609) teacher/usage_max 0.9985 (0.7401) teacher/usage_min 0.0003 (0.0922) teacher/usage_std 0.4703 (0.2922) nleep/row_max_mean 1525.1960 (1524.0317) nleep/row_max_std 61.5539 (62.8125) nleep/row_min_mean 1503.4177 (1508.5421) lr 1.9980e-03 eta 0:12:30
epoch [3/50] batch [120/162] time 0.097 (0.097) data 0.000 (0.002) loss 1.6766 (1.5958) teacher_loss 0.5007 (0.3601) loss_zs_kd 0.0174 (0.0424) loss_oracle 0.3418 (0.5649) kd_loss 0.9963 (0.9321) acc 84.3750 (88.2812) gate/entropy 1.0965 (1.0980) gate/usage_max 0.3623 (0.3460) gate/usage_min 0.3107 (0.3208) gate/usage_std 0.0215 (0.0105) teacher/entropy 0.0196 (0.1394) teacher/usage_max 0.9957 (0.7789) teacher/usage_min 0.0008 (0.0769) teacher/usage_std 0.4683 (0.3189) nleep/row_max_mean 1518.1003 (1523.9650) nleep/row_max_std 59.2629 (63.0585) nleep/row_min_mean 1497.4612 (1507.5909) lr 1.9980e-03 eta 0:12:24
epoch [3/50] batch [140/162] time 0.104 (0.097) data 0.000 (0.002) loss 1.5362 (1.6036) teacher_loss 0.3283 (0.3714) loss_zs_kd 0.0107 (0.0384) loss_oracle 0.4583 (0.5448) kd_loss 0.9734 (0.9406) acc 90.6250 (87.5446) gate/entropy 1.0955 (1.0977) gate/usage_max 0.3696 (0.3489) gate/usage_min 0.3073 (0.3191) gate/usage_std 0.0265 (0.0125) teacher/entropy 0.0253 (0.1217) teacher/usage_max 0.9744 (0.8083) teacher/usage_min 0.0000 (0.0659) teacher/usage_std 0.4534 (0.3392) nleep/row_max_mean 1520.4307 (1524.2520) nleep/row_max_std 59.0624 (63.3197) nleep/row_min_mean 1497.1455 (1506.8913) lr 1.9980e-03 eta 0:12:20
epoch [3/50] batch [160/162] time 0.151 (0.097) data 0.000 (0.002) loss 1.4020 (1.6073) teacher_loss 0.2922 (0.3789) loss_zs_kd 0.0171 (0.0356) loss_oracle 0.2873 (0.5317) kd_loss 0.9576 (0.9447) acc 90.6250 (87.3047) gate/entropy 1.0942 (1.0974) gate/usage_max 0.3771 (0.3520) gate/usage_min 0.3034 (0.3174) gate/usage_std 0.0316 (0.0145) teacher/entropy 0.0265 (0.1082) teacher/usage_max 0.9466 (0.8304) teacher/usage_min 0.0000 (0.0577) teacher/usage_std 0.4342 (0.3544) nleep/row_max_mean 1520.2031 (1524.4516) nleep/row_max_std 68.3466 (63.4604) nleep/row_min_mean 1495.4585 (1506.1837) lr 1.9980e-03 eta 0:12:16
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,948
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 89.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,598
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 74.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      87.2%, epoch: 3 *******
******* Domain s best val test acc: 79.2%, epoch: 3 *******
******* Domain s best test acc:     79.2%, epoch: 3 *******
epoch [4/50] batch [20/162] time 0.082 (0.113) data 0.000 (0.020) loss 1.7669 (1.5717) teacher_loss 0.6083 (0.4276) loss_zs_kd 0.0111 (0.0122) loss_oracle 0.4019 (0.3793) kd_loss 0.9521 (0.9483) acc 75.0000 (84.8438) gate/entropy 1.0926 (1.0933) gate/usage_max 0.3850 (0.3816) gate/usage_min 0.2997 (0.3014) gate/usage_std 0.0371 (0.0347) teacher/entropy 0.0026 (0.0174) teacher/usage_max 0.9995 (0.9869) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4711 (0.4623) nleep/row_max_mean 1535.5752 (1527.9095) nleep/row_max_std 61.6033 (64.7365) nleep/row_min_mean 1510.5842 (1503.7760) lr 1.9921e-03 eta 0:14:14
epoch [4/50] batch [40/162] time 0.080 (0.101) data 0.000 (0.010) loss 1.5714 (1.5703) teacher_loss 0.4274 (0.4313) loss_zs_kd 0.0081 (0.0116) loss_oracle 0.4289 (0.3866) kd_loss 0.9255 (0.9399) acc 87.5000 (84.6875) gate/entropy 1.0909 (1.0925) gate/usage_max 0.3920 (0.3852) gate/usage_min 0.2965 (0.2997) gate/usage_std 0.0419 (0.0372) teacher/entropy 0.0195 (0.0166) teacher/usage_max 0.9626 (0.9879) teacher/usage_min 0.0001 (0.0003) teacher/usage_std 0.4452 (0.4629) nleep/row_max_mean 1498.4746 (1525.1832) nleep/row_max_std 78.5396 (64.7406) nleep/row_min_mean 1475.9806 (1501.4115) lr 1.9921e-03 eta 0:12:41
epoch [4/50] batch [60/162] time 0.075 (0.094) data 0.001 (0.007) loss 1.4679 (1.5749) teacher_loss 0.3589 (0.4429) loss_zs_kd 0.0053 (0.0108) loss_oracle 0.3965 (0.3873) kd_loss 0.9081 (0.9329) acc 90.6250 (83.7500) gate/entropy 1.0889 (1.0916) gate/usage_max 0.3992 (0.3887) gate/usage_min 0.2931 (0.2981) gate/usage_std 0.0470 (0.0396) teacher/entropy 0.0108 (0.0143) teacher/usage_max 0.9978 (0.9899) teacher/usage_min 0.0010 (0.0002) teacher/usage_std 0.4698 (0.4643) nleep/row_max_mean 1514.3639 (1523.4283) nleep/row_max_std 69.6393 (65.6088) nleep/row_min_mean 1491.0701 (1499.4538) lr 1.9921e-03 eta 0:11:53
epoch [4/50] batch [80/162] time 0.095 (0.092) data 0.000 (0.005) loss 1.4713 (1.5585) teacher_loss 0.3846 (0.4322) loss_zs_kd 0.0103 (0.0100) loss_oracle 0.3852 (0.3923) kd_loss 0.8889 (0.9252) acc 78.1250 (84.0234) gate/entropy 1.0869 (1.0907) gate/usage_max 0.4063 (0.3922) gate/usage_min 0.2901 (0.2965) gate/usage_std 0.0519 (0.0421) teacher/entropy 0.0131 (0.0128) teacher/usage_max 0.9955 (0.9915) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4683 (0.4654) nleep/row_max_mean 1545.7036 (1523.0951) nleep/row_max_std 58.4625 (65.3116) nleep/row_min_mean 1517.2731 (1498.9617) lr 1.9921e-03 eta 0:11:34
epoch [4/50] batch [100/162] time 0.082 (0.092) data 0.000 (0.004) loss 1.4624 (1.5578) teacher_loss 0.3965 (0.4373) loss_zs_kd 0.0091 (0.0102) loss_oracle 0.3848 (0.3964) kd_loss 0.8690 (0.9173) acc 87.5000 (83.6562) gate/entropy 1.0847 (1.0897) gate/usage_max 0.4129 (0.3957) gate/usage_min 0.2872 (0.2949) gate/usage_std 0.0565 (0.0445) teacher/entropy 0.0171 (0.0121) teacher/usage_max 0.9949 (0.9916) teacher/usage_min 0.0006 (0.0002) teacher/usage_std 0.4678 (0.4655) nleep/row_max_mean 1542.0730 (1523.0464) nleep/row_max_std 55.0632 (65.4997) nleep/row_min_mean 1516.6846 (1498.8674) lr 1.9921e-03 eta 0:11:30
epoch [4/50] batch [120/162] time 0.090 (0.092) data 0.000 (0.004) loss 1.8047 (1.5546) teacher_loss 0.7544 (0.4419) loss_zs_kd 0.0200 (0.0105) loss_oracle 0.3430 (0.3982) kd_loss 0.8688 (0.9084) acc 71.8750 (83.6979) gate/entropy 1.0825 (1.0887) gate/usage_max 0.4192 (0.3991) gate/usage_min 0.2842 (0.2933) gate/usage_std 0.0609 (0.0469) teacher/entropy 0.0007 (0.0131) teacher/usage_max 0.9999 (0.9904) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4713 (0.4647) nleep/row_max_mean 1517.3245 (1522.3478) nleep/row_max_std 76.1843 (65.5011) nleep/row_min_mean 1492.7363 (1498.2823) lr 1.9921e-03 eta 0:11:27
epoch [4/50] batch [140/162] time 0.081 (0.091) data 0.000 (0.003) loss 1.4455 (1.5457) teacher_loss 0.4095 (0.4412) loss_zs_kd 0.0049 (0.0102) loss_oracle 0.3524 (0.3989) kd_loss 0.8572 (0.8999) acc 78.1250 (83.7723) gate/entropy 1.0804 (1.0876) gate/usage_max 0.4248 (0.4024) gate/usage_min 0.2817 (0.2918) gate/usage_std 0.0649 (0.0492) teacher/entropy 0.0213 (0.0140) teacher/usage_max 0.9391 (0.9893) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4291 (0.4639) nleep/row_max_mean 1518.0411 (1521.4475) nleep/row_max_std 60.8598 (65.5528) nleep/row_min_mean 1495.5647 (1497.5319) lr 1.9921e-03 eta 0:11:23
epoch [4/50] batch [160/162] time 0.085 (0.091) data 0.000 (0.003) loss 1.7405 (1.5475) teacher_loss 0.6663 (0.4497) loss_zs_kd 0.0102 (0.0102) loss_oracle 0.4312 (0.4012) kd_loss 0.8535 (0.8921) acc 78.1250 (83.4180) gate/entropy 1.0778 (1.0866) gate/usage_max 0.4311 (0.4056) gate/usage_min 0.2787 (0.2904) gate/usage_std 0.0693 (0.0515) teacher/entropy 0.0003 (0.0152) teacher/usage_max 0.9687 (0.9867) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.4495 (0.4621) nleep/row_max_mean 1520.0378 (1521.5651) nleep/row_max_std 67.0460 (65.4381) nleep/row_min_mean 1495.3612 (1497.6471) lr 1.9921e-03 eta 0:11:16
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,915
* accuracy: 85.7%
* error: 14.3%
* macro_f1: 88.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,685
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 74.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      87.2%, epoch: 3 *******
******* Domain s best val test acc: 79.2%, epoch: 3 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [5/50] batch [20/162] time 0.092 (0.112) data 0.000 (0.013) loss 1.5154 (1.5065) teacher_loss 0.4522 (0.4686) loss_zs_kd 0.0039 (0.0076) loss_oracle 0.4594 (0.4244) kd_loss 0.8315 (0.8219) acc 81.2500 (82.5000) gate/entropy 1.0751 (1.0763) gate/usage_max 0.4375 (0.4347) gate/usage_min 0.2760 (0.2773) gate/usage_std 0.0738 (0.0718) teacher/entropy 0.0087 (0.0216) teacher/usage_max 0.9677 (0.9754) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.4488 (0.4542) nleep/row_max_mean 1522.8656 (1520.8215) nleep/row_max_std 63.0523 (61.7833) nleep/row_min_mean 1498.0225 (1496.5758) lr 1.9823e-03 eta 0:13:55
epoch [5/50] batch [40/162] time 0.102 (0.103) data 0.000 (0.007) loss 1.4769 (1.4428) teacher_loss 0.4789 (0.4146) loss_zs_kd 0.0049 (0.0085) loss_oracle 0.4071 (0.4210) kd_loss 0.7920 (0.8135) acc 84.3750 (83.8281) gate/entropy 1.0725 (1.0751) gate/usage_max 0.4434 (0.4375) gate/usage_min 0.2736 (0.2760) gate/usage_std 0.0779 (0.0738) teacher/entropy 0.0248 (0.0251) teacher/usage_max 0.9925 (0.9721) teacher/usage_min 0.0006 (0.0037) teacher/usage_std 0.4661 (0.4518) nleep/row_max_mean 1525.8074 (1519.8315) nleep/row_max_std 58.5134 (60.4067) nleep/row_min_mean 1500.6035 (1495.5447) lr 1.9823e-03 eta 0:12:41
epoch [5/50] batch [60/162] time 0.115 (0.104) data 0.002 (0.005) loss 1.2266 (1.4411) teacher_loss 0.2157 (0.4215) loss_zs_kd 0.0062 (0.0090) loss_oracle 0.4482 (0.4168) kd_loss 0.7837 (0.8068) acc 90.6250 (83.8021) gate/entropy 1.0699 (1.0737) gate/usage_max 0.4488 (0.4404) gate/usage_min 0.2714 (0.2748) gate/usage_std 0.0817 (0.0759) teacher/entropy 0.0319 (0.0238) teacher/usage_max 0.9694 (0.9759) teacher/usage_min 0.0003 (0.0030) teacher/usage_std 0.4499 (0.4545) nleep/row_max_mean 1524.9518 (1518.9112) nleep/row_max_std 53.4793 (61.2281) nleep/row_min_mean 1500.2197 (1494.3709) lr 1.9823e-03 eta 0:12:47
epoch [5/50] batch [80/162] time 0.097 (0.102) data 0.000 (0.004) loss 1.5047 (1.4313) teacher_loss 0.5207 (0.4198) loss_zs_kd 0.0116 (0.0090) loss_oracle 0.4414 (0.4123) kd_loss 0.7575 (0.8009) acc 78.1250 (84.2969) gate/entropy 1.0670 (1.0724) gate/usage_max 0.4546 (0.4433) gate/usage_min 0.2691 (0.2736) gate/usage_std 0.0858 (0.0779) teacher/entropy 0.0370 (0.0236) teacher/usage_max 0.9877 (0.9760) teacher/usage_min 0.0035 (0.0031) teacher/usage_std 0.4627 (0.4546) nleep/row_max_mean 1520.7852 (1519.0095) nleep/row_max_std 59.3295 (60.9254) nleep/row_min_mean 1494.7675 (1494.2678) lr 1.9823e-03 eta 0:12:34
epoch [5/50] batch [100/162] time 0.096 (0.102) data 0.000 (0.003) loss 1.4826 (1.4278) teacher_loss 0.5406 (0.4221) loss_zs_kd 0.0122 (0.0093) loss_oracle 0.3236 (0.4099) kd_loss 0.7741 (0.7961) acc 75.0000 (84.1250) gate/entropy 1.0644 (1.0710) gate/usage_max 0.4597 (0.4461) gate/usage_min 0.2670 (0.2725) gate/usage_std 0.0894 (0.0798) teacher/entropy 0.0034 (0.0225) teacher/usage_max 0.9993 (0.9757) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.4709 (0.4544) nleep/row_max_mean 1526.1727 (1519.9602) nleep/row_max_std 52.8189 (60.5421) nleep/row_min_mean 1499.7007 (1494.8729) lr 1.9823e-03 eta 0:12:28
epoch [5/50] batch [120/162] time 0.098 (0.101) data 0.000 (0.002) loss 1.5262 (1.4242) teacher_loss 0.5627 (0.4239) loss_zs_kd 0.0081 (0.0091) loss_oracle 0.3920 (0.4106) kd_loss 0.7634 (0.7904) acc 81.2500 (83.9062) gate/entropy 1.0617 (1.0697) gate/usage_max 0.4647 (0.4488) gate/usage_min 0.2651 (0.2714) gate/usage_std 0.0929 (0.0818) teacher/entropy 0.0227 (0.0231) teacher/usage_max 0.9647 (0.9745) teacher/usage_min 0.0000 (0.0036) teacher/usage_std 0.4467 (0.4535) nleep/row_max_mean 1504.1050 (1519.7491) nleep/row_max_std 65.2822 (60.4957) nleep/row_min_mean 1480.1611 (1494.5942) lr 1.9823e-03 eta 0:12:20
epoch [5/50] batch [140/162] time 0.107 (0.101) data 0.000 (0.002) loss 1.1665 (1.4191) teacher_loss 0.2250 (0.4250) loss_zs_kd 0.0079 (0.0096) loss_oracle 0.3924 (0.4104) kd_loss 0.7414 (0.7840) acc 93.7500 (84.1295) gate/entropy 1.0589 (1.0683) gate/usage_max 0.4696 (0.4515) gate/usage_min 0.2632 (0.2703) gate/usage_std 0.0964 (0.0836) teacher/entropy 0.0437 (0.0245) teacher/usage_max 0.9490 (0.9736) teacher/usage_min 0.0247 (0.0040) teacher/usage_std 0.4354 (0.4529) nleep/row_max_mean 1519.0273 (1519.8006) nleep/row_max_std 65.6485 (60.4975) nleep/row_min_mean 1492.2739 (1494.4997) lr 1.9823e-03 eta 0:12:14
epoch [5/50] batch [160/162] time 0.085 (0.099) data 0.000 (0.002) loss 1.2195 (1.4105) teacher_loss 0.2991 (0.4238) loss_zs_kd 0.0047 (0.0098) loss_oracle 0.3936 (0.4075) kd_loss 0.7212 (0.7780) acc 93.7500 (84.2188) gate/entropy 1.0561 (1.0670) gate/usage_max 0.4745 (0.4541) gate/usage_min 0.2612 (0.2693) gate/usage_std 0.0998 (0.0854) teacher/entropy 0.0629 (0.0253) teacher/usage_max 0.9345 (0.9733) teacher/usage_min 0.0254 (0.0043) teacher/usage_std 0.4251 (0.4527) nleep/row_max_mean 1507.6870 (1519.2029) nleep/row_max_std 73.5025 (60.9053) nleep/row_min_mean 1480.7007 (1493.8701) lr 1.9823e-03 eta 0:12:04
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,946
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,585
* accuracy: 78.8%
* error: 21.2%
* macro_f1: 72.4%
******* Domain s best val acc:      87.2%, epoch: 3 *******
******* Domain s best val test acc: 79.2%, epoch: 3 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [6/50] batch [20/162] time 0.089 (0.100) data 0.000 (0.015) loss 1.4296 (1.3803) teacher_loss 0.4666 (0.4563) loss_zs_kd 0.0100 (0.0114) loss_oracle 0.4705 (0.3885) kd_loss 0.7227 (0.7240) acc 87.5000 (81.8750) gate/entropy 1.0532 (1.0545) gate/usage_max 0.4794 (0.4771) gate/usage_min 0.2593 (0.2602) gate/usage_std 0.1033 (0.1017) teacher/entropy 0.0145 (0.0350) teacher/usage_max 0.9969 (0.9682) teacher/usage_min 0.0000 (0.0065) teacher/usage_std 0.4692 (0.4490) nleep/row_max_mean 1522.7251 (1516.3522) nleep/row_max_std 66.7822 (62.2793) nleep/row_min_mean 1495.8579 (1489.4377) lr 1.9686e-03 eta 0:12:06
epoch [6/50] batch [40/162] time 0.085 (0.092) data 0.000 (0.008) loss 1.1368 (1.3248) teacher_loss 0.2221 (0.4040) loss_zs_kd 0.0070 (0.0106) loss_oracle 0.3726 (0.3908) kd_loss 0.7249 (0.7201) acc 93.7500 (84.2969) gate/entropy 1.0507 (1.0532) gate/usage_max 0.4834 (0.4793) gate/usage_min 0.2575 (0.2593) gate/usage_std 0.1061 (0.1032) teacher/entropy 0.0260 (0.0454) teacher/usage_max 0.9617 (0.9509) teacher/usage_min 0.0000 (0.0106) teacher/usage_std 0.4446 (0.4370) nleep/row_max_mean 1510.5623 (1517.9910) nleep/row_max_std 61.0238 (60.0666) nleep/row_min_mean 1484.4338 (1491.3801) lr 1.9686e-03 eta 0:11:07
epoch [6/50] batch [60/162] time 0.086 (0.089) data 0.001 (0.005) loss 1.2151 (1.3288) teacher_loss 0.3241 (0.4072) loss_zs_kd 0.0131 (0.0123) loss_oracle 0.3757 (0.3956) kd_loss 0.6966 (0.7177) acc 90.6250 (84.2188) gate/entropy 1.0484 (1.0519) gate/usage_max 0.4870 (0.4814) gate/usage_min 0.2562 (0.2584) gate/usage_std 0.1086 (0.1047) teacher/entropy 0.1086 (0.0573) teacher/usage_max 0.8674 (0.9299) teacher/usage_min 0.0028 (0.0125) teacher/usage_std 0.3812 (0.4226) nleep/row_max_mean 1517.4811 (1518.7059) nleep/row_max_std 60.6506 (59.3557) nleep/row_min_mean 1492.5385 (1492.4187) lr 1.9686e-03 eta 0:10:44
epoch [6/50] batch [80/162] time 0.094 (0.088) data 0.000 (0.004) loss 1.2103 (1.3244) teacher_loss 0.3438 (0.4050) loss_zs_kd 0.0098 (0.0139) loss_oracle 0.3537 (0.3947) kd_loss 0.6848 (0.7151) acc 87.5000 (84.5312) gate/entropy 1.0462 (1.0507) gate/usage_max 0.4904 (0.4833) gate/usage_min 0.2546 (0.2576) gate/usage_std 0.1111 (0.1060) teacher/entropy 0.1100 (0.0691) teacher/usage_max 0.8740 (0.9102) teacher/usage_min 0.0021 (0.0113) teacher/usage_std 0.3855 (0.4098) nleep/row_max_mean 1507.2325 (1518.4146) nleep/row_max_std 59.3046 (58.9719) nleep/row_min_mean 1484.8225 (1492.4745) lr 1.9686e-03 eta 0:10:34
epoch [6/50] batch [100/162] time 0.091 (0.089) data 0.000 (0.003) loss 1.2385 (1.3150) teacher_loss 0.2679 (0.3972) loss_zs_kd 0.0286 (0.0151) loss_oracle 0.4153 (0.3941) kd_loss 0.7485 (0.7131) acc 87.5000 (84.6875) gate/entropy 1.0437 (1.0495) gate/usage_max 0.4941 (0.4851) gate/usage_min 0.2523 (0.2568) gate/usage_std 0.1137 (0.1073) teacher/entropy 0.0923 (0.0769) teacher/usage_max 0.7958 (0.8963) teacher/usage_min 0.0007 (0.0112) teacher/usage_std 0.3373 (0.4007) nleep/row_max_mean 1530.6946 (1518.9953) nleep/row_max_std 55.1485 (58.3912) nleep/row_min_mean 1505.8394 (1493.3606) lr 1.9686e-03 eta 0:10:39
epoch [6/50] batch [120/162] time 0.094 (0.090) data 0.000 (0.003) loss 1.2834 (1.3186) teacher_loss 0.3259 (0.4022) loss_zs_kd 0.0170 (0.0171) loss_oracle 0.4352 (0.3954) kd_loss 0.7314 (0.7102) acc 87.5000 (84.7135) gate/entropy 1.0418 (1.0484) gate/usage_max 0.4969 (0.4868) gate/usage_min 0.2504 (0.2559) gate/usage_std 0.1157 (0.1085) teacher/entropy 0.1168 (0.0831) teacher/usage_max 0.7788 (0.8870) teacher/usage_min 0.0002 (0.0122) teacher/usage_std 0.3276 (0.3944) nleep/row_max_mean 1517.2817 (1519.0290) nleep/row_max_std 60.2476 (57.9313) nleep/row_min_mean 1490.8049 (1493.5511) lr 1.9686e-03 eta 0:10:45
epoch [6/50] batch [140/162] time 0.093 (0.091) data 0.000 (0.002) loss 1.8229 (1.3241) teacher_loss 0.8997 (0.4054) loss_zs_kd 0.0143 (0.0180) loss_oracle 0.4101 (0.3989) kd_loss 0.7110 (0.7103) acc 71.8750 (84.3750) gate/entropy 1.0401 (1.0473) gate/usage_max 0.4995 (0.4885) gate/usage_min 0.2486 (0.2549) gate/usage_std 0.1175 (0.1097) teacher/entropy 0.1586 (0.0876) teacher/usage_max 0.7440 (0.8760) teacher/usage_min 0.0283 (0.0131) teacher/usage_std 0.3015 (0.3872) nleep/row_max_mean 1505.5913 (1518.8601) nleep/row_max_std 57.8580 (57.9590) nleep/row_min_mean 1483.7605 (1493.6499) lr 1.9686e-03 eta 0:10:48
epoch [6/50] batch [160/162] time 0.087 (0.091) data 0.000 (0.002) loss 1.2878 (1.3237) teacher_loss 0.4633 (0.4078) loss_zs_kd 0.0241 (0.0182) loss_oracle 0.4109 (0.3979) kd_loss 0.6071 (0.7079) acc 78.1250 (84.3945) gate/entropy 1.0383 (1.0463) gate/usage_max 0.5020 (0.4900) gate/usage_min 0.2470 (0.2540) gate/usage_std 0.1193 (0.1108) teacher/entropy 0.1128 (0.0904) teacher/usage_max 0.9558 (0.8715) teacher/usage_min 0.0091 (0.0129) teacher/usage_std 0.4403 (0.3842) nleep/row_max_mean 1509.2325 (1518.7629) nleep/row_max_std 52.9343 (57.7952) nleep/row_min_mean 1487.2208 (1493.8553) lr 1.9686e-03 eta 0:10:48
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,950
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,322
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 69.8%
******* Domain s best val acc:      87.3%, epoch: 6 *******
******* Domain s best val test acc: 70.7%, epoch: 6 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [7/50] batch [20/162] time 0.090 (0.113) data 0.000 (0.017) loss 1.4304 (1.2693) teacher_loss 0.4392 (0.3533) loss_zs_kd 0.0337 (0.0240) loss_oracle 0.4172 (0.4013) kd_loss 0.7657 (0.7034) acc 84.3750 (86.2500) gate/entropy 1.0362 (1.0371) gate/usage_max 0.5050 (0.5037) gate/usage_min 0.2449 (0.2457) gate/usage_std 0.1214 (0.1205) teacher/entropy 0.0532 (0.1126) teacher/usage_max 0.8070 (0.8135) teacher/usage_min 0.0003 (0.0155) teacher/usage_std 0.3440 (0.3470) nleep/row_max_mean 1510.3564 (1516.8685) nleep/row_max_std 57.8814 (59.1411) nleep/row_min_mean 1484.7310 (1492.8602) lr 1.9511e-03 eta 0:13:20
epoch [7/50] batch [40/162] time 0.094 (0.103) data 0.000 (0.009) loss 1.1348 (1.2738) teacher_loss 0.2122 (0.3655) loss_zs_kd 0.0122 (0.0218) loss_oracle 0.4371 (0.3921) kd_loss 0.6979 (0.7013) acc 93.7500 (85.3906) gate/entropy 1.0347 (1.0362) gate/usage_max 0.5071 (0.5049) gate/usage_min 0.2435 (0.2449) gate/usage_std 0.1229 (0.1214) teacher/entropy 0.0968 (0.1017) teacher/usage_max 0.8365 (0.8296) teacher/usage_min 0.0044 (0.0181) teacher/usage_std 0.3614 (0.3563) nleep/row_max_mean 1522.6541 (1517.6372) nleep/row_max_std 61.0508 (60.1489) nleep/row_min_mean 1495.8701 (1493.6815) lr 1.9511e-03 eta 0:12:06
epoch [7/50] batch [60/162] time 0.095 (0.097) data 0.000 (0.006) loss 1.7219 (1.2913) teacher_loss 0.7561 (0.3881) loss_zs_kd 0.0243 (0.0217) loss_oracle 0.4518 (0.3832) kd_loss 0.7277 (0.7008) acc 65.6250 (84.9479) gate/entropy 1.0326 (1.0353) gate/usage_max 0.5099 (0.5062) gate/usage_min 0.2417 (0.2441) gate/usage_std 0.1249 (0.1223) teacher/entropy 0.0301 (0.0988) teacher/usage_max 0.8822 (0.8320) teacher/usage_min 0.0012 (0.0191) teacher/usage_std 0.3910 (0.3576) nleep/row_max_mean 1512.0459 (1516.2027) nleep/row_max_std 57.9215 (60.5983) nleep/row_min_mean 1487.0923 (1492.1148) lr 1.9511e-03 eta 0:11:28
epoch [7/50] batch [80/162] time 0.087 (0.095) data 0.000 (0.004) loss 1.3482 (1.2866) teacher_loss 0.4231 (0.3867) loss_zs_kd 0.0308 (0.0230) loss_oracle 0.4991 (0.3868) kd_loss 0.6601 (0.6950) acc 78.1250 (85.5469) gate/entropy 1.0308 (1.0344) gate/usage_max 0.5123 (0.5075) gate/usage_min 0.2405 (0.2433) gate/usage_std 0.1266 (0.1232) teacher/entropy 0.1266 (0.0985) teacher/usage_max 0.8399 (0.8382) teacher/usage_min 0.0457 (0.0216) teacher/usage_std 0.3593 (0.3614) nleep/row_max_mean 1511.7277 (1516.6024) nleep/row_max_std 65.4667 (60.5707) nleep/row_min_mean 1486.4758 (1492.2805) lr 1.9511e-03 eta 0:11:08
epoch [7/50] batch [100/162] time 0.094 (0.094) data 0.000 (0.004) loss 1.2750 (1.2752) teacher_loss 0.4277 (0.3752) loss_zs_kd 0.0272 (0.0225) loss_oracle 0.3298 (0.3900) kd_loss 0.6688 (0.6937) acc 78.1250 (86.0938) gate/entropy 1.0286 (1.0334) gate/usage_max 0.5152 (0.5087) gate/usage_min 0.2388 (0.2426) gate/usage_std 0.1287 (0.1241) teacher/entropy 0.0951 (0.0946) teacher/usage_max 0.8638 (0.8431) teacher/usage_min 0.0179 (0.0229) teacher/usage_std 0.3773 (0.3644) nleep/row_max_mean 1517.6831 (1517.2713) nleep/row_max_std 59.3867 (60.4465) nleep/row_min_mean 1492.5032 (1492.6683) lr 1.9511e-03 eta 0:10:59
epoch [7/50] batch [120/162] time 0.100 (0.094) data 0.000 (0.003) loss 1.5274 (1.2841) teacher_loss 0.5157 (0.3820) loss_zs_kd 0.0440 (0.0231) loss_oracle 0.4858 (0.3942) kd_loss 0.7468 (0.6935) acc 81.2500 (85.9375) gate/entropy 1.0272 (1.0325) gate/usage_max 0.5172 (0.5100) gate/usage_min 0.2377 (0.2418) gate/usage_std 0.1300 (0.1249) teacher/entropy 0.0525 (0.0904) teacher/usage_max 0.8133 (0.8468) teacher/usage_min 0.0443 (0.0248) teacher/usage_std 0.3418 (0.3666) nleep/row_max_mean 1505.6055 (1517.1036) nleep/row_max_std 57.1474 (60.4245) nleep/row_min_mean 1480.0659 (1492.4184) lr 1.9511e-03 eta 0:10:55
epoch [7/50] batch [140/162] time 0.097 (0.094) data 0.000 (0.003) loss 1.2852 (1.2847) teacher_loss 0.2411 (0.3815) loss_zs_kd 0.0168 (0.0226) loss_oracle 0.4751 (0.3944) kd_loss 0.7982 (0.6947) acc 93.7500 (85.8482) gate/entropy 1.0252 (1.0316) gate/usage_max 0.5198 (0.5112) gate/usage_min 0.2362 (0.2412) gate/usage_std 0.1319 (0.1258) teacher/entropy 0.0489 (0.0871) teacher/usage_max 0.7505 (0.8476) teacher/usage_min 0.1138 (0.0269) teacher/usage_std 0.2951 (0.3669) nleep/row_max_mean 1516.0127 (1517.1167) nleep/row_max_std 66.2057 (60.3010) nleep/row_min_mean 1491.3701 (1492.3866) lr 1.9511e-03 eta 0:10:57
epoch [7/50] batch [160/162] time 0.081 (0.093) data 0.000 (0.002) loss 1.1899 (1.2798) teacher_loss 0.3130 (0.3798) loss_zs_kd 0.0190 (0.0223) loss_oracle 0.3664 (0.3918) kd_loss 0.6842 (0.6930) acc 93.7500 (85.8398) gate/entropy 1.0238 (1.0307) gate/usage_max 0.5215 (0.5124) gate/usage_min 0.2354 (0.2405) gate/usage_std 0.1331 (0.1266) teacher/entropy 0.0776 (0.0854) teacher/usage_max 0.8557 (0.8502) teacher/usage_min 0.0236 (0.0277) teacher/usage_std 0.3715 (0.3685) nleep/row_max_mean 1518.8053 (1516.8638) nleep/row_max_std 59.2907 (60.1990) nleep/row_min_mean 1495.3794 (1492.2424) lr 1.9511e-03 eta 0:10:51
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,958
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 89.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,341
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 71.5%
******* Domain s best val acc:      87.6%, epoch: 7 *******
******* Domain s best val test acc: 71.3%, epoch: 7 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [8/50] batch [20/162] time 0.087 (0.112) data 0.000 (0.018) loss 1.3489 (1.2804) teacher_loss 0.4484 (0.3884) loss_zs_kd 0.0108 (0.0177) loss_oracle 0.4728 (0.3879) kd_loss 0.6587 (0.6892) acc 84.3750 (85.1562) gate/entropy 1.0221 (1.0229) gate/usage_max 0.5237 (0.5226) gate/usage_min 0.2343 (0.2349) gate/usage_std 0.1346 (0.1339) teacher/entropy 0.0893 (0.0627) teacher/usage_max 0.8716 (0.8671) teacher/usage_min 0.0624 (0.0366) teacher/usage_std 0.3806 (0.3787) nleep/row_max_mean 1514.7556 (1515.9565) nleep/row_max_std 60.1980 (57.9997) nleep/row_min_mean 1490.8303 (1492.3039) lr 1.9298e-03 eta 0:12:55
epoch [8/50] batch [40/162] time 0.091 (0.104) data 0.000 (0.009) loss 1.3513 (1.3012) teacher_loss 0.4827 (0.4169) loss_zs_kd 0.0270 (0.0170) loss_oracle 0.3959 (0.3869) kd_loss 0.6571 (0.6823) acc 81.2500 (83.7500) gate/entropy 1.0206 (1.0222) gate/usage_max 0.5257 (0.5236) gate/usage_min 0.2335 (0.2344) gate/usage_std 0.1360 (0.1346) teacher/entropy 0.1001 (0.0647) teacher/usage_max 0.8557 (0.8720) teacher/usage_min 0.0479 (0.0381) teacher/usage_std 0.3699 (0.3819) nleep/row_max_mean 1503.4619 (1513.8678) nleep/row_max_std 57.3806 (58.4092) nleep/row_min_mean 1481.0751 (1490.5170) lr 1.9298e-03 eta 0:11:58
epoch [8/50] batch [60/162] time 0.092 (0.101) data 0.000 (0.006) loss 1.3587 (1.2744) teacher_loss 0.4212 (0.3903) loss_zs_kd 0.0180 (0.0171) loss_oracle 0.3942 (0.3857) kd_loss 0.7314 (0.6826) acc 84.3750 (84.3229) gate/entropy 1.0190 (1.0214) gate/usage_max 0.5276 (0.5246) gate/usage_min 0.2327 (0.2340) gate/usage_std 0.1374 (0.1353) teacher/entropy 0.0357 (0.0641) teacher/usage_max 0.8415 (0.8707) teacher/usage_min 0.0620 (0.0398) teacher/usage_std 0.3596 (0.3809) nleep/row_max_mean 1498.1404 (1514.9654) nleep/row_max_std 64.5675 (58.1696) nleep/row_min_mean 1475.6787 (1491.2302) lr 1.9298e-03 eta 0:11:38
epoch [8/50] batch [80/162] time 0.081 (0.097) data 0.000 (0.005) loss 1.5728 (1.2769) teacher_loss 0.6944 (0.3883) loss_zs_kd 0.0170 (0.0175) loss_oracle 0.3489 (0.3910) kd_loss 0.6954 (0.6844) acc 78.1250 (84.8047) gate/entropy 1.0174 (1.0206) gate/usage_max 0.5296 (0.5256) gate/usage_min 0.2318 (0.2336) gate/usage_std 0.1388 (0.1360) teacher/entropy 0.0569 (0.0614) teacher/usage_max 0.8563 (0.8704) teacher/usage_min 0.0556 (0.0390) teacher/usage_std 0.3700 (0.3807) nleep/row_max_mean 1495.4354 (1515.1498) nleep/row_max_std 70.5823 (58.9251) nleep/row_min_mean 1472.4208 (1491.0056) lr 1.9298e-03 eta 0:11:09
epoch [8/50] batch [100/162] time 0.075 (0.099) data 0.000 (0.004) loss 1.4770 (1.2769) teacher_loss 0.5894 (0.3909) loss_zs_kd 0.0089 (0.0176) loss_oracle 0.4345 (0.3887) kd_loss 0.6658 (0.6828) acc 75.0000 (84.5938) gate/entropy 1.0160 (1.0198) gate/usage_max 0.5314 (0.5266) gate/usage_min 0.2311 (0.2331) gate/usage_std 0.1401 (0.1367) teacher/entropy 0.0353 (0.0597) teacher/usage_max 0.9162 (0.8728) teacher/usage_min 0.0337 (0.0392) teacher/usage_std 0.4122 (0.3824) nleep/row_max_mean 1520.6650 (1514.6015) nleep/row_max_std 58.8379 (59.0385) nleep/row_min_mean 1492.5430 (1490.3303) lr 1.9298e-03 eta 0:11:22
epoch [8/50] batch [120/162] time 0.085 (0.096) data 0.000 (0.003) loss 1.6660 (1.2778) teacher_loss 0.7698 (0.3914) loss_zs_kd 0.0299 (0.0176) loss_oracle 0.3303 (0.3863) kd_loss 0.7162 (0.6845) acc 78.1250 (84.5833) gate/entropy 1.0147 (1.0191) gate/usage_max 0.5330 (0.5275) gate/usage_min 0.2304 (0.2327) gate/usage_std 0.1412 (0.1373) teacher/entropy 0.0411 (0.0576) teacher/usage_max 0.8447 (0.8718) teacher/usage_min 0.0774 (0.0404) teacher/usage_std 0.3616 (0.3817) nleep/row_max_mean 1490.8059 (1514.0094) nleep/row_max_std 70.0564 (59.0419) nleep/row_min_mean 1470.2557 (1489.6930) lr 1.9298e-03 eta 0:10:58
epoch [8/50] batch [140/162] time 0.095 (0.095) data 0.000 (0.003) loss 1.2930 (1.2805) teacher_loss 0.3865 (0.3918) loss_zs_kd 0.0146 (0.0174) loss_oracle 0.4308 (0.3898) kd_loss 0.6838 (0.6851) acc 87.5000 (84.5982) gate/entropy 1.0132 (1.0183) gate/usage_max 0.5348 (0.5284) gate/usage_min 0.2296 (0.2323) gate/usage_std 0.1425 (0.1380) teacher/entropy 0.0526 (0.0557) teacher/usage_max 0.8677 (0.8720) teacher/usage_min 0.0486 (0.0408) teacher/usage_std 0.3782 (0.3818) nleep/row_max_mean 1519.2129 (1514.4368) nleep/row_max_std 65.4141 (59.1569) nleep/row_min_mean 1491.8555 (1489.7292) lr 1.9298e-03 eta 0:10:45
epoch [8/50] batch [160/162] time 0.085 (0.094) data 0.000 (0.002) loss 1.3681 (1.2744) teacher_loss 0.5205 (0.3875) loss_zs_kd 0.0084 (0.0169) loss_oracle 0.4009 (0.3896) kd_loss 0.6429 (0.6837) acc 78.1250 (84.7266) gate/entropy 1.0117 (1.0176) gate/usage_max 0.5365 (0.5293) gate/usage_min 0.2289 (0.2319) gate/usage_std 0.1437 (0.1386) teacher/entropy 0.0213 (0.0528) teacher/usage_max 0.9503 (0.8757) teacher/usage_min 0.0184 (0.0383) teacher/usage_std 0.4363 (0.3844) nleep/row_max_mean 1518.9492 (1514.8297) nleep/row_max_std 58.7937 (59.3465) nleep/row_min_mean 1489.0286 (1489.7464) lr 1.9298e-03 eta 0:10:39
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,956
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,512
* accuracy: 76.5%
* error: 23.5%
* macro_f1: 76.0%
******* Domain s best val acc:      87.6%, epoch: 7 *******
******* Domain s best val test acc: 71.3%, epoch: 7 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [9/50] batch [20/162] time 0.095 (0.115) data 0.000 (0.017) loss 1.4332 (1.3066) teacher_loss 0.5644 (0.4158) loss_zs_kd 0.0433 (0.0200) loss_oracle 0.3974 (0.3886) kd_loss 0.6485 (0.6865) acc 81.2500 (82.3438) gate/entropy 1.0103 (1.0109) gate/usage_max 0.5382 (0.5374) gate/usage_min 0.2282 (0.2285) gate/usage_std 0.1449 (0.1443) teacher/entropy 0.0255 (0.0400) teacher/usage_max 0.9365 (0.8752) teacher/usage_min 0.0057 (0.0343) teacher/usage_std 0.4270 (0.3842) nleep/row_max_mean 1522.7677 (1512.8783) nleep/row_max_std 60.8258 (61.3925) nleep/row_min_mean 1493.6714 (1485.2488) lr 1.9048e-03 eta 0:12:56
epoch [9/50] batch [40/162] time 0.094 (0.103) data 0.000 (0.009) loss 1.2655 (1.2789) teacher_loss 0.3983 (0.4003) loss_zs_kd 0.0069 (0.0191) loss_oracle 0.3696 (0.3800) kd_loss 0.6789 (0.6791) acc 81.2500 (83.9844) gate/entropy 1.0090 (1.0103) gate/usage_max 0.5398 (0.5382) gate/usage_min 0.2276 (0.2282) gate/usage_std 0.1460 (0.1449) teacher/entropy 0.0220 (0.0323) teacher/usage_max 0.9022 (0.8918) teacher/usage_min 0.0025 (0.0306) teacher/usage_std 0.4040 (0.3957) nleep/row_max_mean 1526.0613 (1516.0060) nleep/row_max_std 56.8028 (60.4231) nleep/row_min_mean 1496.3369 (1488.0306) lr 1.9048e-03 eta 0:11:38
epoch [9/50] batch [60/162] time 0.096 (0.100) data 0.000 (0.006) loss 1.0944 (1.2612) teacher_loss 0.3295 (0.3883) loss_zs_kd 0.0088 (0.0179) loss_oracle 0.2945 (0.3742) kd_loss 0.6133 (0.6768) acc 93.7500 (84.4792) gate/entropy 1.0076 (1.0097) gate/usage_max 0.5413 (0.5389) gate/usage_min 0.2269 (0.2279) gate/usage_std 0.1471 (0.1454) teacher/entropy 0.0005 (0.0293) teacher/usage_max 0.9999 (0.8967) teacher/usage_min 0.0000 (0.0253) teacher/usage_std 0.4714 (0.3993) nleep/row_max_mean 1532.6809 (1516.9440) nleep/row_max_std 53.0464 (59.8499) nleep/row_min_mean 1500.4817 (1488.4486) lr 1.9048e-03 eta 0:11:13
epoch [9/50] batch [80/162] time 0.093 (0.099) data 0.000 (0.004) loss 1.3348 (1.2644) teacher_loss 0.4457 (0.3884) loss_zs_kd 0.0162 (0.0172) loss_oracle 0.4402 (0.3776) kd_loss 0.6609 (0.6786) acc 81.2500 (84.8438) gate/entropy 1.0066 (1.0091) gate/usage_max 0.5425 (0.5396) gate/usage_min 0.2265 (0.2276) gate/usage_std 0.1479 (0.1459) teacher/entropy 0.0049 (0.0287) teacher/usage_max 0.9375 (0.8942) teacher/usage_min 0.0011 (0.0262) teacher/usage_std 0.4279 (0.3975) nleep/row_max_mean 1540.0627 (1516.9549) nleep/row_max_std 55.6765 (60.4712) nleep/row_min_mean 1505.3323 (1488.2581) lr 1.9048e-03 eta 0:11:02
epoch [9/50] batch [100/162] time 0.102 (0.098) data 0.000 (0.004) loss 1.0317 (1.2605) teacher_loss 0.2264 (0.3836) loss_zs_kd 0.0182 (0.0175) loss_oracle 0.2870 (0.3766) kd_loss 0.6527 (0.6798) acc 90.6250 (85.0312) gate/entropy 1.0057 (1.0085) gate/usage_max 0.5436 (0.5403) gate/usage_min 0.2262 (0.2274) gate/usage_std 0.1487 (0.1464) teacher/entropy 0.0112 (0.0272) teacher/usage_max 0.9375 (0.8935) teacher/usage_min 0.0035 (0.0239) teacher/usage_std 0.4278 (0.3973) nleep/row_max_mean 1513.8529 (1516.3085) nleep/row_max_std 59.3914 (60.8168) nleep/row_min_mean 1485.2054 (1487.6247) lr 1.9048e-03 eta 0:10:54
epoch [9/50] batch [120/162] time 0.094 (0.097) data 0.000 (0.003) loss 1.2465 (1.2575) teacher_loss 0.3236 (0.3832) loss_zs_kd 0.0094 (0.0179) loss_oracle 0.3532 (0.3745) kd_loss 0.7416 (0.6781) acc 87.5000 (85.1562) gate/entropy 1.0047 (1.0079) gate/usage_max 0.5447 (0.5410) gate/usage_min 0.2257 (0.2271) gate/usage_std 0.1495 (0.1468) teacher/entropy 0.0028 (0.0254) teacher/usage_max 0.8438 (0.8964) teacher/usage_min 0.0316 (0.0217) teacher/usage_std 0.3629 (0.3995) nleep/row_max_mean 1520.9708 (1516.3535) nleep/row_max_std 55.1905 (61.0063) nleep/row_min_mean 1489.6013 (1487.6469) lr 1.9048e-03 eta 0:10:50
epoch [9/50] batch [140/162] time 0.097 (0.097) data 0.000 (0.003) loss 1.1221 (1.2552) teacher_loss 0.2954 (0.3837) loss_zs_kd 0.0128 (0.0174) loss_oracle 0.3596 (0.3738) kd_loss 0.6404 (0.6759) acc 87.5000 (85.4911) gate/entropy 1.0038 (1.0074) gate/usage_max 0.5458 (0.5416) gate/usage_min 0.2252 (0.2269) gate/usage_std 0.1502 (0.1473) teacher/entropy 0.0253 (0.0256) teacher/usage_max 0.9310 (0.8977) teacher/usage_min 0.0313 (0.0206) teacher/usage_std 0.4226 (0.4004) nleep/row_max_mean 1507.4227 (1516.3468) nleep/row_max_std 68.3136 (61.3467) nleep/row_min_mean 1480.7495 (1487.7498) lr 1.9048e-03 eta 0:10:46
epoch [9/50] batch [160/162] time 0.084 (0.097) data 0.000 (0.002) loss 1.3278 (1.2517) teacher_loss 0.4946 (0.3811) loss_zs_kd 0.0151 (0.0173) loss_oracle 0.3571 (0.3732) kd_loss 0.6471 (0.6754) acc 75.0000 (85.6250) gate/entropy 1.0027 (1.0068) gate/usage_max 0.5471 (0.5422) gate/usage_min 0.2247 (0.2266) gate/usage_std 0.1511 (0.1477) teacher/entropy 0.0628 (0.0261) teacher/usage_max 0.8789 (0.8967) teacher/usage_min 0.0457 (0.0200) teacher/usage_std 0.3860 (0.3998) nleep/row_max_mean 1517.8806 (1516.8541) nleep/row_max_std 60.9738 (61.0829) nleep/row_min_mean 1491.2292 (1488.3190) lr 1.9048e-03 eta 0:10:41
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,950
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 89.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,650
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 77.7%
******* Domain s best val acc:      87.6%, epoch: 7 *******
******* Domain s best val test acc: 71.3%, epoch: 7 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [10/50] batch [20/162] time 0.096 (0.128) data 0.000 (0.016) loss 1.4920 (1.2865) teacher_loss 0.6490 (0.3976) loss_zs_kd 0.0218 (0.0166) loss_oracle 0.3158 (0.3646) kd_loss 0.6742 (0.6982) acc 81.2500 (86.8750) gate/entropy 1.0016 (1.0022) gate/usage_max 0.5483 (0.5476) gate/usage_min 0.2243 (0.2245) gate/usage_std 0.1520 (0.1515) teacher/entropy 0.0117 (0.0130) teacher/usage_max 0.9043 (0.8772) teacher/usage_min 0.0337 (0.0102) teacher/usage_std 0.4039 (0.3877) nleep/row_max_mean 1511.5006 (1511.8804) nleep/row_max_std 62.6459 (61.5180) nleep/row_min_mean 1485.8153 (1484.7053) lr 1.8763e-03 eta 0:14:05
epoch [10/50] batch [40/162] time 0.100 (0.112) data 0.000 (0.008) loss 1.1579 (1.2602) teacher_loss 0.3545 (0.3812) loss_zs_kd 0.0114 (0.0182) loss_oracle 0.3445 (0.3672) kd_loss 0.6254 (0.6863) acc 84.3750 (86.7188) gate/entropy 1.0007 (1.0017) gate/usage_max 0.5492 (0.5481) gate/usage_min 0.2239 (0.2243) gate/usage_std 0.1527 (0.1519) teacher/entropy 0.0021 (0.0179) teacher/usage_max 0.9684 (0.8842) teacher/usage_min 0.0003 (0.0152) teacher/usage_std 0.4493 (0.3918) nleep/row_max_mean 1534.8990 (1516.5380) nleep/row_max_std 52.3228 (58.5789) nleep/row_min_mean 1505.5269 (1488.7169) lr 1.8763e-03 eta 0:12:16
epoch [10/50] batch [60/162] time 0.094 (0.107) data 0.001 (0.006) loss 1.3251 (1.2413) teacher_loss 0.4283 (0.3639) loss_zs_kd 0.0132 (0.0179) loss_oracle 0.3386 (0.3749) kd_loss 0.7209 (0.6809) acc 84.3750 (86.9271) gate/entropy 1.0002 (1.0013) gate/usage_max 0.5498 (0.5485) gate/usage_min 0.2237 (0.2242) gate/usage_std 0.1531 (0.1522) teacher/entropy 0.0227 (0.0193) teacher/usage_max 0.8376 (0.8880) teacher/usage_min 0.0066 (0.0162) teacher/usage_std 0.3618 (0.3942) nleep/row_max_mean 1514.5480 (1517.5889) nleep/row_max_std 62.5074 (59.0456) nleep/row_min_mean 1486.7365 (1489.7668) lr 1.8763e-03 eta 0:11:45
epoch [10/50] batch [80/162] time 0.091 (0.104) data 0.000 (0.004) loss 1.2281 (1.2469) teacher_loss 0.2556 (0.3703) loss_zs_kd 0.0251 (0.0176) loss_oracle 0.4195 (0.3790) kd_loss 0.7503 (0.6783) acc 90.6250 (86.4062) gate/entropy 0.9996 (1.0009) gate/usage_max 0.5505 (0.5490) gate/usage_min 0.2233 (0.2240) gate/usage_std 0.1536 (0.1525) teacher/entropy 0.0119 (0.0195) teacher/usage_max 0.8161 (0.8900) teacher/usage_min 0.0276 (0.0169) teacher/usage_std 0.3454 (0.3954) nleep/row_max_mean 1501.2963 (1517.7606) nleep/row_max_std 65.4501 (58.9001) nleep/row_min_mean 1476.6580 (1489.8989) lr 1.8763e-03 eta 0:11:19
epoch [10/50] batch [100/162] time 0.092 (0.101) data 0.000 (0.003) loss 1.4241 (1.2507) teacher_loss 0.6462 (0.3781) loss_zs_kd 0.0182 (0.0171) loss_oracle 0.3067 (0.3783) kd_loss 0.6154 (0.6749) acc 81.2500 (85.8438) gate/entropy 0.9985 (1.0006) gate/usage_max 0.5517 (0.5494) gate/usage_min 0.2228 (0.2238) gate/usage_std 0.1544 (0.1528) teacher/entropy 0.0227 (0.0204) teacher/usage_max 0.9519 (0.8922) teacher/usage_min 0.0168 (0.0173) teacher/usage_std 0.4374 (0.3968) nleep/row_max_mean 1511.0686 (1516.0435) nleep/row_max_std 69.8009 (59.6280) nleep/row_min_mean 1483.9644 (1488.5452) lr 1.8763e-03 eta 0:11:02
epoch [10/50] batch [120/162] time 0.098 (0.100) data 0.000 (0.003) loss 1.5867 (1.2530) teacher_loss 0.6261 (0.3802) loss_zs_kd 0.0123 (0.0167) loss_oracle 0.3846 (0.3789) kd_loss 0.7621 (0.6750) acc 71.8750 (85.8073) gate/entropy 0.9981 (1.0002) gate/usage_max 0.5522 (0.5498) gate/usage_min 0.2226 (0.2236) gate/usage_std 0.1548 (0.1531) teacher/entropy 0.0488 (0.0218) teacher/usage_max 0.7598 (0.8898) teacher/usage_min 0.0664 (0.0191) teacher/usage_std 0.3047 (0.3951) nleep/row_max_mean 1514.9066 (1516.1681) nleep/row_max_std 59.6575 (59.2727) nleep/row_min_mean 1491.0490 (1488.8174) lr 1.8763e-03 eta 0:10:53
epoch [10/50] batch [140/162] time 0.100 (0.099) data 0.000 (0.003) loss 1.3410 (1.2523) teacher_loss 0.4750 (0.3805) loss_zs_kd 0.0274 (0.0163) loss_oracle 0.3229 (0.3772) kd_loss 0.6908 (0.6751) acc 81.2500 (85.7143) gate/entropy 0.9975 (0.9999) gate/usage_max 0.5528 (0.5502) gate/usage_min 0.2224 (0.2235) gate/usage_std 0.1552 (0.1534) teacher/entropy 0.0195 (0.0230) teacher/usage_max 0.8712 (0.8877) teacher/usage_min 0.0012 (0.0198) teacher/usage_std 0.3838 (0.3937) nleep/row_max_mean 1498.0714 (1515.9402) nleep/row_max_std 59.1736 (59.3525) nleep/row_min_mean 1473.6704 (1488.7751) lr 1.8763e-03 eta 0:10:45
epoch [10/50] batch [160/162] time 0.084 (0.098) data 0.000 (0.002) loss 1.2035 (1.2499) teacher_loss 0.3001 (0.3795) loss_zs_kd 0.0153 (0.0165) loss_oracle 0.3550 (0.3767) kd_loss 0.7182 (0.6738) acc 84.3750 (85.6836) gate/entropy 0.9969 (0.9995) gate/usage_max 0.5535 (0.5506) gate/usage_min 0.2220 (0.2233) gate/usage_std 0.1557 (0.1536) teacher/entropy 0.0274 (0.0233) teacher/usage_max 0.8309 (0.8883) teacher/usage_min 0.0131 (0.0200) teacher/usage_std 0.3566 (0.3940) nleep/row_max_mean 1511.6593 (1515.5364) nleep/row_max_std 55.9741 (59.1954) nleep/row_min_mean 1486.4524 (1488.5047) lr 1.8763e-03 eta 0:10:38
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,959
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 89.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,535
* accuracy: 77.2%
* error: 22.8%
* macro_f1: 75.8%
******* Domain s best val acc:      87.7%, epoch: 10 *******
******* Domain s best val test acc: 77.2%, epoch: 10 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [11/50] batch [20/162] time 0.086 (0.111) data 0.000 (0.014) loss 1.0309 (1.1895) teacher_loss 0.2607 (0.3225) loss_zs_kd 0.0091 (0.0163) loss_oracle 0.2953 (0.3731) kd_loss 0.6179 (0.6723) acc 93.7500 (89.5312) gate/entropy 0.9963 (0.9966) gate/usage_max 0.5541 (0.5539) gate/usage_min 0.2218 (0.2219) gate/usage_std 0.1561 (0.1559) teacher/entropy 0.0011 (0.0236) teacher/usage_max 0.9687 (0.8845) teacher/usage_min 0.0001 (0.0280) teacher/usage_std 0.4495 (0.3908) nleep/row_max_mean 1530.2661 (1516.0897) nleep/row_max_std 54.3809 (55.4691) nleep/row_min_mean 1503.0540 (1489.5628) lr 1.8443e-03 eta 0:11:58
epoch [11/50] batch [40/162] time 0.091 (0.103) data 0.000 (0.007) loss 1.0359 (1.1971) teacher_loss 0.2219 (0.3262) loss_zs_kd 0.0138 (0.0147) loss_oracle 0.3231 (0.3666) kd_loss 0.6456 (0.6803) acc 93.7500 (88.7500) gate/entropy 0.9959 (0.9963) gate/usage_max 0.5546 (0.5542) gate/usage_min 0.2216 (0.2218) gate/usage_std 0.1565 (0.1562) teacher/entropy 0.0243 (0.0241) teacher/usage_max 0.9121 (0.8747) teacher/usage_min 0.0277 (0.0270) teacher/usage_std 0.4095 (0.3843) nleep/row_max_mean 1523.4542 (1515.8138) nleep/row_max_std 44.4517 (55.2969) nleep/row_min_mean 1497.4501 (1489.1720) lr 1.8443e-03 eta 0:11:04
epoch [11/50] batch [60/162] time 0.086 (0.098) data 0.000 (0.005) loss 1.3132 (1.2104) teacher_loss 0.4171 (0.3387) loss_zs_kd 0.0175 (0.0165) loss_oracle 0.3777 (0.3699) kd_loss 0.6985 (0.6786) acc 84.3750 (87.9688) gate/entropy 0.9953 (0.9960) gate/usage_max 0.5552 (0.5544) gate/usage_min 0.2213 (0.2216) gate/usage_std 0.1569 (0.1564) teacher/entropy 0.0050 (0.0242) teacher/usage_max 0.8747 (0.8761) teacher/usage_min 0.0007 (0.0253) teacher/usage_std 0.3861 (0.3855) nleep/row_max_mean 1517.6350 (1515.3524) nleep/row_max_std 54.4874 (55.5545) nleep/row_min_mean 1491.0020 (1488.6306) lr 1.8443e-03 eta 0:10:26
epoch [11/50] batch [80/162] time 0.084 (0.093) data 0.000 (0.004) loss 1.1666 (1.2235) teacher_loss 0.2177 (0.3511) loss_zs_kd 0.0187 (0.0171) loss_oracle 0.5194 (0.3789) kd_loss 0.6799 (0.6743) acc 90.6250 (87.1875) gate/entropy 0.9949 (0.9958) gate/usage_max 0.5557 (0.5547) gate/usage_min 0.2211 (0.2215) gate/usage_std 0.1573 (0.1566) teacher/entropy 0.0780 (0.0264) teacher/usage_max 0.8136 (0.8779) teacher/usage_min 0.0793 (0.0258) teacher/usage_std 0.3398 (0.3867) nleep/row_max_mean 1514.4990 (1516.4368) nleep/row_max_std 52.7584 (54.7902) nleep/row_min_mean 1490.7170 (1489.5566) lr 1.8443e-03 eta 0:09:53
epoch [11/50] batch [100/162] time 0.087 (0.092) data 0.000 (0.003) loss 1.2356 (1.2384) teacher_loss 0.3634 (0.3640) loss_zs_kd 0.0153 (0.0166) loss_oracle 0.4117 (0.3807) kd_loss 0.6587 (0.6758) acc 81.2500 (86.6250) gate/entropy 0.9945 (0.9955) gate/usage_max 0.5561 (0.5550) gate/usage_min 0.2209 (0.2214) gate/usage_std 0.1575 (0.1567) teacher/entropy 0.0171 (0.0267) teacher/usage_max 0.9026 (0.8756) teacher/usage_min 0.0317 (0.0260) teacher/usage_std 0.4028 (0.3851) nleep/row_max_mean 1508.9490 (1515.7137) nleep/row_max_std 63.6697 (55.4005) nleep/row_min_mean 1485.1531 (1488.9107) lr 1.8443e-03 eta 0:09:49
epoch [11/50] batch [120/162] time 0.086 (0.093) data 0.000 (0.003) loss 1.0971 (1.2403) teacher_loss 0.2172 (0.3661) loss_zs_kd 0.0220 (0.0166) loss_oracle 0.3799 (0.3753) kd_loss 0.6789 (0.6782) acc 87.5000 (86.4062) gate/entropy 0.9941 (0.9953) gate/usage_max 0.5566 (0.5553) gate/usage_min 0.2207 (0.2213) gate/usage_std 0.1579 (0.1569) teacher/entropy 0.0495 (0.0270) teacher/usage_max 0.8447 (0.8723) teacher/usage_min 0.0625 (0.0270) teacher/usage_std 0.3618 (0.3829) nleep/row_max_mean 1513.7035 (1515.0041) nleep/row_max_std 52.7947 (55.4328) nleep/row_min_mean 1486.0836 (1488.3924) lr 1.8443e-03 eta 0:09:50
epoch [11/50] batch [140/162] time 0.084 (0.093) data 0.000 (0.002) loss 1.0840 (1.2395) teacher_loss 0.2955 (0.3716) loss_zs_kd 0.0068 (0.0166) loss_oracle 0.3150 (0.3722) kd_loss 0.6276 (0.6735) acc 90.6250 (86.0938) gate/entropy 0.9935 (0.9950) gate/usage_max 0.5572 (0.5555) gate/usage_min 0.2204 (0.2212) gate/usage_std 0.1583 (0.1571) teacher/entropy 0.0275 (0.0283) teacher/usage_max 0.9236 (0.8757) teacher/usage_min 0.0322 (0.0270) teacher/usage_std 0.4174 (0.3852) nleep/row_max_mean 1523.5952 (1515.1010) nleep/row_max_std 55.3715 (55.4383) nleep/row_min_mean 1495.5569 (1488.4782) lr 1.8443e-03 eta 0:09:51
epoch [11/50] batch [160/162] time 0.090 (0.093) data 0.000 (0.002) loss 1.0494 (1.2356) teacher_loss 0.2121 (0.3718) loss_zs_kd 0.0162 (0.0161) loss_oracle 0.3379 (0.3688) kd_loss 0.6602 (0.6714) acc 90.6250 (85.9375) gate/entropy 0.9929 (0.9948) gate/usage_max 0.5578 (0.5558) gate/usage_min 0.2202 (0.2211) gate/usage_std 0.1587 (0.1573) teacher/entropy 0.0401 (0.0275) teacher/usage_max 0.8742 (0.8784) teacher/usage_min 0.0482 (0.0261) teacher/usage_std 0.3826 (0.3871) nleep/row_max_mean 1506.8002 (1515.1437) nleep/row_max_std 49.3314 (55.5226) nleep/row_min_mean 1480.8936 (1488.4291) lr 1.8443e-03 eta 0:09:45
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,961
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 89.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,505
* accuracy: 76.3%
* error: 23.7%
* macro_f1: 75.9%
******* Domain s best val acc:      87.8%, epoch: 11 *******
******* Domain s best val test acc: 76.3%, epoch: 11 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [12/50] batch [20/162] time 0.073 (0.103) data 0.000 (0.019) loss 1.1144 (1.2371) teacher_loss 0.3267 (0.4080) loss_zs_kd 0.0046 (0.0124) loss_oracle 0.2917 (0.3451) kd_loss 0.6396 (0.6503) acc 84.3750 (83.5938) gate/entropy 0.9925 (0.9926) gate/usage_max 0.5583 (0.5582) gate/usage_min 0.2200 (0.2200) gate/usage_std 0.1591 (0.1590) teacher/entropy 0.0012 (0.0276) teacher/usage_max 0.9373 (0.8977) teacher/usage_min 0.0313 (0.0200) teacher/usage_std 0.4271 (0.4004) nleep/row_max_mean 1518.3704 (1513.5787) nleep/row_max_std 51.6308 (56.7458) nleep/row_min_mean 1488.3728 (1486.0584) lr 1.8090e-03 eta 0:10:51
epoch [12/50] batch [40/162] time 0.094 (0.096) data 0.000 (0.010) loss 1.2865 (1.2500) teacher_loss 0.4386 (0.4071) loss_zs_kd 0.0154 (0.0146) loss_oracle 0.3383 (0.3474) kd_loss 0.6711 (0.6620) acc 75.0000 (83.8281) gate/entropy 0.9920 (0.9924) gate/usage_max 0.5589 (0.5584) gate/usage_min 0.2197 (0.2199) gate/usage_std 0.1595 (0.1592) teacher/entropy 0.0241 (0.0252) teacher/usage_max 0.8779 (0.8875) teacher/usage_min 0.0575 (0.0185) teacher/usage_std 0.3851 (0.3939) nleep/row_max_mean 1519.5486 (1512.5588) nleep/row_max_std 57.8107 (58.0749) nleep/row_min_mean 1491.5865 (1485.5037) lr 1.8090e-03 eta 0:10:01
epoch [12/50] batch [60/162] time 0.075 (0.092) data 0.000 (0.007) loss 1.5464 (1.2581) teacher_loss 0.6595 (0.4036) loss_zs_kd 0.0347 (0.0170) loss_oracle 0.3936 (0.3555) kd_loss 0.6728 (0.6683) acc 78.1250 (84.1667) gate/entropy 0.9915 (0.9922) gate/usage_max 0.5594 (0.5586) gate/usage_min 0.2195 (0.2198) gate/usage_std 0.1599 (0.1593) teacher/entropy 0.0284 (0.0226) teacher/usage_max 0.8711 (0.8831) teacher/usage_min 0.0067 (0.0196) teacher/usage_std 0.3831 (0.3909) nleep/row_max_mean 1521.5997 (1511.7578) nleep/row_max_std 57.5011 (58.4039) nleep/row_min_mean 1493.5396 (1484.7805) lr 1.8090e-03 eta 0:09:36
epoch [12/50] batch [80/162] time 0.096 (0.092) data 0.000 (0.005) loss 1.2009 (1.2584) teacher_loss 0.3123 (0.3986) loss_zs_kd 0.0159 (0.0166) loss_oracle 0.4086 (0.3614) kd_loss 0.6763 (0.6708) acc 93.7500 (84.5312) gate/entropy 0.9910 (0.9920) gate/usage_max 0.5599 (0.5588) gate/usage_min 0.2193 (0.2197) gate/usage_std 0.1602 (0.1595) teacher/entropy 0.0290 (0.0221) teacher/usage_max 0.8661 (0.8807) teacher/usage_min 0.0048 (0.0191) teacher/usage_std 0.3801 (0.3895) nleep/row_max_mean 1501.2065 (1510.9828) nleep/row_max_std 63.6557 (58.2743) nleep/row_min_mean 1476.7943 (1484.1814) lr 1.8090e-03 eta 0:09:36
epoch [12/50] batch [100/162] time 0.101 (0.093) data 0.000 (0.004) loss 1.2011 (1.2561) teacher_loss 0.3857 (0.3970) loss_zs_kd 0.0119 (0.0165) loss_oracle 0.3097 (0.3590) kd_loss 0.6546 (0.6713) acc 84.3750 (84.7188) gate/entropy 0.9908 (0.9918) gate/usage_max 0.5601 (0.5590) gate/usage_min 0.2192 (0.2197) gate/usage_std 0.1603 (0.1596) teacher/entropy 0.0227 (0.0221) teacher/usage_max 0.8957 (0.8798) teacher/usage_min 0.0104 (0.0196) teacher/usage_std 0.3991 (0.3888) nleep/row_max_mean 1509.8762 (1511.2161) nleep/row_max_std 64.7283 (57.9693) nleep/row_min_mean 1482.1835 (1484.3880) lr 1.8090e-03 eta 0:09:39
epoch [12/50] batch [120/162] time 0.106 (0.094) data 0.000 (0.003) loss 1.1821 (1.2463) teacher_loss 0.3530 (0.3841) loss_zs_kd 0.0144 (0.0168) loss_oracle 0.3723 (0.3599) kd_loss 0.6358 (0.6738) acc 84.3750 (85.2083) gate/entropy 0.9907 (0.9916) gate/usage_max 0.5603 (0.5592) gate/usage_min 0.2192 (0.2196) gate/usage_std 0.1605 (0.1597) teacher/entropy 0.0232 (0.0212) teacher/usage_max 0.9147 (0.8778) teacher/usage_min 0.0219 (0.0192) teacher/usage_std 0.4115 (0.3875) nleep/row_max_mean 1510.5979 (1511.4836) nleep/row_max_std 53.0669 (57.8100) nleep/row_min_mean 1484.7600 (1484.5426) lr 1.8090e-03 eta 0:09:44
epoch [12/50] batch [140/162] time 0.100 (0.095) data 0.000 (0.003) loss 1.1018 (1.2483) teacher_loss 0.2893 (0.3851) loss_zs_kd 0.0205 (0.0167) loss_oracle 0.3527 (0.3632) kd_loss 0.6258 (0.6732) acc 84.3750 (84.9777) gate/entropy 0.9902 (0.9914) gate/usage_max 0.5607 (0.5595) gate/usage_min 0.2190 (0.2195) gate/usage_std 0.1608 (0.1599) teacher/entropy 0.0119 (0.0208) teacher/usage_max 0.9369 (0.8787) teacher/usage_min 0.0000 (0.0186) teacher/usage_std 0.4276 (0.3880) nleep/row_max_mean 1508.4954 (1511.8812) nleep/row_max_std 62.4817 (58.1328) nleep/row_min_mean 1481.4526 (1484.7875) lr 1.8090e-03 eta 0:09:43
epoch [12/50] batch [160/162] time 0.090 (0.094) data 0.000 (0.003) loss 1.5407 (1.2413) teacher_loss 0.6032 (0.3778) loss_zs_kd 0.0168 (0.0168) loss_oracle 0.3803 (0.3654) kd_loss 0.7390 (0.6724) acc 78.1250 (85.3906) gate/entropy 0.9901 (0.9912) gate/usage_max 0.5609 (0.5596) gate/usage_min 0.2189 (0.2194) gate/usage_std 0.1609 (0.1600) teacher/entropy 0.0151 (0.0208) teacher/usage_max 0.8124 (0.8792) teacher/usage_min 0.0628 (0.0181) teacher/usage_std 0.3397 (0.3884) nleep/row_max_mean 1479.7708 (1511.6205) nleep/row_max_std 59.0390 (58.4247) nleep/row_min_mean 1453.0267 (1484.4509) lr 1.8090e-03 eta 0:09:40
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,952
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,530
* accuracy: 77.1%
* error: 22.9%
* macro_f1: 76.1%
******* Domain s best val acc:      87.8%, epoch: 11 *******
******* Domain s best val test acc: 76.3%, epoch: 11 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [13/50] batch [20/162] time 0.101 (0.111) data 0.000 (0.014) loss 1.1495 (1.2576) teacher_loss 0.3519 (0.3871) loss_zs_kd 0.0150 (0.0137) loss_oracle 0.2798 (0.3718) kd_loss 0.6501 (0.6778) acc 90.6250 (84.6875) gate/entropy 0.9893 (0.9896) gate/usage_max 0.5617 (0.5614) gate/usage_min 0.2186 (0.2187) gate/usage_std 0.1615 (0.1613) teacher/entropy 0.0143 (0.0157) teacher/usage_max 0.9071 (0.8764) teacher/usage_min 0.0005 (0.0151) teacher/usage_std 0.4075 (0.3865) nleep/row_max_mean 1515.2485 (1510.1035) nleep/row_max_std 54.3267 (59.6412) nleep/row_min_mean 1487.1642 (1481.6652) lr 1.7705e-03 eta 0:11:19
epoch [13/50] batch [40/162] time 0.100 (0.108) data 0.000 (0.007) loss 1.2491 (1.2484) teacher_loss 0.4348 (0.3809) loss_zs_kd 0.0236 (0.0166) loss_oracle 0.3608 (0.3736) kd_loss 0.6221 (0.6724) acc 81.2500 (85.4688) gate/entropy 0.9892 (0.9894) gate/usage_max 0.5618 (0.5616) gate/usage_min 0.2185 (0.2186) gate/usage_std 0.1616 (0.1614) teacher/entropy 0.0210 (0.0142) teacher/usage_max 0.9294 (0.8835) teacher/usage_min 0.0005 (0.0106) teacher/usage_std 0.4224 (0.3919) nleep/row_max_mean 1514.8933 (1511.8001) nleep/row_max_std 61.7010 (58.9463) nleep/row_min_mean 1486.1169 (1482.8444) lr 1.7705e-03 eta 0:11:00
epoch [13/50] batch [60/162] time 0.097 (0.104) data 0.001 (0.005) loss 1.3547 (1.2348) teacher_loss 0.4296 (0.3730) loss_zs_kd 0.0222 (0.0176) loss_oracle 0.3423 (0.3730) kd_loss 0.7429 (0.6666) acc 81.2500 (85.8854) gate/entropy 0.9889 (0.9892) gate/usage_max 0.5622 (0.5618) gate/usage_min 0.2184 (0.2185) gate/usage_std 0.1618 (0.1615) teacher/entropy 0.0081 (0.0143) teacher/usage_max 0.8143 (0.8893) teacher/usage_min 0.0002 (0.0093) teacher/usage_std 0.3484 (0.3959) nleep/row_max_mean 1513.9794 (1513.0391) nleep/row_max_std 63.3171 (58.6703) nleep/row_min_mean 1485.1458 (1483.7604) lr 1.7705e-03 eta 0:10:34
epoch [13/50] batch [80/162] time 0.089 (0.101) data 0.000 (0.004) loss 1.8052 (1.2497) teacher_loss 0.8704 (0.3875) loss_zs_kd 0.0170 (0.0168) loss_oracle 0.4203 (0.3732) kd_loss 0.7162 (0.6672) acc 75.0000 (85.4688) gate/entropy 0.9886 (0.9891) gate/usage_max 0.5625 (0.5619) gate/usage_min 0.2182 (0.2185) gate/usage_std 0.1620 (0.1617) teacher/entropy 0.0098 (0.0137) teacher/usage_max 0.8410 (0.8890) teacher/usage_min 0.0001 (0.0112) teacher/usage_std 0.3648 (0.3954) nleep/row_max_mean 1491.5514 (1511.6042) nleep/row_max_std 68.2534 (59.6858) nleep/row_min_mean 1461.8373 (1482.2538) lr 1.7705e-03 eta 0:10:12
epoch [13/50] batch [100/162] time 0.082 (0.099) data 0.000 (0.003) loss 1.1202 (1.2358) teacher_loss 0.2402 (0.3781) loss_zs_kd 0.0160 (0.0163) loss_oracle 0.3262 (0.3726) kd_loss 0.7089 (0.6633) acc 90.6250 (85.7812) gate/entropy 0.9885 (0.9889) gate/usage_max 0.5626 (0.5621) gate/usage_min 0.2182 (0.2184) gate/usage_std 0.1621 (0.1618) teacher/entropy 0.0292 (0.0136) teacher/usage_max 0.8278 (0.8930) teacher/usage_min 0.0021 (0.0114) teacher/usage_std 0.3563 (0.3981) nleep/row_max_mean 1506.9768 (1512.8551) nleep/row_max_std 59.7664 (59.1940) nleep/row_min_mean 1478.6382 (1483.2276) lr 1.7705e-03 eta 0:09:59
epoch [13/50] batch [120/162] time 0.096 (0.098) data 0.000 (0.003) loss 1.1249 (1.2373) teacher_loss 0.3365 (0.3815) loss_zs_kd 0.0102 (0.0156) loss_oracle 0.3104 (0.3692) kd_loss 0.6281 (0.6635) acc 87.5000 (85.6510) gate/entropy 0.9879 (0.9888) gate/usage_max 0.5632 (0.5623) gate/usage_min 0.2179 (0.2183) gate/usage_std 0.1625 (0.1619) teacher/entropy 0.0227 (0.0134) teacher/usage_max 0.9189 (0.8928) teacher/usage_min 0.0314 (0.0117) teacher/usage_std 0.4142 (0.3979) nleep/row_max_mean 1502.3213 (1512.0349) nleep/row_max_std 72.3472 (60.5967) nleep/row_min_mean 1475.2969 (1482.4568) lr 1.7705e-03 eta 0:09:51
epoch [13/50] batch [140/162] time 0.103 (0.098) data 0.000 (0.002) loss 1.2504 (1.2359) teacher_loss 0.2953 (0.3780) loss_zs_kd 0.0259 (0.0157) loss_oracle 0.4058 (0.3719) kd_loss 0.7393 (0.6641) acc 90.6250 (85.8259) gate/entropy 0.9878 (0.9886) gate/usage_max 0.5633 (0.5624) gate/usage_min 0.2179 (0.2182) gate/usage_std 0.1626 (0.1620) teacher/entropy 0.0150 (0.0142) teacher/usage_max 0.8096 (0.8912) teacher/usage_min 0.0013 (0.0127) teacher/usage_std 0.3454 (0.3967) nleep/row_max_mean 1504.3889 (1511.6152) nleep/row_max_std 57.3460 (60.5677) nleep/row_min_mean 1475.5553 (1482.0736) lr 1.7705e-03 eta 0:09:47
epoch [13/50] batch [160/162] time 0.088 (0.097) data 0.000 (0.002) loss 1.0220 (1.2364) teacher_loss 0.1843 (0.3782) loss_zs_kd 0.0134 (0.0158) loss_oracle 0.3611 (0.3728) kd_loss 0.6505 (0.6639) acc 93.7500 (85.5078) gate/entropy 0.9874 (0.9885) gate/usage_max 0.5638 (0.5626) gate/usage_min 0.2177 (0.2182) gate/usage_std 0.1629 (0.1621) teacher/entropy 0.0218 (0.0141) teacher/usage_max 0.8958 (0.8912) teacher/usage_min 0.0104 (0.0131) teacher/usage_std 0.3992 (0.3968) nleep/row_max_mean 1519.8838 (1511.4709) nleep/row_max_std 53.8820 (60.3553) nleep/row_min_mean 1493.1570 (1482.0236) lr 1.7705e-03 eta 0:09:40
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,955
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,622
* accuracy: 79.9%
* error: 20.1%
* macro_f1: 77.7%
******* Domain s best val acc:      87.8%, epoch: 11 *******
******* Domain s best val test acc: 76.3%, epoch: 11 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [14/50] batch [20/162] time 0.095 (0.117) data 0.001 (0.016) loss 1.1981 (1.2210) teacher_loss 0.3798 (0.3576) loss_zs_kd 0.0231 (0.0181) loss_oracle 0.3686 (0.3718) kd_loss 0.6224 (0.6684) acc 87.5000 (86.8750) gate/entropy 0.9873 (0.9873) gate/usage_max 0.5639 (0.5638) gate/usage_min 0.2176 (0.2176) gate/usage_std 0.1630 (0.1630) teacher/entropy 0.0115 (0.0160) teacher/usage_max 0.9357 (0.8826) teacher/usage_min 0.0014 (0.0127) teacher/usage_std 0.4267 (0.3912) nleep/row_max_mean 1528.5618 (1510.9166) nleep/row_max_std 61.8648 (57.8731) nleep/row_min_mean 1498.4131 (1482.4652) lr 1.7290e-03 eta 0:11:38
epoch [14/50] batch [40/162] time 0.092 (0.106) data 0.000 (0.008) loss 1.1626 (1.2333) teacher_loss 0.3687 (0.3722) loss_zs_kd 0.0075 (0.0166) loss_oracle 0.3241 (0.3810) kd_loss 0.6280 (0.6623) acc 87.5000 (85.4688) gate/entropy 0.9871 (0.9872) gate/usage_max 0.5641 (0.5640) gate/usage_min 0.2175 (0.2176) gate/usage_std 0.1631 (0.1631) teacher/entropy 0.0215 (0.0202) teacher/usage_max 0.9189 (0.8845) teacher/usage_min 0.0000 (0.0153) teacher/usage_std 0.4154 (0.3921) nleep/row_max_mean 1506.4802 (1511.7486) nleep/row_max_std 66.5630 (58.6411) nleep/row_min_mean 1480.1021 (1483.5865) lr 1.7290e-03 eta 0:10:31
epoch [14/50] batch [60/162] time 0.098 (0.103) data 0.001 (0.006) loss 1.1841 (1.2357) teacher_loss 0.3632 (0.3761) loss_zs_kd 0.0144 (0.0163) loss_oracle 0.3125 (0.3781) kd_loss 0.6575 (0.6624) acc 84.3750 (84.9479) gate/entropy 0.9867 (0.9871) gate/usage_max 0.5645 (0.5641) gate/usage_min 0.2174 (0.2175) gate/usage_std 0.1634 (0.1632) teacher/entropy 0.0037 (0.0180) teacher/usage_max 0.9055 (0.8865) teacher/usage_min 0.0320 (0.0154) teacher/usage_std 0.4048 (0.3933) nleep/row_max_mean 1525.4758 (1511.8984) nleep/row_max_std 48.5892 (58.3730) nleep/row_min_mean 1497.3547 (1483.5799) lr 1.7290e-03 eta 0:10:08
epoch [14/50] batch [80/162] time 0.094 (0.100) data 0.000 (0.004) loss 1.2552 (1.2445) teacher_loss 0.4387 (0.3870) loss_zs_kd 0.0033 (0.0160) loss_oracle 0.4310 (0.3712) kd_loss 0.5993 (0.6639) acc 84.3750 (84.9609) gate/entropy 0.9866 (0.9869) gate/usage_max 0.5646 (0.5642) gate/usage_min 0.2173 (0.2175) gate/usage_std 0.1635 (0.1633) teacher/entropy 0.0326 (0.0189) teacher/usage_max 0.9364 (0.8839) teacher/usage_min 0.0299 (0.0162) teacher/usage_std 0.4264 (0.3915) nleep/row_max_mean 1506.5570 (1511.8739) nleep/row_max_std 60.2109 (58.5186) nleep/row_min_mean 1481.1399 (1483.7263) lr 1.7290e-03 eta 0:09:53
epoch [14/50] batch [100/162] time 0.101 (0.099) data 0.000 (0.003) loss 1.2501 (1.2426) teacher_loss 0.4600 (0.3869) loss_zs_kd 0.0178 (0.0159) loss_oracle 0.2803 (0.3698) kd_loss 0.6411 (0.6629) acc 78.1250 (84.9062) gate/entropy 0.9862 (0.9868) gate/usage_max 0.5650 (0.5643) gate/usage_min 0.2171 (0.2174) gate/usage_std 0.1638 (0.1633) teacher/entropy 0.0151 (0.0185) teacher/usage_max 0.9104 (0.8852) teacher/usage_min 0.0277 (0.0163) teacher/usage_std 0.4083 (0.3924) nleep/row_max_mean 1520.0472 (1511.9512) nleep/row_max_std 50.5666 (58.4345) nleep/row_min_mean 1490.5909 (1483.8209) lr 1.7290e-03 eta 0:09:45
epoch [14/50] batch [120/162] time 0.095 (0.100) data 0.000 (0.003) loss 1.0554 (1.2347) teacher_loss 0.2482 (0.3815) loss_zs_kd 0.0098 (0.0157) loss_oracle 0.3116 (0.3672) kd_loss 0.6465 (0.6618) acc 93.7500 (85.2865) gate/entropy 0.9861 (0.9867) gate/usage_max 0.5651 (0.5644) gate/usage_min 0.2171 (0.2174) gate/usage_std 0.1639 (0.1634) teacher/entropy 0.0121 (0.0178) teacher/usage_max 0.9081 (0.8869) teacher/usage_min 0.0006 (0.0159) teacher/usage_std 0.4081 (0.3935) nleep/row_max_mean 1527.3630 (1512.9065) nleep/row_max_std 62.1937 (57.7649) nleep/row_min_mean 1499.9341 (1484.6957) lr 1.7290e-03 eta 0:09:45
epoch [14/50] batch [140/162] time 0.096 (0.099) data 0.001 (0.003) loss 1.1105 (1.2291) teacher_loss 0.2775 (0.3785) loss_zs_kd 0.0173 (0.0156) loss_oracle 0.3537 (0.3657) kd_loss 0.6474 (0.6599) acc 93.7500 (85.5580) gate/entropy 0.9857 (0.9866) gate/usage_max 0.5655 (0.5645) gate/usage_min 0.2169 (0.2173) gate/usage_std 0.1642 (0.1635) teacher/entropy 0.0177 (0.0187) teacher/usage_max 0.9003 (0.8878) teacher/usage_min 0.0318 (0.0159) teacher/usage_std 0.4011 (0.3941) nleep/row_max_mean 1527.2629 (1512.8603) nleep/row_max_std 56.0828 (57.8569) nleep/row_min_mean 1499.8641 (1484.8431) lr 1.7290e-03 eta 0:09:41
epoch [14/50] batch [160/162] time 0.088 (0.099) data 0.000 (0.002) loss 1.4033 (1.2350) teacher_loss 0.5065 (0.3807) loss_zs_kd 0.0228 (0.0159) loss_oracle 0.3516 (0.3670) kd_loss 0.7096 (0.6629) acc 68.7500 (85.2734) gate/entropy 0.9858 (0.9865) gate/usage_max 0.5654 (0.5646) gate/usage_min 0.2170 (0.2173) gate/usage_std 0.1641 (0.1636) teacher/entropy 0.0102 (0.0186) teacher/usage_max 0.8436 (0.8847) teacher/usage_min 0.0029 (0.0160) teacher/usage_std 0.3660 (0.3920) nleep/row_max_mean 1514.1038 (1512.6531) nleep/row_max_std 48.1357 (57.6395) nleep/row_min_mean 1486.9858 (1484.8134) lr 1.7290e-03 eta 0:09:39
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,964
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,546
* accuracy: 77.6%
* error: 22.4%
* macro_f1: 76.4%
******* Domain s best val acc:      87.9%, epoch: 14 *******
******* Domain s best val test acc: 77.6%, epoch: 14 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [15/50] batch [20/162] time 0.103 (0.116) data 0.000 (0.016) loss 1.3281 (1.2289) teacher_loss 0.4419 (0.3593) loss_zs_kd 0.0146 (0.0154) loss_oracle 0.3634 (0.3695) kd_loss 0.6972 (0.6772) acc 81.2500 (86.0938) gate/entropy 0.9855 (0.9856) gate/usage_max 0.5657 (0.5656) gate/usage_min 0.2168 (0.2169) gate/usage_std 0.1643 (0.1642) teacher/entropy 0.0248 (0.0226) teacher/usage_max 0.8410 (0.8641) teacher/usage_min 0.0038 (0.0189) teacher/usage_std 0.3643 (0.3785) nleep/row_max_mean 1519.5759 (1518.1987) nleep/row_max_std 57.4705 (55.5654) nleep/row_min_mean 1491.3491 (1491.2255) lr 1.6845e-03 eta 0:11:12
epoch [15/50] batch [40/162] time 0.094 (0.104) data 0.000 (0.008) loss 1.1246 (1.2101) teacher_loss 0.3322 (0.3438) loss_zs_kd 0.0130 (0.0158) loss_oracle 0.3398 (0.3671) kd_loss 0.6160 (0.6748) acc 87.5000 (86.3281) gate/entropy 0.9853 (0.9856) gate/usage_max 0.5659 (0.5657) gate/usage_min 0.2167 (0.2168) gate/usage_std 0.1645 (0.1643) teacher/entropy 0.0215 (0.0235) teacher/usage_max 0.9289 (0.8656) teacher/usage_min 0.0090 (0.0220) teacher/usage_std 0.4217 (0.3791) nleep/row_max_mean 1522.6942 (1516.0407) nleep/row_max_std 57.0934 (56.5074) nleep/row_min_mean 1495.8721 (1489.3439) lr 1.6845e-03 eta 0:10:04
epoch [15/50] batch [60/162] time 0.094 (0.101) data 0.001 (0.006) loss 1.2400 (1.2184) teacher_loss 0.2956 (0.3566) loss_zs_kd 0.0144 (0.0175) loss_oracle 0.4452 (0.3687) kd_loss 0.7146 (0.6687) acc 96.8750 (86.1458) gate/entropy 0.9853 (0.9855) gate/usage_max 0.5659 (0.5657) gate/usage_min 0.2167 (0.2168) gate/usage_std 0.1645 (0.1643) teacher/entropy 0.0280 (0.0256) teacher/usage_max 0.8186 (0.8697) teacher/usage_min 0.0635 (0.0213) teacher/usage_std 0.3439 (0.3819) nleep/row_max_mean 1507.3301 (1514.8048) nleep/row_max_std 57.0227 (56.3770) nleep/row_min_mean 1481.1521 (1488.3708) lr 1.6845e-03 eta 0:09:44
epoch [15/50] batch [80/162] time 0.088 (0.099) data 0.000 (0.004) loss 1.2897 (1.2164) teacher_loss 0.5593 (0.3560) loss_zs_kd 0.0149 (0.0181) loss_oracle 0.3129 (0.3723) kd_loss 0.5665 (0.6652) acc 75.0000 (86.0547) gate/entropy 0.9848 (0.9854) gate/usage_max 0.5665 (0.5658) gate/usage_min 0.2165 (0.2168) gate/usage_std 0.1648 (0.1644) teacher/entropy 0.0021 (0.0259) teacher/usage_max 0.9997 (0.8729) teacher/usage_min 0.0000 (0.0215) teacher/usage_std 0.4712 (0.3840) nleep/row_max_mean 1506.1147 (1514.4724) nleep/row_max_std 76.5583 (56.5658) nleep/row_min_mean 1482.1753 (1488.3392) lr 1.6845e-03 eta 0:09:28
epoch [15/50] batch [100/162] time 0.093 (0.097) data 0.000 (0.003) loss 1.1266 (1.2267) teacher_loss 0.2918 (0.3648) loss_zs_kd 0.0106 (0.0174) loss_oracle 0.3168 (0.3725) kd_loss 0.6711 (0.6670) acc 84.3750 (86.0625) gate/entropy 0.9848 (0.9853) gate/usage_max 0.5664 (0.5659) gate/usage_min 0.2165 (0.2167) gate/usage_std 0.1648 (0.1645) teacher/entropy 0.0265 (0.0263) teacher/usage_max 0.8655 (0.8705) teacher/usage_min 0.0393 (0.0237) teacher/usage_std 0.3770 (0.3822) nleep/row_max_mean 1517.7009 (1513.1270) nleep/row_max_std 55.4622 (57.0217) nleep/row_min_mean 1491.0464 (1487.3266) lr 1.6845e-03 eta 0:09:18
epoch [15/50] batch [120/162] time 0.096 (0.097) data 0.000 (0.003) loss 1.3698 (1.2284) teacher_loss 0.5404 (0.3678) loss_zs_kd 0.0181 (0.0171) loss_oracle 0.3910 (0.3734) kd_loss 0.6248 (0.6653) acc 87.5000 (86.1198) gate/entropy 0.9848 (0.9853) gate/usage_max 0.5664 (0.5660) gate/usage_min 0.2165 (0.2167) gate/usage_std 0.1648 (0.1645) teacher/entropy 0.0043 (0.0268) teacher/usage_max 0.9366 (0.8717) teacher/usage_min 0.0009 (0.0237) teacher/usage_std 0.4273 (0.3829) nleep/row_max_mean 1499.7688 (1512.2925) nleep/row_max_std 74.4449 (57.0658) nleep/row_min_mean 1474.8813 (1486.6843) lr 1.6845e-03 eta 0:09:12
epoch [15/50] batch [140/162] time 0.098 (0.096) data 0.000 (0.003) loss 1.1633 (1.2324) teacher_loss 0.2985 (0.3716) loss_zs_kd 0.0101 (0.0168) loss_oracle 0.3454 (0.3737) kd_loss 0.6871 (0.6655) acc 78.1250 (85.8929) gate/entropy 0.9847 (0.9852) gate/usage_max 0.5665 (0.5661) gate/usage_min 0.2165 (0.2167) gate/usage_std 0.1649 (0.1646) teacher/entropy 0.0015 (0.0267) teacher/usage_max 0.8748 (0.8715) teacher/usage_min 0.0002 (0.0232) teacher/usage_std 0.3863 (0.3828) nleep/row_max_mean 1494.5404 (1511.6107) nleep/row_max_std 67.0356 (57.3032) nleep/row_min_mean 1469.8357 (1486.1311) lr 1.6845e-03 eta 0:09:09
epoch [15/50] batch [160/162] time 0.089 (0.095) data 0.000 (0.002) loss 1.3040 (1.2236) teacher_loss 0.3625 (0.3640) loss_zs_kd 0.0213 (0.0167) loss_oracle 0.3140 (0.3719) kd_loss 0.7738 (0.6653) acc 93.7500 (86.2109) gate/entropy 0.9844 (0.9851) gate/usage_max 0.5668 (0.5661) gate/usage_min 0.2163 (0.2166) gate/usage_std 0.1651 (0.1646) teacher/entropy 0.0049 (0.0253) teacher/usage_max 0.7804 (0.8730) teacher/usage_min 0.0321 (0.0217) teacher/usage_std 0.3225 (0.3839) nleep/row_max_mean 1521.5762 (1511.0098) nleep/row_max_std 60.8987 (57.4376) nleep/row_min_mean 1495.4913 (1485.5490) lr 1.6845e-03 eta 0:09:00
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,953
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,584
* accuracy: 78.7%
* error: 21.3%
* macro_f1: 77.9%
******* Domain s best val acc:      87.9%, epoch: 14 *******
******* Domain s best val test acc: 77.6%, epoch: 14 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [16/50] batch [20/162] time 0.109 (0.107) data 0.000 (0.012) loss 1.2488 (1.2568) teacher_loss 0.4047 (0.3996) loss_zs_kd 0.0175 (0.0165) loss_oracle 0.4180 (0.3770) kd_loss 0.6264 (0.6604) acc 87.5000 (83.7500) gate/entropy 0.9844 (0.9844) gate/usage_max 0.5669 (0.5669) gate/usage_min 0.2163 (0.2163) gate/usage_std 0.1651 (0.1651) teacher/entropy 0.0012 (0.0178) teacher/usage_max 0.9374 (0.8849) teacher/usage_min 0.0312 (0.0230) teacher/usage_std 0.4271 (0.3916) nleep/row_max_mean 1517.9844 (1514.6343) nleep/row_max_std 52.0561 (54.6334) nleep/row_min_mean 1490.4993 (1488.0931) lr 1.6374e-03 eta 0:10:06
epoch [16/50] batch [40/162] time 0.090 (0.100) data 0.000 (0.006) loss 1.1434 (1.2501) teacher_loss 0.1711 (0.3886) loss_zs_kd 0.0063 (0.0154) loss_oracle 0.3582 (0.3772) kd_loss 0.7901 (0.6652) acc 93.7500 (84.6094) gate/entropy 0.9843 (0.9843) gate/usage_max 0.5670 (0.5669) gate/usage_min 0.2162 (0.2163) gate/usage_std 0.1652 (0.1652) teacher/entropy 0.0183 (0.0194) teacher/usage_max 0.7495 (0.8783) teacher/usage_min 0.0061 (0.0186) teacher/usage_std 0.3100 (0.3879) nleep/row_max_mean 1509.3796 (1512.6677) nleep/row_max_std 48.6127 (54.6075) nleep/row_min_mean 1483.3319 (1486.3519) lr 1.6374e-03 eta 0:09:23
epoch [16/50] batch [60/162] time 0.096 (0.102) data 0.001 (0.004) loss 1.2011 (1.2554) teacher_loss 0.3529 (0.3928) loss_zs_kd 0.0396 (0.0174) loss_oracle 0.4171 (0.3759) kd_loss 0.6198 (0.6659) acc 87.5000 (84.1146) gate/entropy 0.9840 (0.9843) gate/usage_max 0.5673 (0.5670) gate/usage_min 0.2161 (0.2162) gate/usage_std 0.1654 (0.1652) teacher/entropy 0.0475 (0.0203) teacher/usage_max 0.8958 (0.8766) teacher/usage_min 0.0486 (0.0187) teacher/usage_std 0.3977 (0.3867) nleep/row_max_mean 1511.8978 (1512.3115) nleep/row_max_std 53.4992 (55.4688) nleep/row_min_mean 1485.5815 (1486.0596) lr 1.6374e-03 eta 0:09:30
epoch [16/50] batch [80/162] time 0.094 (0.100) data 0.000 (0.003) loss 1.5020 (1.2391) teacher_loss 0.6234 (0.3759) loss_zs_kd 0.0254 (0.0178) loss_oracle 0.3609 (0.3800) kd_loss 0.6855 (0.6643) acc 78.1250 (85.4297) gate/entropy 0.9839 (0.9842) gate/usage_max 0.5674 (0.5671) gate/usage_min 0.2160 (0.2162) gate/usage_std 0.1655 (0.1653) teacher/entropy 0.0018 (0.0200) teacher/usage_max 0.8749 (0.8783) teacher/usage_min 0.0003 (0.0178) teacher/usage_std 0.3863 (0.3879) nleep/row_max_mean 1494.8235 (1512.1700) nleep/row_max_std 61.7432 (55.8012) nleep/row_min_mean 1466.1936 (1485.8620) lr 1.6374e-03 eta 0:09:18
epoch [16/50] batch [100/162] time 0.093 (0.099) data 0.000 (0.003) loss 1.2357 (1.2331) teacher_loss 0.4391 (0.3752) loss_zs_kd 0.0099 (0.0175) loss_oracle 0.3584 (0.3770) kd_loss 0.6125 (0.6608) acc 90.6250 (85.6562) gate/entropy 0.9840 (0.9841) gate/usage_max 0.5673 (0.5671) gate/usage_min 0.2161 (0.2162) gate/usage_std 0.1655 (0.1653) teacher/entropy 0.0195 (0.0207) teacher/usage_max 0.9323 (0.8813) teacher/usage_min 0.0014 (0.0160) teacher/usage_std 0.4244 (0.3900) nleep/row_max_mean 1508.6586 (1512.4945) nleep/row_max_std 56.7090 (55.7600) nleep/row_min_mean 1481.4015 (1485.9925) lr 1.6374e-03 eta 0:09:12
epoch [16/50] batch [120/162] time 0.099 (0.099) data 0.000 (0.002) loss 1.3002 (1.2421) teacher_loss 0.4147 (0.3825) loss_zs_kd 0.0143 (0.0176) loss_oracle 0.4154 (0.3750) kd_loss 0.6707 (0.6633) acc 84.3750 (85.4688) gate/entropy 0.9838 (0.9841) gate/usage_max 0.5675 (0.5672) gate/usage_min 0.2160 (0.2161) gate/usage_std 0.1656 (0.1654) teacher/entropy 0.0473 (0.0216) teacher/usage_max 0.8431 (0.8776) teacher/usage_min 0.0427 (0.0174) teacher/usage_std 0.3616 (0.3874) nleep/row_max_mean 1510.3567 (1511.3964) nleep/row_max_std 47.7519 (56.2112) nleep/row_min_mean 1487.0615 (1485.0106) lr 1.6374e-03 eta 0:09:07
epoch [16/50] batch [140/162] time 0.096 (0.098) data 0.000 (0.002) loss 0.9742 (1.2247) teacher_loss 0.1482 (0.3678) loss_zs_kd 0.0135 (0.0180) loss_oracle 0.3832 (0.3783) kd_loss 0.6276 (0.6588) acc 100.0000 (86.1384) gate/entropy 0.9835 (0.9840) gate/usage_max 0.5678 (0.5673) gate/usage_min 0.2159 (0.2161) gate/usage_std 0.1658 (0.1654) teacher/entropy 0.0204 (0.0213) teacher/usage_max 0.9147 (0.8825) teacher/usage_min 0.0313 (0.0177) teacher/usage_std 0.4112 (0.3906) nleep/row_max_mean 1532.3616 (1511.4980) nleep/row_max_std 41.3668 (56.1690) nleep/row_min_mean 1502.1692 (1484.9776) lr 1.6374e-03 eta 0:09:02
epoch [16/50] batch [160/162] time 0.087 (0.097) data 0.000 (0.002) loss 1.0509 (1.2215) teacher_loss 0.3249 (0.3675) loss_zs_kd 0.0226 (0.0178) loss_oracle 0.3008 (0.3755) kd_loss 0.5643 (0.6573) acc 87.5000 (86.0938) gate/entropy 0.9834 (0.9839) gate/usage_max 0.5679 (0.5673) gate/usage_min 0.2158 (0.2161) gate/usage_std 0.1659 (0.1655) teacher/entropy 0.0017 (0.0224) teacher/usage_max 0.9997 (0.8829) teacher/usage_min 0.0001 (0.0191) teacher/usage_std 0.4712 (0.3908) nleep/row_max_mean 1518.4392 (1511.3659) nleep/row_max_std 48.9926 (56.0515) nleep/row_min_mean 1487.8326 (1484.7562) lr 1.6374e-03 eta 0:08:55
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,959
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,567
* accuracy: 78.2%
* error: 21.8%
* macro_f1: 77.1%
******* Domain s best val acc:      87.9%, epoch: 14 *******
******* Domain s best val test acc: 77.6%, epoch: 14 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [17/50] batch [20/162] time 0.097 (0.113) data 0.000 (0.015) loss 1.3164 (1.1829) teacher_loss 0.5223 (0.3266) loss_zs_kd 0.0150 (0.0173) loss_oracle 0.3856 (0.3852) kd_loss 0.5938 (0.6551) acc 78.1250 (87.9688) gate/entropy 0.9833 (0.9833) gate/usage_max 0.5680 (0.5680) gate/usage_min 0.2157 (0.2158) gate/usage_std 0.1660 (0.1659) teacher/entropy 0.0023 (0.0238) teacher/usage_max 0.9684 (0.8828) teacher/usage_min 0.0000 (0.0284) teacher/usage_std 0.4492 (0.3897) nleep/row_max_mean 1519.3007 (1508.0644) nleep/row_max_std 61.0872 (60.0146) nleep/row_min_mean 1488.9547 (1480.2299) lr 1.5878e-03 eta 0:10:22
epoch [17/50] batch [40/162] time 0.092 (0.105) data 0.000 (0.008) loss 1.2086 (1.1649) teacher_loss 0.3887 (0.3185) loss_zs_kd 0.0205 (0.0175) loss_oracle 0.3147 (0.3789) kd_loss 0.6523 (0.6482) acc 81.2500 (87.0312) gate/entropy 0.9831 (0.9833) gate/usage_max 0.5683 (0.5680) gate/usage_min 0.2156 (0.2158) gate/usage_std 0.1661 (0.1660) teacher/entropy 0.0042 (0.0265) teacher/usage_max 0.9058 (0.8871) teacher/usage_min 0.0006 (0.0249) teacher/usage_std 0.4066 (0.3928) nleep/row_max_mean 1503.4435 (1509.7586) nleep/row_max_std 76.3849 (60.0081) nleep/row_min_mean 1475.8167 (1481.7919) lr 1.5878e-03 eta 0:09:32
epoch [17/50] batch [60/162] time 0.098 (0.102) data 0.001 (0.005) loss 1.1610 (1.1841) teacher_loss 0.3590 (0.3428) loss_zs_kd 0.0197 (0.0174) loss_oracle 0.3855 (0.3749) kd_loss 0.5994 (0.6452) acc 87.5000 (86.3021) gate/entropy 0.9831 (0.9832) gate/usage_max 0.5682 (0.5681) gate/usage_min 0.2157 (0.2157) gate/usage_std 0.1661 (0.1660) teacher/entropy 0.0566 (0.0271) teacher/usage_max 0.9062 (0.8896) teacher/usage_min 0.0423 (0.0239) teacher/usage_std 0.4051 (0.3945) nleep/row_max_mean 1514.2600 (1508.5396) nleep/row_max_std 54.5406 (60.3817) nleep/row_min_mean 1486.7373 (1481.0145) lr 1.5878e-03 eta 0:09:14
epoch [17/50] batch [80/162] time 0.089 (0.099) data 0.000 (0.004) loss 1.1751 (1.1987) teacher_loss 0.3287 (0.3617) loss_zs_kd 0.0047 (0.0169) loss_oracle 0.3634 (0.3752) kd_loss 0.6624 (0.6409) acc 78.1250 (85.7812) gate/entropy 0.9830 (0.9832) gate/usage_max 0.5684 (0.5681) gate/usage_min 0.2156 (0.2157) gate/usage_std 0.1662 (0.1660) teacher/entropy 0.0240 (0.0297) teacher/usage_max 0.8747 (0.8912) teacher/usage_min 0.0114 (0.0239) teacher/usage_std 0.3851 (0.3956) nleep/row_max_mean 1492.5807 (1507.9738) nleep/row_max_std 55.9063 (60.6813) nleep/row_min_mean 1464.4980 (1480.6242) lr 1.5878e-03 eta 0:08:59
epoch [17/50] batch [100/162] time 0.094 (0.098) data 0.000 (0.003) loss 1.4665 (1.2099) teacher_loss 0.5628 (0.3744) loss_zs_kd 0.0159 (0.0163) loss_oracle 0.3891 (0.3738) kd_loss 0.7012 (0.6405) acc 78.1250 (85.3750) gate/entropy 0.9828 (0.9831) gate/usage_max 0.5685 (0.5682) gate/usage_min 0.2155 (0.2157) gate/usage_std 0.1663 (0.1661) teacher/entropy 0.0424 (0.0298) teacher/usage_max 0.8153 (0.8914) teacher/usage_min 0.0118 (0.0247) teacher/usage_std 0.3471 (0.3957) nleep/row_max_mean 1503.1366 (1507.2647) nleep/row_max_std 61.7087 (60.6578) nleep/row_min_mean 1477.2949 (1480.0137) lr 1.5878e-03 eta 0:08:51
epoch [17/50] batch [120/162] time 0.095 (0.098) data 0.000 (0.003) loss 1.0324 (1.2040) teacher_loss 0.2164 (0.3699) loss_zs_kd 0.0148 (0.0161) loss_oracle 0.3421 (0.3724) kd_loss 0.6375 (0.6399) acc 93.7500 (85.5469) gate/entropy 0.9827 (0.9831) gate/usage_max 0.5687 (0.5683) gate/usage_min 0.2155 (0.2156) gate/usage_std 0.1664 (0.1661) teacher/entropy 0.0180 (0.0288) teacher/usage_max 0.9059 (0.8929) teacher/usage_min 0.0047 (0.0240) teacher/usage_std 0.4063 (0.3968) nleep/row_max_mean 1504.7607 (1508.0282) nleep/row_max_std 66.6210 (60.1672) nleep/row_min_mean 1478.9163 (1480.6085) lr 1.5878e-03 eta 0:08:45
epoch [17/50] batch [140/162] time 0.094 (0.097) data 0.000 (0.002) loss 0.9558 (1.2041) teacher_loss 0.1400 (0.3693) loss_zs_kd 0.0081 (0.0162) loss_oracle 0.3845 (0.3740) kd_loss 0.6195 (0.6397) acc 93.7500 (85.5357) gate/entropy 0.9826 (0.9830) gate/usage_max 0.5687 (0.5683) gate/usage_min 0.2154 (0.2156) gate/usage_std 0.1664 (0.1662) teacher/entropy 0.0048 (0.0289) teacher/usage_max 0.9381 (0.8930) teacher/usage_min 0.0002 (0.0241) teacher/usage_std 0.4283 (0.3968) nleep/row_max_mean 1513.2509 (1508.0050) nleep/row_max_std 60.6959 (60.1300) nleep/row_min_mean 1484.3590 (1480.4884) lr 1.5878e-03 eta 0:08:39
epoch [17/50] batch [160/162] time 0.084 (0.096) data 0.000 (0.002) loss 1.1492 (1.2046) teacher_loss 0.2799 (0.3668) loss_zs_kd 0.0285 (0.0165) loss_oracle 0.3525 (0.3754) kd_loss 0.6787 (0.6418) acc 87.5000 (85.5859) gate/entropy 0.9825 (0.9829) gate/usage_max 0.5689 (0.5684) gate/usage_min 0.2154 (0.2156) gate/usage_std 0.1665 (0.1662) teacher/entropy 0.0068 (0.0284) teacher/usage_max 0.8749 (0.8912) teacher/usage_min 0.0012 (0.0251) teacher/usage_std 0.3862 (0.3956) nleep/row_max_mean 1503.4614 (1508.0627) nleep/row_max_std 60.7192 (60.2277) nleep/row_min_mean 1476.0972 (1480.4592) lr 1.5878e-03 eta 0:08:31
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,965
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 89.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,603
* accuracy: 79.3%
* error: 20.7%
* macro_f1: 77.5%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [18/50] batch [20/162] time 0.114 (0.115) data 0.000 (0.014) loss 1.0872 (1.2092) teacher_loss 0.2052 (0.3717) loss_zs_kd 0.0177 (0.0161) loss_oracle 0.3929 (0.3800) kd_loss 0.6766 (0.6395) acc 90.6250 (84.8438) gate/entropy 0.9826 (0.9824) gate/usage_max 0.5688 (0.5689) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1665 (0.1666) teacher/entropy 0.0096 (0.0269) teacher/usage_max 0.8742 (0.8945) teacher/usage_min 0.0018 (0.0207) teacher/usage_std 0.3857 (0.3981) nleep/row_max_mean 1506.8284 (1513.2308) nleep/row_max_std 51.9808 (57.5315) nleep/row_min_mean 1477.0483 (1483.5825) lr 1.5358e-03 eta 0:10:10
epoch [18/50] batch [40/162] time 0.097 (0.108) data 0.000 (0.007) loss 1.1031 (1.2138) teacher_loss 0.2830 (0.3760) loss_zs_kd 0.0262 (0.0171) loss_oracle 0.3512 (0.3845) kd_loss 0.6313 (0.6370) acc 90.6250 (84.8438) gate/entropy 0.9823 (0.9824) gate/usage_max 0.5691 (0.5690) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1667 (0.1666) teacher/entropy 0.0242 (0.0287) teacher/usage_max 0.9055 (0.8950) teacher/usage_min 0.0427 (0.0253) teacher/usage_std 0.4046 (0.3982) nleep/row_max_mean 1509.7880 (1511.2761) nleep/row_max_std 60.4691 (58.2750) nleep/row_min_mean 1481.1145 (1481.7997) lr 1.5358e-03 eta 0:09:33
epoch [18/50] batch [60/162] time 0.093 (0.104) data 0.000 (0.005) loss 1.2338 (1.2010) teacher_loss 0.4225 (0.3628) loss_zs_kd 0.0117 (0.0169) loss_oracle 0.3044 (0.3809) kd_loss 0.6532 (0.6393) acc 78.1250 (85.5729) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5692 (0.5690) gate/usage_min 0.2152 (0.2153) gate/usage_std 0.1668 (0.1666) teacher/entropy 0.0012 (0.0282) teacher/usage_max 0.9062 (0.8932) teacher/usage_min 0.0314 (0.0268) teacher/usage_std 0.4052 (0.3968) nleep/row_max_mean 1528.0897 (1511.7049) nleep/row_max_std 44.7403 (57.5144) nleep/row_min_mean 1493.8788 (1482.0835) lr 1.5358e-03 eta 0:09:09
epoch [18/50] batch [80/162] time 0.096 (0.102) data 0.000 (0.004) loss 1.1772 (1.2051) teacher_loss 0.2419 (0.3651) loss_zs_kd 0.0262 (0.0175) loss_oracle 0.4477 (0.3846) kd_loss 0.6983 (0.6390) acc 96.8750 (85.8984) gate/entropy 0.9820 (0.9823) gate/usage_max 0.5694 (0.5691) gate/usage_min 0.2151 (0.2153) gate/usage_std 0.1669 (0.1667) teacher/entropy 0.0165 (0.0276) teacher/usage_max 0.8442 (0.8941) teacher/usage_min 0.0040 (0.0249) teacher/usage_std 0.3663 (0.3976) nleep/row_max_mean 1513.8384 (1512.1947) nleep/row_max_std 57.2187 (57.3036) nleep/row_min_mean 1482.9095 (1482.3912) lr 1.5358e-03 eta 0:08:59
epoch [18/50] batch [100/162] time 0.102 (0.102) data 0.000 (0.003) loss 1.2244 (1.2116) teacher_loss 0.4519 (0.3745) loss_zs_kd 0.0195 (0.0168) loss_oracle 0.3416 (0.3827) kd_loss 0.5920 (0.6374) acc 81.2500 (85.5312) gate/entropy 0.9819 (0.9822) gate/usage_max 0.5694 (0.5691) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1669 (0.1667) teacher/entropy 0.0388 (0.0270) teacher/usage_max 0.9303 (0.8963) teacher/usage_min 0.0070 (0.0236) teacher/usage_std 0.4227 (0.3991) nleep/row_max_mean 1515.1128 (1512.0722) nleep/row_max_std 59.2938 (57.4321) nleep/row_min_mean 1484.5029 (1482.2602) lr 1.5358e-03 eta 0:08:52
epoch [18/50] batch [120/162] time 0.099 (0.101) data 0.000 (0.003) loss 1.5728 (1.2043) teacher_loss 0.7142 (0.3699) loss_zs_kd 0.0232 (0.0161) loss_oracle 0.3427 (0.3819) kd_loss 0.6757 (0.6354) acc 68.7500 (85.3385) gate/entropy 0.9820 (0.9822) gate/usage_max 0.5694 (0.5692) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1669 (0.1667) teacher/entropy 0.0086 (0.0266) teacher/usage_max 0.8750 (0.8986) teacher/usage_min 0.0334 (0.0236) teacher/usage_std 0.3838 (0.4007) nleep/row_max_mean 1489.4980 (1511.7092) nleep/row_max_std 63.7877 (57.8823) nleep/row_min_mean 1461.5844 (1481.7898) lr 1.5358e-03 eta 0:08:47
epoch [18/50] batch [140/162] time 0.098 (0.100) data 0.000 (0.002) loss 1.0308 (1.2081) teacher_loss 0.1252 (0.3716) loss_zs_kd 0.0099 (0.0158) loss_oracle 0.3809 (0.3850) kd_loss 0.7102 (0.6361) acc 96.8750 (85.4688) gate/entropy 0.9818 (0.9821) gate/usage_max 0.5695 (0.5692) gate/usage_min 0.2150 (0.2152) gate/usage_std 0.1670 (0.1668) teacher/entropy 0.0347 (0.0278) teacher/usage_max 0.8128 (0.8967) teacher/usage_min 0.0307 (0.0245) teacher/usage_std 0.3429 (0.3994) nleep/row_max_mean 1514.9436 (1511.4746) nleep/row_max_std 58.2855 (58.2329) nleep/row_min_mean 1484.7577 (1481.3733) lr 1.5358e-03 eta 0:08:40
epoch [18/50] batch [160/162] time 0.091 (0.099) data 0.000 (0.002) loss 1.0896 (1.2171) teacher_loss 0.1765 (0.3798) loss_zs_kd 0.0127 (0.0159) loss_oracle 0.4203 (0.3853) kd_loss 0.6965 (0.6368) acc 96.8750 (85.1953) gate/entropy 0.9817 (0.9821) gate/usage_max 0.5697 (0.5692) gate/usage_min 0.2150 (0.2152) gate/usage_std 0.1671 (0.1668) teacher/entropy 0.0179 (0.0261) teacher/usage_max 0.8441 (0.8976) teacher/usage_min 0.0042 (0.0236) teacher/usage_std 0.3661 (0.4000) nleep/row_max_mean 1528.9802 (1511.1403) nleep/row_max_std 57.1214 (58.4811) nleep/row_min_mean 1495.8350 (1480.9045) lr 1.5358e-03 eta 0:08:34
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,962
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 89.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,608
* accuracy: 79.5%
* error: 20.5%
* macro_f1: 76.8%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [19/50] batch [20/162] time 0.102 (0.118) data 0.000 (0.016) loss 1.5346 (1.2033) teacher_loss 0.6928 (0.3449) loss_zs_kd 0.0424 (0.0188) loss_oracle 0.4180 (0.4103) kd_loss 0.6116 (0.6439) acc 68.7500 (86.8750) gate/entropy 0.9817 (0.9817) gate/usage_max 0.5697 (0.5697) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0422 (0.0327) teacher/usage_max 0.9062 (0.8830) teacher/usage_min 0.0291 (0.0282) teacher/usage_std 0.4054 (0.3900) nleep/row_max_mean 1498.1753 (1505.1664) nleep/row_max_std 75.8442 (60.8900) nleep/row_min_mean 1469.5964 (1474.8979) lr 1.4818e-03 eta 0:10:10
epoch [19/50] batch [40/162] time 0.093 (0.106) data 0.000 (0.008) loss 1.3021 (1.2109) teacher_loss 0.4495 (0.3721) loss_zs_kd 0.0052 (0.0184) loss_oracle 0.4199 (0.3939) kd_loss 0.6401 (0.6326) acc 81.2500 (85.5469) gate/entropy 0.9816 (0.9817) gate/usage_max 0.5698 (0.5697) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1672 (0.1671) teacher/entropy 0.0287 (0.0289) teacher/usage_max 0.8909 (0.8984) teacher/usage_min 0.0160 (0.0229) teacher/usage_std 0.3955 (0.4006) nleep/row_max_mean 1506.4235 (1507.5103) nleep/row_max_std 68.3618 (60.5340) nleep/row_min_mean 1476.5519 (1477.0905) lr 1.4818e-03 eta 0:09:02
epoch [19/50] batch [60/162] time 0.150 (0.109) data 0.001 (0.006) loss 1.1920 (1.2034) teacher_loss 0.2833 (0.3664) loss_zs_kd 0.0269 (0.0191) loss_oracle 0.4280 (0.3884) kd_loss 0.6812 (0.6333) acc 90.6250 (85.8854) gate/entropy 0.9815 (0.9816) gate/usage_max 0.5698 (0.5698) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1672 (0.1672) teacher/entropy 0.0484 (0.0282) teacher/usage_max 0.8284 (0.8983) teacher/usage_min 0.0596 (0.0220) teacher/usage_std 0.3507 (0.4006) nleep/row_max_mean 1507.7537 (1507.6736) nleep/row_max_std 56.4925 (61.2796) nleep/row_min_mean 1478.4551 (1477.1980) lr 1.4818e-03 eta 0:09:17
epoch [19/50] batch [80/162] time 0.089 (0.107) data 0.000 (0.004) loss 1.1546 (1.1973) teacher_loss 0.3552 (0.3583) loss_zs_kd 0.0105 (0.0180) loss_oracle 0.3239 (0.3878) kd_loss 0.6322 (0.6360) acc 87.5000 (86.5625) gate/entropy 0.9814 (0.9816) gate/usage_max 0.5700 (0.5698) gate/usage_min 0.2148 (0.2149) gate/usage_std 0.1673 (0.1672) teacher/entropy 0.0217 (0.0283) teacher/usage_max 0.9059 (0.8954) teacher/usage_min 0.0245 (0.0217) teacher/usage_std 0.4053 (0.3987) nleep/row_max_mean 1518.8018 (1508.0236) nleep/row_max_std 58.5916 (61.0461) nleep/row_min_mean 1489.3348 (1477.8318) lr 1.4818e-03 eta 0:09:04
epoch [19/50] batch [100/162] time 0.111 (0.105) data 0.000 (0.004) loss 1.1791 (1.2036) teacher_loss 0.3759 (0.3669) loss_zs_kd 0.0085 (0.0174) loss_oracle 0.3284 (0.3828) kd_loss 0.6347 (0.6366) acc 81.2500 (86.2188) gate/entropy 0.9813 (0.9815) gate/usage_max 0.5701 (0.5698) gate/usage_min 0.2148 (0.2149) gate/usage_std 0.1674 (0.1672) teacher/entropy 0.0187 (0.0277) teacher/usage_max 0.9062 (0.8954) teacher/usage_min 0.0054 (0.0211) teacher/usage_std 0.4065 (0.3988) nleep/row_max_mean 1504.6055 (1507.6304) nleep/row_max_std 60.1743 (61.3830) nleep/row_min_mean 1474.6709 (1477.6762) lr 1.4818e-03 eta 0:08:51
epoch [19/50] batch [120/162] time 0.099 (0.104) data 0.000 (0.003) loss 1.1022 (1.2027) teacher_loss 0.2151 (0.3662) loss_zs_kd 0.0171 (0.0168) loss_oracle 0.4237 (0.3792) kd_loss 0.6667 (0.6384) acc 90.6250 (86.3021) gate/entropy 0.9814 (0.9815) gate/usage_max 0.5700 (0.5699) gate/usage_min 0.2148 (0.2149) gate/usage_std 0.1673 (0.1673) teacher/entropy 0.0735 (0.0263) teacher/usage_max 0.8175 (0.8948) teacher/usage_min 0.0565 (0.0204) teacher/usage_std 0.3435 (0.3985) nleep/row_max_mean 1501.9834 (1507.9337) nleep/row_max_std 63.6899 (61.6650) nleep/row_min_mean 1474.8643 (1478.1072) lr 1.4818e-03 eta 0:08:44
epoch [19/50] batch [140/162] time 0.112 (0.103) data 0.000 (0.003) loss 1.0619 (1.2076) teacher_loss 0.2823 (0.3684) loss_zs_kd 0.0147 (0.0167) loss_oracle 0.3673 (0.3792) kd_loss 0.5886 (0.6413) acc 90.6250 (86.1161) gate/entropy 0.9812 (0.9815) gate/usage_max 0.5702 (0.5699) gate/usage_min 0.2147 (0.2149) gate/usage_std 0.1675 (0.1673) teacher/entropy 0.0048 (0.0257) teacher/usage_max 0.9677 (0.8924) teacher/usage_min 0.0000 (0.0201) teacher/usage_std 0.4487 (0.3970) nleep/row_max_mean 1523.2971 (1507.7905) nleep/row_max_std 55.6917 (61.4783) nleep/row_min_mean 1491.9867 (1478.1919) lr 1.4818e-03 eta 0:08:38
epoch [19/50] batch [160/162] time 0.090 (0.102) data 0.000 (0.002) loss 1.1201 (1.2108) teacher_loss 0.2413 (0.3731) loss_zs_kd 0.0128 (0.0163) loss_oracle 0.4447 (0.3793) kd_loss 0.6501 (0.6399) acc 96.8750 (85.9961) gate/entropy 0.9811 (0.9814) gate/usage_max 0.5703 (0.5699) gate/usage_min 0.2147 (0.2149) gate/usage_std 0.1675 (0.1673) teacher/entropy 0.0033 (0.0248) teacher/usage_max 0.9060 (0.8947) teacher/usage_min 0.0003 (0.0188) teacher/usage_std 0.4067 (0.3985) nleep/row_max_mean 1511.2324 (1507.9432) nleep/row_max_std 51.1405 (61.3142) nleep/row_min_mean 1481.7933 (1478.4002) lr 1.4818e-03 eta 0:08:30
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,962
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 89.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,611
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 76.6%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [20/50] batch [20/162] time 0.099 (0.114) data 0.000 (0.016) loss 1.2294 (1.2276) teacher_loss 0.3771 (0.3715) loss_zs_kd 0.0270 (0.0184) loss_oracle 0.4287 (0.3957) kd_loss 0.6245 (0.6491) acc 81.2500 (86.0938) gate/entropy 0.9811 (0.9811) gate/usage_max 0.5703 (0.5702) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1675 (0.1675) teacher/entropy 0.0369 (0.0203) teacher/usage_max 0.8978 (0.8896) teacher/usage_min 0.0287 (0.0154) teacher/usage_std 0.3996 (0.3954) nleep/row_max_mean 1497.5051 (1506.7931) nleep/row_max_std 54.7609 (56.3306) nleep/row_min_mean 1469.8219 (1477.3003) lr 1.4258e-03 eta 0:09:31
epoch [20/50] batch [40/162] time 0.095 (0.106) data 0.000 (0.008) loss 1.1081 (1.2289) teacher_loss 0.3594 (0.3752) loss_zs_kd 0.0069 (0.0174) loss_oracle 0.3344 (0.3895) kd_loss 0.5780 (0.6503) acc 81.2500 (85.9375) gate/entropy 0.9810 (0.9811) gate/usage_max 0.5704 (0.5703) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1676 (0.1676) teacher/entropy 0.0310 (0.0200) teacher/usage_max 0.9511 (0.8886) teacher/usage_min 0.0194 (0.0143) teacher/usage_std 0.4369 (0.3949) nleep/row_max_mean 1516.9153 (1508.5828) nleep/row_max_std 49.1427 (57.3687) nleep/row_min_mean 1489.1704 (1479.4437) lr 1.4258e-03 eta 0:08:48
epoch [20/50] batch [60/162] time 0.094 (0.104) data 0.001 (0.005) loss 1.2456 (1.2398) teacher_loss 0.2423 (0.3898) loss_zs_kd 0.0141 (0.0161) loss_oracle 0.4135 (0.3881) kd_loss 0.7895 (0.6479) acc 90.6250 (84.8438) gate/entropy 0.9810 (0.9810) gate/usage_max 0.5704 (0.5703) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1676 (0.1676) teacher/entropy 0.0339 (0.0217) teacher/usage_max 0.7316 (0.8892) teacher/usage_min 0.0035 (0.0150) teacher/usage_std 0.3012 (0.3952) nleep/row_max_mean 1500.3984 (1509.4743) nleep/row_max_std 56.7597 (57.0236) nleep/row_min_mean 1475.7756 (1480.5410) lr 1.4258e-03 eta 0:08:33
epoch [20/50] batch [80/162] time 0.094 (0.102) data 0.000 (0.004) loss 1.2110 (1.2316) teacher_loss 0.3769 (0.3825) loss_zs_kd 0.0093 (0.0160) loss_oracle 0.3484 (0.3896) kd_loss 0.6552 (0.6463) acc 78.1250 (84.9609) gate/entropy 0.9810 (0.9810) gate/usage_max 0.5704 (0.5704) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1676 (0.1676) teacher/entropy 0.0311 (0.0209) teacher/usage_max 0.8720 (0.8917) teacher/usage_min 0.0243 (0.0164) teacher/usage_std 0.3823 (0.3967) nleep/row_max_mean 1511.6987 (1510.3634) nleep/row_max_std 50.3032 (56.6338) nleep/row_min_mean 1483.4659 (1481.2635) lr 1.4258e-03 eta 0:08:23
epoch [20/50] batch [100/162] time 0.100 (0.101) data 0.001 (0.003) loss 1.0988 (1.2285) teacher_loss 0.2869 (0.3786) loss_zs_kd 0.0167 (0.0160) loss_oracle 0.3616 (0.3875) kd_loss 0.6228 (0.6481) acc 93.7500 (85.1562) gate/entropy 0.9808 (0.9810) gate/usage_max 0.5706 (0.5704) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1677 (0.1676) teacher/entropy 0.0302 (0.0212) teacher/usage_max 0.9059 (0.8894) teacher/usage_min 0.0385 (0.0180) teacher/usage_std 0.4049 (0.3951) nleep/row_max_mean 1503.7216 (1510.5384) nleep/row_max_std 56.2221 (56.4759) nleep/row_min_mean 1475.8484 (1481.6573) lr 1.4258e-03 eta 0:08:15
epoch [20/50] batch [120/162] time 0.090 (0.100) data 0.000 (0.003) loss 0.9857 (1.2222) teacher_loss 0.2042 (0.3743) loss_zs_kd 0.0063 (0.0156) loss_oracle 0.3518 (0.3873) kd_loss 0.6024 (0.6464) acc 93.7500 (85.4948) gate/entropy 0.9808 (0.9810) gate/usage_max 0.5706 (0.5704) gate/usage_min 0.2146 (0.2146) gate/usage_std 0.1678 (0.1676) teacher/entropy 0.0326 (0.0228) teacher/usage_max 0.9242 (0.8895) teacher/usage_min 0.0159 (0.0194) teacher/usage_std 0.4182 (0.3950) nleep/row_max_mean 1501.4968 (1510.7470) nleep/row_max_std 62.6002 (56.1705) nleep/row_min_mean 1477.0103 (1482.1019) lr 1.4258e-03 eta 0:08:07
epoch [20/50] batch [140/162] time 0.100 (0.099) data 0.000 (0.003) loss 1.3621 (1.2178) teacher_loss 0.6102 (0.3711) loss_zs_kd 0.0209 (0.0155) loss_oracle 0.3550 (0.3874) kd_loss 0.5640 (0.6452) acc 87.5000 (85.7589) gate/entropy 0.9807 (0.9809) gate/usage_max 0.5707 (0.5704) gate/usage_min 0.2145 (0.2146) gate/usage_std 0.1678 (0.1677) teacher/entropy 0.0196 (0.0228) teacher/usage_max 0.9768 (0.8907) teacher/usage_min 0.0002 (0.0192) teacher/usage_std 0.4551 (0.3958) nleep/row_max_mean 1511.6276 (1511.0500) nleep/row_max_std 55.5370 (55.9721) nleep/row_min_mean 1483.8499 (1482.5329) lr 1.4258e-03 eta 0:08:03
epoch [20/50] batch [160/162] time 0.091 (0.098) data 0.000 (0.002) loss 1.0559 (1.2163) teacher_loss 0.2651 (0.3707) loss_zs_kd 0.0096 (0.0153) loss_oracle 0.3647 (0.3854) kd_loss 0.6037 (0.6452) acc 90.6250 (85.6836) gate/entropy 0.9807 (0.9809) gate/usage_max 0.5707 (0.5705) gate/usage_min 0.2145 (0.2146) gate/usage_std 0.1679 (0.1677) teacher/entropy 0.0183 (0.0234) teacher/usage_max 0.9375 (0.8901) teacher/usage_min 0.0233 (0.0202) teacher/usage_std 0.4272 (0.3953) nleep/row_max_mean 1500.3986 (1511.1789) nleep/row_max_std 61.3151 (55.7397) nleep/row_min_mean 1476.7280 (1482.8821) lr 1.4258e-03 eta 0:07:58
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,958
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,481
* accuracy: 75.6%
* error: 24.4%
* macro_f1: 74.7%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [21/50] batch [20/162] time 0.092 (0.117) data 0.000 (0.019) loss 1.2308 (1.2091) teacher_loss 0.4026 (0.3653) loss_zs_kd 0.0180 (0.0183) loss_oracle 0.3753 (0.3664) kd_loss 0.6315 (0.6515) acc 87.5000 (86.4062) gate/entropy 0.9806 (0.9806) gate/usage_max 0.5708 (0.5708) gate/usage_min 0.2145 (0.2145) gate/usage_std 0.1679 (0.1679) teacher/entropy 0.0698 (0.0281) teacher/usage_max 0.8563 (0.8785) teacher/usage_min 0.0476 (0.0280) teacher/usage_std 0.3703 (0.3871) nleep/row_max_mean 1507.6301 (1511.5689) nleep/row_max_std 56.0374 (54.7749) nleep/row_min_mean 1480.7157 (1484.1855) lr 1.3681e-03 eta 0:09:27
epoch [21/50] batch [40/162] time 0.099 (0.106) data 0.000 (0.009) loss 1.2421 (1.2037) teacher_loss 0.4160 (0.3607) loss_zs_kd 0.0072 (0.0158) loss_oracle 0.3774 (0.3732) kd_loss 0.6338 (0.6486) acc 84.3750 (87.0312) gate/entropy 0.9806 (0.9806) gate/usage_max 0.5708 (0.5708) gate/usage_min 0.2145 (0.2145) gate/usage_std 0.1679 (0.1679) teacher/entropy 0.0380 (0.0302) teacher/usage_max 0.8863 (0.8792) teacher/usage_min 0.0201 (0.0269) teacher/usage_std 0.3922 (0.3874) nleep/row_max_mean 1514.0027 (1513.4150) nleep/row_max_std 50.4415 (53.4445) nleep/row_min_mean 1488.9138 (1486.7800) lr 1.3681e-03 eta 0:08:28
epoch [21/50] batch [60/162] time 0.094 (0.102) data 0.001 (0.006) loss 1.0210 (1.2116) teacher_loss 0.2271 (0.3634) loss_zs_kd 0.0152 (0.0162) loss_oracle 0.3516 (0.3761) kd_loss 0.6105 (0.6520) acc 87.5000 (86.5104) gate/entropy 0.9806 (0.9806) gate/usage_max 0.5708 (0.5708) gate/usage_min 0.2145 (0.2145) gate/usage_std 0.1679 (0.1679) teacher/entropy 0.0137 (0.0313) teacher/usage_max 0.9349 (0.8746) teacher/usage_min 0.0312 (0.0278) teacher/usage_std 0.4254 (0.3843) nleep/row_max_mean 1519.2031 (1514.9091) nleep/row_max_std 55.2558 (52.8815) nleep/row_min_mean 1494.0784 (1488.8244) lr 1.3681e-03 eta 0:08:11
epoch [21/50] batch [80/162] time 0.102 (0.101) data 0.000 (0.005) loss 1.3286 (1.2163) teacher_loss 0.5127 (0.3703) loss_zs_kd 0.0200 (0.0167) loss_oracle 0.3981 (0.3759) kd_loss 0.6069 (0.6496) acc 81.2500 (86.3281) gate/entropy 0.9804 (0.9806) gate/usage_max 0.5710 (0.5708) gate/usage_min 0.2144 (0.2144) gate/usage_std 0.1680 (0.1679) teacher/entropy 0.0239 (0.0307) teacher/usage_max 0.9283 (0.8776) teacher/usage_min 0.0008 (0.0274) teacher/usage_std 0.4217 (0.3864) nleep/row_max_mean 1516.2407 (1515.2164) nleep/row_max_std 58.8560 (52.8628) nleep/row_min_mean 1491.1797 (1489.3828) lr 1.3681e-03 eta 0:08:02
epoch [21/50] batch [100/162] time 0.089 (0.100) data 0.000 (0.004) loss 1.5342 (1.2181) teacher_loss 0.5833 (0.3724) loss_zs_kd 0.0245 (0.0174) loss_oracle 0.4117 (0.3751) kd_loss 0.7328 (0.6494) acc 75.0000 (86.0625) gate/entropy 0.9803 (0.9805) gate/usage_max 0.5711 (0.5709) gate/usage_min 0.2143 (0.2144) gate/usage_std 0.1681 (0.1680) teacher/entropy 0.0255 (0.0322) teacher/usage_max 0.7974 (0.8763) teacher/usage_min 0.0315 (0.0275) teacher/usage_std 0.3331 (0.3855) nleep/row_max_mean 1509.1506 (1514.2959) nleep/row_max_std 60.9489 (53.1945) nleep/row_min_mean 1483.2732 (1488.8427) lr 1.3681e-03 eta 0:07:56
epoch [21/50] batch [120/162] time 0.091 (0.100) data 0.000 (0.003) loss 1.4054 (1.2226) teacher_loss 0.4754 (0.3762) loss_zs_kd 0.0276 (0.0174) loss_oracle 0.4361 (0.3758) kd_loss 0.6982 (0.6498) acc 75.0000 (86.0156) gate/entropy 0.9805 (0.9805) gate/usage_max 0.5709 (0.5709) gate/usage_min 0.2144 (0.2144) gate/usage_std 0.1680 (0.1680) teacher/entropy 0.0675 (0.0336) teacher/usage_max 0.7903 (0.8744) teacher/usage_min 0.0184 (0.0263) teacher/usage_std 0.3307 (0.3843) nleep/row_max_mean 1494.7289 (1512.9489) nleep/row_max_std 56.3211 (53.7531) nleep/row_min_mean 1470.9303 (1487.7271) lr 1.3681e-03 eta 0:07:51
epoch [21/50] batch [140/162] time 0.099 (0.099) data 0.000 (0.003) loss 1.2464 (1.2245) teacher_loss 0.2897 (0.3754) loss_zs_kd 0.0144 (0.0176) loss_oracle 0.3757 (0.3748) kd_loss 0.7617 (0.6529) acc 87.5000 (85.8259) gate/entropy 0.9805 (0.9805) gate/usage_max 0.5709 (0.5709) gate/usage_min 0.2144 (0.2144) gate/usage_std 0.1680 (0.1680) teacher/entropy 0.0143 (0.0338) teacher/usage_max 0.7796 (0.8710) teacher/usage_min 0.0343 (0.0248) teacher/usage_std 0.3216 (0.3822) nleep/row_max_mean 1510.8984 (1512.0287) nleep/row_max_std 47.1555 (53.6822) nleep/row_min_mean 1486.4921 (1486.9383) lr 1.3681e-03 eta 0:07:47
epoch [21/50] batch [160/162] time 0.090 (0.098) data 0.000 (0.003) loss 1.1481 (1.2216) teacher_loss 0.2468 (0.3716) loss_zs_kd 0.0118 (0.0176) loss_oracle 0.4341 (0.3761) kd_loss 0.6783 (0.6532) acc 90.6250 (85.9570) gate/entropy 0.9802 (0.9805) gate/usage_max 0.5712 (0.5709) gate/usage_min 0.2143 (0.2144) gate/usage_std 0.1682 (0.1680) teacher/entropy 0.0349 (0.0330) teacher/usage_max 0.8437 (0.8714) teacher/usage_min 0.0151 (0.0243) teacher/usage_std 0.3645 (0.3826) nleep/row_max_mean 1498.9712 (1511.6966) nleep/row_max_std 56.4679 (53.7233) nleep/row_min_mean 1475.8933 (1486.5723) lr 1.3681e-03 eta 0:07:40
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,964
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,488
* accuracy: 75.8%
* error: 24.2%
* macro_f1: 74.8%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [22/50] batch [20/162] time 0.094 (0.112) data 0.000 (0.018) loss 1.2533 (1.1680) teacher_loss 0.3521 (0.3228) loss_zs_kd 0.0230 (0.0171) loss_oracle 0.4180 (0.3792) kd_loss 0.6807 (0.6470) acc 75.0000 (88.4375) gate/entropy 0.9802 (0.9803) gate/usage_max 0.5712 (0.5711) gate/usage_min 0.2143 (0.2143) gate/usage_std 0.1682 (0.1682) teacher/entropy 0.0020 (0.0311) teacher/usage_max 0.8748 (0.8795) teacher/usage_min 0.0002 (0.0213) teacher/usage_std 0.3862 (0.3883) nleep/row_max_mean 1501.0712 (1509.8086) nleep/row_max_std 58.7686 (54.1969) nleep/row_min_mean 1475.9453 (1484.8549) lr 1.3090e-03 eta 0:08:45
epoch [22/50] batch [40/162] time 0.095 (0.103) data 0.001 (0.009) loss 1.1698 (1.1957) teacher_loss 0.2984 (0.3459) loss_zs_kd 0.0202 (0.0172) loss_oracle 0.3942 (0.3814) kd_loss 0.6641 (0.6506) acc 87.5000 (87.2656) gate/entropy 0.9802 (0.9802) gate/usage_max 0.5712 (0.5712) gate/usage_min 0.2143 (0.2143) gate/usage_std 0.1682 (0.1682) teacher/entropy 0.0161 (0.0250) teacher/usage_max 0.8772 (0.8820) teacher/usage_min 0.0323 (0.0197) teacher/usage_std 0.3853 (0.3900) nleep/row_max_mean 1523.0953 (1509.9208) nleep/row_max_std 50.3799 (55.6262) nleep/row_min_mean 1495.2900 (1484.3906) lr 1.3090e-03 eta 0:08:01
epoch [22/50] batch [60/162] time 0.091 (0.101) data 0.001 (0.006) loss 1.3237 (1.2058) teacher_loss 0.4788 (0.3543) loss_zs_kd 0.0088 (0.0174) loss_oracle 0.4180 (0.3812) kd_loss 0.6316 (0.6522) acc 81.2500 (86.6146) gate/entropy 0.9804 (0.9802) gate/usage_max 0.5710 (0.5712) gate/usage_min 0.2144 (0.2143) gate/usage_std 0.1681 (0.1682) teacher/entropy 0.0293 (0.0244) teacher/usage_max 0.8971 (0.8810) teacher/usage_min 0.0326 (0.0172) teacher/usage_std 0.3990 (0.3896) nleep/row_max_mean 1484.7267 (1509.0799) nleep/row_max_std 66.7401 (57.0301) nleep/row_min_mean 1462.0227 (1482.9908) lr 1.3090e-03 eta 0:07:47
epoch [22/50] batch [80/162] time 0.097 (0.104) data 0.000 (0.005) loss 1.1673 (1.1990) teacher_loss 0.3518 (0.3496) loss_zs_kd 0.0179 (0.0180) loss_oracle 0.3731 (0.3829) kd_loss 0.6200 (0.6489) acc 84.3750 (86.7969) gate/entropy 0.9799 (0.9802) gate/usage_max 0.5715 (0.5712) gate/usage_min 0.2142 (0.2143) gate/usage_std 0.1684 (0.1682) teacher/entropy 0.0010 (0.0239) teacher/usage_max 0.9374 (0.8848) teacher/usage_min 0.0001 (0.0183) teacher/usage_std 0.4279 (0.3921) nleep/row_max_mean 1520.8452 (1508.2629) nleep/row_max_std 58.7898 (57.7826) nleep/row_min_mean 1491.0449 (1481.7725) lr 1.3090e-03 eta 0:08:00
epoch [22/50] batch [100/162] time 0.103 (0.103) data 0.000 (0.004) loss 1.1469 (1.2013) teacher_loss 0.2770 (0.3466) loss_zs_kd 0.0182 (0.0178) loss_oracle 0.4276 (0.3869) kd_loss 0.6470 (0.6523) acc 87.5000 (86.8438) gate/entropy 0.9801 (0.9802) gate/usage_max 0.5712 (0.5712) gate/usage_min 0.2143 (0.2143) gate/usage_std 0.1682 (0.1682) teacher/entropy 0.0048 (0.0235) teacher/usage_max 0.9060 (0.8818) teacher/usage_min 0.0007 (0.0185) teacher/usage_std 0.4067 (0.3899) nleep/row_max_mean 1512.2655 (1508.0449) nleep/row_max_std 58.9820 (57.9346) nleep/row_min_mean 1485.1028 (1481.2641) lr 1.3090e-03 eta 0:07:53
epoch [22/50] batch [120/162] time 0.092 (0.102) data 0.000 (0.003) loss 1.1749 (1.2119) teacher_loss 0.3563 (0.3556) loss_zs_kd 0.0248 (0.0178) loss_oracle 0.4151 (0.3876) kd_loss 0.5986 (0.6536) acc 90.6250 (86.3021) gate/entropy 0.9800 (0.9802) gate/usage_max 0.5714 (0.5712) gate/usage_min 0.2142 (0.2143) gate/usage_std 0.1684 (0.1682) teacher/entropy 0.0224 (0.0221) teacher/usage_max 0.9375 (0.8818) teacher/usage_min 0.0184 (0.0183) teacher/usage_std 0.4273 (0.3900) nleep/row_max_mean 1501.4625 (1508.2249) nleep/row_max_std 63.1105 (58.1489) nleep/row_min_mean 1473.2976 (1481.1237) lr 1.3090e-03 eta 0:07:46
epoch [22/50] batch [140/162] time 0.102 (0.101) data 0.000 (0.003) loss 1.1525 (1.2181) teacher_loss 0.3455 (0.3628) loss_zs_kd 0.0268 (0.0178) loss_oracle 0.4456 (0.3872) kd_loss 0.5708 (0.6529) acc 90.6250 (86.0268) gate/entropy 0.9800 (0.9801) gate/usage_max 0.5714 (0.5713) gate/usage_min 0.2142 (0.2143) gate/usage_std 0.1683 (0.1682) teacher/entropy 0.0478 (0.0222) teacher/usage_max 0.9400 (0.8824) teacher/usage_min 0.0115 (0.0183) teacher/usage_std 0.4292 (0.3905) nleep/row_max_mean 1499.2600 (1508.0346) nleep/row_max_std 68.1383 (58.1309) nleep/row_min_mean 1470.6934 (1480.7951) lr 1.3090e-03 eta 0:07:41
epoch [22/50] batch [160/162] time 0.084 (0.100) data 0.000 (0.003) loss 1.0931 (1.2192) teacher_loss 0.2465 (0.3654) loss_zs_kd 0.0169 (0.0174) loss_oracle 0.3841 (0.3870) kd_loss 0.6462 (0.6516) acc 87.5000 (86.0352) gate/entropy 0.9799 (0.9801) gate/usage_max 0.5715 (0.5713) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1684 (0.1683) teacher/entropy 0.0063 (0.0221) teacher/usage_max 0.9052 (0.8838) teacher/usage_min 0.0010 (0.0178) teacher/usage_std 0.4061 (0.3914) nleep/row_max_mean 1517.9485 (1508.3778) nleep/row_max_std 50.4073 (57.9556) nleep/row_min_mean 1489.3448 (1481.0523) lr 1.3090e-03 eta 0:07:34
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,959
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,540
* accuracy: 77.4%
* error: 22.6%
* macro_f1: 76.0%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [23/50] batch [20/162] time 0.083 (0.102) data 0.000 (0.017) loss 1.2279 (1.2153) teacher_loss 0.3884 (0.3817) loss_zs_kd 0.0302 (0.0185) loss_oracle 0.3318 (0.3932) kd_loss 0.6585 (0.6278) acc 81.2500 (83.7500) gate/entropy 0.9798 (0.9799) gate/usage_max 0.5716 (0.5715) gate/usage_min 0.2141 (0.2142) gate/usage_std 0.1685 (0.1684) teacher/entropy 0.0420 (0.0225) teacher/usage_max 0.8560 (0.9075) teacher/usage_min 0.0556 (0.0163) teacher/usage_std 0.3698 (0.4076) nleep/row_max_mean 1508.8047 (1509.5180) nleep/row_max_std 56.3412 (54.8992) nleep/row_min_mean 1479.9697 (1481.2742) lr 1.2487e-03 eta 0:07:40
epoch [23/50] batch [40/162] time 0.093 (0.094) data 0.000 (0.009) loss 1.0196 (1.1986) teacher_loss 0.2154 (0.3574) loss_zs_kd 0.0125 (0.0179) loss_oracle 0.3284 (0.3952) kd_loss 0.6338 (0.6346) acc 93.7500 (84.9219) gate/entropy 0.9800 (0.9799) gate/usage_max 0.5714 (0.5715) gate/usage_min 0.2142 (0.2141) gate/usage_std 0.1683 (0.1684) teacher/entropy 0.0639 (0.0196) teacher/usage_max 0.8591 (0.9034) teacher/usage_min 0.0195 (0.0164) teacher/usage_std 0.3741 (0.4046) nleep/row_max_mean 1498.3004 (1508.7080) nleep/row_max_std 68.4514 (57.1739) nleep/row_min_mean 1472.9265 (1480.6991) lr 1.2487e-03 eta 0:07:04
epoch [23/50] batch [60/162] time 0.085 (0.091) data 0.000 (0.006) loss 1.4021 (1.2034) teacher_loss 0.5860 (0.3462) loss_zs_kd 0.0088 (0.0174) loss_oracle 0.3356 (0.4027) kd_loss 0.6440 (0.6471) acc 81.2500 (85.6771) gate/entropy 0.9798 (0.9799) gate/usage_max 0.5716 (0.5715) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1685 (0.1684) teacher/entropy 0.0088 (0.0201) teacher/usage_max 0.9045 (0.8901) teacher/usage_min 0.0003 (0.0186) teacher/usage_std 0.4058 (0.3956) nleep/row_max_mean 1512.2583 (1508.9100) nleep/row_max_std 63.7242 (56.5927) nleep/row_min_mean 1486.3944 (1481.2790) lr 1.2487e-03 eta 0:06:47
epoch [23/50] batch [80/162] time 0.088 (0.090) data 0.000 (0.005) loss 1.2052 (1.2108) teacher_loss 0.3473 (0.3507) loss_zs_kd 0.0200 (0.0183) loss_oracle 0.4264 (0.4057) kd_loss 0.6347 (0.6481) acc 90.6250 (86.1719) gate/entropy 0.9798 (0.9799) gate/usage_max 0.5716 (0.5715) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1685 (0.1684) teacher/entropy 0.0223 (0.0233) teacher/usage_max 0.9003 (0.8858) teacher/usage_min 0.0058 (0.0211) teacher/usage_std 0.4025 (0.3925) nleep/row_max_mean 1509.6940 (1508.5314) nleep/row_max_std 67.9231 (56.5518) nleep/row_min_mean 1483.0020 (1481.0929) lr 1.2487e-03 eta 0:06:40
epoch [23/50] batch [100/162] time 0.086 (0.089) data 0.000 (0.004) loss 1.2418 (1.2200) teacher_loss 0.4114 (0.3630) loss_zs_kd 0.0094 (0.0182) loss_oracle 0.3672 (0.4002) kd_loss 0.6421 (0.6479) acc 84.3750 (85.6562) gate/entropy 0.9797 (0.9799) gate/usage_max 0.5717 (0.5715) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1685 (0.1684) teacher/entropy 0.0543 (0.0254) teacher/usage_max 0.8600 (0.8838) teacher/usage_min 0.0203 (0.0231) teacher/usage_std 0.3746 (0.3910) nleep/row_max_mean 1508.9329 (1508.3357) nleep/row_max_std 56.8183 (55.7685) nleep/row_min_mean 1483.7954 (1481.0919) lr 1.2487e-03 eta 0:06:36
epoch [23/50] batch [120/162] time 0.098 (0.089) data 0.000 (0.003) loss 1.0506 (1.2190) teacher_loss 0.3218 (0.3635) loss_zs_kd 0.0114 (0.0174) loss_oracle 0.3583 (0.3969) kd_loss 0.5439 (0.6483) acc 81.2500 (85.7031) gate/entropy 0.9797 (0.9798) gate/usage_max 0.5717 (0.5716) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1685 (0.1684) teacher/entropy 0.0306 (0.0271) teacher/usage_max 0.9843 (0.8816) teacher/usage_min 0.0004 (0.0244) teacher/usage_std 0.4604 (0.3894) nleep/row_max_mean 1508.7463 (1507.9451) nleep/row_max_std 53.3886 (55.0456) nleep/row_min_mean 1480.6266 (1480.9052) lr 1.2487e-03 eta 0:06:34
epoch [23/50] batch [140/162] time 0.099 (0.090) data 0.000 (0.003) loss 1.3019 (1.2152) teacher_loss 0.4710 (0.3608) loss_zs_kd 0.0232 (0.0173) loss_oracle 0.3930 (0.3950) kd_loss 0.6228 (0.6482) acc 84.3750 (85.7589) gate/entropy 0.9796 (0.9798) gate/usage_max 0.5718 (0.5716) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1686 (0.1685) teacher/entropy 0.0617 (0.0285) teacher/usage_max 0.8722 (0.8804) teacher/usage_min 0.0614 (0.0269) teacher/usage_std 0.3811 (0.3884) nleep/row_max_mean 1525.1700 (1508.7764) nleep/row_max_std 55.6942 (54.3484) nleep/row_min_mean 1497.3401 (1481.6606) lr 1.2487e-03 eta 0:06:34
epoch [23/50] batch [160/162] time 0.087 (0.090) data 0.000 (0.002) loss 1.1676 (1.2240) teacher_loss 0.3021 (0.3691) loss_zs_kd 0.0078 (0.0172) loss_oracle 0.3734 (0.3949) kd_loss 0.6749 (0.6489) acc 93.7500 (85.6445) gate/entropy 0.9797 (0.9798) gate/usage_max 0.5717 (0.5716) gate/usage_min 0.2141 (0.2141) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0069 (0.0295) teacher/usage_max 0.8750 (0.8786) teacher/usage_min 0.0328 (0.0291) teacher/usage_std 0.3838 (0.3871) nleep/row_max_mean 1515.6577 (1508.8678) nleep/row_max_std 53.1921 (54.2847) nleep/row_min_mean 1486.4358 (1481.7020) lr 1.2487e-03 eta 0:06:33
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,959
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,580
* accuracy: 78.6%
* error: 21.4%
* macro_f1: 76.6%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [24/50] batch [20/162] time 0.081 (0.106) data 0.000 (0.015) loss 1.3487 (1.1994) teacher_loss 0.3717 (0.3452) loss_zs_kd 0.0238 (0.0171) loss_oracle 0.4876 (0.3857) kd_loss 0.7213 (0.6527) acc 84.3750 (88.1250) gate/entropy 0.9796 (0.9797) gate/usage_max 0.5718 (0.5717) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1686 (0.1686) teacher/entropy 0.0527 (0.0365) teacher/usage_max 0.7811 (0.8674) teacher/usage_min 0.0743 (0.0340) teacher/usage_std 0.3179 (0.3788) nleep/row_max_mean 1514.4132 (1510.4930) nleep/row_max_std 50.2706 (50.5307) nleep/row_min_mean 1487.5771 (1483.1976) lr 1.1874e-03 eta 0:07:42
epoch [24/50] batch [40/162] time 0.093 (0.095) data 0.000 (0.008) loss 1.1273 (1.2155) teacher_loss 0.2516 (0.3572) loss_zs_kd 0.0207 (0.0181) loss_oracle 0.3518 (0.3890) kd_loss 0.6895 (0.6547) acc 96.8750 (87.3438) gate/entropy 0.9795 (0.9797) gate/usage_max 0.5719 (0.5717) gate/usage_min 0.2139 (0.2140) gate/usage_std 0.1687 (0.1686) teacher/entropy 0.0620 (0.0379) teacher/usage_max 0.8038 (0.8639) teacher/usage_min 0.0329 (0.0345) teacher/usage_std 0.3369 (0.3767) nleep/row_max_mean 1527.9779 (1511.2799) nleep/row_max_std 49.5526 (51.3854) nleep/row_min_mean 1500.7017 (1483.7076) lr 1.1874e-03 eta 0:06:51
epoch [24/50] batch [60/162] time 0.071 (0.093) data 0.001 (0.005) loss 1.4038 (1.2079) teacher_loss 0.6124 (0.3567) loss_zs_kd 0.0114 (0.0183) loss_oracle 0.3568 (0.3870) kd_loss 0.6073 (0.6485) acc 75.0000 (86.7188) gate/entropy 0.9795 (0.9796) gate/usage_max 0.5719 (0.5718) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1687 (0.1686) teacher/entropy 0.0129 (0.0335) teacher/usage_max 0.9374 (0.8747) teacher/usage_min 0.0042 (0.0323) teacher/usage_std 0.4277 (0.3840) nleep/row_max_mean 1504.5444 (1511.1759) nleep/row_max_std 61.2081 (52.8002) nleep/row_min_mean 1476.3480 (1483.1649) lr 1.1874e-03 eta 0:06:39
epoch [24/50] batch [80/162] time 0.087 (0.091) data 0.000 (0.004) loss 1.2891 (1.2139) teacher_loss 0.5228 (0.3656) loss_zs_kd 0.0097 (0.0178) loss_oracle 0.3088 (0.3870) kd_loss 0.6070 (0.6460) acc 81.2500 (86.3672) gate/entropy 0.9795 (0.9796) gate/usage_max 0.5719 (0.5718) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1687 (0.1686) teacher/entropy 0.0146 (0.0316) teacher/usage_max 0.9360 (0.8792) teacher/usage_min 0.0294 (0.0328) teacher/usage_std 0.4262 (0.3871) nleep/row_max_mean 1514.2678 (1511.3398) nleep/row_max_std 60.4736 (53.3759) nleep/row_min_mean 1484.8259 (1483.1707) lr 1.1874e-03 eta 0:06:28
epoch [24/50] batch [100/162] time 0.088 (0.090) data 0.000 (0.003) loss 1.2217 (1.2207) teacher_loss 0.3357 (0.3754) loss_zs_kd 0.0180 (0.0175) loss_oracle 0.4274 (0.3865) kd_loss 0.6633 (0.6434) acc 84.3750 (85.8125) gate/entropy 0.9795 (0.9796) gate/usage_max 0.5719 (0.5718) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1687 (0.1686) teacher/entropy 0.0182 (0.0302) teacher/usage_max 0.8749 (0.8833) teacher/usage_min 0.0336 (0.0312) teacher/usage_std 0.3837 (0.3899) nleep/row_max_mean 1505.8379 (1510.2871) nleep/row_max_std 60.7355 (54.9276) nleep/row_min_mean 1478.7689 (1482.2288) lr 1.1874e-03 eta 0:06:25
epoch [24/50] batch [120/162] time 0.089 (0.090) data 0.000 (0.003) loss 1.2068 (1.2143) teacher_loss 0.4161 (0.3700) loss_zs_kd 0.0129 (0.0170) loss_oracle 0.3740 (0.3870) kd_loss 0.5973 (0.6423) acc 87.5000 (86.3021) gate/entropy 0.9796 (0.9796) gate/usage_max 0.5718 (0.5718) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1686 (0.1686) teacher/entropy 0.0233 (0.0297) teacher/usage_max 0.9373 (0.8848) teacher/usage_min 0.0153 (0.0307) teacher/usage_std 0.4273 (0.3909) nleep/row_max_mean 1494.9766 (1509.7518) nleep/row_max_std 60.5243 (55.4160) nleep/row_min_mean 1468.4951 (1481.7486) lr 1.1874e-03 eta 0:06:21
epoch [24/50] batch [140/162] time 0.091 (0.090) data 0.000 (0.002) loss 1.1588 (1.2105) teacher_loss 0.3812 (0.3693) loss_zs_kd 0.0224 (0.0170) loss_oracle 0.2986 (0.3842) kd_loss 0.6170 (0.6406) acc 90.6250 (86.2500) gate/entropy 0.9795 (0.9796) gate/usage_max 0.5720 (0.5718) gate/usage_min 0.2139 (0.2140) gate/usage_std 0.1687 (0.1686) teacher/entropy 0.0218 (0.0290) teacher/usage_max 0.9185 (0.8872) teacher/usage_min 0.0190 (0.0299) teacher/usage_std 0.4141 (0.3927) nleep/row_max_mean 1512.5524 (1509.1497) nleep/row_max_std 53.8263 (55.9371) nleep/row_min_mean 1484.1178 (1481.2290) lr 1.1874e-03 eta 0:06:20
epoch [24/50] batch [160/162] time 0.090 (0.090) data 0.001 (0.002) loss 1.2356 (1.2124) teacher_loss 0.3669 (0.3687) loss_zs_kd 0.0123 (0.0170) loss_oracle 0.3734 (0.3844) kd_loss 0.6758 (0.6430) acc 87.5000 (86.1914) gate/entropy 0.9795 (0.9796) gate/usage_max 0.5719 (0.5718) gate/usage_min 0.2139 (0.2140) gate/usage_std 0.1687 (0.1686) teacher/entropy 0.0363 (0.0287) teacher/usage_max 0.8439 (0.8851) teacher/usage_min 0.0152 (0.0293) teacher/usage_std 0.3647 (0.3913) nleep/row_max_mean 1502.6212 (1508.8193) nleep/row_max_std 58.5869 (56.0194) nleep/row_min_mean 1477.4690 (1480.9627) lr 1.1874e-03 eta 0:06:20
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,959
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,614
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 77.2%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [25/50] batch [20/162] time 0.112 (0.110) data 0.000 (0.014) loss 1.2186 (1.2682) teacher_loss 0.3141 (0.4081) loss_zs_kd 0.0125 (0.0177) loss_oracle 0.4569 (0.4031) kd_loss 0.6698 (0.6497) acc 90.6250 (83.1250) gate/entropy 0.9795 (0.9794) gate/usage_max 0.5719 (0.5720) gate/usage_min 0.2139 (0.2139) gate/usage_std 0.1687 (0.1688) teacher/entropy 0.0597 (0.0351) teacher/usage_max 0.8262 (0.8716) teacher/usage_min 0.0519 (0.0284) teacher/usage_std 0.3497 (0.3820) nleep/row_max_mean 1495.9321 (1508.7446) nleep/row_max_std 48.1720 (52.7017) nleep/row_min_mean 1471.6862 (1482.0112) lr 1.1253e-03 eta 0:07:39
epoch [25/50] batch [40/162] time 0.090 (0.102) data 0.000 (0.007) loss 1.1199 (1.2302) teacher_loss 0.3416 (0.3666) loss_zs_kd 0.0145 (0.0181) loss_oracle 0.3263 (0.4021) kd_loss 0.6079 (0.6535) acc 87.5000 (85.3906) gate/entropy 0.9794 (0.9794) gate/usage_max 0.5720 (0.5720) gate/usage_min 0.2139 (0.2139) gate/usage_std 0.1687 (0.1688) teacher/entropy 0.0371 (0.0319) teacher/usage_max 0.9121 (0.8710) teacher/usage_min 0.0215 (0.0293) teacher/usage_std 0.4097 (0.3817) nleep/row_max_mean 1509.5906 (1510.1577) nleep/row_max_std 59.0560 (52.8150) nleep/row_min_mean 1483.1582 (1483.3339) lr 1.1253e-03 eta 0:07:07
epoch [25/50] batch [60/162] time 0.096 (0.100) data 0.001 (0.005) loss 1.0620 (1.2072) teacher_loss 0.3288 (0.3596) loss_zs_kd 0.0149 (0.0176) loss_oracle 0.3090 (0.3930) kd_loss 0.5712 (0.6423) acc 90.6250 (86.0938) gate/entropy 0.9794 (0.9794) gate/usage_max 0.5720 (0.5720) gate/usage_min 0.2139 (0.2139) gate/usage_std 0.1688 (0.1688) teacher/entropy 0.0313 (0.0293) teacher/usage_max 0.9552 (0.8850) teacher/usage_min 0.0002 (0.0241) teacher/usage_std 0.4401 (0.3916) nleep/row_max_mean 1502.3044 (1509.7169) nleep/row_max_std 55.2630 (52.7322) nleep/row_min_mean 1475.7283 (1483.3418) lr 1.1253e-03 eta 0:06:53
epoch [25/50] batch [80/162] time 0.090 (0.097) data 0.000 (0.004) loss 1.1224 (1.2026) teacher_loss 0.3165 (0.3579) loss_zs_kd 0.0137 (0.0179) loss_oracle 0.3559 (0.3865) kd_loss 0.6211 (0.6425) acc 90.6250 (86.2500) gate/entropy 0.9793 (0.9794) gate/usage_max 0.5721 (0.5720) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1688 (0.1688) teacher/entropy 0.0537 (0.0293) teacher/usage_max 0.8817 (0.8848) teacher/usage_min 0.0199 (0.0242) teacher/usage_std 0.3891 (0.3914) nleep/row_max_mean 1519.5771 (1509.3486) nleep/row_max_std 45.6676 (52.9484) nleep/row_min_mean 1492.7200 (1483.1115) lr 1.1253e-03 eta 0:06:38
epoch [25/50] batch [100/162] time 0.088 (0.096) data 0.000 (0.003) loss 1.0718 (1.2011) teacher_loss 0.2779 (0.3586) loss_zs_kd 0.0090 (0.0168) loss_oracle 0.2911 (0.3821) kd_loss 0.6438 (0.6431) acc 90.6250 (86.2188) gate/entropy 0.9793 (0.9794) gate/usage_max 0.5721 (0.5720) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1689 (0.1688) teacher/entropy 0.0088 (0.0295) teacher/usage_max 0.9041 (0.8839) teacher/usage_min 0.0000 (0.0244) teacher/usage_std 0.4055 (0.3909) nleep/row_max_mean 1518.5671 (1508.8244) nleep/row_max_std 56.9650 (53.5843) nleep/row_min_mean 1491.9288 (1482.7731) lr 1.1253e-03 eta 0:06:33
epoch [25/50] batch [120/162] time 0.085 (0.098) data 0.000 (0.003) loss 1.3115 (1.2017) teacher_loss 0.5174 (0.3576) loss_zs_kd 0.0098 (0.0169) loss_oracle 0.2935 (0.3808) kd_loss 0.6425 (0.6453) acc 75.0000 (85.9896) gate/entropy 0.9793 (0.9794) gate/usage_max 0.5722 (0.5720) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1689 (0.1688) teacher/entropy 0.0282 (0.0297) teacher/usage_max 0.8856 (0.8815) teacher/usage_min 0.0002 (0.0249) teacher/usage_std 0.3933 (0.3892) nleep/row_max_mean 1513.4401 (1508.9771) nleep/row_max_std 62.4886 (53.2317) nleep/row_min_mean 1488.0466 (1482.8811) lr 1.1253e-03 eta 0:06:41
epoch [25/50] batch [140/162] time 0.089 (0.098) data 0.000 (0.002) loss 1.0621 (1.2061) teacher_loss 0.1726 (0.3587) loss_zs_kd 0.0144 (0.0169) loss_oracle 0.4393 (0.3816) kd_loss 0.6626 (0.6481) acc 96.8750 (86.0938) gate/entropy 0.9793 (0.9794) gate/usage_max 0.5721 (0.5720) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1688 (0.1688) teacher/entropy 0.0276 (0.0285) teacher/usage_max 0.8661 (0.8798) teacher/usage_min 0.0077 (0.0234) teacher/usage_std 0.3798 (0.3882) nleep/row_max_mean 1499.6804 (1508.7924) nleep/row_max_std 56.6227 (53.3653) nleep/row_min_mean 1474.0664 (1482.7314) lr 1.1253e-03 eta 0:06:38
epoch [25/50] batch [160/162] time 0.088 (0.097) data 0.000 (0.002) loss 1.2775 (1.2094) teacher_loss 0.3823 (0.3595) loss_zs_kd 0.0090 (0.0173) loss_oracle 0.3329 (0.3819) kd_loss 0.7243 (0.6502) acc 78.1250 (86.0742) gate/entropy 0.9792 (0.9794) gate/usage_max 0.5722 (0.5721) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1689 (0.1688) teacher/entropy 0.0189 (0.0288) teacher/usage_max 0.8121 (0.8774) teacher/usage_min 0.0625 (0.0231) teacher/usage_std 0.3395 (0.3866) nleep/row_max_mean 1503.8274 (1509.0721) nleep/row_max_std 52.9565 (53.3033) nleep/row_min_mean 1481.4275 (1483.0776) lr 1.1253e-03 eta 0:06:32
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,960
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,543
* accuracy: 77.5%
* error: 22.5%
* macro_f1: 75.8%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [26/50] batch [20/162] time 0.105 (0.114) data 0.000 (0.016) loss 1.1906 (1.2415) teacher_loss 0.2916 (0.3495) loss_zs_kd 0.0221 (0.0180) loss_oracle 0.4274 (0.3930) kd_loss 0.6743 (0.6865) acc 93.7500 (85.7812) gate/entropy 0.9792 (0.9792) gate/usage_max 0.5722 (0.5722) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1689 (0.1689) teacher/entropy 0.0071 (0.0322) teacher/usage_max 0.8749 (0.8369) teacher/usage_min 0.0315 (0.0298) teacher/usage_std 0.3838 (0.3605) nleep/row_max_mean 1515.9410 (1512.1558) nleep/row_max_std 35.5964 (47.2561) nleep/row_min_mean 1488.1257 (1485.8888) lr 1.0628e-03 eta 0:07:38
epoch [26/50] batch [40/162] time 0.092 (0.105) data 0.000 (0.008) loss 1.2205 (1.2483) teacher_loss 0.2772 (0.3694) loss_zs_kd 0.0209 (0.0172) loss_oracle 0.4196 (0.3877) kd_loss 0.7231 (0.6765) acc 87.5000 (85.4688) gate/entropy 0.9792 (0.9792) gate/usage_max 0.5722 (0.5722) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1689 (0.1689) teacher/entropy 0.0193 (0.0268) teacher/usage_max 0.8129 (0.8526) teacher/usage_min 0.0579 (0.0225) teacher/usage_std 0.3404 (0.3712) nleep/row_max_mean 1499.9753 (1511.8334) nleep/row_max_std 48.5437 (49.5822) nleep/row_min_mean 1474.4408 (1485.8250) lr 1.0628e-03 eta 0:07:00
epoch [26/50] batch [60/162] time 0.091 (0.100) data 0.001 (0.006) loss 1.0743 (1.2391) teacher_loss 0.1937 (0.3610) loss_zs_kd 0.0206 (0.0184) loss_oracle 0.3876 (0.3879) kd_loss 0.6765 (0.6749) acc 90.6250 (85.6250) gate/entropy 0.9792 (0.9792) gate/usage_max 0.5723 (0.5722) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1689 (0.1689) teacher/entropy 0.0044 (0.0266) teacher/usage_max 0.8751 (0.8543) teacher/usage_min 0.0619 (0.0211) teacher/usage_std 0.3831 (0.3724) nleep/row_max_mean 1501.3650 (1510.5167) nleep/row_max_std 58.2298 (51.3861) nleep/row_min_mean 1474.9390 (1484.5069) lr 1.0628e-03 eta 0:06:38
epoch [26/50] batch [80/162] time 0.084 (0.097) data 0.000 (0.004) loss 1.1261 (1.2436) teacher_loss 0.3585 (0.3692) loss_zs_kd 0.0106 (0.0190) loss_oracle 0.4069 (0.3886) kd_loss 0.5588 (0.6705) acc 81.2500 (85.4297) gate/entropy 0.9791 (0.9792) gate/usage_max 0.5723 (0.5722) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1690 (0.1689) teacher/entropy 0.0543 (0.0256) teacher/usage_max 0.9439 (0.8598) teacher/usage_min 0.0001 (0.0200) teacher/usage_std 0.4324 (0.3760) nleep/row_max_mean 1520.5681 (1510.2344) nleep/row_max_std 51.9972 (52.2232) nleep/row_min_mean 1493.2988 (1484.0085) lr 1.0628e-03 eta 0:06:26
epoch [26/50] batch [100/162] time 0.089 (0.096) data 0.000 (0.004) loss 1.0888 (1.2331) teacher_loss 0.2250 (0.3658) loss_zs_kd 0.0269 (0.0191) loss_oracle 0.4341 (0.3872) kd_loss 0.6333 (0.6641) acc 93.7500 (85.6875) gate/entropy 0.9791 (0.9792) gate/usage_max 0.5723 (0.5722) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1690 (0.1689) teacher/entropy 0.0339 (0.0242) teacher/usage_max 0.8891 (0.8677) teacher/usage_min 0.0486 (0.0190) teacher/usage_std 0.3931 (0.3811) nleep/row_max_mean 1502.2732 (1511.5225) nleep/row_max_std 56.2274 (52.2844) nleep/row_min_mean 1473.9487 (1484.8991) lr 1.0628e-03 eta 0:06:19
epoch [26/50] batch [120/162] time 0.090 (0.095) data 0.000 (0.003) loss 1.1958 (1.2281) teacher_loss 0.3870 (0.3648) loss_zs_kd 0.0121 (0.0190) loss_oracle 0.3057 (0.3852) kd_loss 0.6500 (0.6613) acc 84.3750 (85.6250) gate/entropy 0.9790 (0.9792) gate/usage_max 0.5724 (0.5722) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1690 (0.1689) teacher/entropy 0.0002 (0.0229) teacher/usage_max 0.9062 (0.8720) teacher/usage_min 0.0000 (0.0186) teacher/usage_std 0.4069 (0.3840) nleep/row_max_mean 1526.8115 (1511.3278) nleep/row_max_std 51.0503 (52.7808) nleep/row_min_mean 1496.8772 (1484.4565) lr 1.0628e-03 eta 0:06:13
epoch [26/50] batch [140/162] time 0.100 (0.095) data 0.000 (0.003) loss 1.0986 (1.2195) teacher_loss 0.2339 (0.3573) loss_zs_kd 0.0245 (0.0186) loss_oracle 0.3821 (0.3835) kd_loss 0.6614 (0.6612) acc 93.7500 (85.8705) gate/entropy 0.9791 (0.9792) gate/usage_max 0.5723 (0.5722) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1690 (0.1689) teacher/entropy 0.0326 (0.0213) teacher/usage_max 0.8619 (0.8736) teacher/usage_min 0.0001 (0.0169) teacher/usage_std 0.3780 (0.3851) nleep/row_max_mean 1523.7544 (1511.1270) nleep/row_max_std 45.1842 (52.8387) nleep/row_min_mean 1494.4576 (1484.1524) lr 1.0628e-03 eta 0:06:10
epoch [26/50] batch [160/162] time 0.086 (0.094) data 0.000 (0.002) loss 1.2381 (1.2143) teacher_loss 0.4530 (0.3571) loss_zs_kd 0.0091 (0.0186) loss_oracle 0.3453 (0.3815) kd_loss 0.6079 (0.6571) acc 84.3750 (85.8398) gate/entropy 0.9791 (0.9792) gate/usage_max 0.5724 (0.5723) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1690 (0.1689) teacher/entropy 0.0217 (0.0212) teacher/usage_max 0.9272 (0.8778) teacher/usage_min 0.0002 (0.0166) teacher/usage_std 0.4210 (0.3879) nleep/row_max_mean 1492.0110 (1510.6617) nleep/row_max_std 68.0351 (53.4708) nleep/row_min_mean 1466.0854 (1483.6966) lr 1.0628e-03 eta 0:06:06
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,609
* accuracy: 79.5%
* error: 20.5%
* macro_f1: 77.1%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [27/50] batch [20/162] time 0.143 (0.131) data 0.000 (0.018) loss 1.2533 (1.2040) teacher_loss 0.4176 (0.3508) loss_zs_kd 0.0164 (0.0187) loss_oracle 0.3662 (0.3892) kd_loss 0.6444 (0.6492) acc 75.0000 (85.3125) gate/entropy 0.9791 (0.9791) gate/usage_max 0.5723 (0.5723) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0078 (0.0207) teacher/usage_max 0.9043 (0.8862) teacher/usage_min 0.0019 (0.0163) teacher/usage_std 0.4055 (0.3934) nleep/row_max_mean 1496.2738 (1505.9575) nleep/row_max_std 56.5524 (57.3104) nleep/row_min_mean 1470.4231 (1479.1446) lr 1.0000e-03 eta 0:08:26
epoch [27/50] batch [40/162] time 0.082 (0.110) data 0.000 (0.009) loss 1.1281 (1.2197) teacher_loss 0.2626 (0.3718) loss_zs_kd 0.0063 (0.0185) loss_oracle 0.3894 (0.3848) kd_loss 0.6676 (0.6463) acc 90.6250 (85.6250) gate/entropy 0.9792 (0.9791) gate/usage_max 0.5722 (0.5724) gate/usage_min 0.2138 (0.2137) gate/usage_std 0.1689 (0.1690) teacher/entropy 0.0165 (0.0209) teacher/usage_max 0.8720 (0.8891) teacher/usage_min 0.0315 (0.0176) teacher/usage_std 0.3818 (0.3950) nleep/row_max_mean 1505.1201 (1503.5921) nleep/row_max_std 47.9297 (59.7299) nleep/row_min_mean 1478.7571 (1477.3138) lr 1.0000e-03 eta 0:07:03
epoch [27/50] batch [60/162] time 0.095 (0.104) data 0.000 (0.006) loss 1.0772 (1.2166) teacher_loss 0.2557 (0.3681) loss_zs_kd 0.0123 (0.0192) loss_oracle 0.3331 (0.3821) kd_loss 0.6488 (0.6478) acc 87.5000 (85.6771) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0016 (0.0211) teacher/usage_max 0.9060 (0.8873) teacher/usage_min 0.0003 (0.0164) teacher/usage_std 0.4067 (0.3940) nleep/row_max_mean 1496.0106 (1501.8470) nleep/row_max_std 62.3356 (60.1516) nleep/row_min_mean 1469.5066 (1475.8292) lr 1.0000e-03 eta 0:06:38
epoch [27/50] batch [80/162] time 0.084 (0.101) data 0.000 (0.005) loss 1.3372 (1.2118) teacher_loss 0.5100 (0.3668) loss_zs_kd 0.0192 (0.0187) loss_oracle 0.3578 (0.3796) kd_loss 0.6388 (0.6459) acc 81.2500 (85.8203) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0122 (0.0205) teacher/usage_max 0.9053 (0.8899) teacher/usage_min 0.0335 (0.0161) teacher/usage_std 0.4046 (0.3957) nleep/row_max_mean 1498.8677 (1502.1236) nleep/row_max_std 56.9325 (59.8862) nleep/row_min_mean 1471.6335 (1476.0715) lr 1.0000e-03 eta 0:06:25
epoch [27/50] batch [100/162] time 0.090 (0.099) data 0.000 (0.004) loss 1.2250 (1.1989) teacher_loss 0.2541 (0.3543) loss_zs_kd 0.0089 (0.0180) loss_oracle 0.4550 (0.3795) kd_loss 0.7390 (0.6458) acc 90.6250 (86.5000) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0474 (0.0205) teacher/usage_max 0.7680 (0.8899) teacher/usage_min 0.0228 (0.0153) teacher/usage_std 0.3166 (0.3958) nleep/row_max_mean 1502.9783 (1503.1198) nleep/row_max_std 54.5909 (59.3492) nleep/row_min_mean 1474.8278 (1476.8321) lr 1.0000e-03 eta 0:06:15
epoch [27/50] batch [120/162] time 0.100 (0.098) data 0.001 (0.003) loss 1.3024 (1.1969) teacher_loss 0.4056 (0.3487) loss_zs_kd 0.0180 (0.0175) loss_oracle 0.4403 (0.3805) kd_loss 0.6677 (0.6492) acc 90.6250 (86.7708) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0202 (0.0205) teacher/usage_max 0.8680 (0.8864) teacher/usage_min 0.0060 (0.0162) teacher/usage_std 0.3812 (0.3933) nleep/row_max_mean 1496.4700 (1503.4877) nleep/row_max_std 53.4876 (58.9890) nleep/row_min_mean 1472.5724 (1477.0481) lr 1.0000e-03 eta 0:06:10
epoch [27/50] batch [140/162] time 0.089 (0.097) data 0.000 (0.003) loss 1.1530 (1.2044) teacher_loss 0.3202 (0.3536) loss_zs_kd 0.0044 (0.0175) loss_oracle 0.3720 (0.3820) kd_loss 0.6446 (0.6511) acc 87.5000 (86.3616) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0068 (0.0197) teacher/usage_max 0.9050 (0.8853) teacher/usage_min 0.0000 (0.0159) teacher/usage_std 0.4061 (0.3926) nleep/row_max_mean 1509.0920 (1504.3535) nleep/row_max_std 53.1003 (58.5335) nleep/row_min_mean 1483.1545 (1477.7872) lr 1.0000e-03 eta 0:06:03
epoch [27/50] batch [160/162] time 0.090 (0.096) data 0.000 (0.002) loss 1.0398 (1.2039) teacher_loss 0.2103 (0.3513) loss_zs_kd 0.0061 (0.0172) loss_oracle 0.3541 (0.3823) kd_loss 0.6493 (0.6528) acc 90.6250 (86.3672) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0007 (0.0192) teacher/usage_max 0.9062 (0.8840) teacher/usage_min 0.0001 (0.0154) teacher/usage_std 0.4069 (0.3918) nleep/row_max_mean 1511.0964 (1505.0104) nleep/row_max_std 59.4639 (57.8326) nleep/row_min_mean 1483.9011 (1478.4262) lr 1.0000e-03 eta 0:05:57
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,964
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,604
* accuracy: 79.3%
* error: 20.7%
* macro_f1: 77.0%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [28/50] batch [20/162] time 0.096 (0.110) data 0.000 (0.017) loss 1.1696 (1.2346) teacher_loss 0.3735 (0.3763) loss_zs_kd 0.0321 (0.0184) loss_oracle 0.3449 (0.3764) kd_loss 0.6076 (0.6609) acc 78.1250 (85.6250) gate/entropy 0.9790 (0.9789) gate/usage_max 0.5724 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1691) teacher/entropy 0.0097 (0.0196) teacher/usage_max 0.9396 (0.8754) teacher/usage_min 0.0002 (0.0182) teacher/usage_std 0.4294 (0.3855) nleep/row_max_mean 1507.0510 (1508.5497) nleep/row_max_std 54.5664 (51.6080) nleep/row_min_mean 1479.9387 (1481.5130) lr 9.3721e-04 eta 0:06:46
epoch [28/50] batch [40/162] time 0.093 (0.099) data 0.000 (0.009) loss 1.3276 (1.2584) teacher_loss 0.4975 (0.4008) loss_zs_kd 0.0196 (0.0173) loss_oracle 0.3674 (0.3783) kd_loss 0.6365 (0.6598) acc 84.3750 (84.1406) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5726 (0.5725) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0120 (0.0213) teacher/usage_max 0.9077 (0.8747) teacher/usage_min 0.0003 (0.0194) teacher/usage_std 0.4079 (0.3850) nleep/row_max_mean 1505.2971 (1507.4669) nleep/row_max_std 63.9977 (53.6728) nleep/row_min_mean 1478.9362 (1480.9497) lr 9.3721e-04 eta 0:06:05
epoch [28/50] batch [60/162] time 0.096 (0.097) data 0.000 (0.006) loss 1.2038 (1.2484) teacher_loss 0.3539 (0.3875) loss_zs_kd 0.0095 (0.0172) loss_oracle 0.3653 (0.3817) kd_loss 0.6625 (0.6614) acc 81.2500 (85.0000) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5726 (0.5725) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0173 (0.0192) teacher/usage_max 0.8759 (0.8752) teacher/usage_min 0.0598 (0.0182) teacher/usage_std 0.3836 (0.3855) nleep/row_max_mean 1521.9863 (1507.5787) nleep/row_max_std 52.8685 (53.8541) nleep/row_min_mean 1495.2466 (1481.0127) lr 9.3721e-04 eta 0:05:55
epoch [28/50] batch [80/162] time 0.096 (0.096) data 0.000 (0.004) loss 1.1449 (1.2368) teacher_loss 0.2584 (0.3782) loss_zs_kd 0.0119 (0.0179) loss_oracle 0.4236 (0.3842) kd_loss 0.6688 (0.6575) acc 84.3750 (85.2734) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5726 (0.5725) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0094 (0.0196) teacher/usage_max 0.8775 (0.8787) teacher/usage_min 0.0287 (0.0184) teacher/usage_std 0.3857 (0.3878) nleep/row_max_mean 1510.0449 (1507.6691) nleep/row_max_std 56.1119 (53.4976) nleep/row_min_mean 1482.6229 (1480.9374) lr 9.3721e-04 eta 0:05:51
epoch [28/50] batch [100/162] time 0.096 (0.097) data 0.000 (0.004) loss 1.2746 (1.2105) teacher_loss 0.4691 (0.3605) loss_zs_kd 0.0176 (0.0179) loss_oracle 0.2950 (0.3787) kd_loss 0.6493 (0.6516) acc 84.3750 (86.0000) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5726 (0.5725) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0008 (0.0180) teacher/usage_max 0.9062 (0.8863) teacher/usage_min 0.0001 (0.0173) teacher/usage_std 0.4068 (0.3929) nleep/row_max_mean 1506.7197 (1508.7273) nleep/row_max_std 55.5610 (52.9908) nleep/row_min_mean 1481.4504 (1481.8614) lr 9.3721e-04 eta 0:05:50
epoch [28/50] batch [120/162] time 0.096 (0.097) data 0.000 (0.003) loss 1.4958 (1.2088) teacher_loss 0.6734 (0.3572) loss_zs_kd 0.0169 (0.0172) loss_oracle 0.3597 (0.3782) kd_loss 0.6341 (0.6539) acc 78.1250 (86.2760) gate/entropy 0.9789 (0.9789) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0370 (0.0184) teacher/usage_max 0.8849 (0.8836) teacher/usage_min 0.0038 (0.0170) teacher/usage_std 0.3925 (0.3911) nleep/row_max_mean 1487.3915 (1508.9706) nleep/row_max_std 60.2059 (52.9093) nleep/row_min_mean 1463.7876 (1482.1371) lr 9.3721e-04 eta 0:05:49
epoch [28/50] batch [140/162] time 0.133 (0.098) data 0.000 (0.003) loss 1.5953 (1.2144) teacher_loss 0.7580 (0.3613) loss_zs_kd 0.0143 (0.0172) loss_oracle 0.3309 (0.3770) kd_loss 0.6646 (0.6560) acc 71.8750 (86.3839) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0157 (0.0186) teacher/usage_max 0.8752 (0.8812) teacher/usage_min 0.0570 (0.0173) teacher/usage_std 0.3831 (0.3896) nleep/row_max_mean 1489.4607 (1508.3009) nleep/row_max_std 63.7982 (53.0509) nleep/row_min_mean 1465.1377 (1481.7789) lr 9.3721e-04 eta 0:05:52
epoch [28/50] batch [160/162] time 0.087 (0.098) data 0.000 (0.002) loss 1.4087 (1.2130) teacher_loss 0.3846 (0.3573) loss_zs_kd 0.0072 (0.0170) loss_oracle 0.3897 (0.3772) kd_loss 0.8256 (0.6585) acc 90.6250 (86.5234) gate/entropy 0.9787 (0.9789) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0106 (0.0194) teacher/usage_max 0.7171 (0.8779) teacher/usage_min 0.0023 (0.0190) teacher/usage_std 0.2942 (0.3873) nleep/row_max_mean 1511.2981 (1508.2508) nleep/row_max_std 58.2678 (52.9751) nleep/row_min_mean 1485.9336 (1481.8885) lr 9.3721e-04 eta 0:05:49
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,965
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 89.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,553
* accuracy: 77.8%
* error: 22.2%
* macro_f1: 75.7%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [29/50] batch [20/162] time 0.090 (0.106) data 0.000 (0.014) loss 1.4113 (1.1983) teacher_loss 0.5070 (0.3445) loss_zs_kd 0.0118 (0.0158) loss_oracle 0.3350 (0.3751) kd_loss 0.7309 (0.6583) acc 84.3750 (86.2500) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0141 (0.0254) teacher/usage_max 0.8097 (0.8719) teacher/usage_min 0.0311 (0.0265) teacher/usage_std 0.3409 (0.3826) nleep/row_max_mean 1489.0447 (1506.4581) nleep/row_max_std 62.7899 (56.1925) nleep/row_min_mean 1464.8727 (1481.6701) lr 8.7467e-04 eta 0:06:15
epoch [29/50] batch [40/162] time 0.096 (0.100) data 0.000 (0.007) loss 1.3164 (1.2226) teacher_loss 0.5510 (0.3559) loss_zs_kd 0.0103 (0.0178) loss_oracle 0.2944 (0.3782) kd_loss 0.6131 (0.6686) acc 68.7500 (85.9375) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0073 (0.0236) teacher/usage_max 0.9361 (0.8632) teacher/usage_min 0.0012 (0.0233) teacher/usage_std 0.4270 (0.3770) nleep/row_max_mean 1506.0891 (1505.8914) nleep/row_max_std 66.8165 (55.7255) nleep/row_min_mean 1481.7784 (1480.9024) lr 8.7467e-04 eta 0:05:53
epoch [29/50] batch [60/162] time 0.091 (0.099) data 0.000 (0.005) loss 1.1683 (1.2202) teacher_loss 0.2303 (0.3494) loss_zs_kd 0.0267 (0.0182) loss_oracle 0.4726 (0.3817) kd_loss 0.6884 (0.6709) acc 87.5000 (86.0938) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0391 (0.0243) teacher/usage_max 0.8274 (0.8603) teacher/usage_min 0.0355 (0.0256) teacher/usage_std 0.3518 (0.3750) nleep/row_max_mean 1512.2765 (1506.4551) nleep/row_max_std 62.3371 (54.8775) nleep/row_min_mean 1485.9473 (1481.3914) lr 8.7467e-04 eta 0:05:45
epoch [29/50] batch [80/162] time 0.091 (0.097) data 0.000 (0.004) loss 1.1624 (1.2233) teacher_loss 0.2715 (0.3456) loss_zs_kd 0.0045 (0.0176) loss_oracle 0.4074 (0.3883) kd_loss 0.6849 (0.6747) acc 87.5000 (86.5625) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0313 (0.0245) teacher/usage_max 0.8389 (0.8561) teacher/usage_min 0.0359 (0.0286) teacher/usage_std 0.3593 (0.3721) nleep/row_max_mean 1504.1567 (1507.1647) nleep/row_max_std 48.1653 (54.2550) nleep/row_min_mean 1477.9999 (1481.9548) lr 8.7467e-04 eta 0:05:39
epoch [29/50] batch [100/162] time 0.103 (0.097) data 0.000 (0.003) loss 1.0899 (1.2146) teacher_loss 0.2744 (0.3461) loss_zs_kd 0.0152 (0.0180) loss_oracle 0.3243 (0.3862) kd_loss 0.6458 (0.6664) acc 93.7500 (86.8125) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0048 (0.0242) teacher/usage_max 0.9055 (0.8648) teacher/usage_min 0.0320 (0.0281) teacher/usage_std 0.4048 (0.3780) nleep/row_max_mean 1516.5483 (1507.6982) nleep/row_max_std 58.8752 (54.6720) nleep/row_min_mean 1488.0135 (1482.3038) lr 8.7467e-04 eta 0:05:36
epoch [29/50] batch [120/162] time 0.099 (0.097) data 0.000 (0.003) loss 1.3284 (1.2215) teacher_loss 0.5118 (0.3547) loss_zs_kd 0.0203 (0.0179) loss_oracle 0.3934 (0.3886) kd_loss 0.6098 (0.6635) acc 78.1250 (86.7188) gate/entropy 0.9788 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0119 (0.0244) teacher/usage_max 0.9350 (0.8676) teacher/usage_min 0.0017 (0.0269) teacher/usage_std 0.4262 (0.3799) nleep/row_max_mean 1511.4143 (1507.3125) nleep/row_max_std 44.0942 (55.0959) nleep/row_min_mean 1484.7794 (1482.0142) lr 8.7467e-04 eta 0:05:33
epoch [29/50] batch [140/162] time 0.097 (0.097) data 0.000 (0.002) loss 1.1370 (1.2208) teacher_loss 0.2667 (0.3560) loss_zs_kd 0.0246 (0.0180) loss_oracle 0.3998 (0.3893) kd_loss 0.6581 (0.6611) acc 93.7500 (86.7188) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5728 (0.5727) gate/usage_min 0.2135 (0.2136) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0586 (0.0253) teacher/usage_max 0.8383 (0.8691) teacher/usage_min 0.0451 (0.0267) teacher/usage_std 0.3582 (0.3809) nleep/row_max_mean 1502.0503 (1507.6885) nleep/row_max_std 70.7403 (55.1059) nleep/row_min_mean 1477.2800 (1482.3673) lr 8.7467e-04 eta 0:05:33
epoch [29/50] batch [160/162] time 0.086 (0.097) data 0.000 (0.002) loss 1.3071 (1.2194) teacher_loss 0.4915 (0.3524) loss_zs_kd 0.0132 (0.0178) loss_oracle 0.4004 (0.3902) kd_loss 0.6088 (0.6630) acc 81.2500 (86.7773) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5729 (0.5727) gate/usage_min 0.2135 (0.2136) gate/usage_std 0.1694 (0.1692) teacher/entropy 0.0126 (0.0264) teacher/usage_max 0.9349 (0.8661) teacher/usage_min 0.0032 (0.0270) teacher/usage_std 0.4261 (0.3789) nleep/row_max_mean 1509.3569 (1507.2178) nleep/row_max_std 58.5136 (55.1508) nleep/row_min_mean 1484.7566 (1482.0832) lr 8.7467e-04 eta 0:05:29
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,610
* accuracy: 79.5%
* error: 20.5%
* macro_f1: 76.9%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [30/50] batch [20/162] time 0.100 (0.121) data 0.001 (0.019) loss 1.0733 (1.2184) teacher_loss 0.2111 (0.3576) loss_zs_kd 0.0140 (0.0153) loss_oracle 0.4117 (0.3909) kd_loss 0.6493 (0.6577) acc 90.6250 (85.7812) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5727 (0.5728) gate/usage_min 0.2136 (0.2135) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0006 (0.0220) teacher/usage_max 0.9062 (0.8758) teacher/usage_min 0.0001 (0.0254) teacher/usage_std 0.4069 (0.3854) nleep/row_max_mean 1503.2727 (1507.9464) nleep/row_max_std 49.0299 (55.1382) nleep/row_min_mean 1474.0017 (1482.0430) lr 8.1262e-04 eta 0:06:47
epoch [30/50] batch [40/162] time 0.179 (0.116) data 0.001 (0.010) loss 0.9792 (1.2016) teacher_loss 0.1415 (0.3288) loss_zs_kd 0.0206 (0.0159) loss_oracle 0.3775 (0.3941) kd_loss 0.6386 (0.6679) acc 96.8750 (87.2656) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0414 (0.0303) teacher/usage_max 0.8754 (0.8571) teacher/usage_min 0.0475 (0.0368) teacher/usage_std 0.3835 (0.3720) nleep/row_max_mean 1505.2513 (1505.0043) nleep/row_max_std 57.0340 (56.9045) nleep/row_min_mean 1479.1177 (1479.4934) lr 8.1262e-04 eta 0:06:28
epoch [30/50] batch [60/162] time 0.091 (0.111) data 0.000 (0.007) loss 1.2414 (1.2135) teacher_loss 0.3465 (0.3399) loss_zs_kd 0.0262 (0.0164) loss_oracle 0.3874 (0.3998) kd_loss 0.6882 (0.6655) acc 81.2500 (87.0833) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1693) teacher/entropy 0.0228 (0.0295) teacher/usage_max 0.8438 (0.8602) teacher/usage_min 0.0690 (0.0364) teacher/usage_std 0.3611 (0.3742) nleep/row_max_mean 1507.8203 (1504.7320) nleep/row_max_std 49.4346 (57.0372) nleep/row_min_mean 1481.5413 (1479.3081) lr 8.1262e-04 eta 0:06:11
epoch [30/50] batch [80/162] time 0.091 (0.108) data 0.000 (0.005) loss 1.4701 (1.2234) teacher_loss 0.5998 (0.3553) loss_zs_kd 0.0287 (0.0164) loss_oracle 0.4023 (0.3953) kd_loss 0.6548 (0.6622) acc 75.0000 (86.6797) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0457 (0.0311) teacher/usage_max 0.8546 (0.8620) teacher/usage_min 0.0233 (0.0368) teacher/usage_std 0.3708 (0.3753) nleep/row_max_mean 1510.1589 (1504.9513) nleep/row_max_std 60.2450 (57.2889) nleep/row_min_mean 1483.6703 (1479.5946) lr 8.1262e-04 eta 0:05:58
epoch [30/50] batch [100/162] time 0.094 (0.105) data 0.000 (0.004) loss 1.1591 (1.2176) teacher_loss 0.1900 (0.3435) loss_zs_kd 0.0160 (0.0170) loss_oracle 0.3985 (0.3968) kd_loss 0.7619 (0.6672) acc 93.7500 (87.0938) gate/entropy 0.9787 (0.9786) gate/usage_max 0.5727 (0.5728) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0094 (0.0323) teacher/usage_max 0.7829 (0.8557) teacher/usage_min 0.0624 (0.0388) teacher/usage_std 0.3201 (0.3710) nleep/row_max_mean 1509.6006 (1504.8101) nleep/row_max_std 54.0953 (57.4763) nleep/row_min_mean 1483.6431 (1479.4882) lr 8.1262e-04 eta 0:05:48
epoch [30/50] batch [120/162] time 0.092 (0.103) data 0.000 (0.003) loss 1.1342 (1.2082) teacher_loss 0.2980 (0.3396) loss_zs_kd 0.0189 (0.0173) loss_oracle 0.3346 (0.3931) kd_loss 0.6594 (0.6634) acc 84.3750 (87.1354) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1693) teacher/entropy 0.0267 (0.0339) teacher/usage_max 0.8690 (0.8579) teacher/usage_min 0.0629 (0.0397) teacher/usage_std 0.3788 (0.3724) nleep/row_max_mean 1507.4855 (1504.2846) nleep/row_max_std 59.4852 (57.7438) nleep/row_min_mean 1484.4990 (1479.0477) lr 8.1262e-04 eta 0:05:39
epoch [30/50] batch [140/162] time 0.097 (0.102) data 0.000 (0.003) loss 1.2734 (1.2117) teacher_loss 0.3780 (0.3474) loss_zs_kd 0.0161 (0.0176) loss_oracle 0.4037 (0.3902) kd_loss 0.6855 (0.6605) acc 84.3750 (86.8527) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0442 (0.0351) teacher/usage_max 0.8250 (0.8596) teacher/usage_min 0.0559 (0.0395) teacher/usage_std 0.3486 (0.3735) nleep/row_max_mean 1485.1870 (1503.8153) nleep/row_max_std 61.5843 (58.0005) nleep/row_min_mean 1461.4214 (1478.6687) lr 8.1262e-04 eta 0:05:34
epoch [30/50] batch [160/162] time 0.089 (0.101) data 0.000 (0.003) loss 1.0350 (1.2141) teacher_loss 0.3167 (0.3492) loss_zs_kd 0.0085 (0.0173) loss_oracle 0.3097 (0.3874) kd_loss 0.5592 (0.6626) acc 84.3750 (86.6992) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1693) teacher/entropy 0.0477 (0.0353) teacher/usage_max 0.9495 (0.8573) teacher/usage_min 0.0197 (0.0400) teacher/usage_std 0.4357 (0.3720) nleep/row_max_mean 1518.4724 (1503.5370) nleep/row_max_std 45.5593 (58.0284) nleep/row_min_mean 1494.4954 (1478.5440) lr 8.1262e-04 eta 0:05:27
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,963
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,525
* accuracy: 76.9%
* error: 23.1%
* macro_f1: 75.8%
******* Domain s best val acc:      88.0%, epoch: 17 *******
******* Domain s best val test acc: 79.3%, epoch: 17 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [31/50] batch [20/162] time 0.092 (0.112) data 0.000 (0.016) loss 1.3874 (1.2449) teacher_loss 0.5555 (0.3877) loss_zs_kd 0.0092 (0.0156) loss_oracle 0.3569 (0.3817) kd_loss 0.6488 (0.6586) acc 84.3750 (86.4062) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0342 (0.0432) teacher/usage_max 0.8722 (0.8533) teacher/usage_min 0.0459 (0.0402) teacher/usage_std 0.3814 (0.3696) nleep/row_max_mean 1492.7028 (1496.6087) nleep/row_max_std 59.5960 (59.8686) nleep/row_min_mean 1467.5312 (1472.9947) lr 7.5131e-04 eta 0:06:00
epoch [31/50] batch [40/162] time 0.086 (0.103) data 0.000 (0.008) loss 1.1076 (1.2060) teacher_loss 0.1790 (0.3482) loss_zs_kd 0.0218 (0.0175) loss_oracle 0.3608 (0.3837) kd_loss 0.7373 (0.6573) acc 96.8750 (87.9688) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0328 (0.0510) teacher/usage_max 0.7841 (0.8466) teacher/usage_min 0.0623 (0.0431) teacher/usage_std 0.3209 (0.3647) nleep/row_max_mean 1510.5872 (1499.2955) nleep/row_max_std 50.8940 (58.2060) nleep/row_min_mean 1486.5681 (1475.8935) lr 7.5131e-04 eta 0:05:31
epoch [31/50] batch [60/162] time 0.094 (0.100) data 0.001 (0.005) loss 0.9796 (1.2044) teacher_loss 0.0868 (0.3454) loss_zs_kd 0.0092 (0.0171) loss_oracle 0.3696 (0.3826) kd_loss 0.7034 (0.6591) acc 96.8750 (87.4479) gate/entropy 0.9787 (0.9786) gate/usage_max 0.5727 (0.5729) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0409 (0.0536) teacher/usage_max 0.8103 (0.8422) teacher/usage_min 0.0560 (0.0449) teacher/usage_std 0.3388 (0.3616) nleep/row_max_mean 1504.2904 (1499.7004) nleep/row_max_std 47.7437 (58.2059) nleep/row_min_mean 1479.4883 (1476.3196) lr 7.5131e-04 eta 0:05:18
epoch [31/50] batch [80/162] time 0.093 (0.099) data 0.000 (0.004) loss 1.1194 (1.2047) teacher_loss 0.2651 (0.3496) loss_zs_kd 0.0372 (0.0174) loss_oracle 0.3497 (0.3804) kd_loss 0.6608 (0.6562) acc 87.5000 (86.9531) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0219 (0.0531) teacher/usage_max 0.8724 (0.8457) teacher/usage_min 0.0353 (0.0447) teacher/usage_std 0.3819 (0.3639) nleep/row_max_mean 1505.2080 (1500.3385) nleep/row_max_std 55.4798 (58.1405) nleep/row_min_mean 1481.0642 (1477.0689) lr 7.5131e-04 eta 0:05:11
epoch [31/50] batch [100/162] time 0.079 (0.097) data 0.000 (0.003) loss 1.0949 (1.2101) teacher_loss 0.2696 (0.3485) loss_zs_kd 0.0103 (0.0176) loss_oracle 0.3579 (0.3792) kd_loss 0.6412 (0.6632) acc 84.3750 (86.9375) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0396 (0.0517) teacher/usage_max 0.8746 (0.8399) teacher/usage_min 0.0004 (0.0459) teacher/usage_std 0.3861 (0.3599) nleep/row_max_mean 1514.3398 (1499.6381) nleep/row_max_std 58.6835 (58.8498) nleep/row_min_mean 1491.8630 (1476.5975) lr 7.5131e-04 eta 0:05:03
epoch [31/50] batch [120/162] time 0.080 (0.094) data 0.000 (0.003) loss 0.9535 (1.2057) teacher_loss 0.2345 (0.3507) loss_zs_kd 0.0130 (0.0175) loss_oracle 0.3302 (0.3759) kd_loss 0.5474 (0.6583) acc 93.7500 (86.9271) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0851 (0.0509) teacher/usage_max 0.9235 (0.8457) teacher/usage_min 0.0313 (0.0439) teacher/usage_std 0.4174 (0.3639) nleep/row_max_mean 1492.9528 (1500.2693) nleep/row_max_std 65.9730 (59.3023) nleep/row_min_mean 1471.9130 (1477.2343) lr 7.5131e-04 eta 0:04:52
epoch [31/50] batch [140/162] time 0.097 (0.092) data 0.000 (0.002) loss 1.4296 (1.2093) teacher_loss 0.3931 (0.3492) loss_zs_kd 0.0251 (0.0176) loss_oracle 0.4507 (0.3780) kd_loss 0.7985 (0.6623) acc 84.3750 (87.1205) gate/entropy 0.9787 (0.9786) gate/usage_max 0.5727 (0.5729) gate/usage_min 0.2136 (0.2135) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0379 (0.0492) teacher/usage_max 0.7169 (0.8434) teacher/usage_min 0.0973 (0.0450) teacher/usage_std 0.2736 (0.3623) nleep/row_max_mean 1481.2866 (1499.4405) nleep/row_max_std 62.9203 (59.9094) nleep/row_min_mean 1458.8274 (1476.5661) lr 7.5131e-04 eta 0:04:45
epoch [31/50] batch [160/162] time 0.099 (0.092) data 0.001 (0.002) loss 1.3417 (1.2047) teacher_loss 0.3859 (0.3442) loss_zs_kd 0.0281 (0.0175) loss_oracle 0.4167 (0.3792) kd_loss 0.7333 (0.6622) acc 87.5000 (87.2852) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0571 (0.0500) teacher/usage_max 0.7634 (0.8427) teacher/usage_min 0.0345 (0.0441) teacher/usage_std 0.3117 (0.3620) nleep/row_max_mean 1500.7808 (1498.9804) nleep/row_max_std 57.7464 (60.1880) nleep/row_min_mean 1479.6472 (1476.2202) lr 7.5131e-04 eta 0:04:42
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,969
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 89.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,591
* accuracy: 78.9%
* error: 21.1%
* macro_f1: 76.7%
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [32/50] batch [20/162] time 0.091 (0.104) data 0.000 (0.012) loss 1.3634 (1.2319) teacher_loss 0.4032 (0.3669) loss_zs_kd 0.0095 (0.0148) loss_oracle 0.3778 (0.3706) kd_loss 0.7665 (0.6723) acc 84.3750 (86.0938) gate/entropy 0.9786 (0.9785) gate/usage_max 0.5728 (0.5729) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0538 (0.0463) teacher/usage_max 0.7329 (0.8360) teacher/usage_min 0.1334 (0.0502) teacher/usage_std 0.2825 (0.3569) nleep/row_max_mean 1493.1604 (1502.0722) nleep/row_max_std 57.0396 (58.6246) nleep/row_min_mean 1472.5638 (1479.5782) lr 6.9098e-04 eta 0:05:19
epoch [32/50] batch [40/162] time 0.101 (0.098) data 0.000 (0.006) loss 1.1767 (1.2227) teacher_loss 0.2168 (0.3538) loss_zs_kd 0.0117 (0.0163) loss_oracle 0.4199 (0.3803) kd_loss 0.7441 (0.6705) acc 93.7500 (86.4844) gate/entropy 0.9786 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0438 (0.0472) teacher/usage_max 0.7658 (0.8370) teacher/usage_min 0.0846 (0.0428) teacher/usage_std 0.3070 (0.3587) nleep/row_max_mean 1498.2390 (1499.9123) nleep/row_max_std 53.2736 (60.0456) nleep/row_min_mean 1475.3130 (1477.5764) lr 6.9098e-04 eta 0:04:58
epoch [32/50] batch [60/162] time 0.102 (0.097) data 0.001 (0.004) loss 1.4617 (1.2163) teacher_loss 0.6257 (0.3501) loss_zs_kd 0.0168 (0.0174) loss_oracle 0.3554 (0.3784) kd_loss 0.6498 (0.6682) acc 84.3750 (86.9271) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0275 (0.0494) teacher/usage_max 0.8779 (0.8371) teacher/usage_min 0.0594 (0.0419) teacher/usage_std 0.3850 (0.3588) nleep/row_max_mean 1510.4008 (1500.2561) nleep/row_max_std 61.4968 (59.9955) nleep/row_min_mean 1489.2566 (1478.2225) lr 6.9098e-04 eta 0:04:52
epoch [32/50] batch [80/162] time 0.093 (0.097) data 0.000 (0.003) loss 1.0981 (1.2148) teacher_loss 0.2973 (0.3404) loss_zs_kd 0.0089 (0.0173) loss_oracle 0.3460 (0.3762) kd_loss 0.6234 (0.6776) acc 87.5000 (87.1484) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0885 (0.0492) teacher/usage_max 0.8429 (0.8279) teacher/usage_min 0.0208 (0.0436) teacher/usage_std 0.3634 (0.3526) nleep/row_max_mean 1489.7554 (1500.1984) nleep/row_max_std 66.9382 (59.9229) nleep/row_min_mean 1469.1846 (1478.2065) lr 6.9098e-04 eta 0:04:49
epoch [32/50] batch [100/162] time 0.092 (0.097) data 0.000 (0.003) loss 1.2980 (1.2012) teacher_loss 0.4149 (0.3322) loss_zs_kd 0.0256 (0.0180) loss_oracle 0.4030 (0.3736) kd_loss 0.6688 (0.6732) acc 81.2500 (87.5625) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0815 (0.0518) teacher/usage_max 0.8040 (0.8296) teacher/usage_min 0.0542 (0.0449) teacher/usage_std 0.3347 (0.3536) nleep/row_max_mean 1502.0659 (1501.4793) nleep/row_max_std 60.7868 (59.1964) nleep/row_min_mean 1481.4684 (1479.5310) lr 6.9098e-04 eta 0:04:48
epoch [32/50] batch [120/162] time 0.095 (0.097) data 0.000 (0.002) loss 1.2704 (1.2144) teacher_loss 0.3410 (0.3427) loss_zs_kd 0.0171 (0.0179) loss_oracle 0.3366 (0.3746) kd_loss 0.7526 (0.6755) acc 87.5000 (87.1094) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2135 (0.2134) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0290 (0.0511) teacher/usage_max 0.7723 (0.8281) teacher/usage_min 0.0384 (0.0436) teacher/usage_std 0.3164 (0.3527) nleep/row_max_mean 1477.2844 (1501.6112) nleep/row_max_std 44.5516 (58.5394) nleep/row_min_mean 1457.7258 (1479.8297) lr 6.9098e-04 eta 0:04:46
epoch [32/50] batch [140/162] time 0.107 (0.097) data 0.000 (0.002) loss 1.1029 (1.2128) teacher_loss 0.1924 (0.3381) loss_zs_kd 0.0183 (0.0177) loss_oracle 0.4295 (0.3771) kd_loss 0.6866 (0.6774) acc 93.7500 (87.0982) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0281 (0.0505) teacher/usage_max 0.8401 (0.8268) teacher/usage_min 0.0049 (0.0441) teacher/usage_std 0.3635 (0.3518) nleep/row_max_mean 1517.3632 (1502.1614) nleep/row_max_std 54.6240 (57.7040) nleep/row_min_mean 1492.7502 (1480.3104) lr 6.9098e-04 eta 0:04:43
epoch [32/50] batch [160/162] time 0.092 (0.096) data 0.000 (0.002) loss 1.4209 (1.2126) teacher_loss 0.4758 (0.3370) loss_zs_kd 0.0180 (0.0176) loss_oracle 0.4228 (0.3796) kd_loss 0.7247 (0.6770) acc 71.8750 (87.1094) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0173 (0.0520) teacher/usage_max 0.8124 (0.8256) teacher/usage_min 0.0335 (0.0440) teacher/usage_std 0.3423 (0.3510) nleep/row_max_mean 1505.8733 (1502.7496) nleep/row_max_std 44.1719 (57.1802) nleep/row_min_mean 1482.0299 (1480.8719) lr 6.9098e-04 eta 0:04:40
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,964
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 89.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,487
* accuracy: 75.8%
* error: 24.2%
* macro_f1: 74.3%
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [33/50] batch [20/162] time 0.096 (0.111) data 0.000 (0.015) loss 1.5452 (1.2733) teacher_loss 0.6014 (0.3607) loss_zs_kd 0.0309 (0.0252) loss_oracle 0.4476 (0.4064) kd_loss 0.7046 (0.6968) acc 75.0000 (85.9375) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0341 (0.0464) teacher/usage_max 0.8158 (0.8111) teacher/usage_min 0.0048 (0.0508) teacher/usage_std 0.3485 (0.3406) nleep/row_max_mean 1490.6262 (1504.6354) nleep/row_max_std 60.2471 (52.8249) nleep/row_min_mean 1467.8389 (1482.0056) lr 6.3188e-04 eta 0:05:20
epoch [33/50] batch [40/162] time 0.088 (0.103) data 0.000 (0.007) loss 1.1108 (1.2316) teacher_loss 0.3778 (0.3416) loss_zs_kd 0.0147 (0.0237) loss_oracle 0.2854 (0.3928) kd_loss 0.5829 (0.6817) acc 90.6250 (86.8750) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0750 (0.0478) teacher/usage_max 0.8975 (0.8250) teacher/usage_min 0.0254 (0.0419) teacher/usage_std 0.3995 (0.3507) nleep/row_max_mean 1511.0463 (1505.3211) nleep/row_max_std 55.1431 (54.7614) nleep/row_min_mean 1488.7781 (1482.8275) lr 6.3188e-04 eta 0:04:55
epoch [33/50] batch [60/162] time 0.161 (0.100) data 0.000 (0.005) loss 1.1657 (1.2206) teacher_loss 0.3340 (0.3315) loss_zs_kd 0.0157 (0.0228) loss_oracle 0.3257 (0.3939) kd_loss 0.6609 (0.6807) acc 87.5000 (87.5000) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0659 (0.0467) teacher/usage_max 0.8278 (0.8271) teacher/usage_min 0.0295 (0.0405) teacher/usage_std 0.3527 (0.3521) nleep/row_max_mean 1500.3446 (1504.6203) nleep/row_max_std 66.3576 (55.3293) nleep/row_min_mean 1480.6833 (1482.2791) lr 6.3188e-04 eta 0:04:44
epoch [33/50] batch [80/162] time 0.100 (0.103) data 0.001 (0.004) loss 1.4220 (1.2224) teacher_loss 0.4562 (0.3309) loss_zs_kd 0.0215 (0.0223) loss_oracle 0.4346 (0.3939) kd_loss 0.7377 (0.6834) acc 78.1250 (87.3438) gate/entropy 0.9785 (0.9784) gate/usage_max 0.5729 (0.5730) gate/usage_min 0.2135 (0.2134) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0358 (0.0464) teacher/usage_max 0.7805 (0.8247) teacher/usage_min 0.0008 (0.0360) teacher/usage_std 0.3285 (0.3513) nleep/row_max_mean 1499.6254 (1504.8827) nleep/row_max_std 60.2034 (55.2413) nleep/row_min_mean 1478.9995 (1482.4944) lr 6.3188e-04 eta 0:04:52
epoch [33/50] batch [100/162] time 0.089 (0.102) data 0.000 (0.003) loss 1.1059 (1.2235) teacher_loss 0.3201 (0.3292) loss_zs_kd 0.0273 (0.0222) loss_oracle 0.4097 (0.3944) kd_loss 0.5673 (0.6859) acc 87.5000 (87.3125) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0794 (0.0477) teacher/usage_max 0.9089 (0.8208) teacher/usage_min 0.0386 (0.0371) teacher/usage_std 0.4070 (0.3488) nleep/row_max_mean 1502.1483 (1504.8130) nleep/row_max_std 53.6734 (54.6947) nleep/row_min_mean 1477.3779 (1482.4291) lr 6.3188e-04 eta 0:04:46
epoch [33/50] batch [120/162] time 0.098 (0.101) data 0.000 (0.003) loss 1.1264 (1.2212) teacher_loss 0.3265 (0.3286) loss_zs_kd 0.0220 (0.0219) loss_oracle 0.4076 (0.3947) kd_loss 0.5852 (0.6843) acc 87.5000 (87.4740) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0921 (0.0476) teacher/usage_max 0.8779 (0.8226) teacher/usage_min 0.0421 (0.0378) teacher/usage_std 0.3854 (0.3498) nleep/row_max_mean 1513.7023 (1505.1623) nleep/row_max_std 60.8051 (54.6179) nleep/row_min_mean 1492.6637 (1482.7791) lr 6.3188e-04 eta 0:04:42
epoch [33/50] batch [140/162] time 0.101 (0.101) data 0.000 (0.002) loss 1.1731 (1.2225) teacher_loss 0.2449 (0.3300) loss_zs_kd 0.0302 (0.0217) loss_oracle 0.4096 (0.3930) kd_loss 0.7083 (0.6852) acc 87.5000 (87.4330) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0772 (0.0480) teacher/usage_max 0.7683 (0.8213) teacher/usage_min 0.0943 (0.0390) teacher/usage_std 0.3080 (0.3488) nleep/row_max_mean 1511.6777 (1504.3720) nleep/row_max_std 55.0341 (54.6716) nleep/row_min_mean 1492.0298 (1482.1337) lr 6.3188e-04 eta 0:04:39
epoch [33/50] batch [160/162] time 0.091 (0.100) data 0.000 (0.002) loss 0.9319 (1.2217) teacher_loss 0.1433 (0.3270) loss_zs_kd 0.0216 (0.0219) loss_oracle 0.3573 (0.3960) kd_loss 0.5992 (0.6858) acc 96.8750 (87.5586) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0324 (0.0500) teacher/usage_max 0.9242 (0.8187) teacher/usage_min 0.0134 (0.0411) teacher/usage_std 0.4183 (0.3468) nleep/row_max_mean 1506.9156 (1504.2395) nleep/row_max_std 55.4700 (54.4743) nleep/row_min_mean 1485.1790 (1482.1015) lr 6.3188e-04 eta 0:04:34
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,967
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 89.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,545
* accuracy: 77.5%
* error: 22.5%
* macro_f1: 75.0%
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [34/50] batch [20/162] time 0.090 (0.116) data 0.000 (0.017) loss 1.0873 (1.2396) teacher_loss 0.1568 (0.3196) loss_zs_kd 0.0238 (0.0231) loss_oracle 0.4682 (0.4140) kd_loss 0.6844 (0.7014) acc 96.8750 (88.9062) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.1028 (0.0685) teacher/usage_max 0.7667 (0.7841) teacher/usage_min 0.0441 (0.0568) teacher/usage_std 0.3121 (0.3229) nleep/row_max_mean 1507.2285 (1503.8754) nleep/row_max_std 52.9079 (50.6509) nleep/row_min_mean 1487.5878 (1482.7093) lr 5.7422e-04 eta 0:05:17
epoch [34/50] batch [40/162] time 0.096 (0.105) data 0.000 (0.009) loss 1.1115 (1.2255) teacher_loss 0.2648 (0.3187) loss_zs_kd 0.0131 (0.0222) loss_oracle 0.3545 (0.3969) kd_loss 0.6629 (0.6971) acc 87.5000 (88.1250) gate/entropy 0.9785 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0588 (0.0634) teacher/usage_max 0.8331 (0.7936) teacher/usage_min 0.0011 (0.0492) teacher/usage_std 0.3597 (0.3298) nleep/row_max_mean 1505.8372 (1504.4166) nleep/row_max_std 45.2749 (52.5273) nleep/row_min_mean 1484.4087 (1483.3765) lr 5.7422e-04 eta 0:04:46
epoch [34/50] batch [60/162] time 0.097 (0.103) data 0.001 (0.006) loss 1.1458 (1.2272) teacher_loss 0.3470 (0.3146) loss_zs_kd 0.0190 (0.0215) loss_oracle 0.3551 (0.3992) kd_loss 0.6117 (0.7022) acc 84.3750 (88.0208) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5731 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0987 (0.0652) teacher/usage_max 0.8443 (0.7866) teacher/usage_min 0.0516 (0.0485) teacher/usage_std 0.3619 (0.3258) nleep/row_max_mean 1510.0328 (1504.2940) nleep/row_max_std 52.2370 (51.9315) nleep/row_min_mean 1490.2714 (1483.1315) lr 5.7422e-04 eta 0:04:36
epoch [34/50] batch [80/162] time 0.098 (0.100) data 0.000 (0.004) loss 1.2308 (1.2210) teacher_loss 0.3577 (0.3117) loss_zs_kd 0.0223 (0.0228) loss_oracle 0.3593 (0.3960) kd_loss 0.6823 (0.7000) acc 90.6250 (88.3203) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0454 (0.0653) teacher/usage_max 0.8266 (0.7888) teacher/usage_min 0.0302 (0.0510) teacher/usage_std 0.3518 (0.3268) nleep/row_max_mean 1514.5107 (1504.4363) nleep/row_max_std 55.3255 (51.9521) nleep/row_min_mean 1491.5530 (1483.3510) lr 5.7422e-04 eta 0:04:27
epoch [34/50] batch [100/162] time 0.096 (0.099) data 0.000 (0.004) loss 1.2782 (1.2203) teacher_loss 0.4206 (0.3138) loss_zs_kd 0.0142 (0.0226) loss_oracle 0.3398 (0.3938) kd_loss 0.6806 (0.6983) acc 84.3750 (88.4062) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5732 (0.5730) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0426 (0.0662) teacher/usage_max 0.8314 (0.7896) teacher/usage_min 0.0315 (0.0496) teacher/usage_std 0.3548 (0.3274) nleep/row_max_mean 1519.0275 (1503.8370) nleep/row_max_std 57.9958 (52.8127) nleep/row_min_mean 1495.7488 (1482.8871) lr 5.7422e-04 eta 0:04:23
epoch [34/50] batch [120/162] time 0.099 (0.099) data 0.000 (0.003) loss 1.1386 (1.2230) teacher_loss 0.3338 (0.3096) loss_zs_kd 0.0255 (0.0228) loss_oracle 0.3639 (0.3960) kd_loss 0.6101 (0.7040) acc 87.5000 (88.8802) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.1271 (0.0686) teacher/usage_max 0.8173 (0.7813) teacher/usage_min 0.0254 (0.0506) teacher/usage_std 0.3464 (0.3221) nleep/row_max_mean 1501.1438 (1503.6272) nleep/row_max_std 60.0993 (53.2417) nleep/row_min_mean 1481.9856 (1482.8296) lr 5.7422e-04 eta 0:04:19
epoch [34/50] batch [140/162] time 0.102 (0.098) data 0.000 (0.003) loss 1.2597 (1.2305) teacher_loss 0.3075 (0.3104) loss_zs_kd 0.0191 (0.0229) loss_oracle 0.3743 (0.4006) kd_loss 0.7555 (0.7083) acc 93.7500 (88.7946) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0646 (0.0697) teacher/usage_max 0.7334 (0.7758) teacher/usage_min 0.0532 (0.0534) teacher/usage_std 0.2904 (0.3184) nleep/row_max_mean 1501.4683 (1503.1921) nleep/row_max_std 61.1988 (53.4053) nleep/row_min_mean 1481.3176 (1482.4936) lr 5.7422e-04 eta 0:04:16
epoch [34/50] batch [160/162] time 0.086 (0.097) data 0.000 (0.002) loss 1.2575 (1.2334) teacher_loss 0.1755 (0.3089) loss_zs_kd 0.0209 (0.0231) loss_oracle 0.4660 (0.4010) kd_loss 0.8386 (0.7125) acc 93.7500 (88.7891) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.1464 (0.0738) teacher/usage_max 0.5662 (0.7674) teacher/usage_min 0.1091 (0.0570) teacher/usage_std 0.1867 (0.3127) nleep/row_max_mean 1503.0518 (1502.9374) nleep/row_max_std 52.9082 (53.5392) nleep/row_min_mean 1483.1813 (1482.3971) lr 5.7422e-04 eta 0:04:12
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,959
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,446
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 72.5%
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [35/50] batch [20/162] time 0.101 (0.111) data 0.001 (0.016) loss 1.2403 (1.2795) teacher_loss 0.2231 (0.3180) loss_zs_kd 0.0282 (0.0289) loss_oracle 0.4651 (0.4306) kd_loss 0.7705 (0.7318) acc 84.3750 (88.5938) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.1016 (0.0988) teacher/usage_max 0.6803 (0.7226) teacher/usage_min 0.1231 (0.0654) teacher/usage_std 0.2472 (0.2837) nleep/row_max_mean 1512.6613 (1504.1511) nleep/row_max_std 51.4368 (51.0107) nleep/row_min_mean 1494.8105 (1484.7133) lr 5.1825e-04 eta 0:04:44
epoch [35/50] batch [40/162] time 0.099 (0.105) data 0.000 (0.008) loss 1.2399 (1.3047) teacher_loss 0.1507 (0.3096) loss_zs_kd 0.0419 (0.0283) loss_oracle 0.4708 (0.4441) kd_loss 0.8330 (0.7589) acc 96.8750 (89.5312) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0801 (0.1001) teacher/usage_max 0.6391 (0.6938) teacher/usage_min 0.0840 (0.0866) teacher/usage_std 0.2301 (0.2629) nleep/row_max_mean 1513.6650 (1502.5207) nleep/row_max_std 40.9370 (52.2368) nleep/row_min_mean 1493.4683 (1483.0252) lr 5.1825e-04 eta 0:04:27
epoch [35/50] batch [60/162] time 0.104 (0.102) data 0.001 (0.005) loss 1.3723 (1.3109) teacher_loss 0.4844 (0.2976) loss_zs_kd 0.0303 (0.0305) loss_oracle 0.3850 (0.4393) kd_loss 0.6802 (0.7784) acc 87.5000 (89.9479) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0858 (0.0996) teacher/usage_max 0.7881 (0.6754) teacher/usage_min 0.0824 (0.0965) teacher/usage_std 0.3221 (0.2505) nleep/row_max_mean 1500.0010 (1503.1162) nleep/row_max_std 68.3390 (52.5237) nleep/row_min_mean 1479.5508 (1483.8146) lr 5.1825e-04 eta 0:04:17
epoch [35/50] batch [80/162] time 0.093 (0.100) data 0.000 (0.004) loss 1.1451 (1.3062) teacher_loss 0.2520 (0.2966) loss_zs_kd 0.0355 (0.0317) loss_oracle 0.3612 (0.4297) kd_loss 0.6948 (0.7790) acc 87.5000 (90.2344) gate/entropy 0.9782 (0.9784) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.1588 (0.1004) teacher/usage_max 0.6994 (0.6737) teacher/usage_min 0.0652 (0.0960) teacher/usage_std 0.2680 (0.2505) nleep/row_max_mean 1514.5920 (1502.7175) nleep/row_max_std 53.7324 (53.0553) nleep/row_min_mean 1497.2341 (1483.4564) lr 5.1825e-04 eta 0:04:12
epoch [35/50] batch [100/162] time 0.092 (0.100) data 0.000 (0.003) loss 1.2832 (1.3097) teacher_loss 0.1130 (0.2910) loss_zs_kd 0.0366 (0.0325) loss_oracle 0.4682 (0.4300) kd_loss 0.9178 (0.7874) acc 100.0000 (90.2188) gate/entropy 0.9784 (0.9783) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.1259 (0.1030) teacher/usage_max 0.5070 (0.6625) teacher/usage_min 0.1517 (0.0978) teacher/usage_std 0.1452 (0.2440) nleep/row_max_mean 1492.4385 (1502.3919) nleep/row_max_std 54.3195 (53.3151) nleep/row_min_mean 1475.0638 (1483.2533) lr 5.1825e-04 eta 0:04:09
epoch [35/50] batch [120/162] time 0.104 (0.100) data 0.000 (0.003) loss 1.2116 (1.3115) teacher_loss 0.1161 (0.2745) loss_zs_kd 0.0305 (0.0342) loss_oracle 0.5001 (0.4345) kd_loss 0.8302 (0.8026) acc 96.8750 (90.8594) gate/entropy 0.9784 (0.9783) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.1682 (0.1051) teacher/usage_max 0.5528 (0.6449) teacher/usage_min 0.1611 (0.0999) teacher/usage_std 0.1633 (0.2345) nleep/row_max_mean 1488.5745 (1502.0057) nleep/row_max_std 57.3028 (53.3486) nleep/row_min_mean 1472.2258 (1482.9070) lr 5.1825e-04 eta 0:04:06
epoch [35/50] batch [140/162] time 0.097 (0.099) data 0.001 (0.002) loss 1.4132 (1.3136) teacher_loss 0.1497 (0.2624) loss_zs_kd 0.0187 (0.0358) loss_oracle 0.4227 (0.4407) kd_loss 1.0428 (0.8130) acc 93.7500 (91.3170) gate/entropy 0.9784 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.1161 (0.1060) teacher/usage_max 0.5063 (0.6342) teacher/usage_min 0.1035 (0.0995) teacher/usage_std 0.1693 (0.2295) nleep/row_max_mean 1502.3350 (1502.0211) nleep/row_max_std 46.7252 (53.0410) nleep/row_min_mean 1485.8669 (1482.8657) lr 5.1825e-04 eta 0:04:03
epoch [35/50] batch [160/162] time 0.089 (0.099) data 0.001 (0.002) loss 1.3518 (1.3298) teacher_loss 0.1687 (0.2594) loss_zs_kd 0.0341 (0.0358) loss_oracle 0.4887 (0.4421) kd_loss 0.9218 (0.8314) acc 96.8750 (91.5430) gate/entropy 0.9784 (0.9783) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0812 (0.1071) teacher/usage_max 0.5480 (0.6180) teacher/usage_min 0.1300 (0.1017) teacher/usage_std 0.1708 (0.2214) nleep/row_max_mean 1502.9607 (1501.7681) nleep/row_max_std 41.0428 (52.7980) nleep/row_min_mean 1480.9374 (1482.6133) lr 5.1825e-04 eta 0:03:59
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,954
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 89.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,626
* accuracy: 80.0%
* error: 20.0%
* macro_f1: 76.6%
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [36/50] batch [20/162] time 0.082 (0.103) data 0.000 (0.014) loss 1.5029 (1.4487) teacher_loss 0.1265 (0.1548) loss_zs_kd 0.0297 (0.0391) loss_oracle 0.5251 (0.5410) kd_loss 1.0991 (1.0039) acc 93.7500 (95.1562) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0604 (0.0932) teacher/usage_max 0.4709 (0.4903) teacher/usage_min 0.1398 (0.1450) teacher/usage_std 0.1409 (0.1478) nleep/row_max_mean 1503.1885 (1501.6978) nleep/row_max_std 56.0004 (52.0790) nleep/row_min_mean 1483.1499 (1481.9088) lr 4.6417e-04 eta 0:04:08
epoch [36/50] batch [40/162] time 0.097 (0.094) data 0.000 (0.007) loss 1.5423 (1.4858) teacher_loss 0.1026 (0.1489) loss_zs_kd 0.0739 (0.0465) loss_oracle 0.4748 (0.5526) kd_loss 1.1652 (1.0373) acc 100.0000 (95.3906) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.1024 (0.0949) teacher/usage_max 0.5514 (0.5061) teacher/usage_min 0.1683 (0.1332) teacher/usage_std 0.1608 (0.1585) nleep/row_max_mean 1502.7672 (1503.4016) nleep/row_max_std 56.5535 (51.1792) nleep/row_min_mean 1481.2114 (1483.5401) lr 4.6417e-04 eta 0:03:43
epoch [36/50] batch [60/162] time 0.075 (0.090) data 0.001 (0.005) loss 1.5286 (1.4981) teacher_loss 0.0197 (0.1557) loss_zs_kd 0.0377 (0.0460) loss_oracle 0.6814 (0.5524) kd_loss 1.1493 (1.0432) acc 100.0000 (95.2604) gate/entropy 0.9784 (0.9783) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0773 (0.0939) teacher/usage_max 0.4422 (0.5017) teacher/usage_min 0.2362 (0.1341) teacher/usage_std 0.0845 (0.1565) nleep/row_max_mean 1512.0179 (1503.0068) nleep/row_max_std 50.8749 (51.5921) nleep/row_min_mean 1490.5012 (1482.8600) lr 4.6417e-04 eta 0:03:32
epoch [36/50] batch [80/162] time 0.096 (0.089) data 0.000 (0.004) loss 1.6126 (1.5415) teacher_loss 0.0769 (0.1555) loss_zs_kd 0.0680 (0.0477) loss_oracle 0.6799 (0.5786) kd_loss 1.1618 (1.0729) acc 96.8750 (95.3906) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0316 (0.0894) teacher/usage_max 0.5313 (0.5133) teacher/usage_min 0.1134 (0.1387) teacher/usage_std 0.1713 (0.1592) nleep/row_max_mean 1515.0972 (1502.2310) nleep/row_max_std 41.8288 (51.0976) nleep/row_min_mean 1488.4657 (1481.7645) lr 4.6417e-04 eta 0:03:29
epoch [36/50] batch [100/162] time 0.080 (0.093) data 0.000 (0.003) loss 1.7279 (1.5624) teacher_loss 0.1365 (0.1485) loss_zs_kd 0.0422 (0.0474) loss_oracle 0.6126 (0.5906) kd_loss 1.2640 (1.0948) acc 93.7500 (95.7188) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0563 (0.0855) teacher/usage_max 0.5751 (0.5193) teacher/usage_min 0.1980 (0.1412) teacher/usage_std 0.1714 (0.1612) nleep/row_max_mean 1498.6849 (1501.9599) nleep/row_max_std 52.0780 (51.1079) nleep/row_min_mean 1477.0508 (1481.2345) lr 4.6417e-04 eta 0:03:37
epoch [36/50] batch [120/162] time 0.100 (0.093) data 0.000 (0.002) loss 1.6914 (1.5938) teacher_loss 0.1613 (0.1528) loss_zs_kd 0.0623 (0.0489) loss_oracle 0.6765 (0.6055) kd_loss 1.1608 (1.1137) acc 93.7500 (95.6510) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0147 (0.0814) teacher/usage_max 0.5000 (0.5230) teacher/usage_min 0.1263 (0.1451) teacher/usage_std 0.1552 (0.1610) nleep/row_max_mean 1476.7838 (1501.1460) nleep/row_max_std 63.7300 (51.7989) nleep/row_min_mean 1453.6637 (1480.0715) lr 4.6417e-04 eta 0:03:34
epoch [36/50] batch [140/162] time 0.083 (0.091) data 0.000 (0.002) loss 1.6234 (1.6124) teacher_loss 0.1574 (0.1485) loss_zs_kd 0.0677 (0.0504) loss_oracle 0.6138 (0.6240) kd_loss 1.1252 (1.1267) acc 96.8750 (95.7366) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0768 (0.0787) teacher/usage_max 0.5556 (0.5245) teacher/usage_min 0.0977 (0.1483) teacher/usage_std 0.1872 (0.1605) nleep/row_max_mean 1499.2675 (1500.6689) nleep/row_max_std 61.1281 (52.1022) nleep/row_min_mean 1477.9004 (1479.3075) lr 4.6417e-04 eta 0:03:29
epoch [36/50] batch [160/162] time 0.075 (0.090) data 0.000 (0.002) loss 1.8433 (1.6294) teacher_loss 0.2872 (0.1462) loss_zs_kd 0.0467 (0.0514) loss_oracle 0.6687 (0.6388) kd_loss 1.1984 (1.1381) acc 90.6250 (95.8008) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2135 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0918 (0.0750) teacher/usage_max 0.4284 (0.5255) teacher/usage_min 0.2572 (0.1529) teacher/usage_std 0.0712 (0.1593) nleep/row_max_mean 1502.1171 (1500.2081) nleep/row_max_std 44.1802 (52.3311) nleep/row_min_mean 1480.8267 (1478.4526) lr 4.6417e-04 eta 0:03:23
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,757
* accuracy: 78.6%
* error: 21.4%
* macro_f1: 82.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,659
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 76.3%
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [37/50] batch [20/162] time 0.102 (0.136) data 0.000 (0.023) loss 2.0171 (1.8594) teacher_loss 0.0972 (0.1655) loss_zs_kd 0.0840 (0.0537) loss_oracle 1.0028 (0.8078) kd_loss 1.3765 (1.2631) acc 96.8750 (95.1562) gate/entropy 0.9785 (0.9784) gate/usage_max 0.5729 (0.5730) gate/usage_min 0.2135 (0.2134) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0236 (0.0557) teacher/usage_max 0.6880 (0.5478) teacher/usage_min 0.1458 (0.1653) teacher/usage_std 0.2509 (0.1644) nleep/row_max_mean 1493.7151 (1496.4065) nleep/row_max_std 55.7738 (54.5874) nleep/row_min_mean 1463.1599 (1471.0276) lr 4.1221e-04 eta 0:05:05
epoch [37/50] batch [40/162] time 0.122 (0.123) data 0.001 (0.012) loss 2.1090 (1.8754) teacher_loss 0.2145 (0.1502) loss_zs_kd 0.0937 (0.0620) loss_oracle 1.0549 (0.8433) kd_loss 1.3203 (1.2726) acc 93.7500 (95.7031) gate/entropy 0.9785 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2135 (0.2134) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0259 (0.0500) teacher/usage_max 0.6249 (0.5558) teacher/usage_min 0.1746 (0.1678) teacher/usage_std 0.2064 (0.1668) nleep/row_max_mean 1490.7979 (1497.3027) nleep/row_max_std 48.0690 (54.7295) nleep/row_min_mean 1458.2605 (1470.7705) lr 4.1221e-04 eta 0:04:34
epoch [37/50] batch [60/162] time 0.117 (0.119) data 0.002 (0.008) loss 2.1024 (1.8906) teacher_loss 0.1592 (0.1356) loss_zs_kd 0.0642 (0.0638) loss_oracle 0.9614 (0.8754) kd_loss 1.4305 (1.2854) acc 96.8750 (96.3542) gate/entropy 0.9785 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2135 (0.2134) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0686 (0.0531) teacher/usage_max 0.7195 (0.5512) teacher/usage_min 0.0456 (0.1690) teacher/usage_std 0.2838 (0.1647) nleep/row_max_mean 1499.0610 (1498.0364) nleep/row_max_std 48.5694 (55.0629) nleep/row_min_mean 1469.0404 (1470.8112) lr 4.1221e-04 eta 0:04:22
epoch [37/50] batch [80/162] time 0.093 (0.114) data 0.000 (0.006) loss 2.0497 (1.9156) teacher_loss 0.1997 (0.1349) loss_zs_kd 0.0589 (0.0641) loss_oracle 0.9083 (0.8864) kd_loss 1.3664 (1.3054) acc 93.7500 (96.3672) gate/entropy 0.9785 (0.9784) gate/usage_max 0.5729 (0.5730) gate/usage_min 0.2135 (0.2134) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0753 (0.0534) teacher/usage_max 0.4970 (0.5536) teacher/usage_min 0.1034 (0.1575) teacher/usage_std 0.1674 (0.1698) nleep/row_max_mean 1505.0188 (1497.9207) nleep/row_max_std 42.5006 (54.9134) nleep/row_min_mean 1475.6221 (1470.0438) lr 4.1221e-04 eta 0:04:09
epoch [37/50] batch [100/162] time 0.099 (0.111) data 0.000 (0.005) loss 1.9302 (1.9265) teacher_loss 0.1104 (0.1307) loss_zs_kd 0.0649 (0.0634) loss_oracle 0.8818 (0.8901) kd_loss 1.3464 (1.3190) acc 96.8750 (96.5312) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0830 (0.0538) teacher/usage_max 0.5876 (0.5569) teacher/usage_min 0.1163 (0.1480) teacher/usage_std 0.1942 (0.1746) nleep/row_max_mean 1499.0896 (1497.9535) nleep/row_max_std 54.6243 (54.9984) nleep/row_min_mean 1470.5657 (1469.4568) lr 4.1221e-04 eta 0:04:00
epoch [37/50] batch [120/162] time 0.101 (0.108) data 0.000 (0.004) loss 2.1153 (1.9449) teacher_loss 0.2868 (0.1290) loss_zs_kd 0.0799 (0.0656) loss_oracle 0.8407 (0.9034) kd_loss 1.3682 (1.3314) acc 87.5000 (96.4583) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2135 (0.2134) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0449 (0.0513) teacher/usage_max 0.5372 (0.5559) teacher/usage_min 0.1327 (0.1423) teacher/usage_std 0.1652 (0.1761) nleep/row_max_mean 1494.5353 (1497.7346) nleep/row_max_std 62.8302 (55.2235) nleep/row_min_mean 1464.5288 (1468.7111) lr 4.1221e-04 eta 0:03:52
epoch [37/50] batch [140/162] time 0.104 (0.107) data 0.000 (0.004) loss 2.0463 (1.9601) teacher_loss 0.0930 (0.1239) loss_zs_kd 0.0654 (0.0663) loss_oracle 0.9874 (0.9146) kd_loss 1.4269 (1.3457) acc 96.8750 (96.5625) gate/entropy 0.9786 (0.9784) gate/usage_max 0.5728 (0.5730) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0367 (0.0487) teacher/usage_max 0.4688 (0.5543) teacher/usage_min 0.0812 (0.1335) teacher/usage_std 0.1784 (0.1789) nleep/row_max_mean 1491.4178 (1497.7915) nleep/row_max_std 53.9547 (55.1195) nleep/row_min_mean 1456.5671 (1468.1737) lr 4.1221e-04 eta 0:03:47
epoch [37/50] batch [160/162] time 0.088 (0.105) data 0.000 (0.003) loss 1.9595 (1.9717) teacher_loss 0.0354 (0.1198) loss_zs_kd 0.0629 (0.0679) loss_oracle 0.8701 (0.9190) kd_loss 1.4576 (1.3585) acc 100.0000 (96.7383) gate/entropy 0.9785 (0.9784) gate/usage_max 0.5729 (0.5730) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0184 (0.0468) teacher/usage_max 0.6249 (0.5607) teacher/usage_min 0.0688 (0.1247) teacher/usage_std 0.2278 (0.1850) nleep/row_max_mean 1496.7993 (1497.6620) nleep/row_max_std 57.6558 (55.0882) nleep/row_min_mean 1463.3210 (1467.5298) lr 4.1221e-04 eta 0:03:42
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,817
* accuracy: 81.3%
* error: 18.7%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,666
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 77.1%
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [38/50] batch [20/162] time 0.091 (0.105) data 0.000 (0.014) loss 2.0562 (2.0830) teacher_loss 0.0972 (0.1180) loss_zs_kd 0.0822 (0.0808) loss_oracle 1.0029 (0.9916) kd_loss 1.4164 (1.4287) acc 96.8750 (96.4062) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0526 (0.0412) teacher/usage_max 0.5001 (0.5350) teacher/usage_min 0.0759 (0.0750) teacher/usage_std 0.1847 (0.1976) nleep/row_max_mean 1485.9479 (1493.7691) nleep/row_max_std 61.2897 (56.7619) nleep/row_min_mean 1452.2444 (1460.1025) lr 3.6258e-04 eta 0:03:38
epoch [38/50] batch [40/162] time 0.097 (0.098) data 0.000 (0.007) loss 2.1841 (2.0818) teacher_loss 0.2264 (0.1155) loss_zs_kd 0.0493 (0.0789) loss_oracle 0.9768 (0.9923) kd_loss 1.4447 (1.4307) acc 93.7500 (96.6406) gate/entropy 0.9786 (0.9785) gate/usage_max 0.5728 (0.5729) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0081 (0.0399) teacher/usage_max 0.5937 (0.5333) teacher/usage_min 0.0922 (0.0744) teacher/usage_std 0.2052 (0.1971) nleep/row_max_mean 1478.9415 (1492.2011) nleep/row_max_std 54.7380 (57.7021) nleep/row_min_mean 1443.1572 (1458.7152) lr 3.6258e-04 eta 0:03:22
epoch [38/50] batch [60/162] time 0.089 (0.098) data 0.001 (0.005) loss 2.0522 (2.0920) teacher_loss 0.0677 (0.1200) loss_zs_kd 0.0817 (0.0767) loss_oracle 0.9244 (0.9860) kd_loss 1.4815 (1.4407) acc 100.0000 (96.7708) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0312 (0.0354) teacher/usage_max 0.6249 (0.5517) teacher/usage_min 0.0320 (0.0687) teacher/usage_std 0.2422 (0.2053) nleep/row_max_mean 1496.3695 (1493.8082) nleep/row_max_std 61.9780 (57.4107) nleep/row_min_mean 1462.2266 (1459.5430) lr 3.6258e-04 eta 0:03:19
epoch [38/50] batch [80/162] time 0.090 (0.097) data 0.000 (0.004) loss 2.1604 (2.0982) teacher_loss 0.1139 (0.1217) loss_zs_kd 0.0737 (0.0750) loss_oracle 1.0925 (0.9840) kd_loss 1.4633 (1.4470) acc 96.8750 (96.6797) gate/entropy 0.9786 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0462 (0.0344) teacher/usage_max 0.6095 (0.5512) teacher/usage_min 0.0347 (0.0634) teacher/usage_std 0.2352 (0.2074) nleep/row_max_mean 1496.0321 (1494.5575) nleep/row_max_std 50.2031 (56.5831) nleep/row_min_mean 1463.2419 (1460.2388) lr 3.6258e-04 eta 0:03:16
epoch [38/50] batch [100/162] time 0.088 (0.096) data 0.000 (0.003) loss 2.1195 (2.0996) teacher_loss 0.0570 (0.1198) loss_zs_kd 0.0689 (0.0743) loss_oracle 1.0375 (0.9863) kd_loss 1.5093 (1.4495) acc 96.8750 (96.5938) gate/entropy 0.9787 (0.9785) gate/usage_max 0.5728 (0.5729) gate/usage_min 0.2136 (0.2135) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0273 (0.0346) teacher/usage_max 0.5549 (0.5547) teacher/usage_min 0.0070 (0.0607) teacher/usage_std 0.2356 (0.2099) nleep/row_max_mean 1505.6709 (1495.0170) nleep/row_max_std 56.5355 (56.2726) nleep/row_min_mean 1464.8478 (1460.2846) lr 3.6258e-04 eta 0:03:12
epoch [38/50] batch [120/162] time 0.096 (0.097) data 0.000 (0.002) loss 2.2326 (2.0997) teacher_loss 0.1434 (0.1157) loss_zs_kd 0.0919 (0.0737) loss_oracle 1.1071 (0.9865) kd_loss 1.4897 (1.4539) acc 96.8750 (96.7708) gate/entropy 0.9786 (0.9785) gate/usage_max 0.5728 (0.5729) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0244 (0.0342) teacher/usage_max 0.5244 (0.5593) teacher/usage_min 0.0301 (0.0566) teacher/usage_std 0.2168 (0.2131) nleep/row_max_mean 1494.8076 (1495.9879) nleep/row_max_std 51.1677 (55.6293) nleep/row_min_mean 1458.6753 (1461.0657) lr 3.6258e-04 eta 0:03:12
epoch [38/50] batch [140/162] time 0.105 (0.097) data 0.000 (0.002) loss 1.9732 (2.1013) teacher_loss 0.0471 (0.1151) loss_zs_kd 0.0706 (0.0740) loss_oracle 0.9178 (0.9841) kd_loss 1.4319 (1.4572) acc 100.0000 (96.7634) gate/entropy 0.9787 (0.9785) gate/usage_max 0.5727 (0.5729) gate/usage_min 0.2136 (0.2135) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0796 (0.0340) teacher/usage_max 0.6167 (0.5636) teacher/usage_min 0.0324 (0.0534) teacher/usage_std 0.2389 (0.2159) nleep/row_max_mean 1494.1890 (1496.7370) nleep/row_max_std 50.3732 (55.0656) nleep/row_min_mean 1456.4014 (1461.5138) lr 3.6258e-04 eta 0:03:11
epoch [38/50] batch [160/162] time 0.088 (0.097) data 0.000 (0.002) loss 2.2068 (2.1017) teacher_loss 0.0905 (0.1133) loss_zs_kd 0.0632 (0.0739) loss_oracle 1.0849 (0.9822) kd_loss 1.5423 (1.4603) acc 100.0000 (96.8164) gate/entropy 0.9786 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0015 (0.0331) teacher/usage_max 0.5623 (0.5665) teacher/usage_min 0.0000 (0.0512) teacher/usage_std 0.2411 (0.2180) nleep/row_max_mean 1508.4429 (1497.0647) nleep/row_max_std 49.9646 (54.8686) nleep/row_min_mean 1469.8717 (1461.5484) lr 3.6258e-04 eta 0:03:08
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,852
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,658
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 76.8%
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     81.8%, epoch: 4 *******
epoch [39/50] batch [20/162] time 0.105 (0.115) data 0.000 (0.018) loss 2.2559 (2.1144) teacher_loss 0.2062 (0.1097) loss_zs_kd 0.0750 (0.0749) loss_oracle 0.9410 (0.9507) kd_loss 1.5418 (1.4920) acc 93.7500 (97.0312) gate/entropy 0.9787 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2136 (0.2135) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0017 (0.0256) teacher/usage_max 0.6250 (0.5784) teacher/usage_min 0.0002 (0.0266) teacher/usage_std 0.2568 (0.2350) nleep/row_max_mean 1490.9937 (1496.3078) nleep/row_max_std 60.7999 (55.5718) nleep/row_min_mean 1454.4742 (1460.0208) lr 3.1545e-04 eta 0:03:41
epoch [39/50] batch [40/162] time 0.087 (0.106) data 0.000 (0.009) loss 2.3615 (2.1600) teacher_loss 0.2926 (0.1316) loss_zs_kd 0.0898 (0.0734) loss_oracle 1.0457 (0.9892) kd_loss 1.5012 (1.4970) acc 90.6250 (96.3281) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2136 (0.2135) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0242 (0.0249) teacher/usage_max 0.5440 (0.5823) teacher/usage_min 0.0185 (0.0222) teacher/usage_std 0.2268 (0.2384) nleep/row_max_mean 1501.7429 (1497.8522) nleep/row_max_std 62.0623 (56.0024) nleep/row_min_mean 1464.7225 (1461.1136) lr 3.1545e-04 eta 0:03:21
epoch [39/50] batch [60/162] time 0.108 (0.103) data 0.001 (0.006) loss 2.0960 (2.1676) teacher_loss 0.0678 (0.1276) loss_zs_kd 0.0580 (0.0718) loss_oracle 0.9820 (1.0040) kd_loss 1.5082 (1.5022) acc 100.0000 (96.7188) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0060 (0.0222) teacher/usage_max 0.5939 (0.5751) teacher/usage_min 0.0301 (0.0197) teacher/usage_std 0.2321 (0.2376) nleep/row_max_mean 1503.9268 (1497.1930) nleep/row_max_std 57.9012 (56.3556) nleep/row_min_mean 1466.7410 (1460.0644) lr 3.1545e-04 eta 0:03:14
epoch [39/50] batch [80/162] time 0.095 (0.102) data 0.000 (0.005) loss 2.2445 (2.1642) teacher_loss 0.1829 (0.1273) loss_zs_kd 0.0735 (0.0707) loss_oracle 1.0372 (0.9979) kd_loss 1.5062 (1.5026) acc 93.7500 (96.8359) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2136 (0.2135) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0087 (0.0227) teacher/usage_max 0.5021 (0.5715) teacher/usage_min 0.0291 (0.0187) teacher/usage_std 0.2156 (0.2368) nleep/row_max_mean 1485.4125 (1497.7562) nleep/row_max_std 60.4606 (55.5650) nleep/row_min_mean 1448.5350 (1460.3531) lr 3.1545e-04 eta 0:03:10
epoch [39/50] batch [100/162] time 0.144 (0.105) data 0.000 (0.004) loss 2.1739 (2.1632) teacher_loss 0.1838 (0.1272) loss_zs_kd 0.0795 (0.0717) loss_oracle 0.9146 (0.9897) kd_loss 1.4930 (1.5052) acc 93.7500 (96.8438) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0429 (0.0218) teacher/usage_max 0.6137 (0.5723) teacher/usage_min 0.0079 (0.0169) teacher/usage_std 0.2494 (0.2377) nleep/row_max_mean 1499.2666 (1498.3034) nleep/row_max_std 59.7248 (55.1102) nleep/row_min_mean 1463.5073 (1460.8436) lr 3.1545e-04 eta 0:03:13
epoch [39/50] batch [120/162] time 0.111 (0.104) data 0.000 (0.003) loss 2.2327 (2.1650) teacher_loss 0.1903 (0.1238) loss_zs_kd 0.0604 (0.0716) loss_oracle 1.0055 (0.9917) kd_loss 1.5095 (1.5096) acc 87.5000 (96.7708) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0263 (0.0201) teacher/usage_max 0.5549 (0.5734) teacher/usage_min 0.0079 (0.0142) teacher/usage_std 0.2351 (0.2392) nleep/row_max_mean 1499.6619 (1498.8372) nleep/row_max_std 61.7518 (55.3147) nleep/row_min_mean 1461.5022 (1461.2485) lr 3.1545e-04 eta 0:03:09
epoch [39/50] batch [140/162] time 0.090 (0.103) data 0.000 (0.003) loss 2.1044 (2.1667) teacher_loss 0.0544 (0.1250) loss_zs_kd 0.0869 (0.0707) loss_oracle 0.9273 (0.9891) kd_loss 1.5429 (1.5118) acc 100.0000 (96.8527) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2136 (0.2135) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0007 (0.0198) teacher/usage_max 0.6250 (0.5749) teacher/usage_min 0.0001 (0.0123) teacher/usage_std 0.2568 (0.2407) nleep/row_max_mean 1502.6549 (1498.3111) nleep/row_max_std 54.2646 (55.3556) nleep/row_min_mean 1464.6215 (1460.7804) lr 3.1545e-04 eta 0:03:04
epoch [39/50] batch [160/162] time 0.081 (0.101) data 0.000 (0.003) loss 2.1809 (2.1744) teacher_loss 0.1553 (0.1315) loss_zs_kd 0.0633 (0.0697) loss_oracle 0.9189 (0.9877) kd_loss 1.5345 (1.5142) acc 96.8750 (96.7383) gate/entropy 0.9787 (0.9786) gate/usage_max 0.5727 (0.5728) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0090 (0.0188) teacher/usage_max 0.5294 (0.5756) teacher/usage_min 0.0000 (0.0108) teacher/usage_std 0.2369 (0.2415) nleep/row_max_mean 1487.9915 (1497.8875) nleep/row_max_std 55.9773 (55.6775) nleep/row_min_mean 1453.8069 (1460.3401) lr 3.1545e-04 eta 0:03:00
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,902
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,698
* accuracy: 82.2%
* error: 17.8%
* macro_f1: 78.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 39 *******
epoch [40/50] batch [20/162] time 0.095 (0.113) data 0.000 (0.020) loss 2.1715 (2.1959) teacher_loss 0.1463 (0.1721) loss_zs_kd 0.0621 (0.0571) loss_oracle 0.9690 (0.9548) kd_loss 1.5097 (1.5178) acc 96.8750 (95.1562) gate/entropy 0.9788 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1693) teacher/entropy 0.0337 (0.0245) teacher/usage_max 0.5010 (0.5713) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.2357 (0.2480) nleep/row_max_mean 1492.3201 (1493.4075) nleep/row_max_std 63.0360 (57.0798) nleep/row_min_mean 1454.1029 (1457.1522) lr 2.7103e-04 eta 0:03:19
epoch [40/50] batch [40/162] time 0.105 (0.103) data 0.000 (0.010) loss 2.3007 (2.2003) teacher_loss 0.2693 (0.1666) loss_zs_kd 0.0658 (0.0575) loss_oracle 0.9715 (0.9777) kd_loss 1.5128 (1.5161) acc 90.6250 (95.5469) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5728 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0308 (0.0267) teacher/usage_max 0.5724 (0.5775) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.2430 (0.2489) nleep/row_max_mean 1481.0681 (1497.9662) nleep/row_max_std 62.8686 (55.8677) nleep/row_min_mean 1447.7178 (1461.2628) lr 2.7103e-04 eta 0:03:00
epoch [40/50] batch [60/162] time 0.096 (0.101) data 0.001 (0.007) loss 2.3525 (2.2197) teacher_loss 0.2710 (0.1804) loss_zs_kd 0.0620 (0.0575) loss_oracle 1.1240 (0.9950) kd_loss 1.4885 (1.5131) acc 87.5000 (94.9479) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5728 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0549 (0.0299) teacher/usage_max 0.7346 (0.5811) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.3037 (0.2490) nleep/row_max_mean 1496.4963 (1498.4691) nleep/row_max_std 70.4260 (56.9957) nleep/row_min_mean 1458.5220 (1461.9913) lr 2.7103e-04 eta 0:02:54
epoch [40/50] batch [80/162] time 0.096 (0.100) data 0.000 (0.005) loss 2.2620 (2.2272) teacher_loss 0.2127 (0.1886) loss_zs_kd 0.0674 (0.0590) loss_oracle 0.9608 (0.9926) kd_loss 1.5351 (1.5129) acc 93.7500 (95.0391) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0083 (0.0302) teacher/usage_max 0.5016 (0.5798) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.2357 (0.2485) nleep/row_max_mean 1487.7502 (1497.8122) nleep/row_max_std 60.3273 (57.2442) nleep/row_min_mean 1453.3689 (1461.5714) lr 2.7103e-04 eta 0:02:50
epoch [40/50] batch [100/162] time 0.099 (0.099) data 0.000 (0.004) loss 2.0956 (2.2212) teacher_loss 0.0377 (0.1831) loss_zs_kd 0.0458 (0.0585) loss_oracle 1.0456 (0.9936) kd_loss 1.5121 (1.5120) acc 100.0000 (95.2188) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0287 (0.0307) teacher/usage_max 0.5846 (0.5769) teacher/usage_min 0.0026 (0.0008) teacher/usage_std 0.2442 (0.2474) nleep/row_max_mean 1500.8715 (1497.8043) nleep/row_max_std 57.5883 (57.0248) nleep/row_min_mean 1463.1996 (1461.6846) lr 2.7103e-04 eta 0:02:47
epoch [40/50] batch [120/162] time 0.099 (0.099) data 0.000 (0.004) loss 2.2749 (2.2210) teacher_loss 0.3099 (0.1879) loss_zs_kd 0.0469 (0.0572) loss_oracle 0.9412 (0.9862) kd_loss 1.4709 (1.5114) acc 93.7500 (95.2604) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0718 (0.0312) teacher/usage_max 0.5331 (0.5737) teacher/usage_min 0.0007 (0.0009) teacher/usage_std 0.2368 (0.2465) nleep/row_max_mean 1498.0618 (1497.9332) nleep/row_max_std 52.3888 (56.7743) nleep/row_min_mean 1462.9973 (1461.8632) lr 2.7103e-04 eta 0:02:44
epoch [40/50] batch [140/162] time 0.097 (0.098) data 0.000 (0.003) loss 2.1684 (2.2200) teacher_loss 0.0367 (0.1866) loss_zs_kd 0.0552 (0.0573) loss_oracle 1.1731 (0.9871) kd_loss 1.5176 (1.5113) acc 100.0000 (95.2679) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0258 (0.0313) teacher/usage_max 0.6963 (0.5754) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.2850 (0.2470) nleep/row_max_mean 1501.5088 (1498.4419) nleep/row_max_std 52.1474 (56.3003) nleep/row_min_mean 1462.7150 (1462.4241) lr 2.7103e-04 eta 0:02:41
epoch [40/50] batch [160/162] time 0.084 (0.097) data 0.000 (0.003) loss 2.1039 (2.2122) teacher_loss 0.0898 (0.1831) loss_zs_kd 0.0347 (0.0573) loss_oracle 0.9192 (0.9805) kd_loss 1.5372 (1.5102) acc 96.8750 (95.3906) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0064 (0.0322) teacher/usage_max 0.5928 (0.5759) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.2476 (0.2470) nleep/row_max_mean 1514.6183 (1499.1589) nleep/row_max_std 49.2922 (55.5198) nleep/row_min_mean 1479.5524 (1463.2209) lr 2.7103e-04 eta 0:02:37
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,927
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 88.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,677
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 77.0%
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 39 *******
epoch [41/50] batch [20/162] time 0.089 (0.120) data 0.000 (0.016) loss 2.2216 (2.1697) teacher_loss 0.2088 (0.1752) loss_zs_kd 0.0591 (0.0542) loss_oracle 0.9333 (0.9160) kd_loss 1.5166 (1.5094) acc 96.8750 (94.6875) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0270 (0.0337) teacher/usage_max 0.5931 (0.5902) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.2477 (0.2504) nleep/row_max_mean 1520.0509 (1504.0357) nleep/row_max_std 41.3995 (49.9715) nleep/row_min_mean 1484.3816 (1468.8994) lr 2.2949e-04 eta 0:03:11
epoch [41/50] batch [40/162] time 0.100 (0.108) data 0.000 (0.008) loss 2.0895 (2.1838) teacher_loss 0.1073 (0.1756) loss_zs_kd 0.0722 (0.0559) loss_oracle 0.8970 (0.9439) kd_loss 1.4976 (1.5083) acc 96.8750 (95.5469) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0459 (0.0337) teacher/usage_max 0.5208 (0.5816) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.2363 (0.2483) nleep/row_max_mean 1500.4917 (1505.1730) nleep/row_max_std 54.7622 (49.7420) nleep/row_min_mean 1468.4271 (1470.3576) lr 2.2949e-04 eta 0:02:50
epoch [41/50] batch [60/162] time 0.098 (0.104) data 0.001 (0.006) loss 2.7211 (2.1812) teacher_loss 0.6961 (0.1728) loss_zs_kd 0.0752 (0.0583) loss_oracle 0.9513 (0.9352) kd_loss 1.5117 (1.5116) acc 81.2500 (95.6771) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0269 (0.0295) teacher/usage_max 0.4996 (0.5717) teacher/usage_min 0.0048 (0.0023) teacher/usage_std 0.2323 (0.2457) nleep/row_max_mean 1496.7104 (1504.9512) nleep/row_max_std 42.4270 (48.8182) nleep/row_min_mean 1463.3188 (1470.3321) lr 2.2949e-04 eta 0:02:42
epoch [41/50] batch [80/162] time 0.096 (0.103) data 0.000 (0.004) loss 2.2255 (2.1616) teacher_loss 0.2356 (0.1553) loss_zs_kd 0.0463 (0.0590) loss_oracle 0.9825 (0.9309) kd_loss 1.4755 (1.5112) acc 90.6250 (96.0938) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0369 (0.0288) teacher/usage_max 0.5862 (0.5701) teacher/usage_min 0.0313 (0.0033) teacher/usage_std 0.2292 (0.2448) nleep/row_max_mean 1514.6653 (1504.8398) nleep/row_max_std 40.5809 (48.3145) nleep/row_min_mean 1483.4324 (1470.8137) lr 2.2949e-04 eta 0:02:38
epoch [41/50] batch [100/162] time 0.101 (0.101) data 0.000 (0.004) loss 2.1585 (2.1671) teacher_loss 0.1152 (0.1550) loss_zs_kd 0.0455 (0.0592) loss_oracle 0.9934 (0.9397) kd_loss 1.5238 (1.5127) acc 93.7500 (96.1875) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5727) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0188 (0.0279) teacher/usage_max 0.5894 (0.5703) teacher/usage_min 0.0007 (0.0028) teacher/usage_std 0.2464 (0.2450) nleep/row_max_mean 1499.1116 (1504.2000) nleep/row_max_std 51.0176 (47.7906) nleep/row_min_mean 1468.4396 (1470.4189) lr 2.2949e-04 eta 0:02:33
epoch [41/50] batch [120/162] time 0.098 (0.100) data 0.000 (0.003) loss 2.1045 (2.1698) teacher_loss 0.0570 (0.1551) loss_zs_kd 0.0865 (0.0591) loss_oracle 0.9983 (0.9442) kd_loss 1.5051 (1.5130) acc 100.0000 (96.1198) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0350 (0.0271) teacher/usage_max 0.5097 (0.5689) teacher/usage_min 0.0033 (0.0032) teacher/usage_std 0.2336 (0.2445) nleep/row_max_mean 1506.9937 (1503.5845) nleep/row_max_std 52.6702 (48.3848) nleep/row_min_mean 1473.5486 (1470.0055) lr 2.2949e-04 eta 0:02:30
epoch [41/50] batch [140/162] time 0.103 (0.100) data 0.000 (0.003) loss 2.1750 (2.1660) teacher_loss 0.2055 (0.1552) loss_zs_kd 0.0414 (0.0588) loss_oracle 0.8729 (0.9378) kd_loss 1.5123 (1.5126) acc 90.6250 (96.0938) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0301 (0.0272) teacher/usage_max 0.5677 (0.5689) teacher/usage_min 0.0008 (0.0035) teacher/usage_std 0.2416 (0.2443) nleep/row_max_mean 1505.7550 (1503.0524) nleep/row_max_std 49.5003 (48.6277) nleep/row_min_mean 1475.3198 (1469.7512) lr 2.2949e-04 eta 0:02:27
epoch [41/50] batch [160/162] time 0.084 (0.098) data 0.000 (0.002) loss 2.0866 (2.1641) teacher_loss 0.0724 (0.1566) loss_zs_kd 0.0629 (0.0581) loss_oracle 0.8809 (0.9314) kd_loss 1.5423 (1.5128) acc 96.8750 (95.9766) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0009 (0.0265) teacher/usage_max 0.5936 (0.5684) teacher/usage_min 0.0001 (0.0041) teacher/usage_std 0.2478 (0.2438) nleep/row_max_mean 1516.1666 (1502.4239) nleep/row_max_std 43.3491 (48.9333) nleep/row_min_mean 1481.6302 (1469.3452) lr 2.2949e-04 eta 0:02:23
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,917
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 87.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,696
* accuracy: 82.1%
* error: 17.9%
* macro_f1: 79.3%
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 39 *******
epoch [42/50] batch [20/162] time 0.092 (0.109) data 0.001 (0.017) loss 2.2361 (2.1152) teacher_loss 0.2382 (0.1392) loss_zs_kd 0.0732 (0.0615) loss_oracle 0.8908 (0.8512) kd_loss 1.5159 (1.5197) acc 87.5000 (95.9375) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0256 (0.0213) teacher/usage_max 0.5565 (0.5847) teacher/usage_min 0.0019 (0.0023) teacher/usage_std 0.2390 (0.2480) nleep/row_max_mean 1503.1592 (1498.6751) nleep/row_max_std 54.2062 (50.9008) nleep/row_min_mean 1469.9417 (1467.1940) lr 1.9098e-04 eta 0:02:37
epoch [42/50] batch [40/162] time 0.074 (0.100) data 0.000 (0.009) loss 2.1771 (2.1124) teacher_loss 0.2331 (0.1178) loss_zs_kd 0.0552 (0.0634) loss_oracle 0.8007 (0.8866) kd_loss 1.5160 (1.5196) acc 93.7500 (96.5625) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0269 (0.0208) teacher/usage_max 0.6129 (0.5741) teacher/usage_min 0.0003 (0.0029) teacher/usage_std 0.2529 (0.2446) nleep/row_max_mean 1492.2346 (1500.3508) nleep/row_max_std 47.8610 (50.0398) nleep/row_min_mean 1462.7098 (1468.2389) lr 1.9098e-04 eta 0:02:21
epoch [42/50] batch [60/162] time 0.093 (0.097) data 0.001 (0.006) loss 2.0671 (2.1178) teacher_loss 0.0994 (0.1303) loss_zs_kd 0.0594 (0.0637) loss_oracle 0.9313 (0.8828) kd_loss 1.4724 (1.5142) acc 96.8750 (96.4062) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0510 (0.0225) teacher/usage_max 0.5573 (0.5733) teacher/usage_min 0.0202 (0.0066) teacher/usage_std 0.2282 (0.2430) nleep/row_max_mean 1502.2539 (1498.9460) nleep/row_max_std 47.5868 (50.4395) nleep/row_min_mean 1474.2629 (1467.3685) lr 1.9098e-04 eta 0:02:15
epoch [42/50] batch [80/162] time 0.100 (0.096) data 0.000 (0.004) loss 2.1830 (2.1110) teacher_loss 0.1592 (0.1292) loss_zs_kd 0.0506 (0.0621) loss_oracle 0.9392 (0.8779) kd_loss 1.5289 (1.5119) acc 96.8750 (96.4844) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0141 (0.0238) teacher/usage_max 0.5273 (0.5695) teacher/usage_min 0.0003 (0.0077) teacher/usage_std 0.2366 (0.2416) nleep/row_max_mean 1492.1597 (1498.7141) nleep/row_max_std 56.0357 (50.6670) nleep/row_min_mean 1459.9382 (1467.2400) lr 1.9098e-04 eta 0:02:12
epoch [42/50] batch [100/162] time 0.092 (0.096) data 0.000 (0.004) loss 2.1213 (2.1072) teacher_loss 0.0909 (0.1241) loss_zs_kd 0.0781 (0.0626) loss_oracle 0.8999 (0.8801) kd_loss 1.5414 (1.5118) acc 96.8750 (96.6875) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0016 (0.0242) teacher/usage_max 0.5313 (0.5658) teacher/usage_min 0.0001 (0.0073) teacher/usage_std 0.2370 (0.2408) nleep/row_max_mean 1484.8647 (1498.9244) nleep/row_max_std 56.0751 (51.1661) nleep/row_min_mean 1451.3639 (1467.3341) lr 1.9098e-04 eta 0:02:10
epoch [42/50] batch [120/162] time 0.112 (0.100) data 0.001 (0.003) loss 2.1001 (2.1068) teacher_loss 0.1093 (0.1288) loss_zs_kd 0.0661 (0.0631) loss_oracle 0.9250 (0.8721) kd_loss 1.4953 (1.5104) acc 96.8750 (96.4583) gate/entropy 0.9789 (0.9788) gate/usage_max 0.5725 (0.5726) gate/usage_min 0.2137 (0.2136) gate/usage_std 0.1691 (0.1692) teacher/entropy 0.0399 (0.0250) teacher/usage_max 0.6724 (0.5675) teacher/usage_min 0.0080 (0.0079) teacher/usage_std 0.2714 (0.2407) nleep/row_max_mean 1491.1754 (1498.5853) nleep/row_max_std 54.6800 (51.3789) nleep/row_min_mean 1460.9951 (1467.2101) lr 1.9098e-04 eta 0:02:14
epoch [42/50] batch [140/162] time 0.096 (0.100) data 0.000 (0.003) loss 2.3171 (2.1074) teacher_loss 0.2285 (0.1307) loss_zs_kd 0.0817 (0.0629) loss_oracle 1.0666 (0.8740) kd_loss 1.5144 (1.5082) acc 93.7500 (96.5402) gate/entropy 0.9789 (0.9788) gate/usage_max 0.5725 (0.5726) gate/usage_min 0.2137 (0.2136) gate/usage_std 0.1691 (0.1692) teacher/entropy 0.0283 (0.0267) teacher/usage_max 0.6075 (0.5653) teacher/usage_min 0.0002 (0.0083) teacher/usage_std 0.2514 (0.2399) nleep/row_max_mean 1488.1294 (1498.0153) nleep/row_max_std 62.4916 (51.9453) nleep/row_min_mean 1454.1404 (1466.8947) lr 1.9098e-04 eta 0:02:11
epoch [42/50] batch [160/162] time 0.092 (0.099) data 0.000 (0.002) loss 2.1837 (2.1166) teacher_loss 0.1083 (0.1363) loss_zs_kd 0.0773 (0.0632) loss_oracle 0.9976 (0.8811) kd_loss 1.5380 (1.5081) acc 96.8750 (96.4062) gate/entropy 0.9789 (0.9788) gate/usage_max 0.5725 (0.5726) gate/usage_min 0.2137 (0.2136) gate/usage_std 0.1691 (0.1692) teacher/entropy 0.0047 (0.0269) teacher/usage_max 0.5629 (0.5641) teacher/usage_min 0.0002 (0.0083) teacher/usage_std 0.2411 (0.2395) nleep/row_max_mean 1493.5122 (1497.6021) nleep/row_max_std 52.2790 (52.1682) nleep/row_min_mean 1460.5632 (1466.5748) lr 1.9098e-04 eta 0:02:08
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,918
* accuracy: 85.9%
* error: 14.1%
* macro_f1: 87.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,699
* accuracy: 82.2%
* error: 17.8%
* macro_f1: 78.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     82.2%, epoch: 42 *******
epoch [43/50] batch [20/162] time 0.103 (0.116) data 0.000 (0.021) loss 2.0432 (2.1221) teacher_loss 0.1115 (0.1613) loss_zs_kd 0.0643 (0.0602) loss_oracle 0.7738 (0.8570) kd_loss 1.5127 (1.5023) acc 93.7500 (94.5312) gate/entropy 0.9790 (0.9789) gate/usage_max 0.5724 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0295 (0.0290) teacher/usage_max 0.5532 (0.5691) teacher/usage_min 0.0006 (0.0120) teacher/usage_std 0.2393 (0.2397) nleep/row_max_mean 1466.0109 (1492.3112) nleep/row_max_std 61.1717 (57.0149) nleep/row_min_mean 1437.6167 (1462.7384) lr 1.5567e-04 eta 0:02:27
epoch [43/50] batch [40/162] time 0.085 (0.102) data 0.000 (0.010) loss 2.1760 (2.1272) teacher_loss 0.1856 (0.1551) loss_zs_kd 0.0517 (0.0603) loss_oracle 1.0019 (0.8762) kd_loss 1.4636 (1.5038) acc 93.7500 (95.3125) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5726 (0.5725) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0630 (0.0287) teacher/usage_max 0.5384 (0.5675) teacher/usage_min 0.0169 (0.0107) teacher/usage_std 0.2270 (0.2394) nleep/row_max_mean 1506.8369 (1492.8185) nleep/row_max_std 53.3341 (57.5921) nleep/row_min_mean 1477.6023 (1463.1238) lr 1.5567e-04 eta 0:02:07
epoch [43/50] batch [60/162] time 0.096 (0.098) data 0.001 (0.007) loss 2.3141 (2.1153) teacher_loss 0.4079 (0.1469) loss_zs_kd 0.0854 (0.0613) loss_oracle 0.8569 (0.8753) kd_loss 1.4351 (1.5001) acc 90.6250 (95.7812) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5727 (0.5725) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0819 (0.0305) teacher/usage_max 0.5322 (0.5656) teacher/usage_min 0.0267 (0.0127) teacher/usage_std 0.2200 (0.2377) nleep/row_max_mean 1487.7983 (1491.9413) nleep/row_max_std 65.5443 (57.4435) nleep/row_min_mean 1457.8904 (1462.3603) lr 1.5567e-04 eta 0:02:01
epoch [43/50] batch [80/162] time 0.083 (0.096) data 0.000 (0.005) loss 2.0448 (2.1032) teacher_loss 0.1434 (0.1419) loss_zs_kd 0.0537 (0.0602) loss_oracle 0.8622 (0.8683) kd_loss 1.4434 (1.4971) acc 93.7500 (95.9375) gate/entropy 0.9789 (0.9789) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0381 (0.0319) teacher/usage_max 0.5611 (0.5675) teacher/usage_min 0.0625 (0.0143) teacher/usage_std 0.2058 (0.2370) nleep/row_max_mean 1506.1479 (1492.8136) nleep/row_max_std 44.4578 (57.0618) nleep/row_min_mean 1477.8329 (1463.2469) lr 1.5567e-04 eta 0:01:56
epoch [43/50] batch [100/162] time 0.097 (0.095) data 0.000 (0.004) loss 2.0308 (2.0935) teacher_loss 0.1078 (0.1397) loss_zs_kd 0.0488 (0.0594) loss_oracle 0.9206 (0.8612) kd_loss 1.4383 (1.4935) acc 96.8750 (96.0938) gate/entropy 0.9789 (0.9789) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0504 (0.0338) teacher/usage_max 0.5513 (0.5657) teacher/usage_min 0.0549 (0.0160) teacher/usage_std 0.2071 (0.2357) nleep/row_max_mean 1508.5559 (1492.6225) nleep/row_max_std 48.7948 (56.7261) nleep/row_min_mean 1477.1030 (1463.1798) lr 1.5567e-04 eta 0:01:53
epoch [43/50] batch [120/162] time 0.091 (0.094) data 0.000 (0.004) loss 1.9757 (2.0956) teacher_loss 0.1154 (0.1409) loss_zs_kd 0.0779 (0.0600) loss_oracle 0.6628 (0.8622) kd_loss 1.4899 (1.4936) acc 96.8750 (96.1979) gate/entropy 0.9789 (0.9789) gate/usage_max 0.5726 (0.5725) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0529 (0.0344) teacher/usage_max 0.6950 (0.5672) teacher/usage_min 0.0004 (0.0152) teacher/usage_std 0.2843 (0.2367) nleep/row_max_mean 1489.5654 (1493.3128) nleep/row_max_std 51.7179 (56.5089) nleep/row_min_mean 1462.7859 (1463.9046) lr 1.5567e-04 eta 0:01:50
epoch [43/50] batch [140/162] time 0.095 (0.093) data 0.000 (0.003) loss 2.0448 (2.0944) teacher_loss 0.1046 (0.1396) loss_zs_kd 0.0575 (0.0606) loss_oracle 0.9040 (0.8622) kd_loss 1.4594 (1.4934) acc 96.8750 (96.2500) gate/entropy 0.9790 (0.9789) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0770 (0.0349) teacher/usage_max 0.5340 (0.5680) teacher/usage_min 0.0064 (0.0150) teacher/usage_std 0.2331 (0.2372) nleep/row_max_mean 1480.0923 (1492.8678) nleep/row_max_std 51.6749 (56.3073) nleep/row_min_mean 1450.3937 (1463.5238) lr 1.5567e-04 eta 0:01:47
epoch [43/50] batch [160/162] time 0.085 (0.092) data 0.000 (0.003) loss 2.0399 (2.0889) teacher_loss 0.0362 (0.1370) loss_zs_kd 0.0608 (0.0607) loss_oracle 0.8885 (0.8582) kd_loss 1.5290 (1.4925) acc 100.0000 (96.3477) gate/entropy 0.9789 (0.9789) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0138 (0.0362) teacher/usage_max 0.5649 (0.5686) teacher/usage_min 0.0001 (0.0146) teacher/usage_std 0.2415 (0.2375) nleep/row_max_mean 1491.3939 (1493.5523) nleep/row_max_std 63.4742 (55.8592) nleep/row_min_mean 1461.5778 (1464.2464) lr 1.5567e-04 eta 0:01:44
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,934
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 88.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,702
* accuracy: 82.3%
* error: 17.7%
* macro_f1: 77.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     82.3%, epoch: 43 *******
epoch [44/50] batch [20/162] time 0.085 (0.105) data 0.000 (0.021) loss 2.0769 (2.0820) teacher_loss 0.1656 (0.1363) loss_zs_kd 0.0589 (0.0607) loss_oracle 0.9026 (0.8828) kd_loss 1.4305 (1.4739) acc 96.8750 (96.5625) gate/entropy 0.9790 (0.9789) gate/usage_max 0.5724 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0837 (0.0524) teacher/usage_max 0.5296 (0.5491) teacher/usage_min 0.0290 (0.0169) teacher/usage_std 0.2182 (0.2310) nleep/row_max_mean 1488.4714 (1493.6374) nleep/row_max_std 45.7582 (54.3641) nleep/row_min_mean 1459.5212 (1464.9056) lr 1.2369e-04 eta 0:01:56
epoch [44/50] batch [40/162] time 0.074 (0.095) data 0.000 (0.011) loss 2.1441 (2.0646) teacher_loss 0.1169 (0.1239) loss_zs_kd 0.0513 (0.0602) loss_oracle 0.9520 (0.8746) kd_loss 1.5255 (1.4733) acc 96.8750 (96.8750) gate/entropy 0.9790 (0.9789) gate/usage_max 0.5724 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0164 (0.0491) teacher/usage_max 0.5341 (0.5536) teacher/usage_min 0.0009 (0.0208) teacher/usage_std 0.2367 (0.2301) nleep/row_max_mean 1488.5647 (1495.8311) nleep/row_max_std 56.0076 (53.1412) nleep/row_min_mean 1460.5688 (1467.0012) lr 1.2369e-04 eta 0:01:44
epoch [44/50] batch [60/162] time 0.090 (0.093) data 0.001 (0.007) loss 2.0108 (2.0720) teacher_loss 0.0273 (0.1364) loss_zs_kd 0.0652 (0.0599) loss_oracle 0.9375 (0.8568) kd_loss 1.4822 (1.4772) acc 100.0000 (96.4062) gate/entropy 0.9790 (0.9789) gate/usage_max 0.5724 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0499 (0.0481) teacher/usage_max 0.5061 (0.5617) teacher/usage_min 0.0109 (0.0179) teacher/usage_std 0.2282 (0.2338) nleep/row_max_mean 1483.6211 (1495.9747) nleep/row_max_std 55.5322 (52.4172) nleep/row_min_mean 1452.0302 (1466.8878) lr 1.2369e-04 eta 0:01:39
epoch [44/50] batch [80/162] time 0.086 (0.090) data 0.000 (0.006) loss 2.0229 (2.0742) teacher_loss 0.1226 (0.1391) loss_zs_kd 0.0649 (0.0602) loss_oracle 0.8843 (0.8569) kd_loss 1.4257 (1.4765) acc 93.7500 (96.2891) gate/entropy 0.9790 (0.9789) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0814 (0.0469) teacher/usage_max 0.4992 (0.5616) teacher/usage_min 0.0364 (0.0198) teacher/usage_std 0.2104 (0.2330) nleep/row_max_mean 1498.7130 (1496.1090) nleep/row_max_std 50.1918 (52.7780) nleep/row_min_mean 1467.3271 (1466.9641) lr 1.2369e-04 eta 0:01:35
epoch [44/50] batch [100/162] time 0.101 (0.090) data 0.000 (0.004) loss 2.0729 (2.0686) teacher_loss 0.0684 (0.1324) loss_zs_kd 0.0565 (0.0600) loss_oracle 0.9752 (0.8555) kd_loss 1.4886 (1.4784) acc 96.8750 (96.4062) gate/entropy 0.9789 (0.9789) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0214 (0.0455) teacher/usage_max 0.5014 (0.5643) teacher/usage_min 0.0335 (0.0193) teacher/usage_std 0.2125 (0.2341) nleep/row_max_mean 1497.4855 (1496.8256) nleep/row_max_std 60.2829 (52.7090) nleep/row_min_mean 1468.4237 (1467.6433) lr 1.2369e-04 eta 0:01:33
epoch [44/50] batch [120/162] time 0.079 (0.091) data 0.000 (0.004) loss 1.9805 (2.0731) teacher_loss 0.0630 (0.1371) loss_zs_kd 0.0798 (0.0605) loss_oracle 0.7888 (0.8543) kd_loss 1.4832 (1.4787) acc 100.0000 (96.4323) gate/entropy 0.9790 (0.9789) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0494 (0.0450) teacher/usage_max 0.5985 (0.5623) teacher/usage_min 0.0105 (0.0196) teacher/usage_std 0.2435 (0.2333) nleep/row_max_mean 1500.0021 (1496.9923) nleep/row_max_std 47.3119 (52.8597) nleep/row_min_mean 1465.8728 (1467.6404) lr 1.2369e-04 eta 0:01:32
epoch [44/50] batch [140/162] time 0.090 (0.091) data 0.000 (0.003) loss 2.1688 (2.0745) teacher_loss 0.2166 (0.1400) loss_zs_kd 0.0594 (0.0611) loss_oracle 0.8001 (0.8512) kd_loss 1.5224 (1.4784) acc 93.7500 (96.2723) gate/entropy 0.9789 (0.9789) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0196 (0.0442) teacher/usage_max 0.5570 (0.5621) teacher/usage_min 0.0010 (0.0206) teacher/usage_std 0.2396 (0.2325) nleep/row_max_mean 1503.1897 (1496.7940) nleep/row_max_std 48.0429 (53.0768) nleep/row_min_mean 1473.4771 (1467.4081) lr 1.2369e-04 eta 0:01:30
epoch [44/50] batch [160/162] time 0.088 (0.091) data 0.000 (0.003) loss 2.1802 (2.0741) teacher_loss 0.2776 (0.1377) loss_zs_kd 0.0855 (0.0621) loss_oracle 0.8885 (0.8523) kd_loss 1.4156 (1.4792) acc 90.6250 (96.3477) gate/entropy 0.9789 (0.9789) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0600 (0.0436) teacher/usage_max 0.6122 (0.5609) teacher/usage_min 0.0683 (0.0204) teacher/usage_std 0.2222 (0.2321) nleep/row_max_mean 1480.4746 (1496.8161) nleep/row_max_std 61.7933 (53.3443) nleep/row_min_mean 1450.1909 (1467.3586) lr 1.2369e-04 eta 0:01:28
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,925
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 88.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,710
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 78.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     82.6%, epoch: 44 *******
epoch [45/50] batch [20/162] time 0.098 (0.117) data 0.000 (0.021) loss 2.2263 (2.0281) teacher_loss 0.3577 (0.1176) loss_zs_kd 0.0663 (0.0661) loss_oracle 0.8567 (0.8311) kd_loss 1.4071 (1.4619) acc 93.7500 (97.5000) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0897 (0.0559) teacher/usage_max 0.4888 (0.5684) teacher/usage_min 0.0468 (0.0255) teacher/usage_std 0.2029 (0.2318) nleep/row_max_mean 1473.7942 (1495.8703) nleep/row_max_std 66.0387 (56.5234) nleep/row_min_mean 1446.5825 (1466.6963) lr 9.5173e-05 eta 0:01:51
epoch [45/50] batch [40/162] time 0.092 (0.105) data 0.000 (0.011) loss 2.0957 (2.0415) teacher_loss 0.2993 (0.1417) loss_zs_kd 0.0479 (0.0657) loss_oracle 0.7070 (0.8174) kd_loss 1.4189 (1.4582) acc 93.7500 (95.9375) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0497 (0.0557) teacher/usage_max 0.5175 (0.5578) teacher/usage_min 0.0754 (0.0294) teacher/usage_std 0.1879 (0.2260) nleep/row_max_mean 1492.9348 (1493.4674) nleep/row_max_std 64.0646 (57.1812) nleep/row_min_mean 1468.6805 (1464.3823) lr 9.5173e-05 eta 0:01:38
epoch [45/50] batch [60/162] time 0.086 (0.102) data 0.001 (0.007) loss 1.8863 (2.0300) teacher_loss 0.0283 (0.1217) loss_zs_kd 0.0407 (0.0660) loss_oracle 0.7517 (0.8114) kd_loss 1.4618 (1.4695) acc 100.0000 (96.6667) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0594 (0.0496) teacher/usage_max 0.5203 (0.5560) teacher/usage_min 0.0220 (0.0241) teacher/usage_std 0.2216 (0.2287) nleep/row_max_mean 1507.0081 (1495.8374) nleep/row_max_std 48.5768 (55.5360) nleep/row_min_mean 1478.8999 (1466.3318) lr 9.5173e-05 eta 0:01:33
epoch [45/50] batch [80/162] time 0.092 (0.101) data 0.000 (0.006) loss 1.9970 (2.0259) teacher_loss 0.0918 (0.1173) loss_zs_kd 0.0544 (0.0657) loss_oracle 0.7654 (0.8057) kd_loss 1.4953 (1.4729) acc 96.8750 (96.6797) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0440 (0.0467) teacher/usage_max 0.5032 (0.5594) teacher/usage_min 0.0035 (0.0236) teacher/usage_std 0.2332 (0.2303) nleep/row_max_mean 1502.8652 (1496.3972) nleep/row_max_std 50.4426 (54.8245) nleep/row_min_mean 1475.9453 (1467.0723) lr 9.5173e-05 eta 0:01:29
epoch [45/50] batch [100/162] time 0.090 (0.098) data 0.000 (0.005) loss 1.9722 (2.0165) teacher_loss 0.1039 (0.1166) loss_zs_kd 0.0606 (0.0645) loss_oracle 0.7759 (0.7981) kd_loss 1.4501 (1.4687) acc 96.8750 (96.7500) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0722 (0.0492) teacher/usage_max 0.5580 (0.5556) teacher/usage_min 0.0210 (0.0253) teacher/usage_std 0.2278 (0.2285) nleep/row_max_mean 1499.0305 (1496.6988) nleep/row_max_std 54.2401 (54.6532) nleep/row_min_mean 1470.2655 (1467.5270) lr 9.5173e-05 eta 0:01:25
epoch [45/50] batch [120/162] time 0.096 (0.096) data 0.000 (0.004) loss 2.0188 (2.0232) teacher_loss 0.0422 (0.1197) loss_zs_kd 0.0584 (0.0646) loss_oracle 0.9377 (0.8037) kd_loss 1.4786 (1.4694) acc 100.0000 (96.7969) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0415 (0.0486) teacher/usage_max 0.4891 (0.5566) teacher/usage_min 0.0231 (0.0253) teacher/usage_std 0.2194 (0.2291) nleep/row_max_mean 1497.5105 (1496.0586) nleep/row_max_std 54.7368 (54.8845) nleep/row_min_mean 1472.0491 (1466.9761) lr 9.5173e-05 eta 0:01:22
epoch [45/50] batch [140/162] time 0.098 (0.098) data 0.000 (0.003) loss 2.0230 (2.0219) teacher_loss 0.1449 (0.1216) loss_zs_kd 0.0578 (0.0644) loss_oracle 0.8138 (0.8012) kd_loss 1.4423 (1.4675) acc 96.8750 (96.6741) gate/entropy 0.9791 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1691) teacher/entropy 0.0451 (0.0488) teacher/usage_max 0.4761 (0.5555) teacher/usage_min 0.0562 (0.0269) teacher/usage_std 0.1960 (0.2280) nleep/row_max_mean 1491.0718 (1495.9304) nleep/row_max_std 56.7205 (55.0961) nleep/row_min_mean 1465.2302 (1466.9262) lr 9.5173e-05 eta 0:01:21
epoch [45/50] batch [160/162] time 0.085 (0.097) data 0.000 (0.003) loss 2.1219 (2.0226) teacher_loss 0.1123 (0.1222) loss_zs_kd 0.0703 (0.0642) loss_oracle 0.9986 (0.8049) kd_loss 1.4752 (1.4658) acc 93.7500 (96.6797) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5726 (0.5724) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0355 (0.0496) teacher/usage_max 0.6421 (0.5551) teacher/usage_min 0.0328 (0.0279) teacher/usage_std 0.2488 (0.2273) nleep/row_max_mean 1493.4020 (1495.6617) nleep/row_max_std 64.7169 (55.3253) nleep/row_min_mean 1467.2533 (1466.7817) lr 9.5173e-05 eta 0:01:18
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,930
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 88.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,716
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 78.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     82.8%, epoch: 45 *******
epoch [46/50] batch [20/162] time 0.085 (0.102) data 0.000 (0.022) loss 1.9239 (2.0212) teacher_loss 0.0677 (0.1448) loss_zs_kd 0.0410 (0.0628) loss_oracle 0.7284 (0.7895) kd_loss 1.4715 (1.4503) acc 100.0000 (96.0938) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0696 (0.0514) teacher/usage_max 0.5115 (0.5532) teacher/usage_min 0.0016 (0.0418) teacher/usage_std 0.2348 (0.2189) nleep/row_max_mean 1487.2440 (1496.4007) nleep/row_max_std 61.2241 (53.5394) nleep/row_min_mean 1461.0835 (1467.5535) lr 7.0224e-05 eta 0:01:20
epoch [46/50] batch [40/162] time 0.089 (0.096) data 0.000 (0.011) loss 2.0526 (2.0296) teacher_loss 0.2121 (0.1516) loss_zs_kd 0.0598 (0.0622) loss_oracle 0.7842 (0.7952) kd_loss 1.4184 (1.4494) acc 93.7500 (95.9375) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0791 (0.0546) teacher/usage_max 0.5387 (0.5488) teacher/usage_min 0.0461 (0.0395) teacher/usage_std 0.2093 (0.2181) nleep/row_max_mean 1495.2819 (1495.1657) nleep/row_max_std 54.7678 (55.1378) nleep/row_min_mean 1468.8480 (1466.5086) lr 7.0224e-05 eta 0:01:14
epoch [46/50] batch [60/162] time 0.096 (0.095) data 0.001 (0.008) loss 2.0878 (2.0201) teacher_loss 0.1313 (0.1375) loss_zs_kd 0.0668 (0.0638) loss_oracle 0.8608 (0.7887) kd_loss 1.4927 (1.4563) acc 96.8750 (96.3542) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5726 (0.5724) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0487 (0.0520) teacher/usage_max 0.5692 (0.5476) teacher/usage_min 0.0017 (0.0350) teacher/usage_std 0.2414 (0.2207) nleep/row_max_mean 1508.5110 (1494.6634) nleep/row_max_std 54.5414 (56.0358) nleep/row_min_mean 1480.3787 (1466.3276) lr 7.0224e-05 eta 0:01:10
epoch [46/50] batch [80/162] time 0.082 (0.093) data 0.000 (0.006) loss 1.8152 (2.0082) teacher_loss 0.1233 (0.1319) loss_zs_kd 0.0430 (0.0633) loss_oracle 0.6725 (0.7870) kd_loss 1.3342 (1.4511) acc 96.8750 (96.5625) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0774 (0.0542) teacher/usage_max 0.4523 (0.5418) teacher/usage_min 0.1332 (0.0381) teacher/usage_std 0.1424 (0.2176) nleep/row_max_mean 1489.2632 (1494.6413) nleep/row_max_std 57.1770 (55.6960) nleep/row_min_mean 1464.9517 (1466.4722) lr 7.0224e-05 eta 0:01:07
epoch [46/50] batch [100/162] time 0.105 (0.092) data 0.000 (0.005) loss 2.0911 (2.0027) teacher_loss 0.0747 (0.1276) loss_zs_kd 0.0746 (0.0623) loss_oracle 0.9286 (0.7888) kd_loss 1.5148 (1.4495) acc 96.8750 (96.6562) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1691) teacher/entropy 0.0234 (0.0555) teacher/usage_max 0.5018 (0.5413) teacher/usage_min 0.0045 (0.0383) teacher/usage_std 0.2325 (0.2176) nleep/row_max_mean 1482.6787 (1494.3876) nleep/row_max_std 50.0521 (55.2149) nleep/row_min_mean 1454.4922 (1466.3702) lr 7.0224e-05 eta 0:01:05
epoch [46/50] batch [120/162] time 0.077 (0.092) data 0.000 (0.004) loss 1.8973 (2.0073) teacher_loss 0.0620 (0.1339) loss_zs_kd 0.0589 (0.0633) loss_oracle 0.6846 (0.7872) kd_loss 1.4636 (1.4482) acc 96.8750 (96.4844) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0562 (0.0557) teacher/usage_max 0.5054 (0.5414) teacher/usage_min 0.0235 (0.0395) teacher/usage_std 0.2195 (0.2169) nleep/row_max_mean 1500.7979 (1494.2734) nleep/row_max_std 58.5687 (55.3554) nleep/row_min_mean 1472.8405 (1466.3836) lr 7.0224e-05 eta 0:01:03
epoch [46/50] batch [140/162] time 0.106 (0.092) data 0.000 (0.003) loss 1.8652 (1.9991) teacher_loss 0.1397 (0.1298) loss_zs_kd 0.0565 (0.0629) loss_oracle 0.6009 (0.7865) kd_loss 1.3968 (1.4446) acc 96.8750 (96.6518) gate/entropy 0.9791 (0.9790) gate/usage_max 0.5723 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1691) teacher/entropy 0.0784 (0.0569) teacher/usage_max 0.5168 (0.5412) teacher/usage_min 0.0685 (0.0419) teacher/usage_std 0.1918 (0.2154) nleep/row_max_mean 1481.6533 (1494.0253) nleep/row_max_std 53.9530 (55.1545) nleep/row_min_mean 1455.1969 (1466.2375) lr 7.0224e-05 eta 0:01:01
epoch [46/50] batch [160/162] time 0.083 (0.091) data 0.000 (0.003) loss 1.9781 (2.0030) teacher_loss 0.1147 (0.1298) loss_zs_kd 0.0644 (0.0625) loss_oracle 0.8050 (0.7911) kd_loss 1.4286 (1.4464) acc 96.8750 (96.6602) gate/entropy 0.9791 (0.9790) gate/usage_max 0.5723 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1691) teacher/entropy 0.0855 (0.0562) teacher/usage_max 0.5885 (0.5442) teacher/usage_min 0.0289 (0.0408) teacher/usage_std 0.2311 (0.2168) nleep/row_max_mean 1475.1992 (1493.7878) nleep/row_max_std 52.4114 (54.8744) nleep/row_min_mean 1448.5775 (1466.1117) lr 7.0224e-05 eta 0:00:59
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,934
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 88.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,715
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 78.1%
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     82.8%, epoch: 45 *******
epoch [47/50] batch [20/162] time 0.094 (0.111) data 0.000 (0.017) loss 1.8823 (1.9595) teacher_loss 0.0338 (0.0896) loss_zs_kd 0.0725 (0.0630) loss_oracle 0.8279 (0.7974) kd_loss 1.3983 (1.4397) acc 100.0000 (97.5000) gate/entropy 0.9791 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0764 (0.0604) teacher/usage_max 0.4788 (0.5527) teacher/usage_min 0.0690 (0.0433) teacher/usage_std 0.1872 (0.2182) nleep/row_max_mean 1491.9017 (1495.7580) nleep/row_max_std 54.5683 (51.1570) nleep/row_min_mean 1463.6804 (1468.4042) lr 4.8943e-05 eta 0:01:09
epoch [47/50] batch [40/162] time 0.084 (0.110) data 0.000 (0.009) loss 1.9882 (1.9555) teacher_loss 0.2324 (0.0973) loss_zs_kd 0.0697 (0.0629) loss_oracle 0.6301 (0.7855) kd_loss 1.4059 (1.4340) acc 87.5000 (97.4219) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0482 (0.0631) teacher/usage_max 0.4715 (0.5387) teacher/usage_min 0.0900 (0.0463) teacher/usage_std 0.1726 (0.2128) nleep/row_max_mean 1495.9807 (1495.0808) nleep/row_max_std 51.8132 (51.6650) nleep/row_min_mean 1469.3604 (1467.7695) lr 4.8943e-05 eta 0:01:07
epoch [47/50] batch [60/162] time 0.101 (0.105) data 0.001 (0.006) loss 2.2432 (1.9651) teacher_loss 0.2695 (0.1214) loss_zs_kd 0.0767 (0.0645) loss_oracle 0.8514 (0.7839) kd_loss 1.5096 (1.4195) acc 90.6250 (96.8229) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0328 (0.0699) teacher/usage_max 0.5003 (0.5289) teacher/usage_min 0.0003 (0.0542) teacher/usage_std 0.2355 (0.2063) nleep/row_max_mean 1490.0559 (1494.9499) nleep/row_max_std 51.9824 (51.9369) nleep/row_min_mean 1464.0466 (1467.3033) lr 4.8943e-05 eta 0:01:01
epoch [47/50] batch [80/162] time 0.099 (0.102) data 0.000 (0.004) loss 1.9741 (1.9653) teacher_loss 0.1520 (0.1180) loss_zs_kd 0.0782 (0.0640) loss_oracle 0.8071 (0.7865) kd_loss 1.3794 (1.4221) acc 96.8750 (96.9922) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0797 (0.0680) teacher/usage_max 0.5122 (0.5329) teacher/usage_min 0.0850 (0.0535) teacher/usage_std 0.1812 (0.2072) nleep/row_max_mean 1498.3290 (1495.3180) nleep/row_max_std 50.0894 (51.5092) nleep/row_min_mean 1470.1255 (1467.6572) lr 4.8943e-05 eta 0:00:58
epoch [47/50] batch [100/162] time 0.097 (0.101) data 0.000 (0.004) loss 1.9592 (1.9666) teacher_loss 0.0779 (0.1172) loss_zs_kd 0.0642 (0.0638) loss_oracle 0.8443 (0.7919) kd_loss 1.4271 (1.4215) acc 100.0000 (97.0938) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0402 (0.0676) teacher/usage_max 0.5151 (0.5343) teacher/usage_min 0.0768 (0.0545) teacher/usage_std 0.1866 (0.2071) nleep/row_max_mean 1513.2605 (1496.1384) nleep/row_max_std 46.1563 (51.2042) nleep/row_min_mean 1485.8258 (1468.4391) lr 4.8943e-05 eta 0:00:55
epoch [47/50] batch [120/162] time 0.090 (0.100) data 0.000 (0.003) loss 1.8134 (1.9672) teacher_loss 0.0853 (0.1187) loss_zs_kd 0.0646 (0.0636) loss_oracle 0.7078 (0.7931) kd_loss 1.3419 (1.4202) acc 100.0000 (97.1094) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.1204 (0.0674) teacher/usage_max 0.5046 (0.5325) teacher/usage_min 0.0816 (0.0559) teacher/usage_std 0.1818 (0.2060) nleep/row_max_mean 1495.1106 (1496.1488) nleep/row_max_std 54.9216 (51.2696) nleep/row_min_mean 1469.2400 (1468.5341) lr 4.8943e-05 eta 0:00:52
epoch [47/50] batch [140/162] time 0.091 (0.099) data 0.000 (0.003) loss 1.9731 (1.9667) teacher_loss 0.1683 (0.1194) loss_zs_kd 0.0740 (0.0633) loss_oracle 0.6515 (0.7922) kd_loss 1.4421 (1.4196) acc 96.8750 (97.0536) gate/entropy 0.9791 (0.9790) gate/usage_max 0.5723 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0593 (0.0674) teacher/usage_max 0.6184 (0.5327) teacher/usage_min 0.0419 (0.0566) teacher/usage_std 0.2354 (0.2057) nleep/row_max_mean 1476.3732 (1496.1154) nleep/row_max_std 54.2929 (51.0875) nleep/row_min_mean 1450.0457 (1468.5767) lr 4.8943e-05 eta 0:00:50
epoch [47/50] batch [160/162] time 0.090 (0.098) data 0.000 (0.002) loss 1.9761 (1.9751) teacher_loss 0.1310 (0.1242) loss_zs_kd 0.0480 (0.0629) loss_oracle 0.8229 (0.7974) kd_loss 1.4097 (1.4207) acc 96.8750 (96.7773) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0602 (0.0662) teacher/usage_max 0.5213 (0.5336) teacher/usage_min 0.0739 (0.0566) teacher/usage_std 0.1895 (0.2057) nleep/row_max_mean 1494.7224 (1496.1395) nleep/row_max_std 42.1146 (51.1447) nleep/row_min_mean 1470.5072 (1468.6711) lr 4.8943e-05 eta 0:00:47
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,927
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 88.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,719
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 78.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     82.8%, epoch: 47 *******
epoch [48/50] batch [20/162] time 0.100 (0.117) data 0.000 (0.019) loss 1.7913 (1.9617) teacher_loss 0.0677 (0.1154) loss_zs_kd 0.0402 (0.0617) loss_oracle 0.6587 (0.8035) kd_loss 1.3741 (1.4137) acc 96.8750 (96.7188) gate/entropy 0.9791 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0815 (0.0605) teacher/usage_max 0.5228 (0.5180) teacher/usage_min 0.0884 (0.0695) teacher/usage_std 0.1816 (0.1941) nleep/row_max_mean 1482.6564 (1494.9373) nleep/row_max_std 61.9600 (50.9691) nleep/row_min_mean 1458.0809 (1467.5144) lr 3.1417e-05 eta 0:00:54
epoch [48/50] batch [40/162] time 0.102 (0.107) data 0.000 (0.010) loss 2.1672 (1.9563) teacher_loss 0.2824 (0.1088) loss_zs_kd 0.0386 (0.0613) loss_oracle 0.7854 (0.8035) kd_loss 1.4728 (1.4150) acc 90.6250 (96.8750) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0426 (0.0614) teacher/usage_max 0.6848 (0.5298) teacher/usage_min 0.0275 (0.0673) teacher/usage_std 0.2703 (0.1985) nleep/row_max_mean 1485.9969 (1495.2862) nleep/row_max_std 63.5627 (51.5684) nleep/row_min_mean 1462.6270 (1468.0062) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [60/162] time 0.102 (0.104) data 0.001 (0.007) loss 2.2968 (1.9639) teacher_loss 0.3089 (0.1160) loss_zs_kd 0.0680 (0.0604) loss_oracle 0.9456 (0.8004) kd_loss 1.4811 (1.4175) acc 90.6250 (96.6146) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0504 (0.0638) teacher/usage_max 0.5424 (0.5319) teacher/usage_min 0.0114 (0.0623) teacher/usage_std 0.2310 (0.2021) nleep/row_max_mean 1501.7843 (1495.5923) nleep/row_max_std 53.7752 (51.0230) nleep/row_min_mean 1471.4752 (1468.3653) lr 3.1417e-05 eta 0:00:44
epoch [48/50] batch [80/162] time 0.094 (0.101) data 0.000 (0.005) loss 2.1056 (1.9659) teacher_loss 0.1916 (0.1115) loss_zs_kd 0.0548 (0.0616) loss_oracle 0.8068 (0.7980) kd_loss 1.4833 (1.4246) acc 90.6250 (96.7969) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0291 (0.0615) teacher/usage_max 0.4960 (0.5387) teacher/usage_min 0.0308 (0.0574) teacher/usage_std 0.2142 (0.2065) nleep/row_max_mean 1489.6008 (1494.9294) nleep/row_max_std 56.1979 (51.5364) nleep/row_min_mean 1465.5066 (1467.7621) lr 3.1417e-05 eta 0:00:41
epoch [48/50] batch [100/162] time 0.115 (0.101) data 0.000 (0.004) loss 2.0656 (1.9682) teacher_loss 0.2503 (0.1178) loss_zs_kd 0.0681 (0.0629) loss_oracle 0.7465 (0.7923) kd_loss 1.4081 (1.4229) acc 93.7500 (96.6562) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0366 (0.0633) teacher/usage_max 0.5010 (0.5393) teacher/usage_min 0.0998 (0.0574) teacher/usage_std 0.1703 (0.2065) nleep/row_max_mean 1498.2733 (1494.9318) nleep/row_max_std 49.8141 (51.5414) nleep/row_min_mean 1470.8870 (1467.6687) lr 3.1417e-05 eta 0:00:39
epoch [48/50] batch [120/162] time 0.095 (0.101) data 0.000 (0.003) loss 1.9213 (1.9762) teacher_loss 0.0945 (0.1261) loss_zs_kd 0.0618 (0.0636) loss_oracle 0.7737 (0.7923) kd_loss 1.4090 (1.4222) acc 96.8750 (96.5104) gate/entropy 0.9791 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0803 (0.0631) teacher/usage_max 0.4866 (0.5370) teacher/usage_min 0.0540 (0.0583) teacher/usage_std 0.1978 (0.2054) nleep/row_max_mean 1482.2039 (1494.7035) nleep/row_max_std 56.4141 (51.5012) nleep/row_min_mean 1457.3757 (1467.3232) lr 3.1417e-05 eta 0:00:36
epoch [48/50] batch [140/162] time 0.075 (0.101) data 0.000 (0.003) loss 2.0267 (1.9794) teacher_loss 0.1814 (0.1259) loss_zs_kd 0.0476 (0.0632) loss_oracle 0.7046 (0.7934) kd_loss 1.4692 (1.4253) acc 96.8750 (96.5402) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0125 (0.0609) teacher/usage_max 0.4693 (0.5358) teacher/usage_min 0.0619 (0.0574) teacher/usage_std 0.1920 (0.2055) nleep/row_max_mean 1502.2415 (1495.1734) nleep/row_max_std 58.0624 (51.6833) nleep/row_min_mean 1476.1162 (1467.8182) lr 3.1417e-05 eta 0:00:35
epoch [48/50] batch [160/162] time 0.085 (0.102) data 0.000 (0.003) loss 1.8816 (1.9816) teacher_loss 0.0357 (0.1277) loss_zs_kd 0.0580 (0.0635) loss_oracle 0.8414 (0.7922) kd_loss 1.3961 (1.4261) acc 100.0000 (96.5039) gate/entropy 0.9791 (0.9790) gate/usage_max 0.5723 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0861 (0.0591) teacher/usage_max 0.4700 (0.5351) teacher/usage_min 0.0614 (0.0584) teacher/usage_std 0.1923 (0.2050) nleep/row_max_mean 1492.6425 (1495.5627) nleep/row_max_std 51.3658 (52.0278) nleep/row_min_mean 1465.8350 (1468.1248) lr 3.1417e-05 eta 0:00:33
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,931
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 88.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,721
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 78.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     82.9%, epoch: 48 *******
epoch [49/50] batch [20/162] time 0.106 (0.104) data 0.000 (0.014) loss 1.8287 (1.9759) teacher_loss 0.0379 (0.1383) loss_zs_kd 0.0702 (0.0668) loss_oracle 0.7057 (0.7932) kd_loss 1.4029 (1.4076) acc 100.0000 (95.9375) gate/entropy 0.9790 (0.9791) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0798 (0.0623) teacher/usage_max 0.5363 (0.5145) teacher/usage_min 0.0609 (0.0739) teacher/usage_std 0.2002 (0.1896) nleep/row_max_mean 1487.2542 (1493.5122) nleep/row_max_std 54.5889 (51.3564) nleep/row_min_mean 1460.8147 (1465.6994) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [40/162] time 0.104 (0.102) data 0.000 (0.007) loss 2.0251 (1.9905) teacher_loss 0.1052 (0.1363) loss_zs_kd 0.0554 (0.0616) loss_oracle 0.7895 (0.7992) kd_loss 1.4975 (1.4239) acc 96.8750 (96.0156) gate/entropy 0.9791 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0384 (0.0618) teacher/usage_max 0.5850 (0.5269) teacher/usage_min 0.0069 (0.0578) teacher/usage_std 0.2419 (0.2019) nleep/row_max_mean 1512.5265 (1493.9567) nleep/row_max_std 32.9081 (52.0803) nleep/row_min_mean 1481.9541 (1466.5639) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [60/162] time 0.096 (0.098) data 0.001 (0.005) loss 2.0414 (1.9854) teacher_loss 0.2089 (0.1319) loss_zs_kd 0.0609 (0.0620) loss_oracle 0.7151 (0.8010) kd_loss 1.4445 (1.4221) acc 90.6250 (96.0938) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0444 (0.0586) teacher/usage_max 0.4763 (0.5308) teacher/usage_min 0.0546 (0.0630) teacher/usage_std 0.1971 (0.2005) nleep/row_max_mean 1489.1545 (1495.4878) nleep/row_max_std 63.6142 (51.8568) nleep/row_min_mean 1461.8959 (1467.9078) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [80/162] time 0.091 (0.097) data 0.000 (0.004) loss 1.8264 (1.9788) teacher_loss 0.1396 (0.1321) loss_zs_kd 0.0628 (0.0620) loss_oracle 0.7729 (0.7956) kd_loss 1.2690 (1.4178) acc 96.8750 (96.2500) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.1583 (0.0614) teacher/usage_max 0.4543 (0.5308) teacher/usage_min 0.1172 (0.0644) teacher/usage_std 0.1532 (0.1999) nleep/row_max_mean 1499.7343 (1496.1932) nleep/row_max_std 41.0021 (52.3319) nleep/row_min_mean 1473.7439 (1468.6560) lr 1.7713e-05 eta 0:00:23
epoch [49/50] batch [100/162] time 0.098 (0.097) data 0.000 (0.003) loss 2.1485 (1.9769) teacher_loss 0.2641 (0.1295) loss_zs_kd 0.0675 (0.0628) loss_oracle 0.8300 (0.7960) kd_loss 1.4356 (1.4179) acc 93.7500 (96.4062) gate/entropy 0.9791 (0.9790) gate/usage_max 0.5723 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0692 (0.0617) teacher/usage_max 0.4857 (0.5340) teacher/usage_min 0.0383 (0.0640) teacher/usage_std 0.2086 (0.2009) nleep/row_max_mean 1488.9023 (1496.8329) nleep/row_max_std 54.2058 (52.2870) nleep/row_min_mean 1461.1387 (1469.2354) lr 1.7713e-05 eta 0:00:21
epoch [49/50] batch [120/162] time 0.097 (0.097) data 0.000 (0.003) loss 1.8853 (1.9770) teacher_loss 0.0588 (0.1301) loss_zs_kd 0.0633 (0.0634) loss_oracle 0.7359 (0.7934) kd_loss 1.4269 (1.4184) acc 100.0000 (96.4583) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0759 (0.0622) teacher/usage_max 0.5248 (0.5378) teacher/usage_min 0.0405 (0.0630) teacher/usage_std 0.2103 (0.2025) nleep/row_max_mean 1502.3129 (1496.8342) nleep/row_max_std 45.1367 (51.9580) nleep/row_min_mean 1475.9161 (1469.2736) lr 1.7713e-05 eta 0:00:19
epoch [49/50] batch [140/162] time 0.083 (0.097) data 0.000 (0.002) loss 1.8783 (1.9727) teacher_loss 0.1246 (0.1263) loss_zs_kd 0.0798 (0.0631) loss_oracle 0.7421 (0.7931) kd_loss 1.3428 (1.4184) acc 96.8750 (96.6295) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0511 (0.0625) teacher/usage_max 0.4396 (0.5382) teacher/usage_min 0.1512 (0.0628) teacher/usage_std 0.1294 (0.2029) nleep/row_max_mean 1504.4874 (1496.7597) nleep/row_max_std 38.0556 (51.9860) nleep/row_min_mean 1478.0392 (1469.2849) lr 1.7713e-05 eta 0:00:17
epoch [49/50] batch [160/162] time 0.087 (0.097) data 0.000 (0.002) loss 2.1068 (1.9796) teacher_loss 0.1541 (0.1319) loss_zs_kd 0.0538 (0.0636) loss_oracle 0.8524 (0.7960) kd_loss 1.4996 (1.4179) acc 93.7500 (96.4648) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0392 (0.0615) teacher/usage_max 0.5106 (0.5347) teacher/usage_min 0.0039 (0.0643) teacher/usage_std 0.2332 (0.2012) nleep/row_max_mean 1491.2418 (1496.2136) nleep/row_max_std 45.4129 (51.9048) nleep/row_min_mean 1463.4225 (1468.8066) lr 1.7713e-05 eta 0:00:15
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,929
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 88.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,724
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 78.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     83.0%, epoch: 49 *******
epoch [50/50] batch [20/162] time 0.106 (0.102) data 0.000 (0.012) loss 1.9574 (1.9375) teacher_loss 0.0831 (0.1143) loss_zs_kd 0.0646 (0.0623) loss_oracle 0.7666 (0.7722) kd_loss 1.4587 (1.4060) acc 96.8750 (96.7188) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0475 (0.0673) teacher/usage_max 0.4852 (0.5128) teacher/usage_min 0.0370 (0.0704) teacher/usage_std 0.2096 (0.1943) nleep/row_max_mean 1494.8210 (1496.6394) nleep/row_max_std 58.6882 (48.8720) nleep/row_min_mean 1469.8555 (1469.5287) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [40/162] time 0.100 (0.101) data 0.000 (0.006) loss 1.8623 (1.9505) teacher_loss 0.0754 (0.1162) loss_zs_kd 0.0645 (0.0618) loss_oracle 0.6967 (0.7783) kd_loss 1.4062 (1.4142) acc 100.0000 (96.6406) gate/entropy 0.9790 (0.9791) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0500 (0.0633) teacher/usage_max 0.5282 (0.5253) teacher/usage_min 0.0880 (0.0661) teacher/usage_std 0.1832 (0.1996) nleep/row_max_mean 1499.7013 (1495.0827) nleep/row_max_std 49.5151 (49.2702) nleep/row_min_mean 1471.7292 (1467.9092) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [60/162] time 0.085 (0.101) data 0.001 (0.004) loss 1.7887 (1.9456) teacher_loss 0.1140 (0.1164) loss_zs_kd 0.0438 (0.0610) loss_oracle 0.5798 (0.7785) kd_loss 1.3629 (1.4095) acc 96.8750 (96.5625) gate/entropy 0.9791 (0.9791) gate/usage_max 0.5723 (0.5724) gate/usage_min 0.2138 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.1110 (0.0656) teacher/usage_max 0.5347 (0.5294) teacher/usage_min 0.0697 (0.0686) teacher/usage_std 0.1949 (0.1989) nleep/row_max_mean 1488.5674 (1495.2071) nleep/row_max_std 48.9170 (49.6402) nleep/row_min_mean 1462.3018 (1468.2047) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [80/162] time 0.101 (0.098) data 0.000 (0.003) loss 2.1439 (1.9519) teacher_loss 0.1827 (0.1214) loss_zs_kd 0.0701 (0.0611) loss_oracle 0.8499 (0.7786) kd_loss 1.5012 (1.4107) acc 93.7500 (96.3672) gate/entropy 0.9791 (0.9791) gate/usage_max 0.5723 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0103 (0.0654) teacher/usage_max 0.4991 (0.5306) teacher/usage_min 0.0315 (0.0676) teacher/usage_std 0.2138 (0.1992) nleep/row_max_mean 1500.0957 (1495.1751) nleep/row_max_std 51.8075 (49.6894) nleep/row_min_mean 1473.3855 (1468.2972) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [100/162] time 0.088 (0.096) data 0.000 (0.003) loss 2.0453 (1.9559) teacher_loss 0.1134 (0.1203) loss_zs_kd 0.0947 (0.0620) loss_oracle 0.8490 (0.7817) kd_loss 1.4600 (1.4137) acc 93.7500 (96.4062) gate/entropy 0.9790 (0.9791) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0469 (0.0632) teacher/usage_max 0.5195 (0.5368) teacher/usage_min 0.0365 (0.0667) teacher/usage_std 0.2121 (0.2021) nleep/row_max_mean 1500.2584 (1495.9837) nleep/row_max_std 55.6078 (49.6068) nleep/row_min_mean 1471.9235 (1468.9580) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [120/162] time 0.099 (0.095) data 0.000 (0.002) loss 2.0718 (1.9540) teacher_loss 0.0659 (0.1179) loss_zs_kd 0.0901 (0.0621) loss_oracle 0.9453 (0.7877) kd_loss 1.4883 (1.4112) acc 100.0000 (96.5625) gate/entropy 0.9792 (0.9790) gate/usage_max 0.5722 (0.5724) gate/usage_min 0.2138 (0.2137) gate/usage_std 0.1689 (0.1690) teacher/entropy 0.0225 (0.0627) teacher/usage_max 0.5652 (0.5333) teacher/usage_min 0.0320 (0.0698) teacher/usage_std 0.2232 (0.1994) nleep/row_max_mean 1487.7861 (1496.1607) nleep/row_max_std 47.0037 (49.5670) nleep/row_min_mean 1459.2019 (1469.1169) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [140/162] time 0.091 (0.094) data 0.000 (0.002) loss 2.4177 (1.9614) teacher_loss 0.5717 (0.1237) loss_zs_kd 0.0635 (0.0621) loss_oracle 0.9204 (0.7884) kd_loss 1.3541 (1.4125) acc 87.5000 (96.4509) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0560 (0.0614) teacher/usage_max 0.4635 (0.5325) teacher/usage_min 0.1347 (0.0697) teacher/usage_std 0.1427 (0.1990) nleep/row_max_mean 1484.9429 (1496.3199) nleep/row_max_std 58.0953 (49.8993) nleep/row_min_mean 1459.3186 (1469.3498) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [160/162] time 0.087 (0.094) data 0.000 (0.002) loss 1.9977 (1.9628) teacher_loss 0.1706 (0.1229) loss_zs_kd 0.0577 (0.0626) loss_oracle 0.7477 (0.7902) kd_loss 1.4244 (1.4135) acc 93.7500 (96.4648) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0728 (0.0606) teacher/usage_max 0.4992 (0.5323) teacher/usage_min 0.0462 (0.0696) teacher/usage_std 0.2038 (0.1991) nleep/row_max_mean 1497.9663 (1496.0038) nleep/row_max_std 56.8791 (50.4146) nleep/row_min_mean 1474.3042 (1468.9702) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,928
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 88.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,722
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 78.5%
******* Domain s best val acc:      88.1%, epoch: 31 *******
******* Domain s best val test acc: 78.9%, epoch: 31 *******
******* Domain s best test acc:     83.0%, epoch: 49 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:17:40

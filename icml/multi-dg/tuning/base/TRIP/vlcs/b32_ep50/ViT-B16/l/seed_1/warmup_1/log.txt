Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'pascal', 'sun']
Target     ['labelme']
# classes  5
# train_x  5,651
# val      2,422
# test     2,656
---------  ----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/176] time 0.142 (0.180) data 0.000 (0.019) loss 0.6974 (0.8625) teacher_loss 0.3668 (0.5049) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0007 (0.0002) kd_loss 0.3302 (0.3575) acc 81.2500 (80.6250) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3350) gate/usage_min 0.3312 (0.3312) gate/usage_std 0.0016 (0.0016) teacher/entropy 0.7682 (0.7410) teacher/usage_max 0.4552 (0.4640) teacher/usage_min 0.2687 (0.2392) teacher/usage_std 0.0862 (0.0975) nleep/row_max_mean 1480.6074 (1465.7606) nleep/row_max_std 126.3823 (140.7547) nleep/row_min_mean 1477.9315 (1462.9356) lr 1.0000e-05 eta 0:26:22
epoch [1/50] batch [40/176] time 0.132 (0.158) data 0.000 (0.010) loss 0.6762 (0.8180) teacher_loss 0.5239 (0.5222) loss_zs_kd 0.0002 (0.0000) loss_oracle 0.0032 (0.0012) kd_loss 0.1506 (0.2952) acc 81.2500 (80.7031) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3350) gate/usage_min 0.3313 (0.3312) gate/usage_std 0.0015 (0.0016) teacher/entropy 0.9477 (0.8032) teacher/usage_max 0.4136 (0.4570) teacher/usage_min 0.2776 (0.2482) teacher/usage_std 0.0582 (0.0911) nleep/row_max_mean 1455.4624 (1464.8017) nleep/row_max_std 125.3493 (133.9678) nleep/row_min_mean 1454.1602 (1462.5377) lr 1.0000e-05 eta 0:23:05
epoch [1/50] batch [60/176] time 0.146 (0.151) data 0.000 (0.007) loss 0.6657 (0.7795) teacher_loss 0.5210 (0.5247) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0041 (0.0023) kd_loss 0.1426 (0.2536) acc 78.1250 (81.3542) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3349) gate/usage_min 0.3313 (0.3312) gate/usage_std 0.0015 (0.0016) teacher/entropy 0.9560 (0.8448) teacher/usage_max 0.3640 (0.4406) teacher/usage_min 0.3100 (0.2590) teacher/usage_std 0.0227 (0.0791) nleep/row_max_mean 1469.6307 (1464.6555) nleep/row_max_std 122.0150 (128.4310) nleep/row_min_mean 1468.3400 (1462.6950) lr 1.0000e-05 eta 0:21:59
epoch [1/50] batch [80/176] time 0.136 (0.149) data 0.000 (0.005) loss 0.5953 (0.7450) teacher_loss 0.4503 (0.5220) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0079 (0.0033) kd_loss 0.1409 (0.2213) acc 87.5000 (81.8359) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3349) gate/usage_min 0.3313 (0.3312) gate/usage_std 0.0015 (0.0016) teacher/entropy 0.9576 (0.8772) teacher/usage_max 0.4454 (0.4251) teacher/usage_min 0.2723 (0.2688) teacher/usage_std 0.0793 (0.0682) nleep/row_max_mean 1458.9648 (1465.4292) nleep/row_max_std 100.2556 (122.1258) nleep/row_min_mean 1457.7759 (1463.6818) lr 1.0000e-05 eta 0:21:36
epoch [1/50] batch [100/176] time 0.149 (0.147) data 0.000 (0.004) loss 0.4390 (0.7116) teacher_loss 0.3657 (0.5139) loss_zs_kd 0.0006 (0.0002) loss_oracle 0.0071 (0.0043) kd_loss 0.0694 (0.1955) acc 87.5000 (82.3438) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3349) gate/usage_min 0.3313 (0.3312) gate/usage_std 0.0015 (0.0016) teacher/entropy 1.0293 (0.9030) teacher/usage_max 0.3385 (0.4113) teacher/usage_min 0.3281 (0.2774) teacher/usage_std 0.0043 (0.0583) nleep/row_max_mean 1480.3713 (1465.7516) nleep/row_max_std 89.8389 (116.8847) nleep/row_min_mean 1479.5398 (1464.1726) lr 1.0000e-05 eta 0:21:19
epoch [1/50] batch [120/176] time 0.102 (0.141) data 0.000 (0.003) loss 0.3316 (0.6922) teacher_loss 0.2391 (0.5128) loss_zs_kd 0.0000 (0.0002) loss_oracle 0.0078 (0.0050) kd_loss 0.0886 (0.1767) acc 93.7500 (82.4479) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3349) gate/usage_min 0.3312 (0.3312) gate/usage_std 0.0016 (0.0016) teacher/entropy 1.0102 (0.9218) teacher/usage_max 0.3423 (0.4025) teacher/usage_min 0.3190 (0.2821) teacher/usage_std 0.0102 (0.0524) nleep/row_max_mean 1488.7344 (1467.7161) nleep/row_max_std 81.8553 (111.2113) nleep/row_min_mean 1487.7804 (1466.2536) lr 1.0000e-05 eta 0:20:20
epoch [1/50] batch [140/176] time 0.102 (0.137) data 0.000 (0.003) loss 0.7398 (0.6893) teacher_loss 0.6449 (0.5242) loss_zs_kd 0.0003 (0.0002) loss_oracle 0.0080 (0.0054) kd_loss 0.0907 (0.1623) acc 78.1250 (82.0536) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3349) gate/usage_min 0.3311 (0.3312) gate/usage_std 0.0016 (0.0016) teacher/entropy 1.0078 (0.9363) teacher/usage_max 0.3836 (0.3972) teacher/usage_min 0.2826 (0.2839) teacher/usage_std 0.0412 (0.0492) nleep/row_max_mean 1485.6356 (1469.8688) nleep/row_max_std 63.8592 (105.9580) nleep/row_min_mean 1484.6554 (1468.4943) lr 1.0000e-05 eta 0:19:45
epoch [1/50] batch [160/176] time 0.155 (0.135) data 0.000 (0.003) loss 0.4009 (0.6768) teacher_loss 0.3187 (0.5227) loss_zs_kd 0.0000 (0.0002) loss_oracle 0.0093 (0.0057) kd_loss 0.0775 (0.1512) acc 87.5000 (81.8750) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3349) gate/usage_min 0.3313 (0.3312) gate/usage_std 0.0015 (0.0016) teacher/entropy 1.0209 (0.9474) teacher/usage_max 0.3957 (0.3954) teacher/usage_min 0.2741 (0.2823) teacher/usage_std 0.0497 (0.0489) nleep/row_max_mean 1497.4932 (1471.8912) nleep/row_max_std 66.7328 (101.3705) nleep/row_min_mean 1496.6132 (1470.5822) lr 1.0000e-05 eta 0:19:23
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,073
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 88.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,832
* accuracy: 69.0%
* error: 31.0%
* macro_f1: 61.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain l best val acc:      85.6%, epoch: 1 *******
******* Domain l best val test acc: 69.0%, epoch: 1 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [2/50] batch [20/176] time 0.140 (0.121) data 0.000 (0.014) loss 0.7714 (0.6617) teacher_loss 0.5468 (0.5186) loss_zs_kd 0.0110 (0.0044) loss_oracle 0.1722 (0.0957) kd_loss 0.1330 (0.0930) acc 78.1250 (81.2500) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3355 (0.3352) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0017 (0.0016) teacher/entropy 0.9646 (1.0051) teacher/usage_max 0.4512 (0.4082) teacher/usage_min 0.1859 (0.2417) teacher/usage_std 0.1103 (0.0708) nleep/row_max_mean 1488.8401 (1498.5879) nleep/row_max_std 66.9956 (59.7173) nleep/row_min_mean 1487.6436 (1497.6389) lr 2.0000e-03 eta 0:17:16
epoch [2/50] batch [40/176] time 0.077 (0.112) data 0.000 (0.007) loss 0.9930 (0.7505) teacher_loss 0.4443 (0.4761) loss_zs_kd 0.0113 (0.0064) loss_oracle 0.2731 (0.1903) kd_loss 0.4065 (0.1760) acc 81.2500 (83.5156) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3363 (0.3356) gate/usage_min 0.3303 (0.3310) gate/usage_std 0.0024 (0.0019) teacher/entropy 0.6886 (0.9214) teacher/usage_max 0.5029 (0.4588) teacher/usage_min 0.0414 (0.1747) teacher/usage_std 0.2073 (0.1202) nleep/row_max_mean 1505.2800 (1500.4324) nleep/row_max_std 57.8268 (58.5038) nleep/row_min_mean 1501.8828 (1498.9061) lr 2.0000e-03 eta 0:16:03
epoch [2/50] batch [60/176] time 0.144 (0.115) data 0.000 (0.005) loss 1.1533 (0.8840) teacher_loss 0.2768 (0.4556) loss_zs_kd 0.0073 (0.0078) loss_oracle 0.3671 (0.2367) kd_loss 0.6893 (0.3062) acc 90.6250 (84.2188) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3372 (0.3360) gate/usage_min 0.3282 (0.3304) gate/usage_std 0.0038 (0.0023) teacher/entropy 0.4036 (0.7903) teacher/usage_max 0.7128 (0.5294) teacher/usage_min 0.0117 (0.1252) teacher/usage_std 0.2892 (0.1691) nleep/row_max_mean 1516.0347 (1502.0740) nleep/row_max_std 57.3404 (58.6743) nleep/row_min_mean 1510.0837 (1499.5124) lr 2.0000e-03 eta 0:16:23
epoch [2/50] batch [80/176] time 0.161 (0.122) data 0.000 (0.004) loss 1.6002 (1.0020) teacher_loss 0.5603 (0.4346) loss_zs_kd 0.0134 (0.0089) loss_oracle 0.5369 (0.2970) kd_loss 0.7648 (0.4144) acc 84.3750 (85.0391) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3372 (0.3363) gate/usage_min 0.3265 (0.3297) gate/usage_std 0.0049 (0.0028) teacher/entropy 0.3232 (0.6806) teacher/usage_max 0.7244 (0.5833) teacher/usage_min 0.0059 (0.0971) teacher/usage_std 0.2967 (0.2036) nleep/row_max_mean 1501.9111 (1503.0248) nleep/row_max_std 50.0003 (58.4075) nleep/row_min_mean 1494.8405 (1499.4552) lr 2.0000e-03 eta 0:17:19
epoch [2/50] batch [100/176] time 0.136 (0.125) data 0.000 (0.003) loss 1.8249 (1.1014) teacher_loss 0.6248 (0.4189) loss_zs_kd 0.0147 (0.0112) loss_oracle 0.4846 (0.3451) kd_loss 0.9505 (0.5044) acc 87.5000 (85.7188) gate/entropy 1.0984 (1.0986) gate/usage_max 0.3397 (0.3367) gate/usage_min 0.3250 (0.3289) gate/usage_std 0.0061 (0.0033) teacher/entropy 0.1320 (0.5888) teacher/usage_max 0.8081 (0.6179) teacher/usage_min 0.0148 (0.0802) teacher/usage_std 0.3422 (0.2258) nleep/row_max_mean 1508.2991 (1504.5719) nleep/row_max_std 60.5710 (58.2271) nleep/row_min_mean 1499.0469 (1500.0655) lr 2.0000e-03 eta 0:17:44
epoch [2/50] batch [120/176] time 0.126 (0.127) data 0.000 (0.002) loss 1.4797 (1.1765) teacher_loss 0.2332 (0.3959) loss_zs_kd 0.0330 (0.0132) loss_oracle 0.5331 (0.3847) kd_loss 0.9634 (0.5816) acc 93.7500 (86.5885) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3428 (0.3375) gate/usage_min 0.3238 (0.3281) gate/usage_std 0.0078 (0.0040) teacher/entropy 0.1157 (0.5093) teacher/usage_max 0.7135 (0.6499) teacher/usage_min 0.0078 (0.0687) teacher/usage_std 0.2907 (0.2458) nleep/row_max_mean 1512.6511 (1505.8640) nleep/row_max_std 62.0441 (58.1319) nleep/row_min_mean 1501.5400 (1500.3992) lr 2.0000e-03 eta 0:17:59
epoch [2/50] batch [140/176] time 0.117 (0.128) data 0.000 (0.002) loss 1.4511 (1.2245) teacher_loss 0.1718 (0.3736) loss_zs_kd 0.0143 (0.0146) loss_oracle 0.6404 (0.4158) kd_loss 0.9519 (0.6357) acc 96.8750 (87.3438) gate/entropy 1.0982 (1.0985) gate/usage_max 0.3455 (0.3385) gate/usage_min 0.3223 (0.3274) gate/usage_std 0.0095 (0.0046) teacher/entropy 0.1213 (0.4529) teacher/usage_max 0.7635 (0.6659) teacher/usage_min 0.0294 (0.0619) teacher/usage_std 0.3127 (0.2559) nleep/row_max_mean 1485.4138 (1506.2643) nleep/row_max_std 67.0716 (58.0058) nleep/row_min_mean 1474.2886 (1499.9878) lr 2.0000e-03 eta 0:18:06
epoch [2/50] batch [160/176] time 0.131 (0.130) data 0.000 (0.002) loss 1.4479 (1.2639) teacher_loss 0.1619 (0.3599) loss_zs_kd 0.0086 (0.0167) loss_oracle 0.5945 (0.4411) kd_loss 0.9844 (0.6750) acc 93.7500 (87.8906) gate/entropy 1.0980 (1.0984) gate/usage_max 0.3482 (0.3395) gate/usage_min 0.3205 (0.3266) gate/usage_std 0.0114 (0.0054) teacher/entropy 0.0823 (0.4114) teacher/usage_max 0.7827 (0.6760) teacher/usage_min 0.0261 (0.0582) teacher/usage_std 0.3248 (0.2620) nleep/row_max_mean 1525.9489 (1506.7558) nleep/row_max_std 53.5378 (57.8641) nleep/row_min_mean 1513.7341 (1499.7635) lr 2.0000e-03 eta 0:18:17
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,155
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 91.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,633
* accuracy: 61.5%
* error: 38.5%
* macro_f1: 57.2%
******* Domain l best val acc:      89.0%, epoch: 2 *******
******* Domain l best val test acc: 61.5%, epoch: 2 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [3/50] batch [20/176] time 0.123 (0.118) data 0.000 (0.017) loss 1.6174 (1.4969) teacher_loss 0.3167 (0.2377) loss_zs_kd 0.0441 (0.0327) loss_oracle 0.5459 (0.5457) kd_loss 1.0057 (0.9700) acc 93.7500 (92.3438) gate/entropy 1.0977 (1.0978) gate/usage_max 0.3525 (0.3514) gate/usage_min 0.3179 (0.3186) gate/usage_std 0.0144 (0.0136) teacher/entropy 0.0486 (0.0939) teacher/usage_max 0.8316 (0.7406) teacher/usage_min 0.0088 (0.0489) teacher/usage_std 0.3577 (0.2981) nleep/row_max_mean 1522.6838 (1517.6701) nleep/row_max_std 40.9946 (50.5145) nleep/row_min_mean 1507.7476 (1503.8966) lr 1.9980e-03 eta 0:16:36
epoch [3/50] batch [40/176] time 0.106 (0.114) data 0.000 (0.008) loss 1.3969 (1.4835) teacher_loss 0.0961 (0.2249) loss_zs_kd 0.0473 (0.0344) loss_oracle 0.6078 (0.5645) kd_loss 0.9732 (0.9591) acc 96.8750 (92.6562) gate/entropy 1.0974 (1.0977) gate/usage_max 0.3553 (0.3527) gate/usage_min 0.3166 (0.3179) gate/usage_std 0.0162 (0.0145) teacher/entropy 0.0885 (0.1027) teacher/usage_max 0.6872 (0.7434) teacher/usage_min 0.0548 (0.0571) teacher/usage_std 0.2636 (0.2981) nleep/row_max_mean 1515.4573 (1515.7626) nleep/row_max_std 51.1292 (54.8519) nleep/row_min_mean 1497.7498 (1501.3754) lr 1.9980e-03 eta 0:16:01
epoch [3/50] batch [60/176] time 0.077 (0.112) data 0.000 (0.006) loss 1.5837 (1.4740) teacher_loss 0.3258 (0.2132) loss_zs_kd 0.0271 (0.0338) loss_oracle 0.6381 (0.5787) kd_loss 0.9253 (0.9545) acc 87.5000 (93.0208) gate/entropy 1.0972 (1.0976) gate/usage_max 0.3573 (0.3539) gate/usage_min 0.3157 (0.3173) gate/usage_std 0.0176 (0.0153) teacher/entropy 0.1330 (0.1063) teacher/usage_max 0.6957 (0.7333) teacher/usage_min 0.0533 (0.0614) teacher/usage_std 0.2686 (0.2914) nleep/row_max_mean 1505.8645 (1515.6000) nleep/row_max_std 70.1882 (55.2292) nleep/row_min_mean 1490.5237 (1500.7463) lr 1.9980e-03 eta 0:15:43
epoch [3/50] batch [80/176] time 0.103 (0.113) data 0.000 (0.004) loss 1.3690 (1.4658) teacher_loss 0.0527 (0.1984) loss_zs_kd 0.0332 (0.0345) loss_oracle 0.7567 (0.5995) kd_loss 0.9213 (0.9504) acc 100.0000 (93.2812) gate/entropy 1.0970 (1.0974) gate/usage_max 0.3592 (0.3550) gate/usage_min 0.3150 (0.3168) gate/usage_std 0.0188 (0.0160) teacher/entropy 0.1482 (0.1099) teacher/usage_max 0.5730 (0.7223) teacher/usage_min 0.1143 (0.0711) teacher/usage_std 0.1878 (0.2830) nleep/row_max_mean 1517.2773 (1515.6947) nleep/row_max_std 63.3343 (55.7342) nleep/row_min_mean 1498.0100 (1500.4312) lr 1.9980e-03 eta 0:15:47
epoch [3/50] batch [100/176] time 0.099 (0.113) data 0.000 (0.004) loss 1.4238 (1.4766) teacher_loss 0.0925 (0.2042) loss_zs_kd 0.0505 (0.0353) loss_oracle 0.6662 (0.6153) kd_loss 0.9731 (0.9471) acc 100.0000 (93.1562) gate/entropy 1.0969 (1.0973) gate/usage_max 0.3609 (0.3560) gate/usage_min 0.3148 (0.3164) gate/usage_std 0.0199 (0.0167) teacher/entropy 0.0967 (0.1131) teacher/usage_max 0.5769 (0.7112) teacher/usage_min 0.1723 (0.0818) teacher/usage_std 0.1752 (0.2745) nleep/row_max_mean 1503.0503 (1514.9439) nleep/row_max_std 57.1930 (56.0975) nleep/row_min_mean 1485.0400 (1499.3079) lr 1.9980e-03 eta 0:15:44
epoch [3/50] batch [120/176] time 0.155 (0.113) data 0.000 (0.003) loss 1.4544 (1.4701) teacher_loss 0.0774 (0.2013) loss_zs_kd 0.0514 (0.0365) loss_oracle 0.6872 (0.6159) kd_loss 1.0077 (0.9426) acc 100.0000 (93.2552) gate/entropy 1.0967 (1.0973) gate/usage_max 0.3623 (0.3570) gate/usage_min 0.3148 (0.3161) gate/usage_std 0.0208 (0.0173) teacher/entropy 0.0786 (0.1181) teacher/usage_max 0.4301 (0.6986) teacher/usage_min 0.2260 (0.0911) teacher/usage_std 0.0837 (0.2655) nleep/row_max_mean 1517.0737 (1513.7405) nleep/row_max_std 59.8745 (56.7081) nleep/row_min_mean 1498.3711 (1497.8626) lr 1.9980e-03 eta 0:15:40
epoch [3/50] batch [140/176] time 0.156 (0.113) data 0.000 (0.003) loss 1.4512 (1.4694) teacher_loss 0.1617 (0.1997) loss_zs_kd 0.0365 (0.0371) loss_oracle 0.6986 (0.6181) kd_loss 0.9219 (0.9421) acc 90.6250 (93.1473) gate/entropy 1.0966 (1.0972) gate/usage_max 0.3635 (0.3578) gate/usage_min 0.3147 (0.3159) gate/usage_std 0.0215 (0.0179) teacher/entropy 0.1481 (0.1186) teacher/usage_max 0.5607 (0.6889) teacher/usage_min 0.2086 (0.0988) teacher/usage_std 0.1610 (0.2582) nleep/row_max_mean 1507.4696 (1512.8628) nleep/row_max_std 61.2555 (56.8784) nleep/row_min_mean 1487.5142 (1496.6527) lr 1.9980e-03 eta 0:15:40
epoch [3/50] batch [160/176] time 0.112 (0.112) data 0.000 (0.002) loss 1.4171 (1.4674) teacher_loss 0.1688 (0.2005) loss_zs_kd 0.0408 (0.0371) loss_oracle 0.6419 (0.6111) kd_loss 0.9070 (0.9428) acc 90.6250 (93.1641) gate/entropy 1.0964 (1.0971) gate/usage_max 0.3648 (0.3586) gate/usage_min 0.3143 (0.3158) gate/usage_std 0.0224 (0.0184) teacher/entropy 0.1357 (0.1171) teacher/usage_max 0.7492 (0.6858) teacher/usage_min 0.1086 (0.1022) teacher/usage_std 0.2944 (0.2558) nleep/row_max_mean 1508.7817 (1512.5281) nleep/row_max_std 52.4234 (56.8478) nleep/row_min_mean 1491.0802 (1496.0102) lr 1.9980e-03 eta 0:15:27
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,148
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 90.8%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,765
* accuracy: 66.5%
* error: 33.5%
* macro_f1: 60.0%
******* Domain l best val acc:      89.0%, epoch: 2 *******
******* Domain l best val test acc: 61.5%, epoch: 2 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [4/50] batch [20/176] time 0.115 (0.141) data 0.000 (0.016) loss 1.3362 (1.5117) teacher_loss 0.1000 (0.2194) loss_zs_kd 0.0412 (0.0465) loss_oracle 0.6494 (0.6509) kd_loss 0.8910 (0.9435) acc 96.8750 (94.0625) gate/entropy 1.0960 (1.0961) gate/usage_max 0.3674 (0.3668) gate/usage_min 0.3131 (0.3135) gate/usage_std 0.0242 (0.0238) teacher/entropy 0.1515 (0.1058) teacher/usage_max 0.7244 (0.6806) teacher/usage_min 0.1336 (0.1080) teacher/usage_std 0.2765 (0.2524) nleep/row_max_mean 1492.5215 (1508.9857) nleep/row_max_std 65.6174 (55.4302) nleep/row_min_mean 1475.5269 (1489.6568) lr 1.9921e-03 eta 0:19:19
epoch [4/50] batch [40/176] time 0.147 (0.138) data 0.001 (0.008) loss 1.5744 (1.4936) teacher_loss 0.2456 (0.2072) loss_zs_kd 0.0404 (0.0433) loss_oracle 0.6624 (0.6302) kd_loss 0.9773 (0.9498) acc 90.6250 (93.5156) gate/entropy 1.0957 (1.0960) gate/usage_max 0.3694 (0.3676) gate/usage_min 0.3122 (0.3131) gate/usage_std 0.0256 (0.0243) teacher/entropy 0.0778 (0.0975) teacher/usage_max 0.6294 (0.6865) teacher/usage_min 0.1566 (0.1090) teacher/usage_std 0.2107 (0.2552) nleep/row_max_mean 1514.3273 (1507.4780) nleep/row_max_std 49.6074 (56.4317) nleep/row_min_mean 1495.0103 (1488.1484) lr 1.9921e-03 eta 0:18:59
epoch [4/50] batch [60/176] time 0.124 (0.136) data 0.000 (0.006) loss 1.4915 (1.4864) teacher_loss 0.1632 (0.1975) loss_zs_kd 0.0404 (0.0431) loss_oracle 0.5820 (0.6285) kd_loss 1.0171 (0.9531) acc 90.6250 (93.6458) gate/entropy 1.0955 (1.0959) gate/usage_max 0.3709 (0.3684) gate/usage_min 0.3116 (0.3127) gate/usage_std 0.0267 (0.0249) teacher/entropy 0.0192 (0.0926) teacher/usage_max 0.7123 (0.6882) teacher/usage_min 0.0069 (0.1018) teacher/usage_std 0.2904 (0.2577) nleep/row_max_mean 1531.2161 (1507.8179) nleep/row_max_std 47.6917 (55.9942) nleep/row_min_mean 1506.3037 (1488.1022) lr 1.9921e-03 eta 0:18:38
epoch [4/50] batch [80/176] time 0.136 (0.136) data 0.000 (0.004) loss 1.4471 (1.4776) teacher_loss 0.1498 (0.1942) loss_zs_kd 0.0621 (0.0429) loss_oracle 0.5630 (0.6086) kd_loss 0.9848 (0.9576) acc 96.8750 (93.7109) gate/entropy 1.0951 (1.0957) gate/usage_max 0.3730 (0.3693) gate/usage_min 0.3107 (0.3123) gate/usage_std 0.0282 (0.0255) teacher/entropy 0.0599 (0.0856) teacher/usage_max 0.6539 (0.6957) teacher/usage_min 0.0959 (0.0994) teacher/usage_std 0.2353 (0.2622) nleep/row_max_mean 1515.9309 (1508.7778) nleep/row_max_std 56.1433 (55.1644) nleep/row_min_mean 1494.3542 (1488.6576) lr 1.9921e-03 eta 0:18:36
epoch [4/50] batch [100/176] time 0.129 (0.137) data 0.000 (0.003) loss 1.4061 (1.4786) teacher_loss 0.0621 (0.1952) loss_zs_kd 0.0448 (0.0429) loss_oracle 0.5504 (0.5937) kd_loss 1.0464 (0.9652) acc 96.8750 (93.6875) gate/entropy 1.0947 (1.0956) gate/usage_max 0.3752 (0.3703) gate/usage_min 0.3089 (0.3118) gate/usage_std 0.0298 (0.0262) teacher/entropy 0.0175 (0.0759) teacher/usage_max 0.5319 (0.7001) teacher/usage_min 0.1255 (0.0941) teacher/usage_std 0.1661 (0.2657) nleep/row_max_mean 1511.5098 (1509.4961) nleep/row_max_std 51.7112 (54.5712) nleep/row_min_mean 1487.9445 (1488.8000) lr 1.9921e-03 eta 0:18:38
epoch [4/50] batch [120/176] time 0.130 (0.137) data 0.000 (0.003) loss 1.3217 (1.4805) teacher_loss 0.0402 (0.1939) loss_zs_kd 0.0410 (0.0438) loss_oracle 0.5287 (0.5913) kd_loss 0.9966 (0.9691) acc 100.0000 (93.6458) gate/entropy 1.0942 (1.0954) gate/usage_max 0.3775 (0.3713) gate/usage_min 0.3070 (0.3112) gate/usage_std 0.0315 (0.0270) teacher/entropy 0.0240 (0.0701) teacher/usage_max 0.7517 (0.7021) teacher/usage_min 0.0601 (0.0905) teacher/usage_std 0.3004 (0.2677) nleep/row_max_mean 1513.4216 (1509.4800) nleep/row_max_std 56.3881 (54.6678) nleep/row_min_mean 1488.1848 (1488.2589) lr 1.9921e-03 eta 0:18:37
epoch [4/50] batch [140/176] time 0.082 (0.137) data 0.000 (0.002) loss 1.5371 (1.4827) teacher_loss 0.1911 (0.1971) loss_zs_kd 0.0495 (0.0440) loss_oracle 0.5918 (0.5848) kd_loss 1.0254 (0.9712) acc 93.7500 (93.5714) gate/entropy 1.0938 (1.0952) gate/usage_max 0.3796 (0.3723) gate/usage_min 0.3051 (0.3104) gate/usage_std 0.0330 (0.0277) teacher/entropy 0.0215 (0.0654) teacher/usage_max 0.5847 (0.7070) teacher/usage_min 0.0313 (0.0843) teacher/usage_std 0.2288 (0.2717) nleep/row_max_mean 1508.3134 (1509.1231) nleep/row_max_std 42.4999 (54.7297) nleep/row_min_mean 1481.6017 (1487.4895) lr 1.9921e-03 eta 0:18:32
epoch [4/50] batch [160/176] time 0.111 (0.132) data 0.000 (0.002) loss 1.4197 (1.4780) teacher_loss 0.1494 (0.1938) loss_zs_kd 0.0291 (0.0432) loss_oracle 0.5742 (0.5806) kd_loss 0.9686 (0.9724) acc 93.7500 (93.6523) gate/entropy 1.0933 (1.0950) gate/usage_max 0.3821 (0.3734) gate/usage_min 0.3029 (0.3096) gate/usage_std 0.0348 (0.0285) teacher/entropy 0.0305 (0.0611) teacher/usage_max 0.8093 (0.7137) teacher/usage_min 0.0061 (0.0791) teacher/usage_std 0.3443 (0.2767) nleep/row_max_mean 1509.0264 (1508.9278) nleep/row_max_std 59.0315 (55.1826) nleep/row_min_mean 1482.5349 (1486.7943) lr 1.9921e-03 eta 0:17:50
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,146
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 90.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,734
* accuracy: 65.3%
* error: 34.7%
* macro_f1: 59.4%
******* Domain l best val acc:      89.0%, epoch: 2 *******
******* Domain l best val test acc: 61.5%, epoch: 2 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [5/50] batch [20/176] time 0.103 (0.110) data 0.000 (0.013) loss 1.4481 (1.4472) teacher_loss 0.1504 (0.1467) loss_zs_kd 0.0390 (0.0423) loss_oracle 0.6069 (0.6051) kd_loss 0.9747 (0.9767) acc 93.7500 (95.4688) gate/entropy 1.0923 (1.0925) gate/usage_max 0.3863 (0.3853) gate/usage_min 0.2992 (0.3002) gate/usage_std 0.0380 (0.0372) teacher/entropy 0.0253 (0.0305) teacher/usage_max 0.7690 (0.7439) teacher/usage_min 0.0316 (0.0322) teacher/usage_std 0.3156 (0.3029) nleep/row_max_mean 1512.7795 (1504.5661) nleep/row_max_std 50.2579 (59.3948) nleep/row_min_mean 1485.8669 (1477.7553) lr 1.9823e-03 eta 0:14:46
epoch [5/50] batch [40/176] time 0.082 (0.111) data 0.000 (0.007) loss 1.4251 (1.4668) teacher_loss 0.1435 (0.1857) loss_zs_kd 0.0376 (0.0392) loss_oracle 0.5622 (0.5767) kd_loss 0.9817 (0.9732) acc 96.8750 (93.8281) gate/entropy 1.0916 (1.0922) gate/usage_max 0.3887 (0.3864) gate/usage_min 0.2967 (0.2991) gate/usage_std 0.0398 (0.0381) teacher/entropy 0.0531 (0.0317) teacher/usage_max 0.5855 (0.7451) teacher/usage_min 0.0389 (0.0303) teacher/usage_std 0.2252 (0.3042) nleep/row_max_mean 1508.2524 (1505.6857) nleep/row_max_std 54.3377 (58.5184) nleep/row_min_mean 1482.0569 (1478.6800) lr 1.9823e-03 eta 0:14:56
epoch [5/50] batch [60/176] time 0.086 (0.112) data 0.001 (0.004) loss 1.3811 (1.4418) teacher_loss 0.1114 (0.1748) loss_zs_kd 0.0265 (0.0386) loss_oracle 0.5897 (0.5633) kd_loss 0.9616 (0.9660) acc 96.8750 (94.2708) gate/entropy 1.0909 (1.0919) gate/usage_max 0.3914 (0.3876) gate/usage_min 0.2942 (0.2979) gate/usage_std 0.0419 (0.0390) teacher/entropy 0.0280 (0.0332) teacher/usage_max 0.7691 (0.7605) teacher/usage_min 0.0114 (0.0289) teacher/usage_std 0.3196 (0.3136) nleep/row_max_mean 1517.4829 (1506.1095) nleep/row_max_std 50.7947 (59.2748) nleep/row_min_mean 1489.6418 (1479.0489) lr 1.9823e-03 eta 0:14:57
epoch [5/50] batch [80/176] time 0.136 (0.116) data 0.000 (0.003) loss 1.4417 (1.4532) teacher_loss 0.2113 (0.1869) loss_zs_kd 0.0440 (0.0400) loss_oracle 0.5387 (0.5645) kd_loss 0.9390 (0.9640) acc 90.6250 (93.6719) gate/entropy 1.0902 (1.0916) gate/usage_max 0.3938 (0.3889) gate/usage_min 0.2919 (0.2967) gate/usage_std 0.0437 (0.0399) teacher/entropy 0.0388 (0.0336) teacher/usage_max 0.8010 (0.7571) teacher/usage_min 0.0142 (0.0269) teacher/usage_std 0.3379 (0.3122) nleep/row_max_mean 1492.5774 (1505.7216) nleep/row_max_std 60.8931 (58.7446) nleep/row_min_mean 1466.5354 (1478.4717) lr 1.9823e-03 eta 0:15:32
epoch [5/50] batch [100/176] time 0.125 (0.119) data 0.000 (0.003) loss 1.4645 (1.4531) teacher_loss 0.2386 (0.1899) loss_zs_kd 0.0368 (0.0395) loss_oracle 0.5049 (0.5645) kd_loss 0.9551 (0.9612) acc 96.8750 (93.6562) gate/entropy 1.0895 (1.0912) gate/usage_max 0.3962 (0.3901) gate/usage_min 0.2896 (0.2955) gate/usage_std 0.0456 (0.0409) teacher/entropy 0.0071 (0.0325) teacher/usage_max 0.8424 (0.7636) teacher/usage_min 0.0012 (0.0251) teacher/usage_std 0.3655 (0.3161) nleep/row_max_mean 1497.3350 (1505.1267) nleep/row_max_std 60.2673 (58.6274) nleep/row_min_mean 1469.3977 (1477.7249) lr 1.9823e-03 eta 0:15:50
epoch [5/50] batch [120/176] time 0.156 (0.123) data 0.000 (0.002) loss 1.4212 (1.4575) teacher_loss 0.1766 (0.1957) loss_zs_kd 0.0330 (0.0391) loss_oracle 0.5415 (0.5658) kd_loss 0.9573 (0.9594) acc 96.8750 (93.3854) gate/entropy 1.0886 (1.0908) gate/usage_max 0.3989 (0.3914) gate/usage_min 0.2873 (0.2943) gate/usage_std 0.0476 (0.0419) teacher/entropy 0.0273 (0.0310) teacher/usage_max 0.7324 (0.7671) teacher/usage_min 0.0166 (0.0226) teacher/usage_std 0.2980 (0.3188) nleep/row_max_mean 1502.4177 (1505.3795) nleep/row_max_std 62.1754 (58.4485) nleep/row_min_mean 1472.9823 (1477.6822) lr 1.9823e-03 eta 0:16:20
epoch [5/50] batch [140/176] time 0.124 (0.126) data 0.000 (0.002) loss 1.3020 (1.4580) teacher_loss 0.1002 (0.1979) loss_zs_kd 0.0443 (0.0388) loss_oracle 0.6723 (0.5730) kd_loss 0.8435 (0.9542) acc 100.0000 (93.3705) gate/entropy 1.0878 (1.0905) gate/usage_max 0.4015 (0.3927) gate/usage_min 0.2852 (0.2931) gate/usage_std 0.0496 (0.0428) teacher/entropy 0.1405 (0.0328) teacher/usage_max 0.7285 (0.7711) teacher/usage_min 0.0463 (0.0219) teacher/usage_std 0.2888 (0.3211) nleep/row_max_mean 1490.0869 (1504.4109) nleep/row_max_std 67.3609 (58.7779) nleep/row_min_mean 1465.8898 (1476.6500) lr 1.9823e-03 eta 0:16:40
epoch [5/50] batch [160/176] time 0.117 (0.127) data 0.000 (0.002) loss 1.4046 (1.4624) teacher_loss 0.1292 (0.2010) loss_zs_kd 0.0411 (0.0390) loss_oracle 0.6521 (0.5797) kd_loss 0.9288 (0.9520) acc 93.7500 (93.2031) gate/entropy 1.0870 (1.0901) gate/usage_max 0.4040 (0.3939) gate/usage_min 0.2831 (0.2920) gate/usage_std 0.0514 (0.0438) teacher/entropy 0.0101 (0.0320) teacher/usage_max 0.8728 (0.7741) teacher/usage_min 0.0020 (0.0213) teacher/usage_std 0.3848 (0.3230) nleep/row_max_mean 1501.5300 (1504.4390) nleep/row_max_std 59.3025 (58.9017) nleep/row_min_mean 1471.6926 (1476.4373) lr 1.9823e-03 eta 0:16:48
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,162
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,668
* accuracy: 62.8%
* error: 37.2%
* macro_f1: 57.4%
******* Domain l best val acc:      89.3%, epoch: 5 *******
******* Domain l best val test acc: 62.8%, epoch: 5 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [6/50] batch [20/176] time 0.131 (0.153) data 0.000 (0.015) loss 1.2711 (1.4383) teacher_loss 0.0561 (0.1657) loss_zs_kd 0.0277 (0.0348) loss_oracle 0.5220 (0.6353) kd_loss 0.9402 (0.9376) acc 100.0000 (94.3750) gate/entropy 1.0855 (1.0859) gate/usage_max 0.4078 (0.4069) gate/usage_min 0.2789 (0.2800) gate/usage_std 0.0545 (0.0537) teacher/entropy 0.0067 (0.0239) teacher/usage_max 0.8109 (0.7656) teacher/usage_min 0.0000 (0.0085) teacher/usage_std 0.3464 (0.3213) nleep/row_max_mean 1509.5757 (1504.7278) nleep/row_max_std 53.5205 (57.4126) nleep/row_min_mean 1477.3800 (1474.3751) lr 1.9686e-03 eta 0:20:08
epoch [6/50] batch [40/176] time 0.076 (0.140) data 0.000 (0.008) loss 1.3978 (1.4463) teacher_loss 0.1896 (0.1800) loss_zs_kd 0.0277 (0.0383) loss_oracle 0.5942 (0.6294) kd_loss 0.8973 (0.9325) acc 87.5000 (93.7500) gate/entropy 1.0847 (1.0855) gate/usage_max 0.4099 (0.4079) gate/usage_min 0.2769 (0.2790) gate/usage_std 0.0561 (0.0545) teacher/entropy 0.0315 (0.0288) teacher/usage_max 0.8658 (0.7600) teacher/usage_min 0.0077 (0.0104) teacher/usage_std 0.3796 (0.3176) nleep/row_max_mean 1487.0486 (1503.1620) nleep/row_max_std 66.9835 (55.6375) nleep/row_min_mean 1461.1187 (1473.0064) lr 1.9686e-03 eta 0:18:23
epoch [6/50] batch [60/176] time 0.070 (0.127) data 0.000 (0.005) loss 1.3362 (1.4473) teacher_loss 0.1465 (0.1834) loss_zs_kd 0.0436 (0.0375) loss_oracle 0.5237 (0.6240) kd_loss 0.9060 (0.9331) acc 96.8750 (93.8542) gate/entropy 1.0841 (1.0851) gate/usage_max 0.4114 (0.4088) gate/usage_min 0.2753 (0.2780) gate/usage_std 0.0573 (0.0553) teacher/entropy 0.0327 (0.0281) teacher/usage_max 0.8288 (0.7543) teacher/usage_min 0.0322 (0.0111) teacher/usage_std 0.3531 (0.3147) nleep/row_max_mean 1487.4290 (1503.7745) nleep/row_max_std 60.8985 (55.5077) nleep/row_min_mean 1457.9712 (1473.9948) lr 1.9686e-03 eta 0:16:38
epoch [6/50] batch [80/176] time 0.069 (0.124) data 0.000 (0.004) loss 1.3329 (1.4359) teacher_loss 0.1036 (0.1807) loss_zs_kd 0.0232 (0.0376) loss_oracle 0.6039 (0.6139) kd_loss 0.9157 (0.9294) acc 96.8750 (94.0234) gate/entropy 1.0833 (1.0848) gate/usage_max 0.4135 (0.4097) gate/usage_min 0.2734 (0.2770) gate/usage_std 0.0590 (0.0560) teacher/entropy 0.0435 (0.0279) teacher/usage_max 0.7418 (0.7615) teacher/usage_min 0.0338 (0.0103) teacher/usage_std 0.2991 (0.3191) nleep/row_max_mean 1498.0012 (1503.8673) nleep/row_max_std 54.7112 (55.1932) nleep/row_min_mean 1471.2051 (1474.2315) lr 1.9686e-03 eta 0:16:11
epoch [6/50] batch [100/176] time 0.087 (0.122) data 0.000 (0.003) loss 1.5805 (1.4406) teacher_loss 0.3048 (0.1880) loss_zs_kd 0.0491 (0.0372) loss_oracle 0.6379 (0.6141) kd_loss 0.9322 (0.9269) acc 87.5000 (93.8438) gate/entropy 1.0823 (1.0844) gate/usage_max 0.4159 (0.4107) gate/usage_min 0.2712 (0.2761) gate/usage_std 0.0608 (0.0568) teacher/entropy 0.0063 (0.0277) teacher/usage_max 0.7828 (0.7647) teacher/usage_min 0.0000 (0.0099) teacher/usage_std 0.3299 (0.3208) nleep/row_max_mean 1519.2701 (1503.4243) nleep/row_max_std 35.8008 (55.4328) nleep/row_min_mean 1487.2299 (1473.9933) lr 1.9686e-03 eta 0:15:57
epoch [6/50] batch [120/176] time 0.161 (0.122) data 0.000 (0.003) loss 1.4023 (1.4429) teacher_loss 0.1102 (0.1916) loss_zs_kd 0.0453 (0.0376) loss_oracle 0.6715 (0.6171) kd_loss 0.9337 (0.9240) acc 96.8750 (93.6719) gate/entropy 1.0815 (1.0840) gate/usage_max 0.4179 (0.4117) gate/usage_min 0.2693 (0.2752) gate/usage_std 0.0624 (0.0576) teacher/entropy 0.0252 (0.0279) teacher/usage_max 0.7068 (0.7677) teacher/usage_min 0.0111 (0.0093) teacher/usage_std 0.2863 (0.3227) nleep/row_max_mean 1508.3073 (1503.4367) nleep/row_max_std 54.7410 (55.3320) nleep/row_min_mean 1478.5876 (1474.1656) lr 1.9686e-03 eta 0:15:53
epoch [6/50] batch [140/176] time 0.100 (0.118) data 0.000 (0.002) loss 1.5790 (1.4437) teacher_loss 0.3578 (0.1949) loss_zs_kd 0.0375 (0.0371) loss_oracle 0.6017 (0.6191) kd_loss 0.9016 (0.9207) acc 90.6250 (93.6607) gate/entropy 1.0807 (1.0836) gate/usage_max 0.4196 (0.4127) gate/usage_min 0.2676 (0.2742) gate/usage_std 0.0637 (0.0584) teacher/entropy 0.0461 (0.0291) teacher/usage_max 0.7425 (0.7685) teacher/usage_min 0.0242 (0.0089) teacher/usage_std 0.3016 (0.3231) nleep/row_max_mean 1495.8816 (1502.8369) nleep/row_max_std 61.3075 (55.6991) nleep/row_min_mean 1466.3088 (1473.6453) lr 1.9686e-03 eta 0:15:16
epoch [6/50] batch [160/176] time 0.103 (0.116) data 0.000 (0.002) loss 1.4750 (1.4413) teacher_loss 0.2559 (0.1954) loss_zs_kd 0.0480 (0.0371) loss_oracle 0.5714 (0.6168) kd_loss 0.9095 (0.9189) acc 90.6250 (93.5352) gate/entropy 1.0799 (1.0832) gate/usage_max 0.4214 (0.4137) gate/usage_min 0.2660 (0.2733) gate/usage_std 0.0651 (0.0591) teacher/entropy 0.0309 (0.0292) teacher/usage_max 0.7603 (0.7687) teacher/usage_min 0.0294 (0.0095) teacher/usage_std 0.3108 (0.3231) nleep/row_max_mean 1499.6248 (1502.6753) nleep/row_max_std 48.8605 (55.3224) nleep/row_min_mean 1467.6545 (1473.4512) lr 1.9686e-03 eta 0:15:00
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,165
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,602
* accuracy: 60.3%
* error: 39.7%
* macro_f1: 55.2%
******* Domain l best val acc:      89.4%, epoch: 6 *******
******* Domain l best val test acc: 60.3%, epoch: 6 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [7/50] batch [20/176] time 0.145 (0.150) data 0.000 (0.015) loss 1.4770 (1.4160) teacher_loss 0.2988 (0.1905) loss_zs_kd 0.0311 (0.0386) loss_oracle 0.5236 (0.6219) kd_loss 0.9008 (0.8953) acc 84.3750 (93.2812) gate/entropy 1.0780 (1.0785) gate/usage_max 0.4258 (0.4246) gate/usage_min 0.2628 (0.2636) gate/usage_std 0.0683 (0.0675) teacher/entropy 0.0016 (0.0230) teacher/usage_max 0.8435 (0.8030) teacher/usage_min 0.0002 (0.0067) teacher/usage_std 0.3663 (0.3420) nleep/row_max_mean 1513.3694 (1501.4483) nleep/row_max_std 56.1497 (56.3253) nleep/row_min_mean 1480.5990 (1471.0980) lr 1.9511e-03 eta 0:19:22
epoch [7/50] batch [40/176] time 0.123 (0.142) data 0.000 (0.008) loss 1.3996 (1.4135) teacher_loss 0.1737 (0.1800) loss_zs_kd 0.0353 (0.0366) loss_oracle 0.6658 (0.6356) kd_loss 0.8753 (0.8974) acc 93.7500 (93.7500) gate/entropy 1.0772 (1.0781) gate/usage_max 0.4276 (0.4257) gate/usage_min 0.2611 (0.2628) gate/usage_std 0.0697 (0.0683) teacher/entropy 0.0267 (0.0226) teacher/usage_max 0.8359 (0.7912) teacher/usage_min 0.0040 (0.0056) teacher/usage_std 0.3610 (0.3364) nleep/row_max_mean 1493.3971 (1501.3272) nleep/row_max_std 61.9689 (56.2124) nleep/row_min_mean 1463.4011 (1470.9992) lr 1.9511e-03 eta 0:18:15
epoch [7/50] batch [60/176] time 0.152 (0.140) data 0.001 (0.005) loss 1.3944 (1.4378) teacher_loss 0.1329 (0.2054) loss_zs_kd 0.0281 (0.0371) loss_oracle 0.6787 (0.6359) kd_loss 0.9081 (0.8959) acc 93.7500 (93.2292) gate/entropy 1.0764 (1.0776) gate/usage_max 0.4292 (0.4266) gate/usage_min 0.2594 (0.2619) gate/usage_std 0.0710 (0.0690) teacher/entropy 0.0325 (0.0248) teacher/usage_max 0.7050 (0.7836) teacher/usage_min 0.0002 (0.0052) teacher/usage_std 0.2890 (0.3320) nleep/row_max_mean 1494.3865 (1500.6885) nleep/row_max_std 54.9146 (57.0111) nleep/row_min_mean 1465.2426 (1470.4481) lr 1.9511e-03 eta 0:17:57
epoch [7/50] batch [80/176] time 0.146 (0.140) data 0.000 (0.004) loss 1.1928 (1.4327) teacher_loss 0.0353 (0.2036) loss_zs_kd 0.0260 (0.0378) loss_oracle 0.5605 (0.6333) kd_loss 0.8642 (0.8935) acc 100.0000 (93.0469) gate/entropy 1.0755 (1.0772) gate/usage_max 0.4309 (0.4275) gate/usage_min 0.2579 (0.2611) gate/usage_std 0.0723 (0.0697) teacher/entropy 0.0354 (0.0263) teacher/usage_max 0.8228 (0.7811) teacher/usage_min 0.0009 (0.0052) teacher/usage_std 0.3534 (0.3307) nleep/row_max_mean 1486.6074 (1500.2089) nleep/row_max_std 60.2204 (57.8422) nleep/row_min_mean 1458.5933 (1470.2867) lr 1.9511e-03 eta 0:17:53
epoch [7/50] batch [100/176] time 0.149 (0.140) data 0.000 (0.003) loss 1.3831 (1.4273) teacher_loss 0.1759 (0.1991) loss_zs_kd 0.0497 (0.0389) loss_oracle 0.6414 (0.6331) kd_loss 0.8616 (0.8921) acc 93.7500 (93.2812) gate/entropy 1.0747 (1.0768) gate/usage_max 0.4327 (0.4284) gate/usage_min 0.2564 (0.2603) gate/usage_std 0.0737 (0.0704) teacher/entropy 0.0386 (0.0265) teacher/usage_max 0.8131 (0.7802) teacher/usage_min 0.0037 (0.0054) teacher/usage_std 0.3471 (0.3303) nleep/row_max_mean 1486.1958 (1500.2859) nleep/row_max_std 60.3979 (57.8177) nleep/row_min_mean 1458.2476 (1470.5250) lr 1.9511e-03 eta 0:17:51
epoch [7/50] batch [120/176] time 0.127 (0.141) data 0.000 (0.003) loss 1.4766 (1.4316) teacher_loss 0.2884 (0.1997) loss_zs_kd 0.0273 (0.0391) loss_oracle 0.6214 (0.6412) kd_loss 0.8638 (0.8917) acc 84.3750 (93.2292) gate/entropy 1.0738 (1.0763) gate/usage_max 0.4345 (0.4293) gate/usage_min 0.2552 (0.2595) gate/usage_std 0.0750 (0.0710) teacher/entropy 0.0521 (0.0273) teacher/usage_max 0.7736 (0.7751) teacher/usage_min 0.0339 (0.0063) teacher/usage_std 0.3180 (0.3276) nleep/row_max_mean 1498.4126 (1500.0397) nleep/row_max_std 54.0726 (57.5845) nleep/row_min_mean 1470.3237 (1470.4421) lr 1.9511e-03 eta 0:17:54
epoch [7/50] batch [140/176] time 0.124 (0.139) data 0.000 (0.002) loss 1.5198 (1.4353) teacher_loss 0.3085 (0.1984) loss_zs_kd 0.0356 (0.0391) loss_oracle 0.6162 (0.6515) kd_loss 0.8854 (0.8916) acc 90.6250 (93.2589) gate/entropy 1.0731 (1.0759) gate/usage_max 0.4357 (0.4301) gate/usage_min 0.2538 (0.2588) gate/usage_std 0.0760 (0.0717) teacher/entropy 0.0315 (0.0276) teacher/usage_max 0.7454 (0.7707) teacher/usage_min 0.0023 (0.0068) teacher/usage_std 0.3088 (0.3251) nleep/row_max_mean 1510.3367 (1500.3437) nleep/row_max_std 55.0605 (57.1565) nleep/row_min_mean 1480.5703 (1470.8812) lr 1.9511e-03 eta 0:17:39
epoch [7/50] batch [160/176] time 0.155 (0.139) data 0.000 (0.002) loss 1.5788 (1.4378) teacher_loss 0.2937 (0.1982) loss_zs_kd 0.0553 (0.0396) loss_oracle 0.6859 (0.6584) kd_loss 0.9144 (0.8906) acc 90.6250 (93.2617) gate/entropy 1.0723 (1.0755) gate/usage_max 0.4372 (0.4309) gate/usage_min 0.2523 (0.2581) gate/usage_std 0.0772 (0.0723) teacher/entropy 0.0195 (0.0276) teacher/usage_max 0.6882 (0.7696) teacher/usage_min 0.0000 (0.0070) teacher/usage_std 0.2813 (0.3246) nleep/row_max_mean 1510.8353 (1500.7847) nleep/row_max_std 55.7373 (56.9434) nleep/row_min_mean 1479.9666 (1471.4379) lr 1.9511e-03 eta 0:17:37
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,160
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 91.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,591
* accuracy: 59.9%
* error: 40.1%
* macro_f1: 54.5%
******* Domain l best val acc:      89.4%, epoch: 6 *******
******* Domain l best val test acc: 60.3%, epoch: 6 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [8/50] batch [20/176] time 0.159 (0.134) data 0.000 (0.015) loss 1.3333 (1.4023) teacher_loss 0.1103 (0.1593) loss_zs_kd 0.0342 (0.0396) loss_oracle 0.6165 (0.6774) kd_loss 0.8977 (0.8844) acc 96.8750 (95.1562) gate/entropy 1.0714 (1.0716) gate/usage_max 0.4387 (0.4383) gate/usage_min 0.2503 (0.2509) gate/usage_std 0.0785 (0.0781) teacher/entropy 0.0272 (0.0368) teacher/usage_max 0.7062 (0.7234) teacher/usage_min 0.0000 (0.0076) teacher/usage_std 0.2896 (0.2996) nleep/row_max_mean 1512.4478 (1500.9647) nleep/row_max_std 50.5405 (57.3880) nleep/row_min_mean 1482.3435 (1472.3157) lr 1.9298e-03 eta 0:16:48
epoch [8/50] batch [40/176] time 0.080 (0.116) data 0.000 (0.008) loss 1.3090 (1.4073) teacher_loss 0.0940 (0.1674) loss_zs_kd 0.0278 (0.0396) loss_oracle 0.6327 (0.6814) kd_loss 0.8848 (0.8794) acc 100.0000 (94.5312) gate/entropy 1.0708 (1.0713) gate/usage_max 0.4396 (0.4388) gate/usage_min 0.2491 (0.2502) gate/usage_std 0.0793 (0.0786) teacher/entropy 0.0270 (0.0351) teacher/usage_max 0.7436 (0.7411) teacher/usage_min 0.0080 (0.0095) teacher/usage_std 0.3062 (0.3081) nleep/row_max_mean 1487.1289 (1499.4577) nleep/row_max_std 64.0778 (58.5045) nleep/row_min_mean 1458.6562 (1470.9929) lr 1.9298e-03 eta 0:14:31
epoch [8/50] batch [60/176] time 0.089 (0.112) data 0.001 (0.005) loss 1.3685 (1.4094) teacher_loss 0.1713 (0.1729) loss_zs_kd 0.0489 (0.0400) loss_oracle 0.6717 (0.6844) kd_loss 0.8369 (0.8743) acc 93.7500 (94.2188) gate/entropy 1.0701 (1.0710) gate/usage_max 0.4407 (0.4393) gate/usage_min 0.2477 (0.2495) gate/usage_std 0.0803 (0.0791) teacher/entropy 0.0571 (0.0391) teacher/usage_max 0.7842 (0.7408) teacher/usage_min 0.0000 (0.0084) teacher/usage_std 0.3307 (0.3080) nleep/row_max_mean 1510.7625 (1500.7480) nleep/row_max_std 50.4537 (57.9470) nleep/row_min_mean 1480.5679 (1472.1419) lr 1.9298e-03 eta 0:14:03
epoch [8/50] batch [80/176] time 0.102 (0.110) data 0.000 (0.004) loss 1.3472 (1.4071) teacher_loss 0.1640 (0.1734) loss_zs_kd 0.0262 (0.0401) loss_oracle 0.7008 (0.6803) kd_loss 0.8197 (0.8735) acc 93.7500 (94.2578) gate/entropy 1.0694 (1.0707) gate/usage_max 0.4419 (0.4398) gate/usage_min 0.2464 (0.2489) gate/usage_std 0.0812 (0.0795) teacher/entropy 0.0777 (0.0404) teacher/usage_max 0.7774 (0.7362) teacher/usage_min 0.0129 (0.0076) teacher/usage_std 0.3241 (0.3059) nleep/row_max_mean 1478.5195 (1500.0676) nleep/row_max_std 66.0320 (58.4995) nleep/row_min_mean 1453.9231 (1471.4877) lr 1.9298e-03 eta 0:13:40
epoch [8/50] batch [100/176] time 0.098 (0.111) data 0.000 (0.003) loss 1.4706 (1.4031) teacher_loss 0.1666 (0.1719) loss_zs_kd 0.0519 (0.0400) loss_oracle 0.8466 (0.6811) kd_loss 0.8548 (0.8706) acc 96.8750 (94.3125) gate/entropy 1.0688 (1.0704) gate/usage_max 0.4426 (0.4403) gate/usage_min 0.2452 (0.2483) gate/usage_std 0.0820 (0.0799) teacher/entropy 0.0484 (0.0424) teacher/usage_max 0.7665 (0.7360) teacher/usage_min 0.0281 (0.0072) teacher/usage_std 0.3147 (0.3063) nleep/row_max_mean 1494.4492 (1500.0106) nleep/row_max_std 59.1443 (58.3932) nleep/row_min_mean 1466.6827 (1471.5069) lr 1.9298e-03 eta 0:13:46
epoch [8/50] batch [120/176] time 0.149 (0.112) data 0.000 (0.003) loss 1.5021 (1.4088) teacher_loss 0.2372 (0.1766) loss_zs_kd 0.0569 (0.0403) loss_oracle 0.6897 (0.6834) kd_loss 0.8915 (0.8703) acc 90.6250 (94.2188) gate/entropy 1.0683 (1.0701) gate/usage_max 0.4433 (0.4408) gate/usage_min 0.2440 (0.2477) gate/usage_std 0.0827 (0.0803) teacher/entropy 0.0096 (0.0421) teacher/usage_max 0.7482 (0.7355) teacher/usage_min 0.0005 (0.0079) teacher/usage_std 0.3107 (0.3058) nleep/row_max_mean 1512.9768 (1500.8609) nleep/row_max_std 50.0131 (57.4147) nleep/row_min_mean 1480.4850 (1472.1829) lr 1.9298e-03 eta 0:13:52
epoch [8/50] batch [140/176] time 0.132 (0.115) data 0.000 (0.002) loss 1.3776 (1.4105) teacher_loss 0.1519 (0.1793) loss_zs_kd 0.0477 (0.0402) loss_oracle 0.7061 (0.6832) kd_loss 0.8488 (0.8695) acc 93.7500 (94.1295) gate/entropy 1.0677 (1.0698) gate/usage_max 0.4443 (0.4412) gate/usage_min 0.2429 (0.2471) gate/usage_std 0.0835 (0.0807) teacher/entropy 0.0458 (0.0415) teacher/usage_max 0.7665 (0.7369) teacher/usage_min 0.0072 (0.0078) teacher/usage_std 0.3191 (0.3063) nleep/row_max_mean 1503.3750 (1501.6037) nleep/row_max_std 60.6798 (57.4523) nleep/row_min_mean 1473.8683 (1472.8887) lr 1.9298e-03 eta 0:14:15
epoch [8/50] batch [160/176] time 0.133 (0.119) data 0.000 (0.002) loss 1.3777 (1.4121) teacher_loss 0.2544 (0.1795) loss_zs_kd 0.0570 (0.0406) loss_oracle 0.5969 (0.6857) kd_loss 0.7964 (0.8694) acc 87.5000 (94.1602) gate/entropy 1.0671 (1.0695) gate/usage_max 0.4452 (0.4417) gate/usage_min 0.2418 (0.2465) gate/usage_std 0.0843 (0.0811) teacher/entropy 0.0950 (0.0413) teacher/usage_max 0.7783 (0.7362) teacher/usage_min 0.0172 (0.0088) teacher/usage_std 0.3238 (0.3057) nleep/row_max_mean 1501.6040 (1501.6149) nleep/row_max_std 69.5845 (57.4736) nleep/row_min_mean 1471.4175 (1472.8824) lr 1.9298e-03 eta 0:14:39
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,171
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,620
* accuracy: 61.0%
* error: 39.0%
* macro_f1: 56.1%
******* Domain l best val acc:      89.6%, epoch: 8 *******
******* Domain l best val test acc: 61.0%, epoch: 8 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [9/50] batch [20/176] time 0.140 (0.163) data 0.000 (0.015) loss 1.3753 (1.4329) teacher_loss 0.1988 (0.1998) loss_zs_kd 0.0442 (0.0396) loss_oracle 0.6093 (0.6919) kd_loss 0.8498 (0.8674) acc 90.6250 (93.4375) gate/entropy 1.0660 (1.0663) gate/usage_max 0.4468 (0.4464) gate/usage_min 0.2399 (0.2404) gate/usage_std 0.0857 (0.0853) teacher/entropy 0.0202 (0.0352) teacher/usage_max 0.8182 (0.7353) teacher/usage_min 0.0000 (0.0102) teacher/usage_std 0.3508 (0.3042) nleep/row_max_mean 1509.0597 (1499.7690) nleep/row_max_std 54.0129 (57.2798) nleep/row_min_mean 1479.1827 (1471.2072) lr 1.9048e-03 eta 0:20:02
epoch [9/50] batch [40/176] time 0.123 (0.153) data 0.000 (0.008) loss 1.6776 (1.4405) teacher_loss 0.4577 (0.2067) loss_zs_kd 0.0495 (0.0384) loss_oracle 0.7322 (0.7031) kd_loss 0.8291 (0.8630) acc 87.5000 (93.5156) gate/entropy 1.0655 (1.0660) gate/usage_max 0.4474 (0.4468) gate/usage_min 0.2388 (0.2399) gate/usage_std 0.0863 (0.0856) teacher/entropy 0.1271 (0.0480) teacher/usage_max 0.6181 (0.7118) teacher/usage_min 0.0635 (0.0131) teacher/usage_std 0.2266 (0.2923) nleep/row_max_mean 1494.8475 (1499.0109) nleep/row_max_std 76.9464 (58.7171) nleep/row_min_mean 1469.2444 (1471.0389) lr 1.9048e-03 eta 0:18:42
epoch [9/50] batch [60/176] time 0.157 (0.150) data 0.001 (0.005) loss 1.3321 (1.4146) teacher_loss 0.1115 (0.1917) loss_zs_kd 0.0484 (0.0405) loss_oracle 0.6530 (0.6942) kd_loss 0.8699 (0.8555) acc 96.8750 (93.9062) gate/entropy 1.0649 (1.0658) gate/usage_max 0.4484 (0.4471) gate/usage_min 0.2379 (0.2394) gate/usage_std 0.0870 (0.0860) teacher/entropy 0.0534 (0.0516) teacher/usage_max 0.6599 (0.7200) teacher/usage_min 0.0001 (0.0119) teacher/usage_std 0.2694 (0.2963) nleep/row_max_mean 1494.4563 (1497.8807) nleep/row_max_std 64.4904 (58.7875) nleep/row_min_mean 1470.4241 (1470.4839) lr 1.9048e-03 eta 0:18:17
epoch [9/50] batch [80/176] time 0.103 (0.142) data 0.000 (0.004) loss 1.4068 (1.4121) teacher_loss 0.1006 (0.1941) loss_zs_kd 0.0560 (0.0400) loss_oracle 0.7273 (0.6884) kd_loss 0.9145 (0.8539) acc 96.8750 (93.9844) gate/entropy 1.0645 (1.0655) gate/usage_max 0.4490 (0.4475) gate/usage_min 0.2371 (0.2389) gate/usage_std 0.0876 (0.0863) teacher/entropy 0.0310 (0.0517) teacher/usage_max 0.5934 (0.7226) teacher/usage_min 0.0005 (0.0119) teacher/usage_std 0.2475 (0.2981) nleep/row_max_mean 1506.3909 (1498.0682) nleep/row_max_std 41.3843 (59.1501) nleep/row_min_mean 1477.1271 (1470.8306) lr 1.9048e-03 eta 0:17:15
epoch [9/50] batch [100/176] time 0.078 (0.134) data 0.000 (0.003) loss 1.2229 (1.4042) teacher_loss 0.0508 (0.1887) loss_zs_kd 0.0365 (0.0401) loss_oracle 0.6409 (0.6864) kd_loss 0.8334 (0.8523) acc 100.0000 (94.2812) gate/entropy 1.0641 (1.0653) gate/usage_max 0.4496 (0.4479) gate/usage_min 0.2364 (0.2385) gate/usage_std 0.0881 (0.0866) teacher/entropy 0.0769 (0.0527) teacher/usage_max 0.7203 (0.7233) teacher/usage_min 0.0375 (0.0132) teacher/usage_std 0.2861 (0.2986) nleep/row_max_mean 1482.6660 (1497.7971) nleep/row_max_std 60.0152 (58.9252) nleep/row_min_mean 1456.6343 (1470.6668) lr 1.9048e-03 eta 0:16:15
epoch [9/50] batch [120/176] time 0.104 (0.128) data 0.000 (0.003) loss 1.6206 (1.4055) teacher_loss 0.3917 (0.1900) loss_zs_kd 0.0489 (0.0414) loss_oracle 0.7063 (0.6852) kd_loss 0.8512 (0.8522) acc 93.7500 (94.2708) gate/entropy 1.0635 (1.0650) gate/usage_max 0.4503 (0.4482) gate/usage_min 0.2353 (0.2380) gate/usage_std 0.0888 (0.0869) teacher/entropy 0.0403 (0.0532) teacher/usage_max 0.7819 (0.7208) teacher/usage_min 0.0557 (0.0138) teacher/usage_std 0.3201 (0.2969) nleep/row_max_mean 1509.8179 (1497.8788) nleep/row_max_std 46.6281 (58.4877) nleep/row_min_mean 1483.6600 (1470.8615) lr 1.9048e-03 eta 0:15:32
epoch [9/50] batch [140/176] time 0.087 (0.126) data 0.000 (0.002) loss 1.2989 (1.3980) teacher_loss 0.1364 (0.1863) loss_zs_kd 0.0407 (0.0416) loss_oracle 0.6043 (0.6795) kd_loss 0.8401 (0.8511) acc 93.7500 (94.2188) gate/entropy 1.0632 (1.0648) gate/usage_max 0.4508 (0.4486) gate/usage_min 0.2347 (0.2376) gate/usage_std 0.0892 (0.0872) teacher/entropy 0.0418 (0.0546) teacher/usage_max 0.7688 (0.7198) teacher/usage_min 0.0076 (0.0156) teacher/usage_std 0.3203 (0.2956) nleep/row_max_mean 1495.9297 (1497.9019) nleep/row_max_std 63.8403 (58.3678) nleep/row_min_mean 1468.4894 (1471.0013) lr 1.9048e-03 eta 0:15:10
epoch [9/50] batch [160/176] time 0.080 (0.124) data 0.000 (0.002) loss 1.5442 (1.3994) teacher_loss 0.3071 (0.1874) loss_zs_kd 0.0303 (0.0416) loss_oracle 0.7740 (0.6777) kd_loss 0.8349 (0.8523) acc 93.7500 (94.1992) gate/entropy 1.0627 (1.0645) gate/usage_max 0.4512 (0.4489) gate/usage_min 0.2338 (0.2371) gate/usage_std 0.0897 (0.0875) teacher/entropy 0.0787 (0.0554) teacher/usage_max 0.6911 (0.7139) teacher/usage_min 0.0256 (0.0171) teacher/usage_std 0.2740 (0.2924) nleep/row_max_mean 1503.2163 (1497.7631) nleep/row_max_std 59.1778 (58.1791) nleep/row_min_mean 1477.5062 (1471.0151) lr 1.9048e-03 eta 0:14:53
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,164
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,549
* accuracy: 58.3%
* error: 41.7%
* macro_f1: 54.3%
******* Domain l best val acc:      89.6%, epoch: 8 *******
******* Domain l best val test acc: 61.0%, epoch: 8 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [10/50] batch [20/176] time 0.158 (0.138) data 0.000 (0.015) loss 1.5478 (1.4163) teacher_loss 0.2632 (0.1836) loss_zs_kd 0.0370 (0.0411) loss_oracle 0.7875 (0.6764) kd_loss 0.8723 (0.8740) acc 93.7500 (93.9062) gate/entropy 1.0621 (1.0622) gate/usage_max 0.4515 (0.4516) gate/usage_min 0.2321 (0.2326) gate/usage_std 0.0904 (0.0903) teacher/entropy 0.0963 (0.0498) teacher/usage_max 0.5318 (0.6531) teacher/usage_min 0.0236 (0.0177) teacher/usage_std 0.2219 (0.2646) nleep/row_max_mean 1499.1558 (1499.9284) nleep/row_max_std 56.7340 (56.1952) nleep/row_min_mean 1472.6951 (1473.8499) lr 1.8763e-03 eta 0:16:29
epoch [10/50] batch [40/176] time 0.142 (0.142) data 0.000 (0.007) loss 1.4245 (1.3771) teacher_loss 0.2072 (0.1610) loss_zs_kd 0.0405 (0.0410) loss_oracle 0.6706 (0.6678) kd_loss 0.8618 (0.8617) acc 90.6250 (94.6094) gate/entropy 1.0618 (1.0621) gate/usage_max 0.4517 (0.4516) gate/usage_min 0.2314 (0.2321) gate/usage_std 0.0907 (0.0904) teacher/entropy 0.0585 (0.0538) teacher/usage_max 0.7051 (0.6772) teacher/usage_min 0.0697 (0.0198) teacher/usage_std 0.2704 (0.2759) nleep/row_max_mean 1502.5286 (1500.1342) nleep/row_max_std 53.8566 (55.1399) nleep/row_min_mean 1476.8296 (1474.5655) lr 1.8763e-03 eta 0:16:59
epoch [10/50] batch [60/176] time 0.149 (0.146) data 0.000 (0.005) loss 1.2453 (1.3677) teacher_loss 0.1115 (0.1608) loss_zs_kd 0.0433 (0.0401) loss_oracle 0.5607 (0.6649) kd_loss 0.8318 (0.8544) acc 93.7500 (94.4792) gate/entropy 1.0613 (1.0619) gate/usage_max 0.4525 (0.4518) gate/usage_min 0.2306 (0.2317) gate/usage_std 0.0913 (0.0906) teacher/entropy 0.0299 (0.0546) teacher/usage_max 0.8230 (0.6937) teacher/usage_min 0.0196 (0.0191) teacher/usage_std 0.3508 (0.2836) nleep/row_max_mean 1508.0518 (1498.3484) nleep/row_max_std 56.7637 (54.3906) nleep/row_min_mean 1479.8816 (1473.0064) lr 1.8763e-03 eta 0:17:21
epoch [10/50] batch [80/176] time 0.156 (0.149) data 0.000 (0.004) loss 1.4867 (1.3677) teacher_loss 0.2808 (0.1646) loss_zs_kd 0.0428 (0.0410) loss_oracle 0.6804 (0.6618) kd_loss 0.8442 (0.8518) acc 87.5000 (94.6094) gate/entropy 1.0608 (1.0617) gate/usage_max 0.4532 (0.4520) gate/usage_min 0.2298 (0.2313) gate/usage_std 0.0919 (0.0909) teacher/entropy 0.0822 (0.0581) teacher/usage_max 0.6268 (0.6916) teacher/usage_min 0.0082 (0.0210) teacher/usage_std 0.2535 (0.2818) nleep/row_max_mean 1499.0493 (1497.3372) nleep/row_max_std 55.4842 (54.4199) nleep/row_min_mean 1476.1350 (1472.3300) lr 1.8763e-03 eta 0:17:41
epoch [10/50] batch [100/176] time 0.150 (0.148) data 0.000 (0.003) loss 1.3234 (1.3694) teacher_loss 0.2283 (0.1733) loss_zs_kd 0.0552 (0.0409) loss_oracle 0.5271 (0.6568) kd_loss 0.8039 (0.8472) acc 93.7500 (94.3125) gate/entropy 1.0604 (1.0615) gate/usage_max 0.4536 (0.4523) gate/usage_min 0.2291 (0.2310) gate/usage_std 0.0924 (0.0911) teacher/entropy 0.1212 (0.0613) teacher/usage_max 0.6331 (0.6961) teacher/usage_min 0.0125 (0.0232) teacher/usage_std 0.2538 (0.2833) nleep/row_max_mean 1496.8438 (1496.4541) nleep/row_max_std 57.3389 (54.7561) nleep/row_min_mean 1474.1364 (1471.7849) lr 1.8763e-03 eta 0:17:36
epoch [10/50] batch [120/176] time 0.159 (0.149) data 0.000 (0.003) loss 1.4794 (1.3643) teacher_loss 0.3002 (0.1759) loss_zs_kd 0.0333 (0.0408) loss_oracle 0.5325 (0.6466) kd_loss 0.8963 (0.8448) acc 90.6250 (94.1667) gate/entropy 1.0597 (1.0613) gate/usage_max 0.4547 (0.4526) gate/usage_min 0.2281 (0.2306) gate/usage_std 0.0932 (0.0914) teacher/entropy 0.0264 (0.0618) teacher/usage_max 0.6248 (0.7004) teacher/usage_min 0.0012 (0.0234) teacher/usage_std 0.2562 (0.2856) nleep/row_max_mean 1494.8101 (1495.4419) nleep/row_max_std 59.1313 (55.8760) nleep/row_min_mean 1471.2563 (1470.9763) lr 1.8763e-03 eta 0:17:35
epoch [10/50] batch [140/176] time 0.127 (0.149) data 0.000 (0.002) loss 1.3148 (1.3631) teacher_loss 0.1567 (0.1804) loss_zs_kd 0.0430 (0.0410) loss_oracle 0.5873 (0.6422) kd_loss 0.8430 (0.8411) acc 96.8750 (93.9955) gate/entropy 1.0594 (1.0610) gate/usage_max 0.4552 (0.4529) gate/usage_min 0.2277 (0.2302) gate/usage_std 0.0936 (0.0917) teacher/entropy 0.0246 (0.0629) teacher/usage_max 0.7795 (0.7072) teacher/usage_min 0.0047 (0.0245) teacher/usage_std 0.3270 (0.2884) nleep/row_max_mean 1512.4700 (1494.8845) nleep/row_max_std 31.2586 (56.1239) nleep/row_min_mean 1485.5847 (1470.5957) lr 1.8763e-03 eta 0:17:31
epoch [10/50] batch [160/176] time 0.154 (0.149) data 0.000 (0.002) loss 1.2890 (1.3626) teacher_loss 0.1084 (0.1807) loss_zs_kd 0.0317 (0.0411) loss_oracle 0.7058 (0.6450) kd_loss 0.8119 (0.8389) acc 96.8750 (94.1602) gate/entropy 1.0590 (1.0608) gate/usage_max 0.4558 (0.4532) gate/usage_min 0.2270 (0.2298) gate/usage_std 0.0941 (0.0919) teacher/entropy 0.0690 (0.0654) teacher/usage_max 0.7719 (0.7061) teacher/usage_min 0.0382 (0.0256) teacher/usage_std 0.3163 (0.2872) nleep/row_max_mean 1499.7482 (1494.4963) nleep/row_max_std 54.9300 (55.8732) nleep/row_min_mean 1475.3726 (1470.3608) lr 1.8763e-03 eta 0:17:28
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,160
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,561
* accuracy: 58.8%
* error: 41.2%
* macro_f1: 53.6%
******* Domain l best val acc:      89.6%, epoch: 8 *******
******* Domain l best val test acc: 61.0%, epoch: 8 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [11/50] batch [20/176] time 0.076 (0.140) data 0.000 (0.016) loss 1.5722 (1.3961) teacher_loss 0.3311 (0.1880) loss_zs_kd 0.0543 (0.0471) loss_oracle 0.7165 (0.6952) kd_loss 0.8557 (0.8369) acc 93.7500 (94.5312) gate/entropy 1.0583 (1.0584) gate/usage_max 0.4567 (0.4565) gate/usage_min 0.2260 (0.2263) gate/usage_std 0.0948 (0.0947) teacher/entropy 0.0745 (0.0778) teacher/usage_max 0.6045 (0.6815) teacher/usage_min 0.0108 (0.0451) teacher/usage_std 0.2451 (0.2676) nleep/row_max_mean 1505.8041 (1494.5052) nleep/row_max_std 51.5196 (53.6879) nleep/row_min_mean 1481.9546 (1471.5419) lr 1.8443e-03 eta 0:16:24
epoch [11/50] batch [40/176] time 0.062 (0.111) data 0.000 (0.008) loss 1.4458 (1.3652) teacher_loss 0.1712 (0.1652) loss_zs_kd 0.0505 (0.0444) loss_oracle 0.7689 (0.6892) kd_loss 0.8649 (0.8332) acc 93.7500 (94.6094) gate/entropy 1.0581 (1.0583) gate/usage_max 0.4568 (0.4566) gate/usage_min 0.2255 (0.2261) gate/usage_std 0.0951 (0.0948) teacher/entropy 0.0574 (0.0757) teacher/usage_max 0.6739 (0.6948) teacher/usage_min 0.0617 (0.0425) teacher/usage_std 0.2546 (0.2753) nleep/row_max_mean 1495.1108 (1492.8678) nleep/row_max_std 51.6453 (55.4846) nleep/row_min_mean 1472.4235 (1469.9565) lr 1.8443e-03 eta 0:12:54
epoch [11/50] batch [60/176] time 0.103 (0.104) data 0.001 (0.005) loss 1.2232 (1.3643) teacher_loss 0.1091 (0.1734) loss_zs_kd 0.0391 (0.0445) loss_oracle 0.5940 (0.6844) kd_loss 0.7976 (0.8264) acc 100.0000 (94.8438) gate/entropy 1.0575 (1.0582) gate/usage_max 0.4576 (0.4568) gate/usage_min 0.2248 (0.2258) gate/usage_std 0.0957 (0.0950) teacher/entropy 0.0731 (0.0769) teacher/usage_max 0.7782 (0.7075) teacher/usage_min 0.0234 (0.0407) teacher/usage_std 0.3226 (0.2825) nleep/row_max_mean 1502.5143 (1494.5316) nleep/row_max_std 54.7611 (55.4914) nleep/row_min_mean 1476.1344 (1471.3721) lr 1.8443e-03 eta 0:12:08
epoch [11/50] batch [80/176] time 0.059 (0.106) data 0.000 (0.004) loss 1.4325 (1.3778) teacher_loss 0.3518 (0.1824) loss_zs_kd 0.0414 (0.0427) loss_oracle 0.5731 (0.6886) kd_loss 0.7734 (0.8298) acc 90.6250 (94.3750) gate/entropy 1.0573 (1.0580) gate/usage_max 0.4577 (0.4570) gate/usage_min 0.2242 (0.2254) gate/usage_std 0.0960 (0.0952) teacher/entropy 0.0638 (0.0759) teacher/usage_max 0.8528 (0.7002) teacher/usage_min 0.0066 (0.0411) teacher/usage_std 0.3713 (0.2782) nleep/row_max_mean 1488.5320 (1495.2666) nleep/row_max_std 58.6824 (55.8162) nleep/row_min_mean 1463.4182 (1472.1053) lr 1.8443e-03 eta 0:12:17
epoch [11/50] batch [100/176] time 0.079 (0.107) data 0.000 (0.003) loss 1.2372 (1.3684) teacher_loss 0.0701 (0.1739) loss_zs_kd 0.0400 (0.0420) loss_oracle 0.6768 (0.6856) kd_loss 0.8087 (0.8307) acc 100.0000 (94.7812) gate/entropy 1.0569 (1.0578) gate/usage_max 0.4581 (0.4571) gate/usage_min 0.2237 (0.2251) gate/usage_std 0.0963 (0.0954) teacher/entropy 0.0777 (0.0718) teacher/usage_max 0.7354 (0.7065) teacher/usage_min 0.0278 (0.0394) teacher/usage_std 0.2968 (0.2823) nleep/row_max_mean 1489.8188 (1496.3824) nleep/row_max_std 61.7243 (55.5503) nleep/row_min_mean 1465.2510 (1472.9890) lr 1.8443e-03 eta 0:12:20
epoch [11/50] batch [120/176] time 0.152 (0.108) data 0.000 (0.003) loss 1.2525 (1.3708) teacher_loss 0.0912 (0.1776) loss_zs_kd 0.0263 (0.0412) loss_oracle 0.6695 (0.6864) kd_loss 0.8133 (0.8294) acc 100.0000 (94.6354) gate/entropy 1.0565 (1.0576) gate/usage_max 0.4587 (0.4573) gate/usage_min 0.2231 (0.2249) gate/usage_std 0.0968 (0.0955) teacher/entropy 0.0660 (0.0722) teacher/usage_max 0.7289 (0.7090) teacher/usage_min 0.0044 (0.0404) teacher/usage_std 0.2995 (0.2831) nleep/row_max_mean 1498.8452 (1496.9152) nleep/row_max_std 66.8156 (55.2884) nleep/row_min_mean 1474.7493 (1473.2854) lr 1.8443e-03 eta 0:12:28
epoch [11/50] batch [140/176] time 0.148 (0.113) data 0.000 (0.002) loss 1.5723 (1.3732) teacher_loss 0.3029 (0.1808) loss_zs_kd 0.0318 (0.0410) loss_oracle 0.7994 (0.6858) kd_loss 0.8538 (0.8290) acc 93.7500 (94.5312) gate/entropy 1.0563 (1.0575) gate/usage_max 0.4590 (0.4576) gate/usage_min 0.2227 (0.2246) gate/usage_std 0.0970 (0.0957) teacher/entropy 0.0705 (0.0711) teacher/usage_max 0.6806 (0.7122) teacher/usage_min 0.0833 (0.0405) teacher/usage_std 0.2534 (0.2847) nleep/row_max_mean 1486.2271 (1496.9731) nleep/row_max_std 60.0530 (55.3898) nleep/row_min_mean 1461.8053 (1473.2038) lr 1.8443e-03 eta 0:12:56
epoch [11/50] batch [160/176] time 0.139 (0.117) data 0.000 (0.002) loss 1.2739 (1.3818) teacher_loss 0.0816 (0.1874) loss_zs_kd 0.0459 (0.0408) loss_oracle 0.6657 (0.6864) kd_loss 0.8365 (0.8308) acc 100.0000 (94.2188) gate/entropy 1.0558 (1.0573) gate/usage_max 0.4595 (0.4578) gate/usage_min 0.2219 (0.2243) gate/usage_std 0.0976 (0.0960) teacher/entropy 0.0255 (0.0689) teacher/usage_max 0.7684 (0.7125) teacher/usage_min 0.0003 (0.0406) teacher/usage_std 0.3218 (0.2850) nleep/row_max_mean 1509.0613 (1497.1814) nleep/row_max_std 39.9953 (55.4981) nleep/row_min_mean 1482.2146 (1473.2255) lr 1.8443e-03 eta 0:13:22
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,178
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,605
* accuracy: 60.4%
* error: 39.6%
* macro_f1: 57.6%
******* Domain l best val acc:      89.9%, epoch: 11 *******
******* Domain l best val test acc: 60.4%, epoch: 11 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [12/50] batch [20/176] time 0.120 (0.150) data 0.000 (0.016) loss 1.3556 (1.3568) teacher_loss 0.1753 (0.1934) loss_zs_kd 0.0282 (0.0395) loss_oracle 0.6729 (0.6524) kd_loss 0.8297 (0.8175) acc 96.8750 (95.1562) gate/entropy 1.0550 (1.0553) gate/usage_max 0.4602 (0.4600) gate/usage_min 0.2204 (0.2208) gate/usage_std 0.0984 (0.0981) teacher/entropy 0.0518 (0.0639) teacher/usage_max 0.7114 (0.7361) teacher/usage_min 0.0036 (0.0245) teacher/usage_std 0.2910 (0.3008) nleep/row_max_mean 1506.0549 (1499.7068) nleep/row_max_std 64.7707 (58.5308) nleep/row_min_mean 1478.9750 (1473.7041) lr 1.8090e-03 eta 0:17:07
epoch [12/50] batch [40/176] time 0.137 (0.137) data 0.000 (0.008) loss 1.6304 (1.3691) teacher_loss 0.4315 (0.2012) loss_zs_kd 0.0244 (0.0367) loss_oracle 0.6491 (0.6639) kd_loss 0.8621 (0.8176) acc 87.5000 (94.5312) gate/entropy 1.0545 (1.0550) gate/usage_max 0.4606 (0.4602) gate/usage_min 0.2195 (0.2204) gate/usage_std 0.0989 (0.0984) teacher/entropy 0.0279 (0.0651) teacher/usage_max 0.7188 (0.7356) teacher/usage_min 0.0326 (0.0288) teacher/usage_std 0.2865 (0.2996) nleep/row_max_mean 1499.4567 (1500.2671) nleep/row_max_std 64.9509 (58.0992) nleep/row_min_mean 1473.2615 (1473.8927) lr 1.8090e-03 eta 0:15:36
epoch [12/50] batch [60/176] time 0.134 (0.136) data 0.000 (0.006) loss 1.4395 (1.3607) teacher_loss 0.2441 (0.2017) loss_zs_kd 0.0529 (0.0366) loss_oracle 0.7002 (0.6498) kd_loss 0.8188 (0.8157) acc 90.6250 (93.8542) gate/entropy 1.0540 (1.0548) gate/usage_max 0.4610 (0.4603) gate/usage_min 0.2185 (0.2200) gate/usage_std 0.0994 (0.0986) teacher/entropy 0.1030 (0.0654) teacher/usage_max 0.6256 (0.7363) teacher/usage_min 0.0310 (0.0263) teacher/usage_std 0.2428 (0.3011) nleep/row_max_mean 1514.0814 (1500.0458) nleep/row_max_std 52.6589 (57.8799) nleep/row_min_mean 1489.7740 (1473.9003) lr 1.8090e-03 eta 0:15:28
epoch [12/50] batch [80/176] time 0.092 (0.130) data 0.000 (0.004) loss 1.1721 (1.3482) teacher_loss 0.1097 (0.1986) loss_zs_kd 0.0452 (0.0371) loss_oracle 0.4913 (0.6338) kd_loss 0.7941 (0.8141) acc 96.8750 (93.8672) gate/entropy 1.0536 (1.0546) gate/usage_max 0.4616 (0.4605) gate/usage_min 0.2179 (0.2196) gate/usage_std 0.0999 (0.0988) teacher/entropy 0.0366 (0.0646) teacher/usage_max 0.8697 (0.7407) teacher/usage_min 0.0267 (0.0253) teacher/usage_std 0.3805 (0.3041) nleep/row_max_mean 1490.3635 (1499.8970) nleep/row_max_std 54.7123 (57.3730) nleep/row_min_mean 1464.5077 (1473.6730) lr 1.8090e-03 eta 0:14:39
epoch [12/50] batch [100/176] time 0.088 (0.126) data 0.000 (0.003) loss 1.2603 (1.3446) teacher_loss 0.1451 (0.1943) loss_zs_kd 0.0202 (0.0372) loss_oracle 0.5626 (0.6351) kd_loss 0.8237 (0.8141) acc 96.8750 (93.9688) gate/entropy 1.0531 (1.0543) gate/usage_max 0.4620 (0.4608) gate/usage_min 0.2172 (0.2192) gate/usage_std 0.1003 (0.0991) teacher/entropy 0.0184 (0.0645) teacher/usage_max 0.8065 (0.7393) teacher/usage_min 0.0002 (0.0248) teacher/usage_std 0.3437 (0.3032) nleep/row_max_mean 1506.9244 (1500.5054) nleep/row_max_std 61.0635 (56.7851) nleep/row_min_mean 1477.5834 (1473.9741) lr 1.8090e-03 eta 0:14:09
epoch [12/50] batch [120/176] time 0.092 (0.124) data 0.000 (0.003) loss 1.1760 (1.3420) teacher_loss 0.0693 (0.1915) loss_zs_kd 0.0388 (0.0381) loss_oracle 0.6626 (0.6368) kd_loss 0.7560 (0.8131) acc 96.8750 (94.0365) gate/entropy 1.0527 (1.0541) gate/usage_max 0.4624 (0.4610) gate/usage_min 0.2165 (0.2188) gate/usage_std 0.1008 (0.0993) teacher/entropy 0.0725 (0.0630) teacher/usage_max 0.8427 (0.7427) teacher/usage_min 0.0007 (0.0226) teacher/usage_std 0.3657 (0.3056) nleep/row_max_mean 1501.4139 (1501.1002) nleep/row_max_std 57.3634 (56.7787) nleep/row_min_mean 1471.6636 (1474.3381) lr 1.8090e-03 eta 0:13:53
epoch [12/50] batch [140/176] time 0.086 (0.122) data 0.000 (0.003) loss 1.5707 (1.3447) teacher_loss 0.4380 (0.1954) loss_zs_kd 0.0352 (0.0379) loss_oracle 0.6109 (0.6354) kd_loss 0.8096 (0.8127) acc 84.3750 (93.8393) gate/entropy 1.0523 (1.0539) gate/usage_max 0.4629 (0.4612) gate/usage_min 0.2161 (0.2184) gate/usage_std 0.1012 (0.0996) teacher/entropy 0.0187 (0.0620) teacher/usage_max 0.8393 (0.7450) teacher/usage_min 0.0000 (0.0224) teacher/usage_std 0.3637 (0.3067) nleep/row_max_mean 1499.0984 (1501.2597) nleep/row_max_std 64.0832 (56.8532) nleep/row_min_mean 1470.5669 (1474.3141) lr 1.8090e-03 eta 0:13:38
epoch [12/50] batch [160/176] time 0.143 (0.121) data 0.000 (0.002) loss 1.3449 (1.3452) teacher_loss 0.1674 (0.1970) loss_zs_kd 0.0370 (0.0375) loss_oracle 0.6011 (0.6317) kd_loss 0.8584 (0.8136) acc 93.7500 (93.7109) gate/entropy 1.0517 (1.0536) gate/usage_max 0.4638 (0.4615) gate/usage_min 0.2152 (0.2181) gate/usage_std 0.1019 (0.0998) teacher/entropy 0.0138 (0.0596) teacher/usage_max 0.7500 (0.7471) teacher/usage_min 0.0310 (0.0217) teacher/usage_std 0.3045 (0.3078) nleep/row_max_mean 1498.4689 (1501.4243) nleep/row_max_std 52.4534 (56.5901) nleep/row_min_mean 1468.6626 (1474.2847) lr 1.8090e-03 eta 0:13:29
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,158
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 90.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,617
* accuracy: 60.9%
* error: 39.1%
* macro_f1: 56.5%
******* Domain l best val acc:      89.9%, epoch: 11 *******
******* Domain l best val test acc: 60.4%, epoch: 11 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [13/50] batch [20/176] time 0.092 (0.108) data 0.001 (0.017) loss 1.4270 (1.3585) teacher_loss 0.2916 (0.2099) loss_zs_kd 0.0390 (0.0383) loss_oracle 0.7289 (0.6639) kd_loss 0.7515 (0.7976) acc 93.7500 (93.1250) gate/entropy 1.0506 (1.0509) gate/usage_max 0.4657 (0.4652) gate/usage_min 0.2142 (0.2145) gate/usage_std 0.1031 (0.1028) teacher/entropy 0.0990 (0.0513) teacher/usage_max 0.7701 (0.7840) teacher/usage_min 0.0007 (0.0091) teacher/usage_std 0.3226 (0.3307) nleep/row_max_mean 1472.6187 (1499.3887) nleep/row_max_std 66.8275 (59.2580) nleep/row_min_mean 1450.7056 (1470.9626) lr 1.7705e-03 eta 0:12:02
epoch [13/50] batch [40/176] time 0.066 (0.116) data 0.000 (0.008) loss 1.2446 (1.3406) teacher_loss 0.0721 (0.1852) loss_zs_kd 0.0389 (0.0395) loss_oracle 0.7018 (0.6619) kd_loss 0.8021 (0.8046) acc 100.0000 (94.2969) gate/entropy 1.0502 (1.0506) gate/usage_max 0.4663 (0.4656) gate/usage_min 0.2138 (0.2142) gate/usage_std 0.1035 (0.1031) teacher/entropy 0.0544 (0.0469) teacher/usage_max 0.8131 (0.7790) teacher/usage_min 0.0576 (0.0125) teacher/usage_std 0.3405 (0.3279) nleep/row_max_mean 1486.0090 (1499.3032) nleep/row_max_std 64.8238 (57.7360) nleep/row_min_mean 1459.6707 (1471.0177) lr 1.7705e-03 eta 0:12:48
epoch [13/50] batch [60/176] time 0.085 (0.112) data 0.001 (0.006) loss 1.1600 (1.3459) teacher_loss 0.1107 (0.1952) loss_zs_kd 0.0300 (0.0394) loss_oracle 0.5613 (0.6586) kd_loss 0.7537 (0.8017) acc 93.7500 (93.8021) gate/entropy 1.0497 (1.0504) gate/usage_max 0.4669 (0.4659) gate/usage_min 0.2131 (0.2140) gate/usage_std 0.1041 (0.1033) teacher/entropy 0.0368 (0.0513) teacher/usage_max 0.9233 (0.7751) teacher/usage_min 0.0008 (0.0135) teacher/usage_std 0.4183 (0.3255) nleep/row_max_mean 1496.9078 (1498.4231) nleep/row_max_std 58.5193 (56.4173) nleep/row_min_mean 1466.6107 (1470.4610) lr 1.7705e-03 eta 0:12:19
epoch [13/50] batch [80/176] time 0.112 (0.108) data 0.000 (0.004) loss 1.2410 (1.3565) teacher_loss 0.1280 (0.2042) loss_zs_kd 0.0379 (0.0386) loss_oracle 0.6236 (0.6604) kd_loss 0.7822 (0.8029) acc 96.8750 (93.5547) gate/entropy 1.0491 (1.0502) gate/usage_max 0.4677 (0.4662) gate/usage_min 0.2125 (0.2137) gate/usage_std 0.1047 (0.1035) teacher/entropy 0.0275 (0.0536) teacher/usage_max 0.9326 (0.7688) teacher/usage_min 0.0079 (0.0169) teacher/usage_std 0.4243 (0.3209) nleep/row_max_mean 1498.8077 (1497.9840) nleep/row_max_std 62.3731 (56.4831) nleep/row_min_mean 1470.6561 (1470.4346) lr 1.7705e-03 eta 0:11:53
epoch [13/50] batch [100/176] time 0.089 (0.103) data 0.000 (0.004) loss 1.2435 (1.3563) teacher_loss 0.0826 (0.2033) loss_zs_kd 0.0413 (0.0399) loss_oracle 0.7173 (0.6641) kd_loss 0.7816 (0.8010) acc 93.7500 (93.5312) gate/entropy 1.0489 (1.0499) gate/usage_max 0.4680 (0.4665) gate/usage_min 0.2121 (0.2134) gate/usage_std 0.1049 (0.1038) teacher/entropy 0.0536 (0.0564) teacher/usage_max 0.8251 (0.7660) teacher/usage_min 0.0241 (0.0176) teacher/usage_std 0.3516 (0.3195) nleep/row_max_mean 1493.3357 (1497.7452) nleep/row_max_std 66.1768 (56.9758) nleep/row_min_mean 1468.0376 (1470.5157) lr 1.7705e-03 eta 0:11:18
epoch [13/50] batch [120/176] time 0.065 (0.100) data 0.000 (0.003) loss 1.3483 (1.3581) teacher_loss 0.2159 (0.2007) loss_zs_kd 0.0280 (0.0396) loss_oracle 0.6700 (0.6687) kd_loss 0.7834 (0.8033) acc 84.3750 (93.7240) gate/entropy 1.0489 (1.0497) gate/usage_max 0.4679 (0.4668) gate/usage_min 0.2120 (0.2132) gate/usage_std 0.1049 (0.1040) teacher/entropy 0.0648 (0.0578) teacher/usage_max 0.7965 (0.7604) teacher/usage_min 0.0297 (0.0226) teacher/usage_std 0.3327 (0.3152) nleep/row_max_mean 1495.6514 (1496.9205) nleep/row_max_std 48.7128 (57.3230) nleep/row_min_mean 1468.5995 (1470.0452) lr 1.7705e-03 eta 0:10:59
epoch [13/50] batch [140/176] time 0.152 (0.101) data 0.000 (0.003) loss 1.3573 (1.3630) teacher_loss 0.2162 (0.2034) loss_zs_kd 0.0308 (0.0394) loss_oracle 0.7342 (0.6747) kd_loss 0.7586 (0.8026) acc 90.6250 (93.6384) gate/entropy 1.0483 (1.0495) gate/usage_max 0.4687 (0.4670) gate/usage_min 0.2113 (0.2129) gate/usage_std 0.1055 (0.1042) teacher/entropy 0.0712 (0.0608) teacher/usage_max 0.8232 (0.7548) teacher/usage_min 0.0120 (0.0240) teacher/usage_std 0.3520 (0.3117) nleep/row_max_mean 1493.0906 (1496.1603) nleep/row_max_std 55.6522 (57.7527) nleep/row_min_mean 1468.7598 (1469.6931) lr 1.7705e-03 eta 0:10:59
epoch [13/50] batch [160/176] time 0.113 (0.104) data 0.000 (0.002) loss 1.4108 (1.3626) teacher_loss 0.1580 (0.2004) loss_zs_kd 0.0499 (0.0386) loss_oracle 0.7614 (0.6782) kd_loss 0.8471 (0.8039) acc 93.7500 (93.7305) gate/entropy 1.0479 (1.0494) gate/usage_max 0.4686 (0.4672) gate/usage_min 0.2104 (0.2127) gate/usage_std 0.1058 (0.1043) teacher/entropy 0.1206 (0.0631) teacher/usage_max 0.5568 (0.7474) teacher/usage_min 0.1011 (0.0267) teacher/usage_std 0.1861 (0.3070) nleep/row_max_mean 1493.7122 (1496.5030) nleep/row_max_std 74.3702 (57.8365) nleep/row_min_mean 1471.2456 (1470.2988) lr 1.7705e-03 eta 0:11:17
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,180
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,590
* accuracy: 59.9%
* error: 40.1%
* macro_f1: 56.9%
******* Domain l best val acc:      90.0%, epoch: 13 *******
******* Domain l best val test acc: 59.9%, epoch: 13 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [14/50] batch [20/176] time 0.154 (0.159) data 0.000 (0.017) loss 1.3878 (1.3587) teacher_loss 0.2105 (0.1914) loss_zs_kd 0.0355 (0.0397) loss_oracle 0.7369 (0.7019) kd_loss 0.7911 (0.7965) acc 96.8750 (94.5312) gate/entropy 1.0478 (1.0478) gate/usage_max 0.4687 (0.4688) gate/usage_min 0.2101 (0.2102) gate/usage_std 0.1059 (0.1059) teacher/entropy 0.1243 (0.0753) teacher/usage_max 0.6066 (0.7372) teacher/usage_min 0.0224 (0.0361) teacher/usage_std 0.2400 (0.2990) nleep/row_max_mean 1482.2882 (1493.9235) nleep/row_max_std 66.8868 (59.0386) nleep/row_min_mean 1460.0204 (1469.5562) lr 1.7290e-03 eta 0:17:14
epoch [14/50] batch [40/176] time 0.132 (0.153) data 0.000 (0.009) loss 1.3357 (1.3549) teacher_loss 0.2113 (0.1937) loss_zs_kd 0.0713 (0.0428) loss_oracle 0.6669 (0.6807) kd_loss 0.7553 (0.7995) acc 93.7500 (94.3750) gate/entropy 1.0475 (1.0476) gate/usage_max 0.4689 (0.4689) gate/usage_min 0.2096 (0.2100) gate/usage_std 0.1062 (0.1060) teacher/entropy 0.1163 (0.0768) teacher/usage_max 0.7455 (0.7320) teacher/usage_min 0.0433 (0.0424) teacher/usage_std 0.2994 (0.2955) nleep/row_max_mean 1501.6302 (1494.9895) nleep/row_max_std 44.8513 (59.2389) nleep/row_min_mean 1478.3792 (1470.7499) lr 1.7290e-03 eta 0:16:29
epoch [14/50] batch [60/176] time 0.151 (0.153) data 0.001 (0.006) loss 1.2860 (1.3599) teacher_loss 0.1829 (0.1892) loss_zs_kd 0.0436 (0.0416) loss_oracle 0.6266 (0.6862) kd_loss 0.7679 (0.8069) acc 96.8750 (94.6875) gate/entropy 1.0474 (1.0475) gate/usage_max 0.4687 (0.4689) gate/usage_min 0.2093 (0.2097) gate/usage_std 0.1062 (0.1061) teacher/entropy 0.1274 (0.0792) teacher/usage_max 0.6931 (0.7120) teacher/usage_min 0.0526 (0.0479) teacher/usage_std 0.2674 (0.2835) nleep/row_max_mean 1475.9998 (1493.6129) nleep/row_max_std 66.0238 (60.1087) nleep/row_min_mean 1449.6294 (1469.7194) lr 1.7290e-03 eta 0:16:26
epoch [14/50] batch [80/176] time 0.098 (0.145) data 0.000 (0.004) loss 1.4977 (1.3699) teacher_loss 0.3321 (0.2025) loss_zs_kd 0.0434 (0.0422) loss_oracle 0.6625 (0.6819) kd_loss 0.8127 (0.8054) acc 87.5000 (94.0234) gate/entropy 1.0470 (1.0474) gate/usage_max 0.4688 (0.4689) gate/usage_min 0.2085 (0.2095) gate/usage_std 0.1065 (0.1062) teacher/entropy 0.0591 (0.0815) teacher/usage_max 0.7277 (0.7094) teacher/usage_min 0.0302 (0.0479) teacher/usage_std 0.2920 (0.2821) nleep/row_max_mean 1495.9750 (1493.6845) nleep/row_max_std 60.2033 (59.9440) nleep/row_min_mean 1471.7451 (1469.7364) lr 1.7290e-03 eta 0:15:35
epoch [14/50] batch [100/176] time 0.169 (0.141) data 0.000 (0.004) loss 1.3329 (1.3669) teacher_loss 0.1186 (0.1937) loss_zs_kd 0.0381 (0.0429) loss_oracle 0.6912 (0.6882) kd_loss 0.8497 (0.8077) acc 96.8750 (94.1562) gate/entropy 1.0467 (1.0473) gate/usage_max 0.4692 (0.4689) gate/usage_min 0.2081 (0.2093) gate/usage_std 0.1069 (0.1063) teacher/entropy 0.0885 (0.0798) teacher/usage_max 0.6343 (0.7096) teacher/usage_min 0.1031 (0.0495) teacher/usage_std 0.2226 (0.2818) nleep/row_max_mean 1491.2046 (1493.8432) nleep/row_max_std 60.2563 (59.3400) nleep/row_min_mean 1469.8784 (1469.9327) lr 1.7290e-03 eta 0:15:02
epoch [14/50] batch [120/176] time 0.112 (0.137) data 0.000 (0.003) loss 1.3498 (1.3816) teacher_loss 0.2096 (0.2006) loss_zs_kd 0.0162 (0.0422) loss_oracle 0.6979 (0.6985) kd_loss 0.7832 (0.8107) acc 90.6250 (93.7760) gate/entropy 1.0469 (1.0472) gate/usage_max 0.4687 (0.4689) gate/usage_min 0.2081 (0.2091) gate/usage_std 0.1067 (0.1064) teacher/entropy 0.1135 (0.0814) teacher/usage_max 0.6868 (0.7003) teacher/usage_min 0.0540 (0.0524) teacher/usage_std 0.2636 (0.2762) nleep/row_max_mean 1501.6638 (1493.0991) nleep/row_max_std 56.0329 (59.3266) nleep/row_min_mean 1477.8896 (1469.4829) lr 1.7290e-03 eta 0:14:33
epoch [14/50] batch [140/176] time 0.169 (0.134) data 0.000 (0.003) loss 1.1641 (1.3846) teacher_loss 0.0514 (0.1989) loss_zs_kd 0.0353 (0.0419) loss_oracle 0.6312 (0.7005) kd_loss 0.7795 (0.8145) acc 100.0000 (93.8839) gate/entropy 1.0466 (1.0472) gate/usage_max 0.4682 (0.4688) gate/usage_min 0.2071 (0.2089) gate/usage_std 0.1068 (0.1064) teacher/entropy 0.1069 (0.0809) teacher/usage_max 0.7265 (0.6933) teacher/usage_min 0.0626 (0.0543) teacher/usage_std 0.2845 (0.2718) nleep/row_max_mean 1493.1357 (1493.1694) nleep/row_max_std 62.0168 (59.0102) nleep/row_min_mean 1471.9240 (1469.7796) lr 1.7290e-03 eta 0:14:13
epoch [14/50] batch [160/176] time 0.102 (0.130) data 0.000 (0.002) loss 1.2712 (1.3874) teacher_loss 0.1011 (0.1998) loss_zs_kd 0.0481 (0.0419) loss_oracle 0.6848 (0.6994) kd_loss 0.8037 (0.8170) acc 100.0000 (93.8281) gate/entropy 1.0470 (1.0471) gate/usage_max 0.4671 (0.4687) gate/usage_min 0.2070 (0.2087) gate/usage_std 0.1063 (0.1064) teacher/entropy 0.1215 (0.0823) teacher/usage_max 0.6799 (0.6854) teacher/usage_min 0.1086 (0.0566) teacher/usage_std 0.2486 (0.2672) nleep/row_max_mean 1477.2289 (1492.2472) nleep/row_max_std 64.9699 (59.3827) nleep/row_min_mean 1455.5991 (1469.0845) lr 1.7290e-03 eta 0:13:48
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,154
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,585
* accuracy: 59.7%
* error: 40.3%
* macro_f1: 54.4%
******* Domain l best val acc:      90.0%, epoch: 13 *******
******* Domain l best val test acc: 59.9%, epoch: 13 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [15/50] batch [20/176] time 0.155 (0.129) data 0.000 (0.016) loss 1.4520 (1.3791) teacher_loss 0.2161 (0.1882) loss_zs_kd 0.0589 (0.0420) loss_oracle 0.6632 (0.6602) kd_loss 0.8749 (0.8398) acc 90.6250 (93.4375) gate/entropy 1.0467 (1.0468) gate/usage_max 0.4665 (0.4666) gate/usage_min 0.2059 (0.2062) gate/usage_std 0.1065 (0.1064) teacher/entropy 0.0901 (0.0729) teacher/usage_max 0.6066 (0.6613) teacher/usage_min 0.1376 (0.0667) teacher/usage_std 0.1992 (0.2514) nleep/row_max_mean 1504.7229 (1495.8849) nleep/row_max_std 56.8981 (57.3251) nleep/row_min_mean 1481.6211 (1472.2381) lr 1.6845e-03 eta 0:13:35
epoch [15/50] batch [40/176] time 0.153 (0.141) data 0.000 (0.008) loss 1.4087 (1.3736) teacher_loss 0.1849 (0.1910) loss_zs_kd 0.0456 (0.0430) loss_oracle 0.6237 (0.6473) kd_loss 0.8891 (0.8374) acc 93.7500 (93.9844) gate/entropy 1.0467 (1.0467) gate/usage_max 0.4659 (0.4664) gate/usage_min 0.2054 (0.2059) gate/usage_std 0.1064 (0.1064) teacher/entropy 0.0492 (0.0731) teacher/usage_max 0.5952 (0.6701) teacher/usage_min 0.0723 (0.0688) teacher/usage_std 0.2135 (0.2550) nleep/row_max_mean 1508.1941 (1494.2764) nleep/row_max_std 47.8048 (58.6612) nleep/row_min_mean 1485.4214 (1470.7302) lr 1.6845e-03 eta 0:14:49
epoch [15/50] batch [60/176] time 0.139 (0.146) data 0.001 (0.006) loss 1.3387 (1.3633) teacher_loss 0.0988 (0.1859) loss_zs_kd 0.0440 (0.0434) loss_oracle 0.7475 (0.6508) kd_loss 0.8441 (0.8304) acc 96.8750 (94.1146) gate/entropy 1.0465 (1.0467) gate/usage_max 0.4658 (0.4662) gate/usage_min 0.2050 (0.2057) gate/usage_std 0.1065 (0.1064) teacher/entropy 0.0835 (0.0754) teacher/usage_max 0.5609 (0.6814) teacher/usage_min 0.0237 (0.0671) teacher/usage_std 0.2269 (0.2617) nleep/row_max_mean 1482.4644 (1494.6570) nleep/row_max_std 72.9919 (57.8664) nleep/row_min_mean 1460.0167 (1470.9157) lr 1.6845e-03 eta 0:15:13
epoch [15/50] batch [80/176] time 0.155 (0.148) data 0.000 (0.004) loss 1.3528 (1.3719) teacher_loss 0.2558 (0.1955) loss_zs_kd 0.0423 (0.0452) loss_oracle 0.5868 (0.6527) kd_loss 0.7824 (0.8274) acc 96.8750 (93.7500) gate/entropy 1.0463 (1.0466) gate/usage_max 0.4656 (0.4661) gate/usage_min 0.2044 (0.2055) gate/usage_std 0.1067 (0.1065) teacher/entropy 0.0665 (0.0781) teacher/usage_max 0.7627 (0.6800) teacher/usage_min 0.0079 (0.0654) teacher/usage_std 0.3168 (0.2612) nleep/row_max_mean 1508.0059 (1494.4401) nleep/row_max_std 52.2227 (57.7565) nleep/row_min_mean 1483.0801 (1470.6734) lr 1.6845e-03 eta 0:15:22
epoch [15/50] batch [100/176] time 0.138 (0.149) data 0.000 (0.003) loss 1.4783 (1.3647) teacher_loss 0.3251 (0.1933) loss_zs_kd 0.0387 (0.0450) loss_oracle 0.6914 (0.6476) kd_loss 0.7881 (0.8251) acc 87.5000 (93.8125) gate/entropy 1.0463 (1.0466) gate/usage_max 0.4649 (0.4659) gate/usage_min 0.2039 (0.2052) gate/usage_std 0.1066 (0.1065) teacher/entropy 0.0556 (0.0766) teacher/usage_max 0.7880 (0.6812) teacher/usage_min 0.0137 (0.0584) teacher/usage_std 0.3302 (0.2636) nleep/row_max_mean 1507.5348 (1494.0501) nleep/row_max_std 58.9969 (57.6845) nleep/row_min_mean 1478.8135 (1470.2288) lr 1.6845e-03 eta 0:15:26
epoch [15/50] batch [120/176] time 0.123 (0.149) data 0.000 (0.003) loss 1.2721 (1.3651) teacher_loss 0.0833 (0.1907) loss_zs_kd 0.0575 (0.0462) loss_oracle 0.6375 (0.6465) kd_loss 0.8413 (0.8280) acc 96.8750 (93.9583) gate/entropy 1.0462 (1.0465) gate/usage_max 0.4645 (0.4657) gate/usage_min 0.2035 (0.2050) gate/usage_std 0.1066 (0.1065) teacher/entropy 0.0790 (0.0743) teacher/usage_max 0.6052 (0.6772) teacher/usage_min 0.0438 (0.0567) teacher/usage_std 0.2296 (0.2621) nleep/row_max_mean 1488.9385 (1493.6616) nleep/row_max_std 58.2479 (57.8178) nleep/row_min_mean 1464.2953 (1469.7628) lr 1.6845e-03 eta 0:15:25
epoch [15/50] batch [140/176] time 0.147 (0.149) data 0.000 (0.003) loss 1.3924 (1.3589) teacher_loss 0.1118 (0.1882) loss_zs_kd 0.0256 (0.0453) loss_oracle 0.7511 (0.6433) kd_loss 0.8923 (0.8264) acc 96.8750 (93.9955) gate/entropy 1.0458 (1.0465) gate/usage_max 0.4649 (0.4656) gate/usage_min 0.2028 (0.2047) gate/usage_std 0.1070 (0.1065) teacher/entropy 0.0613 (0.0746) teacher/usage_max 0.5885 (0.6809) teacher/usage_min 0.1033 (0.0566) teacher/usage_std 0.1989 (0.2639) nleep/row_max_mean 1496.4612 (1493.3903) nleep/row_max_std 63.7414 (58.0373) nleep/row_min_mean 1474.9563 (1469.5115) lr 1.6845e-03 eta 0:15:21
epoch [15/50] batch [160/176] time 0.154 (0.147) data 0.000 (0.002) loss 1.4066 (1.3548) teacher_loss 0.2596 (0.1873) loss_zs_kd 0.0557 (0.0455) loss_oracle 0.6795 (0.6380) kd_loss 0.7793 (0.8258) acc 90.6250 (94.0234) gate/entropy 1.0457 (1.0464) gate/usage_max 0.4648 (0.4654) gate/usage_min 0.2026 (0.2045) gate/usage_std 0.1070 (0.1066) teacher/entropy 0.1033 (0.0736) teacher/usage_max 0.7223 (0.6830) teacher/usage_min 0.0500 (0.0548) teacher/usage_std 0.2844 (0.2657) nleep/row_max_mean 1502.1284 (1493.9046) nleep/row_max_std 46.9652 (57.5194) nleep/row_min_mean 1480.8711 (1470.0322) lr 1.6845e-03 eta 0:15:10
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,141
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 90.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,541
* accuracy: 58.0%
* error: 42.0%
* macro_f1: 53.2%
******* Domain l best val acc:      90.0%, epoch: 13 *******
******* Domain l best val test acc: 59.9%, epoch: 13 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [16/50] batch [20/176] time 0.080 (0.116) data 0.000 (0.018) loss 1.4266 (1.3395) teacher_loss 0.2361 (0.1994) loss_zs_kd 0.0542 (0.0442) loss_oracle 0.5800 (0.5906) kd_loss 0.8734 (0.8227) acc 96.8750 (94.2188) gate/entropy 1.0455 (1.0454) gate/usage_max 0.4649 (0.4650) gate/usage_min 0.2024 (0.2022) gate/usage_std 0.1072 (0.1073) teacher/entropy 0.0630 (0.0625) teacher/usage_max 0.6603 (0.7080) teacher/usage_min 0.1166 (0.0449) teacher/usage_std 0.2352 (0.2805) nleep/row_max_mean 1480.3032 (1495.4216) nleep/row_max_std 60.9899 (56.3620) nleep/row_min_mean 1457.8246 (1471.5330) lr 1.6374e-03 eta 0:11:51
epoch [16/50] batch [40/176] time 0.080 (0.105) data 0.000 (0.009) loss 1.3468 (1.3296) teacher_loss 0.2055 (0.1864) loss_zs_kd 0.0443 (0.0429) loss_oracle 0.6321 (0.6009) kd_loss 0.8031 (0.8214) acc 93.7500 (94.1406) gate/entropy 1.0451 (1.0453) gate/usage_max 0.4654 (0.4652) gate/usage_min 0.2018 (0.2020) gate/usage_std 0.1076 (0.1074) teacher/entropy 0.0801 (0.0635) teacher/usage_max 0.6775 (0.7042) teacher/usage_min 0.0213 (0.0422) teacher/usage_std 0.2689 (0.2793) nleep/row_max_mean 1501.0254 (1495.2134) nleep/row_max_std 41.9070 (55.2313) nleep/row_min_mean 1477.2832 (1471.3779) lr 1.6374e-03 eta 0:10:45
epoch [16/50] batch [60/176] time 0.076 (0.105) data 0.001 (0.006) loss 1.2714 (1.3405) teacher_loss 0.1123 (0.1986) loss_zs_kd 0.0371 (0.0416) loss_oracle 0.6231 (0.6022) kd_loss 0.8290 (0.8200) acc 96.8750 (93.6979) gate/entropy 1.0449 (1.0452) gate/usage_max 0.4655 (0.4653) gate/usage_min 0.2015 (0.2019) gate/usage_std 0.1078 (0.1075) teacher/entropy 0.0336 (0.0623) teacher/usage_max 0.7804 (0.7098) teacher/usage_min 0.0496 (0.0412) teacher/usage_std 0.3199 (0.2831) nleep/row_max_mean 1489.3937 (1493.4940) nleep/row_max_std 59.6817 (56.2555) nleep/row_min_mean 1465.3842 (1469.8215) lr 1.6374e-03 eta 0:10:38
epoch [16/50] batch [80/176] time 0.068 (0.105) data 0.000 (0.005) loss 1.4664 (1.3499) teacher_loss 0.3813 (0.2093) loss_zs_kd 0.0316 (0.0415) loss_oracle 0.5342 (0.6084) kd_loss 0.8022 (0.8157) acc 87.5000 (93.4375) gate/entropy 1.0446 (1.0451) gate/usage_max 0.4653 (0.4653) gate/usage_min 0.2008 (0.2017) gate/usage_std 0.1080 (0.1076) teacher/entropy 0.0244 (0.0676) teacher/usage_max 0.8149 (0.7057) teacher/usage_min 0.0006 (0.0407) teacher/usage_std 0.3487 (0.2808) nleep/row_max_mean 1499.6702 (1492.9946) nleep/row_max_std 53.0710 (56.0717) nleep/row_min_mean 1477.8660 (1469.7684) lr 1.6374e-03 eta 0:10:40
epoch [16/50] batch [100/176] time 0.086 (0.106) data 0.000 (0.004) loss 1.4479 (1.3569) teacher_loss 0.3181 (0.2148) loss_zs_kd 0.0265 (0.0410) loss_oracle 0.6839 (0.6145) kd_loss 0.7747 (0.8143) acc 84.3750 (92.9062) gate/entropy 1.0444 (1.0450) gate/usage_max 0.4654 (0.4653) gate/usage_min 0.2005 (0.2015) gate/usage_std 0.1081 (0.1077) teacher/entropy 0.0680 (0.0681) teacher/usage_max 0.7968 (0.7079) teacher/usage_min 0.0218 (0.0405) teacher/usage_std 0.3342 (0.2820) nleep/row_max_mean 1494.9905 (1493.2435) nleep/row_max_std 62.1095 (56.7444) nleep/row_min_mean 1473.2317 (1470.2325) lr 1.6374e-03 eta 0:10:42
epoch [16/50] batch [120/176] time 0.152 (0.107) data 0.000 (0.003) loss 1.3223 (1.3570) teacher_loss 0.1304 (0.2112) loss_zs_kd 0.0592 (0.0403) loss_oracle 0.6435 (0.6215) kd_loss 0.8406 (0.8148) acc 96.8750 (93.0990) gate/entropy 1.0443 (1.0449) gate/usage_max 0.4653 (0.4653) gate/usage_min 0.2001 (0.2013) gate/usage_std 0.1083 (0.1078) teacher/entropy 0.0199 (0.0682) teacher/usage_max 0.7529 (0.7080) teacher/usage_min 0.0283 (0.0421) teacher/usage_std 0.3067 (0.2819) nleep/row_max_mean 1508.6086 (1493.4684) nleep/row_max_std 49.5066 (57.1966) nleep/row_min_mean 1481.7124 (1470.4750) lr 1.6374e-03 eta 0:10:46
epoch [16/50] batch [140/176] time 0.137 (0.112) data 0.000 (0.003) loss 1.3247 (1.3562) teacher_loss 0.1415 (0.2075) loss_zs_kd 0.0410 (0.0391) loss_oracle 0.7412 (0.6291) kd_loss 0.7922 (0.8146) acc 93.7500 (93.3259) gate/entropy 1.0441 (1.0448) gate/usage_max 0.4651 (0.4653) gate/usage_min 0.1997 (0.2011) gate/usage_std 0.1084 (0.1079) teacher/entropy 0.1234 (0.0681) teacher/usage_max 0.6136 (0.7073) teacher/usage_min 0.0473 (0.0410) teacher/usage_std 0.2313 (0.2816) nleep/row_max_mean 1486.3671 (1493.6137) nleep/row_max_std 62.0111 (57.4558) nleep/row_min_mean 1465.8423 (1470.5864) lr 1.6374e-03 eta 0:11:15
epoch [16/50] batch [160/176] time 0.171 (0.118) data 0.000 (0.002) loss 1.4587 (1.3598) teacher_loss 0.3210 (0.2092) loss_zs_kd 0.0313 (0.0385) loss_oracle 0.6601 (0.6329) kd_loss 0.7920 (0.8150) acc 87.5000 (93.3008) gate/entropy 1.0440 (1.0447) gate/usage_max 0.4649 (0.4652) gate/usage_min 0.1993 (0.2009) gate/usage_std 0.1084 (0.1079) teacher/entropy 0.0924 (0.0675) teacher/usage_max 0.7589 (0.7066) teacher/usage_min 0.0778 (0.0404) teacher/usage_std 0.3030 (0.2815) nleep/row_max_mean 1495.2488 (1493.2282) nleep/row_max_std 62.3131 (57.5917) nleep/row_min_mean 1469.9961 (1470.2136) lr 1.6374e-03 eta 0:11:45
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,149
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 90.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,636
* accuracy: 61.6%
* error: 38.4%
* macro_f1: 57.6%
******* Domain l best val acc:      90.0%, epoch: 13 *******
******* Domain l best val test acc: 59.9%, epoch: 13 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [17/50] batch [20/176] time 0.133 (0.156) data 0.000 (0.015) loss 1.4125 (1.4108) teacher_loss 0.1922 (0.2343) loss_zs_kd 0.0381 (0.0350) loss_oracle 0.6499 (0.6780) kd_loss 0.8763 (0.8201) acc 93.7500 (93.4375) gate/entropy 1.0438 (1.0439) gate/usage_max 0.4643 (0.4643) gate/usage_min 0.1985 (0.1988) gate/usage_std 0.1085 (0.1084) teacher/entropy 0.0381 (0.0740) teacher/usage_max 0.7093 (0.6837) teacher/usage_min 0.1035 (0.0494) teacher/usage_std 0.2680 (0.2672) nleep/row_max_mean 1496.1992 (1489.1991) nleep/row_max_std 59.8594 (59.0680) nleep/row_min_mean 1473.6650 (1467.5739) lr 1.5878e-03 eta 0:15:27
epoch [17/50] batch [40/176] time 0.158 (0.151) data 0.000 (0.007) loss 1.3442 (1.4094) teacher_loss 0.1360 (0.2370) loss_zs_kd 0.0174 (0.0340) loss_oracle 0.7135 (0.6775) kd_loss 0.8427 (0.8167) acc 96.8750 (92.5000) gate/entropy 1.0437 (1.0438) gate/usage_max 0.4642 (0.4642) gate/usage_min 0.1983 (0.1986) gate/usage_std 0.1086 (0.1085) teacher/entropy 0.0699 (0.0767) teacher/usage_max 0.6489 (0.6859) teacher/usage_min 0.0636 (0.0495) teacher/usage_std 0.2411 (0.2685) nleep/row_max_mean 1489.1250 (1492.2241) nleep/row_max_std 55.5300 (57.3742) nleep/row_min_mean 1466.2374 (1470.5424) lr 1.5878e-03 eta 0:14:59
epoch [17/50] batch [60/176] time 0.087 (0.138) data 0.001 (0.005) loss 1.4165 (1.4030) teacher_loss 0.2199 (0.2298) loss_zs_kd 0.0343 (0.0350) loss_oracle 0.6886 (0.6785) kd_loss 0.8351 (0.8165) acc 96.8750 (92.8125) gate/entropy 1.0436 (1.0438) gate/usage_max 0.4641 (0.4641) gate/usage_min 0.1981 (0.1984) gate/usage_std 0.1086 (0.1085) teacher/entropy 0.0503 (0.0790) teacher/usage_max 0.7455 (0.6766) teacher/usage_min 0.0709 (0.0481) teacher/usage_std 0.2950 (0.2639) nleep/row_max_mean 1507.3140 (1493.7751) nleep/row_max_std 39.7852 (55.9078) nleep/row_min_mean 1485.2803 (1472.3260) lr 1.5878e-03 eta 0:13:39
epoch [17/50] batch [80/176] time 0.078 (0.129) data 0.000 (0.004) loss 1.4717 (1.4135) teacher_loss 0.2878 (0.2401) loss_zs_kd 0.0359 (0.0348) loss_oracle 0.7187 (0.6851) kd_loss 0.8065 (0.8135) acc 87.5000 (92.3047) gate/entropy 1.0435 (1.0437) gate/usage_max 0.4637 (0.4641) gate/usage_min 0.1977 (0.1983) gate/usage_std 0.1087 (0.1086) teacher/entropy 0.0923 (0.0797) teacher/usage_max 0.5881 (0.6817) teacher/usage_min 0.0029 (0.0466) teacher/usage_std 0.2448 (0.2670) nleep/row_max_mean 1491.5409 (1493.7675) nleep/row_max_std 59.8582 (55.9668) nleep/row_min_mean 1470.6672 (1472.3672) lr 1.5878e-03 eta 0:12:44
epoch [17/50] batch [100/176] time 0.084 (0.125) data 0.000 (0.003) loss 1.4113 (1.4236) teacher_loss 0.1999 (0.2482) loss_zs_kd 0.0299 (0.0333) loss_oracle 0.7451 (0.6947) kd_loss 0.8238 (0.8115) acc 90.6250 (91.8125) gate/entropy 1.0435 (1.0436) gate/usage_max 0.4637 (0.4640) gate/usage_min 0.1977 (0.1981) gate/usage_std 0.1086 (0.1086) teacher/entropy 0.1136 (0.0829) teacher/usage_max 0.6121 (0.6851) teacher/usage_min 0.0890 (0.0510) teacher/usage_std 0.2150 (0.2676) nleep/row_max_mean 1481.1418 (1493.1981) nleep/row_max_std 59.1567 (56.3873) nleep/row_min_mean 1460.7307 (1471.9129) lr 1.5878e-03 eta 0:12:17
epoch [17/50] batch [120/176] time 0.167 (0.124) data 0.000 (0.003) loss 1.4785 (1.4304) teacher_loss 0.2266 (0.2536) loss_zs_kd 0.0614 (0.0336) loss_oracle 0.7079 (0.6965) kd_loss 0.8672 (0.8117) acc 96.8750 (91.7188) gate/entropy 1.0432 (1.0436) gate/usage_max 0.4643 (0.4641) gate/usage_min 0.1975 (0.1981) gate/usage_std 0.1090 (0.1086) teacher/entropy 0.1640 (0.0858) teacher/usage_max 0.5853 (0.6869) teacher/usage_min 0.1686 (0.0565) teacher/usage_std 0.1810 (0.2670) nleep/row_max_mean 1487.3229 (1492.6647) nleep/row_max_std 51.5521 (56.1688) nleep/row_min_mean 1471.9784 (1471.6170) lr 1.5878e-03 eta 0:12:07
epoch [17/50] batch [140/176] time 0.077 (0.120) data 0.000 (0.002) loss 1.3523 (1.4280) teacher_loss 0.2060 (0.2528) loss_zs_kd 0.0429 (0.0329) loss_oracle 0.6201 (0.6971) kd_loss 0.8148 (0.8102) acc 93.7500 (91.7634) gate/entropy 1.0430 (1.0435) gate/usage_max 0.4649 (0.4641) gate/usage_min 0.1974 (0.1980) gate/usage_std 0.1092 (0.1087) teacher/entropy 0.1048 (0.0901) teacher/usage_max 0.7074 (0.6868) teacher/usage_min 0.1133 (0.0620) teacher/usage_std 0.2659 (0.2655) nleep/row_max_mean 1499.9288 (1493.2338) nleep/row_max_std 52.9699 (55.5449) nleep/row_min_mean 1481.2791 (1472.4732) lr 1.5878e-03 eta 0:11:43
epoch [17/50] batch [160/176] time 0.156 (0.116) data 0.000 (0.002) loss 1.4262 (1.4266) teacher_loss 0.2885 (0.2504) loss_zs_kd 0.0308 (0.0321) loss_oracle 0.6808 (0.7008) kd_loss 0.7818 (0.8098) acc 90.6250 (91.8945) gate/entropy 1.0429 (1.0435) gate/usage_max 0.4652 (0.4642) gate/usage_min 0.1975 (0.1980) gate/usage_std 0.1093 (0.1087) teacher/entropy 0.1152 (0.0929) teacher/usage_max 0.6682 (0.6870) teacher/usage_min 0.0480 (0.0663) teacher/usage_std 0.2556 (0.2647) nleep/row_max_mean 1508.3855 (1493.3645) nleep/row_max_std 51.2103 (55.6956) nleep/row_min_mean 1490.3851 (1472.7772) lr 1.5878e-03 eta 0:11:15
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,176
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,687
* accuracy: 63.5%
* error: 36.5%
* macro_f1: 56.5%
******* Domain l best val acc:      90.0%, epoch: 13 *******
******* Domain l best val test acc: 59.9%, epoch: 13 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [18/50] batch [20/176] time 0.146 (0.157) data 0.000 (0.017) loss 1.3790 (1.4674) teacher_loss 0.1826 (0.2433) loss_zs_kd 0.0176 (0.0314) loss_oracle 0.7084 (0.7235) kd_loss 0.8335 (0.8466) acc 90.6250 (90.3125) gate/entropy 1.0431 (1.0431) gate/usage_max 0.4657 (0.4654) gate/usage_min 0.1981 (0.1980) gate/usage_std 0.1093 (0.1092) teacher/entropy 0.1160 (0.1058) teacher/usage_max 0.7143 (0.6740) teacher/usage_min 0.1120 (0.1288) teacher/usage_std 0.2706 (0.2435) nleep/row_max_mean 1489.0831 (1490.9035) nleep/row_max_std 55.3684 (54.4781) nleep/row_min_mean 1469.5682 (1471.9111) lr 1.5358e-03 eta 0:15:07
epoch [18/50] batch [40/176] time 0.123 (0.149) data 0.000 (0.009) loss 1.6032 (1.4724) teacher_loss 0.4032 (0.2395) loss_zs_kd 0.0338 (0.0339) loss_oracle 0.6975 (0.7380) kd_loss 0.8345 (0.8470) acc 81.2500 (91.0938) gate/entropy 1.0431 (1.0431) gate/usage_max 0.4663 (0.4657) gate/usage_min 0.1984 (0.1981) gate/usage_std 0.1094 (0.1092) teacher/entropy 0.0990 (0.1018) teacher/usage_max 0.7044 (0.6815) teacher/usage_min 0.1391 (0.1303) teacher/usage_std 0.2625 (0.2485) nleep/row_max_mean 1484.1987 (1492.0459) nleep/row_max_std 54.8185 (53.7810) nleep/row_min_mean 1466.8169 (1472.4059) lr 1.5358e-03 eta 0:14:17
epoch [18/50] batch [60/176] time 0.118 (0.142) data 0.001 (0.006) loss 1.4756 (1.4892) teacher_loss 0.2604 (0.2594) loss_zs_kd 0.0403 (0.0365) loss_oracle 0.7090 (0.7280) kd_loss 0.8405 (0.8476) acc 90.6250 (90.2604) gate/entropy 1.0430 (1.0431) gate/usage_max 0.4669 (0.4660) gate/usage_min 0.1987 (0.1983) gate/usage_std 0.1095 (0.1093) teacher/entropy 0.1062 (0.0996) teacher/usage_max 0.6206 (0.6846) teacher/usage_min 0.1129 (0.1299) teacher/usage_std 0.2126 (0.2504) nleep/row_max_mean 1500.5088 (1492.8972) nleep/row_max_std 49.7195 (54.1456) nleep/row_min_mean 1478.8921 (1472.6691) lr 1.5358e-03 eta 0:13:34
epoch [18/50] batch [80/176] time 0.151 (0.140) data 0.000 (0.004) loss 1.3590 (1.4847) teacher_loss 0.2190 (0.2692) loss_zs_kd 0.0236 (0.0370) loss_oracle 0.6189 (0.7021) kd_loss 0.8187 (0.8459) acc 87.5000 (90.0391) gate/entropy 1.0428 (1.0431) gate/usage_max 0.4677 (0.4663) gate/usage_min 0.1988 (0.1984) gate/usage_std 0.1098 (0.1094) teacher/entropy 0.1023 (0.0996) teacher/usage_max 0.7676 (0.6914) teacher/usage_min 0.0731 (0.1242) teacher/usage_std 0.3091 (0.2554) nleep/row_max_mean 1488.5156 (1493.4200) nleep/row_max_std 71.3636 (54.1717) nleep/row_min_mean 1466.8823 (1473.0008) lr 1.5358e-03 eta 0:13:24
epoch [18/50] batch [100/176] time 0.135 (0.141) data 0.000 (0.004) loss 1.4105 (1.4800) teacher_loss 0.1802 (0.2692) loss_zs_kd 0.0428 (0.0364) loss_oracle 0.8368 (0.7061) kd_loss 0.7905 (0.8396) acc 93.7500 (90.0938) gate/entropy 1.0429 (1.0430) gate/usage_max 0.4679 (0.4666) gate/usage_min 0.1992 (0.1986) gate/usage_std 0.1097 (0.1094) teacher/entropy 0.1066 (0.0997) teacher/usage_max 0.7216 (0.7016) teacher/usage_min 0.0836 (0.1155) teacher/usage_std 0.2783 (0.2630) nleep/row_max_mean 1488.6035 (1493.6371) nleep/row_max_std 58.6781 (54.4156) nleep/row_min_mean 1468.3784 (1472.9014) lr 1.5358e-03 eta 0:13:22
epoch [18/50] batch [120/176] time 0.157 (0.142) data 0.000 (0.003) loss 1.2541 (1.4746) teacher_loss 0.1145 (0.2654) loss_zs_kd 0.0204 (0.0352) loss_oracle 0.6973 (0.7069) kd_loss 0.7808 (0.8382) acc 93.7500 (90.1562) gate/entropy 1.0424 (1.0430) gate/usage_max 0.4690 (0.4669) gate/usage_min 0.1990 (0.1986) gate/usage_std 0.1102 (0.1095) teacher/entropy 0.0771 (0.0975) teacher/usage_max 0.7983 (0.7089) teacher/usage_min 0.0605 (0.1117) teacher/usage_std 0.3304 (0.2681) nleep/row_max_mean 1497.2144 (1493.6562) nleep/row_max_std 52.5322 (54.6964) nleep/row_min_mean 1474.0383 (1472.5670) lr 1.5358e-03 eta 0:13:27
epoch [18/50] batch [140/176] time 0.137 (0.143) data 0.000 (0.003) loss 1.3521 (1.4638) teacher_loss 0.1671 (0.2565) loss_zs_kd 0.0349 (0.0347) loss_oracle 0.6829 (0.7032) kd_loss 0.8261 (0.8384) acc 93.7500 (90.4911) gate/entropy 1.0424 (1.0429) gate/usage_max 0.4697 (0.4672) gate/usage_min 0.1995 (0.1987) gate/usage_std 0.1103 (0.1096) teacher/entropy 0.0633 (0.0945) teacher/usage_max 0.7729 (0.7142) teacher/usage_min 0.1077 (0.1093) teacher/usage_std 0.3108 (0.2718) nleep/row_max_mean 1492.4685 (1493.3535) nleep/row_max_std 56.2567 (54.9454) nleep/row_min_mean 1469.8833 (1472.0924) lr 1.5358e-03 eta 0:13:33
epoch [18/50] batch [160/176] time 0.150 (0.144) data 0.000 (0.002) loss 1.5451 (1.4588) teacher_loss 0.3589 (0.2540) loss_zs_kd 0.0456 (0.0349) loss_oracle 0.6911 (0.6973) kd_loss 0.8178 (0.8387) acc 84.3750 (90.5273) gate/entropy 1.0422 (1.0428) gate/usage_max 0.4705 (0.4676) gate/usage_min 0.1996 (0.1988) gate/usage_std 0.1106 (0.1097) teacher/entropy 0.0944 (0.0921) teacher/usage_max 0.7378 (0.7193) teacher/usage_min 0.1296 (0.1063) teacher/usage_std 0.2860 (0.2755) nleep/row_max_mean 1499.3240 (1493.3688) nleep/row_max_std 54.0670 (55.1192) nleep/row_min_mean 1475.4758 (1471.8124) lr 1.5358e-03 eta 0:13:33
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,176
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,637
* accuracy: 61.6%
* error: 38.4%
* macro_f1: 55.1%
******* Domain l best val acc:      90.0%, epoch: 13 *******
******* Domain l best val test acc: 59.9%, epoch: 13 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [19/50] batch [20/176] time 0.090 (0.114) data 0.000 (0.014) loss 1.5825 (1.4965) teacher_loss 0.4162 (0.2828) loss_zs_kd 0.0474 (0.0350) loss_oracle 0.6305 (0.7176) kd_loss 0.8273 (0.8374) acc 81.2500 (89.2188) gate/entropy 1.0417 (1.0419) gate/usage_max 0.4722 (0.4717) gate/usage_min 0.1998 (0.1998) gate/usage_std 0.1113 (0.1110) teacher/entropy 0.1072 (0.0748) teacher/usage_max 0.7391 (0.7584) teacher/usage_min 0.0808 (0.0864) teacher/usage_std 0.2898 (0.3026) nleep/row_max_mean 1486.6846 (1494.7843) nleep/row_max_std 53.5288 (55.4971) nleep/row_min_mean 1466.0571 (1470.2441) lr 1.4818e-03 eta 0:10:39
epoch [19/50] batch [40/176] time 0.121 (0.109) data 0.000 (0.007) loss 1.3020 (1.4798) teacher_loss 0.1160 (0.2596) loss_zs_kd 0.0434 (0.0417) loss_oracle 0.6653 (0.7142) kd_loss 0.8317 (0.8422) acc 96.8750 (90.6250) gate/entropy 1.0417 (1.0418) gate/usage_max 0.4731 (0.4723) gate/usage_min 0.2005 (0.2000) gate/usage_std 0.1114 (0.1112) teacher/entropy 0.0728 (0.0728) teacher/usage_max 0.7390 (0.7513) teacher/usage_min 0.1215 (0.0900) teacher/usage_std 0.2869 (0.2982) nleep/row_max_mean 1504.5872 (1494.2328) nleep/row_max_std 55.4485 (57.4607) nleep/row_min_mean 1480.6862 (1469.6356) lr 1.4818e-03 eta 0:10:08
epoch [19/50] batch [60/176] time 0.095 (0.109) data 0.001 (0.005) loss 1.4548 (1.4620) teacher_loss 0.2493 (0.2582) loss_zs_kd 0.0282 (0.0401) loss_oracle 0.7272 (0.6896) kd_loss 0.8279 (0.8389) acc 90.6250 (90.3646) gate/entropy 1.0412 (1.0417) gate/usage_max 0.4746 (0.4728) gate/usage_min 0.2005 (0.2002) gate/usage_std 0.1120 (0.1114) teacher/entropy 0.0327 (0.0729) teacher/usage_max 0.8425 (0.7557) teacher/usage_min 0.0425 (0.0870) teacher/usage_std 0.3613 (0.3014) nleep/row_max_mean 1515.3252 (1493.7728) nleep/row_max_std 46.8355 (57.5894) nleep/row_min_mean 1489.3270 (1468.8771) lr 1.4818e-03 eta 0:10:07
epoch [19/50] batch [80/176] time 0.140 (0.111) data 0.000 (0.004) loss 1.2703 (1.4417) teacher_loss 0.2055 (0.2450) loss_zs_kd 0.0315 (0.0395) loss_oracle 0.6637 (0.6819) kd_loss 0.7172 (0.8359) acc 93.7500 (91.0938) gate/entropy 1.0409 (1.0416) gate/usage_max 0.4757 (0.4734) gate/usage_min 0.2008 (0.2004) gate/usage_std 0.1125 (0.1116) teacher/entropy 0.0868 (0.0713) teacher/usage_max 0.8940 (0.7602) teacher/usage_min 0.0427 (0.0857) teacher/usage_std 0.3965 (0.3044) nleep/row_max_mean 1509.7977 (1493.3508) nleep/row_max_std 55.3611 (58.7387) nleep/row_min_mean 1483.8868 (1468.2079) lr 1.4818e-03 eta 0:10:16
epoch [19/50] batch [100/176] time 0.135 (0.111) data 0.000 (0.003) loss 1.4615 (1.4363) teacher_loss 0.3237 (0.2542) loss_zs_kd 0.0205 (0.0388) loss_oracle 0.6360 (0.6710) kd_loss 0.8095 (0.8271) acc 87.5000 (90.8125) gate/entropy 1.0406 (1.0414) gate/usage_max 0.4769 (0.4739) gate/usage_min 0.2013 (0.2006) gate/usage_std 0.1128 (0.1118) teacher/entropy 0.0274 (0.0687) teacher/usage_max 0.8668 (0.7758) teacher/usage_min 0.0386 (0.0780) teacher/usage_std 0.3779 (0.3153) nleep/row_max_mean 1501.1985 (1493.7008) nleep/row_max_std 56.6439 (58.5688) nleep/row_min_mean 1470.4907 (1467.9747) lr 1.4818e-03 eta 0:10:14
epoch [19/50] batch [120/176] time 0.147 (0.112) data 0.000 (0.003) loss 1.4385 (1.4339) teacher_loss 0.3279 (0.2606) loss_zs_kd 0.0239 (0.0370) loss_oracle 0.5936 (0.6723) kd_loss 0.8018 (0.8186) acc 87.5000 (90.7292) gate/entropy 1.0403 (1.0413) gate/usage_max 0.4783 (0.4746) gate/usage_min 0.2018 (0.2007) gate/usage_std 0.1133 (0.1120) teacher/entropy 0.0613 (0.0668) teacher/usage_max 0.8281 (0.7889) teacher/usage_min 0.0498 (0.0740) teacher/usage_std 0.3511 (0.3242) nleep/row_max_mean 1482.4683 (1494.2461) nleep/row_max_std 60.9941 (58.0620) nleep/row_min_mean 1454.4209 (1467.9725) lr 1.4818e-03 eta 0:10:18
epoch [19/50] batch [140/176] time 0.137 (0.116) data 0.000 (0.002) loss 1.3125 (1.4239) teacher_loss 0.2463 (0.2583) loss_zs_kd 0.0207 (0.0362) loss_oracle 0.7016 (0.6745) kd_loss 0.7052 (0.8102) acc 96.8750 (90.6473) gate/entropy 1.0397 (1.0411) gate/usage_max 0.4799 (0.4752) gate/usage_min 0.2019 (0.2009) gate/usage_std 0.1140 (0.1122) teacher/entropy 0.1264 (0.0645) teacher/usage_max 0.8575 (0.8028) teacher/usage_min 0.0573 (0.0689) teacher/usage_std 0.3708 (0.3338) nleep/row_max_mean 1496.5210 (1494.7589) nleep/row_max_std 67.1281 (57.6247) nleep/row_min_mean 1467.5964 (1467.9576) lr 1.4818e-03 eta 0:10:35
epoch [19/50] batch [160/176] time 0.152 (0.118) data 0.000 (0.002) loss 1.5436 (1.4127) teacher_loss 0.3829 (0.2535) loss_zs_kd 0.0298 (0.0354) loss_oracle 0.7910 (0.6745) kd_loss 0.7503 (0.8043) acc 84.3750 (90.8594) gate/entropy 1.0394 (1.0409) gate/usage_max 0.4812 (0.4759) gate/usage_min 0.2023 (0.2010) gate/usage_std 0.1145 (0.1125) teacher/entropy 0.0684 (0.0624) teacher/usage_max 0.8587 (0.8120) teacher/usage_min 0.0624 (0.0656) teacher/usage_std 0.3715 (0.3402) nleep/row_max_mean 1491.4131 (1495.1413) nleep/row_max_std 53.6985 (57.5292) nleep/row_min_mean 1465.2189 (1467.8843) lr 1.4818e-03 eta 0:10:47
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,167
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 91.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,544
* accuracy: 58.1%
* error: 41.9%
* macro_f1: 53.4%
******* Domain l best val acc:      90.0%, epoch: 13 *******
******* Domain l best val test acc: 59.9%, epoch: 13 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [20/50] batch [20/176] time 0.123 (0.179) data 0.000 (0.017) loss 1.4084 (1.3801) teacher_loss 0.2729 (0.2829) loss_zs_kd 0.0366 (0.0273) loss_oracle 0.6507 (0.6731) kd_loss 0.7919 (0.7470) acc 84.3750 (89.3750) gate/entropy 1.0383 (1.0386) gate/usage_max 0.4838 (0.4832) gate/usage_min 0.2024 (0.2024) gate/usage_std 0.1157 (0.1154) teacher/entropy 0.0180 (0.0459) teacher/usage_max 0.8750 (0.8979) teacher/usage_min 0.0575 (0.0370) teacher/usage_std 0.3830 (0.3995) nleep/row_max_mean 1500.0598 (1498.0619) nleep/row_max_std 58.5090 (55.5265) nleep/row_min_mean 1469.3945 (1468.2632) lr 1.4258e-03 eta 0:16:13
epoch [20/50] batch [40/176] time 0.122 (0.159) data 0.000 (0.009) loss 1.2015 (1.3795) teacher_loss 0.1233 (0.2787) loss_zs_kd 0.0129 (0.0259) loss_oracle 0.6809 (0.6857) kd_loss 0.7312 (0.7449) acc 90.6250 (90.1562) gate/entropy 1.0377 (1.0383) gate/usage_max 0.4854 (0.4839) gate/usage_min 0.2025 (0.2025) gate/usage_std 0.1164 (0.1157) teacher/entropy 0.0541 (0.0399) teacher/usage_max 0.9119 (0.9088) teacher/usage_min 0.0336 (0.0282) teacher/usage_std 0.4092 (0.4073) nleep/row_max_mean 1508.8456 (1498.2041) nleep/row_max_std 52.4295 (55.0052) nleep/row_min_mean 1477.3301 (1467.9703) lr 1.4258e-03 eta 0:14:19
epoch [20/50] batch [60/176] time 0.078 (0.141) data 0.001 (0.006) loss 1.3659 (1.3814) teacher_loss 0.2441 (0.2819) loss_zs_kd 0.0127 (0.0251) loss_oracle 0.7754 (0.6814) kd_loss 0.7277 (0.7463) acc 93.7500 (89.8438) gate/entropy 1.0372 (1.0380) gate/usage_max 0.4865 (0.4845) gate/usage_min 0.2025 (0.2025) gate/usage_std 0.1170 (0.1160) teacher/entropy 0.0387 (0.0375) teacher/usage_max 0.9157 (0.9075) teacher/usage_min 0.0182 (0.0278) teacher/usage_std 0.4122 (0.4065) nleep/row_max_mean 1503.9004 (1497.7954) nleep/row_max_std 58.6184 (56.0114) nleep/row_min_mean 1471.5762 (1467.1341) lr 1.4258e-03 eta 0:12:42
epoch [20/50] batch [80/176] time 0.073 (0.132) data 0.000 (0.004) loss 1.3958 (1.3823) teacher_loss 0.2906 (0.2838) loss_zs_kd 0.0279 (0.0245) loss_oracle 0.6643 (0.6821) kd_loss 0.7591 (0.7453) acc 87.5000 (89.7266) gate/entropy 1.0368 (1.0378) gate/usage_max 0.4876 (0.4852) gate/usage_min 0.2028 (0.2026) gate/usage_std 0.1175 (0.1163) teacher/entropy 0.0183 (0.0390) teacher/usage_max 0.9063 (0.9035) teacher/usage_min 0.0392 (0.0291) teacher/usage_std 0.4052 (0.4037) nleep/row_max_mean 1487.1758 (1496.9930) nleep/row_max_std 59.5823 (56.7118) nleep/row_min_mean 1456.5413 (1466.1395) lr 1.4258e-03 eta 0:11:51
epoch [20/50] batch [100/176] time 0.092 (0.126) data 0.000 (0.004) loss 1.3671 (1.3860) teacher_loss 0.3052 (0.2873) loss_zs_kd 0.0208 (0.0237) loss_oracle 0.6416 (0.6861) kd_loss 0.7307 (0.7438) acc 84.3750 (89.3438) gate/entropy 1.0361 (1.0375) gate/usage_max 0.4890 (0.4858) gate/usage_min 0.2027 (0.2026) gate/usage_std 0.1182 (0.1166) teacher/entropy 0.0608 (0.0379) teacher/usage_max 0.8867 (0.9038) teacher/usage_min 0.0565 (0.0276) teacher/usage_std 0.3913 (0.4040) nleep/row_max_mean 1499.8020 (1496.7502) nleep/row_max_std 64.6772 (56.9089) nleep/row_min_mean 1468.5088 (1465.6496) lr 1.4258e-03 eta 0:11:14
epoch [20/50] batch [120/176] time 0.075 (0.124) data 0.000 (0.003) loss 1.3332 (1.3833) teacher_loss 0.2847 (0.2867) loss_zs_kd 0.0227 (0.0234) loss_oracle 0.6309 (0.6830) kd_loss 0.7217 (0.7434) acc 90.6250 (89.2969) gate/entropy 1.0359 (1.0373) gate/usage_max 0.4898 (0.4864) gate/usage_min 0.2029 (0.2027) gate/usage_std 0.1185 (0.1169) teacher/entropy 0.0250 (0.0353) teacher/usage_max 0.9371 (0.9060) teacher/usage_min 0.0089 (0.0266) teacher/usage_std 0.4273 (0.4055) nleep/row_max_mean 1499.1500 (1496.6548) nleep/row_max_std 59.6652 (57.1619) nleep/row_min_mean 1463.2102 (1465.1866) lr 1.4258e-03 eta 0:10:59
epoch [20/50] batch [140/176] time 0.070 (0.122) data 0.000 (0.003) loss 1.5318 (1.3801) teacher_loss 0.4388 (0.2870) loss_zs_kd 0.0258 (0.0232) loss_oracle 0.7471 (0.6786) kd_loss 0.7065 (0.7422) acc 81.2500 (89.2411) gate/entropy 1.0353 (1.0370) gate/usage_max 0.4909 (0.4869) gate/usage_min 0.2028 (0.2027) gate/usage_std 0.1191 (0.1172) teacher/entropy 0.0259 (0.0335) teacher/usage_max 0.9631 (0.9072) teacher/usage_min 0.0083 (0.0245) teacher/usage_std 0.4454 (0.4065) nleep/row_max_mean 1494.1471 (1496.7616) nleep/row_max_std 59.1527 (57.2451) nleep/row_min_mean 1462.0680 (1465.0326) lr 1.4258e-03 eta 0:10:47
epoch [20/50] batch [160/176] time 0.092 (0.119) data 0.000 (0.002) loss 1.2617 (1.3816) teacher_loss 0.2202 (0.2901) loss_zs_kd 0.0147 (0.0235) loss_oracle 0.6521 (0.6763) kd_loss 0.7081 (0.7415) acc 84.3750 (89.0234) gate/entropy 1.0348 (1.0368) gate/usage_max 0.4920 (0.4875) gate/usage_min 0.2030 (0.2027) gate/usage_std 0.1197 (0.1175) teacher/entropy 0.0233 (0.0317) teacher/usage_max 0.9686 (0.9082) teacher/usage_min 0.0144 (0.0229) teacher/usage_std 0.4492 (0.4073) nleep/row_max_mean 1504.7002 (1496.8948) nleep/row_max_std 44.8095 (57.2658) nleep/row_min_mean 1470.1815 (1464.8825) lr 1.4258e-03 eta 0:10:28
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,180
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,620
* accuracy: 61.0%
* error: 39.0%
* macro_f1: 55.6%
******* Domain l best val acc:      90.0%, epoch: 13 *******
******* Domain l best val test acc: 59.9%, epoch: 13 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [21/50] batch [20/176] time 0.124 (0.147) data 0.000 (0.014) loss 1.4357 (1.3965) teacher_loss 0.3063 (0.2986) loss_zs_kd 0.0152 (0.0211) loss_oracle 0.7948 (0.7034) kd_loss 0.7244 (0.7357) acc 87.5000 (88.7500) gate/entropy 1.0339 (1.0340) gate/usage_max 0.4940 (0.4937) gate/usage_min 0.2031 (0.2030) gate/usage_std 0.1207 (0.1205) teacher/entropy 0.0236 (0.0149) teacher/usage_max 0.9138 (0.9197) teacher/usage_min 0.0009 (0.0124) teacher/usage_std 0.4119 (0.4156) nleep/row_max_mean 1492.8677 (1495.7266) nleep/row_max_std 59.1993 (61.7852) nleep/row_min_mean 1462.5852 (1461.5894) lr 1.3681e-03 eta 0:12:53
epoch [21/50] batch [40/176] time 0.154 (0.145) data 0.000 (0.007) loss 1.3020 (1.3912) teacher_loss 0.1346 (0.2798) loss_zs_kd 0.0164 (0.0214) loss_oracle 0.7955 (0.7316) kd_loss 0.7614 (0.7349) acc 96.8750 (89.3750) gate/entropy 1.0334 (1.0338) gate/usage_max 0.4948 (0.4941) gate/usage_min 0.2029 (0.2030) gate/usage_std 0.1212 (0.1208) teacher/entropy 0.0043 (0.0157) teacher/usage_max 0.8745 (0.9182) teacher/usage_min 0.0005 (0.0088) teacher/usage_std 0.3861 (0.4148) nleep/row_max_mean 1487.7211 (1495.6840) nleep/row_max_std 68.7264 (61.3619) nleep/row_min_mean 1456.1898 (1461.3773) lr 1.3681e-03 eta 0:12:37
epoch [21/50] batch [60/176] time 0.111 (0.141) data 0.001 (0.005) loss 1.4541 (1.3937) teacher_loss 0.2507 (0.2764) loss_zs_kd 0.0293 (0.0221) loss_oracle 0.9130 (0.7475) kd_loss 0.7322 (0.7325) acc 96.8750 (89.4271) gate/entropy 1.0332 (1.0336) gate/usage_max 0.4953 (0.4945) gate/usage_min 0.2030 (0.2030) gate/usage_std 0.1214 (0.1210) teacher/entropy 0.0162 (0.0155) teacher/usage_max 0.9081 (0.9199) teacher/usage_min 0.0012 (0.0076) teacher/usage_std 0.4080 (0.4160) nleep/row_max_mean 1492.0822 (1495.1675) nleep/row_max_std 44.3097 (60.6472) nleep/row_min_mean 1458.5669 (1461.0544) lr 1.3681e-03 eta 0:12:15
epoch [21/50] batch [80/176] time 0.118 (0.136) data 0.000 (0.004) loss 1.6139 (1.4050) teacher_loss 0.4133 (0.2853) loss_zs_kd 0.0200 (0.0212) loss_oracle 0.8700 (0.7554) kd_loss 0.7556 (0.7314) acc 96.8750 (89.3359) gate/entropy 1.0329 (1.0334) gate/usage_max 0.4958 (0.4948) gate/usage_min 0.2027 (0.2029) gate/usage_std 0.1217 (0.1212) teacher/entropy 0.0303 (0.0179) teacher/usage_max 0.8323 (0.9158) teacher/usage_min 0.0014 (0.0078) teacher/usage_std 0.3592 (0.4132) nleep/row_max_mean 1487.0175 (1494.5021) nleep/row_max_std 76.1434 (60.9418) nleep/row_min_mean 1452.9325 (1460.4170) lr 1.3681e-03 eta 0:11:47
epoch [21/50] batch [100/176] time 0.158 (0.137) data 0.000 (0.003) loss 1.3507 (1.4118) teacher_loss 0.1737 (0.2893) loss_zs_kd 0.0361 (0.0219) loss_oracle 0.8908 (0.7630) kd_loss 0.7136 (0.7301) acc 93.7500 (89.3438) gate/entropy 1.0325 (1.0333) gate/usage_max 0.4962 (0.4951) gate/usage_min 0.2024 (0.2028) gate/usage_std 0.1221 (0.1213) teacher/entropy 0.0260 (0.0187) teacher/usage_max 0.9438 (0.9152) teacher/usage_min 0.0271 (0.0073) teacher/usage_std 0.4317 (0.4129) nleep/row_max_mean 1501.6208 (1495.8216) nleep/row_max_std 46.6943 (60.2482) nleep/row_min_mean 1467.9987 (1461.4445) lr 1.3681e-03 eta 0:11:47
epoch [21/50] batch [120/176] time 0.140 (0.137) data 0.000 (0.002) loss 1.5692 (1.4259) teacher_loss 0.4811 (0.3013) loss_zs_kd 0.0050 (0.0211) loss_oracle 0.7254 (0.7695) kd_loss 0.7229 (0.7293) acc 78.1250 (88.8802) gate/entropy 1.0323 (1.0331) gate/usage_max 0.4964 (0.4953) gate/usage_min 0.2021 (0.2027) gate/usage_std 0.1222 (0.1215) teacher/entropy 0.0100 (0.0191) teacher/usage_max 0.9352 (0.9146) teacher/usage_min 0.0001 (0.0066) teacher/usage_std 0.4264 (0.4126) nleep/row_max_mean 1502.7722 (1496.2184) nleep/row_max_std 60.3359 (60.2881) nleep/row_min_mean 1465.0225 (1461.5318) lr 1.3681e-03 eta 0:11:49
epoch [21/50] batch [140/176] time 0.116 (0.137) data 0.000 (0.002) loss 1.3163 (1.4194) teacher_loss 0.1755 (0.2953) loss_zs_kd 0.0182 (0.0209) loss_oracle 0.7735 (0.7694) kd_loss 0.7449 (0.7289) acc 93.7500 (88.9955) gate/entropy 1.0322 (1.0330) gate/usage_max 0.4966 (0.4955) gate/usage_min 0.2020 (0.2026) gate/usage_std 0.1224 (0.1216) teacher/entropy 0.0023 (0.0188) teacher/usage_max 0.9060 (0.9148) teacher/usage_min 0.0003 (0.0063) teacher/usage_std 0.4067 (0.4127) nleep/row_max_mean 1483.1316 (1495.7413) nleep/row_max_std 65.8233 (60.2852) nleep/row_min_mean 1447.1318 (1460.9653) lr 1.3681e-03 eta 0:11:46
epoch [21/50] batch [160/176] time 0.134 (0.138) data 0.001 (0.002) loss 1.3849 (1.4200) teacher_loss 0.2571 (0.2969) loss_zs_kd 0.0235 (0.0208) loss_oracle 0.7615 (0.7692) kd_loss 0.7352 (0.7280) acc 90.6250 (88.7500) gate/entropy 1.0318 (1.0329) gate/usage_max 0.4971 (0.4956) gate/usage_min 0.2018 (0.2025) gate/usage_std 0.1227 (0.1217) teacher/entropy 0.0120 (0.0186) teacher/usage_max 0.9061 (0.9157) teacher/usage_min 0.0025 (0.0057) teacher/usage_std 0.4066 (0.4134) nleep/row_max_mean 1494.6802 (1495.6517) nleep/row_max_std 60.2188 (60.0949) nleep/row_min_mean 1458.0823 (1460.6621) lr 1.3681e-03 eta 0:11:48
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,179
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,653
* accuracy: 62.2%
* error: 37.8%
* macro_f1: 56.0%
******* Domain l best val acc:      90.0%, epoch: 13 *******
******* Domain l best val test acc: 59.9%, epoch: 13 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [22/50] batch [20/176] time 0.165 (0.127) data 0.000 (0.017) loss 1.5385 (1.4303) teacher_loss 0.3228 (0.3075) loss_zs_kd 0.0233 (0.0199) loss_oracle 0.8385 (0.7751) kd_loss 0.7848 (0.7253) acc 90.6250 (87.8125) gate/entropy 1.0313 (1.0316) gate/usage_max 0.4978 (0.4974) gate/usage_min 0.2013 (0.2015) gate/usage_std 0.1232 (0.1229) teacher/entropy 0.0552 (0.0153) teacher/usage_max 0.7401 (0.9206) teacher/usage_min 0.0282 (0.0056) teacher/usage_std 0.2994 (0.4170) nleep/row_max_mean 1466.8630 (1495.7495) nleep/row_max_std 78.5792 (57.5628) nleep/row_min_mean 1434.7424 (1458.9481) lr 1.3090e-03 eta 0:10:47
epoch [22/50] batch [40/176] time 0.103 (0.116) data 0.000 (0.008) loss 1.5541 (1.4191) teacher_loss 0.4369 (0.3021) loss_zs_kd 0.0075 (0.0203) loss_oracle 0.7391 (0.7779) kd_loss 0.7438 (0.7180) acc 84.3750 (87.9688) gate/entropy 1.0311 (1.0314) gate/usage_max 0.4983 (0.4977) gate/usage_min 0.2014 (0.2014) gate/usage_std 0.1235 (0.1231) teacher/entropy 0.0178 (0.0151) teacher/usage_max 0.8753 (0.9329) teacher/usage_min 0.0047 (0.0034) teacher/usage_std 0.3861 (0.4253) nleep/row_max_mean 1487.7771 (1495.6124) nleep/row_max_std 68.8724 (56.3147) nleep/row_min_mean 1454.0920 (1458.7266) lr 1.3090e-03 eta 0:09:46
epoch [22/50] batch [60/176] time 0.069 (0.113) data 0.001 (0.006) loss 1.4572 (1.4175) teacher_loss 0.3155 (0.2931) loss_zs_kd 0.0197 (0.0198) loss_oracle 0.8205 (0.7826) kd_loss 0.7216 (0.7232) acc 90.6250 (88.8542) gate/entropy 1.0309 (1.0313) gate/usage_max 0.4983 (0.4979) gate/usage_min 0.2011 (0.2013) gate/usage_std 0.1235 (0.1232) teacher/entropy 0.0336 (0.0148) teacher/usage_max 0.8859 (0.9221) teacher/usage_min 0.0021 (0.0029) teacher/usage_std 0.3933 (0.4180) nleep/row_max_mean 1486.0828 (1494.8351) nleep/row_max_std 57.4904 (58.8937) nleep/row_min_mean 1448.8733 (1458.0765) lr 1.3090e-03 eta 0:09:29
epoch [22/50] batch [80/176] time 0.082 (0.113) data 0.000 (0.004) loss 1.4541 (1.4187) teacher_loss 0.2557 (0.2940) loss_zs_kd 0.0225 (0.0197) loss_oracle 0.8387 (0.7808) kd_loss 0.7678 (0.7245) acc 93.7500 (88.8672) gate/entropy 1.0306 (1.0312) gate/usage_max 0.4987 (0.4980) gate/usage_min 0.2008 (0.2012) gate/usage_std 0.1238 (0.1233) teacher/entropy 0.0081 (0.0143) teacher/usage_max 0.8415 (0.9199) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.3651 (0.4165) nleep/row_max_mean 1492.2511 (1494.9180) nleep/row_max_std 74.3285 (58.3471) nleep/row_min_mean 1454.6333 (1457.9920) lr 1.3090e-03 eta 0:09:26
epoch [22/50] batch [100/176] time 0.070 (0.112) data 0.000 (0.004) loss 1.4222 (1.4276) teacher_loss 0.3205 (0.3014) loss_zs_kd 0.0137 (0.0200) loss_oracle 0.7906 (0.7857) kd_loss 0.6995 (0.7233) acc 84.3750 (88.7812) gate/entropy 1.0306 (1.0311) gate/usage_max 0.4986 (0.4981) gate/usage_min 0.2007 (0.2012) gate/usage_std 0.1238 (0.1234) teacher/entropy 0.0234 (0.0148) teacher/usage_max 0.9470 (0.9204) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.4345 (0.4168) nleep/row_max_mean 1500.6776 (1495.0182) nleep/row_max_std 44.8462 (57.7081) nleep/row_min_mean 1461.0146 (1457.8842) lr 1.3090e-03 eta 0:09:20
epoch [22/50] batch [120/176] time 0.178 (0.112) data 0.000 (0.003) loss 1.6929 (1.4272) teacher_loss 0.5904 (0.3034) loss_zs_kd 0.0281 (0.0200) loss_oracle 0.7647 (0.7808) kd_loss 0.7061 (0.7234) acc 87.5000 (88.6719) gate/entropy 1.0305 (1.0310) gate/usage_max 0.4988 (0.4983) gate/usage_min 0.2006 (0.2011) gate/usage_std 0.1239 (0.1235) teacher/entropy 0.0297 (0.0151) teacher/usage_max 0.9262 (0.9189) teacher/usage_min 0.0069 (0.0021) teacher/usage_std 0.4199 (0.4158) nleep/row_max_mean 1485.8948 (1495.4235) nleep/row_max_std 58.9837 (58.0096) nleep/row_min_mean 1447.7292 (1458.0267) lr 1.3090e-03 eta 0:09:17
epoch [22/50] batch [140/176] time 0.160 (0.114) data 0.000 (0.003) loss 1.3037 (1.4206) teacher_loss 0.2290 (0.3007) loss_zs_kd 0.0130 (0.0196) loss_oracle 0.7826 (0.7756) kd_loss 0.6768 (0.7223) acc 90.6250 (88.7946) gate/entropy 1.0302 (1.0309) gate/usage_max 0.4992 (0.4984) gate/usage_min 0.2003 (0.2010) gate/usage_std 0.1242 (0.1236) teacher/entropy 0.0206 (0.0149) teacher/usage_max 0.9948 (0.9211) teacher/usage_min 0.0001 (0.0022) teacher/usage_std 0.4677 (0.4172) nleep/row_max_mean 1511.3981 (1496.0907) nleep/row_max_std 43.1512 (57.5885) nleep/row_min_mean 1472.1450 (1458.3826) lr 1.3090e-03 eta 0:09:27
epoch [22/50] batch [160/176] time 0.124 (0.119) data 0.000 (0.002) loss 1.4661 (1.4205) teacher_loss 0.3247 (0.3013) loss_zs_kd 0.0085 (0.0190) loss_oracle 0.8960 (0.7760) kd_loss 0.6892 (0.7217) acc 84.3750 (88.6914) gate/entropy 1.0301 (1.0308) gate/usage_max 0.4992 (0.4985) gate/usage_min 0.2001 (0.2009) gate/usage_std 0.1242 (0.1237) teacher/entropy 0.0065 (0.0156) teacher/usage_max 0.9985 (0.9204) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.4703 (0.4168) nleep/row_max_mean 1511.0685 (1496.6417) nleep/row_max_std 46.4058 (57.3367) nleep/row_min_mean 1469.3702 (1458.6897) lr 1.3090e-03 eta 0:09:48
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,171
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,675
* accuracy: 63.1%
* error: 36.9%
* macro_f1: 55.7%
******* Domain l best val acc:      90.0%, epoch: 13 *******
******* Domain l best val test acc: 59.9%, epoch: 13 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [23/50] batch [20/176] time 0.134 (0.156) data 0.000 (0.018) loss 1.3063 (1.4086) teacher_loss 0.2565 (0.3216) loss_zs_kd 0.0203 (0.0203) loss_oracle 0.6352 (0.7022) kd_loss 0.7221 (0.7258) acc 90.6250 (87.5000) gate/entropy 1.0297 (1.0298) gate/usage_max 0.4998 (0.4996) gate/usage_min 0.1998 (0.1999) gate/usage_std 0.1247 (0.1246) teacher/entropy 0.0037 (0.0131) teacher/usage_max 0.9368 (0.9117) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4275 (0.4115) nleep/row_max_mean 1502.2993 (1496.6149) nleep/row_max_std 61.4437 (59.1176) nleep/row_min_mean 1459.2384 (1457.4883) lr 1.2487e-03 eta 0:12:46
epoch [23/50] batch [40/176] time 0.140 (0.150) data 0.000 (0.009) loss 1.4466 (1.3829) teacher_loss 0.3481 (0.2956) loss_zs_kd 0.0163 (0.0206) loss_oracle 0.7784 (0.7091) kd_loss 0.7012 (0.7224) acc 81.2500 (88.5156) gate/entropy 1.0294 (1.0297) gate/usage_max 0.5004 (0.4998) gate/usage_min 0.1998 (0.1998) gate/usage_std 0.1250 (0.1247) teacher/entropy 0.0276 (0.0121) teacher/usage_max 0.9295 (0.9198) teacher/usage_min 0.0011 (0.0003) teacher/usage_std 0.4224 (0.4167) nleep/row_max_mean 1494.7654 (1498.2494) nleep/row_max_std 62.8374 (57.7687) nleep/row_min_mean 1456.3950 (1458.2732) lr 1.2487e-03 eta 0:12:11
epoch [23/50] batch [60/176] time 0.124 (0.147) data 0.000 (0.006) loss 1.5182 (1.3906) teacher_loss 0.4773 (0.3022) loss_zs_kd 0.0156 (0.0198) loss_oracle 0.6443 (0.7169) kd_loss 0.7109 (0.7200) acc 78.1250 (88.4896) gate/entropy 1.0292 (1.0296) gate/usage_max 0.5006 (0.5000) gate/usage_min 0.1997 (0.1998) gate/usage_std 0.1251 (0.1248) teacher/entropy 0.0186 (0.0130) teacher/usage_max 0.9310 (0.9224) teacher/usage_min 0.0059 (0.0003) teacher/usage_std 0.4233 (0.4184) nleep/row_max_mean 1484.0562 (1497.6632) nleep/row_max_std 67.8428 (56.5317) nleep/row_min_mean 1446.8049 (1457.5963) lr 1.2487e-03 eta 0:11:55
epoch [23/50] batch [80/176] time 0.097 (0.135) data 0.000 (0.005) loss 1.7403 (1.3933) teacher_loss 0.5414 (0.3028) loss_zs_kd 0.0234 (0.0206) loss_oracle 0.8037 (0.7180) kd_loss 0.7854 (0.7212) acc 81.2500 (88.3594) gate/entropy 1.0289 (1.0295) gate/usage_max 0.5012 (0.5002) gate/usage_min 0.1996 (0.1998) gate/usage_std 0.1255 (0.1249) teacher/entropy 0.0018 (0.0132) teacher/usage_max 0.8128 (0.9189) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.3475 (0.4161) nleep/row_max_mean 1480.5027 (1496.8599) nleep/row_max_std 67.9363 (57.2883) nleep/row_min_mean 1443.0659 (1456.9892) lr 1.2487e-03 eta 0:10:54
epoch [23/50] batch [100/176] time 0.155 (0.129) data 0.000 (0.004) loss 1.5747 (1.3867) teacher_loss 0.4986 (0.2963) loss_zs_kd 0.0164 (0.0204) loss_oracle 0.6800 (0.7152) kd_loss 0.7279 (0.7226) acc 75.0000 (88.5938) gate/entropy 1.0288 (1.0293) gate/usage_max 0.5013 (0.5004) gate/usage_min 0.1996 (0.1997) gate/usage_std 0.1255 (0.1250) teacher/entropy 0.0226 (0.0124) teacher/usage_max 0.8842 (0.9173) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.3924 (0.4150) nleep/row_max_mean 1489.3831 (1496.4936) nleep/row_max_std 66.4378 (57.6764) nleep/row_min_mean 1449.0518 (1456.5349) lr 1.2487e-03 eta 0:10:22
epoch [23/50] batch [120/176] time 0.150 (0.127) data 0.000 (0.003) loss 1.2165 (1.3840) teacher_loss 0.1870 (0.2955) loss_zs_kd 0.0111 (0.0205) loss_oracle 0.6189 (0.7123) kd_loss 0.7145 (0.7220) acc 90.6250 (88.6719) gate/entropy 1.0285 (1.0292) gate/usage_max 0.5017 (0.5006) gate/usage_min 0.1993 (0.1997) gate/usage_std 0.1258 (0.1251) teacher/entropy 0.0069 (0.0124) teacher/usage_max 0.9390 (0.9180) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4290 (0.4154) nleep/row_max_mean 1487.2965 (1496.3595) nleep/row_max_std 65.8818 (57.7725) nleep/row_min_mean 1444.8074 (1456.2500) lr 1.2487e-03 eta 0:10:09
epoch [23/50] batch [140/176] time 0.148 (0.124) data 0.000 (0.003) loss 1.3665 (1.3792) teacher_loss 0.3133 (0.2960) loss_zs_kd 0.0235 (0.0206) loss_oracle 0.6463 (0.7035) kd_loss 0.7183 (0.7212) acc 87.5000 (88.7277) gate/entropy 1.0283 (1.0291) gate/usage_max 0.5022 (0.5008) gate/usage_min 0.1994 (0.1997) gate/usage_std 0.1260 (0.1252) teacher/entropy 0.0034 (0.0118) teacher/usage_max 0.9369 (0.9201) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4276 (0.4168) nleep/row_max_mean 1490.2648 (1496.3079) nleep/row_max_std 62.8878 (58.0198) nleep/row_min_mean 1449.0579 (1456.0913) lr 1.2487e-03 eta 0:09:55
epoch [23/50] batch [160/176] time 0.104 (0.123) data 0.000 (0.002) loss 1.2912 (1.3702) teacher_loss 0.1783 (0.2912) loss_zs_kd 0.0176 (0.0200) loss_oracle 0.7237 (0.6977) kd_loss 0.7423 (0.7201) acc 96.8750 (89.0234) gate/entropy 1.0279 (1.0290) gate/usage_max 0.5029 (0.5010) gate/usage_min 0.1995 (0.1996) gate/usage_std 0.1264 (0.1254) teacher/entropy 0.0116 (0.0118) teacher/usage_max 0.8755 (0.9215) teacher/usage_min 0.0023 (0.0006) teacher/usage_std 0.3865 (0.4178) nleep/row_max_mean 1484.1934 (1496.5073) nleep/row_max_std 66.4858 (58.0660) nleep/row_min_mean 1444.1343 (1456.0509) lr 1.2487e-03 eta 0:09:47
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,178
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,613
* accuracy: 60.7%
* error: 39.3%
* macro_f1: 54.8%
******* Domain l best val acc:      90.0%, epoch: 13 *******
******* Domain l best val test acc: 59.9%, epoch: 13 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [24/50] batch [20/176] time 0.134 (0.127) data 0.000 (0.011) loss 1.3533 (1.3376) teacher_loss 0.3035 (0.2587) loss_zs_kd 0.0387 (0.0238) loss_oracle 0.6693 (0.7000) kd_loss 0.6958 (0.7170) acc 93.7500 (90.3125) gate/entropy 1.0275 (1.0276) gate/usage_max 0.5038 (0.5035) gate/usage_min 0.1995 (0.1994) gate/usage_std 0.1269 (0.1268) teacher/entropy 0.0072 (0.0079) teacher/usage_max 0.9672 (0.9267) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4484 (0.4212) nleep/row_max_mean 1493.5339 (1499.9186) nleep/row_max_std 54.7468 (58.5857) nleep/row_min_mean 1452.3409 (1457.8685) lr 1.1874e-03 eta 0:09:58
epoch [24/50] batch [40/176] time 0.136 (0.130) data 0.000 (0.006) loss 1.1999 (1.3337) teacher_loss 0.1658 (0.2606) loss_zs_kd 0.0254 (0.0207) loss_oracle 0.6554 (0.6987) kd_loss 0.6936 (0.7134) acc 93.7500 (89.3750) gate/entropy 1.0273 (1.0275) gate/usage_max 0.5040 (0.5037) gate/usage_min 0.1994 (0.1994) gate/usage_std 0.1270 (0.1269) teacher/entropy 0.0098 (0.0095) teacher/usage_max 0.9659 (0.9301) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4475 (0.4233) nleep/row_max_mean 1508.5796 (1499.0652) nleep/row_max_std 51.8921 (58.5411) nleep/row_min_mean 1463.5466 (1457.0162) lr 1.1874e-03 eta 0:10:11
epoch [24/50] batch [60/176] time 0.128 (0.132) data 0.000 (0.004) loss 1.3616 (1.3691) teacher_loss 0.2697 (0.2900) loss_zs_kd 0.0170 (0.0209) loss_oracle 0.7357 (0.7090) kd_loss 0.7156 (0.7142) acc 84.3750 (88.9583) gate/entropy 1.0270 (1.0273) gate/usage_max 0.5046 (0.5040) gate/usage_min 0.1994 (0.1994) gate/usage_std 0.1273 (0.1270) teacher/entropy 0.0212 (0.0098) teacher/usage_max 0.9007 (0.9276) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4032 (0.4216) nleep/row_max_mean 1482.0718 (1497.3218) nleep/row_max_std 73.5432 (60.0193) nleep/row_min_mean 1444.4634 (1455.5809) lr 1.1874e-03 eta 0:10:17
epoch [24/50] batch [80/176] time 0.116 (0.134) data 0.000 (0.003) loss 1.3849 (1.3844) teacher_loss 0.2016 (0.2941) loss_zs_kd 0.0142 (0.0201) loss_oracle 0.7667 (0.7270) kd_loss 0.7928 (0.7167) acc 90.6250 (88.7109) gate/entropy 1.0270 (1.0272) gate/usage_max 0.5047 (0.5042) gate/usage_min 0.1994 (0.1994) gate/usage_std 0.1274 (0.1271) teacher/entropy 0.0061 (0.0102) teacher/usage_max 0.7827 (0.9216) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.3299 (0.4178) nleep/row_max_mean 1476.1349 (1496.8539) nleep/row_max_std 78.5073 (60.9286) nleep/row_min_mean 1439.0342 (1455.2525) lr 1.1874e-03 eta 0:10:28
epoch [24/50] batch [100/176] time 0.153 (0.135) data 0.000 (0.002) loss 1.1098 (1.3777) teacher_loss 0.0968 (0.2906) loss_zs_kd 0.0141 (0.0202) loss_oracle 0.5957 (0.7210) kd_loss 0.7081 (0.7165) acc 96.8750 (89.0312) gate/entropy 1.0264 (1.0271) gate/usage_max 0.5055 (0.5043) gate/usage_min 0.1992 (0.1993) gate/usage_std 0.1279 (0.1272) teacher/entropy 0.0068 (0.0114) teacher/usage_max 0.9391 (0.9192) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4290 (0.4162) nleep/row_max_mean 1503.5885 (1496.2337) nleep/row_max_std 62.4401 (61.6408) nleep/row_min_mean 1464.9353 (1454.9061) lr 1.1874e-03 eta 0:10:28
epoch [24/50] batch [120/176] time 0.144 (0.135) data 0.000 (0.002) loss 1.2929 (1.3752) teacher_loss 0.1932 (0.2904) loss_zs_kd 0.0096 (0.0197) loss_oracle 0.7922 (0.7180) kd_loss 0.6987 (0.7160) acc 93.7500 (88.9062) gate/entropy 1.0266 (1.0270) gate/usage_max 0.5053 (0.5045) gate/usage_min 0.1992 (0.1993) gate/usage_std 0.1278 (0.1273) teacher/entropy 0.0008 (0.0108) teacher/usage_max 0.9686 (0.9207) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4494 (0.4172) nleep/row_max_mean 1504.9763 (1496.3938) nleep/row_max_std 48.0849 (60.9714) nleep/row_min_mean 1461.3931 (1454.9696) lr 1.1874e-03 eta 0:10:26
epoch [24/50] batch [140/176] time 0.122 (0.135) data 0.000 (0.002) loss 1.3605 (1.3713) teacher_loss 0.2457 (0.2843) loss_zs_kd 0.0141 (0.0192) loss_oracle 0.7575 (0.7250) kd_loss 0.7291 (0.7148) acc 84.3750 (88.9062) gate/entropy 1.0262 (1.0270) gate/usage_max 0.5057 (0.5046) gate/usage_min 0.1990 (0.1993) gate/usage_std 0.1281 (0.1274) teacher/entropy 0.0038 (0.0110) teacher/usage_max 0.9055 (0.9220) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4064 (0.4181) nleep/row_max_mean 1495.3390 (1496.4706) nleep/row_max_std 67.5682 (61.0772) nleep/row_min_mean 1457.4387 (1455.0658) lr 1.1874e-03 eta 0:10:23
epoch [24/50] batch [160/176] time 0.123 (0.134) data 0.000 (0.002) loss 1.6777 (1.3770) teacher_loss 0.5331 (0.2902) loss_zs_kd 0.0168 (0.0195) loss_oracle 0.7968 (0.7259) kd_loss 0.7378 (0.7141) acc 81.2500 (88.6328) gate/entropy 1.0262 (1.0269) gate/usage_max 0.5058 (0.5048) gate/usage_min 0.1990 (0.1993) gate/usage_std 0.1281 (0.1275) teacher/entropy 0.0125 (0.0118) teacher/usage_max 0.8718 (0.9214) teacher/usage_min 0.0001 (0.0006) teacher/usage_std 0.3843 (0.4177) nleep/row_max_mean 1489.9988 (1496.2753) nleep/row_max_std 70.0750 (61.0984) nleep/row_min_mean 1449.4454 (1454.9337) lr 1.1874e-03 eta 0:10:17
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,181
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,659
* accuracy: 62.5%
* error: 37.5%
* macro_f1: 56.8%
******* Domain l best val acc:      90.0%, epoch: 24 *******
******* Domain l best val test acc: 62.5%, epoch: 24 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [25/50] batch [20/176] time 0.095 (0.120) data 0.000 (0.016) loss 1.3464 (1.3510) teacher_loss 0.3067 (0.2921) loss_zs_kd 0.0226 (0.0184) loss_oracle 0.6287 (0.6775) kd_loss 0.7141 (0.7110) acc 84.3750 (89.2188) gate/entropy 1.0261 (1.0260) gate/usage_max 0.5060 (0.5061) gate/usage_min 0.1990 (0.1989) gate/usage_std 0.1282 (0.1283) teacher/entropy 0.0005 (0.0171) teacher/usage_max 0.9374 (0.9127) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4279 (0.4117) nleep/row_max_mean 1497.3439 (1495.7392) nleep/row_max_std 49.4465 (60.6277) nleep/row_min_mean 1453.3433 (1454.7002) lr 1.1253e-03 eta 0:09:06
epoch [25/50] batch [40/176] time 0.095 (0.116) data 0.000 (0.008) loss 1.4210 (1.3419) teacher_loss 0.3189 (0.2854) loss_zs_kd 0.0227 (0.0175) loss_oracle 0.7551 (0.6888) kd_loss 0.7132 (0.7034) acc 81.2500 (89.0625) gate/entropy 1.0257 (1.0259) gate/usage_max 0.5066 (0.5063) gate/usage_min 0.1989 (0.1989) gate/usage_std 0.1286 (0.1284) teacher/entropy 0.0007 (0.0194) teacher/usage_max 0.9374 (0.9222) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4279 (0.4180) nleep/row_max_mean 1487.1746 (1496.8808) nleep/row_max_std 61.1301 (59.0850) nleep/row_min_mean 1446.7994 (1455.3849) lr 1.1253e-03 eta 0:08:44
epoch [25/50] batch [60/176] time 0.146 (0.109) data 0.000 (0.006) loss 1.2953 (1.3368) teacher_loss 0.1783 (0.2702) loss_zs_kd 0.0265 (0.0174) loss_oracle 0.8155 (0.7035) kd_loss 0.6961 (0.7062) acc 90.6250 (89.4271) gate/entropy 1.0254 (1.0258) gate/usage_max 0.5071 (0.5065) gate/usage_min 0.1988 (0.1989) gate/usage_std 0.1289 (0.1285) teacher/entropy 0.0001 (0.0189) teacher/usage_max 0.9687 (0.9177) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4495 (0.4150) nleep/row_max_mean 1512.8813 (1496.1989) nleep/row_max_std 45.8155 (59.5338) nleep/row_min_mean 1469.4872 (1454.7843) lr 1.1253e-03 eta 0:08:14
epoch [25/50] batch [80/176] time 0.136 (0.109) data 0.000 (0.004) loss 1.3507 (1.3449) teacher_loss 0.2518 (0.2685) loss_zs_kd 0.0183 (0.0180) loss_oracle 0.8157 (0.7157) kd_loss 0.6820 (0.7095) acc 87.5000 (89.4922) gate/entropy 1.0255 (1.0257) gate/usage_max 0.5069 (0.5066) gate/usage_min 0.1987 (0.1989) gate/usage_std 0.1288 (0.1286) teacher/entropy 0.0192 (0.0175) teacher/usage_max 0.9600 (0.9139) teacher/usage_min 0.0001 (0.0006) teacher/usage_std 0.4434 (0.4126) nleep/row_max_mean 1512.4165 (1495.5540) nleep/row_max_std 59.5128 (60.5160) nleep/row_min_mean 1468.7589 (1454.4522) lr 1.1253e-03 eta 0:08:10
epoch [25/50] batch [100/176] time 0.119 (0.110) data 0.000 (0.003) loss 1.4526 (1.3527) teacher_loss 0.3082 (0.2766) loss_zs_kd 0.0142 (0.0188) loss_oracle 0.8329 (0.7179) kd_loss 0.7209 (0.7078) acc 93.7500 (89.2812) gate/entropy 1.0252 (1.0257) gate/usage_max 0.5074 (0.5067) gate/usage_min 0.1987 (0.1988) gate/usage_std 0.1291 (0.1287) teacher/entropy 0.0670 (0.0189) teacher/usage_max 0.7996 (0.9141) teacher/usage_min 0.0003 (0.0005) teacher/usage_std 0.3397 (0.4127) nleep/row_max_mean 1479.3250 (1494.5308) nleep/row_max_std 72.8144 (60.8274) nleep/row_min_mean 1442.7134 (1453.6628) lr 1.1253e-03 eta 0:08:10
epoch [25/50] batch [120/176] time 0.093 (0.109) data 0.000 (0.003) loss 1.5469 (1.3637) teacher_loss 0.4704 (0.2869) loss_zs_kd 0.0211 (0.0190) loss_oracle 0.7498 (0.7175) kd_loss 0.6910 (0.7085) acc 84.3750 (89.0104) gate/entropy 1.0252 (1.0256) gate/usage_max 0.5073 (0.5068) gate/usage_min 0.1986 (0.1988) gate/usage_std 0.1291 (0.1287) teacher/entropy 0.0317 (0.0202) teacher/usage_max 0.9189 (0.9100) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4154 (0.4100) nleep/row_max_mean 1496.0615 (1493.6047) nleep/row_max_std 48.7424 (61.4638) nleep/row_min_mean 1456.0359 (1452.9412) lr 1.1253e-03 eta 0:08:06
epoch [25/50] batch [140/176] time 0.135 (0.108) data 0.000 (0.002) loss 1.2577 (1.3684) teacher_loss 0.1953 (0.2917) loss_zs_kd 0.0143 (0.0191) loss_oracle 0.6534 (0.7161) kd_loss 0.7286 (0.7090) acc 90.6250 (88.8616) gate/entropy 1.0252 (1.0255) gate/usage_max 0.5073 (0.5069) gate/usage_min 0.1985 (0.1988) gate/usage_std 0.1291 (0.1288) teacher/entropy 0.0012 (0.0200) teacher/usage_max 0.9061 (0.9092) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4068 (0.4095) nleep/row_max_mean 1486.5472 (1494.1166) nleep/row_max_std 64.9799 (61.1988) nleep/row_min_mean 1445.2675 (1453.3735) lr 1.1253e-03 eta 0:08:00
epoch [25/50] batch [160/176] time 0.136 (0.111) data 0.000 (0.002) loss 1.4204 (1.3687) teacher_loss 0.3605 (0.2924) loss_zs_kd 0.0280 (0.0193) loss_oracle 0.6874 (0.7158) kd_loss 0.7022 (0.7087) acc 87.5000 (88.7500) gate/entropy 1.0251 (1.0255) gate/usage_max 0.5074 (0.5069) gate/usage_min 0.1983 (0.1987) gate/usage_std 0.1292 (0.1288) teacher/entropy 0.0390 (0.0206) teacher/usage_max 0.8853 (0.9084) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.3931 (0.4089) nleep/row_max_mean 1495.4016 (1494.2280) nleep/row_max_std 66.0507 (61.1874) nleep/row_min_mean 1456.8695 (1453.4452) lr 1.1253e-03 eta 0:08:11
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,175
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,682
* accuracy: 63.3%
* error: 36.7%
* macro_f1: 57.0%
******* Domain l best val acc:      90.0%, epoch: 24 *******
******* Domain l best val test acc: 62.5%, epoch: 24 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [26/50] batch [20/176] time 0.140 (0.159) data 0.000 (0.019) loss 1.4522 (1.3259) teacher_loss 0.3316 (0.2570) loss_zs_kd 0.0149 (0.0203) loss_oracle 0.7492 (0.6768) kd_loss 0.7385 (0.7204) acc 90.6250 (90.6250) gate/entropy 1.0248 (1.0250) gate/usage_max 0.5078 (0.5076) gate/usage_min 0.1982 (0.1983) gate/usage_std 0.1294 (0.1293) teacher/entropy 0.0068 (0.0166) teacher/usage_max 0.8768 (0.8922) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3875 (0.3983) nleep/row_max_mean 1500.7937 (1497.6961) nleep/row_max_std 59.1303 (59.2887) nleep/row_min_mean 1459.6436 (1454.9720) lr 1.0628e-03 eta 0:11:36
epoch [26/50] batch [40/176] time 0.124 (0.145) data 0.000 (0.010) loss 1.5812 (1.3618) teacher_loss 0.5041 (0.2941) loss_zs_kd 0.0169 (0.0188) loss_oracle 0.6800 (0.6804) kd_loss 0.7286 (0.7181) acc 84.3750 (88.9844) gate/entropy 1.0249 (1.0249) gate/usage_max 0.5076 (0.5076) gate/usage_min 0.1981 (0.1982) gate/usage_std 0.1293 (0.1293) teacher/entropy 0.0245 (0.0219) teacher/usage_max 0.8628 (0.8869) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.3785 (0.3947) nleep/row_max_mean 1488.6941 (1495.0274) nleep/row_max_std 68.9524 (61.1001) nleep/row_min_mean 1446.9797 (1452.8006) lr 1.0628e-03 eta 0:10:34
epoch [26/50] batch [60/176] time 0.144 (0.141) data 0.000 (0.007) loss 1.4983 (1.3735) teacher_loss 0.3612 (0.3008) loss_zs_kd 0.0132 (0.0187) loss_oracle 0.7891 (0.6926) kd_loss 0.7359 (0.7171) acc 87.5000 (88.5938) gate/entropy 1.0248 (1.0249) gate/usage_max 0.5077 (0.5076) gate/usage_min 0.1980 (0.1982) gate/usage_std 0.1294 (0.1293) teacher/entropy 0.0115 (0.0220) teacher/usage_max 0.8724 (0.8885) teacher/usage_min 0.0001 (0.0004) teacher/usage_std 0.3847 (0.3959) nleep/row_max_mean 1500.5913 (1495.1174) nleep/row_max_std 64.6027 (60.4404) nleep/row_min_mean 1461.2681 (1452.8195) lr 1.0628e-03 eta 0:10:13
epoch [26/50] batch [80/176] time 0.078 (0.139) data 0.000 (0.005) loss 1.2431 (1.3669) teacher_loss 0.2513 (0.2992) loss_zs_kd 0.0102 (0.0193) loss_oracle 0.5639 (0.6894) kd_loss 0.7047 (0.7134) acc 87.5000 (88.4766) gate/entropy 1.0246 (1.0248) gate/usage_max 0.5081 (0.5077) gate/usage_min 0.1980 (0.1981) gate/usage_std 0.1296 (0.1294) teacher/entropy 0.0077 (0.0207) teacher/usage_max 0.9355 (0.8975) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4266 (0.4019) nleep/row_max_mean 1508.0383 (1496.8766) nleep/row_max_std 61.9513 (58.6479) nleep/row_min_mean 1465.9741 (1454.2508) lr 1.0628e-03 eta 0:09:58
epoch [26/50] batch [100/176] time 0.146 (0.129) data 0.000 (0.004) loss 1.3279 (1.3711) teacher_loss 0.1899 (0.3021) loss_zs_kd 0.0336 (0.0195) loss_oracle 0.7323 (0.6922) kd_loss 0.7551 (0.7132) acc 87.5000 (88.2188) gate/entropy 1.0245 (1.0248) gate/usage_max 0.5082 (0.5077) gate/usage_min 0.1980 (0.1981) gate/usage_std 0.1297 (0.1294) teacher/entropy 0.0079 (0.0205) teacher/usage_max 0.8423 (0.8980) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.3656 (0.4022) nleep/row_max_mean 1492.5900 (1497.4251) nleep/row_max_std 65.1637 (58.5697) nleep/row_min_mean 1449.8235 (1454.7174) lr 1.0628e-03 eta 0:09:15
epoch [26/50] batch [120/176] time 0.082 (0.124) data 0.000 (0.003) loss 1.1403 (1.3604) teacher_loss 0.1779 (0.2968) loss_zs_kd 0.0081 (0.0191) loss_oracle 0.5308 (0.6825) kd_loss 0.6929 (0.7128) acc 93.7500 (88.5417) gate/entropy 1.0243 (1.0247) gate/usage_max 0.5085 (0.5078) gate/usage_min 0.1980 (0.1981) gate/usage_std 0.1299 (0.1295) teacher/entropy 0.0006 (0.0203) teacher/usage_max 0.9687 (0.8989) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4494 (0.4028) nleep/row_max_mean 1506.5891 (1497.7441) nleep/row_max_std 56.8272 (58.4832) nleep/row_min_mean 1461.4441 (1454.9038) lr 1.0628e-03 eta 0:08:49
epoch [26/50] batch [140/176] time 0.170 (0.121) data 0.000 (0.003) loss 1.4977 (1.3570) teacher_loss 0.3680 (0.2938) loss_zs_kd 0.0268 (0.0186) loss_oracle 0.8386 (0.6852) kd_loss 0.6970 (0.7113) acc 81.2500 (88.7054) gate/entropy 1.0245 (1.0247) gate/usage_max 0.5082 (0.5079) gate/usage_min 0.1979 (0.1980) gate/usage_std 0.1297 (0.1295) teacher/entropy 0.0201 (0.0201) teacher/usage_max 0.9269 (0.9019) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4207 (0.4048) nleep/row_max_mean 1501.5465 (1498.3490) nleep/row_max_std 55.9458 (57.9641) nleep/row_min_mean 1454.3625 (1455.2270) lr 1.0628e-03 eta 0:08:35
epoch [26/50] batch [160/176] time 0.160 (0.119) data 0.000 (0.003) loss 1.2018 (1.3514) teacher_loss 0.1795 (0.2884) loss_zs_kd 0.0131 (0.0183) loss_oracle 0.6126 (0.6852) kd_loss 0.7095 (0.7112) acc 90.6250 (88.9453) gate/entropy 1.0241 (1.0246) gate/usage_max 0.5089 (0.5080) gate/usage_min 0.1979 (0.1980) gate/usage_std 0.1301 (0.1296) teacher/entropy 0.0352 (0.0197) teacher/usage_max 0.8741 (0.9024) teacher/usage_min 0.0001 (0.0006) teacher/usage_std 0.3858 (0.4051) nleep/row_max_mean 1493.4751 (1498.3076) nleep/row_max_std 65.3419 (57.8179) nleep/row_min_mean 1453.8318 (1455.1059) lr 1.0628e-03 eta 0:08:26
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,682
* accuracy: 63.3%
* error: 36.7%
* macro_f1: 57.2%
******* Domain l best val acc:      90.0%, epoch: 24 *******
******* Domain l best val test acc: 62.5%, epoch: 24 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [27/50] batch [20/176] time 0.077 (0.127) data 0.000 (0.019) loss 1.1514 (1.3212) teacher_loss 0.1411 (0.2433) loss_zs_kd 0.0200 (0.0200) loss_oracle 0.6418 (0.7079) kd_loss 0.6794 (0.7140) acc 96.8750 (92.0312) gate/entropy 1.0241 (1.0241) gate/usage_max 0.5089 (0.5089) gate/usage_min 0.1978 (0.1978) gate/usage_std 0.1301 (0.1301) teacher/entropy 0.0584 (0.0214) teacher/usage_max 0.8875 (0.8925) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.3945 (0.3985) nleep/row_max_mean 1483.2915 (1495.2532) nleep/row_max_std 58.6570 (59.6908) nleep/row_min_mean 1443.5566 (1452.1389) lr 1.0000e-03 eta 0:08:53
epoch [27/50] batch [40/176] time 0.155 (0.127) data 0.000 (0.009) loss 1.1200 (1.3207) teacher_loss 0.1056 (0.2476) loss_zs_kd 0.0056 (0.0200) loss_oracle 0.5699 (0.7018) kd_loss 0.7267 (0.7123) acc 93.7500 (91.1719) gate/entropy 1.0239 (1.0240) gate/usage_max 0.5090 (0.5089) gate/usage_min 0.1976 (0.1977) gate/usage_std 0.1302 (0.1301) teacher/entropy 0.0001 (0.0236) teacher/usage_max 0.9062 (0.8910) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4069 (0.3975) nleep/row_max_mean 1500.9326 (1495.2868) nleep/row_max_std 66.4141 (59.3448) nleep/row_min_mean 1456.0228 (1452.8601) lr 1.0000e-03 eta 0:08:51
epoch [27/50] batch [60/176] time 0.138 (0.128) data 0.001 (0.006) loss 1.3775 (1.3353) teacher_loss 0.2801 (0.2686) loss_zs_kd 0.0254 (0.0195) loss_oracle 0.6878 (0.6959) kd_loss 0.7408 (0.7090) acc 84.3750 (90.0521) gate/entropy 1.0239 (1.0240) gate/usage_max 0.5090 (0.5089) gate/usage_min 0.1976 (0.1977) gate/usage_std 0.1302 (0.1302) teacher/entropy 0.0032 (0.0237) teacher/usage_max 0.8756 (0.8965) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.3868 (0.4012) nleep/row_max_mean 1491.2380 (1495.1579) nleep/row_max_std 63.0339 (58.3932) nleep/row_min_mean 1449.2488 (1452.8190) lr 1.0000e-03 eta 0:08:53
epoch [27/50] batch [80/176] time 0.130 (0.129) data 0.000 (0.005) loss 1.3193 (1.3316) teacher_loss 0.1910 (0.2675) loss_zs_kd 0.0227 (0.0199) loss_oracle 0.7319 (0.6862) kd_loss 0.7510 (0.7111) acc 96.8750 (89.7266) gate/entropy 1.0239 (1.0240) gate/usage_max 0.5091 (0.5090) gate/usage_min 0.1976 (0.1976) gate/usage_std 0.1303 (0.1302) teacher/entropy 0.0096 (0.0212) teacher/usage_max 0.8447 (0.8970) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.3671 (0.4014) nleep/row_max_mean 1479.2677 (1494.9864) nleep/row_max_std 61.0711 (58.2510) nleep/row_min_mean 1440.2046 (1452.6446) lr 1.0000e-03 eta 0:08:54
epoch [27/50] batch [100/176] time 0.160 (0.131) data 0.000 (0.004) loss 1.3482 (1.3243) teacher_loss 0.3168 (0.2650) loss_zs_kd 0.0141 (0.0205) loss_oracle 0.6444 (0.6767) kd_loss 0.7021 (0.7107) acc 90.6250 (89.9375) gate/entropy 1.0238 (1.0239) gate/usage_max 0.5091 (0.5090) gate/usage_min 0.1975 (0.1976) gate/usage_std 0.1303 (0.1302) teacher/entropy 0.0089 (0.0206) teacher/usage_max 0.9351 (0.8986) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4264 (0.4024) nleep/row_max_mean 1496.1831 (1494.6130) nleep/row_max_std 56.3420 (57.9901) nleep/row_min_mean 1450.3718 (1452.3158) lr 1.0000e-03 eta 0:08:58
epoch [27/50] batch [120/176] time 0.128 (0.133) data 0.000 (0.003) loss 1.3594 (1.3217) teacher_loss 0.3104 (0.2664) loss_zs_kd 0.0294 (0.0203) loss_oracle 0.6527 (0.6730) kd_loss 0.7080 (0.7086) acc 84.3750 (89.6875) gate/entropy 1.0236 (1.0239) gate/usage_max 0.5095 (0.5091) gate/usage_min 0.1975 (0.1976) gate/usage_std 0.1305 (0.1303) teacher/entropy 0.0007 (0.0204) teacher/usage_max 0.9374 (0.9026) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4279 (0.4051) nleep/row_max_mean 1504.2322 (1494.5532) nleep/row_max_std 45.5595 (57.2697) nleep/row_min_mean 1462.1897 (1452.3402) lr 1.0000e-03 eta 0:09:06
epoch [27/50] batch [140/176] time 0.160 (0.135) data 0.000 (0.003) loss 1.2684 (1.3286) teacher_loss 0.2345 (0.2749) loss_zs_kd 0.0081 (0.0198) loss_oracle 0.5906 (0.6694) kd_loss 0.7345 (0.7091) acc 87.5000 (89.2411) gate/entropy 1.0235 (1.0238) gate/usage_max 0.5099 (0.5092) gate/usage_min 0.1977 (0.1976) gate/usage_std 0.1307 (0.1303) teacher/entropy 0.0317 (0.0206) teacher/usage_max 0.8337 (0.9010) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.3602 (0.4041) nleep/row_max_mean 1474.5996 (1494.1997) nleep/row_max_std 65.8652 (57.4013) nleep/row_min_mean 1435.2687 (1452.1171) lr 1.0000e-03 eta 0:09:11
epoch [27/50] batch [160/176] time 0.157 (0.136) data 0.000 (0.002) loss 1.5287 (1.3337) teacher_loss 0.5168 (0.2833) loss_zs_kd 0.0188 (0.0193) loss_oracle 0.5968 (0.6665) kd_loss 0.7041 (0.7075) acc 90.6250 (88.7891) gate/entropy 1.0232 (1.0237) gate/usage_max 0.5102 (0.5093) gate/usage_min 0.1976 (0.1976) gate/usage_std 0.1309 (0.1304) teacher/entropy 0.0040 (0.0214) teacher/usage_max 0.9372 (0.9022) teacher/usage_min 0.0004 (0.0005) teacher/usage_std 0.4277 (0.4048) nleep/row_max_mean 1494.3712 (1494.1304) nleep/row_max_std 52.2854 (57.4053) nleep/row_min_mean 1451.6993 (1452.1526) lr 1.0000e-03 eta 0:09:12
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,180
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,626
* accuracy: 61.2%
* error: 38.8%
* macro_f1: 55.6%
******* Domain l best val acc:      90.0%, epoch: 24 *******
******* Domain l best val test acc: 62.5%, epoch: 24 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [28/50] batch [20/176] time 0.176 (0.137) data 0.000 (0.021) loss 1.1931 (1.3046) teacher_loss 0.1967 (0.2782) loss_zs_kd 0.0183 (0.0185) loss_oracle 0.6633 (0.6296) kd_loss 0.6557 (0.7023) acc 93.7500 (90.1562) gate/entropy 1.0226 (1.0229) gate/usage_max 0.5113 (0.5108) gate/usage_min 0.1976 (0.1976) gate/usage_std 0.1315 (0.1312) teacher/entropy 0.0207 (0.0239) teacher/usage_max 0.9899 (0.9034) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4643 (0.4056) nleep/row_max_mean 1520.4539 (1494.7783) nleep/row_max_std 43.2199 (58.4804) nleep/row_min_mean 1475.7775 (1452.6202) lr 9.3721e-04 eta 0:09:12
epoch [28/50] batch [40/176] time 0.096 (0.125) data 0.000 (0.011) loss 1.1180 (1.3144) teacher_loss 0.1687 (0.2799) loss_zs_kd 0.0084 (0.0194) loss_oracle 0.4965 (0.6402) kd_loss 0.6969 (0.7048) acc 93.7500 (89.9219) gate/entropy 1.0228 (1.0228) gate/usage_max 0.5111 (0.5110) gate/usage_min 0.1977 (0.1977) gate/usage_std 0.1314 (0.1313) teacher/entropy 0.0114 (0.0211) teacher/usage_max 0.9341 (0.9034) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4256 (0.4056) nleep/row_max_mean 1490.8479 (1493.6317) nleep/row_max_std 62.7442 (59.6210) nleep/row_min_mean 1443.3118 (1451.7273) lr 9.3721e-04 eta 0:08:20
epoch [28/50] batch [60/176] time 0.094 (0.115) data 0.000 (0.007) loss 1.5291 (1.3202) teacher_loss 0.4292 (0.2841) loss_zs_kd 0.0213 (0.0188) loss_oracle 0.6727 (0.6400) kd_loss 0.7529 (0.7066) acc 84.3750 (89.2708) gate/entropy 1.0225 (1.0228) gate/usage_max 0.5116 (0.5111) gate/usage_min 0.1978 (0.1977) gate/usage_std 0.1316 (0.1314) teacher/entropy 0.0267 (0.0209) teacher/usage_max 0.8076 (0.9009) teacher/usage_min 0.0004 (0.0014) teacher/usage_std 0.3444 (0.4038) nleep/row_max_mean 1472.3163 (1492.2397) nleep/row_max_std 70.5680 (60.3430) nleep/row_min_mean 1432.9165 (1450.3754) lr 9.3721e-04 eta 0:07:37
epoch [28/50] batch [80/176] time 0.083 (0.116) data 0.000 (0.005) loss 1.2114 (1.3215) teacher_loss 0.2368 (0.2822) loss_zs_kd 0.0212 (0.0181) loss_oracle 0.5953 (0.6480) kd_loss 0.6664 (0.7063) acc 87.5000 (88.9062) gate/entropy 1.0224 (1.0227) gate/usage_max 0.5118 (0.5112) gate/usage_min 0.1977 (0.1977) gate/usage_std 0.1318 (0.1314) teacher/entropy 0.0280 (0.0190) teacher/usage_max 0.9570 (0.9043) teacher/usage_min 0.0010 (0.0011) teacher/usage_std 0.4413 (0.4064) nleep/row_max_mean 1509.4108 (1493.4041) nleep/row_max_std 58.8500 (59.2145) nleep/row_min_mean 1464.9252 (1451.1638) lr 9.3721e-04 eta 0:07:38
epoch [28/50] batch [100/176] time 0.089 (0.115) data 0.000 (0.004) loss 1.1146 (1.3259) teacher_loss 0.0981 (0.2807) loss_zs_kd 0.0247 (0.0181) loss_oracle 0.5750 (0.6578) kd_loss 0.7166 (0.7072) acc 96.8750 (89.0312) gate/entropy 1.0224 (1.0226) gate/usage_max 0.5119 (0.5114) gate/usage_min 0.1978 (0.1977) gate/usage_std 0.1318 (0.1315) teacher/entropy 0.0069 (0.0180) teacher/usage_max 0.9045 (0.9040) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4057 (0.4062) nleep/row_max_mean 1495.5391 (1493.5617) nleep/row_max_std 66.1985 (59.8311) nleep/row_min_mean 1449.4907 (1451.2124) lr 9.3721e-04 eta 0:07:34
epoch [28/50] batch [120/176] time 0.095 (0.115) data 0.000 (0.004) loss 1.4583 (1.3315) teacher_loss 0.4936 (0.2845) loss_zs_kd 0.0153 (0.0182) loss_oracle 0.6052 (0.6639) kd_loss 0.6544 (0.7060) acc 90.6250 (89.0365) gate/entropy 1.0223 (1.0226) gate/usage_max 0.5119 (0.5115) gate/usage_min 0.1977 (0.1977) gate/usage_std 0.1318 (0.1316) teacher/entropy 0.0587 (0.0190) teacher/usage_max 0.9237 (0.9041) teacher/usage_min 0.0001 (0.0010) teacher/usage_std 0.4186 (0.4062) nleep/row_max_mean 1488.2122 (1493.3660) nleep/row_max_std 64.0587 (60.0574) nleep/row_min_mean 1444.3375 (1450.9735) lr 9.3721e-04 eta 0:07:32
epoch [28/50] batch [140/176] time 0.074 (0.114) data 0.000 (0.003) loss 1.3287 (1.3290) teacher_loss 0.2524 (0.2797) loss_zs_kd 0.0351 (0.0182) loss_oracle 0.6670 (0.6695) kd_loss 0.7252 (0.7055) acc 90.6250 (89.1071) gate/entropy 1.0223 (1.0225) gate/usage_max 0.5119 (0.5115) gate/usage_min 0.1977 (0.1977) gate/usage_std 0.1318 (0.1316) teacher/entropy 0.0182 (0.0187) teacher/usage_max 0.8701 (0.9053) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.3833 (0.4070) nleep/row_max_mean 1484.1621 (1492.8685) nleep/row_max_std 62.9742 (60.2140) nleep/row_min_mean 1443.1887 (1450.4940) lr 9.3721e-04 eta 0:07:24
epoch [28/50] batch [160/176] time 0.149 (0.117) data 0.000 (0.003) loss 1.2177 (1.3275) teacher_loss 0.1509 (0.2776) loss_zs_kd 0.0218 (0.0187) loss_oracle 0.5880 (0.6705) kd_loss 0.7619 (0.7052) acc 90.6250 (89.0234) gate/entropy 1.0220 (1.0225) gate/usage_max 0.5125 (0.5116) gate/usage_min 0.1977 (0.1977) gate/usage_std 0.1322 (0.1317) teacher/entropy 0.0119 (0.0188) teacher/usage_max 0.8153 (0.9056) teacher/usage_min 0.0001 (0.0012) teacher/usage_std 0.3490 (0.4071) nleep/row_max_mean 1481.1162 (1492.3999) nleep/row_max_std 66.1210 (60.2882) nleep/row_min_mean 1439.4407 (1450.1365) lr 9.3721e-04 eta 0:07:34
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,175
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,736
* accuracy: 65.4%
* error: 34.6%
* macro_f1: 57.9%
******* Domain l best val acc:      90.0%, epoch: 24 *******
******* Domain l best val test acc: 62.5%, epoch: 24 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [29/50] batch [20/176] time 0.151 (0.153) data 0.000 (0.017) loss 1.2528 (1.3154) teacher_loss 0.2618 (0.2793) loss_zs_kd 0.0301 (0.0217) loss_oracle 0.5780 (0.6531) kd_loss 0.6869 (0.6987) acc 93.7500 (89.5312) gate/entropy 1.0218 (1.0218) gate/usage_max 0.5129 (0.5128) gate/usage_min 0.1978 (0.1978) gate/usage_std 0.1324 (0.1323) teacher/entropy 0.0213 (0.0202) teacher/usage_max 0.9300 (0.9119) teacher/usage_min 0.0006 (0.0017) teacher/usage_std 0.4228 (0.4117) nleep/row_max_mean 1488.4700 (1491.0476) nleep/row_max_std 60.4745 (55.7075) nleep/row_min_mean 1444.9213 (1449.3072) lr 8.7467e-04 eta 0:09:47
epoch [29/50] batch [40/176] time 0.161 (0.147) data 0.000 (0.009) loss 1.2186 (1.3266) teacher_loss 0.1403 (0.2786) loss_zs_kd 0.0147 (0.0208) loss_oracle 0.7297 (0.6723) kd_loss 0.7061 (0.7014) acc 93.7500 (89.2188) gate/entropy 1.0216 (1.0217) gate/usage_max 0.5132 (0.5130) gate/usage_min 0.1978 (0.1978) gate/usage_std 0.1325 (0.1324) teacher/entropy 0.0194 (0.0186) teacher/usage_max 0.8982 (0.9096) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.4016 (0.4099) nleep/row_max_mean 1487.2518 (1490.6611) nleep/row_max_std 60.3102 (56.4227) nleep/row_min_mean 1447.0293 (1449.2265) lr 8.7467e-04 eta 0:09:22
epoch [29/50] batch [60/176] time 0.150 (0.140) data 0.001 (0.006) loss 1.6546 (1.3354) teacher_loss 0.5434 (0.2881) loss_zs_kd 0.0107 (0.0199) loss_oracle 0.7858 (0.6755) kd_loss 0.7129 (0.6997) acc 75.0000 (88.9062) gate/entropy 1.0214 (1.0217) gate/usage_max 0.5135 (0.5132) gate/usage_min 0.1977 (0.1978) gate/usage_std 0.1327 (0.1325) teacher/entropy 0.0090 (0.0180) teacher/usage_max 0.9041 (0.9128) teacher/usage_min 0.0004 (0.0013) teacher/usage_std 0.4054 (0.4119) nleep/row_max_mean 1495.4817 (1490.8522) nleep/row_max_std 56.1330 (56.9016) nleep/row_min_mean 1453.0554 (1449.4343) lr 8.7467e-04 eta 0:08:54
epoch [29/50] batch [80/176] time 0.107 (0.137) data 0.000 (0.004) loss 1.3171 (1.3371) teacher_loss 0.3626 (0.2921) loss_zs_kd 0.0135 (0.0190) loss_oracle 0.5062 (0.6702) kd_loss 0.6946 (0.7004) acc 78.1250 (88.9453) gate/entropy 1.0213 (1.0216) gate/usage_max 0.5139 (0.5133) gate/usage_min 0.1980 (0.1978) gate/usage_std 0.1329 (0.1326) teacher/entropy 0.0084 (0.0163) teacher/usage_max 0.9353 (0.9143) teacher/usage_min 0.0001 (0.0016) teacher/usage_std 0.4264 (0.4128) nleep/row_max_mean 1493.2133 (1491.6855) nleep/row_max_std 60.0862 (56.7054) nleep/row_min_mean 1451.3618 (1450.0516) lr 8.7467e-04 eta 0:08:40
epoch [29/50] batch [100/176] time 0.119 (0.133) data 0.000 (0.004) loss 1.5243 (1.3426) teacher_loss 0.4598 (0.2987) loss_zs_kd 0.0189 (0.0190) loss_oracle 0.7653 (0.6702) kd_loss 0.6724 (0.6993) acc 75.0000 (88.4375) gate/entropy 1.0210 (1.0215) gate/usage_max 0.5143 (0.5135) gate/usage_min 0.1979 (0.1978) gate/usage_std 0.1331 (0.1327) teacher/entropy 0.0377 (0.0159) teacher/usage_max 0.9240 (0.9163) teacher/usage_min 0.0022 (0.0013) teacher/usage_std 0.4187 (0.4141) nleep/row_max_mean 1490.0845 (1491.8910) nleep/row_max_std 62.9702 (57.2799) nleep/row_min_mean 1451.1820 (1450.2512) lr 8.7467e-04 eta 0:08:21
epoch [29/50] batch [120/176] time 0.151 (0.130) data 0.000 (0.003) loss 1.1752 (1.3349) teacher_loss 0.1414 (0.2923) loss_zs_kd 0.0230 (0.0196) loss_oracle 0.6149 (0.6675) kd_loss 0.7148 (0.6991) acc 93.7500 (88.7760) gate/entropy 1.0210 (1.0214) gate/usage_max 0.5144 (0.5136) gate/usage_min 0.1980 (0.1978) gate/usage_std 0.1332 (0.1327) teacher/entropy 0.0049 (0.0159) teacher/usage_max 0.9051 (0.9163) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4062 (0.4141) nleep/row_max_mean 1488.6428 (1491.9303) nleep/row_max_std 58.8180 (57.9490) nleep/row_min_mean 1446.9016 (1450.2540) lr 8.7467e-04 eta 0:08:06
epoch [29/50] batch [140/176] time 0.071 (0.126) data 0.000 (0.003) loss 1.3437 (1.3284) teacher_loss 0.3501 (0.2879) loss_zs_kd 0.0314 (0.0196) loss_oracle 0.6162 (0.6612) kd_loss 0.6697 (0.7001) acc 87.5000 (88.9732) gate/entropy 1.0207 (1.0214) gate/usage_max 0.5148 (0.5137) gate/usage_min 0.1979 (0.1979) gate/usage_std 0.1334 (0.1328) teacher/entropy 0.0423 (0.0159) teacher/usage_max 0.9174 (0.9140) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4144 (0.4126) nleep/row_max_mean 1493.7976 (1491.6377) nleep/row_max_std 65.7866 (58.6792) nleep/row_min_mean 1452.9990 (1449.9916) lr 8.7467e-04 eta 0:07:49
epoch [29/50] batch [160/176] time 0.094 (0.125) data 0.000 (0.002) loss 1.1777 (1.3233) teacher_loss 0.1565 (0.2838) loss_zs_kd 0.0354 (0.0196) loss_oracle 0.6083 (0.6611) kd_loss 0.6994 (0.6992) acc 96.8750 (89.2969) gate/entropy 1.0209 (1.0213) gate/usage_max 0.5146 (0.5138) gate/usage_min 0.1980 (0.1979) gate/usage_std 0.1333 (0.1329) teacher/entropy 0.0012 (0.0163) teacher/usage_max 0.9373 (0.9147) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4278 (0.4131) nleep/row_max_mean 1486.8801 (1491.9009) nleep/row_max_std 58.9937 (58.6235) nleep/row_min_mean 1444.3993 (1450.0995) lr 8.7467e-04 eta 0:07:42
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,178
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,764
* accuracy: 66.4%
* error: 33.6%
* macro_f1: 57.7%
******* Domain l best val acc:      90.0%, epoch: 24 *******
******* Domain l best val test acc: 62.5%, epoch: 24 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [30/50] batch [20/176] time 0.141 (0.124) data 0.000 (0.019) loss 1.1891 (1.3139) teacher_loss 0.1990 (0.2837) loss_zs_kd 0.0097 (0.0177) loss_oracle 0.5641 (0.6520) kd_loss 0.7032 (0.6954) acc 90.6250 (88.4375) gate/entropy 1.0206 (1.0206) gate/usage_max 0.5151 (0.5150) gate/usage_min 0.1980 (0.1979) gate/usage_std 0.1336 (0.1335) teacher/entropy 0.0175 (0.0151) teacher/usage_max 0.9020 (0.9198) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4041 (0.4164) nleep/row_max_mean 1482.3173 (1492.9723) nleep/row_max_std 74.1770 (61.1584) nleep/row_min_mean 1444.1504 (1450.7888) lr 8.1262e-04 eta 0:07:36
epoch [30/50] batch [40/176] time 0.124 (0.109) data 0.000 (0.009) loss 1.3845 (1.3116) teacher_loss 0.2742 (0.2747) loss_zs_kd 0.0235 (0.0186) loss_oracle 0.7285 (0.6660) kd_loss 0.7342 (0.6946) acc 87.5000 (89.2188) gate/entropy 1.0207 (1.0206) gate/usage_max 0.5149 (0.5151) gate/usage_min 0.1980 (0.1980) gate/usage_std 0.1334 (0.1336) teacher/entropy 0.0286 (0.0183) teacher/usage_max 0.8306 (0.9154) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.3584 (0.4136) nleep/row_max_mean 1470.7019 (1490.8620) nleep/row_max_std 58.1168 (60.2012) nleep/row_min_mean 1429.6575 (1449.1550) lr 8.1262e-04 eta 0:06:38
epoch [30/50] batch [60/176] time 0.135 (0.119) data 0.000 (0.006) loss 1.1738 (1.3154) teacher_loss 0.2059 (0.2825) loss_zs_kd 0.0132 (0.0172) loss_oracle 0.6593 (0.6621) kd_loss 0.6316 (0.6932) acc 87.5000 (89.2708) gate/entropy 1.0203 (1.0205) gate/usage_max 0.5156 (0.5152) gate/usage_min 0.1981 (0.1980) gate/usage_std 0.1338 (0.1336) teacher/entropy 0.0522 (0.0197) teacher/usage_max 0.9679 (0.9151) teacher/usage_min 0.0071 (0.0002) teacher/usage_std 0.4488 (0.4134) nleep/row_max_mean 1500.2025 (1490.4874) nleep/row_max_std 53.5418 (59.5729) nleep/row_min_mean 1459.2527 (1449.3542) lr 8.1262e-04 eta 0:07:11
epoch [30/50] batch [80/176] time 0.149 (0.125) data 0.000 (0.005) loss 1.3757 (1.3173) teacher_loss 0.3177 (0.2843) loss_zs_kd 0.0157 (0.0178) loss_oracle 0.6545 (0.6580) kd_loss 0.7229 (0.6951) acc 84.3750 (89.5312) gate/entropy 1.0201 (1.0205) gate/usage_max 0.5159 (0.5153) gate/usage_min 0.1980 (0.1980) gate/usage_std 0.1340 (0.1337) teacher/entropy 0.0155 (0.0197) teacher/usage_max 0.8709 (0.9119) teacher/usage_min 0.0021 (0.0005) teacher/usage_std 0.3835 (0.4113) nleep/row_max_mean 1483.3748 (1489.9146) nleep/row_max_std 66.1461 (59.0151) nleep/row_min_mean 1445.1021 (1448.9057) lr 8.1262e-04 eta 0:07:30
epoch [30/50] batch [100/176] time 0.154 (0.129) data 0.000 (0.004) loss 1.1674 (1.3189) teacher_loss 0.2092 (0.2862) loss_zs_kd 0.0155 (0.0185) loss_oracle 0.5443 (0.6540) kd_loss 0.6782 (0.6965) acc 96.8750 (89.3125) gate/entropy 1.0202 (1.0204) gate/usage_max 0.5158 (0.5154) gate/usage_min 0.1980 (0.1980) gate/usage_std 0.1339 (0.1337) teacher/entropy 0.0024 (0.0192) teacher/usage_max 0.9683 (0.9102) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4492 (0.4102) nleep/row_max_mean 1502.4641 (1490.5864) nleep/row_max_std 42.6058 (58.5748) nleep/row_min_mean 1459.5328 (1449.5595) lr 8.1262e-04 eta 0:07:43
epoch [30/50] batch [120/176] time 0.135 (0.130) data 0.000 (0.003) loss 1.3451 (1.3119) teacher_loss 0.3344 (0.2835) loss_zs_kd 0.0159 (0.0195) loss_oracle 0.6487 (0.6494) kd_loss 0.6784 (0.6939) acc 84.3750 (89.2969) gate/entropy 1.0201 (1.0204) gate/usage_max 0.5160 (0.5155) gate/usage_min 0.1981 (0.1980) gate/usage_std 0.1341 (0.1338) teacher/entropy 0.0017 (0.0206) teacher/usage_max 0.9685 (0.9124) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4493 (0.4116) nleep/row_max_mean 1495.8051 (1491.0549) nleep/row_max_std 49.5063 (58.2664) nleep/row_min_mean 1452.1719 (1450.0402) lr 8.1262e-04 eta 0:07:44
epoch [30/50] batch [140/176] time 0.136 (0.132) data 0.000 (0.003) loss 1.3494 (1.3150) teacher_loss 0.3320 (0.2834) loss_zs_kd 0.0071 (0.0195) loss_oracle 0.6778 (0.6534) kd_loss 0.6750 (0.6952) acc 84.3750 (89.2188) gate/entropy 1.0200 (1.0203) gate/usage_max 0.5161 (0.5156) gate/usage_min 0.1980 (0.1980) gate/usage_std 0.1341 (0.1338) teacher/entropy 0.0057 (0.0209) teacher/usage_max 0.9674 (0.9093) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4486 (0.4096) nleep/row_max_mean 1501.9141 (1490.5491) nleep/row_max_std 51.0890 (58.6251) nleep/row_min_mean 1457.9594 (1449.6793) lr 8.1262e-04 eta 0:07:49
epoch [30/50] batch [160/176] time 0.124 (0.133) data 0.000 (0.003) loss 1.1141 (1.3119) teacher_loss 0.1055 (0.2795) loss_zs_kd 0.0243 (0.0194) loss_oracle 0.6804 (0.6560) kd_loss 0.6563 (0.6947) acc 96.8750 (89.2383) gate/entropy 1.0199 (1.0203) gate/usage_max 0.5164 (0.5157) gate/usage_min 0.1980 (0.1980) gate/usage_std 0.1343 (0.1339) teacher/entropy 0.0674 (0.0219) teacher/usage_max 0.8942 (0.9082) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.3989 (0.4088) nleep/row_max_mean 1489.1338 (1490.8085) nleep/row_max_std 61.9894 (58.7670) nleep/row_min_mean 1446.8601 (1449.9147) lr 8.1262e-04 eta 0:07:49
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,181
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,749
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 57.9%
******* Domain l best val acc:      90.0%, epoch: 24 *******
******* Domain l best val test acc: 62.5%, epoch: 24 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [31/50] batch [20/176] time 0.147 (0.137) data 0.000 (0.020) loss 1.1498 (1.2822) teacher_loss 0.1267 (0.2384) loss_zs_kd 0.0148 (0.0170) loss_oracle 0.6663 (0.6597) kd_loss 0.6826 (0.7055) acc 93.7500 (90.3125) gate/entropy 1.0198 (1.0199) gate/usage_max 0.5164 (0.5162) gate/usage_min 0.1979 (0.1979) gate/usage_std 0.1343 (0.1342) teacher/entropy 0.0195 (0.0204) teacher/usage_max 0.9301 (0.8908) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4230 (0.3977) nleep/row_max_mean 1491.2682 (1489.2853) nleep/row_max_std 58.3623 (57.7868) nleep/row_min_mean 1450.5769 (1448.3279) lr 7.5131e-04 eta 0:07:59
epoch [31/50] batch [40/176] time 0.076 (0.125) data 0.000 (0.010) loss 1.4360 (1.3089) teacher_loss 0.3720 (0.2608) loss_zs_kd 0.0123 (0.0181) loss_oracle 0.6829 (0.6683) kd_loss 0.7164 (0.7048) acc 84.3750 (89.9219) gate/entropy 1.0199 (1.0199) gate/usage_max 0.5161 (0.5162) gate/usage_min 0.1978 (0.1979) gate/usage_std 0.1342 (0.1342) teacher/entropy 0.0000 (0.0207) teacher/usage_max 0.9062 (0.8915) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4069 (0.3981) nleep/row_max_mean 1499.0828 (1489.0438) nleep/row_max_std 55.3015 (56.7362) nleep/row_min_mean 1455.7456 (1448.3380) lr 7.5131e-04 eta 0:07:15
epoch [31/50] batch [60/176] time 0.076 (0.121) data 0.000 (0.007) loss 1.3980 (1.3203) teacher_loss 0.3943 (0.2767) loss_zs_kd 0.0280 (0.0189) loss_oracle 0.6348 (0.6665) kd_loss 0.6723 (0.7009) acc 81.2500 (89.1146) gate/entropy 1.0198 (1.0199) gate/usage_max 0.5163 (0.5163) gate/usage_min 0.1979 (0.1979) gate/usage_std 0.1343 (0.1342) teacher/entropy 0.0245 (0.0218) teacher/usage_max 0.9396 (0.8968) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4294 (0.4015) nleep/row_max_mean 1491.4558 (1489.1694) nleep/row_max_std 51.3149 (57.1459) nleep/row_min_mean 1453.5117 (1448.5934) lr 7.5131e-04 eta 0:06:58
epoch [31/50] batch [80/176] time 0.088 (0.116) data 0.000 (0.005) loss 1.2676 (1.3256) teacher_loss 0.2440 (0.2842) loss_zs_kd 0.0214 (0.0184) loss_oracle 0.6665 (0.6674) kd_loss 0.6796 (0.6985) acc 87.5000 (88.7500) gate/entropy 1.0197 (1.0198) gate/usage_max 0.5164 (0.5163) gate/usage_min 0.1978 (0.1979) gate/usage_std 0.1344 (0.1343) teacher/entropy 0.0419 (0.0216) teacher/usage_max 0.8973 (0.9012) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4010 (0.4043) nleep/row_max_mean 1489.4093 (1490.6228) nleep/row_max_std 63.7733 (56.4567) nleep/row_min_mean 1448.4065 (1449.7755) lr 7.5131e-04 eta 0:06:39
epoch [31/50] batch [100/176] time 0.134 (0.115) data 0.000 (0.004) loss 1.4355 (1.3190) teacher_loss 0.3604 (0.2821) loss_zs_kd 0.0203 (0.0187) loss_oracle 0.6989 (0.6649) kd_loss 0.7155 (0.6951) acc 87.5000 (89.0000) gate/entropy 1.0196 (1.0198) gate/usage_max 0.5168 (0.5164) gate/usage_min 0.1980 (0.1979) gate/usage_std 0.1345 (0.1343) teacher/entropy 0.0001 (0.0215) teacher/usage_max 0.9062 (0.9068) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.4069 (0.4080) nleep/row_max_mean 1492.6959 (1490.9927) nleep/row_max_std 54.8480 (56.0316) nleep/row_min_mean 1451.3574 (1450.1094) lr 7.5131e-04 eta 0:06:32
epoch [31/50] batch [120/176] time 0.159 (0.115) data 0.000 (0.003) loss 1.1865 (1.3130) teacher_loss 0.1926 (0.2784) loss_zs_kd 0.0109 (0.0187) loss_oracle 0.5543 (0.6618) kd_loss 0.7113 (0.6944) acc 96.8750 (89.2448) gate/entropy 1.0194 (1.0198) gate/usage_max 0.5171 (0.5165) gate/usage_min 0.1980 (0.1979) gate/usage_std 0.1347 (0.1343) teacher/entropy 0.0178 (0.0210) teacher/usage_max 0.8829 (0.9085) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.3916 (0.4092) nleep/row_max_mean 1489.3584 (1491.3469) nleep/row_max_std 62.1969 (55.8048) nleep/row_min_mean 1450.1335 (1450.5064) lr 7.5131e-04 eta 0:06:32
epoch [31/50] batch [140/176] time 0.133 (0.115) data 0.000 (0.003) loss 1.1029 (1.3128) teacher_loss 0.0752 (0.2766) loss_zs_kd 0.0078 (0.0185) loss_oracle 0.6435 (0.6632) kd_loss 0.7021 (0.6953) acc 100.0000 (89.4196) gate/entropy 1.0195 (1.0197) gate/usage_max 0.5171 (0.5165) gate/usage_min 0.1981 (0.1979) gate/usage_std 0.1347 (0.1344) teacher/entropy 0.0158 (0.0206) teacher/usage_max 0.9029 (0.9073) teacher/usage_min 0.0013 (0.0012) teacher/usage_std 0.4046 (0.4083) nleep/row_max_mean 1488.2334 (1491.0539) nleep/row_max_std 57.8360 (56.2689) nleep/row_min_mean 1447.2891 (1450.3264) lr 7.5131e-04 eta 0:06:28
epoch [31/50] batch [160/176] time 0.075 (0.114) data 0.000 (0.003) loss 1.4742 (1.3122) teacher_loss 0.3579 (0.2782) loss_zs_kd 0.0303 (0.0187) loss_oracle 0.7503 (0.6598) kd_loss 0.7260 (0.6947) acc 90.6250 (89.2578) gate/entropy 1.0193 (1.0197) gate/usage_max 0.5172 (0.5166) gate/usage_min 0.1980 (0.1979) gate/usage_std 0.1348 (0.1345) teacher/entropy 0.0092 (0.0201) teacher/usage_max 0.8733 (0.9090) teacher/usage_min 0.0007 (0.0012) teacher/usage_std 0.3852 (0.4094) nleep/row_max_mean 1472.3961 (1491.3700) nleep/row_max_std 66.5951 (55.7726) nleep/row_min_mean 1436.0529 (1450.5993) lr 7.5131e-04 eta 0:06:24
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,183
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 91.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,732
* accuracy: 65.2%
* error: 34.8%
* macro_f1: 58.3%
******* Domain l best val acc:      90.1%, epoch: 31 *******
******* Domain l best val test acc: 65.2%, epoch: 31 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [32/50] batch [20/176] time 0.119 (0.154) data 0.000 (0.020) loss 1.2204 (1.3020) teacher_loss 0.2163 (0.2896) loss_zs_kd 0.0094 (0.0201) loss_oracle 0.6899 (0.6344) kd_loss 0.6545 (0.6852) acc 93.7500 (90.1562) gate/entropy 1.0190 (1.0191) gate/usage_max 0.5179 (0.5178) gate/usage_min 0.1981 (0.1981) gate/usage_std 0.1351 (0.1351) teacher/entropy 0.0219 (0.0177) teacher/usage_max 0.9808 (0.9265) teacher/usage_min 0.0001 (0.0004) teacher/usage_std 0.4579 (0.4209) nleep/row_max_mean 1505.7780 (1495.3003) nleep/row_max_std 40.9303 (51.7795) nleep/row_min_mean 1463.0897 (1454.1471) lr 6.9098e-04 eta 0:08:32
epoch [32/50] batch [40/176] time 0.142 (0.144) data 0.000 (0.010) loss 1.1061 (1.2930) teacher_loss 0.1482 (0.2753) loss_zs_kd 0.0161 (0.0195) loss_oracle 0.5460 (0.6335) kd_loss 0.6769 (0.6912) acc 93.7500 (90.3125) gate/entropy 1.0191 (1.0190) gate/usage_max 0.5178 (0.5179) gate/usage_min 0.1982 (0.1981) gate/usage_std 0.1351 (0.1351) teacher/entropy 0.0001 (0.0168) teacher/usage_max 0.9687 (0.9175) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4495 (0.4150) nleep/row_max_mean 1495.3967 (1494.1172) nleep/row_max_std 49.0229 (54.6567) nleep/row_min_mean 1453.3920 (1453.1261) lr 6.9098e-04 eta 0:07:56
epoch [32/50] batch [60/176] time 0.148 (0.140) data 0.000 (0.007) loss 1.6229 (1.2971) teacher_loss 0.6618 (0.2791) loss_zs_kd 0.0157 (0.0197) loss_oracle 0.5635 (0.6290) kd_loss 0.6715 (0.6936) acc 75.0000 (89.9479) gate/entropy 1.0187 (1.0189) gate/usage_max 0.5185 (0.5180) gate/usage_min 0.1982 (0.1981) gate/usage_std 0.1354 (0.1352) teacher/entropy 0.0045 (0.0158) teacher/usage_max 0.9679 (0.9150) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4489 (0.4132) nleep/row_max_mean 1490.1204 (1493.6247) nleep/row_max_std 54.8511 (55.4788) nleep/row_min_mean 1450.2731 (1452.6923) lr 6.9098e-04 eta 0:07:38
epoch [32/50] batch [80/176] time 0.120 (0.138) data 0.000 (0.005) loss 1.5150 (1.2922) teacher_loss 0.5017 (0.2774) loss_zs_kd 0.0246 (0.0196) loss_oracle 0.5439 (0.6244) kd_loss 0.7291 (0.6928) acc 81.2500 (90.0000) gate/entropy 1.0185 (1.0189) gate/usage_max 0.5188 (0.5181) gate/usage_min 0.1983 (0.1982) gate/usage_std 0.1356 (0.1353) teacher/entropy 0.0031 (0.0150) teacher/usage_max 0.8750 (0.9173) teacher/usage_min 0.0005 (0.0012) teacher/usage_std 0.3863 (0.4147) nleep/row_max_mean 1484.6858 (1494.1848) nleep/row_max_std 58.8252 (55.1569) nleep/row_min_mean 1443.5714 (1452.9948) lr 6.9098e-04 eta 0:07:30
epoch [32/50] batch [100/176] time 0.141 (0.137) data 0.000 (0.004) loss 1.4172 (1.2941) teacher_loss 0.4058 (0.2818) loss_zs_kd 0.0243 (0.0196) loss_oracle 0.6016 (0.6199) kd_loss 0.6984 (0.6925) acc 78.1250 (89.6250) gate/entropy 1.0181 (1.0188) gate/usage_max 0.5195 (0.5183) gate/usage_min 0.1984 (0.1982) gate/usage_std 0.1360 (0.1353) teacher/entropy 0.0153 (0.0144) teacher/usage_max 0.9038 (0.9185) teacher/usage_min 0.0003 (0.0013) teacher/usage_std 0.4053 (0.4156) nleep/row_max_mean 1495.4489 (1494.5468) nleep/row_max_std 59.1997 (54.9999) nleep/row_min_mean 1453.9417 (1453.2039) lr 6.9098e-04 eta 0:07:23
epoch [32/50] batch [120/176] time 0.108 (0.135) data 0.000 (0.004) loss 1.3432 (1.2894) teacher_loss 0.3438 (0.2800) loss_zs_kd 0.0237 (0.0193) loss_oracle 0.6094 (0.6166) kd_loss 0.6828 (0.6914) acc 84.3750 (89.6094) gate/entropy 1.0184 (1.0187) gate/usage_max 0.5192 (0.5185) gate/usage_min 0.1986 (0.1983) gate/usage_std 0.1358 (0.1354) teacher/entropy 0.0031 (0.0151) teacher/usage_max 0.9682 (0.9188) teacher/usage_min 0.0006 (0.0013) teacher/usage_std 0.4491 (0.4158) nleep/row_max_mean 1498.2738 (1494.6311) nleep/row_max_std 44.5025 (54.7800) nleep/row_min_mean 1452.3868 (1453.2012) lr 6.9098e-04 eta 0:07:15
epoch [32/50] batch [140/176] time 0.123 (0.131) data 0.000 (0.003) loss 1.2846 (1.2882) teacher_loss 0.2494 (0.2772) loss_zs_kd 0.0107 (0.0188) loss_oracle 0.6369 (0.6203) kd_loss 0.7114 (0.6915) acc 84.3750 (89.6875) gate/entropy 1.0180 (1.0186) gate/usage_max 0.5197 (0.5186) gate/usage_min 0.1985 (0.1983) gate/usage_std 0.1361 (0.1355) teacher/entropy 0.0003 (0.0149) teacher/usage_max 0.9062 (0.9187) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.4069 (0.4157) nleep/row_max_mean 1505.1278 (1494.6061) nleep/row_max_std 56.5098 (54.3809) nleep/row_min_mean 1460.4846 (1453.1670) lr 6.9098e-04 eta 0:07:00
epoch [32/50] batch [160/176] time 0.086 (0.128) data 0.000 (0.003) loss 1.2964 (1.2926) teacher_loss 0.2120 (0.2764) loss_zs_kd 0.0160 (0.0188) loss_oracle 0.7817 (0.6277) kd_loss 0.6856 (0.6930) acc 90.6250 (89.7070) gate/entropy 1.0180 (1.0185) gate/usage_max 0.5198 (0.5188) gate/usage_min 0.1987 (0.1983) gate/usage_std 0.1361 (0.1356) teacher/entropy 0.0392 (0.0146) teacher/usage_max 0.8880 (0.9164) teacher/usage_min 0.0055 (0.0016) teacher/usage_std 0.3944 (0.4142) nleep/row_max_mean 1474.6948 (1494.6356) nleep/row_max_std 60.6023 (54.5741) nleep/row_min_mean 1439.8621 (1453.1712) lr 6.9098e-04 eta 0:06:47
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,176
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,759
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 58.3%
******* Domain l best val acc:      90.1%, epoch: 31 *******
******* Domain l best val test acc: 65.2%, epoch: 31 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [33/50] batch [20/176] time 0.126 (0.146) data 0.000 (0.017) loss 1.4925 (1.3061) teacher_loss 0.4349 (0.2603) loss_zs_kd 0.0086 (0.0182) loss_oracle 0.6469 (0.6739) kd_loss 0.7298 (0.6998) acc 87.5000 (90.6250) gate/entropy 1.0177 (1.0178) gate/usage_max 0.5203 (0.5202) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1364 (0.1363) teacher/entropy 0.0002 (0.0140) teacher/usage_max 0.8750 (0.9026) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.3864 (0.4049) nleep/row_max_mean 1490.0122 (1490.7910) nleep/row_max_std 59.3376 (54.3714) nleep/row_min_mean 1450.2979 (1450.6878) lr 6.3188e-04 eta 0:07:38
epoch [33/50] batch [40/176] time 0.151 (0.130) data 0.000 (0.009) loss 1.3455 (1.3219) teacher_loss 0.3125 (0.2890) loss_zs_kd 0.0259 (0.0188) loss_oracle 0.7207 (0.6751) kd_loss 0.6597 (0.6860) acc 87.5000 (88.9062) gate/entropy 1.0177 (1.0177) gate/usage_max 0.5203 (0.5202) gate/usage_min 0.1987 (0.1986) gate/usage_std 0.1364 (0.1364) teacher/entropy 0.0168 (0.0173) teacher/usage_max 0.9623 (0.9195) teacher/usage_min 0.0001 (0.0009) teacher/usage_std 0.4450 (0.4163) nleep/row_max_mean 1493.1404 (1492.0702) nleep/row_max_std 45.5887 (51.4630) nleep/row_min_mean 1451.8126 (1451.9970) lr 6.3188e-04 eta 0:06:46
epoch [33/50] batch [60/176] time 0.090 (0.122) data 0.001 (0.006) loss 1.1916 (1.3119) teacher_loss 0.1763 (0.2822) loss_zs_kd 0.0165 (0.0190) loss_oracle 0.6991 (0.6734) kd_loss 0.6575 (0.6834) acc 93.7500 (89.2708) gate/entropy 1.0175 (1.0177) gate/usage_max 0.5207 (0.5203) gate/usage_min 0.1987 (0.1986) gate/usage_std 0.1366 (0.1364) teacher/entropy 0.0179 (0.0170) teacher/usage_max 0.9632 (0.9239) teacher/usage_min 0.0002 (0.0007) teacher/usage_std 0.4456 (0.4192) nleep/row_max_mean 1495.8480 (1493.5331) nleep/row_max_std 47.8235 (51.0964) nleep/row_min_mean 1453.9285 (1453.2799) lr 6.3188e-04 eta 0:06:18
epoch [33/50] batch [80/176] time 0.129 (0.124) data 0.000 (0.005) loss 1.2825 (1.3219) teacher_loss 0.2179 (0.2823) loss_zs_kd 0.0263 (0.0191) loss_oracle 0.6972 (0.6795) kd_loss 0.7028 (0.6903) acc 90.6250 (89.2969) gate/entropy 1.0176 (1.0177) gate/usage_max 0.5205 (0.5204) gate/usage_min 0.1987 (0.1987) gate/usage_std 0.1365 (0.1365) teacher/entropy 0.0203 (0.0168) teacher/usage_max 0.8860 (0.9131) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.3935 (0.4122) nleep/row_max_mean 1497.3556 (1492.2250) nleep/row_max_std 56.3748 (52.4561) nleep/row_min_mean 1457.3564 (1452.2462) lr 6.3188e-04 eta 0:06:21
epoch [33/50] batch [100/176] time 0.140 (0.125) data 0.000 (0.004) loss 1.1655 (1.3150) teacher_loss 0.1295 (0.2785) loss_zs_kd 0.0096 (0.0197) loss_oracle 0.7152 (0.6760) kd_loss 0.6737 (0.6886) acc 96.8750 (89.2812) gate/entropy 1.0175 (1.0176) gate/usage_max 0.5208 (0.5205) gate/usage_min 0.1988 (0.1987) gate/usage_std 0.1367 (0.1365) teacher/entropy 0.0318 (0.0170) teacher/usage_max 0.9153 (0.9152) teacher/usage_min 0.0022 (0.0011) teacher/usage_std 0.4128 (0.4136) nleep/row_max_mean 1498.2070 (1493.0194) nleep/row_max_std 46.1956 (52.6841) nleep/row_min_mean 1456.3258 (1452.9059) lr 6.3188e-04 eta 0:06:24
epoch [33/50] batch [120/176] time 0.128 (0.127) data 0.000 (0.003) loss 1.2570 (1.3162) teacher_loss 0.2568 (0.2833) loss_zs_kd 0.0161 (0.0203) loss_oracle 0.6576 (0.6701) kd_loss 0.6633 (0.6876) acc 90.6250 (89.1927) gate/entropy 1.0174 (1.0176) gate/usage_max 0.5209 (0.5205) gate/usage_min 0.1987 (0.1987) gate/usage_std 0.1368 (0.1365) teacher/entropy 0.0342 (0.0180) teacher/usage_max 0.9270 (0.9154) teacher/usage_min 0.0002 (0.0014) teacher/usage_std 0.4208 (0.4137) nleep/row_max_mean 1496.2178 (1492.8601) nleep/row_max_std 58.4969 (52.9580) nleep/row_min_mean 1455.7233 (1452.8394) lr 6.3188e-04 eta 0:06:27
epoch [33/50] batch [140/176] time 0.122 (0.128) data 0.000 (0.003) loss 1.1891 (1.3117) teacher_loss 0.1483 (0.2778) loss_zs_kd 0.0108 (0.0199) loss_oracle 0.7208 (0.6712) kd_loss 0.6750 (0.6883) acc 93.7500 (89.4420) gate/entropy 1.0172 (1.0175) gate/usage_max 0.5212 (0.5206) gate/usage_min 0.1988 (0.1987) gate/usage_std 0.1369 (0.1366) teacher/entropy 0.0193 (0.0188) teacher/usage_max 0.9315 (0.9127) teacher/usage_min 0.0005 (0.0015) teacher/usage_std 0.4238 (0.4119) nleep/row_max_mean 1498.0635 (1492.8293) nleep/row_max_std 57.5502 (53.5925) nleep/row_min_mean 1458.5352 (1452.8538) lr 6.3188e-04 eta 0:06:28
epoch [33/50] batch [160/176] time 0.170 (0.130) data 0.000 (0.002) loss 1.4142 (1.3128) teacher_loss 0.4143 (0.2788) loss_zs_kd 0.0117 (0.0195) loss_oracle 0.6107 (0.6700) kd_loss 0.6888 (0.6892) acc 84.3750 (89.1406) gate/entropy 1.0173 (1.0175) gate/usage_max 0.5210 (0.5207) gate/usage_min 0.1987 (0.1987) gate/usage_std 0.1368 (0.1366) teacher/entropy 0.0024 (0.0189) teacher/usage_max 0.9371 (0.9109) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.4277 (0.4108) nleep/row_max_mean 1504.8020 (1492.6807) nleep/row_max_std 44.5408 (53.7411) nleep/row_min_mean 1461.8746 (1452.7472) lr 6.3188e-04 eta 0:06:30
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,741
* accuracy: 65.5%
* error: 34.5%
* macro_f1: 58.4%
******* Domain l best val acc:      90.1%, epoch: 31 *******
******* Domain l best val test acc: 65.2%, epoch: 31 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [34/50] batch [20/176] time 0.092 (0.125) data 0.000 (0.015) loss 1.1568 (1.3206) teacher_loss 0.1871 (0.2818) loss_zs_kd 0.0189 (0.0171) loss_oracle 0.5624 (0.6808) kd_loss 0.6791 (0.6898) acc 96.8750 (89.2188) gate/entropy 1.0171 (1.0172) gate/usage_max 0.5214 (0.5211) gate/usage_min 0.1988 (0.1987) gate/usage_std 0.1370 (0.1369) teacher/entropy 0.0134 (0.0284) teacher/usage_max 0.9331 (0.8937) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4250 (0.3989) nleep/row_max_mean 1502.9248 (1485.6458) nleep/row_max_std 60.4969 (59.3521) nleep/row_min_mean 1463.5020 (1447.2491) lr 5.7422e-04 eta 0:06:11
epoch [34/50] batch [40/176] time 0.090 (0.120) data 0.000 (0.008) loss 1.3624 (1.3262) teacher_loss 0.3406 (0.2794) loss_zs_kd 0.0133 (0.0174) loss_oracle 0.6610 (0.6906) kd_loss 0.6846 (0.6928) acc 78.1250 (88.7500) gate/entropy 1.0171 (1.0172) gate/usage_max 0.5214 (0.5212) gate/usage_min 0.1987 (0.1987) gate/usage_std 0.1370 (0.1369) teacher/entropy 0.0396 (0.0268) teacher/usage_max 0.8850 (0.8913) teacher/usage_min 0.0040 (0.0017) teacher/usage_std 0.3925 (0.3977) nleep/row_max_mean 1476.4607 (1486.9950) nleep/row_max_std 67.0547 (59.6290) nleep/row_min_mean 1440.8485 (1448.5753) lr 5.7422e-04 eta 0:05:53
epoch [34/50] batch [60/176] time 0.078 (0.116) data 0.001 (0.005) loss 1.2422 (1.3057) teacher_loss 0.2982 (0.2641) loss_zs_kd 0.0127 (0.0173) loss_oracle 0.5942 (0.6820) kd_loss 0.6406 (0.6920) acc 90.6250 (89.4792) gate/entropy 1.0171 (1.0172) gate/usage_max 0.5214 (0.5212) gate/usage_min 0.1988 (0.1987) gate/usage_std 0.1370 (0.1369) teacher/entropy 0.0268 (0.0243) teacher/usage_max 0.9827 (0.8965) teacher/usage_min 0.0011 (0.0013) teacher/usage_std 0.4592 (0.4011) nleep/row_max_mean 1503.1399 (1489.1672) nleep/row_max_std 59.6251 (58.9453) nleep/row_min_mean 1460.4185 (1450.0708) lr 5.7422e-04 eta 0:05:40
epoch [34/50] batch [80/176] time 0.085 (0.115) data 0.000 (0.004) loss 1.3500 (1.3123) teacher_loss 0.2369 (0.2731) loss_zs_kd 0.0290 (0.0176) loss_oracle 0.7583 (0.6799) kd_loss 0.7195 (0.6905) acc 87.5000 (89.2578) gate/entropy 1.0170 (1.0172) gate/usage_max 0.5214 (0.5212) gate/usage_min 0.1986 (0.1987) gate/usage_std 0.1371 (0.1369) teacher/entropy 0.0084 (0.0249) teacher/usage_max 0.8772 (0.8981) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.3878 (0.4021) nleep/row_max_mean 1491.5302 (1489.3238) nleep/row_max_std 59.0073 (58.7724) nleep/row_min_mean 1452.0167 (1450.0739) lr 5.7422e-04 eta 0:05:35
epoch [34/50] batch [100/176] time 0.098 (0.114) data 0.000 (0.003) loss 1.4267 (1.3180) teacher_loss 0.4743 (0.2790) loss_zs_kd 0.0302 (0.0180) loss_oracle 0.5878 (0.6796) kd_loss 0.6434 (0.6903) acc 84.3750 (89.1562) gate/entropy 1.0169 (1.0172) gate/usage_max 0.5215 (0.5212) gate/usage_min 0.1986 (0.1987) gate/usage_std 0.1371 (0.1369) teacher/entropy 0.0315 (0.0255) teacher/usage_max 0.9617 (0.8975) teacher/usage_min 0.0003 (0.0016) teacher/usage_std 0.4446 (0.4017) nleep/row_max_mean 1500.1033 (1489.7274) nleep/row_max_std 56.3913 (58.5084) nleep/row_min_mean 1458.9385 (1450.4191) lr 5.7422e-04 eta 0:05:29
epoch [34/50] batch [120/176] time 0.091 (0.113) data 0.000 (0.003) loss 1.4136 (1.3233) teacher_loss 0.3733 (0.2836) loss_zs_kd 0.0122 (0.0177) loss_oracle 0.6831 (0.6806) kd_loss 0.6926 (0.6906) acc 87.5000 (89.0365) gate/entropy 1.0173 (1.0171) gate/usage_max 0.5210 (0.5212) gate/usage_min 0.1986 (0.1987) gate/usage_std 0.1368 (0.1370) teacher/entropy 0.0219 (0.0253) teacher/usage_max 0.8990 (0.8972) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4021 (0.4015) nleep/row_max_mean 1472.4662 (1489.2969) nleep/row_max_std 61.5597 (58.8473) nleep/row_min_mean 1433.4431 (1450.1697) lr 5.7422e-04 eta 0:05:23
epoch [34/50] batch [140/176] time 0.102 (0.113) data 0.000 (0.002) loss 1.2026 (1.3169) teacher_loss 0.1881 (0.2785) loss_zs_kd 0.0087 (0.0180) loss_oracle 0.6660 (0.6738) kd_loss 0.6771 (0.6925) acc 93.7500 (89.0848) gate/entropy 1.0170 (1.0171) gate/usage_max 0.5214 (0.5212) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1371 (0.1370) teacher/entropy 0.0553 (0.0247) teacher/usage_max 0.8995 (0.8954) teacher/usage_min 0.0462 (0.0018) teacher/usage_std 0.4003 (0.4003) nleep/row_max_mean 1509.4580 (1489.5656) nleep/row_max_std 40.7094 (58.5774) nleep/row_min_mean 1467.8311 (1450.3329) lr 5.7422e-04 eta 0:05:22
epoch [34/50] batch [160/176] time 0.152 (0.114) data 0.000 (0.002) loss 1.4681 (1.3164) teacher_loss 0.4151 (0.2777) loss_zs_kd 0.0064 (0.0183) loss_oracle 0.7460 (0.6732) kd_loss 0.6768 (0.6930) acc 81.2500 (89.1602) gate/entropy 1.0171 (1.0171) gate/usage_max 0.5212 (0.5212) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1370 (0.1370) teacher/entropy 0.0298 (0.0239) teacher/usage_max 0.9119 (0.8956) teacher/usage_min 0.0011 (0.0016) teacher/usage_std 0.4106 (0.4005) nleep/row_max_mean 1481.7195 (1489.2222) nleep/row_max_std 58.9249 (58.3343) nleep/row_min_mean 1443.3823 (1449.9557) lr 5.7422e-04 eta 0:05:21
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,178
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,784
* accuracy: 67.2%
* error: 32.8%
* macro_f1: 59.0%
******* Domain l best val acc:      90.1%, epoch: 31 *******
******* Domain l best val test acc: 65.2%, epoch: 31 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [35/50] batch [20/176] time 0.137 (0.149) data 0.000 (0.013) loss 1.4203 (1.3033) teacher_loss 0.3961 (0.2545) loss_zs_kd 0.0174 (0.0160) loss_oracle 0.7116 (0.6654) kd_loss 0.6597 (0.7081) acc 81.2500 (90.1562) gate/entropy 1.0171 (1.0171) gate/usage_max 0.5212 (0.5213) gate/usage_min 0.1985 (0.1985) gate/usage_std 0.1370 (0.1370) teacher/entropy 0.0138 (0.0188) teacher/usage_max 0.9648 (0.8798) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.4468 (0.3901) nleep/row_max_mean 1490.4591 (1489.9648) nleep/row_max_std 38.4867 (55.9149) nleep/row_min_mean 1451.6741 (1450.1022) lr 5.1825e-04 eta 0:06:57
epoch [35/50] batch [40/176] time 0.160 (0.144) data 0.000 (0.006) loss 1.2843 (1.3096) teacher_loss 0.3205 (0.2715) loss_zs_kd 0.0087 (0.0168) loss_oracle 0.5781 (0.6627) kd_loss 0.6703 (0.6983) acc 87.5000 (89.2969) gate/entropy 1.0170 (1.0170) gate/usage_max 0.5213 (0.5213) gate/usage_min 0.1985 (0.1985) gate/usage_std 0.1371 (0.1370) teacher/entropy 0.0290 (0.0218) teacher/usage_max 0.9240 (0.8904) teacher/usage_min 0.0020 (0.0022) teacher/usage_std 0.4187 (0.3971) nleep/row_max_mean 1497.9500 (1491.8429) nleep/row_max_std 48.3784 (54.9178) nleep/row_min_mean 1458.7137 (1452.0507) lr 5.1825e-04 eta 0:06:39
epoch [35/50] batch [60/176] time 0.141 (0.142) data 0.001 (0.004) loss 1.1238 (1.2998) teacher_loss 0.0809 (0.2600) loss_zs_kd 0.0297 (0.0183) loss_oracle 0.7228 (0.6637) kd_loss 0.6667 (0.6988) acc 96.8750 (89.8958) gate/entropy 1.0171 (1.0170) gate/usage_max 0.5212 (0.5213) gate/usage_min 0.1985 (0.1985) gate/usage_std 0.1370 (0.1371) teacher/entropy 0.0480 (0.0209) teacher/usage_max 0.8984 (0.8906) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.4017 (0.3972) nleep/row_max_mean 1494.7505 (1492.1009) nleep/row_max_std 57.0642 (55.1478) nleep/row_min_mean 1454.4961 (1452.4432) lr 5.1825e-04 eta 0:06:30
epoch [35/50] batch [80/176] time 0.119 (0.140) data 0.000 (0.003) loss 1.1491 (1.2998) teacher_loss 0.1517 (0.2575) loss_zs_kd 0.0236 (0.0192) loss_oracle 0.6203 (0.6645) kd_loss 0.6755 (0.7005) acc 93.7500 (90.0781) gate/entropy 1.0168 (1.0170) gate/usage_max 0.5217 (0.5214) gate/usage_min 0.1985 (0.1985) gate/usage_std 0.1373 (0.1371) teacher/entropy 0.0118 (0.0191) teacher/usage_max 0.9412 (0.8910) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.4305 (0.3974) nleep/row_max_mean 1510.9467 (1492.1451) nleep/row_max_std 46.7588 (54.9477) nleep/row_min_mean 1470.2173 (1452.7876) lr 5.1825e-04 eta 0:06:24
epoch [35/50] batch [100/176] time 0.143 (0.139) data 0.000 (0.003) loss 1.2168 (1.3024) teacher_loss 0.1819 (0.2606) loss_zs_kd 0.0076 (0.0196) loss_oracle 0.6613 (0.6648) kd_loss 0.7005 (0.6996) acc 90.6250 (89.9375) gate/entropy 1.0168 (1.0170) gate/usage_max 0.5217 (0.5214) gate/usage_min 0.1985 (0.1985) gate/usage_std 0.1373 (0.1371) teacher/entropy 0.0090 (0.0195) teacher/usage_max 0.9052 (0.8918) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.4062 (0.3978) nleep/row_max_mean 1498.2693 (1491.6210) nleep/row_max_std 53.0543 (55.0454) nleep/row_min_mean 1459.8564 (1452.5834) lr 5.1825e-04 eta 0:06:16
epoch [35/50] batch [120/176] time 0.154 (0.139) data 0.000 (0.002) loss 1.2818 (1.3041) teacher_loss 0.2896 (0.2649) loss_zs_kd 0.0186 (0.0196) loss_oracle 0.6241 (0.6618) kd_loss 0.6709 (0.6984) acc 90.6250 (89.8698) gate/entropy 1.0168 (1.0170) gate/usage_max 0.5217 (0.5214) gate/usage_min 0.1985 (0.1985) gate/usage_std 0.1373 (0.1371) teacher/entropy 0.0233 (0.0203) teacher/usage_max 0.9299 (0.8924) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.4228 (0.3982) nleep/row_max_mean 1495.0176 (1490.9598) nleep/row_max_std 55.9017 (55.0841) nleep/row_min_mean 1456.2380 (1452.1037) lr 5.1825e-04 eta 0:06:15
epoch [35/50] batch [140/176] time 0.089 (0.136) data 0.000 (0.002) loss 1.2483 (1.3116) teacher_loss 0.3386 (0.2742) loss_zs_kd 0.0104 (0.0196) loss_oracle 0.5157 (0.6613) kd_loss 0.6466 (0.6970) acc 84.3750 (89.4196) gate/entropy 1.0168 (1.0169) gate/usage_max 0.5217 (0.5215) gate/usage_min 0.1986 (0.1985) gate/usage_std 0.1372 (0.1371) teacher/entropy 0.0047 (0.0200) teacher/usage_max 0.9991 (0.8950) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.4708 (0.3999) nleep/row_max_mean 1496.4919 (1491.0444) nleep/row_max_std 51.8517 (55.0722) nleep/row_min_mean 1453.9524 (1452.1394) lr 5.1825e-04 eta 0:06:03
epoch [35/50] batch [160/176] time 0.087 (0.132) data 0.000 (0.002) loss 1.3201 (1.3119) teacher_loss 0.3373 (0.2750) loss_zs_kd 0.0260 (0.0194) loss_oracle 0.6285 (0.6627) kd_loss 0.6556 (0.6958) acc 87.5000 (89.3750) gate/entropy 1.0168 (1.0169) gate/usage_max 0.5218 (0.5215) gate/usage_min 0.1985 (0.1985) gate/usage_std 0.1373 (0.1372) teacher/entropy 0.0522 (0.0210) teacher/usage_max 0.9099 (0.8953) teacher/usage_min 0.0032 (0.0021) teacher/usage_std 0.4091 (0.4001) nleep/row_max_mean 1495.1072 (1490.8281) nleep/row_max_std 56.2540 (55.1271) nleep/row_min_mean 1458.7063 (1452.0593) lr 5.1825e-04 eta 0:05:50
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,183
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,743
* accuracy: 65.6%
* error: 34.4%
* macro_f1: 59.0%
******* Domain l best val acc:      90.1%, epoch: 31 *******
******* Domain l best val test acc: 65.2%, epoch: 31 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [36/50] batch [20/176] time 0.092 (0.118) data 0.000 (0.017) loss 1.3681 (1.2967) teacher_loss 0.3485 (0.2582) loss_zs_kd 0.0175 (0.0185) loss_oracle 0.6977 (0.6683) kd_loss 0.6620 (0.6951) acc 87.5000 (90.0000) gate/entropy 1.0168 (1.0167) gate/usage_max 0.5217 (0.5219) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1373 (0.1374) teacher/entropy 0.0499 (0.0228) teacher/usage_max 0.9022 (0.8921) teacher/usage_min 0.0012 (0.0006) teacher/usage_std 0.4041 (0.3980) nleep/row_max_mean 1490.2454 (1488.6788) nleep/row_max_std 51.7212 (54.9229) nleep/row_min_mean 1451.5608 (1450.4889) lr 4.6417e-04 eta 0:05:09
epoch [36/50] batch [40/176] time 0.073 (0.116) data 0.000 (0.009) loss 1.2264 (1.2680) teacher_loss 0.2020 (0.2446) loss_zs_kd 0.0145 (0.0199) loss_oracle 0.7033 (0.6455) kd_loss 0.6655 (0.6907) acc 90.6250 (90.9375) gate/entropy 1.0164 (1.0167) gate/usage_max 0.5223 (0.5219) gate/usage_min 0.1985 (0.1986) gate/usage_std 0.1376 (0.1374) teacher/entropy 0.0034 (0.0210) teacher/usage_max 0.9688 (0.9023) teacher/usage_min 0.0001 (0.0016) teacher/usage_std 0.4495 (0.4047) nleep/row_max_mean 1505.4487 (1490.8381) nleep/row_max_std 45.4667 (54.4772) nleep/row_min_mean 1464.7317 (1452.1416) lr 4.6417e-04 eta 0:05:02
epoch [36/50] batch [60/176] time 0.096 (0.116) data 0.001 (0.006) loss 1.3813 (1.2878) teacher_loss 0.3562 (0.2553) loss_zs_kd 0.0150 (0.0192) loss_oracle 0.6527 (0.6537) kd_loss 0.6913 (0.6961) acc 93.7500 (90.7812) gate/entropy 1.0167 (1.0166) gate/usage_max 0.5218 (0.5220) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1373 (0.1374) teacher/entropy 0.0159 (0.0198) teacher/usage_max 0.9090 (0.8957) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.4088 (0.4004) nleep/row_max_mean 1473.9792 (1489.4408) nleep/row_max_std 41.1777 (55.7284) nleep/row_min_mean 1435.0326 (1450.8838) lr 4.6417e-04 eta 0:04:59
epoch [36/50] batch [80/176] time 0.123 (0.115) data 0.000 (0.004) loss 1.4096 (1.3012) teacher_loss 0.4215 (0.2654) loss_zs_kd 0.0180 (0.0192) loss_oracle 0.5837 (0.6574) kd_loss 0.6873 (0.6974) acc 87.5000 (90.3125) gate/entropy 1.0164 (1.0166) gate/usage_max 0.5224 (0.5220) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1377 (0.1375) teacher/entropy 0.0466 (0.0190) teacher/usage_max 0.8650 (0.8954) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.3800 (0.4002) nleep/row_max_mean 1481.4595 (1489.3405) nleep/row_max_std 63.2053 (55.8081) nleep/row_min_mean 1444.4421 (1450.5614) lr 4.6417e-04 eta 0:04:53
epoch [36/50] batch [100/176] time 0.159 (0.121) data 0.000 (0.004) loss 1.2406 (1.2997) teacher_loss 0.2643 (0.2640) loss_zs_kd 0.0290 (0.0193) loss_oracle 0.5971 (0.6557) kd_loss 0.6633 (0.6982) acc 84.3750 (90.0000) gate/entropy 1.0163 (1.0166) gate/usage_max 0.5225 (0.5221) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1377 (0.1375) teacher/entropy 0.0422 (0.0190) teacher/usage_max 0.9098 (0.8942) teacher/usage_min 0.0001 (0.0035) teacher/usage_std 0.4093 (0.3993) nleep/row_max_mean 1504.7772 (1489.8753) nleep/row_max_std 59.5579 (56.1689) nleep/row_min_mean 1465.2083 (1451.0658) lr 4.6417e-04 eta 0:05:07
epoch [36/50] batch [120/176] time 0.133 (0.126) data 0.000 (0.003) loss 1.2617 (1.2954) teacher_loss 0.3082 (0.2640) loss_zs_kd 0.0080 (0.0190) loss_oracle 0.5622 (0.6512) kd_loss 0.6685 (0.6963) acc 81.2500 (89.8177) gate/entropy 1.0164 (1.0166) gate/usage_max 0.5224 (0.5221) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1377 (0.1375) teacher/entropy 0.0165 (0.0186) teacher/usage_max 0.9426 (0.8976) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.4315 (0.4016) nleep/row_max_mean 1504.0740 (1490.6320) nleep/row_max_std 55.5942 (55.5904) nleep/row_min_mean 1463.3218 (1451.6811) lr 4.6417e-04 eta 0:05:18
epoch [36/50] batch [140/176] time 0.148 (0.127) data 0.000 (0.003) loss 1.4495 (1.2893) teacher_loss 0.4198 (0.2605) loss_zs_kd 0.0149 (0.0192) loss_oracle 0.6455 (0.6479) kd_loss 0.6996 (0.6952) acc 87.5000 (90.0223) gate/entropy 1.0162 (1.0165) gate/usage_max 0.5226 (0.5221) gate/usage_min 0.1985 (0.1986) gate/usage_std 0.1378 (0.1375) teacher/entropy 0.0315 (0.0183) teacher/usage_max 0.8741 (0.8998) teacher/usage_min 0.0101 (0.0032) teacher/usage_std 0.3848 (0.4030) nleep/row_max_mean 1506.6023 (1491.2084) nleep/row_max_std 58.2105 (55.4518) nleep/row_min_mean 1469.0608 (1452.1827) lr 4.6417e-04 eta 0:05:18
epoch [36/50] batch [160/176] time 0.145 (0.128) data 0.000 (0.002) loss 1.2433 (1.2921) teacher_loss 0.2948 (0.2611) loss_zs_kd 0.0149 (0.0190) loss_oracle 0.6031 (0.6510) kd_loss 0.6395 (0.6960) acc 90.6250 (89.8047) gate/entropy 1.0164 (1.0165) gate/usage_max 0.5224 (0.5222) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1377 (0.1375) teacher/entropy 0.0530 (0.0186) teacher/usage_max 0.9311 (0.8979) teacher/usage_min 0.0001 (0.0031) teacher/usage_std 0.4236 (0.4019) nleep/row_max_mean 1500.1843 (1490.3798) nleep/row_max_std 48.8249 (55.7000) nleep/row_min_mean 1460.6073 (1451.5889) lr 4.6417e-04 eta 0:05:18
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,180
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,759
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 59.3%
******* Domain l best val acc:      90.1%, epoch: 31 *******
******* Domain l best val test acc: 65.2%, epoch: 31 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [37/50] batch [20/176] time 0.070 (0.161) data 0.000 (0.017) loss 1.3186 (1.2676) teacher_loss 0.2518 (0.2331) loss_zs_kd 0.0139 (0.0199) loss_oracle 0.6758 (0.6665) kd_loss 0.7219 (0.6913) acc 90.6250 (91.0938) gate/entropy 1.0163 (1.0162) gate/usage_max 0.5225 (0.5228) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1377 (0.1379) teacher/entropy 0.0073 (0.0178) teacher/usage_max 0.8735 (0.9040) teacher/usage_min 0.0016 (0.0004) teacher/usage_std 0.3852 (0.4061) nleep/row_max_mean 1487.7380 (1489.2268) nleep/row_max_std 58.5574 (53.8572) nleep/row_min_mean 1447.1110 (1451.0136) lr 4.1221e-04 eta 0:06:34
epoch [37/50] batch [40/176] time 0.153 (0.127) data 0.000 (0.009) loss 1.3563 (1.2982) teacher_loss 0.2909 (0.2497) loss_zs_kd 0.0170 (0.0206) loss_oracle 0.6977 (0.6655) kd_loss 0.7079 (0.7054) acc 87.5000 (90.4688) gate/entropy 1.0162 (1.0162) gate/usage_max 0.5227 (0.5227) gate/usage_min 0.1987 (0.1986) gate/usage_std 0.1378 (0.1378) teacher/entropy 0.0164 (0.0183) teacher/usage_max 0.8800 (0.8813) teacher/usage_min 0.0005 (0.0011) teacher/usage_std 0.3896 (0.3916) nleep/row_max_mean 1487.8619 (1487.1414) nleep/row_max_std 53.3406 (56.5469) nleep/row_min_mean 1449.3069 (1449.4034) lr 4.1221e-04 eta 0:05:06
epoch [37/50] batch [60/176] time 0.167 (0.121) data 0.001 (0.006) loss 1.3955 (1.3154) teacher_loss 0.2490 (0.2647) loss_zs_kd 0.0076 (0.0196) loss_oracle 0.8101 (0.6721) kd_loss 0.7376 (0.7048) acc 93.7500 (90.0521) gate/entropy 1.0164 (1.0162) gate/usage_max 0.5224 (0.5227) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1376 (0.1378) teacher/entropy 0.0092 (0.0195) teacher/usage_max 0.8448 (0.8805) teacher/usage_min 0.0004 (0.0015) teacher/usage_std 0.3671 (0.3912) nleep/row_max_mean 1477.6788 (1486.8114) nleep/row_max_std 55.5211 (56.1022) nleep/row_min_mean 1444.5710 (1449.3411) lr 4.1221e-04 eta 0:04:50
epoch [37/50] batch [80/176] time 0.168 (0.117) data 0.000 (0.004) loss 1.2802 (1.3047) teacher_loss 0.2573 (0.2647) loss_zs_kd 0.0125 (0.0196) loss_oracle 0.6235 (0.6617) kd_loss 0.7048 (0.6993) acc 90.6250 (89.8438) gate/entropy 1.0161 (1.0162) gate/usage_max 0.5228 (0.5227) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1379 (0.1378) teacher/entropy 0.0024 (0.0188) teacher/usage_max 0.9058 (0.8904) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4066 (0.3976) nleep/row_max_mean 1491.2140 (1487.9145) nleep/row_max_std 59.4763 (54.8978) nleep/row_min_mean 1452.8833 (1450.2841) lr 4.1221e-04 eta 0:04:39
epoch [37/50] batch [100/176] time 0.169 (0.116) data 0.000 (0.004) loss 1.5472 (1.3133) teacher_loss 0.4692 (0.2722) loss_zs_kd 0.0178 (0.0192) loss_oracle 0.7340 (0.6572) kd_loss 0.7021 (0.7029) acc 78.1250 (89.4688) gate/entropy 1.0161 (1.0162) gate/usage_max 0.5228 (0.5227) gate/usage_min 0.1985 (0.1986) gate/usage_std 0.1379 (0.1379) teacher/entropy 0.0241 (0.0193) teacher/usage_max 0.8783 (0.8847) teacher/usage_min 0.0028 (0.0029) teacher/usage_std 0.3883 (0.3938) nleep/row_max_mean 1486.3152 (1487.4793) nleep/row_max_std 55.9565 (55.4345) nleep/row_min_mean 1448.8157 (1450.0301) lr 4.1221e-04 eta 0:04:34
epoch [37/50] batch [120/176] time 0.162 (0.114) data 0.000 (0.003) loss 1.2231 (1.3141) teacher_loss 0.2680 (0.2720) loss_zs_kd 0.0145 (0.0201) loss_oracle 0.5754 (0.6566) kd_loss 0.6601 (0.7037) acc 90.6250 (89.5833) gate/entropy 1.0161 (1.0162) gate/usage_max 0.5228 (0.5228) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1379 (0.1379) teacher/entropy 0.0099 (0.0189) teacher/usage_max 0.9660 (0.8837) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.4476 (0.3931) nleep/row_max_mean 1501.2134 (1487.3940) nleep/row_max_std 44.2713 (55.3970) nleep/row_min_mean 1461.5066 (1449.9663) lr 4.1221e-04 eta 0:04:28
epoch [37/50] batch [140/176] time 0.100 (0.114) data 0.000 (0.003) loss 1.2824 (1.3155) teacher_loss 0.2591 (0.2746) loss_zs_kd 0.0256 (0.0206) loss_oracle 0.6839 (0.6560) kd_loss 0.6685 (0.7026) acc 87.5000 (89.3750) gate/entropy 1.0162 (1.0162) gate/usage_max 0.5226 (0.5228) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1378 (0.1379) teacher/entropy 0.0000 (0.0180) teacher/usage_max 0.9687 (0.8870) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.4495 (0.3952) nleep/row_max_mean 1493.4685 (1487.8736) nleep/row_max_std 34.9866 (55.0290) nleep/row_min_mean 1455.0955 (1450.4692) lr 4.1221e-04 eta 0:04:26
epoch [37/50] batch [160/176] time 0.096 (0.116) data 0.000 (0.002) loss 1.1379 (1.3123) teacher_loss 0.1743 (0.2711) loss_zs_kd 0.0331 (0.0207) loss_oracle 0.6008 (0.6552) kd_loss 0.6467 (0.7033) acc 93.7500 (89.4922) gate/entropy 1.0160 (1.0162) gate/usage_max 0.5229 (0.5228) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1380 (0.1379) teacher/entropy 0.0512 (0.0190) teacher/usage_max 0.9214 (0.8841) teacher/usage_min 0.0003 (0.0024) teacher/usage_std 0.4171 (0.3933) nleep/row_max_mean 1490.4465 (1487.4012) nleep/row_max_std 54.3152 (55.4714) nleep/row_min_mean 1453.3523 (1450.1274) lr 4.1221e-04 eta 0:04:27
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,176
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,772
* accuracy: 66.7%
* error: 33.3%
* macro_f1: 58.9%
******* Domain l best val acc:      90.1%, epoch: 31 *******
******* Domain l best val test acc: 65.2%, epoch: 31 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [38/50] batch [20/176] time 0.159 (0.156) data 0.000 (0.016) loss 1.3141 (1.3021) teacher_loss 0.2970 (0.2816) loss_zs_kd 0.0276 (0.0190) loss_oracle 0.5991 (0.6327) kd_loss 0.7038 (0.6947) acc 87.5000 (89.3750) gate/entropy 1.0159 (1.0160) gate/usage_max 0.5232 (0.5231) gate/usage_min 0.1987 (0.1986) gate/usage_std 0.1381 (0.1380) teacher/entropy 0.0313 (0.0146) teacher/usage_max 0.8621 (0.9046) teacher/usage_min 0.0001 (0.0031) teacher/usage_std 0.3781 (0.4061) nleep/row_max_mean 1477.7185 (1485.7879) nleep/row_max_std 58.6199 (52.9913) nleep/row_min_mean 1442.3386 (1448.8679) lr 3.6258e-04 eta 0:05:52
epoch [38/50] batch [40/176] time 0.144 (0.150) data 0.000 (0.008) loss 1.2338 (1.3110) teacher_loss 0.2108 (0.2738) loss_zs_kd 0.0051 (0.0195) loss_oracle 0.6281 (0.6546) kd_loss 0.7064 (0.7002) acc 96.8750 (89.7656) gate/entropy 1.0159 (1.0160) gate/usage_max 0.5231 (0.5231) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1381 (0.1381) teacher/entropy 0.0007 (0.0151) teacher/usage_max 0.9062 (0.8947) teacher/usage_min 0.0001 (0.0024) teacher/usage_std 0.4069 (0.3999) nleep/row_max_mean 1484.7791 (1484.0275) nleep/row_max_std 57.3616 (54.9864) nleep/row_min_mean 1450.1414 (1447.4040) lr 3.6258e-04 eta 0:05:36
epoch [38/50] batch [60/176] time 0.137 (0.145) data 0.000 (0.005) loss 1.3425 (1.2843) teacher_loss 0.3133 (0.2541) loss_zs_kd 0.0393 (0.0189) loss_oracle 0.7323 (0.6451) kd_loss 0.6434 (0.6982) acc 87.5000 (90.5208) gate/entropy 1.0159 (1.0160) gate/usage_max 0.5233 (0.5231) gate/usage_min 0.1987 (0.1986) gate/usage_std 0.1381 (0.1381) teacher/entropy 0.0633 (0.0183) teacher/usage_max 0.9071 (0.8925) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.4075 (0.3984) nleep/row_max_mean 1481.6943 (1484.1605) nleep/row_max_std 49.9069 (55.5724) nleep/row_min_mean 1446.0963 (1447.3996) lr 3.6258e-04 eta 0:05:22
epoch [38/50] batch [80/176] time 0.142 (0.142) data 0.000 (0.004) loss 1.2912 (1.2909) teacher_loss 0.2090 (0.2582) loss_zs_kd 0.0300 (0.0189) loss_oracle 0.6920 (0.6415) kd_loss 0.7212 (0.7024) acc 90.6250 (90.0781) gate/entropy 1.0159 (1.0159) gate/usage_max 0.5232 (0.5231) gate/usage_min 0.1986 (0.1986) gate/usage_std 0.1381 (0.1381) teacher/entropy 0.0471 (0.0163) teacher/usage_max 0.8093 (0.8888) teacher/usage_min 0.0001 (0.0022) teacher/usage_std 0.3454 (0.3961) nleep/row_max_mean 1477.8730 (1484.8093) nleep/row_max_std 59.3898 (55.5742) nleep/row_min_mean 1442.5654 (1448.1079) lr 3.6258e-04 eta 0:05:12
epoch [38/50] batch [100/176] time 0.147 (0.139) data 0.000 (0.003) loss 1.4817 (1.2986) teacher_loss 0.2652 (0.2663) loss_zs_kd 0.0255 (0.0195) loss_oracle 0.8037 (0.6365) kd_loss 0.8019 (0.7044) acc 87.5000 (89.8125) gate/entropy 1.0159 (1.0159) gate/usage_max 0.5231 (0.5232) gate/usage_min 0.1987 (0.1986) gate/usage_std 0.1381 (0.1381) teacher/entropy 0.0189 (0.0170) teacher/usage_max 0.7271 (0.8846) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.2999 (0.3935) nleep/row_max_mean 1463.9733 (1484.3134) nleep/row_max_std 62.6933 (55.1103) nleep/row_min_mean 1430.1064 (1447.7480) lr 3.6258e-04 eta 0:05:05
epoch [38/50] batch [120/176] time 0.142 (0.138) data 0.000 (0.003) loss 1.4537 (1.2874) teacher_loss 0.4437 (0.2596) loss_zs_kd 0.0159 (0.0194) loss_oracle 0.6197 (0.6316) kd_loss 0.6922 (0.7022) acc 81.2500 (90.1562) gate/entropy 1.0158 (1.0159) gate/usage_max 0.5234 (0.5232) gate/usage_min 0.1986 (0.1987) gate/usage_std 0.1382 (0.1381) teacher/entropy 0.0449 (0.0177) teacher/usage_max 0.8602 (0.8868) teacher/usage_min 0.0039 (0.0021) teacher/usage_std 0.3764 (0.3949) nleep/row_max_mean 1485.2484 (1485.1204) nleep/row_max_std 58.2040 (54.4257) nleep/row_min_mean 1451.1642 (1448.4171) lr 3.6258e-04 eta 0:04:59
epoch [38/50] batch [140/176] time 0.066 (0.137) data 0.000 (0.002) loss 1.3699 (1.2854) teacher_loss 0.2677 (0.2600) loss_zs_kd 0.0134 (0.0194) loss_oracle 0.6212 (0.6279) kd_loss 0.7849 (0.7017) acc 90.6250 (90.0446) gate/entropy 1.0157 (1.0159) gate/usage_max 0.5235 (0.5232) gate/usage_min 0.1987 (0.1987) gate/usage_std 0.1383 (0.1381) teacher/entropy 0.0010 (0.0170) teacher/usage_max 0.7812 (0.8887) teacher/usage_min 0.0001 (0.0020) teacher/usage_std 0.3290 (0.3962) nleep/row_max_mean 1477.0840 (1486.0573) nleep/row_max_std 65.1114 (53.9501) nleep/row_min_mean 1442.3103 (1449.1350) lr 3.6258e-04 eta 0:04:54
epoch [38/50] batch [160/176] time 0.119 (0.133) data 0.000 (0.002) loss 1.5862 (1.2893) teacher_loss 0.5307 (0.2650) loss_zs_kd 0.0310 (0.0193) loss_oracle 0.7063 (0.6287) kd_loss 0.6869 (0.7003) acc 78.1250 (90.0195) gate/entropy 1.0157 (1.0159) gate/usage_max 0.5236 (0.5233) gate/usage_min 0.1987 (0.1987) gate/usage_std 0.1383 (0.1382) teacher/entropy 0.0164 (0.0175) teacher/usage_max 0.9118 (0.8900) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.4106 (0.3969) nleep/row_max_mean 1493.6771 (1486.4797) nleep/row_max_std 39.1622 (53.6518) nleep/row_min_mean 1455.8303 (1449.5341) lr 3.6258e-04 eta 0:04:42
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,179
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,739
* accuracy: 65.5%
* error: 34.5%
* macro_f1: 58.3%
******* Domain l best val acc:      90.1%, epoch: 31 *******
******* Domain l best val test acc: 65.2%, epoch: 31 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [39/50] batch [20/176] time 0.186 (0.100) data 0.000 (0.012) loss 1.2963 (1.2466) teacher_loss 0.2778 (0.2544) loss_zs_kd 0.0293 (0.0209) loss_oracle 0.6581 (0.6166) kd_loss 0.6748 (0.6734) acc 90.6250 (91.4062) gate/entropy 1.0155 (1.0156) gate/usage_max 0.5238 (0.5237) gate/usage_min 0.1987 (0.1988) gate/usage_std 0.1385 (0.1384) teacher/entropy 0.0189 (0.0164) teacher/usage_max 0.9375 (0.9332) teacher/usage_min 0.0222 (0.0019) teacher/usage_std 0.4273 (0.4252) nleep/row_max_mean 1504.4900 (1496.3811) nleep/row_max_std 54.5822 (49.0170) nleep/row_min_mean 1462.3672 (1456.9861) lr 3.1545e-04 eta 0:03:29
epoch [39/50] batch [40/176] time 0.139 (0.100) data 0.000 (0.006) loss 1.1780 (1.2668) teacher_loss 0.0911 (0.2610) loss_zs_kd 0.0143 (0.0193) loss_oracle 0.7188 (0.6235) kd_loss 0.7203 (0.6845) acc 100.0000 (90.3906) gate/entropy 1.0156 (1.0156) gate/usage_max 0.5238 (0.5238) gate/usage_min 0.1988 (0.1988) gate/usage_std 0.1385 (0.1384) teacher/entropy 0.0070 (0.0191) teacher/usage_max 0.8735 (0.9118) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.3854 (0.4109) nleep/row_max_mean 1485.3976 (1493.1386) nleep/row_max_std 50.6810 (51.9462) nleep/row_min_mean 1447.0125 (1454.4148) lr 3.1545e-04 eta 0:03:27
epoch [39/50] batch [60/176] time 0.094 (0.105) data 0.001 (0.004) loss 1.2597 (1.2669) teacher_loss 0.2330 (0.2558) loss_zs_kd 0.0116 (0.0202) loss_oracle 0.6322 (0.6238) kd_loss 0.7048 (0.6891) acc 90.6250 (90.8854) gate/entropy 1.0154 (1.0156) gate/usage_max 0.5241 (0.5238) gate/usage_min 0.1988 (0.1988) gate/usage_std 0.1386 (0.1385) teacher/entropy 0.0190 (0.0186) teacher/usage_max 0.8773 (0.9052) teacher/usage_min 0.0004 (0.0027) teacher/usage_std 0.3878 (0.4066) nleep/row_max_mean 1500.6204 (1492.0518) nleep/row_max_std 56.4686 (52.4864) nleep/row_min_mean 1462.7842 (1453.6487) lr 3.1545e-04 eta 0:03:34
epoch [39/50] batch [80/176] time 0.188 (0.107) data 0.000 (0.003) loss 1.0993 (1.2854) teacher_loss 0.1503 (0.2745) loss_zs_kd 0.0183 (0.0205) loss_oracle 0.5874 (0.6211) kd_loss 0.6462 (0.6901) acc 93.7500 (89.9219) gate/entropy 1.0154 (1.0155) gate/usage_max 0.5241 (0.5239) gate/usage_min 0.1988 (0.1988) gate/usage_std 0.1386 (0.1385) teacher/entropy 0.0288 (0.0179) teacher/usage_max 0.9550 (0.9044) teacher/usage_min 0.0003 (0.0024) teacher/usage_std 0.4399 (0.4061) nleep/row_max_mean 1497.6870 (1491.8100) nleep/row_max_std 48.2777 (52.2755) nleep/row_min_mean 1459.0315 (1453.6026) lr 3.1545e-04 eta 0:03:37
epoch [39/50] batch [100/176] time 0.089 (0.107) data 0.000 (0.003) loss 1.1714 (1.2849) teacher_loss 0.1362 (0.2705) loss_zs_kd 0.0105 (0.0206) loss_oracle 0.5964 (0.6257) kd_loss 0.7318 (0.6912) acc 93.7500 (89.8750) gate/entropy 1.0154 (1.0155) gate/usage_max 0.5241 (0.5239) gate/usage_min 0.1989 (0.1988) gate/usage_std 0.1386 (0.1385) teacher/entropy 0.0168 (0.0191) teacher/usage_max 0.8387 (0.9008) teacher/usage_min 0.0001 (0.0025) teacher/usage_std 0.3633 (0.4038) nleep/row_max_mean 1481.3516 (1491.5831) nleep/row_max_std 62.9731 (52.1346) nleep/row_min_mean 1444.9026 (1453.3798) lr 3.1545e-04 eta 0:03:36
epoch [39/50] batch [120/176] time 0.127 (0.111) data 0.000 (0.002) loss 1.2845 (1.2837) teacher_loss 0.2024 (0.2668) loss_zs_kd 0.0112 (0.0202) loss_oracle 0.7107 (0.6317) kd_loss 0.7212 (0.6910) acc 93.7500 (89.9740) gate/entropy 1.0153 (1.0155) gate/usage_max 0.5243 (0.5239) gate/usage_min 0.1989 (0.1988) gate/usage_std 0.1387 (0.1385) teacher/entropy 0.0037 (0.0190) teacher/usage_max 0.8758 (0.9011) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.3869 (0.4040) nleep/row_max_mean 1491.8159 (1491.7584) nleep/row_max_std 57.9356 (51.8247) nleep/row_min_mean 1453.3470 (1453.5094) lr 3.1545e-04 eta 0:03:41
epoch [39/50] batch [140/176] time 0.146 (0.115) data 0.000 (0.002) loss 1.4975 (1.2891) teacher_loss 0.3621 (0.2694) loss_zs_kd 0.0330 (0.0201) loss_oracle 0.7678 (0.6358) kd_loss 0.7350 (0.6918) acc 84.3750 (89.9554) gate/entropy 1.0154 (1.0155) gate/usage_max 0.5241 (0.5240) gate/usage_min 0.1988 (0.1988) gate/usage_std 0.1386 (0.1386) teacher/entropy 0.0126 (0.0191) teacher/usage_max 0.8403 (0.8996) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.3643 (0.4030) nleep/row_max_mean 1482.8324 (1491.1818) nleep/row_max_std 64.9469 (52.0073) nleep/row_min_mean 1446.9102 (1453.0991) lr 3.1545e-04 eta 0:03:46
epoch [39/50] batch [160/176] time 0.133 (0.118) data 0.000 (0.002) loss 1.2496 (1.2902) teacher_loss 0.2942 (0.2700) loss_zs_kd 0.0190 (0.0201) loss_oracle 0.5209 (0.6339) kd_loss 0.6854 (0.6932) acc 87.5000 (89.9023) gate/entropy 1.0153 (1.0154) gate/usage_max 0.5242 (0.5240) gate/usage_min 0.1989 (0.1988) gate/usage_std 0.1387 (0.1386) teacher/entropy 0.0166 (0.0195) teacher/usage_max 0.9117 (0.8968) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.4105 (0.4011) nleep/row_max_mean 1501.1317 (1490.7766) nleep/row_max_std 51.4098 (52.4527) nleep/row_min_mean 1461.5696 (1452.8053) lr 3.1545e-04 eta 0:03:50
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,175
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,740
* accuracy: 65.5%
* error: 34.5%
* macro_f1: 58.7%
******* Domain l best val acc:      90.1%, epoch: 31 *******
******* Domain l best val test acc: 65.2%, epoch: 31 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [40/50] batch [20/176] time 0.148 (0.162) data 0.000 (0.020) loss 1.0831 (1.2685) teacher_loss 0.1200 (0.2700) loss_zs_kd 0.0144 (0.0176) loss_oracle 0.6441 (0.6198) kd_loss 0.6339 (0.6798) acc 96.8750 (88.9062) gate/entropy 1.0154 (1.0153) gate/usage_max 0.5241 (0.5243) gate/usage_min 0.1989 (0.1989) gate/usage_std 0.1386 (0.1387) teacher/entropy 0.0220 (0.0159) teacher/usage_max 0.9846 (0.9225) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.4605 (0.4180) nleep/row_max_mean 1499.0668 (1489.6065) nleep/row_max_std 37.5241 (51.1184) nleep/row_min_mean 1458.2213 (1452.0517) lr 2.7103e-04 eta 0:05:09
epoch [40/50] batch [40/176] time 0.144 (0.149) data 0.000 (0.010) loss 1.1967 (1.2918) teacher_loss 0.2649 (0.2797) loss_zs_kd 0.0176 (0.0197) loss_oracle 0.5196 (0.6261) kd_loss 0.6631 (0.6892) acc 87.5000 (88.5156) gate/entropy 1.0150 (1.0152) gate/usage_max 0.5247 (0.5244) gate/usage_min 0.1989 (0.1989) gate/usage_std 0.1390 (0.1388) teacher/entropy 0.0201 (0.0162) teacher/usage_max 0.9404 (0.9070) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.4299 (0.4078) nleep/row_max_mean 1506.0345 (1488.5744) nleep/row_max_std 50.9029 (53.0109) nleep/row_min_mean 1465.4574 (1450.8863) lr 2.7103e-04 eta 0:04:41
epoch [40/50] batch [60/176] time 0.094 (0.135) data 0.001 (0.007) loss 1.3363 (1.3064) teacher_loss 0.2531 (0.2945) loss_zs_kd 0.0188 (0.0199) loss_oracle 0.7091 (0.6244) kd_loss 0.7193 (0.6897) acc 84.3750 (88.4375) gate/entropy 1.0151 (1.0152) gate/usage_max 0.5246 (0.5244) gate/usage_min 0.1989 (0.1989) gate/usage_std 0.1389 (0.1388) teacher/entropy 0.0065 (0.0166) teacher/usage_max 0.8735 (0.9053) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.3855 (0.4067) nleep/row_max_mean 1477.3599 (1487.9532) nleep/row_max_std 70.6389 (53.7497) nleep/row_min_mean 1441.6196 (1450.5098) lr 2.7103e-04 eta 0:04:13
epoch [40/50] batch [80/176] time 0.076 (0.128) data 0.000 (0.005) loss 1.2266 (1.3033) teacher_loss 0.1719 (0.2899) loss_zs_kd 0.0122 (0.0196) loss_oracle 0.7284 (0.6277) kd_loss 0.6844 (0.6897) acc 96.8750 (88.6328) gate/entropy 1.0152 (1.0152) gate/usage_max 0.5244 (0.5244) gate/usage_min 0.1989 (0.1989) gate/usage_std 0.1388 (0.1388) teacher/entropy 0.0008 (0.0166) teacher/usage_max 0.9374 (0.9052) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.4279 (0.4068) nleep/row_max_mean 1489.9392 (1487.8931) nleep/row_max_std 47.0962 (53.3805) nleep/row_min_mean 1452.2422 (1450.4947) lr 2.7103e-04 eta 0:03:57
epoch [40/50] batch [100/176] time 0.149 (0.128) data 0.000 (0.004) loss 1.2083 (1.2941) teacher_loss 0.1401 (0.2773) loss_zs_kd 0.0172 (0.0193) loss_oracle 0.6047 (0.6316) kd_loss 0.7572 (0.6914) acc 93.7500 (89.3125) gate/entropy 1.0151 (1.0152) gate/usage_max 0.5246 (0.5245) gate/usage_min 0.1989 (0.1989) gate/usage_std 0.1389 (0.1388) teacher/entropy 0.0237 (0.0180) teacher/usage_max 0.7872 (0.9007) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.3324 (0.4039) nleep/row_max_mean 1477.9683 (1487.2917) nleep/row_max_std 66.7667 (54.1078) nleep/row_min_mean 1442.6162 (1450.0946) lr 2.7103e-04 eta 0:03:55
epoch [40/50] batch [120/176] time 0.078 (0.125) data 0.000 (0.004) loss 1.1485 (1.2912) teacher_loss 0.1838 (0.2721) loss_zs_kd 0.0188 (0.0188) loss_oracle 0.5352 (0.6341) kd_loss 0.6877 (0.6926) acc 90.6250 (89.4271) gate/entropy 1.0149 (1.0152) gate/usage_max 0.5249 (0.5245) gate/usage_min 0.1990 (0.1989) gate/usage_std 0.1391 (0.1388) teacher/entropy 0.0343 (0.0192) teacher/usage_max 0.8796 (0.8967) teacher/usage_min 0.0001 (0.0016) teacher/usage_std 0.3894 (0.4012) nleep/row_max_mean 1498.4319 (1486.7200) nleep/row_max_std 58.1612 (54.6603) nleep/row_min_mean 1458.6497 (1449.7035) lr 2.7103e-04 eta 0:03:46
epoch [40/50] batch [140/176] time 0.076 (0.121) data 0.000 (0.003) loss 1.3973 (1.2867) teacher_loss 0.3554 (0.2695) loss_zs_kd 0.0158 (0.0190) loss_oracle 0.6888 (0.6319) kd_loss 0.6896 (0.6917) acc 84.3750 (89.6875) gate/entropy 1.0149 (1.0151) gate/usage_max 0.5249 (0.5245) gate/usage_min 0.1990 (0.1989) gate/usage_std 0.1391 (0.1389) teacher/entropy 0.0050 (0.0186) teacher/usage_max 0.9373 (0.8992) teacher/usage_min 0.0305 (0.0022) teacher/usage_std 0.4271 (0.4028) nleep/row_max_mean 1494.3726 (1487.4155) nleep/row_max_std 50.0333 (54.3392) nleep/row_min_mean 1455.7161 (1450.2463) lr 2.7103e-04 eta 0:03:37
epoch [40/50] batch [160/176] time 0.154 (0.117) data 0.000 (0.003) loss 1.2284 (1.2902) teacher_loss 0.2434 (0.2716) loss_zs_kd 0.0170 (0.0190) loss_oracle 0.6839 (0.6353) kd_loss 0.6345 (0.6915) acc 90.6250 (89.5703) gate/entropy 1.0149 (1.0151) gate/usage_max 0.5250 (0.5246) gate/usage_min 0.1990 (0.1989) gate/usage_std 0.1391 (0.1389) teacher/entropy 0.0123 (0.0186) teacher/usage_max 0.9963 (0.8998) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.4688 (0.4032) nleep/row_max_mean 1499.4958 (1487.5759) nleep/row_max_std 41.7098 (54.3254) nleep/row_min_mean 1462.4839 (1450.3379) lr 2.7103e-04 eta 0:03:27
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,180
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,749
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 59.2%
******* Domain l best val acc:      90.1%, epoch: 31 *******
******* Domain l best val test acc: 65.2%, epoch: 31 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [41/50] batch [20/176] time 0.136 (0.165) data 0.000 (0.016) loss 1.5027 (1.2583) teacher_loss 0.4836 (0.2473) loss_zs_kd 0.0289 (0.0181) loss_oracle 0.6216 (0.6218) kd_loss 0.6939 (0.6911) acc 84.3750 (90.4688) gate/entropy 1.0148 (1.0149) gate/usage_max 0.5251 (0.5249) gate/usage_min 0.1990 (0.1990) gate/usage_std 0.1392 (0.1391) teacher/entropy 0.0130 (0.0283) teacher/usage_max 0.9026 (0.8870) teacher/usage_min 0.0001 (0.0071) teacher/usage_std 0.4045 (0.3940) nleep/row_max_mean 1487.7792 (1484.2708) nleep/row_max_std 51.8405 (60.3719) nleep/row_min_mean 1451.2874 (1447.7559) lr 2.2949e-04 eta 0:04:47
epoch [41/50] batch [40/176] time 0.184 (0.153) data 0.001 (0.008) loss 1.3940 (1.2635) teacher_loss 0.2796 (0.2435) loss_zs_kd 0.0262 (0.0192) loss_oracle 0.6495 (0.6277) kd_loss 0.7766 (0.6965) acc 87.5000 (90.0781) gate/entropy 1.0148 (1.0149) gate/usage_max 0.5251 (0.5249) gate/usage_min 0.1990 (0.1990) gate/usage_std 0.1392 (0.1391) teacher/entropy 0.0073 (0.0223) teacher/usage_max 0.7826 (0.8870) teacher/usage_min 0.0002 (0.0052) teacher/usage_std 0.3298 (0.3946) nleep/row_max_mean 1467.3184 (1485.2934) nleep/row_max_std 71.2496 (59.1610) nleep/row_min_mean 1432.4124 (1448.3556) lr 2.2949e-04 eta 0:04:22
epoch [41/50] batch [60/176] time 0.151 (0.146) data 0.001 (0.006) loss 1.3333 (1.2651) teacher_loss 0.3199 (0.2464) loss_zs_kd 0.0227 (0.0192) loss_oracle 0.6356 (0.6278) kd_loss 0.6842 (0.6951) acc 90.6250 (89.9479) gate/entropy 1.0149 (1.0149) gate/usage_max 0.5250 (0.5250) gate/usage_min 0.1990 (0.1990) gate/usage_std 0.1391 (0.1391) teacher/entropy 0.0001 (0.0212) teacher/usage_max 0.9375 (0.8904) teacher/usage_min 0.0000 (0.0045) teacher/usage_std 0.4280 (0.3969) nleep/row_max_mean 1496.3241 (1485.7409) nleep/row_max_std 51.7782 (58.1547) nleep/row_min_mean 1458.2397 (1448.8540) lr 2.2949e-04 eta 0:04:08
epoch [41/50] batch [80/176] time 0.148 (0.145) data 0.000 (0.004) loss 1.2771 (1.2706) teacher_loss 0.2454 (0.2545) loss_zs_kd 0.0088 (0.0192) loss_oracle 0.6979 (0.6309) kd_loss 0.6783 (0.6910) acc 84.3750 (89.9609) gate/entropy 1.0150 (1.0149) gate/usage_max 0.5248 (0.5250) gate/usage_min 0.1991 (0.1990) gate/usage_std 0.1390 (0.1391) teacher/entropy 0.0505 (0.0223) teacher/usage_max 0.8691 (0.8949) teacher/usage_min 0.0000 (0.0040) teacher/usage_std 0.3826 (0.3999) nleep/row_max_mean 1467.3578 (1486.0586) nleep/row_max_std 58.7268 (57.5910) nleep/row_min_mean 1434.0696 (1449.2812) lr 2.2949e-04 eta 0:04:04
epoch [41/50] batch [100/176] time 0.152 (0.144) data 0.000 (0.003) loss 1.2341 (1.2727) teacher_loss 0.2112 (0.2547) loss_zs_kd 0.0089 (0.0191) loss_oracle 0.6462 (0.6339) kd_loss 0.6954 (0.6915) acc 87.5000 (89.9688) gate/entropy 1.0147 (1.0149) gate/usage_max 0.5252 (0.5250) gate/usage_min 0.1990 (0.1990) gate/usage_std 0.1392 (0.1391) teacher/entropy 0.0479 (0.0214) teacher/usage_max 0.8471 (0.8954) teacher/usage_min 0.0025 (0.0037) teacher/usage_std 0.3682 (0.4003) nleep/row_max_mean 1479.6125 (1486.0739) nleep/row_max_std 63.6555 (57.5862) nleep/row_min_mean 1444.3420 (1449.3484) lr 2.2949e-04 eta 0:03:59
epoch [41/50] batch [120/176] time 0.136 (0.143) data 0.000 (0.003) loss 1.1274 (1.2772) teacher_loss 0.1916 (0.2606) loss_zs_kd 0.0196 (0.0188) loss_oracle 0.5459 (0.6334) kd_loss 0.6531 (0.6905) acc 96.8750 (89.7135) gate/entropy 1.0147 (1.0149) gate/usage_max 0.5253 (0.5250) gate/usage_min 0.1990 (0.1990) gate/usage_std 0.1393 (0.1391) teacher/entropy 0.0326 (0.0220) teacher/usage_max 0.9350 (0.8957) teacher/usage_min 0.0000 (0.0036) teacher/usage_std 0.4263 (0.4004) nleep/row_max_mean 1504.8490 (1485.8282) nleep/row_max_std 46.7117 (57.5764) nleep/row_min_mean 1464.7341 (1449.1379) lr 2.2949e-04 eta 0:03:54
epoch [41/50] batch [140/176] time 0.152 (0.142) data 0.000 (0.003) loss 1.1015 (1.2754) teacher_loss 0.1405 (0.2616) loss_zs_kd 0.0228 (0.0185) loss_oracle 0.5604 (0.6302) kd_loss 0.6694 (0.6893) acc 93.7500 (89.7768) gate/entropy 1.0147 (1.0149) gate/usage_max 0.5253 (0.5250) gate/usage_min 0.1991 (0.1990) gate/usage_std 0.1393 (0.1391) teacher/entropy 0.0168 (0.0217) teacher/usage_max 0.9362 (0.8980) teacher/usage_min 0.0036 (0.0037) teacher/usage_std 0.4269 (0.4020) nleep/row_max_mean 1490.3156 (1485.9497) nleep/row_max_std 52.9313 (57.2529) nleep/row_min_mean 1449.9950 (1449.1853) lr 2.2949e-04 eta 0:03:50
epoch [41/50] batch [160/176] time 0.152 (0.142) data 0.000 (0.002) loss 1.3222 (1.2840) teacher_loss 0.2928 (0.2673) loss_zs_kd 0.0232 (0.0183) loss_oracle 0.5524 (0.6329) kd_loss 0.7417 (0.6911) acc 81.2500 (89.4727) gate/entropy 1.0148 (1.0148) gate/usage_max 0.5252 (0.5251) gate/usage_min 0.1990 (0.1990) gate/usage_std 0.1392 (0.1392) teacher/entropy 0.0026 (0.0219) teacher/usage_max 0.8441 (0.8949) teacher/usage_min 0.0000 (0.0035) teacher/usage_std 0.3668 (0.4000) nleep/row_max_mean 1480.2209 (1485.2775) nleep/row_max_std 61.4054 (57.6940) nleep/row_min_mean 1443.4954 (1448.5521) lr 2.2949e-04 eta 0:03:46
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,186
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 91.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,751
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 59.2%
******* Domain l best val acc:      90.3%, epoch: 41 *******
******* Domain l best val test acc: 65.9%, epoch: 41 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [42/50] batch [20/176] time 0.098 (0.121) data 0.000 (0.015) loss 1.3216 (1.2511) teacher_loss 0.2686 (0.2446) loss_zs_kd 0.0204 (0.0198) loss_oracle 0.7034 (0.6242) kd_loss 0.6911 (0.6845) acc 90.6250 (91.2500) gate/entropy 1.0146 (1.0147) gate/usage_max 0.5255 (0.5253) gate/usage_min 0.1991 (0.1991) gate/usage_std 0.1394 (0.1393) teacher/entropy 0.0228 (0.0154) teacher/usage_max 0.8910 (0.9127) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.3969 (0.4118) nleep/row_max_mean 1477.0842 (1487.6892) nleep/row_max_std 54.6855 (55.3714) nleep/row_min_mean 1443.1689 (1450.9073) lr 1.9098e-04 eta 0:03:09
epoch [42/50] batch [40/176] time 0.077 (0.116) data 0.000 (0.008) loss 1.1056 (1.2376) teacher_loss 0.1573 (0.2267) loss_zs_kd 0.0111 (0.0190) loss_oracle 0.5426 (0.6259) kd_loss 0.6715 (0.6884) acc 96.8750 (91.4062) gate/entropy 1.0145 (1.0147) gate/usage_max 0.5256 (0.5254) gate/usage_min 0.1992 (0.1991) gate/usage_std 0.1395 (0.1393) teacher/entropy 0.0108 (0.0223) teacher/usage_max 0.9396 (0.8974) teacher/usage_min 0.0006 (0.0029) teacher/usage_std 0.4294 (0.4016) nleep/row_max_mean 1501.3306 (1485.9518) nleep/row_max_std 47.1445 (55.8492) nleep/row_min_mean 1460.9928 (1449.3042) lr 1.9098e-04 eta 0:02:58
epoch [42/50] batch [60/176] time 0.150 (0.115) data 0.001 (0.005) loss 1.3476 (1.2655) teacher_loss 0.4096 (0.2492) loss_zs_kd 0.0094 (0.0188) loss_oracle 0.5083 (0.6327) kd_loss 0.6792 (0.6906) acc 84.3750 (90.5208) gate/entropy 1.0144 (1.0147) gate/usage_max 0.5257 (0.5254) gate/usage_min 0.1991 (0.1991) gate/usage_std 0.1396 (0.1393) teacher/entropy 0.0042 (0.0219) teacher/usage_max 0.9375 (0.8950) teacher/usage_min 0.0009 (0.0036) teacher/usage_std 0.4279 (0.3998) nleep/row_max_mean 1506.1741 (1486.1652) nleep/row_max_std 46.1750 (54.6272) nleep/row_min_mean 1464.9529 (1449.6655) lr 1.9098e-04 eta 0:02:54
epoch [42/50] batch [80/176] time 0.165 (0.118) data 0.000 (0.004) loss 1.0988 (1.2609) teacher_loss 0.0937 (0.2456) loss_zs_kd 0.0111 (0.0193) loss_oracle 0.6488 (0.6332) kd_loss 0.6751 (0.6890) acc 100.0000 (90.5859) gate/entropy 1.0146 (1.0146) gate/usage_max 0.5254 (0.5254) gate/usage_min 0.1990 (0.1991) gate/usage_std 0.1394 (0.1393) teacher/entropy 0.0107 (0.0234) teacher/usage_max 0.9341 (0.8949) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.4257 (0.3999) nleep/row_max_mean 1493.4736 (1485.9388) nleep/row_max_std 53.6295 (55.1509) nleep/row_min_mean 1454.8900 (1449.4792) lr 1.9098e-04 eta 0:02:57
epoch [42/50] batch [100/176] time 0.106 (0.116) data 0.000 (0.003) loss 1.3908 (1.2654) teacher_loss 0.3917 (0.2503) loss_zs_kd 0.0285 (0.0194) loss_oracle 0.5372 (0.6311) kd_loss 0.7162 (0.6899) acc 81.2500 (90.4688) gate/entropy 1.0145 (1.0146) gate/usage_max 0.5256 (0.5254) gate/usage_min 0.1991 (0.1991) gate/usage_std 0.1395 (0.1394) teacher/entropy 0.0076 (0.0215) teacher/usage_max 0.8759 (0.8963) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.3870 (0.4009) nleep/row_max_mean 1485.7332 (1486.1713) nleep/row_max_std 58.9327 (54.7475) nleep/row_min_mean 1450.5107 (1449.7112) lr 1.9098e-04 eta 0:02:52
epoch [42/50] batch [120/176] time 0.140 (0.119) data 0.000 (0.003) loss 1.3380 (1.2625) teacher_loss 0.3331 (0.2481) loss_zs_kd 0.0187 (0.0195) loss_oracle 0.6424 (0.6311) kd_loss 0.6743 (0.6891) acc 81.2500 (90.4167) gate/entropy 1.0144 (1.0146) gate/usage_max 0.5258 (0.5255) gate/usage_min 0.1991 (0.1991) gate/usage_std 0.1396 (0.1394) teacher/entropy 0.0220 (0.0211) teacher/usage_max 0.9179 (0.8980) teacher/usage_min 0.0002 (0.0026) teacher/usage_std 0.4147 (0.4019) nleep/row_max_mean 1486.5159 (1486.2687) nleep/row_max_std 51.4688 (54.3951) nleep/row_min_mean 1453.1956 (1449.7229) lr 1.9098e-04 eta 0:02:54
epoch [42/50] batch [140/176] time 0.133 (0.122) data 0.000 (0.002) loss 1.3181 (1.2783) teacher_loss 0.3068 (0.2588) loss_zs_kd 0.0291 (0.0197) loss_oracle 0.5990 (0.6381) kd_loss 0.6973 (0.6906) acc 87.5000 (90.1116) gate/entropy 1.0145 (1.0146) gate/usage_max 0.5257 (0.5255) gate/usage_min 0.1992 (0.1991) gate/usage_std 0.1395 (0.1394) teacher/entropy 0.0199 (0.0206) teacher/usage_max 0.8854 (0.8963) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.3931 (0.4009) nleep/row_max_mean 1488.7161 (1486.0446) nleep/row_max_std 57.3161 (54.4822) nleep/row_min_mean 1451.4146 (1449.5763) lr 1.9098e-04 eta 0:02:55
epoch [42/50] batch [160/176] time 0.135 (0.125) data 0.000 (0.002) loss 1.2497 (1.2768) teacher_loss 0.2226 (0.2574) loss_zs_kd 0.0303 (0.0198) loss_oracle 0.6806 (0.6363) kd_loss 0.6717 (0.6913) acc 87.5000 (90.1758) gate/entropy 1.0147 (1.0146) gate/usage_max 0.5254 (0.5255) gate/usage_min 0.1992 (0.1991) gate/usage_std 0.1393 (0.1394) teacher/entropy 0.0174 (0.0199) teacher/usage_max 0.9299 (0.8962) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.4228 (0.4008) nleep/row_max_mean 1479.8884 (1486.5056) nleep/row_max_std 51.9422 (54.5563) nleep/row_min_mean 1443.5618 (1449.9584) lr 1.9098e-04 eta 0:02:57
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,185
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,733
* accuracy: 65.2%
* error: 34.8%
* macro_f1: 58.3%
******* Domain l best val acc:      90.3%, epoch: 41 *******
******* Domain l best val test acc: 65.9%, epoch: 41 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [43/50] batch [20/176] time 0.182 (0.167) data 0.000 (0.017) loss 1.1936 (1.2804) teacher_loss 0.2015 (0.2614) loss_zs_kd 0.0049 (0.0210) loss_oracle 0.6133 (0.6269) kd_loss 0.6830 (0.6950) acc 96.8750 (89.6875) gate/entropy 1.0144 (1.0144) gate/usage_max 0.5258 (0.5258) gate/usage_min 0.1992 (0.1992) gate/usage_std 0.1396 (0.1396) teacher/entropy 0.0003 (0.0176) teacher/usage_max 0.9375 (0.8925) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4280 (0.3985) nleep/row_max_mean 1492.8013 (1490.1000) nleep/row_max_std 44.4101 (53.6522) nleep/row_min_mean 1451.3325 (1453.3392) lr 1.5567e-04 eta 0:03:52
epoch [43/50] batch [40/176] time 0.116 (0.158) data 0.000 (0.008) loss 1.2199 (1.2604) teacher_loss 0.1136 (0.2395) loss_zs_kd 0.0073 (0.0198) loss_oracle 0.6735 (0.6327) kd_loss 0.7660 (0.6947) acc 96.8750 (90.0781) gate/entropy 1.0145 (1.0144) gate/usage_max 0.5257 (0.5258) gate/usage_min 0.1992 (0.1992) gate/usage_std 0.1395 (0.1396) teacher/entropy 0.0191 (0.0188) teacher/usage_max 0.7800 (0.8922) teacher/usage_min 0.0001 (0.0023) teacher/usage_std 0.3283 (0.3983) nleep/row_max_mean 1473.3174 (1489.0645) nleep/row_max_std 73.8430 (53.2825) nleep/row_min_mean 1438.3003 (1452.2011) lr 1.5567e-04 eta 0:03:36
epoch [43/50] batch [60/176] time 0.126 (0.141) data 0.001 (0.006) loss 1.3996 (1.2678) teacher_loss 0.3668 (0.2485) loss_zs_kd 0.0204 (0.0193) loss_oracle 0.7188 (0.6343) kd_loss 0.6631 (0.6925) acc 81.2500 (89.8438) gate/entropy 1.0142 (1.0144) gate/usage_max 0.5261 (0.5258) gate/usage_min 0.1991 (0.1992) gate/usage_std 0.1397 (0.1396) teacher/entropy 0.0544 (0.0204) teacher/usage_max 0.8954 (0.8937) teacher/usage_min 0.0225 (0.0039) teacher/usage_std 0.3982 (0.3990) nleep/row_max_mean 1495.2354 (1489.3129) nleep/row_max_std 51.6515 (53.9629) nleep/row_min_mean 1463.2319 (1452.6601) lr 1.5567e-04 eta 0:03:09
epoch [43/50] batch [80/176] time 0.177 (0.134) data 0.000 (0.004) loss 1.1820 (1.2708) teacher_loss 0.1537 (0.2493) loss_zs_kd 0.0110 (0.0190) loss_oracle 0.6073 (0.6358) kd_loss 0.7191 (0.6940) acc 93.7500 (89.8047) gate/entropy 1.0145 (1.0144) gate/usage_max 0.5257 (0.5258) gate/usage_min 0.1992 (0.1992) gate/usage_std 0.1395 (0.1396) teacher/entropy 0.0373 (0.0196) teacher/usage_max 0.8244 (0.8923) teacher/usage_min 0.0004 (0.0034) teacher/usage_std 0.3545 (0.3981) nleep/row_max_mean 1470.1021 (1489.2218) nleep/row_max_std 61.7314 (54.2266) nleep/row_min_mean 1436.4761 (1452.5737) lr 1.5567e-04 eta 0:02:57
epoch [43/50] batch [100/176] time 0.077 (0.130) data 0.000 (0.004) loss 1.1729 (1.2737) teacher_loss 0.1322 (0.2520) loss_zs_kd 0.0200 (0.0194) loss_oracle 0.6872 (0.6362) kd_loss 0.6871 (0.6939) acc 96.8750 (90.0000) gate/entropy 1.0144 (1.0144) gate/usage_max 0.5258 (0.5258) gate/usage_min 0.1992 (0.1992) gate/usage_std 0.1396 (0.1396) teacher/entropy 0.0140 (0.0211) teacher/usage_max 0.9093 (0.8908) teacher/usage_min 0.0000 (0.0046) teacher/usage_std 0.4090 (0.3970) nleep/row_max_mean 1497.4751 (1489.2477) nleep/row_max_std 51.6309 (54.2725) nleep/row_min_mean 1459.9475 (1452.6761) lr 1.5567e-04 eta 0:02:50
epoch [43/50] batch [120/176] time 0.093 (0.128) data 0.000 (0.003) loss 1.2665 (1.2825) teacher_loss 0.2667 (0.2590) loss_zs_kd 0.0217 (0.0199) loss_oracle 0.5842 (0.6370) kd_loss 0.6969 (0.6950) acc 87.5000 (89.7396) gate/entropy 1.0144 (1.0144) gate/usage_max 0.5258 (0.5258) gate/usage_min 0.1992 (0.1992) gate/usage_std 0.1396 (0.1396) teacher/entropy 0.0288 (0.0219) teacher/usage_max 0.8872 (0.8877) teacher/usage_min 0.0309 (0.0047) teacher/usage_std 0.3922 (0.3950) nleep/row_max_mean 1487.1901 (1489.2205) nleep/row_max_std 53.2432 (53.8043) nleep/row_min_mean 1450.1586 (1452.7524) lr 1.5567e-04 eta 0:02:44
epoch [43/50] batch [140/176] time 0.142 (0.124) data 0.000 (0.003) loss 1.4130 (1.2829) teacher_loss 0.4019 (0.2597) loss_zs_kd 0.0303 (0.0202) loss_oracle 0.6623 (0.6378) kd_loss 0.6647 (0.6942) acc 84.3750 (89.7321) gate/entropy 1.0143 (1.0144) gate/usage_max 0.5261 (0.5259) gate/usage_min 0.1993 (0.1992) gate/usage_std 0.1397 (0.1396) teacher/entropy 0.0146 (0.0218) teacher/usage_max 0.9430 (0.8890) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.4317 (0.3958) nleep/row_max_mean 1495.1451 (1489.5801) nleep/row_max_std 40.0849 (53.3812) nleep/row_min_mean 1455.1787 (1453.0924) lr 1.5567e-04 eta 0:02:36
epoch [43/50] batch [160/176] time 0.157 (0.123) data 0.000 (0.002) loss 1.1973 (1.2859) teacher_loss 0.2513 (0.2655) loss_zs_kd 0.0268 (0.0203) loss_oracle 0.5949 (0.6342) kd_loss 0.6351 (0.6932) acc 93.7500 (89.6680) gate/entropy 1.0142 (1.0144) gate/usage_max 0.5261 (0.5259) gate/usage_min 0.1992 (0.1992) gate/usage_std 0.1397 (0.1396) teacher/entropy 0.0381 (0.0208) teacher/usage_max 0.9523 (0.8922) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.4381 (0.3979) nleep/row_max_mean 1490.2090 (1489.7813) nleep/row_max_std 45.8911 (53.0599) nleep/row_min_mean 1453.5026 (1453.2420) lr 1.5567e-04 eta 0:02:33
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,185
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,749
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 58.9%
******* Domain l best val acc:      90.3%, epoch: 41 *******
******* Domain l best val test acc: 65.9%, epoch: 41 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [44/50] batch [20/176] time 0.133 (0.157) data 0.001 (0.014) loss 1.2770 (1.2486) teacher_loss 0.2943 (0.2274) loss_zs_kd 0.0205 (0.0183) loss_oracle 0.5989 (0.6396) kd_loss 0.6729 (0.6923) acc 90.6250 (91.5625) gate/entropy 1.0143 (1.0143) gate/usage_max 0.5260 (0.5260) gate/usage_min 0.1992 (0.1992) gate/usage_std 0.1397 (0.1397) teacher/entropy 0.0417 (0.0255) teacher/usage_max 0.8912 (0.8856) teacher/usage_min 0.0054 (0.0031) teacher/usage_std 0.3965 (0.3943) nleep/row_max_mean 1490.9628 (1488.2505) nleep/row_max_std 55.3595 (53.2248) nleep/row_min_mean 1452.8915 (1451.8729) lr 1.2369e-04 eta 0:03:10
epoch [44/50] batch [40/176] time 0.124 (0.146) data 0.000 (0.007) loss 1.3596 (1.2628) teacher_loss 0.2826 (0.2441) loss_zs_kd 0.0177 (0.0200) loss_oracle 0.7239 (0.6396) kd_loss 0.7062 (0.6889) acc 93.7500 (90.2344) gate/entropy 1.0143 (1.0143) gate/usage_max 0.5260 (0.5261) gate/usage_min 0.1992 (0.1992) gate/usage_std 0.1397 (0.1397) teacher/entropy 0.0218 (0.0233) teacher/usage_max 0.8686 (0.8939) teacher/usage_min 0.0006 (0.0027) teacher/usage_std 0.3822 (0.3994) nleep/row_max_mean 1479.4185 (1489.4191) nleep/row_max_std 60.6578 (51.7349) nleep/row_min_mean 1447.7139 (1453.2336) lr 1.2369e-04 eta 0:02:54
epoch [44/50] batch [60/176] time 0.144 (0.142) data 0.001 (0.005) loss 1.2599 (1.2646) teacher_loss 0.2506 (0.2478) loss_zs_kd 0.0063 (0.0191) loss_oracle 0.6338 (0.6346) kd_loss 0.6892 (0.6899) acc 84.3750 (89.8438) gate/entropy 1.0142 (1.0143) gate/usage_max 0.5262 (0.5261) gate/usage_min 0.1993 (0.1992) gate/usage_std 0.1398 (0.1397) teacher/entropy 0.0364 (0.0228) teacher/usage_max 0.8787 (0.8940) teacher/usage_min 0.0154 (0.0045) teacher/usage_std 0.3874 (0.3992) nleep/row_max_mean 1483.5144 (1488.5096) nleep/row_max_std 59.1179 (52.6189) nleep/row_min_mean 1448.1101 (1452.3698) lr 1.2369e-04 eta 0:02:46
epoch [44/50] batch [80/176] time 0.131 (0.139) data 0.000 (0.004) loss 1.2739 (1.2592) teacher_loss 0.3169 (0.2460) loss_zs_kd 0.0310 (0.0198) loss_oracle 0.5509 (0.6260) kd_loss 0.6660 (0.6903) acc 87.5000 (90.3906) gate/entropy 1.0141 (1.0142) gate/usage_max 0.5263 (0.5261) gate/usage_min 0.1992 (0.1992) gate/usage_std 0.1399 (0.1398) teacher/entropy 0.0286 (0.0218) teacher/usage_max 0.9189 (0.8948) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.4154 (0.3998) nleep/row_max_mean 1498.6782 (1489.8810) nleep/row_max_std 55.7651 (53.3014) nleep/row_min_mean 1461.4412 (1453.4841) lr 1.2369e-04 eta 0:02:40
epoch [44/50] batch [100/176] time 0.144 (0.139) data 0.000 (0.003) loss 1.1533 (1.2664) teacher_loss 0.1668 (0.2512) loss_zs_kd 0.0171 (0.0199) loss_oracle 0.6154 (0.6273) kd_loss 0.6702 (0.6916) acc 93.7500 (90.2188) gate/entropy 1.0141 (1.0142) gate/usage_max 0.5264 (0.5261) gate/usage_min 0.1993 (0.1992) gate/usage_std 0.1399 (0.1398) teacher/entropy 0.0102 (0.0202) teacher/usage_max 0.9404 (0.8950) teacher/usage_min 0.0001 (0.0043) teacher/usage_std 0.4299 (0.4000) nleep/row_max_mean 1497.1016 (1489.7671) nleep/row_max_std 42.3002 (53.5748) nleep/row_min_mean 1457.9255 (1453.3090) lr 1.2369e-04 eta 0:02:37
epoch [44/50] batch [120/176] time 0.131 (0.139) data 0.000 (0.003) loss 1.1925 (1.2799) teacher_loss 0.1639 (0.2600) loss_zs_kd 0.0257 (0.0201) loss_oracle 0.5765 (0.6312) kd_loss 0.7274 (0.6942) acc 96.8750 (90.0000) gate/entropy 1.0140 (1.0142) gate/usage_max 0.5264 (0.5261) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1399 (0.1398) teacher/entropy 0.0158 (0.0206) teacher/usage_max 0.8456 (0.8902) teacher/usage_min 0.0024 (0.0038) teacher/usage_std 0.3673 (0.3968) nleep/row_max_mean 1492.8826 (1488.7158) nleep/row_max_std 54.9280 (54.2272) nleep/row_min_mean 1458.3572 (1452.5398) lr 1.2369e-04 eta 0:02:35
epoch [44/50] batch [140/176] time 0.149 (0.139) data 0.000 (0.002) loss 1.2094 (1.2831) teacher_loss 0.1376 (0.2644) loss_zs_kd 0.0196 (0.0196) loss_oracle 0.6427 (0.6298) kd_loss 0.7406 (0.6939) acc 93.7500 (89.7321) gate/entropy 1.0141 (1.0142) gate/usage_max 0.5263 (0.5262) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1398 (0.1398) teacher/entropy 0.0024 (0.0203) teacher/usage_max 0.8437 (0.8912) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.3665 (0.3974) nleep/row_max_mean 1491.2388 (1488.9870) nleep/row_max_std 61.6630 (54.0913) nleep/row_min_mean 1456.6558 (1452.8653) lr 1.2369e-04 eta 0:02:31
epoch [44/50] batch [160/176] time 0.088 (0.136) data 0.000 (0.002) loss 1.0354 (1.2806) teacher_loss 0.0812 (0.2648) loss_zs_kd 0.0494 (0.0196) loss_oracle 0.4633 (0.6254) kd_loss 0.6978 (0.6932) acc 100.0000 (89.7070) gate/entropy 1.0142 (1.0142) gate/usage_max 0.5262 (0.5262) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1398 (0.1398) teacher/entropy 0.0140 (0.0193) teacher/usage_max 0.9063 (0.8936) teacher/usage_min 0.0263 (0.0042) teacher/usage_std 0.4055 (0.3990) nleep/row_max_mean 1484.7258 (1489.4607) nleep/row_max_std 56.1130 (53.9011) nleep/row_min_mean 1448.3960 (1453.2268) lr 1.2369e-04 eta 0:02:26
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,188
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 91.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,749
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 58.6%
******* Domain l best val acc:      90.3%, epoch: 44 *******
******* Domain l best val test acc: 65.9%, epoch: 44 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [45/50] batch [20/176] time 0.107 (0.116) data 0.000 (0.015) loss 1.2454 (1.3013) teacher_loss 0.2614 (0.2717) loss_zs_kd 0.0292 (0.0219) loss_oracle 0.5965 (0.6370) kd_loss 0.6711 (0.7001) acc 90.6250 (88.9062) gate/entropy 1.0139 (1.0141) gate/usage_max 0.5266 (0.5264) gate/usage_min 0.1992 (0.1993) gate/usage_std 0.1400 (0.1399) teacher/entropy 0.0138 (0.0188) teacher/usage_max 0.9331 (0.8817) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4250 (0.3914) nleep/row_max_mean 1498.4625 (1486.5733) nleep/row_max_std 56.2977 (57.9714) nleep/row_min_mean 1458.1044 (1450.5992) lr 9.5173e-05 eta 0:02:00
epoch [45/50] batch [40/176] time 0.172 (0.110) data 0.000 (0.007) loss 1.2671 (1.3021) teacher_loss 0.2183 (0.2712) loss_zs_kd 0.0349 (0.0197) loss_oracle 0.6172 (0.6436) kd_loss 0.7227 (0.6992) acc 87.5000 (89.6094) gate/entropy 1.0141 (1.0141) gate/usage_max 0.5264 (0.5263) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1399 (0.1399) teacher/entropy 0.0001 (0.0181) teacher/usage_max 0.8750 (0.8857) teacher/usage_min 0.0000 (0.0036) teacher/usage_std 0.3864 (0.3936) nleep/row_max_mean 1481.9695 (1486.9424) nleep/row_max_std 60.2977 (57.0756) nleep/row_min_mean 1446.6494 (1451.1824) lr 9.5173e-05 eta 0:01:51
epoch [45/50] batch [60/176] time 0.168 (0.109) data 0.001 (0.005) loss 1.2029 (1.2993) teacher_loss 0.1915 (0.2684) loss_zs_kd 0.0183 (0.0193) loss_oracle 0.5916 (0.6504) kd_loss 0.7065 (0.6961) acc 93.7500 (89.9479) gate/entropy 1.0140 (1.0141) gate/usage_max 0.5264 (0.5263) gate/usage_min 0.1992 (0.1993) gate/usage_std 0.1399 (0.1399) teacher/entropy 0.0285 (0.0208) teacher/usage_max 0.8710 (0.8867) teacher/usage_min 0.0295 (0.0040) teacher/usage_std 0.3813 (0.3943) nleep/row_max_mean 1483.3459 (1486.3094) nleep/row_max_std 61.2805 (56.9540) nleep/row_min_mean 1447.4365 (1450.6469) lr 9.5173e-05 eta 0:01:48
epoch [45/50] batch [80/176] time 0.098 (0.110) data 0.000 (0.004) loss 1.3442 (1.3057) teacher_loss 0.3782 (0.2814) loss_zs_kd 0.0196 (0.0200) loss_oracle 0.5713 (0.6422) kd_loss 0.6707 (0.6932) acc 90.6250 (89.4531) gate/entropy 1.0142 (1.0141) gate/usage_max 0.5262 (0.5263) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1398 (0.1399) teacher/entropy 0.0337 (0.0219) teacher/usage_max 0.9043 (0.8893) teacher/usage_min 0.0003 (0.0036) teacher/usage_std 0.4056 (0.3962) nleep/row_max_mean 1476.5649 (1485.9288) nleep/row_max_std 59.0201 (56.7829) nleep/row_min_mean 1440.8259 (1450.2556) lr 9.5173e-05 eta 0:01:47
epoch [45/50] batch [100/176] time 0.075 (0.109) data 0.000 (0.003) loss 1.4475 (1.2944) teacher_loss 0.3841 (0.2745) loss_zs_kd 0.0219 (0.0195) loss_oracle 0.6401 (0.6377) kd_loss 0.7324 (0.6913) acc 87.5000 (89.6875) gate/entropy 1.0141 (1.0141) gate/usage_max 0.5264 (0.5263) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1399 (0.1399) teacher/entropy 0.0207 (0.0213) teacher/usage_max 0.8438 (0.8933) teacher/usage_min 0.0317 (0.0038) teacher/usage_std 0.3630 (0.3987) nleep/row_max_mean 1475.2633 (1485.7547) nleep/row_max_std 68.5413 (57.0796) nleep/row_min_mean 1440.9756 (1450.0957) lr 9.5173e-05 eta 0:01:44
epoch [45/50] batch [120/176] time 0.154 (0.112) data 0.000 (0.003) loss 1.1274 (1.2977) teacher_loss 0.1090 (0.2751) loss_zs_kd 0.0097 (0.0194) loss_oracle 0.6505 (0.6434) kd_loss 0.6883 (0.6912) acc 100.0000 (89.7135) gate/entropy 1.0141 (1.0141) gate/usage_max 0.5263 (0.5263) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1399 (0.1399) teacher/entropy 0.0603 (0.0222) teacher/usage_max 0.8363 (0.8921) teacher/usage_min 0.0004 (0.0040) teacher/usage_std 0.3618 (0.3979) nleep/row_max_mean 1463.0321 (1485.0713) nleep/row_max_std 72.6164 (57.0706) nleep/row_min_mean 1431.6613 (1449.6545) lr 9.5173e-05 eta 0:01:45
epoch [45/50] batch [140/176] time 0.139 (0.119) data 0.000 (0.002) loss 1.2738 (1.2947) teacher_loss 0.2805 (0.2722) loss_zs_kd 0.0101 (0.0193) loss_oracle 0.5766 (0.6420) kd_loss 0.7000 (0.6920) acc 87.5000 (89.6205) gate/entropy 1.0140 (1.0141) gate/usage_max 0.5266 (0.5264) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1400 (0.1399) teacher/entropy 0.0027 (0.0228) teacher/usage_max 0.9059 (0.8898) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.4067 (0.3966) nleep/row_max_mean 1489.4197 (1485.1026) nleep/row_max_std 63.3605 (57.3871) nleep/row_min_mean 1451.3615 (1449.7434) lr 9.5173e-05 eta 0:01:48
epoch [45/50] batch [160/176] time 0.148 (0.123) data 0.000 (0.002) loss 1.7767 (1.2977) teacher_loss 0.7395 (0.2731) loss_zs_kd 0.0135 (0.0193) loss_oracle 0.6985 (0.6426) kd_loss 0.6812 (0.6936) acc 75.0000 (89.5312) gate/entropy 1.0141 (1.0141) gate/usage_max 0.5263 (0.5264) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1399 (0.1399) teacher/entropy 0.0227 (0.0227) teacher/usage_max 0.9045 (0.8875) teacher/usage_min 0.0000 (0.0041) teacher/usage_std 0.4058 (0.3951) nleep/row_max_mean 1485.7622 (1484.7178) nleep/row_max_std 45.8392 (57.6602) nleep/row_min_mean 1449.8827 (1449.3572) lr 9.5173e-05 eta 0:01:50
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,185
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,752
* accuracy: 66.0%
* error: 34.0%
* macro_f1: 59.0%
******* Domain l best val acc:      90.3%, epoch: 44 *******
******* Domain l best val test acc: 65.9%, epoch: 44 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [46/50] batch [20/176] time 0.155 (0.159) data 0.000 (0.014) loss 1.4316 (1.2628) teacher_loss 0.3533 (0.2488) loss_zs_kd 0.0341 (0.0221) loss_oracle 0.6783 (0.6234) kd_loss 0.7221 (0.6912) acc 87.5000 (90.0000) gate/entropy 1.0142 (1.0140) gate/usage_max 0.5262 (0.5264) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1398 (0.1399) teacher/entropy 0.0017 (0.0241) teacher/usage_max 0.8749 (0.8878) teacher/usage_min 0.0002 (0.0017) teacher/usage_std 0.3863 (0.3954) nleep/row_max_mean 1470.6646 (1481.7726) nleep/row_max_std 59.6818 (61.1098) nleep/row_min_mean 1433.8395 (1446.9331) lr 7.0224e-05 eta 0:02:17
epoch [46/50] batch [40/176] time 0.161 (0.156) data 0.000 (0.007) loss 1.4431 (1.2682) teacher_loss 0.3348 (0.2465) loss_zs_kd 0.0188 (0.0204) loss_oracle 0.7380 (0.6407) kd_loss 0.7299 (0.6912) acc 84.3750 (90.3125) gate/entropy 1.0140 (1.0140) gate/usage_max 0.5264 (0.5264) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1399 (0.1399) teacher/entropy 0.0251 (0.0271) teacher/usage_max 0.8253 (0.8840) teacher/usage_min 0.0001 (0.0034) teacher/usage_std 0.3551 (0.3928) nleep/row_max_mean 1474.4077 (1481.4720) nleep/row_max_std 77.6435 (61.1516) nleep/row_min_mean 1439.2611 (1446.6570) lr 7.0224e-05 eta 0:02:10
epoch [46/50] batch [60/176] time 0.140 (0.137) data 0.001 (0.005) loss 1.4019 (1.2786) teacher_loss 0.2407 (0.2507) loss_zs_kd 0.0115 (0.0196) loss_oracle 0.7634 (0.6432) kd_loss 0.7737 (0.6965) acc 93.7500 (89.9479) gate/entropy 1.0141 (1.0140) gate/usage_max 0.5264 (0.5265) gate/usage_min 0.1992 (0.1993) gate/usage_std 0.1399 (0.1399) teacher/entropy 0.0348 (0.0246) teacher/usage_max 0.7467 (0.8803) teacher/usage_min 0.0062 (0.0039) teacher/usage_std 0.3084 (0.3904) nleep/row_max_mean 1484.5234 (1481.9199) nleep/row_max_std 75.6675 (61.2189) nleep/row_min_mean 1448.4167 (1447.0259) lr 7.0224e-05 eta 0:01:52
epoch [46/50] batch [80/176] time 0.119 (0.131) data 0.000 (0.004) loss 1.2407 (1.2691) teacher_loss 0.2083 (0.2427) loss_zs_kd 0.0332 (0.0190) loss_oracle 0.5972 (0.6427) kd_loss 0.7173 (0.6956) acc 96.8750 (90.3906) gate/entropy 1.0139 (1.0140) gate/usage_max 0.5266 (0.5264) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1399) teacher/entropy 0.0062 (0.0228) teacher/usage_max 0.8750 (0.8839) teacher/usage_min 0.0012 (0.0031) teacher/usage_std 0.3862 (0.3928) nleep/row_max_mean 1490.6980 (1482.4717) nleep/row_max_std 57.8895 (60.6388) nleep/row_min_mean 1453.3440 (1447.4837) lr 7.0224e-05 eta 0:01:45
epoch [46/50] batch [100/176] time 0.169 (0.128) data 0.000 (0.003) loss 1.0247 (1.2607) teacher_loss 0.1174 (0.2381) loss_zs_kd 0.0187 (0.0192) loss_oracle 0.4872 (0.6397) kd_loss 0.6544 (0.6931) acc 96.8750 (90.7188) gate/entropy 1.0140 (1.0140) gate/usage_max 0.5266 (0.5265) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1399) teacher/entropy 0.0087 (0.0224) teacher/usage_max 0.9668 (0.8881) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.4481 (0.3956) nleep/row_max_mean 1493.6636 (1483.2115) nleep/row_max_std 54.8492 (60.3825) nleep/row_min_mean 1455.8362 (1448.1206) lr 7.0224e-05 eta 0:01:40
epoch [46/50] batch [120/176] time 0.073 (0.125) data 0.000 (0.003) loss 1.3817 (1.2699) teacher_loss 0.3018 (0.2454) loss_zs_kd 0.0217 (0.0194) loss_oracle 0.7065 (0.6413) kd_loss 0.7159 (0.6942) acc 90.6250 (90.3906) gate/entropy 1.0142 (1.0140) gate/usage_max 0.5263 (0.5265) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1398 (0.1400) teacher/entropy 0.0072 (0.0229) teacher/usage_max 0.8748 (0.8859) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.3863 (0.3942) nleep/row_max_mean 1481.3414 (1483.8603) nleep/row_max_std 52.3491 (59.7342) nleep/row_min_mean 1446.8176 (1448.7292) lr 7.0224e-05 eta 0:01:34
epoch [46/50] batch [140/176] time 0.085 (0.121) data 0.000 (0.002) loss 1.2175 (1.2700) teacher_loss 0.1869 (0.2424) loss_zs_kd 0.0119 (0.0196) loss_oracle 0.6346 (0.6421) kd_loss 0.7073 (0.6967) acc 90.6250 (90.4911) gate/entropy 1.0142 (1.0140) gate/usage_max 0.5262 (0.5265) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1398 (0.1400) teacher/entropy 0.0176 (0.0221) teacher/usage_max 0.8730 (0.8830) teacher/usage_min 0.0006 (0.0029) teacher/usage_std 0.3851 (0.3924) nleep/row_max_mean 1482.5975 (1483.8042) nleep/row_max_std 57.2639 (59.5237) nleep/row_min_mean 1449.1036 (1448.7467) lr 7.0224e-05 eta 0:01:29
epoch [46/50] batch [160/176] time 0.095 (0.119) data 0.000 (0.002) loss 1.2754 (1.2720) teacher_loss 0.3365 (0.2459) loss_zs_kd 0.0134 (0.0197) loss_oracle 0.5423 (0.6408) kd_loss 0.6611 (0.6958) acc 87.5000 (90.2539) gate/entropy 1.0139 (1.0140) gate/usage_max 0.5266 (0.5265) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0007 (0.0224) teacher/usage_max 0.9688 (0.8839) teacher/usage_min 0.0001 (0.0030) teacher/usage_std 0.4495 (0.3930) nleep/row_max_mean 1494.1021 (1484.2000) nleep/row_max_std 44.3985 (59.0465) nleep/row_min_mean 1456.0256 (1449.1608) lr 7.0224e-05 eta 0:01:25
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,184
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,749
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 58.9%
******* Domain l best val acc:      90.3%, epoch: 44 *******
******* Domain l best val test acc: 65.9%, epoch: 44 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [47/50] batch [20/176] time 0.122 (0.156) data 0.000 (0.013) loss 1.3144 (1.3371) teacher_loss 0.2965 (0.3068) loss_zs_kd 0.0145 (0.0200) loss_oracle 0.6867 (0.6477) kd_loss 0.6673 (0.6965) acc 90.6250 (88.4375) gate/entropy 1.0140 (1.0140) gate/usage_max 0.5265 (0.5265) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0660 (0.0237) teacher/usage_max 0.8603 (0.8811) teacher/usage_min 0.0017 (0.0040) teacher/usage_std 0.3768 (0.3907) nleep/row_max_mean 1477.8838 (1482.3230) nleep/row_max_std 60.6033 (57.2774) nleep/row_min_mean 1445.0736 (1447.6874) lr 4.8943e-05 eta 0:01:46
epoch [47/50] batch [40/176] time 0.145 (0.148) data 0.000 (0.007) loss 1.2784 (1.3260) teacher_loss 0.3085 (0.3096) loss_zs_kd 0.0150 (0.0197) loss_oracle 0.5578 (0.6337) kd_loss 0.6835 (0.6897) acc 87.5000 (87.8125) gate/entropy 1.0141 (1.0140) gate/usage_max 0.5264 (0.5265) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1399 (0.1400) teacher/entropy 0.0244 (0.0254) teacher/usage_max 0.8982 (0.8888) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.4015 (0.3958) nleep/row_max_mean 1463.2869 (1483.7589) nleep/row_max_std 56.4948 (56.9702) nleep/row_min_mean 1433.5632 (1449.0542) lr 4.8943e-05 eta 0:01:38
epoch [47/50] batch [60/176] time 0.149 (0.147) data 0.001 (0.005) loss 1.3673 (1.3206) teacher_loss 0.2872 (0.2983) loss_zs_kd 0.0194 (0.0197) loss_oracle 0.6558 (0.6383) kd_loss 0.7425 (0.6933) acc 87.5000 (88.5417) gate/entropy 1.0140 (1.0140) gate/usage_max 0.5265 (0.5265) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0004 (0.0260) teacher/usage_max 0.8437 (0.8827) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.3665 (0.3919) nleep/row_max_mean 1478.8297 (1483.6254) nleep/row_max_std 65.8579 (58.7154) nleep/row_min_mean 1443.8635 (1448.9095) lr 4.8943e-05 eta 0:01:34
epoch [47/50] batch [80/176] time 0.144 (0.145) data 0.000 (0.003) loss 1.4819 (1.3206) teacher_loss 0.4321 (0.2981) loss_zs_kd 0.0093 (0.0187) loss_oracle 0.6642 (0.6362) kd_loss 0.7130 (0.6950) acc 81.2500 (88.7109) gate/entropy 1.0140 (1.0140) gate/usage_max 0.5265 (0.5265) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0118 (0.0241) teacher/usage_max 0.8720 (0.8834) teacher/usage_min 0.0002 (0.0052) teacher/usage_std 0.3845 (0.3923) nleep/row_max_mean 1485.6384 (1483.9086) nleep/row_max_std 68.4379 (58.7267) nleep/row_min_mean 1449.9994 (1449.0903) lr 4.8943e-05 eta 0:01:30
epoch [47/50] batch [100/176] time 0.129 (0.141) data 0.000 (0.003) loss 1.2893 (1.3009) teacher_loss 0.2711 (0.2836) loss_zs_kd 0.0196 (0.0184) loss_oracle 0.5723 (0.6316) kd_loss 0.7222 (0.6924) acc 90.6250 (89.0312) gate/entropy 1.0139 (1.0140) gate/usage_max 0.5266 (0.5265) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0006 (0.0242) teacher/usage_max 0.8749 (0.8872) teacher/usage_min 0.0000 (0.0049) teacher/usage_std 0.3864 (0.3947) nleep/row_max_mean 1485.4011 (1485.0829) nleep/row_max_std 58.1519 (58.3641) nleep/row_min_mean 1449.6329 (1450.0284) lr 4.8943e-05 eta 0:01:25
epoch [47/50] batch [120/176] time 0.122 (0.139) data 0.000 (0.002) loss 1.1491 (1.2931) teacher_loss 0.1753 (0.2746) loss_zs_kd 0.0277 (0.0186) loss_oracle 0.5900 (0.6344) kd_loss 0.6649 (0.6920) acc 96.8750 (89.4010) gate/entropy 1.0138 (1.0140) gate/usage_max 0.5268 (0.5265) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1401 (0.1400) teacher/entropy 0.0530 (0.0253) teacher/usage_max 0.8822 (0.8861) teacher/usage_min 0.0000 (0.0051) teacher/usage_std 0.3911 (0.3939) nleep/row_max_mean 1484.8535 (1484.4959) nleep/row_max_std 63.7554 (58.6899) nleep/row_min_mean 1451.6896 (1449.5311) lr 4.8943e-05 eta 0:01:21
epoch [47/50] batch [140/176] time 0.151 (0.138) data 0.000 (0.002) loss 1.1564 (1.2909) teacher_loss 0.1744 (0.2693) loss_zs_kd 0.0034 (0.0191) loss_oracle 0.6072 (0.6372) kd_loss 0.6767 (0.6935) acc 96.8750 (89.6429) gate/entropy 1.0139 (1.0140) gate/usage_max 0.5266 (0.5265) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0385 (0.0245) teacher/usage_max 0.8865 (0.8849) teacher/usage_min 0.0003 (0.0046) teacher/usage_std 0.3939 (0.3932) nleep/row_max_mean 1482.4520 (1484.2866) nleep/row_max_std 62.4885 (59.1798) nleep/row_min_mean 1448.1232 (1449.3535) lr 4.8943e-05 eta 0:01:17
epoch [47/50] batch [160/176] time 0.123 (0.137) data 0.000 (0.002) loss 1.2498 (1.2873) teacher_loss 0.1929 (0.2669) loss_zs_kd 0.0074 (0.0190) loss_oracle 0.6213 (0.6343) kd_loss 0.7426 (0.6937) acc 96.8750 (89.8438) gate/entropy 1.0141 (1.0140) gate/usage_max 0.5264 (0.5265) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1399 (0.1400) teacher/entropy 0.0007 (0.0242) teacher/usage_max 0.8438 (0.8848) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.3666 (0.3932) nleep/row_max_mean 1475.5120 (1484.0058) nleep/row_max_std 62.6705 (59.4480) nleep/row_min_mean 1440.0588 (1449.0885) lr 4.8943e-05 eta 0:01:14
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,188
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,746
* accuracy: 65.7%
* error: 34.3%
* macro_f1: 58.9%
******* Domain l best val acc:      90.3%, epoch: 44 *******
******* Domain l best val test acc: 65.9%, epoch: 44 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [48/50] batch [20/176] time 0.090 (0.134) data 0.000 (0.022) loss 1.2397 (1.2754) teacher_loss 0.2776 (0.2639) loss_zs_kd 0.0103 (0.0193) loss_oracle 0.6071 (0.6219) kd_loss 0.6533 (0.6909) acc 84.3750 (89.8438) gate/entropy 1.0140 (1.0139) gate/usage_max 0.5265 (0.5266) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1399 (0.1400) teacher/entropy 0.0426 (0.0200) teacher/usage_max 0.9164 (0.8945) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.4137 (0.3997) nleep/row_max_mean 1480.8220 (1488.4869) nleep/row_max_std 57.3698 (55.6186) nleep/row_min_mean 1445.9763 (1452.3979) lr 3.1417e-05 eta 0:01:08
epoch [48/50] batch [40/176] time 0.088 (0.114) data 0.000 (0.011) loss 1.2703 (1.2913) teacher_loss 0.2060 (0.2761) loss_zs_kd 0.0277 (0.0195) loss_oracle 0.6981 (0.6341) kd_loss 0.7014 (0.6884) acc 93.7500 (89.5312) gate/entropy 1.0140 (1.0139) gate/usage_max 0.5266 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0013 (0.0225) teacher/usage_max 0.9061 (0.8948) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.4068 (0.3997) nleep/row_max_mean 1483.2117 (1488.3699) nleep/row_max_std 48.5904 (55.9766) nleep/row_min_mean 1449.2622 (1452.6147) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [60/176] time 0.082 (0.109) data 0.001 (0.007) loss 1.3897 (1.2861) teacher_loss 0.4442 (0.2703) loss_zs_kd 0.0303 (0.0203) loss_oracle 0.5634 (0.6343) kd_loss 0.6487 (0.6885) acc 81.2500 (89.6354) gate/entropy 1.0139 (1.0139) gate/usage_max 0.5267 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1401 (0.1400) teacher/entropy 0.0205 (0.0222) teacher/usage_max 0.9605 (0.8957) teacher/usage_min 0.0076 (0.0042) teacher/usage_std 0.4436 (0.4003) nleep/row_max_mean 1504.4856 (1488.3719) nleep/row_max_std 43.0002 (55.1556) nleep/row_min_mean 1467.8279 (1452.7395) lr 3.1417e-05 eta 0:00:51
epoch [48/50] batch [80/176] time 0.144 (0.109) data 0.000 (0.006) loss 1.1099 (1.2878) teacher_loss 0.1956 (0.2724) loss_zs_kd 0.0092 (0.0203) loss_oracle 0.5074 (0.6350) kd_loss 0.6560 (0.6877) acc 90.6250 (89.8047) gate/entropy 1.0139 (1.0139) gate/usage_max 0.5266 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0512 (0.0240) teacher/usage_max 0.8996 (0.8939) teacher/usage_min 0.0003 (0.0037) teacher/usage_std 0.4025 (0.3990) nleep/row_max_mean 1483.6375 (1488.1688) nleep/row_max_std 60.4111 (55.4527) nleep/row_min_mean 1446.8884 (1452.6420) lr 3.1417e-05 eta 0:00:48
epoch [48/50] batch [100/176] time 0.065 (0.109) data 0.000 (0.005) loss 1.2585 (1.2891) teacher_loss 0.2893 (0.2719) loss_zs_kd 0.0216 (0.0197) loss_oracle 0.5845 (0.6344) kd_loss 0.6662 (0.6902) acc 90.6250 (89.6562) gate/entropy 1.0139 (1.0139) gate/usage_max 0.5266 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0147 (0.0253) teacher/usage_max 0.9394 (0.8883) teacher/usage_min 0.0000 (0.0043) teacher/usage_std 0.4293 (0.3953) nleep/row_max_mean 1497.1829 (1487.1899) nleep/row_max_std 36.9416 (56.2049) nleep/row_min_mean 1462.8340 (1451.9517) lr 3.1417e-05 eta 0:00:46
epoch [48/50] batch [120/176] time 0.135 (0.109) data 0.000 (0.004) loss 1.2836 (1.2904) teacher_loss 0.2816 (0.2735) loss_zs_kd 0.0092 (0.0193) loss_oracle 0.6527 (0.6340) kd_loss 0.6711 (0.6903) acc 84.3750 (89.4531) gate/entropy 1.0140 (1.0139) gate/usage_max 0.5265 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0128 (0.0253) teacher/usage_max 0.9352 (0.8882) teacher/usage_min 0.0004 (0.0042) teacher/usage_std 0.4264 (0.3953) nleep/row_max_mean 1496.4197 (1487.0707) nleep/row_max_std 46.9993 (56.3059) nleep/row_min_mean 1459.7585 (1451.8543) lr 3.1417e-05 eta 0:00:44
epoch [48/50] batch [140/176] time 0.148 (0.109) data 0.000 (0.003) loss 1.2686 (1.2918) teacher_loss 0.3120 (0.2739) loss_zs_kd 0.0120 (0.0190) loss_oracle 0.5503 (0.6340) kd_loss 0.6754 (0.6914) acc 93.7500 (89.5089) gate/entropy 1.0139 (1.0139) gate/usage_max 0.5267 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1401 (0.1400) teacher/entropy 0.0074 (0.0251) teacher/usage_max 0.9367 (0.8866) teacher/usage_min 0.0000 (0.0041) teacher/usage_std 0.4274 (0.3944) nleep/row_max_mean 1481.6653 (1487.0022) nleep/row_max_std 53.2299 (56.2919) nleep/row_min_mean 1447.6558 (1451.7835) lr 3.1417e-05 eta 0:00:42
epoch [48/50] batch [160/176] time 0.150 (0.113) data 0.000 (0.003) loss 1.3792 (1.2948) teacher_loss 0.2969 (0.2734) loss_zs_kd 0.0203 (0.0188) loss_oracle 0.7027 (0.6383) kd_loss 0.7208 (0.6928) acc 84.3750 (89.4141) gate/entropy 1.0139 (1.0139) gate/usage_max 0.5267 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1401 (0.1400) teacher/entropy 0.0372 (0.0252) teacher/usage_max 0.8212 (0.8842) teacher/usage_min 0.0003 (0.0039) teacher/usage_std 0.3526 (0.3928) nleep/row_max_mean 1490.4111 (1486.4933) nleep/row_max_std 63.3996 (56.5255) nleep/row_min_mean 1455.4481 (1451.4338) lr 3.1417e-05 eta 0:00:41
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,187
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,745
* accuracy: 65.7%
* error: 34.3%
* macro_f1: 58.8%
******* Domain l best val acc:      90.3%, epoch: 44 *******
******* Domain l best val test acc: 65.9%, epoch: 44 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [49/50] batch [20/176] time 0.143 (0.151) data 0.000 (0.014) loss 1.1947 (1.2326) teacher_loss 0.2089 (0.2152) loss_zs_kd 0.0116 (0.0153) loss_oracle 0.6305 (0.6370) kd_loss 0.6648 (0.6912) acc 90.6250 (91.4062) gate/entropy 1.0138 (1.0140) gate/usage_max 0.5268 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1402 (0.1400) teacher/entropy 0.0192 (0.0295) teacher/usage_max 0.9340 (0.8818) teacher/usage_min 0.0000 (0.0071) teacher/usage_std 0.4256 (0.3909) nleep/row_max_mean 1502.9749 (1484.2241) nleep/row_max_std 49.0800 (56.8251) nleep/row_min_mean 1468.2979 (1450.1973) lr 1.7713e-05 eta 0:00:49
epoch [49/50] batch [40/176] time 0.136 (0.141) data 0.000 (0.007) loss 1.3624 (1.2474) teacher_loss 0.2836 (0.2293) loss_zs_kd 0.0194 (0.0183) loss_oracle 0.6979 (0.6376) kd_loss 0.7202 (0.6901) acc 87.5000 (90.6250) gate/entropy 1.0139 (1.0140) gate/usage_max 0.5267 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1401 (0.1400) teacher/entropy 0.0028 (0.0253) teacher/usage_max 0.8747 (0.8887) teacher/usage_min 0.0001 (0.0049) teacher/usage_std 0.3862 (0.3958) nleep/row_max_mean 1483.8281 (1485.9791) nleep/row_max_std 65.4662 (56.4975) nleep/row_min_mean 1449.3256 (1451.3214) lr 1.7713e-05 eta 0:00:44
epoch [49/50] batch [60/176] time 0.126 (0.138) data 0.000 (0.005) loss 1.4380 (1.2665) teacher_loss 0.3763 (0.2430) loss_zs_kd 0.0145 (0.0194) loss_oracle 0.6684 (0.6415) kd_loss 0.7203 (0.6930) acc 84.3750 (90.2083) gate/entropy 1.0139 (1.0140) gate/usage_max 0.5266 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0022 (0.0247) teacher/usage_max 0.8751 (0.8855) teacher/usage_min 0.0001 (0.0053) teacher/usage_std 0.3865 (0.3937) nleep/row_max_mean 1486.7340 (1485.8527) nleep/row_max_std 52.0227 (55.6349) nleep/row_min_mean 1451.5162 (1451.0830) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [80/176] time 0.139 (0.137) data 0.000 (0.003) loss 1.3120 (1.2726) teacher_loss 0.2288 (0.2450) loss_zs_kd 0.0055 (0.0198) loss_oracle 0.7399 (0.6441) kd_loss 0.7105 (0.6958) acc 90.6250 (90.3516) gate/entropy 1.0141 (1.0139) gate/usage_max 0.5264 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1399 (0.1400) teacher/entropy 0.0174 (0.0254) teacher/usage_max 0.8681 (0.8802) teacher/usage_min 0.0000 (0.0055) teacher/usage_std 0.3819 (0.3905) nleep/row_max_mean 1489.3225 (1485.3062) nleep/row_max_std 53.5944 (55.7751) nleep/row_min_mean 1454.3665 (1450.6379) lr 1.7713e-05 eta 0:00:37
epoch [49/50] batch [100/176] time 0.098 (0.128) data 0.000 (0.003) loss 1.0968 (1.2682) teacher_loss 0.0796 (0.2407) loss_zs_kd 0.0179 (0.0204) loss_oracle 0.6123 (0.6422) kd_loss 0.7020 (0.6961) acc 100.0000 (90.4062) gate/entropy 1.0140 (1.0139) gate/usage_max 0.5266 (0.5266) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0165 (0.0236) teacher/usage_max 0.8810 (0.8824) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.3903 (0.3918) nleep/row_max_mean 1492.0061 (1486.2847) nleep/row_max_std 55.8988 (55.3502) nleep/row_min_mean 1454.7742 (1451.3318) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [120/176] time 0.089 (0.124) data 0.000 (0.002) loss 1.2383 (1.2768) teacher_loss 0.1995 (0.2471) loss_zs_kd 0.0240 (0.0205) loss_oracle 0.6106 (0.6449) kd_loss 0.7215 (0.6970) acc 93.7500 (90.3385) gate/entropy 1.0139 (1.0139) gate/usage_max 0.5267 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1401 (0.1400) teacher/entropy 0.0013 (0.0230) teacher/usage_max 0.8752 (0.8817) teacher/usage_min 0.0000 (0.0046) teacher/usage_std 0.3865 (0.3913) nleep/row_max_mean 1485.0024 (1486.5146) nleep/row_max_std 47.4167 (55.2004) nleep/row_min_mean 1448.5730 (1451.5134) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [140/176] time 0.089 (0.122) data 0.000 (0.002) loss 1.4180 (1.2826) teacher_loss 0.3011 (0.2508) loss_zs_kd 0.0205 (0.0205) loss_oracle 0.6520 (0.6467) kd_loss 0.7807 (0.6982) acc 90.6250 (90.2455) gate/entropy 1.0137 (1.0139) gate/usage_max 0.5269 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1402 (0.1400) teacher/entropy 0.0024 (0.0227) teacher/usage_max 0.7812 (0.8802) teacher/usage_min 0.0003 (0.0046) teacher/usage_std 0.3290 (0.3904) nleep/row_max_mean 1482.7915 (1486.0265) nleep/row_max_std 71.1617 (55.3508) nleep/row_min_mean 1448.7800 (1451.0457) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [160/176] time 0.175 (0.122) data 0.000 (0.002) loss 1.2119 (1.2777) teacher_loss 0.1953 (0.2506) loss_zs_kd 0.0127 (0.0203) loss_oracle 0.6178 (0.6416) kd_loss 0.7013 (0.6961) acc 93.7500 (90.1562) gate/entropy 1.0138 (1.0139) gate/usage_max 0.5268 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1401 (0.1400) teacher/entropy 0.0013 (0.0229) teacher/usage_max 0.9061 (0.8829) teacher/usage_min 0.0002 (0.0042) teacher/usage_std 0.4068 (0.3921) nleep/row_max_mean 1496.8125 (1486.5947) nleep/row_max_std 54.4774 (55.0382) nleep/row_min_mean 1458.0933 (1451.4363) lr 1.7713e-05 eta 0:00:23
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,183
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,746
* accuracy: 65.7%
* error: 34.3%
* macro_f1: 58.9%
******* Domain l best val acc:      90.3%, epoch: 44 *******
******* Domain l best val test acc: 65.9%, epoch: 44 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
epoch [50/50] batch [20/176] time 0.077 (0.140) data 0.000 (0.017) loss 1.2199 (1.2519) teacher_loss 0.1762 (0.2210) loss_zs_kd 0.0156 (0.0180) loss_oracle 0.6855 (0.6495) kd_loss 0.6931 (0.6972) acc 93.7500 (92.0312) gate/entropy 1.0139 (1.0139) gate/usage_max 0.5267 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1401 (0.1400) teacher/entropy 0.0221 (0.0239) teacher/usage_max 0.8862 (0.8789) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.3937 (0.3896) nleep/row_max_mean 1497.2527 (1486.5089) nleep/row_max_std 54.5031 (56.1583) nleep/row_min_mean 1460.5730 (1451.4994) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [40/176] time 0.143 (0.123) data 0.000 (0.009) loss 1.3434 (1.2656) teacher_loss 0.3602 (0.2370) loss_zs_kd 0.0226 (0.0189) loss_oracle 0.5729 (0.6388) kd_loss 0.6855 (0.6998) acc 87.5000 (90.7031) gate/entropy 1.0139 (1.0139) gate/usage_max 0.5267 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1401 (0.1400) teacher/entropy 0.0205 (0.0229) teacher/usage_max 0.9062 (0.8768) teacher/usage_min 0.0113 (0.0033) teacher/usage_std 0.4062 (0.3883) nleep/row_max_mean 1498.0149 (1485.8240) nleep/row_max_std 51.8907 (56.9230) nleep/row_min_mean 1461.3656 (1450.5429) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [60/176] time 0.159 (0.127) data 0.001 (0.006) loss 1.2843 (1.2632) teacher_loss 0.1784 (0.2349) loss_zs_kd 0.0263 (0.0190) loss_oracle 0.6958 (0.6386) kd_loss 0.7449 (0.6995) acc 93.7500 (90.7812) gate/entropy 1.0140 (1.0139) gate/usage_max 0.5266 (0.5266) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0093 (0.0204) teacher/usage_max 0.8432 (0.8816) teacher/usage_min 0.0324 (0.0045) teacher/usage_std 0.3625 (0.3913) nleep/row_max_mean 1472.1379 (1486.5618) nleep/row_max_std 60.6315 (55.5871) nleep/row_min_mean 1442.1360 (1451.2443) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [80/176] time 0.157 (0.133) data 0.000 (0.004) loss 1.2503 (1.2697) teacher_loss 0.1819 (0.2387) loss_zs_kd 0.0215 (0.0194) loss_oracle 0.7041 (0.6409) kd_loss 0.7056 (0.7008) acc 90.6250 (90.7812) gate/entropy 1.0140 (1.0139) gate/usage_max 0.5265 (0.5266) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0312 (0.0222) teacher/usage_max 0.8542 (0.8766) teacher/usage_min 0.0001 (0.0038) teacher/usage_std 0.3731 (0.3881) nleep/row_max_mean 1463.0168 (1485.8795) nleep/row_max_std 65.0680 (56.5120) nleep/row_min_mean 1432.1716 (1450.6897) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [100/176] time 0.142 (0.136) data 0.000 (0.004) loss 1.1932 (1.2717) teacher_loss 0.1823 (0.2410) loss_zs_kd 0.0171 (0.0196) loss_oracle 0.6049 (0.6438) kd_loss 0.6999 (0.6990) acc 90.6250 (90.6250) gate/entropy 1.0137 (1.0139) gate/usage_max 0.5270 (0.5266) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1402 (0.1400) teacher/entropy 0.0019 (0.0219) teacher/usage_max 0.9065 (0.8798) teacher/usage_min 0.0000 (0.0040) teacher/usage_std 0.4071 (0.3901) nleep/row_max_mean 1499.3099 (1485.4782) nleep/row_max_std 52.3012 (56.1317) nleep/row_min_mean 1466.3069 (1450.4528) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [120/176] time 0.164 (0.139) data 0.000 (0.003) loss 1.3345 (1.2767) teacher_loss 0.2436 (0.2483) loss_zs_kd 0.0231 (0.0202) loss_oracle 0.6754 (0.6394) kd_loss 0.7416 (0.6986) acc 90.6250 (90.2604) gate/entropy 1.0140 (1.0139) gate/usage_max 0.5264 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1399 (0.1400) teacher/entropy 0.0020 (0.0209) teacher/usage_max 0.8437 (0.8818) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.3665 (0.3914) nleep/row_max_mean 1478.9214 (1485.5066) nleep/row_max_std 57.2885 (56.0640) nleep/row_min_mean 1445.8750 (1450.5526) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [140/176] time 0.160 (0.142) data 0.000 (0.003) loss 1.1279 (1.2880) teacher_loss 0.2066 (0.2583) loss_zs_kd 0.0196 (0.0202) loss_oracle 0.5955 (0.6427) kd_loss 0.6137 (0.6982) acc 93.7500 (90.1116) gate/entropy 1.0139 (1.0139) gate/usage_max 0.5267 (0.5266) gate/usage_min 0.1994 (0.1993) gate/usage_std 0.1401 (0.1400) teacher/entropy 0.0806 (0.0233) teacher/usage_max 0.9183 (0.8791) teacher/usage_min 0.0001 (0.0044) teacher/usage_std 0.4150 (0.3895) nleep/row_max_mean 1482.6631 (1485.2939) nleep/row_max_std 56.7297 (56.2598) nleep/row_min_mean 1450.3013 (1450.4249) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [160/176] time 0.164 (0.144) data 0.000 (0.002) loss 1.4166 (1.2876) teacher_loss 0.2655 (0.2602) loss_zs_kd 0.0239 (0.0203) loss_oracle 0.7333 (0.6415) kd_loss 0.7725 (0.6964) acc 90.6250 (90.1367) gate/entropy 1.0139 (1.0139) gate/usage_max 0.5266 (0.5266) gate/usage_min 0.1993 (0.1993) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0136 (0.0236) teacher/usage_max 0.7780 (0.8814) teacher/usage_min 0.0002 (0.0042) teacher/usage_std 0.3272 (0.3910) nleep/row_max_mean 1466.0449 (1485.2714) nleep/row_max_std 74.5325 (56.1579) nleep/row_min_mean 1434.1704 (1450.4548) lr 7.8853e-06 eta 0:00:02
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,186
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,744
* accuracy: 65.7%
* error: 34.3%
* macro_f1: 58.5%
******* Domain l best val acc:      90.3%, epoch: 44 *******
******* Domain l best val test acc: 65.9%, epoch: 44 *******
******* Domain l best test acc:     69.0%, epoch: 1 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:24:24

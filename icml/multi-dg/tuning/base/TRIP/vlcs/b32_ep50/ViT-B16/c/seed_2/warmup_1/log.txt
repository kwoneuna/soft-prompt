Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------
Dataset    SPG_VLCS
Source     ['labelme', 'pascal', 'sun']
Target     ['caltech']
# classes  5
# train_x  6,519
# val      2,795
# test     1,415
---------  ----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/tensorboard)
epoch [1/50] batch [20/203] time 0.073 (0.125) data 0.000 (0.019) loss 1.5659 (1.2181) teacher_loss 1.0494 (0.7629) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0003 (0.0000) kd_loss 0.5163 (0.4551) acc 53.1250 (72.8125) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3384) gate/usage_min 0.3302 (0.3302) gate/usage_std 0.0035 (0.0036) teacher/entropy 0.5847 (0.6445) teacher/usage_max 0.4641 (0.4253) teacher/usage_min 0.2415 (0.2627) teacher/usage_std 0.0950 (0.0703) nleep/row_max_mean 1524.8871 (1516.8835) nleep/row_max_std 42.2521 (78.2769) nleep/row_min_mean 1521.2875 (1512.9797) lr 1.0000e-05 eta 0:21:01
epoch [1/50] batch [40/203] time 0.080 (0.105) data 0.000 (0.010) loss 1.1730 (1.1786) teacher_loss 0.8661 (0.7827) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0011 (0.0004) kd_loss 0.3063 (0.3956) acc 68.7500 (72.3438) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3384) gate/usage_min 0.3303 (0.3302) gate/usage_std 0.0035 (0.0036) teacher/entropy 0.7914 (0.7037) teacher/usage_max 0.3648 (0.4053) teacher/usage_min 0.3083 (0.2752) teacher/usage_std 0.0235 (0.0563) nleep/row_max_mean 1530.3811 (1512.5871) nleep/row_max_std 25.4549 (80.2555) nleep/row_min_mean 1528.0017 (1509.4495) lr 1.0000e-05 eta 0:17:45
epoch [1/50] batch [60/203] time 0.091 (0.100) data 0.001 (0.006) loss 1.6455 (1.1418) teacher_loss 1.4143 (0.7831) loss_zs_kd 0.0014 (0.0002) loss_oracle 0.0046 (0.0012) kd_loss 0.2283 (0.3580) acc 53.1250 (72.4479) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3384) gate/usage_min 0.3303 (0.3302) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.8704 (0.7411) teacher/usage_max 0.3373 (0.3943) teacher/usage_min 0.3289 (0.2815) teacher/usage_std 0.0035 (0.0487) nleep/row_max_mean 1513.2537 (1512.9513) nleep/row_max_std 40.9964 (77.0825) nleep/row_min_mean 1511.4406 (1510.1779) lr 1.0000e-05 eta 0:16:45
epoch [1/50] batch [80/203] time 0.079 (0.096) data 0.000 (0.005) loss 0.6320 (1.0918) teacher_loss 0.4713 (0.7671) loss_zs_kd 0.0003 (0.0003) loss_oracle 0.0082 (0.0023) kd_loss 0.1564 (0.3234) acc 75.0000 (72.8906) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3385 (0.3384) gate/usage_min 0.3303 (0.3302) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.9435 (0.7756) teacher/usage_max 0.3998 (0.3883) teacher/usage_min 0.2807 (0.2837) teacher/usage_std 0.0496 (0.0451) nleep/row_max_mean 1514.7979 (1512.7191) nleep/row_max_std 83.2655 (76.6227) nleep/row_min_mean 1513.4929 (1510.2207) lr 1.0000e-05 eta 0:16:06
epoch [1/50] batch [100/203] time 0.141 (0.096) data 0.000 (0.004) loss 0.8722 (1.0427) teacher_loss 0.7089 (0.7436) loss_zs_kd 0.0032 (0.0005) loss_oracle 0.0145 (0.0037) kd_loss 0.1544 (0.2970) acc 71.8750 (73.5938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3384) gate/usage_min 0.3303 (0.3302) gate/usage_std 0.0035 (0.0036) teacher/entropy 0.9448 (0.8019) teacher/usage_max 0.3744 (0.3846) teacher/usage_min 0.3094 (0.2867) teacher/usage_std 0.0292 (0.0422) nleep/row_max_mean 1525.8068 (1514.0252) nleep/row_max_std 85.6978 (74.2044) nleep/row_min_mean 1524.4492 (1511.7207) lr 1.0000e-05 eta 0:16:00
epoch [1/50] batch [120/203] time 0.095 (0.096) data 0.000 (0.003) loss 0.6082 (1.0041) teacher_loss 0.4587 (0.7312) loss_zs_kd 0.0019 (0.0006) loss_oracle 0.0116 (0.0053) kd_loss 0.1427 (0.2699) acc 81.2500 (73.9062) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3384) gate/usage_min 0.3302 (0.3303) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.9563 (0.8290) teacher/usage_max 0.3420 (0.3815) teacher/usage_min 0.3167 (0.2888) teacher/usage_std 0.0118 (0.0398) nleep/row_max_mean 1505.7700 (1514.0172) nleep/row_max_std 84.5630 (73.5933) nleep/row_min_mean 1504.5073 (1511.8975) lr 1.0000e-05 eta 0:16:04
epoch [1/50] batch [140/203] time 0.095 (0.096) data 0.000 (0.003) loss 0.7346 (0.9702) teacher_loss 0.6148 (0.7172) loss_zs_kd 0.0017 (0.0008) loss_oracle 0.0181 (0.0069) kd_loss 0.1100 (0.2491) acc 71.8750 (74.2188) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3385 (0.3384) gate/usage_min 0.3302 (0.3303) gate/usage_std 0.0037 (0.0036) teacher/entropy 0.9890 (0.8499) teacher/usage_max 0.3457 (0.3792) teacher/usage_min 0.3230 (0.2905) teacher/usage_std 0.0094 (0.0381) nleep/row_max_mean 1507.8638 (1514.2143) nleep/row_max_std 77.7193 (73.0668) nleep/row_min_mean 1506.7682 (1512.2333) lr 1.0000e-05 eta 0:15:56
epoch [1/50] batch [160/203] time 0.095 (0.096) data 0.000 (0.003) loss 0.9124 (0.9519) teacher_loss 0.8004 (0.7144) loss_zs_kd 0.0036 (0.0010) loss_oracle 0.0229 (0.0088) kd_loss 0.0987 (0.2326) acc 81.2500 (74.3359) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3384) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0036 (0.0036) teacher/entropy 1.0010 (0.8664) teacher/usage_max 0.3783 (0.3776) teacher/usage_min 0.2876 (0.2922) teacher/usage_std 0.0370 (0.0366) nleep/row_max_mean 1508.2004 (1514.2127) nleep/row_max_std 88.3261 (72.2125) nleep/row_min_mean 1507.1798 (1512.3384) lr 1.0000e-05 eta 0:15:56
epoch [1/50] batch [180/203] time 0.108 (0.096) data 0.000 (0.002) loss 0.7722 (0.9406) teacher_loss 0.6033 (0.7150) loss_zs_kd 0.0041 (0.0013) loss_oracle 0.0253 (0.0108) kd_loss 0.1543 (0.2195) acc 81.2500 (74.2361) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3384) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.9442 (0.8795) teacher/usage_max 0.3424 (0.3773) teacher/usage_min 0.3229 (0.2920) teacher/usage_std 0.0080 (0.0365) nleep/row_max_mean 1527.6342 (1513.9744) nleep/row_max_std 43.1793 (72.3551) nleep/row_min_mean 1526.2745 (1512.1834) lr 1.0000e-05 eta 0:15:56
epoch [1/50] batch [200/203] time 0.083 (0.096) data 0.000 (0.002) loss 0.8585 (0.9307) teacher_loss 0.6937 (0.7139) loss_zs_kd 0.0045 (0.0015) loss_oracle 0.0340 (0.0131) kd_loss 0.1456 (0.2095) acc 71.8750 (74.2500) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3384) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.9543 (0.8896) teacher/usage_max 0.4089 (0.3777) teacher/usage_min 0.2810 (0.2911) teacher/usage_std 0.0548 (0.0370) nleep/row_max_mean 1510.9463 (1514.2089) nleep/row_max_std 77.0207 (71.6062) nleep/row_min_mean 1509.6674 (1512.4813) lr 1.0000e-05 eta 0:15:51
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,193
* accuracy: 78.5%
* error: 21.5%
* macro_f1: 82.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      78.5%, epoch: 1 *******
******* Domain c best val test acc: 100.0%, epoch: 1 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [2/50] batch [20/203] time 0.086 (0.120) data 0.000 (0.020) loss 0.9792 (0.9416) teacher_loss 0.4050 (0.5509) loss_zs_kd 0.0323 (0.0239) loss_oracle 0.2436 (0.2156) kd_loss 0.4363 (0.2711) acc 84.3750 (82.9688) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3378 (0.3380) gate/usage_min 0.3308 (0.3306) gate/usage_std 0.0031 (0.0033) teacher/entropy 0.6607 (0.8268) teacher/usage_max 0.4252 (0.4126) teacher/usage_min 0.2533 (0.2727) teacher/usage_std 0.0707 (0.0603) nleep/row_max_mean 1518.5032 (1516.4397) nleep/row_max_std 77.8865 (72.1888) nleep/row_min_mean 1515.6465 (1514.4830) lr 2.0000e-03 eta 0:19:54
epoch [2/50] batch [40/203] time 0.092 (0.108) data 0.001 (0.010) loss 1.0113 (1.0313) teacher_loss 0.1229 (0.4290) loss_zs_kd 0.0440 (0.0374) loss_oracle 0.3572 (0.2806) kd_loss 0.6878 (0.4434) acc 100.0000 (87.9688) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3376 (0.3378) gate/usage_min 0.3308 (0.3308) gate/usage_std 0.0030 (0.0032) teacher/entropy 0.4098 (0.6539) teacher/usage_max 0.5246 (0.4533) teacher/usage_min 0.1203 (0.2160) teacher/usage_std 0.1658 (0.1008) nleep/row_max_mean 1511.8607 (1518.2194) nleep/row_max_std 85.0386 (69.6034) nleep/row_min_mean 1506.7506 (1515.0750) lr 2.0000e-03 eta 0:17:48
epoch [2/50] batch [60/203] time 0.095 (0.103) data 0.001 (0.007) loss 1.2480 (1.0959) teacher_loss 0.2426 (0.3654) loss_zs_kd 0.0543 (0.0470) loss_oracle 0.3700 (0.3060) kd_loss 0.7932 (0.5540) acc 93.7500 (90.3646) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3377 (0.3378) gate/usage_min 0.3290 (0.3305) gate/usage_std 0.0035 (0.0032) teacher/entropy 0.2995 (0.5426) teacher/usage_max 0.5004 (0.4786) teacher/usage_min 0.0592 (0.1709) teacher/usage_std 0.1954 (0.1309) nleep/row_max_mean 1529.9738 (1518.2649) nleep/row_max_std 57.4792 (69.5662) nleep/row_min_mean 1523.5500 (1514.1532) lr 2.0000e-03 eta 0:17:00
epoch [2/50] batch [80/203] time 0.101 (0.101) data 0.000 (0.005) loss 1.2629 (1.1489) teacher_loss 0.2099 (0.3508) loss_zs_kd 0.0543 (0.0482) loss_oracle 0.4398 (0.3336) kd_loss 0.8059 (0.6072) acc 93.7500 (90.7031) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3371 (0.3377) gate/usage_min 0.3272 (0.3299) gate/usage_std 0.0044 (0.0034) teacher/entropy 0.2870 (0.4887) teacher/usage_max 0.5305 (0.4989) teacher/usage_min 0.1101 (0.1509) teacher/usage_std 0.1726 (0.1478) nleep/row_max_mean 1522.6654 (1516.8307) nleep/row_max_std 62.8125 (70.8597) nleep/row_min_mean 1514.5203 (1511.9368) lr 2.0000e-03 eta 0:16:32
epoch [2/50] batch [100/203] time 0.089 (0.099) data 0.000 (0.004) loss 1.4464 (1.1720) teacher_loss 0.4688 (0.3372) loss_zs_kd 0.0382 (0.0479) loss_oracle 0.4751 (0.3552) kd_loss 0.7209 (0.6332) acc 87.5000 (91.0938) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3386 (0.3376) gate/usage_min 0.3252 (0.3292) gate/usage_std 0.0058 (0.0037) teacher/entropy 0.3707 (0.4617) teacher/usage_max 0.4633 (0.5101) teacher/usage_min 0.1405 (0.1397) teacher/usage_std 0.1391 (0.1574) nleep/row_max_mean 1491.7253 (1515.2610) nleep/row_max_std 89.3505 (72.2369) nleep/row_min_mean 1483.6812 (1509.8028) lr 2.0000e-03 eta 0:16:10
epoch [2/50] batch [120/203] time 0.091 (0.098) data 0.000 (0.004) loss 1.2368 (1.2224) teacher_loss 0.1804 (0.3434) loss_zs_kd 0.0544 (0.0488) loss_oracle 0.5014 (0.3849) kd_loss 0.7785 (0.6622) acc 96.8750 (90.8073) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3421 (0.3381) gate/usage_min 0.3229 (0.3283) gate/usage_std 0.0079 (0.0042) teacher/entropy 0.3077 (0.4312) teacher/usage_max 0.5319 (0.5266) teacher/usage_min 0.1085 (0.1290) teacher/usage_std 0.1739 (0.1682) nleep/row_max_mean 1500.3340 (1515.4146) nleep/row_max_std 79.2579 (71.6324) nleep/row_min_mean 1491.4612 (1509.3300) lr 2.0000e-03 eta 0:15:58
epoch [2/50] batch [140/203] time 0.095 (0.096) data 0.000 (0.003) loss 1.5463 (1.2606) teacher_loss 0.2632 (0.3446) loss_zs_kd 0.0619 (0.0483) loss_oracle 0.7154 (0.4125) kd_loss 0.8944 (0.6856) acc 90.6250 (90.7143) gate/entropy 1.0981 (1.0985) gate/usage_max 0.3466 (0.3390) gate/usage_min 0.3199 (0.3273) gate/usage_std 0.0109 (0.0050) teacher/entropy 0.1802 (0.4059) teacher/usage_max 0.6388 (0.5403) teacher/usage_min 0.0271 (0.1207) teacher/usage_std 0.2497 (0.1771) nleep/row_max_mean 1525.9418 (1516.1647) nleep/row_max_std 61.2418 (70.5002) nleep/row_min_mean 1513.7664 (1509.4915) lr 2.0000e-03 eta 0:15:45
epoch [2/50] batch [160/203] time 0.176 (0.096) data 0.001 (0.003) loss 1.7158 (1.2925) teacher_loss 0.4753 (0.3493) loss_zs_kd 0.0484 (0.0477) loss_oracle 0.5454 (0.4330) kd_loss 0.9436 (0.7028) acc 81.2500 (90.3711) gate/entropy 1.0977 (1.0984) gate/usage_max 0.3516 (0.3403) gate/usage_min 0.3166 (0.3262) gate/usage_std 0.0143 (0.0059) teacher/entropy 0.1160 (0.3860) teacher/usage_max 0.7541 (0.5566) teacher/usage_min 0.0115 (0.1118) teacher/usage_std 0.3111 (0.1874) nleep/row_max_mean 1532.8181 (1515.7915) nleep/row_max_std 56.0028 (69.9949) nleep/row_min_mean 1519.9186 (1508.5989) lr 2.0000e-03 eta 0:15:43
epoch [2/50] batch [180/203] time 0.068 (0.097) data 0.000 (0.003) loss 1.5081 (1.3181) teacher_loss 0.2998 (0.3581) loss_zs_kd 0.0395 (0.0465) loss_oracle 0.6510 (0.4474) kd_loss 0.8631 (0.7130) acc 90.6250 (89.9479) gate/entropy 1.0972 (1.0983) gate/usage_max 0.3567 (0.3418) gate/usage_min 0.3135 (0.3250) gate/usage_std 0.0178 (0.0071) teacher/entropy 0.2014 (0.3731) teacher/usage_max 0.6116 (0.5672) teacher/usage_min 0.0576 (0.1068) teacher/usage_std 0.2261 (0.1937) nleep/row_max_mean 1521.1527 (1515.3041) nleep/row_max_std 50.5566 (69.8288) nleep/row_min_mean 1509.5332 (1507.6743) lr 2.0000e-03 eta 0:15:47
epoch [2/50] batch [200/203] time 0.079 (0.096) data 0.000 (0.002) loss 1.6725 (1.3439) teacher_loss 0.4870 (0.3663) loss_zs_kd 0.0387 (0.0456) loss_oracle 0.5756 (0.4647) kd_loss 0.8784 (0.7224) acc 71.8750 (89.4844) gate/entropy 1.0965 (1.0982) gate/usage_max 0.3620 (0.3436) gate/usage_min 0.3102 (0.3237) gate/usage_std 0.0215 (0.0083) teacher/entropy 0.1607 (0.3609) teacher/usage_max 0.7674 (0.5754) teacher/usage_min 0.0048 (0.1014) teacher/usage_std 0.3201 (0.1993) nleep/row_max_mean 1536.7695 (1515.1339) nleep/row_max_std 33.2787 (69.8029) nleep/row_min_mean 1523.7744 (1507.0952) lr 2.0000e-03 eta 0:15:35
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,251
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 84.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      80.5%, epoch: 2 *******
******* Domain c best val test acc: 100.0%, epoch: 2 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [3/50] batch [20/203] time 0.100 (0.109) data 0.001 (0.018) loss 1.2333 (1.5156) teacher_loss 0.1790 (0.4116) loss_zs_kd 0.0280 (0.0329) loss_oracle 0.4578 (0.5431) kd_loss 0.8114 (0.8160) acc 96.8750 (88.1250) gate/entropy 1.0957 (1.0960) gate/usage_max 0.3676 (0.3654) gate/usage_min 0.3064 (0.3079) gate/usage_std 0.0255 (0.0240) teacher/entropy 0.2640 (0.2351) teacher/usage_max 0.5710 (0.6377) teacher/usage_min 0.0332 (0.0484) teacher/usage_std 0.2240 (0.2464) nleep/row_max_mean 1510.9956 (1514.2118) nleep/row_max_std 72.1687 (66.0973) nleep/row_min_mean 1498.8472 (1502.0098) lr 1.9980e-03 eta 0:17:43
epoch [3/50] batch [40/203] time 0.090 (0.101) data 0.000 (0.009) loss 1.5726 (1.5046) teacher_loss 0.4808 (0.3924) loss_zs_kd 0.0302 (0.0347) loss_oracle 0.5906 (0.5305) kd_loss 0.7814 (0.8296) acc 81.2500 (87.9688) gate/entropy 1.0949 (1.0957) gate/usage_max 0.3722 (0.3678) gate/usage_min 0.3028 (0.3062) gate/usage_std 0.0289 (0.0257) teacher/entropy 0.2640 (0.2216) teacher/usage_max 0.6305 (0.6101) teacher/usage_min 0.0974 (0.0495) teacher/usage_std 0.2219 (0.2354) nleep/row_max_mean 1506.8218 (1514.5876) nleep/row_max_std 75.6585 (65.6984) nleep/row_min_mean 1493.8893 (1501.8005) lr 1.9980e-03 eta 0:16:19
epoch [3/50] batch [60/203] time 0.089 (0.096) data 0.000 (0.006) loss 1.4919 (1.5021) teacher_loss 0.2825 (0.3755) loss_zs_kd 0.0321 (0.0365) loss_oracle 0.5425 (0.5208) kd_loss 0.9221 (0.8479) acc 96.8750 (88.6458) gate/entropy 1.0942 (1.0953) gate/usage_max 0.3753 (0.3698) gate/usage_min 0.3000 (0.3046) gate/usage_std 0.0313 (0.0272) teacher/entropy 0.1336 (0.2070) teacher/usage_max 0.4951 (0.5865) teacher/usage_min 0.0317 (0.0495) teacher/usage_std 0.2134 (0.2268) nleep/row_max_mean 1512.8181 (1514.7822) nleep/row_max_std 74.9356 (66.0891) nleep/row_min_mean 1497.4291 (1501.3091) lr 1.9980e-03 eta 0:15:33
epoch [3/50] batch [80/203] time 0.095 (0.093) data 0.000 (0.005) loss 1.4654 (1.5000) teacher_loss 0.2402 (0.3535) loss_zs_kd 0.0237 (0.0379) loss_oracle 0.4783 (0.5276) kd_loss 0.9741 (0.8638) acc 90.6250 (89.2188) gate/entropy 1.0936 (1.0949) gate/usage_max 0.3779 (0.3715) gate/usage_min 0.2968 (0.3030) gate/usage_std 0.0336 (0.0285) teacher/entropy 0.0970 (0.1929) teacher/usage_max 0.5986 (0.5784) teacher/usage_min 0.0348 (0.0470) teacher/usage_std 0.2314 (0.2254) nleep/row_max_mean 1513.0688 (1514.9990) nleep/row_max_std 65.2234 (66.3272) nleep/row_min_mean 1497.2988 (1500.9764) lr 1.9980e-03 eta 0:15:03
epoch [3/50] batch [100/203] time 0.094 (0.092) data 0.000 (0.004) loss 1.7091 (1.5162) teacher_loss 0.5258 (0.3516) loss_zs_kd 0.0576 (0.0393) loss_oracle 0.5085 (0.5308) kd_loss 0.9002 (0.8795) acc 87.5000 (89.3750) gate/entropy 1.0930 (1.0946) gate/usage_max 0.3798 (0.3730) gate/usage_min 0.2935 (0.3014) gate/usage_std 0.0356 (0.0297) teacher/entropy 0.1632 (0.1786) teacher/usage_max 0.5855 (0.5817) teacher/usage_min 0.0295 (0.0436) teacher/usage_std 0.2299 (0.2279) nleep/row_max_mean 1512.5524 (1514.0401) nleep/row_max_std 72.1629 (66.6293) nleep/row_min_mean 1495.3838 (1499.3246) lr 1.9980e-03 eta 0:14:43
epoch [3/50] batch [120/203] time 0.095 (0.091) data 0.000 (0.003) loss 1.5088 (1.5277) teacher_loss 0.2100 (0.3480) loss_zs_kd 0.0551 (0.0409) loss_oracle 0.5676 (0.5330) kd_loss 0.9875 (0.8928) acc 87.5000 (89.4531) gate/entropy 1.0924 (1.0943) gate/usage_max 0.3812 (0.3743) gate/usage_min 0.2902 (0.2998) gate/usage_std 0.0373 (0.0309) teacher/entropy 0.0591 (0.1668) teacher/usage_max 0.5529 (0.5870) teacher/usage_min 0.0020 (0.0420) teacher/usage_std 0.2384 (0.2304) nleep/row_max_mean 1515.6276 (1513.3976) nleep/row_max_std 71.3914 (66.5027) nleep/row_min_mean 1496.5913 (1498.0244) lr 1.9980e-03 eta 0:14:34
epoch [3/50] batch [140/203] time 0.081 (0.090) data 0.000 (0.003) loss 1.5177 (1.5364) teacher_loss 0.2204 (0.3405) loss_zs_kd 0.0438 (0.0432) loss_oracle 0.5653 (0.5371) kd_loss 0.9927 (0.9058) acc 87.5000 (89.6875) gate/entropy 1.0918 (1.0940) gate/usage_max 0.3824 (0.3754) gate/usage_min 0.2870 (0.2982) gate/usage_std 0.0390 (0.0319) teacher/entropy 0.0516 (0.1533) teacher/usage_max 0.5549 (0.5914) teacher/usage_min 0.0097 (0.0383) teacher/usage_std 0.2340 (0.2335) nleep/row_max_mean 1513.1665 (1514.6444) nleep/row_max_std 63.8591 (65.0260) nleep/row_min_mean 1493.1160 (1498.4148) lr 1.9980e-03 eta 0:14:19
epoch [3/50] batch [160/203] time 0.099 (0.090) data 0.000 (0.002) loss 1.5766 (1.5357) teacher_loss 0.3021 (0.3320) loss_zs_kd 0.0397 (0.0441) loss_oracle 0.5482 (0.5339) kd_loss 0.9805 (0.9147) acc 87.5000 (89.8242) gate/entropy 1.0911 (1.0936) gate/usage_max 0.3837 (0.3763) gate/usage_min 0.2840 (0.2966) gate/usage_std 0.0407 (0.0329) teacher/entropy 0.0765 (0.1441) teacher/usage_max 0.6286 (0.5986) teacher/usage_min 0.0291 (0.0355) teacher/usage_std 0.2448 (0.2374) nleep/row_max_mean 1520.8527 (1514.5685) nleep/row_max_std 56.1993 (65.0245) nleep/row_min_mean 1497.9803 (1497.6767) lr 1.9980e-03 eta 0:14:19
epoch [3/50] batch [180/203] time 0.096 (0.090) data 0.000 (0.002) loss 1.4298 (1.5353) teacher_loss 0.1517 (0.3246) loss_zs_kd 0.0508 (0.0452) loss_oracle 0.5733 (0.5311) kd_loss 0.9660 (0.9225) acc 93.7500 (89.9653) gate/entropy 1.0906 (1.0933) gate/usage_max 0.3843 (0.3772) gate/usage_min 0.2812 (0.2950) gate/usage_std 0.0421 (0.0339) teacher/entropy 0.0766 (0.1357) teacher/usage_max 0.5756 (0.6051) teacher/usage_min 0.0219 (0.0333) teacher/usage_std 0.2313 (0.2409) nleep/row_max_mean 1506.0681 (1514.8589) nleep/row_max_std 70.3309 (64.1786) nleep/row_min_mean 1483.8618 (1497.4217) lr 1.9980e-03 eta 0:14:22
epoch [3/50] batch [200/203] time 0.092 (0.091) data 0.000 (0.002) loss 1.5095 (1.5371) teacher_loss 0.2558 (0.3204) loss_zs_kd 0.0756 (0.0463) loss_oracle 0.4793 (0.5276) kd_loss 0.9763 (0.9297) acc 87.5000 (90.0156) gate/entropy 1.0900 (1.0930) gate/usage_max 0.3850 (0.3779) gate/usage_min 0.2784 (0.2935) gate/usage_std 0.0436 (0.0348) teacher/entropy 0.0726 (0.1282) teacher/usage_max 0.6422 (0.6139) teacher/usage_min 0.0271 (0.0317) teacher/usage_std 0.2511 (0.2451) nleep/row_max_mean 1507.7628 (1514.4097) nleep/row_max_std 62.6246 (63.9052) nleep/row_min_mean 1483.7690 (1496.4681) lr 1.9980e-03 eta 0:14:23
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,291
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 86.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      82.0%, epoch: 3 *******
******* Domain c best val test acc: 100.0%, epoch: 3 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [4/50] batch [20/203] time 0.063 (0.125) data 0.000 (0.020) loss 1.3782 (1.5320) teacher_loss 0.0608 (0.2716) loss_zs_kd 0.0753 (0.0569) loss_oracle 0.5588 (0.5011) kd_loss 1.0004 (0.9813) acc 100.0000 (90.9375) gate/entropy 1.0894 (1.0897) gate/usage_max 0.3850 (0.3849) gate/usage_min 0.2757 (0.2768) gate/usage_std 0.0449 (0.0443) teacher/entropy 0.0315 (0.0678) teacher/usage_max 0.5262 (0.6716) teacher/usage_min 0.0347 (0.0242) teacher/usage_std 0.2141 (0.2702) nleep/row_max_mean 1518.0903 (1508.8322) nleep/row_max_std 60.6771 (64.6818) nleep/row_min_mean 1496.7400 (1487.1913) lr 1.9921e-03 eta 0:19:46
epoch [4/50] batch [40/203] time 0.070 (0.098) data 0.000 (0.010) loss 1.4828 (1.5141) teacher_loss 0.2721 (0.2569) loss_zs_kd 0.0601 (0.0602) loss_oracle 0.4556 (0.4997) kd_loss 0.9529 (0.9772) acc 90.6250 (91.6406) gate/entropy 1.0888 (1.0894) gate/usage_max 0.3858 (0.3852) gate/usage_min 0.2731 (0.2756) gate/usage_std 0.0464 (0.0450) teacher/entropy 0.1022 (0.0681) teacher/usage_max 0.7320 (0.6603) teacher/usage_min 0.0381 (0.0233) teacher/usage_std 0.2926 (0.2660) nleep/row_max_mean 1500.1167 (1509.9220) nleep/row_max_std 82.3191 (64.7934) nleep/row_min_mean 1479.7330 (1487.9099) lr 1.9921e-03 eta 0:15:27
epoch [4/50] batch [60/203] time 0.059 (0.088) data 0.000 (0.007) loss 1.4784 (1.5178) teacher_loss 0.3224 (0.2615) loss_zs_kd 0.0647 (0.0618) loss_oracle 0.4410 (0.5072) kd_loss 0.9031 (0.9719) acc 90.6250 (91.3021) gate/entropy 1.0882 (1.0891) gate/usage_max 0.3863 (0.3855) gate/usage_min 0.2708 (0.2743) gate/usage_std 0.0476 (0.0457) teacher/entropy 0.1534 (0.0728) teacher/usage_max 0.6348 (0.6600) teacher/usage_min 0.0829 (0.0273) teacher/usage_std 0.2282 (0.2635) nleep/row_max_mean 1479.0157 (1508.7584) nleep/row_max_std 80.2598 (66.2731) nleep/row_min_mean 1460.5386 (1486.6264) lr 1.9921e-03 eta 0:13:55
epoch [4/50] batch [80/203] time 0.086 (0.084) data 0.000 (0.005) loss 1.6277 (1.5055) teacher_loss 0.3873 (0.2526) loss_zs_kd 0.0622 (0.0595) loss_oracle 0.4555 (0.5046) kd_loss 0.9815 (0.9709) acc 87.5000 (91.6016) gate/entropy 1.0874 (1.0888) gate/usage_max 0.3873 (0.3858) gate/usage_min 0.2679 (0.2731) gate/usage_std 0.0494 (0.0464) teacher/entropy 0.0597 (0.0724) teacher/usage_max 0.6516 (0.6553) teacher/usage_min 0.0470 (0.0303) teacher/usage_std 0.2479 (0.2606) nleep/row_max_mean 1512.5503 (1508.4267) nleep/row_max_std 67.7194 (66.4444) nleep/row_min_mean 1488.8806 (1486.1676) lr 1.9921e-03 eta 0:13:17
epoch [4/50] batch [100/203] time 0.061 (0.082) data 0.000 (0.004) loss 1.5395 (1.5094) teacher_loss 0.2493 (0.2546) loss_zs_kd 0.0984 (0.0605) loss_oracle 0.5224 (0.5144) kd_loss 0.9798 (0.9673) acc 87.5000 (91.3438) gate/entropy 1.0868 (1.0884) gate/usage_max 0.3874 (0.3861) gate/usage_min 0.2658 (0.2719) gate/usage_std 0.0505 (0.0471) teacher/entropy 0.0650 (0.0759) teacher/usage_max 0.6520 (0.6561) teacher/usage_min 0.0663 (0.0350) teacher/usage_std 0.2419 (0.2592) nleep/row_max_mean 1500.7336 (1506.7028) nleep/row_max_std 70.6523 (67.9424) nleep/row_min_mean 1477.4573 (1484.4444) lr 1.9921e-03 eta 0:12:49
epoch [4/50] batch [120/203] time 0.074 (0.079) data 0.000 (0.004) loss 1.3643 (1.5148) teacher_loss 0.1774 (0.2562) loss_zs_kd 0.0585 (0.0614) loss_oracle 0.4440 (0.5173) kd_loss 0.9356 (0.9692) acc 93.7500 (91.3542) gate/entropy 1.0862 (1.0881) gate/usage_max 0.3873 (0.3863) gate/usage_min 0.2635 (0.2706) gate/usage_std 0.0518 (0.0478) teacher/entropy 0.1013 (0.0728) teacher/usage_max 0.7409 (0.6621) teacher/usage_min 0.0318 (0.0353) teacher/usage_std 0.2991 (0.2620) nleep/row_max_mean 1494.1567 (1506.8461) nleep/row_max_std 82.0100 (67.2508) nleep/row_min_mean 1473.9698 (1484.3428) lr 1.9921e-03 eta 0:12:23
epoch [4/50] batch [140/203] time 0.062 (0.078) data 0.000 (0.003) loss 1.3848 (1.5060) teacher_loss 0.1395 (0.2484) loss_zs_kd 0.0404 (0.0612) loss_oracle 0.5348 (0.5178) kd_loss 0.9577 (0.9682) acc 93.7500 (91.6518) gate/entropy 1.0855 (1.0878) gate/usage_max 0.3877 (0.3865) gate/usage_min 0.2611 (0.2694) gate/usage_std 0.0532 (0.0484) teacher/entropy 0.0722 (0.0723) teacher/usage_max 0.6358 (0.6603) teacher/usage_min 0.0519 (0.0367) teacher/usage_std 0.2388 (0.2604) nleep/row_max_mean 1510.6445 (1507.7546) nleep/row_max_std 69.3488 (65.8362) nleep/row_min_mean 1488.2797 (1485.1791) lr 1.9921e-03 eta 0:12:09
epoch [4/50] batch [160/203] time 0.094 (0.077) data 0.000 (0.003) loss 1.7223 (1.5084) teacher_loss 0.4350 (0.2513) loss_zs_kd 0.0914 (0.0603) loss_oracle 0.6002 (0.5204) kd_loss 0.9415 (0.9669) acc 84.3750 (91.5820) gate/entropy 1.0848 (1.0875) gate/usage_max 0.3883 (0.3866) gate/usage_min 0.2591 (0.2683) gate/usage_std 0.0545 (0.0491) teacher/entropy 0.1057 (0.0744) teacher/usage_max 0.5754 (0.6538) teacher/usage_min 0.1142 (0.0451) teacher/usage_std 0.1890 (0.2545) nleep/row_max_mean 1510.2878 (1507.4776) nleep/row_max_std 71.2728 (65.8817) nleep/row_min_mean 1487.6554 (1484.9561) lr 1.9921e-03 eta 0:12:01
epoch [4/50] batch [180/203] time 0.074 (0.078) data 0.000 (0.002) loss 1.7199 (1.5092) teacher_loss 0.4043 (0.2508) loss_zs_kd 0.0615 (0.0610) loss_oracle 0.6281 (0.5212) kd_loss 0.9707 (0.9673) acc 84.3750 (91.7708) gate/entropy 1.0843 (1.0871) gate/usage_max 0.3880 (0.3868) gate/usage_min 0.2574 (0.2672) gate/usage_std 0.0554 (0.0497) teacher/entropy 0.0565 (0.0739) teacher/usage_max 0.5815 (0.6534) teacher/usage_min 0.0694 (0.0493) teacher/usage_std 0.2094 (0.2528) nleep/row_max_mean 1511.5898 (1507.7615) nleep/row_max_std 45.2144 (65.1735) nleep/row_min_mean 1489.0344 (1485.1594) lr 1.9921e-03 eta 0:12:09
epoch [4/50] batch [200/203] time 0.081 (0.078) data 0.000 (0.002) loss 1.5741 (1.5110) teacher_loss 0.3198 (0.2519) loss_zs_kd 0.0743 (0.0609) loss_oracle 0.5493 (0.5245) kd_loss 0.9425 (0.9664) acc 87.5000 (91.6094) gate/entropy 1.0836 (1.0868) gate/usage_max 0.3882 (0.3869) gate/usage_min 0.2554 (0.2661) gate/usage_std 0.0566 (0.0504) teacher/entropy 0.0865 (0.0744) teacher/usage_max 0.6071 (0.6521) teacher/usage_min 0.0750 (0.0530) teacher/usage_std 0.2175 (0.2508) nleep/row_max_mean 1511.5007 (1507.8579) nleep/row_max_std 64.0887 (65.0164) nleep/row_min_mean 1488.6267 (1485.1774) lr 1.9921e-03 eta 0:12:09
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,313
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 86.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      82.8%, epoch: 4 *******
******* Domain c best val test acc: 99.9%, epoch: 4 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [5/50] batch [20/203] time 0.064 (0.091) data 0.000 (0.014) loss 1.4582 (1.4850) teacher_loss 0.1931 (0.2182) loss_zs_kd 0.0587 (0.0635) loss_oracle 0.5031 (0.5413) kd_loss 0.9841 (0.9645) acc 93.7500 (93.4375) gate/entropy 1.0829 (1.0832) gate/usage_max 0.3886 (0.3883) gate/usage_min 0.2532 (0.2542) gate/usage_std 0.0580 (0.0574) teacher/entropy 0.0685 (0.0834) teacher/usage_max 0.6032 (0.6137) teacher/usage_min 0.1375 (0.1185) teacher/usage_std 0.1972 (0.2098) nleep/row_max_mean 1512.7190 (1504.8808) nleep/row_max_std 69.2284 (67.7940) nleep/row_min_mean 1489.3333 (1481.9119) lr 1.9823e-03 eta 0:14:12
epoch [5/50] batch [40/203] time 0.088 (0.084) data 0.000 (0.007) loss 1.4930 (1.4921) teacher_loss 0.2308 (0.2283) loss_zs_kd 0.0570 (0.0615) loss_oracle 0.4962 (0.5259) kd_loss 0.9856 (0.9701) acc 90.6250 (92.3438) gate/entropy 1.0824 (1.0829) gate/usage_max 0.3884 (0.3884) gate/usage_min 0.2519 (0.2534) gate/usage_std 0.0588 (0.0579) teacher/entropy 0.0476 (0.0781) teacher/usage_max 0.5892 (0.6157) teacher/usage_min 0.0983 (0.1197) teacher/usage_std 0.2009 (0.2117) nleep/row_max_mean 1508.6606 (1504.6729) nleep/row_max_std 57.6381 (67.0917) nleep/row_min_mean 1485.9937 (1482.0468) lr 1.9823e-03 eta 0:13:05
epoch [5/50] batch [60/203] time 0.078 (0.084) data 0.000 (0.005) loss 1.7029 (1.5034) teacher_loss 0.4452 (0.2388) loss_zs_kd 0.0627 (0.0629) loss_oracle 0.4740 (0.5207) kd_loss 0.9894 (0.9729) acc 90.6250 (92.1354) gate/entropy 1.0819 (1.0827) gate/usage_max 0.3883 (0.3884) gate/usage_min 0.2506 (0.2527) gate/usage_std 0.0595 (0.0583) teacher/entropy 0.0470 (0.0777) teacher/usage_max 0.7554 (0.6127) teacher/usage_min 0.0821 (0.1219) teacher/usage_std 0.3003 (0.2092) nleep/row_max_mean 1520.9795 (1505.1165) nleep/row_max_std 61.8075 (67.2379) nleep/row_min_mean 1497.3035 (1482.6856) lr 1.9823e-03 eta 0:13:00
epoch [5/50] batch [80/203] time 0.090 (0.085) data 0.000 (0.004) loss 1.6113 (1.5221) teacher_loss 0.3308 (0.2523) loss_zs_kd 0.0586 (0.0629) loss_oracle 0.4815 (0.5206) kd_loss 1.0104 (0.9780) acc 87.5000 (91.7969) gate/entropy 1.0819 (1.0825) gate/usage_max 0.3872 (0.3882) gate/usage_min 0.2503 (0.2521) gate/usage_std 0.0596 (0.0586) teacher/entropy 0.0739 (0.0774) teacher/usage_max 0.6757 (0.6102) teacher/usage_min 0.1152 (0.1315) teacher/usage_std 0.2451 (0.2055) nleep/row_max_mean 1489.0615 (1505.0161) nleep/row_max_std 90.4559 (67.2090) nleep/row_min_mean 1467.8523 (1482.7371) lr 1.9823e-03 eta 0:13:10
epoch [5/50] batch [100/203] time 0.066 (0.085) data 0.000 (0.003) loss 1.4834 (1.5263) teacher_loss 0.1776 (0.2491) loss_zs_kd 0.0361 (0.0616) loss_oracle 0.5487 (0.5336) kd_loss 1.0134 (0.9796) acc 100.0000 (92.0625) gate/entropy 1.0820 (1.0824) gate/usage_max 0.3863 (0.3879) gate/usage_min 0.2503 (0.2518) gate/usage_std 0.0595 (0.0588) teacher/entropy 0.0977 (0.0802) teacher/usage_max 0.5614 (0.6031) teacher/usage_min 0.1483 (0.1363) teacher/usage_std 0.1714 (0.2003) nleep/row_max_mean 1502.9453 (1505.5825) nleep/row_max_std 77.4099 (66.2830) nleep/row_min_mean 1482.9417 (1483.5440) lr 1.9823e-03 eta 0:13:09
epoch [5/50] batch [120/203] time 0.087 (0.084) data 0.000 (0.002) loss 1.4630 (1.5359) teacher_loss 0.1519 (0.2527) loss_zs_kd 0.0720 (0.0602) loss_oracle 0.5622 (0.5374) kd_loss 0.9940 (0.9844) acc 96.8750 (91.8229) gate/entropy 1.0821 (1.0823) gate/usage_max 0.3855 (0.3876) gate/usage_min 0.2506 (0.2515) gate/usage_std 0.0592 (0.0589) teacher/entropy 0.0975 (0.0823) teacher/usage_max 0.5545 (0.5952) teacher/usage_min 0.1991 (0.1422) teacher/usage_std 0.1576 (0.1945) nleep/row_max_mean 1500.2333 (1504.5535) nleep/row_max_std 60.8992 (66.7166) nleep/row_min_mean 1477.1180 (1482.7141) lr 1.9823e-03 eta 0:12:57
epoch [5/50] batch [140/203] time 0.074 (0.084) data 0.000 (0.002) loss 1.4774 (1.5362) teacher_loss 0.2157 (0.2543) loss_zs_kd 0.0675 (0.0602) loss_oracle 0.5041 (0.5290) kd_loss 0.9759 (0.9873) acc 90.6250 (91.8750) gate/entropy 1.0821 (1.0823) gate/usage_max 0.3848 (0.3872) gate/usage_min 0.2504 (0.2514) gate/usage_std 0.0592 (0.0589) teacher/entropy 0.1007 (0.0838) teacher/usage_max 0.4387 (0.5900) teacher/usage_min 0.2297 (0.1457) teacher/usage_std 0.0853 (0.1910) nleep/row_max_mean 1520.0815 (1504.2910) nleep/row_max_std 54.6870 (66.5269) nleep/row_min_mean 1500.5701 (1482.5566) lr 1.9823e-03 eta 0:12:56
epoch [5/50] batch [160/203] time 0.112 (0.087) data 0.000 (0.002) loss 1.5944 (1.5346) teacher_loss 0.2312 (0.2527) loss_zs_kd 0.0522 (0.0598) loss_oracle 0.6333 (0.5259) kd_loss 1.0205 (0.9891) acc 93.7500 (91.7969) gate/entropy 1.0823 (1.0823) gate/usage_max 0.3835 (0.3868) gate/usage_min 0.2508 (0.2513) gate/usage_std 0.0588 (0.0589) teacher/entropy 0.1091 (0.0854) teacher/usage_max 0.4067 (0.5823) teacher/usage_min 0.2340 (0.1505) teacher/usage_std 0.0729 (0.1857) nleep/row_max_mean 1484.2350 (1504.4400) nleep/row_max_std 79.7888 (66.0545) nleep/row_min_mean 1466.3254 (1482.7742) lr 1.9823e-03 eta 0:13:18
epoch [5/50] batch [180/203] time 0.072 (0.087) data 0.000 (0.002) loss 1.7610 (1.5375) teacher_loss 0.4766 (0.2541) loss_zs_kd 0.0438 (0.0588) loss_oracle 0.5510 (0.5273) kd_loss 0.9870 (0.9903) acc 87.5000 (91.7708) gate/entropy 1.0823 (1.0823) gate/usage_max 0.3832 (0.3865) gate/usage_min 0.2508 (0.2512) gate/usage_std 0.0588 (0.0589) teacher/entropy 0.1569 (0.0863) teacher/usage_max 0.4911 (0.5765) teacher/usage_min 0.1264 (0.1539) teacher/usage_std 0.1529 (0.1817) nleep/row_max_mean 1484.8735 (1504.5266) nleep/row_max_std 82.7609 (65.8850) nleep/row_min_mean 1466.3916 (1483.0527) lr 1.9823e-03 eta 0:13:18
epoch [5/50] batch [200/203] time 0.088 (0.087) data 0.000 (0.002) loss 1.4679 (1.5400) teacher_loss 0.2050 (0.2555) loss_zs_kd 0.0630 (0.0588) loss_oracle 0.5781 (0.5295) kd_loss 0.9424 (0.9904) acc 93.7500 (91.7031) gate/entropy 1.0823 (1.0823) gate/usage_max 0.3834 (0.3861) gate/usage_min 0.2509 (0.2512) gate/usage_std 0.0587 (0.0589) teacher/entropy 0.0980 (0.0883) teacher/usage_max 0.5051 (0.5673) teacher/usage_min 0.1377 (0.1594) teacher/usage_std 0.1509 (0.1754) nleep/row_max_mean 1523.2273 (1504.3516) nleep/row_max_std 44.2876 (65.4972) nleep/row_min_mean 1502.3669 (1483.0935) lr 1.9823e-03 eta 0:13:14
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,289
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 86.0%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      82.8%, epoch: 4 *******
******* Domain c best val test acc: 99.9%, epoch: 4 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [6/50] batch [20/203] time 0.076 (0.102) data 0.000 (0.016) loss 1.5592 (1.5652) teacher_loss 0.1419 (0.2476) loss_zs_kd 0.0570 (0.0538) loss_oracle 0.7411 (0.6014) kd_loss 1.0182 (0.9900) acc 100.0000 (92.6562) gate/entropy 1.0826 (1.0824) gate/usage_max 0.3826 (0.3830) gate/usage_min 0.2514 (0.2511) gate/usage_std 0.0583 (0.0586) teacher/entropy 0.0664 (0.1031) teacher/usage_max 0.6432 (0.5115) teacher/usage_min 0.1286 (0.2055) teacher/usage_std 0.2228 (0.1318) nleep/row_max_mean 1495.7578 (1501.0000) nleep/row_max_std 65.0641 (61.2658) nleep/row_min_mean 1474.5238 (1481.2961) lr 1.9686e-03 eta 0:15:26
epoch [6/50] batch [40/203] time 0.092 (0.092) data 0.000 (0.008) loss 1.6924 (1.5566) teacher_loss 0.3702 (0.2457) loss_zs_kd 0.0758 (0.0604) loss_oracle 0.5554 (0.5838) kd_loss 1.0066 (0.9888) acc 87.5000 (92.4219) gate/entropy 1.0828 (1.0825) gate/usage_max 0.3817 (0.3826) gate/usage_min 0.2518 (0.2513) gate/usage_std 0.0580 (0.0584) teacher/entropy 0.0452 (0.0940) teacher/usage_max 0.5600 (0.5330) teacher/usage_min 0.1602 (0.1934) teacher/usage_std 0.1676 (0.1482) nleep/row_max_mean 1484.8827 (1502.8136) nleep/row_max_std 65.9906 (60.3519) nleep/row_min_mean 1464.6545 (1482.6812) lr 1.9686e-03 eta 0:13:57
epoch [6/50] batch [60/203] time 0.077 (0.089) data 0.001 (0.005) loss 1.7488 (1.5580) teacher_loss 0.4870 (0.2469) loss_zs_kd 0.0549 (0.0654) loss_oracle 0.5212 (0.5739) kd_loss 0.9737 (0.9915) acc 87.5000 (92.2917) gate/entropy 1.0828 (1.0826) gate/usage_max 0.3808 (0.3821) gate/usage_min 0.2517 (0.2514) gate/usage_std 0.0580 (0.0583) teacher/entropy 0.0702 (0.0897) teacher/usage_max 0.5457 (0.5380) teacher/usage_min 0.1451 (0.1932) teacher/usage_std 0.1644 (0.1506) nleep/row_max_mean 1499.9014 (1502.3035) nleep/row_max_std 63.8364 (61.3742) nleep/row_min_mean 1477.4895 (1481.8102) lr 1.9686e-03 eta 0:13:26
epoch [6/50] batch [80/203] time 0.098 (0.088) data 0.000 (0.004) loss 1.5035 (1.5502) teacher_loss 0.1821 (0.2363) loss_zs_kd 0.0578 (0.0643) loss_oracle 0.6289 (0.5754) kd_loss 0.9780 (0.9940) acc 90.6250 (92.5391) gate/entropy 1.0829 (1.0827) gate/usage_max 0.3801 (0.3817) gate/usage_min 0.2519 (0.2515) gate/usage_std 0.0578 (0.0582) teacher/entropy 0.0872 (0.0873) teacher/usage_max 0.5229 (0.5334) teacher/usage_min 0.1974 (0.1913) teacher/usage_std 0.1382 (0.1487) nleep/row_max_mean 1509.7322 (1502.0279) nleep/row_max_std 60.9415 (61.9113) nleep/row_min_mean 1485.7289 (1481.2905) lr 1.9686e-03 eta 0:13:12
epoch [6/50] batch [100/203] time 0.101 (0.087) data 0.000 (0.003) loss 1.5453 (1.5546) teacher_loss 0.2804 (0.2368) loss_zs_kd 0.0494 (0.0622) loss_oracle 0.5162 (0.5822) kd_loss 0.9821 (0.9956) acc 90.6250 (92.2188) gate/entropy 1.0830 (1.0827) gate/usage_max 0.3791 (0.3812) gate/usage_min 0.2521 (0.2517) gate/usage_std 0.0576 (0.0580) teacher/entropy 0.0744 (0.0837) teacher/usage_max 0.5573 (0.5440) teacher/usage_min 0.1769 (0.1851) teacher/usage_std 0.1625 (0.1559) nleep/row_max_mean 1512.4395 (1501.9904) nleep/row_max_std 56.7957 (61.6585) nleep/row_min_mean 1488.9043 (1480.8765) lr 1.9686e-03 eta 0:13:10
epoch [6/50] batch [120/203] time 0.097 (0.089) data 0.000 (0.003) loss 1.5604 (1.5525) teacher_loss 0.1791 (0.2354) loss_zs_kd 0.0746 (0.0625) loss_oracle 0.6414 (0.5818) kd_loss 1.0233 (0.9949) acc 93.7500 (92.2396) gate/entropy 1.0831 (1.0828) gate/usage_max 0.3778 (0.3808) gate/usage_min 0.2524 (0.2518) gate/usage_std 0.0573 (0.0579) teacher/entropy 0.0813 (0.0829) teacher/usage_max 0.4692 (0.5492) teacher/usage_min 0.2286 (0.1840) teacher/usage_std 0.1007 (0.1590) nleep/row_max_mean 1516.1503 (1503.0799) nleep/row_max_std 67.7386 (61.0498) nleep/row_min_mean 1492.2155 (1481.4595) lr 1.9686e-03 eta 0:13:21
epoch [6/50] batch [140/203] time 0.105 (0.090) data 0.000 (0.002) loss 1.6979 (1.5551) teacher_loss 0.3898 (0.2358) loss_zs_kd 0.0955 (0.0646) loss_oracle 0.5800 (0.5823) kd_loss 0.9704 (0.9959) acc 84.3750 (92.2321) gate/entropy 1.0833 (1.0828) gate/usage_max 0.3761 (0.3802) gate/usage_min 0.2527 (0.2519) gate/usage_std 0.0570 (0.0578) teacher/entropy 0.1273 (0.0811) teacher/usage_max 0.5395 (0.5565) teacher/usage_min 0.1757 (0.1818) teacher/usage_std 0.1524 (0.1637) nleep/row_max_mean 1501.7662 (1503.9551) nleep/row_max_std 61.9460 (60.2330) nleep/row_min_mean 1480.2856 (1481.8539) lr 1.9686e-03 eta 0:13:26
epoch [6/50] batch [160/203] time 0.092 (0.090) data 0.001 (0.002) loss 1.6516 (1.5594) teacher_loss 0.2051 (0.2413) loss_zs_kd 0.0850 (0.0646) loss_oracle 0.6318 (0.5783) kd_loss 1.0881 (0.9966) acc 93.7500 (92.0898) gate/entropy 1.0834 (1.0829) gate/usage_max 0.3747 (0.3796) gate/usage_min 0.2530 (0.2520) gate/usage_std 0.0568 (0.0577) teacher/entropy 0.0549 (0.0804) teacher/usage_max 0.4258 (0.5579) teacher/usage_min 0.1697 (0.1807) teacher/usage_std 0.1160 (0.1649) nleep/row_max_mean 1479.1646 (1504.0002) nleep/row_max_std 80.4683 (60.9667) nleep/row_min_mean 1458.3312 (1481.6346) lr 1.9686e-03 eta 0:13:29
epoch [6/50] batch [180/203] time 0.096 (0.091) data 0.000 (0.002) loss 1.7101 (1.5533) teacher_loss 0.3869 (0.2374) loss_zs_kd 0.0588 (0.0648) loss_oracle 0.5703 (0.5737) kd_loss 1.0086 (0.9967) acc 90.6250 (92.3438) gate/entropy 1.0835 (1.0830) gate/usage_max 0.3735 (0.3790) gate/usage_min 0.2532 (0.2522) gate/usage_std 0.0567 (0.0576) teacher/entropy 0.0729 (0.0796) teacher/usage_max 0.5404 (0.5615) teacher/usage_min 0.2106 (0.1794) teacher/usage_std 0.1473 (0.1672) nleep/row_max_mean 1492.1538 (1503.9966) nleep/row_max_std 78.7845 (61.0168) nleep/row_min_mean 1469.3682 (1481.3356) lr 1.9686e-03 eta 0:13:31
epoch [6/50] batch [200/203] time 0.089 (0.091) data 0.000 (0.002) loss 1.3833 (1.5442) teacher_loss 0.1143 (0.2311) loss_zs_kd 0.0687 (0.0645) loss_oracle 0.5244 (0.5676) kd_loss 0.9725 (0.9970) acc 96.8750 (92.6406) gate/entropy 1.0834 (1.0830) gate/usage_max 0.3744 (0.3785) gate/usage_min 0.2531 (0.2523) gate/usage_std 0.0567 (0.0575) teacher/entropy 0.1139 (0.0785) teacher/usage_max 0.4645 (0.5628) teacher/usage_min 0.2632 (0.1777) teacher/usage_std 0.0928 (0.1683) nleep/row_max_mean 1503.8241 (1503.9034) nleep/row_max_std 72.6876 (61.3790) nleep/row_min_mean 1481.4315 (1481.1569) lr 1.9686e-03 eta 0:13:31
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,248
* accuracy: 80.4%
* error: 19.6%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,413
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      82.8%, epoch: 4 *******
******* Domain c best val test acc: 99.9%, epoch: 4 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [7/50] batch [20/203] time 0.089 (0.130) data 0.000 (0.019) loss 1.6052 (1.5217) teacher_loss 0.2444 (0.2178) loss_zs_kd 0.0644 (0.0656) loss_oracle 0.5872 (0.5122) kd_loss 1.0350 (1.0150) acc 93.7500 (93.1250) gate/entropy 1.0835 (1.0834) gate/usage_max 0.3762 (0.3754) gate/usage_min 0.2532 (0.2531) gate/usage_std 0.0567 (0.0568) teacher/entropy 0.0678 (0.0539) teacher/usage_max 0.5247 (0.6291) teacher/usage_min 0.1617 (0.1325) teacher/usage_std 0.1488 (0.2172) nleep/row_max_mean 1471.4772 (1505.2864) nleep/row_max_std 91.2507 (57.3094) nleep/row_min_mean 1448.9861 (1480.2996) lr 1.9511e-03 eta 0:19:21
epoch [7/50] batch [40/203] time 0.095 (0.112) data 0.000 (0.010) loss 1.4269 (1.5173) teacher_loss 0.0944 (0.2147) loss_zs_kd 0.0633 (0.0657) loss_oracle 0.5350 (0.5150) kd_loss 1.0334 (1.0122) acc 96.8750 (92.7344) gate/entropy 1.0835 (1.0834) gate/usage_max 0.3775 (0.3762) gate/usage_min 0.2533 (0.2531) gate/usage_std 0.0567 (0.0568) teacher/entropy 0.0490 (0.0564) teacher/usage_max 0.6297 (0.6116) teacher/usage_min 0.1021 (0.1508) teacher/usage_std 0.2203 (0.2022) nleep/row_max_mean 1496.8135 (1503.1757) nleep/row_max_std 74.2002 (60.8942) nleep/row_min_mean 1472.4684 (1478.3465) lr 1.9511e-03 eta 0:16:36
epoch [7/50] batch [60/203] time 0.111 (0.110) data 0.001 (0.007) loss 1.3527 (1.5123) teacher_loss 0.1258 (0.2177) loss_zs_kd 0.0609 (0.0642) loss_oracle 0.3656 (0.5054) kd_loss 1.0137 (1.0097) acc 93.7500 (92.6042) gate/entropy 1.0833 (1.0834) gate/usage_max 0.3790 (0.3770) gate/usage_min 0.2531 (0.2531) gate/usage_std 0.0569 (0.0568) teacher/entropy 0.0782 (0.0613) teacher/usage_max 0.5376 (0.6017) teacher/usage_min 0.1715 (0.1538) teacher/usage_std 0.1524 (0.1963) nleep/row_max_mean 1488.8918 (1502.3862) nleep/row_max_std 84.6813 (63.3619) nleep/row_min_mean 1462.6003 (1477.4801) lr 1.9511e-03 eta 0:16:11
epoch [7/50] batch [80/203] time 0.098 (0.107) data 0.000 (0.005) loss 1.7493 (1.5363) teacher_loss 0.4250 (0.2464) loss_zs_kd 0.0543 (0.0640) loss_oracle 0.5209 (0.5047) kd_loss 1.0368 (1.0055) acc 78.1250 (91.6016) gate/entropy 1.0831 (1.0834) gate/usage_max 0.3805 (0.3777) gate/usage_min 0.2527 (0.2531) gate/usage_std 0.0573 (0.0569) teacher/entropy 0.0254 (0.0611) teacher/usage_max 0.5860 (0.6074) teacher/usage_min 0.1954 (0.1540) teacher/usage_std 0.1789 (0.1993) nleep/row_max_mean 1491.1082 (1501.2769) nleep/row_max_std 76.4296 (64.3169) nleep/row_min_mean 1466.2068 (1476.3499) lr 1.9511e-03 eta 0:15:49
epoch [7/50] batch [100/203] time 0.103 (0.105) data 0.000 (0.004) loss 1.5693 (1.5305) teacher_loss 0.3237 (0.2457) loss_zs_kd 0.0575 (0.0630) loss_oracle 0.4571 (0.5084) kd_loss 0.9883 (0.9991) acc 90.6250 (91.7500) gate/entropy 1.0827 (1.0833) gate/usage_max 0.3823 (0.3784) gate/usage_min 0.2518 (0.2530) gate/usage_std 0.0580 (0.0570) teacher/entropy 0.0710 (0.0626) teacher/usage_max 0.6322 (0.6138) teacher/usage_min 0.1484 (0.1525) teacher/usage_std 0.2133 (0.2037) nleep/row_max_mean 1506.2603 (1502.7772) nleep/row_max_std 71.0139 (64.1593) nleep/row_min_mean 1480.1492 (1477.7039) lr 1.9511e-03 eta 0:15:28
epoch [7/50] batch [120/203] time 0.094 (0.104) data 0.000 (0.004) loss 1.4473 (1.5228) teacher_loss 0.2263 (0.2438) loss_zs_kd 0.0469 (0.0613) loss_oracle 0.4676 (0.5078) kd_loss 0.9638 (0.9945) acc 90.6250 (91.8750) gate/entropy 1.0826 (1.0832) gate/usage_max 0.3838 (0.3792) gate/usage_min 0.2516 (0.2528) gate/usage_std 0.0583 (0.0572) teacher/entropy 0.0665 (0.0640) teacher/usage_max 0.7331 (0.6189) teacher/usage_min 0.1074 (0.1507) teacher/usage_std 0.2835 (0.2068) nleep/row_max_mean 1501.4424 (1502.6491) nleep/row_max_std 68.9092 (64.5972) nleep/row_min_mean 1473.2913 (1477.5077) lr 1.9511e-03 eta 0:15:14
epoch [7/50] batch [140/203] time 0.094 (0.103) data 0.000 (0.003) loss 1.5068 (1.5195) teacher_loss 0.2204 (0.2443) loss_zs_kd 0.0379 (0.0600) loss_oracle 0.5286 (0.5073) kd_loss 1.0032 (0.9915) acc 93.7500 (91.8973) gate/entropy 1.0823 (1.0831) gate/usage_max 0.3859 (0.3800) gate/usage_min 0.2512 (0.2526) gate/usage_std 0.0588 (0.0574) teacher/entropy 0.0442 (0.0651) teacher/usage_max 0.6245 (0.6259) teacher/usage_min 0.1798 (0.1470) teacher/usage_std 0.2060 (0.2116) nleep/row_max_mean 1509.1387 (1502.7784) nleep/row_max_std 79.3740 (64.6864) nleep/row_min_mean 1483.5139 (1477.6470) lr 1.9511e-03 eta 0:15:04
epoch [7/50] batch [160/203] time 0.104 (0.103) data 0.001 (0.003) loss 1.5061 (1.5213) teacher_loss 0.1972 (0.2480) loss_zs_kd 0.0501 (0.0604) loss_oracle 0.5284 (0.5097) kd_loss 1.0197 (0.9883) acc 96.8750 (91.6602) gate/entropy 1.0824 (1.0830) gate/usage_max 0.3870 (0.3808) gate/usage_min 0.2516 (0.2524) gate/usage_std 0.0587 (0.0576) teacher/entropy 0.0622 (0.0674) teacher/usage_max 0.6193 (0.6249) teacher/usage_min 0.0847 (0.1473) teacher/usage_std 0.2198 (0.2109) nleep/row_max_mean 1486.8544 (1502.1389) nleep/row_max_std 83.4179 (65.6374) nleep/row_min_mean 1463.8567 (1477.2013) lr 1.9511e-03 eta 0:15:00
epoch [7/50] batch [180/203] time 0.102 (0.103) data 0.001 (0.002) loss 1.5277 (1.5213) teacher_loss 0.2771 (0.2497) loss_zs_kd 0.0670 (0.0599) loss_oracle 0.5465 (0.5106) kd_loss 0.9439 (0.9863) acc 90.6250 (91.5799) gate/entropy 1.0819 (1.0829) gate/usage_max 0.3888 (0.3816) gate/usage_min 0.2507 (0.2523) gate/usage_std 0.0596 (0.0577) teacher/entropy 0.1165 (0.0680) teacher/usage_max 0.5214 (0.6238) teacher/usage_min 0.2209 (0.1482) teacher/usage_std 0.1338 (0.2100) nleep/row_max_mean 1500.6139 (1501.8789) nleep/row_max_std 74.5094 (65.5528) nleep/row_min_mean 1479.6152 (1477.1015) lr 1.9511e-03 eta 0:14:57
epoch [7/50] batch [200/203] time 0.086 (0.102) data 0.000 (0.002) loss 1.5157 (1.5239) teacher_loss 0.2718 (0.2530) loss_zs_kd 0.0407 (0.0591) loss_oracle 0.5451 (0.5111) kd_loss 0.9510 (0.9858) acc 90.6250 (91.5000) gate/entropy 1.0819 (1.0828) gate/usage_max 0.3900 (0.3824) gate/usage_min 0.2510 (0.2521) gate/usage_std 0.0596 (0.0579) teacher/entropy 0.0907 (0.0685) teacher/usage_max 0.6577 (0.6216) teacher/usage_min 0.1403 (0.1487) teacher/usage_std 0.2307 (0.2087) nleep/row_max_mean 1503.9420 (1501.6584) nleep/row_max_std 60.0375 (65.8026) nleep/row_min_mean 1479.1578 (1477.0459) lr 1.9511e-03 eta 0:14:47
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,282
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 85.8%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      82.8%, epoch: 4 *******
******* Domain c best val test acc: 99.9%, epoch: 4 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [8/50] batch [20/203] time 0.099 (0.112) data 0.000 (0.013) loss 1.6546 (1.5397) teacher_loss 0.3518 (0.3110) loss_zs_kd 0.0384 (0.0509) loss_oracle 0.5625 (0.4865) kd_loss 1.0023 (0.9600) acc 87.5000 (89.8438) gate/entropy 1.0817 (1.0817) gate/usage_max 0.3918 (0.3911) gate/usage_min 0.2507 (0.2506) gate/usage_std 0.0601 (0.0600) teacher/entropy 0.0636 (0.0763) teacher/usage_max 0.6288 (0.6553) teacher/usage_min 0.1023 (0.1324) teacher/usage_std 0.2197 (0.2308) nleep/row_max_mean 1488.4102 (1503.6142) nleep/row_max_std 83.0891 (64.3353) nleep/row_min_mean 1462.3638 (1478.5592) lr 1.9298e-03 eta 0:16:16
epoch [8/50] batch [40/203] time 0.097 (0.105) data 0.000 (0.007) loss 1.5071 (1.5392) teacher_loss 0.3631 (0.3149) loss_zs_kd 0.0530 (0.0479) loss_oracle 0.4911 (0.4893) kd_loss 0.8719 (0.9557) acc 84.3750 (89.0625) gate/entropy 1.0813 (1.0816) gate/usage_max 0.3939 (0.3920) gate/usage_min 0.2502 (0.2505) gate/usage_std 0.0608 (0.0603) teacher/entropy 0.1224 (0.0768) teacher/usage_max 0.7129 (0.6595) teacher/usage_min 0.0947 (0.1301) teacher/usage_std 0.2714 (0.2341) nleep/row_max_mean 1500.6017 (1503.7805) nleep/row_max_std 62.8526 (65.5077) nleep/row_min_mean 1477.4849 (1478.9520) lr 1.9298e-03 eta 0:15:11
epoch [8/50] batch [60/203] time 0.105 (0.103) data 0.000 (0.004) loss 1.4550 (1.5436) teacher_loss 0.3164 (0.3240) loss_zs_kd 0.0558 (0.0466) loss_oracle 0.5064 (0.4967) kd_loss 0.8574 (0.9479) acc 84.3750 (88.6458) gate/entropy 1.0809 (1.0814) gate/usage_max 0.3961 (0.3930) gate/usage_min 0.2498 (0.2503) gate/usage_std 0.0615 (0.0605) teacher/entropy 0.1277 (0.0765) teacher/usage_max 0.7662 (0.6814) teacher/usage_min 0.0948 (0.1185) teacher/usage_std 0.3066 (0.2498) nleep/row_max_mean 1509.1542 (1505.1664) nleep/row_max_std 51.6853 (63.6654) nleep/row_min_mean 1483.4495 (1479.6429) lr 1.9298e-03 eta 0:14:53
epoch [8/50] batch [80/203] time 0.098 (0.102) data 0.000 (0.003) loss 1.5121 (1.5345) teacher_loss 0.3237 (0.3162) loss_zs_kd 0.0532 (0.0465) loss_oracle 0.4808 (0.5019) kd_loss 0.9214 (0.9441) acc 90.6250 (89.0625) gate/entropy 1.0804 (1.0813) gate/usage_max 0.3984 (0.3940) gate/usage_min 0.2491 (0.2502) gate/usage_std 0.0625 (0.0609) teacher/entropy 0.0867 (0.0771) teacher/usage_max 0.6791 (0.6894) teacher/usage_min 0.1418 (0.1148) teacher/usage_std 0.2450 (0.2552) nleep/row_max_mean 1518.9539 (1504.7765) nleep/row_max_std 69.5599 (63.5861) nleep/row_min_mean 1490.9005 (1479.0774) lr 1.9298e-03 eta 0:14:42
epoch [8/50] batch [100/203] time 0.093 (0.105) data 0.000 (0.003) loss 1.5638 (1.5336) teacher_loss 0.3469 (0.3188) loss_zs_kd 0.0245 (0.0457) loss_oracle 0.5361 (0.5046) kd_loss 0.9366 (0.9397) acc 81.2500 (88.6562) gate/entropy 1.0800 (1.0811) gate/usage_max 0.4003 (0.3951) gate/usage_min 0.2487 (0.2499) gate/usage_std 0.0631 (0.0612) teacher/entropy 0.0599 (0.0780) teacher/usage_max 0.6979 (0.6960) teacher/usage_min 0.1221 (0.1136) teacher/usage_std 0.2589 (0.2596) nleep/row_max_mean 1500.7178 (1504.2462) nleep/row_max_std 63.4999 (63.8319) nleep/row_min_mean 1475.9991 (1478.5244) lr 1.9298e-03 eta 0:15:03
epoch [8/50] batch [120/203] time 0.106 (0.104) data 0.000 (0.002) loss 1.6275 (1.5282) teacher_loss 0.4417 (0.3156) loss_zs_kd 0.0702 (0.0452) loss_oracle 0.4432 (0.5073) kd_loss 0.9291 (0.9363) acc 75.0000 (88.5156) gate/entropy 1.0795 (1.0809) gate/usage_max 0.4028 (0.3962) gate/usage_min 0.2482 (0.2497) gate/usage_std 0.0641 (0.0616) teacher/entropy 0.0912 (0.0787) teacher/usage_max 0.7376 (0.7033) teacher/usage_min 0.0449 (0.1101) teacher/usage_std 0.2944 (0.2647) nleep/row_max_mean 1480.5692 (1503.3061) nleep/row_max_std 86.8224 (64.3946) nleep/row_min_mean 1454.2198 (1477.5283) lr 1.9298e-03 eta 0:14:54
epoch [8/50] batch [140/203] time 0.092 (0.103) data 0.000 (0.002) loss 1.5205 (1.5343) teacher_loss 0.3535 (0.3240) loss_zs_kd 0.0335 (0.0461) loss_oracle 0.5187 (0.5122) kd_loss 0.8909 (0.9311) acc 87.5000 (87.9911) gate/entropy 1.0791 (1.0806) gate/usage_max 0.4049 (0.3973) gate/usage_min 0.2478 (0.2495) gate/usage_std 0.0649 (0.0620) teacher/entropy 0.1186 (0.0801) teacher/usage_max 0.6864 (0.7073) teacher/usage_min 0.1425 (0.1081) teacher/usage_std 0.2499 (0.2675) nleep/row_max_mean 1481.5493 (1503.4040) nleep/row_max_std 76.3418 (64.0713) nleep/row_min_mean 1457.2295 (1477.4659) lr 1.9298e-03 eta 0:14:44
epoch [8/50] batch [160/203] time 0.095 (0.102) data 0.000 (0.002) loss 1.4172 (1.5311) teacher_loss 0.2838 (0.3262) loss_zs_kd 0.0363 (0.0457) loss_oracle 0.5360 (0.5116) kd_loss 0.8472 (0.9263) acc 87.5000 (87.8906) gate/entropy 1.0783 (1.0804) gate/usage_max 0.4076 (0.3984) gate/usage_min 0.2467 (0.2492) gate/usage_std 0.0663 (0.0625) teacher/entropy 0.1430 (0.0814) teacher/usage_max 0.6986 (0.7123) teacher/usage_min 0.1292 (0.1066) teacher/usage_std 0.2589 (0.2708) nleep/row_max_mean 1494.4241 (1502.9989) nleep/row_max_std 75.2150 (64.3345) nleep/row_min_mean 1471.4939 (1476.8444) lr 1.9298e-03 eta 0:14:35
epoch [8/50] batch [180/203] time 0.085 (0.101) data 0.000 (0.002) loss 1.3217 (1.5349) teacher_loss 0.2027 (0.3381) loss_zs_kd 0.0410 (0.0448) loss_oracle 0.4648 (0.5058) kd_loss 0.8661 (0.9215) acc 90.6250 (87.4132) gate/entropy 1.0775 (1.0801) gate/usage_max 0.4104 (0.3996) gate/usage_min 0.2457 (0.2488) gate/usage_std 0.0676 (0.0630) teacher/entropy 0.0541 (0.0811) teacher/usage_max 0.9171 (0.7212) teacher/usage_min 0.0392 (0.1034) teacher/usage_std 0.4128 (0.2770) nleep/row_max_mean 1514.6414 (1503.2960) nleep/row_max_std 58.8584 (63.8577) nleep/row_min_mean 1483.8972 (1476.8694) lr 1.9298e-03 eta 0:14:26
epoch [8/50] batch [200/203] time 0.089 (0.100) data 0.000 (0.002) loss 1.5391 (1.5397) teacher_loss 0.4864 (0.3514) loss_zs_kd 0.0248 (0.0437) loss_oracle 0.4026 (0.4989) kd_loss 0.8389 (0.9170) acc 71.8750 (86.7500) gate/entropy 1.0765 (1.0798) gate/usage_max 0.4135 (0.4008) gate/usage_min 0.2444 (0.2485) gate/usage_std 0.0693 (0.0635) teacher/entropy 0.0695 (0.0801) teacher/usage_max 0.9193 (0.7331) teacher/usage_min 0.0298 (0.0989) teacher/usage_std 0.4144 (0.2852) nleep/row_max_mean 1511.9307 (1503.4134) nleep/row_max_std 56.4955 (63.8269) nleep/row_min_mean 1479.8805 (1476.6996) lr 1.9298e-03 eta 0:14:16
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,288
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 86.0%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      82.8%, epoch: 4 *******
******* Domain c best val test acc: 99.9%, epoch: 4 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [9/50] batch [20/203] time 0.095 (0.112) data 0.000 (0.016) loss 1.3387 (1.5186) teacher_loss 0.1947 (0.3790) loss_zs_kd 0.0213 (0.0347) loss_oracle 0.5232 (0.4948) kd_loss 0.8718 (0.8749) acc 93.7500 (84.8438) gate/entropy 1.0754 (1.0758) gate/usage_max 0.4175 (0.4159) gate/usage_min 0.2435 (0.2439) gate/usage_std 0.0712 (0.0704) teacher/entropy 0.0669 (0.0759) teacher/usage_max 0.7919 (0.8226) teacher/usage_min 0.0654 (0.0475) teacher/usage_std 0.3258 (0.3484) nleep/row_max_mean 1518.3225 (1504.7608) nleep/row_max_std 56.9219 (66.9990) nleep/row_min_mean 1487.3060 (1474.5955) lr 1.9048e-03 eta 0:15:55
epoch [9/50] batch [40/203] time 0.097 (0.104) data 0.001 (0.008) loss 1.4943 (1.5388) teacher_loss 0.4296 (0.4172) loss_zs_kd 0.0338 (0.0332) loss_oracle 0.4451 (0.4848) kd_loss 0.8252 (0.8626) acc 87.5000 (84.0625) gate/entropy 1.0742 (1.0753) gate/usage_max 0.4210 (0.4176) gate/usage_min 0.2424 (0.2434) gate/usage_std 0.0730 (0.0712) teacher/entropy 0.0874 (0.0711) teacher/usage_max 0.8576 (0.8475) teacher/usage_min 0.0474 (0.0433) teacher/usage_std 0.3712 (0.3653) nleep/row_max_mean 1508.2395 (1506.5576) nleep/row_max_std 63.8683 (62.9932) nleep/row_min_mean 1476.8499 (1475.9055) lr 1.9048e-03 eta 0:14:45
epoch [9/50] batch [60/203] time 0.092 (0.101) data 0.000 (0.005) loss 1.7352 (1.5612) teacher_loss 0.6214 (0.4500) loss_zs_kd 0.0284 (0.0299) loss_oracle 0.5255 (0.4763) kd_loss 0.8368 (0.8580) acc 75.0000 (82.4479) gate/entropy 1.0730 (1.0748) gate/usage_max 0.4246 (0.4193) gate/usage_min 0.2412 (0.2429) gate/usage_std 0.0749 (0.0721) teacher/entropy 0.0822 (0.0695) teacher/usage_max 0.8502 (0.8539) teacher/usage_min 0.0659 (0.0429) teacher/usage_std 0.3655 (0.3695) nleep/row_max_mean 1505.3960 (1506.5898) nleep/row_max_std 75.5839 (63.0483) nleep/row_min_mean 1476.9309 (1476.2255) lr 1.9048e-03 eta 0:14:12
epoch [9/50] batch [80/203] time 0.073 (0.098) data 0.001 (0.004) loss 1.5410 (1.5352) teacher_loss 0.4980 (0.4335) loss_zs_kd 0.0251 (0.0286) loss_oracle 0.4486 (0.4684) kd_loss 0.8061 (0.8533) acc 87.5000 (82.8125) gate/entropy 1.0720 (1.0742) gate/usage_max 0.4278 (0.4210) gate/usage_min 0.2405 (0.2424) gate/usage_std 0.0765 (0.0730) teacher/entropy 0.0897 (0.0686) teacher/usage_max 0.9130 (0.8617) teacher/usage_min 0.0100 (0.0392) teacher/usage_std 0.4108 (0.3749) nleep/row_max_mean 1484.5603 (1505.1362) nleep/row_max_std 86.5935 (65.0641) nleep/row_min_mean 1456.2444 (1475.2640) lr 1.9048e-03 eta 0:13:46
epoch [9/50] batch [100/203] time 0.096 (0.096) data 0.000 (0.003) loss 1.5216 (1.5352) teacher_loss 0.4354 (0.4398) loss_zs_kd 0.0321 (0.0287) loss_oracle 0.4596 (0.4676) kd_loss 0.8403 (0.8473) acc 78.1250 (82.5938) gate/entropy 1.0708 (1.0736) gate/usage_max 0.4312 (0.4227) gate/usage_min 0.2394 (0.2419) gate/usage_std 0.0784 (0.0739) teacher/entropy 0.0194 (0.0692) teacher/usage_max 0.9685 (0.8672) teacher/usage_min 0.0003 (0.0378) teacher/usage_std 0.4493 (0.3787) nleep/row_max_mean 1505.7068 (1504.5313) nleep/row_max_std 72.4809 (65.8630) nleep/row_min_mean 1476.6321 (1474.9960) lr 1.9048e-03 eta 0:13:24
epoch [9/50] batch [120/203] time 0.077 (0.094) data 0.000 (0.003) loss 1.7573 (1.5299) teacher_loss 0.6141 (0.4339) loss_zs_kd 0.0453 (0.0286) loss_oracle 0.5066 (0.4715) kd_loss 0.8673 (0.8460) acc 81.2500 (82.9948) gate/entropy 1.0696 (1.0730) gate/usage_max 0.4345 (0.4244) gate/usage_min 0.2388 (0.2414) gate/usage_std 0.0800 (0.0748) teacher/entropy 0.0128 (0.0683) teacher/usage_max 0.9038 (0.8664) teacher/usage_min 0.0333 (0.0378) teacher/usage_std 0.4036 (0.3782) nleep/row_max_mean 1510.0522 (1504.4509) nleep/row_max_std 69.4893 (65.5221) nleep/row_min_mean 1477.2341 (1475.0687) lr 1.9048e-03 eta 0:13:08
epoch [9/50] batch [140/203] time 0.088 (0.094) data 0.000 (0.002) loss 1.5159 (1.5279) teacher_loss 0.4560 (0.4337) loss_zs_kd 0.0295 (0.0291) loss_oracle 0.4314 (0.4718) kd_loss 0.8294 (0.8438) acc 87.5000 (82.9241) gate/entropy 1.0685 (1.0725) gate/usage_max 0.4374 (0.4261) gate/usage_min 0.2377 (0.2409) gate/usage_std 0.0818 (0.0757) teacher/entropy 0.0732 (0.0683) teacher/usage_max 0.8324 (0.8647) teacher/usage_min 0.0827 (0.0395) teacher/usage_std 0.3529 (0.3769) nleep/row_max_mean 1505.2543 (1504.4231) nleep/row_max_std 68.6213 (65.9011) nleep/row_min_mean 1475.0603 (1475.2949) lr 1.9048e-03 eta 0:13:04
epoch [9/50] batch [160/203] time 0.081 (0.093) data 0.000 (0.002) loss 1.5206 (1.5262) teacher_loss 0.4831 (0.4360) loss_zs_kd 0.0399 (0.0287) loss_oracle 0.4215 (0.4705) kd_loss 0.8068 (0.8406) acc 87.5000 (82.6758) gate/entropy 1.0674 (1.0719) gate/usage_max 0.4403 (0.4277) gate/usage_min 0.2370 (0.2405) gate/usage_std 0.0833 (0.0765) teacher/entropy 0.0282 (0.0683) teacher/usage_max 0.9604 (0.8648) teacher/usage_min 0.0090 (0.0405) teacher/usage_std 0.4435 (0.3769) nleep/row_max_mean 1511.8356 (1504.2236) nleep/row_max_std 56.5700 (65.6663) nleep/row_min_mean 1480.8981 (1475.2316) lr 1.9048e-03 eta 0:12:55
epoch [9/50] batch [180/203] time 0.145 (0.093) data 0.000 (0.002) loss 1.4188 (1.5254) teacher_loss 0.3808 (0.4362) loss_zs_kd 0.0259 (0.0290) loss_oracle 0.5099 (0.4711) kd_loss 0.7702 (0.8392) acc 90.6250 (82.5868) gate/entropy 1.0661 (1.0713) gate/usage_max 0.4436 (0.4293) gate/usage_min 0.2361 (0.2400) gate/usage_std 0.0852 (0.0774) teacher/entropy 0.1214 (0.0681) teacher/usage_max 0.8438 (0.8627) teacher/usage_min 0.0648 (0.0422) teacher/usage_std 0.3611 (0.3754) nleep/row_max_mean 1503.7999 (1503.6901) nleep/row_max_std 76.4379 (66.1926) nleep/row_min_mean 1473.7354 (1474.8458) lr 1.9048e-03 eta 0:12:53
epoch [9/50] batch [200/203] time 0.062 (0.094) data 0.000 (0.002) loss 1.5573 (1.5251) teacher_loss 0.4639 (0.4386) loss_zs_kd 0.0255 (0.0288) loss_oracle 0.5610 (0.4739) kd_loss 0.8002 (0.8351) acc 84.3750 (82.7031) gate/entropy 1.0649 (1.0707) gate/usage_max 0.4465 (0.4309) gate/usage_min 0.2355 (0.2396) gate/usage_std 0.0868 (0.0783) teacher/entropy 0.0766 (0.0674) teacher/usage_max 0.8879 (0.8665) teacher/usage_min 0.0015 (0.0402) teacher/usage_std 0.3947 (0.3781) nleep/row_max_mean 1491.0474 (1503.6345) nleep/row_max_std 67.2324 (65.8819) nleep/row_min_mean 1462.3320 (1474.7935) lr 1.9048e-03 eta 0:13:06
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,306
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,412
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.6%
******* Domain c best val acc:      82.8%, epoch: 4 *******
******* Domain c best val test acc: 99.9%, epoch: 4 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [10/50] batch [20/203] time 0.095 (0.110) data 0.000 (0.016) loss 1.7041 (1.5132) teacher_loss 0.6451 (0.4228) loss_zs_kd 0.0310 (0.0258) loss_oracle 0.4741 (0.5218) kd_loss 0.8064 (0.8166) acc 75.0000 (84.3750) gate/entropy 1.0633 (1.0640) gate/usage_max 0.4500 (0.4486) gate/usage_min 0.2343 (0.2348) gate/usage_std 0.0889 (0.0881) teacher/entropy 0.0349 (0.0538) teacher/usage_max 0.9289 (0.8662) teacher/usage_min 0.0109 (0.0461) teacher/usage_std 0.4216 (0.3775) nleep/row_max_mean 1508.7415 (1500.7664) nleep/row_max_std 54.2651 (65.4390) nleep/row_min_mean 1475.4875 (1472.3080) lr 1.8763e-03 eta 0:15:09
epoch [10/50] batch [40/203] time 0.090 (0.102) data 0.000 (0.008) loss 1.7452 (1.5135) teacher_loss 0.7062 (0.4452) loss_zs_kd 0.0339 (0.0264) loss_oracle 0.5127 (0.5047) kd_loss 0.7657 (0.8027) acc 78.1250 (83.1250) gate/entropy 1.0622 (1.0633) gate/usage_max 0.4525 (0.4500) gate/usage_min 0.2337 (0.2344) gate/usage_std 0.0904 (0.0889) teacher/entropy 0.0812 (0.0581) teacher/usage_max 0.8984 (0.8791) teacher/usage_min 0.0440 (0.0395) teacher/usage_std 0.3996 (0.3866) nleep/row_max_mean 1498.5414 (1503.8440) nleep/row_max_std 75.0088 (62.8144) nleep/row_min_mean 1467.7307 (1474.9327) lr 1.8763e-03 eta 0:14:05
epoch [10/50] batch [60/203] time 0.093 (0.100) data 0.000 (0.006) loss 1.5865 (1.5236) teacher_loss 0.5012 (0.4543) loss_zs_kd 0.0239 (0.0256) loss_oracle 0.5583 (0.5137) kd_loss 0.7942 (0.7996) acc 84.3750 (82.9167) gate/entropy 1.0607 (1.0627) gate/usage_max 0.4557 (0.4514) gate/usage_min 0.2325 (0.2339) gate/usage_std 0.0924 (0.0898) teacher/entropy 0.0473 (0.0568) teacher/usage_max 0.8755 (0.8807) teacher/usage_min 0.0305 (0.0395) teacher/usage_std 0.3842 (0.3877) nleep/row_max_mean 1510.7395 (1503.8237) nleep/row_max_std 58.5249 (63.1573) nleep/row_min_mean 1483.2261 (1475.1358) lr 1.8763e-03 eta 0:13:47
epoch [10/50] batch [80/203] time 0.093 (0.100) data 0.001 (0.004) loss 1.4601 (1.5239) teacher_loss 0.4301 (0.4564) loss_zs_kd 0.0237 (0.0259) loss_oracle 0.5144 (0.5142) kd_loss 0.7610 (0.7974) acc 84.3750 (82.9688) gate/entropy 1.0595 (1.0621) gate/usage_max 0.4582 (0.4528) gate/usage_min 0.2317 (0.2335) gate/usage_std 0.0939 (0.0906) teacher/entropy 0.1203 (0.0589) teacher/usage_max 0.8154 (0.8766) teacher/usage_min 0.0855 (0.0425) teacher/usage_std 0.3409 (0.3847) nleep/row_max_mean 1503.9365 (1503.8282) nleep/row_max_std 75.4755 (63.8118) nleep/row_min_mean 1479.2668 (1475.4633) lr 1.8763e-03 eta 0:13:40
epoch [10/50] batch [100/203] time 0.091 (0.099) data 0.000 (0.003) loss 1.6421 (1.5218) teacher_loss 0.6305 (0.4613) loss_zs_kd 0.0332 (0.0264) loss_oracle 0.5205 (0.5115) kd_loss 0.7348 (0.7915) acc 78.1250 (82.8125) gate/entropy 1.0584 (1.0614) gate/usage_max 0.4606 (0.4541) gate/usage_min 0.2311 (0.2331) gate/usage_std 0.0953 (0.0914) teacher/entropy 0.0708 (0.0615) teacher/usage_max 0.9449 (0.8785) teacher/usage_min 0.0246 (0.0425) teacher/usage_std 0.4325 (0.3860) nleep/row_max_mean 1499.1265 (1503.0663) nleep/row_max_std 64.4340 (64.9456) nleep/row_min_mean 1470.0546 (1474.9678) lr 1.8763e-03 eta 0:13:32
epoch [10/50] batch [120/203] time 0.093 (0.098) data 0.000 (0.003) loss 1.3695 (1.5088) teacher_loss 0.3654 (0.4552) loss_zs_kd 0.0238 (0.0259) loss_oracle 0.4912 (0.5034) kd_loss 0.7465 (0.7890) acc 90.6250 (83.0469) gate/entropy 1.0570 (1.0608) gate/usage_max 0.4634 (0.4554) gate/usage_min 0.2303 (0.2327) gate/usage_std 0.0971 (0.0922) teacher/entropy 0.0271 (0.0602) teacher/usage_max 0.9917 (0.8809) teacher/usage_min 0.0039 (0.0420) teacher/usage_std 0.4655 (0.3877) nleep/row_max_mean 1512.8146 (1503.2477) nleep/row_max_std 54.5382 (65.0592) nleep/row_min_mean 1484.1111 (1475.2370) lr 1.8763e-03 eta 0:13:24
epoch [10/50] batch [140/203] time 0.100 (0.098) data 0.000 (0.003) loss 1.3887 (1.5017) teacher_loss 0.3958 (0.4507) loss_zs_kd 0.0135 (0.0250) loss_oracle 0.4190 (0.5018) kd_loss 0.7767 (0.7875) acc 84.3750 (83.0357) gate/entropy 1.0558 (1.0602) gate/usage_max 0.4659 (0.4567) gate/usage_min 0.2300 (0.2323) gate/usage_std 0.0985 (0.0930) teacher/entropy 0.0345 (0.0604) teacher/usage_max 0.9296 (0.8804) teacher/usage_min 0.0061 (0.0408) teacher/usage_std 0.4223 (0.3874) nleep/row_max_mean 1501.9084 (1502.2568) nleep/row_max_std 73.5214 (65.8840) nleep/row_min_mean 1474.6304 (1474.5553) lr 1.8763e-03 eta 0:13:19
epoch [10/50] batch [160/203] time 0.098 (0.097) data 0.000 (0.002) loss 1.2870 (1.4948) teacher_loss 0.3376 (0.4470) loss_zs_kd 0.0304 (0.0251) loss_oracle 0.4786 (0.4999) kd_loss 0.6950 (0.7852) acc 84.3750 (82.8516) gate/entropy 1.0546 (1.0596) gate/usage_max 0.4686 (0.4581) gate/usage_min 0.2294 (0.2320) gate/usage_std 0.1001 (0.0938) teacher/entropy 0.1188 (0.0611) teacher/usage_max 0.8993 (0.8797) teacher/usage_min 0.0416 (0.0403) teacher/usage_std 0.4002 (0.3870) nleep/row_max_mean 1491.1646 (1502.2393) nleep/row_max_std 77.6375 (65.7401) nleep/row_min_mean 1468.0813 (1474.6781) lr 1.8763e-03 eta 0:13:14
epoch [10/50] batch [180/203] time 0.096 (0.097) data 0.000 (0.002) loss 1.4369 (1.4948) teacher_loss 0.4705 (0.4473) loss_zs_kd 0.0286 (0.0250) loss_oracle 0.4760 (0.5013) kd_loss 0.7142 (0.7844) acc 81.2500 (82.8993) gate/entropy 1.0532 (1.0589) gate/usage_max 0.4712 (0.4593) gate/usage_min 0.2289 (0.2317) gate/usage_std 0.1017 (0.0946) teacher/entropy 0.0827 (0.0606) teacher/usage_max 0.9105 (0.8786) teacher/usage_min 0.0153 (0.0399) teacher/usage_std 0.4088 (0.3862) nleep/row_max_mean 1517.8801 (1501.7060) nleep/row_max_std 49.4683 (66.0329) nleep/row_min_mean 1493.1844 (1474.4368) lr 1.8763e-03 eta 0:13:09
epoch [10/50] batch [200/203] time 0.090 (0.097) data 0.000 (0.002) loss 1.3553 (1.4966) teacher_loss 0.3844 (0.4520) loss_zs_kd 0.0294 (0.0247) loss_oracle 0.4136 (0.4988) kd_loss 0.7494 (0.7828) acc 93.7500 (82.6875) gate/entropy 1.0520 (1.0583) gate/usage_max 0.4736 (0.4606) gate/usage_min 0.2284 (0.2314) gate/usage_std 0.1031 (0.0953) teacher/entropy 0.0657 (0.0599) teacher/usage_max 0.8872 (0.8786) teacher/usage_min 0.0560 (0.0396) teacher/usage_std 0.3916 (0.3863) nleep/row_max_mean 1506.8667 (1502.0405) nleep/row_max_std 55.6971 (65.2254) nleep/row_min_mean 1482.4662 (1475.0536) lr 1.8763e-03 eta 0:13:03
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,331
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 87.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,411
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.5%
******* Domain c best val acc:      83.4%, epoch: 10 *******
******* Domain c best val test acc: 99.7%, epoch: 10 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [11/50] batch [20/203] time 0.104 (0.120) data 0.000 (0.014) loss 1.2268 (1.5101) teacher_loss 0.2095 (0.4725) loss_zs_kd 0.0043 (0.0227) loss_oracle 0.4933 (0.5342) kd_loss 0.7684 (0.7592) acc 90.6250 (81.5625) gate/entropy 1.0508 (1.0514) gate/usage_max 0.4760 (0.4749) gate/usage_min 0.2282 (0.2283) gate/usage_std 0.1046 (0.1039) teacher/entropy 0.0270 (0.0787) teacher/usage_max 0.9054 (0.8469) teacher/usage_min 0.0319 (0.0545) teacher/usage_std 0.4047 (0.3638) nleep/row_max_mean 1514.3208 (1497.7846) nleep/row_max_std 61.0469 (62.6704) nleep/row_min_mean 1488.9010 (1474.4509) lr 1.8443e-03 eta 0:16:13
epoch [11/50] batch [40/203] time 0.093 (0.114) data 0.000 (0.007) loss 1.5122 (1.5042) teacher_loss 0.4789 (0.4625) loss_zs_kd 0.0230 (0.0234) loss_oracle 0.5622 (0.5251) kd_loss 0.7406 (0.7674) acc 84.3750 (81.7188) gate/entropy 1.0498 (1.0509) gate/usage_max 0.4778 (0.4759) gate/usage_min 0.2274 (0.2281) gate/usage_std 0.1058 (0.1045) teacher/entropy 0.0986 (0.0710) teacher/usage_max 0.8302 (0.8433) teacher/usage_min 0.0742 (0.0569) teacher/usage_std 0.3515 (0.3613) nleep/row_max_mean 1512.9260 (1498.7690) nleep/row_max_std 51.7238 (62.9509) nleep/row_min_mean 1490.2595 (1475.3189) lr 1.8443e-03 eta 0:15:18
epoch [11/50] batch [60/203] time 0.087 (0.107) data 0.001 (0.005) loss 1.5646 (1.4782) teacher_loss 0.5437 (0.4439) loss_zs_kd 0.0206 (0.0235) loss_oracle 0.5213 (0.5186) kd_loss 0.7500 (0.7633) acc 87.5000 (82.7083) gate/entropy 1.0491 (1.0504) gate/usage_max 0.4792 (0.4768) gate/usage_min 0.2274 (0.2278) gate/usage_std 0.1066 (0.1051) teacher/entropy 0.0824 (0.0708) teacher/usage_max 0.8493 (0.8456) teacher/usage_min 0.0594 (0.0543) teacher/usage_std 0.3651 (0.3629) nleep/row_max_mean 1499.7990 (1499.3969) nleep/row_max_std 55.6804 (62.6642) nleep/row_min_mean 1475.6477 (1475.9372) lr 1.8443e-03 eta 0:14:25
epoch [11/50] batch [80/203] time 0.095 (0.105) data 0.000 (0.004) loss 1.4364 (1.4743) teacher_loss 0.2930 (0.4356) loss_zs_kd 0.0259 (0.0243) loss_oracle 0.5976 (0.5224) kd_loss 0.8316 (0.7654) acc 87.5000 (82.6562) gate/entropy 1.0479 (1.0499) gate/usage_max 0.4811 (0.4777) gate/usage_min 0.2267 (0.2276) gate/usage_std 0.1079 (0.1057) teacher/entropy 0.0707 (0.0692) teacher/usage_max 0.7331 (0.8421) teacher/usage_min 0.1143 (0.0557) teacher/usage_std 0.2831 (0.3605) nleep/row_max_mean 1479.0417 (1499.7910) nleep/row_max_std 80.7808 (62.0718) nleep/row_min_mean 1457.5779 (1476.4736) lr 1.8443e-03 eta 0:14:00
epoch [11/50] batch [100/203] time 0.089 (0.102) data 0.000 (0.003) loss 1.7694 (1.4709) teacher_loss 0.7442 (0.4350) loss_zs_kd 0.0234 (0.0247) loss_oracle 0.5285 (0.5244) kd_loss 0.7493 (0.7613) acc 81.2500 (82.9375) gate/entropy 1.0472 (1.0494) gate/usage_max 0.4824 (0.4785) gate/usage_min 0.2262 (0.2273) gate/usage_std 0.1087 (0.1062) teacher/entropy 0.0928 (0.0711) teacher/usage_max 0.8204 (0.8421) teacher/usage_min 0.0894 (0.0540) teacher/usage_std 0.3444 (0.3606) nleep/row_max_mean 1484.8977 (1500.5243) nleep/row_max_std 67.4917 (60.7163) nleep/row_min_mean 1465.0751 (1477.2226) lr 1.8443e-03 eta 0:13:41
epoch [11/50] batch [120/203] time 0.096 (0.101) data 0.000 (0.003) loss 1.3530 (1.4658) teacher_loss 0.2710 (0.4305) loss_zs_kd 0.0115 (0.0242) loss_oracle 0.5931 (0.5208) kd_loss 0.7797 (0.7628) acc 93.7500 (83.4896) gate/entropy 1.0462 (1.0489) gate/usage_max 0.4841 (0.4793) gate/usage_min 0.2256 (0.2271) gate/usage_std 0.1098 (0.1068) teacher/entropy 0.0544 (0.0721) teacher/usage_max 0.8056 (0.8359) teacher/usage_min 0.0378 (0.0564) teacher/usage_std 0.3374 (0.3564) nleep/row_max_mean 1498.4441 (1500.4841) nleep/row_max_std 64.9301 (60.8875) nleep/row_min_mean 1476.9613 (1477.3600) lr 1.8443e-03 eta 0:13:29
epoch [11/50] batch [140/203] time 0.102 (0.101) data 0.000 (0.002) loss 1.4216 (1.4607) teacher_loss 0.2415 (0.4211) loss_zs_kd 0.0300 (0.0248) loss_oracle 0.6707 (0.5222) kd_loss 0.8297 (0.7660) acc 90.6250 (83.8839) gate/entropy 1.0456 (1.0485) gate/usage_max 0.4850 (0.4801) gate/usage_min 0.2252 (0.2268) gate/usage_std 0.1104 (0.1072) teacher/entropy 0.1220 (0.0729) teacher/usage_max 0.6007 (0.8270) teacher/usage_min 0.0914 (0.0599) teacher/usage_std 0.2087 (0.3502) nleep/row_max_mean 1501.6431 (1500.2324) nleep/row_max_std 53.4312 (61.2799) nleep/row_min_mean 1478.3074 (1477.1743) lr 1.8443e-03 eta 0:13:23
epoch [11/50] batch [160/203] time 0.096 (0.100) data 0.000 (0.002) loss 1.5490 (1.4609) teacher_loss 0.5406 (0.4180) loss_zs_kd 0.0281 (0.0257) loss_oracle 0.4849 (0.5241) kd_loss 0.7519 (0.7679) acc 84.3750 (84.1406) gate/entropy 1.0447 (1.0480) gate/usage_max 0.4864 (0.4808) gate/usage_min 0.2244 (0.2266) gate/usage_std 0.1114 (0.1077) teacher/entropy 0.0288 (0.0728) teacher/usage_max 0.9001 (0.8213) teacher/usage_min 0.0318 (0.0606) teacher/usage_std 0.4011 (0.3464) nleep/row_max_mean 1509.1194 (1499.7505) nleep/row_max_std 46.1352 (61.2868) nleep/row_min_mean 1486.7987 (1476.8178) lr 1.8443e-03 eta 0:13:12
epoch [11/50] batch [180/203] time 0.103 (0.099) data 0.000 (0.002) loss 1.3608 (1.4603) teacher_loss 0.4329 (0.4151) loss_zs_kd 0.0331 (0.0263) loss_oracle 0.5253 (0.5282) kd_loss 0.6486 (0.7680) acc 87.5000 (84.3403) gate/entropy 1.0441 (1.0477) gate/usage_max 0.4873 (0.4815) gate/usage_min 0.2238 (0.2263) gate/usage_std 0.1120 (0.1081) teacher/entropy 0.1252 (0.0745) teacher/usage_max 0.9025 (0.8156) teacher/usage_min 0.0185 (0.0613) teacher/usage_std 0.4032 (0.3427) nleep/row_max_mean 1514.6150 (1499.3964) nleep/row_max_std 40.9424 (61.2660) nleep/row_min_mean 1491.4214 (1476.5048) lr 1.8443e-03 eta 0:13:07
epoch [11/50] batch [200/203] time 0.083 (0.098) data 0.000 (0.002) loss 1.5427 (1.4634) teacher_loss 0.4131 (0.4152) loss_zs_kd 0.0228 (0.0271) loss_oracle 0.5767 (0.5305) kd_loss 0.8298 (0.7694) acc 78.1250 (84.5312) gate/entropy 1.0436 (1.0473) gate/usage_max 0.4878 (0.4821) gate/usage_min 0.2232 (0.2260) gate/usage_std 0.1125 (0.1085) teacher/entropy 0.0510 (0.0754) teacher/usage_max 0.7043 (0.8092) teacher/usage_min 0.0305 (0.0622) teacher/usage_std 0.2792 (0.3386) nleep/row_max_mean 1503.7954 (1499.2781) nleep/row_max_std 56.8229 (61.1424) nleep/row_min_mean 1482.3267 (1476.3930) lr 1.8443e-03 eta 0:12:59
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,309
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 86.3%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,412
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.7%
******* Domain c best val acc:      83.4%, epoch: 10 *******
******* Domain c best val test acc: 99.7%, epoch: 10 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [12/50] batch [20/203] time 0.093 (0.106) data 0.000 (0.013) loss 1.3048 (1.4219) teacher_loss 0.2893 (0.3342) loss_zs_kd 0.0388 (0.0420) loss_oracle 0.5115 (0.5467) kd_loss 0.7403 (0.7934) acc 90.6250 (88.5938) gate/entropy 1.0433 (1.0434) gate/usage_max 0.4882 (0.4880) gate/usage_min 0.2227 (0.2228) gate/usage_std 0.1128 (0.1127) teacher/entropy 0.1094 (0.0739) teacher/usage_max 0.7881 (0.7473) teacher/usage_min 0.0816 (0.0668) teacher/usage_std 0.3222 (0.2981) nleep/row_max_mean 1485.9843 (1496.4202) nleep/row_max_std 70.3713 (61.9916) nleep/row_min_mean 1464.8188 (1472.8935) lr 1.8090e-03 eta 0:13:58
epoch [12/50] batch [40/203] time 0.100 (0.101) data 0.001 (0.006) loss 1.3939 (1.4235) teacher_loss 0.3196 (0.3363) loss_zs_kd 0.0366 (0.0397) loss_oracle 0.4709 (0.5358) kd_loss 0.8206 (0.7994) acc 87.5000 (88.3594) gate/entropy 1.0427 (1.0432) gate/usage_max 0.4889 (0.4883) gate/usage_min 0.2220 (0.2225) gate/usage_std 0.1134 (0.1129) teacher/entropy 0.0776 (0.0747) teacher/usage_max 0.6988 (0.7346) teacher/usage_min 0.0916 (0.0678) teacher/usage_std 0.2629 (0.2913) nleep/row_max_mean 1493.0269 (1494.3940) nleep/row_max_std 72.6446 (62.4140) nleep/row_min_mean 1469.6635 (1470.5062) lr 1.8090e-03 eta 0:13:14
epoch [12/50] batch [60/203] time 0.098 (0.099) data 0.001 (0.004) loss 1.3372 (1.4377) teacher_loss 0.3704 (0.3551) loss_zs_kd 0.0585 (0.0396) loss_oracle 0.4749 (0.5389) kd_loss 0.7001 (0.7933) acc 90.6250 (87.3958) gate/entropy 1.0425 (1.0430) gate/usage_max 0.4893 (0.4886) gate/usage_min 0.2216 (0.2223) gate/usage_std 0.1136 (0.1131) teacher/entropy 0.1202 (0.0776) teacher/usage_max 0.8165 (0.7369) teacher/usage_min 0.0346 (0.0595) teacher/usage_std 0.3448 (0.2939) nleep/row_max_mean 1496.9329 (1495.8353) nleep/row_max_std 63.8558 (61.3938) nleep/row_min_mean 1474.1379 (1471.8848) lr 1.8090e-03 eta 0:12:54
epoch [12/50] batch [80/203] time 0.096 (0.098) data 0.000 (0.003) loss 1.6125 (1.4490) teacher_loss 0.5147 (0.3616) loss_zs_kd 0.0559 (0.0401) loss_oracle 0.5615 (0.5459) kd_loss 0.7892 (0.7943) acc 84.3750 (87.5391) gate/entropy 1.0419 (1.0428) gate/usage_max 0.4899 (0.4889) gate/usage_min 0.2208 (0.2220) gate/usage_std 0.1142 (0.1133) teacher/entropy 0.0373 (0.0789) teacher/usage_max 0.8033 (0.7308) teacher/usage_min 0.0353 (0.0591) teacher/usage_std 0.3363 (0.2907) nleep/row_max_mean 1504.6851 (1495.9963) nleep/row_max_std 58.3329 (62.0583) nleep/row_min_mean 1477.5320 (1472.2795) lr 1.8090e-03 eta 0:12:46
epoch [12/50] batch [100/203] time 0.089 (0.099) data 0.000 (0.003) loss 1.5635 (1.4418) teacher_loss 0.4968 (0.3524) loss_zs_kd 0.0328 (0.0395) loss_oracle 0.4978 (0.5455) kd_loss 0.8014 (0.7969) acc 87.5000 (88.1562) gate/entropy 1.0420 (1.0426) gate/usage_max 0.4896 (0.4890) gate/usage_min 0.2206 (0.2218) gate/usage_std 0.1140 (0.1135) teacher/entropy 0.0635 (0.0809) teacher/usage_max 0.7285 (0.7239) teacher/usage_min 0.0329 (0.0640) teacher/usage_std 0.2917 (0.2855) nleep/row_max_mean 1494.3064 (1494.9269) nleep/row_max_std 53.0415 (62.9128) nleep/row_min_mean 1471.6466 (1471.5056) lr 1.8090e-03 eta 0:12:51
epoch [12/50] batch [120/203] time 0.129 (0.099) data 0.000 (0.002) loss 1.5696 (1.4453) teacher_loss 0.5346 (0.3532) loss_zs_kd 0.0382 (0.0391) loss_oracle 0.5532 (0.5480) kd_loss 0.7394 (0.7985) acc 75.0000 (88.1771) gate/entropy 1.0418 (1.0425) gate/usage_max 0.4897 (0.4891) gate/usage_min 0.2199 (0.2215) gate/usage_std 0.1142 (0.1136) teacher/entropy 0.1330 (0.0814) teacher/usage_max 0.7178 (0.7181) teacher/usage_min 0.0395 (0.0616) teacher/usage_std 0.2842 (0.2831) nleep/row_max_mean 1490.1808 (1495.3422) nleep/row_max_std 58.3191 (61.3368) nleep/row_min_mean 1466.3438 (1472.0291) lr 1.8090e-03 eta 0:12:48
epoch [12/50] batch [140/203] time 0.096 (0.100) data 0.000 (0.002) loss 1.2154 (1.4395) teacher_loss 0.1811 (0.3418) loss_zs_kd 0.0450 (0.0392) loss_oracle 0.4889 (0.5503) kd_loss 0.7674 (0.8030) acc 93.7500 (88.5938) gate/entropy 1.0420 (1.0424) gate/usage_max 0.4890 (0.4892) gate/usage_min 0.2195 (0.2212) gate/usage_std 0.1139 (0.1137) teacher/entropy 0.0775 (0.0813) teacher/usage_max 0.7633 (0.7106) teacher/usage_min 0.0262 (0.0647) teacher/usage_std 0.3132 (0.2781) nleep/row_max_mean 1489.9014 (1495.1493) nleep/row_max_std 66.2578 (61.9394) nleep/row_min_mean 1467.5480 (1471.8262) lr 1.8090e-03 eta 0:12:59
epoch [12/50] batch [160/203] time 0.092 (0.099) data 0.000 (0.002) loss 1.3188 (1.4364) teacher_loss 0.2648 (0.3389) loss_zs_kd 0.0553 (0.0394) loss_oracle 0.4576 (0.5481) kd_loss 0.7976 (0.8038) acc 90.6250 (88.6914) gate/entropy 1.0415 (1.0423) gate/usage_max 0.4894 (0.4892) gate/usage_min 0.2186 (0.2209) gate/usage_std 0.1144 (0.1137) teacher/entropy 0.0282 (0.0815) teacher/usage_max 0.7847 (0.7083) teacher/usage_min 0.0000 (0.0647) teacher/usage_std 0.3310 (0.2771) nleep/row_max_mean 1512.3916 (1495.0736) nleep/row_max_std 29.0596 (62.3492) nleep/row_min_mean 1486.0452 (1471.7313) lr 1.8090e-03 eta 0:12:51
epoch [12/50] batch [180/203] time 0.090 (0.099) data 0.000 (0.002) loss 1.4922 (1.4388) teacher_loss 0.4628 (0.3420) loss_zs_kd 0.0218 (0.0388) loss_oracle 0.4603 (0.5482) kd_loss 0.7884 (0.8033) acc 78.1250 (88.5069) gate/entropy 1.0413 (1.0422) gate/usage_max 0.4895 (0.4892) gate/usage_min 0.2178 (0.2206) gate/usage_std 0.1146 (0.1138) teacher/entropy 0.0597 (0.0808) teacher/usage_max 0.7569 (0.7083) teacher/usage_min 0.0304 (0.0613) teacher/usage_std 0.3086 (0.2780) nleep/row_max_mean 1526.2263 (1495.2542) nleep/row_max_std 27.7103 (62.1696) nleep/row_min_mean 1497.4717 (1471.8183) lr 1.8090e-03 eta 0:12:45
epoch [12/50] batch [200/203] time 0.088 (0.098) data 0.000 (0.002) loss 1.4871 (1.4400) teacher_loss 0.3711 (0.3428) loss_zs_kd 0.0335 (0.0387) loss_oracle 0.5623 (0.5505) kd_loss 0.8181 (0.8026) acc 84.3750 (88.4219) gate/entropy 1.0414 (1.0421) gate/usage_max 0.4890 (0.4892) gate/usage_min 0.2173 (0.2203) gate/usage_std 0.1144 (0.1139) teacher/entropy 0.1183 (0.0826) teacher/usage_max 0.6511 (0.7056) teacher/usage_min 0.1469 (0.0608) teacher/usage_std 0.2258 (0.2765) nleep/row_max_mean 1486.9932 (1494.8839) nleep/row_max_std 73.2629 (62.7617) nleep/row_min_mean 1463.8345 (1471.4417) lr 1.8090e-03 eta 0:12:39
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,314
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,413
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      83.4%, epoch: 10 *******
******* Domain c best val test acc: 99.7%, epoch: 10 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [13/50] batch [20/203] time 0.101 (0.112) data 0.000 (0.016) loss 1.4803 (1.4165) teacher_loss 0.3938 (0.2754) loss_zs_kd 0.0617 (0.0407) loss_oracle 0.5327 (0.5866) kd_loss 0.7892 (0.8275) acc 84.3750 (90.7812) gate/entropy 1.0415 (1.0415) gate/usage_max 0.4883 (0.4885) gate/usage_min 0.2165 (0.2168) gate/usage_std 0.1142 (0.1142) teacher/entropy 0.0820 (0.0741) teacher/usage_max 0.7288 (0.6607) teacher/usage_min 0.0577 (0.0465) teacher/usage_std 0.2868 (0.2568) nleep/row_max_mean 1490.4338 (1499.8094) nleep/row_max_std 80.3080 (59.3277) nleep/row_min_mean 1466.1218 (1474.8591) lr 1.7705e-03 eta 0:14:24
epoch [13/50] batch [40/203] time 0.103 (0.103) data 0.000 (0.008) loss 1.2682 (1.4407) teacher_loss 0.2546 (0.3091) loss_zs_kd 0.0240 (0.0417) loss_oracle 0.4541 (0.5781) kd_loss 0.7746 (0.8217) acc 90.6250 (89.8438) gate/entropy 1.0415 (1.0415) gate/usage_max 0.4877 (0.4883) gate/usage_min 0.2158 (0.2164) gate/usage_std 0.1140 (0.1142) teacher/entropy 0.1084 (0.0759) teacher/usage_max 0.7154 (0.6676) teacher/usage_min 0.0763 (0.0441) teacher/usage_std 0.2755 (0.2620) nleep/row_max_mean 1479.0851 (1498.4257) nleep/row_max_std 94.3766 (61.5596) nleep/row_min_mean 1456.6166 (1474.0097) lr 1.7705e-03 eta 0:13:09
epoch [13/50] batch [60/203] time 0.104 (0.100) data 0.000 (0.005) loss 1.4684 (1.4251) teacher_loss 0.3173 (0.3026) loss_zs_kd 0.0597 (0.0439) loss_oracle 0.6170 (0.5677) kd_loss 0.8127 (0.8167) acc 84.3750 (90.4167) gate/entropy 1.0412 (1.0415) gate/usage_max 0.4878 (0.4880) gate/usage_min 0.2149 (0.2161) gate/usage_std 0.1143 (0.1142) teacher/entropy 0.0722 (0.0799) teacher/usage_max 0.7015 (0.6707) teacher/usage_min 0.0620 (0.0460) teacher/usage_std 0.2699 (0.2628) nleep/row_max_mean 1507.2810 (1498.6233) nleep/row_max_std 58.6251 (62.4089) nleep/row_min_mean 1482.4365 (1474.3177) lr 1.7705e-03 eta 0:12:45
epoch [13/50] batch [80/203] time 0.096 (0.099) data 0.000 (0.004) loss 1.3342 (1.4216) teacher_loss 0.2252 (0.3038) loss_zs_kd 0.0296 (0.0432) loss_oracle 0.5403 (0.5636) kd_loss 0.8241 (0.8144) acc 93.7500 (90.1953) gate/entropy 1.0415 (1.0414) gate/usage_max 0.4871 (0.4879) gate/usage_min 0.2146 (0.2157) gate/usage_std 0.1139 (0.1141) teacher/entropy 0.0869 (0.0782) teacher/usage_max 0.6477 (0.6789) teacher/usage_min 0.0590 (0.0473) teacher/usage_std 0.2420 (0.2661) nleep/row_max_mean 1470.5529 (1496.6375) nleep/row_max_std 77.0429 (63.4399) nleep/row_min_mean 1445.9926 (1472.1699) lr 1.7705e-03 eta 0:12:33
epoch [13/50] batch [100/203] time 0.092 (0.098) data 0.000 (0.003) loss 1.5786 (1.4255) teacher_loss 0.4314 (0.3075) loss_zs_kd 0.0374 (0.0439) loss_oracle 0.6164 (0.5602) kd_loss 0.8204 (0.8160) acc 87.5000 (90.4688) gate/entropy 1.0413 (1.0414) gate/usage_max 0.4870 (0.4878) gate/usage_min 0.2138 (0.2154) gate/usage_std 0.1141 (0.1141) teacher/entropy 0.1021 (0.0777) teacher/usage_max 0.5995 (0.6750) teacher/usage_min 0.0270 (0.0454) teacher/usage_std 0.2354 (0.2651) nleep/row_max_mean 1500.1764 (1496.6514) nleep/row_max_std 64.3515 (63.4554) nleep/row_min_mean 1477.6160 (1472.2607) lr 1.7705e-03 eta 0:12:25
epoch [13/50] batch [120/203] time 0.091 (0.097) data 0.000 (0.003) loss 1.3239 (1.4257) teacher_loss 0.1938 (0.3047) loss_zs_kd 0.0515 (0.0443) loss_oracle 0.5774 (0.5610) kd_loss 0.8157 (0.8184) acc 93.7500 (90.5469) gate/entropy 1.0412 (1.0414) gate/usage_max 0.4865 (0.4876) gate/usage_min 0.2130 (0.2151) gate/usage_std 0.1141 (0.1141) teacher/entropy 0.0829 (0.0781) teacher/usage_max 0.6809 (0.6712) teacher/usage_min 0.0715 (0.0487) teacher/usage_std 0.2561 (0.2624) nleep/row_max_mean 1487.0791 (1496.2681) nleep/row_max_std 72.0771 (63.4033) nleep/row_min_mean 1461.9932 (1471.9066) lr 1.7705e-03 eta 0:12:19
epoch [13/50] batch [140/203] time 0.094 (0.097) data 0.000 (0.002) loss 1.4623 (1.4277) teacher_loss 0.1779 (0.3021) loss_zs_kd 0.0414 (0.0451) loss_oracle 0.7013 (0.5655) kd_loss 0.9131 (0.8203) acc 93.7500 (90.7366) gate/entropy 1.0415 (1.0414) gate/usage_max 0.4855 (0.4874) gate/usage_min 0.2126 (0.2147) gate/usage_std 0.1136 (0.1141) teacher/entropy 0.0864 (0.0802) teacher/usage_max 0.5223 (0.6641) teacher/usage_min 0.1454 (0.0506) teacher/usage_std 0.1538 (0.2582) nleep/row_max_mean 1476.6187 (1495.3879) nleep/row_max_std 75.0203 (63.9094) nleep/row_min_mean 1451.7419 (1471.1784) lr 1.7705e-03 eta 0:12:15
epoch [13/50] batch [160/203] time 0.093 (0.097) data 0.000 (0.002) loss 1.4281 (1.4219) teacher_loss 0.2790 (0.2956) loss_zs_kd 0.0331 (0.0448) loss_oracle 0.6061 (0.5634) kd_loss 0.8295 (0.8222) acc 90.6250 (90.8984) gate/entropy 1.0414 (1.0414) gate/usage_max 0.4852 (0.4872) gate/usage_min 0.2119 (0.2144) gate/usage_std 0.1136 (0.1141) teacher/entropy 0.0995 (0.0793) teacher/usage_max 0.6302 (0.6615) teacher/usage_min 0.0911 (0.0506) teacher/usage_std 0.2234 (0.2570) nleep/row_max_mean 1490.0657 (1495.5716) nleep/row_max_std 63.9086 (62.8182) nleep/row_min_mean 1466.1694 (1471.4353) lr 1.7705e-03 eta 0:12:13
epoch [13/50] batch [180/203] time 0.126 (0.098) data 0.001 (0.002) loss 1.2758 (1.4180) teacher_loss 0.1849 (0.2903) loss_zs_kd 0.0538 (0.0462) loss_oracle 0.4942 (0.5602) kd_loss 0.8169 (0.8246) acc 96.8750 (91.1285) gate/entropy 1.0415 (1.0414) gate/usage_max 0.4849 (0.4869) gate/usage_min 0.2115 (0.2141) gate/usage_std 0.1136 (0.1140) teacher/entropy 0.0426 (0.0776) teacher/usage_max 0.7292 (0.6613) teacher/usage_min 0.0235 (0.0528) teacher/usage_std 0.2944 (0.2561) nleep/row_max_mean 1504.7544 (1495.1888) nleep/row_max_std 38.6863 (62.8346) nleep/row_min_mean 1478.8928 (1471.1631) lr 1.7705e-03 eta 0:12:18
epoch [13/50] batch [200/203] time 0.070 (0.097) data 0.000 (0.002) loss 1.5074 (1.4160) teacher_loss 0.4187 (0.2860) loss_zs_kd 0.0526 (0.0469) loss_oracle 0.5120 (0.5602) kd_loss 0.8064 (0.8264) acc 87.5000 (91.2188) gate/entropy 1.0411 (1.0413) gate/usage_max 0.4851 (0.4867) gate/usage_min 0.2108 (0.2138) gate/usage_std 0.1139 (0.1140) teacher/entropy 0.0850 (0.0774) teacher/usage_max 0.7116 (0.6589) teacher/usage_min 0.0921 (0.0545) teacher/usage_std 0.2708 (0.2544) nleep/row_max_mean 1483.6978 (1494.8706) nleep/row_max_std 72.4497 (62.6325) nleep/row_min_mean 1462.8584 (1471.0580) lr 1.7705e-03 eta 0:12:10
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,336
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 87.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,412
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.7%
******* Domain c best val acc:      83.6%, epoch: 13 *******
******* Domain c best val test acc: 99.8%, epoch: 13 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [14/50] batch [20/203] time 0.102 (0.109) data 0.000 (0.017) loss 1.3669 (1.4052) teacher_loss 0.2257 (0.2549) loss_zs_kd 0.0448 (0.0553) loss_oracle 0.5358 (0.5526) kd_loss 0.8508 (0.8464) acc 93.7500 (92.3438) gate/entropy 1.0413 (1.0413) gate/usage_max 0.4843 (0.4845) gate/usage_min 0.2104 (0.2106) gate/usage_std 0.1135 (0.1136) teacher/entropy 0.0435 (0.0833) teacher/usage_max 0.6598 (0.6206) teacher/usage_min 0.0331 (0.0811) teacher/usage_std 0.2565 (0.2253) nleep/row_max_mean 1497.2327 (1489.5151) nleep/row_max_std 52.4409 (61.1447) nleep/row_min_mean 1476.3645 (1468.0263) lr 1.7290e-03 eta 0:13:38
epoch [14/50] batch [40/203] time 0.091 (0.102) data 0.000 (0.009) loss 1.3942 (1.4135) teacher_loss 0.2302 (0.2603) loss_zs_kd 0.0878 (0.0547) loss_oracle 0.6217 (0.5589) kd_loss 0.8093 (0.8464) acc 96.8750 (92.2656) gate/entropy 1.0412 (1.0413) gate/usage_max 0.4842 (0.4843) gate/usage_min 0.2099 (0.2104) gate/usage_std 0.1136 (0.1136) teacher/entropy 0.1639 (0.0846) teacher/usage_max 0.5744 (0.6260) teacher/usage_min 0.1402 (0.0905) teacher/usage_std 0.1805 (0.2274) nleep/row_max_mean 1496.3242 (1491.7620) nleep/row_max_std 59.3744 (58.6888) nleep/row_min_mean 1477.7373 (1470.5084) lr 1.7290e-03 eta 0:12:38
epoch [14/50] batch [60/203] time 0.097 (0.099) data 0.001 (0.006) loss 1.3531 (1.4341) teacher_loss 0.1375 (0.2501) loss_zs_kd 0.0456 (0.0585) loss_oracle 0.5578 (0.5827) kd_loss 0.9140 (0.8635) acc 93.7500 (92.5000) gate/entropy 1.0414 (1.0413) gate/usage_max 0.4834 (0.4842) gate/usage_min 0.2097 (0.2102) gate/usage_std 0.1133 (0.1136) teacher/entropy 0.0756 (0.0774) teacher/usage_max 0.5638 (0.6127) teacher/usage_min 0.1694 (0.0951) teacher/usage_std 0.1677 (0.2190) nleep/row_max_mean 1478.6310 (1491.4123) nleep/row_max_std 70.1161 (59.1731) nleep/row_min_mean 1460.0408 (1470.1528) lr 1.7290e-03 eta 0:12:21
epoch [14/50] batch [80/203] time 0.095 (0.098) data 0.000 (0.005) loss 1.5489 (1.4301) teacher_loss 0.3392 (0.2329) loss_zs_kd 0.0640 (0.0611) loss_oracle 0.6686 (0.5923) kd_loss 0.8433 (0.8705) acc 93.7500 (93.2422) gate/entropy 1.0415 (1.0414) gate/usage_max 0.4825 (0.4839) gate/usage_min 0.2088 (0.2100) gate/usage_std 0.1131 (0.1135) teacher/entropy 0.1238 (0.0757) teacher/usage_max 0.5487 (0.5983) teacher/usage_min 0.0941 (0.0937) teacher/usage_std 0.1864 (0.2127) nleep/row_max_mean 1504.5735 (1491.8641) nleep/row_max_std 51.6964 (58.5986) nleep/row_min_mean 1484.8815 (1470.6298) lr 1.7290e-03 eta 0:12:10
epoch [14/50] batch [100/203] time 0.099 (0.098) data 0.000 (0.004) loss 1.3229 (1.4252) teacher_loss 0.0602 (0.2171) loss_zs_kd 0.0671 (0.0617) loss_oracle 0.5655 (0.5990) kd_loss 0.9465 (0.8778) acc 100.0000 (93.8438) gate/entropy 1.0420 (1.0415) gate/usage_max 0.4810 (0.4834) gate/usage_min 0.2084 (0.2097) gate/usage_std 0.1125 (0.1133) teacher/entropy 0.0317 (0.0755) teacher/usage_max 0.5017 (0.5879) teacher/usage_min 0.0722 (0.0972) teacher/usage_std 0.1872 (0.2077) nleep/row_max_mean 1488.3608 (1491.5399) nleep/row_max_std 65.6435 (59.0706) nleep/row_min_mean 1467.5543 (1470.3389) lr 1.7290e-03 eta 0:12:08
epoch [14/50] batch [120/203] time 0.099 (0.098) data 0.000 (0.003) loss 1.5735 (1.4276) teacher_loss 0.2911 (0.2106) loss_zs_kd 0.0649 (0.0627) loss_oracle 0.6298 (0.5998) kd_loss 0.9351 (0.8858) acc 93.7500 (94.0885) gate/entropy 1.0423 (1.0416) gate/usage_max 0.4799 (0.4829) gate/usage_min 0.2080 (0.2095) gate/usage_std 0.1120 (0.1131) teacher/entropy 0.0873 (0.0725) teacher/usage_max 0.4842 (0.5814) teacher/usage_min 0.0962 (0.0997) teacher/usage_std 0.1698 (0.2039) nleep/row_max_mean 1486.6053 (1492.1499) nleep/row_max_std 63.6470 (58.5541) nleep/row_min_mean 1465.5107 (1470.8508) lr 1.7290e-03 eta 0:12:04
epoch [14/50] batch [140/203] time 0.098 (0.098) data 0.000 (0.003) loss 1.4574 (1.4274) teacher_loss 0.2250 (0.2073) loss_zs_kd 0.0679 (0.0631) loss_oracle 0.5974 (0.5995) kd_loss 0.8997 (0.8888) acc 93.7500 (94.1295) gate/entropy 1.0428 (1.0417) gate/usage_max 0.4785 (0.4824) gate/usage_min 0.2076 (0.2092) gate/usage_std 0.1115 (0.1129) teacher/entropy 0.0444 (0.0721) teacher/usage_max 0.5548 (0.5761) teacher/usage_min 0.0487 (0.0984) teacher/usage_std 0.2114 (0.2021) nleep/row_max_mean 1490.9471 (1491.9471) nleep/row_max_std 60.2478 (59.3990) nleep/row_min_mean 1466.2428 (1470.6045) lr 1.7290e-03 eta 0:12:01
epoch [14/50] batch [160/203] time 0.092 (0.097) data 0.000 (0.002) loss 1.6972 (1.4326) teacher_loss 0.2702 (0.2012) loss_zs_kd 0.0828 (0.0656) loss_oracle 0.7306 (0.6091) kd_loss 1.0203 (0.8941) acc 84.3750 (94.2969) gate/entropy 1.0432 (1.0419) gate/usage_max 0.4773 (0.4819) gate/usage_min 0.2073 (0.2090) gate/usage_std 0.1110 (0.1127) teacher/entropy 0.0637 (0.0706) teacher/usage_max 0.4520 (0.5691) teacher/usage_min 0.1901 (0.0993) teacher/usage_std 0.1083 (0.1987) nleep/row_max_mean 1478.9150 (1492.0877) nleep/row_max_std 63.5129 (59.1350) nleep/row_min_mean 1457.3900 (1470.6264) lr 1.7290e-03 eta 0:11:55
epoch [14/50] batch [180/203] time 0.101 (0.097) data 0.001 (0.002) loss 1.3756 (1.4287) teacher_loss 0.1104 (0.1935) loss_zs_kd 0.0579 (0.0665) loss_oracle 0.6458 (0.6098) kd_loss 0.9134 (0.8970) acc 96.8750 (94.6007) gate/entropy 1.0433 (1.0420) gate/usage_max 0.4760 (0.4813) gate/usage_min 0.2065 (0.2087) gate/usage_std 0.1106 (0.1125) teacher/entropy 0.1459 (0.0715) teacher/usage_max 0.5247 (0.5640) teacher/usage_min 0.1261 (0.1005) teacher/usage_std 0.1631 (0.1963) nleep/row_max_mean 1500.3022 (1492.3448) nleep/row_max_std 54.6604 (59.0582) nleep/row_min_mean 1479.5063 (1470.8117) lr 1.7290e-03 eta 0:11:52
epoch [14/50] batch [200/203] time 0.092 (0.097) data 0.000 (0.002) loss 1.3418 (1.4330) teacher_loss 0.1749 (0.1929) loss_zs_kd 0.0573 (0.0673) loss_oracle 0.5477 (0.6098) kd_loss 0.8643 (0.9016) acc 96.8750 (94.5312) gate/entropy 1.0440 (1.0422) gate/usage_max 0.4736 (0.4806) gate/usage_min 0.2058 (0.2085) gate/usage_std 0.1097 (0.1123) teacher/entropy 0.0872 (0.0702) teacher/usage_max 0.5431 (0.5591) teacher/usage_min 0.0606 (0.1016) teacher/usage_std 0.2019 (0.1940) nleep/row_max_mean 1486.4799 (1492.2111) nleep/row_max_std 56.8109 (59.2964) nleep/row_min_mean 1463.9275 (1470.6347) lr 1.7290e-03 eta 0:11:45
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,318
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 86.4%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,412
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.6%
******* Domain c best val acc:      83.6%, epoch: 13 *******
******* Domain c best val test acc: 99.8%, epoch: 13 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [15/50] batch [20/203] time 0.086 (0.120) data 0.000 (0.017) loss 1.4688 (1.4810) teacher_loss 0.2253 (0.1850) loss_zs_kd 0.0774 (0.0663) loss_oracle 0.6073 (0.6499) kd_loss 0.9012 (0.9379) acc 93.7500 (94.5312) gate/entropy 1.0442 (1.0441) gate/usage_max 0.4719 (0.4728) gate/usage_min 0.2048 (0.2053) gate/usage_std 0.1093 (0.1095) teacher/entropy 0.0400 (0.0474) teacher/usage_max 0.5339 (0.5112) teacher/usage_min 0.0320 (0.0919) teacher/usage_std 0.2169 (0.1808) nleep/row_max_mean 1509.8311 (1490.4498) nleep/row_max_std 42.6344 (58.4069) nleep/row_min_mean 1486.2761 (1468.0209) lr 1.6845e-03 eta 0:14:36
epoch [15/50] batch [40/203] time 0.089 (0.103) data 0.000 (0.008) loss 1.4128 (1.4694) teacher_loss 0.1335 (0.1711) loss_zs_kd 0.0812 (0.0717) loss_oracle 0.6404 (0.6526) kd_loss 0.9186 (0.9362) acc 100.0000 (95.2344) gate/entropy 1.0447 (1.0442) gate/usage_max 0.4700 (0.4719) gate/usage_min 0.2042 (0.2049) gate/usage_std 0.1086 (0.1092) teacher/entropy 0.0422 (0.0509) teacher/usage_max 0.4898 (0.5146) teacher/usage_min 0.0317 (0.0925) teacher/usage_std 0.2133 (0.1811) nleep/row_max_mean 1506.0203 (1491.6853) nleep/row_max_std 28.4987 (59.8580) nleep/row_min_mean 1481.0829 (1468.6235) lr 1.6845e-03 eta 0:12:28
epoch [15/50] batch [60/203] time 0.064 (0.106) data 0.000 (0.006) loss 1.5446 (1.4830) teacher_loss 0.2373 (0.1733) loss_zs_kd 0.0708 (0.0693) loss_oracle 0.7279 (0.6715) kd_loss 0.9080 (0.9392) acc 93.7500 (94.9479) gate/entropy 1.0449 (1.0444) gate/usage_max 0.4673 (0.4708) gate/usage_min 0.2028 (0.2044) gate/usage_std 0.1080 (0.1089) teacher/entropy 0.0457 (0.0519) teacher/usage_max 0.5294 (0.5188) teacher/usage_min 0.0103 (0.0863) teacher/usage_std 0.2301 (0.1856) nleep/row_max_mean 1510.6941 (1492.9809) nleep/row_max_std 29.5010 (59.8832) nleep/row_min_mean 1483.1533 (1468.9915) lr 1.6845e-03 eta 0:12:45
epoch [15/50] batch [80/203] time 0.084 (0.099) data 0.000 (0.004) loss 1.4882 (1.4911) teacher_loss 0.1204 (0.1778) loss_zs_kd 0.0835 (0.0684) loss_oracle 0.6953 (0.6810) kd_loss 0.9784 (0.9386) acc 96.8750 (94.8438) gate/entropy 1.0456 (1.0446) gate/usage_max 0.4641 (0.4695) gate/usage_min 0.2020 (0.2039) gate/usage_std 0.1070 (0.1086) teacher/entropy 0.0446 (0.0559) teacher/usage_max 0.5338 (0.5229) teacher/usage_min 0.0962 (0.0848) teacher/usage_std 0.1806 (0.1876) nleep/row_max_mean 1492.8142 (1492.3745) nleep/row_max_std 58.1780 (60.0030) nleep/row_min_mean 1464.8911 (1467.6311) lr 1.6845e-03 eta 0:11:58
epoch [15/50] batch [100/203] time 0.070 (0.097) data 0.000 (0.004) loss 1.6258 (1.4990) teacher_loss 0.3212 (0.1839) loss_zs_kd 0.0807 (0.0685) loss_oracle 0.6677 (0.6851) kd_loss 0.9305 (0.9383) acc 93.7500 (94.6562) gate/entropy 1.0456 (1.0449) gate/usage_max 0.4614 (0.4681) gate/usage_min 0.2002 (0.2034) gate/usage_std 0.1067 (0.1082) teacher/entropy 0.0348 (0.0579) teacher/usage_max 0.4865 (0.5333) teacher/usage_min 0.0625 (0.0803) teacher/usage_std 0.1921 (0.1932) nleep/row_max_mean 1495.4380 (1493.2549) nleep/row_max_std 72.3578 (59.9818) nleep/row_min_mean 1467.3569 (1467.7753) lr 1.6845e-03 eta 0:11:36
epoch [15/50] batch [120/203] time 0.084 (0.093) data 0.000 (0.003) loss 1.4248 (1.4984) teacher_loss 0.1429 (0.1881) loss_zs_kd 0.0582 (0.0670) loss_oracle 0.6608 (0.6874) kd_loss 0.9223 (0.9332) acc 96.8750 (94.5833) gate/entropy 1.0460 (1.0450) gate/usage_max 0.4580 (0.4667) gate/usage_min 0.1991 (0.2028) gate/usage_std 0.1059 (0.1079) teacher/entropy 0.0846 (0.0636) teacher/usage_max 0.5357 (0.5388) teacher/usage_min 0.0861 (0.0782) teacher/usage_std 0.1862 (0.1962) nleep/row_max_mean 1488.3306 (1493.8467) nleep/row_max_std 79.6152 (60.0625) nleep/row_min_mean 1459.1598 (1467.6540) lr 1.6845e-03 eta 0:11:09
epoch [15/50] batch [140/203] time 0.077 (0.092) data 0.000 (0.003) loss 1.7114 (1.5111) teacher_loss 0.3819 (0.2033) loss_zs_kd 0.0392 (0.0661) loss_oracle 0.7490 (0.6866) kd_loss 0.9354 (0.9314) acc 84.3750 (94.0179) gate/entropy 1.0464 (1.0452) gate/usage_max 0.4545 (0.4652) gate/usage_min 0.1981 (0.2022) gate/usage_std 0.1051 (0.1075) teacher/entropy 0.1184 (0.0658) teacher/usage_max 0.6711 (0.5521) teacher/usage_min 0.1037 (0.0739) teacher/usage_std 0.2439 (0.2029) nleep/row_max_mean 1487.6689 (1494.5165) nleep/row_max_std 72.2476 (60.0384) nleep/row_min_mean 1457.7040 (1467.5164) lr 1.6845e-03 eta 0:10:56
epoch [15/50] batch [160/203] time 0.099 (0.092) data 0.000 (0.002) loss 1.4544 (1.5254) teacher_loss 0.2036 (0.2209) loss_zs_kd 0.0280 (0.0646) loss_oracle 0.6917 (0.6839) kd_loss 0.8910 (0.9302) acc 93.7500 (93.4375) gate/entropy 1.0466 (1.0454) gate/usage_max 0.4507 (0.4636) gate/usage_min 0.1967 (0.2016) gate/usage_std 0.1046 (0.1072) teacher/entropy 0.1251 (0.0700) teacher/usage_max 0.7578 (0.5668) teacher/usage_min 0.0404 (0.0732) teacher/usage_std 0.3073 (0.2092) nleep/row_max_mean 1496.2756 (1494.6798) nleep/row_max_std 65.0179 (60.8300) nleep/row_min_mean 1462.5581 (1467.0212) lr 1.6845e-03 eta 0:10:58
epoch [15/50] batch [180/203] time 0.095 (0.093) data 0.000 (0.002) loss 1.5356 (1.5431) teacher_loss 0.2919 (0.2425) loss_zs_kd 0.0558 (0.0628) loss_oracle 0.6786 (0.6833) kd_loss 0.8766 (0.9275) acc 90.6250 (92.5174) gate/entropy 1.0465 (1.0455) gate/usage_max 0.4464 (0.4619) gate/usage_min 0.1950 (0.2009) gate/usage_std 0.1042 (0.1069) teacher/entropy 0.1396 (0.0740) teacher/usage_max 0.8536 (0.5926) teacher/usage_min 0.0279 (0.0686) teacher/usage_std 0.3697 (0.2233) nleep/row_max_mean 1502.1804 (1495.4871) nleep/row_max_std 65.3836 (61.2351) nleep/row_min_mean 1463.5490 (1466.8947) lr 1.6845e-03 eta 0:11:04
epoch [15/50] batch [200/203] time 0.090 (0.093) data 0.000 (0.002) loss 1.9516 (1.5643) teacher_loss 0.7102 (0.2662) loss_zs_kd 0.0435 (0.0615) loss_oracle 0.6311 (0.6827) kd_loss 0.9041 (0.9261) acc 78.1250 (91.7812) gate/entropy 1.0461 (1.0456) gate/usage_max 0.4417 (0.4601) gate/usage_min 0.1927 (0.2002) gate/usage_std 0.1042 (0.1066) teacher/entropy 0.1070 (0.0752) teacher/usage_max 0.9417 (0.6183) teacher/usage_min 0.0192 (0.0634) teacher/usage_std 0.4303 (0.2379) nleep/row_max_mean 1486.0576 (1495.8840) nleep/row_max_std 86.2916 (61.8216) nleep/row_min_mean 1449.9990 (1466.3276) lr 1.6845e-03 eta 0:11:01
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,243
* accuracy: 80.3%
* error: 19.7%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,413
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.7%
******* Domain c best val acc:      83.6%, epoch: 13 *******
******* Domain c best val test acc: 99.8%, epoch: 13 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [16/50] batch [20/203] time 0.090 (0.115) data 0.000 (0.015) loss 1.7275 (1.7116) teacher_loss 0.4466 (0.4422) loss_zs_kd 0.0208 (0.0358) loss_oracle 0.7409 (0.6504) kd_loss 0.9000 (0.9263) acc 81.2500 (82.5000) gate/entropy 1.0458 (1.0460) gate/usage_max 0.4363 (0.4385) gate/usage_min 0.1908 (0.1917) gate/usage_std 0.1041 (0.1040) teacher/entropy 0.0873 (0.0628) teacher/usage_max 0.8908 (0.8904) teacher/usage_min 0.0222 (0.0161) teacher/usage_std 0.3951 (0.3957) nleep/row_max_mean 1522.4387 (1503.2708) nleep/row_max_std 48.9380 (66.6570) nleep/row_min_mean 1477.7131 (1464.3387) lr 1.6374e-03 eta 0:13:35
epoch [16/50] batch [40/203] time 0.094 (0.104) data 0.000 (0.008) loss 2.0279 (1.7384) teacher_loss 0.7645 (0.4643) loss_zs_kd 0.0340 (0.0354) loss_oracle 0.5980 (0.6558) kd_loss 0.9473 (0.9285) acc 75.0000 (81.3281) gate/entropy 1.0453 (1.0458) gate/usage_max 0.4317 (0.4362) gate/usage_min 0.1892 (0.1908) gate/usage_std 0.1042 (0.1040) teacher/entropy 0.0191 (0.0561) teacher/usage_max 0.9707 (0.9145) teacher/usage_min 0.0003 (0.0127) teacher/usage_std 0.4508 (0.4122) nleep/row_max_mean 1490.0763 (1504.8031) nleep/row_max_std 89.1014 (65.6951) nleep/row_min_mean 1451.5269 (1465.2350) lr 1.6374e-03 eta 0:12:15
epoch [16/50] batch [60/203] time 0.094 (0.101) data 0.000 (0.005) loss 1.6342 (1.7306) teacher_loss 0.4180 (0.4618) loss_zs_kd 0.0237 (0.0342) loss_oracle 0.5951 (0.6529) kd_loss 0.9068 (0.9253) acc 78.1250 (81.3021) gate/entropy 1.0448 (1.0455) gate/usage_max 0.4276 (0.4339) gate/usage_min 0.1878 (0.1900) gate/usage_std 0.1044 (0.1041) teacher/entropy 0.0439 (0.0523) teacher/usage_max 0.9555 (0.9266) teacher/usage_min 0.0000 (0.0108) teacher/usage_std 0.4403 (0.4205) nleep/row_max_mean 1514.1915 (1506.0825) nleep/row_max_std 53.3492 (66.3398) nleep/row_min_mean 1472.7235 (1466.2419) lr 1.6374e-03 eta 0:11:48
epoch [16/50] batch [80/203] time 0.093 (0.099) data 0.000 (0.004) loss 1.5737 (1.7377) teacher_loss 0.3274 (0.4717) loss_zs_kd 0.0262 (0.0338) loss_oracle 0.6248 (0.6495) kd_loss 0.9207 (0.9244) acc 84.3750 (81.2109) gate/entropy 1.0441 (1.0452) gate/usage_max 0.4231 (0.4317) gate/usage_min 0.1863 (0.1892) gate/usage_std 0.1048 (0.1043) teacher/entropy 0.0183 (0.0461) teacher/usage_max 0.9698 (0.9347) teacher/usage_min 0.0018 (0.0094) teacher/usage_std 0.4502 (0.4260) nleep/row_max_mean 1515.6625 (1506.3728) nleep/row_max_std 58.2034 (67.6322) nleep/row_min_mean 1471.3715 (1466.0390) lr 1.6374e-03 eta 0:11:35
epoch [16/50] batch [100/203] time 0.073 (0.098) data 0.000 (0.003) loss 1.6414 (1.7433) teacher_loss 0.4355 (0.4828) loss_zs_kd 0.0242 (0.0322) loss_oracle 0.5608 (0.6427) kd_loss 0.9133 (0.9231) acc 87.5000 (81.2188) gate/entropy 1.0437 (1.0449) gate/usage_max 0.4193 (0.4296) gate/usage_min 0.1854 (0.1884) gate/usage_std 0.1051 (0.1045) teacher/entropy 0.0164 (0.0402) teacher/usage_max 0.9963 (0.9433) teacher/usage_min 0.0012 (0.0079) teacher/usage_std 0.4688 (0.4320) nleep/row_max_mean 1499.8077 (1508.0080) nleep/row_max_std 70.5381 (66.9673) nleep/row_min_mean 1458.3159 (1467.2977) lr 1.6374e-03 eta 0:11:26
epoch [16/50] batch [120/203] time 0.096 (0.099) data 0.000 (0.003) loss 1.6012 (1.7419) teacher_loss 0.3926 (0.4871) loss_zs_kd 0.0196 (0.0310) loss_oracle 0.5866 (0.6381) kd_loss 0.9055 (0.9203) acc 87.5000 (81.4062) gate/entropy 1.0428 (1.0446) gate/usage_max 0.4159 (0.4276) gate/usage_min 0.1839 (0.1878) gate/usage_std 0.1059 (0.1047) teacher/entropy 0.0107 (0.0364) teacher/usage_max 0.9975 (0.9490) teacher/usage_min 0.0008 (0.0073) teacher/usage_std 0.4697 (0.4359) nleep/row_max_mean 1499.9099 (1507.5160) nleep/row_max_std 80.5105 (67.6172) nleep/row_min_mean 1461.4794 (1467.0367) lr 1.6374e-03 eta 0:11:30
epoch [16/50] batch [140/203] time 0.092 (0.099) data 0.000 (0.002) loss 1.7178 (1.7430) teacher_loss 0.5848 (0.4952) loss_zs_kd 0.0263 (0.0293) loss_oracle 0.5106 (0.6329) kd_loss 0.8645 (0.9167) acc 78.1250 (80.9821) gate/entropy 1.0422 (1.0443) gate/usage_max 0.4124 (0.4257) gate/usage_min 0.1831 (0.1872) gate/usage_std 0.1063 (0.1049) teacher/entropy 0.0405 (0.0338) teacher/usage_max 0.9836 (0.9539) teacher/usage_min 0.0003 (0.0066) teacher/usage_std 0.4599 (0.4393) nleep/row_max_mean 1520.6229 (1507.8738) nleep/row_max_std 61.9926 (67.4276) nleep/row_min_mean 1480.3285 (1467.2577) lr 1.6374e-03 eta 0:11:27
epoch [16/50] batch [160/203] time 0.102 (0.100) data 0.000 (0.002) loss 1.7583 (1.7459) teacher_loss 0.5444 (0.5019) loss_zs_kd 0.0144 (0.0279) loss_oracle 0.6592 (0.6330) kd_loss 0.8771 (0.9135) acc 81.2500 (80.5664) gate/entropy 1.0419 (1.0440) gate/usage_max 0.4091 (0.4238) gate/usage_min 0.1826 (0.1866) gate/usage_std 0.1066 (0.1051) teacher/entropy 0.0229 (0.0322) teacher/usage_max 0.9934 (0.9559) teacher/usage_min 0.0015 (0.0067) teacher/usage_std 0.4667 (0.4407) nleep/row_max_mean 1506.7623 (1508.4750) nleep/row_max_std 81.3972 (67.2076) nleep/row_min_mean 1468.3029 (1467.8315) lr 1.6374e-03 eta 0:11:34
epoch [16/50] batch [180/203] time 0.101 (0.100) data 0.000 (0.002) loss 1.6676 (1.7420) teacher_loss 0.4668 (0.5029) loss_zs_kd 0.0061 (0.0266) loss_oracle 0.6747 (0.6307) kd_loss 0.8604 (0.9104) acc 75.0000 (80.6424) gate/entropy 1.0414 (1.0438) gate/usage_max 0.4121 (0.4223) gate/usage_min 0.1820 (0.1861) gate/usage_std 0.1070 (0.1053) teacher/entropy 0.0312 (0.0298) teacher/usage_max 0.9876 (0.9594) teacher/usage_min 0.0061 (0.0063) teacher/usage_std 0.4626 (0.4431) nleep/row_max_mean 1508.0452 (1509.0757) nleep/row_max_std 77.4545 (66.7322) nleep/row_min_mean 1465.7059 (1468.4338) lr 1.6374e-03 eta 0:11:29
epoch [16/50] batch [200/203] time 0.092 (0.099) data 0.000 (0.002) loss 1.6775 (1.7385) teacher_loss 0.4781 (0.5056) loss_zs_kd 0.0184 (0.0256) loss_oracle 0.6371 (0.6265) kd_loss 0.8717 (0.9069) acc 81.2500 (80.7656) gate/entropy 1.0411 (1.0435) gate/usage_max 0.4158 (0.4215) gate/usage_min 0.1818 (0.1857) gate/usage_std 0.1073 (0.1055) teacher/entropy 0.0062 (0.0282) teacher/usage_max 0.9987 (0.9621) teacher/usage_min 0.0003 (0.0058) teacher/usage_std 0.4705 (0.4449) nleep/row_max_mean 1502.0686 (1508.8483) nleep/row_max_std 81.9507 (67.5473) nleep/row_min_mean 1461.4282 (1468.1337) lr 1.6374e-03 eta 0:11:23
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,335
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      83.6%, epoch: 13 *******
******* Domain c best val test acc: 99.8%, epoch: 13 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [17/50] batch [20/203] time 0.093 (0.111) data 0.000 (0.018) loss 1.7331 (1.7395) teacher_loss 0.5759 (0.5600) loss_zs_kd 0.0123 (0.0163) loss_oracle 0.5755 (0.6019) kd_loss 0.8633 (0.8704) acc 75.0000 (78.4375) gate/entropy 1.0405 (1.0408) gate/usage_max 0.4200 (0.4183) gate/usage_min 0.1813 (0.1815) gate/usage_std 0.1079 (0.1076) teacher/entropy 0.0049 (0.0060) teacher/usage_max 0.9990 (0.9938) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4707 (0.4670) nleep/row_max_mean 1506.8933 (1508.7703) nleep/row_max_std 75.7290 (68.8781) nleep/row_min_mean 1465.4753 (1468.2099) lr 1.5878e-03 eta 0:12:45
epoch [17/50] batch [40/203] time 0.096 (0.101) data 0.000 (0.009) loss 1.6564 (1.7314) teacher_loss 0.4918 (0.5626) loss_zs_kd 0.0162 (0.0166) loss_oracle 0.5972 (0.5885) kd_loss 0.8580 (0.8662) acc 75.0000 (78.6719) gate/entropy 1.0403 (1.0407) gate/usage_max 0.4235 (0.4200) gate/usage_min 0.1812 (0.1815) gate/usage_std 0.1082 (0.1078) teacher/entropy 0.0014 (0.0063) teacher/usage_max 0.9998 (0.9938) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4712 (0.4671) nleep/row_max_mean 1514.9487 (1511.5043) nleep/row_max_std 73.0500 (68.1789) nleep/row_min_mean 1469.3865 (1470.2427) lr 1.5878e-03 eta 0:11:35
epoch [17/50] batch [60/203] time 0.096 (0.098) data 0.000 (0.006) loss 1.6007 (1.7028) teacher_loss 0.4760 (0.5371) loss_zs_kd 0.0119 (0.0148) loss_oracle 0.5354 (0.5919) kd_loss 0.8510 (0.8624) acc 78.1250 (79.2188) gate/entropy 1.0404 (1.0406) gate/usage_max 0.4266 (0.4216) gate/usage_min 0.1817 (0.1815) gate/usage_std 0.1082 (0.1079) teacher/entropy 0.0010 (0.0066) teacher/usage_max 0.9998 (0.9931) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4713 (0.4665) nleep/row_max_mean 1517.9634 (1510.1022) nleep/row_max_std 58.6541 (70.4000) nleep/row_min_mean 1477.4254 (1469.1111) lr 1.5878e-03 eta 0:11:12
epoch [17/50] batch [80/203] time 0.095 (0.097) data 0.000 (0.005) loss 1.5899 (1.6890) teacher_loss 0.4746 (0.5294) loss_zs_kd 0.0145 (0.0147) loss_oracle 0.5357 (0.5873) kd_loss 0.8402 (0.8587) acc 81.2500 (79.3750) gate/entropy 1.0399 (1.0405) gate/usage_max 0.4304 (0.4233) gate/usage_min 0.1815 (0.1815) gate/usage_std 0.1088 (0.1080) teacher/entropy 0.0028 (0.0070) teacher/usage_max 0.9995 (0.9922) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4710 (0.4660) nleep/row_max_mean 1533.5983 (1510.9840) nleep/row_max_std 60.7683 (69.0398) nleep/row_min_mean 1490.2388 (1470.0577) lr 1.5878e-03 eta 0:11:03
epoch [17/50] batch [100/203] time 0.080 (0.097) data 0.000 (0.004) loss 1.8390 (1.6767) teacher_loss 0.7129 (0.5230) loss_zs_kd 0.0063 (0.0143) loss_oracle 0.6022 (0.5849) kd_loss 0.8219 (0.8542) acc 78.1250 (79.7812) gate/entropy 1.0400 (1.0404) gate/usage_max 0.4335 (0.4250) gate/usage_min 0.1821 (0.1816) gate/usage_std 0.1088 (0.1081) teacher/entropy 0.0168 (0.0070) teacher/usage_max 0.9958 (0.9926) teacher/usage_min 0.0009 (0.0003) teacher/usage_std 0.4685 (0.4662) nleep/row_max_mean 1504.2673 (1512.7386) nleep/row_max_std 83.3732 (67.7447) nleep/row_min_mean 1466.1626 (1471.8565) lr 1.5878e-03 eta 0:10:59
epoch [17/50] batch [120/203] time 0.091 (0.096) data 0.000 (0.003) loss 1.8332 (1.6742) teacher_loss 0.6766 (0.5242) loss_zs_kd 0.0149 (0.0145) loss_oracle 0.6508 (0.5847) kd_loss 0.8238 (0.8504) acc 78.1250 (79.9479) gate/entropy 1.0400 (1.0403) gate/usage_max 0.4373 (0.4268) gate/usage_min 0.1827 (0.1818) gate/usage_std 0.1090 (0.1083) teacher/entropy 0.0040 (0.0069) teacher/usage_max 0.9993 (0.9922) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4709 (0.4659) nleep/row_max_mean 1508.4209 (1512.8982) nleep/row_max_std 79.3160 (67.5673) nleep/row_min_mean 1467.7942 (1472.2920) lr 1.5878e-03 eta 0:10:53
epoch [17/50] batch [140/203] time 0.095 (0.096) data 0.000 (0.003) loss 1.5343 (1.6678) teacher_loss 0.4489 (0.5233) loss_zs_kd 0.0121 (0.0144) loss_oracle 0.5644 (0.5815) kd_loss 0.7971 (0.8465) acc 81.2500 (79.8884) gate/entropy 1.0399 (1.0403) gate/usage_max 0.4411 (0.4285) gate/usage_min 0.1835 (0.1819) gate/usage_std 0.1093 (0.1084) teacher/entropy 0.0341 (0.0068) teacher/usage_max 0.9832 (0.9921) teacher/usage_min 0.0028 (0.0004) teacher/usage_std 0.4595 (0.4659) nleep/row_max_mean 1510.3020 (1512.7489) nleep/row_max_std 63.5050 (67.5803) nleep/row_min_mean 1474.6785 (1472.3872) lr 1.5878e-03 eta 0:10:50
epoch [17/50] batch [160/203] time 0.098 (0.096) data 0.000 (0.002) loss 1.8470 (1.6615) teacher_loss 0.7046 (0.5213) loss_zs_kd 0.0213 (0.0140) loss_oracle 0.5956 (0.5807) kd_loss 0.8340 (0.8428) acc 71.8750 (79.9805) gate/entropy 1.0400 (1.0402) gate/usage_max 0.4452 (0.4304) gate/usage_min 0.1845 (0.1822) gate/usage_std 0.1096 (0.1085) teacher/entropy 0.0027 (0.0071) teacher/usage_max 0.9683 (0.9913) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4492 (0.4653) nleep/row_max_mean 1515.4070 (1512.9792) nleep/row_max_std 45.8482 (67.1691) nleep/row_min_mean 1476.0734 (1472.7171) lr 1.5878e-03 eta 0:10:48
epoch [17/50] batch [180/203] time 0.093 (0.096) data 0.000 (0.002) loss 1.4737 (1.6521) teacher_loss 0.3773 (0.5177) loss_zs_kd 0.0200 (0.0141) loss_oracle 0.5858 (0.5783) kd_loss 0.7935 (0.8383) acc 81.2500 (80.1736) gate/entropy 1.0395 (1.0402) gate/usage_max 0.4499 (0.4323) gate/usage_min 0.1852 (0.1825) gate/usage_std 0.1103 (0.1087) teacher/entropy 0.0062 (0.0071) teacher/usage_max 0.9988 (0.9915) teacher/usage_min 0.0002 (0.0003) teacher/usage_std 0.4706 (0.4654) nleep/row_max_mean 1515.8918 (1512.7454) nleep/row_max_std 62.0051 (67.3389) nleep/row_min_mean 1474.2095 (1472.6360) lr 1.5878e-03 eta 0:10:46
epoch [17/50] batch [200/203] time 0.086 (0.096) data 0.000 (0.002) loss 1.4647 (1.6395) teacher_loss 0.3804 (0.5104) loss_zs_kd 0.0133 (0.0139) loss_oracle 0.5787 (0.5773) kd_loss 0.7882 (0.8335) acc 84.3750 (80.3750) gate/entropy 1.0394 (1.0401) gate/usage_max 0.4545 (0.4343) gate/usage_min 0.1865 (0.1828) gate/usage_std 0.1109 (0.1089) teacher/entropy 0.0005 (0.0072) teacher/usage_max 0.9999 (0.9918) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4714 (0.4656) nleep/row_max_mean 1507.8849 (1512.6729) nleep/row_max_std 76.6798 (67.1783) nleep/row_min_mean 1465.7396 (1472.7162) lr 1.5878e-03 eta 0:10:43
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,341
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 87.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.8%, epoch: 17 *******
******* Domain c best val test acc: 100.0%, epoch: 17 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [18/50] batch [20/203] time 0.106 (0.101) data 0.000 (0.015) loss 1.5024 (1.5397) teacher_loss 0.4226 (0.4775) loss_zs_kd 0.0045 (0.0102) loss_oracle 0.5566 (0.5507) kd_loss 0.7993 (0.7817) acc 84.3750 (81.8750) gate/entropy 1.0391 (1.0390) gate/usage_max 0.4597 (0.4579) gate/usage_min 0.1881 (0.1873) gate/usage_std 0.1117 (0.1115) teacher/entropy 0.0062 (0.0121) teacher/usage_max 0.9676 (0.9841) teacher/usage_min 0.0003 (0.0002) teacher/usage_std 0.4487 (0.4603) nleep/row_max_mean 1478.6335 (1511.0270) nleep/row_max_std 82.5161 (66.1252) nleep/row_min_mean 1446.8655 (1472.1933) lr 1.5358e-03 eta 0:11:15
epoch [18/50] batch [40/203] time 0.091 (0.094) data 0.000 (0.008) loss 1.7548 (1.5427) teacher_loss 0.6948 (0.4856) loss_zs_kd 0.0265 (0.0119) loss_oracle 0.5847 (0.5507) kd_loss 0.7544 (0.7759) acc 78.1250 (81.7188) gate/entropy 1.0381 (1.0387) gate/usage_max 0.4657 (0.4606) gate/usage_min 0.1893 (0.1880) gate/usage_std 0.1131 (0.1120) teacher/entropy 0.0127 (0.0117) teacher/usage_max 0.9968 (0.9849) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4691 (0.4608) nleep/row_max_mean 1498.6902 (1510.4917) nleep/row_max_std 73.7078 (65.8160) nleep/row_min_mean 1462.7328 (1472.3185) lr 1.5358e-03 eta 0:10:24
epoch [18/50] batch [60/203] time 0.089 (0.091) data 0.001 (0.005) loss 1.8080 (1.5289) teacher_loss 0.7782 (0.4789) loss_zs_kd 0.0119 (0.0113) loss_oracle 0.4997 (0.5484) kd_loss 0.7740 (0.7701) acc 65.6250 (81.7188) gate/entropy 1.0371 (1.0384) gate/usage_max 0.4716 (0.4633) gate/usage_min 0.1908 (0.1887) gate/usage_std 0.1147 (0.1126) teacher/entropy 0.0198 (0.0116) teacher/usage_max 0.9339 (0.9851) teacher/usage_min 0.0299 (0.0007) teacher/usage_std 0.4247 (0.4610) nleep/row_max_mean 1501.1155 (1509.2524) nleep/row_max_std 73.8184 (67.2042) nleep/row_min_mean 1464.4875 (1471.5646) lr 1.5358e-03 eta 0:10:04
epoch [18/50] batch [80/203] time 0.085 (0.090) data 0.000 (0.004) loss 1.2829 (1.5113) teacher_loss 0.2823 (0.4708) loss_zs_kd 0.0076 (0.0109) loss_oracle 0.5263 (0.5424) kd_loss 0.7336 (0.7638) acc 93.7500 (81.9922) gate/entropy 1.0359 (1.0380) gate/usage_max 0.4776 (0.4661) gate/usage_min 0.1925 (0.1895) gate/usage_std 0.1164 (0.1134) teacher/entropy 0.0066 (0.0117) teacher/usage_max 0.9986 (0.9854) teacher/usage_min 0.0003 (0.0005) teacher/usage_std 0.4704 (0.4612) nleep/row_max_mean 1507.0125 (1510.1037) nleep/row_max_std 71.7382 (66.5782) nleep/row_min_mean 1475.1013 (1472.7664) lr 1.5358e-03 eta 0:09:53
epoch [18/50] batch [100/203] time 0.075 (0.089) data 0.000 (0.003) loss 1.6584 (1.5142) teacher_loss 0.6606 (0.4848) loss_zs_kd 0.0154 (0.0106) loss_oracle 0.5453 (0.5344) kd_loss 0.7175 (0.7569) acc 75.0000 (81.5938) gate/entropy 1.0344 (1.0374) gate/usage_max 0.4838 (0.4690) gate/usage_min 0.1942 (0.1903) gate/usage_std 0.1185 (0.1142) teacher/entropy 0.0219 (0.0116) teacher/usage_max 0.9854 (0.9866) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4611 (0.4620) nleep/row_max_mean 1488.6763 (1509.9732) nleep/row_max_std 86.0448 (66.8137) nleep/row_min_mean 1454.4977 (1472.9597) lr 1.5358e-03 eta 0:09:48
epoch [18/50] batch [120/203] time 0.087 (0.088) data 0.000 (0.003) loss 1.3760 (1.5092) teacher_loss 0.3975 (0.4857) loss_zs_kd 0.0153 (0.0109) loss_oracle 0.5239 (0.5335) kd_loss 0.7089 (0.7513) acc 78.1250 (81.3281) gate/entropy 1.0326 (1.0368) gate/usage_max 0.4902 (0.4720) gate/usage_min 0.1961 (0.1911) gate/usage_std 0.1209 (0.1151) teacher/entropy 0.0050 (0.0114) teacher/usage_max 0.9991 (0.9861) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4707 (0.4617) nleep/row_max_mean 1509.5344 (1510.0009) nleep/row_max_std 73.7779 (66.2897) nleep/row_min_mean 1472.1843 (1473.0467) lr 1.5358e-03 eta 0:09:39
epoch [18/50] batch [140/203] time 0.078 (0.088) data 0.000 (0.002) loss 1.2261 (1.5045) teacher_loss 0.2389 (0.4871) loss_zs_kd 0.0160 (0.0112) loss_oracle 0.5775 (0.5327) kd_loss 0.6905 (0.7454) acc 90.6250 (81.1830) gate/entropy 1.0311 (1.0361) gate/usage_max 0.4952 (0.4750) gate/usage_min 0.1980 (0.1920) gate/usage_std 0.1228 (0.1161) teacher/entropy 0.0502 (0.0122) teacher/usage_max 0.9585 (0.9849) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4424 (0.4608) nleep/row_max_mean 1485.7366 (1509.6994) nleep/row_max_std 82.9862 (66.6197) nleep/row_min_mean 1453.1047 (1472.7738) lr 1.5358e-03 eta 0:09:36
epoch [18/50] batch [160/203] time 0.086 (0.087) data 0.000 (0.002) loss 1.4876 (1.5000) teacher_loss 0.5347 (0.4911) loss_zs_kd 0.0157 (0.0113) loss_oracle 0.5074 (0.5282) kd_loss 0.6914 (0.7391) acc 81.2500 (81.0742) gate/entropy 1.0281 (1.0352) gate/usage_max 0.5028 (0.4781) gate/usage_min 0.1997 (0.1928) gate/usage_std 0.1263 (0.1172) teacher/entropy 0.0388 (0.0121) teacher/usage_max 0.9420 (0.9849) teacher/usage_min 0.0269 (0.0007) teacher/usage_std 0.4304 (0.4608) nleep/row_max_mean 1491.3037 (1510.1221) nleep/row_max_std 86.1114 (66.5066) nleep/row_min_mean 1456.7681 (1473.1785) lr 1.5358e-03 eta 0:09:29
epoch [18/50] batch [180/203] time 0.069 (0.087) data 0.000 (0.002) loss 1.5208 (1.4950) teacher_loss 0.6204 (0.4946) loss_zs_kd 0.0081 (0.0113) loss_oracle 0.4463 (0.5247) kd_loss 0.6732 (0.7324) acc 65.6250 (80.7118) gate/entropy 1.0256 (1.0343) gate/usage_max 0.5087 (0.4812) gate/usage_min 0.2015 (0.1937) gate/usage_std 0.1291 (0.1184) teacher/entropy 0.0033 (0.0117) teacher/usage_max 0.9995 (0.9858) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4710 (0.4614) nleep/row_max_mean 1487.8684 (1510.8128) nleep/row_max_std 83.8398 (65.9976) nleep/row_min_mean 1456.1982 (1473.7090) lr 1.5358e-03 eta 0:09:25
epoch [18/50] batch [200/203] time 0.086 (0.087) data 0.000 (0.002) loss 1.4269 (1.4929) teacher_loss 0.5518 (0.5000) loss_zs_kd 0.0089 (0.0111) loss_oracle 0.4162 (0.5221) kd_loss 0.6625 (0.7263) acc 87.5000 (80.6094) gate/entropy 1.0221 (1.0332) gate/usage_max 0.5155 (0.4843) gate/usage_min 0.2030 (0.1945) gate/usage_std 0.1328 (0.1196) teacher/entropy 0.0000 (0.0117) teacher/usage_max 1.0000 (0.9857) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4714 (0.4614) nleep/row_max_mean 1533.2004 (1510.7999) nleep/row_max_std 51.5902 (66.4151) nleep/row_min_mean 1492.2971 (1473.5218) lr 1.5358e-03 eta 0:09:23
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,337
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      83.8%, epoch: 17 *******
******* Domain c best val test acc: 100.0%, epoch: 17 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [19/50] batch [20/203] time 0.090 (0.112) data 0.000 (0.019) loss 1.3439 (1.3771) teacher_loss 0.4631 (0.4855) loss_zs_kd 0.0115 (0.0132) loss_oracle 0.4750 (0.4652) kd_loss 0.6375 (0.6524) acc 84.3750 (80.4688) gate/entropy 1.0193 (1.0205) gate/usage_max 0.5208 (0.5186) gate/usage_min 0.2046 (0.2040) gate/usage_std 0.1356 (0.1344) teacher/entropy 0.0353 (0.0095) teacher/usage_max 0.9782 (0.9943) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4561 (0.4674) nleep/row_max_mean 1508.1354 (1514.7721) nleep/row_max_std 78.2055 (67.7353) nleep/row_min_mean 1467.3676 (1475.2163) lr 1.4818e-03 eta 0:12:05
epoch [19/50] batch [40/203] time 0.090 (0.101) data 0.000 (0.010) loss 1.4891 (1.3811) teacher_loss 0.5260 (0.4886) loss_zs_kd 0.0126 (0.0130) loss_oracle 0.5874 (0.4689) kd_loss 0.6631 (0.6515) acc 71.8750 (81.0938) gate/entropy 1.0162 (1.0191) gate/usage_max 0.5261 (0.5210) gate/usage_min 0.2059 (0.2046) gate/usage_std 0.1387 (0.1358) teacher/entropy 0.0114 (0.0090) teacher/usage_max 0.9652 (0.9908) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4471 (0.4649) nleep/row_max_mean 1525.6963 (1513.5072) nleep/row_max_std 51.0119 (66.8902) nleep/row_min_mean 1487.3096 (1474.1262) lr 1.4818e-03 eta 0:10:49
epoch [19/50] batch [60/203] time 0.094 (0.100) data 0.000 (0.007) loss 1.5046 (1.3695) teacher_loss 0.6210 (0.4825) loss_zs_kd 0.0086 (0.0134) loss_oracle 0.5191 (0.4680) kd_loss 0.6197 (0.6463) acc 78.1250 (81.1979) gate/entropy 1.0135 (1.0178) gate/usage_max 0.5304 (0.5233) gate/usage_min 0.2070 (0.2053) gate/usage_std 0.1412 (0.1371) teacher/entropy 0.0369 (0.0119) teacher/usage_max 0.9759 (0.9885) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4545 (0.4634) nleep/row_max_mean 1514.4642 (1511.1270) nleep/row_max_std 76.7242 (70.0553) nleep/row_min_mean 1472.4888 (1472.2130) lr 1.4818e-03 eta 0:10:45
epoch [19/50] batch [80/203] time 0.095 (0.098) data 0.000 (0.005) loss 1.2667 (1.3743) teacher_loss 0.3829 (0.4907) loss_zs_kd 0.0095 (0.0130) loss_oracle 0.5274 (0.4676) kd_loss 0.6154 (0.6433) acc 81.2500 (81.2500) gate/entropy 1.0116 (1.0164) gate/usage_max 0.5334 (0.5255) gate/usage_min 0.2080 (0.2058) gate/usage_std 0.1429 (0.1384) teacher/entropy 0.0183 (0.0108) teacher/usage_max 0.9945 (0.9884) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4675 (0.4633) nleep/row_max_mean 1505.9812 (1511.5731) nleep/row_max_std 68.9224 (69.4059) nleep/row_min_mean 1464.7095 (1472.7510) lr 1.4818e-03 eta 0:10:30
epoch [19/50] batch [100/203] time 0.090 (0.097) data 0.000 (0.004) loss 1.0877 (1.3768) teacher_loss 0.2258 (0.4983) loss_zs_kd 0.0128 (0.0124) loss_oracle 0.4687 (0.4647) kd_loss 0.6212 (0.6399) acc 90.6250 (80.6250) gate/entropy 1.0089 (1.0151) gate/usage_max 0.5373 (0.5276) gate/usage_min 0.2089 (0.2063) gate/usage_std 0.1454 (0.1396) teacher/entropy 0.0000 (0.0102) teacher/usage_max 1.0000 (0.9886) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4634) nleep/row_max_mean 1508.1282 (1510.9843) nleep/row_max_std 63.1539 (69.5814) nleep/row_min_mean 1468.3501 (1472.2521) lr 1.4818e-03 eta 0:10:22
epoch [19/50] batch [120/203] time 0.101 (0.099) data 0.000 (0.003) loss 1.2742 (1.3691) teacher_loss 0.4624 (0.4966) loss_zs_kd 0.0106 (0.0122) loss_oracle 0.3949 (0.4609) kd_loss 0.6091 (0.6360) acc 81.2500 (80.7552) gate/entropy 1.0066 (1.0138) gate/usage_max 0.5404 (0.5295) gate/usage_min 0.2096 (0.2068) gate/usage_std 0.1473 (0.1408) teacher/entropy 0.0087 (0.0104) teacher/usage_max 0.9975 (0.9887) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4697 (0.4635) nleep/row_max_mean 1516.5133 (1511.2381) nleep/row_max_std 64.5284 (68.9789) nleep/row_min_mean 1477.3678 (1472.4732) lr 1.4818e-03 eta 0:10:32
epoch [19/50] batch [140/203] time 0.090 (0.098) data 0.000 (0.003) loss 1.4165 (1.3620) teacher_loss 0.5569 (0.4938) loss_zs_kd 0.0167 (0.0120) loss_oracle 0.4684 (0.4588) kd_loss 0.6171 (0.6328) acc 75.0000 (81.0045) gate/entropy 1.0043 (1.0126) gate/usage_max 0.5436 (0.5313) gate/usage_min 0.2102 (0.2073) gate/usage_std 0.1494 (0.1418) teacher/entropy 0.0330 (0.0109) teacher/usage_max 0.9571 (0.9880) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4414 (0.4630) nleep/row_max_mean 1513.3367 (1511.1314) nleep/row_max_std 72.2815 (68.7352) nleep/row_min_mean 1474.0404 (1472.5000) lr 1.4818e-03 eta 0:10:20
epoch [19/50] batch [160/203] time 0.098 (0.097) data 0.000 (0.003) loss 1.2236 (1.3627) teacher_loss 0.4213 (0.4993) loss_zs_kd 0.0124 (0.0119) loss_oracle 0.3847 (0.4561) kd_loss 0.6038 (0.6294) acc 78.1250 (80.8008) gate/entropy 1.0024 (1.0115) gate/usage_max 0.5461 (0.5330) gate/usage_min 0.2107 (0.2077) gate/usage_std 0.1510 (0.1429) teacher/entropy 0.0015 (0.0114) teacher/usage_max 0.9998 (0.9877) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4712 (0.4628) nleep/row_max_mean 1510.5610 (1510.7105) nleep/row_max_std 71.8053 (69.0323) nleep/row_min_mean 1472.2858 (1472.1065) lr 1.4818e-03 eta 0:10:13
epoch [19/50] batch [180/203] time 0.089 (0.096) data 0.000 (0.002) loss 1.2655 (1.3493) teacher_loss 0.4451 (0.4894) loss_zs_kd 0.0156 (0.0117) loss_oracle 0.3879 (0.4542) kd_loss 0.6186 (0.6270) acc 84.3750 (81.2674) gate/entropy 1.0003 (1.0104) gate/usage_max 0.5486 (0.5345) gate/usage_min 0.2111 (0.2080) gate/usage_std 0.1527 (0.1438) teacher/entropy 0.0172 (0.0114) teacher/usage_max 0.9624 (0.9872) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4451 (0.4625) nleep/row_max_mean 1516.8982 (1510.7897) nleep/row_max_std 73.4016 (68.9598) nleep/row_min_mean 1477.7264 (1472.2422) lr 1.4818e-03 eta 0:10:07
epoch [19/50] batch [200/203] time 0.082 (0.095) data 0.000 (0.002) loss 1.4616 (1.3500) teacher_loss 0.5548 (0.4933) loss_zs_kd 0.0120 (0.0119) loss_oracle 0.5223 (0.4531) kd_loss 0.6397 (0.6242) acc 75.0000 (80.9531) gate/entropy 0.9993 (1.0094) gate/usage_max 0.5499 (0.5360) gate/usage_min 0.2115 (0.2084) gate/usage_std 0.1536 (0.1448) teacher/entropy 0.0406 (0.0120) teacher/usage_max 0.9133 (0.9867) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4116 (0.4621) nleep/row_max_mean 1511.6404 (1510.3284) nleep/row_max_std 68.5215 (69.4233) nleep/row_min_mean 1476.3135 (1472.0028) lr 1.4818e-03 eta 0:09:57
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,334
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      83.8%, epoch: 17 *******
******* Domain c best val test acc: 100.0%, epoch: 17 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [20/50] batch [20/203] time 0.088 (0.113) data 0.000 (0.013) loss 1.2694 (1.3390) teacher_loss 0.4344 (0.5151) loss_zs_kd 0.0130 (0.0113) loss_oracle 0.4895 (0.4454) kd_loss 0.5837 (0.5956) acc 84.3750 (79.3750) gate/entropy 0.9982 (0.9984) gate/usage_max 0.5513 (0.5511) gate/usage_min 0.2120 (0.2118) gate/usage_std 0.1545 (0.1543) teacher/entropy 0.0169 (0.0150) teacher/usage_max 0.9946 (0.9844) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4676 (0.4605) nleep/row_max_mean 1515.9443 (1512.5624) nleep/row_max_std 50.6671 (65.2666) nleep/row_min_mean 1476.2065 (1474.9754) lr 1.4258e-03 eta 0:11:46
epoch [20/50] batch [40/203] time 0.114 (0.106) data 0.000 (0.007) loss 1.4682 (1.3400) teacher_loss 0.6355 (0.5144) loss_zs_kd 0.0186 (0.0114) loss_oracle 0.4606 (0.4434) kd_loss 0.5931 (0.5981) acc 75.0000 (79.9219) gate/entropy 0.9964 (0.9977) gate/usage_max 0.5534 (0.5519) gate/usage_min 0.2122 (0.2119) gate/usage_std 0.1559 (0.1549) teacher/entropy 0.0367 (0.0136) teacher/usage_max 0.9572 (0.9816) teacher/usage_min 0.0149 (0.0006) teacher/usage_std 0.4412 (0.4585) nleep/row_max_mean 1525.3164 (1513.4409) nleep/row_max_std 30.0866 (64.1789) nleep/row_min_mean 1487.4380 (1475.8288) lr 1.4258e-03 eta 0:11:03
epoch [20/50] batch [60/203] time 0.094 (0.104) data 0.000 (0.004) loss 1.3072 (1.3064) teacher_loss 0.5302 (0.4859) loss_zs_kd 0.0115 (0.0117) loss_oracle 0.3858 (0.4371) kd_loss 0.5783 (0.5961) acc 78.1250 (80.9896) gate/entropy 0.9956 (0.9971) gate/usage_max 0.5544 (0.5526) gate/usage_min 0.2124 (0.2121) gate/usage_std 0.1565 (0.1554) teacher/entropy 0.0217 (0.0156) teacher/usage_max 0.9894 (0.9803) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4639 (0.4576) nleep/row_max_mean 1489.8296 (1512.5676) nleep/row_max_std 84.9443 (65.1804) nleep/row_min_mean 1456.8599 (1475.2719) lr 1.4258e-03 eta 0:10:46
epoch [20/50] batch [80/203] time 0.105 (0.101) data 0.000 (0.003) loss 1.5463 (1.2949) teacher_loss 0.6749 (0.4792) loss_zs_kd 0.0161 (0.0116) loss_oracle 0.4406 (0.4295) kd_loss 0.6430 (0.5951) acc 65.6250 (81.5234) gate/entropy 0.9943 (0.9965) gate/usage_max 0.5559 (0.5533) gate/usage_min 0.2126 (0.2122) gate/usage_std 0.1576 (0.1558) teacher/entropy 0.0046 (0.0145) teacher/usage_max 0.9366 (0.9813) teacher/usage_min 0.0005 (0.0007) teacher/usage_std 0.4274 (0.4584) nleep/row_max_mean 1516.9836 (1512.3949) nleep/row_max_std 54.7435 (66.2091) nleep/row_min_mean 1481.7689 (1475.1171) lr 1.4258e-03 eta 0:10:30
epoch [20/50] batch [100/203] time 0.098 (0.101) data 0.000 (0.003) loss 1.3427 (1.2869) teacher_loss 0.5686 (0.4737) loss_zs_kd 0.0076 (0.0118) loss_oracle 0.3751 (0.4251) kd_loss 0.5827 (0.5947) acc 81.2500 (81.8750) gate/entropy 0.9934 (0.9960) gate/usage_max 0.5569 (0.5539) gate/usage_min 0.2128 (0.2123) gate/usage_std 0.1583 (0.1562) teacher/entropy 0.0031 (0.0142) teacher/usage_max 0.9995 (0.9808) teacher/usage_min 0.0001 (0.0008) teacher/usage_std 0.4710 (0.4580) nleep/row_max_mean 1511.3813 (1512.2114) nleep/row_max_std 69.1553 (66.7886) nleep/row_min_mean 1473.2256 (1474.9390) lr 1.4258e-03 eta 0:10:26
epoch [20/50] batch [120/203] time 0.107 (0.101) data 0.000 (0.002) loss 1.1823 (1.2769) teacher_loss 0.3920 (0.4668) loss_zs_kd 0.0089 (0.0119) loss_oracle 0.4129 (0.4236) kd_loss 0.5794 (0.5924) acc 84.3750 (82.0312) gate/entropy 0.9925 (0.9954) gate/usage_max 0.5580 (0.5545) gate/usage_min 0.2129 (0.2124) gate/usage_std 0.1590 (0.1567) teacher/entropy 0.0053 (0.0141) teacher/usage_max 0.9988 (0.9822) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4706 (0.4590) nleep/row_max_mean 1513.2664 (1511.7690) nleep/row_max_std 59.5511 (66.4947) nleep/row_min_mean 1476.5500 (1474.6344) lr 1.4258e-03 eta 0:10:20
epoch [20/50] batch [140/203] time 0.094 (0.100) data 0.000 (0.002) loss 1.3243 (1.2883) teacher_loss 0.4964 (0.4782) loss_zs_kd 0.0089 (0.0120) loss_oracle 0.4853 (0.4250) kd_loss 0.5809 (0.5916) acc 81.2500 (81.7634) gate/entropy 0.9914 (0.9950) gate/usage_max 0.5592 (0.5551) gate/usage_min 0.2130 (0.2125) gate/usage_std 0.1598 (0.1570) teacher/entropy 0.0605 (0.0153) teacher/usage_max 0.9374 (0.9807) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4279 (0.4579) nleep/row_max_mean 1500.2915 (1510.6322) nleep/row_max_std 95.1410 (67.5371) nleep/row_min_mean 1464.9784 (1473.5940) lr 1.4258e-03 eta 0:10:16
epoch [20/50] batch [160/203] time 0.089 (0.100) data 0.000 (0.002) loss 1.2816 (1.2942) teacher_loss 0.5210 (0.4857) loss_zs_kd 0.0155 (0.0119) loss_oracle 0.3541 (0.4244) kd_loss 0.5757 (0.5903) acc 71.8750 (81.3867) gate/entropy 0.9910 (0.9945) gate/usage_max 0.5596 (0.5556) gate/usage_min 0.2132 (0.2126) gate/usage_std 0.1601 (0.1574) teacher/entropy 0.0056 (0.0152) teacher/usage_max 0.9990 (0.9812) teacher/usage_min 0.0003 (0.0007) teacher/usage_std 0.4707 (0.4583) nleep/row_max_mean 1483.2625 (1509.7516) nleep/row_max_std 85.4388 (68.3006) nleep/row_min_mean 1452.8982 (1472.9233) lr 1.4258e-03 eta 0:10:16
epoch [20/50] batch [180/203] time 0.096 (0.100) data 0.000 (0.002) loss 1.2732 (1.3010) teacher_loss 0.4674 (0.4941) loss_zs_kd 0.0146 (0.0120) loss_oracle 0.4508 (0.4240) kd_loss 0.5730 (0.5889) acc 81.2500 (81.0938) gate/entropy 0.9897 (0.9941) gate/usage_max 0.5611 (0.5561) gate/usage_min 0.2132 (0.2126) gate/usage_std 0.1611 (0.1577) teacher/entropy 0.0062 (0.0151) teacher/usage_max 0.9987 (0.9819) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4705 (0.4588) nleep/row_max_mean 1505.8838 (1509.4629) nleep/row_max_std 85.5858 (68.1865) nleep/row_min_mean 1468.2554 (1472.7029) lr 1.4258e-03 eta 0:10:10
epoch [20/50] batch [200/203] time 0.074 (0.100) data 0.000 (0.002) loss 1.0870 (1.2990) teacher_loss 0.3071 (0.4921) loss_zs_kd 0.0218 (0.0119) loss_oracle 0.3888 (0.4252) kd_loss 0.5746 (0.5883) acc 87.5000 (81.2188) gate/entropy 0.9897 (0.9937) gate/usage_max 0.5611 (0.5566) gate/usage_min 0.2134 (0.2127) gate/usage_std 0.1611 (0.1580) teacher/entropy 0.0041 (0.0149) teacher/usage_max 0.9992 (0.9819) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4709 (0.4587) nleep/row_max_mean 1491.8071 (1509.6933) nleep/row_max_std 82.0194 (67.5300) nleep/row_min_mean 1454.7571 (1472.9079) lr 1.4258e-03 eta 0:10:08
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,345
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 87.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      83.9%, epoch: 20 *******
******* Domain c best val test acc: 99.9%, epoch: 20 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [21/50] batch [20/203] time 0.083 (0.110) data 0.000 (0.017) loss 1.6643 (1.2837) teacher_loss 0.8923 (0.4819) loss_zs_kd 0.0157 (0.0122) loss_oracle 0.3761 (0.4340) kd_loss 0.5761 (0.5786) acc 56.2500 (80.3125) gate/entropy 0.9888 (0.9893) gate/usage_max 0.5621 (0.5616) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1618 (0.1615) teacher/entropy 0.0000 (0.0149) teacher/usage_max 1.0000 (0.9829) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4714 (0.4594) nleep/row_max_mean 1525.8765 (1508.6981) nleep/row_max_std 28.7904 (65.8756) nleep/row_min_mean 1486.9457 (1471.3677) lr 1.3681e-03 eta 0:11:09
epoch [21/50] batch [40/203] time 0.104 (0.098) data 0.001 (0.009) loss 1.1982 (1.2950) teacher_loss 0.3978 (0.4875) loss_zs_kd 0.0190 (0.0119) loss_oracle 0.4595 (0.4369) kd_loss 0.5611 (0.5832) acc 81.2500 (80.3125) gate/entropy 0.9887 (0.9890) gate/usage_max 0.5622 (0.5618) gate/usage_min 0.2135 (0.2134) gate/usage_std 0.1619 (0.1616) teacher/entropy 0.0408 (0.0141) teacher/usage_max 0.9731 (0.9785) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4525 (0.4564) nleep/row_max_mean 1498.1599 (1507.6172) nleep/row_max_std 67.4957 (67.9222) nleep/row_min_mean 1465.8416 (1470.7331) lr 1.3681e-03 eta 0:09:51
epoch [21/50] batch [60/203] time 0.088 (0.095) data 0.001 (0.006) loss 1.2171 (1.2786) teacher_loss 0.3891 (0.4778) loss_zs_kd 0.0097 (0.0118) loss_oracle 0.5270 (0.4302) kd_loss 0.5597 (0.5798) acc 84.3750 (81.0417) gate/entropy 0.9883 (0.9888) gate/usage_max 0.5626 (0.5622) gate/usage_min 0.2136 (0.2135) gate/usage_std 0.1622 (0.1619) teacher/entropy 0.0245 (0.0151) teacher/usage_max 0.9906 (0.9803) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4648 (0.4576) nleep/row_max_mean 1500.0510 (1508.7425) nleep/row_max_std 66.1888 (66.9713) nleep/row_min_mean 1465.8390 (1471.5956) lr 1.3681e-03 eta 0:09:30
epoch [21/50] batch [80/203] time 0.093 (0.093) data 0.000 (0.004) loss 1.1404 (1.2733) teacher_loss 0.3904 (0.4793) loss_zs_kd 0.0141 (0.0111) loss_oracle 0.3807 (0.4240) kd_loss 0.5526 (0.5765) acc 84.3750 (81.0156) gate/entropy 0.9876 (0.9885) gate/usage_max 0.5634 (0.5624) gate/usage_min 0.2136 (0.2135) gate/usage_std 0.1627 (0.1620) teacher/entropy 0.0318 (0.0144) teacher/usage_max 0.9890 (0.9841) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4636 (0.4603) nleep/row_max_mean 1493.4695 (1508.3765) nleep/row_max_std 86.1188 (67.5552) nleep/row_min_mean 1458.4680 (1471.2473) lr 1.3681e-03 eta 0:09:20
epoch [21/50] batch [100/203] time 0.084 (0.092) data 0.000 (0.004) loss 1.6313 (1.2713) teacher_loss 0.8636 (0.4774) loss_zs_kd 0.0082 (0.0108) loss_oracle 0.3672 (0.4242) kd_loss 0.5800 (0.5764) acc 62.5000 (81.0312) gate/entropy 0.9874 (0.9883) gate/usage_max 0.5637 (0.5627) gate/usage_min 0.2136 (0.2135) gate/usage_std 0.1629 (0.1622) teacher/entropy 0.0169 (0.0141) teacher/usage_max 0.9756 (0.9839) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4542 (0.4602) nleep/row_max_mean 1484.2888 (1508.3343) nleep/row_max_std 85.2050 (67.4216) nleep/row_min_mean 1450.5403 (1471.0213) lr 1.3681e-03 eta 0:09:10
epoch [21/50] batch [120/203] time 0.113 (0.092) data 0.000 (0.003) loss 1.3521 (1.2738) teacher_loss 0.4830 (0.4781) loss_zs_kd 0.0087 (0.0110) loss_oracle 0.5539 (0.4273) kd_loss 0.5878 (0.5766) acc 87.5000 (81.2760) gate/entropy 0.9871 (0.9880) gate/usage_max 0.5639 (0.5629) gate/usage_min 0.2137 (0.2135) gate/usage_std 0.1631 (0.1624) teacher/entropy 0.0136 (0.0142) teacher/usage_max 0.9704 (0.9833) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4506 (0.4597) nleep/row_max_mean 1505.0258 (1508.0552) nleep/row_max_std 64.4993 (67.3646) nleep/row_min_mean 1466.4225 (1470.7416) lr 1.3681e-03 eta 0:09:07
epoch [21/50] batch [140/203] time 0.077 (0.090) data 0.000 (0.003) loss 1.0871 (1.2865) teacher_loss 0.2841 (0.4905) loss_zs_kd 0.0061 (0.0109) loss_oracle 0.4902 (0.4272) kd_loss 0.5548 (0.5769) acc 87.5000 (80.5804) gate/entropy 0.9867 (0.9878) gate/usage_max 0.5644 (0.5632) gate/usage_min 0.2137 (0.2136) gate/usage_std 0.1634 (0.1626) teacher/entropy 0.0224 (0.0137) teacher/usage_max 0.9946 (0.9829) teacher/usage_min 0.0001 (0.0000) teacher/usage_std 0.4676 (0.4595) nleep/row_max_mean 1497.5475 (1508.1910) nleep/row_max_std 72.0591 (67.3215) nleep/row_min_mean 1462.4979 (1470.8271) lr 1.3681e-03 eta 0:08:55
epoch [21/50] batch [160/203] time 0.076 (0.089) data 0.000 (0.002) loss 1.3116 (1.2876) teacher_loss 0.4813 (0.4927) loss_zs_kd 0.0163 (0.0110) loss_oracle 0.4403 (0.4256) kd_loss 0.6021 (0.5766) acc 81.2500 (80.6641) gate/entropy 0.9857 (0.9876) gate/usage_max 0.5654 (0.5634) gate/usage_min 0.2137 (0.2136) gate/usage_std 0.1641 (0.1627) teacher/entropy 0.0252 (0.0133) teacher/usage_max 0.9411 (0.9834) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4304 (0.4598) nleep/row_max_mean 1529.2329 (1508.7697) nleep/row_max_std 46.6198 (67.0353) nleep/row_min_mean 1491.6406 (1471.2043) lr 1.3681e-03 eta 0:08:48
epoch [21/50] batch [180/203] time 0.076 (0.089) data 0.000 (0.002) loss 1.1876 (1.2858) teacher_loss 0.4262 (0.4922) loss_zs_kd 0.0041 (0.0111) loss_oracle 0.4114 (0.4237) kd_loss 0.5536 (0.5762) acc 84.3750 (80.7292) gate/entropy 0.9860 (0.9874) gate/usage_max 0.5651 (0.5636) gate/usage_min 0.2138 (0.2136) gate/usage_std 0.1639 (0.1629) teacher/entropy 0.0261 (0.0130) teacher/usage_max 0.9908 (0.9837) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4649 (0.4600) nleep/row_max_mean 1508.7089 (1508.5225) nleep/row_max_std 68.2619 (67.5565) nleep/row_min_mean 1468.3906 (1470.9114) lr 1.3681e-03 eta 0:08:44
epoch [21/50] batch [200/203] time 0.079 (0.088) data 0.000 (0.002) loss 1.0852 (1.2841) teacher_loss 0.3236 (0.4915) loss_zs_kd 0.0181 (0.0112) loss_oracle 0.3671 (0.4227) kd_loss 0.5690 (0.5756) acc 84.3750 (80.8594) gate/entropy 0.9852 (0.9872) gate/usage_max 0.5660 (0.5638) gate/usage_min 0.2137 (0.2136) gate/usage_std 0.1646 (0.1630) teacher/entropy 0.0001 (0.0136) teacher/usage_max 1.0000 (0.9832) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.4714 (0.4597) nleep/row_max_mean 1525.3262 (1508.8049) nleep/row_max_std 62.0188 (67.1815) nleep/row_min_mean 1483.7791 (1471.1460) lr 1.3681e-03 eta 0:08:35
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,339
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      83.9%, epoch: 20 *******
******* Domain c best val test acc: 99.9%, epoch: 20 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [22/50] batch [20/203] time 0.085 (0.100) data 0.000 (0.015) loss 1.1631 (1.3396) teacher_loss 0.4026 (0.5543) loss_zs_kd 0.0044 (0.0117) loss_oracle 0.3883 (0.4248) kd_loss 0.5641 (0.5670) acc 84.3750 (79.0625) gate/entropy 0.9851 (0.9852) gate/usage_max 0.5661 (0.5660) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1646 (0.1645) teacher/entropy 0.0063 (0.0158) teacher/usage_max 0.9985 (0.9858) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4704 (0.4615) nleep/row_max_mean 1503.3196 (1507.1102) nleep/row_max_std 74.8016 (71.0423) nleep/row_min_mean 1463.2803 (1469.2226) lr 1.3090e-03 eta 0:09:47
epoch [22/50] batch [40/203] time 0.089 (0.092) data 0.000 (0.008) loss 1.2054 (1.2893) teacher_loss 0.4575 (0.5008) loss_zs_kd 0.0101 (0.0124) loss_oracle 0.3808 (0.4290) kd_loss 0.5525 (0.5678) acc 71.8750 (80.3906) gate/entropy 0.9849 (0.9850) gate/usage_max 0.5663 (0.5662) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1647 (0.1647) teacher/entropy 0.0213 (0.0132) teacher/usage_max 0.9947 (0.9875) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.4677 (0.4626) nleep/row_max_mean 1495.1917 (1508.8286) nleep/row_max_std 83.2619 (70.3579) nleep/row_min_mean 1457.4741 (1470.6381) lr 1.3090e-03 eta 0:08:56
epoch [22/50] batch [60/203] time 0.083 (0.096) data 0.003 (0.005) loss 1.1603 (1.2832) teacher_loss 0.3831 (0.4949) loss_zs_kd 0.0147 (0.0132) loss_oracle 0.4032 (0.4262) kd_loss 0.5682 (0.5686) acc 84.3750 (80.6250) gate/entropy 0.9846 (0.9849) gate/usage_max 0.5666 (0.5663) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1650 (0.1648) teacher/entropy 0.0484 (0.0150) teacher/usage_max 0.9502 (0.9845) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4366 (0.4605) nleep/row_max_mean 1490.3386 (1509.0412) nleep/row_max_std 83.8144 (68.5762) nleep/row_min_mean 1458.2548 (1471.2200) lr 1.3090e-03 eta 0:09:18
epoch [22/50] batch [80/203] time 0.090 (0.094) data 0.000 (0.004) loss 1.3500 (1.2858) teacher_loss 0.5823 (0.4991) loss_zs_kd 0.0071 (0.0129) loss_oracle 0.3940 (0.4229) kd_loss 0.5671 (0.5689) acc 84.3750 (80.4688) gate/entropy 0.9844 (0.9847) gate/usage_max 0.5668 (0.5665) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1651 (0.1649) teacher/entropy 0.0008 (0.0148) teacher/usage_max 0.9999 (0.9842) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.4713 (0.4603) nleep/row_max_mean 1516.6676 (1509.9037) nleep/row_max_std 60.3312 (66.3755) nleep/row_min_mean 1479.2579 (1472.1443) lr 1.3090e-03 eta 0:09:05
epoch [22/50] batch [100/203] time 0.085 (0.092) data 0.000 (0.003) loss 1.0468 (1.2787) teacher_loss 0.3053 (0.4938) loss_zs_kd 0.0101 (0.0127) loss_oracle 0.3477 (0.4191) kd_loss 0.5626 (0.5690) acc 90.6250 (80.6562) gate/entropy 0.9844 (0.9846) gate/usage_max 0.5669 (0.5666) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1652 (0.1650) teacher/entropy 0.0061 (0.0144) teacher/usage_max 0.9988 (0.9843) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4706 (0.4604) nleep/row_max_mean 1497.0601 (1509.9494) nleep/row_max_std 80.3011 (66.8192) nleep/row_min_mean 1461.0244 (1472.2684) lr 1.3090e-03 eta 0:08:54
epoch [22/50] batch [120/203] time 0.085 (0.092) data 0.000 (0.003) loss 1.2860 (1.2828) teacher_loss 0.4396 (0.4950) loss_zs_kd 0.0087 (0.0124) loss_oracle 0.4962 (0.4223) kd_loss 0.5939 (0.5704) acc 90.6250 (80.5469) gate/entropy 0.9838 (0.9845) gate/usage_max 0.5674 (0.5667) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1655 (0.1651) teacher/entropy 0.0037 (0.0143) teacher/usage_max 0.9682 (0.9827) teacher/usage_min 0.0001 (0.0010) teacher/usage_std 0.4491 (0.4593) nleep/row_max_mean 1504.1169 (1510.2444) nleep/row_max_std 74.4101 (66.6659) nleep/row_min_mean 1469.3602 (1472.6816) lr 1.3090e-03 eta 0:08:48
epoch [22/50] batch [140/203] time 0.071 (0.091) data 0.000 (0.002) loss 1.4824 (1.2828) teacher_loss 0.7245 (0.4952) loss_zs_kd 0.0081 (0.0123) loss_oracle 0.3867 (0.4231) kd_loss 0.5604 (0.5699) acc 84.3750 (80.7589) gate/entropy 0.9836 (0.9844) gate/usage_max 0.5676 (0.5669) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1657 (0.1651) teacher/entropy 0.0075 (0.0147) teacher/usage_max 0.9983 (0.9825) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4702 (0.4592) nleep/row_max_mean 1490.0952 (1510.3235) nleep/row_max_std 90.6122 (66.8538) nleep/row_min_mean 1454.7832 (1472.7863) lr 1.3090e-03 eta 0:08:42
epoch [22/50] batch [160/203] time 0.091 (0.090) data 0.000 (0.002) loss 1.2520 (1.2833) teacher_loss 0.5019 (0.4936) loss_zs_kd 0.0056 (0.0123) loss_oracle 0.3788 (0.4257) kd_loss 0.5579 (0.5707) acc 81.2500 (80.9180) gate/entropy 0.9836 (0.9843) gate/usage_max 0.5677 (0.5670) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1657 (0.1652) teacher/entropy 0.0106 (0.0152) teacher/usage_max 0.9976 (0.9810) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4697 (0.4581) nleep/row_max_mean 1502.8875 (1510.1745) nleep/row_max_std 74.4866 (66.8310) nleep/row_min_mean 1466.0459 (1472.7221) lr 1.3090e-03 eta 0:08:36
epoch [22/50] batch [180/203] time 0.084 (0.090) data 0.000 (0.002) loss 1.1694 (1.2848) teacher_loss 0.3992 (0.4975) loss_zs_kd 0.0121 (0.0125) loss_oracle 0.4298 (0.4224) kd_loss 0.5493 (0.5698) acc 78.1250 (80.7118) gate/entropy 0.9834 (0.9841) gate/usage_max 0.5678 (0.5671) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1658 (0.1653) teacher/entropy 0.0358 (0.0153) teacher/usage_max 0.9804 (0.9815) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4576 (0.4585) nleep/row_max_mean 1508.0088 (1510.0189) nleep/row_max_std 69.7692 (66.8262) nleep/row_min_mean 1471.5750 (1472.6944) lr 1.3090e-03 eta 0:08:30
epoch [22/50] batch [200/203] time 0.084 (0.089) data 0.000 (0.002) loss 1.4219 (1.2825) teacher_loss 0.5934 (0.4947) loss_zs_kd 0.0105 (0.0124) loss_oracle 0.5006 (0.4239) kd_loss 0.5729 (0.5696) acc 81.2500 (80.9219) gate/entropy 0.9832 (0.9840) gate/usage_max 0.5681 (0.5672) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1660 (0.1654) teacher/entropy 0.0223 (0.0154) teacher/usage_max 0.9694 (0.9815) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4500 (0.4584) nleep/row_max_mean 1513.3453 (1509.8616) nleep/row_max_std 62.6679 (66.9748) nleep/row_min_mean 1474.8528 (1472.5284) lr 1.3090e-03 eta 0:08:24
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,347
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 87.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      84.0%, epoch: 22 *******
******* Domain c best val test acc: 99.9%, epoch: 22 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [23/50] batch [20/203] time 0.093 (0.101) data 0.000 (0.016) loss 1.4473 (1.2532) teacher_loss 0.6908 (0.4616) loss_zs_kd 0.0196 (0.0137) loss_oracle 0.4097 (0.4277) kd_loss 0.5419 (0.5710) acc 87.5000 (84.3750) gate/entropy 0.9829 (0.9829) gate/usage_max 0.5684 (0.5684) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1662 (0.1662) teacher/entropy 0.0322 (0.0175) teacher/usage_max 0.9906 (0.9757) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4648 (0.4544) nleep/row_max_mean 1481.8273 (1512.3302) nleep/row_max_std 86.9046 (64.3520) nleep/row_min_mean 1447.6862 (1474.7339) lr 1.2487e-03 eta 0:09:31
epoch [23/50] batch [40/203] time 0.092 (0.096) data 0.000 (0.008) loss 1.4829 (1.2808) teacher_loss 0.6160 (0.4920) loss_zs_kd 0.0125 (0.0134) loss_oracle 0.4714 (0.4261) kd_loss 0.6249 (0.5690) acc 68.7500 (81.8750) gate/entropy 0.9827 (0.9828) gate/usage_max 0.5686 (0.5685) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1664 (0.1663) teacher/entropy 0.0300 (0.0201) teacher/usage_max 0.9073 (0.9751) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4076 (0.4540) nleep/row_max_mean 1494.2166 (1507.5323) nleep/row_max_std 71.4440 (65.6966) nleep/row_min_mean 1458.6736 (1470.5991) lr 1.2487e-03 eta 0:09:01
epoch [23/50] batch [60/203] time 0.099 (0.095) data 0.001 (0.006) loss 1.2273 (1.2609) teacher_loss 0.4744 (0.4738) loss_zs_kd 0.0124 (0.0135) loss_oracle 0.3976 (0.4236) kd_loss 0.5478 (0.5686) acc 87.5000 (82.0833) gate/entropy 0.9824 (0.9827) gate/usage_max 0.5689 (0.5686) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1666 (0.1663) teacher/entropy 0.0264 (0.0204) teacher/usage_max 0.9896 (0.9750) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4641 (0.4539) nleep/row_max_mean 1526.7010 (1507.0088) nleep/row_max_std 49.4158 (65.7187) nleep/row_min_mean 1488.7476 (1470.2899) lr 1.2487e-03 eta 0:08:55
epoch [23/50] batch [80/203] time 0.094 (0.096) data 0.000 (0.004) loss 1.3249 (1.2538) teacher_loss 0.5796 (0.4673) loss_zs_kd 0.0101 (0.0129) loss_oracle 0.3702 (0.4228) kd_loss 0.5551 (0.5687) acc 78.1250 (81.8359) gate/entropy 0.9822 (0.9827) gate/usage_max 0.5691 (0.5687) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1667 (0.1664) teacher/entropy 0.0113 (0.0187) teacher/usage_max 0.9972 (0.9765) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4694 (0.4550) nleep/row_max_mean 1517.4385 (1507.5137) nleep/row_max_std 55.3239 (65.5376) nleep/row_min_mean 1477.6874 (1470.6637) lr 1.2487e-03 eta 0:08:56
epoch [23/50] batch [100/203] time 0.095 (0.097) data 0.000 (0.003) loss 1.4596 (1.2526) teacher_loss 0.7173 (0.4676) loss_zs_kd 0.0194 (0.0131) loss_oracle 0.3655 (0.4198) kd_loss 0.5499 (0.5685) acc 81.2500 (81.9375) gate/entropy 0.9822 (0.9826) gate/usage_max 0.5692 (0.5687) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1668 (0.1665) teacher/entropy 0.0195 (0.0186) teacher/usage_max 0.9941 (0.9767) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4672 (0.4551) nleep/row_max_mean 1496.9325 (1507.1833) nleep/row_max_std 82.1413 (66.0179) nleep/row_min_mean 1459.3860 (1470.3684) lr 1.2487e-03 eta 0:09:01
epoch [23/50] batch [120/203] time 0.104 (0.097) data 0.000 (0.003) loss 1.1313 (1.2562) teacher_loss 0.3737 (0.4725) loss_zs_kd 0.0132 (0.0129) loss_oracle 0.3971 (0.4186) kd_loss 0.5524 (0.5680) acc 84.3750 (81.5625) gate/entropy 0.9821 (0.9825) gate/usage_max 0.5692 (0.5688) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1668 (0.1665) teacher/entropy 0.0148 (0.0177) teacher/usage_max 0.9962 (0.9780) teacher/usage_min 0.0004 (0.0004) teacher/usage_std 0.4687 (0.4561) nleep/row_max_mean 1509.5125 (1507.5860) nleep/row_max_std 66.8742 (65.3913) nleep/row_min_mean 1471.7634 (1470.8920) lr 1.2487e-03 eta 0:09:01
epoch [23/50] batch [140/203] time 0.116 (0.098) data 0.001 (0.003) loss 1.1495 (1.2599) teacher_loss 0.3623 (0.4755) loss_zs_kd 0.0036 (0.0127) loss_oracle 0.4503 (0.4199) kd_loss 0.5602 (0.5681) acc 90.6250 (81.8304) gate/entropy 0.9820 (0.9825) gate/usage_max 0.5693 (0.5689) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1669 (0.1666) teacher/entropy 0.0038 (0.0179) teacher/usage_max 0.9993 (0.9776) teacher/usage_min 0.0001 (0.0005) teacher/usage_std 0.4709 (0.4557) nleep/row_max_mean 1514.1118 (1507.8856) nleep/row_max_std 57.4553 (65.3195) nleep/row_min_mean 1479.1915 (1471.2178) lr 1.2487e-03 eta 0:09:02
epoch [23/50] batch [160/203] time 0.082 (0.099) data 0.000 (0.002) loss 1.3696 (1.2621) teacher_loss 0.6213 (0.4784) loss_zs_kd 0.0132 (0.0126) loss_oracle 0.3711 (0.4194) kd_loss 0.5562 (0.5677) acc 81.2500 (81.6211) gate/entropy 0.9819 (0.9824) gate/usage_max 0.5695 (0.5689) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1670 (0.1666) teacher/entropy 0.0095 (0.0174) teacher/usage_max 0.9973 (0.9784) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4695 (0.4563) nleep/row_max_mean 1507.3707 (1508.0244) nleep/row_max_std 59.2757 (65.4814) nleep/row_min_mean 1469.2671 (1471.3796) lr 1.2487e-03 eta 0:09:09
epoch [23/50] batch [180/203] time 0.104 (0.098) data 0.000 (0.002) loss 1.1641 (1.2593) teacher_loss 0.3401 (0.4766) loss_zs_kd 0.0055 (0.0124) loss_oracle 0.4793 (0.4185) kd_loss 0.5815 (0.5673) acc 84.3750 (81.6319) gate/entropy 0.9818 (0.9823) gate/usage_max 0.5696 (0.5690) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1670 (0.1667) teacher/entropy 0.0145 (0.0177) teacher/usage_max 0.9661 (0.9784) teacher/usage_min 0.0001 (0.0004) teacher/usage_std 0.4476 (0.4563) nleep/row_max_mean 1510.5092 (1507.9727) nleep/row_max_std 66.2232 (65.5033) nleep/row_min_mean 1470.4036 (1471.3779) lr 1.2487e-03 eta 0:08:59
epoch [23/50] batch [200/203] time 0.088 (0.097) data 0.000 (0.002) loss 1.3107 (1.2636) teacher_loss 0.5474 (0.4816) loss_zs_kd 0.0122 (0.0123) loss_oracle 0.4135 (0.4179) kd_loss 0.5505 (0.5669) acc 75.0000 (81.4844) gate/entropy 0.9816 (0.9822) gate/usage_max 0.5698 (0.5691) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1672 (0.1667) teacher/entropy 0.0156 (0.0177) teacher/usage_max 0.9964 (0.9785) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4688 (0.4564) nleep/row_max_mean 1500.3833 (1507.9089) nleep/row_max_std 81.4123 (65.8067) nleep/row_min_mean 1464.2102 (1471.3171) lr 1.2487e-03 eta 0:08:54
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,348
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 87.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      84.0%, epoch: 23 *******
******* Domain c best val test acc: 99.9%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [24/50] batch [20/203] time 0.104 (0.109) data 0.000 (0.012) loss 1.2526 (1.2418) teacher_loss 0.4794 (0.4493) loss_zs_kd 0.0128 (0.0132) loss_oracle 0.4417 (0.4395) kd_loss 0.5459 (0.5661) acc 78.1250 (83.7500) gate/entropy 0.9817 (0.9815) gate/usage_max 0.5696 (0.5698) gate/usage_min 0.2138 (0.2137) gate/usage_std 0.1671 (0.1672) teacher/entropy 0.0266 (0.0193) teacher/usage_max 0.9901 (0.9764) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.4644 (0.4549) nleep/row_max_mean 1485.3867 (1509.1698) nleep/row_max_std 85.0381 (66.5478) nleep/row_min_mean 1450.1658 (1472.1961) lr 1.1874e-03 eta 0:09:54
epoch [24/50] batch [40/203] time 0.091 (0.101) data 0.000 (0.006) loss 1.1367 (1.2469) teacher_loss 0.3931 (0.4574) loss_zs_kd 0.0134 (0.0134) loss_oracle 0.3726 (0.4309) kd_loss 0.5506 (0.5673) acc 87.5000 (83.1250) gate/entropy 0.9813 (0.9815) gate/usage_max 0.5700 (0.5699) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1674 (0.1673) teacher/entropy 0.0155 (0.0183) teacher/usage_max 0.9959 (0.9762) teacher/usage_min 0.0001 (0.0004) teacher/usage_std 0.4685 (0.4548) nleep/row_max_mean 1513.6334 (1511.5059) nleep/row_max_std 60.2090 (65.5741) nleep/row_min_mean 1475.7625 (1474.2162) lr 1.1874e-03 eta 0:09:12
epoch [24/50] batch [60/203] time 0.091 (0.100) data 0.000 (0.004) loss 1.4038 (1.2697) teacher_loss 0.6399 (0.4844) loss_zs_kd 0.0181 (0.0138) loss_oracle 0.3910 (0.4268) kd_loss 0.5594 (0.5650) acc 81.2500 (81.9792) gate/entropy 0.9814 (0.9814) gate/usage_max 0.5700 (0.5699) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1673 (0.1673) teacher/entropy 0.0032 (0.0194) teacher/usage_max 0.9995 (0.9773) teacher/usage_min 0.0002 (0.0010) teacher/usage_std 0.4710 (0.4555) nleep/row_max_mean 1516.6282 (1510.2006) nleep/row_max_std 53.8664 (66.8286) nleep/row_min_mean 1480.4421 (1473.2702) lr 1.1874e-03 eta 0:09:00
epoch [24/50] batch [80/203] time 0.083 (0.097) data 0.000 (0.003) loss 1.4102 (1.2831) teacher_loss 0.6440 (0.4958) loss_zs_kd 0.0061 (0.0131) loss_oracle 0.4312 (0.4298) kd_loss 0.5476 (0.5658) acc 84.3750 (81.6797) gate/entropy 0.9810 (0.9814) gate/usage_max 0.5704 (0.5700) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1676 (0.1673) teacher/entropy 0.0194 (0.0195) teacher/usage_max 0.9944 (0.9764) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.4674 (0.4549) nleep/row_max_mean 1510.1450 (1509.6382) nleep/row_max_std 74.2110 (67.4828) nleep/row_min_mean 1470.4365 (1472.8710) lr 1.1874e-03 eta 0:08:45
epoch [24/50] batch [100/203] time 0.095 (0.097) data 0.000 (0.003) loss 1.5122 (1.2790) teacher_loss 0.7626 (0.4948) loss_zs_kd 0.0123 (0.0125) loss_oracle 0.3647 (0.4268) kd_loss 0.5611 (0.5645) acc 65.6250 (81.7188) gate/entropy 0.9809 (0.9813) gate/usage_max 0.5704 (0.5700) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1677 (0.1674) teacher/entropy 0.0003 (0.0194) teacher/usage_max 1.0000 (0.9776) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.4714 (0.4557) nleep/row_max_mean 1517.9463 (1509.5475) nleep/row_max_std 66.8282 (67.6683) nleep/row_min_mean 1477.4614 (1472.6619) lr 1.1874e-03 eta 0:08:40
epoch [24/50] batch [120/203] time 0.082 (0.096) data 0.000 (0.002) loss 1.2200 (1.2725) teacher_loss 0.4610 (0.4865) loss_zs_kd 0.0174 (0.0127) loss_oracle 0.3965 (0.4304) kd_loss 0.5521 (0.5644) acc 81.2500 (82.0833) gate/entropy 0.9810 (0.9813) gate/usage_max 0.5704 (0.5701) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1676 (0.1674) teacher/entropy 0.0141 (0.0203) teacher/usage_max 0.9952 (0.9768) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.4680 (0.4552) nleep/row_max_mean 1512.4739 (1509.2616) nleep/row_max_std 68.2081 (68.1623) nleep/row_min_mean 1475.5776 (1472.5842) lr 1.1874e-03 eta 0:08:33
epoch [24/50] batch [140/203] time 0.104 (0.095) data 0.000 (0.002) loss 1.7247 (1.2675) teacher_loss 0.9658 (0.4810) loss_zs_kd 0.0257 (0.0128) loss_oracle 0.3995 (0.4288) kd_loss 0.5463 (0.5657) acc 59.3750 (82.2321) gate/entropy 0.9807 (0.9812) gate/usage_max 0.5707 (0.5701) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1678 (0.1674) teacher/entropy 0.0363 (0.0206) teacher/usage_max 0.9779 (0.9751) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4559 (0.4540) nleep/row_max_mean 1496.4431 (1508.7007) nleep/row_max_std 77.1442 (68.2812) nleep/row_min_mean 1463.8772 (1472.2443) lr 1.1874e-03 eta 0:08:28
epoch [24/50] batch [160/203] time 0.093 (0.095) data 0.000 (0.002) loss 1.1805 (1.2632) teacher_loss 0.3833 (0.4793) loss_zs_kd 0.0077 (0.0127) loss_oracle 0.4249 (0.4257) kd_loss 0.5809 (0.5647) acc 84.3750 (82.3633) gate/entropy 0.9809 (0.9812) gate/usage_max 0.5705 (0.5702) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1677 (0.1675) teacher/entropy 0.0152 (0.0202) teacher/usage_max 0.9644 (0.9764) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4465 (0.4549) nleep/row_max_mean 1489.6538 (1508.9850) nleep/row_max_std 79.5696 (67.6191) nleep/row_min_mean 1458.1211 (1472.5380) lr 1.1874e-03 eta 0:08:27
epoch [24/50] batch [180/203] time 0.087 (0.096) data 0.000 (0.002) loss 1.3128 (1.2659) teacher_loss 0.5343 (0.4826) loss_zs_kd 0.0075 (0.0124) loss_oracle 0.4451 (0.4252) kd_loss 0.5522 (0.5645) acc 71.8750 (82.1701) gate/entropy 0.9807 (0.9811) gate/usage_max 0.5707 (0.5702) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1678 (0.1675) teacher/entropy 0.0132 (0.0206) teacher/usage_max 0.9955 (0.9761) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4682 (0.4547) nleep/row_max_mean 1519.5247 (1509.1663) nleep/row_max_std 61.1111 (67.0472) nleep/row_min_mean 1483.3591 (1472.9058) lr 1.1874e-03 eta 0:08:30
epoch [24/50] batch [200/203] time 0.088 (0.096) data 0.000 (0.001) loss 1.2360 (1.2704) teacher_loss 0.4587 (0.4848) loss_zs_kd 0.0088 (0.0124) loss_oracle 0.3694 (0.4276) kd_loss 0.5883 (0.5656) acc 75.0000 (82.0000) gate/entropy 0.9807 (0.9811) gate/usage_max 0.5706 (0.5703) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1678 (0.1675) teacher/entropy 0.0029 (0.0213) teacher/usage_max 0.9693 (0.9743) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.4499 (0.4534) nleep/row_max_mean 1509.7969 (1508.8788) nleep/row_max_std 59.8105 (66.7305) nleep/row_min_mean 1476.2666 (1472.8270) lr 1.1874e-03 eta 0:08:24
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,342
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 87.4%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      84.0%, epoch: 23 *******
******* Domain c best val test acc: 99.9%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [25/50] batch [20/203] time 0.099 (0.113) data 0.000 (0.018) loss 1.2092 (1.2928) teacher_loss 0.4729 (0.4996) loss_zs_kd 0.0088 (0.0126) loss_oracle 0.3706 (0.4334) kd_loss 0.5465 (0.5701) acc 78.1250 (80.9375) gate/entropy 0.9808 (0.9806) gate/usage_max 0.5706 (0.5707) gate/usage_min 0.2137 (0.2136) gate/usage_std 0.1677 (0.1679) teacher/entropy 0.0249 (0.0233) teacher/usage_max 0.9896 (0.9667) teacher/usage_min 0.0001 (0.0013) teacher/usage_std 0.4640 (0.4481) nleep/row_max_mean 1496.0688 (1509.6114) nleep/row_max_std 69.0846 (56.7582) nleep/row_min_mean 1462.4316 (1475.1890) lr 1.1253e-03 eta 0:09:53
epoch [25/50] batch [40/203] time 0.091 (0.101) data 0.000 (0.009) loss 1.1241 (1.2811) teacher_loss 0.3422 (0.4948) loss_zs_kd 0.0102 (0.0130) loss_oracle 0.4490 (0.4252) kd_loss 0.5522 (0.5673) acc 90.6250 (80.7031) gate/entropy 0.9805 (0.9806) gate/usage_max 0.5709 (0.5708) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1680 (0.1679) teacher/entropy 0.0294 (0.0226) teacher/usage_max 0.9783 (0.9703) teacher/usage_min 0.0019 (0.0023) teacher/usage_std 0.4561 (0.4506) nleep/row_max_mean 1505.3945 (1507.4845) nleep/row_max_std 73.1849 (60.8351) nleep/row_min_mean 1471.4031 (1473.1283) lr 1.1253e-03 eta 0:08:51
epoch [25/50] batch [60/203] time 0.093 (0.098) data 0.001 (0.006) loss 1.2356 (1.2748) teacher_loss 0.4177 (0.4890) loss_zs_kd 0.0039 (0.0128) loss_oracle 0.4506 (0.4231) kd_loss 0.5907 (0.5679) acc 78.1250 (80.3646) gate/entropy 0.9804 (0.9806) gate/usage_max 0.5710 (0.5708) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1681 (0.1679) teacher/entropy 0.0003 (0.0193) teacher/usage_max 0.9687 (0.9729) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4495 (0.4524) nleep/row_max_mean 1523.1155 (1509.3793) nleep/row_max_std 31.8256 (60.2065) nleep/row_min_mean 1483.8208 (1474.6575) lr 1.1253e-03 eta 0:08:29
epoch [25/50] batch [80/203] time 0.096 (0.096) data 0.000 (0.005) loss 1.0681 (1.2699) teacher_loss 0.2943 (0.4818) loss_zs_kd 0.0085 (0.0129) loss_oracle 0.4419 (0.4253) kd_loss 0.5486 (0.5690) acc 87.5000 (80.9766) gate/entropy 0.9805 (0.9805) gate/usage_max 0.5709 (0.5709) gate/usage_min 0.2137 (0.2136) gate/usage_std 0.1680 (0.1680) teacher/entropy 0.0597 (0.0213) teacher/usage_max 0.9513 (0.9698) teacher/usage_min 0.0053 (0.0014) teacher/usage_std 0.4373 (0.4503) nleep/row_max_mean 1488.1776 (1508.8894) nleep/row_max_std 81.7099 (61.4827) nleep/row_min_mean 1454.5116 (1474.1875) lr 1.1253e-03 eta 0:08:19
epoch [25/50] batch [100/203] time 0.106 (0.096) data 0.002 (0.004) loss 1.2359 (1.2692) teacher_loss 0.4928 (0.4800) loss_zs_kd 0.0242 (0.0130) loss_oracle 0.3791 (0.4263) kd_loss 0.5414 (0.5695) acc 78.1250 (81.5312) gate/entropy 0.9804 (0.9805) gate/usage_max 0.5710 (0.5709) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1681 (0.1680) teacher/entropy 0.0284 (0.0210) teacher/usage_max 0.9904 (0.9695) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.4646 (0.4501) nleep/row_max_mean 1487.9264 (1509.0900) nleep/row_max_std 83.2556 (60.9992) nleep/row_min_mean 1457.2264 (1474.4345) lr 1.1253e-03 eta 0:08:16
epoch [25/50] batch [120/203] time 0.101 (0.096) data 0.000 (0.003) loss 1.1749 (1.2685) teacher_loss 0.4034 (0.4803) loss_zs_kd 0.0100 (0.0130) loss_oracle 0.3812 (0.4247) kd_loss 0.5760 (0.5694) acc 84.3750 (81.4583) gate/entropy 0.9802 (0.9805) gate/usage_max 0.5712 (0.5709) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1682 (0.1680) teacher/entropy 0.0610 (0.0220) teacher/usage_max 0.9215 (0.9685) teacher/usage_min 0.0258 (0.0016) teacher/usage_std 0.4160 (0.4494) nleep/row_max_mean 1492.9309 (1508.0417) nleep/row_max_std 82.8884 (62.4028) nleep/row_min_mean 1458.5206 (1473.5152) lr 1.1253e-03 eta 0:08:14
epoch [25/50] batch [140/203] time 0.085 (0.096) data 0.000 (0.003) loss 1.0534 (1.2670) teacher_loss 0.2862 (0.4803) loss_zs_kd 0.0137 (0.0133) loss_oracle 0.4005 (0.4220) kd_loss 0.5601 (0.5691) acc 93.7500 (81.6071) gate/entropy 0.9803 (0.9804) gate/usage_max 0.5711 (0.5710) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1681 (0.1680) teacher/entropy 0.0001 (0.0226) teacher/usage_max 1.0000 (0.9681) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4714 (0.4491) nleep/row_max_mean 1522.1646 (1508.0071) nleep/row_max_std 42.6450 (62.7121) nleep/row_min_mean 1486.8043 (1473.5718) lr 1.1253e-03 eta 0:08:11
epoch [25/50] batch [160/203] time 0.094 (0.095) data 0.000 (0.003) loss 1.1928 (1.2700) teacher_loss 0.3657 (0.4819) loss_zs_kd 0.0106 (0.0133) loss_oracle 0.4732 (0.4239) kd_loss 0.5853 (0.5695) acc 87.5000 (81.4648) gate/entropy 0.9802 (0.9804) gate/usage_max 0.5712 (0.5710) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1682 (0.1681) teacher/entropy 0.0290 (0.0234) teacher/usage_max 0.9448 (0.9668) teacher/usage_min 0.0003 (0.0018) teacher/usage_std 0.4330 (0.4482) nleep/row_max_mean 1504.1041 (1507.7994) nleep/row_max_std 65.7420 (62.9722) nleep/row_min_mean 1471.4167 (1473.2985) lr 1.1253e-03 eta 0:08:08
epoch [25/50] batch [180/203] time 0.093 (0.095) data 0.000 (0.002) loss 1.2206 (1.2671) teacher_loss 0.4716 (0.4809) loss_zs_kd 0.0182 (0.0132) loss_oracle 0.3607 (0.4227) kd_loss 0.5595 (0.5683) acc 87.5000 (81.3889) gate/entropy 0.9801 (0.9804) gate/usage_max 0.5713 (0.5710) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1683 (0.1681) teacher/entropy 0.0003 (0.0240) teacher/usage_max 1.0000 (0.9674) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.4714 (0.4486) nleep/row_max_mean 1519.4482 (1507.7575) nleep/row_max_std 55.3724 (62.9958) nleep/row_min_mean 1482.0869 (1473.2607) lr 1.1253e-03 eta 0:08:04
epoch [25/50] batch [200/203] time 0.076 (0.094) data 0.000 (0.002) loss 1.1851 (1.2669) teacher_loss 0.4372 (0.4814) loss_zs_kd 0.0117 (0.0131) loss_oracle 0.3831 (0.4221) kd_loss 0.5505 (0.5679) acc 87.5000 (81.3750) gate/entropy 0.9800 (0.9803) gate/usage_max 0.5714 (0.5711) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1683 (0.1681) teacher/entropy 0.0144 (0.0240) teacher/usage_max 0.9947 (0.9677) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.4677 (0.4489) nleep/row_max_mean 1513.7051 (1507.2494) nleep/row_max_std 55.3107 (63.4734) nleep/row_min_mean 1477.1517 (1472.7656) lr 1.1253e-03 eta 0:07:59
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,341
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      84.0%, epoch: 23 *******
******* Domain c best val test acc: 99.9%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [26/50] batch [20/203] time 0.084 (0.096) data 0.000 (0.018) loss 1.0548 (1.1964) teacher_loss 0.2686 (0.4104) loss_zs_kd 0.0077 (0.0122) loss_oracle 0.4209 (0.4245) kd_loss 0.5719 (0.5677) acc 93.7500 (85.0000) gate/entropy 0.9799 (0.9800) gate/usage_max 0.5715 (0.5714) gate/usage_min 0.2135 (0.2136) gate/usage_std 0.1684 (0.1683) teacher/entropy 0.0218 (0.0250) teacher/usage_max 0.9652 (0.9663) teacher/usage_min 0.0001 (0.0036) teacher/usage_std 0.4470 (0.4479) nleep/row_max_mean 1502.3322 (1505.0530) nleep/row_max_std 81.9425 (68.2519) nleep/row_min_mean 1466.6392 (1470.2072) lr 1.0628e-03 eta 0:08:04
epoch [26/50] batch [40/203] time 0.085 (0.095) data 0.000 (0.009) loss 0.9874 (1.2353) teacher_loss 0.2195 (0.4521) loss_zs_kd 0.0082 (0.0138) loss_oracle 0.4182 (0.4253) kd_loss 0.5546 (0.5637) acc 93.7500 (82.8906) gate/entropy 0.9799 (0.9800) gate/usage_max 0.5715 (0.5714) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1684 (0.1684) teacher/entropy 0.0060 (0.0255) teacher/usage_max 0.9989 (0.9699) teacher/usage_min 0.0003 (0.0020) teacher/usage_std 0.4706 (0.4504) nleep/row_max_mean 1514.7803 (1506.4433) nleep/row_max_std 51.1027 (67.6200) nleep/row_min_mean 1479.6964 (1471.2347) lr 1.0628e-03 eta 0:07:58
epoch [26/50] batch [60/203] time 0.097 (0.094) data 0.000 (0.006) loss 1.0715 (1.2442) teacher_loss 0.3050 (0.4642) loss_zs_kd 0.0049 (0.0142) loss_oracle 0.4099 (0.4209) kd_loss 0.5591 (0.5625) acc 90.6250 (81.9271) gate/entropy 0.9797 (0.9799) gate/usage_max 0.5717 (0.5715) gate/usage_min 0.2135 (0.2136) gate/usage_std 0.1685 (0.1684) teacher/entropy 0.0001 (0.0209) teacher/usage_max 1.0000 (0.9757) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.4714 (0.4544) nleep/row_max_mean 1522.2267 (1508.1452) nleep/row_max_std 45.4499 (66.8734) nleep/row_min_mean 1483.9674 (1472.2430) lr 1.0628e-03 eta 0:07:52
epoch [26/50] batch [80/203] time 0.099 (0.094) data 0.000 (0.005) loss 1.6567 (1.2525) teacher_loss 0.8277 (0.4745) loss_zs_kd 0.0150 (0.0139) loss_oracle 0.5162 (0.4169) kd_loss 0.5635 (0.5626) acc 68.7500 (81.6016) gate/entropy 0.9798 (0.9799) gate/usage_max 0.5716 (0.5715) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1685 (0.1684) teacher/entropy 0.0438 (0.0187) teacher/usage_max 0.9511 (0.9778) teacher/usage_min 0.0001 (0.0012) teacher/usage_std 0.4373 (0.4558) nleep/row_max_mean 1500.0443 (1508.6947) nleep/row_max_std 78.0140 (66.5325) nleep/row_min_mean 1464.4556 (1472.5408) lr 1.0628e-03 eta 0:07:50
epoch [26/50] batch [100/203] time 0.072 (0.097) data 0.000 (0.004) loss 1.1491 (1.2450) teacher_loss 0.3954 (0.4648) loss_zs_kd 0.0093 (0.0139) loss_oracle 0.3817 (0.4179) kd_loss 0.5582 (0.5642) acc 81.2500 (82.1250) gate/entropy 0.9797 (0.9799) gate/usage_max 0.5717 (0.5715) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1686 (0.1684) teacher/entropy 0.0010 (0.0183) teacher/usage_max 0.9999 (0.9764) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.4713 (0.4549) nleep/row_max_mean 1520.2426 (1508.9733) nleep/row_max_std 61.4969 (66.1191) nleep/row_min_mean 1481.2314 (1472.7541) lr 1.0628e-03 eta 0:08:03
epoch [26/50] batch [120/203] time 0.075 (0.095) data 0.000 (0.003) loss 1.2137 (1.2444) teacher_loss 0.4211 (0.4635) loss_zs_kd 0.0216 (0.0139) loss_oracle 0.4655 (0.4194) kd_loss 0.5491 (0.5642) acc 87.5000 (82.3177) gate/entropy 0.9797 (0.9798) gate/usage_max 0.5717 (0.5716) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1686 (0.1685) teacher/entropy 0.0204 (0.0194) teacher/usage_max 0.9895 (0.9753) teacher/usage_min 0.0001 (0.0021) teacher/usage_std 0.4640 (0.4541) nleep/row_max_mean 1519.9761 (1508.7644) nleep/row_max_std 48.9269 (65.8555) nleep/row_min_mean 1482.2048 (1472.4910) lr 1.0628e-03 eta 0:07:51
epoch [26/50] batch [140/203] time 0.071 (0.093) data 0.000 (0.003) loss 1.0654 (1.2485) teacher_loss 0.2776 (0.4682) loss_zs_kd 0.0086 (0.0139) loss_oracle 0.4697 (0.4211) kd_loss 0.5487 (0.5628) acc 90.6250 (81.9866) gate/entropy 0.9797 (0.9798) gate/usage_max 0.5717 (0.5716) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0170 (0.0195) teacher/usage_max 0.9934 (0.9766) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.4668 (0.4550) nleep/row_max_mean 1516.8702 (1508.8611) nleep/row_max_std 52.3793 (64.8745) nleep/row_min_mean 1480.5126 (1472.6214) lr 1.0628e-03 eta 0:07:40
epoch [26/50] batch [160/203] time 0.091 (0.092) data 0.000 (0.002) loss 1.0819 (1.2459) teacher_loss 0.2074 (0.4642) loss_zs_kd 0.0047 (0.0138) loss_oracle 0.5527 (0.4231) kd_loss 0.5958 (0.5632) acc 93.7500 (82.1680) gate/entropy 0.9797 (0.9798) gate/usage_max 0.5717 (0.5716) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0362 (0.0205) teacher/usage_max 0.9259 (0.9752) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.4201 (0.4540) nleep/row_max_mean 1494.2793 (1508.0563) nleep/row_max_std 82.9837 (65.2933) nleep/row_min_mean 1460.4719 (1471.9355) lr 1.0628e-03 eta 0:07:33
epoch [26/50] batch [180/203] time 0.081 (0.092) data 0.000 (0.002) loss 1.2356 (1.2446) teacher_loss 0.5209 (0.4627) loss_zs_kd 0.0129 (0.0136) loss_oracle 0.3208 (0.4233) kd_loss 0.5479 (0.5634) acc 78.1250 (82.2049) gate/entropy 0.9794 (0.9798) gate/usage_max 0.5720 (0.5716) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1688 (0.1685) teacher/entropy 0.0200 (0.0200) teacher/usage_max 0.9906 (0.9754) teacher/usage_min 0.0000 (0.0018) teacher/usage_std 0.4648 (0.4542) nleep/row_max_mean 1498.9304 (1507.8244) nleep/row_max_std 79.5305 (64.5348) nleep/row_min_mean 1464.8767 (1471.7739) lr 1.0628e-03 eta 0:07:28
epoch [26/50] batch [200/203] time 0.081 (0.091) data 0.000 (0.002) loss 1.0220 (1.2475) teacher_loss 0.2792 (0.4662) loss_zs_kd 0.0093 (0.0137) loss_oracle 0.3697 (0.4225) kd_loss 0.5533 (0.5632) acc 87.5000 (82.1406) gate/entropy 0.9794 (0.9797) gate/usage_max 0.5720 (0.5717) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1688 (0.1685) teacher/entropy 0.0256 (0.0201) teacher/usage_max 0.9794 (0.9755) teacher/usage_min 0.0002 (0.0020) teacher/usage_std 0.4569 (0.4542) nleep/row_max_mean 1497.2808 (1507.2961) nleep/row_max_std 78.5074 (64.7813) nleep/row_min_mean 1462.8601 (1471.3869) lr 1.0628e-03 eta 0:07:22
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,348
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      84.0%, epoch: 23 *******
******* Domain c best val test acc: 99.9%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [27/50] batch [20/203] time 0.102 (0.108) data 0.000 (0.014) loss 1.4508 (1.2451) teacher_loss 0.7066 (0.4669) loss_zs_kd 0.0074 (0.0120) loss_oracle 0.3642 (0.4201) kd_loss 0.5584 (0.5621) acc 62.5000 (82.0312) gate/entropy 0.9793 (0.9795) gate/usage_max 0.5721 (0.5719) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1688 (0.1687) teacher/entropy 0.0000 (0.0256) teacher/usage_max 1.0000 (0.9706) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.4714 (0.4509) nleep/row_max_mean 1527.9622 (1504.8125) nleep/row_max_std 45.3718 (67.9685) nleep/row_min_mean 1487.0078 (1469.2158) lr 1.0000e-03 eta 0:08:44
epoch [27/50] batch [40/203] time 0.091 (0.100) data 0.000 (0.007) loss 1.1023 (1.2422) teacher_loss 0.3245 (0.4629) loss_zs_kd 0.0104 (0.0121) loss_oracle 0.4312 (0.4256) kd_loss 0.5570 (0.5605) acc 87.5000 (82.7344) gate/entropy 0.9795 (0.9795) gate/usage_max 0.5719 (0.5719) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1687 (0.1687) teacher/entropy 0.0021 (0.0222) teacher/usage_max 0.9997 (0.9756) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.4712 (0.4543) nleep/row_max_mean 1515.8718 (1507.7326) nleep/row_max_std 60.4750 (66.3564) nleep/row_min_mean 1477.9792 (1471.6511) lr 1.0000e-03 eta 0:08:04
epoch [27/50] batch [60/203] time 0.094 (0.098) data 0.001 (0.005) loss 1.3047 (1.2483) teacher_loss 0.5335 (0.4697) loss_zs_kd 0.0129 (0.0118) loss_oracle 0.4200 (0.4236) kd_loss 0.5547 (0.5608) acc 75.0000 (82.3958) gate/entropy 0.9794 (0.9794) gate/usage_max 0.5720 (0.5720) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1688 (0.1687) teacher/entropy 0.0048 (0.0213) teacher/usage_max 0.9989 (0.9762) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.4707 (0.4547) nleep/row_max_mean 1523.0410 (1508.3966) nleep/row_max_std 61.2812 (65.6103) nleep/row_min_mean 1481.0686 (1471.9746) lr 1.0000e-03 eta 0:07:50
epoch [27/50] batch [80/203] time 0.088 (0.097) data 0.000 (0.004) loss 1.2468 (1.2615) teacher_loss 0.5166 (0.4848) loss_zs_kd 0.0206 (0.0123) loss_oracle 0.3232 (0.4198) kd_loss 0.5582 (0.5607) acc 84.3750 (81.4062) gate/entropy 0.9792 (0.9794) gate/usage_max 0.5722 (0.5720) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1689 (0.1688) teacher/entropy 0.0001 (0.0201) teacher/usage_max 1.0000 (0.9774) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.4714 (0.4556) nleep/row_max_mean 1530.2371 (1509.2142) nleep/row_max_std 46.7831 (64.9382) nleep/row_min_mean 1491.4940 (1472.7287) lr 1.0000e-03 eta 0:07:42
epoch [27/50] batch [100/203] time 0.096 (0.096) data 0.000 (0.003) loss 1.4010 (1.2587) teacher_loss 0.6419 (0.4830) loss_zs_kd 0.0166 (0.0127) loss_oracle 0.4092 (0.4201) kd_loss 0.5462 (0.5593) acc 71.8750 (81.5000) gate/entropy 0.9792 (0.9794) gate/usage_max 0.5722 (0.5720) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1689 (0.1688) teacher/entropy 0.0197 (0.0201) teacher/usage_max 0.9922 (0.9788) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.4659 (0.4565) nleep/row_max_mean 1505.1224 (1508.2512) nleep/row_max_std 76.4922 (66.4731) nleep/row_min_mean 1468.9347 (1471.7161) lr 1.0000e-03 eta 0:07:38
epoch [27/50] batch [120/203] time 0.089 (0.096) data 0.000 (0.003) loss 1.1874 (1.2575) teacher_loss 0.4491 (0.4806) loss_zs_kd 0.0090 (0.0129) loss_oracle 0.3900 (0.4211) kd_loss 0.5388 (0.5599) acc 81.2500 (81.6927) gate/entropy 0.9793 (0.9794) gate/usage_max 0.5721 (0.5720) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1688 (0.1688) teacher/entropy 0.0375 (0.0201) teacher/usage_max 0.9819 (0.9783) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.4587 (0.4562) nleep/row_max_mean 1483.5801 (1508.1858) nleep/row_max_std 82.2507 (66.2117) nleep/row_min_mean 1453.1426 (1471.6479) lr 1.0000e-03 eta 0:07:33
epoch [27/50] batch [140/203] time 0.097 (0.096) data 0.000 (0.002) loss 1.1765 (1.2469) teacher_loss 0.4067 (0.4717) loss_zs_kd 0.0166 (0.0133) loss_oracle 0.4230 (0.4185) kd_loss 0.5500 (0.5593) acc 90.6250 (82.2098) gate/entropy 0.9792 (0.9794) gate/usage_max 0.5722 (0.5720) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1689 (0.1688) teacher/entropy 0.0124 (0.0202) teacher/usage_max 0.9958 (0.9787) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4684 (0.4565) nleep/row_max_mean 1522.5020 (1508.0406) nleep/row_max_std 48.9629 (66.3622) nleep/row_min_mean 1483.5529 (1471.4837) lr 1.0000e-03 eta 0:07:36
epoch [27/50] batch [160/203] time 0.095 (0.096) data 0.000 (0.002) loss 1.1736 (1.2447) teacher_loss 0.4096 (0.4666) loss_zs_kd 0.0064 (0.0131) loss_oracle 0.4145 (0.4207) kd_loss 0.5536 (0.5612) acc 84.3750 (82.4219) gate/entropy 0.9792 (0.9793) gate/usage_max 0.5722 (0.5721) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1689 (0.1688) teacher/entropy 0.0701 (0.0208) teacher/usage_max 0.9336 (0.9761) teacher/usage_min 0.0035 (0.0014) teacher/usage_std 0.4252 (0.4547) nleep/row_max_mean 1481.6781 (1508.1103) nleep/row_max_std 88.2791 (66.2512) nleep/row_min_mean 1448.1980 (1471.5749) lr 1.0000e-03 eta 0:07:32
epoch [27/50] batch [180/203] time 0.091 (0.096) data 0.000 (0.002) loss 1.3035 (1.2524) teacher_loss 0.5329 (0.4742) loss_zs_kd 0.0195 (0.0131) loss_oracle 0.4063 (0.4212) kd_loss 0.5576 (0.5610) acc 84.3750 (81.9271) gate/entropy 0.9791 (0.9793) gate/usage_max 0.5723 (0.5721) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1690 (0.1688) teacher/entropy 0.0006 (0.0211) teacher/usage_max 0.9999 (0.9759) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.4714 (0.4545) nleep/row_max_mean 1505.2483 (1507.8585) nleep/row_max_std 65.6430 (66.2831) nleep/row_min_mean 1473.6722 (1471.4686) lr 1.0000e-03 eta 0:07:29
epoch [27/50] batch [200/203] time 0.131 (0.095) data 0.000 (0.002) loss 1.3051 (1.2546) teacher_loss 0.5331 (0.4769) loss_zs_kd 0.0158 (0.0130) loss_oracle 0.4123 (0.4209) kd_loss 0.5580 (0.5607) acc 78.1250 (81.7344) gate/entropy 0.9791 (0.9793) gate/usage_max 0.5723 (0.5721) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1690 (0.1688) teacher/entropy 0.0001 (0.0210) teacher/usage_max 1.0000 (0.9764) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.4714 (0.4549) nleep/row_max_mean 1520.0099 (1507.3883) nleep/row_max_std 42.7389 (66.6507) nleep/row_min_mean 1479.9990 (1471.0352) lr 1.0000e-03 eta 0:07:25
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,348
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 87.5%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      84.0%, epoch: 23 *******
******* Domain c best val test acc: 99.9%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [28/50] batch [20/203] time 0.088 (0.102) data 0.000 (0.013) loss 1.2202 (1.2351) teacher_loss 0.4342 (0.4419) loss_zs_kd 0.0089 (0.0136) loss_oracle 0.3839 (0.4297) kd_loss 0.5897 (0.5716) acc 87.5000 (83.4375) gate/entropy 0.9790 (0.9791) gate/usage_max 0.5724 (0.5723) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0197 (0.0242) teacher/usage_max 0.9477 (0.9618) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.4349 (0.4448) nleep/row_max_mean 1524.1978 (1507.6576) nleep/row_max_std 46.5871 (65.1169) nleep/row_min_mean 1484.8387 (1471.5072) lr 9.3721e-04 eta 0:07:52
epoch [28/50] batch [40/203] time 0.094 (0.097) data 0.000 (0.006) loss 1.2824 (1.2362) teacher_loss 0.5095 (0.4502) loss_zs_kd 0.0185 (0.0135) loss_oracle 0.4196 (0.4253) kd_loss 0.5538 (0.5665) acc 81.2500 (82.8125) gate/entropy 0.9791 (0.9791) gate/usage_max 0.5723 (0.5723) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0053 (0.0225) teacher/usage_max 0.9989 (0.9685) teacher/usage_min 0.0003 (0.0010) teacher/usage_std 0.4706 (0.4495) nleep/row_max_mean 1513.9498 (1507.3287) nleep/row_max_std 41.0798 (64.6982) nleep/row_min_mean 1475.3293 (1471.0687) lr 9.3721e-04 eta 0:07:28
epoch [28/50] batch [60/203] time 0.097 (0.097) data 0.000 (0.004) loss 1.2474 (1.2557) teacher_loss 0.4930 (0.4745) loss_zs_kd 0.0043 (0.0129) loss_oracle 0.4088 (0.4208) kd_loss 0.5478 (0.5644) acc 78.1250 (82.0833) gate/entropy 0.9791 (0.9791) gate/usage_max 0.5723 (0.5723) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0239 (0.0215) teacher/usage_max 0.9862 (0.9717) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.4616 (0.4517) nleep/row_max_mean 1506.3276 (1505.8806) nleep/row_max_std 52.1618 (64.0393) nleep/row_min_mean 1469.8713 (1469.8501) lr 9.3721e-04 eta 0:07:25
epoch [28/50] batch [80/203] time 0.097 (0.096) data 0.001 (0.003) loss 1.3746 (1.2627) teacher_loss 0.4564 (0.4812) loss_zs_kd 0.0071 (0.0130) loss_oracle 0.5350 (0.4213) kd_loss 0.6471 (0.5644) acc 81.2500 (81.4844) gate/entropy 0.9789 (0.9791) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0032 (0.0202) teacher/usage_max 0.9059 (0.9730) teacher/usage_min 0.0005 (0.0010) teacher/usage_std 0.4066 (0.4526) nleep/row_max_mean 1518.3765 (1507.1660) nleep/row_max_std 38.8484 (62.8114) nleep/row_min_mean 1482.7351 (1470.9259) lr 9.3721e-04 eta 0:07:22
epoch [28/50] batch [100/203] time 0.098 (0.097) data 0.000 (0.003) loss 1.2376 (1.2611) teacher_loss 0.4982 (0.4809) loss_zs_kd 0.0138 (0.0123) loss_oracle 0.3704 (0.4223) kd_loss 0.5474 (0.5629) acc 78.1250 (81.6250) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0214 (0.0199) teacher/usage_max 0.9888 (0.9748) teacher/usage_min 0.0002 (0.0009) teacher/usage_std 0.4635 (0.4538) nleep/row_max_mean 1518.2715 (1507.0231) nleep/row_max_std 32.4180 (62.8318) nleep/row_min_mean 1482.9403 (1470.8225) lr 9.3721e-04 eta 0:07:23
epoch [28/50] batch [120/203] time 0.100 (0.097) data 0.000 (0.002) loss 1.2597 (1.2594) teacher_loss 0.4857 (0.4809) loss_zs_kd 0.0097 (0.0125) loss_oracle 0.4418 (0.4209) kd_loss 0.5482 (0.5619) acc 81.2500 (81.7969) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5724 (0.5724) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0125 (0.0205) teacher/usage_max 0.9972 (0.9751) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4695 (0.4540) nleep/row_max_mean 1506.5413 (1507.1895) nleep/row_max_std 56.7249 (63.3402) nleep/row_min_mean 1468.7925 (1471.0220) lr 9.3721e-04 eta 0:07:21
epoch [28/50] batch [140/203] time 0.090 (0.097) data 0.000 (0.002) loss 1.2627 (1.2575) teacher_loss 0.5344 (0.4802) loss_zs_kd 0.0157 (0.0126) loss_oracle 0.3339 (0.4198) kd_loss 0.5535 (0.5611) acc 75.0000 (81.8080) gate/entropy 0.9788 (0.9790) gate/usage_max 0.5726 (0.5724) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0053 (0.0206) teacher/usage_max 0.9987 (0.9759) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4705 (0.4545) nleep/row_max_mean 1513.2474 (1507.3632) nleep/row_max_std 60.1739 (63.3304) nleep/row_min_mean 1480.7479 (1471.1841) lr 9.3721e-04 eta 0:07:18
epoch [28/50] batch [160/203] time 0.101 (0.096) data 0.000 (0.002) loss 1.1290 (1.2518) teacher_loss 0.3392 (0.4753) loss_zs_kd 0.0067 (0.0127) loss_oracle 0.4899 (0.4197) kd_loss 0.5414 (0.5603) acc 90.6250 (81.9141) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5726 (0.5724) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0337 (0.0213) teacher/usage_max 0.9823 (0.9758) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4590 (0.4545) nleep/row_max_mean 1507.5742 (1506.9720) nleep/row_max_std 74.5143 (63.7146) nleep/row_min_mean 1468.8589 (1470.8462) lr 9.3721e-04 eta 0:07:14
epoch [28/50] batch [180/203] time 0.094 (0.096) data 0.000 (0.002) loss 1.1695 (1.2522) teacher_loss 0.3966 (0.4754) loss_zs_kd 0.0074 (0.0128) loss_oracle 0.4241 (0.4205) kd_loss 0.5572 (0.5602) acc 81.2500 (81.8576) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0007 (0.0215) teacher/usage_max 0.9999 (0.9758) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4713 (0.4545) nleep/row_max_mean 1517.6038 (1506.8488) nleep/row_max_std 54.2115 (64.1522) nleep/row_min_mean 1476.2955 (1470.7079) lr 9.3721e-04 eta 0:07:12
epoch [28/50] batch [200/203] time 0.084 (0.095) data 0.000 (0.002) loss 1.3617 (1.2578) teacher_loss 0.4556 (0.4811) loss_zs_kd 0.0101 (0.0129) loss_oracle 0.5694 (0.4207) kd_loss 0.6163 (0.5599) acc 78.1250 (81.4688) gate/entropy 0.9788 (0.9790) gate/usage_max 0.5726 (0.5725) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0588 (0.0211) teacher/usage_max 0.8807 (0.9765) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.3901 (0.4550) nleep/row_max_mean 1504.9175 (1507.0526) nleep/row_max_std 79.8597 (64.2988) nleep/row_min_mean 1466.2900 (1470.8606) lr 9.3721e-04 eta 0:07:05
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,345
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      84.0%, epoch: 23 *******
******* Domain c best val test acc: 99.9%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [29/50] batch [20/203] time 0.093 (0.113) data 0.000 (0.017) loss 1.1058 (1.2005) teacher_loss 0.3182 (0.4233) loss_zs_kd 0.0111 (0.0114) loss_oracle 0.4423 (0.4259) kd_loss 0.5609 (0.5585) acc 81.2500 (82.6562) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0476 (0.0197) teacher/usage_max 0.9482 (0.9791) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4353 (0.4568) nleep/row_max_mean 1513.7573 (1508.6013) nleep/row_max_std 64.1871 (66.4735) nleep/row_min_mean 1479.5476 (1472.7366) lr 8.7467e-04 eta 0:08:22
epoch [29/50] batch [40/203] time 0.090 (0.105) data 0.000 (0.009) loss 1.1041 (1.2594) teacher_loss 0.3438 (0.4825) loss_zs_kd 0.0148 (0.0119) loss_oracle 0.3925 (0.4248) kd_loss 0.5567 (0.5585) acc 87.5000 (80.9375) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0008 (0.0215) teacher/usage_max 0.9999 (0.9771) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.4713 (0.4554) nleep/row_max_mean 1503.8997 (1508.3047) nleep/row_max_std 70.0339 (65.8093) nleep/row_min_mean 1465.9167 (1472.2868) lr 8.7467e-04 eta 0:07:43
epoch [29/50] batch [60/203] time 0.096 (0.108) data 0.001 (0.006) loss 1.2770 (1.2721) teacher_loss 0.4935 (0.4922) loss_zs_kd 0.0122 (0.0127) loss_oracle 0.4408 (0.4282) kd_loss 0.5570 (0.5594) acc 81.2500 (80.5729) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0005 (0.0242) teacher/usage_max 0.9999 (0.9735) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.4714 (0.4529) nleep/row_max_mean 1511.4430 (1507.3265) nleep/row_max_std 63.3838 (67.3991) nleep/row_min_mean 1475.5815 (1471.4130) lr 8.7467e-04 eta 0:07:55
epoch [29/50] batch [80/203] time 0.095 (0.104) data 0.000 (0.005) loss 1.4041 (1.2642) teacher_loss 0.5492 (0.4813) loss_zs_kd 0.0177 (0.0130) loss_oracle 0.4884 (0.4316) kd_loss 0.6019 (0.5606) acc 78.1250 (81.2500) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0264 (0.0236) teacher/usage_max 0.9281 (0.9729) teacher/usage_min 0.0313 (0.0029) teacher/usage_std 0.4206 (0.4524) nleep/row_max_mean 1510.5054 (1507.7965) nleep/row_max_std 63.1114 (65.7302) nleep/row_min_mean 1472.9019 (1471.5323) lr 8.7467e-04 eta 0:07:38
epoch [29/50] batch [100/203] time 0.094 (0.103) data 0.000 (0.004) loss 1.3359 (1.2630) teacher_loss 0.5528 (0.4802) loss_zs_kd 0.0122 (0.0135) loss_oracle 0.4118 (0.4301) kd_loss 0.5712 (0.5609) acc 84.3750 (81.5625) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0179 (0.0227) teacher/usage_max 0.9679 (0.9734) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.4489 (0.4528) nleep/row_max_mean 1503.5835 (1508.2701) nleep/row_max_std 68.8898 (64.7180) nleep/row_min_mean 1470.6088 (1471.9674) lr 8.7467e-04 eta 0:07:31
epoch [29/50] batch [120/203] time 0.092 (0.103) data 0.000 (0.003) loss 1.2296 (1.2669) teacher_loss 0.4499 (0.4850) loss_zs_kd 0.0246 (0.0137) loss_oracle 0.4340 (0.4273) kd_loss 0.5505 (0.5614) acc 87.5000 (81.2240) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5728 (0.5727) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0582 (0.0219) teacher/usage_max 0.9478 (0.9738) teacher/usage_min 0.0097 (0.0027) teacher/usage_std 0.4347 (0.4530) nleep/row_max_mean 1510.5452 (1507.8035) nleep/row_max_std 67.8705 (64.6703) nleep/row_min_mean 1473.3076 (1471.5186) lr 8.7467e-04 eta 0:07:26
epoch [29/50] batch [140/203] time 0.090 (0.102) data 0.000 (0.003) loss 1.0899 (1.2633) teacher_loss 0.3474 (0.4835) loss_zs_kd 0.0132 (0.0136) loss_oracle 0.3783 (0.4248) kd_loss 0.5468 (0.5606) acc 87.5000 (81.1830) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0305 (0.0216) teacher/usage_max 0.9798 (0.9748) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.4572 (0.4538) nleep/row_max_mean 1509.7175 (1507.6275) nleep/row_max_std 61.2266 (64.4860) nleep/row_min_mean 1472.5496 (1471.4111) lr 8.7467e-04 eta 0:07:20
epoch [29/50] batch [160/203] time 0.104 (0.101) data 0.000 (0.002) loss 1.1765 (1.2614) teacher_loss 0.3712 (0.4822) loss_zs_kd 0.0281 (0.0134) loss_oracle 0.4411 (0.4244) kd_loss 0.5706 (0.5603) acc 84.3750 (81.2891) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0273 (0.0214) teacher/usage_max 0.9588 (0.9754) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.4426 (0.4541) nleep/row_max_mean 1520.1232 (1507.7363) nleep/row_max_std 45.3658 (63.8107) nleep/row_min_mean 1480.4573 (1471.4637) lr 8.7467e-04 eta 0:07:16
epoch [29/50] batch [180/203] time 0.096 (0.101) data 0.000 (0.002) loss 1.2359 (1.2570) teacher_loss 0.4794 (0.4789) loss_zs_kd 0.0167 (0.0133) loss_oracle 0.3841 (0.4237) kd_loss 0.5561 (0.5596) acc 71.8750 (81.5799) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5728 (0.5727) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0501 (0.0212) teacher/usage_max 0.9503 (0.9762) teacher/usage_min 0.0189 (0.0022) teacher/usage_std 0.4363 (0.4547) nleep/row_max_mean 1506.9507 (1507.7331) nleep/row_max_std 66.6136 (63.7990) nleep/row_min_mean 1470.8569 (1471.4538) lr 8.7467e-04 eta 0:07:11
epoch [29/50] batch [200/203] time 0.089 (0.100) data 0.000 (0.002) loss 1.2789 (1.2566) teacher_loss 0.4591 (0.4774) loss_zs_kd 0.0160 (0.0132) loss_oracle 0.4492 (0.4250) kd_loss 0.5872 (0.5600) acc 84.3750 (81.7344) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5728 (0.5727) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0008 (0.0208) teacher/usage_max 0.9687 (0.9763) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.4494 (0.4548) nleep/row_max_mean 1518.7073 (1507.7160) nleep/row_max_std 44.4697 (63.6502) nleep/row_min_mean 1482.2694 (1471.4583) lr 8.7467e-04 eta 0:07:05
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,344
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      84.0%, epoch: 23 *******
******* Domain c best val test acc: 99.9%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [30/50] batch [20/203] time 0.073 (0.088) data 0.000 (0.011) loss 1.2600 (1.2106) teacher_loss 0.4834 (0.4329) loss_zs_kd 0.0198 (0.0132) loss_oracle 0.4262 (0.4214) kd_loss 0.5536 (0.5604) acc 78.1250 (81.8750) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0042 (0.0234) teacher/usage_max 0.9992 (0.9729) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.4709 (0.4524) nleep/row_max_mean 1512.0854 (1508.1173) nleep/row_max_std 65.0031 (65.2861) nleep/row_min_mean 1478.6509 (1473.0191) lr 8.1262e-04 eta 0:06:14
epoch [30/50] batch [40/203] time 0.059 (0.083) data 0.000 (0.006) loss 1.1636 (1.2149) teacher_loss 0.3658 (0.4356) loss_zs_kd 0.0196 (0.0134) loss_oracle 0.4367 (0.4185) kd_loss 0.5696 (0.5634) acc 81.2500 (82.3438) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0288 (0.0205) teacher/usage_max 0.9581 (0.9728) teacher/usage_min 0.0024 (0.0027) teacher/usage_std 0.4420 (0.4524) nleep/row_max_mean 1520.4590 (1506.8082) nleep/row_max_std 50.7978 (62.4049) nleep/row_min_mean 1485.6875 (1472.3230) lr 8.1262e-04 eta 0:05:51
epoch [30/50] batch [60/203] time 0.061 (0.076) data 0.000 (0.004) loss 1.0161 (1.2047) teacher_loss 0.3040 (0.4300) loss_zs_kd 0.0125 (0.0131) loss_oracle 0.3595 (0.4162) kd_loss 0.5261 (0.5601) acc 87.5000 (82.8125) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0626 (0.0250) teacher/usage_max 0.9679 (0.9716) teacher/usage_min 0.0005 (0.0035) teacher/usage_std 0.4489 (0.4515) nleep/row_max_mean 1499.3594 (1506.9118) nleep/row_max_std 64.4319 (61.9343) nleep/row_min_mean 1467.6050 (1472.8769) lr 8.1262e-04 eta 0:05:19
epoch [30/50] batch [80/203] time 0.060 (0.076) data 0.000 (0.003) loss 1.3242 (1.2174) teacher_loss 0.5138 (0.4362) loss_zs_kd 0.0249 (0.0132) loss_oracle 0.4499 (0.4203) kd_loss 0.5730 (0.5645) acc 68.7500 (82.8906) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0442 (0.0276) teacher/usage_max 0.9391 (0.9645) teacher/usage_min 0.0092 (0.0053) teacher/usage_std 0.4287 (0.4465) nleep/row_max_mean 1483.5107 (1506.6199) nleep/row_max_std 77.7503 (61.8209) nleep/row_min_mean 1454.6781 (1472.8504) lr 8.1262e-04 eta 0:05:16
epoch [30/50] batch [100/203] time 0.059 (0.073) data 0.000 (0.002) loss 1.1344 (1.2280) teacher_loss 0.3626 (0.4470) loss_zs_kd 0.0195 (0.0137) loss_oracle 0.4004 (0.4192) kd_loss 0.5618 (0.5646) acc 84.3750 (82.5312) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0544 (0.0284) teacher/usage_max 0.9398 (0.9635) teacher/usage_min 0.0146 (0.0057) teacher/usage_std 0.4290 (0.4459) nleep/row_max_mean 1511.5800 (1506.0435) nleep/row_max_std 58.1364 (62.3456) nleep/row_min_mean 1480.6355 (1472.4638) lr 8.1262e-04 eta 0:05:02
epoch [30/50] batch [120/203] time 0.055 (0.070) data 0.000 (0.002) loss 1.5504 (1.2366) teacher_loss 0.7665 (0.4540) loss_zs_kd 0.0198 (0.0141) loss_oracle 0.4339 (0.4214) kd_loss 0.5570 (0.5649) acc 78.1250 (82.3958) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0217 (0.0284) teacher/usage_max 0.9779 (0.9632) teacher/usage_min 0.0000 (0.0052) teacher/usage_std 0.4559 (0.4457) nleep/row_max_mean 1505.6923 (1506.1811) nleep/row_max_std 65.5503 (61.7063) nleep/row_min_mean 1474.4858 (1472.6544) lr 8.1262e-04 eta 0:04:51
epoch [30/50] batch [140/203] time 0.063 (0.069) data 0.000 (0.002) loss 1.1038 (1.2386) teacher_loss 0.3213 (0.4565) loss_zs_kd 0.0100 (0.0141) loss_oracle 0.4256 (0.4219) kd_loss 0.5647 (0.5641) acc 84.3750 (82.2545) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0364 (0.0288) teacher/usage_max 0.9552 (0.9636) teacher/usage_min 0.0018 (0.0056) teacher/usage_std 0.4401 (0.4459) nleep/row_max_mean 1490.8142 (1505.7327) nleep/row_max_std 78.8991 (62.0589) nleep/row_min_mean 1461.1982 (1472.2409) lr 8.1262e-04 eta 0:04:42
epoch [30/50] batch [160/203] time 0.084 (0.068) data 0.000 (0.002) loss 1.1387 (1.2437) teacher_loss 0.3684 (0.4606) loss_zs_kd 0.0143 (0.0144) loss_oracle 0.4165 (0.4223) kd_loss 0.5549 (0.5647) acc 90.6250 (81.9336) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0023 (0.0282) teacher/usage_max 0.9996 (0.9636) teacher/usage_min 0.0001 (0.0052) teacher/usage_std 0.4711 (0.4459) nleep/row_max_mean 1520.9723 (1505.7147) nleep/row_max_std 45.8632 (62.2667) nleep/row_min_mean 1485.4349 (1472.2025) lr 8.1262e-04 eta 0:04:39
epoch [30/50] batch [180/203] time 0.065 (0.070) data 0.000 (0.001) loss 1.2672 (1.2452) teacher_loss 0.5073 (0.4628) loss_zs_kd 0.0263 (0.0145) loss_oracle 0.4193 (0.4233) kd_loss 0.5371 (0.5635) acc 78.1250 (81.8403) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0333 (0.0285) teacher/usage_max 0.9863 (0.9645) teacher/usage_min 0.0057 (0.0051) teacher/usage_std 0.4617 (0.4465) nleep/row_max_mean 1506.2600 (1505.2359) nleep/row_max_std 58.7813 (62.4656) nleep/row_min_mean 1472.3286 (1471.7035) lr 8.1262e-04 eta 0:04:45
epoch [30/50] batch [200/203] time 0.069 (0.072) data 0.000 (0.001) loss 1.2668 (1.2432) teacher_loss 0.4715 (0.4610) loss_zs_kd 0.0146 (0.0146) loss_oracle 0.4872 (0.4237) kd_loss 0.5445 (0.5631) acc 78.1250 (81.8750) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0686 (0.0286) teacher/usage_max 0.9429 (0.9648) teacher/usage_min 0.0016 (0.0046) teacher/usage_std 0.4316 (0.4467) nleep/row_max_mean 1483.6958 (1505.2282) nleep/row_max_std 67.4662 (62.6341) nleep/row_min_mean 1455.1870 (1471.6262) lr 8.1262e-04 eta 0:04:51
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,353
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 87.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      84.2%, epoch: 30 *******
******* Domain c best val test acc: 99.9%, epoch: 30 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [31/50] batch [20/203] time 0.102 (0.116) data 0.000 (0.017) loss 1.2230 (1.2314) teacher_loss 0.4090 (0.4412) loss_zs_kd 0.0119 (0.0128) loss_oracle 0.4577 (0.4323) kd_loss 0.5793 (0.5677) acc 84.3750 (83.2812) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2133 (0.2132) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0108 (0.0276) teacher/usage_max 0.9662 (0.9609) teacher/usage_min 0.0001 (0.0048) teacher/usage_std 0.4477 (0.4441) nleep/row_max_mean 1503.5591 (1505.7066) nleep/row_max_std 68.5994 (65.7647) nleep/row_min_mean 1471.8856 (1471.5513) lr 7.5131e-04 eta 0:07:49
epoch [31/50] batch [40/203] time 0.094 (0.108) data 0.000 (0.009) loss 1.0933 (1.2618) teacher_loss 0.3031 (0.4711) loss_zs_kd 0.0037 (0.0139) loss_oracle 0.4273 (0.4239) kd_loss 0.5747 (0.5718) acc 84.3750 (81.3281) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2133 (0.2132) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0200 (0.0277) teacher/usage_max 0.9616 (0.9566) teacher/usage_min 0.0075 (0.0067) teacher/usage_std 0.4444 (0.4411) nleep/row_max_mean 1519.7705 (1505.6998) nleep/row_max_std 48.5121 (62.8410) nleep/row_min_mean 1482.5243 (1471.2782) lr 7.5131e-04 eta 0:07:12
epoch [31/50] batch [60/203] time 0.105 (0.106) data 0.001 (0.006) loss 1.0547 (1.2517) teacher_loss 0.2537 (0.4662) loss_zs_kd 0.0291 (0.0140) loss_oracle 0.4306 (0.4201) kd_loss 0.5711 (0.5685) acc 93.7500 (81.7188) gate/entropy 0.9785 (0.9784) gate/usage_max 0.5729 (0.5731) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0205 (0.0278) teacher/usage_max 0.9649 (0.9600) teacher/usage_min 0.0052 (0.0059) teacher/usage_std 0.4467 (0.4434) nleep/row_max_mean 1487.3928 (1505.9375) nleep/row_max_std 78.4402 (62.3839) nleep/row_min_mean 1458.2058 (1471.7231) lr 7.5131e-04 eta 0:07:02
epoch [31/50] batch [80/203] time 0.107 (0.104) data 0.000 (0.005) loss 1.0976 (1.2472) teacher_loss 0.3508 (0.4623) loss_zs_kd 0.0147 (0.0142) loss_oracle 0.3855 (0.4202) kd_loss 0.5467 (0.5677) acc 87.5000 (82.0312) gate/entropy 0.9782 (0.9784) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0144 (0.0272) teacher/usage_max 0.9954 (0.9614) teacher/usage_min 0.0000 (0.0047) teacher/usage_std 0.4682 (0.4444) nleep/row_max_mean 1506.8627 (1506.6384) nleep/row_max_std 74.0247 (62.1558) nleep/row_min_mean 1472.4834 (1472.3276) lr 7.5131e-04 eta 0:06:54
epoch [31/50] batch [100/203] time 0.101 (0.103) data 0.000 (0.004) loss 1.2127 (1.2417) teacher_loss 0.3758 (0.4519) loss_zs_kd 0.0197 (0.0149) loss_oracle 0.5156 (0.4244) kd_loss 0.5693 (0.5701) acc 93.7500 (82.6875) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0424 (0.0279) teacher/usage_max 0.9442 (0.9582) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.4326 (0.4421) nleep/row_max_mean 1481.1079 (1506.8810) nleep/row_max_std 85.7256 (62.4295) nleep/row_min_mean 1451.5488 (1472.7534) lr 7.5131e-04 eta 0:06:47
epoch [31/50] batch [120/203] time 0.096 (0.102) data 0.000 (0.003) loss 1.0721 (1.2493) teacher_loss 0.3036 (0.4613) loss_zs_kd 0.0178 (0.0157) loss_oracle 0.3616 (0.4215) kd_loss 0.5788 (0.5695) acc 87.5000 (82.3958) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0225 (0.0296) teacher/usage_max 0.9546 (0.9571) teacher/usage_min 0.0141 (0.0061) teacher/usage_std 0.4394 (0.4414) nleep/row_max_mean 1504.6086 (1506.3427) nleep/row_max_std 62.5737 (63.0776) nleep/row_min_mean 1472.1575 (1472.4290) lr 7.5131e-04 eta 0:06:40
epoch [31/50] batch [140/203] time 0.095 (0.101) data 0.000 (0.003) loss 1.3887 (1.2486) teacher_loss 0.6345 (0.4607) loss_zs_kd 0.0193 (0.0158) loss_oracle 0.3901 (0.4218) kd_loss 0.5495 (0.5691) acc 71.8750 (81.9866) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0092 (0.0295) teacher/usage_max 0.9979 (0.9576) teacher/usage_min 0.0003 (0.0064) teacher/usage_std 0.4699 (0.4417) nleep/row_max_mean 1511.1487 (1506.6831) nleep/row_max_std 66.4093 (62.7715) nleep/row_min_mean 1481.4833 (1472.8623) lr 7.5131e-04 eta 0:06:37
epoch [31/50] batch [160/203] time 0.095 (0.101) data 0.000 (0.002) loss 1.1477 (1.2506) teacher_loss 0.4071 (0.4622) loss_zs_kd 0.0226 (0.0158) loss_oracle 0.3532 (0.4235) kd_loss 0.5527 (0.5688) acc 87.5000 (82.0508) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2133 (0.2132) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0050 (0.0294) teacher/usage_max 0.9991 (0.9579) teacher/usage_min 0.0004 (0.0061) teacher/usage_std 0.4708 (0.4420) nleep/row_max_mean 1509.0569 (1506.5540) nleep/row_max_std 58.0484 (62.9136) nleep/row_min_mean 1475.7322 (1472.8574) lr 7.5131e-04 eta 0:06:33
epoch [31/50] batch [180/203] time 0.091 (0.100) data 0.000 (0.002) loss 1.3929 (1.2561) teacher_loss 0.5934 (0.4689) loss_zs_kd 0.0341 (0.0161) loss_oracle 0.4046 (0.4237) kd_loss 0.5802 (0.5673) acc 75.0000 (81.9444) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0476 (0.0296) teacher/usage_max 0.9279 (0.9593) teacher/usage_min 0.0325 (0.0058) teacher/usage_std 0.4204 (0.4429) nleep/row_max_mean 1505.5438 (1506.1663) nleep/row_max_std 58.6455 (63.2986) nleep/row_min_mean 1471.9758 (1472.4518) lr 7.5131e-04 eta 0:06:28
epoch [31/50] batch [200/203] time 0.088 (0.100) data 0.000 (0.002) loss 1.1254 (1.2535) teacher_loss 0.2803 (0.4673) loss_zs_kd 0.0184 (0.0160) loss_oracle 0.4800 (0.4235) kd_loss 0.5959 (0.5665) acc 90.6250 (81.9531) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0628 (0.0291) teacher/usage_max 0.8966 (0.9606) teacher/usage_min 0.0000 (0.0053) teacher/usage_std 0.4005 (0.4438) nleep/row_max_mean 1474.7334 (1506.2745) nleep/row_max_std 95.6927 (63.2302) nleep/row_min_mean 1444.9817 (1472.4863) lr 7.5131e-04 eta 0:06:25
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,358
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 87.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      84.4%, epoch: 31 *******
******* Domain c best val test acc: 99.9%, epoch: 31 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [32/50] batch [20/203] time 0.146 (0.132) data 0.001 (0.019) loss 1.1606 (1.2349) teacher_loss 0.4025 (0.4699) loss_zs_kd 0.0163 (0.0176) loss_oracle 0.4042 (0.4052) kd_loss 0.5478 (0.5536) acc 81.2500 (81.7188) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0110 (0.0258) teacher/usage_max 0.9976 (0.9767) teacher/usage_min 0.0006 (0.0021) teacher/usage_std 0.4697 (0.4551) nleep/row_max_mean 1510.4105 (1509.8368) nleep/row_max_std 63.9724 (65.7931) nleep/row_min_mean 1477.7958 (1475.1019) lr 6.9098e-04 eta 0:08:25
epoch [32/50] batch [40/203] time 0.090 (0.111) data 0.000 (0.010) loss 1.0695 (1.2462) teacher_loss 0.3162 (0.4647) loss_zs_kd 0.0092 (0.0166) loss_oracle 0.4005 (0.4198) kd_loss 0.5485 (0.5633) acc 87.5000 (82.1094) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0365 (0.0304) teacher/usage_max 0.9711 (0.9623) teacher/usage_min 0.0000 (0.0054) teacher/usage_std 0.4511 (0.4451) nleep/row_max_mean 1507.7546 (1507.2469) nleep/row_max_std 75.1051 (67.8708) nleep/row_min_mean 1476.9641 (1473.1218) lr 6.9098e-04 eta 0:07:03
epoch [32/50] batch [60/203] time 0.094 (0.105) data 0.001 (0.007) loss 1.3825 (1.2474) teacher_loss 0.5303 (0.4642) loss_zs_kd 0.0236 (0.0158) loss_oracle 0.4995 (0.4196) kd_loss 0.5906 (0.5654) acc 71.8750 (82.0312) gate/entropy 0.9780 (0.9782) gate/usage_max 0.5734 (0.5732) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1698 (0.1696) teacher/entropy 0.0199 (0.0304) teacher/usage_max 0.9450 (0.9601) teacher/usage_min 0.0000 (0.0060) teacher/usage_std 0.4331 (0.4435) nleep/row_max_mean 1509.0674 (1507.0705) nleep/row_max_std 74.5008 (68.0728) nleep/row_min_mean 1474.3628 (1472.6991) lr 6.9098e-04 eta 0:06:38
epoch [32/50] batch [80/203] time 0.087 (0.102) data 0.000 (0.005) loss 1.6343 (1.2605) teacher_loss 0.8926 (0.4734) loss_zs_kd 0.0107 (0.0162) loss_oracle 0.3784 (0.4234) kd_loss 0.5471 (0.5673) acc 50.0000 (81.3281) gate/entropy 0.9781 (0.9782) gate/usage_max 0.5733 (0.5733) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1697 (0.1696) teacher/entropy 0.0133 (0.0302) teacher/usage_max 0.9959 (0.9585) teacher/usage_min 0.0002 (0.0060) teacher/usage_std 0.4685 (0.4424) nleep/row_max_mean 1518.8081 (1506.7128) nleep/row_max_std 43.0036 (68.1126) nleep/row_min_mean 1482.1182 (1472.3271) lr 6.9098e-04 eta 0:06:25
epoch [32/50] batch [100/203] time 0.102 (0.100) data 0.000 (0.004) loss 1.1243 (1.2500) teacher_loss 0.2685 (0.4593) loss_zs_kd 0.0159 (0.0164) loss_oracle 0.5331 (0.4290) kd_loss 0.5812 (0.5680) acc 90.6250 (82.1562) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5733) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0886 (0.0306) teacher/usage_max 0.8854 (0.9573) teacher/usage_min 0.0000 (0.0062) teacher/usage_std 0.3931 (0.4415) nleep/row_max_mean 1478.8679 (1506.2588) nleep/row_max_std 93.7545 (67.2844) nleep/row_min_mean 1448.8069 (1472.1035) lr 6.9098e-04 eta 0:06:17
epoch [32/50] batch [120/203] time 0.102 (0.100) data 0.000 (0.003) loss 1.2740 (1.2381) teacher_loss 0.4954 (0.4491) loss_zs_kd 0.0230 (0.0168) loss_oracle 0.4222 (0.4271) kd_loss 0.5560 (0.5670) acc 78.1250 (82.6562) gate/entropy 0.9781 (0.9782) gate/usage_max 0.5733 (0.5733) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0213 (0.0308) teacher/usage_max 0.9787 (0.9581) teacher/usage_min 0.0001 (0.0068) teacher/usage_std 0.4565 (0.4421) nleep/row_max_mean 1507.1241 (1506.9726) nleep/row_max_std 67.3847 (66.6570) nleep/row_min_mean 1476.8676 (1472.8072) lr 6.9098e-04 eta 0:06:12
epoch [32/50] batch [140/203] time 0.092 (0.099) data 0.000 (0.003) loss 1.3783 (1.2384) teacher_loss 0.6030 (0.4481) loss_zs_kd 0.0205 (0.0168) loss_oracle 0.3765 (0.4282) kd_loss 0.5768 (0.5678) acc 78.1250 (82.5893) gate/entropy 0.9781 (0.9782) gate/usage_max 0.5733 (0.5733) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0093 (0.0303) teacher/usage_max 0.9696 (0.9578) teacher/usage_min 0.0006 (0.0061) teacher/usage_std 0.4501 (0.4419) nleep/row_max_mean 1505.4958 (1506.7849) nleep/row_max_std 71.7281 (66.1892) nleep/row_min_mean 1469.1802 (1472.6677) lr 6.9098e-04 eta 0:06:07
epoch [32/50] batch [160/203] time 0.096 (0.098) data 0.000 (0.003) loss 1.1879 (1.2373) teacher_loss 0.4508 (0.4460) loss_zs_kd 0.0073 (0.0172) loss_oracle 0.3892 (0.4293) kd_loss 0.5388 (0.5680) acc 78.1250 (82.6953) gate/entropy 0.9781 (0.9782) gate/usage_max 0.5733 (0.5733) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0341 (0.0305) teacher/usage_max 0.9831 (0.9573) teacher/usage_min 0.0000 (0.0062) teacher/usage_std 0.4595 (0.4416) nleep/row_max_mean 1498.4707 (1506.6095) nleep/row_max_std 88.9671 (66.2256) nleep/row_min_mean 1463.5203 (1472.5559) lr 6.9098e-04 eta 0:06:03
epoch [32/50] batch [180/203] time 0.096 (0.098) data 0.000 (0.002) loss 1.2773 (1.2474) teacher_loss 0.5031 (0.4565) loss_zs_kd 0.0126 (0.0172) loss_oracle 0.4412 (0.4295) kd_loss 0.5473 (0.5675) acc 84.3750 (82.2569) gate/entropy 0.9781 (0.9782) gate/usage_max 0.5734 (0.5733) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0122 (0.0301) teacher/usage_max 0.9967 (0.9582) teacher/usage_min 0.0000 (0.0060) teacher/usage_std 0.4691 (0.4422) nleep/row_max_mean 1495.0128 (1506.3281) nleep/row_max_std 79.4932 (66.0493) nleep/row_min_mean 1459.6169 (1472.3505) lr 6.9098e-04 eta 0:06:01
epoch [32/50] batch [200/203] time 0.084 (0.097) data 0.000 (0.002) loss 1.4807 (1.2462) teacher_loss 0.6409 (0.4536) loss_zs_kd 0.0156 (0.0173) loss_oracle 0.5039 (0.4312) kd_loss 0.5801 (0.5683) acc 68.7500 (82.2500) gate/entropy 0.9781 (0.9781) gate/usage_max 0.5734 (0.5733) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0477 (0.0303) teacher/usage_max 0.9277 (0.9572) teacher/usage_min 0.0119 (0.0059) teacher/usage_std 0.4207 (0.4415) nleep/row_max_mean 1518.7288 (1506.1319) nleep/row_max_std 45.8096 (65.9547) nleep/row_min_mean 1480.8645 (1472.1515) lr 6.9098e-04 eta 0:05:56
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,355
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 87.4%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      84.4%, epoch: 31 *******
******* Domain c best val test acc: 99.9%, epoch: 31 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [33/50] batch [20/203] time 0.091 (0.116) data 0.000 (0.019) loss 1.2141 (1.2535) teacher_loss 0.4562 (0.4526) loss_zs_kd 0.0080 (0.0148) loss_oracle 0.3978 (0.4448) kd_loss 0.5549 (0.5711) acc 78.1250 (82.5000) gate/entropy 0.9781 (0.9781) gate/usage_max 0.5734 (0.5734) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0015 (0.0249) teacher/usage_max 0.9998 (0.9597) teacher/usage_min 0.0000 (0.0060) teacher/usage_std 0.4712 (0.4431) nleep/row_max_mean 1508.6565 (1507.1563) nleep/row_max_std 55.5765 (61.9841) nleep/row_min_mean 1473.9629 (1472.8899) lr 6.3188e-04 eta 0:07:02
epoch [33/50] batch [40/203] time 0.088 (0.106) data 0.000 (0.009) loss 1.5055 (1.2652) teacher_loss 0.7512 (0.4684) loss_zs_kd 0.0125 (0.0171) loss_oracle 0.3770 (0.4434) kd_loss 0.5595 (0.5665) acc 81.2500 (82.8906) gate/entropy 0.9780 (0.9781) gate/usage_max 0.5735 (0.5734) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1698 (0.1697) teacher/entropy 0.0249 (0.0248) teacher/usage_max 0.9714 (0.9645) teacher/usage_min 0.0000 (0.0035) teacher/usage_std 0.4513 (0.4466) nleep/row_max_mean 1508.7561 (1508.7442) nleep/row_max_std 76.5351 (62.0211) nleep/row_min_mean 1474.0835 (1473.9557) lr 6.3188e-04 eta 0:06:22
epoch [33/50] batch [60/203] time 0.106 (0.102) data 0.000 (0.006) loss 1.2176 (1.2479) teacher_loss 0.4557 (0.4555) loss_zs_kd 0.0100 (0.0168) loss_oracle 0.3886 (0.4426) kd_loss 0.5626 (0.5627) acc 87.5000 (83.0729) gate/entropy 0.9780 (0.9781) gate/usage_max 0.5734 (0.5734) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1698 (0.1697) teacher/entropy 0.0439 (0.0288) teacher/usage_max 0.9491 (0.9644) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.4359 (0.4465) nleep/row_max_mean 1492.4768 (1506.0772) nleep/row_max_std 80.4073 (65.1287) nleep/row_min_mean 1462.2593 (1471.7236) lr 6.3188e-04 eta 0:06:07
epoch [33/50] batch [80/203] time 0.094 (0.101) data 0.000 (0.005) loss 1.2112 (1.2432) teacher_loss 0.4533 (0.4500) loss_zs_kd 0.0171 (0.0166) loss_oracle 0.4282 (0.4420) kd_loss 0.5352 (0.5639) acc 81.2500 (83.0469) gate/entropy 0.9781 (0.9781) gate/usage_max 0.5733 (0.5734) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0464 (0.0284) teacher/usage_max 0.9743 (0.9635) teacher/usage_min 0.0097 (0.0045) teacher/usage_std 0.4532 (0.4458) nleep/row_max_mean 1505.8430 (1505.9281) nleep/row_max_std 45.3488 (64.3965) nleep/row_min_mean 1471.7292 (1471.5865) lr 6.3188e-04 eta 0:06:00
epoch [33/50] batch [100/203] time 0.099 (0.101) data 0.000 (0.004) loss 1.1273 (1.2365) teacher_loss 0.3635 (0.4453) loss_zs_kd 0.0208 (0.0163) loss_oracle 0.4187 (0.4402) kd_loss 0.5440 (0.5629) acc 84.3750 (82.9688) gate/entropy 0.9780 (0.9781) gate/usage_max 0.5734 (0.5734) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1698 (0.1697) teacher/entropy 0.0210 (0.0293) teacher/usage_max 0.9910 (0.9635) teacher/usage_min 0.0000 (0.0046) teacher/usage_std 0.4650 (0.4459) nleep/row_max_mean 1495.1240 (1505.3506) nleep/row_max_std 74.1277 (64.9117) nleep/row_min_mean 1461.6559 (1471.0357) lr 6.3188e-04 eta 0:05:57
epoch [33/50] batch [120/203] time 0.094 (0.102) data 0.000 (0.003) loss 1.2320 (1.2334) teacher_loss 0.4641 (0.4444) loss_zs_kd 0.0126 (0.0164) loss_oracle 0.4187 (0.4370) kd_loss 0.5522 (0.5623) acc 78.1250 (82.9948) gate/entropy 0.9779 (0.9780) gate/usage_max 0.5735 (0.5734) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1698 (0.1697) teacher/entropy 0.0302 (0.0296) teacher/usage_max 0.9732 (0.9639) teacher/usage_min 0.0007 (0.0049) teacher/usage_std 0.4526 (0.4461) nleep/row_max_mean 1519.1995 (1505.4059) nleep/row_max_std 61.7741 (64.9082) nleep/row_min_mean 1485.0107 (1471.0965) lr 6.3188e-04 eta 0:05:59
epoch [33/50] batch [140/203] time 0.091 (0.101) data 0.000 (0.003) loss 1.3050 (1.2394) teacher_loss 0.5025 (0.4486) loss_zs_kd 0.0119 (0.0161) loss_oracle 0.3933 (0.4384) kd_loss 0.5999 (0.5636) acc 78.1250 (82.5670) gate/entropy 0.9781 (0.9780) gate/usage_max 0.5733 (0.5734) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0424 (0.0290) teacher/usage_max 0.9129 (0.9632) teacher/usage_min 0.0253 (0.0045) teacher/usage_std 0.4101 (0.4457) nleep/row_max_mean 1494.9500 (1505.5748) nleep/row_max_std 75.8981 (64.7882) nleep/row_min_mean 1462.7441 (1471.1435) lr 6.3188e-04 eta 0:05:54
epoch [33/50] batch [160/203] time 0.094 (0.100) data 0.000 (0.003) loss 1.1605 (1.2461) teacher_loss 0.3433 (0.4559) loss_zs_kd 0.0261 (0.0162) loss_oracle 0.4393 (0.4367) kd_loss 0.5845 (0.5637) acc 87.5000 (82.3828) gate/entropy 0.9779 (0.9780) gate/usage_max 0.5735 (0.5734) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1698 (0.1697) teacher/entropy 0.0021 (0.0280) teacher/usage_max 0.9690 (0.9641) teacher/usage_min 0.0000 (0.0041) teacher/usage_std 0.4496 (0.4462) nleep/row_max_mean 1526.0598 (1505.6291) nleep/row_max_std 44.5752 (64.5945) nleep/row_min_mean 1491.6272 (1471.2455) lr 6.3188e-04 eta 0:05:49
epoch [33/50] batch [180/203] time 0.101 (0.100) data 0.000 (0.002) loss 1.2481 (1.2436) teacher_loss 0.3995 (0.4531) loss_zs_kd 0.0284 (0.0162) loss_oracle 0.4568 (0.4363) kd_loss 0.6060 (0.5643) acc 93.7500 (82.6215) gate/entropy 0.9780 (0.9780) gate/usage_max 0.5734 (0.5734) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1698 (0.1697) teacher/entropy 0.0308 (0.0284) teacher/usage_max 0.9184 (0.9631) teacher/usage_min 0.0000 (0.0040) teacher/usage_std 0.4151 (0.4456) nleep/row_max_mean 1515.0122 (1505.3680) nleep/row_max_std 55.4679 (64.6108) nleep/row_min_mean 1478.3601 (1471.0330) lr 6.3188e-04 eta 0:05:46
epoch [33/50] batch [200/203] time 0.085 (0.099) data 0.000 (0.002) loss 1.3553 (1.2447) teacher_loss 0.5925 (0.4544) loss_zs_kd 0.0256 (0.0159) loss_oracle 0.4003 (0.4360) kd_loss 0.5499 (0.5643) acc 71.8750 (82.4844) gate/entropy 0.9780 (0.9780) gate/usage_max 0.5734 (0.5734) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1698 (0.1698) teacher/entropy 0.0080 (0.0276) teacher/usage_max 0.9982 (0.9638) teacher/usage_min 0.0000 (0.0039) teacher/usage_std 0.4701 (0.4461) nleep/row_max_mean 1509.6914 (1505.7316) nleep/row_max_std 50.1117 (64.0657) nleep/row_min_mean 1475.1106 (1471.4167) lr 6.3188e-04 eta 0:05:41
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,349
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 87.4%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.4%, epoch: 31 *******
******* Domain c best val test acc: 99.9%, epoch: 31 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [34/50] batch [20/203] time 0.100 (0.109) data 0.000 (0.015) loss 1.0386 (1.2757) teacher_loss 0.2793 (0.4854) loss_zs_kd 0.0137 (0.0178) loss_oracle 0.3919 (0.4338) kd_loss 0.5566 (0.5645) acc 87.5000 (80.6250) gate/entropy 0.9780 (0.9780) gate/usage_max 0.5735 (0.5735) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1698 (0.1698) teacher/entropy 0.0207 (0.0296) teacher/usage_max 0.9786 (0.9616) teacher/usage_min 0.0000 (0.0060) teacher/usage_std 0.4563 (0.4445) nleep/row_max_mean 1508.9161 (1502.6128) nleep/row_max_std 66.7271 (67.0231) nleep/row_min_mean 1472.9043 (1468.6962) lr 5.7422e-04 eta 0:06:13
epoch [34/50] batch [40/203] time 0.093 (0.102) data 0.000 (0.008) loss 1.2478 (1.2452) teacher_loss 0.3917 (0.4535) loss_zs_kd 0.0177 (0.0166) loss_oracle 0.4808 (0.4362) kd_loss 0.6068 (0.5653) acc 81.2500 (82.8906) gate/entropy 0.9781 (0.9780) gate/usage_max 0.5734 (0.5735) gate/usage_min 0.2132 (0.2131) gate/usage_std 0.1697 (0.1698) teacher/entropy 0.0161 (0.0312) teacher/usage_max 0.9324 (0.9591) teacher/usage_min 0.0050 (0.0054) teacher/usage_std 0.4243 (0.4428) nleep/row_max_mean 1506.9258 (1501.9138) nleep/row_max_std 44.3656 (66.7692) nleep/row_min_mean 1472.6107 (1468.0214) lr 5.7422e-04 eta 0:05:48
epoch [34/50] batch [60/203] time 0.094 (0.099) data 0.001 (0.005) loss 1.2239 (1.2550) teacher_loss 0.4721 (0.4636) loss_zs_kd 0.0167 (0.0167) loss_oracle 0.4119 (0.4360) kd_loss 0.5375 (0.5650) acc 84.3750 (82.8125) gate/entropy 0.9779 (0.9780) gate/usage_max 0.5736 (0.5735) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1698) teacher/entropy 0.0324 (0.0305) teacher/usage_max 0.9859 (0.9602) teacher/usage_min 0.0002 (0.0043) teacher/usage_std 0.4614 (0.4436) nleep/row_max_mean 1517.5215 (1502.0507) nleep/row_max_std 53.8374 (66.2660) nleep/row_min_mean 1483.8622 (1468.3560) lr 5.7422e-04 eta 0:05:36
epoch [34/50] batch [80/203] time 0.096 (0.098) data 0.000 (0.004) loss 1.2072 (1.2581) teacher_loss 0.4699 (0.4668) loss_zs_kd 0.0125 (0.0166) loss_oracle 0.3732 (0.4361) kd_loss 0.5444 (0.5650) acc 84.3750 (81.9922) gate/entropy 0.9779 (0.9780) gate/usage_max 0.5736 (0.5735) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1698) teacher/entropy 0.0220 (0.0305) teacher/usage_max 0.9894 (0.9601) teacher/usage_min 0.0004 (0.0050) teacher/usage_std 0.4639 (0.4435) nleep/row_max_mean 1515.1676 (1503.2999) nleep/row_max_std 57.3512 (64.4693) nleep/row_min_mean 1478.7080 (1469.4371) lr 5.7422e-04 eta 0:05:31
epoch [34/50] batch [100/203] time 0.165 (0.100) data 0.001 (0.003) loss 1.2477 (1.2483) teacher_loss 0.4829 (0.4563) loss_zs_kd 0.0086 (0.0159) loss_oracle 0.3975 (0.4372) kd_loss 0.5617 (0.5655) acc 78.1250 (82.5938) gate/entropy 0.9780 (0.9780) gate/usage_max 0.5735 (0.5735) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1698 (0.1698) teacher/entropy 0.0304 (0.0298) teacher/usage_max 0.9635 (0.9603) teacher/usage_min 0.0010 (0.0048) teacher/usage_std 0.4458 (0.4436) nleep/row_max_mean 1482.4218 (1503.9296) nleep/row_max_std 83.4310 (63.7104) nleep/row_min_mean 1454.0537 (1470.0858) lr 5.7422e-04 eta 0:05:33
epoch [34/50] batch [120/203] time 0.098 (0.098) data 0.000 (0.003) loss 1.4512 (1.2564) teacher_loss 0.6776 (0.4631) loss_zs_kd 0.0155 (0.0161) loss_oracle 0.3816 (0.4370) kd_loss 0.5751 (0.5667) acc 81.2500 (82.4219) gate/entropy 0.9778 (0.9779) gate/usage_max 0.5736 (0.5735) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1698) teacher/entropy 0.0182 (0.0285) teacher/usage_max 0.9622 (0.9603) teacher/usage_min 0.0065 (0.0051) teacher/usage_std 0.4448 (0.4437) nleep/row_max_mean 1505.2649 (1505.0963) nleep/row_max_std 85.5455 (63.7371) nleep/row_min_mean 1471.1110 (1471.2758) lr 5.7422e-04 eta 0:05:28
epoch [34/50] batch [140/203] time 0.102 (0.098) data 0.000 (0.002) loss 1.2473 (1.2535) teacher_loss 0.4197 (0.4619) loss_zs_kd 0.0160 (0.0160) loss_oracle 0.4518 (0.4345) kd_loss 0.5937 (0.5664) acc 84.3750 (82.2991) gate/entropy 0.9780 (0.9779) gate/usage_max 0.5734 (0.5735) gate/usage_min 0.2132 (0.2131) gate/usage_std 0.1698 (0.1698) teacher/entropy 0.0324 (0.0283) teacher/usage_max 0.9293 (0.9609) teacher/usage_min 0.0332 (0.0055) teacher/usage_std 0.4214 (0.4440) nleep/row_max_mean 1487.0474 (1504.5617) nleep/row_max_std 75.3578 (64.0146) nleep/row_min_mean 1457.7485 (1470.9692) lr 5.7422e-04 eta 0:05:23
epoch [34/50] batch [160/203] time 0.106 (0.098) data 0.000 (0.002) loss 1.3756 (1.2464) teacher_loss 0.6144 (0.4554) loss_zs_kd 0.0155 (0.0160) loss_oracle 0.3654 (0.4324) kd_loss 0.5706 (0.5667) acc 78.1250 (82.6367) gate/entropy 0.9780 (0.9779) gate/usage_max 0.5735 (0.5735) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1698 (0.1698) teacher/entropy 0.0400 (0.0286) teacher/usage_max 0.9448 (0.9602) teacher/usage_min 0.0240 (0.0056) teacher/usage_std 0.4324 (0.4435) nleep/row_max_mean 1496.3978 (1504.8326) nleep/row_max_std 73.2872 (64.2021) nleep/row_min_mean 1464.9834 (1471.3122) lr 5.7422e-04 eta 0:05:21
epoch [34/50] batch [180/203] time 0.104 (0.098) data 0.000 (0.002) loss 1.5381 (1.2450) teacher_loss 0.7141 (0.4544) loss_zs_kd 0.0043 (0.0160) loss_oracle 0.4791 (0.4324) kd_loss 0.5823 (0.5663) acc 71.8750 (82.5347) gate/entropy 0.9780 (0.9779) gate/usage_max 0.5734 (0.5735) gate/usage_min 0.2132 (0.2131) gate/usage_std 0.1698 (0.1698) teacher/entropy 0.0491 (0.0293) teacher/usage_max 0.9239 (0.9598) teacher/usage_min 0.0041 (0.0059) teacher/usage_std 0.4185 (0.4433) nleep/row_max_mean 1501.0575 (1504.9365) nleep/row_max_std 64.5580 (64.1360) nleep/row_min_mean 1468.3440 (1471.4510) lr 5.7422e-04 eta 0:05:19
epoch [34/50] batch [200/203] time 0.131 (0.098) data 0.000 (0.002) loss 1.1580 (1.2473) teacher_loss 0.3876 (0.4578) loss_zs_kd 0.0274 (0.0160) loss_oracle 0.4269 (0.4315) kd_loss 0.5432 (0.5657) acc 87.5000 (82.2812) gate/entropy 0.9780 (0.9779) gate/usage_max 0.5734 (0.5735) gate/usage_min 0.2132 (0.2131) gate/usage_std 0.1698 (0.1698) teacher/entropy 0.0468 (0.0295) teacher/usage_max 0.9656 (0.9603) teacher/usage_min 0.0110 (0.0058) teacher/usage_std 0.4471 (0.4436) nleep/row_max_mean 1515.6689 (1505.0097) nleep/row_max_std 29.3475 (63.9971) nleep/row_min_mean 1483.3870 (1471.6330) lr 5.7422e-04 eta 0:05:17
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,356
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 87.5%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.4%, epoch: 31 *******
******* Domain c best val test acc: 99.9%, epoch: 31 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [35/50] batch [20/203] time 0.068 (0.100) data 0.000 (0.013) loss 1.3638 (1.2219) teacher_loss 0.6094 (0.4457) loss_zs_kd 0.0109 (0.0165) loss_oracle 0.4107 (0.4302) kd_loss 0.5436 (0.5528) acc 78.1250 (82.8125) gate/entropy 0.9779 (0.9779) gate/usage_max 0.5736 (0.5736) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0224 (0.0419) teacher/usage_max 0.9898 (0.9606) teacher/usage_min 0.0003 (0.0083) teacher/usage_std 0.4642 (0.4437) nleep/row_max_mean 1502.5389 (1498.4868) nleep/row_max_std 72.9361 (74.2975) nleep/row_min_mean 1468.4526 (1466.3278) lr 5.1825e-04 eta 0:05:22
epoch [35/50] batch [40/203] time 0.092 (0.091) data 0.000 (0.007) loss 1.0714 (1.2487) teacher_loss 0.3841 (0.4665) loss_zs_kd 0.0091 (0.0174) loss_oracle 0.3734 (0.4331) kd_loss 0.4960 (0.5570) acc 87.5000 (81.7188) gate/entropy 0.9779 (0.9779) gate/usage_max 0.5735 (0.5736) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1698 (0.1699) teacher/entropy 0.0967 (0.0403) teacher/usage_max 0.9629 (0.9582) teacher/usage_min 0.0071 (0.0089) teacher/usage_std 0.4453 (0.4420) nleep/row_max_mean 1471.6185 (1500.6775) nleep/row_max_std 87.6057 (70.0208) nleep/row_min_mean 1442.5360 (1468.6308) lr 5.1825e-04 eta 0:04:53
epoch [35/50] batch [60/203] time 0.094 (0.091) data 0.001 (0.004) loss 1.7703 (1.2644) teacher_loss 0.9853 (0.4789) loss_zs_kd 0.0094 (0.0166) loss_oracle 0.4305 (0.4337) kd_loss 0.5650 (0.5603) acc 71.8750 (81.8229) gate/entropy 0.9778 (0.9779) gate/usage_max 0.5736 (0.5736) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0514 (0.0372) teacher/usage_max 0.9388 (0.9579) teacher/usage_min 0.0171 (0.0082) teacher/usage_std 0.4282 (0.4418) nleep/row_max_mean 1483.4172 (1502.7249) nleep/row_max_std 91.6983 (67.8576) nleep/row_min_mean 1453.9287 (1470.0617) lr 5.1825e-04 eta 0:04:51
epoch [35/50] batch [80/203] time 0.090 (0.092) data 0.000 (0.003) loss 1.4108 (1.2685) teacher_loss 0.6065 (0.4803) loss_zs_kd 0.0143 (0.0170) loss_oracle 0.4436 (0.4356) kd_loss 0.5753 (0.5618) acc 78.1250 (81.8359) gate/entropy 0.9778 (0.9779) gate/usage_max 0.5736 (0.5736) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0169 (0.0344) teacher/usage_max 0.9632 (0.9592) teacher/usage_min 0.0057 (0.0076) teacher/usage_std 0.4455 (0.4427) nleep/row_max_mean 1511.6528 (1503.1149) nleep/row_max_std 64.6290 (67.9396) nleep/row_min_mean 1476.1042 (1470.2842) lr 5.1825e-04 eta 0:04:51
epoch [35/50] batch [100/203] time 0.098 (0.092) data 0.000 (0.003) loss 1.2414 (1.2542) teacher_loss 0.3751 (0.4652) loss_zs_kd 0.0216 (0.0167) loss_oracle 0.4794 (0.4368) kd_loss 0.6159 (0.5623) acc 84.3750 (82.4688) gate/entropy 0.9779 (0.9779) gate/usage_max 0.5736 (0.5736) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0020 (0.0337) teacher/usage_max 0.9374 (0.9594) teacher/usage_min 0.0001 (0.0073) teacher/usage_std 0.4279 (0.4429) nleep/row_max_mean 1505.6799 (1503.2624) nleep/row_max_std 53.0537 (67.8067) nleep/row_min_mean 1472.9375 (1470.4432) lr 5.1825e-04 eta 0:04:50
epoch [35/50] batch [120/203] time 0.094 (0.092) data 0.000 (0.002) loss 1.5287 (1.2480) teacher_loss 0.6630 (0.4561) loss_zs_kd 0.0238 (0.0171) loss_oracle 0.4625 (0.4394) kd_loss 0.6225 (0.5636) acc 78.1250 (82.8646) gate/entropy 0.9778 (0.9779) gate/usage_max 0.5737 (0.5736) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0347 (0.0347) teacher/usage_max 0.8974 (0.9570) teacher/usage_min 0.0412 (0.0079) teacher/usage_std 0.3989 (0.4412) nleep/row_max_mean 1518.4631 (1503.1326) nleep/row_max_std 30.8961 (67.7348) nleep/row_min_mean 1482.9170 (1470.2374) lr 5.1825e-04 eta 0:04:48
epoch [35/50] batch [140/203] time 0.088 (0.092) data 0.000 (0.002) loss 1.2520 (1.2529) teacher_loss 0.5004 (0.4581) loss_zs_kd 0.0160 (0.0171) loss_oracle 0.3875 (0.4401) kd_loss 0.5499 (0.5661) acc 81.2500 (82.6339) gate/entropy 0.9779 (0.9778) gate/usage_max 0.5736 (0.5736) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0412 (0.0342) teacher/usage_max 0.9645 (0.9550) teacher/usage_min 0.0070 (0.0081) teacher/usage_std 0.4464 (0.4399) nleep/row_max_mean 1490.1907 (1503.2785) nleep/row_max_std 68.4961 (66.7315) nleep/row_min_mean 1461.2001 (1470.3963) lr 5.1825e-04 eta 0:04:47
epoch [35/50] batch [160/203] time 0.100 (0.093) data 0.000 (0.002) loss 1.0382 (1.2524) teacher_loss 0.3235 (0.4565) loss_zs_kd 0.0220 (0.0174) loss_oracle 0.3441 (0.4402) kd_loss 0.5317 (0.5671) acc 90.6250 (82.4219) gate/entropy 0.9778 (0.9778) gate/usage_max 0.5737 (0.5736) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0426 (0.0329) teacher/usage_max 0.9812 (0.9553) teacher/usage_min 0.0065 (0.0079) teacher/usage_std 0.4581 (0.4401) nleep/row_max_mean 1509.2477 (1503.6231) nleep/row_max_std 74.3740 (65.8762) nleep/row_min_mean 1476.5427 (1470.7991) lr 5.1825e-04 eta 0:04:47
epoch [35/50] batch [180/203] time 0.093 (0.093) data 0.000 (0.002) loss 1.2420 (1.2550) teacher_loss 0.4371 (0.4591) loss_zs_kd 0.0192 (0.0176) loss_oracle 0.4949 (0.4399) kd_loss 0.5478 (0.5672) acc 75.0000 (82.5000) gate/entropy 0.9777 (0.9778) gate/usage_max 0.5737 (0.5736) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1700 (0.1699) teacher/entropy 0.0436 (0.0321) teacher/usage_max 0.9639 (0.9560) teacher/usage_min 0.0001 (0.0081) teacher/usage_std 0.4461 (0.4406) nleep/row_max_mean 1511.5867 (1504.0012) nleep/row_max_std 59.1400 (65.6713) nleep/row_min_mean 1476.8828 (1471.1698) lr 5.1825e-04 eta 0:04:45
epoch [35/50] batch [200/203] time 0.093 (0.094) data 0.000 (0.001) loss 1.2484 (1.2546) teacher_loss 0.3787 (0.4567) loss_zs_kd 0.0292 (0.0179) loss_oracle 0.4998 (0.4417) kd_loss 0.6052 (0.5681) acc 87.5000 (82.7031) gate/entropy 0.9777 (0.9778) gate/usage_max 0.5737 (0.5736) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1700 (0.1699) teacher/entropy 0.0723 (0.0328) teacher/usage_max 0.8769 (0.9544) teacher/usage_min 0.0177 (0.0084) teacher/usage_std 0.3860 (0.4394) nleep/row_max_mean 1490.2904 (1503.6404) nleep/row_max_std 85.0195 (65.8287) nleep/row_min_mean 1462.9585 (1470.9571) lr 5.1825e-04 eta 0:04:45
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,355
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 87.5%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,413
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.6%
******* Domain c best val acc:      84.4%, epoch: 31 *******
******* Domain c best val test acc: 99.9%, epoch: 31 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [36/50] batch [20/203] time 0.090 (0.107) data 0.000 (0.016) loss 1.2111 (1.2792) teacher_loss 0.3391 (0.4776) loss_zs_kd 0.0197 (0.0188) loss_oracle 0.5189 (0.4338) kd_loss 0.6027 (0.5753) acc 78.1250 (81.0938) gate/entropy 0.9778 (0.9778) gate/usage_max 0.5736 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0225 (0.0259) teacher/usage_max 0.9298 (0.9539) teacher/usage_min 0.0017 (0.0064) teacher/usage_std 0.4226 (0.4392) nleep/row_max_mean 1506.1696 (1506.6085) nleep/row_max_std 60.9742 (62.6662) nleep/row_min_mean 1472.4602 (1474.6651) lr 4.6417e-04 eta 0:05:24
epoch [36/50] batch [40/203] time 0.097 (0.098) data 0.000 (0.008) loss 1.2115 (1.2463) teacher_loss 0.3323 (0.4379) loss_zs_kd 0.0217 (0.0187) loss_oracle 0.5517 (0.4399) kd_loss 0.5925 (0.5791) acc 87.5000 (83.2031) gate/entropy 0.9778 (0.9778) gate/usage_max 0.5736 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0279 (0.0316) teacher/usage_max 0.9348 (0.9445) teacher/usage_min 0.0012 (0.0107) teacher/usage_std 0.4260 (0.4325) nleep/row_max_mean 1497.6208 (1504.8385) nleep/row_max_std 71.4672 (62.6796) nleep/row_min_mean 1466.0732 (1472.8155) lr 4.6417e-04 eta 0:04:53
epoch [36/50] batch [60/203] time 0.091 (0.101) data 0.000 (0.006) loss 1.1954 (1.2445) teacher_loss 0.3248 (0.4392) loss_zs_kd 0.0281 (0.0192) loss_oracle 0.4930 (0.4417) kd_loss 0.6100 (0.5748) acc 84.3750 (83.1771) gate/entropy 0.9778 (0.9778) gate/usage_max 0.5736 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0096 (0.0355) teacher/usage_max 0.9355 (0.9449) teacher/usage_min 0.0001 (0.0111) teacher/usage_std 0.4266 (0.4328) nleep/row_max_mean 1511.4491 (1504.0251) nleep/row_max_std 58.8141 (62.2001) nleep/row_min_mean 1479.6392 (1472.3900) lr 4.6417e-04 eta 0:05:02
epoch [36/50] batch [80/203] time 0.096 (0.100) data 0.000 (0.004) loss 1.2639 (1.2542) teacher_loss 0.4274 (0.4485) loss_zs_kd 0.0201 (0.0187) loss_oracle 0.4621 (0.4433) kd_loss 0.5953 (0.5747) acc 75.0000 (82.9688) gate/entropy 0.9777 (0.9778) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1700 (0.1699) teacher/entropy 0.0626 (0.0358) teacher/usage_max 0.8965 (0.9447) teacher/usage_min 0.0109 (0.0114) teacher/usage_std 0.3996 (0.4326) nleep/row_max_mean 1514.5626 (1504.1793) nleep/row_max_std 44.1491 (61.4980) nleep/row_min_mean 1480.2405 (1472.5128) lr 4.6417e-04 eta 0:04:55
epoch [36/50] batch [100/203] time 0.101 (0.099) data 0.000 (0.003) loss 1.0778 (1.2597) teacher_loss 0.3121 (0.4544) loss_zs_kd 0.0204 (0.0189) loss_oracle 0.4433 (0.4425) kd_loss 0.5339 (0.5746) acc 87.5000 (82.5312) gate/entropy 0.9777 (0.9778) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1700 (0.1699) teacher/entropy 0.0761 (0.0355) teacher/usage_max 0.9451 (0.9450) teacher/usage_min 0.0253 (0.0118) teacher/usage_std 0.4326 (0.4328) nleep/row_max_mean 1491.8254 (1504.5305) nleep/row_max_std 80.1811 (61.7204) nleep/row_min_mean 1461.7925 (1472.8412) lr 4.6417e-04 eta 0:04:51
epoch [36/50] batch [120/203] time 0.099 (0.098) data 0.000 (0.003) loss 1.1951 (1.2578) teacher_loss 0.4095 (0.4530) loss_zs_kd 0.0152 (0.0194) loss_oracle 0.4629 (0.4420) kd_loss 0.5465 (0.5741) acc 87.5000 (82.7083) gate/entropy 0.9778 (0.9778) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0858 (0.0374) teacher/usage_max 0.9226 (0.9436) teacher/usage_min 0.0024 (0.0123) teacher/usage_std 0.4177 (0.4319) nleep/row_max_mean 1488.8102 (1503.4240) nleep/row_max_std 81.9312 (62.6037) nleep/row_min_mean 1458.1945 (1471.9410) lr 4.6417e-04 eta 0:04:47
epoch [36/50] batch [140/203] time 0.087 (0.098) data 0.000 (0.003) loss 1.1423 (1.2541) teacher_loss 0.3108 (0.4492) loss_zs_kd 0.0205 (0.0196) loss_oracle 0.4407 (0.4410) kd_loss 0.6010 (0.5746) acc 90.6250 (82.8571) gate/entropy 0.9778 (0.9778) gate/usage_max 0.5736 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0221 (0.0374) teacher/usage_max 0.9320 (0.9431) teacher/usage_min 0.0328 (0.0130) teacher/usage_std 0.4233 (0.4315) nleep/row_max_mean 1487.3965 (1503.5049) nleep/row_max_std 73.5182 (62.7466) nleep/row_min_mean 1459.1577 (1471.9246) lr 4.6417e-04 eta 0:04:44
epoch [36/50] batch [160/203] time 0.098 (0.098) data 0.001 (0.002) loss 1.0736 (1.2573) teacher_loss 0.3189 (0.4506) loss_zs_kd 0.0252 (0.0196) loss_oracle 0.4002 (0.4416) kd_loss 0.5419 (0.5761) acc 87.5000 (82.7539) gate/entropy 0.9778 (0.9778) gate/usage_max 0.5736 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0559 (0.0388) teacher/usage_max 0.9575 (0.9401) teacher/usage_min 0.0113 (0.0141) teacher/usage_std 0.4414 (0.4294) nleep/row_max_mean 1501.6838 (1502.9889) nleep/row_max_std 76.0503 (63.1850) nleep/row_min_mean 1471.9637 (1471.6453) lr 4.6417e-04 eta 0:04:41
epoch [36/50] batch [180/203] time 0.093 (0.097) data 0.000 (0.002) loss 1.2080 (1.2553) teacher_loss 0.3946 (0.4453) loss_zs_kd 0.0108 (0.0195) loss_oracle 0.4657 (0.4446) kd_loss 0.5752 (0.5780) acc 84.3750 (82.8472) gate/entropy 0.9778 (0.9778) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.1112 (0.0400) teacher/usage_max 0.8680 (0.9370) teacher/usage_min 0.0378 (0.0148) teacher/usage_std 0.3788 (0.4272) nleep/row_max_mean 1478.0284 (1502.1858) nleep/row_max_std 88.5602 (63.9340) nleep/row_min_mean 1451.7229 (1471.1309) lr 4.6417e-04 eta 0:04:39
epoch [36/50] batch [200/203] time 0.085 (0.097) data 0.000 (0.002) loss 1.1727 (1.2562) teacher_loss 0.4129 (0.4446) loss_zs_kd 0.0118 (0.0195) loss_oracle 0.3926 (0.4457) kd_loss 0.5576 (0.5789) acc 84.3750 (82.8594) gate/entropy 0.9777 (0.9778) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1700 (0.1699) teacher/entropy 0.0250 (0.0405) teacher/usage_max 0.9728 (0.9356) teacher/usage_min 0.0003 (0.0159) teacher/usage_std 0.4523 (0.4262) nleep/row_max_mean 1498.6039 (1502.2174) nleep/row_max_std 72.1074 (63.9839) nleep/row_min_mean 1466.7114 (1471.2097) lr 4.6417e-04 eta 0:04:36
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,363
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 87.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [37/50] batch [20/203] time 0.083 (0.105) data 0.000 (0.014) loss 1.0669 (1.2490) teacher_loss 0.2679 (0.4464) loss_zs_kd 0.0188 (0.0231) loss_oracle 0.4498 (0.4417) kd_loss 0.5647 (0.5702) acc 84.3750 (83.1250) gate/entropy 0.9778 (0.9777) gate/usage_max 0.5736 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1700) teacher/entropy 0.0606 (0.0455) teacher/usage_max 0.9298 (0.9393) teacher/usage_min 0.0336 (0.0176) teacher/usage_std 0.4218 (0.4287) nleep/row_max_mean 1500.0461 (1499.6575) nleep/row_max_std 64.3771 (65.1264) nleep/row_min_mean 1470.4490 (1469.5651) lr 4.1221e-04 eta 0:04:55
epoch [37/50] batch [40/203] time 0.098 (0.097) data 0.000 (0.007) loss 1.1070 (1.2467) teacher_loss 0.2514 (0.4389) loss_zs_kd 0.0129 (0.0216) loss_oracle 0.5403 (0.4481) kd_loss 0.5790 (0.5730) acc 87.5000 (83.3594) gate/entropy 0.9778 (0.9777) gate/usage_max 0.5736 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1700) teacher/entropy 0.0669 (0.0461) teacher/usage_max 0.9089 (0.9358) teacher/usage_min 0.0382 (0.0178) teacher/usage_std 0.4070 (0.4263) nleep/row_max_mean 1513.5364 (1502.2704) nleep/row_max_std 56.3409 (63.6837) nleep/row_min_mean 1481.1888 (1471.5201) lr 4.1221e-04 eta 0:04:30
epoch [37/50] batch [60/203] time 0.089 (0.092) data 0.001 (0.005) loss 1.4391 (1.2549) teacher_loss 0.4734 (0.4482) loss_zs_kd 0.0317 (0.0208) loss_oracle 0.5699 (0.4456) kd_loss 0.6648 (0.5735) acc 84.3750 (83.0729) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.1118 (0.0452) teacher/usage_max 0.7766 (0.9362) teacher/usage_min 0.0987 (0.0180) teacher/usage_std 0.3136 (0.4266) nleep/row_max_mean 1498.1493 (1502.0672) nleep/row_max_std 54.7415 (64.5574) nleep/row_min_mean 1471.7430 (1471.3063) lr 4.1221e-04 eta 0:04:17
epoch [37/50] batch [80/203] time 0.094 (0.091) data 0.000 (0.004) loss 1.1252 (1.2464) teacher_loss 0.3317 (0.4393) loss_zs_kd 0.0291 (0.0211) loss_oracle 0.3994 (0.4474) kd_loss 0.5793 (0.5729) acc 81.2500 (83.5938) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0099 (0.0441) teacher/usage_max 0.9661 (0.9379) teacher/usage_min 0.0026 (0.0164) teacher/usage_std 0.4476 (0.4278) nleep/row_max_mean 1506.5697 (1501.4708) nleep/row_max_std 58.9130 (65.1137) nleep/row_min_mean 1477.0273 (1470.5075) lr 4.1221e-04 eta 0:04:12
epoch [37/50] batch [100/203] time 0.085 (0.090) data 0.000 (0.003) loss 1.1813 (1.2407) teacher_loss 0.3688 (0.4338) loss_zs_kd 0.0186 (0.0205) loss_oracle 0.4556 (0.4478) kd_loss 0.5754 (0.5728) acc 87.5000 (83.6875) gate/entropy 0.9776 (0.9777) gate/usage_max 0.5738 (0.5737) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0249 (0.0443) teacher/usage_max 0.9547 (0.9378) teacher/usage_min 0.0136 (0.0170) teacher/usage_std 0.4394 (0.4277) nleep/row_max_mean 1512.6660 (1501.9551) nleep/row_max_std 52.4481 (64.2944) nleep/row_min_mean 1475.7576 (1470.8092) lr 4.1221e-04 eta 0:04:06
epoch [37/50] batch [120/203] time 0.089 (0.089) data 0.000 (0.003) loss 1.3961 (1.2442) teacher_loss 0.6015 (0.4322) loss_zs_kd 0.0111 (0.0207) loss_oracle 0.4776 (0.4505) kd_loss 0.5502 (0.5763) acc 78.1250 (83.9323) gate/entropy 0.9778 (0.9777) gate/usage_max 0.5736 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1700) teacher/entropy 0.0347 (0.0447) teacher/usage_max 0.9706 (0.9339) teacher/usage_min 0.0004 (0.0170) teacher/usage_std 0.4508 (0.4250) nleep/row_max_mean 1481.8115 (1501.7782) nleep/row_max_std 74.5531 (64.3448) nleep/row_min_mean 1455.6970 (1470.6234) lr 4.1221e-04 eta 0:04:02
epoch [37/50] batch [140/203] time 0.083 (0.088) data 0.000 (0.002) loss 1.3053 (1.2481) teacher_loss 0.4649 (0.4340) loss_zs_kd 0.0063 (0.0211) loss_oracle 0.4710 (0.4525) kd_loss 0.6017 (0.5773) acc 81.2500 (83.7500) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5738 (0.5737) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0200 (0.0447) teacher/usage_max 0.9332 (0.9329) teacher/usage_min 0.0046 (0.0172) teacher/usage_std 0.4248 (0.4243) nleep/row_max_mean 1510.8003 (1502.5329) nleep/row_max_std 45.9259 (63.2325) nleep/row_min_mean 1479.6281 (1471.3015) lr 4.1221e-04 eta 0:03:58
epoch [37/50] batch [160/203] time 0.109 (0.090) data 0.000 (0.002) loss 1.2265 (1.2555) teacher_loss 0.4968 (0.4409) loss_zs_kd 0.0137 (0.0215) loss_oracle 0.4030 (0.4529) kd_loss 0.5213 (0.5774) acc 78.1250 (83.4375) gate/entropy 0.9776 (0.9777) gate/usage_max 0.5738 (0.5737) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.1029 (0.0457) teacher/usage_max 0.9306 (0.9317) teacher/usage_min 0.0162 (0.0177) teacher/usage_std 0.4226 (0.4235) nleep/row_max_mean 1501.3047 (1502.2350) nleep/row_max_std 72.7336 (63.4773) nleep/row_min_mean 1471.6338 (1471.0456) lr 4.1221e-04 eta 0:04:02
epoch [37/50] batch [180/203] time 0.101 (0.091) data 0.000 (0.002) loss 1.0897 (1.2558) teacher_loss 0.1740 (0.4361) loss_zs_kd 0.0170 (0.0222) loss_oracle 0.5087 (0.4560) kd_loss 0.6529 (0.5805) acc 93.7500 (83.5938) gate/entropy 0.9778 (0.9777) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1700) teacher/entropy 0.0600 (0.0450) teacher/usage_max 0.8411 (0.9293) teacher/usage_min 0.0706 (0.0190) teacher/usage_std 0.3591 (0.4218) nleep/row_max_mean 1508.2517 (1502.6749) nleep/row_max_std 46.5082 (62.9511) nleep/row_min_mean 1476.8468 (1471.4816) lr 4.1221e-04 eta 0:04:02
epoch [37/50] batch [200/203] time 0.079 (0.091) data 0.000 (0.002) loss 1.5279 (1.2607) teacher_loss 0.5274 (0.4394) loss_zs_kd 0.0264 (0.0224) loss_oracle 0.5780 (0.4579) kd_loss 0.6983 (0.5811) acc 81.2500 (83.3906) gate/entropy 0.9778 (0.9777) gate/usage_max 0.5736 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1699 (0.1700) teacher/entropy 0.0410 (0.0450) teacher/usage_max 0.8145 (0.9287) teacher/usage_min 0.0006 (0.0191) teacher/usage_std 0.3484 (0.4214) nleep/row_max_mean 1482.0366 (1502.4223) nleep/row_max_std 92.0562 (63.6379) nleep/row_min_mean 1449.2473 (1471.1332) lr 4.1221e-04 eta 0:04:01
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,357
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 87.5%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [38/50] batch [20/203] time 0.099 (0.103) data 0.001 (0.015) loss 1.0373 (1.2031) teacher_loss 0.2206 (0.3989) loss_zs_kd 0.0070 (0.0171) loss_oracle 0.4997 (0.4454) kd_loss 0.5634 (0.5729) acc 93.7500 (85.0000) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0372 (0.0471) teacher/usage_max 0.9545 (0.9348) teacher/usage_min 0.0096 (0.0147) teacher/usage_std 0.4394 (0.4257) nleep/row_max_mean 1485.1321 (1500.9144) nleep/row_max_std 75.7726 (67.1563) nleep/row_min_mean 1459.4280 (1469.7736) lr 3.6258e-04 eta 0:04:29
epoch [38/50] batch [40/203] time 0.086 (0.097) data 0.000 (0.007) loss 1.2483 (1.2647) teacher_loss 0.3815 (0.4553) loss_zs_kd 0.0207 (0.0196) loss_oracle 0.4586 (0.4492) kd_loss 0.6271 (0.5750) acc 87.5000 (82.7344) gate/entropy 0.9776 (0.9777) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0358 (0.0463) teacher/usage_max 0.8915 (0.9336) teacher/usage_min 0.0000 (0.0159) teacher/usage_std 0.3971 (0.4248) nleep/row_max_mean 1515.4376 (1501.2497) nleep/row_max_std 59.4531 (67.8806) nleep/row_min_mean 1479.4871 (1469.6491) lr 3.6258e-04 eta 0:04:11
epoch [38/50] batch [60/203] time 0.098 (0.093) data 0.001 (0.005) loss 1.5298 (1.2787) teacher_loss 0.7086 (0.4597) loss_zs_kd 0.0428 (0.0202) loss_oracle 0.4544 (0.4583) kd_loss 0.5726 (0.5797) acc 68.7500 (82.5000) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0201 (0.0445) teacher/usage_max 0.9624 (0.9305) teacher/usage_min 0.0000 (0.0167) teacher/usage_std 0.4451 (0.4227) nleep/row_max_mean 1505.8962 (1502.9686) nleep/row_max_std 68.8598 (65.9388) nleep/row_min_mean 1476.3888 (1470.7911) lr 3.6258e-04 eta 0:04:00
epoch [38/50] batch [80/203] time 0.091 (0.093) data 0.000 (0.004) loss 1.1766 (1.2715) teacher_loss 0.4262 (0.4536) loss_zs_kd 0.0127 (0.0202) loss_oracle 0.3931 (0.4582) kd_loss 0.5475 (0.5787) acc 84.3750 (83.0469) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5737 (0.5738) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0386 (0.0441) teacher/usage_max 0.9692 (0.9319) teacher/usage_min 0.0038 (0.0161) teacher/usage_std 0.4498 (0.4237) nleep/row_max_mean 1489.4712 (1503.0948) nleep/row_max_std 81.5012 (66.6822) nleep/row_min_mean 1456.6125 (1470.6033) lr 3.6258e-04 eta 0:03:57
epoch [38/50] batch [100/203] time 0.091 (0.092) data 0.000 (0.003) loss 1.1802 (1.2671) teacher_loss 0.4110 (0.4504) loss_zs_kd 0.0270 (0.0199) loss_oracle 0.4390 (0.4576) kd_loss 0.5362 (0.5778) acc 84.3750 (82.8750) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0313 (0.0434) teacher/usage_max 0.9879 (0.9336) teacher/usage_min 0.0001 (0.0153) teacher/usage_std 0.4628 (0.4249) nleep/row_max_mean 1524.8799 (1503.4015) nleep/row_max_std 31.1719 (66.1840) nleep/row_min_mean 1491.1577 (1470.8233) lr 3.6258e-04 eta 0:03:53
epoch [38/50] batch [120/203] time 0.081 (0.092) data 0.000 (0.003) loss 1.2489 (1.2612) teacher_loss 0.3317 (0.4470) loss_zs_kd 0.0129 (0.0200) loss_oracle 0.5324 (0.4573) kd_loss 0.6445 (0.5755) acc 87.5000 (83.0729) gate/entropy 0.9778 (0.9777) gate/usage_max 0.5737 (0.5738) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0298 (0.0412) teacher/usage_max 0.8799 (0.9382) teacher/usage_min 0.0315 (0.0136) teacher/usage_std 0.3872 (0.4281) nleep/row_max_mean 1504.0559 (1503.4428) nleep/row_max_std 58.6339 (66.4673) nleep/row_min_mean 1470.6472 (1470.6372) lr 3.6258e-04 eta 0:03:50
epoch [38/50] batch [140/203] time 0.093 (0.092) data 0.000 (0.002) loss 1.0476 (1.2584) teacher_loss 0.2817 (0.4456) loss_zs_kd 0.0235 (0.0197) loss_oracle 0.4343 (0.4566) kd_loss 0.5369 (0.5746) acc 90.6250 (83.1473) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5737 (0.5738) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0650 (0.0407) teacher/usage_max 0.9532 (0.9396) teacher/usage_min 0.0172 (0.0130) teacher/usage_std 0.4384 (0.4291) nleep/row_max_mean 1504.8583 (1503.9888) nleep/row_max_std 63.9286 (66.4261) nleep/row_min_mean 1475.4014 (1471.1347) lr 3.6258e-04 eta 0:03:50
epoch [38/50] batch [160/203] time 0.091 (0.092) data 0.000 (0.002) loss 1.2741 (1.2605) teacher_loss 0.4689 (0.4483) loss_zs_kd 0.0185 (0.0195) loss_oracle 0.4198 (0.4572) kd_loss 0.5860 (0.5738) acc 81.2500 (83.2617) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5737 (0.5738) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0217 (0.0401) teacher/usage_max 0.9472 (0.9409) teacher/usage_min 0.0001 (0.0121) teacher/usage_std 0.4346 (0.4300) nleep/row_max_mean 1501.4653 (1503.9789) nleep/row_max_std 66.2654 (66.4123) nleep/row_min_mean 1469.3427 (1471.1867) lr 3.6258e-04 eta 0:03:47
epoch [38/50] batch [180/203] time 0.085 (0.091) data 0.000 (0.002) loss 1.1661 (1.2682) teacher_loss 0.3478 (0.4548) loss_zs_kd 0.0158 (0.0193) loss_oracle 0.4826 (0.4582) kd_loss 0.5691 (0.5747) acc 87.5000 (82.9340) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5737 (0.5738) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0133 (0.0404) teacher/usage_max 0.9729 (0.9398) teacher/usage_min 0.0001 (0.0131) teacher/usage_std 0.4523 (0.4292) nleep/row_max_mean 1507.4141 (1504.2249) nleep/row_max_std 57.5630 (66.0347) nleep/row_min_mean 1470.5720 (1471.3784) lr 3.6258e-04 eta 0:03:44
epoch [38/50] batch [200/203] time 0.084 (0.091) data 0.000 (0.002) loss 1.2939 (1.2638) teacher_loss 0.4649 (0.4497) loss_zs_kd 0.0209 (0.0192) loss_oracle 0.4610 (0.4583) kd_loss 0.5881 (0.5753) acc 81.2500 (83.0938) gate/entropy 0.9776 (0.9777) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0652 (0.0402) teacher/usage_max 0.9011 (0.9393) teacher/usage_min 0.0455 (0.0137) teacher/usage_std 0.4015 (0.4288) nleep/row_max_mean 1512.1151 (1504.4008) nleep/row_max_std 58.4602 (65.4605) nleep/row_min_mean 1479.0576 (1471.6224) lr 3.6258e-04 eta 0:03:41
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,355
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 87.5%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [39/50] batch [20/203] time 0.078 (0.127) data 0.000 (0.017) loss 1.3493 (1.2565) teacher_loss 0.5489 (0.4489) loss_zs_kd 0.0189 (0.0190) loss_oracle 0.4321 (0.4506) kd_loss 0.5749 (0.5728) acc 75.0000 (82.1875) gate/entropy 0.9777 (0.9776) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0249 (0.0426) teacher/usage_max 0.9553 (0.9394) teacher/usage_min 0.0005 (0.0171) teacher/usage_std 0.4401 (0.4288) nleep/row_max_mean 1499.3470 (1502.2372) nleep/row_max_std 67.5618 (63.3017) nleep/row_min_mean 1464.3396 (1470.1438) lr 3.1545e-04 eta 0:05:05
epoch [39/50] batch [40/203] time 0.091 (0.106) data 0.000 (0.009) loss 1.0684 (1.2576) teacher_loss 0.2926 (0.4490) loss_zs_kd 0.0219 (0.0198) loss_oracle 0.4271 (0.4493) kd_loss 0.5513 (0.5741) acc 84.3750 (83.1250) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0425 (0.0465) teacher/usage_max 0.9612 (0.9342) teacher/usage_min 0.0118 (0.0190) teacher/usage_std 0.4440 (0.4251) nleep/row_max_mean 1512.3394 (1504.7820) nleep/row_max_std 44.9717 (63.5603) nleep/row_min_mean 1481.3677 (1472.4845) lr 3.1545e-04 eta 0:04:14
epoch [39/50] batch [60/203] time 0.088 (0.099) data 0.000 (0.006) loss 1.1954 (1.2455) teacher_loss 0.4420 (0.4304) loss_zs_kd 0.0173 (0.0206) loss_oracle 0.3810 (0.4513) kd_loss 0.5543 (0.5791) acc 84.3750 (83.6979) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0587 (0.0453) teacher/usage_max 0.9419 (0.9303) teacher/usage_min 0.0204 (0.0192) teacher/usage_std 0.4304 (0.4224) nleep/row_max_mean 1480.8911 (1504.5610) nleep/row_max_std 83.3675 (64.2277) nleep/row_min_mean 1451.0293 (1472.3359) lr 3.1545e-04 eta 0:03:56
epoch [39/50] batch [80/203] time 0.094 (0.098) data 0.000 (0.004) loss 1.4897 (1.2461) teacher_loss 0.6705 (0.4324) loss_zs_kd 0.0176 (0.0205) loss_oracle 0.4638 (0.4504) kd_loss 0.5785 (0.5782) acc 81.2500 (83.6719) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0095 (0.0454) teacher/usage_max 0.9671 (0.9311) teacher/usage_min 0.0002 (0.0188) teacher/usage_std 0.4483 (0.4230) nleep/row_max_mean 1522.8693 (1504.6975) nleep/row_max_std 25.2702 (64.2893) nleep/row_min_mean 1485.6191 (1472.4321) lr 3.1545e-04 eta 0:03:51
epoch [39/50] batch [100/203] time 0.106 (0.097) data 0.000 (0.004) loss 1.3556 (1.2463) teacher_loss 0.5448 (0.4348) loss_zs_kd 0.0296 (0.0207) loss_oracle 0.4774 (0.4489) kd_loss 0.5572 (0.5767) acc 75.0000 (83.5625) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1700) teacher/entropy 0.0702 (0.0442) teacher/usage_max 0.9273 (0.9338) teacher/usage_min 0.0073 (0.0167) teacher/usage_std 0.4206 (0.4249) nleep/row_max_mean 1496.0646 (1503.9232) nleep/row_max_std 82.3456 (65.3585) nleep/row_min_mean 1462.1914 (1471.6174) lr 3.1545e-04 eta 0:03:47
epoch [39/50] batch [120/203] time 0.104 (0.098) data 0.001 (0.003) loss 1.3145 (1.2541) teacher_loss 0.5192 (0.4437) loss_zs_kd 0.0130 (0.0203) loss_oracle 0.3937 (0.4493) kd_loss 0.5920 (0.5756) acc 78.1250 (83.3333) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5739 (0.5738) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1700) teacher/entropy 0.0316 (0.0443) teacher/usage_max 0.9310 (0.9349) teacher/usage_min 0.0284 (0.0167) teacher/usage_std 0.4226 (0.4257) nleep/row_max_mean 1516.6946 (1503.4278) nleep/row_max_std 44.1495 (65.7631) nleep/row_min_mean 1485.5746 (1471.1432) lr 3.1545e-04 eta 0:03:46
epoch [39/50] batch [140/203] time 0.103 (0.097) data 0.001 (0.003) loss 1.1908 (1.2578) teacher_loss 0.3371 (0.4438) loss_zs_kd 0.0366 (0.0209) loss_oracle 0.4832 (0.4524) kd_loss 0.5938 (0.5774) acc 81.2500 (83.0804) gate/entropy 0.9777 (0.9776) gate/usage_max 0.5737 (0.5738) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0345 (0.0441) teacher/usage_max 0.9265 (0.9333) teacher/usage_min 0.0108 (0.0166) teacher/usage_std 0.4200 (0.4246) nleep/row_max_mean 1488.0519 (1503.0683) nleep/row_max_std 70.8353 (65.8001) nleep/row_min_mean 1461.2131 (1470.9072) lr 3.1545e-04 eta 0:03:43
epoch [39/50] batch [160/203] time 0.102 (0.098) data 0.001 (0.002) loss 1.1980 (1.2556) teacher_loss 0.3802 (0.4424) loss_zs_kd 0.0129 (0.0208) loss_oracle 0.4475 (0.4530) kd_loss 0.5876 (0.5762) acc 78.1250 (83.2031) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1700) teacher/entropy 0.0433 (0.0432) teacher/usage_max 0.9238 (0.9353) teacher/usage_min 0.0253 (0.0165) teacher/usage_std 0.4177 (0.4260) nleep/row_max_mean 1497.6290 (1503.0396) nleep/row_max_std 63.5132 (65.9153) nleep/row_min_mean 1463.7804 (1470.8589) lr 3.1545e-04 eta 0:03:42
epoch [39/50] batch [180/203] time 0.079 (0.097) data 0.001 (0.002) loss 1.2034 (1.2559) teacher_loss 0.3649 (0.4440) loss_zs_kd 0.0239 (0.0211) loss_oracle 0.4751 (0.4517) kd_loss 0.5890 (0.5754) acc 87.5000 (83.1597) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0315 (0.0434) teacher/usage_max 0.9341 (0.9359) teacher/usage_min 0.0320 (0.0166) teacher/usage_std 0.4248 (0.4264) nleep/row_max_mean 1503.8176 (1503.1463) nleep/row_max_std 72.5502 (65.6800) nleep/row_min_mean 1473.0374 (1470.8851) lr 3.1545e-04 eta 0:03:39
epoch [39/50] batch [200/203] time 0.086 (0.096) data 0.000 (0.002) loss 1.2512 (1.2547) teacher_loss 0.5192 (0.4452) loss_zs_kd 0.0146 (0.0210) loss_oracle 0.4197 (0.4507) kd_loss 0.5148 (0.5737) acc 78.1250 (82.9062) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1701) teacher/entropy 0.0594 (0.0430) teacher/usage_max 0.9811 (0.9380) teacher/usage_min 0.0052 (0.0159) teacher/usage_std 0.4581 (0.4279) nleep/row_max_mean 1485.0859 (1502.5348) nleep/row_max_std 85.3057 (65.9860) nleep/row_min_mean 1452.6538 (1470.2488) lr 3.1545e-04 eta 0:03:35
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,347
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 87.4%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [40/50] batch [20/203] time 0.084 (0.103) data 0.000 (0.017) loss 1.1463 (1.2340) teacher_loss 0.3082 (0.4117) loss_zs_kd 0.0298 (0.0210) loss_oracle 0.4924 (0.4619) kd_loss 0.5770 (0.5809) acc 90.6250 (83.4375) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0676 (0.0393) teacher/usage_max 0.9098 (0.9345) teacher/usage_min 0.0175 (0.0172) teacher/usage_std 0.4083 (0.4256) nleep/row_max_mean 1512.2529 (1506.6680) nleep/row_max_std 56.4732 (60.9199) nleep/row_min_mean 1476.8003 (1473.9303) lr 2.7103e-04 eta 0:03:47
epoch [40/50] batch [40/203] time 0.099 (0.097) data 0.000 (0.009) loss 1.1255 (1.2421) teacher_loss 0.3855 (0.4295) loss_zs_kd 0.0244 (0.0207) loss_oracle 0.4182 (0.4506) kd_loss 0.5187 (0.5769) acc 90.6250 (82.9688) gate/entropy 0.9775 (0.9776) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0633 (0.0435) teacher/usage_max 0.9731 (0.9343) teacher/usage_min 0.0081 (0.0187) teacher/usage_std 0.4524 (0.4252) nleep/row_max_mean 1508.3760 (1505.5053) nleep/row_max_std 67.5133 (63.0709) nleep/row_min_mean 1473.9402 (1472.8355) lr 2.7103e-04 eta 0:03:32
epoch [40/50] batch [60/203] time 0.081 (0.093) data 0.001 (0.006) loss 1.1780 (1.2371) teacher_loss 0.3326 (0.4267) loss_zs_kd 0.0213 (0.0211) loss_oracle 0.4779 (0.4493) kd_loss 0.5958 (0.5752) acc 78.1250 (83.5417) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0210 (0.0439) teacher/usage_max 0.9379 (0.9355) teacher/usage_min 0.0286 (0.0170) teacher/usage_std 0.4275 (0.4262) nleep/row_max_mean 1514.6370 (1505.5487) nleep/row_max_std 58.0762 (63.8548) nleep/row_min_mean 1480.7048 (1472.5278) lr 2.7103e-04 eta 0:03:22
epoch [40/50] batch [80/203] time 0.096 (0.090) data 0.000 (0.004) loss 1.1996 (1.2436) teacher_loss 0.4346 (0.4294) loss_zs_kd 0.0464 (0.0235) loss_oracle 0.3999 (0.4502) kd_loss 0.5419 (0.5774) acc 87.5000 (83.3594) gate/entropy 0.9775 (0.9776) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0181 (0.0450) teacher/usage_max 0.9952 (0.9324) teacher/usage_min 0.0001 (0.0183) teacher/usage_std 0.4680 (0.4239) nleep/row_max_mean 1517.4509 (1504.6225) nleep/row_max_std 56.8365 (64.7191) nleep/row_min_mean 1482.8264 (1471.5991) lr 2.7103e-04 eta 0:03:14
epoch [40/50] batch [100/203] time 0.090 (0.089) data 0.000 (0.004) loss 1.2347 (1.2500) teacher_loss 0.3249 (0.4286) loss_zs_kd 0.0267 (0.0233) loss_oracle 0.5448 (0.4546) kd_loss 0.6241 (0.5824) acc 81.2500 (83.2812) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1701) teacher/entropy 0.0531 (0.0450) teacher/usage_max 0.8772 (0.9272) teacher/usage_min 0.0316 (0.0194) teacher/usage_std 0.3853 (0.4203) nleep/row_max_mean 1502.9919 (1504.9684) nleep/row_max_std 53.6385 (63.7446) nleep/row_min_mean 1471.7511 (1472.0622) lr 2.7103e-04 eta 0:03:10
epoch [40/50] batch [120/203] time 0.091 (0.091) data 0.000 (0.003) loss 1.3439 (1.2531) teacher_loss 0.4511 (0.4287) loss_zs_kd 0.0156 (0.0235) loss_oracle 0.4939 (0.4571) kd_loss 0.6380 (0.5841) acc 87.5000 (83.4635) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0148 (0.0459) teacher/usage_max 0.9015 (0.9245) teacher/usage_min 0.0314 (0.0201) teacher/usage_std 0.4020 (0.4185) nleep/row_max_mean 1503.4253 (1503.8734) nleep/row_max_std 69.8704 (64.6712) nleep/row_min_mean 1469.4167 (1471.2112) lr 2.7103e-04 eta 0:03:12
epoch [40/50] batch [140/203] time 0.057 (0.088) data 0.000 (0.003) loss 1.2644 (1.2548) teacher_loss 0.3811 (0.4304) loss_zs_kd 0.0473 (0.0238) loss_oracle 0.4966 (0.4551) kd_loss 0.6114 (0.5849) acc 87.5000 (83.5714) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0066 (0.0452) teacher/usage_max 0.9367 (0.9246) teacher/usage_min 0.0313 (0.0197) teacher/usage_std 0.4267 (0.4185) nleep/row_max_mean 1508.2323 (1504.4100) nleep/row_max_std 54.7980 (64.4671) nleep/row_min_mean 1475.3403 (1471.7916) lr 2.7103e-04 eta 0:03:03
epoch [40/50] batch [160/203] time 0.082 (0.085) data 0.000 (0.002) loss 1.2520 (1.2537) teacher_loss 0.4372 (0.4277) loss_zs_kd 0.0142 (0.0236) loss_oracle 0.4286 (0.4546) kd_loss 0.5935 (0.5869) acc 87.5000 (83.5352) gate/entropy 0.9775 (0.9776) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0335 (0.0467) teacher/usage_max 0.9274 (0.9209) teacher/usage_min 0.0333 (0.0209) teacher/usage_std 0.4201 (0.4160) nleep/row_max_mean 1497.1986 (1503.4966) nleep/row_max_std 84.5908 (65.3272) nleep/row_min_mean 1464.4297 (1471.0530) lr 2.7103e-04 eta 0:02:56
epoch [40/50] batch [180/203] time 0.062 (0.083) data 0.000 (0.002) loss 1.2894 (1.2573) teacher_loss 0.4758 (0.4312) loss_zs_kd 0.0252 (0.0239) loss_oracle 0.4234 (0.4537) kd_loss 0.5893 (0.5874) acc 78.1250 (83.4375) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1701) teacher/entropy 0.0572 (0.0485) teacher/usage_max 0.9079 (0.9187) teacher/usage_min 0.0315 (0.0216) teacher/usage_std 0.4065 (0.4144) nleep/row_max_mean 1514.6497 (1503.0528) nleep/row_max_std 50.7668 (65.7179) nleep/row_min_mean 1481.4966 (1470.7917) lr 2.7103e-04 eta 0:02:49
epoch [40/50] batch [200/203] time 0.084 (0.082) data 0.000 (0.002) loss 1.3645 (1.2599) teacher_loss 0.5597 (0.4341) loss_zs_kd 0.0328 (0.0243) loss_oracle 0.4598 (0.4536) kd_loss 0.5585 (0.5868) acc 75.0000 (83.3125) gate/entropy 0.9775 (0.9776) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0453 (0.0497) teacher/usage_max 0.9510 (0.9180) teacher/usage_min 0.0176 (0.0218) teacher/usage_std 0.4368 (0.4139) nleep/row_max_mean 1514.0491 (1502.8194) nleep/row_max_std 61.6075 (65.9779) nleep/row_min_mean 1479.2505 (1470.4970) lr 2.7103e-04 eta 0:02:46
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,357
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 87.6%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [41/50] batch [20/203] time 0.089 (0.105) data 0.000 (0.016) loss 1.3327 (1.2506) teacher_loss 0.5389 (0.4278) loss_zs_kd 0.0254 (0.0252) loss_oracle 0.3999 (0.4564) kd_loss 0.5810 (0.5820) acc 78.1250 (84.2188) gate/entropy 0.9775 (0.9776) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0760 (0.0555) teacher/usage_max 0.8972 (0.9170) teacher/usage_min 0.0348 (0.0238) teacher/usage_std 0.3990 (0.4131) nleep/row_max_mean 1504.0784 (1503.9380) nleep/row_max_std 73.6313 (68.2671) nleep/row_min_mean 1470.5532 (1470.8345) lr 2.2949e-04 eta 0:03:31
epoch [41/50] batch [40/203] time 0.091 (0.095) data 0.000 (0.008) loss 1.0838 (1.2622) teacher_loss 0.3096 (0.4312) loss_zs_kd 0.0350 (0.0264) loss_oracle 0.4535 (0.4593) kd_loss 0.5299 (0.5881) acc 90.6250 (82.8125) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0999 (0.0579) teacher/usage_max 0.9248 (0.9084) teacher/usage_min 0.0222 (0.0277) teacher/usage_std 0.4184 (0.4070) nleep/row_max_mean 1499.0469 (1503.1097) nleep/row_max_std 71.9454 (67.0839) nleep/row_min_mean 1468.7288 (1470.3766) lr 2.2949e-04 eta 0:03:08
epoch [41/50] batch [60/203] time 0.092 (0.093) data 0.001 (0.005) loss 1.3353 (1.2515) teacher_loss 0.4242 (0.4217) loss_zs_kd 0.0061 (0.0249) loss_oracle 0.5545 (0.4613) kd_loss 0.6309 (0.5867) acc 81.2500 (83.5938) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.1028 (0.0610) teacher/usage_max 0.8199 (0.9067) teacher/usage_min 0.0571 (0.0263) teacher/usage_std 0.3451 (0.4060) nleep/row_max_mean 1502.7057 (1503.7924) nleep/row_max_std 65.3547 (65.7332) nleep/row_min_mean 1472.1779 (1471.1238) lr 2.2949e-04 eta 0:03:02
epoch [41/50] batch [80/203] time 0.099 (0.092) data 0.000 (0.004) loss 1.1502 (1.2569) teacher_loss 0.3117 (0.4252) loss_zs_kd 0.0326 (0.0253) loss_oracle 0.4849 (0.4617) kd_loss 0.5797 (0.5882) acc 90.6250 (83.5547) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0518 (0.0597) teacher/usage_max 0.9230 (0.9065) teacher/usage_min 0.0196 (0.0257) teacher/usage_std 0.4173 (0.4059) nleep/row_max_mean 1498.7688 (1503.4577) nleep/row_max_std 68.4943 (65.5447) nleep/row_min_mean 1467.8486 (1470.8701) lr 2.2949e-04 eta 0:03:00
epoch [41/50] batch [100/203] time 0.087 (0.093) data 0.000 (0.003) loss 1.3729 (1.2661) teacher_loss 0.5098 (0.4341) loss_zs_kd 0.0389 (0.0257) loss_oracle 0.5024 (0.4631) kd_loss 0.5924 (0.5876) acc 78.1250 (83.0625) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0321 (0.0585) teacher/usage_max 0.9302 (0.9084) teacher/usage_min 0.0047 (0.0259) teacher/usage_std 0.4227 (0.4071) nleep/row_max_mean 1497.7191 (1503.9633) nleep/row_max_std 67.1685 (64.5919) nleep/row_min_mean 1467.7625 (1471.2722) lr 2.2949e-04 eta 0:02:58
epoch [41/50] batch [120/203] time 0.098 (0.093) data 0.000 (0.003) loss 1.0318 (1.2651) teacher_loss 0.2673 (0.4349) loss_zs_kd 0.0159 (0.0257) loss_oracle 0.3947 (0.4615) kd_loss 0.5591 (0.5866) acc 90.6250 (83.3333) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0435 (0.0561) teacher/usage_max 0.9523 (0.9118) teacher/usage_min 0.0014 (0.0241) teacher/usage_std 0.4381 (0.4095) nleep/row_max_mean 1505.4668 (1503.3705) nleep/row_max_std 69.0918 (64.3864) nleep/row_min_mean 1471.5381 (1470.7351) lr 2.2949e-04 eta 0:02:58
epoch [41/50] batch [140/203] time 0.102 (0.094) data 0.000 (0.002) loss 1.1830 (1.2668) teacher_loss 0.3823 (0.4352) loss_zs_kd 0.0303 (0.0261) loss_oracle 0.4899 (0.4605) kd_loss 0.5406 (0.5883) acc 90.6250 (83.3259) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0431 (0.0556) teacher/usage_max 0.9715 (0.9105) teacher/usage_min 0.0046 (0.0238) teacher/usage_std 0.4513 (0.4087) nleep/row_max_mean 1518.4554 (1503.1100) nleep/row_max_std 49.7182 (64.4255) nleep/row_min_mean 1481.3337 (1470.4019) lr 2.2949e-04 eta 0:02:57
epoch [41/50] batch [160/203] time 0.088 (0.094) data 0.000 (0.002) loss 1.3594 (1.2762) teacher_loss 0.6148 (0.4432) loss_zs_kd 0.0167 (0.0261) loss_oracle 0.3797 (0.4605) kd_loss 0.5464 (0.5897) acc 71.8750 (83.1055) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1701) teacher/entropy 0.0394 (0.0543) teacher/usage_max 0.9694 (0.9104) teacher/usage_min 0.0046 (0.0237) teacher/usage_std 0.4499 (0.4087) nleep/row_max_mean 1484.3831 (1503.2143) nleep/row_max_std 84.9629 (64.2985) nleep/row_min_mean 1451.9871 (1470.4561) lr 2.2949e-04 eta 0:02:56
epoch [41/50] batch [180/203] time 0.091 (0.094) data 0.000 (0.002) loss 1.3658 (1.2727) teacher_loss 0.5640 (0.4416) loss_zs_kd 0.0235 (0.0259) loss_oracle 0.4744 (0.4597) kd_loss 0.5528 (0.5882) acc 78.1250 (83.3160) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5738 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0030 (0.0535) teacher/usage_max 0.9996 (0.9127) teacher/usage_min 0.0002 (0.0239) teacher/usage_std 0.4711 (0.4102) nleep/row_max_mean 1502.7903 (1503.1261) nleep/row_max_std 57.1324 (63.9035) nleep/row_min_mean 1469.7246 (1470.3007) lr 2.2949e-04 eta 0:02:54
epoch [41/50] batch [200/203] time 0.085 (0.093) data 0.000 (0.002) loss 1.0966 (1.2686) teacher_loss 0.2860 (0.4371) loss_zs_kd 0.0132 (0.0254) loss_oracle 0.4570 (0.4611) kd_loss 0.5756 (0.5883) acc 90.6250 (83.5312) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5738 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0367 (0.0522) teacher/usage_max 0.9425 (0.9140) teacher/usage_min 0.0234 (0.0236) teacher/usage_std 0.4308 (0.4111) nleep/row_max_mean 1492.5082 (1503.2990) nleep/row_max_std 70.6292 (63.5906) nleep/row_min_mean 1457.0991 (1470.3480) lr 2.2949e-04 eta 0:02:50
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,362
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 87.5%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [42/50] batch [20/203] time 0.100 (0.114) data 0.000 (0.016) loss 1.3563 (1.2287) teacher_loss 0.5686 (0.4210) loss_zs_kd 0.0239 (0.0258) loss_oracle 0.4590 (0.4600) kd_loss 0.5462 (0.5649) acc 81.2500 (85.1562) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0114 (0.0443) teacher/usage_max 0.9976 (0.9455) teacher/usage_min 0.0008 (0.0137) teacher/usage_std 0.4697 (0.4331) nleep/row_max_mean 1496.0006 (1499.3374) nleep/row_max_std 63.1205 (67.2979) nleep/row_min_mean 1462.0236 (1466.9233) lr 1.9098e-04 eta 0:03:26
epoch [42/50] batch [40/203] time 0.088 (0.103) data 0.000 (0.008) loss 1.3060 (1.2255) teacher_loss 0.5088 (0.4107) loss_zs_kd 0.0190 (0.0234) loss_oracle 0.4695 (0.4616) kd_loss 0.5530 (0.5723) acc 78.1250 (85.3906) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0026 (0.0412) teacher/usage_max 0.9996 (0.9412) teacher/usage_min 0.0001 (0.0174) teacher/usage_std 0.4711 (0.4300) nleep/row_max_mean 1496.7163 (1498.3977) nleep/row_max_std 65.4035 (66.3105) nleep/row_min_mean 1463.2263 (1465.8261) lr 1.9098e-04 eta 0:03:03
epoch [42/50] batch [60/203] time 0.096 (0.100) data 0.001 (0.006) loss 1.2769 (1.2292) teacher_loss 0.4306 (0.4156) loss_zs_kd 0.0213 (0.0223) loss_oracle 0.4683 (0.4576) kd_loss 0.6015 (0.5736) acc 84.3750 (84.0104) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0149 (0.0384) teacher/usage_max 0.9381 (0.9426) teacher/usage_min 0.0000 (0.0155) teacher/usage_std 0.4283 (0.4311) nleep/row_max_mean 1516.6992 (1500.9132) nleep/row_max_std 40.8600 (63.8453) nleep/row_min_mean 1482.6202 (1467.9537) lr 1.9098e-04 eta 0:02:56
epoch [42/50] batch [80/203] time 0.091 (0.099) data 0.000 (0.004) loss 1.5432 (1.2399) teacher_loss 0.6398 (0.4216) loss_zs_kd 0.0225 (0.0216) loss_oracle 0.5600 (0.4621) kd_loss 0.6121 (0.5764) acc 81.2500 (83.6719) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0730 (0.0403) teacher/usage_max 0.8689 (0.9379) teacher/usage_min 0.0261 (0.0161) teacher/usage_std 0.3800 (0.4278) nleep/row_max_mean 1471.6847 (1501.1250) nleep/row_max_std 80.1946 (63.2784) nleep/row_min_mean 1440.9314 (1468.0549) lr 1.9098e-04 eta 0:02:52
epoch [42/50] batch [100/203] time 0.089 (0.098) data 0.000 (0.003) loss 1.1565 (1.2485) teacher_loss 0.3367 (0.4293) loss_zs_kd 0.0201 (0.0218) loss_oracle 0.4519 (0.4619) kd_loss 0.5838 (0.5774) acc 87.5000 (83.4375) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0409 (0.0423) teacher/usage_max 0.9299 (0.9350) teacher/usage_min 0.0299 (0.0170) teacher/usage_std 0.4219 (0.4258) nleep/row_max_mean 1519.5278 (1500.1217) nleep/row_max_std 43.5798 (64.0503) nleep/row_min_mean 1482.8975 (1467.2372) lr 1.9098e-04 eta 0:02:48
epoch [42/50] batch [120/203] time 0.086 (0.096) data 0.000 (0.003) loss 1.3367 (1.2557) teacher_loss 0.4486 (0.4380) loss_zs_kd 0.0194 (0.0216) loss_oracle 0.5957 (0.4619) kd_loss 0.5805 (0.5760) acc 84.3750 (83.2292) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5738 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0573 (0.0423) teacher/usage_max 0.9168 (0.9363) teacher/usage_min 0.0175 (0.0165) teacher/usage_std 0.4130 (0.4267) nleep/row_max_mean 1506.4792 (1499.6095) nleep/row_max_std 37.9653 (64.0125) nleep/row_min_mean 1475.9553 (1466.8863) lr 1.9098e-04 eta 0:02:44
epoch [42/50] batch [140/203] time 0.096 (0.095) data 0.000 (0.003) loss 1.1821 (1.2603) teacher_loss 0.4107 (0.4423) loss_zs_kd 0.0667 (0.0223) loss_oracle 0.4538 (0.4616) kd_loss 0.5112 (0.5761) acc 81.2500 (82.9018) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.1082 (0.0433) teacher/usage_max 0.9352 (0.9352) teacher/usage_min 0.0211 (0.0170) teacher/usage_std 0.4257 (0.4259) nleep/row_max_mean 1502.0387 (1499.8917) nleep/row_max_std 51.5533 (63.6702) nleep/row_min_mean 1470.4172 (1467.1402) lr 1.9098e-04 eta 0:02:40
epoch [42/50] batch [160/203] time 0.096 (0.095) data 0.000 (0.002) loss 1.3024 (1.2609) teacher_loss 0.4210 (0.4423) loss_zs_kd 0.0202 (0.0225) loss_oracle 0.5401 (0.4605) kd_loss 0.6013 (0.5771) acc 84.3750 (82.8906) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0130 (0.0424) teacher/usage_max 0.9404 (0.9352) teacher/usage_min 0.0000 (0.0169) teacher/usage_std 0.4300 (0.4259) nleep/row_max_mean 1503.0667 (1500.4707) nleep/row_max_std 67.6182 (62.9613) nleep/row_min_mean 1465.2397 (1467.5506) lr 1.9098e-04 eta 0:02:38
epoch [42/50] batch [180/203] time 0.094 (0.095) data 0.000 (0.002) loss 1.4784 (1.2682) teacher_loss 0.6406 (0.4488) loss_zs_kd 0.0109 (0.0224) loss_oracle 0.4646 (0.4611) kd_loss 0.6001 (0.5777) acc 78.1250 (82.6736) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0437 (0.0432) teacher/usage_max 0.9107 (0.9337) teacher/usage_min 0.0371 (0.0173) teacher/usage_std 0.4083 (0.4249) nleep/row_max_mean 1498.6154 (1500.4657) nleep/row_max_std 63.8105 (62.9597) nleep/row_min_mean 1467.0359 (1467.5078) lr 1.9098e-04 eta 0:02:35
epoch [42/50] batch [200/203] time 0.103 (0.094) data 0.000 (0.002) loss 1.2818 (1.2663) teacher_loss 0.5067 (0.4462) loss_zs_kd 0.0284 (0.0221) loss_oracle 0.4144 (0.4620) kd_loss 0.5536 (0.5780) acc 81.2500 (82.5781) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0292 (0.0448) teacher/usage_max 0.9721 (0.9318) teacher/usage_min 0.0001 (0.0174) teacher/usage_std 0.4518 (0.4236) nleep/row_max_mean 1507.8723 (1500.5195) nleep/row_max_std 71.9677 (62.9561) nleep/row_min_mean 1471.2202 (1467.6722) lr 1.9098e-04 eta 0:02:33
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,357
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 87.5%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [43/50] batch [20/203] time 0.087 (0.103) data 0.001 (0.015) loss 1.3625 (1.3066) teacher_loss 0.5771 (0.4849) loss_zs_kd 0.0199 (0.0215) loss_oracle 0.4415 (0.4601) kd_loss 0.5547 (0.5809) acc 90.6250 (82.6562) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0585 (0.0462) teacher/usage_max 0.9414 (0.9274) teacher/usage_min 0.0187 (0.0166) teacher/usage_std 0.4301 (0.4205) nleep/row_max_mean 1511.6653 (1503.6688) nleep/row_max_std 55.1164 (61.8698) nleep/row_min_mean 1478.5183 (1470.8318) lr 1.5567e-04 eta 0:02:44
epoch [43/50] batch [40/203] time 0.089 (0.095) data 0.000 (0.007) loss 1.1194 (1.2973) teacher_loss 0.3001 (0.4853) loss_zs_kd 0.0211 (0.0208) loss_oracle 0.4678 (0.4523) kd_loss 0.5749 (0.5754) acc 90.6250 (82.4219) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0679 (0.0456) teacher/usage_max 0.9116 (0.9335) teacher/usage_min 0.0428 (0.0134) teacher/usage_std 0.4089 (0.4249) nleep/row_max_mean 1515.0726 (1503.4687) nleep/row_max_std 57.9452 (62.2520) nleep/row_min_mean 1480.5583 (1470.5140) lr 1.5567e-04 eta 0:02:30
epoch [43/50] batch [60/203] time 0.075 (0.091) data 0.001 (0.005) loss 1.1144 (1.2937) teacher_loss 0.2995 (0.4790) loss_zs_kd 0.0113 (0.0210) loss_oracle 0.4558 (0.4551) kd_loss 0.5814 (0.5766) acc 90.6250 (82.2917) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0304 (0.0435) teacher/usage_max 0.9429 (0.9344) teacher/usage_min 0.0237 (0.0132) teacher/usage_std 0.4310 (0.4255) nleep/row_max_mean 1493.5837 (1503.0641) nleep/row_max_std 68.8095 (61.6776) nleep/row_min_mean 1463.9646 (1470.0801) lr 1.5567e-04 eta 0:02:23
epoch [43/50] batch [80/203] time 0.104 (0.090) data 0.000 (0.004) loss 1.1457 (1.2828) teacher_loss 0.2879 (0.4615) loss_zs_kd 0.0127 (0.0205) loss_oracle 0.4694 (0.4628) kd_loss 0.6167 (0.5797) acc 90.6250 (82.5000) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0325 (0.0414) teacher/usage_max 0.9052 (0.9335) teacher/usage_min 0.0346 (0.0153) teacher/usage_std 0.4045 (0.4248) nleep/row_max_mean 1507.5286 (1503.4469) nleep/row_max_std 59.9119 (60.9340) nleep/row_min_mean 1470.6820 (1470.3263) lr 1.5567e-04 eta 0:02:18
epoch [43/50] batch [100/203] time 0.078 (0.093) data 0.000 (0.003) loss 1.2665 (1.2733) teacher_loss 0.4662 (0.4477) loss_zs_kd 0.0266 (0.0205) loss_oracle 0.4279 (0.4626) kd_loss 0.5731 (0.5841) acc 78.1250 (83.0000) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0172 (0.0428) teacher/usage_max 0.9645 (0.9277) teacher/usage_min 0.0001 (0.0172) teacher/usage_std 0.4466 (0.4208) nleep/row_max_mean 1505.8451 (1503.0451) nleep/row_max_std 59.3068 (60.4273) nleep/row_min_mean 1468.4749 (1470.1844) lr 1.5567e-04 eta 0:02:21
epoch [43/50] batch [120/203] time 0.096 (0.092) data 0.000 (0.003) loss 1.2947 (1.2695) teacher_loss 0.5217 (0.4462) loss_zs_kd 0.0151 (0.0204) loss_oracle 0.4206 (0.4627) kd_loss 0.5551 (0.5817) acc 75.0000 (82.9167) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0493 (0.0436) teacher/usage_max 0.9503 (0.9292) teacher/usage_min 0.0183 (0.0168) teacher/usage_std 0.4363 (0.4218) nleep/row_max_mean 1489.9375 (1502.8171) nleep/row_max_std 73.0681 (60.7943) nleep/row_min_mean 1456.7012 (1469.9548) lr 1.5567e-04 eta 0:02:18
epoch [43/50] batch [140/203] time 0.076 (0.091) data 0.000 (0.002) loss 1.1099 (1.2646) teacher_loss 0.3249 (0.4414) loss_zs_kd 0.0146 (0.0207) loss_oracle 0.4524 (0.4623) kd_loss 0.5515 (0.5817) acc 81.2500 (82.9911) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0047 (0.0435) teacher/usage_max 0.9992 (0.9294) teacher/usage_min 0.0001 (0.0168) teacher/usage_std 0.4709 (0.4220) nleep/row_max_mean 1512.5446 (1502.7935) nleep/row_max_std 48.4571 (60.3535) nleep/row_min_mean 1475.6917 (1469.9440) lr 1.5567e-04 eta 0:02:14
epoch [43/50] batch [160/203] time 0.088 (0.091) data 0.000 (0.002) loss 1.2085 (1.2620) teacher_loss 0.4137 (0.4396) loss_zs_kd 0.0214 (0.0210) loss_oracle 0.4784 (0.4616) kd_loss 0.5450 (0.5811) acc 87.5000 (83.2227) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0357 (0.0438) teacher/usage_max 0.9743 (0.9297) teacher/usage_min 0.0001 (0.0170) teacher/usage_std 0.4534 (0.4222) nleep/row_max_mean 1512.4758 (1502.7027) nleep/row_max_std 54.3858 (60.1500) nleep/row_min_mean 1476.4158 (1469.8528) lr 1.5567e-04 eta 0:02:12
epoch [43/50] batch [180/203] time 0.076 (0.090) data 0.000 (0.002) loss 1.0047 (1.2627) teacher_loss 0.2460 (0.4416) loss_zs_kd 0.0117 (0.0213) loss_oracle 0.4391 (0.4613) kd_loss 0.5332 (0.5798) acc 84.3750 (82.8472) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0403 (0.0432) teacher/usage_max 0.9817 (0.9315) teacher/usage_min 0.0038 (0.0168) teacher/usage_std 0.4585 (0.4234) nleep/row_max_mean 1497.9490 (1502.1241) nleep/row_max_std 61.5519 (60.4219) nleep/row_min_mean 1466.7374 (1469.3680) lr 1.5567e-04 eta 0:02:10
epoch [43/50] batch [200/203] time 0.087 (0.090) data 0.000 (0.002) loss 1.1486 (1.2616) teacher_loss 0.3299 (0.4405) loss_zs_kd 0.0251 (0.0217) loss_oracle 0.5019 (0.4621) kd_loss 0.5552 (0.5792) acc 90.6250 (82.9062) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.1007 (0.0436) teacher/usage_max 0.8984 (0.9318) teacher/usage_min 0.0279 (0.0163) teacher/usage_std 0.4000 (0.4236) nleep/row_max_mean 1491.9559 (1502.1519) nleep/row_max_std 73.7841 (60.5637) nleep/row_min_mean 1461.2388 (1469.4026) lr 1.5567e-04 eta 0:02:08
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,359
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 87.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [44/50] batch [20/203] time 0.099 (0.110) data 0.000 (0.015) loss 1.2754 (1.2284) teacher_loss 0.5139 (0.4177) loss_zs_kd 0.0219 (0.0232) loss_oracle 0.4257 (0.4543) kd_loss 0.5377 (0.5719) acc 71.8750 (83.7500) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0434 (0.0345) teacher/usage_max 0.9738 (0.9483) teacher/usage_min 0.0073 (0.0130) teacher/usage_std 0.4529 (0.4350) nleep/row_max_mean 1525.5104 (1503.6789) nleep/row_max_std 50.4859 (63.3128) nleep/row_min_mean 1487.0000 (1469.7859) lr 1.2369e-04 eta 0:02:33
epoch [44/50] batch [40/203] time 0.089 (0.099) data 0.000 (0.007) loss 1.2609 (1.2285) teacher_loss 0.4553 (0.4120) loss_zs_kd 0.0162 (0.0226) loss_oracle 0.4226 (0.4583) kd_loss 0.5861 (0.5760) acc 78.1250 (83.6719) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0283 (0.0345) teacher/usage_max 0.9403 (0.9441) teacher/usage_min 0.0042 (0.0130) teacher/usage_std 0.4297 (0.4321) nleep/row_max_mean 1485.0505 (1501.4485) nleep/row_max_std 66.5039 (63.5916) nleep/row_min_mean 1456.3260 (1467.9353) lr 1.2369e-04 eta 0:02:16
epoch [44/50] batch [60/203] time 0.093 (0.099) data 0.001 (0.005) loss 1.1138 (1.2333) teacher_loss 0.2851 (0.4149) loss_zs_kd 0.0248 (0.0220) loss_oracle 0.4752 (0.4575) kd_loss 0.5786 (0.5786) acc 87.5000 (83.9583) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0545 (0.0366) teacher/usage_max 0.9214 (0.9394) teacher/usage_min 0.0368 (0.0155) teacher/usage_std 0.4158 (0.4288) nleep/row_max_mean 1499.4646 (1501.1347) nleep/row_max_std 61.6413 (62.7796) nleep/row_min_mean 1465.1134 (1467.9493) lr 1.2369e-04 eta 0:02:14
epoch [44/50] batch [80/203] time 0.092 (0.098) data 0.000 (0.004) loss 1.1609 (1.2417) teacher_loss 0.3465 (0.4270) loss_zs_kd 0.0161 (0.0223) loss_oracle 0.4561 (0.4554) kd_loss 0.5783 (0.5759) acc 81.2500 (83.3984) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0279 (0.0378) teacher/usage_max 0.9485 (0.9410) teacher/usage_min 0.0230 (0.0146) teacher/usage_std 0.4350 (0.4299) nleep/row_max_mean 1505.1648 (1501.8804) nleep/row_max_std 60.1870 (61.4504) nleep/row_min_mean 1471.3961 (1468.7237) lr 1.2369e-04 eta 0:02:11
epoch [44/50] batch [100/203] time 0.099 (0.097) data 0.001 (0.003) loss 1.1344 (1.2374) teacher_loss 0.3809 (0.4212) loss_zs_kd 0.0066 (0.0215) loss_oracle 0.4378 (0.4566) kd_loss 0.5313 (0.5771) acc 87.5000 (83.5625) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0550 (0.0389) teacher/usage_max 0.9688 (0.9386) teacher/usage_min 0.0050 (0.0166) teacher/usage_std 0.4494 (0.4283) nleep/row_max_mean 1482.3645 (1501.4617) nleep/row_max_std 81.1756 (62.2110) nleep/row_min_mean 1450.7853 (1468.4067) lr 1.2369e-04 eta 0:02:08
epoch [44/50] batch [120/203] time 0.093 (0.097) data 0.000 (0.003) loss 1.3514 (1.2332) teacher_loss 0.4934 (0.4186) loss_zs_kd 0.0287 (0.0214) loss_oracle 0.5156 (0.4568) kd_loss 0.5858 (0.5755) acc 84.3750 (83.4115) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5738 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0474 (0.0397) teacher/usage_max 0.9213 (0.9394) teacher/usage_min 0.0309 (0.0161) teacher/usage_std 0.4158 (0.4288) nleep/row_max_mean 1507.3883 (1502.5152) nleep/row_max_std 59.6823 (61.3625) nleep/row_min_mean 1476.4043 (1469.4981) lr 1.2369e-04 eta 0:02:05
epoch [44/50] batch [140/203] time 0.100 (0.096) data 0.000 (0.002) loss 1.2563 (1.2413) teacher_loss 0.5060 (0.4291) loss_zs_kd 0.0285 (0.0217) loss_oracle 0.3886 (0.4551) kd_loss 0.5418 (0.5738) acc 75.0000 (82.8348) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0196 (0.0389) teacher/usage_max 0.9937 (0.9419) teacher/usage_min 0.0011 (0.0152) teacher/usage_std 0.4670 (0.4306) nleep/row_max_mean 1506.4844 (1502.5213) nleep/row_max_std 55.7402 (61.6094) nleep/row_min_mean 1470.9615 (1469.4527) lr 1.2369e-04 eta 0:02:03
epoch [44/50] batch [160/203] time 0.096 (0.096) data 0.000 (0.002) loss 1.3097 (1.2449) teacher_loss 0.4929 (0.4310) loss_zs_kd 0.0245 (0.0212) loss_oracle 0.4801 (0.4560) kd_loss 0.5645 (0.5753) acc 75.0000 (82.7930) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0393 (0.0384) teacher/usage_max 0.9509 (0.9410) teacher/usage_min 0.0137 (0.0150) teacher/usage_std 0.4368 (0.4299) nleep/row_max_mean 1493.8271 (1502.3479) nleep/row_max_std 69.4325 (61.8030) nleep/row_min_mean 1463.5298 (1469.3282) lr 1.2369e-04 eta 0:02:00
epoch [44/50] batch [180/203] time 0.095 (0.096) data 0.000 (0.002) loss 1.5080 (1.2472) teacher_loss 0.6904 (0.4337) loss_zs_kd 0.0341 (0.0212) loss_oracle 0.4299 (0.4557) kd_loss 0.5856 (0.5750) acc 75.0000 (82.9861) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0584 (0.0388) teacher/usage_max 0.9105 (0.9408) teacher/usage_min 0.0341 (0.0152) teacher/usage_std 0.4082 (0.4298) nleep/row_max_mean 1508.8049 (1502.5520) nleep/row_max_std 54.6695 (61.7087) nleep/row_min_mean 1476.3850 (1469.5922) lr 1.2369e-04 eta 0:01:58
epoch [44/50] batch [200/203] time 0.084 (0.096) data 0.000 (0.002) loss 1.2511 (1.2473) teacher_loss 0.4335 (0.4328) loss_zs_kd 0.0254 (0.0212) loss_oracle 0.4821 (0.4559) kd_loss 0.5639 (0.5760) acc 81.2500 (83.0625) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0670 (0.0386) teacher/usage_max 0.9237 (0.9400) teacher/usage_min 0.0108 (0.0157) teacher/usage_std 0.4181 (0.4292) nleep/row_max_mean 1486.7252 (1502.6169) nleep/row_max_std 77.8104 (61.5323) nleep/row_min_mean 1456.5032 (1469.7048) lr 1.2369e-04 eta 0:01:57
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,361
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 87.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [45/50] batch [20/203] time 0.094 (0.117) data 0.000 (0.017) loss 1.2498 (1.2730) teacher_loss 0.3493 (0.4528) loss_zs_kd 0.0312 (0.0192) loss_oracle 0.4694 (0.4651) kd_loss 0.6502 (0.5781) acc 87.5000 (81.4062) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0230 (0.0374) teacher/usage_max 0.8807 (0.9391) teacher/usage_min 0.0576 (0.0153) teacher/usage_std 0.3870 (0.4286) nleep/row_max_mean 1507.2905 (1506.2478) nleep/row_max_std 64.3450 (59.7310) nleep/row_min_mean 1474.3978 (1473.0455) lr 9.5173e-05 eta 0:02:19
epoch [45/50] batch [40/203] time 0.086 (0.108) data 0.000 (0.009) loss 1.2295 (1.2875) teacher_loss 0.3591 (0.4660) loss_zs_kd 0.0179 (0.0193) loss_oracle 0.4841 (0.4586) kd_loss 0.6194 (0.5826) acc 84.3750 (81.6406) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0251 (0.0424) teacher/usage_max 0.9097 (0.9295) teacher/usage_min 0.0015 (0.0183) teacher/usage_std 0.4091 (0.4219) nleep/row_max_mean 1500.1776 (1502.2350) nleep/row_max_std 62.5397 (62.9860) nleep/row_min_mean 1468.4207 (1469.6781) lr 9.5173e-05 eta 0:02:07
epoch [45/50] batch [60/203] time 0.090 (0.105) data 0.001 (0.006) loss 1.6311 (1.2834) teacher_loss 0.6634 (0.4596) loss_zs_kd 0.0127 (0.0200) loss_oracle 0.5119 (0.4601) kd_loss 0.7054 (0.5838) acc 78.1250 (82.0833) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0328 (0.0445) teacher/usage_max 0.8152 (0.9262) teacher/usage_min 0.0634 (0.0200) teacher/usage_std 0.3415 (0.4196) nleep/row_max_mean 1491.9568 (1502.2735) nleep/row_max_std 65.2565 (62.0811) nleep/row_min_mean 1461.0793 (1469.7950) lr 9.5173e-05 eta 0:02:01
epoch [45/50] batch [80/203] time 0.091 (0.102) data 0.001 (0.004) loss 1.5266 (1.2847) teacher_loss 0.7439 (0.4609) loss_zs_kd 0.0148 (0.0195) loss_oracle 0.4557 (0.4636) kd_loss 0.5475 (0.5823) acc 75.0000 (81.7969) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0104 (0.0436) teacher/usage_max 0.9974 (0.9285) teacher/usage_min 0.0003 (0.0193) teacher/usage_std 0.4695 (0.4212) nleep/row_max_mean 1503.6716 (1502.4465) nleep/row_max_std 72.3447 (61.4924) nleep/row_min_mean 1468.5286 (1469.7961) lr 9.5173e-05 eta 0:01:55
epoch [45/50] batch [100/203] time 0.093 (0.100) data 0.000 (0.004) loss 1.1465 (1.2829) teacher_loss 0.3161 (0.4536) loss_zs_kd 0.0241 (0.0204) loss_oracle 0.5310 (0.4652) kd_loss 0.5529 (0.5865) acc 90.6250 (82.1562) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0509 (0.0451) teacher/usage_max 0.9510 (0.9229) teacher/usage_min 0.0128 (0.0218) teacher/usage_std 0.4369 (0.4172) nleep/row_max_mean 1493.9197 (1501.7247) nleep/row_max_std 67.0197 (61.9096) nleep/row_min_mean 1462.0198 (1469.3942) lr 9.5173e-05 eta 0:01:51
epoch [45/50] batch [120/203] time 0.088 (0.099) data 0.000 (0.003) loss 1.2245 (1.2743) teacher_loss 0.4032 (0.4467) loss_zs_kd 0.0244 (0.0207) loss_oracle 0.4094 (0.4639) kd_loss 0.6044 (0.5852) acc 81.2500 (82.5000) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0170 (0.0444) teacher/usage_max 0.9331 (0.9249) teacher/usage_min 0.0313 (0.0215) teacher/usage_std 0.4241 (0.4187) nleep/row_max_mean 1511.2157 (1501.5666) nleep/row_max_std 75.7031 (62.6528) nleep/row_min_mean 1472.9144 (1469.1996) lr 9.5173e-05 eta 0:01:49
epoch [45/50] batch [140/203] time 0.082 (0.099) data 0.000 (0.003) loss 1.2991 (1.2697) teacher_loss 0.4688 (0.4429) loss_zs_kd 0.0053 (0.0212) loss_oracle 0.4905 (0.4634) kd_loss 0.5823 (0.5845) acc 81.2500 (82.8125) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0041 (0.0440) teacher/usage_max 0.9685 (0.9260) teacher/usage_min 0.0003 (0.0204) teacher/usage_std 0.4493 (0.4194) nleep/row_max_mean 1514.4993 (1502.4252) nleep/row_max_std 46.6533 (61.4507) nleep/row_min_mean 1478.6814 (1469.9184) lr 9.5173e-05 eta 0:01:47
epoch [45/50] batch [160/203] time 0.096 (0.098) data 0.000 (0.002) loss 1.0928 (1.2678) teacher_loss 0.2424 (0.4404) loss_zs_kd 0.0083 (0.0216) loss_oracle 0.4899 (0.4634) kd_loss 0.6014 (0.5849) acc 90.6250 (83.0664) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0529 (0.0443) teacher/usage_max 0.8999 (0.9252) teacher/usage_min 0.0358 (0.0208) teacher/usage_std 0.4008 (0.4189) nleep/row_max_mean 1509.2908 (1501.7659) nleep/row_max_std 58.6681 (62.1703) nleep/row_min_mean 1478.4331 (1469.3927) lr 9.5173e-05 eta 0:01:44
epoch [45/50] batch [180/203] time 0.085 (0.098) data 0.000 (0.002) loss 1.2121 (1.2704) teacher_loss 0.4258 (0.4436) loss_zs_kd 0.0111 (0.0215) loss_oracle 0.4257 (0.4635) kd_loss 0.5679 (0.5842) acc 81.2500 (83.1250) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0635 (0.0458) teacher/usage_max 0.9229 (0.9245) teacher/usage_min 0.0363 (0.0209) teacher/usage_std 0.4169 (0.4184) nleep/row_max_mean 1505.9915 (1501.6534) nleep/row_max_std 65.7743 (62.4978) nleep/row_min_mean 1472.7424 (1469.3323) lr 9.5173e-05 eta 0:01:41
epoch [45/50] batch [200/203] time 0.083 (0.097) data 0.000 (0.002) loss 1.3574 (1.2730) teacher_loss 0.5574 (0.4471) loss_zs_kd 0.0102 (0.0213) loss_oracle 0.4409 (0.4634) kd_loss 0.5744 (0.5835) acc 81.2500 (82.9531) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0762 (0.0465) teacher/usage_max 0.9037 (0.9245) teacher/usage_min 0.0332 (0.0208) teacher/usage_std 0.4035 (0.4184) nleep/row_max_mean 1491.8901 (1501.4939) nleep/row_max_std 79.2171 (63.0435) nleep/row_min_mean 1460.0491 (1469.2131) lr 9.5173e-05 eta 0:01:38
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,360
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 87.5%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [46/50] batch [20/203] time 0.087 (0.104) data 0.000 (0.014) loss 1.0996 (1.2594) teacher_loss 0.3043 (0.4255) loss_zs_kd 0.0301 (0.0235) loss_oracle 0.4663 (0.4683) kd_loss 0.5471 (0.5880) acc 90.6250 (83.9062) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0221 (0.0429) teacher/usage_max 0.9858 (0.9235) teacher/usage_min 0.0001 (0.0166) teacher/usage_std 0.4614 (0.4178) nleep/row_max_mean 1523.2930 (1505.4345) nleep/row_max_std 32.9856 (57.3579) nleep/row_min_mean 1487.5161 (1472.9087) lr 7.0224e-05 eta 0:01:43
epoch [46/50] batch [40/203] time 0.093 (0.106) data 0.001 (0.007) loss 1.1550 (1.2651) teacher_loss 0.3076 (0.4348) loss_zs_kd 0.0091 (0.0208) loss_oracle 0.4321 (0.4700) kd_loss 0.6269 (0.5849) acc 87.5000 (83.2812) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0225 (0.0446) teacher/usage_max 0.9049 (0.9250) teacher/usage_min 0.0011 (0.0177) teacher/usage_std 0.4059 (0.4189) nleep/row_max_mean 1502.8906 (1502.8646) nleep/row_max_std 59.6894 (63.2070) nleep/row_min_mean 1471.8494 (1470.4404) lr 7.0224e-05 eta 0:01:43
epoch [46/50] batch [60/203] time 0.086 (0.103) data 0.000 (0.005) loss 1.5423 (1.2654) teacher_loss 0.6953 (0.4376) loss_zs_kd 0.0469 (0.0206) loss_oracle 0.4856 (0.4657) kd_loss 0.5808 (0.5846) acc 71.8750 (83.4375) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0552 (0.0484) teacher/usage_max 0.9184 (0.9214) teacher/usage_min 0.0317 (0.0212) teacher/usage_std 0.4138 (0.4162) nleep/row_max_mean 1507.6382 (1502.1085) nleep/row_max_std 42.0643 (63.0942) nleep/row_min_mean 1479.9701 (1470.1924) lr 7.0224e-05 eta 0:01:38
epoch [46/50] batch [80/203] time 0.089 (0.101) data 0.000 (0.004) loss 1.5598 (1.2800) teacher_loss 0.6707 (0.4508) loss_zs_kd 0.0207 (0.0215) loss_oracle 0.4847 (0.4645) kd_loss 0.6364 (0.5861) acc 71.8750 (82.9688) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0573 (0.0458) teacher/usage_max 0.8601 (0.9225) teacher/usage_min 0.0599 (0.0212) teacher/usage_std 0.3726 (0.4170) nleep/row_max_mean 1502.6477 (1501.3821) nleep/row_max_std 55.2880 (63.9197) nleep/row_min_mean 1471.6340 (1469.4004) lr 7.0224e-05 eta 0:01:34
epoch [46/50] batch [100/203] time 0.097 (0.100) data 0.000 (0.003) loss 1.3152 (1.2736) teacher_loss 0.5199 (0.4435) loss_zs_kd 0.0152 (0.0208) loss_oracle 0.4137 (0.4649) kd_loss 0.5808 (0.5873) acc 81.2500 (83.2500) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0057 (0.0465) teacher/usage_max 0.9682 (0.9206) teacher/usage_min 0.0000 (0.0217) teacher/usage_std 0.4491 (0.4157) nleep/row_max_mean 1526.9447 (1501.6453) nleep/row_max_std 35.9962 (64.2426) nleep/row_min_mean 1490.6084 (1469.5174) lr 7.0224e-05 eta 0:01:31
epoch [46/50] batch [120/203] time 0.096 (0.099) data 0.000 (0.003) loss 1.1990 (1.2805) teacher_loss 0.3969 (0.4500) loss_zs_kd 0.0164 (0.0216) loss_oracle 0.4302 (0.4635) kd_loss 0.5789 (0.5879) acc 87.5000 (82.8385) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0897 (0.0470) teacher/usage_max 0.8853 (0.9194) teacher/usage_min 0.0530 (0.0218) teacher/usage_std 0.3903 (0.4149) nleep/row_max_mean 1498.8882 (1501.4400) nleep/row_max_std 79.3217 (64.8266) nleep/row_min_mean 1467.4841 (1469.2955) lr 7.0224e-05 eta 0:01:28
epoch [46/50] batch [140/203] time 0.098 (0.099) data 0.000 (0.002) loss 1.0035 (1.2730) teacher_loss 0.1536 (0.4445) loss_zs_kd 0.0120 (0.0214) loss_oracle 0.5390 (0.4625) kd_loss 0.5744 (0.5865) acc 100.0000 (83.2589) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0568 (0.0480) teacher/usage_max 0.9234 (0.9199) teacher/usage_min 0.0113 (0.0224) teacher/usage_std 0.4178 (0.4152) nleep/row_max_mean 1511.4940 (1501.2357) nleep/row_max_std 61.7323 (64.8712) nleep/row_min_mean 1475.3927 (1469.1406) lr 7.0224e-05 eta 0:01:26
epoch [46/50] batch [160/203] time 0.103 (0.099) data 0.000 (0.002) loss 1.0802 (1.2695) teacher_loss 0.2282 (0.4413) loss_zs_kd 0.0311 (0.0215) loss_oracle 0.4576 (0.4627) kd_loss 0.6077 (0.5861) acc 90.6250 (83.3398) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0531 (0.0484) teacher/usage_max 0.8934 (0.9199) teacher/usage_min 0.0453 (0.0230) teacher/usage_std 0.3961 (0.4152) nleep/row_max_mean 1493.4507 (1500.8436) nleep/row_max_std 68.2289 (65.0650) nleep/row_min_mean 1465.2490 (1468.7850) lr 7.0224e-05 eta 0:01:24
epoch [46/50] batch [180/203] time 0.080 (0.097) data 0.000 (0.002) loss 1.3103 (1.2685) teacher_loss 0.4652 (0.4399) loss_zs_kd 0.0254 (0.0212) loss_oracle 0.4661 (0.4633) kd_loss 0.5994 (0.5864) acc 87.5000 (83.3854) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0594 (0.0479) teacher/usage_max 0.8953 (0.9201) teacher/usage_min 0.0435 (0.0228) teacher/usage_std 0.3975 (0.4153) nleep/row_max_mean 1512.9990 (1501.4369) nleep/row_max_std 51.8920 (64.7311) nleep/row_min_mean 1479.5437 (1469.3454) lr 7.0224e-05 eta 0:01:21
epoch [46/50] batch [200/203] time 0.085 (0.096) data 0.000 (0.002) loss 1.5216 (1.2651) teacher_loss 0.6174 (0.4370) loss_zs_kd 0.0284 (0.0212) loss_oracle 0.5207 (0.4618) kd_loss 0.6297 (0.5866) acc 81.2500 (83.4531) gate/entropy 0.9777 (0.9775) gate/usage_max 0.5738 (0.5740) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1700 (0.1702) teacher/entropy 0.1062 (0.0487) teacher/usage_max 0.8179 (0.9190) teacher/usage_min 0.0732 (0.0235) teacher/usage_std 0.3430 (0.4146) nleep/row_max_mean 1473.0818 (1501.1782) nleep/row_max_std 67.3074 (64.7631) nleep/row_min_mean 1444.4094 (1469.1329) lr 7.0224e-05 eta 0:01:18
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,359
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 87.6%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,413
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [47/50] batch [20/203] time 0.089 (0.103) data 0.000 (0.012) loss 1.2556 (1.2970) teacher_loss 0.3415 (0.4539) loss_zs_kd 0.0189 (0.0229) loss_oracle 0.5366 (0.4763) kd_loss 0.6363 (0.5935) acc 90.6250 (82.3438) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0853 (0.0581) teacher/usage_max 0.8319 (0.9027) teacher/usage_min 0.0804 (0.0197) teacher/usage_std 0.3525 (0.4035) nleep/row_max_mean 1497.6968 (1499.4546) nleep/row_max_std 60.6398 (66.5100) nleep/row_min_mean 1466.0597 (1467.4542) lr 4.8943e-05 eta 0:01:21
epoch [47/50] batch [40/203] time 0.098 (0.098) data 0.000 (0.006) loss 1.2446 (1.2705) teacher_loss 0.4576 (0.4429) loss_zs_kd 0.0246 (0.0218) loss_oracle 0.4335 (0.4593) kd_loss 0.5580 (0.5870) acc 87.5000 (82.7344) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0415 (0.0539) teacher/usage_max 0.9552 (0.9134) teacher/usage_min 0.0006 (0.0199) teacher/usage_std 0.4401 (0.4108) nleep/row_max_mean 1495.7354 (1501.3004) nleep/row_max_std 84.0230 (66.6486) nleep/row_min_mean 1463.6836 (1469.0023) lr 4.8943e-05 eta 0:01:15
epoch [47/50] batch [60/203] time 0.088 (0.097) data 0.001 (0.004) loss 1.2452 (1.2819) teacher_loss 0.3355 (0.4534) loss_zs_kd 0.0218 (0.0223) loss_oracle 0.5531 (0.4627) kd_loss 0.6223 (0.5860) acc 93.7500 (82.6562) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0307 (0.0509) teacher/usage_max 0.9013 (0.9175) teacher/usage_min 0.0352 (0.0202) teacher/usage_std 0.4018 (0.4136) nleep/row_max_mean 1478.3994 (1500.1402) nleep/row_max_std 89.9754 (67.3726) nleep/row_min_mean 1448.2024 (1468.2185) lr 4.8943e-05 eta 0:01:12
epoch [47/50] batch [80/203] time 0.098 (0.095) data 0.000 (0.003) loss 1.3463 (1.2742) teacher_loss 0.5178 (0.4449) loss_zs_kd 0.0271 (0.0220) loss_oracle 0.4713 (0.4638) kd_loss 0.5794 (0.5865) acc 78.1250 (82.8125) gate/entropy 0.9773 (0.9775) gate/usage_max 0.5741 (0.5740) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1703 (0.1702) teacher/entropy 0.0080 (0.0506) teacher/usage_max 0.9673 (0.9173) teacher/usage_min 0.0015 (0.0214) teacher/usage_std 0.4484 (0.4135) nleep/row_max_mean 1519.6558 (1500.6906) nleep/row_max_std 41.1418 (65.5026) nleep/row_min_mean 1489.6213 (1468.8486) lr 4.8943e-05 eta 0:01:09
epoch [47/50] batch [100/203] time 0.089 (0.095) data 0.000 (0.003) loss 1.1298 (1.2701) teacher_loss 0.3152 (0.4426) loss_zs_kd 0.0499 (0.0223) loss_oracle 0.4859 (0.4634) kd_loss 0.5467 (0.5846) acc 84.3750 (82.6250) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0533 (0.0504) teacher/usage_max 0.9548 (0.9194) teacher/usage_min 0.0176 (0.0216) teacher/usage_std 0.4395 (0.4149) nleep/row_max_mean 1495.8420 (1499.9589) nleep/row_max_std 62.5607 (65.3572) nleep/row_min_mean 1464.7974 (1468.2070) lr 4.8943e-05 eta 0:01:07
epoch [47/50] batch [120/203] time 0.093 (0.095) data 0.000 (0.002) loss 1.3374 (1.2746) teacher_loss 0.5327 (0.4465) loss_zs_kd 0.0207 (0.0228) loss_oracle 0.4720 (0.4641) kd_loss 0.5583 (0.5847) acc 81.2500 (82.5000) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0418 (0.0497) teacher/usage_max 0.9545 (0.9200) teacher/usage_min 0.0031 (0.0222) teacher/usage_std 0.4395 (0.4152) nleep/row_max_mean 1511.6367 (1499.9613) nleep/row_max_std 61.2880 (64.1293) nleep/row_min_mean 1476.5103 (1468.2089) lr 4.8943e-05 eta 0:01:05
epoch [47/50] batch [140/203] time 0.091 (0.097) data 0.000 (0.002) loss 1.0998 (1.2712) teacher_loss 0.2784 (0.4431) loss_zs_kd 0.0048 (0.0224) loss_oracle 0.4782 (0.4638) kd_loss 0.5799 (0.5850) acc 87.5000 (82.9241) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0628 (0.0494) teacher/usage_max 0.9117 (0.9200) teacher/usage_min 0.0272 (0.0227) teacher/usage_std 0.4092 (0.4152) nleep/row_max_mean 1491.0042 (1499.6369) nleep/row_max_std 65.0414 (64.0133) nleep/row_min_mean 1462.8855 (1467.9160) lr 4.8943e-05 eta 0:01:04
epoch [47/50] batch [160/203] time 0.101 (0.097) data 0.000 (0.002) loss 1.2021 (1.2671) teacher_loss 0.4225 (0.4381) loss_zs_kd 0.0200 (0.0222) loss_oracle 0.3801 (0.4638) kd_loss 0.5795 (0.5860) acc 84.3750 (83.2812) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5741 (0.5740) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0502 (0.0495) teacher/usage_max 0.9246 (0.9189) teacher/usage_min 0.0029 (0.0224) teacher/usage_std 0.4190 (0.4145) nleep/row_max_mean 1497.9653 (1499.7347) nleep/row_max_std 71.2969 (63.9293) nleep/row_min_mean 1465.9753 (1467.9870) lr 4.8943e-05 eta 0:01:02
epoch [47/50] batch [180/203] time 0.097 (0.097) data 0.000 (0.002) loss 1.3816 (1.2599) teacher_loss 0.5395 (0.4304) loss_zs_kd 0.0289 (0.0221) loss_oracle 0.5272 (0.4633) kd_loss 0.5641 (0.5867) acc 78.1250 (83.5243) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0614 (0.0498) teacher/usage_max 0.9290 (0.9178) teacher/usage_min 0.0088 (0.0225) teacher/usage_std 0.4217 (0.4137) nleep/row_max_mean 1486.7958 (1499.9369) nleep/row_max_std 75.6610 (63.5326) nleep/row_min_mean 1454.6687 (1468.2476) lr 4.8943e-05 eta 0:01:01
epoch [47/50] batch [200/203] time 0.087 (0.097) data 0.000 (0.001) loss 1.1460 (1.2553) teacher_loss 0.3393 (0.4270) loss_zs_kd 0.0244 (0.0219) loss_oracle 0.3950 (0.4621) kd_loss 0.5970 (0.5863) acc 81.2500 (83.6250) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0376 (0.0497) teacher/usage_max 0.9199 (0.9184) teacher/usage_min 0.0328 (0.0223) teacher/usage_std 0.4148 (0.4142) nleep/row_max_mean 1500.5292 (1500.3123) nleep/row_max_std 62.5553 (63.1104) nleep/row_min_mean 1473.2854 (1468.6409) lr 4.8943e-05 eta 0:00:59
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,363
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 87.6%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [48/50] batch [20/203] time 0.091 (0.106) data 0.000 (0.014) loss 1.2844 (1.2939) teacher_loss 0.5103 (0.4686) loss_zs_kd 0.0250 (0.0230) loss_oracle 0.4106 (0.4654) kd_loss 0.5563 (0.5811) acc 81.2500 (82.5000) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0220 (0.0520) teacher/usage_max 0.9767 (0.9214) teacher/usage_min 0.0006 (0.0238) teacher/usage_std 0.4550 (0.4161) nleep/row_max_mean 1508.2742 (1499.9993) nleep/row_max_std 57.1938 (60.4245) nleep/row_min_mean 1475.8154 (1468.7696) lr 3.1417e-05 eta 0:01:02
epoch [48/50] batch [40/203] time 0.096 (0.101) data 0.000 (0.007) loss 1.2913 (1.2613) teacher_loss 0.4688 (0.4440) loss_zs_kd 0.0138 (0.0229) loss_oracle 0.5071 (0.4628) kd_loss 0.5621 (0.5745) acc 78.1250 (82.5000) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0314 (0.0560) teacher/usage_max 0.9613 (0.9240) teacher/usage_min 0.0004 (0.0217) teacher/usage_std 0.4443 (0.4180) nleep/row_max_mean 1501.2976 (1496.4854) nleep/row_max_std 75.5174 (65.4715) nleep/row_min_mean 1471.9478 (1465.6990) lr 3.1417e-05 eta 0:00:57
epoch [48/50] batch [60/203] time 0.094 (0.099) data 0.000 (0.005) loss 1.0777 (1.2488) teacher_loss 0.2742 (0.4299) loss_zs_kd 0.0223 (0.0232) loss_oracle 0.4808 (0.4561) kd_loss 0.5519 (0.5792) acc 87.5000 (83.1250) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0543 (0.0565) teacher/usage_max 0.9485 (0.9187) teacher/usage_min 0.0159 (0.0239) teacher/usage_std 0.4350 (0.4143) nleep/row_max_mean 1493.9453 (1497.0332) nleep/row_max_std 69.1094 (66.1539) nleep/row_min_mean 1464.9149 (1466.1807) lr 3.1417e-05 eta 0:00:54
epoch [48/50] batch [80/203] time 0.100 (0.100) data 0.000 (0.004) loss 1.3250 (1.2564) teacher_loss 0.4385 (0.4337) loss_zs_kd 0.0278 (0.0229) loss_oracle 0.5037 (0.4573) kd_loss 0.6208 (0.5826) acc 78.1250 (83.3594) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0641 (0.0551) teacher/usage_max 0.8689 (0.9167) teacher/usage_min 0.0432 (0.0225) teacher/usage_std 0.3791 (0.4130) nleep/row_max_mean 1489.0591 (1496.5958) nleep/row_max_std 66.0681 (66.9270) nleep/row_min_mean 1455.9910 (1465.5771) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [100/203] time 0.092 (0.100) data 0.000 (0.003) loss 1.3930 (1.2651) teacher_loss 0.5297 (0.4399) loss_zs_kd 0.0261 (0.0227) loss_oracle 0.4999 (0.4580) kd_loss 0.6003 (0.5848) acc 75.0000 (83.3125) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0225 (0.0551) teacher/usage_max 0.9317 (0.9144) teacher/usage_min 0.0332 (0.0231) teacher/usage_std 0.4231 (0.4114) nleep/row_max_mean 1505.0388 (1497.0474) nleep/row_max_std 58.5143 (66.2267) nleep/row_min_mean 1472.4551 (1466.0704) lr 3.1417e-05 eta 0:00:50
epoch [48/50] batch [120/203] time 0.102 (0.099) data 0.000 (0.003) loss 1.1889 (1.2623) teacher_loss 0.3479 (0.4376) loss_zs_kd 0.0069 (0.0225) loss_oracle 0.5169 (0.4605) kd_loss 0.5792 (0.5832) acc 87.5000 (83.0990) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0700 (0.0551) teacher/usage_max 0.9050 (0.9160) teacher/usage_min 0.0355 (0.0230) teacher/usage_std 0.4044 (0.4125) nleep/row_max_mean 1496.7825 (1497.1454) nleep/row_max_std 63.3078 (65.9368) nleep/row_min_mean 1467.8712 (1466.1763) lr 3.1417e-05 eta 0:00:48
epoch [48/50] batch [140/203] time 0.094 (0.098) data 0.000 (0.002) loss 1.2911 (1.2653) teacher_loss 0.4723 (0.4376) loss_zs_kd 0.0244 (0.0225) loss_oracle 0.4271 (0.4625) kd_loss 0.5930 (0.5852) acc 87.5000 (83.1696) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0711 (0.0558) teacher/usage_max 0.8901 (0.9133) teacher/usage_min 0.0470 (0.0245) teacher/usage_std 0.3937 (0.4106) nleep/row_max_mean 1506.4437 (1497.4960) nleep/row_max_std 56.7606 (65.2903) nleep/row_min_mean 1476.2263 (1466.6003) lr 3.1417e-05 eta 0:00:46
epoch [48/50] batch [160/203] time 0.107 (0.098) data 0.000 (0.002) loss 1.2112 (1.2615) teacher_loss 0.3303 (0.4349) loss_zs_kd 0.0141 (0.0224) loss_oracle 0.5054 (0.4614) kd_loss 0.6211 (0.5846) acc 87.5000 (83.3008) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0441 (0.0546) teacher/usage_max 0.8888 (0.9151) teacher/usage_min 0.0331 (0.0244) teacher/usage_std 0.3932 (0.4118) nleep/row_max_mean 1500.5823 (1497.8081) nleep/row_max_std 74.0855 (65.1465) nleep/row_min_mean 1467.6655 (1466.8300) lr 3.1417e-05 eta 0:00:44
epoch [48/50] batch [180/203] time 0.096 (0.099) data 0.000 (0.002) loss 1.0893 (1.2627) teacher_loss 0.2629 (0.4381) loss_zs_kd 0.0307 (0.0230) loss_oracle 0.4306 (0.4610) kd_loss 0.5958 (0.5826) acc 93.7500 (83.0729) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0523 (0.0547) teacher/usage_max 0.9061 (0.9171) teacher/usage_min 0.0450 (0.0240) teacher/usage_std 0.4050 (0.4132) nleep/row_max_mean 1491.2532 (1497.8413) nleep/row_max_std 70.5777 (65.1516) nleep/row_min_mean 1459.0825 (1466.7863) lr 3.1417e-05 eta 0:00:42
epoch [48/50] batch [200/203] time 0.085 (0.098) data 0.000 (0.002) loss 1.3282 (1.2595) teacher_loss 0.4145 (0.4346) loss_zs_kd 0.0144 (0.0227) loss_oracle 0.5197 (0.4615) kd_loss 0.6466 (0.5828) acc 81.2500 (83.0938) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0513 (0.0552) teacher/usage_max 0.8559 (0.9163) teacher/usage_min 0.0373 (0.0239) teacher/usage_std 0.3706 (0.4127) nleep/row_max_mean 1503.5540 (1498.2082) nleep/row_max_std 52.2439 (64.9684) nleep/row_min_mean 1473.1892 (1467.1593) lr 3.1417e-05 eta 0:00:40
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,363
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 87.6%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [49/50] batch [20/203] time 0.087 (0.110) data 0.000 (0.014) loss 1.2592 (1.2839) teacher_loss 0.4403 (0.4412) loss_zs_kd 0.0137 (0.0241) loss_oracle 0.4570 (0.4667) kd_loss 0.5835 (0.5973) acc 90.6250 (82.6562) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0031 (0.0453) teacher/usage_max 0.9682 (0.9117) teacher/usage_min 0.0000 (0.0209) teacher/usage_std 0.4491 (0.4098) nleep/row_max_mean 1502.5273 (1504.0907) nleep/row_max_std 65.2742 (59.3813) nleep/row_min_mean 1469.1310 (1471.6778) lr 1.7713e-05 eta 0:00:42
epoch [49/50] batch [40/203] time 0.097 (0.100) data 0.000 (0.007) loss 1.3318 (1.2904) teacher_loss 0.4937 (0.4449) loss_zs_kd 0.0160 (0.0226) loss_oracle 0.5063 (0.4679) kd_loss 0.5770 (0.6003) acc 78.1250 (82.6562) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0972 (0.0488) teacher/usage_max 0.8800 (0.9052) teacher/usage_min 0.0559 (0.0252) teacher/usage_std 0.3865 (0.4050) nleep/row_max_mean 1475.0636 (1500.9839) nleep/row_max_std 79.7487 (61.8446) nleep/row_min_mean 1448.9369 (1469.4987) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [60/203] time 0.090 (0.097) data 0.001 (0.005) loss 1.2800 (1.2659) teacher_loss 0.3561 (0.4270) loss_zs_kd 0.0263 (0.0217) loss_oracle 0.5577 (0.4674) kd_loss 0.6319 (0.5944) acc 93.7500 (83.8021) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0511 (0.0489) teacher/usage_max 0.8709 (0.9111) teacher/usage_min 0.0474 (0.0259) teacher/usage_std 0.3804 (0.4090) nleep/row_max_mean 1497.8298 (1501.2232) nleep/row_max_std 76.0154 (62.3052) nleep/row_min_mean 1465.0940 (1469.4167) lr 1.7713e-05 eta 0:00:33
epoch [49/50] batch [80/203] time 0.100 (0.096) data 0.000 (0.004) loss 1.4866 (1.2817) teacher_loss 0.5798 (0.4382) loss_zs_kd 0.0195 (0.0213) loss_oracle 0.5701 (0.4689) kd_loss 0.6120 (0.5984) acc 84.3750 (83.2031) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0464 (0.0478) teacher/usage_max 0.8957 (0.9081) teacher/usage_min 0.0268 (0.0267) teacher/usage_std 0.3982 (0.4069) nleep/row_max_mean 1501.9822 (1501.0197) nleep/row_max_std 71.9088 (62.2072) nleep/row_min_mean 1472.6613 (1469.4882) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [100/203] time 0.093 (0.096) data 0.000 (0.003) loss 1.0428 (1.2754) teacher_loss 0.2685 (0.4355) loss_zs_kd 0.0027 (0.0216) loss_oracle 0.4469 (0.4692) kd_loss 0.5495 (0.5946) acc 93.7500 (83.4375) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0507 (0.0496) teacher/usage_max 0.9548 (0.9101) teacher/usage_min 0.0004 (0.0263) teacher/usage_std 0.4398 (0.4084) nleep/row_max_mean 1464.5854 (1501.0196) nleep/row_max_std 88.8465 (62.5922) nleep/row_min_mean 1439.4226 (1469.6344) lr 1.7713e-05 eta 0:00:29
epoch [49/50] batch [120/203] time 0.090 (0.095) data 0.000 (0.002) loss 1.1763 (1.2814) teacher_loss 0.4371 (0.4434) loss_zs_kd 0.0197 (0.0213) loss_oracle 0.4039 (0.4694) kd_loss 0.5275 (0.5926) acc 87.5000 (83.3333) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0497 (0.0520) teacher/usage_max 0.9780 (0.9097) teacher/usage_min 0.0018 (0.0269) teacher/usage_std 0.4559 (0.4080) nleep/row_max_mean 1494.7908 (1499.7384) nleep/row_max_std 66.0829 (63.4399) nleep/row_min_mean 1463.8801 (1468.5504) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [140/203] time 0.099 (0.096) data 0.000 (0.002) loss 1.0510 (1.2724) teacher_loss 0.2330 (0.4379) loss_zs_kd 0.0150 (0.0210) loss_oracle 0.4630 (0.4657) kd_loss 0.5790 (0.5912) acc 87.5000 (83.5491) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0625 (0.0511) teacher/usage_max 0.9128 (0.9120) teacher/usage_min 0.0406 (0.0262) teacher/usage_std 0.4098 (0.4096) nleep/row_max_mean 1478.0441 (1499.1986) nleep/row_max_std 75.3339 (63.4212) nleep/row_min_mean 1451.0927 (1468.0477) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [160/203] time 0.088 (0.097) data 0.000 (0.002) loss 1.2757 (1.2707) teacher_loss 0.5055 (0.4362) loss_zs_kd 0.0220 (0.0211) loss_oracle 0.4223 (0.4660) kd_loss 0.5481 (0.5909) acc 84.3750 (83.5547) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0217 (0.0509) teacher/usage_max 0.9853 (0.9125) teacher/usage_min 0.0000 (0.0262) teacher/usage_std 0.4610 (0.4100) nleep/row_max_mean 1506.7280 (1499.2307) nleep/row_max_std 62.9483 (63.4663) nleep/row_min_mean 1470.7324 (1468.0092) lr 1.7713e-05 eta 0:00:23
epoch [49/50] batch [180/203] time 0.102 (0.097) data 0.000 (0.002) loss 1.0072 (1.2725) teacher_loss 0.2757 (0.4386) loss_zs_kd 0.0072 (0.0211) loss_oracle 0.4200 (0.4651) kd_loss 0.5179 (0.5908) acc 93.7500 (83.4896) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5741 (0.5740) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0515 (0.0512) teacher/usage_max 0.9855 (0.9123) teacher/usage_min 0.0059 (0.0267) teacher/usage_std 0.4612 (0.4098) nleep/row_max_mean 1511.8677 (1499.4038) nleep/row_max_std 53.7327 (63.2829) nleep/row_min_mean 1482.1134 (1468.2173) lr 1.7713e-05 eta 0:00:21
epoch [49/50] batch [200/203] time 0.089 (0.097) data 0.000 (0.002) loss 1.2244 (1.2708) teacher_loss 0.4363 (0.4381) loss_zs_kd 0.0168 (0.0211) loss_oracle 0.4069 (0.4638) kd_loss 0.5762 (0.5903) acc 81.2500 (83.6094) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0844 (0.0519) teacher/usage_max 0.8934 (0.9121) teacher/usage_min 0.0467 (0.0265) teacher/usage_std 0.3961 (0.4097) nleep/row_max_mean 1496.0781 (1498.9169) nleep/row_max_std 59.3038 (63.3810) nleep/row_min_mean 1468.5513 (1467.8223) lr 1.7713e-05 eta 0:00:19
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,362
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 87.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.5%, epoch: 36 *******
******* Domain c best val test acc: 99.9%, epoch: 36 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [50/50] batch [20/203] time 0.106 (0.116) data 0.000 (0.014) loss 1.2626 (1.2767) teacher_loss 0.5193 (0.4532) loss_zs_kd 0.0251 (0.0228) loss_oracle 0.3917 (0.4689) kd_loss 0.5349 (0.5777) acc 81.2500 (83.5938) gate/entropy 0.9774 (0.9774) gate/usage_max 0.5741 (0.5740) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0420 (0.0565) teacher/usage_max 0.9780 (0.9202) teacher/usage_min 0.0021 (0.0255) teacher/usage_std 0.4559 (0.4153) nleep/row_max_mean 1480.0193 (1499.6702) nleep/row_max_std 89.0774 (58.4698) nleep/row_min_mean 1451.7019 (1469.2256) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [40/203] time 0.095 (0.105) data 0.000 (0.007) loss 1.0802 (1.2561) teacher_loss 0.2154 (0.4333) loss_zs_kd 0.0131 (0.0233) loss_oracle 0.4760 (0.4553) kd_loss 0.6202 (0.5835) acc 93.7500 (83.3594) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0421 (0.0596) teacher/usage_max 0.8918 (0.9112) teacher/usage_min 0.0459 (0.0232) teacher/usage_std 0.3949 (0.4092) nleep/row_max_mean 1496.7505 (1497.3590) nleep/row_max_std 65.4426 (60.9520) nleep/row_min_mean 1468.4095 (1466.9073) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [60/203] time 0.139 (0.102) data 0.003 (0.005) loss 1.1222 (1.2588) teacher_loss 0.3294 (0.4272) loss_zs_kd 0.0298 (0.0229) loss_oracle 0.4341 (0.4602) kd_loss 0.5608 (0.5900) acc 84.3750 (83.6458) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0452 (0.0527) teacher/usage_max 0.9487 (0.9116) teacher/usage_min 0.0027 (0.0215) teacher/usage_std 0.4355 (0.4096) nleep/row_max_mean 1482.6963 (1495.8040) nleep/row_max_std 80.0490 (63.0154) nleep/row_min_mean 1451.9707 (1465.1489) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [80/203] time 0.097 (0.102) data 0.000 (0.004) loss 1.3146 (1.2520) teacher_loss 0.4789 (0.4184) loss_zs_kd 0.0236 (0.0222) loss_oracle 0.4834 (0.4624) kd_loss 0.5823 (0.5912) acc 84.3750 (83.9844) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0618 (0.0509) teacher/usage_max 0.9101 (0.9121) teacher/usage_min 0.0021 (0.0216) teacher/usage_std 0.4093 (0.4099) nleep/row_max_mean 1490.7075 (1497.0898) nleep/row_max_std 86.3390 (63.1179) nleep/row_min_mean 1457.4948 (1465.9431) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [100/203] time 0.099 (0.101) data 0.000 (0.003) loss 1.1690 (1.2391) teacher_loss 0.3991 (0.4074) loss_zs_kd 0.0139 (0.0223) loss_oracle 0.3711 (0.4618) kd_loss 0.5774 (0.5897) acc 81.2500 (84.1875) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0532 (0.0518) teacher/usage_max 0.9238 (0.9128) teacher/usage_min 0.0101 (0.0220) teacher/usage_std 0.4182 (0.4104) nleep/row_max_mean 1492.3134 (1497.4925) nleep/row_max_std 61.0211 (62.5492) nleep/row_min_mean 1462.6909 (1466.3857) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [120/203] time 0.087 (0.100) data 0.000 (0.003) loss 1.0953 (1.2422) teacher_loss 0.1795 (0.4101) loss_zs_kd 0.0151 (0.0224) loss_oracle 0.5585 (0.4619) kd_loss 0.6291 (0.5899) acc 93.7500 (84.3750) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0824 (0.0548) teacher/usage_max 0.8424 (0.9095) teacher/usage_min 0.0313 (0.0238) teacher/usage_std 0.3620 (0.4081) nleep/row_max_mean 1459.3315 (1497.0174) nleep/row_max_std 89.6171 (62.5265) nleep/row_min_mean 1433.0826 (1466.2221) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [140/203] time 0.096 (0.100) data 0.000 (0.002) loss 1.0554 (1.2456) teacher_loss 0.2736 (0.4128) loss_zs_kd 0.0212 (0.0226) loss_oracle 0.4480 (0.4620) kd_loss 0.5472 (0.5904) acc 90.6250 (84.2634) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0544 (0.0544) teacher/usage_max 0.9530 (0.9095) teacher/usage_min 0.0037 (0.0240) teacher/usage_std 0.4385 (0.4080) nleep/row_max_mean 1483.7473 (1496.9000) nleep/row_max_std 82.1007 (62.3957) nleep/row_min_mean 1456.1270 (1466.1491) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [160/203] time 0.103 (0.099) data 0.000 (0.002) loss 1.2402 (1.2486) teacher_loss 0.4581 (0.4162) loss_zs_kd 0.0079 (0.0225) loss_oracle 0.5119 (0.4626) kd_loss 0.5222 (0.5899) acc 87.5000 (84.3164) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.1030 (0.0547) teacher/usage_max 0.9293 (0.9097) teacher/usage_min 0.0274 (0.0242) teacher/usage_std 0.4215 (0.4082) nleep/row_max_mean 1496.1836 (1496.4497) nleep/row_max_std 68.9472 (63.0068) nleep/row_min_mean 1467.1826 (1465.7756) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [180/203] time 0.095 (0.099) data 0.000 (0.002) loss 1.0646 (1.2553) teacher_loss 0.2933 (0.4232) loss_zs_kd 0.0265 (0.0230) loss_oracle 0.4481 (0.4638) kd_loss 0.5340 (0.5887) acc 87.5000 (83.9583) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0390 (0.0550) teacher/usage_max 0.9821 (0.9106) teacher/usage_min 0.0019 (0.0249) teacher/usage_std 0.4588 (0.4087) nleep/row_max_mean 1486.4751 (1496.3621) nleep/row_max_std 68.9809 (63.0439) nleep/row_min_mean 1458.6726 (1465.6928) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [200/203] time 0.092 (0.098) data 0.000 (0.002) loss 1.3350 (1.2549) teacher_loss 0.5494 (0.4237) loss_zs_kd 0.0240 (0.0228) loss_oracle 0.4234 (0.4642) kd_loss 0.5619 (0.5876) acc 81.2500 (84.0469) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0340 (0.0546) teacher/usage_max 0.9588 (0.9120) teacher/usage_min 0.0100 (0.0245) teacher/usage_std 0.4423 (0.4098) nleep/row_max_mean 1487.6152 (1496.0541) nleep/row_max_std 81.5212 (63.3211) nleep/row_min_mean 1456.5049 (1465.3786) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,365
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 87.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      84.6%, epoch: 50 *******
******* Domain c best val test acc: 99.9%, epoch: 50 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_2/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:19:51

Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'pascal']
Target     ['sun']
# classes  5
# train_x  5,213
# val      2,234
# test     3,282
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/tensorboard)
epoch [1/50] batch [20/162] time 0.083 (0.114) data 0.000 (0.020) loss 1.0466 (1.3670) teacher_loss 0.4749 (0.6573) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0006 (0.0001) kd_loss 0.5714 (0.7096) acc 81.2500 (76.8750) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3382 (0.3383) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0035 (0.0036) teacher/entropy 0.5268 (0.3902) teacher/usage_max 0.3738 (0.4554) teacher/usage_min 0.2724 (0.2387) teacher/usage_std 0.0439 (0.0929) nleep/row_max_mean 1540.1711 (1520.2693) nleep/row_max_std 53.4100 (72.5953) nleep/row_min_mean 1535.4646 (1509.3540) lr 1.0000e-05 eta 0:15:23
epoch [1/50] batch [40/162] time 0.107 (0.103) data 0.000 (0.010) loss 1.4169 (1.2599) teacher_loss 0.8858 (0.6384) loss_zs_kd 0.0006 (0.0001) loss_oracle 0.0031 (0.0010) kd_loss 0.5292 (0.6209) acc 68.7500 (78.3594) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0035 (0.0036) teacher/entropy 0.5685 (0.4785) teacher/usage_max 0.4285 (0.4375) teacher/usage_min 0.1703 (0.2430) teacher/usage_std 0.1158 (0.0829) nleep/row_max_mean 1539.7244 (1529.7519) nleep/row_max_std 45.7999 (60.4025) nleep/row_min_mean 1535.5527 (1522.0863) lr 1.0000e-05 eta 0:13:52
epoch [1/50] batch [60/162] time 0.086 (0.101) data 0.000 (0.007) loss 1.0806 (1.1709) teacher_loss 0.6257 (0.6091) loss_zs_kd 0.0015 (0.0003) loss_oracle 0.0072 (0.0025) kd_loss 0.4506 (0.5605) acc 78.1250 (79.5312) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0035 (0.0036) teacher/entropy 0.6497 (0.5387) teacher/usage_max 0.4792 (0.4276) teacher/usage_min 0.2358 (0.2483) teacher/usage_std 0.1051 (0.0764) nleep/row_max_mean 1552.6473 (1534.8318) nleep/row_max_std 46.4664 (55.5469) nleep/row_min_mean 1549.5129 (1528.6460) lr 1.0000e-05 eta 0:13:30
epoch [1/50] batch [80/162] time 0.086 (0.098) data 0.000 (0.005) loss 0.6913 (1.1013) teacher_loss 0.4043 (0.5926) loss_zs_kd 0.0005 (0.0005) loss_oracle 0.0105 (0.0040) kd_loss 0.2815 (0.5065) acc 87.5000 (79.9609) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0036 (0.0035) teacher/entropy 0.8164 (0.5924) teacher/usage_max 0.3893 (0.4249) teacher/usage_min 0.2251 (0.2442) teacher/usage_std 0.0765 (0.0768) nleep/row_max_mean 1544.4521 (1536.1907) nleep/row_max_std 48.5396 (52.5338) nleep/row_min_mean 1542.4586 (1530.9404) lr 1.0000e-05 eta 0:13:06
epoch [1/50] batch [100/162] time 0.087 (0.095) data 0.000 (0.004) loss 0.7748 (1.0579) teacher_loss 0.5447 (0.5915) loss_zs_kd 0.0037 (0.0008) loss_oracle 0.0160 (0.0055) kd_loss 0.2202 (0.4632) acc 87.5000 (79.9375) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3302 (0.3303) gate/usage_std 0.0036 (0.0035) teacher/entropy 0.8782 (0.6356) teacher/usage_max 0.3593 (0.4233) teacher/usage_min 0.2818 (0.2418) teacher/usage_std 0.0365 (0.0773) nleep/row_max_mean 1531.2593 (1536.3113) nleep/row_max_std 37.4613 (51.0170) nleep/row_min_mean 1529.4810 (1531.7080) lr 1.0000e-05 eta 0:12:38
epoch [1/50] batch [120/162] time 0.149 (0.094) data 0.002 (0.004) loss 1.0138 (1.0148) teacher_loss 0.7762 (0.5849) loss_zs_kd 0.0047 (0.0011) loss_oracle 0.0140 (0.0073) kd_loss 0.2282 (0.4257) acc 62.5000 (79.7135) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3385 (0.3383) gate/usage_min 0.3301 (0.3303) gate/usage_std 0.0037 (0.0035) teacher/entropy 0.8721 (0.6731) teacher/usage_max 0.4689 (0.4230) teacher/usage_min 0.2378 (0.2404) teacher/usage_std 0.0985 (0.0779) nleep/row_max_mean 1506.9087 (1535.4654) nleep/row_max_std 50.4958 (50.6543) nleep/row_min_mean 1505.1187 (1531.3492) lr 1.0000e-05 eta 0:12:30
epoch [1/50] batch [140/162] time 0.082 (0.094) data 0.000 (0.003) loss 0.7238 (0.9750) teacher_loss 0.4994 (0.5781) loss_zs_kd 0.0067 (0.0013) loss_oracle 0.0208 (0.0088) kd_loss 0.2106 (0.3918) acc 81.2500 (79.9107) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3382 (0.3383) gate/usage_min 0.3305 (0.3303) gate/usage_std 0.0034 (0.0035) teacher/entropy 0.8874 (0.7069) teacher/usage_max 0.3889 (0.4211) teacher/usage_min 0.2381 (0.2398) teacher/usage_std 0.0677 (0.0773) nleep/row_max_mean 1537.7317 (1533.9319) nleep/row_max_std 49.3537 (50.3652) nleep/row_min_mean 1536.1545 (1530.2002) lr 1.0000e-05 eta 0:12:24
epoch [1/50] batch [160/162] time 0.083 (0.092) data 0.000 (0.003) loss 0.9337 (0.9415) teacher_loss 0.7565 (0.5676) loss_zs_kd 0.0045 (0.0016) loss_oracle 0.0230 (0.0102) kd_loss 0.1634 (0.3680) acc 75.0000 (80.3320) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0035 (0.0035) teacher/entropy 0.9353 (0.7305) teacher/usage_max 0.4247 (0.4207) teacher/usage_min 0.2267 (0.2375) teacher/usage_std 0.0815 (0.0782) nleep/row_max_mean 1531.4612 (1533.4511) nleep/row_max_std 52.1353 (50.5440) nleep/row_min_mean 1530.1165 (1529.9999) lr 1.0000e-05 eta 0:12:11
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,905
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 87.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,328
* accuracy: 70.9%
* error: 29.1%
* macro_f1: 66.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      85.3%, epoch: 1 *******
******* Domain s best val test acc: 70.9%, epoch: 1 *******
******* Domain s best test acc:     70.9%, epoch: 1 *******
epoch [2/50] batch [20/162] time 0.097 (0.106) data 0.000 (0.013) loss 0.9430 (0.9159) teacher_loss 0.3643 (0.5228) loss_zs_kd 0.0342 (0.0179) loss_oracle 0.2895 (0.2348) kd_loss 0.4169 (0.2668) acc 87.5000 (83.5938) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3392 (0.3387) gate/usage_min 0.3302 (0.3304) gate/usage_std 0.0041 (0.0038) teacher/entropy 0.6802 (0.8311) teacher/usage_max 0.4317 (0.4354) teacher/usage_min 0.1712 (0.2065) teacher/usage_std 0.1155 (0.0970) nleep/row_max_mean 1548.2463 (1527.9042) nleep/row_max_std 43.4525 (49.2587) nleep/row_min_mean 1545.3226 (1526.0696) lr 2.0000e-03 eta 0:13:55
epoch [2/50] batch [40/162] time 0.101 (0.102) data 0.000 (0.007) loss 1.0410 (0.9322) teacher_loss 0.2056 (0.4326) loss_zs_kd 0.0267 (0.0291) loss_oracle 0.3438 (0.2591) kd_loss 0.6502 (0.3554) acc 96.8750 (87.4219) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3398 (0.3392) gate/usage_min 0.3295 (0.3301) gate/usage_std 0.0046 (0.0042) teacher/entropy 0.4490 (0.7430) teacher/usage_max 0.5183 (0.4371) teacher/usage_min 0.1787 (0.2252) teacher/usage_std 0.1403 (0.0903) nleep/row_max_mean 1541.5439 (1529.9373) nleep/row_max_std 54.2822 (50.7956) nleep/row_min_mean 1536.3901 (1527.3084) lr 2.0000e-03 eta 0:13:29
epoch [2/50] batch [60/162] time 0.097 (0.101) data 0.001 (0.005) loss 1.4517 (0.9896) teacher_loss 0.4875 (0.3815) loss_zs_kd 0.0462 (0.0330) loss_oracle 0.5985 (0.3110) kd_loss 0.6418 (0.4360) acc 87.5000 (89.4792) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3394 (0.3394) gate/usage_min 0.3294 (0.3298) gate/usage_std 0.0044 (0.0043) teacher/entropy 0.4619 (0.6631) teacher/usage_max 0.4658 (0.4417) teacher/usage_min 0.1704 (0.2283) teacher/usage_std 0.1225 (0.0913) nleep/row_max_mean 1517.4646 (1528.9024) nleep/row_max_std 52.9909 (52.9579) nleep/row_min_mean 1511.5801 (1525.3668) lr 2.0000e-03 eta 0:13:13
epoch [2/50] batch [80/162] time 0.093 (0.099) data 0.000 (0.004) loss 1.1724 (1.0359) teacher_loss 0.0953 (0.3410) loss_zs_kd 0.0584 (0.0361) loss_oracle 0.3987 (0.3333) kd_loss 0.8486 (0.5101) acc 96.8750 (91.0156) gate/entropy 1.0986 (1.0985) gate/usage_max 0.3373 (0.3391) gate/usage_min 0.3311 (0.3299) gate/usage_std 0.0028 (0.0041) teacher/entropy 0.2538 (0.5900) teacher/usage_max 0.4491 (0.4525) teacher/usage_min 0.1174 (0.2072) teacher/usage_std 0.1528 (0.1051) nleep/row_max_mean 1533.1448 (1530.2998) nleep/row_max_std 62.5574 (53.5799) nleep/row_min_mean 1523.2317 (1525.6347) lr 2.0000e-03 eta 0:12:55
epoch [2/50] batch [100/162] time 0.094 (0.098) data 0.000 (0.003) loss 1.3789 (1.0929) teacher_loss 0.1493 (0.3065) loss_zs_kd 0.0469 (0.0423) loss_oracle 0.5665 (0.3653) kd_loss 0.9229 (0.5826) acc 96.8750 (92.1250) gate/entropy 1.0986 (1.0985) gate/usage_max 0.3345 (0.3384) gate/usage_min 0.3325 (0.3303) gate/usage_std 0.0008 (0.0036) teacher/entropy 0.1772 (0.5177) teacher/usage_max 0.4703 (0.4624) teacher/usage_min 0.0648 (0.1830) teacher/usage_std 0.1899 (0.1201) nleep/row_max_mean 1540.0433 (1530.3268) nleep/row_max_std 62.2215 (54.5338) nleep/row_min_mean 1529.0376 (1524.6539) lr 2.0000e-03 eta 0:12:50
epoch [2/50] batch [120/162] time 0.092 (0.100) data 0.000 (0.002) loss 1.4689 (1.1602) teacher_loss 0.1734 (0.2854) loss_zs_kd 0.0500 (0.0452) loss_oracle 0.5921 (0.4129) kd_loss 0.9744 (0.6458) acc 93.7500 (92.6042) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3377) gate/usage_min 0.3309 (0.3306) gate/usage_std 0.0017 (0.0032) teacher/entropy 0.1207 (0.4542) teacher/usage_max 0.5198 (0.4747) teacher/usage_min 0.0233 (0.1597) teacher/usage_std 0.2207 (0.1355) nleep/row_max_mean 1519.4092 (1530.5267) nleep/row_max_std 57.6137 (54.8341) nleep/row_min_mean 1507.5839 (1523.7850) lr 2.0000e-03 eta 0:13:02
epoch [2/50] batch [140/162] time 0.100 (0.100) data 0.001 (0.002) loss 1.4694 (1.2080) teacher_loss 0.1517 (0.2681) loss_zs_kd 0.0421 (0.0453) loss_oracle 0.5732 (0.4434) kd_loss 1.0100 (0.6955) acc 93.7500 (92.9464) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3368 (0.3374) gate/usage_min 0.3266 (0.3304) gate/usage_std 0.0047 (0.0032) teacher/entropy 0.0788 (0.4033) teacher/usage_max 0.5170 (0.4881) teacher/usage_min 0.0098 (0.1397) teacher/usage_std 0.2295 (0.1496) nleep/row_max_mean 1520.9011 (1530.1969) nleep/row_max_std 63.7599 (55.4697) nleep/row_min_mean 1507.4993 (1522.4785) lr 2.0000e-03 eta 0:12:57
epoch [2/50] batch [160/162] time 0.076 (0.099) data 0.000 (0.002) loss 1.6010 (1.2513) teacher_loss 0.2143 (0.2601) loss_zs_kd 0.0530 (0.0460) loss_oracle 0.6354 (0.4670) kd_loss 1.0425 (0.7347) acc 93.7500 (93.2031) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3393 (0.3375) gate/usage_min 0.3222 (0.3296) gate/usage_std 0.0079 (0.0036) teacher/entropy 0.0393 (0.3624) teacher/usage_max 0.6544 (0.4973) teacher/usage_min 0.0050 (0.1228) teacher/usage_std 0.2652 (0.1609) nleep/row_max_mean 1519.4313 (1529.9958) nleep/row_max_std 68.8810 (56.1390) nleep/row_min_mean 1504.0122 (1521.3331) lr 2.0000e-03 eta 0:12:46
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,933
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 88.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,362
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 71.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      86.5%, epoch: 2 *******
******* Domain s best val test acc: 72.0%, epoch: 2 *******
******* Domain s best test acc:     72.0%, epoch: 2 *******
epoch [3/50] batch [20/162] time 0.087 (0.115) data 0.001 (0.017) loss 1.4868 (1.5875) teacher_loss 0.1974 (0.2229) loss_zs_kd 0.0373 (0.0526) loss_oracle 0.6031 (0.6858) kd_loss 0.9692 (0.9954) acc 96.8750 (94.3750) gate/entropy 1.0980 (1.0982) gate/usage_max 0.3422 (0.3409) gate/usage_min 0.3176 (0.3196) gate/usage_std 0.0111 (0.0097) teacher/entropy 0.1053 (0.0826) teacher/usage_max 0.6112 (0.5782) teacher/usage_min 0.0014 (0.0008) teacher/usage_std 0.2519 (0.2490) nleep/row_max_mean 1515.2501 (1527.4717) nleep/row_max_std 62.3316 (61.0021) nleep/row_min_mean 1498.6824 (1510.8487) lr 1.9980e-03 eta 0:14:55
epoch [3/50] batch [40/162] time 0.086 (0.103) data 0.000 (0.008) loss 1.5396 (1.5665) teacher_loss 0.1408 (0.2123) loss_zs_kd 0.0658 (0.0478) loss_oracle 0.6749 (0.6690) kd_loss 1.0285 (0.9958) acc 96.8750 (94.2188) gate/entropy 1.0977 (1.0980) gate/usage_max 0.3448 (0.3422) gate/usage_min 0.3131 (0.3174) gate/usage_std 0.0143 (0.0113) teacher/entropy 0.0387 (0.0788) teacher/usage_max 0.6954 (0.5830) teacher/usage_min 0.0002 (0.0005) teacher/usage_std 0.2845 (0.2494) nleep/row_max_mean 1525.7864 (1527.4147) nleep/row_max_std 59.8839 (59.8384) nleep/row_min_mean 1506.4650 (1509.8534) lr 1.9980e-03 eta 0:13:13
epoch [3/50] batch [60/162] time 0.093 (0.099) data 0.000 (0.006) loss 1.6047 (1.5430) teacher_loss 0.1996 (0.1917) loss_zs_kd 0.0723 (0.0505) loss_oracle 0.6988 (0.6508) kd_loss 1.0195 (1.0007) acc 96.8750 (95.0521) gate/entropy 1.0972 (1.0978) gate/usage_max 0.3473 (0.3435) gate/usage_min 0.3090 (0.3153) gate/usage_std 0.0173 (0.0128) teacher/entropy 0.0436 (0.0708) teacher/usage_max 0.5285 (0.5829) teacher/usage_min 0.0002 (0.0004) teacher/usage_std 0.2367 (0.2495) nleep/row_max_mean 1537.9797 (1529.1846) nleep/row_max_std 53.4934 (58.1727) nleep/row_min_mean 1515.7173 (1510.8159) lr 1.9980e-03 eta 0:12:43
epoch [3/50] batch [80/162] time 0.091 (0.098) data 0.000 (0.004) loss 1.4288 (1.5432) teacher_loss 0.1053 (0.1922) loss_zs_kd 0.0486 (0.0531) loss_oracle 0.5709 (0.6362) kd_loss 1.0137 (1.0063) acc 96.8750 (94.8047) gate/entropy 1.0967 (1.0976) gate/usage_max 0.3493 (0.3447) gate/usage_min 0.3048 (0.3131) gate/usage_std 0.0202 (0.0143) teacher/entropy 0.0424 (0.0620) teacher/usage_max 0.5684 (0.5859) teacher/usage_min 0.0001 (0.0003) teacher/usage_std 0.2422 (0.2504) nleep/row_max_mean 1540.0447 (1529.4883) nleep/row_max_std 55.7604 (57.5172) nleep/row_min_mean 1519.3545 (1510.6210) lr 1.9980e-03 eta 0:12:33
epoch [3/50] batch [100/162] time 0.098 (0.097) data 0.000 (0.004) loss 1.4398 (1.5287) teacher_loss 0.1026 (0.1782) loss_zs_kd 0.0654 (0.0530) loss_oracle 0.5855 (0.6332) kd_loss 1.0117 (1.0074) acc 96.8750 (95.2188) gate/entropy 1.0962 (1.0974) gate/usage_max 0.3514 (0.3459) gate/usage_min 0.3008 (0.3111) gate/usage_std 0.0230 (0.0158) teacher/entropy 0.0386 (0.0580) teacher/usage_max 0.5544 (0.5840) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.2398 (0.2495) nleep/row_max_mean 1533.6191 (1529.3680) nleep/row_max_std 70.2671 (57.4946) nleep/row_min_mean 1512.2505 (1510.0641) lr 1.9980e-03 eta 0:12:24
epoch [3/50] batch [120/162] time 0.111 (0.097) data 0.001 (0.003) loss 1.4147 (1.5293) teacher_loss 0.0569 (0.1796) loss_zs_kd 0.0528 (0.0533) loss_oracle 0.6132 (0.6287) kd_loss 1.0248 (1.0087) acc 100.0000 (95.3125) gate/entropy 1.0955 (1.0971) gate/usage_max 0.3535 (0.3470) gate/usage_min 0.2968 (0.3090) gate/usage_std 0.0259 (0.0172) teacher/entropy 0.0211 (0.0536) teacher/usage_max 0.5909 (0.5824) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.2471 (0.2495) nleep/row_max_mean 1538.4601 (1528.8575) nleep/row_max_std 51.1946 (57.7195) nleep/row_min_mean 1513.3552 (1509.1336) lr 1.9980e-03 eta 0:12:20
epoch [3/50] batch [140/162] time 0.091 (0.098) data 0.000 (0.003) loss 1.3777 (1.5234) teacher_loss 0.0903 (0.1747) loss_zs_kd 0.0657 (0.0535) loss_oracle 0.5305 (0.6260) kd_loss 0.9893 (1.0089) acc 96.8750 (95.3571) gate/entropy 1.0949 (1.0969) gate/usage_max 0.3562 (0.3481) gate/usage_min 0.2933 (0.3070) gate/usage_std 0.0284 (0.0187) teacher/entropy 0.0520 (0.0506) teacher/usage_max 0.5833 (0.5807) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.2453 (0.2491) nleep/row_max_mean 1521.7220 (1528.9780) nleep/row_max_std 49.8158 (57.4255) nleep/row_min_mean 1499.4205 (1508.8718) lr 1.9980e-03 eta 0:12:28
epoch [3/50] batch [160/162] time 0.092 (0.098) data 0.001 (0.002) loss 1.6697 (1.5209) teacher_loss 0.3501 (0.1748) loss_zs_kd 0.0665 (0.0538) loss_oracle 0.6179 (0.6207) kd_loss 0.9775 (1.0088) acc 90.6250 (95.3906) gate/entropy 1.0942 (1.0966) gate/usage_max 0.3588 (0.3493) gate/usage_min 0.2897 (0.3050) gate/usage_std 0.0310 (0.0201) teacher/entropy 0.0560 (0.0479) teacher/usage_max 0.5901 (0.5804) teacher/usage_min 0.0004 (0.0003) teacher/usage_std 0.2467 (0.2490) nleep/row_max_mean 1499.9810 (1528.6315) nleep/row_max_std 61.6902 (57.4905) nleep/row_min_mean 1480.5686 (1508.2622) lr 1.9980e-03 eta 0:12:24
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,929
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,468
* accuracy: 75.2%
* error: 24.8%
* macro_f1: 73.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      86.5%, epoch: 2 *******
******* Domain s best val test acc: 72.0%, epoch: 2 *******
******* Domain s best test acc:     75.2%, epoch: 3 *******
epoch [4/50] batch [20/162] time 0.077 (0.100) data 0.000 (0.014) loss 1.5937 (1.4693) teacher_loss 0.2231 (0.1375) loss_zs_kd 0.0681 (0.0549) loss_oracle 0.6438 (0.5992) kd_loss 1.0147 (1.0047) acc 93.7500 (96.7188) gate/entropy 1.0933 (1.0937) gate/usage_max 0.3615 (0.3605) gate/usage_min 0.2857 (0.2873) gate/usage_std 0.0339 (0.0327) teacher/entropy 0.0094 (0.0264) teacher/usage_max 0.7200 (0.5697) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.2963 (0.2475) nleep/row_max_mean 1516.9142 (1522.2577) nleep/row_max_std 58.4138 (57.3079) nleep/row_min_mean 1494.2478 (1500.3791) lr 1.9921e-03 eta 0:12:38
epoch [4/50] batch [40/162] time 0.088 (0.093) data 0.000 (0.007) loss 1.3998 (1.4822) teacher_loss 0.0684 (0.1425) loss_zs_kd 0.0607 (0.0576) loss_oracle 0.6004 (0.6119) kd_loss 1.0008 (1.0050) acc 96.8750 (96.2500) gate/entropy 1.0925 (1.0933) gate/usage_max 0.3640 (0.3617) gate/usage_min 0.2821 (0.2855) gate/usage_std 0.0365 (0.0340) teacher/entropy 0.0281 (0.0237) teacher/usage_max 0.5286 (0.5768) teacher/usage_min 0.0237 (0.0008) teacher/usage_std 0.2214 (0.2486) nleep/row_max_mean 1523.7698 (1524.1736) nleep/row_max_std 50.5681 (56.0303) nleep/row_min_mean 1501.9929 (1501.7700) lr 1.9921e-03 eta 0:11:41
epoch [4/50] batch [60/162] time 0.079 (0.091) data 0.001 (0.005) loss 1.4008 (1.4947) teacher_loss 0.0706 (0.1440) loss_zs_kd 0.0576 (0.0586) loss_oracle 0.6268 (0.6335) kd_loss 0.9879 (1.0045) acc 96.8750 (96.1458) gate/entropy 1.0916 (1.0928) gate/usage_max 0.3661 (0.3628) gate/usage_min 0.2786 (0.2837) gate/usage_std 0.0389 (0.0353) teacher/entropy 0.0343 (0.0217) teacher/usage_max 0.5766 (0.5738) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.2438 (0.2476) nleep/row_max_mean 1534.3226 (1526.3695) nleep/row_max_std 56.7696 (56.4879) nleep/row_min_mean 1509.8433 (1503.4680) lr 1.9921e-03 eta 0:11:29
epoch [4/50] batch [80/162] time 0.087 (0.090) data 0.000 (0.004) loss 1.5177 (1.4898) teacher_loss 0.1557 (0.1409) loss_zs_kd 0.0636 (0.0564) loss_oracle 0.6773 (0.6359) kd_loss 0.9916 (1.0027) acc 93.7500 (96.0547) gate/entropy 1.0906 (1.0924) gate/usage_max 0.3682 (0.3639) gate/usage_min 0.2751 (0.2820) gate/usage_std 0.0415 (0.0365) teacher/entropy 0.0204 (0.0210) teacher/usage_max 0.5887 (0.5683) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.2466 (0.2459) nleep/row_max_mean 1516.1267 (1525.1786) nleep/row_max_std 66.2883 (57.4508) nleep/row_min_mean 1492.7015 (1502.1063) lr 1.9921e-03 eta 0:11:19
epoch [4/50] batch [100/162] time 0.076 (0.090) data 0.000 (0.003) loss 1.3968 (1.4946) teacher_loss 0.0387 (0.1420) loss_zs_kd 0.0543 (0.0571) loss_oracle 0.6627 (0.6445) kd_loss 0.9996 (1.0018) acc 100.0000 (96.0625) gate/entropy 1.0896 (1.0919) gate/usage_max 0.3703 (0.3650) gate/usage_min 0.2715 (0.2802) gate/usage_std 0.0440 (0.0378) teacher/entropy 0.0112 (0.0193) teacher/usage_max 0.5301 (0.5719) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.2370 (0.2470) nleep/row_max_mean 1517.6743 (1523.8740) nleep/row_max_std 57.8395 (58.2076) nleep/row_min_mean 1494.9612 (1500.5428) lr 1.9921e-03 eta 0:11:17
epoch [4/50] batch [120/162] time 0.087 (0.089) data 0.000 (0.002) loss 1.5438 (1.4970) teacher_loss 0.1531 (0.1466) loss_zs_kd 0.0710 (0.0569) loss_oracle 0.7053 (0.6426) kd_loss 1.0025 (1.0006) acc 96.8750 (95.9896) gate/entropy 1.0886 (1.0915) gate/usage_max 0.3721 (0.3661) gate/usage_min 0.2683 (0.2785) gate/usage_std 0.0462 (0.0390) teacher/entropy 0.0040 (0.0182) teacher/usage_max 0.5319 (0.5702) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.2371 (0.2467) nleep/row_max_mean 1523.5973 (1523.5653) nleep/row_max_std 68.8923 (59.0792) nleep/row_min_mean 1499.1692 (1500.0142) lr 1.9921e-03 eta 0:11:09
epoch [4/50] batch [140/162] time 0.079 (0.092) data 0.000 (0.002) loss 1.3595 (1.4898) teacher_loss 0.0288 (0.1450) loss_zs_kd 0.0686 (0.0564) loss_oracle 0.6314 (0.6379) kd_loss 0.9807 (0.9977) acc 100.0000 (96.0938) gate/entropy 1.0875 (1.0910) gate/usage_max 0.3741 (0.3671) gate/usage_min 0.2648 (0.2768) gate/usage_std 0.0487 (0.0402) teacher/entropy 0.0217 (0.0187) teacher/usage_max 0.5507 (0.5739) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.2393 (0.2476) nleep/row_max_mean 1532.7769 (1522.8770) nleep/row_max_std 50.6522 (59.9049) nleep/row_min_mean 1506.5120 (1499.2369) lr 1.9921e-03 eta 0:11:25
epoch [4/50] batch [160/162] time 0.084 (0.091) data 0.000 (0.002) loss 1.3402 (1.4822) teacher_loss 0.0483 (0.1432) loss_zs_kd 0.0616 (0.0567) loss_oracle 0.6192 (0.6328) kd_loss 0.9515 (0.9943) acc 100.0000 (96.2109) gate/entropy 1.0865 (1.0905) gate/usage_max 0.3757 (0.3680) gate/usage_min 0.2619 (0.2751) gate/usage_std 0.0508 (0.0414) teacher/entropy 0.0451 (0.0198) teacher/usage_max 0.5105 (0.5729) teacher/usage_min 0.0001 (0.0005) teacher/usage_std 0.2358 (0.2474) nleep/row_max_mean 1516.6790 (1522.2372) nleep/row_max_std 69.4235 (60.9477) nleep/row_min_mean 1493.1565 (1498.5780) lr 1.9921e-03 eta 0:11:20
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,896
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 87.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,625
* accuracy: 80.0%
* error: 20.0%
* macro_f1: 74.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      86.5%, epoch: 2 *******
******* Domain s best val test acc: 72.0%, epoch: 2 *******
******* Domain s best test acc:     80.0%, epoch: 4 *******
epoch [5/50] batch [20/162] time 0.094 (0.103) data 0.000 (0.014) loss 1.3944 (1.4353) teacher_loss 0.0423 (0.1378) loss_zs_kd 0.0757 (0.0643) loss_oracle 0.7033 (0.6052) kd_loss 0.9626 (0.9627) acc 100.0000 (96.4062) gate/entropy 1.0855 (1.0859) gate/usage_max 0.3772 (0.3767) gate/usage_min 0.2589 (0.2602) gate/usage_std 0.0529 (0.0520) teacher/entropy 0.0365 (0.0331) teacher/usage_max 0.6793 (0.5633) teacher/usage_min 0.0001 (0.0002) teacher/usage_std 0.2774 (0.2440) nleep/row_max_mean 1528.3517 (1517.9407) nleep/row_max_std 64.9333 (65.9980) nleep/row_min_mean 1502.1387 (1493.7926) lr 1.9823e-03 eta 0:12:45
epoch [5/50] batch [40/162] time 0.091 (0.098) data 0.000 (0.007) loss 1.3538 (1.3906) teacher_loss 0.1234 (0.1135) loss_zs_kd 0.0550 (0.0610) loss_oracle 0.4937 (0.5859) kd_loss 0.9560 (0.9536) acc 96.8750 (97.1094) gate/entropy 1.0844 (1.0854) gate/usage_max 0.3784 (0.3773) gate/usage_min 0.2559 (0.2588) gate/usage_std 0.0550 (0.0530) teacher/entropy 0.0339 (0.0399) teacher/usage_max 0.5418 (0.5586) teacher/usage_min 0.0004 (0.0002) teacher/usage_std 0.2379 (0.2425) nleep/row_max_mean 1508.6108 (1517.1685) nleep/row_max_std 68.0368 (65.3856) nleep/row_min_mean 1486.7594 (1493.7781) lr 1.9823e-03 eta 0:12:08
epoch [5/50] batch [60/162] time 0.088 (0.097) data 0.001 (0.005) loss 1.6428 (1.3808) teacher_loss 0.4564 (0.1232) loss_zs_kd 0.0574 (0.0557) loss_oracle 0.5041 (0.5627) kd_loss 0.9056 (0.9484) acc 90.6250 (96.9792) gate/entropy 1.0834 (1.0849) gate/usage_max 0.3793 (0.3778) gate/usage_min 0.2532 (0.2574) gate/usage_std 0.0569 (0.0540) teacher/entropy 0.0758 (0.0431) teacher/usage_max 0.6146 (0.5603) teacher/usage_min 0.0003 (0.0004) teacher/usage_std 0.2535 (0.2431) nleep/row_max_mean 1528.5981 (1518.1292) nleep/row_max_std 64.6782 (64.4241) nleep/row_min_mean 1505.9844 (1494.8135) lr 1.9823e-03 eta 0:11:57
epoch [5/50] batch [80/162] time 0.092 (0.096) data 0.000 (0.004) loss 1.3270 (1.3696) teacher_loss 0.1082 (0.1229) loss_zs_kd 0.0561 (0.0540) loss_oracle 0.5244 (0.5512) kd_loss 0.9285 (0.9441) acc 96.8750 (96.9141) gate/entropy 1.0823 (1.0844) gate/usage_max 0.3799 (0.3782) gate/usage_min 0.2506 (0.2560) gate/usage_std 0.0587 (0.0549) teacher/entropy 0.0518 (0.0457) teacher/usage_max 0.5429 (0.5607) teacher/usage_min 0.0002 (0.0004) teacher/usage_std 0.2382 (0.2432) nleep/row_max_mean 1521.2235 (1518.9360) nleep/row_max_std 63.5891 (64.2929) nleep/row_min_mean 1498.0876 (1495.6711) lr 1.9823e-03 eta 0:11:46
epoch [5/50] batch [100/162] time 0.100 (0.096) data 0.000 (0.003) loss 1.3466 (1.3731) teacher_loss 0.1024 (0.1339) loss_zs_kd 0.0466 (0.0533) loss_oracle 0.5710 (0.5451) kd_loss 0.9355 (0.9400) acc 96.8750 (96.7188) gate/entropy 1.0813 (1.0839) gate/usage_max 0.3809 (0.3787) gate/usage_min 0.2481 (0.2547) gate/usage_std 0.0604 (0.0558) teacher/entropy 0.0426 (0.0482) teacher/usage_max 0.5064 (0.5636) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.2357 (0.2438) nleep/row_max_mean 1523.9573 (1518.1910) nleep/row_max_std 66.5707 (64.4848) nleep/row_min_mean 1500.1282 (1495.1541) lr 1.9823e-03 eta 0:11:43
epoch [5/50] batch [120/162] time 0.136 (0.096) data 0.000 (0.003) loss 1.3263 (1.3753) teacher_loss 0.1444 (0.1424) loss_zs_kd 0.0434 (0.0521) loss_oracle 0.5155 (0.5415) kd_loss 0.9024 (0.9360) acc 96.8750 (96.4844) gate/entropy 1.0804 (1.0834) gate/usage_max 0.3812 (0.3791) gate/usage_min 0.2457 (0.2534) gate/usage_std 0.0621 (0.0567) teacher/entropy 0.0705 (0.0506) teacher/usage_max 0.6026 (0.5657) teacher/usage_min 0.0002 (0.0008) teacher/usage_std 0.2500 (0.2441) nleep/row_max_mean 1507.4429 (1518.1540) nleep/row_max_std 66.4138 (64.3936) nleep/row_min_mean 1485.9333 (1495.3055) lr 1.9823e-03 eta 0:11:45
epoch [5/50] batch [140/162] time 0.089 (0.097) data 0.000 (0.002) loss 1.4353 (1.3822) teacher_loss 0.1496 (0.1497) loss_zs_kd 0.0545 (0.0522) loss_oracle 0.6257 (0.5437) kd_loss 0.9456 (0.9345) acc 96.8750 (96.3393) gate/entropy 1.0793 (1.0829) gate/usage_max 0.3821 (0.3794) gate/usage_min 0.2432 (0.2521) gate/usage_std 0.0638 (0.0576) teacher/entropy 0.0254 (0.0503) teacher/usage_max 0.5282 (0.5638) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.2368 (0.2437) nleep/row_max_mean 1507.6816 (1518.4329) nleep/row_max_std 51.9364 (63.6488) nleep/row_min_mean 1483.4612 (1495.6082) lr 1.9823e-03 eta 0:11:46
epoch [5/50] batch [160/162] time 0.085 (0.096) data 0.000 (0.002) loss 1.4830 (1.3736) teacher_loss 0.2172 (0.1471) loss_zs_kd 0.0556 (0.0510) loss_oracle 0.6270 (0.5402) kd_loss 0.9244 (0.9309) acc 93.7500 (96.4844) gate/entropy 1.0782 (1.0823) gate/usage_max 0.3826 (0.3798) gate/usage_min 0.2408 (0.2508) gate/usage_std 0.0655 (0.0585) teacher/entropy 0.0451 (0.0523) teacher/usage_max 0.5506 (0.5644) teacher/usage_min 0.0006 (0.0010) teacher/usage_std 0.2389 (0.2438) nleep/row_max_mean 1521.0767 (1518.5885) nleep/row_max_std 60.1061 (63.3081) nleep/row_min_mean 1495.0203 (1495.7887) lr 1.9823e-03 eta 0:11:39
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,897
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 87.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,628
* accuracy: 80.1%
* error: 19.9%
* macro_f1: 74.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      86.5%, epoch: 2 *******
******* Domain s best val test acc: 72.0%, epoch: 2 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [6/50] batch [20/162] time 0.092 (0.118) data 0.000 (0.021) loss 1.2087 (1.3738) teacher_loss 0.1087 (0.1711) loss_zs_kd 0.0393 (0.0496) loss_oracle 0.4489 (0.5330) kd_loss 0.8559 (0.9114) acc 96.8750 (94.5312) gate/entropy 1.0769 (1.0775) gate/usage_max 0.3829 (0.3828) gate/usage_min 0.2379 (0.2392) gate/usage_std 0.0675 (0.0666) teacher/entropy 0.1117 (0.0574) teacher/usage_max 0.5216 (0.5983) teacher/usage_min 0.0060 (0.0028) teacher/usage_std 0.2323 (0.2532) nleep/row_max_mean 1512.2983 (1522.5299) nleep/row_max_std 67.0914 (59.3418) nleep/row_min_mean 1490.1112 (1497.8700) lr 1.9686e-03 eta 0:14:17
epoch [6/50] batch [40/162] time 0.086 (0.114) data 0.000 (0.011) loss 1.4485 (1.3858) teacher_loss 0.2466 (0.1914) loss_zs_kd 0.0405 (0.0474) loss_oracle 0.5125 (0.5236) kd_loss 0.9253 (0.9089) acc 96.8750 (93.9844) gate/entropy 1.0759 (1.0769) gate/usage_max 0.3829 (0.3828) gate/usage_min 0.2359 (0.2380) gate/usage_std 0.0689 (0.0674) teacher/entropy 0.0379 (0.0584) teacher/usage_max 0.6196 (0.5916) teacher/usage_min 0.0016 (0.0038) teacher/usage_std 0.2543 (0.2495) nleep/row_max_mean 1506.6696 (1522.4729) nleep/row_max_std 68.8229 (59.1063) nleep/row_min_mean 1480.4354 (1498.0763) lr 1.9686e-03 eta 0:13:48
epoch [6/50] batch [60/162] time 0.102 (0.108) data 0.001 (0.007) loss 1.4361 (1.3787) teacher_loss 0.2719 (0.1841) loss_zs_kd 0.0434 (0.0472) loss_oracle 0.5081 (0.5242) kd_loss 0.8885 (0.9089) acc 96.8750 (94.6354) gate/entropy 1.0750 (1.0764) gate/usage_max 0.3831 (0.3828) gate/usage_min 0.2339 (0.2370) gate/usage_std 0.0703 (0.0682) teacher/entropy 0.0713 (0.0565) teacher/usage_max 0.6628 (0.6004) teacher/usage_min 0.0005 (0.0031) teacher/usage_std 0.2704 (0.2524) nleep/row_max_mean 1504.4702 (1522.2911) nleep/row_max_std 67.4516 (59.7869) nleep/row_min_mean 1479.4750 (1497.8647) lr 1.9686e-03 eta 0:12:59
epoch [6/50] batch [80/162] time 0.100 (0.104) data 0.000 (0.006) loss 1.6473 (1.3822) teacher_loss 0.4656 (0.1961) loss_zs_kd 0.0489 (0.0446) loss_oracle 0.5352 (0.5172) kd_loss 0.8896 (0.9052) acc 84.3750 (94.2188) gate/entropy 1.0737 (1.0759) gate/usage_max 0.3858 (0.3833) gate/usage_min 0.2315 (0.2359) gate/usage_std 0.0720 (0.0689) teacher/entropy 0.0674 (0.0585) teacher/usage_max 0.6196 (0.6024) teacher/usage_min 0.0036 (0.0029) teacher/usage_std 0.2534 (0.2532) nleep/row_max_mean 1511.7817 (1522.0116) nleep/row_max_std 72.2994 (59.5079) nleep/row_min_mean 1487.3142 (1497.5487) lr 1.9686e-03 eta 0:12:29
epoch [6/50] batch [100/162] time 0.094 (0.103) data 0.000 (0.004) loss 1.6200 (1.3800) teacher_loss 0.4840 (0.2007) loss_zs_kd 0.0630 (0.0440) loss_oracle 0.4419 (0.5097) kd_loss 0.8836 (0.9025) acc 87.5000 (94.1250) gate/entropy 1.0729 (1.0754) gate/usage_max 0.3878 (0.3840) gate/usage_min 0.2298 (0.2349) gate/usage_std 0.0732 (0.0696) teacher/entropy 0.0681 (0.0599) teacher/usage_max 0.7456 (0.6063) teacher/usage_min 0.0024 (0.0035) teacher/usage_std 0.3088 (0.2540) nleep/row_max_mean 1510.0076 (1521.7618) nleep/row_max_std 70.3082 (59.6641) nleep/row_min_mean 1484.3536 (1497.2107) lr 1.9686e-03 eta 0:12:21
epoch [6/50] batch [120/162] time 0.093 (0.101) data 0.000 (0.004) loss 1.3032 (1.3831) teacher_loss 0.1721 (0.2105) loss_zs_kd 0.0453 (0.0428) loss_oracle 0.4879 (0.5018) kd_loss 0.8645 (0.9003) acc 96.8750 (93.5156) gate/entropy 1.0718 (1.0749) gate/usage_max 0.3904 (0.3848) gate/usage_min 0.2278 (0.2338) gate/usage_std 0.0747 (0.0704) teacher/entropy 0.0900 (0.0604) teacher/usage_max 0.5775 (0.6117) teacher/usage_min 0.0091 (0.0037) teacher/usage_std 0.2389 (0.2559) nleep/row_max_mean 1524.9735 (1521.1904) nleep/row_max_std 65.7565 (59.6333) nleep/row_min_mean 1500.2920 (1496.4055) lr 1.9686e-03 eta 0:12:07
epoch [6/50] batch [140/162] time 0.099 (0.101) data 0.001 (0.003) loss 1.4950 (1.3859) teacher_loss 0.3498 (0.2167) loss_zs_kd 0.0226 (0.0419) loss_oracle 0.4907 (0.5006) kd_loss 0.8886 (0.8979) acc 84.3750 (93.2143) gate/entropy 1.0708 (1.0744) gate/usage_max 0.3944 (0.3859) gate/usage_min 0.2261 (0.2329) gate/usage_std 0.0761 (0.0711) teacher/entropy 0.0477 (0.0604) teacher/usage_max 0.8473 (0.6309) teacher/usage_min 0.0007 (0.0034) teacher/usage_std 0.3686 (0.2639) nleep/row_max_mean 1535.2012 (1521.9950) nleep/row_max_std 58.5900 (59.6651) nleep/row_min_mean 1506.9827 (1496.7992) lr 1.9686e-03 eta 0:12:00
epoch [6/50] batch [160/162] time 0.084 (0.100) data 0.000 (0.003) loss 1.3755 (1.3904) teacher_loss 0.1542 (0.2227) loss_zs_kd 0.0264 (0.0402) loss_oracle 0.6167 (0.5036) kd_loss 0.8997 (0.8958) acc 96.8750 (92.7344) gate/entropy 1.0700 (1.0739) gate/usage_max 0.3986 (0.3873) gate/usage_min 0.2250 (0.2319) gate/usage_std 0.0771 (0.0718) teacher/entropy 0.0363 (0.0600) teacher/usage_max 0.7521 (0.6475) teacher/usage_min 0.0046 (0.0036) teacher/usage_std 0.3117 (0.2711) nleep/row_max_mean 1522.2786 (1521.9797) nleep/row_max_std 67.5607 (59.7979) nleep/row_min_mean 1496.4257 (1496.5994) lr 1.9686e-03 eta 0:11:50
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,893
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 87.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,608
* accuracy: 79.5%
* error: 20.5%
* macro_f1: 74.8%
******* Domain s best val acc:      86.5%, epoch: 2 *******
******* Domain s best val test acc: 72.0%, epoch: 2 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [7/50] batch [20/162] time 0.082 (0.109) data 0.000 (0.016) loss 1.3732 (1.4118) teacher_loss 0.2219 (0.3025) loss_zs_kd 0.0326 (0.0243) loss_oracle 0.5449 (0.4756) kd_loss 0.8625 (0.8593) acc 90.6250 (88.7500) gate/entropy 1.0691 (1.0695) gate/usage_max 0.4033 (0.4013) gate/usage_min 0.2239 (0.2243) gate/usage_std 0.0784 (0.0779) teacher/entropy 0.0859 (0.0749) teacher/usage_max 0.7134 (0.7916) teacher/usage_min 0.0354 (0.0137) teacher/usage_std 0.2828 (0.3340) nleep/row_max_mean 1502.8872 (1519.3084) nleep/row_max_std 69.5580 (64.0041) nleep/row_min_mean 1478.8269 (1493.2241) lr 1.9511e-03 eta 0:12:56
epoch [7/50] batch [40/162] time 0.085 (0.096) data 0.000 (0.008) loss 1.3629 (1.4586) teacher_loss 0.1768 (0.3306) loss_zs_kd 0.0213 (0.0250) loss_oracle 0.6036 (0.5097) kd_loss 0.8737 (0.8606) acc 93.7500 (87.2656) gate/entropy 1.0683 (1.0690) gate/usage_max 0.4080 (0.4036) gate/usage_min 0.2231 (0.2238) gate/usage_std 0.0796 (0.0785) teacher/entropy 0.0485 (0.0704) teacher/usage_max 0.8668 (0.8048) teacher/usage_min 0.0249 (0.0169) teacher/usage_std 0.3787 (0.3413) nleep/row_max_mean 1519.4456 (1519.8692) nleep/row_max_std 63.2589 (63.7422) nleep/row_min_mean 1492.5747 (1493.9794) lr 1.9511e-03 eta 0:11:19
epoch [7/50] batch [60/162] time 0.097 (0.092) data 0.000 (0.005) loss 1.8071 (1.4612) teacher_loss 0.6232 (0.3258) loss_zs_kd 0.0202 (0.0259) loss_oracle 0.6146 (0.5268) kd_loss 0.8666 (0.8591) acc 71.8750 (87.2396) gate/entropy 1.0672 (1.0686) gate/usage_max 0.4132 (0.4060) gate/usage_min 0.2220 (0.2233) gate/usage_std 0.0812 (0.0792) teacher/entropy 0.0721 (0.0677) teacher/usage_max 0.7340 (0.8110) teacher/usage_min 0.0448 (0.0171) teacher/usage_std 0.2923 (0.3451) nleep/row_max_mean 1507.8225 (1520.2370) nleep/row_max_std 69.6350 (63.0244) nleep/row_min_mean 1481.5354 (1494.0721) lr 1.9511e-03 eta 0:10:53
epoch [7/50] batch [80/162] time 0.094 (0.094) data 0.000 (0.004) loss 1.5032 (1.4679) teacher_loss 0.3679 (0.3296) loss_zs_kd 0.0266 (0.0267) loss_oracle 0.4899 (0.5326) kd_loss 0.8770 (0.8586) acc 84.3750 (87.3047) gate/entropy 1.0662 (1.0681) gate/usage_max 0.4178 (0.4084) gate/usage_min 0.2213 (0.2229) gate/usage_std 0.0826 (0.0799) teacher/entropy 0.0435 (0.0655) teacher/usage_max 0.8241 (0.8166) teacher/usage_min 0.0450 (0.0208) teacher/usage_std 0.3488 (0.3482) nleep/row_max_mean 1522.6569 (1520.7275) nleep/row_max_std 71.7810 (62.6426) nleep/row_min_mean 1494.1366 (1494.4206) lr 1.9511e-03 eta 0:11:04
epoch [7/50] batch [100/162] time 0.089 (0.094) data 0.000 (0.003) loss 1.4102 (1.4726) teacher_loss 0.2821 (0.3308) loss_zs_kd 0.0311 (0.0271) loss_oracle 0.5429 (0.5424) kd_loss 0.8411 (0.8570) acc 87.5000 (87.4062) gate/entropy 1.0651 (1.0676) gate/usage_max 0.4228 (0.4109) gate/usage_min 0.2207 (0.2225) gate/usage_std 0.0841 (0.0806) teacher/entropy 0.0486 (0.0638) teacher/usage_max 0.8402 (0.8168) teacher/usage_min 0.0040 (0.0220) teacher/usage_std 0.3637 (0.3481) nleep/row_max_mean 1512.6038 (1520.4793) nleep/row_max_std 63.7300 (62.3865) nleep/row_min_mean 1486.0872 (1494.1026) lr 1.9511e-03 eta 0:11:03
epoch [7/50] batch [120/162] time 0.098 (0.093) data 0.000 (0.003) loss 1.4022 (1.4769) teacher_loss 0.2696 (0.3345) loss_zs_kd 0.0331 (0.0281) loss_oracle 0.5839 (0.5513) kd_loss 0.8241 (0.8528) acc 84.3750 (87.3698) gate/entropy 1.0638 (1.0671) gate/usage_max 0.4281 (0.4133) gate/usage_min 0.2200 (0.2221) gate/usage_std 0.0860 (0.0813) teacher/entropy 0.0516 (0.0633) teacher/usage_max 0.9125 (0.8244) teacher/usage_min 0.0219 (0.0225) teacher/usage_std 0.4099 (0.3529) nleep/row_max_mean 1516.6538 (1520.7819) nleep/row_max_std 58.1683 (61.5682) nleep/row_min_mean 1488.8188 (1494.1769) lr 1.9511e-03 eta 0:10:53
epoch [7/50] batch [140/162] time 0.089 (0.092) data 0.000 (0.002) loss 1.3686 (1.4701) teacher_loss 0.2917 (0.3335) loss_zs_kd 0.0181 (0.0273) loss_oracle 0.5163 (0.5482) kd_loss 0.8096 (0.8489) acc 90.6250 (87.3438) gate/entropy 1.0624 (1.0665) gate/usage_max 0.4336 (0.4159) gate/usage_min 0.2193 (0.2217) gate/usage_std 0.0880 (0.0822) teacher/entropy 0.0814 (0.0619) teacher/usage_max 0.8106 (0.8317) teacher/usage_min 0.0294 (0.0226) teacher/usage_std 0.3417 (0.3575) nleep/row_max_mean 1519.7695 (1521.9461) nleep/row_max_std 58.0978 (60.9060) nleep/row_min_mean 1494.3455 (1495.0212) lr 1.9511e-03 eta 0:10:44
epoch [7/50] batch [160/162] time 0.085 (0.092) data 0.000 (0.002) loss 1.2840 (1.4620) teacher_loss 0.1805 (0.3310) loss_zs_kd 0.0283 (0.0269) loss_oracle 0.5756 (0.5464) kd_loss 0.8016 (0.8444) acc 96.8750 (87.3828) gate/entropy 1.0608 (1.0659) gate/usage_max 0.4391 (0.4184) gate/usage_min 0.2188 (0.2214) gate/usage_std 0.0902 (0.0830) teacher/entropy 0.0366 (0.0618) teacher/usage_max 0.9564 (0.8356) teacher/usage_min 0.0100 (0.0232) teacher/usage_std 0.4407 (0.3599) nleep/row_max_mean 1534.5519 (1522.2564) nleep/row_max_std 60.7108 (60.7019) nleep/row_min_mean 1505.3809 (1495.1474) lr 1.9511e-03 eta 0:10:40
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,936
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 88.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,540
* accuracy: 77.4%
* error: 22.6%
* macro_f1: 73.1%
******* Domain s best val acc:      86.7%, epoch: 7 *******
******* Domain s best val test acc: 77.4%, epoch: 7 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [8/50] batch [20/162] time 0.070 (0.094) data 0.000 (0.017) loss 1.3248 (1.3800) teacher_loss 0.2025 (0.3005) loss_zs_kd 0.0279 (0.0250) loss_oracle 0.5901 (0.5297) kd_loss 0.8133 (0.8022) acc 90.6250 (87.3438) gate/entropy 1.0590 (1.0598) gate/usage_max 0.4451 (0.4426) gate/usage_min 0.2182 (0.2184) gate/usage_std 0.0927 (0.0916) teacher/entropy 0.0055 (0.0541) teacher/usage_max 0.9677 (0.8793) teacher/usage_min 0.0008 (0.0212) teacher/usage_std 0.4488 (0.3881) nleep/row_max_mean 1536.3835 (1522.4247) nleep/row_max_std 51.0845 (59.7071) nleep/row_min_mean 1505.8477 (1494.5486) lr 1.9298e-03 eta 0:10:51
epoch [8/50] batch [40/162] time 0.085 (0.089) data 0.000 (0.009) loss 1.4108 (1.4079) teacher_loss 0.3361 (0.3211) loss_zs_kd 0.0258 (0.0296) loss_oracle 0.5796 (0.5469) kd_loss 0.7719 (0.7986) acc 87.5000 (87.5781) gate/entropy 1.0571 (1.0589) gate/usage_max 0.4509 (0.4454) gate/usage_min 0.2178 (0.2182) gate/usage_std 0.0952 (0.0928) teacher/entropy 0.0987 (0.0522) teacher/usage_max 0.7860 (0.8791) teacher/usage_min 0.0206 (0.0187) teacher/usage_std 0.3278 (0.3881) nleep/row_max_mean 1518.8386 (1522.8838) nleep/row_max_std 64.2759 (60.0402) nleep/row_min_mean 1492.3083 (1495.0315) lr 1.9298e-03 eta 0:10:13
epoch [8/50] batch [60/162] time 0.104 (0.090) data 0.000 (0.006) loss 1.2463 (1.4011) teacher_loss 0.1922 (0.3239) loss_zs_kd 0.0226 (0.0270) loss_oracle 0.4791 (0.5330) kd_loss 0.8032 (0.7972) acc 90.6250 (87.0833) gate/entropy 1.0555 (1.0580) gate/usage_max 0.4560 (0.4482) gate/usage_min 0.2178 (0.2181) gate/usage_std 0.0974 (0.0940) teacher/entropy 0.0029 (0.0439) teacher/usage_max 0.9376 (0.8922) teacher/usage_min 0.0001 (0.0159) teacher/usage_std 0.4280 (0.3970) nleep/row_max_mean 1524.3367 (1523.9543) nleep/row_max_std 56.2684 (59.1796) nleep/row_min_mean 1496.7354 (1495.5759) lr 1.9298e-03 eta 0:10:24
epoch [8/50] batch [80/162] time 0.094 (0.092) data 0.000 (0.004) loss 1.5372 (1.3888) teacher_loss 0.4383 (0.3183) loss_zs_kd 0.0330 (0.0269) loss_oracle 0.5812 (0.5256) kd_loss 0.7917 (0.7943) acc 78.1250 (87.1875) gate/entropy 1.0534 (1.0571) gate/usage_max 0.4614 (0.4508) gate/usage_min 0.2172 (0.2179) gate/usage_std 0.1000 (0.0952) teacher/entropy 0.0052 (0.0435) teacher/usage_max 0.9364 (0.8885) teacher/usage_min 0.0011 (0.0155) teacher/usage_std 0.4272 (0.3946) nleep/row_max_mean 1533.8699 (1522.5920) nleep/row_max_std 62.0257 (59.9480) nleep/row_min_mean 1501.9840 (1494.4968) lr 1.9298e-03 eta 0:10:32
epoch [8/50] batch [100/162] time 0.093 (0.093) data 0.000 (0.004) loss 1.4110 (1.3849) teacher_loss 0.3958 (0.3181) loss_zs_kd 0.0408 (0.0278) loss_oracle 0.4590 (0.5240) kd_loss 0.7653 (0.7909) acc 81.2500 (87.2188) gate/entropy 1.0515 (1.0562) gate/usage_max 0.4662 (0.4534) gate/usage_min 0.2171 (0.2178) gate/usage_std 0.1024 (0.0964) teacher/entropy 0.0377 (0.0414) teacher/usage_max 0.9147 (0.8907) teacher/usage_min 0.0194 (0.0146) teacher/usage_std 0.4115 (0.3961) nleep/row_max_mean 1524.5786 (1523.0388) nleep/row_max_std 62.2242 (60.5001) nleep/row_min_mean 1497.0547 (1494.8363) lr 1.9298e-03 eta 0:10:35
epoch [8/50] batch [120/162] time 0.097 (0.093) data 0.000 (0.003) loss 1.1481 (1.3749) teacher_loss 0.1606 (0.3143) loss_zs_kd 0.0197 (0.0275) loss_oracle 0.4927 (0.5170) kd_loss 0.7313 (0.7884) acc 96.8750 (87.4219) gate/entropy 1.0495 (1.0552) gate/usage_max 0.4709 (0.4559) gate/usage_min 0.2169 (0.2176) gate/usage_std 0.1048 (0.0976) teacher/entropy 0.0412 (0.0387) teacher/usage_max 0.9528 (0.8915) teacher/usage_min 0.0001 (0.0129) teacher/usage_std 0.4385 (0.3968) nleep/row_max_mean 1510.5936 (1522.3244) nleep/row_max_std 62.7683 (60.7331) nleep/row_min_mean 1485.1787 (1494.2494) lr 1.9298e-03 eta 0:10:36
epoch [8/50] batch [140/162] time 0.181 (0.094) data 0.000 (0.003) loss 1.2922 (1.3761) teacher_loss 0.2654 (0.3193) loss_zs_kd 0.0248 (0.0275) loss_oracle 0.5262 (0.5152) kd_loss 0.7512 (0.7854) acc 93.7500 (87.3661) gate/entropy 1.0472 (1.0543) gate/usage_max 0.4762 (0.4585) gate/usage_min 0.2167 (0.2175) gate/usage_std 0.1076 (0.0988) teacher/entropy 0.0401 (0.0359) teacher/usage_max 0.8942 (0.8945) teacher/usage_min 0.0082 (0.0124) teacher/usage_std 0.3983 (0.3988) nleep/row_max_mean 1511.6909 (1522.3553) nleep/row_max_std 69.8407 (61.2989) nleep/row_min_mean 1482.6423 (1494.1816) lr 1.9298e-03 eta 0:10:39
epoch [8/50] batch [160/162] time 0.083 (0.094) data 0.000 (0.002) loss 1.1459 (1.3825) teacher_loss 0.1452 (0.3286) loss_zs_kd 0.0191 (0.0284) loss_oracle 0.4399 (0.5113) kd_loss 0.7712 (0.7841) acc 100.0000 (87.1094) gate/entropy 1.0449 (1.0532) gate/usage_max 0.4812 (0.4610) gate/usage_min 0.2166 (0.2174) gate/usage_std 0.1102 (0.1001) teacher/entropy 0.0043 (0.0327) teacher/usage_max 0.9056 (0.8946) teacher/usage_min 0.0002 (0.0112) teacher/usage_std 0.4064 (0.3990) nleep/row_max_mean 1528.5312 (1521.6543) nleep/row_max_std 64.0633 (61.5816) nleep/row_min_mean 1500.8562 (1493.4044) lr 1.9298e-03 eta 0:10:40
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,937
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 88.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,447
* accuracy: 74.6%
* error: 25.4%
* macro_f1: 73.3%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [9/50] batch [20/162] time 0.091 (0.106) data 0.000 (0.014) loss 1.1278 (1.2679) teacher_loss 0.2131 (0.2590) loss_zs_kd 0.0300 (0.0244) loss_oracle 0.3321 (0.4577) kd_loss 0.7337 (0.7679) acc 93.7500 (90.9375) gate/entropy 1.0426 (1.0435) gate/usage_max 0.4861 (0.4843) gate/usage_min 0.2166 (0.2165) gate/usage_std 0.1129 (0.1119) teacher/entropy 0.0221 (0.0099) teacher/usage_max 0.9295 (0.8945) teacher/usage_min 0.0000 (0.0062) teacher/usage_std 0.4225 (0.3992) nleep/row_max_mean 1518.8522 (1522.0076) nleep/row_max_std 52.4529 (60.7971) nleep/row_min_mean 1490.0498 (1492.4937) lr 1.9048e-03 eta 0:11:56
epoch [9/50] batch [40/162] time 0.100 (0.099) data 0.000 (0.007) loss 1.6914 (1.2921) teacher_loss 0.6112 (0.2888) loss_zs_kd 0.0378 (0.0289) loss_oracle 0.5093 (0.4558) kd_loss 0.8066 (0.7609) acc 75.0000 (88.9062) gate/entropy 1.0400 (1.0423) gate/usage_max 0.4910 (0.4865) gate/usage_min 0.2163 (0.2164) gate/usage_std 0.1158 (0.1132) teacher/entropy 0.0011 (0.0081) teacher/usage_max 0.8126 (0.9039) teacher/usage_min 0.0000 (0.0041) teacher/usage_std 0.3474 (0.4060) nleep/row_max_mean 1504.6456 (1521.4905) nleep/row_max_std 64.1388 (61.3860) nleep/row_min_mean 1475.5237 (1491.6598) lr 1.9048e-03 eta 0:11:08
epoch [9/50] batch [60/162] time 0.098 (0.098) data 0.000 (0.005) loss 1.2980 (1.3037) teacher_loss 0.3509 (0.3075) loss_zs_kd 0.0277 (0.0292) loss_oracle 0.4591 (0.4531) kd_loss 0.7037 (0.7551) acc 87.5000 (87.4479) gate/entropy 1.0376 (1.0411) gate/usage_max 0.4956 (0.4888) gate/usage_min 0.2162 (0.2164) gate/usage_std 0.1184 (0.1145) teacher/entropy 0.0191 (0.0087) teacher/usage_max 0.9622 (0.9066) teacher/usage_min 0.0002 (0.0029) teacher/usage_std 0.4449 (0.4078) nleep/row_max_mean 1526.5952 (1520.5929) nleep/row_max_std 62.5547 (61.6176) nleep/row_min_mean 1494.8665 (1490.9990) lr 1.9048e-03 eta 0:10:58
epoch [9/50] batch [80/162] time 0.102 (0.100) data 0.000 (0.004) loss 1.3254 (1.2975) teacher_loss 0.2868 (0.3039) loss_zs_kd 0.0385 (0.0283) loss_oracle 0.5284 (0.4534) kd_loss 0.7552 (0.7528) acc 87.5000 (87.7734) gate/entropy 1.0351 (1.0400) gate/usage_max 0.5000 (0.4910) gate/usage_min 0.2160 (0.2163) gate/usage_std 0.1211 (0.1158) teacher/entropy 0.0089 (0.0088) teacher/usage_max 0.8729 (0.9042) teacher/usage_min 0.0001 (0.0023) teacher/usage_std 0.3850 (0.4061) nleep/row_max_mean 1530.2378 (1521.5354) nleep/row_max_std 63.2388 (61.0990) nleep/row_min_mean 1500.0245 (1491.7674) lr 1.9048e-03 eta 0:11:12
epoch [9/50] batch [100/162] time 0.097 (0.099) data 0.000 (0.003) loss 1.2000 (1.3016) teacher_loss 0.2785 (0.3140) loss_zs_kd 0.0310 (0.0280) loss_oracle 0.4058 (0.4508) kd_loss 0.7032 (0.7482) acc 84.3750 (87.1250) gate/entropy 1.0330 (1.0388) gate/usage_max 0.5036 (0.4932) gate/usage_min 0.2161 (0.2163) gate/usage_std 0.1232 (0.1171) teacher/entropy 0.0014 (0.0081) teacher/usage_max 0.9685 (0.9075) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.4493 (0.4084) nleep/row_max_mean 1534.3757 (1522.0256) nleep/row_max_std 56.6476 (60.6323) nleep/row_min_mean 1504.9448 (1492.2535) lr 1.9048e-03 eta 0:11:02
epoch [9/50] batch [120/162] time 0.095 (0.098) data 0.000 (0.003) loss 1.2351 (1.3032) teacher_loss 0.3255 (0.3175) loss_zs_kd 0.0309 (0.0282) loss_oracle 0.3957 (0.4545) kd_loss 0.6963 (0.7444) acc 81.2500 (87.0052) gate/entropy 1.0307 (1.0376) gate/usage_max 0.5076 (0.4953) gate/usage_min 0.2162 (0.2163) gate/usage_std 0.1256 (0.1183) teacher/entropy 0.0006 (0.0075) teacher/usage_max 0.9687 (0.9096) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.4494 (0.4097) nleep/row_max_mean 1528.0702 (1522.4538) nleep/row_max_std 46.6253 (60.1640) nleep/row_min_mean 1497.5686 (1492.5741) lr 1.9048e-03 eta 0:10:55
epoch [9/50] batch [140/162] time 0.096 (0.098) data 0.000 (0.002) loss 1.1443 (1.2973) teacher_loss 0.2734 (0.3182) loss_zs_kd 0.0172 (0.0274) loss_oracle 0.3940 (0.4508) kd_loss 0.6653 (0.7400) acc 87.5000 (86.9420) gate/entropy 1.0285 (1.0364) gate/usage_max 0.5111 (0.4973) gate/usage_min 0.2163 (0.2162) gate/usage_std 0.1278 (0.1195) teacher/entropy 0.0069 (0.0069) teacher/usage_max 0.9982 (0.9124) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.4701 (0.4116) nleep/row_max_mean 1529.8704 (1523.0002) nleep/row_max_std 57.6076 (60.2666) nleep/row_min_mean 1498.2404 (1493.1121) lr 1.9048e-03 eta 0:10:51
epoch [9/50] batch [160/162] time 0.088 (0.097) data 0.000 (0.002) loss 1.3704 (1.2969) teacher_loss 0.4092 (0.3188) loss_zs_kd 0.0259 (0.0276) loss_oracle 0.4473 (0.4515) kd_loss 0.7246 (0.7386) acc 81.2500 (86.9531) gate/entropy 1.0261 (1.0352) gate/usage_max 0.5149 (0.4994) gate/usage_min 0.2162 (0.2162) gate/usage_std 0.1302 (0.1208) teacher/entropy 0.0003 (0.0067) teacher/usage_max 0.9062 (0.9102) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.4069 (0.4102) nleep/row_max_mean 1505.4590 (1522.9049) nleep/row_max_std 72.2578 (60.7045) nleep/row_min_mean 1477.9752 (1493.1547) lr 1.9048e-03 eta 0:10:42
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,937
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 87.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,474
* accuracy: 75.4%
* error: 24.6%
* macro_f1: 71.1%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [10/50] batch [20/162] time 0.087 (0.115) data 0.000 (0.019) loss 1.3336 (1.2678) teacher_loss 0.4145 (0.3085) loss_zs_kd 0.0192 (0.0285) loss_oracle 0.4208 (0.4516) kd_loss 0.6990 (0.7192) acc 84.3750 (87.3438) gate/entropy 1.0241 (1.0246) gate/usage_max 0.5179 (0.5171) gate/usage_min 0.2164 (0.2162) gate/usage_std 0.1321 (0.1316) teacher/entropy 0.0003 (0.0029) teacher/usage_max 0.9375 (0.9056) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.4280 (0.4070) nleep/row_max_mean 1507.9924 (1520.1927) nleep/row_max_std 58.8452 (61.3209) nleep/row_min_mean 1480.0527 (1491.5206) lr 1.8763e-03 eta 0:12:42
epoch [10/50] batch [40/162] time 0.092 (0.103) data 0.000 (0.009) loss 1.2112 (1.2670) teacher_loss 0.2559 (0.3095) loss_zs_kd 0.0310 (0.0295) loss_oracle 0.4516 (0.4559) kd_loss 0.7140 (0.7148) acc 87.5000 (86.5625) gate/entropy 1.0216 (1.0236) gate/usage_max 0.5216 (0.5187) gate/usage_min 0.2162 (0.2162) gate/usage_std 0.1344 (0.1326) teacher/entropy 0.0011 (0.0029) teacher/usage_max 0.9061 (0.9087) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4068 (0.4090) nleep/row_max_mean 1524.9808 (1523.1632) nleep/row_max_std 61.8398 (60.5995) nleep/row_min_mean 1495.8215 (1493.9030) lr 1.8763e-03 eta 0:11:22
epoch [10/50] batch [60/162] time 0.085 (0.103) data 0.000 (0.006) loss 1.1817 (1.2679) teacher_loss 0.2293 (0.3204) loss_zs_kd 0.0104 (0.0291) loss_oracle 0.4377 (0.4433) kd_loss 0.7283 (0.7114) acc 87.5000 (86.6667) gate/entropy 1.0196 (1.0225) gate/usage_max 0.5245 (0.5202) gate/usage_min 0.2162 (0.2162) gate/usage_std 0.1363 (0.1335) teacher/entropy 0.0055 (0.0032) teacher/usage_max 0.8740 (0.9102) teacher/usage_min 0.0002 (0.0008) teacher/usage_std 0.3857 (0.4100) nleep/row_max_mean 1495.2141 (1522.0725) nleep/row_max_std 67.2525 (61.7163) nleep/row_min_mean 1471.4360 (1493.0979) lr 1.8763e-03 eta 0:11:20
epoch [10/50] batch [80/162] time 0.082 (0.101) data 0.000 (0.005) loss 1.2476 (1.2626) teacher_loss 0.3433 (0.3270) loss_zs_kd 0.0245 (0.0288) loss_oracle 0.4260 (0.4327) kd_loss 0.6791 (0.7048) acc 90.6250 (86.7578) gate/entropy 1.0172 (1.0215) gate/usage_max 0.5278 (0.5216) gate/usage_min 0.2160 (0.2162) gate/usage_std 0.1385 (0.1345) teacher/entropy 0.0058 (0.0051) teacher/usage_max 0.9365 (0.9140) teacher/usage_min 0.0008 (0.0007) teacher/usage_std 0.4272 (0.4126) nleep/row_max_mean 1533.2927 (1521.0826) nleep/row_max_std 65.3371 (62.3129) nleep/row_min_mean 1506.4988 (1492.5048) lr 1.8763e-03 eta 0:11:00
epoch [10/50] batch [100/162] time 0.096 (0.099) data 0.000 (0.004) loss 1.1574 (1.2504) teacher_loss 0.2370 (0.3190) loss_zs_kd 0.0265 (0.0280) loss_oracle 0.3902 (0.4287) kd_loss 0.7121 (0.7031) acc 84.3750 (86.9375) gate/entropy 1.0158 (1.0206) gate/usage_max 0.5297 (0.5230) gate/usage_min 0.2162 (0.2162) gate/usage_std 0.1397 (0.1354) teacher/entropy 0.0199 (0.0051) teacher/usage_max 0.8688 (0.9134) teacher/usage_min 0.0022 (0.0007) teacher/usage_std 0.3821 (0.4121) nleep/row_max_mean 1508.4407 (1521.5860) nleep/row_max_std 72.9998 (62.5651) nleep/row_min_mean 1481.6991 (1492.9804) lr 1.8763e-03 eta 0:10:48
epoch [10/50] batch [120/162] time 0.093 (0.099) data 0.000 (0.003) loss 1.1674 (1.2509) teacher_loss 0.3446 (0.3215) loss_zs_kd 0.0461 (0.0283) loss_oracle 0.3595 (0.4244) kd_loss 0.6200 (0.7030) acc 90.6250 (86.9792) gate/entropy 1.0145 (1.0196) gate/usage_max 0.5316 (0.5243) gate/usage_min 0.2162 (0.2162) gate/usage_std 0.1409 (0.1362) teacher/entropy 0.0144 (0.0055) teacher/usage_max 0.9969 (0.9106) teacher/usage_min 0.0009 (0.0006) teacher/usage_std 0.4692 (0.4103) nleep/row_max_mean 1515.0466 (1521.4732) nleep/row_max_std 58.9134 (63.0260) nleep/row_min_mean 1487.1461 (1492.9614) lr 1.8763e-03 eta 0:10:44
epoch [10/50] batch [140/162] time 0.097 (0.099) data 0.000 (0.003) loss 1.1995 (1.2435) teacher_loss 0.2697 (0.3185) loss_zs_kd 0.0356 (0.0279) loss_oracle 0.4376 (0.4205) kd_loss 0.6932 (0.7007) acc 87.5000 (87.2098) gate/entropy 1.0121 (1.0187) gate/usage_max 0.5346 (0.5256) gate/usage_min 0.2160 (0.2162) gate/usage_std 0.1430 (0.1371) teacher/entropy 0.0054 (0.0056) teacher/usage_max 0.9051 (0.9111) teacher/usage_min 0.0011 (0.0006) teacher/usage_std 0.4061 (0.4106) nleep/row_max_mean 1524.6417 (1522.0268) nleep/row_max_std 61.9371 (62.5792) nleep/row_min_mean 1497.5426 (1493.5882) lr 1.8763e-03 eta 0:10:41
epoch [10/50] batch [160/162] time 0.076 (0.097) data 0.001 (0.003) loss 1.2287 (1.2394) teacher_loss 0.2461 (0.3168) loss_zs_kd 0.0270 (0.0278) loss_oracle 0.4836 (0.4200) kd_loss 0.7273 (0.6988) acc 90.6250 (87.2656) gate/entropy 1.0110 (1.0178) gate/usage_max 0.5361 (0.5268) gate/usage_min 0.2160 (0.2162) gate/usage_std 0.1439 (0.1378) teacher/entropy 0.0239 (0.0067) teacher/usage_max 0.8437 (0.9102) teacher/usage_min 0.0608 (0.0013) teacher/usage_std 0.3612 (0.4100) nleep/row_max_mean 1536.4214 (1522.3032) nleep/row_max_std 66.8602 (62.5758) nleep/row_min_mean 1507.5228 (1493.8934) lr 1.8763e-03 eta 0:10:30
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,937
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 87.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,428
* accuracy: 74.0%
* error: 26.0%
* macro_f1: 70.5%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [11/50] batch [20/162] time 0.077 (0.100) data 0.000 (0.014) loss 1.3208 (1.2226) teacher_loss 0.3929 (0.3111) loss_zs_kd 0.0231 (0.0260) loss_oracle 0.4557 (0.4164) kd_loss 0.6886 (0.6903) acc 87.5000 (87.8125) gate/entropy 1.0096 (1.0101) gate/usage_max 0.5379 (0.5372) gate/usage_min 0.2161 (0.2160) gate/usage_std 0.1452 (0.1447) teacher/entropy 0.0053 (0.0132) teacher/usage_max 0.9050 (0.8946) teacher/usage_min 0.0012 (0.0034) teacher/usage_std 0.4060 (0.3992) nleep/row_max_mean 1530.2583 (1521.2285) nleep/row_max_std 57.7807 (64.0072) nleep/row_min_mean 1499.6230 (1493.6658) lr 1.8443e-03 eta 0:10:48
epoch [11/50] batch [40/162] time 0.094 (0.093) data 0.000 (0.007) loss 1.3838 (1.2112) teacher_loss 0.5146 (0.3105) loss_zs_kd 0.0216 (0.0256) loss_oracle 0.4043 (0.4126) kd_loss 0.6562 (0.6816) acc 78.1250 (87.9688) gate/entropy 1.0083 (1.0095) gate/usage_max 0.5396 (0.5380) gate/usage_min 0.2160 (0.2160) gate/usage_std 0.1463 (0.1453) teacher/entropy 0.0238 (0.0153) teacher/usage_max 0.9210 (0.9017) teacher/usage_min 0.0001 (0.0038) teacher/usage_std 0.4168 (0.4041) nleep/row_max_mean 1529.7288 (1522.1707) nleep/row_max_std 56.6093 (64.0047) nleep/row_min_mean 1501.8665 (1495.0892) lr 1.8443e-03 eta 0:09:56
epoch [11/50] batch [60/162] time 0.076 (0.090) data 0.000 (0.005) loss 1.2937 (1.2042) teacher_loss 0.4095 (0.3070) loss_zs_kd 0.0231 (0.0271) loss_oracle 0.4094 (0.4101) kd_loss 0.6679 (0.6786) acc 84.3750 (88.1250) gate/entropy 1.0069 (1.0089) gate/usage_max 0.5413 (0.5388) gate/usage_min 0.2159 (0.2160) gate/usage_std 0.1475 (0.1458) teacher/entropy 0.0293 (0.0162) teacher/usage_max 0.8971 (0.9030) teacher/usage_min 0.0080 (0.0032) teacher/usage_std 0.4002 (0.4050) nleep/row_max_mean 1514.8590 (1522.5518) nleep/row_max_std 67.3374 (62.5290) nleep/row_min_mean 1489.7358 (1495.4575) lr 1.8443e-03 eta 0:09:37
epoch [11/50] batch [80/162] time 0.093 (0.088) data 0.000 (0.004) loss 1.2078 (1.1922) teacher_loss 0.3973 (0.2980) loss_zs_kd 0.0297 (0.0277) loss_oracle 0.3596 (0.4094) kd_loss 0.6159 (0.6757) acc 90.6250 (88.5156) gate/entropy 1.0054 (1.0082) gate/usage_max 0.5431 (0.5396) gate/usage_min 0.2158 (0.2160) gate/usage_std 0.1487 (0.1463) teacher/entropy 0.0298 (0.0154) teacher/usage_max 0.9579 (0.9064) teacher/usage_min 0.0085 (0.0028) teacher/usage_std 0.4418 (0.4073) nleep/row_max_mean 1523.7335 (1523.5075) nleep/row_max_std 67.7842 (61.7001) nleep/row_min_mean 1496.8938 (1496.3009) lr 1.8443e-03 eta 0:09:21
epoch [11/50] batch [100/162] time 0.088 (0.087) data 0.000 (0.003) loss 0.9556 (1.1866) teacher_loss 0.1770 (0.2953) loss_zs_kd 0.0152 (0.0281) loss_oracle 0.3105 (0.4056) kd_loss 0.6158 (0.6744) acc 100.0000 (88.8125) gate/entropy 1.0047 (1.0076) gate/usage_max 0.5440 (0.5404) gate/usage_min 0.2158 (0.2159) gate/usage_std 0.1493 (0.1468) teacher/entropy 0.0269 (0.0154) teacher/usage_max 0.9590 (0.9068) teacher/usage_min 0.0067 (0.0032) teacher/usage_std 0.4425 (0.4076) nleep/row_max_mean 1532.6960 (1523.0650) nleep/row_max_std 46.9170 (61.5077) nleep/row_min_mean 1506.4166 (1495.9659) lr 1.8443e-03 eta 0:09:16
epoch [11/50] batch [120/162] time 0.096 (0.088) data 0.000 (0.002) loss 1.3190 (1.1917) teacher_loss 0.4458 (0.3009) loss_zs_kd 0.0406 (0.0280) loss_oracle 0.3749 (0.4041) kd_loss 0.6654 (0.6748) acc 81.2500 (88.7500) gate/entropy 1.0038 (1.0070) gate/usage_max 0.5451 (0.5411) gate/usage_min 0.2158 (0.2159) gate/usage_std 0.1500 (0.1474) teacher/entropy 0.0254 (0.0153) teacher/usage_max 0.8981 (0.9053) teacher/usage_min 0.0051 (0.0029) teacher/usage_std 0.4011 (0.4067) nleep/row_max_mean 1505.6016 (1522.9045) nleep/row_max_std 68.5306 (61.2343) nleep/row_min_mean 1480.0344 (1495.9228) lr 1.8443e-03 eta 0:09:21
epoch [11/50] batch [140/162] time 0.092 (0.089) data 0.000 (0.002) loss 1.0866 (1.1973) teacher_loss 0.2079 (0.3049) loss_zs_kd 0.0253 (0.0281) loss_oracle 0.3836 (0.4073) kd_loss 0.6742 (0.6747) acc 90.6250 (88.4821) gate/entropy 1.0028 (1.0064) gate/usage_max 0.5463 (0.5418) gate/usage_min 0.2157 (0.2159) gate/usage_std 0.1508 (0.1478) teacher/entropy 0.0270 (0.0149) teacher/usage_max 0.8832 (0.9048) teacher/usage_min 0.0006 (0.0028) teacher/usage_std 0.3917 (0.4063) nleep/row_max_mean 1508.2798 (1522.4013) nleep/row_max_std 64.4353 (61.3880) nleep/row_min_mean 1482.9685 (1495.4993) lr 1.8443e-03 eta 0:09:24
epoch [11/50] batch [160/162] time 0.081 (0.089) data 0.000 (0.002) loss 1.1793 (1.1987) teacher_loss 0.3488 (0.3075) loss_zs_kd 0.0166 (0.0280) loss_oracle 0.3952 (0.4053) kd_loss 0.6246 (0.6746) acc 84.3750 (88.1836) gate/entropy 1.0016 (1.0059) gate/usage_max 0.5477 (0.5425) gate/usage_min 0.2156 (0.2159) gate/usage_std 0.1518 (0.1483) teacher/entropy 0.0043 (0.0149) teacher/usage_max 0.9680 (0.9038) teacher/usage_min 0.0002 (0.0028) teacher/usage_std 0.4490 (0.4057) nleep/row_max_mean 1520.1190 (1522.2133) nleep/row_max_std 60.8535 (61.6373) nleep/row_min_mean 1494.7659 (1495.3996) lr 1.8443e-03 eta 0:09:22
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,923
* accuracy: 86.1%
* error: 13.9%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,370
* accuracy: 72.2%
* error: 27.8%
* macro_f1: 69.9%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [12/50] batch [20/162] time 0.072 (0.106) data 0.000 (0.014) loss 1.2355 (1.1537) teacher_loss 0.2657 (0.2682) loss_zs_kd 0.0356 (0.0281) loss_oracle 0.4769 (0.4017) kd_loss 0.7136 (0.6707) acc 78.1250 (87.1875) gate/entropy 1.0000 (1.0011) gate/usage_max 0.5496 (0.5483) gate/usage_min 0.2154 (0.2156) gate/usage_std 0.1531 (0.1523) teacher/entropy 0.0247 (0.0190) teacher/usage_max 0.8361 (0.8949) teacher/usage_min 0.0074 (0.0041) teacher/usage_std 0.3607 (0.3996) nleep/row_max_mean 1523.0552 (1520.8113) nleep/row_max_std 63.4497 (62.8915) nleep/row_min_mean 1497.8481 (1494.7562) lr 1.8090e-03 eta 0:11:09
epoch [12/50] batch [40/162] time 0.086 (0.099) data 0.000 (0.007) loss 1.1472 (1.1972) teacher_loss 0.2890 (0.3101) loss_zs_kd 0.0282 (0.0291) loss_oracle 0.3957 (0.4077) kd_loss 0.6463 (0.6687) acc 93.7500 (87.2656) gate/entropy 0.9998 (1.0006) gate/usage_max 0.5498 (0.5488) gate/usage_min 0.2155 (0.2155) gate/usage_std 0.1533 (0.1526) teacher/entropy 0.0062 (0.0218) teacher/usage_max 0.9364 (0.8933) teacher/usage_min 0.0002 (0.0055) teacher/usage_std 0.4272 (0.3985) nleep/row_max_mean 1530.0660 (1519.6264) nleep/row_max_std 58.6554 (62.4183) nleep/row_min_mean 1504.7368 (1494.1095) lr 1.8090e-03 eta 0:10:20
epoch [12/50] batch [60/162] time 0.089 (0.097) data 0.001 (0.005) loss 1.2411 (1.1902) teacher_loss 0.3640 (0.3168) loss_zs_kd 0.0276 (0.0266) loss_oracle 0.3932 (0.3966) kd_loss 0.6668 (0.6618) acc 84.3750 (87.6562) gate/entropy 0.9992 (1.0002) gate/usage_max 0.5505 (0.5493) gate/usage_min 0.2155 (0.2155) gate/usage_std 0.1538 (0.1529) teacher/entropy 0.0218 (0.0196) teacher/usage_max 0.8927 (0.9032) teacher/usage_min 0.0000 (0.0041) teacher/usage_std 0.3979 (0.4052) nleep/row_max_mean 1515.5762 (1521.4374) nleep/row_max_std 64.5462 (61.8687) nleep/row_min_mean 1488.5389 (1495.8320) lr 1.8090e-03 eta 0:10:09
epoch [12/50] batch [80/162] time 0.097 (0.096) data 0.000 (0.004) loss 1.1015 (1.2046) teacher_loss 0.2702 (0.3303) loss_zs_kd 0.0231 (0.0262) loss_oracle 0.4074 (0.3994) kd_loss 0.6161 (0.6615) acc 84.3750 (87.1484) gate/entropy 0.9983 (0.9998) gate/usage_max 0.5516 (0.5498) gate/usage_min 0.2154 (0.2155) gate/usage_std 0.1545 (0.1533) teacher/entropy 0.0223 (0.0196) teacher/usage_max 0.9494 (0.9028) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.4361 (0.4050) nleep/row_max_mean 1519.9302 (1521.6401) nleep/row_max_std 54.8640 (61.2433) nleep/row_min_mean 1490.6637 (1495.8815) lr 1.8090e-03 eta 0:09:59
epoch [12/50] batch [100/162] time 0.093 (0.095) data 0.000 (0.003) loss 1.4143 (1.2055) teacher_loss 0.5332 (0.3301) loss_zs_kd 0.0202 (0.0266) loss_oracle 0.4222 (0.4018) kd_loss 0.6599 (0.6613) acc 84.3750 (87.4688) gate/entropy 0.9973 (0.9994) gate/usage_max 0.5527 (0.5503) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1553 (0.1536) teacher/entropy 0.0303 (0.0199) teacher/usage_max 0.8877 (0.9019) teacher/usage_min 0.0002 (0.0032) teacher/usage_std 0.3946 (0.4045) nleep/row_max_mean 1522.9226 (1522.1060) nleep/row_max_std 57.7167 (60.7756) nleep/row_min_mean 1495.6157 (1496.2850) lr 1.8090e-03 eta 0:09:53
epoch [12/50] batch [120/162] time 0.167 (0.097) data 0.001 (0.003) loss 1.3877 (1.2024) teacher_loss 0.4539 (0.3243) loss_zs_kd 0.0454 (0.0271) loss_oracle 0.4776 (0.4073) kd_loss 0.6723 (0.6609) acc 78.1250 (87.5781) gate/entropy 0.9966 (0.9990) gate/usage_max 0.5535 (0.5507) gate/usage_min 0.2152 (0.2154) gate/usage_std 0.1558 (0.1539) teacher/entropy 0.0013 (0.0203) teacher/usage_max 0.9062 (0.9013) teacher/usage_min 0.0001 (0.0034) teacher/usage_std 0.4069 (0.4041) nleep/row_max_mean 1516.9561 (1522.0963) nleep/row_max_std 58.2941 (60.4302) nleep/row_min_mean 1487.7465 (1496.1339) lr 1.8090e-03 eta 0:09:59
epoch [12/50] batch [140/162] time 0.081 (0.097) data 0.000 (0.002) loss 1.3459 (1.1903) teacher_loss 0.3812 (0.3126) loss_zs_kd 0.0415 (0.0270) loss_oracle 0.5037 (0.4086) kd_loss 0.6921 (0.6599) acc 81.2500 (87.8571) gate/entropy 0.9958 (0.9986) gate/usage_max 0.5544 (0.5512) gate/usage_min 0.2152 (0.2154) gate/usage_std 0.1564 (0.1542) teacher/entropy 0.0076 (0.0191) teacher/usage_max 0.8746 (0.9031) teacher/usage_min 0.0016 (0.0031) teacher/usage_std 0.3860 (0.4053) nleep/row_max_mean 1534.6084 (1522.5963) nleep/row_max_std 59.2550 (60.4372) nleep/row_min_mean 1504.8262 (1496.4159) lr 1.8090e-03 eta 0:10:01
epoch [12/50] batch [160/162] time 0.092 (0.097) data 0.000 (0.002) loss 1.0285 (1.1873) teacher_loss 0.1572 (0.3096) loss_zs_kd 0.0316 (0.0272) loss_oracle 0.4490 (0.4089) kd_loss 0.6310 (0.6597) acc 93.7500 (88.0664) gate/entropy 0.9949 (0.9982) gate/usage_max 0.5554 (0.5516) gate/usage_min 0.2151 (0.2154) gate/usage_std 0.1572 (0.1545) teacher/entropy 0.0157 (0.0182) teacher/usage_max 0.9336 (0.9037) teacher/usage_min 0.0038 (0.0031) teacher/usage_std 0.4251 (0.4057) nleep/row_max_mean 1521.9045 (1523.1082) nleep/row_max_std 62.3958 (60.3871) nleep/row_min_mean 1493.2552 (1496.7587) lr 1.8090e-03 eta 0:09:55
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,912
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,281
* accuracy: 69.5%
* error: 30.5%
* macro_f1: 68.7%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [13/50] batch [20/162] time 0.075 (0.105) data 0.000 (0.016) loss 1.0923 (1.1340) teacher_loss 0.2635 (0.2936) loss_zs_kd 0.0291 (0.0294) loss_oracle 0.3473 (0.3785) kd_loss 0.6406 (0.6364) acc 90.6250 (87.6562) gate/entropy 0.9943 (0.9946) gate/usage_max 0.5561 (0.5558) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1576 (0.1574) teacher/entropy 0.0019 (0.0102) teacher/usage_max 0.9375 (0.9332) teacher/usage_min 0.0003 (0.0015) teacher/usage_std 0.4279 (0.4254) nleep/row_max_mean 1528.5708 (1528.8168) nleep/row_max_std 56.2889 (58.8412) nleep/row_min_mean 1499.7998 (1500.0089) lr 1.7705e-03 eta 0:10:45
epoch [13/50] batch [40/162] time 0.096 (0.098) data 0.000 (0.008) loss 1.3383 (1.1701) teacher_loss 0.3046 (0.3141) loss_zs_kd 0.0251 (0.0307) loss_oracle 0.4832 (0.3855) kd_loss 0.7795 (0.6479) acc 93.7500 (87.5781) gate/entropy 0.9940 (0.9943) gate/usage_max 0.5565 (0.5561) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1579 (0.1576) teacher/entropy 0.0014 (0.0108) teacher/usage_max 0.7812 (0.9192) teacher/usage_min 0.0001 (0.0018) teacher/usage_std 0.3290 (0.4162) nleep/row_max_mean 1518.7106 (1525.3684) nleep/row_max_std 67.7529 (59.4905) nleep/row_min_mean 1492.5686 (1496.9196) lr 1.7705e-03 eta 0:09:56
epoch [13/50] batch [60/162] time 0.079 (0.093) data 0.001 (0.006) loss 1.3286 (1.1753) teacher_loss 0.4972 (0.3182) loss_zs_kd 0.0271 (0.0297) loss_oracle 0.3021 (0.3854) kd_loss 0.6668 (0.6495) acc 81.2500 (87.6042) gate/entropy 0.9934 (0.9940) gate/usage_max 0.5571 (0.5564) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1583 (0.1578) teacher/entropy 0.0022 (0.0120) teacher/usage_max 0.9060 (0.9155) teacher/usage_min 0.0003 (0.0020) teacher/usage_std 0.4067 (0.4136) nleep/row_max_mean 1514.6312 (1524.8770) nleep/row_max_std 54.4471 (59.0386) nleep/row_min_mean 1489.0515 (1496.7133) lr 1.7705e-03 eta 0:09:29
epoch [13/50] batch [80/162] time 0.093 (0.091) data 0.000 (0.004) loss 1.0643 (1.1642) teacher_loss 0.2115 (0.3034) loss_zs_kd 0.0412 (0.0301) loss_oracle 0.3936 (0.3884) kd_loss 0.6354 (0.6515) acc 93.7500 (88.2812) gate/entropy 0.9930 (0.9938) gate/usage_max 0.5576 (0.5567) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1586 (0.1580) teacher/entropy 0.0076 (0.0122) teacher/usage_max 0.9362 (0.9125) teacher/usage_min 0.0313 (0.0028) teacher/usage_std 0.4263 (0.4116) nleep/row_max_mean 1522.3091 (1525.1238) nleep/row_max_std 61.0104 (58.6967) nleep/row_min_mean 1496.3854 (1497.1228) lr 1.7705e-03 eta 0:09:13
epoch [13/50] batch [100/162] time 0.087 (0.092) data 0.000 (0.003) loss 1.3982 (1.1706) teacher_loss 0.5311 (0.3121) loss_zs_kd 0.0215 (0.0292) loss_oracle 0.3478 (0.3850) kd_loss 0.6824 (0.6514) acc 71.8750 (87.7500) gate/entropy 0.9922 (0.9935) gate/usage_max 0.5585 (0.5570) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1593 (0.1583) teacher/entropy 0.0149 (0.0127) teacher/usage_max 0.8729 (0.9117) teacher/usage_min 0.0015 (0.0030) teacher/usage_std 0.3849 (0.4110) nleep/row_max_mean 1521.6783 (1525.3480) nleep/row_max_std 61.7673 (58.6678) nleep/row_min_mean 1496.4078 (1497.5840) lr 1.7705e-03 eta 0:09:18
epoch [13/50] batch [120/162] time 0.094 (0.092) data 0.000 (0.003) loss 1.1558 (1.1817) teacher_loss 0.2423 (0.3180) loss_zs_kd 0.0387 (0.0296) loss_oracle 0.4704 (0.3911) kd_loss 0.6590 (0.6534) acc 87.5000 (87.5781) gate/entropy 0.9918 (0.9932) gate/usage_max 0.5589 (0.5573) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1595 (0.1585) teacher/entropy 0.0097 (0.0132) teacher/usage_max 0.9036 (0.9086) teacher/usage_min 0.0027 (0.0034) teacher/usage_std 0.4050 (0.4088) nleep/row_max_mean 1510.6499 (1524.5190) nleep/row_max_std 53.9637 (59.0635) nleep/row_min_mean 1483.2625 (1497.0626) lr 1.7705e-03 eta 0:09:15
epoch [13/50] batch [140/162] time 0.105 (0.092) data 0.000 (0.003) loss 1.0566 (1.1759) teacher_loss 0.1714 (0.3106) loss_zs_kd 0.0134 (0.0294) loss_oracle 0.4057 (0.3959) kd_loss 0.6756 (0.6526) acc 90.6250 (87.8125) gate/entropy 0.9914 (0.9930) gate/usage_max 0.5593 (0.5576) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1598 (0.1586) teacher/entropy 0.0231 (0.0143) teacher/usage_max 0.8706 (0.9078) teacher/usage_min 0.0032 (0.0035) teacher/usage_std 0.3832 (0.4083) nleep/row_max_mean 1504.3174 (1524.3422) nleep/row_max_std 55.0472 (59.0584) nleep/row_min_mean 1482.6824 (1497.2191) lr 1.7705e-03 eta 0:09:16
epoch [13/50] batch [160/162] time 0.095 (0.093) data 0.000 (0.002) loss 1.0119 (1.1712) teacher_loss 0.1951 (0.3071) loss_zs_kd 0.0244 (0.0290) loss_oracle 0.4533 (0.3954) kd_loss 0.5780 (0.6518) acc 93.7500 (88.0469) gate/entropy 0.9911 (0.9927) gate/usage_max 0.5596 (0.5578) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1601 (0.1588) teacher/entropy 0.0363 (0.0146) teacher/usage_max 0.9641 (0.9080) teacher/usage_min 0.0117 (0.0041) teacher/usage_std 0.4460 (0.4084) nleep/row_max_mean 1522.6349 (1524.2915) nleep/row_max_std 50.0092 (58.9789) nleep/row_min_mean 1494.1941 (1497.3461) lr 1.7705e-03 eta 0:09:14
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,922
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,327
* accuracy: 70.9%
* error: 29.1%
* macro_f1: 68.3%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [14/50] batch [20/162] time 0.103 (0.104) data 0.000 (0.017) loss 1.1015 (1.1334) teacher_loss 0.3034 (0.2789) loss_zs_kd 0.0304 (0.0275) loss_oracle 0.3748 (0.3905) kd_loss 0.5954 (0.6455) acc 90.6250 (89.0625) gate/entropy 0.9907 (0.9907) gate/usage_max 0.5601 (0.5601) gate/usage_min 0.2149 (0.2148) gate/usage_std 0.1604 (0.1604) teacher/entropy 0.0169 (0.0150) teacher/usage_max 0.9641 (0.9114) teacher/usage_min 0.0044 (0.0058) teacher/usage_std 0.4461 (0.4104) nleep/row_max_mean 1521.4602 (1518.3224) nleep/row_max_std 59.4712 (60.6206) nleep/row_min_mean 1495.4761 (1492.7596) lr 1.7290e-03 eta 0:10:20
epoch [14/50] batch [40/162] time 0.117 (0.107) data 0.001 (0.009) loss 1.3462 (1.1530) teacher_loss 0.4827 (0.3021) loss_zs_kd 0.0186 (0.0258) loss_oracle 0.3863 (0.3883) kd_loss 0.6611 (0.6439) acc 84.3750 (87.8906) gate/entropy 0.9900 (0.9904) gate/usage_max 0.5609 (0.5604) gate/usage_min 0.2147 (0.2148) gate/usage_std 0.1609 (0.1606) teacher/entropy 0.0032 (0.0153) teacher/usage_max 0.9058 (0.9124) teacher/usage_min 0.0002 (0.0046) teacher/usage_std 0.4066 (0.4112) nleep/row_max_mean 1508.0354 (1519.9555) nleep/row_max_std 66.0520 (61.0454) nleep/row_min_mean 1481.2617 (1494.1624) lr 1.7290e-03 eta 0:10:36
epoch [14/50] batch [60/162] time 0.095 (0.099) data 0.001 (0.006) loss 1.0335 (1.1695) teacher_loss 0.1498 (0.3146) loss_zs_kd 0.0234 (0.0262) loss_oracle 0.4586 (0.3925) kd_loss 0.6426 (0.6456) acc 93.7500 (87.2917) gate/entropy 0.9899 (0.9902) gate/usage_max 0.5609 (0.5606) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1610 (0.1608) teacher/entropy 0.0823 (0.0174) teacher/usage_max 0.8410 (0.9081) teacher/usage_min 0.0250 (0.0059) teacher/usage_std 0.3617 (0.4082) nleep/row_max_mean 1501.7490 (1518.8584) nleep/row_max_std 60.9477 (62.1435) nleep/row_min_mean 1479.9731 (1493.2343) lr 1.7290e-03 eta 0:09:49
epoch [14/50] batch [80/162] time 0.098 (0.097) data 0.000 (0.004) loss 1.1505 (1.1656) teacher_loss 0.2448 (0.3026) loss_zs_kd 0.0330 (0.0270) loss_oracle 0.4857 (0.4011) kd_loss 0.6464 (0.6490) acc 87.5000 (87.8906) gate/entropy 0.9895 (0.9901) gate/usage_max 0.5614 (0.5608) gate/usage_min 0.2147 (0.2148) gate/usage_std 0.1613 (0.1609) teacher/entropy 0.0383 (0.0179) teacher/usage_max 0.8838 (0.9035) teacher/usage_min 0.0197 (0.0062) teacher/usage_std 0.3905 (0.4052) nleep/row_max_mean 1507.4659 (1518.7855) nleep/row_max_std 61.2901 (62.3138) nleep/row_min_mean 1483.1710 (1493.3584) lr 1.7290e-03 eta 0:09:32
epoch [14/50] batch [100/162] time 0.084 (0.094) data 0.000 (0.004) loss 1.3127 (1.1698) teacher_loss 0.5371 (0.3046) loss_zs_kd 0.0290 (0.0284) loss_oracle 0.3330 (0.4018) kd_loss 0.5946 (0.6501) acc 81.2500 (88.0000) gate/entropy 0.9890 (0.9899) gate/usage_max 0.5620 (0.5610) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1617 (0.1610) teacher/entropy 0.0268 (0.0188) teacher/usage_max 0.9508 (0.9011) teacher/usage_min 0.0003 (0.0067) teacher/usage_std 0.4370 (0.4036) nleep/row_max_mean 1518.3235 (1518.8507) nleep/row_max_std 61.9102 (61.9149) nleep/row_min_mean 1493.8461 (1493.5590) lr 1.7290e-03 eta 0:09:16
epoch [14/50] batch [120/162] time 0.088 (0.093) data 0.000 (0.003) loss 1.0990 (1.1658) teacher_loss 0.3100 (0.3006) loss_zs_kd 0.0157 (0.0286) loss_oracle 0.3798 (0.4033) kd_loss 0.5912 (0.6492) acc 84.3750 (88.2292) gate/entropy 0.9887 (0.9897) gate/usage_max 0.5623 (0.5612) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1619 (0.1612) teacher/entropy 0.0232 (0.0191) teacher/usage_max 0.9584 (0.9015) teacher/usage_min 0.0103 (0.0062) teacher/usage_std 0.4421 (0.4039) nleep/row_max_mean 1533.8151 (1519.9731) nleep/row_max_std 48.9343 (61.5354) nleep/row_min_mean 1507.1699 (1494.6087) lr 1.7290e-03 eta 0:09:05
epoch [14/50] batch [140/162] time 0.068 (0.091) data 0.000 (0.003) loss 1.1604 (1.1700) teacher_loss 0.3659 (0.3059) loss_zs_kd 0.0365 (0.0288) loss_oracle 0.3606 (0.4030) kd_loss 0.5960 (0.6482) acc 84.3750 (88.2143) gate/entropy 0.9884 (0.9895) gate/usage_max 0.5626 (0.5614) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1622 (0.1613) teacher/entropy 0.0109 (0.0199) teacher/usage_max 0.9655 (0.9014) teacher/usage_min 0.0001 (0.0062) teacher/usage_std 0.4472 (0.4039) nleep/row_max_mean 1526.9856 (1519.7581) nleep/row_max_std 55.3419 (61.9330) nleep/row_min_mean 1498.8616 (1494.3776) lr 1.7290e-03 eta 0:08:54
epoch [14/50] batch [160/162] time 0.084 (0.091) data 0.000 (0.002) loss 1.2817 (1.1702) teacher_loss 0.3937 (0.3034) loss_zs_kd 0.0325 (0.0292) loss_oracle 0.3911 (0.4038) kd_loss 0.6761 (0.6503) acc 84.3750 (88.4570) gate/entropy 0.9880 (0.9894) gate/usage_max 0.5630 (0.5616) gate/usage_min 0.2145 (0.2147) gate/usage_std 0.1624 (0.1614) teacher/entropy 0.0295 (0.0205) teacher/usage_max 0.8587 (0.8982) teacher/usage_min 0.0001 (0.0057) teacher/usage_std 0.3759 (0.4019) nleep/row_max_mean 1517.9337 (1519.6558) nleep/row_max_std 61.2895 (62.1224) nleep/row_min_mean 1492.0797 (1494.3209) lr 1.7290e-03 eta 0:08:49
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,911
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 85.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,302
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 69.1%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [15/50] batch [20/162] time 0.094 (0.125) data 0.000 (0.018) loss 1.2056 (1.1676) teacher_loss 0.3030 (0.2857) loss_zs_kd 0.0463 (0.0340) loss_oracle 0.4123 (0.4040) kd_loss 0.6732 (0.6629) acc 87.5000 (89.0625) gate/entropy 0.9880 (0.9879) gate/usage_max 0.5631 (0.5631) gate/usage_min 0.2145 (0.2145) gate/usage_std 0.1625 (0.1625) teacher/entropy 0.0784 (0.0239) teacher/usage_max 0.8089 (0.8790) teacher/usage_min 0.0111 (0.0055) teacher/usage_std 0.3433 (0.3896) nleep/row_max_mean 1502.3993 (1514.4552) nleep/row_max_std 64.5375 (62.3590) nleep/row_min_mean 1478.4767 (1489.2346) lr 1.6845e-03 eta 0:12:09
epoch [15/50] batch [40/162] time 0.095 (0.108) data 0.000 (0.009) loss 1.1865 (1.1653) teacher_loss 0.2465 (0.2924) loss_zs_kd 0.0423 (0.0321) loss_oracle 0.4921 (0.4020) kd_loss 0.6729 (0.6558) acc 93.7500 (88.5156) gate/entropy 0.9875 (0.9878) gate/usage_max 0.5635 (0.5632) gate/usage_min 0.2144 (0.2145) gate/usage_std 0.1628 (0.1626) teacher/entropy 0.0639 (0.0261) teacher/usage_max 0.8256 (0.8841) teacher/usage_min 0.0169 (0.0065) teacher/usage_std 0.3528 (0.3926) nleep/row_max_mean 1512.2458 (1517.3192) nleep/row_max_std 53.5660 (60.9000) nleep/row_min_mean 1487.7549 (1492.1669) lr 1.6845e-03 eta 0:10:26
epoch [15/50] batch [60/162] time 0.102 (0.103) data 0.001 (0.006) loss 1.3482 (1.1706) teacher_loss 0.4868 (0.2988) loss_zs_kd 0.0327 (0.0313) loss_oracle 0.3797 (0.4015) kd_loss 0.6552 (0.6554) acc 78.1250 (88.4375) gate/entropy 0.9873 (0.9877) gate/usage_max 0.5638 (0.5634) gate/usage_min 0.2144 (0.2144) gate/usage_std 0.1630 (0.1627) teacher/entropy 0.0063 (0.0222) teacher/usage_max 0.9052 (0.8886) teacher/usage_min 0.0007 (0.0059) teacher/usage_std 0.4062 (0.3957) nleep/row_max_mean 1510.2988 (1518.3790) nleep/row_max_std 61.2533 (60.7976) nleep/row_min_mean 1483.3096 (1492.9246) lr 1.6845e-03 eta 0:09:53
epoch [15/50] batch [80/162] time 0.088 (0.100) data 0.000 (0.005) loss 1.3085 (1.1792) teacher_loss 0.3573 (0.3099) loss_zs_kd 0.0364 (0.0298) loss_oracle 0.3949 (0.4000) kd_loss 0.7356 (0.6544) acc 90.6250 (88.2812) gate/entropy 0.9870 (0.9875) gate/usage_max 0.5640 (0.5635) gate/usage_min 0.2144 (0.2144) gate/usage_std 0.1632 (0.1628) teacher/entropy 0.0109 (0.0210) teacher/usage_max 0.8142 (0.8907) teacher/usage_min 0.0295 (0.0061) teacher/usage_std 0.3440 (0.3971) nleep/row_max_mean 1516.6510 (1517.8170) nleep/row_max_std 73.9550 (61.2951) nleep/row_min_mean 1491.2521 (1492.1949) lr 1.6845e-03 eta 0:09:36
epoch [15/50] batch [100/162] time 0.095 (0.098) data 0.000 (0.004) loss 1.3808 (1.1766) teacher_loss 0.4441 (0.3104) loss_zs_kd 0.0248 (0.0288) loss_oracle 0.4582 (0.3990) kd_loss 0.6951 (0.6523) acc 93.7500 (88.3438) gate/entropy 0.9869 (0.9874) gate/usage_max 0.5642 (0.5636) gate/usage_min 0.2144 (0.2144) gate/usage_std 0.1633 (0.1629) teacher/entropy 0.0236 (0.0191) teacher/usage_max 0.8433 (0.8948) teacher/usage_min 0.0096 (0.0052) teacher/usage_std 0.3649 (0.3998) nleep/row_max_mean 1497.8438 (1518.2869) nleep/row_max_std 80.1172 (61.3562) nleep/row_min_mean 1470.6407 (1492.3900) lr 1.6845e-03 eta 0:09:22
epoch [15/50] batch [120/162] time 0.095 (0.097) data 0.000 (0.003) loss 1.0028 (1.1710) teacher_loss 0.2249 (0.3007) loss_zs_kd 0.0330 (0.0296) loss_oracle 0.3266 (0.4028) kd_loss 0.5981 (0.6541) acc 90.6250 (88.5677) gate/entropy 0.9865 (0.9873) gate/usage_max 0.5646 (0.5638) gate/usage_min 0.2143 (0.2144) gate/usage_std 0.1636 (0.1630) teacher/entropy 0.0032 (0.0186) teacher/usage_max 0.9683 (0.8933) teacher/usage_min 0.0001 (0.0052) teacher/usage_std 0.4491 (0.3987) nleep/row_max_mean 1535.9121 (1517.5657) nleep/row_max_std 44.5051 (62.2452) nleep/row_min_mean 1507.2256 (1491.4562) lr 1.6845e-03 eta 0:09:14
epoch [15/50] batch [140/162] time 0.095 (0.096) data 0.000 (0.003) loss 1.1061 (1.1720) teacher_loss 0.2193 (0.2996) loss_zs_kd 0.0234 (0.0299) loss_oracle 0.4661 (0.4070) kd_loss 0.6421 (0.6539) acc 93.7500 (88.4598) gate/entropy 0.9866 (0.9872) gate/usage_max 0.5645 (0.5639) gate/usage_min 0.2144 (0.2144) gate/usage_std 0.1635 (0.1631) teacher/entropy 0.0175 (0.0181) teacher/usage_max 0.9064 (0.8938) teacher/usage_min 0.0005 (0.0052) teacher/usage_std 0.4069 (0.3991) nleep/row_max_mean 1532.5354 (1517.6036) nleep/row_max_std 57.4100 (62.3890) nleep/row_min_mean 1505.6648 (1491.4484) lr 1.6845e-03 eta 0:09:09
epoch [15/50] batch [160/162] time 0.084 (0.096) data 0.000 (0.002) loss 1.1096 (1.1668) teacher_loss 0.3464 (0.2969) loss_zs_kd 0.0313 (0.0302) loss_oracle 0.3241 (0.4080) kd_loss 0.5855 (0.6508) acc 87.5000 (88.5547) gate/entropy 0.9862 (0.9871) gate/usage_max 0.5650 (0.5640) gate/usage_min 0.2143 (0.2144) gate/usage_std 0.1638 (0.1632) teacher/entropy 0.0195 (0.0189) teacher/usage_max 0.9638 (0.8962) teacher/usage_min 0.0007 (0.0058) teacher/usage_std 0.4460 (0.4006) nleep/row_max_mean 1510.7861 (1517.7630) nleep/row_max_std 66.8927 (62.5010) nleep/row_min_mean 1487.1665 (1491.7013) lr 1.6845e-03 eta 0:09:02
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,916
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 85.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,256
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 67.4%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [16/50] batch [20/162] time 0.086 (0.106) data 0.000 (0.017) loss 1.2955 (1.1517) teacher_loss 0.4061 (0.2878) loss_zs_kd 0.0301 (0.0264) loss_oracle 0.4292 (0.4060) kd_loss 0.6597 (0.6477) acc 87.5000 (87.1875) gate/entropy 0.9861 (0.9860) gate/usage_max 0.5650 (0.5652) gate/usage_min 0.2143 (0.2142) gate/usage_std 0.1638 (0.1639) teacher/entropy 0.0309 (0.0297) teacher/usage_max 0.8725 (0.8867) teacher/usage_min 0.0136 (0.0128) teacher/usage_std 0.3834 (0.3936) nleep/row_max_mean 1485.7380 (1509.7351) nleep/row_max_std 72.7950 (67.5944) nleep/row_min_mean 1464.9407 (1486.0918) lr 1.6374e-03 eta 0:09:59
epoch [16/50] batch [40/162] time 0.089 (0.093) data 0.000 (0.009) loss 1.1888 (1.1950) teacher_loss 0.2529 (0.3182) loss_zs_kd 0.0276 (0.0270) loss_oracle 0.4764 (0.4149) kd_loss 0.6839 (0.6559) acc 87.5000 (87.1875) gate/entropy 0.9856 (0.9859) gate/usage_max 0.5656 (0.5653) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1643 (0.1640) teacher/entropy 0.0436 (0.0292) teacher/usage_max 0.8329 (0.8784) teacher/usage_min 0.0026 (0.0114) teacher/usage_std 0.3594 (0.3883) nleep/row_max_mean 1517.3140 (1509.7268) nleep/row_max_std 65.8729 (67.9946) nleep/row_min_mean 1495.1979 (1486.0376) lr 1.6374e-03 eta 0:08:45
epoch [16/50] batch [60/162] time 0.073 (0.091) data 0.001 (0.006) loss 1.3107 (1.1848) teacher_loss 0.4043 (0.3187) loss_zs_kd 0.0402 (0.0278) loss_oracle 0.4032 (0.4087) kd_loss 0.6847 (0.6478) acc 84.3750 (87.8646) gate/entropy 0.9856 (0.9858) gate/usage_max 0.5656 (0.5654) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1643 (0.1641) teacher/entropy 0.0029 (0.0259) teacher/usage_max 0.8750 (0.8903) teacher/usage_min 0.0005 (0.0094) teacher/usage_std 0.3863 (0.3963) nleep/row_max_mean 1502.3269 (1510.6351) nleep/row_max_std 68.9673 (67.0963) nleep/row_min_mean 1477.4929 (1487.0120) lr 1.6374e-03 eta 0:08:28
epoch [16/50] batch [80/162] time 0.075 (0.088) data 0.000 (0.004) loss 1.1398 (1.1823) teacher_loss 0.3357 (0.3118) loss_zs_kd 0.0210 (0.0272) loss_oracle 0.3928 (0.4143) kd_loss 0.5972 (0.6497) acc 90.6250 (88.0469) gate/entropy 0.9851 (0.9857) gate/usage_max 0.5661 (0.5655) gate/usage_min 0.2141 (0.2142) gate/usage_std 0.1646 (0.1642) teacher/entropy 0.0017 (0.0250) teacher/usage_max 0.9685 (0.8891) teacher/usage_min 0.0002 (0.0099) teacher/usage_std 0.4493 (0.3955) nleep/row_max_mean 1504.3730 (1510.8707) nleep/row_max_std 70.0609 (66.1478) nleep/row_min_mean 1480.4626 (1487.2200) lr 1.6374e-03 eta 0:08:09
epoch [16/50] batch [100/162] time 0.079 (0.085) data 0.000 (0.004) loss 1.0535 (1.1798) teacher_loss 0.2180 (0.3077) loss_zs_kd 0.0285 (0.0275) loss_oracle 0.3904 (0.4172) kd_loss 0.6260 (0.6498) acc 87.5000 (88.1562) gate/entropy 0.9855 (0.9856) gate/usage_max 0.5657 (0.5656) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1643 (0.1642) teacher/entropy 0.0030 (0.0244) teacher/usage_max 0.9370 (0.8896) teacher/usage_min 0.0002 (0.0100) teacher/usage_std 0.4276 (0.3959) nleep/row_max_mean 1514.2588 (1511.4474) nleep/row_max_std 51.6322 (65.2833) nleep/row_min_mean 1488.3317 (1487.6187) lr 1.6374e-03 eta 0:07:55
epoch [16/50] batch [120/162] time 0.097 (0.084) data 0.000 (0.003) loss 1.1124 (1.1695) teacher_loss 0.1991 (0.3018) loss_zs_kd 0.0214 (0.0278) loss_oracle 0.4801 (0.4142) kd_loss 0.6626 (0.6467) acc 93.7500 (88.4635) gate/entropy 0.9848 (0.9855) gate/usage_max 0.5664 (0.5657) gate/usage_min 0.2141 (0.2142) gate/usage_std 0.1648 (0.1643) teacher/entropy 0.0277 (0.0235) teacher/usage_max 0.8713 (0.8937) teacher/usage_min 0.0083 (0.0090) teacher/usage_std 0.3832 (0.3987) nleep/row_max_mean 1516.2153 (1512.9063) nleep/row_max_std 63.9773 (64.3874) nleep/row_min_mean 1493.3551 (1488.8286) lr 1.6374e-03 eta 0:07:48
epoch [16/50] batch [140/162] time 0.106 (0.086) data 0.001 (0.003) loss 1.0100 (1.1586) teacher_loss 0.1946 (0.2962) loss_zs_kd 0.0264 (0.0274) loss_oracle 0.3745 (0.4094) kd_loss 0.6149 (0.6439) acc 96.8750 (88.8616) gate/entropy 0.9847 (0.9854) gate/usage_max 0.5665 (0.5658) gate/usage_min 0.2141 (0.2142) gate/usage_std 0.1649 (0.1644) teacher/entropy 0.0248 (0.0229) teacher/usage_max 0.9245 (0.8971) teacher/usage_min 0.0006 (0.0083) teacher/usage_std 0.4191 (0.4010) nleep/row_max_mean 1517.4463 (1513.7973) nleep/row_max_std 67.3104 (64.1325) nleep/row_min_mean 1491.8745 (1489.5678) lr 1.6374e-03 eta 0:07:53
epoch [16/50] batch [160/162] time 0.087 (0.088) data 0.000 (0.002) loss 0.9905 (1.1530) teacher_loss 0.2186 (0.2913) loss_zs_kd 0.0243 (0.0274) loss_oracle 0.3557 (0.4054) kd_loss 0.5819 (0.6452) acc 93.7500 (89.0430) gate/entropy 0.9844 (0.9853) gate/usage_max 0.5668 (0.5659) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1651 (0.1644) teacher/entropy 0.0279 (0.0228) teacher/usage_max 0.9557 (0.8957) teacher/usage_min 0.0009 (0.0079) teacher/usage_std 0.4404 (0.4001) nleep/row_max_mean 1523.5388 (1513.5610) nleep/row_max_std 58.2722 (64.3918) nleep/row_min_mean 1497.9420 (1489.4641) lr 1.6374e-03 eta 0:08:02
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,922
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 86.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,251
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 68.3%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [17/50] batch [20/162] time 0.092 (0.109) data 0.000 (0.016) loss 1.1114 (1.1702) teacher_loss 0.1780 (0.2910) loss_zs_kd 0.0418 (0.0296) loss_oracle 0.4589 (0.4136) kd_loss 0.6830 (0.6577) acc 93.7500 (87.6562) gate/entropy 0.9844 (0.9845) gate/usage_max 0.5669 (0.5667) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1652 (0.1651) teacher/entropy 0.0041 (0.0204) teacher/usage_max 0.8744 (0.8839) teacher/usage_min 0.0004 (0.0078) teacher/usage_std 0.3860 (0.3923) nleep/row_max_mean 1513.3804 (1516.1123) nleep/row_max_std 70.4210 (65.0577) nleep/row_min_mean 1490.8376 (1492.4531) lr 1.5878e-03 eta 0:09:58
epoch [17/50] batch [40/162] time 0.086 (0.098) data 0.000 (0.008) loss 1.0303 (1.1571) teacher_loss 0.2279 (0.2924) loss_zs_kd 0.0291 (0.0286) loss_oracle 0.3348 (0.4010) kd_loss 0.6204 (0.6499) acc 90.6250 (87.7344) gate/entropy 0.9846 (0.9844) gate/usage_max 0.5666 (0.5668) gate/usage_min 0.2141 (0.2140) gate/usage_std 0.1650 (0.1651) teacher/entropy 0.0089 (0.0228) teacher/usage_max 0.9354 (0.8895) teacher/usage_min 0.0018 (0.0063) teacher/usage_std 0.4264 (0.3962) nleep/row_max_mean 1527.9302 (1515.1717) nleep/row_max_std 51.7132 (63.9466) nleep/row_min_mean 1501.1694 (1491.8243) lr 1.5878e-03 eta 0:08:55
epoch [17/50] batch [60/162] time 0.089 (0.095) data 0.002 (0.005) loss 1.0892 (1.1676) teacher_loss 0.2006 (0.2947) loss_zs_kd 0.0289 (0.0292) loss_oracle 0.4007 (0.4106) kd_loss 0.6738 (0.6530) acc 90.6250 (87.9167) gate/entropy 0.9844 (0.9844) gate/usage_max 0.5669 (0.5669) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1652 (0.1652) teacher/entropy 0.0185 (0.0222) teacher/usage_max 0.8686 (0.8867) teacher/usage_min 0.0061 (0.0059) teacher/usage_std 0.3816 (0.3944) nleep/row_max_mean 1513.1379 (1514.3081) nleep/row_max_std 62.9623 (64.5200) nleep/row_min_mean 1490.8279 (1491.0659) lr 1.5878e-03 eta 0:08:40
epoch [17/50] batch [80/162] time 0.084 (0.095) data 0.000 (0.004) loss 1.1284 (1.1577) teacher_loss 0.2607 (0.2889) loss_zs_kd 0.0257 (0.0291) loss_oracle 0.4291 (0.4073) kd_loss 0.6403 (0.6505) acc 87.5000 (88.3984) gate/entropy 0.9841 (0.9843) gate/usage_max 0.5671 (0.5669) gate/usage_min 0.2140 (0.2140) gate/usage_std 0.1653 (0.1652) teacher/entropy 0.0804 (0.0243) teacher/usage_max 0.8392 (0.8871) teacher/usage_min 0.0213 (0.0070) teacher/usage_std 0.3610 (0.3945) nleep/row_max_mean 1510.7229 (1514.5864) nleep/row_max_std 63.0063 (63.8724) nleep/row_min_mean 1489.6707 (1491.5385) lr 1.5878e-03 eta 0:08:32
epoch [17/50] batch [100/162] time 0.145 (0.094) data 0.000 (0.003) loss 0.9708 (1.1638) teacher_loss 0.1648 (0.2941) loss_zs_kd 0.0327 (0.0290) loss_oracle 0.3276 (0.4059) kd_loss 0.6258 (0.6523) acc 96.8750 (88.3750) gate/entropy 0.9838 (0.9842) gate/usage_max 0.5675 (0.5670) gate/usage_min 0.2139 (0.2140) gate/usage_std 0.1656 (0.1653) teacher/entropy 0.0003 (0.0264) teacher/usage_max 0.9375 (0.8830) teacher/usage_min 0.0000 (0.0082) teacher/usage_std 0.4280 (0.3916) nleep/row_max_mean 1535.5648 (1515.5416) nleep/row_max_std 48.9266 (62.7637) nleep/row_min_mean 1509.3754 (1492.5716) lr 1.5878e-03 eta 0:08:26
epoch [17/50] batch [120/162] time 0.102 (0.096) data 0.000 (0.003) loss 1.0345 (1.1572) teacher_loss 0.1914 (0.2889) loss_zs_kd 0.0292 (0.0291) loss_oracle 0.3810 (0.4048) kd_loss 0.6379 (0.6515) acc 93.7500 (88.6719) gate/entropy 0.9836 (0.9842) gate/usage_max 0.5677 (0.5671) gate/usage_min 0.2139 (0.2140) gate/usage_std 0.1657 (0.1653) teacher/entropy 0.0209 (0.0262) teacher/usage_max 0.9029 (0.8840) teacher/usage_min 0.0025 (0.0090) teacher/usage_std 0.4045 (0.3923) nleep/row_max_mean 1532.3445 (1516.1460) nleep/row_max_std 51.9448 (62.0834) nleep/row_min_mean 1506.9707 (1493.1023) lr 1.5878e-03 eta 0:08:35
epoch [17/50] batch [140/162] time 0.083 (0.095) data 0.000 (0.003) loss 1.2065 (1.1582) teacher_loss 0.3070 (0.2909) loss_zs_kd 0.0275 (0.0289) loss_oracle 0.3925 (0.4036) kd_loss 0.6895 (0.6510) acc 84.3750 (88.7054) gate/entropy 0.9836 (0.9841) gate/usage_max 0.5676 (0.5672) gate/usage_min 0.2139 (0.2140) gate/usage_std 0.1657 (0.1653) teacher/entropy 0.0189 (0.0272) teacher/usage_max 0.8518 (0.8833) teacher/usage_min 0.0232 (0.0098) teacher/usage_std 0.3690 (0.3918) nleep/row_max_mean 1517.8699 (1516.6957) nleep/row_max_std 63.6635 (61.5549) nleep/row_min_mean 1494.8835 (1493.6697) lr 1.5878e-03 eta 0:08:30
epoch [17/50] batch [160/162] time 0.084 (0.094) data 0.000 (0.002) loss 1.0529 (1.1576) teacher_loss 0.1982 (0.2913) loss_zs_kd 0.0337 (0.0288) loss_oracle 0.4653 (0.4052) kd_loss 0.6052 (0.6492) acc 90.6250 (88.9062) gate/entropy 0.9835 (0.9840) gate/usage_max 0.5678 (0.5672) gate/usage_min 0.2139 (0.2139) gate/usage_std 0.1658 (0.1654) teacher/entropy 0.0237 (0.0277) teacher/usage_max 0.9343 (0.8846) teacher/usage_min 0.0040 (0.0095) teacher/usage_std 0.4256 (0.3926) nleep/row_max_mean 1533.9236 (1516.9652) nleep/row_max_std 51.6641 (60.9864) nleep/row_min_mean 1507.3867 (1493.8583) lr 1.5878e-03 eta 0:08:23
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,916
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,242
* accuracy: 68.3%
* error: 31.7%
* macro_f1: 66.8%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [18/50] batch [20/162] time 0.086 (0.102) data 0.000 (0.014) loss 1.1455 (1.1538) teacher_loss 0.2884 (0.2720) loss_zs_kd 0.0354 (0.0300) loss_oracle 0.3984 (0.4263) kd_loss 0.6402 (0.6536) acc 93.7500 (90.6250) gate/entropy 0.9834 (0.9834) gate/usage_max 0.5678 (0.5678) gate/usage_min 0.2139 (0.2139) gate/usage_std 0.1658 (0.1658) teacher/entropy 0.0198 (0.0231) teacher/usage_max 0.9014 (0.8841) teacher/usage_min 0.0002 (0.0075) teacher/usage_std 0.4037 (0.3922) nleep/row_max_mean 1516.1262 (1517.5734) nleep/row_max_std 56.1816 (59.5177) nleep/row_min_mean 1492.8398 (1493.3277) lr 1.5358e-03 eta 0:09:05
epoch [18/50] batch [40/162] time 0.091 (0.097) data 0.000 (0.007) loss 1.0302 (1.1508) teacher_loss 0.2431 (0.2704) loss_zs_kd 0.0202 (0.0303) loss_oracle 0.3495 (0.4194) kd_loss 0.6023 (0.6555) acc 93.7500 (90.3125) gate/entropy 0.9835 (0.9834) gate/usage_max 0.5677 (0.5679) gate/usage_min 0.2139 (0.2138) gate/usage_std 0.1658 (0.1659) teacher/entropy 0.0195 (0.0244) teacher/usage_max 0.9413 (0.8808) teacher/usage_min 0.0008 (0.0085) teacher/usage_std 0.4305 (0.3899) nleep/row_max_mean 1523.7610 (1517.7208) nleep/row_max_std 50.3115 (59.5997) nleep/row_min_mean 1500.5559 (1493.2763) lr 1.5358e-03 eta 0:08:33
epoch [18/50] batch [60/162] time 0.084 (0.098) data 0.001 (0.005) loss 1.1532 (1.1696) teacher_loss 0.2454 (0.2919) loss_zs_kd 0.0304 (0.0297) loss_oracle 0.4234 (0.4168) kd_loss 0.6809 (0.6545) acc 93.7500 (89.9479) gate/entropy 0.9829 (0.9833) gate/usage_max 0.5684 (0.5679) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1662 (0.1659) teacher/entropy 0.0044 (0.0257) teacher/usage_max 0.8743 (0.8804) teacher/usage_min 0.0001 (0.0095) teacher/usage_std 0.3859 (0.3896) nleep/row_max_mean 1517.2888 (1517.2263) nleep/row_max_std 62.2598 (60.4847) nleep/row_min_mean 1490.5627 (1492.8261) lr 1.5358e-03 eta 0:08:36
epoch [18/50] batch [80/162] time 0.092 (0.096) data 0.000 (0.004) loss 0.9505 (1.1642) teacher_loss 0.1373 (0.2906) loss_zs_kd 0.0280 (0.0294) loss_oracle 0.3772 (0.4156) kd_loss 0.6107 (0.6512) acc 96.8750 (89.7656) gate/entropy 0.9832 (0.9833) gate/usage_max 0.5681 (0.5680) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1660 (0.1659) teacher/entropy 0.0219 (0.0252) teacher/usage_max 0.9299 (0.8843) teacher/usage_min 0.0069 (0.0093) teacher/usage_std 0.4225 (0.3922) nleep/row_max_mean 1518.8992 (1516.7918) nleep/row_max_std 57.4127 (60.6979) nleep/row_min_mean 1495.5706 (1492.3865) lr 1.5358e-03 eta 0:08:26
epoch [18/50] batch [100/162] time 0.089 (0.096) data 0.000 (0.003) loss 1.0618 (1.1631) teacher_loss 0.2701 (0.2918) loss_zs_kd 0.0341 (0.0294) loss_oracle 0.3610 (0.4155) kd_loss 0.5941 (0.6488) acc 90.6250 (89.0938) gate/entropy 0.9830 (0.9832) gate/usage_max 0.5683 (0.5681) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1662 (0.1660) teacher/entropy 0.0435 (0.0262) teacher/usage_max 0.9249 (0.8856) teacher/usage_min 0.0363 (0.0097) teacher/usage_std 0.4183 (0.3930) nleep/row_max_mean 1521.5352 (1516.6886) nleep/row_max_std 55.2772 (60.5132) nleep/row_min_mean 1497.5256 (1492.3257) lr 1.5358e-03 eta 0:08:25
epoch [18/50] batch [120/162] time 0.096 (0.096) data 0.000 (0.003) loss 1.0069 (1.1615) teacher_loss 0.1944 (0.2899) loss_zs_kd 0.0337 (0.0295) loss_oracle 0.3853 (0.4171) kd_loss 0.6030 (0.6483) acc 90.6250 (89.0885) gate/entropy 0.9830 (0.9832) gate/usage_max 0.5683 (0.5681) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1661 (0.1660) teacher/entropy 0.0225 (0.0274) teacher/usage_max 0.9371 (0.8849) teacher/usage_min 0.0208 (0.0106) teacher/usage_std 0.4270 (0.3925) nleep/row_max_mean 1529.7640 (1516.6661) nleep/row_max_std 56.2206 (60.3127) nleep/row_min_mean 1501.6570 (1492.1641) lr 1.5358e-03 eta 0:08:23
epoch [18/50] batch [140/162] time 0.087 (0.097) data 0.000 (0.002) loss 1.0999 (1.1506) teacher_loss 0.2507 (0.2837) loss_zs_kd 0.0211 (0.0294) loss_oracle 0.3790 (0.4119) kd_loss 0.6492 (0.6462) acc 87.5000 (89.3080) gate/entropy 0.9828 (0.9831) gate/usage_max 0.5685 (0.5682) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1663 (0.1661) teacher/entropy 0.0063 (0.0266) teacher/usage_max 0.9052 (0.8878) teacher/usage_min 0.0003 (0.0102) teacher/usage_std 0.4062 (0.3945) nleep/row_max_mean 1518.1736 (1516.9132) nleep/row_max_std 62.0168 (60.2123) nleep/row_min_mean 1493.7891 (1492.3193) lr 1.5358e-03 eta 0:08:22
epoch [18/50] batch [160/162] time 0.089 (0.096) data 0.000 (0.002) loss 1.0594 (1.1451) teacher_loss 0.1337 (0.2784) loss_zs_kd 0.0352 (0.0292) loss_oracle 0.4596 (0.4116) kd_loss 0.6782 (0.6463) acc 96.8750 (89.4922) gate/entropy 0.9826 (0.9831) gate/usage_max 0.5687 (0.5682) gate/usage_min 0.2137 (0.2138) gate/usage_std 0.1664 (0.1661) teacher/entropy 0.0072 (0.0268) teacher/usage_max 0.8742 (0.8875) teacher/usage_min 0.0010 (0.0102) teacher/usage_std 0.3857 (0.3943) nleep/row_max_mean 1519.2592 (1516.8656) nleep/row_max_std 62.3582 (60.4747) nleep/row_min_mean 1495.1982 (1492.2646) lr 1.5358e-03 eta 0:08:15
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,927
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,317
* accuracy: 70.6%
* error: 29.4%
* macro_f1: 69.8%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [19/50] batch [20/162] time 0.119 (0.141) data 0.001 (0.018) loss 0.8242 (1.1562) teacher_loss 0.0737 (0.2860) loss_zs_kd 0.0293 (0.0302) loss_oracle 0.3859 (0.4153) kd_loss 0.5429 (0.6475) acc 100.0000 (89.3750) gate/entropy 0.9827 (0.9825) gate/usage_max 0.5687 (0.5688) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1664 (0.1665) teacher/entropy 0.0588 (0.0348) teacher/usage_max 0.9618 (0.8772) teacher/usage_min 0.0031 (0.0082) teacher/usage_std 0.4446 (0.3880) nleep/row_max_mean 1526.1907 (1512.4908) nleep/row_max_std 54.5657 (64.0312) nleep/row_min_mean 1500.9058 (1488.1315) lr 1.4818e-03 eta 0:12:07
epoch [19/50] batch [40/162] time 0.108 (0.126) data 0.000 (0.010) loss 1.2611 (1.1418) teacher_loss 0.3882 (0.2777) loss_zs_kd 0.0173 (0.0287) loss_oracle 0.4021 (0.4107) kd_loss 0.6632 (0.6444) acc 87.5000 (89.6094) gate/entropy 0.9825 (0.9825) gate/usage_max 0.5688 (0.5688) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1665 (0.1665) teacher/entropy 0.0347 (0.0365) teacher/usage_max 0.8612 (0.8787) teacher/usage_min 0.0119 (0.0083) teacher/usage_std 0.3762 (0.3888) nleep/row_max_mean 1488.7565 (1512.0446) nleep/row_max_std 65.4525 (64.7517) nleep/row_min_mean 1464.6548 (1487.7271) lr 1.4818e-03 eta 0:10:46
epoch [19/50] batch [60/162] time 0.109 (0.117) data 0.003 (0.007) loss 1.0818 (1.1430) teacher_loss 0.1906 (0.2876) loss_zs_kd 0.0291 (0.0294) loss_oracle 0.4719 (0.4133) kd_loss 0.6407 (0.6340) acc 93.7500 (89.2708) gate/entropy 0.9823 (0.9825) gate/usage_max 0.5690 (0.5689) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1667 (0.1666) teacher/entropy 0.0631 (0.0376) teacher/usage_max 0.8551 (0.8883) teacher/usage_min 0.0355 (0.0102) teacher/usage_std 0.3702 (0.3950) nleep/row_max_mean 1507.6331 (1513.8440) nleep/row_max_std 70.8757 (64.5458) nleep/row_min_mean 1484.2841 (1489.2697) lr 1.4818e-03 eta 0:10:00
epoch [19/50] batch [80/162] time 0.096 (0.116) data 0.000 (0.005) loss 1.1997 (1.1443) teacher_loss 0.3449 (0.2831) loss_zs_kd 0.0361 (0.0296) loss_oracle 0.4192 (0.4206) kd_loss 0.6272 (0.6360) acc 90.6250 (89.6875) gate/entropy 0.9822 (0.9824) gate/usage_max 0.5691 (0.5689) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1667 (0.1666) teacher/entropy 0.0228 (0.0377) teacher/usage_max 0.9105 (0.8861) teacher/usage_min 0.0013 (0.0116) teacher/usage_std 0.4096 (0.3933) nleep/row_max_mean 1511.1171 (1512.5877) nleep/row_max_std 61.9091 (65.6510) nleep/row_min_mean 1486.0354 (1488.0155) lr 1.4818e-03 eta 0:09:52
epoch [19/50] batch [100/162] time 0.104 (0.113) data 0.001 (0.004) loss 1.2234 (1.1376) teacher_loss 0.2095 (0.2726) loss_zs_kd 0.0258 (0.0301) loss_oracle 0.5087 (0.4243) kd_loss 0.7467 (0.6378) acc 90.6250 (90.1250) gate/entropy 0.9823 (0.9824) gate/usage_max 0.5691 (0.5689) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1667 (0.1666) teacher/entropy 0.0456 (0.0396) teacher/usage_max 0.7643 (0.8823) teacher/usage_min 0.0910 (0.0142) teacher/usage_std 0.3055 (0.3906) nleep/row_max_mean 1490.6827 (1511.2065) nleep/row_max_std 68.5499 (66.0591) nleep/row_min_mean 1469.7600 (1486.7696) lr 1.4818e-03 eta 0:09:34
epoch [19/50] batch [120/162] time 0.068 (0.109) data 0.000 (0.003) loss 1.0736 (1.1407) teacher_loss 0.2984 (0.2746) loss_zs_kd 0.0170 (0.0299) loss_oracle 0.3965 (0.4237) kd_loss 0.5684 (0.6393) acc 93.7500 (90.1562) gate/entropy 0.9820 (0.9823) gate/usage_max 0.5693 (0.5690) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1669 (0.1666) teacher/entropy 0.0362 (0.0403) teacher/usage_max 0.9572 (0.8799) teacher/usage_min 0.0073 (0.0149) teacher/usage_std 0.4413 (0.3889) nleep/row_max_mean 1516.0732 (1510.6492) nleep/row_max_std 70.3746 (66.3746) nleep/row_min_mean 1492.0120 (1486.1897) lr 1.4818e-03 eta 0:09:12
epoch [19/50] batch [140/162] time 0.083 (0.105) data 0.000 (0.003) loss 1.4531 (1.1426) teacher_loss 0.6105 (0.2809) loss_zs_kd 0.0376 (0.0307) loss_oracle 0.3726 (0.4179) kd_loss 0.6374 (0.6373) acc 68.7500 (89.7321) gate/entropy 0.9820 (0.9823) gate/usage_max 0.5694 (0.5690) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1669 (0.1667) teacher/entropy 0.0144 (0.0396) teacher/usage_max 0.9084 (0.8826) teacher/usage_min 0.0284 (0.0150) teacher/usage_std 0.4069 (0.3908) nleep/row_max_mean 1512.5316 (1511.0724) nleep/row_max_std 60.6127 (66.0777) nleep/row_min_mean 1483.2971 (1486.4897) lr 1.4818e-03 eta 0:08:50
epoch [19/50] batch [160/162] time 0.090 (0.104) data 0.000 (0.003) loss 1.0987 (1.1459) teacher_loss 0.2094 (0.2817) loss_zs_kd 0.0218 (0.0306) loss_oracle 0.4632 (0.4185) kd_loss 0.6468 (0.6396) acc 93.7500 (89.7656) gate/entropy 0.9818 (0.9823) gate/usage_max 0.5695 (0.5691) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1670 (0.1667) teacher/entropy 0.0285 (0.0384) teacher/usage_max 0.8842 (0.8814) teacher/usage_min 0.0531 (0.0149) teacher/usage_std 0.3896 (0.3900) nleep/row_max_mean 1536.5957 (1511.3095) nleep/row_max_std 65.6331 (65.9824) nleep/row_min_mean 1508.3823 (1486.5928) lr 1.4818e-03 eta 0:08:40
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,919
* accuracy: 85.9%
* error: 14.1%
* macro_f1: 86.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,314
* accuracy: 70.5%
* error: 29.5%
* macro_f1: 69.6%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [20/50] batch [20/162] time 0.079 (0.115) data 0.000 (0.016) loss 1.0142 (1.1584) teacher_loss 0.2416 (0.3010) loss_zs_kd 0.0191 (0.0301) loss_oracle 0.3492 (0.3998) kd_loss 0.5884 (0.6424) acc 84.3750 (88.5938) gate/entropy 0.9820 (0.9819) gate/usage_max 0.5694 (0.5694) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1669 (0.1670) teacher/entropy 0.0059 (0.0191) teacher/usage_max 0.9678 (0.8979) teacher/usage_min 0.0008 (0.0039) teacher/usage_std 0.4488 (0.4017) nleep/row_max_mean 1512.9570 (1514.5220) nleep/row_max_std 64.9320 (63.2245) nleep/row_min_mean 1486.7969 (1488.0540) lr 1.4258e-03 eta 0:09:34
epoch [20/50] batch [40/162] time 0.098 (0.100) data 0.000 (0.008) loss 1.0519 (1.1539) teacher_loss 0.2676 (0.3031) loss_zs_kd 0.0292 (0.0278) loss_oracle 0.3546 (0.3983) kd_loss 0.5924 (0.6378) acc 90.6250 (88.5938) gate/entropy 0.9817 (0.9819) gate/usage_max 0.5697 (0.5695) gate/usage_min 0.2135 (0.2136) gate/usage_std 0.1671 (0.1670) teacher/entropy 0.0007 (0.0222) teacher/usage_max 0.9687 (0.8996) teacher/usage_min 0.0001 (0.0065) teacher/usage_std 0.4494 (0.4026) nleep/row_max_mean 1533.9679 (1512.0463) nleep/row_max_std 54.3965 (65.4538) nleep/row_min_mean 1504.9127 (1485.7387) lr 1.4258e-03 eta 0:08:20
epoch [20/50] batch [60/162] time 0.086 (0.097) data 0.001 (0.006) loss 1.1004 (1.1529) teacher_loss 0.1865 (0.3056) loss_zs_kd 0.0306 (0.0282) loss_oracle 0.3766 (0.3958) kd_loss 0.7103 (0.6352) acc 93.7500 (88.2292) gate/entropy 0.9818 (0.9818) gate/usage_max 0.5695 (0.5695) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1670 (0.1670) teacher/entropy 0.0040 (0.0222) teacher/usage_max 0.8431 (0.9022) teacher/usage_min 0.0003 (0.0070) teacher/usage_std 0.3661 (0.4043) nleep/row_max_mean 1505.1243 (1511.7445) nleep/row_max_std 70.3563 (66.0378) nleep/row_min_mean 1479.6873 (1485.4816) lr 1.4258e-03 eta 0:08:00
epoch [20/50] batch [80/162] time 0.085 (0.094) data 0.000 (0.004) loss 1.1825 (1.1563) teacher_loss 0.2986 (0.3036) loss_zs_kd 0.0294 (0.0286) loss_oracle 0.4078 (0.4035) kd_loss 0.6653 (0.6367) acc 96.8750 (88.2812) gate/entropy 0.9817 (0.9818) gate/usage_max 0.5697 (0.5696) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1671 (0.1671) teacher/entropy 0.0507 (0.0236) teacher/usage_max 0.8409 (0.8992) teacher/usage_min 0.0049 (0.0087) teacher/usage_std 0.3640 (0.4021) nleep/row_max_mean 1514.0483 (1511.9776) nleep/row_max_std 74.8776 (66.1676) nleep/row_min_mean 1487.7577 (1485.5465) lr 1.4258e-03 eta 0:07:44
epoch [20/50] batch [100/162] time 0.081 (0.091) data 0.000 (0.003) loss 1.1395 (1.1570) teacher_loss 0.2908 (0.2965) loss_zs_kd 0.0352 (0.0285) loss_oracle 0.4285 (0.4078) kd_loss 0.6169 (0.6423) acc 87.5000 (88.3750) gate/entropy 0.9814 (0.9817) gate/usage_max 0.5699 (0.5696) gate/usage_min 0.2135 (0.2136) gate/usage_std 0.1673 (0.1671) teacher/entropy 0.0293 (0.0213) teacher/usage_max 0.9133 (0.8956) teacher/usage_min 0.0248 (0.0093) teacher/usage_std 0.4104 (0.3999) nleep/row_max_mean 1510.6707 (1512.0931) nleep/row_max_std 69.4747 (65.8426) nleep/row_min_mean 1486.2864 (1485.5393) lr 1.4258e-03 eta 0:07:30
epoch [20/50] batch [120/162] time 0.088 (0.091) data 0.000 (0.003) loss 1.1548 (1.1631) teacher_loss 0.3189 (0.3028) loss_zs_kd 0.0201 (0.0282) loss_oracle 0.4330 (0.4099) kd_loss 0.6093 (0.6413) acc 87.5000 (88.3073) gate/entropy 0.9815 (0.9817) gate/usage_max 0.5699 (0.5697) gate/usage_min 0.2135 (0.2136) gate/usage_std 0.1673 (0.1671) teacher/entropy 0.0161 (0.0213) teacher/usage_max 0.9348 (0.8967) teacher/usage_min 0.0037 (0.0089) teacher/usage_std 0.4260 (0.4006) nleep/row_max_mean 1521.1140 (1513.0164) nleep/row_max_std 63.6779 (65.5011) nleep/row_min_mean 1493.3678 (1486.3728) lr 1.4258e-03 eta 0:07:24
epoch [20/50] batch [140/162] time 0.157 (0.092) data 0.002 (0.003) loss 1.4047 (1.1617) teacher_loss 0.4506 (0.3025) loss_zs_kd 0.0242 (0.0281) loss_oracle 0.4942 (0.4107) kd_loss 0.6949 (0.6398) acc 75.0000 (88.3705) gate/entropy 0.9814 (0.9816) gate/usage_max 0.5700 (0.5697) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1673 (0.1671) teacher/entropy 0.0223 (0.0219) teacher/usage_max 0.8401 (0.8976) teacher/usage_min 0.0053 (0.0093) teacher/usage_std 0.3635 (0.4012) nleep/row_max_mean 1493.8877 (1512.5638) nleep/row_max_std 72.1597 (65.9513) nleep/row_min_mean 1468.3425 (1486.0067) lr 1.4258e-03 eta 0:07:31
epoch [20/50] batch [160/162] time 0.080 (0.092) data 0.000 (0.002) loss 1.3586 (1.1623) teacher_loss 0.3520 (0.3010) loss_zs_kd 0.0457 (0.0284) loss_oracle 0.4871 (0.4142) kd_loss 0.7403 (0.6400) acc 87.5000 (88.3789) gate/entropy 0.9813 (0.9816) gate/usage_max 0.5700 (0.5697) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1674 (0.1672) teacher/entropy 0.0038 (0.0218) teacher/usage_max 0.8120 (0.8974) teacher/usage_min 0.0003 (0.0094) teacher/usage_std 0.3470 (0.4010) nleep/row_max_mean 1498.8235 (1512.5705) nleep/row_max_std 71.1053 (65.9763) nleep/row_min_mean 1473.2991 (1485.9873) lr 1.4258e-03 eta 0:07:28
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,926
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,320
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 68.5%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [21/50] batch [20/162] time 0.122 (0.115) data 0.001 (0.013) loss 1.0225 (1.1595) teacher_loss 0.1650 (0.2981) loss_zs_kd 0.0145 (0.0240) loss_oracle 0.4264 (0.4360) kd_loss 0.6370 (0.6314) acc 93.7500 (88.4375) gate/entropy 0.9812 (0.9813) gate/usage_max 0.5702 (0.5701) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1675 (0.1674) teacher/entropy 0.0220 (0.0300) teacher/usage_max 0.8993 (0.8975) teacher/usage_min 0.0071 (0.0168) teacher/usage_std 0.4018 (0.4007) nleep/row_max_mean 1522.1945 (1513.6765) nleep/row_max_std 72.2224 (65.0646) nleep/row_min_mean 1494.3262 (1487.6046) lr 1.3681e-03 eta 0:09:14
epoch [21/50] batch [40/162] time 0.098 (0.112) data 0.000 (0.007) loss 1.3618 (1.1686) teacher_loss 0.4051 (0.2929) loss_zs_kd 0.0492 (0.0263) loss_oracle 0.4830 (0.4413) kd_loss 0.6906 (0.6419) acc 84.3750 (88.8281) gate/entropy 0.9813 (0.9813) gate/usage_max 0.5701 (0.5701) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1674 (0.1674) teacher/entropy 0.0681 (0.0309) teacher/usage_max 0.7970 (0.8856) teacher/usage_min 0.0419 (0.0191) teacher/usage_std 0.3314 (0.3923) nleep/row_max_mean 1500.4995 (1512.0560) nleep/row_max_std 72.9220 (66.2799) nleep/row_min_mean 1478.7336 (1486.6889) lr 1.3681e-03 eta 0:09:00
epoch [21/50] batch [60/162] time 0.096 (0.107) data 0.001 (0.004) loss 1.1908 (1.1678) teacher_loss 0.3147 (0.2863) loss_zs_kd 0.0405 (0.0273) loss_oracle 0.4780 (0.4533) kd_loss 0.6168 (0.6412) acc 90.6250 (89.2188) gate/entropy 0.9812 (0.9812) gate/usage_max 0.5702 (0.5701) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1675 (0.1674) teacher/entropy 0.0066 (0.0289) teacher/usage_max 0.9362 (0.8883) teacher/usage_min 0.0004 (0.0168) teacher/usage_std 0.4271 (0.3943) nleep/row_max_mean 1519.6646 (1512.3984) nleep/row_max_std 58.1597 (66.2044) nleep/row_min_mean 1492.3346 (1486.9147) lr 1.3681e-03 eta 0:08:34
epoch [21/50] batch [80/162] time 0.069 (0.103) data 0.000 (0.003) loss 1.1701 (1.1583) teacher_loss 0.1925 (0.2788) loss_zs_kd 0.0255 (0.0270) loss_oracle 0.4687 (0.4534) kd_loss 0.7304 (0.6393) acc 96.8750 (89.5312) gate/entropy 0.9811 (0.9812) gate/usage_max 0.5703 (0.5702) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1675 (0.1675) teacher/entropy 0.0156 (0.0293) teacher/usage_max 0.8095 (0.8899) teacher/usage_min 0.0035 (0.0156) teacher/usage_std 0.3450 (0.3954) nleep/row_max_mean 1507.1086 (1512.8413) nleep/row_max_std 64.5710 (65.9166) nleep/row_min_mean 1482.4615 (1487.3815) lr 1.3681e-03 eta 0:08:13
epoch [21/50] batch [100/162] time 0.097 (0.101) data 0.000 (0.003) loss 1.3494 (1.1615) teacher_loss 0.4728 (0.2837) loss_zs_kd 0.0298 (0.0279) loss_oracle 0.3645 (0.4491) kd_loss 0.6795 (0.6392) acc 84.3750 (89.4062) gate/entropy 0.9809 (0.9812) gate/usage_max 0.5704 (0.5702) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1677 (0.1675) teacher/entropy 0.0312 (0.0282) teacher/usage_max 0.8461 (0.8910) teacher/usage_min 0.0001 (0.0141) teacher/usage_std 0.3680 (0.3963) nleep/row_max_mean 1520.6730 (1513.6414) nleep/row_max_std 52.2856 (64.5559) nleep/row_min_mean 1495.4650 (1488.0487) lr 1.3681e-03 eta 0:08:01
epoch [21/50] batch [120/162] time 0.094 (0.100) data 0.000 (0.002) loss 1.0821 (1.1645) teacher_loss 0.2137 (0.2829) loss_zs_kd 0.0286 (0.0283) loss_oracle 0.4159 (0.4482) kd_loss 0.6462 (0.6434) acc 90.6250 (89.5052) gate/entropy 0.9808 (0.9811) gate/usage_max 0.5705 (0.5702) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1677 (0.1675) teacher/entropy 0.0080 (0.0296) teacher/usage_max 0.9044 (0.8853) teacher/usage_min 0.0001 (0.0139) teacher/usage_std 0.4057 (0.3926) nleep/row_max_mean 1514.3738 (1512.7225) nleep/row_max_std 62.0605 (64.4145) nleep/row_min_mean 1490.4297 (1487.2248) lr 1.3681e-03 eta 0:07:55
epoch [21/50] batch [140/162] time 0.088 (0.099) data 0.000 (0.002) loss 1.3164 (1.1673) teacher_loss 0.2931 (0.2845) loss_zs_kd 0.0356 (0.0286) loss_oracle 0.6443 (0.4493) kd_loss 0.6833 (0.6438) acc 87.5000 (89.3527) gate/entropy 0.9811 (0.9811) gate/usage_max 0.5703 (0.5703) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1676 (0.1675) teacher/entropy 0.0782 (0.0292) teacher/usage_max 0.7945 (0.8852) teacher/usage_min 0.0242 (0.0129) teacher/usage_std 0.3323 (0.3927) nleep/row_max_mean 1497.0063 (1512.6149) nleep/row_max_std 54.0189 (64.0893) nleep/row_min_mean 1473.2708 (1486.9639) lr 1.3681e-03 eta 0:07:49
epoch [21/50] batch [160/162] time 0.087 (0.099) data 0.001 (0.002) loss 1.0311 (1.1695) teacher_loss 0.1114 (0.2868) loss_zs_kd 0.0266 (0.0289) loss_oracle 0.4484 (0.4494) kd_loss 0.6823 (0.6435) acc 96.8750 (89.1992) gate/entropy 0.9807 (0.9811) gate/usage_max 0.5706 (0.5703) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1678 (0.1676) teacher/entropy 0.0002 (0.0289) teacher/usage_max 0.8750 (0.8857) teacher/usage_min 0.0000 (0.0120) teacher/usage_std 0.3864 (0.3931) nleep/row_max_mean 1529.5422 (1512.6505) nleep/row_max_std 54.4888 (63.7168) nleep/row_min_mean 1501.8630 (1486.9774) lr 1.3681e-03 eta 0:07:43
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,919
* accuracy: 85.9%
* error: 14.1%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,365
* accuracy: 72.1%
* error: 27.9%
* macro_f1: 70.4%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [22/50] batch [20/162] time 0.120 (0.142) data 0.000 (0.023) loss 1.3359 (1.1087) teacher_loss 0.4673 (0.2838) loss_zs_kd 0.0262 (0.0248) loss_oracle 0.4768 (0.4024) kd_loss 0.6171 (0.6113) acc 81.2500 (89.0625) gate/entropy 0.9810 (0.9808) gate/usage_max 0.5703 (0.5706) gate/usage_min 0.2135 (0.2134) gate/usage_std 0.1676 (0.1677) teacher/entropy 0.0680 (0.0321) teacher/usage_max 0.8730 (0.9153) teacher/usage_min 0.0612 (0.0087) teacher/usage_std 0.3816 (0.4130) nleep/row_max_mean 1510.5142 (1517.5342) nleep/row_max_std 59.8224 (59.4108) nleep/row_min_mean 1485.2540 (1491.6595) lr 1.3090e-03 eta 0:11:04
epoch [22/50] batch [40/162] time 0.086 (0.132) data 0.000 (0.012) loss 1.4266 (1.1202) teacher_loss 0.4895 (0.2855) loss_zs_kd 0.0414 (0.0254) loss_oracle 0.4399 (0.4073) kd_loss 0.6965 (0.6184) acc 78.1250 (88.9062) gate/entropy 0.9808 (0.9808) gate/usage_max 0.5706 (0.5706) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1678 (0.1678) teacher/entropy 0.0211 (0.0285) teacher/usage_max 0.8387 (0.9116) teacher/usage_min 0.0009 (0.0069) teacher/usage_std 0.3633 (0.4106) nleep/row_max_mean 1498.6155 (1516.2059) nleep/row_max_std 70.1320 (61.6473) nleep/row_min_mean 1474.8071 (1490.2755) lr 1.3090e-03 eta 0:10:15
epoch [22/50] batch [60/162] time 0.112 (0.125) data 0.002 (0.008) loss 1.0006 (1.1410) teacher_loss 0.2012 (0.2933) loss_zs_kd 0.0203 (0.0249) loss_oracle 0.3680 (0.4209) kd_loss 0.6052 (0.6248) acc 93.7500 (88.9583) gate/entropy 0.9806 (0.9807) gate/usage_max 0.5708 (0.5706) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1679 (0.1678) teacher/entropy 0.0276 (0.0309) teacher/usage_max 0.9260 (0.9025) teacher/usage_min 0.0102 (0.0074) teacher/usage_std 0.4196 (0.4047) nleep/row_max_mean 1516.8010 (1514.8179) nleep/row_max_std 72.8936 (63.4901) nleep/row_min_mean 1489.7180 (1489.0704) lr 1.3090e-03 eta 0:09:37
epoch [22/50] batch [80/162] time 0.112 (0.121) data 0.001 (0.006) loss 1.0423 (1.1590) teacher_loss 0.1965 (0.2935) loss_zs_kd 0.0111 (0.0263) loss_oracle 0.4687 (0.4327) kd_loss 0.6059 (0.6360) acc 93.7500 (89.2578) gate/entropy 0.9806 (0.9807) gate/usage_max 0.5707 (0.5706) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1679 (0.1678) teacher/entropy 0.0948 (0.0328) teacher/usage_max 0.8567 (0.8890) teacher/usage_min 0.0559 (0.0094) teacher/usage_std 0.3703 (0.3959) nleep/row_max_mean 1519.1520 (1513.1995) nleep/row_max_std 62.7413 (64.8229) nleep/row_min_mean 1493.3475 (1487.7453) lr 1.3090e-03 eta 0:09:18
epoch [22/50] batch [100/162] time 0.085 (0.117) data 0.000 (0.005) loss 1.0757 (1.1625) teacher_loss 0.2325 (0.2951) loss_zs_kd 0.0206 (0.0280) loss_oracle 0.4527 (0.4349) kd_loss 0.6066 (0.6360) acc 90.6250 (88.8438) gate/entropy 0.9805 (0.9807) gate/usage_max 0.5709 (0.5707) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1680 (0.1678) teacher/entropy 0.0163 (0.0336) teacher/usage_max 0.9361 (0.8882) teacher/usage_min 0.0311 (0.0100) teacher/usage_std 0.4262 (0.3953) nleep/row_max_mean 1532.5322 (1512.8173) nleep/row_max_std 58.5214 (65.0255) nleep/row_min_mean 1504.8650 (1487.5069) lr 1.3090e-03 eta 0:08:59
epoch [22/50] batch [120/162] time 0.097 (0.114) data 0.000 (0.004) loss 1.2746 (1.1661) teacher_loss 0.3217 (0.2932) loss_zs_kd 0.0147 (0.0282) loss_oracle 0.5873 (0.4410) kd_loss 0.6520 (0.6383) acc 84.3750 (88.9583) gate/entropy 0.9806 (0.9807) gate/usage_max 0.5708 (0.5707) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1679 (0.1678) teacher/entropy 0.0648 (0.0343) teacher/usage_max 0.8397 (0.8851) teacher/usage_min 0.0552 (0.0110) teacher/usage_std 0.3587 (0.3931) nleep/row_max_mean 1519.1384 (1511.7224) nleep/row_max_std 71.9221 (65.3229) nleep/row_min_mean 1492.3048 (1486.6258) lr 1.3090e-03 eta 0:08:40
epoch [22/50] batch [140/162] time 0.104 (0.111) data 0.000 (0.004) loss 1.2347 (1.1595) teacher_loss 0.2910 (0.2853) loss_zs_kd 0.0392 (0.0286) loss_oracle 0.4960 (0.4414) kd_loss 0.6761 (0.6391) acc 78.1250 (89.0625) gate/entropy 0.9805 (0.9807) gate/usage_max 0.5709 (0.5707) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1680 (0.1679) teacher/entropy 0.0498 (0.0324) teacher/usage_max 0.8304 (0.8862) teacher/usage_min 0.0199 (0.0109) teacher/usage_std 0.3554 (0.3938) nleep/row_max_mean 1515.3771 (1512.5686) nleep/row_max_std 66.8012 (65.2160) nleep/row_min_mean 1489.3081 (1487.2545) lr 1.3090e-03 eta 0:08:26
epoch [22/50] batch [160/162] time 0.087 (0.109) data 0.000 (0.003) loss 1.1568 (1.1638) teacher_loss 0.2062 (0.2886) loss_zs_kd 0.0244 (0.0287) loss_oracle 0.5488 (0.4434) kd_loss 0.6640 (0.6392) acc 93.7500 (89.0039) gate/entropy 0.9805 (0.9806) gate/usage_max 0.5708 (0.5707) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1680 (0.1679) teacher/entropy 0.0217 (0.0320) teacher/usage_max 0.8716 (0.8865) teacher/usage_min 0.0327 (0.0112) teacher/usage_std 0.3815 (0.3939) nleep/row_max_mean 1510.8530 (1512.7572) nleep/row_max_std 67.8182 (64.6198) nleep/row_min_mean 1484.7185 (1487.3179) lr 1.3090e-03 eta 0:08:14
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,935
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,376
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 71.0%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [23/50] batch [20/162] time 0.079 (0.111) data 0.000 (0.017) loss 1.1120 (1.1525) teacher_loss 0.2891 (0.2508) loss_zs_kd 0.0154 (0.0300) loss_oracle 0.4295 (0.4661) kd_loss 0.6004 (0.6536) acc 81.2500 (91.0938) gate/entropy 0.9804 (0.9804) gate/usage_max 0.5710 (0.5710) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1681 (0.1680) teacher/entropy 0.0325 (0.0240) teacher/usage_max 0.9257 (0.8796) teacher/usage_min 0.0098 (0.0090) teacher/usage_std 0.4195 (0.3895) nleep/row_max_mean 1503.1746 (1514.4760) nleep/row_max_std 66.6614 (60.3065) nleep/row_min_mean 1480.0222 (1487.7214) lr 1.2487e-03 eta 0:08:20
epoch [23/50] batch [40/162] time 0.101 (0.098) data 0.000 (0.008) loss 1.2597 (1.1897) teacher_loss 0.2873 (0.3011) loss_zs_kd 0.0205 (0.0293) loss_oracle 0.5550 (0.4551) kd_loss 0.6848 (0.6464) acc 87.5000 (88.9062) gate/entropy 0.9805 (0.9804) gate/usage_max 0.5709 (0.5710) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1680 (0.1680) teacher/entropy 0.0495 (0.0237) teacher/usage_max 0.8218 (0.8873) teacher/usage_min 0.0467 (0.0100) teacher/usage_std 0.3472 (0.3943) nleep/row_max_mean 1502.2534 (1513.3965) nleep/row_max_std 62.8192 (61.1740) nleep/row_min_mean 1477.6318 (1486.7305) lr 1.2487e-03 eta 0:07:21
epoch [23/50] batch [60/162] time 0.084 (0.095) data 0.001 (0.006) loss 1.0347 (1.1891) teacher_loss 0.1932 (0.3001) loss_zs_kd 0.0243 (0.0272) loss_oracle 0.4000 (0.4568) kd_loss 0.6293 (0.6470) acc 96.8750 (89.0104) gate/entropy 0.9802 (0.9804) gate/usage_max 0.5711 (0.5710) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1682 (0.1681) teacher/entropy 0.0262 (0.0239) teacher/usage_max 0.9021 (0.8865) teacher/usage_min 0.0045 (0.0126) teacher/usage_std 0.4038 (0.3934) nleep/row_max_mean 1519.1415 (1514.0599) nleep/row_max_std 60.9289 (60.2871) nleep/row_min_mean 1491.9788 (1487.5458) lr 1.2487e-03 eta 0:07:06
epoch [23/50] batch [80/162] time 0.089 (0.094) data 0.000 (0.004) loss 1.1990 (1.1903) teacher_loss 0.2383 (0.3061) loss_zs_kd 0.0450 (0.0271) loss_oracle 0.5202 (0.4565) kd_loss 0.6781 (0.6424) acc 90.6250 (88.8672) gate/entropy 0.9803 (0.9804) gate/usage_max 0.5711 (0.5710) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1681 (0.1681) teacher/entropy 0.0044 (0.0248) teacher/usage_max 0.8743 (0.8902) teacher/usage_min 0.0005 (0.0122) teacher/usage_std 0.3859 (0.3960) nleep/row_max_mean 1509.9717 (1513.3015) nleep/row_max_std 60.2159 (60.9343) nleep/row_min_mean 1478.3325 (1486.8484) lr 1.2487e-03 eta 0:06:57
epoch [23/50] batch [100/162] time 0.079 (0.093) data 0.000 (0.004) loss 1.1909 (1.1873) teacher_loss 0.3273 (0.3003) loss_zs_kd 0.0447 (0.0275) loss_oracle 0.5035 (0.4602) kd_loss 0.5895 (0.6432) acc 90.6250 (88.9688) gate/entropy 0.9802 (0.9804) gate/usage_max 0.5712 (0.5710) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1682 (0.1681) teacher/entropy 0.0464 (0.0259) teacher/usage_max 0.9219 (0.8884) teacher/usage_min 0.0049 (0.0120) teacher/usage_std 0.4171 (0.3948) nleep/row_max_mean 1513.8781 (1513.4194) nleep/row_max_std 60.1138 (61.1327) nleep/row_min_mean 1486.1450 (1487.0990) lr 1.2487e-03 eta 0:06:51
epoch [23/50] batch [120/162] time 0.098 (0.094) data 0.000 (0.003) loss 1.0017 (1.1774) teacher_loss 0.1856 (0.2930) loss_zs_kd 0.0224 (0.0279) loss_oracle 0.4581 (0.4595) kd_loss 0.5758 (0.6407) acc 90.6250 (89.0365) gate/entropy 0.9803 (0.9803) gate/usage_max 0.5711 (0.5711) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1682 (0.1681) teacher/entropy 0.0873 (0.0248) teacher/usage_max 0.8944 (0.8920) teacher/usage_min 0.0147 (0.0115) teacher/usage_std 0.3980 (0.3972) nleep/row_max_mean 1502.6896 (1514.2613) nleep/row_max_std 73.6338 (60.6175) nleep/row_min_mean 1479.5477 (1488.0093) lr 1.2487e-03 eta 0:06:53
epoch [23/50] batch [140/162] time 0.105 (0.095) data 0.000 (0.003) loss 1.0635 (1.1688) teacher_loss 0.2145 (0.2880) loss_zs_kd 0.0252 (0.0286) loss_oracle 0.3847 (0.4546) kd_loss 0.6441 (0.6392) acc 96.8750 (89.0848) gate/entropy 0.9802 (0.9803) gate/usage_max 0.5712 (0.5711) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1682 (0.1681) teacher/entropy 0.0102 (0.0256) teacher/usage_max 0.9034 (0.8926) teacher/usage_min 0.0001 (0.0122) teacher/usage_std 0.4050 (0.3976) nleep/row_max_mean 1517.2966 (1514.6128) nleep/row_max_std 57.5849 (60.1806) nleep/row_min_mean 1490.5010 (1488.3997) lr 1.2487e-03 eta 0:06:56
epoch [23/50] batch [160/162] time 0.092 (0.096) data 0.000 (0.002) loss 1.2820 (1.1657) teacher_loss 0.3033 (0.2869) loss_zs_kd 0.0253 (0.0287) loss_oracle 0.4925 (0.4519) kd_loss 0.7198 (0.6385) acc 87.5000 (89.0430) gate/entropy 0.9802 (0.9803) gate/usage_max 0.5712 (0.5711) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1682 (0.1681) teacher/entropy 0.0308 (0.0264) teacher/usage_max 0.8044 (0.8925) teacher/usage_min 0.0081 (0.0117) teacher/usage_std 0.3411 (0.3975) nleep/row_max_mean 1511.0896 (1514.5105) nleep/row_max_std 56.4214 (60.0643) nleep/row_min_mean 1486.9612 (1488.3970) lr 1.2487e-03 eta 0:07:01
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,933
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,316
* accuracy: 70.6%
* error: 29.4%
* macro_f1: 68.8%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [24/50] batch [20/162] time 0.097 (0.112) data 0.000 (0.013) loss 1.2801 (1.1375) teacher_loss 0.3846 (0.2736) loss_zs_kd 0.0288 (0.0305) loss_oracle 0.4942 (0.4409) kd_loss 0.6341 (0.6282) acc 81.2500 (88.9062) gate/entropy 0.9801 (0.9801) gate/usage_max 0.5713 (0.5713) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1683 (0.1683) teacher/entropy 0.0183 (0.0383) teacher/usage_max 0.9054 (0.8907) teacher/usage_min 0.0317 (0.0152) teacher/usage_std 0.4047 (0.3963) nleep/row_max_mean 1519.2625 (1515.5393) nleep/row_max_std 59.9779 (59.1651) nleep/row_min_mean 1492.7288 (1490.4020) lr 1.1874e-03 eta 0:08:09
epoch [24/50] batch [40/162] time 0.094 (0.106) data 0.000 (0.006) loss 1.0607 (1.1585) teacher_loss 0.1959 (0.2943) loss_zs_kd 0.0261 (0.0291) loss_oracle 0.4250 (0.4439) kd_loss 0.6392 (0.6277) acc 90.6250 (87.5000) gate/entropy 0.9801 (0.9801) gate/usage_max 0.5713 (0.5713) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1683 (0.1683) teacher/entropy 0.0519 (0.0401) teacher/usage_max 0.8653 (0.8894) teacher/usage_min 0.0143 (0.0180) teacher/usage_std 0.3786 (0.3950) nleep/row_max_mean 1520.1274 (1514.0561) nleep/row_max_std 54.5445 (60.4398) nleep/row_min_mean 1494.9747 (1488.9363) lr 1.1874e-03 eta 0:07:39
epoch [24/50] batch [60/162] time 0.097 (0.103) data 0.001 (0.004) loss 1.1535 (1.1655) teacher_loss 0.3318 (0.3012) loss_zs_kd 0.0198 (0.0285) loss_oracle 0.4598 (0.4451) kd_loss 0.5819 (0.6275) acc 81.2500 (87.2917) gate/entropy 0.9801 (0.9801) gate/usage_max 0.5713 (0.5713) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1683 (0.1683) teacher/entropy 0.0102 (0.0389) teacher/usage_max 0.9669 (0.8909) teacher/usage_min 0.0012 (0.0189) teacher/usage_std 0.4481 (0.3960) nleep/row_max_mean 1514.3000 (1513.4388) nleep/row_max_std 67.1383 (60.8359) nleep/row_min_mean 1490.5911 (1488.4071) lr 1.1874e-03 eta 0:07:23
epoch [24/50] batch [80/162] time 0.190 (0.102) data 0.001 (0.003) loss 1.2013 (1.1713) teacher_loss 0.2889 (0.2999) loss_zs_kd 0.0395 (0.0277) loss_oracle 0.4661 (0.4490) kd_loss 0.6596 (0.6331) acc 84.3750 (87.8516) gate/entropy 0.9800 (0.9801) gate/usage_max 0.5714 (0.5713) gate/usage_min 0.2132 (0.2133) gate/usage_std 0.1684 (0.1683) teacher/entropy 0.0545 (0.0385) teacher/usage_max 0.8420 (0.8855) teacher/usage_min 0.0236 (0.0197) teacher/usage_std 0.3625 (0.3924) nleep/row_max_mean 1504.8860 (1513.2730) nleep/row_max_std 65.9527 (60.7927) nleep/row_min_mean 1479.3518 (1488.2421) lr 1.1874e-03 eta 0:07:16
epoch [24/50] batch [100/162] time 0.100 (0.100) data 0.000 (0.003) loss 1.3157 (1.1672) teacher_loss 0.4090 (0.2941) loss_zs_kd 0.0183 (0.0274) loss_oracle 0.4595 (0.4488) kd_loss 0.6678 (0.6350) acc 81.2500 (88.1250) gate/entropy 0.9798 (0.9800) gate/usage_max 0.5716 (0.5714) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1684 (0.1683) teacher/entropy 0.0164 (0.0360) teacher/usage_max 0.8719 (0.8860) teacher/usage_min 0.0020 (0.0192) teacher/usage_std 0.3842 (0.3927) nleep/row_max_mean 1511.9330 (1513.8250) nleep/row_max_std 67.3043 (60.7622) nleep/row_min_mean 1488.6066 (1488.6151) lr 1.1874e-03 eta 0:07:05
epoch [24/50] batch [120/162] time 0.097 (0.098) data 0.000 (0.002) loss 1.4204 (1.1735) teacher_loss 0.4784 (0.2971) loss_zs_kd 0.0280 (0.0278) loss_oracle 0.4731 (0.4523) kd_loss 0.6915 (0.6363) acc 84.3750 (88.0990) gate/entropy 0.9799 (0.9800) gate/usage_max 0.5715 (0.5714) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1684 (0.1683) teacher/entropy 0.0366 (0.0367) teacher/usage_max 0.8274 (0.8841) teacher/usage_min 0.0025 (0.0195) teacher/usage_std 0.3560 (0.3914) nleep/row_max_mean 1509.4941 (1513.7776) nleep/row_max_std 52.3755 (60.4316) nleep/row_min_mean 1484.3252 (1488.4156) lr 1.1874e-03 eta 0:06:58
epoch [24/50] batch [140/162] time 0.092 (0.098) data 0.000 (0.002) loss 1.1570 (1.1726) teacher_loss 0.3191 (0.2957) loss_zs_kd 0.0391 (0.0276) loss_oracle 0.4134 (0.4534) kd_loss 0.6117 (0.6364) acc 90.6250 (88.3705) gate/entropy 0.9798 (0.9800) gate/usage_max 0.5716 (0.5714) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1685 (0.1683) teacher/entropy 0.0304 (0.0351) teacher/usage_max 0.9155 (0.8855) teacher/usage_min 0.0181 (0.0188) teacher/usage_std 0.4121 (0.3924) nleep/row_max_mean 1520.9019 (1513.8098) nleep/row_max_std 57.0581 (60.5459) nleep/row_min_mean 1492.5577 (1488.2077) lr 1.1874e-03 eta 0:06:55
epoch [24/50] batch [160/162] time 0.087 (0.097) data 0.000 (0.002) loss 1.0831 (1.1778) teacher_loss 0.2415 (0.2986) loss_zs_kd 0.0180 (0.0276) loss_oracle 0.4643 (0.4565) kd_loss 0.6005 (0.6372) acc 93.7500 (88.3398) gate/entropy 0.9798 (0.9800) gate/usage_max 0.5716 (0.5714) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1685 (0.1684) teacher/entropy 0.0185 (0.0341) teacher/usage_max 0.9392 (0.8857) teacher/usage_min 0.0295 (0.0198) teacher/usage_std 0.4284 (0.3924) nleep/row_max_mean 1517.2626 (1514.4091) nleep/row_max_std 68.7685 (60.4234) nleep/row_min_mean 1487.7080 (1488.5200) lr 1.1874e-03 eta 0:06:46
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,931
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,292
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 67.2%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [25/50] batch [20/162] time 0.099 (0.110) data 0.000 (0.013) loss 1.5640 (1.1823) teacher_loss 0.6942 (0.3148) loss_zs_kd 0.0239 (0.0237) loss_oracle 0.4584 (0.4556) kd_loss 0.6287 (0.6279) acc 81.2500 (87.8125) gate/entropy 0.9799 (0.9798) gate/usage_max 0.5715 (0.5716) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1684 (0.1685) teacher/entropy 0.0366 (0.0287) teacher/usage_max 0.8916 (0.9004) teacher/usage_min 0.0257 (0.0115) teacher/usage_std 0.3955 (0.4028) nleep/row_max_mean 1497.2512 (1515.6227) nleep/row_max_std 73.0321 (62.9330) nleep/row_min_mean 1471.0563 (1488.0694) lr 1.1253e-03 eta 0:07:39
epoch [25/50] batch [40/162] time 0.100 (0.100) data 0.000 (0.007) loss 1.0411 (1.1826) teacher_loss 0.2190 (0.3187) loss_zs_kd 0.0223 (0.0250) loss_oracle 0.4673 (0.4555) kd_loss 0.5773 (0.6237) acc 84.3750 (87.5000) gate/entropy 0.9798 (0.9798) gate/usage_max 0.5716 (0.5716) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0102 (0.0212) teacher/usage_max 0.9714 (0.9125) teacher/usage_min 0.0002 (0.0092) teacher/usage_std 0.4513 (0.4109) nleep/row_max_mean 1521.0371 (1513.6332) nleep/row_max_std 63.3517 (64.4688) nleep/row_min_mean 1490.7588 (1486.0264) lr 1.1253e-03 eta 0:06:58
epoch [25/50] batch [60/162] time 0.083 (0.099) data 0.001 (0.004) loss 1.1116 (1.1896) teacher_loss 0.1461 (0.3139) loss_zs_kd 0.0277 (0.0269) loss_oracle 0.5048 (0.4619) kd_loss 0.6993 (0.6313) acc 93.7500 (87.5521) gate/entropy 0.9798 (0.9798) gate/usage_max 0.5716 (0.5716) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0222 (0.0206) teacher/usage_max 0.8339 (0.9052) teacher/usage_min 0.0005 (0.0099) teacher/usage_std 0.3603 (0.4063) nleep/row_max_mean 1521.0183 (1512.7465) nleep/row_max_std 58.0946 (64.4465) nleep/row_min_mean 1493.3397 (1485.0593) lr 1.1253e-03 eta 0:06:52
epoch [25/50] batch [80/162] time 0.094 (0.103) data 0.000 (0.003) loss 0.9863 (1.1776) teacher_loss 0.0872 (0.3076) loss_zs_kd 0.0201 (0.0266) loss_oracle 0.4978 (0.4564) kd_loss 0.6401 (0.6285) acc 96.8750 (87.9688) gate/entropy 0.9798 (0.9798) gate/usage_max 0.5716 (0.5716) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1685 (0.1685) teacher/entropy 0.0214 (0.0192) teacher/usage_max 0.8954 (0.9095) teacher/usage_min 0.0107 (0.0088) teacher/usage_std 0.3989 (0.4092) nleep/row_max_mean 1517.8641 (1513.4823) nleep/row_max_std 57.8449 (64.0627) nleep/row_min_mean 1489.6890 (1485.5479) lr 1.1253e-03 eta 0:07:04
epoch [25/50] batch [100/162] time 0.096 (0.101) data 0.000 (0.003) loss 1.1612 (1.1670) teacher_loss 0.2386 (0.2953) loss_zs_kd 0.0213 (0.0265) loss_oracle 0.4628 (0.4535) kd_loss 0.6806 (0.6317) acc 87.5000 (88.5000) gate/entropy 0.9795 (0.9798) gate/usage_max 0.5719 (0.5716) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1687 (0.1685) teacher/entropy 0.0007 (0.0186) teacher/usage_max 0.8749 (0.9068) teacher/usage_min 0.0001 (0.0089) teacher/usage_std 0.3863 (0.4073) nleep/row_max_mean 1529.2042 (1514.6390) nleep/row_max_std 56.9714 (63.2666) nleep/row_min_mean 1498.0997 (1486.6219) lr 1.1253e-03 eta 0:06:56
epoch [25/50] batch [120/162] time 0.093 (0.100) data 0.000 (0.002) loss 1.1064 (1.1679) teacher_loss 0.2025 (0.2945) loss_zs_kd 0.0254 (0.0272) loss_oracle 0.5606 (0.4527) kd_loss 0.6109 (0.6335) acc 90.6250 (88.7500) gate/entropy 0.9796 (0.9797) gate/usage_max 0.5718 (0.5717) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1687 (0.1685) teacher/entropy 0.0310 (0.0195) teacher/usage_max 0.9154 (0.9041) teacher/usage_min 0.0219 (0.0095) teacher/usage_std 0.4119 (0.4054) nleep/row_max_mean 1534.0464 (1514.8978) nleep/row_max_std 64.5511 (63.0398) nleep/row_min_mean 1505.5220 (1486.9388) lr 1.1253e-03 eta 0:06:50
epoch [25/50] batch [140/162] time 0.087 (0.100) data 0.000 (0.002) loss 1.0862 (1.1680) teacher_loss 0.0760 (0.2943) loss_zs_kd 0.0383 (0.0274) loss_oracle 0.4842 (0.4514) kd_loss 0.7490 (0.6343) acc 100.0000 (88.7054) gate/entropy 0.9794 (0.9797) gate/usage_max 0.5720 (0.5717) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1688 (0.1685) teacher/entropy 0.0360 (0.0204) teacher/usage_max 0.7689 (0.9023) teacher/usage_min 0.0094 (0.0101) teacher/usage_std 0.3199 (0.4042) nleep/row_max_mean 1511.5884 (1514.9339) nleep/row_max_std 74.6620 (63.1434) nleep/row_min_mean 1488.4041 (1487.0839) lr 1.1253e-03 eta 0:06:45
epoch [25/50] batch [160/162] time 0.085 (0.098) data 0.000 (0.002) loss 1.4599 (1.1734) teacher_loss 0.5517 (0.2978) loss_zs_kd 0.0205 (0.0276) loss_oracle 0.4708 (0.4528) kd_loss 0.6625 (0.6354) acc 87.5000 (88.8281) gate/entropy 0.9795 (0.9797) gate/usage_max 0.5719 (0.5717) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1687 (0.1686) teacher/entropy 0.0145 (0.0215) teacher/usage_max 0.8793 (0.9000) teacher/usage_min 0.0269 (0.0107) teacher/usage_std 0.3870 (0.4026) nleep/row_max_mean 1522.9584 (1514.8728) nleep/row_max_std 61.3108 (63.2316) nleep/row_min_mean 1495.7968 (1487.0772) lr 1.1253e-03 eta 0:06:39
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,937
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,278
* accuracy: 69.4%
* error: 30.6%
* macro_f1: 68.5%
******* Domain s best val acc:      86.7%, epoch: 8 *******
******* Domain s best val test acc: 74.6%, epoch: 8 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [26/50] batch [20/162] time 0.088 (0.111) data 0.000 (0.016) loss 0.9500 (1.1186) teacher_loss 0.0897 (0.2612) loss_zs_kd 0.0230 (0.0274) loss_oracle 0.4591 (0.4505) kd_loss 0.6193 (0.6184) acc 100.0000 (90.1562) gate/entropy 0.9795 (0.9796) gate/usage_max 0.5719 (0.5718) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1687 (0.1686) teacher/entropy 0.0230 (0.0235) teacher/usage_max 0.9149 (0.9152) teacher/usage_min 0.0225 (0.0160) teacher/usage_std 0.4115 (0.4124) nleep/row_max_mean 1519.3773 (1519.7895) nleep/row_max_std 61.6145 (57.6051) nleep/row_min_mean 1490.5547 (1491.6934) lr 1.0628e-03 eta 0:07:28
epoch [26/50] batch [40/162] time 0.091 (0.104) data 0.000 (0.008) loss 1.4673 (1.1757) teacher_loss 0.4423 (0.2972) loss_zs_kd 0.0284 (0.0313) loss_oracle 0.5627 (0.4553) kd_loss 0.7295 (0.6352) acc 87.5000 (88.3594) gate/entropy 0.9796 (0.9795) gate/usage_max 0.5718 (0.5719) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1687 (0.1687) teacher/entropy 0.0294 (0.0200) teacher/usage_max 0.7958 (0.9016) teacher/usage_min 0.0486 (0.0131) teacher/usage_std 0.3299 (0.4035) nleep/row_max_mean 1517.1963 (1518.9344) nleep/row_max_std 60.2235 (58.5493) nleep/row_min_mean 1492.0192 (1491.0790) lr 1.0628e-03 eta 0:06:58
epoch [26/50] batch [60/162] time 0.102 (0.102) data 0.001 (0.006) loss 1.2103 (1.1762) teacher_loss 0.4039 (0.2997) loss_zs_kd 0.0268 (0.0306) loss_oracle 0.4373 (0.4587) kd_loss 0.5745 (0.6318) acc 75.0000 (87.8125) gate/entropy 0.9796 (0.9795) gate/usage_max 0.5718 (0.5719) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1686 (0.1687) teacher/entropy 0.0662 (0.0209) teacher/usage_max 0.9170 (0.9042) teacher/usage_min 0.0255 (0.0126) teacher/usage_std 0.4130 (0.4053) nleep/row_max_mean 1494.9443 (1517.7182) nleep/row_max_std 58.5412 (59.0289) nleep/row_min_mean 1468.5939 (1490.1310) lr 1.0628e-03 eta 0:06:46
epoch [26/50] batch [80/162] time 0.101 (0.100) data 0.000 (0.004) loss 1.2482 (1.1858) teacher_loss 0.3511 (0.3062) loss_zs_kd 0.0365 (0.0296) loss_oracle 0.4156 (0.4607) kd_loss 0.6711 (0.6345) acc 84.3750 (87.8906) gate/entropy 0.9795 (0.9795) gate/usage_max 0.5719 (0.5719) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1687 (0.1687) teacher/entropy 0.0134 (0.0194) teacher/usage_max 0.8715 (0.9029) teacher/usage_min 0.0003 (0.0106) teacher/usage_std 0.3841 (0.4047) nleep/row_max_mean 1516.6831 (1517.5265) nleep/row_max_std 69.8342 (59.5415) nleep/row_min_mean 1491.8296 (1490.0515) lr 1.0628e-03 eta 0:06:38
epoch [26/50] batch [100/162] time 0.091 (0.099) data 0.000 (0.003) loss 1.2475 (1.1851) teacher_loss 0.4197 (0.3026) loss_zs_kd 0.0376 (0.0291) loss_oracle 0.4577 (0.4639) kd_loss 0.5802 (0.6360) acc 81.2500 (87.9688) gate/entropy 0.9793 (0.9795) gate/usage_max 0.5721 (0.5719) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1688 (0.1687) teacher/entropy 0.0210 (0.0201) teacher/usage_max 0.9564 (0.9006) teacher/usage_min 0.0124 (0.0110) teacher/usage_std 0.4406 (0.4032) nleep/row_max_mean 1544.6687 (1517.3347) nleep/row_max_std 44.8625 (59.4189) nleep/row_min_mean 1511.4590 (1489.9304) lr 1.0628e-03 eta 0:06:32
epoch [26/50] batch [120/162] time 0.088 (0.099) data 0.000 (0.003) loss 0.9634 (1.1821) teacher_loss 0.1973 (0.3019) loss_zs_kd 0.0140 (0.0292) loss_oracle 0.4333 (0.4624) kd_loss 0.5424 (0.6344) acc 90.6250 (87.8646) gate/entropy 0.9794 (0.9795) gate/usage_max 0.5720 (0.5719) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1688 (0.1687) teacher/entropy 0.0325 (0.0206) teacher/usage_max 0.9834 (0.9017) teacher/usage_min 0.0003 (0.0120) teacher/usage_std 0.4597 (0.4038) nleep/row_max_mean 1511.0027 (1517.3295) nleep/row_max_std 54.7991 (59.0628) nleep/row_min_mean 1483.9438 (1489.9659) lr 1.0628e-03 eta 0:06:27
epoch [26/50] batch [140/162] time 0.088 (0.098) data 0.000 (0.003) loss 1.2132 (1.1784) teacher_loss 0.2869 (0.3013) loss_zs_kd 0.0272 (0.0284) loss_oracle 0.5088 (0.4592) kd_loss 0.6583 (0.6332) acc 90.6250 (87.8348) gate/entropy 0.9794 (0.9795) gate/usage_max 0.5720 (0.5719) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1687 (0.1687) teacher/entropy 0.0403 (0.0209) teacher/usage_max 0.8572 (0.9026) teacher/usage_min 0.0174 (0.0118) teacher/usage_std 0.3731 (0.4043) nleep/row_max_mean 1490.9720 (1516.8155) nleep/row_max_std 67.7851 (59.2093) nleep/row_min_mean 1467.8271 (1489.5399) lr 1.0628e-03 eta 0:06:22
epoch [26/50] batch [160/162] time 0.089 (0.098) data 0.000 (0.002) loss 1.2837 (1.1765) teacher_loss 0.3721 (0.2975) loss_zs_kd 0.0316 (0.0283) loss_oracle 0.5157 (0.4600) kd_loss 0.6379 (0.6349) acc 93.7500 (88.1641) gate/entropy 0.9793 (0.9795) gate/usage_max 0.5721 (0.5719) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1689 (0.1687) teacher/entropy 0.0173 (0.0216) teacher/usage_max 0.9012 (0.9002) teacher/usage_min 0.0036 (0.0121) teacher/usage_std 0.4033 (0.4027) nleep/row_max_mean 1513.9274 (1516.2404) nleep/row_max_std 66.7286 (59.2575) nleep/row_min_mean 1486.2104 (1489.0599) lr 1.0628e-03 eta 0:06:19
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,941
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,270
* accuracy: 69.2%
* error: 30.8%
* macro_f1: 67.6%
******* Domain s best val acc:      86.9%, epoch: 26 *******
******* Domain s best val test acc: 69.2%, epoch: 26 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [27/50] batch [20/162] time 0.093 (0.113) data 0.000 (0.014) loss 1.1360 (1.1726) teacher_loss 0.2966 (0.2845) loss_zs_kd 0.0186 (0.0269) loss_oracle 0.4276 (0.4542) kd_loss 0.6163 (0.6476) acc 87.5000 (88.7500) gate/entropy 0.9794 (0.9794) gate/usage_max 0.5720 (0.5720) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1688 (0.1688) teacher/entropy 0.0039 (0.0246) teacher/usage_max 0.9372 (0.8841) teacher/usage_min 0.0007 (0.0147) teacher/usage_std 0.4277 (0.3913) nleep/row_max_mean 1518.1091 (1514.7439) nleep/row_max_std 57.8688 (58.5228) nleep/row_min_mean 1493.4578 (1489.0817) lr 1.0000e-03 eta 0:07:16
epoch [27/50] batch [40/162] time 0.090 (0.102) data 0.000 (0.007) loss 1.1055 (1.1802) teacher_loss 0.1990 (0.2907) loss_zs_kd 0.0118 (0.0277) loss_oracle 0.4460 (0.4503) kd_loss 0.6776 (0.6506) acc 93.7500 (89.2969) gate/entropy 0.9793 (0.9794) gate/usage_max 0.5721 (0.5721) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1689 (0.1688) teacher/entropy 0.0032 (0.0262) teacher/usage_max 0.8750 (0.8793) teacher/usage_min 0.0006 (0.0152) teacher/usage_std 0.3863 (0.3884) nleep/row_max_mean 1525.4810 (1513.3689) nleep/row_max_std 53.6638 (58.8404) nleep/row_min_mean 1498.3079 (1487.9210) lr 1.0000e-03 eta 0:06:34
epoch [27/50] batch [60/162] time 0.094 (0.101) data 0.001 (0.005) loss 1.2555 (1.1716) teacher_loss 0.3843 (0.2888) loss_zs_kd 0.0347 (0.0282) loss_oracle 0.4704 (0.4460) kd_loss 0.6187 (0.6456) acc 84.3750 (89.1146) gate/entropy 0.9793 (0.9793) gate/usage_max 0.5721 (0.5721) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1689 (0.1688) teacher/entropy 0.0579 (0.0276) teacher/usage_max 0.8796 (0.8829) teacher/usage_min 0.0203 (0.0144) teacher/usage_std 0.3876 (0.3908) nleep/row_max_mean 1519.0471 (1514.7294) nleep/row_max_std 56.5792 (58.3367) nleep/row_min_mean 1492.9172 (1489.2460) lr 1.0000e-03 eta 0:06:26
epoch [27/50] batch [80/162] time 0.106 (0.101) data 0.000 (0.004) loss 1.0219 (1.1560) teacher_loss 0.1511 (0.2851) loss_zs_kd 0.0365 (0.0285) loss_oracle 0.4636 (0.4394) kd_loss 0.6207 (0.6369) acc 96.8750 (89.1016) gate/entropy 0.9793 (0.9793) gate/usage_max 0.5721 (0.5721) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1688 (0.1688) teacher/entropy 0.0552 (0.0298) teacher/usage_max 0.8801 (0.8895) teacher/usage_min 0.0170 (0.0158) teacher/usage_std 0.3882 (0.3951) nleep/row_max_mean 1495.6443 (1515.8840) nleep/row_max_std 60.5967 (57.9845) nleep/row_min_mean 1471.1885 (1490.3705) lr 1.0000e-03 eta 0:06:23
epoch [27/50] batch [100/162] time 0.103 (0.103) data 0.000 (0.003) loss 1.0967 (1.1528) teacher_loss 0.3605 (0.2861) loss_zs_kd 0.0148 (0.0280) loss_oracle 0.3733 (0.4353) kd_loss 0.5421 (0.6351) acc 84.3750 (88.8125) gate/entropy 0.9792 (0.9793) gate/usage_max 0.5722 (0.5721) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1689 (0.1688) teacher/entropy 0.1012 (0.0308) teacher/usage_max 0.9132 (0.8905) teacher/usage_min 0.0169 (0.0166) teacher/usage_std 0.4106 (0.3957) nleep/row_max_mean 1521.6803 (1515.4121) nleep/row_max_std 45.4218 (57.8096) nleep/row_min_mean 1495.2764 (1489.9803) lr 1.0000e-03 eta 0:06:28
epoch [27/50] batch [120/162] time 0.092 (0.102) data 0.000 (0.003) loss 1.1719 (1.1491) teacher_loss 0.2942 (0.2856) loss_zs_kd 0.0149 (0.0276) loss_oracle 0.3974 (0.4314) kd_loss 0.6716 (0.6340) acc 90.6250 (88.9844) gate/entropy 0.9792 (0.9793) gate/usage_max 0.5722 (0.5721) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1689 (0.1688) teacher/entropy 0.0233 (0.0313) teacher/usage_max 0.8607 (0.8910) teacher/usage_min 0.0002 (0.0163) teacher/usage_std 0.3772 (0.3961) nleep/row_max_mean 1503.1013 (1514.7896) nleep/row_max_std 62.8784 (58.4008) nleep/row_min_mean 1479.1754 (1489.4863) lr 1.0000e-03 eta 0:06:23
epoch [27/50] batch [140/162] time 0.102 (0.101) data 0.000 (0.002) loss 1.2802 (1.1477) teacher_loss 0.2384 (0.2807) loss_zs_kd 0.0137 (0.0272) loss_oracle 0.5644 (0.4329) kd_loss 0.7527 (0.6369) acc 90.6250 (89.1741) gate/entropy 0.9792 (0.9793) gate/usage_max 0.5722 (0.5721) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1689 (0.1689) teacher/entropy 0.0804 (0.0332) teacher/usage_max 0.7202 (0.8860) teacher/usage_min 0.0548 (0.0175) teacher/usage_std 0.2823 (0.3928) nleep/row_max_mean 1493.4172 (1514.5254) nleep/row_max_std 59.2610 (58.7690) nleep/row_min_mean 1472.9458 (1489.4062) lr 1.0000e-03 eta 0:06:19
epoch [27/50] batch [160/162] time 0.087 (0.100) data 0.000 (0.002) loss 1.8919 (1.1523) teacher_loss 1.0106 (0.2852) loss_zs_kd 0.0525 (0.0280) loss_oracle 0.4479 (0.4322) kd_loss 0.6311 (0.6370) acc 71.8750 (89.1602) gate/entropy 0.9791 (0.9793) gate/usage_max 0.5723 (0.5721) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1690 (0.1689) teacher/entropy 0.0317 (0.0341) teacher/usage_max 0.8932 (0.8850) teacher/usage_min 0.0108 (0.0180) teacher/usage_std 0.3974 (0.3921) nleep/row_max_mean 1512.7040 (1515.0478) nleep/row_max_std 60.8108 (58.5955) nleep/row_min_mean 1486.5300 (1490.0461) lr 1.0000e-03 eta 0:06:14
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,930
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,342
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 68.3%
******* Domain s best val acc:      86.9%, epoch: 26 *******
******* Domain s best val test acc: 69.2%, epoch: 26 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [28/50] batch [20/162] time 0.106 (0.117) data 0.000 (0.015) loss 1.0839 (1.1228) teacher_loss 0.1612 (0.2754) loss_zs_kd 0.0322 (0.0252) loss_oracle 0.4660 (0.4235) kd_loss 0.6736 (0.6231) acc 93.7500 (89.3750) gate/entropy 0.9791 (0.9792) gate/usage_max 0.5723 (0.5723) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1689 (0.1689) teacher/entropy 0.0258 (0.0479) teacher/usage_max 0.8561 (0.8850) teacher/usage_min 0.0007 (0.0246) teacher/usage_std 0.3742 (0.3916) nleep/row_max_mean 1505.7771 (1519.5463) nleep/row_max_std 60.7456 (56.0113) nleep/row_min_mean 1482.8087 (1495.5810) lr 9.3721e-04 eta 0:07:12
epoch [28/50] batch [40/162] time 0.090 (0.111) data 0.000 (0.008) loss 1.1719 (1.1512) teacher_loss 0.1436 (0.2627) loss_zs_kd 0.0277 (0.0281) loss_oracle 0.5026 (0.4510) kd_loss 0.7632 (0.6489) acc 93.7500 (89.6875) gate/entropy 0.9791 (0.9792) gate/usage_max 0.5723 (0.5723) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1690 (0.1689) teacher/entropy 0.0131 (0.0511) teacher/usage_max 0.7773 (0.8555) teacher/usage_min 0.0039 (0.0256) teacher/usage_std 0.3260 (0.3723) nleep/row_max_mean 1520.9287 (1514.4754) nleep/row_max_std 54.8895 (58.6881) nleep/row_min_mean 1495.6647 (1490.9858) lr 9.3721e-04 eta 0:06:47
epoch [28/50] batch [60/162] time 0.091 (0.105) data 0.001 (0.005) loss 1.0839 (1.1556) teacher_loss 0.1922 (0.2650) loss_zs_kd 0.0260 (0.0271) loss_oracle 0.4385 (0.4500) kd_loss 0.6595 (0.6520) acc 93.7500 (89.8958) gate/entropy 0.9792 (0.9792) gate/usage_max 0.5722 (0.5723) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1689 (0.1689) teacher/entropy 0.0372 (0.0507) teacher/usage_max 0.8588 (0.8527) teacher/usage_min 0.0030 (0.0256) teacher/usage_std 0.3757 (0.3704) nleep/row_max_mean 1493.8005 (1513.7199) nleep/row_max_std 69.6635 (59.5844) nleep/row_min_mean 1473.4735 (1490.5893) lr 9.3721e-04 eta 0:06:25
epoch [28/50] batch [80/162] time 0.092 (0.108) data 0.000 (0.004) loss 1.2857 (1.1540) teacher_loss 0.4773 (0.2687) loss_zs_kd 0.0250 (0.0273) loss_oracle 0.3901 (0.4452) kd_loss 0.6009 (0.6492) acc 78.1250 (89.6094) gate/entropy 0.9790 (0.9791) gate/usage_max 0.5724 (0.5723) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0270 (0.0514) teacher/usage_max 0.9289 (0.8549) teacher/usage_min 0.0018 (0.0248) teacher/usage_std 0.4220 (0.3718) nleep/row_max_mean 1522.7649 (1514.8046) nleep/row_max_std 55.6370 (59.2625) nleep/row_min_mean 1498.4897 (1491.6951) lr 9.3721e-04 eta 0:06:32
epoch [28/50] batch [100/162] time 0.094 (0.105) data 0.000 (0.003) loss 1.3886 (1.1620) teacher_loss 0.4574 (0.2761) loss_zs_kd 0.0402 (0.0271) loss_oracle 0.4792 (0.4435) kd_loss 0.6715 (0.6506) acc 75.0000 (89.4375) gate/entropy 0.9790 (0.9791) gate/usage_max 0.5724 (0.5723) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0486 (0.0521) teacher/usage_max 0.8347 (0.8527) teacher/usage_min 0.0001 (0.0258) teacher/usage_std 0.3609 (0.3703) nleep/row_max_mean 1515.0708 (1514.2394) nleep/row_max_std 53.8167 (59.1471) nleep/row_min_mean 1488.9661 (1491.1130) lr 9.3721e-04 eta 0:06:20
epoch [28/50] batch [120/162] time 0.095 (0.104) data 0.000 (0.003) loss 1.0631 (1.1635) teacher_loss 0.1817 (0.2811) loss_zs_kd 0.0189 (0.0261) loss_oracle 0.4474 (0.4405) kd_loss 0.6482 (0.6492) acc 96.8750 (89.2448) gate/entropy 0.9791 (0.9791) gate/usage_max 0.5723 (0.5723) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0435 (0.0510) teacher/usage_max 0.8640 (0.8553) teacher/usage_min 0.0352 (0.0248) teacher/usage_std 0.3762 (0.3722) nleep/row_max_mean 1512.4702 (1514.1547) nleep/row_max_std 70.1639 (59.2236) nleep/row_min_mean 1490.2881 (1490.9707) lr 9.3721e-04 eta 0:06:14
epoch [28/50] batch [140/162] time 0.089 (0.103) data 0.000 (0.002) loss 1.0082 (1.1632) teacher_loss 0.1264 (0.2812) loss_zs_kd 0.0250 (0.0265) loss_oracle 0.4295 (0.4416) kd_loss 0.6546 (0.6480) acc 96.8750 (89.2857) gate/entropy 0.9790 (0.9791) gate/usage_max 0.5724 (0.5723) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0262 (0.0494) teacher/usage_max 0.8747 (0.8581) teacher/usage_min 0.0068 (0.0230) teacher/usage_std 0.3855 (0.3741) nleep/row_max_mean 1516.5767 (1513.9151) nleep/row_max_std 61.6228 (59.2379) nleep/row_min_mean 1493.2214 (1490.5746) lr 9.3721e-04 eta 0:06:09
epoch [28/50] batch [160/162] time 0.088 (0.102) data 0.000 (0.002) loss 1.0824 (1.1602) teacher_loss 0.2732 (0.2798) loss_zs_kd 0.0311 (0.0265) loss_oracle 0.3574 (0.4425) kd_loss 0.6150 (0.6459) acc 87.5000 (89.3555) gate/entropy 0.9790 (0.9791) gate/usage_max 0.5724 (0.5723) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0595 (0.0491) teacher/usage_max 0.8810 (0.8604) teacher/usage_min 0.0151 (0.0220) teacher/usage_std 0.3889 (0.3757) nleep/row_max_mean 1507.9375 (1513.1941) nleep/row_max_std 67.8501 (59.6043) nleep/row_min_mean 1484.9247 (1489.8832) lr 9.3721e-04 eta 0:06:02
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,924
* accuracy: 86.1%
* error: 13.9%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,320
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 68.0%
******* Domain s best val acc:      86.9%, epoch: 26 *******
******* Domain s best val test acc: 69.2%, epoch: 26 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [29/50] batch [20/162] time 0.070 (0.111) data 0.000 (0.015) loss 1.3266 (1.1615) teacher_loss 0.3364 (0.2692) loss_zs_kd 0.0224 (0.0281) loss_oracle 0.5227 (0.4636) kd_loss 0.7177 (0.6464) acc 93.7500 (90.7812) gate/entropy 0.9791 (0.9790) gate/usage_max 0.5723 (0.5724) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1690 (0.1690) teacher/entropy 0.0561 (0.0558) teacher/usage_max 0.7800 (0.8531) teacher/usage_min 0.0373 (0.0250) teacher/usage_std 0.3214 (0.3708) nleep/row_max_mean 1497.4065 (1513.4802) nleep/row_max_std 67.5928 (58.4310) nleep/row_min_mean 1474.7104 (1489.4606) lr 8.7467e-04 eta 0:06:31
epoch [29/50] batch [40/162] time 0.101 (0.101) data 0.000 (0.008) loss 1.1259 (1.1703) teacher_loss 0.2776 (0.2698) loss_zs_kd 0.0198 (0.0259) loss_oracle 0.4583 (0.4592) kd_loss 0.6092 (0.6580) acc 93.7500 (90.0781) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0532 (0.0445) teacher/usage_max 0.8935 (0.8527) teacher/usage_min 0.0335 (0.0190) teacher/usage_std 0.3964 (0.3717) nleep/row_max_mean 1517.7131 (1513.2640) nleep/row_max_std 59.6138 (60.4588) nleep/row_min_mean 1493.2102 (1489.3848) lr 8.7467e-04 eta 0:05:56
epoch [29/50] batch [60/162] time 0.096 (0.101) data 0.001 (0.005) loss 1.4234 (1.1689) teacher_loss 0.4492 (0.2724) loss_zs_kd 0.0385 (0.0259) loss_oracle 0.4908 (0.4482) kd_loss 0.7095 (0.6594) acc 84.3750 (90.0521) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0734 (0.0434) teacher/usage_max 0.7709 (0.8523) teacher/usage_min 0.0364 (0.0179) teacher/usage_std 0.3159 (0.3712) nleep/row_max_mean 1507.4636 (1514.0128) nleep/row_max_std 63.3297 (60.5560) nleep/row_min_mean 1481.1201 (1489.8866) lr 8.7467e-04 eta 0:05:53
epoch [29/50] batch [80/162] time 0.104 (0.099) data 0.000 (0.004) loss 1.2116 (1.1806) teacher_loss 0.2655 (0.2864) loss_zs_kd 0.0229 (0.0270) loss_oracle 0.4949 (0.4486) kd_loss 0.6872 (0.6565) acc 90.6250 (89.6484) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1691 (0.1690) teacher/entropy 0.0212 (0.0422) teacher/usage_max 0.8464 (0.8566) teacher/usage_min 0.0023 (0.0184) teacher/usage_std 0.3679 (0.3740) nleep/row_max_mean 1514.7913 (1513.2999) nleep/row_max_std 59.5513 (60.6236) nleep/row_min_mean 1491.4366 (1489.2004) lr 8.7467e-04 eta 0:05:43
epoch [29/50] batch [100/162] time 0.100 (0.099) data 0.000 (0.003) loss 1.3541 (1.1831) teacher_loss 0.4664 (0.2877) loss_zs_kd 0.0263 (0.0277) loss_oracle 0.4494 (0.4521) kd_loss 0.6499 (0.6555) acc 78.1250 (89.1875) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0360 (0.0435) teacher/usage_max 0.8695 (0.8563) teacher/usage_min 0.0259 (0.0209) teacher/usage_std 0.3805 (0.3734) nleep/row_max_mean 1520.2375 (1513.9897) nleep/row_max_std 61.5806 (60.1179) nleep/row_min_mean 1494.7061 (1489.7994) lr 8.7467e-04 eta 0:05:43
epoch [29/50] batch [120/162] time 0.104 (0.099) data 0.000 (0.003) loss 1.3029 (1.1887) teacher_loss 0.3658 (0.2901) loss_zs_kd 0.0301 (0.0273) loss_oracle 0.4896 (0.4549) kd_loss 0.6773 (0.6575) acc 90.6250 (89.0625) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0687 (0.0455) teacher/usage_max 0.8083 (0.8523) teacher/usage_min 0.0115 (0.0227) teacher/usage_std 0.3428 (0.3705) nleep/row_max_mean 1500.1809 (1513.8495) nleep/row_max_std 68.4835 (59.6245) nleep/row_min_mean 1476.3226 (1489.5855) lr 8.7467e-04 eta 0:05:41
epoch [29/50] batch [140/162] time 0.094 (0.098) data 0.000 (0.002) loss 1.0473 (1.1873) teacher_loss 0.0975 (0.2887) loss_zs_kd 0.0440 (0.0277) loss_oracle 0.5277 (0.4556) kd_loss 0.6640 (0.6570) acc 96.8750 (88.9955) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0594 (0.0452) teacher/usage_max 0.8317 (0.8530) teacher/usage_min 0.0792 (0.0232) teacher/usage_std 0.3525 (0.3708) nleep/row_max_mean 1518.1919 (1514.7287) nleep/row_max_std 54.4349 (58.8678) nleep/row_min_mean 1495.5410 (1490.3246) lr 8.7467e-04 eta 0:05:36
epoch [29/50] batch [160/162] time 0.094 (0.097) data 0.001 (0.002) loss 1.2227 (1.1817) teacher_loss 0.2917 (0.2825) loss_zs_kd 0.0283 (0.0285) loss_oracle 0.5852 (0.4571) kd_loss 0.6242 (0.6565) acc 84.3750 (89.0625) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0630 (0.0439) teacher/usage_max 0.8684 (0.8549) teacher/usage_min 0.0388 (0.0228) teacher/usage_std 0.3790 (0.3720) nleep/row_max_mean 1519.5854 (1515.2269) nleep/row_max_std 57.3652 (58.7318) nleep/row_min_mean 1491.7911 (1490.5953) lr 8.7467e-04 eta 0:05:31
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,939
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,268
* accuracy: 69.1%
* error: 30.9%
* macro_f1: 66.0%
******* Domain s best val acc:      86.9%, epoch: 26 *******
******* Domain s best val test acc: 69.2%, epoch: 26 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [30/50] batch [20/162] time 0.057 (0.105) data 0.000 (0.019) loss 1.2600 (1.1627) teacher_loss 0.3087 (0.2569) loss_zs_kd 0.0252 (0.0296) loss_oracle 0.5387 (0.4741) kd_loss 0.6693 (0.6539) acc 87.5000 (89.8438) gate/entropy 0.9790 (0.9789) gate/usage_max 0.5724 (0.5725) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0433 (0.0361) teacher/usage_max 0.8425 (0.8653) teacher/usage_min 0.0272 (0.0237) teacher/usage_std 0.3625 (0.3783) nleep/row_max_mean 1512.2979 (1518.8895) nleep/row_max_std 59.4426 (58.7213) nleep/row_min_mean 1488.2874 (1493.1859) lr 8.1262e-04 eta 0:05:56
epoch [30/50] batch [40/162] time 0.097 (0.099) data 0.000 (0.009) loss 1.2008 (1.1749) teacher_loss 0.3657 (0.2653) loss_zs_kd 0.0321 (0.0302) loss_oracle 0.4147 (0.4745) kd_loss 0.6117 (0.6573) acc 84.3750 (89.8438) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5727 (0.5725) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0089 (0.0411) teacher/usage_max 0.9359 (0.8568) teacher/usage_min 0.0019 (0.0267) teacher/usage_std 0.4268 (0.3728) nleep/row_max_mean 1524.7388 (1516.4471) nleep/row_max_std 52.0280 (59.0839) nleep/row_min_mean 1499.2510 (1490.8688) lr 8.1262e-04 eta 0:05:33
epoch [30/50] batch [60/162] time 0.104 (0.100) data 0.001 (0.006) loss 1.0061 (1.1682) teacher_loss 0.2253 (0.2577) loss_zs_kd 0.0196 (0.0293) loss_oracle 0.3803 (0.4706) kd_loss 0.5808 (0.6606) acc 90.6250 (90.0521) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5726 (0.5725) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0322 (0.0434) teacher/usage_max 0.9436 (0.8512) teacher/usage_min 0.0178 (0.0293) teacher/usage_std 0.4316 (0.3689) nleep/row_max_mean 1534.0012 (1515.3558) nleep/row_max_std 49.7967 (59.7704) nleep/row_min_mean 1506.3993 (1489.9160) lr 8.1262e-04 eta 0:05:33
epoch [30/50] batch [80/162] time 0.108 (0.098) data 0.000 (0.005) loss 1.1115 (1.1683) teacher_loss 0.2376 (0.2563) loss_zs_kd 0.0260 (0.0286) loss_oracle 0.4433 (0.4699) kd_loss 0.6392 (0.6628) acc 93.7500 (90.3125) gate/entropy 0.9789 (0.9789) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0105 (0.0443) teacher/usage_max 0.9062 (0.8481) teacher/usage_min 0.0031 (0.0285) teacher/usage_std 0.4067 (0.3671) nleep/row_max_mean 1521.9705 (1514.2797) nleep/row_max_std 51.6565 (60.6282) nleep/row_min_mean 1496.2646 (1488.9374) lr 8.1262e-04 eta 0:05:26
epoch [30/50] batch [100/162] time 0.112 (0.099) data 0.000 (0.004) loss 1.4832 (1.1761) teacher_loss 0.3589 (0.2569) loss_zs_kd 0.0456 (0.0292) loss_oracle 0.5845 (0.4718) kd_loss 0.8092 (0.6686) acc 81.2500 (90.2812) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5727 (0.5725) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0551 (0.0452) teacher/usage_max 0.6882 (0.8411) teacher/usage_min 0.0928 (0.0283) teacher/usage_std 0.2562 (0.3628) nleep/row_max_mean 1506.1312 (1514.0793) nleep/row_max_std 67.1863 (60.6506) nleep/row_min_mean 1482.0865 (1488.8219) lr 8.1262e-04 eta 0:05:27
epoch [30/50] batch [120/162] time 0.094 (0.100) data 0.000 (0.003) loss 1.1528 (1.1843) teacher_loss 0.2932 (0.2635) loss_zs_kd 0.0309 (0.0292) loss_oracle 0.4332 (0.4703) kd_loss 0.6275 (0.6711) acc 90.6250 (90.1823) gate/entropy 0.9787 (0.9789) gate/usage_max 0.5727 (0.5725) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0223 (0.0455) teacher/usage_max 0.9060 (0.8383) teacher/usage_min 0.0110 (0.0300) teacher/usage_std 0.4060 (0.3608) nleep/row_max_mean 1540.9507 (1513.7763) nleep/row_max_std 43.4161 (60.3745) nleep/row_min_mean 1513.3901 (1488.6091) lr 8.1262e-04 eta 0:05:27
epoch [30/50] batch [140/162] time 0.108 (0.100) data 0.001 (0.003) loss 1.4267 (1.1951) teacher_loss 0.4865 (0.2680) loss_zs_kd 0.0313 (0.0290) loss_oracle 0.4479 (0.4719) kd_loss 0.7006 (0.6767) acc 78.1250 (89.8884) gate/entropy 0.9787 (0.9789) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0100 (0.0452) teacher/usage_max 0.8441 (0.8329) teacher/usage_min 0.0016 (0.0316) teacher/usage_std 0.3665 (0.3572) nleep/row_max_mean 1500.2727 (1513.4005) nleep/row_max_std 68.1081 (60.7035) nleep/row_min_mean 1476.3224 (1488.3706) lr 8.1262e-04 eta 0:05:26
epoch [30/50] batch [160/162] time 0.088 (0.100) data 0.000 (0.003) loss 1.1541 (1.1984) teacher_loss 0.2672 (0.2688) loss_zs_kd 0.0315 (0.0298) loss_oracle 0.4529 (0.4737) kd_loss 0.6447 (0.6778) acc 90.6250 (89.7461) gate/entropy 0.9787 (0.9789) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0538 (0.0462) teacher/usage_max 0.8567 (0.8307) teacher/usage_min 0.0574 (0.0328) teacher/usage_std 0.3703 (0.3558) nleep/row_max_mean 1526.8955 (1513.2336) nleep/row_max_std 47.1427 (60.3987) nleep/row_min_mean 1500.0513 (1488.2460) lr 8.1262e-04 eta 0:05:23
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,938
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,355
* accuracy: 71.8%
* error: 28.2%
* macro_f1: 67.2%
******* Domain s best val acc:      86.9%, epoch: 26 *******
******* Domain s best val test acc: 69.2%, epoch: 26 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [31/50] batch [20/162] time 0.091 (0.112) data 0.000 (0.018) loss 1.0139 (1.1923) teacher_loss 0.1385 (0.2353) loss_zs_kd 0.0245 (0.0284) loss_oracle 0.3922 (0.4851) kd_loss 0.6671 (0.7002) acc 93.7500 (90.9375) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0501 (0.0373) teacher/usage_max 0.8376 (0.8171) teacher/usage_min 0.0279 (0.0402) teacher/usage_std 0.3592 (0.3453) nleep/row_max_mean 1516.8926 (1508.6386) nleep/row_max_std 60.5770 (62.5914) nleep/row_min_mean 1491.9485 (1483.8576) lr 7.5131e-04 eta 0:06:00
epoch [31/50] batch [40/162] time 0.098 (0.100) data 0.000 (0.009) loss 1.3012 (1.2278) teacher_loss 0.2692 (0.2710) loss_zs_kd 0.0307 (0.0288) loss_oracle 0.5387 (0.4949) kd_loss 0.7473 (0.6950) acc 90.6250 (89.1406) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0379 (0.0391) teacher/usage_max 0.7681 (0.8205) teacher/usage_min 0.0045 (0.0370) teacher/usage_std 0.3206 (0.3480) nleep/row_max_mean 1502.2231 (1510.1753) nleep/row_max_std 64.9359 (61.4677) nleep/row_min_mean 1476.1079 (1485.2460) lr 7.5131e-04 eta 0:05:20
epoch [31/50] batch [60/162] time 0.108 (0.097) data 0.000 (0.006) loss 1.1733 (1.2206) teacher_loss 0.2437 (0.2620) loss_zs_kd 0.0388 (0.0291) loss_oracle 0.5194 (0.4977) kd_loss 0.6505 (0.6952) acc 87.5000 (89.4792) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0359 (0.0381) teacher/usage_max 0.8689 (0.8213) teacher/usage_min 0.0066 (0.0361) teacher/usage_std 0.3817 (0.3487) nleep/row_max_mean 1512.9646 (1511.0184) nleep/row_max_std 57.5704 (61.0518) nleep/row_min_mean 1485.7295 (1485.8415) lr 7.5131e-04 eta 0:05:07
epoch [31/50] batch [80/162] time 0.097 (0.097) data 0.000 (0.005) loss 1.3198 (1.2190) teacher_loss 0.3256 (0.2636) loss_zs_kd 0.0547 (0.0296) loss_oracle 0.5784 (0.4978) kd_loss 0.6777 (0.6916) acc 84.3750 (89.6875) gate/entropy 0.9789 (0.9788) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0699 (0.0419) teacher/usage_max 0.8069 (0.8210) teacher/usage_min 0.0552 (0.0395) teacher/usage_std 0.3366 (0.3482) nleep/row_max_mean 1511.0013 (1512.5690) nleep/row_max_std 54.1570 (60.2679) nleep/row_min_mean 1486.1660 (1487.0876) lr 7.5131e-04 eta 0:05:06
epoch [31/50] batch [100/162] time 0.100 (0.100) data 0.000 (0.004) loss 1.1306 (1.2108) teacher_loss 0.2888 (0.2626) loss_zs_kd 0.0186 (0.0294) loss_oracle 0.4315 (0.4938) kd_loss 0.6167 (0.6866) acc 84.3750 (89.8125) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0541 (0.0428) teacher/usage_max 0.8847 (0.8252) teacher/usage_min 0.0177 (0.0405) teacher/usage_std 0.3912 (0.3508) nleep/row_max_mean 1518.9957 (1513.1996) nleep/row_max_std 59.1660 (60.2449) nleep/row_min_mean 1491.1985 (1487.5306) lr 7.5131e-04 eta 0:05:13
epoch [31/50] batch [120/162] time 0.086 (0.099) data 0.000 (0.003) loss 1.4098 (1.2138) teacher_loss 0.2699 (0.2649) loss_zs_kd 0.0393 (0.0294) loss_oracle 0.5683 (0.4920) kd_loss 0.8361 (0.6882) acc 87.5000 (89.6875) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0287 (0.0425) teacher/usage_max 0.6875 (0.8239) teacher/usage_min 0.0489 (0.0395) teacher/usage_std 0.2653 (0.3502) nleep/row_max_mean 1509.2432 (1512.9467) nleep/row_max_std 57.2965 (60.3400) nleep/row_min_mean 1484.9746 (1487.2994) lr 7.5131e-04 eta 0:05:08
epoch [31/50] batch [140/162] time 0.093 (0.099) data 0.000 (0.003) loss 1.2461 (1.2075) teacher_loss 0.1181 (0.2600) loss_zs_kd 0.0184 (0.0295) loss_oracle 0.5864 (0.4909) kd_loss 0.8256 (0.6873) acc 96.8750 (89.7768) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0699 (0.0412) teacher/usage_max 0.6562 (0.8261) teacher/usage_min 0.0310 (0.0386) teacher/usage_std 0.2557 (0.3518) nleep/row_max_mean 1484.5188 (1513.2704) nleep/row_max_std 74.1374 (60.5179) nleep/row_min_mean 1462.7380 (1487.5647) lr 7.5131e-04 eta 0:05:06
epoch [31/50] batch [160/162] time 0.090 (0.098) data 0.000 (0.002) loss 1.3048 (1.2144) teacher_loss 0.2201 (0.2636) loss_zs_kd 0.0256 (0.0302) loss_oracle 0.5078 (0.4917) kd_loss 0.8180 (0.6898) acc 90.6250 (89.8242) gate/entropy 0.9788 (0.9788) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0157 (0.0410) teacher/usage_max 0.7189 (0.8238) teacher/usage_min 0.0364 (0.0380) teacher/usage_std 0.2856 (0.3504) nleep/row_max_mean 1509.0254 (1512.1587) nleep/row_max_std 61.6469 (61.3273) nleep/row_min_mean 1483.1875 (1486.4996) lr 7.5131e-04 eta 0:05:01
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,935
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,277
* accuracy: 69.4%
* error: 30.6%
* macro_f1: 66.4%
******* Domain s best val acc:      86.9%, epoch: 26 *******
******* Domain s best val test acc: 69.2%, epoch: 26 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [32/50] batch [20/162] time 0.090 (0.120) data 0.001 (0.023) loss 1.1214 (1.1946) teacher_loss 0.2043 (0.2459) loss_zs_kd 0.0447 (0.0345) loss_oracle 0.4525 (0.4839) kd_loss 0.6684 (0.6895) acc 87.5000 (90.0000) gate/entropy 0.9788 (0.9787) gate/usage_max 0.5726 (0.5727) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1693) teacher/entropy 0.0122 (0.0345) teacher/usage_max 0.8748 (0.8306) teacher/usage_min 0.0279 (0.0306) teacher/usage_std 0.3839 (0.3556) nleep/row_max_mean 1524.6708 (1513.2499) nleep/row_max_std 50.4188 (60.6927) nleep/row_min_mean 1494.5914 (1487.0581) lr 6.9098e-04 eta 0:06:05
epoch [32/50] batch [40/162] time 0.088 (0.105) data 0.000 (0.012) loss 1.2600 (1.2110) teacher_loss 0.3530 (0.2526) loss_zs_kd 0.0382 (0.0338) loss_oracle 0.4843 (0.4843) kd_loss 0.6458 (0.6993) acc 84.3750 (89.2188) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5728 (0.5727) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1694 (0.1693) teacher/entropy 0.0035 (0.0360) teacher/usage_max 0.9062 (0.8191) teacher/usage_min 0.0006 (0.0300) teacher/usage_std 0.4068 (0.3481) nleep/row_max_mean 1531.5250 (1512.0542) nleep/row_max_std 51.7047 (61.6494) nleep/row_min_mean 1500.7273 (1486.2350) lr 6.9098e-04 eta 0:05:17
epoch [32/50] batch [60/162] time 0.096 (0.102) data 0.000 (0.008) loss 1.2580 (1.2291) teacher_loss 0.4252 (0.2787) loss_zs_kd 0.0372 (0.0321) loss_oracle 0.3547 (0.4781) kd_loss 0.6368 (0.6953) acc 81.2500 (88.5417) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5728 (0.5727) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0126 (0.0333) teacher/usage_max 0.9063 (0.8259) teacher/usage_min 0.0034 (0.0277) teacher/usage_std 0.4067 (0.3530) nleep/row_max_mean 1516.2621 (1512.4007) nleep/row_max_std 65.7420 (61.6894) nleep/row_min_mean 1491.7479 (1486.5526) lr 6.9098e-04 eta 0:05:08
epoch [32/50] batch [80/162] time 0.099 (0.100) data 0.000 (0.006) loss 1.6055 (1.2361) teacher_loss 0.5329 (0.2861) loss_zs_kd 0.0350 (0.0320) loss_oracle 0.5740 (0.4798) kd_loss 0.7680 (0.6940) acc 71.8750 (88.4375) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5728 (0.5727) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0341 (0.0338) teacher/usage_max 0.7510 (0.8266) teacher/usage_min 0.0061 (0.0272) teacher/usage_std 0.3108 (0.3535) nleep/row_max_mean 1497.8348 (1511.8231) nleep/row_max_std 66.5978 (62.1610) nleep/row_min_mean 1473.9014 (1485.9957) lr 6.9098e-04 eta 0:05:00
epoch [32/50] batch [100/162] time 0.092 (0.100) data 0.000 (0.005) loss 1.3295 (1.2338) teacher_loss 0.3071 (0.2797) loss_zs_kd 0.0231 (0.0313) loss_oracle 0.5618 (0.4842) kd_loss 0.7300 (0.6964) acc 84.3750 (88.5000) gate/entropy 0.9788 (0.9787) gate/usage_max 0.5726 (0.5727) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1693) teacher/entropy 0.0119 (0.0338) teacher/usage_max 0.8125 (0.8243) teacher/usage_min 0.0333 (0.0263) teacher/usage_std 0.3424 (0.3522) nleep/row_max_mean 1504.3680 (1512.0278) nleep/row_max_std 60.2509 (61.9612) nleep/row_min_mean 1477.0708 (1486.0781) lr 6.9098e-04 eta 0:04:57
epoch [32/50] batch [120/162] time 0.089 (0.100) data 0.000 (0.004) loss 1.2546 (1.2341) teacher_loss 0.3856 (0.2779) loss_zs_kd 0.0236 (0.0308) loss_oracle 0.4486 (0.4841) kd_loss 0.6329 (0.6987) acc 90.6250 (88.7760) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5728 (0.5727) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0161 (0.0326) teacher/usage_max 0.9069 (0.8231) teacher/usage_min 0.0272 (0.0254) teacher/usage_std 0.4059 (0.3517) nleep/row_max_mean 1509.5322 (1512.1838) nleep/row_max_std 59.5417 (61.6031) nleep/row_min_mean 1482.1334 (1486.1527) lr 6.9098e-04 eta 0:04:54
epoch [32/50] batch [140/162] time 0.082 (0.099) data 0.000 (0.004) loss 1.1794 (1.2282) teacher_loss 0.2248 (0.2748) loss_zs_kd 0.0410 (0.0313) loss_oracle 0.4682 (0.4804) kd_loss 0.7000 (0.6975) acc 87.5000 (88.9509) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0138 (0.0305) teacher/usage_max 0.8408 (0.8264) teacher/usage_min 0.0017 (0.0234) teacher/usage_std 0.3644 (0.3539) nleep/row_max_mean 1512.6072 (1512.5144) nleep/row_max_std 63.3588 (61.4599) nleep/row_min_mean 1485.0229 (1486.4422) lr 6.9098e-04 eta 0:04:51
epoch [32/50] batch [160/162] time 0.091 (0.098) data 0.000 (0.003) loss 1.0878 (1.2299) teacher_loss 0.1928 (0.2738) loss_zs_kd 0.0281 (0.0318) loss_oracle 0.4152 (0.4800) kd_loss 0.6733 (0.7001) acc 93.7500 (88.9258) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5727 (0.5727) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0219 (0.0293) teacher/usage_max 0.8598 (0.8250) teacher/usage_min 0.0000 (0.0216) teacher/usage_std 0.3766 (0.3534) nleep/row_max_mean 1512.7976 (1512.1062) nleep/row_max_std 60.6942 (62.2015) nleep/row_min_mean 1486.8306 (1486.0469) lr 6.9098e-04 eta 0:04:46
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,933
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,247
* accuracy: 68.5%
* error: 31.5%
* macro_f1: 66.2%
******* Domain s best val acc:      86.9%, epoch: 26 *******
******* Domain s best val test acc: 69.2%, epoch: 26 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [33/50] batch [20/162] time 0.114 (0.128) data 0.000 (0.012) loss 1.1461 (1.2133) teacher_loss 0.2919 (0.2591) loss_zs_kd 0.0376 (0.0304) loss_oracle 0.4896 (0.4792) kd_loss 0.5906 (0.6994) acc 84.3750 (91.2500) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1694 (0.1693) teacher/entropy 0.0236 (0.0268) teacher/usage_max 0.9419 (0.8282) teacher/usage_min 0.0001 (0.0116) teacher/usage_std 0.4310 (0.3570) nleep/row_max_mean 1522.0754 (1510.7035) nleep/row_max_std 60.1730 (64.4100) nleep/row_min_mean 1491.4492 (1485.3964) lr 6.3188e-04 eta 0:06:09
epoch [33/50] batch [40/162] time 0.092 (0.116) data 0.000 (0.006) loss 1.1151 (1.2324) teacher_loss 0.2155 (0.2733) loss_zs_kd 0.0235 (0.0318) loss_oracle 0.4783 (0.4851) kd_loss 0.6486 (0.7006) acc 90.6250 (89.6875) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0008 (0.0316) teacher/usage_max 0.9062 (0.8221) teacher/usage_min 0.0001 (0.0142) teacher/usage_std 0.4069 (0.3529) nleep/row_max_mean 1527.9216 (1511.1120) nleep/row_max_std 46.6267 (62.8516) nleep/row_min_mean 1500.5110 (1485.5542) lr 6.3188e-04 eta 0:05:33
epoch [33/50] batch [60/162] time 0.093 (0.107) data 0.000 (0.004) loss 1.1362 (1.2364) teacher_loss 0.1507 (0.2725) loss_zs_kd 0.0271 (0.0310) loss_oracle 0.4971 (0.4888) kd_loss 0.7235 (0.7040) acc 93.7500 (89.7917) gate/entropy 0.9788 (0.9786) gate/usage_max 0.5726 (0.5728) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1692 (0.1693) teacher/entropy 0.0203 (0.0304) teacher/usage_max 0.8107 (0.8198) teacher/usage_min 0.0042 (0.0167) teacher/usage_std 0.3455 (0.3512) nleep/row_max_mean 1502.0317 (1510.7068) nleep/row_max_std 59.1966 (63.2581) nleep/row_min_mean 1479.4747 (1485.0575) lr 6.3188e-04 eta 0:05:06
epoch [33/50] batch [80/162] time 0.086 (0.102) data 0.000 (0.003) loss 1.1429 (1.2261) teacher_loss 0.3014 (0.2645) loss_zs_kd 0.0424 (0.0314) loss_oracle 0.4657 (0.4870) kd_loss 0.5875 (0.7024) acc 90.6250 (90.1953) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1694 (0.1693) teacher/entropy 0.0005 (0.0291) teacher/usage_max 0.9687 (0.8228) teacher/usage_min 0.0001 (0.0171) teacher/usage_std 0.4494 (0.3529) nleep/row_max_mean 1532.4860 (1511.4983) nleep/row_max_std 47.9193 (61.8050) nleep/row_min_mean 1501.8564 (1485.6534) lr 6.3188e-04 eta 0:04:50
epoch [33/50] batch [100/162] time 0.093 (0.100) data 0.000 (0.003) loss 1.0761 (1.2292) teacher_loss 0.1705 (0.2631) loss_zs_kd 0.0247 (0.0313) loss_oracle 0.4530 (0.4906) kd_loss 0.6668 (0.7052) acc 96.8750 (90.0625) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0303 (0.0290) teacher/usage_max 0.8579 (0.8201) teacher/usage_min 0.0309 (0.0181) teacher/usage_std 0.3724 (0.3509) nleep/row_max_mean 1526.0698 (1511.4960) nleep/row_max_std 41.0360 (60.8809) nleep/row_min_mean 1497.8972 (1485.5598) lr 6.3188e-04 eta 0:04:41
epoch [33/50] batch [120/162] time 0.086 (0.099) data 0.000 (0.002) loss 1.3812 (1.2289) teacher_loss 0.2807 (0.2651) loss_zs_kd 0.0204 (0.0310) loss_oracle 0.5171 (0.4876) kd_loss 0.8318 (0.7045) acc 84.3750 (89.6094) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1694 (0.1693) teacher/entropy 0.0018 (0.0281) teacher/usage_max 0.7187 (0.8217) teacher/usage_min 0.0003 (0.0175) teacher/usage_std 0.2956 (0.3519) nleep/row_max_mean 1503.6294 (1511.8339) nleep/row_max_std 71.1349 (60.7410) nleep/row_min_mean 1477.7046 (1485.7493) lr 6.3188e-04 eta 0:04:37
epoch [33/50] batch [140/162] time 0.091 (0.098) data 0.000 (0.002) loss 1.0459 (1.2313) teacher_loss 0.1257 (0.2693) loss_zs_kd 0.0226 (0.0316) loss_oracle 0.5235 (0.4844) kd_loss 0.6472 (0.7040) acc 100.0000 (89.4196) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1694 (0.1693) teacher/entropy 0.0777 (0.0271) teacher/usage_max 0.8295 (0.8233) teacher/usage_min 0.0453 (0.0166) teacher/usage_std 0.3524 (0.3531) nleep/row_max_mean 1525.5038 (1512.3304) nleep/row_max_std 58.4982 (60.6527) nleep/row_min_mean 1500.6843 (1486.1899) lr 6.3188e-04 eta 0:04:32
epoch [33/50] batch [160/162] time 0.089 (0.097) data 0.000 (0.002) loss 1.0974 (1.2291) teacher_loss 0.1763 (0.2691) loss_zs_kd 0.0416 (0.0315) loss_oracle 0.4653 (0.4836) kd_loss 0.6676 (0.7025) acc 90.6250 (89.3750) gate/entropy 0.9787 (0.9786) gate/usage_max 0.5727 (0.5728) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0133 (0.0270) teacher/usage_max 0.8740 (0.8248) teacher/usage_min 0.0033 (0.0163) teacher/usage_std 0.3854 (0.3541) nleep/row_max_mean 1514.1443 (1512.1601) nleep/row_max_std 60.6995 (60.5796) nleep/row_min_mean 1486.8748 (1485.9566) lr 6.3188e-04 eta 0:04:27
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,943
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 87.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,353
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 69.0%
******* Domain s best val acc:      87.0%, epoch: 33 *******
******* Domain s best val test acc: 71.7%, epoch: 33 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [34/50] batch [20/162] time 0.109 (0.114) data 0.000 (0.015) loss 0.9961 (1.2054) teacher_loss 0.0733 (0.2662) loss_zs_kd 0.0339 (0.0284) loss_oracle 0.4010 (0.4615) kd_loss 0.7053 (0.6942) acc 100.0000 (90.7812) gate/entropy 0.9787 (0.9786) gate/usage_max 0.5727 (0.5729) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0053 (0.0231) teacher/usage_max 0.8442 (0.8372) teacher/usage_min 0.0004 (0.0198) teacher/usage_std 0.3667 (0.3613) nleep/row_max_mean 1500.0404 (1510.0536) nleep/row_max_std 63.5914 (64.9199) nleep/row_min_mean 1474.9482 (1483.7937) lr 5.7422e-04 eta 0:05:12
epoch [34/50] batch [40/162] time 0.091 (0.104) data 0.000 (0.007) loss 1.1902 (1.2167) teacher_loss 0.1984 (0.2719) loss_zs_kd 0.0439 (0.0303) loss_oracle 0.5610 (0.4706) kd_loss 0.6893 (0.6943) acc 96.8750 (90.0000) gate/entropy 0.9787 (0.9786) gate/usage_max 0.5727 (0.5728) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0780 (0.0277) teacher/usage_max 0.7866 (0.8324) teacher/usage_min 0.0523 (0.0201) teacher/usage_std 0.3236 (0.3581) nleep/row_max_mean 1496.0580 (1509.3676) nleep/row_max_std 59.8936 (62.9566) nleep/row_min_mean 1471.3185 (1482.9002) lr 5.7422e-04 eta 0:04:42
epoch [34/50] batch [60/162] time 0.092 (0.100) data 0.001 (0.005) loss 1.3127 (1.2069) teacher_loss 0.2420 (0.2573) loss_zs_kd 0.0341 (0.0315) loss_oracle 0.5344 (0.4761) kd_loss 0.7865 (0.6958) acc 93.7500 (90.4688) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0193 (0.0268) teacher/usage_max 0.7472 (0.8318) teacher/usage_min 0.0328 (0.0192) teacher/usage_std 0.3024 (0.3581) nleep/row_max_mean 1507.7365 (1510.5313) nleep/row_max_std 63.4031 (62.8811) nleep/row_min_mean 1482.0104 (1483.7263) lr 5.7422e-04 eta 0:04:29
epoch [34/50] batch [80/162] time 0.090 (0.098) data 0.001 (0.004) loss 1.0451 (1.2089) teacher_loss 0.2092 (0.2672) loss_zs_kd 0.0335 (0.0303) loss_oracle 0.4035 (0.4708) kd_loss 0.6174 (0.6911) acc 93.7500 (90.1172) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0296 (0.0273) teacher/usage_max 0.9087 (0.8361) teacher/usage_min 0.0401 (0.0199) teacher/usage_std 0.4069 (0.3608) nleep/row_max_mean 1525.7465 (1510.2277) nleep/row_max_std 54.3290 (63.1898) nleep/row_min_mean 1496.6844 (1483.5165) lr 5.7422e-04 eta 0:04:21
epoch [34/50] batch [100/162] time 0.096 (0.097) data 0.000 (0.003) loss 0.9503 (1.2072) teacher_loss 0.1257 (0.2649) loss_zs_kd 0.0145 (0.0298) loss_oracle 0.4258 (0.4706) kd_loss 0.6044 (0.6921) acc 93.7500 (90.0312) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5728) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0328 (0.0275) teacher/usage_max 0.9189 (0.8348) teacher/usage_min 0.0268 (0.0192) teacher/usage_std 0.4142 (0.3602) nleep/row_max_mean 1509.2997 (1510.6615) nleep/row_max_std 65.7565 (62.8573) nleep/row_min_mean 1483.8484 (1483.9865) lr 5.7422e-04 eta 0:04:18
epoch [34/50] batch [120/162] time 0.093 (0.099) data 0.000 (0.003) loss 1.2386 (1.2166) teacher_loss 0.2835 (0.2669) loss_zs_kd 0.0290 (0.0296) loss_oracle 0.4848 (0.4727) kd_loss 0.6982 (0.6987) acc 87.5000 (89.7656) gate/entropy 0.9786 (0.9786) gate/usage_max 0.5728 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0258 (0.0275) teacher/usage_max 0.8304 (0.8282) teacher/usage_min 0.0002 (0.0193) teacher/usage_std 0.3582 (0.3561) nleep/row_max_mean 1508.3483 (1510.3229) nleep/row_max_std 58.8843 (63.3293) nleep/row_min_mean 1481.9031 (1483.8066) lr 5.7422e-04 eta 0:04:20
epoch [34/50] batch [140/162] time 0.094 (0.098) data 0.001 (0.002) loss 1.3329 (1.2236) teacher_loss 0.3011 (0.2717) loss_zs_kd 0.0541 (0.0300) loss_oracle 0.4869 (0.4732) kd_loss 0.7613 (0.7003) acc 84.3750 (89.6429) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0418 (0.0269) teacher/usage_max 0.7500 (0.8271) teacher/usage_min 0.0210 (0.0183) teacher/usage_std 0.3066 (0.3555) nleep/row_max_mean 1497.4197 (1510.1816) nleep/row_max_std 61.2570 (63.1622) nleep/row_min_mean 1470.5131 (1483.5885) lr 5.7422e-04 eta 0:04:16
epoch [34/50] batch [160/162] time 0.080 (0.097) data 0.000 (0.002) loss 1.2768 (1.2277) teacher_loss 0.2672 (0.2730) loss_zs_kd 0.0492 (0.0302) loss_oracle 0.4519 (0.4751) kd_loss 0.7591 (0.7021) acc 90.6250 (89.5117) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0469 (0.0273) teacher/usage_max 0.7472 (0.8249) teacher/usage_min 0.0342 (0.0191) teacher/usage_std 0.3022 (0.3539) nleep/row_max_mean 1487.2407 (1509.9151) nleep/row_max_std 67.3973 (63.1813) nleep/row_min_mean 1463.0051 (1483.3525) lr 5.7422e-04 eta 0:04:11
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,932
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,241
* accuracy: 68.3%
* error: 31.7%
* macro_f1: 67.4%
******* Domain s best val acc:      87.0%, epoch: 33 *******
******* Domain s best val test acc: 71.7%, epoch: 33 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [35/50] batch [20/162] time 0.095 (0.124) data 0.000 (0.017) loss 1.2429 (1.2276) teacher_loss 0.3318 (0.2541) loss_zs_kd 0.0303 (0.0358) loss_oracle 0.4561 (0.4919) kd_loss 0.6679 (0.7097) acc 90.6250 (87.9688) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0726 (0.0321) teacher/usage_max 0.8136 (0.8123) teacher/usage_min 0.0459 (0.0232) teacher/usage_std 0.3418 (0.3452) nleep/row_max_mean 1513.4594 (1508.7367) nleep/row_max_std 69.8334 (64.0449) nleep/row_min_mean 1484.8000 (1482.1460) lr 5.1825e-04 eta 0:05:20
epoch [35/50] batch [40/162] time 0.088 (0.110) data 0.000 (0.008) loss 1.3069 (1.2206) teacher_loss 0.3661 (0.2622) loss_zs_kd 0.0279 (0.0320) loss_oracle 0.4576 (0.4741) kd_loss 0.6981 (0.7054) acc 84.3750 (88.2812) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0123 (0.0299) teacher/usage_max 0.8438 (0.8189) teacher/usage_min 0.0039 (0.0206) teacher/usage_std 0.3660 (0.3496) nleep/row_max_mean 1527.2338 (1509.2176) nleep/row_max_std 64.6798 (63.1358) nleep/row_min_mean 1497.6051 (1482.4950) lr 5.1825e-04 eta 0:04:40
epoch [35/50] batch [60/162] time 0.079 (0.105) data 0.001 (0.006) loss 1.0777 (1.2022) teacher_loss 0.1468 (0.2504) loss_zs_kd 0.0346 (0.0302) loss_oracle 0.5153 (0.4769) kd_loss 0.6560 (0.6982) acc 93.7500 (89.4792) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0247 (0.0321) teacher/usage_max 0.8743 (0.8240) teacher/usage_min 0.0094 (0.0245) teacher/usage_std 0.3850 (0.3522) nleep/row_max_mean 1529.7532 (1509.9886) nleep/row_max_std 56.2129 (62.7495) nleep/row_min_mean 1500.6677 (1483.0053) lr 5.1825e-04 eta 0:04:24
epoch [35/50] batch [80/162] time 0.087 (0.101) data 0.000 (0.004) loss 1.1622 (1.2002) teacher_loss 0.1417 (0.2494) loss_zs_kd 0.0141 (0.0296) loss_oracle 0.4213 (0.4746) kd_loss 0.8029 (0.6986) acc 93.7500 (89.8438) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0294 (0.0319) teacher/usage_max 0.7201 (0.8238) teacher/usage_min 0.0047 (0.0246) teacher/usage_std 0.2949 (0.3521) nleep/row_max_mean 1507.6698 (1510.2276) nleep/row_max_std 68.0596 (62.4048) nleep/row_min_mean 1483.2859 (1483.3029) lr 5.1825e-04 eta 0:04:14
epoch [35/50] batch [100/162] time 0.088 (0.100) data 0.000 (0.004) loss 1.3099 (1.2058) teacher_loss 0.3672 (0.2552) loss_zs_kd 0.0269 (0.0299) loss_oracle 0.5119 (0.4750) kd_loss 0.6733 (0.6981) acc 87.5000 (89.4375) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0090 (0.0308) teacher/usage_max 0.8727 (0.8254) teacher/usage_min 0.0023 (0.0227) teacher/usage_std 0.3847 (0.3533) nleep/row_max_mean 1523.9949 (1511.2465) nleep/row_max_std 54.0603 (61.9153) nleep/row_min_mean 1493.2048 (1484.1258) lr 5.1825e-04 eta 0:04:08
epoch [35/50] batch [120/162] time 0.088 (0.098) data 0.000 (0.003) loss 1.3806 (1.2103) teacher_loss 0.3313 (0.2584) loss_zs_kd 0.0149 (0.0302) loss_oracle 0.5549 (0.4770) kd_loss 0.7644 (0.6982) acc 84.3750 (89.3229) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0407 (0.0311) teacher/usage_max 0.7480 (0.8249) teacher/usage_min 0.0523 (0.0243) teacher/usage_std 0.2993 (0.3527) nleep/row_max_mean 1495.0161 (1511.5771) nleep/row_max_std 67.8764 (61.5776) nleep/row_min_mean 1473.7556 (1484.5412) lr 5.1825e-04 eta 0:04:03
epoch [35/50] batch [140/162] time 0.102 (0.098) data 0.000 (0.003) loss 1.2174 (1.2177) teacher_loss 0.2474 (0.2685) loss_zs_kd 0.0354 (0.0308) loss_oracle 0.4602 (0.4754) kd_loss 0.7222 (0.6961) acc 90.6250 (89.0848) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0201 (0.0315) teacher/usage_max 0.8116 (0.8267) teacher/usage_min 0.0019 (0.0236) teacher/usage_std 0.3465 (0.3538) nleep/row_max_mean 1495.1410 (1511.8183) nleep/row_max_std 52.6729 (61.0655) nleep/row_min_mean 1470.9420 (1484.8112) lr 5.1825e-04 eta 0:04:00
epoch [35/50] batch [160/162] time 0.087 (0.097) data 0.000 (0.002) loss 1.1093 (1.2171) teacher_loss 0.1350 (0.2679) loss_zs_kd 0.0257 (0.0303) loss_oracle 0.5410 (0.4732) kd_loss 0.6910 (0.6975) acc 93.7500 (89.1016) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5731 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0199 (0.0307) teacher/usage_max 0.8437 (0.8262) teacher/usage_min 0.0230 (0.0233) teacher/usage_std 0.3637 (0.3535) nleep/row_max_mean 1503.9181 (1511.8214) nleep/row_max_std 61.4699 (60.7586) nleep/row_min_mean 1479.6357 (1484.8553) lr 5.1825e-04 eta 0:03:56
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,953
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,339
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 68.4%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [36/50] batch [20/162] time 0.109 (0.129) data 0.000 (0.015) loss 1.2522 (1.2778) teacher_loss 0.2815 (0.3097) loss_zs_kd 0.0305 (0.0334) loss_oracle 0.4070 (0.4783) kd_loss 0.7520 (0.7122) acc 93.7500 (88.1250) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0183 (0.0341) teacher/usage_max 0.7835 (0.8076) teacher/usage_min 0.0027 (0.0244) teacher/usage_std 0.3298 (0.3417) nleep/row_max_mean 1500.0514 (1511.4054) nleep/row_max_std 52.2189 (61.6840) nleep/row_min_mean 1475.1108 (1484.4648) lr 4.6417e-04 eta 0:05:10
epoch [36/50] batch [40/162] time 0.082 (0.113) data 0.000 (0.008) loss 1.2077 (1.2710) teacher_loss 0.2862 (0.2968) loss_zs_kd 0.0319 (0.0304) loss_oracle 0.4365 (0.4798) kd_loss 0.6873 (0.7191) acc 87.5000 (88.5938) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0235 (0.0318) teacher/usage_max 0.8435 (0.8030) teacher/usage_min 0.0076 (0.0259) teacher/usage_std 0.3653 (0.3387) nleep/row_max_mean 1514.8214 (1511.9325) nleep/row_max_std 61.4386 (60.9717) nleep/row_min_mean 1487.6348 (1485.0993) lr 4.6417e-04 eta 0:04:30
epoch [36/50] batch [60/162] time 0.093 (0.108) data 0.001 (0.005) loss 1.2780 (1.2663) teacher_loss 0.2711 (0.2938) loss_zs_kd 0.0339 (0.0315) loss_oracle 0.4644 (0.4817) kd_loss 0.7578 (0.7159) acc 84.3750 (88.8021) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0585 (0.0328) teacher/usage_max 0.7364 (0.8053) teacher/usage_min 0.0093 (0.0296) teacher/usage_std 0.3021 (0.3396) nleep/row_max_mean 1515.4055 (1512.9335) nleep/row_max_std 59.9465 (60.8965) nleep/row_min_mean 1486.6333 (1486.0428) lr 4.6417e-04 eta 0:04:14
epoch [36/50] batch [80/162] time 0.073 (0.104) data 0.000 (0.004) loss 1.1849 (1.2550) teacher_loss 0.1247 (0.2871) loss_zs_kd 0.0361 (0.0326) loss_oracle 0.5527 (0.4822) kd_loss 0.7658 (0.7105) acc 96.8750 (88.8672) gate/entropy 0.9786 (0.9785) gate/usage_max 0.5728 (0.5729) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1693 (0.1694) teacher/entropy 0.0399 (0.0312) teacher/usage_max 0.7476 (0.8123) teacher/usage_min 0.0919 (0.0283) teacher/usage_std 0.2943 (0.3443) nleep/row_max_mean 1494.1136 (1513.3962) nleep/row_max_std 67.7291 (60.4188) nleep/row_min_mean 1468.3247 (1486.4207) lr 4.6417e-04 eta 0:04:05
epoch [36/50] batch [100/162] time 0.100 (0.103) data 0.000 (0.003) loss 1.1856 (1.2466) teacher_loss 0.2829 (0.2850) loss_zs_kd 0.0365 (0.0324) loss_oracle 0.4763 (0.4786) kd_loss 0.6463 (0.7061) acc 84.3750 (89.0000) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0034 (0.0318) teacher/usage_max 0.9057 (0.8162) teacher/usage_min 0.0005 (0.0286) teacher/usage_std 0.4065 (0.3467) nleep/row_max_mean 1517.6226 (1513.5228) nleep/row_max_std 61.3355 (60.4241) nleep/row_min_mean 1490.1129 (1486.4229) lr 4.6417e-04 eta 0:03:59
epoch [36/50] batch [120/162] time 0.094 (0.102) data 0.000 (0.003) loss 1.0800 (1.2383) teacher_loss 0.2362 (0.2795) loss_zs_kd 0.0322 (0.0322) loss_oracle 0.4533 (0.4786) kd_loss 0.6010 (0.7034) acc 84.3750 (89.0104) gate/entropy 0.9785 (0.9785) gate/usage_max 0.5729 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0624 (0.0328) teacher/usage_max 0.8918 (0.8180) teacher/usage_min 0.0213 (0.0290) teacher/usage_std 0.3958 (0.3477) nleep/row_max_mean 1521.6753 (1513.1554) nleep/row_max_std 54.1646 (60.6964) nleep/row_min_mean 1492.8938 (1486.0806) lr 4.6417e-04 eta 0:03:56
epoch [36/50] batch [140/162] time 0.095 (0.102) data 0.000 (0.002) loss 1.0923 (1.2307) teacher_loss 0.2010 (0.2725) loss_zs_kd 0.0195 (0.0317) loss_oracle 0.4395 (0.4779) kd_loss 0.6619 (0.7033) acc 87.5000 (89.2188) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0719 (0.0330) teacher/usage_max 0.8201 (0.8179) teacher/usage_min 0.0363 (0.0278) teacher/usage_std 0.3469 (0.3478) nleep/row_max_mean 1513.7329 (1512.4184) nleep/row_max_std 67.4231 (60.7950) nleep/row_min_mean 1486.5662 (1485.3223) lr 4.6417e-04 eta 0:03:53
epoch [36/50] batch [160/162] time 0.094 (0.101) data 0.000 (0.002) loss 1.3143 (1.2275) teacher_loss 0.3399 (0.2734) loss_zs_kd 0.0391 (0.0310) loss_oracle 0.4549 (0.4755) kd_loss 0.7274 (0.7008) acc 90.6250 (89.1211) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0140 (0.0327) teacher/usage_max 0.8128 (0.8206) teacher/usage_min 0.0273 (0.0269) teacher/usage_std 0.3433 (0.3497) nleep/row_max_mean 1495.3591 (1512.6793) nleep/row_max_std 70.0346 (60.7295) nleep/row_min_mean 1469.0857 (1485.5549) lr 4.6417e-04 eta 0:03:48
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,941
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,330
* accuracy: 71.0%
* error: 29.0%
* macro_f1: 68.0%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [37/50] batch [20/162] time 0.088 (0.106) data 0.000 (0.023) loss 1.0625 (1.2594) teacher_loss 0.1403 (0.2741) loss_zs_kd 0.0300 (0.0318) loss_oracle 0.4331 (0.4826) kd_loss 0.6906 (0.7281) acc 90.6250 (88.7500) gate/entropy 0.9787 (0.9784) gate/usage_max 0.5728 (0.5730) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1693 (0.1695) teacher/entropy 0.0253 (0.0288) teacher/usage_max 0.8388 (0.7969) teacher/usage_min 0.0072 (0.0291) teacher/usage_std 0.3624 (0.3346) nleep/row_max_mean 1505.1128 (1508.7059) nleep/row_max_std 51.8453 (62.3283) nleep/row_min_mean 1478.9171 (1481.8858) lr 4.1221e-04 eta 0:03:59
epoch [37/50] batch [40/162] time 0.081 (0.099) data 0.000 (0.012) loss 1.1355 (1.2268) teacher_loss 0.2265 (0.2603) loss_zs_kd 0.0291 (0.0318) loss_oracle 0.4786 (0.4754) kd_loss 0.6551 (0.7130) acc 90.6250 (88.7500) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0573 (0.0300) teacher/usage_max 0.8422 (0.8110) teacher/usage_min 0.0206 (0.0276) teacher/usage_std 0.3629 (0.3432) nleep/row_max_mean 1514.3202 (1511.5604) nleep/row_max_std 64.3275 (61.5765) nleep/row_min_mean 1486.8643 (1484.4629) lr 4.1221e-04 eta 0:03:39
epoch [37/50] batch [60/162] time 0.093 (0.097) data 0.001 (0.008) loss 1.2366 (1.2326) teacher_loss 0.1808 (0.2728) loss_zs_kd 0.0175 (0.0319) loss_oracle 0.5636 (0.4734) kd_loss 0.7652 (0.7071) acc 90.6250 (88.2292) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0644 (0.0310) teacher/usage_max 0.7234 (0.8159) teacher/usage_min 0.1191 (0.0274) teacher/usage_std 0.2762 (0.3463) nleep/row_max_mean 1519.0076 (1513.1542) nleep/row_max_std 52.8678 (60.4771) nleep/row_min_mean 1492.0676 (1485.8619) lr 4.1221e-04 eta 0:03:34
epoch [37/50] batch [80/162] time 0.092 (0.097) data 0.000 (0.006) loss 1.1743 (1.2166) teacher_loss 0.1963 (0.2645) loss_zs_kd 0.0234 (0.0308) loss_oracle 0.4736 (0.4730) kd_loss 0.7296 (0.7003) acc 90.6250 (88.7500) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0101 (0.0297) teacher/usage_max 0.8143 (0.8242) teacher/usage_min 0.0315 (0.0258) teacher/usage_std 0.3438 (0.3519) nleep/row_max_mean 1514.2063 (1513.4108) nleep/row_max_std 71.2309 (60.2009) nleep/row_min_mean 1486.4280 (1485.8737) lr 4.1221e-04 eta 0:03:32
epoch [37/50] batch [100/162] time 0.102 (0.097) data 0.000 (0.005) loss 1.2121 (1.2143) teacher_loss 0.2784 (0.2594) loss_zs_kd 0.0228 (0.0311) loss_oracle 0.4582 (0.4733) kd_loss 0.6932 (0.7027) acc 87.5000 (89.1875) gate/entropy 0.9785 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0178 (0.0320) teacher/usage_max 0.8437 (0.8195) teacher/usage_min 0.0069 (0.0261) teacher/usage_std 0.3656 (0.3491) nleep/row_max_mean 1499.8289 (1513.2196) nleep/row_max_std 59.7388 (59.7248) nleep/row_min_mean 1471.9591 (1485.8254) lr 4.1221e-04 eta 0:03:30
epoch [37/50] batch [120/162] time 0.097 (0.097) data 0.000 (0.004) loss 1.2179 (1.2172) teacher_loss 0.2011 (0.2602) loss_zs_kd 0.0294 (0.0312) loss_oracle 0.4929 (0.4752) kd_loss 0.7557 (0.7038) acc 90.6250 (89.1406) gate/entropy 0.9785 (0.9784) gate/usage_max 0.5729 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0145 (0.0317) teacher/usage_max 0.7834 (0.8186) teacher/usage_min 0.0609 (0.0258) teacher/usage_std 0.3206 (0.3486) nleep/row_max_mean 1518.6310 (1513.1738) nleep/row_max_std 54.7960 (59.5923) nleep/row_min_mean 1492.5471 (1485.8477) lr 4.1221e-04 eta 0:03:28
epoch [37/50] batch [140/162] time 0.110 (0.100) data 0.000 (0.004) loss 1.0887 (1.2157) teacher_loss 0.1954 (0.2613) loss_zs_kd 0.0294 (0.0307) loss_oracle 0.4236 (0.4735) kd_loss 0.6668 (0.7022) acc 87.5000 (89.1295) gate/entropy 0.9785 (0.9784) gate/usage_max 0.5729 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0106 (0.0315) teacher/usage_max 0.8776 (0.8203) teacher/usage_min 0.0001 (0.0251) teacher/usage_std 0.3881 (0.3497) nleep/row_max_mean 1500.2141 (1513.1398) nleep/row_max_std 57.9389 (59.2624) nleep/row_min_mean 1474.1134 (1485.8228) lr 4.1221e-04 eta 0:03:32
epoch [37/50] batch [160/162] time 0.077 (0.099) data 0.000 (0.003) loss 1.1352 (1.2173) teacher_loss 0.2151 (0.2665) loss_zs_kd 0.0434 (0.0306) loss_oracle 0.4883 (0.4710) kd_loss 0.6543 (0.7000) acc 93.7500 (88.9453) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5731 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0513 (0.0327) teacher/usage_max 0.8490 (0.8215) teacher/usage_min 0.0492 (0.0260) teacher/usage_std 0.3652 (0.3503) nleep/row_max_mean 1531.7002 (1513.1684) nleep/row_max_std 45.8546 (59.0872) nleep/row_min_mean 1501.7163 (1485.8911) lr 4.1221e-04 eta 0:03:28
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,948
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 87.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,323
* accuracy: 70.8%
* error: 29.2%
* macro_f1: 68.6%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [38/50] batch [20/162] time 0.092 (0.113) data 0.000 (0.013) loss 1.0349 (1.2004) teacher_loss 0.1896 (0.2552) loss_zs_kd 0.0351 (0.0303) loss_oracle 0.3818 (0.4647) kd_loss 0.6368 (0.6978) acc 93.7500 (90.3125) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5731 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0124 (0.0311) teacher/usage_max 0.9061 (0.8253) teacher/usage_min 0.0036 (0.0283) teacher/usage_std 0.4066 (0.3524) nleep/row_max_mean 1514.4808 (1506.5479) nleep/row_max_std 60.5088 (60.3601) nleep/row_min_mean 1488.6195 (1480.3028) lr 3.6258e-04 eta 0:03:54
epoch [38/50] batch [40/162] time 0.071 (0.106) data 0.000 (0.007) loss 1.2584 (1.1756) teacher_loss 0.3271 (0.2311) loss_zs_kd 0.0407 (0.0305) loss_oracle 0.4675 (0.4657) kd_loss 0.6771 (0.6965) acc 87.5000 (91.1719) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0027 (0.0311) teacher/usage_max 0.8750 (0.8267) teacher/usage_min 0.0005 (0.0260) teacher/usage_std 0.3863 (0.3539) nleep/row_max_mean 1518.5430 (1508.5991) nleep/row_max_std 48.5237 (59.8273) nleep/row_min_mean 1488.5331 (1482.0498) lr 3.6258e-04 eta 0:03:38
epoch [38/50] batch [60/162] time 0.101 (0.102) data 0.001 (0.005) loss 1.1162 (1.1812) teacher_loss 0.2342 (0.2426) loss_zs_kd 0.0283 (0.0316) loss_oracle 0.4096 (0.4629) kd_loss 0.6630 (0.6914) acc 93.7500 (90.2083) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0169 (0.0317) teacher/usage_max 0.8752 (0.8312) teacher/usage_min 0.0058 (0.0240) teacher/usage_std 0.3859 (0.3569) nleep/row_max_mean 1486.5486 (1508.7333) nleep/row_max_std 62.7987 (60.1897) nleep/row_min_mean 1461.4977 (1482.3362) lr 3.6258e-04 eta 0:03:29
epoch [38/50] batch [80/162] time 0.093 (0.102) data 0.000 (0.004) loss 1.1692 (1.2061) teacher_loss 0.3668 (0.2592) loss_zs_kd 0.0350 (0.0322) loss_oracle 0.3335 (0.4666) kd_loss 0.6182 (0.6976) acc 84.3750 (89.6875) gate/entropy 0.9785 (0.9784) gate/usage_max 0.5729 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1694 (0.1695) teacher/entropy 0.0341 (0.0313) teacher/usage_max 0.9032 (0.8253) teacher/usage_min 0.0073 (0.0246) teacher/usage_std 0.4043 (0.3530) nleep/row_max_mean 1501.0730 (1508.6007) nleep/row_max_std 59.8700 (61.1430) nleep/row_min_mean 1476.7283 (1482.3425) lr 3.6258e-04 eta 0:03:26
epoch [38/50] batch [100/162] time 0.115 (0.102) data 0.000 (0.003) loss 1.2873 (1.2123) teacher_loss 0.3599 (0.2654) loss_zs_kd 0.0341 (0.0315) loss_oracle 0.4881 (0.4670) kd_loss 0.6663 (0.6977) acc 90.6250 (89.3125) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0141 (0.0314) teacher/usage_max 0.8743 (0.8251) teacher/usage_min 0.0039 (0.0241) teacher/usage_std 0.3856 (0.3531) nleep/row_max_mean 1508.6946 (1508.5800) nleep/row_max_std 68.8514 (61.6630) nleep/row_min_mean 1480.0293 (1482.2794) lr 3.6258e-04 eta 0:03:25
epoch [38/50] batch [120/162] time 0.105 (0.103) data 0.000 (0.002) loss 1.1236 (1.2189) teacher_loss 0.1433 (0.2668) loss_zs_kd 0.0274 (0.0314) loss_oracle 0.5149 (0.4696) kd_loss 0.7092 (0.7016) acc 93.7500 (89.2969) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0446 (0.0317) teacher/usage_max 0.8000 (0.8207) teacher/usage_min 0.0460 (0.0238) teacher/usage_std 0.3329 (0.3504) nleep/row_max_mean 1519.2206 (1508.0133) nleep/row_max_std 55.3209 (62.0930) nleep/row_min_mean 1491.4995 (1481.8304) lr 3.6258e-04 eta 0:03:23
epoch [38/50] batch [140/162] time 0.108 (0.102) data 0.000 (0.002) loss 1.1246 (1.2266) teacher_loss 0.2251 (0.2735) loss_zs_kd 0.0168 (0.0312) loss_oracle 0.5015 (0.4711) kd_loss 0.6404 (0.7019) acc 93.7500 (88.9509) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0543 (0.0325) teacher/usage_max 0.8598 (0.8197) teacher/usage_min 0.0266 (0.0239) teacher/usage_std 0.3739 (0.3498) nleep/row_max_mean 1506.3413 (1508.0465) nleep/row_max_std 68.1549 (61.9544) nleep/row_min_mean 1480.8975 (1481.8137) lr 3.6258e-04 eta 0:03:20
epoch [38/50] batch [160/162] time 0.092 (0.101) data 0.000 (0.002) loss 1.7037 (1.2347) teacher_loss 0.5976 (0.2822) loss_zs_kd 0.0430 (0.0312) loss_oracle 0.5493 (0.4692) kd_loss 0.8100 (0.7023) acc 81.2500 (88.6328) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5730) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0237 (0.0318) teacher/usage_max 0.7189 (0.8200) teacher/usage_min 0.0077 (0.0234) teacher/usage_std 0.2934 (0.3500) nleep/row_max_mean 1488.9408 (1507.6904) nleep/row_max_std 66.0282 (62.0869) nleep/row_min_mean 1466.0979 (1481.5293) lr 3.6258e-04 eta 0:03:16
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,943
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 87.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,348
* accuracy: 71.5%
* error: 28.5%
* macro_f1: 68.4%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [39/50] batch [20/162] time 0.096 (0.114) data 0.000 (0.015) loss 1.3385 (1.2091) teacher_loss 0.4117 (0.2803) loss_zs_kd 0.0239 (0.0257) loss_oracle 0.4550 (0.4565) kd_loss 0.6873 (0.6877) acc 81.2500 (87.5000) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0239 (0.0255) teacher/usage_max 0.8433 (0.8412) teacher/usage_min 0.0257 (0.0226) teacher/usage_std 0.3632 (0.3640) nleep/row_max_mean 1509.4473 (1512.8836) nleep/row_max_std 63.6540 (57.6814) nleep/row_min_mean 1482.9810 (1486.3588) lr 3.1545e-04 eta 0:03:38
epoch [39/50] batch [40/162] time 0.088 (0.106) data 0.001 (0.008) loss 1.2507 (1.2345) teacher_loss 0.1953 (0.2855) loss_zs_kd 0.0119 (0.0272) loss_oracle 0.4898 (0.4690) kd_loss 0.8046 (0.7009) acc 96.8750 (88.1250) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0486 (0.0249) teacher/usage_max 0.6990 (0.8284) teacher/usage_min 0.0080 (0.0199) teacher/usage_std 0.2835 (0.3564) nleep/row_max_mean 1507.4631 (1512.8145) nleep/row_max_std 65.5545 (57.9748) nleep/row_min_mean 1485.5328 (1486.5972) lr 3.1545e-04 eta 0:03:21
epoch [39/50] batch [60/162] time 0.091 (0.102) data 0.001 (0.005) loss 1.0136 (1.2325) teacher_loss 0.1101 (0.2742) loss_zs_kd 0.0201 (0.0279) loss_oracle 0.3989 (0.4707) kd_loss 0.6940 (0.7091) acc 96.8750 (89.1146) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0164 (0.0277) teacher/usage_max 0.8438 (0.8172) teacher/usage_min 0.0062 (0.0210) teacher/usage_std 0.3657 (0.3492) nleep/row_max_mean 1524.4427 (1512.6899) nleep/row_max_std 51.5784 (58.4259) nleep/row_min_mean 1497.7644 (1486.8122) lr 3.1545e-04 eta 0:03:12
epoch [39/50] batch [80/162] time 0.113 (0.102) data 0.000 (0.004) loss 1.2146 (1.2261) teacher_loss 0.2773 (0.2712) loss_zs_kd 0.0349 (0.0286) loss_oracle 0.4950 (0.4711) kd_loss 0.6724 (0.7051) acc 93.7500 (89.0625) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0436 (0.0287) teacher/usage_max 0.8381 (0.8203) teacher/usage_min 0.0228 (0.0200) teacher/usage_std 0.3601 (0.3510) nleep/row_max_mean 1507.0226 (1513.7438) nleep/row_max_std 64.0890 (57.8935) nleep/row_min_mean 1479.7714 (1487.6576) lr 3.1545e-04 eta 0:03:09
epoch [39/50] batch [100/162] time 0.090 (0.101) data 0.000 (0.003) loss 1.1007 (1.2227) teacher_loss 0.1421 (0.2701) loss_zs_kd 0.0305 (0.0278) loss_oracle 0.5144 (0.4698) kd_loss 0.6861 (0.7038) acc 100.0000 (89.4062) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0252 (0.0289) teacher/usage_max 0.8431 (0.8214) teacher/usage_min 0.0334 (0.0214) teacher/usage_std 0.3623 (0.3513) nleep/row_max_mean 1525.8452 (1514.2079) nleep/row_max_std 56.6327 (57.4532) nleep/row_min_mean 1497.6351 (1488.0450) lr 3.1545e-04 eta 0:03:06
epoch [39/50] batch [120/162] time 0.109 (0.101) data 0.000 (0.003) loss 1.0687 (1.2215) teacher_loss 0.1579 (0.2636) loss_zs_kd 0.0343 (0.0285) loss_oracle 0.4853 (0.4753) kd_loss 0.6509 (0.7060) acc 96.8750 (89.7396) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0493 (0.0300) teacher/usage_max 0.8545 (0.8180) teacher/usage_min 0.0520 (0.0232) teacher/usage_std 0.3689 (0.3488) nleep/row_max_mean 1525.6569 (1514.0385) nleep/row_max_std 59.0242 (57.5231) nleep/row_min_mean 1498.8330 (1487.8825) lr 3.1545e-04 eta 0:03:03
epoch [39/50] batch [140/162] time 0.093 (0.101) data 0.001 (0.002) loss 1.1357 (1.2186) teacher_loss 0.2744 (0.2639) loss_zs_kd 0.0165 (0.0284) loss_oracle 0.4242 (0.4732) kd_loss 0.6410 (0.7039) acc 87.5000 (89.5312) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0095 (0.0302) teacher/usage_max 0.9047 (0.8199) teacher/usage_min 0.0006 (0.0227) teacher/usage_std 0.4058 (0.3499) nleep/row_max_mean 1512.5063 (1513.8146) nleep/row_max_std 65.9569 (58.0766) nleep/row_min_mean 1483.9756 (1487.6281) lr 3.1545e-04 eta 0:03:02
epoch [39/50] batch [160/162] time 0.089 (0.100) data 0.000 (0.002) loss 0.9683 (1.2205) teacher_loss 0.1147 (0.2622) loss_zs_kd 0.0121 (0.0284) loss_oracle 0.3790 (0.4753) kd_loss 0.6581 (0.7065) acc 96.8750 (89.6094) gate/entropy 0.9784 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0653 (0.0305) teacher/usage_max 0.8309 (0.8170) teacher/usage_min 0.0258 (0.0231) teacher/usage_std 0.3551 (0.3482) nleep/row_max_mean 1512.2397 (1513.1719) nleep/row_max_std 65.0341 (58.7230) nleep/row_min_mean 1488.1749 (1486.9906) lr 3.1545e-04 eta 0:02:58
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,344
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 69.0%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [40/50] batch [20/162] time 0.096 (0.118) data 0.000 (0.015) loss 1.3849 (1.2458) teacher_loss 0.4744 (0.3014) loss_zs_kd 0.0381 (0.0338) loss_oracle 0.4470 (0.4751) kd_loss 0.6680 (0.6900) acc 78.1250 (87.5000) gate/entropy 0.9784 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0423 (0.0259) teacher/usage_max 0.8438 (0.8383) teacher/usage_min 0.0228 (0.0153) teacher/usage_std 0.3638 (0.3624) nleep/row_max_mean 1503.5024 (1510.2463) nleep/row_max_std 68.5792 (62.6402) nleep/row_min_mean 1477.4210 (1483.9532) lr 2.7103e-04 eta 0:03:28
epoch [40/50] batch [40/162] time 0.110 (0.107) data 0.001 (0.008) loss 1.2133 (1.2389) teacher_loss 0.1517 (0.2786) loss_zs_kd 0.0339 (0.0317) loss_oracle 0.4756 (0.4752) kd_loss 0.8069 (0.7069) acc 90.6250 (89.0625) gate/entropy 0.9784 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0572 (0.0284) teacher/usage_max 0.6881 (0.8186) teacher/usage_min 0.0906 (0.0200) teacher/usage_std 0.2565 (0.3494) nleep/row_max_mean 1504.3296 (1510.1942) nleep/row_max_std 67.3699 (62.9150) nleep/row_min_mean 1480.5758 (1484.2233) lr 2.7103e-04 eta 0:03:07
epoch [40/50] batch [60/162] time 0.085 (0.102) data 0.001 (0.005) loss 1.4038 (1.2417) teacher_loss 0.4110 (0.2848) loss_zs_kd 0.0353 (0.0309) loss_oracle 0.4580 (0.4745) kd_loss 0.7461 (0.7042) acc 84.3750 (88.8542) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0271 (0.0289) teacher/usage_max 0.7802 (0.8209) teacher/usage_min 0.0247 (0.0223) teacher/usage_std 0.3235 (0.3503) nleep/row_max_mean 1502.9094 (1510.0645) nleep/row_max_std 61.6636 (62.5185) nleep/row_min_mean 1476.2017 (1483.9746) lr 2.7103e-04 eta 0:02:55
epoch [40/50] batch [80/162] time 0.097 (0.100) data 0.000 (0.004) loss 1.0662 (1.2231) teacher_loss 0.1901 (0.2755) loss_zs_kd 0.0187 (0.0296) loss_oracle 0.4117 (0.4649) kd_loss 0.6610 (0.7004) acc 90.6250 (89.0625) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0258 (0.0303) teacher/usage_max 0.8678 (0.8234) teacher/usage_min 0.0086 (0.0211) teacher/usage_std 0.3808 (0.3522) nleep/row_max_mean 1528.3342 (1509.8625) nleep/row_max_std 56.5985 (62.3046) nleep/row_min_mean 1499.7810 (1483.8620) lr 2.7103e-04 eta 0:02:50
epoch [40/50] batch [100/162] time 0.095 (0.101) data 0.000 (0.003) loss 1.0600 (1.2139) teacher_loss 0.1178 (0.2628) loss_zs_kd 0.0275 (0.0299) loss_oracle 0.3914 (0.4685) kd_loss 0.7327 (0.7019) acc 96.8750 (89.5938) gate/entropy 0.9784 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0321 (0.0307) teacher/usage_max 0.7891 (0.8214) teacher/usage_min 0.0559 (0.0222) teacher/usage_std 0.3248 (0.3510) nleep/row_max_mean 1506.5458 (1510.2190) nleep/row_max_std 68.4814 (62.4111) nleep/row_min_mean 1482.2307 (1484.2633) lr 2.7103e-04 eta 0:02:49
epoch [40/50] batch [120/162] time 0.088 (0.102) data 0.000 (0.003) loss 1.1660 (1.2124) teacher_loss 0.3037 (0.2604) loss_zs_kd 0.0314 (0.0298) loss_oracle 0.4107 (0.4686) kd_loss 0.6413 (0.7028) acc 90.6250 (89.8438) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0079 (0.0307) teacher/usage_max 0.9060 (0.8206) teacher/usage_min 0.0016 (0.0220) teacher/usage_std 0.4066 (0.3505) nleep/row_max_mean 1522.3944 (1510.0385) nleep/row_max_std 58.5543 (62.6120) nleep/row_min_mean 1494.3721 (1484.0413) lr 2.7103e-04 eta 0:02:48
epoch [40/50] batch [140/162] time 0.094 (0.100) data 0.000 (0.002) loss 1.1485 (1.2175) teacher_loss 0.2392 (0.2635) loss_zs_kd 0.0406 (0.0302) loss_oracle 0.4413 (0.4708) kd_loss 0.6683 (0.7035) acc 84.3750 (89.5759) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0359 (0.0295) teacher/usage_max 0.8503 (0.8211) teacher/usage_min 0.0268 (0.0212) teacher/usage_std 0.3676 (0.3509) nleep/row_max_mean 1517.1785 (1509.9133) nleep/row_max_std 60.0428 (62.6686) nleep/row_min_mean 1491.1436 (1483.8951) lr 2.7103e-04 eta 0:02:44
epoch [40/50] batch [160/162] time 0.086 (0.101) data 0.000 (0.002) loss 1.0898 (1.2214) teacher_loss 0.1834 (0.2671) loss_zs_kd 0.0252 (0.0303) loss_oracle 0.4789 (0.4700) kd_loss 0.6543 (0.7041) acc 90.6250 (89.3164) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5733 (0.5731) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1697 (0.1695) teacher/entropy 0.0242 (0.0300) teacher/usage_max 0.8761 (0.8200) teacher/usage_min 0.0302 (0.0218) teacher/usage_std 0.3847 (0.3501) nleep/row_max_mean 1538.8755 (1509.9602) nleep/row_max_std 54.2413 (62.5815) nleep/row_min_mean 1508.5237 (1483.9698) lr 2.7103e-04 eta 0:02:43
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,945
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 87.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,356
* accuracy: 71.8%
* error: 28.2%
* macro_f1: 69.3%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [41/50] batch [20/162] time 0.087 (0.114) data 0.000 (0.015) loss 1.1852 (1.1890) teacher_loss 0.1990 (0.2428) loss_zs_kd 0.0252 (0.0289) loss_oracle 0.4466 (0.4641) kd_loss 0.7503 (0.6997) acc 90.6250 (91.0938) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0221 (0.0356) teacher/usage_max 0.7813 (0.8187) teacher/usage_min 0.0640 (0.0320) teacher/usage_std 0.3189 (0.3480) nleep/row_max_mean 1509.2712 (1513.8509) nleep/row_max_std 64.2941 (61.1847) nleep/row_min_mean 1483.4954 (1488.0844) lr 2.2949e-04 eta 0:03:01
epoch [41/50] batch [40/162] time 0.086 (0.107) data 0.000 (0.008) loss 1.0936 (1.2010) teacher_loss 0.2231 (0.2629) loss_zs_kd 0.0320 (0.0308) loss_oracle 0.4206 (0.4602) kd_loss 0.6442 (0.6926) acc 93.7500 (89.9219) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0057 (0.0319) teacher/usage_max 0.9053 (0.8297) teacher/usage_min 0.0010 (0.0256) teacher/usage_std 0.4062 (0.3557) nleep/row_max_mean 1509.0922 (1511.0492) nleep/row_max_std 69.9402 (62.4323) nleep/row_min_mean 1485.8000 (1485.2073) lr 2.2949e-04 eta 0:02:49
epoch [41/50] batch [60/162] time 0.097 (0.102) data 0.001 (0.005) loss 1.4996 (1.2072) teacher_loss 0.4387 (0.2629) loss_zs_kd 0.0262 (0.0295) loss_oracle 0.4722 (0.4651) kd_loss 0.8117 (0.6970) acc 84.3750 (90.0521) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0215 (0.0325) teacher/usage_max 0.7189 (0.8246) teacher/usage_min 0.0056 (0.0259) teacher/usage_std 0.2941 (0.3526) nleep/row_max_mean 1511.8058 (1510.2348) nleep/row_max_std 69.6956 (62.6794) nleep/row_min_mean 1486.6688 (1484.5222) lr 2.2949e-04 eta 0:02:39
epoch [41/50] batch [80/162] time 0.090 (0.101) data 0.000 (0.004) loss 1.0809 (1.2084) teacher_loss 0.1617 (0.2654) loss_zs_kd 0.0256 (0.0295) loss_oracle 0.4468 (0.4600) kd_loss 0.6830 (0.6982) acc 93.7500 (89.8438) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0645 (0.0336) teacher/usage_max 0.8064 (0.8222) teacher/usage_min 0.0228 (0.0268) teacher/usage_std 0.3399 (0.3509) nleep/row_max_mean 1508.8936 (1509.6607) nleep/row_max_std 65.8509 (63.2967) nleep/row_min_mean 1484.4092 (1484.0543) lr 2.2949e-04 eta 0:02:34
epoch [41/50] batch [100/162] time 0.099 (0.100) data 0.001 (0.003) loss 1.2020 (1.2072) teacher_loss 0.3062 (0.2625) loss_zs_kd 0.0235 (0.0288) loss_oracle 0.4522 (0.4605) kd_loss 0.6579 (0.7000) acc 93.7500 (90.0000) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0517 (0.0340) teacher/usage_max 0.8449 (0.8201) teacher/usage_min 0.0759 (0.0275) teacher/usage_std 0.3617 (0.3494) nleep/row_max_mean 1524.1086 (1509.1867) nleep/row_max_std 66.0493 (63.3941) nleep/row_min_mean 1498.3856 (1483.6532) lr 2.2949e-04 eta 0:02:32
epoch [41/50] batch [120/162] time 0.102 (0.101) data 0.000 (0.003) loss 1.0186 (1.2061) teacher_loss 0.1266 (0.2594) loss_zs_kd 0.0178 (0.0287) loss_oracle 0.4458 (0.4629) kd_loss 0.6602 (0.7009) acc 96.8750 (90.0260) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0196 (0.0344) teacher/usage_max 0.8750 (0.8187) teacher/usage_min 0.0221 (0.0291) teacher/usage_std 0.3844 (0.3483) nleep/row_max_mean 1525.3918 (1509.2740) nleep/row_max_std 52.3896 (63.1932) nleep/row_min_mean 1497.1406 (1483.6679) lr 2.2949e-04 eta 0:02:31
epoch [41/50] batch [140/162] time 0.105 (0.101) data 0.000 (0.002) loss 1.4369 (1.2203) teacher_loss 0.3744 (0.2650) loss_zs_kd 0.0427 (0.0294) loss_oracle 0.5414 (0.4701) kd_loss 0.7704 (0.7056) acc 84.3750 (89.7321) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0337 (0.0364) teacher/usage_max 0.7491 (0.8120) teacher/usage_min 0.0354 (0.0303) teacher/usage_std 0.3030 (0.3442) nleep/row_max_mean 1488.4431 (1508.7024) nleep/row_max_std 72.3883 (63.1953) nleep/row_min_mean 1463.9159 (1483.1703) lr 2.2949e-04 eta 0:02:30
epoch [41/50] batch [160/162] time 0.087 (0.100) data 0.000 (0.002) loss 1.1618 (1.2198) teacher_loss 0.2281 (0.2696) loss_zs_kd 0.0318 (0.0292) loss_oracle 0.4478 (0.4674) kd_loss 0.6939 (0.7019) acc 90.6250 (89.5898) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0154 (0.0354) teacher/usage_max 0.8450 (0.8167) teacher/usage_min 0.0291 (0.0293) teacher/usage_std 0.3639 (0.3473) nleep/row_max_mean 1533.5342 (1509.4919) nleep/row_max_std 57.2775 (62.6595) nleep/row_min_mean 1507.1884 (1483.8809) lr 2.2949e-04 eta 0:02:26
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,937
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,362
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 69.0%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [42/50] batch [20/162] time 0.098 (0.120) data 0.000 (0.018) loss 1.2260 (1.1990) teacher_loss 0.2307 (0.2425) loss_zs_kd 0.0222 (0.0310) loss_oracle 0.5149 (0.4690) kd_loss 0.7267 (0.7064) acc 90.6250 (91.2500) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0909 (0.0413) teacher/usage_max 0.7354 (0.8061) teacher/usage_min 0.1105 (0.0294) teacher/usage_std 0.2849 (0.3406) nleep/row_max_mean 1516.8816 (1511.8979) nleep/row_max_std 63.4583 (61.7835) nleep/row_min_mean 1490.2876 (1486.6956) lr 1.9098e-04 eta 0:02:53
epoch [42/50] batch [40/162] time 0.185 (0.114) data 0.002 (0.009) loss 1.2808 (1.2134) teacher_loss 0.2348 (0.2548) loss_zs_kd 0.0328 (0.0299) loss_oracle 0.5280 (0.4717) kd_loss 0.7656 (0.7077) acc 93.7500 (90.3125) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0340 (0.0339) teacher/usage_max 0.7532 (0.8123) teacher/usage_min 0.0304 (0.0258) teacher/usage_std 0.3065 (0.3450) nleep/row_max_mean 1509.2585 (1509.4151) nleep/row_max_std 60.5800 (61.9721) nleep/row_min_mean 1482.1416 (1483.8454) lr 1.9098e-04 eta 0:02:42
epoch [42/50] batch [60/162] time 0.105 (0.113) data 0.001 (0.006) loss 1.1608 (1.2049) teacher_loss 0.2209 (0.2554) loss_zs_kd 0.0292 (0.0296) loss_oracle 0.4766 (0.4651) kd_loss 0.6870 (0.7021) acc 93.7500 (90.6771) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0238 (0.0329) teacher/usage_max 0.8435 (0.8189) teacher/usage_min 0.0084 (0.0263) teacher/usage_std 0.3652 (0.3490) nleep/row_max_mean 1507.7788 (1510.2032) nleep/row_max_std 61.4079 (61.2077) nleep/row_min_mean 1481.8755 (1484.5588) lr 1.9098e-04 eta 0:02:38
epoch [42/50] batch [80/162] time 0.110 (0.111) data 0.001 (0.005) loss 1.0959 (1.2045) teacher_loss 0.1175 (0.2541) loss_zs_kd 0.0237 (0.0293) loss_oracle 0.4910 (0.4657) kd_loss 0.7211 (0.7029) acc 96.8750 (90.5078) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0183 (0.0340) teacher/usage_max 0.8141 (0.8171) teacher/usage_min 0.0018 (0.0254) teacher/usage_std 0.3480 (0.3481) nleep/row_max_mean 1515.8252 (1510.9689) nleep/row_max_std 57.2117 (60.0337) nleep/row_min_mean 1491.3496 (1485.3203) lr 1.9098e-04 eta 0:02:32
epoch [42/50] batch [100/162] time 0.105 (0.107) data 0.000 (0.004) loss 1.2093 (1.2168) teacher_loss 0.2100 (0.2640) loss_zs_kd 0.0312 (0.0289) loss_oracle 0.5138 (0.4700) kd_loss 0.7268 (0.7032) acc 90.6250 (90.0000) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0145 (0.0340) teacher/usage_max 0.8127 (0.8167) teacher/usage_min 0.0352 (0.0262) teacher/usage_std 0.3423 (0.3477) nleep/row_max_mean 1517.9849 (1511.6536) nleep/row_max_std 50.7456 (59.3542) nleep/row_min_mean 1491.6218 (1485.8640) lr 1.9098e-04 eta 0:02:25
epoch [42/50] batch [120/162] time 0.114 (0.107) data 0.001 (0.003) loss 1.1988 (1.2102) teacher_loss 0.1575 (0.2602) loss_zs_kd 0.0299 (0.0290) loss_oracle 0.5813 (0.4677) kd_loss 0.7357 (0.7016) acc 96.8750 (90.0521) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0367 (0.0354) teacher/usage_max 0.7810 (0.8170) teacher/usage_min 0.0159 (0.0271) teacher/usage_std 0.3256 (0.3477) nleep/row_max_mean 1508.2772 (1511.8174) nleep/row_max_std 61.2751 (59.2344) nleep/row_min_mean 1481.9741 (1485.9836) lr 1.9098e-04 eta 0:02:22
epoch [42/50] batch [140/162] time 0.093 (0.106) data 0.000 (0.003) loss 1.2040 (1.2156) teacher_loss 0.2982 (0.2649) loss_zs_kd 0.0306 (0.0292) loss_oracle 0.4291 (0.4691) kd_loss 0.6759 (0.7016) acc 84.3750 (89.6652) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0403 (0.0350) teacher/usage_max 0.8379 (0.8174) teacher/usage_min 0.0154 (0.0274) teacher/usage_std 0.3608 (0.3479) nleep/row_max_mean 1520.4053 (1511.7403) nleep/row_max_std 61.2056 (59.1121) nleep/row_min_mean 1495.3467 (1485.9064) lr 1.9098e-04 eta 0:02:19
epoch [42/50] batch [160/162] time 0.089 (0.104) data 0.000 (0.003) loss 1.3129 (1.2160) teacher_loss 0.2511 (0.2620) loss_zs_kd 0.0510 (0.0291) loss_oracle 0.5364 (0.4704) kd_loss 0.7682 (0.7043) acc 90.6250 (89.6484) gate/entropy 0.9784 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0308 (0.0363) teacher/usage_max 0.7546 (0.8134) teacher/usage_min 0.1003 (0.0287) teacher/usage_std 0.2984 (0.3452) nleep/row_max_mean 1499.2141 (1511.2745) nleep/row_max_std 61.8834 (59.2556) nleep/row_min_mean 1471.3142 (1485.4963) lr 1.9098e-04 eta 0:02:15
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 87.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,350
* accuracy: 71.6%
* error: 28.4%
* macro_f1: 69.2%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [43/50] batch [20/162] time 0.107 (0.127) data 0.000 (0.016) loss 1.1884 (1.2048) teacher_loss 0.2518 (0.2617) loss_zs_kd 0.0235 (0.0267) loss_oracle 0.4072 (0.4651) kd_loss 0.7213 (0.6972) acc 87.5000 (89.2188) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0200 (0.0282) teacher/usage_max 0.8124 (0.8287) teacher/usage_min 0.0056 (0.0260) teacher/usage_std 0.3463 (0.3553) nleep/row_max_mean 1513.1023 (1513.7236) nleep/row_max_std 59.7087 (59.6851) nleep/row_min_mean 1487.7394 (1487.3794) lr 1.5567e-04 eta 0:02:42
epoch [43/50] batch [40/162] time 0.115 (0.120) data 0.000 (0.008) loss 1.1918 (1.2112) teacher_loss 0.1713 (0.2648) loss_zs_kd 0.0398 (0.0287) loss_oracle 0.5066 (0.4686) kd_loss 0.7473 (0.6978) acc 96.8750 (89.6875) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0842 (0.0314) teacher/usage_max 0.7210 (0.8248) teacher/usage_min 0.0451 (0.0254) teacher/usage_std 0.2848 (0.3529) nleep/row_max_mean 1495.4757 (1513.3494) nleep/row_max_std 62.3641 (59.9395) nleep/row_min_mean 1473.0918 (1486.7785) lr 1.5567e-04 eta 0:02:30
epoch [43/50] batch [60/162] time 0.116 (0.118) data 0.001 (0.006) loss 1.0634 (1.2064) teacher_loss 0.1879 (0.2545) loss_zs_kd 0.0209 (0.0284) loss_oracle 0.4144 (0.4699) kd_loss 0.6578 (0.7028) acc 90.6250 (90.4167) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0180 (0.0306) teacher/usage_max 0.8788 (0.8206) teacher/usage_min 0.0009 (0.0252) teacher/usage_std 0.3888 (0.3503) nleep/row_max_mean 1524.4102 (1511.4369) nleep/row_max_std 54.5722 (60.3908) nleep/row_min_mean 1498.7847 (1485.2753) lr 1.5567e-04 eta 0:02:25
epoch [43/50] batch [80/162] time 0.096 (0.114) data 0.000 (0.004) loss 1.2588 (1.2183) teacher_loss 0.2646 (0.2654) loss_zs_kd 0.0371 (0.0287) loss_oracle 0.4704 (0.4700) kd_loss 0.7404 (0.7035) acc 87.5000 (89.4922) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0404 (0.0308) teacher/usage_max 0.7726 (0.8197) teacher/usage_min 0.0380 (0.0237) teacher/usage_std 0.3167 (0.3498) nleep/row_max_mean 1507.3069 (1511.3627) nleep/row_max_std 69.3225 (60.0992) nleep/row_min_mean 1482.9265 (1485.3398) lr 1.5567e-04 eta 0:02:18
epoch [43/50] batch [100/162] time 0.111 (0.111) data 0.000 (0.003) loss 1.2188 (1.2179) teacher_loss 0.1912 (0.2634) loss_zs_kd 0.0388 (0.0288) loss_oracle 0.4993 (0.4706) kd_loss 0.7586 (0.7049) acc 93.7500 (89.3750) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0456 (0.0317) teacher/usage_max 0.7487 (0.8174) teacher/usage_min 0.0030 (0.0224) teacher/usage_std 0.3103 (0.3485) nleep/row_max_mean 1501.2146 (1510.7559) nleep/row_max_std 67.0663 (60.1203) nleep/row_min_mean 1477.4562 (1484.7185) lr 1.5567e-04 eta 0:02:13
epoch [43/50] batch [120/162] time 0.097 (0.109) data 0.000 (0.003) loss 1.2202 (1.2219) teacher_loss 0.3212 (0.2634) loss_zs_kd 0.0385 (0.0288) loss_oracle 0.4378 (0.4733) kd_loss 0.6608 (0.7074) acc 84.3750 (89.4271) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0158 (0.0306) teacher/usage_max 0.8781 (0.8158) teacher/usage_min 0.0289 (0.0217) teacher/usage_std 0.3861 (0.3477) nleep/row_max_mean 1528.6871 (1511.0828) nleep/row_max_std 40.9204 (59.5910) nleep/row_min_mean 1501.8973 (1484.9341) lr 1.5567e-04 eta 0:02:08
epoch [43/50] batch [140/162] time 0.207 (0.109) data 0.001 (0.003) loss 1.4312 (1.2175) teacher_loss 0.4460 (0.2606) loss_zs_kd 0.0354 (0.0292) loss_oracle 0.4672 (0.4725) kd_loss 0.7340 (0.7061) acc 87.5000 (89.7098) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0073 (0.0306) teacher/usage_max 0.8125 (0.8172) teacher/usage_min 0.0013 (0.0221) teacher/usage_std 0.3471 (0.3485) nleep/row_max_mean 1491.7244 (1511.1855) nleep/row_max_std 64.1116 (59.8662) nleep/row_min_mean 1465.9824 (1485.0492) lr 1.5567e-04 eta 0:02:05
epoch [43/50] batch [160/162] time 0.091 (0.109) data 0.000 (0.002) loss 1.2069 (1.2233) teacher_loss 0.3504 (0.2649) loss_zs_kd 0.0401 (0.0296) loss_oracle 0.4567 (0.4747) kd_loss 0.6081 (0.7063) acc 87.5000 (89.5898) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0177 (0.0304) teacher/usage_max 0.9299 (0.8172) teacher/usage_min 0.0076 (0.0221) teacher/usage_std 0.4224 (0.3485) nleep/row_max_mean 1500.7786 (1511.1752) nleep/row_max_std 60.9232 (60.0843) nleep/row_min_mean 1473.7881 (1484.9964) lr 1.5567e-04 eta 0:02:03
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,947
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 87.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,377
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 69.5%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [44/50] batch [20/162] time 0.077 (0.115) data 0.000 (0.014) loss 1.1052 (1.2536) teacher_loss 0.1705 (0.2735) loss_zs_kd 0.0272 (0.0300) loss_oracle 0.4865 (0.4873) kd_loss 0.6779 (0.7215) acc 90.6250 (88.2812) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0018 (0.0291) teacher/usage_max 0.8749 (0.8031) teacher/usage_min 0.0002 (0.0211) teacher/usage_std 0.3863 (0.3401) nleep/row_max_mean 1512.3551 (1510.3617) nleep/row_max_std 64.2753 (59.3614) nleep/row_min_mean 1484.8384 (1484.2199) lr 1.2369e-04 eta 0:02:08
epoch [44/50] batch [40/162] time 0.097 (0.102) data 0.000 (0.007) loss 1.4595 (1.2359) teacher_loss 0.2913 (0.2535) loss_zs_kd 0.0589 (0.0313) loss_oracle 0.6012 (0.4881) kd_loss 0.8382 (0.7227) acc 90.6250 (89.4531) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0421 (0.0303) teacher/usage_max 0.6714 (0.8007) teacher/usage_min 0.0192 (0.0227) teacher/usage_std 0.2668 (0.3384) nleep/row_max_mean 1502.2136 (1509.5127) nleep/row_max_std 69.2054 (60.3787) nleep/row_min_mean 1477.0822 (1483.3809) lr 1.2369e-04 eta 0:01:51
epoch [44/50] batch [60/162] time 0.070 (0.097) data 0.001 (0.005) loss 1.2828 (1.2277) teacher_loss 0.3602 (0.2566) loss_zs_kd 0.0201 (0.0304) loss_oracle 0.4105 (0.4853) kd_loss 0.7073 (0.7132) acc 87.5000 (89.6875) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0036 (0.0317) teacher/usage_max 0.8433 (0.8089) teacher/usage_min 0.0005 (0.0227) teacher/usage_std 0.3662 (0.3435) nleep/row_max_mean 1514.0715 (1510.4807) nleep/row_max_std 57.6654 (60.7673) nleep/row_min_mean 1489.3954 (1484.1815) lr 1.2369e-04 eta 0:01:43
epoch [44/50] batch [80/162] time 0.084 (0.094) data 0.000 (0.004) loss 1.2417 (1.2229) teacher_loss 0.1733 (0.2568) loss_zs_kd 0.0285 (0.0301) loss_oracle 0.5205 (0.4814) kd_loss 0.7940 (0.7104) acc 93.7500 (89.8438) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0087 (0.0305) teacher/usage_max 0.7500 (0.8130) teacher/usage_min 0.0018 (0.0217) teacher/usage_std 0.3113 (0.3461) nleep/row_max_mean 1509.1781 (1509.7982) nleep/row_max_std 67.4050 (61.3195) nleep/row_min_mean 1484.7090 (1483.6159) lr 1.2369e-04 eta 0:01:39
epoch [44/50] batch [100/162] time 0.069 (0.092) data 0.000 (0.003) loss 1.1146 (1.2227) teacher_loss 0.2291 (0.2554) loss_zs_kd 0.0323 (0.0298) loss_oracle 0.4158 (0.4817) kd_loss 0.6614 (0.7115) acc 90.6250 (90.0000) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0170 (0.0304) teacher/usage_max 0.8763 (0.8120) teacher/usage_min 0.0036 (0.0215) teacher/usage_std 0.3868 (0.3455) nleep/row_max_mean 1522.7965 (1509.9963) nleep/row_max_std 45.2813 (61.3959) nleep/row_min_mean 1494.4734 (1483.7722) lr 1.2369e-04 eta 0:01:35
epoch [44/50] batch [120/162] time 0.086 (0.091) data 0.000 (0.003) loss 1.1846 (1.2270) teacher_loss 0.2865 (0.2624) loss_zs_kd 0.0232 (0.0298) loss_oracle 0.4225 (0.4811) kd_loss 0.6752 (0.7091) acc 90.6250 (89.8438) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0048 (0.0300) teacher/usage_max 0.8748 (0.8147) teacher/usage_min 0.0007 (0.0215) teacher/usage_std 0.3862 (0.3472) nleep/row_max_mean 1504.6057 (1509.7584) nleep/row_max_std 67.0437 (61.5948) nleep/row_min_mean 1480.6287 (1483.5322) lr 1.2369e-04 eta 0:01:32
epoch [44/50] batch [140/162] time 0.068 (0.090) data 0.000 (0.002) loss 1.2716 (1.2217) teacher_loss 0.3024 (0.2587) loss_zs_kd 0.0211 (0.0297) loss_oracle 0.4327 (0.4803) kd_loss 0.7422 (0.7080) acc 90.6250 (89.8661) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0290 (0.0301) teacher/usage_max 0.7821 (0.8158) teacher/usage_min 0.0374 (0.0212) teacher/usage_std 0.3227 (0.3477) nleep/row_max_mean 1498.4078 (1509.3839) nleep/row_max_std 70.9812 (62.2715) nleep/row_min_mean 1473.8175 (1483.1920) lr 1.2369e-04 eta 0:01:29
epoch [44/50] batch [160/162] time 0.086 (0.089) data 0.000 (0.002) loss 1.2950 (1.2239) teacher_loss 0.3524 (0.2608) loss_zs_kd 0.0375 (0.0297) loss_oracle 0.4976 (0.4814) kd_loss 0.6749 (0.7075) acc 90.6250 (89.8047) gate/entropy 0.9781 (0.9783) gate/usage_max 0.5733 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1697 (0.1696) teacher/entropy 0.0562 (0.0309) teacher/usage_max 0.8227 (0.8155) teacher/usage_min 0.0382 (0.0218) teacher/usage_std 0.3485 (0.3475) nleep/row_max_mean 1523.8279 (1509.4477) nleep/row_max_std 57.4197 (62.2063) nleep/row_min_mean 1494.9973 (1483.2388) lr 1.2369e-04 eta 0:01:26
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,370
* accuracy: 72.2%
* error: 27.8%
* macro_f1: 69.8%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [45/50] batch [20/162] time 0.109 (0.126) data 0.000 (0.021) loss 1.2434 (1.2409) teacher_loss 0.3457 (0.2853) loss_zs_kd 0.0219 (0.0338) loss_oracle 0.4173 (0.4704) kd_loss 0.6781 (0.7036) acc 84.3750 (88.5938) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0019 (0.0294) teacher/usage_max 0.8749 (0.8209) teacher/usage_min 0.0314 (0.0202) teacher/usage_std 0.3838 (0.3504) nleep/row_max_mean 1518.0804 (1509.0292) nleep/row_max_std 55.2090 (61.6925) nleep/row_min_mean 1492.3057 (1483.0868) lr 9.5173e-05 eta 0:02:00
epoch [45/50] batch [40/162] time 0.111 (0.122) data 0.003 (0.011) loss 1.1417 (1.2374) teacher_loss 0.2690 (0.2828) loss_zs_kd 0.0246 (0.0320) loss_oracle 0.4531 (0.4817) kd_loss 0.6338 (0.6978) acc 90.6250 (88.6719) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0158 (0.0320) teacher/usage_max 0.9053 (0.8242) teacher/usage_min 0.0031 (0.0207) teacher/usage_std 0.4061 (0.3525) nleep/row_max_mean 1516.5952 (1509.0556) nleep/row_max_std 60.4468 (62.1551) nleep/row_min_mean 1488.6537 (1482.9716) lr 9.5173e-05 eta 0:01:53
epoch [45/50] batch [60/162] time 0.119 (0.124) data 0.002 (0.007) loss 1.3181 (1.2352) teacher_loss 0.3633 (0.2861) loss_zs_kd 0.0280 (0.0313) loss_oracle 0.4785 (0.4728) kd_loss 0.7016 (0.6971) acc 87.5000 (88.7500) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0090 (0.0297) teacher/usage_max 0.8439 (0.8273) teacher/usage_min 0.0325 (0.0224) teacher/usage_std 0.3629 (0.3541) nleep/row_max_mean 1499.8933 (1509.2098) nleep/row_max_std 70.9442 (62.4017) nleep/row_min_mean 1474.7609 (1482.9652) lr 9.5173e-05 eta 0:01:53
epoch [45/50] batch [80/162] time 0.107 (0.121) data 0.000 (0.006) loss 1.1963 (1.2367) teacher_loss 0.1939 (0.2772) loss_zs_kd 0.0225 (0.0312) loss_oracle 0.4817 (0.4759) kd_loss 0.7503 (0.7059) acc 90.6250 (89.4141) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5733 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1697 (0.1696) teacher/entropy 0.0643 (0.0299) teacher/usage_max 0.7380 (0.8181) teacher/usage_min 0.0260 (0.0216) teacher/usage_std 0.2987 (0.3488) nleep/row_max_mean 1506.5377 (1509.0469) nleep/row_max_std 64.3752 (62.4595) nleep/row_min_mean 1481.6486 (1482.7488) lr 9.5173e-05 eta 0:01:47
epoch [45/50] batch [100/162] time 0.109 (0.117) data 0.000 (0.005) loss 1.0668 (1.2224) teacher_loss 0.1305 (0.2661) loss_zs_kd 0.0184 (0.0316) loss_oracle 0.4829 (0.4742) kd_loss 0.6856 (0.7034) acc 93.7500 (89.8438) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0439 (0.0295) teacher/usage_max 0.8244 (0.8211) teacher/usage_min 0.0290 (0.0204) teacher/usage_std 0.3506 (0.3507) nleep/row_max_mean 1525.6478 (1510.0651) nleep/row_max_std 50.2323 (62.1598) nleep/row_min_mean 1497.3821 (1483.6004) lr 9.5173e-05 eta 0:01:41
epoch [45/50] batch [120/162] time 0.095 (0.115) data 0.000 (0.004) loss 1.1634 (1.2184) teacher_loss 0.1669 (0.2602) loss_zs_kd 0.0271 (0.0313) loss_oracle 0.4365 (0.4763) kd_loss 0.7647 (0.7044) acc 93.7500 (90.0521) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0083 (0.0295) teacher/usage_max 0.7802 (0.8201) teacher/usage_min 0.0014 (0.0202) teacher/usage_std 0.3282 (0.3500) nleep/row_max_mean 1512.0698 (1510.0132) nleep/row_max_std 61.9790 (62.5379) nleep/row_min_mean 1487.0217 (1483.5021) lr 9.5173e-05 eta 0:01:37
epoch [45/50] batch [140/162] time 0.098 (0.113) data 0.000 (0.003) loss 1.3587 (1.2209) teacher_loss 0.3697 (0.2604) loss_zs_kd 0.0337 (0.0313) loss_oracle 0.4690 (0.4761) kd_loss 0.7377 (0.7068) acc 78.1250 (90.0893) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0331 (0.0295) teacher/usage_max 0.7823 (0.8176) teacher/usage_min 0.0384 (0.0212) teacher/usage_std 0.3226 (0.3483) nleep/row_max_mean 1519.9062 (1509.4044) nleep/row_max_std 61.8156 (62.6392) nleep/row_min_mean 1493.2352 (1482.9435) lr 9.5173e-05 eta 0:01:33
epoch [45/50] batch [160/162] time 0.089 (0.110) data 0.000 (0.003) loss 1.2217 (1.2210) teacher_loss 0.2022 (0.2603) loss_zs_kd 0.0174 (0.0305) loss_oracle 0.5338 (0.4769) kd_loss 0.7439 (0.7070) acc 93.7500 (90.0977) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0229 (0.0306) teacher/usage_max 0.7865 (0.8163) teacher/usage_min 0.0017 (0.0219) teacher/usage_std 0.3317 (0.3475) nleep/row_max_mean 1510.3065 (1509.0609) nleep/row_max_std 60.9732 (62.4217) nleep/row_min_mean 1485.8633 (1482.6761) lr 9.5173e-05 eta 0:01:29
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,940
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,356
* accuracy: 71.8%
* error: 28.2%
* macro_f1: 69.5%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [46/50] batch [20/162] time 0.100 (0.113) data 0.000 (0.016) loss 0.9560 (1.2565) teacher_loss 0.1225 (0.3088) loss_zs_kd 0.0184 (0.0314) loss_oracle 0.3601 (0.4624) kd_loss 0.6443 (0.7008) acc 93.7500 (88.1250) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0056 (0.0276) teacher/usage_max 0.9053 (0.8256) teacher/usage_min 0.0011 (0.0151) teacher/usage_std 0.4062 (0.3554) nleep/row_max_mean 1518.1279 (1505.0438) nleep/row_max_std 52.0098 (60.8144) nleep/row_min_mean 1491.1790 (1479.2407) lr 7.0224e-05 eta 0:01:29
epoch [46/50] batch [40/162] time 0.099 (0.104) data 0.000 (0.008) loss 1.2698 (1.2569) teacher_loss 0.2663 (0.2956) loss_zs_kd 0.0325 (0.0325) loss_oracle 0.4644 (0.4770) kd_loss 0.7551 (0.7066) acc 93.7500 (88.7500) gate/entropy 0.9784 (0.9783) gate/usage_max 0.5730 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0178 (0.0251) teacher/usage_max 0.7804 (0.8222) teacher/usage_min 0.0045 (0.0153) teacher/usage_std 0.3276 (0.3532) nleep/row_max_mean 1483.9784 (1506.8390) nleep/row_max_std 66.2888 (60.4711) nleep/row_min_mean 1460.6542 (1480.6987) lr 7.0224e-05 eta 0:01:19
epoch [46/50] batch [60/162] time 0.088 (0.097) data 0.000 (0.005) loss 1.1522 (1.2414) teacher_loss 0.1777 (0.2807) loss_zs_kd 0.0104 (0.0307) loss_oracle 0.4712 (0.4765) kd_loss 0.7337 (0.7072) acc 90.6250 (89.2188) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0616 (0.0280) teacher/usage_max 0.7577 (0.8188) teacher/usage_min 0.0949 (0.0208) teacher/usage_std 0.3009 (0.3498) nleep/row_max_mean 1521.4697 (1508.6049) nleep/row_max_std 60.2502 (60.2313) nleep/row_min_mean 1495.8782 (1482.4004) lr 7.0224e-05 eta 0:01:13
epoch [46/50] batch [80/162] time 0.099 (0.096) data 0.000 (0.004) loss 1.4791 (1.2403) teacher_loss 0.5145 (0.2784) loss_zs_kd 0.0263 (0.0312) loss_oracle 0.4647 (0.4809) kd_loss 0.7192 (0.7058) acc 81.2500 (89.2578) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0186 (0.0271) teacher/usage_max 0.8160 (0.8210) teacher/usage_min 0.0295 (0.0199) teacher/usage_std 0.3451 (0.3513) nleep/row_max_mean 1494.4556 (1508.8814) nleep/row_max_std 79.1441 (60.5279) nleep/row_min_mean 1470.4871 (1482.4253) lr 7.0224e-05 eta 0:01:10
epoch [46/50] batch [100/162] time 0.090 (0.095) data 0.000 (0.003) loss 1.2784 (1.2314) teacher_loss 0.2628 (0.2770) loss_zs_kd 0.0260 (0.0313) loss_oracle 0.5210 (0.4773) kd_loss 0.7422 (0.7000) acc 96.8750 (89.5312) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0376 (0.0273) teacher/usage_max 0.7734 (0.8267) teacher/usage_min 0.0074 (0.0184) teacher/usage_std 0.3230 (0.3551) nleep/row_max_mean 1486.2899 (1508.9324) nleep/row_max_std 68.9177 (60.6931) nleep/row_min_mean 1461.0126 (1482.4481) lr 7.0224e-05 eta 0:01:07
epoch [46/50] batch [120/162] time 0.102 (0.095) data 0.001 (0.003) loss 1.1076 (1.2237) teacher_loss 0.2315 (0.2686) loss_zs_kd 0.0341 (0.0307) loss_oracle 0.4775 (0.4763) kd_loss 0.6204 (0.7017) acc 87.5000 (89.7396) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0510 (0.0270) teacher/usage_max 0.8836 (0.8253) teacher/usage_min 0.0142 (0.0177) teacher/usage_std 0.3907 (0.3544) nleep/row_max_mean 1497.3363 (1509.0258) nleep/row_max_std 70.6237 (60.8279) nleep/row_min_mean 1472.8423 (1482.5753) lr 7.0224e-05 eta 0:01:05
epoch [46/50] batch [140/162] time 0.096 (0.095) data 0.000 (0.002) loss 1.1710 (1.2208) teacher_loss 0.2435 (0.2640) loss_zs_kd 0.0435 (0.0305) loss_oracle 0.5165 (0.4776) kd_loss 0.6475 (0.7028) acc 90.6250 (89.9554) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0014 (0.0273) teacher/usage_max 0.9062 (0.8239) teacher/usage_min 0.0001 (0.0179) teacher/usage_std 0.4069 (0.3537) nleep/row_max_mean 1518.9941 (1508.7866) nleep/row_max_std 53.8411 (61.1323) nleep/row_min_mean 1489.5867 (1482.4495) lr 7.0224e-05 eta 0:01:03
epoch [46/50] batch [160/162] time 0.092 (0.095) data 0.001 (0.002) loss 1.2111 (1.2227) teacher_loss 0.2592 (0.2627) loss_zs_kd 0.0213 (0.0300) loss_oracle 0.4671 (0.4786) kd_loss 0.7076 (0.7057) acc 93.7500 (90.0000) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0464 (0.0275) teacher/usage_max 0.7997 (0.8206) teacher/usage_min 0.0516 (0.0185) teacher/usage_std 0.3321 (0.3514) nleep/row_max_mean 1498.9594 (1508.5697) nleep/row_max_std 65.9883 (61.1290) nleep/row_min_mean 1475.2992 (1482.2543) lr 7.0224e-05 eta 0:01:01
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,354
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 69.0%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [47/50] batch [20/162] time 0.091 (0.118) data 0.000 (0.017) loss 1.2270 (1.2687) teacher_loss 0.3949 (0.2698) loss_zs_kd 0.0421 (0.0313) loss_oracle 0.3910 (0.4999) kd_loss 0.6156 (0.7332) acc 87.5000 (88.4375) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0029 (0.0304) teacher/usage_max 0.9373 (0.7899) teacher/usage_min 0.0003 (0.0242) teacher/usage_std 0.4278 (0.3320) nleep/row_max_mean 1498.3796 (1505.9135) nleep/row_max_std 70.3908 (59.5705) nleep/row_min_mean 1473.3964 (1479.9877) lr 4.8943e-05 eta 0:01:14
epoch [47/50] batch [40/162] time 0.119 (0.110) data 0.000 (0.009) loss 1.3419 (1.2426) teacher_loss 0.3421 (0.2613) loss_zs_kd 0.0349 (0.0296) loss_oracle 0.4877 (0.4894) kd_loss 0.7385 (0.7218) acc 78.1250 (88.2812) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5733 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1697 (0.1696) teacher/entropy 0.0027 (0.0277) teacher/usage_max 0.8125 (0.8041) teacher/usage_min 0.0004 (0.0230) teacher/usage_std 0.3473 (0.3405) nleep/row_max_mean 1516.4485 (1510.4660) nleep/row_max_std 53.6708 (57.5272) nleep/row_min_mean 1489.1333 (1484.1160) lr 4.8943e-05 eta 0:01:07
epoch [47/50] batch [60/162] time 0.098 (0.107) data 0.001 (0.006) loss 1.1236 (1.2459) teacher_loss 0.1896 (0.2653) loss_zs_kd 0.0317 (0.0296) loss_oracle 0.4682 (0.4880) kd_loss 0.6841 (0.7219) acc 93.7500 (88.4375) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0438 (0.0279) teacher/usage_max 0.8263 (0.8039) teacher/usage_min 0.0078 (0.0208) teacher/usage_std 0.3545 (0.3408) nleep/row_max_mean 1508.8398 (1511.0891) nleep/row_max_std 51.6093 (56.3717) nleep/row_min_mean 1482.9139 (1484.4991) lr 4.8943e-05 eta 0:01:02
epoch [47/50] batch [80/162] time 0.094 (0.104) data 0.000 (0.005) loss 1.0144 (1.2391) teacher_loss 0.1120 (0.2668) loss_zs_kd 0.0291 (0.0297) loss_oracle 0.4437 (0.4838) kd_loss 0.6660 (0.7156) acc 96.8750 (88.3203) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0245 (0.0277) teacher/usage_max 0.8641 (0.8106) teacher/usage_min 0.0007 (0.0192) teacher/usage_std 0.3793 (0.3450) nleep/row_max_mean 1513.6538 (1511.1800) nleep/row_max_std 60.9878 (56.2789) nleep/row_min_mean 1487.0671 (1484.4066) lr 4.8943e-05 eta 0:00:59
epoch [47/50] batch [100/162] time 0.096 (0.103) data 0.000 (0.004) loss 1.2004 (1.2282) teacher_loss 0.1838 (0.2653) loss_zs_kd 0.0240 (0.0291) loss_oracle 0.5188 (0.4775) kd_loss 0.7451 (0.7096) acc 93.7500 (88.5625) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0275 (0.0262) teacher/usage_max 0.7806 (0.8182) teacher/usage_min 0.0044 (0.0170) teacher/usage_std 0.3278 (0.3500) nleep/row_max_mean 1506.2589 (1512.0146) nleep/row_max_std 68.5447 (56.7913) nleep/row_min_mean 1480.4371 (1485.1806) lr 4.8943e-05 eta 0:00:56
epoch [47/50] batch [120/162] time 0.088 (0.102) data 0.000 (0.003) loss 1.3501 (1.2212) teacher_loss 0.2824 (0.2554) loss_zs_kd 0.0627 (0.0294) loss_oracle 0.5359 (0.4796) kd_loss 0.7684 (0.7113) acc 87.5000 (89.1406) gate/entropy 0.9781 (0.9782) gate/usage_max 0.5733 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1697 (0.1696) teacher/entropy 0.0040 (0.0265) teacher/usage_max 0.7808 (0.8161) teacher/usage_min 0.0006 (0.0170) teacher/usage_std 0.3287 (0.3488) nleep/row_max_mean 1514.7075 (1512.1454) nleep/row_max_std 66.7760 (57.2230) nleep/row_min_mean 1485.9015 (1485.3384) lr 4.8943e-05 eta 0:00:54
epoch [47/50] batch [140/162] time 0.087 (0.101) data 0.000 (0.003) loss 1.2765 (1.2255) teacher_loss 0.2596 (0.2634) loss_zs_kd 0.0305 (0.0295) loss_oracle 0.5452 (0.4782) kd_loss 0.7290 (0.7082) acc 90.6250 (88.9062) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0440 (0.0269) teacher/usage_max 0.7807 (0.8188) teacher/usage_min 0.0305 (0.0169) teacher/usage_std 0.3228 (0.3504) nleep/row_max_mean 1512.9091 (1511.9315) nleep/row_max_std 53.9232 (57.3559) nleep/row_min_mean 1485.9644 (1485.1479) lr 4.8943e-05 eta 0:00:51
epoch [47/50] batch [160/162] time 0.091 (0.100) data 0.000 (0.002) loss 1.0278 (1.2206) teacher_loss 0.1354 (0.2597) loss_zs_kd 0.0290 (0.0300) loss_oracle 0.5338 (0.4779) kd_loss 0.6110 (0.7069) acc 96.8750 (89.1797) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5733 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1697 (0.1696) teacher/entropy 0.0268 (0.0260) teacher/usage_max 0.9174 (0.8210) teacher/usage_min 0.0018 (0.0160) teacher/usage_std 0.4142 (0.3519) nleep/row_max_mean 1531.1665 (1512.9218) nleep/row_max_std 47.3402 (57.2002) nleep/row_min_mean 1502.9578 (1486.0121) lr 4.8943e-05 eta 0:00:48
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,940
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,352
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 69.4%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [48/50] batch [20/162] time 0.099 (0.117) data 0.000 (0.018) loss 1.1403 (1.2290) teacher_loss 0.2546 (0.2571) loss_zs_kd 0.0335 (0.0297) loss_oracle 0.4417 (0.4810) kd_loss 0.6481 (0.7166) acc 87.5000 (90.1562) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5733 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1697 (0.1696) teacher/entropy 0.0206 (0.0267) teacher/usage_max 0.8860 (0.8105) teacher/usage_min 0.0202 (0.0194) teacher/usage_std 0.3920 (0.3447) nleep/row_max_mean 1526.7432 (1512.3712) nleep/row_max_std 56.1136 (60.3523) nleep/row_min_mean 1498.2058 (1485.2343) lr 3.1417e-05 eta 0:00:54
epoch [48/50] batch [40/162] time 0.084 (0.105) data 0.000 (0.009) loss 1.3847 (1.2047) teacher_loss 0.4412 (0.2452) loss_zs_kd 0.0275 (0.0296) loss_oracle 0.4422 (0.4708) kd_loss 0.7087 (0.7094) acc 84.3750 (90.6250) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0217 (0.0281) teacher/usage_max 0.8237 (0.8164) teacher/usage_min 0.0314 (0.0214) teacher/usage_std 0.3498 (0.3480) nleep/row_max_mean 1510.0522 (1510.7040) nleep/row_max_std 65.9672 (61.2173) nleep/row_min_mean 1482.9275 (1483.7348) lr 3.1417e-05 eta 0:00:46
epoch [48/50] batch [60/162] time 0.189 (0.108) data 0.004 (0.006) loss 1.2254 (1.2059) teacher_loss 0.1950 (0.2508) loss_zs_kd 0.0333 (0.0297) loss_oracle 0.5114 (0.4700) kd_loss 0.7581 (0.7053) acc 93.7500 (90.4688) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0430 (0.0313) teacher/usage_max 0.7521 (0.8172) teacher/usage_min 0.0141 (0.0232) teacher/usage_std 0.3094 (0.3481) nleep/row_max_mean 1501.6108 (1508.8794) nleep/row_max_std 67.1035 (62.0271) nleep/row_min_mean 1477.2747 (1482.3026) lr 3.1417e-05 eta 0:00:45
epoch [48/50] batch [80/162] time 0.094 (0.105) data 0.000 (0.005) loss 1.1325 (1.2297) teacher_loss 0.1418 (0.2670) loss_zs_kd 0.0319 (0.0306) loss_oracle 0.4618 (0.4754) kd_loss 0.7438 (0.7097) acc 96.8750 (89.4141) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0273 (0.0300) teacher/usage_max 0.7823 (0.8141) teacher/usage_min 0.0056 (0.0203) teacher/usage_std 0.3285 (0.3468) nleep/row_max_mean 1502.7841 (1508.7947) nleep/row_max_std 61.5741 (61.9984) nleep/row_min_mean 1479.2802 (1482.2554) lr 3.1417e-05 eta 0:00:42
epoch [48/50] batch [100/162] time 0.098 (0.101) data 0.000 (0.004) loss 1.1595 (1.2298) teacher_loss 0.1744 (0.2708) loss_zs_kd 0.0124 (0.0304) loss_oracle 0.4907 (0.4738) kd_loss 0.7335 (0.7070) acc 90.6250 (89.2188) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0078 (0.0296) teacher/usage_max 0.8126 (0.8173) teacher/usage_min 0.0014 (0.0191) teacher/usage_std 0.3472 (0.3489) nleep/row_max_mean 1483.4183 (1509.2164) nleep/row_max_std 66.3332 (61.1203) nleep/row_min_mean 1458.9872 (1482.5560) lr 3.1417e-05 eta 0:00:39
epoch [48/50] batch [120/162] time 0.107 (0.100) data 0.000 (0.003) loss 1.4328 (1.2319) teacher_loss 0.3724 (0.2701) loss_zs_kd 0.0245 (0.0302) loss_oracle 0.5525 (0.4785) kd_loss 0.7719 (0.7074) acc 87.5000 (89.5052) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0232 (0.0297) teacher/usage_max 0.7578 (0.8168) teacher/usage_min 0.0238 (0.0181) teacher/usage_std 0.3105 (0.3488) nleep/row_max_mean 1505.5359 (1509.6822) nleep/row_max_std 68.1982 (60.9339) nleep/row_min_mean 1478.6436 (1482.9261) lr 3.1417e-05 eta 0:00:36
epoch [48/50] batch [140/162] time 0.141 (0.101) data 0.001 (0.003) loss 1.2930 (1.2303) teacher_loss 0.2721 (0.2688) loss_zs_kd 0.0472 (0.0301) loss_oracle 0.4795 (0.4787) kd_loss 0.7576 (0.7071) acc 87.5000 (89.5982) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0140 (0.0292) teacher/usage_max 0.7819 (0.8176) teacher/usage_min 0.0610 (0.0180) teacher/usage_std 0.3196 (0.3493) nleep/row_max_mean 1504.8352 (1510.1254) nleep/row_max_std 60.0151 (60.8789) nleep/row_min_mean 1479.9984 (1483.2947) lr 3.1417e-05 eta 0:00:35
epoch [48/50] batch [160/162] time 0.091 (0.100) data 0.000 (0.003) loss 1.1232 (1.2273) teacher_loss 0.2111 (0.2674) loss_zs_kd 0.0260 (0.0303) loss_oracle 0.4614 (0.4780) kd_loss 0.6684 (0.7058) acc 84.3750 (89.5508) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0113 (0.0291) teacher/usage_max 0.8750 (0.8190) teacher/usage_min 0.0033 (0.0184) teacher/usage_std 0.3860 (0.3500) nleep/row_max_mean 1503.6375 (1510.3129) nleep/row_max_std 61.7587 (60.7233) nleep/row_min_mean 1474.3564 (1483.4680) lr 3.1417e-05 eta 0:00:32
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,352
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 69.4%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [49/50] batch [20/162] time 0.095 (0.120) data 0.001 (0.016) loss 1.1733 (1.1701) teacher_loss 0.2368 (0.2408) loss_zs_kd 0.0229 (0.0325) loss_oracle 0.4803 (0.4729) kd_loss 0.6849 (0.6765) acc 90.6250 (90.4688) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0248 (0.0293) teacher/usage_max 0.8445 (0.8485) teacher/usage_min 0.0053 (0.0129) teacher/usage_std 0.3663 (0.3690) nleep/row_max_mean 1507.1082 (1509.0605) nleep/row_max_std 67.6981 (61.9118) nleep/row_min_mean 1480.1086 (1482.3677) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [40/162] time 0.105 (0.112) data 0.000 (0.008) loss 1.0669 (1.1903) teacher_loss 0.1635 (0.2406) loss_zs_kd 0.0281 (0.0313) loss_oracle 0.4081 (0.4739) kd_loss 0.6853 (0.6971) acc 96.8750 (90.7812) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0457 (0.0267) teacher/usage_max 0.8232 (0.8303) teacher/usage_min 0.0302 (0.0116) teacher/usage_std 0.3496 (0.3588) nleep/row_max_mean 1498.8945 (1506.1682) nleep/row_max_std 65.9567 (64.4019) nleep/row_min_mean 1474.5502 (1479.8203) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [60/162] time 0.086 (0.107) data 0.001 (0.006) loss 1.1784 (1.1904) teacher_loss 0.1958 (0.2356) loss_zs_kd 0.0350 (0.0309) loss_oracle 0.4946 (0.4776) kd_loss 0.7178 (0.7006) acc 90.6250 (90.6771) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0427 (0.0292) teacher/usage_max 0.7931 (0.8242) teacher/usage_min 0.0189 (0.0153) teacher/usage_std 0.3324 (0.3539) nleep/row_max_mean 1500.5698 (1505.4615) nleep/row_max_std 68.8830 (65.4640) nleep/row_min_mean 1474.7039 (1479.2586) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [80/162] time 0.093 (0.104) data 0.000 (0.004) loss 1.1912 (1.2011) teacher_loss 0.2673 (0.2463) loss_zs_kd 0.0358 (0.0311) loss_oracle 0.4939 (0.4783) kd_loss 0.6590 (0.7000) acc 96.8750 (90.1172) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0202 (0.0300) teacher/usage_max 0.8754 (0.8239) teacher/usage_min 0.0244 (0.0160) teacher/usage_std 0.3846 (0.3536) nleep/row_max_mean 1510.6729 (1505.4852) nleep/row_max_std 69.1259 (65.1438) nleep/row_min_mean 1484.5542 (1479.2335) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [100/162] time 0.089 (0.102) data 0.000 (0.004) loss 1.2247 (1.2074) teacher_loss 0.2926 (0.2485) loss_zs_kd 0.0371 (0.0308) loss_oracle 0.4520 (0.4833) kd_loss 0.6876 (0.7018) acc 87.5000 (90.0625) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0228 (0.0303) teacher/usage_max 0.8440 (0.8218) teacher/usage_min 0.0492 (0.0178) teacher/usage_std 0.3618 (0.3520) nleep/row_max_mean 1520.9343 (1505.7862) nleep/row_max_std 54.4708 (64.9827) nleep/row_min_mean 1490.7667 (1479.4644) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [120/162] time 0.094 (0.101) data 0.000 (0.003) loss 1.1567 (1.2140) teacher_loss 0.1512 (0.2581) loss_zs_kd 0.0438 (0.0306) loss_oracle 0.5107 (0.4811) kd_loss 0.7282 (0.7000) acc 96.8750 (89.7656) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0108 (0.0294) teacher/usage_max 0.8148 (0.8246) teacher/usage_min 0.0002 (0.0175) teacher/usage_std 0.3487 (0.3537) nleep/row_max_mean 1503.1326 (1506.2899) nleep/row_max_std 63.8351 (64.9359) nleep/row_min_mean 1475.5040 (1479.8694) lr 1.7713e-05 eta 0:00:20
epoch [49/50] batch [140/162] time 0.094 (0.100) data 0.000 (0.003) loss 1.4353 (1.2172) teacher_loss 0.4121 (0.2590) loss_zs_kd 0.0253 (0.0302) loss_oracle 0.4835 (0.4812) kd_loss 0.7688 (0.7025) acc 81.2500 (89.8214) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0034 (0.0292) teacher/usage_max 0.7812 (0.8222) teacher/usage_min 0.0005 (0.0179) teacher/usage_std 0.3289 (0.3522) nleep/row_max_mean 1501.1276 (1506.0939) nleep/row_max_std 65.8299 (64.9168) nleep/row_min_mean 1473.9246 (1479.7115) lr 1.7713e-05 eta 0:00:18
epoch [49/50] batch [160/162] time 0.084 (0.099) data 0.000 (0.002) loss 1.4029 (1.2203) teacher_loss 0.4238 (0.2613) loss_zs_kd 0.0283 (0.0302) loss_oracle 0.4457 (0.4806) kd_loss 0.7421 (0.7037) acc 84.3750 (89.5117) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0299 (0.0287) teacher/usage_max 0.7814 (0.8216) teacher/usage_min 0.0411 (0.0175) teacher/usage_std 0.3217 (0.3519) nleep/row_max_mean 1513.1654 (1506.5733) nleep/row_max_std 55.3963 (64.4974) nleep/row_min_mean 1484.9606 (1480.0667) lr 1.7713e-05 eta 0:00:16
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,352
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 69.4%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
epoch [50/50] batch [20/162] time 0.089 (0.104) data 0.000 (0.012) loss 1.0919 (1.3155) teacher_loss 0.2191 (0.3315) loss_zs_kd 0.0323 (0.0303) loss_oracle 0.3874 (0.4761) kd_loss 0.6630 (0.7307) acc 87.5000 (87.5000) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0190 (0.0277) teacher/usage_max 0.8727 (0.7951) teacher/usage_min 0.0031 (0.0198) teacher/usage_std 0.3846 (0.3350) nleep/row_max_mean 1520.0686 (1508.3475) nleep/row_max_std 48.2755 (60.7912) nleep/row_min_mean 1493.8032 (1481.6625) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [40/162] time 0.089 (0.098) data 0.000 (0.006) loss 1.1372 (1.2793) teacher_loss 0.2429 (0.3109) loss_zs_kd 0.0292 (0.0310) loss_oracle 0.4109 (0.4713) kd_loss 0.6742 (0.7172) acc 90.6250 (88.2812) gate/entropy 0.9784 (0.9782) gate/usage_max 0.5730 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0072 (0.0241) teacher/usage_max 0.8736 (0.8125) teacher/usage_min 0.0328 (0.0157) teacher/usage_std 0.3828 (0.3461) nleep/row_max_mean 1511.5161 (1510.6167) nleep/row_max_std 49.2708 (59.4854) nleep/row_min_mean 1482.6797 (1483.6805) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [60/162] time 0.093 (0.098) data 0.001 (0.004) loss 1.2935 (1.2633) teacher_loss 0.1483 (0.2906) loss_zs_kd 0.0333 (0.0306) loss_oracle 0.5865 (0.4796) kd_loss 0.8353 (0.7176) acc 93.7500 (88.6458) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0702 (0.0258) teacher/usage_max 0.6458 (0.8104) teacher/usage_min 0.0270 (0.0165) teacher/usage_std 0.2526 (0.3448) nleep/row_max_mean 1495.5481 (1511.0939) nleep/row_max_std 61.9453 (58.8304) nleep/row_min_mean 1473.1488 (1484.1512) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [80/162] time 0.093 (0.097) data 0.000 (0.003) loss 1.3006 (1.2522) teacher_loss 0.3785 (0.2785) loss_zs_kd 0.0188 (0.0304) loss_oracle 0.4911 (0.4840) kd_loss 0.6672 (0.7165) acc 81.2500 (88.6719) gate/entropy 0.9782 (0.9782) gate/usage_max 0.5732 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0129 (0.0286) teacher/usage_max 0.8745 (0.8086) teacher/usage_min 0.0032 (0.0180) teacher/usage_std 0.3857 (0.3437) nleep/row_max_mean 1517.3466 (1510.8576) nleep/row_max_std 57.2626 (58.4938) nleep/row_min_mean 1488.7947 (1484.0420) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [100/162] time 0.093 (0.096) data 0.000 (0.003) loss 1.1946 (1.2444) teacher_loss 0.2069 (0.2759) loss_zs_kd 0.0292 (0.0307) loss_oracle 0.4474 (0.4814) kd_loss 0.7495 (0.7124) acc 93.7500 (88.8125) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1695 (0.1696) teacher/entropy 0.0400 (0.0293) teacher/usage_max 0.7638 (0.8121) teacher/usage_min 0.0543 (0.0191) teacher/usage_std 0.3088 (0.3457) nleep/row_max_mean 1505.3879 (1511.5839) nleep/row_max_std 62.4668 (58.2113) nleep/row_min_mean 1480.3097 (1484.6622) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [120/162] time 0.076 (0.095) data 0.000 (0.002) loss 1.0045 (1.2324) teacher_loss 0.1038 (0.2665) loss_zs_kd 0.0243 (0.0305) loss_oracle 0.4784 (0.4804) kd_loss 0.6494 (0.7105) acc 96.8750 (89.1667) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0459 (0.0287) teacher/usage_max 0.8590 (0.8147) teacher/usage_min 0.0088 (0.0181) teacher/usage_std 0.3751 (0.3477) nleep/row_max_mean 1523.1611 (1512.2684) nleep/row_max_std 46.3450 (57.4406) nleep/row_min_mean 1494.0854 (1485.2409) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [140/162] time 0.107 (0.094) data 0.000 (0.002) loss 1.2218 (1.2257) teacher_loss 0.2744 (0.2628) loss_zs_kd 0.0400 (0.0307) loss_oracle 0.4946 (0.4794) kd_loss 0.6801 (0.7078) acc 93.7500 (89.5312) gate/entropy 0.9781 (0.9782) gate/usage_max 0.5733 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1697 (0.1696) teacher/entropy 0.0280 (0.0294) teacher/usage_max 0.8461 (0.8168) teacher/usage_min 0.0087 (0.0179) teacher/usage_std 0.3668 (0.3489) nleep/row_max_mean 1529.0728 (1512.6118) nleep/row_max_std 53.2994 (57.4890) nleep/row_min_mean 1502.6643 (1485.6178) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [160/162] time 0.087 (0.094) data 0.000 (0.002) loss 1.0748 (1.2229) teacher_loss 0.2002 (0.2626) loss_zs_kd 0.0088 (0.0306) loss_oracle 0.4208 (0.4786) kd_loss 0.6599 (0.7057) acc 90.6250 (89.5312) gate/entropy 0.9783 (0.9782) gate/usage_max 0.5731 (0.5732) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0199 (0.0282) teacher/usage_max 0.8750 (0.8200) teacher/usage_min 0.0396 (0.0178) teacher/usage_std 0.3835 (0.3509) nleep/row_max_mean 1517.8853 (1512.6730) nleep/row_max_std 57.7367 (57.4400) nleep/row_min_mean 1489.9901 (1485.6631) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,941
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,352
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 69.4%
******* Domain s best val acc:      87.4%, epoch: 35 *******
******* Domain s best val test acc: 71.3%, epoch: 35 *******
******* Domain s best test acc:     80.1%, epoch: 5 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_2/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:17:44

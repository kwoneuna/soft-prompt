Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'pascal', 'sun']
Target     ['labelme']
# classes  5
# train_x  5,651
# val      2,422
# test     2,656
---------  ----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_3/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_3/warmup_1/tensorboard)
epoch [1/50] batch [20/176] time 0.101 (0.133) data 0.000 (0.020) loss 0.9786 (1.0646) teacher_loss 0.4941 (0.5501) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0010 (0.0001) kd_loss 0.4840 (0.5145) acc 81.2500 (81.5625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3376 (0.3374) gate/usage_min 0.3294 (0.3295) gate/usage_std 0.0033 (0.0033) teacher/entropy 0.6144 (0.5843) teacher/usage_max 0.3522 (0.4004) teacher/usage_min 0.3076 (0.2705) teacher/usage_std 0.0188 (0.0554) nleep/row_max_mean 1485.2927 (1501.0923) nleep/row_max_std 98.2470 (99.3604) nleep/row_min_mean 1481.1938 (1496.1953) lr 1.0000e-05 eta 0:19:25
epoch [1/50] batch [40/176] time 0.101 (0.117) data 0.000 (0.010) loss 0.8718 (1.0093) teacher_loss 0.5714 (0.5498) loss_zs_kd 0.0002 (0.0000) loss_oracle 0.0029 (0.0013) kd_loss 0.2988 (0.4588) acc 75.0000 (81.2500) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3295 (0.3295) gate/usage_std 0.0033 (0.0032) teacher/entropy 0.7996 (0.6400) teacher/usage_max 0.4488 (0.3887) teacher/usage_min 0.2560 (0.2815) teacher/usage_std 0.0832 (0.0457) nleep/row_max_mean 1486.3751 (1502.3809) nleep/row_max_std 116.4942 (93.8581) nleep/row_min_mean 1484.1621 (1498.3819) lr 1.0000e-05 eta 0:17:05
epoch [1/50] batch [60/176] time 0.079 (0.110) data 0.000 (0.007) loss 0.8919 (0.9498) teacher_loss 0.6102 (0.5350) loss_zs_kd 0.0000 (0.0001) loss_oracle 0.0096 (0.0030) kd_loss 0.2769 (0.4133) acc 81.2500 (81.8229) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3376 (0.3374) gate/usage_min 0.3294 (0.3295) gate/usage_std 0.0034 (0.0033) teacher/entropy 0.8223 (0.6854) teacher/usage_max 0.4388 (0.3904) teacher/usage_min 0.2693 (0.2788) teacher/usage_std 0.0752 (0.0474) nleep/row_max_mean 1523.5554 (1501.7045) nleep/row_max_std 60.7259 (92.6781) nleep/row_min_mean 1521.1908 (1498.1994) lr 1.0000e-05 eta 0:16:04
epoch [1/50] batch [80/176] time 0.096 (0.109) data 0.000 (0.005) loss 0.8479 (0.9245) teacher_loss 0.6421 (0.5447) loss_zs_kd 0.0002 (0.0002) loss_oracle 0.0094 (0.0046) kd_loss 0.2010 (0.3774) acc 71.8750 (81.4844) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3295 (0.3295) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.8982 (0.7215) teacher/usage_max 0.3509 (0.3905) teacher/usage_min 0.3039 (0.2795) teacher/usage_std 0.0209 (0.0474) nleep/row_max_mean 1483.5153 (1504.4313) nleep/row_max_std 87.2135 (85.6288) nleep/row_min_mean 1482.0667 (1501.2660) lr 1.0000e-05 eta 0:15:50
epoch [1/50] batch [100/176] time 0.096 (0.106) data 0.000 (0.004) loss 0.7389 (0.8988) teacher_loss 0.5458 (0.5509) loss_zs_kd 0.0003 (0.0002) loss_oracle 0.0165 (0.0062) kd_loss 0.1847 (0.3447) acc 75.0000 (81.1875) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3296 (0.3295) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.9149 (0.7544) teacher/usage_max 0.3752 (0.3906) teacher/usage_min 0.2771 (0.2780) teacher/usage_std 0.0413 (0.0482) nleep/row_max_mean 1514.1609 (1505.4635) nleep/row_max_std 70.4656 (82.4498) nleep/row_min_mean 1512.6812 (1502.5858) lr 1.0000e-05 eta 0:15:22
epoch [1/50] batch [120/176] time 0.093 (0.104) data 0.000 (0.004) loss 0.6301 (0.8636) teacher_loss 0.4740 (0.5425) loss_zs_kd 0.0003 (0.0003) loss_oracle 0.0119 (0.0072) kd_loss 0.1499 (0.3174) acc 87.5000 (81.4583) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3294 (0.3295) gate/usage_std 0.0033 (0.0032) teacher/entropy 0.9504 (0.7819) teacher/usage_max 0.3992 (0.3949) teacher/usage_min 0.2613 (0.2749) teacher/usage_std 0.0565 (0.0513) nleep/row_max_mean 1509.3489 (1505.8782) nleep/row_max_std 54.7611 (80.6751) nleep/row_min_mean 1507.9337 (1503.2327) lr 1.0000e-05 eta 0:15:05
epoch [1/50] batch [140/176] time 0.083 (0.103) data 0.000 (0.003) loss 0.7884 (0.8398) teacher_loss 0.5857 (0.5393) loss_zs_kd 0.0007 (0.0003) loss_oracle 0.0112 (0.0080) kd_loss 0.1968 (0.2964) acc 78.1250 (81.4732) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3295 (0.3295) gate/usage_std 0.0033 (0.0032) teacher/entropy 0.9048 (0.8031) teacher/usage_max 0.4674 (0.4006) teacher/usage_min 0.2239 (0.2733) teacher/usage_std 0.1009 (0.0546) nleep/row_max_mean 1530.9026 (1507.1092) nleep/row_max_std 42.6629 (78.6782) nleep/row_min_mean 1529.3223 (1504.6391) lr 1.0000e-05 eta 0:14:52
epoch [1/50] batch [160/176] time 0.092 (0.102) data 0.000 (0.003) loss 1.0303 (0.8300) teacher_loss 0.8464 (0.5449) loss_zs_kd 0.0003 (0.0004) loss_oracle 0.0116 (0.0085) kd_loss 0.1779 (0.2806) acc 68.7500 (81.0938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3295 (0.3295) gate/usage_std 0.0033 (0.0032) teacher/entropy 0.9240 (0.8190) teacher/usage_max 0.4886 (0.4085) teacher/usage_min 0.2110 (0.2703) teacher/usage_std 0.1157 (0.0595) nleep/row_max_mean 1518.0186 (1507.8354) nleep/row_max_std 49.1406 (76.9330) nleep/row_min_mean 1516.5784 (1505.5001) lr 1.0000e-05 eta 0:14:42
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,072
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 87.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,840
* accuracy: 69.3%
* error: 30.7%
* macro_f1: 62.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain l best val acc:      85.5%, epoch: 1 *******
******* Domain l best val test acc: 69.3%, epoch: 1 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [2/50] batch [20/176] time 0.081 (0.113) data 0.000 (0.021) loss 0.8777 (0.7524) teacher_loss 0.4061 (0.4866) loss_zs_kd 0.0060 (0.0043) loss_oracle 0.1910 (0.1004) kd_loss 0.3731 (0.2135) acc 87.5000 (83.7500) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3368 (0.3371) gate/usage_min 0.3312 (0.3303) gate/usage_std 0.0025 (0.0028) teacher/entropy 0.7289 (0.8879) teacher/usage_max 0.6881 (0.5407) teacher/usage_min 0.1471 (0.2150) teacher/usage_std 0.2510 (0.1474) nleep/row_max_mean 1527.3257 (1515.2429) nleep/row_max_std 60.2689 (61.8242) nleep/row_min_mean 1525.1785 (1513.7358) lr 2.0000e-03 eta 0:16:11
epoch [2/50] batch [40/176] time 0.093 (0.098) data 0.000 (0.011) loss 0.7539 (0.8330) teacher_loss 0.1988 (0.4211) loss_zs_kd 0.0125 (0.0072) loss_oracle 0.2786 (0.1510) kd_loss 0.4096 (0.3328) acc 90.6250 (85.9375) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3357 (0.3367) gate/usage_min 0.3303 (0.3307) gate/usage_std 0.0022 (0.0025) teacher/entropy 0.6875 (0.7676) teacher/usage_max 0.6110 (0.6114) teacher/usage_min 0.1708 (0.1785) teacher/usage_std 0.1973 (0.1974) nleep/row_max_mean 1517.1726 (1516.5715) nleep/row_max_std 68.8653 (60.9615) nleep/row_min_mean 1514.8132 (1514.5657) lr 2.0000e-03 eta 0:13:59
epoch [2/50] batch [60/176] time 0.081 (0.093) data 0.000 (0.007) loss 0.9802 (0.8616) teacher_loss 0.3851 (0.4035) loss_zs_kd 0.0225 (0.0081) loss_oracle 0.3347 (0.1985) kd_loss 0.4164 (0.3548) acc 90.6250 (86.6146) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3380 (0.3366) gate/usage_min 0.3280 (0.3302) gate/usage_std 0.0041 (0.0027) teacher/entropy 0.6786 (0.7440) teacher/usage_max 0.4973 (0.5998) teacher/usage_min 0.2408 (0.1842) teacher/usage_std 0.1163 (0.1892) nleep/row_max_mean 1526.9390 (1516.9956) nleep/row_max_std 56.8791 (60.1534) nleep/row_min_mean 1524.0830 (1514.8213) lr 2.0000e-03 eta 0:13:16
epoch [2/50] batch [80/176] time 0.086 (0.090) data 0.000 (0.005) loss 1.3874 (0.9270) teacher_loss 0.3391 (0.3829) loss_zs_kd 0.0418 (0.0117) loss_oracle 0.6923 (0.2837) kd_loss 0.6812 (0.3964) acc 87.5000 (87.3438) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3409 (0.3373) gate/usage_min 0.3268 (0.3294) gate/usage_std 0.0058 (0.0033) teacher/entropy 0.4121 (0.7018) teacher/usage_max 0.5106 (0.5627) teacher/usage_min 0.1924 (0.1910) teacher/usage_std 0.1324 (0.1677) nleep/row_max_mean 1500.7660 (1516.5847) nleep/row_max_std 67.6193 (60.1870) nleep/row_min_mean 1494.9500 (1513.9773) lr 2.0000e-03 eta 0:12:51
epoch [2/50] batch [100/176] time 0.085 (0.089) data 0.000 (0.004) loss 1.2309 (0.9918) teacher_loss 0.1582 (0.3520) loss_zs_kd 0.0390 (0.0153) loss_oracle 0.3413 (0.3413) kd_loss 0.8826 (0.4615) acc 96.8750 (88.9062) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3442 (0.3384) gate/usage_min 0.3256 (0.3287) gate/usage_std 0.0079 (0.0040) teacher/entropy 0.2169 (0.6365) teacher/usage_max 0.5199 (0.5507) teacher/usage_min 0.1138 (0.1823) teacher/usage_std 0.1674 (0.1636) nleep/row_max_mean 1531.1940 (1516.6990) nleep/row_max_std 48.5255 (59.4952) nleep/row_min_mean 1522.3611 (1513.2393) lr 2.0000e-03 eta 0:12:37
epoch [2/50] batch [120/176] time 0.097 (0.089) data 0.001 (0.004) loss 1.2221 (1.0333) teacher_loss 0.0957 (0.3254) loss_zs_kd 0.0315 (0.0183) loss_oracle 0.4916 (0.3572) kd_loss 0.8648 (0.5202) acc 96.8750 (89.9219) gate/entropy 1.0982 (1.0985) gate/usage_max 0.3463 (0.3396) gate/usage_min 0.3258 (0.3282) gate/usage_std 0.0092 (0.0048) teacher/entropy 0.2316 (0.5775) teacher/usage_max 0.5192 (0.5437) teacher/usage_min 0.0781 (0.1711) teacher/usage_std 0.1866 (0.1641) nleep/row_max_mean 1514.0498 (1516.7907) nleep/row_max_std 65.8805 (59.0166) nleep/row_min_mean 1503.7961 (1512.4504) lr 2.0000e-03 eta 0:12:34
epoch [2/50] batch [140/176] time 0.083 (0.088) data 0.000 (0.003) loss 1.5380 (1.0970) teacher_loss 0.2695 (0.3161) loss_zs_kd 0.0466 (0.0219) loss_oracle 0.6720 (0.3982) kd_loss 0.9092 (0.5708) acc 87.5000 (90.3125) gate/entropy 1.0981 (1.0984) gate/usage_max 0.3488 (0.3407) gate/usage_min 0.3249 (0.3279) gate/usage_std 0.0109 (0.0056) teacher/entropy 0.1801 (0.5264) teacher/usage_max 0.4791 (0.5412) teacher/usage_min 0.0622 (0.1580) teacher/usage_std 0.1919 (0.1680) nleep/row_max_mean 1508.6896 (1516.6308) nleep/row_max_std 61.8619 (59.3568) nleep/row_min_mean 1495.2925 (1511.2993) lr 2.0000e-03 eta 0:12:29
epoch [2/50] batch [160/176] time 0.100 (0.088) data 0.000 (0.003) loss 1.3836 (1.1332) teacher_loss 0.0740 (0.2953) loss_zs_kd 0.0484 (0.0243) loss_oracle 0.5592 (0.4195) kd_loss 1.0058 (0.6160) acc 100.0000 (91.1328) gate/entropy 1.0978 (1.0984) gate/usage_max 0.3517 (0.3419) gate/usage_min 0.3213 (0.3273) gate/usage_std 0.0132 (0.0064) teacher/entropy 0.0863 (0.4804) teacher/usage_max 0.5643 (0.5412) teacher/usage_min 0.0721 (0.1459) teacher/usage_std 0.2021 (0.1730) nleep/row_max_mean 1530.1586 (1516.0590) nleep/row_max_std 51.0841 (59.5750) nleep/row_min_mean 1514.2649 (1509.6705) lr 2.0000e-03 eta 0:12:28
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,148
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 90.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,561
* accuracy: 58.8%
* error: 41.2%
* macro_f1: 56.4%
******* Domain l best val acc:      88.7%, epoch: 2 *******
******* Domain l best val test acc: 58.8%, epoch: 2 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [3/50] batch [20/176] time 0.094 (0.102) data 0.000 (0.015) loss 1.2996 (1.3708) teacher_loss 0.0563 (0.1522) loss_zs_kd 0.0566 (0.0528) loss_oracle 0.5226 (0.5051) kd_loss 0.9537 (0.9396) acc 100.0000 (96.5625) gate/entropy 1.0976 (1.0977) gate/usage_max 0.3534 (0.3530) gate/usage_min 0.3173 (0.3184) gate/usage_std 0.0150 (0.0145) teacher/entropy 0.1308 (0.1536) teacher/usage_max 0.4543 (0.5604) teacher/usage_min 0.1183 (0.1187) teacher/usage_std 0.1525 (0.1870) nleep/row_max_mean 1511.0394 (1512.3020) nleep/row_max_std 53.0451 (58.9798) nleep/row_min_mean 1492.8914 (1496.8659) lr 1.9980e-03 eta 0:14:15
epoch [3/50] batch [40/176] time 0.091 (0.096) data 0.000 (0.008) loss 1.4764 (1.3750) teacher_loss 0.1844 (0.1455) loss_zs_kd 0.0683 (0.0530) loss_oracle 0.5391 (0.5334) kd_loss 0.9883 (0.9363) acc 93.7500 (96.6406) gate/entropy 1.0976 (1.0976) gate/usage_max 0.3531 (0.3531) gate/usage_min 0.3157 (0.3174) gate/usage_std 0.0153 (0.0149) teacher/entropy 0.0992 (0.1567) teacher/usage_max 0.5582 (0.5565) teacher/usage_min 0.1005 (0.1296) teacher/usage_std 0.1870 (0.1802) nleep/row_max_mean 1507.6658 (1508.3067) nleep/row_max_std 60.7968 (60.8912) nleep/row_min_mean 1490.4211 (1492.3207) lr 1.9980e-03 eta 0:13:22
epoch [3/50] batch [60/176] time 0.087 (0.092) data 0.000 (0.005) loss 1.4659 (1.3931) teacher_loss 0.1509 (0.1432) loss_zs_kd 0.0448 (0.0520) loss_oracle 0.5572 (0.5501) kd_loss 1.0140 (0.9488) acc 96.8750 (96.5625) gate/entropy 1.0974 (1.0976) gate/usage_max 0.3537 (0.3532) gate/usage_min 0.3142 (0.3166) gate/usage_std 0.0161 (0.0152) teacher/entropy 0.0742 (0.1436) teacher/usage_max 0.5059 (0.5640) teacher/usage_min 0.1493 (0.1286) teacher/usage_std 0.1458 (0.1849) nleep/row_max_mean 1517.7247 (1509.0759) nleep/row_max_std 63.8547 (60.0963) nleep/row_min_mean 1496.9935 (1492.0718) lr 1.9980e-03 eta 0:12:50
epoch [3/50] batch [80/176] time 0.079 (0.090) data 0.000 (0.004) loss 1.4101 (1.3937) teacher_loss 0.1353 (0.1378) loss_zs_kd 0.0432 (0.0510) loss_oracle 0.4927 (0.5461) kd_loss 1.0068 (0.9574) acc 96.8750 (96.5234) gate/entropy 1.0973 (1.0975) gate/usage_max 0.3535 (0.3533) gate/usage_min 0.3123 (0.3157) gate/usage_std 0.0168 (0.0155) teacher/entropy 0.0874 (0.1344) teacher/usage_max 0.7420 (0.5777) teacher/usage_min 0.1045 (0.1254) teacher/usage_std 0.2897 (0.1925) nleep/row_max_mean 1508.6169 (1509.6673) nleep/row_max_std 57.1737 (59.6580) nleep/row_min_mean 1485.9658 (1491.9224) lr 1.9980e-03 eta 0:12:33
epoch [3/50] batch [100/176] time 0.097 (0.090) data 0.000 (0.003) loss 1.4318 (1.3966) teacher_loss 0.1366 (0.1407) loss_zs_kd 0.0543 (0.0506) loss_oracle 0.5371 (0.5363) kd_loss 0.9995 (0.9625) acc 96.8750 (96.3750) gate/entropy 1.0972 (1.0975) gate/usage_max 0.3535 (0.3534) gate/usage_min 0.3104 (0.3149) gate/usage_std 0.0177 (0.0158) teacher/entropy 0.0878 (0.1281) teacher/usage_max 0.6701 (0.5812) teacher/usage_min 0.1083 (0.1228) teacher/usage_std 0.2426 (0.1946) nleep/row_max_mean 1509.7751 (1509.3477) nleep/row_max_std 51.3449 (58.9644) nleep/row_min_mean 1486.3243 (1491.0412) lr 1.9980e-03 eta 0:12:28
epoch [3/50] batch [120/176] time 0.082 (0.091) data 0.000 (0.003) loss 1.4808 (1.4087) teacher_loss 0.2597 (0.1495) loss_zs_kd 0.0492 (0.0505) loss_oracle 0.5255 (0.5374) kd_loss 0.9337 (0.9653) acc 87.5000 (95.9896) gate/entropy 1.0970 (1.0974) gate/usage_max 0.3534 (0.3534) gate/usage_min 0.3084 (0.3140) gate/usage_std 0.0187 (0.0162) teacher/entropy 0.1518 (0.1240) teacher/usage_max 0.7021 (0.5931) teacher/usage_min 0.1103 (0.1182) teacher/usage_std 0.2627 (0.2017) nleep/row_max_mean 1486.3947 (1508.8455) nleep/row_max_std 65.7251 (58.9570) nleep/row_min_mean 1464.3926 (1489.9087) lr 1.9980e-03 eta 0:12:34
epoch [3/50] batch [140/176] time 0.083 (0.090) data 0.000 (0.002) loss 1.4072 (1.4198) teacher_loss 0.1439 (0.1548) loss_zs_kd 0.0425 (0.0494) loss_oracle 0.4192 (0.5394) kd_loss 1.0324 (0.9706) acc 96.8750 (95.7366) gate/entropy 1.0967 (1.0973) gate/usage_max 0.3535 (0.3534) gate/usage_min 0.3054 (0.3129) gate/usage_std 0.0204 (0.0167) teacher/entropy 0.0372 (0.1164) teacher/usage_max 0.7177 (0.6080) teacher/usage_min 0.0322 (0.1076) teacher/usage_std 0.2860 (0.2124) nleep/row_max_mean 1498.2390 (1508.6412) nleep/row_max_std 64.2297 (58.2241) nleep/row_min_mean 1473.6233 (1489.0175) lr 1.9980e-03 eta 0:12:31
epoch [3/50] batch [160/176] time 0.089 (0.090) data 0.000 (0.002) loss 1.4473 (1.4235) teacher_loss 0.0765 (0.1586) loss_zs_kd 0.0665 (0.0496) loss_oracle 0.6007 (0.5343) kd_loss 1.0372 (0.9730) acc 100.0000 (95.5859) gate/entropy 1.0964 (1.0972) gate/usage_max 0.3536 (0.3534) gate/usage_min 0.3027 (0.3118) gate/usage_std 0.0220 (0.0173) teacher/entropy 0.0298 (0.1124) teacher/usage_max 0.5819 (0.6165) teacher/usage_min 0.0750 (0.1044) teacher/usage_std 0.2070 (0.2175) nleep/row_max_mean 1523.4426 (1508.8181) nleep/row_max_std 34.4619 (57.6227) nleep/row_min_mean 1494.4192 (1488.7066) lr 1.9980e-03 eta 0:12:28
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,136
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 90.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,457
* accuracy: 54.9%
* error: 45.1%
* macro_f1: 53.1%
******* Domain l best val acc:      88.7%, epoch: 2 *******
******* Domain l best val test acc: 58.8%, epoch: 2 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [4/50] batch [20/176] time 0.101 (0.110) data 0.000 (0.014) loss 1.4831 (1.4877) teacher_loss 0.1868 (0.2023) loss_zs_kd 0.0321 (0.0439) loss_oracle 0.5256 (0.5383) kd_loss 1.0174 (0.9944) acc 90.6250 (93.1250) gate/entropy 1.0958 (1.0959) gate/usage_max 0.3533 (0.3534) gate/usage_min 0.2982 (0.2993) gate/usage_std 0.0249 (0.0242) teacher/entropy 0.0450 (0.0709) teacher/usage_max 0.6997 (0.7096) teacher/usage_min 0.0761 (0.0776) teacher/usage_std 0.2660 (0.2744) nleep/row_max_mean 1513.1110 (1502.5582) nleep/row_max_std 49.6636 (62.4923) nleep/row_min_mean 1488.4663 (1477.9104) lr 1.9921e-03 eta 0:15:06
epoch [4/50] batch [40/176] time 0.092 (0.103) data 0.000 (0.007) loss 1.3976 (1.5007) teacher_loss 0.0697 (0.2089) loss_zs_kd 0.0393 (0.0432) loss_oracle 0.5519 (0.5504) kd_loss 1.0323 (0.9950) acc 96.8750 (92.8125) gate/entropy 1.0954 (1.0958) gate/usage_max 0.3530 (0.3532) gate/usage_min 0.2957 (0.2982) gate/usage_std 0.0266 (0.0250) teacher/entropy 0.0217 (0.0661) teacher/usage_max 0.7257 (0.7057) teacher/usage_min 0.0555 (0.0682) teacher/usage_std 0.2854 (0.2741) nleep/row_max_mean 1502.4800 (1503.8599) nleep/row_max_std 69.3258 (60.8904) nleep/row_min_mean 1476.0797 (1478.6920) lr 1.9921e-03 eta 0:14:10
epoch [4/50] batch [60/176] time 0.105 (0.101) data 0.001 (0.005) loss 1.4417 (1.5028) teacher_loss 0.1125 (0.2041) loss_zs_kd 0.0457 (0.0423) loss_oracle 0.5801 (0.5580) kd_loss 1.0162 (0.9986) acc 96.8750 (93.3333) gate/entropy 1.0949 (1.0955) gate/usage_max 0.3542 (0.3533) gate/usage_min 0.2930 (0.2969) gate/usage_std 0.0285 (0.0258) teacher/entropy 0.0288 (0.0591) teacher/usage_max 0.8056 (0.7189) teacher/usage_min 0.0359 (0.0603) teacher/usage_std 0.3376 (0.2834) nleep/row_max_mean 1514.3181 (1504.9250) nleep/row_max_std 73.7573 (60.5678) nleep/row_min_mean 1487.4282 (1479.0899) lr 1.9921e-03 eta 0:13:47
epoch [4/50] batch [80/176] time 0.093 (0.104) data 0.000 (0.004) loss 1.3956 (1.5037) teacher_loss 0.0758 (0.1993) loss_zs_kd 0.0540 (0.0422) loss_oracle 0.5187 (0.5669) kd_loss 1.0334 (0.9998) acc 96.8750 (93.3594) gate/entropy 1.0943 (1.0953) gate/usage_max 0.3567 (0.3538) gate/usage_min 0.2903 (0.2956) gate/usage_std 0.0305 (0.0268) teacher/entropy 0.0055 (0.0548) teacher/usage_max 0.7802 (0.7205) teacher/usage_min 0.0322 (0.0577) teacher/usage_std 0.3223 (0.2849) nleep/row_max_mean 1506.9468 (1505.2665) nleep/row_max_std 61.5871 (60.0845) nleep/row_min_mean 1479.0465 (1478.9360) lr 1.9921e-03 eta 0:14:09
epoch [4/50] batch [100/176] time 0.101 (0.102) data 0.000 (0.003) loss 1.6076 (1.5053) teacher_loss 0.2846 (0.2004) loss_zs_kd 0.0345 (0.0429) loss_oracle 0.6452 (0.5705) kd_loss 0.9832 (0.9982) acc 93.7500 (93.4062) gate/entropy 1.0937 (1.0950) gate/usage_max 0.3593 (0.3546) gate/usage_min 0.2873 (0.2942) gate/usage_std 0.0326 (0.0277) teacher/entropy 0.0481 (0.0531) teacher/usage_max 0.6715 (0.7199) teacher/usage_min 0.0142 (0.0536) teacher/usage_std 0.2687 (0.2861) nleep/row_max_mean 1487.4963 (1504.9486) nleep/row_max_std 80.8257 (60.3817) nleep/row_min_mean 1461.3091 (1478.3615) lr 1.9921e-03 eta 0:13:50
epoch [4/50] batch [120/176] time 0.095 (0.100) data 0.000 (0.003) loss 1.3639 (1.5029) teacher_loss 0.0445 (0.1964) loss_zs_kd 0.0360 (0.0432) loss_oracle 0.6504 (0.5779) kd_loss 0.9762 (0.9960) acc 100.0000 (93.3594) gate/entropy 1.0930 (1.0948) gate/usage_max 0.3622 (0.3556) gate/usage_min 0.2845 (0.2928) gate/usage_std 0.0347 (0.0287) teacher/entropy 0.0598 (0.0523) teacher/usage_max 0.7438 (0.7284) teacher/usage_min 0.0680 (0.0515) teacher/usage_std 0.2944 (0.2913) nleep/row_max_mean 1487.0891 (1504.3031) nleep/row_max_std 79.2659 (60.9780) nleep/row_min_mean 1461.6195 (1477.5900) lr 1.9921e-03 eta 0:13:35
epoch [4/50] batch [140/176] time 0.094 (0.099) data 0.000 (0.002) loss 1.4717 (1.5038) teacher_loss 0.1450 (0.1973) loss_zs_kd 0.0540 (0.0439) loss_oracle 0.6450 (0.5823) kd_loss 0.9772 (0.9934) acc 90.6250 (93.1473) gate/entropy 1.0923 (1.0945) gate/usage_max 0.3648 (0.3568) gate/usage_min 0.2815 (0.2914) gate/usage_std 0.0370 (0.0297) teacher/entropy 0.0453 (0.0516) teacher/usage_max 0.7634 (0.7302) teacher/usage_min 0.0313 (0.0488) teacher/usage_std 0.3123 (0.2926) nleep/row_max_mean 1495.1975 (1504.2816) nleep/row_max_std 72.0140 (60.8891) nleep/row_min_mean 1467.4530 (1477.4224) lr 1.9921e-03 eta 0:13:26
epoch [4/50] batch [160/176] time 0.094 (0.098) data 0.000 (0.002) loss 1.5363 (1.5029) teacher_loss 0.2461 (0.1961) loss_zs_kd 0.0213 (0.0440) loss_oracle 0.6257 (0.5886) kd_loss 0.9667 (0.9905) acc 87.5000 (93.2617) gate/entropy 1.0915 (1.0941) gate/usage_max 0.3673 (0.3579) gate/usage_min 0.2786 (0.2900) gate/usage_std 0.0391 (0.0308) teacher/entropy 0.0483 (0.0514) teacher/usage_max 0.8321 (0.7332) teacher/usage_min 0.0306 (0.0466) teacher/usage_std 0.3553 (0.2949) nleep/row_max_mean 1493.3467 (1504.2648) nleep/row_max_std 71.5366 (61.0277) nleep/row_min_mean 1466.1691 (1477.2392) lr 1.9921e-03 eta 0:13:17
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,157
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 90.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,674
* accuracy: 63.0%
* error: 37.0%
* macro_f1: 58.0%
******* Domain l best val acc:      89.1%, epoch: 4 *******
******* Domain l best val test acc: 63.0%, epoch: 4 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [5/50] batch [20/176] time 0.095 (0.109) data 0.000 (0.017) loss 1.6181 (1.5257) teacher_loss 0.3149 (0.2053) loss_zs_kd 0.0513 (0.0403) loss_oracle 0.6157 (0.7100) kd_loss 0.9697 (0.9452) acc 84.3750 (92.6562) gate/entropy 1.0900 (1.0904) gate/usage_max 0.3717 (0.3706) gate/usage_min 0.2733 (0.2746) gate/usage_std 0.0430 (0.0420) teacher/entropy 0.0348 (0.0658) teacher/usage_max 0.8503 (0.7630) teacher/usage_min 0.0310 (0.0325) teacher/usage_std 0.3673 (0.3163) nleep/row_max_mean 1513.8516 (1506.1545) nleep/row_max_std 56.3750 (58.9646) nleep/row_min_mean 1488.9150 (1478.7663) lr 1.9823e-03 eta 0:14:38
epoch [5/50] batch [40/176] time 0.094 (0.103) data 0.000 (0.009) loss 1.5020 (1.4982) teacher_loss 0.2980 (0.2024) loss_zs_kd 0.0327 (0.0402) loss_oracle 0.5404 (0.6665) kd_loss 0.9175 (0.9424) acc 84.3750 (93.0469) gate/entropy 1.0891 (1.0900) gate/usage_max 0.3742 (0.3717) gate/usage_min 0.2701 (0.2731) gate/usage_std 0.0453 (0.0431) teacher/entropy 0.0814 (0.0657) teacher/usage_max 0.7589 (0.7515) teacher/usage_min 0.0137 (0.0288) teacher/usage_std 0.3133 (0.3100) nleep/row_max_mean 1520.9099 (1505.4245) nleep/row_max_std 48.5002 (58.9629) nleep/row_min_mean 1493.9436 (1477.7718) lr 1.9823e-03 eta 0:13:46
epoch [5/50] batch [60/176] time 0.105 (0.100) data 0.001 (0.006) loss 1.5268 (1.4946) teacher_loss 0.2353 (0.2107) loss_zs_kd 0.0569 (0.0400) loss_oracle 0.6598 (0.6451) kd_loss 0.9332 (0.9413) acc 93.7500 (93.1250) gate/entropy 1.0881 (1.0895) gate/usage_max 0.3767 (0.3730) gate/usage_min 0.2672 (0.2716) gate/usage_std 0.0475 (0.0442) teacher/entropy 0.0592 (0.0638) teacher/usage_max 0.7334 (0.7555) teacher/usage_min 0.0047 (0.0278) teacher/usage_std 0.3017 (0.3117) nleep/row_max_mean 1508.7915 (1506.6557) nleep/row_max_std 58.5901 (58.6543) nleep/row_min_mean 1477.7554 (1479.1686) lr 1.9823e-03 eta 0:13:19
epoch [5/50] batch [80/176] time 0.101 (0.100) data 0.000 (0.005) loss 1.3861 (1.4973) teacher_loss 0.0660 (0.2104) loss_zs_kd 0.0415 (0.0407) loss_oracle 0.7870 (0.6609) kd_loss 0.9058 (0.9361) acc 100.0000 (93.2031) gate/entropy 1.0872 (1.0890) gate/usage_max 0.3789 (0.3742) gate/usage_min 0.2644 (0.2702) gate/usage_std 0.0496 (0.0453) teacher/entropy 0.0982 (0.0669) teacher/usage_max 0.5829 (0.7501) teacher/usage_min 0.0296 (0.0278) teacher/usage_std 0.2291 (0.3083) nleep/row_max_mean 1509.0115 (1505.8487) nleep/row_max_std 64.8612 (59.2510) nleep/row_min_mean 1478.9834 (1478.5899) lr 1.9823e-03 eta 0:13:25
epoch [5/50] batch [100/176] time 0.096 (0.100) data 0.001 (0.004) loss 1.4855 (1.5003) teacher_loss 0.1564 (0.2111) loss_zs_kd 0.0466 (0.0423) loss_oracle 0.7061 (0.6674) kd_loss 0.9527 (0.9344) acc 93.7500 (93.2812) gate/entropy 1.0863 (1.0886) gate/usage_max 0.3805 (0.3753) gate/usage_min 0.2619 (0.2688) gate/usage_std 0.0514 (0.0463) teacher/entropy 0.0382 (0.0670) teacher/usage_max 0.7701 (0.7469) teacher/usage_min 0.0354 (0.0293) teacher/usage_std 0.3156 (0.3065) nleep/row_max_mean 1502.8433 (1505.1018) nleep/row_max_std 57.4110 (59.0997) nleep/row_min_mean 1476.5038 (1478.0860) lr 1.9823e-03 eta 0:13:20
epoch [5/50] batch [120/176] time 0.075 (0.099) data 0.000 (0.003) loss 1.5157 (1.5028) teacher_loss 0.2155 (0.2136) loss_zs_kd 0.0455 (0.0423) loss_oracle 0.6946 (0.6716) kd_loss 0.9302 (0.9323) acc 96.8750 (93.1771) gate/entropy 1.0853 (1.0881) gate/usage_max 0.3825 (0.3764) gate/usage_min 0.2592 (0.2674) gate/usage_std 0.0533 (0.0474) teacher/entropy 0.0530 (0.0676) teacher/usage_max 0.6520 (0.7407) teacher/usage_min 0.0001 (0.0301) teacher/usage_std 0.2663 (0.3031) nleep/row_max_mean 1524.4604 (1505.5302) nleep/row_max_std 44.8582 (58.5763) nleep/row_min_mean 1496.5526 (1478.6721) lr 1.9823e-03 eta 0:13:09
epoch [5/50] batch [140/176] time 0.097 (0.098) data 0.000 (0.003) loss 1.4027 (1.4942) teacher_loss 0.1574 (0.2071) loss_zs_kd 0.0449 (0.0432) loss_oracle 0.7742 (0.6712) kd_loss 0.8358 (0.9299) acc 93.7500 (93.2143) gate/entropy 1.0843 (1.0876) gate/usage_max 0.3839 (0.3774) gate/usage_min 0.2564 (0.2660) gate/usage_std 0.0553 (0.0483) teacher/entropy 0.1550 (0.0699) teacher/usage_max 0.6937 (0.7290) teacher/usage_min 0.0410 (0.0336) teacher/usage_std 0.2708 (0.2959) nleep/row_max_mean 1505.7023 (1505.7077) nleep/row_max_std 57.4453 (58.1025) nleep/row_min_mean 1480.9099 (1478.9727) lr 1.9823e-03 eta 0:12:59
epoch [5/50] batch [160/176] time 0.087 (0.096) data 0.000 (0.002) loss 1.5423 (1.4905) teacher_loss 0.2569 (0.2014) loss_zs_kd 0.0409 (0.0430) loss_oracle 0.7410 (0.6781) kd_loss 0.8944 (0.9285) acc 90.6250 (93.4570) gate/entropy 1.0836 (1.0872) gate/usage_max 0.3842 (0.3782) gate/usage_min 0.2546 (0.2647) gate/usage_std 0.0565 (0.0493) teacher/entropy 0.1168 (0.0712) teacher/usage_max 0.6608 (0.7176) teacher/usage_min 0.0950 (0.0364) teacher/usage_std 0.2394 (0.2898) nleep/row_max_mean 1484.4722 (1505.7208) nleep/row_max_std 55.4866 (57.9255) nleep/row_min_mean 1462.6804 (1479.0847) lr 1.9823e-03 eta 0:12:43
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,158
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 90.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,571
* accuracy: 59.1%
* error: 40.9%
* macro_f1: 55.9%
******* Domain l best val acc:      89.1%, epoch: 5 *******
******* Domain l best val test acc: 59.1%, epoch: 5 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [6/50] batch [20/176] time 0.097 (0.106) data 0.000 (0.018) loss 1.5771 (1.4047) teacher_loss 0.3978 (0.1839) loss_zs_kd 0.0207 (0.0430) loss_oracle 0.5622 (0.5597) kd_loss 0.8878 (0.9195) acc 87.5000 (93.9062) gate/entropy 1.0820 (1.0824) gate/usage_max 0.3863 (0.3856) gate/usage_min 0.2504 (0.2514) gate/usage_std 0.0594 (0.0587) teacher/entropy 0.1138 (0.0768) teacher/usage_max 0.6084 (0.6375) teacher/usage_min 0.0719 (0.0597) teacher/usage_std 0.2192 (0.2387) nleep/row_max_mean 1488.3024 (1503.8589) nleep/row_max_std 67.7309 (56.9318) nleep/row_min_mean 1465.4238 (1478.0248) lr 1.9686e-03 eta 0:13:59
epoch [6/50] batch [40/176] time 0.080 (0.097) data 0.000 (0.009) loss 1.2854 (1.3805) teacher_loss 0.0874 (0.1772) loss_zs_kd 0.0537 (0.0424) loss_oracle 0.5278 (0.5292) kd_loss 0.9073 (0.9175) acc 100.0000 (94.1406) gate/entropy 1.0811 (1.0820) gate/usage_max 0.3878 (0.3863) gate/usage_min 0.2484 (0.2504) gate/usage_std 0.0609 (0.0594) teacher/entropy 0.0716 (0.0777) teacher/usage_max 0.7060 (0.6449) teacher/usage_min 0.0344 (0.0611) teacher/usage_std 0.2791 (0.2425) nleep/row_max_mean 1513.0608 (1503.8564) nleep/row_max_std 61.4062 (57.2548) nleep/row_min_mean 1486.9045 (1478.0432) lr 1.9686e-03 eta 0:12:40
epoch [6/50] batch [60/176] time 0.097 (0.093) data 0.001 (0.006) loss 1.3515 (1.3918) teacher_loss 0.1017 (0.1790) loss_zs_kd 0.0659 (0.0467) loss_oracle 0.5738 (0.5352) kd_loss 0.9299 (0.9219) acc 96.8750 (94.4271) gate/entropy 1.0803 (1.0816) gate/usage_max 0.3895 (0.3871) gate/usage_min 0.2466 (0.2494) gate/usage_std 0.0622 (0.0601) teacher/entropy 0.0637 (0.0734) teacher/usage_max 0.5799 (0.6388) teacher/usage_min 0.0591 (0.0633) teacher/usage_std 0.2135 (0.2404) nleep/row_max_mean 1511.6110 (1504.3481) nleep/row_max_std 56.2529 (56.9005) nleep/row_min_mean 1482.0701 (1478.3483) lr 1.9686e-03 eta 0:12:12
epoch [6/50] batch [80/176] time 0.093 (0.093) data 0.000 (0.005) loss 1.4236 (1.4013) teacher_loss 0.0861 (0.1790) loss_zs_kd 0.0695 (0.0468) loss_oracle 0.6994 (0.5541) kd_loss 0.9531 (0.9219) acc 100.0000 (94.4531) gate/entropy 1.0796 (1.0812) gate/usage_max 0.3906 (0.3878) gate/usage_min 0.2448 (0.2485) gate/usage_std 0.0635 (0.0608) teacher/entropy 0.0166 (0.0715) teacher/usage_max 0.5560 (0.6474) teacher/usage_min 0.0000 (0.0627) teacher/usage_std 0.2401 (0.2449) nleep/row_max_mean 1519.4741 (1503.3882) nleep/row_max_std 29.7463 (56.6070) nleep/row_min_mean 1488.1907 (1477.5063) lr 1.9686e-03 eta 0:12:06
epoch [6/50] batch [100/176] time 0.095 (0.095) data 0.000 (0.004) loss 1.6092 (1.4089) teacher_loss 0.3319 (0.1754) loss_zs_kd 0.0108 (0.0467) loss_oracle 0.7009 (0.5745) kd_loss 0.9215 (0.9229) acc 90.6250 (94.6250) gate/entropy 1.0788 (1.0808) gate/usage_max 0.3921 (0.3885) gate/usage_min 0.2431 (0.2476) gate/usage_std 0.0648 (0.0614) teacher/entropy 0.0762 (0.0697) teacher/usage_max 0.6009 (0.6485) teacher/usage_min 0.0820 (0.0638) teacher/usage_std 0.2121 (0.2450) nleep/row_max_mean 1494.8596 (1503.3516) nleep/row_max_std 64.3323 (56.4037) nleep/row_min_mean 1471.2539 (1477.4270) lr 1.9686e-03 eta 0:12:23
epoch [6/50] batch [120/176] time 0.091 (0.095) data 0.000 (0.003) loss 1.3793 (1.4115) teacher_loss 0.2131 (0.1727) loss_zs_kd 0.0392 (0.0465) loss_oracle 0.5906 (0.5887) kd_loss 0.8513 (0.9213) acc 90.6250 (94.7656) gate/entropy 1.0778 (1.0804) gate/usage_max 0.3928 (0.3891) gate/usage_min 0.2408 (0.2467) gate/usage_std 0.0663 (0.0621) teacher/entropy 0.1091 (0.0695) teacher/usage_max 0.6969 (0.6474) teacher/usage_min 0.0119 (0.0616) teacher/usage_std 0.2812 (0.2450) nleep/row_max_mean 1505.2010 (1503.1518) nleep/row_max_std 67.2012 (56.1502) nleep/row_min_mean 1479.3485 (1477.2243) lr 1.9686e-03 eta 0:12:18
epoch [6/50] batch [140/176] time 0.094 (0.095) data 0.000 (0.003) loss 1.4496 (1.3992) teacher_loss 0.2133 (0.1656) loss_zs_kd 0.0653 (0.0479) loss_oracle 0.5437 (0.5809) kd_loss 0.9317 (0.9192) acc 90.6250 (95.0446) gate/entropy 1.0770 (1.0799) gate/usage_max 0.3940 (0.3897) gate/usage_min 0.2392 (0.2457) gate/usage_std 0.0675 (0.0628) teacher/entropy 0.0344 (0.0695) teacher/usage_max 0.6975 (0.6505) teacher/usage_min 0.0309 (0.0598) teacher/usage_std 0.2756 (0.2472) nleep/row_max_mean 1505.1003 (1503.3127) nleep/row_max_std 51.2428 (56.0977) nleep/row_min_mean 1478.9885 (1477.3707) lr 1.9686e-03 eta 0:12:15
epoch [6/50] batch [160/176] time 0.089 (0.094) data 0.000 (0.002) loss 1.3863 (1.3941) teacher_loss 0.1335 (0.1664) loss_zs_kd 0.0425 (0.0474) loss_oracle 0.5842 (0.5732) kd_loss 0.9395 (0.9174) acc 93.7500 (95.0000) gate/entropy 1.0762 (1.0795) gate/usage_max 0.3959 (0.3904) gate/usage_min 0.2376 (0.2448) gate/usage_std 0.0687 (0.0635) teacher/entropy 0.0445 (0.0709) teacher/usage_max 0.5977 (0.6485) teacher/usage_min 0.0623 (0.0608) teacher/usage_std 0.2186 (0.2459) nleep/row_max_mean 1494.4370 (1502.9145) nleep/row_max_std 61.2920 (56.3447) nleep/row_min_mean 1468.2891 (1477.0410) lr 1.9686e-03 eta 0:12:10
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,152
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 90.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,551
* accuracy: 58.4%
* error: 41.6%
* macro_f1: 55.7%
******* Domain l best val acc:      89.1%, epoch: 5 *******
******* Domain l best val test acc: 59.1%, epoch: 5 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [7/50] batch [20/176] time 0.087 (0.102) data 0.000 (0.013) loss 1.2683 (1.3223) teacher_loss 0.1164 (0.1617) loss_zs_kd 0.0504 (0.0405) loss_oracle 0.4562 (0.4766) kd_loss 0.8986 (0.9020) acc 100.0000 (94.8438) gate/entropy 1.0745 (1.0750) gate/usage_max 0.3996 (0.3986) gate/usage_min 0.2345 (0.2353) gate/usage_std 0.0712 (0.0706) teacher/entropy 0.1036 (0.0760) teacher/usage_max 0.7246 (0.6441) teacher/usage_min 0.1359 (0.0646) teacher/usage_std 0.2767 (0.2467) nleep/row_max_mean 1491.6858 (1499.7503) nleep/row_max_std 61.3601 (53.1407) nleep/row_min_mean 1469.3628 (1474.9973) lr 1.9511e-03 eta 0:13:09
epoch [7/50] batch [40/176] time 0.085 (0.096) data 0.000 (0.007) loss 1.3587 (1.3461) teacher_loss 0.1735 (0.1779) loss_zs_kd 0.0509 (0.0447) loss_oracle 0.5671 (0.4808) kd_loss 0.8762 (0.9054) acc 96.8750 (94.7656) gate/entropy 1.0737 (1.0745) gate/usage_max 0.4022 (0.3997) gate/usage_min 0.2332 (0.2346) gate/usage_std 0.0724 (0.0712) teacher/entropy 0.0812 (0.0671) teacher/usage_max 0.6940 (0.6793) teacher/usage_min 0.0377 (0.0612) teacher/usage_std 0.2718 (0.2652) nleep/row_max_mean 1503.7402 (1498.5023) nleep/row_max_std 56.7638 (53.4070) nleep/row_min_mean 1476.9109 (1473.3745) lr 1.9511e-03 eta 0:12:16
epoch [7/50] batch [60/176] time 0.095 (0.094) data 0.001 (0.004) loss 1.3359 (1.3409) teacher_loss 0.1714 (0.1593) loss_zs_kd 0.0360 (0.0469) loss_oracle 0.5427 (0.5028) kd_loss 0.8752 (0.9068) acc 90.6250 (95.1562) gate/entropy 1.0728 (1.0741) gate/usage_max 0.4046 (0.4009) gate/usage_min 0.2319 (0.2339) gate/usage_std 0.0737 (0.0718) teacher/entropy 0.0647 (0.0634) teacher/usage_max 0.8185 (0.6847) teacher/usage_min 0.0355 (0.0609) teacher/usage_std 0.3460 (0.2665) nleep/row_max_mean 1503.1367 (1500.2103) nleep/row_max_std 53.4557 (52.4222) nleep/row_min_mean 1472.8982 (1474.3735) lr 1.9511e-03 eta 0:12:04
epoch [7/50] batch [80/176] time 0.087 (0.099) data 0.000 (0.003) loss 1.3075 (1.3459) teacher_loss 0.1119 (0.1569) loss_zs_kd 0.0506 (0.0475) loss_oracle 0.5655 (0.5108) kd_loss 0.8875 (0.9098) acc 93.7500 (95.0781) gate/entropy 1.0721 (1.0737) gate/usage_max 0.4068 (0.4022) gate/usage_min 0.2307 (0.2332) gate/usage_std 0.0748 (0.0725) teacher/entropy 0.1348 (0.0630) teacher/usage_max 0.6188 (0.6863) teacher/usage_min 0.1738 (0.0706) teacher/usage_std 0.2023 (0.2646) nleep/row_max_mean 1476.7775 (1498.2346) nleep/row_max_std 55.2019 (52.8987) nleep/row_min_mean 1456.0195 (1472.6294) lr 1.9511e-03 eta 0:12:40
epoch [7/50] batch [100/176] time 0.103 (0.100) data 0.000 (0.003) loss 1.3267 (1.3537) teacher_loss 0.0719 (0.1569) loss_zs_kd 0.0382 (0.0478) loss_oracle 0.6178 (0.5237) kd_loss 0.9267 (0.9110) acc 100.0000 (95.0625) gate/entropy 1.0712 (1.0733) gate/usage_max 0.4087 (0.4033) gate/usage_min 0.2292 (0.2326) gate/usage_std 0.0760 (0.0730) teacher/entropy 0.0824 (0.0613) teacher/usage_max 0.5670 (0.6846) teacher/usage_min 0.1367 (0.0721) teacher/usage_std 0.1776 (0.2631) nleep/row_max_mean 1499.3115 (1498.9590) nleep/row_max_std 57.3234 (52.6893) nleep/row_min_mean 1475.7742 (1473.1938) lr 1.9511e-03 eta 0:12:41
epoch [7/50] batch [120/176] time 0.097 (0.099) data 0.000 (0.002) loss 1.3253 (1.3554) teacher_loss 0.0959 (0.1568) loss_zs_kd 0.0412 (0.0464) loss_oracle 0.5903 (0.5274) kd_loss 0.9136 (0.9117) acc 96.8750 (94.9740) gate/entropy 1.0706 (1.0729) gate/usage_max 0.4101 (0.4043) gate/usage_min 0.2283 (0.2320) gate/usage_std 0.0769 (0.0736) teacher/entropy 0.0410 (0.0606) teacher/usage_max 0.7130 (0.6865) teacher/usage_min 0.0604 (0.0755) teacher/usage_std 0.2769 (0.2631) nleep/row_max_mean 1497.0386 (1499.4802) nleep/row_max_std 55.0228 (52.1578) nleep/row_min_mean 1471.8157 (1473.7936) lr 1.9511e-03 eta 0:12:37
epoch [7/50] batch [140/176] time 0.095 (0.099) data 0.000 (0.002) loss 1.3487 (1.3630) teacher_loss 0.1025 (0.1607) loss_zs_kd 0.0405 (0.0452) loss_oracle 0.5783 (0.5366) kd_loss 0.9367 (0.9114) acc 96.8750 (94.9330) gate/entropy 1.0698 (1.0725) gate/usage_max 0.4115 (0.4053) gate/usage_min 0.2270 (0.2313) gate/usage_std 0.0779 (0.0741) teacher/entropy 0.0349 (0.0605) teacher/usage_max 0.6584 (0.6860) teacher/usage_min 0.0854 (0.0771) teacher/usage_std 0.2402 (0.2623) nleep/row_max_mean 1520.5989 (1499.5718) nleep/row_max_std 41.4120 (52.5200) nleep/row_min_mean 1494.5669 (1473.9795) lr 1.9511e-03 eta 0:12:32
epoch [7/50] batch [160/176] time 0.103 (0.099) data 0.000 (0.002) loss 1.2916 (1.3627) teacher_loss 0.1174 (0.1593) loss_zs_kd 0.0285 (0.0451) loss_oracle 0.5818 (0.5440) kd_loss 0.8690 (0.9088) acc 100.0000 (94.9609) gate/entropy 1.0691 (1.0721) gate/usage_max 0.4129 (0.4061) gate/usage_min 0.2259 (0.2307) gate/usage_std 0.0788 (0.0747) teacher/entropy 0.0908 (0.0625) teacher/usage_max 0.7807 (0.6853) teacher/usage_min 0.0983 (0.0780) teacher/usage_std 0.3165 (0.2615) nleep/row_max_mean 1492.0471 (1498.9334) nleep/row_max_std 51.3800 (53.0208) nleep/row_min_mean 1469.1628 (1473.5505) lr 1.9511e-03 eta 0:12:27
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,146
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 90.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,430
* accuracy: 53.8%
* error: 46.2%
* macro_f1: 51.7%
******* Domain l best val acc:      89.1%, epoch: 5 *******
******* Domain l best val test acc: 59.1%, epoch: 5 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [8/50] batch [20/176] time 0.081 (0.107) data 0.000 (0.016) loss 1.3004 (1.3308) teacher_loss 0.1757 (0.1584) loss_zs_kd 0.0443 (0.0473) loss_oracle 0.4933 (0.5361) kd_loss 0.8559 (0.8807) acc 93.7500 (95.3125) gate/entropy 1.0679 (1.0682) gate/usage_max 0.4153 (0.4146) gate/usage_min 0.2240 (0.2245) gate/usage_std 0.0804 (0.0800) teacher/entropy 0.0854 (0.0812) teacher/usage_max 0.7385 (0.6885) teacher/usage_min 0.0539 (0.0820) teacher/usage_std 0.2933 (0.2601) nleep/row_max_mean 1490.0518 (1497.2936) nleep/row_max_std 58.4519 (55.7727) nleep/row_min_mean 1467.7441 (1473.7795) lr 1.9298e-03 eta 0:13:24
epoch [8/50] batch [40/176] time 0.097 (0.100) data 0.000 (0.008) loss 1.3345 (1.3517) teacher_loss 0.0856 (0.1598) loss_zs_kd 0.0460 (0.0474) loss_oracle 0.6113 (0.5498) kd_loss 0.9203 (0.8933) acc 100.0000 (95.0000) gate/entropy 1.0673 (1.0679) gate/usage_max 0.4165 (0.4152) gate/usage_min 0.2231 (0.2241) gate/usage_std 0.0812 (0.0804) teacher/entropy 0.0686 (0.0801) teacher/usage_max 0.5823 (0.6667) teacher/usage_min 0.1119 (0.0985) teacher/usage_std 0.1930 (0.2451) nleep/row_max_mean 1506.4131 (1497.2677) nleep/row_max_std 52.4906 (55.4225) nleep/row_min_mean 1480.4554 (1473.6894) lr 1.9298e-03 eta 0:12:30
epoch [8/50] batch [60/176] time 0.099 (0.098) data 0.001 (0.005) loss 1.4072 (1.3605) teacher_loss 0.1925 (0.1514) loss_zs_kd 0.0624 (0.0506) loss_oracle 0.5640 (0.5667) kd_loss 0.9014 (0.9005) acc 90.6250 (95.1562) gate/entropy 1.0671 (1.0677) gate/usage_max 0.4170 (0.4158) gate/usage_min 0.2228 (0.2237) gate/usage_std 0.0815 (0.0807) teacher/entropy 0.0608 (0.0770) teacher/usage_max 0.6781 (0.6632) teacher/usage_min 0.0855 (0.1028) teacher/usage_std 0.2515 (0.2424) nleep/row_max_mean 1506.0366 (1498.1317) nleep/row_max_std 38.8132 (54.3345) nleep/row_min_mean 1481.2729 (1474.3124) lr 1.9298e-03 eta 0:12:17
epoch [8/50] batch [80/176] time 0.095 (0.097) data 0.000 (0.004) loss 1.4219 (1.3687) teacher_loss 0.2003 (0.1552) loss_zs_kd 0.0568 (0.0492) loss_oracle 0.5741 (0.5769) kd_loss 0.9062 (0.9004) acc 93.7500 (95.1562) gate/entropy 1.0664 (1.0674) gate/usage_max 0.4184 (0.4163) gate/usage_min 0.2219 (0.2233) gate/usage_std 0.0824 (0.0811) teacher/entropy 0.0727 (0.0775) teacher/usage_max 0.6544 (0.6559) teacher/usage_min 0.1165 (0.1040) teacher/usage_std 0.2316 (0.2381) nleep/row_max_mean 1489.5620 (1497.9965) nleep/row_max_std 70.3623 (54.9492) nleep/row_min_mean 1464.1650 (1474.0800) lr 1.9298e-03 eta 0:12:10
epoch [8/50] batch [100/176] time 0.099 (0.097) data 0.001 (0.003) loss 1.3235 (1.3652) teacher_loss 0.1659 (0.1514) loss_zs_kd 0.0534 (0.0495) loss_oracle 0.5092 (0.5763) kd_loss 0.8764 (0.9010) acc 93.7500 (95.2500) gate/entropy 1.0658 (1.0672) gate/usage_max 0.4193 (0.4168) gate/usage_min 0.2209 (0.2230) gate/usage_std 0.0831 (0.0814) teacher/entropy 0.0288 (0.0751) teacher/usage_max 0.8680 (0.6568) teacher/usage_min 0.0330 (0.1014) teacher/usage_std 0.3790 (0.2392) nleep/row_max_mean 1511.1733 (1498.1999) nleep/row_max_std 51.6955 (55.1343) nleep/row_min_mean 1482.4590 (1473.9877) lr 1.9298e-03 eta 0:12:05
epoch [8/50] batch [120/176] time 0.092 (0.097) data 0.000 (0.003) loss 1.4608 (1.3631) teacher_loss 0.2337 (0.1541) loss_zs_kd 0.0474 (0.0502) loss_oracle 0.6160 (0.5724) kd_loss 0.8954 (0.8977) acc 96.8750 (95.0781) gate/entropy 1.0654 (1.0669) gate/usage_max 0.4203 (0.4173) gate/usage_min 0.2204 (0.2226) gate/usage_std 0.0836 (0.0817) teacher/entropy 0.0765 (0.0776) teacher/usage_max 0.6021 (0.6555) teacher/usage_min 0.0899 (0.1014) teacher/usage_std 0.2099 (0.2386) nleep/row_max_mean 1497.8333 (1497.4219) nleep/row_max_std 56.7302 (55.8651) nleep/row_min_mean 1473.2324 (1473.2310) lr 1.9298e-03 eta 0:12:02
epoch [8/50] batch [140/176] time 0.095 (0.096) data 0.000 (0.002) loss 1.2092 (1.3642) teacher_loss 0.0263 (0.1520) loss_zs_kd 0.0258 (0.0497) loss_oracle 0.6372 (0.5836) kd_loss 0.8514 (0.8956) acc 100.0000 (95.1786) gate/entropy 1.0651 (1.0667) gate/usage_max 0.4207 (0.4177) gate/usage_min 0.2198 (0.2222) gate/usage_std 0.0841 (0.0820) teacher/entropy 0.0806 (0.0781) teacher/usage_max 0.6787 (0.6547) teacher/usage_min 0.0335 (0.0997) teacher/usage_std 0.2654 (0.2388) nleep/row_max_mean 1488.3557 (1497.2139) nleep/row_max_std 63.0013 (55.7545) nleep/row_min_mean 1462.0048 (1472.8517) lr 1.9298e-03 eta 0:11:56
epoch [8/50] batch [160/176] time 0.091 (0.096) data 0.000 (0.002) loss 1.3747 (1.3637) teacher_loss 0.1944 (0.1517) loss_zs_kd 0.0381 (0.0489) loss_oracle 0.5875 (0.5870) kd_loss 0.8675 (0.8941) acc 96.8750 (95.1367) gate/entropy 1.0644 (1.0664) gate/usage_max 0.4211 (0.4181) gate/usage_min 0.2186 (0.2218) gate/usage_std 0.0848 (0.0823) teacher/entropy 0.1136 (0.0771) teacher/usage_max 0.5866 (0.6537) teacher/usage_min 0.1047 (0.0957) teacher/usage_std 0.1975 (0.2393) nleep/row_max_mean 1488.5134 (1497.1721) nleep/row_max_std 56.6472 (55.8735) nleep/row_min_mean 1466.2106 (1472.7169) lr 1.9298e-03 eta 0:11:51
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,185
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 91.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,581
* accuracy: 59.5%
* error: 40.5%
* macro_f1: 56.7%
******* Domain l best val acc:      90.2%, epoch: 8 *******
******* Domain l best val test acc: 59.5%, epoch: 8 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [9/50] batch [20/176] time 0.096 (0.111) data 0.000 (0.017) loss 1.3927 (1.3442) teacher_loss 0.0400 (0.1233) loss_zs_kd 0.0356 (0.0435) loss_oracle 0.7248 (0.6194) kd_loss 0.9725 (0.8894) acc 100.0000 (96.2500) gate/entropy 1.0635 (1.0636) gate/usage_max 0.4212 (0.4213) gate/usage_min 0.2168 (0.2170) gate/usage_std 0.0859 (0.0858) teacher/entropy 0.0259 (0.0587) teacher/usage_max 0.5069 (0.6512) teacher/usage_min 0.1184 (0.0611) teacher/usage_std 0.1613 (0.2475) nleep/row_max_mean 1510.9862 (1498.2692) nleep/row_max_std 43.8312 (57.5470) nleep/row_min_mean 1482.1549 (1472.6278) lr 1.9048e-03 eta 0:13:41
epoch [9/50] batch [40/176] time 0.092 (0.102) data 0.000 (0.009) loss 1.3331 (1.3656) teacher_loss 0.0652 (0.1464) loss_zs_kd 0.0437 (0.0434) loss_oracle 0.6711 (0.6243) kd_loss 0.9105 (0.8855) acc 96.8750 (95.2344) gate/entropy 1.0627 (1.0633) gate/usage_max 0.4216 (0.4215) gate/usage_min 0.2155 (0.2165) gate/usage_std 0.0867 (0.0861) teacher/entropy 0.0614 (0.0608) teacher/usage_max 0.5776 (0.6524) teacher/usage_min 0.0877 (0.0587) teacher/usage_std 0.2000 (0.2487) nleep/row_max_mean 1506.8296 (1498.2640) nleep/row_max_std 44.6514 (55.8954) nleep/row_min_mean 1478.8696 (1472.4973) lr 1.9048e-03 eta 0:12:28
epoch [9/50] batch [60/176] time 0.089 (0.100) data 0.001 (0.006) loss 1.3138 (1.3598) teacher_loss 0.1098 (0.1436) loss_zs_kd 0.0421 (0.0475) loss_oracle 0.6897 (0.6213) kd_loss 0.8381 (0.8819) acc 96.8750 (95.5208) gate/entropy 1.0618 (1.0629) gate/usage_max 0.4225 (0.4217) gate/usage_min 0.2139 (0.2159) gate/usage_std 0.0878 (0.0865) teacher/entropy 0.0893 (0.0580) teacher/usage_max 0.6343 (0.6616) teacher/usage_min 0.0223 (0.0498) teacher/usage_std 0.2499 (0.2558) nleep/row_max_mean 1501.2498 (1498.3342) nleep/row_max_std 60.4151 (55.1176) nleep/row_min_mean 1474.4943 (1472.3684) lr 1.9048e-03 eta 0:12:11
epoch [9/50] batch [80/176] time 0.092 (0.100) data 0.000 (0.005) loss 1.3169 (1.3695) teacher_loss 0.0792 (0.1520) loss_zs_kd 0.0402 (0.0485) loss_oracle 0.6371 (0.6222) kd_loss 0.8990 (0.8821) acc 96.8750 (95.0781) gate/entropy 1.0613 (1.0626) gate/usage_max 0.4224 (0.4218) gate/usage_min 0.2130 (0.2153) gate/usage_std 0.0883 (0.0868) teacher/entropy 0.0138 (0.0556) teacher/usage_max 0.6559 (0.6580) teacher/usage_min 0.0016 (0.0456) teacher/usage_std 0.2672 (0.2558) nleep/row_max_mean 1512.4015 (1499.7881) nleep/row_max_std 53.3461 (53.5919) nleep/row_min_mean 1483.6108 (1473.4991) lr 1.9048e-03 eta 0:12:08
epoch [9/50] batch [100/176] time 0.095 (0.098) data 0.000 (0.004) loss 1.4223 (1.3629) teacher_loss 0.2856 (0.1499) loss_zs_kd 0.0400 (0.0470) loss_oracle 0.6120 (0.6166) kd_loss 0.8107 (0.8812) acc 93.7500 (95.3438) gate/entropy 1.0607 (1.0623) gate/usage_max 0.4226 (0.4220) gate/usage_min 0.2120 (0.2148) gate/usage_std 0.0889 (0.0872) teacher/entropy 0.1626 (0.0560) teacher/usage_max 0.5173 (0.6559) teacher/usage_min 0.0780 (0.0448) teacher/usage_std 0.1863 (0.2550) nleep/row_max_mean 1487.8280 (1500.0068) nleep/row_max_std 60.9607 (54.0207) nleep/row_min_mean 1464.6200 (1473.7719) lr 1.9048e-03 eta 0:11:56
epoch [9/50] batch [120/176] time 0.097 (0.098) data 0.000 (0.003) loss 1.2216 (1.3659) teacher_loss 0.0366 (0.1575) loss_zs_kd 0.0379 (0.0466) loss_oracle 0.5663 (0.6072) kd_loss 0.8830 (0.8815) acc 100.0000 (95.1042) gate/entropy 1.0602 (1.0620) gate/usage_max 0.4232 (0.4221) gate/usage_min 0.2112 (0.2143) gate/usage_std 0.0895 (0.0875) teacher/entropy 0.0173 (0.0548) teacher/usage_max 0.7206 (0.6565) teacher/usage_min 0.0001 (0.0439) teacher/usage_std 0.2966 (0.2560) nleep/row_max_mean 1500.0149 (1499.5506) nleep/row_max_std 53.8865 (54.3737) nleep/row_min_mean 1473.9026 (1473.3841) lr 1.9048e-03 eta 0:11:50
epoch [9/50] batch [140/176] time 0.097 (0.098) data 0.001 (0.003) loss 1.3306 (1.3612) teacher_loss 0.1487 (0.1546) loss_zs_kd 0.0380 (0.0464) loss_oracle 0.6161 (0.6061) kd_loss 0.8549 (0.8804) acc 93.7500 (95.2679) gate/entropy 1.0596 (1.0617) gate/usage_max 0.4235 (0.4223) gate/usage_min 0.2102 (0.2137) gate/usage_std 0.0902 (0.0879) teacher/entropy 0.1037 (0.0555) teacher/usage_max 0.6165 (0.6541) teacher/usage_min 0.0791 (0.0434) teacher/usage_std 0.2203 (0.2552) nleep/row_max_mean 1485.8522 (1499.0693) nleep/row_max_std 63.4228 (54.7713) nleep/row_min_mean 1464.4573 (1472.9736) lr 1.9048e-03 eta 0:11:47
epoch [9/50] batch [160/176] time 0.096 (0.097) data 0.000 (0.002) loss 1.2066 (1.3558) teacher_loss 0.0695 (0.1523) loss_zs_kd 0.0443 (0.0472) loss_oracle 0.5494 (0.6002) kd_loss 0.8403 (0.8798) acc 96.8750 (95.2344) gate/entropy 1.0589 (1.0614) gate/usage_max 0.4242 (0.4225) gate/usage_min 0.2091 (0.2132) gate/usage_std 0.0909 (0.0882) teacher/entropy 0.0663 (0.0538) teacher/usage_max 0.7789 (0.6585) teacher/usage_min 0.0309 (0.0413) teacher/usage_std 0.3217 (0.2578) nleep/row_max_mean 1476.8406 (1499.4571) nleep/row_max_std 76.5764 (54.8430) nleep/row_min_mean 1453.5684 (1473.2683) lr 1.9048e-03 eta 0:11:42
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,524
* accuracy: 57.4%
* error: 42.6%
* macro_f1: 54.5%
******* Domain l best val acc:      90.2%, epoch: 8 *******
******* Domain l best val test acc: 59.5%, epoch: 8 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [10/50] batch [20/176] time 0.098 (0.112) data 0.000 (0.016) loss 1.4060 (1.3473) teacher_loss 0.1365 (0.1570) loss_zs_kd 0.0395 (0.0479) loss_oracle 0.7073 (0.5935) kd_loss 0.8961 (0.8696) acc 93.7500 (95.1562) gate/entropy 1.0579 (1.0582) gate/usage_max 0.4255 (0.4250) gate/usage_min 0.2077 (0.2081) gate/usage_std 0.0920 (0.0917) teacher/entropy 0.0103 (0.0608) teacher/usage_max 0.6544 (0.6707) teacher/usage_min 0.0021 (0.0475) teacher/usage_std 0.2664 (0.2621) nleep/row_max_mean 1511.9814 (1494.4691) nleep/row_max_std 48.9248 (56.2430) nleep/row_min_mean 1482.4287 (1469.8512) lr 1.8763e-03 eta 0:13:24
epoch [10/50] batch [40/176] time 0.091 (0.104) data 0.000 (0.008) loss 1.2619 (1.3350) teacher_loss 0.0650 (0.1413) loss_zs_kd 0.0440 (0.0472) loss_oracle 0.5846 (0.5862) kd_loss 0.8826 (0.8770) acc 96.8750 (95.6250) gate/entropy 1.0576 (1.0580) gate/usage_max 0.4263 (0.4254) gate/usage_min 0.2074 (0.2079) gate/usage_std 0.0923 (0.0919) teacher/entropy 0.0451 (0.0543) teacher/usage_max 0.6425 (0.6722) teacher/usage_min 0.0379 (0.0505) teacher/usage_std 0.2470 (0.2608) nleep/row_max_mean 1487.9727 (1494.2005) nleep/row_max_std 55.9001 (54.9488) nleep/row_min_mean 1463.4937 (1469.4782) lr 1.8763e-03 eta 0:12:24
epoch [10/50] batch [60/176] time 0.092 (0.101) data 0.001 (0.006) loss 1.3134 (1.3286) teacher_loss 0.1853 (0.1349) loss_zs_kd 0.0337 (0.0482) loss_oracle 0.5107 (0.5837) kd_loss 0.8559 (0.8777) acc 90.6250 (95.7292) gate/entropy 1.0572 (1.0578) gate/usage_max 0.4270 (0.4258) gate/usage_min 0.2068 (0.2076) gate/usage_std 0.0928 (0.0921) teacher/entropy 0.0229 (0.0548) teacher/usage_max 0.8400 (0.6653) teacher/usage_min 0.0056 (0.0516) teacher/usage_std 0.3634 (0.2574) nleep/row_max_mean 1500.2727 (1495.0471) nleep/row_max_std 43.2804 (54.1563) nleep/row_min_mean 1473.7732 (1470.0569) lr 1.8763e-03 eta 0:12:05
epoch [10/50] batch [80/176] time 0.099 (0.104) data 0.000 (0.004) loss 1.3936 (1.3449) teacher_loss 0.1533 (0.1444) loss_zs_kd 0.0654 (0.0485) loss_oracle 0.6022 (0.5921) kd_loss 0.9066 (0.8802) acc 93.7500 (95.3516) gate/entropy 1.0568 (1.0576) gate/usage_max 0.4279 (0.4262) gate/usage_min 0.2065 (0.2073) gate/usage_std 0.0932 (0.0924) teacher/entropy 0.0308 (0.0549) teacher/usage_max 0.5837 (0.6667) teacher/usage_min 0.0420 (0.0575) teacher/usage_std 0.2231 (0.2569) nleep/row_max_mean 1485.9332 (1494.7925) nleep/row_max_std 57.5705 (54.2084) nleep/row_min_mean 1457.3427 (1469.4267) lr 1.8763e-03 eta 0:12:23
epoch [10/50] batch [100/176] time 0.094 (0.102) data 0.000 (0.003) loss 1.2897 (1.3447) teacher_loss 0.0885 (0.1472) loss_zs_kd 0.0469 (0.0478) loss_oracle 0.6121 (0.5887) kd_loss 0.8717 (0.8792) acc 96.8750 (95.3438) gate/entropy 1.0562 (1.0574) gate/usage_max 0.4292 (0.4267) gate/usage_min 0.2058 (0.2071) gate/usage_std 0.0939 (0.0926) teacher/entropy 0.0323 (0.0562) teacher/usage_max 0.6446 (0.6687) teacher/usage_min 0.0018 (0.0592) teacher/usage_std 0.2628 (0.2576) nleep/row_max_mean 1495.0032 (1494.1732) nleep/row_max_std 58.4046 (54.4843) nleep/row_min_mean 1469.1027 (1468.5775) lr 1.8763e-03 eta 0:12:08
epoch [10/50] batch [120/176] time 0.098 (0.102) data 0.000 (0.003) loss 1.8068 (1.3438) teacher_loss 0.6330 (0.1511) loss_zs_kd 0.0505 (0.0476) loss_oracle 0.6018 (0.5843) kd_loss 0.8476 (0.8768) acc 84.3750 (95.2083) gate/entropy 1.0558 (1.0572) gate/usage_max 0.4303 (0.4271) gate/usage_min 0.2054 (0.2069) gate/usage_std 0.0944 (0.0928) teacher/entropy 0.0494 (0.0560) teacher/usage_max 0.8229 (0.6745) teacher/usage_min 0.0431 (0.0573) teacher/usage_std 0.3482 (0.2611) nleep/row_max_mean 1498.2544 (1494.0573) nleep/row_max_std 65.1625 (54.5019) nleep/row_min_mean 1469.1101 (1468.1896) lr 1.8763e-03 eta 0:12:00
epoch [10/50] batch [140/176] time 0.089 (0.101) data 0.000 (0.003) loss 1.2135 (1.3396) teacher_loss 0.0606 (0.1530) loss_zs_kd 0.0422 (0.0472) loss_oracle 0.5344 (0.5778) kd_loss 0.8646 (0.8741) acc 100.0000 (95.1116) gate/entropy 1.0554 (1.0570) gate/usage_max 0.4318 (0.4277) gate/usage_min 0.2051 (0.2067) gate/usage_std 0.0949 (0.0931) teacher/entropy 0.0437 (0.0571) teacher/usage_max 0.7206 (0.6806) teacher/usage_min 0.0369 (0.0572) teacher/usage_std 0.2864 (0.2640) nleep/row_max_mean 1498.8918 (1493.9465) nleep/row_max_std 49.5404 (54.3873) nleep/row_min_mean 1470.5552 (1467.8711) lr 1.8763e-03 eta 0:11:54
epoch [10/50] batch [160/176] time 0.094 (0.100) data 0.000 (0.002) loss 1.3720 (1.3403) teacher_loss 0.2976 (0.1616) loss_zs_kd 0.0402 (0.0467) loss_oracle 0.5200 (0.5721) kd_loss 0.7943 (0.8693) acc 87.5000 (94.8438) gate/entropy 1.0548 (1.0567) gate/usage_max 0.4337 (0.4283) gate/usage_min 0.2046 (0.2064) gate/usage_std 0.0957 (0.0934) teacher/entropy 0.0887 (0.0593) teacher/usage_max 0.8517 (0.6915) teacher/usage_min 0.0375 (0.0568) teacher/usage_std 0.3678 (0.2702) nleep/row_max_mean 1497.8077 (1494.3348) nleep/row_max_std 58.5479 (53.9545) nleep/row_min_mean 1469.4369 (1467.8905) lr 1.8763e-03 eta 0:11:49
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.8%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,512
* accuracy: 56.9%
* error: 43.1%
* macro_f1: 54.5%
******* Domain l best val acc:      90.2%, epoch: 8 *******
******* Domain l best val test acc: 59.5%, epoch: 8 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [11/50] batch [20/176] time 0.095 (0.101) data 0.000 (0.014) loss 1.3335 (1.3559) teacher_loss 0.2694 (0.2586) loss_zs_kd 0.0514 (0.0374) loss_oracle 0.5026 (0.5237) kd_loss 0.7871 (0.8167) acc 90.6250 (91.5625) gate/entropy 1.0533 (1.0538) gate/usage_max 0.4383 (0.4370) gate/usage_min 0.2036 (0.2041) gate/usage_std 0.0974 (0.0968) teacher/entropy 0.0605 (0.0668) teacher/usage_max 0.8888 (0.8267) teacher/usage_min 0.0010 (0.0352) teacher/usage_std 0.3953 (0.3529) nleep/row_max_mean 1498.4011 (1497.8436) nleep/row_max_std 53.4174 (52.2821) nleep/row_min_mean 1466.8325 (1467.2498) lr 1.8443e-03 eta 0:11:45
epoch [11/50] batch [40/176] time 0.092 (0.092) data 0.000 (0.007) loss 1.3985 (1.3954) teacher_loss 0.3237 (0.2972) loss_zs_kd 0.0248 (0.0352) loss_oracle 0.5490 (0.5409) kd_loss 0.7879 (0.8102) acc 90.6250 (89.8438) gate/entropy 1.0528 (1.0535) gate/usage_max 0.4409 (0.4383) gate/usage_min 0.2037 (0.2038) gate/usage_std 0.0981 (0.0973) teacher/entropy 0.0885 (0.0644) teacher/usage_max 0.8202 (0.8544) teacher/usage_min 0.0335 (0.0339) teacher/usage_std 0.3473 (0.3709) nleep/row_max_mean 1488.3553 (1496.9795) nleep/row_max_std 57.8949 (54.6115) nleep/row_min_mean 1458.4720 (1465.7954) lr 1.8443e-03 eta 0:10:46
epoch [11/50] batch [60/176] time 0.094 (0.092) data 0.001 (0.005) loss 1.3482 (1.3950) teacher_loss 0.3017 (0.3021) loss_zs_kd 0.0209 (0.0329) loss_oracle 0.5257 (0.5437) kd_loss 0.7732 (0.8045) acc 84.3750 (89.8958) gate/entropy 1.0518 (1.0531) gate/usage_max 0.4438 (0.4397) gate/usage_min 0.2031 (0.2037) gate/usage_std 0.0993 (0.0978) teacher/entropy 0.0841 (0.0613) teacher/usage_max 0.8158 (0.8711) teacher/usage_min 0.0057 (0.0281) teacher/usage_std 0.3484 (0.3823) nleep/row_max_mean 1498.3167 (1497.5965) nleep/row_max_std 58.0276 (54.7020) nleep/row_min_mean 1466.0432 (1465.8393) lr 1.8443e-03 eta 0:10:44
epoch [11/50] batch [80/176] time 0.099 (0.092) data 0.000 (0.004) loss 1.3468 (1.3866) teacher_loss 0.2598 (0.2964) loss_zs_kd 0.0144 (0.0319) loss_oracle 0.5383 (0.5463) kd_loss 0.8107 (0.8012) acc 87.5000 (90.0781) gate/entropy 1.0509 (1.0527) gate/usage_max 0.4463 (0.4410) gate/usage_min 0.2025 (0.2035) gate/usage_std 0.1003 (0.0983) teacher/entropy 0.0263 (0.0596) teacher/usage_max 0.8804 (0.8796) teacher/usage_min 0.0025 (0.0262) teacher/usage_std 0.3897 (0.3880) nleep/row_max_mean 1502.8229 (1497.6943) nleep/row_max_std 56.4865 (55.3105) nleep/row_min_mean 1470.8420 (1465.9509) lr 1.8443e-03 eta 0:10:41
epoch [11/50] batch [100/176] time 0.096 (0.093) data 0.000 (0.003) loss 1.4988 (1.3972) teacher_loss 0.3133 (0.3029) loss_zs_kd 0.0267 (0.0304) loss_oracle 0.6744 (0.5598) kd_loss 0.8349 (0.7992) acc 90.6250 (89.8438) gate/entropy 1.0501 (1.0523) gate/usage_max 0.4485 (0.4423) gate/usage_min 0.2019 (0.2033) gate/usage_std 0.1013 (0.0988) teacher/entropy 0.0209 (0.0565) teacher/usage_max 0.7865 (0.8862) teacher/usage_min 0.0005 (0.0238) teacher/usage_std 0.3320 (0.3926) nleep/row_max_mean 1488.7559 (1497.7596) nleep/row_max_std 64.8131 (55.4351) nleep/row_min_mean 1458.8423 (1465.9652) lr 1.8443e-03 eta 0:10:43
epoch [11/50] batch [120/176] time 0.096 (0.093) data 0.000 (0.002) loss 1.4387 (1.3971) teacher_loss 0.2841 (0.2976) loss_zs_kd 0.0159 (0.0296) loss_oracle 0.6981 (0.5688) kd_loss 0.7977 (0.8003) acc 90.6250 (89.8698) gate/entropy 1.0491 (1.0518) gate/usage_max 0.4507 (0.4435) gate/usage_min 0.2012 (0.2030) gate/usage_std 0.1024 (0.0993) teacher/entropy 0.0164 (0.0523) teacher/usage_max 0.9374 (0.8877) teacher/usage_min 0.0023 (0.0228) teacher/usage_std 0.4278 (0.3937) nleep/row_max_mean 1517.3240 (1498.1468) nleep/row_max_std 53.8165 (55.5613) nleep/row_min_mean 1484.8062 (1466.4000) lr 1.8443e-03 eta 0:10:46
epoch [11/50] batch [140/176] time 0.102 (0.093) data 0.000 (0.002) loss 1.3394 (1.4001) teacher_loss 0.2266 (0.2971) loss_zs_kd 0.0259 (0.0293) loss_oracle 0.6739 (0.5802) kd_loss 0.7629 (0.7983) acc 90.6250 (89.7768) gate/entropy 1.0485 (1.0514) gate/usage_max 0.4521 (0.4446) gate/usage_min 0.2008 (0.2027) gate/usage_std 0.1031 (0.0997) teacher/entropy 0.0461 (0.0509) teacher/usage_max 0.9428 (0.8890) teacher/usage_min 0.0002 (0.0208) teacher/usage_std 0.4316 (0.3946) nleep/row_max_mean 1520.2085 (1498.3476) nleep/row_max_std 34.8960 (55.5260) nleep/row_min_mean 1487.4967 (1466.7470) lr 1.8443e-03 eta 0:10:42
epoch [11/50] batch [160/176] time 0.088 (0.092) data 0.000 (0.002) loss 1.2666 (1.3992) teacher_loss 0.1249 (0.2951) loss_zs_kd 0.0296 (0.0285) loss_oracle 0.6926 (0.5853) kd_loss 0.7807 (0.7971) acc 93.7500 (89.6875) gate/entropy 1.0480 (1.0510) gate/usage_max 0.4535 (0.4457) gate/usage_min 0.2005 (0.2025) gate/usage_std 0.1037 (0.1002) teacher/entropy 0.0890 (0.0502) teacher/usage_max 0.7545 (0.8862) teacher/usage_min 0.0231 (0.0197) teacher/usage_std 0.3087 (0.3929) nleep/row_max_mean 1475.9069 (1497.5512) nleep/row_max_std 61.5587 (55.5248) nleep/row_min_mean 1450.4337 (1466.2199) lr 1.8443e-03 eta 0:10:36
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,188
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,539
* accuracy: 57.9%
* error: 42.1%
* macro_f1: 55.0%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [12/50] batch [20/176] time 0.097 (0.106) data 0.000 (0.014) loss 1.3295 (1.4663) teacher_loss 0.2460 (0.3454) loss_zs_kd 0.0195 (0.0239) loss_oracle 0.6063 (0.6244) kd_loss 0.7707 (0.7967) acc 87.5000 (87.8125) gate/entropy 1.0463 (1.0469) gate/usage_max 0.4565 (0.4555) gate/usage_min 0.1988 (0.1995) gate/usage_std 0.1055 (0.1049) teacher/entropy 0.0392 (0.0301) teacher/usage_max 0.9104 (0.8860) teacher/usage_min 0.0012 (0.0162) teacher/usage_std 0.4096 (0.3931) nleep/row_max_mean 1501.7856 (1498.1951) nleep/row_max_std 57.9104 (52.1342) nleep/row_min_mean 1474.4974 (1470.0670) lr 1.8090e-03 eta 0:12:04
epoch [12/50] batch [40/176] time 0.086 (0.097) data 0.000 (0.007) loss 1.2245 (1.4312) teacher_loss 0.1812 (0.3261) loss_zs_kd 0.0218 (0.0244) loss_oracle 0.4923 (0.6041) kd_loss 0.7862 (0.7908) acc 96.8750 (88.3594) gate/entropy 1.0460 (1.0466) gate/usage_max 0.4576 (0.4562) gate/usage_min 0.1988 (0.1993) gate/usage_std 0.1059 (0.1052) teacher/entropy 0.0047 (0.0328) teacher/usage_max 0.9682 (0.8903) teacher/usage_min 0.0001 (0.0143) teacher/usage_std 0.4491 (0.3958) nleep/row_max_mean 1489.9856 (1496.5875) nleep/row_max_std 61.9695 (52.5196) nleep/row_min_mean 1459.8912 (1468.3331) lr 1.8090e-03 eta 0:11:04
epoch [12/50] batch [60/176] time 0.115 (0.095) data 0.001 (0.005) loss 1.3890 (1.4270) teacher_loss 0.3253 (0.3229) loss_zs_kd 0.0242 (0.0242) loss_oracle 0.6290 (0.6044) kd_loss 0.7371 (0.7899) acc 90.6250 (88.8542) gate/entropy 1.0453 (1.0462) gate/usage_max 0.4595 (0.4570) gate/usage_min 0.1986 (0.1990) gate/usage_std 0.1067 (0.1056) teacher/entropy 0.0583 (0.0289) teacher/usage_max 0.9397 (0.8959) teacher/usage_min 0.0002 (0.0111) teacher/usage_std 0.4295 (0.3999) nleep/row_max_mean 1479.7418 (1495.7974) nleep/row_max_std 62.9451 (53.5774) nleep/row_min_mean 1453.4302 (1467.1778) lr 1.8090e-03 eta 0:10:46
epoch [12/50] batch [80/176] time 0.101 (0.095) data 0.000 (0.004) loss 1.2783 (1.4209) teacher_loss 0.1778 (0.3179) loss_zs_kd 0.0291 (0.0248) loss_oracle 0.6247 (0.6018) kd_loss 0.7735 (0.7897) acc 96.8750 (89.1406) gate/entropy 1.0445 (1.0459) gate/usage_max 0.4612 (0.4579) gate/usage_min 0.1982 (0.1989) gate/usage_std 0.1075 (0.1060) teacher/entropy 0.0224 (0.0278) teacher/usage_max 0.9261 (0.8952) teacher/usage_min 0.0001 (0.0110) teacher/usage_std 0.4202 (0.3994) nleep/row_max_mean 1500.6162 (1495.8781) nleep/row_max_std 49.9535 (53.2101) nleep/row_min_mean 1472.1047 (1466.8271) lr 1.8090e-03 eta 0:10:46
epoch [12/50] batch [100/176] time 0.099 (0.095) data 0.001 (0.003) loss 1.3006 (1.4192) teacher_loss 0.2006 (0.3126) loss_zs_kd 0.0228 (0.0251) loss_oracle 0.6268 (0.6090) kd_loss 0.7752 (0.7895) acc 96.8750 (89.0312) gate/entropy 1.0436 (1.0455) gate/usage_max 0.4630 (0.4587) gate/usage_min 0.1975 (0.1987) gate/usage_std 0.1085 (0.1064) teacher/entropy 0.0159 (0.0262) teacher/usage_max 0.9321 (0.8934) teacher/usage_min 0.0000 (0.0093) teacher/usage_std 0.4243 (0.3984) nleep/row_max_mean 1487.8931 (1495.4997) nleep/row_max_std 72.7595 (54.1127) nleep/row_min_mean 1459.7294 (1466.3506) lr 1.8090e-03 eta 0:10:44
epoch [12/50] batch [120/176] time 0.083 (0.094) data 0.000 (0.003) loss 1.3167 (1.4204) teacher_loss 0.2590 (0.3112) loss_zs_kd 0.0267 (0.0244) loss_oracle 0.5492 (0.6164) kd_loss 0.7698 (0.7888) acc 87.5000 (89.3229) gate/entropy 1.0432 (1.0452) gate/usage_max 0.4638 (0.4595) gate/usage_min 0.1971 (0.1985) gate/usage_std 0.1090 (0.1067) teacher/entropy 0.0092 (0.0261) teacher/usage_max 0.9662 (0.8916) teacher/usage_min 0.0000 (0.0091) teacher/usage_std 0.4477 (0.3973) nleep/row_max_mean 1495.2645 (1495.6850) nleep/row_max_std 60.0378 (54.0718) nleep/row_min_mean 1464.6307 (1466.4087) lr 1.8090e-03 eta 0:10:34
epoch [12/50] batch [140/176] time 0.092 (0.094) data 0.000 (0.002) loss 1.7449 (1.4153) teacher_loss 0.5864 (0.3074) loss_zs_kd 0.0234 (0.0236) loss_oracle 0.7078 (0.6170) kd_loss 0.7929 (0.7876) acc 84.3750 (89.5536) gate/entropy 1.0425 (1.0449) gate/usage_max 0.4650 (0.4601) gate/usage_min 0.1966 (0.1982) gate/usage_std 0.1096 (0.1071) teacher/entropy 0.0028 (0.0250) teacher/usage_max 0.9058 (0.8933) teacher/usage_min 0.0000 (0.0082) teacher/usage_std 0.4066 (0.3985) nleep/row_max_mean 1505.9500 (1496.0784) nleep/row_max_std 37.9778 (54.0080) nleep/row_min_mean 1473.7483 (1466.7073) lr 1.8090e-03 eta 0:10:31
epoch [12/50] batch [160/176] time 0.115 (0.095) data 0.000 (0.002) loss 1.4303 (1.4160) teacher_loss 0.3940 (0.3110) loss_zs_kd 0.0180 (0.0233) loss_oracle 0.5324 (0.6162) kd_loss 0.7610 (0.7854) acc 84.3750 (89.4141) gate/entropy 1.0422 (1.0446) gate/usage_max 0.4658 (0.4608) gate/usage_min 0.1966 (0.1980) gate/usage_std 0.1100 (0.1074) teacher/entropy 0.0359 (0.0260) teacher/usage_max 0.8995 (0.8922) teacher/usage_min 0.0009 (0.0075) teacher/usage_std 0.4024 (0.3978) nleep/row_max_mean 1479.8881 (1496.0339) nleep/row_max_std 64.5035 (54.2649) nleep/row_min_mean 1452.1875 (1466.7426) lr 1.8090e-03 eta 0:10:33
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,167
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,625
* accuracy: 61.2%
* error: 38.8%
* macro_f1: 58.0%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [13/50] batch [20/176] time 0.081 (0.101) data 0.000 (0.016) loss 1.2860 (1.3793) teacher_loss 0.1969 (0.2812) loss_zs_kd 0.0166 (0.0203) loss_oracle 0.6512 (0.6321) kd_loss 0.7552 (0.7719) acc 93.7500 (89.6875) gate/entropy 1.0411 (1.0413) gate/usage_max 0.4683 (0.4678) gate/usage_min 0.1960 (0.1961) gate/usage_std 0.1112 (0.1109) teacher/entropy 0.0211 (0.0251) teacher/usage_max 0.9601 (0.8908) teacher/usage_min 0.0081 (0.0021) teacher/usage_std 0.4433 (0.3972) nleep/row_max_mean 1503.9448 (1491.7823) nleep/row_max_std 44.6367 (55.4711) nleep/row_min_mean 1475.8712 (1464.2931) lr 1.7705e-03 eta 0:11:15
epoch [13/50] batch [40/176] time 0.092 (0.093) data 0.000 (0.008) loss 1.3734 (1.3914) teacher_loss 0.2750 (0.3083) loss_zs_kd 0.0303 (0.0212) loss_oracle 0.5245 (0.6008) kd_loss 0.8210 (0.7721) acc 90.6250 (88.2031) gate/entropy 1.0408 (1.0411) gate/usage_max 0.4692 (0.4684) gate/usage_min 0.1960 (0.1960) gate/usage_std 0.1115 (0.1112) teacher/entropy 0.0048 (0.0235) teacher/usage_max 0.8442 (0.8973) teacher/usage_min 0.0310 (0.0055) teacher/usage_std 0.3632 (0.4011) nleep/row_max_mean 1486.1436 (1493.6605) nleep/row_max_std 46.2281 (54.9074) nleep/row_min_mean 1457.4075 (1465.8248) lr 1.7705e-03 eta 0:10:17
epoch [13/50] batch [60/176] time 0.094 (0.091) data 0.001 (0.005) loss 1.3717 (1.3832) teacher_loss 0.2888 (0.3011) loss_zs_kd 0.0171 (0.0203) loss_oracle 0.6198 (0.6027) kd_loss 0.7645 (0.7706) acc 93.7500 (88.6979) gate/entropy 1.0400 (1.0408) gate/usage_max 0.4711 (0.4691) gate/usage_min 0.1956 (0.1959) gate/usage_std 0.1125 (0.1115) teacher/entropy 0.0088 (0.0221) teacher/usage_max 0.9396 (0.9027) teacher/usage_min 0.0000 (0.0055) teacher/usage_std 0.4294 (0.4048) nleep/row_max_mean 1508.9385 (1495.3212) nleep/row_max_std 48.4305 (54.1057) nleep/row_min_mean 1477.4644 (1467.1990) lr 1.7705e-03 eta 0:10:02
epoch [13/50] batch [80/176] time 0.077 (0.091) data 0.000 (0.004) loss 1.2808 (1.3837) teacher_loss 0.2326 (0.3006) loss_zs_kd 0.0136 (0.0212) loss_oracle 0.4541 (0.6080) kd_loss 0.8143 (0.7685) acc 93.7500 (89.0625) gate/entropy 1.0394 (1.0405) gate/usage_max 0.4724 (0.4697) gate/usage_min 0.1954 (0.1958) gate/usage_std 0.1131 (0.1118) teacher/entropy 0.0082 (0.0221) teacher/usage_max 0.8430 (0.9050) teacher/usage_min 0.0319 (0.0051) teacher/usage_std 0.3624 (0.4063) nleep/row_max_mean 1481.3301 (1494.9440) nleep/row_max_std 66.0440 (54.5689) nleep/row_min_mean 1453.7869 (1466.8810) lr 1.7705e-03 eta 0:10:02
epoch [13/50] batch [100/176] time 0.097 (0.095) data 0.000 (0.003) loss 1.5869 (1.4008) teacher_loss 0.4356 (0.3106) loss_zs_kd 0.0211 (0.0205) loss_oracle 0.6701 (0.6220) kd_loss 0.8057 (0.7690) acc 81.2500 (88.6875) gate/entropy 1.0392 (1.0402) gate/usage_max 0.4730 (0.4703) gate/usage_min 0.1954 (0.1957) gate/usage_std 0.1133 (0.1121) teacher/entropy 0.0042 (0.0224) teacher/usage_max 0.8745 (0.9010) teacher/usage_min 0.0313 (0.0058) teacher/usage_std 0.3835 (0.4036) nleep/row_max_mean 1472.3152 (1494.6050) nleep/row_max_std 62.2182 (55.0071) nleep/row_min_mean 1449.1638 (1466.7938) lr 1.7705e-03 eta 0:10:28
epoch [13/50] batch [120/176] time 0.096 (0.096) data 0.000 (0.003) loss 1.3711 (1.4097) teacher_loss 0.4026 (0.3219) loss_zs_kd 0.0290 (0.0202) loss_oracle 0.4717 (0.6225) kd_loss 0.7182 (0.7664) acc 87.5000 (88.3333) gate/entropy 1.0384 (1.0400) gate/usage_max 0.4741 (0.4709) gate/usage_min 0.1947 (0.1956) gate/usage_std 0.1141 (0.1124) teacher/entropy 0.0363 (0.0247) teacher/usage_max 0.9791 (0.9007) teacher/usage_min 0.0012 (0.0067) teacher/usage_std 0.4567 (0.4033) nleep/row_max_mean 1502.4456 (1494.4151) nleep/row_max_std 60.8670 (55.2493) nleep/row_min_mean 1474.7195 (1466.9208) lr 1.7705e-03 eta 0:10:29
epoch [13/50] batch [140/176] time 0.092 (0.096) data 0.000 (0.003) loss 1.2037 (1.4008) teacher_loss 0.1658 (0.3177) loss_zs_kd 0.0296 (0.0202) loss_oracle 0.5157 (0.6146) kd_loss 0.7652 (0.7658) acc 93.7500 (88.4821) gate/entropy 1.0381 (1.0398) gate/usage_max 0.4754 (0.4714) gate/usage_min 0.1949 (0.1955) gate/usage_std 0.1145 (0.1126) teacher/entropy 0.0015 (0.0244) teacher/usage_max 0.9373 (0.9008) teacher/usage_min 0.0001 (0.0067) teacher/usage_std 0.4278 (0.4034) nleep/row_max_mean 1492.8792 (1493.8893) nleep/row_max_std 52.7032 (55.9292) nleep/row_min_mean 1470.1299 (1466.6936) lr 1.7705e-03 eta 0:10:31
epoch [13/50] batch [160/176] time 0.102 (0.096) data 0.000 (0.002) loss 1.5422 (1.3940) teacher_loss 0.4575 (0.3176) loss_zs_kd 0.0182 (0.0203) loss_oracle 0.6001 (0.6036) kd_loss 0.7755 (0.7645) acc 78.1250 (88.4375) gate/entropy 1.0378 (1.0395) gate/usage_max 0.4765 (0.4720) gate/usage_min 0.1952 (0.1954) gate/usage_std 0.1149 (0.1129) teacher/entropy 0.0009 (0.0243) teacher/usage_max 0.9061 (0.9021) teacher/usage_min 0.0000 (0.0068) teacher/usage_std 0.4068 (0.4042) nleep/row_max_mean 1490.5134 (1493.9176) nleep/row_max_std 50.7422 (55.9119) nleep/row_min_mean 1461.1172 (1466.7569) lr 1.7705e-03 eta 0:10:27
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,185
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 91.8%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,625
* accuracy: 61.2%
* error: 38.8%
* macro_f1: 56.2%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [14/50] batch [20/176] time 0.086 (0.107) data 0.000 (0.015) loss 1.3770 (1.3559) teacher_loss 0.3400 (0.2974) loss_zs_kd 0.0139 (0.0201) loss_oracle 0.5213 (0.5872) kd_loss 0.7694 (0.7549) acc 84.3750 (88.4375) gate/entropy 1.0368 (1.0369) gate/usage_max 0.4791 (0.4787) gate/usage_min 0.1951 (0.1951) gate/usage_std 0.1161 (0.1159) teacher/entropy 0.0030 (0.0236) teacher/usage_max 0.9058 (0.9008) teacher/usage_min 0.0001 (0.0051) teacher/usage_std 0.4066 (0.4042) nleep/row_max_mean 1486.4001 (1492.4002) nleep/row_max_std 59.6272 (56.5533) nleep/row_min_mean 1460.8845 (1466.6445) lr 1.7290e-03 eta 0:11:34
epoch [14/50] batch [40/176] time 0.095 (0.097) data 0.000 (0.008) loss 1.3190 (1.3561) teacher_loss 0.3247 (0.3111) loss_zs_kd 0.0173 (0.0202) loss_oracle 0.4598 (0.5667) kd_loss 0.7557 (0.7516) acc 87.5000 (88.1250) gate/entropy 1.0363 (1.0367) gate/usage_max 0.4805 (0.4793) gate/usage_min 0.1952 (0.1951) gate/usage_std 0.1166 (0.1162) teacher/entropy 0.0021 (0.0316) teacher/usage_max 0.9372 (0.8959) teacher/usage_min 0.0003 (0.0117) teacher/usage_std 0.4277 (0.4003) nleep/row_max_mean 1492.4573 (1491.9554) nleep/row_max_std 53.9717 (56.8839) nleep/row_min_mean 1467.2260 (1466.3069) lr 1.7290e-03 eta 0:10:28
epoch [14/50] batch [60/176] time 0.093 (0.093) data 0.001 (0.005) loss 1.5692 (1.3576) teacher_loss 0.4775 (0.3077) loss_zs_kd 0.0186 (0.0201) loss_oracle 0.6746 (0.5728) kd_loss 0.7451 (0.7534) acc 78.1250 (88.0729) gate/entropy 1.0359 (1.0364) gate/usage_max 0.4819 (0.4800) gate/usage_min 0.1955 (0.1951) gate/usage_std 0.1171 (0.1165) teacher/entropy 0.0577 (0.0300) teacher/usage_max 0.8633 (0.8939) teacher/usage_min 0.0366 (0.0138) teacher/usage_std 0.3757 (0.3986) nleep/row_max_mean 1494.2698 (1491.7049) nleep/row_max_std 51.4816 (56.3594) nleep/row_min_mean 1468.3442 (1466.1668) lr 1.7290e-03 eta 0:10:01
epoch [14/50] batch [80/176] time 0.100 (0.093) data 0.000 (0.004) loss 1.3905 (1.3667) teacher_loss 0.3016 (0.3212) loss_zs_kd 0.0303 (0.0207) loss_oracle 0.5723 (0.5676) kd_loss 0.7877 (0.7513) acc 90.6250 (87.8906) gate/entropy 1.0349 (1.0362) gate/usage_max 0.4842 (0.4808) gate/usage_min 0.1955 (0.1952) gate/usage_std 0.1182 (0.1168) teacher/entropy 0.0029 (0.0308) teacher/usage_max 0.8436 (0.8962) teacher/usage_min 0.0004 (0.0151) teacher/usage_std 0.3664 (0.4000) nleep/row_max_mean 1496.5093 (1491.7504) nleep/row_max_std 53.3313 (55.3737) nleep/row_min_mean 1469.6628 (1466.0832) lr 1.7290e-03 eta 0:09:58
epoch [14/50] batch [100/176] time 0.097 (0.092) data 0.000 (0.003) loss 1.1505 (1.3690) teacher_loss 0.1743 (0.3188) loss_zs_kd 0.0202 (0.0208) loss_oracle 0.4902 (0.5729) kd_loss 0.7210 (0.7534) acc 96.8750 (88.3750) gate/entropy 1.0348 (1.0359) gate/usage_max 0.4854 (0.4816) gate/usage_min 0.1963 (0.1954) gate/usage_std 0.1185 (0.1171) teacher/entropy 0.0833 (0.0338) teacher/usage_max 0.8929 (0.8897) teacher/usage_min 0.0313 (0.0193) teacher/usage_std 0.3961 (0.3953) nleep/row_max_mean 1476.0198 (1491.8715) nleep/row_max_std 65.7045 (54.6814) nleep/row_min_mean 1454.3926 (1466.3434) lr 1.7290e-03 eta 0:09:51
epoch [14/50] batch [120/176] time 0.093 (0.092) data 0.000 (0.003) loss 1.7257 (1.3645) teacher_loss 0.6121 (0.3153) loss_zs_kd 0.0213 (0.0211) loss_oracle 0.5954 (0.5725) kd_loss 0.8053 (0.7524) acc 87.5000 (88.4896) gate/entropy 1.0340 (1.0357) gate/usage_max 0.4876 (0.4824) gate/usage_min 0.1965 (0.1955) gate/usage_std 0.1195 (0.1174) teacher/entropy 0.0128 (0.0362) teacher/usage_max 0.8733 (0.8881) teacher/usage_min 0.0314 (0.0219) teacher/usage_std 0.3827 (0.3940) nleep/row_max_mean 1496.7051 (1492.5929) nleep/row_max_std 59.4870 (54.1971) nleep/row_min_mean 1472.0803 (1467.0276) lr 1.7290e-03 eta 0:09:45
epoch [14/50] batch [140/176] time 0.075 (0.090) data 0.000 (0.002) loss 1.1638 (1.3674) teacher_loss 0.1333 (0.3124) loss_zs_kd 0.0168 (0.0217) loss_oracle 0.5411 (0.5790) kd_loss 0.7516 (0.7546) acc 96.8750 (88.5268) gate/entropy 1.0333 (1.0354) gate/usage_max 0.4896 (0.4833) gate/usage_min 0.1969 (0.1957) gate/usage_std 0.1203 (0.1177) teacher/entropy 0.0673 (0.0381) teacher/usage_max 0.8533 (0.8827) teacher/usage_min 0.0623 (0.0254) teacher/usage_std 0.3678 (0.3900) nleep/row_max_mean 1498.1377 (1491.8785) nleep/row_max_std 57.8392 (54.6553) nleep/row_min_mean 1472.0161 (1466.5459) lr 1.7290e-03 eta 0:09:36
epoch [14/50] batch [160/176] time 0.095 (0.091) data 0.000 (0.002) loss 1.3090 (1.3708) teacher_loss 0.1243 (0.3084) loss_zs_kd 0.0309 (0.0220) loss_oracle 0.6567 (0.5896) kd_loss 0.8409 (0.7566) acc 96.8750 (88.7500) gate/entropy 1.0328 (1.0351) gate/usage_max 0.4912 (0.4842) gate/usage_min 0.1974 (0.1959) gate/usage_std 0.1209 (0.1181) teacher/entropy 0.1159 (0.0431) teacher/usage_max 0.6832 (0.8744) teacher/usage_min 0.0941 (0.0294) teacher/usage_std 0.2529 (0.3842) nleep/row_max_mean 1482.2734 (1492.0997) nleep/row_max_std 64.6612 (54.8763) nleep/row_min_mean 1458.3394 (1466.9096) lr 1.7290e-03 eta 0:09:35
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.8%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,690
* accuracy: 63.6%
* error: 36.4%
* macro_f1: 59.4%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     69.3%, epoch: 1 *******
epoch [15/50] batch [20/176] time 0.090 (0.097) data 0.000 (0.012) loss 1.7061 (1.3999) teacher_loss 0.4406 (0.2631) loss_zs_kd 0.0396 (0.0246) loss_oracle 0.6018 (0.5520) kd_loss 0.9449 (0.8485) acc 87.5000 (91.2500) gate/entropy 1.0323 (1.0323) gate/usage_max 0.4933 (0.4928) gate/usage_min 0.1985 (0.1980) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.0822 (0.0898) teacher/usage_max 0.6297 (0.7088) teacher/usage_min 0.0362 (0.0724) teacher/usage_std 0.2423 (0.2750) nleep/row_max_mean 1477.9922 (1494.0260) nleep/row_max_std 59.1974 (52.6743) nleep/row_min_mean 1454.2451 (1470.4230) lr 1.6845e-03 eta 0:10:12
epoch [15/50] batch [40/176] time 0.084 (0.093) data 0.000 (0.006) loss 1.6045 (1.4485) teacher_loss 0.2079 (0.2419) loss_zs_kd 0.0332 (0.0278) loss_oracle 0.7270 (0.5806) kd_loss 1.0164 (0.9024) acc 93.7500 (92.2656) gate/entropy 1.0318 (1.0321) gate/usage_max 0.4951 (0.4937) gate/usage_min 0.1993 (0.1984) gate/usage_std 0.1223 (0.1219) teacher/entropy 0.0536 (0.0850) teacher/usage_max 0.5178 (0.6517) teacher/usage_min 0.1675 (0.0760) teacher/usage_std 0.1436 (0.2438) nleep/row_max_mean 1480.7478 (1493.3139) nleep/row_max_std 62.1179 (54.2424) nleep/row_min_mean 1456.9005 (1469.3544) lr 1.6845e-03 eta 0:09:47
epoch [15/50] batch [60/176] time 0.092 (0.093) data 0.001 (0.004) loss 1.6167 (1.4825) teacher_loss 0.2943 (0.2403) loss_zs_kd 0.0365 (0.0286) loss_oracle 0.6062 (0.5957) kd_loss 1.0010 (0.9301) acc 90.6250 (91.9271) gate/entropy 1.0313 (1.0318) gate/usage_max 0.4967 (0.4946) gate/usage_min 0.2001 (0.1988) gate/usage_std 0.1230 (0.1222) teacher/entropy 0.0781 (0.0838) teacher/usage_max 0.5659 (0.6237) teacher/usage_min 0.0376 (0.0738) teacher/usage_std 0.2203 (0.2323) nleep/row_max_mean 1484.7592 (1494.1962) nleep/row_max_std 61.5602 (55.2229) nleep/row_min_mean 1460.3958 (1469.9503) lr 1.6845e-03 eta 0:09:41
epoch [15/50] batch [80/176] time 0.094 (0.089) data 0.000 (0.003) loss 1.7673 (1.5051) teacher_loss 0.3264 (0.2450) loss_zs_kd 0.0298 (0.0287) loss_oracle 0.7158 (0.6031) kd_loss 1.0681 (0.9442) acc 93.7500 (91.9531) gate/entropy 1.0307 (1.0316) gate/usage_max 0.4985 (0.4954) gate/usage_min 0.2008 (0.1992) gate/usage_std 0.1237 (0.1225) teacher/entropy 0.0722 (0.0874) teacher/usage_max 0.4545 (0.6087) teacher/usage_min 0.1285 (0.0732) teacher/usage_std 0.1457 (0.2262) nleep/row_max_mean 1484.6255 (1493.9176) nleep/row_max_std 71.3730 (55.7191) nleep/row_min_mean 1460.2223 (1469.8710) lr 1.6845e-03 eta 0:09:19
epoch [15/50] batch [100/176] time 0.081 (0.090) data 0.000 (0.003) loss 1.6090 (1.5263) teacher_loss 0.3686 (0.2547) loss_zs_kd 0.0195 (0.0281) loss_oracle 0.5349 (0.6070) kd_loss 0.9632 (0.9541) acc 87.5000 (91.4688) gate/entropy 1.0303 (1.0314) gate/usage_max 0.5000 (0.4962) gate/usage_min 0.2016 (0.1996) gate/usage_std 0.1243 (0.1228) teacher/entropy 0.0161 (0.0885) teacher/usage_max 0.6843 (0.5948) teacher/usage_min 0.0000 (0.0728) teacher/usage_std 0.2796 (0.2212) nleep/row_max_mean 1492.4556 (1493.8699) nleep/row_max_std 55.9637 (55.2501) nleep/row_min_mean 1465.6631 (1469.8570) lr 1.6845e-03 eta 0:09:20
epoch [15/50] batch [120/176] time 0.095 (0.090) data 0.000 (0.002) loss 1.7318 (1.5460) teacher_loss 0.3197 (0.2576) loss_zs_kd 0.0200 (0.0284) loss_oracle 0.5984 (0.6110) kd_loss 1.1029 (0.9687) acc 90.6250 (91.4062) gate/entropy 1.0300 (1.0311) gate/usage_max 0.5011 (0.4969) gate/usage_min 0.2023 (0.2000) gate/usage_std 0.1247 (0.1231) teacher/entropy 0.1508 (0.0900) teacher/usage_max 0.6201 (0.5834) teacher/usage_min 0.0002 (0.0769) teacher/usage_std 0.2552 (0.2149) nleep/row_max_mean 1507.0399 (1493.4799) nleep/row_max_std 36.8334 (55.0298) nleep/row_min_mean 1483.6653 (1469.5406) lr 1.6845e-03 eta 0:09:19
epoch [15/50] batch [140/176] time 0.077 (0.088) data 0.000 (0.002) loss 1.6304 (1.5631) teacher_loss 0.0928 (0.2588) loss_zs_kd 0.0216 (0.0288) loss_oracle 0.6153 (0.6092) kd_loss 1.2192 (0.9852) acc 100.0000 (91.2946) gate/entropy 1.0298 (1.0309) gate/usage_max 0.5021 (0.4976) gate/usage_min 0.2032 (0.2004) gate/usage_std 0.1251 (0.1234) teacher/entropy 0.0787 (0.0913) teacher/usage_max 0.5812 (0.5782) teacher/usage_min 0.1562 (0.0774) teacher/usage_std 0.1806 (0.2126) nleep/row_max_mean 1488.1949 (1493.3686) nleep/row_max_std 56.3719 (54.7250) nleep/row_min_mean 1460.0679 (1469.3899) lr 1.6845e-03 eta 0:09:07
epoch [15/50] batch [160/176] time 0.079 (0.087) data 0.000 (0.002) loss 1.6523 (1.5747) teacher_loss 0.1830 (0.2594) loss_zs_kd 0.0533 (0.0292) loss_oracle 0.5196 (0.6091) kd_loss 1.1829 (0.9962) acc 96.8750 (91.3281) gate/entropy 1.0293 (1.0308) gate/usage_max 0.5033 (0.4982) gate/usage_min 0.2036 (0.2007) gate/usage_std 0.1256 (0.1236) teacher/entropy 0.0589 (0.0915) teacher/usage_max 0.5939 (0.5720) teacher/usage_min 0.0319 (0.0771) teacher/usage_std 0.2313 (0.2103) nleep/row_max_mean 1491.3018 (1493.1308) nleep/row_max_std 59.2453 (54.4495) nleep/row_min_mean 1467.4609 (1469.1471) lr 1.6845e-03 eta 0:08:57
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,143
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 90.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,893
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 62.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.3%, epoch: 15 *******
epoch [16/50] batch [20/176] time 0.095 (0.119) data 0.000 (0.021) loss 1.8176 (1.8105) teacher_loss 0.2794 (0.3313) loss_zs_kd 0.0344 (0.0263) loss_oracle 0.7480 (0.6269) kd_loss 1.1470 (1.1526) acc 93.7500 (88.7500) gate/entropy 1.0295 (1.0294) gate/usage_max 0.5039 (0.5038) gate/usage_min 0.2051 (0.2048) gate/usage_std 0.1256 (0.1256) teacher/entropy 0.1136 (0.0960) teacher/usage_max 0.5255 (0.5778) teacher/usage_min 0.1875 (0.0957) teacher/usage_std 0.1418 (0.2041) nleep/row_max_mean 1473.5050 (1489.2933) nleep/row_max_std 65.1546 (54.9122) nleep/row_min_mean 1446.9656 (1464.4553) lr 1.6374e-03 eta 0:12:08
epoch [16/50] batch [40/176] time 0.104 (0.106) data 0.000 (0.010) loss 1.6789 (1.7915) teacher_loss 0.1370 (0.2922) loss_zs_kd 0.0204 (0.0292) loss_oracle 0.6528 (0.6285) kd_loss 1.2052 (1.1704) acc 96.8750 (90.3125) gate/entropy 1.0296 (1.0295) gate/usage_max 0.5042 (0.5039) gate/usage_min 0.2059 (0.2052) gate/usage_std 0.1256 (0.1256) teacher/entropy 0.0800 (0.0935) teacher/usage_max 0.6713 (0.5925) teacher/usage_min 0.0000 (0.0924) teacher/usage_std 0.2741 (0.2101) nleep/row_max_mean 1502.0831 (1490.2071) nleep/row_max_std 47.2069 (54.0898) nleep/row_min_mean 1474.9172 (1465.2155) lr 1.6374e-03 eta 0:10:50
epoch [16/50] batch [60/176] time 0.088 (0.103) data 0.001 (0.007) loss 2.0371 (1.8238) teacher_loss 0.4132 (0.2895) loss_zs_kd 0.0362 (0.0291) loss_oracle 0.6749 (0.6495) kd_loss 1.2684 (1.1951) acc 90.6250 (90.5208) gate/entropy 1.0297 (1.0296) gate/usage_max 0.5046 (0.5041) gate/usage_min 0.2068 (0.2056) gate/usage_std 0.1256 (0.1256) teacher/entropy 0.0408 (0.0907) teacher/usage_max 0.6430 (0.6178) teacher/usage_min 0.0938 (0.0904) teacher/usage_std 0.2296 (0.2228) nleep/row_max_mean 1501.5557 (1490.8525) nleep/row_max_std 51.0389 (52.7382) nleep/row_min_mean 1475.6571 (1465.9102) lr 1.6374e-03 eta 0:10:25
epoch [16/50] batch [80/176] time 0.095 (0.099) data 0.000 (0.005) loss 1.8461 (1.8565) teacher_loss 0.1980 (0.2839) loss_zs_kd 0.0301 (0.0298) loss_oracle 0.6799 (0.6721) kd_loss 1.2930 (1.2216) acc 90.6250 (90.3906) gate/entropy 1.0296 (1.0296) gate/usage_max 0.5053 (0.5042) gate/usage_min 0.2076 (0.2060) gate/usage_std 0.1259 (0.1256) teacher/entropy 0.0504 (0.0860) teacher/usage_max 0.7032 (0.6435) teacher/usage_min 0.0626 (0.0882) teacher/usage_std 0.2708 (0.2370) nleep/row_max_mean 1504.5903 (1491.9259) nleep/row_max_std 47.4851 (51.4360) nleep/row_min_mean 1479.4170 (1466.7929) lr 1.6374e-03 eta 0:10:01
epoch [16/50] batch [100/176] time 0.091 (0.098) data 0.000 (0.004) loss 1.8865 (1.8679) teacher_loss 0.2986 (0.2800) loss_zs_kd 0.0373 (0.0313) loss_oracle 0.6241 (0.6685) kd_loss 1.2571 (1.2380) acc 84.3750 (90.0938) gate/entropy 1.0306 (1.0298) gate/usage_max 0.5042 (0.5043) gate/usage_min 0.2088 (0.2065) gate/usage_std 0.1249 (0.1255) teacher/entropy 0.0890 (0.0807) teacher/usage_max 0.6899 (0.6548) teacher/usage_min 0.0937 (0.0917) teacher/usage_std 0.2571 (0.2423) nleep/row_max_mean 1492.9757 (1491.6974) nleep/row_max_std 47.2599 (51.2969) nleep/row_min_mean 1466.6743 (1466.5108) lr 1.6374e-03 eta 0:09:51
epoch [16/50] batch [120/176] time 0.086 (0.100) data 0.000 (0.004) loss 1.7046 (1.8730) teacher_loss 0.1337 (0.2770) loss_zs_kd 0.0247 (0.0308) loss_oracle 0.5767 (0.6635) kd_loss 1.2703 (1.2488) acc 96.8750 (90.4427) gate/entropy 1.0314 (1.0300) gate/usage_max 0.5032 (0.5042) gate/usage_min 0.2098 (0.2070) gate/usage_std 0.1242 (0.1254) teacher/entropy 0.0881 (0.0797) teacher/usage_max 0.7274 (0.6690) teacher/usage_min 0.0627 (0.0885) teacher/usage_std 0.2851 (0.2507) nleep/row_max_mean 1494.1090 (1492.0439) nleep/row_max_std 50.1435 (50.5144) nleep/row_min_mean 1469.3000 (1467.0311) lr 1.6374e-03 eta 0:10:04
epoch [16/50] batch [140/176] time 0.089 (0.099) data 0.000 (0.003) loss 1.8582 (1.8743) teacher_loss 0.2564 (0.2735) loss_zs_kd 0.0302 (0.0313) loss_oracle 0.5850 (0.6658) kd_loss 1.2941 (1.2523) acc 87.5000 (90.5134) gate/entropy 1.0318 (1.0302) gate/usage_max 0.5030 (0.5040) gate/usage_min 0.2106 (0.2074) gate/usage_std 0.1239 (0.1252) teacher/entropy 0.1077 (0.0785) teacher/usage_max 0.7959 (0.6738) teacher/usage_min 0.0381 (0.0871) teacher/usage_std 0.3313 (0.2534) nleep/row_max_mean 1490.7920 (1491.8693) nleep/row_max_std 56.6195 (50.0183) nleep/row_min_mean 1470.5425 (1467.0751) lr 1.6374e-03 eta 0:09:53
epoch [16/50] batch [160/176] time 0.092 (0.097) data 0.000 (0.003) loss 2.0389 (1.8803) teacher_loss 0.4464 (0.2774) loss_zs_kd 0.0337 (0.0314) loss_oracle 0.6107 (0.6645) kd_loss 1.2703 (1.2550) acc 84.3750 (90.4883) gate/entropy 1.0326 (1.0305) gate/usage_max 0.5021 (0.5038) gate/usage_min 0.2114 (0.2079) gate/usage_std 0.1232 (0.1249) teacher/entropy 0.0447 (0.0770) teacher/usage_max 0.6627 (0.6753) teacher/usage_min 0.0942 (0.0877) teacher/usage_std 0.2407 (0.2540) nleep/row_max_mean 1495.5553 (1491.2870) nleep/row_max_std 52.2643 (50.1765) nleep/row_min_mean 1472.7200 (1466.8397) lr 1.6374e-03 eta 0:09:44
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,132
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 90.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,869
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 61.9%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.3%, epoch: 15 *******
epoch [17/50] batch [20/176] time 0.090 (0.104) data 0.000 (0.014) loss 1.8233 (1.8683) teacher_loss 0.2117 (0.2782) loss_zs_kd 0.0425 (0.0349) loss_oracle 0.6835 (0.6600) kd_loss 1.2486 (1.2427) acc 84.3750 (89.5312) gate/entropy 1.0341 (1.0339) gate/usage_max 0.5003 (0.5005) gate/usage_min 0.2131 (0.2128) gate/usage_std 0.1218 (0.1220) teacher/entropy 0.0621 (0.0682) teacher/usage_max 0.6625 (0.6609) teacher/usage_min 0.0945 (0.0940) teacher/usage_std 0.2405 (0.2416) nleep/row_max_mean 1481.7932 (1486.8570) nleep/row_max_std 66.2218 (53.8379) nleep/row_min_mean 1461.1188 (1465.6353) lr 1.5878e-03 eta 0:10:20
epoch [17/50] batch [40/176] time 0.102 (0.099) data 0.000 (0.007) loss 1.7929 (1.8429) teacher_loss 0.1537 (0.2551) loss_zs_kd 0.0418 (0.0329) loss_oracle 0.6412 (0.6534) kd_loss 1.2977 (1.2447) acc 87.5000 (91.1719) gate/entropy 1.0351 (1.0343) gate/usage_max 0.4989 (0.4999) gate/usage_min 0.2140 (0.2133) gate/usage_std 0.1208 (0.1216) teacher/entropy 0.0448 (0.0666) teacher/usage_max 0.6986 (0.6589) teacher/usage_min 0.1016 (0.1001) teacher/usage_std 0.2614 (0.2402) nleep/row_max_mean 1476.8033 (1485.6774) nleep/row_max_std 57.3824 (54.4154) nleep/row_min_mean 1456.2256 (1464.6350) lr 1.5878e-03 eta 0:09:47
epoch [17/50] batch [60/176] time 0.089 (0.099) data 0.001 (0.005) loss 1.7783 (1.8013) teacher_loss 0.2839 (0.2352) loss_zs_kd 0.0718 (0.0336) loss_oracle 0.6338 (0.6447) kd_loss 1.1415 (1.2270) acc 90.6250 (91.9792) gate/entropy 1.0358 (1.0347) gate/usage_max 0.4979 (0.4994) gate/usage_min 0.2146 (0.2136) gate/usage_std 0.1201 (0.1212) teacher/entropy 0.1422 (0.0714) teacher/usage_max 0.6263 (0.6421) teacher/usage_min 0.1085 (0.1052) teacher/usage_std 0.2168 (0.2313) nleep/row_max_mean 1492.4243 (1487.7196) nleep/row_max_std 50.0616 (53.4238) nleep/row_min_mean 1475.6290 (1466.7911) lr 1.5878e-03 eta 0:09:46
epoch [17/50] batch [80/176] time 0.097 (0.099) data 0.000 (0.004) loss 1.6139 (1.7849) teacher_loss 0.0926 (0.2287) loss_zs_kd 0.0352 (0.0335) loss_oracle 0.6465 (0.6586) kd_loss 1.1805 (1.2101) acc 100.0000 (92.2266) gate/entropy 1.0368 (1.0352) gate/usage_max 0.4967 (0.4988) gate/usage_min 0.2154 (0.2140) gate/usage_std 0.1192 (0.1208) teacher/entropy 0.0440 (0.0735) teacher/usage_max 0.5047 (0.6213) teacher/usage_min 0.1871 (0.1129) teacher/usage_std 0.1308 (0.2183) nleep/row_max_mean 1478.9956 (1487.4455) nleep/row_max_std 61.6251 (52.8629) nleep/row_min_mean 1458.5728 (1466.7944) lr 1.5878e-03 eta 0:09:41
epoch [17/50] batch [100/176] time 0.095 (0.098) data 0.000 (0.003) loss 1.6972 (1.7840) teacher_loss 0.1863 (0.2317) loss_zs_kd 0.0425 (0.0328) loss_oracle 0.7790 (0.6802) kd_loss 1.1002 (1.1958) acc 93.7500 (92.0938) gate/entropy 1.0378 (1.0356) gate/usage_max 0.4950 (0.4982) gate/usage_min 0.2160 (0.2144) gate/usage_std 0.1181 (0.1203) teacher/entropy 0.0793 (0.0784) teacher/usage_max 0.4499 (0.6097) teacher/usage_min 0.1924 (0.1165) teacher/usage_std 0.1065 (0.2117) nleep/row_max_mean 1497.4474 (1487.8810) nleep/row_max_std 43.3932 (52.4484) nleep/row_min_mean 1478.1733 (1467.3552) lr 1.5878e-03 eta 0:09:35
epoch [17/50] batch [120/176] time 0.099 (0.098) data 0.000 (0.003) loss 1.6068 (1.7770) teacher_loss 0.2200 (0.2351) loss_zs_kd 0.0276 (0.0332) loss_oracle 0.6366 (0.6907) kd_loss 1.0547 (1.1799) acc 96.8750 (91.8750) gate/entropy 1.0389 (1.0361) gate/usage_max 0.4933 (0.4975) gate/usage_min 0.2166 (0.2147) gate/usage_std 0.1170 (0.1198) teacher/entropy 0.0450 (0.0820) teacher/usage_max 0.5201 (0.5978) teacher/usage_min 0.0034 (0.1176) teacher/usage_std 0.2340 (0.2057) nleep/row_max_mean 1506.3879 (1488.4117) nleep/row_max_std 41.8490 (51.5682) nleep/row_min_mean 1485.8689 (1468.1932) lr 1.5878e-03 eta 0:09:33
epoch [17/50] batch [140/176] time 0.091 (0.097) data 0.000 (0.002) loss 1.7762 (1.7697) teacher_loss 0.2012 (0.2364) loss_zs_kd 0.0294 (0.0337) loss_oracle 0.8513 (0.7060) kd_loss 1.1347 (1.1634) acc 96.8750 (91.7411) gate/entropy 1.0400 (1.0366) gate/usage_max 0.4914 (0.4967) gate/usage_min 0.2170 (0.2150) gate/usage_std 0.1159 (0.1193) teacher/entropy 0.1201 (0.0873) teacher/usage_max 0.5978 (0.5800) teacher/usage_min 0.1062 (0.1261) teacher/usage_std 0.2024 (0.1947) nleep/row_max_mean 1499.2568 (1488.6788) nleep/row_max_std 58.2557 (50.9385) nleep/row_min_mean 1483.7812 (1468.6996) lr 1.5878e-03 eta 0:09:28
epoch [17/50] batch [160/176] time 0.099 (0.097) data 0.000 (0.002) loss 2.0127 (1.7751) teacher_loss 0.4513 (0.2460) loss_zs_kd 0.0674 (0.0339) loss_oracle 0.8652 (0.7170) kd_loss 1.0952 (1.1536) acc 81.2500 (91.5039) gate/entropy 1.0411 (1.0371) gate/usage_max 0.4895 (0.4959) gate/usage_min 0.2174 (0.2153) gate/usage_std 0.1147 (0.1188) teacher/entropy 0.1000 (0.0900) teacher/usage_max 0.4865 (0.5705) teacher/usage_min 0.1671 (0.1286) teacher/usage_std 0.1307 (0.1892) nleep/row_max_mean 1489.4476 (1488.5837) nleep/row_max_std 57.2633 (50.9738) nleep/row_min_mean 1470.3959 (1468.8244) lr 1.5878e-03 eta 0:09:25
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,156
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 90.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,867
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 61.2%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.3%, epoch: 15 *******
epoch [18/50] batch [20/176] time 0.076 (0.122) data 0.000 (0.014) loss 1.8300 (1.7299) teacher_loss 0.2697 (0.2293) loss_zs_kd 0.0506 (0.0418) loss_oracle 0.9619 (0.8284) kd_loss 1.0541 (1.0655) acc 87.5000 (92.6562) gate/entropy 1.0436 (1.0427) gate/usage_max 0.4851 (0.4866) gate/usage_min 0.2182 (0.2178) gate/usage_std 0.1120 (0.1129) teacher/entropy 0.0979 (0.1040) teacher/usage_max 0.3539 (0.4829) teacher/usage_min 0.3001 (0.1806) teacher/usage_std 0.0237 (0.1297) nleep/row_max_mean 1471.1312 (1489.1760) nleep/row_max_std 51.2625 (50.9101) nleep/row_min_mean 1454.3672 (1471.0891) lr 1.5358e-03 eta 0:11:47
epoch [18/50] batch [40/176] time 0.083 (0.103) data 0.000 (0.007) loss 1.7077 (1.7302) teacher_loss 0.1704 (0.2266) loss_zs_kd 0.0268 (0.0377) loss_oracle 0.8279 (0.8378) kd_loss 1.1099 (1.0659) acc 96.8750 (92.5781) gate/entropy 1.0447 (1.0433) gate/usage_max 0.4830 (0.4855) gate/usage_min 0.2185 (0.2180) gate/usage_std 0.1108 (0.1123) teacher/entropy 0.1312 (0.1105) teacher/usage_max 0.5511 (0.4805) teacher/usage_min 0.1583 (0.1844) teacher/usage_std 0.1632 (0.1266) nleep/row_max_mean 1468.6233 (1486.4318) nleep/row_max_std 58.7206 (51.8388) nleep/row_min_mean 1452.5342 (1468.8425) lr 1.5358e-03 eta 0:09:56
epoch [18/50] batch [60/176] time 0.076 (0.097) data 0.001 (0.005) loss 1.6963 (1.7465) teacher_loss 0.2153 (0.2361) loss_zs_kd 0.0421 (0.0371) loss_oracle 0.9667 (0.8627) kd_loss 0.9765 (1.0605) acc 93.7500 (92.0833) gate/entropy 1.0457 (1.0439) gate/usage_max 0.4808 (0.4844) gate/usage_min 0.2183 (0.2181) gate/usage_std 0.1096 (0.1116) teacher/entropy 0.1170 (0.1111) teacher/usage_max 0.4294 (0.4736) teacher/usage_min 0.2797 (0.1961) teacher/usage_std 0.0681 (0.1187) nleep/row_max_mean 1486.6259 (1486.2942) nleep/row_max_std 48.5638 (52.1878) nleep/row_min_mean 1467.3169 (1468.6300) lr 1.5358e-03 eta 0:09:16
epoch [18/50] batch [80/176] time 0.093 (0.094) data 0.000 (0.004) loss 1.7081 (1.7508) teacher_loss 0.2556 (0.2420) loss_zs_kd 0.0439 (0.0369) loss_oracle 0.9039 (0.8692) kd_loss 0.9787 (1.0558) acc 90.6250 (91.7969) gate/entropy 1.0467 (1.0445) gate/usage_max 0.4785 (0.4832) gate/usage_min 0.2182 (0.2181) gate/usage_std 0.1083 (0.1110) teacher/entropy 0.1874 (0.1174) teacher/usage_max 0.4688 (0.4661) teacher/usage_min 0.1334 (0.2022) teacher/usage_std 0.1443 (0.1125) nleep/row_max_mean 1499.4230 (1486.6164) nleep/row_max_std 44.3796 (52.2113) nleep/row_min_mean 1483.7720 (1469.1126) lr 1.5358e-03 eta 0:09:01
epoch [18/50] batch [100/176] time 0.069 (0.094) data 0.000 (0.003) loss 1.6584 (1.7495) teacher_loss 0.1891 (0.2311) loss_zs_kd 0.0600 (0.0386) loss_oracle 0.8901 (0.8751) kd_loss 0.9943 (1.0616) acc 93.7500 (92.3125) gate/entropy 1.0483 (1.0451) gate/usage_max 0.4749 (0.4818) gate/usage_min 0.2181 (0.2181) gate/usage_std 0.1065 (0.1102) teacher/entropy 0.1041 (0.1122) teacher/usage_max 0.4097 (0.4593) teacher/usage_min 0.2812 (0.2086) teacher/usage_std 0.0552 (0.1072) nleep/row_max_mean 1492.6707 (1486.9413) nleep/row_max_std 43.3433 (51.3514) nleep/row_min_mean 1474.8584 (1469.3059) lr 1.5358e-03 eta 0:08:55
epoch [18/50] batch [120/176] time 0.095 (0.094) data 0.000 (0.003) loss 1.7671 (1.7420) teacher_loss 0.2839 (0.2251) loss_zs_kd 0.0428 (0.0378) loss_oracle 0.6817 (0.8721) kd_loss 1.1210 (1.0619) acc 84.3750 (92.4479) gate/entropy 1.0498 (1.0458) gate/usage_max 0.4713 (0.4804) gate/usage_min 0.2180 (0.2181) gate/usage_std 0.1047 (0.1094) teacher/entropy 0.0470 (0.1112) teacher/usage_max 0.3652 (0.4573) teacher/usage_min 0.3129 (0.2131) teacher/usage_std 0.0228 (0.1044) nleep/row_max_mean 1478.1694 (1486.6486) nleep/row_max_std 49.1119 (51.1827) nleep/row_min_mean 1458.3289 (1468.7764) lr 1.5358e-03 eta 0:08:52
epoch [18/50] batch [140/176] time 0.086 (0.094) data 0.000 (0.002) loss 1.7244 (1.7334) teacher_loss 0.1492 (0.2255) loss_zs_kd 0.0207 (0.0376) loss_oracle 0.8456 (0.8598) kd_loss 1.1421 (1.0592) acc 93.7500 (92.5446) gate/entropy 1.0507 (1.0464) gate/usage_max 0.4688 (0.4789) gate/usage_min 0.2176 (0.2181) gate/usage_std 0.1035 (0.1086) teacher/entropy 0.0956 (0.1113) teacher/usage_max 0.4722 (0.4531) teacher/usage_min 0.2352 (0.2192) teacher/usage_std 0.1009 (0.1000) nleep/row_max_mean 1485.9589 (1486.8685) nleep/row_max_std 49.6494 (51.0870) nleep/row_min_mean 1468.5613 (1468.9331) lr 1.5358e-03 eta 0:08:51
epoch [18/50] batch [160/176] time 0.088 (0.094) data 0.000 (0.002) loss 1.7478 (1.7285) teacher_loss 0.2347 (0.2217) loss_zs_kd 0.0536 (0.0386) loss_oracle 0.8049 (0.8530) kd_loss 1.0839 (1.0610) acc 90.6250 (92.7344) gate/entropy 1.0522 (1.0471) gate/usage_max 0.4652 (0.4773) gate/usage_min 0.2178 (0.2181) gate/usage_std 0.1017 (0.1079) teacher/entropy 0.1150 (0.1107) teacher/usage_max 0.3847 (0.4482) teacher/usage_min 0.2458 (0.2216) teacher/usage_std 0.0622 (0.0968) nleep/row_max_mean 1481.2512 (1487.2676) nleep/row_max_std 52.8984 (50.9322) nleep/row_min_mean 1463.1042 (1469.1527) lr 1.5358e-03 eta 0:08:50
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,143
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 90.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,896
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 61.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [19/50] batch [20/176] time 0.098 (0.120) data 0.000 (0.019) loss 1.7056 (1.6924) teacher_loss 0.1445 (0.1625) loss_zs_kd 0.0418 (0.0497) loss_oracle 0.8663 (0.8259) kd_loss 1.1071 (1.0921) acc 96.8750 (94.0625) gate/entropy 1.0540 (1.0536) gate/usage_max 0.4595 (0.4609) gate/usage_min 0.2172 (0.2175) gate/usage_std 0.0992 (0.0997) teacher/entropy 0.1124 (0.0848) teacher/usage_max 0.4638 (0.4399) teacher/usage_min 0.1632 (0.2299) teacher/usage_std 0.1258 (0.0900) nleep/row_max_mean 1484.5071 (1486.5331) nleep/row_max_std 60.5023 (53.3240) nleep/row_min_mean 1464.8965 (1466.5980) lr 1.4818e-03 eta 0:11:10
epoch [19/50] batch [40/176] time 0.092 (0.109) data 0.000 (0.009) loss 1.8094 (1.6884) teacher_loss 0.2031 (0.1637) loss_zs_kd 0.0527 (0.0462) loss_oracle 0.9275 (0.8152) kd_loss 1.1162 (1.0941) acc 93.7500 (94.2969) gate/entropy 1.0553 (1.0542) gate/usage_max 0.4558 (0.4591) gate/usage_min 0.2172 (0.2174) gate/usage_std 0.0975 (0.0989) teacher/entropy 0.0548 (0.0864) teacher/usage_max 0.5252 (0.4404) teacher/usage_min 0.1904 (0.2252) teacher/usage_std 0.1410 (0.0925) nleep/row_max_mean 1475.4563 (1486.0136) nleep/row_max_std 69.3197 (54.5586) nleep/row_min_mean 1454.0605 (1466.2498) lr 1.4818e-03 eta 0:10:07
epoch [19/50] batch [60/176] time 0.108 (0.106) data 0.001 (0.006) loss 1.6150 (1.6847) teacher_loss 0.0846 (0.1573) loss_zs_kd 0.0403 (0.0481) loss_oracle 0.8299 (0.8247) kd_loss 1.0952 (1.0910) acc 96.8750 (94.6354) gate/entropy 1.0563 (1.0548) gate/usage_max 0.4522 (0.4573) gate/usage_min 0.2168 (0.2173) gate/usage_std 0.0961 (0.0982) teacher/entropy 0.0361 (0.0841) teacher/usage_max 0.5590 (0.4508) teacher/usage_min 0.2188 (0.2222) teacher/usage_std 0.1596 (0.0980) nleep/row_max_mean 1488.7473 (1485.9318) nleep/row_max_std 51.0329 (54.5076) nleep/row_min_mean 1466.5952 (1465.7864) lr 1.4818e-03 eta 0:09:48
epoch [19/50] batch [80/176] time 0.091 (0.103) data 0.000 (0.005) loss 1.7287 (1.6879) teacher_loss 0.0903 (0.1571) loss_zs_kd 0.0543 (0.0474) loss_oracle 0.8418 (0.8188) kd_loss 1.1903 (1.0978) acc 93.7500 (94.7266) gate/entropy 1.0574 (1.0553) gate/usage_max 0.4486 (0.4555) gate/usage_min 0.2170 (0.2172) gate/usage_std 0.0946 (0.0974) teacher/entropy 0.0695 (0.0829) teacher/usage_max 0.4740 (0.4503) teacher/usage_min 0.0856 (0.2184) teacher/usage_std 0.1757 (0.0994) nleep/row_max_mean 1505.2056 (1486.2750) nleep/row_max_std 35.2929 (53.5467) nleep/row_min_mean 1483.6970 (1465.8744) lr 1.4818e-03 eta 0:09:30
epoch [19/50] batch [100/176] time 0.097 (0.101) data 0.000 (0.004) loss 1.5640 (1.6872) teacher_loss 0.1148 (0.1565) loss_zs_kd 0.0396 (0.0467) loss_oracle 0.7672 (0.8127) kd_loss 1.0458 (1.1010) acc 96.8750 (94.7812) gate/entropy 1.0584 (1.0559) gate/usage_max 0.4451 (0.4538) gate/usage_min 0.2168 (0.2172) gate/usage_std 0.0933 (0.0967) teacher/entropy 0.0184 (0.0808) teacher/usage_max 0.4346 (0.4493) teacher/usage_min 0.1879 (0.2133) teacher/usage_std 0.1054 (0.1012) nleep/row_max_mean 1500.9969 (1487.1633) nleep/row_max_std 46.7724 (53.7146) nleep/row_min_mean 1477.4491 (1466.4859) lr 1.4818e-03 eta 0:09:19
epoch [19/50] batch [120/176] time 0.120 (0.100) data 0.000 (0.003) loss 1.5799 (1.6806) teacher_loss 0.0205 (0.1470) loss_zs_kd 0.0332 (0.0459) loss_oracle 0.7851 (0.8075) kd_loss 1.1502 (1.1069) acc 100.0000 (95.1823) gate/entropy 1.0595 (1.0564) gate/usage_max 0.4413 (0.4520) gate/usage_min 0.2172 (0.2171) gate/usage_std 0.0917 (0.0960) teacher/entropy 0.0335 (0.0765) teacher/usage_max 0.4692 (0.4531) teacher/usage_min 0.1837 (0.2092) teacher/usage_std 0.1170 (0.1046) nleep/row_max_mean 1469.5338 (1487.5996) nleep/row_max_std 58.3039 (53.5273) nleep/row_min_mean 1448.2362 (1466.5958) lr 1.4818e-03 eta 0:09:12
epoch [19/50] batch [140/176] time 0.094 (0.101) data 0.000 (0.003) loss 1.9211 (1.6778) teacher_loss 0.4594 (0.1457) loss_zs_kd 0.0549 (0.0460) loss_oracle 0.7048 (0.8034) kd_loss 1.0818 (1.1074) acc 90.6250 (95.2679) gate/entropy 1.0604 (1.0569) gate/usage_max 0.4377 (0.4502) gate/usage_min 0.2171 (0.2171) gate/usage_std 0.0905 (0.0953) teacher/entropy 0.0744 (0.0755) teacher/usage_max 0.3846 (0.4565) teacher/usage_min 0.2542 (0.2081) teacher/usage_std 0.0568 (0.1064) nleep/row_max_mean 1505.7756 (1487.7966) nleep/row_max_std 33.8717 (53.7060) nleep/row_min_mean 1481.5706 (1466.5454) lr 1.4818e-03 eta 0:09:16
epoch [19/50] batch [160/176] time 0.085 (0.100) data 0.000 (0.003) loss 1.5499 (1.6736) teacher_loss 0.0919 (0.1429) loss_zs_kd 0.0989 (0.0462) loss_oracle 0.7444 (0.7971) kd_loss 1.0363 (1.1090) acc 96.8750 (95.4102) gate/entropy 1.0612 (1.0574) gate/usage_max 0.4344 (0.4484) gate/usage_min 0.2172 (0.2171) gate/usage_std 0.0893 (0.0946) teacher/entropy 0.0505 (0.0725) teacher/usage_max 0.5440 (0.4579) teacher/usage_min 0.1924 (0.2063) teacher/usage_std 0.1518 (0.1078) nleep/row_max_mean 1489.4302 (1487.8610) nleep/row_max_std 49.3474 (53.6293) nleep/row_min_mean 1466.1504 (1466.3172) lr 1.4818e-03 eta 0:09:08
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,151
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 90.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,875
* accuracy: 70.6%
* error: 29.4%
* macro_f1: 61.5%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [20/50] batch [20/176] time 0.097 (0.114) data 0.000 (0.017) loss 1.5661 (1.6069) teacher_loss 0.0672 (0.1177) loss_zs_kd 0.0638 (0.0560) loss_oracle 0.6789 (0.7513) kd_loss 1.1276 (1.0855) acc 100.0000 (95.7812) gate/entropy 1.0624 (1.0620) gate/usage_max 0.4285 (0.4301) gate/usage_min 0.2172 (0.2171) gate/usage_std 0.0875 (0.0881) teacher/entropy 0.0220 (0.0502) teacher/usage_max 0.3796 (0.5259) teacher/usage_min 0.2797 (0.1955) teacher/usage_std 0.0411 (0.1430) nleep/row_max_mean 1483.8535 (1489.4709) nleep/row_max_std 50.4593 (50.9739) nleep/row_min_mean 1460.6346 (1466.0629) lr 1.4258e-03 eta 0:10:17
epoch [20/50] batch [40/176] time 0.098 (0.103) data 0.000 (0.009) loss 1.5825 (1.6134) teacher_loss 0.0751 (0.1195) loss_zs_kd 0.0403 (0.0510) loss_oracle 0.7554 (0.7581) kd_loss 1.1096 (1.0893) acc 96.8750 (96.3281) gate/entropy 1.0628 (1.0623) gate/usage_max 0.4254 (0.4285) gate/usage_min 0.2168 (0.2170) gate/usage_std 0.0869 (0.0877) teacher/entropy 0.0343 (0.0477) teacher/usage_max 0.5931 (0.5109) teacher/usage_min 0.1304 (0.1896) teacher/usage_std 0.1931 (0.1377) nleep/row_max_mean 1498.5916 (1488.3546) nleep/row_max_std 49.2598 (52.6271) nleep/row_min_mean 1475.7406 (1464.9564) lr 1.4258e-03 eta 0:09:17
epoch [20/50] batch [60/176] time 0.085 (0.097) data 0.001 (0.006) loss 1.5171 (1.5971) teacher_loss 0.0504 (0.1106) loss_zs_kd 0.0773 (0.0533) loss_oracle 0.7411 (0.7446) kd_loss 1.0575 (1.0876) acc 100.0000 (96.6667) gate/entropy 1.0631 (1.0625) gate/usage_max 0.4220 (0.4268) gate/usage_min 0.2164 (0.2169) gate/usage_std 0.0863 (0.0873) teacher/entropy 0.0181 (0.0457) teacher/usage_max 0.5627 (0.5232) teacher/usage_min 0.1896 (0.1814) teacher/usage_std 0.1639 (0.1464) nleep/row_max_mean 1482.5840 (1488.0096) nleep/row_max_std 52.5709 (53.5893) nleep/row_min_mean 1457.6807 (1464.7020) lr 1.4258e-03 eta 0:08:42
epoch [20/50] batch [80/176] time 0.084 (0.095) data 0.000 (0.004) loss 1.4468 (1.6015) teacher_loss 0.0166 (0.1213) loss_zs_kd 0.0436 (0.0549) loss_oracle 0.7339 (0.7353) kd_loss 1.0415 (1.0851) acc 100.0000 (96.4844) gate/entropy 1.0635 (1.0628) gate/usage_max 0.4191 (0.4252) gate/usage_min 0.2163 (0.2168) gate/usage_std 0.0857 (0.0869) teacher/entropy 0.0200 (0.0446) teacher/usage_max 0.6211 (0.5177) teacher/usage_min 0.1584 (0.1883) teacher/usage_std 0.2050 (0.1417) nleep/row_max_mean 1492.2739 (1487.2967) nleep/row_max_std 58.7934 (54.4962) nleep/row_min_mean 1466.9639 (1464.0075) lr 1.4258e-03 eta 0:08:29
epoch [20/50] batch [100/176] time 0.083 (0.094) data 0.000 (0.004) loss 1.5503 (1.5891) teacher_loss 0.0403 (0.1140) loss_zs_kd 0.0402 (0.0541) loss_oracle 0.7970 (0.7240) kd_loss 1.0914 (1.0861) acc 100.0000 (96.7500) gate/entropy 1.0640 (1.0630) gate/usage_max 0.4163 (0.4237) gate/usage_min 0.2166 (0.2167) gate/usage_std 0.0850 (0.0866) teacher/entropy 0.0325 (0.0438) teacher/usage_max 0.5311 (0.5075) teacher/usage_min 0.1926 (0.1939) teacher/usage_std 0.1440 (0.1349) nleep/row_max_mean 1468.4053 (1486.1281) nleep/row_max_std 66.9900 (55.2572) nleep/row_min_mean 1446.6654 (1462.9983) lr 1.4258e-03 eta 0:08:21
epoch [20/50] batch [120/176] time 0.088 (0.093) data 0.000 (0.003) loss 1.5582 (1.5813) teacher_loss 0.2011 (0.1133) loss_zs_kd 0.0634 (0.0539) loss_oracle 0.5529 (0.7190) kd_loss 1.0491 (1.0816) acc 96.8750 (96.8490) gate/entropy 1.0644 (1.0632) gate/usage_max 0.4135 (0.4222) gate/usage_min 0.2167 (0.2167) gate/usage_std 0.0844 (0.0863) teacher/entropy 0.0900 (0.0476) teacher/usage_max 0.3390 (0.5023) teacher/usage_min 0.3262 (0.1950) teacher/usage_std 0.0053 (0.1323) nleep/row_max_mean 1475.5002 (1485.0639) nleep/row_max_std 60.4650 (55.1454) nleep/row_min_mean 1454.0424 (1462.0386) lr 1.4258e-03 eta 0:08:15
epoch [20/50] batch [140/176] time 0.086 (0.093) data 0.000 (0.003) loss 1.4900 (1.5760) teacher_loss 0.0811 (0.1104) loss_zs_kd 0.0812 (0.0539) loss_oracle 0.6336 (0.7143) kd_loss 1.0516 (1.0816) acc 96.8750 (96.9196) gate/entropy 1.0646 (1.0634) gate/usage_max 0.4109 (0.4208) gate/usage_min 0.2165 (0.2167) gate/usage_std 0.0841 (0.0860) teacher/entropy 0.0471 (0.0465) teacher/usage_max 0.4489 (0.4994) teacher/usage_min 0.2595 (0.1981) teacher/usage_std 0.0828 (0.1296) nleep/row_max_mean 1478.7134 (1484.7944) nleep/row_max_std 55.9670 (54.6574) nleep/row_min_mean 1454.2705 (1461.7098) lr 1.4258e-03 eta 0:08:13
epoch [20/50] batch [160/176] time 0.093 (0.093) data 0.000 (0.002) loss 1.6387 (1.5746) teacher_loss 0.0577 (0.1125) loss_zs_kd 0.0392 (0.0534) loss_oracle 0.8269 (0.7131) kd_loss 1.1479 (1.0789) acc 100.0000 (96.8945) gate/entropy 1.0650 (1.0636) gate/usage_max 0.4086 (0.4194) gate/usage_min 0.2169 (0.2167) gate/usage_std 0.0835 (0.0857) teacher/entropy 0.0430 (0.0472) teacher/usage_max 0.4347 (0.4961) teacher/usage_min 0.1563 (0.1990) teacher/usage_std 0.1256 (0.1279) nleep/row_max_mean 1470.9338 (1484.3458) nleep/row_max_std 65.1252 (54.7041) nleep/row_min_mean 1446.1892 (1461.2761) lr 1.4258e-03 eta 0:08:10
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,169
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,812
* accuracy: 68.2%
* error: 31.8%
* macro_f1: 60.2%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [21/50] batch [20/176] time 0.157 (0.132) data 0.001 (0.017) loss 1.6387 (1.5768) teacher_loss 0.0844 (0.1150) loss_zs_kd 0.0855 (0.0633) loss_oracle 0.7965 (0.7301) kd_loss 1.1133 (1.0651) acc 96.8750 (96.0938) gate/entropy 1.0652 (1.0652) gate/usage_max 0.4038 (0.4051) gate/usage_min 0.2167 (0.2168) gate/usage_std 0.0831 (0.0831) teacher/entropy 0.0159 (0.0470) teacher/usage_max 0.5039 (0.5088) teacher/usage_min 0.1882 (0.1959) teacher/usage_std 0.1302 (0.1333) nleep/row_max_mean 1488.8345 (1478.3584) nleep/row_max_std 55.0170 (56.3924) nleep/row_min_mean 1461.9868 (1453.6912) lr 1.3681e-03 eta 0:11:33
epoch [21/50] batch [40/176] time 0.086 (0.113) data 0.000 (0.009) loss 1.6642 (1.5660) teacher_loss 0.2788 (0.1129) loss_zs_kd 0.0754 (0.0662) loss_oracle 0.6947 (0.7167) kd_loss 1.0004 (1.0617) acc 93.7500 (96.7188) gate/entropy 1.0653 (1.0653) gate/usage_max 0.4013 (0.4037) gate/usage_min 0.2165 (0.2168) gate/usage_std 0.0830 (0.0830) teacher/entropy 0.0519 (0.0414) teacher/usage_max 0.5767 (0.5193) teacher/usage_min 0.1813 (0.1972) teacher/usage_std 0.1739 (0.1389) nleep/row_max_mean 1478.9321 (1477.7789) nleep/row_max_std 66.9154 (57.8864) nleep/row_min_mean 1454.0991 (1452.9458) lr 1.3681e-03 eta 0:09:50
epoch [21/50] batch [60/176] time 0.089 (0.106) data 0.001 (0.006) loss 1.4730 (1.5475) teacher_loss 0.0221 (0.1003) loss_zs_kd 0.0536 (0.0631) loss_oracle 0.6649 (0.7082) kd_loss 1.0916 (1.0616) acc 100.0000 (97.1875) gate/entropy 1.0656 (1.0654) gate/usage_max 0.3983 (0.4024) gate/usage_min 0.2168 (0.2167) gate/usage_std 0.0826 (0.0829) teacher/entropy 0.0440 (0.0426) teacher/usage_max 0.3781 (0.5101) teacher/usage_min 0.2878 (0.2024) teacher/usage_std 0.0369 (0.1327) nleep/row_max_mean 1485.6611 (1479.4491) nleep/row_max_std 47.8673 (56.4744) nleep/row_min_mean 1459.4497 (1454.3595) lr 1.3681e-03 eta 0:09:10
epoch [21/50] batch [80/176] time 0.125 (0.103) data 0.000 (0.005) loss 1.5809 (1.5487) teacher_loss 0.1836 (0.1017) loss_zs_kd 0.0396 (0.0624) loss_oracle 0.7469 (0.7111) kd_loss 1.0040 (1.0602) acc 93.7500 (97.1484) gate/entropy 1.0657 (1.0654) gate/usage_max 0.3958 (0.4011) gate/usage_min 0.2169 (0.2167) gate/usage_std 0.0824 (0.0828) teacher/entropy 0.0203 (0.0405) teacher/usage_max 0.7812 (0.5253) teacher/usage_min 0.0843 (0.1940) teacher/usage_std 0.3174 (0.1433) nleep/row_max_mean 1481.4086 (1479.8456) nleep/row_max_std 56.0550 (55.9378) nleep/row_min_mean 1455.2146 (1454.3951) lr 1.3681e-03 eta 0:08:55
epoch [21/50] batch [100/176] time 0.091 (0.102) data 0.000 (0.004) loss 1.4613 (1.5467) teacher_loss 0.0990 (0.1028) loss_zs_kd 0.0584 (0.0606) loss_oracle 0.5891 (0.7047) kd_loss 1.0385 (1.0612) acc 100.0000 (97.1875) gate/entropy 1.0656 (1.0655) gate/usage_max 0.3929 (0.3997) gate/usage_min 0.2167 (0.2167) gate/usage_std 0.0825 (0.0828) teacher/entropy 0.0283 (0.0386) teacher/usage_max 0.4633 (0.5225) teacher/usage_min 0.2186 (0.1918) teacher/usage_std 0.1005 (0.1430) nleep/row_max_mean 1491.8322 (1479.8772) nleep/row_max_std 42.4921 (55.4968) nleep/row_min_mean 1466.2363 (1454.3011) lr 1.3681e-03 eta 0:08:46
epoch [21/50] batch [120/176] time 0.093 (0.101) data 0.001 (0.003) loss 1.3696 (1.5481) teacher_loss 0.0403 (0.1067) loss_zs_kd 0.0291 (0.0590) loss_oracle 0.6548 (0.7034) kd_loss 0.9874 (1.0603) acc 100.0000 (97.1094) gate/entropy 1.0657 (1.0655) gate/usage_max 0.3930 (0.3985) gate/usage_min 0.2169 (0.2168) gate/usage_std 0.0823 (0.0827) teacher/entropy 0.0886 (0.0389) teacher/usage_max 0.3831 (0.5225) teacher/usage_min 0.2350 (0.1913) teacher/usage_std 0.0695 (0.1433) nleep/row_max_mean 1487.2434 (1480.0358) nleep/row_max_std 50.3842 (55.1500) nleep/row_min_mean 1460.0869 (1454.3808) lr 1.3681e-03 eta 0:08:39
epoch [21/50] batch [140/176] time 0.095 (0.100) data 0.000 (0.003) loss 1.4517 (1.5444) teacher_loss 0.0430 (0.1046) loss_zs_kd 0.0597 (0.0581) loss_oracle 0.6081 (0.7022) kd_loss 1.0748 (1.0597) acc 100.0000 (97.0982) gate/entropy 1.0659 (1.0655) gate/usage_max 0.3952 (0.3978) gate/usage_min 0.2172 (0.2168) gate/usage_std 0.0822 (0.0827) teacher/entropy 0.0505 (0.0387) teacher/usage_max 0.4434 (0.5225) teacher/usage_min 0.2362 (0.1913) teacher/usage_std 0.0851 (0.1433) nleep/row_max_mean 1488.4680 (1480.6319) nleep/row_max_std 39.1189 (54.6701) nleep/row_min_mean 1464.1165 (1455.0383) lr 1.3681e-03 eta 0:08:31
epoch [21/50] batch [160/176] time 0.095 (0.099) data 0.000 (0.002) loss 1.5229 (1.5403) teacher_loss 0.0807 (0.1014) loss_zs_kd 0.0461 (0.0574) loss_oracle 0.7602 (0.7026) kd_loss 1.0391 (1.0589) acc 96.8750 (97.2070) gate/entropy 1.0657 (1.0656) gate/usage_max 0.3982 (0.3977) gate/usage_min 0.2169 (0.2168) gate/usage_std 0.0825 (0.0826) teacher/entropy 0.0286 (0.0380) teacher/usage_max 0.6255 (0.5277) teacher/usage_min 0.1405 (0.1882) teacher/usage_std 0.2101 (0.1468) nleep/row_max_mean 1481.0409 (1480.4787) nleep/row_max_std 58.8348 (54.8722) nleep/row_min_mean 1454.3054 (1454.8464) lr 1.3681e-03 eta 0:08:27
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,154
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 91.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,782
* accuracy: 67.1%
* error: 32.9%
* macro_f1: 60.3%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [22/50] batch [20/176] time 0.092 (0.111) data 0.000 (0.016) loss 1.4858 (1.5207) teacher_loss 0.0625 (0.0991) loss_zs_kd 0.0564 (0.0602) loss_oracle 0.7146 (0.6850) kd_loss 1.0378 (1.0491) acc 100.0000 (97.5000) gate/entropy 1.0657 (1.0658) gate/usage_max 0.4022 (0.4010) gate/usage_min 0.2173 (0.2174) gate/usage_std 0.0825 (0.0824) teacher/entropy 0.0133 (0.0367) teacher/usage_max 0.6559 (0.5370) teacher/usage_min 0.1287 (0.1832) teacher/usage_std 0.2308 (0.1532) nleep/row_max_mean 1490.1404 (1481.6198) nleep/row_max_std 46.9413 (54.0084) nleep/row_min_mean 1463.7634 (1456.3025) lr 1.3090e-03 eta 0:09:24
epoch [22/50] batch [40/176] time 0.089 (0.102) data 0.000 (0.008) loss 1.5039 (1.5223) teacher_loss 0.0869 (0.1054) loss_zs_kd 0.0583 (0.0565) loss_oracle 0.6989 (0.6754) kd_loss 1.0384 (1.0509) acc 96.8750 (97.4219) gate/entropy 1.0659 (1.0658) gate/usage_max 0.4042 (0.4022) gate/usage_min 0.2178 (0.2175) gate/usage_std 0.0824 (0.0824) teacher/entropy 0.0117 (0.0338) teacher/usage_max 0.6545 (0.5357) teacher/usage_min 0.1259 (0.1795) teacher/usage_std 0.2303 (0.1539) nleep/row_max_mean 1472.9803 (1480.7379) nleep/row_max_std 43.9996 (55.0773) nleep/row_min_mean 1449.2465 (1455.3557) lr 1.3090e-03 eta 0:08:37
epoch [22/50] batch [60/176] time 0.091 (0.099) data 0.001 (0.005) loss 1.6075 (1.5143) teacher_loss 0.1863 (0.1017) loss_zs_kd 0.0520 (0.0541) loss_oracle 0.7058 (0.6722) kd_loss 1.0423 (1.0494) acc 90.6250 (97.0833) gate/entropy 1.0658 (1.0658) gate/usage_max 0.4065 (0.4033) gate/usage_min 0.2181 (0.2176) gate/usage_std 0.0825 (0.0825) teacher/entropy 0.0262 (0.0368) teacher/usage_max 0.4376 (0.5282) teacher/usage_min 0.2280 (0.1842) teacher/usage_std 0.0856 (0.1489) nleep/row_max_mean 1479.5764 (1479.8601) nleep/row_max_std 55.5934 (54.9375) nleep/row_min_mean 1454.1210 (1454.6084) lr 1.3090e-03 eta 0:08:18
epoch [22/50] batch [80/176] time 0.096 (0.098) data 0.000 (0.004) loss 1.5540 (1.5174) teacher_loss 0.1938 (0.1086) loss_zs_kd 0.0689 (0.0555) loss_oracle 0.6977 (0.6663) kd_loss 0.9769 (1.0479) acc 93.7500 (96.8359) gate/entropy 1.0656 (1.0658) gate/usage_max 0.4084 (0.4043) gate/usage_min 0.2180 (0.2177) gate/usage_std 0.0828 (0.0825) teacher/entropy 0.0651 (0.0379) teacher/usage_max 0.6595 (0.5208) teacher/usage_min 0.1251 (0.1886) teacher/usage_std 0.2335 (0.1432) nleep/row_max_mean 1476.9487 (1479.4521) nleep/row_max_std 53.7941 (54.4374) nleep/row_min_mean 1452.7332 (1454.3436) lr 1.3090e-03 eta 0:08:10
epoch [22/50] batch [100/176] time 0.094 (0.097) data 0.000 (0.003) loss 1.6419 (1.5069) teacher_loss 0.1769 (0.1034) loss_zs_kd 0.0612 (0.0541) loss_oracle 0.6895 (0.6613) kd_loss 1.0896 (1.0458) acc 93.7500 (97.0938) gate/entropy 1.0658 (1.0657) gate/usage_max 0.4103 (0.4053) gate/usage_min 0.2186 (0.2178) gate/usage_std 0.0827 (0.0826) teacher/entropy 0.0507 (0.0397) teacher/usage_max 0.4542 (0.5159) teacher/usage_min 0.1751 (0.1919) teacher/usage_std 0.1169 (0.1394) nleep/row_max_mean 1465.2241 (1479.5105) nleep/row_max_std 50.5297 (53.9945) nleep/row_min_mean 1442.9628 (1454.6915) lr 1.3090e-03 eta 0:08:06
epoch [22/50] batch [120/176] time 0.094 (0.096) data 0.000 (0.003) loss 1.4912 (1.5050) teacher_loss 0.1666 (0.1045) loss_zs_kd 0.0515 (0.0546) loss_oracle 0.6142 (0.6622) kd_loss 0.9917 (1.0421) acc 90.6250 (96.9271) gate/entropy 1.0655 (1.0657) gate/usage_max 0.4124 (0.4064) gate/usage_min 0.2185 (0.2179) gate/usage_std 0.0831 (0.0826) teacher/entropy 0.0863 (0.0411) teacher/usage_max 0.5199 (0.5175) teacher/usage_min 0.2131 (0.1909) teacher/usage_std 0.1337 (0.1406) nleep/row_max_mean 1472.9091 (1479.2420) nleep/row_max_std 54.2791 (53.6051) nleep/row_min_mean 1447.9866 (1454.5547) lr 1.3090e-03 eta 0:07:59
epoch [22/50] batch [140/176] time 0.084 (0.098) data 0.000 (0.003) loss 1.6744 (1.5022) teacher_loss 0.3036 (0.1019) loss_zs_kd 0.0652 (0.0545) loss_oracle 0.6386 (0.6661) kd_loss 1.0188 (1.0400) acc 93.7500 (97.1205) gate/entropy 1.0652 (1.0657) gate/usage_max 0.4148 (0.4074) gate/usage_min 0.2185 (0.2180) gate/usage_std 0.0835 (0.0827) teacher/entropy 0.0220 (0.0412) teacher/usage_max 0.4969 (0.5208) teacher/usage_min 0.1909 (0.1875) teacher/usage_std 0.1258 (0.1432) nleep/row_max_mean 1488.7347 (1479.4314) nleep/row_max_std 45.9728 (52.8849) nleep/row_min_mean 1464.2852 (1454.7114) lr 1.3090e-03 eta 0:08:08
epoch [22/50] batch [160/176] time 0.096 (0.098) data 0.000 (0.002) loss 1.5211 (1.5043) teacher_loss 0.1088 (0.1028) loss_zs_kd 0.0638 (0.0547) loss_oracle 0.7082 (0.6661) kd_loss 1.0264 (1.0411) acc 96.8750 (97.1094) gate/entropy 1.0650 (1.0656) gate/usage_max 0.4170 (0.4084) gate/usage_min 0.2186 (0.2181) gate/usage_std 0.0839 (0.0828) teacher/entropy 0.0167 (0.0415) teacher/usage_max 0.4641 (0.5169) teacher/usage_min 0.1875 (0.1896) teacher/usage_std 0.1135 (0.1406) nleep/row_max_mean 1489.5620 (1479.4482) nleep/row_max_std 54.2907 (52.5896) nleep/row_min_mean 1465.2737 (1454.8362) lr 1.3090e-03 eta 0:08:02
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,165
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,835
* accuracy: 69.1%
* error: 30.9%
* macro_f1: 59.5%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [23/50] batch [20/176] time 0.098 (0.109) data 0.000 (0.016) loss 1.5262 (1.5245) teacher_loss 0.0954 (0.1136) loss_zs_kd 0.0563 (0.0506) loss_oracle 0.6608 (0.6920) kd_loss 1.0723 (1.0396) acc 96.8750 (96.4062) gate/entropy 1.0651 (1.0651) gate/usage_max 0.4197 (0.4189) gate/usage_min 0.2197 (0.2193) gate/usage_std 0.0839 (0.0839) teacher/entropy 0.0038 (0.0366) teacher/usage_max 0.4375 (0.5050) teacher/usage_min 0.2504 (0.2031) teacher/usage_std 0.0779 (0.1309) nleep/row_max_mean 1489.2595 (1485.3842) nleep/row_max_std 49.0009 (48.5632) nleep/row_min_mean 1460.5763 (1459.8298) lr 1.2487e-03 eta 0:08:54
epoch [23/50] batch [40/176] time 0.102 (0.101) data 0.000 (0.008) loss 1.4184 (1.5136) teacher_loss 0.0532 (0.1142) loss_zs_kd 0.0485 (0.0511) loss_oracle 0.6314 (0.6913) kd_loss 1.0253 (1.0282) acc 100.0000 (96.4844) gate/entropy 1.0646 (1.0650) gate/usage_max 0.4220 (0.4199) gate/usage_min 0.2194 (0.2194) gate/usage_std 0.0846 (0.0841) teacher/entropy 0.0443 (0.0406) teacher/usage_max 0.4793 (0.5179) teacher/usage_min 0.2490 (0.1952) teacher/usage_std 0.1037 (0.1388) nleep/row_max_mean 1485.6619 (1483.1022) nleep/row_max_std 58.7943 (50.0949) nleep/row_min_mean 1462.3186 (1457.7318) lr 1.2487e-03 eta 0:08:13
epoch [23/50] batch [60/176] time 0.098 (0.099) data 0.001 (0.006) loss 1.4744 (1.5031) teacher_loss 0.0596 (0.1076) loss_zs_kd 0.0679 (0.0540) loss_oracle 0.6892 (0.6857) kd_loss 1.0362 (1.0256) acc 100.0000 (96.9792) gate/entropy 1.0643 (1.0648) gate/usage_max 0.4243 (0.4210) gate/usage_min 0.2194 (0.2194) gate/usage_std 0.0852 (0.0844) teacher/entropy 0.0337 (0.0396) teacher/usage_max 0.4381 (0.5221) teacher/usage_min 0.2363 (0.1929) teacher/usage_std 0.0826 (0.1420) nleep/row_max_mean 1479.4984 (1483.1112) nleep/row_max_std 47.2731 (50.2456) nleep/row_min_mean 1454.6174 (1457.5342) lr 1.2487e-03 eta 0:08:00
epoch [23/50] batch [80/176] time 0.089 (0.097) data 0.000 (0.004) loss 1.4225 (1.4886) teacher_loss 0.0373 (0.1051) loss_zs_kd 0.0561 (0.0538) loss_oracle 0.6764 (0.6730) kd_loss 1.0190 (1.0202) acc 100.0000 (97.1484) gate/entropy 1.0640 (1.0647) gate/usage_max 0.4261 (0.4220) gate/usage_min 0.2195 (0.2195) gate/usage_std 0.0856 (0.0846) teacher/entropy 0.0578 (0.0405) teacher/usage_max 0.5038 (0.5207) teacher/usage_min 0.2191 (0.1917) teacher/usage_std 0.1228 (0.1418) nleep/row_max_mean 1494.4631 (1483.4214) nleep/row_max_std 46.6114 (49.2570) nleep/row_min_mean 1466.5762 (1457.6877) lr 1.2487e-03 eta 0:07:50
epoch [23/50] batch [100/176] time 0.093 (0.097) data 0.000 (0.003) loss 1.3626 (1.4838) teacher_loss 0.0528 (0.1057) loss_zs_kd 0.0544 (0.0544) loss_oracle 0.6544 (0.6684) kd_loss 0.9554 (1.0167) acc 100.0000 (97.0000) gate/entropy 1.0639 (1.0645) gate/usage_max 0.4275 (0.4230) gate/usage_min 0.2199 (0.2195) gate/usage_std 0.0858 (0.0848) teacher/entropy 0.0585 (0.0426) teacher/usage_max 0.6297 (0.5199) teacher/usage_min 0.1720 (0.1934) teacher/usage_std 0.2099 (0.1412) nleep/row_max_mean 1481.9507 (1483.0208) nleep/row_max_std 44.5417 (49.2829) nleep/row_min_mean 1455.6313 (1457.2970) lr 1.2487e-03 eta 0:07:48
epoch [23/50] batch [120/176] time 0.098 (0.097) data 0.000 (0.003) loss 1.4986 (1.4806) teacher_loss 0.1425 (0.1018) loss_zs_kd 0.0605 (0.0557) loss_oracle 0.6394 (0.6691) kd_loss 1.0060 (1.0165) acc 96.8750 (97.1094) gate/entropy 1.0635 (1.0644) gate/usage_max 0.4297 (0.4240) gate/usage_min 0.2200 (0.2196) gate/usage_std 0.0864 (0.0851) teacher/entropy 0.0452 (0.0411) teacher/usage_max 0.5685 (0.5261) teacher/usage_min 0.1765 (0.1904) teacher/usage_std 0.1694 (0.1453) nleep/row_max_mean 1478.5438 (1482.8485) nleep/row_max_std 52.5325 (48.9204) nleep/row_min_mean 1452.2449 (1456.8901) lr 1.2487e-03 eta 0:07:44
epoch [23/50] batch [140/176] time 0.087 (0.096) data 0.000 (0.003) loss 1.5199 (1.4796) teacher_loss 0.1103 (0.0989) loss_zs_kd 0.0598 (0.0558) loss_oracle 0.5786 (0.6681) kd_loss 1.0904 (1.0187) acc 93.7500 (97.2098) gate/entropy 1.0631 (1.0642) gate/usage_max 0.4320 (0.4250) gate/usage_min 0.2200 (0.2196) gate/usage_std 0.0871 (0.0853) teacher/entropy 0.0271 (0.0404) teacher/usage_max 0.4385 (0.5245) teacher/usage_min 0.2191 (0.1904) teacher/usage_std 0.0898 (0.1446) nleep/row_max_mean 1472.3198 (1482.1567) nleep/row_max_std 52.3459 (49.0791) nleep/row_min_mean 1447.0415 (1456.2128) lr 1.2487e-03 eta 0:07:41
epoch [23/50] batch [160/176] time 0.105 (0.096) data 0.000 (0.002) loss 1.4859 (1.4774) teacher_loss 0.0194 (0.0958) loss_zs_kd 0.0306 (0.0558) loss_oracle 0.5504 (0.6668) kd_loss 1.1760 (1.0203) acc 100.0000 (97.2070) gate/entropy 1.0626 (1.0640) gate/usage_max 0.4342 (0.4260) gate/usage_min 0.2202 (0.2197) gate/usage_std 0.0878 (0.0856) teacher/entropy 0.0646 (0.0400) teacher/usage_max 0.5266 (0.5255) teacher/usage_min 0.2136 (0.1889) teacher/usage_std 0.1380 (0.1457) nleep/row_max_mean 1468.2827 (1482.2029) nleep/row_max_std 59.7105 (48.9388) nleep/row_min_mean 1446.9495 (1456.2040) lr 1.2487e-03 eta 0:07:38
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,174
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,781
* accuracy: 67.1%
* error: 32.9%
* macro_f1: 59.0%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [24/50] batch [20/176] time 0.155 (0.128) data 0.001 (0.017) loss 1.4001 (1.4155) teacher_loss 0.0155 (0.0811) loss_zs_kd 0.0484 (0.0534) loss_oracle 0.6966 (0.6388) kd_loss 1.0120 (0.9884) acc 100.0000 (97.8125) gate/entropy 1.0619 (1.0621) gate/usage_max 0.4377 (0.4369) gate/usage_min 0.2204 (0.2204) gate/usage_std 0.0889 (0.0887) teacher/entropy 0.0496 (0.0464) teacher/usage_max 0.5304 (0.5559) teacher/usage_min 0.1942 (0.1808) teacher/usage_std 0.1432 (0.1635) nleep/row_max_mean 1481.8574 (1477.8973) nleep/row_max_std 48.8846 (49.8968) nleep/row_min_mean 1453.4788 (1452.0515) lr 1.1874e-03 eta 0:10:04
epoch [24/50] batch [40/176] time 0.096 (0.108) data 0.001 (0.009) loss 1.3981 (1.4229) teacher_loss 0.1097 (0.0817) loss_zs_kd 0.0284 (0.0534) loss_oracle 0.5740 (0.6330) kd_loss 0.9872 (0.9980) acc 93.7500 (97.4219) gate/entropy 1.0613 (1.0618) gate/usage_max 0.4397 (0.4379) gate/usage_min 0.2203 (0.2204) gate/usage_std 0.0897 (0.0890) teacher/entropy 0.0360 (0.0423) teacher/usage_max 0.4782 (0.5354) teacher/usage_min 0.1533 (0.1869) teacher/usage_std 0.1349 (0.1518) nleep/row_max_mean 1488.4761 (1481.1253) nleep/row_max_std 57.0621 (49.1171) nleep/row_min_mean 1460.9592 (1454.8072) lr 1.1874e-03 eta 0:08:30
epoch [24/50] batch [60/176] time 0.101 (0.104) data 0.001 (0.006) loss 1.5328 (1.4422) teacher_loss 0.0904 (0.0861) loss_zs_kd 0.0589 (0.0547) loss_oracle 0.6103 (0.6369) kd_loss 1.1077 (1.0102) acc 96.8750 (97.1875) gate/entropy 1.0609 (1.0616) gate/usage_max 0.4417 (0.4388) gate/usage_min 0.2204 (0.2204) gate/usage_std 0.0904 (0.0893) teacher/entropy 0.0269 (0.0397) teacher/usage_max 0.5037 (0.5282) teacher/usage_min 0.0628 (0.1846) teacher/usage_std 0.1934 (0.1493) nleep/row_max_mean 1474.2170 (1481.1381) nleep/row_max_std 64.2189 (50.0103) nleep/row_min_mean 1448.8296 (1454.9897) lr 1.1874e-03 eta 0:08:07
epoch [24/50] batch [80/176] time 0.089 (0.102) data 0.000 (0.004) loss 1.4134 (1.4423) teacher_loss 0.0860 (0.0875) loss_zs_kd 0.0429 (0.0555) loss_oracle 0.6767 (0.6331) kd_loss 0.9677 (1.0106) acc 96.8750 (97.3828) gate/entropy 1.0605 (1.0614) gate/usage_max 0.4433 (0.4398) gate/usage_min 0.2207 (0.2205) gate/usage_std 0.0909 (0.0897) teacher/entropy 0.0358 (0.0380) teacher/usage_max 0.6526 (0.5281) teacher/usage_min 0.1250 (0.1864) teacher/usage_std 0.2292 (0.1490) nleep/row_max_mean 1479.6119 (1481.9972) nleep/row_max_std 57.1841 (49.8300) nleep/row_min_mean 1450.5890 (1455.5847) lr 1.1874e-03 eta 0:07:58
epoch [24/50] batch [100/176] time 0.098 (0.101) data 0.000 (0.004) loss 1.6683 (1.4454) teacher_loss 0.2654 (0.0932) loss_zs_kd 0.0882 (0.0556) loss_oracle 0.5981 (0.6342) kd_loss 1.0598 (1.0074) acc 93.7500 (97.3438) gate/entropy 1.0599 (1.0611) gate/usage_max 0.4457 (0.4407) gate/usage_min 0.2207 (0.2205) gate/usage_std 0.0918 (0.0900) teacher/entropy 0.0372 (0.0372) teacher/usage_max 0.4690 (0.5345) teacher/usage_min 0.2033 (0.1829) teacher/usage_std 0.1086 (0.1528) nleep/row_max_mean 1492.3663 (1482.5812) nleep/row_max_std 36.2127 (49.4500) nleep/row_min_mean 1464.7180 (1455.9725) lr 1.1874e-03 eta 0:07:48
epoch [24/50] batch [120/176] time 0.094 (0.099) data 0.000 (0.003) loss 1.4303 (1.4495) teacher_loss 0.0462 (0.0917) loss_zs_kd 0.0464 (0.0571) loss_oracle 0.6069 (0.6330) kd_loss 1.0573 (1.0128) acc 100.0000 (97.3698) gate/entropy 1.0593 (1.0609) gate/usage_max 0.4476 (0.4417) gate/usage_min 0.2208 (0.2206) gate/usage_std 0.0926 (0.0904) teacher/entropy 0.0038 (0.0372) teacher/usage_max 0.5629 (0.5281) teacher/usage_min 0.1252 (0.1840) teacher/usage_std 0.1793 (0.1489) nleep/row_max_mean 1502.3030 (1482.9569) nleep/row_max_std 51.1450 (50.0383) nleep/row_min_mean 1472.0116 (1456.2935) lr 1.1874e-03 eta 0:07:40
epoch [24/50] batch [140/176] time 0.093 (0.099) data 0.000 (0.003) loss 1.4645 (1.4497) teacher_loss 0.0871 (0.0921) loss_zs_kd 0.0530 (0.0573) loss_oracle 0.6259 (0.6361) kd_loss 1.0379 (1.0110) acc 93.7500 (97.2545) gate/entropy 1.0588 (1.0607) gate/usage_max 0.4498 (0.4427) gate/usage_min 0.2211 (0.2207) gate/usage_std 0.0934 (0.0907) teacher/entropy 0.0074 (0.0366) teacher/usage_max 0.5302 (0.5336) teacher/usage_min 0.2200 (0.1825) teacher/usage_std 0.1397 (0.1521) nleep/row_max_mean 1482.4889 (1482.2101) nleep/row_max_std 49.8127 (51.0726) nleep/row_min_mean 1456.8123 (1455.4944) lr 1.1874e-03 eta 0:07:37
epoch [24/50] batch [160/176] time 0.093 (0.098) data 0.000 (0.002) loss 1.5511 (1.4473) teacher_loss 0.1523 (0.0912) loss_zs_kd 0.0552 (0.0571) loss_oracle 0.6381 (0.6356) kd_loss 1.0522 (1.0098) acc 93.7500 (97.2461) gate/entropy 1.0584 (1.0604) gate/usage_max 0.4515 (0.4437) gate/usage_min 0.2215 (0.2207) gate/usage_std 0.0940 (0.0911) teacher/entropy 0.0058 (0.0367) teacher/usage_max 0.5626 (0.5354) teacher/usage_min 0.1251 (0.1809) teacher/usage_std 0.1792 (0.1533) nleep/row_max_mean 1484.0918 (1481.9937) nleep/row_max_std 58.9970 (51.9729) nleep/row_min_mean 1454.2830 (1455.2368) lr 1.1874e-03 eta 0:07:30
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,172
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,766
* accuracy: 66.5%
* error: 33.5%
* macro_f1: 58.8%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [25/50] batch [20/176] time 0.122 (0.134) data 0.001 (0.021) loss 1.5050 (1.4448) teacher_loss 0.0643 (0.0910) loss_zs_kd 0.0698 (0.0608) loss_oracle 0.5839 (0.6262) kd_loss 1.1139 (1.0104) acc 96.8750 (97.3438) gate/entropy 1.0573 (1.0575) gate/usage_max 0.4551 (0.4542) gate/usage_min 0.2216 (0.2215) gate/usage_std 0.0956 (0.0952) teacher/entropy 0.0579 (0.0391) teacher/usage_max 0.4492 (0.5353) teacher/usage_min 0.2292 (0.1868) teacher/usage_std 0.0902 (0.1515) nleep/row_max_mean 1498.4531 (1483.0931) nleep/row_max_std 33.3616 (54.2481) nleep/row_min_mean 1470.5201 (1455.7190) lr 1.1253e-03 eta 0:10:08
epoch [25/50] batch [40/176] time 0.098 (0.123) data 0.001 (0.011) loss 1.3532 (1.4230) teacher_loss 0.0396 (0.0839) loss_zs_kd 0.0612 (0.0597) loss_oracle 0.5901 (0.6213) kd_loss 0.9880 (0.9985) acc 100.0000 (97.7344) gate/entropy 1.0568 (1.0573) gate/usage_max 0.4565 (0.4551) gate/usage_min 0.2218 (0.2216) gate/usage_std 0.0962 (0.0956) teacher/entropy 0.0649 (0.0459) teacher/usage_max 0.5346 (0.5277) teacher/usage_min 0.1800 (0.1918) teacher/usage_std 0.1487 (0.1464) nleep/row_max_mean 1484.4254 (1483.4633) nleep/row_max_std 49.8218 (53.0811) nleep/row_min_mean 1457.6512 (1456.1581) lr 1.1253e-03 eta 0:09:16
epoch [25/50] batch [60/176] time 0.101 (0.114) data 0.000 (0.007) loss 1.3729 (1.4295) teacher_loss 0.0539 (0.0836) loss_zs_kd 0.0448 (0.0585) loss_oracle 0.6516 (0.6227) kd_loss 0.9708 (1.0053) acc 100.0000 (97.9167) gate/entropy 1.0562 (1.0570) gate/usage_max 0.4582 (0.4558) gate/usage_min 0.2218 (0.2217) gate/usage_std 0.0970 (0.0959) teacher/entropy 0.0731 (0.0431) teacher/usage_max 0.5013 (0.5232) teacher/usage_min 0.2303 (0.1923) teacher/usage_std 0.1198 (0.1437) nleep/row_max_mean 1481.3728 (1481.9704) nleep/row_max_std 64.2012 (53.1576) nleep/row_min_mean 1454.1566 (1454.7444) lr 1.1253e-03 eta 0:08:33
epoch [25/50] batch [80/176] time 0.089 (0.110) data 0.000 (0.005) loss 1.4462 (1.4213) teacher_loss 0.1079 (0.0782) loss_zs_kd 0.0735 (0.0588) loss_oracle 0.6282 (0.6217) kd_loss 0.9874 (1.0029) acc 96.8750 (97.9688) gate/entropy 1.0558 (1.0568) gate/usage_max 0.4598 (0.4566) gate/usage_min 0.2221 (0.2218) gate/usage_std 0.0976 (0.0963) teacher/entropy 0.0063 (0.0395) teacher/usage_max 0.5952 (0.5315) teacher/usage_min 0.1875 (0.1867) teacher/usage_std 0.1855 (0.1501) nleep/row_max_mean 1488.2424 (1481.9572) nleep/row_max_std 49.4129 (52.7454) nleep/row_min_mean 1458.2095 (1454.6817) lr 1.1253e-03 eta 0:08:12
epoch [25/50] batch [100/176] time 0.087 (0.107) data 0.000 (0.004) loss 1.4374 (1.4182) teacher_loss 0.0808 (0.0733) loss_zs_kd 0.0613 (0.0588) loss_oracle 0.6381 (0.6188) kd_loss 1.0068 (1.0061) acc 96.8750 (98.1875) gate/entropy 1.0551 (1.0565) gate/usage_max 0.4615 (0.4575) gate/usage_min 0.2221 (0.2218) gate/usage_std 0.0985 (0.0966) teacher/entropy 0.0252 (0.0384) teacher/usage_max 0.5315 (0.5294) teacher/usage_min 0.2302 (0.1894) teacher/usage_std 0.1401 (0.1481) nleep/row_max_mean 1491.4910 (1481.9511) nleep/row_max_std 46.8218 (52.3145) nleep/row_min_mean 1462.9138 (1454.7081) lr 1.1253e-03 eta 0:07:57
epoch [25/50] batch [120/176] time 0.175 (0.108) data 0.000 (0.004) loss 1.4490 (1.4140) teacher_loss 0.0808 (0.0737) loss_zs_kd 0.0681 (0.0581) loss_oracle 0.6390 (0.6154) kd_loss 1.0147 (1.0035) acc 100.0000 (98.0990) gate/entropy 1.0547 (1.0562) gate/usage_max 0.4630 (0.4583) gate/usage_min 0.2224 (0.2219) gate/usage_std 0.0991 (0.0970) teacher/entropy 0.0522 (0.0385) teacher/usage_max 0.4132 (0.5305) teacher/usage_min 0.2013 (0.1875) teacher/usage_std 0.0940 (0.1492) nleep/row_max_mean 1484.1708 (1481.8046) nleep/row_max_std 46.1384 (52.0185) nleep/row_min_mean 1456.9381 (1454.6815) lr 1.1253e-03 eta 0:08:02
epoch [25/50] batch [140/176] time 0.099 (0.107) data 0.000 (0.003) loss 1.4264 (1.4194) teacher_loss 0.1524 (0.0810) loss_zs_kd 0.0687 (0.0589) loss_oracle 0.6237 (0.6137) kd_loss 0.9278 (1.0022) acc 96.8750 (97.8795) gate/entropy 1.0542 (1.0559) gate/usage_max 0.4642 (0.4591) gate/usage_min 0.2225 (0.2219) gate/usage_std 0.0997 (0.0974) teacher/entropy 0.0733 (0.0381) teacher/usage_max 0.5878 (0.5305) teacher/usage_min 0.2016 (0.1891) teacher/usage_std 0.1800 (0.1487) nleep/row_max_mean 1486.5840 (1482.4110) nleep/row_max_std 39.7396 (51.7076) nleep/row_min_mean 1460.4374 (1455.3145) lr 1.1253e-03 eta 0:07:52
epoch [25/50] batch [160/176] time 0.146 (0.106) data 0.000 (0.003) loss 1.4592 (1.4221) teacher_loss 0.1513 (0.0844) loss_zs_kd 0.0462 (0.0593) loss_oracle 0.5706 (0.6098) kd_loss 0.9995 (1.0032) acc 96.8750 (97.7734) gate/entropy 1.0535 (1.0557) gate/usage_max 0.4658 (0.4598) gate/usage_min 0.2223 (0.2220) gate/usage_std 0.1005 (0.0977) teacher/entropy 0.0459 (0.0388) teacher/usage_max 0.4768 (0.5252) teacher/usage_min 0.2093 (0.1927) teacher/usage_std 0.1101 (0.1447) nleep/row_max_mean 1488.3779 (1482.3788) nleep/row_max_std 57.2996 (51.5915) nleep/row_min_mean 1461.9504 (1455.3358) lr 1.1253e-03 eta 0:07:47
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,171
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,745
* accuracy: 65.7%
* error: 34.3%
* macro_f1: 58.8%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [26/50] batch [20/176] time 0.088 (0.111) data 0.000 (0.015) loss 1.4560 (1.4197) teacher_loss 0.0827 (0.0997) loss_zs_kd 0.0600 (0.0584) loss_oracle 0.5419 (0.5800) kd_loss 1.0723 (1.0008) acc 93.7500 (96.8750) gate/entropy 1.0530 (1.0531) gate/usage_max 0.4675 (0.4672) gate/usage_min 0.2228 (0.2226) gate/usage_std 0.1013 (0.1012) teacher/entropy 0.0483 (0.0391) teacher/usage_max 0.3723 (0.4992) teacher/usage_min 0.3084 (0.1910) teacher/usage_std 0.0279 (0.1311) nleep/row_max_mean 1479.6084 (1480.3719) nleep/row_max_std 55.8506 (53.1146) nleep/row_min_mean 1452.8269 (1452.8169) lr 1.0628e-03 eta 0:08:06
epoch [26/50] batch [40/176] time 0.104 (0.103) data 0.000 (0.007) loss 1.3410 (1.4080) teacher_loss 0.0279 (0.0873) loss_zs_kd 0.0491 (0.0606) loss_oracle 0.5712 (0.5898) kd_loss 1.0029 (0.9955) acc 100.0000 (97.5000) gate/entropy 1.0523 (1.0528) gate/usage_max 0.4691 (0.4678) gate/usage_min 0.2226 (0.2225) gate/usage_std 0.1022 (0.1015) teacher/entropy 0.0266 (0.0405) teacher/usage_max 0.5314 (0.5168) teacher/usage_min 0.2326 (0.1934) teacher/usage_std 0.1401 (0.1400) nleep/row_max_mean 1471.7587 (1481.4181) nleep/row_max_std 58.1661 (51.9058) nleep/row_min_mean 1445.4785 (1453.9395) lr 1.0628e-03 eta 0:07:29
epoch [26/50] batch [60/176] time 0.094 (0.101) data 0.001 (0.005) loss 1.5897 (1.4035) teacher_loss 0.1020 (0.0908) loss_zs_kd 0.0932 (0.0601) loss_oracle 0.6701 (0.5918) kd_loss 1.1060 (0.9868) acc 96.8750 (97.5521) gate/entropy 1.0515 (1.0525) gate/usage_max 0.4708 (0.4684) gate/usage_min 0.2223 (0.2226) gate/usage_std 0.1031 (0.1018) teacher/entropy 0.0322 (0.0412) teacher/usage_max 0.3516 (0.5267) teacher/usage_min 0.3122 (0.1884) teacher/usage_std 0.0162 (0.1460) nleep/row_max_mean 1499.2996 (1481.8643) nleep/row_max_std 30.0445 (50.4455) nleep/row_min_mean 1469.6748 (1454.2798) lr 1.0628e-03 eta 0:07:18
epoch [26/50] batch [80/176] time 0.100 (0.100) data 0.000 (0.004) loss 1.4179 (1.3966) teacher_loss 0.0619 (0.0855) loss_zs_kd 0.0657 (0.0607) loss_oracle 0.6129 (0.5949) kd_loss 1.0167 (0.9833) acc 100.0000 (97.8125) gate/entropy 1.0511 (1.0523) gate/usage_max 0.4717 (0.4690) gate/usage_min 0.2223 (0.2226) gate/usage_std 0.1036 (0.1021) teacher/entropy 0.0206 (0.0422) teacher/usage_max 0.4779 (0.5298) teacher/usage_min 0.1873 (0.1836) teacher/usage_std 0.1186 (0.1490) nleep/row_max_mean 1490.5310 (1480.9495) nleep/row_max_std 41.4268 (50.4336) nleep/row_min_mean 1460.4661 (1453.5237) lr 1.0628e-03 eta 0:07:13
epoch [26/50] batch [100/176] time 0.092 (0.100) data 0.000 (0.003) loss 1.2963 (1.4020) teacher_loss 0.0364 (0.0871) loss_zs_kd 0.0556 (0.0607) loss_oracle 0.5537 (0.5941) kd_loss 0.9553 (0.9876) acc 100.0000 (97.6250) gate/entropy 1.0509 (1.0521) gate/usage_max 0.4723 (0.4696) gate/usage_min 0.2226 (0.2226) gate/usage_std 0.1039 (0.1024) teacher/entropy 0.0224 (0.0419) teacher/usage_max 0.5942 (0.5230) teacher/usage_min 0.1582 (0.1881) teacher/usage_std 0.1880 (0.1445) nleep/row_max_mean 1480.9495 (1480.6328) nleep/row_max_std 48.1441 (50.9872) nleep/row_min_mean 1452.9529 (1453.2224) lr 1.0628e-03 eta 0:07:08
epoch [26/50] batch [120/176] time 0.092 (0.099) data 0.000 (0.003) loss 1.3117 (1.3992) teacher_loss 0.0176 (0.0854) loss_zs_kd 0.0548 (0.0594) loss_oracle 0.5980 (0.5894) kd_loss 0.9677 (0.9894) acc 100.0000 (97.6823) gate/entropy 1.0505 (1.0518) gate/usage_max 0.4731 (0.4701) gate/usage_min 0.2224 (0.2226) gate/usage_std 0.1043 (0.1027) teacher/entropy 0.0218 (0.0426) teacher/usage_max 0.6253 (0.5175) teacher/usage_min 0.1273 (0.1902) teacher/usage_std 0.2122 (0.1410) nleep/row_max_mean 1491.3740 (1480.2850) nleep/row_max_std 46.4602 (51.3505) nleep/row_min_mean 1462.9479 (1452.9134) lr 1.0628e-03 eta 0:07:03
epoch [26/50] batch [140/176] time 0.096 (0.098) data 0.000 (0.002) loss 1.3761 (1.3961) teacher_loss 0.0550 (0.0861) loss_zs_kd 0.0442 (0.0585) loss_oracle 0.5530 (0.5847) kd_loss 1.0225 (0.9884) acc 100.0000 (97.7009) gate/entropy 1.0503 (1.0516) gate/usage_max 0.4736 (0.4706) gate/usage_min 0.2226 (0.2226) gate/usage_std 0.1046 (0.1030) teacher/entropy 0.0271 (0.0432) teacher/usage_max 0.4374 (0.5160) teacher/usage_min 0.1727 (0.1887) teacher/usage_std 0.1152 (0.1408) nleep/row_max_mean 1483.0630 (1480.5689) nleep/row_max_std 50.2836 (51.2807) nleep/row_min_mean 1456.0100 (1453.1696) lr 1.0628e-03 eta 0:06:59
epoch [26/50] batch [160/176] time 0.098 (0.098) data 0.000 (0.002) loss 1.2613 (1.3911) teacher_loss 0.0815 (0.0831) loss_zs_kd 0.0231 (0.0585) loss_oracle 0.5986 (0.5831) kd_loss 0.8689 (0.9873) acc 96.8750 (97.7539) gate/entropy 1.0496 (1.0514) gate/usage_max 0.4751 (0.4711) gate/usage_min 0.2223 (0.2225) gate/usage_std 0.1055 (0.1032) teacher/entropy 0.0567 (0.0443) teacher/usage_max 0.7032 (0.5149) teacher/usage_min 0.1415 (0.1878) teacher/usage_std 0.2616 (0.1409) nleep/row_max_mean 1463.4744 (1481.2645) nleep/row_max_std 67.3660 (50.8246) nleep/row_min_mean 1437.3264 (1453.8425) lr 1.0628e-03 eta 0:06:53
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,160
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 91.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,778
* accuracy: 66.9%
* error: 33.1%
* macro_f1: 59.2%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [27/50] batch [20/176] time 0.103 (0.128) data 0.000 (0.017) loss 1.3853 (1.4029) teacher_loss 0.0613 (0.0993) loss_zs_kd 0.0498 (0.0579) loss_oracle 0.5060 (0.5721) kd_loss 1.0461 (0.9886) acc 100.0000 (96.5625) gate/entropy 1.0493 (1.0493) gate/usage_max 0.4759 (0.4758) gate/usage_min 0.2226 (0.2225) gate/usage_std 0.1058 (0.1058) teacher/entropy 0.0351 (0.0469) teacher/usage_max 0.4414 (0.4999) teacher/usage_min 0.2790 (0.2024) teacher/usage_std 0.0764 (0.1274) nleep/row_max_mean 1480.1018 (1479.9436) nleep/row_max_std 47.4000 (51.6029) nleep/row_min_mean 1452.8547 (1453.3650) lr 1.0000e-03 eta 0:08:56
epoch [27/50] batch [40/176] time 0.143 (0.112) data 0.001 (0.009) loss 1.3191 (1.3978) teacher_loss 0.0753 (0.0919) loss_zs_kd 0.0453 (0.0581) loss_oracle 0.6140 (0.5787) kd_loss 0.9142 (0.9876) acc 96.8750 (97.1875) gate/entropy 1.0490 (1.0491) gate/usage_max 0.4765 (0.4762) gate/usage_min 0.2227 (0.2224) gate/usage_std 0.1062 (0.1060) teacher/entropy 0.0520 (0.0488) teacher/usage_max 0.6184 (0.5002) teacher/usage_min 0.1673 (0.1965) teacher/usage_std 0.2025 (0.1309) nleep/row_max_mean 1471.1221 (1483.1865) nleep/row_max_std 49.8148 (50.8103) nleep/row_min_mean 1446.0262 (1456.4156) lr 1.0000e-03 eta 0:07:48
epoch [27/50] batch [60/176] time 0.092 (0.106) data 0.000 (0.006) loss 1.4230 (1.3944) teacher_loss 0.0774 (0.0890) loss_zs_kd 0.0711 (0.0581) loss_oracle 0.5873 (0.5785) kd_loss 1.0165 (0.9871) acc 96.8750 (97.2396) gate/entropy 1.0484 (1.0489) gate/usage_max 0.4778 (0.4766) gate/usage_min 0.2225 (0.2224) gate/usage_std 0.1069 (0.1063) teacher/entropy 0.0259 (0.0468) teacher/usage_max 0.5064 (0.5059) teacher/usage_min 0.2452 (0.1960) teacher/usage_std 0.1224 (0.1339) nleep/row_max_mean 1485.6106 (1483.1410) nleep/row_max_std 42.9434 (50.7221) nleep/row_min_mean 1458.6707 (1456.4029) lr 1.0000e-03 eta 0:07:23
epoch [27/50] batch [80/176] time 0.089 (0.103) data 0.000 (0.004) loss 1.2870 (1.3943) teacher_loss 0.0396 (0.0903) loss_zs_kd 0.0376 (0.0565) loss_oracle 0.5860 (0.5802) kd_loss 0.9356 (0.9856) acc 100.0000 (97.1484) gate/entropy 1.0477 (1.0487) gate/usage_max 0.4792 (0.4771) gate/usage_min 0.2223 (0.2224) gate/usage_std 0.1077 (0.1065) teacher/entropy 0.0446 (0.0473) teacher/usage_max 0.5892 (0.5061) teacher/usage_min 0.1717 (0.1947) teacher/usage_std 0.1830 (0.1343) nleep/row_max_mean 1467.0466 (1483.4852) nleep/row_max_std 59.1969 (50.1898) nleep/row_min_mean 1441.1301 (1456.7160) lr 1.0000e-03 eta 0:07:08
epoch [27/50] batch [100/176] time 0.102 (0.102) data 0.000 (0.004) loss 1.3283 (1.3904) teacher_loss 0.0855 (0.0882) loss_zs_kd 0.0206 (0.0565) loss_oracle 0.5260 (0.5839) kd_loss 0.9695 (0.9820) acc 93.7500 (97.2812) gate/entropy 1.0476 (1.0485) gate/usage_max 0.4795 (0.4775) gate/usage_min 0.2225 (0.2224) gate/usage_std 0.1079 (0.1068) teacher/entropy 0.0743 (0.0467) teacher/usage_max 0.5344 (0.5134) teacher/usage_min 0.1640 (0.1920) teacher/usage_std 0.1529 (0.1386) nleep/row_max_mean 1452.0537 (1483.5195) nleep/row_max_std 65.4474 (50.0615) nleep/row_min_mean 1429.3435 (1456.7267) lr 1.0000e-03 eta 0:06:59
epoch [27/50] batch [120/176] time 0.100 (0.101) data 0.000 (0.003) loss 1.2885 (1.3878) teacher_loss 0.0279 (0.0856) loss_zs_kd 0.0665 (0.0579) loss_oracle 0.6105 (0.5835) kd_loss 0.9220 (0.9815) acc 100.0000 (97.4219) gate/entropy 1.0469 (1.0483) gate/usage_max 0.4809 (0.4780) gate/usage_min 0.2224 (0.2224) gate/usage_std 0.1087 (0.1070) teacher/entropy 0.0401 (0.0466) teacher/usage_max 0.6507 (0.5156) teacher/usage_min 0.1352 (0.1920) teacher/usage_std 0.2267 (0.1394) nleep/row_max_mean 1489.1893 (1483.2042) nleep/row_max_std 55.5058 (50.1902) nleep/row_min_mean 1461.3418 (1456.3865) lr 1.0000e-03 eta 0:06:54
epoch [27/50] batch [140/176] time 0.099 (0.100) data 0.000 (0.003) loss 1.3605 (1.3877) teacher_loss 0.0343 (0.0838) loss_zs_kd 0.0527 (0.0588) loss_oracle 0.5184 (0.5823) kd_loss 1.0407 (0.9833) acc 100.0000 (97.4554) gate/entropy 1.0464 (1.0480) gate/usage_max 0.4819 (0.4785) gate/usage_min 0.2225 (0.2224) gate/usage_std 0.1092 (0.1073) teacher/entropy 0.0520 (0.0453) teacher/usage_max 0.4298 (0.5157) teacher/usage_min 0.1974 (0.1924) teacher/usage_std 0.0989 (0.1395) nleep/row_max_mean 1486.3835 (1483.7524) nleep/row_max_std 47.8997 (49.8627) nleep/row_min_mean 1456.6194 (1456.7555) lr 1.0000e-03 eta 0:06:47
epoch [27/50] batch [160/176] time 0.095 (0.099) data 0.000 (0.002) loss 1.3352 (1.3902) teacher_loss 0.0307 (0.0854) loss_zs_kd 0.0687 (0.0585) loss_oracle 0.5676 (0.5800) kd_loss 0.9864 (0.9856) acc 100.0000 (97.3438) gate/entropy 1.0459 (1.0478) gate/usage_max 0.4829 (0.4790) gate/usage_min 0.2223 (0.2224) gate/usage_std 0.1098 (0.1076) teacher/entropy 0.0297 (0.0448) teacher/usage_max 0.4996 (0.5114) teacher/usage_min 0.1439 (0.1933) teacher/usage_std 0.1461 (0.1372) nleep/row_max_mean 1492.5942 (1483.8431) nleep/row_max_std 55.1901 (49.9810) nleep/row_min_mean 1464.5396 (1456.7345) lr 1.0000e-03 eta 0:06:43
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,170
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,760
* accuracy: 66.3%
* error: 33.7%
* macro_f1: 59.4%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [28/50] batch [20/176] time 0.084 (0.112) data 0.000 (0.016) loss 1.3525 (1.4115) teacher_loss 0.0773 (0.1034) loss_zs_kd 0.0762 (0.0591) loss_oracle 0.5292 (0.5748) kd_loss 0.9726 (0.9912) acc 96.8750 (97.0312) gate/entropy 1.0453 (1.0456) gate/usage_max 0.4839 (0.4834) gate/usage_min 0.2221 (0.2222) gate/usage_std 0.1104 (0.1101) teacher/entropy 0.0530 (0.0481) teacher/usage_max 0.4673 (0.4896) teacher/usage_min 0.1210 (0.1937) teacher/usage_std 0.1518 (0.1266) nleep/row_max_mean 1499.6809 (1480.5479) nleep/row_max_std 35.9154 (47.3249) nleep/row_min_mean 1471.1564 (1453.6354) lr 9.3721e-04 eta 0:07:31
epoch [28/50] batch [40/176] time 0.089 (0.102) data 0.000 (0.008) loss 1.5023 (1.4084) teacher_loss 0.1441 (0.0985) loss_zs_kd 0.0739 (0.0587) loss_oracle 0.6452 (0.5819) kd_loss 0.9987 (0.9896) acc 93.7500 (97.1875) gate/entropy 1.0449 (1.0454) gate/usage_max 0.4847 (0.4838) gate/usage_min 0.2220 (0.2222) gate/usage_std 0.1109 (0.1104) teacher/entropy 0.0573 (0.0422) teacher/usage_max 0.4794 (0.5028) teacher/usage_min 0.2538 (0.1881) teacher/usage_std 0.1034 (0.1354) nleep/row_max_mean 1484.2673 (1481.8272) nleep/row_max_std 43.8621 (47.0867) nleep/row_min_mean 1456.7456 (1454.6663) lr 9.3721e-04 eta 0:06:48
epoch [28/50] batch [60/176] time 0.080 (0.098) data 0.000 (0.006) loss 1.2302 (1.4004) teacher_loss 0.0450 (0.0956) loss_zs_kd 0.0326 (0.0583) loss_oracle 0.5602 (0.5781) kd_loss 0.8888 (0.9866) acc 100.0000 (97.1875) gate/entropy 1.0447 (1.0452) gate/usage_max 0.4851 (0.4841) gate/usage_min 0.2219 (0.2221) gate/usage_std 0.1112 (0.1106) teacher/entropy 0.0505 (0.0415) teacher/usage_max 0.6437 (0.5091) teacher/usage_min 0.1301 (0.1834) teacher/usage_std 0.2230 (0.1396) nleep/row_max_mean 1493.9990 (1483.1367) nleep/row_max_std 31.9470 (46.5848) nleep/row_min_mean 1465.6941 (1456.0445) lr 9.3721e-04 eta 0:06:31
epoch [28/50] batch [80/176] time 0.088 (0.096) data 0.000 (0.004) loss 1.3715 (1.3974) teacher_loss 0.0379 (0.0913) loss_zs_kd 0.1024 (0.0586) loss_oracle 0.5850 (0.5714) kd_loss 0.9899 (0.9911) acc 100.0000 (97.2656) gate/entropy 1.0444 (1.0450) gate/usage_max 0.4857 (0.4845) gate/usage_min 0.2220 (0.2221) gate/usage_std 0.1115 (0.1108) teacher/entropy 0.0777 (0.0424) teacher/usage_max 0.4637 (0.5030) teacher/usage_min 0.2679 (0.1910) teacher/usage_std 0.0922 (0.1343) nleep/row_max_mean 1488.2526 (1483.1102) nleep/row_max_std 49.6169 (47.1981) nleep/row_min_mean 1461.4097 (1456.1737) lr 9.3721e-04 eta 0:06:19
epoch [28/50] batch [100/176] time 0.089 (0.094) data 0.000 (0.003) loss 1.3340 (1.3931) teacher_loss 0.0841 (0.0910) loss_zs_kd 0.0462 (0.0584) loss_oracle 0.5679 (0.5659) kd_loss 0.9428 (0.9899) acc 96.8750 (97.2812) gate/entropy 1.0440 (1.0449) gate/usage_max 0.4864 (0.4848) gate/usage_min 0.2219 (0.2221) gate/usage_std 0.1119 (0.1109) teacher/entropy 0.0697 (0.0436) teacher/usage_max 0.4933 (0.5033) teacher/usage_min 0.1166 (0.1922) teacher/usage_std 0.1589 (0.1339) nleep/row_max_mean 1500.1030 (1483.5596) nleep/row_max_std 38.2418 (46.7683) nleep/row_min_mean 1471.2188 (1456.5619) lr 9.3721e-04 eta 0:06:09
epoch [28/50] batch [120/176] time 0.155 (0.093) data 0.000 (0.003) loss 1.3446 (1.3916) teacher_loss 0.0546 (0.0948) loss_zs_kd 0.0543 (0.0573) loss_oracle 0.5860 (0.5667) kd_loss 0.9699 (0.9848) acc 100.0000 (97.1354) gate/entropy 1.0439 (1.0447) gate/usage_max 0.4866 (0.4850) gate/usage_min 0.2219 (0.2220) gate/usage_std 0.1120 (0.1111) teacher/entropy 0.0228 (0.0447) teacher/usage_max 0.5545 (0.5100) teacher/usage_min 0.1644 (0.1876) teacher/usage_std 0.1635 (0.1387) nleep/row_max_mean 1478.4354 (1483.0735) nleep/row_max_std 47.1012 (47.2733) nleep/row_min_mean 1453.7341 (1456.2313) lr 9.3721e-04 eta 0:06:06
epoch [28/50] batch [140/176] time 0.088 (0.095) data 0.000 (0.003) loss 1.4096 (1.3886) teacher_loss 0.0581 (0.0954) loss_zs_kd 0.0524 (0.0566) loss_oracle 0.4239 (0.5642) kd_loss 1.1133 (0.9827) acc 100.0000 (97.2098) gate/entropy 1.0435 (1.0446) gate/usage_max 0.4874 (0.4854) gate/usage_min 0.2217 (0.2220) gate/usage_std 0.1125 (0.1113) teacher/entropy 0.0442 (0.0444) teacher/usage_max 0.5587 (0.5126) teacher/usage_min 0.1912 (0.1826) teacher/usage_std 0.1611 (0.1418) nleep/row_max_mean 1498.6538 (1483.6029) nleep/row_max_std 36.3151 (47.2596) nleep/row_min_mean 1474.5208 (1456.7833) lr 9.3721e-04 eta 0:06:09
epoch [28/50] batch [160/176] time 0.078 (0.094) data 0.000 (0.002) loss 1.3124 (1.3866) teacher_loss 0.0348 (0.0946) loss_zs_kd 0.0521 (0.0568) loss_oracle 0.5626 (0.5653) kd_loss 0.9704 (0.9810) acc 100.0000 (97.2070) gate/entropy 1.0429 (1.0444) gate/usage_max 0.4884 (0.4856) gate/usage_min 0.2214 (0.2220) gate/usage_std 0.1132 (0.1115) teacher/entropy 0.0868 (0.0449) teacher/usage_max 0.4525 (0.5129) teacher/usage_min 0.2050 (0.1804) teacher/usage_std 0.1012 (0.1427) nleep/row_max_mean 1475.4646 (1483.2443) nleep/row_max_std 69.4935 (47.9486) nleep/row_min_mean 1449.0010 (1456.5290) lr 9.3721e-04 eta 0:06:07
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,133
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 89.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,846
* accuracy: 69.5%
* error: 30.5%
* macro_f1: 58.4%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [29/50] batch [20/176] time 0.084 (0.107) data 0.000 (0.016) loss 1.3824 (1.3922) teacher_loss 0.1177 (0.1006) loss_zs_kd 0.0423 (0.0585) loss_oracle 0.5579 (0.5616) kd_loss 0.9645 (0.9816) acc 96.8750 (97.1875) gate/entropy 1.0427 (1.0427) gate/usage_max 0.4887 (0.4887) gate/usage_min 0.2215 (0.2215) gate/usage_std 0.1133 (0.1133) teacher/entropy 0.0318 (0.0482) teacher/usage_max 0.4983 (0.5079) teacher/usage_min 0.0718 (0.1609) teacher/usage_std 0.1870 (0.1485) nleep/row_max_mean 1470.5288 (1480.2936) nleep/row_max_std 55.0436 (52.5042) nleep/row_min_mean 1445.4475 (1454.2956) lr 8.7467e-04 eta 0:06:53
epoch [29/50] batch [40/176] time 0.087 (0.098) data 0.000 (0.008) loss 1.3333 (1.3864) teacher_loss 0.0761 (0.1157) loss_zs_kd 0.0609 (0.0559) loss_oracle 0.4684 (0.5548) kd_loss 0.9926 (0.9655) acc 100.0000 (96.9531) gate/entropy 1.0424 (1.0426) gate/usage_max 0.4892 (0.4888) gate/usage_min 0.2213 (0.2214) gate/usage_std 0.1137 (0.1134) teacher/entropy 0.0852 (0.0528) teacher/usage_max 0.4688 (0.5163) teacher/usage_min 0.1480 (0.1506) teacher/usage_std 0.1356 (0.1563) nleep/row_max_mean 1470.2837 (1479.6842) nleep/row_max_std 64.2356 (53.2542) nleep/row_min_mean 1445.0243 (1453.7895) lr 8.7467e-04 eta 0:06:13
epoch [29/50] batch [60/176] time 0.092 (0.095) data 0.000 (0.006) loss 1.2236 (1.3768) teacher_loss 0.0623 (0.1050) loss_zs_kd 0.0480 (0.0551) loss_oracle 0.5338 (0.5599) kd_loss 0.8703 (0.9643) acc 96.8750 (97.0312) gate/entropy 1.0421 (1.0425) gate/usage_max 0.4896 (0.4889) gate/usage_min 0.2210 (0.2214) gate/usage_std 0.1139 (0.1135) teacher/entropy 0.0412 (0.0544) teacher/usage_max 0.6450 (0.5145) teacher/usage_min 0.0376 (0.1433) teacher/usage_std 0.2482 (0.1583) nleep/row_max_mean 1481.5653 (1479.5463) nleep/row_max_std 47.6108 (52.8900) nleep/row_min_mean 1454.6210 (1453.3660) lr 8.7467e-04 eta 0:06:02
epoch [29/50] batch [80/176] time 0.098 (0.093) data 0.000 (0.004) loss 1.3013 (1.3687) teacher_loss 0.0510 (0.0992) loss_zs_kd 0.0619 (0.0553) loss_oracle 0.5490 (0.5563) kd_loss 0.9448 (0.9637) acc 100.0000 (97.1875) gate/entropy 1.0421 (1.0425) gate/usage_max 0.4895 (0.4891) gate/usage_min 0.2208 (0.2213) gate/usage_std 0.1140 (0.1136) teacher/entropy 0.0698 (0.0547) teacher/usage_max 0.4997 (0.5136) teacher/usage_min 0.1402 (0.1371) teacher/usage_std 0.1480 (0.1604) nleep/row_max_mean 1478.9324 (1480.2124) nleep/row_max_std 53.9785 (52.4753) nleep/row_min_mean 1453.3301 (1453.8940) lr 8.7467e-04 eta 0:05:53
epoch [29/50] batch [100/176] time 0.103 (0.094) data 0.000 (0.003) loss 1.3951 (1.3717) teacher_loss 0.0262 (0.0981) loss_zs_kd 0.0541 (0.0553) loss_oracle 0.6234 (0.5612) kd_loss 1.0302 (0.9654) acc 100.0000 (97.2500) gate/entropy 1.0421 (1.0424) gate/usage_max 0.4895 (0.4891) gate/usage_min 0.2208 (0.2212) gate/usage_std 0.1140 (0.1137) teacher/entropy 0.0419 (0.0531) teacher/usage_max 0.4188 (0.5177) teacher/usage_min 0.1751 (0.1366) teacher/usage_std 0.1120 (0.1626) nleep/row_max_mean 1473.6863 (1479.3667) nleep/row_max_std 60.2767 (52.9624) nleep/row_min_mean 1447.3927 (1452.9662) lr 8.7467e-04 eta 0:05:54
epoch [29/50] batch [120/176] time 0.093 (0.094) data 0.000 (0.003) loss 1.5671 (1.3744) teacher_loss 0.1668 (0.0989) loss_zs_kd 0.0681 (0.0552) loss_oracle 0.5644 (0.5649) kd_loss 1.0841 (0.9655) acc 93.7500 (97.1354) gate/entropy 1.0421 (1.0423) gate/usage_max 0.4894 (0.4892) gate/usage_min 0.2207 (0.2211) gate/usage_std 0.1139 (0.1137) teacher/entropy 0.0404 (0.0520) teacher/usage_max 0.4131 (0.5171) teacher/usage_min 0.2445 (0.1365) teacher/usage_std 0.0692 (0.1626) nleep/row_max_mean 1475.3221 (1479.7641) nleep/row_max_std 58.8786 (52.6749) nleep/row_min_mean 1448.6729 (1453.3345) lr 8.7467e-04 eta 0:05:52
epoch [29/50] batch [140/176] time 0.088 (0.094) data 0.000 (0.003) loss 1.2669 (1.3685) teacher_loss 0.0168 (0.0965) loss_zs_kd 0.0530 (0.0548) loss_oracle 0.6670 (0.5636) kd_loss 0.8901 (0.9628) acc 100.0000 (97.1429) gate/entropy 1.0420 (1.0423) gate/usage_max 0.4895 (0.4893) gate/usage_min 0.2205 (0.2210) gate/usage_std 0.1140 (0.1138) teacher/entropy 0.0637 (0.0508) teacher/usage_max 0.6322 (0.5195) teacher/usage_min 0.1770 (0.1334) teacher/usage_std 0.2114 (0.1649) nleep/row_max_mean 1479.4635 (1479.9808) nleep/row_max_std 46.5005 (52.4635) nleep/row_min_mean 1452.0500 (1453.4809) lr 8.7467e-04 eta 0:05:50
epoch [29/50] batch [160/176] time 0.108 (0.094) data 0.000 (0.002) loss 1.4950 (1.3753) teacher_loss 0.1341 (0.0993) loss_zs_kd 0.0719 (0.0552) loss_oracle 0.6307 (0.5635) kd_loss 1.0097 (0.9667) acc 93.7500 (97.0312) gate/entropy 1.0416 (1.0422) gate/usage_max 0.4901 (0.4894) gate/usage_min 0.2202 (0.2209) gate/usage_std 0.1144 (0.1139) teacher/entropy 0.0264 (0.0500) teacher/usage_max 0.4689 (0.5150) teacher/usage_min 0.1600 (0.1352) teacher/usage_std 0.1289 (0.1621) nleep/row_max_mean 1472.7197 (1480.0755) nleep/row_max_std 56.7595 (52.8757) nleep/row_min_mean 1444.5374 (1453.5634) lr 8.7467e-04 eta 0:05:49
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,155
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 90.8%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,780
* accuracy: 67.0%
* error: 33.0%
* macro_f1: 59.7%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [30/50] batch [20/176] time 0.078 (0.129) data 0.000 (0.018) loss 1.4155 (1.3980) teacher_loss 0.0983 (0.0979) loss_zs_kd 0.0568 (0.0688) loss_oracle 0.5936 (0.5845) kd_loss 0.9920 (0.9734) acc 96.8750 (96.5625) gate/entropy 1.0415 (1.0414) gate/usage_max 0.4901 (0.4903) gate/usage_min 0.2198 (0.2199) gate/usage_std 0.1145 (0.1146) teacher/entropy 0.0358 (0.0412) teacher/usage_max 0.4682 (0.5038) teacher/usage_min 0.1333 (0.1111) teacher/usage_std 0.1443 (0.1690) nleep/row_max_mean 1471.6143 (1483.4962) nleep/row_max_std 57.8301 (52.4851) nleep/row_min_mean 1445.6992 (1455.2910) lr 8.1262e-04 eta 0:07:52
epoch [30/50] batch [40/176] time 0.159 (0.113) data 0.001 (0.009) loss 1.2552 (1.3686) teacher_loss 0.0375 (0.0976) loss_zs_kd 0.0598 (0.0581) loss_oracle 0.6214 (0.5696) kd_loss 0.8771 (0.9571) acc 100.0000 (96.7188) gate/entropy 1.0414 (1.0414) gate/usage_max 0.4902 (0.4904) gate/usage_min 0.2195 (0.2197) gate/usage_std 0.1146 (0.1147) teacher/entropy 0.0698 (0.0422) teacher/usage_max 0.5964 (0.5309) teacher/usage_min 0.0826 (0.1060) teacher/usage_std 0.2099 (0.1798) nleep/row_max_mean 1493.1069 (1481.0764) nleep/row_max_std 28.1327 (54.0206) nleep/row_min_mean 1466.7111 (1453.8966) lr 8.1262e-04 eta 0:06:51
epoch [30/50] batch [60/176] time 0.103 (0.106) data 0.000 (0.006) loss 1.3597 (1.3796) teacher_loss 0.1259 (0.1103) loss_zs_kd 0.0754 (0.0566) loss_oracle 0.6192 (0.5652) kd_loss 0.8865 (0.9584) acc 96.8750 (96.4583) gate/entropy 1.0412 (1.0413) gate/usage_max 0.4905 (0.4904) gate/usage_min 0.2193 (0.2196) gate/usage_std 0.1148 (0.1147) teacher/entropy 0.1091 (0.0479) teacher/usage_max 0.5059 (0.5209) teacher/usage_min 0.0856 (0.1062) teacher/usage_std 0.1796 (0.1760) nleep/row_max_mean 1461.7539 (1480.1753) nleep/row_max_std 60.8439 (53.8114) nleep/row_min_mean 1437.3932 (1453.2085) lr 8.1262e-04 eta 0:06:26
epoch [30/50] batch [80/176] time 0.094 (0.103) data 0.000 (0.005) loss 1.3764 (1.3735) teacher_loss 0.0374 (0.1040) loss_zs_kd 0.0417 (0.0558) loss_oracle 0.5731 (0.5641) kd_loss 1.0316 (0.9596) acc 100.0000 (96.6797) gate/entropy 1.0413 (1.0413) gate/usage_max 0.4902 (0.4903) gate/usage_min 0.2191 (0.2195) gate/usage_std 0.1147 (0.1147) teacher/entropy 0.0207 (0.0484) teacher/usage_max 0.4691 (0.5202) teacher/usage_min 0.1182 (0.1050) teacher/usage_std 0.1538 (0.1771) nleep/row_max_mean 1484.7927 (1480.7081) nleep/row_max_std 50.4454 (52.7358) nleep/row_min_mean 1455.1362 (1453.6306) lr 8.1262e-04 eta 0:06:11
epoch [30/50] batch [100/176] time 0.071 (0.099) data 0.000 (0.004) loss 1.5609 (1.3822) teacher_loss 0.0541 (0.1035) loss_zs_kd 0.0509 (0.0563) loss_oracle 0.6769 (0.5689) kd_loss 1.1429 (0.9661) acc 100.0000 (96.5312) gate/entropy 1.0409 (1.0413) gate/usage_max 0.4905 (0.4903) gate/usage_min 0.2186 (0.2194) gate/usage_std 0.1150 (0.1147) teacher/entropy 0.0243 (0.0479) teacher/usage_max 0.4440 (0.5197) teacher/usage_min 0.2762 (0.1072) teacher/usage_std 0.0783 (0.1757) nleep/row_max_mean 1480.6367 (1481.1225) nleep/row_max_std 62.8884 (52.6433) nleep/row_min_mean 1452.3293 (1453.8232) lr 8.1262e-04 eta 0:05:55
epoch [30/50] batch [120/176] time 0.087 (0.096) data 0.000 (0.003) loss 1.3742 (1.3771) teacher_loss 0.0800 (0.0981) loss_zs_kd 0.0724 (0.0567) loss_oracle 0.6149 (0.5699) kd_loss 0.9505 (0.9658) acc 100.0000 (96.7448) gate/entropy 1.0417 (1.0413) gate/usage_max 0.4892 (0.4903) gate/usage_min 0.2188 (0.2192) gate/usage_std 0.1142 (0.1147) teacher/entropy 0.0439 (0.0469) teacher/usage_max 0.4998 (0.5206) teacher/usage_min 0.0765 (0.1061) teacher/usage_std 0.1842 (0.1765) nleep/row_max_mean 1477.2883 (1481.2750) nleep/row_max_std 59.1491 (52.5001) nleep/row_min_mean 1447.4607 (1453.8756) lr 8.1262e-04 eta 0:05:44
epoch [30/50] batch [140/176] time 0.071 (0.094) data 0.000 (0.003) loss 1.5306 (1.3798) teacher_loss 0.2144 (0.1009) loss_zs_kd 0.1056 (0.0573) loss_oracle 0.5065 (0.5682) kd_loss 1.0102 (0.9661) acc 93.7500 (96.7634) gate/entropy 1.0413 (1.0413) gate/usage_max 0.4898 (0.4902) gate/usage_min 0.2183 (0.2191) gate/usage_std 0.1146 (0.1147) teacher/entropy 0.0186 (0.0475) teacher/usage_max 0.4712 (0.5177) teacher/usage_min 0.0888 (0.1085) teacher/usage_std 0.1734 (0.1745) nleep/row_max_mean 1489.1055 (1481.3142) nleep/row_max_std 51.9441 (52.4551) nleep/row_min_mean 1458.0817 (1453.8989) lr 8.1262e-04 eta 0:05:35
epoch [30/50] batch [160/176] time 0.093 (0.093) data 0.000 (0.003) loss 1.3411 (1.3797) teacher_loss 0.0248 (0.1015) loss_zs_kd 0.0492 (0.0573) loss_oracle 0.6125 (0.5693) kd_loss 0.9854 (0.9649) acc 100.0000 (96.6992) gate/entropy 1.0409 (1.0413) gate/usage_max 0.4903 (0.4901) gate/usage_min 0.2178 (0.2190) gate/usage_std 0.1150 (0.1147) teacher/entropy 0.0131 (0.0468) teacher/usage_max 0.4997 (0.5187) teacher/usage_min 0.0943 (0.1096) teacher/usage_std 0.1733 (0.1745) nleep/row_max_mean 1487.2883 (1481.1198) nleep/row_max_std 50.0800 (52.6114) nleep/row_min_mean 1455.5349 (1453.6144) lr 8.1262e-04 eta 0:05:30
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,159
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 90.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,779
* accuracy: 67.0%
* error: 33.0%
* macro_f1: 59.2%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [31/50] batch [20/176] time 0.086 (0.104) data 0.000 (0.017) loss 1.5481 (1.3539) teacher_loss 0.1548 (0.0874) loss_zs_kd 0.0569 (0.0532) loss_oracle 0.6232 (0.5546) kd_loss 1.0532 (0.9626) acc 96.8750 (97.5000) gate/entropy 1.0409 (1.0410) gate/usage_max 0.4901 (0.4900) gate/usage_min 0.2176 (0.2177) gate/usage_std 0.1150 (0.1149) teacher/entropy 0.0116 (0.0445) teacher/usage_max 0.5282 (0.5190) teacher/usage_min 0.0969 (0.1053) teacher/usage_std 0.1785 (0.1757) nleep/row_max_mean 1485.1267 (1479.9878) nleep/row_max_std 46.7104 (52.5581) nleep/row_min_mean 1453.4849 (1452.2083) lr 7.5131e-04 eta 0:06:05
epoch [31/50] batch [40/176] time 0.090 (0.095) data 0.000 (0.009) loss 1.4138 (1.3555) teacher_loss 0.1163 (0.0889) loss_zs_kd 0.0347 (0.0507) loss_oracle 0.5905 (0.5494) kd_loss 0.9848 (0.9665) acc 93.7500 (97.2656) gate/entropy 1.0411 (1.0410) gate/usage_max 0.4897 (0.4899) gate/usage_min 0.2174 (0.2176) gate/usage_std 0.1148 (0.1148) teacher/entropy 0.0368 (0.0384) teacher/usage_max 0.4967 (0.5169) teacher/usage_min 0.0663 (0.0992) teacher/usage_std 0.1904 (0.1787) nleep/row_max_mean 1492.5110 (1479.8442) nleep/row_max_std 41.6844 (51.6322) nleep/row_min_mean 1461.0613 (1451.6330) lr 7.5131e-04 eta 0:05:30
epoch [31/50] batch [60/176] time 0.082 (0.093) data 0.000 (0.006) loss 1.4925 (1.3446) teacher_loss 0.1985 (0.0836) loss_zs_kd 0.0543 (0.0531) loss_oracle 0.5369 (0.5502) kd_loss 0.9984 (0.9594) acc 90.6250 (97.3438) gate/entropy 1.0409 (1.0410) gate/usage_max 0.4899 (0.4899) gate/usage_min 0.2172 (0.2175) gate/usage_std 0.1149 (0.1149) teacher/entropy 0.0068 (0.0360) teacher/usage_max 0.4688 (0.5276) teacher/usage_min 0.0626 (0.0937) teacher/usage_std 0.1914 (0.1846) nleep/row_max_mean 1490.8403 (1479.5642) nleep/row_max_std 36.1061 (50.4533) nleep/row_min_mean 1457.8257 (1451.3070) lr 7.5131e-04 eta 0:05:20
epoch [31/50] batch [80/176] time 0.093 (0.091) data 0.000 (0.004) loss 1.4675 (1.3496) teacher_loss 0.1611 (0.0834) loss_zs_kd 0.0500 (0.0542) loss_oracle 0.5381 (0.5523) kd_loss 1.0124 (0.9630) acc 93.7500 (97.3828) gate/entropy 1.0404 (1.0409) gate/usage_max 0.4905 (0.4899) gate/usage_min 0.2168 (0.2174) gate/usage_std 0.1154 (0.1149) teacher/entropy 0.0470 (0.0351) teacher/usage_max 0.4519 (0.5273) teacher/usage_min 0.1400 (0.0914) teacher/usage_std 0.1379 (0.1853) nleep/row_max_mean 1484.5034 (1480.4733) nleep/row_max_std 54.7215 (50.1654) nleep/row_min_mean 1457.2383 (1451.8708) lr 7.5131e-04 eta 0:05:14
epoch [31/50] batch [100/176] time 0.084 (0.090) data 0.000 (0.004) loss 1.3872 (1.3592) teacher_loss 0.1156 (0.0894) loss_zs_kd 0.0420 (0.0535) loss_oracle 0.6556 (0.5542) kd_loss 0.9227 (0.9660) acc 93.7500 (97.1562) gate/entropy 1.0408 (1.0409) gate/usage_max 0.4898 (0.4899) gate/usage_min 0.2167 (0.2173) gate/usage_std 0.1150 (0.1149) teacher/entropy 0.0187 (0.0335) teacher/usage_max 0.5934 (0.5248) teacher/usage_min 0.0687 (0.0913) teacher/usage_std 0.2142 (0.1846) nleep/row_max_mean 1483.2029 (1481.0611) nleep/row_max_std 49.8659 (49.8762) nleep/row_min_mean 1453.5499 (1452.2923) lr 7.5131e-04 eta 0:05:08
epoch [31/50] batch [120/176] time 0.086 (0.090) data 0.000 (0.003) loss 1.5287 (1.3702) teacher_loss 0.2199 (0.0979) loss_zs_kd 0.0596 (0.0538) loss_oracle 0.5429 (0.5581) kd_loss 1.0076 (0.9664) acc 93.7500 (97.0052) gate/entropy 1.0406 (1.0408) gate/usage_max 0.4899 (0.4899) gate/usage_min 0.2165 (0.2171) gate/usage_std 0.1151 (0.1150) teacher/entropy 0.0241 (0.0321) teacher/usage_max 0.5597 (0.5256) teacher/usage_min 0.0388 (0.0929) teacher/usage_std 0.2180 (0.1839) nleep/row_max_mean 1488.7644 (1481.1811) nleep/row_max_std 49.5991 (50.2739) nleep/row_min_mean 1458.0288 (1452.2475) lr 7.5131e-04 eta 0:05:05
epoch [31/50] batch [140/176] time 0.093 (0.090) data 0.000 (0.003) loss 1.3470 (1.3655) teacher_loss 0.1361 (0.0961) loss_zs_kd 0.0586 (0.0536) loss_oracle 0.5459 (0.5575) kd_loss 0.9087 (0.9638) acc 93.7500 (97.1429) gate/entropy 1.0405 (1.0408) gate/usage_max 0.4900 (0.4900) gate/usage_min 0.2163 (0.2170) gate/usage_std 0.1152 (0.1150) teacher/entropy 0.0442 (0.0321) teacher/usage_max 0.5845 (0.5281) teacher/usage_min 0.0899 (0.0905) teacher/usage_std 0.2020 (0.1859) nleep/row_max_mean 1488.6055 (1481.4809) nleep/row_max_std 46.9135 (50.0117) nleep/row_min_mean 1457.1835 (1452.3817) lr 7.5131e-04 eta 0:05:03
epoch [31/50] batch [160/176] time 0.088 (0.092) data 0.000 (0.002) loss 1.3940 (1.3659) teacher_loss 0.1101 (0.0957) loss_zs_kd 0.0581 (0.0546) loss_oracle 0.6176 (0.5603) kd_loss 0.9461 (0.9628) acc 96.8750 (97.0508) gate/entropy 1.0407 (1.0407) gate/usage_max 0.4896 (0.4900) gate/usage_min 0.2160 (0.2169) gate/usage_std 0.1150 (0.1150) teacher/entropy 0.0343 (0.0308) teacher/usage_max 0.5359 (0.5317) teacher/usage_min 0.0999 (0.0859) teacher/usage_std 0.1793 (0.1892) nleep/row_max_mean 1481.7681 (1482.1479) nleep/row_max_std 46.9914 (49.3503) nleep/row_min_mean 1451.0364 (1452.7770) lr 7.5131e-04 eta 0:05:09
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,147
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 90.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,823
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 59.1%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [32/50] batch [20/176] time 0.092 (0.112) data 0.000 (0.014) loss 1.3877 (1.3482) teacher_loss 0.0500 (0.0655) loss_zs_kd 0.0658 (0.0638) loss_oracle 0.6622 (0.5934) kd_loss 0.9737 (0.9541) acc 100.0000 (98.1250) gate/entropy 1.0407 (1.0405) gate/usage_max 0.4892 (0.4896) gate/usage_min 0.2155 (0.2155) gate/usage_std 0.1149 (0.1152) teacher/entropy 0.0031 (0.0258) teacher/usage_max 0.5000 (0.5629) teacher/usage_min 0.0317 (0.0622) teacher/usage_std 0.2137 (0.2127) nleep/row_max_mean 1478.4409 (1484.8911) nleep/row_max_std 42.7616 (47.2360) nleep/row_min_mean 1446.2594 (1453.0904) lr 6.9098e-04 eta 0:06:11
epoch [32/50] batch [40/176] time 0.095 (0.104) data 0.000 (0.007) loss 1.1898 (1.3522) teacher_loss 0.0302 (0.0759) loss_zs_kd 0.0705 (0.0628) loss_oracle 0.5914 (0.5849) kd_loss 0.8286 (0.9525) acc 100.0000 (97.7344) gate/entropy 1.0405 (1.0404) gate/usage_max 0.4893 (0.4897) gate/usage_min 0.2152 (0.2154) gate/usage_std 0.1151 (0.1152) teacher/entropy 0.0282 (0.0233) teacher/usage_max 0.7339 (0.5612) teacher/usage_min 0.0312 (0.0578) teacher/usage_std 0.2952 (0.2141) nleep/row_max_mean 1488.6655 (1486.4165) nleep/row_max_std 35.6499 (46.5359) nleep/row_min_mean 1456.1951 (1454.2257) lr 6.9098e-04 eta 0:05:41
epoch [32/50] batch [60/176] time 0.092 (0.100) data 0.000 (0.005) loss 1.4421 (1.3641) teacher_loss 0.1545 (0.0879) loss_zs_kd 0.0245 (0.0600) loss_oracle 0.5219 (0.5848) kd_loss 1.0144 (0.9539) acc 96.8750 (97.5000) gate/entropy 1.0404 (1.0404) gate/usage_max 0.4895 (0.4897) gate/usage_min 0.2149 (0.2152) gate/usage_std 0.1152 (0.1153) teacher/entropy 0.0257 (0.0244) teacher/usage_max 0.5641 (0.5537) teacher/usage_min 0.0517 (0.0628) teacher/usage_std 0.2123 (0.2095) nleep/row_max_mean 1483.3757 (1485.9544) nleep/row_max_std 46.8523 (47.1478) nleep/row_min_mean 1452.0542 (1453.8736) lr 6.9098e-04 eta 0:05:29
epoch [32/50] batch [80/176] time 0.101 (0.098) data 0.000 (0.004) loss 1.3370 (1.3723) teacher_loss 0.0202 (0.0904) loss_zs_kd 0.0333 (0.0601) loss_oracle 0.5599 (0.5863) kd_loss 1.0202 (0.9587) acc 100.0000 (97.2656) gate/entropy 1.0407 (1.0403) gate/usage_max 0.4888 (0.4897) gate/usage_min 0.2149 (0.2151) gate/usage_std 0.1149 (0.1153) teacher/entropy 0.0290 (0.0237) teacher/usage_max 0.4776 (0.5464) teacher/usage_min 0.1155 (0.0655) teacher/usage_std 0.1567 (0.2055) nleep/row_max_mean 1490.0233 (1485.2467) nleep/row_max_std 52.2589 (47.7779) nleep/row_min_mean 1454.8190 (1452.8940) lr 6.9098e-04 eta 0:05:20
epoch [32/50] batch [100/176] time 0.097 (0.098) data 0.000 (0.003) loss 1.4577 (1.3709) teacher_loss 0.1090 (0.0898) loss_zs_kd 0.0631 (0.0604) loss_oracle 0.5532 (0.5868) kd_loss 1.0405 (0.9575) acc 93.7500 (97.2500) gate/entropy 1.0402 (1.0403) gate/usage_max 0.4894 (0.4896) gate/usage_min 0.2142 (0.2149) gate/usage_std 0.1154 (0.1153) teacher/entropy 0.0017 (0.0224) teacher/usage_max 0.6561 (0.5496) teacher/usage_min 0.0002 (0.0610) teacher/usage_std 0.2679 (0.2088) nleep/row_max_mean 1498.6747 (1485.2938) nleep/row_max_std 38.1279 (47.5859) nleep/row_min_mean 1461.6929 (1452.7346) lr 6.9098e-04 eta 0:05:16
epoch [32/50] batch [120/176] time 0.087 (0.097) data 0.000 (0.003) loss 1.2342 (1.3677) teacher_loss 0.0198 (0.0889) loss_zs_kd 0.0407 (0.0601) loss_oracle 0.5055 (0.5812) kd_loss 0.9413 (0.9581) acc 100.0000 (97.2656) gate/entropy 1.0404 (1.0403) gate/usage_max 0.4889 (0.4896) gate/usage_min 0.2141 (0.2148) gate/usage_std 0.1151 (0.1153) teacher/entropy 0.0194 (0.0224) teacher/usage_max 0.5069 (0.5491) teacher/usage_min 0.0001 (0.0595) teacher/usage_std 0.2357 (0.2095) nleep/row_max_mean 1492.0504 (1485.3207) nleep/row_max_std 41.8000 (47.9610) nleep/row_min_mean 1456.8438 (1452.6209) lr 6.9098e-04 eta 0:05:12
epoch [32/50] batch [140/176] time 0.092 (0.097) data 0.000 (0.002) loss 1.5007 (1.3712) teacher_loss 0.1977 (0.0913) loss_zs_kd 0.0604 (0.0604) loss_oracle 0.5776 (0.5817) kd_loss 0.9839 (0.9588) acc 96.8750 (97.2321) gate/entropy 1.0402 (1.0403) gate/usage_max 0.4891 (0.4895) gate/usage_min 0.2137 (0.2147) gate/usage_std 0.1153 (0.1153) teacher/entropy 0.0579 (0.0234) teacher/usage_max 0.5082 (0.5465) teacher/usage_min 0.0886 (0.0611) teacher/usage_std 0.1783 (0.2079) nleep/row_max_mean 1475.8793 (1484.3923) nleep/row_max_std 55.4295 (48.6918) nleep/row_min_mean 1443.7284 (1451.6086) lr 6.9098e-04 eta 0:05:09
epoch [32/50] batch [160/176] time 0.090 (0.097) data 0.000 (0.002) loss 1.4879 (1.3712) teacher_loss 0.1467 (0.0924) loss_zs_kd 0.0479 (0.0597) loss_oracle 0.5139 (0.5783) kd_loss 1.0603 (0.9598) acc 96.8750 (97.3242) gate/entropy 1.0401 (1.0403) gate/usage_max 0.4889 (0.4895) gate/usage_min 0.2134 (0.2145) gate/usage_std 0.1153 (0.1153) teacher/entropy 0.0091 (0.0235) teacher/usage_max 0.5627 (0.5466) teacher/usage_min 0.0919 (0.0616) teacher/usage_std 0.1924 (0.2072) nleep/row_max_mean 1484.4828 (1484.2401) nleep/row_max_std 54.5383 (49.1246) nleep/row_min_mean 1449.4937 (1451.3645) lr 6.9098e-04 eta 0:05:08
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,125
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 89.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,868
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 60.5%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [33/50] batch [20/176] time 0.104 (0.113) data 0.000 (0.014) loss 1.3361 (1.3582) teacher_loss 0.0541 (0.0779) loss_zs_kd 0.0724 (0.0653) loss_oracle 0.5344 (0.5809) kd_loss 0.9787 (0.9571) acc 100.0000 (97.8125) gate/entropy 1.0401 (1.0400) gate/usage_max 0.4886 (0.4889) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1152 (0.1154) teacher/entropy 0.0189 (0.0201) teacher/usage_max 0.5717 (0.5476) teacher/usage_min 0.0000 (0.0441) teacher/usage_std 0.2429 (0.2197) nleep/row_max_mean 1497.5629 (1488.4030) nleep/row_max_std 38.4794 (48.3665) nleep/row_min_mean 1456.3009 (1451.7221) lr 6.3188e-04 eta 0:05:57
epoch [33/50] batch [40/176] time 0.072 (0.113) data 0.000 (0.007) loss 1.2642 (1.3391) teacher_loss 0.0250 (0.0670) loss_zs_kd 0.0681 (0.0647) loss_oracle 0.5381 (0.5804) kd_loss 0.9361 (0.9496) acc 100.0000 (97.8906) gate/entropy 1.0399 (1.0400) gate/usage_max 0.4889 (0.4889) gate/usage_min 0.2125 (0.2128) gate/usage_std 0.1155 (0.1154) teacher/entropy 0.0208 (0.0199) teacher/usage_max 0.5287 (0.5587) teacher/usage_min 0.0304 (0.0409) teacher/usage_std 0.2172 (0.2222) nleep/row_max_mean 1491.7250 (1489.8906) nleep/row_max_std 47.5433 (47.7900) nleep/row_min_mean 1455.8518 (1452.9562) lr 6.3188e-04 eta 0:05:54
epoch [33/50] batch [60/176] time 0.095 (0.108) data 0.000 (0.005) loss 1.4369 (1.3417) teacher_loss 0.1280 (0.0707) loss_zs_kd 0.0487 (0.0623) loss_oracle 0.6556 (0.5764) kd_loss 0.9568 (0.9516) acc 93.7500 (97.9167) gate/entropy 1.0400 (1.0399) gate/usage_max 0.4885 (0.4889) gate/usage_min 0.2124 (0.2126) gate/usage_std 0.1153 (0.1154) teacher/entropy 0.0046 (0.0230) teacher/usage_max 0.5625 (0.5502) teacher/usage_min 0.0929 (0.0485) teacher/usage_std 0.1919 (0.2151) nleep/row_max_mean 1474.2529 (1486.6786) nleep/row_max_std 60.3935 (51.5695) nleep/row_min_mean 1437.7152 (1449.9158) lr 6.3188e-04 eta 0:05:35
epoch [33/50] batch [80/176] time 0.089 (0.104) data 0.000 (0.004) loss 1.3235 (1.3359) teacher_loss 0.0841 (0.0715) loss_zs_kd 0.0561 (0.0610) loss_oracle 0.6172 (0.5768) kd_loss 0.9027 (0.9455) acc 96.8750 (97.9297) gate/entropy 1.0402 (1.0399) gate/usage_max 0.4880 (0.4888) gate/usage_min 0.2122 (0.2125) gate/usage_std 0.1151 (0.1154) teacher/entropy 0.0068 (0.0245) teacher/usage_max 0.6247 (0.5558) teacher/usage_min 0.0304 (0.0448) teacher/usage_std 0.2428 (0.2183) nleep/row_max_mean 1480.0083 (1485.4153) nleep/row_max_std 58.0395 (52.3709) nleep/row_min_mean 1438.1826 (1448.3922) lr 6.3188e-04 eta 0:05:22
epoch [33/50] batch [100/176] time 0.089 (0.103) data 0.000 (0.003) loss 1.2349 (1.3295) teacher_loss 0.0126 (0.0700) loss_zs_kd 0.0322 (0.0609) loss_oracle 0.4861 (0.5696) kd_loss 0.9632 (0.9442) acc 100.0000 (98.0000) gate/entropy 1.0399 (1.0399) gate/usage_max 0.4883 (0.4887) gate/usage_min 0.2118 (0.2124) gate/usage_std 0.1153 (0.1154) teacher/entropy 0.0210 (0.0249) teacher/usage_max 0.5507 (0.5570) teacher/usage_min 0.0000 (0.0443) teacher/usage_std 0.2393 (0.2187) nleep/row_max_mean 1472.0939 (1484.9852) nleep/row_max_std 59.6854 (52.9789) nleep/row_min_mean 1439.0928 (1447.9253) lr 6.3188e-04 eta 0:05:14
epoch [33/50] batch [120/176] time 0.089 (0.101) data 0.000 (0.003) loss 1.2836 (1.3282) teacher_loss 0.0575 (0.0739) loss_zs_kd 0.0481 (0.0603) loss_oracle 0.4685 (0.5681) kd_loss 0.9678 (0.9401) acc 93.7500 (97.7865) gate/entropy 1.0398 (1.0399) gate/usage_max 0.4883 (0.4887) gate/usage_min 0.2115 (0.2122) gate/usage_std 0.1154 (0.1154) teacher/entropy 0.0060 (0.0266) teacher/usage_max 0.5300 (0.5588) teacher/usage_min 0.0000 (0.0432) teacher/usage_std 0.2370 (0.2199) nleep/row_max_mean 1488.5627 (1484.6248) nleep/row_max_std 40.8225 (53.2820) nleep/row_min_mean 1450.3362 (1447.6187) lr 6.3188e-04 eta 0:05:07
epoch [33/50] batch [140/176] time 0.101 (0.101) data 0.000 (0.002) loss 1.3726 (1.3291) teacher_loss 0.1238 (0.0759) loss_zs_kd 0.0629 (0.0613) loss_oracle 0.6056 (0.5697) kd_loss 0.9145 (0.9377) acc 93.7500 (97.7455) gate/entropy 1.0395 (1.0398) gate/usage_max 0.4887 (0.4887) gate/usage_min 0.2111 (0.2121) gate/usage_std 0.1157 (0.1155) teacher/entropy 0.0184 (0.0278) teacher/usage_max 0.5539 (0.5595) teacher/usage_min 0.0000 (0.0426) teacher/usage_std 0.2398 (0.2201) nleep/row_max_mean 1484.3136 (1483.9966) nleep/row_max_std 50.3826 (53.5496) nleep/row_min_mean 1449.0631 (1446.9807) lr 6.3188e-04 eta 0:05:04
epoch [33/50] batch [160/176] time 0.101 (0.100) data 0.000 (0.002) loss 1.2448 (1.3251) teacher_loss 0.0868 (0.0761) loss_zs_kd 0.0485 (0.0612) loss_oracle 0.5065 (0.5697) kd_loss 0.8805 (0.9336) acc 96.8750 (97.7539) gate/entropy 1.0398 (1.0398) gate/usage_max 0.4879 (0.4886) gate/usage_min 0.2110 (0.2119) gate/usage_std 0.1153 (0.1155) teacher/entropy 0.0016 (0.0279) teacher/usage_max 0.6560 (0.5637) teacher/usage_min 0.0000 (0.0404) teacher/usage_std 0.2679 (0.2223) nleep/row_max_mean 1482.3793 (1483.3950) nleep/row_max_std 45.9945 (53.2184) nleep/row_min_mean 1443.7441 (1446.4160) lr 6.3188e-04 eta 0:04:59
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,173
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,804
* accuracy: 67.9%
* error: 32.1%
* macro_f1: 60.2%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [34/50] batch [20/176] time 0.093 (0.109) data 0.000 (0.017) loss 1.3508 (1.3120) teacher_loss 0.1245 (0.0894) loss_zs_kd 0.0788 (0.0514) loss_oracle 0.5614 (0.5676) kd_loss 0.9062 (0.9131) acc 96.8750 (97.6562) gate/entropy 1.0395 (1.0393) gate/usage_max 0.4882 (0.4885) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.1156 (0.1158) teacher/entropy 0.0377 (0.0371) teacher/usage_max 0.5659 (0.5625) teacher/usage_min 0.0511 (0.0362) teacher/usage_std 0.2131 (0.2246) nleep/row_max_mean 1481.0291 (1479.0814) nleep/row_max_std 52.9181 (53.2314) nleep/row_min_mean 1445.1396 (1443.7073) lr 5.7422e-04 eta 0:05:23
epoch [34/50] batch [40/176] time 0.088 (0.101) data 0.000 (0.009) loss 1.3050 (1.3237) teacher_loss 0.0306 (0.0902) loss_zs_kd 0.0569 (0.0546) loss_oracle 0.6331 (0.5896) kd_loss 0.9295 (0.9114) acc 100.0000 (97.5781) gate/entropy 1.0392 (1.0393) gate/usage_max 0.4885 (0.4885) gate/usage_min 0.2101 (0.2104) gate/usage_std 0.1159 (0.1158) teacher/entropy 0.0342 (0.0359) teacher/usage_max 0.5065 (0.5680) teacher/usage_min 0.0242 (0.0318) teacher/usage_std 0.2191 (0.2283) nleep/row_max_mean 1478.8342 (1477.8424) nleep/row_max_std 53.4720 (53.8039) nleep/row_min_mean 1441.8848 (1442.3432) lr 5.7422e-04 eta 0:04:58
epoch [34/50] batch [60/176] time 0.085 (0.098) data 0.001 (0.006) loss 1.3075 (1.3283) teacher_loss 0.0601 (0.0848) loss_zs_kd 0.0576 (0.0564) loss_oracle 0.6091 (0.5926) kd_loss 0.9140 (0.9190) acc 96.8750 (97.5000) gate/entropy 1.0395 (1.0393) gate/usage_max 0.4878 (0.4884) gate/usage_min 0.2100 (0.2102) gate/usage_std 0.1155 (0.1158) teacher/entropy 0.0247 (0.0305) teacher/usage_max 0.5382 (0.5633) teacher/usage_min 0.0005 (0.0253) teacher/usage_std 0.2374 (0.2307) nleep/row_max_mean 1475.9614 (1480.0797) nleep/row_max_std 50.4329 (52.2695) nleep/row_min_mean 1441.1949 (1444.2032) lr 5.7422e-04 eta 0:04:47
epoch [34/50] batch [80/176] time 0.094 (0.098) data 0.000 (0.004) loss 1.1242 (1.3249) teacher_loss 0.0175 (0.0823) loss_zs_kd 0.0555 (0.0575) loss_oracle 0.5024 (0.5900) kd_loss 0.8277 (0.9188) acc 100.0000 (97.5391) gate/entropy 1.0395 (1.0393) gate/usage_max 0.4876 (0.4883) gate/usage_min 0.2097 (0.2101) gate/usage_std 0.1155 (0.1158) teacher/entropy 0.0095 (0.0312) teacher/usage_max 0.7481 (0.5635) teacher/usage_min 0.0007 (0.0238) teacher/usage_std 0.3106 (0.2313) nleep/row_max_mean 1474.6444 (1480.2279) nleep/row_max_std 42.5017 (52.7062) nleep/row_min_mean 1440.4448 (1444.0607) lr 5.7422e-04 eta 0:04:45
epoch [34/50] batch [100/176] time 0.093 (0.098) data 0.001 (0.004) loss 1.4746 (1.3209) teacher_loss 0.1505 (0.0828) loss_zs_kd 0.0560 (0.0572) loss_oracle 0.5723 (0.5875) kd_loss 1.0099 (0.9157) acc 96.8750 (97.4688) gate/entropy 1.0394 (1.0393) gate/usage_max 0.4875 (0.4882) gate/usage_min 0.2093 (0.2100) gate/usage_std 0.1155 (0.1158) teacher/entropy 0.0046 (0.0330) teacher/usage_max 0.6260 (0.5689) teacher/usage_min 0.0000 (0.0224) teacher/usage_std 0.2572 (0.2335) nleep/row_max_mean 1494.3655 (1480.4938) nleep/row_max_std 47.0171 (53.1769) nleep/row_min_mean 1452.1932 (1444.1862) lr 5.7422e-04 eta 0:04:42
epoch [34/50] batch [120/176] time 0.092 (0.097) data 0.000 (0.003) loss 1.2686 (1.3200) teacher_loss 0.0629 (0.0819) loss_zs_kd 0.0479 (0.0563) loss_oracle 0.5496 (0.5836) kd_loss 0.9070 (0.9181) acc 96.8750 (97.4479) gate/entropy 1.0394 (1.0393) gate/usage_max 0.4874 (0.4881) gate/usage_min 0.2090 (0.2098) gate/usage_std 0.1156 (0.1158) teacher/entropy 0.0378 (0.0323) teacher/usage_max 0.5184 (0.5673) teacher/usage_min 0.0000 (0.0211) teacher/usage_std 0.2362 (0.2337) nleep/row_max_mean 1497.0131 (1481.0466) nleep/row_max_std 44.6507 (53.1058) nleep/row_min_mean 1458.5096 (1444.5810) lr 5.7422e-04 eta 0:04:38
epoch [34/50] batch [140/176] time 0.097 (0.097) data 0.000 (0.003) loss 1.4108 (1.3187) teacher_loss 0.1166 (0.0840) loss_zs_kd 0.0598 (0.0555) loss_oracle 0.6275 (0.5826) kd_loss 0.9507 (0.9156) acc 96.8750 (97.4330) gate/entropy 1.0394 (1.0393) gate/usage_max 0.4871 (0.4880) gate/usage_min 0.2087 (0.2097) gate/usage_std 0.1155 (0.1158) teacher/entropy 0.0225 (0.0327) teacher/usage_max 0.5176 (0.5694) teacher/usage_min 0.0136 (0.0201) teacher/usage_std 0.2269 (0.2346) nleep/row_max_mean 1482.0223 (1481.1517) nleep/row_max_std 55.2580 (53.0679) nleep/row_min_mean 1446.9836 (1444.6960) lr 5.7422e-04 eta 0:04:36
epoch [34/50] batch [160/176] time 0.179 (0.100) data 0.000 (0.002) loss 1.3188 (1.3262) teacher_loss 0.1061 (0.0926) loss_zs_kd 0.0438 (0.0557) loss_oracle 0.6134 (0.5809) kd_loss 0.8841 (0.9153) acc 90.6250 (97.1484) gate/entropy 1.0393 (1.0393) gate/usage_max 0.4871 (0.4879) gate/usage_min 0.2084 (0.2095) gate/usage_std 0.1156 (0.1157) teacher/entropy 0.0298 (0.0332) teacher/usage_max 0.5846 (0.5690) teacher/usage_min 0.0013 (0.0191) teacher/usage_std 0.2449 (0.2350) nleep/row_max_mean 1480.4805 (1481.0320) nleep/row_max_std 50.2763 (53.3175) nleep/row_min_mean 1442.9434 (1444.5377) lr 5.7422e-04 eta 0:04:41
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,164
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,811
* accuracy: 68.2%
* error: 31.8%
* macro_f1: 61.0%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [35/50] batch [20/176] time 0.108 (0.104) data 0.000 (0.012) loss 1.3165 (1.3388) teacher_loss 0.0961 (0.0910) loss_zs_kd 0.0444 (0.0557) loss_oracle 0.6274 (0.5729) kd_loss 0.8844 (0.9335) acc 96.8750 (97.6562) gate/entropy 1.0390 (1.0392) gate/usage_max 0.4869 (0.4868) gate/usage_min 0.2076 (0.2078) gate/usage_std 0.1157 (0.1156) teacher/entropy 0.0264 (0.0234) teacher/usage_max 0.5876 (0.5762) teacher/usage_min 0.0002 (0.0054) teacher/usage_std 0.2462 (0.2429) nleep/row_max_mean 1481.8883 (1482.7323) nleep/row_max_std 59.4552 (52.8692) nleep/row_min_mean 1443.4637 (1445.4627) lr 5.1825e-04 eta 0:04:49
epoch [35/50] batch [40/176] time 0.090 (0.100) data 0.000 (0.006) loss 1.3478 (1.3489) teacher_loss 0.1351 (0.1009) loss_zs_kd 0.0563 (0.0557) loss_oracle 0.6065 (0.5805) kd_loss 0.8814 (0.9300) acc 96.8750 (96.9531) gate/entropy 1.0392 (1.0393) gate/usage_max 0.4864 (0.4866) gate/usage_min 0.2074 (0.2077) gate/usage_std 0.1155 (0.1155) teacher/entropy 0.0253 (0.0256) teacher/usage_max 0.6245 (0.5692) teacher/usage_min 0.0331 (0.0068) teacher/usage_std 0.2415 (0.2417) nleep/row_max_mean 1465.3882 (1482.9624) nleep/row_max_std 65.1442 (52.2214) nleep/row_min_mean 1432.6869 (1445.4324) lr 5.1825e-04 eta 0:04:38
epoch [35/50] batch [60/176] time 0.100 (0.099) data 0.001 (0.004) loss 1.3064 (1.3463) teacher_loss 0.0362 (0.1020) loss_zs_kd 0.0597 (0.0563) loss_oracle 0.6500 (0.5864) kd_loss 0.9153 (0.9229) acc 100.0000 (97.1354) gate/entropy 1.0394 (1.0393) gate/usage_max 0.4859 (0.4864) gate/usage_min 0.2072 (0.2076) gate/usage_std 0.1153 (0.1155) teacher/entropy 0.0175 (0.0243) teacher/usage_max 0.5385 (0.5733) teacher/usage_min 0.0001 (0.0065) teacher/usage_std 0.2377 (0.2433) nleep/row_max_mean 1486.1631 (1482.7803) nleep/row_max_std 43.1345 (51.4150) nleep/row_min_mean 1444.0869 (1445.2459) lr 5.1825e-04 eta 0:04:33
epoch [35/50] batch [80/176] time 0.097 (0.099) data 0.000 (0.003) loss 1.3683 (1.3368) teacher_loss 0.0261 (0.0978) loss_zs_kd 0.0816 (0.0558) loss_oracle 0.6402 (0.5824) kd_loss 0.9812 (0.9199) acc 100.0000 (97.1875) gate/entropy 1.0392 (1.0393) gate/usage_max 0.4859 (0.4863) gate/usage_min 0.2067 (0.2074) gate/usage_std 0.1155 (0.1154) teacher/entropy 0.0109 (0.0262) teacher/usage_max 0.5914 (0.5716) teacher/usage_min 0.0000 (0.0078) teacher/usage_std 0.2472 (0.2424) nleep/row_max_mean 1497.6620 (1482.6910) nleep/row_max_std 42.6442 (51.2685) nleep/row_min_mean 1455.1006 (1445.1306) lr 5.1825e-04 eta 0:04:31
epoch [35/50] batch [100/176] time 0.097 (0.099) data 0.000 (0.003) loss 1.3368 (1.3347) teacher_loss 0.0713 (0.0923) loss_zs_kd 0.0697 (0.0559) loss_oracle 0.5419 (0.5848) kd_loss 0.9597 (0.9221) acc 96.8750 (97.3438) gate/entropy 1.0394 (1.0393) gate/usage_max 0.4854 (0.4862) gate/usage_min 0.2067 (0.2073) gate/usage_std 0.1152 (0.1154) teacher/entropy 0.0037 (0.0246) teacher/usage_max 0.5311 (0.5682) teacher/usage_min 0.0000 (0.0073) teacher/usage_std 0.2371 (0.2418) nleep/row_max_mean 1490.8762 (1483.4490) nleep/row_max_std 38.0294 (50.6031) nleep/row_min_mean 1451.3060 (1445.7434) lr 5.1825e-04 eta 0:04:30
epoch [35/50] batch [120/176] time 0.101 (0.099) data 0.000 (0.002) loss 1.2584 (1.3316) teacher_loss 0.0466 (0.0936) loss_zs_kd 0.0737 (0.0558) loss_oracle 0.6610 (0.5860) kd_loss 0.8444 (0.9171) acc 100.0000 (97.2396) gate/entropy 1.0391 (1.0393) gate/usage_max 0.4857 (0.4860) gate/usage_min 0.2063 (0.2072) gate/usage_std 0.1155 (0.1154) teacher/entropy 0.0259 (0.0236) teacher/usage_max 0.6733 (0.5719) teacher/usage_min 0.0000 (0.0065) teacher/usage_std 0.2749 (0.2430) nleep/row_max_mean 1470.0393 (1483.2696) nleep/row_max_std 52.7745 (49.8798) nleep/row_min_mean 1434.8208 (1445.6464) lr 5.1825e-04 eta 0:04:27
epoch [35/50] batch [140/176] time 0.099 (0.099) data 0.000 (0.002) loss 1.3138 (1.3279) teacher_loss 0.0227 (0.0887) loss_zs_kd 0.1038 (0.0565) loss_oracle 0.6281 (0.5874) kd_loss 0.9251 (0.9173) acc 100.0000 (97.3884) gate/entropy 1.0392 (1.0393) gate/usage_max 0.4852 (0.4859) gate/usage_min 0.2061 (0.2070) gate/usage_std 0.1153 (0.1154) teacher/entropy 0.0310 (0.0235) teacher/usage_max 0.5128 (0.5683) teacher/usage_min 0.0325 (0.0063) teacher/usage_std 0.2141 (0.2423) nleep/row_max_mean 1488.1951 (1483.9501) nleep/row_max_std 58.5612 (49.4855) nleep/row_min_mean 1447.5337 (1446.1493) lr 5.1825e-04 eta 0:04:25
epoch [35/50] batch [160/176] time 0.096 (0.098) data 0.000 (0.002) loss 1.3615 (1.3353) teacher_loss 0.0553 (0.0943) loss_zs_kd 0.0956 (0.0576) loss_oracle 0.6311 (0.5869) kd_loss 0.9429 (0.9187) acc 100.0000 (97.3242) gate/entropy 1.0392 (1.0393) gate/usage_max 0.4849 (0.4858) gate/usage_min 0.2058 (0.2069) gate/usage_std 0.1152 (0.1154) teacher/entropy 0.0064 (0.0237) teacher/usage_max 0.5000 (0.5657) teacher/usage_min 0.0015 (0.0068) teacher/usage_std 0.2346 (0.2416) nleep/row_max_mean 1491.2300 (1483.9235) nleep/row_max_std 49.1955 (49.6311) nleep/row_min_mean 1449.4114 (1445.9763) lr 5.1825e-04 eta 0:04:21
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,156
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,816
* accuracy: 68.4%
* error: 31.6%
* macro_f1: 59.9%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [36/50] batch [20/176] time 0.087 (0.110) data 0.000 (0.015) loss 1.1911 (1.3188) teacher_loss 0.0550 (0.0899) loss_zs_kd 0.0389 (0.0532) loss_oracle 0.5492 (0.5790) kd_loss 0.8422 (0.9129) acc 96.8750 (96.8750) gate/entropy 1.0392 (1.0392) gate/usage_max 0.4846 (0.4847) gate/usage_min 0.2054 (0.2054) gate/usage_std 0.1152 (0.1152) teacher/entropy 0.0364 (0.0223) teacher/usage_max 0.6553 (0.5914) teacher/usage_min 0.0015 (0.0058) teacher/usage_std 0.2670 (0.2481) nleep/row_max_mean 1481.2073 (1481.3148) nleep/row_max_std 61.9408 (58.6262) nleep/row_min_mean 1445.6473 (1443.5932) lr 4.6417e-04 eta 0:04:48
epoch [36/50] batch [40/176] time 0.119 (0.112) data 0.000 (0.007) loss 1.2650 (1.2984) teacher_loss 0.0494 (0.0762) loss_zs_kd 0.0316 (0.0541) loss_oracle 0.5232 (0.5706) kd_loss 0.9382 (0.9099) acc 96.8750 (97.3438) gate/entropy 1.0393 (1.0392) gate/usage_max 0.4843 (0.4846) gate/usage_min 0.2052 (0.2053) gate/usage_std 0.1151 (0.1152) teacher/entropy 0.0249 (0.0255) teacher/usage_max 0.5364 (0.5825) teacher/usage_min 0.0011 (0.0083) teacher/usage_std 0.2369 (0.2443) nleep/row_max_mean 1481.8669 (1480.5980) nleep/row_max_std 60.0662 (58.0170) nleep/row_min_mean 1445.2971 (1442.7292) lr 4.6417e-04 eta 0:04:51
epoch [36/50] batch [60/176] time 0.095 (0.106) data 0.001 (0.005) loss 1.2630 (1.3077) teacher_loss 0.0162 (0.0808) loss_zs_kd 0.0583 (0.0562) loss_oracle 0.6085 (0.5739) kd_loss 0.9135 (0.9119) acc 100.0000 (97.3958) gate/entropy 1.0394 (1.0392) gate/usage_max 0.4839 (0.4845) gate/usage_min 0.2050 (0.2052) gate/usage_std 0.1149 (0.1152) teacher/entropy 0.0265 (0.0276) teacher/usage_max 0.5146 (0.5740) teacher/usage_min 0.0005 (0.0082) teacher/usage_std 0.2356 (0.2422) nleep/row_max_mean 1479.7493 (1480.1844) nleep/row_max_std 52.6176 (57.6130) nleep/row_min_mean 1441.1428 (1442.3768) lr 4.6417e-04 eta 0:04:34
epoch [36/50] batch [80/176] time 0.099 (0.104) data 0.000 (0.004) loss 1.3192 (1.3047) teacher_loss 0.0683 (0.0828) loss_zs_kd 0.0786 (0.0550) loss_oracle 0.5984 (0.5744) kd_loss 0.9124 (0.9072) acc 96.8750 (97.3438) gate/entropy 1.0390 (1.0392) gate/usage_max 0.4843 (0.4843) gate/usage_min 0.2045 (0.2051) gate/usage_std 0.1153 (0.1151) teacher/entropy 0.0045 (0.0278) teacher/usage_max 0.5634 (0.5765) teacher/usage_min 0.0000 (0.0089) teacher/usage_std 0.2413 (0.2426) nleep/row_max_mean 1492.5449 (1480.5021) nleep/row_max_std 44.2796 (56.7892) nleep/row_min_mean 1452.9558 (1442.7661) lr 4.6417e-04 eta 0:04:26
epoch [36/50] batch [100/176] time 0.097 (0.102) data 0.000 (0.003) loss 1.3156 (1.3014) teacher_loss 0.0789 (0.0806) loss_zs_kd 0.0427 (0.0547) loss_oracle 0.6068 (0.5778) kd_loss 0.9120 (0.9046) acc 93.7500 (97.3125) gate/entropy 1.0390 (1.0392) gate/usage_max 0.4841 (0.4843) gate/usage_min 0.2043 (0.2050) gate/usage_std 0.1153 (0.1151) teacher/entropy 0.0319 (0.0276) teacher/usage_max 0.5070 (0.5780) teacher/usage_min 0.0054 (0.0090) teacher/usage_std 0.2320 (0.2428) nleep/row_max_mean 1486.6702 (1480.5814) nleep/row_max_std 53.4673 (56.3370) nleep/row_min_mean 1449.0642 (1442.7863) lr 4.6417e-04 eta 0:04:18
epoch [36/50] batch [120/176] time 0.101 (0.101) data 0.000 (0.003) loss 1.3947 (1.3047) teacher_loss 0.1153 (0.0809) loss_zs_kd 0.0678 (0.0552) loss_oracle 0.5899 (0.5761) kd_loss 0.9505 (0.9082) acc 96.8750 (97.2917) gate/entropy 1.0390 (1.0392) gate/usage_max 0.4838 (0.4842) gate/usage_min 0.2041 (0.2049) gate/usage_std 0.1152 (0.1151) teacher/entropy 0.0076 (0.0268) teacher/usage_max 0.4993 (0.5754) teacher/usage_min 0.0311 (0.0089) teacher/usage_std 0.2141 (0.2422) nleep/row_max_mean 1488.7040 (1480.8741) nleep/row_max_std 57.1593 (55.9546) nleep/row_min_mean 1448.3853 (1442.9984) lr 4.6417e-04 eta 0:04:15
epoch [36/50] batch [140/176] time 0.089 (0.099) data 0.000 (0.002) loss 1.2551 (1.3091) teacher_loss 0.0172 (0.0836) loss_zs_kd 0.0580 (0.0559) loss_oracle 0.5593 (0.5765) kd_loss 0.9293 (0.9094) acc 100.0000 (97.2321) gate/entropy 1.0393 (1.0392) gate/usage_max 0.4833 (0.4841) gate/usage_min 0.2041 (0.2048) gate/usage_std 0.1149 (0.1151) teacher/entropy 0.0011 (0.0253) teacher/usage_max 0.5313 (0.5730) teacher/usage_min 0.0002 (0.0082) teacher/usage_std 0.2370 (0.2419) nleep/row_max_mean 1499.3271 (1481.4660) nleep/row_max_std 41.1402 (55.2891) nleep/row_min_mean 1455.1508 (1443.4419) lr 4.6417e-04 eta 0:04:08
epoch [36/50] batch [160/176] time 0.088 (0.097) data 0.000 (0.002) loss 1.3217 (1.3079) teacher_loss 0.0736 (0.0826) loss_zs_kd 0.0374 (0.0555) loss_oracle 0.5758 (0.5771) kd_loss 0.9415 (0.9089) acc 96.8750 (97.3438) gate/entropy 1.0392 (1.0392) gate/usage_max 0.4833 (0.4840) gate/usage_min 0.2039 (0.2047) gate/usage_std 0.1150 (0.1151) teacher/entropy 0.0220 (0.0249) teacher/usage_max 0.5453 (0.5748) teacher/usage_min 0.0000 (0.0077) teacher/usage_std 0.2386 (0.2427) nleep/row_max_mean 1478.4424 (1481.5704) nleep/row_max_std 48.9395 (55.0322) nleep/row_min_mean 1444.5768 (1443.5932) lr 4.6417e-04 eta 0:04:01
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,166
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,797
* accuracy: 67.7%
* error: 32.3%
* macro_f1: 60.1%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [37/50] batch [20/176] time 0.094 (0.106) data 0.000 (0.013) loss 1.2961 (1.3341) teacher_loss 0.1302 (0.1166) loss_zs_kd 0.0449 (0.0510) loss_oracle 0.5452 (0.5720) kd_loss 0.8708 (0.9060) acc 93.7500 (96.7188) gate/entropy 1.0390 (1.0391) gate/usage_max 0.4831 (0.4832) gate/usage_min 0.2034 (0.2035) gate/usage_std 0.1151 (0.1150) teacher/entropy 0.0048 (0.0325) teacher/usage_max 0.6553 (0.5583) teacher/usage_min 0.0000 (0.0084) teacher/usage_std 0.2677 (0.2381) nleep/row_max_mean 1477.5186 (1477.4507) nleep/row_max_std 51.5173 (53.8523) nleep/row_min_mean 1440.8740 (1440.5544) lr 4.1221e-04 eta 0:04:19
epoch [37/50] batch [40/176] time 0.096 (0.101) data 0.000 (0.007) loss 1.4253 (1.3242) teacher_loss 0.2135 (0.1112) loss_zs_kd 0.0533 (0.0527) loss_oracle 0.6454 (0.5697) kd_loss 0.8625 (0.9017) acc 96.8750 (97.1094) gate/entropy 1.0393 (1.0391) gate/usage_max 0.4825 (0.4831) gate/usage_min 0.2035 (0.2034) gate/usage_std 0.1147 (0.1150) teacher/entropy 0.1049 (0.0307) teacher/usage_max 0.5090 (0.5636) teacher/usage_min 0.0244 (0.0070) teacher/usage_std 0.2191 (0.2408) nleep/row_max_mean 1481.5547 (1479.2582) nleep/row_max_std 44.4673 (52.9368) nleep/row_min_mean 1443.8459 (1442.0962) lr 4.1221e-04 eta 0:04:05
epoch [37/50] batch [60/176] time 0.101 (0.099) data 0.001 (0.005) loss 1.2905 (1.3220) teacher_loss 0.0338 (0.1057) loss_zs_kd 0.0601 (0.0546) loss_oracle 0.6448 (0.5729) kd_loss 0.9042 (0.9025) acc 100.0000 (97.0833) gate/entropy 1.0390 (1.0390) gate/usage_max 0.4829 (0.4830) gate/usage_min 0.2030 (0.2033) gate/usage_std 0.1151 (0.1150) teacher/entropy 0.0126 (0.0284) teacher/usage_max 0.5583 (0.5671) teacher/usage_min 0.0000 (0.0080) teacher/usage_std 0.2405 (0.2404) nleep/row_max_mean 1493.6642 (1480.5614) nleep/row_max_std 46.9915 (52.0209) nleep/row_min_mean 1451.1781 (1443.2053) lr 4.1221e-04 eta 0:03:57
epoch [37/50] batch [80/176] time 0.095 (0.098) data 0.000 (0.004) loss 1.3122 (1.3139) teacher_loss 0.0977 (0.0988) loss_zs_kd 0.0491 (0.0537) loss_oracle 0.5654 (0.5687) kd_loss 0.9073 (0.9039) acc 93.7500 (97.1484) gate/entropy 1.0389 (1.0390) gate/usage_max 0.4828 (0.4830) gate/usage_min 0.2027 (0.2032) gate/usage_std 0.1151 (0.1150) teacher/entropy 0.0181 (0.0285) teacher/usage_max 0.5365 (0.5693) teacher/usage_min 0.0000 (0.0072) teacher/usage_std 0.2376 (0.2413) nleep/row_max_mean 1479.7531 (1481.8708) nleep/row_max_std 56.7992 (51.6559) nleep/row_min_mean 1442.7319 (1444.5487) lr 4.1221e-04 eta 0:03:54
epoch [37/50] batch [100/176] time 0.108 (0.099) data 0.000 (0.003) loss 1.3539 (1.3096) teacher_loss 0.1595 (0.0997) loss_zs_kd 0.0297 (0.0528) loss_oracle 0.5166 (0.5672) kd_loss 0.9212 (0.8999) acc 96.8750 (97.1250) gate/entropy 1.0388 (1.0390) gate/usage_max 0.4828 (0.4829) gate/usage_min 0.2025 (0.2031) gate/usage_std 0.1152 (0.1150) teacher/entropy 0.0270 (0.0287) teacher/usage_max 0.5151 (0.5735) teacher/usage_min 0.0001 (0.0068) teacher/usage_std 0.2360 (0.2430) nleep/row_max_mean 1477.7661 (1481.5811) nleep/row_max_std 55.2174 (51.1129) nleep/row_min_mean 1443.8365 (1444.3634) lr 4.1221e-04 eta 0:03:53
epoch [37/50] batch [120/176] time 0.093 (0.098) data 0.000 (0.002) loss 1.3266 (1.3140) teacher_loss 0.0642 (0.1027) loss_zs_kd 0.0651 (0.0516) loss_oracle 0.5775 (0.5704) kd_loss 0.9411 (0.9004) acc 100.0000 (96.9531) gate/entropy 1.0389 (1.0390) gate/usage_max 0.4824 (0.4828) gate/usage_min 0.2025 (0.2030) gate/usage_std 0.1150 (0.1150) teacher/entropy 0.0006 (0.0274) teacher/usage_max 0.5001 (0.5741) teacher/usage_min 0.0000 (0.0062) teacher/usage_std 0.2357 (0.2436) nleep/row_max_mean 1485.0217 (1481.7683) nleep/row_max_std 49.9972 (51.1197) nleep/row_min_mean 1444.4648 (1444.4844) lr 4.1221e-04 eta 0:03:50
epoch [37/50] batch [140/176] time 0.097 (0.098) data 0.000 (0.002) loss 1.2627 (1.3139) teacher_loss 0.1331 (0.1040) loss_zs_kd 0.0445 (0.0511) loss_oracle 0.4378 (0.5697) kd_loss 0.8884 (0.8995) acc 93.7500 (96.9420) gate/entropy 1.0389 (1.0390) gate/usage_max 0.4822 (0.4827) gate/usage_min 0.2022 (0.2029) gate/usage_std 0.1150 (0.1150) teacher/entropy 0.0433 (0.0275) teacher/usage_max 0.5222 (0.5756) teacher/usage_min 0.0000 (0.0066) teacher/usage_std 0.2364 (0.2438) nleep/row_max_mean 1491.0880 (1481.7545) nleep/row_max_std 48.6559 (51.0176) nleep/row_min_mean 1450.7025 (1444.4917) lr 4.1221e-04 eta 0:03:48
epoch [37/50] batch [160/176] time 0.098 (0.100) data 0.000 (0.002) loss 1.3297 (1.3130) teacher_loss 0.0313 (0.1020) loss_zs_kd 0.0611 (0.0516) loss_oracle 0.5783 (0.5701) kd_loss 0.9787 (0.9001) acc 100.0000 (97.0117) gate/entropy 1.0389 (1.0390) gate/usage_max 0.4820 (0.4827) gate/usage_min 0.2021 (0.2028) gate/usage_std 0.1149 (0.1150) teacher/entropy 0.0000 (0.0275) teacher/usage_max 0.5938 (0.5733) teacher/usage_min 0.0000 (0.0065) teacher/usage_std 0.2478 (0.2433) nleep/row_max_mean 1490.1960 (1481.9390) nleep/row_max_std 54.4967 (50.9640) nleep/row_min_mean 1449.9310 (1444.6264) lr 4.1221e-04 eta 0:03:51
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,163
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,799
* accuracy: 67.7%
* error: 32.3%
* macro_f1: 60.6%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [38/50] batch [20/176] time 0.089 (0.106) data 0.000 (0.017) loss 1.3794 (1.3014) teacher_loss 0.1450 (0.1128) loss_zs_kd 0.0730 (0.0477) loss_oracle 0.6120 (0.5484) kd_loss 0.8918 (0.8905) acc 96.8750 (96.4062) gate/entropy 1.0388 (1.0389) gate/usage_max 0.4818 (0.4818) gate/usage_min 0.2016 (0.2018) gate/usage_std 0.1150 (0.1149) teacher/entropy 0.0292 (0.0333) teacher/usage_max 0.5454 (0.5734) teacher/usage_min 0.0006 (0.0038) teacher/usage_std 0.2382 (0.2460) nleep/row_max_mean 1488.8914 (1478.7107) nleep/row_max_std 48.8392 (52.8145) nleep/row_min_mean 1451.9965 (1441.8049) lr 3.6258e-04 eta 0:04:00
epoch [38/50] batch [40/176] time 0.082 (0.093) data 0.000 (0.009) loss 1.3368 (1.3079) teacher_loss 0.1799 (0.1095) loss_zs_kd 0.0629 (0.0497) loss_oracle 0.5670 (0.5562) kd_loss 0.8419 (0.8955) acc 93.7500 (96.7969) gate/entropy 1.0391 (1.0389) gate/usage_max 0.4813 (0.4818) gate/usage_min 0.2018 (0.2017) gate/usage_std 0.1147 (0.1150) teacher/entropy 0.0234 (0.0329) teacher/usage_max 0.6811 (0.5738) teacher/usage_min 0.0021 (0.0053) teacher/usage_std 0.2774 (0.2443) nleep/row_max_mean 1472.6626 (1479.3852) nleep/row_max_std 55.1296 (52.5940) nleep/row_min_mean 1436.4004 (1442.7548) lr 3.6258e-04 eta 0:03:30
epoch [38/50] batch [60/176] time 0.065 (0.087) data 0.000 (0.006) loss 1.3615 (1.3036) teacher_loss 0.0564 (0.1002) loss_zs_kd 0.0547 (0.0504) loss_oracle 0.6271 (0.5645) kd_loss 0.9641 (0.8959) acc 100.0000 (97.1875) gate/entropy 1.0389 (1.0388) gate/usage_max 0.4813 (0.4818) gate/usage_min 0.2014 (0.2016) gate/usage_std 0.1148 (0.1150) teacher/entropy 0.0009 (0.0310) teacher/usage_max 0.5624 (0.5788) teacher/usage_min 0.0000 (0.0052) teacher/usage_std 0.2411 (0.2462) nleep/row_max_mean 1484.0972 (1479.8515) nleep/row_max_std 51.8592 (52.8311) nleep/row_min_mean 1446.7319 (1443.2921) lr 3.6258e-04 eta 0:03:13
epoch [38/50] batch [80/176] time 0.069 (0.085) data 0.000 (0.004) loss 1.3756 (1.3144) teacher_loss 0.1480 (0.1052) loss_zs_kd 0.0395 (0.0501) loss_oracle 0.6048 (0.5697) kd_loss 0.9055 (0.8993) acc 93.7500 (96.9531) gate/entropy 1.0387 (1.0388) gate/usage_max 0.4815 (0.4816) gate/usage_min 0.2010 (0.2015) gate/usage_std 0.1151 (0.1150) teacher/entropy 0.0190 (0.0291) teacher/usage_max 0.5347 (0.5746) teacher/usage_min 0.0011 (0.0054) teacher/usage_std 0.2367 (0.2447) nleep/row_max_mean 1483.8806 (1479.2377) nleep/row_max_std 62.9682 (54.0612) nleep/row_min_mean 1447.2499 (1442.8374) lr 3.6258e-04 eta 0:03:07
epoch [38/50] batch [100/176] time 0.086 (0.085) data 0.000 (0.004) loss 1.2392 (1.3153) teacher_loss 0.0305 (0.1050) loss_zs_kd 0.0463 (0.0508) loss_oracle 0.6093 (0.5723) kd_loss 0.8810 (0.8988) acc 100.0000 (96.7500) gate/entropy 1.0389 (1.0388) gate/usage_max 0.4810 (0.4816) gate/usage_min 0.2010 (0.2014) gate/usage_std 0.1148 (0.1149) teacher/entropy 0.0217 (0.0286) teacher/usage_max 0.5853 (0.5733) teacher/usage_min 0.0002 (0.0050) teacher/usage_std 0.2457 (0.2444) nleep/row_max_mean 1471.8915 (1478.7937) nleep/row_max_std 60.3802 (54.6838) nleep/row_min_mean 1437.1265 (1442.2895) lr 3.6258e-04 eta 0:03:05
epoch [38/50] batch [120/176] time 0.069 (0.086) data 0.000 (0.003) loss 1.3354 (1.3159) teacher_loss 0.1129 (0.1068) loss_zs_kd 0.0536 (0.0506) loss_oracle 0.5996 (0.5755) kd_loss 0.8959 (0.8961) acc 96.8750 (96.7708) gate/entropy 1.0386 (1.0388) gate/usage_max 0.4812 (0.4815) gate/usage_min 0.2007 (0.2013) gate/usage_std 0.1150 (0.1149) teacher/entropy 0.0030 (0.0299) teacher/usage_max 0.5932 (0.5768) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.2477 (0.2450) nleep/row_max_mean 1488.5247 (1478.8388) nleep/row_max_std 48.3270 (54.5045) nleep/row_min_mean 1449.0042 (1442.3133) lr 3.6258e-04 eta 0:03:05
epoch [38/50] batch [140/176] time 0.083 (0.085) data 0.000 (0.003) loss 1.2683 (1.3167) teacher_loss 0.0563 (0.1060) loss_zs_kd 0.0470 (0.0505) loss_oracle 0.5289 (0.5751) kd_loss 0.9241 (0.8979) acc 100.0000 (96.8304) gate/entropy 1.0389 (1.0388) gate/usage_max 0.4806 (0.4814) gate/usage_min 0.2008 (0.2013) gate/usage_std 0.1147 (0.1149) teacher/entropy 0.0564 (0.0298) teacher/usage_max 0.5975 (0.5750) teacher/usage_min 0.0036 (0.0053) teacher/usage_std 0.2468 (0.2445) nleep/row_max_mean 1475.6102 (1479.5043) nleep/row_max_std 61.4589 (54.2305) nleep/row_min_mean 1437.1833 (1442.7682) lr 3.6258e-04 eta 0:03:02
epoch [38/50] batch [160/176] time 0.070 (0.086) data 0.000 (0.002) loss 1.4160 (1.3149) teacher_loss 0.2023 (0.1056) loss_zs_kd 0.0343 (0.0507) loss_oracle 0.6015 (0.5752) kd_loss 0.8958 (0.8964) acc 93.7500 (96.8164) gate/entropy 1.0387 (1.0388) gate/usage_max 0.4807 (0.4813) gate/usage_min 0.2003 (0.2012) gate/usage_std 0.1149 (0.1149) teacher/entropy 0.0162 (0.0296) teacher/usage_max 0.5629 (0.5741) teacher/usage_min 0.0026 (0.0049) teacher/usage_std 0.2397 (0.2446) nleep/row_max_mean 1483.4341 (1480.0504) nleep/row_max_std 53.7489 (54.0463) nleep/row_min_mean 1446.6560 (1443.2045) lr 3.6258e-04 eta 0:03:02
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,166
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,796
* accuracy: 67.6%
* error: 32.4%
* macro_f1: 60.2%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [39/50] batch [20/176] time 0.091 (0.115) data 0.000 (0.018) loss 1.2205 (1.2713) teacher_loss 0.0205 (0.0827) loss_zs_kd 0.0610 (0.0494) loss_oracle 0.5264 (0.5505) kd_loss 0.9064 (0.8886) acc 100.0000 (97.6562) gate/entropy 1.0390 (1.0388) gate/usage_max 0.4801 (0.4804) gate/usage_min 0.2004 (0.2002) gate/usage_std 0.1146 (0.1148) teacher/entropy 0.0053 (0.0334) teacher/usage_max 0.5614 (0.5838) teacher/usage_min 0.0009 (0.0035) teacher/usage_std 0.2405 (0.2477) nleep/row_max_mean 1488.7644 (1485.1481) nleep/row_max_std 43.9713 (52.4249) nleep/row_min_mean 1447.6997 (1447.2123) lr 3.1545e-04 eta 0:03:59
epoch [39/50] batch [40/176] time 0.092 (0.102) data 0.000 (0.009) loss 1.4642 (1.2762) teacher_loss 0.2262 (0.0897) loss_zs_kd 0.0493 (0.0472) loss_oracle 0.5814 (0.5613) kd_loss 0.9226 (0.8822) acc 96.8750 (97.2656) gate/entropy 1.0385 (1.0387) gate/usage_max 0.4806 (0.4804) gate/usage_min 0.1999 (0.2002) gate/usage_std 0.1150 (0.1148) teacher/entropy 0.0008 (0.0304) teacher/usage_max 0.5313 (0.5891) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.2371 (0.2486) nleep/row_max_mean 1482.1228 (1485.0346) nleep/row_max_std 57.1926 (51.2403) nleep/row_min_mean 1447.3979 (1446.8076) lr 3.1545e-04 eta 0:03:31
epoch [39/50] batch [60/176] time 0.134 (0.106) data 0.001 (0.006) loss 1.2713 (1.2828) teacher_loss 0.0352 (0.0898) loss_zs_kd 0.0571 (0.0465) loss_oracle 0.5697 (0.5670) kd_loss 0.9227 (0.8864) acc 100.0000 (97.3958) gate/entropy 1.0384 (1.0387) gate/usage_max 0.4806 (0.4804) gate/usage_min 0.1996 (0.2001) gate/usage_std 0.1151 (0.1148) teacher/entropy 0.0000 (0.0305) teacher/usage_max 0.5312 (0.5860) teacher/usage_min 0.0000 (0.0038) teacher/usage_std 0.2371 (0.2481) nleep/row_max_mean 1511.8955 (1485.1053) nleep/row_max_std 35.1207 (51.7652) nleep/row_min_mean 1471.4006 (1447.0143) lr 3.1545e-04 eta 0:03:36
epoch [39/50] batch [80/176] time 0.092 (0.104) data 0.000 (0.005) loss 1.3509 (1.2798) teacher_loss 0.0919 (0.0859) loss_zs_kd 0.0541 (0.0479) loss_oracle 0.5768 (0.5671) kd_loss 0.9435 (0.8865) acc 96.8750 (97.4609) gate/entropy 1.0388 (1.0387) gate/usage_max 0.4798 (0.4803) gate/usage_min 0.1998 (0.2000) gate/usage_std 0.1147 (0.1148) teacher/entropy 0.0210 (0.0320) teacher/usage_max 0.5686 (0.5811) teacher/usage_min 0.0009 (0.0038) teacher/usage_std 0.2417 (0.2467) nleep/row_max_mean 1489.4268 (1484.7324) nleep/row_max_std 41.1324 (51.4736) nleep/row_min_mean 1451.8507 (1446.6492) lr 3.1545e-04 eta 0:03:31
epoch [39/50] batch [100/176] time 0.089 (0.102) data 0.000 (0.004) loss 1.2097 (1.2912) teacher_loss 0.0629 (0.0931) loss_zs_kd 0.0514 (0.0498) loss_oracle 0.5898 (0.5687) kd_loss 0.8262 (0.8889) acc 96.8750 (97.1875) gate/entropy 1.0384 (1.0387) gate/usage_max 0.4803 (0.4802) gate/usage_min 0.1994 (0.2000) gate/usage_std 0.1151 (0.1148) teacher/entropy 0.0425 (0.0298) teacher/usage_max 0.6655 (0.5816) teacher/usage_min 0.0001 (0.0043) teacher/usage_std 0.2716 (0.2463) nleep/row_max_mean 1488.6948 (1484.1510) nleep/row_max_std 59.5511 (51.9518) nleep/row_min_mean 1450.9580 (1446.1511) lr 3.1545e-04 eta 0:03:24
epoch [39/50] batch [120/176] time 0.089 (0.100) data 0.000 (0.003) loss 1.2053 (1.2953) teacher_loss 0.0456 (0.0981) loss_zs_kd 0.0268 (0.0505) loss_oracle 0.5460 (0.5697) kd_loss 0.8732 (0.8871) acc 100.0000 (97.0833) gate/entropy 1.0384 (1.0387) gate/usage_max 0.4803 (0.4802) gate/usage_min 0.1993 (0.1999) gate/usage_std 0.1151 (0.1148) teacher/entropy 0.0113 (0.0302) teacher/usage_max 0.6234 (0.5824) teacher/usage_min 0.0001 (0.0044) teacher/usage_std 0.2563 (0.2464) nleep/row_max_mean 1459.4399 (1483.4320) nleep/row_max_std 70.6407 (52.7502) nleep/row_min_mean 1428.9962 (1445.5990) lr 3.1545e-04 eta 0:03:19
epoch [39/50] batch [140/176] time 0.097 (0.100) data 0.000 (0.003) loss 1.2771 (1.2987) teacher_loss 0.0815 (0.1012) loss_zs_kd 0.0358 (0.0502) loss_oracle 0.5649 (0.5697) kd_loss 0.8952 (0.8876) acc 96.8750 (96.9866) gate/entropy 1.0385 (1.0387) gate/usage_max 0.4799 (0.4801) gate/usage_min 0.1993 (0.1998) gate/usage_std 0.1149 (0.1148) teacher/entropy 0.0023 (0.0298) teacher/usage_max 0.5934 (0.5844) teacher/usage_min 0.0000 (0.0047) teacher/usage_std 0.2477 (0.2469) nleep/row_max_mean 1476.2689 (1483.1120) nleep/row_max_std 59.5382 (53.1824) nleep/row_min_mean 1438.0148 (1445.3718) lr 3.1545e-04 eta 0:03:16
epoch [39/50] batch [160/176] time 0.093 (0.100) data 0.001 (0.002) loss 1.1653 (1.2985) teacher_loss 0.0390 (0.1012) loss_zs_kd 0.0273 (0.0508) loss_oracle 0.5146 (0.5691) kd_loss 0.8554 (0.8873) acc 100.0000 (97.0312) gate/entropy 1.0387 (1.0387) gate/usage_max 0.4795 (0.4801) gate/usage_min 0.1993 (0.1997) gate/usage_std 0.1147 (0.1148) teacher/entropy 0.0611 (0.0301) teacher/usage_max 0.5872 (0.5824) teacher/usage_min 0.0349 (0.0049) teacher/usage_std 0.2277 (0.2467) nleep/row_max_mean 1472.3945 (1482.8949) nleep/row_max_std 58.7269 (53.5602) nleep/row_min_mean 1437.1772 (1445.1509) lr 3.1545e-04 eta 0:03:14
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,174
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,721
* accuracy: 64.8%
* error: 35.2%
* macro_f1: 59.1%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [40/50] batch [20/176] time 0.113 (0.115) data 0.000 (0.015) loss 1.3664 (1.2948) teacher_loss 0.1980 (0.1229) loss_zs_kd 0.0630 (0.0490) loss_oracle 0.5332 (0.5586) kd_loss 0.8702 (0.8681) acc 93.7500 (96.8750) gate/entropy 1.0384 (1.0385) gate/usage_max 0.4798 (0.4797) gate/usage_min 0.1990 (0.1990) gate/usage_std 0.1149 (0.1149) teacher/entropy 0.0427 (0.0253) teacher/usage_max 0.5580 (0.6042) teacher/usage_min 0.0031 (0.0021) teacher/usage_std 0.2385 (0.2545) nleep/row_max_mean 1468.2825 (1479.4898) nleep/row_max_std 76.3045 (58.6758) nleep/row_min_mean 1433.8156 (1442.3229) lr 2.7103e-04 eta 0:03:40
epoch [40/50] batch [40/176] time 0.092 (0.106) data 0.000 (0.008) loss 1.3623 (1.2989) teacher_loss 0.1709 (0.1257) loss_zs_kd 0.0816 (0.0481) loss_oracle 0.5516 (0.5562) kd_loss 0.8748 (0.8711) acc 96.8750 (96.2500) gate/entropy 1.0384 (1.0384) gate/usage_max 0.4798 (0.4797) gate/usage_min 0.1990 (0.1990) gate/usage_std 0.1150 (0.1149) teacher/entropy 0.0459 (0.0277) teacher/usage_max 0.5359 (0.5935) teacher/usage_min 0.0005 (0.0035) teacher/usage_std 0.2372 (0.2506) nleep/row_max_mean 1485.6696 (1479.4349) nleep/row_max_std 65.7035 (58.2721) nleep/row_min_mean 1445.2716 (1442.2807) lr 2.7103e-04 eta 0:03:21
epoch [40/50] batch [60/176] time 0.110 (0.102) data 0.001 (0.005) loss 1.3167 (1.3032) teacher_loss 0.0246 (0.1258) loss_zs_kd 0.0765 (0.0506) loss_oracle 0.6492 (0.5562) kd_loss 0.9293 (0.8739) acc 100.0000 (96.6146) gate/entropy 1.0385 (1.0384) gate/usage_max 0.4794 (0.4797) gate/usage_min 0.1989 (0.1989) gate/usage_std 0.1148 (0.1149) teacher/entropy 0.0048 (0.0278) teacher/usage_max 0.5003 (0.5897) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.2357 (0.2496) nleep/row_max_mean 1491.7863 (1480.0868) nleep/row_max_std 35.5527 (57.1569) nleep/row_min_mean 1451.3358 (1442.8629) lr 2.7103e-04 eta 0:03:10
epoch [40/50] batch [80/176] time 0.095 (0.100) data 0.000 (0.004) loss 1.1816 (1.2977) teacher_loss 0.0086 (0.1186) loss_zs_kd 0.0395 (0.0500) loss_oracle 0.5929 (0.5573) kd_loss 0.8568 (0.8755) acc 100.0000 (96.6406) gate/entropy 1.0388 (1.0384) gate/usage_max 0.4790 (0.4796) gate/usage_min 0.1992 (0.1989) gate/usage_std 0.1145 (0.1149) teacher/entropy 0.0200 (0.0277) teacher/usage_max 0.6458 (0.5903) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.2640 (0.2496) nleep/row_max_mean 1478.7920 (1480.5559) nleep/row_max_std 43.2089 (56.0153) nleep/row_min_mean 1436.3181 (1443.0970) lr 2.7103e-04 eta 0:03:05
epoch [40/50] batch [100/176] time 0.094 (0.099) data 0.000 (0.003) loss 1.2287 (1.2916) teacher_loss 0.0487 (0.1126) loss_zs_kd 0.0441 (0.0486) loss_oracle 0.5535 (0.5572) kd_loss 0.8812 (0.8761) acc 96.8750 (96.7812) gate/entropy 1.0383 (1.0384) gate/usage_max 0.4797 (0.4796) gate/usage_min 0.1986 (0.1989) gate/usage_std 0.1150 (0.1149) teacher/entropy 0.0169 (0.0274) teacher/usage_max 0.5891 (0.5880) teacher/usage_min 0.0011 (0.0036) teacher/usage_std 0.2461 (0.2490) nleep/row_max_mean 1480.1498 (1481.2286) nleep/row_max_std 52.0434 (55.4068) nleep/row_min_mean 1445.0759 (1443.7656) lr 2.7103e-04 eta 0:03:01
epoch [40/50] batch [120/176] time 0.092 (0.098) data 0.000 (0.003) loss 1.1914 (1.2895) teacher_loss 0.0247 (0.1076) loss_zs_kd 0.0388 (0.0491) loss_oracle 0.5476 (0.5561) kd_loss 0.8735 (0.8793) acc 100.0000 (96.9010) gate/entropy 1.0385 (1.0384) gate/usage_max 0.4790 (0.4796) gate/usage_min 0.1986 (0.1988) gate/usage_std 0.1148 (0.1149) teacher/entropy 0.0260 (0.0261) teacher/usage_max 0.5857 (0.5854) teacher/usage_min 0.0000 (0.0038) teacher/usage_std 0.2459 (0.2482) nleep/row_max_mean 1486.9338 (1481.8057) nleep/row_max_std 35.6836 (54.5597) nleep/row_min_mean 1449.7246 (1444.3098) lr 2.7103e-04 eta 0:02:57
epoch [40/50] batch [140/176] time 0.098 (0.098) data 0.000 (0.002) loss 1.2417 (1.2902) teacher_loss 0.0799 (0.1069) loss_zs_kd 0.0706 (0.0495) loss_oracle 0.5154 (0.5559) kd_loss 0.8688 (0.8806) acc 96.8750 (96.9643) gate/entropy 1.0384 (1.0384) gate/usage_max 0.4792 (0.4795) gate/usage_min 0.1985 (0.1988) gate/usage_std 0.1149 (0.1149) teacher/entropy 0.0401 (0.0272) teacher/usage_max 0.5618 (0.5810) teacher/usage_min 0.0010 (0.0037) teacher/usage_std 0.2405 (0.2471) nleep/row_max_mean 1475.1282 (1481.6424) nleep/row_max_std 57.1573 (54.7508) nleep/row_min_mean 1437.6348 (1444.1650) lr 2.7103e-04 eta 0:02:55
epoch [40/50] batch [160/176] time 0.180 (0.098) data 0.001 (0.002) loss 1.3828 (1.2911) teacher_loss 0.1838 (0.1087) loss_zs_kd 0.0394 (0.0492) loss_oracle 0.5670 (0.5547) kd_loss 0.8958 (0.8804) acc 96.8750 (96.9531) gate/entropy 1.0387 (1.0384) gate/usage_max 0.4786 (0.4795) gate/usage_min 0.1986 (0.1987) gate/usage_std 0.1146 (0.1149) teacher/entropy 0.0236 (0.0268) teacher/usage_max 0.5492 (0.5813) teacher/usage_min 0.0131 (0.0036) teacher/usage_std 0.2310 (0.2474) nleep/row_max_mean 1473.4584 (1481.2642) nleep/row_max_std 55.3230 (55.3311) nleep/row_min_mean 1436.3929 (1443.7797) lr 2.7103e-04 eta 0:02:54
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,176
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,759
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 60.0%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [41/50] batch [20/176] time 0.093 (0.112) data 0.000 (0.017) loss 1.4209 (1.2706) teacher_loss 0.1853 (0.0828) loss_zs_kd 0.0678 (0.0520) loss_oracle 0.5559 (0.5451) kd_loss 0.9238 (0.8894) acc 93.7500 (97.3438) gate/entropy 1.0384 (1.0383) gate/usage_max 0.4789 (0.4791) gate/usage_min 0.1982 (0.1981) gate/usage_std 0.1148 (0.1150) teacher/entropy 0.0188 (0.0220) teacher/usage_max 0.5261 (0.5786) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.2367 (0.2466) nleep/row_max_mean 1474.1111 (1480.6164) nleep/row_max_std 43.3963 (54.9348) nleep/row_min_mean 1438.8243 (1443.0389) lr 2.2949e-04 eta 0:03:14
epoch [41/50] batch [40/176] time 0.096 (0.102) data 0.000 (0.009) loss 1.2460 (1.2869) teacher_loss 0.1293 (0.1070) loss_zs_kd 0.0568 (0.0523) loss_oracle 0.5332 (0.5475) kd_loss 0.8217 (0.8800) acc 93.7500 (97.0312) gate/entropy 1.0384 (1.0382) gate/usage_max 0.4789 (0.4791) gate/usage_min 0.1982 (0.1981) gate/usage_std 0.1148 (0.1150) teacher/entropy 0.0403 (0.0250) teacher/usage_max 0.6905 (0.5890) teacher/usage_min 0.0094 (0.0022) teacher/usage_std 0.2791 (0.2505) nleep/row_max_mean 1470.9374 (1480.2195) nleep/row_max_std 57.5528 (55.2752) nleep/row_min_mean 1436.5081 (1443.1561) lr 2.2949e-04 eta 0:02:55
epoch [41/50] batch [60/176] time 0.090 (0.100) data 0.001 (0.006) loss 1.2864 (1.2914) teacher_loss 0.0596 (0.1059) loss_zs_kd 0.0557 (0.0536) loss_oracle 0.5367 (0.5522) kd_loss 0.9306 (0.8826) acc 96.8750 (97.1354) gate/entropy 1.0384 (1.0382) gate/usage_max 0.4787 (0.4791) gate/usage_min 0.1980 (0.1980) gate/usage_std 0.1148 (0.1150) teacher/entropy 0.0016 (0.0236) teacher/usage_max 0.5001 (0.5841) teacher/usage_min 0.0001 (0.0016) teacher/usage_std 0.2357 (0.2491) nleep/row_max_mean 1487.0753 (1481.7640) nleep/row_max_std 42.9375 (53.2435) nleep/row_min_mean 1446.0630 (1444.1392) lr 2.2949e-04 eta 0:02:49
epoch [41/50] batch [80/176] time 0.100 (0.098) data 0.000 (0.004) loss 1.5733 (1.2902) teacher_loss 0.3272 (0.1014) loss_zs_kd 0.0540 (0.0522) loss_oracle 0.5814 (0.5581) kd_loss 0.9285 (0.8836) acc 93.7500 (97.2656) gate/entropy 1.0381 (1.0382) gate/usage_max 0.4791 (0.4791) gate/usage_min 0.1978 (0.1980) gate/usage_std 0.1151 (0.1150) teacher/entropy 0.0041 (0.0223) teacher/usage_max 0.5009 (0.5816) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.2357 (0.2487) nleep/row_max_mean 1478.9822 (1480.9824) nleep/row_max_std 59.9066 (53.3789) nleep/row_min_mean 1441.7872 (1443.4301) lr 2.2949e-04 eta 0:02:45
epoch [41/50] batch [100/176] time 0.092 (0.098) data 0.000 (0.004) loss 1.3958 (1.2960) teacher_loss 0.1321 (0.1057) loss_zs_kd 0.0494 (0.0530) loss_oracle 0.6723 (0.5617) kd_loss 0.9029 (0.8830) acc 96.8750 (97.0938) gate/entropy 1.0383 (1.0382) gate/usage_max 0.4786 (0.4790) gate/usage_min 0.1978 (0.1979) gate/usage_std 0.1148 (0.1150) teacher/entropy 0.0214 (0.0225) teacher/usage_max 0.5209 (0.5825) teacher/usage_min 0.0003 (0.0023) teacher/usage_std 0.2361 (0.2483) nleep/row_max_mean 1489.7954 (1481.6320) nleep/row_max_std 49.1855 (52.9117) nleep/row_min_mean 1449.0573 (1443.9768) lr 2.2949e-04 eta 0:02:42
epoch [41/50] batch [120/176] time 0.088 (0.098) data 0.000 (0.003) loss 1.2625 (1.2963) teacher_loss 0.1009 (0.1071) loss_zs_kd 0.0296 (0.0528) loss_oracle 0.5319 (0.5607) kd_loss 0.8809 (0.8825) acc 93.7500 (96.8750) gate/entropy 1.0383 (1.0382) gate/usage_max 0.4787 (0.4790) gate/usage_min 0.1978 (0.1979) gate/usage_std 0.1149 (0.1150) teacher/entropy 0.0304 (0.0231) teacher/usage_max 0.5522 (0.5829) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.2395 (0.2485) nleep/row_max_mean 1465.0664 (1481.1349) nleep/row_max_std 56.7153 (53.4816) nleep/row_min_mean 1431.5837 (1443.6429) lr 2.2949e-04 eta 0:02:39
epoch [41/50] batch [140/176] time 0.094 (0.097) data 0.000 (0.003) loss 1.2326 (1.2906) teacher_loss 0.0625 (0.1040) loss_zs_kd 0.0536 (0.0521) loss_oracle 0.5940 (0.5593) kd_loss 0.8463 (0.8810) acc 96.8750 (96.9196) gate/entropy 1.0379 (1.0382) gate/usage_max 0.4791 (0.4790) gate/usage_min 0.1974 (0.1979) gate/usage_std 0.1152 (0.1150) teacher/entropy 0.0137 (0.0228) teacher/usage_max 0.6840 (0.5872) teacher/usage_min 0.0014 (0.0030) teacher/usage_std 0.2790 (0.2499) nleep/row_max_mean 1490.4956 (1481.1817) nleep/row_max_std 47.5655 (53.1588) nleep/row_min_mean 1449.0200 (1443.7703) lr 2.2949e-04 eta 0:02:37
epoch [41/50] batch [160/176] time 0.097 (0.098) data 0.000 (0.002) loss 1.3371 (1.2949) teacher_loss 0.1853 (0.1061) loss_zs_kd 0.0544 (0.0524) loss_oracle 0.5476 (0.5615) kd_loss 0.8507 (0.8819) acc 93.7500 (96.9336) gate/entropy 1.0382 (1.0382) gate/usage_max 0.4786 (0.4789) gate/usage_min 0.1977 (0.1978) gate/usage_std 0.1149 (0.1150) teacher/entropy 0.0096 (0.0226) teacher/usage_max 0.6852 (0.5889) teacher/usage_min 0.0020 (0.0031) teacher/usage_std 0.2793 (0.2502) nleep/row_max_mean 1473.5503 (1481.1872) nleep/row_max_std 52.4697 (53.1571) nleep/row_min_mean 1437.5663 (1443.7097) lr 2.2949e-04 eta 0:02:36
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,172
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,758
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 59.9%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [42/50] batch [20/176] time 0.089 (0.114) data 0.000 (0.018) loss 1.1973 (1.3033) teacher_loss 0.0343 (0.1116) loss_zs_kd 0.0348 (0.0467) loss_oracle 0.5241 (0.5539) kd_loss 0.8835 (0.8913) acc 100.0000 (96.8750) gate/entropy 1.0382 (1.0380) gate/usage_max 0.4783 (0.4787) gate/usage_min 0.1975 (0.1973) gate/usage_std 0.1148 (0.1151) teacher/entropy 0.0103 (0.0263) teacher/usage_max 0.5952 (0.5787) teacher/usage_min 0.0007 (0.0074) teacher/usage_std 0.2478 (0.2450) nleep/row_max_mean 1485.0210 (1478.5046) nleep/row_max_std 44.7947 (52.0236) nleep/row_min_mean 1449.1443 (1442.7279) lr 1.9098e-04 eta 0:02:57
epoch [42/50] batch [40/176] time 0.091 (0.108) data 0.000 (0.009) loss 1.3103 (1.2884) teacher_loss 0.0794 (0.1060) loss_zs_kd 0.0595 (0.0511) loss_oracle 0.6030 (0.5541) kd_loss 0.8997 (0.8798) acc 100.0000 (96.9531) gate/entropy 1.0383 (1.0381) gate/usage_max 0.4782 (0.4786) gate/usage_min 0.1974 (0.1973) gate/usage_std 0.1148 (0.1150) teacher/entropy 0.0069 (0.0245) teacher/usage_max 0.5626 (0.6024) teacher/usage_min 0.0003 (0.0059) teacher/usage_std 0.2410 (0.2533) nleep/row_max_mean 1476.4463 (1478.0454) nleep/row_max_std 45.7706 (51.0554) nleep/row_min_mean 1439.7693 (1442.0610) lr 1.9098e-04 eta 0:02:46
epoch [42/50] batch [60/176] time 0.095 (0.110) data 0.001 (0.006) loss 1.1810 (1.3012) teacher_loss 0.0684 (0.1161) loss_zs_kd 0.0628 (0.0544) loss_oracle 0.5033 (0.5572) kd_loss 0.8295 (0.8793) acc 100.0000 (96.5625) gate/entropy 1.0381 (1.0381) gate/usage_max 0.4784 (0.4786) gate/usage_min 0.1972 (0.1973) gate/usage_std 0.1150 (0.1150) teacher/entropy 0.0559 (0.0259) teacher/usage_max 0.6225 (0.6013) teacher/usage_min 0.0036 (0.0049) teacher/usage_std 0.2543 (0.2530) nleep/row_max_mean 1476.0508 (1478.4999) nleep/row_max_std 46.4548 (50.1693) nleep/row_min_mean 1441.1265 (1442.4402) lr 1.9098e-04 eta 0:02:47
epoch [42/50] batch [80/176] time 0.102 (0.106) data 0.000 (0.005) loss 1.1338 (1.2970) teacher_loss 0.0377 (0.1116) loss_zs_kd 0.0347 (0.0529) loss_oracle 0.5330 (0.5586) kd_loss 0.8122 (0.8796) acc 100.0000 (96.7578) gate/entropy 1.0378 (1.0381) gate/usage_max 0.4788 (0.4785) gate/usage_min 0.1969 (0.1973) gate/usage_std 0.1152 (0.1150) teacher/entropy 0.0640 (0.0245) teacher/usage_max 0.6606 (0.6018) teacher/usage_min 0.0166 (0.0051) teacher/usage_std 0.2630 (0.2534) nleep/row_max_mean 1472.6445 (1478.6176) nleep/row_max_std 61.1850 (50.5381) nleep/row_min_mean 1437.2693 (1442.5775) lr 1.9098e-04 eta 0:02:39
epoch [42/50] batch [100/176] time 0.095 (0.103) data 0.001 (0.004) loss 1.3380 (1.2959) teacher_loss 0.1322 (0.1078) loss_zs_kd 0.0436 (0.0511) loss_oracle 0.5893 (0.5557) kd_loss 0.8894 (0.8847) acc 96.8750 (96.9062) gate/entropy 1.0381 (1.0381) gate/usage_max 0.4783 (0.4785) gate/usage_min 0.1971 (0.1972) gate/usage_std 0.1150 (0.1150) teacher/entropy 0.0067 (0.0233) teacher/usage_max 0.6266 (0.5950) teacher/usage_min 0.0296 (0.0047) teacher/usage_std 0.2438 (0.2514) nleep/row_max_mean 1475.1831 (1478.9454) nleep/row_max_std 50.3742 (50.3627) nleep/row_min_mean 1439.4884 (1442.8972) lr 1.9098e-04 eta 0:02:33
epoch [42/50] batch [120/176] time 0.092 (0.101) data 0.000 (0.003) loss 1.2379 (1.2952) teacher_loss 0.0418 (0.1099) loss_zs_kd 0.0612 (0.0500) loss_oracle 0.5792 (0.5561) kd_loss 0.8759 (0.8822) acc 100.0000 (96.9010) gate/entropy 1.0380 (1.0381) gate/usage_max 0.4783 (0.4785) gate/usage_min 0.1969 (0.1972) gate/usage_std 0.1150 (0.1150) teacher/entropy 0.0059 (0.0234) teacher/usage_max 0.6237 (0.5985) teacher/usage_min 0.0000 (0.0041) teacher/usage_std 0.2564 (0.2531) nleep/row_max_mean 1466.8143 (1478.3974) nleep/row_max_std 54.1015 (50.9187) nleep/row_min_mean 1431.0101 (1442.5303) lr 1.9098e-04 eta 0:02:28
epoch [42/50] batch [140/176] time 0.103 (0.101) data 0.001 (0.003) loss 1.3898 (1.2922) teacher_loss 0.2503 (0.1098) loss_zs_kd 0.0415 (0.0492) loss_oracle 0.4881 (0.5556) kd_loss 0.8747 (0.8800) acc 93.7500 (96.7857) gate/entropy 1.0380 (1.0380) gate/usage_max 0.4784 (0.4784) gate/usage_min 0.1970 (0.1972) gate/usage_std 0.1151 (0.1150) teacher/entropy 0.0243 (0.0235) teacher/usage_max 0.5832 (0.5995) teacher/usage_min 0.0007 (0.0039) teacher/usage_std 0.2449 (0.2536) nleep/row_max_mean 1468.1313 (1478.2147) nleep/row_max_std 49.7718 (51.1805) nleep/row_min_mean 1433.8625 (1442.4192) lr 1.9098e-04 eta 0:02:25
epoch [42/50] batch [160/176] time 0.100 (0.100) data 0.000 (0.003) loss 1.3111 (1.2910) teacher_loss 0.1808 (0.1085) loss_zs_kd 0.0516 (0.0494) loss_oracle 0.5686 (0.5556) kd_loss 0.8202 (0.8800) acc 90.6250 (96.7969) gate/entropy 1.0378 (1.0380) gate/usage_max 0.4785 (0.4784) gate/usage_min 0.1967 (0.1971) gate/usage_std 0.1152 (0.1150) teacher/entropy 0.0505 (0.0236) teacher/usage_max 0.6797 (0.5991) teacher/usage_min 0.0214 (0.0039) teacher/usage_std 0.2698 (0.2534) nleep/row_max_mean 1462.6213 (1477.7574) nleep/row_max_std 69.4276 (51.6516) nleep/row_min_mean 1429.4849 (1442.0521) lr 1.9098e-04 eta 0:02:23
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,175
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,765
* accuracy: 66.5%
* error: 33.5%
* macro_f1: 60.1%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [43/50] batch [20/176] time 0.086 (0.103) data 0.000 (0.013) loss 1.2505 (1.2982) teacher_loss 0.0771 (0.1159) loss_zs_kd 0.0494 (0.0508) loss_oracle 0.5610 (0.5639) kd_loss 0.8682 (0.8750) acc 96.8750 (96.8750) gate/entropy 1.0381 (1.0379) gate/usage_max 0.4780 (0.4783) gate/usage_min 0.1969 (0.1968) gate/usage_std 0.1149 (0.1151) teacher/entropy 0.0166 (0.0299) teacher/usage_max 0.6248 (0.5975) teacher/usage_min 0.0061 (0.0057) teacher/usage_std 0.2538 (0.2498) nleep/row_max_mean 1482.5146 (1476.1370) nleep/row_max_std 41.5810 (53.8862) nleep/row_min_mean 1446.3816 (1441.0910) lr 1.5567e-04 eta 0:02:23
epoch [43/50] batch [40/176] time 0.088 (0.094) data 0.000 (0.007) loss 1.2950 (1.2966) teacher_loss 0.1536 (0.1154) loss_zs_kd 0.0603 (0.0525) loss_oracle 0.5673 (0.5615) kd_loss 0.8275 (0.8742) acc 96.8750 (96.6406) gate/entropy 1.0379 (1.0379) gate/usage_max 0.4783 (0.4782) gate/usage_min 0.1966 (0.1967) gate/usage_std 0.1151 (0.1151) teacher/entropy 0.0256 (0.0264) teacher/usage_max 0.7020 (0.5937) teacher/usage_min 0.0000 (0.0035) teacher/usage_std 0.2877 (0.2509) nleep/row_max_mean 1482.3784 (1477.3161) nleep/row_max_std 39.9191 (52.5222) nleep/row_min_mean 1446.2041 (1441.5221) lr 1.5567e-04 eta 0:02:09
epoch [43/50] batch [60/176] time 0.089 (0.092) data 0.001 (0.005) loss 1.4613 (1.3030) teacher_loss 0.1910 (0.1195) loss_zs_kd 0.0686 (0.0519) loss_oracle 0.6534 (0.5637) kd_loss 0.9093 (0.8757) acc 93.7500 (96.5104) gate/entropy 1.0378 (1.0379) gate/usage_max 0.4782 (0.4782) gate/usage_min 0.1965 (0.1967) gate/usage_std 0.1151 (0.1151) teacher/entropy 0.0259 (0.0241) teacher/usage_max 0.5091 (0.5959) teacher/usage_min 0.0021 (0.0039) teacher/usage_std 0.2343 (0.2517) nleep/row_max_mean 1484.2717 (1478.1003) nleep/row_max_std 40.0607 (52.6184) nleep/row_min_mean 1446.0608 (1442.0239) lr 1.5567e-04 eta 0:02:04
epoch [43/50] batch [80/176] time 0.096 (0.091) data 0.000 (0.004) loss 1.3135 (1.3013) teacher_loss 0.1006 (0.1173) loss_zs_kd 0.0535 (0.0523) loss_oracle 0.5745 (0.5618) kd_loss 0.8989 (0.8770) acc 100.0000 (96.5625) gate/entropy 1.0377 (1.0379) gate/usage_max 0.4783 (0.4782) gate/usage_min 0.1964 (0.1967) gate/usage_std 0.1152 (0.1151) teacher/entropy 0.0169 (0.0233) teacher/usage_max 0.5357 (0.5902) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.2375 (0.2505) nleep/row_max_mean 1489.0232 (1477.6264) nleep/row_max_std 47.9193 (53.7660) nleep/row_min_mean 1449.9014 (1441.7173) lr 1.5567e-04 eta 0:02:00
epoch [43/50] batch [100/176] time 0.089 (0.091) data 0.000 (0.003) loss 1.2781 (1.3015) teacher_loss 0.0819 (0.1148) loss_zs_kd 0.0485 (0.0522) loss_oracle 0.6403 (0.5648) kd_loss 0.8518 (0.8782) acc 96.8750 (96.6250) gate/entropy 1.0376 (1.0379) gate/usage_max 0.4784 (0.4782) gate/usage_min 0.1963 (0.1966) gate/usage_std 0.1153 (0.1151) teacher/entropy 0.0404 (0.0226) teacher/usage_max 0.5964 (0.5906) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.2485 (0.2503) nleep/row_max_mean 1492.6852 (1477.7387) nleep/row_max_std 61.1555 (54.4299) nleep/row_min_mean 1452.9387 (1441.7753) lr 1.5567e-04 eta 0:01:59
epoch [43/50] batch [120/176] time 0.080 (0.092) data 0.000 (0.002) loss 1.3382 (1.3053) teacher_loss 0.0687 (0.1191) loss_zs_kd 0.0687 (0.0520) loss_oracle 0.6334 (0.5634) kd_loss 0.9184 (0.8784) acc 96.8750 (96.5104) gate/entropy 1.0382 (1.0379) gate/usage_max 0.4775 (0.4782) gate/usage_min 0.1968 (0.1966) gate/usage_std 0.1147 (0.1151) teacher/entropy 0.0149 (0.0221) teacher/usage_max 0.5314 (0.5915) teacher/usage_min 0.0309 (0.0033) teacher/usage_std 0.2173 (0.2503) nleep/row_max_mean 1473.7279 (1477.6623) nleep/row_max_std 50.2202 (54.8043) nleep/row_min_mean 1435.8501 (1441.7150) lr 1.5567e-04 eta 0:01:57
epoch [43/50] batch [140/176] time 0.095 (0.092) data 0.000 (0.002) loss 1.3226 (1.3030) teacher_loss 0.1325 (0.1166) loss_zs_kd 0.0621 (0.0515) loss_oracle 0.5445 (0.5623) kd_loss 0.8868 (0.8796) acc 96.8750 (96.4955) gate/entropy 1.0379 (1.0379) gate/usage_max 0.4780 (0.4782) gate/usage_min 0.1965 (0.1966) gate/usage_std 0.1151 (0.1151) teacher/entropy 0.0069 (0.0225) teacher/usage_max 0.5936 (0.5890) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.2478 (0.2495) nleep/row_max_mean 1472.1304 (1478.1322) nleep/row_max_std 60.5094 (54.9370) nleep/row_min_mean 1434.0703 (1442.0388) lr 1.5567e-04 eta 0:01:56
epoch [43/50] batch [160/176] time 0.097 (0.093) data 0.000 (0.002) loss 1.2508 (1.3003) teacher_loss 0.0455 (0.1139) loss_zs_kd 0.0368 (0.0509) loss_oracle 0.5408 (0.5628) kd_loss 0.9165 (0.8796) acc 96.8750 (96.6016) gate/entropy 1.0380 (1.0379) gate/usage_max 0.4777 (0.4781) gate/usage_min 0.1965 (0.1965) gate/usage_std 0.1149 (0.1151) teacher/entropy 0.0005 (0.0223) teacher/usage_max 0.5312 (0.5880) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.2371 (0.2494) nleep/row_max_mean 1475.4491 (1477.7583) nleep/row_max_std 45.8912 (55.0412) nleep/row_min_mean 1441.1110 (1441.6592) lr 1.5567e-04 eta 0:01:56
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,762
* accuracy: 66.3%
* error: 33.7%
* macro_f1: 59.8%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [44/50] batch [20/176] time 0.088 (0.105) data 0.000 (0.017) loss 1.4439 (1.3033) teacher_loss 0.1855 (0.1057) loss_zs_kd 0.0618 (0.0489) loss_oracle 0.6165 (0.5760) kd_loss 0.9192 (0.8851) acc 87.5000 (97.1875) gate/entropy 1.0380 (1.0378) gate/usage_max 0.4776 (0.4780) gate/usage_min 0.1964 (0.1962) gate/usage_std 0.1149 (0.1152) teacher/entropy 0.0117 (0.0228) teacher/usage_max 0.5013 (0.5867) teacher/usage_min 0.0014 (0.0030) teacher/usage_std 0.2347 (0.2489) nleep/row_max_mean 1482.0266 (1474.9154) nleep/row_max_std 45.7036 (59.5735) nleep/row_min_mean 1447.2189 (1439.2511) lr 1.2369e-04 eta 0:02:07
epoch [44/50] batch [40/176] time 0.098 (0.097) data 0.000 (0.008) loss 1.4294 (1.3254) teacher_loss 0.2300 (0.1279) loss_zs_kd 0.0647 (0.0519) loss_oracle 0.4908 (0.5649) kd_loss 0.9217 (0.8891) acc 93.7500 (96.4844) gate/entropy 1.0379 (1.0378) gate/usage_max 0.4777 (0.4779) gate/usage_min 0.1963 (0.1962) gate/usage_std 0.1150 (0.1151) teacher/entropy 0.0190 (0.0210) teacher/usage_max 0.5001 (0.5789) teacher/usage_min 0.0230 (0.0046) teacher/usage_std 0.2196 (0.2465) nleep/row_max_mean 1477.8123 (1474.9062) nleep/row_max_std 53.4273 (59.1892) nleep/row_min_mean 1446.1686 (1439.3670) lr 1.2369e-04 eta 0:01:56
epoch [44/50] batch [60/176] time 0.095 (0.096) data 0.001 (0.006) loss 1.2555 (1.3052) teacher_loss 0.0752 (0.1092) loss_zs_kd 0.0554 (0.0521) loss_oracle 0.5613 (0.5685) kd_loss 0.8720 (0.8857) acc 96.8750 (96.8750) gate/entropy 1.0378 (1.0378) gate/usage_max 0.4777 (0.4779) gate/usage_min 0.1962 (0.1962) gate/usage_std 0.1151 (0.1151) teacher/entropy 0.0362 (0.0211) teacher/usage_max 0.5747 (0.5834) teacher/usage_min 0.0155 (0.0049) teacher/usage_std 0.2346 (0.2467) nleep/row_max_mean 1486.1880 (1475.2711) nleep/row_max_std 54.3845 (59.3683) nleep/row_min_mean 1447.6885 (1439.3097) lr 1.2369e-04 eta 0:01:53
epoch [44/50] batch [80/176] time 0.090 (0.096) data 0.000 (0.004) loss 1.1872 (1.2992) teacher_loss 0.0219 (0.1087) loss_zs_kd 0.0455 (0.0522) loss_oracle 0.6095 (0.5633) kd_loss 0.8378 (0.8828) acc 100.0000 (97.0312) gate/entropy 1.0378 (1.0378) gate/usage_max 0.4778 (0.4779) gate/usage_min 0.1961 (0.1962) gate/usage_std 0.1151 (0.1151) teacher/entropy 0.0316 (0.0212) teacher/usage_max 0.6554 (0.5914) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.2677 (0.2489) nleep/row_max_mean 1477.6505 (1474.8806) nleep/row_max_std 56.5342 (59.6715) nleep/row_min_mean 1441.5422 (1439.0198) lr 1.2369e-04 eta 0:01:50
epoch [44/50] batch [100/176] time 0.093 (0.096) data 0.000 (0.004) loss 1.1514 (1.2983) teacher_loss 0.0650 (0.1061) loss_zs_kd 0.0351 (0.0523) loss_oracle 0.5244 (0.5663) kd_loss 0.8066 (0.8828) acc 96.8750 (97.0000) gate/entropy 1.0376 (1.0378) gate/usage_max 0.4781 (0.4778) gate/usage_min 0.1960 (0.1962) gate/usage_std 0.1153 (0.1151) teacher/entropy 0.0169 (0.0198) teacher/usage_max 0.7780 (0.5913) teacher/usage_min 0.0019 (0.0043) teacher/usage_std 0.3268 (0.2492) nleep/row_max_mean 1481.1128 (1475.6300) nleep/row_max_std 67.3955 (59.0140) nleep/row_min_mean 1444.7742 (1439.5816) lr 1.2369e-04 eta 0:01:48
epoch [44/50] batch [120/176] time 0.091 (0.096) data 0.000 (0.003) loss 1.3484 (1.2990) teacher_loss 0.1422 (0.1063) loss_zs_kd 0.0499 (0.0531) loss_oracle 0.5327 (0.5652) kd_loss 0.9149 (0.8836) acc 93.7500 (97.0052) gate/entropy 1.0376 (1.0378) gate/usage_max 0.4779 (0.4778) gate/usage_min 0.1959 (0.1961) gate/usage_std 0.1152 (0.1151) teacher/entropy 0.0410 (0.0201) teacher/usage_max 0.5338 (0.5908) teacher/usage_min 0.0161 (0.0041) teacher/usage_std 0.2269 (0.2493) nleep/row_max_mean 1469.4529 (1475.3517) nleep/row_max_std 61.7633 (59.3163) nleep/row_min_mean 1436.8530 (1439.4300) lr 1.2369e-04 eta 0:01:46
epoch [44/50] batch [140/176] time 0.103 (0.095) data 0.000 (0.003) loss 1.4167 (1.2971) teacher_loss 0.2512 (0.1055) loss_zs_kd 0.0262 (0.0532) loss_oracle 0.4666 (0.5640) kd_loss 0.9191 (0.8830) acc 93.7500 (97.0536) gate/entropy 1.0378 (1.0378) gate/usage_max 0.4777 (0.4778) gate/usage_min 0.1961 (0.1961) gate/usage_std 0.1151 (0.1151) teacher/entropy 0.0259 (0.0197) teacher/usage_max 0.5391 (0.5938) teacher/usage_min 0.0019 (0.0040) teacher/usage_std 0.2366 (0.2504) nleep/row_max_mean 1468.8015 (1475.6941) nleep/row_max_std 67.1966 (58.8849) nleep/row_min_mean 1435.9436 (1439.5893) lr 1.2369e-04 eta 0:01:44
epoch [44/50] batch [160/176] time 0.096 (0.095) data 0.000 (0.002) loss 1.3150 (1.3016) teacher_loss 0.1279 (0.1124) loss_zs_kd 0.0498 (0.0529) loss_oracle 0.5511 (0.5625) kd_loss 0.8866 (0.8815) acc 96.8750 (96.8555) gate/entropy 1.0378 (1.0378) gate/usage_max 0.4775 (0.4778) gate/usage_min 0.1960 (0.1961) gate/usage_std 0.1151 (0.1151) teacher/entropy 0.0234 (0.0204) teacher/usage_max 0.5490 (0.5935) teacher/usage_min 0.0003 (0.0038) teacher/usage_std 0.2389 (0.2503) nleep/row_max_mean 1484.6490 (1475.4288) nleep/row_max_std 40.4182 (58.5756) nleep/row_min_mean 1446.6309 (1439.3840) lr 1.2369e-04 eta 0:01:41
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,178
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,759
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 59.7%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [45/50] batch [20/176] time 0.093 (0.108) data 0.000 (0.016) loss 1.1930 (1.3184) teacher_loss 0.0132 (0.1312) loss_zs_kd 0.0378 (0.0522) loss_oracle 0.5451 (0.5518) kd_loss 0.8884 (0.8852) acc 100.0000 (96.7188) gate/entropy 1.0376 (1.0377) gate/usage_max 0.4779 (0.4777) gate/usage_min 0.1958 (0.1959) gate/usage_std 0.1153 (0.1152) teacher/entropy 0.0046 (0.0204) teacher/usage_max 0.5929 (0.6026) teacher/usage_min 0.0002 (0.0013) teacher/usage_std 0.2475 (0.2541) nleep/row_max_mean 1489.4266 (1479.1144) nleep/row_max_std 50.7411 (51.6283) nleep/row_min_mean 1452.4668 (1442.6417) lr 9.5173e-05 eta 0:01:52
epoch [45/50] batch [40/176] time 0.069 (0.095) data 0.000 (0.008) loss 1.2592 (1.3147) teacher_loss 0.1497 (0.1267) loss_zs_kd 0.0528 (0.0539) loss_oracle 0.5339 (0.5674) kd_loss 0.8162 (0.8773) acc 93.7500 (96.6406) gate/entropy 1.0380 (1.0377) gate/usage_max 0.4773 (0.4777) gate/usage_min 0.1961 (0.1959) gate/usage_std 0.1149 (0.1152) teacher/entropy 0.0200 (0.0214) teacher/usage_max 0.7440 (0.6125) teacher/usage_min 0.0001 (0.0029) teacher/usage_std 0.3086 (0.2568) nleep/row_max_mean 1464.5898 (1480.1302) nleep/row_max_std 55.6451 (51.8330) nleep/row_min_mean 1429.1514 (1443.0481) lr 9.5173e-05 eta 0:01:36
epoch [45/50] batch [60/176] time 0.086 (0.093) data 0.001 (0.005) loss 1.1986 (1.3058) teacher_loss 0.0404 (0.1120) loss_zs_kd 0.0428 (0.0514) loss_oracle 0.5019 (0.5652) kd_loss 0.8858 (0.8854) acc 100.0000 (96.9271) gate/entropy 1.0377 (1.0377) gate/usage_max 0.4777 (0.4777) gate/usage_min 0.1958 (0.1958) gate/usage_std 0.1152 (0.1152) teacher/entropy 0.0072 (0.0182) teacher/usage_max 0.5933 (0.6063) teacher/usage_min 0.0005 (0.0026) teacher/usage_std 0.2474 (0.2548) nleep/row_max_mean 1471.2439 (1479.6264) nleep/row_max_std 69.7703 (52.0065) nleep/row_min_mean 1433.7241 (1442.7512) lr 9.5173e-05 eta 0:01:32
epoch [45/50] batch [80/176] time 0.060 (0.095) data 0.000 (0.004) loss 1.3191 (1.2982) teacher_loss 0.1020 (0.1082) loss_zs_kd 0.0692 (0.0515) loss_oracle 0.5357 (0.5635) kd_loss 0.9147 (0.8826) acc 96.8750 (97.1094) gate/entropy 1.0379 (1.0377) gate/usage_max 0.4774 (0.4777) gate/usage_min 0.1961 (0.1958) gate/usage_std 0.1149 (0.1152) teacher/entropy 0.0376 (0.0196) teacher/usage_max 0.5013 (0.6047) teacher/usage_min 0.0261 (0.0030) teacher/usage_std 0.2176 (0.2544) nleep/row_max_mean 1467.9348 (1478.3540) nleep/row_max_std 54.0546 (52.2641) nleep/row_min_mean 1433.1587 (1441.7399) lr 9.5173e-05 eta 0:01:33
epoch [45/50] batch [100/176] time 0.086 (0.092) data 0.000 (0.003) loss 1.3573 (1.3018) teacher_loss 0.1928 (0.1112) loss_zs_kd 0.0442 (0.0503) loss_oracle 0.5613 (0.5612) kd_loss 0.8617 (0.8849) acc 93.7500 (96.9375) gate/entropy 1.0374 (1.0377) gate/usage_max 0.4780 (0.4777) gate/usage_min 0.1955 (0.1958) gate/usage_std 0.1154 (0.1152) teacher/entropy 0.0592 (0.0189) teacher/usage_max 0.5200 (0.5956) teacher/usage_min 0.0012 (0.0026) teacher/usage_std 0.2354 (0.2522) nleep/row_max_mean 1471.3032 (1479.0062) nleep/row_max_std 68.0160 (52.3435) nleep/row_min_mean 1437.7405 (1442.3081) lr 9.5173e-05 eta 0:01:27
epoch [45/50] batch [120/176] time 0.096 (0.089) data 0.000 (0.003) loss 1.1976 (1.2952) teacher_loss 0.0145 (0.1063) loss_zs_kd 0.0478 (0.0512) loss_oracle 0.6496 (0.5613) kd_loss 0.8344 (0.8827) acc 100.0000 (96.9531) gate/entropy 1.0375 (1.0377) gate/usage_max 0.4779 (0.4777) gate/usage_min 0.1956 (0.1958) gate/usage_std 0.1154 (0.1152) teacher/entropy 0.0177 (0.0179) teacher/usage_max 0.7110 (0.6001) teacher/usage_min 0.0077 (0.0023) teacher/usage_std 0.2895 (0.2537) nleep/row_max_mean 1484.9224 (1478.9193) nleep/row_max_std 57.8683 (52.8321) nleep/row_min_mean 1446.8413 (1442.1064) lr 9.5173e-05 eta 0:01:23
epoch [45/50] batch [140/176] time 0.090 (0.088) data 0.000 (0.002) loss 1.2505 (1.2909) teacher_loss 0.0977 (0.1046) loss_zs_kd 0.0767 (0.0511) loss_oracle 0.4711 (0.5602) kd_loss 0.8788 (0.8807) acc 93.7500 (97.0089) gate/entropy 1.0376 (1.0377) gate/usage_max 0.4776 (0.4777) gate/usage_min 0.1956 (0.1958) gate/usage_std 0.1152 (0.1152) teacher/entropy 0.0154 (0.0184) teacher/usage_max 0.5893 (0.6007) teacher/usage_min 0.0010 (0.0023) teacher/usage_std 0.2462 (0.2539) nleep/row_max_mean 1495.5919 (1478.7141) nleep/row_max_std 42.5492 (53.4001) nleep/row_min_mean 1459.0723 (1441.9093) lr 9.5173e-05 eta 0:01:20
epoch [45/50] batch [160/176] time 0.074 (0.088) data 0.000 (0.002) loss 1.4374 (1.2924) teacher_loss 0.2899 (0.1071) loss_zs_kd 0.0542 (0.0513) loss_oracle 0.5107 (0.5596) kd_loss 0.8651 (0.8799) acc 96.8750 (96.9922) gate/entropy 1.0377 (1.0377) gate/usage_max 0.4776 (0.4776) gate/usage_min 0.1957 (0.1958) gate/usage_std 0.1152 (0.1152) teacher/entropy 0.0171 (0.0185) teacher/usage_max 0.6235 (0.6005) teacher/usage_min 0.0018 (0.0024) teacher/usage_std 0.2555 (0.2537) nleep/row_max_mean 1468.4569 (1477.8966) nleep/row_max_std 57.4493 (54.3120) nleep/row_min_mean 1434.9781 (1441.1864) lr 9.5173e-05 eta 0:01:18
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,176
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,757
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 59.7%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [46/50] batch [20/176] time 0.093 (0.104) data 0.000 (0.014) loss 1.3731 (1.2886) teacher_loss 0.2309 (0.1096) loss_zs_kd 0.0476 (0.0508) loss_oracle 0.5562 (0.5578) kd_loss 0.8404 (0.8747) acc 96.8750 (97.0312) gate/entropy 1.0376 (1.0376) gate/usage_max 0.4777 (0.4776) gate/usage_min 0.1956 (0.1956) gate/usage_std 0.1152 (0.1152) teacher/entropy 0.0514 (0.0155) teacher/usage_max 0.5957 (0.6037) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.2483 (0.2527) nleep/row_max_mean 1477.6378 (1478.1089) nleep/row_max_std 60.8115 (58.3673) nleep/row_min_mean 1438.8088 (1441.3115) lr 7.0224e-05 eta 0:01:29
epoch [46/50] batch [40/176] time 0.095 (0.098) data 0.000 (0.007) loss 1.2203 (1.2885) teacher_loss 0.0647 (0.1092) loss_zs_kd 0.0566 (0.0509) loss_oracle 0.5580 (0.5430) kd_loss 0.8483 (0.8823) acc 100.0000 (97.0312) gate/entropy 1.0375 (1.0376) gate/usage_max 0.4778 (0.4776) gate/usage_min 0.1955 (0.1956) gate/usage_std 0.1153 (0.1152) teacher/entropy 0.0089 (0.0164) teacher/usage_max 0.6859 (0.5958) teacher/usage_min 0.0006 (0.0027) teacher/usage_std 0.2801 (0.2509) nleep/row_max_mean 1468.1624 (1479.0543) nleep/row_max_std 54.1403 (55.4591) nleep/row_min_mean 1435.0100 (1442.5290) lr 7.0224e-05 eta 0:01:22
epoch [46/50] batch [60/176] time 0.095 (0.098) data 0.000 (0.005) loss 1.2356 (1.2818) teacher_loss 0.0401 (0.1045) loss_zs_kd 0.0435 (0.0507) loss_oracle 0.5374 (0.5465) kd_loss 0.9050 (0.8787) acc 100.0000 (97.1875) gate/entropy 1.0377 (1.0376) gate/usage_max 0.4774 (0.4776) gate/usage_min 0.1957 (0.1956) gate/usage_std 0.1151 (0.1152) teacher/entropy 0.0026 (0.0178) teacher/usage_max 0.5936 (0.6025) teacher/usage_min 0.0311 (0.0040) teacher/usage_std 0.2315 (0.2524) nleep/row_max_mean 1474.6782 (1478.0576) nleep/row_max_std 61.4870 (56.0643) nleep/row_min_mean 1437.1765 (1441.8345) lr 7.0224e-05 eta 0:01:20
epoch [46/50] batch [80/176] time 0.092 (0.096) data 0.000 (0.004) loss 1.3360 (1.2911) teacher_loss 0.1657 (0.1118) loss_zs_kd 0.0312 (0.0499) loss_oracle 0.5399 (0.5490) kd_loss 0.8848 (0.8799) acc 96.8750 (96.7969) gate/entropy 1.0375 (1.0376) gate/usage_max 0.4776 (0.4776) gate/usage_min 0.1955 (0.1956) gate/usage_std 0.1152 (0.1152) teacher/entropy 0.0235 (0.0178) teacher/usage_max 0.5527 (0.5988) teacher/usage_min 0.0009 (0.0035) teacher/usage_std 0.2390 (0.2516) nleep/row_max_mean 1476.0708 (1477.5157) nleep/row_max_std 62.0794 (55.7397) nleep/row_min_mean 1440.9757 (1441.3535) lr 7.0224e-05 eta 0:01:16
epoch [46/50] batch [100/176] time 0.093 (0.096) data 0.000 (0.003) loss 1.3313 (1.2915) teacher_loss 0.1737 (0.1109) loss_zs_kd 0.0570 (0.0498) loss_oracle 0.5364 (0.5532) kd_loss 0.8609 (0.8790) acc 93.7500 (96.8125) gate/entropy 1.0374 (1.0376) gate/usage_max 0.4778 (0.4776) gate/usage_min 0.1954 (0.1956) gate/usage_std 0.1154 (0.1152) teacher/entropy 0.0081 (0.0181) teacher/usage_max 0.6545 (0.5972) teacher/usage_min 0.0001 (0.0033) teacher/usage_std 0.2673 (0.2515) nleep/row_max_mean 1481.2487 (1477.6815) nleep/row_max_std 57.5396 (55.8704) nleep/row_min_mean 1446.2356 (1441.3051) lr 7.0224e-05 eta 0:01:14
epoch [46/50] batch [120/176] time 0.102 (0.097) data 0.000 (0.003) loss 1.3258 (1.2956) teacher_loss 0.0759 (0.1148) loss_zs_kd 0.0585 (0.0505) loss_oracle 0.6043 (0.5520) kd_loss 0.9185 (0.8796) acc 100.0000 (96.8490) gate/entropy 1.0378 (1.0376) gate/usage_max 0.4773 (0.4776) gate/usage_min 0.1957 (0.1956) gate/usage_std 0.1150 (0.1152) teacher/entropy 0.0105 (0.0190) teacher/usage_max 0.5024 (0.5930) teacher/usage_min 0.0001 (0.0034) teacher/usage_std 0.2356 (0.2503) nleep/row_max_mean 1478.2528 (1477.5781) nleep/row_max_std 54.6135 (55.9996) nleep/row_min_mean 1438.9684 (1441.2658) lr 7.0224e-05 eta 0:01:13
epoch [46/50] batch [140/176] time 0.101 (0.098) data 0.000 (0.002) loss 1.2839 (1.2921) teacher_loss 0.0827 (0.1096) loss_zs_kd 0.0460 (0.0506) loss_oracle 0.5959 (0.5542) kd_loss 0.8803 (0.8801) acc 96.8750 (96.9196) gate/entropy 1.0377 (1.0376) gate/usage_max 0.4774 (0.4776) gate/usage_min 0.1956 (0.1955) gate/usage_std 0.1151 (0.1152) teacher/entropy 0.0003 (0.0182) teacher/usage_max 0.6250 (0.5936) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.2568 (0.2504) nleep/row_max_mean 1475.9833 (1477.6725) nleep/row_max_std 52.9189 (55.2060) nleep/row_min_mean 1436.4719 (1441.1182) lr 7.0224e-05 eta 0:01:12
epoch [46/50] batch [160/176] time 0.101 (0.099) data 0.000 (0.002) loss 1.4794 (1.2938) teacher_loss 0.3034 (0.1103) loss_zs_kd 0.0496 (0.0507) loss_oracle 0.5402 (0.5552) kd_loss 0.8811 (0.8806) acc 90.6250 (96.8750) gate/entropy 1.0376 (1.0376) gate/usage_max 0.4775 (0.4776) gate/usage_min 0.1955 (0.1955) gate/usage_std 0.1152 (0.1152) teacher/entropy 0.0281 (0.0179) teacher/usage_max 0.5476 (0.5929) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.2389 (0.2502) nleep/row_max_mean 1466.1261 (1477.3172) nleep/row_max_std 58.3060 (55.3716) nleep/row_min_mean 1430.6360 (1440.7955) lr 7.0224e-05 eta 0:01:11
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,755
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 59.6%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [47/50] batch [20/176] time 0.098 (0.110) data 0.000 (0.013) loss 1.2214 (1.3039) teacher_loss 0.0645 (0.1134) loss_zs_kd 0.0495 (0.0588) loss_oracle 0.5754 (0.5734) kd_loss 0.8444 (0.8743) acc 96.8750 (97.3438) gate/entropy 1.0376 (1.0375) gate/usage_max 0.4775 (0.4775) gate/usage_min 0.1955 (0.1954) gate/usage_std 0.1152 (0.1152) teacher/entropy 0.0004 (0.0208) teacher/usage_max 0.7188 (0.6058) teacher/usage_min 0.0000 (0.0038) teacher/usage_std 0.2958 (0.2539) nleep/row_max_mean 1477.4537 (1479.9118) nleep/row_max_std 45.3618 (54.0596) nleep/row_min_mean 1440.2495 (1442.4111) lr 4.8943e-05 eta 0:01:15
epoch [47/50] batch [40/176] time 0.089 (0.104) data 0.000 (0.007) loss 1.2020 (1.2835) teacher_loss 0.0298 (0.0927) loss_zs_kd 0.0483 (0.0557) loss_oracle 0.5817 (0.5706) kd_loss 0.8573 (0.8777) acc 100.0000 (97.8125) gate/entropy 1.0376 (1.0375) gate/usage_max 0.4775 (0.4775) gate/usage_min 0.1954 (0.1954) gate/usage_std 0.1152 (0.1152) teacher/entropy 0.0119 (0.0190) teacher/usage_max 0.6532 (0.6059) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.2669 (0.2545) nleep/row_max_mean 1482.0190 (1481.5098) nleep/row_max_std 49.3753 (52.9901) nleep/row_min_mean 1442.7078 (1443.7011) lr 4.8943e-05 eta 0:01:08
epoch [47/50] batch [60/176] time 0.103 (0.101) data 0.001 (0.004) loss 1.3546 (1.2817) teacher_loss 0.1906 (0.0933) loss_zs_kd 0.0425 (0.0544) loss_oracle 0.5838 (0.5643) kd_loss 0.8508 (0.8791) acc 93.7500 (97.5521) gate/entropy 1.0375 (1.0375) gate/usage_max 0.4776 (0.4775) gate/usage_min 0.1954 (0.1954) gate/usage_std 0.1153 (0.1152) teacher/entropy 0.0338 (0.0187) teacher/usage_max 0.6145 (0.6021) teacher/usage_min 0.0004 (0.0030) teacher/usage_std 0.2534 (0.2539) nleep/row_max_mean 1469.7435 (1481.4334) nleep/row_max_std 61.9498 (53.0277) nleep/row_min_mean 1433.7817 (1443.9452) lr 4.8943e-05 eta 0:01:04
epoch [47/50] batch [80/176] time 0.092 (0.100) data 0.000 (0.003) loss 1.3704 (1.2806) teacher_loss 0.1874 (0.0957) loss_zs_kd 0.0534 (0.0534) loss_oracle 0.5597 (0.5612) kd_loss 0.8764 (0.8776) acc 93.7500 (97.3438) gate/entropy 1.0378 (1.0375) gate/usage_max 0.4771 (0.4775) gate/usage_min 0.1957 (0.1954) gate/usage_std 0.1150 (0.1153) teacher/entropy 0.0042 (0.0187) teacher/usage_max 0.6252 (0.6020) teacher/usage_min 0.0004 (0.0029) teacher/usage_std 0.2567 (0.2542) nleep/row_max_mean 1461.1926 (1480.7465) nleep/row_max_std 50.1525 (53.4224) nleep/row_min_mean 1424.9495 (1443.6198) lr 4.8943e-05 eta 0:01:02
epoch [47/50] batch [100/176] time 0.095 (0.099) data 0.001 (0.003) loss 1.3758 (1.2808) teacher_loss 0.1399 (0.0958) loss_zs_kd 0.0591 (0.0524) loss_oracle 0.5861 (0.5622) kd_loss 0.9133 (0.8777) acc 93.7500 (97.2188) gate/entropy 1.0377 (1.0375) gate/usage_max 0.4772 (0.4775) gate/usage_min 0.1955 (0.1954) gate/usage_std 0.1151 (0.1152) teacher/entropy 0.0058 (0.0176) teacher/usage_max 0.5623 (0.6028) teacher/usage_min 0.0303 (0.0031) teacher/usage_std 0.2234 (0.2541) nleep/row_max_mean 1484.8593 (1480.3601) nleep/row_max_std 45.6265 (53.1470) nleep/row_min_mean 1444.0220 (1443.2697) lr 4.8943e-05 eta 0:00:59
epoch [47/50] batch [120/176] time 0.108 (0.098) data 0.000 (0.002) loss 1.2091 (1.2861) teacher_loss 0.0827 (0.1013) loss_zs_kd 0.0394 (0.0519) loss_oracle 0.5607 (0.5614) kd_loss 0.8263 (0.8782) acc 100.0000 (97.0833) gate/entropy 1.0376 (1.0375) gate/usage_max 0.4773 (0.4775) gate/usage_min 0.1953 (0.1954) gate/usage_std 0.1152 (0.1152) teacher/entropy 0.0646 (0.0182) teacher/usage_max 0.5983 (0.6017) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.2490 (0.2534) nleep/row_max_mean 1476.3276 (1480.0133) nleep/row_max_std 62.1429 (53.3189) nleep/row_min_mean 1440.2792 (1443.0536) lr 4.8943e-05 eta 0:00:57
epoch [47/50] batch [140/176] time 0.092 (0.098) data 0.000 (0.002) loss 1.2317 (1.2910) teacher_loss 0.0423 (0.1057) loss_zs_kd 0.0476 (0.0519) loss_oracle 0.5412 (0.5604) kd_loss 0.8949 (0.8792) acc 100.0000 (97.0312) gate/entropy 1.0376 (1.0375) gate/usage_max 0.4774 (0.4775) gate/usage_min 0.1955 (0.1954) gate/usage_std 0.1152 (0.1153) teacher/entropy 0.0010 (0.0176) teacher/usage_max 0.6252 (0.6018) teacher/usage_min 0.0311 (0.0032) teacher/usage_std 0.2426 (0.2534) nleep/row_max_mean 1481.9768 (1481.2350) nleep/row_max_std 39.6007 (52.5280) nleep/row_min_mean 1440.5486 (1444.1584) lr 4.8943e-05 eta 0:00:54
epoch [47/50] batch [160/176] time 0.089 (0.097) data 0.000 (0.002) loss 1.4324 (1.2934) teacher_loss 0.2844 (0.1087) loss_zs_kd 0.0410 (0.0511) loss_oracle 0.5348 (0.5608) kd_loss 0.8600 (0.8787) acc 93.7500 (96.9336) gate/entropy 1.0374 (1.0375) gate/usage_max 0.4776 (0.4775) gate/usage_min 0.1952 (0.1954) gate/usage_std 0.1153 (0.1153) teacher/entropy 0.0090 (0.0178) teacher/usage_max 0.6544 (0.6008) teacher/usage_min 0.0003 (0.0029) teacher/usage_std 0.2672 (0.2533) nleep/row_max_mean 1477.5469 (1480.6261) nleep/row_max_std 53.6871 (52.6540) nleep/row_min_mean 1441.0717 (1443.7879) lr 4.8943e-05 eta 0:00:52
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,175
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,750
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 59.5%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [48/50] batch [20/176] time 0.106 (0.111) data 0.000 (0.017) loss 1.3046 (1.3197) teacher_loss 0.1088 (0.1260) loss_zs_kd 0.0443 (0.0484) loss_oracle 0.6429 (0.5605) kd_loss 0.8522 (0.8894) acc 96.8750 (95.9375) gate/entropy 1.0375 (1.0375) gate/usage_max 0.4774 (0.4774) gate/usage_min 0.1953 (0.1953) gate/usage_std 0.1152 (0.1153) teacher/entropy 0.0054 (0.0105) teacher/usage_max 0.6863 (0.6080) teacher/usage_min 0.0000 (0.0035) teacher/usage_std 0.2805 (0.2557) nleep/row_max_mean 1482.0889 (1482.6909) nleep/row_max_std 48.2654 (46.8724) nleep/row_min_mean 1442.0940 (1446.0073) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [40/176] time 0.099 (0.105) data 0.000 (0.009) loss 1.2781 (1.3059) teacher_loss 0.1671 (0.1182) loss_zs_kd 0.0254 (0.0498) loss_oracle 0.4854 (0.5666) kd_loss 0.8556 (0.8794) acc 96.8750 (96.3281) gate/entropy 1.0375 (1.0375) gate/usage_max 0.4775 (0.4774) gate/usage_min 0.1953 (0.1953) gate/usage_std 0.1153 (0.1153) teacher/entropy 0.0258 (0.0158) teacher/usage_max 0.6202 (0.6116) teacher/usage_min 0.0000 (0.0036) teacher/usage_std 0.2553 (0.2571) nleep/row_max_mean 1480.5779 (1483.9406) nleep/row_max_std 47.0307 (46.1898) nleep/row_min_mean 1448.5784 (1447.0475) lr 3.1417e-05 eta 0:00:51
epoch [48/50] batch [60/176] time 0.092 (0.101) data 0.001 (0.006) loss 1.3600 (1.2972) teacher_loss 0.1904 (0.1134) loss_zs_kd 0.0555 (0.0510) loss_oracle 0.5147 (0.5632) kd_loss 0.8845 (0.8767) acc 93.7500 (96.5104) gate/entropy 1.0373 (1.0375) gate/usage_max 0.4777 (0.4774) gate/usage_min 0.1951 (0.1953) gate/usage_std 0.1154 (0.1153) teacher/entropy 0.0295 (0.0166) teacher/usage_max 0.5349 (0.6103) teacher/usage_min 0.0001 (0.0025) teacher/usage_std 0.2374 (0.2570) nleep/row_max_mean 1468.9541 (1483.0323) nleep/row_max_std 58.5956 (46.5211) nleep/row_min_mean 1436.5269 (1446.2404) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [80/176] time 0.096 (0.099) data 0.000 (0.004) loss 1.2515 (1.2953) teacher_loss 0.0711 (0.1118) loss_zs_kd 0.0828 (0.0521) loss_oracle 0.5604 (0.5619) kd_loss 0.8587 (0.8765) acc 96.8750 (96.4844) gate/entropy 1.0373 (1.0375) gate/usage_max 0.4776 (0.4774) gate/usage_min 0.1950 (0.1953) gate/usage_std 0.1154 (0.1153) teacher/entropy 0.0181 (0.0153) teacher/usage_max 0.6326 (0.6094) teacher/usage_min 0.0001 (0.0020) teacher/usage_std 0.2593 (0.2564) nleep/row_max_mean 1486.0408 (1482.5896) nleep/row_max_std 51.4174 (46.7040) nleep/row_min_mean 1448.0671 (1445.6805) lr 3.1417e-05 eta 0:00:44
epoch [48/50] batch [100/176] time 0.095 (0.102) data 0.000 (0.004) loss 1.2297 (1.2905) teacher_loss 0.0704 (0.1100) loss_zs_kd 0.0303 (0.0506) loss_oracle 0.5326 (0.5605) kd_loss 0.8778 (0.8750) acc 96.8750 (96.6875) gate/entropy 1.0373 (1.0375) gate/usage_max 0.4777 (0.4774) gate/usage_min 0.1952 (0.1953) gate/usage_std 0.1154 (0.1153) teacher/entropy 0.0155 (0.0171) teacher/usage_max 0.5898 (0.6069) teacher/usage_min 0.0001 (0.0021) teacher/usage_std 0.2468 (0.2557) nleep/row_max_mean 1478.9883 (1482.7207) nleep/row_max_std 52.6364 (47.0852) nleep/row_min_mean 1445.6454 (1445.8274) lr 3.1417e-05 eta 0:00:43
epoch [48/50] batch [120/176] time 0.100 (0.101) data 0.000 (0.003) loss 1.3170 (1.2965) teacher_loss 0.0996 (0.1132) loss_zs_kd 0.0569 (0.0512) loss_oracle 0.5237 (0.5623) kd_loss 0.9270 (0.8765) acc 100.0000 (96.5625) gate/entropy 1.0378 (1.0375) gate/usage_max 0.4771 (0.4774) gate/usage_min 0.1956 (0.1953) gate/usage_std 0.1150 (0.1153) teacher/entropy 0.0205 (0.0176) teacher/usage_max 0.5531 (0.6042) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.2397 (0.2548) nleep/row_max_mean 1469.7031 (1482.1883) nleep/row_max_std 39.4857 (47.5666) nleep/row_min_mean 1436.2659 (1445.2778) lr 3.1417e-05 eta 0:00:41
epoch [48/50] batch [140/176] time 0.098 (0.100) data 0.000 (0.003) loss 1.2266 (1.2930) teacher_loss 0.0707 (0.1094) loss_zs_kd 0.0707 (0.0510) loss_oracle 0.5643 (0.5623) kd_loss 0.8384 (0.8770) acc 96.8750 (96.7188) gate/entropy 1.0376 (1.0375) gate/usage_max 0.4773 (0.4774) gate/usage_min 0.1954 (0.1953) gate/usage_std 0.1151 (0.1153) teacher/entropy 0.0078 (0.0176) teacher/usage_max 0.7170 (0.6035) teacher/usage_min 0.0013 (0.0025) teacher/usage_std 0.2945 (0.2543) nleep/row_max_mean 1480.7319 (1482.0010) nleep/row_max_std 52.8014 (47.9496) nleep/row_min_mean 1442.5720 (1445.1095) lr 3.1417e-05 eta 0:00:38
epoch [48/50] batch [160/176] time 0.096 (0.100) data 0.000 (0.002) loss 1.2489 (1.2946) teacher_loss 0.0529 (0.1090) loss_zs_kd 0.0536 (0.0507) loss_oracle 0.5101 (0.5626) kd_loss 0.9142 (0.8790) acc 96.8750 (96.8359) gate/entropy 1.0375 (1.0375) gate/usage_max 0.4773 (0.4774) gate/usage_min 0.1953 (0.1953) gate/usage_std 0.1152 (0.1153) teacher/entropy 0.0265 (0.0178) teacher/usage_max 0.5355 (0.5999) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.2375 (0.2533) nleep/row_max_mean 1483.8495 (1481.3383) nleep/row_max_std 42.2125 (48.3602) nleep/row_min_mean 1445.0312 (1444.5098) lr 3.1417e-05 eta 0:00:36
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,174
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,747
* accuracy: 65.8%
* error: 34.2%
* macro_f1: 59.5%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [49/50] batch [20/176] time 0.100 (0.103) data 0.000 (0.013) loss 1.2346 (1.2556) teacher_loss 0.0183 (0.0689) loss_zs_kd 0.0427 (0.0507) loss_oracle 0.5734 (0.5547) kd_loss 0.9082 (0.8840) acc 100.0000 (98.4375) gate/entropy 1.0376 (1.0374) gate/usage_max 0.4773 (0.4775) gate/usage_min 0.1953 (0.1952) gate/usage_std 0.1152 (0.1153) teacher/entropy 0.0272 (0.0153) teacher/usage_max 0.5204 (0.5864) teacher/usage_min 0.0001 (0.0010) teacher/usage_std 0.2362 (0.2510) nleep/row_max_mean 1472.5010 (1478.8501) nleep/row_max_std 56.9698 (51.4641) nleep/row_min_mean 1435.9775 (1441.6641) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [40/176] time 0.107 (0.099) data 0.000 (0.007) loss 1.2407 (1.2872) teacher_loss 0.0594 (0.0986) loss_zs_kd 0.0560 (0.0505) loss_oracle 0.5743 (0.5572) kd_loss 0.8662 (0.8848) acc 100.0000 (97.2656) gate/entropy 1.0372 (1.0374) gate/usage_max 0.4777 (0.4774) gate/usage_min 0.1949 (0.1952) gate/usage_std 0.1155 (0.1153) teacher/entropy 0.0351 (0.0163) teacher/usage_max 0.5683 (0.5829) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.2422 (0.2496) nleep/row_max_mean 1481.7534 (1481.3656) nleep/row_max_std 67.3579 (51.2770) nleep/row_min_mean 1444.0808 (1444.1490) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [60/176] time 0.064 (0.094) data 0.000 (0.005) loss 1.3070 (1.2906) teacher_loss 0.0690 (0.1051) loss_zs_kd 0.0678 (0.0517) loss_oracle 0.5312 (0.5533) kd_loss 0.9385 (0.8830) acc 96.8750 (97.0833) gate/entropy 1.0375 (1.0374) gate/usage_max 0.4774 (0.4774) gate/usage_min 0.1952 (0.1952) gate/usage_std 0.1153 (0.1153) teacher/entropy 0.0001 (0.0173) teacher/usage_max 0.5313 (0.5882) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.2371 (0.2504) nleep/row_max_mean 1482.3846 (1480.1039) nleep/row_max_std 40.9202 (51.7078) nleep/row_min_mean 1446.0768 (1443.2177) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [80/176] time 0.088 (0.089) data 0.000 (0.004) loss 1.2289 (1.2940) teacher_loss 0.0667 (0.1093) loss_zs_kd 0.0463 (0.0526) loss_oracle 0.5416 (0.5495) kd_loss 0.8683 (0.8837) acc 96.8750 (97.0312) gate/entropy 1.0373 (1.0374) gate/usage_max 0.4776 (0.4774) gate/usage_min 0.1950 (0.1952) gate/usage_std 0.1154 (0.1153) teacher/entropy 0.0002 (0.0161) teacher/usage_max 0.6562 (0.5897) teacher/usage_min 0.0000 (0.0015) teacher/usage_std 0.2680 (0.2507) nleep/row_max_mean 1493.0740 (1480.7564) nleep/row_max_std 41.5918 (51.9586) nleep/row_min_mean 1453.1130 (1443.6710) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [100/176] time 0.071 (0.089) data 0.000 (0.003) loss 1.2152 (1.2962) teacher_loss 0.0475 (0.1146) loss_zs_kd 0.0303 (0.0517) loss_oracle 0.5675 (0.5514) kd_loss 0.8688 (0.8800) acc 96.8750 (96.8750) gate/entropy 1.0374 (1.0374) gate/usage_max 0.4775 (0.4774) gate/usage_min 0.1951 (0.1952) gate/usage_std 0.1153 (0.1153) teacher/entropy 0.0117 (0.0169) teacher/usage_max 0.6221 (0.5962) teacher/usage_min 0.0003 (0.0018) teacher/usage_std 0.2558 (0.2525) nleep/row_max_mean 1481.2209 (1480.4560) nleep/row_max_std 48.2715 (52.1013) nleep/row_min_mean 1443.0691 (1443.4455) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [120/176] time 0.091 (0.089) data 0.000 (0.002) loss 1.1803 (1.2926) teacher_loss 0.0168 (0.1110) loss_zs_kd 0.0274 (0.0512) loss_oracle 0.5377 (0.5513) kd_loss 0.8809 (0.8803) acc 100.0000 (97.0833) gate/entropy 1.0374 (1.0374) gate/usage_max 0.4774 (0.4774) gate/usage_min 0.1951 (0.1952) gate/usage_std 0.1153 (0.1153) teacher/entropy 0.0391 (0.0161) teacher/usage_max 0.5615 (0.5976) teacher/usage_min 0.0321 (0.0021) teacher/usage_std 0.2222 (0.2529) nleep/row_max_mean 1494.7566 (1480.8931) nleep/row_max_std 52.8307 (51.2538) nleep/row_min_mean 1457.9283 (1443.8877) lr 1.7713e-05 eta 0:00:20
epoch [49/50] batch [140/176] time 0.073 (0.089) data 0.000 (0.002) loss 1.3453 (1.2910) teacher_loss 0.1812 (0.1087) loss_zs_kd 0.0564 (0.0514) loss_oracle 0.5823 (0.5538) kd_loss 0.8448 (0.8797) acc 90.6250 (97.0312) gate/entropy 1.0374 (1.0374) gate/usage_max 0.4774 (0.4774) gate/usage_min 0.1951 (0.1952) gate/usage_std 0.1153 (0.1153) teacher/entropy 0.0001 (0.0162) teacher/usage_max 0.7187 (0.5970) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.2957 (0.2527) nleep/row_max_mean 1494.4961 (1481.3589) nleep/row_max_std 47.3091 (50.8573) nleep/row_min_mean 1451.2617 (1444.2535) lr 1.7713e-05 eta 0:00:18
epoch [49/50] batch [160/176] time 0.095 (0.088) data 0.000 (0.002) loss 1.3950 (1.2935) teacher_loss 0.1791 (0.1088) loss_zs_kd 0.0507 (0.0513) loss_oracle 0.6131 (0.5557) kd_loss 0.8840 (0.8811) acc 93.7500 (96.9727) gate/entropy 1.0373 (1.0374) gate/usage_max 0.4775 (0.4774) gate/usage_min 0.1950 (0.1952) gate/usage_std 0.1154 (0.1153) teacher/entropy 0.0071 (0.0158) teacher/usage_max 0.5952 (0.5952) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.2482 (0.2520) nleep/row_max_mean 1488.0991 (1481.2080) nleep/row_max_std 49.8649 (50.8410) nleep/row_min_mean 1448.8115 (1444.1240) lr 1.7713e-05 eta 0:00:16
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,746
* accuracy: 65.7%
* error: 34.3%
* macro_f1: 59.5%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
epoch [50/50] batch [20/176] time 0.090 (0.108) data 0.000 (0.015) loss 1.2881 (1.3122) teacher_loss 0.0970 (0.1163) loss_zs_kd 0.0745 (0.0525) loss_oracle 0.5589 (0.5596) kd_loss 0.8744 (0.8899) acc 93.7500 (95.7812) gate/entropy 1.0373 (1.0374) gate/usage_max 0.4776 (0.4774) gate/usage_min 0.1949 (0.1951) gate/usage_std 0.1155 (0.1153) teacher/entropy 0.0074 (0.0124) teacher/usage_max 0.6232 (0.5866) teacher/usage_min 0.0018 (0.0040) teacher/usage_std 0.2554 (0.2490) nleep/row_max_mean 1481.5391 (1476.0233) nleep/row_max_std 51.4496 (50.5801) nleep/row_min_mean 1445.3660 (1439.5651) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [40/176] time 0.086 (0.100) data 0.000 (0.008) loss 1.2249 (1.2978) teacher_loss 0.0268 (0.1115) loss_zs_kd 0.0407 (0.0538) loss_oracle 0.5592 (0.5611) kd_loss 0.8981 (0.8788) acc 100.0000 (96.5625) gate/entropy 1.0375 (1.0375) gate/usage_max 0.4772 (0.4774) gate/usage_min 0.1953 (0.1952) gate/usage_std 0.1152 (0.1153) teacher/entropy 0.0059 (0.0181) teacher/usage_max 0.5615 (0.5992) teacher/usage_min 0.0003 (0.0047) teacher/usage_std 0.2408 (0.2517) nleep/row_max_mean 1480.5181 (1477.3258) nleep/row_max_std 48.5621 (50.7870) nleep/row_min_mean 1442.1920 (1440.6232) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [60/176] time 0.095 (0.098) data 0.000 (0.005) loss 1.3109 (1.2908) teacher_loss 0.1022 (0.1031) loss_zs_kd 0.0411 (0.0534) loss_oracle 0.5292 (0.5594) kd_loss 0.9235 (0.8813) acc 96.8750 (96.8750) gate/entropy 1.0377 (1.0374) gate/usage_max 0.4769 (0.4774) gate/usage_min 0.1954 (0.1952) gate/usage_std 0.1150 (0.1153) teacher/entropy 0.0040 (0.0174) teacher/usage_max 0.5005 (0.5917) teacher/usage_min 0.0002 (0.0036) teacher/usage_std 0.2356 (0.2513) nleep/row_max_mean 1480.6316 (1478.2562) nleep/row_max_std 51.2684 (51.3477) nleep/row_min_mean 1441.9790 (1441.4174) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [80/176] time 0.100 (0.097) data 0.000 (0.004) loss 1.2577 (1.2986) teacher_loss 0.0144 (0.1126) loss_zs_kd 0.0546 (0.0526) loss_oracle 0.5777 (0.5575) kd_loss 0.9271 (0.8810) acc 100.0000 (96.8750) gate/entropy 1.0377 (1.0374) gate/usage_max 0.4769 (0.4774) gate/usage_min 0.1954 (0.1951) gate/usage_std 0.1150 (0.1153) teacher/entropy 0.0231 (0.0175) teacher/usage_max 0.5568 (0.5937) teacher/usage_min 0.0018 (0.0029) teacher/usage_std 0.2391 (0.2524) nleep/row_max_mean 1479.2306 (1478.6386) nleep/row_max_std 41.4020 (52.0615) nleep/row_min_mean 1440.6055 (1441.8740) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [100/176] time 0.102 (0.097) data 0.000 (0.003) loss 1.2788 (1.2999) teacher_loss 0.1133 (0.1165) loss_zs_kd 0.0490 (0.0516) loss_oracle 0.5422 (0.5550) kd_loss 0.8698 (0.8801) acc 96.8750 (96.6562) gate/entropy 1.0374 (1.0374) gate/usage_max 0.4773 (0.4774) gate/usage_min 0.1951 (0.1951) gate/usage_std 0.1153 (0.1153) teacher/entropy 0.0270 (0.0166) teacher/usage_max 0.5859 (0.5971) teacher/usage_min 0.0040 (0.0027) teacher/usage_std 0.2437 (0.2533) nleep/row_max_mean 1470.4858 (1477.6954) nleep/row_max_std 59.2161 (53.0517) nleep/row_min_mean 1434.7482 (1441.1360) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [120/176] time 0.096 (0.097) data 0.000 (0.003) loss 1.2826 (1.3017) teacher_loss 0.0614 (0.1171) loss_zs_kd 0.0709 (0.0513) loss_oracle 0.4731 (0.5549) kd_loss 0.9492 (0.8816) acc 96.8750 (96.7188) gate/entropy 1.0374 (1.0374) gate/usage_max 0.4774 (0.4774) gate/usage_min 0.1951 (0.1951) gate/usage_std 0.1153 (0.1153) teacher/entropy 0.0011 (0.0175) teacher/usage_max 0.5624 (0.5940) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.2411 (0.2523) nleep/row_max_mean 1489.8201 (1478.0688) nleep/row_max_std 43.3820 (52.7376) nleep/row_min_mean 1451.1510 (1441.5362) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [140/176] time 0.102 (0.097) data 0.000 (0.002) loss 1.3972 (1.2961) teacher_loss 0.2209 (0.1135) loss_zs_kd 0.0377 (0.0512) loss_oracle 0.5625 (0.5549) kd_loss 0.8762 (0.8796) acc 90.6250 (96.8080) gate/entropy 1.0373 (1.0374) gate/usage_max 0.4776 (0.4774) gate/usage_min 0.1950 (0.1951) gate/usage_std 0.1154 (0.1153) teacher/entropy 0.0033 (0.0175) teacher/usage_max 0.6253 (0.5969) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.2569 (0.2531) nleep/row_max_mean 1479.8527 (1478.1287) nleep/row_max_std 48.1788 (52.8118) nleep/row_min_mean 1444.9465 (1441.5714) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [160/176] time 0.102 (0.097) data 0.000 (0.002) loss 1.2878 (1.2914) teacher_loss 0.0619 (0.1083) loss_zs_kd 0.0511 (0.0516) loss_oracle 0.6267 (0.5556) kd_loss 0.8870 (0.8795) acc 96.8750 (97.0117) gate/entropy 1.0372 (1.0374) gate/usage_max 0.4776 (0.4774) gate/usage_min 0.1949 (0.1951) gate/usage_std 0.1155 (0.1153) teacher/entropy 0.0208 (0.0170) teacher/usage_max 0.5506 (0.5966) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.2393 (0.2531) nleep/row_max_mean 1490.7329 (1478.5076) nleep/row_max_std 47.4046 (52.1951) nleep/row_min_mean 1449.7295 (1441.8761) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,745
* accuracy: 65.7%
* error: 34.3%
* macro_f1: 59.4%
******* Domain l best val acc:      90.3%, epoch: 11 *******
******* Domain l best val test acc: 57.9%, epoch: 11 *******
******* Domain l best test acc:     71.4%, epoch: 18 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_3/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:18:16

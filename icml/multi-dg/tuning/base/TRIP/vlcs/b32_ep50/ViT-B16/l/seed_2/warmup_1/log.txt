Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'pascal', 'sun']
Target     ['labelme']
# classes  5
# train_x  5,651
# val      2,422
# test     2,656
---------  ----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/tensorboard)
epoch [1/50] batch [20/176] time 0.102 (0.122) data 0.000 (0.018) loss 1.1162 (1.1999) teacher_loss 0.4812 (0.5412) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0001 (-0.0001) kd_loss 0.6349 (0.6587) acc 84.3750 (79.6875) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3384) gate/usage_min 0.3302 (0.3302) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.4634 (0.4386) teacher/usage_max 0.3891 (0.4283) teacher/usage_min 0.2614 (0.2418) teacher/usage_std 0.0534 (0.0797) nleep/row_max_mean 1535.4531 (1519.4681) nleep/row_max_std 49.0030 (54.7961) nleep/row_min_mean 1530.4050 (1512.1706) lr 1.0000e-05 eta 0:17:55
epoch [1/50] batch [40/176] time 0.078 (0.105) data 0.000 (0.009) loss 0.7023 (1.0924) teacher_loss 0.4269 (0.5262) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0004 (0.0000) kd_loss 0.2752 (0.5662) acc 81.2500 (80.7812) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3385 (0.3384) gate/usage_min 0.3301 (0.3302) gate/usage_std 0.0037 (0.0036) teacher/entropy 0.8207 (0.5310) teacher/usage_max 0.4454 (0.4180) teacher/usage_min 0.2563 (0.2502) teacher/usage_std 0.0811 (0.0713) nleep/row_max_mean 1536.6990 (1524.1124) nleep/row_max_std 30.1075 (48.7017) nleep/row_min_mean 1534.3977 (1518.6942) lr 1.0000e-05 eta 0:15:21
epoch [1/50] batch [60/176] time 0.094 (0.100) data 0.000 (0.006) loss 0.9124 (1.0283) teacher_loss 0.5953 (0.5339) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0008 (0.0003) kd_loss 0.3166 (0.4942) acc 78.1250 (80.3646) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3384) gate/usage_min 0.3301 (0.3301) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.7806 (0.6032) teacher/usage_max 0.3877 (0.4098) teacher/usage_min 0.2614 (0.2587) teacher/usage_std 0.0530 (0.0643) nleep/row_max_mean 1527.9006 (1526.2421) nleep/row_max_std 39.3154 (46.0916) nleep/row_min_mean 1525.6018 (1521.7841) lr 1.0000e-05 eta 0:14:34
epoch [1/50] batch [80/176] time 0.084 (0.099) data 0.000 (0.005) loss 0.6331 (0.9659) teacher_loss 0.4240 (0.5359) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0020 (0.0006) kd_loss 0.2081 (0.4297) acc 84.3750 (80.5469) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3384) gate/usage_min 0.3301 (0.3301) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.8910 (0.6678) teacher/usage_max 0.4111 (0.4019) teacher/usage_min 0.2612 (0.2667) teacher/usage_std 0.0613 (0.0575) nleep/row_max_mean 1520.5209 (1526.3476) nleep/row_max_std 39.3558 (44.3063) nleep/row_min_mean 1518.9534 (1522.5425) lr 1.0000e-05 eta 0:14:21
epoch [1/50] batch [100/176] time 0.101 (0.099) data 0.000 (0.004) loss 0.7222 (0.9149) teacher_loss 0.5579 (0.5347) loss_zs_kd 0.0002 (0.0000) loss_oracle 0.0016 (0.0008) kd_loss 0.1634 (0.3797) acc 71.8750 (80.7188) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3384) gate/usage_min 0.3302 (0.3301) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.9358 (0.7179) teacher/usage_max 0.3427 (0.3975) teacher/usage_min 0.3152 (0.2718) teacher/usage_std 0.0128 (0.0534) nleep/row_max_mean 1516.5093 (1526.1962) nleep/row_max_std 43.3814 (43.3426) nleep/row_min_mean 1515.1062 (1522.8539) lr 1.0000e-05 eta 0:14:21
epoch [1/50] batch [120/176] time 0.104 (0.099) data 0.000 (0.003) loss 0.6543 (0.8752) teacher_loss 0.5206 (0.5384) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0020 (0.0010) kd_loss 0.1327 (0.3363) acc 81.2500 (80.4688) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3384) gate/usage_min 0.3302 (0.3301) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.9659 (0.7615) teacher/usage_max 0.3650 (0.3923) teacher/usage_min 0.3022 (0.2771) teacher/usage_std 0.0256 (0.0490) nleep/row_max_mean 1534.2279 (1525.4671) nleep/row_max_std 49.4493 (43.8914) nleep/row_min_mean 1533.0535 (1522.4933) lr 1.0000e-05 eta 0:14:17
epoch [1/50] batch [140/176] time 0.087 (0.099) data 0.000 (0.003) loss 0.6339 (0.8375) teacher_loss 0.5672 (0.5353) loss_zs_kd 0.0000 (0.0001) loss_oracle 0.0019 (0.0012) kd_loss 0.0657 (0.3016) acc 81.2500 (80.4464) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3384) gate/usage_min 0.3301 (0.3301) gate/usage_std 0.0036 (0.0036) teacher/entropy 1.0320 (0.7963) teacher/usage_max 0.3716 (0.3878) teacher/usage_min 0.2826 (0.2814) teacher/usage_std 0.0374 (0.0452) nleep/row_max_mean 1524.6124 (1525.5136) nleep/row_max_std 48.9833 (43.7936) nleep/row_min_mean 1523.7900 (1522.8265) lr 1.0000e-05 eta 0:14:13
epoch [1/50] batch [160/176] time 0.099 (0.098) data 0.000 (0.002) loss 0.4665 (0.8080) teacher_loss 0.3742 (0.5340) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0022 (0.0013) kd_loss 0.0911 (0.2733) acc 84.3750 (80.7227) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3384) gate/usage_min 0.3301 (0.3301) gate/usage_std 0.0036 (0.0036) teacher/entropy 1.0078 (0.8246) teacher/usage_max 0.3722 (0.3849) teacher/usage_min 0.3127 (0.2844) teacher/usage_std 0.0275 (0.0428) nleep/row_max_mean 1540.3057 (1525.7470) nleep/row_max_std 42.3897 (44.0050) nleep/row_min_mean 1539.4150 (1523.2904) lr 1.0000e-05 eta 0:14:08
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,071
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 87.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,842
* accuracy: 69.4%
* error: 30.6%
* macro_f1: 62.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain l best val acc:      85.5%, epoch: 1 *******
******* Domain l best val test acc: 69.4%, epoch: 1 *******
******* Domain l best test acc:     69.4%, epoch: 1 *******
epoch [2/50] batch [20/176] time 0.097 (0.108) data 0.000 (0.019) loss 0.8489 (0.6860) teacher_loss 0.5063 (0.5388) loss_zs_kd 0.0165 (0.0051) loss_oracle 0.3027 (0.1195) kd_loss 0.1829 (0.0849) acc 84.3750 (83.2812) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3385 (0.3384) gate/usage_min 0.3299 (0.3300) gate/usage_std 0.0037 (0.0037) teacher/entropy 0.9146 (1.0127) teacher/usage_max 0.4667 (0.3886) teacher/usage_min 0.1779 (0.2575) teacher/usage_std 0.1189 (0.0565) nleep/row_max_mean 1513.0291 (1519.3741) nleep/row_max_std 59.0669 (54.4811) nleep/row_min_mean 1511.5028 (1518.4689) lr 2.0000e-03 eta 0:15:32
epoch [2/50] batch [40/176] time 0.096 (0.102) data 0.000 (0.010) loss 1.1250 (0.7723) teacher_loss 0.4160 (0.4699) loss_zs_kd 0.0216 (0.0082) loss_oracle 0.2862 (0.1791) kd_loss 0.5550 (0.2087) acc 84.3750 (84.6094) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3380 (0.3384) gate/usage_min 0.3288 (0.3297) gate/usage_std 0.0038 (0.0037) teacher/entropy 0.5416 (0.8886) teacher/usage_max 0.7201 (0.4839) teacher/usage_min 0.0569 (0.1876) teacher/usage_std 0.2817 (0.1246) nleep/row_max_mean 1518.8459 (1520.7850) nleep/row_max_std 65.5425 (54.4047) nleep/row_min_mean 1515.0240 (1519.1320) lr 2.0000e-03 eta 0:14:31
epoch [2/50] batch [60/176] time 0.088 (0.099) data 0.001 (0.007) loss 0.8321 (0.8480) teacher_loss 0.2146 (0.4316) loss_zs_kd 0.0089 (0.0091) loss_oracle 0.1841 (0.1910) kd_loss 0.5211 (0.3164) acc 96.8750 (86.1458) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3371 (0.3381) gate/usage_min 0.3269 (0.3290) gate/usage_std 0.0046 (0.0038) teacher/entropy 0.5707 (0.7797) teacher/usage_max 0.5427 (0.5333) teacher/usage_min 0.0858 (0.1468) teacher/usage_std 0.1885 (0.1614) nleep/row_max_mean 1519.8473 (1520.9549) nleep/row_max_std 72.9577 (55.0102) nleep/row_min_mean 1515.6956 (1518.4498) lr 2.0000e-03 eta 0:14:06
epoch [2/50] batch [80/176] time 0.091 (0.096) data 0.000 (0.005) loss 1.1143 (0.9293) teacher_loss 0.2461 (0.4067) loss_zs_kd 0.0166 (0.0114) loss_oracle 0.4715 (0.2359) kd_loss 0.6242 (0.3989) acc 93.7500 (87.1875) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3393 (0.3380) gate/usage_min 0.3246 (0.3282) gate/usage_std 0.0063 (0.0042) teacher/entropy 0.4615 (0.6953) teacher/usage_max 0.6423 (0.5530) teacher/usage_min 0.0362 (0.1227) teacher/usage_std 0.2476 (0.1790) nleep/row_max_mean 1532.1028 (1520.4961) nleep/row_max_std 44.1049 (55.8440) nleep/row_min_mean 1525.8823 (1517.1968) lr 2.0000e-03 eta 0:13:41
epoch [2/50] batch [100/176] time 0.093 (0.095) data 0.000 (0.004) loss 1.0781 (0.9938) teacher_loss 0.2709 (0.3861) loss_zs_kd 0.0162 (0.0140) loss_oracle 0.3611 (0.2694) kd_loss 0.6185 (0.4660) acc 90.6250 (87.9688) gate/entropy 1.0982 (1.0985) gate/usage_max 0.3433 (0.3387) gate/usage_min 0.3214 (0.3271) gate/usage_std 0.0090 (0.0049) teacher/entropy 0.4659 (0.6259) teacher/usage_max 0.5254 (0.5700) teacher/usage_min 0.0985 (0.1084) teacher/usage_std 0.1769 (0.1923) nleep/row_max_mean 1500.7865 (1520.1836) nleep/row_max_std 61.9147 (56.2904) nleep/row_min_mean 1494.7063 (1516.0992) lr 2.0000e-03 eta 0:13:29
epoch [2/50] batch [120/176] time 0.094 (0.094) data 0.000 (0.003) loss 1.6537 (1.0476) teacher_loss 0.5303 (0.3729) loss_zs_kd 0.0562 (0.0154) loss_oracle 0.6828 (0.3168) kd_loss 0.7539 (0.5086) acc 90.6250 (88.4896) gate/entropy 1.0980 (1.0984) gate/usage_max 0.3475 (0.3398) gate/usage_min 0.3185 (0.3259) gate/usage_std 0.0119 (0.0059) teacher/entropy 0.3238 (0.5811) teacher/usage_max 0.5734 (0.5805) teacher/usage_min 0.0811 (0.1056) teacher/usage_std 0.2012 (0.1982) nleep/row_max_mean 1515.0117 (1519.5025) nleep/row_max_std 49.9661 (56.4165) nleep/row_min_mean 1506.8296 (1514.9484) lr 2.0000e-03 eta 0:13:23
epoch [2/50] batch [140/176] time 0.094 (0.094) data 0.000 (0.003) loss 1.3206 (1.0850) teacher_loss 0.2216 (0.3589) loss_zs_kd 0.0253 (0.0169) loss_oracle 0.6543 (0.3601) kd_loss 0.7593 (0.5376) acc 90.6250 (88.9509) gate/entropy 1.0976 (1.0983) gate/usage_max 0.3527 (0.3413) gate/usage_min 0.3155 (0.3246) gate/usage_std 0.0152 (0.0070) teacher/entropy 0.3044 (0.5495) teacher/usage_max 0.7256 (0.5920) teacher/usage_min 0.0957 (0.1060) teacher/usage_std 0.2794 (0.2040) nleep/row_max_mean 1524.2684 (1519.0486) nleep/row_max_std 59.6437 (56.6671) nleep/row_min_mean 1515.8054 (1514.0956) lr 2.0000e-03 eta 0:13:17
epoch [2/50] batch [160/176] time 0.098 (0.094) data 0.000 (0.003) loss 1.3184 (1.1182) teacher_loss 0.3338 (0.3544) loss_zs_kd 0.0448 (0.0186) loss_oracle 0.4196 (0.3798) kd_loss 0.7525 (0.5645) acc 87.5000 (88.9844) gate/entropy 1.0971 (1.0982) gate/usage_max 0.3580 (0.3431) gate/usage_min 0.3128 (0.3233) gate/usage_std 0.0187 (0.0082) teacher/entropy 0.3269 (0.5197) teacher/usage_max 0.5669 (0.6055) teacher/usage_min 0.1259 (0.1079) teacher/usage_std 0.1810 (0.2112) nleep/row_max_mean 1509.4172 (1518.3546) nleep/row_max_std 69.6098 (56.8202) nleep/row_min_mean 1500.1097 (1512.9549) lr 2.0000e-03 eta 0:13:15
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,083
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 88.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,922
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 61.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain l best val acc:      86.0%, epoch: 2 *******
******* Domain l best val test acc: 72.4%, epoch: 2 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [3/50] batch [20/176] time 0.112 (0.115) data 0.001 (0.013) loss 1.4153 (1.4660) teacher_loss 0.1969 (0.2898) loss_zs_kd 0.0464 (0.0324) loss_oracle 0.7221 (0.7347) kd_loss 0.8341 (0.7926) acc 90.6250 (91.8750) gate/entropy 1.0959 (1.0962) gate/usage_max 0.3673 (0.3648) gate/usage_min 0.3092 (0.3102) gate/usage_std 0.0247 (0.0230) teacher/entropy 0.2182 (0.2618) teacher/usage_max 0.6759 (0.6873) teacher/usage_min 0.1090 (0.1000) teacher/usage_std 0.2461 (0.2559) nleep/row_max_mean 1522.9727 (1515.5198) nleep/row_max_std 49.5384 (58.0750) nleep/row_min_mean 1511.9479 (1505.3299) lr 1.9980e-03 eta 0:16:12
epoch [3/50] batch [40/176] time 0.099 (0.109) data 0.000 (0.007) loss 1.4059 (1.4405) teacher_loss 0.2574 (0.2685) loss_zs_kd 0.0433 (0.0328) loss_oracle 0.7346 (0.7034) kd_loss 0.7596 (0.8038) acc 90.6250 (91.4844) gate/entropy 1.0950 (1.0958) gate/usage_max 0.3730 (0.3675) gate/usage_min 0.3072 (0.3092) gate/usage_std 0.0285 (0.0249) teacher/entropy 0.2765 (0.2486) teacher/usage_max 0.7232 (0.6790) teacher/usage_min 0.0961 (0.0938) teacher/usage_std 0.2779 (0.2524) nleep/row_max_mean 1514.7363 (1513.3041) nleep/row_max_std 54.5042 (57.6007) nleep/row_min_mean 1502.8831 (1502.6846) lr 1.9980e-03 eta 0:15:15
epoch [3/50] batch [60/176] time 0.094 (0.105) data 0.001 (0.005) loss 1.1740 (1.4336) teacher_loss 0.0876 (0.2693) loss_zs_kd 0.0223 (0.0336) loss_oracle 0.6667 (0.6891) kd_loss 0.7419 (0.8030) acc 100.0000 (91.9271) gate/entropy 1.0941 (1.0954) gate/usage_max 0.3778 (0.3702) gate/usage_min 0.3057 (0.3082) gate/usage_std 0.0318 (0.0267) teacher/entropy 0.3352 (0.2532) teacher/usage_max 0.4934 (0.6423) teacher/usage_min 0.1157 (0.1037) teacher/usage_std 0.1595 (0.2313) nleep/row_max_mean 1505.6854 (1511.9144) nleep/row_max_std 69.0954 (58.7617) nleep/row_min_mean 1495.7617 (1501.2062) lr 1.9980e-03 eta 0:14:42
epoch [3/50] batch [80/176] time 0.110 (0.103) data 0.001 (0.004) loss 1.3356 (1.4195) teacher_loss 0.1605 (0.2603) loss_zs_kd 0.0332 (0.0341) loss_oracle 0.6915 (0.6814) kd_loss 0.8128 (0.8015) acc 96.8750 (92.1484) gate/entropy 1.0934 (1.0950) gate/usage_max 0.3819 (0.3726) gate/usage_min 0.3046 (0.3074) gate/usage_std 0.0345 (0.0283) teacher/entropy 0.2287 (0.2563) teacher/usage_max 0.6372 (0.6185) teacher/usage_min 0.1208 (0.1124) teacher/usage_std 0.2205 (0.2165) nleep/row_max_mean 1504.7939 (1510.8283) nleep/row_max_std 59.7091 (59.4765) nleep/row_min_mean 1489.3342 (1499.7938) lr 1.9980e-03 eta 0:14:22
epoch [3/50] batch [100/176] time 0.155 (0.103) data 0.000 (0.003) loss 1.4557 (1.4292) teacher_loss 0.2771 (0.2609) loss_zs_kd 0.0578 (0.0345) loss_oracle 0.6067 (0.6748) kd_loss 0.8464 (0.8136) acc 90.6250 (91.9375) gate/entropy 1.0924 (1.0946) gate/usage_max 0.3865 (0.3749) gate/usage_min 0.3031 (0.3067) gate/usage_std 0.0377 (0.0299) teacher/entropy 0.1982 (0.2399) teacher/usage_max 0.6056 (0.6251) teacher/usage_min 0.0813 (0.1068) teacher/usage_std 0.2145 (0.2209) nleep/row_max_mean 1511.8582 (1509.7469) nleep/row_max_std 58.7201 (60.1484) nleep/row_min_mean 1497.7000 (1498.0518) lr 1.9980e-03 eta 0:14:20
epoch [3/50] batch [120/176] time 0.099 (0.103) data 0.000 (0.003) loss 1.3335 (1.4324) teacher_loss 0.1548 (0.2597) loss_zs_kd 0.0218 (0.0344) loss_oracle 0.6654 (0.6713) kd_loss 0.8351 (0.8198) acc 96.8750 (91.9271) gate/entropy 1.0912 (1.0941) gate/usage_max 0.3913 (0.3773) gate/usage_min 0.3016 (0.3060) gate/usage_std 0.0411 (0.0314) teacher/entropy 0.1881 (0.2302) teacher/usage_max 0.6702 (0.6283) teacher/usage_min 0.0452 (0.0996) teacher/usage_std 0.2575 (0.2246) nleep/row_max_mean 1478.8575 (1509.4575) nleep/row_max_std 77.3453 (59.9207) nleep/row_min_mean 1463.7738 (1497.2597) lr 1.9980e-03 eta 0:14:13
epoch [3/50] batch [140/176] time 0.106 (0.102) data 0.000 (0.002) loss 1.4652 (1.4336) teacher_loss 0.1794 (0.2526) loss_zs_kd 0.0554 (0.0355) loss_oracle 0.6978 (0.6690) kd_loss 0.9092 (0.8287) acc 90.6250 (92.2098) gate/entropy 1.0901 (1.0936) gate/usage_max 0.3956 (0.3796) gate/usage_min 0.3008 (0.3053) gate/usage_std 0.0441 (0.0331) teacher/entropy 0.1182 (0.2201) teacher/usage_max 0.6319 (0.6227) teacher/usage_min 0.0766 (0.0961) teacher/usage_std 0.2286 (0.2235) nleep/row_max_mean 1499.7048 (1509.0387) nleep/row_max_std 61.0715 (59.6281) nleep/row_min_mean 1482.8964 (1496.3259) lr 1.9980e-03 eta 0:14:05
epoch [3/50] batch [160/176] time 0.101 (0.101) data 0.000 (0.002) loss 1.5535 (1.4349) teacher_loss 0.2427 (0.2432) loss_zs_kd 0.0356 (0.0364) loss_oracle 0.6541 (0.6687) kd_loss 0.9660 (0.8392) acc 87.5000 (92.4805) gate/entropy 1.0890 (1.0931) gate/usage_max 0.3996 (0.3819) gate/usage_min 0.3001 (0.3047) gate/usage_std 0.0469 (0.0346) teacher/entropy 0.0996 (0.2099) teacher/usage_max 0.4825 (0.6156) teacher/usage_min 0.0480 (0.0939) teacher/usage_std 0.2018 (0.2216) nleep/row_max_mean 1506.8068 (1508.6632) nleep/row_max_std 48.8133 (59.1818) nleep/row_min_mean 1490.5466 (1495.4782) lr 1.9980e-03 eta 0:14:01
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,160
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 91.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,796
* accuracy: 67.6%
* error: 32.4%
* macro_f1: 60.9%
******* Domain l best val acc:      89.2%, epoch: 3 *******
******* Domain l best val test acc: 67.6%, epoch: 3 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [4/50] batch [20/176] time 0.094 (0.115) data 0.000 (0.018) loss 1.4768 (1.4264) teacher_loss 0.1225 (0.1617) loss_zs_kd 0.0610 (0.0512) loss_oracle 0.5996 (0.5901) kd_loss 1.0240 (0.9440) acc 93.7500 (95.4688) gate/entropy 1.0873 (1.0877) gate/usage_max 0.4052 (0.4039) gate/usage_min 0.2947 (0.2961) gate/usage_std 0.0509 (0.0499) teacher/entropy 0.0774 (0.1240) teacher/usage_max 0.5902 (0.5274) teacher/usage_min 0.0659 (0.0747) teacher/usage_std 0.2142 (0.1953) nleep/row_max_mean 1510.7939 (1504.4855) nleep/row_max_std 49.2786 (55.9668) nleep/row_min_mean 1489.8806 (1486.7922) lr 1.9921e-03 eta 0:15:51
epoch [4/50] batch [40/176] time 0.094 (0.114) data 0.000 (0.009) loss 1.3633 (1.4189) teacher_loss 0.1396 (0.1666) loss_zs_kd 0.0567 (0.0494) loss_oracle 0.5509 (0.5704) kd_loss 0.9199 (0.9424) acc 96.8750 (95.0781) gate/entropy 1.0866 (1.0873) gate/usage_max 0.4073 (0.4051) gate/usage_min 0.2919 (0.2946) gate/usage_std 0.0524 (0.0508) teacher/entropy 0.1128 (0.1252) teacher/usage_max 0.5588 (0.5326) teacher/usage_min 0.0266 (0.0735) teacher/usage_std 0.2247 (0.1969) nleep/row_max_mean 1512.3342 (1504.3170) nleep/row_max_std 55.6477 (57.0436) nleep/row_min_mean 1493.4287 (1486.5532) lr 1.9921e-03 eta 0:15:41
epoch [4/50] batch [60/176] time 0.099 (0.107) data 0.001 (0.006) loss 1.4355 (1.4091) teacher_loss 0.0975 (0.1518) loss_zs_kd 0.0635 (0.0514) loss_oracle 0.6043 (0.5719) kd_loss 1.0041 (0.9457) acc 93.7500 (95.4688) gate/entropy 1.0860 (1.0870) gate/usage_max 0.4090 (0.4061) gate/usage_min 0.2896 (0.2933) gate/usage_std 0.0537 (0.0516) teacher/entropy 0.0611 (0.1227) teacher/usage_max 0.5417 (0.5257) teacher/usage_min 0.0160 (0.0759) teacher/usage_std 0.2280 (0.1933) nleep/row_max_mean 1511.3673 (1503.6359) nleep/row_max_std 45.9620 (56.8055) nleep/row_min_mean 1489.3618 (1485.2352) lr 1.9921e-03 eta 0:14:41
epoch [4/50] batch [80/176] time 0.094 (0.104) data 0.000 (0.005) loss 1.3725 (1.4043) teacher_loss 0.0784 (0.1431) loss_zs_kd 0.0487 (0.0523) loss_oracle 0.5615 (0.5692) kd_loss 0.9890 (0.9505) acc 96.8750 (95.8594) gate/entropy 1.0853 (1.0867) gate/usage_max 0.4110 (0.4071) gate/usage_min 0.2868 (0.2920) gate/usage_std 0.0553 (0.0523) teacher/entropy 0.1058 (0.1200) teacher/usage_max 0.6138 (0.5257) teacher/usage_min 0.0474 (0.0775) teacher/usage_std 0.2313 (0.1921) nleep/row_max_mean 1499.9371 (1504.2337) nleep/row_max_std 72.0358 (56.2048) nleep/row_min_mean 1478.9979 (1485.1242) lr 1.9921e-03 eta 0:14:10
epoch [4/50] batch [100/176] time 0.096 (0.102) data 0.000 (0.004) loss 1.3226 (1.3999) teacher_loss 0.0435 (0.1340) loss_zs_kd 0.0585 (0.0519) loss_oracle 0.5534 (0.5636) kd_loss 0.9732 (0.9581) acc 100.0000 (96.3125) gate/entropy 1.0850 (1.0863) gate/usage_max 0.4116 (0.4080) gate/usage_min 0.2845 (0.2907) gate/usage_std 0.0559 (0.0530) teacher/entropy 0.1053 (0.1163) teacher/usage_max 0.5731 (0.5382) teacher/usage_min 0.0465 (0.0778) teacher/usage_std 0.2176 (0.1962) nleep/row_max_mean 1492.3881 (1503.3983) nleep/row_max_std 68.6476 (57.0811) nleep/row_min_mean 1471.2672 (1483.6358) lr 1.9921e-03 eta 0:13:52
epoch [4/50] batch [120/176] time 0.091 (0.101) data 0.000 (0.003) loss 1.4696 (1.4064) teacher_loss 0.1630 (0.1379) loss_zs_kd 0.0507 (0.0515) loss_oracle 0.5941 (0.5619) kd_loss 0.9842 (0.9618) acc 93.7500 (96.1719) gate/entropy 1.0846 (1.0861) gate/usage_max 0.4123 (0.4086) gate/usage_min 0.2822 (0.2895) gate/usage_std 0.0566 (0.0535) teacher/entropy 0.1439 (0.1153) teacher/usage_max 0.7111 (0.5427) teacher/usage_min 0.0769 (0.0804) teacher/usage_std 0.2727 (0.1968) nleep/row_max_mean 1483.0345 (1502.3642) nleep/row_max_std 69.8655 (57.7046) nleep/row_min_mean 1463.3329 (1482.1572) lr 1.9921e-03 eta 0:13:39
epoch [4/50] batch [140/176] time 0.075 (0.099) data 0.000 (0.003) loss 1.3418 (1.4057) teacher_loss 0.0380 (0.1300) loss_zs_kd 0.0374 (0.0529) loss_oracle 0.6265 (0.5696) kd_loss 0.9717 (0.9645) acc 96.8750 (96.4509) gate/entropy 1.0842 (1.0858) gate/usage_max 0.4130 (0.4092) gate/usage_min 0.2802 (0.2883) gate/usage_std 0.0574 (0.0540) teacher/entropy 0.0914 (0.1136) teacher/usage_max 0.4637 (0.5432) teacher/usage_min 0.1055 (0.0832) teacher/usage_std 0.1617 (0.1958) nleep/row_max_mean 1498.2545 (1501.8317) nleep/row_max_std 62.1016 (57.8621) nleep/row_min_mean 1474.3801 (1481.1515) lr 1.9921e-03 eta 0:13:23
epoch [4/50] batch [160/176] time 0.089 (0.097) data 0.000 (0.003) loss 1.5066 (1.4132) teacher_loss 0.1765 (0.1353) loss_zs_kd 0.0403 (0.0527) loss_oracle 0.6413 (0.5701) kd_loss 0.9893 (0.9664) acc 93.7500 (96.4258) gate/entropy 1.0840 (1.0856) gate/usage_max 0.4134 (0.4097) gate/usage_min 0.2789 (0.2872) gate/usage_std 0.0578 (0.0545) teacher/entropy 0.1249 (0.1152) teacher/usage_max 0.3557 (0.5370) teacher/usage_min 0.3081 (0.0965) teacher/usage_std 0.0195 (0.1878) nleep/row_max_mean 1501.5074 (1500.6865) nleep/row_max_std 50.9275 (58.0722) nleep/row_min_mean 1480.5195 (1479.6718) lr 1.9921e-03 eta 0:13:10
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,149
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 90.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,612
* accuracy: 60.7%
* error: 39.3%
* macro_f1: 57.7%
******* Domain l best val acc:      89.2%, epoch: 3 *******
******* Domain l best val test acc: 67.6%, epoch: 3 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [5/50] batch [20/176] time 0.076 (0.103) data 0.000 (0.013) loss 1.3983 (1.4701) teacher_loss 0.0784 (0.1197) loss_zs_kd 0.0780 (0.0686) loss_oracle 0.5474 (0.5864) kd_loss 1.0071 (1.0228) acc 96.8750 (97.1875) gate/entropy 1.0844 (1.0842) gate/usage_max 0.4117 (0.4124) gate/usage_min 0.2785 (0.2784) gate/usage_std 0.0568 (0.0573) teacher/entropy 0.1337 (0.1252) teacher/usage_max 0.4963 (0.5210) teacher/usage_min 0.2155 (0.1821) teacher/usage_std 0.1190 (0.1444) nleep/row_max_mean 1493.4221 (1497.1705) nleep/row_max_std 59.8268 (60.0906) nleep/row_min_mean 1466.2566 (1471.0152) lr 1.9823e-03 eta 0:13:52
epoch [5/50] batch [40/176] time 0.092 (0.097) data 0.000 (0.007) loss 1.5798 (1.4672) teacher_loss 0.2980 (0.1154) loss_zs_kd 0.0471 (0.0651) loss_oracle 0.6420 (0.5879) kd_loss 0.9373 (1.0253) acc 90.6250 (96.9531) gate/entropy 1.0848 (1.0844) gate/usage_max 0.4105 (0.4118) gate/usage_min 0.2789 (0.2786) gate/usage_std 0.0561 (0.0569) teacher/entropy 0.1968 (0.1200) teacher/usage_max 0.4356 (0.4978) teacher/usage_min 0.2475 (0.1930) teacher/usage_std 0.0777 (0.1302) nleep/row_max_mean 1475.5513 (1496.0398) nleep/row_max_std 68.7344 (57.6696) nleep/row_min_mean 1450.9102 (1469.4901) lr 1.9823e-03 eta 0:13:05
epoch [5/50] batch [60/176] time 0.088 (0.096) data 0.001 (0.005) loss 1.5214 (1.4787) teacher_loss 0.2459 (0.1252) loss_zs_kd 0.0460 (0.0621) loss_oracle 0.5532 (0.5845) kd_loss 0.9759 (1.0301) acc 90.6250 (96.6667) gate/entropy 1.0852 (1.0846) gate/usage_max 0.4091 (0.4111) gate/usage_min 0.2794 (0.2787) gate/usage_std 0.0552 (0.0565) teacher/entropy 0.1462 (0.1175) teacher/usage_max 0.4732 (0.4934) teacher/usage_min 0.2616 (0.1859) teacher/usage_std 0.0989 (0.1307) nleep/row_max_mean 1479.3782 (1495.3154) nleep/row_max_std 57.7027 (56.1751) nleep/row_min_mean 1455.3763 (1468.5525) lr 1.9823e-03 eta 0:12:49
epoch [5/50] batch [80/176] time 0.096 (0.094) data 0.000 (0.004) loss 1.4058 (1.4783) teacher_loss 0.0256 (0.1193) loss_zs_kd 0.0689 (0.0627) loss_oracle 0.6506 (0.5816) kd_loss 1.0205 (1.0369) acc 100.0000 (96.8359) gate/entropy 1.0855 (1.0848) gate/usage_max 0.4082 (0.4105) gate/usage_min 0.2792 (0.2789) gate/usage_std 0.0547 (0.0561) teacher/entropy 0.0926 (0.1098) teacher/usage_max 0.4739 (0.4993) teacher/usage_min 0.2394 (0.1877) teacher/usage_std 0.1013 (0.1330) nleep/row_max_mean 1505.9645 (1496.1041) nleep/row_max_std 47.3480 (55.2580) nleep/row_min_mean 1475.3077 (1469.0109) lr 1.9823e-03 eta 0:12:36
epoch [5/50] batch [100/176] time 0.080 (0.094) data 0.000 (0.003) loss 1.5689 (1.4829) teacher_loss 0.2249 (0.1216) loss_zs_kd 0.0658 (0.0622) loss_oracle 0.5429 (0.5775) kd_loss 1.0396 (1.0413) acc 96.8750 (96.8438) gate/entropy 1.0859 (1.0850) gate/usage_max 0.4066 (0.4099) gate/usage_min 0.2796 (0.2790) gate/usage_std 0.0537 (0.0557) teacher/entropy 0.0821 (0.1054) teacher/usage_max 0.4189 (0.5028) teacher/usage_min 0.2773 (0.1860) teacher/usage_std 0.0615 (0.1352) nleep/row_max_mean 1487.0138 (1494.9978) nleep/row_max_std 52.1820 (55.7368) nleep/row_min_mean 1465.3651 (1467.9216) lr 1.9823e-03 eta 0:12:34
epoch [5/50] batch [120/176] time 0.088 (0.093) data 0.000 (0.002) loss 1.4392 (1.4886) teacher_loss 0.1116 (0.1251) loss_zs_kd 0.0656 (0.0631) loss_oracle 0.5621 (0.5757) kd_loss 1.0138 (1.0441) acc 96.8750 (96.8229) gate/entropy 1.0863 (1.0852) gate/usage_max 0.4052 (0.4092) gate/usage_min 0.2798 (0.2791) gate/usage_std 0.0528 (0.0553) teacher/entropy 0.0890 (0.1004) teacher/usage_max 0.3967 (0.5074) teacher/usage_min 0.2695 (0.1861) teacher/usage_std 0.0519 (0.1376) nleep/row_max_mean 1479.8550 (1494.4532) nleep/row_max_std 64.8459 (55.2950) nleep/row_min_mean 1455.7472 (1467.2378) lr 1.9823e-03 eta 0:12:23
epoch [5/50] batch [140/176] time 0.077 (0.092) data 0.000 (0.002) loss 1.4924 (1.4873) teacher_loss 0.0492 (0.1220) loss_zs_kd 0.0710 (0.0633) loss_oracle 0.6120 (0.5717) kd_loss 1.1017 (1.0479) acc 100.0000 (96.8304) gate/entropy 1.0864 (1.0853) gate/usage_max 0.4044 (0.4086) gate/usage_min 0.2790 (0.2791) gate/usage_std 0.0526 (0.0549) teacher/entropy 0.0591 (0.0941) teacher/usage_max 0.5455 (0.5111) teacher/usage_min 0.1257 (0.1845) teacher/usage_std 0.1714 (0.1396) nleep/row_max_mean 1487.3530 (1494.1794) nleep/row_max_std 60.8616 (55.3504) nleep/row_min_mean 1460.2927 (1466.7625) lr 1.9823e-03 eta 0:12:14
epoch [5/50] batch [160/176] time 0.150 (0.093) data 0.001 (0.002) loss 1.6549 (1.4854) teacher_loss 0.2583 (0.1171) loss_zs_kd 0.0516 (0.0624) loss_oracle 0.5674 (0.5710) kd_loss 1.0871 (1.0515) acc 96.8750 (96.9922) gate/entropy 1.0866 (1.0855) gate/usage_max 0.4031 (0.4080) gate/usage_min 0.2783 (0.2791) gate/usage_std 0.0520 (0.0546) teacher/entropy 0.0531 (0.0889) teacher/usage_max 0.6759 (0.5197) teacher/usage_min 0.1256 (0.1831) teacher/usage_std 0.2440 (0.1444) nleep/row_max_mean 1481.2468 (1494.1999) nleep/row_max_std 64.6118 (55.2748) nleep/row_min_mean 1452.0428 (1466.5635) lr 1.9823e-03 eta 0:12:16
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,147
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 90.8%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,572
* accuracy: 59.2%
* error: 40.8%
* macro_f1: 56.1%
******* Domain l best val acc:      89.2%, epoch: 3 *******
******* Domain l best val test acc: 67.6%, epoch: 3 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [6/50] batch [20/176] time 0.095 (0.111) data 0.000 (0.019) loss 1.4781 (1.5254) teacher_loss 0.0516 (0.1302) loss_zs_kd 0.0556 (0.0593) loss_oracle 0.6057 (0.5659) kd_loss 1.0959 (1.0826) acc 100.0000 (96.4062) gate/entropy 1.0871 (1.0870) gate/usage_max 0.4003 (0.4010) gate/usage_min 0.2772 (0.2774) gate/usage_std 0.0509 (0.0511) teacher/entropy 0.0079 (0.0411) teacher/usage_max 0.5010 (0.5898) teacher/usage_min 0.2182 (0.1561) teacher/usage_std 0.1213 (0.1892) nleep/row_max_mean 1502.6538 (1493.4122) nleep/row_max_std 58.9847 (57.2296) nleep/row_min_mean 1472.0583 (1463.1196) lr 1.9686e-03 eta 0:14:38
epoch [6/50] batch [40/176] time 0.089 (0.104) data 0.000 (0.010) loss 1.4349 (1.5028) teacher_loss 0.0487 (0.1021) loss_zs_kd 0.0417 (0.0624) loss_oracle 0.5901 (0.5741) kd_loss 1.0703 (1.0825) acc 96.8750 (97.0312) gate/entropy 1.0875 (1.0871) gate/usage_max 0.3983 (0.4001) gate/usage_min 0.2772 (0.2773) gate/usage_std 0.0498 (0.0507) teacher/entropy 0.0603 (0.0429) teacher/usage_max 0.5371 (0.5906) teacher/usage_min 0.1861 (0.1549) teacher/usage_std 0.1488 (0.1894) nleep/row_max_mean 1492.3048 (1492.1944) nleep/row_max_std 60.7516 (58.1659) nleep/row_min_mean 1463.3750 (1461.9397) lr 1.9686e-03 eta 0:13:36
epoch [6/50] batch [60/176] time 0.103 (0.102) data 0.002 (0.007) loss 1.5401 (1.5094) teacher_loss 0.2284 (0.1086) loss_zs_kd 0.0724 (0.0607) loss_oracle 0.4754 (0.5705) kd_loss 1.0378 (1.0853) acc 96.8750 (96.9792) gate/entropy 1.0879 (1.0873) gate/usage_max 0.3965 (0.3993) gate/usage_min 0.2771 (0.2772) gate/usage_std 0.0490 (0.0503) teacher/entropy 0.0615 (0.0406) teacher/usage_max 0.7404 (0.5950) teacher/usage_min 0.0836 (0.1527) teacher/usage_std 0.2903 (0.1919) nleep/row_max_mean 1477.6709 (1492.5478) nleep/row_max_std 71.3294 (57.9443) nleep/row_min_mean 1448.7734 (1462.1136) lr 1.9686e-03 eta 0:13:18
epoch [6/50] batch [80/176] time 0.094 (0.099) data 0.000 (0.005) loss 1.5911 (1.5187) teacher_loss 0.1074 (0.1182) loss_zs_kd 0.0717 (0.0593) loss_oracle 0.7038 (0.5737) kd_loss 1.0959 (1.0840) acc 93.7500 (96.4453) gate/entropy 1.0882 (1.0875) gate/usage_max 0.3944 (0.3983) gate/usage_min 0.2769 (0.2772) gate/usage_std 0.0481 (0.0499) teacher/entropy 0.0249 (0.0419) teacher/usage_max 0.6274 (0.5997) teacher/usage_min 0.1563 (0.1502) teacher/usage_std 0.2093 (0.1954) nleep/row_max_mean 1492.9233 (1492.8239) nleep/row_max_std 58.3420 (57.7176) nleep/row_min_mean 1460.0280 (1462.1191) lr 1.9686e-03 eta 0:12:56
epoch [6/50] batch [100/176] time 0.090 (0.099) data 0.000 (0.004) loss 1.6235 (1.5187) teacher_loss 0.2373 (0.1209) loss_zs_kd 0.0711 (0.0608) loss_oracle 0.4948 (0.5702) kd_loss 1.1032 (1.0823) acc 93.7500 (96.3125) gate/entropy 1.0884 (1.0877) gate/usage_max 0.3929 (0.3974) gate/usage_min 0.2766 (0.2771) gate/usage_std 0.0475 (0.0494) teacher/entropy 0.0141 (0.0420) teacher/usage_max 0.6871 (0.5984) teacher/usage_min 0.1288 (0.1526) teacher/usage_std 0.2512 (0.1943) nleep/row_max_mean 1505.8105 (1493.7113) nleep/row_max_std 52.4085 (56.8868) nleep/row_min_mean 1471.0377 (1462.9251) lr 1.9686e-03 eta 0:12:57
epoch [6/50] batch [120/176] time 0.092 (0.099) data 0.001 (0.004) loss 1.7444 (1.5149) teacher_loss 0.2942 (0.1189) loss_zs_kd 0.0818 (0.0614) loss_oracle 0.6041 (0.5693) kd_loss 1.1072 (1.0807) acc 84.3750 (96.2760) gate/entropy 1.0886 (1.0878) gate/usage_max 0.3916 (0.3965) gate/usage_min 0.2762 (0.2770) gate/usage_std 0.0471 (0.0491) teacher/entropy 0.0340 (0.0424) teacher/usage_max 0.4899 (0.5960) teacher/usage_min 0.1560 (0.1536) teacher/usage_std 0.1371 (0.1927) nleep/row_max_mean 1497.9141 (1494.6240) nleep/row_max_std 56.3439 (56.0814) nleep/row_min_mean 1464.6837 (1463.7087) lr 1.9686e-03 eta 0:12:52
epoch [6/50] batch [140/176] time 0.108 (0.099) data 0.001 (0.003) loss 1.5288 (1.5106) teacher_loss 0.0846 (0.1151) loss_zs_kd 0.0593 (0.0619) loss_oracle 0.6935 (0.5738) kd_loss 1.0679 (1.0777) acc 96.8750 (96.3839) gate/entropy 1.0887 (1.0879) gate/usage_max 0.3900 (0.3957) gate/usage_min 0.2757 (0.2768) gate/usage_std 0.0467 (0.0488) teacher/entropy 0.0324 (0.0434) teacher/usage_max 0.4697 (0.5995) teacher/usage_min 0.2496 (0.1527) teacher/usage_std 0.0973 (0.1950) nleep/row_max_mean 1492.1456 (1494.5261) nleep/row_max_std 53.6847 (56.4255) nleep/row_min_mean 1463.8845 (1463.6540) lr 1.9686e-03 eta 0:12:53
epoch [6/50] batch [160/176] time 0.092 (0.099) data 0.000 (0.003) loss 1.4168 (1.5136) teacher_loss 0.0481 (0.1194) loss_zs_kd 0.0309 (0.0608) loss_oracle 0.4953 (0.5754) kd_loss 1.1056 (1.0761) acc 100.0000 (96.2695) gate/entropy 1.0887 (1.0880) gate/usage_max 0.3889 (0.3949) gate/usage_min 0.2747 (0.2766) gate/usage_std 0.0467 (0.0485) teacher/entropy 0.0233 (0.0437) teacher/usage_max 0.7508 (0.6031) teacher/usage_min 0.0302 (0.1506) teacher/usage_std 0.3051 (0.1974) nleep/row_max_mean 1502.0176 (1494.0601) nleep/row_max_std 62.5405 (57.0429) nleep/row_min_mean 1467.5459 (1463.2801) lr 1.9686e-03 eta 0:12:45
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,166
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,837
* accuracy: 69.2%
* error: 30.8%
* macro_f1: 63.1%
******* Domain l best val acc:      89.4%, epoch: 6 *******
******* Domain l best val test acc: 69.2%, epoch: 6 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [7/50] batch [20/176] time 0.087 (0.107) data 0.000 (0.015) loss 1.5142 (1.5357) teacher_loss 0.1242 (0.1509) loss_zs_kd 0.0603 (0.0626) loss_oracle 0.6306 (0.5853) kd_loss 1.0446 (1.0609) acc 93.7500 (96.2500) gate/entropy 1.0890 (1.0889) gate/usage_max 0.3861 (0.3868) gate/usage_min 0.2740 (0.2743) gate/usage_std 0.0460 (0.0461) teacher/entropy 0.0920 (0.0489) teacher/usage_max 0.6255 (0.6349) teacher/usage_min 0.0658 (0.1372) teacher/usage_std 0.2292 (0.2198) nleep/row_max_mean 1496.2517 (1493.1908) nleep/row_max_std 47.6364 (58.3638) nleep/row_min_mean 1462.0002 (1462.6893) lr 1.9511e-03 eta 0:13:49
epoch [7/50] batch [40/176] time 0.102 (0.099) data 0.000 (0.008) loss 1.6795 (1.5342) teacher_loss 0.3039 (0.1465) loss_zs_kd 0.0892 (0.0606) loss_oracle 0.5743 (0.5955) kd_loss 1.0438 (1.0596) acc 90.6250 (96.0156) gate/entropy 1.0891 (1.0890) gate/usage_max 0.3843 (0.3860) gate/usage_min 0.2737 (0.2741) gate/usage_std 0.0456 (0.0459) teacher/entropy 0.0759 (0.0512) teacher/usage_max 0.7031 (0.6228) teacher/usage_min 0.0566 (0.1362) teacher/usage_std 0.2720 (0.2121) nleep/row_max_mean 1474.5239 (1491.9487) nleep/row_max_std 69.5418 (59.4044) nleep/row_min_mean 1443.0063 (1461.7333) lr 1.9511e-03 eta 0:12:44
epoch [7/50] batch [60/176] time 0.097 (0.104) data 0.001 (0.005) loss 1.4733 (1.5170) teacher_loss 0.0783 (0.1418) loss_zs_kd 0.0732 (0.0578) loss_oracle 0.6036 (0.5856) kd_loss 1.0566 (1.0535) acc 96.8750 (96.1979) gate/entropy 1.0891 (1.0890) gate/usage_max 0.3828 (0.3852) gate/usage_min 0.2728 (0.2738) gate/usage_std 0.0456 (0.0458) teacher/entropy 0.0502 (0.0529) teacher/usage_max 0.5859 (0.6322) teacher/usage_min 0.1630 (0.1374) teacher/usage_std 0.1822 (0.2173) nleep/row_max_mean 1507.7688 (1491.6508) nleep/row_max_std 39.3240 (58.6649) nleep/row_min_mean 1473.8865 (1461.6873) lr 1.9511e-03 eta 0:13:19
epoch [7/50] batch [80/176] time 0.080 (0.102) data 0.000 (0.004) loss 1.6331 (1.5175) teacher_loss 0.2242 (0.1493) loss_zs_kd 0.0621 (0.0584) loss_oracle 0.5541 (0.5742) kd_loss 1.1008 (1.0519) acc 93.7500 (96.0547) gate/entropy 1.0891 (1.0890) gate/usage_max 0.3812 (0.3844) gate/usage_min 0.2722 (0.2734) gate/usage_std 0.0455 (0.0458) teacher/entropy 0.0363 (0.0533) teacher/usage_max 0.6330 (0.6320) teacher/usage_min 0.0314 (0.1358) teacher/usage_std 0.2456 (0.2174) nleep/row_max_mean 1483.6055 (1491.7933) nleep/row_max_std 68.5169 (58.2861) nleep/row_min_mean 1458.4768 (1462.2130) lr 1.9511e-03 eta 0:12:59
epoch [7/50] batch [100/176] time 0.087 (0.099) data 0.000 (0.003) loss 1.3580 (1.5026) teacher_loss 0.0686 (0.1403) loss_zs_kd 0.0530 (0.0567) loss_oracle 0.4514 (0.5652) kd_loss 1.0372 (1.0513) acc 96.8750 (96.1875) gate/entropy 1.0892 (1.0891) gate/usage_max 0.3791 (0.3835) gate/usage_min 0.2719 (0.2732) gate/usage_std 0.0451 (0.0457) teacher/entropy 0.0428 (0.0538) teacher/usage_max 0.7789 (0.6373) teacher/usage_min 0.0827 (0.1290) teacher/usage_std 0.3159 (0.2221) nleep/row_max_mean 1506.6426 (1492.7280) nleep/row_max_std 54.6784 (57.5278) nleep/row_min_mean 1477.7878 (1463.4608) lr 1.9511e-03 eta 0:12:38
epoch [7/50] batch [120/176] time 0.095 (0.099) data 0.000 (0.003) loss 1.7498 (1.5007) teacher_loss 0.5000 (0.1446) loss_zs_kd 0.0511 (0.0559) loss_oracle 0.5418 (0.5601) kd_loss 0.9533 (1.0481) acc 87.5000 (95.9896) gate/entropy 1.0895 (1.0891) gate/usage_max 0.3764 (0.3825) gate/usage_min 0.2723 (0.2730) gate/usage_std 0.0443 (0.0455) teacher/entropy 0.1560 (0.0578) teacher/usage_max 0.6417 (0.6390) teacher/usage_min 0.0848 (0.1218) teacher/usage_std 0.2312 (0.2251) nleep/row_max_mean 1491.2544 (1492.9541) nleep/row_max_std 58.2495 (56.9781) nleep/row_min_mean 1466.5748 (1463.8937) lr 1.9511e-03 eta 0:12:36
epoch [7/50] batch [140/176] time 0.114 (0.100) data 0.001 (0.003) loss 1.4538 (1.5014) teacher_loss 0.1401 (0.1497) loss_zs_kd 0.0463 (0.0559) loss_oracle 0.5006 (0.5525) kd_loss 1.0403 (1.0475) acc 93.7500 (95.8259) gate/entropy 1.0897 (1.0892) gate/usage_max 0.3737 (0.3815) gate/usage_min 0.2726 (0.2729) gate/usage_std 0.0437 (0.0453) teacher/entropy 0.0459 (0.0590) teacher/usage_max 0.7430 (0.6395) teacher/usage_min 0.0617 (0.1154) teacher/usage_std 0.2948 (0.2272) nleep/row_max_mean 1503.1273 (1492.6499) nleep/row_max_std 57.1972 (56.9885) nleep/row_min_mean 1473.8418 (1463.8985) lr 1.9511e-03 eta 0:12:38
epoch [7/50] batch [160/176] time 0.102 (0.100) data 0.000 (0.002) loss 1.4015 (1.4988) teacher_loss 0.0326 (0.1486) loss_zs_kd 0.0549 (0.0557) loss_oracle 0.5514 (0.5491) kd_loss 1.0658 (1.0479) acc 100.0000 (95.8203) gate/entropy 1.0901 (1.0893) gate/usage_max 0.3708 (0.3803) gate/usage_min 0.2734 (0.2729) gate/usage_std 0.0429 (0.0450) teacher/entropy 0.0743 (0.0587) teacher/usage_max 0.5665 (0.6423) teacher/usage_min 0.0234 (0.1082) teacher/usage_std 0.2283 (0.2307) nleep/row_max_mean 1497.8030 (1492.3838) nleep/row_max_std 54.3201 (57.2749) nleep/row_min_mean 1471.1853 (1463.8460) lr 1.9511e-03 eta 0:12:40
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,111
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 90.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,647
* accuracy: 62.0%
* error: 38.0%
* macro_f1: 57.9%
******* Domain l best val acc:      89.4%, epoch: 6 *******
******* Domain l best val test acc: 69.2%, epoch: 6 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [8/50] batch [20/176] time 0.098 (0.112) data 0.000 (0.016) loss 1.3344 (1.5063) teacher_loss 0.0828 (0.1649) loss_zs_kd 0.0659 (0.0535) loss_oracle 0.5607 (0.5804) kd_loss 0.9383 (1.0244) acc 100.0000 (95.7812) gate/entropy 1.0903 (1.0902) gate/usage_max 0.3665 (0.3675) gate/usage_min 0.2735 (0.2736) gate/usage_std 0.0424 (0.0424) teacher/entropy 0.1632 (0.0754) teacher/usage_max 0.5386 (0.6503) teacher/usage_min 0.1605 (0.0657) teacher/usage_std 0.1560 (0.2450) nleep/row_max_mean 1489.5330 (1494.8336) nleep/row_max_std 57.8490 (54.5320) nleep/row_min_mean 1469.9751 (1469.7908) lr 1.9298e-03 eta 0:14:03
epoch [8/50] batch [40/176] time 0.095 (0.101) data 0.000 (0.008) loss 1.5811 (1.4959) teacher_loss 0.2243 (0.1555) loss_zs_kd 0.0496 (0.0539) loss_oracle 0.6014 (0.5766) kd_loss 1.0312 (1.0251) acc 93.7500 (95.9375) gate/entropy 1.0902 (1.0902) gate/usage_max 0.3644 (0.3665) gate/usage_min 0.2732 (0.2735) gate/usage_std 0.0425 (0.0424) teacher/entropy 0.0567 (0.0675) teacher/usage_max 0.6677 (0.6669) teacher/usage_min 0.0702 (0.0676) teacher/usage_std 0.2491 (0.2542) nleep/row_max_mean 1499.3784 (1493.7740) nleep/row_max_std 41.9569 (54.2687) nleep/row_min_mean 1470.9500 (1469.0520) lr 1.9298e-03 eta 0:12:42
epoch [8/50] batch [60/176] time 0.086 (0.097) data 0.001 (0.006) loss 1.7556 (1.4968) teacher_loss 0.4404 (0.1690) loss_zs_kd 0.0625 (0.0524) loss_oracle 0.5378 (0.5669) kd_loss 1.0150 (1.0181) acc 84.3750 (95.2604) gate/entropy 1.0900 (1.0902) gate/usage_max 0.3652 (0.3657) gate/usage_min 0.2725 (0.2732) gate/usage_std 0.0430 (0.0426) teacher/entropy 0.0468 (0.0666) teacher/usage_max 0.7477 (0.6891) teacher/usage_min 0.0664 (0.0665) teacher/usage_std 0.2971 (0.2665) nleep/row_max_mean 1481.7458 (1492.6499) nleep/row_max_std 53.9146 (55.4976) nleep/row_min_mean 1459.4084 (1468.2686) lr 1.9298e-03 eta 0:12:11
epoch [8/50] batch [80/176] time 0.089 (0.096) data 0.000 (0.004) loss 1.4356 (1.4944) teacher_loss 0.1538 (0.1779) loss_zs_kd 0.0523 (0.0518) loss_oracle 0.5052 (0.5589) kd_loss 1.0031 (1.0111) acc 93.7500 (94.8438) gate/entropy 1.0898 (1.0901) gate/usage_max 0.3680 (0.3660) gate/usage_min 0.2719 (0.2730) gate/usage_std 0.0435 (0.0427) teacher/entropy 0.0809 (0.0706) teacher/usage_max 0.6783 (0.6847) teacher/usage_min 0.0457 (0.0735) teacher/usage_std 0.2614 (0.2619) nleep/row_max_mean 1485.0353 (1492.7388) nleep/row_max_std 57.8204 (55.2550) nleep/row_min_mean 1464.0344 (1468.7930) lr 1.9298e-03 eta 0:11:58
epoch [8/50] batch [100/176] time 0.077 (0.095) data 0.001 (0.003) loss 1.4007 (1.4756) teacher_loss 0.1590 (0.1744) loss_zs_kd 0.0661 (0.0511) loss_oracle 0.3936 (0.5469) kd_loss 1.0119 (1.0022) acc 96.8750 (95.0625) gate/entropy 1.0894 (1.0900) gate/usage_max 0.3707 (0.3667) gate/usage_min 0.2710 (0.2727) gate/usage_std 0.0444 (0.0430) teacher/entropy 0.0223 (0.0721) teacher/usage_max 0.7755 (0.6932) teacher/usage_min 0.0990 (0.0803) teacher/usage_std 0.3129 (0.2656) nleep/row_max_mean 1497.6128 (1493.0468) nleep/row_max_std 57.9839 (55.8255) nleep/row_min_mean 1473.1750 (1469.4105) lr 1.9298e-03 eta 0:11:46
epoch [8/50] batch [120/176] time 0.097 (0.093) data 0.000 (0.003) loss 1.3936 (1.4718) teacher_loss 0.1556 (0.1766) loss_zs_kd 0.0643 (0.0500) loss_oracle 0.5736 (0.5445) kd_loss 0.9191 (0.9979) acc 96.8750 (95.0521) gate/entropy 1.0893 (1.0899) gate/usage_max 0.3730 (0.3676) gate/usage_min 0.2706 (0.2724) gate/usage_std 0.0449 (0.0433) teacher/entropy 0.1453 (0.0742) teacher/usage_max 0.6334 (0.6867) teacher/usage_min 0.1428 (0.0870) teacher/usage_std 0.2148 (0.2601) nleep/row_max_mean 1493.3295 (1493.0391) nleep/row_max_std 60.0834 (55.3910) nleep/row_min_mean 1470.4128 (1469.6510) lr 1.9298e-03 eta 0:11:33
epoch [8/50] batch [140/176] time 0.079 (0.093) data 0.000 (0.003) loss 1.4200 (1.4708) teacher_loss 0.1555 (0.1768) loss_zs_kd 0.0379 (0.0501) loss_oracle 0.5945 (0.5447) kd_loss 0.9482 (0.9965) acc 96.8750 (94.9554) gate/entropy 1.0891 (1.0898) gate/usage_max 0.3751 (0.3685) gate/usage_min 0.2706 (0.2721) gate/usage_std 0.0452 (0.0435) teacher/entropy 0.1247 (0.0738) teacher/usage_max 0.6195 (0.6824) teacher/usage_min 0.1160 (0.0908) teacher/usage_std 0.2112 (0.2566) nleep/row_max_mean 1480.7563 (1493.3721) nleep/row_max_std 65.0823 (55.2530) nleep/row_min_mean 1461.6019 (1470.1064) lr 1.9298e-03 eta 0:11:29
epoch [8/50] batch [160/176] time 0.166 (0.094) data 0.001 (0.002) loss 1.5373 (1.4703) teacher_loss 0.2867 (0.1802) loss_zs_kd 0.0688 (0.0500) loss_oracle 0.4826 (0.5459) kd_loss 0.9748 (0.9922) acc 90.6250 (94.7852) gate/entropy 1.0887 (1.0897) gate/usage_max 0.3776 (0.3695) gate/usage_min 0.2697 (0.2719) gate/usage_std 0.0462 (0.0438) teacher/entropy 0.0711 (0.0752) teacher/usage_max 0.7235 (0.6831) teacher/usage_min 0.0788 (0.0936) teacher/usage_std 0.2801 (0.2563) nleep/row_max_mean 1492.8241 (1492.8709) nleep/row_max_std 52.4178 (55.8020) nleep/row_min_mean 1470.9799 (1469.7264) lr 1.9298e-03 eta 0:11:33
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,135
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 90.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,621
* accuracy: 61.0%
* error: 39.0%
* macro_f1: 57.6%
******* Domain l best val acc:      89.4%, epoch: 6 *******
******* Domain l best val test acc: 69.2%, epoch: 6 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [9/50] batch [20/176] time 0.089 (0.102) data 0.000 (0.013) loss 1.3472 (1.4236) teacher_loss 0.0755 (0.1909) loss_zs_kd 0.0378 (0.0515) loss_oracle 0.5576 (0.5763) kd_loss 0.9739 (0.9188) acc 100.0000 (94.3750) gate/entropy 1.0880 (1.0882) gate/usage_max 0.3811 (0.3803) gate/usage_min 0.2680 (0.2685) gate/usage_std 0.0478 (0.0474) teacher/entropy 0.0627 (0.1195) teacher/usage_max 0.6302 (0.6421) teacher/usage_min 0.1553 (0.1371) teacher/usage_std 0.2113 (0.2232) nleep/row_max_mean 1501.1354 (1488.8438) nleep/row_max_std 54.8905 (57.2088) nleep/row_min_mean 1476.7581 (1467.3473) lr 1.9048e-03 eta 0:12:35
epoch [9/50] batch [40/176] time 0.106 (0.096) data 0.000 (0.007) loss 1.2636 (1.4004) teacher_loss 0.1217 (0.1691) loss_zs_kd 0.0300 (0.0489) loss_oracle 0.5260 (0.5867) kd_loss 0.8639 (0.9135) acc 93.7500 (95.0781) gate/entropy 1.0877 (1.0880) gate/usage_max 0.3825 (0.3811) gate/usage_min 0.2672 (0.2680) gate/usage_std 0.0486 (0.0478) teacher/entropy 0.1302 (0.1234) teacher/usage_max 0.8060 (0.6382) teacher/usage_min 0.0608 (0.1378) teacher/usage_std 0.3355 (0.2204) nleep/row_max_mean 1500.4983 (1491.3722) nleep/row_max_std 47.0371 (57.0973) nleep/row_min_mean 1477.1597 (1469.4797) lr 1.9048e-03 eta 0:11:47
epoch [9/50] batch [60/176] time 0.093 (0.093) data 0.001 (0.005) loss 1.4481 (1.4093) teacher_loss 0.2607 (0.1756) loss_zs_kd 0.0699 (0.0493) loss_oracle 0.4876 (0.5853) kd_loss 0.9087 (0.9164) acc 90.6250 (94.8958) gate/entropy 1.0873 (1.0878) gate/usage_max 0.3835 (0.3818) gate/usage_min 0.2663 (0.2676) gate/usage_std 0.0493 (0.0482) teacher/entropy 0.1110 (0.1209) teacher/usage_max 0.6947 (0.6273) teacher/usage_min 0.1233 (0.1439) teacher/usage_std 0.2567 (0.2129) nleep/row_max_mean 1486.0048 (1491.8661) nleep/row_max_std 52.6757 (56.8708) nleep/row_min_mean 1463.7395 (1470.0182) lr 1.9048e-03 eta 0:11:24
epoch [9/50] batch [80/176] time 0.102 (0.092) data 0.000 (0.004) loss 1.4101 (1.4130) teacher_loss 0.2215 (0.1839) loss_zs_kd 0.0261 (0.0473) loss_oracle 0.6286 (0.5777) kd_loss 0.8613 (0.9166) acc 93.7500 (94.4922) gate/entropy 1.0869 (1.0877) gate/usage_max 0.3851 (0.3824) gate/usage_min 0.2652 (0.2671) gate/usage_std 0.0503 (0.0486) teacher/entropy 0.1817 (0.1195) teacher/usage_max 0.5766 (0.6254) teacher/usage_min 0.1755 (0.1438) teacher/usage_std 0.1745 (0.2121) nleep/row_max_mean 1478.4082 (1490.1279) nleep/row_max_std 69.5060 (57.9555) nleep/row_min_mean 1460.8667 (1468.6239) lr 1.9048e-03 eta 0:11:13
epoch [9/50] batch [100/176] time 0.093 (0.094) data 0.000 (0.003) loss 1.3502 (1.4046) teacher_loss 0.0888 (0.1843) loss_zs_kd 0.0462 (0.0465) loss_oracle 0.5986 (0.5698) kd_loss 0.9390 (0.9122) acc 96.8750 (94.5312) gate/entropy 1.0866 (1.0875) gate/usage_max 0.3862 (0.3830) gate/usage_min 0.2646 (0.2667) gate/usage_std 0.0509 (0.0490) teacher/entropy 0.0636 (0.1234) teacher/usage_max 0.7437 (0.6224) teacher/usage_min 0.0938 (0.1446) teacher/usage_std 0.2915 (0.2107) nleep/row_max_mean 1487.3533 (1489.3108) nleep/row_max_std 61.1258 (57.4273) nleep/row_min_mean 1464.3191 (1468.0642) lr 1.9048e-03 eta 0:11:24
epoch [9/50] batch [120/176] time 0.089 (0.094) data 0.000 (0.002) loss 1.5496 (1.4045) teacher_loss 0.3332 (0.1858) loss_zs_kd 0.0544 (0.0461) loss_oracle 0.5662 (0.5675) kd_loss 0.9060 (0.9119) acc 87.5000 (94.4271) gate/entropy 1.0863 (1.0873) gate/usage_max 0.3875 (0.3837) gate/usage_min 0.2638 (0.2663) gate/usage_std 0.0517 (0.0494) teacher/entropy 0.1246 (0.1218) teacher/usage_max 0.6308 (0.6259) teacher/usage_min 0.1586 (0.1409) teacher/usage_std 0.2114 (0.2134) nleep/row_max_mean 1502.4065 (1489.4867) nleep/row_max_std 43.7000 (56.6093) nleep/row_min_mean 1480.3494 (1468.3884) lr 1.9048e-03 eta 0:11:23
epoch [9/50] batch [140/176] time 0.096 (0.094) data 0.000 (0.002) loss 1.2766 (1.3975) teacher_loss 0.0380 (0.1818) loss_zs_kd 0.0398 (0.0449) loss_oracle 0.5807 (0.5671) kd_loss 0.9283 (0.9097) acc 100.0000 (94.4866) gate/entropy 1.0859 (1.0871) gate/usage_max 0.3886 (0.3843) gate/usage_min 0.2628 (0.2659) gate/usage_std 0.0525 (0.0498) teacher/entropy 0.1307 (0.1228) teacher/usage_max 0.5641 (0.6205) teacher/usage_min 0.1955 (0.1386) teacher/usage_std 0.1642 (0.2110) nleep/row_max_mean 1496.9211 (1488.9471) nleep/row_max_std 54.3329 (56.6476) nleep/row_min_mean 1477.0287 (1468.0714) lr 1.9048e-03 eta 0:11:22
epoch [9/50] batch [160/176] time 0.094 (0.094) data 0.001 (0.002) loss 1.3070 (1.3967) teacher_loss 0.0310 (0.1812) loss_zs_kd 0.0504 (0.0450) loss_oracle 0.6276 (0.5646) kd_loss 0.9370 (0.9107) acc 100.0000 (94.4336) gate/entropy 1.0857 (1.0870) gate/usage_max 0.3893 (0.3849) gate/usage_min 0.2623 (0.2654) gate/usage_std 0.0529 (0.0501) teacher/entropy 0.1337 (0.1217) teacher/usage_max 0.5128 (0.6174) teacher/usage_min 0.2250 (0.1388) teacher/usage_std 0.1278 (0.2091) nleep/row_max_mean 1501.8986 (1489.2055) nleep/row_max_std 56.3106 (56.2091) nleep/row_min_mean 1481.0193 (1468.4897) lr 1.9048e-03 eta 0:11:22
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,152
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 91.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,630
* accuracy: 61.4%
* error: 38.6%
* macro_f1: 58.4%
******* Domain l best val acc:      89.4%, epoch: 6 *******
******* Domain l best val test acc: 69.2%, epoch: 6 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [10/50] batch [20/176] time 0.091 (0.108) data 0.000 (0.013) loss 1.6310 (1.4079) teacher_loss 0.4043 (0.2177) loss_zs_kd 0.0310 (0.0434) loss_oracle 0.6044 (0.5289) kd_loss 0.9089 (0.9041) acc 84.3750 (92.0312) gate/entropy 1.0850 (1.0852) gate/usage_max 0.3911 (0.3907) gate/usage_min 0.2609 (0.2613) gate/usage_std 0.0542 (0.0538) teacher/entropy 0.1290 (0.1205) teacher/usage_max 0.5350 (0.5612) teacher/usage_min 0.1558 (0.1154) teacher/usage_std 0.1557 (0.1889) nleep/row_max_mean 1483.8234 (1487.5168) nleep/row_max_std 58.3172 (56.6327) nleep/row_min_mean 1466.4635 (1468.6688) lr 1.8763e-03 eta 0:12:59
epoch [10/50] batch [40/176] time 0.101 (0.100) data 0.000 (0.007) loss 1.2364 (1.4089) teacher_loss 0.1169 (0.2246) loss_zs_kd 0.0266 (0.0407) loss_oracle 0.4634 (0.5264) kd_loss 0.8745 (0.9007) acc 96.8750 (92.7344) gate/entropy 1.0847 (1.0850) gate/usage_max 0.3919 (0.3911) gate/usage_min 0.2601 (0.2609) gate/usage_std 0.0548 (0.0541) teacher/entropy 0.1514 (0.1264) teacher/usage_max 0.5016 (0.5584) teacher/usage_min 0.1042 (0.1237) teacher/usage_std 0.1679 (0.1836) nleep/row_max_mean 1493.6244 (1488.4782) nleep/row_max_std 51.8818 (53.2709) nleep/row_min_mean 1476.1034 (1469.8988) lr 1.8763e-03 eta 0:11:57
epoch [10/50] batch [60/176] time 0.185 (0.104) data 0.003 (0.005) loss 1.3964 (1.4070) teacher_loss 0.2133 (0.2093) loss_zs_kd 0.0278 (0.0423) loss_oracle 0.5163 (0.5373) kd_loss 0.9110 (0.9078) acc 93.7500 (93.1771) gate/entropy 1.0845 (1.0849) gate/usage_max 0.3920 (0.3914) gate/usage_min 0.2594 (0.2605) gate/usage_std 0.0552 (0.0544) teacher/entropy 0.1079 (0.1240) teacher/usage_max 0.6223 (0.5484) teacher/usage_min 0.1313 (0.1367) teacher/usage_std 0.2097 (0.1746) nleep/row_max_mean 1501.3802 (1490.2702) nleep/row_max_std 48.4611 (51.5874) nleep/row_min_mean 1482.4646 (1471.7306) lr 1.8763e-03 eta 0:12:21
epoch [10/50] batch [80/176] time 0.097 (0.101) data 0.000 (0.004) loss 1.7129 (1.4139) teacher_loss 0.3900 (0.2062) loss_zs_kd 0.0392 (0.0428) loss_oracle 0.6509 (0.5485) kd_loss 0.9779 (0.9120) acc 87.5000 (93.3984) gate/entropy 1.0843 (1.0848) gate/usage_max 0.3922 (0.3915) gate/usage_min 0.2589 (0.2602) gate/usage_std 0.0555 (0.0547) teacher/entropy 0.0949 (0.1236) teacher/usage_max 0.3914 (0.5434) teacher/usage_min 0.2236 (0.1480) teacher/usage_std 0.0776 (0.1687) nleep/row_max_mean 1481.4325 (1491.2682) nleep/row_max_std 61.8047 (50.9933) nleep/row_min_mean 1465.3533 (1472.8594) lr 1.8763e-03 eta 0:12:04
epoch [10/50] batch [100/176] time 0.097 (0.100) data 0.000 (0.003) loss 1.2442 (1.4112) teacher_loss 0.0826 (0.1997) loss_zs_kd 0.0322 (0.0435) loss_oracle 0.6282 (0.5585) kd_loss 0.8314 (0.9105) acc 100.0000 (93.5938) gate/entropy 1.0841 (1.0847) gate/usage_max 0.3925 (0.3917) gate/usage_min 0.2582 (0.2599) gate/usage_std 0.0560 (0.0549) teacher/entropy 0.1692 (0.1246) teacher/usage_max 0.6435 (0.5500) teacher/usage_min 0.0800 (0.1499) teacher/usage_std 0.2335 (0.1712) nleep/row_max_mean 1503.6217 (1491.7231) nleep/row_max_std 45.3349 (51.0567) nleep/row_min_mean 1485.3096 (1473.3779) lr 1.8763e-03 eta 0:11:54
epoch [10/50] batch [120/176] time 0.091 (0.100) data 0.000 (0.002) loss 1.4895 (1.4143) teacher_loss 0.2731 (0.1981) loss_zs_kd 0.0201 (0.0430) loss_oracle 0.5559 (0.5645) kd_loss 0.9284 (0.9124) acc 87.5000 (93.5417) gate/entropy 1.0839 (1.0845) gate/usage_max 0.3931 (0.3919) gate/usage_min 0.2577 (0.2595) gate/usage_std 0.0564 (0.0551) teacher/entropy 0.0971 (0.1235) teacher/usage_max 0.5103 (0.5501) teacher/usage_min 0.1131 (0.1535) teacher/usage_std 0.1650 (0.1699) nleep/row_max_mean 1475.7844 (1491.1771) nleep/row_max_std 69.4697 (51.8682) nleep/row_min_mean 1460.6049 (1472.9199) lr 1.8763e-03 eta 0:11:46
epoch [10/50] batch [140/176] time 0.093 (0.099) data 0.000 (0.002) loss 1.5907 (1.4228) teacher_loss 0.3717 (0.2021) loss_zs_kd 0.0441 (0.0430) loss_oracle 0.5813 (0.5680) kd_loss 0.9062 (0.9152) acc 84.3750 (93.3705) gate/entropy 1.0836 (1.0844) gate/usage_max 0.3936 (0.3921) gate/usage_min 0.2570 (0.2592) gate/usage_std 0.0569 (0.0553) teacher/entropy 0.1255 (0.1202) teacher/usage_max 0.5903 (0.5549) teacher/usage_min 0.1677 (0.1538) teacher/usage_std 0.1842 (0.1723) nleep/row_max_mean 1487.4375 (1490.9094) nleep/row_max_std 58.0638 (52.3345) nleep/row_min_mean 1471.2870 (1472.5726) lr 1.8763e-03 eta 0:11:38
epoch [10/50] batch [160/176] time 0.095 (0.099) data 0.000 (0.002) loss 1.6436 (1.4337) teacher_loss 0.3934 (0.2062) loss_zs_kd 0.0383 (0.0433) loss_oracle 0.5545 (0.5728) kd_loss 0.9537 (0.9195) acc 90.6250 (93.1836) gate/entropy 1.0836 (1.0843) gate/usage_max 0.3942 (0.3923) gate/usage_min 0.2574 (0.2590) gate/usage_std 0.0569 (0.0555) teacher/entropy 0.0819 (0.1170) teacher/usage_max 0.6563 (0.5613) teacher/usage_min 0.1347 (0.1523) teacher/usage_std 0.2304 (0.1761) nleep/row_max_mean 1504.7698 (1490.8616) nleep/row_max_std 48.8585 (52.3230) nleep/row_min_mean 1484.3391 (1472.4447) lr 1.8763e-03 eta 0:11:35
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,141
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 90.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,811
* accuracy: 68.2%
* error: 31.8%
* macro_f1: 62.9%
******* Domain l best val acc:      89.4%, epoch: 6 *******
******* Domain l best val test acc: 69.2%, epoch: 6 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [11/50] batch [20/176] time 0.103 (0.123) data 0.000 (0.013) loss 1.7355 (1.4421) teacher_loss 0.3765 (0.1924) loss_zs_kd 0.0537 (0.0426) loss_oracle 0.5917 (0.5773) kd_loss 1.0363 (0.9397) acc 87.5000 (93.5938) gate/entropy 1.0832 (1.0833) gate/usage_max 0.3972 (0.3964) gate/usage_min 0.2574 (0.2574) gate/usage_std 0.0577 (0.0575) teacher/entropy 0.0437 (0.1000) teacher/usage_max 0.5661 (0.6384) teacher/usage_min 0.1053 (0.1219) teacher/usage_std 0.1882 (0.2236) nleep/row_max_mean 1492.9656 (1492.3435) nleep/row_max_std 44.2377 (52.1415) nleep/row_min_mean 1471.2314 (1472.6409) lr 1.8443e-03 eta 0:14:22
epoch [11/50] batch [40/176] time 0.093 (0.112) data 0.000 (0.007) loss 1.5377 (1.4440) teacher_loss 0.2776 (0.1953) loss_zs_kd 0.0437 (0.0442) loss_oracle 0.5681 (0.5710) kd_loss 0.9541 (0.9411) acc 93.7500 (93.4375) gate/entropy 1.0828 (1.0832) gate/usage_max 0.3992 (0.3973) gate/usage_min 0.2571 (0.2573) gate/usage_std 0.0585 (0.0578) teacher/entropy 0.0669 (0.0882) teacher/usage_max 0.6271 (0.6562) teacher/usage_min 0.1644 (0.1250) teacher/usage_std 0.2085 (0.2338) nleep/row_max_mean 1490.3862 (1492.6675) nleep/row_max_std 48.7760 (51.1757) nleep/row_min_mean 1469.4812 (1472.6668) lr 1.8443e-03 eta 0:13:01
epoch [11/50] batch [60/176] time 0.105 (0.107) data 0.001 (0.005) loss 1.4547 (1.4420) teacher_loss 0.0998 (0.1859) loss_zs_kd 0.0438 (0.0415) loss_oracle 0.6207 (0.5762) kd_loss 1.0227 (0.9472) acc 100.0000 (93.9583) gate/entropy 1.0826 (1.0830) gate/usage_max 0.4006 (0.3982) gate/usage_min 0.2570 (0.2572) gate/usage_std 0.0590 (0.0581) teacher/entropy 0.0072 (0.0852) teacher/usage_max 0.6565 (0.6429) teacher/usage_min 0.1252 (0.1295) teacher/usage_std 0.2317 (0.2253) nleep/row_max_mean 1498.8936 (1491.2968) nleep/row_max_std 33.8144 (50.5220) nleep/row_min_mean 1477.0902 (1471.1883) lr 1.8443e-03 eta 0:12:24
epoch [11/50] batch [80/176] time 0.110 (0.106) data 0.000 (0.004) loss 1.5824 (1.4509) teacher_loss 0.3081 (0.1920) loss_zs_kd 0.0263 (0.0409) loss_oracle 0.6551 (0.5796) kd_loss 0.9336 (0.9487) acc 87.5000 (93.4766) gate/entropy 1.0823 (1.0829) gate/usage_max 0.4023 (0.3991) gate/usage_min 0.2569 (0.2571) gate/usage_std 0.0596 (0.0585) teacher/entropy 0.1422 (0.0831) teacher/usage_max 0.4793 (0.6455) teacher/usage_min 0.2395 (0.1272) teacher/usage_std 0.1046 (0.2269) nleep/row_max_mean 1481.2865 (1491.4693) nleep/row_max_std 60.6822 (50.1064) nleep/row_min_mean 1464.3550 (1471.2357) lr 1.8443e-03 eta 0:12:15
epoch [11/50] batch [100/176] time 0.093 (0.104) data 0.000 (0.003) loss 1.5427 (1.4429) teacher_loss 0.2073 (0.1888) loss_zs_kd 0.0314 (0.0406) loss_oracle 0.6633 (0.5776) kd_loss 0.9882 (0.9450) acc 90.6250 (93.5000) gate/entropy 1.0820 (1.0827) gate/usage_max 0.4038 (0.3999) gate/usage_min 0.2566 (0.2570) gate/usage_std 0.0602 (0.0588) teacher/entropy 0.0704 (0.0873) teacher/usage_max 0.5032 (0.6377) teacher/usage_min 0.2385 (0.1329) teacher/usage_std 0.1204 (0.2211) nleep/row_max_mean 1485.2405 (1490.7776) nleep/row_max_std 60.3329 (51.0039) nleep/row_min_mean 1468.3215 (1470.8622) lr 1.8443e-03 eta 0:12:02
epoch [11/50] batch [120/176] time 0.105 (0.104) data 0.000 (0.002) loss 1.7467 (1.4474) teacher_loss 0.4374 (0.1909) loss_zs_kd 0.0284 (0.0402) loss_oracle 0.6872 (0.5799) kd_loss 0.9515 (0.9464) acc 81.2500 (93.5417) gate/entropy 1.0820 (1.0826) gate/usage_max 0.4044 (0.4006) gate/usage_min 0.2570 (0.2570) gate/usage_std 0.0603 (0.0590) teacher/entropy 0.1375 (0.0892) teacher/usage_max 0.5095 (0.6292) teacher/usage_min 0.1364 (0.1346) teacher/usage_std 0.1530 (0.2162) nleep/row_max_mean 1489.7489 (1489.9702) nleep/row_max_std 49.8598 (51.0552) nleep/row_min_mean 1469.7700 (1470.2324) lr 1.8443e-03 eta 0:11:56
epoch [11/50] batch [140/176] time 0.097 (0.102) data 0.001 (0.002) loss 1.3195 (1.4509) teacher_loss 0.0977 (0.1894) loss_zs_kd 0.0272 (0.0392) loss_oracle 0.5550 (0.5849) kd_loss 0.9307 (0.9495) acc 100.0000 (93.6161) gate/entropy 1.0821 (1.0825) gate/usage_max 0.4053 (0.4012) gate/usage_min 0.2580 (0.2571) gate/usage_std 0.0601 (0.0592) teacher/entropy 0.1121 (0.0906) teacher/usage_max 0.6007 (0.6195) teacher/usage_min 0.1505 (0.1350) teacher/usage_std 0.1933 (0.2111) nleep/row_max_mean 1493.5634 (1489.4725) nleep/row_max_std 53.4255 (51.2501) nleep/row_min_mean 1473.5605 (1469.8746) lr 1.8443e-03 eta 0:11:46
epoch [11/50] batch [160/176] time 0.106 (0.102) data 0.000 (0.002) loss 1.6294 (1.4577) teacher_loss 0.3274 (0.1953) loss_zs_kd 0.0328 (0.0383) loss_oracle 0.5767 (0.5838) kd_loss 0.9972 (0.9513) acc 84.3750 (93.3594) gate/entropy 1.0823 (1.0825) gate/usage_max 0.4059 (0.4018) gate/usage_min 0.2591 (0.2572) gate/usage_std 0.0599 (0.0593) teacher/entropy 0.0638 (0.0908) teacher/usage_max 0.5734 (0.6163) teacher/usage_min 0.1225 (0.1313) teacher/usage_std 0.1852 (0.2104) nleep/row_max_mean 1480.0076 (1489.5515) nleep/row_max_std 56.7408 (51.3313) nleep/row_min_mean 1458.5835 (1470.0349) lr 1.8443e-03 eta 0:11:39
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,132
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 90.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,848
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 63.3%
******* Domain l best val acc:      89.4%, epoch: 6 *******
******* Domain l best val test acc: 69.2%, epoch: 6 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [12/50] batch [20/176] time 0.099 (0.113) data 0.000 (0.016) loss 1.6102 (1.5187) teacher_loss 0.3683 (0.2384) loss_zs_kd 0.0396 (0.0364) loss_oracle 0.5391 (0.5662) kd_loss 0.9526 (0.9790) acc 93.7500 (91.7188) gate/entropy 1.0820 (1.0821) gate/usage_max 0.4082 (0.4076) gate/usage_min 0.2597 (0.2597) gate/usage_std 0.0606 (0.0604) teacher/entropy 0.0954 (0.0716) teacher/usage_max 0.5561 (0.5967) teacher/usage_min 0.1970 (0.1148) teacher/usage_std 0.1589 (0.2043) nleep/row_max_mean 1458.1089 (1486.0247) nleep/row_max_std 63.3828 (52.1720) nleep/row_min_mean 1440.9749 (1466.7431) lr 1.8090e-03 eta 0:12:56
epoch [12/50] batch [40/176] time 0.109 (0.107) data 0.000 (0.008) loss 1.5067 (1.4790) teacher_loss 0.0886 (0.1994) loss_zs_kd 0.0345 (0.0352) loss_oracle 0.5919 (0.5658) kd_loss 1.1049 (0.9791) acc 96.8750 (93.2812) gate/entropy 1.0818 (1.0820) gate/usage_max 0.4095 (0.4082) gate/usage_min 0.2602 (0.2599) gate/usage_std 0.0610 (0.0606) teacher/entropy 0.0316 (0.0713) teacher/usage_max 0.5104 (0.6050) teacher/usage_min 0.0626 (0.1058) teacher/usage_std 0.1945 (0.2117) nleep/row_max_mean 1490.4025 (1487.6356) nleep/row_max_std 47.8730 (53.0644) nleep/row_min_mean 1469.1050 (1468.4340) lr 1.8090e-03 eta 0:12:13
epoch [12/50] batch [60/176] time 0.099 (0.104) data 0.001 (0.006) loss 1.4264 (1.4972) teacher_loss 0.1863 (0.2066) loss_zs_kd 0.0316 (0.0372) loss_oracle 0.6675 (0.5811) kd_loss 0.8905 (0.9814) acc 90.6250 (92.7604) gate/entropy 1.0817 (1.0819) gate/usage_max 0.4104 (0.4088) gate/usage_min 0.2604 (0.2600) gate/usage_std 0.0613 (0.0608) teacher/entropy 0.0758 (0.0699) teacher/usage_max 0.7588 (0.5986) teacher/usage_min 0.0981 (0.1060) teacher/usage_std 0.3014 (0.2093) nleep/row_max_mean 1490.5006 (1488.1718) nleep/row_max_std 59.5318 (53.5640) nleep/row_min_mean 1473.8916 (1469.1205) lr 1.8090e-03 eta 0:11:49
epoch [12/50] batch [80/176] time 0.100 (0.104) data 0.000 (0.004) loss 1.7051 (1.5019) teacher_loss 0.4035 (0.2050) loss_zs_kd 0.0316 (0.0386) loss_oracle 0.5902 (0.5939) kd_loss 0.9908 (0.9807) acc 87.5000 (92.7344) gate/entropy 1.0817 (1.0818) gate/usage_max 0.4108 (0.4093) gate/usage_min 0.2611 (0.2602) gate/usage_std 0.0612 (0.0609) teacher/entropy 0.0701 (0.0701) teacher/usage_max 0.5503 (0.5934) teacher/usage_min 0.1383 (0.1141) teacher/usage_std 0.1689 (0.2038) nleep/row_max_mean 1480.9221 (1488.0570) nleep/row_max_std 49.4612 (53.3265) nleep/row_min_mean 1463.8066 (1469.0828) lr 1.8090e-03 eta 0:11:46
epoch [12/50] batch [100/176] time 0.094 (0.103) data 0.000 (0.003) loss 1.6754 (1.5101) teacher_loss 0.3838 (0.2173) loss_zs_kd 0.0385 (0.0387) loss_oracle 0.6054 (0.5983) kd_loss 0.9696 (0.9743) acc 84.3750 (92.3438) gate/entropy 1.0814 (1.0818) gate/usage_max 0.4117 (0.4097) gate/usage_min 0.2605 (0.2603) gate/usage_std 0.0619 (0.0611) teacher/entropy 0.0931 (0.0730) teacher/usage_max 0.5453 (0.5944) teacher/usage_min 0.1406 (0.1190) teacher/usage_std 0.1658 (0.2025) nleep/row_max_mean 1474.8066 (1487.3248) nleep/row_max_std 72.1214 (54.2077) nleep/row_min_mean 1456.7919 (1468.2792) lr 1.8090e-03 eta 0:11:34
epoch [12/50] batch [120/176] time 0.096 (0.102) data 0.000 (0.003) loss 1.4169 (1.4995) teacher_loss 0.1076 (0.2114) loss_zs_kd 0.0366 (0.0379) loss_oracle 0.6773 (0.6012) kd_loss 0.9524 (0.9686) acc 96.8750 (92.6562) gate/entropy 1.0811 (1.0817) gate/usage_max 0.4125 (0.4102) gate/usage_min 0.2601 (0.2602) gate/usage_std 0.0624 (0.0613) teacher/entropy 0.1311 (0.0752) teacher/usage_max 0.4421 (0.5951) teacher/usage_min 0.2509 (0.1273) teacher/usage_std 0.0803 (0.2008) nleep/row_max_mean 1487.0841 (1487.0597) nleep/row_max_std 52.2475 (54.6183) nleep/row_min_mean 1467.3301 (1467.9233) lr 1.8090e-03 eta 0:11:25
epoch [12/50] batch [140/176] time 0.101 (0.101) data 0.000 (0.003) loss 1.6046 (1.5055) teacher_loss 0.2980 (0.2168) loss_zs_kd 0.0598 (0.0378) loss_oracle 0.5999 (0.6092) kd_loss 0.9768 (0.9652) acc 90.6250 (92.3438) gate/entropy 1.0807 (1.0815) gate/usage_max 0.4133 (0.4106) gate/usage_min 0.2592 (0.2601) gate/usage_std 0.0631 (0.0615) teacher/entropy 0.0840 (0.0775) teacher/usage_max 0.5735 (0.5927) teacher/usage_min 0.0889 (0.1330) teacher/usage_std 0.1979 (0.1978) nleep/row_max_mean 1484.6494 (1487.0868) nleep/row_max_std 54.9840 (54.5469) nleep/row_min_mean 1463.3201 (1467.7927) lr 1.8090e-03 eta 0:11:18
epoch [12/50] batch [160/176] time 0.095 (0.100) data 0.000 (0.002) loss 1.3625 (1.5037) teacher_loss 0.1753 (0.2151) loss_zs_kd 0.0510 (0.0383) loss_oracle 0.6020 (0.6177) kd_loss 0.8607 (0.9607) acc 93.7500 (92.3633) gate/entropy 1.0804 (1.0814) gate/usage_max 0.4136 (0.4110) gate/usage_min 0.2583 (0.2600) gate/usage_std 0.0635 (0.0617) teacher/entropy 0.1782 (0.0802) teacher/usage_max 0.5374 (0.5891) teacher/usage_min 0.2051 (0.1381) teacher/usage_std 0.1459 (0.1941) nleep/row_max_mean 1494.1086 (1487.1862) nleep/row_max_std 49.9197 (54.7668) nleep/row_min_mean 1472.8035 (1467.7115) lr 1.8090e-03 eta 0:11:11
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,170
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,656
* accuracy: 62.3%
* error: 37.7%
* macro_f1: 58.7%
******* Domain l best val acc:      89.6%, epoch: 12 *******
******* Domain l best val test acc: 62.3%, epoch: 12 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [13/50] batch [20/176] time 0.087 (0.110) data 0.000 (0.019) loss 1.5407 (1.4859) teacher_loss 0.2799 (0.1948) loss_zs_kd 0.0344 (0.0376) loss_oracle 0.6693 (0.6733) kd_loss 0.9089 (0.9357) acc 87.5000 (92.1875) gate/entropy 1.0801 (1.0802) gate/usage_max 0.4133 (0.4134) gate/usage_min 0.2568 (0.2571) gate/usage_std 0.0639 (0.0639) teacher/entropy 0.1386 (0.0944) teacher/usage_max 0.5019 (0.5450) teacher/usage_min 0.2104 (0.1674) teacher/usage_std 0.1233 (0.1618) nleep/row_max_mean 1485.9514 (1489.3337) nleep/row_max_std 44.2343 (53.6662) nleep/row_min_mean 1465.6414 (1468.0249) lr 1.7705e-03 eta 0:12:15
epoch [13/50] batch [40/176] time 0.158 (0.103) data 0.001 (0.010) loss 1.5431 (1.4985) teacher_loss 0.2464 (0.2043) loss_zs_kd 0.0443 (0.0366) loss_oracle 0.6417 (0.6757) kd_loss 0.9537 (0.9380) acc 90.6250 (91.7188) gate/entropy 1.0797 (1.0801) gate/usage_max 0.4137 (0.4134) gate/usage_min 0.2554 (0.2566) gate/usage_std 0.0646 (0.0640) teacher/entropy 0.0455 (0.0894) teacher/usage_max 0.6569 (0.5611) teacher/usage_min 0.1553 (0.1689) teacher/usage_std 0.2292 (0.1696) nleep/row_max_mean 1496.0388 (1488.5179) nleep/row_max_std 55.1203 (53.3664) nleep/row_min_mean 1474.9324 (1467.2317) lr 1.7705e-03 eta 0:11:25
epoch [13/50] batch [60/176] time 0.075 (0.100) data 0.001 (0.007) loss 1.4040 (1.5018) teacher_loss 0.1079 (0.2035) loss_zs_kd 0.0331 (0.0356) loss_oracle 0.6437 (0.6770) kd_loss 0.9577 (0.9420) acc 93.7500 (92.1875) gate/entropy 1.0796 (1.0800) gate/usage_max 0.4135 (0.4133) gate/usage_min 0.2549 (0.2562) gate/usage_std 0.0647 (0.0642) teacher/entropy 0.0402 (0.0888) teacher/usage_max 0.6300 (0.5552) teacher/usage_min 0.1282 (0.1701) teacher/usage_std 0.2148 (0.1663) nleep/row_max_mean 1503.7229 (1488.6391) nleep/row_max_std 46.0381 (53.0714) nleep/row_min_mean 1481.2377 (1467.5901) lr 1.7705e-03 eta 0:11:06
epoch [13/50] batch [80/176] time 0.096 (0.097) data 0.000 (0.005) loss 1.4375 (1.5121) teacher_loss 0.1314 (0.2121) loss_zs_kd 0.0338 (0.0346) loss_oracle 0.6352 (0.6822) kd_loss 0.9717 (0.9417) acc 96.8750 (92.0312) gate/entropy 1.0795 (1.0799) gate/usage_max 0.4130 (0.4133) gate/usage_min 0.2542 (0.2558) gate/usage_std 0.0648 (0.0643) teacher/entropy 0.1053 (0.0910) teacher/usage_max 0.4059 (0.5480) teacher/usage_min 0.2407 (0.1705) teacher/usage_std 0.0689 (0.1626) nleep/row_max_mean 1476.7539 (1486.9251) nleep/row_max_std 67.3626 (54.2614) nleep/row_min_mean 1457.7522 (1466.0393) lr 1.7705e-03 eta 0:10:37
epoch [13/50] batch [100/176] time 0.085 (0.094) data 0.000 (0.004) loss 1.4723 (1.5128) teacher_loss 0.2088 (0.2173) loss_zs_kd 0.0466 (0.0350) loss_oracle 0.7082 (0.6785) kd_loss 0.8861 (0.9387) acc 93.7500 (91.8750) gate/entropy 1.0794 (1.0798) gate/usage_max 0.4125 (0.4132) gate/usage_min 0.2535 (0.2554) gate/usage_std 0.0649 (0.0644) teacher/entropy 0.1294 (0.0932) teacher/usage_max 0.4864 (0.5457) teacher/usage_min 0.0802 (0.1689) teacher/usage_std 0.1803 (0.1618) nleep/row_max_mean 1474.9067 (1485.8430) nleep/row_max_std 57.8479 (54.9665) nleep/row_min_mean 1456.4518 (1465.0444) lr 1.7705e-03 eta 0:10:16
epoch [13/50] batch [120/176] time 0.095 (0.093) data 0.000 (0.003) loss 1.5191 (1.5085) teacher_loss 0.1979 (0.2152) loss_zs_kd 0.0286 (0.0348) loss_oracle 0.7189 (0.6798) kd_loss 0.9475 (0.9360) acc 90.6250 (92.0052) gate/entropy 1.0791 (1.0797) gate/usage_max 0.4125 (0.4131) gate/usage_min 0.2522 (0.2549) gate/usage_std 0.0655 (0.0646) teacher/entropy 0.1484 (0.0946) teacher/usage_max 0.4662 (0.5454) teacher/usage_min 0.1801 (0.1649) teacher/usage_std 0.1177 (0.1626) nleep/row_max_mean 1482.9774 (1485.9943) nleep/row_max_std 53.3728 (54.1979) nleep/row_min_mean 1463.1152 (1465.1406) lr 1.7705e-03 eta 0:10:08
epoch [13/50] batch [140/176] time 0.075 (0.092) data 0.000 (0.003) loss 1.4298 (1.5135) teacher_loss 0.1188 (0.2191) loss_zs_kd 0.0224 (0.0350) loss_oracle 0.6490 (0.6762) kd_loss 0.9754 (0.9388) acc 96.8750 (91.9643) gate/entropy 1.0790 (1.0796) gate/usage_max 0.4121 (0.4130) gate/usage_min 0.2516 (0.2545) gate/usage_std 0.0655 (0.0647) teacher/entropy 0.0589 (0.0920) teacher/usage_max 0.5567 (0.5448) teacher/usage_min 0.2069 (0.1658) teacher/usage_std 0.1584 (0.1620) nleep/row_max_mean 1479.6252 (1485.0379) nleep/row_max_std 51.8941 (54.3269) nleep/row_min_mean 1459.5035 (1464.2725) lr 1.7705e-03 eta 0:10:00
epoch [13/50] batch [160/176] time 0.096 (0.091) data 0.000 (0.003) loss 1.6727 (1.5145) teacher_loss 0.3722 (0.2217) loss_zs_kd 0.0576 (0.0364) loss_oracle 0.6401 (0.6718) kd_loss 0.9516 (0.9387) acc 84.3750 (91.8945) gate/entropy 1.0786 (1.0795) gate/usage_max 0.4125 (0.4129) gate/usage_min 0.2504 (0.2540) gate/usage_std 0.0662 (0.0649) teacher/entropy 0.0404 (0.0913) teacher/usage_max 0.6536 (0.5464) teacher/usage_min 0.1271 (0.1663) teacher/usage_std 0.2295 (0.1629) nleep/row_max_mean 1482.8074 (1484.7501) nleep/row_max_std 53.0298 (54.1320) nleep/row_min_mean 1456.9136 (1463.9695) lr 1.7705e-03 eta 0:09:55
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,171
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,673
* accuracy: 63.0%
* error: 37.0%
* macro_f1: 58.1%
******* Domain l best val acc:      89.6%, epoch: 13 *******
******* Domain l best val test acc: 63.0%, epoch: 13 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [14/50] batch [20/176] time 0.098 (0.104) data 0.000 (0.014) loss 1.6017 (1.5667) teacher_loss 0.3043 (0.2496) loss_zs_kd 0.0450 (0.0401) loss_oracle 0.7359 (0.6784) kd_loss 0.9069 (0.9578) acc 90.6250 (90.3125) gate/entropy 1.0781 (1.0782) gate/usage_max 0.4129 (0.4127) gate/usage_min 0.2490 (0.2494) gate/usage_std 0.0670 (0.0668) teacher/entropy 0.0946 (0.0764) teacher/usage_max 0.5872 (0.5486) teacher/usage_min 0.1145 (0.1842) teacher/usage_std 0.1946 (0.1592) nleep/row_max_mean 1477.4253 (1482.4326) nleep/row_max_std 59.3327 (53.4007) nleep/row_min_mean 1457.0618 (1461.1728) lr 1.7290e-03 eta 0:11:16
epoch [14/50] batch [40/176] time 0.095 (0.097) data 0.000 (0.007) loss 1.5199 (1.5123) teacher_loss 0.2316 (0.2241) loss_zs_kd 0.0354 (0.0353) loss_oracle 0.6283 (0.6420) kd_loss 0.9564 (0.9496) acc 90.6250 (91.6406) gate/entropy 1.0778 (1.0780) gate/usage_max 0.4132 (0.4129) gate/usage_min 0.2483 (0.2490) gate/usage_std 0.0674 (0.0670) teacher/entropy 0.0759 (0.0717) teacher/usage_max 0.5701 (0.5843) teacher/usage_min 0.2085 (0.1650) teacher/usage_std 0.1675 (0.1831) nleep/row_max_mean 1488.4999 (1484.6901) nleep/row_max_std 52.3260 (52.8786) nleep/row_min_mean 1465.9900 (1463.0705) lr 1.7290e-03 eta 0:10:29
epoch [14/50] batch [60/176] time 0.092 (0.096) data 0.001 (0.005) loss 1.4656 (1.5125) teacher_loss 0.2164 (0.2274) loss_zs_kd 0.0269 (0.0359) loss_oracle 0.5191 (0.6327) kd_loss 0.9762 (0.9507) acc 93.7500 (91.5104) gate/entropy 1.0773 (1.0778) gate/usage_max 0.4144 (0.4133) gate/usage_min 0.2475 (0.2485) gate/usage_std 0.0682 (0.0673) teacher/entropy 0.0241 (0.0680) teacher/usage_max 0.5995 (0.5922) teacher/usage_min 0.1250 (0.1581) teacher/usage_std 0.1980 (0.1891) nleep/row_max_mean 1478.5557 (1483.9064) nleep/row_max_std 60.0141 (53.0787) nleep/row_min_mean 1456.5392 (1462.0393) lr 1.7290e-03 eta 0:10:20
epoch [14/50] batch [80/176] time 0.093 (0.096) data 0.000 (0.004) loss 1.3274 (1.4950) teacher_loss 0.0857 (0.2165) loss_zs_kd 0.0401 (0.0357) loss_oracle 0.6327 (0.6316) kd_loss 0.9054 (0.9449) acc 100.0000 (92.1484) gate/entropy 1.0765 (1.0776) gate/usage_max 0.4158 (0.4138) gate/usage_min 0.2460 (0.2481) gate/usage_std 0.0694 (0.0677) teacher/entropy 0.1208 (0.0692) teacher/usage_max 0.6088 (0.6018) teacher/usage_min 0.1746 (0.1528) teacher/usage_std 0.1956 (0.1958) nleep/row_max_mean 1478.9260 (1483.9763) nleep/row_max_std 57.1048 (53.1599) nleep/row_min_mean 1455.3149 (1461.8599) lr 1.7290e-03 eta 0:10:17
epoch [14/50] batch [100/176] time 0.097 (0.096) data 0.000 (0.003) loss 1.4120 (1.4987) teacher_loss 0.1632 (0.2218) loss_zs_kd 0.0341 (0.0369) loss_oracle 0.6412 (0.6320) kd_loss 0.9111 (0.9425) acc 93.7500 (91.8438) gate/entropy 1.0760 (1.0773) gate/usage_max 0.4169 (0.4143) gate/usage_min 0.2451 (0.2476) gate/usage_std 0.0702 (0.0681) teacher/entropy 0.0497 (0.0692) teacher/usage_max 0.6889 (0.6103) teacher/usage_min 0.0683 (0.1479) teacher/usage_std 0.2613 (0.2019) nleep/row_max_mean 1501.4623 (1483.6629) nleep/row_max_std 49.1690 (53.2553) nleep/row_min_mean 1476.0381 (1461.5866) lr 1.7290e-03 eta 0:10:17
epoch [14/50] batch [120/176] time 0.095 (0.097) data 0.000 (0.003) loss 1.6188 (1.5027) teacher_loss 0.3353 (0.2222) loss_zs_kd 0.0413 (0.0369) loss_oracle 0.6701 (0.6407) kd_loss 0.9278 (0.9417) acc 84.3750 (91.9010) gate/entropy 1.0757 (1.0771) gate/usage_max 0.4175 (0.4148) gate/usage_min 0.2445 (0.2471) gate/usage_std 0.0707 (0.0685) teacher/entropy 0.0616 (0.0695) teacher/usage_max 0.7152 (0.6114) teacher/usage_min 0.1080 (0.1464) teacher/usage_std 0.2715 (0.2032) nleep/row_max_mean 1492.0872 (1482.8068) nleep/row_max_std 47.0328 (54.0830) nleep/row_min_mean 1466.3158 (1460.6709) lr 1.7290e-03 eta 0:10:19
epoch [14/50] batch [140/176] time 0.098 (0.098) data 0.000 (0.002) loss 1.7300 (1.5058) teacher_loss 0.4123 (0.2247) loss_zs_kd 0.0360 (0.0363) loss_oracle 0.7242 (0.6456) kd_loss 0.9375 (0.9401) acc 90.6250 (91.6295) gate/entropy 1.0754 (1.0769) gate/usage_max 0.4181 (0.4152) gate/usage_min 0.2440 (0.2467) gate/usage_std 0.0711 (0.0689) teacher/entropy 0.1268 (0.0704) teacher/usage_max 0.4594 (0.6143) teacher/usage_min 0.2386 (0.1465) teacher/usage_std 0.0928 (0.2050) nleep/row_max_mean 1451.9199 (1482.1537) nleep/row_max_std 58.1157 (54.0945) nleep/row_min_mean 1433.6853 (1459.9726) lr 1.7290e-03 eta 0:10:23
epoch [14/50] batch [160/176] time 0.103 (0.100) data 0.000 (0.002) loss 1.3549 (1.5017) teacher_loss 0.1189 (0.2219) loss_zs_kd 0.0418 (0.0366) loss_oracle 0.6587 (0.6476) kd_loss 0.8857 (0.9377) acc 93.7500 (91.8164) gate/entropy 1.0747 (1.0766) gate/usage_max 0.4196 (0.4157) gate/usage_min 0.2429 (0.2463) gate/usage_std 0.0722 (0.0692) teacher/entropy 0.0861 (0.0703) teacher/usage_max 0.7109 (0.6217) teacher/usage_min 0.1253 (0.1448) teacher/usage_std 0.2675 (0.2097) nleep/row_max_mean 1493.1328 (1482.0423) nleep/row_max_std 47.2266 (54.4640) nleep/row_min_mean 1469.0719 (1459.7258) lr 1.7290e-03 eta 0:10:36
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,175
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,602
* accuracy: 60.3%
* error: 39.7%
* macro_f1: 56.9%
******* Domain l best val acc:      89.8%, epoch: 14 *******
******* Domain l best val test acc: 60.3%, epoch: 14 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [15/50] batch [20/176] time 0.068 (0.102) data 0.000 (0.020) loss 1.4000 (1.4382) teacher_loss 0.1653 (0.1819) loss_zs_kd 0.0530 (0.0394) loss_oracle 0.6551 (0.6455) kd_loss 0.8807 (0.9138) acc 93.7500 (92.6562) gate/entropy 1.0739 (1.0741) gate/usage_max 0.4215 (0.4210) gate/usage_min 0.2417 (0.2420) gate/usage_std 0.0735 (0.0731) teacher/entropy 0.0896 (0.0780) teacher/usage_max 0.6970 (0.6614) teacher/usage_min 0.1200 (0.1253) teacher/usage_std 0.2585 (0.2367) nleep/row_max_mean 1497.8057 (1480.4275) nleep/row_max_std 39.2392 (53.4559) nleep/row_min_mean 1473.7634 (1457.9492) lr 1.6845e-03 eta 0:10:47
epoch [15/50] batch [40/176] time 0.102 (0.096) data 0.000 (0.010) loss 1.5855 (1.4476) teacher_loss 0.2395 (0.1921) loss_zs_kd 0.0401 (0.0433) loss_oracle 0.6781 (0.6407) kd_loss 0.9869 (0.9136) acc 90.6250 (92.8125) gate/entropy 1.0732 (1.0738) gate/usage_max 0.4230 (0.4217) gate/usage_min 0.2406 (0.2415) gate/usage_std 0.0745 (0.0736) teacher/entropy 0.0316 (0.0714) teacher/usage_max 0.6247 (0.6808) teacher/usage_min 0.1598 (0.1206) teacher/usage_std 0.2073 (0.2491) nleep/row_max_mean 1480.6099 (1482.2110) nleep/row_max_std 51.7012 (52.6082) nleep/row_min_mean 1456.7592 (1458.9316) lr 1.6845e-03 eta 0:10:04
epoch [15/50] batch [60/176] time 0.070 (0.095) data 0.001 (0.007) loss 1.6426 (1.4555) teacher_loss 0.3220 (0.1915) loss_zs_kd 0.0218 (0.0423) loss_oracle 0.7312 (0.6532) kd_loss 0.9440 (0.9162) acc 87.5000 (92.8125) gate/entropy 1.0727 (1.0735) gate/usage_max 0.4241 (0.4223) gate/usage_min 0.2400 (0.2411) gate/usage_std 0.0752 (0.0740) teacher/entropy 0.0451 (0.0691) teacher/usage_max 0.6910 (0.6795) teacher/usage_min 0.1275 (0.1234) teacher/usage_std 0.2539 (0.2479) nleep/row_max_mean 1484.3088 (1483.2246) nleep/row_max_std 53.0361 (52.3066) nleep/row_min_mean 1459.5432 (1459.7229) lr 1.6845e-03 eta 0:09:54
epoch [15/50] batch [80/176] time 0.106 (0.091) data 0.000 (0.005) loss 1.4767 (1.4562) teacher_loss 0.1689 (0.1901) loss_zs_kd 0.0446 (0.0414) loss_oracle 0.7178 (0.6551) kd_loss 0.9266 (0.9179) acc 93.7500 (92.9688) gate/entropy 1.0723 (1.0733) gate/usage_max 0.4254 (0.4229) gate/usage_min 0.2395 (0.2408) gate/usage_std 0.0759 (0.0744) teacher/entropy 0.0622 (0.0709) teacher/usage_max 0.6750 (0.6735) teacher/usage_min 0.1550 (0.1294) teacher/usage_std 0.2416 (0.2433) nleep/row_max_mean 1483.7960 (1482.2326) nleep/row_max_std 54.5082 (51.8251) nleep/row_min_mean 1460.2178 (1458.9180) lr 1.6845e-03 eta 0:09:29
epoch [15/50] batch [100/176] time 0.080 (0.088) data 0.000 (0.004) loss 1.4510 (1.4634) teacher_loss 0.1555 (0.1990) loss_zs_kd 0.0529 (0.0414) loss_oracle 0.7521 (0.6532) kd_loss 0.8930 (0.9171) acc 93.7500 (92.5938) gate/entropy 1.0717 (1.0730) gate/usage_max 0.4265 (0.4235) gate/usage_min 0.2387 (0.2405) gate/usage_std 0.0767 (0.0747) teacher/entropy 0.0881 (0.0702) teacher/usage_max 0.6503 (0.6720) teacher/usage_min 0.1318 (0.1270) teacher/usage_std 0.2269 (0.2428) nleep/row_max_mean 1470.8987 (1481.7800) nleep/row_max_std 62.4541 (52.0886) nleep/row_min_mean 1447.0769 (1458.4711) lr 1.6845e-03 eta 0:09:10
epoch [15/50] batch [120/176] time 0.096 (0.089) data 0.001 (0.003) loss 1.4243 (1.4621) teacher_loss 0.1600 (0.1990) loss_zs_kd 0.0647 (0.0413) loss_oracle 0.6308 (0.6500) kd_loss 0.9165 (0.9175) acc 90.6250 (92.4740) gate/entropy 1.0712 (1.0728) gate/usage_max 0.4276 (0.4241) gate/usage_min 0.2381 (0.2402) gate/usage_std 0.0774 (0.0751) teacher/entropy 0.1001 (0.0684) teacher/usage_max 0.6353 (0.6720) teacher/usage_min 0.1348 (0.1273) teacher/usage_std 0.2170 (0.2427) nleep/row_max_mean 1491.2932 (1482.5293) nleep/row_max_std 41.5828 (51.2503) nleep/row_min_mean 1469.0378 (1459.2162) lr 1.6845e-03 eta 0:09:10
epoch [15/50] batch [140/176] time 0.084 (0.088) data 0.000 (0.003) loss 1.4401 (1.4611) teacher_loss 0.0978 (0.1990) loss_zs_kd 0.0323 (0.0413) loss_oracle 0.6740 (0.6471) kd_loss 0.9892 (0.9180) acc 93.7500 (92.6116) gate/entropy 1.0710 (1.0725) gate/usage_max 0.4284 (0.4247) gate/usage_min 0.2379 (0.2398) gate/usage_std 0.0778 (0.0755) teacher/entropy 0.0458 (0.0685) teacher/usage_max 0.5893 (0.6713) teacher/usage_min 0.1558 (0.1285) teacher/usage_std 0.1855 (0.2421) nleep/row_max_mean 1469.3070 (1482.4209) nleep/row_max_std 56.7010 (51.0242) nleep/row_min_mean 1448.9629 (1459.1818) lr 1.6845e-03 eta 0:09:07
epoch [15/50] batch [160/176] time 0.076 (0.089) data 0.000 (0.003) loss 1.4054 (1.4687) teacher_loss 0.2187 (0.2074) loss_zs_kd 0.0252 (0.0406) loss_oracle 0.5459 (0.6433) kd_loss 0.9011 (0.9193) acc 87.5000 (92.2852) gate/entropy 1.0703 (1.0723) gate/usage_max 0.4301 (0.4252) gate/usage_min 0.2371 (0.2396) gate/usage_std 0.0788 (0.0758) teacher/entropy 0.0686 (0.0688) teacher/usage_max 0.7149 (0.6673) teacher/usage_min 0.1255 (0.1286) teacher/usage_std 0.2701 (0.2399) nleep/row_max_mean 1488.2531 (1482.1159) nleep/row_max_std 55.7357 (51.1464) nleep/row_min_mean 1463.0535 (1458.8927) lr 1.6845e-03 eta 0:09:08
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,167
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,577
* accuracy: 59.4%
* error: 40.6%
* macro_f1: 56.9%
******* Domain l best val acc:      89.8%, epoch: 14 *******
******* Domain l best val test acc: 60.3%, epoch: 14 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [16/50] batch [20/176] time 0.122 (0.131) data 0.001 (0.016) loss 1.3547 (1.4109) teacher_loss 0.0743 (0.1751) loss_zs_kd 0.0343 (0.0345) loss_oracle 0.6281 (0.6175) kd_loss 0.9492 (0.9098) acc 100.0000 (94.2188) gate/entropy 1.0696 (1.0698) gate/usage_max 0.4323 (0.4317) gate/usage_min 0.2367 (0.2369) gate/usage_std 0.0798 (0.0795) teacher/entropy 0.0317 (0.0740) teacher/usage_max 0.6910 (0.6782) teacher/usage_min 0.1275 (0.1301) teacher/usage_std 0.2539 (0.2460) nleep/row_max_mean 1496.3987 (1483.2382) nleep/row_max_std 46.0222 (51.9369) nleep/row_min_mean 1469.3469 (1459.3927) lr 1.6374e-03 eta 0:13:21
epoch [16/50] batch [40/176] time 0.106 (0.117) data 0.001 (0.008) loss 1.5152 (1.4243) teacher_loss 0.2692 (0.1895) loss_zs_kd 0.0404 (0.0348) loss_oracle 0.6545 (0.6187) kd_loss 0.8985 (0.9081) acc 90.6250 (93.3594) gate/entropy 1.0689 (1.0695) gate/usage_max 0.4341 (0.4323) gate/usage_min 0.2359 (0.2366) gate/usage_std 0.0809 (0.0799) teacher/entropy 0.0425 (0.0722) teacher/usage_max 0.7626 (0.6854) teacher/usage_min 0.1133 (0.1192) teacher/usage_std 0.3036 (0.2521) nleep/row_max_mean 1484.4546 (1481.8863) nleep/row_max_std 48.8450 (50.3795) nleep/row_min_mean 1456.7480 (1457.7411) lr 1.6374e-03 eta 0:11:57
epoch [16/50] batch [60/176] time 0.099 (0.117) data 0.001 (0.006) loss 1.2655 (1.4488) teacher_loss 0.0665 (0.2138) loss_zs_kd 0.0377 (0.0376) loss_oracle 0.5994 (0.6238) kd_loss 0.8805 (0.9044) acc 100.0000 (92.6042) gate/entropy 1.0682 (1.0693) gate/usage_max 0.4355 (0.4330) gate/usage_min 0.2353 (0.2364) gate/usage_std 0.0818 (0.0803) teacher/entropy 0.0789 (0.0720) teacher/usage_max 0.7274 (0.6910) teacher/usage_min 0.1175 (0.1190) teacher/usage_std 0.2791 (0.2556) nleep/row_max_mean 1477.9727 (1482.1414) nleep/row_max_std 59.5032 (50.0309) nleep/row_min_mean 1453.9397 (1458.0978) lr 1.6374e-03 eta 0:11:54
epoch [16/50] batch [80/176] time 0.121 (0.115) data 0.000 (0.004) loss 1.4622 (1.4526) teacher_loss 0.3112 (0.2256) loss_zs_kd 0.0339 (0.0376) loss_oracle 0.6234 (0.6183) kd_loss 0.8223 (0.8991) acc 90.6250 (91.9922) gate/entropy 1.0676 (1.0690) gate/usage_max 0.4371 (0.4338) gate/usage_min 0.2346 (0.2361) gate/usage_std 0.0827 (0.0807) teacher/entropy 0.1015 (0.0745) teacher/usage_max 0.7734 (0.6934) teacher/usage_min 0.0938 (0.1205) teacher/usage_std 0.3116 (0.2569) nleep/row_max_mean 1480.2766 (1481.3662) nleep/row_max_std 44.6765 (50.3217) nleep/row_min_mean 1456.7566 (1457.3322) lr 1.6374e-03 eta 0:11:41
epoch [16/50] batch [100/176] time 0.103 (0.113) data 0.000 (0.004) loss 1.5933 (1.4507) teacher_loss 0.2859 (0.2262) loss_zs_kd 0.0256 (0.0373) loss_oracle 0.7303 (0.6226) kd_loss 0.9295 (0.8946) acc 87.5000 (91.7500) gate/entropy 1.0672 (1.0687) gate/usage_max 0.4380 (0.4346) gate/usage_min 0.2344 (0.2358) gate/usage_std 0.0832 (0.0812) teacher/entropy 0.0851 (0.0754) teacher/usage_max 0.6116 (0.6972) teacher/usage_min 0.1563 (0.1191) teacher/usage_std 0.1992 (0.2595) nleep/row_max_mean 1485.8979 (1481.7877) nleep/row_max_std 37.1550 (50.0998) nleep/row_min_mean 1459.6760 (1457.6570) lr 1.6374e-03 eta 0:11:24
epoch [16/50] batch [120/176] time 0.104 (0.112) data 0.000 (0.003) loss 1.3754 (1.4440) teacher_loss 0.1077 (0.2210) loss_zs_kd 0.0414 (0.0375) loss_oracle 0.6783 (0.6278) kd_loss 0.9078 (0.8905) acc 96.8750 (91.9531) gate/entropy 1.0664 (1.0683) gate/usage_max 0.4397 (0.4353) gate/usage_min 0.2335 (0.2355) gate/usage_std 0.0843 (0.0816) teacher/entropy 0.0637 (0.0773) teacher/usage_max 0.7149 (0.6996) teacher/usage_min 0.0870 (0.1184) teacher/usage_std 0.2736 (0.2612) nleep/row_max_mean 1491.5731 (1481.6560) nleep/row_max_std 43.3583 (50.0866) nleep/row_min_mean 1469.6921 (1457.5524) lr 1.6374e-03 eta 0:11:14
epoch [16/50] batch [140/176] time 0.098 (0.110) data 0.000 (0.003) loss 1.5105 (1.4469) teacher_loss 0.3138 (0.2255) loss_zs_kd 0.0220 (0.0380) loss_oracle 0.6280 (0.6327) kd_loss 0.8717 (0.8861) acc 90.6250 (91.7857) gate/entropy 1.0660 (1.0680) gate/usage_max 0.4407 (0.4360) gate/usage_min 0.2332 (0.2352) gate/usage_std 0.0849 (0.0821) teacher/entropy 0.0546 (0.0797) teacher/usage_max 0.7490 (0.7010) teacher/usage_min 0.0948 (0.1188) teacher/usage_std 0.2950 (0.2620) nleep/row_max_mean 1466.6692 (1481.2175) nleep/row_max_std 57.1941 (50.1016) nleep/row_min_mean 1440.9285 (1457.2829) lr 1.6374e-03 eta 0:11:02
epoch [16/50] batch [160/176] time 0.096 (0.110) data 0.000 (0.002) loss 1.3155 (1.4433) teacher_loss 0.1652 (0.2261) loss_zs_kd 0.0298 (0.0378) loss_oracle 0.6522 (0.6312) kd_loss 0.8094 (0.8827) acc 96.8750 (91.8555) gate/entropy 1.0652 (1.0677) gate/usage_max 0.4423 (0.4367) gate/usage_min 0.2324 (0.2349) gate/usage_std 0.0859 (0.0825) teacher/entropy 0.0718 (0.0799) teacher/usage_max 0.8457 (0.7050) teacher/usage_min 0.0566 (0.1180) teacher/usage_std 0.3627 (0.2647) nleep/row_max_mean 1502.7302 (1481.3790) nleep/row_max_std 43.0671 (50.0160) nleep/row_min_mean 1473.1995 (1457.3739) lr 1.6374e-03 eta 0:10:59
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,175
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,590
* accuracy: 59.9%
* error: 40.1%
* macro_f1: 57.4%
******* Domain l best val acc:      89.8%, epoch: 14 *******
******* Domain l best val test acc: 60.3%, epoch: 14 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [17/50] batch [20/176] time 0.082 (0.107) data 0.000 (0.016) loss 1.2585 (1.4311) teacher_loss 0.0630 (0.2386) loss_zs_kd 0.0343 (0.0310) loss_oracle 0.6380 (0.6349) kd_loss 0.8593 (0.8595) acc 100.0000 (91.7188) gate/entropy 1.0640 (1.0643) gate/usage_max 0.4454 (0.4445) gate/usage_min 0.2314 (0.2317) gate/usage_std 0.0877 (0.0872) teacher/entropy 0.0661 (0.0654) teacher/usage_max 0.8037 (0.7692) teacher/usage_min 0.0333 (0.0855) teacher/usage_std 0.3368 (0.3099) nleep/row_max_mean 1494.9119 (1485.1196) nleep/row_max_std 37.9253 (50.3461) nleep/row_min_mean 1466.5486 (1459.5161) lr 1.5878e-03 eta 0:10:36
epoch [17/50] batch [40/176] time 0.094 (0.099) data 0.000 (0.008) loss 1.7701 (1.4398) teacher_loss 0.4915 (0.2449) loss_zs_kd 0.0468 (0.0344) loss_oracle 0.6837 (0.6233) kd_loss 0.9133 (0.8661) acc 84.3750 (91.4844) gate/entropy 1.0634 (1.0640) gate/usage_max 0.4469 (0.4454) gate/usage_min 0.2313 (0.2315) gate/usage_std 0.0884 (0.0876) teacher/entropy 0.0600 (0.0756) teacher/usage_max 0.6793 (0.7429) teacher/usage_min 0.1300 (0.0929) teacher/usage_std 0.2459 (0.2919) nleep/row_max_mean 1466.1328 (1482.2744) nleep/row_max_std 62.4192 (52.0413) nleep/row_min_mean 1443.8582 (1457.0470) lr 1.5878e-03 eta 0:09:51
epoch [17/50] batch [60/176] time 0.073 (0.094) data 0.001 (0.006) loss 1.2152 (1.4402) teacher_loss 0.1529 (0.2528) loss_zs_kd 0.0299 (0.0368) loss_oracle 0.6133 (0.6234) kd_loss 0.7407 (0.8573) acc 96.8750 (91.3542) gate/entropy 1.0626 (1.0636) gate/usage_max 0.4489 (0.4463) gate/usage_min 0.2307 (0.2313) gate/usage_std 0.0895 (0.0881) teacher/entropy 0.1493 (0.0797) teacher/usage_max 0.8283 (0.7484) teacher/usage_min 0.0772 (0.0893) teacher/usage_std 0.3500 (0.2959) nleep/row_max_mean 1471.1355 (1481.7916) nleep/row_max_std 58.2186 (52.5837) nleep/row_min_mean 1450.1560 (1456.3885) lr 1.5878e-03 eta 0:09:16
epoch [17/50] batch [80/176] time 0.097 (0.090) data 0.000 (0.004) loss 1.4071 (1.4305) teacher_loss 0.3036 (0.2532) loss_zs_kd 0.0285 (0.0363) loss_oracle 0.5172 (0.6133) kd_loss 0.8306 (0.8524) acc 87.5000 (91.2891) gate/entropy 1.0614 (1.0632) gate/usage_max 0.4514 (0.4472) gate/usage_min 0.2297 (0.2311) gate/usage_std 0.0911 (0.0886) teacher/entropy 0.0384 (0.0781) teacher/usage_max 0.8509 (0.7583) teacher/usage_min 0.0689 (0.0863) teacher/usage_std 0.3660 (0.3027) nleep/row_max_mean 1494.3636 (1482.0776) nleep/row_max_std 49.7904 (52.4825) nleep/row_min_mean 1466.2954 (1456.3249) lr 1.5878e-03 eta 0:08:51
epoch [17/50] batch [100/176] time 0.086 (0.090) data 0.000 (0.003) loss 1.3371 (1.4335) teacher_loss 0.1641 (0.2606) loss_zs_kd 0.0110 (0.0341) loss_oracle 0.6305 (0.6120) kd_loss 0.8522 (0.8498) acc 93.7500 (90.8438) gate/entropy 1.0607 (1.0628) gate/usage_max 0.4530 (0.4482) gate/usage_min 0.2294 (0.2308) gate/usage_std 0.0920 (0.0892) teacher/entropy 0.0736 (0.0776) teacher/usage_max 0.7858 (0.7627) teacher/usage_min 0.0373 (0.0849) teacher/usage_std 0.3250 (0.3057) nleep/row_max_mean 1468.3059 (1481.6763) nleep/row_max_std 63.3853 (53.1053) nleep/row_min_mean 1443.1373 (1455.7468) lr 1.5878e-03 eta 0:08:50
epoch [17/50] batch [120/176] time 0.087 (0.089) data 0.000 (0.003) loss 1.3682 (1.4315) teacher_loss 0.1693 (0.2602) loss_zs_kd 0.0268 (0.0339) loss_oracle 0.6016 (0.6106) kd_loss 0.8847 (0.8491) acc 93.7500 (90.8594) gate/entropy 1.0599 (1.0624) gate/usage_max 0.4550 (0.4492) gate/usage_min 0.2292 (0.2305) gate/usage_std 0.0930 (0.0898) teacher/entropy 0.0607 (0.0761) teacher/usage_max 0.7001 (0.7651) teacher/usage_min 0.1448 (0.0817) teacher/usage_std 0.2593 (0.3077) nleep/row_max_mean 1480.4634 (1482.1259) nleep/row_max_std 58.6401 (52.7785) nleep/row_min_mean 1456.0989 (1455.9929) lr 1.5878e-03 eta 0:08:39
epoch [17/50] batch [140/176] time 0.107 (0.089) data 0.000 (0.003) loss 1.3642 (1.4263) teacher_loss 0.1944 (0.2547) loss_zs_kd 0.0445 (0.0342) loss_oracle 0.6062 (0.6121) kd_loss 0.8444 (0.8485) acc 87.5000 (91.0045) gate/entropy 1.0590 (1.0620) gate/usage_max 0.4571 (0.4502) gate/usage_min 0.2287 (0.2303) gate/usage_std 0.0942 (0.0903) teacher/entropy 0.1043 (0.0753) teacher/usage_max 0.7470 (0.7666) teacher/usage_min 0.0265 (0.0795) teacher/usage_std 0.3037 (0.3089) nleep/row_max_mean 1473.2925 (1482.1950) nleep/row_max_std 54.5645 (52.6107) nleep/row_min_mean 1448.0811 (1456.0079) lr 1.5878e-03 eta 0:08:40
epoch [17/50] batch [160/176] time 0.155 (0.092) data 0.001 (0.002) loss 1.3331 (1.4291) teacher_loss 0.1486 (0.2587) loss_zs_kd 0.0265 (0.0338) loss_oracle 0.6876 (0.6133) kd_loss 0.8274 (0.8468) acc 93.7500 (90.9180) gate/entropy 1.0580 (1.0615) gate/usage_max 0.4594 (0.4512) gate/usage_min 0.2283 (0.2301) gate/usage_std 0.0955 (0.0909) teacher/entropy 0.0823 (0.0756) teacher/usage_max 0.7495 (0.7675) teacher/usage_min 0.1157 (0.0780) teacher/usage_std 0.2944 (0.3097) nleep/row_max_mean 1481.2800 (1481.9160) nleep/row_max_std 59.6496 (53.0311) nleep/row_min_mean 1456.2505 (1455.7021) lr 1.5878e-03 eta 0:08:56
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,181
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 91.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,569
* accuracy: 59.1%
* error: 40.9%
* macro_f1: 56.5%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [18/50] batch [20/176] time 0.090 (0.106) data 0.000 (0.012) loss 1.4369 (1.4652) teacher_loss 0.1936 (0.2446) loss_zs_kd 0.0403 (0.0359) loss_oracle 0.7032 (0.6745) kd_loss 0.8716 (0.8654) acc 93.7500 (90.9375) gate/entropy 1.0573 (1.0574) gate/usage_max 0.4615 (0.4611) gate/usage_min 0.2287 (0.2285) gate/usage_std 0.0965 (0.0963) teacher/entropy 0.0815 (0.0852) teacher/usage_max 0.7187 (0.7076) teacher/usage_min 0.0559 (0.0904) teacher/usage_std 0.2811 (0.2705) nleep/row_max_mean 1473.9822 (1478.4416) nleep/row_max_std 52.9268 (52.2408) nleep/row_min_mean 1448.0992 (1453.8800) lr 1.5358e-03 eta 0:10:12
epoch [18/50] batch [40/176] time 0.105 (0.104) data 0.000 (0.006) loss 1.6001 (1.4502) teacher_loss 0.2668 (0.2194) loss_zs_kd 0.0214 (0.0353) loss_oracle 0.7389 (0.6650) kd_loss 0.9532 (0.8807) acc 93.7500 (92.1875) gate/entropy 1.0568 (1.0572) gate/usage_max 0.4628 (0.4617) gate/usage_min 0.2288 (0.2286) gate/usage_std 0.0972 (0.0966) teacher/entropy 0.0647 (0.0820) teacher/usage_max 0.6076 (0.6914) teacher/usage_min 0.0947 (0.0846) teacher/usage_std 0.2109 (0.2631) nleep/row_max_mean 1472.5251 (1477.6861) nleep/row_max_std 58.3784 (52.7579) nleep/row_min_mean 1445.4673 (1452.9259) lr 1.5358e-03 eta 0:10:00
epoch [18/50] batch [60/176] time 0.102 (0.101) data 0.001 (0.004) loss 1.3358 (1.4530) teacher_loss 0.0968 (0.2095) loss_zs_kd 0.0301 (0.0368) loss_oracle 0.6222 (0.6607) kd_loss 0.9129 (0.8947) acc 96.8750 (92.3958) gate/entropy 1.0566 (1.0570) gate/usage_max 0.4637 (0.4623) gate/usage_min 0.2295 (0.2288) gate/usage_std 0.0975 (0.0969) teacher/entropy 0.0742 (0.0814) teacher/usage_max 0.6689 (0.6749) teacher/usage_min 0.0401 (0.0759) teacher/usage_std 0.2584 (0.2580) nleep/row_max_mean 1487.8687 (1479.0104) nleep/row_max_std 44.2195 (51.8073) nleep/row_min_mean 1461.8104 (1454.1921) lr 1.5358e-03 eta 0:09:41
epoch [18/50] batch [80/176] time 0.089 (0.099) data 0.000 (0.003) loss 1.3617 (1.4607) teacher_loss 0.1459 (0.2155) loss_zs_kd 0.0496 (0.0361) loss_oracle 0.6256 (0.6500) kd_loss 0.8782 (0.9021) acc 93.7500 (92.4609) gate/entropy 1.0563 (1.0569) gate/usage_max 0.4650 (0.4629) gate/usage_min 0.2300 (0.2290) gate/usage_std 0.0980 (0.0971) teacher/entropy 0.1032 (0.0768) teacher/usage_max 0.6548 (0.6716) teacher/usage_min 0.0910 (0.0707) teacher/usage_std 0.2369 (0.2571) nleep/row_max_mean 1476.7429 (1478.8770) nleep/row_max_std 60.4505 (52.3950) nleep/row_min_mean 1449.5098 (1453.7915) lr 1.5358e-03 eta 0:09:27
epoch [18/50] batch [100/176] time 0.102 (0.098) data 0.000 (0.003) loss 1.3858 (1.4458) teacher_loss 0.2541 (0.2109) loss_zs_kd 0.0316 (0.0347) loss_oracle 0.6757 (0.6365) kd_loss 0.7780 (0.8993) acc 87.5000 (92.5938) gate/entropy 1.0555 (1.0567) gate/usage_max 0.4668 (0.4635) gate/usage_min 0.2300 (0.2293) gate/usage_std 0.0990 (0.0974) teacher/entropy 0.1327 (0.0779) teacher/usage_max 0.7575 (0.6738) teacher/usage_min 0.0787 (0.0677) teacher/usage_std 0.3020 (0.2585) nleep/row_max_mean 1479.1619 (1479.3387) nleep/row_max_std 56.0208 (52.6830) nleep/row_min_mean 1455.6067 (1454.2036) lr 1.5358e-03 eta 0:09:19
epoch [18/50] batch [120/176] time 0.088 (0.098) data 0.000 (0.002) loss 1.6012 (1.4525) teacher_loss 0.2715 (0.2124) loss_zs_kd 0.0608 (0.0356) loss_oracle 0.6777 (0.6316) kd_loss 0.9605 (0.9065) acc 87.5000 (92.5000) gate/entropy 1.0554 (1.0565) gate/usage_max 0.4675 (0.4640) gate/usage_min 0.2308 (0.2295) gate/usage_std 0.0992 (0.0976) teacher/entropy 0.0754 (0.0739) teacher/usage_max 0.5819 (0.6687) teacher/usage_min 0.0632 (0.0656) teacher/usage_std 0.2123 (0.2561) nleep/row_max_mean 1472.8373 (1479.9610) nleep/row_max_std 62.5775 (52.6233) nleep/row_min_mean 1447.9602 (1454.6589) lr 1.5358e-03 eta 0:09:15
epoch [18/50] batch [140/176] time 0.092 (0.097) data 0.000 (0.002) loss 1.4280 (1.4594) teacher_loss 0.1578 (0.2151) loss_zs_kd 0.0244 (0.0360) loss_oracle 0.6089 (0.6326) kd_loss 0.9536 (0.9100) acc 93.7500 (92.4554) gate/entropy 1.0550 (1.0563) gate/usage_max 0.4685 (0.4646) gate/usage_min 0.2312 (0.2297) gate/usage_std 0.0997 (0.0979) teacher/entropy 0.0622 (0.0731) teacher/usage_max 0.6007 (0.6639) teacher/usage_min 0.0854 (0.0649) teacher/usage_std 0.2108 (0.2541) nleep/row_max_mean 1479.6028 (1480.1539) nleep/row_max_std 56.7156 (52.5563) nleep/row_min_mean 1454.2817 (1454.8626) lr 1.5358e-03 eta 0:09:10
epoch [18/50] batch [160/176] time 0.088 (0.096) data 0.000 (0.002) loss 1.4022 (1.4595) teacher_loss 0.2512 (0.2137) loss_zs_kd 0.0398 (0.0363) loss_oracle 0.6260 (0.6334) kd_loss 0.8182 (0.9110) acc 84.3750 (92.4023) gate/entropy 1.0545 (1.0561) gate/usage_max 0.4698 (0.4652) gate/usage_min 0.2315 (0.2299) gate/usage_std 0.1003 (0.0982) teacher/entropy 0.0652 (0.0718) teacher/usage_max 0.8070 (0.6638) teacher/usage_min 0.0286 (0.0627) teacher/usage_std 0.3395 (0.2544) nleep/row_max_mean 1477.2162 (1480.5812) nleep/row_max_std 61.4814 (52.2966) nleep/row_min_mean 1448.7402 (1455.0879) lr 1.5358e-03 eta 0:09:02
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,166
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,738
* accuracy: 65.4%
* error: 34.6%
* macro_f1: 59.9%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [19/50] batch [20/176] time 0.107 (0.101) data 0.000 (0.014) loss 1.3459 (1.4785) teacher_loss 0.0733 (0.2298) loss_zs_kd 0.0377 (0.0449) loss_oracle 0.5913 (0.5987) kd_loss 0.9582 (0.9270) acc 100.0000 (91.4062) gate/entropy 1.0536 (1.0540) gate/usage_max 0.4723 (0.4714) gate/usage_min 0.2321 (0.2321) gate/usage_std 0.1016 (0.1011) teacher/entropy 0.0256 (0.0512) teacher/usage_max 0.6670 (0.6658) teacher/usage_min 0.0003 (0.0364) teacher/usage_std 0.2722 (0.2611) nleep/row_max_mean 1495.0547 (1487.3953) nleep/row_max_std 45.7265 (50.2107) nleep/row_min_mean 1465.8860 (1459.1134) lr 1.4818e-03 eta 0:09:28
epoch [19/50] batch [40/176] time 0.128 (0.106) data 0.001 (0.007) loss 1.5327 (1.4615) teacher_loss 0.3859 (0.2393) loss_zs_kd 0.0421 (0.0392) loss_oracle 0.5578 (0.5962) kd_loss 0.8468 (0.9045) acc 81.2500 (91.2500) gate/entropy 1.0531 (1.0537) gate/usage_max 0.4736 (0.4720) gate/usage_min 0.2326 (0.2323) gate/usage_std 0.1023 (0.1014) teacher/entropy 0.0563 (0.0572) teacher/usage_max 0.7700 (0.6872) teacher/usage_min 0.0312 (0.0374) teacher/usage_std 0.3162 (0.2725) nleep/row_max_mean 1488.5861 (1484.9414) nleep/row_max_std 43.0110 (53.0255) nleep/row_min_mean 1458.7368 (1456.6597) lr 1.4818e-03 eta 0:09:51
epoch [19/50] batch [60/176] time 0.093 (0.104) data 0.001 (0.005) loss 1.5188 (1.4517) teacher_loss 0.2376 (0.2433) loss_zs_kd 0.0314 (0.0389) loss_oracle 0.6411 (0.5863) kd_loss 0.9450 (0.8958) acc 93.7500 (91.4062) gate/entropy 1.0522 (1.0533) gate/usage_max 0.4753 (0.4729) gate/usage_min 0.2327 (0.2324) gate/usage_std 0.1033 (0.1019) teacher/entropy 0.0471 (0.0528) teacher/usage_max 0.6485 (0.7059) teacher/usage_min 0.0008 (0.0312) teacher/usage_std 0.2647 (0.2839) nleep/row_max_mean 1486.7197 (1486.3461) nleep/row_max_std 60.1535 (53.2414) nleep/row_min_mean 1458.6708 (1457.5691) lr 1.4818e-03 eta 0:09:36
epoch [19/50] batch [80/176] time 0.094 (0.101) data 0.000 (0.004) loss 1.5368 (1.4463) teacher_loss 0.3434 (0.2393) loss_zs_kd 0.0271 (0.0385) loss_oracle 0.5626 (0.5858) kd_loss 0.8985 (0.8948) acc 87.5000 (91.3672) gate/entropy 1.0515 (1.0530) gate/usage_max 0.4770 (0.4737) gate/usage_min 0.2331 (0.2325) gate/usage_std 0.1042 (0.1024) teacher/entropy 0.0237 (0.0519) teacher/usage_max 0.7423 (0.7070) teacher/usage_min 0.0021 (0.0303) teacher/usage_std 0.3071 (0.2844) nleep/row_max_mean 1492.4614 (1486.3293) nleep/row_max_std 48.8972 (53.7112) nleep/row_min_mean 1460.2041 (1457.3380) lr 1.4818e-03 eta 0:09:19
epoch [19/50] batch [100/176] time 0.083 (0.099) data 0.000 (0.003) loss 1.3070 (1.4503) teacher_loss 0.1080 (0.2429) loss_zs_kd 0.0358 (0.0378) loss_oracle 0.7079 (0.5933) kd_loss 0.8271 (0.8918) acc 96.8750 (91.2188) gate/entropy 1.0507 (1.0526) gate/usage_max 0.4788 (0.4746) gate/usage_min 0.2334 (0.2326) gate/usage_std 0.1052 (0.1029) teacher/entropy 0.0857 (0.0515) teacher/usage_max 0.7462 (0.7105) teacher/usage_min 0.0241 (0.0287) teacher/usage_std 0.3038 (0.2869) nleep/row_max_mean 1489.0591 (1486.5516) nleep/row_max_std 55.2056 (53.7383) nleep/row_min_mean 1458.3116 (1457.2900) lr 1.4818e-03 eta 0:09:08
epoch [19/50] batch [120/176] time 0.091 (0.098) data 0.000 (0.003) loss 1.4477 (1.4536) teacher_loss 0.2805 (0.2480) loss_zs_kd 0.0329 (0.0368) loss_oracle 0.5835 (0.5964) kd_loss 0.8590 (0.8890) acc 93.7500 (91.0938) gate/entropy 1.0500 (1.0522) gate/usage_max 0.4802 (0.4755) gate/usage_min 0.2336 (0.2327) gate/usage_std 0.1060 (0.1034) teacher/entropy 0.0894 (0.0528) teacher/usage_max 0.6838 (0.7108) teacher/usage_min 0.0542 (0.0288) teacher/usage_std 0.2619 (0.2870) nleep/row_max_mean 1483.0964 (1486.1104) nleep/row_max_std 60.0662 (54.1292) nleep/row_min_mean 1456.2367 (1456.8252) lr 1.4818e-03 eta 0:09:02
epoch [19/50] batch [140/176] time 0.088 (0.098) data 0.000 (0.002) loss 1.2532 (1.4447) teacher_loss 0.0761 (0.2384) loss_zs_kd 0.0527 (0.0365) loss_oracle 0.6450 (0.6010) kd_loss 0.8282 (0.8876) acc 100.0000 (91.5179) gate/entropy 1.0488 (1.0518) gate/usage_max 0.4824 (0.4763) gate/usage_min 0.2336 (0.2329) gate/usage_std 0.1074 (0.1038) teacher/entropy 0.0389 (0.0527) teacher/usage_max 0.8002 (0.7112) teacher/usage_min 0.0313 (0.0283) teacher/usage_std 0.3348 (0.2873) nleep/row_max_mean 1494.6135 (1485.8119) nleep/row_max_std 47.4163 (54.4836) nleep/row_min_mean 1459.7717 (1456.5063) lr 1.4818e-03 eta 0:08:55
epoch [19/50] batch [160/176] time 0.083 (0.098) data 0.000 (0.002) loss 1.4153 (1.4416) teacher_loss 0.2715 (0.2359) loss_zs_kd 0.0211 (0.0356) loss_oracle 0.5201 (0.6033) kd_loss 0.8732 (0.8862) acc 90.6250 (91.5820) gate/entropy 1.0481 (1.0514) gate/usage_max 0.4838 (0.4771) gate/usage_min 0.2338 (0.2330) gate/usage_std 0.1082 (0.1043) teacher/entropy 0.0450 (0.0527) teacher/usage_max 0.7336 (0.7115) teacher/usage_min 0.0000 (0.0284) teacher/usage_std 0.3032 (0.2875) nleep/row_max_mean 1490.5627 (1486.2740) nleep/row_max_std 55.5915 (54.0370) nleep/row_min_mean 1460.0908 (1456.8989) lr 1.4818e-03 eta 0:08:56
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,172
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,637
* accuracy: 61.6%
* error: 38.4%
* macro_f1: 58.3%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [20/50] batch [20/176] time 0.090 (0.104) data 0.000 (0.014) loss 1.3574 (1.4084) teacher_loss 0.1296 (0.2072) loss_zs_kd 0.0399 (0.0337) loss_oracle 0.6126 (0.6375) kd_loss 0.9016 (0.8656) acc 93.7500 (92.5000) gate/entropy 1.0470 (1.0475) gate/usage_max 0.4860 (0.4851) gate/usage_min 0.2344 (0.2343) gate/usage_std 0.1095 (0.1090) teacher/entropy 0.0140 (0.0443) teacher/usage_max 0.7179 (0.7359) teacher/usage_min 0.0607 (0.0223) teacher/usage_std 0.2797 (0.3032) nleep/row_max_mean 1483.2499 (1487.7568) nleep/row_max_std 54.0675 (55.3969) nleep/row_min_mean 1454.1388 (1457.4398) lr 1.4258e-03 eta 0:09:27
epoch [20/50] batch [40/176] time 0.092 (0.098) data 0.000 (0.007) loss 1.7061 (1.4198) teacher_loss 0.3632 (0.2175) loss_zs_kd 0.0226 (0.0344) loss_oracle 0.6496 (0.6318) kd_loss 1.0068 (0.8692) acc 93.7500 (92.3438) gate/entropy 1.0471 (1.0471) gate/usage_max 0.4861 (0.4858) gate/usage_min 0.2350 (0.2344) gate/usage_std 0.1095 (0.1094) teacher/entropy 0.0420 (0.0465) teacher/usage_max 0.5357 (0.7260) teacher/usage_min 0.0390 (0.0243) teacher/usage_std 0.2130 (0.2969) nleep/row_max_mean 1468.4744 (1486.5682) nleep/row_max_std 60.3080 (54.5686) nleep/row_min_mean 1443.7510 (1457.0439) lr 1.4258e-03 eta 0:08:48
epoch [20/50] batch [60/176] time 0.097 (0.096) data 0.001 (0.005) loss 1.5046 (1.4319) teacher_loss 0.1821 (0.2329) loss_zs_kd 0.0453 (0.0328) loss_oracle 0.6473 (0.6259) kd_loss 0.9762 (0.8696) acc 93.7500 (91.6146) gate/entropy 1.0464 (1.0468) gate/usage_max 0.4874 (0.4864) gate/usage_min 0.2351 (0.2345) gate/usage_std 0.1103 (0.1098) teacher/entropy 0.0919 (0.0507) teacher/usage_max 0.5138 (0.7182) teacher/usage_min 0.0235 (0.0250) teacher/usage_std 0.2201 (0.2927) nleep/row_max_mean 1465.2354 (1486.3211) nleep/row_max_std 55.3181 (54.8544) nleep/row_min_mean 1437.0925 (1456.9514) lr 1.4258e-03 eta 0:08:37
epoch [20/50] batch [80/176] time 0.104 (0.095) data 0.000 (0.004) loss 1.3460 (1.4243) teacher_loss 0.1554 (0.2317) loss_zs_kd 0.0373 (0.0313) loss_oracle 0.6265 (0.6210) kd_loss 0.8587 (0.8664) acc 93.7500 (91.8750) gate/entropy 1.0451 (1.0465) gate/usage_max 0.4896 (0.4870) gate/usage_min 0.2348 (0.2346) gate/usage_std 0.1117 (0.1101) teacher/entropy 0.0583 (0.0514) teacher/usage_max 0.7181 (0.7202) teacher/usage_min 0.0144 (0.0259) teacher/usage_std 0.2910 (0.2934) nleep/row_max_mean 1496.1895 (1485.7536) nleep/row_max_std 50.3229 (54.5575) nleep/row_min_mean 1466.5399 (1456.6953) lr 1.4258e-03 eta 0:08:30
epoch [20/50] batch [100/176] time 0.100 (0.095) data 0.001 (0.003) loss 1.4261 (1.4310) teacher_loss 0.1860 (0.2402) loss_zs_kd 0.0494 (0.0322) loss_oracle 0.7250 (0.6196) kd_loss 0.8529 (0.8649) acc 96.8750 (91.6250) gate/entropy 1.0446 (1.0462) gate/usage_max 0.4905 (0.4876) gate/usage_min 0.2350 (0.2346) gate/usage_std 0.1123 (0.1105) teacher/entropy 0.1102 (0.0518) teacher/usage_max 0.6462 (0.7208) teacher/usage_min 0.0522 (0.0241) teacher/usage_std 0.2436 (0.2942) nleep/row_max_mean 1472.2063 (1484.7419) nleep/row_max_std 59.1807 (54.4267) nleep/row_min_mean 1446.4788 (1455.9490) lr 1.4258e-03 eta 0:08:29
epoch [20/50] batch [120/176] time 0.095 (0.095) data 0.000 (0.003) loss 1.3488 (1.4248) teacher_loss 0.1131 (0.2327) loss_zs_kd 0.0128 (0.0323) loss_oracle 0.6367 (0.6219) kd_loss 0.9109 (0.8651) acc 93.7500 (91.9010) gate/entropy 1.0439 (1.0458) gate/usage_max 0.4917 (0.4882) gate/usage_min 0.2350 (0.2347) gate/usage_std 0.1131 (0.1109) teacher/entropy 0.0800 (0.0523) teacher/usage_max 0.6152 (0.7186) teacher/usage_min 0.0076 (0.0244) teacher/usage_std 0.2500 (0.2928) nleep/row_max_mean 1480.2673 (1484.9037) nleep/row_max_std 57.9286 (54.6670) nleep/row_min_mean 1454.6625 (1456.2712) lr 1.4258e-03 eta 0:08:28
epoch [20/50] batch [140/176] time 0.097 (0.096) data 0.000 (0.002) loss 1.4076 (1.4187) teacher_loss 0.2698 (0.2307) loss_zs_kd 0.0203 (0.0327) loss_oracle 0.5316 (0.6207) kd_loss 0.8618 (0.8613) acc 90.6250 (91.8973) gate/entropy 1.0428 (1.0455) gate/usage_max 0.4935 (0.4888) gate/usage_min 0.2348 (0.2347) gate/usage_std 0.1142 (0.1113) teacher/entropy 0.0221 (0.0528) teacher/usage_max 0.7576 (0.7217) teacher/usage_min 0.0000 (0.0250) teacher/usage_std 0.3159 (0.2943) nleep/row_max_mean 1498.8268 (1484.7881) nleep/row_max_std 54.6404 (54.6202) nleep/row_min_mean 1468.8666 (1456.3757) lr 1.4258e-03 eta 0:08:29
epoch [20/50] batch [160/176] time 0.083 (0.098) data 0.000 (0.002) loss 1.6102 (1.4220) teacher_loss 0.1874 (0.2309) loss_zs_kd 0.0417 (0.0333) loss_oracle 0.7097 (0.6223) kd_loss 1.0470 (0.8633) acc 87.5000 (91.9336) gate/entropy 1.0433 (1.0452) gate/usage_max 0.4929 (0.4894) gate/usage_min 0.2358 (0.2348) gate/usage_std 0.1137 (0.1116) teacher/entropy 0.0293 (0.0534) teacher/usage_max 0.5020 (0.7167) teacher/usage_min 0.0023 (0.0271) teacher/usage_std 0.2341 (0.2914) nleep/row_max_mean 1474.7118 (1484.7015) nleep/row_max_std 43.6436 (54.0628) nleep/row_min_mean 1448.3829 (1456.6017) lr 1.4258e-03 eta 0:08:38
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,172
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,661
* accuracy: 62.5%
* error: 37.5%
* macro_f1: 58.8%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [21/50] batch [20/176] time 0.097 (0.115) data 0.001 (0.017) loss 1.5145 (1.4142) teacher_loss 0.3185 (0.2186) loss_zs_kd 0.0524 (0.0371) loss_oracle 0.6000 (0.6144) kd_loss 0.8698 (0.8699) acc 90.6250 (90.7812) gate/entropy 1.0418 (1.0420) gate/usage_max 0.4953 (0.4950) gate/usage_min 0.2358 (0.2356) gate/usage_std 0.1153 (0.1152) teacher/entropy 0.0193 (0.0470) teacher/usage_max 0.7465 (0.7051) teacher/usage_min 0.0020 (0.0252) teacher/usage_std 0.3094 (0.2848) nleep/row_max_mean 1487.1406 (1481.7864) nleep/row_max_std 56.3519 (55.5056) nleep/row_min_mean 1457.7021 (1454.8894) lr 1.3681e-03 eta 0:10:06
epoch [21/50] batch [40/176] time 0.104 (0.112) data 0.001 (0.009) loss 1.3483 (1.4292) teacher_loss 0.1643 (0.2151) loss_zs_kd 0.0409 (0.0362) loss_oracle 0.5581 (0.6231) kd_loss 0.8845 (0.8844) acc 96.8750 (91.5625) gate/entropy 1.0416 (1.0418) gate/usage_max 0.4958 (0.4953) gate/usage_min 0.2362 (0.2358) gate/usage_std 0.1156 (0.1153) teacher/entropy 0.0531 (0.0495) teacher/usage_max 0.6772 (0.6826) teacher/usage_min 0.0067 (0.0336) teacher/usage_std 0.2740 (0.2715) nleep/row_max_mean 1492.0670 (1482.8881) nleep/row_max_std 43.5155 (54.1138) nleep/row_min_mean 1465.5767 (1456.4230) lr 1.3681e-03 eta 0:09:45
epoch [21/50] batch [60/176] time 0.100 (0.107) data 0.001 (0.006) loss 1.3113 (1.4236) teacher_loss 0.1435 (0.2088) loss_zs_kd 0.0437 (0.0355) loss_oracle 0.6305 (0.6312) kd_loss 0.8306 (0.8815) acc 93.7500 (92.3438) gate/entropy 1.0409 (1.0416) gate/usage_max 0.4970 (0.4957) gate/usage_min 0.2362 (0.2360) gate/usage_std 0.1164 (0.1156) teacher/entropy 0.0548 (0.0523) teacher/usage_max 0.7376 (0.6808) teacher/usage_min 0.0591 (0.0353) teacher/usage_std 0.2919 (0.2701) nleep/row_max_mean 1480.3553 (1481.7629) nleep/row_max_std 52.5157 (53.8778) nleep/row_min_mean 1453.8596 (1455.6010) lr 1.3681e-03 eta 0:09:21
epoch [21/50] batch [80/176] time 0.095 (0.105) data 0.000 (0.005) loss 1.4172 (1.4252) teacher_loss 0.2252 (0.2136) loss_zs_kd 0.0293 (0.0346) loss_oracle 0.6296 (0.6338) kd_loss 0.8625 (0.8774) acc 90.6250 (92.1094) gate/entropy 1.0403 (1.0414) gate/usage_max 0.4978 (0.4960) gate/usage_min 0.2364 (0.2361) gate/usage_std 0.1169 (0.1158) teacher/entropy 0.0567 (0.0575) teacher/usage_max 0.6953 (0.6772) teacher/usage_min 0.0260 (0.0396) teacher/usage_std 0.2759 (0.2672) nleep/row_max_mean 1482.6423 (1481.3020) nleep/row_max_std 58.3011 (53.8672) nleep/row_min_mean 1456.2505 (1455.3407) lr 1.3681e-03 eta 0:09:03
epoch [21/50] batch [100/176] time 0.098 (0.103) data 0.000 (0.004) loss 1.3713 (1.4259) teacher_loss 0.2429 (0.2174) loss_zs_kd 0.0201 (0.0335) loss_oracle 0.5841 (0.6338) kd_loss 0.8263 (0.8748) acc 90.6250 (92.2188) gate/entropy 1.0402 (1.0412) gate/usage_max 0.4981 (0.4964) gate/usage_min 0.2366 (0.2362) gate/usage_std 0.1171 (0.1160) teacher/entropy 0.0474 (0.0595) teacher/usage_max 0.7458 (0.6764) teacher/usage_min 0.0944 (0.0433) teacher/usage_std 0.2929 (0.2656) nleep/row_max_mean 1490.1318 (1481.9648) nleep/row_max_std 49.4495 (53.5616) nleep/row_min_mean 1462.5939 (1455.9412) lr 1.3681e-03 eta 0:08:55
epoch [21/50] batch [120/176] time 0.091 (0.102) data 0.000 (0.003) loss 1.6970 (1.4286) teacher_loss 0.5823 (0.2196) loss_zs_kd 0.0388 (0.0338) loss_oracle 0.6024 (0.6408) kd_loss 0.7941 (0.8717) acc 84.3750 (92.3177) gate/entropy 1.0398 (1.0410) gate/usage_max 0.4988 (0.4967) gate/usage_min 0.2366 (0.2363) gate/usage_std 0.1175 (0.1162) teacher/entropy 0.0466 (0.0595) teacher/usage_max 0.8010 (0.6796) teacher/usage_min 0.0146 (0.0439) teacher/usage_std 0.3379 (0.2671) nleep/row_max_mean 1473.4806 (1481.5502) nleep/row_max_std 52.7437 (53.7865) nleep/row_min_mean 1446.6785 (1455.6491) lr 1.3681e-03 eta 0:08:47
epoch [21/50] batch [140/176] time 0.099 (0.102) data 0.001 (0.003) loss 1.1741 (1.4274) teacher_loss 0.0346 (0.2151) loss_zs_kd 0.0183 (0.0335) loss_oracle 0.5961 (0.6491) kd_loss 0.8323 (0.8710) acc 100.0000 (92.5000) gate/entropy 1.0393 (1.0408) gate/usage_max 0.4994 (0.4970) gate/usage_min 0.2366 (0.2363) gate/usage_std 0.1180 (0.1164) teacher/entropy 0.0523 (0.0607) teacher/usage_max 0.7296 (0.6776) teacher/usage_min 0.0846 (0.0481) teacher/usage_std 0.2832 (0.2648) nleep/row_max_mean 1495.8455 (1481.5479) nleep/row_max_std 54.8574 (54.3179) nleep/row_min_mean 1469.4490 (1455.7318) lr 1.3681e-03 eta 0:08:42
epoch [21/50] batch [160/176] time 0.093 (0.101) data 0.000 (0.002) loss 1.2327 (1.4239) teacher_loss 0.1487 (0.2148) loss_zs_kd 0.0381 (0.0339) loss_oracle 0.5020 (0.6451) kd_loss 0.8139 (0.8696) acc 93.7500 (92.4219) gate/entropy 1.0389 (1.0407) gate/usage_max 0.5001 (0.4973) gate/usage_min 0.2366 (0.2364) gate/usage_std 0.1184 (0.1166) teacher/entropy 0.0142 (0.0609) teacher/usage_max 0.8119 (0.6780) teacher/usage_min 0.0321 (0.0511) teacher/usage_std 0.3422 (0.2641) nleep/row_max_mean 1492.6931 (1481.4741) nleep/row_max_std 48.8687 (54.4085) nleep/row_min_mean 1464.6300 (1455.6951) lr 1.3681e-03 eta 0:08:37
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,158
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,742
* accuracy: 65.6%
* error: 34.4%
* macro_f1: 59.7%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [22/50] batch [20/176] time 0.094 (0.110) data 0.000 (0.015) loss 1.3368 (1.4314) teacher_loss 0.1222 (0.2307) loss_zs_kd 0.0413 (0.0348) loss_oracle 0.6280 (0.6498) kd_loss 0.8799 (0.8584) acc 93.7500 (91.0938) gate/entropy 1.0385 (1.0386) gate/usage_max 0.5007 (0.5006) gate/usage_min 0.2367 (0.2367) gate/usage_std 0.1188 (0.1187) teacher/entropy 0.0418 (0.0578) teacher/usage_max 0.6863 (0.6903) teacher/usage_min 0.0381 (0.0552) teacher/usage_std 0.2677 (0.2692) nleep/row_max_mean 1475.5212 (1477.3951) nleep/row_max_std 59.6617 (58.1551) nleep/row_min_mean 1446.6553 (1452.0006) lr 1.3090e-03 eta 0:09:17
epoch [22/50] batch [40/176] time 0.091 (0.111) data 0.000 (0.008) loss 1.3618 (1.4478) teacher_loss 0.1517 (0.2427) loss_zs_kd 0.0224 (0.0338) loss_oracle 0.6632 (0.6496) kd_loss 0.8673 (0.8635) acc 96.8750 (91.1719) gate/entropy 1.0379 (1.0384) gate/usage_max 0.5017 (0.5009) gate/usage_min 0.2367 (0.2367) gate/usage_std 0.1195 (0.1190) teacher/entropy 0.0051 (0.0581) teacher/usage_max 0.7496 (0.6829) teacher/usage_min 0.0314 (0.0529) teacher/usage_std 0.3041 (0.2659) nleep/row_max_mean 1488.6412 (1480.7995) nleep/row_max_std 45.7879 (54.4684) nleep/row_min_mean 1462.0806 (1454.7314) lr 1.3090e-03 eta 0:09:21
epoch [22/50] batch [60/176] time 0.094 (0.105) data 0.001 (0.005) loss 1.3659 (1.4336) teacher_loss 0.1837 (0.2305) loss_zs_kd 0.0306 (0.0342) loss_oracle 0.6520 (0.6538) kd_loss 0.8409 (0.8591) acc 93.7500 (91.6146) gate/entropy 1.0374 (1.0382) gate/usage_max 0.5025 (0.5013) gate/usage_min 0.2367 (0.2368) gate/usage_std 0.1200 (0.1192) teacher/entropy 0.0269 (0.0564) teacher/usage_max 0.7603 (0.6914) teacher/usage_min 0.0010 (0.0509) teacher/usage_std 0.3171 (0.2712) nleep/row_max_mean 1486.6249 (1481.6734) nleep/row_max_std 52.7728 (53.6884) nleep/row_min_mean 1458.6821 (1455.1669) lr 1.3090e-03 eta 0:08:49
epoch [22/50] batch [80/176] time 0.088 (0.103) data 0.000 (0.004) loss 1.5165 (1.4305) teacher_loss 0.3610 (0.2310) loss_zs_kd 0.0267 (0.0355) loss_oracle 0.6693 (0.6563) kd_loss 0.8075 (0.8536) acc 81.2500 (91.4453) gate/entropy 1.0370 (1.0380) gate/usage_max 0.5030 (0.5016) gate/usage_min 0.2366 (0.2367) gate/usage_std 0.1204 (0.1194) teacher/entropy 0.0367 (0.0565) teacher/usage_max 0.7842 (0.6973) teacher/usage_min 0.0576 (0.0556) teacher/usage_std 0.3214 (0.2730) nleep/row_max_mean 1485.8408 (1481.7684) nleep/row_max_std 46.5111 (53.9770) nleep/row_min_mean 1458.5206 (1455.3226) lr 1.3090e-03 eta 0:08:35
epoch [22/50] batch [100/176] time 0.095 (0.101) data 0.000 (0.003) loss 1.4820 (1.4245) teacher_loss 0.2179 (0.2297) loss_zs_kd 0.0473 (0.0369) loss_oracle 0.7364 (0.6551) kd_loss 0.8722 (0.8488) acc 93.7500 (91.6250) gate/entropy 1.0368 (1.0377) gate/usage_max 0.5033 (0.5020) gate/usage_min 0.2365 (0.2367) gate/usage_std 0.1206 (0.1197) teacher/entropy 0.0797 (0.0558) teacher/usage_max 0.6312 (0.7036) teacher/usage_min 0.1103 (0.0579) teacher/usage_std 0.2192 (0.2759) nleep/row_max_mean 1484.9678 (1482.1176) nleep/row_max_std 41.5038 (54.2481) nleep/row_min_mean 1458.6711 (1455.4249) lr 1.3090e-03 eta 0:08:24
epoch [22/50] batch [120/176] time 0.111 (0.100) data 0.000 (0.003) loss 1.3951 (1.4162) teacher_loss 0.1549 (0.2242) loss_zs_kd 0.0585 (0.0384) loss_oracle 0.7225 (0.6522) kd_loss 0.8497 (0.8466) acc 96.8750 (91.9792) gate/entropy 1.0363 (1.0374) gate/usage_max 0.5040 (0.5024) gate/usage_min 0.2363 (0.2366) gate/usage_std 0.1211 (0.1199) teacher/entropy 0.0912 (0.0534) teacher/usage_max 0.6334 (0.7088) teacher/usage_min 0.1587 (0.0591) teacher/usage_std 0.2131 (0.2785) nleep/row_max_mean 1463.7791 (1482.3257) nleep/row_max_std 54.6934 (54.5222) nleep/row_min_mean 1440.4897 (1455.5489) lr 1.3090e-03 eta 0:08:17
epoch [22/50] batch [140/176] time 0.093 (0.100) data 0.000 (0.002) loss 1.3919 (1.4163) teacher_loss 0.2016 (0.2275) loss_zs_kd 0.0685 (0.0385) loss_oracle 0.7112 (0.6533) kd_loss 0.8005 (0.8429) acc 90.6250 (91.7188) gate/entropy 1.0346 (1.0372) gate/usage_max 0.5065 (0.5028) gate/usage_min 0.2353 (0.2365) gate/usage_std 0.1228 (0.1202) teacher/entropy 0.0457 (0.0534) teacher/usage_max 0.7715 (0.7132) teacher/usage_min 0.0849 (0.0594) teacher/usage_std 0.3107 (0.2807) nleep/row_max_mean 1505.0535 (1482.3949) nleep/row_max_std 49.1881 (54.8541) nleep/row_min_mean 1476.6763 (1455.6435) lr 1.3090e-03 eta 0:08:18
epoch [22/50] batch [160/176] time 0.094 (0.100) data 0.000 (0.002) loss 1.4965 (1.4163) teacher_loss 0.2624 (0.2299) loss_zs_kd 0.0403 (0.0380) loss_oracle 0.7166 (0.6548) kd_loss 0.8557 (0.8400) acc 90.6250 (91.6406) gate/entropy 1.0349 (1.0369) gate/usage_max 0.5060 (0.5031) gate/usage_min 0.2355 (0.2364) gate/usage_std 0.1225 (0.1205) teacher/entropy 0.0882 (0.0538) teacher/usage_max 0.6355 (0.7158) teacher/usage_min 0.1445 (0.0612) teacher/usage_std 0.2159 (0.2819) nleep/row_max_mean 1483.7931 (1482.3255) nleep/row_max_std 49.5840 (54.7910) nleep/row_min_mean 1460.4340 (1455.7168) lr 1.3090e-03 eta 0:08:12
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,163
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,732
* accuracy: 65.2%
* error: 34.8%
* macro_f1: 59.9%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [23/50] batch [20/176] time 0.089 (0.110) data 0.000 (0.014) loss 1.1904 (1.4171) teacher_loss 0.0853 (0.2647) loss_zs_kd 0.0261 (0.0324) loss_oracle 0.5667 (0.6208) kd_loss 0.8087 (0.8258) acc 96.8750 (90.7812) gate/entropy 1.0340 (1.0345) gate/usage_max 0.5074 (0.5067) gate/usage_min 0.2350 (0.2353) gate/usage_std 0.1234 (0.1229) teacher/entropy 0.0648 (0.0495) teacher/usage_max 0.7389 (0.7353) teacher/usage_min 0.0452 (0.0627) teacher/usage_std 0.2951 (0.2927) nleep/row_max_mean 1490.9136 (1479.7703) nleep/row_max_std 60.0129 (56.8865) nleep/row_min_mean 1468.8948 (1455.0238) lr 1.2487e-03 eta 0:09:00
epoch [23/50] batch [40/176] time 0.098 (0.101) data 0.000 (0.007) loss 1.2225 (1.3857) teacher_loss 0.1452 (0.2458) loss_zs_kd 0.0257 (0.0341) loss_oracle 0.5585 (0.6067) kd_loss 0.7852 (0.8196) acc 96.8750 (91.2500) gate/entropy 1.0335 (1.0342) gate/usage_max 0.5081 (0.5070) gate/usage_min 0.2348 (0.2352) gate/usage_std 0.1239 (0.1232) teacher/entropy 0.0512 (0.0523) teacher/usage_max 0.7857 (0.7392) teacher/usage_min 0.0402 (0.0628) teacher/usage_std 0.3245 (0.2949) nleep/row_max_mean 1488.2894 (1480.0078) nleep/row_max_std 55.7080 (56.7382) nleep/row_min_mean 1461.3328 (1455.0779) lr 1.2487e-03 eta 0:08:11
epoch [23/50] batch [60/176] time 0.094 (0.099) data 0.001 (0.005) loss 1.2913 (1.3693) teacher_loss 0.1346 (0.2347) loss_zs_kd 0.0385 (0.0333) loss_oracle 0.6197 (0.6028) kd_loss 0.8275 (0.8165) acc 96.8750 (91.2500) gate/entropy 1.0336 (1.0340) gate/usage_max 0.5079 (0.5073) gate/usage_min 0.2351 (0.2351) gate/usage_std 0.1238 (0.1233) teacher/entropy 0.0757 (0.0591) teacher/usage_max 0.6975 (0.7338) teacher/usage_min 0.0581 (0.0631) teacher/usage_std 0.2685 (0.2921) nleep/row_max_mean 1484.1016 (1479.8944) nleep/row_max_std 53.9337 (54.9745) nleep/row_min_mean 1459.5398 (1454.9890) lr 1.2487e-03 eta 0:07:59
epoch [23/50] batch [80/176] time 0.096 (0.097) data 0.000 (0.004) loss 1.4645 (1.3738) teacher_loss 0.2616 (0.2329) loss_zs_kd 0.0445 (0.0336) loss_oracle 0.6604 (0.6081) kd_loss 0.8504 (0.8201) acc 90.6250 (91.6406) gate/entropy 1.0329 (1.0338) gate/usage_max 0.5089 (0.5076) gate/usage_min 0.2349 (0.2351) gate/usage_std 0.1244 (0.1236) teacher/entropy 0.0568 (0.0607) teacher/usage_max 0.6838 (0.7264) teacher/usage_min 0.1298 (0.0653) teacher/usage_std 0.2489 (0.2869) nleep/row_max_mean 1475.8762 (1478.8466) nleep/row_max_std 53.7289 (55.4288) nleep/row_min_mean 1453.0854 (1454.0455) lr 1.2487e-03 eta 0:07:52
epoch [23/50] batch [100/176] time 0.101 (0.097) data 0.000 (0.003) loss 1.4617 (1.3700) teacher_loss 0.3055 (0.2288) loss_zs_kd 0.0353 (0.0330) loss_oracle 0.6770 (0.6111) kd_loss 0.8000 (0.8192) acc 90.6250 (91.9688) gate/entropy 1.0328 (1.0336) gate/usage_max 0.5091 (0.5079) gate/usage_min 0.2350 (0.2350) gate/usage_std 0.1246 (0.1238) teacher/entropy 0.0904 (0.0626) teacher/usage_max 0.7143 (0.7249) teacher/usage_min 0.0429 (0.0643) teacher/usage_std 0.2815 (0.2867) nleep/row_max_mean 1474.5730 (1478.9442) nleep/row_max_std 57.0240 (55.8973) nleep/row_min_mean 1449.3940 (1454.2046) lr 1.2487e-03 eta 0:07:48
epoch [23/50] batch [120/176] time 0.100 (0.097) data 0.000 (0.003) loss 1.1953 (1.3734) teacher_loss 0.0863 (0.2299) loss_zs_kd 0.0243 (0.0334) loss_oracle 0.5390 (0.6145) kd_loss 0.8273 (0.8195) acc 100.0000 (91.9271) gate/entropy 1.0319 (1.0334) gate/usage_max 0.5104 (0.5082) gate/usage_min 0.2345 (0.2350) gate/usage_std 0.1255 (0.1240) teacher/entropy 0.0387 (0.0609) teacher/usage_max 0.7494 (0.7266) teacher/usage_min 0.0024 (0.0622) teacher/usage_std 0.3108 (0.2877) nleep/row_max_mean 1488.8191 (1478.6724) nleep/row_max_std 55.7627 (55.9942) nleep/row_min_mean 1460.8979 (1453.8832) lr 1.2487e-03 eta 0:07:47
epoch [23/50] batch [140/176] time 0.091 (0.097) data 0.000 (0.002) loss 1.3795 (1.3699) teacher_loss 0.1936 (0.2258) loss_zs_kd 0.0177 (0.0333) loss_oracle 0.6647 (0.6184) kd_loss 0.8447 (0.8183) acc 90.6250 (91.8527) gate/entropy 1.0317 (1.0332) gate/usage_max 0.5106 (0.5085) gate/usage_min 0.2346 (0.2349) gate/usage_std 0.1256 (0.1242) teacher/entropy 0.0801 (0.0603) teacher/usage_max 0.6682 (0.7287) teacher/usage_min 0.0311 (0.0596) teacher/usage_std 0.2611 (0.2894) nleep/row_max_mean 1491.3442 (1478.9288) nleep/row_max_std 44.0292 (55.8048) nleep/row_min_mean 1465.7803 (1454.1173) lr 1.2487e-03 eta 0:07:44
epoch [23/50] batch [160/176] time 0.100 (0.099) data 0.000 (0.002) loss 1.1629 (1.3702) teacher_loss 0.1838 (0.2268) loss_zs_kd 0.0230 (0.0327) loss_oracle 0.4935 (0.6213) kd_loss 0.7208 (0.8164) acc 93.7500 (91.8555) gate/entropy 1.0305 (1.0329) gate/usage_max 0.5123 (0.5089) gate/usage_min 0.2341 (0.2349) gate/usage_std 0.1268 (0.1244) teacher/entropy 0.0530 (0.0601) teacher/usage_max 0.8616 (0.7309) teacher/usage_min 0.0195 (0.0586) teacher/usage_std 0.3757 (0.2908) nleep/row_max_mean 1496.0935 (1479.2659) nleep/row_max_std 43.9577 (55.8924) nleep/row_min_mean 1470.3552 (1454.4637) lr 1.2487e-03 eta 0:07:50
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,175
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.7%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,614
* accuracy: 60.8%
* error: 39.2%
* macro_f1: 57.3%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [24/50] batch [20/176] time 0.088 (0.110) data 0.000 (0.013) loss 1.3437 (1.3710) teacher_loss 0.3442 (0.2557) loss_zs_kd 0.0111 (0.0277) loss_oracle 0.5727 (0.6034) kd_loss 0.7076 (0.7998) acc 87.5000 (91.2500) gate/entropy 1.0300 (1.0304) gate/usage_max 0.5130 (0.5124) gate/usage_min 0.2339 (0.2341) gate/usage_std 0.1273 (0.1269) teacher/entropy 0.0657 (0.0560) teacher/usage_max 0.8619 (0.7542) teacher/usage_min 0.0231 (0.0493) teacher/usage_std 0.3756 (0.3052) nleep/row_max_mean 1475.3331 (1479.0655) nleep/row_max_std 61.9662 (54.7628) nleep/row_min_mean 1451.5575 (1454.3370) lr 1.1874e-03 eta 0:08:40
epoch [24/50] batch [40/176] time 0.088 (0.098) data 0.000 (0.007) loss 1.4070 (1.3741) teacher_loss 0.3569 (0.2599) loss_zs_kd 0.0443 (0.0293) loss_oracle 0.6460 (0.6086) kd_loss 0.7049 (0.7952) acc 84.3750 (90.7812) gate/entropy 1.0296 (1.0301) gate/usage_max 0.5135 (0.5129) gate/usage_min 0.2339 (0.2340) gate/usage_std 0.1276 (0.1272) teacher/entropy 0.0630 (0.0587) teacher/usage_max 0.8686 (0.7554) teacher/usage_min 0.0162 (0.0519) teacher/usage_std 0.3806 (0.3063) nleep/row_max_mean 1488.7882 (1480.2837) nleep/row_max_std 43.6941 (55.0870) nleep/row_min_mean 1460.4084 (1455.4561) lr 1.1874e-03 eta 0:07:39
epoch [24/50] batch [60/176] time 0.087 (0.094) data 0.001 (0.005) loss 1.4365 (1.3771) teacher_loss 0.2658 (0.2534) loss_zs_kd 0.0591 (0.0303) loss_oracle 0.6498 (0.6161) kd_loss 0.8162 (0.8005) acc 90.6250 (90.8854) gate/entropy 1.0291 (1.0298) gate/usage_max 0.5143 (0.5132) gate/usage_min 0.2336 (0.2339) gate/usage_std 0.1282 (0.1275) teacher/entropy 0.0949 (0.0607) teacher/usage_max 0.6755 (0.7454) teacher/usage_min 0.0973 (0.0546) teacher/usage_std 0.2477 (0.2997) nleep/row_max_mean 1481.3386 (1480.5825) nleep/row_max_std 61.0577 (54.8713) nleep/row_min_mean 1458.1042 (1455.7335) lr 1.1874e-03 eta 0:07:18
epoch [24/50] batch [80/176] time 0.089 (0.091) data 0.000 (0.003) loss 1.4010 (1.3652) teacher_loss 0.2779 (0.2421) loss_zs_kd 0.0612 (0.0316) loss_oracle 0.6049 (0.6128) kd_loss 0.7901 (0.8009) acc 87.5000 (91.1719) gate/entropy 1.0283 (1.0296) gate/usage_max 0.5153 (0.5136) gate/usage_min 0.2334 (0.2338) gate/usage_std 0.1288 (0.1277) teacher/entropy 0.0380 (0.0604) teacher/usage_max 0.7827 (0.7451) teacher/usage_min 0.0575 (0.0550) teacher/usage_std 0.3205 (0.2998) nleep/row_max_mean 1496.5767 (1481.1049) nleep/row_max_std 44.8671 (54.5330) nleep/row_min_mean 1470.6804 (1456.3198) lr 1.1874e-03 eta 0:07:05
epoch [24/50] batch [100/176] time 0.099 (0.091) data 0.000 (0.003) loss 1.4879 (1.3755) teacher_loss 0.3379 (0.2446) loss_zs_kd 0.0240 (0.0312) loss_oracle 0.7653 (0.6184) kd_loss 0.7553 (0.8062) acc 87.5000 (90.9688) gate/entropy 1.0280 (1.0293) gate/usage_max 0.5157 (0.5139) gate/usage_min 0.2335 (0.2338) gate/usage_std 0.1291 (0.1279) teacher/entropy 0.0675 (0.0605) teacher/usage_max 0.7931 (0.7377) teacher/usage_min 0.0180 (0.0545) teacher/usage_std 0.3325 (0.2955) nleep/row_max_mean 1476.7227 (1481.4679) nleep/row_max_std 61.4274 (54.1714) nleep/row_min_mean 1452.7090 (1456.8586) lr 1.1874e-03 eta 0:07:05
epoch [24/50] batch [120/176] time 0.096 (0.092) data 0.000 (0.002) loss 1.3088 (1.3770) teacher_loss 0.1568 (0.2391) loss_zs_kd 0.0282 (0.0310) loss_oracle 0.7021 (0.6276) kd_loss 0.7869 (0.8086) acc 93.7500 (91.1979) gate/entropy 1.0278 (1.0291) gate/usage_max 0.5161 (0.5142) gate/usage_min 0.2334 (0.2337) gate/usage_std 0.1294 (0.1281) teacher/entropy 0.0654 (0.0604) teacher/usage_max 0.7480 (0.7342) teacher/usage_min 0.1054 (0.0546) teacher/usage_std 0.2937 (0.2934) nleep/row_max_mean 1484.8318 (1481.9874) nleep/row_max_std 52.0522 (54.0458) nleep/row_min_mean 1461.6487 (1457.4360) lr 1.1874e-03 eta 0:07:04
epoch [24/50] batch [140/176] time 0.084 (0.091) data 0.000 (0.002) loss 1.6202 (1.3844) teacher_loss 0.3166 (0.2340) loss_zs_kd 0.0433 (0.0304) loss_oracle 0.8445 (0.6390) kd_loss 0.8597 (0.8157) acc 84.3750 (91.4062) gate/entropy 1.0278 (1.0289) gate/usage_max 0.5161 (0.5145) gate/usage_min 0.2335 (0.2337) gate/usage_std 0.1294 (0.1283) teacher/entropy 0.0556 (0.0614) teacher/usage_max 0.6672 (0.7234) teacher/usage_min 0.1218 (0.0565) teacher/usage_std 0.2389 (0.2872) nleep/row_max_mean 1488.3823 (1482.1129) nleep/row_max_std 49.5537 (53.9838) nleep/row_min_mean 1467.4193 (1457.8120) lr 1.1874e-03 eta 0:07:01
epoch [24/50] batch [160/176] time 0.096 (0.091) data 0.000 (0.002) loss 1.5783 (1.3876) teacher_loss 0.3083 (0.2318) loss_zs_kd 0.0255 (0.0308) loss_oracle 0.6566 (0.6469) kd_loss 0.9290 (0.8170) acc 90.6250 (91.4844) gate/entropy 1.0281 (1.0288) gate/usage_max 0.5156 (0.5147) gate/usage_min 0.2337 (0.2337) gate/usage_std 0.1290 (0.1284) teacher/entropy 0.0992 (0.0651) teacher/usage_max 0.5233 (0.7164) teacher/usage_min 0.1227 (0.0602) teacher/usage_std 0.1642 (0.2824) nleep/row_max_mean 1481.8595 (1481.8507) nleep/row_max_std 42.3802 (53.8415) nleep/row_min_mean 1462.8390 (1457.8684) lr 1.1874e-03 eta 0:06:57
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,163
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,802
* accuracy: 67.8%
* error: 32.2%
* macro_f1: 61.5%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [25/50] batch [20/176] time 0.101 (0.114) data 0.000 (0.014) loss 1.4468 (1.4018) teacher_loss 0.3765 (0.2102) loss_zs_kd 0.0260 (0.0296) loss_oracle 0.5629 (0.6677) kd_loss 0.7758 (0.8430) acc 87.5000 (92.3438) gate/entropy 1.0281 (1.0276) gate/usage_max 0.5157 (0.5162) gate/usage_min 0.2338 (0.2335) gate/usage_std 0.1291 (0.1295) teacher/entropy 0.0977 (0.0853) teacher/usage_max 0.7253 (0.6518) teacher/usage_min 0.0493 (0.1006) teacher/usage_std 0.2863 (0.2355) nleep/row_max_mean 1489.6066 (1480.8585) nleep/row_max_std 43.3504 (51.9284) nleep/row_min_mean 1468.5376 (1459.9044) lr 1.1253e-03 eta 0:08:41
epoch [25/50] batch [40/176] time 0.101 (0.104) data 0.000 (0.007) loss 1.4178 (1.4112) teacher_loss 0.1116 (0.2072) loss_zs_kd 0.0288 (0.0332) loss_oracle 0.7464 (0.6708) kd_loss 0.9186 (0.8520) acc 93.7500 (92.6562) gate/entropy 1.0283 (1.0277) gate/usage_max 0.5153 (0.5162) gate/usage_min 0.2339 (0.2336) gate/usage_std 0.1289 (0.1295) teacher/entropy 0.1149 (0.0861) teacher/usage_max 0.5129 (0.6383) teacher/usage_min 0.1683 (0.1108) teacher/usage_std 0.1410 (0.2271) nleep/row_max_mean 1481.3350 (1480.5166) nleep/row_max_std 51.5550 (51.7408) nleep/row_min_mean 1460.7482 (1459.5693) lr 1.1253e-03 eta 0:07:51
epoch [25/50] batch [60/176] time 0.102 (0.108) data 0.001 (0.005) loss 1.2921 (1.4169) teacher_loss 0.1473 (0.2184) loss_zs_kd 0.0130 (0.0333) loss_oracle 0.6989 (0.6656) kd_loss 0.7889 (0.8490) acc 93.7500 (92.1875) gate/entropy 1.0272 (1.0277) gate/usage_max 0.5169 (0.5162) gate/usage_min 0.2333 (0.2336) gate/usage_std 0.1300 (0.1295) teacher/entropy 0.0943 (0.0857) teacher/usage_max 0.7051 (0.6432) teacher/usage_min 0.1430 (0.1050) teacher/usage_std 0.2629 (0.2313) nleep/row_max_mean 1478.3289 (1480.3331) nleep/row_max_std 62.6021 (51.2980) nleep/row_min_mean 1458.7493 (1459.4000) lr 1.1253e-03 eta 0:08:09
epoch [25/50] batch [80/176] time 0.109 (0.105) data 0.000 (0.004) loss 1.5044 (1.4238) teacher_loss 0.2376 (0.2180) loss_zs_kd 0.0405 (0.0327) loss_oracle 0.7917 (0.6777) kd_loss 0.8507 (0.8506) acc 93.7500 (92.1875) gate/entropy 1.0274 (1.0276) gate/usage_max 0.5165 (0.5162) gate/usage_min 0.2335 (0.2336) gate/usage_std 0.1297 (0.1295) teacher/entropy 0.0718 (0.0858) teacher/usage_max 0.6557 (0.6409) teacher/usage_min 0.1521 (0.1063) teacher/usage_std 0.2285 (0.2296) nleep/row_max_mean 1480.2346 (1478.8334) nleep/row_max_std 44.4745 (51.8698) nleep/row_min_mean 1459.5758 (1457.9617) lr 1.1253e-03 eta 0:07:53
epoch [25/50] batch [100/176] time 0.093 (0.103) data 0.000 (0.003) loss 1.5668 (1.4216) teacher_loss 0.2682 (0.2162) loss_zs_kd 0.0505 (0.0331) loss_oracle 0.6902 (0.6857) kd_loss 0.9282 (0.8461) acc 93.7500 (92.4375) gate/entropy 1.0280 (1.0276) gate/usage_max 0.5158 (0.5162) gate/usage_min 0.2338 (0.2336) gate/usage_std 0.1292 (0.1295) teacher/entropy 0.0631 (0.0871) teacher/usage_max 0.5719 (0.6450) teacher/usage_min 0.1007 (0.1047) teacher/usage_std 0.1924 (0.2324) nleep/row_max_mean 1478.5283 (1478.6988) nleep/row_max_std 41.4734 (51.4870) nleep/row_min_mean 1453.3625 (1457.6289) lr 1.1253e-03 eta 0:07:42
epoch [25/50] batch [120/176] time 0.101 (0.102) data 0.000 (0.003) loss 1.4273 (1.4298) teacher_loss 0.1381 (0.2219) loss_zs_kd 0.0172 (0.0338) loss_oracle 0.7062 (0.6901) kd_loss 0.9275 (0.8459) acc 93.7500 (92.1094) gate/entropy 1.0279 (1.0276) gate/usage_max 0.5159 (0.5163) gate/usage_min 0.2337 (0.2336) gate/usage_std 0.1293 (0.1295) teacher/entropy 0.0309 (0.0868) teacher/usage_max 0.6175 (0.6457) teacher/usage_min 0.0387 (0.1033) teacher/usage_std 0.2364 (0.2333) nleep/row_max_mean 1472.7275 (1477.8986) nleep/row_max_std 53.9909 (51.5827) nleep/row_min_mean 1450.5620 (1456.7975) lr 1.1253e-03 eta 0:07:36
epoch [25/50] batch [140/176] time 0.095 (0.102) data 0.000 (0.002) loss 1.4810 (1.4327) teacher_loss 0.2894 (0.2186) loss_zs_kd 0.0366 (0.0345) loss_oracle 0.7218 (0.6914) kd_loss 0.8124 (0.8511) acc 87.5000 (92.0759) gate/entropy 1.0275 (1.0276) gate/usage_max 0.5164 (0.5162) gate/usage_min 0.2336 (0.2336) gate/usage_std 0.1296 (0.1295) teacher/entropy 0.0814 (0.0854) teacher/usage_max 0.6969 (0.6408) teacher/usage_min 0.0898 (0.1041) teacher/usage_std 0.2620 (0.2306) nleep/row_max_mean 1479.2870 (1478.0728) nleep/row_max_std 59.0874 (51.2010) nleep/row_min_mean 1457.5234 (1456.7995) lr 1.1253e-03 eta 0:07:34
epoch [25/50] batch [160/176] time 0.103 (0.102) data 0.000 (0.002) loss 1.4119 (1.4258) teacher_loss 0.1289 (0.2139) loss_zs_kd 0.0411 (0.0354) loss_oracle 0.7046 (0.6908) kd_loss 0.9101 (0.8487) acc 93.7500 (92.3242) gate/entropy 1.0276 (1.0276) gate/usage_max 0.5163 (0.5162) gate/usage_min 0.2336 (0.2336) gate/usage_std 0.1296 (0.1295) teacher/entropy 0.0367 (0.0844) teacher/usage_max 0.6274 (0.6452) teacher/usage_min 0.1109 (0.1037) teacher/usage_std 0.2169 (0.2330) nleep/row_max_mean 1492.9812 (1478.6435) nleep/row_max_std 39.3476 (51.0459) nleep/row_min_mean 1469.9225 (1457.1802) lr 1.1253e-03 eta 0:07:30
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,169
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,717
* accuracy: 64.6%
* error: 35.4%
* macro_f1: 59.8%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [26/50] batch [20/176] time 0.087 (0.100) data 0.000 (0.014) loss 1.3909 (1.4489) teacher_loss 0.1893 (0.2050) loss_zs_kd 0.0130 (0.0383) loss_oracle 0.6501 (0.7042) kd_loss 0.8700 (0.8726) acc 90.6250 (91.8750) gate/entropy 1.0274 (1.0277) gate/usage_max 0.5166 (0.5162) gate/usage_min 0.2337 (0.2338) gate/usage_std 0.1297 (0.1295) teacher/entropy 0.0582 (0.0683) teacher/usage_max 0.6551 (0.6355) teacher/usage_min 0.0649 (0.0987) teacher/usage_std 0.2439 (0.2287) nleep/row_max_mean 1471.9531 (1476.7239) nleep/row_max_std 58.6643 (51.0377) nleep/row_min_mean 1449.5308 (1454.5891) lr 1.0628e-03 eta 0:07:17
epoch [26/50] batch [40/176] time 0.078 (0.088) data 0.000 (0.007) loss 1.4356 (1.4430) teacher_loss 0.1902 (0.2201) loss_zs_kd 0.0340 (0.0363) loss_oracle 0.6397 (0.6795) kd_loss 0.9086 (0.8650) acc 96.8750 (92.1094) gate/entropy 1.0277 (1.0276) gate/usage_max 0.5162 (0.5163) gate/usage_min 0.2339 (0.2338) gate/usage_std 0.1294 (0.1295) teacher/entropy 0.0344 (0.0737) teacher/usage_max 0.6332 (0.6408) teacher/usage_min 0.0940 (0.0904) teacher/usage_std 0.2243 (0.2348) nleep/row_max_mean 1488.8911 (1477.3473) nleep/row_max_std 44.9201 (52.8644) nleep/row_min_mean 1468.1149 (1455.3249) lr 1.0628e-03 eta 0:06:23
epoch [26/50] batch [60/176] time 0.083 (0.086) data 0.001 (0.005) loss 1.3810 (1.4464) teacher_loss 0.1925 (0.2247) loss_zs_kd 0.0408 (0.0331) loss_oracle 0.6358 (0.6672) kd_loss 0.8503 (0.8715) acc 96.8750 (91.6146) gate/entropy 1.0278 (1.0277) gate/usage_max 0.5161 (0.5162) gate/usage_min 0.2341 (0.2339) gate/usage_std 0.1294 (0.1295) teacher/entropy 0.1123 (0.0751) teacher/usage_max 0.6073 (0.6299) teacher/usage_min 0.1227 (0.0928) teacher/usage_std 0.2028 (0.2292) nleep/row_max_mean 1471.9188 (1476.7724) nleep/row_max_std 55.2295 (52.9443) nleep/row_min_mean 1452.2063 (1454.9348) lr 1.0628e-03 eta 0:06:12
epoch [26/50] batch [80/176] time 0.092 (0.086) data 0.000 (0.004) loss 1.6149 (1.4463) teacher_loss 0.2724 (0.2210) loss_zs_kd 0.0476 (0.0334) loss_oracle 0.7619 (0.6665) kd_loss 0.9379 (0.8753) acc 87.5000 (91.7969) gate/entropy 1.0279 (1.0277) gate/usage_max 0.5159 (0.5162) gate/usage_min 0.2344 (0.2340) gate/usage_std 0.1293 (0.1295) teacher/entropy 0.1453 (0.0786) teacher/usage_max 0.4489 (0.6203) teacher/usage_min 0.1731 (0.0905) teacher/usage_std 0.1169 (0.2247) nleep/row_max_mean 1477.4871 (1476.7167) nleep/row_max_std 49.9589 (53.0525) nleep/row_min_mean 1457.7488 (1454.9228) lr 1.0628e-03 eta 0:06:09
epoch [26/50] batch [100/176] time 0.074 (0.086) data 0.000 (0.003) loss 1.1778 (1.4428) teacher_loss 0.1027 (0.2201) loss_zs_kd 0.0274 (0.0333) loss_oracle 0.5300 (0.6635) kd_loss 0.7964 (0.8743) acc 100.0000 (91.9688) gate/entropy 1.0272 (1.0277) gate/usage_max 0.5169 (0.5162) gate/usage_min 0.2343 (0.2341) gate/usage_std 0.1299 (0.1295) teacher/entropy 0.0794 (0.0800) teacher/usage_max 0.7227 (0.6216) teacher/usage_min 0.0434 (0.0846) teacher/usage_std 0.2861 (0.2275) nleep/row_max_mean 1473.4124 (1476.5773) nleep/row_max_std 58.0779 (53.6836) nleep/row_min_mean 1449.0596 (1454.5259) lr 1.0628e-03 eta 0:06:07
epoch [26/50] batch [120/176] time 0.088 (0.086) data 0.000 (0.002) loss 1.2440 (1.4463) teacher_loss 0.1218 (0.2206) loss_zs_kd 0.0427 (0.0338) loss_oracle 0.5395 (0.6630) kd_loss 0.8311 (0.8774) acc 100.0000 (91.9531) gate/entropy 1.0277 (1.0277) gate/usage_max 0.5163 (0.5162) gate/usage_min 0.2348 (0.2342) gate/usage_std 0.1295 (0.1295) teacher/entropy 0.0457 (0.0798) teacher/usage_max 0.7169 (0.6178) teacher/usage_min 0.0950 (0.0805) teacher/usage_std 0.2739 (0.2276) nleep/row_max_mean 1483.0247 (1477.6873) nleep/row_max_std 52.5993 (53.2134) nleep/row_min_mean 1459.6044 (1455.4052) lr 1.0628e-03 eta 0:06:06
epoch [26/50] batch [140/176] time 0.080 (0.085) data 0.000 (0.002) loss 1.5022 (1.4459) teacher_loss 0.2439 (0.2188) loss_zs_kd 0.0315 (0.0347) loss_oracle 0.6041 (0.6612) kd_loss 0.9405 (0.8791) acc 90.6250 (92.0982) gate/entropy 1.0284 (1.0277) gate/usage_max 0.5154 (0.5162) gate/usage_min 0.2355 (0.2343) gate/usage_std 0.1289 (0.1294) teacher/entropy 0.0487 (0.0790) teacher/usage_max 0.5804 (0.6166) teacher/usage_min 0.0001 (0.0761) teacher/usage_std 0.2446 (0.2284) nleep/row_max_mean 1469.9309 (1477.6072) nleep/row_max_std 48.7631 (53.0771) nleep/row_min_mean 1445.0354 (1455.1990) lr 1.0628e-03 eta 0:06:03
epoch [26/50] batch [160/176] time 0.094 (0.086) data 0.000 (0.002) loss 1.4012 (1.4475) teacher_loss 0.2164 (0.2234) loss_zs_kd 0.0253 (0.0343) loss_oracle 0.6294 (0.6606) kd_loss 0.8575 (0.8767) acc 93.7500 (91.9727) gate/entropy 1.0279 (1.0277) gate/usage_max 0.5160 (0.5162) gate/usage_min 0.2354 (0.2344) gate/usage_std 0.1293 (0.1294) teacher/entropy 0.0662 (0.0779) teacher/usage_max 0.6601 (0.6210) teacher/usage_min 0.0421 (0.0726) teacher/usage_std 0.2536 (0.2312) nleep/row_max_mean 1478.3672 (1477.9618) nleep/row_max_std 51.5119 (53.0404) nleep/row_min_mean 1453.9524 (1455.4651) lr 1.0628e-03 eta 0:06:03
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,155
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 90.8%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,825
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 62.4%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [27/50] batch [20/176] time 0.081 (0.099) data 0.000 (0.014) loss 1.4832 (1.4415) teacher_loss 0.1651 (0.2022) loss_zs_kd 0.0202 (0.0331) loss_oracle 0.6716 (0.6705) kd_loss 0.9721 (0.8875) acc 93.7500 (92.0312) gate/entropy 1.0277 (1.0277) gate/usage_max 0.5163 (0.5163) gate/usage_min 0.2358 (0.2357) gate/usage_std 0.1295 (0.1295) teacher/entropy 0.0774 (0.0938) teacher/usage_max 0.4901 (0.5904) teacher/usage_min 0.1674 (0.0899) teacher/usage_std 0.1319 (0.2089) nleep/row_max_mean 1484.4965 (1479.7305) nleep/row_max_std 43.5089 (51.5184) nleep/row_min_mean 1461.8315 (1456.5816) lr 1.0000e-03 eta 0:06:55
epoch [27/50] batch [40/176] time 0.097 (0.096) data 0.000 (0.007) loss 1.5849 (1.4495) teacher_loss 0.3413 (0.2191) loss_zs_kd 0.0741 (0.0394) loss_oracle 0.6716 (0.6681) kd_loss 0.8708 (0.8766) acc 90.6250 (92.2656) gate/entropy 1.0275 (1.0276) gate/usage_max 0.5166 (0.5164) gate/usage_min 0.2359 (0.2357) gate/usage_std 0.1297 (0.1296) teacher/entropy 0.0835 (0.0804) teacher/usage_max 0.6228 (0.6189) teacher/usage_min 0.0065 (0.0691) teacher/usage_std 0.2530 (0.2293) nleep/row_max_mean 1479.9634 (1479.6352) nleep/row_max_std 50.1798 (52.1075) nleep/row_min_mean 1457.9448 (1456.5175) lr 1.0000e-03 eta 0:06:41
epoch [27/50] batch [60/176] time 0.092 (0.093) data 0.001 (0.005) loss 1.4160 (1.4435) teacher_loss 0.1730 (0.2122) loss_zs_kd 0.0468 (0.0405) loss_oracle 0.6711 (0.6699) kd_loss 0.8841 (0.8761) acc 93.7500 (92.2917) gate/entropy 1.0273 (1.0276) gate/usage_max 0.5169 (0.5165) gate/usage_min 0.2359 (0.2358) gate/usage_std 0.1299 (0.1296) teacher/entropy 0.0834 (0.0774) teacher/usage_max 0.6002 (0.6220) teacher/usage_min 0.0714 (0.0654) teacher/usage_std 0.2159 (0.2322) nleep/row_max_mean 1477.6412 (1478.7979) nleep/row_max_std 55.3613 (53.7110) nleep/row_min_mean 1456.9041 (1455.8971) lr 1.0000e-03 eta 0:06:26
epoch [27/50] batch [80/176] time 0.098 (0.093) data 0.000 (0.004) loss 1.6184 (1.4559) teacher_loss 0.2873 (0.2181) loss_zs_kd 0.0372 (0.0394) loss_oracle 0.7373 (0.6758) kd_loss 0.9438 (0.8802) acc 96.8750 (92.3438) gate/entropy 1.0270 (1.0276) gate/usage_max 0.5173 (0.5165) gate/usage_min 0.2360 (0.2359) gate/usage_std 0.1301 (0.1296) teacher/entropy 0.0888 (0.0781) teacher/usage_max 0.5196 (0.6148) teacher/usage_min 0.0331 (0.0687) teacher/usage_std 0.2143 (0.2285) nleep/row_max_mean 1468.1523 (1479.1952) nleep/row_max_std 65.0113 (53.6570) nleep/row_min_mean 1448.0808 (1456.3545) lr 1.0000e-03 eta 0:06:24
epoch [27/50] batch [100/176] time 0.095 (0.092) data 0.000 (0.003) loss 1.4384 (1.4471) teacher_loss 0.2530 (0.2154) loss_zs_kd 0.0209 (0.0388) loss_oracle 0.6822 (0.6666) kd_loss 0.8338 (0.8790) acc 90.6250 (92.1875) gate/entropy 1.0274 (1.0276) gate/usage_max 0.5167 (0.5165) gate/usage_min 0.2365 (0.2360) gate/usage_std 0.1297 (0.1296) teacher/entropy 0.0996 (0.0745) teacher/usage_max 0.6426 (0.6206) teacher/usage_min 0.0546 (0.0648) teacher/usage_std 0.2410 (0.2330) nleep/row_max_mean 1477.9076 (1479.2657) nleep/row_max_std 56.7204 (52.9290) nleep/row_min_mean 1457.7910 (1456.4383) lr 1.0000e-03 eta 0:06:19
epoch [27/50] batch [120/176] time 0.093 (0.091) data 0.000 (0.002) loss 1.4390 (1.4446) teacher_loss 0.3364 (0.2208) loss_zs_kd 0.0408 (0.0386) loss_oracle 0.5923 (0.6579) kd_loss 0.7861 (0.8756) acc 87.5000 (91.9792) gate/entropy 1.0272 (1.0276) gate/usage_max 0.5171 (0.5165) gate/usage_min 0.2366 (0.2361) gate/usage_std 0.1300 (0.1296) teacher/entropy 0.0581 (0.0743) teacher/usage_max 0.7605 (0.6247) teacher/usage_min 0.0162 (0.0651) teacher/usage_std 0.3137 (0.2348) nleep/row_max_mean 1475.4644 (1479.3688) nleep/row_max_std 58.0830 (52.4727) nleep/row_min_mean 1453.4568 (1456.5293) lr 1.0000e-03 eta 0:06:15
epoch [27/50] batch [140/176] time 0.085 (0.090) data 0.000 (0.002) loss 1.6792 (1.4423) teacher_loss 0.4072 (0.2226) loss_zs_kd 0.0609 (0.0385) loss_oracle 0.6073 (0.6501) kd_loss 0.9379 (0.8754) acc 90.6250 (92.0312) gate/entropy 1.0274 (1.0276) gate/usage_max 0.5168 (0.5166) gate/usage_min 0.2370 (0.2362) gate/usage_std 0.1298 (0.1296) teacher/entropy 0.0311 (0.0723) teacher/usage_max 0.5953 (0.6271) teacher/usage_min 0.0976 (0.0658) teacher/usage_std 0.2040 (0.2356) nleep/row_max_mean 1476.0249 (1479.5768) nleep/row_max_std 62.1388 (52.7304) nleep/row_min_mean 1452.7482 (1456.6113) lr 1.0000e-03 eta 0:06:09
epoch [27/50] batch [160/176] time 0.088 (0.090) data 0.000 (0.002) loss 1.4060 (1.4372) teacher_loss 0.1496 (0.2194) loss_zs_kd 0.0228 (0.0385) loss_oracle 0.6707 (0.6467) kd_loss 0.9096 (0.8752) acc 96.8750 (92.0703) gate/entropy 1.0267 (1.0275) gate/usage_max 0.5177 (0.5166) gate/usage_min 0.2367 (0.2363) gate/usage_std 0.1304 (0.1297) teacher/entropy 0.0821 (0.0700) teacher/usage_max 0.5638 (0.6301) teacher/usage_min 0.1623 (0.0642) teacher/usage_std 0.1692 (0.2375) nleep/row_max_mean 1481.2292 (1479.6801) nleep/row_max_std 55.0023 (52.6603) nleep/row_min_mean 1457.7710 (1456.6259) lr 1.0000e-03 eta 0:06:04
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,167
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 91.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,796
* accuracy: 67.6%
* error: 32.4%
* macro_f1: 61.8%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [28/50] batch [20/176] time 0.087 (0.107) data 0.000 (0.018) loss 1.3960 (1.4109) teacher_loss 0.1668 (0.2040) loss_zs_kd 0.0294 (0.0361) loss_oracle 0.6341 (0.6207) kd_loss 0.8976 (0.8785) acc 96.8750 (91.4062) gate/entropy 1.0273 (1.0269) gate/usage_max 0.5170 (0.5175) gate/usage_min 0.2375 (0.2371) gate/usage_std 0.1299 (0.1303) teacher/entropy 0.0975 (0.0501) teacher/usage_max 0.5662 (0.6490) teacher/usage_min 0.0101 (0.0353) teacher/usage_std 0.2358 (0.2575) nleep/row_max_mean 1464.0302 (1482.8234) nleep/row_max_std 59.3555 (53.0445) nleep/row_min_mean 1444.8567 (1458.0724) lr 9.3721e-04 eta 0:07:10
epoch [28/50] batch [40/176] time 0.092 (0.099) data 0.000 (0.009) loss 1.3409 (1.4344) teacher_loss 0.0797 (0.2111) loss_zs_kd 0.0465 (0.0356) loss_oracle 0.6178 (0.6501) kd_loss 0.9291 (0.8804) acc 100.0000 (92.1875) gate/entropy 1.0265 (1.0268) gate/usage_max 0.5180 (0.5176) gate/usage_min 0.2372 (0.2372) gate/usage_std 0.1306 (0.1303) teacher/entropy 0.0736 (0.0594) teacher/usage_max 0.5520 (0.6342) teacher/usage_min 0.1023 (0.0467) teacher/usage_std 0.1838 (0.2452) nleep/row_max_mean 1474.7842 (1479.2633) nleep/row_max_std 55.6421 (55.3098) nleep/row_min_mean 1450.5610 (1454.7785) lr 9.3721e-04 eta 0:06:35
epoch [28/50] batch [60/176] time 0.089 (0.096) data 0.001 (0.006) loss 1.3379 (1.4327) teacher_loss 0.1437 (0.2162) loss_zs_kd 0.0200 (0.0355) loss_oracle 0.6177 (0.6365) kd_loss 0.8753 (0.8805) acc 93.7500 (91.8229) gate/entropy 1.0264 (1.0268) gate/usage_max 0.5182 (0.5177) gate/usage_min 0.2375 (0.2373) gate/usage_std 0.1307 (0.1304) teacher/entropy 0.0176 (0.0541) teacher/usage_max 0.6949 (0.6409) teacher/usage_min 0.0001 (0.0413) teacher/usage_std 0.2843 (0.2505) nleep/row_max_mean 1494.5012 (1481.0178) nleep/row_max_std 49.0103 (53.5075) nleep/row_min_mean 1465.9789 (1456.3084) lr 9.3721e-04 eta 0:06:24
epoch [28/50] batch [80/176] time 0.112 (0.098) data 0.000 (0.005) loss 1.6037 (1.4233) teacher_loss 0.3815 (0.2114) loss_zs_kd 0.0456 (0.0358) loss_oracle 0.6455 (0.6376) kd_loss 0.8766 (0.8752) acc 81.2500 (92.0312) gate/entropy 1.0260 (1.0267) gate/usage_max 0.5187 (0.5177) gate/usage_min 0.2375 (0.2374) gate/usage_std 0.1311 (0.1304) teacher/entropy 0.0764 (0.0541) teacher/usage_max 0.6177 (0.6475) teacher/usage_min 0.0387 (0.0388) teacher/usage_std 0.2365 (0.2542) nleep/row_max_mean 1455.6215 (1481.2828) nleep/row_max_std 67.6398 (53.4071) nleep/row_min_mean 1433.1106 (1456.3640) lr 9.3721e-04 eta 0:06:30
epoch [28/50] batch [100/176] time 0.090 (0.098) data 0.000 (0.004) loss 1.3048 (1.4195) teacher_loss 0.1673 (0.2134) loss_zs_kd 0.0362 (0.0362) loss_oracle 0.5562 (0.6312) kd_loss 0.8412 (0.8723) acc 93.7500 (92.0625) gate/entropy 1.0262 (1.0266) gate/usage_max 0.5184 (0.5179) gate/usage_min 0.2380 (0.2375) gate/usage_std 0.1309 (0.1305) teacher/entropy 0.0565 (0.0528) teacher/usage_max 0.6874 (0.6527) teacher/usage_min 0.0162 (0.0353) teacher/usage_std 0.2752 (0.2576) nleep/row_max_mean 1472.4800 (1481.4195) nleep/row_max_std 58.2341 (53.7106) nleep/row_min_mean 1446.1826 (1456.3132) lr 9.3721e-04 eta 0:06:28
epoch [28/50] batch [120/176] time 0.098 (0.098) data 0.000 (0.003) loss 1.3806 (1.4240) teacher_loss 0.1401 (0.2147) loss_zs_kd 0.0369 (0.0373) loss_oracle 0.6363 (0.6349) kd_loss 0.9040 (0.8732) acc 93.7500 (92.0052) gate/entropy 1.0267 (1.0266) gate/usage_max 0.5178 (0.5180) gate/usage_min 0.2385 (0.2376) gate/usage_std 0.1305 (0.1306) teacher/entropy 0.1100 (0.0543) teacher/usage_max 0.5366 (0.6500) teacher/usage_min 0.0417 (0.0388) teacher/usage_std 0.2115 (0.2554) nleep/row_max_mean 1482.5093 (1481.1861) nleep/row_max_std 48.6747 (53.6066) nleep/row_min_mean 1459.4263 (1456.1001) lr 9.3721e-04 eta 0:06:23
epoch [28/50] batch [140/176] time 0.108 (0.098) data 0.000 (0.003) loss 1.7615 (1.4255) teacher_loss 0.4423 (0.2172) loss_zs_kd 0.0302 (0.0374) loss_oracle 0.7365 (0.6336) kd_loss 0.9358 (0.8728) acc 81.2500 (92.0759) gate/entropy 1.0261 (1.0265) gate/usage_max 0.5186 (0.5180) gate/usage_min 0.2383 (0.2377) gate/usage_std 0.1310 (0.1306) teacher/entropy 0.0452 (0.0527) teacher/usage_max 0.5771 (0.6524) teacher/usage_min 0.0525 (0.0375) teacher/usage_std 0.2158 (0.2575) nleep/row_max_mean 1485.4736 (1481.1325) nleep/row_max_std 50.4204 (53.7118) nleep/row_min_mean 1461.3778 (1455.9706) lr 9.3721e-04 eta 0:06:22
epoch [28/50] batch [160/176] time 0.089 (0.099) data 0.000 (0.002) loss 1.4695 (1.4281) teacher_loss 0.3495 (0.2188) loss_zs_kd 0.0310 (0.0378) loss_oracle 0.6315 (0.6356) kd_loss 0.7888 (0.8726) acc 84.3750 (92.0117) gate/entropy 1.0255 (1.0264) gate/usage_max 0.5194 (0.5181) gate/usage_min 0.2382 (0.2378) gate/usage_std 0.1316 (0.1307) teacher/entropy 0.0352 (0.0516) teacher/usage_max 0.7813 (0.6543) teacher/usage_min 0.0267 (0.0383) teacher/usage_std 0.3238 (0.2580) nleep/row_max_mean 1490.7483 (1481.1319) nleep/row_max_std 47.4335 (53.6620) nleep/row_min_mean 1463.0492 (1455.9015) lr 9.3721e-04 eta 0:06:22
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,159
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 90.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,798
* accuracy: 67.7%
* error: 32.3%
* macro_f1: 62.0%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [29/50] batch [20/176] time 0.089 (0.111) data 0.000 (0.016) loss 1.4138 (1.3574) teacher_loss 0.2662 (0.2064) loss_zs_kd 0.0569 (0.0399) loss_oracle 0.6357 (0.5971) kd_loss 0.8014 (0.8324) acc 87.5000 (92.1875) gate/entropy 1.0253 (1.0256) gate/usage_max 0.5197 (0.5193) gate/usage_min 0.2385 (0.2385) gate/usage_std 0.1318 (0.1315) teacher/entropy 0.0215 (0.0414) teacher/usage_max 0.7812 (0.7152) teacher/usage_min 0.0124 (0.0389) teacher/usage_std 0.3265 (0.2856) nleep/row_max_mean 1493.3557 (1485.2604) nleep/row_max_std 55.3041 (52.2028) nleep/row_min_mean 1465.6133 (1458.6663) lr 8.7467e-04 eta 0:07:08
epoch [29/50] batch [40/176] time 0.099 (0.102) data 0.000 (0.008) loss 1.2244 (1.3886) teacher_loss 0.1306 (0.2092) loss_zs_kd 0.0302 (0.0397) loss_oracle 0.5834 (0.6123) kd_loss 0.7870 (0.8534) acc 96.8750 (92.4219) gate/entropy 1.0245 (1.0254) gate/usage_max 0.5206 (0.5195) gate/usage_min 0.2381 (0.2385) gate/usage_std 0.1325 (0.1316) teacher/entropy 0.0331 (0.0377) teacher/usage_max 0.7837 (0.6927) teacher/usage_min 0.0358 (0.0391) teacher/usage_std 0.3239 (0.2760) nleep/row_max_mean 1467.8481 (1481.2979) nleep/row_max_std 70.8546 (56.3643) nleep/row_min_mean 1445.1281 (1455.3433) lr 8.7467e-04 eta 0:06:32
epoch [29/50] batch [60/176] time 0.088 (0.101) data 0.001 (0.006) loss 1.4676 (1.3910) teacher_loss 0.3445 (0.2119) loss_zs_kd 0.0437 (0.0410) loss_oracle 0.5831 (0.6144) kd_loss 0.8096 (0.8514) acc 87.5000 (92.2396) gate/entropy 1.0251 (1.0253) gate/usage_max 0.5199 (0.5196) gate/usage_min 0.2387 (0.2385) gate/usage_std 0.1319 (0.1317) teacher/entropy 0.0537 (0.0361) teacher/usage_max 0.7283 (0.6971) teacher/usage_min 0.0377 (0.0384) teacher/usage_std 0.2906 (0.2776) nleep/row_max_mean 1478.8105 (1481.9400) nleep/row_max_std 60.6158 (56.4330) nleep/row_min_mean 1451.5217 (1455.9148) lr 8.7467e-04 eta 0:06:24
epoch [29/50] batch [80/176] time 0.101 (0.100) data 0.000 (0.004) loss 1.3677 (1.3989) teacher_loss 0.2673 (0.2146) loss_zs_kd 0.0385 (0.0394) loss_oracle 0.5947 (0.6223) kd_loss 0.7837 (0.8534) acc 90.6250 (92.0312) gate/entropy 1.0247 (1.0252) gate/usage_max 0.5205 (0.5198) gate/usage_min 0.2386 (0.2386) gate/usage_std 0.1323 (0.1318) teacher/entropy 0.0390 (0.0379) teacher/usage_max 0.7800 (0.6919) teacher/usage_min 0.0476 (0.0397) teacher/usage_std 0.3199 (0.2747) nleep/row_max_mean 1483.0939 (1480.8667) nleep/row_max_std 43.0904 (56.0857) nleep/row_min_mean 1455.4805 (1454.9492) lr 8.7467e-04 eta 0:06:21
epoch [29/50] batch [100/176] time 0.089 (0.099) data 0.000 (0.003) loss 1.3393 (1.4093) teacher_loss 0.1472 (0.2179) loss_zs_kd 0.0552 (0.0385) loss_oracle 0.6340 (0.6297) kd_loss 0.8476 (0.8573) acc 93.7500 (91.9688) gate/entropy 1.0248 (1.0251) gate/usage_max 0.5204 (0.5199) gate/usage_min 0.2389 (0.2386) gate/usage_std 0.1322 (0.1319) teacher/entropy 0.0279 (0.0371) teacher/usage_max 0.7123 (0.6877) teacher/usage_min 0.0335 (0.0423) teacher/usage_std 0.2827 (0.2715) nleep/row_max_mean 1472.8594 (1481.4954) nleep/row_max_std 54.1439 (55.6533) nleep/row_min_mean 1449.0491 (1455.5439) lr 8.7467e-04 eta 0:06:13
epoch [29/50] batch [120/176] time 0.091 (0.098) data 0.000 (0.003) loss 1.5131 (1.4080) teacher_loss 0.3117 (0.2132) loss_zs_kd 0.0541 (0.0391) loss_oracle 0.6937 (0.6348) kd_loss 0.8275 (0.8578) acc 90.6250 (92.2656) gate/entropy 1.0246 (1.0250) gate/usage_max 0.5206 (0.5200) gate/usage_min 0.2389 (0.2386) gate/usage_std 0.1324 (0.1320) teacher/entropy 0.0449 (0.0392) teacher/usage_max 0.7159 (0.6846) teacher/usage_min 0.0395 (0.0454) teacher/usage_std 0.2832 (0.2694) nleep/row_max_mean 1484.5514 (1481.7867) nleep/row_max_std 48.6507 (55.0941) nleep/row_min_mean 1460.8660 (1455.7646) lr 8.7467e-04 eta 0:06:09
epoch [29/50] batch [140/176] time 0.102 (0.099) data 0.000 (0.003) loss 1.4486 (1.4156) teacher_loss 0.3788 (0.2174) loss_zs_kd 0.0245 (0.0388) loss_oracle 0.5187 (0.6380) kd_loss 0.7983 (0.8598) acc 87.5000 (91.9866) gate/entropy 1.0238 (1.0249) gate/usage_max 0.5216 (0.5201) gate/usage_min 0.2386 (0.2387) gate/usage_std 0.1331 (0.1321) teacher/entropy 0.0399 (0.0382) teacher/usage_max 0.7581 (0.6830) teacher/usage_min 0.0041 (0.0459) teacher/usage_std 0.3151 (0.2686) nleep/row_max_mean 1475.6931 (1481.9003) nleep/row_max_std 62.1374 (54.5630) nleep/row_min_mean 1450.1931 (1455.8202) lr 8.7467e-04 eta 0:06:08
epoch [29/50] batch [160/176] time 0.099 (0.099) data 0.000 (0.002) loss 1.2933 (1.4153) teacher_loss 0.1671 (0.2160) loss_zs_kd 0.0292 (0.0385) loss_oracle 0.5538 (0.6385) kd_loss 0.8347 (0.8609) acc 90.6250 (92.0312) gate/entropy 1.0245 (1.0249) gate/usage_max 0.5207 (0.5202) gate/usage_min 0.2392 (0.2387) gate/usage_std 0.1325 (0.1322) teacher/entropy 0.0412 (0.0379) teacher/usage_max 0.7111 (0.6822) teacher/usage_min 0.0446 (0.0451) teacher/usage_std 0.2793 (0.2686) nleep/row_max_mean 1479.5444 (1482.1279) nleep/row_max_std 52.4305 (53.9491) nleep/row_min_mean 1456.4893 (1455.9881) lr 8.7467e-04 eta 0:06:05
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,164
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,760
* accuracy: 66.3%
* error: 33.7%
* macro_f1: 60.8%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [30/50] batch [20/176] time 0.089 (0.109) data 0.000 (0.014) loss 1.3394 (1.3952) teacher_loss 0.1363 (0.2131) loss_zs_kd 0.0480 (0.0370) loss_oracle 0.6276 (0.6088) kd_loss 0.8653 (0.8592) acc 93.7500 (93.1250) gate/entropy 1.0237 (1.0237) gate/usage_max 0.5218 (0.5217) gate/usage_min 0.2390 (0.2390) gate/usage_std 0.1332 (0.1332) teacher/entropy 0.0246 (0.0260) teacher/usage_max 0.6894 (0.6963) teacher/usage_min 0.0686 (0.0352) teacher/usage_std 0.2615 (0.2781) nleep/row_max_mean 1490.7229 (1486.3604) nleep/row_max_std 54.7379 (52.6551) nleep/row_min_mean 1460.3142 (1459.4123) lr 8.1262e-04 eta 0:06:41
epoch [30/50] batch [40/176] time 0.108 (0.110) data 0.000 (0.007) loss 1.4436 (1.3900) teacher_loss 0.4443 (0.2123) loss_zs_kd 0.0276 (0.0360) loss_oracle 0.5049 (0.6172) kd_loss 0.7331 (0.8510) acc 81.2500 (92.8125) gate/entropy 1.0225 (1.0237) gate/usage_max 0.5232 (0.5217) gate/usage_min 0.2382 (0.2390) gate/usage_std 0.1343 (0.1332) teacher/entropy 0.0168 (0.0348) teacher/usage_max 0.8681 (0.6954) teacher/usage_min 0.0313 (0.0435) teacher/usage_std 0.3792 (0.2764) nleep/row_max_mean 1510.5378 (1484.7730) nleep/row_max_std 42.9580 (52.9024) nleep/row_min_mean 1476.5723 (1457.7019) lr 8.1262e-04 eta 0:06:41
epoch [30/50] batch [60/176] time 0.093 (0.107) data 0.001 (0.005) loss 1.4101 (1.3957) teacher_loss 0.2684 (0.2124) loss_zs_kd 0.0253 (0.0364) loss_oracle 0.5876 (0.6244) kd_loss 0.8353 (0.8529) acc 87.5000 (92.5521) gate/entropy 1.0234 (1.0236) gate/usage_max 0.5221 (0.5218) gate/usage_min 0.2387 (0.2390) gate/usage_std 0.1335 (0.1333) teacher/entropy 0.0090 (0.0356) teacher/usage_max 0.7485 (0.6919) teacher/usage_min 0.0313 (0.0442) teacher/usage_std 0.3035 (0.2740) nleep/row_max_mean 1477.9792 (1483.0279) nleep/row_max_std 53.7682 (54.2985) nleep/row_min_mean 1450.2007 (1456.2041) lr 8.1262e-04 eta 0:06:28
epoch [30/50] batch [80/176] time 0.099 (0.105) data 0.000 (0.004) loss 1.2488 (1.3990) teacher_loss 0.1577 (0.2190) loss_zs_kd 0.0384 (0.0365) loss_oracle 0.5749 (0.6261) kd_loss 0.7845 (0.8487) acc 93.7500 (92.5781) gate/entropy 1.0226 (1.0235) gate/usage_max 0.5231 (0.5220) gate/usage_min 0.2380 (0.2389) gate/usage_std 0.1342 (0.1334) teacher/entropy 0.0397 (0.0356) teacher/usage_max 0.7731 (0.6970) teacher/usage_min 0.0088 (0.0416) teacher/usage_std 0.3225 (0.2767) nleep/row_max_mean 1485.4471 (1482.4863) nleep/row_max_std 49.8609 (54.6007) nleep/row_min_mean 1459.2338 (1455.7650) lr 8.1262e-04 eta 0:06:18
epoch [30/50] batch [100/176] time 0.094 (0.103) data 0.000 (0.003) loss 1.4480 (1.3970) teacher_loss 0.2655 (0.2200) loss_zs_kd 0.0337 (0.0367) loss_oracle 0.6678 (0.6313) kd_loss 0.8317 (0.8429) acc 84.3750 (92.5938) gate/entropy 1.0228 (1.0234) gate/usage_max 0.5229 (0.5221) gate/usage_min 0.2381 (0.2387) gate/usage_std 0.1340 (0.1335) teacher/entropy 0.0605 (0.0374) teacher/usage_max 0.6854 (0.7020) teacher/usage_min 0.0509 (0.0389) teacher/usage_std 0.2637 (0.2802) nleep/row_max_mean 1498.3551 (1482.3489) nleep/row_max_std 48.7118 (54.5774) nleep/row_min_mean 1472.0466 (1455.8319) lr 8.1262e-04 eta 0:06:10
epoch [30/50] batch [120/176] time 0.099 (0.102) data 0.000 (0.003) loss 1.4889 (1.3974) teacher_loss 0.2658 (0.2199) loss_zs_kd 0.0408 (0.0372) loss_oracle 0.7815 (0.6361) kd_loss 0.8120 (0.8409) acc 90.6250 (92.5521) gate/entropy 1.0234 (1.0233) gate/usage_max 0.5221 (0.5222) gate/usage_min 0.2383 (0.2386) gate/usage_std 0.1335 (0.1336) teacher/entropy 0.1427 (0.0385) teacher/usage_max 0.6065 (0.7031) teacher/usage_min 0.0361 (0.0379) teacher/usage_std 0.2335 (0.2809) nleep/row_max_mean 1476.8094 (1482.3236) nleep/row_max_std 51.9373 (53.9550) nleep/row_min_mean 1454.0664 (1455.8764) lr 8.1262e-04 eta 0:06:04
epoch [30/50] batch [140/176] time 0.103 (0.101) data 0.000 (0.002) loss 1.4106 (1.3928) teacher_loss 0.2428 (0.2212) loss_zs_kd 0.0328 (0.0367) loss_oracle 0.6746 (0.6326) kd_loss 0.8140 (0.8369) acc 93.7500 (92.4777) gate/entropy 1.0226 (1.0232) gate/usage_max 0.5232 (0.5223) gate/usage_min 0.2377 (0.2385) gate/usage_std 0.1342 (0.1337) teacher/entropy 0.0720 (0.0393) teacher/usage_max 0.6947 (0.7070) teacher/usage_min 0.0390 (0.0383) teacher/usage_std 0.2719 (0.2828) nleep/row_max_mean 1475.2205 (1482.4024) nleep/row_max_std 52.9426 (53.5102) nleep/row_min_mean 1452.3716 (1455.9422) lr 8.1262e-04 eta 0:06:00
epoch [30/50] batch [160/176] time 0.099 (0.100) data 0.000 (0.002) loss 1.3218 (1.3942) teacher_loss 0.2490 (0.2250) loss_zs_kd 0.0276 (0.0362) loss_oracle 0.5715 (0.6304) kd_loss 0.7732 (0.8359) acc 87.5000 (92.4219) gate/entropy 1.0218 (1.0231) gate/usage_max 0.5241 (0.5225) gate/usage_min 0.2371 (0.2384) gate/usage_std 0.1349 (0.1337) teacher/entropy 0.0452 (0.0397) teacher/usage_max 0.7791 (0.7076) teacher/usage_min 0.0336 (0.0383) teacher/usage_std 0.3214 (0.2830) nleep/row_max_mean 1499.8979 (1482.3643) nleep/row_max_std 43.3625 (53.0612) nleep/row_min_mean 1474.3699 (1455.9291) lr 8.1262e-04 eta 0:05:54
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,171
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,636
* accuracy: 61.6%
* error: 38.4%
* macro_f1: 57.5%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [31/50] batch [20/176] time 0.087 (0.102) data 0.000 (0.013) loss 1.2367 (1.3970) teacher_loss 0.1596 (0.2600) loss_zs_kd 0.0442 (0.0325) loss_oracle 0.5508 (0.6198) kd_loss 0.7796 (0.8109) acc 96.8750 (91.2500) gate/entropy 1.0216 (1.0220) gate/usage_max 0.5244 (0.5240) gate/usage_min 0.2367 (0.2370) gate/usage_std 0.1351 (0.1348) teacher/entropy 0.0153 (0.0402) teacher/usage_max 0.8082 (0.7365) teacher/usage_min 0.0001 (0.0263) teacher/usage_std 0.3448 (0.3008) nleep/row_max_mean 1491.2399 (1483.8478) nleep/row_max_std 45.0733 (52.1988) nleep/row_min_mean 1465.1581 (1457.9171) lr 7.5131e-04 eta 0:05:58
epoch [31/50] batch [40/176] time 0.089 (0.097) data 0.000 (0.006) loss 1.5097 (1.3741) teacher_loss 0.4775 (0.2432) loss_zs_kd 0.0269 (0.0314) loss_oracle 0.5387 (0.6155) kd_loss 0.7494 (0.8075) acc 81.2500 (92.0312) gate/entropy 1.0219 (1.0219) gate/usage_max 0.5240 (0.5240) gate/usage_min 0.2368 (0.2369) gate/usage_std 0.1348 (0.1349) teacher/entropy 0.0627 (0.0470) teacher/usage_max 0.7867 (0.7321) teacher/usage_min 0.0309 (0.0357) teacher/usage_std 0.3265 (0.2961) nleep/row_max_mean 1477.8158 (1483.9845) nleep/row_max_std 50.0243 (51.4726) nleep/row_min_mean 1451.6416 (1458.3076) lr 7.5131e-04 eta 0:05:37
epoch [31/50] batch [60/176] time 0.092 (0.096) data 0.001 (0.004) loss 1.3658 (1.3919) teacher_loss 0.2974 (0.2495) loss_zs_kd 0.0649 (0.0313) loss_oracle 0.4531 (0.6190) kd_loss 0.8094 (0.8173) acc 84.3750 (91.3542) gate/entropy 1.0216 (1.0218) gate/usage_max 0.5244 (0.5241) gate/usage_min 0.2364 (0.2368) gate/usage_std 0.1351 (0.1349) teacher/entropy 0.0500 (0.0495) teacher/usage_max 0.7272 (0.7165) teacher/usage_min 0.0615 (0.0426) teacher/usage_std 0.2851 (0.2861) nleep/row_max_mean 1488.0098 (1482.5815) nleep/row_max_std 41.1665 (51.6297) nleep/row_min_mean 1464.9044 (1457.3666) lr 7.5131e-04 eta 0:05:31
epoch [31/50] batch [80/176] time 0.071 (0.099) data 0.000 (0.003) loss 1.1856 (1.3832) teacher_loss 0.1009 (0.2426) loss_zs_kd 0.0535 (0.0309) loss_oracle 0.5872 (0.6153) kd_loss 0.7644 (0.8174) acc 100.0000 (91.6406) gate/entropy 1.0215 (1.0218) gate/usage_max 0.5245 (0.5242) gate/usage_min 0.2363 (0.2367) gate/usage_std 0.1352 (0.1350) teacher/entropy 0.0553 (0.0522) teacher/usage_max 0.7749 (0.7128) teacher/usage_min 0.0009 (0.0459) teacher/usage_std 0.3252 (0.2833) nleep/row_max_mean 1482.2845 (1481.0557) nleep/row_max_std 50.3399 (51.8750) nleep/row_min_mean 1458.7693 (1456.2476) lr 7.5131e-04 eta 0:05:40
epoch [31/50] batch [100/176] time 0.089 (0.098) data 0.000 (0.003) loss 1.6335 (1.3757) teacher_loss 0.4489 (0.2419) loss_zs_kd 0.0291 (0.0303) loss_oracle 0.7537 (0.6107) kd_loss 0.7932 (0.8133) acc 78.1250 (91.5625) gate/entropy 1.0216 (1.0217) gate/usage_max 0.5244 (0.5243) gate/usage_min 0.2362 (0.2366) gate/usage_std 0.1351 (0.1350) teacher/entropy 0.0863 (0.0525) teacher/usage_max 0.6976 (0.7176) teacher/usage_min 0.0115 (0.0434) teacher/usage_std 0.2817 (0.2863) nleep/row_max_mean 1486.4675 (1481.0185) nleep/row_max_std 37.8115 (51.8610) nleep/row_min_mean 1461.7478 (1456.4025) lr 7.5131e-04 eta 0:05:33
epoch [31/50] batch [120/176] time 0.089 (0.097) data 0.000 (0.002) loss 1.2176 (1.3754) teacher_loss 0.1033 (0.2427) loss_zs_kd 0.0226 (0.0303) loss_oracle 0.6719 (0.6152) kd_loss 0.7670 (0.8099) acc 96.8750 (91.5365) gate/entropy 1.0211 (1.0216) gate/usage_max 0.5250 (0.5244) gate/usage_min 0.2357 (0.2364) gate/usage_std 0.1355 (0.1351) teacher/entropy 0.0554 (0.0547) teacher/usage_max 0.7724 (0.7189) teacher/usage_min 0.0338 (0.0436) teacher/usage_std 0.3173 (0.2870) nleep/row_max_mean 1487.3539 (1480.4380) nleep/row_max_std 38.3695 (51.9207) nleep/row_min_mean 1461.5303 (1455.9142) lr 7.5131e-04 eta 0:05:28
epoch [31/50] batch [140/176] time 0.087 (0.096) data 0.000 (0.002) loss 1.2091 (1.3821) teacher_loss 0.1808 (0.2416) loss_zs_kd 0.0281 (0.0308) loss_oracle 0.5322 (0.6186) kd_loss 0.7482 (0.8158) acc 96.8750 (91.6071) gate/entropy 1.0205 (1.0215) gate/usage_max 0.5258 (0.5245) gate/usage_min 0.2352 (0.2363) gate/usage_std 0.1361 (0.1352) teacher/entropy 0.0623 (0.0553) teacher/usage_max 0.7855 (0.7104) teacher/usage_min 0.0139 (0.0453) teacher/usage_std 0.3287 (0.2822) nleep/row_max_mean 1496.1716 (1480.6148) nleep/row_max_std 42.7080 (51.7808) nleep/row_min_mean 1469.8239 (1456.0611) lr 7.5131e-04 eta 0:05:24
epoch [31/50] batch [160/176] time 0.092 (0.097) data 0.000 (0.002) loss 1.5042 (1.3796) teacher_loss 0.1826 (0.2381) loss_zs_kd 0.0365 (0.0309) loss_oracle 0.6982 (0.6201) kd_loss 0.9543 (0.8160) acc 87.5000 (91.6992) gate/entropy 1.0210 (1.0214) gate/usage_max 0.5251 (0.5246) gate/usage_min 0.2353 (0.2362) gate/usage_std 0.1356 (0.1353) teacher/entropy 0.0067 (0.0555) teacher/usage_max 0.5938 (0.7097) teacher/usage_min 0.0315 (0.0435) teacher/usage_std 0.2314 (0.2823) nleep/row_max_mean 1467.1051 (1480.3930) nleep/row_max_std 57.1367 (52.2127) nleep/row_min_mean 1441.1558 (1455.8870) lr 7.5131e-04 eta 0:05:24
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,172
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,655
* accuracy: 62.3%
* error: 37.7%
* macro_f1: 58.6%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [32/50] batch [20/176] time 0.091 (0.109) data 0.000 (0.018) loss 1.3966 (1.4178) teacher_loss 0.2067 (0.2115) loss_zs_kd 0.0134 (0.0351) loss_oracle 0.6605 (0.6676) kd_loss 0.8530 (0.8548) acc 96.8750 (92.1875) gate/entropy 1.0203 (1.0206) gate/usage_max 0.5260 (0.5256) gate/usage_min 0.2346 (0.2349) gate/usage_std 0.1363 (0.1359) teacher/entropy 0.0101 (0.0541) teacher/usage_max 0.7177 (0.6598) teacher/usage_min 0.0324 (0.0449) teacher/usage_std 0.2859 (0.2567) nleep/row_max_mean 1495.9286 (1477.9574) nleep/row_max_std 47.6216 (55.9776) nleep/row_min_mean 1470.8047 (1454.0045) lr 6.9098e-04 eta 0:06:03
epoch [32/50] batch [40/176] time 0.092 (0.097) data 0.000 (0.009) loss 1.3823 (1.4126) teacher_loss 0.2414 (0.2205) loss_zs_kd 0.0310 (0.0310) loss_oracle 0.6091 (0.6593) kd_loss 0.8209 (0.8468) acc 87.5000 (91.6406) gate/entropy 1.0208 (1.0206) gate/usage_max 0.5253 (0.5256) gate/usage_min 0.2347 (0.2348) gate/usage_std 0.1358 (0.1360) teacher/entropy 0.1178 (0.0524) teacher/usage_max 0.6209 (0.6724) teacher/usage_min 0.0253 (0.0488) teacher/usage_std 0.2436 (0.2618) nleep/row_max_mean 1477.3436 (1478.7288) nleep/row_max_std 57.2462 (55.2419) nleep/row_min_mean 1455.7117 (1454.8880) lr 6.9098e-04 eta 0:05:21
epoch [32/50] batch [60/176] time 0.087 (0.094) data 0.001 (0.006) loss 1.5530 (1.4015) teacher_loss 0.1886 (0.2230) loss_zs_kd 0.0269 (0.0326) loss_oracle 0.8302 (0.6455) kd_loss 0.9359 (0.8394) acc 93.7500 (91.8229) gate/entropy 1.0203 (1.0206) gate/usage_max 0.5260 (0.5257) gate/usage_min 0.2343 (0.2346) gate/usage_std 0.1363 (0.1360) teacher/entropy 0.0831 (0.0540) teacher/usage_max 0.5200 (0.6798) teacher/usage_min 0.0795 (0.0510) teacher/usage_std 0.1860 (0.2648) nleep/row_max_mean 1475.2478 (1477.8919) nleep/row_max_std 59.5544 (55.9287) nleep/row_min_mean 1452.7378 (1454.1723) lr 6.9098e-04 eta 0:05:09
epoch [32/50] batch [80/176] time 0.096 (0.093) data 0.000 (0.005) loss 1.3820 (1.4214) teacher_loss 0.1257 (0.2403) loss_zs_kd 0.0333 (0.0330) loss_oracle 0.6317 (0.6424) kd_loss 0.9237 (0.8434) acc 96.8750 (91.3281) gate/entropy 1.0206 (1.0205) gate/usage_max 0.5256 (0.5258) gate/usage_min 0.2343 (0.2345) gate/usage_std 0.1360 (0.1361) teacher/entropy 0.0217 (0.0542) teacher/usage_max 0.6124 (0.6747) teacher/usage_min 0.0126 (0.0483) teacher/usage_std 0.2466 (0.2633) nleep/row_max_mean 1478.5530 (1477.0269) nleep/row_max_std 58.2407 (56.9548) nleep/row_min_mean 1454.2383 (1453.5383) lr 6.9098e-04 eta 0:05:02
epoch [32/50] batch [100/176] time 0.074 (0.091) data 0.000 (0.004) loss 1.5672 (1.4296) teacher_loss 0.5217 (0.2495) loss_zs_kd 0.0404 (0.0333) loss_oracle 0.5936 (0.6403) kd_loss 0.7285 (0.8433) acc 81.2500 (91.0625) gate/entropy 1.0202 (1.0205) gate/usage_max 0.5261 (0.5258) gate/usage_min 0.2339 (0.2344) gate/usage_std 0.1363 (0.1361) teacher/entropy 0.1135 (0.0540) teacher/usage_max 0.7458 (0.6748) teacher/usage_min 0.0699 (0.0473) teacher/usage_std 0.2954 (0.2635) nleep/row_max_mean 1477.7614 (1476.6428) nleep/row_max_std 50.7429 (56.0279) nleep/row_min_mean 1452.7510 (1453.2493) lr 6.9098e-04 eta 0:04:53
epoch [32/50] batch [120/176] time 0.098 (0.090) data 0.000 (0.003) loss 1.4998 (1.4258) teacher_loss 0.3221 (0.2419) loss_zs_kd 0.0509 (0.0330) loss_oracle 0.6936 (0.6455) kd_loss 0.8054 (0.8447) acc 90.6250 (91.4323) gate/entropy 1.0202 (1.0204) gate/usage_max 0.5261 (0.5259) gate/usage_min 0.2337 (0.2343) gate/usage_std 0.1363 (0.1362) teacher/entropy 0.0279 (0.0533) teacher/usage_max 0.7549 (0.6737) teacher/usage_min 0.0637 (0.0476) teacher/usage_std 0.3020 (0.2634) nleep/row_max_mean 1484.2939 (1477.2906) nleep/row_max_std 35.7754 (55.1879) nleep/row_min_mean 1461.6079 (1453.8561) lr 6.9098e-04 eta 0:04:50
epoch [32/50] batch [140/176] time 0.074 (0.089) data 0.000 (0.003) loss 1.1505 (1.4149) teacher_loss 0.1111 (0.2334) loss_zs_kd 0.0360 (0.0330) loss_oracle 0.5618 (0.6432) kd_loss 0.7404 (0.8434) acc 96.8750 (91.7857) gate/entropy 1.0202 (1.0204) gate/usage_max 0.5261 (0.5259) gate/usage_min 0.2336 (0.2342) gate/usage_std 0.1364 (0.1362) teacher/entropy 0.0238 (0.0525) teacher/usage_max 0.8422 (0.6761) teacher/usage_min 0.0258 (0.0467) teacher/usage_std 0.3624 (0.2652) nleep/row_max_mean 1476.5402 (1477.0250) nleep/row_max_std 59.2004 (55.3362) nleep/row_min_mean 1451.7515 (1453.6655) lr 6.9098e-04 eta 0:04:46
epoch [32/50] batch [160/176] time 0.089 (0.089) data 0.000 (0.002) loss 1.3078 (1.4115) teacher_loss 0.1796 (0.2310) loss_zs_kd 0.0536 (0.0334) loss_oracle 0.6464 (0.6453) kd_loss 0.7782 (0.8412) acc 96.8750 (91.8359) gate/entropy 1.0198 (1.0203) gate/usage_max 0.5266 (0.5260) gate/usage_min 0.2332 (0.2341) gate/usage_std 0.1367 (0.1362) teacher/entropy 0.0386 (0.0524) teacher/usage_max 0.7784 (0.6789) teacher/usage_min 0.1085 (0.0461) teacher/usage_std 0.3147 (0.2665) nleep/row_max_mean 1487.0858 (1477.3211) nleep/row_max_std 49.6815 (55.1602) nleep/row_min_mean 1463.6050 (1453.9610) lr 6.9098e-04 eta 0:04:43
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,171
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,671
* accuracy: 62.9%
* error: 37.1%
* macro_f1: 58.6%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [33/50] batch [20/176] time 0.098 (0.107) data 0.000 (0.017) loss 1.4818 (1.4314) teacher_loss 0.2953 (0.2150) loss_zs_kd 0.0378 (0.0289) loss_oracle 0.5974 (0.6658) kd_loss 0.8688 (0.8691) acc 84.3750 (92.1875) gate/entropy 1.0201 (1.0200) gate/usage_max 0.5262 (0.5264) gate/usage_min 0.2332 (0.2331) gate/usage_std 0.1364 (0.1365) teacher/entropy 0.0298 (0.0527) teacher/usage_max 0.6717 (0.6416) teacher/usage_min 0.0317 (0.0533) teacher/usage_std 0.2626 (0.2446) nleep/row_max_mean 1475.4438 (1476.6613) nleep/row_max_std 60.0454 (53.9804) nleep/row_min_mean 1448.9125 (1453.1280) lr 6.3188e-04 eta 0:05:36
epoch [33/50] batch [40/176] time 0.095 (0.095) data 0.000 (0.008) loss 1.1214 (1.4010) teacher_loss 0.1106 (0.2211) loss_zs_kd 0.0205 (0.0304) loss_oracle 0.6060 (0.6439) kd_loss 0.6975 (0.8428) acc 100.0000 (92.4219) gate/entropy 1.0190 (1.0199) gate/usage_max 0.5276 (0.5265) gate/usage_min 0.2323 (0.2330) gate/usage_std 0.1374 (0.1366) teacher/entropy 0.0504 (0.0549) teacher/usage_max 0.8603 (0.6721) teacher/usage_min 0.0022 (0.0520) teacher/usage_std 0.3767 (0.2610) nleep/row_max_mean 1502.3525 (1479.8837) nleep/row_max_std 48.3434 (54.0262) nleep/row_min_mean 1478.8091 (1456.3737) lr 6.3188e-04 eta 0:04:56
epoch [33/50] batch [60/176] time 0.094 (0.097) data 0.001 (0.006) loss 1.5035 (1.4148) teacher_loss 0.4452 (0.2262) loss_zs_kd 0.0545 (0.0321) loss_oracle 0.6410 (0.6547) kd_loss 0.7105 (0.8452) acc 87.5000 (92.3958) gate/entropy 1.0195 (1.0198) gate/usage_max 0.5269 (0.5266) gate/usage_min 0.2324 (0.2329) gate/usage_std 0.1369 (0.1367) teacher/entropy 0.1531 (0.0584) teacher/usage_max 0.7160 (0.6646) teacher/usage_min 0.0349 (0.0527) teacher/usage_std 0.2843 (0.2568) nleep/row_max_mean 1476.4075 (1478.8788) nleep/row_max_std 58.8840 (55.1544) nleep/row_min_mean 1454.5275 (1455.4641) lr 6.3188e-04 eta 0:05:01
epoch [33/50] batch [80/176] time 0.098 (0.097) data 0.000 (0.004) loss 1.4635 (1.4249) teacher_loss 0.2545 (0.2333) loss_zs_kd 0.0406 (0.0321) loss_oracle 0.6937 (0.6543) kd_loss 0.8418 (0.8484) acc 84.3750 (91.8750) gate/entropy 1.0199 (1.0198) gate/usage_max 0.5264 (0.5266) gate/usage_min 0.2326 (0.2328) gate/usage_std 0.1366 (0.1367) teacher/entropy 0.0640 (0.0573) teacher/usage_max 0.6596 (0.6624) teacher/usage_min 0.0160 (0.0494) teacher/usage_std 0.2629 (0.2576) nleep/row_max_mean 1470.1304 (1477.8008) nleep/row_max_std 60.4109 (55.1287) nleep/row_min_mean 1447.2378 (1454.6750) lr 6.3188e-04 eta 0:04:58
epoch [33/50] batch [100/176] time 0.095 (0.096) data 0.000 (0.004) loss 1.3489 (1.4148) teacher_loss 0.1684 (0.2279) loss_zs_kd 0.0367 (0.0326) loss_oracle 0.6247 (0.6462) kd_loss 0.8497 (0.8476) acc 93.7500 (92.2188) gate/entropy 1.0198 (1.0198) gate/usage_max 0.5266 (0.5265) gate/usage_min 0.2323 (0.2327) gate/usage_std 0.1367 (0.1367) teacher/entropy 0.0713 (0.0577) teacher/usage_max 0.6431 (0.6624) teacher/usage_min 0.0694 (0.0478) teacher/usage_std 0.2364 (0.2583) nleep/row_max_mean 1466.2483 (1477.6469) nleep/row_max_std 62.1088 (54.2979) nleep/row_min_mean 1444.1292 (1454.5270) lr 6.3188e-04 eta 0:04:55
epoch [33/50] batch [120/176] time 0.098 (0.096) data 0.000 (0.003) loss 1.4718 (1.4266) teacher_loss 0.1444 (0.2301) loss_zs_kd 0.0379 (0.0323) loss_oracle 0.7729 (0.6539) kd_loss 0.9220 (0.8534) acc 93.7500 (92.1094) gate/entropy 1.0194 (1.0198) gate/usage_max 0.5270 (0.5266) gate/usage_min 0.2319 (0.2326) gate/usage_std 0.1370 (0.1367) teacher/entropy 0.0489 (0.0571) teacher/usage_max 0.5757 (0.6556) teacher/usage_min 0.0323 (0.0488) teacher/usage_std 0.2257 (0.2553) nleep/row_max_mean 1489.8242 (1477.6340) nleep/row_max_std 48.4911 (53.7249) nleep/row_min_mean 1466.7612 (1454.4857) lr 6.3188e-04 eta 0:04:53
epoch [33/50] batch [140/176] time 0.079 (0.096) data 0.000 (0.003) loss 1.4955 (1.4247) teacher_loss 0.3483 (0.2274) loss_zs_kd 0.0573 (0.0322) loss_oracle 0.4915 (0.6529) kd_loss 0.8728 (0.8547) acc 87.5000 (92.2768) gate/entropy 1.0207 (1.0198) gate/usage_max 0.5255 (0.5266) gate/usage_min 0.2325 (0.2326) gate/usage_std 0.1359 (0.1367) teacher/entropy 0.0352 (0.0569) teacher/usage_max 0.6583 (0.6539) teacher/usage_min 0.0618 (0.0473) teacher/usage_std 0.2464 (0.2546) nleep/row_max_mean 1469.4912 (1477.8157) nleep/row_max_std 52.7720 (53.6938) nleep/row_min_mean 1442.0122 (1454.5006) lr 6.3188e-04 eta 0:04:50
epoch [33/50] batch [160/176] time 0.087 (0.096) data 0.000 (0.002) loss 1.3125 (1.4202) teacher_loss 0.1263 (0.2230) loss_zs_kd 0.0161 (0.0322) loss_oracle 0.5791 (0.6515) kd_loss 0.8885 (0.8553) acc 96.8750 (92.4805) gate/entropy 1.0197 (1.0198) gate/usage_max 0.5267 (0.5266) gate/usage_min 0.2317 (0.2325) gate/usage_std 0.1368 (0.1367) teacher/entropy 0.0149 (0.0563) teacher/usage_max 0.6598 (0.6537) teacher/usage_min 0.0000 (0.0459) teacher/usage_std 0.2694 (0.2549) nleep/row_max_mean 1479.5166 (1477.8629) nleep/row_max_std 65.5934 (53.5738) nleep/row_min_mean 1452.2015 (1454.4648) lr 6.3188e-04 eta 0:04:48
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,164
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.1%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,812
* accuracy: 68.2%
* error: 31.8%
* macro_f1: 62.3%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [34/50] batch [20/176] time 0.089 (0.104) data 0.000 (0.017) loss 1.5898 (1.4355) teacher_loss 0.3713 (0.2359) loss_zs_kd 0.0180 (0.0318) loss_oracle 0.6266 (0.6411) kd_loss 0.8963 (0.8631) acc 87.5000 (92.5000) gate/entropy 1.0202 (1.0198) gate/usage_max 0.5260 (0.5265) gate/usage_min 0.2317 (0.2315) gate/usage_std 0.1363 (0.1367) teacher/entropy 0.1470 (0.0523) teacher/usage_max 0.4805 (0.6512) teacher/usage_min 0.0476 (0.0412) teacher/usage_std 0.2021 (0.2559) nleep/row_max_mean 1474.6812 (1478.4264) nleep/row_max_std 55.0381 (53.2731) nleep/row_min_mean 1450.4373 (1453.9485) lr 5.7422e-04 eta 0:05:09
epoch [34/50] batch [40/176] time 0.089 (0.098) data 0.000 (0.009) loss 1.2278 (1.4327) teacher_loss 0.1923 (0.2261) loss_zs_kd 0.0194 (0.0338) loss_oracle 0.5501 (0.6403) kd_loss 0.7507 (0.8695) acc 96.8750 (92.1875) gate/entropy 1.0192 (1.0198) gate/usage_max 0.5272 (0.5265) gate/usage_min 0.2310 (0.2315) gate/usage_std 0.1372 (0.1367) teacher/entropy 0.0672 (0.0529) teacher/usage_max 0.7705 (0.6401) teacher/usage_min 0.0129 (0.0454) teacher/usage_std 0.3201 (0.2483) nleep/row_max_mean 1484.0703 (1478.7628) nleep/row_max_std 53.4822 (51.6771) nleep/row_min_mean 1461.0999 (1454.6040) lr 5.7422e-04 eta 0:04:48
epoch [34/50] batch [60/176] time 0.097 (0.096) data 0.001 (0.006) loss 1.4687 (1.4112) teacher_loss 0.2381 (0.2096) loss_zs_kd 0.0411 (0.0343) loss_oracle 0.6703 (0.6359) kd_loss 0.8749 (0.8665) acc 90.6250 (92.8125) gate/entropy 1.0197 (1.0198) gate/usage_max 0.5266 (0.5265) gate/usage_min 0.2311 (0.2314) gate/usage_std 0.1367 (0.1367) teacher/entropy 0.0428 (0.0507) teacher/usage_max 0.6449 (0.6461) teacher/usage_min 0.0716 (0.0434) teacher/usage_std 0.2367 (0.2520) nleep/row_max_mean 1482.2294 (1479.8990) nleep/row_max_std 47.7591 (50.6549) nleep/row_min_mean 1456.4771 (1455.6676) lr 5.7422e-04 eta 0:04:42
epoch [34/50] batch [80/176] time 0.095 (0.096) data 0.000 (0.004) loss 1.2413 (1.4063) teacher_loss 0.0825 (0.2066) loss_zs_kd 0.0317 (0.0345) loss_oracle 0.6876 (0.6405) kd_loss 0.7992 (0.8621) acc 100.0000 (92.7734) gate/entropy 1.0195 (1.0198) gate/usage_max 0.5268 (0.5265) gate/usage_min 0.2308 (0.2313) gate/usage_std 0.1369 (0.1367) teacher/entropy 0.1220 (0.0504) teacher/usage_max 0.6398 (0.6516) teacher/usage_min 0.0479 (0.0434) teacher/usage_std 0.2421 (0.2550) nleep/row_max_mean 1485.2903 (1479.9573) nleep/row_max_std 57.3071 (50.7243) nleep/row_min_mean 1457.2822 (1455.7744) lr 5.7422e-04 eta 0:04:39
epoch [34/50] batch [100/176] time 0.160 (0.099) data 0.001 (0.004) loss 1.2063 (1.4096) teacher_loss 0.0809 (0.2102) loss_zs_kd 0.0372 (0.0344) loss_oracle 0.5900 (0.6439) kd_loss 0.8118 (0.8603) acc 96.8750 (92.6562) gate/entropy 1.0196 (1.0198) gate/usage_max 0.5267 (0.5266) gate/usage_min 0.2307 (0.2312) gate/usage_std 0.1368 (0.1367) teacher/entropy 0.0216 (0.0481) teacher/usage_max 0.7500 (0.6565) teacher/usage_min 0.0029 (0.0424) teacher/usage_std 0.3110 (0.2569) nleep/row_max_mean 1484.0151 (1480.2041) nleep/row_max_std 45.6019 (50.5185) nleep/row_min_mean 1455.5048 (1455.7858) lr 5.7422e-04 eta 0:04:46
epoch [34/50] batch [120/176] time 0.095 (0.098) data 0.000 (0.003) loss 1.3406 (1.4099) teacher_loss 0.1762 (0.2072) loss_zs_kd 0.0354 (0.0351) loss_oracle 0.6511 (0.6432) kd_loss 0.8212 (0.8635) acc 96.8750 (92.7083) gate/entropy 1.0196 (1.0197) gate/usage_max 0.5267 (0.5266) gate/usage_min 0.2305 (0.2311) gate/usage_std 0.1368 (0.1367) teacher/entropy 0.0229 (0.0457) teacher/usage_max 0.7372 (0.6567) teacher/usage_min 0.0128 (0.0421) teacher/usage_std 0.3015 (0.2568) nleep/row_max_mean 1481.1106 (1480.6765) nleep/row_max_std 49.5882 (50.5985) nleep/row_min_mean 1454.1274 (1456.0892) lr 5.7422e-04 eta 0:04:42
epoch [34/50] batch [140/176] time 0.102 (0.098) data 0.000 (0.003) loss 1.6729 (1.4107) teacher_loss 0.2819 (0.2044) loss_zs_kd 0.0197 (0.0351) loss_oracle 0.7788 (0.6471) kd_loss 0.9917 (0.8652) acc 90.6250 (93.0357) gate/entropy 1.0194 (1.0197) gate/usage_max 0.5270 (0.5266) gate/usage_min 0.2302 (0.2310) gate/usage_std 0.1370 (0.1367) teacher/entropy 0.0271 (0.0458) teacher/usage_max 0.5145 (0.6543) teacher/usage_min 0.0931 (0.0435) teacher/usage_std 0.1771 (0.2552) nleep/row_max_mean 1469.5083 (1480.2070) nleep/row_max_std 61.8954 (50.9430) nleep/row_min_mean 1445.8130 (1455.6366) lr 5.7422e-04 eta 0:04:38
epoch [34/50] batch [160/176] time 0.084 (0.098) data 0.000 (0.002) loss 1.4861 (1.4202) teacher_loss 0.1747 (0.2125) loss_zs_kd 0.0421 (0.0349) loss_oracle 0.7569 (0.6473) kd_loss 0.9120 (0.8666) acc 93.7500 (92.7930) gate/entropy 1.0200 (1.0197) gate/usage_max 0.5262 (0.5266) gate/usage_min 0.2306 (0.2309) gate/usage_std 0.1364 (0.1367) teacher/entropy 0.0403 (0.0453) teacher/usage_max 0.5960 (0.6529) teacher/usage_min 0.0267 (0.0460) teacher/usage_std 0.2345 (0.2541) nleep/row_max_mean 1463.3539 (1479.5619) nleep/row_max_std 66.6707 (51.6707) nleep/row_min_mean 1439.2236 (1455.0075) lr 5.7422e-04 eta 0:04:38
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,160
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,795
* accuracy: 67.6%
* error: 32.4%
* macro_f1: 62.1%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [35/50] batch [20/176] time 0.095 (0.116) data 0.000 (0.016) loss 1.4291 (1.4235) teacher_loss 0.2717 (0.2115) loss_zs_kd 0.0310 (0.0388) loss_oracle 0.6023 (0.6641) kd_loss 0.8406 (0.8606) acc 93.7500 (93.7500) gate/entropy 1.0198 (1.0197) gate/usage_max 0.5264 (0.5265) gate/usage_min 0.2302 (0.2302) gate/usage_std 0.1366 (0.1367) teacher/entropy 0.0314 (0.0435) teacher/usage_max 0.6996 (0.6594) teacher/usage_min 0.0002 (0.0362) teacher/usage_std 0.2865 (0.2602) nleep/row_max_mean 1455.4421 (1472.2814) nleep/row_max_std 69.3762 (58.2033) nleep/row_min_mean 1430.8650 (1447.4518) lr 5.1825e-04 eta 0:05:23
epoch [35/50] batch [40/176] time 0.098 (0.104) data 0.000 (0.008) loss 1.3731 (1.4059) teacher_loss 0.2221 (0.2025) loss_zs_kd 0.0458 (0.0362) loss_oracle 0.6477 (0.6542) kd_loss 0.8044 (0.8582) acc 90.6250 (93.6719) gate/entropy 1.0193 (1.0197) gate/usage_max 0.5271 (0.5265) gate/usage_min 0.2298 (0.2302) gate/usage_std 0.1371 (0.1367) teacher/entropy 0.0600 (0.0425) teacher/usage_max 0.7138 (0.6642) teacher/usage_min 0.0728 (0.0450) teacher/usage_std 0.2751 (0.2592) nleep/row_max_mean 1481.0886 (1473.1752) nleep/row_max_std 52.6645 (56.9616) nleep/row_min_mean 1456.9133 (1448.4909) lr 5.1825e-04 eta 0:04:48
epoch [35/50] batch [60/176] time 0.096 (0.101) data 0.001 (0.005) loss 1.3755 (1.3961) teacher_loss 0.3132 (0.1989) loss_zs_kd 0.0486 (0.0352) loss_oracle 0.5571 (0.6546) kd_loss 0.7594 (0.8523) acc 90.6250 (93.6458) gate/entropy 1.0198 (1.0196) gate/usage_max 0.5265 (0.5266) gate/usage_min 0.2300 (0.2301) gate/usage_std 0.1367 (0.1368) teacher/entropy 0.0750 (0.0419) teacher/usage_max 0.7464 (0.6726) teacher/usage_min 0.0149 (0.0458) teacher/usage_std 0.3060 (0.2631) nleep/row_max_mean 1485.9479 (1474.3423) nleep/row_max_std 39.8241 (56.9855) nleep/row_min_mean 1457.2205 (1449.1952) lr 5.1825e-04 eta 0:04:38
epoch [35/50] batch [80/176] time 0.092 (0.100) data 0.000 (0.004) loss 1.4761 (1.4044) teacher_loss 0.2206 (0.1980) loss_zs_kd 0.0312 (0.0343) loss_oracle 0.7331 (0.6579) kd_loss 0.8734 (0.8604) acc 84.3750 (93.5938) gate/entropy 1.0190 (1.0196) gate/usage_max 0.5274 (0.5267) gate/usage_min 0.2294 (0.2300) gate/usage_std 0.1373 (0.1368) teacher/entropy 0.0394 (0.0393) teacher/usage_max 0.6484 (0.6656) teacher/usage_min 0.0407 (0.0478) teacher/usage_std 0.2486 (0.2590) nleep/row_max_mean 1476.0718 (1474.4019) nleep/row_max_std 57.8998 (56.9123) nleep/row_min_mean 1449.6760 (1449.2969) lr 5.1825e-04 eta 0:04:33
epoch [35/50] batch [100/176] time 0.088 (0.099) data 0.000 (0.003) loss 1.7235 (1.4099) teacher_loss 0.3761 (0.2005) loss_zs_kd 0.0474 (0.0355) loss_oracle 0.7561 (0.6606) kd_loss 0.9457 (0.8614) acc 90.6250 (93.2188) gate/entropy 1.0200 (1.0196) gate/usage_max 0.5261 (0.5267) gate/usage_min 0.2300 (0.2299) gate/usage_std 0.1364 (0.1368) teacher/entropy 0.0715 (0.0377) teacher/usage_max 0.5137 (0.6675) teacher/usage_min 0.0609 (0.0463) teacher/usage_std 0.1960 (0.2610) nleep/row_max_mean 1468.1274 (1474.6457) nleep/row_max_std 60.9810 (56.8363) nleep/row_min_mean 1443.5475 (1449.5029) lr 5.1825e-04 eta 0:04:28
epoch [35/50] batch [120/176] time 0.101 (0.098) data 0.000 (0.003) loss 1.4796 (1.4157) teacher_loss 0.2173 (0.2043) loss_zs_kd 0.0352 (0.0358) loss_oracle 0.6665 (0.6645) kd_loss 0.9114 (0.8613) acc 93.7500 (93.1510) gate/entropy 1.0199 (1.0196) gate/usage_max 0.5263 (0.5267) gate/usage_min 0.2297 (0.2299) gate/usage_std 0.1366 (0.1368) teacher/entropy 0.0479 (0.0384) teacher/usage_max 0.5859 (0.6666) teacher/usage_min 0.0183 (0.0483) teacher/usage_std 0.2359 (0.2597) nleep/row_max_mean 1458.3364 (1474.5464) nleep/row_max_std 63.1216 (56.4490) nleep/row_min_mean 1435.6174 (1449.4359) lr 5.1825e-04 eta 0:04:24
epoch [35/50] batch [140/176] time 0.100 (0.098) data 0.000 (0.003) loss 1.6875 (1.4175) teacher_loss 0.4776 (0.2035) loss_zs_kd 0.0339 (0.0358) loss_oracle 0.6947 (0.6656) kd_loss 0.8457 (0.8633) acc 87.5000 (93.1473) gate/entropy 1.0197 (1.0196) gate/usage_max 0.5265 (0.5267) gate/usage_min 0.2296 (0.2298) gate/usage_std 0.1367 (0.1368) teacher/entropy 0.0546 (0.0399) teacher/usage_max 0.6603 (0.6624) teacher/usage_min 0.0011 (0.0496) teacher/usage_std 0.2691 (0.2574) nleep/row_max_mean 1482.3381 (1474.6803) nleep/row_max_std 49.6707 (55.8132) nleep/row_min_mean 1454.5927 (1449.6355) lr 5.1825e-04 eta 0:04:20
epoch [35/50] batch [160/176] time 0.103 (0.097) data 0.000 (0.002) loss 1.4059 (1.4136) teacher_loss 0.2241 (0.2040) loss_zs_kd 0.0323 (0.0360) loss_oracle 0.6727 (0.6638) kd_loss 0.8294 (0.8596) acc 90.6250 (92.9688) gate/entropy 1.0194 (1.0196) gate/usage_max 0.5270 (0.5267) gate/usage_min 0.2293 (0.2298) gate/usage_std 0.1370 (0.1369) teacher/entropy 0.0349 (0.0395) teacher/usage_max 0.7078 (0.6674) teacher/usage_min 0.0065 (0.0489) teacher/usage_std 0.2883 (0.2600) nleep/row_max_mean 1464.1902 (1474.8140) nleep/row_max_std 57.0417 (55.4960) nleep/row_min_mean 1439.0432 (1449.6921) lr 5.1825e-04 eta 0:04:18
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,157
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 90.9%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,764
* accuracy: 66.4%
* error: 33.6%
* macro_f1: 61.4%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [36/50] batch [20/176] time 0.083 (0.101) data 0.000 (0.014) loss 1.3527 (1.4505) teacher_loss 0.0799 (0.2358) loss_zs_kd 0.0482 (0.0354) loss_oracle 0.7510 (0.6725) kd_loss 0.8732 (0.8608) acc 96.8750 (92.9688) gate/entropy 1.0193 (1.0192) gate/usage_max 0.5270 (0.5271) gate/usage_min 0.2292 (0.2292) gate/usage_std 0.1371 (0.1371) teacher/entropy 0.0905 (0.0467) teacher/usage_max 0.5906 (0.6573) teacher/usage_min 0.1487 (0.0819) teacher/usage_std 0.1876 (0.2479) nleep/row_max_mean 1469.1029 (1477.2155) nleep/row_max_std 55.4820 (54.1867) nleep/row_min_mean 1445.3090 (1451.8111) lr 4.6417e-04 eta 0:04:25
epoch [36/50] batch [40/176] time 0.086 (0.091) data 0.000 (0.007) loss 1.2984 (1.4265) teacher_loss 0.1601 (0.2178) loss_zs_kd 0.0291 (0.0371) loss_oracle 0.7028 (0.6694) kd_loss 0.7723 (0.8555) acc 90.6250 (92.6562) gate/entropy 1.0191 (1.0193) gate/usage_max 0.5273 (0.5270) gate/usage_min 0.2290 (0.2292) gate/usage_std 0.1373 (0.1371) teacher/entropy 0.0724 (0.0492) teacher/usage_max 0.7336 (0.6605) teacher/usage_min 0.0177 (0.0767) teacher/usage_std 0.2984 (0.2487) nleep/row_max_mean 1487.5728 (1475.3851) nleep/row_max_std 44.7312 (53.9802) nleep/row_min_mean 1458.7074 (1450.4563) lr 4.6417e-04 eta 0:03:57
epoch [36/50] batch [60/176] time 0.072 (0.092) data 0.001 (0.005) loss 1.3230 (1.4266) teacher_loss 0.2415 (0.2130) loss_zs_kd 0.0397 (0.0375) loss_oracle 0.5520 (0.6749) kd_loss 0.7857 (0.8574) acc 96.8750 (92.5521) gate/entropy 1.0191 (1.0193) gate/usage_max 0.5272 (0.5270) gate/usage_min 0.2290 (0.2292) gate/usage_std 0.1372 (0.1371) teacher/entropy 0.0298 (0.0481) teacher/usage_max 0.7721 (0.6590) teacher/usage_min 0.0083 (0.0725) teacher/usage_std 0.3220 (0.2484) nleep/row_max_mean 1459.0295 (1476.0491) nleep/row_max_std 62.6701 (53.3969) nleep/row_min_mean 1435.2275 (1451.2266) lr 4.6417e-04 eta 0:03:56
epoch [36/50] batch [80/176] time 0.093 (0.090) data 0.000 (0.004) loss 1.3924 (1.4156) teacher_loss 0.1378 (0.2077) loss_zs_kd 0.0583 (0.0367) loss_oracle 0.6865 (0.6752) kd_loss 0.8822 (0.8520) acc 96.8750 (92.9297) gate/entropy 1.0191 (1.0193) gate/usage_max 0.5272 (0.5270) gate/usage_min 0.2290 (0.2292) gate/usage_std 0.1372 (0.1371) teacher/entropy 0.0258 (0.0478) teacher/usage_max 0.6564 (0.6666) teacher/usage_min 0.0820 (0.0743) teacher/usage_std 0.2399 (0.2517) nleep/row_max_mean 1480.4406 (1475.9981) nleep/row_max_std 51.6982 (52.7050) nleep/row_min_mean 1453.9371 (1451.2074) lr 4.6417e-04 eta 0:03:49
epoch [36/50] batch [100/176] time 0.085 (0.089) data 0.000 (0.003) loss 1.5713 (1.4173) teacher_loss 0.2232 (0.2067) loss_zs_kd 0.0619 (0.0358) loss_oracle 0.7218 (0.6789) kd_loss 0.9562 (0.8532) acc 90.6250 (93.0625) gate/entropy 1.0194 (1.0193) gate/usage_max 0.5268 (0.5270) gate/usage_min 0.2291 (0.2291) gate/usage_std 0.1369 (0.1371) teacher/entropy 0.0680 (0.0480) teacher/usage_max 0.5095 (0.6648) teacher/usage_min 0.1392 (0.0783) teacher/usage_std 0.1517 (0.2497) nleep/row_max_mean 1468.4622 (1476.3349) nleep/row_max_std 48.5749 (52.2460) nleep/row_min_mean 1442.7382 (1451.5268) lr 4.6417e-04 eta 0:03:46
epoch [36/50] batch [120/176] time 0.088 (0.089) data 0.000 (0.003) loss 1.4069 (1.4126) teacher_loss 0.1873 (0.2082) loss_zs_kd 0.0336 (0.0363) loss_oracle 0.5893 (0.6710) kd_loss 0.9082 (0.8507) acc 90.6250 (92.6823) gate/entropy 1.0193 (1.0193) gate/usage_max 0.5269 (0.5270) gate/usage_min 0.2290 (0.2291) gate/usage_std 0.1370 (0.1371) teacher/entropy 0.0388 (0.0481) teacher/usage_max 0.5985 (0.6676) teacher/usage_min 0.0052 (0.0743) teacher/usage_std 0.2463 (0.2522) nleep/row_max_mean 1466.6685 (1476.3833) nleep/row_max_std 58.5466 (52.0199) nleep/row_min_mean 1440.9661 (1451.5958) lr 4.6417e-04 eta 0:03:43
epoch [36/50] batch [140/176] time 0.084 (0.088) data 0.000 (0.002) loss 1.4060 (1.4096) teacher_loss 0.3531 (0.2088) loss_zs_kd 0.0194 (0.0364) loss_oracle 0.5702 (0.6659) kd_loss 0.7581 (0.8497) acc 90.6250 (92.5893) gate/entropy 1.0187 (1.0193) gate/usage_max 0.5277 (0.5270) gate/usage_min 0.2286 (0.2291) gate/usage_std 0.1376 (0.1371) teacher/entropy 0.0446 (0.0489) teacher/usage_max 0.7876 (0.6678) teacher/usage_min 0.0349 (0.0724) teacher/usage_std 0.3265 (0.2528) nleep/row_max_mean 1486.0726 (1476.3668) nleep/row_max_std 47.3168 (51.8415) nleep/row_min_mean 1460.0017 (1451.6498) lr 4.6417e-04 eta 0:03:41
epoch [36/50] batch [160/176] time 0.091 (0.088) data 0.000 (0.002) loss 1.4940 (1.4124) teacher_loss 0.3169 (0.2122) loss_zs_kd 0.0400 (0.0363) loss_oracle 0.6470 (0.6616) kd_loss 0.8336 (0.8512) acc 87.5000 (92.5391) gate/entropy 1.0187 (1.0193) gate/usage_max 0.5278 (0.5270) gate/usage_min 0.2285 (0.2291) gate/usage_std 0.1376 (0.1371) teacher/entropy 0.0626 (0.0497) teacher/usage_max 0.6742 (0.6648) teacher/usage_min 0.1124 (0.0733) teacher/usage_std 0.2445 (0.2509) nleep/row_max_mean 1481.5018 (1476.1886) nleep/row_max_std 51.0125 (51.7474) nleep/row_min_mean 1457.4648 (1451.5508) lr 4.6417e-04 eta 0:03:39
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,159
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 91.0%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,757
* accuracy: 66.2%
* error: 33.8%
* macro_f1: 61.2%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [37/50] batch [20/176] time 0.087 (0.112) data 0.000 (0.016) loss 1.3967 (1.4051) teacher_loss 0.2947 (0.2746) loss_zs_kd 0.0435 (0.0360) loss_oracle 0.5967 (0.6177) kd_loss 0.7820 (0.8037) acc 84.3750 (90.3125) gate/entropy 1.0190 (1.0190) gate/usage_max 0.5273 (0.5274) gate/usage_min 0.2287 (0.2286) gate/usage_std 0.1373 (0.1374) teacher/entropy 0.0277 (0.0590) teacher/usage_max 0.7799 (0.7141) teacher/usage_min 0.0467 (0.0679) teacher/usage_std 0.3200 (0.2779) nleep/row_max_mean 1488.1520 (1477.6819) nleep/row_max_std 43.7703 (51.2869) nleep/row_min_mean 1462.7120 (1453.2488) lr 4.1221e-04 eta 0:04:32
epoch [37/50] batch [40/176] time 0.100 (0.101) data 0.000 (0.008) loss 1.4894 (1.4178) teacher_loss 0.2675 (0.2626) loss_zs_kd 0.0289 (0.0350) loss_oracle 0.6316 (0.6165) kd_loss 0.8916 (0.8294) acc 87.5000 (90.3125) gate/entropy 1.0191 (1.0190) gate/usage_max 0.5272 (0.5274) gate/usage_min 0.2287 (0.2286) gate/usage_std 0.1373 (0.1374) teacher/entropy 0.0547 (0.0551) teacher/usage_max 0.6025 (0.6850) teacher/usage_min 0.0441 (0.0638) teacher/usage_std 0.2284 (0.2634) nleep/row_max_mean 1474.7120 (1477.5872) nleep/row_max_std 55.6253 (52.9863) nleep/row_min_mean 1449.6807 (1453.1202) lr 4.1221e-04 eta 0:04:03
epoch [37/50] batch [60/176] time 0.083 (0.096) data 0.000 (0.006) loss 1.3120 (1.4010) teacher_loss 0.2705 (0.2403) loss_zs_kd 0.0565 (0.0351) loss_oracle 0.5489 (0.6247) kd_loss 0.7387 (0.8309) acc 93.7500 (91.4583) gate/entropy 1.0183 (1.0189) gate/usage_max 0.5282 (0.5274) gate/usage_min 0.2281 (0.2286) gate/usage_std 0.1380 (0.1374) teacher/entropy 0.0505 (0.0521) teacher/usage_max 0.8038 (0.6867) teacher/usage_min 0.0035 (0.0587) teacher/usage_std 0.3415 (0.2668) nleep/row_max_mean 1486.8711 (1477.0702) nleep/row_max_std 47.0487 (53.4931) nleep/row_min_mean 1459.3583 (1452.4552) lr 4.1221e-04 eta 0:03:51
epoch [37/50] batch [80/176] time 0.100 (0.094) data 0.000 (0.004) loss 1.2471 (1.4005) teacher_loss 0.1120 (0.2368) loss_zs_kd 0.0213 (0.0343) loss_oracle 0.6204 (0.6235) kd_loss 0.8143 (0.8348) acc 100.0000 (92.0312) gate/entropy 1.0192 (1.0189) gate/usage_max 0.5271 (0.5274) gate/usage_min 0.2286 (0.2286) gate/usage_std 0.1372 (0.1374) teacher/entropy 0.0387 (0.0477) teacher/usage_max 0.7261 (0.6868) teacher/usage_min 0.0512 (0.0544) teacher/usage_std 0.2864 (0.2682) nleep/row_max_mean 1461.2329 (1475.4198) nleep/row_max_std 59.9966 (54.0490) nleep/row_min_mean 1440.2053 (1450.7215) lr 4.1221e-04 eta 0:03:45
epoch [37/50] batch [100/176] time 0.085 (0.093) data 0.001 (0.003) loss 1.3965 (1.3909) teacher_loss 0.2396 (0.2362) loss_zs_kd 0.0320 (0.0337) loss_oracle 0.6477 (0.6188) kd_loss 0.8171 (0.8284) acc 93.7500 (92.1250) gate/entropy 1.0186 (1.0189) gate/usage_max 0.5278 (0.5275) gate/usage_min 0.2283 (0.2286) gate/usage_std 0.1377 (0.1374) teacher/entropy 0.0365 (0.0490) teacher/usage_max 0.7272 (0.6931) teacher/usage_min 0.0845 (0.0516) teacher/usage_std 0.2817 (0.2721) nleep/row_max_mean 1482.3265 (1475.4099) nleep/row_max_std 55.2394 (54.2309) nleep/row_min_mean 1457.5897 (1450.6724) lr 4.1221e-04 eta 0:03:40
epoch [37/50] batch [120/176] time 0.092 (0.093) data 0.000 (0.003) loss 1.3807 (1.3925) teacher_loss 0.1185 (0.2373) loss_zs_kd 0.0450 (0.0344) loss_oracle 0.7147 (0.6208) kd_loss 0.8824 (0.8276) acc 96.8750 (92.0833) gate/entropy 1.0189 (1.0189) gate/usage_max 0.5275 (0.5275) gate/usage_min 0.2283 (0.2285) gate/usage_std 0.1375 (0.1374) teacher/entropy 0.0590 (0.0499) teacher/usage_max 0.6125 (0.6929) teacher/usage_min 0.0674 (0.0511) teacher/usage_std 0.2227 (0.2718) nleep/row_max_mean 1466.7485 (1474.9386) nleep/row_max_std 58.0516 (54.4625) nleep/row_min_mean 1441.4760 (1450.2975) lr 4.1221e-04 eta 0:03:37
epoch [37/50] batch [140/176] time 0.095 (0.095) data 0.000 (0.003) loss 1.2856 (1.3949) teacher_loss 0.1393 (0.2384) loss_zs_kd 0.0102 (0.0337) loss_oracle 0.5793 (0.6243) kd_loss 0.8516 (0.8274) acc 96.8750 (92.1652) gate/entropy 1.0188 (1.0189) gate/usage_max 0.5276 (0.5275) gate/usage_min 0.2283 (0.2285) gate/usage_std 0.1375 (0.1375) teacher/entropy 0.0478 (0.0509) teacher/usage_max 0.6649 (0.6918) teacher/usage_min 0.0551 (0.0512) teacher/usage_std 0.2518 (0.2714) nleep/row_max_mean 1484.0272 (1474.5889) nleep/row_max_std 50.4441 (54.8327) nleep/row_min_mean 1456.9854 (1449.8876) lr 4.1221e-04 eta 0:03:39
epoch [37/50] batch [160/176] time 0.085 (0.094) data 0.000 (0.002) loss 1.2649 (1.3860) teacher_loss 0.1048 (0.2303) loss_zs_kd 0.0373 (0.0337) loss_oracle 0.6538 (0.6248) kd_loss 0.8145 (0.8264) acc 96.8750 (92.3438) gate/entropy 1.0184 (1.0188) gate/usage_max 0.5281 (0.5276) gate/usage_min 0.2281 (0.2284) gate/usage_std 0.1379 (0.1375) teacher/entropy 0.0147 (0.0502) teacher/usage_max 0.7501 (0.6938) teacher/usage_min 0.0052 (0.0503) teacher/usage_std 0.3105 (0.2726) nleep/row_max_mean 1477.8813 (1475.2015) nleep/row_max_std 59.0880 (54.5606) nleep/row_min_mean 1452.1244 (1450.4662) lr 4.1221e-04 eta 0:03:37
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,167
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 91.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,701
* accuracy: 64.0%
* error: 36.0%
* macro_f1: 59.2%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [38/50] batch [20/176] time 0.083 (0.103) data 0.000 (0.013) loss 1.3039 (1.3750) teacher_loss 0.1352 (0.2234) loss_zs_kd 0.0148 (0.0292) loss_oracle 0.6370 (0.6277) kd_loss 0.8427 (0.8231) acc 93.7500 (91.5625) gate/entropy 1.0186 (1.0185) gate/usage_max 0.5278 (0.5279) gate/usage_min 0.2281 (0.2280) gate/usage_std 0.1376 (0.1378) teacher/entropy 0.0311 (0.0402) teacher/usage_max 0.6924 (0.7097) teacher/usage_min 0.0035 (0.0405) teacher/usage_std 0.2820 (0.2836) nleep/row_max_mean 1471.7552 (1477.6065) nleep/row_max_std 51.9135 (51.8181) nleep/row_min_mean 1447.8345 (1452.1093) lr 3.6258e-04 eta 0:03:52
epoch [38/50] batch [40/176] time 0.093 (0.096) data 0.000 (0.007) loss 1.3483 (1.3753) teacher_loss 0.2288 (0.2195) loss_zs_kd 0.0177 (0.0308) loss_oracle 0.6921 (0.6254) kd_loss 0.7646 (0.8277) acc 90.6250 (91.5625) gate/entropy 1.0185 (1.0186) gate/usage_max 0.5279 (0.5279) gate/usage_min 0.2280 (0.2280) gate/usage_std 0.1377 (0.1377) teacher/entropy 0.0323 (0.0411) teacher/usage_max 0.7952 (0.7023) teacher/usage_min 0.0327 (0.0376) teacher/usage_std 0.3315 (0.2795) nleep/row_max_mean 1478.4987 (1477.3889) nleep/row_max_std 54.8832 (52.2444) nleep/row_min_mean 1449.8573 (1452.1731) lr 3.6258e-04 eta 0:03:36
epoch [38/50] batch [60/176] time 0.096 (0.093) data 0.001 (0.004) loss 1.4099 (1.3742) teacher_loss 0.2137 (0.2135) loss_zs_kd 0.0257 (0.0322) loss_oracle 0.7121 (0.6265) kd_loss 0.8272 (0.8313) acc 93.7500 (92.1354) gate/entropy 1.0188 (1.0186) gate/usage_max 0.5276 (0.5279) gate/usage_min 0.2281 (0.2280) gate/usage_std 0.1375 (0.1377) teacher/entropy 0.0467 (0.0419) teacher/usage_max 0.7004 (0.6968) teacher/usage_min 0.0720 (0.0403) teacher/usage_std 0.2672 (0.2755) nleep/row_max_mean 1457.3833 (1476.4594) nleep/row_max_std 57.8812 (51.9422) nleep/row_min_mean 1435.0956 (1451.4241) lr 3.6258e-04 eta 0:03:27
epoch [38/50] batch [80/176] time 0.097 (0.093) data 0.000 (0.003) loss 1.4170 (1.3732) teacher_loss 0.2058 (0.2143) loss_zs_kd 0.0161 (0.0327) loss_oracle 0.6537 (0.6259) kd_loss 0.8763 (0.8296) acc 90.6250 (92.1484) gate/entropy 1.0182 (1.0185) gate/usage_max 0.5283 (0.5279) gate/usage_min 0.2277 (0.2280) gate/usage_std 0.1380 (0.1378) teacher/entropy 0.0233 (0.0422) teacher/usage_max 0.6612 (0.6987) teacher/usage_min 0.0315 (0.0412) teacher/usage_std 0.2577 (0.2762) nleep/row_max_mean 1471.9993 (1476.4722) nleep/row_max_std 52.5937 (52.4395) nleep/row_min_mean 1448.2795 (1451.5008) lr 3.6258e-04 eta 0:03:25
epoch [38/50] batch [100/176] time 0.087 (0.093) data 0.000 (0.003) loss 1.3350 (1.3851) teacher_loss 0.1936 (0.2283) loss_zs_kd 0.0227 (0.0327) loss_oracle 0.6313 (0.6284) kd_loss 0.8144 (0.8262) acc 93.7500 (91.6562) gate/entropy 1.0183 (1.0185) gate/usage_max 0.5281 (0.5280) gate/usage_min 0.2278 (0.2279) gate/usage_std 0.1379 (0.1378) teacher/entropy 0.0555 (0.0427) teacher/usage_max 0.6982 (0.7025) teacher/usage_min 0.0162 (0.0424) teacher/usage_std 0.2805 (0.2779) nleep/row_max_mean 1489.5796 (1476.6689) nleep/row_max_std 45.2709 (52.4576) nleep/row_min_mean 1463.4540 (1451.6596) lr 3.6258e-04 eta 0:03:24
epoch [38/50] batch [120/176] time 0.089 (0.094) data 0.000 (0.002) loss 1.3089 (1.3834) teacher_loss 0.2204 (0.2237) loss_zs_kd 0.0265 (0.0324) loss_oracle 0.5953 (0.6360) kd_loss 0.7776 (0.8255) acc 93.7500 (92.0052) gate/entropy 1.0181 (1.0184) gate/usage_max 0.5284 (0.5280) gate/usage_min 0.2276 (0.2279) gate/usage_std 0.1381 (0.1378) teacher/entropy 0.0283 (0.0412) teacher/usage_max 0.7809 (0.7052) teacher/usage_min 0.0136 (0.0416) teacher/usage_std 0.3260 (0.2795) nleep/row_max_mean 1459.4978 (1476.5452) nleep/row_max_std 69.3588 (53.1663) nleep/row_min_mean 1436.3806 (1451.4945) lr 3.6258e-04 eta 0:03:23
epoch [38/50] batch [140/176] time 0.103 (0.095) data 0.000 (0.002) loss 1.3269 (1.3887) teacher_loss 0.2628 (0.2274) loss_zs_kd 0.0288 (0.0329) loss_oracle 0.5216 (0.6405) kd_loss 0.7889 (0.8245) acc 93.7500 (91.9643) gate/entropy 1.0177 (1.0184) gate/usage_max 0.5289 (0.5281) gate/usage_min 0.2273 (0.2278) gate/usage_std 0.1384 (0.1379) teacher/entropy 0.0463 (0.0435) teacher/usage_max 0.7444 (0.7035) teacher/usage_min 0.0514 (0.0428) teacher/usage_std 0.2973 (0.2785) nleep/row_max_mean 1491.4163 (1476.1703) nleep/row_max_std 52.2049 (53.6395) nleep/row_min_mean 1463.9788 (1451.2111) lr 3.6258e-04 eta 0:03:23
epoch [38/50] batch [160/176] time 0.101 (0.095) data 0.000 (0.002) loss 1.3684 (1.3923) teacher_loss 0.1716 (0.2281) loss_zs_kd 0.0330 (0.0330) loss_oracle 0.6747 (0.6435) kd_loss 0.8429 (0.8259) acc 93.7500 (91.9727) gate/entropy 1.0183 (1.0184) gate/usage_max 0.5282 (0.5281) gate/usage_min 0.2277 (0.2278) gate/usage_std 0.1379 (0.1379) teacher/entropy 0.0213 (0.0450) teacher/usage_max 0.7107 (0.7000) teacher/usage_min 0.0625 (0.0448) teacher/usage_std 0.2751 (0.2762) nleep/row_max_mean 1464.7278 (1475.9333) nleep/row_max_std 64.3770 (53.4346) nleep/row_min_mean 1441.4600 (1451.1207) lr 3.6258e-04 eta 0:03:22
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,163
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,638
* accuracy: 61.7%
* error: 38.3%
* macro_f1: 57.1%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [39/50] batch [20/176] time 0.163 (0.123) data 0.002 (0.015) loss 1.3118 (1.3508) teacher_loss 0.1782 (0.2199) loss_zs_kd 0.0431 (0.0287) loss_oracle 0.6058 (0.6288) kd_loss 0.8092 (0.8022) acc 90.6250 (91.5625) gate/entropy 1.0182 (1.0180) gate/usage_max 0.5283 (0.5285) gate/usage_min 0.2275 (0.2275) gate/usage_std 0.1380 (0.1382) teacher/entropy 0.0627 (0.0443) teacher/usage_max 0.6948 (0.7305) teacher/usage_min 0.0052 (0.0396) teacher/usage_std 0.2825 (0.2941) nleep/row_max_mean 1479.0007 (1475.0946) nleep/row_max_std 55.6617 (56.4121) nleep/row_min_mean 1455.2361 (1450.9086) lr 3.1545e-04 eta 0:04:17
epoch [39/50] batch [40/176] time 0.092 (0.111) data 0.000 (0.008) loss 1.1650 (1.3659) teacher_loss 0.0896 (0.2273) loss_zs_kd 0.0196 (0.0306) loss_oracle 0.6653 (0.6382) kd_loss 0.7330 (0.8042) acc 93.7500 (91.8750) gate/entropy 1.0176 (1.0180) gate/usage_max 0.5290 (0.5286) gate/usage_min 0.2272 (0.2274) gate/usage_std 0.1385 (0.1382) teacher/entropy 0.0673 (0.0455) teacher/usage_max 0.7858 (0.7266) teacher/usage_min 0.0003 (0.0434) teacher/usage_std 0.3316 (0.2912) nleep/row_max_mean 1484.9226 (1474.3092) nleep/row_max_std 53.8666 (55.4961) nleep/row_min_mean 1458.2085 (1450.2763) lr 3.1545e-04 eta 0:03:50
epoch [39/50] batch [60/176] time 0.082 (0.104) data 0.000 (0.005) loss 1.2084 (1.3787) teacher_loss 0.1440 (0.2394) loss_zs_kd 0.0198 (0.0302) loss_oracle 0.5861 (0.6441) kd_loss 0.7614 (0.8022) acc 96.8750 (91.7188) gate/entropy 1.0176 (1.0180) gate/usage_max 0.5291 (0.5286) gate/usage_min 0.2271 (0.2274) gate/usage_std 0.1386 (0.1382) teacher/entropy 0.0161 (0.0496) teacher/usage_max 0.8151 (0.7243) teacher/usage_min 0.0000 (0.0468) teacher/usage_std 0.3489 (0.2890) nleep/row_max_mean 1483.8833 (1474.5643) nleep/row_max_std 43.8346 (54.6186) nleep/row_min_mean 1458.7742 (1450.5060) lr 3.1545e-04 eta 0:03:34
epoch [39/50] batch [80/176] time 0.091 (0.101) data 0.000 (0.004) loss 1.4617 (1.3822) teacher_loss 0.2348 (0.2374) loss_zs_kd 0.0501 (0.0310) loss_oracle 0.6686 (0.6465) kd_loss 0.8676 (0.8059) acc 87.5000 (91.4844) gate/entropy 1.0180 (1.0180) gate/usage_max 0.5285 (0.5286) gate/usage_min 0.2274 (0.2274) gate/usage_std 0.1382 (0.1382) teacher/entropy 0.0368 (0.0489) teacher/usage_max 0.6551 (0.7203) teacher/usage_min 0.0437 (0.0468) teacher/usage_std 0.2506 (0.2874) nleep/row_max_mean 1473.8311 (1475.4920) nleep/row_max_std 53.4857 (54.0106) nleep/row_min_mean 1449.5684 (1451.2608) lr 3.1545e-04 eta 0:03:24
epoch [39/50] batch [100/176] time 0.096 (0.097) data 0.000 (0.003) loss 1.5604 (1.3779) teacher_loss 0.1713 (0.2312) loss_zs_kd 0.0467 (0.0322) loss_oracle 0.8359 (0.6447) kd_loss 0.9478 (0.8083) acc 90.6250 (91.9062) gate/entropy 1.0179 (1.0179) gate/usage_max 0.5286 (0.5286) gate/usage_min 0.2274 (0.2274) gate/usage_std 0.1383 (0.1382) teacher/entropy 0.0437 (0.0484) teacher/usage_max 0.5439 (0.7180) teacher/usage_min 0.0546 (0.0482) teacher/usage_std 0.2055 (0.2859) nleep/row_max_mean 1450.3209 (1475.9350) nleep/row_max_std 73.3539 (54.1462) nleep/row_min_mean 1429.2977 (1451.5959) lr 3.1545e-04 eta 0:03:16
epoch [39/50] batch [120/176] time 0.098 (0.097) data 0.000 (0.003) loss 1.3187 (1.3773) teacher_loss 0.2980 (0.2298) loss_zs_kd 0.0207 (0.0318) loss_oracle 0.5777 (0.6453) kd_loss 0.7216 (0.8089) acc 87.5000 (91.9010) gate/entropy 1.0176 (1.0179) gate/usage_max 0.5290 (0.5286) gate/usage_min 0.2271 (0.2274) gate/usage_std 0.1385 (0.1383) teacher/entropy 0.0703 (0.0496) teacher/usage_max 0.7984 (0.7159) teacher/usage_min 0.0092 (0.0502) teacher/usage_std 0.3372 (0.2849) nleep/row_max_mean 1473.1216 (1475.6101) nleep/row_max_std 63.3543 (54.0535) nleep/row_min_mean 1449.7231 (1451.2709) lr 3.1545e-04 eta 0:03:12
epoch [39/50] batch [140/176] time 0.097 (0.097) data 0.000 (0.002) loss 1.2975 (1.3767) teacher_loss 0.1637 (0.2322) loss_zs_kd 0.0533 (0.0319) loss_oracle 0.5678 (0.6402) kd_loss 0.8233 (0.8085) acc 93.7500 (91.8080) gate/entropy 1.0176 (1.0179) gate/usage_max 0.5291 (0.5287) gate/usage_min 0.2271 (0.2274) gate/usage_std 0.1386 (0.1383) teacher/entropy 0.0563 (0.0494) teacher/usage_max 0.6908 (0.7166) teacher/usage_min 0.0613 (0.0502) teacher/usage_std 0.2640 (0.2852) nleep/row_max_mean 1472.6440 (1475.8969) nleep/row_max_std 51.2098 (53.7352) nleep/row_min_mean 1448.9841 (1451.5666) lr 3.1545e-04 eta 0:03:11
epoch [39/50] batch [160/176] time 0.080 (0.097) data 0.000 (0.002) loss 1.4694 (1.3795) teacher_loss 0.3125 (0.2350) loss_zs_kd 0.0217 (0.0323) loss_oracle 0.6392 (0.6415) kd_loss 0.8264 (0.8076) acc 87.5000 (91.6211) gate/entropy 1.0179 (1.0179) gate/usage_max 0.5286 (0.5287) gate/usage_min 0.2273 (0.2273) gate/usage_std 0.1383 (0.1383) teacher/entropy 0.0358 (0.0506) teacher/usage_max 0.7193 (0.7164) teacher/usage_min 0.1264 (0.0518) teacher/usage_std 0.2732 (0.2847) nleep/row_max_mean 1460.5757 (1475.7529) nleep/row_max_std 55.9181 (53.8837) nleep/row_min_mean 1437.5122 (1451.4005) lr 3.1545e-04 eta 0:03:08
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,163
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.2%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,631
* accuracy: 61.4%
* error: 38.6%
* macro_f1: 56.7%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [40/50] batch [20/176] time 0.095 (0.108) data 0.000 (0.014) loss 1.3870 (1.4107) teacher_loss 0.2450 (0.2590) loss_zs_kd 0.0561 (0.0318) loss_oracle 0.5645 (0.6393) kd_loss 0.8317 (0.8162) acc 96.8750 (91.5625) gate/entropy 1.0174 (1.0177) gate/usage_max 0.5292 (0.5289) gate/usage_min 0.2270 (0.2272) gate/usage_std 0.1387 (0.1385) teacher/entropy 0.0788 (0.0562) teacher/usage_max 0.6498 (0.6988) teacher/usage_min 0.0655 (0.0601) teacher/usage_std 0.2410 (0.2717) nleep/row_max_mean 1490.4340 (1476.5834) nleep/row_max_std 45.7768 (52.5460) nleep/row_min_mean 1465.9011 (1452.6956) lr 2.7103e-04 eta 0:03:26
epoch [40/50] batch [40/176] time 0.094 (0.101) data 0.000 (0.007) loss 1.2170 (1.3912) teacher_loss 0.1286 (0.2547) loss_zs_kd 0.0223 (0.0327) loss_oracle 0.6286 (0.6405) kd_loss 0.7630 (0.7999) acc 93.7500 (91.9531) gate/entropy 1.0178 (1.0177) gate/usage_max 0.5288 (0.5290) gate/usage_min 0.2273 (0.2272) gate/usage_std 0.1384 (0.1385) teacher/entropy 0.0904 (0.0607) teacher/usage_max 0.7300 (0.7133) teacher/usage_min 0.1284 (0.0536) teacher/usage_std 0.2805 (0.2816) nleep/row_max_mean 1474.7322 (1475.1198) nleep/row_max_std 47.4347 (53.8551) nleep/row_min_mean 1448.5154 (1451.3541) lr 2.7103e-04 eta 0:03:10
epoch [40/50] batch [60/176] time 0.091 (0.098) data 0.001 (0.005) loss 1.3670 (1.3868) teacher_loss 0.3530 (0.2504) loss_zs_kd 0.0313 (0.0319) loss_oracle 0.5425 (0.6420) kd_loss 0.7271 (0.7995) acc 87.5000 (92.0833) gate/entropy 1.0173 (1.0177) gate/usage_max 0.5294 (0.5290) gate/usage_min 0.2269 (0.2271) gate/usage_std 0.1388 (0.1385) teacher/entropy 0.0810 (0.0606) teacher/usage_max 0.7825 (0.7142) teacher/usage_min 0.0722 (0.0564) teacher/usage_std 0.3190 (0.2815) nleep/row_max_mean 1494.0094 (1474.6053) nleep/row_max_std 48.8791 (53.6504) nleep/row_min_mean 1469.7249 (1450.8237) lr 2.7103e-04 eta 0:03:04
epoch [40/50] batch [80/176] time 0.093 (0.097) data 0.000 (0.004) loss 1.2534 (1.3749) teacher_loss 0.1039 (0.2412) loss_zs_kd 0.0193 (0.0317) loss_oracle 0.6737 (0.6384) kd_loss 0.8030 (0.7986) acc 93.7500 (91.9922) gate/entropy 1.0170 (1.0176) gate/usage_max 0.5298 (0.5291) gate/usage_min 0.2267 (0.2271) gate/usage_std 0.1391 (0.1386) teacher/entropy 0.0742 (0.0572) teacher/usage_max 0.6905 (0.7193) teacher/usage_min 0.0507 (0.0537) teacher/usage_std 0.2665 (0.2850) nleep/row_max_mean 1489.3977 (1475.3522) nleep/row_max_std 48.6848 (53.8990) nleep/row_min_mean 1462.7996 (1451.4482) lr 2.7103e-04 eta 0:03:00
epoch [40/50] batch [100/176] time 0.102 (0.097) data 0.000 (0.003) loss 1.3611 (1.3791) teacher_loss 0.2000 (0.2431) loss_zs_kd 0.0179 (0.0315) loss_oracle 0.6532 (0.6444) kd_loss 0.8256 (0.7981) acc 93.7500 (91.5312) gate/entropy 1.0175 (1.0175) gate/usage_max 0.5292 (0.5291) gate/usage_min 0.2270 (0.2271) gate/usage_std 0.1386 (0.1386) teacher/entropy 0.0762 (0.0563) teacher/usage_max 0.6663 (0.7209) teacher/usage_min 0.1156 (0.0534) teacher/usage_std 0.2391 (0.2859) nleep/row_max_mean 1470.2910 (1475.6822) nleep/row_max_std 56.9851 (54.1660) nleep/row_min_mean 1450.0625 (1451.7568) lr 2.7103e-04 eta 0:02:57
epoch [40/50] batch [120/176] time 0.097 (0.097) data 0.000 (0.003) loss 1.2776 (1.3834) teacher_loss 0.2777 (0.2524) loss_zs_kd 0.0280 (0.0315) loss_oracle 0.5807 (0.6415) kd_loss 0.6955 (0.7944) acc 84.3750 (91.2240) gate/entropy 1.0165 (1.0175) gate/usage_max 0.5304 (0.5292) gate/usage_min 0.2265 (0.2270) gate/usage_std 0.1395 (0.1387) teacher/entropy 0.0458 (0.0567) teacher/usage_max 0.8647 (0.7255) teacher/usage_min 0.0433 (0.0562) teacher/usage_std 0.3763 (0.2883) nleep/row_max_mean 1480.0883 (1475.6470) nleep/row_max_std 61.3661 (53.9435) nleep/row_min_mean 1455.1572 (1451.8821) lr 2.7103e-04 eta 0:02:55
epoch [40/50] batch [140/176] time 0.173 (0.099) data 0.001 (0.002) loss 1.4931 (1.3767) teacher_loss 0.2371 (0.2469) loss_zs_kd 0.0359 (0.0315) loss_oracle 0.7468 (0.6410) kd_loss 0.8647 (0.7936) acc 90.6250 (91.3393) gate/entropy 1.0172 (1.0174) gate/usage_max 0.5295 (0.5292) gate/usage_min 0.2269 (0.2270) gate/usage_std 0.1389 (0.1387) teacher/entropy 0.1003 (0.0577) teacher/usage_max 0.5816 (0.7254) teacher/usage_min 0.0809 (0.0567) teacher/usage_std 0.2044 (0.2880) nleep/row_max_mean 1458.7557 (1475.2041) nleep/row_max_std 60.2966 (54.0716) nleep/row_min_mean 1438.4548 (1451.5739) lr 2.7103e-04 eta 0:02:57
epoch [40/50] batch [160/176] time 0.107 (0.098) data 0.000 (0.002) loss 1.3247 (1.3824) teacher_loss 0.2426 (0.2506) loss_zs_kd 0.0340 (0.0319) loss_oracle 0.5411 (0.6403) kd_loss 0.7946 (0.7957) acc 90.6250 (91.3086) gate/entropy 1.0174 (1.0174) gate/usage_max 0.5293 (0.5293) gate/usage_min 0.2269 (0.2270) gate/usage_std 0.1387 (0.1387) teacher/entropy 0.0325 (0.0575) teacher/usage_max 0.7535 (0.7227) teacher/usage_min 0.0322 (0.0554) teacher/usage_std 0.3062 (0.2870) nleep/row_max_mean 1481.3374 (1475.2355) nleep/row_max_std 45.7734 (53.8865) nleep/row_min_mean 1457.2656 (1451.6584) lr 2.7103e-04 eta 0:02:54
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,170
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.4%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,607
* accuracy: 60.5%
* error: 39.5%
* macro_f1: 56.3%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [41/50] batch [20/176] time 0.086 (0.107) data 0.000 (0.015) loss 1.1870 (1.3331) teacher_loss 0.1507 (0.2218) loss_zs_kd 0.0367 (0.0264) loss_oracle 0.6168 (0.6032) kd_loss 0.7095 (0.7965) acc 93.7500 (92.3438) gate/entropy 1.0173 (1.0171) gate/usage_max 0.5294 (0.5297) gate/usage_min 0.2269 (0.2268) gate/usage_std 0.1388 (0.1390) teacher/entropy 0.1095 (0.0507) teacher/usage_max 0.7643 (0.7301) teacher/usage_min 0.0412 (0.0515) teacher/usage_std 0.3111 (0.2908) nleep/row_max_mean 1488.7849 (1475.8321) nleep/row_max_std 45.9903 (53.7586) nleep/row_min_mean 1465.5770 (1452.4225) lr 2.2949e-04 eta 0:03:06
epoch [41/50] batch [40/176] time 0.087 (0.096) data 0.000 (0.007) loss 1.2690 (1.3487) teacher_loss 0.1541 (0.2289) loss_zs_kd 0.0217 (0.0281) loss_oracle 0.4952 (0.6192) kd_loss 0.8565 (0.7962) acc 96.8750 (92.0312) gate/entropy 1.0169 (1.0171) gate/usage_max 0.5299 (0.5296) gate/usage_min 0.2267 (0.2268) gate/usage_std 0.1391 (0.1390) teacher/entropy 0.0588 (0.0574) teacher/usage_max 0.6386 (0.7213) teacher/usage_min 0.0432 (0.0476) teacher/usage_std 0.2433 (0.2868) nleep/row_max_mean 1482.8147 (1473.7560) nleep/row_max_std 49.6452 (54.6416) nleep/row_min_mean 1460.0719 (1451.0217) lr 2.2949e-04 eta 0:02:45
epoch [41/50] batch [60/176] time 0.097 (0.092) data 0.001 (0.005) loss 1.4143 (1.3618) teacher_loss 0.1788 (0.2472) loss_zs_kd 0.0269 (0.0274) loss_oracle 0.7673 (0.6248) kd_loss 0.8385 (0.7886) acc 90.6250 (91.4062) gate/entropy 1.0172 (1.0171) gate/usage_max 0.5295 (0.5296) gate/usage_min 0.2268 (0.2268) gate/usage_std 0.1389 (0.1390) teacher/entropy 0.0636 (0.0580) teacher/usage_max 0.6627 (0.7302) teacher/usage_min 0.0938 (0.0455) teacher/usage_std 0.2408 (0.2922) nleep/row_max_mean 1467.1392 (1473.0270) nleep/row_max_std 53.1164 (54.2320) nleep/row_min_mean 1445.6133 (1450.2201) lr 2.2949e-04 eta 0:02:36
epoch [41/50] batch [80/176] time 0.094 (0.093) data 0.000 (0.004) loss 1.3664 (1.3618) teacher_loss 0.1977 (0.2475) loss_zs_kd 0.0259 (0.0279) loss_oracle 0.6040 (0.6234) kd_loss 0.8538 (0.7887) acc 90.6250 (91.3281) gate/entropy 1.0168 (1.0171) gate/usage_max 0.5300 (0.5297) gate/usage_min 0.2266 (0.2268) gate/usage_std 0.1392 (0.1390) teacher/entropy 0.0286 (0.0585) teacher/usage_max 0.6871 (0.7294) teacher/usage_min 0.0931 (0.0456) teacher/usage_std 0.2554 (0.2919) nleep/row_max_mean 1473.1968 (1474.0746) nleep/row_max_std 55.1784 (53.7962) nleep/row_min_mean 1450.9602 (1451.1657) lr 2.2949e-04 eta 0:02:36
epoch [41/50] batch [100/176] time 0.096 (0.093) data 0.000 (0.003) loss 1.4668 (1.3643) teacher_loss 0.3992 (0.2506) loss_zs_kd 0.0241 (0.0288) loss_oracle 0.5740 (0.6218) kd_loss 0.7685 (0.7885) acc 90.6250 (91.4688) gate/entropy 1.0170 (1.0171) gate/usage_max 0.5298 (0.5297) gate/usage_min 0.2266 (0.2268) gate/usage_std 0.1391 (0.1390) teacher/entropy 0.0555 (0.0598) teacher/usage_max 0.7570 (0.7279) teacher/usage_min 0.0153 (0.0457) teacher/usage_std 0.3119 (0.2911) nleep/row_max_mean 1485.9822 (1474.1507) nleep/row_max_std 43.7188 (53.7931) nleep/row_min_mean 1459.4148 (1451.1878) lr 2.2949e-04 eta 0:02:34
epoch [41/50] batch [120/176] time 0.095 (0.094) data 0.000 (0.003) loss 1.4345 (1.3607) teacher_loss 0.2391 (0.2486) loss_zs_kd 0.0465 (0.0291) loss_oracle 0.6715 (0.6213) kd_loss 0.8363 (0.7868) acc 93.7500 (91.3802) gate/entropy 1.0170 (1.0170) gate/usage_max 0.5297 (0.5297) gate/usage_min 0.2267 (0.2267) gate/usage_std 0.1390 (0.1390) teacher/entropy 0.0672 (0.0608) teacher/usage_max 0.6570 (0.7285) teacher/usage_min 0.0432 (0.0450) teacher/usage_std 0.2517 (0.2917) nleep/row_max_mean 1475.3938 (1474.5308) nleep/row_max_std 52.4765 (53.8743) nleep/row_min_mean 1450.5161 (1451.5140) lr 2.2949e-04 eta 0:02:33
epoch [41/50] batch [140/176] time 0.104 (0.094) data 0.000 (0.002) loss 1.3068 (1.3544) teacher_loss 0.0778 (0.2430) loss_zs_kd 0.0195 (0.0289) loss_oracle 0.7469 (0.6232) kd_loss 0.8459 (0.7854) acc 96.8750 (91.6071) gate/entropy 1.0170 (1.0170) gate/usage_max 0.5298 (0.5298) gate/usage_min 0.2267 (0.2267) gate/usage_std 0.1391 (0.1391) teacher/entropy 0.0700 (0.0614) teacher/usage_max 0.6419 (0.7296) teacher/usage_min 0.0701 (0.0452) teacher/usage_std 0.2356 (0.2921) nleep/row_max_mean 1446.8541 (1474.5746) nleep/row_max_std 71.1842 (54.1935) nleep/row_min_mean 1427.2336 (1451.6059) lr 2.2949e-04 eta 0:02:32
epoch [41/50] batch [160/176] time 0.092 (0.094) data 0.000 (0.002) loss 1.3091 (1.3577) teacher_loss 0.2167 (0.2448) loss_zs_kd 0.0219 (0.0293) loss_oracle 0.5635 (0.6247) kd_loss 0.7997 (0.7859) acc 90.6250 (91.5820) gate/entropy 1.0170 (1.0170) gate/usage_max 0.5297 (0.5298) gate/usage_min 0.2267 (0.2267) gate/usage_std 0.1391 (0.1391) teacher/entropy 0.0817 (0.0625) teacher/usage_max 0.6813 (0.7274) teacher/usage_min 0.0074 (0.0445) teacher/usage_std 0.2756 (0.2912) nleep/row_max_mean 1461.8362 (1474.2515) nleep/row_max_std 63.8668 (54.1821) nleep/row_min_mean 1438.7750 (1451.2469) lr 2.2949e-04 eta 0:02:31
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,640
* accuracy: 61.7%
* error: 38.3%
* macro_f1: 56.9%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [42/50] batch [20/176] time 0.087 (0.111) data 0.000 (0.016) loss 1.2584 (1.3526) teacher_loss 0.2226 (0.2225) loss_zs_kd 0.0194 (0.0336) loss_oracle 0.5702 (0.6347) kd_loss 0.7410 (0.7960) acc 90.6250 (91.7188) gate/entropy 1.0166 (1.0168) gate/usage_max 0.5303 (0.5301) gate/usage_min 0.2264 (0.2265) gate/usage_std 0.1395 (0.1393) teacher/entropy 0.0954 (0.0562) teacher/usage_max 0.7396 (0.7210) teacher/usage_min 0.0225 (0.0323) teacher/usage_std 0.3004 (0.2902) nleep/row_max_mean 1482.8459 (1477.1540) nleep/row_max_std 54.0357 (50.4565) nleep/row_min_mean 1457.9875 (1453.5790) lr 1.9098e-04 eta 0:02:53
epoch [42/50] batch [40/176] time 0.095 (0.111) data 0.000 (0.008) loss 1.5304 (1.3580) teacher_loss 0.3957 (0.2295) loss_zs_kd 0.0360 (0.0317) loss_oracle 0.6262 (0.6265) kd_loss 0.8036 (0.7995) acc 84.3750 (91.7188) gate/entropy 1.0163 (1.0166) gate/usage_max 0.5306 (0.5302) gate/usage_min 0.2262 (0.2264) gate/usage_std 0.1396 (0.1394) teacher/entropy 0.0555 (0.0589) teacher/usage_max 0.7138 (0.7136) teacher/usage_min 0.0661 (0.0405) teacher/usage_std 0.2763 (0.2846) nleep/row_max_mean 1473.8994 (1477.6932) nleep/row_max_std 64.5413 (52.2515) nleep/row_min_mean 1450.9412 (1454.0676) lr 1.9098e-04 eta 0:02:51
epoch [42/50] batch [60/176] time 0.097 (0.108) data 0.001 (0.005) loss 1.4721 (1.3633) teacher_loss 0.4427 (0.2409) loss_zs_kd 0.0187 (0.0313) loss_oracle 0.5351 (0.6237) kd_loss 0.7525 (0.7949) acc 84.3750 (91.7708) gate/entropy 1.0170 (1.0166) gate/usage_max 0.5297 (0.5302) gate/usage_min 0.2266 (0.2264) gate/usage_std 0.1390 (0.1394) teacher/entropy 0.0465 (0.0571) teacher/usage_max 0.7926 (0.7217) teacher/usage_min 0.0568 (0.0407) teacher/usage_std 0.3270 (0.2891) nleep/row_max_mean 1460.1597 (1475.5728) nleep/row_max_std 53.7707 (53.2372) nleep/row_min_mean 1435.3115 (1452.0903) lr 1.9098e-04 eta 0:02:44
epoch [42/50] batch [80/176] time 0.094 (0.105) data 0.000 (0.004) loss 1.3460 (1.3586) teacher_loss 0.1995 (0.2404) loss_zs_kd 0.0252 (0.0303) loss_oracle 0.6240 (0.6236) kd_loss 0.8219 (0.7912) acc 93.7500 (91.6797) gate/entropy 1.0164 (1.0166) gate/usage_max 0.5304 (0.5302) gate/usage_min 0.2263 (0.2264) gate/usage_std 0.1395 (0.1394) teacher/entropy 0.0578 (0.0590) teacher/usage_max 0.6855 (0.7239) teacher/usage_min 0.0333 (0.0399) teacher/usage_std 0.2688 (0.2905) nleep/row_max_mean 1456.5149 (1474.9553) nleep/row_max_std 66.1704 (54.0605) nleep/row_min_mean 1434.9973 (1451.4885) lr 1.9098e-04 eta 0:02:37
epoch [42/50] batch [100/176] time 0.092 (0.103) data 0.000 (0.003) loss 1.2418 (1.3638) teacher_loss 0.1143 (0.2381) loss_zs_kd 0.0333 (0.0306) loss_oracle 0.6113 (0.6246) kd_loss 0.8052 (0.7981) acc 93.7500 (91.5000) gate/entropy 1.0163 (1.0166) gate/usage_max 0.5307 (0.5303) gate/usage_min 0.2262 (0.2264) gate/usage_std 0.1397 (0.1394) teacher/entropy 0.0419 (0.0585) teacher/usage_max 0.7308 (0.7156) teacher/usage_min 0.0935 (0.0405) teacher/usage_std 0.2830 (0.2863) nleep/row_max_mean 1487.3152 (1475.6691) nleep/row_max_std 58.6023 (53.8584) nleep/row_min_mean 1463.3555 (1452.3017) lr 1.9098e-04 eta 0:02:32
epoch [42/50] batch [120/176] time 0.090 (0.102) data 0.000 (0.003) loss 1.2848 (1.3703) teacher_loss 0.1280 (0.2367) loss_zs_kd 0.0358 (0.0309) loss_oracle 0.6660 (0.6284) kd_loss 0.8059 (0.8039) acc 93.7500 (91.5104) gate/entropy 1.0163 (1.0166) gate/usage_max 0.5307 (0.5302) gate/usage_min 0.2261 (0.2264) gate/usage_std 0.1397 (0.1394) teacher/entropy 0.1135 (0.0578) teacher/usage_max 0.6376 (0.7093) teacher/usage_min 0.0661 (0.0403) teacher/usage_std 0.2348 (0.2836) nleep/row_max_mean 1489.1542 (1475.6595) nleep/row_max_std 53.6160 (53.8026) nleep/row_min_mean 1465.7664 (1452.2922) lr 1.9098e-04 eta 0:02:28
epoch [42/50] batch [140/176] time 0.091 (0.101) data 0.000 (0.002) loss 1.3913 (1.3772) teacher_loss 0.2972 (0.2405) loss_zs_kd 0.0429 (0.0312) loss_oracle 0.5497 (0.6280) kd_loss 0.7978 (0.8071) acc 84.3750 (91.3393) gate/entropy 1.0165 (1.0166) gate/usage_max 0.5303 (0.5302) gate/usage_min 0.2262 (0.2264) gate/usage_std 0.1395 (0.1394) teacher/entropy 0.1274 (0.0589) teacher/usage_max 0.6247 (0.7037) teacher/usage_min 0.0096 (0.0387) teacher/usage_std 0.2522 (0.2812) nleep/row_max_mean 1480.4944 (1475.9028) nleep/row_max_std 44.5082 (53.3516) nleep/row_min_mean 1457.9614 (1452.5552) lr 1.9098e-04 eta 0:02:25
epoch [42/50] batch [160/176] time 0.092 (0.100) data 0.000 (0.002) loss 1.4211 (1.3743) teacher_loss 0.2459 (0.2394) loss_zs_kd 0.0165 (0.0315) loss_oracle 0.6947 (0.6245) kd_loss 0.8196 (0.8069) acc 84.3750 (91.3281) gate/entropy 1.0165 (1.0166) gate/usage_max 0.5304 (0.5302) gate/usage_min 0.2262 (0.2264) gate/usage_std 0.1395 (0.1394) teacher/entropy 0.0760 (0.0601) teacher/usage_max 0.6700 (0.7025) teacher/usage_min 0.0973 (0.0397) teacher/usage_std 0.2444 (0.2801) nleep/row_max_mean 1485.7695 (1476.1938) nleep/row_max_std 48.1233 (52.8109) nleep/row_min_mean 1464.1975 (1452.8244) lr 1.9098e-04 eta 0:02:22
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,176
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,638
* accuracy: 61.7%
* error: 38.3%
* macro_f1: 57.0%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [43/50] batch [20/176] time 0.091 (0.107) data 0.000 (0.015) loss 1.3658 (1.3976) teacher_loss 0.2118 (0.2633) loss_zs_kd 0.0261 (0.0284) loss_oracle 0.6325 (0.6127) kd_loss 0.8248 (0.8137) acc 87.5000 (90.3125) gate/entropy 1.0164 (1.0165) gate/usage_max 0.5305 (0.5303) gate/usage_min 0.2261 (0.2262) gate/usage_std 0.1396 (0.1395) teacher/entropy 0.0537 (0.0533) teacher/usage_max 0.6889 (0.7030) teacher/usage_min 0.0530 (0.0496) teacher/usage_std 0.2650 (0.2774) nleep/row_max_mean 1494.3475 (1477.7114) nleep/row_max_std 45.5334 (52.0150) nleep/row_min_mean 1468.6556 (1454.3994) lr 1.5567e-04 eta 0:02:28
epoch [43/50] batch [40/176] time 0.095 (0.100) data 0.000 (0.007) loss 1.5896 (1.3734) teacher_loss 0.5740 (0.2571) loss_zs_kd 0.0259 (0.0274) loss_oracle 0.6263 (0.6115) kd_loss 0.6895 (0.7969) acc 87.5000 (90.6250) gate/entropy 1.0158 (1.0164) gate/usage_max 0.5313 (0.5304) gate/usage_min 0.2257 (0.2261) gate/usage_std 0.1401 (0.1395) teacher/entropy 0.0674 (0.0531) teacher/usage_max 0.8410 (0.7246) teacher/usage_min 0.0192 (0.0442) teacher/usage_std 0.3623 (0.2901) nleep/row_max_mean 1478.5587 (1477.1770) nleep/row_max_std 57.4141 (52.5654) nleep/row_min_mean 1456.8893 (1454.0250) lr 1.5567e-04 eta 0:02:17
epoch [43/50] batch [60/176] time 0.099 (0.098) data 0.000 (0.005) loss 1.1609 (1.3716) teacher_loss 0.2102 (0.2598) loss_zs_kd 0.0094 (0.0272) loss_oracle 0.5423 (0.6051) kd_loss 0.6747 (0.7956) acc 93.7500 (90.4167) gate/entropy 1.0162 (1.0164) gate/usage_max 0.5308 (0.5305) gate/usage_min 0.2260 (0.2261) gate/usage_std 0.1398 (0.1396) teacher/entropy 0.0855 (0.0550) teacher/usage_max 0.8393 (0.7234) teacher/usage_min 0.0347 (0.0421) teacher/usage_std 0.3597 (0.2908) nleep/row_max_mean 1470.5151 (1475.1684) nleep/row_max_std 59.7184 (53.6051) nleep/row_min_mean 1448.0977 (1452.0994) lr 1.5567e-04 eta 0:02:12
epoch [43/50] batch [80/176] time 0.087 (0.098) data 0.000 (0.004) loss 1.4488 (1.3940) teacher_loss 0.3749 (0.2708) loss_zs_kd 0.0368 (0.0274) loss_oracle 0.5247 (0.6140) kd_loss 0.7931 (0.8026) acc 84.3750 (90.2344) gate/entropy 1.0163 (1.0164) gate/usage_max 0.5307 (0.5305) gate/usage_min 0.2260 (0.2261) gate/usage_std 0.1397 (0.1396) teacher/entropy 0.0468 (0.0557) teacher/usage_max 0.7327 (0.7139) teacher/usage_min 0.0001 (0.0449) teacher/usage_std 0.3027 (0.2847) nleep/row_max_mean 1483.5565 (1475.5938) nleep/row_max_std 44.3545 (53.1816) nleep/row_min_mean 1459.9927 (1452.4477) lr 1.5567e-04 eta 0:02:09
epoch [43/50] batch [100/176] time 0.096 (0.097) data 0.000 (0.003) loss 1.3343 (1.3853) teacher_loss 0.1428 (0.2631) loss_zs_kd 0.0470 (0.0272) loss_oracle 0.7101 (0.6131) kd_loss 0.8130 (0.8021) acc 96.8750 (90.5000) gate/entropy 1.0164 (1.0164) gate/usage_max 0.5305 (0.5305) gate/usage_min 0.2261 (0.2261) gate/usage_std 0.1396 (0.1396) teacher/entropy 0.0976 (0.0579) teacher/usage_max 0.6526 (0.7115) teacher/usage_min 0.1103 (0.0448) teacher/usage_std 0.2316 (0.2833) nleep/row_max_mean 1478.0063 (1476.1725) nleep/row_max_std 46.4859 (52.9496) nleep/row_min_mean 1457.4398 (1452.9846) lr 1.5567e-04 eta 0:02:07
epoch [43/50] batch [120/176] time 0.104 (0.097) data 0.000 (0.003) loss 1.3499 (1.3785) teacher_loss 0.1563 (0.2508) loss_zs_kd 0.0328 (0.0279) loss_oracle 0.6729 (0.6161) kd_loss 0.8408 (0.8057) acc 93.7500 (91.0417) gate/entropy 1.0164 (1.0164) gate/usage_max 0.5305 (0.5304) gate/usage_min 0.2260 (0.2261) gate/usage_std 0.1396 (0.1395) teacher/entropy 0.0702 (0.0574) teacher/usage_max 0.6488 (0.7076) teacher/usage_min 0.0617 (0.0459) teacher/usage_std 0.2417 (0.2808) nleep/row_max_mean 1484.3956 (1476.2877) nleep/row_max_std 53.9121 (52.6958) nleep/row_min_mean 1460.4619 (1452.9877) lr 1.5567e-04 eta 0:02:04
epoch [43/50] batch [140/176] time 0.099 (0.099) data 0.002 (0.002) loss 1.2748 (1.3809) teacher_loss 0.2073 (0.2500) loss_zs_kd 0.0379 (0.0282) loss_oracle 0.5593 (0.6195) kd_loss 0.7688 (0.8070) acc 87.5000 (90.9821) gate/entropy 1.0163 (1.0165) gate/usage_max 0.5306 (0.5304) gate/usage_min 0.2260 (0.2261) gate/usage_std 0.1397 (0.1395) teacher/entropy 0.1022 (0.0589) teacher/usage_max 0.6966 (0.7039) teacher/usage_min 0.0333 (0.0454) teacher/usage_std 0.2744 (0.2791) nleep/row_max_mean 1476.5337 (1475.9185) nleep/row_max_std 54.7364 (52.8664) nleep/row_min_mean 1453.6912 (1452.6188) lr 1.5567e-04 eta 0:02:04
epoch [43/50] batch [160/176] time 0.156 (0.098) data 0.000 (0.002) loss 1.2347 (1.3791) teacher_loss 0.1424 (0.2460) loss_zs_kd 0.0070 (0.0285) loss_oracle 0.6557 (0.6202) kd_loss 0.7610 (0.8088) acc 96.8750 (91.2500) gate/entropy 1.0163 (1.0165) gate/usage_max 0.5306 (0.5304) gate/usage_min 0.2260 (0.2261) gate/usage_std 0.1397 (0.1395) teacher/entropy 0.0435 (0.0597) teacher/usage_max 0.7832 (0.7006) teacher/usage_min 0.0355 (0.0453) teacher/usage_std 0.3236 (0.2774) nleep/row_max_mean 1472.4607 (1475.9060) nleep/row_max_std 57.3199 (52.7819) nleep/row_min_mean 1447.8168 (1452.5943) lr 1.5567e-04 eta 0:02:02
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,624
* accuracy: 61.1%
* error: 38.9%
* macro_f1: 56.7%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [44/50] batch [20/176] time 0.095 (0.112) data 0.000 (0.018) loss 1.4333 (1.4060) teacher_loss 0.1784 (0.2738) loss_zs_kd 0.0214 (0.0275) loss_oracle 0.8016 (0.6273) kd_loss 0.8434 (0.8047) acc 90.6250 (90.1562) gate/entropy 1.0169 (1.0162) gate/usage_max 0.5298 (0.5307) gate/usage_min 0.2263 (0.2259) gate/usage_std 0.1391 (0.1397) teacher/entropy 0.1232 (0.0592) teacher/usage_max 0.5776 (0.7065) teacher/usage_min 0.0672 (0.0483) teacher/usage_std 0.2090 (0.2800) nleep/row_max_mean 1467.7543 (1477.2567) nleep/row_max_std 55.1740 (54.2729) nleep/row_min_mean 1447.0697 (1453.3593) lr 1.2369e-04 eta 0:02:15
epoch [44/50] batch [40/176] time 0.091 (0.100) data 0.000 (0.009) loss 1.3184 (1.3813) teacher_loss 0.1857 (0.2492) loss_zs_kd 0.0362 (0.0302) loss_oracle 0.5769 (0.6213) kd_loss 0.8262 (0.8064) acc 93.7500 (91.2500) gate/entropy 1.0165 (1.0163) gate/usage_max 0.5303 (0.5306) gate/usage_min 0.2261 (0.2260) gate/usage_std 0.1395 (0.1396) teacher/entropy 0.0503 (0.0613) teacher/usage_max 0.6911 (0.7015) teacher/usage_min 0.0625 (0.0468) teacher/usage_std 0.2639 (0.2773) nleep/row_max_mean 1477.2970 (1476.0098) nleep/row_max_std 51.6101 (53.9635) nleep/row_min_mean 1454.2905 (1452.5180) lr 1.2369e-04 eta 0:01:59
epoch [44/50] batch [60/176] time 0.081 (0.097) data 0.000 (0.006) loss 1.2583 (1.3741) teacher_loss 0.0972 (0.2450) loss_zs_kd 0.0224 (0.0307) loss_oracle 0.5911 (0.6177) kd_loss 0.8543 (0.8049) acc 96.8750 (91.8750) gate/entropy 1.0166 (1.0163) gate/usage_max 0.5302 (0.5306) gate/usage_min 0.2262 (0.2260) gate/usage_std 0.1394 (0.1397) teacher/entropy 0.0403 (0.0616) teacher/usage_max 0.6670 (0.7034) teacher/usage_min 0.0582 (0.0504) teacher/usage_std 0.2519 (0.2775) nleep/row_max_mean 1460.2607 (1474.9045) nleep/row_max_std 68.9163 (54.6205) nleep/row_min_mean 1438.3574 (1451.6522) lr 1.2369e-04 eta 0:01:54
epoch [44/50] batch [80/176] time 0.087 (0.096) data 0.000 (0.005) loss 1.3424 (1.3681) teacher_loss 0.0812 (0.2365) loss_zs_kd 0.0371 (0.0306) loss_oracle 0.7083 (0.6173) kd_loss 0.8885 (0.8077) acc 96.8750 (92.0312) gate/entropy 1.0163 (1.0163) gate/usage_max 0.5306 (0.5306) gate/usage_min 0.2259 (0.2260) gate/usage_std 0.1396 (0.1397) teacher/entropy 0.0521 (0.0595) teacher/usage_max 0.6090 (0.7023) teacher/usage_min 0.0827 (0.0485) teacher/usage_std 0.2156 (0.2772) nleep/row_max_mean 1482.6001 (1474.0667) nleep/row_max_std 55.2722 (55.4811) nleep/row_min_mean 1457.8882 (1450.7939) lr 1.2369e-04 eta 0:01:50
epoch [44/50] batch [100/176] time 0.097 (0.096) data 0.000 (0.004) loss 1.2903 (1.3660) teacher_loss 0.1978 (0.2343) loss_zs_kd 0.0216 (0.0309) loss_oracle 0.5809 (0.6158) kd_loss 0.7912 (0.8083) acc 90.6250 (91.9375) gate/entropy 1.0161 (1.0163) gate/usage_max 0.5309 (0.5306) gate/usage_min 0.2258 (0.2259) gate/usage_std 0.1399 (0.1397) teacher/entropy 0.0763 (0.0579) teacher/usage_max 0.7017 (0.7035) teacher/usage_min 0.0564 (0.0489) teacher/usage_std 0.2713 (0.2776) nleep/row_max_mean 1476.0227 (1474.6767) nleep/row_max_std 55.5025 (55.2213) nleep/row_min_mean 1451.9219 (1451.3650) lr 1.2369e-04 eta 0:01:49
epoch [44/50] batch [120/176] time 0.104 (0.097) data 0.000 (0.003) loss 1.3271 (1.3715) teacher_loss 0.1815 (0.2325) loss_zs_kd 0.0389 (0.0315) loss_oracle 0.6050 (0.6211) kd_loss 0.8236 (0.8127) acc 90.6250 (91.8490) gate/entropy 1.0160 (1.0163) gate/usage_max 0.5309 (0.5306) gate/usage_min 0.2258 (0.2259) gate/usage_std 0.1399 (0.1397) teacher/entropy 0.0363 (0.0569) teacher/usage_max 0.7109 (0.6991) teacher/usage_min 0.0411 (0.0486) teacher/usage_std 0.2800 (0.2753) nleep/row_max_mean 1478.4441 (1474.9757) nleep/row_max_std 51.9236 (54.7303) nleep/row_min_mean 1452.5764 (1451.5599) lr 1.2369e-04 eta 0:01:47
epoch [44/50] batch [140/176] time 0.096 (0.096) data 0.000 (0.003) loss 1.2688 (1.3676) teacher_loss 0.0987 (0.2332) loss_zs_kd 0.0484 (0.0313) loss_oracle 0.5983 (0.6207) kd_loss 0.8468 (0.8085) acc 96.8750 (91.6964) gate/entropy 1.0164 (1.0163) gate/usage_max 0.5305 (0.5306) gate/usage_min 0.2259 (0.2259) gate/usage_std 0.1396 (0.1397) teacher/entropy 0.0519 (0.0570) teacher/usage_max 0.6571 (0.7042) teacher/usage_min 0.0100 (0.0467) teacher/usage_std 0.2642 (0.2785) nleep/row_max_mean 1496.3646 (1475.1275) nleep/row_max_std 33.7371 (54.2067) nleep/row_min_mean 1473.3341 (1451.7129) lr 1.2369e-04 eta 0:01:44
epoch [44/50] batch [160/176] time 0.096 (0.096) data 0.000 (0.003) loss 1.4222 (1.3724) teacher_loss 0.2077 (0.2357) loss_zs_kd 0.0369 (0.0311) loss_oracle 0.6950 (0.6237) kd_loss 0.8485 (0.8093) acc 87.5000 (91.6016) gate/entropy 1.0167 (1.0163) gate/usage_max 0.5301 (0.5306) gate/usage_min 0.2261 (0.2259) gate/usage_std 0.1393 (0.1397) teacher/entropy 0.0966 (0.0575) teacher/usage_max 0.6002 (0.7025) teacher/usage_min 0.0192 (0.0463) teacher/usage_std 0.2395 (0.2775) nleep/row_max_mean 1455.2479 (1474.9672) nleep/row_max_std 57.3913 (54.0780) nleep/row_min_mean 1431.4823 (1451.4860) lr 1.2369e-04 eta 0:01:42
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,171
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 91.3%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,642
* accuracy: 61.8%
* error: 38.2%
* macro_f1: 57.4%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [45/50] batch [20/176] time 0.109 (0.117) data 0.000 (0.017) loss 1.3843 (1.4562) teacher_loss 0.2707 (0.3093) loss_zs_kd 0.0210 (0.0363) loss_oracle 0.6610 (0.6403) kd_loss 0.7726 (0.8086) acc 93.7500 (89.5312) gate/entropy 1.0159 (1.0162) gate/usage_max 0.5311 (0.5307) gate/usage_min 0.2256 (0.2258) gate/usage_std 0.1400 (0.1398) teacher/entropy 0.0846 (0.0569) teacher/usage_max 0.7133 (0.7054) teacher/usage_min 0.0278 (0.0587) teacher/usage_std 0.2848 (0.2751) nleep/row_max_mean 1481.6589 (1477.6662) nleep/row_max_std 54.0557 (51.9156) nleep/row_min_mean 1457.0115 (1453.6349) lr 9.5173e-05 eta 0:02:01
epoch [45/50] batch [40/176] time 0.141 (0.118) data 0.000 (0.009) loss 1.4571 (1.4161) teacher_loss 0.2093 (0.2726) loss_zs_kd 0.0219 (0.0330) loss_oracle 0.6201 (0.6315) kd_loss 0.9268 (0.8113) acc 90.6250 (90.6250) gate/entropy 1.0168 (1.0162) gate/usage_max 0.5300 (0.5307) gate/usage_min 0.2261 (0.2258) gate/usage_std 0.1392 (0.1398) teacher/entropy 0.0586 (0.0541) teacher/usage_max 0.5459 (0.7048) teacher/usage_min 0.0034 (0.0516) teacher/usage_std 0.2365 (0.2778) nleep/row_max_mean 1474.3250 (1477.6619) nleep/row_max_std 45.2649 (52.0552) nleep/row_min_mean 1452.5367 (1453.5728) lr 9.5173e-05 eta 0:02:00
epoch [45/50] batch [60/176] time 0.093 (0.111) data 0.001 (0.006) loss 1.1207 (1.4052) teacher_loss 0.0889 (0.2680) loss_zs_kd 0.0235 (0.0313) loss_oracle 0.4939 (0.6315) kd_loss 0.7731 (0.8058) acc 100.0000 (90.9375) gate/entropy 1.0160 (1.0162) gate/usage_max 0.5310 (0.5308) gate/usage_min 0.2257 (0.2258) gate/usage_std 0.1399 (0.1398) teacher/entropy 0.0436 (0.0570) teacher/usage_max 0.7686 (0.7083) teacher/usage_min 0.0610 (0.0537) teacher/usage_std 0.3110 (0.2793) nleep/row_max_mean 1487.2668 (1477.4388) nleep/row_max_std 39.0770 (52.4611) nleep/row_min_mean 1462.0322 (1453.3745) lr 9.5173e-05 eta 0:01:50
epoch [45/50] batch [80/176] time 0.096 (0.108) data 0.000 (0.004) loss 1.6755 (1.3872) teacher_loss 0.3901 (0.2624) loss_zs_kd 0.0464 (0.0321) loss_oracle 0.7892 (0.6251) kd_loss 0.8676 (0.7962) acc 84.3750 (91.0156) gate/entropy 1.0168 (1.0162) gate/usage_max 0.5300 (0.5308) gate/usage_min 0.2261 (0.2258) gate/usage_std 0.1393 (0.1398) teacher/entropy 0.0732 (0.0603) teacher/usage_max 0.6169 (0.7161) teacher/usage_min 0.1221 (0.0511) teacher/usage_std 0.2084 (0.2842) nleep/row_max_mean 1464.8350 (1477.4421) nleep/row_max_std 43.5435 (52.4196) nleep/row_min_mean 1441.5150 (1453.2913) lr 9.5173e-05 eta 0:01:45
epoch [45/50] batch [100/176] time 0.099 (0.106) data 0.000 (0.004) loss 1.3581 (1.3845) teacher_loss 0.0947 (0.2597) loss_zs_kd 0.0090 (0.0311) loss_oracle 0.7980 (0.6239) kd_loss 0.8600 (0.7974) acc 96.8750 (91.0312) gate/entropy 1.0161 (1.0162) gate/usage_max 0.5309 (0.5308) gate/usage_min 0.2257 (0.2258) gate/usage_std 0.1399 (0.1398) teacher/entropy 0.0463 (0.0589) teacher/usage_max 0.6550 (0.7162) teacher/usage_min 0.0954 (0.0492) teacher/usage_std 0.2360 (0.2844) nleep/row_max_mean 1491.8123 (1477.0191) nleep/row_max_std 48.5284 (52.6188) nleep/row_min_mean 1466.6605 (1452.8385) lr 9.5173e-05 eta 0:01:41
epoch [45/50] batch [120/176] time 0.092 (0.104) data 0.000 (0.003) loss 1.2892 (1.3861) teacher_loss 0.2497 (0.2591) loss_zs_kd 0.0448 (0.0310) loss_oracle 0.6072 (0.6257) kd_loss 0.7136 (0.7986) acc 90.6250 (91.0156) gate/entropy 1.0167 (1.0162) gate/usage_max 0.5301 (0.5308) gate/usage_min 0.2261 (0.2258) gate/usage_std 0.1393 (0.1398) teacher/entropy 0.0941 (0.0574) teacher/usage_max 0.7806 (0.7166) teacher/usage_min 0.0453 (0.0495) teacher/usage_std 0.3206 (0.2844) nleep/row_max_mean 1452.9995 (1476.5124) nleep/row_max_std 57.8924 (52.8267) nleep/row_min_mean 1430.8740 (1452.3650) lr 9.5173e-05 eta 0:01:37
epoch [45/50] batch [140/176] time 0.098 (0.103) data 0.000 (0.003) loss 1.6187 (1.3801) teacher_loss 0.4299 (0.2573) loss_zs_kd 0.0397 (0.0312) loss_oracle 0.7380 (0.6240) kd_loss 0.7999 (0.7952) acc 78.1250 (91.0491) gate/entropy 1.0160 (1.0161) gate/usage_max 0.5309 (0.5308) gate/usage_min 0.2257 (0.2258) gate/usage_std 0.1399 (0.1398) teacher/entropy 0.0865 (0.0586) teacher/usage_max 0.6778 (0.7193) teacher/usage_min 0.0453 (0.0491) teacher/usage_std 0.2613 (0.2858) nleep/row_max_mean 1463.8683 (1477.0520) nleep/row_max_std 64.3211 (52.4172) nleep/row_min_mean 1442.3875 (1452.8646) lr 9.5173e-05 eta 0:01:34
epoch [45/50] batch [160/176] time 0.095 (0.103) data 0.000 (0.002) loss 1.4982 (1.3773) teacher_loss 0.3074 (0.2542) loss_zs_kd 0.0413 (0.0305) loss_oracle 0.7581 (0.6237) kd_loss 0.7911 (0.7960) acc 90.6250 (91.1133) gate/entropy 1.0167 (1.0161) gate/usage_max 0.5301 (0.5308) gate/usage_min 0.2261 (0.2258) gate/usage_std 0.1393 (0.1398) teacher/entropy 0.1193 (0.0578) teacher/usage_max 0.6500 (0.7194) teacher/usage_min 0.0714 (0.0483) teacher/usage_std 0.2394 (0.2859) nleep/row_max_mean 1473.8691 (1476.7488) nleep/row_max_std 47.2436 (52.3153) nleep/row_min_mean 1449.9465 (1452.4932) lr 9.5173e-05 eta 0:01:32
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,175
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,639
* accuracy: 61.7%
* error: 38.3%
* macro_f1: 57.3%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [46/50] batch [20/176] time 0.097 (0.115) data 0.000 (0.016) loss 1.3418 (1.4156) teacher_loss 0.1791 (0.2510) loss_zs_kd 0.0294 (0.0302) loss_oracle 0.6568 (0.6504) kd_loss 0.8196 (0.8243) acc 90.6250 (91.7188) gate/entropy 1.0168 (1.0160) gate/usage_max 0.5299 (0.5310) gate/usage_min 0.2261 (0.2257) gate/usage_std 0.1392 (0.1399) teacher/entropy 0.0553 (0.0486) teacher/usage_max 0.6951 (0.6956) teacher/usage_min 0.0661 (0.0586) teacher/usage_std 0.2654 (0.2709) nleep/row_max_mean 1469.9718 (1478.0344) nleep/row_max_std 46.2007 (50.2838) nleep/row_min_mean 1446.6111 (1453.3042) lr 7.0224e-05 eta 0:01:39
epoch [46/50] batch [40/176] time 0.091 (0.104) data 0.000 (0.008) loss 1.3322 (1.4012) teacher_loss 0.3213 (0.2625) loss_zs_kd 0.0325 (0.0316) loss_oracle 0.6147 (0.6420) kd_loss 0.6873 (0.8019) acc 81.2500 (90.5469) gate/entropy 1.0153 (1.0161) gate/usage_max 0.5318 (0.5309) gate/usage_min 0.2253 (0.2257) gate/usage_std 0.1405 (0.1399) teacher/entropy 0.0444 (0.0589) teacher/usage_max 0.8710 (0.7106) teacher/usage_min 0.0083 (0.0509) teacher/usage_std 0.3829 (0.2808) nleep/row_max_mean 1491.4836 (1476.0792) nleep/row_max_std 48.2684 (50.6597) nleep/row_min_mean 1465.3420 (1451.8497) lr 7.0224e-05 eta 0:01:26
epoch [46/50] batch [60/176] time 0.091 (0.101) data 0.000 (0.005) loss 1.4183 (1.3870) teacher_loss 0.2217 (0.2529) loss_zs_kd 0.0517 (0.0300) loss_oracle 0.7250 (0.6376) kd_loss 0.8082 (0.8003) acc 93.7500 (90.7292) gate/entropy 1.0160 (1.0160) gate/usage_max 0.5310 (0.5309) gate/usage_min 0.2256 (0.2257) gate/usage_std 0.1399 (0.1399) teacher/entropy 0.0576 (0.0572) teacher/usage_max 0.7098 (0.7147) teacher/usage_min 0.0985 (0.0508) teacher/usage_std 0.2689 (0.2830) nleep/row_max_mean 1485.0947 (1475.1810) nleep/row_max_std 42.1176 (52.1539) nleep/row_min_mean 1455.8193 (1450.9712) lr 7.0224e-05 eta 0:01:22
epoch [46/50] batch [80/176] time 0.096 (0.098) data 0.000 (0.004) loss 1.5248 (1.3825) teacher_loss 0.4522 (0.2502) loss_zs_kd 0.0188 (0.0298) loss_oracle 0.6519 (0.6346) kd_loss 0.7372 (0.8001) acc 84.3750 (90.7812) gate/entropy 1.0158 (1.0160) gate/usage_max 0.5312 (0.5310) gate/usage_min 0.2255 (0.2256) gate/usage_std 0.1401 (0.1400) teacher/entropy 0.0772 (0.0571) teacher/usage_max 0.7720 (0.7154) teacher/usage_min 0.0596 (0.0548) teacher/usage_std 0.3133 (0.2825) nleep/row_max_mean 1473.0995 (1476.0974) nleep/row_max_std 51.4482 (51.8446) nleep/row_min_mean 1449.3004 (1451.9275) lr 7.0224e-05 eta 0:01:18
epoch [46/50] batch [100/176] time 0.082 (0.096) data 0.000 (0.003) loss 1.3631 (1.3769) teacher_loss 0.2302 (0.2486) loss_zs_kd 0.0294 (0.0308) loss_oracle 0.6229 (0.6304) kd_loss 0.8068 (0.7977) acc 90.6250 (90.8438) gate/entropy 1.0166 (1.0160) gate/usage_max 0.5303 (0.5310) gate/usage_min 0.2259 (0.2256) gate/usage_std 0.1394 (0.1400) teacher/entropy 0.1316 (0.0555) teacher/usage_max 0.6098 (0.7203) teacher/usage_min 0.0294 (0.0515) teacher/usage_std 0.2378 (0.2860) nleep/row_max_mean 1472.1293 (1476.1914) nleep/row_max_std 44.0222 (51.8838) nleep/row_min_mean 1451.8409 (1451.9854) lr 7.0224e-05 eta 0:01:15
epoch [46/50] batch [120/176] time 0.095 (0.095) data 0.000 (0.003) loss 1.3929 (1.3771) teacher_loss 0.2780 (0.2490) loss_zs_kd 0.0225 (0.0311) loss_oracle 0.6166 (0.6279) kd_loss 0.7954 (0.7986) acc 87.5000 (90.9375) gate/entropy 1.0154 (1.0160) gate/usage_max 0.5317 (0.5310) gate/usage_min 0.2253 (0.2256) gate/usage_std 0.1405 (0.1399) teacher/entropy 0.0122 (0.0563) teacher/usage_max 0.7790 (0.7181) teacher/usage_min 0.0625 (0.0510) teacher/usage_std 0.3175 (0.2848) nleep/row_max_mean 1490.8022 (1476.7259) nleep/row_max_std 45.1855 (51.3036) nleep/row_min_mean 1465.3463 (1452.5993) lr 7.0224e-05 eta 0:01:12
epoch [46/50] batch [140/176] time 0.058 (0.096) data 0.000 (0.002) loss 1.5594 (1.3741) teacher_loss 0.2615 (0.2464) loss_zs_kd 0.0157 (0.0312) loss_oracle 0.6640 (0.6259) kd_loss 0.9581 (0.7991) acc 90.6250 (90.9598) gate/entropy 1.0162 (1.0160) gate/usage_max 0.5308 (0.5310) gate/usage_min 0.2257 (0.2256) gate/usage_std 0.1398 (0.1400) teacher/entropy 0.0124 (0.0555) teacher/usage_max 0.5654 (0.7182) teacher/usage_min 0.0313 (0.0481) teacher/usage_std 0.2236 (0.2860) nleep/row_max_mean 1478.2025 (1476.7524) nleep/row_max_std 45.6770 (51.4999) nleep/row_min_mean 1453.8130 (1452.6198) lr 7.0224e-05 eta 0:01:11
epoch [46/50] batch [160/176] time 0.091 (0.096) data 0.000 (0.002) loss 1.2616 (1.3651) teacher_loss 0.2391 (0.2418) loss_zs_kd 0.0346 (0.0310) loss_oracle 0.5311 (0.6213) kd_loss 0.7397 (0.7972) acc 93.7500 (91.1328) gate/entropy 1.0160 (1.0159) gate/usage_max 0.5310 (0.5310) gate/usage_min 0.2256 (0.2256) gate/usage_std 0.1399 (0.1400) teacher/entropy 0.0767 (0.0548) teacher/usage_max 0.7639 (0.7213) teacher/usage_min 0.0015 (0.0468) teacher/usage_std 0.3190 (0.2879) nleep/row_max_mean 1491.4250 (1477.4116) nleep/row_max_std 38.5299 (51.2673) nleep/row_min_mean 1466.1833 (1453.1775) lr 7.0224e-05 eta 0:01:08
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,174
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,634
* accuracy: 61.5%
* error: 38.5%
* macro_f1: 57.1%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [47/50] batch [20/176] time 0.076 (0.106) data 0.000 (0.018) loss 1.3857 (1.3519) teacher_loss 0.1570 (0.2296) loss_zs_kd 0.0126 (0.0267) loss_oracle 0.6633 (0.6378) kd_loss 0.8908 (0.7901) acc 96.8750 (91.8750) gate/entropy 1.0159 (1.0160) gate/usage_max 0.5310 (0.5310) gate/usage_min 0.2256 (0.2256) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0590 (0.0577) teacher/usage_max 0.6017 (0.7261) teacher/usage_min 0.1251 (0.0414) teacher/usage_std 0.1992 (0.2915) nleep/row_max_mean 1470.9365 (1473.9074) nleep/row_max_std 63.2042 (54.3515) nleep/row_min_mean 1448.0881 (1449.8951) lr 4.8943e-05 eta 0:01:12
epoch [47/50] batch [40/176] time 0.083 (0.095) data 0.000 (0.009) loss 1.5039 (1.3761) teacher_loss 0.4858 (0.2575) loss_zs_kd 0.0443 (0.0311) loss_oracle 0.6546 (0.6217) kd_loss 0.6687 (0.7922) acc 84.3750 (90.7812) gate/entropy 1.0156 (1.0159) gate/usage_max 0.5315 (0.5311) gate/usage_min 0.2254 (0.2256) gate/usage_std 0.1403 (0.1400) teacher/entropy 0.1068 (0.0587) teacher/usage_max 0.8183 (0.7228) teacher/usage_min 0.0319 (0.0474) teacher/usage_std 0.3462 (0.2876) nleep/row_max_mean 1486.2294 (1476.7902) nleep/row_max_std 41.6696 (51.4626) nleep/row_min_mean 1462.4246 (1452.5589) lr 4.8943e-05 eta 0:01:03
epoch [47/50] batch [60/176] time 0.082 (0.093) data 0.001 (0.006) loss 1.5908 (1.3638) teacher_loss 0.3734 (0.2391) loss_zs_kd 0.0307 (0.0321) loss_oracle 0.6883 (0.6252) kd_loss 0.8579 (0.7960) acc 87.5000 (91.5625) gate/entropy 1.0161 (1.0159) gate/usage_max 0.5308 (0.5311) gate/usage_min 0.2257 (0.2256) gate/usage_std 0.1398 (0.1400) teacher/entropy 0.0648 (0.0609) teacher/usage_max 0.6266 (0.7151) teacher/usage_min 0.0044 (0.0486) teacher/usage_std 0.2553 (0.2833) nleep/row_max_mean 1470.2020 (1475.3968) nleep/row_max_std 48.0940 (52.3065) nleep/row_min_mean 1451.1956 (1451.7813) lr 4.8943e-05 eta 0:00:59
epoch [47/50] batch [80/176] time 0.102 (0.091) data 0.000 (0.005) loss 1.3155 (1.3570) teacher_loss 0.1781 (0.2395) loss_zs_kd 0.0401 (0.0318) loss_oracle 0.6584 (0.6212) kd_loss 0.7882 (0.7910) acc 96.8750 (91.6797) gate/entropy 1.0154 (1.0159) gate/usage_max 0.5317 (0.5311) gate/usage_min 0.2253 (0.2256) gate/usage_std 0.1405 (0.1400) teacher/entropy 0.0544 (0.0599) teacher/usage_max 0.7359 (0.7225) teacher/usage_min 0.0842 (0.0457) teacher/usage_std 0.2873 (0.2880) nleep/row_max_mean 1475.4182 (1475.4197) nleep/row_max_std 53.9355 (52.3502) nleep/row_min_mean 1453.6396 (1451.5743) lr 4.8943e-05 eta 0:00:56
epoch [47/50] batch [100/176] time 0.100 (0.092) data 0.000 (0.004) loss 1.3428 (1.3505) teacher_loss 0.2107 (0.2393) loss_zs_kd 0.0391 (0.0319) loss_oracle 0.5981 (0.6161) kd_loss 0.8135 (0.7872) acc 93.7500 (91.6875) gate/entropy 1.0157 (1.0159) gate/usage_max 0.5314 (0.5311) gate/usage_min 0.2255 (0.2256) gate/usage_std 0.1402 (0.1400) teacher/entropy 0.0228 (0.0615) teacher/usage_max 0.7382 (0.7253) teacher/usage_min 0.0117 (0.0449) teacher/usage_std 0.3024 (0.2898) nleep/row_max_mean 1476.0740 (1476.2400) nleep/row_max_std 53.9509 (51.7165) nleep/row_min_mean 1451.0574 (1452.3085) lr 4.8943e-05 eta 0:00:55
epoch [47/50] batch [120/176] time 0.092 (0.093) data 0.000 (0.003) loss 1.4264 (1.3578) teacher_loss 0.2375 (0.2382) loss_zs_kd 0.0544 (0.0317) loss_oracle 0.6720 (0.6166) kd_loss 0.8256 (0.7955) acc 84.3750 (91.4323) gate/entropy 1.0160 (1.0159) gate/usage_max 0.5309 (0.5311) gate/usage_min 0.2256 (0.2256) gate/usage_std 0.1399 (0.1400) teacher/entropy 0.0458 (0.0593) teacher/usage_max 0.6939 (0.7175) teacher/usage_min 0.0114 (0.0458) teacher/usage_std 0.2800 (0.2851) nleep/row_max_mean 1471.8572 (1475.4808) nleep/row_max_std 51.7896 (51.9110) nleep/row_min_mean 1448.6577 (1451.6316) lr 4.8943e-05 eta 0:00:54
epoch [47/50] batch [140/176] time 0.095 (0.094) data 0.000 (0.003) loss 1.3041 (1.3592) teacher_loss 0.1983 (0.2334) loss_zs_kd 0.0254 (0.0316) loss_oracle 0.7036 (0.6177) kd_loss 0.7413 (0.8012) acc 93.7500 (91.5625) gate/entropy 1.0160 (1.0159) gate/usage_max 0.5309 (0.5311) gate/usage_min 0.2257 (0.2256) gate/usage_std 0.1399 (0.1400) teacher/entropy 0.0619 (0.0603) teacher/usage_max 0.7829 (0.7088) teacher/usage_min 0.0326 (0.0462) teacher/usage_std 0.3239 (0.2806) nleep/row_max_mean 1482.9246 (1475.6865) nleep/row_max_std 47.8663 (51.8719) nleep/row_min_mean 1457.1609 (1451.8249) lr 4.8943e-05 eta 0:00:52
epoch [47/50] batch [160/176] time 0.091 (0.094) data 0.000 (0.003) loss 1.3985 (1.3601) teacher_loss 0.3433 (0.2321) loss_zs_kd 0.0440 (0.0316) loss_oracle 0.6555 (0.6219) kd_loss 0.7054 (0.8013) acc 90.6250 (91.5820) gate/entropy 1.0156 (1.0159) gate/usage_max 0.5315 (0.5311) gate/usage_min 0.2253 (0.2256) gate/usage_std 0.1403 (0.1400) teacher/entropy 0.0829 (0.0602) teacher/usage_max 0.8040 (0.7091) teacher/usage_min 0.0595 (0.0471) teacher/usage_std 0.3343 (0.2806) nleep/row_max_mean 1477.7615 (1476.2445) nleep/row_max_std 51.4810 (51.4074) nleep/row_min_mean 1453.7800 (1452.3458) lr 4.8943e-05 eta 0:00:51
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,177
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.6%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,637
* accuracy: 61.6%
* error: 38.4%
* macro_f1: 57.2%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [48/50] batch [20/176] time 0.094 (0.104) data 0.000 (0.013) loss 1.5704 (1.3767) teacher_loss 0.4569 (0.2561) loss_zs_kd 0.0214 (0.0343) loss_oracle 0.6822 (0.6168) kd_loss 0.7617 (0.7951) acc 81.2500 (90.4688) gate/entropy 1.0159 (1.0159) gate/usage_max 0.5311 (0.5311) gate/usage_min 0.2255 (0.2255) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.1282 (0.0663) teacher/usage_max 0.6809 (0.7098) teacher/usage_min 0.1170 (0.0554) teacher/usage_std 0.2482 (0.2797) nleep/row_max_mean 1492.8574 (1477.7068) nleep/row_max_std 36.2583 (49.7768) nleep/row_min_mean 1468.3151 (1453.4357) lr 3.1417e-05 eta 0:00:52
epoch [48/50] batch [40/176] time 0.090 (0.109) data 0.001 (0.007) loss 1.2510 (1.3524) teacher_loss 0.2552 (0.2370) loss_zs_kd 0.0463 (0.0324) loss_oracle 0.5902 (0.6191) kd_loss 0.6776 (0.7896) acc 90.6250 (91.4844) gate/entropy 1.0154 (1.0159) gate/usage_max 0.5317 (0.5311) gate/usage_min 0.2253 (0.2255) gate/usage_std 0.1404 (0.1400) teacher/entropy 0.0711 (0.0594) teacher/usage_max 0.8491 (0.7256) teacher/usage_min 0.0032 (0.0539) teacher/usage_std 0.3694 (0.2883) nleep/row_max_mean 1483.5286 (1478.8079) nleep/row_max_std 56.2240 (49.1595) nleep/row_min_mean 1457.6942 (1454.3507) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [60/176] time 0.095 (0.104) data 0.001 (0.005) loss 1.2760 (1.3618) teacher_loss 0.2499 (0.2398) loss_zs_kd 0.0272 (0.0321) loss_oracle 0.5812 (0.6197) kd_loss 0.7219 (0.7961) acc 90.6250 (91.4062) gate/entropy 1.0157 (1.0159) gate/usage_max 0.5314 (0.5311) gate/usage_min 0.2255 (0.2255) gate/usage_std 0.1402 (0.1401) teacher/entropy 0.0370 (0.0564) teacher/usage_max 0.8408 (0.7204) teacher/usage_min 0.0333 (0.0476) teacher/usage_std 0.3608 (0.2867) nleep/row_max_mean 1479.9706 (1478.7863) nleep/row_max_std 52.4404 (49.5569) nleep/row_min_mean 1455.2360 (1454.4499) lr 3.1417e-05 eta 0:00:48
epoch [48/50] batch [80/176] time 0.097 (0.102) data 0.000 (0.004) loss 1.3135 (1.3629) teacher_loss 0.1204 (0.2369) loss_zs_kd 0.0241 (0.0321) loss_oracle 0.7518 (0.6277) kd_loss 0.8052 (0.7961) acc 93.7500 (91.4844) gate/entropy 1.0159 (1.0158) gate/usage_max 0.5311 (0.5312) gate/usage_min 0.2256 (0.2255) gate/usage_std 0.1401 (0.1401) teacher/entropy 0.1149 (0.0551) teacher/usage_max 0.6419 (0.7221) teacher/usage_min 0.1184 (0.0478) teacher/usage_std 0.2237 (0.2875) nleep/row_max_mean 1491.2651 (1478.5665) nleep/row_max_std 42.5997 (50.2796) nleep/row_min_mean 1465.5936 (1454.2541) lr 3.1417e-05 eta 0:00:45
epoch [48/50] batch [100/176] time 0.094 (0.100) data 0.000 (0.003) loss 1.5567 (1.3697) teacher_loss 0.2909 (0.2423) loss_zs_kd 0.0378 (0.0324) loss_oracle 0.6940 (0.6256) kd_loss 0.8999 (0.7984) acc 87.5000 (91.4688) gate/entropy 1.0159 (1.0158) gate/usage_max 0.5310 (0.5312) gate/usage_min 0.2255 (0.2255) gate/usage_std 0.1400 (0.1401) teacher/entropy 0.0027 (0.0548) teacher/usage_max 0.6560 (0.7195) teacher/usage_min 0.0313 (0.0470) teacher/usage_std 0.2555 (0.2863) nleep/row_max_mean 1465.9393 (1478.5934) nleep/row_max_std 54.6538 (50.2547) nleep/row_min_mean 1439.2515 (1454.0488) lr 3.1417e-05 eta 0:00:42
epoch [48/50] batch [120/176] time 0.114 (0.100) data 0.001 (0.002) loss 1.1738 (1.3722) teacher_loss 0.0762 (0.2394) loss_zs_kd 0.0401 (0.0325) loss_oracle 0.6055 (0.6299) kd_loss 0.7748 (0.8015) acc 100.0000 (91.7969) gate/entropy 1.0156 (1.0158) gate/usage_max 0.5314 (0.5312) gate/usage_min 0.2254 (0.2255) gate/usage_std 0.1402 (0.1401) teacher/entropy 0.0897 (0.0547) teacher/usage_max 0.7043 (0.7155) teacher/usage_min 0.0398 (0.0460) teacher/usage_std 0.2768 (0.2843) nleep/row_max_mean 1487.7866 (1477.8425) nleep/row_max_std 33.6303 (50.5950) nleep/row_min_mean 1465.7266 (1453.4452) lr 3.1417e-05 eta 0:00:40
epoch [48/50] batch [140/176] time 0.094 (0.099) data 0.000 (0.002) loss 1.3644 (1.3734) teacher_loss 0.1352 (0.2352) loss_zs_kd 0.0406 (0.0327) loss_oracle 0.6591 (0.6310) kd_loss 0.8794 (0.8064) acc 93.7500 (91.9866) gate/entropy 1.0158 (1.0158) gate/usage_max 0.5312 (0.5311) gate/usage_min 0.2255 (0.2255) gate/usage_std 0.1401 (0.1401) teacher/entropy 0.0331 (0.0539) teacher/usage_max 0.6411 (0.7104) teacher/usage_min 0.0313 (0.0479) teacher/usage_std 0.2490 (0.2815) nleep/row_max_mean 1485.7847 (1477.0980) nleep/row_max_std 44.9377 (50.6427) nleep/row_min_mean 1460.2844 (1452.8441) lr 3.1417e-05 eta 0:00:38
epoch [48/50] batch [160/176] time 0.095 (0.098) data 0.000 (0.002) loss 1.2332 (1.3716) teacher_loss 0.1614 (0.2355) loss_zs_kd 0.0470 (0.0329) loss_oracle 0.6212 (0.6280) kd_loss 0.7378 (0.8057) acc 93.7500 (91.8359) gate/entropy 1.0158 (1.0158) gate/usage_max 0.5312 (0.5311) gate/usage_min 0.2255 (0.2255) gate/usage_std 0.1401 (0.1401) teacher/entropy 0.1212 (0.0550) teacher/usage_max 0.7112 (0.7099) teacher/usage_min 0.0404 (0.0472) teacher/usage_std 0.2804 (0.2817) nleep/row_max_mean 1481.7078 (1476.5210) nleep/row_max_std 49.9028 (50.9836) nleep/row_min_mean 1457.0975 (1452.3630) lr 3.1417e-05 eta 0:00:36
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,176
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,637
* accuracy: 61.6%
* error: 38.4%
* macro_f1: 57.2%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [49/50] batch [20/176] time 0.086 (0.111) data 0.000 (0.017) loss 1.4244 (1.3729) teacher_loss 0.3462 (0.2325) loss_zs_kd 0.0529 (0.0354) loss_oracle 0.5675 (0.6566) kd_loss 0.7681 (0.7945) acc 84.3750 (92.0312) gate/entropy 1.0159 (1.0158) gate/usage_max 0.5311 (0.5312) gate/usage_min 0.2255 (0.2255) gate/usage_std 0.1401 (0.1401) teacher/entropy 0.0575 (0.0670) teacher/usage_max 0.7522 (0.7093) teacher/usage_min 0.0178 (0.0528) teacher/usage_std 0.3086 (0.2787) nleep/row_max_mean 1484.8438 (1479.4498) nleep/row_max_std 34.2460 (49.8420) nleep/row_min_mean 1458.9609 (1454.9118) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [40/176] time 0.098 (0.102) data 0.001 (0.009) loss 1.3498 (1.3564) teacher_loss 0.2545 (0.2263) loss_zs_kd 0.0421 (0.0330) loss_oracle 0.5702 (0.6331) kd_loss 0.7892 (0.7970) acc 87.5000 (91.9531) gate/entropy 1.0156 (1.0157) gate/usage_max 0.5314 (0.5313) gate/usage_min 0.2254 (0.2254) gate/usage_std 0.1403 (0.1402) teacher/entropy 0.0442 (0.0590) teacher/usage_max 0.7474 (0.7156) teacher/usage_min 0.0785 (0.0455) teacher/usage_std 0.2954 (0.2848) nleep/row_max_mean 1477.0444 (1478.3349) nleep/row_max_std 54.5657 (50.0954) nleep/row_min_mean 1450.1772 (1454.1517) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [60/176] time 0.086 (0.100) data 0.001 (0.006) loss 1.2879 (1.3521) teacher_loss 0.1454 (0.2200) loss_zs_kd 0.0447 (0.0310) loss_oracle 0.6958 (0.6277) kd_loss 0.7723 (0.8027) acc 96.8750 (92.3958) gate/entropy 1.0162 (1.0158) gate/usage_max 0.5308 (0.5312) gate/usage_min 0.2257 (0.2255) gate/usage_std 0.1398 (0.1401) teacher/entropy 0.0556 (0.0589) teacher/usage_max 0.7490 (0.7086) teacher/usage_min 0.0226 (0.0465) teacher/usage_std 0.3057 (0.2805) nleep/row_max_mean 1468.3132 (1477.2217) nleep/row_max_std 55.0488 (51.1098) nleep/row_min_mean 1446.1234 (1453.1739) lr 1.7713e-05 eta 0:00:29
epoch [49/50] batch [80/176] time 0.090 (0.099) data 0.000 (0.004) loss 1.3095 (1.3677) teacher_loss 0.2198 (0.2331) loss_zs_kd 0.0285 (0.0308) loss_oracle 0.6362 (0.6280) kd_loss 0.7574 (0.8052) acc 96.8750 (91.7578) gate/entropy 1.0163 (1.0158) gate/usage_max 0.5306 (0.5312) gate/usage_min 0.2258 (0.2255) gate/usage_std 0.1397 (0.1401) teacher/entropy 0.1013 (0.0581) teacher/usage_max 0.7132 (0.7066) teacher/usage_min 0.0445 (0.0475) teacher/usage_std 0.2805 (0.2792) nleep/row_max_mean 1458.8351 (1475.4327) nleep/row_max_std 54.8410 (51.7093) nleep/row_min_mean 1437.8047 (1451.5037) lr 1.7713e-05 eta 0:00:26
epoch [49/50] batch [100/176] time 0.095 (0.098) data 0.000 (0.004) loss 1.4475 (1.3601) teacher_loss 0.2365 (0.2280) loss_zs_kd 0.0298 (0.0302) loss_oracle 0.7083 (0.6255) kd_loss 0.8420 (0.8042) acc 87.5000 (91.7500) gate/entropy 1.0155 (1.0158) gate/usage_max 0.5316 (0.5312) gate/usage_min 0.2253 (0.2255) gate/usage_std 0.1404 (0.1401) teacher/entropy 0.0089 (0.0567) teacher/usage_max 0.7174 (0.7096) teacher/usage_min 0.0012 (0.0465) teacher/usage_std 0.2947 (0.2812) nleep/row_max_mean 1475.0492 (1476.3046) nleep/row_max_std 55.1642 (51.5565) nleep/row_min_mean 1450.9159 (1452.3242) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [120/176] time 0.099 (0.098) data 0.000 (0.003) loss 1.5075 (1.3627) teacher_loss 0.3883 (0.2310) loss_zs_kd 0.0141 (0.0306) loss_oracle 0.5942 (0.6235) kd_loss 0.8150 (0.8047) acc 87.5000 (91.6667) gate/entropy 1.0164 (1.0158) gate/usage_max 0.5305 (0.5312) gate/usage_min 0.2258 (0.2255) gate/usage_std 0.1396 (0.1401) teacher/entropy 0.0790 (0.0565) teacher/usage_max 0.6679 (0.7093) teacher/usage_min 0.0583 (0.0478) teacher/usage_std 0.2524 (0.2806) nleep/row_max_mean 1471.1884 (1476.4437) nleep/row_max_std 54.9411 (51.3938) nleep/row_min_mean 1449.8060 (1452.4963) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [140/176] time 0.253 (0.099) data 0.001 (0.003) loss 1.1575 (1.3670) teacher_loss 0.1004 (0.2335) loss_zs_kd 0.0317 (0.0310) loss_oracle 0.5838 (0.6240) kd_loss 0.7493 (0.8059) acc 96.8750 (91.4062) gate/entropy 1.0153 (1.0158) gate/usage_max 0.5318 (0.5312) gate/usage_min 0.2252 (0.2255) gate/usage_std 0.1405 (0.1401) teacher/entropy 0.0456 (0.0545) teacher/usage_max 0.7885 (0.7104) teacher/usage_min 0.0044 (0.0479) teacher/usage_std 0.3323 (0.2812) nleep/row_max_mean 1495.5024 (1476.8057) nleep/row_max_std 43.9759 (51.1938) nleep/row_min_mean 1469.2649 (1452.7365) lr 1.7713e-05 eta 0:00:21
epoch [49/50] batch [160/176] time 0.087 (0.098) data 0.000 (0.002) loss 1.3194 (1.3669) teacher_loss 0.1919 (0.2359) loss_zs_kd 0.0211 (0.0311) loss_oracle 0.6207 (0.6203) kd_loss 0.8066 (0.8054) acc 87.5000 (91.2891) gate/entropy 1.0159 (1.0158) gate/usage_max 0.5310 (0.5312) gate/usage_min 0.2256 (0.2255) gate/usage_std 0.1400 (0.1401) teacher/entropy 0.0255 (0.0546) teacher/usage_max 0.7422 (0.7109) teacher/usage_min 0.0066 (0.0487) teacher/usage_std 0.3059 (0.2813) nleep/row_max_mean 1479.0210 (1476.9993) nleep/row_max_std 48.7376 (51.1617) nleep/row_min_mean 1455.1613 (1452.9688) lr 1.7713e-05 eta 0:00:18
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,176
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,639
* accuracy: 61.7%
* error: 38.3%
* macro_f1: 57.3%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
epoch [50/50] batch [20/176] time 0.110 (0.110) data 0.000 (0.015) loss 1.4364 (1.3190) teacher_loss 0.2104 (0.1867) loss_zs_kd 0.0428 (0.0275) loss_oracle 0.6854 (0.6239) kd_loss 0.8619 (0.8065) acc 93.7500 (92.3438) gate/entropy 1.0159 (1.0159) gate/usage_max 0.5311 (0.5311) gate/usage_min 0.2256 (0.2255) gate/usage_std 0.1400 (0.1400) teacher/entropy 0.0137 (0.0505) teacher/usage_max 0.6877 (0.7157) teacher/usage_min 0.0319 (0.0575) teacher/usage_std 0.2704 (0.2834) nleep/row_max_mean 1477.2249 (1474.6254) nleep/row_max_std 56.9787 (52.2499) nleep/row_min_mean 1451.7194 (1450.4182) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [40/176] time 0.088 (0.101) data 0.000 (0.008) loss 1.2378 (1.3356) teacher_loss 0.1226 (0.2079) loss_zs_kd 0.0113 (0.0287) loss_oracle 0.6142 (0.6301) kd_loss 0.8024 (0.7983) acc 96.8750 (92.3438) gate/entropy 1.0160 (1.0158) gate/usage_max 0.5309 (0.5311) gate/usage_min 0.2257 (0.2255) gate/usage_std 0.1399 (0.1401) teacher/entropy 0.0964 (0.0531) teacher/usage_max 0.6624 (0.7223) teacher/usage_min 0.0784 (0.0515) teacher/usage_std 0.2441 (0.2881) nleep/row_max_mean 1474.5773 (1475.9053) nleep/row_max_std 60.0599 (52.4653) nleep/row_min_mean 1454.0332 (1451.8180) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [60/176] time 0.101 (0.099) data 0.000 (0.005) loss 1.2476 (1.3533) teacher_loss 0.1412 (0.2224) loss_zs_kd 0.0472 (0.0289) loss_oracle 0.6030 (0.6231) kd_loss 0.7813 (0.8049) acc 96.8750 (92.2396) gate/entropy 1.0163 (1.0159) gate/usage_max 0.5305 (0.5311) gate/usage_min 0.2258 (0.2255) gate/usage_std 0.1396 (0.1400) teacher/entropy 0.0468 (0.0528) teacher/usage_max 0.7503 (0.7140) teacher/usage_min 0.0235 (0.0512) teacher/usage_std 0.3062 (0.2836) nleep/row_max_mean 1472.1111 (1475.5877) nleep/row_max_std 48.8366 (52.8894) nleep/row_min_mean 1451.0824 (1451.3789) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [80/176] time 0.101 (0.099) data 0.000 (0.004) loss 1.3240 (1.3617) teacher_loss 0.2452 (0.2308) loss_zs_kd 0.0330 (0.0297) loss_oracle 0.5620 (0.6184) kd_loss 0.7812 (0.8068) acc 90.6250 (91.8750) gate/entropy 1.0158 (1.0158) gate/usage_max 0.5312 (0.5312) gate/usage_min 0.2255 (0.2255) gate/usage_std 0.1401 (0.1401) teacher/entropy 0.0238 (0.0532) teacher/usage_max 0.7764 (0.7109) teacher/usage_min 0.0004 (0.0495) teacher/usage_std 0.3262 (0.2819) nleep/row_max_mean 1467.1488 (1475.1503) nleep/row_max_std 63.5259 (53.2811) nleep/row_min_mean 1443.8086 (1451.1030) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [100/176] time 0.096 (0.098) data 0.000 (0.003) loss 1.2123 (1.3645) teacher_loss 0.1524 (0.2314) loss_zs_kd 0.0508 (0.0309) loss_oracle 0.5892 (0.6207) kd_loss 0.7399 (0.8074) acc 100.0000 (92.0312) gate/entropy 1.0157 (1.0158) gate/usage_max 0.5313 (0.5312) gate/usage_min 0.2255 (0.2255) gate/usage_std 0.1402 (0.1401) teacher/entropy 0.0843 (0.0534) teacher/usage_max 0.7648 (0.7099) teacher/usage_min 0.1154 (0.0493) teacher/usage_std 0.3051 (0.2814) nleep/row_max_mean 1489.5916 (1475.8069) nleep/row_max_std 44.5222 (53.0656) nleep/row_min_mean 1464.7639 (1451.8090) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [120/176] time 0.093 (0.097) data 0.000 (0.003) loss 1.4163 (1.3553) teacher_loss 0.1351 (0.2274) loss_zs_kd 0.0291 (0.0311) loss_oracle 0.7084 (0.6162) kd_loss 0.9125 (0.8042) acc 96.8750 (92.2135) gate/entropy 1.0159 (1.0158) gate/usage_max 0.5310 (0.5312) gate/usage_min 0.2256 (0.2255) gate/usage_std 0.1400 (0.1401) teacher/entropy 0.0343 (0.0539) teacher/usage_max 0.5983 (0.7132) teacher/usage_min 0.0315 (0.0479) teacher/usage_std 0.2328 (0.2836) nleep/row_max_mean 1471.8103 (1476.1297) nleep/row_max_std 56.3604 (53.3317) nleep/row_min_mean 1449.6360 (1452.1149) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [140/176] time 0.102 (0.097) data 0.000 (0.002) loss 1.3621 (1.3619) teacher_loss 0.2590 (0.2321) loss_zs_kd 0.0401 (0.0316) loss_oracle 0.6298 (0.6154) kd_loss 0.7682 (0.8062) acc 90.6250 (92.0536) gate/entropy 1.0154 (1.0158) gate/usage_max 0.5317 (0.5312) gate/usage_min 0.2253 (0.2255) gate/usage_std 0.1404 (0.1401) teacher/entropy 0.0349 (0.0547) teacher/usage_max 0.7815 (0.7095) teacher/usage_min 0.0326 (0.0481) teacher/usage_std 0.3230 (0.2815) nleep/row_max_mean 1487.1368 (1475.6193) nleep/row_max_std 54.4883 (53.4682) nleep/row_min_mean 1462.1498 (1451.6202) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [160/176] time 0.098 (0.096) data 0.000 (0.002) loss 1.3165 (1.3717) teacher_loss 0.2446 (0.2406) loss_zs_kd 0.0162 (0.0314) loss_oracle 0.5322 (0.6141) kd_loss 0.7977 (0.8084) acc 93.7500 (91.7578) gate/entropy 1.0156 (1.0158) gate/usage_max 0.5315 (0.5312) gate/usage_min 0.2254 (0.2255) gate/usage_std 0.1403 (0.1401) teacher/entropy 0.0234 (0.0534) teacher/usage_max 0.7577 (0.7084) teacher/usage_min 0.0313 (0.0484) teacher/usage_std 0.3089 (0.2808) nleep/row_max_mean 1448.7688 (1475.2431) nleep/row_max_std 73.6635 (53.7769) nleep/row_min_mean 1424.9808 (1451.2593) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 2,422
* correct: 2,176
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 91.5%
Evaluate on the *test* set
=> result
* total: 2,656
* correct: 1,640
* accuracy: 61.7%
* error: 38.3%
* macro_f1: 57.3%
******* Domain l best val acc:      90.0%, epoch: 17 *******
******* Domain l best val test acc: 59.1%, epoch: 17 *******
******* Domain l best test acc:     72.4%, epoch: 2 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/l/seed_2/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:18:21

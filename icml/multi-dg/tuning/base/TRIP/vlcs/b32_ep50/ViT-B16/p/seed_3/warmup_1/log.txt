Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'sun']
Target     ['pascal']
# classes  5
# train_x  5,147
# val      2,206
# test     3,376
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/tensorboard)
epoch [1/50] batch [20/160] time 0.064 (0.134) data 0.000 (0.022) loss 0.8769 (1.1123) teacher_loss 0.5313 (0.6955) loss_zs_kd 0.0002 (0.0000) loss_oracle 0.0014 (0.0004) kd_loss 0.3448 (0.4166) acc 78.1250 (75.1562) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3296 (0.3296) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.7549 (0.6833) teacher/usage_max 0.4923 (0.5377) teacher/usage_min 0.2076 (0.1831) teacher/usage_std 0.1186 (0.1521) nleep/row_max_mean 1411.9882 (1437.9522) nleep/row_max_std 152.1494 (145.0922) nleep/row_min_mean 1409.6836 (1435.1314) lr 1.0000e-05 eta 0:17:51
epoch [1/50] batch [40/160] time 0.089 (0.108) data 0.000 (0.011) loss 1.1415 (1.0748) teacher_loss 0.8810 (0.6959) loss_zs_kd 0.0010 (0.0002) loss_oracle 0.0112 (0.0027) kd_loss 0.2544 (0.3775) acc 68.7500 (75.1562) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3296 (0.3296) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.8459 (0.7224) teacher/usage_max 0.4485 (0.5231) teacher/usage_min 0.2060 (0.1889) teacher/usage_std 0.0994 (0.1426) nleep/row_max_mean 1441.1079 (1438.3773) nleep/row_max_std 142.4064 (142.8069) nleep/row_min_mean 1439.3657 (1435.8848) lr 1.0000e-05 eta 0:14:19
epoch [1/50] batch [60/160] time 0.091 (0.101) data 0.000 (0.007) loss 0.9872 (1.0439) teacher_loss 0.7828 (0.6954) loss_zs_kd 0.0021 (0.0004) loss_oracle 0.0129 (0.0061) kd_loss 0.1968 (0.3453) acc 78.1250 (75.4688) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3295 (0.3296) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.9029 (0.7547) teacher/usage_max 0.4386 (0.5103) teacher/usage_min 0.2373 (0.1941) teacher/usage_std 0.0825 (0.1346) nleep/row_max_mean 1464.4211 (1441.6423) nleep/row_max_std 119.8668 (139.3012) nleep/row_min_mean 1463.0034 (1439.3835) lr 1.0000e-05 eta 0:13:24
epoch [1/50] batch [80/160] time 0.095 (0.098) data 0.000 (0.006) loss 0.8643 (1.0138) teacher_loss 0.6525 (0.6889) loss_zs_kd 0.0010 (0.0006) loss_oracle 0.0295 (0.0097) kd_loss 0.1965 (0.3197) acc 81.2500 (75.7812) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3376 (0.3374) gate/usage_min 0.3295 (0.3296) gate/usage_std 0.0033 (0.0032) teacher/entropy 0.9033 (0.7801) teacher/usage_max 0.4222 (0.5006) teacher/usage_min 0.2423 (0.2025) teacher/usage_std 0.0735 (0.1268) nleep/row_max_mean 1457.4836 (1448.0337) nleep/row_max_std 117.9783 (133.2031) nleep/row_min_mean 1456.2070 (1445.9492) lr 1.0000e-05 eta 0:12:56
epoch [1/50] batch [100/160] time 0.095 (0.097) data 0.000 (0.005) loss 1.0934 (0.9915) teacher_loss 0.7840 (0.6846) loss_zs_kd 0.0019 (0.0010) loss_oracle 0.0328 (0.0131) kd_loss 0.2920 (0.2999) acc 75.0000 (75.7500) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3373 (0.3374) gate/usage_min 0.3296 (0.3296) gate/usage_std 0.0031 (0.0032) teacher/entropy 0.8063 (0.7998) teacher/usage_max 0.4927 (0.4898) teacher/usage_min 0.2442 (0.2117) teacher/usage_std 0.1129 (0.1186) nleep/row_max_mean 1472.1313 (1454.2512) nleep/row_max_std 105.0826 (126.9267) nleep/row_min_mean 1470.4348 (1452.2909) lr 1.0000e-05 eta 0:12:44
epoch [1/50] batch [120/160] time 0.110 (0.097) data 0.000 (0.004) loss 0.9335 (0.9706) teacher_loss 0.8077 (0.6845) loss_zs_kd 0.0013 (0.0013) loss_oracle 0.0324 (0.0161) kd_loss 0.1089 (0.2774) acc 81.2500 (75.9375) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3296 (0.3296) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.9900 (0.8222) teacher/usage_max 0.4058 (0.4764) teacher/usage_min 0.2815 (0.2217) teacher/usage_std 0.0528 (0.1086) nleep/row_max_mean 1487.1315 (1458.9372) nleep/row_max_std 93.8274 (122.1080) nleep/row_min_mean 1486.2087 (1457.1020) lr 1.0000e-05 eta 0:12:42
epoch [1/50] batch [140/160] time 0.099 (0.097) data 0.000 (0.003) loss 0.7089 (0.9483) teacher_loss 0.5175 (0.6787) loss_zs_kd 0.0056 (0.0016) loss_oracle 0.0405 (0.0189) kd_loss 0.1684 (0.2594) acc 81.2500 (76.0938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3373 (0.3374) gate/usage_min 0.3295 (0.3296) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.9301 (0.8401) teacher/usage_max 0.4251 (0.4652) teacher/usage_min 0.2818 (0.2307) teacher/usage_std 0.0651 (0.1000) nleep/row_max_mean 1486.4209 (1462.2644) nleep/row_max_std 86.9768 (118.4462) nleep/row_min_mean 1485.2690 (1460.5280) lr 1.0000e-05 eta 0:12:39
epoch [1/50] batch [160/160] time 0.080 (0.096) data 0.000 (0.003) loss 1.0434 (0.9312) teacher_loss 0.9013 (0.6764) loss_zs_kd 0.0037 (0.0018) loss_oracle 0.0345 (0.0214) kd_loss 0.1230 (0.2432) acc 65.6250 (76.2305) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3296 (0.3296) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.9752 (0.8561) teacher/usage_max 0.3582 (0.4537) teacher/usage_min 0.3028 (0.2396) teacher/usage_std 0.0230 (0.0914) nleep/row_max_mean 1494.1803 (1465.6705) nleep/row_max_std 65.4655 (114.9326) nleep/row_min_mean 1493.1316 (1464.0154) lr 2.0000e-03 eta 0:12:29
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,723
* accuracy: 78.1%
* error: 21.9%
* macro_f1: 79.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,923
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      78.1%, epoch: 1 *******
******* Domain p best val test acc: 86.6%, epoch: 1 *******
******* Domain p best test acc:     86.6%, epoch: 1 *******
epoch [2/50] batch [20/160] time 0.097 (0.113) data 0.000 (0.020) loss 1.0503 (0.9391) teacher_loss 0.4928 (0.6189) loss_zs_kd 0.0174 (0.0131) loss_oracle 0.2654 (0.2078) kd_loss 0.4161 (0.2097) acc 81.2500 (80.7812) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3295 (0.3296) gate/usage_std 0.0033 (0.0032) teacher/entropy 0.6808 (0.8879) teacher/usage_max 0.5394 (0.4122) teacher/usage_min 0.1391 (0.2581) teacher/usage_std 0.1636 (0.0654) nleep/row_max_mean 1499.3661 (1489.0052) nleep/row_max_std 66.9615 (86.5353) nleep/row_min_mean 1496.9348 (1487.5479) lr 2.0000e-03 eta 0:14:46
epoch [2/50] batch [40/160] time 0.093 (0.103) data 0.001 (0.010) loss 1.2830 (0.9889) teacher_loss 0.4359 (0.4902) loss_zs_kd 0.0410 (0.0233) loss_oracle 0.3955 (0.2767) kd_loss 0.6288 (0.3487) acc 87.5000 (85.8594) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3378 (0.3375) gate/usage_min 0.3288 (0.3294) gate/usage_std 0.0037 (0.0033) teacher/entropy 0.4679 (0.7482) teacher/usage_max 0.5961 (0.4578) teacher/usage_min 0.1352 (0.2105) teacher/usage_std 0.1936 (0.1045) nleep/row_max_mean 1510.5378 (1494.9789) nleep/row_max_std 61.8563 (83.8062) nleep/row_min_mean 1506.3613 (1492.7168) lr 2.0000e-03 eta 0:13:26
epoch [2/50] batch [60/160] time 0.095 (0.101) data 0.000 (0.007) loss 1.1490 (1.0419) teacher_loss 0.2468 (0.4325) loss_zs_kd 0.0435 (0.0315) loss_oracle 0.3849 (0.3224) kd_loss 0.6880 (0.4325) acc 90.6250 (88.3333) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3375 (0.3375) gate/usage_min 0.3277 (0.3290) gate/usage_std 0.0041 (0.0035) teacher/entropy 0.4070 (0.6640) teacher/usage_max 0.5356 (0.4796) teacher/usage_min 0.1604 (0.1926) teacher/usage_std 0.1546 (0.1214) nleep/row_max_mean 1529.2457 (1499.1491) nleep/row_max_std 60.3849 (80.1585) nleep/row_min_mean 1523.5509 (1496.1723) lr 2.0000e-03 eta 0:13:05
epoch [2/50] batch [80/160] time 0.156 (0.101) data 0.000 (0.005) loss 1.4416 (1.0909) teacher_loss 0.3719 (0.3914) loss_zs_kd 0.0483 (0.0356) loss_oracle 0.4640 (0.3503) kd_loss 0.8136 (0.5065) acc 90.6250 (89.5703) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3370 (0.3374) gate/usage_min 0.3263 (0.3286) gate/usage_std 0.0050 (0.0037) teacher/entropy 0.2764 (0.5891) teacher/usage_max 0.6297 (0.5042) teacher/usage_min 0.0598 (0.1760) teacher/usage_std 0.2332 (0.1386) nleep/row_max_mean 1513.5812 (1503.2553) nleep/row_max_std 53.7564 (77.6117) nleep/row_min_mean 1507.1273 (1499.5834) lr 2.0000e-03 eta 0:13:03
epoch [2/50] batch [100/160] time 0.101 (0.100) data 0.000 (0.004) loss 1.4473 (1.1450) teacher_loss 0.2317 (0.3694) loss_zs_kd 0.0672 (0.0387) loss_oracle 0.5271 (0.3715) kd_loss 0.9184 (0.5705) acc 96.8750 (90.0938) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3393 (0.3375) gate/usage_min 0.3242 (0.3279) gate/usage_std 0.0065 (0.0041) teacher/entropy 0.1683 (0.5239) teacher/usage_max 0.4949 (0.5252) teacher/usage_min 0.0447 (0.1595) teacher/usage_std 0.2045 (0.1542) nleep/row_max_mean 1530.8882 (1505.0418) nleep/row_max_std 42.9535 (77.5169) nleep/row_min_mean 1521.9077 (1500.6421) lr 2.0000e-03 eta 0:12:55
epoch [2/50] batch [120/160] time 0.095 (0.099) data 0.001 (0.004) loss 1.5220 (1.1839) teacher_loss 0.3893 (0.3505) loss_zs_kd 0.0429 (0.0413) loss_oracle 0.4161 (0.3817) kd_loss 0.9031 (0.6219) acc 87.5000 (90.5729) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3417 (0.3380) gate/usage_min 0.3220 (0.3271) gate/usage_std 0.0083 (0.0047) teacher/entropy 0.1773 (0.4709) teacher/usage_max 0.6823 (0.5422) teacher/usage_min 0.0443 (0.1457) teacher/usage_std 0.2639 (0.1671) nleep/row_max_mean 1522.3269 (1507.4724) nleep/row_max_std 62.3081 (75.7468) nleep/row_min_mean 1513.2290 (1502.3896) lr 2.0000e-03 eta 0:12:43
epoch [2/50] batch [140/160] time 0.098 (0.101) data 0.000 (0.003) loss 1.2629 (1.2133) teacher_loss 0.2086 (0.3414) loss_zs_kd 0.0258 (0.0421) loss_oracle 0.3651 (0.3836) kd_loss 0.8588 (0.6591) acc 90.6250 (90.7589) gate/entropy 1.0981 (1.0985) gate/usage_max 0.3445 (0.3388) gate/usage_min 0.3197 (0.3262) gate/usage_std 0.0103 (0.0053) teacher/entropy 0.2163 (0.4318) teacher/usage_max 0.7592 (0.5587) teacher/usage_min 0.0662 (0.1353) teacher/usage_std 0.3044 (0.1787) nleep/row_max_mean 1519.6344 (1508.6606) nleep/row_max_std 76.3747 (75.8409) nleep/row_min_mean 1511.0808 (1502.9739) lr 2.0000e-03 eta 0:13:00
epoch [2/50] batch [160/160] time 0.085 (0.099) data 0.000 (0.003) loss 1.2997 (1.2369) teacher_loss 0.1044 (0.3293) loss_zs_kd 0.0403 (0.0430) loss_oracle 0.4978 (0.3928) kd_loss 0.9263 (0.6897) acc 100.0000 (91.1719) gate/entropy 1.0979 (1.0984) gate/usage_max 0.3474 (0.3397) gate/usage_min 0.3174 (0.3253) gate/usage_std 0.0123 (0.0061) teacher/entropy 0.1479 (0.3995) teacher/usage_max 0.6542 (0.5696) teacher/usage_min 0.0958 (0.1291) teacher/usage_std 0.2355 (0.1861) nleep/row_max_mean 1534.8362 (1510.3411) nleep/row_max_std 68.5353 (75.1597) nleep/row_min_mean 1522.5192 (1504.0133) lr 1.9980e-03 eta 0:12:42
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,780
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 82.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,913
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.8%
******* Domain p best val acc:      80.7%, epoch: 2 *******
******* Domain p best val test acc: 86.3%, epoch: 2 *******
******* Domain p best test acc:     86.6%, epoch: 1 *******
epoch [3/50] batch [20/160] time 0.090 (0.099) data 0.000 (0.015) loss 1.3436 (1.4525) teacher_loss 0.2425 (0.2720) loss_zs_kd 0.0440 (0.0519) loss_oracle 0.4159 (0.4584) kd_loss 0.8712 (0.9253) acc 84.3750 (90.3125) gate/entropy 1.0977 (1.0978) gate/usage_max 0.3506 (0.3489) gate/usage_min 0.3151 (0.3163) gate/usage_std 0.0145 (0.0134) teacher/entropy 0.1949 (0.1469) teacher/usage_max 0.7269 (0.6588) teacher/usage_min 0.0846 (0.0947) teacher/usage_std 0.2815 (0.2423) nleep/row_max_mean 1504.4928 (1524.9956) nleep/row_max_std 73.3865 (65.9904) nleep/row_min_mean 1494.0227 (1513.1798) lr 1.9980e-03 eta 0:12:40
epoch [3/50] batch [40/160] time 0.090 (0.091) data 0.000 (0.007) loss 1.5610 (1.4624) teacher_loss 0.3507 (0.2574) loss_zs_kd 0.0620 (0.0510) loss_oracle 0.6049 (0.5075) kd_loss 0.8768 (0.9258) acc 87.5000 (92.1875) gate/entropy 1.0973 (1.0976) gate/usage_max 0.3546 (0.3508) gate/usage_min 0.3130 (0.3151) gate/usage_std 0.0170 (0.0146) teacher/entropy 0.1931 (0.1427) teacher/usage_max 0.6487 (0.6829) teacher/usage_min 0.1729 (0.0974) teacher/usage_std 0.2230 (0.2558) nleep/row_max_mean 1499.6743 (1522.8303) nleep/row_max_std 115.2450 (70.4357) nleep/row_min_mean 1487.4324 (1510.6662) lr 1.9980e-03 eta 0:11:38
epoch [3/50] batch [60/160] time 0.085 (0.089) data 0.000 (0.005) loss 1.5398 (1.4634) teacher_loss 0.3286 (0.2524) loss_zs_kd 0.0644 (0.0526) loss_oracle 0.5844 (0.5204) kd_loss 0.8868 (0.9245) acc 87.5000 (92.1875) gate/entropy 1.0969 (1.0975) gate/usage_max 0.3587 (0.3528) gate/usage_min 0.3114 (0.3141) gate/usage_std 0.0195 (0.0159) teacher/entropy 0.1763 (0.1407) teacher/usage_max 0.6486 (0.6922) teacher/usage_min 0.1496 (0.1003) teacher/usage_std 0.2239 (0.2605) nleep/row_max_mean 1533.4661 (1522.8577) nleep/row_max_std 33.2690 (68.7846) nleep/row_min_mean 1520.4517 (1510.3281) lr 1.9980e-03 eta 0:11:14
epoch [3/50] batch [80/160] time 0.093 (0.087) data 0.000 (0.004) loss 1.5637 (1.4874) teacher_loss 0.3728 (0.2758) loss_zs_kd 0.0798 (0.0525) loss_oracle 0.5053 (0.5262) kd_loss 0.8984 (0.9223) acc 93.7500 (91.5625) gate/entropy 1.0964 (1.0973) gate/usage_max 0.3631 (0.3549) gate/usage_min 0.3099 (0.3132) gate/usage_std 0.0222 (0.0171) teacher/entropy 0.1362 (0.1401) teacher/usage_max 0.8394 (0.6987) teacher/usage_min 0.0714 (0.1015) teacher/usage_std 0.3579 (0.2640) nleep/row_max_mean 1527.9392 (1523.2984) nleep/row_max_std 64.4439 (68.6165) nleep/row_min_mean 1510.6375 (1510.3632) lr 1.9980e-03 eta 0:11:00
epoch [3/50] batch [100/160] time 0.087 (0.087) data 0.000 (0.003) loss 1.5299 (1.5007) teacher_loss 0.3007 (0.2923) loss_zs_kd 0.0256 (0.0490) loss_oracle 0.5228 (0.5278) kd_loss 0.9550 (0.9200) acc 93.7500 (91.2188) gate/entropy 1.0958 (1.0970) gate/usage_max 0.3678 (0.3570) gate/usage_min 0.3086 (0.3124) gate/usage_std 0.0251 (0.0184) teacher/entropy 0.0921 (0.1378) teacher/usage_max 0.7090 (0.7145) teacher/usage_min 0.0733 (0.0935) teacher/usage_std 0.2721 (0.2747) nleep/row_max_mean 1537.3287 (1522.8312) nleep/row_max_std 47.0109 (70.2544) nleep/row_min_mean 1520.9110 (1509.2600) lr 1.9980e-03 eta 0:10:57
epoch [3/50] batch [120/160] time 0.091 (0.088) data 0.000 (0.003) loss 1.8206 (1.5205) teacher_loss 0.6121 (0.3115) loss_zs_kd 0.0250 (0.0461) loss_oracle 0.5633 (0.5366) kd_loss 0.9144 (0.9177) acc 78.1250 (90.4688) gate/entropy 1.0950 (1.0967) gate/usage_max 0.3734 (0.3593) gate/usage_min 0.3074 (0.3116) gate/usage_std 0.0287 (0.0199) teacher/entropy 0.0922 (0.1340) teacher/usage_max 0.8885 (0.7349) teacher/usage_min 0.0005 (0.0823) teacher/usage_std 0.3952 (0.2889) nleep/row_max_mean 1528.3555 (1523.3661) nleep/row_max_std 59.0717 (69.2548) nleep/row_min_mean 1509.3867 (1509.2059) lr 1.9980e-03 eta 0:11:04
epoch [3/50] batch [140/160] time 0.091 (0.089) data 0.000 (0.002) loss 1.4905 (1.5355) teacher_loss 0.3274 (0.3273) loss_zs_kd 0.0144 (0.0427) loss_oracle 0.5241 (0.5407) kd_loss 0.8938 (0.9165) acc 90.6250 (89.5536) gate/entropy 1.0938 (1.0964) gate/usage_max 0.3795 (0.3618) gate/usage_min 0.3056 (0.3109) gate/usage_std 0.0329 (0.0215) teacher/entropy 0.1272 (0.1293) teacher/usage_max 0.7526 (0.7485) teacher/usage_min 0.0287 (0.0726) teacher/usage_std 0.3065 (0.2986) nleep/row_max_mean 1542.1942 (1523.7016) nleep/row_max_std 65.7719 (69.1776) nleep/row_min_mean 1524.0806 (1508.9841) lr 1.9980e-03 eta 0:11:09
epoch [3/50] batch [160/160] time 0.082 (0.089) data 0.000 (0.002) loss 1.5335 (1.5545) teacher_loss 0.3400 (0.3469) loss_zs_kd 0.0297 (0.0396) loss_oracle 0.5958 (0.5423) kd_loss 0.8807 (0.9166) acc 87.5000 (88.6133) gate/entropy 1.0925 (1.0960) gate/usage_max 0.3861 (0.3644) gate/usage_min 0.3036 (0.3101) gate/usage_std 0.0374 (0.0232) teacher/entropy 0.0888 (0.1214) teacher/usage_max 0.9232 (0.7669) teacher/usage_min 0.0263 (0.0644) teacher/usage_std 0.4172 (0.3113) nleep/row_max_mean 1516.0542 (1524.3584) nleep/row_max_std 83.1991 (68.2909) nleep/row_min_mean 1496.5197 (1508.9832) lr 1.9921e-03 eta 0:11:07
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,816
* accuracy: 82.3%
* error: 17.7%
* macro_f1: 84.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,968
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.3%, epoch: 3 *******
******* Domain p best val test acc: 87.9%, epoch: 3 *******
******* Domain p best test acc:     87.9%, epoch: 3 *******
epoch [4/50] batch [20/160] time 0.093 (0.121) data 0.000 (0.018) loss 1.6843 (1.6608) teacher_loss 0.4783 (0.4614) loss_zs_kd 0.0186 (0.0224) loss_oracle 0.5539 (0.5751) kd_loss 0.9197 (0.9006) acc 78.1250 (81.4062) gate/entropy 1.0906 (1.0915) gate/usage_max 0.3936 (0.3900) gate/usage_min 0.3007 (0.3022) gate/usage_std 0.0426 (0.0401) teacher/entropy 0.0401 (0.0627) teacher/usage_max 0.8977 (0.9135) teacher/usage_min 0.0043 (0.0089) teacher/usage_std 0.4009 (0.4115) nleep/row_max_mean 1521.8458 (1524.3422) nleep/row_max_std 77.3609 (69.8875) nleep/row_min_mean 1501.5735 (1503.6166) lr 1.9921e-03 eta 0:15:05
epoch [4/50] batch [40/160] time 0.074 (0.119) data 0.000 (0.009) loss 1.5926 (1.6551) teacher_loss 0.3870 (0.4702) loss_zs_kd 0.0080 (0.0169) loss_oracle 0.5762 (0.5657) kd_loss 0.9135 (0.8936) acc 81.2500 (81.0938) gate/entropy 1.0886 (1.0906) gate/usage_max 0.4010 (0.3937) gate/usage_min 0.2977 (0.3007) gate/usage_std 0.0479 (0.0427) teacher/entropy 0.0195 (0.0596) teacher/usage_max 0.9332 (0.9199) teacher/usage_min 0.0025 (0.0095) teacher/usage_std 0.4249 (0.4158) nleep/row_max_mean 1515.9368 (1525.0062) nleep/row_max_std 81.1723 (69.7045) nleep/row_min_mean 1494.7839 (1504.1607) lr 1.9921e-03 eta 0:14:53
epoch [4/50] batch [60/160] time 0.096 (0.111) data 0.000 (0.006) loss 1.8019 (1.6392) teacher_loss 0.6456 (0.4635) loss_zs_kd 0.0112 (0.0149) loss_oracle 0.5242 (0.5585) kd_loss 0.8886 (0.8890) acc 65.6250 (81.1979) gate/entropy 1.0864 (1.0895) gate/usage_max 0.4083 (0.3975) gate/usage_min 0.2948 (0.2992) gate/usage_std 0.0530 (0.0454) teacher/entropy 0.0160 (0.0548) teacher/usage_max 0.9725 (0.9242) teacher/usage_min 0.0000 (0.0083) teacher/usage_std 0.4521 (0.4188) nleep/row_max_mean 1524.3479 (1525.0718) nleep/row_max_std 63.0367 (69.6118) nleep/row_min_mean 1502.7723 (1503.9515) lr 1.9921e-03 eta 0:13:47
epoch [4/50] batch [80/160] time 0.108 (0.106) data 0.000 (0.005) loss 1.5638 (1.6368) teacher_loss 0.4631 (0.4679) loss_zs_kd 0.0116 (0.0137) loss_oracle 0.5558 (0.5582) kd_loss 0.8171 (0.8830) acc 78.1250 (81.1328) gate/entropy 1.0839 (1.0884) gate/usage_max 0.4156 (0.4012) gate/usage_min 0.2917 (0.2976) gate/usage_std 0.0582 (0.0480) teacher/entropy 0.0797 (0.0501) teacher/usage_max 0.9464 (0.9317) teacher/usage_min 0.0166 (0.0083) teacher/usage_std 0.4336 (0.4240) nleep/row_max_mean 1513.8981 (1525.5671) nleep/row_max_std 41.3008 (67.5828) nleep/row_min_mean 1491.4469 (1504.0795) lr 1.9921e-03 eta 0:13:11
epoch [4/50] batch [100/160] time 0.101 (0.104) data 0.000 (0.004) loss 1.4822 (1.6246) teacher_loss 0.3590 (0.4685) loss_zs_kd 0.0030 (0.0133) loss_oracle 0.4969 (0.5488) kd_loss 0.8733 (0.8751) acc 90.6250 (81.2500) gate/entropy 1.0810 (1.0872) gate/usage_max 0.4235 (0.4050) gate/usage_min 0.2882 (0.2960) gate/usage_std 0.0638 (0.0507) teacher/entropy 0.0103 (0.0467) teacher/usage_max 0.9363 (0.9403) teacher/usage_min 0.0002 (0.0074) teacher/usage_std 0.4272 (0.4299) nleep/row_max_mean 1526.4449 (1525.6338) nleep/row_max_std 48.1449 (66.4706) nleep/row_min_mean 1506.4365 (1503.9352) lr 1.9921e-03 eta 0:12:54
epoch [4/50] batch [120/160] time 0.107 (0.103) data 0.001 (0.003) loss 1.4716 (1.6081) teacher_loss 0.4334 (0.4655) loss_zs_kd 0.0044 (0.0125) loss_oracle 0.5113 (0.5429) kd_loss 0.7803 (0.8649) acc 87.5000 (81.6667) gate/entropy 1.0779 (1.0859) gate/usage_max 0.4313 (0.4088) gate/usage_min 0.2840 (0.2944) gate/usage_std 0.0693 (0.0534) teacher/entropy 0.0716 (0.0471) teacher/usage_max 0.9735 (0.9445) teacher/usage_min 0.0030 (0.0075) teacher/usage_std 0.4527 (0.4328) nleep/row_max_mean 1489.7422 (1525.3444) nleep/row_max_std 113.0416 (66.2931) nleep/row_min_mean 1470.1954 (1503.6433) lr 1.9921e-03 eta 0:12:43
epoch [4/50] batch [140/160] time 0.096 (0.102) data 0.000 (0.003) loss 1.5109 (1.6048) teacher_loss 0.4478 (0.4722) loss_zs_kd 0.0235 (0.0122) loss_oracle 0.5042 (0.5383) kd_loss 0.7993 (0.8574) acc 81.2500 (81.5179) gate/entropy 1.0748 (1.0845) gate/usage_max 0.4383 (0.4125) gate/usage_min 0.2802 (0.2926) gate/usage_std 0.0743 (0.0560) teacher/entropy 0.0514 (0.0451) teacher/usage_max 0.9415 (0.9480) teacher/usage_min 0.0112 (0.0074) teacher/usage_std 0.4303 (0.4352) nleep/row_max_mean 1525.8402 (1525.4602) nleep/row_max_std 52.1944 (65.7915) nleep/row_min_mean 1502.9065 (1503.7484) lr 1.9921e-03 eta 0:12:32
epoch [4/50] batch [160/160] time 0.085 (0.100) data 0.000 (0.003) loss 1.3020 (1.5872) teacher_loss 0.2818 (0.4630) loss_zs_kd 0.0154 (0.0120) loss_oracle 0.4875 (0.5362) kd_loss 0.7688 (0.8501) acc 90.6250 (81.8945) gate/entropy 1.0713 (1.0830) gate/usage_max 0.4461 (0.4163) gate/usage_min 0.2761 (0.2908) gate/usage_std 0.0797 (0.0587) teacher/entropy 0.0491 (0.0432) teacher/usage_max 0.9780 (0.9508) teacher/usage_min 0.0043 (0.0076) teacher/usage_std 0.4559 (0.4371) nleep/row_max_mean 1503.4321 (1525.9168) nleep/row_max_std 87.2757 (64.5377) nleep/row_min_mean 1479.3013 (1504.0517) lr 1.9823e-03 eta 0:12:17
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,823
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 84.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,974
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 88.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.6%, epoch: 4 *******
******* Domain p best val test acc: 88.1%, epoch: 4 *******
******* Domain p best test acc:     88.1%, epoch: 4 *******
epoch [5/50] batch [20/160] time 0.124 (0.136) data 0.000 (0.022) loss 1.5130 (1.5038) teacher_loss 0.5619 (0.4828) loss_zs_kd 0.0196 (0.0119) loss_oracle 0.4932 (0.4836) kd_loss 0.6947 (0.7733) acc 71.8750 (79.8438) gate/entropy 1.0679 (1.0694) gate/usage_max 0.4530 (0.4498) gate/usage_min 0.2724 (0.2742) gate/usage_std 0.0846 (0.0824) teacher/entropy 0.1293 (0.0407) teacher/usage_max 0.9360 (0.9692) teacher/usage_min 0.0252 (0.0076) teacher/usage_std 0.4262 (0.4498) nleep/row_max_mean 1509.7137 (1526.0919) nleep/row_max_std 73.9562 (58.8681) nleep/row_min_mean 1491.8921 (1504.2350) lr 1.9823e-03 eta 0:16:41
epoch [5/50] batch [40/160] time 0.097 (0.119) data 0.000 (0.011) loss 1.5721 (1.4885) teacher_loss 0.6080 (0.4870) loss_zs_kd 0.0176 (0.0127) loss_oracle 0.4387 (0.4700) kd_loss 0.7359 (0.7601) acc 78.1250 (80.4688) gate/entropy 1.0642 (1.0677) gate/usage_max 0.4601 (0.4533) gate/usage_min 0.2687 (0.2723) gate/usage_std 0.0896 (0.0848) teacher/entropy 0.0480 (0.0517) teacher/usage_max 0.9856 (0.9597) teacher/usage_min 0.0025 (0.0107) teacher/usage_std 0.4613 (0.4431) nleep/row_max_mean 1509.0632 (1524.2795) nleep/row_max_std 92.7885 (63.2048) nleep/row_min_mean 1490.0461 (1503.1471) lr 1.9823e-03 eta 0:14:31
epoch [5/50] batch [60/160] time 0.091 (0.111) data 0.000 (0.008) loss 1.2093 (1.4782) teacher_loss 0.2421 (0.4841) loss_zs_kd 0.0088 (0.0130) loss_oracle 0.4361 (0.4646) kd_loss 0.7447 (0.7553) acc 93.7500 (80.6771) gate/entropy 1.0610 (1.0660) gate/usage_max 0.4659 (0.4565) gate/usage_min 0.2656 (0.2706) gate/usage_std 0.0937 (0.0871) teacher/entropy 0.0861 (0.0528) teacher/usage_max 0.8797 (0.9542) teacher/usage_min 0.0531 (0.0126) teacher/usage_std 0.3864 (0.4393) nleep/row_max_mean 1533.7612 (1523.6679) nleep/row_max_std 46.3459 (62.8865) nleep/row_min_mean 1514.3998 (1502.7361) lr 1.9823e-03 eta 0:13:30
epoch [5/50] batch [80/160] time 0.096 (0.109) data 0.000 (0.006) loss 1.5950 (1.4689) teacher_loss 0.6165 (0.4821) loss_zs_kd 0.0184 (0.0124) loss_oracle 0.4865 (0.4634) kd_loss 0.7260 (0.7489) acc 75.0000 (81.0547) gate/entropy 1.0574 (1.0643) gate/usage_max 0.4723 (0.4597) gate/usage_min 0.2623 (0.2690) gate/usage_std 0.0983 (0.0893) teacher/entropy 0.0748 (0.0546) teacher/usage_max 0.9115 (0.9511) teacher/usage_min 0.0408 (0.0144) teacher/usage_std 0.4089 (0.4370) nleep/row_max_mean 1528.8112 (1522.6076) nleep/row_max_std 50.4188 (64.7730) nleep/row_min_mean 1506.2686 (1501.9039) lr 1.9823e-03 eta 0:13:16
epoch [5/50] batch [100/160] time 0.091 (0.105) data 0.000 (0.005) loss 1.4931 (1.4475) teacher_loss 0.5967 (0.4705) loss_zs_kd 0.0149 (0.0125) loss_oracle 0.3648 (0.4592) kd_loss 0.7065 (0.7412) acc 71.8750 (81.9375) gate/entropy 1.0541 (1.0626) gate/usage_max 0.4779 (0.4627) gate/usage_min 0.2594 (0.2674) gate/usage_std 0.1022 (0.0915) teacher/entropy 0.0544 (0.0573) teacher/usage_max 0.9623 (0.9495) teacher/usage_min 0.0103 (0.0147) teacher/usage_std 0.4448 (0.4359) nleep/row_max_mean 1526.5745 (1521.3574) nleep/row_max_std 54.5772 (66.3526) nleep/row_min_mean 1508.6775 (1500.9235) lr 1.9823e-03 eta 0:12:44
epoch [5/50] batch [120/160] time 0.090 (0.103) data 0.000 (0.004) loss 1.1625 (1.4296) teacher_loss 0.2638 (0.4627) loss_zs_kd 0.0097 (0.0125) loss_oracle 0.4078 (0.4502) kd_loss 0.6900 (0.7356) acc 84.3750 (81.8490) gate/entropy 1.0507 (1.0609) gate/usage_max 0.4833 (0.4657) gate/usage_min 0.2565 (0.2658) gate/usage_std 0.1061 (0.0936) teacher/entropy 0.0460 (0.0606) teacher/usage_max 0.9855 (0.9435) teacher/usage_min 0.0001 (0.0151) teacher/usage_std 0.4612 (0.4318) nleep/row_max_mean 1524.2605 (1521.0442) nleep/row_max_std 72.6831 (66.2760) nleep/row_min_mean 1504.1370 (1500.7172) lr 1.9823e-03 eta 0:12:24
epoch [5/50] batch [140/160] time 0.103 (0.102) data 0.000 (0.003) loss 1.2487 (1.4248) teacher_loss 0.2872 (0.4620) loss_zs_kd 0.0204 (0.0133) loss_oracle 0.4665 (0.4474) kd_loss 0.7181 (0.7325) acc 93.7500 (82.1429) gate/entropy 1.0476 (1.0592) gate/usage_max 0.4882 (0.4686) gate/usage_min 0.2537 (0.2642) gate/usage_std 0.1095 (0.0957) teacher/entropy 0.0827 (0.0652) teacher/usage_max 0.8667 (0.9322) teacher/usage_min 0.0112 (0.0138) teacher/usage_std 0.3799 (0.4243) nleep/row_max_mean 1516.8082 (1520.4425) nleep/row_max_std 59.8224 (66.3949) nleep/row_min_mean 1496.4595 (1500.2309) lr 1.9823e-03 eta 0:12:16
epoch [5/50] batch [160/160] time 0.076 (0.100) data 0.000 (0.003) loss 1.5567 (1.4163) teacher_loss 0.6151 (0.4569) loss_zs_kd 0.0254 (0.0138) loss_oracle 0.4708 (0.4501) kd_loss 0.6936 (0.7274) acc 81.2500 (82.5781) gate/entropy 1.0444 (1.0575) gate/usage_max 0.4930 (0.4714) gate/usage_min 0.2508 (0.2627) gate/usage_std 0.1129 (0.0976) teacher/entropy 0.0616 (0.0700) teacher/usage_max 0.9266 (0.9246) teacher/usage_min 0.0046 (0.0125) teacher/usage_std 0.4203 (0.4193) nleep/row_max_mean 1528.2924 (1520.5533) nleep/row_max_std 61.6656 (66.0763) nleep/row_min_mean 1508.6282 (1500.3001) lr 1.9686e-03 eta 0:12:00
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,834
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 85.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,002
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 89.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.1%, epoch: 5 *******
******* Domain p best val test acc: 88.9%, epoch: 5 *******
******* Domain p best test acc:     88.9%, epoch: 5 *******
epoch [6/50] batch [20/160] time 0.090 (0.108) data 0.000 (0.020) loss 1.4380 (1.3608) teacher_loss 0.4358 (0.4318) loss_zs_kd 0.0087 (0.0173) loss_oracle 0.5955 (0.4807) kd_loss 0.7000 (0.6800) acc 78.1250 (83.1250) gate/entropy 1.0421 (1.0431) gate/usage_max 0.4965 (0.4950) gate/usage_min 0.2487 (0.2496) gate/usage_std 0.1154 (0.1143) teacher/entropy 0.0248 (0.0824) teacher/usage_max 0.9625 (0.9102) teacher/usage_min 0.0002 (0.0039) teacher/usage_std 0.4452 (0.4098) nleep/row_max_mean 1505.3853 (1520.1670) nleep/row_max_std 72.7623 (60.4811) nleep/row_min_mean 1481.1907 (1498.8828) lr 1.9686e-03 eta 0:12:58
epoch [6/50] batch [40/160] time 0.088 (0.098) data 0.000 (0.010) loss 1.4293 (1.3474) teacher_loss 0.5316 (0.4291) loss_zs_kd 0.0082 (0.0151) loss_oracle 0.4902 (0.4675) kd_loss 0.6485 (0.6769) acc 75.0000 (83.6719) gate/entropy 1.0389 (1.0417) gate/usage_max 0.5011 (0.4970) gate/usage_min 0.2460 (0.2484) gate/usage_std 0.1187 (0.1158) teacher/entropy 0.0898 (0.0806) teacher/usage_max 0.9309 (0.9123) teacher/usage_min 0.0121 (0.0046) teacher/usage_std 0.4229 (0.4112) nleep/row_max_mean 1511.7383 (1516.9373) nleep/row_max_std 89.4240 (65.9540) nleep/row_min_mean 1490.9739 (1495.5555) lr 1.9686e-03 eta 0:11:44
epoch [6/50] batch [60/160] time 0.092 (0.095) data 0.000 (0.007) loss 1.4928 (1.3508) teacher_loss 0.5693 (0.4360) loss_zs_kd 0.0138 (0.0158) loss_oracle 0.4459 (0.4664) kd_loss 0.6936 (0.6737) acc 84.3750 (83.4896) gate/entropy 1.0356 (1.0402) gate/usage_max 0.5058 (0.4992) gate/usage_min 0.2436 (0.2472) gate/usage_std 0.1220 (0.1173) teacher/entropy 0.0110 (0.0721) teacher/usage_max 0.9670 (0.9242) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.4483 (0.4192) nleep/row_max_mean 1525.0912 (1517.8757) nleep/row_max_std 60.8916 (64.6046) nleep/row_min_mean 1501.3743 (1496.1632) lr 1.9686e-03 eta 0:11:18
epoch [6/50] batch [80/160] time 0.099 (0.095) data 0.000 (0.005) loss 1.2644 (1.3638) teacher_loss 0.3420 (0.4514) loss_zs_kd 0.0058 (0.0145) loss_oracle 0.4903 (0.4669) kd_loss 0.6743 (0.6717) acc 84.3750 (82.8516) gate/entropy 1.0329 (1.0387) gate/usage_max 0.5095 (0.5013) gate/usage_min 0.2416 (0.2461) gate/usage_std 0.1246 (0.1188) teacher/entropy 0.0203 (0.0668) teacher/usage_max 0.9716 (0.9294) teacher/usage_min 0.0022 (0.0049) teacher/usage_std 0.4515 (0.4226) nleep/row_max_mean 1531.9930 (1518.4157) nleep/row_max_std 45.6437 (64.8919) nleep/row_min_mean 1507.5593 (1496.5887) lr 1.9686e-03 eta 0:11:15
epoch [6/50] batch [100/160] time 0.099 (0.095) data 0.000 (0.004) loss 1.4874 (1.3706) teacher_loss 0.5508 (0.4640) loss_zs_kd 0.0135 (0.0134) loss_oracle 0.4781 (0.4617) kd_loss 0.6908 (0.6691) acc 81.2500 (82.5000) gate/entropy 1.0300 (1.0373) gate/usage_max 0.5134 (0.5033) gate/usage_min 0.2396 (0.2450) gate/usage_std 0.1274 (0.1202) teacher/entropy 0.0807 (0.0619) teacher/usage_max 0.8571 (0.9353) teacher/usage_min 0.0307 (0.0055) teacher/usage_std 0.3719 (0.4266) nleep/row_max_mean 1507.6150 (1517.8978) nleep/row_max_std 79.5420 (66.4717) nleep/row_min_mean 1486.1085 (1496.0248) lr 1.9686e-03 eta 0:11:16
epoch [6/50] batch [120/160] time 0.091 (0.095) data 0.000 (0.004) loss 1.3097 (1.3666) teacher_loss 0.4353 (0.4620) loss_zs_kd 0.0068 (0.0131) loss_oracle 0.4632 (0.4614) kd_loss 0.6394 (0.6674) acc 81.2500 (82.6042) gate/entropy 1.0271 (1.0358) gate/usage_max 0.5172 (0.5053) gate/usage_min 0.2378 (0.2439) gate/usage_std 0.1301 (0.1216) teacher/entropy 0.0272 (0.0569) teacher/usage_max 0.9903 (0.9399) teacher/usage_min 0.0028 (0.0052) teacher/usage_std 0.4646 (0.4297) nleep/row_max_mean 1530.6179 (1518.5969) nleep/row_max_std 49.5211 (66.0425) nleep/row_min_mean 1504.8719 (1496.3665) lr 1.9686e-03 eta 0:11:12
epoch [6/50] batch [140/160] time 0.076 (0.094) data 0.000 (0.003) loss 1.1055 (1.3531) teacher_loss 0.2614 (0.4515) loss_zs_kd 0.0082 (0.0130) loss_oracle 0.4036 (0.4605) kd_loss 0.6382 (0.6649) acc 90.6250 (82.9241) gate/entropy 1.0245 (1.0344) gate/usage_max 0.5206 (0.5073) gate/usage_min 0.2362 (0.2429) gate/usage_std 0.1325 (0.1230) teacher/entropy 0.0273 (0.0533) teacher/usage_max 0.9838 (0.9435) teacher/usage_min 0.0008 (0.0054) teacher/usage_std 0.4600 (0.4322) nleep/row_max_mean 1503.6298 (1519.0492) nleep/row_max_std 86.8401 (65.6790) nleep/row_min_mean 1481.7430 (1496.6181) lr 1.9686e-03 eta 0:11:06
epoch [6/50] batch [160/160] time 0.083 (0.093) data 0.000 (0.003) loss 1.2417 (1.3484) teacher_loss 0.3770 (0.4501) loss_zs_kd 0.0091 (0.0128) loss_oracle 0.4216 (0.4583) kd_loss 0.6493 (0.6627) acc 87.5000 (83.0273) gate/entropy 1.0216 (1.0330) gate/usage_max 0.5243 (0.5092) gate/usage_min 0.2345 (0.2420) gate/usage_std 0.1351 (0.1244) teacher/entropy 0.0265 (0.0491) teacher/usage_max 0.9613 (0.9478) teacher/usage_min 0.0057 (0.0052) teacher/usage_std 0.4442 (0.4352) nleep/row_max_mean 1528.4771 (1519.6444) nleep/row_max_std 70.1637 (64.9174) nleep/row_min_mean 1503.4724 (1496.9713) lr 1.9511e-03 eta 0:10:56
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 85.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,012
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 89.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.4%, epoch: 6 *******
******* Domain p best val test acc: 89.2%, epoch: 6 *******
******* Domain p best test acc:     89.2%, epoch: 6 *******
epoch [7/50] batch [20/160] time 0.089 (0.106) data 0.000 (0.014) loss 1.3556 (1.2950) teacher_loss 0.4895 (0.4242) loss_zs_kd 0.0098 (0.0106) loss_oracle 0.4519 (0.4575) kd_loss 0.6353 (0.6368) acc 81.2500 (82.1875) gate/entropy 1.0192 (1.0204) gate/usage_max 0.5274 (0.5259) gate/usage_min 0.2332 (0.2338) gate/usage_std 0.1372 (0.1362) teacher/entropy 0.0054 (0.0157) teacher/usage_max 0.9990 (0.9877) teacher/usage_min 0.0002 (0.0018) teacher/usage_std 0.4707 (0.4627) nleep/row_max_mean 1523.1772 (1519.8095) nleep/row_max_std 72.3039 (66.9401) nleep/row_min_mean 1498.1206 (1494.7296) lr 1.9511e-03 eta 0:12:26
epoch [7/50] batch [40/160] time 0.153 (0.108) data 0.001 (0.007) loss 1.2464 (1.2873) teacher_loss 0.3438 (0.4205) loss_zs_kd 0.0144 (0.0109) loss_oracle 0.4881 (0.4578) kd_loss 0.6513 (0.6325) acc 96.8750 (83.5938) gate/entropy 1.0169 (1.0192) gate/usage_max 0.5303 (0.5273) gate/usage_min 0.2319 (0.2331) gate/usage_std 0.1393 (0.1372) teacher/entropy 0.0070 (0.0178) teacher/usage_max 0.9690 (0.9870) teacher/usage_min 0.0002 (0.0021) teacher/usage_std 0.4497 (0.4622) nleep/row_max_mean 1512.3097 (1517.6732) nleep/row_max_std 88.4452 (68.8587) nleep/row_min_mean 1486.2451 (1492.6329) lr 1.9511e-03 eta 0:12:36
epoch [7/50] batch [60/160] time 0.090 (0.105) data 0.000 (0.005) loss 1.1949 (1.2967) teacher_loss 0.3521 (0.4376) loss_zs_kd 0.0174 (0.0106) loss_oracle 0.4415 (0.4482) kd_loss 0.6134 (0.6297) acc 90.6250 (83.2292) gate/entropy 1.0147 (1.0180) gate/usage_max 0.5329 (0.5288) gate/usage_min 0.2307 (0.2325) gate/usage_std 0.1411 (0.1382) teacher/entropy 0.0405 (0.0184) teacher/usage_max 0.9702 (0.9865) teacher/usage_min 0.0085 (0.0020) teacher/usage_std 0.4504 (0.4619) nleep/row_max_mean 1531.6572 (1518.8253) nleep/row_max_std 31.4669 (65.9277) nleep/row_min_mean 1506.0583 (1493.3128) lr 1.9511e-03 eta 0:12:13
epoch [7/50] batch [80/160] time 0.096 (0.103) data 0.000 (0.004) loss 1.2074 (1.2978) teacher_loss 0.3688 (0.4426) loss_zs_kd 0.0118 (0.0103) loss_oracle 0.4056 (0.4416) kd_loss 0.6299 (0.6293) acc 81.2500 (83.1250) gate/entropy 1.0123 (1.0169) gate/usage_max 0.5359 (0.5302) gate/usage_min 0.2294 (0.2319) gate/usage_std 0.1432 (0.1392) teacher/entropy 0.0293 (0.0180) teacher/usage_max 0.9580 (0.9843) teacher/usage_min 0.0010 (0.0017) teacher/usage_std 0.4420 (0.4604) nleep/row_max_mean 1523.8718 (1520.1271) nleep/row_max_std 73.6582 (63.6155) nleep/row_min_mean 1498.6085 (1494.3060) lr 1.9511e-03 eta 0:11:54
epoch [7/50] batch [100/160] time 0.099 (0.101) data 0.000 (0.003) loss 1.3714 (1.3075) teacher_loss 0.4934 (0.4542) loss_zs_kd 0.0053 (0.0101) loss_oracle 0.4834 (0.4444) kd_loss 0.6337 (0.6260) acc 84.3750 (82.5312) gate/entropy 1.0106 (1.0158) gate/usage_max 0.5379 (0.5315) gate/usage_min 0.2285 (0.2313) gate/usage_std 0.1447 (0.1402) teacher/entropy 0.0122 (0.0184) teacher/usage_max 0.9694 (0.9849) teacher/usage_min 0.0004 (0.0016) teacher/usage_std 0.4500 (0.4608) nleep/row_max_mean 1511.2660 (1518.7524) nleep/row_max_std 81.4863 (65.1125) nleep/row_min_mean 1485.4569 (1492.8733) lr 1.9511e-03 eta 0:11:44
epoch [7/50] batch [120/160] time 0.098 (0.100) data 0.000 (0.003) loss 1.2903 (1.3071) teacher_loss 0.4574 (0.4559) loss_zs_kd 0.0162 (0.0102) loss_oracle 0.4487 (0.4435) kd_loss 0.6004 (0.6244) acc 81.2500 (82.3698) gate/entropy 1.0086 (1.0148) gate/usage_max 0.5402 (0.5328) gate/usage_min 0.2276 (0.2308) gate/usage_std 0.1463 (0.1411) teacher/entropy 0.0231 (0.0174) teacher/usage_max 0.9910 (0.9854) teacher/usage_min 0.0014 (0.0015) teacher/usage_std 0.4651 (0.4611) nleep/row_max_mean 1510.9214 (1518.4915) nleep/row_max_std 77.4509 (64.6226) nleep/row_min_mean 1480.9089 (1492.2943) lr 1.9511e-03 eta 0:11:34
epoch [7/50] batch [140/160] time 0.092 (0.100) data 0.000 (0.002) loss 1.2258 (1.2997) teacher_loss 0.4144 (0.4511) loss_zs_kd 0.0044 (0.0103) loss_oracle 0.4224 (0.4429) kd_loss 0.5980 (0.6221) acc 81.2500 (82.4330) gate/entropy 1.0071 (1.0138) gate/usage_max 0.5420 (0.5340) gate/usage_min 0.2268 (0.2302) gate/usage_std 0.1475 (0.1419) teacher/entropy 0.0189 (0.0172) teacher/usage_max 0.9950 (0.9857) teacher/usage_min 0.0003 (0.0014) teacher/usage_std 0.4678 (0.4614) nleep/row_max_mean 1522.2521 (1518.7620) nleep/row_max_std 60.4620 (64.8860) nleep/row_min_mean 1496.9406 (1492.2474) lr 1.9511e-03 eta 0:11:27
epoch [7/50] batch [160/160] time 0.080 (0.098) data 0.000 (0.002) loss 1.1513 (1.3008) teacher_loss 0.3155 (0.4537) loss_zs_kd 0.0209 (0.0104) loss_oracle 0.4440 (0.4441) kd_loss 0.6033 (0.6199) acc 87.5000 (82.2852) gate/entropy 1.0051 (1.0128) gate/usage_max 0.5442 (0.5351) gate/usage_min 0.2258 (0.2297) gate/usage_std 0.1491 (0.1427) teacher/entropy 0.0066 (0.0169) teacher/usage_max 0.9983 (0.9861) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.4702 (0.4617) nleep/row_max_mean 1540.9216 (1519.1847) nleep/row_max_std 21.3155 (64.6332) nleep/row_min_mean 1508.6660 (1492.3449) lr 1.9298e-03 eta 0:11:15
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,843
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,009
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 89.9%
******* Domain p best val acc:      83.5%, epoch: 7 *******
******* Domain p best val test acc: 89.1%, epoch: 7 *******
******* Domain p best test acc:     89.2%, epoch: 6 *******
epoch [8/50] batch [20/160] time 0.080 (0.100) data 0.000 (0.015) loss 1.3007 (1.2535) teacher_loss 0.4539 (0.4222) loss_zs_kd 0.0057 (0.0098) loss_oracle 0.4821 (0.4463) kd_loss 0.6029 (0.6033) acc 78.1250 (84.2188) gate/entropy 1.0040 (1.0045) gate/usage_max 0.5455 (0.5449) gate/usage_min 0.2252 (0.2255) gate/usage_std 0.1500 (0.1496) teacher/entropy 0.0037 (0.0107) teacher/usage_max 0.9994 (0.9922) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4710 (0.4660) nleep/row_max_mean 1531.1007 (1522.2625) nleep/row_max_std 21.5240 (57.0141) nleep/row_min_mean 1500.9861 (1493.0709) lr 1.9298e-03 eta 0:11:25
epoch [8/50] batch [40/160] time 0.086 (0.091) data 0.000 (0.008) loss 1.4780 (1.2873) teacher_loss 0.6328 (0.4576) loss_zs_kd 0.0175 (0.0110) loss_oracle 0.4678 (0.4471) kd_loss 0.6025 (0.6007) acc 78.1250 (83.2031) gate/entropy 1.0023 (1.0038) gate/usage_max 0.5474 (0.5458) gate/usage_min 0.2244 (0.2251) gate/usage_std 0.1514 (0.1502) teacher/entropy 0.0000 (0.0140) teacher/usage_max 1.0000 (0.9896) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4714 (0.4641) nleep/row_max_mean 1536.5122 (1518.1494) nleep/row_max_std 23.6314 (65.5783) nleep/row_min_mean 1502.2942 (1488.6348) lr 1.9298e-03 eta 0:10:19
epoch [8/50] batch [60/160] time 0.100 (0.093) data 0.001 (0.005) loss 1.4002 (1.2769) teacher_loss 0.5791 (0.4465) loss_zs_kd 0.0102 (0.0108) loss_oracle 0.4382 (0.4502) kd_loss 0.5968 (0.5998) acc 71.8750 (83.6979) gate/entropy 1.0010 (1.0030) gate/usage_max 0.5489 (0.5466) gate/usage_min 0.2238 (0.2248) gate/usage_std 0.1524 (0.1508) teacher/entropy 0.0036 (0.0114) teacher/usage_max 0.9993 (0.9918) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4709 (0.4656) nleep/row_max_mean 1520.5291 (1519.2885) nleep/row_max_std 55.3990 (64.7788) nleep/row_min_mean 1488.5717 (1489.6721) lr 1.9298e-03 eta 0:10:34
epoch [8/50] batch [80/160] time 0.131 (0.094) data 0.000 (0.004) loss 1.6873 (1.2831) teacher_loss 0.7944 (0.4520) loss_zs_kd 0.0275 (0.0107) loss_oracle 0.5601 (0.4535) kd_loss 0.5990 (0.5990) acc 68.7500 (83.3594) gate/entropy 0.9998 (1.0024) gate/usage_max 0.5503 (0.5473) gate/usage_min 0.2232 (0.2245) gate/usage_std 0.1534 (0.1513) teacher/entropy 0.0186 (0.0112) teacher/usage_max 0.9774 (0.9914) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.4555 (0.4654) nleep/row_max_mean 1526.6075 (1519.7412) nleep/row_max_std 30.8277 (63.8418) nleep/row_min_mean 1494.8918 (1490.0932) lr 1.9298e-03 eta 0:10:39
epoch [8/50] batch [100/160] time 0.106 (0.095) data 0.000 (0.003) loss 1.3208 (1.2799) teacher_loss 0.5273 (0.4496) loss_zs_kd 0.0162 (0.0104) loss_oracle 0.4071 (0.4537) kd_loss 0.5818 (0.5982) acc 84.3750 (83.1250) gate/entropy 0.9987 (1.0017) gate/usage_max 0.5515 (0.5481) gate/usage_min 0.2226 (0.2241) gate/usage_std 0.1543 (0.1518) teacher/entropy 0.0172 (0.0109) teacher/usage_max 0.9956 (0.9912) teacher/usage_min 0.0013 (0.0010) teacher/usage_std 0.4683 (0.4652) nleep/row_max_mean 1509.3982 (1520.4067) nleep/row_max_std 80.2270 (63.4240) nleep/row_min_mean 1479.7666 (1490.7966) lr 1.9298e-03 eta 0:10:42
epoch [8/50] batch [120/160] time 0.098 (0.095) data 0.000 (0.003) loss 1.2337 (1.2757) teacher_loss 0.4317 (0.4495) loss_zs_kd 0.0073 (0.0104) loss_oracle 0.4183 (0.4483) kd_loss 0.5892 (0.5968) acc 78.1250 (83.1771) gate/entropy 0.9975 (1.0011) gate/usage_max 0.5528 (0.5488) gate/usage_min 0.2221 (0.2238) gate/usage_std 0.1552 (0.1523) teacher/entropy 0.0043 (0.0102) teacher/usage_max 0.9992 (0.9921) teacher/usage_min 0.0001 (0.0009) teacher/usage_std 0.4708 (0.4659) nleep/row_max_mean 1520.8954 (1520.0913) nleep/row_max_std 60.8447 (64.7219) nleep/row_min_mean 1491.2915 (1490.5444) lr 1.9298e-03 eta 0:10:44
epoch [8/50] batch [140/160] time 0.106 (0.096) data 0.000 (0.002) loss 1.4693 (1.2733) teacher_loss 0.6620 (0.4509) loss_zs_kd 0.0021 (0.0103) loss_oracle 0.4351 (0.4433) kd_loss 0.5887 (0.5956) acc 78.1250 (83.3705) gate/entropy 0.9964 (1.0005) gate/usage_max 0.5540 (0.5494) gate/usage_min 0.2215 (0.2235) gate/usage_std 0.1560 (0.1528) teacher/entropy 0.0022 (0.0096) teacher/usage_max 0.9996 (0.9928) teacher/usage_min 0.0001 (0.0008) teacher/usage_std 0.4711 (0.4664) nleep/row_max_mean 1520.7480 (1520.1782) nleep/row_max_std 74.7672 (64.7799) nleep/row_min_mean 1491.7971 (1490.7339) lr 1.9298e-03 eta 0:10:45
epoch [8/50] batch [160/160] time 0.107 (0.095) data 0.000 (0.002) loss 1.2744 (1.2705) teacher_loss 0.4703 (0.4509) loss_zs_kd 0.0175 (0.0103) loss_oracle 0.4234 (0.4404) kd_loss 0.5837 (0.5942) acc 81.2500 (83.3203) gate/entropy 0.9957 (1.0000) gate/usage_max 0.5548 (0.5501) gate/usage_min 0.2212 (0.2233) gate/usage_std 0.1566 (0.1533) teacher/entropy 0.0068 (0.0093) teacher/usage_max 0.9986 (0.9935) teacher/usage_min 0.0007 (0.0007) teacher/usage_std 0.4704 (0.4668) nleep/row_max_mean 1534.1636 (1520.6765) nleep/row_max_std 24.6077 (63.8640) nleep/row_min_mean 1504.4222 (1491.3798) lr 1.9048e-03 eta 0:10:41
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,838
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,007
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 89.8%
******* Domain p best val acc:      83.5%, epoch: 7 *******
******* Domain p best val test acc: 89.1%, epoch: 7 *******
******* Domain p best test acc:     89.2%, epoch: 6 *******
epoch [9/50] batch [20/160] time 0.074 (0.093) data 0.000 (0.013) loss 1.2268 (1.2363) teacher_loss 0.4077 (0.4383) loss_zs_kd 0.0047 (0.0093) loss_oracle 0.4142 (0.4125) kd_loss 0.6096 (0.5871) acc 84.3750 (83.1250) gate/entropy 0.9948 (0.9951) gate/usage_max 0.5558 (0.5555) gate/usage_min 0.2207 (0.2209) gate/usage_std 0.1573 (0.1571) teacher/entropy 0.0062 (0.0100) teacher/usage_max 0.9685 (0.9900) teacher/usage_min 0.0005 (0.0004) teacher/usage_std 0.4493 (0.4644) nleep/row_max_mean 1515.5876 (1517.6924) nleep/row_max_std 71.4299 (68.5927) nleep/row_min_mean 1487.7468 (1490.0483) lr 1.9048e-03 eta 0:10:21
epoch [9/50] batch [40/160] time 0.087 (0.087) data 0.000 (0.007) loss 1.4741 (1.2481) teacher_loss 0.6263 (0.4496) loss_zs_kd 0.0055 (0.0100) loss_oracle 0.4728 (0.4162) kd_loss 0.6087 (0.5853) acc 68.7500 (83.4375) gate/entropy 0.9940 (0.9947) gate/usage_max 0.5566 (0.5559) gate/usage_min 0.2204 (0.2207) gate/usage_std 0.1579 (0.1574) teacher/entropy 0.0050 (0.0110) teacher/usage_max 0.9691 (0.9900) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4497 (0.4644) nleep/row_max_mean 1527.4731 (1519.1544) nleep/row_max_std 36.6396 (65.0226) nleep/row_min_mean 1500.0918 (1491.3076) lr 1.9048e-03 eta 0:09:41
epoch [9/50] batch [60/160] time 0.098 (0.089) data 0.002 (0.005) loss 1.2859 (1.2321) teacher_loss 0.5261 (0.4399) loss_zs_kd 0.0114 (0.0102) loss_oracle 0.3686 (0.4048) kd_loss 0.5697 (0.5847) acc 84.3750 (84.1667) gate/entropy 0.9929 (0.9943) gate/usage_max 0.5578 (0.5563) gate/usage_min 0.2199 (0.2205) gate/usage_std 0.1588 (0.1577) teacher/entropy 0.0184 (0.0091) teacher/usage_max 0.9952 (0.9919) teacher/usage_min 0.0009 (0.0003) teacher/usage_std 0.4680 (0.4657) nleep/row_max_mean 1515.9192 (1520.6229) nleep/row_max_std 90.6737 (64.5193) nleep/row_min_mean 1491.1670 (1493.0264) lr 1.9048e-03 eta 0:09:55
epoch [9/50] batch [80/160] time 0.083 (0.091) data 0.000 (0.003) loss 1.2011 (1.2305) teacher_loss 0.4094 (0.4419) loss_zs_kd 0.0091 (0.0099) loss_oracle 0.4507 (0.4021) kd_loss 0.5618 (0.5826) acc 84.3750 (83.5547) gate/entropy 0.9923 (0.9939) gate/usage_max 0.5585 (0.5568) gate/usage_min 0.2196 (0.2203) gate/usage_std 0.1592 (0.1580) teacher/entropy 0.0312 (0.0115) teacher/usage_max 0.9886 (0.9909) teacher/usage_min 0.0032 (0.0008) teacher/usage_std 0.4634 (0.4650) nleep/row_max_mean 1516.9109 (1520.7225) nleep/row_max_std 80.7041 (64.2167) nleep/row_min_mean 1490.7535 (1493.4980) lr 1.9048e-03 eta 0:10:01
epoch [9/50] batch [100/160] time 0.095 (0.091) data 0.000 (0.003) loss 1.1951 (1.2360) teacher_loss 0.3988 (0.4496) loss_zs_kd 0.0119 (0.0100) loss_oracle 0.4190 (0.3998) kd_loss 0.5808 (0.5816) acc 81.2500 (82.8438) gate/entropy 0.9916 (0.9935) gate/usage_max 0.5592 (0.5572) gate/usage_min 0.2193 (0.2202) gate/usage_std 0.1597 (0.1583) teacher/entropy 0.0005 (0.0117) teacher/usage_max 0.9999 (0.9908) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.4714 (0.4649) nleep/row_max_mean 1534.4500 (1520.9783) nleep/row_max_std 46.3158 (64.0629) nleep/row_min_mean 1505.9537 (1493.9812) lr 1.9048e-03 eta 0:10:01
epoch [9/50] batch [120/160] time 0.097 (0.091) data 0.000 (0.002) loss 1.0655 (1.2341) teacher_loss 0.2884 (0.4477) loss_zs_kd 0.0154 (0.0097) loss_oracle 0.4017 (0.4026) kd_loss 0.5685 (0.5802) acc 93.7500 (82.9688) gate/entropy 0.9912 (0.9932) gate/usage_max 0.5597 (0.5575) gate/usage_min 0.2191 (0.2200) gate/usage_std 0.1600 (0.1585) teacher/entropy 0.0174 (0.0125) teacher/usage_max 0.9941 (0.9907) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.4673 (0.4649) nleep/row_max_mean 1527.3596 (1520.0280) nleep/row_max_std 45.6230 (64.7946) nleep/row_min_mean 1501.1702 (1493.2656) lr 1.9048e-03 eta 0:10:02
epoch [9/50] batch [140/160] time 0.091 (0.092) data 0.000 (0.002) loss 1.4246 (1.2266) teacher_loss 0.6709 (0.4407) loss_zs_kd 0.0087 (0.0101) loss_oracle 0.3504 (0.4015) kd_loss 0.5741 (0.5800) acc 68.7500 (83.2589) gate/entropy 0.9904 (0.9928) gate/usage_max 0.5605 (0.5579) gate/usage_min 0.2187 (0.2198) gate/usage_std 0.1606 (0.1588) teacher/entropy 0.0056 (0.0125) teacher/usage_max 0.9991 (0.9902) teacher/usage_min 0.0004 (0.0012) teacher/usage_std 0.4708 (0.4645) nleep/row_max_mean 1519.4727 (1520.6679) nleep/row_max_std 82.9006 (63.7089) nleep/row_min_mean 1496.0132 (1494.0805) lr 1.9048e-03 eta 0:10:02
epoch [9/50] batch [160/160] time 0.087 (0.091) data 0.000 (0.002) loss 1.2160 (1.2269) teacher_loss 0.3614 (0.4425) loss_zs_kd 0.0067 (0.0104) loss_oracle 0.4749 (0.4006) kd_loss 0.6138 (0.5789) acc 84.3750 (83.1250) gate/entropy 0.9900 (0.9925) gate/usage_max 0.5609 (0.5583) gate/usage_min 0.2186 (0.2197) gate/usage_std 0.1609 (0.1591) teacher/entropy 0.0251 (0.0138) teacher/usage_max 0.9352 (0.9894) teacher/usage_min 0.0315 (0.0014) teacher/usage_std 0.4256 (0.4640) nleep/row_max_mean 1516.0093 (1520.9577) nleep/row_max_std 68.6877 (63.2458) nleep/row_min_mean 1491.3966 (1494.6233) lr 1.8763e-03 eta 0:09:58
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,838
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,985
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.3%
******* Domain p best val acc:      83.5%, epoch: 7 *******
******* Domain p best val test acc: 89.1%, epoch: 7 *******
******* Domain p best test acc:     89.2%, epoch: 6 *******
epoch [10/50] batch [20/160] time 0.078 (0.095) data 0.000 (0.016) loss 1.1585 (1.2210) teacher_loss 0.3923 (0.4333) loss_zs_kd 0.0128 (0.0153) loss_oracle 0.3772 (0.4013) kd_loss 0.5712 (0.5794) acc 84.3750 (82.1875) gate/entropy 0.9894 (0.9897) gate/usage_max 0.5616 (0.5613) gate/usage_min 0.2183 (0.2184) gate/usage_std 0.1614 (0.1612) teacher/entropy 0.0316 (0.0199) teacher/usage_max 0.9726 (0.9767) teacher/usage_min 0.0064 (0.0019) teacher/usage_std 0.4520 (0.4551) nleep/row_max_mean 1529.5680 (1522.4052) nleep/row_max_std 46.2216 (56.9918) nleep/row_min_mean 1503.4612 (1498.1999) lr 1.8763e-03 eta 0:10:21
epoch [10/50] batch [40/160] time 0.094 (0.090) data 0.000 (0.008) loss 1.0063 (1.2098) teacher_loss 0.2813 (0.4402) loss_zs_kd 0.0058 (0.0145) loss_oracle 0.3171 (0.3748) kd_loss 0.5636 (0.5749) acc 84.3750 (83.0469) gate/entropy 0.9890 (0.9894) gate/usage_max 0.5620 (0.5616) gate/usage_min 0.2181 (0.2183) gate/usage_std 0.1617 (0.1614) teacher/entropy 0.0166 (0.0259) teacher/usage_max 0.9958 (0.9746) teacher/usage_min 0.0003 (0.0049) teacher/usage_std 0.4684 (0.4536) nleep/row_max_mean 1524.3938 (1520.6455) nleep/row_max_std 72.5012 (58.8367) nleep/row_min_mean 1501.7921 (1497.2481) lr 1.8763e-03 eta 0:09:48
epoch [10/50] batch [60/160] time 0.092 (0.092) data 0.000 (0.005) loss 1.3851 (1.2120) teacher_loss 0.6301 (0.4467) loss_zs_kd 0.0101 (0.0135) loss_oracle 0.3811 (0.3719) kd_loss 0.5594 (0.5726) acc 81.2500 (83.0208) gate/entropy 0.9886 (0.9892) gate/usage_max 0.5625 (0.5619) gate/usage_min 0.2179 (0.2182) gate/usage_std 0.1620 (0.1616) teacher/entropy 0.0365 (0.0314) teacher/usage_max 0.9784 (0.9707) teacher/usage_min 0.0022 (0.0053) teacher/usage_std 0.4562 (0.4508) nleep/row_max_mean 1501.9641 (1521.2121) nleep/row_max_std 82.3474 (57.9020) nleep/row_min_mean 1482.1477 (1498.4334) lr 1.8763e-03 eta 0:09:56
epoch [10/50] batch [80/160] time 0.099 (0.092) data 0.000 (0.004) loss 1.3661 (1.2025) teacher_loss 0.5734 (0.4390) loss_zs_kd 0.0063 (0.0140) loss_oracle 0.3462 (0.3717) kd_loss 0.6165 (0.5706) acc 81.2500 (82.8516) gate/entropy 0.9882 (0.9889) gate/usage_max 0.5629 (0.5621) gate/usage_min 0.2177 (0.2181) gate/usage_std 0.1623 (0.1618) teacher/entropy 0.0689 (0.0381) teacher/usage_max 0.8819 (0.9653) teacher/usage_min 0.0003 (0.0055) teacher/usage_std 0.3909 (0.4471) nleep/row_max_mean 1516.0208 (1519.8271) nleep/row_max_std 69.5327 (61.7735) nleep/row_min_mean 1497.7537 (1497.7243) lr 1.8763e-03 eta 0:09:58
epoch [10/50] batch [100/160] time 0.072 (0.096) data 0.000 (0.003) loss 1.0209 (1.2046) teacher_loss 0.2881 (0.4420) loss_zs_kd 0.0093 (0.0148) loss_oracle 0.3336 (0.3691) kd_loss 0.5613 (0.5707) acc 87.5000 (82.9062) gate/entropy 0.9876 (0.9887) gate/usage_max 0.5635 (0.5623) gate/usage_min 0.2174 (0.2179) gate/usage_std 0.1628 (0.1619) teacher/entropy 0.0864 (0.0426) teacher/usage_max 0.9212 (0.9599) teacher/usage_min 0.0012 (0.0062) teacher/usage_std 0.4169 (0.4434) nleep/row_max_mean 1518.3496 (1520.0255) nleep/row_max_std 72.3208 (61.8679) nleep/row_min_mean 1499.1991 (1498.1287) lr 1.8763e-03 eta 0:10:22
epoch [10/50] batch [120/160] time 0.095 (0.095) data 0.000 (0.003) loss 1.3003 (1.2021) teacher_loss 0.5245 (0.4353) loss_zs_kd 0.0151 (0.0150) loss_oracle 0.3562 (0.3708) kd_loss 0.5901 (0.5739) acc 84.3750 (83.4375) gate/entropy 0.9874 (0.9885) gate/usage_max 0.5638 (0.5625) gate/usage_min 0.2172 (0.2178) gate/usage_std 0.1629 (0.1621) teacher/entropy 0.0700 (0.0453) teacher/usage_max 0.9077 (0.9533) teacher/usage_min 0.0011 (0.0058) teacher/usage_std 0.4078 (0.4389) nleep/row_max_mean 1522.5988 (1520.4510) nleep/row_max_std 64.8124 (61.1950) nleep/row_min_mean 1499.6077 (1498.5151) lr 1.8763e-03 eta 0:10:08
epoch [10/50] batch [140/160] time 0.104 (0.095) data 0.000 (0.002) loss 1.2269 (1.1981) teacher_loss 0.4552 (0.4334) loss_zs_kd 0.0254 (0.0163) loss_oracle 0.3865 (0.3687) kd_loss 0.5657 (0.5722) acc 81.2500 (83.5268) gate/entropy 0.9872 (0.9883) gate/usage_max 0.5639 (0.5627) gate/usage_min 0.2172 (0.2178) gate/usage_std 0.1631 (0.1622) teacher/entropy 0.0567 (0.0472) teacher/usage_max 0.9472 (0.9527) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.4346 (0.4385) nleep/row_max_mean 1530.9163 (1520.3290) nleep/row_max_std 29.6494 (61.4173) nleep/row_min_mean 1508.6560 (1498.2459) lr 1.8763e-03 eta 0:10:08
epoch [10/50] batch [160/160] time 0.083 (0.094) data 0.000 (0.002) loss 1.2616 (1.1997) teacher_loss 0.4405 (0.4326) loss_zs_kd 0.0323 (0.0160) loss_oracle 0.4200 (0.3731) kd_loss 0.5949 (0.5726) acc 87.5000 (83.7500) gate/entropy 0.9866 (0.9881) gate/usage_max 0.5646 (0.5629) gate/usage_min 0.2168 (0.2177) gate/usage_std 0.1635 (0.1624) teacher/entropy 0.0475 (0.0491) teacher/usage_max 0.9252 (0.9499) teacher/usage_min 0.0000 (0.0051) teacher/usage_std 0.4197 (0.4366) nleep/row_max_mean 1520.8445 (1520.5701) nleep/row_max_std 42.1793 (61.1529) nleep/row_min_mean 1496.1914 (1498.2947) lr 1.8443e-03 eta 0:10:00
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,844
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 85.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,989
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 89.3%
******* Domain p best val acc:      83.6%, epoch: 10 *******
******* Domain p best val test acc: 88.5%, epoch: 10 *******
******* Domain p best test acc:     89.2%, epoch: 6 *******
epoch [11/50] batch [20/160] time 0.089 (0.109) data 0.000 (0.019) loss 1.2086 (1.2060) teacher_loss 0.4401 (0.4417) loss_zs_kd 0.0074 (0.0183) loss_oracle 0.3723 (0.3869) kd_loss 0.5787 (0.5617) acc 90.6250 (83.2812) gate/entropy 0.9865 (0.9865) gate/usage_max 0.5647 (0.5646) gate/usage_min 0.2168 (0.2168) gate/usage_std 0.1636 (0.1635) teacher/entropy 0.0677 (0.0505) teacher/usage_max 0.9212 (0.9571) teacher/usage_min 0.0304 (0.0020) teacher/usage_std 0.4157 (0.4416) nleep/row_max_mean 1503.8696 (1524.5334) nleep/row_max_std 87.2751 (51.8576) nleep/row_min_mean 1481.0100 (1500.8083) lr 1.8443e-03 eta 0:11:35
epoch [11/50] batch [40/160] time 0.096 (0.100) data 0.000 (0.009) loss 1.1273 (1.2047) teacher_loss 0.3909 (0.4499) loss_zs_kd 0.0225 (0.0176) loss_oracle 0.3319 (0.3695) kd_loss 0.5592 (0.5613) acc 84.3750 (82.0312) gate/entropy 0.9860 (0.9864) gate/usage_max 0.5652 (0.5648) gate/usage_min 0.2166 (0.2168) gate/usage_std 0.1639 (0.1637) teacher/entropy 0.0591 (0.0564) teacher/usage_max 0.9499 (0.9510) teacher/usage_min 0.0121 (0.0024) teacher/usage_std 0.4361 (0.4373) nleep/row_max_mean 1526.8633 (1522.7258) nleep/row_max_std 44.4362 (55.7926) nleep/row_min_mean 1502.7600 (1498.8558) lr 1.8443e-03 eta 0:10:36
epoch [11/50] batch [60/160] time 0.096 (0.098) data 0.000 (0.006) loss 1.2138 (1.1870) teacher_loss 0.4506 (0.4288) loss_zs_kd 0.0280 (0.0180) loss_oracle 0.3831 (0.3658) kd_loss 0.5577 (0.5663) acc 87.5000 (83.3854) gate/entropy 0.9861 (0.9863) gate/usage_max 0.5651 (0.5649) gate/usage_min 0.2166 (0.2167) gate/usage_std 0.1639 (0.1638) teacher/entropy 0.0570 (0.0547) teacher/usage_max 0.9537 (0.9474) teacher/usage_min 0.0001 (0.0020) teacher/usage_std 0.4391 (0.4349) nleep/row_max_mean 1505.7793 (1520.5630) nleep/row_max_std 85.1252 (60.0671) nleep/row_min_mean 1478.8413 (1496.4296) lr 1.8443e-03 eta 0:10:22
epoch [11/50] batch [80/160] time 0.099 (0.097) data 0.000 (0.005) loss 1.2896 (1.2017) teacher_loss 0.5842 (0.4432) loss_zs_kd 0.0140 (0.0179) loss_oracle 0.2965 (0.3621) kd_loss 0.5501 (0.5686) acc 81.2500 (82.7734) gate/entropy 0.9855 (0.9861) gate/usage_max 0.5657 (0.5651) gate/usage_min 0.2163 (0.2166) gate/usage_std 0.1643 (0.1639) teacher/entropy 0.0725 (0.0533) teacher/usage_max 0.9444 (0.9461) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.4327 (0.4341) nleep/row_max_mean 1520.3599 (1519.9083) nleep/row_max_std 71.5751 (60.9414) nleep/row_min_mean 1495.7153 (1495.6691) lr 1.8443e-03 eta 0:10:10
epoch [11/50] batch [100/160] time 0.089 (0.096) data 0.000 (0.004) loss 1.2455 (1.1938) teacher_loss 0.4754 (0.4346) loss_zs_kd 0.0156 (0.0183) loss_oracle 0.3430 (0.3622) kd_loss 0.5907 (0.5689) acc 78.1250 (83.2500) gate/entropy 0.9856 (0.9860) gate/usage_max 0.5656 (0.5652) gate/usage_min 0.2164 (0.2166) gate/usage_std 0.1643 (0.1640) teacher/entropy 0.0123 (0.0509) teacher/usage_max 0.9651 (0.9480) teacher/usage_min 0.0036 (0.0024) teacher/usage_std 0.4469 (0.4354) nleep/row_max_mean 1529.5813 (1519.0710) nleep/row_max_std 25.8344 (61.0565) nleep/row_min_mean 1503.5969 (1494.6210) lr 1.8443e-03 eta 0:10:06
epoch [11/50] batch [120/160] time 0.098 (0.097) data 0.000 (0.003) loss 0.8533 (1.1832) teacher_loss 0.1724 (0.4269) loss_zs_kd 0.0109 (0.0176) loss_oracle 0.2727 (0.3603) kd_loss 0.5391 (0.5673) acc 96.8750 (83.6979) gate/entropy 0.9849 (0.9858) gate/usage_max 0.5663 (0.5654) gate/usage_min 0.2161 (0.2165) gate/usage_std 0.1648 (0.1641) teacher/entropy 0.0435 (0.0501) teacher/usage_max 0.9853 (0.9503) teacher/usage_min 0.0003 (0.0024) teacher/usage_std 0.4610 (0.4369) nleep/row_max_mean 1507.1030 (1518.5856) nleep/row_max_std 74.2143 (62.0385) nleep/row_min_mean 1486.0930 (1494.2323) lr 1.8443e-03 eta 0:10:06
epoch [11/50] batch [140/160] time 0.088 (0.096) data 0.000 (0.003) loss 1.5158 (1.1882) teacher_loss 0.7893 (0.4333) loss_zs_kd 0.0162 (0.0175) loss_oracle 0.3410 (0.3584) kd_loss 0.5479 (0.5669) acc 71.8750 (83.5491) gate/entropy 0.9847 (0.9857) gate/usage_max 0.5666 (0.5655) gate/usage_min 0.2160 (0.2164) gate/usage_std 0.1649 (0.1642) teacher/entropy 0.0289 (0.0468) teacher/usage_max 0.9911 (0.9540) teacher/usage_min 0.0035 (0.0021) teacher/usage_std 0.4651 (0.4395) nleep/row_max_mean 1521.3219 (1518.5638) nleep/row_max_std 43.6448 (61.2567) nleep/row_min_mean 1498.8374 (1494.3158) lr 1.8443e-03 eta 0:10:02
epoch [11/50] batch [160/160] time 0.081 (0.095) data 0.000 (0.003) loss 1.4024 (1.1889) teacher_loss 0.6732 (0.4355) loss_zs_kd 0.0113 (0.0168) loss_oracle 0.3375 (0.3574) kd_loss 0.5549 (0.5663) acc 81.2500 (83.4961) gate/entropy 0.9843 (0.9855) gate/usage_max 0.5670 (0.5657) gate/usage_min 0.2158 (0.2164) gate/usage_std 0.1652 (0.1643) teacher/entropy 0.0197 (0.0440) teacher/usage_max 0.9926 (0.9573) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.4662 (0.4417) nleep/row_max_mean 1512.6433 (1517.8313) nleep/row_max_std 82.4841 (62.0605) nleep/row_min_mean 1490.1521 (1493.7305) lr 1.8090e-03 eta 0:09:53
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,835
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,009
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 89.7%
******* Domain p best val acc:      83.6%, epoch: 10 *******
******* Domain p best val test acc: 88.5%, epoch: 10 *******
******* Domain p best test acc:     89.2%, epoch: 6 *******
epoch [12/50] batch [20/160] time 0.085 (0.114) data 0.000 (0.024) loss 1.1311 (1.1577) teacher_loss 0.4121 (0.4025) loss_zs_kd 0.0178 (0.0141) loss_oracle 0.3132 (0.3642) kd_loss 0.5536 (0.5660) acc 75.0000 (83.1250) gate/entropy 0.9844 (0.9844) gate/usage_max 0.5669 (0.5669) gate/usage_min 0.2158 (0.2158) gate/usage_std 0.1652 (0.1651) teacher/entropy 0.0172 (0.0393) teacher/usage_max 0.9967 (0.9606) teacher/usage_min 0.0001 (0.0045) teacher/usage_std 0.4691 (0.4440) nleep/row_max_mean 1523.2559 (1519.1043) nleep/row_max_std 49.1242 (54.1692) nleep/row_min_mean 1503.7188 (1496.9875) lr 1.8090e-03 eta 0:11:48
epoch [12/50] batch [40/160] time 0.087 (0.100) data 0.000 (0.012) loss 1.0853 (1.1564) teacher_loss 0.3057 (0.4006) loss_zs_kd 0.0230 (0.0135) loss_oracle 0.4078 (0.3707) kd_loss 0.5641 (0.5638) acc 96.8750 (84.2969) gate/entropy 0.9838 (0.9842) gate/usage_max 0.5675 (0.5670) gate/usage_min 0.2156 (0.2158) gate/usage_std 0.1656 (0.1652) teacher/entropy 0.0029 (0.0329) teacher/usage_max 0.9995 (0.9694) teacher/usage_min 0.0000 (0.0040) teacher/usage_std 0.4711 (0.4501) nleep/row_max_mean 1526.9330 (1518.5684) nleep/row_max_std 63.2478 (57.0616) nleep/row_min_mean 1503.4928 (1496.0874) lr 1.8090e-03 eta 0:10:17
epoch [12/50] batch [60/160] time 0.089 (0.096) data 0.001 (0.008) loss 1.3878 (1.1684) teacher_loss 0.6299 (0.4118) loss_zs_kd 0.0254 (0.0136) loss_oracle 0.3326 (0.3710) kd_loss 0.5788 (0.5642) acc 71.8750 (84.0625) gate/entropy 0.9836 (0.9841) gate/usage_max 0.5677 (0.5672) gate/usage_min 0.2155 (0.2157) gate/usage_std 0.1657 (0.1653) teacher/entropy 0.0349 (0.0319) teacher/usage_max 0.9503 (0.9697) teacher/usage_min 0.0022 (0.0044) teacher/usage_std 0.4367 (0.4502) nleep/row_max_mean 1520.0840 (1517.6840) nleep/row_max_std 45.7702 (59.5642) nleep/row_min_mean 1495.6458 (1495.3643) lr 1.8090e-03 eta 0:09:50
epoch [12/50] batch [80/160] time 0.090 (0.096) data 0.000 (0.006) loss 1.0857 (1.1746) teacher_loss 0.3417 (0.4217) loss_zs_kd 0.0128 (0.0141) loss_oracle 0.3384 (0.3664) kd_loss 0.5684 (0.5626) acc 81.2500 (83.3203) gate/entropy 0.9836 (0.9840) gate/usage_max 0.5677 (0.5673) gate/usage_min 0.2155 (0.2157) gate/usage_std 0.1657 (0.1654) teacher/entropy 0.0550 (0.0323) teacher/usage_max 0.9405 (0.9708) teacher/usage_min 0.0255 (0.0044) teacher/usage_std 0.4294 (0.4510) nleep/row_max_mean 1527.3293 (1517.3353) nleep/row_max_std 60.3588 (61.2187) nleep/row_min_mean 1504.8218 (1495.1237) lr 1.8090e-03 eta 0:09:48
epoch [12/50] batch [100/160] time 0.093 (0.095) data 0.000 (0.005) loss 1.1906 (1.1815) teacher_loss 0.4641 (0.4304) loss_zs_kd 0.0079 (0.0137) loss_oracle 0.3443 (0.3677) kd_loss 0.5504 (0.5604) acc 75.0000 (82.9375) gate/entropy 0.9831 (0.9839) gate/usage_max 0.5682 (0.5674) gate/usage_min 0.2153 (0.2156) gate/usage_std 0.1661 (0.1655) teacher/entropy 0.0183 (0.0323) teacher/usage_max 0.9965 (0.9729) teacher/usage_min 0.0013 (0.0042) teacher/usage_std 0.4689 (0.4524) nleep/row_max_mean 1517.5420 (1516.4298) nleep/row_max_std 67.2720 (62.7782) nleep/row_min_mean 1496.0203 (1494.3254) lr 1.8090e-03 eta 0:09:45
epoch [12/50] batch [120/160] time 0.102 (0.095) data 0.000 (0.004) loss 0.9781 (1.1799) teacher_loss 0.2418 (0.4278) loss_zs_kd 0.0142 (0.0132) loss_oracle 0.3752 (0.3706) kd_loss 0.5416 (0.5601) acc 90.6250 (83.1510) gate/entropy 0.9831 (0.9838) gate/usage_max 0.5682 (0.5675) gate/usage_min 0.2153 (0.2156) gate/usage_std 0.1661 (0.1656) teacher/entropy 0.0434 (0.0310) teacher/usage_max 0.9796 (0.9743) teacher/usage_min 0.0010 (0.0040) teacher/usage_std 0.4571 (0.4534) nleep/row_max_mean 1532.2299 (1516.7445) nleep/row_max_std 44.8684 (62.7081) nleep/row_min_mean 1509.6079 (1494.4948) lr 1.8090e-03 eta 0:09:42
epoch [12/50] batch [140/160] time 0.085 (0.095) data 0.000 (0.004) loss 1.5193 (1.1844) teacher_loss 0.7350 (0.4314) loss_zs_kd 0.0133 (0.0131) loss_oracle 0.4327 (0.3718) kd_loss 0.5613 (0.5605) acc 65.6250 (82.9018) gate/entropy 0.9828 (0.9837) gate/usage_max 0.5686 (0.5676) gate/usage_min 0.2152 (0.2155) gate/usage_std 0.1663 (0.1657) teacher/entropy 0.0039 (0.0309) teacher/usage_max 0.9994 (0.9739) teacher/usage_min 0.0003 (0.0041) teacher/usage_std 0.4710 (0.4531) nleep/row_max_mean 1522.4360 (1516.4165) nleep/row_max_std 71.2037 (63.5034) nleep/row_min_mean 1495.2209 (1494.0814) lr 1.8090e-03 eta 0:09:38
epoch [12/50] batch [160/160] time 0.080 (0.094) data 0.000 (0.003) loss 1.1714 (1.1900) teacher_loss 0.4169 (0.4354) loss_zs_kd 0.0208 (0.0131) loss_oracle 0.3853 (0.3754) kd_loss 0.5514 (0.5604) acc 78.1250 (82.8320) gate/entropy 0.9828 (0.9836) gate/usage_max 0.5685 (0.5677) gate/usage_min 0.2152 (0.2155) gate/usage_std 0.1663 (0.1657) teacher/entropy 0.0219 (0.0296) teacher/usage_max 0.9911 (0.9751) teacher/usage_min 0.0006 (0.0039) teacher/usage_std 0.4651 (0.4540) nleep/row_max_mean 1527.1240 (1516.2799) nleep/row_max_std 26.8009 (63.6728) nleep/row_min_mean 1503.3416 (1493.8085) lr 1.7705e-03 eta 0:09:34
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,014
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 89.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.6%, epoch: 10 *******
******* Domain p best val test acc: 88.5%, epoch: 10 *******
******* Domain p best test acc:     89.3%, epoch: 12 *******
epoch [13/50] batch [20/160] time 0.088 (0.120) data 0.000 (0.021) loss 1.1620 (1.1872) teacher_loss 0.3800 (0.4196) loss_zs_kd 0.0113 (0.0124) loss_oracle 0.4536 (0.3993) kd_loss 0.5495 (0.5617) acc 81.2500 (83.4375) gate/entropy 0.9825 (0.9827) gate/usage_max 0.5689 (0.5687) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1666 (0.1664) teacher/entropy 0.0184 (0.0251) teacher/usage_max 0.9960 (0.9769) teacher/usage_min 0.0010 (0.0045) teacher/usage_std 0.4686 (0.4551) nleep/row_max_mean 1516.3303 (1515.8299) nleep/row_max_std 78.3601 (63.1574) nleep/row_min_mean 1490.6001 (1491.4284) lr 1.7705e-03 eta 0:12:09
epoch [13/50] batch [40/160] time 0.109 (0.108) data 0.000 (0.011) loss 1.0287 (1.2084) teacher_loss 0.2471 (0.4429) loss_zs_kd 0.0063 (0.0133) loss_oracle 0.4289 (0.4009) kd_loss 0.5640 (0.5584) acc 90.6250 (82.6562) gate/entropy 0.9826 (0.9826) gate/usage_max 0.5687 (0.5688) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1665 (0.1665) teacher/entropy 0.0004 (0.0245) teacher/usage_max 1.0000 (0.9808) teacher/usage_min 0.0000 (0.0035) teacher/usage_std 0.4714 (0.4579) nleep/row_max_mean 1524.3237 (1518.2667) nleep/row_max_std 46.5924 (60.1565) nleep/row_min_mean 1497.9412 (1493.5608) lr 1.7705e-03 eta 0:10:52
epoch [13/50] batch [60/160] time 0.090 (0.102) data 0.001 (0.007) loss 1.3481 (1.2089) teacher_loss 0.5893 (0.4431) loss_zs_kd 0.0041 (0.0130) loss_oracle 0.4067 (0.4016) kd_loss 0.5533 (0.5584) acc 84.3750 (82.6042) gate/entropy 0.9823 (0.9825) gate/usage_max 0.5690 (0.5688) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1667 (0.1665) teacher/entropy 0.0130 (0.0227) teacher/usage_max 0.9974 (0.9825) teacher/usage_min 0.0012 (0.0033) teacher/usage_std 0.4696 (0.4591) nleep/row_max_mean 1488.6176 (1517.1157) nleep/row_max_std 103.2157 (61.6358) nleep/row_min_mean 1461.7273 (1492.0935) lr 1.7705e-03 eta 0:10:16
epoch [13/50] batch [80/160] time 0.106 (0.101) data 0.000 (0.006) loss 1.2851 (1.1971) teacher_loss 0.4908 (0.4295) loss_zs_kd 0.0064 (0.0124) loss_oracle 0.4566 (0.4046) kd_loss 0.5628 (0.5590) acc 81.2500 (83.3203) gate/entropy 0.9820 (0.9824) gate/usage_max 0.5694 (0.5689) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1669 (0.1666) teacher/entropy 0.0005 (0.0195) teacher/usage_max 0.9999 (0.9851) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.4714 (0.4609) nleep/row_max_mean 1514.7668 (1518.2273) nleep/row_max_std 81.5618 (60.8316) nleep/row_min_mean 1486.2573 (1492.6983) lr 1.7705e-03 eta 0:10:04
epoch [13/50] batch [100/160] time 0.090 (0.100) data 0.000 (0.005) loss 1.1558 (1.2047) teacher_loss 0.3574 (0.4346) loss_zs_kd 0.0112 (0.0130) loss_oracle 0.4433 (0.4082) kd_loss 0.5711 (0.5595) acc 90.6250 (82.7812) gate/entropy 0.9820 (0.9823) gate/usage_max 0.5693 (0.5690) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1669 (0.1666) teacher/entropy 0.0222 (0.0185) teacher/usage_max 0.9690 (0.9854) teacher/usage_min 0.0067 (0.0026) teacher/usage_std 0.4496 (0.4612) nleep/row_max_mean 1526.3831 (1517.7970) nleep/row_max_std 47.1045 (61.7861) nleep/row_min_mean 1497.5630 (1492.0009) lr 1.7705e-03 eta 0:09:58
epoch [13/50] batch [120/160] time 0.190 (0.102) data 0.002 (0.004) loss 1.4727 (1.2080) teacher_loss 0.6881 (0.4366) loss_zs_kd 0.0210 (0.0129) loss_oracle 0.4308 (0.4110) kd_loss 0.5588 (0.5595) acc 75.0000 (82.8125) gate/entropy 0.9817 (0.9822) gate/usage_max 0.5697 (0.5691) gate/usage_min 0.2147 (0.2150) gate/usage_std 0.1671 (0.1667) teacher/entropy 0.0049 (0.0165) teacher/usage_max 0.9991 (0.9874) teacher/usage_min 0.0001 (0.0022) teacher/usage_std 0.4707 (0.4625) nleep/row_max_mean 1503.3890 (1518.0663) nleep/row_max_std 91.2964 (62.3700) nleep/row_min_mean 1476.0123 (1491.8980) lr 1.7705e-03 eta 0:10:07
epoch [13/50] batch [140/160] time 0.098 (0.103) data 0.000 (0.003) loss 1.1585 (1.2144) teacher_loss 0.3841 (0.4423) loss_zs_kd 0.0171 (0.0128) loss_oracle 0.4420 (0.4120) kd_loss 0.5448 (0.5596) acc 87.5000 (82.6562) gate/entropy 0.9817 (0.9822) gate/usage_max 0.5697 (0.5692) gate/usage_min 0.2147 (0.2149) gate/usage_std 0.1671 (0.1668) teacher/entropy 0.0478 (0.0160) teacher/usage_max 0.9692 (0.9875) teacher/usage_min 0.0008 (0.0021) teacher/usage_std 0.4498 (0.4626) nleep/row_max_mean 1495.0804 (1517.8392) nleep/row_max_std 95.3225 (62.3497) nleep/row_min_mean 1469.5144 (1491.4811) lr 1.7705e-03 eta 0:10:09
epoch [13/50] batch [160/160] time 0.087 (0.101) data 0.000 (0.003) loss 1.0674 (1.2089) teacher_loss 0.2800 (0.4370) loss_zs_kd 0.0114 (0.0127) loss_oracle 0.4444 (0.4122) kd_loss 0.5595 (0.5594) acc 93.7500 (83.2422) gate/entropy 0.9816 (0.9821) gate/usage_max 0.5698 (0.5692) gate/usage_min 0.2147 (0.2149) gate/usage_std 0.1672 (0.1668) teacher/entropy 0.0036 (0.0148) teacher/usage_max 0.9994 (0.9889) teacher/usage_min 0.0003 (0.0019) teacher/usage_std 0.4710 (0.4636) nleep/row_max_mean 1517.0054 (1517.6839) nleep/row_max_std 80.8672 (63.2971) nleep/row_min_mean 1490.0176 (1491.0993) lr 1.7290e-03 eta 0:09:56
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,848
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,020
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 90.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.8%, epoch: 13 *******
******* Domain p best val test acc: 89.5%, epoch: 13 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [14/50] batch [20/160] time 0.087 (0.106) data 0.000 (0.014) loss 0.9615 (1.1896) teacher_loss 0.1741 (0.4132) loss_zs_kd 0.0183 (0.0109) loss_oracle 0.4356 (0.4206) kd_loss 0.5604 (0.5606) acc 96.8750 (84.0625) gate/entropy 0.9816 (0.9815) gate/usage_max 0.5697 (0.5699) gate/usage_min 0.2147 (0.2146) gate/usage_std 0.1672 (0.1673) teacher/entropy 0.0026 (0.0077) teacher/usage_max 0.9996 (0.9939) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4711 (0.4671) nleep/row_max_mean 1506.3112 (1515.4884) nleep/row_max_std 71.8670 (69.2180) nleep/row_min_mean 1477.5605 (1487.3410) lr 1.7290e-03 eta 0:10:23
epoch [14/50] batch [40/160] time 0.094 (0.100) data 0.000 (0.007) loss 1.0610 (1.2127) teacher_loss 0.2952 (0.4332) loss_zs_kd 0.0121 (0.0108) loss_oracle 0.4319 (0.4260) kd_loss 0.5437 (0.5611) acc 84.3750 (83.2812) gate/entropy 0.9812 (0.9814) gate/usage_max 0.5701 (0.5700) gate/usage_min 0.2145 (0.2146) gate/usage_std 0.1674 (0.1673) teacher/entropy 0.0293 (0.0073) teacher/usage_max 0.9885 (0.9936) teacher/usage_min 0.0044 (0.0006) teacher/usage_std 0.4633 (0.4669) nleep/row_max_mean 1514.7837 (1517.4612) nleep/row_max_std 76.6961 (64.5415) nleep/row_min_mean 1485.6938 (1488.7396) lr 1.7290e-03 eta 0:09:45
epoch [14/50] batch [60/160] time 0.096 (0.098) data 0.001 (0.005) loss 1.3072 (1.1999) teacher_loss 0.5168 (0.4209) loss_zs_kd 0.0100 (0.0120) loss_oracle 0.4590 (0.4237) kd_loss 0.5559 (0.5612) acc 87.5000 (84.2708) gate/entropy 0.9812 (0.9813) gate/usage_max 0.5702 (0.5700) gate/usage_min 0.2145 (0.2146) gate/usage_std 0.1675 (0.1674) teacher/entropy 0.0073 (0.0083) teacher/usage_max 0.9985 (0.9924) teacher/usage_min 0.0002 (0.0005) teacher/usage_std 0.4704 (0.4660) nleep/row_max_mean 1495.6067 (1519.4480) nleep/row_max_std 84.9621 (62.0802) nleep/row_min_mean 1468.6528 (1490.6142) lr 1.7290e-03 eta 0:09:33
epoch [14/50] batch [80/160] time 0.089 (0.097) data 0.000 (0.004) loss 1.2594 (1.2018) teacher_loss 0.4835 (0.4239) loss_zs_kd 0.0091 (0.0119) loss_oracle 0.4518 (0.4227) kd_loss 0.5455 (0.5606) acc 84.3750 (84.1797) gate/entropy 0.9811 (0.9813) gate/usage_max 0.5703 (0.5701) gate/usage_min 0.2145 (0.2145) gate/usage_std 0.1676 (0.1674) teacher/entropy 0.0218 (0.0082) teacher/usage_max 0.9941 (0.9929) teacher/usage_min 0.0013 (0.0005) teacher/usage_std 0.4673 (0.4664) nleep/row_max_mean 1519.6143 (1519.8313) nleep/row_max_std 60.6887 (63.1623) nleep/row_min_mean 1491.4855 (1490.9317) lr 1.7290e-03 eta 0:09:24
epoch [14/50] batch [100/160] time 0.087 (0.096) data 0.000 (0.003) loss 1.1948 (1.1997) teacher_loss 0.4190 (0.4232) loss_zs_kd 0.0059 (0.0116) loss_oracle 0.4390 (0.4223) kd_loss 0.5533 (0.5595) acc 84.3750 (84.3750) gate/entropy 0.9810 (0.9812) gate/usage_max 0.5704 (0.5702) gate/usage_min 0.2144 (0.2145) gate/usage_std 0.1676 (0.1675) teacher/entropy 0.0243 (0.0087) teacher/usage_max 0.9835 (0.9935) teacher/usage_min 0.0002 (0.0004) teacher/usage_std 0.4598 (0.4668) nleep/row_max_mean 1513.3811 (1519.2022) nleep/row_max_std 76.5202 (63.5960) nleep/row_min_mean 1485.0586 (1490.4009) lr 1.7290e-03 eta 0:09:17
epoch [14/50] batch [120/160] time 0.093 (0.096) data 0.000 (0.003) loss 1.4097 (1.2057) teacher_loss 0.6507 (0.4263) loss_zs_kd 0.0056 (0.0114) loss_oracle 0.3994 (0.4268) kd_loss 0.5565 (0.5603) acc 78.1250 (84.1927) gate/entropy 0.9809 (0.9811) gate/usage_max 0.5705 (0.5702) gate/usage_min 0.2144 (0.2145) gate/usage_std 0.1677 (0.1675) teacher/entropy 0.0055 (0.0084) teacher/usage_max 0.9991 (0.9928) teacher/usage_min 0.0003 (0.0004) teacher/usage_std 0.4708 (0.4664) nleep/row_max_mean 1492.9260 (1518.8100) nleep/row_max_std 95.7251 (63.6194) nleep/row_min_mean 1468.7742 (1489.8725) lr 1.7290e-03 eta 0:09:18
epoch [14/50] batch [140/160] time 0.106 (0.096) data 0.000 (0.002) loss 1.1990 (1.2132) teacher_loss 0.3668 (0.4321) loss_zs_kd 0.0259 (0.0114) loss_oracle 0.5173 (0.4300) kd_loss 0.5606 (0.5604) acc 87.5000 (83.9509) gate/entropy 0.9808 (0.9811) gate/usage_max 0.5706 (0.5703) gate/usage_min 0.2143 (0.2145) gate/usage_std 0.1678 (0.1676) teacher/entropy 0.0005 (0.0080) teacher/usage_max 0.9999 (0.9930) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.4714 (0.4665) nleep/row_max_mean 1523.9502 (1518.5566) nleep/row_max_std 45.4766 (63.4505) nleep/row_min_mean 1492.5699 (1489.5175) lr 1.7290e-03 eta 0:09:16
epoch [14/50] batch [160/160] time 0.073 (0.093) data 0.000 (0.002) loss 1.0127 (1.2208) teacher_loss 0.2174 (0.4378) loss_zs_kd 0.0038 (0.0111) loss_oracle 0.4664 (0.4341) kd_loss 0.5602 (0.5604) acc 96.8750 (83.4961) gate/entropy 0.9805 (0.9810) gate/usage_max 0.5709 (0.5704) gate/usage_min 0.2142 (0.2144) gate/usage_std 0.1680 (0.1676) teacher/entropy 0.0215 (0.0084) teacher/usage_max 0.9783 (0.9925) teacher/usage_min 0.0001 (0.0004) teacher/usage_std 0.4562 (0.4661) nleep/row_max_mean 1517.0912 (1518.9702) nleep/row_max_std 72.3113 (62.1128) nleep/row_min_mean 1487.8013 (1489.8336) lr 1.6845e-03 eta 0:08:57
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,827
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,011
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 89.8%
******* Domain p best val acc:      83.8%, epoch: 13 *******
******* Domain p best val test acc: 89.5%, epoch: 13 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [15/50] batch [20/160] time 0.090 (0.105) data 0.000 (0.016) loss 1.5064 (1.2407) teacher_loss 0.7340 (0.4623) loss_zs_kd 0.0098 (0.0138) loss_oracle 0.4324 (0.4397) kd_loss 0.5513 (0.5517) acc 75.0000 (82.0312) gate/entropy 0.9804 (0.9805) gate/usage_max 0.5709 (0.5708) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1680 (0.1679) teacher/entropy 0.0242 (0.0134) teacher/usage_max 0.9846 (0.9955) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4606 (0.4682) nleep/row_max_mean 1496.1381 (1512.3792) nleep/row_max_std 95.9562 (68.7623) nleep/row_min_mean 1467.7495 (1482.5904) lr 1.6845e-03 eta 0:10:04
epoch [15/50] batch [40/160] time 0.080 (0.107) data 0.000 (0.008) loss 1.3190 (1.2486) teacher_loss 0.4687 (0.4658) loss_zs_kd 0.0260 (0.0131) loss_oracle 0.4526 (0.4416) kd_loss 0.6109 (0.5554) acc 81.2500 (82.4219) gate/entropy 0.9804 (0.9805) gate/usage_max 0.5710 (0.5709) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1681 (0.1680) teacher/entropy 0.0119 (0.0155) teacher/usage_max 0.9362 (0.9893) teacher/usage_min 0.0003 (0.0006) teacher/usage_std 0.4271 (0.4639) nleep/row_max_mean 1517.1843 (1514.9220) nleep/row_max_std 49.0268 (67.2587) nleep/row_min_mean 1489.2231 (1484.9322) lr 1.6845e-03 eta 0:10:12
epoch [15/50] batch [60/160] time 0.097 (0.101) data 0.001 (0.005) loss 0.9906 (1.2301) teacher_loss 0.2166 (0.4482) loss_zs_kd 0.0103 (0.0123) loss_oracle 0.4243 (0.4398) kd_loss 0.5567 (0.5559) acc 93.7500 (83.2812) gate/entropy 0.9804 (0.9804) gate/usage_max 0.5709 (0.5709) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1680 (0.1680) teacher/entropy 0.0044 (0.0156) teacher/usage_max 0.9993 (0.9887) teacher/usage_min 0.0001 (0.0005) teacher/usage_std 0.4709 (0.4635) nleep/row_max_mean 1515.6829 (1515.4634) nleep/row_max_std 62.4428 (67.1941) nleep/row_min_mean 1486.4117 (1485.4254) lr 1.6845e-03 eta 0:09:35
epoch [15/50] batch [80/160] time 0.085 (0.098) data 0.000 (0.004) loss 1.1807 (1.2123) teacher_loss 0.3565 (0.4300) loss_zs_kd 0.0097 (0.0121) loss_oracle 0.4630 (0.4390) kd_loss 0.5878 (0.5568) acc 90.6250 (83.6328) gate/entropy 0.9802 (0.9804) gate/usage_max 0.5712 (0.5710) gate/usage_min 0.2141 (0.2142) gate/usage_std 0.1682 (0.1680) teacher/entropy 0.0033 (0.0160) teacher/usage_max 0.9682 (0.9874) teacher/usage_min 0.0003 (0.0006) teacher/usage_std 0.4491 (0.4626) nleep/row_max_mean 1523.8538 (1515.9107) nleep/row_max_std 46.6525 (65.6833) nleep/row_min_mean 1488.3145 (1485.6871) lr 1.6845e-03 eta 0:09:18
epoch [15/50] batch [100/160] time 0.091 (0.096) data 0.000 (0.003) loss 1.3068 (1.2145) teacher_loss 0.5065 (0.4311) loss_zs_kd 0.0086 (0.0118) loss_oracle 0.4779 (0.4383) kd_loss 0.5570 (0.5584) acc 81.2500 (83.6562) gate/entropy 0.9801 (0.9804) gate/usage_max 0.5713 (0.5710) gate/usage_min 0.2141 (0.2142) gate/usage_std 0.1682 (0.1681) teacher/entropy 0.0035 (0.0156) teacher/usage_max 0.9994 (0.9861) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4710 (0.4617) nleep/row_max_mean 1518.4329 (1516.2533) nleep/row_max_std 62.6464 (65.0639) nleep/row_min_mean 1488.1854 (1485.9365) lr 1.6845e-03 eta 0:09:05
epoch [15/50] batch [120/160] time 0.081 (0.095) data 0.000 (0.003) loss 1.3408 (1.2170) teacher_loss 0.5500 (0.4333) loss_zs_kd 0.0070 (0.0119) loss_oracle 0.4606 (0.4397) kd_loss 0.5570 (0.5579) acc 75.0000 (83.5677) gate/entropy 0.9800 (0.9803) gate/usage_max 0.5714 (0.5711) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1683 (0.1681) teacher/entropy 0.0034 (0.0151) teacher/usage_max 0.9994 (0.9870) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.4710 (0.4623) nleep/row_max_mean 1518.1372 (1516.2633) nleep/row_max_std 69.9613 (64.8158) nleep/row_min_mean 1489.3567 (1485.9131) lr 1.6845e-03 eta 0:08:57
epoch [15/50] batch [140/160] time 0.096 (0.094) data 0.000 (0.002) loss 1.2161 (1.2147) teacher_loss 0.4435 (0.4303) loss_zs_kd 0.0065 (0.0119) loss_oracle 0.4221 (0.4416) kd_loss 0.5584 (0.5577) acc 81.2500 (83.7500) gate/entropy 0.9799 (0.9803) gate/usage_max 0.5715 (0.5711) gate/usage_min 0.2140 (0.2141) gate/usage_std 0.1684 (0.1681) teacher/entropy 0.0013 (0.0154) teacher/usage_max 0.9998 (0.9868) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4713 (0.4622) nleep/row_max_mean 1526.0250 (1516.0624) nleep/row_max_std 62.0661 (65.2848) nleep/row_min_mean 1494.9517 (1485.7598) lr 1.6845e-03 eta 0:08:49
epoch [15/50] batch [160/160] time 0.081 (0.093) data 0.000 (0.002) loss 1.1556 (1.2156) teacher_loss 0.3704 (0.4320) loss_zs_kd 0.0225 (0.0119) loss_oracle 0.4308 (0.4406) kd_loss 0.5585 (0.5574) acc 84.3750 (83.8281) gate/entropy 0.9798 (0.9802) gate/usage_max 0.5716 (0.5712) gate/usage_min 0.2139 (0.2141) gate/usage_std 0.1685 (0.1682) teacher/entropy 0.0009 (0.0155) teacher/usage_max 0.9999 (0.9869) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.4713 (0.4622) nleep/row_max_mean 1520.5979 (1516.4654) nleep/row_max_std 59.0371 (64.6499) nleep/row_min_mean 1490.9097 (1486.2364) lr 1.6374e-03 eta 0:08:41
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,017
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 90.1%
******* Domain p best val acc:      83.8%, epoch: 13 *******
******* Domain p best val test acc: 89.5%, epoch: 13 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [16/50] batch [20/160] time 0.090 (0.101) data 0.000 (0.014) loss 1.1885 (1.2433) teacher_loss 0.3788 (0.4542) loss_zs_kd 0.0094 (0.0118) loss_oracle 0.4415 (0.4502) kd_loss 0.5842 (0.5581) acc 81.2500 (83.7500) gate/entropy 0.9800 (0.9799) gate/usage_max 0.5714 (0.5715) gate/usage_min 0.2140 (0.2139) gate/usage_std 0.1683 (0.1684) teacher/entropy 0.0074 (0.0098) teacher/usage_max 0.9673 (0.9914) teacher/usage_min 0.0013 (0.0017) teacher/usage_std 0.4485 (0.4653) nleep/row_max_mean 1510.1021 (1516.6428) nleep/row_max_std 67.8967 (68.0604) nleep/row_min_mean 1483.5823 (1487.3686) lr 1.6374e-03 eta 0:09:22
epoch [16/50] batch [40/160] time 0.102 (0.096) data 0.000 (0.007) loss 1.0623 (1.2338) teacher_loss 0.2750 (0.4455) loss_zs_kd 0.0101 (0.0113) loss_oracle 0.4287 (0.4480) kd_loss 0.5679 (0.5587) acc 84.3750 (83.8281) gate/entropy 0.9799 (0.9798) gate/usage_max 0.5715 (0.5716) gate/usage_min 0.2140 (0.2139) gate/usage_std 0.1684 (0.1684) teacher/entropy 0.0175 (0.0111) teacher/usage_max 0.9736 (0.9894) teacher/usage_min 0.0004 (0.0010) teacher/usage_std 0.4529 (0.4640) nleep/row_max_mean 1511.1218 (1518.5061) nleep/row_max_std 70.4614 (64.8510) nleep/row_min_mean 1481.9746 (1488.6126) lr 1.6374e-03 eta 0:08:55
epoch [16/50] batch [60/160] time 0.105 (0.096) data 0.001 (0.005) loss 1.3502 (1.2212) teacher_loss 0.5551 (0.4360) loss_zs_kd 0.0096 (0.0111) loss_oracle 0.4677 (0.4466) kd_loss 0.5565 (0.5564) acc 78.1250 (83.8021) gate/entropy 0.9796 (0.9798) gate/usage_max 0.5718 (0.5716) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1686 (0.1685) teacher/entropy 0.0030 (0.0119) teacher/usage_max 0.9995 (0.9909) teacher/usage_min 0.0002 (0.0008) teacher/usage_std 0.4711 (0.4650) nleep/row_max_mean 1529.9653 (1518.3920) nleep/row_max_std 48.4116 (63.6497) nleep/row_min_mean 1498.4668 (1488.4138) lr 1.6374e-03 eta 0:08:51
epoch [16/50] batch [80/160] time 0.099 (0.095) data 0.000 (0.004) loss 1.1107 (1.2109) teacher_loss 0.3278 (0.4292) loss_zs_kd 0.0167 (0.0115) loss_oracle 0.4351 (0.4412) kd_loss 0.5571 (0.5554) acc 87.5000 (84.2578) gate/entropy 0.9797 (0.9798) gate/usage_max 0.5718 (0.5716) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1686 (0.1685) teacher/entropy 0.0023 (0.0118) teacher/usage_max 0.9996 (0.9920) teacher/usage_min 0.0001 (0.0008) teacher/usage_std 0.4712 (0.4657) nleep/row_max_mean 1520.1506 (1517.7599) nleep/row_max_std 62.7657 (63.6430) nleep/row_min_mean 1490.5781 (1487.8101) lr 1.6374e-03 eta 0:08:46
epoch [16/50] batch [100/160] time 0.087 (0.095) data 0.000 (0.003) loss 1.1850 (1.2017) teacher_loss 0.3842 (0.4217) loss_zs_kd 0.0084 (0.0115) loss_oracle 0.4848 (0.4383) kd_loss 0.5541 (0.5551) acc 84.3750 (84.5625) gate/entropy 0.9796 (0.9798) gate/usage_max 0.5718 (0.5717) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1686 (0.1685) teacher/entropy 0.0058 (0.0120) teacher/usage_max 0.9991 (0.9919) teacher/usage_min 0.0002 (0.0008) teacher/usage_std 0.4707 (0.4657) nleep/row_max_mean 1514.8425 (1517.3792) nleep/row_max_std 72.3059 (64.0306) nleep/row_min_mean 1488.2484 (1487.5715) lr 1.6374e-03 eta 0:08:43
epoch [16/50] batch [120/160] time 0.093 (0.095) data 0.000 (0.003) loss 1.3491 (1.2048) teacher_loss 0.5620 (0.4254) loss_zs_kd 0.0089 (0.0115) loss_oracle 0.4528 (0.4381) kd_loss 0.5563 (0.5547) acc 78.1250 (84.5052) gate/entropy 0.9795 (0.9797) gate/usage_max 0.5719 (0.5717) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1687 (0.1685) teacher/entropy 0.0030 (0.0122) teacher/usage_max 0.9995 (0.9921) teacher/usage_min 0.0002 (0.0008) teacher/usage_std 0.4711 (0.4659) nleep/row_max_mean 1514.9875 (1517.4767) nleep/row_max_std 71.7429 (63.7951) nleep/row_min_mean 1485.3888 (1487.7938) lr 1.6374e-03 eta 0:08:39
epoch [16/50] batch [140/160] time 0.100 (0.095) data 0.000 (0.002) loss 1.1585 (1.2013) teacher_loss 0.3702 (0.4227) loss_zs_kd 0.0092 (0.0113) loss_oracle 0.5001 (0.4379) kd_loss 0.5337 (0.5539) acc 93.7500 (84.6205) gate/entropy 0.9794 (0.9797) gate/usage_max 0.5720 (0.5717) gate/usage_min 0.2138 (0.2139) gate/usage_std 0.1687 (0.1686) teacher/entropy 0.0450 (0.0138) teacher/usage_max 0.9796 (0.9912) teacher/usage_min 0.0012 (0.0009) teacher/usage_std 0.4571 (0.4652) nleep/row_max_mean 1508.0137 (1517.1249) nleep/row_max_std 75.7739 (64.0000) nleep/row_min_mean 1478.6188 (1487.5760) lr 1.6374e-03 eta 0:08:39
epoch [16/50] batch [160/160] time 0.093 (0.095) data 0.000 (0.002) loss 1.3634 (1.2090) teacher_loss 0.6223 (0.4299) loss_zs_kd 0.0164 (0.0113) loss_oracle 0.3726 (0.4394) kd_loss 0.5465 (0.5537) acc 81.2500 (84.2969) gate/entropy 0.9794 (0.9797) gate/usage_max 0.5720 (0.5717) gate/usage_min 0.2137 (0.2139) gate/usage_std 0.1688 (0.1686) teacher/entropy 0.0214 (0.0141) teacher/usage_max 0.9906 (0.9912) teacher/usage_min 0.0001 (0.0010) teacher/usage_std 0.4647 (0.4652) nleep/row_max_mean 1505.5168 (1517.0756) nleep/row_max_std 78.9687 (63.8167) nleep/row_min_mean 1478.5652 (1487.6841) lr 1.5878e-03 eta 0:08:35
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,850
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 85.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,013
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 89.9%
******* Domain p best val acc:      83.9%, epoch: 16 *******
******* Domain p best val test acc: 89.2%, epoch: 16 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [17/50] batch [20/160] time 0.088 (0.116) data 0.000 (0.016) loss 1.3752 (1.1400) teacher_loss 0.5967 (0.3665) loss_zs_kd 0.0139 (0.0095) loss_oracle 0.4349 (0.4325) kd_loss 0.5541 (0.5526) acc 81.2500 (86.5625) gate/entropy 0.9793 (0.9794) gate/usage_max 0.5721 (0.5720) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1688 (0.1688) teacher/entropy 0.0053 (0.0199) teacher/usage_max 0.9991 (0.9858) teacher/usage_min 0.0002 (0.0010) teacher/usage_std 0.4708 (0.4615) nleep/row_max_mean 1515.5781 (1512.7750) nleep/row_max_std 77.8993 (72.2595) nleep/row_min_mean 1486.9092 (1485.0153) lr 1.5878e-03 eta 0:10:27
epoch [17/50] batch [40/160] time 0.094 (0.106) data 0.000 (0.008) loss 1.1727 (1.1880) teacher_loss 0.3660 (0.4082) loss_zs_kd 0.0040 (0.0109) loss_oracle 0.5044 (0.4440) kd_loss 0.5525 (0.5524) acc 75.0000 (83.9062) gate/entropy 0.9794 (0.9794) gate/usage_max 0.5720 (0.5721) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1688 (0.1688) teacher/entropy 0.0074 (0.0197) teacher/usage_max 0.9987 (0.9862) teacher/usage_min 0.0007 (0.0015) teacher/usage_std 0.4705 (0.4617) nleep/row_max_mean 1512.1228 (1514.7730) nleep/row_max_std 72.3029 (69.0878) nleep/row_min_mean 1484.6982 (1486.9299) lr 1.5878e-03 eta 0:09:31
epoch [17/50] batch [60/160] time 0.101 (0.102) data 0.001 (0.005) loss 1.3353 (1.2052) teacher_loss 0.5207 (0.4210) loss_zs_kd 0.0096 (0.0120) loss_oracle 0.4622 (0.4516) kd_loss 0.5786 (0.5524) acc 81.2500 (83.8021) gate/entropy 0.9793 (0.9793) gate/usage_max 0.5721 (0.5721) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1688 (0.1688) teacher/entropy 0.0122 (0.0211) teacher/usage_max 0.9671 (0.9848) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.4484 (0.4607) nleep/row_max_mean 1514.8143 (1516.8100) nleep/row_max_std 59.0569 (65.6902) nleep/row_min_mean 1484.5681 (1488.9917) lr 1.5878e-03 eta 0:09:07
epoch [17/50] batch [80/160] time 0.089 (0.100) data 0.000 (0.004) loss 1.3439 (1.2107) teacher_loss 0.5486 (0.4257) loss_zs_kd 0.0072 (0.0116) loss_oracle 0.4112 (0.4538) kd_loss 0.5861 (0.5523) acc 84.3750 (83.6328) gate/entropy 0.9792 (0.9793) gate/usage_max 0.5722 (0.5721) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1689 (0.1688) teacher/entropy 0.0030 (0.0206) teacher/usage_max 0.9686 (0.9852) teacher/usage_min 0.0002 (0.0016) teacher/usage_std 0.4494 (0.4610) nleep/row_max_mean 1517.6362 (1517.4095) nleep/row_max_std 59.7148 (64.8905) nleep/row_min_mean 1488.2859 (1489.4722) lr 1.5878e-03 eta 0:08:55
epoch [17/50] batch [100/160] time 0.092 (0.099) data 0.000 (0.003) loss 1.0378 (1.2011) teacher_loss 0.2457 (0.4150) loss_zs_kd 0.0067 (0.0113) loss_oracle 0.4908 (0.4567) kd_loss 0.5434 (0.5521) acc 90.6250 (84.0000) gate/entropy 0.9793 (0.9793) gate/usage_max 0.5722 (0.5721) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1689 (0.1689) teacher/entropy 0.0206 (0.0206) teacher/usage_max 0.9943 (0.9855) teacher/usage_min 0.0018 (0.0016) teacher/usage_std 0.4674 (0.4612) nleep/row_max_mean 1506.0583 (1516.5576) nleep/row_max_std 79.7654 (66.1386) nleep/row_min_mean 1480.3333 (1488.7943) lr 1.5878e-03 eta 0:08:47
epoch [17/50] batch [120/160] time 0.099 (0.098) data 0.000 (0.003) loss 1.1668 (1.2070) teacher_loss 0.3678 (0.4191) loss_zs_kd 0.0150 (0.0111) loss_oracle 0.4912 (0.4585) kd_loss 0.5459 (0.5531) acc 87.5000 (84.0625) gate/entropy 0.9792 (0.9792) gate/usage_max 0.5722 (0.5722) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1689 (0.1689) teacher/entropy 0.0163 (0.0203) teacher/usage_max 0.9959 (0.9847) teacher/usage_min 0.0012 (0.0019) teacher/usage_std 0.4685 (0.4606) nleep/row_max_mean 1506.2405 (1517.5782) nleep/row_max_std 78.8913 (64.2452) nleep/row_min_mean 1480.9226 (1489.9031) lr 1.5878e-03 eta 0:08:42
epoch [17/50] batch [140/160] time 0.099 (0.098) data 0.000 (0.002) loss 1.0564 (1.2061) teacher_loss 0.2852 (0.4194) loss_zs_kd 0.0123 (0.0114) loss_oracle 0.4487 (0.4559) kd_loss 0.5407 (0.5530) acc 90.6250 (83.8616) gate/entropy 0.9791 (0.9792) gate/usage_max 0.5724 (0.5722) gate/usage_min 0.2136 (0.2137) gate/usage_std 0.1690 (0.1689) teacher/entropy 0.0223 (0.0213) teacher/usage_max 0.9949 (0.9837) teacher/usage_min 0.0022 (0.0018) teacher/usage_std 0.4678 (0.4600) nleep/row_max_mean 1509.6475 (1517.6327) nleep/row_max_std 88.7019 (63.7779) nleep/row_min_mean 1482.4722 (1490.0509) lr 1.5878e-03 eta 0:08:38
epoch [17/50] batch [160/160] time 0.086 (0.096) data 0.000 (0.002) loss 1.2353 (1.2085) teacher_loss 0.4910 (0.4218) loss_zs_kd 0.0097 (0.0115) loss_oracle 0.4073 (0.4558) kd_loss 0.5358 (0.5531) acc 75.0000 (83.6133) gate/entropy 0.9790 (0.9792) gate/usage_max 0.5724 (0.5722) gate/usage_min 0.2136 (0.2136) gate/usage_std 0.1690 (0.1689) teacher/entropy 0.0310 (0.0218) teacher/usage_max 0.9910 (0.9831) teacher/usage_min 0.0001 (0.0018) teacher/usage_std 0.4651 (0.4596) nleep/row_max_mean 1510.0240 (1518.4899) nleep/row_max_std 70.5416 (61.7576) nleep/row_min_mean 1484.1222 (1490.9861) lr 1.5358e-03 eta 0:08:28
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,836
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,008
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 89.7%
******* Domain p best val acc:      83.9%, epoch: 16 *******
******* Domain p best val test acc: 89.2%, epoch: 16 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [18/50] batch [20/160] time 0.103 (0.114) data 0.000 (0.018) loss 1.2236 (1.1927) teacher_loss 0.4224 (0.4088) loss_zs_kd 0.0133 (0.0106) loss_oracle 0.4571 (0.4380) kd_loss 0.5660 (0.5596) acc 84.3750 (85.7812) gate/entropy 0.9790 (0.9790) gate/usage_max 0.5725 (0.5724) gate/usage_min 0.2135 (0.2136) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0470 (0.0316) teacher/usage_max 0.9440 (0.9662) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.4324 (0.4477) nleep/row_max_mean 1527.2822 (1514.0974) nleep/row_max_std 34.1374 (69.0475) nleep/row_min_mean 1499.3035 (1487.5950) lr 1.5358e-03 eta 0:10:01
epoch [18/50] batch [40/160] time 0.093 (0.105) data 0.000 (0.009) loss 1.3584 (1.2172) teacher_loss 0.5949 (0.4331) loss_zs_kd 0.0042 (0.0112) loss_oracle 0.3979 (0.4437) kd_loss 0.5625 (0.5566) acc 81.2500 (84.7656) gate/entropy 0.9789 (0.9790) gate/usage_max 0.5725 (0.5725) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1691 (0.1691) teacher/entropy 0.0213 (0.0248) teacher/usage_max 0.9736 (0.9760) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.4529 (0.4546) nleep/row_max_mean 1508.1577 (1516.9678) nleep/row_max_std 90.3782 (64.8980) nleep/row_min_mean 1484.2039 (1490.0219) lr 1.5358e-03 eta 0:09:08
epoch [18/50] batch [60/160] time 0.094 (0.102) data 0.001 (0.006) loss 1.1889 (1.2210) teacher_loss 0.3187 (0.4334) loss_zs_kd 0.0058 (0.0116) loss_oracle 0.5499 (0.4521) kd_loss 0.5923 (0.5558) acc 90.6250 (84.8958) gate/entropy 0.9789 (0.9789) gate/usage_max 0.5726 (0.5725) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0423 (0.0253) teacher/usage_max 0.9220 (0.9763) teacher/usage_min 0.0001 (0.0017) teacher/usage_std 0.4175 (0.4548) nleep/row_max_mean 1541.7565 (1519.5933) nleep/row_max_std 32.3370 (61.1900) nleep/row_min_mean 1511.8730 (1492.2782) lr 1.5358e-03 eta 0:08:49
epoch [18/50] batch [80/160] time 0.081 (0.105) data 0.000 (0.005) loss 1.1716 (1.2130) teacher_loss 0.3599 (0.4247) loss_zs_kd 0.0169 (0.0114) loss_oracle 0.5162 (0.4559) kd_loss 0.5452 (0.5546) acc 87.5000 (84.6875) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5726 (0.5725) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0163 (0.0256) teacher/usage_max 0.9960 (0.9772) teacher/usage_min 0.0005 (0.0016) teacher/usage_std 0.4686 (0.4554) nleep/row_max_mean 1510.2109 (1519.5539) nleep/row_max_std 86.6722 (61.7679) nleep/row_min_mean 1484.2732 (1492.2665) lr 1.5358e-03 eta 0:09:06
epoch [18/50] batch [100/160] time 0.096 (0.103) data 0.000 (0.004) loss 1.1407 (1.2051) teacher_loss 0.3503 (0.4172) loss_zs_kd 0.0057 (0.0111) loss_oracle 0.4093 (0.4547) kd_loss 0.5829 (0.5551) acc 84.3750 (84.5000) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5727 (0.5725) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1692 (0.1691) teacher/entropy 0.0064 (0.0259) teacher/usage_max 0.9676 (0.9763) teacher/usage_min 0.0002 (0.0015) teacher/usage_std 0.4487 (0.4548) nleep/row_max_mean 1522.6344 (1520.4610) nleep/row_max_std 55.7900 (60.8480) nleep/row_min_mean 1492.6028 (1492.9969) lr 1.5358e-03 eta 0:08:52
epoch [18/50] batch [120/160] time 0.095 (0.101) data 0.000 (0.003) loss 1.2709 (1.2097) teacher_loss 0.4766 (0.4224) loss_zs_kd 0.0058 (0.0111) loss_oracle 0.4710 (0.4548) kd_loss 0.5560 (0.5544) acc 87.5000 (84.4010) gate/entropy 0.9788 (0.9789) gate/usage_max 0.5726 (0.5726) gate/usage_min 0.2135 (0.2135) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0381 (0.0264) teacher/usage_max 0.9630 (0.9765) teacher/usage_min 0.0031 (0.0014) teacher/usage_std 0.4454 (0.4549) nleep/row_max_mean 1495.4225 (1520.1144) nleep/row_max_std 88.1698 (61.1617) nleep/row_min_mean 1470.5454 (1492.6292) lr 1.5358e-03 eta 0:08:41
epoch [18/50] batch [140/160] time 0.092 (0.100) data 0.000 (0.003) loss 1.3312 (1.2120) teacher_loss 0.5276 (0.4219) loss_zs_kd 0.0067 (0.0112) loss_oracle 0.4466 (0.4591) kd_loss 0.5769 (0.5549) acc 75.0000 (84.3973) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5728 (0.5726) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1693 (0.1692) teacher/entropy 0.0152 (0.0267) teacher/usage_max 0.9647 (0.9757) teacher/usage_min 0.0001 (0.0016) teacher/usage_std 0.4467 (0.4544) nleep/row_max_mean 1503.5325 (1520.0966) nleep/row_max_std 101.1731 (60.8621) nleep/row_min_mean 1476.9207 (1492.6637) lr 1.5358e-03 eta 0:08:33
epoch [18/50] batch [160/160] time 0.082 (0.099) data 0.000 (0.002) loss 1.1180 (1.2113) teacher_loss 0.3599 (0.4195) loss_zs_kd 0.0078 (0.0116) loss_oracle 0.4385 (0.4627) kd_loss 0.5349 (0.5547) acc 87.5000 (84.3750) gate/entropy 0.9787 (0.9788) gate/usage_max 0.5727 (0.5726) gate/usage_min 0.2134 (0.2135) gate/usage_std 0.1692 (0.1692) teacher/entropy 0.0341 (0.0274) teacher/usage_max 0.9882 (0.9751) teacher/usage_min 0.0002 (0.0017) teacher/usage_std 0.4631 (0.4540) nleep/row_max_mean 1525.2015 (1519.8030) nleep/row_max_std 45.6582 (60.9966) nleep/row_min_mean 1499.8723 (1492.3522) lr 1.4818e-03 eta 0:08:24
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,852
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,011
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 89.9%
******* Domain p best val acc:      84.0%, epoch: 18 *******
******* Domain p best val test acc: 89.2%, epoch: 18 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [19/50] batch [20/160] time 0.087 (0.109) data 0.000 (0.017) loss 1.5093 (1.2590) teacher_loss 0.7375 (0.4554) loss_zs_kd 0.0042 (0.0111) loss_oracle 0.4571 (0.4905) kd_loss 0.5412 (0.5528) acc 68.7500 (81.2500) gate/entropy 0.9787 (0.9787) gate/usage_max 0.5728 (0.5727) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1693 (0.1693) teacher/entropy 0.0279 (0.0247) teacher/usage_max 0.9880 (0.9795) teacher/usage_min 0.0001 (0.0019) teacher/usage_std 0.4630 (0.4570) nleep/row_max_mean 1527.3916 (1519.2443) nleep/row_max_std 62.1214 (58.8003) nleep/row_min_mean 1501.8494 (1491.9537) lr 1.4818e-03 eta 0:09:18
epoch [19/50] batch [40/160] time 0.098 (0.101) data 0.000 (0.009) loss 1.0713 (1.2569) teacher_loss 0.2787 (0.4561) loss_zs_kd 0.0055 (0.0117) loss_oracle 0.5085 (0.4867) kd_loss 0.5356 (0.5515) acc 90.6250 (82.5781) gate/entropy 0.9786 (0.9787) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1694 (0.1693) teacher/entropy 0.0326 (0.0214) teacher/usage_max 0.9888 (0.9842) teacher/usage_min 0.0016 (0.0016) teacher/usage_std 0.4635 (0.4603) nleep/row_max_mean 1519.5203 (1518.6099) nleep/row_max_std 70.0707 (62.4197) nleep/row_min_mean 1493.9788 (1491.4300) lr 1.4818e-03 eta 0:08:32
epoch [19/50] batch [60/160] time 0.086 (0.099) data 0.001 (0.006) loss 1.0201 (1.2462) teacher_loss 0.2216 (0.4432) loss_zs_kd 0.0112 (0.0114) loss_oracle 0.4461 (0.4885) kd_loss 0.5698 (0.5531) acc 100.0000 (83.0208) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1694 (0.1693) teacher/entropy 0.0150 (0.0215) teacher/usage_max 0.9720 (0.9824) teacher/usage_min 0.0005 (0.0016) teacher/usage_std 0.4517 (0.4591) nleep/row_max_mean 1529.5233 (1517.7618) nleep/row_max_std 44.8204 (62.1563) nleep/row_min_mean 1502.0122 (1490.7176) lr 1.4818e-03 eta 0:08:23
epoch [19/50] batch [80/160] time 0.098 (0.098) data 0.000 (0.004) loss 1.2633 (1.2426) teacher_loss 0.4627 (0.4427) loss_zs_kd 0.0118 (0.0114) loss_oracle 0.4695 (0.4805) kd_loss 0.5600 (0.5539) acc 75.0000 (83.0859) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1694 (0.1693) teacher/entropy 0.0315 (0.0226) teacher/usage_max 0.9650 (0.9804) teacher/usage_min 0.0083 (0.0017) teacher/usage_std 0.4467 (0.4577) nleep/row_max_mean 1537.4829 (1518.0968) nleep/row_max_std 24.2933 (61.4899) nleep/row_min_mean 1508.3638 (1490.8543) lr 1.4818e-03 eta 0:08:11
epoch [19/50] batch [100/160] time 0.101 (0.097) data 0.000 (0.004) loss 1.1519 (1.2412) teacher_loss 0.3991 (0.4466) loss_zs_kd 0.0102 (0.0117) loss_oracle 0.4374 (0.4725) kd_loss 0.5290 (0.5525) acc 87.5000 (83.3750) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0565 (0.0224) teacher/usage_max 0.9711 (0.9820) teacher/usage_min 0.0035 (0.0016) teacher/usage_std 0.4511 (0.4588) nleep/row_max_mean 1526.9834 (1517.8303) nleep/row_max_std 24.7983 (61.2556) nleep/row_min_mean 1501.4207 (1490.6932) lr 1.4818e-03 eta 0:08:08
epoch [19/50] batch [120/160] time 0.101 (0.097) data 0.000 (0.003) loss 1.1332 (1.2407) teacher_loss 0.3752 (0.4489) loss_zs_kd 0.0081 (0.0116) loss_oracle 0.4362 (0.4682) kd_loss 0.5358 (0.5518) acc 84.3750 (83.4115) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5728) gate/usage_min 0.2134 (0.2134) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0280 (0.0229) teacher/usage_max 0.9932 (0.9822) teacher/usage_min 0.0032 (0.0017) teacher/usage_std 0.4666 (0.4589) nleep/row_max_mean 1519.2196 (1516.6021) nleep/row_max_std 55.2932 (63.2448) nleep/row_min_mean 1493.9360 (1489.7012) lr 1.4818e-03 eta 0:08:06
epoch [19/50] batch [140/160] time 0.090 (0.097) data 0.000 (0.003) loss 1.1230 (1.2348) teacher_loss 0.3007 (0.4423) loss_zs_kd 0.0092 (0.0114) loss_oracle 0.4825 (0.4691) kd_loss 0.5765 (0.5521) acc 84.3750 (83.5268) gate/entropy 0.9785 (0.9786) gate/usage_max 0.5729 (0.5729) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1694 (0.1694) teacher/entropy 0.0094 (0.0226) teacher/usage_max 0.9708 (0.9821) teacher/usage_min 0.0001 (0.0017) teacher/usage_std 0.4509 (0.4588) nleep/row_max_mean 1527.9744 (1516.9013) nleep/row_max_std 47.5823 (62.6251) nleep/row_min_mean 1501.0090 (1489.9812) lr 1.4818e-03 eta 0:08:02
epoch [19/50] batch [160/160] time 0.083 (0.095) data 0.000 (0.002) loss 1.0248 (1.2264) teacher_loss 0.2444 (0.4342) loss_zs_kd 0.0075 (0.0113) loss_oracle 0.4632 (0.4689) kd_loss 0.5450 (0.5521) acc 93.7500 (83.9844) gate/entropy 0.9784 (0.9785) gate/usage_max 0.5730 (0.5729) gate/usage_min 0.2133 (0.2134) gate/usage_std 0.1695 (0.1694) teacher/entropy 0.0440 (0.0235) teacher/usage_max 0.9675 (0.9812) teacher/usage_min 0.0000 (0.0018) teacher/usage_std 0.4486 (0.4582) nleep/row_max_mean 1526.8716 (1516.5021) nleep/row_max_std 42.8496 (62.7975) nleep/row_min_mean 1501.6963 (1489.6117) lr 1.4258e-03 eta 0:07:50
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,849
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,994
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 89.4%
******* Domain p best val acc:      84.0%, epoch: 18 *******
******* Domain p best val test acc: 89.2%, epoch: 18 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [20/50] batch [20/160] time 0.074 (0.099) data 0.000 (0.016) loss 1.2844 (1.2017) teacher_loss 0.4609 (0.4063) loss_zs_kd 0.0104 (0.0118) loss_oracle 0.4489 (0.4662) kd_loss 0.5939 (0.5564) acc 84.3750 (84.6875) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5730) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0205 (0.0237) teacher/usage_max 0.9416 (0.9764) teacher/usage_min 0.0004 (0.0037) teacher/usage_std 0.4307 (0.4548) nleep/row_max_mean 1516.1766 (1519.9676) nleep/row_max_std 72.8215 (58.2098) nleep/row_min_mean 1492.1077 (1493.5993) lr 1.4258e-03 eta 0:08:07
epoch [20/50] batch [40/160] time 0.091 (0.093) data 0.000 (0.008) loss 1.4883 (1.2056) teacher_loss 0.7351 (0.4164) loss_zs_kd 0.0088 (0.0125) loss_oracle 0.4253 (0.4634) kd_loss 0.5361 (0.5513) acc 84.3750 (84.9219) gate/entropy 0.9784 (0.9784) gate/usage_max 0.5730 (0.5731) gate/usage_min 0.2133 (0.2133) gate/usage_std 0.1695 (0.1695) teacher/entropy 0.0269 (0.0216) teacher/usage_max 0.9938 (0.9837) teacher/usage_min 0.0012 (0.0022) teacher/usage_std 0.4670 (0.4600) nleep/row_max_mean 1492.6853 (1518.8639) nleep/row_max_std 92.1431 (59.1933) nleep/row_min_mean 1467.8832 (1492.4631) lr 1.4258e-03 eta 0:07:37
epoch [20/50] batch [60/160] time 0.085 (0.089) data 0.001 (0.006) loss 1.1218 (1.2069) teacher_loss 0.3096 (0.4182) loss_zs_kd 0.0195 (0.0129) loss_oracle 0.5119 (0.4617) kd_loss 0.5465 (0.5513) acc 81.2500 (84.7396) gate/entropy 0.9783 (0.9784) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2132 (0.2133) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0225 (0.0239) teacher/usage_max 0.9874 (0.9812) teacher/usage_min 0.0002 (0.0024) teacher/usage_std 0.4625 (0.4582) nleep/row_max_mean 1523.2877 (1517.6507) nleep/row_max_std 45.7705 (60.1568) nleep/row_min_mean 1496.3923 (1491.4242) lr 1.4258e-03 eta 0:07:17
epoch [20/50] batch [80/160] time 0.081 (0.087) data 0.000 (0.004) loss 1.2911 (1.2171) teacher_loss 0.5141 (0.4297) loss_zs_kd 0.0096 (0.0129) loss_oracle 0.4483 (0.4582) kd_loss 0.5481 (0.5518) acc 78.1250 (83.6328) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2132 (0.2133) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0106 (0.0248) teacher/usage_max 0.9977 (0.9798) teacher/usage_min 0.0004 (0.0032) teacher/usage_std 0.4698 (0.4572) nleep/row_max_mean 1511.3088 (1515.6417) nleep/row_max_std 74.3438 (62.5673) nleep/row_min_mean 1484.9812 (1489.6838) lr 1.4258e-03 eta 0:07:05
epoch [20/50] batch [100/160] time 0.095 (0.087) data 0.000 (0.003) loss 1.0262 (1.2135) teacher_loss 0.2407 (0.4280) loss_zs_kd 0.0059 (0.0123) loss_oracle 0.4708 (0.4568) kd_loss 0.5472 (0.5510) acc 90.6250 (83.6562) gate/entropy 0.9783 (0.9783) gate/usage_max 0.5731 (0.5731) gate/usage_min 0.2132 (0.2133) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0506 (0.0244) teacher/usage_max 0.9583 (0.9811) teacher/usage_min 0.0006 (0.0031) teacher/usage_std 0.4423 (0.4581) nleep/row_max_mean 1524.6116 (1516.2889) nleep/row_max_std 41.0331 (62.3094) nleep/row_min_mean 1500.1415 (1490.2870) lr 1.4258e-03 eta 0:07:04
epoch [20/50] batch [120/160] time 0.095 (0.088) data 0.000 (0.003) loss 1.1716 (1.2116) teacher_loss 0.3732 (0.4260) loss_zs_kd 0.0091 (0.0118) loss_oracle 0.5344 (0.4587) kd_loss 0.5266 (0.5503) acc 93.7500 (83.7500) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2132 (0.2133) gate/usage_std 0.1696 (0.1695) teacher/entropy 0.0488 (0.0237) teacher/usage_max 0.9809 (0.9825) teacher/usage_min 0.0043 (0.0031) teacher/usage_std 0.4579 (0.4591) nleep/row_max_mean 1492.4580 (1516.5302) nleep/row_max_std 93.6024 (61.9988) nleep/row_min_mean 1464.4384 (1490.4400) lr 1.4258e-03 eta 0:07:06
epoch [20/50] batch [140/160] time 0.089 (0.089) data 0.000 (0.003) loss 1.0049 (1.2054) teacher_loss 0.2380 (0.4206) loss_zs_kd 0.0042 (0.0115) loss_oracle 0.4393 (0.4587) kd_loss 0.5452 (0.5497) acc 87.5000 (83.8839) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2132 (0.2133) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0231 (0.0238) teacher/usage_max 0.9881 (0.9829) teacher/usage_min 0.0002 (0.0031) teacher/usage_std 0.4630 (0.4594) nleep/row_max_mean 1499.4998 (1516.5458) nleep/row_max_std 91.8030 (62.1139) nleep/row_min_mean 1471.0618 (1490.4737) lr 1.4258e-03 eta 0:07:09
epoch [20/50] batch [160/160] time 0.080 (0.089) data 0.000 (0.002) loss 1.0893 (1.2048) teacher_loss 0.3338 (0.4202) loss_zs_kd 0.0068 (0.0115) loss_oracle 0.4134 (0.4580) kd_loss 0.5454 (0.5499) acc 84.3750 (83.8867) gate/entropy 0.9782 (0.9783) gate/usage_max 0.5732 (0.5731) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1696 (0.1696) teacher/entropy 0.0162 (0.0239) teacher/usage_max 0.9948 (0.9827) teacher/usage_min 0.0001 (0.0033) teacher/usage_std 0.4677 (0.4592) nleep/row_max_mean 1520.9360 (1516.8019) nleep/row_max_std 48.4838 (61.7385) nleep/row_min_mean 1494.8403 (1490.6648) lr 1.3681e-03 eta 0:07:05
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,010
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 89.9%
******* Domain p best val acc:      84.0%, epoch: 18 *******
******* Domain p best val test acc: 89.2%, epoch: 18 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [21/50] batch [20/160] time 0.094 (0.114) data 0.000 (0.018) loss 1.1485 (1.1653) teacher_loss 0.3721 (0.3833) loss_zs_kd 0.0099 (0.0102) loss_oracle 0.4643 (0.4564) kd_loss 0.5393 (0.5487) acc 84.3750 (84.3750) gate/entropy 0.9781 (0.9782) gate/usage_max 0.5733 (0.5733) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0258 (0.0236) teacher/usage_max 0.9912 (0.9840) teacher/usage_min 0.0040 (0.0031) teacher/usage_std 0.4652 (0.4601) nleep/row_max_mean 1529.6519 (1515.6679) nleep/row_max_std 56.4895 (68.0314) nleep/row_min_mean 1500.5701 (1490.3683) lr 1.3681e-03 eta 0:09:03
epoch [21/50] batch [40/160] time 0.096 (0.103) data 0.000 (0.009) loss 1.3660 (1.1775) teacher_loss 0.6084 (0.3950) loss_zs_kd 0.0086 (0.0117) loss_oracle 0.4370 (0.4585) kd_loss 0.5348 (0.5474) acc 78.1250 (84.3750) gate/entropy 0.9781 (0.9782) gate/usage_max 0.5733 (0.5733) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0349 (0.0261) teacher/usage_max 0.9863 (0.9827) teacher/usage_min 0.0002 (0.0029) teacher/usage_std 0.4618 (0.4593) nleep/row_max_mean 1508.6934 (1514.8031) nleep/row_max_std 76.8034 (68.2117) nleep/row_min_mean 1482.9735 (1489.4085) lr 1.3681e-03 eta 0:08:10
epoch [21/50] batch [60/160] time 0.085 (0.100) data 0.001 (0.006) loss 0.9229 (1.1709) teacher_loss 0.1493 (0.3849) loss_zs_kd 0.0011 (0.0118) loss_oracle 0.4496 (0.4606) kd_loss 0.5483 (0.5498) acc 96.8750 (84.8958) gate/entropy 0.9781 (0.9781) gate/usage_max 0.5734 (0.5733) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0566 (0.0264) teacher/usage_max 0.9507 (0.9799) teacher/usage_min 0.0238 (0.0046) teacher/usage_std 0.4365 (0.4572) nleep/row_max_mean 1509.7416 (1516.0316) nleep/row_max_std 77.5361 (65.5319) nleep/row_min_mean 1486.4565 (1490.6642) lr 1.3681e-03 eta 0:07:51
epoch [21/50] batch [80/160] time 0.107 (0.098) data 0.000 (0.005) loss 1.1921 (1.1863) teacher_loss 0.3886 (0.3996) loss_zs_kd 0.0108 (0.0120) loss_oracle 0.4291 (0.4595) kd_loss 0.5835 (0.5509) acc 78.1250 (84.3359) gate/entropy 0.9781 (0.9781) gate/usage_max 0.5734 (0.5733) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0244 (0.0259) teacher/usage_max 0.9477 (0.9793) teacher/usage_min 0.0208 (0.0046) teacher/usage_std 0.4344 (0.4568) nleep/row_max_mean 1527.6138 (1516.5241) nleep/row_max_std 48.1353 (64.5599) nleep/row_min_mean 1502.4814 (1491.3264) lr 1.3681e-03 eta 0:07:44
epoch [21/50] batch [100/160] time 0.093 (0.097) data 0.000 (0.004) loss 1.1519 (1.1934) teacher_loss 0.3327 (0.4061) loss_zs_kd 0.0148 (0.0124) loss_oracle 0.5187 (0.4610) kd_loss 0.5524 (0.5506) acc 84.3750 (84.4062) gate/entropy 0.9781 (0.9781) gate/usage_max 0.5733 (0.5733) gate/usage_min 0.2132 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0049 (0.0256) teacher/usage_max 0.9990 (0.9798) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.4707 (0.4572) nleep/row_max_mean 1522.3699 (1516.7167) nleep/row_max_std 46.4159 (64.6736) nleep/row_min_mean 1496.0989 (1491.5196) lr 1.3681e-03 eta 0:07:37
epoch [21/50] batch [120/160] time 0.121 (0.097) data 0.000 (0.003) loss 1.2557 (1.1905) teacher_loss 0.4174 (0.4043) loss_zs_kd 0.0130 (0.0121) loss_oracle 0.4631 (0.4592) kd_loss 0.6003 (0.5505) acc 71.8750 (84.3229) gate/entropy 0.9780 (0.9781) gate/usage_max 0.5735 (0.5733) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1698 (0.1697) teacher/entropy 0.0197 (0.0263) teacher/usage_max 0.9354 (0.9792) teacher/usage_min 0.0002 (0.0046) teacher/usage_std 0.4265 (0.4568) nleep/row_max_mean 1539.7498 (1516.9381) nleep/row_max_std 25.7366 (64.1527) nleep/row_min_mean 1516.2010 (1491.8308) lr 1.3681e-03 eta 0:07:35
epoch [21/50] batch [140/160] time 0.098 (0.100) data 0.000 (0.003) loss 1.0476 (1.1946) teacher_loss 0.2473 (0.4096) loss_zs_kd 0.0116 (0.0118) loss_oracle 0.4849 (0.4568) kd_loss 0.5520 (0.5506) acc 90.6250 (84.2411) gate/entropy 0.9780 (0.9781) gate/usage_max 0.5734 (0.5733) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0051 (0.0254) teacher/usage_max 0.9991 (0.9800) teacher/usage_min 0.0001 (0.0046) teacher/usage_std 0.4708 (0.4573) nleep/row_max_mean 1540.9323 (1517.7457) nleep/row_max_std 22.4636 (63.1223) nleep/row_min_mean 1515.7579 (1492.6864) lr 1.3681e-03 eta 0:07:45
epoch [21/50] batch [160/160] time 0.083 (0.098) data 0.000 (0.003) loss 1.0163 (1.1988) teacher_loss 0.1876 (0.4145) loss_zs_kd 0.0062 (0.0118) loss_oracle 0.5185 (0.4562) kd_loss 0.5663 (0.5503) acc 90.6250 (84.0234) gate/entropy 0.9780 (0.9781) gate/usage_max 0.5734 (0.5733) gate/usage_min 0.2131 (0.2132) gate/usage_std 0.1697 (0.1697) teacher/entropy 0.0292 (0.0269) teacher/usage_max 0.9602 (0.9788) teacher/usage_min 0.0082 (0.0045) teacher/usage_std 0.4434 (0.4565) nleep/row_max_mean 1537.1398 (1517.9612) nleep/row_max_std 34.3805 (62.7642) nleep/row_min_mean 1513.5294 (1493.0291) lr 1.3090e-03 eta 0:07:36
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,851
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,007
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 89.8%
******* Domain p best val acc:      84.0%, epoch: 18 *******
******* Domain p best val test acc: 89.2%, epoch: 18 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [22/50] batch [20/160] time 0.091 (0.115) data 0.000 (0.018) loss 1.2075 (1.1600) teacher_loss 0.4198 (0.3895) loss_zs_kd 0.0124 (0.0109) loss_oracle 0.4330 (0.4296) kd_loss 0.5650 (0.5502) acc 75.0000 (84.3750) gate/entropy 0.9778 (0.9780) gate/usage_max 0.5736 (0.5735) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1699 (0.1698) teacher/entropy 0.0440 (0.0391) teacher/usage_max 0.9463 (0.9663) teacher/usage_min 0.0133 (0.0043) teacher/usage_std 0.4336 (0.4478) nleep/row_max_mean 1535.6865 (1519.8030) nleep/row_max_std 49.6304 (63.5371) nleep/row_min_mean 1510.4639 (1495.6272) lr 1.3090e-03 eta 0:08:50
epoch [22/50] batch [40/160] time 0.080 (0.102) data 0.000 (0.009) loss 1.1383 (1.1448) teacher_loss 0.3948 (0.3790) loss_zs_kd 0.0083 (0.0115) loss_oracle 0.3875 (0.4231) kd_loss 0.5456 (0.5485) acc 78.1250 (85.3125) gate/entropy 0.9780 (0.9780) gate/usage_max 0.5735 (0.5735) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1698 (0.1698) teacher/entropy 0.0203 (0.0401) teacher/usage_max 0.9900 (0.9670) teacher/usage_min 0.0000 (0.0040) teacher/usage_std 0.4644 (0.4483) nleep/row_max_mean 1531.9510 (1517.6074) nleep/row_max_std 33.9077 (65.8354) nleep/row_min_mean 1508.1777 (1494.0758) lr 1.3090e-03 eta 0:07:47
epoch [22/50] batch [60/160] time 0.098 (0.098) data 0.001 (0.006) loss 1.1487 (1.1586) teacher_loss 0.3868 (0.3898) loss_zs_kd 0.0091 (0.0114) loss_oracle 0.4346 (0.4273) kd_loss 0.5400 (0.5494) acc 75.0000 (84.6875) gate/entropy 0.9779 (0.9780) gate/usage_max 0.5735 (0.5735) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1698 (0.1698) teacher/entropy 0.0221 (0.0364) teacher/usage_max 0.9937 (0.9699) teacher/usage_min 0.0008 (0.0038) teacher/usage_std 0.4670 (0.4503) nleep/row_max_mean 1521.7089 (1518.0910) nleep/row_max_std 68.2127 (63.4709) nleep/row_min_mean 1497.6006 (1494.3932) lr 1.3090e-03 eta 0:07:27
epoch [22/50] batch [80/160] time 0.127 (0.097) data 0.000 (0.005) loss 1.1104 (1.1675) teacher_loss 0.3714 (0.3981) loss_zs_kd 0.0084 (0.0122) loss_oracle 0.4582 (0.4301) kd_loss 0.5057 (0.5482) acc 87.5000 (84.6484) gate/entropy 0.9779 (0.9779) gate/usage_max 0.5735 (0.5735) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1698 (0.1698) teacher/entropy 0.0941 (0.0424) teacher/usage_max 0.9556 (0.9650) teacher/usage_min 0.0165 (0.0064) teacher/usage_std 0.4401 (0.4468) nleep/row_max_mean 1504.8738 (1514.5041) nleep/row_max_std 77.3066 (66.2407) nleep/row_min_mean 1484.9170 (1491.2457) lr 1.3090e-03 eta 0:07:20
epoch [22/50] batch [100/160] time 0.090 (0.095) data 0.000 (0.004) loss 1.3181 (1.1771) teacher_loss 0.5248 (0.4050) loss_zs_kd 0.0135 (0.0123) loss_oracle 0.4467 (0.4333) kd_loss 0.5632 (0.5492) acc 78.1250 (84.3125) gate/entropy 0.9779 (0.9779) gate/usage_max 0.5735 (0.5735) gate/usage_min 0.2131 (0.2131) gate/usage_std 0.1698 (0.1698) teacher/entropy 0.0486 (0.0442) teacher/usage_max 0.9436 (0.9622) teacher/usage_min 0.0049 (0.0070) teacher/usage_std 0.4319 (0.4448) nleep/row_max_mean 1513.9952 (1513.4660) nleep/row_max_std 55.8049 (66.5979) nleep/row_min_mean 1490.8835 (1490.4655) lr 1.3090e-03 eta 0:07:10
epoch [22/50] batch [120/160] time 0.086 (0.093) data 0.000 (0.003) loss 1.1098 (1.1870) teacher_loss 0.3750 (0.4152) loss_zs_kd 0.0112 (0.0121) loss_oracle 0.3804 (0.4320) kd_loss 0.5390 (0.5497) acc 87.5000 (84.2188) gate/entropy 0.9778 (0.9779) gate/usage_max 0.5736 (0.5735) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1699 (0.1698) teacher/entropy 0.0259 (0.0449) teacher/usage_max 0.9907 (0.9609) teacher/usage_min 0.0010 (0.0078) teacher/usage_std 0.4649 (0.4439) nleep/row_max_mean 1539.5828 (1512.8126) nleep/row_max_std 22.3146 (66.5535) nleep/row_min_mean 1516.7911 (1489.9174) lr 1.3090e-03 eta 0:07:01
epoch [22/50] batch [140/160] time 0.088 (0.093) data 0.000 (0.003) loss 1.0987 (1.1835) teacher_loss 0.2692 (0.4118) loss_zs_kd 0.0162 (0.0121) loss_oracle 0.5008 (0.4309) kd_loss 0.5710 (0.5503) acc 84.3750 (84.1964) gate/entropy 0.9778 (0.9779) gate/usage_max 0.5736 (0.5735) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1699 (0.1698) teacher/entropy 0.0292 (0.0430) teacher/usage_max 0.9551 (0.9622) teacher/usage_min 0.0006 (0.0077) teacher/usage_std 0.4400 (0.4449) nleep/row_max_mean 1519.4586 (1513.9767) nleep/row_max_std 58.0937 (64.1926) nleep/row_min_mean 1494.3201 (1490.9767) lr 1.3090e-03 eta 0:06:57
epoch [22/50] batch [160/160] time 0.080 (0.092) data 0.000 (0.002) loss 1.0871 (1.1878) teacher_loss 0.2740 (0.4142) loss_zs_kd 0.0178 (0.0122) loss_oracle 0.4744 (0.4313) kd_loss 0.5670 (0.5518) acc 93.7500 (84.0820) gate/entropy 0.9778 (0.9779) gate/usage_max 0.5736 (0.5735) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1699 (0.1698) teacher/entropy 0.0848 (0.0430) teacher/usage_max 0.9029 (0.9608) teacher/usage_min 0.0383 (0.0081) teacher/usage_std 0.4028 (0.4438) nleep/row_max_mean 1528.1447 (1514.2297) nleep/row_max_std 29.1257 (63.1764) nleep/row_min_mean 1503.6208 (1491.2051) lr 1.2487e-03 eta 0:06:52
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,847
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,002
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 89.6%
******* Domain p best val acc:      84.0%, epoch: 18 *******
******* Domain p best val test acc: 89.2%, epoch: 18 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [23/50] batch [20/160] time 0.089 (0.109) data 0.000 (0.013) loss 1.1078 (1.1638) teacher_loss 0.3684 (0.3839) loss_zs_kd 0.0048 (0.0118) loss_oracle 0.4065 (0.4452) kd_loss 0.5338 (0.5514) acc 78.1250 (83.7500) gate/entropy 0.9778 (0.9778) gate/usage_max 0.5736 (0.5736) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0783 (0.0514) teacher/usage_max 0.9432 (0.9525) teacher/usage_min 0.0221 (0.0127) teacher/usage_std 0.4313 (0.4380) nleep/row_max_mean 1521.9164 (1516.0455) nleep/row_max_std 71.6123 (59.4866) nleep/row_min_mean 1502.3715 (1493.4827) lr 1.2487e-03 eta 0:08:04
epoch [23/50] batch [40/160] time 0.188 (0.104) data 0.001 (0.007) loss 1.3166 (1.1859) teacher_loss 0.4823 (0.4050) loss_zs_kd 0.0077 (0.0143) loss_oracle 0.4629 (0.4361) kd_loss 0.5991 (0.5556) acc 81.2500 (83.9062) gate/entropy 0.9779 (0.9778) gate/usage_max 0.5736 (0.5736) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0156 (0.0505) teacher/usage_max 0.9405 (0.9491) teacher/usage_min 0.0274 (0.0121) teacher/usage_std 0.4293 (0.4356) nleep/row_max_mean 1515.2112 (1513.0757) nleep/row_max_std 45.1935 (62.6307) nleep/row_min_mean 1489.5435 (1490.1088) lr 1.2487e-03 eta 0:07:40
epoch [23/50] batch [60/160] time 0.087 (0.103) data 0.000 (0.005) loss 1.4375 (1.2055) teacher_loss 0.6401 (0.4203) loss_zs_kd 0.0171 (0.0146) loss_oracle 0.4548 (0.4411) kd_loss 0.5615 (0.5573) acc 78.1250 (83.9583) gate/entropy 0.9777 (0.9778) gate/usage_max 0.5737 (0.5736) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1699) teacher/entropy 0.0184 (0.0464) teacher/usage_max 0.9755 (0.9515) teacher/usage_min 0.0002 (0.0103) teacher/usage_std 0.4542 (0.4373) nleep/row_max_mean 1515.8959 (1513.3146) nleep/row_max_std 60.9498 (62.2003) nleep/row_min_mean 1490.8312 (1489.8794) lr 1.2487e-03 eta 0:07:35
epoch [23/50] batch [80/160] time 0.089 (0.100) data 0.000 (0.004) loss 1.2904 (1.2016) teacher_loss 0.5330 (0.4219) loss_zs_kd 0.0098 (0.0141) loss_oracle 0.3795 (0.4331) kd_loss 0.5627 (0.5561) acc 81.2500 (83.9844) gate/entropy 0.9778 (0.9778) gate/usage_max 0.5737 (0.5736) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1699 (0.1699) teacher/entropy 0.0436 (0.0452) teacher/usage_max 0.9488 (0.9539) teacher/usage_min 0.0240 (0.0101) teacher/usage_std 0.4352 (0.4390) nleep/row_max_mean 1524.3169 (1513.7579) nleep/row_max_std 35.3891 (62.1771) nleep/row_min_mean 1499.0522 (1490.1038) lr 1.2487e-03 eta 0:07:21
epoch [23/50] batch [100/160] time 0.093 (0.098) data 0.000 (0.003) loss 1.0962 (1.2010) teacher_loss 0.2292 (0.4227) loss_zs_kd 0.0136 (0.0138) loss_oracle 0.3982 (0.4277) kd_loss 0.6611 (0.5575) acc 93.7500 (83.9062) gate/entropy 0.9779 (0.9778) gate/usage_max 0.5735 (0.5736) gate/usage_min 0.2131 (0.2130) gate/usage_std 0.1698 (0.1699) teacher/entropy 0.0618 (0.0482) teacher/usage_max 0.8312 (0.9495) teacher/usage_min 0.0214 (0.0115) teacher/usage_std 0.3558 (0.4359) nleep/row_max_mean 1479.5360 (1512.5736) nleep/row_max_std 85.4843 (63.9505) nleep/row_min_mean 1458.1704 (1489.0148) lr 1.2487e-03 eta 0:07:10
epoch [23/50] batch [120/160] time 0.094 (0.098) data 0.000 (0.002) loss 0.9825 (1.1972) teacher_loss 0.1855 (0.4189) loss_zs_kd 0.0090 (0.0139) loss_oracle 0.4376 (0.4259) kd_loss 0.5737 (0.5584) acc 96.8750 (84.0104) gate/entropy 0.9777 (0.9778) gate/usage_max 0.5738 (0.5737) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1699) teacher/entropy 0.0288 (0.0488) teacher/usage_max 0.9525 (0.9480) teacher/usage_min 0.0009 (0.0117) teacher/usage_std 0.4382 (0.4349) nleep/row_max_mean 1516.8420 (1513.0920) nleep/row_max_std 55.4259 (63.2764) nleep/row_min_mean 1492.1522 (1489.4747) lr 1.2487e-03 eta 0:07:05
epoch [23/50] batch [140/160] time 0.100 (0.097) data 0.000 (0.002) loss 1.1242 (1.1969) teacher_loss 0.2674 (0.4152) loss_zs_kd 0.0162 (0.0143) loss_oracle 0.4425 (0.4274) kd_loss 0.6274 (0.5608) acc 87.5000 (84.0625) gate/entropy 0.9777 (0.9778) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1699) teacher/entropy 0.0212 (0.0489) teacher/usage_max 0.9060 (0.9453) teacher/usage_min 0.0295 (0.0112) teacher/usage_std 0.4052 (0.4331) nleep/row_max_mean 1522.0378 (1513.4167) nleep/row_max_std 47.4652 (63.0954) nleep/row_min_mean 1497.9991 (1489.5840) lr 1.2487e-03 eta 0:07:00
epoch [23/50] batch [160/160] time 0.087 (0.096) data 0.000 (0.002) loss 1.1208 (1.1969) teacher_loss 0.3190 (0.4127) loss_zs_kd 0.0170 (0.0146) loss_oracle 0.4845 (0.4290) kd_loss 0.5511 (0.5624) acc 87.5000 (84.2578) gate/entropy 0.9777 (0.9778) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1699) teacher/entropy 0.0629 (0.0490) teacher/usage_max 0.9410 (0.9437) teacher/usage_min 0.0000 (0.0109) teacher/usage_std 0.4303 (0.4320) nleep/row_max_mean 1523.2717 (1513.7406) nleep/row_max_std 28.3775 (63.0609) nleep/row_min_mean 1497.1323 (1489.7911) lr 1.1874e-03 eta 0:06:53
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,836
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,006
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 89.6%
******* Domain p best val acc:      84.0%, epoch: 18 *******
******* Domain p best val test acc: 89.2%, epoch: 18 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [24/50] batch [20/160] time 0.089 (0.106) data 0.000 (0.015) loss 1.1545 (1.1394) teacher_loss 0.3450 (0.3505) loss_zs_kd 0.0108 (0.0153) loss_oracle 0.4299 (0.4272) kd_loss 0.5892 (0.5676) acc 90.6250 (86.0938) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0567 (0.0506) teacher/usage_max 0.9087 (0.9368) teacher/usage_min 0.0006 (0.0102) teacher/usage_std 0.4085 (0.4273) nleep/row_max_mean 1515.6283 (1513.2766) nleep/row_max_std 60.5817 (59.5223) nleep/row_min_mean 1492.3010 (1488.9570) lr 1.1874e-03 eta 0:07:37
epoch [24/50] batch [40/160] time 0.096 (0.099) data 0.000 (0.008) loss 1.0596 (1.1700) teacher_loss 0.3014 (0.3832) loss_zs_kd 0.0059 (0.0148) loss_oracle 0.4216 (0.4341) kd_loss 0.5445 (0.5624) acc 93.7500 (85.4688) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5737 (0.5737) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0482 (0.0457) teacher/usage_max 0.9625 (0.9469) teacher/usage_min 0.0008 (0.0073) teacher/usage_std 0.4451 (0.4344) nleep/row_max_mean 1529.7061 (1514.0529) nleep/row_max_std 23.3710 (60.2491) nleep/row_min_mean 1505.2490 (1488.5192) lr 1.1874e-03 eta 0:07:05
epoch [24/50] batch [60/160] time 0.090 (0.097) data 0.001 (0.005) loss 1.2009 (1.1680) teacher_loss 0.4458 (0.3907) loss_zs_kd 0.0139 (0.0144) loss_oracle 0.4140 (0.4235) kd_loss 0.5412 (0.5584) acc 78.1250 (85.6771) gate/entropy 0.9776 (0.9777) gate/usage_max 0.5739 (0.5738) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1701 (0.1700) teacher/entropy 0.0356 (0.0460) teacher/usage_max 0.9784 (0.9507) teacher/usage_min 0.0005 (0.0064) teacher/usage_std 0.4562 (0.4370) nleep/row_max_mean 1506.9553 (1511.6426) nleep/row_max_std 87.8654 (64.2879) nleep/row_min_mean 1478.4075 (1485.8444) lr 1.1874e-03 eta 0:06:52
epoch [24/50] batch [80/160] time 0.095 (0.096) data 0.000 (0.004) loss 1.3781 (1.1702) teacher_loss 0.6177 (0.3944) loss_zs_kd 0.0100 (0.0150) loss_oracle 0.4250 (0.4181) kd_loss 0.5429 (0.5593) acc 78.1250 (85.5469) gate/entropy 0.9777 (0.9777) gate/usage_max 0.5737 (0.5738) gate/usage_min 0.2130 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0613 (0.0446) teacher/usage_max 0.9509 (0.9512) teacher/usage_min 0.0073 (0.0061) teacher/usage_std 0.4369 (0.4373) nleep/row_max_mean 1499.9698 (1512.6127) nleep/row_max_std 89.0719 (62.8272) nleep/row_min_mean 1475.3662 (1486.6308) lr 1.1874e-03 eta 0:06:47
epoch [24/50] batch [100/160] time 0.092 (0.096) data 0.000 (0.003) loss 1.0790 (1.1708) teacher_loss 0.3015 (0.3922) loss_zs_kd 0.0286 (0.0149) loss_oracle 0.4385 (0.4232) kd_loss 0.5440 (0.5596) acc 93.7500 (85.4688) gate/entropy 0.9776 (0.9777) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1700 (0.1700) teacher/entropy 0.0147 (0.0430) teacher/usage_max 0.9967 (0.9524) teacher/usage_min 0.0010 (0.0054) teacher/usage_std 0.4691 (0.4382) nleep/row_max_mean 1522.3848 (1512.8707) nleep/row_max_std 43.2594 (62.5488) nleep/row_min_mean 1495.3938 (1486.8536) lr 1.1874e-03 eta 0:06:45
epoch [24/50] batch [120/160] time 0.092 (0.096) data 0.000 (0.003) loss 1.2442 (1.1805) teacher_loss 0.4032 (0.3995) loss_zs_kd 0.0174 (0.0151) loss_oracle 0.4656 (0.4274) kd_loss 0.5995 (0.5596) acc 75.0000 (85.0000) gate/entropy 0.9776 (0.9777) gate/usage_max 0.5738 (0.5738) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1701 (0.1700) teacher/entropy 0.0280 (0.0423) teacher/usage_max 0.9272 (0.9530) teacher/usage_min 0.0002 (0.0055) teacher/usage_std 0.4210 (0.4386) nleep/row_max_mean 1512.6155 (1512.9479) nleep/row_max_std 82.0128 (62.4657) nleep/row_min_mean 1486.4174 (1486.9521) lr 1.1874e-03 eta 0:06:43
epoch [24/50] batch [140/160] time 0.095 (0.096) data 0.000 (0.002) loss 1.2394 (1.1860) teacher_loss 0.4851 (0.4039) loss_zs_kd 0.0169 (0.0150) loss_oracle 0.3875 (0.4286) kd_loss 0.5522 (0.5603) acc 68.7500 (84.8884) gate/entropy 0.9775 (0.9776) gate/usage_max 0.5739 (0.5738) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1701 (0.1700) teacher/entropy 0.0524 (0.0416) teacher/usage_max 0.9503 (0.9531) teacher/usage_min 0.0005 (0.0056) teacher/usage_std 0.4367 (0.4387) nleep/row_max_mean 1517.0940 (1513.2805) nleep/row_max_std 64.3099 (62.3807) nleep/row_min_mean 1489.2496 (1487.2179) lr 1.1874e-03 eta 0:06:39
epoch [24/50] batch [160/160] time 0.089 (0.095) data 0.000 (0.002) loss 1.4080 (1.1928) teacher_loss 0.5694 (0.4117) loss_zs_kd 0.0077 (0.0152) loss_oracle 0.5029 (0.4283) kd_loss 0.5832 (0.5594) acc 75.0000 (84.5703) gate/entropy 0.9775 (0.9776) gate/usage_max 0.5739 (0.5738) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1701 (0.1700) teacher/entropy 0.0675 (0.0404) teacher/usage_max 0.9036 (0.9552) teacher/usage_min 0.0359 (0.0056) teacher/usage_std 0.4034 (0.4401) nleep/row_max_mean 1517.1250 (1513.5708) nleep/row_max_std 54.7549 (62.1051) nleep/row_min_mean 1491.9019 (1487.4023) lr 1.1253e-03 eta 0:06:35
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,848
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,998
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 89.4%
******* Domain p best val acc:      84.0%, epoch: 18 *******
******* Domain p best val test acc: 89.2%, epoch: 18 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [25/50] batch [20/160] time 0.091 (0.103) data 0.000 (0.011) loss 1.0307 (1.2009) teacher_loss 0.2813 (0.4341) loss_zs_kd 0.0133 (0.0132) loss_oracle 0.4031 (0.4087) kd_loss 0.5413 (0.5559) acc 90.6250 (82.0312) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0531 (0.0316) teacher/usage_max 0.9605 (0.9675) teacher/usage_min 0.0001 (0.0043) teacher/usage_std 0.4438 (0.4486) nleep/row_max_mean 1519.2001 (1517.0581) nleep/row_max_std 56.0639 (58.1116) nleep/row_min_mean 1492.6716 (1490.6412) lr 1.1253e-03 eta 0:07:08
epoch [25/50] batch [40/160] time 0.089 (0.097) data 0.000 (0.006) loss 1.1043 (1.1759) teacher_loss 0.3561 (0.4114) loss_zs_kd 0.0111 (0.0129) loss_oracle 0.3341 (0.4061) kd_loss 0.5756 (0.5551) acc 87.5000 (83.5156) gate/entropy 0.9776 (0.9776) gate/usage_max 0.5738 (0.5739) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1700 (0.1701) teacher/entropy 0.0550 (0.0355) teacher/usage_max 0.9240 (0.9644) teacher/usage_min 0.0045 (0.0054) teacher/usage_std 0.4186 (0.4465) nleep/row_max_mean 1488.9966 (1514.1384) nleep/row_max_std 96.6944 (62.3142) nleep/row_min_mean 1465.5034 (1487.6197) lr 1.1253e-03 eta 0:06:39
epoch [25/50] batch [60/160] time 0.092 (0.095) data 0.000 (0.004) loss 1.2612 (1.1807) teacher_loss 0.4549 (0.4154) loss_zs_kd 0.0174 (0.0140) loss_oracle 0.4424 (0.4056) kd_loss 0.5764 (0.5555) acc 78.1250 (83.9583) gate/entropy 0.9775 (0.9776) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0078 (0.0328) teacher/usage_max 0.9708 (0.9667) teacher/usage_min 0.0000 (0.0053) teacher/usage_std 0.4509 (0.4481) nleep/row_max_mean 1525.3674 (1512.6846) nleep/row_max_std 52.0722 (64.2053) nleep/row_min_mean 1498.4102 (1486.1814) lr 1.1253e-03 eta 0:06:31
epoch [25/50] batch [80/160] time 0.110 (0.095) data 0.000 (0.003) loss 1.1947 (1.1875) teacher_loss 0.4379 (0.4222) loss_zs_kd 0.0123 (0.0143) loss_oracle 0.3752 (0.4064) kd_loss 0.5630 (0.5549) acc 75.0000 (83.8672) gate/entropy 0.9775 (0.9776) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0798 (0.0346) teacher/usage_max 0.9115 (0.9655) teacher/usage_min 0.0275 (0.0061) teacher/usage_std 0.4091 (0.4472) nleep/row_max_mean 1506.1278 (1512.6507) nleep/row_max_std 72.2465 (64.5522) nleep/row_min_mean 1482.1482 (1486.2994) lr 1.1253e-03 eta 0:06:28
epoch [25/50] batch [100/160] time 0.093 (0.096) data 0.000 (0.002) loss 1.1187 (1.1843) teacher_loss 0.3610 (0.4177) loss_zs_kd 0.0114 (0.0153) loss_oracle 0.3941 (0.4077) kd_loss 0.5550 (0.5552) acc 84.3750 (84.3438) gate/entropy 0.9776 (0.9775) gate/usage_max 0.5738 (0.5739) gate/usage_min 0.2130 (0.2129) gate/usage_std 0.1700 (0.1701) teacher/entropy 0.0252 (0.0358) teacher/usage_max 0.9750 (0.9640) teacher/usage_min 0.0001 (0.0057) teacher/usage_std 0.4539 (0.4462) nleep/row_max_mean 1505.5723 (1512.0179) nleep/row_max_std 59.5305 (65.2497) nleep/row_min_mean 1480.3843 (1485.8109) lr 1.1253e-03 eta 0:06:28
epoch [25/50] batch [120/160] time 0.103 (0.097) data 0.000 (0.002) loss 1.0404 (1.1801) teacher_loss 0.2837 (0.4115) loss_zs_kd 0.0148 (0.0150) loss_oracle 0.4079 (0.4085) kd_loss 0.5454 (0.5568) acc 87.5000 (84.5573) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0203 (0.0353) teacher/usage_max 0.9893 (0.9628) teacher/usage_min 0.0000 (0.0055) teacher/usage_std 0.4639 (0.4454) nleep/row_max_mean 1527.8093 (1512.7788) nleep/row_max_std 32.7251 (63.7116) nleep/row_min_mean 1501.2622 (1486.5704) lr 1.1253e-03 eta 0:06:30
epoch [25/50] batch [140/160] time 0.091 (0.097) data 0.000 (0.002) loss 1.3063 (1.1852) teacher_loss 0.5102 (0.4152) loss_zs_kd 0.0218 (0.0150) loss_oracle 0.4836 (0.4095) kd_loss 0.5434 (0.5577) acc 84.3750 (84.3304) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0381 (0.0341) teacher/usage_max 0.9734 (0.9630) teacher/usage_min 0.0001 (0.0051) teacher/usage_std 0.4527 (0.4455) nleep/row_max_mean 1500.4001 (1513.1648) nleep/row_max_std 77.2754 (63.0139) nleep/row_min_mean 1474.2655 (1486.9481) lr 1.1253e-03 eta 0:06:28
epoch [25/50] batch [160/160] time 0.087 (0.095) data 0.000 (0.002) loss 1.1162 (1.1844) teacher_loss 0.3519 (0.4132) loss_zs_kd 0.0153 (0.0147) loss_oracle 0.4313 (0.4127) kd_loss 0.5410 (0.5575) acc 87.5000 (84.2969) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5739) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0192 (0.0336) teacher/usage_max 0.9950 (0.9639) teacher/usage_min 0.0011 (0.0049) teacher/usage_std 0.4679 (0.4461) nleep/row_max_mean 1517.6748 (1513.4087) nleep/row_max_std 59.7636 (62.4743) nleep/row_min_mean 1487.7034 (1487.0254) lr 1.0628e-03 eta 0:06:20
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,858
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 85.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,004
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 89.6%
******* Domain p best val acc:      84.2%, epoch: 25 *******
******* Domain p best val test acc: 89.0%, epoch: 25 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [26/50] batch [20/160] time 0.089 (0.102) data 0.000 (0.015) loss 1.1640 (1.1365) teacher_loss 0.3698 (0.3642) loss_zs_kd 0.0183 (0.0148) loss_oracle 0.4672 (0.4295) kd_loss 0.5515 (0.5501) acc 81.2500 (85.7812) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5739) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1702 (0.1701) teacher/entropy 0.0464 (0.0383) teacher/usage_max 0.9568 (0.9665) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.4412 (0.4480) nleep/row_max_mean 1528.9474 (1509.4159) nleep/row_max_std 46.4331 (65.9073) nleep/row_min_mean 1499.0078 (1481.9316) lr 1.0628e-03 eta 0:06:45
epoch [26/50] batch [40/160] time 0.077 (0.091) data 0.000 (0.008) loss 1.2962 (1.1590) teacher_loss 0.4561 (0.3762) loss_zs_kd 0.0100 (0.0149) loss_oracle 0.4567 (0.4347) kd_loss 0.6068 (0.5580) acc 84.3750 (85.2344) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1701 (0.1701) teacher/entropy 0.0123 (0.0334) teacher/usage_max 0.9355 (0.9634) teacher/usage_min 0.0023 (0.0028) teacher/usage_std 0.4265 (0.4459) nleep/row_max_mean 1502.4375 (1512.0404) nleep/row_max_std 74.5690 (61.9611) nleep/row_min_mean 1472.1649 (1484.2492) lr 1.0628e-03 eta 0:06:01
epoch [26/50] batch [60/160] time 0.096 (0.088) data 0.001 (0.005) loss 1.4535 (1.1615) teacher_loss 0.6901 (0.3825) loss_zs_kd 0.0065 (0.0144) loss_oracle 0.3940 (0.4289) kd_loss 0.5631 (0.5573) acc 81.2500 (84.8438) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5741 (0.5740) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0222 (0.0331) teacher/usage_max 0.9694 (0.9643) teacher/usage_min 0.0009 (0.0026) teacher/usage_std 0.4499 (0.4465) nleep/row_max_mean 1505.5199 (1511.8367) nleep/row_max_std 81.5632 (62.7704) nleep/row_min_mean 1476.5854 (1484.2518) lr 1.0628e-03 eta 0:05:46
epoch [26/50] batch [80/160] time 0.078 (0.087) data 0.000 (0.004) loss 1.0524 (1.1710) teacher_loss 0.2512 (0.3936) loss_zs_kd 0.0116 (0.0140) loss_oracle 0.4569 (0.4287) kd_loss 0.5669 (0.5560) acc 84.3750 (84.6094) gate/entropy 0.9774 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0265 (0.0310) teacher/usage_max 0.9613 (0.9678) teacher/usage_min 0.0037 (0.0028) teacher/usage_std 0.4442 (0.4490) nleep/row_max_mean 1510.6782 (1512.2092) nleep/row_max_std 62.8823 (62.6788) nleep/row_min_mean 1483.7511 (1484.4644) lr 1.0628e-03 eta 0:05:41
epoch [26/50] batch [100/160] time 0.091 (0.086) data 0.000 (0.003) loss 1.2798 (1.1831) teacher_loss 0.4771 (0.4066) loss_zs_kd 0.0216 (0.0147) loss_oracle 0.4358 (0.4264) kd_loss 0.5740 (0.5560) acc 78.1250 (84.6562) gate/entropy 0.9775 (0.9775) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0123 (0.0312) teacher/usage_max 0.9685 (0.9677) teacher/usage_min 0.0014 (0.0031) teacher/usage_std 0.4493 (0.4488) nleep/row_max_mean 1506.5966 (1511.9697) nleep/row_max_std 67.2326 (63.3265) nleep/row_min_mean 1477.3057 (1484.2375) lr 1.0628e-03 eta 0:05:36
epoch [26/50] batch [120/160] time 0.077 (0.089) data 0.000 (0.003) loss 1.4532 (1.1809) teacher_loss 0.6936 (0.4054) loss_zs_kd 0.0212 (0.0147) loss_oracle 0.4265 (0.4257) kd_loss 0.5358 (0.5553) acc 78.1250 (84.6615) gate/entropy 0.9774 (0.9774) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0307 (0.0311) teacher/usage_max 0.9884 (0.9684) teacher/usage_min 0.0008 (0.0034) teacher/usage_std 0.4633 (0.4493) nleep/row_max_mean 1494.0110 (1511.9790) nleep/row_max_std 94.0746 (63.5033) nleep/row_min_mean 1468.3743 (1484.2020) lr 1.0628e-03 eta 0:05:47
epoch [26/50] batch [140/160] time 0.091 (0.089) data 0.000 (0.002) loss 1.2891 (1.1791) teacher_loss 0.5026 (0.4046) loss_zs_kd 0.0180 (0.0147) loss_oracle 0.4201 (0.4251) kd_loss 0.5675 (0.5546) acc 78.1250 (84.5536) gate/entropy 0.9775 (0.9774) gate/usage_max 0.5739 (0.5740) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1701 (0.1702) teacher/entropy 0.0266 (0.0302) teacher/usage_max 0.9608 (0.9701) teacher/usage_min 0.0003 (0.0033) teacher/usage_std 0.4439 (0.4505) nleep/row_max_mean 1500.8508 (1512.0631) nleep/row_max_std 79.3078 (63.0597) nleep/row_min_mean 1474.9661 (1484.2290) lr 1.0628e-03 eta 0:05:42
epoch [26/50] batch [160/160] time 0.082 (0.088) data 0.000 (0.002) loss 1.1549 (1.1818) teacher_loss 0.4162 (0.4076) loss_zs_kd 0.0104 (0.0146) loss_oracle 0.4096 (0.4247) kd_loss 0.5287 (0.5545) acc 87.5000 (84.4531) gate/entropy 0.9774 (0.9774) gate/usage_max 0.5740 (0.5740) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0391 (0.0301) teacher/usage_max 0.9872 (0.9703) teacher/usage_min 0.0040 (0.0031) teacher/usage_std 0.4623 (0.4506) nleep/row_max_mean 1500.4332 (1512.6009) nleep/row_max_std 77.6987 (62.0958) nleep/row_min_mean 1472.3745 (1484.6487) lr 1.0000e-03 eta 0:05:38
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,848
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,996
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 89.5%
******* Domain p best val acc:      84.2%, epoch: 25 *******
******* Domain p best val test acc: 89.0%, epoch: 25 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [27/50] batch [20/160] time 0.085 (0.103) data 0.000 (0.013) loss 1.2685 (1.1657) teacher_loss 0.4889 (0.3938) loss_zs_kd 0.0200 (0.0126) loss_oracle 0.3969 (0.4211) kd_loss 0.5711 (0.5551) acc 81.2500 (85.1562) gate/entropy 0.9774 (0.9774) gate/usage_max 0.5741 (0.5741) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0557 (0.0323) teacher/usage_max 0.9276 (0.9673) teacher/usage_min 0.0012 (0.0043) teacher/usage_std 0.4212 (0.4485) nleep/row_max_mean 1505.3647 (1515.4712) nleep/row_max_std 76.7133 (58.5868) nleep/row_min_mean 1476.0574 (1486.5749) lr 1.0000e-03 eta 0:06:33
epoch [27/50] batch [40/160] time 0.080 (0.096) data 0.000 (0.007) loss 1.2024 (1.1884) teacher_loss 0.4165 (0.4124) loss_zs_kd 0.0053 (0.0125) loss_oracle 0.4221 (0.4219) kd_loss 0.5722 (0.5589) acc 84.3750 (84.9219) gate/entropy 0.9774 (0.9774) gate/usage_max 0.5740 (0.5741) gate/usage_min 0.2129 (0.2128) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0144 (0.0293) teacher/usage_max 0.9681 (0.9666) teacher/usage_min 0.0005 (0.0045) teacher/usage_std 0.4490 (0.4480) nleep/row_max_mean 1501.8762 (1514.2928) nleep/row_max_std 86.8948 (61.2416) nleep/row_min_mean 1471.7178 (1485.6745) lr 1.0000e-03 eta 0:06:05
epoch [27/50] batch [60/160] time 0.084 (0.091) data 0.000 (0.005) loss 1.1616 (1.1777) teacher_loss 0.4010 (0.4038) loss_zs_kd 0.0075 (0.0134) loss_oracle 0.4233 (0.4213) kd_loss 0.5452 (0.5566) acc 84.3750 (85.0521) gate/entropy 0.9773 (0.9774) gate/usage_max 0.5741 (0.5741) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1702) teacher/entropy 0.0248 (0.0290) teacher/usage_max 0.9847 (0.9692) teacher/usage_min 0.0004 (0.0042) teacher/usage_std 0.4606 (0.4498) nleep/row_max_mean 1521.8086 (1514.2298) nleep/row_max_std 62.6651 (63.2355) nleep/row_min_mean 1494.2202 (1485.8415) lr 1.0000e-03 eta 0:05:44
epoch [27/50] batch [80/160] time 0.087 (0.088) data 0.000 (0.003) loss 1.2368 (1.1820) teacher_loss 0.4162 (0.4074) loss_zs_kd 0.0193 (0.0139) loss_oracle 0.4330 (0.4238) kd_loss 0.5945 (0.5558) acc 81.2500 (84.8438) gate/entropy 0.9773 (0.9774) gate/usage_max 0.5742 (0.5741) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1702) teacher/entropy 0.0310 (0.0293) teacher/usage_max 0.9287 (0.9696) teacher/usage_min 0.0003 (0.0037) teacher/usage_std 0.4220 (0.4501) nleep/row_max_mean 1506.1082 (1514.3833) nleep/row_max_std 79.8793 (62.9155) nleep/row_min_mean 1478.4592 (1485.8881) lr 1.0000e-03 eta 0:05:31
epoch [27/50] batch [100/160] time 0.092 (0.089) data 0.000 (0.003) loss 1.3498 (1.1831) teacher_loss 0.5342 (0.4067) loss_zs_kd 0.0083 (0.0143) loss_oracle 0.4207 (0.4231) kd_loss 0.6012 (0.5577) acc 81.2500 (84.8750) gate/entropy 0.9774 (0.9773) gate/usage_max 0.5741 (0.5741) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1702 (0.1702) teacher/entropy 0.0362 (0.0280) teacher/usage_max 0.9168 (0.9690) teacher/usage_min 0.0001 (0.0031) teacher/usage_std 0.4140 (0.4497) nleep/row_max_mean 1504.4448 (1514.2466) nleep/row_max_std 76.9161 (63.5777) nleep/row_min_mean 1476.6633 (1485.8777) lr 1.0000e-03 eta 0:05:31
epoch [27/50] batch [120/160] time 0.081 (0.088) data 0.000 (0.002) loss 0.9610 (1.1911) teacher_loss 0.2189 (0.4135) loss_zs_kd 0.0291 (0.0141) loss_oracle 0.4025 (0.4247) kd_loss 0.5263 (0.5582) acc 93.7500 (84.4271) gate/entropy 0.9773 (0.9773) gate/usage_max 0.5741 (0.5741) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1702) teacher/entropy 0.0939 (0.0287) teacher/usage_max 0.9342 (0.9678) teacher/usage_min 0.0035 (0.0034) teacher/usage_std 0.4255 (0.4489) nleep/row_max_mean 1503.7958 (1514.0589) nleep/row_max_std 73.7782 (62.9490) nleep/row_min_mean 1477.4708 (1485.7894) lr 1.0000e-03 eta 0:05:28
epoch [27/50] batch [140/160] time 0.088 (0.088) data 0.000 (0.002) loss 1.2074 (1.1892) teacher_loss 0.3556 (0.4126) loss_zs_kd 0.0116 (0.0140) loss_oracle 0.4752 (0.4234) kd_loss 0.6084 (0.5579) acc 81.2500 (84.3527) gate/entropy 0.9772 (0.9773) gate/usage_max 0.5742 (0.5741) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1702) teacher/entropy 0.0345 (0.0279) teacher/usage_max 0.9112 (0.9688) teacher/usage_min 0.0276 (0.0032) teacher/usage_std 0.4088 (0.4496) nleep/row_max_mean 1512.2332 (1514.0248) nleep/row_max_std 82.7782 (62.2062) nleep/row_min_mean 1483.9504 (1485.7987) lr 1.0000e-03 eta 0:05:24
epoch [27/50] batch [160/160] time 0.085 (0.088) data 0.000 (0.002) loss 1.1180 (1.1903) teacher_loss 0.3597 (0.4133) loss_zs_kd 0.0139 (0.0140) loss_oracle 0.4114 (0.4224) kd_loss 0.5456 (0.5588) acc 84.3750 (84.3945) gate/entropy 0.9773 (0.9773) gate/usage_max 0.5741 (0.5741) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1702) teacher/entropy 0.0472 (0.0281) teacher/usage_max 0.9618 (0.9677) teacher/usage_min 0.0005 (0.0033) teacher/usage_std 0.4446 (0.4488) nleep/row_max_mean 1519.9952 (1513.6687) nleep/row_max_std 76.3781 (62.4840) nleep/row_min_mean 1489.6676 (1485.4661) lr 9.3721e-04 eta 0:05:22
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,852
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,000
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 89.6%
******* Domain p best val acc:      84.2%, epoch: 25 *******
******* Domain p best val test acc: 89.0%, epoch: 25 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [28/50] batch [20/160] time 0.081 (0.109) data 0.000 (0.021) loss 1.0941 (1.2360) teacher_loss 0.3269 (0.4546) loss_zs_kd 0.0084 (0.0152) loss_oracle 0.4086 (0.4289) kd_loss 0.5588 (0.5594) acc 87.5000 (83.4375) gate/entropy 0.9773 (0.9773) gate/usage_max 0.5742 (0.5741) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1703) teacher/entropy 0.0444 (0.0250) teacher/usage_max 0.9512 (0.9702) teacher/usage_min 0.0015 (0.0026) teacher/usage_std 0.4373 (0.4507) nleep/row_max_mean 1522.6400 (1514.9193) nleep/row_max_std 61.3130 (62.0247) nleep/row_min_mean 1494.1715 (1486.2615) lr 9.3721e-04 eta 0:06:39
epoch [28/50] batch [40/160] time 0.176 (0.108) data 0.002 (0.011) loss 1.3228 (1.1952) teacher_loss 0.5584 (0.4117) loss_zs_kd 0.0115 (0.0144) loss_oracle 0.4329 (0.4278) kd_loss 0.5422 (0.5624) acc 81.2500 (84.0625) gate/entropy 0.9774 (0.9773) gate/usage_max 0.5741 (0.5741) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1702 (0.1703) teacher/entropy 0.0176 (0.0239) teacher/usage_max 0.9951 (0.9683) teacher/usage_min 0.0013 (0.0033) teacher/usage_std 0.4680 (0.4493) nleep/row_max_mean 1503.6082 (1514.0485) nleep/row_max_std 63.5754 (63.2168) nleep/row_min_mean 1475.2272 (1485.4923) lr 9.3721e-04 eta 0:06:34
epoch [28/50] batch [60/160] time 0.099 (0.105) data 0.001 (0.007) loss 1.0919 (1.1915) teacher_loss 0.3365 (0.4088) loss_zs_kd 0.0244 (0.0145) loss_oracle 0.4229 (0.4281) kd_loss 0.5317 (0.5615) acc 90.6250 (84.4271) gate/entropy 0.9773 (0.9773) gate/usage_max 0.5742 (0.5742) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1703) teacher/entropy 0.0493 (0.0223) teacher/usage_max 0.9736 (0.9708) teacher/usage_min 0.0048 (0.0026) teacher/usage_std 0.4528 (0.4510) nleep/row_max_mean 1510.0522 (1515.1979) nleep/row_max_std 78.3576 (61.6298) nleep/row_min_mean 1482.7910 (1486.6442) lr 9.3721e-04 eta 0:06:20
epoch [28/50] batch [80/160] time 0.100 (0.103) data 0.000 (0.005) loss 1.0852 (1.1834) teacher_loss 0.3315 (0.4009) loss_zs_kd 0.0130 (0.0144) loss_oracle 0.4228 (0.4266) kd_loss 0.5358 (0.5620) acc 87.5000 (84.8438) gate/entropy 0.9773 (0.9773) gate/usage_max 0.5742 (0.5742) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1703) teacher/entropy 0.0441 (0.0235) teacher/usage_max 0.9747 (0.9691) teacher/usage_min 0.0080 (0.0037) teacher/usage_std 0.4535 (0.4498) nleep/row_max_mean 1533.0569 (1515.7375) nleep/row_max_std 24.6859 (60.7283) nleep/row_min_mean 1506.3396 (1487.4975) lr 9.3721e-04 eta 0:06:10
epoch [28/50] batch [100/160] time 0.093 (0.102) data 0.000 (0.004) loss 1.1881 (1.1729) teacher_loss 0.3790 (0.3896) loss_zs_kd 0.0092 (0.0142) loss_oracle 0.4037 (0.4267) kd_loss 0.6028 (0.5628) acc 81.2500 (85.1562) gate/entropy 0.9773 (0.9773) gate/usage_max 0.5742 (0.5742) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1703) teacher/entropy 0.0655 (0.0252) teacher/usage_max 0.8857 (0.9665) teacher/usage_min 0.0005 (0.0037) teacher/usage_std 0.3933 (0.4480) nleep/row_max_mean 1489.1237 (1515.1108) nleep/row_max_std 85.8976 (61.1283) nleep/row_min_mean 1466.2721 (1487.0699) lr 9.3721e-04 eta 0:06:03
epoch [28/50] batch [120/160] time 0.098 (0.101) data 0.000 (0.004) loss 1.1063 (1.1706) teacher_loss 0.3222 (0.3884) loss_zs_kd 0.0099 (0.0143) loss_oracle 0.4490 (0.4259) kd_loss 0.5547 (0.5622) acc 87.5000 (84.8438) gate/entropy 0.9773 (0.9773) gate/usage_max 0.5741 (0.5742) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1703) teacher/entropy 0.0003 (0.0273) teacher/usage_max 1.0000 (0.9651) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.4714 (0.4470) nleep/row_max_mean 1523.4917 (1515.6012) nleep/row_max_std 30.7892 (59.6151) nleep/row_min_mean 1491.8823 (1487.6537) lr 9.3721e-04 eta 0:05:58
epoch [28/50] batch [140/160] time 0.092 (0.100) data 0.000 (0.003) loss 1.1459 (1.1760) teacher_loss 0.3813 (0.3931) loss_zs_kd 0.0199 (0.0146) loss_oracle 0.4209 (0.4265) kd_loss 0.5442 (0.5624) acc 84.3750 (84.8884) gate/entropy 0.9772 (0.9773) gate/usage_max 0.5742 (0.5742) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1703) teacher/entropy 0.0142 (0.0272) teacher/usage_max 0.9963 (0.9650) teacher/usage_min 0.0004 (0.0039) teacher/usage_std 0.4688 (0.4469) nleep/row_max_mean 1518.3384 (1514.9779) nleep/row_max_std 56.4874 (61.3469) nleep/row_min_mean 1491.0957 (1487.1518) lr 9.3721e-04 eta 0:05:54
epoch [28/50] batch [160/160] time 0.084 (0.098) data 0.000 (0.003) loss 1.2610 (1.1819) teacher_loss 0.4682 (0.3993) loss_zs_kd 0.0101 (0.0149) loss_oracle 0.4009 (0.4256) kd_loss 0.5873 (0.5623) acc 81.2500 (84.6484) gate/entropy 0.9773 (0.9773) gate/usage_max 0.5742 (0.5742) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1703) teacher/entropy 0.0255 (0.0266) teacher/usage_max 0.9414 (0.9656) teacher/usage_min 0.0005 (0.0038) teacher/usage_std 0.4306 (0.4473) nleep/row_max_mean 1502.3799 (1514.8523) nleep/row_max_std 76.1366 (62.0620) nleep/row_min_mean 1475.9071 (1487.0333) lr 8.7467e-04 eta 0:05:46
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,852
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,996
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 89.6%
******* Domain p best val acc:      84.2%, epoch: 25 *******
******* Domain p best val test acc: 89.0%, epoch: 25 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [29/50] batch [20/160] time 0.073 (0.115) data 0.000 (0.017) loss 1.1414 (1.1460) teacher_loss 0.4022 (0.3667) loss_zs_kd 0.0221 (0.0150) loss_oracle 0.3760 (0.4174) kd_loss 0.5401 (0.5631) acc 84.3750 (84.2188) gate/entropy 0.9772 (0.9772) gate/usage_max 0.5742 (0.5742) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1703) teacher/entropy 0.0409 (0.0232) teacher/usage_max 0.9734 (0.9682) teacher/usage_min 0.0039 (0.0032) teacher/usage_std 0.4527 (0.4492) nleep/row_max_mean 1519.8750 (1518.1986) nleep/row_max_std 56.8159 (57.0473) nleep/row_min_mean 1494.0413 (1489.8820) lr 8.7467e-04 eta 0:06:43
epoch [29/50] batch [40/160] time 0.096 (0.105) data 0.000 (0.009) loss 1.1153 (1.1762) teacher_loss 0.3813 (0.3949) loss_zs_kd 0.0213 (0.0157) loss_oracle 0.4018 (0.4173) kd_loss 0.5225 (0.5649) acc 84.3750 (84.6094) gate/entropy 0.9773 (0.9772) gate/usage_max 0.5741 (0.5742) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1703) teacher/entropy 0.0473 (0.0243) teacher/usage_max 0.9850 (0.9653) teacher/usage_min 0.0065 (0.0043) teacher/usage_std 0.4608 (0.4471) nleep/row_max_mean 1510.4829 (1518.3984) nleep/row_max_std 81.1986 (58.5782) nleep/row_min_mean 1481.1069 (1490.0036) lr 8.7467e-04 eta 0:06:06
epoch [29/50] batch [60/160] time 0.084 (0.099) data 0.001 (0.006) loss 1.2485 (1.1739) teacher_loss 0.4788 (0.3968) loss_zs_kd 0.0215 (0.0149) loss_oracle 0.4517 (0.4142) kd_loss 0.5331 (0.5625) acc 78.1250 (84.2708) gate/entropy 0.9772 (0.9772) gate/usage_max 0.5742 (0.5742) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1703) teacher/entropy 0.0307 (0.0224) teacher/usage_max 0.9909 (0.9696) teacher/usage_min 0.0031 (0.0043) teacher/usage_std 0.4650 (0.4501) nleep/row_max_mean 1500.0295 (1517.7252) nleep/row_max_std 87.2057 (60.2490) nleep/row_min_mean 1473.8464 (1489.2851) lr 8.7467e-04 eta 0:05:42
epoch [29/50] batch [80/160] time 0.095 (0.097) data 0.000 (0.004) loss 1.1123 (1.1680) teacher_loss 0.3450 (0.3947) loss_zs_kd 0.0182 (0.0145) loss_oracle 0.4141 (0.4120) kd_loss 0.5512 (0.5601) acc 87.5000 (84.4922) gate/entropy 0.9772 (0.9772) gate/usage_max 0.5742 (0.5742) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1703 (0.1703) teacher/entropy 0.0043 (0.0228) teacher/usage_max 0.9992 (0.9716) teacher/usage_min 0.0003 (0.0046) teacher/usage_std 0.4709 (0.4515) nleep/row_max_mean 1511.6184 (1516.3596) nleep/row_max_std 60.5233 (61.7253) nleep/row_min_mean 1482.7375 (1487.9838) lr 8.7467e-04 eta 0:05:35
epoch [29/50] batch [100/160] time 0.099 (0.097) data 0.000 (0.004) loss 1.1202 (1.1724) teacher_loss 0.3795 (0.3982) loss_zs_kd 0.0122 (0.0147) loss_oracle 0.4053 (0.4133) kd_loss 0.5320 (0.5603) acc 78.1250 (84.4375) gate/entropy 0.9772 (0.9772) gate/usage_max 0.5743 (0.5742) gate/usage_min 0.2127 (0.2128) gate/usage_std 0.1704 (0.1703) teacher/entropy 0.0422 (0.0240) teacher/usage_max 0.9803 (0.9702) teacher/usage_min 0.0014 (0.0045) teacher/usage_std 0.4575 (0.4505) nleep/row_max_mean 1499.6981 (1515.6801) nleep/row_max_std 85.9687 (62.1954) nleep/row_min_mean 1470.0470 (1487.3762) lr 8.7467e-04 eta 0:05:30
epoch [29/50] batch [120/160] time 0.101 (0.097) data 0.000 (0.003) loss 1.2412 (1.1785) teacher_loss 0.4695 (0.4035) loss_zs_kd 0.0246 (0.0148) loss_oracle 0.4235 (0.4153) kd_loss 0.5476 (0.5599) acc 75.0000 (84.2448) gate/entropy 0.9772 (0.9772) gate/usage_max 0.5743 (0.5742) gate/usage_min 0.2127 (0.2128) gate/usage_std 0.1704 (0.1703) teacher/entropy 0.0280 (0.0233) teacher/usage_max 0.9788 (0.9713) teacher/usage_min 0.0012 (0.0041) teacher/usage_std 0.4565 (0.4513) nleep/row_max_mean 1502.8110 (1515.1894) nleep/row_max_std 74.3673 (63.4953) nleep/row_min_mean 1474.1709 (1486.8767) lr 8.7467e-04 eta 0:05:28
epoch [29/50] batch [140/160] time 0.091 (0.096) data 0.000 (0.003) loss 1.1796 (1.1786) teacher_loss 0.4197 (0.4035) loss_zs_kd 0.0027 (0.0144) loss_oracle 0.4169 (0.4175) kd_loss 0.5502 (0.5592) acc 78.1250 (84.2857) gate/entropy 0.9772 (0.9772) gate/usage_max 0.5743 (0.5742) gate/usage_min 0.2127 (0.2128) gate/usage_std 0.1704 (0.1703) teacher/entropy 0.0058 (0.0234) teacher/usage_max 0.9987 (0.9719) teacher/usage_min 0.0001 (0.0041) teacher/usage_std 0.4705 (0.4517) nleep/row_max_mean 1531.2690 (1514.9720) nleep/row_max_std 26.9976 (63.1910) nleep/row_min_mean 1500.8049 (1486.5584) lr 8.7467e-04 eta 0:05:24
epoch [29/50] batch [160/160] time 0.088 (0.095) data 0.000 (0.002) loss 1.3551 (1.1788) teacher_loss 0.5524 (0.4025) loss_zs_kd 0.0177 (0.0149) loss_oracle 0.4512 (0.4195) kd_loss 0.5682 (0.5591) acc 78.1250 (84.5117) gate/entropy 0.9772 (0.9772) gate/usage_max 0.5743 (0.5742) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.1704 (0.1703) teacher/entropy 0.0158 (0.0232) teacher/usage_max 0.9704 (0.9721) teacher/usage_min 0.0014 (0.0042) teacher/usage_std 0.4506 (0.4518) nleep/row_max_mean 1514.7888 (1514.6314) nleep/row_max_std 61.2482 (63.5847) nleep/row_min_mean 1486.3500 (1486.1110) lr 8.1262e-04 eta 0:05:20
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,860
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,995
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 89.5%
******* Domain p best val acc:      84.3%, epoch: 29 *******
******* Domain p best val test acc: 88.7%, epoch: 29 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [30/50] batch [20/160] time 0.085 (0.107) data 0.000 (0.017) loss 1.2394 (1.2332) teacher_loss 0.4677 (0.4582) loss_zs_kd 0.0164 (0.0148) loss_oracle 0.4180 (0.4265) kd_loss 0.5545 (0.5544) acc 84.3750 (80.9375) gate/entropy 0.9771 (0.9771) gate/usage_max 0.5743 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0001 (0.0176) teacher/usage_max 1.0000 (0.9824) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.4714 (0.4590) nleep/row_max_mean 1527.9326 (1516.0041) nleep/row_max_std 23.6805 (56.6683) nleep/row_min_mean 1498.1344 (1485.7893) lr 8.1262e-04 eta 0:05:57
epoch [30/50] batch [40/160] time 0.095 (0.097) data 0.000 (0.008) loss 1.0042 (1.2251) teacher_loss 0.2545 (0.4483) loss_zs_kd 0.0106 (0.0147) loss_oracle 0.4195 (0.4256) kd_loss 0.5347 (0.5567) acc 90.6250 (81.7188) gate/entropy 0.9771 (0.9771) gate/usage_max 0.5743 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0356 (0.0200) teacher/usage_max 0.9842 (0.9778) teacher/usage_min 0.0051 (0.0042) teacher/usage_std 0.4602 (0.4558) nleep/row_max_mean 1517.7576 (1515.0508) nleep/row_max_std 70.2488 (60.4105) nleep/row_min_mean 1486.3708 (1484.9378) lr 8.1262e-04 eta 0:05:22
epoch [30/50] batch [60/160] time 0.119 (0.096) data 0.000 (0.006) loss 1.0925 (1.1960) teacher_loss 0.2485 (0.4200) loss_zs_kd 0.0176 (0.0137) loss_oracle 0.4676 (0.4250) kd_loss 0.6013 (0.5566) acc 90.6250 (83.6458) gate/entropy 0.9771 (0.9772) gate/usage_max 0.5744 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0133 (0.0231) teacher/usage_max 0.9394 (0.9747) teacher/usage_min 0.0287 (0.0044) teacher/usage_std 0.4286 (0.4536) nleep/row_max_mean 1517.3247 (1514.3329) nleep/row_max_std 78.2201 (61.8838) nleep/row_min_mean 1485.5830 (1483.9623) lr 8.1262e-04 eta 0:05:17
epoch [30/50] batch [80/160] time 0.095 (0.097) data 0.000 (0.004) loss 1.1224 (1.1906) teacher_loss 0.3258 (0.4162) loss_zs_kd 0.0063 (0.0131) loss_oracle 0.4820 (0.4269) kd_loss 0.5524 (0.5544) acc 84.3750 (84.0625) gate/entropy 0.9772 (0.9771) gate/usage_max 0.5743 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0027 (0.0249) teacher/usage_max 0.9995 (0.9751) teacher/usage_min 0.0002 (0.0049) teacher/usage_std 0.4711 (0.4539) nleep/row_max_mean 1519.8177 (1514.3429) nleep/row_max_std 59.7832 (61.7704) nleep/row_min_mean 1484.8899 (1483.5607) lr 8.1262e-04 eta 0:05:16
epoch [30/50] batch [100/160] time 0.096 (0.096) data 0.000 (0.003) loss 1.2369 (1.1888) teacher_loss 0.4683 (0.4151) loss_zs_kd 0.0140 (0.0132) loss_oracle 0.4239 (0.4250) kd_loss 0.5496 (0.5545) acc 78.1250 (83.9375) gate/entropy 0.9772 (0.9771) gate/usage_max 0.5743 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0061 (0.0245) teacher/usage_max 0.9989 (0.9754) teacher/usage_min 0.0002 (0.0048) teacher/usage_std 0.4706 (0.4541) nleep/row_max_mean 1526.2321 (1514.6142) nleep/row_max_std 27.6707 (61.7809) nleep/row_min_mean 1492.9333 (1483.6152) lr 8.1262e-04 eta 0:05:14
epoch [30/50] batch [120/160] time 0.095 (0.096) data 0.000 (0.003) loss 1.2336 (1.1896) teacher_loss 0.4573 (0.4164) loss_zs_kd 0.0080 (0.0131) loss_oracle 0.4367 (0.4260) kd_loss 0.5539 (0.5537) acc 84.3750 (84.0104) gate/entropy 0.9772 (0.9771) gate/usage_max 0.5743 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0008 (0.0241) teacher/usage_max 0.9999 (0.9766) teacher/usage_min 0.0000 (0.0046) teacher/usage_std 0.4713 (0.4549) nleep/row_max_mean 1513.2400 (1515.4078) nleep/row_max_std 67.0788 (60.9881) nleep/row_min_mean 1477.9395 (1484.0085) lr 8.1262e-04 eta 0:05:11
epoch [30/50] batch [140/160] time 0.096 (0.096) data 0.000 (0.003) loss 1.4070 (1.1899) teacher_loss 0.6665 (0.4167) loss_zs_kd 0.0226 (0.0128) loss_oracle 0.4008 (0.4262) kd_loss 0.5288 (0.5536) acc 75.0000 (84.2634) gate/entropy 0.9771 (0.9771) gate/usage_max 0.5743 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0401 (0.0239) teacher/usage_max 0.9856 (0.9769) teacher/usage_min 0.0008 (0.0044) teacher/usage_std 0.4612 (0.4551) nleep/row_max_mean 1506.4460 (1515.3987) nleep/row_max_std 60.6106 (61.3577) nleep/row_min_mean 1473.7788 (1483.8405) lr 8.1262e-04 eta 0:05:08
epoch [30/50] batch [160/160] time 0.084 (0.095) data 0.000 (0.002) loss 1.0746 (1.1867) teacher_loss 0.2524 (0.4134) loss_zs_kd 0.0139 (0.0131) loss_oracle 0.4705 (0.4262) kd_loss 0.5800 (0.5537) acc 93.7500 (84.4531) gate/entropy 0.9771 (0.9771) gate/usage_max 0.5743 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0277 (0.0232) teacher/usage_max 0.9464 (0.9775) teacher/usage_min 0.0016 (0.0043) teacher/usage_std 0.4340 (0.4556) nleep/row_max_mean 1518.4972 (1515.2744) nleep/row_max_std 54.6593 (61.7949) nleep/row_min_mean 1483.8030 (1483.5744) lr 7.5131e-04 eta 0:05:03
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,857
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,008
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 89.9%
******* Domain p best val acc:      84.3%, epoch: 29 *******
******* Domain p best val test acc: 88.7%, epoch: 29 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [31/50] batch [20/160] time 0.077 (0.099) data 0.000 (0.016) loss 1.0358 (1.1688) teacher_loss 0.2831 (0.3960) loss_zs_kd 0.0096 (0.0142) loss_oracle 0.4164 (0.4191) kd_loss 0.5397 (0.5561) acc 93.7500 (85.1562) gate/entropy 0.9772 (0.9771) gate/usage_max 0.5743 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0469 (0.0185) teacher/usage_max 0.9678 (0.9798) teacher/usage_min 0.0005 (0.0010) teacher/usage_std 0.4488 (0.4572) nleep/row_max_mean 1499.9248 (1522.6306) nleep/row_max_std 66.4488 (51.3980) nleep/row_min_mean 1470.3685 (1489.3741) lr 7.5131e-04 eta 0:05:15
epoch [31/50] batch [40/160] time 0.085 (0.094) data 0.000 (0.008) loss 1.1282 (1.1713) teacher_loss 0.3760 (0.4017) loss_zs_kd 0.0148 (0.0135) loss_oracle 0.4088 (0.4205) kd_loss 0.5403 (0.5526) acc 87.5000 (85.0781) gate/entropy 0.9771 (0.9771) gate/usage_max 0.5744 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0356 (0.0216) teacher/usage_max 0.9784 (0.9802) teacher/usage_min 0.0097 (0.0025) teacher/usage_std 0.4561 (0.4575) nleep/row_max_mean 1512.3359 (1518.3521) nleep/row_max_std 86.8357 (59.4580) nleep/row_min_mean 1479.1995 (1485.7396) lr 7.5131e-04 eta 0:04:57
epoch [31/50] batch [60/160] time 0.088 (0.091) data 0.001 (0.006) loss 1.1797 (1.1791) teacher_loss 0.3994 (0.4061) loss_zs_kd 0.0105 (0.0132) loss_oracle 0.3943 (0.4236) kd_loss 0.5779 (0.5546) acc 87.5000 (84.7396) gate/entropy 0.9771 (0.9771) gate/usage_max 0.5743 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0075 (0.0218) teacher/usage_max 0.9689 (0.9780) teacher/usage_min 0.0014 (0.0026) teacher/usage_std 0.4496 (0.4560) nleep/row_max_mean 1524.4128 (1517.3040) nleep/row_max_std 49.5370 (59.8240) nleep/row_min_mean 1490.9380 (1484.8617) lr 7.5131e-04 eta 0:04:44
epoch [31/50] batch [80/160] time 0.145 (0.092) data 0.001 (0.004) loss 1.0178 (1.1635) teacher_loss 0.2499 (0.3906) loss_zs_kd 0.0188 (0.0139) loss_oracle 0.4288 (0.4229) kd_loss 0.5441 (0.5545) acc 96.8750 (85.1562) gate/entropy 0.9771 (0.9771) gate/usage_max 0.5743 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0171 (0.0201) teacher/usage_max 0.9933 (0.9798) teacher/usage_min 0.0001 (0.0022) teacher/usage_std 0.4667 (0.4572) nleep/row_max_mean 1512.2562 (1517.5365) nleep/row_max_std 70.4635 (60.0186) nleep/row_min_mean 1479.3770 (1485.2426) lr 7.5131e-04 eta 0:04:48
epoch [31/50] batch [100/160] time 0.092 (0.095) data 0.000 (0.004) loss 1.4160 (1.1710) teacher_loss 0.5603 (0.3963) loss_zs_kd 0.0241 (0.0141) loss_oracle 0.4849 (0.4250) kd_loss 0.6012 (0.5552) acc 78.1250 (84.9688) gate/entropy 0.9771 (0.9771) gate/usage_max 0.5744 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0149 (0.0198) teacher/usage_max 0.9379 (0.9794) teacher/usage_min 0.0309 (0.0028) teacher/usage_std 0.4275 (0.4569) nleep/row_max_mean 1516.2195 (1516.6614) nleep/row_max_std 53.1887 (61.7739) nleep/row_min_mean 1482.7386 (1484.6877) lr 7.5131e-04 eta 0:04:53
epoch [31/50] batch [120/160] time 0.105 (0.095) data 0.000 (0.003) loss 1.3417 (1.1681) teacher_loss 0.5793 (0.3948) loss_zs_kd 0.0099 (0.0136) loss_oracle 0.4228 (0.4256) kd_loss 0.5461 (0.5537) acc 81.2500 (85.0260) gate/entropy 0.9771 (0.9771) gate/usage_max 0.5744 (0.5743) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0390 (0.0199) teacher/usage_max 0.9692 (0.9807) teacher/usage_min 0.0043 (0.0027) teacher/usage_std 0.4497 (0.4579) nleep/row_max_mean 1514.4497 (1516.1413) nleep/row_max_std 71.7281 (62.8716) nleep/row_min_mean 1482.6569 (1484.3011) lr 7.5131e-04 eta 0:04:53
epoch [31/50] batch [140/160] time 0.091 (0.096) data 0.000 (0.003) loss 1.1395 (1.1735) teacher_loss 0.3928 (0.4010) loss_zs_kd 0.0050 (0.0133) loss_oracle 0.3975 (0.4255) kd_loss 0.5455 (0.5531) acc 81.2500 (84.8661) gate/entropy 0.9771 (0.9771) gate/usage_max 0.5743 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0237 (0.0198) teacher/usage_max 0.9853 (0.9814) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.4610 (0.4584) nleep/row_max_mean 1526.2305 (1516.2940) nleep/row_max_std 24.2254 (62.2252) nleep/row_min_mean 1494.2737 (1484.5093) lr 7.5131e-04 eta 0:04:52
epoch [31/50] batch [160/160] time 0.086 (0.095) data 0.000 (0.002) loss 1.0253 (1.1736) teacher_loss 0.2686 (0.4016) loss_zs_kd 0.0102 (0.0132) loss_oracle 0.4267 (0.4270) kd_loss 0.5382 (0.5520) acc 87.5000 (84.8633) gate/entropy 0.9771 (0.9771) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0321 (0.0207) teacher/usage_max 0.9841 (0.9817) teacher/usage_min 0.0056 (0.0029) teacher/usage_std 0.4602 (0.4585) nleep/row_max_mean 1526.5016 (1515.8665) nleep/row_max_std 49.6278 (62.0168) nleep/row_min_mean 1494.9570 (1484.1360) lr 6.9098e-04 eta 0:04:48
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,854
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,005
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 89.8%
******* Domain p best val acc:      84.3%, epoch: 29 *******
******* Domain p best val test acc: 88.7%, epoch: 29 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [32/50] batch [20/160] time 0.097 (0.115) data 0.000 (0.017) loss 1.3094 (1.1847) teacher_loss 0.5341 (0.4067) loss_zs_kd 0.0157 (0.0127) loss_oracle 0.4508 (0.4414) kd_loss 0.5420 (0.5509) acc 81.2500 (84.5312) gate/entropy 0.9771 (0.9771) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1704) teacher/entropy 0.0535 (0.0200) teacher/usage_max 0.9587 (0.9835) teacher/usage_min 0.0120 (0.0027) teacher/usage_std 0.4422 (0.4598) nleep/row_max_mean 1483.5322 (1513.8411) nleep/row_max_std 94.5696 (62.0255) nleep/row_min_mean 1455.9915 (1483.0472) lr 6.9098e-04 eta 0:05:47
epoch [32/50] batch [40/160] time 0.101 (0.106) data 0.000 (0.008) loss 1.1685 (1.1923) teacher_loss 0.4208 (0.4194) loss_zs_kd 0.0125 (0.0126) loss_oracle 0.3739 (0.4338) kd_loss 0.5544 (0.5498) acc 87.5000 (84.0625) gate/entropy 0.9770 (0.9771) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1704) teacher/entropy 0.0000 (0.0219) teacher/usage_max 1.0000 (0.9827) teacher/usage_min 0.0000 (0.0022) teacher/usage_std 0.4714 (0.4592) nleep/row_max_mean 1530.8997 (1513.5336) nleep/row_max_std 34.1789 (64.4508) nleep/row_min_mean 1501.6293 (1483.2279) lr 6.9098e-04 eta 0:05:19
epoch [32/50] batch [60/160] time 0.089 (0.103) data 0.001 (0.006) loss 1.0662 (1.2117) teacher_loss 0.3137 (0.4387) loss_zs_kd 0.0102 (0.0124) loss_oracle 0.4043 (0.4295) kd_loss 0.5453 (0.5521) acc 84.3750 (82.9688) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0120 (0.0208) teacher/usage_max 0.9971 (0.9814) teacher/usage_min 0.0008 (0.0034) teacher/usage_std 0.4694 (0.4583) nleep/row_max_mean 1506.2263 (1512.8660) nleep/row_max_std 87.7052 (65.2542) nleep/row_min_mean 1478.4470 (1482.7333) lr 6.9098e-04 eta 0:05:06
epoch [32/50] batch [80/160] time 0.088 (0.101) data 0.000 (0.004) loss 1.0180 (1.2006) teacher_loss 0.2369 (0.4280) loss_zs_kd 0.0107 (0.0120) loss_oracle 0.4440 (0.4290) kd_loss 0.5537 (0.5521) acc 93.7500 (83.5938) gate/entropy 0.9771 (0.9770) gate/usage_max 0.5743 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1705) teacher/entropy 0.0009 (0.0211) teacher/usage_max 0.9999 (0.9811) teacher/usage_min 0.0000 (0.0034) teacher/usage_std 0.4713 (0.4581) nleep/row_max_mean 1507.8240 (1512.0590) nleep/row_max_std 59.8034 (65.6583) nleep/row_min_mean 1476.8445 (1481.9229) lr 6.9098e-04 eta 0:04:59
epoch [32/50] batch [100/160] time 0.096 (0.100) data 0.000 (0.004) loss 1.2320 (1.1979) teacher_loss 0.4419 (0.4250) loss_zs_kd 0.0105 (0.0121) loss_oracle 0.4214 (0.4294) kd_loss 0.5741 (0.5523) acc 84.3750 (83.8125) gate/entropy 0.9771 (0.9770) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1705) teacher/entropy 0.0142 (0.0200) teacher/usage_max 0.9659 (0.9820) teacher/usage_min 0.0010 (0.0030) teacher/usage_std 0.4475 (0.4588) nleep/row_max_mean 1486.4390 (1511.9292) nleep/row_max_std 89.0751 (65.0082) nleep/row_min_mean 1460.3064 (1481.7645) lr 6.9098e-04 eta 0:04:55
epoch [32/50] batch [120/160] time 0.081 (0.099) data 0.000 (0.003) loss 1.4188 (1.1990) teacher_loss 0.6470 (0.4244) loss_zs_kd 0.0214 (0.0125) loss_oracle 0.4263 (0.4321) kd_loss 0.5479 (0.5523) acc 87.5000 (84.0885) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0078 (0.0192) teacher/usage_max 0.9986 (0.9828) teacher/usage_min 0.0003 (0.0027) teacher/usage_std 0.4704 (0.4593) nleep/row_max_mean 1486.9952 (1511.7348) nleep/row_max_std 98.0525 (65.0201) nleep/row_min_mean 1456.4250 (1481.4474) lr 6.9098e-04 eta 0:04:50
epoch [32/50] batch [140/160] time 0.090 (0.098) data 0.000 (0.003) loss 1.2660 (1.1957) teacher_loss 0.4649 (0.4220) loss_zs_kd 0.0253 (0.0123) loss_oracle 0.4682 (0.4314) kd_loss 0.5544 (0.5518) acc 78.1250 (84.1518) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0000 (0.0194) teacher/usage_max 1.0000 (0.9831) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.4714 (0.4595) nleep/row_max_mean 1512.8219 (1512.1849) nleep/row_max_std 46.9373 (64.4267) nleep/row_min_mean 1479.5056 (1481.8392) lr 6.9098e-04 eta 0:04:42
epoch [32/50] batch [160/160] time 0.082 (0.096) data 0.000 (0.002) loss 1.2566 (1.1942) teacher_loss 0.4817 (0.4212) loss_zs_kd 0.0101 (0.0125) loss_oracle 0.4325 (0.4311) kd_loss 0.5536 (0.5512) acc 84.3750 (84.1797) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0009 (0.0194) teacher/usage_max 0.9999 (0.9837) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.4713 (0.4599) nleep/row_max_mean 1504.1886 (1512.4931) nleep/row_max_std 77.2102 (63.2057) nleep/row_min_mean 1471.8098 (1482.0726) lr 6.3188e-04 eta 0:04:35
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,862
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 85.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,006
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 89.8%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [33/50] batch [20/160] time 0.092 (0.116) data 0.000 (0.021) loss 1.0760 (1.1756) teacher_loss 0.3194 (0.4045) loss_zs_kd 0.0072 (0.0133) loss_oracle 0.4034 (0.4294) kd_loss 0.5513 (0.5497) acc 90.6250 (85.7812) gate/entropy 0.9771 (0.9770) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1704 (0.1705) teacher/entropy 0.0039 (0.0117) teacher/usage_max 0.9993 (0.9929) teacher/usage_min 0.0001 (0.0008) teacher/usage_std 0.4709 (0.4664) nleep/row_max_mean 1504.8647 (1513.2453) nleep/row_max_std 67.1382 (61.6826) nleep/row_min_mean 1474.0916 (1482.2709) lr 6.3188e-04 eta 0:05:31
epoch [33/50] batch [40/160] time 0.101 (0.105) data 0.000 (0.011) loss 1.1614 (1.1874) teacher_loss 0.4112 (0.4103) loss_zs_kd 0.0126 (0.0149) loss_oracle 0.4393 (0.4354) kd_loss 0.5242 (0.5519) acc 84.3750 (84.5312) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5745 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0572 (0.0155) teacher/usage_max 0.9727 (0.9868) teacher/usage_min 0.0074 (0.0027) teacher/usage_std 0.4521 (0.4621) nleep/row_max_mean 1492.9863 (1515.4731) nleep/row_max_std 102.4918 (59.5369) nleep/row_min_mean 1463.6663 (1484.4495) lr 6.3188e-04 eta 0:04:57
epoch [33/50] batch [60/160] time 0.098 (0.101) data 0.001 (0.007) loss 1.5634 (1.2040) teacher_loss 0.7891 (0.4238) loss_zs_kd 0.0287 (0.0144) loss_oracle 0.4247 (0.4392) kd_loss 0.5476 (0.5534) acc 65.6250 (83.6979) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0084 (0.0182) teacher/usage_max 0.9984 (0.9826) teacher/usage_min 0.0004 (0.0028) teacher/usage_std 0.4703 (0.4592) nleep/row_max_mean 1509.0336 (1514.3244) nleep/row_max_std 63.5282 (61.3137) nleep/row_min_mean 1479.0936 (1483.4155) lr 6.3188e-04 eta 0:04:45
epoch [33/50] batch [80/160] time 0.091 (0.099) data 0.000 (0.006) loss 1.0465 (1.1951) teacher_loss 0.2923 (0.4165) loss_zs_kd 0.0024 (0.0135) loss_oracle 0.4147 (0.4381) kd_loss 0.5456 (0.5527) acc 81.2500 (84.0625) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0217 (0.0203) teacher/usage_max 0.9870 (0.9812) teacher/usage_min 0.0001 (0.0028) teacher/usage_std 0.4622 (0.4582) nleep/row_max_mean 1524.4653 (1514.2496) nleep/row_max_std 46.8733 (61.4435) nleep/row_min_mean 1491.7874 (1483.3841) lr 6.3188e-04 eta 0:04:38
epoch [33/50] batch [100/160] time 0.100 (0.100) data 0.000 (0.004) loss 1.1489 (1.1897) teacher_loss 0.3896 (0.4121) loss_zs_kd 0.0050 (0.0135) loss_oracle 0.4136 (0.4369) kd_loss 0.5500 (0.5524) acc 78.1250 (83.9062) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0054 (0.0205) teacher/usage_max 0.9990 (0.9813) teacher/usage_min 0.0004 (0.0029) teacher/usage_std 0.4707 (0.4582) nleep/row_max_mean 1515.7582 (1513.7269) nleep/row_max_std 60.3839 (62.9769) nleep/row_min_mean 1483.8442 (1482.8039) lr 6.3188e-04 eta 0:04:36
epoch [33/50] batch [120/160] time 0.101 (0.099) data 0.000 (0.004) loss 1.1431 (1.1930) teacher_loss 0.3839 (0.4174) loss_zs_kd 0.0229 (0.0135) loss_oracle 0.3945 (0.4339) kd_loss 0.5505 (0.5519) acc 78.1250 (83.6458) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0459 (0.0211) teacher/usage_max 0.9576 (0.9812) teacher/usage_min 0.0011 (0.0027) teacher/usage_std 0.4418 (0.4582) nleep/row_max_mean 1498.9849 (1513.9182) nleep/row_max_std 78.2947 (62.7227) nleep/row_min_mean 1472.9136 (1483.0279) lr 6.3188e-04 eta 0:04:32
epoch [33/50] batch [140/160] time 0.097 (0.098) data 0.000 (0.003) loss 1.2433 (1.1905) teacher_loss 0.4481 (0.4163) loss_zs_kd 0.0040 (0.0133) loss_oracle 0.4256 (0.4311) kd_loss 0.5804 (0.5519) acc 84.3750 (83.7054) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5745 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0453 (0.0202) teacher/usage_max 0.9280 (0.9821) teacher/usage_min 0.0205 (0.0026) teacher/usage_std 0.4207 (0.4588) nleep/row_max_mean 1512.6047 (1514.1513) nleep/row_max_std 71.3015 (63.4147) nleep/row_min_mean 1482.8296 (1483.2765) lr 6.3188e-04 eta 0:04:29
epoch [33/50] batch [160/160] time 0.080 (0.097) data 0.000 (0.003) loss 1.0143 (1.1845) teacher_loss 0.2734 (0.4108) loss_zs_kd 0.0210 (0.0134) loss_oracle 0.3834 (0.4313) kd_loss 0.5387 (0.5513) acc 84.3750 (83.8672) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5744 (0.5744) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0203 (0.0202) teacher/usage_max 0.9954 (0.9827) teacher/usage_min 0.0010 (0.0025) teacher/usage_std 0.4681 (0.4593) nleep/row_max_mean 1494.1818 (1514.0840) nleep/row_max_std 79.5455 (64.1127) nleep/row_min_mean 1464.2170 (1483.1714) lr 5.7422e-04 eta 0:04:23
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,859
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,008
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 89.9%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [34/50] batch [20/160] time 0.082 (0.104) data 0.000 (0.018) loss 1.3109 (1.1867) teacher_loss 0.5571 (0.4186) loss_zs_kd 0.0131 (0.0124) loss_oracle 0.4287 (0.4230) kd_loss 0.5328 (0.5505) acc 90.6250 (85.4688) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5744 (0.5745) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0384 (0.0211) teacher/usage_max 0.9830 (0.9826) teacher/usage_min 0.0003 (0.0020) teacher/usage_std 0.4594 (0.4591) nleep/row_max_mean 1504.6138 (1517.0385) nleep/row_max_std 80.2980 (61.6808) nleep/row_min_mean 1472.9620 (1485.7933) lr 5.7422e-04 eta 0:04:41
epoch [34/50] batch [40/160] time 0.086 (0.094) data 0.000 (0.009) loss 1.2762 (1.1874) teacher_loss 0.4977 (0.4194) loss_zs_kd 0.0170 (0.0131) loss_oracle 0.4526 (0.4210) kd_loss 0.5437 (0.5509) acc 87.5000 (85.3125) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0293 (0.0191) teacher/usage_max 0.9812 (0.9842) teacher/usage_min 0.0021 (0.0019) teacher/usage_std 0.4581 (0.4603) nleep/row_max_mean 1492.6111 (1517.4998) nleep/row_max_std 88.3469 (60.9251) nleep/row_min_mean 1463.4987 (1486.2146) lr 5.7422e-04 eta 0:04:13
epoch [34/50] batch [60/160] time 0.089 (0.091) data 0.001 (0.006) loss 1.2359 (1.1944) teacher_loss 0.4591 (0.4260) loss_zs_kd 0.0181 (0.0131) loss_oracle 0.4557 (0.4249) kd_loss 0.5399 (0.5494) acc 87.5000 (83.9583) gate/entropy 0.9769 (0.9770) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0249 (0.0186) teacher/usage_max 0.9894 (0.9863) teacher/usage_min 0.0014 (0.0021) teacher/usage_std 0.4639 (0.4617) nleep/row_max_mean 1509.9294 (1517.1324) nleep/row_max_std 71.4569 (60.8519) nleep/row_min_mean 1477.1216 (1485.6819) lr 5.7422e-04 eta 0:04:02
epoch [34/50] batch [80/160] time 0.075 (0.090) data 0.000 (0.005) loss 1.1252 (1.1952) teacher_loss 0.3143 (0.4248) loss_zs_kd 0.0095 (0.0128) loss_oracle 0.4743 (0.4283) kd_loss 0.5690 (0.5498) acc 87.5000 (83.7891) gate/entropy 0.9769 (0.9770) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0169 (0.0183) teacher/usage_max 0.9681 (0.9861) teacher/usage_min 0.0022 (0.0021) teacher/usage_std 0.4490 (0.4616) nleep/row_max_mean 1494.5693 (1516.0740) nleep/row_max_std 92.7628 (61.7468) nleep/row_min_mean 1462.5336 (1484.4477) lr 5.7422e-04 eta 0:03:56
epoch [34/50] batch [100/160] time 0.088 (0.089) data 0.000 (0.004) loss 0.9829 (1.1886) teacher_loss 0.1984 (0.4183) loss_zs_kd 0.0244 (0.0130) loss_oracle 0.4132 (0.4295) kd_loss 0.5657 (0.5491) acc 93.7500 (83.9375) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5744 (0.5745) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0183 (0.0197) teacher/usage_max 0.9701 (0.9854) teacher/usage_min 0.0020 (0.0022) teacher/usage_std 0.4504 (0.4611) nleep/row_max_mean 1519.0895 (1514.8652) nleep/row_max_std 60.2848 (63.5297) nleep/row_min_mean 1488.5884 (1483.3026) lr 5.7422e-04 eta 0:03:52
epoch [34/50] batch [120/160] time 0.093 (0.090) data 0.000 (0.003) loss 1.1312 (1.1912) teacher_loss 0.3447 (0.4212) loss_zs_kd 0.0242 (0.0132) loss_oracle 0.4414 (0.4292) kd_loss 0.5537 (0.5488) acc 90.6250 (83.8021) gate/entropy 0.9769 (0.9770) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2126 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0006 (0.0198) teacher/usage_max 0.9999 (0.9856) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.4713 (0.4613) nleep/row_max_mean 1529.2666 (1515.0074) nleep/row_max_std 48.0469 (63.3794) nleep/row_min_mean 1495.6372 (1483.4354) lr 5.7422e-04 eta 0:03:53
epoch [34/50] batch [140/160] time 0.096 (0.093) data 0.000 (0.003) loss 0.9942 (1.1816) teacher_loss 0.2570 (0.4122) loss_zs_kd 0.0085 (0.0129) loss_oracle 0.4001 (0.4292) kd_loss 0.5329 (0.5483) acc 90.6250 (84.0179) gate/entropy 0.9770 (0.9770) gate/usage_max 0.5744 (0.5745) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0368 (0.0198) teacher/usage_max 0.9846 (0.9861) teacher/usage_min 0.0048 (0.0021) teacher/usage_std 0.4605 (0.4616) nleep/row_max_mean 1502.2697 (1514.8942) nleep/row_max_std 77.2314 (63.0510) nleep/row_min_mean 1472.3544 (1483.3385) lr 5.7422e-04 eta 0:04:00
epoch [34/50] batch [160/160] time 0.081 (0.092) data 0.000 (0.003) loss 1.2171 (1.1794) teacher_loss 0.4479 (0.4092) loss_zs_kd 0.0133 (0.0128) loss_oracle 0.4287 (0.4299) kd_loss 0.5482 (0.5489) acc 81.2500 (84.1406) gate/entropy 0.9769 (0.9770) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2126 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0075 (0.0194) teacher/usage_max 0.9985 (0.9859) teacher/usage_min 0.0007 (0.0024) teacher/usage_std 0.4703 (0.4615) nleep/row_max_mean 1514.5188 (1514.8053) nleep/row_max_std 69.3281 (63.0901) nleep/row_min_mean 1484.3018 (1483.2715) lr 5.1825e-04 eta 0:03:55
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,861
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,996
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 89.5%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [35/50] batch [20/160] time 0.096 (0.115) data 0.000 (0.015) loss 1.1375 (1.1935) teacher_loss 0.3593 (0.4200) loss_zs_kd 0.0114 (0.0127) loss_oracle 0.4384 (0.4322) kd_loss 0.5533 (0.5510) acc 87.5000 (84.8438) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0011 (0.0232) teacher/usage_max 0.9998 (0.9799) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.4713 (0.4573) nleep/row_max_mean 1523.6729 (1511.4542) nleep/row_max_std 60.6763 (64.4963) nleep/row_min_mean 1490.5468 (1480.5224) lr 5.1825e-04 eta 0:04:51
epoch [35/50] batch [40/160] time 0.089 (0.105) data 0.000 (0.007) loss 1.1030 (1.1773) teacher_loss 0.3314 (0.4045) loss_zs_kd 0.0054 (0.0133) loss_oracle 0.4334 (0.4290) kd_loss 0.5522 (0.5516) acc 93.7500 (85.1562) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2126 (0.2127) gate/usage_std 0.1706 (0.1705) teacher/entropy 0.0024 (0.0212) teacher/usage_max 0.9996 (0.9813) teacher/usage_min 0.0001 (0.0024) teacher/usage_std 0.4711 (0.4582) nleep/row_max_mean 1519.0500 (1515.5828) nleep/row_max_std 53.4179 (59.1899) nleep/row_min_mean 1485.1631 (1484.0812) lr 5.1825e-04 eta 0:04:23
epoch [35/50] batch [60/160] time 0.101 (0.102) data 0.001 (0.005) loss 1.1540 (1.1627) teacher_loss 0.4008 (0.3913) loss_zs_kd 0.0114 (0.0128) loss_oracle 0.4148 (0.4270) kd_loss 0.5401 (0.5515) acc 90.6250 (85.4688) gate/entropy 0.9770 (0.9769) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0207 (0.0198) teacher/usage_max 0.9934 (0.9828) teacher/usage_min 0.0029 (0.0032) teacher/usage_std 0.4667 (0.4593) nleep/row_max_mean 1519.9329 (1515.0977) nleep/row_max_std 43.8262 (60.2666) nleep/row_min_mean 1489.8022 (1483.8586) lr 5.1825e-04 eta 0:04:13
epoch [35/50] batch [80/160] time 0.093 (0.099) data 0.000 (0.004) loss 1.0096 (1.1639) teacher_loss 0.2419 (0.3935) loss_zs_kd 0.0115 (0.0126) loss_oracle 0.4211 (0.4262) kd_loss 0.5514 (0.5510) acc 90.6250 (85.1562) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0033 (0.0187) teacher/usage_max 0.9995 (0.9844) teacher/usage_min 0.0001 (0.0026) teacher/usage_std 0.4710 (0.4604) nleep/row_max_mean 1513.6377 (1516.2279) nleep/row_max_std 66.9229 (59.3303) nleep/row_min_mean 1481.6707 (1484.8562) lr 5.1825e-04 eta 0:04:05
epoch [35/50] batch [100/160] time 0.093 (0.098) data 0.000 (0.003) loss 1.1413 (1.1764) teacher_loss 0.3784 (0.4045) loss_zs_kd 0.0057 (0.0126) loss_oracle 0.4408 (0.4283) kd_loss 0.5398 (0.5515) acc 84.3750 (84.5625) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2127 (0.2127) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0234 (0.0189) teacher/usage_max 0.9910 (0.9838) teacher/usage_min 0.0013 (0.0028) teacher/usage_std 0.4651 (0.4600) nleep/row_max_mean 1508.5769 (1515.9504) nleep/row_max_std 68.4261 (59.9566) nleep/row_min_mean 1480.0549 (1484.5982) lr 5.1825e-04 eta 0:04:01
epoch [35/50] batch [120/160] time 0.100 (0.098) data 0.000 (0.003) loss 1.2952 (1.1779) teacher_loss 0.5274 (0.4042) loss_zs_kd 0.0109 (0.0126) loss_oracle 0.4361 (0.4297) kd_loss 0.5443 (0.5525) acc 81.2500 (84.5573) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5745) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1705) teacher/entropy 0.0125 (0.0189) teacher/usage_max 0.9973 (0.9827) teacher/usage_min 0.0002 (0.0028) teacher/usage_std 0.4695 (0.4592) nleep/row_max_mean 1492.9808 (1515.9853) nleep/row_max_std 101.5424 (60.1714) nleep/row_min_mean 1462.5405 (1484.5602) lr 5.1825e-04 eta 0:03:59
epoch [35/50] batch [140/160] time 0.095 (0.098) data 0.000 (0.002) loss 1.0351 (1.1779) teacher_loss 0.2803 (0.4054) loss_zs_kd 0.0064 (0.0123) loss_oracle 0.3855 (0.4290) kd_loss 0.5588 (0.5519) acc 90.6250 (84.6205) gate/entropy 0.9770 (0.9769) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2127 (0.2126) gate/usage_std 0.1705 (0.1705) teacher/entropy 0.0259 (0.0195) teacher/usage_max 0.9694 (0.9827) teacher/usage_min 0.0042 (0.0027) teacher/usage_std 0.4498 (0.4592) nleep/row_max_mean 1516.2288 (1515.5036) nleep/row_max_std 61.9715 (61.4378) nleep/row_min_mean 1485.3134 (1484.1583) lr 5.1825e-04 eta 0:03:57
epoch [35/50] batch [160/160] time 0.092 (0.097) data 0.000 (0.002) loss 0.9534 (1.1785) teacher_loss 0.1886 (0.4061) loss_zs_kd 0.0030 (0.0122) loss_oracle 0.4163 (0.4290) kd_loss 0.5551 (0.5518) acc 96.8750 (84.4531) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5745) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1705) teacher/entropy 0.0631 (0.0199) teacher/usage_max 0.9356 (0.9824) teacher/usage_min 0.0165 (0.0029) teacher/usage_std 0.4261 (0.4590) nleep/row_max_mean 1507.0514 (1515.4497) nleep/row_max_std 85.0060 (61.4114) nleep/row_min_mean 1480.3140 (1484.1615) lr 4.6417e-04 eta 0:03:53
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,858
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,999
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 89.6%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [36/50] batch [20/160] time 0.097 (0.103) data 0.000 (0.017) loss 1.0612 (1.1993) teacher_loss 0.3020 (0.4279) loss_zs_kd 0.0102 (0.0131) loss_oracle 0.4475 (0.4279) kd_loss 0.5304 (0.5510) acc 87.5000 (83.9062) gate/entropy 0.9770 (0.9769) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2127 (0.2126) gate/usage_std 0.1705 (0.1706) teacher/entropy 0.0355 (0.0214) teacher/usage_max 0.9883 (0.9817) teacher/usage_min 0.0058 (0.0042) teacher/usage_std 0.4632 (0.4585) nleep/row_max_mean 1502.7510 (1512.7804) nleep/row_max_std 83.3297 (68.3814) nleep/row_min_mean 1471.4678 (1481.2138) lr 4.6417e-04 eta 0:04:05
epoch [36/50] batch [40/160] time 0.089 (0.095) data 0.000 (0.009) loss 1.1894 (1.1594) teacher_loss 0.4072 (0.3874) loss_zs_kd 0.0141 (0.0135) loss_oracle 0.4507 (0.4286) kd_loss 0.5497 (0.5510) acc 87.5000 (85.7031) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1705) teacher/entropy 0.0054 (0.0196) teacher/usage_max 0.9990 (0.9836) teacher/usage_min 0.0004 (0.0034) teacher/usage_std 0.4707 (0.4598) nleep/row_max_mean 1513.4147 (1513.6161) nleep/row_max_std 76.1006 (67.4287) nleep/row_min_mean 1480.4695 (1482.1708) lr 4.6417e-04 eta 0:03:44
epoch [36/50] batch [60/160] time 0.073 (0.097) data 0.000 (0.006) loss 1.3394 (1.1628) teacher_loss 0.5256 (0.3885) loss_zs_kd 0.0130 (0.0134) loss_oracle 0.4897 (0.4328) kd_loss 0.5625 (0.5512) acc 78.1250 (85.2083) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5745) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0658 (0.0193) teacher/usage_max 0.9253 (0.9835) teacher/usage_min 0.0250 (0.0031) teacher/usage_std 0.4187 (0.4598) nleep/row_max_mean 1506.4355 (1515.2524) nleep/row_max_std 71.0024 (63.8263) nleep/row_min_mean 1476.4780 (1483.5563) lr 4.6417e-04 eta 0:03:47
epoch [36/50] batch [80/160] time 0.095 (0.096) data 0.000 (0.004) loss 1.2160 (1.1546) teacher_loss 0.4020 (0.3816) loss_zs_kd 0.0169 (0.0133) loss_oracle 0.4283 (0.4310) kd_loss 0.5914 (0.5508) acc 81.2500 (85.3906) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0280 (0.0202) teacher/usage_max 0.9343 (0.9831) teacher/usage_min 0.0323 (0.0029) teacher/usage_std 0.4250 (0.4595) nleep/row_max_mean 1503.3607 (1515.1741) nleep/row_max_std 74.5869 (62.9950) nleep/row_min_mean 1475.0500 (1483.6365) lr 4.6417e-04 eta 0:03:41
epoch [36/50] batch [100/160] time 0.092 (0.097) data 0.000 (0.004) loss 1.1929 (1.1690) teacher_loss 0.3864 (0.3964) loss_zs_kd 0.0193 (0.0131) loss_oracle 0.4647 (0.4299) kd_loss 0.5644 (0.5511) acc 84.3750 (84.7812) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5745) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0207 (0.0194) teacher/usage_max 0.9688 (0.9836) teacher/usage_min 0.0001 (0.0025) teacher/usage_std 0.4495 (0.4599) nleep/row_max_mean 1507.1873 (1515.5536) nleep/row_max_std 75.6894 (61.6499) nleep/row_min_mean 1472.8319 (1484.0551) lr 4.6417e-04 eta 0:03:42
epoch [36/50] batch [120/160] time 0.098 (0.098) data 0.000 (0.003) loss 1.1391 (1.1800) teacher_loss 0.3577 (0.4090) loss_zs_kd 0.0168 (0.0132) loss_oracle 0.4343 (0.4271) kd_loss 0.5559 (0.5508) acc 87.5000 (84.3750) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0757 (0.0204) teacher/usage_max 0.9222 (0.9829) teacher/usage_min 0.0346 (0.0028) teacher/usage_std 0.4164 (0.4594) nleep/row_max_mean 1505.8403 (1514.5253) nleep/row_max_std 71.6132 (62.7191) nleep/row_min_mean 1475.9076 (1483.2899) lr 4.6417e-04 eta 0:03:43
epoch [36/50] batch [140/160] time 0.093 (0.099) data 0.000 (0.003) loss 0.9730 (1.1731) teacher_loss 0.2246 (0.4029) loss_zs_kd 0.0093 (0.0128) loss_oracle 0.3809 (0.4264) kd_loss 0.5534 (0.5506) acc 100.0000 (84.7321) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5745 (0.5745) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1705 (0.1706) teacher/entropy 0.0722 (0.0216) teacher/usage_max 0.9283 (0.9819) teacher/usage_min 0.0346 (0.0033) teacher/usage_std 0.4207 (0.4587) nleep/row_max_mean 1490.9426 (1514.4535) nleep/row_max_std 84.0629 (62.1678) nleep/row_min_mean 1464.2667 (1483.4236) lr 4.6417e-04 eta 0:03:43
epoch [36/50] batch [160/160] time 0.083 (0.097) data 0.000 (0.002) loss 1.0495 (1.1793) teacher_loss 0.2795 (0.4089) loss_zs_kd 0.0121 (0.0128) loss_oracle 0.4298 (0.4261) kd_loss 0.5490 (0.5508) acc 84.3750 (84.4531) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5745) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0068 (0.0231) teacher/usage_max 0.9983 (0.9801) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.4702 (0.4574) nleep/row_max_mean 1538.2062 (1513.5454) nleep/row_max_std 21.4817 (63.1581) nleep/row_min_mean 1505.2976 (1482.7726) lr 4.1221e-04 eta 0:03:38
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,859
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,996
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 89.5%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [37/50] batch [20/160] time 0.074 (0.100) data 0.000 (0.018) loss 1.2140 (1.1802) teacher_loss 0.4437 (0.4125) loss_zs_kd 0.0189 (0.0143) loss_oracle 0.4580 (0.4279) kd_loss 0.5319 (0.5466) acc 81.2500 (85.6250) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0473 (0.0422) teacher/usage_max 0.9748 (0.9652) teacher/usage_min 0.0083 (0.0066) teacher/usage_std 0.4536 (0.4469) nleep/row_max_mean 1517.6543 (1511.8459) nleep/row_max_std 42.8383 (66.9063) nleep/row_min_mean 1488.0386 (1482.1240) lr 4.1221e-04 eta 0:03:42
epoch [37/50] batch [40/160] time 0.104 (0.099) data 0.000 (0.009) loss 1.0642 (1.1915) teacher_loss 0.3230 (0.4150) loss_zs_kd 0.0123 (0.0130) loss_oracle 0.3790 (0.4275) kd_loss 0.5454 (0.5563) acc 84.3750 (85.1562) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5745 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1705 (0.1706) teacher/entropy 0.0111 (0.0339) teacher/usage_max 0.9977 (0.9637) teacher/usage_min 0.0002 (0.0069) teacher/usage_std 0.4698 (0.4459) nleep/row_max_mean 1528.6168 (1513.6036) nleep/row_max_std 23.2901 (62.7882) nleep/row_min_mean 1498.4637 (1483.9314) lr 4.1221e-04 eta 0:03:37
epoch [37/50] batch [60/160] time 0.095 (0.098) data 0.001 (0.006) loss 1.3674 (1.1884) teacher_loss 0.6069 (0.4171) loss_zs_kd 0.0198 (0.0127) loss_oracle 0.4134 (0.4226) kd_loss 0.5439 (0.5536) acc 71.8750 (85.0521) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0372 (0.0374) teacher/usage_max 0.9729 (0.9629) teacher/usage_min 0.0004 (0.0069) teacher/usage_std 0.4524 (0.4454) nleep/row_max_mean 1515.4875 (1513.2932) nleep/row_max_std 42.8488 (62.1820) nleep/row_min_mean 1488.3950 (1483.9923) lr 4.1221e-04 eta 0:03:32
epoch [37/50] batch [80/160] time 0.101 (0.097) data 0.000 (0.005) loss 1.1803 (1.1840) teacher_loss 0.3827 (0.4140) loss_zs_kd 0.0167 (0.0129) loss_oracle 0.4456 (0.4235) kd_loss 0.5665 (0.5518) acc 84.3750 (84.6484) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0249 (0.0369) teacher/usage_max 0.9626 (0.9653) teacher/usage_min 0.0036 (0.0062) teacher/usage_std 0.4451 (0.4470) nleep/row_max_mean 1512.7954 (1513.6331) nleep/row_max_std 62.1108 (61.7351) nleep/row_min_mean 1484.6538 (1484.4058) lr 4.1221e-04 eta 0:03:29
epoch [37/50] batch [100/160] time 0.091 (0.096) data 0.000 (0.004) loss 1.1127 (1.1857) teacher_loss 0.3606 (0.4179) loss_zs_kd 0.0069 (0.0128) loss_oracle 0.3744 (0.4215) kd_loss 0.5615 (0.5506) acc 87.5000 (84.4688) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0294 (0.0364) teacher/usage_max 0.9631 (0.9669) teacher/usage_min 0.0009 (0.0060) teacher/usage_std 0.4455 (0.4482) nleep/row_max_mean 1504.0005 (1512.7823) nleep/row_max_std 80.3478 (63.3436) nleep/row_min_mean 1477.8831 (1483.7815) lr 4.1221e-04 eta 0:03:24
epoch [37/50] batch [120/160] time 0.086 (0.094) data 0.000 (0.003) loss 1.0712 (1.1770) teacher_loss 0.3116 (0.4084) loss_zs_kd 0.0121 (0.0127) loss_oracle 0.4098 (0.4218) kd_loss 0.5487 (0.5513) acc 90.6250 (84.7396) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0068 (0.0346) teacher/usage_max 0.9986 (0.9680) teacher/usage_min 0.0004 (0.0056) teacher/usage_std 0.4704 (0.4490) nleep/row_max_mean 1520.8607 (1513.1156) nleep/row_max_std 48.2165 (62.9518) nleep/row_min_mean 1492.0410 (1484.1696) lr 4.1221e-04 eta 0:03:20
epoch [37/50] batch [140/160] time 0.072 (0.093) data 0.000 (0.003) loss 0.9860 (1.1760) teacher_loss 0.2304 (0.4058) loss_zs_kd 0.0087 (0.0127) loss_oracle 0.4097 (0.4234) kd_loss 0.5463 (0.5521) acc 96.8750 (84.9777) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5745 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0095 (0.0335) teacher/usage_max 0.9984 (0.9683) teacher/usage_min 0.0005 (0.0050) teacher/usage_std 0.4702 (0.4492) nleep/row_max_mean 1492.1172 (1513.1264) nleep/row_max_std 97.7165 (62.8813) nleep/row_min_mean 1465.3235 (1484.2412) lr 4.1221e-04 eta 0:03:15
epoch [37/50] batch [160/160] time 0.090 (0.092) data 0.000 (0.002) loss 1.1069 (1.1800) teacher_loss 0.3933 (0.4100) loss_zs_kd 0.0148 (0.0130) loss_oracle 0.3354 (0.4228) kd_loss 0.5385 (0.5522) acc 81.2500 (84.7461) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0201 (0.0333) teacher/usage_max 0.9955 (0.9684) teacher/usage_min 0.0021 (0.0051) teacher/usage_std 0.4682 (0.4492) nleep/row_max_mean 1516.0605 (1512.8245) nleep/row_max_std 73.1175 (63.3266) nleep/row_min_mean 1491.6708 (1484.0597) lr 3.6258e-04 eta 0:03:11
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,855
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,994
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 89.4%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [38/50] batch [20/160] time 0.092 (0.104) data 0.000 (0.014) loss 1.3344 (1.2071) teacher_loss 0.5952 (0.4346) loss_zs_kd 0.0048 (0.0160) loss_oracle 0.3957 (0.4336) kd_loss 0.5390 (0.5477) acc 81.2500 (84.6875) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0196 (0.0344) teacher/usage_max 0.9955 (0.9718) teacher/usage_min 0.0005 (0.0070) teacher/usage_std 0.4682 (0.4515) nleep/row_max_mean 1511.7277 (1512.5084) nleep/row_max_std 68.8429 (63.1807) nleep/row_min_mean 1483.0084 (1484.2861) lr 3.6258e-04 eta 0:03:33
epoch [38/50] batch [40/160] time 0.096 (0.098) data 0.000 (0.007) loss 1.2425 (1.1947) teacher_loss 0.4152 (0.4196) loss_zs_kd 0.0138 (0.0141) loss_oracle 0.4713 (0.4305) kd_loss 0.5847 (0.5528) acc 78.1250 (84.6094) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0006 (0.0357) teacher/usage_max 0.9687 (0.9655) teacher/usage_min 0.0000 (0.0083) teacher/usage_std 0.4494 (0.4471) nleep/row_max_mean 1529.3373 (1511.4042) nleep/row_max_std 27.4625 (66.1484) nleep/row_min_mean 1497.4822 (1483.2191) lr 3.6258e-04 eta 0:03:20
epoch [38/50] batch [60/160] time 0.075 (0.093) data 0.001 (0.005) loss 1.2628 (1.1908) teacher_loss 0.5185 (0.4171) loss_zs_kd 0.0272 (0.0136) loss_oracle 0.3807 (0.4308) kd_loss 0.5404 (0.5515) acc 87.5000 (85.0521) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0226 (0.0366) teacher/usage_max 0.9911 (0.9658) teacher/usage_min 0.0008 (0.0083) teacher/usage_std 0.4651 (0.4473) nleep/row_max_mean 1520.7994 (1511.7419) nleep/row_max_std 47.1761 (65.2993) nleep/row_min_mean 1495.3970 (1483.5805) lr 3.6258e-04 eta 0:03:07
epoch [38/50] batch [80/160] time 0.092 (0.091) data 0.000 (0.004) loss 1.0803 (1.1869) teacher_loss 0.2787 (0.4126) loss_zs_kd 0.0208 (0.0139) loss_oracle 0.4819 (0.4314) kd_loss 0.5503 (0.5515) acc 90.6250 (85.1172) gate/entropy 0.9768 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0047 (0.0354) teacher/usage_max 0.9991 (0.9669) teacher/usage_min 0.0003 (0.0074) teacher/usage_std 0.4708 (0.4482) nleep/row_max_mean 1527.0498 (1512.6257) nleep/row_max_std 47.4458 (64.2955) nleep/row_min_mean 1498.1740 (1484.5825) lr 3.6258e-04 eta 0:03:02
epoch [38/50] batch [100/160] time 0.078 (0.090) data 0.000 (0.003) loss 1.2697 (1.1807) teacher_loss 0.4745 (0.4056) loss_zs_kd 0.0186 (0.0137) loss_oracle 0.4710 (0.4312) kd_loss 0.5504 (0.5526) acc 84.3750 (85.2500) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0045 (0.0352) teacher/usage_max 0.9992 (0.9661) teacher/usage_min 0.0004 (0.0075) teacher/usage_std 0.4708 (0.4476) nleep/row_max_mean 1523.5123 (1512.9539) nleep/row_max_std 46.8005 (64.5351) nleep/row_min_mean 1494.3429 (1484.9432) lr 3.6258e-04 eta 0:02:58
epoch [38/50] batch [120/160] time 0.091 (0.089) data 0.000 (0.003) loss 1.0566 (1.1803) teacher_loss 0.2992 (0.4057) loss_zs_kd 0.0181 (0.0137) loss_oracle 0.4369 (0.4308) kd_loss 0.5299 (0.5523) acc 90.6250 (85.0260) gate/entropy 0.9768 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0396 (0.0355) teacher/usage_max 0.9843 (0.9661) teacher/usage_min 0.0015 (0.0073) teacher/usage_std 0.4604 (0.4475) nleep/row_max_mean 1504.6307 (1513.7056) nleep/row_max_std 80.8372 (63.8151) nleep/row_min_mean 1474.7639 (1485.6758) lr 3.6258e-04 eta 0:02:54
epoch [38/50] batch [140/160] time 0.074 (0.089) data 0.000 (0.002) loss 1.2634 (1.1742) teacher_loss 0.4834 (0.3996) loss_zs_kd 0.0084 (0.0137) loss_oracle 0.4563 (0.4300) kd_loss 0.5477 (0.5528) acc 75.0000 (84.9777) gate/entropy 0.9768 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0083 (0.0358) teacher/usage_max 0.9981 (0.9653) teacher/usage_min 0.0000 (0.0078) teacher/usage_std 0.4701 (0.4470) nleep/row_max_mean 1529.9148 (1514.4545) nleep/row_max_std 22.1165 (62.5456) nleep/row_min_mean 1498.2529 (1486.3661) lr 3.6258e-04 eta 0:02:52
epoch [38/50] batch [160/160] time 0.086 (0.088) data 0.000 (0.002) loss 1.3693 (1.1735) teacher_loss 0.6363 (0.3976) loss_zs_kd 0.0081 (0.0138) loss_oracle 0.4001 (0.4299) kd_loss 0.5289 (0.5541) acc 81.2500 (85.0586) gate/entropy 0.9769 (0.9769) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0335 (0.0352) teacher/usage_max 0.9917 (0.9646) teacher/usage_min 0.0019 (0.0078) teacher/usage_std 0.4656 (0.4465) nleep/row_max_mean 1501.5312 (1514.5588) nleep/row_max_std 91.5245 (62.7042) nleep/row_min_mean 1476.2041 (1486.4234) lr 3.1545e-04 eta 0:02:49
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,853
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,978
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 88.9%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [39/50] batch [20/160] time 0.092 (0.097) data 0.000 (0.014) loss 1.1398 (1.2042) teacher_loss 0.3483 (0.4169) loss_zs_kd 0.0100 (0.0150) loss_oracle 0.4324 (0.4362) kd_loss 0.5704 (0.5618) acc 90.6250 (85.9375) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0751 (0.0435) teacher/usage_max 0.9081 (0.9485) teacher/usage_min 0.0022 (0.0118) teacher/usage_std 0.4080 (0.4353) nleep/row_max_mean 1506.9662 (1517.1978) nleep/row_max_std 83.5769 (62.0862) nleep/row_min_mean 1482.0432 (1489.1533) lr 3.1545e-04 eta 0:03:04
epoch [39/50] batch [40/160] time 0.096 (0.094) data 0.000 (0.007) loss 1.0501 (1.1966) teacher_loss 0.2424 (0.4144) loss_zs_kd 0.0145 (0.0138) loss_oracle 0.4868 (0.4329) kd_loss 0.5570 (0.5588) acc 93.7500 (85.4688) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0555 (0.0392) teacher/usage_max 0.9413 (0.9558) teacher/usage_min 0.0266 (0.0095) teacher/usage_std 0.4299 (0.4404) nleep/row_max_mean 1518.6757 (1515.5942) nleep/row_max_std 58.3873 (63.2228) nleep/row_min_mean 1490.7296 (1487.3070) lr 3.1545e-04 eta 0:02:56
epoch [39/50] batch [60/160] time 0.091 (0.095) data 0.001 (0.005) loss 1.1858 (1.1737) teacher_loss 0.4123 (0.3923) loss_zs_kd 0.0100 (0.0137) loss_oracle 0.4376 (0.4303) kd_loss 0.5497 (0.5594) acc 78.1250 (85.7292) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5745 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0432 (0.0376) teacher/usage_max 0.9611 (0.9568) teacher/usage_min 0.0081 (0.0097) teacher/usage_std 0.4440 (0.4411) nleep/row_max_mean 1501.7443 (1515.2818) nleep/row_max_std 73.0404 (63.2914) nleep/row_min_mean 1475.4420 (1487.0267) lr 3.1545e-04 eta 0:02:56
epoch [39/50] batch [80/160] time 0.087 (0.095) data 0.000 (0.004) loss 1.2137 (1.1758) teacher_loss 0.4431 (0.3944) loss_zs_kd 0.0154 (0.0139) loss_oracle 0.4239 (0.4312) kd_loss 0.5510 (0.5588) acc 81.2500 (85.6641) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0037 (0.0374) teacher/usage_max 0.9993 (0.9577) teacher/usage_min 0.0001 (0.0094) teacher/usage_std 0.4709 (0.4417) nleep/row_max_mean 1518.2485 (1515.0708) nleep/row_max_std 68.8315 (62.3884) nleep/row_min_mean 1490.5123 (1486.8309) lr 3.1545e-04 eta 0:02:53
epoch [39/50] batch [100/160] time 0.093 (0.095) data 0.000 (0.003) loss 1.0079 (1.1705) teacher_loss 0.2642 (0.3896) loss_zs_kd 0.0211 (0.0137) loss_oracle 0.4131 (0.4309) kd_loss 0.5266 (0.5585) acc 90.6250 (85.7812) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0572 (0.0367) teacher/usage_max 0.9701 (0.9586) teacher/usage_min 0.0005 (0.0093) teacher/usage_std 0.4504 (0.4423) nleep/row_max_mean 1520.2655 (1515.3075) nleep/row_max_std 58.6804 (61.8479) nleep/row_min_mean 1492.6522 (1487.0311) lr 3.1545e-04 eta 0:02:52
epoch [39/50] batch [120/160] time 0.096 (0.098) data 0.000 (0.003) loss 1.8599 (1.1790) teacher_loss 1.0938 (0.3979) loss_zs_kd 0.0209 (0.0138) loss_oracle 0.4474 (0.4329) kd_loss 0.5319 (0.5577) acc 62.5000 (85.0260) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0556 (0.0366) teacher/usage_max 0.9662 (0.9595) teacher/usage_min 0.0101 (0.0085) teacher/usage_std 0.4476 (0.4430) nleep/row_max_mean 1519.6255 (1516.1008) nleep/row_max_std 47.6573 (60.5377) nleep/row_min_mean 1490.5048 (1487.6593) lr 3.1545e-04 eta 0:02:55
epoch [39/50] batch [140/160] time 0.084 (0.097) data 0.000 (0.002) loss 1.1650 (1.1799) teacher_loss 0.4072 (0.3979) loss_zs_kd 0.0092 (0.0139) loss_oracle 0.4126 (0.4339) kd_loss 0.5469 (0.5580) acc 87.5000 (84.8884) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0408 (0.0360) teacher/usage_max 0.9661 (0.9599) teacher/usage_min 0.0114 (0.0084) teacher/usage_std 0.4474 (0.4432) nleep/row_max_mean 1533.5006 (1516.2569) nleep/row_max_std 46.1611 (60.4513) nleep/row_min_mean 1503.9479 (1487.7291) lr 3.1545e-04 eta 0:02:52
epoch [39/50] batch [160/160] time 0.128 (0.096) data 0.000 (0.002) loss 1.0591 (1.1767) teacher_loss 0.2757 (0.3953) loss_zs_kd 0.0092 (0.0135) loss_oracle 0.4453 (0.4338) kd_loss 0.5562 (0.5577) acc 93.7500 (85.0195) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0441 (0.0356) teacher/usage_max 0.9536 (0.9606) teacher/usage_min 0.0078 (0.0080) teacher/usage_std 0.4388 (0.4437) nleep/row_max_mean 1507.2062 (1515.8641) nleep/row_max_std 74.3150 (60.8224) nleep/row_min_mean 1476.8979 (1487.2992) lr 2.7103e-04 eta 0:02:48
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,859
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,985
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.2%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [40/50] batch [20/160] time 0.087 (0.102) data 0.000 (0.014) loss 1.0937 (1.1690) teacher_loss 0.2977 (0.3988) loss_zs_kd 0.0096 (0.0141) loss_oracle 0.4551 (0.4211) kd_loss 0.5636 (0.5525) acc 87.5000 (83.2812) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0213 (0.0251) teacher/usage_max 0.9690 (0.9763) teacher/usage_min 0.0000 (0.0043) teacher/usage_std 0.4496 (0.4547) nleep/row_max_mean 1510.4136 (1514.5726) nleep/row_max_std 78.2506 (65.2925) nleep/row_min_mean 1479.3708 (1485.3714) lr 2.7103e-04 eta 0:02:58
epoch [40/50] batch [40/160] time 0.094 (0.095) data 0.000 (0.007) loss 1.2609 (1.1753) teacher_loss 0.4507 (0.3981) loss_zs_kd 0.0143 (0.0136) loss_oracle 0.4340 (0.4310) kd_loss 0.5861 (0.5549) acc 87.5000 (84.6094) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0708 (0.0282) teacher/usage_max 0.8966 (0.9708) teacher/usage_min 0.0192 (0.0043) teacher/usage_std 0.3991 (0.4509) nleep/row_max_mean 1509.3882 (1516.9424) nleep/row_max_std 57.1542 (60.5369) nleep/row_min_mean 1479.9951 (1487.7033) lr 2.7103e-04 eta 0:02:42
epoch [40/50] batch [60/160] time 0.089 (0.092) data 0.001 (0.005) loss 1.1606 (1.1850) teacher_loss 0.3882 (0.4058) loss_zs_kd 0.0235 (0.0141) loss_oracle 0.4273 (0.4335) kd_loss 0.5470 (0.5554) acc 87.5000 (84.5833) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0086 (0.0299) teacher/usage_max 0.9985 (0.9686) teacher/usage_min 0.0002 (0.0047) teacher/usage_std 0.4703 (0.4494) nleep/row_max_mean 1511.9265 (1515.4167) nleep/row_max_std 70.3576 (62.8229) nleep/row_min_mean 1482.0836 (1486.1528) lr 2.7103e-04 eta 0:02:36
epoch [40/50] batch [80/160] time 0.086 (0.091) data 0.000 (0.004) loss 1.1509 (1.1814) teacher_loss 0.3961 (0.4016) loss_zs_kd 0.0115 (0.0140) loss_oracle 0.4271 (0.4336) kd_loss 0.5356 (0.5560) acc 90.6250 (84.2188) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5745 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1705 (0.1706) teacher/entropy 0.0311 (0.0307) teacher/usage_max 0.9874 (0.9671) teacher/usage_min 0.0004 (0.0056) teacher/usage_std 0.4625 (0.4483) nleep/row_max_mean 1489.4458 (1515.5641) nleep/row_max_std 90.4778 (61.9040) nleep/row_min_mean 1463.8879 (1486.3118) lr 2.7103e-04 eta 0:02:32
epoch [40/50] batch [100/160] time 0.092 (0.090) data 0.000 (0.003) loss 1.2095 (1.1848) teacher_loss 0.4543 (0.4034) loss_zs_kd 0.0090 (0.0140) loss_oracle 0.4283 (0.4344) kd_loss 0.5365 (0.5572) acc 81.2500 (84.3750) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0398 (0.0316) teacher/usage_max 0.9776 (0.9650) teacher/usage_min 0.0105 (0.0060) teacher/usage_std 0.4556 (0.4469) nleep/row_max_mean 1513.8770 (1515.0272) nleep/row_max_std 79.3124 (62.6911) nleep/row_min_mean 1485.3259 (1485.8565) lr 2.7103e-04 eta 0:02:28
epoch [40/50] batch [120/160] time 0.090 (0.090) data 0.001 (0.003) loss 1.2738 (1.1905) teacher_loss 0.5204 (0.4086) loss_zs_kd 0.0182 (0.0139) loss_oracle 0.3902 (0.4339) kd_loss 0.5492 (0.5580) acc 81.2500 (84.3229) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0541 (0.0323) teacher/usage_max 0.9506 (0.9636) teacher/usage_min 0.0213 (0.0066) teacher/usage_std 0.4365 (0.4459) nleep/row_max_mean 1491.5830 (1514.1746) nleep/row_max_std 88.2379 (64.1000) nleep/row_min_mean 1464.0613 (1485.0171) lr 2.7103e-04 eta 0:02:27
epoch [40/50] batch [140/160] time 0.094 (0.090) data 0.000 (0.002) loss 1.1934 (1.1867) teacher_loss 0.4053 (0.4045) loss_zs_kd 0.0065 (0.0135) loss_oracle 0.4396 (0.4340) kd_loss 0.5651 (0.5585) acc 90.6250 (84.5982) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0347 (0.0319) teacher/usage_max 0.9540 (0.9634) teacher/usage_min 0.0005 (0.0068) teacher/usage_std 0.4392 (0.4457) nleep/row_max_mean 1514.2952 (1514.3475) nleep/row_max_std 60.5777 (63.0496) nleep/row_min_mean 1484.0294 (1485.2047) lr 2.7103e-04 eta 0:02:25
epoch [40/50] batch [160/160] time 0.086 (0.090) data 0.000 (0.002) loss 1.1571 (1.1796) teacher_loss 0.3561 (0.3973) loss_zs_kd 0.0196 (0.0136) loss_oracle 0.4257 (0.4335) kd_loss 0.5784 (0.5588) acc 84.3750 (84.8047) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0278 (0.0321) teacher/usage_max 0.9475 (0.9630) teacher/usage_min 0.0215 (0.0072) teacher/usage_std 0.4343 (0.4454) nleep/row_max_mean 1505.6770 (1514.2069) nleep/row_max_std 62.1959 (62.4666) nleep/row_min_mean 1477.1160 (1485.1153) lr 2.2949e-04 eta 0:02:23
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,856
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,983
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.2%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [41/50] batch [20/160] time 0.095 (0.103) data 0.000 (0.013) loss 1.2122 (1.1661) teacher_loss 0.4611 (0.3863) loss_zs_kd 0.0108 (0.0135) loss_oracle 0.3966 (0.4258) kd_loss 0.5474 (0.5601) acc 87.5000 (83.5938) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0088 (0.0343) teacher/usage_max 0.9978 (0.9595) teacher/usage_min 0.0001 (0.0067) teacher/usage_std 0.4699 (0.4430) nleep/row_max_mean 1519.7611 (1508.5623) nleep/row_max_std 43.9587 (65.7001) nleep/row_min_mean 1491.8567 (1480.2597) lr 2.2949e-04 eta 0:02:43
epoch [41/50] batch [40/160] time 0.079 (0.113) data 0.000 (0.007) loss 1.1070 (1.1632) teacher_loss 0.3177 (0.3744) loss_zs_kd 0.0199 (0.0153) loss_oracle 0.4399 (0.4292) kd_loss 0.5594 (0.5665) acc 87.5000 (85.1562) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0497 (0.0354) teacher/usage_max 0.9446 (0.9518) teacher/usage_min 0.0227 (0.0069) teacher/usage_std 0.4323 (0.4378) nleep/row_max_mean 1508.6580 (1510.9453) nleep/row_max_std 52.3597 (58.8131) nleep/row_min_mean 1480.2289 (1482.5519) lr 2.2949e-04 eta 0:02:56
epoch [41/50] batch [60/160] time 0.097 (0.107) data 0.001 (0.005) loss 1.1628 (1.1606) teacher_loss 0.3768 (0.3726) loss_zs_kd 0.0198 (0.0145) loss_oracle 0.4777 (0.4296) kd_loss 0.5372 (0.5659) acc 87.5000 (85.6771) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0705 (0.0355) teacher/usage_max 0.9461 (0.9524) teacher/usage_min 0.0060 (0.0073) teacher/usage_std 0.4336 (0.4381) nleep/row_max_mean 1481.8108 (1510.0428) nleep/row_max_std 94.2193 (62.4286) nleep/row_min_mean 1452.9806 (1481.4261) lr 2.2949e-04 eta 0:02:44
epoch [41/50] batch [80/160] time 0.152 (0.104) data 0.000 (0.004) loss 1.3365 (1.1748) teacher_loss 0.4766 (0.3852) loss_zs_kd 0.0179 (0.0149) loss_oracle 0.4972 (0.4308) kd_loss 0.6024 (0.5667) acc 81.2500 (85.2344) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0214 (0.0347) teacher/usage_max 0.9298 (0.9523) teacher/usage_min 0.0000 (0.0066) teacher/usage_std 0.4228 (0.4381) nleep/row_max_mean 1523.2297 (1511.1842) nleep/row_max_std 27.3878 (60.8651) nleep/row_min_mean 1489.7603 (1482.4627) lr 2.2949e-04 eta 0:02:38
epoch [41/50] batch [100/160] time 0.092 (0.102) data 0.000 (0.003) loss 1.1740 (1.1741) teacher_loss 0.3448 (0.3810) loss_zs_kd 0.0170 (0.0145) loss_oracle 0.4221 (0.4346) kd_loss 0.6097 (0.5685) acc 81.2500 (85.3125) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0058 (0.0361) teacher/usage_max 0.9382 (0.9491) teacher/usage_min 0.0000 (0.0076) teacher/usage_std 0.4285 (0.4359) nleep/row_max_mean 1518.3414 (1511.9174) nleep/row_max_std 57.6122 (60.2105) nleep/row_min_mean 1489.7078 (1483.1717) lr 2.2949e-04 eta 0:02:33
epoch [41/50] batch [120/160] time 0.091 (0.101) data 0.001 (0.003) loss 1.3144 (1.1812) teacher_loss 0.5570 (0.3898) loss_zs_kd 0.0150 (0.0144) loss_oracle 0.3937 (0.4332) kd_loss 0.5531 (0.5676) acc 78.1250 (85.1042) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0375 (0.0347) teacher/usage_max 0.9634 (0.9515) teacher/usage_min 0.0015 (0.0075) teacher/usage_std 0.4457 (0.4375) nleep/row_max_mean 1506.6683 (1511.6590) nleep/row_max_std 68.7775 (60.9018) nleep/row_min_mean 1480.6699 (1482.9188) lr 2.2949e-04 eta 0:02:28
epoch [41/50] batch [140/160] time 0.087 (0.099) data 0.000 (0.002) loss 1.1514 (1.1860) teacher_loss 0.4223 (0.3948) loss_zs_kd 0.0172 (0.0147) loss_oracle 0.3899 (0.4336) kd_loss 0.5255 (0.5670) acc 81.2500 (85.0223) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0481 (0.0360) teacher/usage_max 0.9803 (0.9507) teacher/usage_min 0.0022 (0.0073) teacher/usage_std 0.4575 (0.4370) nleep/row_max_mean 1507.4926 (1511.8710) nleep/row_max_std 76.0043 (60.9739) nleep/row_min_mean 1478.7145 (1483.1281) lr 2.2949e-04 eta 0:02:24
epoch [41/50] batch [160/160] time 0.080 (0.097) data 0.000 (0.002) loss 1.1167 (1.1856) teacher_loss 0.3084 (0.3930) loss_zs_kd 0.0091 (0.0145) loss_oracle 0.4321 (0.4344) kd_loss 0.5877 (0.5681) acc 87.5000 (85.2734) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0226 (0.0370) teacher/usage_max 0.9434 (0.9486) teacher/usage_min 0.0000 (0.0074) teacher/usage_std 0.4320 (0.4355) nleep/row_max_mean 1528.5477 (1512.4276) nleep/row_max_std 56.0118 (60.3703) nleep/row_min_mean 1498.9271 (1483.6708) lr 1.9098e-04 eta 0:02:20
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,860
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,986
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.3%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [42/50] batch [20/160] time 0.102 (0.109) data 0.000 (0.015) loss 1.2478 (1.1905) teacher_loss 0.4892 (0.3940) loss_zs_kd 0.0087 (0.0180) loss_oracle 0.4192 (0.4411) kd_loss 0.5447 (0.5669) acc 87.5000 (85.6250) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0122 (0.0350) teacher/usage_max 0.9971 (0.9519) teacher/usage_min 0.0000 (0.0098) teacher/usage_std 0.4694 (0.4376) nleep/row_max_mean 1525.9749 (1514.1032) nleep/row_max_std 25.6551 (54.8535) nleep/row_min_mean 1497.0392 (1485.7246) lr 1.9098e-04 eta 0:02:34
epoch [42/50] batch [40/160] time 0.097 (0.102) data 0.000 (0.008) loss 1.1391 (1.1830) teacher_loss 0.3794 (0.3837) loss_zs_kd 0.0179 (0.0167) loss_oracle 0.4354 (0.4430) kd_loss 0.5331 (0.5694) acc 75.0000 (85.3125) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0416 (0.0372) teacher/usage_max 0.9793 (0.9471) teacher/usage_min 0.0073 (0.0112) teacher/usage_std 0.4567 (0.4343) nleep/row_max_mean 1511.4552 (1512.2370) nleep/row_max_std 57.7847 (58.4748) nleep/row_min_mean 1482.8340 (1484.0579) lr 1.9098e-04 eta 0:02:22
epoch [42/50] batch [60/160] time 0.086 (0.098) data 0.001 (0.005) loss 1.0851 (1.1803) teacher_loss 0.3199 (0.3834) loss_zs_kd 0.0248 (0.0159) loss_oracle 0.4044 (0.4375) kd_loss 0.5506 (0.5702) acc 81.2500 (85.4688) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0041 (0.0375) teacher/usage_max 0.9993 (0.9460) teacher/usage_min 0.0000 (0.0099) teacher/usage_std 0.4709 (0.4336) nleep/row_max_mean 1533.5552 (1512.8816) nleep/row_max_std 25.1990 (57.4837) nleep/row_min_mean 1503.4692 (1484.6619) lr 1.9098e-04 eta 0:02:15
epoch [42/50] batch [80/160] time 0.097 (0.097) data 0.000 (0.004) loss 0.9700 (1.1759) teacher_loss 0.2405 (0.3820) loss_zs_kd 0.0047 (0.0148) loss_oracle 0.3893 (0.4371) kd_loss 0.5325 (0.5680) acc 96.8750 (85.6641) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0392 (0.0399) teacher/usage_max 0.9821 (0.9458) teacher/usage_min 0.0031 (0.0104) teacher/usage_std 0.4588 (0.4335) nleep/row_max_mean 1522.5415 (1513.3267) nleep/row_max_std 55.3822 (57.8574) nleep/row_min_mean 1495.9392 (1485.2248) lr 1.9098e-04 eta 0:02:12
epoch [42/50] batch [100/160] time 0.102 (0.096) data 0.000 (0.003) loss 1.1951 (1.1830) teacher_loss 0.3946 (0.3927) loss_zs_kd 0.0256 (0.0146) loss_oracle 0.4439 (0.4356) kd_loss 0.5657 (0.5651) acc 90.6250 (85.1250) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0200 (0.0384) teacher/usage_max 0.9682 (0.9501) teacher/usage_min 0.0029 (0.0097) teacher/usage_std 0.4490 (0.4365) nleep/row_max_mean 1515.3607 (1513.5393) nleep/row_max_std 56.9444 (57.8325) nleep/row_min_mean 1485.8611 (1485.4161) lr 1.9098e-04 eta 0:02:09
epoch [42/50] batch [120/160] time 0.091 (0.096) data 0.000 (0.003) loss 1.2557 (1.1851) teacher_loss 0.4999 (0.3951) loss_zs_kd 0.0013 (0.0143) loss_oracle 0.3863 (0.4357) kd_loss 0.5620 (0.5650) acc 81.2500 (84.8698) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0452 (0.0378) teacher/usage_max 0.9465 (0.9509) teacher/usage_min 0.0173 (0.0096) teacher/usage_std 0.4337 (0.4370) nleep/row_max_mean 1504.2407 (1513.0115) nleep/row_max_std 84.7358 (59.3012) nleep/row_min_mean 1478.1753 (1484.8791) lr 1.9098e-04 eta 0:02:06
epoch [42/50] batch [140/160] time 0.101 (0.096) data 0.000 (0.002) loss 1.0634 (1.1840) teacher_loss 0.2620 (0.3952) loss_zs_kd 0.0182 (0.0144) loss_oracle 0.4167 (0.4351) kd_loss 0.5840 (0.5640) acc 84.3750 (84.9107) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0434 (0.0365) teacher/usage_max 0.9262 (0.9532) teacher/usage_min 0.0359 (0.0092) teacher/usage_std 0.4192 (0.4386) nleep/row_max_mean 1495.0244 (1512.8939) nleep/row_max_std 78.8726 (59.7082) nleep/row_min_mean 1470.4299 (1484.7547) lr 1.9098e-04 eta 0:02:04
epoch [42/50] batch [160/160] time 0.080 (0.095) data 0.000 (0.002) loss 1.3907 (1.1796) teacher_loss 0.5646 (0.3902) loss_zs_kd 0.0122 (0.0145) loss_oracle 0.4457 (0.4357) kd_loss 0.5971 (0.5643) acc 81.2500 (85.1367) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0444 (0.0367) teacher/usage_max 0.9120 (0.9527) teacher/usage_min 0.0003 (0.0092) teacher/usage_std 0.4107 (0.4382) nleep/row_max_mean 1532.9971 (1513.0789) nleep/row_max_std 28.0506 (60.1074) nleep/row_min_mean 1505.3470 (1485.0324) lr 1.5567e-04 eta 0:02:01
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,854
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,985
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 89.2%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [43/50] batch [20/160] time 0.098 (0.104) data 0.000 (0.018) loss 1.1411 (1.2226) teacher_loss 0.3373 (0.4341) loss_zs_kd 0.0101 (0.0163) loss_oracle 0.4502 (0.4308) kd_loss 0.5736 (0.5649) acc 87.5000 (83.5938) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0095 (0.0296) teacher/usage_max 0.9708 (0.9592) teacher/usage_min 0.0002 (0.0072) teacher/usage_std 0.4509 (0.4428) nleep/row_max_mean 1506.8624 (1511.4633) nleep/row_max_std 71.9396 (63.7512) nleep/row_min_mean 1478.0548 (1483.4794) lr 1.5567e-04 eta 0:02:11
epoch [43/50] batch [40/160] time 0.099 (0.099) data 0.000 (0.009) loss 1.0450 (1.1988) teacher_loss 0.2294 (0.4158) loss_zs_kd 0.0098 (0.0153) loss_oracle 0.4259 (0.4263) kd_loss 0.5978 (0.5622) acc 96.8750 (84.1406) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0421 (0.0350) teacher/usage_max 0.9135 (0.9566) teacher/usage_min 0.0039 (0.0092) teacher/usage_std 0.4115 (0.4409) nleep/row_max_mean 1502.4912 (1512.5624) nleep/row_max_std 73.8770 (62.8921) nleep/row_min_mean 1475.1416 (1484.7078) lr 1.5567e-04 eta 0:02:02
epoch [43/50] batch [60/160] time 0.096 (0.097) data 0.001 (0.006) loss 1.0449 (1.1853) teacher_loss 0.2765 (0.3971) loss_zs_kd 0.0236 (0.0156) loss_oracle 0.4361 (0.4297) kd_loss 0.5386 (0.5655) acc 87.5000 (84.7396) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0203 (0.0344) teacher/usage_max 0.9951 (0.9538) teacher/usage_min 0.0003 (0.0089) teacher/usage_std 0.4679 (0.4390) nleep/row_max_mean 1528.2402 (1515.2086) nleep/row_max_std 45.0804 (59.5262) nleep/row_min_mean 1499.1555 (1487.0637) lr 1.5567e-04 eta 0:01:57
epoch [43/50] batch [80/160] time 0.101 (0.096) data 0.000 (0.005) loss 1.2195 (1.1878) teacher_loss 0.4009 (0.3966) loss_zs_kd 0.0215 (0.0147) loss_oracle 0.4756 (0.4311) kd_loss 0.5700 (0.5683) acc 84.3750 (84.9609) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0464 (0.0342) teacher/usage_max 0.9372 (0.9512) teacher/usage_min 0.0283 (0.0096) teacher/usage_std 0.4270 (0.4372) nleep/row_max_mean 1515.0603 (1515.7392) nleep/row_max_std 55.2402 (58.4464) nleep/row_min_mean 1485.1255 (1487.5507) lr 1.5567e-04 eta 0:01:55
epoch [43/50] batch [100/160] time 0.103 (0.095) data 0.000 (0.004) loss 1.2136 (1.1890) teacher_loss 0.4431 (0.3975) loss_zs_kd 0.0066 (0.0147) loss_oracle 0.3964 (0.4338) kd_loss 0.5689 (0.5672) acc 84.3750 (84.6875) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0160 (0.0347) teacher/usage_max 0.9689 (0.9518) teacher/usage_min 0.0016 (0.0098) teacher/usage_std 0.4496 (0.4376) nleep/row_max_mean 1515.0613 (1515.4090) nleep/row_max_std 72.0503 (60.0631) nleep/row_min_mean 1486.4215 (1487.0333) lr 1.5567e-04 eta 0:01:51
epoch [43/50] batch [120/160] time 0.100 (0.094) data 0.000 (0.003) loss 1.4458 (1.1928) teacher_loss 0.5899 (0.3987) loss_zs_kd 0.0110 (0.0151) loss_oracle 0.4618 (0.4352) kd_loss 0.6195 (0.5690) acc 78.1250 (84.4792) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0639 (0.0344) teacher/usage_max 0.8699 (0.9503) teacher/usage_min 0.0201 (0.0098) teacher/usage_std 0.3812 (0.4366) nleep/row_max_mean 1517.2264 (1515.5837) nleep/row_max_std 44.4444 (59.6838) nleep/row_min_mean 1492.0771 (1487.2194) lr 1.5567e-04 eta 0:01:49
epoch [43/50] batch [140/160] time 0.096 (0.094) data 0.000 (0.003) loss 1.2305 (1.1908) teacher_loss 0.4389 (0.3987) loss_zs_kd 0.0106 (0.0149) loss_oracle 0.4498 (0.4353) kd_loss 0.5614 (0.5670) acc 81.2500 (84.3527) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0318 (0.0346) teacher/usage_max 0.9606 (0.9521) teacher/usage_min 0.0061 (0.0096) teacher/usage_std 0.4437 (0.4379) nleep/row_max_mean 1515.4419 (1514.9800) nleep/row_max_std 76.0979 (60.1938) nleep/row_min_mean 1487.4082 (1486.7085) lr 1.5567e-04 eta 0:01:47
epoch [43/50] batch [160/160] time 0.079 (0.093) data 0.000 (0.002) loss 1.0195 (1.1876) teacher_loss 0.2360 (0.3962) loss_zs_kd 0.0075 (0.0149) loss_oracle 0.4317 (0.4347) kd_loss 0.5639 (0.5666) acc 93.7500 (84.3555) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0283 (0.0343) teacher/usage_max 0.9616 (0.9529) teacher/usage_min 0.0000 (0.0092) teacher/usage_std 0.4446 (0.4384) nleep/row_max_mean 1529.0400 (1515.0140) nleep/row_max_std 29.4023 (59.8921) nleep/row_min_mean 1500.2190 (1486.7874) lr 1.2369e-04 eta 0:01:44
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,858
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,978
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 89.0%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [44/50] batch [20/160] time 0.076 (0.101) data 0.000 (0.016) loss 1.0786 (1.1724) teacher_loss 0.3212 (0.3839) loss_zs_kd 0.0142 (0.0133) loss_oracle 0.3961 (0.4409) kd_loss 0.5523 (0.5614) acc 90.6250 (85.7812) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0021 (0.0358) teacher/usage_max 0.9997 (0.9565) teacher/usage_min 0.0000 (0.0045) teacher/usage_std 0.4712 (0.4411) nleep/row_max_mean 1523.3706 (1514.9876) nleep/row_max_std 60.6413 (60.4264) nleep/row_min_mean 1493.0669 (1486.7934) lr 1.2369e-04 eta 0:01:50
epoch [44/50] batch [40/160] time 0.088 (0.091) data 0.000 (0.008) loss 1.4033 (1.2161) teacher_loss 0.6403 (0.4285) loss_zs_kd 0.0213 (0.0137) loss_oracle 0.4175 (0.4394) kd_loss 0.5436 (0.5609) acc 71.8750 (84.4531) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0143 (0.0358) teacher/usage_max 0.9961 (0.9570) teacher/usage_min 0.0000 (0.0060) teacher/usage_std 0.4687 (0.4413) nleep/row_max_mean 1510.9861 (1512.7872) nleep/row_max_std 57.0119 (62.2753) nleep/row_min_mean 1483.3328 (1484.6433) lr 1.2369e-04 eta 0:01:38
epoch [44/50] batch [60/160] time 0.068 (0.088) data 0.001 (0.005) loss 1.0705 (1.2043) teacher_loss 0.2618 (0.4148) loss_zs_kd 0.0179 (0.0138) loss_oracle 0.4037 (0.4384) kd_loss 0.5979 (0.5634) acc 90.6250 (84.8438) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0909 (0.0354) teacher/usage_max 0.8644 (0.9549) teacher/usage_min 0.0667 (0.0076) teacher/usage_std 0.3755 (0.4398) nleep/row_max_mean 1502.2822 (1512.8790) nleep/row_max_std 80.8730 (62.5026) nleep/row_min_mean 1478.6265 (1484.9757) lr 1.2369e-04 eta 0:01:33
epoch [44/50] batch [80/160] time 0.087 (0.086) data 0.000 (0.004) loss 1.3027 (1.2058) teacher_loss 0.5420 (0.4154) loss_zs_kd 0.0095 (0.0137) loss_oracle 0.4185 (0.4400) kd_loss 0.5467 (0.5635) acc 81.2500 (84.2188) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0096 (0.0340) teacher/usage_max 0.9976 (0.9562) teacher/usage_min 0.0000 (0.0074) teacher/usage_std 0.4697 (0.4408) nleep/row_max_mean 1521.1514 (1514.1392) nleep/row_max_std 61.8599 (61.3686) nleep/row_min_mean 1493.4551 (1486.1083) lr 1.2369e-04 eta 0:01:29
epoch [44/50] batch [100/160] time 0.159 (0.090) data 0.001 (0.003) loss 1.2067 (1.1910) teacher_loss 0.4205 (0.4009) loss_zs_kd 0.0290 (0.0142) loss_oracle 0.4757 (0.4388) kd_loss 0.5338 (0.5636) acc 87.5000 (84.8438) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0414 (0.0326) teacher/usage_max 0.9787 (0.9575) teacher/usage_min 0.0026 (0.0070) teacher/usage_std 0.4564 (0.4417) nleep/row_max_mean 1506.0278 (1514.7374) nleep/row_max_std 75.7383 (60.6900) nleep/row_min_mean 1476.7367 (1486.5356) lr 1.2369e-04 eta 0:01:31
epoch [44/50] batch [120/160] time 0.123 (0.090) data 0.000 (0.003) loss 0.9988 (1.1802) teacher_loss 0.2163 (0.3908) loss_zs_kd 0.0188 (0.0143) loss_oracle 0.4580 (0.4388) kd_loss 0.5441 (0.5628) acc 93.7500 (85.3385) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.1242 (0.0340) teacher/usage_max 0.8850 (0.9569) teacher/usage_min 0.0495 (0.0076) teacher/usage_std 0.3902 (0.4412) nleep/row_max_mean 1509.5625 (1514.9218) nleep/row_max_std 64.2608 (60.7673) nleep/row_min_mean 1483.2911 (1486.6985) lr 1.2369e-04 eta 0:01:29
epoch [44/50] batch [140/160] time 0.071 (0.089) data 0.000 (0.002) loss 1.4384 (1.1864) teacher_loss 0.6471 (0.3958) loss_zs_kd 0.0151 (0.0145) loss_oracle 0.4868 (0.4395) kd_loss 0.5404 (0.5635) acc 78.1250 (85.1116) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0212 (0.0345) teacher/usage_max 0.9923 (0.9557) teacher/usage_min 0.0001 (0.0083) teacher/usage_std 0.4660 (0.4403) nleep/row_max_mean 1509.9192 (1514.7789) nleep/row_max_std 61.6924 (60.9258) nleep/row_min_mean 1481.7898 (1486.5816) lr 1.2369e-04 eta 0:01:27
epoch [44/50] batch [160/160] time 0.077 (0.088) data 0.000 (0.002) loss 1.3471 (1.1901) teacher_loss 0.5377 (0.3980) loss_zs_kd 0.0158 (0.0146) loss_oracle 0.4646 (0.4407) kd_loss 0.5692 (0.5644) acc 78.1250 (85.0195) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0641 (0.0351) teacher/usage_max 0.9203 (0.9543) teacher/usage_min 0.0090 (0.0085) teacher/usage_std 0.4158 (0.4393) nleep/row_max_mean 1502.1670 (1514.2326) nleep/row_max_std 58.9691 (61.4867) nleep/row_min_mean 1472.6091 (1486.1137) lr 9.5173e-05 eta 0:01:24
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,860
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,977
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 89.0%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [45/50] batch [20/160] time 0.098 (0.109) data 0.000 (0.016) loss 1.3270 (1.2108) teacher_loss 0.5535 (0.4306) loss_zs_kd 0.0170 (0.0190) loss_oracle 0.4390 (0.4304) kd_loss 0.5455 (0.5555) acc 65.6250 (83.1250) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0254 (0.0361) teacher/usage_max 0.9830 (0.9622) teacher/usage_min 0.0000 (0.0078) teacher/usage_std 0.4594 (0.4448) nleep/row_max_mean 1525.1992 (1511.0589) nleep/row_max_std 46.9717 (62.3101) nleep/row_min_mean 1493.4810 (1483.0685) lr 9.5173e-05 eta 0:01:42
epoch [45/50] batch [40/160] time 0.078 (0.098) data 0.000 (0.008) loss 1.0725 (1.1979) teacher_loss 0.2718 (0.4090) loss_zs_kd 0.0120 (0.0178) loss_oracle 0.4721 (0.4439) kd_loss 0.5587 (0.5580) acc 96.8750 (84.5312) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0452 (0.0293) teacher/usage_max 0.9498 (0.9665) teacher/usage_min 0.0028 (0.0056) teacher/usage_std 0.4363 (0.4479) nleep/row_max_mean 1499.2061 (1514.5415) nleep/row_max_std 91.7535 (58.2015) nleep/row_min_mean 1468.9945 (1485.6798) lr 9.5173e-05 eta 0:01:29
epoch [45/50] batch [60/160] time 0.085 (0.093) data 0.001 (0.005) loss 1.1044 (1.2051) teacher_loss 0.2933 (0.4152) loss_zs_kd 0.0125 (0.0163) loss_oracle 0.4105 (0.4449) kd_loss 0.5996 (0.5593) acc 93.7500 (84.3750) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0433 (0.0287) teacher/usage_max 0.9105 (0.9658) teacher/usage_min 0.0292 (0.0061) teacher/usage_std 0.4083 (0.4474) nleep/row_max_mean 1512.3716 (1515.1131) nleep/row_max_std 60.5814 (57.2058) nleep/row_min_mean 1485.9802 (1486.3462) lr 9.5173e-05 eta 0:01:23
epoch [45/50] batch [80/160] time 0.077 (0.091) data 0.000 (0.004) loss 1.3023 (1.1999) teacher_loss 0.5128 (0.4069) loss_zs_kd 0.0111 (0.0155) loss_oracle 0.4705 (0.4452) kd_loss 0.5487 (0.5626) acc 81.2500 (84.6484) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0071 (0.0286) teacher/usage_max 0.9982 (0.9625) teacher/usage_min 0.0000 (0.0066) teacher/usage_std 0.4701 (0.4451) nleep/row_max_mean 1512.7146 (1514.5334) nleep/row_max_std 60.5170 (59.3701) nleep/row_min_mean 1483.1619 (1485.7439) lr 9.5173e-05 eta 0:01:20
epoch [45/50] batch [100/160] time 0.089 (0.090) data 0.001 (0.003) loss 1.0185 (1.1940) teacher_loss 0.2348 (0.4013) loss_zs_kd 0.0063 (0.0155) loss_oracle 0.4189 (0.4446) kd_loss 0.5712 (0.5627) acc 96.8750 (84.9688) gate/entropy 0.9767 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0190 (0.0282) teacher/usage_max 0.9635 (0.9628) teacher/usage_min 0.0009 (0.0066) teacher/usage_std 0.4458 (0.4453) nleep/row_max_mean 1522.8235 (1514.8858) nleep/row_max_std 64.1939 (59.0348) nleep/row_min_mean 1494.9900 (1486.1326) lr 9.5173e-05 eta 0:01:17
epoch [45/50] batch [120/160] time 0.075 (0.089) data 0.000 (0.003) loss 1.3991 (1.1950) teacher_loss 0.5886 (0.4011) loss_zs_kd 0.0129 (0.0152) loss_oracle 0.4662 (0.4453) kd_loss 0.5709 (0.5636) acc 84.3750 (85.3906) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0373 (0.0290) teacher/usage_max 0.9454 (0.9611) teacher/usage_min 0.0235 (0.0073) teacher/usage_std 0.4328 (0.4441) nleep/row_max_mean 1507.6230 (1514.0233) nleep/row_max_std 82.0501 (61.1941) nleep/row_min_mean 1480.5270 (1485.3435) lr 9.5173e-05 eta 0:01:14
epoch [45/50] batch [140/160] time 0.086 (0.088) data 0.000 (0.002) loss 1.2519 (1.1917) teacher_loss 0.4563 (0.3988) loss_zs_kd 0.0198 (0.0152) loss_oracle 0.4464 (0.4441) kd_loss 0.5625 (0.5633) acc 87.5000 (85.4241) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0286 (0.0299) teacher/usage_max 0.9627 (0.9606) teacher/usage_min 0.0062 (0.0077) teacher/usage_std 0.4451 (0.4437) nleep/row_max_mean 1478.9768 (1513.4011) nleep/row_max_std 108.2472 (62.7382) nleep/row_min_mean 1452.4487 (1484.7187) lr 9.5173e-05 eta 0:01:12
epoch [45/50] batch [160/160] time 0.085 (0.087) data 0.000 (0.002) loss 1.2986 (1.1877) teacher_loss 0.4959 (0.3954) loss_zs_kd 0.0147 (0.0150) loss_oracle 0.4599 (0.4440) kd_loss 0.5653 (0.5628) acc 81.2500 (85.5273) gate/entropy 0.9767 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0358 (0.0313) teacher/usage_max 0.9524 (0.9596) teacher/usage_min 0.0179 (0.0081) teacher/usage_std 0.4378 (0.4430) nleep/row_max_mean 1524.6133 (1513.1035) nleep/row_max_std 49.7565 (63.1382) nleep/row_min_mean 1495.2405 (1484.4201) lr 7.0224e-05 eta 0:01:09
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,860
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,976
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 88.9%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [46/50] batch [20/160] time 0.096 (0.109) data 0.000 (0.014) loss 1.4060 (1.1644) teacher_loss 0.6175 (0.3853) loss_zs_kd 0.0145 (0.0153) loss_oracle 0.4594 (0.4348) kd_loss 0.5515 (0.5540) acc 75.0000 (84.3750) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5746) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0261 (0.0319) teacher/usage_max 0.9764 (0.9679) teacher/usage_min 0.0015 (0.0036) teacher/usage_std 0.4548 (0.4489) nleep/row_max_mean 1500.0791 (1513.9121) nleep/row_max_std 88.5302 (64.7515) nleep/row_min_mean 1472.0405 (1485.1765) lr 7.0224e-05 eta 0:01:25
epoch [46/50] batch [40/160] time 0.086 (0.111) data 0.000 (0.007) loss 1.2165 (1.1727) teacher_loss 0.3730 (0.3939) loss_zs_kd 0.0333 (0.0157) loss_oracle 0.4730 (0.4300) kd_loss 0.5903 (0.5560) acc 87.5000 (84.2188) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0792 (0.0351) teacher/usage_max 0.8838 (0.9626) teacher/usage_min 0.0492 (0.0062) teacher/usage_std 0.3893 (0.4452) nleep/row_max_mean 1508.9548 (1514.3125) nleep/row_max_std 73.0688 (65.6108) nleep/row_min_mean 1482.2866 (1485.6014) lr 7.0224e-05 eta 0:01:23
epoch [46/50] batch [60/160] time 0.096 (0.106) data 0.001 (0.005) loss 1.1003 (1.1807) teacher_loss 0.2904 (0.3929) loss_zs_kd 0.0096 (0.0158) loss_oracle 0.4228 (0.4340) kd_loss 0.5936 (0.5629) acc 90.6250 (84.5312) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0508 (0.0346) teacher/usage_max 0.9090 (0.9562) teacher/usage_min 0.0323 (0.0086) teacher/usage_std 0.4072 (0.4407) nleep/row_max_mean 1501.5740 (1513.4258) nleep/row_max_std 78.1621 (64.4767) nleep/row_min_mean 1475.2153 (1484.9166) lr 7.0224e-05 eta 0:01:18
epoch [46/50] batch [80/160] time 0.089 (0.103) data 0.000 (0.004) loss 1.2366 (1.1689) teacher_loss 0.4258 (0.3805) loss_zs_kd 0.0222 (0.0155) loss_oracle 0.4334 (0.4348) kd_loss 0.5830 (0.5632) acc 84.3750 (85.2734) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0019 (0.0352) teacher/usage_max 0.9689 (0.9553) teacher/usage_min 0.0000 (0.0085) teacher/usage_std 0.4496 (0.4401) nleep/row_max_mean 1512.0251 (1512.5298) nleep/row_max_std 64.6854 (65.3938) nleep/row_min_mean 1482.3859 (1484.2595) lr 7.0224e-05 eta 0:01:13
epoch [46/50] batch [100/160] time 0.076 (0.101) data 0.000 (0.003) loss 1.4988 (1.1740) teacher_loss 0.7067 (0.3806) loss_zs_kd 0.0157 (0.0156) loss_oracle 0.4911 (0.4381) kd_loss 0.5387 (0.5665) acc 78.1250 (85.3750) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0439 (0.0371) teacher/usage_max 0.9713 (0.9501) teacher/usage_min 0.0098 (0.0113) teacher/usage_std 0.4511 (0.4364) nleep/row_max_mean 1499.3899 (1511.5219) nleep/row_max_std 70.6356 (65.6231) nleep/row_min_mean 1470.3656 (1483.3122) lr 7.0224e-05 eta 0:01:10
epoch [46/50] batch [120/160] time 0.100 (0.100) data 0.000 (0.003) loss 1.3942 (1.1731) teacher_loss 0.6247 (0.3813) loss_zs_kd 0.0247 (0.0156) loss_oracle 0.4563 (0.4385) kd_loss 0.5291 (0.5648) acc 75.0000 (85.4427) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0520 (0.0385) teacher/usage_max 0.9727 (0.9504) teacher/usage_min 0.0120 (0.0116) teacher/usage_std 0.4521 (0.4366) nleep/row_max_mean 1512.8922 (1511.2626) nleep/row_max_std 72.1092 (65.4636) nleep/row_min_mean 1484.5635 (1483.1005) lr 7.0224e-05 eta 0:01:07
epoch [46/50] batch [140/160] time 0.102 (0.099) data 0.000 (0.002) loss 1.1247 (1.1723) teacher_loss 0.3032 (0.3809) loss_zs_kd 0.0095 (0.0156) loss_oracle 0.4831 (0.4367) kd_loss 0.5753 (0.5652) acc 87.5000 (85.2679) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0114 (0.0389) teacher/usage_max 0.9672 (0.9495) teacher/usage_min 0.0008 (0.0118) teacher/usage_std 0.4484 (0.4360) nleep/row_max_mean 1508.3132 (1511.9514) nleep/row_max_std 54.8808 (64.0548) nleep/row_min_mean 1478.3447 (1483.7976) lr 7.0224e-05 eta 0:01:05
epoch [46/50] batch [160/160] time 0.082 (0.098) data 0.000 (0.002) loss 1.2026 (1.1831) teacher_loss 0.3930 (0.3904) loss_zs_kd 0.0141 (0.0156) loss_oracle 0.4616 (0.4373) kd_loss 0.5718 (0.5663) acc 81.2500 (84.9609) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0230 (0.0389) teacher/usage_max 0.9590 (0.9485) teacher/usage_min 0.0004 (0.0120) teacher/usage_std 0.4427 (0.4353) nleep/row_max_mean 1513.3018 (1512.0705) nleep/row_max_std 55.6903 (63.6522) nleep/row_min_mean 1484.1074 (1483.9163) lr 4.8943e-05 eta 0:01:02
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,862
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,976
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 88.9%
******* Domain p best val acc:      84.4%, epoch: 32 *******
******* Domain p best val test acc: 89.0%, epoch: 32 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [47/50] batch [20/160] time 0.081 (0.099) data 0.000 (0.014) loss 1.3238 (1.1982) teacher_loss 0.4778 (0.4029) loss_zs_kd 0.0078 (0.0155) loss_oracle 0.4910 (0.4447) kd_loss 0.5966 (0.5651) acc 84.3750 (85.0000) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0541 (0.0461) teacher/usage_max 0.9026 (0.9424) teacher/usage_min 0.0450 (0.0153) teacher/usage_std 0.4026 (0.4310) nleep/row_max_mean 1510.2043 (1513.8330) nleep/row_max_std 66.8395 (58.5620) nleep/row_min_mean 1482.7295 (1485.5294) lr 4.8943e-05 eta 0:01:01
epoch [47/50] batch [40/160] time 0.078 (0.090) data 0.000 (0.007) loss 1.0073 (1.1655) teacher_loss 0.2465 (0.3727) loss_zs_kd 0.0070 (0.0152) loss_oracle 0.4015 (0.4373) kd_loss 0.5565 (0.5665) acc 87.5000 (85.9375) gate/entropy 0.9767 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0445 (0.0430) teacher/usage_max 0.9526 (0.9441) teacher/usage_min 0.0078 (0.0129) teacher/usage_std 0.4381 (0.4322) nleep/row_max_mean 1509.8680 (1514.2846) nleep/row_max_std 68.7102 (57.6301) nleep/row_min_mean 1484.7053 (1486.2012) lr 4.8943e-05 eta 0:00:54
epoch [47/50] batch [60/160] time 0.086 (0.087) data 0.001 (0.005) loss 1.1506 (1.1682) teacher_loss 0.3458 (0.3720) loss_zs_kd 0.0025 (0.0143) loss_oracle 0.4462 (0.4390) kd_loss 0.5804 (0.5696) acc 84.3750 (85.8333) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0040 (0.0410) teacher/usage_max 0.9694 (0.9431) teacher/usage_min 0.0001 (0.0140) teacher/usage_std 0.4499 (0.4314) nleep/row_max_mean 1523.4668 (1514.1140) nleep/row_max_std 44.0187 (58.3365) nleep/row_min_mean 1492.4418 (1486.0598) lr 4.8943e-05 eta 0:00:50
epoch [47/50] batch [80/160] time 0.077 (0.086) data 0.000 (0.004) loss 1.4379 (1.1737) teacher_loss 0.6575 (0.3789) loss_zs_kd 0.0044 (0.0138) loss_oracle 0.4548 (0.4373) kd_loss 0.5508 (0.5693) acc 71.8750 (85.3906) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0039 (0.0397) teacher/usage_max 0.9992 (0.9447) teacher/usage_min 0.0000 (0.0125) teacher/usage_std 0.4708 (0.4326) nleep/row_max_mean 1511.4601 (1514.5214) nleep/row_max_std 67.1858 (57.5420) nleep/row_min_mean 1482.2883 (1486.3593) lr 4.8943e-05 eta 0:00:48
epoch [47/50] batch [100/160] time 0.098 (0.087) data 0.000 (0.003) loss 0.9873 (1.1764) teacher_loss 0.1958 (0.3804) loss_zs_kd 0.0130 (0.0143) loss_oracle 0.4675 (0.4371) kd_loss 0.5513 (0.5703) acc 93.7500 (85.4688) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0032 (0.0387) teacher/usage_max 0.9995 (0.9446) teacher/usage_min 0.0000 (0.0124) teacher/usage_std 0.4711 (0.4326) nleep/row_max_mean 1529.2043 (1514.3760) nleep/row_max_std 27.3902 (57.7899) nleep/row_min_mean 1499.3560 (1486.3332) lr 4.8943e-05 eta 0:00:46
epoch [47/50] batch [120/160] time 0.098 (0.088) data 0.000 (0.003) loss 1.0638 (1.1763) teacher_loss 0.3123 (0.3817) loss_zs_kd 0.0138 (0.0146) loss_oracle 0.4102 (0.4340) kd_loss 0.5395 (0.5703) acc 87.5000 (85.5469) gate/entropy 0.9767 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0260 (0.0395) teacher/usage_max 0.9884 (0.9439) teacher/usage_min 0.0004 (0.0129) teacher/usage_std 0.4632 (0.4320) nleep/row_max_mean 1519.4080 (1514.3012) nleep/row_max_std 59.0168 (58.6008) nleep/row_min_mean 1490.1100 (1486.2917) lr 4.8943e-05 eta 0:00:45
epoch [47/50] batch [140/160] time 0.084 (0.089) data 0.000 (0.002) loss 1.0254 (1.1755) teacher_loss 0.2103 (0.3816) loss_zs_kd 0.0072 (0.0147) loss_oracle 0.4714 (0.4339) kd_loss 0.5758 (0.5695) acc 87.5000 (85.3795) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0308 (0.0408) teacher/usage_max 0.9470 (0.9434) teacher/usage_min 0.0023 (0.0120) teacher/usage_std 0.4343 (0.4317) nleep/row_max_mean 1524.1670 (1514.8078) nleep/row_max_std 57.5289 (58.9650) nleep/row_min_mean 1493.4686 (1486.8224) lr 4.8943e-05 eta 0:00:44
epoch [47/50] batch [160/160] time 0.084 (0.089) data 0.000 (0.002) loss 1.2821 (1.1785) teacher_loss 0.4674 (0.3835) loss_zs_kd 0.0104 (0.0149) loss_oracle 0.3934 (0.4347) kd_loss 0.6128 (0.5702) acc 87.5000 (85.3320) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0675 (0.0409) teacher/usage_max 0.8730 (0.9425) teacher/usage_min 0.0081 (0.0125) teacher/usage_std 0.3843 (0.4311) nleep/row_max_mean 1513.1700 (1514.7104) nleep/row_max_std 64.8543 (59.7831) nleep/row_min_mean 1487.1050 (1486.6469) lr 3.1417e-05 eta 0:00:42
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,864
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 85.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,977
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 89.0%
******* Domain p best val acc:      84.5%, epoch: 47 *******
******* Domain p best val test acc: 88.2%, epoch: 47 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [48/50] batch [20/160] time 0.098 (0.117) data 0.000 (0.019) loss 0.9435 (1.1497) teacher_loss 0.1657 (0.3627) loss_zs_kd 0.0122 (0.0142) loss_oracle 0.4544 (0.4292) kd_loss 0.5446 (0.5653) acc 100.0000 (85.7812) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1707) teacher/entropy 0.0145 (0.0423) teacher/usage_max 0.9948 (0.9461) teacher/usage_min 0.0001 (0.0116) teacher/usage_std 0.4677 (0.4336) nleep/row_max_mean 1524.4707 (1519.1346) nleep/row_max_std 41.2785 (55.3150) nleep/row_min_mean 1494.0114 (1490.8724) lr 3.1417e-05 eta 0:00:54
epoch [48/50] batch [40/160] time 0.096 (0.107) data 0.000 (0.010) loss 0.9635 (1.1682) teacher_loss 0.2050 (0.3781) loss_zs_kd 0.0138 (0.0151) loss_oracle 0.3882 (0.4281) kd_loss 0.5575 (0.5685) acc 93.7500 (86.2500) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0552 (0.0422) teacher/usage_max 0.9410 (0.9429) teacher/usage_min 0.0054 (0.0130) teacher/usage_std 0.4301 (0.4314) nleep/row_max_mean 1511.7373 (1516.2477) nleep/row_max_std 53.3698 (59.4968) nleep/row_min_mean 1486.1226 (1488.1652) lr 3.1417e-05 eta 0:00:46
epoch [48/50] batch [60/160] time 0.102 (0.104) data 0.001 (0.007) loss 0.9518 (1.1687) teacher_loss 0.2024 (0.3752) loss_zs_kd 0.0273 (0.0150) loss_oracle 0.3844 (0.4290) kd_loss 0.5435 (0.5714) acc 90.6250 (85.7292) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0136 (0.0439) teacher/usage_max 0.9969 (0.9383) teacher/usage_min 0.0010 (0.0146) teacher/usage_std 0.4692 (0.4281) nleep/row_max_mean 1518.4026 (1515.2749) nleep/row_max_std 70.0968 (60.4843) nleep/row_min_mean 1488.9700 (1487.4085) lr 3.1417e-05 eta 0:00:43
epoch [48/50] batch [80/160] time 0.089 (0.101) data 0.000 (0.005) loss 1.2083 (1.1754) teacher_loss 0.4344 (0.3808) loss_zs_kd 0.0262 (0.0155) loss_oracle 0.4316 (0.4334) kd_loss 0.5451 (0.5702) acc 87.5000 (85.6250) gate/entropy 0.9767 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0112 (0.0424) teacher/usage_max 0.9976 (0.9411) teacher/usage_min 0.0001 (0.0146) teacher/usage_std 0.4697 (0.4300) nleep/row_max_mean 1522.1909 (1515.3504) nleep/row_max_std 59.7695 (59.3039) nleep/row_min_mean 1492.5575 (1487.3837) lr 3.1417e-05 eta 0:00:40
epoch [48/50] batch [100/160] time 0.092 (0.100) data 0.000 (0.004) loss 1.1414 (1.1789) teacher_loss 0.3597 (0.3852) loss_zs_kd 0.0177 (0.0158) loss_oracle 0.4210 (0.4332) kd_loss 0.5624 (0.5693) acc 87.5000 (85.4062) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0293 (0.0426) teacher/usage_max 0.9620 (0.9418) teacher/usage_min 0.0084 (0.0142) teacher/usage_std 0.4446 (0.4306) nleep/row_max_mean 1516.1504 (1514.6788) nleep/row_max_std 55.6553 (59.6009) nleep/row_min_mean 1486.6802 (1486.6517) lr 3.1417e-05 eta 0:00:37
epoch [48/50] batch [120/160] time 0.091 (0.099) data 0.000 (0.003) loss 1.0796 (1.1741) teacher_loss 0.2364 (0.3789) loss_zs_kd 0.0241 (0.0156) loss_oracle 0.4646 (0.4341) kd_loss 0.5989 (0.5704) acc 93.7500 (85.7031) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5745 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0205 (0.0421) teacher/usage_max 0.9344 (0.9412) teacher/usage_min 0.0307 (0.0145) teacher/usage_std 0.4250 (0.4301) nleep/row_max_mean 1501.9070 (1514.5774) nleep/row_max_std 65.6425 (59.9725) nleep/row_min_mean 1472.5913 (1486.5698) lr 3.1417e-05 eta 0:00:35
epoch [48/50] batch [140/160] time 0.100 (0.098) data 0.000 (0.003) loss 1.2808 (1.1762) teacher_loss 0.4617 (0.3827) loss_zs_kd 0.0295 (0.0162) loss_oracle 0.3982 (0.4328) kd_loss 0.6053 (0.5690) acc 84.3750 (85.5134) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0428 (0.0434) teacher/usage_max 0.9054 (0.9412) teacher/usage_min 0.0319 (0.0145) teacher/usage_std 0.4047 (0.4302) nleep/row_max_mean 1504.1210 (1514.1949) nleep/row_max_std 65.1476 (60.5942) nleep/row_min_mean 1478.4868 (1486.2289) lr 3.1417e-05 eta 0:00:33
epoch [48/50] batch [160/160] time 0.087 (0.097) data 0.000 (0.003) loss 1.6989 (1.1801) teacher_loss 0.9598 (0.3862) loss_zs_kd 0.0172 (0.0161) loss_oracle 0.3659 (0.4324) kd_loss 0.5476 (0.5697) acc 65.6250 (85.2930) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0647 (0.0429) teacher/usage_max 0.9414 (0.9410) teacher/usage_min 0.0070 (0.0139) teacher/usage_std 0.4304 (0.4301) nleep/row_max_mean 1508.2382 (1513.9665) nleep/row_max_std 59.8836 (60.7150) nleep/row_min_mean 1483.1188 (1486.0092) lr 1.7713e-05 eta 0:00:31
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,862
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,976
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 88.9%
******* Domain p best val acc:      84.5%, epoch: 47 *******
******* Domain p best val test acc: 88.2%, epoch: 47 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [49/50] batch [20/160] time 0.096 (0.095) data 0.000 (0.013) loss 1.2278 (1.2130) teacher_loss 0.4627 (0.4088) loss_zs_kd 0.0234 (0.0169) loss_oracle 0.4182 (0.4486) kd_loss 0.5443 (0.5714) acc 84.3750 (86.0938) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0392 (0.0450) teacher/usage_max 0.9703 (0.9372) teacher/usage_min 0.0054 (0.0143) teacher/usage_std 0.4505 (0.4274) nleep/row_max_mean 1505.6531 (1511.7756) nleep/row_max_std 72.6089 (62.8208) nleep/row_min_mean 1476.7065 (1484.0898) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [40/160] time 0.094 (0.091) data 0.000 (0.006) loss 1.2244 (1.1901) teacher_loss 0.4137 (0.3856) loss_zs_kd 0.0113 (0.0163) loss_oracle 0.4195 (0.4450) kd_loss 0.5953 (0.5739) acc 78.1250 (86.2500) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0254 (0.0446) teacher/usage_max 0.9329 (0.9351) teacher/usage_min 0.0001 (0.0166) teacher/usage_std 0.4248 (0.4258) nleep/row_max_mean 1516.3979 (1513.9550) nleep/row_max_std 55.3713 (58.5615) nleep/row_min_mean 1490.1887 (1485.7722) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [60/160] time 0.099 (0.092) data 0.001 (0.004) loss 1.3488 (1.1797) teacher_loss 0.5710 (0.3812) loss_zs_kd 0.0063 (0.0151) loss_oracle 0.4091 (0.4406) kd_loss 0.5701 (0.5707) acc 75.0000 (85.8333) gate/entropy 0.9767 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0195 (0.0419) teacher/usage_max 0.9640 (0.9411) teacher/usage_min 0.0038 (0.0149) teacher/usage_std 0.4461 (0.4300) nleep/row_max_mean 1506.2655 (1511.7436) nleep/row_max_std 75.4802 (63.2791) nleep/row_min_mean 1477.1534 (1483.6641) lr 1.7713e-05 eta 0:00:23
epoch [49/50] batch [80/160] time 0.085 (0.092) data 0.000 (0.003) loss 1.0932 (1.1849) teacher_loss 0.2832 (0.3818) loss_zs_kd 0.0227 (0.0159) loss_oracle 0.4172 (0.4417) kd_loss 0.5900 (0.5743) acc 90.6250 (86.0156) gate/entropy 0.9767 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0542 (0.0403) teacher/usage_max 0.9092 (0.9391) teacher/usage_min 0.0108 (0.0149) teacher/usage_std 0.4082 (0.4286) nleep/row_max_mean 1512.6409 (1512.5738) nleep/row_max_std 77.5354 (61.6253) nleep/row_min_mean 1484.2368 (1484.5327) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [100/160] time 0.090 (0.095) data 0.000 (0.003) loss 1.1355 (1.1777) teacher_loss 0.3404 (0.3769) loss_zs_kd 0.0096 (0.0160) loss_oracle 0.3837 (0.4385) kd_loss 0.5985 (0.5735) acc 90.6250 (86.1875) gate/entropy 0.9769 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.1040 (0.0431) teacher/usage_max 0.8507 (0.9370) teacher/usage_min 0.0426 (0.0158) teacher/usage_std 0.3668 (0.4272) nleep/row_max_mean 1491.2590 (1512.9044) nleep/row_max_std 82.3124 (61.7761) nleep/row_min_mean 1467.1248 (1485.0612) lr 1.7713e-05 eta 0:00:20
epoch [49/50] batch [120/160] time 0.070 (0.093) data 0.000 (0.002) loss 1.3925 (1.1838) teacher_loss 0.5606 (0.3829) loss_zs_kd 0.0130 (0.0160) loss_oracle 0.4409 (0.4389) kd_loss 0.6050 (0.5734) acc 81.2500 (85.7292) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0645 (0.0409) teacher/usage_max 0.8839 (0.9393) teacher/usage_min 0.0003 (0.0139) teacher/usage_std 0.3921 (0.4288) nleep/row_max_mean 1508.3977 (1513.0647) nleep/row_max_std 69.5397 (61.4215) nleep/row_min_mean 1481.4382 (1485.1822) lr 1.7713e-05 eta 0:00:18
epoch [49/50] batch [140/160] time 0.098 (0.091) data 0.000 (0.002) loss 1.0650 (1.1831) teacher_loss 0.2787 (0.3802) loss_zs_kd 0.0384 (0.0164) loss_oracle 0.4054 (0.4402) kd_loss 0.5645 (0.5747) acc 90.6250 (85.6696) gate/entropy 0.9767 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0390 (0.0408) teacher/usage_max 0.9501 (0.9382) teacher/usage_min 0.0066 (0.0141) teacher/usage_std 0.4364 (0.4280) nleep/row_max_mean 1532.3533 (1513.1099) nleep/row_max_std 48.6133 (61.2791) nleep/row_min_mean 1501.9769 (1485.1479) lr 1.7713e-05 eta 0:00:16
epoch [49/50] batch [160/160] time 0.088 (0.091) data 0.000 (0.002) loss 1.1185 (1.1836) teacher_loss 0.3293 (0.3817) loss_zs_kd 0.0079 (0.0160) loss_oracle 0.3963 (0.4399) kd_loss 0.5871 (0.5740) acc 90.6250 (85.7031) gate/entropy 0.9767 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0389 (0.0403) teacher/usage_max 0.9274 (0.9393) teacher/usage_min 0.0017 (0.0137) teacher/usage_std 0.4210 (0.4289) nleep/row_max_mean 1525.3708 (1512.8234) nleep/row_max_std 62.6800 (62.0937) nleep/row_min_mean 1501.6749 (1484.9000) lr 7.8853e-06 eta 0:00:14
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,861
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,977
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 89.0%
******* Domain p best val acc:      84.5%, epoch: 47 *******
******* Domain p best val test acc: 88.2%, epoch: 47 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
epoch [50/50] batch [20/160] time 0.084 (0.103) data 0.000 (0.017) loss 1.1774 (1.2042) teacher_loss 0.4014 (0.4020) loss_zs_kd 0.0179 (0.0145) loss_oracle 0.4114 (0.4251) kd_loss 0.5614 (0.5824) acc 87.5000 (86.8750) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0580 (0.0420) teacher/usage_max 0.9342 (0.9292) teacher/usage_min 0.0124 (0.0086) teacher/usage_std 0.4252 (0.4221) nleep/row_max_mean 1504.7356 (1512.7203) nleep/row_max_std 71.2044 (63.7684) nleep/row_min_mean 1478.6497 (1485.4733) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [40/160] time 0.086 (0.096) data 0.000 (0.008) loss 1.1147 (1.1969) teacher_loss 0.3454 (0.3926) loss_zs_kd 0.0097 (0.0145) loss_oracle 0.4237 (0.4324) kd_loss 0.5526 (0.5809) acc 87.5000 (85.6250) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0554 (0.0397) teacher/usage_max 0.9456 (0.9330) teacher/usage_min 0.0136 (0.0131) teacher/usage_std 0.4331 (0.4246) nleep/row_max_mean 1501.4060 (1512.6030) nleep/row_max_std 78.1874 (62.2365) nleep/row_min_mean 1473.8114 (1484.9046) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [60/160] time 0.098 (0.095) data 0.001 (0.006) loss 1.2659 (1.1827) teacher_loss 0.4461 (0.3843) loss_zs_kd 0.0116 (0.0154) loss_oracle 0.4970 (0.4307) kd_loss 0.5656 (0.5753) acc 78.1250 (85.7292) gate/entropy 0.9767 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0446 (0.0405) teacher/usage_max 0.9433 (0.9378) teacher/usage_min 0.0052 (0.0123) teacher/usage_std 0.4318 (0.4279) nleep/row_max_mean 1523.4174 (1512.3527) nleep/row_max_std 47.9547 (63.0515) nleep/row_min_mean 1493.1455 (1484.5862) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [80/160] time 0.105 (0.095) data 0.000 (0.004) loss 1.2885 (1.1826) teacher_loss 0.5556 (0.3828) loss_zs_kd 0.0074 (0.0153) loss_oracle 0.3792 (0.4325) kd_loss 0.5396 (0.5759) acc 78.1250 (85.7422) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0385 (0.0422) teacher/usage_max 0.9758 (0.9354) teacher/usage_min 0.0047 (0.0124) teacher/usage_std 0.4543 (0.4263) nleep/row_max_mean 1509.7284 (1512.3582) nleep/row_max_std 71.8478 (64.1836) nleep/row_min_mean 1480.2998 (1484.5292) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [100/160] time 0.086 (0.096) data 0.000 (0.004) loss 1.0498 (1.1782) teacher_loss 0.2095 (0.3793) loss_zs_kd 0.0159 (0.0157) loss_oracle 0.4569 (0.4339) kd_loss 0.6040 (0.5740) acc 93.7500 (85.7500) gate/entropy 0.9767 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0749 (0.0423) teacher/usage_max 0.8742 (0.9373) teacher/usage_min 0.0476 (0.0129) teacher/usage_std 0.3827 (0.4275) nleep/row_max_mean 1519.8378 (1512.8648) nleep/row_max_std 65.8176 (63.5815) nleep/row_min_mean 1491.5754 (1485.0394) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [120/160] time 0.091 (0.095) data 0.000 (0.003) loss 0.9572 (1.1774) teacher_loss 0.2196 (0.3788) loss_zs_kd 0.0134 (0.0151) loss_oracle 0.3993 (0.4346) kd_loss 0.5313 (0.5737) acc 93.7500 (85.7292) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5746 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0491 (0.0418) teacher/usage_max 0.9734 (0.9381) teacher/usage_min 0.0052 (0.0128) teacher/usage_std 0.4527 (0.4281) nleep/row_max_mean 1508.3347 (1512.5720) nleep/row_max_std 68.9313 (63.7783) nleep/row_min_mean 1478.1219 (1484.7542) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [140/160] time 0.094 (0.095) data 0.000 (0.003) loss 1.1529 (1.1817) teacher_loss 0.3279 (0.3805) loss_zs_kd 0.0129 (0.0150) loss_oracle 0.4408 (0.4367) kd_loss 0.5981 (0.5754) acc 90.6250 (85.7589) gate/entropy 0.9768 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1706 (0.1706) teacher/entropy 0.0389 (0.0423) teacher/usage_max 0.9165 (0.9359) teacher/usage_min 0.0265 (0.0136) teacher/usage_std 0.4125 (0.4265) nleep/row_max_mean 1513.2063 (1511.7735) nleep/row_max_std 71.4754 (65.2299) nleep/row_min_mean 1483.5349 (1483.9933) lr 7.8853e-06 eta 0:00:01
epoch [50/50] batch [160/160] time 0.088 (0.094) data 0.000 (0.002) loss 1.2984 (1.1866) teacher_loss 0.4328 (0.3849) loss_zs_kd 0.0168 (0.0152) loss_oracle 0.4320 (0.4376) kd_loss 0.6411 (0.5753) acc 81.2500 (85.4688) gate/entropy 0.9767 (0.9768) gate/usage_max 0.5747 (0.5747) gate/usage_min 0.2126 (0.2126) gate/usage_std 0.1707 (0.1706) teacher/entropy 0.0471 (0.0412) teacher/usage_max 0.8650 (0.9370) teacher/usage_min 0.0051 (0.0132) teacher/usage_std 0.3794 (0.4273) nleep/row_max_mean 1508.9155 (1512.0387) nleep/row_max_std 70.2306 (65.1428) nleep/row_min_mean 1482.0677 (1484.1609) lr 1.9733e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,862
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 85.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,977
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 89.0%
******* Domain p best val acc:      84.5%, epoch: 47 *******
******* Domain p best val test acc: 88.2%, epoch: 47 *******
******* Domain p best test acc:     89.5%, epoch: 13 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:17:14

Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'sun']
Target     ['pascal']
# classes  5
# train_x  5,147
# val      2,206
# test     3,376
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/tensorboard)
epoch [1/50] batch [20/160] time 0.132 (0.165) data 0.000 (0.025) loss 1.2721 (1.2343) teacher_loss 0.7983 (0.6787) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0008 (0.0002) kd_loss 0.4734 (0.5556) acc 71.8750 (75.4688) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3312 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.6260 (0.5444) teacher/usage_max 0.3962 (0.4744) teacher/usage_min 0.2903 (0.2313) teacher/usage_std 0.0455 (0.1052) nleep/row_max_mean 1525.0288 (1532.5052) nleep/row_max_std 75.8094 (55.8037) nleep/row_min_mean 1521.5259 (1527.7872) lr 1.0000e-05 eta 0:21:56
epoch [1/50] batch [40/160] time 0.098 (0.141) data 0.000 (0.013) loss 1.0076 (1.1485) teacher_loss 0.6720 (0.6659) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0018 (0.0008) kd_loss 0.3346 (0.4822) acc 75.0000 (75.7031) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.7658 (0.6177) teacher/usage_max 0.5492 (0.4721) teacher/usage_min 0.2090 (0.2302) teacher/usage_std 0.1532 (0.1044) nleep/row_max_mean 1518.7971 (1529.5475) nleep/row_max_std 71.4663 (59.0552) nleep/row_min_mean 1516.1426 (1525.6959) lr 1.0000e-05 eta 0:18:43
epoch [1/50] batch [60/160] time 0.123 (0.130) data 0.000 (0.009) loss 0.7814 (1.1285) teacher_loss 0.5321 (0.6924) loss_zs_kd 0.0004 (0.0002) loss_oracle 0.0042 (0.0017) kd_loss 0.2470 (0.4352) acc 81.2500 (75.2083) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3312 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.8530 (0.6647) teacher/usage_max 0.4732 (0.4697) teacher/usage_min 0.2524 (0.2333) teacher/usage_std 0.0993 (0.1021) nleep/row_max_mean 1534.7770 (1528.6450) nleep/row_max_std 69.7150 (59.1135) nleep/row_min_mean 1532.9285 (1525.2868) lr 1.0000e-05 eta 0:17:11
epoch [1/50] batch [80/160] time 0.135 (0.130) data 0.000 (0.007) loss 1.1110 (1.0902) teacher_loss 0.9108 (0.7018) loss_zs_kd 0.0006 (0.0003) loss_oracle 0.0064 (0.0024) kd_loss 0.1967 (0.3870) acc 75.0000 (74.4531) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3314 (0.3313) gate/usage_std 0.0014 (0.0015) teacher/entropy 0.9027 (0.7127) teacher/usage_max 0.4196 (0.4583) teacher/usage_min 0.2761 (0.2403) teacher/usage_std 0.0621 (0.0942) nleep/row_max_mean 1525.4740 (1527.4016) nleep/row_max_std 73.4908 (59.7032) nleep/row_min_mean 1523.9672 (1524.4461) lr 1.0000e-05 eta 0:17:10
epoch [1/50] batch [100/160] time 0.154 (0.130) data 0.000 (0.005) loss 0.7742 (1.0497) teacher_loss 0.6263 (0.6979) loss_zs_kd 0.0013 (0.0004) loss_oracle 0.0064 (0.0031) kd_loss 0.1441 (0.3500) acc 81.2500 (74.6562) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.9551 (0.7496) teacher/usage_max 0.3998 (0.4486) teacher/usage_min 0.2702 (0.2461) teacher/usage_std 0.0530 (0.0873) nleep/row_max_mean 1514.2443 (1526.0819) nleep/row_max_std 67.8350 (60.1045) nleep/row_min_mean 1513.0591 (1523.4143) lr 1.0000e-05 eta 0:17:09
epoch [1/50] batch [120/160] time 0.138 (0.130) data 0.000 (0.004) loss 0.8342 (1.0059) teacher_loss 0.7047 (0.6872) loss_zs_kd 0.0012 (0.0005) loss_oracle 0.0088 (0.0038) kd_loss 0.1245 (0.3165) acc 75.0000 (74.9740) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3348) gate/usage_min 0.3312 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.9747 (0.7830) teacher/usage_max 0.3983 (0.4386) teacher/usage_min 0.3002 (0.2523) teacher/usage_std 0.0460 (0.0803) nleep/row_max_mean 1492.2166 (1525.8698) nleep/row_max_std 109.2258 (58.6679) nleep/row_min_mean 1491.0973 (1523.4395) lr 1.0000e-05 eta 0:17:06
epoch [1/50] batch [140/160] time 0.137 (0.131) data 0.000 (0.004) loss 0.6288 (0.9751) teacher_loss 0.4993 (0.6835) loss_zs_kd 0.0009 (0.0006) loss_oracle 0.0080 (0.0045) kd_loss 0.1251 (0.2891) acc 87.5000 (75.0893) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.9735 (0.8103) teacher/usage_max 0.3894 (0.4300) teacher/usage_min 0.2822 (0.2584) teacher/usage_std 0.0439 (0.0740) nleep/row_max_mean 1525.0400 (1525.3536) nleep/row_max_std 37.2201 (58.4116) nleep/row_min_mean 1523.9004 (1523.1124) lr 1.0000e-05 eta 0:17:09
epoch [1/50] batch [160/160] time 0.115 (0.131) data 0.000 (0.003) loss 1.0558 (0.9558) teacher_loss 0.9573 (0.6865) loss_zs_kd 0.0038 (0.0008) loss_oracle 0.0132 (0.0052) kd_loss 0.0899 (0.2663) acc 65.6250 (75.0000) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3347 (0.3348) gate/usage_min 0.3313 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 1.0085 (0.8330) teacher/usage_max 0.3476 (0.4245) teacher/usage_min 0.3206 (0.2617) teacher/usage_std 0.0111 (0.0702) nleep/row_max_mean 1524.6951 (1525.0851) nleep/row_max_std 71.2403 (58.0662) nleep/row_min_mean 1523.7267 (1522.9976) lr 2.0000e-03 eta 0:17:09
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,726
* accuracy: 78.2%
* error: 21.8%
* macro_f1: 80.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,923
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      78.2%, epoch: 1 *******
******* Domain p best val test acc: 86.6%, epoch: 1 *******
******* Domain p best test acc:     86.6%, epoch: 1 *******
epoch [2/50] batch [20/160] time 0.095 (0.133) data 0.000 (0.013) loss 0.8981 (0.8155) teacher_loss 0.6581 (0.6056) loss_zs_kd 0.0092 (0.0100) loss_oracle 0.1270 (0.1276) kd_loss 0.1719 (0.1412) acc 71.8750 (78.2812) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3351 (0.3350) gate/usage_min 0.3316 (0.3313) gate/usage_std 0.0015 (0.0015) teacher/entropy 0.9274 (0.9580) teacher/usage_max 0.4813 (0.4353) teacher/usage_min 0.1843 (0.2294) teacher/usage_std 0.1212 (0.0856) nleep/row_max_mean 1525.3077 (1524.0073) nleep/row_max_std 54.0345 (60.8646) nleep/row_min_mean 1523.9065 (1522.7810) lr 2.0000e-03 eta 0:17:21
epoch [2/50] batch [40/160] time 0.106 (0.121) data 0.000 (0.007) loss 1.3454 (0.9306) teacher_loss 0.6200 (0.5692) loss_zs_kd 0.0119 (0.0100) loss_oracle 0.3972 (0.2088) kd_loss 0.5209 (0.2521) acc 78.1250 (79.5312) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3343 (0.3349) gate/usage_min 0.3327 (0.3317) gate/usage_std 0.0007 (0.0013) teacher/entropy 0.5778 (0.8473) teacher/usage_max 0.6460 (0.5197) teacher/usage_min 0.0900 (0.1886) teacher/usage_std 0.2322 (0.1415) nleep/row_max_mean 1536.0632 (1526.2116) nleep/row_max_std 43.4927 (60.0171) nleep/row_min_mean 1532.3662 (1524.4131) lr 2.0000e-03 eta 0:15:46
epoch [2/50] batch [60/160] time 0.086 (0.118) data 0.000 (0.004) loss 1.1254 (1.0347) teacher_loss 0.3879 (0.5449) loss_zs_kd 0.0180 (0.0121) loss_oracle 0.3779 (0.2832) kd_loss 0.5396 (0.3422) acc 87.5000 (81.0938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3349 (0.3347) gate/usage_min 0.3318 (0.3319) gate/usage_std 0.0013 (0.0012) teacher/entropy 0.5568 (0.7565) teacher/usage_max 0.5471 (0.5271) teacher/usage_min 0.0627 (0.1508) teacher/usage_std 0.2018 (0.1601) nleep/row_max_mean 1547.9912 (1526.8951) nleep/row_max_std 26.2305 (62.8506) nleep/row_min_mean 1543.3323 (1524.4664) lr 2.0000e-03 eta 0:15:18
epoch [2/50] batch [80/160] time 0.077 (0.116) data 0.000 (0.003) loss 1.2424 (1.1071) teacher_loss 0.2709 (0.5167) loss_zs_kd 0.0194 (0.0149) loss_oracle 0.5285 (0.3403) kd_loss 0.6975 (0.4129) acc 90.6250 (82.3828) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3358 (0.3349) gate/usage_min 0.3305 (0.3316) gate/usage_std 0.0022 (0.0014) teacher/entropy 0.3975 (0.6850) teacher/usage_max 0.5001 (0.5226) teacher/usage_min 0.0678 (0.1340) teacher/usage_std 0.1898 (0.1663) nleep/row_max_mean 1542.1104 (1527.7829) nleep/row_max_std 69.9455 (63.2587) nleep/row_min_mean 1536.8024 (1524.7993) lr 2.0000e-03 eta 0:15:02
epoch [2/50] batch [100/160] time 0.085 (0.115) data 0.000 (0.003) loss 1.2640 (1.1535) teacher_loss 0.2006 (0.4884) loss_zs_kd 0.0329 (0.0177) loss_oracle 0.4629 (0.3660) kd_loss 0.8154 (0.4732) acc 96.8750 (83.5000) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3370 (0.3352) gate/usage_min 0.3298 (0.3313) gate/usage_std 0.0029 (0.0016) teacher/entropy 0.2780 (0.6240) teacher/usage_max 0.5669 (0.5260) teacher/usage_min 0.0951 (0.1302) teacher/usage_std 0.1926 (0.1690) nleep/row_max_mean 1547.2192 (1527.9723) nleep/row_max_std 38.3259 (65.0960) nleep/row_min_mean 1540.4587 (1524.4837) lr 2.0000e-03 eta 0:14:52
epoch [2/50] batch [120/160] time 0.163 (0.113) data 0.000 (0.002) loss 1.4818 (1.1956) teacher_loss 0.5357 (0.4731) loss_zs_kd 0.0181 (0.0198) loss_oracle 0.4857 (0.3916) kd_loss 0.6942 (0.5168) acc 84.3750 (84.0365) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3387 (0.3356) gate/usage_min 0.3293 (0.3310) gate/usage_std 0.0040 (0.0019) teacher/entropy 0.4010 (0.5799) teacher/usage_max 0.4431 (0.5302) teacher/usage_min 0.1753 (0.1346) teacher/usage_std 0.1145 (0.1689) nleep/row_max_mean 1529.5791 (1528.4512) nleep/row_max_std 77.9126 (65.7283) nleep/row_min_mean 1523.6174 (1524.4058) lr 2.0000e-03 eta 0:14:32
epoch [2/50] batch [140/160] time 0.168 (0.115) data 0.000 (0.002) loss 1.1772 (1.2269) teacher_loss 0.2147 (0.4546) loss_zs_kd 0.0166 (0.0206) loss_oracle 0.6212 (0.4205) kd_loss 0.6436 (0.5517) acc 96.8750 (84.6429) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3403 (0.3362) gate/usage_min 0.3296 (0.3308) gate/usage_std 0.0049 (0.0023) teacher/entropy 0.4515 (0.5444) teacher/usage_max 0.4579 (0.5328) teacher/usage_min 0.1249 (0.1396) teacher/usage_std 0.1483 (0.1682) nleep/row_max_mean 1524.6929 (1528.9521) nleep/row_max_std 81.4254 (65.5749) nleep/row_min_mean 1517.8534 (1524.3973) lr 2.0000e-03 eta 0:14:47
epoch [2/50] batch [160/160] time 0.070 (0.114) data 0.000 (0.002) loss 1.5493 (1.2573) teacher_loss 0.5329 (0.4437) loss_zs_kd 0.0177 (0.0211) loss_oracle 0.5065 (0.4418) kd_loss 0.7543 (0.5822) acc 78.1250 (84.8242) gate/entropy 1.0984 (1.0986) gate/usage_max 0.3418 (0.3368) gate/usage_min 0.3270 (0.3305) gate/usage_std 0.0062 (0.0027) teacher/entropy 0.3317 (0.5132) teacher/usage_max 0.6293 (0.5377) teacher/usage_min 0.0707 (0.1335) teacher/usage_std 0.2293 (0.1725) nleep/row_max_mean 1529.3341 (1529.3159) nleep/row_max_std 102.9837 (65.7206) nleep/row_min_mean 1520.1553 (1524.2048) lr 1.9980e-03 eta 0:14:38
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,809
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,945
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 88.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.0%, epoch: 2 *******
******* Domain p best val test acc: 87.2%, epoch: 2 *******
******* Domain p best test acc:     87.2%, epoch: 2 *******
epoch [3/50] batch [20/160] time 0.131 (0.153) data 0.000 (0.017) loss 1.5249 (1.5066) teacher_loss 0.3378 (0.3144) loss_zs_kd 0.0479 (0.0304) loss_oracle 0.6082 (0.6154) kd_loss 0.8591 (0.8693) acc 81.2500 (88.2812) gate/entropy 1.0983 (1.0984) gate/usage_max 0.3434 (0.3426) gate/usage_min 0.3231 (0.3250) gate/usage_std 0.0083 (0.0072) teacher/entropy 0.2231 (0.2167) teacher/usage_max 0.5984 (0.5543) teacher/usage_min 0.0442 (0.0483) teacher/usage_std 0.2269 (0.2157) nleep/row_max_mean 1548.8611 (1531.8701) nleep/row_max_std 46.8497 (61.3655) nleep/row_min_mean 1537.3416 (1520.9028) lr 1.9980e-03 eta 0:19:34
epoch [3/50] batch [40/160] time 0.106 (0.146) data 0.000 (0.008) loss 1.5218 (1.5698) teacher_loss 0.2671 (0.3516) loss_zs_kd 0.0246 (0.0307) loss_oracle 0.6731 (0.6400) kd_loss 0.9058 (0.8828) acc 87.5000 (86.4844) gate/entropy 1.0981 (1.0983) gate/usage_max 0.3443 (0.3432) gate/usage_min 0.3193 (0.3231) gate/usage_std 0.0104 (0.0083) teacher/entropy 0.1750 (0.2015) teacher/usage_max 0.4792 (0.5390) teacher/usage_min 0.0471 (0.0433) teacher/usage_std 0.2024 (0.2147) nleep/row_max_mean 1536.5774 (1529.8653) nleep/row_max_std 72.4071 (64.9946) nleep/row_min_mean 1522.9633 (1518.0604) lr 1.9980e-03 eta 0:18:33
epoch [3/50] batch [60/160] time 0.160 (0.145) data 0.000 (0.006) loss 1.7173 (1.6083) teacher_loss 0.4442 (0.3745) loss_zs_kd 0.0164 (0.0291) loss_oracle 0.7001 (0.6518) kd_loss 0.9149 (0.8934) acc 84.3750 (86.0417) gate/entropy 1.0978 (1.0982) gate/usage_max 0.3450 (0.3437) gate/usage_min 0.3151 (0.3211) gate/usage_std 0.0131 (0.0094) teacher/entropy 0.1578 (0.1882) teacher/usage_max 0.5309 (0.5488) teacher/usage_min 0.0064 (0.0342) teacher/usage_std 0.2329 (0.2225) nleep/row_max_mean 1528.6635 (1530.3572) nleep/row_max_std 83.7736 (64.6672) nleep/row_min_mean 1513.6877 (1517.3290) lr 1.9980e-03 eta 0:18:21
epoch [3/50] batch [80/160] time 0.134 (0.141) data 0.000 (0.004) loss 1.6388 (1.6173) teacher_loss 0.3993 (0.3745) loss_zs_kd 0.0300 (0.0288) loss_oracle 0.6787 (0.6537) kd_loss 0.8851 (0.9015) acc 81.2500 (86.3672) gate/entropy 1.0974 (1.0981) gate/usage_max 0.3458 (0.3441) gate/usage_min 0.3107 (0.3191) gate/usage_std 0.0160 (0.0107) teacher/entropy 0.1806 (0.1769) teacher/usage_max 0.5145 (0.5514) teacher/usage_min 0.0060 (0.0271) teacher/usage_std 0.2319 (0.2268) nleep/row_max_mean 1549.1892 (1531.6148) nleep/row_max_std 31.9112 (64.2111) nleep/row_min_mean 1530.1846 (1517.4284) lr 1.9980e-03 eta 0:17:53
epoch [3/50] batch [100/160] time 0.153 (0.140) data 0.000 (0.003) loss 1.4376 (1.6106) teacher_loss 0.1982 (0.3604) loss_zs_kd 0.0190 (0.0276) loss_oracle 0.6917 (0.6608) kd_loss 0.8840 (0.9061) acc 90.6250 (86.8750) gate/entropy 1.0970 (1.0979) gate/usage_max 0.3477 (0.3445) gate/usage_min 0.3068 (0.3170) gate/usage_std 0.0188 (0.0120) teacher/entropy 0.1761 (0.1693) teacher/usage_max 0.6851 (0.5640) teacher/usage_min 0.0144 (0.0232) teacher/usage_std 0.2748 (0.2324) nleep/row_max_mean 1503.2285 (1532.0892) nleep/row_max_std 118.2608 (63.4114) nleep/row_min_mean 1484.8069 (1516.9557) lr 1.9980e-03 eta 0:17:39
epoch [3/50] batch [120/160] time 0.128 (0.137) data 0.000 (0.003) loss 1.4819 (1.6152) teacher_loss 0.2266 (0.3629) loss_zs_kd 0.0358 (0.0286) loss_oracle 0.5507 (0.6570) kd_loss 0.9621 (0.9094) acc 90.6250 (86.6146) gate/entropy 1.0964 (1.0977) gate/usage_max 0.3524 (0.3454) gate/usage_min 0.3029 (0.3150) gate/usage_std 0.0218 (0.0134) teacher/entropy 0.0900 (0.1626) teacher/usage_max 0.5933 (0.5738) teacher/usage_min 0.0025 (0.0202) teacher/usage_std 0.2463 (0.2367) nleep/row_max_mean 1504.5339 (1532.6749) nleep/row_max_std 87.3996 (62.9475) nleep/row_min_mean 1484.1746 (1516.6767) lr 1.9980e-03 eta 0:17:17
epoch [3/50] batch [140/160] time 0.072 (0.134) data 0.000 (0.003) loss 1.4811 (1.6170) teacher_loss 0.1750 (0.3626) loss_zs_kd 0.0320 (0.0290) loss_oracle 0.6997 (0.6529) kd_loss 0.9402 (0.9135) acc 96.8750 (86.7634) gate/entropy 1.0958 (1.0975) gate/usage_max 0.3571 (0.3468) gate/usage_min 0.2990 (0.3129) gate/usage_std 0.0249 (0.0149) teacher/entropy 0.1059 (0.1551) teacher/usage_max 0.5630 (0.5838) teacher/usage_min 0.0002 (0.0181) teacher/usage_std 0.2412 (0.2410) nleep/row_max_mean 1530.9431 (1532.0562) nleep/row_max_std 46.5029 (64.0312) nleep/row_min_mean 1509.1854 (1515.3074) lr 1.9980e-03 eta 0:16:51
epoch [3/50] batch [160/160] time 0.082 (0.130) data 0.000 (0.002) loss 2.1749 (1.6260) teacher_loss 0.8165 (0.3650) loss_zs_kd 0.0307 (0.0296) loss_oracle 0.7635 (0.6591) kd_loss 0.9614 (0.9167) acc 75.0000 (87.0312) gate/entropy 1.0949 (1.0972) gate/usage_max 0.3623 (0.3484) gate/usage_min 0.2949 (0.3109) gate/usage_std 0.0283 (0.0163) teacher/entropy 0.0660 (0.1480) teacher/usage_max 0.7854 (0.5967) teacher/usage_min 0.0011 (0.0159) teacher/usage_std 0.3312 (0.2467) nleep/row_max_mean 1520.8628 (1532.0213) nleep/row_max_std 95.4319 (64.4050) nleep/row_min_mean 1497.9812 (1514.5744) lr 1.9921e-03 eta 0:16:15
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,816
* accuracy: 82.3%
* error: 17.7%
* macro_f1: 84.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,963
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.3%, epoch: 3 *******
******* Domain p best val test acc: 87.8%, epoch: 3 *******
******* Domain p best test acc:     87.8%, epoch: 3 *******
epoch [4/50] batch [20/160] time 0.118 (0.100) data 0.000 (0.014) loss 1.6314 (1.6676) teacher_loss 0.2346 (0.3259) loss_zs_kd 0.0558 (0.0471) loss_oracle 0.7957 (0.7286) kd_loss 0.9710 (0.9538) acc 90.6250 (89.6875) gate/entropy 1.0940 (1.0945) gate/usage_max 0.3680 (0.3653) gate/usage_min 0.2911 (0.2929) gate/usage_std 0.0319 (0.0302) teacher/entropy 0.0470 (0.0715) teacher/usage_max 0.7619 (0.7267) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.3182 (0.3018) nleep/row_max_mean 1545.4597 (1535.4593) nleep/row_max_std 50.0074 (63.4463) nleep/row_min_mean 1516.4857 (1510.3600) lr 1.9921e-03 eta 0:12:30
epoch [4/50] batch [40/160] time 0.062 (0.089) data 0.000 (0.007) loss 1.4663 (1.6210) teacher_loss 0.1508 (0.2861) loss_zs_kd 0.0490 (0.0474) loss_oracle 0.7267 (0.7306) kd_loss 0.9277 (0.9459) acc 100.0000 (91.0938) gate/entropy 1.0928 (1.0939) gate/usage_max 0.3742 (0.3682) gate/usage_min 0.2871 (0.2909) gate/usage_std 0.0358 (0.0320) teacher/entropy 0.0879 (0.0741) teacher/usage_max 0.6706 (0.7283) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.2738 (0.3029) nleep/row_max_mean 1544.2891 (1536.2960) nleep/row_max_std 51.0159 (65.0940) nleep/row_min_mean 1518.6921 (1510.8202) lr 1.9921e-03 eta 0:11:04
epoch [4/50] batch [60/160] time 0.111 (0.092) data 0.001 (0.005) loss 1.6055 (1.6234) teacher_loss 0.3090 (0.2928) loss_zs_kd 0.0468 (0.0485) loss_oracle 0.7097 (0.7312) kd_loss 0.9182 (0.9407) acc 93.7500 (91.0938) gate/entropy 1.0915 (1.0933) gate/usage_max 0.3804 (0.3713) gate/usage_min 0.2834 (0.2890) gate/usage_std 0.0396 (0.0339) teacher/entropy 0.0716 (0.0728) teacher/usage_max 0.8113 (0.7421) teacher/usage_min 0.0003 (0.0010) teacher/usage_std 0.3466 (0.3099) nleep/row_max_mean 1522.7074 (1533.1769) nleep/row_max_std 80.8846 (69.0301) nleep/row_min_mean 1499.1212 (1507.7364) lr 1.9921e-03 eta 0:11:22
epoch [4/50] batch [80/160] time 0.062 (0.090) data 0.000 (0.004) loss 1.5808 (1.6270) teacher_loss 0.2558 (0.3021) loss_zs_kd 0.0321 (0.0486) loss_oracle 0.7967 (0.7309) kd_loss 0.9105 (0.9351) acc 90.6250 (90.5078) gate/entropy 1.0899 (1.0927) gate/usage_max 0.3870 (0.3744) gate/usage_min 0.2798 (0.2871) gate/usage_std 0.0438 (0.0359) teacher/entropy 0.0633 (0.0725) teacher/usage_max 0.8350 (0.7475) teacher/usage_min 0.0000 (0.0009) teacher/usage_std 0.3610 (0.3129) nleep/row_max_mean 1534.4050 (1533.6109) nleep/row_max_std 62.9641 (66.7640) nleep/row_min_mean 1507.1987 (1507.9355) lr 1.9921e-03 eta 0:11:09
epoch [4/50] batch [100/160] time 0.119 (0.092) data 0.000 (0.003) loss 1.5688 (1.6400) teacher_loss 0.2761 (0.3190) loss_zs_kd 0.0428 (0.0490) loss_oracle 0.7190 (0.7307) kd_loss 0.9118 (0.9311) acc 96.8750 (90.0938) gate/entropy 1.0883 (1.0919) gate/usage_max 0.3934 (0.3776) gate/usage_min 0.2762 (0.2853) gate/usage_std 0.0479 (0.0379) teacher/entropy 0.0653 (0.0705) teacher/usage_max 0.7474 (0.7539) teacher/usage_min 0.0006 (0.0016) teacher/usage_std 0.3102 (0.3164) nleep/row_max_mean 1535.1244 (1534.1259) nleep/row_max_std 62.1748 (65.7640) nleep/row_min_mean 1507.8010 (1508.1822) lr 1.9921e-03 eta 0:11:25
epoch [4/50] batch [120/160] time 0.161 (0.099) data 0.000 (0.003) loss 1.7930 (1.6419) teacher_loss 0.5014 (0.3249) loss_zs_kd 0.0395 (0.0482) loss_oracle 0.7201 (0.7332) kd_loss 0.9119 (0.9262) acc 87.5000 (89.7917) gate/entropy 1.0863 (1.0912) gate/usage_max 0.4004 (0.3809) gate/usage_min 0.2728 (0.2834) gate/usage_std 0.0523 (0.0400) teacher/entropy 0.0522 (0.0688) teacher/usage_max 0.7603 (0.7609) teacher/usage_min 0.0015 (0.0014) teacher/usage_std 0.3170 (0.3202) nleep/row_max_mean 1523.4775 (1533.1996) nleep/row_max_std 98.8256 (66.7134) nleep/row_min_mean 1494.8342 (1507.0851) lr 1.9921e-03 eta 0:12:12
epoch [4/50] batch [140/160] time 0.146 (0.104) data 0.000 (0.002) loss 1.4753 (1.6387) teacher_loss 0.2301 (0.3303) loss_zs_kd 0.0379 (0.0473) loss_oracle 0.6941 (0.7308) kd_loss 0.8792 (0.9193) acc 93.7500 (89.5536) gate/entropy 1.0842 (1.0903) gate/usage_max 0.4071 (0.3842) gate/usage_min 0.2692 (0.2816) gate/usage_std 0.0567 (0.0421) teacher/entropy 0.0800 (0.0699) teacher/usage_max 0.7365 (0.7638) teacher/usage_min 0.0003 (0.0015) teacher/usage_std 0.3046 (0.3216) nleep/row_max_mean 1527.6921 (1532.9949) nleep/row_max_std 73.6246 (66.1981) nleep/row_min_mean 1502.6924 (1506.7575) lr 1.9921e-03 eta 0:12:47
epoch [4/50] batch [160/160] time 0.130 (0.106) data 0.000 (0.002) loss 1.4710 (1.6321) teacher_loss 0.2461 (0.3314) loss_zs_kd 0.0345 (0.0464) loss_oracle 0.7063 (0.7299) kd_loss 0.8545 (0.9126) acc 90.6250 (89.5312) gate/entropy 1.0819 (1.0894) gate/usage_max 0.4140 (0.3875) gate/usage_min 0.2657 (0.2798) gate/usage_std 0.0612 (0.0442) teacher/entropy 0.0537 (0.0695) teacher/usage_max 0.8977 (0.7718) teacher/usage_min 0.0001 (0.0014) teacher/usage_std 0.4012 (0.3261) nleep/row_max_mean 1528.8391 (1533.0241) nleep/row_max_std 90.4346 (66.2683) nleep/row_min_mean 1500.9014 (1506.6374) lr 1.9823e-03 eta 0:13:01
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,815
* accuracy: 82.3%
* error: 17.7%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,955
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 88.1%
******* Domain p best val acc:      82.3%, epoch: 3 *******
******* Domain p best val test acc: 87.8%, epoch: 3 *******
******* Domain p best test acc:     87.8%, epoch: 3 *******
epoch [5/50] batch [20/160] time 0.162 (0.163) data 0.000 (0.015) loss 1.3375 (1.5775) teacher_loss 0.1387 (0.3445) loss_zs_kd 0.0209 (0.0397) loss_oracle 0.6812 (0.6923) kd_loss 0.8477 (0.8670) acc 96.8750 (90.4688) gate/entropy 1.0796 (1.0806) gate/usage_max 0.4207 (0.4177) gate/usage_min 0.2627 (0.2641) gate/usage_std 0.0656 (0.0636) teacher/entropy 0.1124 (0.0560) teacher/usage_max 0.6676 (0.8178) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.2726 (0.3527) nleep/row_max_mean 1506.4255 (1533.1267) nleep/row_max_std 90.6666 (66.4954) nleep/row_min_mean 1481.1962 (1504.3250) lr 1.9823e-03 eta 0:19:53
epoch [5/50] batch [40/160] time 0.149 (0.153) data 0.000 (0.008) loss 1.4125 (1.5631) teacher_loss 0.2267 (0.3486) loss_zs_kd 0.0303 (0.0383) loss_oracle 0.6702 (0.6865) kd_loss 0.8355 (0.8521) acc 96.8750 (89.2188) gate/entropy 1.0769 (1.0794) gate/usage_max 0.4276 (0.4211) gate/usage_min 0.2593 (0.2625) gate/usage_std 0.0702 (0.0659) teacher/entropy 0.0857 (0.0628) teacher/usage_max 0.7703 (0.8258) teacher/usage_min 0.0000 (0.0013) teacher/usage_std 0.3229 (0.3571) nleep/row_max_mean 1543.9360 (1532.1232) nleep/row_max_std 47.4159 (65.4757) nleep/row_min_mean 1514.8127 (1503.6611) lr 1.9823e-03 eta 0:18:41
epoch [5/50] batch [60/160] time 0.136 (0.154) data 0.001 (0.005) loss 1.7341 (1.5429) teacher_loss 0.6257 (0.3441) loss_zs_kd 0.0496 (0.0403) loss_oracle 0.5844 (0.6696) kd_loss 0.7914 (0.8439) acc 81.2500 (89.2708) gate/entropy 1.0741 (1.0780) gate/usage_max 0.4342 (0.4244) gate/usage_min 0.2563 (0.2609) gate/usage_std 0.0746 (0.0681) teacher/entropy 0.1280 (0.0676) teacher/usage_max 0.7541 (0.8202) teacher/usage_min 0.0090 (0.0021) teacher/usage_std 0.3117 (0.3533) nleep/row_max_mean 1510.9548 (1531.9896) nleep/row_max_std 102.8478 (66.9317) nleep/row_min_mean 1487.5498 (1503.9532) lr 1.9823e-03 eta 0:18:43
epoch [5/50] batch [80/160] time 0.145 (0.143) data 0.000 (0.004) loss 1.6965 (1.5433) teacher_loss 0.5333 (0.3498) loss_zs_kd 0.0530 (0.0409) loss_oracle 0.6830 (0.6651) kd_loss 0.7952 (0.8405) acc 87.5000 (89.3359) gate/entropy 1.0715 (1.0767) gate/usage_max 0.4403 (0.4277) gate/usage_min 0.2534 (0.2594) gate/usage_std 0.0787 (0.0702) teacher/entropy 0.0545 (0.0673) teacher/usage_max 0.9194 (0.8153) teacher/usage_min 0.0002 (0.0018) teacher/usage_std 0.4157 (0.3504) nleep/row_max_mean 1538.0945 (1531.2056) nleep/row_max_std 85.2210 (69.1644) nleep/row_min_mean 1511.6226 (1503.6497) lr 1.9823e-03 eta 0:17:17
epoch [5/50] batch [100/160] time 0.086 (0.135) data 0.000 (0.003) loss 1.4908 (1.5231) teacher_loss 0.3403 (0.3378) loss_zs_kd 0.0253 (0.0396) loss_oracle 0.6934 (0.6613) kd_loss 0.7912 (0.8348) acc 84.3750 (89.3125) gate/entropy 1.0687 (1.0754) gate/usage_max 0.4463 (0.4308) gate/usage_min 0.2508 (0.2579) gate/usage_std 0.0826 (0.0723) teacher/entropy 0.0684 (0.0683) teacher/usage_max 0.8642 (0.8150) teacher/usage_min 0.0000 (0.0020) teacher/usage_std 0.3795 (0.3502) nleep/row_max_mean 1531.1501 (1531.7200) nleep/row_max_std 73.0866 (67.4951) nleep/row_min_mean 1505.3950 (1504.4361) lr 1.9823e-03 eta 0:16:18
epoch [5/50] batch [120/160] time 0.147 (0.131) data 0.000 (0.003) loss 1.5599 (1.5177) teacher_loss 0.4439 (0.3396) loss_zs_kd 0.0425 (0.0394) loss_oracle 0.6425 (0.6588) kd_loss 0.7735 (0.8290) acc 84.3750 (89.2448) gate/entropy 1.0657 (1.0740) gate/usage_max 0.4524 (0.4339) gate/usage_min 0.2481 (0.2565) gate/usage_std 0.0868 (0.0744) teacher/entropy 0.0666 (0.0684) teacher/usage_max 0.8864 (0.8171) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.3938 (0.3513) nleep/row_max_mean 1528.2158 (1531.7151) nleep/row_max_std 57.4396 (66.8543) nleep/row_min_mean 1499.6959 (1504.5483) lr 1.9823e-03 eta 0:15:49
epoch [5/50] batch [140/160] time 0.145 (0.128) data 0.000 (0.002) loss 1.7558 (1.5109) teacher_loss 0.6537 (0.3382) loss_zs_kd 0.0416 (0.0400) loss_oracle 0.6722 (0.6533) kd_loss 0.7452 (0.8261) acc 78.1250 (89.1964) gate/entropy 1.0629 (1.0726) gate/usage_max 0.4581 (0.4370) gate/usage_min 0.2457 (0.2551) gate/usage_std 0.0906 (0.0765) teacher/entropy 0.0732 (0.0676) teacher/usage_max 0.9130 (0.8152) teacher/usage_min 0.0001 (0.0029) teacher/usage_std 0.4114 (0.3501) nleep/row_max_mean 1523.0720 (1531.6583) nleep/row_max_std 65.0560 (66.2597) nleep/row_min_mean 1495.8763 (1504.5738) lr 1.9823e-03 eta 0:15:24
epoch [5/50] batch [160/160] time 0.133 (0.123) data 0.000 (0.002) loss 1.6232 (1.4992) teacher_loss 0.5204 (0.3327) loss_zs_kd 0.0303 (0.0402) loss_oracle 0.6291 (0.6474) kd_loss 0.7730 (0.8227) acc 84.3750 (89.4141) gate/entropy 1.0601 (1.0712) gate/usage_max 0.4635 (0.4400) gate/usage_min 0.2434 (0.2538) gate/usage_std 0.0942 (0.0785) teacher/entropy 0.0764 (0.0685) teacher/usage_max 0.8254 (0.8109) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.3551 (0.3476) nleep/row_max_mean 1532.8673 (1531.3628) nleep/row_max_std 43.1458 (65.8392) nleep/row_min_mean 1506.8975 (1504.5062) lr 1.9686e-03 eta 0:14:46
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,808
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,972
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 88.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      82.3%, epoch: 3 *******
******* Domain p best val test acc: 87.8%, epoch: 3 *******
******* Domain p best test acc:     88.0%, epoch: 5 *******
epoch [6/50] batch [20/160] time 0.107 (0.131) data 0.000 (0.013) loss 1.3243 (1.4184) teacher_loss 0.1963 (0.3088) loss_zs_kd 0.0414 (0.0429) loss_oracle 0.6148 (0.5955) kd_loss 0.7999 (0.7903) acc 93.7500 (90.1562) gate/entropy 1.0571 (1.0586) gate/usage_max 0.4689 (0.4662) gate/usage_min 0.2411 (0.2423) gate/usage_std 0.0979 (0.0961) teacher/entropy 0.0668 (0.0675) teacher/usage_max 0.7748 (0.8003) teacher/usage_min 0.0030 (0.0044) teacher/usage_std 0.3247 (0.3413) nleep/row_max_mean 1537.1016 (1531.0213) nleep/row_max_std 51.9546 (60.3708) nleep/row_min_mean 1509.8499 (1505.2398) lr 1.9686e-03 eta 0:15:37
epoch [6/50] batch [40/160] time 0.128 (0.129) data 0.000 (0.007) loss 1.3190 (1.4090) teacher_loss 0.1701 (0.3057) loss_zs_kd 0.0449 (0.0423) loss_oracle 0.5966 (0.5960) kd_loss 0.8281 (0.7841) acc 96.8750 (89.6094) gate/entropy 1.0543 (1.0572) gate/usage_max 0.4738 (0.4687) gate/usage_min 0.2393 (0.2413) gate/usage_std 0.1012 (0.0978) teacher/entropy 0.0197 (0.0651) teacher/usage_max 0.8093 (0.8113) teacher/usage_min 0.0308 (0.0051) teacher/usage_std 0.3407 (0.3474) nleep/row_max_mean 1544.5223 (1527.9191) nleep/row_max_std 44.9408 (63.3301) nleep/row_min_mean 1515.5659 (1501.8378) lr 1.9686e-03 eta 0:15:22
epoch [6/50] batch [60/160] time 0.135 (0.134) data 0.001 (0.004) loss 1.3341 (1.4087) teacher_loss 0.2056 (0.3093) loss_zs_kd 0.0552 (0.0422) loss_oracle 0.5558 (0.5881) kd_loss 0.8230 (0.7843) acc 90.6250 (89.7396) gate/entropy 1.0516 (1.0558) gate/usage_max 0.4785 (0.4712) gate/usage_min 0.2374 (0.2403) gate/usage_std 0.1044 (0.0995) teacher/entropy 0.0592 (0.0664) teacher/usage_max 0.7237 (0.8018) teacher/usage_min 0.0051 (0.0046) teacher/usage_std 0.2966 (0.3422) nleep/row_max_mean 1521.1263 (1527.3320) nleep/row_max_std 72.0592 (64.2573) nleep/row_min_mean 1496.7805 (1501.5169) lr 1.9686e-03 eta 0:15:56
epoch [6/50] batch [80/160] time 0.151 (0.135) data 0.000 (0.003) loss 1.3392 (1.4120) teacher_loss 0.2061 (0.3114) loss_zs_kd 0.0772 (0.0429) loss_oracle 0.4624 (0.5825) kd_loss 0.8633 (0.7878) acc 93.7500 (89.6094) gate/entropy 1.0488 (1.0544) gate/usage_max 0.4832 (0.4736) gate/usage_min 0.2355 (0.2394) gate/usage_std 0.1076 (0.1011) teacher/entropy 0.0632 (0.0641) teacher/usage_max 0.6314 (0.7935) teacher/usage_min 0.0008 (0.0038) teacher/usage_std 0.2586 (0.3378) nleep/row_max_mean 1545.7769 (1527.8070) nleep/row_max_std 56.1566 (62.4677) nleep/row_min_mean 1522.6024 (1502.0444) lr 1.9686e-03 eta 0:16:02
epoch [6/50] batch [100/160] time 0.134 (0.136) data 0.000 (0.003) loss 1.3421 (1.4018) teacher_loss 0.1283 (0.3027) loss_zs_kd 0.0356 (0.0428) loss_oracle 0.5112 (0.5766) kd_loss 0.9403 (0.7893) acc 100.0000 (90.0938) gate/entropy 1.0468 (1.0531) gate/usage_max 0.4864 (0.4758) gate/usage_min 0.2341 (0.2384) gate/usage_std 0.1098 (0.1026) teacher/entropy 0.0576 (0.0674) teacher/usage_max 0.5016 (0.7803) teacher/usage_min 0.0011 (0.0062) teacher/usage_std 0.2349 (0.3304) nleep/row_max_mean 1541.8488 (1528.4034) nleep/row_max_std 25.8803 (61.9654) nleep/row_min_mean 1519.6108 (1502.9510) lr 1.9686e-03 eta 0:16:02
epoch [6/50] batch [120/160] time 0.157 (0.137) data 0.000 (0.002) loss 1.3588 (1.3947) teacher_loss 0.1662 (0.2920) loss_zs_kd 0.0883 (0.0454) loss_oracle 0.5537 (0.5750) kd_loss 0.8716 (0.7924) acc 96.8750 (90.6510) gate/entropy 1.0443 (1.0518) gate/usage_max 0.4902 (0.4779) gate/usage_min 0.2323 (0.2376) gate/usage_std 0.1125 (0.1040) teacher/entropy 0.0597 (0.0682) teacher/usage_max 0.6165 (0.7691) teacher/usage_min 0.0001 (0.0064) teacher/usage_std 0.2541 (0.3243) nleep/row_max_mean 1540.0370 (1527.4469) nleep/row_max_std 44.0120 (61.8278) nleep/row_min_mean 1515.0474 (1502.2399) lr 1.9686e-03 eta 0:16:11
epoch [6/50] batch [140/160] time 0.146 (0.138) data 0.000 (0.002) loss 1.3921 (1.3867) teacher_loss 0.2947 (0.2826) loss_zs_kd 0.0355 (0.0457) loss_oracle 0.5331 (0.5742) kd_loss 0.8132 (0.7942) acc 90.6250 (90.9152) gate/entropy 1.0428 (1.0507) gate/usage_max 0.4925 (0.4798) gate/usage_min 0.2313 (0.2367) gate/usage_std 0.1140 (0.1053) teacher/entropy 0.0478 (0.0676) teacher/usage_max 0.7371 (0.7631) teacher/usage_min 0.0013 (0.0072) teacher/usage_std 0.3047 (0.3208) nleep/row_max_mean 1522.2026 (1527.0159) nleep/row_max_std 56.4317 (62.1102) nleep/row_min_mean 1498.4966 (1501.9558) lr 1.9686e-03 eta 0:16:13
epoch [6/50] batch [160/160] time 0.130 (0.138) data 0.000 (0.002) loss 1.5018 (1.3920) teacher_loss 0.3446 (0.2861) loss_zs_kd 0.0622 (0.0465) loss_oracle 0.5924 (0.5742) kd_loss 0.8299 (0.7955) acc 87.5000 (90.8398) gate/entropy 1.0404 (1.0495) gate/usage_max 0.4961 (0.4816) gate/usage_min 0.2297 (0.2360) gate/usage_std 0.1165 (0.1066) teacher/entropy 0.0500 (0.0689) teacher/usage_max 0.6988 (0.7553) teacher/usage_min 0.0002 (0.0087) teacher/usage_std 0.2861 (0.3163) nleep/row_max_mean 1535.8943 (1526.7959) nleep/row_max_std 27.8795 (61.2784) nleep/row_min_mean 1511.2838 (1501.8669) lr 1.9511e-03 eta 0:16:09
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,807
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,947
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.1%
******* Domain p best val acc:      82.3%, epoch: 3 *******
******* Domain p best val test acc: 87.8%, epoch: 3 *******
******* Domain p best test acc:     88.0%, epoch: 5 *******
epoch [7/50] batch [20/160] time 0.089 (0.129) data 0.000 (0.019) loss 1.4275 (1.3300) teacher_loss 0.2760 (0.2098) loss_zs_kd 0.0586 (0.0520) loss_oracle 0.5802 (0.5867) kd_loss 0.8321 (0.8008) acc 90.6250 (94.5312) gate/entropy 1.0384 (1.0395) gate/usage_max 0.4991 (0.4975) gate/usage_min 0.2286 (0.2293) gate/usage_std 0.1186 (0.1175) teacher/entropy 0.0777 (0.0690) teacher/usage_max 0.6515 (0.7215) teacher/usage_min 0.0236 (0.0272) teacher/usage_std 0.2564 (0.2923) nleep/row_max_mean 1529.0266 (1526.4174) nleep/row_max_std 47.1503 (55.2852) nleep/row_min_mean 1505.8477 (1502.1309) lr 1.9511e-03 eta 0:15:07
epoch [7/50] batch [40/160] time 0.079 (0.123) data 0.000 (0.010) loss 1.5049 (1.3570) teacher_loss 0.4123 (0.2400) loss_zs_kd 0.0448 (0.0510) loss_oracle 0.6159 (0.5783) kd_loss 0.7622 (0.8023) acc 87.5000 (92.6562) gate/entropy 1.0366 (1.0385) gate/usage_max 0.5018 (0.4990) gate/usage_min 0.2276 (0.2287) gate/usage_std 0.1204 (0.1185) teacher/entropy 0.0571 (0.0753) teacher/usage_max 0.7976 (0.7066) teacher/usage_min 0.0292 (0.0270) teacher/usage_std 0.3335 (0.2856) nleep/row_max_mean 1521.4260 (1524.8813) nleep/row_max_std 84.1746 (58.2647) nleep/row_min_mean 1492.3353 (1500.6258) lr 1.9511e-03 eta 0:14:19
epoch [7/50] batch [60/160] time 0.093 (0.118) data 0.000 (0.007) loss 1.3032 (1.3543) teacher_loss 0.2298 (0.2384) loss_zs_kd 0.0694 (0.0519) loss_oracle 0.5280 (0.5749) kd_loss 0.7747 (0.8026) acc 90.6250 (92.3438) gate/entropy 1.0350 (1.0376) gate/usage_max 0.5042 (0.5004) gate/usage_min 0.2266 (0.2281) gate/usage_std 0.1221 (0.1194) teacher/entropy 0.1008 (0.0753) teacher/usage_max 0.7092 (0.7046) teacher/usage_min 0.0462 (0.0283) teacher/usage_std 0.2778 (0.2848) nleep/row_max_mean 1527.5336 (1524.1682) nleep/row_max_std 49.6042 (60.5008) nleep/row_min_mean 1502.8757 (1499.4656) lr 1.9511e-03 eta 0:13:45
epoch [7/50] batch [80/160] time 0.087 (0.118) data 0.000 (0.005) loss 1.4132 (1.3499) teacher_loss 0.3026 (0.2330) loss_zs_kd 0.0574 (0.0547) loss_oracle 0.5643 (0.5716) kd_loss 0.7998 (0.8038) acc 93.7500 (92.9297) gate/entropy 1.0332 (1.0366) gate/usage_max 0.5066 (0.5017) gate/usage_min 0.2257 (0.2276) gate/usage_std 0.1237 (0.1204) teacher/entropy 0.0905 (0.0778) teacher/usage_max 0.6808 (0.6977) teacher/usage_min 0.0427 (0.0305) teacher/usage_std 0.2636 (0.2800) nleep/row_max_mean 1523.9680 (1523.6386) nleep/row_max_std 64.4876 (61.3587) nleep/row_min_mean 1498.0089 (1498.9126) lr 1.9511e-03 eta 0:13:39
epoch [7/50] batch [100/160] time 0.082 (0.119) data 0.000 (0.004) loss 1.1814 (1.3483) teacher_loss 0.1021 (0.2334) loss_zs_kd 0.0624 (0.0557) loss_oracle 0.5058 (0.5683) kd_loss 0.7953 (0.8030) acc 96.8750 (92.8750) gate/entropy 1.0312 (1.0357) gate/usage_max 0.5094 (0.5030) gate/usage_min 0.2246 (0.2271) gate/usage_std 0.1257 (0.1212) teacher/entropy 0.1160 (0.0795) teacher/usage_max 0.6458 (0.6951) teacher/usage_min 0.0421 (0.0313) teacher/usage_std 0.2469 (0.2785) nleep/row_max_mean 1526.0684 (1522.6676) nleep/row_max_std 72.3104 (62.9095) nleep/row_min_mean 1503.0692 (1497.8559) lr 1.9511e-03 eta 0:13:48
epoch [7/50] batch [120/160] time 0.083 (0.119) data 0.000 (0.003) loss 1.2155 (1.3502) teacher_loss 0.1064 (0.2315) loss_zs_kd 0.0498 (0.0568) loss_oracle 0.5782 (0.5649) kd_loss 0.7952 (0.8078) acc 96.8750 (92.9948) gate/entropy 1.0305 (1.0349) gate/usage_max 0.5105 (0.5042) gate/usage_min 0.2241 (0.2266) gate/usage_std 0.1264 (0.1221) teacher/entropy 0.0641 (0.0786) teacher/usage_max 0.7150 (0.6885) teacher/usage_min 0.0017 (0.0340) teacher/usage_std 0.2933 (0.2743) nleep/row_max_mean 1503.9240 (1522.3605) nleep/row_max_std 91.2261 (63.5385) nleep/row_min_mean 1481.7778 (1497.4350) lr 1.9511e-03 eta 0:13:40
epoch [7/50] batch [140/160] time 0.133 (0.119) data 0.000 (0.003) loss 1.3606 (1.3405) teacher_loss 0.2022 (0.2198) loss_zs_kd 0.0561 (0.0580) loss_oracle 0.5045 (0.5637) kd_loss 0.8780 (0.8098) acc 96.8750 (93.4598) gate/entropy 1.0291 (1.0341) gate/usage_max 0.5124 (0.5053) gate/usage_min 0.2233 (0.2262) gate/usage_std 0.1277 (0.1228) teacher/entropy 0.0606 (0.0783) teacher/usage_max 0.6016 (0.6851) teacher/usage_min 0.0452 (0.0351) teacher/usage_std 0.2276 (0.2725) nleep/row_max_mean 1496.3165 (1522.4437) nleep/row_max_std 79.0576 (63.7215) nleep/row_min_mean 1473.3584 (1497.4469) lr 1.9511e-03 eta 0:13:43
epoch [7/50] batch [160/160] time 0.135 (0.121) data 0.000 (0.003) loss 1.4672 (1.3477) teacher_loss 0.2267 (0.2155) loss_zs_kd 0.0831 (0.0586) loss_oracle 0.5720 (0.5617) kd_loss 0.9129 (0.8221) acc 93.7500 (93.6328) gate/entropy 1.0277 (1.0334) gate/usage_max 0.5142 (0.5063) gate/usage_min 0.2220 (0.2257) gate/usage_std 0.1290 (0.1235) teacher/entropy 0.0401 (0.0752) teacher/usage_max 0.5851 (0.6716) teacher/usage_min 0.0665 (0.0367) teacher/usage_std 0.2120 (0.2664) nleep/row_max_mean 1523.7263 (1522.4827) nleep/row_max_std 57.2884 (63.6046) nleep/row_min_mean 1499.6306 (1497.5230) lr 1.9298e-03 eta 0:13:54
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,947
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.4%
******* Domain p best val acc:      83.5%, epoch: 7 *******
******* Domain p best val test acc: 87.3%, epoch: 7 *******
******* Domain p best test acc:     88.0%, epoch: 5 *******
epoch [8/50] batch [20/160] time 0.138 (0.144) data 0.000 (0.015) loss 1.5247 (1.3950) teacher_loss 0.1764 (0.1713) loss_zs_kd 0.0819 (0.0710) loss_oracle 0.5575 (0.5721) kd_loss 1.0286 (0.9021) acc 93.7500 (95.9375) gate/entropy 1.0275 (1.0276) gate/usage_max 0.5144 (0.5143) gate/usage_min 0.2215 (0.2218) gate/usage_std 0.1292 (0.1291) teacher/entropy 0.0605 (0.0567) teacher/usage_max 0.5727 (0.5830) teacher/usage_min 0.0520 (0.0461) teacher/usage_std 0.2146 (0.2248) nleep/row_max_mean 1518.3787 (1523.2939) nleep/row_max_std 70.0013 (55.7578) nleep/row_min_mean 1496.4833 (1498.5070) lr 1.9298e-03 eta 0:16:28
epoch [8/50] batch [40/160] time 0.124 (0.133) data 0.000 (0.008) loss 1.4027 (1.3866) teacher_loss 0.1424 (0.1512) loss_zs_kd 0.0828 (0.0723) loss_oracle 0.6133 (0.5792) kd_loss 0.9123 (0.9096) acc 96.8750 (96.1719) gate/entropy 1.0268 (1.0273) gate/usage_max 0.5151 (0.5145) gate/usage_min 0.2205 (0.2214) gate/usage_std 0.1298 (0.1293) teacher/entropy 0.0644 (0.0483) teacher/usage_max 0.5313 (0.5862) teacher/usage_min 0.0069 (0.0424) teacher/usage_std 0.2326 (0.2288) nleep/row_max_mean 1529.0941 (1522.8301) nleep/row_max_std 44.6946 (59.7971) nleep/row_min_mean 1501.8843 (1497.7103) lr 1.9298e-03 eta 0:15:12
epoch [8/50] batch [60/160] time 0.149 (0.135) data 0.001 (0.005) loss 1.4082 (1.3819) teacher_loss 0.0579 (0.1371) loss_zs_kd 0.0785 (0.0718) loss_oracle 0.5873 (0.5741) kd_loss 1.0174 (0.9218) acc 100.0000 (96.4583) gate/entropy 1.0268 (1.0272) gate/usage_max 0.5149 (0.5147) gate/usage_min 0.2198 (0.2210) gate/usage_std 0.1298 (0.1295) teacher/entropy 0.0038 (0.0430) teacher/usage_max 0.4995 (0.5746) teacher/usage_min 0.0316 (0.0411) teacher/usage_std 0.2137 (0.2257) nleep/row_max_mean 1527.9590 (1523.3383) nleep/row_max_std 48.4538 (61.1997) nleep/row_min_mean 1500.7966 (1497.8571) lr 1.9298e-03 eta 0:15:21
epoch [8/50] batch [80/160] time 0.136 (0.137) data 0.000 (0.004) loss 1.3675 (1.3834) teacher_loss 0.0192 (0.1303) loss_zs_kd 0.0659 (0.0720) loss_oracle 0.5209 (0.5803) kd_loss 1.0549 (0.9269) acc 100.0000 (96.5234) gate/entropy 1.0267 (1.0271) gate/usage_max 0.5147 (0.5147) gate/usage_min 0.2189 (0.2206) gate/usage_std 0.1297 (0.1295) teacher/entropy 0.0471 (0.0420) teacher/usage_max 0.4896 (0.5713) teacher/usage_min 0.1356 (0.0425) teacher/usage_std 0.1475 (0.2238) nleep/row_max_mean 1534.0791 (1522.8786) nleep/row_max_std 47.6959 (62.6461) nleep/row_min_mean 1508.6663 (1497.0768) lr 1.9298e-03 eta 0:15:33
epoch [8/50] batch [100/160] time 0.090 (0.129) data 0.000 (0.003) loss 1.4005 (1.3837) teacher_loss 0.0319 (0.1276) loss_zs_kd 0.0670 (0.0717) loss_oracle 0.5734 (0.5775) kd_loss 1.0483 (0.9315) acc 100.0000 (96.5312) gate/entropy 1.0270 (1.0270) gate/usage_max 0.5141 (0.5147) gate/usage_min 0.2182 (0.2201) gate/usage_std 0.1294 (0.1296) teacher/entropy 0.0290 (0.0398) teacher/usage_max 0.4761 (0.5711) teacher/usage_min 0.1176 (0.0429) teacher/usage_std 0.1552 (0.2232) nleep/row_max_mean 1524.5931 (1522.2264) nleep/row_max_std 50.0113 (63.3808) nleep/row_min_mean 1497.3696 (1496.0782) lr 1.9298e-03 eta 0:14:33
epoch [8/50] batch [120/160] time 0.096 (0.125) data 0.000 (0.003) loss 1.4125 (1.3789) teacher_loss 0.0704 (0.1230) loss_zs_kd 0.1090 (0.0731) loss_oracle 0.5884 (0.5790) kd_loss 0.9933 (0.9299) acc 96.8750 (96.6927) gate/entropy 1.0269 (1.0270) gate/usage_max 0.5140 (0.5146) gate/usage_min 0.2173 (0.2197) gate/usage_std 0.1295 (0.1296) teacher/entropy 0.0278 (0.0400) teacher/usage_max 0.4757 (0.5702) teacher/usage_min 0.0556 (0.0438) teacher/usage_std 0.1964 (0.2227) nleep/row_max_mean 1534.0337 (1521.7553) nleep/row_max_std 32.1738 (62.8002) nleep/row_min_mean 1507.3234 (1495.4039) lr 1.9298e-03 eta 0:14:05
epoch [8/50] batch [140/160] time 0.166 (0.126) data 0.000 (0.002) loss 1.3102 (1.3780) teacher_loss 0.0889 (0.1200) loss_zs_kd 0.0740 (0.0740) loss_oracle 0.6234 (0.5823) kd_loss 0.8726 (0.9298) acc 96.8750 (96.8304) gate/entropy 1.0265 (1.0269) gate/usage_max 0.5142 (0.5145) gate/usage_min 0.2163 (0.2193) gate/usage_std 0.1297 (0.1296) teacher/entropy 0.0151 (0.0402) teacher/usage_max 0.6874 (0.5688) teacher/usage_min 0.0979 (0.0443) teacher/usage_std 0.2549 (0.2224) nleep/row_max_mean 1529.5763 (1521.4710) nleep/row_max_std 69.1564 (63.1328) nleep/row_min_mean 1502.9885 (1495.0313) lr 1.9298e-03 eta 0:14:11
epoch [8/50] batch [160/160] time 0.156 (0.124) data 0.000 (0.002) loss 1.4105 (1.3770) teacher_loss 0.0286 (0.1176) loss_zs_kd 0.0676 (0.0747) loss_oracle 0.6053 (0.5833) kd_loss 1.0454 (0.9304) acc 100.0000 (96.8750) gate/entropy 1.0266 (1.0269) gate/usage_max 0.5139 (0.5144) gate/usage_min 0.2156 (0.2189) gate/usage_std 0.1296 (0.1295) teacher/entropy 0.0309 (0.0397) teacher/usage_max 0.5851 (0.5692) teacher/usage_min 0.0403 (0.0448) teacher/usage_std 0.2243 (0.2220) nleep/row_max_mean 1521.9854 (1521.0873) nleep/row_max_std 78.8414 (63.1966) nleep/row_min_mean 1493.9766 (1494.4870) lr 1.9048e-03 eta 0:13:52
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,800
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,879
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 87.2%
******* Domain p best val acc:      83.5%, epoch: 7 *******
******* Domain p best val test acc: 87.3%, epoch: 7 *******
******* Domain p best test acc:     88.0%, epoch: 5 *******
epoch [9/50] batch [20/160] time 0.099 (0.107) data 0.000 (0.015) loss 1.2899 (1.3749) teacher_loss 0.0797 (0.0987) loss_zs_kd 0.0775 (0.0772) loss_oracle 0.6113 (0.5765) kd_loss 0.8658 (0.9493) acc 96.8750 (97.8125) gate/entropy 1.0269 (1.0269) gate/usage_max 0.5131 (0.5132) gate/usage_min 0.2149 (0.2153) gate/usage_std 0.1292 (0.1293) teacher/entropy 0.0246 (0.0310) teacher/usage_max 0.6587 (0.5521) teacher/usage_min 0.0290 (0.0436) teacher/usage_std 0.2575 (0.2174) nleep/row_max_mean 1512.1868 (1516.9604) nleep/row_max_std 76.6835 (64.1064) nleep/row_min_mean 1487.2917 (1489.6744) lr 1.9048e-03 eta 0:11:57
epoch [9/50] batch [40/160] time 0.081 (0.109) data 0.000 (0.007) loss 1.3695 (1.3913) teacher_loss 0.1239 (0.1183) loss_zs_kd 0.0892 (0.0745) loss_oracle 0.5680 (0.5737) kd_loss 0.9170 (0.9489) acc 93.7500 (97.0312) gate/entropy 1.0272 (1.0270) gate/usage_max 0.5124 (0.5129) gate/usage_min 0.2143 (0.2150) gate/usage_std 0.1289 (0.1291) teacher/entropy 0.0917 (0.0377) teacher/usage_max 0.4943 (0.5544) teacher/usage_min 0.0966 (0.0584) teacher/usage_std 0.1710 (0.2105) nleep/row_max_mean 1526.7240 (1517.4360) nleep/row_max_std 49.8973 (61.4304) nleep/row_min_mean 1499.9545 (1490.1571) lr 1.9048e-03 eta 0:12:06
epoch [9/50] batch [60/160] time 0.132 (0.116) data 0.001 (0.005) loss 1.3308 (1.3887) teacher_loss 0.0694 (0.1260) loss_zs_kd 0.0800 (0.0753) loss_oracle 0.6046 (0.5684) kd_loss 0.9191 (0.9409) acc 96.8750 (96.6667) gate/entropy 1.0272 (1.0271) gate/usage_max 0.5121 (0.5127) gate/usage_min 0.2135 (0.2146) gate/usage_std 0.1288 (0.1290) teacher/entropy 0.0437 (0.0454) teacher/usage_max 0.5570 (0.5502) teacher/usage_min 0.0729 (0.0622) teacher/usage_std 0.1993 (0.2074) nleep/row_max_mean 1518.9851 (1516.1786) nleep/row_max_std 71.3873 (62.1616) nleep/row_min_mean 1490.1257 (1488.9618) lr 1.9048e-03 eta 0:12:49
epoch [9/50] batch [80/160] time 0.154 (0.121) data 0.000 (0.004) loss 1.2458 (1.3825) teacher_loss 0.0767 (0.1231) loss_zs_kd 0.0732 (0.0753) loss_oracle 0.5698 (0.5635) kd_loss 0.8476 (0.9400) acc 96.8750 (96.7969) gate/entropy 1.0275 (1.0272) gate/usage_max 0.5114 (0.5124) gate/usage_min 0.2129 (0.2143) gate/usage_std 0.1285 (0.1289) teacher/entropy 0.0773 (0.0496) teacher/usage_max 0.6105 (0.5433) teacher/usage_min 0.0543 (0.0660) teacher/usage_std 0.2271 (0.2038) nleep/row_max_mean 1512.5759 (1515.8361) nleep/row_max_std 58.0028 (62.0740) nleep/row_min_mean 1485.4990 (1488.9044) lr 1.9048e-03 eta 0:13:23
epoch [9/50] batch [100/160] time 0.156 (0.126) data 0.000 (0.003) loss 1.3038 (1.3778) teacher_loss 0.0627 (0.1207) loss_zs_kd 0.0593 (0.0735) loss_oracle 0.5231 (0.5589) kd_loss 0.9499 (0.9408) acc 96.8750 (96.8750) gate/entropy 1.0277 (1.0273) gate/usage_max 0.5109 (0.5122) gate/usage_min 0.2123 (0.2139) gate/usage_std 0.1283 (0.1288) teacher/entropy 0.0901 (0.0519) teacher/usage_max 0.4663 (0.5407) teacher/usage_min 0.0955 (0.0726) teacher/usage_std 0.1685 (0.1999) nleep/row_max_mean 1521.4807 (1515.3781) nleep/row_max_std 43.7443 (62.2087) nleep/row_min_mean 1496.1799 (1488.7563) lr 1.9048e-03 eta 0:13:54
epoch [9/50] batch [120/160] time 0.160 (0.129) data 0.000 (0.003) loss 1.3096 (1.3826) teacher_loss 0.0618 (0.1205) loss_zs_kd 0.0991 (0.0750) loss_oracle 0.5495 (0.5601) kd_loss 0.9235 (0.9445) acc 100.0000 (96.7969) gate/entropy 1.0277 (1.0274) gate/usage_max 0.5105 (0.5119) gate/usage_min 0.2116 (0.2136) gate/usage_std 0.1282 (0.1287) teacher/entropy 0.0605 (0.0527) teacher/usage_max 0.5276 (0.5379) teacher/usage_min 0.0914 (0.0740) teacher/usage_std 0.1812 (0.1982) nleep/row_max_mean 1507.8060 (1515.1507) nleep/row_max_std 76.3576 (62.3550) nleep/row_min_mean 1481.9471 (1488.5506) lr 1.9048e-03 eta 0:14:11
epoch [9/50] batch [140/160] time 0.151 (0.131) data 0.000 (0.002) loss 1.4247 (1.3802) teacher_loss 0.0613 (0.1200) loss_zs_kd 0.0817 (0.0757) loss_oracle 0.5331 (0.5537) kd_loss 1.0560 (0.9455) acc 96.8750 (96.7411) gate/entropy 1.0285 (1.0275) gate/usage_max 0.5091 (0.5116) gate/usage_min 0.2113 (0.2133) gate/usage_std 0.1274 (0.1286) teacher/entropy 0.0517 (0.0565) teacher/usage_max 0.4387 (0.5334) teacher/usage_min 0.1928 (0.0804) teacher/usage_std 0.1034 (0.1934) nleep/row_max_mean 1509.2709 (1514.8498) nleep/row_max_std 60.9771 (62.1804) nleep/row_min_mean 1480.6440 (1488.3103) lr 1.9048e-03 eta 0:14:20
epoch [9/50] batch [160/160] time 0.153 (0.132) data 0.000 (0.002) loss 1.3463 (1.3793) teacher_loss 0.1321 (0.1179) loss_zs_kd 0.0777 (0.0758) loss_oracle 0.4793 (0.5456) kd_loss 0.9357 (0.9506) acc 93.7500 (96.8164) gate/entropy 1.0287 (1.0276) gate/usage_max 0.5084 (0.5113) gate/usage_min 0.2106 (0.2130) gate/usage_std 0.1271 (0.1284) teacher/entropy 0.0926 (0.0590) teacher/usage_max 0.4858 (0.5269) teacher/usage_min 0.1625 (0.0881) teacher/usage_std 0.1326 (0.1877) nleep/row_max_mean 1500.6887 (1514.4053) nleep/row_max_std 71.3383 (62.6376) nleep/row_min_mean 1476.6805 (1487.9147) lr 1.8763e-03 eta 0:14:23
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,818
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,831
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 86.1%
******* Domain p best val acc:      83.5%, epoch: 7 *******
******* Domain p best val test acc: 87.3%, epoch: 7 *******
******* Domain p best test acc:     88.0%, epoch: 5 *******
epoch [10/50] batch [20/160] time 0.142 (0.115) data 0.000 (0.012) loss 1.4158 (1.4061) teacher_loss 0.0755 (0.1157) loss_zs_kd 0.0680 (0.0823) loss_oracle 0.5299 (0.4871) kd_loss 1.0413 (1.0057) acc 96.8750 (96.5625) gate/entropy 1.0287 (1.0288) gate/usage_max 0.5081 (0.5081) gate/usage_min 0.2101 (0.2104) gate/usage_std 0.1270 (0.1270) teacher/entropy 0.1081 (0.0889) teacher/usage_max 0.4276 (0.4575) teacher/usage_min 0.2497 (0.1850) teacher/usage_std 0.0730 (0.1172) nleep/row_max_mean 1539.0690 (1514.5182) nleep/row_max_std 29.8140 (58.0716) nleep/row_min_mean 1510.6365 (1488.1566) lr 1.8763e-03 eta 0:12:33
epoch [10/50] batch [40/160] time 0.164 (0.110) data 0.000 (0.006) loss 1.4631 (1.4129) teacher_loss 0.1937 (0.1122) loss_zs_kd 0.0774 (0.0787) loss_oracle 0.5231 (0.4922) kd_loss 0.9691 (1.0153) acc 90.6250 (96.6406) gate/entropy 1.0293 (1.0290) gate/usage_max 0.5069 (0.5077) gate/usage_min 0.2098 (0.2103) gate/usage_std 0.1264 (0.1267) teacher/entropy 0.0973 (0.0931) teacher/usage_max 0.4635 (0.4559) teacher/usage_min 0.2506 (0.1948) teacher/usage_std 0.0932 (0.1120) nleep/row_max_mean 1506.0405 (1513.3007) nleep/row_max_std 84.6963 (61.6263) nleep/row_min_mean 1483.4238 (1486.7350) lr 1.8763e-03 eta 0:11:59
epoch [10/50] batch [60/160] time 0.073 (0.110) data 0.001 (0.004) loss 1.3446 (1.4206) teacher_loss 0.0684 (0.1112) loss_zs_kd 0.0771 (0.0794) loss_oracle 0.4628 (0.5002) kd_loss 1.0061 (1.0196) acc 100.0000 (96.8750) gate/entropy 1.0299 (1.0292) gate/usage_max 0.5057 (0.5072) gate/usage_min 0.2094 (0.2100) gate/usage_std 0.1257 (0.1265) teacher/entropy 0.1276 (0.0889) teacher/usage_max 0.3917 (0.4573) teacher/usage_min 0.2579 (0.1966) teacher/usage_std 0.0559 (0.1112) nleep/row_max_mean 1508.6688 (1513.4312) nleep/row_max_std 65.9621 (61.7073) nleep/row_min_mean 1483.1123 (1486.6943) lr 1.8763e-03 eta 0:11:57
epoch [10/50] batch [80/160] time 0.092 (0.109) data 0.000 (0.003) loss 1.6843 (1.4295) teacher_loss 0.2208 (0.1110) loss_zs_kd 0.1014 (0.0810) loss_oracle 0.4865 (0.5025) kd_loss 1.1695 (1.0267) acc 96.8750 (96.9531) gate/entropy 1.0303 (1.0295) gate/usage_max 0.5048 (0.5066) gate/usage_min 0.2090 (0.2099) gate/usage_std 0.1252 (0.1262) teacher/entropy 0.0585 (0.0839) teacher/usage_max 0.3759 (0.4598) teacher/usage_min 0.2490 (0.1971) teacher/usage_std 0.0596 (0.1119) nleep/row_max_mean 1523.6594 (1513.3221) nleep/row_max_std 50.9370 (61.0358) nleep/row_min_mean 1497.1802 (1486.6750) lr 1.8763e-03 eta 0:11:46
epoch [10/50] batch [100/160] time 0.087 (0.110) data 0.000 (0.003) loss 1.2857 (1.4274) teacher_loss 0.0382 (0.1052) loss_zs_kd 0.1070 (0.0827) loss_oracle 0.4788 (0.5004) kd_loss 0.9546 (1.0306) acc 100.0000 (97.2500) gate/entropy 1.0309 (1.0297) gate/usage_max 0.5036 (0.5061) gate/usage_min 0.2087 (0.2097) gate/usage_std 0.1246 (0.1259) teacher/entropy 0.1517 (0.0821) teacher/usage_max 0.4101 (0.4638) teacher/usage_min 0.2774 (0.1979) teacher/usage_std 0.0561 (0.1134) nleep/row_max_mean 1515.1560 (1513.7934) nleep/row_max_std 62.1122 (60.3891) nleep/row_min_mean 1490.0479 (1487.1841) lr 1.8763e-03 eta 0:11:48
epoch [10/50] batch [120/160] time 0.096 (0.109) data 0.000 (0.002) loss 1.4992 (1.4348) teacher_loss 0.1323 (0.1092) loss_zs_kd 0.1093 (0.0830) loss_oracle 0.4620 (0.4987) kd_loss 1.0813 (1.0347) acc 96.8750 (97.0833) gate/entropy 1.0311 (1.0300) gate/usage_max 0.5028 (0.5056) gate/usage_min 0.2082 (0.2095) gate/usage_std 0.1243 (0.1257) teacher/entropy 0.0643 (0.0816) teacher/usage_max 0.4078 (0.4625) teacher/usage_min 0.2633 (0.2015) teacher/usage_std 0.0591 (0.1111) nleep/row_max_mean 1526.0724 (1513.7438) nleep/row_max_std 63.1345 (60.9365) nleep/row_min_mean 1497.9414 (1487.1464) lr 1.8763e-03 eta 0:11:43
epoch [10/50] batch [140/160] time 0.093 (0.110) data 0.000 (0.002) loss 1.3730 (1.4421) teacher_loss 0.0436 (0.1038) loss_zs_kd 0.0933 (0.0838) loss_oracle 0.5028 (0.5073) kd_loss 1.0313 (1.0428) acc 100.0000 (97.2768) gate/entropy 1.0323 (1.0302) gate/usage_max 0.5007 (0.5051) gate/usage_min 0.2082 (0.2093) gate/usage_std 0.1231 (0.1254) teacher/entropy 0.0882 (0.0790) teacher/usage_max 0.4255 (0.4646) teacher/usage_min 0.2250 (0.2028) teacher/usage_std 0.0827 (0.1115) nleep/row_max_mean 1496.4636 (1514.0674) nleep/row_max_std 82.6238 (61.0112) nleep/row_min_mean 1471.9535 (1487.2724) lr 1.8763e-03 eta 0:11:45
epoch [10/50] batch [160/160] time 0.136 (0.110) data 0.000 (0.002) loss 1.5962 (1.4546) teacher_loss 0.1656 (0.1086) loss_zs_kd 0.0725 (0.0854) loss_oracle 0.6488 (0.5074) kd_loss 1.0699 (1.0497) acc 93.7500 (97.1484) gate/entropy 1.0328 (1.0305) gate/usage_max 0.4995 (0.5045) gate/usage_min 0.2076 (0.2091) gate/usage_std 0.1226 (0.1251) teacher/entropy 0.1043 (0.0782) teacher/usage_max 0.3445 (0.4657) teacher/usage_min 0.3224 (0.2042) teacher/usage_std 0.0090 (0.1115) nleep/row_max_mean 1512.0444 (1513.4849) nleep/row_max_std 78.6297 (61.8443) nleep/row_min_mean 1484.8450 (1486.6288) lr 1.8443e-03 eta 0:11:44
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,856
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 86.6%
******* Domain p best val acc:      83.5%, epoch: 7 *******
******* Domain p best val test acc: 87.3%, epoch: 7 *******
******* Domain p best test acc:     88.0%, epoch: 5 *******
epoch [11/50] batch [20/160] time 0.150 (0.155) data 0.000 (0.017) loss 1.5060 (1.5720) teacher_loss 0.0485 (0.1146) loss_zs_kd 0.0775 (0.0758) loss_oracle 0.4696 (0.5415) kd_loss 1.1839 (1.1488) acc 100.0000 (97.0312) gate/entropy 1.0334 (1.0331) gate/usage_max 0.4982 (0.4988) gate/usage_min 0.2076 (0.2076) gate/usage_std 0.1218 (0.1221) teacher/entropy 0.0233 (0.0697) teacher/usage_max 0.4366 (0.4556) teacher/usage_min 0.2442 (0.2225) teacher/usage_std 0.0792 (0.1003) nleep/row_max_mean 1512.8152 (1516.0096) nleep/row_max_std 70.2982 (58.0086) nleep/row_min_mean 1484.4019 (1488.4300) lr 1.8443e-03 eta 0:16:30
epoch [11/50] batch [40/160] time 0.141 (0.146) data 0.000 (0.008) loss 1.4829 (1.5725) teacher_loss 0.0331 (0.1184) loss_zs_kd 0.0821 (0.0770) loss_oracle 0.4440 (0.5327) kd_loss 1.1868 (1.1493) acc 100.0000 (97.3438) gate/entropy 1.0342 (1.0335) gate/usage_max 0.4970 (0.4981) gate/usage_min 0.2079 (0.2077) gate/usage_std 0.1211 (0.1218) teacher/entropy 0.1056 (0.0736) teacher/usage_max 0.5302 (0.4554) teacher/usage_min 0.1062 (0.2181) teacher/usage_std 0.1744 (0.1018) nleep/row_max_mean 1515.9524 (1515.3720) nleep/row_max_std 61.2800 (59.3964) nleep/row_min_mean 1488.1160 (1487.6832) lr 1.8443e-03 eta 0:15:30
epoch [11/50] batch [60/160] time 0.152 (0.142) data 0.001 (0.006) loss 1.4482 (1.5830) teacher_loss 0.0439 (0.1192) loss_zs_kd 0.0774 (0.0761) loss_oracle 0.5711 (0.5574) kd_loss 1.0800 (1.1470) acc 100.0000 (97.3958) gate/entropy 1.0349 (1.0338) gate/usage_max 0.4959 (0.4976) gate/usage_min 0.2082 (0.2078) gate/usage_std 0.1204 (0.1214) teacher/entropy 0.0787 (0.0767) teacher/usage_max 0.5342 (0.4507) teacher/usage_min 0.2095 (0.2216) teacher/usage_std 0.1433 (0.0984) nleep/row_max_mean 1494.3777 (1513.4951) nleep/row_max_std 81.7578 (62.1804) nleep/row_min_mean 1468.0361 (1485.8463) lr 1.8443e-03 eta 0:15:00
epoch [11/50] batch [80/160] time 0.123 (0.140) data 0.000 (0.004) loss 1.6686 (1.5906) teacher_loss 0.2284 (0.1160) loss_zs_kd 0.0671 (0.0775) loss_oracle 0.6473 (0.5802) kd_loss 1.0830 (1.1458) acc 93.7500 (97.3438) gate/entropy 1.0355 (1.0342) gate/usage_max 0.4946 (0.4970) gate/usage_min 0.2082 (0.2079) gate/usage_std 0.1197 (0.1211) teacher/entropy 0.1760 (0.0771) teacher/usage_max 0.4722 (0.4526) teacher/usage_min 0.2410 (0.2186) teacher/usage_std 0.1000 (0.1000) nleep/row_max_mean 1500.0083 (1512.2245) nleep/row_max_std 79.6177 (63.6428) nleep/row_min_mean 1473.6741 (1484.3879) lr 1.8443e-03 eta 0:14:42
epoch [11/50] batch [100/160] time 0.107 (0.136) data 0.000 (0.003) loss 1.5751 (1.5894) teacher_loss 0.0731 (0.1175) loss_zs_kd 0.0779 (0.0760) loss_oracle 0.5064 (0.5761) kd_loss 1.2099 (1.1458) acc 100.0000 (97.3750) gate/entropy 1.0362 (1.0345) gate/usage_max 0.4934 (0.4964) gate/usage_min 0.2084 (0.2080) gate/usage_std 0.1190 (0.1207) teacher/entropy 0.1007 (0.0838) teacher/usage_max 0.5200 (0.4553) teacher/usage_min 0.1707 (0.2111) teacher/usage_std 0.1437 (0.1041) nleep/row_max_mean 1505.3356 (1511.3590) nleep/row_max_std 74.4389 (64.0989) nleep/row_min_mean 1480.5107 (1483.2987) lr 1.8443e-03 eta 0:14:18
epoch [11/50] batch [120/160] time 0.120 (0.133) data 0.000 (0.003) loss 1.6103 (1.5905) teacher_loss 0.0799 (0.1157) loss_zs_kd 0.0720 (0.0752) loss_oracle 0.6517 (0.5746) kd_loss 1.1686 (1.1499) acc 100.0000 (97.3698) gate/entropy 1.0371 (1.0349) gate/usage_max 0.4919 (0.4957) gate/usage_min 0.2088 (0.2081) gate/usage_std 0.1180 (0.1203) teacher/entropy 0.0855 (0.0854) teacher/usage_max 0.4259 (0.4589) teacher/usage_min 0.2120 (0.2050) teacher/usage_std 0.0897 (0.1083) nleep/row_max_mean 1506.8453 (1511.3949) nleep/row_max_std 69.3021 (63.9476) nleep/row_min_mean 1477.3237 (1483.0530) lr 1.8443e-03 eta 0:13:56
epoch [11/50] batch [140/160] time 0.127 (0.131) data 0.000 (0.003) loss 1.6711 (1.5979) teacher_loss 0.1548 (0.1147) loss_zs_kd 0.1077 (0.0747) loss_oracle 0.7126 (0.5840) kd_loss 1.1062 (1.1538) acc 96.8750 (97.4554) gate/entropy 1.0379 (1.0353) gate/usage_max 0.4909 (0.4951) gate/usage_min 0.2095 (0.2083) gate/usage_std 0.1173 (0.1200) teacher/entropy 0.1429 (0.0869) teacher/usage_max 0.4916 (0.4633) teacher/usage_min 0.1627 (0.2002) teacher/usage_std 0.1346 (0.1123) nleep/row_max_mean 1507.6508 (1510.9739) nleep/row_max_std 58.9597 (63.7913) nleep/row_min_mean 1480.2617 (1482.7665) lr 1.8443e-03 eta 0:13:39
epoch [11/50] batch [160/160] time 0.069 (0.126) data 0.000 (0.002) loss 1.4814 (1.6021) teacher_loss 0.0536 (0.1180) loss_zs_kd 0.0672 (0.0742) loss_oracle 0.5976 (0.5832) kd_loss 1.0954 (1.1554) acc 100.0000 (97.3828) gate/entropy 1.0385 (1.0356) gate/usage_max 0.4900 (0.4945) gate/usage_min 0.2101 (0.2085) gate/usage_std 0.1167 (0.1196) teacher/entropy 0.0747 (0.0879) teacher/usage_max 0.4243 (0.4640) teacher/usage_min 0.2826 (0.1971) teacher/usage_std 0.0644 (0.1141) nleep/row_max_mean 1509.8364 (1510.9441) nleep/row_max_std 60.6236 (63.1216) nleep/row_min_mean 1483.5651 (1482.7140) lr 1.8090e-03 eta 0:13:04
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,832
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,904
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 87.5%
******* Domain p best val acc:      83.5%, epoch: 7 *******
******* Domain p best val test acc: 87.3%, epoch: 7 *******
******* Domain p best test acc:     88.0%, epoch: 5 *******
epoch [12/50] batch [20/160] time 0.094 (0.121) data 0.000 (0.019) loss 1.5520 (1.6105) teacher_loss 0.0992 (0.1357) loss_zs_kd 0.0794 (0.0699) loss_oracle 0.5531 (0.5354) kd_loss 1.1366 (1.1722) acc 93.7500 (96.2500) gate/entropy 1.0390 (1.0388) gate/usage_max 0.4894 (0.4895) gate/usage_min 0.2106 (0.2104) gate/usage_std 0.1162 (0.1164) teacher/entropy 0.0723 (0.0969) teacher/usage_max 0.4393 (0.4882) teacher/usage_min 0.2531 (0.1662) teacher/usage_std 0.0782 (0.1362) nleep/row_max_mean 1517.0111 (1505.4066) nleep/row_max_std 46.7708 (63.9264) nleep/row_min_mean 1488.7358 (1478.0136) lr 1.8090e-03 eta 0:12:31
epoch [12/50] batch [40/160] time 0.075 (0.110) data 0.000 (0.009) loss 1.6623 (1.5903) teacher_loss 0.0732 (0.1074) loss_zs_kd 0.0598 (0.0694) loss_oracle 0.6484 (0.5435) kd_loss 1.2349 (1.1763) acc 93.7500 (97.1094) gate/entropy 1.0396 (1.0391) gate/usage_max 0.4886 (0.4892) gate/usage_min 0.2113 (0.2107) gate/usage_std 0.1156 (0.1161) teacher/entropy 0.0631 (0.0898) teacher/usage_max 0.5149 (0.4700) teacher/usage_min 0.1769 (0.1732) teacher/usage_std 0.1391 (0.1266) nleep/row_max_mean 1520.6313 (1507.7380) nleep/row_max_std 43.9368 (61.5111) nleep/row_min_mean 1491.9814 (1480.4924) lr 1.8090e-03 eta 0:11:20
epoch [12/50] batch [60/160] time 0.206 (0.110) data 0.001 (0.006) loss 1.5517 (1.5950) teacher_loss 0.0471 (0.1105) loss_zs_kd 0.0764 (0.0739) loss_oracle 0.5802 (0.5481) kd_loss 1.1763 (1.1735) acc 100.0000 (97.2396) gate/entropy 1.0403 (1.0394) gate/usage_max 0.4877 (0.4888) gate/usage_min 0.2119 (0.2110) gate/usage_std 0.1150 (0.1158) teacher/entropy 0.0865 (0.0847) teacher/usage_max 0.4162 (0.4706) teacher/usage_min 0.1725 (0.1807) teacher/usage_std 0.1137 (0.1243) nleep/row_max_mean 1515.8539 (1507.8029) nleep/row_max_std 44.6481 (61.3863) nleep/row_min_mean 1489.5955 (1480.7887) lr 1.8090e-03 eta 0:11:22
epoch [12/50] batch [80/160] time 0.167 (0.113) data 0.000 (0.005) loss 1.4984 (1.6055) teacher_loss 0.1055 (0.1099) loss_zs_kd 0.0760 (0.0749) loss_oracle 0.5574 (0.5717) kd_loss 1.0761 (1.1723) acc 100.0000 (97.3438) gate/entropy 1.0408 (1.0397) gate/usage_max 0.4869 (0.4885) gate/usage_min 0.2125 (0.2113) gate/usage_std 0.1144 (0.1155) teacher/entropy 0.1193 (0.0810) teacher/usage_max 0.4793 (0.4694) teacher/usage_min 0.2261 (0.1820) teacher/usage_std 0.1070 (0.1230) nleep/row_max_mean 1511.0775 (1508.1657) nleep/row_max_std 58.0796 (60.3830) nleep/row_min_mean 1487.0835 (1481.2827) lr 1.8090e-03 eta 0:11:35
epoch [12/50] batch [100/160] time 0.132 (0.113) data 0.000 (0.004) loss 1.6831 (1.6055) teacher_loss 0.0799 (0.1050) loss_zs_kd 0.1013 (0.0781) loss_oracle 0.6782 (0.5832) kd_loss 1.2135 (1.1698) acc 96.8750 (97.3750) gate/entropy 1.0416 (1.0400) gate/usage_max 0.4856 (0.4879) gate/usage_min 0.2128 (0.2116) gate/usage_std 0.1136 (0.1152) teacher/entropy 0.0741 (0.0803) teacher/usage_max 0.4853 (0.4703) teacher/usage_min 0.1682 (0.1833) teacher/usage_std 0.1298 (0.1230) nleep/row_max_mean 1522.4508 (1507.8217) nleep/row_max_std 48.6854 (60.8437) nleep/row_min_mean 1497.0488 (1481.0720) lr 1.8090e-03 eta 0:11:35
epoch [12/50] batch [120/160] time 0.119 (0.112) data 0.000 (0.003) loss 1.6749 (1.6043) teacher_loss 0.1725 (0.1045) loss_zs_kd 0.0570 (0.0781) loss_oracle 0.6339 (0.5918) kd_loss 1.1570 (1.1648) acc 96.8750 (97.3698) gate/entropy 1.0426 (1.0404) gate/usage_max 0.4840 (0.4874) gate/usage_min 0.2135 (0.2119) gate/usage_std 0.1126 (0.1148) teacher/entropy 0.1067 (0.0799) teacher/usage_max 0.4222 (0.4694) teacher/usage_min 0.1697 (0.1881) teacher/usage_std 0.1158 (0.1206) nleep/row_max_mean 1515.2205 (1507.0975) nleep/row_max_std 54.1019 (62.5400) nleep/row_min_mean 1488.9497 (1480.4867) lr 1.8090e-03 eta 0:11:26
epoch [12/50] batch [140/160] time 0.137 (0.116) data 0.000 (0.003) loss 1.7551 (1.6047) teacher_loss 0.0362 (0.1039) loss_zs_kd 0.0700 (0.0774) loss_oracle 0.8330 (0.6006) kd_loss 1.2674 (1.1618) acc 100.0000 (97.3438) gate/entropy 1.0434 (1.0408) gate/usage_max 0.4825 (0.4868) gate/usage_min 0.2139 (0.2122) gate/usage_std 0.1116 (0.1144) teacher/entropy 0.0269 (0.0776) teacher/usage_max 0.4664 (0.4706) teacher/usage_min 0.1326 (0.1885) teacher/usage_std 0.1444 (0.1207) nleep/row_max_mean 1503.9116 (1506.9594) nleep/row_max_std 76.1983 (62.8929) nleep/row_min_mean 1476.2612 (1480.3359) lr 1.8090e-03 eta 0:11:48
epoch [12/50] batch [160/160] time 0.163 (0.119) data 0.000 (0.003) loss 1.6220 (1.6116) teacher_loss 0.1117 (0.0993) loss_zs_kd 0.0789 (0.0796) loss_oracle 0.6005 (0.6163) kd_loss 1.1705 (1.1644) acc 96.8750 (97.4805) gate/entropy 1.0443 (1.0412) gate/usage_max 0.4809 (0.4861) gate/usage_min 0.2144 (0.2124) gate/usage_std 0.1107 (0.1140) teacher/entropy 0.0942 (0.0744) teacher/usage_max 0.4216 (0.4711) teacher/usage_min 0.1581 (0.1878) teacher/usage_std 0.1239 (0.1213) nleep/row_max_mean 1481.6741 (1507.0287) nleep/row_max_std 102.0571 (62.4358) nleep/row_min_mean 1456.0774 (1480.2628) lr 1.7705e-03 eta 0:12:05
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,843
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,905
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 87.6%
******* Domain p best val acc:      83.5%, epoch: 12 *******
******* Domain p best val test acc: 86.0%, epoch: 12 *******
******* Domain p best test acc:     88.0%, epoch: 5 *******
epoch [13/50] batch [20/160] time 0.133 (0.153) data 0.000 (0.011) loss 1.6885 (1.6331) teacher_loss 0.0159 (0.0764) loss_zs_kd 0.0791 (0.0939) loss_oracle 0.7325 (0.6370) kd_loss 1.2668 (1.1912) acc 100.0000 (98.1250) gate/entropy 1.0453 (1.0449) gate/usage_max 0.4790 (0.4797) gate/usage_min 0.2147 (0.2146) gate/usage_std 0.1096 (0.1100) teacher/entropy 0.0156 (0.0480) teacher/usage_max 0.4710 (0.5012) teacher/usage_min 0.1543 (0.1618) teacher/usage_std 0.1326 (0.1439) nleep/row_max_mean 1507.5359 (1511.0481) nleep/row_max_std 87.5286 (61.0662) nleep/row_min_mean 1480.1619 (1482.8081) lr 1.7705e-03 eta 0:15:29
epoch [13/50] batch [40/160] time 0.136 (0.145) data 0.000 (0.006) loss 1.6468 (1.6409) teacher_loss 0.0294 (0.0794) loss_zs_kd 0.0763 (0.0929) loss_oracle 0.7666 (0.6635) kd_loss 1.1959 (1.1833) acc 100.0000 (98.3594) gate/entropy 1.0465 (1.0455) gate/usage_max 0.4767 (0.4787) gate/usage_min 0.2154 (0.2149) gate/usage_std 0.1082 (0.1094) teacher/entropy 0.0217 (0.0470) teacher/usage_max 0.4046 (0.4984) teacher/usage_min 0.2182 (0.1673) teacher/usage_std 0.0822 (0.1398) nleep/row_max_mean 1502.0017 (1509.0842) nleep/row_max_std 69.3013 (62.0213) nleep/row_min_mean 1471.4856 (1480.4102) lr 1.7705e-03 eta 0:14:34
epoch [13/50] batch [60/160] time 0.151 (0.145) data 0.001 (0.004) loss 1.9106 (1.6505) teacher_loss 0.2417 (0.0934) loss_zs_kd 0.0709 (0.0856) loss_oracle 0.7789 (0.6644) kd_loss 1.2440 (1.1821) acc 90.6250 (97.9688) gate/entropy 1.0475 (1.0460) gate/usage_max 0.4750 (0.4778) gate/usage_min 0.2159 (0.2151) gate/usage_std 0.1071 (0.1088) teacher/entropy 0.0871 (0.0514) teacher/usage_max 0.5225 (0.5032) teacher/usage_min 0.0693 (0.1641) teacher/usage_std 0.1924 (0.1431) nleep/row_max_mean 1519.5005 (1507.1858) nleep/row_max_std 50.7491 (64.3742) nleep/row_min_mean 1487.5161 (1478.3295) lr 1.7705e-03 eta 0:14:30
epoch [13/50] batch [80/160] time 0.110 (0.134) data 0.000 (0.003) loss 1.6087 (1.6413) teacher_loss 0.0401 (0.0900) loss_zs_kd 0.0831 (0.0861) loss_oracle 0.6583 (0.6558) kd_loss 1.1979 (1.1804) acc 100.0000 (97.9297) gate/entropy 1.0485 (1.0465) gate/usage_max 0.4729 (0.4767) gate/usage_min 0.2163 (0.2154) gate/usage_std 0.1059 (0.1082) teacher/entropy 0.0725 (0.0551) teacher/usage_max 0.5076 (0.5034) teacher/usage_min 0.0986 (0.1591) teacher/usage_std 0.1723 (0.1462) nleep/row_max_mean 1527.7261 (1507.6422) nleep/row_max_std 47.5835 (62.2402) nleep/row_min_mean 1495.8494 (1478.6339) lr 1.7705e-03 eta 0:13:26
epoch [13/50] batch [100/160] time 0.096 (0.131) data 0.000 (0.002) loss 1.5829 (1.6420) teacher_loss 0.0597 (0.0946) loss_zs_kd 0.0505 (0.0853) loss_oracle 0.5804 (0.6437) kd_loss 1.2077 (1.1829) acc 96.8750 (97.7500) gate/entropy 1.0498 (1.0471) gate/usage_max 0.4705 (0.4757) gate/usage_min 0.2171 (0.2157) gate/usage_std 0.1045 (0.1076) teacher/entropy 0.0452 (0.0555) teacher/usage_max 0.4339 (0.5015) teacher/usage_min 0.1504 (0.1557) teacher/usage_std 0.1295 (0.1469) nleep/row_max_mean 1516.1492 (1507.7618) nleep/row_max_std 47.7500 (62.2865) nleep/row_min_mean 1487.4169 (1478.5946) lr 1.7705e-03 eta 0:13:04
epoch [13/50] batch [120/160] time 0.157 (0.126) data 0.000 (0.002) loss 1.6349 (1.6441) teacher_loss 0.0555 (0.0958) loss_zs_kd 0.0883 (0.0844) loss_oracle 0.6415 (0.6422) kd_loss 1.2145 (1.1851) acc 96.8750 (97.6042) gate/entropy 1.0509 (1.0476) gate/usage_max 0.4686 (0.4747) gate/usage_min 0.2181 (0.2160) gate/usage_std 0.1032 (0.1070) teacher/entropy 0.0385 (0.0575) teacher/usage_max 0.5568 (0.5004) teacher/usage_min 0.0896 (0.1501) teacher/usage_std 0.1913 (0.1489) nleep/row_max_mean 1508.2653 (1507.6891) nleep/row_max_std 60.9082 (62.1694) nleep/row_min_mean 1478.0890 (1478.5496) lr 1.7705e-03 eta 0:12:30
epoch [13/50] batch [140/160] time 0.084 (0.121) data 0.000 (0.002) loss 1.5437 (1.6408) teacher_loss 0.0308 (0.0962) loss_zs_kd 0.0650 (0.0832) loss_oracle 0.6103 (0.6347) kd_loss 1.1752 (1.1857) acc 100.0000 (97.7679) gate/entropy 1.0520 (1.0482) gate/usage_max 0.4667 (0.4737) gate/usage_min 0.2188 (0.2163) gate/usage_std 0.1021 (0.1064) teacher/entropy 0.0443 (0.0598) teacher/usage_max 0.6150 (0.5020) teacher/usage_min 0.1025 (0.1447) teacher/usage_std 0.2123 (0.1523) nleep/row_max_mean 1518.8777 (1507.6728) nleep/row_max_std 49.4608 (62.6906) nleep/row_min_mean 1488.6238 (1478.5576) lr 1.7705e-03 eta 0:12:01
epoch [13/50] batch [160/160] time 0.064 (0.119) data 0.000 (0.002) loss 1.5889 (1.6410) teacher_loss 0.0747 (0.0948) loss_zs_kd 0.0876 (0.0814) loss_oracle 0.5285 (0.6352) kd_loss 1.2061 (1.1879) acc 100.0000 (97.7539) gate/entropy 1.0531 (1.0487) gate/usage_max 0.4648 (0.4727) gate/usage_min 0.2198 (0.2167) gate/usage_std 0.1008 (0.1058) teacher/entropy 0.0532 (0.0610) teacher/usage_max 0.4359 (0.5016) teacher/usage_min 0.1331 (0.1404) teacher/usage_std 0.1416 (0.1541) nleep/row_max_mean 1496.2007 (1507.3086) nleep/row_max_std 72.5995 (63.3873) nleep/row_min_mean 1471.4155 (1478.2805) lr 1.7290e-03 eta 0:11:44
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,842
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,924
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.9%
******* Domain p best val acc:      83.5%, epoch: 12 *******
******* Domain p best val test acc: 86.0%, epoch: 12 *******
******* Domain p best test acc:     88.0%, epoch: 5 *******
epoch [14/50] batch [20/160] time 0.081 (0.136) data 0.000 (0.018) loss 1.5838 (1.6869) teacher_loss 0.0245 (0.0831) loss_zs_kd 0.0928 (0.0922) loss_oracle 0.6215 (0.6896) kd_loss 1.2021 (1.2129) acc 100.0000 (97.8125) gate/entropy 1.0541 (1.0536) gate/usage_max 0.4628 (0.4638) gate/usage_min 0.2207 (0.2203) gate/usage_std 0.0996 (0.1002) teacher/entropy 0.0361 (0.0504) teacher/usage_max 0.6217 (0.5160) teacher/usage_min 0.0666 (0.1040) teacher/usage_std 0.2272 (0.1739) nleep/row_max_mean 1509.4783 (1511.0141) nleep/row_max_std 69.2133 (59.7886) nleep/row_min_mean 1482.0740 (1481.6242) lr 1.7290e-03 eta 0:13:21
epoch [14/50] batch [40/160] time 0.123 (0.120) data 0.000 (0.009) loss 1.7292 (1.6836) teacher_loss 0.1632 (0.0986) loss_zs_kd 0.0831 (0.0832) loss_oracle 0.6395 (0.6670) kd_loss 1.2047 (1.2099) acc 96.8750 (97.1094) gate/entropy 1.0555 (1.0542) gate/usage_max 0.4604 (0.4627) gate/usage_min 0.2220 (0.2208) gate/usage_std 0.0979 (0.0995) teacher/entropy 0.0512 (0.0561) teacher/usage_max 0.4997 (0.5231) teacher/usage_min 0.0969 (0.1015) teacher/usage_std 0.1717 (0.1786) nleep/row_max_mean 1504.6096 (1509.6583) nleep/row_max_std 79.9996 (60.9280) nleep/row_min_mean 1474.7554 (1480.5940) lr 1.7290e-03 eta 0:11:47
epoch [14/50] batch [60/160] time 0.134 (0.128) data 0.001 (0.006) loss 1.6373 (1.6737) teacher_loss 0.0169 (0.0962) loss_zs_kd 0.0843 (0.0822) loss_oracle 0.7028 (0.6602) kd_loss 1.2268 (1.2063) acc 100.0000 (97.1875) gate/entropy 1.0569 (1.0548) gate/usage_max 0.4579 (0.4616) gate/usage_min 0.2232 (0.2214) gate/usage_std 0.0963 (0.0987) teacher/entropy 0.0239 (0.0580) teacher/usage_max 0.6154 (0.5268) teacher/usage_min 0.0410 (0.0984) teacher/usage_std 0.2346 (0.1819) nleep/row_max_mean 1518.2103 (1508.6022) nleep/row_max_std 46.6148 (63.5041) nleep/row_min_mean 1485.8119 (1479.8261) lr 1.7290e-03 eta 0:12:28
epoch [14/50] batch [80/160] time 0.151 (0.131) data 0.000 (0.005) loss 1.8765 (1.6876) teacher_loss 0.1331 (0.1043) loss_zs_kd 0.0871 (0.0826) loss_oracle 0.7819 (0.6583) kd_loss 1.3090 (1.2129) acc 96.8750 (96.9922) gate/entropy 1.0581 (1.0555) gate/usage_max 0.4556 (0.4604) gate/usage_min 0.2245 (0.2219) gate/usage_std 0.0948 (0.0980) teacher/entropy 0.0238 (0.0547) teacher/usage_max 0.5444 (0.5266) teacher/usage_min 0.0004 (0.0900) teacher/usage_std 0.2382 (0.1864) nleep/row_max_mean 1517.4624 (1509.8565) nleep/row_max_std 34.6515 (61.4900) nleep/row_min_mean 1485.7954 (1481.0209) lr 1.7290e-03 eta 0:12:46
epoch [14/50] batch [100/160] time 0.148 (0.134) data 0.000 (0.004) loss 1.7333 (1.6768) teacher_loss 0.0837 (0.0968) loss_zs_kd 0.0872 (0.0821) loss_oracle 0.7607 (0.6532) kd_loss 1.2257 (1.2124) acc 96.8750 (97.2500) gate/entropy 1.0593 (1.0561) gate/usage_max 0.4532 (0.4592) gate/usage_min 0.2255 (0.2225) gate/usage_std 0.0933 (0.0972) teacher/entropy 0.0272 (0.0542) teacher/usage_max 0.4700 (0.5256) teacher/usage_min 0.1428 (0.0879) teacher/usage_std 0.1389 (0.1871) nleep/row_max_mean 1520.0887 (1510.1039) nleep/row_max_std 46.2053 (61.3625) nleep/row_min_mean 1487.5725 (1481.2517) lr 1.7290e-03 eta 0:13:01
epoch [14/50] batch [120/160] time 0.133 (0.137) data 0.000 (0.003) loss 1.6007 (1.6814) teacher_loss 0.0356 (0.0988) loss_zs_kd 0.0792 (0.0821) loss_oracle 0.6107 (0.6589) kd_loss 1.2202 (1.2121) acc 100.0000 (97.1875) gate/entropy 1.0607 (1.0568) gate/usage_max 0.4505 (0.4579) gate/usage_min 0.2268 (0.2232) gate/usage_std 0.0916 (0.0964) teacher/entropy 0.0318 (0.0536) teacher/usage_max 0.4999 (0.5273) teacher/usage_min 0.0807 (0.0871) teacher/usage_std 0.1816 (0.1884) nleep/row_max_mean 1529.1582 (1510.1963) nleep/row_max_std 32.4499 (61.8194) nleep/row_min_mean 1499.2094 (1481.3136) lr 1.7290e-03 eta 0:13:16
epoch [14/50] batch [140/160] time 0.155 (0.140) data 0.000 (0.003) loss 1.6884 (1.6833) teacher_loss 0.1268 (0.1006) loss_zs_kd 0.0627 (0.0817) loss_oracle 0.6614 (0.6596) kd_loss 1.1995 (1.2121) acc 96.8750 (97.1652) gate/entropy 1.0621 (1.0575) gate/usage_max 0.4478 (0.4567) gate/usage_min 0.2284 (0.2238) gate/usage_std 0.0898 (0.0956) teacher/entropy 0.0639 (0.0538) teacher/usage_max 0.4682 (0.5292) teacher/usage_min 0.0869 (0.0836) teacher/usage_std 0.1745 (0.1906) nleep/row_max_mean 1497.0237 (1510.2998) nleep/row_max_std 85.5483 (61.9824) nleep/row_min_mean 1468.6860 (1481.3196) lr 1.7290e-03 eta 0:13:27
epoch [14/50] batch [160/160] time 0.145 (0.140) data 0.000 (0.002) loss 1.6449 (1.6855) teacher_loss 0.0388 (0.1020) loss_zs_kd 0.0663 (0.0807) loss_oracle 0.7203 (0.6611) kd_loss 1.2128 (1.2127) acc 100.0000 (97.1875) gate/entropy 1.0637 (1.0581) gate/usage_max 0.4450 (0.4554) gate/usage_min 0.2303 (0.2245) gate/usage_std 0.0879 (0.0947) teacher/entropy 0.0285 (0.0528) teacher/usage_max 0.5200 (0.5276) teacher/usage_min 0.0737 (0.0812) teacher/usage_std 0.1893 (0.1914) nleep/row_max_mean 1515.1587 (1510.5177) nleep/row_max_std 74.2559 (61.8462) nleep/row_min_mean 1486.2670 (1481.6052) lr 1.6845e-03 eta 0:13:25
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,828
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.7%
******* Domain p best val acc:      83.5%, epoch: 12 *******
******* Domain p best val test acc: 86.0%, epoch: 12 *******
******* Domain p best test acc:     88.0%, epoch: 5 *******
epoch [15/50] batch [20/160] time 0.137 (0.119) data 0.000 (0.015) loss 1.6498 (1.7076) teacher_loss 0.0337 (0.1129) loss_zs_kd 0.0824 (0.0702) loss_oracle 0.7103 (0.6602) kd_loss 1.2197 (1.2295) acc 100.0000 (96.7188) gate/entropy 1.0650 (1.0643) gate/usage_max 0.4424 (0.4438) gate/usage_min 0.2317 (0.2309) gate/usage_std 0.0862 (0.0871) teacher/entropy 0.0284 (0.0362) teacher/usage_max 0.5135 (0.5312) teacher/usage_min 0.0611 (0.0467) teacher/usage_std 0.1958 (0.2088) nleep/row_max_mean 1529.5422 (1514.3158) nleep/row_max_std 27.8363 (55.0533) nleep/row_min_mean 1498.1960 (1485.3655) lr 1.6845e-03 eta 0:11:21
epoch [15/50] batch [40/160] time 0.089 (0.116) data 0.000 (0.008) loss 1.6980 (1.7085) teacher_loss 0.1481 (0.1154) loss_zs_kd 0.0688 (0.0736) loss_oracle 0.5581 (0.6611) kd_loss 1.2365 (1.2257) acc 96.8750 (96.8750) gate/entropy 1.0664 (1.0650) gate/usage_max 0.4399 (0.4424) gate/usage_min 0.2336 (0.2318) gate/usage_std 0.0843 (0.0861) teacher/entropy 0.0455 (0.0428) teacher/usage_max 0.5115 (0.5418) teacher/usage_min 0.0293 (0.0472) teacher/usage_std 0.2160 (0.2115) nleep/row_max_mean 1506.7732 (1512.4281) nleep/row_max_std 56.6087 (58.0884) nleep/row_min_mean 1479.8425 (1483.5976) lr 1.6845e-03 eta 0:11:01
epoch [15/50] batch [60/160] time 0.138 (0.114) data 0.001 (0.005) loss 1.7201 (1.6927) teacher_loss 0.1806 (0.1068) loss_zs_kd 0.1000 (0.0748) loss_oracle 0.5832 (0.6439) kd_loss 1.1979 (1.2265) acc 93.7500 (97.3438) gate/entropy 1.0678 (1.0657) gate/usage_max 0.4371 (0.4410) gate/usage_min 0.2354 (0.2327) gate/usage_std 0.0825 (0.0852) teacher/entropy 0.0384 (0.0422) teacher/usage_max 0.5434 (0.5433) teacher/usage_min 0.0500 (0.0449) teacher/usage_std 0.2080 (0.2141) nleep/row_max_mean 1503.1180 (1512.2045) nleep/row_max_std 55.0048 (58.0681) nleep/row_min_mean 1473.3861 (1483.3451) lr 1.6845e-03 eta 0:10:48
epoch [15/50] batch [80/160] time 0.084 (0.112) data 0.000 (0.004) loss 1.5094 (1.6853) teacher_loss 0.0659 (0.1094) loss_zs_kd 0.0774 (0.0747) loss_oracle 0.5333 (0.6274) kd_loss 1.1382 (1.2249) acc 100.0000 (97.2266) gate/entropy 1.0691 (1.0664) gate/usage_max 0.4344 (0.4397) gate/usage_min 0.2371 (0.2336) gate/usage_std 0.0806 (0.0843) teacher/entropy 0.0684 (0.0401) teacher/usage_max 0.6375 (0.5413) teacher/usage_min 0.0419 (0.0446) teacher/usage_std 0.2433 (0.2136) nleep/row_max_mean 1490.7983 (1511.0838) nleep/row_max_std 82.6574 (59.0288) nleep/row_min_mean 1462.9927 (1482.5469) lr 1.6845e-03 eta 0:10:34
epoch [15/50] batch [100/160] time 0.102 (0.110) data 0.000 (0.003) loss 1.6107 (1.6802) teacher_loss 0.0634 (0.1054) loss_zs_kd 0.0741 (0.0747) loss_oracle 0.6053 (0.6300) kd_loss 1.2076 (1.2224) acc 96.8750 (97.2500) gate/entropy 1.0704 (1.0671) gate/usage_max 0.4317 (0.4384) gate/usage_min 0.2388 (0.2345) gate/usage_std 0.0788 (0.0834) teacher/entropy 0.0333 (0.0392) teacher/usage_max 0.4785 (0.5432) teacher/usage_min 0.0862 (0.0436) teacher/usage_std 0.1756 (0.2150) nleep/row_max_mean 1508.7146 (1510.7890) nleep/row_max_std 69.5634 (60.0052) nleep/row_min_mean 1480.2544 (1482.3344) lr 1.6845e-03 eta 0:10:20
epoch [15/50] batch [120/160] time 0.097 (0.109) data 0.000 (0.003) loss 1.6368 (1.6773) teacher_loss 0.1029 (0.1067) loss_zs_kd 0.0709 (0.0754) loss_oracle 0.6201 (0.6305) kd_loss 1.1885 (1.2176) acc 93.7500 (97.2396) gate/entropy 1.0719 (1.0678) gate/usage_max 0.4285 (0.4370) gate/usage_min 0.2407 (0.2353) gate/usage_std 0.0767 (0.0825) teacher/entropy 0.0205 (0.0393) teacher/usage_max 0.5579 (0.5434) teacher/usage_min 0.0663 (0.0449) teacher/usage_std 0.2029 (0.2142) nleep/row_max_mean 1500.8278 (1510.0740) nleep/row_max_std 78.1139 (61.0185) nleep/row_min_mean 1471.9951 (1481.6382) lr 1.6845e-03 eta 0:10:13
epoch [15/50] batch [140/160] time 0.151 (0.111) data 0.000 (0.002) loss 1.5714 (1.6775) teacher_loss 0.0556 (0.1044) loss_zs_kd 0.0911 (0.0752) loss_oracle 0.5475 (0.6343) kd_loss 1.1965 (1.2183) acc 100.0000 (97.2991) gate/entropy 1.0730 (1.0684) gate/usage_max 0.4260 (0.4356) gate/usage_min 0.2422 (0.2362) gate/usage_std 0.0750 (0.0815) teacher/entropy 0.0410 (0.0375) teacher/usage_max 0.5255 (0.5447) teacher/usage_min 0.0272 (0.0420) teacher/usage_std 0.2188 (0.2160) nleep/row_max_mean 1503.3676 (1510.4385) nleep/row_max_std 73.3589 (61.1468) nleep/row_min_mean 1476.8799 (1481.8380) lr 1.6845e-03 eta 0:10:21
epoch [15/50] batch [160/160] time 0.162 (0.110) data 0.000 (0.002) loss 1.7206 (1.6826) teacher_loss 0.1295 (0.1064) loss_zs_kd 0.0761 (0.0762) loss_oracle 0.7222 (0.6396) kd_loss 1.1920 (1.2183) acc 96.8750 (97.2266) gate/entropy 1.0745 (1.0691) gate/usage_max 0.4229 (0.4342) gate/usage_min 0.2446 (0.2371) gate/usage_std 0.0728 (0.0806) teacher/entropy 0.0290 (0.0362) teacher/usage_max 0.5052 (0.5466) teacher/usage_min 0.0585 (0.0410) teacher/usage_std 0.1964 (0.2170) nleep/row_max_mean 1504.5090 (1509.9144) nleep/row_max_std 85.9206 (62.4157) nleep/row_min_mean 1476.1327 (1481.2640) lr 1.6374e-03 eta 0:10:16
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,829
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,995
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 89.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.5%, epoch: 12 *******
******* Domain p best val test acc: 86.0%, epoch: 12 *******
******* Domain p best test acc:     88.7%, epoch: 15 *******
epoch [16/50] batch [20/160] time 0.153 (0.155) data 0.000 (0.014) loss 1.5414 (1.7081) teacher_loss 0.1100 (0.0922) loss_zs_kd 0.0628 (0.0805) loss_oracle 0.5455 (0.7105) kd_loss 1.1273 (1.2204) acc 96.8750 (97.3438) gate/entropy 1.0760 (1.0752) gate/usage_max 0.4196 (0.4213) gate/usage_min 0.2469 (0.2457) gate/usage_std 0.0705 (0.0717) teacher/entropy 0.0659 (0.0202) teacher/usage_max 0.5720 (0.5490) teacher/usage_min 0.0627 (0.0217) teacher/usage_std 0.2092 (0.2302) nleep/row_max_mean 1489.7307 (1513.0228) nleep/row_max_std 96.1396 (61.1968) nleep/row_min_mean 1461.0156 (1482.5528) lr 1.6374e-03 eta 0:14:24
epoch [16/50] batch [40/160] time 0.147 (0.150) data 0.000 (0.007) loss 1.6063 (1.6797) teacher_loss 0.0917 (0.0893) loss_zs_kd 0.0453 (0.0777) loss_oracle 0.6379 (0.6842) kd_loss 1.1729 (1.2094) acc 96.8750 (97.1875) gate/entropy 1.0773 (1.0759) gate/usage_max 0.4164 (0.4197) gate/usage_min 0.2490 (0.2468) gate/usage_std 0.0684 (0.0706) teacher/entropy 0.0361 (0.0264) teacher/usage_max 0.6117 (0.5585) teacher/usage_min 0.0004 (0.0243) teacher/usage_std 0.2525 (0.2304) nleep/row_max_mean 1517.6116 (1510.9002) nleep/row_max_std 54.6151 (63.8764) nleep/row_min_mean 1486.4143 (1480.3388) lr 1.6374e-03 eta 0:13:52
epoch [16/50] batch [60/160] time 0.155 (0.150) data 0.001 (0.005) loss 1.6185 (1.6856) teacher_loss 0.0337 (0.0952) loss_zs_kd 0.0625 (0.0777) loss_oracle 0.6667 (0.6868) kd_loss 1.2202 (1.2081) acc 100.0000 (97.2917) gate/entropy 1.0787 (1.0766) gate/usage_max 0.4135 (0.4181) gate/usage_min 0.2514 (0.2479) gate/usage_std 0.0662 (0.0695) teacher/entropy 0.0068 (0.0283) teacher/usage_max 0.5298 (0.5621) teacher/usage_min 0.0014 (0.0240) teacher/usage_std 0.2360 (0.2307) nleep/row_max_mean 1517.5383 (1510.2017) nleep/row_max_std 53.6182 (63.6559) nleep/row_min_mean 1485.0334 (1479.3438) lr 1.6374e-03 eta 0:13:50
epoch [16/50] batch [80/160] time 0.157 (0.149) data 0.000 (0.004) loss 1.8072 (1.6774) teacher_loss 0.1736 (0.0995) loss_zs_kd 0.0558 (0.0761) loss_oracle 0.7367 (0.6715) kd_loss 1.2374 (1.2041) acc 93.7500 (97.2266) gate/entropy 1.0798 (1.0773) gate/usage_max 0.4108 (0.4166) gate/usage_min 0.2536 (0.2491) gate/usage_std 0.0642 (0.0684) teacher/entropy 0.0328 (0.0289) teacher/usage_max 0.6720 (0.5662) teacher/usage_min 0.0468 (0.0240) teacher/usage_std 0.2579 (0.2319) nleep/row_max_mean 1520.3640 (1510.9570) nleep/row_max_std 77.9398 (61.9988) nleep/row_min_mean 1484.4709 (1480.0128) lr 1.6374e-03 eta 0:13:42
epoch [16/50] batch [100/160] time 0.124 (0.145) data 0.000 (0.003) loss 1.6281 (1.6767) teacher_loss 0.0444 (0.1033) loss_zs_kd 0.0769 (0.0777) loss_oracle 0.6021 (0.6636) kd_loss 1.2443 (1.2027) acc 100.0000 (97.0938) gate/entropy 1.0809 (1.0779) gate/usage_max 0.4080 (0.4151) gate/usage_min 0.2556 (0.2502) gate/usage_std 0.0622 (0.0673) teacher/entropy 0.0075 (0.0275) teacher/usage_max 0.5921 (0.5648) teacher/usage_min 0.0001 (0.0231) teacher/usage_std 0.2473 (0.2318) nleep/row_max_mean 1516.3728 (1510.7208) nleep/row_max_std 43.7494 (61.6157) nleep/row_min_mean 1485.4170 (1479.8949) lr 1.6374e-03 eta 0:13:17
epoch [16/50] batch [120/160] time 0.144 (0.144) data 0.000 (0.002) loss 1.5652 (1.6696) teacher_loss 0.0646 (0.1013) loss_zs_kd 0.0829 (0.0780) loss_oracle 0.5467 (0.6589) kd_loss 1.1858 (1.1999) acc 96.8750 (97.2135) gate/entropy 1.0821 (1.0785) gate/usage_max 0.4048 (0.4136) gate/usage_min 0.2577 (0.2513) gate/usage_std 0.0601 (0.0663) teacher/entropy 0.0108 (0.0276) teacher/usage_max 0.5912 (0.5626) teacher/usage_min 0.0000 (0.0230) teacher/usage_std 0.2472 (0.2311) nleep/row_max_mean 1521.2898 (1511.0411) nleep/row_max_std 28.2757 (60.9985) nleep/row_min_mean 1490.0590 (1480.2564) lr 1.6374e-03 eta 0:13:10
epoch [16/50] batch [140/160] time 0.105 (0.140) data 0.000 (0.002) loss 1.9588 (1.6698) teacher_loss 0.3398 (0.1027) loss_zs_kd 0.0697 (0.0779) loss_oracle 0.7370 (0.6568) kd_loss 1.2156 (1.1997) acc 87.5000 (97.1429) gate/entropy 1.0831 (1.0791) gate/usage_max 0.4019 (0.4121) gate/usage_min 0.2597 (0.2523) gate/usage_std 0.0582 (0.0653) teacher/entropy 0.0086 (0.0261) teacher/usage_max 0.5319 (0.5596) teacher/usage_min 0.0010 (0.0215) teacher/usage_std 0.2365 (0.2312) nleep/row_max_mean 1509.1365 (1511.2573) nleep/row_max_std 58.1692 (60.4415) nleep/row_min_mean 1476.7218 (1480.3487) lr 1.6374e-03 eta 0:12:42
epoch [16/50] batch [160/160] time 0.069 (0.135) data 0.000 (0.002) loss 1.6331 (1.6747) teacher_loss 0.0370 (0.1070) loss_zs_kd 0.0575 (0.0778) loss_oracle 0.7903 (0.6614) kd_loss 1.1723 (1.1981) acc 100.0000 (96.9531) gate/entropy 1.0844 (1.0797) gate/usage_max 0.3985 (0.4106) gate/usage_min 0.2622 (0.2534) gate/usage_std 0.0558 (0.0642) teacher/entropy 0.0275 (0.0249) teacher/usage_max 0.4998 (0.5606) teacher/usage_min 0.0244 (0.0210) teacher/usage_std 0.2187 (0.2318) nleep/row_max_mean 1489.8884 (1511.2292) nleep/row_max_std 83.6634 (60.6307) nleep/row_min_mean 1460.1666 (1480.1750) lr 1.5878e-03 eta 0:12:12
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,835
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,006
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 89.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.5%, epoch: 12 *******
******* Domain p best val test acc: 86.0%, epoch: 12 *******
******* Domain p best test acc:     89.0%, epoch: 16 *******
epoch [17/50] batch [20/160] time 0.160 (0.131) data 0.000 (0.012) loss 1.7003 (1.6651) teacher_loss 0.1501 (0.1101) loss_zs_kd 0.0790 (0.0646) loss_oracle 0.6651 (0.6884) kd_loss 1.1782 (1.1785) acc 96.8750 (97.6562) gate/entropy 1.0854 (1.0849) gate/usage_max 0.3955 (0.3969) gate/usage_min 0.2644 (0.2633) gate/usage_std 0.0537 (0.0547) teacher/entropy 0.0289 (0.0219) teacher/usage_max 0.5121 (0.5750) teacher/usage_min 0.0000 (0.0161) teacher/usage_std 0.2359 (0.2401) nleep/row_max_mean 1521.5073 (1512.3772) nleep/row_max_std 45.9287 (58.3138) nleep/row_min_mean 1488.4001 (1479.7056) lr 1.5878e-03 eta 0:11:52
epoch [17/50] batch [40/160] time 0.127 (0.126) data 0.000 (0.006) loss 1.6291 (1.6450) teacher_loss 0.0383 (0.1003) loss_zs_kd 0.0656 (0.0655) loss_oracle 0.7926 (0.6882) kd_loss 1.1618 (1.1678) acc 100.0000 (97.7344) gate/entropy 1.0865 (1.0855) gate/usage_max 0.3923 (0.3954) gate/usage_min 0.2669 (0.2646) gate/usage_std 0.0515 (0.0536) teacher/entropy 0.0331 (0.0268) teacher/usage_max 0.4961 (0.5716) teacher/usage_min 0.0117 (0.0130) teacher/usage_std 0.2274 (0.2402) nleep/row_max_mean 1516.5798 (1511.2316) nleep/row_max_std 57.8655 (58.2808) nleep/row_min_mean 1483.0671 (1478.6973) lr 1.5878e-03 eta 0:11:20
epoch [17/50] batch [60/160] time 0.088 (0.122) data 0.001 (0.004) loss 1.6464 (1.6613) teacher_loss 0.0622 (0.1074) loss_zs_kd 0.0849 (0.0669) loss_oracle 0.7357 (0.7005) kd_loss 1.1739 (1.1701) acc 100.0000 (97.2396) gate/entropy 1.0875 (1.0860) gate/usage_max 0.3893 (0.3938) gate/usage_min 0.2695 (0.2658) gate/usage_std 0.0492 (0.0525) teacher/entropy 0.0331 (0.0262) teacher/usage_max 0.5827 (0.5661) teacher/usage_min 0.0425 (0.0119) teacher/usage_std 0.2225 (0.2393) nleep/row_max_mean 1492.1820 (1510.2161) nleep/row_max_std 87.8009 (59.4080) nleep/row_min_mean 1462.4462 (1477.9128) lr 1.5878e-03 eta 0:10:58
epoch [17/50] batch [80/160] time 0.154 (0.120) data 0.000 (0.003) loss 1.7999 (1.6594) teacher_loss 0.2971 (0.1100) loss_zs_kd 0.0885 (0.0702) loss_oracle 0.6082 (0.6946) kd_loss 1.1545 (1.1671) acc 90.6250 (97.1484) gate/entropy 1.0885 (1.0865) gate/usage_max 0.3861 (0.3922) gate/usage_min 0.2721 (0.2671) gate/usage_std 0.0469 (0.0514) teacher/entropy 0.0293 (0.0266) teacher/usage_max 0.4981 (0.5616) teacher/usage_min 0.0117 (0.0113) teacher/usage_std 0.2275 (0.2383) nleep/row_max_mean 1500.6655 (1510.0371) nleep/row_max_std 75.0234 (59.5491) nleep/row_min_mean 1467.9453 (1477.9200) lr 1.5878e-03 eta 0:10:45
epoch [17/50] batch [100/160] time 0.160 (0.126) data 0.000 (0.003) loss 1.6815 (1.6561) teacher_loss 0.0884 (0.1100) loss_zs_kd 0.0763 (0.0720) loss_oracle 0.7995 (0.6914) kd_loss 1.1552 (1.1644) acc 96.8750 (97.0625) gate/entropy 1.0894 (1.0870) gate/usage_max 0.3830 (0.3907) gate/usage_min 0.2746 (0.2684) gate/usage_std 0.0447 (0.0502) teacher/entropy 0.0597 (0.0263) teacher/usage_max 0.6579 (0.5626) teacher/usage_min 0.0173 (0.0117) teacher/usage_std 0.2616 (0.2380) nleep/row_max_mean 1500.3455 (1509.4967) nleep/row_max_std 63.3414 (59.9692) nleep/row_min_mean 1465.6309 (1477.3684) lr 1.5878e-03 eta 0:11:12
epoch [17/50] batch [120/160] time 0.131 (0.129) data 0.000 (0.002) loss 1.7403 (1.6592) teacher_loss 0.1094 (0.1087) loss_zs_kd 0.0677 (0.0735) loss_oracle 0.7949 (0.6994) kd_loss 1.1995 (1.1640) acc 100.0000 (97.0833) gate/entropy 1.0904 (1.0875) gate/usage_max 0.3801 (0.3891) gate/usage_min 0.2776 (0.2696) gate/usage_std 0.0423 (0.0491) teacher/entropy 0.0227 (0.0255) teacher/usage_max 0.7283 (0.5656) teacher/usage_min 0.0224 (0.0114) teacher/usage_std 0.2942 (0.2390) nleep/row_max_mean 1505.9674 (1509.5873) nleep/row_max_std 69.1133 (59.8025) nleep/row_min_mean 1472.1864 (1477.4642) lr 1.5878e-03 eta 0:11:24
epoch [17/50] batch [140/160] time 0.128 (0.130) data 0.000 (0.002) loss 1.4840 (1.6556) teacher_loss 0.0216 (0.1077) loss_zs_kd 0.0858 (0.0756) loss_oracle 0.5870 (0.6964) kd_loss 1.1260 (1.1620) acc 100.0000 (97.1652) gate/entropy 1.0913 (1.0880) gate/usage_max 0.3770 (0.3876) gate/usage_min 0.2803 (0.2710) gate/usage_std 0.0401 (0.0480) teacher/entropy 0.0341 (0.0254) teacher/usage_max 0.5313 (0.5642) teacher/usage_min 0.0158 (0.0122) teacher/usage_std 0.2268 (0.2380) nleep/row_max_mean 1505.5295 (1509.3108) nleep/row_max_std 73.3615 (60.6135) nleep/row_min_mean 1473.5225 (1477.1703) lr 1.5878e-03 eta 0:11:31
epoch [17/50] batch [160/160] time 0.149 (0.131) data 0.000 (0.002) loss 1.6542 (1.6494) teacher_loss 0.1857 (0.1067) loss_zs_kd 0.0783 (0.0758) loss_oracle 0.6698 (0.6913) kd_loss 1.0945 (1.1591) acc 93.7500 (97.1875) gate/entropy 1.0919 (1.0884) gate/usage_max 0.3742 (0.3861) gate/usage_min 0.2822 (0.2722) gate/usage_std 0.0383 (0.0469) teacher/entropy 0.0474 (0.0249) teacher/usage_max 0.5917 (0.5636) teacher/usage_min 0.0264 (0.0123) teacher/usage_std 0.2333 (0.2376) nleep/row_max_mean 1494.8448 (1509.1733) nleep/row_max_std 88.4260 (60.9230) nleep/row_min_mean 1463.5137 (1477.0699) lr 1.5358e-03 eta 0:11:29
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,834
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,016
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 90.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      83.5%, epoch: 12 *******
******* Domain p best val test acc: 86.0%, epoch: 12 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [18/50] batch [20/160] time 0.114 (0.145) data 0.000 (0.015) loss 1.5926 (1.6413) teacher_loss 0.1237 (0.1180) loss_zs_kd 0.0905 (0.0794) loss_oracle 0.5461 (0.6609) kd_loss 1.1507 (1.1532) acc 96.8750 (96.8750) gate/entropy 1.0926 (1.0923) gate/usage_max 0.3713 (0.3726) gate/usage_min 0.2846 (0.2835) gate/usage_std 0.0362 (0.0372) teacher/entropy 0.0051 (0.0147) teacher/usage_max 0.5303 (0.5647) teacher/usage_min 0.0001 (0.0058) teacher/usage_std 0.2369 (0.2412) nleep/row_max_mean 1523.9988 (1513.9917) nleep/row_max_std 26.5913 (55.1242) nleep/row_min_mean 1489.1387 (1480.4384) lr 1.5358e-03 eta 0:12:43
epoch [18/50] batch [40/160] time 0.100 (0.134) data 0.000 (0.008) loss 1.8001 (1.6003) teacher_loss 0.1875 (0.0985) loss_zs_kd 0.0843 (0.0754) loss_oracle 0.7673 (0.6423) kd_loss 1.1868 (1.1429) acc 96.8750 (97.5781) gate/entropy 1.0932 (1.0926) gate/usage_max 0.3683 (0.3711) gate/usage_min 0.2867 (0.2846) gate/usage_std 0.0343 (0.0362) teacher/entropy 0.0093 (0.0163) teacher/usage_max 0.7164 (0.5715) teacher/usage_min 0.0001 (0.0070) teacher/usage_std 0.2945 (0.2421) nleep/row_max_mean 1519.0498 (1511.7384) nleep/row_max_std 58.8975 (57.8325) nleep/row_min_mean 1484.7510 (1478.3285) lr 1.5358e-03 eta 0:11:43
epoch [18/50] batch [60/160] time 0.163 (0.128) data 0.001 (0.005) loss 1.7556 (1.6031) teacher_loss 0.2363 (0.1022) loss_zs_kd 0.0710 (0.0727) loss_oracle 0.7315 (0.6552) kd_loss 1.1180 (1.1369) acc 90.6250 (97.3438) gate/entropy 1.0938 (1.0929) gate/usage_max 0.3654 (0.3697) gate/usage_min 0.2890 (0.2857) gate/usage_std 0.0324 (0.0352) teacher/entropy 0.0237 (0.0211) teacher/usage_max 0.5311 (0.5701) teacher/usage_min 0.0171 (0.0090) teacher/usage_std 0.2259 (0.2411) nleep/row_max_mean 1500.0092 (1510.5137) nleep/row_max_std 89.0427 (60.3065) nleep/row_min_mean 1466.5229 (1477.2554) lr 1.5358e-03 eta 0:11:09
epoch [18/50] batch [80/160] time 0.093 (0.122) data 0.000 (0.004) loss 1.4606 (1.6047) teacher_loss 0.0313 (0.1029) loss_zs_kd 0.0918 (0.0724) loss_oracle 0.6021 (0.6645) kd_loss 1.0823 (1.1334) acc 100.0000 (97.0312) gate/entropy 1.0944 (1.0932) gate/usage_max 0.3625 (0.3683) gate/usage_min 0.2916 (0.2869) gate/usage_std 0.0303 (0.0342) teacher/entropy 0.0434 (0.0215) teacher/usage_max 0.6274 (0.5700) teacher/usage_min 0.0000 (0.0083) teacher/usage_std 0.2576 (0.2412) nleep/row_max_mean 1512.4634 (1510.2766) nleep/row_max_std 45.4308 (60.3775) nleep/row_min_mean 1477.1998 (1477.0344) lr 1.5358e-03 eta 0:10:35
epoch [18/50] batch [100/160] time 0.067 (0.120) data 0.000 (0.003) loss 1.8894 (1.6015) teacher_loss 0.4223 (0.1066) loss_zs_kd 0.0544 (0.0722) loss_oracle 0.6211 (0.6578) kd_loss 1.1293 (1.1299) acc 90.6250 (96.9688) gate/entropy 1.0949 (1.0935) gate/usage_max 0.3597 (0.3668) gate/usage_min 0.2936 (0.2880) gate/usage_std 0.0286 (0.0333) teacher/entropy 0.0238 (0.0212) teacher/usage_max 0.5743 (0.5675) teacher/usage_min 0.0195 (0.0082) teacher/usage_std 0.2323 (0.2407) nleep/row_max_mean 1509.2870 (1509.3734) nleep/row_max_std 80.0170 (61.9317) nleep/row_min_mean 1472.3757 (1476.1445) lr 1.5358e-03 eta 0:10:21
epoch [18/50] batch [120/160] time 0.083 (0.118) data 0.000 (0.003) loss 1.6130 (1.6002) teacher_loss 0.1044 (0.1090) loss_zs_kd 0.0979 (0.0713) loss_oracle 0.6184 (0.6555) kd_loss 1.1504 (1.1279) acc 96.8750 (97.0312) gate/entropy 1.0953 (1.0938) gate/usage_max 0.3568 (0.3654) gate/usage_min 0.2957 (0.2891) gate/usage_std 0.0269 (0.0324) teacher/entropy 0.0021 (0.0214) teacher/usage_max 0.5941 (0.5690) teacher/usage_min 0.0000 (0.0090) teacher/usage_std 0.2479 (0.2409) nleep/row_max_mean 1516.4828 (1509.3725) nleep/row_max_std 60.0210 (62.2283) nleep/row_min_mean 1481.7987 (1475.9854) lr 1.5358e-03 eta 0:10:11
epoch [18/50] batch [140/160] time 0.079 (0.117) data 0.000 (0.002) loss 1.7570 (1.5977) teacher_loss 0.2476 (0.1070) loss_zs_kd 0.0807 (0.0721) loss_oracle 0.6755 (0.6571) kd_loss 1.1313 (1.1260) acc 93.7500 (97.0089) gate/entropy 1.0957 (1.0940) gate/usage_max 0.3539 (0.3639) gate/usage_min 0.2980 (0.2902) gate/usage_std 0.0251 (0.0314) teacher/entropy 0.0189 (0.0213) teacher/usage_max 0.6162 (0.5674) teacher/usage_min 0.0088 (0.0088) teacher/usage_std 0.2497 (0.2406) nleep/row_max_mean 1518.8091 (1509.5303) nleep/row_max_std 60.2854 (62.6342) nleep/row_min_mean 1483.0261 (1475.8869) lr 1.5358e-03 eta 0:10:00
epoch [18/50] batch [160/160] time 0.072 (0.116) data 0.000 (0.002) loss 1.8827 (1.5942) teacher_loss 0.3621 (0.1065) loss_zs_kd 0.0882 (0.0723) loss_oracle 0.6873 (0.6539) kd_loss 1.1328 (1.1246) acc 90.6250 (97.0508) gate/entropy 1.0961 (1.0943) gate/usage_max 0.3510 (0.3625) gate/usage_min 0.3002 (0.2913) gate/usage_std 0.0235 (0.0305) teacher/entropy 0.0002 (0.0204) teacher/usage_max 0.5313 (0.5650) teacher/usage_min 0.0000 (0.0080) teacher/usage_std 0.2371 (0.2404) nleep/row_max_mean 1512.7393 (1509.5819) nleep/row_max_std 60.1927 (62.6379) nleep/row_min_mean 1475.7327 (1475.7020) lr 1.4818e-03 eta 0:09:53
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,833
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,981
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 89.3%
******* Domain p best val acc:      83.5%, epoch: 12 *******
******* Domain p best val test acc: 86.0%, epoch: 12 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [19/50] batch [20/160] time 0.123 (0.151) data 0.000 (0.015) loss 1.6180 (1.5574) teacher_loss 0.0810 (0.1035) loss_zs_kd 0.0818 (0.0679) loss_oracle 0.7543 (0.6434) kd_loss 1.1189 (1.0982) acc 96.8750 (97.6562) gate/entropy 1.0964 (1.0963) gate/usage_max 0.3497 (0.3498) gate/usage_min 0.3022 (0.3013) gate/usage_std 0.0220 (0.0226) teacher/entropy 0.0044 (0.0218) teacher/usage_max 0.5006 (0.5610) teacher/usage_min 0.0001 (0.0069) teacher/usage_std 0.2356 (0.2410) nleep/row_max_mean 1514.9933 (1507.5732) nleep/row_max_std 56.0474 (64.4771) nleep/row_min_mean 1477.9255 (1471.2894) lr 1.4818e-03 eta 0:12:50
epoch [19/50] batch [40/160] time 0.144 (0.141) data 0.000 (0.008) loss 1.6115 (1.5603) teacher_loss 0.1638 (0.1051) loss_zs_kd 0.0981 (0.0728) loss_oracle 0.6257 (0.6384) kd_loss 1.0858 (1.0997) acc 96.8750 (97.7344) gate/entropy 1.0966 (1.0964) gate/usage_max 0.3502 (0.3499) gate/usage_min 0.3041 (0.3023) gate/usage_std 0.0207 (0.0220) teacher/entropy 0.0299 (0.0198) teacher/usage_max 0.5002 (0.5501) teacher/usage_min 0.0274 (0.0078) teacher/usage_std 0.2166 (0.2375) nleep/row_max_mean 1499.0791 (1508.8556) nleep/row_max_std 87.2305 (64.4561) nleep/row_min_mean 1464.7505 (1472.6293) lr 1.4818e-03 eta 0:11:54
epoch [19/50] batch [60/160] time 0.131 (0.137) data 0.001 (0.005) loss 1.5070 (1.5621) teacher_loss 0.0474 (0.1064) loss_zs_kd 0.0706 (0.0741) loss_oracle 0.6524 (0.6401) kd_loss 1.0981 (1.0986) acc 100.0000 (97.6042) gate/entropy 1.0969 (1.0965) gate/usage_max 0.3511 (0.3501) gate/usage_min 0.3060 (0.3033) gate/usage_std 0.0196 (0.0213) teacher/entropy 0.0034 (0.0189) teacher/usage_max 0.5932 (0.5520) teacher/usage_min 0.0000 (0.0069) teacher/usage_std 0.2477 (0.2380) nleep/row_max_mean 1508.3802 (1510.3921) nleep/row_max_std 74.3131 (63.1266) nleep/row_min_mean 1470.8860 (1473.8645) lr 1.4818e-03 eta 0:11:34
epoch [19/50] batch [80/160] time 0.134 (0.136) data 0.000 (0.004) loss 1.6844 (1.5610) teacher_loss 0.2192 (0.1070) loss_zs_kd 0.0749 (0.0737) loss_oracle 0.6274 (0.6381) kd_loss 1.1141 (1.0981) acc 90.6250 (97.4219) gate/entropy 1.0971 (1.0966) gate/usage_max 0.3516 (0.3505) gate/usage_min 0.3082 (0.3042) gate/usage_std 0.0183 (0.0208) teacher/entropy 0.0001 (0.0181) teacher/usage_max 0.5313 (0.5596) teacher/usage_min 0.0000 (0.0056) teacher/usage_std 0.2371 (0.2405) nleep/row_max_mean 1512.7046 (1510.6252) nleep/row_max_std 48.3261 (62.5283) nleep/row_min_mean 1475.9880 (1474.0655) lr 1.4818e-03 eta 0:11:26
epoch [19/50] batch [100/160] time 0.136 (0.137) data 0.000 (0.003) loss 1.5112 (1.5667) teacher_loss 0.0753 (0.1148) loss_zs_kd 0.0894 (0.0739) loss_oracle 0.5776 (0.6360) kd_loss 1.1024 (1.0969) acc 96.8750 (97.1250) gate/entropy 1.0973 (1.0967) gate/usage_max 0.3519 (0.3508) gate/usage_min 0.3103 (0.3052) gate/usage_std 0.0172 (0.0202) teacher/entropy 0.0005 (0.0181) teacher/usage_max 0.5312 (0.5564) teacher/usage_min 0.0000 (0.0051) teacher/usage_std 0.2371 (0.2399) nleep/row_max_mean 1516.1572 (1511.1092) nleep/row_max_std 46.5847 (61.5232) nleep/row_min_mean 1476.8046 (1474.6121) lr 1.4818e-03 eta 0:11:27
epoch [19/50] batch [120/160] time 0.117 (0.137) data 0.000 (0.003) loss 1.8344 (1.5647) teacher_loss 0.3132 (0.1156) loss_zs_kd 0.1059 (0.0737) loss_oracle 0.6984 (0.6320) kd_loss 1.1191 (1.0961) acc 90.6250 (97.0312) gate/entropy 1.0974 (1.0968) gate/usage_max 0.3524 (0.3510) gate/usage_min 0.3124 (0.3063) gate/usage_std 0.0164 (0.0196) teacher/entropy 0.0027 (0.0172) teacher/usage_max 0.6565 (0.5588) teacher/usage_min 0.0001 (0.0050) teacher/usage_std 0.2681 (0.2406) nleep/row_max_mean 1501.8418 (1511.3798) nleep/row_max_std 81.3015 (61.2985) nleep/row_min_mean 1469.7957 (1475.0312) lr 1.4818e-03 eta 0:11:23
epoch [19/50] batch [140/160] time 0.142 (0.135) data 0.000 (0.002) loss 1.4820 (1.5626) teacher_loss 0.0351 (0.1164) loss_zs_kd 0.0640 (0.0732) loss_oracle 0.6406 (0.6312) kd_loss 1.0947 (1.0940) acc 100.0000 (96.9643) gate/entropy 1.0975 (1.0969) gate/usage_max 0.3528 (0.3512) gate/usage_min 0.3145 (0.3073) gate/usage_std 0.0156 (0.0191) teacher/entropy 0.0003 (0.0177) teacher/usage_max 0.5312 (0.5588) teacher/usage_min 0.0000 (0.0051) teacher/usage_std 0.2371 (0.2405) nleep/row_max_mean 1529.6497 (1510.2865) nleep/row_max_std 45.1437 (62.1595) nleep/row_min_mean 1493.2112 (1474.2535) lr 1.4818e-03 eta 0:11:14
epoch [19/50] batch [160/160] time 0.149 (0.135) data 0.000 (0.002) loss 1.6042 (1.5608) teacher_loss 0.2172 (0.1158) loss_zs_kd 0.0619 (0.0737) loss_oracle 0.6021 (0.6307) kd_loss 1.0550 (1.0928) acc 93.7500 (96.9727) gate/entropy 1.0976 (1.0970) gate/usage_max 0.3532 (0.3514) gate/usage_min 0.3165 (0.3083) gate/usage_std 0.0151 (0.0186) teacher/entropy 0.0328 (0.0170) teacher/usage_max 0.5612 (0.5599) teacher/usage_min 0.0099 (0.0047) teacher/usage_std 0.2350 (0.2411) nleep/row_max_mean 1486.6549 (1509.7367) nleep/row_max_std 83.3344 (62.3494) nleep/row_min_mean 1455.4989 (1473.8586) lr 1.4258e-03 eta 0:11:10
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,844
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 85.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,003
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 89.8%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [20/50] batch [20/160] time 0.159 (0.124) data 0.000 (0.017) loss 1.4578 (1.5212) teacher_loss 0.0587 (0.1103) loss_zs_kd 0.0629 (0.0658) loss_oracle 0.5552 (0.6058) kd_loss 1.0901 (1.0751) acc 100.0000 (97.0312) gate/entropy 1.0976 (1.0976) gate/usage_max 0.3535 (0.3533) gate/usage_min 0.3186 (0.3176) gate/usage_std 0.0148 (0.0149) teacher/entropy 0.0010 (0.0192) teacher/usage_max 0.5001 (0.5753) teacher/usage_min 0.0000 (0.0036) teacher/usage_std 0.2357 (0.2450) nleep/row_max_mean 1521.1772 (1506.8564) nleep/row_max_std 40.0484 (61.3033) nleep/row_min_mean 1487.4540 (1472.4758) lr 1.4258e-03 eta 0:10:11
epoch [20/50] batch [40/160] time 0.094 (0.112) data 0.000 (0.008) loss 1.5633 (1.5281) teacher_loss 0.1387 (0.1144) loss_zs_kd 0.0709 (0.0675) loss_oracle 0.6314 (0.6163) kd_loss 1.0734 (1.0718) acc 96.8750 (97.3438) gate/entropy 1.0977 (1.0976) gate/usage_max 0.3534 (0.3535) gate/usage_min 0.3208 (0.3186) gate/usage_std 0.0144 (0.0148) teacher/entropy 0.0142 (0.0200) teacher/usage_max 0.5013 (0.5644) teacher/usage_min 0.0023 (0.0045) teacher/usage_std 0.2341 (0.2420) nleep/row_max_mean 1507.9840 (1505.9448) nleep/row_max_std 60.8525 (65.4392) nleep/row_min_mean 1475.0460 (1471.9707) lr 1.4258e-03 eta 0:09:12
epoch [20/50] batch [60/160] time 0.154 (0.113) data 0.000 (0.006) loss 1.4325 (1.5301) teacher_loss 0.0669 (0.1221) loss_zs_kd 0.0593 (0.0665) loss_oracle 0.5676 (0.6123) kd_loss 1.0522 (1.0686) acc 96.8750 (96.9792) gate/entropy 1.0976 (1.0976) gate/usage_max 0.3542 (0.3537) gate/usage_min 0.3223 (0.3195) gate/usage_std 0.0148 (0.0147) teacher/entropy 0.0292 (0.0209) teacher/usage_max 0.5325 (0.5668) teacher/usage_min 0.0147 (0.0049) teacher/usage_std 0.2276 (0.2426) nleep/row_max_mean 1508.4961 (1505.9062) nleep/row_max_std 61.3856 (64.1341) nleep/row_min_mean 1475.8965 (1472.1041) lr 1.4258e-03 eta 0:09:15
epoch [20/50] batch [80/160] time 0.131 (0.115) data 0.000 (0.004) loss 1.5075 (1.5262) teacher_loss 0.0812 (0.1227) loss_zs_kd 0.0817 (0.0694) loss_oracle 0.6526 (0.6048) kd_loss 1.0592 (1.0665) acc 100.0000 (96.7969) gate/entropy 1.0976 (1.0976) gate/usage_max 0.3547 (0.3539) gate/usage_min 0.3212 (0.3202) gate/usage_std 0.0152 (0.0148) teacher/entropy 0.0342 (0.0207) teacher/usage_max 0.6371 (0.5674) teacher/usage_min 0.0004 (0.0043) teacher/usage_std 0.2607 (0.2431) nleep/row_max_mean 1509.8417 (1506.3306) nleep/row_max_std 58.7548 (63.1317) nleep/row_min_mean 1477.2284 (1472.4074) lr 1.4258e-03 eta 0:09:21
epoch [20/50] batch [100/160] time 0.087 (0.114) data 0.000 (0.003) loss 1.5177 (1.5264) teacher_loss 0.1276 (0.1226) loss_zs_kd 0.0704 (0.0691) loss_oracle 0.6084 (0.6095) kd_loss 1.0507 (1.0644) acc 93.7500 (96.7188) gate/entropy 1.0975 (1.0976) gate/usage_max 0.3554 (0.3541) gate/usage_min 0.3187 (0.3201) gate/usage_std 0.0159 (0.0149) teacher/entropy 0.0288 (0.0212) teacher/usage_max 0.5262 (0.5649) teacher/usage_min 0.0003 (0.0038) teacher/usage_std 0.2365 (0.2427) nleep/row_max_mean 1509.6755 (1506.6308) nleep/row_max_std 80.9772 (62.7519) nleep/row_min_mean 1476.0193 (1472.6972) lr 1.4258e-03 eta 0:09:15
epoch [20/50] batch [120/160] time 0.127 (0.114) data 0.000 (0.003) loss 1.4628 (1.5287) teacher_loss 0.0632 (0.1243) loss_zs_kd 0.0746 (0.0701) loss_oracle 0.6013 (0.6121) kd_loss 1.0617 (1.0634) acc 96.8750 (96.6667) gate/entropy 1.0975 (1.0976) gate/usage_max 0.3551 (0.3543) gate/usage_min 0.3168 (0.3197) gate/usage_std 0.0161 (0.0151) teacher/entropy 0.0112 (0.0209) teacher/usage_max 0.5302 (0.5600) teacher/usage_min 0.0296 (0.0039) teacher/usage_std 0.2179 (0.2416) nleep/row_max_mean 1516.4602 (1506.9643) nleep/row_max_std 49.1246 (63.0720) nleep/row_min_mean 1480.6443 (1473.0371) lr 1.4258e-03 eta 0:09:12
epoch [20/50] batch [140/160] time 0.149 (0.118) data 0.000 (0.003) loss 1.4339 (1.5194) teacher_loss 0.0529 (0.1179) loss_zs_kd 0.0579 (0.0695) loss_oracle 0.6867 (0.6133) kd_loss 1.0087 (1.0602) acc 100.0000 (96.8750) gate/entropy 1.0973 (1.0976) gate/usage_max 0.3555 (0.3545) gate/usage_min 0.3144 (0.3191) gate/usage_std 0.0169 (0.0153) teacher/entropy 0.0661 (0.0222) teacher/usage_max 0.5586 (0.5583) teacher/usage_min 0.0001 (0.0035) teacher/usage_std 0.2405 (0.2413) nleep/row_max_mean 1504.5547 (1507.1651) nleep/row_max_std 79.9469 (62.8402) nleep/row_min_mean 1470.6866 (1473.1645) lr 1.4258e-03 eta 0:09:29
epoch [20/50] batch [160/160] time 0.161 (0.122) data 0.000 (0.002) loss 1.4859 (1.5183) teacher_loss 0.0264 (0.1172) loss_zs_kd 0.0676 (0.0697) loss_oracle 0.6996 (0.6159) kd_loss 1.0760 (1.0583) acc 100.0000 (96.8750) gate/entropy 1.0972 (1.0975) gate/usage_max 0.3559 (0.3546) gate/usage_min 0.3122 (0.3184) gate/usage_std 0.0179 (0.0156) teacher/entropy 0.0002 (0.0227) teacher/usage_max 0.6250 (0.5635) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.2569 (0.2427) nleep/row_max_mean 1515.2563 (1506.8657) nleep/row_max_std 44.5905 (63.6361) nleep/row_min_mean 1478.9604 (1472.8654) lr 1.3681e-03 eta 0:09:46
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,829
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,970
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 89.2%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [21/50] batch [20/160] time 0.134 (0.149) data 0.000 (0.013) loss 1.4546 (1.4852) teacher_loss 0.0563 (0.1120) loss_zs_kd 0.0737 (0.0684) loss_oracle 0.5929 (0.6036) kd_loss 1.0650 (1.0372) acc 100.0000 (97.8125) gate/entropy 1.0970 (1.0971) gate/usage_max 0.3561 (0.3561) gate/usage_min 0.3100 (0.3109) gate/usage_std 0.0188 (0.0185) teacher/entropy 0.0028 (0.0278) teacher/usage_max 0.5630 (0.5741) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.2412 (0.2456) nleep/row_max_mean 1518.4434 (1506.4991) nleep/row_max_std 44.5142 (67.8711) nleep/row_min_mean 1483.9739 (1472.9595) lr 1.3681e-03 eta 0:11:52
epoch [21/50] batch [40/160] time 0.135 (0.136) data 0.000 (0.006) loss 1.4278 (1.4966) teacher_loss 0.0394 (0.1160) loss_zs_kd 0.0522 (0.0685) loss_oracle 0.6226 (0.6166) kd_loss 1.0510 (1.0381) acc 100.0000 (96.9531) gate/entropy 1.0968 (1.0970) gate/usage_max 0.3567 (0.3563) gate/usage_min 0.3077 (0.3098) gate/usage_std 0.0201 (0.0190) teacher/entropy 0.0074 (0.0254) teacher/usage_max 0.5302 (0.5735) teacher/usage_min 0.0004 (0.0028) teacher/usage_std 0.2367 (0.2460) nleep/row_max_mean 1493.6130 (1509.3500) nleep/row_max_std 74.0122 (62.3710) nleep/row_min_mean 1457.9209 (1475.1357) lr 1.3681e-03 eta 0:10:46
epoch [21/50] batch [60/160] time 0.147 (0.135) data 0.001 (0.004) loss 1.4572 (1.5070) teacher_loss 0.0356 (0.1258) loss_zs_kd 0.0871 (0.0663) loss_oracle 0.6828 (0.6225) kd_loss 1.0366 (1.0368) acc 100.0000 (96.7188) gate/entropy 1.0966 (1.0969) gate/usage_max 0.3569 (0.3565) gate/usage_min 0.3058 (0.3088) gate/usage_std 0.0211 (0.0195) teacher/entropy 0.0214 (0.0252) teacher/usage_max 0.5073 (0.5658) teacher/usage_min 0.0000 (0.0030) teacher/usage_std 0.2358 (0.2438) nleep/row_max_mean 1513.6711 (1509.1873) nleep/row_max_std 57.9600 (63.2767) nleep/row_min_mean 1477.8174 (1474.8535) lr 1.3681e-03 eta 0:10:38
epoch [21/50] batch [80/160] time 0.078 (0.133) data 0.000 (0.003) loss 1.3966 (1.5014) teacher_loss 0.0627 (0.1217) loss_zs_kd 0.0759 (0.0674) loss_oracle 0.5909 (0.6239) kd_loss 1.0005 (1.0341) acc 100.0000 (96.8359) gate/entropy 1.0964 (1.0968) gate/usage_max 0.3571 (0.3566) gate/usage_min 0.3036 (0.3078) gate/usage_std 0.0222 (0.0201) teacher/entropy 0.0514 (0.0265) teacher/usage_max 0.5798 (0.5652) teacher/usage_min 0.0124 (0.0028) teacher/usage_std 0.2376 (0.2433) nleep/row_max_mean 1481.0299 (1508.4901) nleep/row_max_std 96.8757 (63.5781) nleep/row_min_mean 1449.1392 (1474.3955) lr 1.3681e-03 eta 0:10:29
epoch [21/50] batch [100/160] time 0.177 (0.128) data 0.000 (0.003) loss 1.5851 (1.5036) teacher_loss 0.1356 (0.1213) loss_zs_kd 0.0841 (0.0683) loss_oracle 0.7152 (0.6298) kd_loss 1.0498 (1.0332) acc 93.7500 (96.7188) gate/entropy 1.0961 (1.0967) gate/usage_max 0.3572 (0.3567) gate/usage_min 0.3016 (0.3067) gate/usage_std 0.0234 (0.0206) teacher/entropy 0.0065 (0.0263) teacher/usage_max 0.5951 (0.5710) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.2482 (0.2445) nleep/row_max_mean 1511.4867 (1508.6616) nleep/row_max_std 45.2179 (63.0200) nleep/row_min_mean 1477.6348 (1474.6757) lr 1.3681e-03 eta 0:09:59
epoch [21/50] batch [120/160] time 0.087 (0.125) data 0.000 (0.002) loss 1.4433 (1.4991) teacher_loss 0.0774 (0.1165) loss_zs_kd 0.0555 (0.0693) loss_oracle 0.6226 (0.6326) kd_loss 1.0269 (1.0317) acc 100.0000 (96.8750) gate/entropy 1.0959 (1.0966) gate/usage_max 0.3572 (0.3568) gate/usage_min 0.2996 (0.3057) gate/usage_std 0.0245 (0.0212) teacher/entropy 0.0192 (0.0263) teacher/usage_max 0.5682 (0.5682) teacher/usage_min 0.0000 (0.0026) teacher/usage_std 0.2422 (0.2439) nleep/row_max_mean 1497.0791 (1508.5894) nleep/row_max_std 63.4399 (62.6704) nleep/row_min_mean 1466.2974 (1474.7291) lr 1.3681e-03 eta 0:09:44
epoch [21/50] batch [140/160] time 0.172 (0.124) data 0.000 (0.002) loss 1.5033 (1.5002) teacher_loss 0.1395 (0.1168) loss_zs_kd 0.0888 (0.0692) loss_oracle 0.6599 (0.6367) kd_loss 0.9894 (1.0304) acc 96.8750 (96.6518) gate/entropy 1.0956 (1.0964) gate/usage_max 0.3570 (0.3569) gate/usage_min 0.2976 (0.3046) gate/usage_std 0.0257 (0.0218) teacher/entropy 0.0597 (0.0264) teacher/usage_max 0.5547 (0.5717) teacher/usage_min 0.0056 (0.0028) teacher/usage_std 0.2364 (0.2447) nleep/row_max_mean 1486.5503 (1508.9030) nleep/row_max_std 86.7745 (62.4660) nleep/row_min_mean 1452.5520 (1475.0407) lr 1.3681e-03 eta 0:09:37
epoch [21/50] batch [160/160] time 0.071 (0.121) data 0.000 (0.002) loss 1.4995 (1.5014) teacher_loss 0.1281 (0.1194) loss_zs_kd 0.0764 (0.0699) loss_oracle 0.6238 (0.6382) kd_loss 1.0214 (1.0280) acc 96.8750 (96.5430) gate/entropy 1.0952 (1.0963) gate/usage_max 0.3572 (0.3569) gate/usage_min 0.2953 (0.3036) gate/usage_std 0.0272 (0.0224) teacher/entropy 0.0217 (0.0274) teacher/usage_max 0.5144 (0.5710) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.2360 (0.2440) nleep/row_max_mean 1522.0776 (1508.7586) nleep/row_max_std 61.9877 (63.2100) nleep/row_min_mean 1486.6094 (1474.9616) lr 1.3090e-03 eta 0:09:23
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,840
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,001
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 89.7%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [22/50] batch [20/160] time 0.075 (0.124) data 0.000 (0.015) loss 1.4169 (1.5049) teacher_loss 0.0592 (0.1234) loss_zs_kd 0.0856 (0.0758) loss_oracle 0.6102 (0.6440) kd_loss 1.0098 (1.0216) acc 100.0000 (96.4062) gate/entropy 1.0949 (1.0951) gate/usage_max 0.3569 (0.3571) gate/usage_min 0.2935 (0.2944) gate/usage_std 0.0283 (0.0278) teacher/entropy 0.0314 (0.0214) teacher/usage_max 0.5037 (0.5642) teacher/usage_min 0.0073 (0.0044) teacher/usage_std 0.2306 (0.2420) nleep/row_max_mean 1502.0293 (1508.0775) nleep/row_max_std 69.1770 (64.4471) nleep/row_min_mean 1471.3596 (1474.9268) lr 1.3090e-03 eta 0:09:34
epoch [22/50] batch [40/160] time 0.090 (0.117) data 0.000 (0.008) loss 1.5320 (1.5025) teacher_loss 0.1655 (0.1268) loss_zs_kd 0.0500 (0.0747) loss_oracle 0.6903 (0.6408) kd_loss 0.9964 (1.0179) acc 93.7500 (96.4844) gate/entropy 1.0946 (1.0949) gate/usage_max 0.3571 (0.3571) gate/usage_min 0.2915 (0.2934) gate/usage_std 0.0296 (0.0284) teacher/entropy 0.0425 (0.0232) teacher/usage_max 0.5375 (0.5756) teacher/usage_min 0.0081 (0.0034) teacher/usage_std 0.2325 (0.2456) nleep/row_max_mean 1509.3640 (1508.0573) nleep/row_max_std 81.4704 (64.7213) nleep/row_min_mean 1472.4528 (1474.6321) lr 1.3090e-03 eta 0:08:58
epoch [22/50] batch [60/160] time 0.125 (0.121) data 0.000 (0.005) loss 1.4027 (1.4944) teacher_loss 0.0221 (0.1262) loss_zs_kd 0.0568 (0.0731) loss_oracle 0.6529 (0.6299) kd_loss 1.0258 (1.0166) acc 100.0000 (96.6146) gate/entropy 1.0943 (1.0947) gate/usage_max 0.3569 (0.3570) gate/usage_min 0.2900 (0.2925) gate/usage_std 0.0307 (0.0290) teacher/entropy 0.0094 (0.0234) teacher/usage_max 0.5603 (0.5759) teacher/usage_min 0.0004 (0.0050) teacher/usage_std 0.2405 (0.2443) nleep/row_max_mean 1497.5242 (1507.7227) nleep/row_max_std 75.4181 (63.2864) nleep/row_min_mean 1467.5304 (1474.6549) lr 1.3090e-03 eta 0:09:13
epoch [22/50] batch [80/160] time 0.179 (0.127) data 0.000 (0.004) loss 1.3722 (1.4858) teacher_loss 0.0200 (0.1193) loss_zs_kd 0.0901 (0.0735) loss_oracle 0.5606 (0.6306) kd_loss 1.0268 (1.0144) acc 100.0000 (96.8359) gate/entropy 1.0939 (1.0946) gate/usage_max 0.3570 (0.3570) gate/usage_min 0.2881 (0.2916) gate/usage_std 0.0320 (0.0296) teacher/entropy 0.0058 (0.0243) teacher/usage_max 0.5000 (0.5688) teacher/usage_min 0.0013 (0.0051) teacher/usage_std 0.2348 (0.2425) nleep/row_max_mean 1516.4167 (1507.2584) nleep/row_max_std 56.3820 (64.0488) nleep/row_min_mean 1483.5596 (1474.5137) lr 1.3090e-03 eta 0:09:38
epoch [22/50] batch [100/160] time 0.162 (0.128) data 0.000 (0.003) loss 1.4547 (1.4791) teacher_loss 0.1191 (0.1168) loss_zs_kd 0.0562 (0.0722) loss_oracle 0.5862 (0.6274) kd_loss 1.0145 (1.0125) acc 93.7500 (96.9062) gate/entropy 1.0935 (1.0944) gate/usage_max 0.3570 (0.3570) gate/usage_min 0.2865 (0.2908) gate/usage_std 0.0331 (0.0302) teacher/entropy 0.0158 (0.0249) teacher/usage_max 0.5008 (0.5665) teacher/usage_min 0.0009 (0.0055) teacher/usage_std 0.2351 (0.2419) nleep/row_max_mean 1495.5029 (1507.1068) nleep/row_max_std 78.0479 (63.8045) nleep/row_min_mean 1461.9988 (1474.4415) lr 1.3090e-03 eta 0:09:42
epoch [22/50] batch [120/160] time 0.138 (0.131) data 0.000 (0.003) loss 1.5619 (1.4762) teacher_loss 0.1998 (0.1170) loss_zs_kd 0.0659 (0.0708) loss_oracle 0.6338 (0.6261) kd_loss 1.0122 (1.0107) acc 96.8750 (96.9531) gate/entropy 1.0932 (1.0942) gate/usage_max 0.3583 (0.3571) gate/usage_min 0.2848 (0.2899) gate/usage_std 0.0343 (0.0308) teacher/entropy 0.0149 (0.0253) teacher/usage_max 0.5346 (0.5662) teacher/usage_min 0.0001 (0.0048) teacher/usage_std 0.2373 (0.2423) nleep/row_max_mean 1512.6659 (1507.7770) nleep/row_max_std 70.8315 (63.3033) nleep/row_min_mean 1477.9985 (1475.1324) lr 1.3090e-03 eta 0:09:53
epoch [22/50] batch [140/160] time 0.121 (0.132) data 0.000 (0.002) loss 1.3955 (1.4690) teacher_loss 0.0303 (0.1118) loss_zs_kd 0.0850 (0.0715) loss_oracle 0.6478 (0.6279) kd_loss 0.9988 (1.0075) acc 100.0000 (97.1205) gate/entropy 1.0928 (1.0940) gate/usage_max 0.3602 (0.3574) gate/usage_min 0.2831 (0.2890) gate/usage_std 0.0355 (0.0314) teacher/entropy 0.0259 (0.0273) teacher/usage_max 0.5390 (0.5651) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.2378 (0.2419) nleep/row_max_mean 1517.0520 (1507.5476) nleep/row_max_std 49.9326 (62.9684) nleep/row_min_mean 1484.6223 (1475.1885) lr 1.3090e-03 eta 0:09:55
epoch [22/50] batch [160/160] time 0.143 (0.133) data 0.000 (0.002) loss 1.5132 (1.4680) teacher_loss 0.1586 (0.1133) loss_zs_kd 0.0476 (0.0717) loss_oracle 0.6344 (0.6260) kd_loss 1.0136 (1.0058) acc 96.8750 (97.0508) gate/entropy 1.0924 (1.0938) gate/usage_max 0.3615 (0.3578) gate/usage_min 0.2816 (0.2881) gate/usage_std 0.0366 (0.0320) teacher/entropy 0.0084 (0.0277) teacher/usage_max 0.5929 (0.5639) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.2476 (0.2416) nleep/row_max_mean 1508.1865 (1507.3947) nleep/row_max_std 62.2437 (63.0932) nleep/row_min_mean 1474.2588 (1475.1676) lr 1.2487e-03 eta 0:09:54
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,831
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,999
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 89.4%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [23/50] batch [20/160] time 0.097 (0.119) data 0.000 (0.015) loss 1.4778 (1.4459) teacher_loss 0.1265 (0.1121) loss_zs_kd 0.1005 (0.0644) loss_oracle 0.6440 (0.6209) kd_loss 0.9790 (0.9912) acc 93.7500 (96.7188) gate/entropy 1.0920 (1.0921) gate/usage_max 0.3634 (0.3625) gate/usage_min 0.2801 (0.2806) gate/usage_std 0.0378 (0.0374) teacher/entropy 0.0423 (0.0314) teacher/usage_max 0.5640 (0.5926) teacher/usage_min 0.0065 (0.0085) teacher/usage_std 0.2375 (0.2502) nleep/row_max_mean 1491.9404 (1507.2035) nleep/row_max_std 81.9922 (60.4215) nleep/row_min_mean 1462.3668 (1475.8446) lr 1.2487e-03 eta 0:08:50
epoch [23/50] batch [40/160] time 0.182 (0.120) data 0.000 (0.008) loss 1.3913 (1.4446) teacher_loss 0.0459 (0.1200) loss_zs_kd 0.0871 (0.0660) loss_oracle 0.6242 (0.6082) kd_loss 0.9898 (0.9875) acc 100.0000 (96.2500) gate/entropy 1.0916 (1.0919) gate/usage_max 0.3650 (0.3634) gate/usage_min 0.2784 (0.2799) gate/usage_std 0.0390 (0.0379) teacher/entropy 0.0323 (0.0348) teacher/usage_max 0.5572 (0.5851) teacher/usage_min 0.0071 (0.0077) teacher/usage_std 0.2360 (0.2468) nleep/row_max_mean 1510.7573 (1505.5507) nleep/row_max_std 60.6374 (61.6710) nleep/row_min_mean 1478.7876 (1474.6813) lr 1.2487e-03 eta 0:08:53
epoch [23/50] batch [60/160] time 0.073 (0.119) data 0.001 (0.005) loss 1.5043 (1.4593) teacher_loss 0.2379 (0.1375) loss_zs_kd 0.0647 (0.0672) loss_oracle 0.4944 (0.6061) kd_loss 0.9868 (0.9852) acc 90.6250 (96.0417) gate/entropy 1.0912 (1.0918) gate/usage_max 0.3662 (0.3642) gate/usage_min 0.2772 (0.2792) gate/usage_std 0.0399 (0.0384) teacher/entropy 0.0339 (0.0360) teacher/usage_max 0.6033 (0.5822) teacher/usage_min 0.0008 (0.0077) teacher/usage_std 0.2499 (0.2459) nleep/row_max_mean 1496.5288 (1504.8704) nleep/row_max_std 70.5859 (63.9551) nleep/row_min_mean 1467.5032 (1473.9021) lr 1.2487e-03 eta 0:08:46
epoch [23/50] batch [80/160] time 0.134 (0.117) data 0.000 (0.004) loss 1.5271 (1.4489) teacher_loss 0.2370 (0.1277) loss_zs_kd 0.0628 (0.0660) loss_oracle 0.5245 (0.6078) kd_loss 0.9964 (0.9843) acc 96.8750 (96.4062) gate/entropy 1.0908 (1.0916) gate/usage_max 0.3679 (0.3649) gate/usage_min 0.2756 (0.2785) gate/usage_std 0.0411 (0.0390) teacher/entropy 0.0214 (0.0359) teacher/usage_max 0.5838 (0.5798) teacher/usage_min 0.0000 (0.0075) teacher/usage_std 0.2454 (0.2451) nleep/row_max_mean 1497.2670 (1504.1651) nleep/row_max_std 77.6624 (65.2006) nleep/row_min_mean 1466.4509 (1473.2370) lr 1.2487e-03 eta 0:08:35
epoch [23/50] batch [100/160] time 0.083 (0.113) data 0.000 (0.003) loss 1.3814 (1.4461) teacher_loss 0.0760 (0.1240) loss_zs_kd 0.0831 (0.0682) loss_oracle 0.5696 (0.6098) kd_loss 0.9791 (0.9830) acc 96.8750 (96.5312) gate/entropy 1.0904 (1.0914) gate/usage_max 0.3695 (0.3657) gate/usage_min 0.2743 (0.2777) gate/usage_std 0.0421 (0.0395) teacher/entropy 0.0372 (0.0362) teacher/usage_max 0.4951 (0.5762) teacher/usage_min 0.0110 (0.0075) teacher/usage_std 0.2279 (0.2443) nleep/row_max_mean 1515.6636 (1504.6781) nleep/row_max_std 58.8276 (64.4862) nleep/row_min_mean 1483.9609 (1473.8490) lr 1.2487e-03 eta 0:08:13
epoch [23/50] batch [120/160] time 0.090 (0.113) data 0.000 (0.003) loss 1.3484 (1.4448) teacher_loss 0.0495 (0.1233) loss_zs_kd 0.0373 (0.0685) loss_oracle 0.6475 (0.6083) kd_loss 0.9565 (0.9832) acc 100.0000 (96.7188) gate/entropy 1.0899 (1.0912) gate/usage_max 0.3709 (0.3665) gate/usage_min 0.2729 (0.2770) gate/usage_std 0.0432 (0.0400) teacher/entropy 0.0552 (0.0351) teacher/usage_max 0.5926 (0.5736) teacher/usage_min 0.0163 (0.0073) teacher/usage_std 0.2388 (0.2435) nleep/row_max_mean 1520.3586 (1505.2140) nleep/row_max_std 46.2366 (63.4947) nleep/row_min_mean 1487.0493 (1474.4007) lr 1.2487e-03 eta 0:08:13
epoch [23/50] batch [140/160] time 0.093 (0.112) data 0.000 (0.002) loss 1.3367 (1.4446) teacher_loss 0.0502 (0.1217) loss_zs_kd 0.0840 (0.0698) loss_oracle 0.5949 (0.6104) kd_loss 0.9471 (0.9828) acc 100.0000 (96.6071) gate/entropy 1.0895 (1.0910) gate/usage_max 0.3722 (0.3672) gate/usage_min 0.2716 (0.2764) gate/usage_std 0.0442 (0.0405) teacher/entropy 0.0653 (0.0346) teacher/usage_max 0.5076 (0.5714) teacher/usage_min 0.0081 (0.0075) teacher/usage_std 0.2302 (0.2427) nleep/row_max_mean 1511.0662 (1505.6329) nleep/row_max_std 43.5198 (62.8785) nleep/row_min_mean 1480.2864 (1474.9541) lr 1.2487e-03 eta 0:08:05
epoch [23/50] batch [160/160] time 0.069 (0.111) data 0.000 (0.002) loss 1.4589 (1.4445) teacher_loss 0.1671 (0.1222) loss_zs_kd 0.0531 (0.0694) loss_oracle 0.5212 (0.6109) kd_loss 1.0046 (0.9821) acc 96.8750 (96.6211) gate/entropy 1.0891 (1.0908) gate/usage_max 0.3737 (0.3679) gate/usage_min 0.2702 (0.2757) gate/usage_std 0.0452 (0.0411) teacher/entropy 0.0062 (0.0345) teacher/usage_max 0.5628 (0.5693) teacher/usage_min 0.0006 (0.0078) teacher/usage_std 0.2408 (0.2419) nleep/row_max_mean 1478.6110 (1505.4870) nleep/row_max_std 86.9902 (63.0814) nleep/row_min_mean 1452.0853 (1474.9442) lr 1.1874e-03 eta 0:07:59
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,821
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.7%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [24/50] batch [20/160] time 0.110 (0.154) data 0.000 (0.016) loss 1.5106 (1.4504) teacher_loss 0.1913 (0.1340) loss_zs_kd 0.0569 (0.0691) loss_oracle 0.6320 (0.6005) kd_loss 0.9748 (0.9816) acc 93.7500 (96.4062) gate/entropy 1.0886 (1.0888) gate/usage_max 0.3752 (0.3745) gate/usage_min 0.2688 (0.2694) gate/usage_std 0.0463 (0.0458) teacher/entropy 0.0201 (0.0261) teacher/usage_max 0.7183 (0.5712) teacher/usage_min 0.0016 (0.0066) teacher/usage_std 0.2950 (0.2434) nleep/row_max_mean 1507.1152 (1507.8392) nleep/row_max_std 82.1274 (61.4472) nleep/row_min_mean 1473.1060 (1477.3339) lr 1.1874e-03 eta 0:11:01
epoch [24/50] batch [40/160] time 0.182 (0.149) data 0.000 (0.008) loss 1.3788 (1.4331) teacher_loss 0.1022 (0.1151) loss_zs_kd 0.0618 (0.0705) loss_oracle 0.5781 (0.6029) kd_loss 0.9566 (0.9814) acc 96.8750 (96.9531) gate/entropy 1.0882 (1.0886) gate/usage_max 0.3761 (0.3751) gate/usage_min 0.2673 (0.2688) gate/usage_std 0.0473 (0.0463) teacher/entropy 0.0566 (0.0265) teacher/usage_max 0.5057 (0.5785) teacher/usage_min 0.0267 (0.0081) teacher/usage_std 0.2174 (0.2439) nleep/row_max_mean 1505.5371 (1505.7708) nleep/row_max_std 54.4559 (64.3360) nleep/row_min_mean 1476.6646 (1475.1035) lr 1.1874e-03 eta 0:10:37
epoch [24/50] batch [60/160] time 0.139 (0.147) data 0.001 (0.006) loss 1.5695 (1.4306) teacher_loss 0.2861 (0.1157) loss_zs_kd 0.0554 (0.0696) loss_oracle 0.5676 (0.6028) kd_loss 0.9719 (0.9787) acc 93.7500 (97.0833) gate/entropy 1.0878 (1.0884) gate/usage_max 0.3772 (0.3757) gate/usage_min 0.2663 (0.2681) gate/usage_std 0.0482 (0.0468) teacher/entropy 0.0400 (0.0281) teacher/usage_max 0.6203 (0.5802) teacher/usage_min 0.0083 (0.0067) teacher/usage_std 0.2513 (0.2449) nleep/row_max_mean 1478.4282 (1505.5641) nleep/row_max_std 89.6117 (65.0352) nleep/row_min_mean 1449.5498 (1474.7250) lr 1.1874e-03 eta 0:10:25
epoch [24/50] batch [80/160] time 0.131 (0.144) data 0.000 (0.004) loss 1.5052 (1.4272) teacher_loss 0.2238 (0.1146) loss_zs_kd 0.0622 (0.0675) loss_oracle 0.5460 (0.6062) kd_loss 0.9773 (0.9757) acc 93.7500 (97.1094) gate/entropy 1.0873 (1.0882) gate/usage_max 0.3786 (0.3763) gate/usage_min 0.2648 (0.2674) gate/usage_std 0.0493 (0.0473) teacher/entropy 0.0242 (0.0301) teacher/usage_max 0.5164 (0.5807) teacher/usage_min 0.0000 (0.0068) teacher/usage_std 0.2361 (0.2451) nleep/row_max_mean 1509.6090 (1505.7991) nleep/row_max_std 44.8504 (64.3812) nleep/row_min_mean 1477.4292 (1474.7989) lr 1.1874e-03 eta 0:10:08
epoch [24/50] batch [100/160] time 0.145 (0.143) data 0.000 (0.003) loss 1.3800 (1.4263) teacher_loss 0.0329 (0.1114) loss_zs_kd 0.0932 (0.0683) loss_oracle 0.6292 (0.6119) kd_loss 0.9858 (0.9748) acc 100.0000 (97.1875) gate/entropy 1.0869 (1.0880) gate/usage_max 0.3798 (0.3768) gate/usage_min 0.2637 (0.2668) gate/usage_std 0.0501 (0.0478) teacher/entropy 0.0099 (0.0301) teacher/usage_max 0.5621 (0.5763) teacher/usage_min 0.0013 (0.0070) teacher/usage_std 0.2403 (0.2438) nleep/row_max_mean 1505.4349 (1506.4900) nleep/row_max_std 69.0670 (62.6481) nleep/row_min_mean 1471.0127 (1475.3931) lr 1.1874e-03 eta 0:10:02
epoch [24/50] batch [120/160] time 0.137 (0.143) data 0.000 (0.003) loss 1.6722 (1.4272) teacher_loss 0.3792 (0.1111) loss_zs_kd 0.0702 (0.0695) loss_oracle 0.6685 (0.6164) kd_loss 0.9237 (0.9731) acc 90.6250 (97.1354) gate/entropy 1.0864 (1.0877) gate/usage_max 0.3810 (0.3774) gate/usage_min 0.2624 (0.2662) gate/usage_std 0.0511 (0.0483) teacher/entropy 0.0674 (0.0305) teacher/usage_max 0.6404 (0.5765) teacher/usage_min 0.0095 (0.0068) teacher/usage_std 0.2578 (0.2440) nleep/row_max_mean 1503.1608 (1506.5531) nleep/row_max_std 69.8275 (62.0995) nleep/row_min_mean 1475.2874 (1475.4468) lr 1.1874e-03 eta 0:10:00
epoch [24/50] batch [140/160] time 0.096 (0.141) data 0.000 (0.002) loss 1.6465 (1.4271) teacher_loss 0.2967 (0.1117) loss_zs_kd 0.0628 (0.0694) loss_oracle 0.7049 (0.6146) kd_loss 0.9659 (0.9734) acc 87.5000 (97.0759) gate/entropy 1.0859 (1.0875) gate/usage_max 0.3826 (0.3781) gate/usage_min 0.2611 (0.2656) gate/usage_std 0.0522 (0.0487) teacher/entropy 0.0271 (0.0289) teacher/usage_max 0.5399 (0.5749) teacher/usage_min 0.0003 (0.0060) teacher/usage_std 0.2378 (0.2440) nleep/row_max_mean 1515.4387 (1506.5944) nleep/row_max_std 62.9987 (61.5180) nleep/row_min_mean 1483.0370 (1475.5842) lr 1.1874e-03 eta 0:09:48
epoch [24/50] batch [160/160] time 0.115 (0.136) data 0.000 (0.002) loss 1.3892 (1.4243) teacher_loss 0.1006 (0.1109) loss_zs_kd 0.0514 (0.0703) loss_oracle 0.5637 (0.6136) kd_loss 0.9811 (0.9714) acc 96.8750 (97.1289) gate/entropy 1.0854 (1.0873) gate/usage_max 0.3840 (0.3787) gate/usage_min 0.2597 (0.2649) gate/usage_std 0.0533 (0.0492) teacher/entropy 0.0176 (0.0300) teacher/usage_max 0.5647 (0.5750) teacher/usage_min 0.0000 (0.0059) teacher/usage_std 0.2415 (0.2443) nleep/row_max_mean 1508.3506 (1506.6523) nleep/row_max_std 62.8694 (61.6767) nleep/row_min_mean 1474.0439 (1475.5828) lr 1.1253e-03 eta 0:09:24
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,821
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,967
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.9%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [25/50] batch [20/160] time 0.084 (0.118) data 0.000 (0.014) loss 1.4798 (1.4069) teacher_loss 0.1787 (0.1218) loss_zs_kd 0.0802 (0.0634) loss_oracle 0.5839 (0.5870) kd_loss 0.9690 (0.9598) acc 96.8750 (97.1875) gate/entropy 1.0850 (1.0852) gate/usage_max 0.3853 (0.3847) gate/usage_min 0.2588 (0.2593) gate/usage_std 0.0540 (0.0537) teacher/entropy 0.0136 (0.0315) teacher/usage_max 0.6255 (0.5807) teacher/usage_min 0.0004 (0.0019) teacher/usage_std 0.2568 (0.2472) nleep/row_max_mean 1496.1606 (1508.4199) nleep/row_max_std 75.9227 (61.6894) nleep/row_min_mean 1466.1962 (1476.4127) lr 1.1253e-03 eta 0:08:10
epoch [25/50] batch [40/160] time 0.079 (0.114) data 0.000 (0.007) loss 1.3545 (1.4058) teacher_loss 0.0582 (0.1126) loss_zs_kd 0.0778 (0.0649) loss_oracle 0.5915 (0.5982) kd_loss 0.9616 (0.9616) acc 96.8750 (97.1875) gate/entropy 1.0846 (1.0849) gate/usage_max 0.3864 (0.3853) gate/usage_min 0.2578 (0.2587) gate/usage_std 0.0548 (0.0541) teacher/entropy 0.0309 (0.0297) teacher/usage_max 0.5149 (0.5696) teacher/usage_min 0.0000 (0.0038) teacher/usage_std 0.2360 (0.2437) nleep/row_max_mean 1506.2068 (1506.8734) nleep/row_max_std 50.9156 (61.0694) nleep/row_min_mean 1473.6774 (1475.1716) lr 1.1253e-03 eta 0:07:49
epoch [25/50] batch [60/160] time 0.102 (0.114) data 0.000 (0.005) loss 1.3190 (1.4096) teacher_loss 0.0806 (0.1173) loss_zs_kd 0.0563 (0.0668) loss_oracle 0.5377 (0.5982) kd_loss 0.9414 (0.9598) acc 96.8750 (96.9792) gate/entropy 1.0840 (1.0847) gate/usage_max 0.3879 (0.3860) gate/usage_min 0.2564 (0.2581) gate/usage_std 0.0560 (0.0546) teacher/entropy 0.0369 (0.0302) teacher/usage_max 0.6501 (0.5655) teacher/usage_min 0.0055 (0.0032) teacher/usage_std 0.2633 (0.2434) nleep/row_max_mean 1510.7008 (1508.0225) nleep/row_max_std 71.1039 (59.3329) nleep/row_min_mean 1478.0155 (1476.3108) lr 1.1253e-03 eta 0:07:48
epoch [25/50] batch [80/160] time 0.113 (0.114) data 0.000 (0.004) loss 1.3413 (1.3970) teacher_loss 0.1122 (0.1096) loss_zs_kd 0.0813 (0.0662) loss_oracle 0.5351 (0.5954) kd_loss 0.9210 (0.9565) acc 93.7500 (97.2656) gate/entropy 1.0836 (1.0845) gate/usage_max 0.3888 (0.3866) gate/usage_min 0.2555 (0.2576) gate/usage_std 0.0567 (0.0550) teacher/entropy 0.0659 (0.0333) teacher/usage_max 0.5185 (0.5622) teacher/usage_min 0.0001 (0.0039) teacher/usage_std 0.2361 (0.2418) nleep/row_max_mean 1507.8616 (1507.8674) nleep/row_max_std 48.6488 (60.3146) nleep/row_min_mean 1476.4944 (1476.2769) lr 1.1253e-03 eta 0:07:43
epoch [25/50] batch [100/160] time 0.134 (0.118) data 0.000 (0.003) loss 1.3873 (1.4033) teacher_loss 0.0871 (0.1167) loss_zs_kd 0.0639 (0.0669) loss_oracle 0.6156 (0.5953) kd_loss 0.9605 (0.9555) acc 96.8750 (97.0938) gate/entropy 1.0832 (1.0842) gate/usage_max 0.3897 (0.3871) gate/usage_min 0.2546 (0.2570) gate/usage_std 0.0574 (0.0555) teacher/entropy 0.0227 (0.0345) teacher/usage_max 0.5603 (0.5608) teacher/usage_min 0.0055 (0.0044) teacher/usage_std 0.2375 (0.2412) nleep/row_max_mean 1489.6633 (1506.6648) nleep/row_max_std 80.9765 (60.8714) nleep/row_min_mean 1460.3223 (1475.2375) lr 1.1253e-03 eta 0:07:58
epoch [25/50] batch [120/160] time 0.133 (0.122) data 0.000 (0.003) loss 1.5268 (1.4111) teacher_loss 0.1973 (0.1217) loss_zs_kd 0.0697 (0.0683) loss_oracle 0.6457 (0.5959) kd_loss 0.9718 (0.9573) acc 90.6250 (96.8750) gate/entropy 1.0826 (1.0840) gate/usage_max 0.3909 (0.3877) gate/usage_min 0.2530 (0.2565) gate/usage_std 0.0585 (0.0559) teacher/entropy 0.0141 (0.0324) teacher/usage_max 0.4995 (0.5598) teacher/usage_min 0.0019 (0.0047) teacher/usage_std 0.2344 (0.2410) nleep/row_max_mean 1497.0872 (1506.4097) nleep/row_max_std 86.5487 (61.0338) nleep/row_min_mean 1467.6290 (1475.0841) lr 1.1253e-03 eta 0:08:13
epoch [25/50] batch [140/160] time 0.153 (0.125) data 0.000 (0.002) loss 1.3696 (1.4125) teacher_loss 0.0821 (0.1221) loss_zs_kd 0.0445 (0.0678) loss_oracle 0.6370 (0.5976) kd_loss 0.9468 (0.9577) acc 96.8750 (96.8750) gate/entropy 1.0822 (1.0838) gate/usage_max 0.3918 (0.3882) gate/usage_min 0.2522 (0.2559) gate/usage_std 0.0592 (0.0563) teacher/entropy 0.0311 (0.0313) teacher/usage_max 0.5702 (0.5597) teacher/usage_min 0.0014 (0.0047) teacher/usage_std 0.2418 (0.2409) nleep/row_max_mean 1510.2177 (1506.3303) nleep/row_max_std 70.5239 (60.8308) nleep/row_min_mean 1476.9230 (1475.0247) lr 1.1253e-03 eta 0:08:22
epoch [25/50] batch [160/160] time 0.131 (0.126) data 0.000 (0.002) loss 1.3695 (1.4094) teacher_loss 0.0515 (0.1200) loss_zs_kd 0.0694 (0.0679) loss_oracle 0.6246 (0.5977) kd_loss 0.9710 (0.9566) acc 96.8750 (96.8945) gate/entropy 1.0817 (1.0836) gate/usage_max 0.3930 (0.3887) gate/usage_min 0.2511 (0.2554) gate/usage_std 0.0601 (0.0567) teacher/entropy 0.0169 (0.0315) teacher/usage_max 0.5303 (0.5591) teacher/usage_min 0.0041 (0.0047) teacher/usage_std 0.2343 (0.2408) nleep/row_max_mean 1504.7151 (1505.5356) nleep/row_max_std 68.0470 (61.4730) nleep/row_min_mean 1472.8418 (1474.3251) lr 1.0628e-03 eta 0:08:24
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,810
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,966
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.9%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [26/50] batch [20/160] time 0.148 (0.160) data 0.000 (0.017) loss 1.3247 (1.4398) teacher_loss 0.0370 (0.1304) loss_zs_kd 0.0808 (0.0706) loss_oracle 0.5327 (0.6318) kd_loss 0.9810 (0.9582) acc 100.0000 (96.4062) gate/entropy 1.0813 (1.0816) gate/usage_max 0.3940 (0.3934) gate/usage_min 0.2503 (0.2508) gate/usage_std 0.0608 (0.0603) teacher/entropy 0.0007 (0.0264) teacher/usage_max 0.5000 (0.5580) teacher/usage_min 0.0001 (0.0055) teacher/usage_std 0.2356 (0.2404) nleep/row_max_mean 1517.3779 (1501.8075) nleep/row_max_std 42.8626 (59.4009) nleep/row_min_mean 1485.9138 (1472.0247) lr 1.0628e-03 eta 0:10:37
epoch [26/50] batch [40/160] time 0.141 (0.148) data 0.000 (0.008) loss 1.4755 (1.4455) teacher_loss 0.1709 (0.1377) loss_zs_kd 0.0825 (0.0717) loss_oracle 0.6703 (0.6273) kd_loss 0.9281 (0.9583) acc 90.6250 (95.8594) gate/entropy 1.0809 (1.0814) gate/usage_max 0.3949 (0.3939) gate/usage_min 0.2493 (0.2504) gate/usage_std 0.0615 (0.0607) teacher/entropy 0.0601 (0.0269) teacher/usage_max 0.6023 (0.5734) teacher/usage_min 0.0524 (0.0095) teacher/usage_std 0.2247 (0.2415) nleep/row_max_mean 1496.6965 (1502.6429) nleep/row_max_std 75.4128 (61.7031) nleep/row_min_mean 1471.9032 (1473.2060) lr 1.0628e-03 eta 0:09:44
epoch [26/50] batch [60/160] time 0.103 (0.130) data 0.001 (0.006) loss 1.3425 (1.4354) teacher_loss 0.0286 (0.1363) loss_zs_kd 0.0653 (0.0704) loss_oracle 0.6026 (0.6148) kd_loss 0.9800 (0.9566) acc 100.0000 (96.3021) gate/entropy 1.0806 (1.0812) gate/usage_max 0.3953 (0.3943) gate/usage_min 0.2486 (0.2499) gate/usage_std 0.0620 (0.0610) teacher/entropy 0.0063 (0.0275) teacher/usage_max 0.5639 (0.5685) teacher/usage_min 0.0000 (0.0082) teacher/usage_std 0.2414 (0.2409) nleep/row_max_mean 1509.6248 (1503.2725) nleep/row_max_std 50.7953 (63.7396) nleep/row_min_mean 1478.5844 (1473.6226) lr 1.0628e-03 eta 0:08:30
epoch [26/50] batch [80/160] time 0.157 (0.126) data 0.000 (0.004) loss 1.2966 (1.4216) teacher_loss 0.0347 (0.1266) loss_zs_kd 0.0788 (0.0707) loss_oracle 0.5671 (0.6067) kd_loss 0.9390 (0.9563) acc 100.0000 (96.7188) gate/entropy 1.0802 (1.0810) gate/usage_max 0.3963 (0.3947) gate/usage_min 0.2477 (0.2494) gate/usage_std 0.0628 (0.0614) teacher/entropy 0.0525 (0.0274) teacher/usage_max 0.6229 (0.5707) teacher/usage_min 0.0005 (0.0084) teacher/usage_std 0.2560 (0.2410) nleep/row_max_mean 1519.5720 (1504.7231) nleep/row_max_std 29.4310 (61.1443) nleep/row_min_mean 1488.2893 (1474.7921) lr 1.0628e-03 eta 0:08:14
epoch [26/50] batch [100/160] time 0.155 (0.123) data 0.000 (0.003) loss 1.3272 (1.4157) teacher_loss 0.0509 (0.1232) loss_zs_kd 0.0619 (0.0703) loss_oracle 0.6609 (0.6066) kd_loss 0.9149 (0.9540) acc 100.0000 (96.8438) gate/entropy 1.0797 (1.0807) gate/usage_max 0.3973 (0.3951) gate/usage_min 0.2467 (0.2490) gate/usage_std 0.0636 (0.0618) teacher/entropy 0.0569 (0.0291) teacher/usage_max 0.5501 (0.5682) teacher/usage_min 0.0000 (0.0087) teacher/usage_std 0.2392 (0.2402) nleep/row_max_mean 1498.2820 (1504.4303) nleep/row_max_std 64.3868 (62.4627) nleep/row_min_mean 1470.7246 (1474.4586) lr 1.0628e-03 eta 0:08:00
epoch [26/50] batch [120/160] time 0.186 (0.121) data 0.000 (0.003) loss 1.5438 (1.4091) teacher_loss 0.2683 (0.1211) loss_zs_kd 0.0707 (0.0694) loss_oracle 0.5773 (0.6006) kd_loss 0.9516 (0.9530) acc 93.7500 (96.8750) gate/entropy 1.0793 (1.0805) gate/usage_max 0.3981 (0.3955) gate/usage_min 0.2458 (0.2485) gate/usage_std 0.0642 (0.0621) teacher/entropy 0.0199 (0.0296) teacher/usage_max 0.5372 (0.5679) teacher/usage_min 0.0001 (0.0087) teacher/usage_std 0.2376 (0.2402) nleep/row_max_mean 1506.3606 (1504.9655) nleep/row_max_std 56.6033 (62.3228) nleep/row_min_mean 1472.4778 (1474.7884) lr 1.0628e-03 eta 0:07:48
epoch [26/50] batch [140/160] time 0.097 (0.119) data 0.000 (0.003) loss 1.6320 (1.4073) teacher_loss 0.2952 (0.1205) loss_zs_kd 0.0774 (0.0695) loss_oracle 0.7065 (0.5997) kd_loss 0.9449 (0.9522) acc 93.7500 (96.8527) gate/entropy 1.0787 (1.0803) gate/usage_max 0.3991 (0.3960) gate/usage_min 0.2446 (0.2480) gate/usage_std 0.0651 (0.0625) teacher/entropy 0.0192 (0.0293) teacher/usage_max 0.6168 (0.5668) teacher/usage_min 0.0083 (0.0081) teacher/usage_std 0.2502 (0.2402) nleep/row_max_mean 1513.8695 (1505.8335) nleep/row_max_std 57.9324 (61.3943) nleep/row_min_mean 1482.8586 (1475.5590) lr 1.0628e-03 eta 0:07:41
epoch [26/50] batch [160/160] time 0.094 (0.117) data 0.000 (0.002) loss 1.3659 (1.4096) teacher_loss 0.0910 (0.1203) loss_zs_kd 0.0616 (0.0701) loss_oracle 0.5412 (0.6044) kd_loss 0.9735 (0.9520) acc 96.8750 (96.8750) gate/entropy 1.0783 (1.0801) gate/usage_max 0.3999 (0.3964) gate/usage_min 0.2436 (0.2476) gate/usage_std 0.0659 (0.0629) teacher/entropy 0.0124 (0.0286) teacher/usage_max 0.5938 (0.5677) teacher/usage_min 0.0041 (0.0078) teacher/usage_std 0.2456 (0.2406) nleep/row_max_mean 1510.3176 (1506.4034) nleep/row_max_std 71.4923 (60.5649) nleep/row_min_mean 1478.4456 (1476.0295) lr 1.0000e-03 eta 0:07:31
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,805
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,948
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.8%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [27/50] batch [20/160] time 0.118 (0.150) data 0.000 (0.014) loss 1.3765 (1.3741) teacher_loss 0.0772 (0.0991) loss_zs_kd 0.0785 (0.0672) loss_oracle 0.5748 (0.5934) kd_loss 0.9727 (0.9447) acc 96.8750 (97.5000) gate/entropy 1.0779 (1.0782) gate/usage_max 0.4004 (0.4001) gate/usage_min 0.2429 (0.2435) gate/usage_std 0.0664 (0.0660) teacher/entropy 0.0066 (0.0302) teacher/usage_max 0.5619 (0.5450) teacher/usage_min 0.0000 (0.0052) teacher/usage_std 0.2411 (0.2373) nleep/row_max_mean 1522.0602 (1505.3161) nleep/row_max_std 26.0179 (59.9992) nleep/row_min_mean 1490.8864 (1475.2967) lr 1.0000e-03 eta 0:09:34
epoch [27/50] batch [40/160] time 0.145 (0.144) data 0.000 (0.007) loss 1.5038 (1.4020) teacher_loss 0.1901 (0.1240) loss_zs_kd 0.0677 (0.0688) loss_oracle 0.6400 (0.5943) kd_loss 0.9598 (0.9464) acc 93.7500 (96.5625) gate/entropy 1.0777 (1.0780) gate/usage_max 0.4009 (0.4004) gate/usage_min 0.2425 (0.2431) gate/usage_std 0.0667 (0.0663) teacher/entropy 0.0370 (0.0300) teacher/usage_max 0.4998 (0.5491) teacher/usage_min 0.0493 (0.0082) teacher/usage_std 0.2019 (0.2364) nleep/row_max_mean 1502.5221 (1503.5313) nleep/row_max_std 65.7486 (63.6669) nleep/row_min_mean 1470.7073 (1473.6356) lr 1.0000e-03 eta 0:09:05
epoch [27/50] batch [60/160] time 0.110 (0.143) data 0.000 (0.005) loss 1.2936 (1.4020) teacher_loss 0.0356 (0.1249) loss_zs_kd 0.0622 (0.0676) loss_oracle 0.5806 (0.5931) kd_loss 0.9367 (0.9468) acc 100.0000 (96.5625) gate/entropy 1.0773 (1.0778) gate/usage_max 0.4016 (0.4008) gate/usage_min 0.2416 (0.2427) gate/usage_std 0.0674 (0.0666) teacher/entropy 0.0565 (0.0301) teacher/usage_max 0.5766 (0.5510) teacher/usage_min 0.0265 (0.0088) teacher/usage_std 0.2290 (0.2363) nleep/row_max_mean 1492.5670 (1503.4387) nleep/row_max_std 86.0133 (62.7686) nleep/row_min_mean 1464.0669 (1473.7433) lr 1.0000e-03 eta 0:09:00
epoch [27/50] batch [80/160] time 0.144 (0.142) data 0.000 (0.004) loss 1.4153 (1.3976) teacher_loss 0.0984 (0.1208) loss_zs_kd 0.0601 (0.0678) loss_oracle 0.6331 (0.5931) kd_loss 0.9703 (0.9463) acc 96.8750 (96.6797) gate/entropy 1.0767 (1.0776) gate/usage_max 0.4024 (0.4011) gate/usage_min 0.2405 (0.2423) gate/usage_std 0.0682 (0.0669) teacher/entropy 0.0063 (0.0300) teacher/usage_max 0.5620 (0.5528) teacher/usage_min 0.0001 (0.0077) teacher/usage_std 0.2410 (0.2374) nleep/row_max_mean 1491.3066 (1503.4820) nleep/row_max_std 73.4876 (61.6650) nleep/row_min_mean 1463.7529 (1473.7213) lr 1.0000e-03 eta 0:08:52
epoch [27/50] batch [100/160] time 0.144 (0.142) data 0.000 (0.003) loss 1.3711 (1.3995) teacher_loss 0.0467 (0.1196) loss_zs_kd 0.0765 (0.0674) loss_oracle 0.6569 (0.6002) kd_loss 0.9577 (0.9461) acc 100.0000 (96.8438) gate/entropy 1.0765 (1.0774) gate/usage_max 0.4030 (0.4014) gate/usage_min 0.2400 (0.2419) gate/usage_std 0.0686 (0.0672) teacher/entropy 0.0169 (0.0286) teacher/usage_max 0.5302 (0.5579) teacher/usage_min 0.0038 (0.0073) teacher/usage_std 0.2345 (0.2390) nleep/row_max_mean 1482.9995 (1503.1422) nleep/row_max_std 91.6737 (62.7706) nleep/row_min_mean 1451.8175 (1473.1413) lr 1.0000e-03 eta 0:08:52
epoch [27/50] batch [120/160] time 0.120 (0.142) data 0.000 (0.002) loss 1.3854 (1.3984) teacher_loss 0.0990 (0.1182) loss_zs_kd 0.0614 (0.0684) loss_oracle 0.6141 (0.6017) kd_loss 0.9486 (0.9451) acc 96.8750 (96.9010) gate/entropy 1.0761 (1.0772) gate/usage_max 0.4040 (0.4018) gate/usage_min 0.2393 (0.2415) gate/usage_std 0.0692 (0.0675) teacher/entropy 0.0196 (0.0291) teacher/usage_max 0.4991 (0.5566) teacher/usage_min 0.0018 (0.0085) teacher/usage_std 0.2344 (0.2382) nleep/row_max_mean 1488.7555 (1502.9395) nleep/row_max_std 81.3691 (62.7398) nleep/row_min_mean 1461.0007 (1472.8505) lr 1.0000e-03 eta 0:08:49
epoch [27/50] batch [140/160] time 0.109 (0.139) data 0.000 (0.002) loss 1.3753 (1.3984) teacher_loss 0.0424 (0.1183) loss_zs_kd 0.0643 (0.0689) loss_oracle 0.6357 (0.6037) kd_loss 0.9830 (0.9438) acc 100.0000 (96.8750) gate/entropy 1.0758 (1.0770) gate/usage_max 0.4046 (0.4022) gate/usage_min 0.2388 (0.2411) gate/usage_std 0.0697 (0.0678) teacher/entropy 0.0166 (0.0289) teacher/usage_max 0.6563 (0.5657) teacher/usage_min 0.0248 (0.0081) teacher/usage_std 0.2580 (0.2413) nleep/row_max_mean 1480.5670 (1503.0072) nleep/row_max_std 77.4706 (61.8779) nleep/row_min_mean 1453.9775 (1472.8320) lr 1.0000e-03 eta 0:08:35
epoch [27/50] batch [160/160] time 0.119 (0.137) data 0.000 (0.002) loss 1.6273 (1.3991) teacher_loss 0.3293 (0.1185) loss_zs_kd 0.0930 (0.0693) loss_oracle 0.6342 (0.6071) kd_loss 0.9343 (0.9424) acc 90.6250 (96.8945) gate/entropy 1.0752 (1.0768) gate/usage_max 0.4057 (0.4026) gate/usage_min 0.2377 (0.2407) gate/usage_std 0.0705 (0.0681) teacher/entropy 0.0267 (0.0299) teacher/usage_max 0.5587 (0.5655) teacher/usage_min 0.0066 (0.0088) teacher/usage_std 0.2365 (0.2408) nleep/row_max_mean 1489.7413 (1502.9704) nleep/row_max_std 78.1851 (61.4521) nleep/row_min_mean 1455.5688 (1472.8167) lr 9.3721e-04 eta 0:08:24
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,815
* accuracy: 82.3%
* error: 17.7%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,950
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.7%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [28/50] batch [20/160] time 0.082 (0.122) data 0.000 (0.015) loss 1.2180 (1.3934) teacher_loss 0.0812 (0.1320) loss_zs_kd 0.0425 (0.0639) loss_oracle 0.5269 (0.5991) kd_loss 0.8521 (0.9299) acc 100.0000 (96.5625) gate/entropy 1.0749 (1.0750) gate/usage_max 0.4064 (0.4062) gate/usage_min 0.2371 (0.2374) gate/usage_std 0.0710 (0.0708) teacher/entropy 0.1136 (0.0348) teacher/usage_max 0.5074 (0.5582) teacher/usage_min 0.0000 (0.0072) teacher/usage_std 0.2358 (0.2386) nleep/row_max_mean 1514.1345 (1502.7173) nleep/row_max_std 23.7659 (56.4546) nleep/row_min_mean 1484.1525 (1472.7484) lr 9.3721e-04 eta 0:07:27
epoch [28/50] batch [40/160] time 0.076 (0.115) data 0.000 (0.008) loss 1.3140 (1.3940) teacher_loss 0.0652 (0.1279) loss_zs_kd 0.0820 (0.0646) loss_oracle 0.5758 (0.6009) kd_loss 0.9199 (0.9334) acc 100.0000 (96.8750) gate/entropy 1.0744 (1.0749) gate/usage_max 0.4074 (0.4066) gate/usage_min 0.2364 (0.2371) gate/usage_std 0.0717 (0.0711) teacher/entropy 0.0382 (0.0308) teacher/usage_max 0.6061 (0.5595) teacher/usage_min 0.0199 (0.0062) teacher/usage_std 0.2410 (0.2394) nleep/row_max_mean 1499.5237 (1500.9671) nleep/row_max_std 66.9297 (60.9496) nleep/row_min_mean 1469.7615 (1471.1453) lr 9.3721e-04 eta 0:06:58
epoch [28/50] batch [60/160] time 0.060 (0.105) data 0.000 (0.005) loss 1.4197 (1.3899) teacher_loss 0.0744 (0.1187) loss_zs_kd 0.0567 (0.0668) loss_oracle 0.7052 (0.6097) kd_loss 0.9644 (0.9330) acc 96.8750 (96.9271) gate/entropy 1.0740 (1.0747) gate/usage_max 0.4082 (0.4069) gate/usage_min 0.2357 (0.2368) gate/usage_std 0.0723 (0.0713) teacher/entropy 0.0029 (0.0320) teacher/usage_max 0.5308 (0.5602) teacher/usage_min 0.0001 (0.0070) teacher/usage_std 0.2370 (0.2393) nleep/row_max_mean 1517.6422 (1501.4843) nleep/row_max_std 42.7820 (61.1982) nleep/row_min_mean 1486.9739 (1471.7165) lr 9.3721e-04 eta 0:06:19
epoch [28/50] batch [80/160] time 0.142 (0.101) data 0.000 (0.004) loss 1.3326 (1.3874) teacher_loss 0.0770 (0.1110) loss_zs_kd 0.0842 (0.0676) loss_oracle 0.6148 (0.6174) kd_loss 0.9061 (0.9339) acc 96.8750 (97.1484) gate/entropy 1.0738 (1.0745) gate/usage_max 0.4086 (0.4073) gate/usage_min 0.2351 (0.2365) gate/usage_std 0.0727 (0.0716) teacher/entropy 0.0630 (0.0313) teacher/usage_max 0.4955 (0.5587) teacher/usage_min 0.0128 (0.0074) teacher/usage_std 0.2267 (0.2387) nleep/row_max_mean 1492.0354 (1502.5347) nleep/row_max_std 86.0882 (59.3572) nleep/row_min_mean 1464.5835 (1472.8890) lr 9.3721e-04 eta 0:06:03
epoch [28/50] batch [100/160] time 0.148 (0.101) data 0.000 (0.003) loss 1.3320 (1.3877) teacher_loss 0.0867 (0.1118) loss_zs_kd 0.0711 (0.0690) loss_oracle 0.6084 (0.6200) kd_loss 0.9055 (0.9314) acc 100.0000 (97.0312) gate/entropy 1.0736 (1.0744) gate/usage_max 0.4092 (0.4076) gate/usage_min 0.2349 (0.2362) gate/usage_std 0.0729 (0.0718) teacher/entropy 0.0650 (0.0337) teacher/usage_max 0.5349 (0.5604) teacher/usage_min 0.0315 (0.0090) teacher/usage_std 0.2174 (0.2387) nleep/row_max_mean 1484.8789 (1502.3194) nleep/row_max_std 79.6047 (60.3863) nleep/row_min_mean 1457.7345 (1472.7879) lr 9.3721e-04 eta 0:05:59
epoch [28/50] batch [120/160] time 0.149 (0.102) data 0.000 (0.003) loss 1.2471 (1.3891) teacher_loss 0.0438 (0.1161) loss_zs_kd 0.0532 (0.0686) loss_oracle 0.5756 (0.6168) kd_loss 0.8889 (0.9303) acc 100.0000 (96.8750) gate/entropy 1.0732 (1.0742) gate/usage_max 0.4102 (0.4080) gate/usage_min 0.2344 (0.2359) gate/usage_std 0.0734 (0.0721) teacher/entropy 0.0568 (0.0345) teacher/usage_max 0.6148 (0.5641) teacher/usage_min 0.0002 (0.0107) teacher/usage_std 0.2535 (0.2385) nleep/row_max_mean 1509.0037 (1502.6057) nleep/row_max_std 42.9900 (59.9289) nleep/row_min_mean 1480.8058 (1473.1430) lr 9.3721e-04 eta 0:06:03
epoch [28/50] batch [140/160] time 0.149 (0.103) data 0.000 (0.002) loss 1.3464 (1.3875) teacher_loss 0.1198 (0.1163) loss_zs_kd 0.0792 (0.0677) loss_oracle 0.5172 (0.6150) kd_loss 0.9284 (0.9298) acc 96.8750 (96.8080) gate/entropy 1.0728 (1.0740) gate/usage_max 0.4112 (0.4083) gate/usage_min 0.2337 (0.2357) gate/usage_std 0.0741 (0.0723) teacher/entropy 0.0337 (0.0349) teacher/usage_max 0.5068 (0.5648) teacher/usage_min 0.0004 (0.0102) teacher/usage_std 0.2355 (0.2390) nleep/row_max_mean 1521.1526 (1502.2778) nleep/row_max_std 33.7351 (60.0114) nleep/row_min_mean 1488.1710 (1472.8708) lr 9.3721e-04 eta 0:06:04
epoch [28/50] batch [160/160] time 0.118 (0.104) data 0.000 (0.002) loss 1.3151 (1.3918) teacher_loss 0.0401 (0.1187) loss_zs_kd 0.0652 (0.0686) loss_oracle 0.6699 (0.6191) kd_loss 0.9074 (0.9292) acc 100.0000 (96.7969) gate/entropy 1.0724 (1.0739) gate/usage_max 0.4119 (0.4087) gate/usage_min 0.2330 (0.2354) gate/usage_std 0.0746 (0.0725) teacher/entropy 0.0416 (0.0346) teacher/usage_max 0.5763 (0.5644) teacher/usage_min 0.0004 (0.0096) teacher/usage_std 0.2436 (0.2393) nleep/row_max_mean 1521.8810 (1502.7237) nleep/row_max_std 29.9895 (59.7730) nleep/row_min_mean 1490.7705 (1473.2092) lr 8.7467e-04 eta 0:06:07
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,827
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,950
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 88.5%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [29/50] batch [20/160] time 0.133 (0.158) data 0.000 (0.013) loss 1.3863 (1.3903) teacher_loss 0.0910 (0.1282) loss_zs_kd 0.0941 (0.0680) loss_oracle 0.6354 (0.6110) kd_loss 0.9305 (0.9226) acc 96.8750 (97.1875) gate/entropy 1.0722 (1.0723) gate/usage_max 0.4122 (0.4120) gate/usage_min 0.2327 (0.2329) gate/usage_std 0.0749 (0.0747) teacher/entropy 0.0299 (0.0368) teacher/usage_max 0.5230 (0.5713) teacher/usage_min 0.0093 (0.0113) teacher/usage_std 0.2303 (0.2409) nleep/row_max_mean 1496.1086 (1503.1848) nleep/row_max_std 65.9890 (60.2331) nleep/row_min_mean 1467.4102 (1473.3333) lr 8.7467e-04 eta 0:09:13
epoch [29/50] batch [40/160] time 0.124 (0.145) data 0.000 (0.007) loss 1.3908 (1.3714) teacher_loss 0.1089 (0.1109) loss_zs_kd 0.0812 (0.0701) loss_oracle 0.6729 (0.6058) kd_loss 0.9048 (0.9226) acc 96.8750 (97.3438) gate/entropy 1.0718 (1.0722) gate/usage_max 0.4132 (0.4124) gate/usage_min 0.2321 (0.2326) gate/usage_std 0.0754 (0.0750) teacher/entropy 0.0469 (0.0341) teacher/usage_max 0.6651 (0.5775) teacher/usage_min 0.0414 (0.0082) teacher/usage_std 0.2562 (0.2440) nleep/row_max_mean 1517.4094 (1505.1696) nleep/row_max_std 25.1432 (57.6200) nleep/row_min_mean 1484.5503 (1474.6224) lr 8.7467e-04 eta 0:08:24
epoch [29/50] batch [60/160] time 0.129 (0.140) data 0.000 (0.005) loss 1.3076 (1.3633) teacher_loss 0.0956 (0.1049) loss_zs_kd 0.0856 (0.0690) loss_oracle 0.5361 (0.6012) kd_loss 0.9012 (0.9233) acc 100.0000 (97.6562) gate/entropy 1.0712 (1.0720) gate/usage_max 0.4145 (0.4128) gate/usage_min 0.2311 (0.2323) gate/usage_std 0.0763 (0.0752) teacher/entropy 0.0226 (0.0331) teacher/usage_max 0.7246 (0.5769) teacher/usage_min 0.0000 (0.0076) teacher/usage_std 0.2986 (0.2447) nleep/row_max_mean 1517.8081 (1504.2708) nleep/row_max_std 47.4469 (58.8209) nleep/row_min_mean 1484.6594 (1473.5605) lr 8.7467e-04 eta 0:08:03
epoch [29/50] batch [80/160] time 0.127 (0.136) data 0.000 (0.003) loss 1.3164 (1.3693) teacher_loss 0.0583 (0.1111) loss_zs_kd 0.0569 (0.0671) loss_oracle 0.6246 (0.6103) kd_loss 0.9173 (0.9196) acc 100.0000 (97.4219) gate/entropy 1.0710 (1.0718) gate/usage_max 0.4150 (0.4132) gate/usage_min 0.2309 (0.2320) gate/usage_std 0.0766 (0.0755) teacher/entropy 0.0344 (0.0352) teacher/usage_max 0.5373 (0.5812) teacher/usage_min 0.0000 (0.0074) teacher/usage_std 0.2376 (0.2458) nleep/row_max_mean 1507.2271 (1503.4127) nleep/row_max_std 50.2599 (60.4638) nleep/row_min_mean 1475.7380 (1472.5021) lr 8.7467e-04 eta 0:07:48
epoch [29/50] batch [100/160] time 0.163 (0.135) data 0.000 (0.003) loss 1.4042 (1.3768) teacher_loss 0.1410 (0.1152) loss_zs_kd 0.0742 (0.0665) loss_oracle 0.6285 (0.6186) kd_loss 0.9119 (0.9192) acc 96.8750 (97.2188) gate/entropy 1.0707 (1.0716) gate/usage_max 0.4158 (0.4137) gate/usage_min 0.2305 (0.2318) gate/usage_std 0.0770 (0.0758) teacher/entropy 0.0324 (0.0354) teacher/usage_max 0.5822 (0.5776) teacher/usage_min 0.0002 (0.0083) teacher/usage_std 0.2450 (0.2441) nleep/row_max_mean 1502.4905 (1503.2906) nleep/row_max_std 52.3110 (60.6213) nleep/row_min_mean 1470.7283 (1472.3140) lr 8.7467e-04 eta 0:07:42
epoch [29/50] batch [120/160] time 0.094 (0.132) data 0.000 (0.002) loss 1.4746 (1.3830) teacher_loss 0.2531 (0.1183) loss_zs_kd 0.0836 (0.0677) loss_oracle 0.5589 (0.6240) kd_loss 0.9002 (0.9188) acc 93.7500 (97.1875) gate/entropy 1.0704 (1.0714) gate/usage_max 0.4165 (0.4141) gate/usage_min 0.2300 (0.2315) gate/usage_std 0.0775 (0.0760) teacher/entropy 0.0529 (0.0358) teacher/usage_max 0.5341 (0.5798) teacher/usage_min 0.0036 (0.0080) teacher/usage_std 0.2350 (0.2447) nleep/row_max_mean 1500.5569 (1502.4194) nleep/row_max_std 75.8157 (61.1157) nleep/row_min_mean 1470.2120 (1471.5978) lr 8.7467e-04 eta 0:07:28
epoch [29/50] batch [140/160] time 0.164 (0.127) data 0.000 (0.002) loss 1.6549 (1.3895) teacher_loss 0.3450 (0.1239) loss_zs_kd 0.0651 (0.0677) loss_oracle 0.7060 (0.6256) kd_loss 0.9243 (0.9189) acc 87.5000 (96.9196) gate/entropy 1.0699 (1.0713) gate/usage_max 0.4175 (0.4145) gate/usage_min 0.2293 (0.2313) gate/usage_std 0.0781 (0.0762) teacher/entropy 0.0515 (0.0354) teacher/usage_max 0.5500 (0.5810) teacher/usage_min 0.0187 (0.0082) teacher/usage_std 0.2277 (0.2449) nleep/row_max_mean 1504.0579 (1502.9996) nleep/row_max_std 78.4377 (60.1627) nleep/row_min_mean 1473.9788 (1472.1110) lr 8.7467e-04 eta 0:07:08
epoch [29/50] batch [160/160] time 0.065 (0.124) data 0.000 (0.002) loss 1.4710 (1.3933) teacher_loss 0.1534 (0.1250) loss_zs_kd 0.0831 (0.0687) loss_oracle 0.6566 (0.6297) kd_loss 0.9477 (0.9190) acc 93.7500 (96.8555) gate/entropy 1.0698 (1.0711) gate/usage_max 0.4179 (0.4149) gate/usage_min 0.2291 (0.2311) gate/usage_std 0.0783 (0.0765) teacher/entropy 0.0090 (0.0354) teacher/usage_max 0.5014 (0.5799) teacher/usage_min 0.0002 (0.0084) teacher/usage_std 0.2355 (0.2444) nleep/row_max_mean 1498.0852 (1502.7830) nleep/row_max_std 50.9908 (60.0575) nleep/row_min_mean 1469.0403 (1471.8682) lr 8.1262e-04 eta 0:06:56
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,822
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,941
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 88.2%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [30/50] batch [20/160] time 0.092 (0.105) data 0.000 (0.012) loss 1.5231 (1.3864) teacher_loss 0.2416 (0.1249) loss_zs_kd 0.0947 (0.0669) loss_oracle 0.6043 (0.6116) kd_loss 0.9320 (0.9222) acc 93.7500 (96.8750) gate/entropy 1.0696 (1.0697) gate/usage_max 0.4185 (0.4183) gate/usage_min 0.2289 (0.2290) gate/usage_std 0.0786 (0.0785) teacher/entropy 0.0212 (0.0352) teacher/usage_max 0.5948 (0.5673) teacher/usage_min 0.0307 (0.0142) teacher/usage_std 0.2321 (0.2366) nleep/row_max_mean 1492.4182 (1498.0362) nleep/row_max_std 67.8591 (63.5753) nleep/row_min_mean 1461.5723 (1468.0421) lr 8.1262e-04 eta 0:05:49
epoch [30/50] batch [40/160] time 0.171 (0.107) data 0.000 (0.006) loss 1.4134 (1.3785) teacher_loss 0.1116 (0.1135) loss_zs_kd 0.0620 (0.0684) loss_oracle 0.6617 (0.6273) kd_loss 0.9400 (0.9172) acc 96.8750 (96.9531) gate/entropy 1.0692 (1.0695) gate/usage_max 0.4193 (0.4186) gate/usage_min 0.2283 (0.2287) gate/usage_std 0.0791 (0.0787) teacher/entropy 0.0211 (0.0369) teacher/usage_max 0.5568 (0.5673) teacher/usage_min 0.0355 (0.0122) teacher/usage_std 0.2192 (0.2383) nleep/row_max_mean 1496.8406 (1500.2269) nleep/row_max_std 66.0863 (61.6572) nleep/row_min_mean 1469.3062 (1470.0942) lr 8.1262e-04 eta 0:05:55
epoch [30/50] batch [60/160] time 0.153 (0.109) data 0.001 (0.004) loss 1.3037 (1.3797) teacher_loss 0.0378 (0.1156) loss_zs_kd 0.0547 (0.0681) loss_oracle 0.6179 (0.6273) kd_loss 0.9296 (0.9163) acc 100.0000 (96.8750) gate/entropy 1.0689 (1.0693) gate/usage_max 0.4200 (0.4190) gate/usage_min 0.2279 (0.2285) gate/usage_std 0.0795 (0.0789) teacher/entropy 0.0031 (0.0358) teacher/usage_max 0.6251 (0.5686) teacher/usage_min 0.0004 (0.0101) teacher/usage_std 0.2567 (0.2401) nleep/row_max_mean 1514.4128 (1500.9219) nleep/row_max_std 48.2021 (61.2542) nleep/row_min_mean 1480.4019 (1470.8074) lr 8.1262e-04 eta 0:05:59
epoch [30/50] batch [80/160] time 0.053 (0.110) data 0.000 (0.003) loss 1.3039 (1.3852) teacher_loss 0.0904 (0.1226) loss_zs_kd 0.0724 (0.0690) loss_oracle 0.5068 (0.6288) kd_loss 0.9239 (0.9137) acc 93.7500 (96.6406) gate/entropy 1.0686 (1.0692) gate/usage_max 0.4208 (0.4193) gate/usage_min 0.2275 (0.2283) gate/usage_std 0.0800 (0.0791) teacher/entropy 0.0289 (0.0378) teacher/usage_max 0.5273 (0.5729) teacher/usage_min 0.0072 (0.0102) teacher/usage_std 0.2320 (0.2410) nleep/row_max_mean 1499.9336 (1499.6054) nleep/row_max_std 56.9692 (62.3174) nleep/row_min_mean 1471.8938 (1469.5188) lr 8.1262e-04 eta 0:06:00
epoch [30/50] batch [100/160] time 0.060 (0.106) data 0.001 (0.003) loss 1.3989 (1.3831) teacher_loss 0.1214 (0.1201) loss_zs_kd 0.0603 (0.0683) loss_oracle 0.6495 (0.6315) kd_loss 0.9225 (0.9130) acc 96.8750 (96.7188) gate/entropy 1.0684 (1.0690) gate/usage_max 0.4211 (0.4197) gate/usage_min 0.2272 (0.2281) gate/usage_std 0.0802 (0.0794) teacher/entropy 0.0285 (0.0380) teacher/usage_max 0.5891 (0.5719) teacher/usage_min 0.0312 (0.0105) teacher/usage_std 0.2301 (0.2407) nleep/row_max_mean 1502.0986 (1499.6711) nleep/row_max_std 49.0316 (62.4741) nleep/row_min_mean 1470.9919 (1469.5943) lr 8.1262e-04 eta 0:05:46
epoch [30/50] batch [120/160] time 0.128 (0.107) data 0.000 (0.002) loss 1.3086 (1.3825) teacher_loss 0.0497 (0.1193) loss_zs_kd 0.0387 (0.0677) loss_oracle 0.6584 (0.6323) kd_loss 0.9103 (0.9131) acc 100.0000 (96.7708) gate/entropy 1.0681 (1.0689) gate/usage_max 0.4218 (0.4200) gate/usage_min 0.2267 (0.2279) gate/usage_std 0.0807 (0.0796) teacher/entropy 0.0612 (0.0387) teacher/usage_max 0.5429 (0.5734) teacher/usage_min 0.0171 (0.0101) teacher/usage_std 0.2275 (0.2409) nleep/row_max_mean 1487.6667 (1499.0120) nleep/row_max_std 85.2078 (63.7279) nleep/row_min_mean 1461.6797 (1469.1444) lr 8.1262e-04 eta 0:05:45
epoch [30/50] batch [140/160] time 0.134 (0.109) data 0.000 (0.002) loss 1.3141 (1.3836) teacher_loss 0.0366 (0.1184) loss_zs_kd 0.0767 (0.0680) loss_oracle 0.5621 (0.6335) kd_loss 0.9580 (0.9146) acc 100.0000 (96.8527) gate/entropy 1.0679 (1.0687) gate/usage_max 0.4222 (0.4203) gate/usage_min 0.2264 (0.2276) gate/usage_std 0.0809 (0.0798) teacher/entropy 0.0172 (0.0366) teacher/usage_max 0.6197 (0.5733) teacher/usage_min 0.0003 (0.0093) teacher/usage_std 0.2550 (0.2417) nleep/row_max_mean 1475.8123 (1499.0816) nleep/row_max_std 77.3684 (62.5540) nleep/row_min_mean 1449.0293 (1469.2893) lr 8.1262e-04 eta 0:05:51
epoch [30/50] batch [160/160] time 0.119 (0.113) data 0.000 (0.002) loss 1.4337 (1.3871) teacher_loss 0.0792 (0.1202) loss_zs_kd 0.0705 (0.0688) loss_oracle 0.7010 (0.6355) kd_loss 0.9687 (0.9148) acc 100.0000 (96.8359) gate/entropy 1.0674 (1.0686) gate/usage_max 0.4233 (0.4207) gate/usage_min 0.2258 (0.2274) gate/usage_std 0.0816 (0.0800) teacher/entropy 0.0041 (0.0359) teacher/usage_max 0.4992 (0.5727) teacher/usage_min 0.0321 (0.0094) teacher/usage_std 0.2134 (0.2417) nleep/row_max_mean 1509.3552 (1499.0394) nleep/row_max_std 19.9708 (62.2457) nleep/row_min_mean 1480.0388 (1469.2941) lr 7.5131e-04 eta 0:06:02
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,824
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,953
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 88.6%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [31/50] batch [20/160] time 0.151 (0.152) data 0.000 (0.016) loss 1.4857 (1.3725) teacher_loss 0.2192 (0.1064) loss_zs_kd 0.0917 (0.0675) loss_oracle 0.6044 (0.6208) kd_loss 0.9184 (0.9220) acc 93.7500 (98.2812) gate/entropy 1.0673 (1.0673) gate/usage_max 0.4235 (0.4236) gate/usage_min 0.2257 (0.2257) gate/usage_std 0.0817 (0.0817) teacher/entropy 0.0323 (0.0286) teacher/usage_max 0.5664 (0.5956) teacher/usage_min 0.0241 (0.0120) teacher/usage_std 0.2279 (0.2481) nleep/row_max_mean 1482.6428 (1495.5098) nleep/row_max_std 79.3849 (64.3863) nleep/row_min_mean 1453.7402 (1465.9486) lr 7.5131e-04 eta 0:08:01
epoch [31/50] batch [40/160] time 0.131 (0.148) data 0.000 (0.008) loss 1.3139 (1.3937) teacher_loss 0.0533 (0.1242) loss_zs_kd 0.0727 (0.0731) loss_oracle 0.5545 (0.6261) kd_loss 0.9469 (0.9200) acc 100.0000 (97.1094) gate/entropy 1.0670 (1.0672) gate/usage_max 0.4242 (0.4238) gate/usage_min 0.2252 (0.2255) gate/usage_std 0.0821 (0.0819) teacher/entropy 0.0314 (0.0326) teacher/usage_max 0.4771 (0.5731) teacher/usage_min 0.0507 (0.0157) teacher/usage_std 0.1999 (0.2394) nleep/row_max_mean 1487.6130 (1495.0497) nleep/row_max_std 79.7412 (66.1561) nleep/row_min_mean 1457.8181 (1465.8037) lr 7.5131e-04 eta 0:07:48
epoch [31/50] batch [60/160] time 0.117 (0.145) data 0.001 (0.005) loss 1.2608 (1.3827) teacher_loss 0.0533 (0.1117) loss_zs_kd 0.0768 (0.0732) loss_oracle 0.5950 (0.6333) kd_loss 0.8716 (0.9177) acc 100.0000 (97.3958) gate/entropy 1.0666 (1.0670) gate/usage_max 0.4249 (0.4241) gate/usage_min 0.2247 (0.2253) gate/usage_std 0.0826 (0.0821) teacher/entropy 0.0998 (0.0346) teacher/usage_max 0.5466 (0.5671) teacher/usage_min 0.0173 (0.0135) teacher/usage_std 0.2280 (0.2390) nleep/row_max_mean 1502.4817 (1496.3618) nleep/row_max_std 53.9639 (64.5160) nleep/row_min_mean 1474.5696 (1467.2622) lr 7.5131e-04 eta 0:07:35
epoch [31/50] batch [80/160] time 0.092 (0.136) data 0.000 (0.004) loss 1.4312 (1.3829) teacher_loss 0.0483 (0.1069) loss_zs_kd 0.0998 (0.0737) loss_oracle 0.7293 (0.6407) kd_loss 0.9684 (0.9188) acc 100.0000 (97.5000) gate/entropy 1.0665 (1.0669) gate/usage_max 0.4252 (0.4243) gate/usage_min 0.2246 (0.2252) gate/usage_std 0.0828 (0.0822) teacher/entropy 0.0164 (0.0335) teacher/usage_max 0.5593 (0.5710) teacher/usage_min 0.0345 (0.0130) teacher/usage_std 0.2204 (0.2405) nleep/row_max_mean 1480.4034 (1496.8185) nleep/row_max_std 77.5282 (63.9160) nleep/row_min_mean 1455.3125 (1467.7041) lr 7.5131e-04 eta 0:07:05
epoch [31/50] batch [100/160] time 0.087 (0.132) data 0.000 (0.003) loss 1.2922 (1.3862) teacher_loss 0.0465 (0.1103) loss_zs_kd 0.0564 (0.0728) loss_oracle 0.6391 (0.6425) kd_loss 0.8980 (0.9181) acc 100.0000 (97.3125) gate/entropy 1.0661 (1.0668) gate/usage_max 0.4259 (0.4246) gate/usage_min 0.2240 (0.2250) gate/usage_std 0.0832 (0.0824) teacher/entropy 0.0545 (0.0341) teacher/usage_max 0.5110 (0.5689) teacher/usage_min 0.0089 (0.0132) teacher/usage_std 0.2298 (0.2399) nleep/row_max_mean 1496.3772 (1497.4448) nleep/row_max_std 84.1870 (63.1838) nleep/row_min_mean 1469.9551 (1468.3687) lr 7.5131e-04 eta 0:06:49
epoch [31/50] batch [120/160] time 0.163 (0.132) data 0.000 (0.003) loss 1.6138 (1.3933) teacher_loss 0.3313 (0.1180) loss_zs_kd 0.0828 (0.0720) loss_oracle 0.6387 (0.6459) kd_loss 0.9217 (0.9164) acc 90.6250 (97.0573) gate/entropy 1.0660 (1.0667) gate/usage_max 0.4264 (0.4248) gate/usage_min 0.2239 (0.2248) gate/usage_std 0.0835 (0.0825) teacher/entropy 0.0255 (0.0338) teacher/usage_max 0.5289 (0.5734) teacher/usage_min 0.0048 (0.0126) teacher/usage_std 0.2337 (0.2412) nleep/row_max_mean 1490.3716 (1497.6938) nleep/row_max_std 66.9546 (62.4940) nleep/row_min_mean 1461.8281 (1468.7682) lr 7.5131e-04 eta 0:06:47
epoch [31/50] batch [140/160] time 0.091 (0.129) data 0.000 (0.002) loss 1.3196 (1.3933) teacher_loss 0.0430 (0.1188) loss_zs_kd 0.0673 (0.0719) loss_oracle 0.6431 (0.6451) kd_loss 0.9214 (0.9159) acc 100.0000 (96.8973) gate/entropy 1.0658 (1.0665) gate/usage_max 0.4267 (0.4251) gate/usage_min 0.2238 (0.2247) gate/usage_std 0.0836 (0.0827) teacher/entropy 0.0259 (0.0344) teacher/usage_max 0.5151 (0.5725) teacher/usage_min 0.0000 (0.0127) teacher/usage_std 0.2360 (0.2408) nleep/row_max_mean 1507.5375 (1497.3532) nleep/row_max_std 30.4652 (63.0496) nleep/row_min_mean 1479.5027 (1468.5877) lr 7.5131e-04 eta 0:06:33
epoch [31/50] batch [160/160] time 0.087 (0.124) data 0.000 (0.002) loss 1.2904 (1.3913) teacher_loss 0.0393 (0.1176) loss_zs_kd 0.0896 (0.0715) loss_oracle 0.6235 (0.6459) kd_loss 0.8946 (0.9150) acc 100.0000 (96.9922) gate/entropy 1.0655 (1.0664) gate/usage_max 0.4276 (0.4254) gate/usage_min 0.2235 (0.2245) gate/usage_std 0.0840 (0.0829) teacher/entropy 0.0261 (0.0353) teacher/usage_max 0.6487 (0.5723) teacher/usage_min 0.0016 (0.0134) teacher/usage_std 0.2644 (0.2402) nleep/row_max_mean 1500.1873 (1497.3669) nleep/row_max_std 49.4541 (62.4828) nleep/row_min_mean 1472.5774 (1468.7256) lr 6.9098e-04 eta 0:06:17
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,832
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,961
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.6%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [32/50] batch [20/160] time 0.129 (0.136) data 0.000 (0.015) loss 1.2809 (1.3546) teacher_loss 0.0669 (0.1087) loss_zs_kd 0.0540 (0.0653) loss_oracle 0.5639 (0.6291) kd_loss 0.9051 (0.8987) acc 96.8750 (97.1875) gate/entropy 1.0653 (1.0653) gate/usage_max 0.4280 (0.4279) gate/usage_min 0.2232 (0.2231) gate/usage_std 0.0843 (0.0844) teacher/entropy 0.0301 (0.0465) teacher/usage_max 0.5700 (0.5767) teacher/usage_min 0.0009 (0.0136) teacher/usage_std 0.2420 (0.2403) nleep/row_max_mean 1479.9280 (1495.1329) nleep/row_max_std 80.5875 (66.9464) nleep/row_min_mean 1453.5671 (1467.4841) lr 6.9098e-04 eta 0:06:49
epoch [32/50] batch [40/160] time 0.117 (0.129) data 0.000 (0.008) loss 1.4744 (1.3946) teacher_loss 0.2345 (0.1413) loss_zs_kd 0.0599 (0.0637) loss_oracle 0.5953 (0.6310) kd_loss 0.9123 (0.9060) acc 90.6250 (95.9375) gate/entropy 1.0650 (1.0652) gate/usage_max 0.4285 (0.4281) gate/usage_min 0.2228 (0.2230) gate/usage_std 0.0847 (0.0845) teacher/entropy 0.0319 (0.0419) teacher/usage_max 0.5523 (0.5778) teacher/usage_min 0.0127 (0.0147) teacher/usage_std 0.2317 (0.2394) nleep/row_max_mean 1479.5032 (1495.6284) nleep/row_max_std 82.5971 (64.3512) nleep/row_min_mean 1452.7739 (1467.7274) lr 6.9098e-04 eta 0:06:26
epoch [32/50] batch [60/160] time 0.126 (0.131) data 0.000 (0.005) loss 1.2763 (1.3935) teacher_loss 0.0336 (0.1390) loss_zs_kd 0.0534 (0.0658) loss_oracle 0.6055 (0.6359) kd_loss 0.9132 (0.9036) acc 100.0000 (96.0938) gate/entropy 1.0647 (1.0651) gate/usage_max 0.4293 (0.4284) gate/usage_min 0.2224 (0.2228) gate/usage_std 0.0851 (0.0846) teacher/entropy 0.0276 (0.0434) teacher/usage_max 0.5402 (0.5763) teacher/usage_min 0.0006 (0.0140) teacher/usage_std 0.2376 (0.2401) nleep/row_max_mean 1507.6016 (1496.4578) nleep/row_max_std 57.3409 (63.5762) nleep/row_min_mean 1476.7946 (1468.6755) lr 6.9098e-04 eta 0:06:30
epoch [32/50] batch [80/160] time 0.123 (0.130) data 0.000 (0.004) loss 1.3703 (1.3787) teacher_loss 0.1296 (0.1232) loss_zs_kd 0.0657 (0.0675) loss_oracle 0.5946 (0.6378) kd_loss 0.9106 (0.9028) acc 96.8750 (96.5625) gate/entropy 1.0645 (1.0649) gate/usage_max 0.4296 (0.4287) gate/usage_min 0.2221 (0.2227) gate/usage_std 0.0854 (0.0848) teacher/entropy 0.0511 (0.0448) teacher/usage_max 0.4987 (0.5753) teacher/usage_min 0.0210 (0.0152) teacher/usage_std 0.2210 (0.2391) nleep/row_max_mean 1508.3848 (1498.0807) nleep/row_max_std 33.5149 (60.1195) nleep/row_min_mean 1480.0818 (1470.2013) lr 6.9098e-04 eta 0:06:24
epoch [32/50] batch [100/160] time 0.133 (0.130) data 0.000 (0.003) loss 1.3254 (1.3772) teacher_loss 0.1046 (0.1242) loss_zs_kd 0.0656 (0.0674) loss_oracle 0.6071 (0.6322) kd_loss 0.8845 (0.9032) acc 100.0000 (96.5000) gate/entropy 1.0643 (1.0648) gate/usage_max 0.4301 (0.4289) gate/usage_min 0.2220 (0.2225) gate/usage_std 0.0856 (0.0849) teacher/entropy 0.0634 (0.0442) teacher/usage_max 0.5938 (0.5760) teacher/usage_min 0.0426 (0.0152) teacher/usage_std 0.2261 (0.2391) nleep/row_max_mean 1503.5684 (1497.7752) nleep/row_max_std 45.4842 (60.7540) nleep/row_min_mean 1474.7058 (1469.9524) lr 6.9098e-04 eta 0:06:22
epoch [32/50] batch [120/160] time 0.119 (0.131) data 0.000 (0.003) loss 1.4200 (1.3767) teacher_loss 0.1588 (0.1244) loss_zs_kd 0.0777 (0.0676) loss_oracle 0.6057 (0.6301) kd_loss 0.9195 (0.9035) acc 96.8750 (96.5365) gate/entropy 1.0640 (1.0647) gate/usage_max 0.4305 (0.4292) gate/usage_min 0.2216 (0.2224) gate/usage_std 0.0859 (0.0851) teacher/entropy 0.0305 (0.0439) teacher/usage_max 0.5643 (0.5725) teacher/usage_min 0.0343 (0.0152) teacher/usage_std 0.2217 (0.2381) nleep/row_max_mean 1505.1401 (1497.7656) nleep/row_max_std 59.2759 (61.0991) nleep/row_min_mean 1476.8469 (1469.8793) lr 6.9098e-04 eta 0:06:22
epoch [32/50] batch [140/160] time 0.112 (0.131) data 0.000 (0.002) loss 1.3633 (1.3738) teacher_loss 0.0659 (0.1202) loss_zs_kd 0.0684 (0.0675) loss_oracle 0.6835 (0.6305) kd_loss 0.9214 (0.9047) acc 100.0000 (96.7188) gate/entropy 1.0641 (1.0646) gate/usage_max 0.4307 (0.4294) gate/usage_min 0.2217 (0.2223) gate/usage_std 0.0859 (0.0852) teacher/entropy 0.0222 (0.0435) teacher/usage_max 0.5701 (0.5689) teacher/usage_min 0.0237 (0.0153) teacher/usage_std 0.2290 (0.2369) nleep/row_max_mean 1493.8440 (1497.2143) nleep/row_max_std 58.8109 (61.4508) nleep/row_min_mean 1464.5602 (1469.4644) lr 6.9098e-04 eta 0:06:21
epoch [32/50] batch [160/160] time 0.146 (0.132) data 0.000 (0.002) loss 1.3423 (1.3752) teacher_loss 0.0996 (0.1213) loss_zs_kd 0.0880 (0.0681) loss_oracle 0.6493 (0.6298) kd_loss 0.8741 (0.9049) acc 100.0000 (96.6602) gate/entropy 1.0636 (1.0645) gate/usage_max 0.4315 (0.4296) gate/usage_min 0.2210 (0.2221) gate/usage_std 0.0865 (0.0854) teacher/entropy 0.0865 (0.0429) teacher/usage_max 0.5041 (0.5703) teacher/usage_min 0.0298 (0.0155) teacher/usage_std 0.2152 (0.2372) nleep/row_max_mean 1495.9321 (1497.1972) nleep/row_max_std 65.7347 (61.2983) nleep/row_min_mean 1469.7395 (1469.4082) lr 6.3188e-04 eta 0:06:19
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,824
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,948
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.5%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [33/50] batch [20/160] time 0.151 (0.130) data 0.000 (0.021) loss 1.2644 (1.3508) teacher_loss 0.0476 (0.1037) loss_zs_kd 0.0652 (0.0737) loss_oracle 0.6340 (0.6220) kd_loss 0.8672 (0.8992) acc 100.0000 (97.5000) gate/entropy 1.0635 (1.0635) gate/usage_max 0.4318 (0.4317) gate/usage_min 0.2209 (0.2209) gate/usage_std 0.0866 (0.0866) teacher/entropy 0.0444 (0.0451) teacher/usage_max 0.6827 (0.5910) teacher/usage_min 0.0069 (0.0188) teacher/usage_std 0.2764 (0.2431) nleep/row_max_mean 1497.4973 (1498.9452) nleep/row_max_std 60.9198 (58.2672) nleep/row_min_mean 1471.1025 (1470.8467) lr 6.3188e-04 eta 0:06:13
epoch [33/50] batch [40/160] time 0.079 (0.121) data 0.000 (0.011) loss 1.3688 (1.3491) teacher_loss 0.1329 (0.1134) loss_zs_kd 0.0601 (0.0683) loss_oracle 0.5604 (0.6033) kd_loss 0.9257 (0.8998) acc 93.7500 (96.7969) gate/entropy 1.0632 (1.0634) gate/usage_max 0.4323 (0.4320) gate/usage_min 0.2206 (0.2207) gate/usage_std 0.0870 (0.0868) teacher/entropy 0.0342 (0.0441) teacher/usage_max 0.4996 (0.5768) teacher/usage_min 0.0276 (0.0157) teacher/usage_std 0.2165 (0.2403) nleep/row_max_mean 1508.4652 (1498.4653) nleep/row_max_std 27.9540 (60.9351) nleep/row_min_mean 1480.5889 (1470.7140) lr 6.3188e-04 eta 0:05:44
epoch [33/50] batch [60/160] time 0.093 (0.118) data 0.001 (0.007) loss 1.4303 (1.3667) teacher_loss 0.1180 (0.1241) loss_zs_kd 0.0832 (0.0665) loss_oracle 0.7066 (0.6162) kd_loss 0.9174 (0.9012) acc 96.8750 (96.6146) gate/entropy 1.0629 (1.0633) gate/usage_max 0.4328 (0.4322) gate/usage_min 0.2201 (0.2206) gate/usage_std 0.0874 (0.0869) teacher/entropy 0.0380 (0.0441) teacher/usage_max 0.5053 (0.5732) teacher/usage_min 0.0215 (0.0168) teacher/usage_std 0.2209 (0.2384) nleep/row_max_mean 1511.5554 (1498.8705) nleep/row_max_std 24.0994 (59.7634) nleep/row_min_mean 1480.7437 (1470.9904) lr 6.3188e-04 eta 0:05:33
epoch [33/50] batch [80/160] time 0.092 (0.113) data 0.000 (0.005) loss 1.4339 (1.3596) teacher_loss 0.1620 (0.1174) loss_zs_kd 0.0684 (0.0658) loss_oracle 0.6391 (0.6149) kd_loss 0.9182 (0.9018) acc 96.8750 (96.9141) gate/entropy 1.0627 (1.0631) gate/usage_max 0.4335 (0.4324) gate/usage_min 0.2200 (0.2205) gate/usage_std 0.0876 (0.0871) teacher/entropy 0.0006 (0.0443) teacher/usage_max 0.6250 (0.5662) teacher/usage_min 0.0000 (0.0165) teacher/usage_std 0.2568 (0.2366) nleep/row_max_mean 1513.5557 (1498.6840) nleep/row_max_std 27.6710 (59.8648) nleep/row_min_mean 1482.2170 (1470.8971) lr 6.3188e-04 eta 0:05:16
epoch [33/50] batch [100/160] time 0.161 (0.112) data 0.000 (0.004) loss 1.3778 (1.3614) teacher_loss 0.1709 (0.1184) loss_zs_kd 0.0652 (0.0661) loss_oracle 0.5911 (0.6121) kd_loss 0.8787 (0.9039) acc 93.7500 (96.8750) gate/entropy 1.0625 (1.0630) gate/usage_max 0.4337 (0.4327) gate/usage_min 0.2196 (0.2203) gate/usage_std 0.0879 (0.0872) teacher/entropy 0.0279 (0.0426) teacher/usage_max 0.6828 (0.5634) teacher/usage_min 0.0023 (0.0166) teacher/usage_std 0.2781 (0.2356) nleep/row_max_mean 1498.2559 (1498.7450) nleep/row_max_std 81.2517 (60.1049) nleep/row_min_mean 1469.4312 (1470.9393) lr 6.3188e-04 eta 0:05:10
epoch [33/50] batch [120/160] time 0.091 (0.111) data 0.000 (0.004) loss 1.3646 (1.3607) teacher_loss 0.1001 (0.1176) loss_zs_kd 0.0988 (0.0671) loss_oracle 0.5936 (0.6090) kd_loss 0.9183 (0.9051) acc 96.8750 (96.9531) gate/entropy 1.0624 (1.0629) gate/usage_max 0.4338 (0.4329) gate/usage_min 0.2195 (0.2202) gate/usage_std 0.0880 (0.0874) teacher/entropy 0.0070 (0.0408) teacher/usage_max 0.5937 (0.5616) teacher/usage_min 0.0000 (0.0160) teacher/usage_std 0.2478 (0.2357) nleep/row_max_mean 1499.8557 (1498.8278) nleep/row_max_std 33.2456 (59.0899) nleep/row_min_mean 1469.8022 (1471.0155) lr 6.3188e-04 eta 0:05:07
epoch [33/50] batch [140/160] time 0.086 (0.112) data 0.000 (0.003) loss 1.5235 (1.3617) teacher_loss 0.2277 (0.1180) loss_zs_kd 0.0592 (0.0673) loss_oracle 0.6744 (0.6102) kd_loss 0.9290 (0.9050) acc 93.7500 (96.8973) gate/entropy 1.0621 (1.0628) gate/usage_max 0.4344 (0.4331) gate/usage_min 0.2191 (0.2201) gate/usage_std 0.0884 (0.0875) teacher/entropy 0.0409 (0.0405) teacher/usage_max 0.5154 (0.5610) teacher/usage_min 0.0308 (0.0158) teacher/usage_std 0.2154 (0.2356) nleep/row_max_mean 1484.9871 (1498.2244) nleep/row_max_std 94.6300 (60.1630) nleep/row_min_mean 1456.7266 (1470.3564) lr 6.3188e-04 eta 0:05:05
epoch [33/50] batch [160/160] time 0.071 (0.111) data 0.000 (0.003) loss 1.2612 (1.3594) teacher_loss 0.0394 (0.1165) loss_zs_kd 0.0539 (0.0674) loss_oracle 0.6440 (0.6091) kd_loss 0.8729 (0.9046) acc 100.0000 (96.9141) gate/entropy 1.0619 (1.0627) gate/usage_max 0.4347 (0.4333) gate/usage_min 0.2188 (0.2199) gate/usage_std 0.0886 (0.0876) teacher/entropy 0.0652 (0.0413) teacher/usage_max 0.5770 (0.5618) teacher/usage_min 0.0230 (0.0154) teacher/usage_std 0.2310 (0.2358) nleep/row_max_mean 1492.8108 (1497.2260) nleep/row_max_std 76.1116 (61.7332) nleep/row_min_mean 1464.8843 (1469.3168) lr 5.7422e-04 eta 0:05:02
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,812
* accuracy: 82.1%
* error: 17.9%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,933
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.1%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [34/50] batch [20/160] time 0.148 (0.167) data 0.000 (0.020) loss 1.3334 (1.3288) teacher_loss 0.1123 (0.0881) loss_zs_kd 0.0662 (0.0660) loss_oracle 0.5145 (0.5860) kd_loss 0.9308 (0.9147) acc 93.7500 (97.5000) gate/entropy 1.0617 (1.0618) gate/usage_max 0.4349 (0.4349) gate/usage_min 0.2185 (0.2187) gate/usage_std 0.0889 (0.0887) teacher/entropy 0.0309 (0.0366) teacher/usage_max 0.5676 (0.5909) teacher/usage_min 0.0018 (0.0141) teacher/usage_std 0.2410 (0.2436) nleep/row_max_mean 1486.2798 (1495.1777) nleep/row_max_std 85.4222 (61.7153) nleep/row_min_mean 1459.1699 (1466.8386) lr 5.7422e-04 eta 0:07:30
epoch [34/50] batch [40/160] time 0.142 (0.154) data 0.000 (0.010) loss 1.3536 (1.3511) teacher_loss 0.0872 (0.1078) loss_zs_kd 0.0714 (0.0690) loss_oracle 0.6473 (0.5972) kd_loss 0.9070 (0.9103) acc 96.8750 (96.8750) gate/entropy 1.0615 (1.0617) gate/usage_max 0.4354 (0.4350) gate/usage_min 0.2183 (0.2186) gate/usage_std 0.0891 (0.0888) teacher/entropy 0.0094 (0.0357) teacher/usage_max 0.6229 (0.5739) teacher/usage_min 0.0005 (0.0136) teacher/usage_std 0.2560 (0.2396) nleep/row_max_mean 1504.5850 (1496.9125) nleep/row_max_std 62.7242 (57.6344) nleep/row_min_mean 1474.5742 (1468.3731) lr 5.7422e-04 eta 0:06:52
epoch [34/50] batch [60/160] time 0.154 (0.149) data 0.001 (0.007) loss 1.4724 (1.3739) teacher_loss 0.2041 (0.1280) loss_zs_kd 0.0650 (0.0695) loss_oracle 0.6126 (0.6051) kd_loss 0.9295 (0.9086) acc 93.7500 (96.2500) gate/entropy 1.0614 (1.0616) gate/usage_max 0.4355 (0.4351) gate/usage_min 0.2181 (0.2185) gate/usage_std 0.0892 (0.0889) teacher/entropy 0.0169 (0.0388) teacher/usage_max 0.4988 (0.5660) teacher/usage_min 0.0028 (0.0146) teacher/usage_std 0.2338 (0.2367) nleep/row_max_mean 1487.7560 (1495.6674) nleep/row_max_std 71.6357 (59.1464) nleep/row_min_mean 1460.3851 (1467.1798) lr 5.7422e-04 eta 0:06:36
epoch [34/50] batch [80/160] time 0.136 (0.144) data 0.000 (0.005) loss 1.3294 (1.3683) teacher_loss 0.0814 (0.1256) loss_zs_kd 0.0734 (0.0689) loss_oracle 0.6095 (0.5987) kd_loss 0.9065 (0.9089) acc 100.0000 (96.4453) gate/entropy 1.0613 (1.0615) gate/usage_max 0.4355 (0.4352) gate/usage_min 0.2181 (0.2184) gate/usage_std 0.0893 (0.0890) teacher/entropy 0.0310 (0.0377) teacher/usage_max 0.5522 (0.5675) teacher/usage_min 0.0103 (0.0139) teacher/usage_std 0.2331 (0.2377) nleep/row_max_mean 1480.9734 (1496.4504) nleep/row_max_std 74.3878 (59.4174) nleep/row_min_mean 1452.4125 (1467.8390) lr 5.7422e-04 eta 0:06:21
epoch [34/50] batch [100/160] time 0.118 (0.142) data 0.000 (0.004) loss 1.2638 (1.3656) teacher_loss 0.0386 (0.1247) loss_zs_kd 0.0673 (0.0697) loss_oracle 0.5496 (0.5974) kd_loss 0.9166 (0.9074) acc 100.0000 (96.4375) gate/entropy 1.0608 (1.0615) gate/usage_max 0.4364 (0.4354) gate/usage_min 0.2173 (0.2182) gate/usage_std 0.0899 (0.0891) teacher/entropy 0.0050 (0.0380) teacher/usage_max 0.5944 (0.5688) teacher/usage_min 0.0002 (0.0136) teacher/usage_std 0.2479 (0.2382) nleep/row_max_mean 1521.8860 (1496.6938) nleep/row_max_std 42.1748 (59.9848) nleep/row_min_mean 1489.7832 (1468.0070) lr 5.7422e-04 eta 0:06:12
epoch [34/50] batch [120/160] time 0.153 (0.142) data 0.000 (0.004) loss 1.3272 (1.3655) teacher_loss 0.0448 (0.1244) loss_zs_kd 0.0811 (0.0689) loss_oracle 0.5410 (0.5953) kd_loss 0.9713 (0.9090) acc 100.0000 (96.4583) gate/entropy 1.0607 (1.0614) gate/usage_max 0.4364 (0.4355) gate/usage_min 0.2171 (0.2181) gate/usage_std 0.0900 (0.0892) teacher/entropy 0.0085 (0.0375) teacher/usage_max 0.6547 (0.5673) teacher/usage_min 0.0004 (0.0132) teacher/usage_std 0.2672 (0.2381) nleep/row_max_mean 1512.7136 (1497.0501) nleep/row_max_std 42.7154 (59.7678) nleep/row_min_mean 1485.7720 (1468.4489) lr 5.7422e-04 eta 0:06:08
epoch [34/50] batch [140/160] time 0.089 (0.136) data 0.000 (0.003) loss 1.4809 (1.3610) teacher_loss 0.2014 (0.1177) loss_zs_kd 0.0762 (0.0683) loss_oracle 0.6294 (0.5948) kd_loss 0.9267 (0.9117) acc 90.6250 (96.6964) gate/entropy 1.0605 (1.0613) gate/usage_max 0.4368 (0.4357) gate/usage_min 0.2169 (0.2180) gate/usage_std 0.0902 (0.0894) teacher/entropy 0.0023 (0.0353) teacher/usage_max 0.5625 (0.5675) teacher/usage_min 0.0000 (0.0128) teacher/usage_std 0.2411 (0.2384) nleep/row_max_mean 1509.4526 (1497.6874) nleep/row_max_std 39.9692 (59.1794) nleep/row_min_mean 1479.0468 (1468.8669) lr 5.7422e-04 eta 0:05:50
epoch [34/50] batch [160/160] time 0.071 (0.131) data 0.000 (0.003) loss 1.4574 (1.3591) teacher_loss 0.1960 (0.1150) loss_zs_kd 0.0465 (0.0683) loss_oracle 0.6085 (0.5965) kd_loss 0.9339 (0.9117) acc 96.8750 (96.8359) gate/entropy 1.0605 (1.0612) gate/usage_max 0.4366 (0.4358) gate/usage_min 0.2168 (0.2178) gate/usage_std 0.0902 (0.0895) teacher/entropy 0.0109 (0.0353) teacher/usage_max 0.5001 (0.5672) teacher/usage_min 0.0031 (0.0138) teacher/usage_std 0.2335 (0.2377) nleep/row_max_mean 1491.7096 (1497.8298) nleep/row_max_std 72.5174 (59.3999) nleep/row_min_mean 1463.6775 (1468.9557) lr 5.1825e-04 eta 0:05:34
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,799
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,904
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 87.5%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [35/50] batch [20/160] time 0.099 (0.115) data 0.000 (0.014) loss 1.2670 (1.3881) teacher_loss 0.0311 (0.1400) loss_zs_kd 0.0537 (0.0641) loss_oracle 0.6059 (0.5943) kd_loss 0.9062 (0.9189) acc 100.0000 (96.4062) gate/entropy 1.0603 (1.0604) gate/usage_max 0.4368 (0.4368) gate/usage_min 0.2165 (0.2166) gate/usage_std 0.0904 (0.0904) teacher/entropy 0.0327 (0.0297) teacher/usage_max 0.5666 (0.5560) teacher/usage_min 0.0247 (0.0181) teacher/usage_std 0.2276 (0.2318) nleep/row_max_mean 1494.3622 (1499.1342) nleep/row_max_std 73.1910 (59.5199) nleep/row_min_mean 1466.9250 (1469.9114) lr 5.1825e-04 eta 0:04:52
epoch [35/50] batch [40/160] time 0.095 (0.110) data 0.000 (0.007) loss 1.3041 (1.3730) teacher_loss 0.0503 (0.1213) loss_zs_kd 0.0511 (0.0637) loss_oracle 0.5705 (0.5915) kd_loss 0.9430 (0.9242) acc 100.0000 (96.7969) gate/entropy 1.0601 (1.0603) gate/usage_max 0.4370 (0.4369) gate/usage_min 0.2162 (0.2165) gate/usage_std 0.0907 (0.0905) teacher/entropy 0.0233 (0.0301) teacher/usage_max 0.5622 (0.5634) teacher/usage_min 0.0138 (0.0137) teacher/usage_std 0.2329 (0.2366) nleep/row_max_mean 1500.4075 (1498.7578) nleep/row_max_std 73.9526 (61.7562) nleep/row_min_mean 1469.2246 (1469.2450) lr 5.1825e-04 eta 0:04:38
epoch [35/50] batch [60/160] time 0.154 (0.122) data 0.001 (0.005) loss 1.4170 (1.3641) teacher_loss 0.1177 (0.1150) loss_zs_kd 0.0616 (0.0635) loss_oracle 0.6486 (0.5907) kd_loss 0.9442 (0.9221) acc 96.8750 (96.9792) gate/entropy 1.0599 (1.0602) gate/usage_max 0.4374 (0.4369) gate/usage_min 0.2158 (0.2164) gate/usage_std 0.0910 (0.0906) teacher/entropy 0.0044 (0.0317) teacher/usage_max 0.5304 (0.5575) teacher/usage_min 0.0000 (0.0138) teacher/usage_std 0.2370 (0.2350) nleep/row_max_mean 1521.6343 (1499.8375) nleep/row_max_std 25.5564 (59.4414) nleep/row_min_mean 1487.1128 (1470.4188) lr 5.1825e-04 eta 0:05:04
epoch [35/50] batch [80/160] time 0.081 (0.120) data 0.000 (0.004) loss 1.4812 (1.3748) teacher_loss 0.2305 (0.1239) loss_zs_kd 0.0896 (0.0654) loss_oracle 0.5644 (0.5908) kd_loss 0.9236 (0.9229) acc 93.7500 (96.6797) gate/entropy 1.0598 (1.0601) gate/usage_max 0.4371 (0.4370) gate/usage_min 0.2156 (0.2162) gate/usage_std 0.0910 (0.0906) teacher/entropy 0.0039 (0.0322) teacher/usage_max 0.5626 (0.5545) teacher/usage_min 0.0003 (0.0151) teacher/usage_std 0.2410 (0.2339) nleep/row_max_mean 1508.3727 (1498.6769) nleep/row_max_std 42.3352 (60.8705) nleep/row_min_mean 1478.9807 (1469.3940) lr 5.1825e-04 eta 0:04:56
epoch [35/50] batch [100/160] time 0.104 (0.117) data 0.000 (0.003) loss 1.3157 (1.3720) teacher_loss 0.1348 (0.1208) loss_zs_kd 0.0468 (0.0658) loss_oracle 0.5861 (0.5895) kd_loss 0.8645 (0.9236) acc 96.8750 (96.7812) gate/entropy 1.0596 (1.0601) gate/usage_max 0.4375 (0.4370) gate/usage_min 0.2154 (0.2161) gate/usage_std 0.0912 (0.0907) teacher/entropy 0.0620 (0.0314) teacher/usage_max 0.5960 (0.5558) teacher/usage_min 0.0151 (0.0161) teacher/usage_std 0.2404 (0.2338) nleep/row_max_mean 1488.6932 (1498.4561) nleep/row_max_std 88.7202 (59.9014) nleep/row_min_mean 1461.6069 (1469.1782) lr 5.1825e-04 eta 0:04:48
epoch [35/50] batch [120/160] time 0.143 (0.121) data 0.000 (0.003) loss 1.3886 (1.3796) teacher_loss 0.1063 (0.1260) loss_zs_kd 0.0723 (0.0674) loss_oracle 0.5985 (0.5901) kd_loss 0.9468 (0.9248) acc 93.7500 (96.4062) gate/entropy 1.0595 (1.0600) gate/usage_max 0.4374 (0.4370) gate/usage_min 0.2151 (0.2160) gate/usage_std 0.0913 (0.0908) teacher/entropy 0.0011 (0.0302) teacher/usage_max 0.5314 (0.5585) teacher/usage_min 0.0000 (0.0159) teacher/usage_std 0.2371 (0.2345) nleep/row_max_mean 1509.1763 (1498.1801) nleep/row_max_std 39.3801 (59.3540) nleep/row_min_mean 1477.0642 (1468.9363) lr 5.1825e-04 eta 0:04:54
epoch [35/50] batch [140/160] time 0.140 (0.123) data 0.000 (0.002) loss 1.4453 (1.3808) teacher_loss 0.2115 (0.1265) loss_zs_kd 0.0631 (0.0666) loss_oracle 0.5953 (0.5944) kd_loss 0.9047 (0.9238) acc 96.8750 (96.3839) gate/entropy 1.0597 (1.0600) gate/usage_max 0.4371 (0.4371) gate/usage_min 0.2153 (0.2159) gate/usage_std 0.0911 (0.0908) teacher/entropy 0.0437 (0.0314) teacher/usage_max 0.5171 (0.5571) teacher/usage_min 0.0227 (0.0159) teacher/usage_std 0.2209 (0.2340) nleep/row_max_mean 1486.3173 (1498.0552) nleep/row_max_std 72.7999 (59.0455) nleep/row_min_mean 1457.1262 (1468.8133) lr 5.1825e-04 eta 0:04:56
epoch [35/50] batch [160/160] time 0.152 (0.126) data 0.000 (0.002) loss 1.3908 (1.3812) teacher_loss 0.0789 (0.1241) loss_zs_kd 0.0632 (0.0675) loss_oracle 0.6630 (0.5985) kd_loss 0.9488 (0.9240) acc 100.0000 (96.4258) gate/entropy 1.0595 (1.0599) gate/usage_max 0.4370 (0.4371) gate/usage_min 0.2148 (0.2157) gate/usage_std 0.0913 (0.0909) teacher/entropy 0.0531 (0.0319) teacher/usage_max 0.5190 (0.5588) teacher/usage_min 0.0806 (0.0164) teacher/usage_std 0.1852 (0.2340) nleep/row_max_mean 1486.2443 (1498.3519) nleep/row_max_std 73.5823 (58.3526) nleep/row_min_mean 1459.7363 (1469.2095) lr 4.6417e-04 eta 0:05:01
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,788
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,884
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 87.3%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [36/50] batch [20/160] time 0.122 (0.151) data 0.000 (0.017) loss 1.3917 (1.3936) teacher_loss 0.0884 (0.1237) loss_zs_kd 0.0783 (0.0646) loss_oracle 0.7017 (0.6266) kd_loss 0.9132 (0.9242) acc 96.8750 (97.0312) gate/entropy 1.0592 (1.0594) gate/usage_max 0.4372 (0.4371) gate/usage_min 0.2144 (0.2147) gate/usage_std 0.0916 (0.0914) teacher/entropy 0.0637 (0.0317) teacher/usage_max 0.5812 (0.5755) teacher/usage_min 0.0262 (0.0092) teacher/usage_std 0.2304 (0.2406) nleep/row_max_mean 1482.3589 (1496.3898) nleep/row_max_std 83.0160 (58.8444) nleep/row_min_mean 1454.6348 (1468.0335) lr 4.6417e-04 eta 0:05:59
epoch [36/50] batch [40/160] time 0.130 (0.145) data 0.000 (0.008) loss 1.4739 (1.3871) teacher_loss 0.2611 (0.1368) loss_zs_kd 0.0617 (0.0664) loss_oracle 0.5601 (0.6065) kd_loss 0.9019 (0.9139) acc 96.8750 (96.5625) gate/entropy 1.0592 (1.0593) gate/usage_max 0.4371 (0.4371) gate/usage_min 0.2143 (0.2145) gate/usage_std 0.0916 (0.0915) teacher/entropy 0.0469 (0.0381) teacher/usage_max 0.5030 (0.5612) teacher/usage_min 0.0205 (0.0114) teacher/usage_std 0.2215 (0.2363) nleep/row_max_mean 1481.2739 (1496.7531) nleep/row_max_std 80.8129 (59.5560) nleep/row_min_mean 1458.5455 (1468.2331) lr 4.6417e-04 eta 0:05:42
epoch [36/50] batch [60/160] time 0.094 (0.140) data 0.000 (0.006) loss 1.3418 (1.3794) teacher_loss 0.0322 (0.1312) loss_zs_kd 0.0575 (0.0639) loss_oracle 0.6629 (0.6045) kd_loss 0.9494 (0.9141) acc 100.0000 (96.5625) gate/entropy 1.0590 (1.0593) gate/usage_max 0.4372 (0.4371) gate/usage_min 0.2140 (0.2144) gate/usage_std 0.0918 (0.0915) teacher/entropy 0.0122 (0.0371) teacher/usage_max 0.5913 (0.5625) teacher/usage_min 0.0023 (0.0135) teacher/usage_std 0.2459 (0.2361) nleep/row_max_mean 1479.2515 (1496.7485) nleep/row_max_std 80.5589 (58.3349) nleep/row_min_mean 1453.5496 (1468.3150) lr 4.6417e-04 eta 0:05:27
epoch [36/50] batch [80/160] time 0.085 (0.134) data 0.000 (0.004) loss 1.2826 (1.3789) teacher_loss 0.0251 (0.1288) loss_zs_kd 0.0657 (0.0652) loss_oracle 0.6128 (0.6016) kd_loss 0.9183 (0.9167) acc 100.0000 (96.4062) gate/entropy 1.0590 (1.0592) gate/usage_max 0.4373 (0.4372) gate/usage_min 0.2140 (0.2144) gate/usage_std 0.0918 (0.0916) teacher/entropy 0.0219 (0.0368) teacher/usage_max 0.5009 (0.5613) teacher/usage_min 0.0010 (0.0152) teacher/usage_std 0.2350 (0.2348) nleep/row_max_mean 1497.2627 (1495.8679) nleep/row_max_std 68.6559 (59.8784) nleep/row_min_mean 1467.9661 (1467.4335) lr 4.6417e-04 eta 0:05:11
epoch [36/50] batch [100/160] time 0.093 (0.130) data 0.000 (0.003) loss 1.4326 (1.3816) teacher_loss 0.1949 (0.1314) loss_zs_kd 0.0604 (0.0653) loss_oracle 0.6138 (0.5989) kd_loss 0.9006 (0.9181) acc 93.7500 (96.3125) gate/entropy 1.0588 (1.0592) gate/usage_max 0.4373 (0.4372) gate/usage_min 0.2136 (0.2143) gate/usage_std 0.0920 (0.0916) teacher/entropy 0.0443 (0.0362) teacher/usage_max 0.4969 (0.5617) teacher/usage_min 0.0115 (0.0156) teacher/usage_std 0.2276 (0.2349) nleep/row_max_mean 1496.1266 (1496.1116) nleep/row_max_std 74.9228 (60.2592) nleep/row_min_mean 1469.7117 (1467.7609) lr 4.6417e-04 eta 0:04:58
epoch [36/50] batch [120/160] time 0.147 (0.128) data 0.000 (0.003) loss 1.2883 (1.3758) teacher_loss 0.0238 (0.1277) loss_zs_kd 0.0596 (0.0659) loss_oracle 0.5634 (0.5960) kd_loss 0.9530 (0.9171) acc 100.0000 (96.3542) gate/entropy 1.0587 (1.0591) gate/usage_max 0.4373 (0.4372) gate/usage_min 0.2134 (0.2141) gate/usage_std 0.0921 (0.0917) teacher/entropy 0.0060 (0.0372) teacher/usage_max 0.5930 (0.5604) teacher/usage_min 0.0000 (0.0176) teacher/usage_std 0.2476 (0.2337) nleep/row_max_mean 1511.3099 (1496.6403) nleep/row_max_std 40.0716 (60.7751) nleep/row_min_mean 1479.8433 (1468.1421) lr 4.6417e-04 eta 0:04:51
epoch [36/50] batch [140/160] time 0.091 (0.125) data 0.000 (0.003) loss 1.3275 (1.3690) teacher_loss 0.0383 (0.1225) loss_zs_kd 0.0900 (0.0660) loss_oracle 0.5258 (0.5947) kd_loss 0.9813 (0.9161) acc 100.0000 (96.5848) gate/entropy 1.0588 (1.0591) gate/usage_max 0.4372 (0.4372) gate/usage_min 0.2134 (0.2141) gate/usage_std 0.0920 (0.0917) teacher/entropy 0.0197 (0.0382) teacher/usage_max 0.6851 (0.5628) teacher/usage_min 0.0288 (0.0187) teacher/usage_std 0.2700 (0.2337) nleep/row_max_mean 1507.1071 (1496.8526) nleep/row_max_std 47.5261 (60.9354) nleep/row_min_mean 1476.4894 (1468.3106) lr 4.6417e-04 eta 0:04:42
epoch [36/50] batch [160/160] time 0.063 (0.122) data 0.000 (0.002) loss 1.3463 (1.3643) teacher_loss 0.1143 (0.1169) loss_zs_kd 0.0679 (0.0670) loss_oracle 0.5677 (0.5922) kd_loss 0.9141 (0.9178) acc 96.8750 (96.7383) gate/entropy 1.0586 (1.0590) gate/usage_max 0.4373 (0.4372) gate/usage_min 0.2132 (0.2139) gate/usage_std 0.0922 (0.0918) teacher/entropy 0.0254 (0.0365) teacher/usage_max 0.5623 (0.5643) teacher/usage_min 0.0305 (0.0180) teacher/usage_std 0.2233 (0.2344) nleep/row_max_mean 1510.7354 (1497.6408) nleep/row_max_std 25.6815 (59.7636) nleep/row_min_mean 1478.5488 (1468.9806) lr 4.1221e-04 eta 0:04:32
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,818
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 84.6%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,936
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 88.3%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [37/50] batch [20/160] time 0.115 (0.118) data 0.000 (0.014) loss 1.2562 (1.3510) teacher_loss 0.0481 (0.1138) loss_zs_kd 0.0770 (0.0690) loss_oracle 0.5508 (0.5619) kd_loss 0.8942 (0.9218) acc 100.0000 (97.0312) gate/entropy 1.0583 (1.0585) gate/usage_max 0.4375 (0.4373) gate/usage_min 0.2127 (0.2130) gate/usage_std 0.0925 (0.0923) teacher/entropy 0.0458 (0.0326) teacher/usage_max 0.5279 (0.5606) teacher/usage_min 0.0176 (0.0142) teacher/usage_std 0.2252 (0.2352) nleep/row_max_mean 1511.3757 (1499.6973) nleep/row_max_std 60.5339 (60.2018) nleep/row_min_mean 1481.9470 (1470.4614) lr 4.1221e-04 eta 0:04:22
epoch [37/50] batch [40/160] time 0.137 (0.129) data 0.000 (0.007) loss 1.3297 (1.3431) teacher_loss 0.0320 (0.1025) loss_zs_kd 0.0637 (0.0661) loss_oracle 0.5911 (0.5698) kd_loss 0.9702 (0.9226) acc 100.0000 (97.4219) gate/entropy 1.0586 (1.0585) gate/usage_max 0.4369 (0.4372) gate/usage_min 0.2129 (0.2129) gate/usage_std 0.0922 (0.0923) teacher/entropy 0.0021 (0.0319) teacher/usage_max 0.6563 (0.5602) teacher/usage_min 0.0000 (0.0166) teacher/usage_std 0.2680 (0.2337) nleep/row_max_mean 1498.6038 (1498.7427) nleep/row_max_std 53.4608 (61.9061) nleep/row_min_mean 1469.3650 (1469.6243) lr 4.1221e-04 eta 0:04:42
epoch [37/50] batch [60/160] time 0.150 (0.132) data 0.000 (0.005) loss 1.4750 (1.3430) teacher_loss 0.2299 (0.1030) loss_zs_kd 0.0406 (0.0674) loss_oracle 0.6507 (0.5749) kd_loss 0.8995 (0.9189) acc 93.7500 (97.6562) gate/entropy 1.0586 (1.0584) gate/usage_max 0.4367 (0.4372) gate/usage_min 0.2128 (0.2128) gate/usage_std 0.0922 (0.0924) teacher/entropy 0.0820 (0.0341) teacher/usage_max 0.5953 (0.5555) teacher/usage_min 0.0321 (0.0187) teacher/usage_std 0.2316 (0.2315) nleep/row_max_mean 1497.5916 (1500.0725) nleep/row_max_std 56.3952 (61.3332) nleep/row_min_mean 1469.0256 (1470.9434) lr 4.1221e-04 eta 0:04:46
epoch [37/50] batch [80/160] time 0.156 (0.130) data 0.000 (0.004) loss 1.3323 (1.3457) teacher_loss 0.1097 (0.1046) loss_zs_kd 0.0504 (0.0684) loss_oracle 0.5728 (0.5776) kd_loss 0.9110 (0.9181) acc 96.8750 (97.5391) gate/entropy 1.0583 (1.0584) gate/usage_max 0.4371 (0.4372) gate/usage_min 0.2125 (0.2127) gate/usage_std 0.0925 (0.0924) teacher/entropy 0.0611 (0.0339) teacher/usage_max 0.5192 (0.5583) teacher/usage_min 0.0425 (0.0179) teacher/usage_std 0.2083 (0.2325) nleep/row_max_mean 1487.6611 (1500.2782) nleep/row_max_std 84.4372 (59.5956) nleep/row_min_mean 1457.0355 (1471.3240) lr 4.1221e-04 eta 0:04:41
epoch [37/50] batch [100/160] time 0.121 (0.131) data 0.000 (0.003) loss 1.4879 (1.3469) teacher_loss 0.2842 (0.1013) loss_zs_kd 0.1124 (0.0684) loss_oracle 0.5960 (0.5805) kd_loss 0.8494 (0.9212) acc 87.5000 (97.5000) gate/entropy 1.0583 (1.0584) gate/usage_max 0.4369 (0.4372) gate/usage_min 0.2124 (0.2126) gate/usage_std 0.0925 (0.0924) teacher/entropy 0.0770 (0.0340) teacher/usage_max 0.6823 (0.5608) teacher/usage_min 0.0588 (0.0207) teacher/usage_std 0.2599 (0.2322) nleep/row_max_mean 1501.5098 (1500.2551) nleep/row_max_std 33.3868 (59.8114) nleep/row_min_mean 1474.3199 (1471.3130) lr 4.1221e-04 eta 0:04:40
epoch [37/50] batch [120/160] time 0.142 (0.133) data 0.000 (0.003) loss 1.2875 (1.3556) teacher_loss 0.0267 (0.1076) loss_zs_kd 0.0899 (0.0699) loss_oracle 0.5467 (0.5816) kd_loss 0.9425 (0.9223) acc 100.0000 (97.1615) gate/entropy 1.0581 (1.0583) gate/usage_max 0.4371 (0.4372) gate/usage_min 0.2120 (0.2125) gate/usage_std 0.0927 (0.0925) teacher/entropy 0.0153 (0.0340) teacher/usage_max 0.5919 (0.5601) teacher/usage_min 0.0018 (0.0216) teacher/usage_std 0.2464 (0.2314) nleep/row_max_mean 1515.2966 (1500.3576) nleep/row_max_std 29.5157 (59.0262) nleep/row_min_mean 1484.2538 (1471.4714) lr 4.1221e-04 eta 0:04:42
epoch [37/50] batch [140/160] time 0.132 (0.134) data 0.000 (0.002) loss 1.4030 (1.3553) teacher_loss 0.1368 (0.1054) loss_zs_kd 0.0762 (0.0705) loss_oracle 0.5848 (0.5849) kd_loss 0.9357 (0.9222) acc 93.7500 (97.2545) gate/entropy 1.0581 (1.0583) gate/usage_max 0.4369 (0.4372) gate/usage_min 0.2119 (0.2124) gate/usage_std 0.0927 (0.0925) teacher/entropy 0.0081 (0.0355) teacher/usage_max 0.5324 (0.5584) teacher/usage_min 0.0002 (0.0241) teacher/usage_std 0.2371 (0.2297) nleep/row_max_mean 1495.9004 (1499.7980) nleep/row_max_std 57.7841 (60.0990) nleep/row_min_mean 1465.4062 (1470.9612) lr 4.1221e-04 eta 0:04:41
epoch [37/50] batch [160/160] time 0.120 (0.133) data 0.000 (0.002) loss 1.5906 (1.3657) teacher_loss 0.3006 (0.1137) loss_zs_kd 0.0624 (0.0703) loss_oracle 0.6967 (0.5889) kd_loss 0.9104 (0.9224) acc 90.6250 (96.9727) gate/entropy 1.0578 (1.0582) gate/usage_max 0.4371 (0.4372) gate/usage_min 0.2115 (0.2124) gate/usage_std 0.0930 (0.0926) teacher/entropy 0.0564 (0.0348) teacher/usage_max 0.5183 (0.5598) teacher/usage_min 0.0702 (0.0244) teacher/usage_std 0.1911 (0.2300) nleep/row_max_mean 1489.8306 (1499.4930) nleep/row_max_std 82.2720 (60.7442) nleep/row_min_mean 1461.9583 (1470.6539) lr 3.6258e-04 eta 0:04:35
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,824
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,932
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 88.3%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [38/50] batch [20/160] time 0.135 (0.127) data 0.000 (0.017) loss 1.3428 (1.3658) teacher_loss 0.0787 (0.1022) loss_zs_kd 0.0847 (0.0763) loss_oracle 0.6033 (0.6260) kd_loss 0.9201 (0.9124) acc 100.0000 (97.5000) gate/entropy 1.0580 (1.0579) gate/usage_max 0.4367 (0.4370) gate/usage_min 0.2117 (0.2117) gate/usage_std 0.0928 (0.0929) teacher/entropy 0.0257 (0.0438) teacher/usage_max 0.5436 (0.5525) teacher/usage_min 0.0009 (0.0315) teacher/usage_std 0.2378 (0.2227) nleep/row_max_mean 1505.8225 (1495.2872) nleep/row_max_std 33.6314 (66.6372) nleep/row_min_mean 1478.5125 (1467.0103) lr 3.6258e-04 eta 0:04:22
epoch [38/50] batch [40/160] time 0.081 (0.118) data 0.000 (0.008) loss 1.4235 (1.3786) teacher_loss 0.1393 (0.1206) loss_zs_kd 0.0838 (0.0747) loss_oracle 0.6943 (0.6122) kd_loss 0.8951 (0.9146) acc 93.7500 (96.7188) gate/entropy 1.0579 (1.0579) gate/usage_max 0.4369 (0.4370) gate/usage_min 0.2117 (0.2116) gate/usage_std 0.0928 (0.0929) teacher/entropy 0.0474 (0.0404) teacher/usage_max 0.5485 (0.5570) teacher/usage_min 0.0330 (0.0260) teacher/usage_std 0.2189 (0.2269) nleep/row_max_mean 1498.9556 (1496.0861) nleep/row_max_std 56.0215 (62.9254) nleep/row_min_mean 1466.3201 (1467.4829) lr 3.6258e-04 eta 0:04:01
epoch [38/50] batch [60/160] time 0.102 (0.116) data 0.000 (0.006) loss 1.3555 (1.3640) teacher_loss 0.1025 (0.1133) loss_zs_kd 0.0696 (0.0747) loss_oracle 0.6476 (0.6027) kd_loss 0.8944 (0.9120) acc 96.8750 (96.6667) gate/entropy 1.0577 (1.0578) gate/usage_max 0.4372 (0.4370) gate/usage_min 0.2114 (0.2115) gate/usage_std 0.0931 (0.0929) teacher/entropy 0.0240 (0.0428) teacher/usage_max 0.5798 (0.5530) teacher/usage_min 0.0002 (0.0285) teacher/usage_std 0.2445 (0.2247) nleep/row_max_mean 1507.1851 (1495.2878) nleep/row_max_std 42.7779 (63.5931) nleep/row_min_mean 1475.7166 (1466.6482) lr 3.6258e-04 eta 0:03:53
epoch [38/50] batch [80/160] time 0.081 (0.111) data 0.000 (0.004) loss 1.4716 (1.3583) teacher_loss 0.1733 (0.1074) loss_zs_kd 0.0808 (0.0751) loss_oracle 0.5769 (0.6022) kd_loss 0.9694 (0.9123) acc 93.7500 (96.9141) gate/entropy 1.0576 (1.0578) gate/usage_max 0.4372 (0.4371) gate/usage_min 0.2111 (0.2115) gate/usage_std 0.0932 (0.0930) teacher/entropy 0.0237 (0.0412) teacher/usage_max 0.5612 (0.5493) teacher/usage_min 0.0616 (0.0270) teacher/usage_std 0.2063 (0.2249) nleep/row_max_mean 1507.7607 (1496.5057) nleep/row_max_std 46.5036 (61.7545) nleep/row_min_mean 1476.6204 (1467.5040) lr 3.6258e-04 eta 0:03:41
epoch [38/50] batch [100/160] time 0.166 (0.110) data 0.000 (0.003) loss 1.4025 (1.3562) teacher_loss 0.1985 (0.1077) loss_zs_kd 0.0624 (0.0746) loss_oracle 0.5302 (0.5991) kd_loss 0.9077 (0.9117) acc 96.8750 (97.0000) gate/entropy 1.0576 (1.0578) gate/usage_max 0.4370 (0.4371) gate/usage_min 0.2110 (0.2114) gate/usage_std 0.0932 (0.0930) teacher/entropy 0.0775 (0.0406) teacher/usage_max 0.5342 (0.5485) teacher/usage_min 0.0584 (0.0258) teacher/usage_std 0.2012 (0.2255) nleep/row_max_mean 1469.1660 (1496.6830) nleep/row_max_std 103.4710 (61.5152) nleep/row_min_mean 1443.8584 (1467.5537) lr 3.6258e-04 eta 0:03:37
epoch [38/50] batch [120/160] time 0.076 (0.110) data 0.000 (0.003) loss 1.3926 (1.3512) teacher_loss 0.1660 (0.1037) loss_zs_kd 0.0742 (0.0740) loss_oracle 0.5585 (0.5991) kd_loss 0.9102 (0.9109) acc 96.8750 (97.1875) gate/entropy 1.0573 (1.0577) gate/usage_max 0.4374 (0.4371) gate/usage_min 0.2107 (0.2113) gate/usage_std 0.0935 (0.0931) teacher/entropy 0.0403 (0.0410) teacher/usage_max 0.5644 (0.5488) teacher/usage_min 0.0023 (0.0257) teacher/usage_std 0.2401 (0.2256) nleep/row_max_mean 1496.1555 (1497.0578) nleep/row_max_std 65.2560 (60.9439) nleep/row_min_mean 1468.9606 (1467.9473) lr 3.6258e-04 eta 0:03:34
epoch [38/50] batch [140/160] time 0.067 (0.110) data 0.000 (0.003) loss 1.3265 (1.3541) teacher_loss 0.1111 (0.1052) loss_zs_kd 0.0529 (0.0745) loss_oracle 0.6195 (0.6013) kd_loss 0.8792 (0.9110) acc 100.0000 (97.0759) gate/entropy 1.0576 (1.0577) gate/usage_max 0.4372 (0.4371) gate/usage_min 0.2112 (0.2113) gate/usage_std 0.0932 (0.0931) teacher/entropy 0.0580 (0.0404) teacher/usage_max 0.5579 (0.5483) teacher/usage_min 0.0280 (0.0265) teacher/usage_std 0.2237 (0.2252) nleep/row_max_mean 1493.3590 (1497.5101) nleep/row_max_std 58.8784 (60.4578) nleep/row_min_mean 1465.8069 (1468.4525) lr 3.6258e-04 eta 0:03:34
epoch [38/50] batch [160/160] time 0.068 (0.110) data 0.000 (0.002) loss 1.2877 (1.3553) teacher_loss 0.0442 (0.1031) loss_zs_kd 0.0598 (0.0747) loss_oracle 0.5596 (0.6031) kd_loss 0.9338 (0.9133) acc 100.0000 (97.1289) gate/entropy 1.0572 (1.0576) gate/usage_max 0.4376 (0.4372) gate/usage_min 0.2106 (0.2112) gate/usage_std 0.0936 (0.0932) teacher/entropy 0.0079 (0.0394) teacher/usage_max 0.5299 (0.5488) teacher/usage_min 0.0012 (0.0272) teacher/usage_std 0.2362 (0.2249) nleep/row_max_mean 1501.7754 (1497.9191) nleep/row_max_std 41.9034 (60.0413) nleep/row_min_mean 1473.2664 (1468.9176) lr 3.1545e-04 eta 0:03:31
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,809
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,918
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 87.9%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [39/50] batch [20/160] time 0.131 (0.155) data 0.000 (0.016) loss 1.2871 (1.3630) teacher_loss 0.0762 (0.1103) loss_zs_kd 0.0325 (0.0750) loss_oracle 0.6316 (0.6064) kd_loss 0.8789 (0.9120) acc 96.8750 (97.1875) gate/entropy 1.0572 (1.0573) gate/usage_max 0.4374 (0.4374) gate/usage_min 0.2104 (0.2106) gate/usage_std 0.0936 (0.0935) teacher/entropy 0.0696 (0.0416) teacher/usage_max 0.5284 (0.5700) teacher/usage_min 0.0117 (0.0254) teacher/usage_std 0.2292 (0.2330) nleep/row_max_mean 1512.9293 (1498.0479) nleep/row_max_std 43.1160 (58.1458) nleep/row_min_mean 1484.0702 (1469.4151) lr 3.1545e-04 eta 0:04:54
epoch [39/50] batch [40/160] time 0.132 (0.146) data 0.000 (0.008) loss 1.4385 (1.3685) teacher_loss 0.1904 (0.1202) loss_zs_kd 0.0691 (0.0712) loss_oracle 0.5266 (0.5993) kd_loss 0.9502 (0.9130) acc 96.8750 (96.9531) gate/entropy 1.0572 (1.0573) gate/usage_max 0.4374 (0.4374) gate/usage_min 0.2105 (0.2105) gate/usage_std 0.0936 (0.0936) teacher/entropy 0.0124 (0.0426) teacher/usage_max 0.5296 (0.5577) teacher/usage_min 0.0303 (0.0301) teacher/usage_std 0.2174 (0.2268) nleep/row_max_mean 1499.5784 (1496.9239) nleep/row_max_std 59.2949 (60.8695) nleep/row_min_mean 1471.6035 (1468.3059) lr 3.1545e-04 eta 0:04:33
epoch [39/50] batch [60/160] time 0.118 (0.144) data 0.001 (0.006) loss 1.3953 (1.3680) teacher_loss 0.1477 (0.1151) loss_zs_kd 0.0490 (0.0720) loss_oracle 0.5867 (0.6007) kd_loss 0.9297 (0.9165) acc 93.7500 (96.9271) gate/entropy 1.0575 (1.0572) gate/usage_max 0.4370 (0.4374) gate/usage_min 0.2108 (0.2105) gate/usage_std 0.0933 (0.0936) teacher/entropy 0.0298 (0.0413) teacher/usage_max 0.5374 (0.5548) teacher/usage_min 0.0233 (0.0307) teacher/usage_std 0.2229 (0.2263) nleep/row_max_mean 1484.3309 (1497.1398) nleep/row_max_std 62.3932 (59.2140) nleep/row_min_mean 1456.6658 (1468.5550) lr 3.1545e-04 eta 0:04:27
epoch [39/50] batch [80/160] time 0.126 (0.142) data 0.000 (0.004) loss 1.4197 (1.3701) teacher_loss 0.1395 (0.1157) loss_zs_kd 0.0759 (0.0726) loss_oracle 0.6412 (0.6026) kd_loss 0.9217 (0.9168) acc 96.8750 (97.0312) gate/entropy 1.0571 (1.0572) gate/usage_max 0.4373 (0.4374) gate/usage_min 0.2103 (0.2104) gate/usage_std 0.0937 (0.0936) teacher/entropy 0.0434 (0.0410) teacher/usage_max 0.5012 (0.5560) teacher/usage_min 0.0625 (0.0317) teacher/usage_std 0.1933 (0.2261) nleep/row_max_mean 1502.1013 (1497.9080) nleep/row_max_std 55.3765 (57.7733) nleep/row_min_mean 1474.0369 (1469.3498) lr 3.1545e-04 eta 0:04:22
epoch [39/50] batch [100/160] time 0.121 (0.141) data 0.000 (0.003) loss 1.3442 (1.3745) teacher_loss 0.0462 (0.1156) loss_zs_kd 0.0754 (0.0739) loss_oracle 0.5957 (0.6047) kd_loss 0.9625 (0.9195) acc 96.8750 (96.9688) gate/entropy 1.0570 (1.0572) gate/usage_max 0.4375 (0.4374) gate/usage_min 0.2100 (0.2104) gate/usage_std 0.0939 (0.0936) teacher/entropy 0.0260 (0.0420) teacher/usage_max 0.5603 (0.5514) teacher/usage_min 0.0579 (0.0360) teacher/usage_std 0.2079 (0.2222) nleep/row_max_mean 1503.9916 (1497.2730) nleep/row_max_std 51.0065 (58.5187) nleep/row_min_mean 1476.3406 (1468.9078) lr 3.1545e-04 eta 0:04:16
epoch [39/50] batch [120/160] time 0.096 (0.140) data 0.000 (0.003) loss 1.4462 (1.3782) teacher_loss 0.1845 (0.1173) loss_zs_kd 0.0744 (0.0734) loss_oracle 0.5733 (0.6050) kd_loss 0.9378 (0.9217) acc 90.6250 (96.9271) gate/entropy 1.0572 (1.0572) gate/usage_max 0.4371 (0.4373) gate/usage_min 0.2102 (0.2103) gate/usage_std 0.0936 (0.0937) teacher/entropy 0.0745 (0.0431) teacher/usage_max 0.5999 (0.5516) teacher/usage_min 0.0779 (0.0399) teacher/usage_std 0.2133 (0.2199) nleep/row_max_mean 1497.8884 (1496.5684) nleep/row_max_std 64.2288 (59.4725) nleep/row_min_mean 1469.8679 (1468.4318) lr 3.1545e-04 eta 0:04:11
epoch [39/50] batch [140/160] time 0.073 (0.131) data 0.000 (0.002) loss 1.2248 (1.3743) teacher_loss 0.0218 (0.1146) loss_zs_kd 0.0443 (0.0724) loss_oracle 0.5294 (0.6047) kd_loss 0.9162 (0.9212) acc 100.0000 (97.0312) gate/entropy 1.0568 (1.0571) gate/usage_max 0.4373 (0.4373) gate/usage_min 0.2097 (0.2103) gate/usage_std 0.0940 (0.0937) teacher/entropy 0.0526 (0.0428) teacher/usage_max 0.5075 (0.5519) teacher/usage_min 0.0469 (0.0391) teacher/usage_std 0.2041 (0.2202) nleep/row_max_mean 1512.1023 (1497.0622) nleep/row_max_std 56.6264 (58.6777) nleep/row_min_mean 1482.0001 (1468.9002) lr 3.1545e-04 eta 0:03:52
epoch [39/50] batch [160/160] time 0.075 (0.126) data 0.000 (0.002) loss 1.2835 (1.3734) teacher_loss 0.0386 (0.1133) loss_zs_kd 0.0897 (0.0730) loss_oracle 0.5914 (0.6021) kd_loss 0.9044 (0.9226) acc 100.0000 (97.0508) gate/entropy 1.0568 (1.0571) gate/usage_max 0.4373 (0.4373) gate/usage_min 0.2097 (0.2102) gate/usage_std 0.0940 (0.0937) teacher/entropy 0.0282 (0.0423) teacher/usage_max 0.5234 (0.5532) teacher/usage_min 0.0081 (0.0396) teacher/usage_std 0.2311 (0.2204) nleep/row_max_mean 1506.5830 (1496.9958) nleep/row_max_std 43.6022 (59.1248) nleep/row_min_mean 1478.3303 (1468.8185) lr 2.7103e-04 eta 0:03:42
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,810
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 84.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,913
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.7%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [40/50] batch [20/160] time 0.145 (0.125) data 0.000 (0.013) loss 1.3056 (1.3429) teacher_loss 0.0295 (0.0788) loss_zs_kd 0.0706 (0.0702) loss_oracle 0.6119 (0.5960) kd_loss 0.9348 (0.9310) acc 100.0000 (97.9688) gate/entropy 1.0570 (1.0569) gate/usage_max 0.4369 (0.4372) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.0937 (0.0939) teacher/entropy 0.0392 (0.0297) teacher/usage_max 0.4989 (0.5298) teacher/usage_min 0.0568 (0.0422) teacher/usage_std 0.1968 (0.2119) nleep/row_max_mean 1492.5592 (1499.9923) nleep/row_max_std 64.8475 (54.4345) nleep/row_min_mean 1461.4100 (1471.0601) lr 2.7103e-04 eta 0:03:36
epoch [40/50] batch [40/160] time 0.112 (0.113) data 0.000 (0.007) loss 1.3989 (1.3525) teacher_loss 0.1486 (0.0808) loss_zs_kd 0.0680 (0.0715) loss_oracle 0.5754 (0.6036) kd_loss 0.9286 (0.9341) acc 96.8750 (97.9688) gate/entropy 1.0568 (1.0569) gate/usage_max 0.4372 (0.4371) gate/usage_min 0.2096 (0.2097) gate/usage_std 0.0939 (0.0939) teacher/entropy 0.0285 (0.0334) teacher/usage_max 0.5001 (0.5393) teacher/usage_min 0.0334 (0.0449) teacher/usage_std 0.2126 (0.2144) nleep/row_max_mean 1494.3467 (1499.5558) nleep/row_max_std 74.9354 (57.1159) nleep/row_min_mean 1465.7867 (1470.5440) lr 2.7103e-04 eta 0:03:15
epoch [40/50] batch [60/160] time 0.060 (0.105) data 0.000 (0.005) loss 1.3219 (1.3525) teacher_loss 0.0144 (0.0762) loss_zs_kd 0.0614 (0.0747) loss_oracle 0.6211 (0.6020) kd_loss 0.9663 (0.9380) acc 100.0000 (98.0208) gate/entropy 1.0569 (1.0569) gate/usage_max 0.4368 (0.4371) gate/usage_min 0.2096 (0.2096) gate/usage_std 0.0939 (0.0939) teacher/entropy 0.0303 (0.0308) teacher/usage_max 0.5649 (0.5405) teacher/usage_min 0.0681 (0.0443) teacher/usage_std 0.2042 (0.2145) nleep/row_max_mean 1491.4012 (1499.6212) nleep/row_max_std 71.9300 (58.1307) nleep/row_min_mean 1463.7816 (1470.3783) lr 2.7103e-04 eta 0:02:57
epoch [40/50] batch [80/160] time 0.099 (0.101) data 0.000 (0.003) loss 1.3950 (1.3664) teacher_loss 0.0705 (0.0886) loss_zs_kd 0.0773 (0.0754) loss_oracle 0.7272 (0.6088) kd_loss 0.9223 (0.9357) acc 96.8750 (97.6172) gate/entropy 1.0569 (1.0568) gate/usage_max 0.4369 (0.4371) gate/usage_min 0.2095 (0.2096) gate/usage_std 0.0939 (0.0939) teacher/entropy 0.0139 (0.0300) teacher/usage_max 0.5635 (0.5384) teacher/usage_min 0.0326 (0.0417) teacher/usage_std 0.2224 (0.2151) nleep/row_max_mean 1495.6278 (1498.9300) nleep/row_max_std 53.5910 (59.0665) nleep/row_min_mean 1468.0239 (1469.7898) lr 2.7103e-04 eta 0:02:49
epoch [40/50] batch [100/160] time 0.089 (0.103) data 0.000 (0.003) loss 1.3418 (1.3658) teacher_loss 0.0976 (0.0925) loss_zs_kd 0.0602 (0.0749) loss_oracle 0.5238 (0.6054) kd_loss 0.9522 (0.9332) acc 96.8750 (97.4688) gate/entropy 1.0567 (1.0568) gate/usage_max 0.4367 (0.4370) gate/usage_min 0.2092 (0.2096) gate/usage_std 0.0940 (0.0939) teacher/entropy 0.0183 (0.0308) teacher/usage_max 0.6802 (0.5440) teacher/usage_min 0.0000 (0.0387) teacher/usage_std 0.2778 (0.2180) nleep/row_max_mean 1496.6198 (1498.6751) nleep/row_max_std 51.1461 (58.7811) nleep/row_min_mean 1464.4465 (1469.4799) lr 2.7103e-04 eta 0:02:51
epoch [40/50] batch [120/160] time 0.147 (0.108) data 0.000 (0.002) loss 1.4201 (1.3683) teacher_loss 0.1367 (0.0928) loss_zs_kd 0.1030 (0.0756) loss_oracle 0.6139 (0.6077) kd_loss 0.9250 (0.9338) acc 96.8750 (97.4479) gate/entropy 1.0566 (1.0568) gate/usage_max 0.4370 (0.4370) gate/usage_min 0.2091 (0.2095) gate/usage_std 0.0941 (0.0940) teacher/entropy 0.0000 (0.0301) teacher/usage_max 0.5312 (0.5457) teacher/usage_min 0.0000 (0.0377) teacher/usage_std 0.2371 (0.2187) nleep/row_max_mean 1517.2858 (1498.5357) nleep/row_max_std 24.1657 (58.2111) nleep/row_min_mean 1482.1863 (1469.2343) lr 2.7103e-04 eta 0:02:56
epoch [40/50] batch [140/160] time 0.132 (0.111) data 0.000 (0.002) loss 1.3432 (1.3691) teacher_loss 0.0667 (0.0927) loss_zs_kd 0.0813 (0.0760) loss_oracle 0.7093 (0.6107) kd_loss 0.8812 (0.9330) acc 100.0000 (97.3884) gate/entropy 1.0567 (1.0568) gate/usage_max 0.4368 (0.4370) gate/usage_min 0.2091 (0.2095) gate/usage_std 0.0941 (0.0940) teacher/entropy 0.0684 (0.0310) teacher/usage_max 0.5812 (0.5460) teacher/usage_min 0.0005 (0.0387) teacher/usage_std 0.2445 (0.2185) nleep/row_max_mean 1511.2571 (1498.3656) nleep/row_max_std 44.1334 (58.1088) nleep/row_min_mean 1478.8083 (1469.0011) lr 2.7103e-04 eta 0:03:00
epoch [40/50] batch [160/160] time 0.144 (0.114) data 0.000 (0.002) loss 1.2905 (1.3710) teacher_loss 0.0638 (0.0960) loss_zs_kd 0.0729 (0.0764) loss_oracle 0.6096 (0.6107) kd_loss 0.8854 (0.9315) acc 100.0000 (97.3438) gate/entropy 1.0565 (1.0568) gate/usage_max 0.4369 (0.4370) gate/usage_min 0.2089 (0.2094) gate/usage_std 0.0942 (0.0940) teacher/entropy 0.0165 (0.0307) teacher/usage_max 0.6527 (0.5482) teacher/usage_min 0.0040 (0.0378) teacher/usage_std 0.2649 (0.2196) nleep/row_max_mean 1501.9337 (1497.8985) nleep/row_max_std 51.0293 (58.5564) nleep/row_min_mean 1468.6882 (1468.5794) lr 2.2949e-04 eta 0:03:02
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,819
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,921
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 88.0%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [41/50] batch [20/160] time 0.146 (0.153) data 0.000 (0.016) loss 1.3251 (1.3442) teacher_loss 0.0501 (0.0974) loss_zs_kd 0.0915 (0.0732) loss_oracle 0.5983 (0.5931) kd_loss 0.9301 (0.9136) acc 100.0000 (97.6562) gate/entropy 1.0564 (1.0566) gate/usage_max 0.4371 (0.4369) gate/usage_min 0.2087 (0.2090) gate/usage_std 0.0944 (0.0942) teacher/entropy 0.0262 (0.0450) teacher/usage_max 0.5289 (0.5562) teacher/usage_min 0.0252 (0.0389) teacher/usage_std 0.2205 (0.2208) nleep/row_max_mean 1508.2740 (1494.2863) nleep/row_max_std 57.0643 (61.8568) nleep/row_min_mean 1477.2347 (1465.0048) lr 2.2949e-04 eta 0:04:01
epoch [41/50] batch [40/160] time 0.125 (0.146) data 0.000 (0.008) loss 1.3744 (1.3638) teacher_loss 0.1190 (0.1083) loss_zs_kd 0.0859 (0.0742) loss_oracle 0.5844 (0.5963) kd_loss 0.9203 (0.9202) acc 93.7500 (97.5000) gate/entropy 1.0563 (1.0565) gate/usage_max 0.4371 (0.4369) gate/usage_min 0.2087 (0.2089) gate/usage_std 0.0944 (0.0942) teacher/entropy 0.0225 (0.0416) teacher/usage_max 0.4999 (0.5598) teacher/usage_min 0.0151 (0.0391) teacher/usage_std 0.2251 (0.2216) nleep/row_max_mean 1502.8929 (1495.4769) nleep/row_max_std 67.6774 (60.2411) nleep/row_min_mean 1472.9175 (1466.2008) lr 2.2949e-04 eta 0:03:47
epoch [41/50] batch [60/160] time 0.160 (0.148) data 0.001 (0.005) loss 1.3364 (1.3612) teacher_loss 0.0417 (0.1048) loss_zs_kd 0.0715 (0.0742) loss_oracle 0.7166 (0.6021) kd_loss 0.9006 (0.9183) acc 100.0000 (97.5000) gate/entropy 1.0563 (1.0565) gate/usage_max 0.4372 (0.4369) gate/usage_min 0.2086 (0.2089) gate/usage_std 0.0945 (0.0942) teacher/entropy 0.0134 (0.0378) teacher/usage_max 0.5911 (0.5579) teacher/usage_min 0.0033 (0.0366) teacher/usage_std 0.2454 (0.2224) nleep/row_max_mean 1500.1421 (1496.5476) nleep/row_max_std 63.6559 (58.3564) nleep/row_min_mean 1471.2402 (1467.1387) lr 2.2949e-04 eta 0:03:47
epoch [41/50] batch [80/160] time 0.136 (0.133) data 0.000 (0.004) loss 1.3086 (1.3703) teacher_loss 0.0277 (0.1078) loss_zs_kd 0.0659 (0.0761) loss_oracle 0.5401 (0.6061) kd_loss 0.9779 (0.9214) acc 100.0000 (97.3828) gate/entropy 1.0567 (1.0565) gate/usage_max 0.4364 (0.4369) gate/usage_min 0.2090 (0.2089) gate/usage_std 0.0940 (0.0943) teacher/entropy 0.0030 (0.0353) teacher/usage_max 0.6247 (0.5564) teacher/usage_min 0.0315 (0.0347) teacher/usage_std 0.2423 (0.2230) nleep/row_max_mean 1501.2778 (1497.7003) nleep/row_max_std 45.4409 (56.8258) nleep/row_min_mean 1471.2064 (1467.9802) lr 2.2949e-04 eta 0:03:22
epoch [41/50] batch [100/160] time 0.097 (0.129) data 0.000 (0.003) loss 1.2641 (1.3646) teacher_loss 0.0335 (0.1035) loss_zs_kd 0.0833 (0.0769) loss_oracle 0.5796 (0.6048) kd_loss 0.8991 (0.9203) acc 100.0000 (97.4688) gate/entropy 1.0562 (1.0565) gate/usage_max 0.4373 (0.4369) gate/usage_min 0.2084 (0.2088) gate/usage_std 0.0946 (0.0943) teacher/entropy 0.0062 (0.0343) teacher/usage_max 0.6253 (0.5596) teacher/usage_min 0.0000 (0.0317) teacher/usage_std 0.2570 (0.2254) nleep/row_max_mean 1515.3435 (1498.5826) nleep/row_max_std 26.0991 (55.6365) nleep/row_min_mean 1484.0955 (1468.7519) lr 2.2949e-04 eta 0:03:14
epoch [41/50] batch [120/160] time 0.144 (0.128) data 0.000 (0.003) loss 1.3651 (1.3632) teacher_loss 0.0989 (0.1023) loss_zs_kd 0.0853 (0.0760) loss_oracle 0.6140 (0.6063) kd_loss 0.9166 (0.9197) acc 96.8750 (97.3438) gate/entropy 1.0562 (1.0564) gate/usage_max 0.4370 (0.4369) gate/usage_min 0.2084 (0.2088) gate/usage_std 0.0945 (0.0943) teacher/entropy 0.0410 (0.0337) teacher/usage_max 0.5313 (0.5587) teacher/usage_min 0.0276 (0.0306) teacher/usage_std 0.2193 (0.2258) nleep/row_max_mean 1499.2266 (1498.1946) nleep/row_max_std 57.8321 (56.6758) nleep/row_min_mean 1469.9336 (1468.4119) lr 2.2949e-04 eta 0:03:09
epoch [41/50] batch [140/160] time 0.159 (0.125) data 0.000 (0.002) loss 1.4147 (1.3662) teacher_loss 0.1999 (0.1043) loss_zs_kd 0.0617 (0.0755) loss_oracle 0.5508 (0.6083) kd_loss 0.9086 (0.9199) acc 93.7500 (97.3214) gate/entropy 1.0563 (1.0564) gate/usage_max 0.4367 (0.4369) gate/usage_min 0.2084 (0.2087) gate/usage_std 0.0944 (0.0943) teacher/entropy 0.0608 (0.0338) teacher/usage_max 0.5990 (0.5581) teacher/usage_min 0.0240 (0.0305) teacher/usage_std 0.2367 (0.2257) nleep/row_max_mean 1486.7166 (1497.7765) nleep/row_max_std 78.5648 (56.5604) nleep/row_min_mean 1457.5492 (1468.1454) lr 2.2949e-04 eta 0:03:03
epoch [41/50] batch [160/160] time 0.087 (0.120) data 0.000 (0.002) loss 1.4306 (1.3653) teacher_loss 0.1938 (0.1035) loss_zs_kd 0.0894 (0.0753) loss_oracle 0.6225 (0.6099) kd_loss 0.8809 (0.9192) acc 93.7500 (97.3047) gate/entropy 1.0563 (1.0564) gate/usage_max 0.4369 (0.4369) gate/usage_min 0.2085 (0.2087) gate/usage_std 0.0945 (0.0944) teacher/entropy 0.0586 (0.0343) teacher/usage_max 0.4977 (0.5579) teacher/usage_min 0.0144 (0.0310) teacher/usage_std 0.2256 (0.2254) nleep/row_max_mean 1500.9707 (1497.2008) nleep/row_max_std 42.9747 (56.8167) nleep/row_min_mean 1471.5598 (1467.6693) lr 1.9098e-04 eta 0:02:53
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,824
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,927
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 88.1%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [42/50] batch [20/160] time 0.079 (0.104) data 0.000 (0.015) loss 1.5875 (1.3706) teacher_loss 0.3083 (0.0987) loss_zs_kd 0.0947 (0.0772) loss_oracle 0.6479 (0.6282) kd_loss 0.9078 (0.9192) acc 90.6250 (97.3438) gate/entropy 1.0562 (1.0562) gate/usage_max 0.4371 (0.4370) gate/usage_min 0.2083 (0.2084) gate/usage_std 0.0946 (0.0945) teacher/entropy 0.0184 (0.0396) teacher/usage_max 0.5954 (0.5503) teacher/usage_min 0.0290 (0.0398) teacher/usage_std 0.2331 (0.2194) nleep/row_max_mean 1493.5260 (1491.0141) nleep/row_max_std 57.3522 (64.7727) nleep/row_min_mean 1460.7833 (1461.7279) lr 1.9098e-04 eta 0:02:27
epoch [42/50] batch [40/160] time 0.090 (0.101) data 0.000 (0.008) loss 1.3740 (1.3631) teacher_loss 0.0798 (0.1018) loss_zs_kd 0.0636 (0.0762) loss_oracle 0.6317 (0.6189) kd_loss 0.9465 (0.9137) acc 96.8750 (97.5000) gate/entropy 1.0563 (1.0562) gate/usage_max 0.4368 (0.4370) gate/usage_min 0.2085 (0.2083) gate/usage_std 0.0944 (0.0946) teacher/entropy 0.0390 (0.0396) teacher/usage_max 0.5912 (0.5563) teacher/usage_min 0.0479 (0.0352) teacher/usage_std 0.2226 (0.2224) nleep/row_max_mean 1489.6021 (1491.9302) nleep/row_max_std 58.7202 (62.2346) nleep/row_min_mean 1463.7148 (1462.9717) lr 1.9098e-04 eta 0:02:21
epoch [42/50] batch [60/160] time 0.167 (0.103) data 0.000 (0.005) loss 1.4257 (1.3579) teacher_loss 0.2165 (0.1053) loss_zs_kd 0.0676 (0.0742) loss_oracle 0.5284 (0.6154) kd_loss 0.9112 (0.9079) acc 93.7500 (97.4479) gate/entropy 1.0559 (1.0562) gate/usage_max 0.4372 (0.4370) gate/usage_min 0.2079 (0.2083) gate/usage_std 0.0949 (0.0946) teacher/entropy 0.0395 (0.0416) teacher/usage_max 0.5963 (0.5615) teacher/usage_min 0.0000 (0.0322) teacher/usage_std 0.2485 (0.2254) nleep/row_max_mean 1508.4427 (1493.8817) nleep/row_max_std 37.8054 (59.4191) nleep/row_min_mean 1479.2827 (1464.8876) lr 1.9098e-04 eta 0:02:21
epoch [42/50] batch [80/160] time 0.155 (0.106) data 0.000 (0.004) loss 1.3059 (1.3516) teacher_loss 0.0537 (0.0971) loss_zs_kd 0.0641 (0.0738) loss_oracle 0.5551 (0.6186) kd_loss 0.9426 (0.9082) acc 96.8750 (97.6953) gate/entropy 1.0561 (1.0561) gate/usage_max 0.4371 (0.4370) gate/usage_min 0.2082 (0.2083) gate/usage_std 0.0947 (0.0946) teacher/entropy 0.0151 (0.0411) teacher/usage_max 0.6217 (0.5546) teacher/usage_min 0.0025 (0.0314) teacher/usage_std 0.2546 (0.2241) nleep/row_max_mean 1491.0010 (1494.1093) nleep/row_max_std 68.1827 (59.0262) nleep/row_min_mean 1463.0573 (1465.1921) lr 1.9098e-04 eta 0:02:24
epoch [42/50] batch [100/160] time 0.150 (0.106) data 0.000 (0.003) loss 1.2968 (1.3495) teacher_loss 0.0995 (0.0988) loss_zs_kd 0.0467 (0.0728) loss_oracle 0.5600 (0.6162) kd_loss 0.8939 (0.9061) acc 96.8750 (97.4062) gate/entropy 1.0561 (1.0561) gate/usage_max 0.4372 (0.4371) gate/usage_min 0.2082 (0.2082) gate/usage_std 0.0947 (0.0946) teacher/entropy 0.0316 (0.0413) teacher/usage_max 0.6200 (0.5538) teacher/usage_min 0.0372 (0.0290) teacher/usage_std 0.2380 (0.2253) nleep/row_max_mean 1511.2094 (1495.0872) nleep/row_max_std 25.4746 (57.4783) nleep/row_min_mean 1480.6902 (1466.1631) lr 1.9098e-04 eta 0:02:21
epoch [42/50] batch [120/160] time 0.090 (0.102) data 0.000 (0.003) loss 1.3218 (1.3488) teacher_loss 0.1116 (0.0991) loss_zs_kd 0.0578 (0.0718) loss_oracle 0.6484 (0.6168) kd_loss 0.8571 (0.9053) acc 96.8750 (97.4479) gate/entropy 1.0558 (1.0561) gate/usage_max 0.4372 (0.4371) gate/usage_min 0.2078 (0.2082) gate/usage_std 0.0949 (0.0946) teacher/entropy 0.0671 (0.0411) teacher/usage_max 0.5978 (0.5557) teacher/usage_min 0.0266 (0.0289) teacher/usage_std 0.2351 (0.2258) nleep/row_max_mean 1494.0906 (1494.8432) nleep/row_max_std 71.6590 (57.1895) nleep/row_min_mean 1466.4109 (1465.9918) lr 1.9098e-04 eta 0:02:14
epoch [42/50] batch [140/160] time 0.137 (0.100) data 0.001 (0.002) loss 1.3278 (1.3505) teacher_loss 0.1055 (0.1023) loss_zs_kd 0.0616 (0.0719) loss_oracle 0.5751 (0.6155) kd_loss 0.9040 (0.9045) acc 93.7500 (97.2768) gate/entropy 1.0559 (1.0561) gate/usage_max 0.4374 (0.4371) gate/usage_min 0.2079 (0.2082) gate/usage_std 0.0949 (0.0947) teacher/entropy 0.0647 (0.0423) teacher/usage_max 0.5821 (0.5557) teacher/usage_min 0.0281 (0.0298) teacher/usage_std 0.2297 (0.2253) nleep/row_max_mean 1504.2688 (1494.7319) nleep/row_max_std 58.8608 (58.3719) nleep/row_min_mean 1478.3500 (1465.8354) lr 1.9098e-04 eta 0:02:10
epoch [42/50] batch [160/160] time 0.057 (0.100) data 0.000 (0.002) loss 1.2793 (1.3469) teacher_loss 0.0861 (0.0998) loss_zs_kd 0.0739 (0.0723) loss_oracle 0.6205 (0.6136) kd_loss 0.8461 (0.9041) acc 96.8750 (97.4023) gate/entropy 1.0558 (1.0561) gate/usage_max 0.4376 (0.4372) gate/usage_min 0.2079 (0.2081) gate/usage_std 0.0950 (0.0947) teacher/entropy 0.0368 (0.0418) teacher/usage_max 0.7284 (0.5545) teacher/usage_min 0.0001 (0.0287) teacher/usage_std 0.3005 (0.2259) nleep/row_max_mean 1513.0616 (1495.0528) nleep/row_max_std 24.4191 (57.7758) nleep/row_min_mean 1481.9840 (1466.1715) lr 1.5567e-04 eta 0:02:08
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,838
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,942
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 88.2%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [43/50] batch [20/160] time 0.092 (0.099) data 0.000 (0.012) loss 1.4675 (1.3286) teacher_loss 0.2906 (0.0950) loss_zs_kd 0.0930 (0.0712) loss_oracle 0.5554 (0.5955) kd_loss 0.8527 (0.9003) acc 93.7500 (96.8750) gate/entropy 1.0559 (1.0559) gate/usage_max 0.4374 (0.4374) gate/usage_min 0.2080 (0.2079) gate/usage_std 0.0948 (0.0949) teacher/entropy 0.0994 (0.0451) teacher/usage_max 0.4885 (0.5565) teacher/usage_min 0.0316 (0.0307) teacher/usage_std 0.2134 (0.2255) nleep/row_max_mean 1490.3525 (1494.4991) nleep/row_max_std 49.9075 (59.2808) nleep/row_min_mean 1462.0139 (1465.0012) lr 1.5567e-04 eta 0:02:04
epoch [43/50] batch [40/160] time 0.081 (0.090) data 0.000 (0.006) loss 1.2848 (1.3280) teacher_loss 0.0451 (0.0926) loss_zs_kd 0.0879 (0.0702) loss_oracle 0.5695 (0.5945) kd_loss 0.9110 (0.9031) acc 100.0000 (97.3438) gate/entropy 1.0558 (1.0558) gate/usage_max 0.4375 (0.4375) gate/usage_min 0.2077 (0.2078) gate/usage_std 0.0950 (0.0950) teacher/entropy 0.0181 (0.0374) teacher/usage_max 0.5071 (0.5570) teacher/usage_min 0.0001 (0.0261) teacher/usage_std 0.2357 (0.2281) nleep/row_max_mean 1504.3030 (1496.5509) nleep/row_max_std 43.3412 (58.4329) nleep/row_min_mean 1472.3777 (1466.5219) lr 1.5567e-04 eta 0:01:51
epoch [43/50] batch [60/160] time 0.086 (0.089) data 0.001 (0.004) loss 1.3046 (1.3384) teacher_loss 0.0368 (0.0978) loss_zs_kd 0.1152 (0.0722) loss_oracle 0.5806 (0.6008) kd_loss 0.9199 (0.9040) acc 100.0000 (97.1354) gate/entropy 1.0554 (1.0558) gate/usage_max 0.4381 (0.4375) gate/usage_min 0.2072 (0.2078) gate/usage_std 0.0954 (0.0950) teacher/entropy 0.0158 (0.0384) teacher/usage_max 0.5260 (0.5610) teacher/usage_min 0.0002 (0.0252) teacher/usage_std 0.2366 (0.2298) nleep/row_max_mean 1502.2678 (1496.7281) nleep/row_max_std 58.3650 (58.8048) nleep/row_min_mean 1474.4355 (1467.1213) lr 1.5567e-04 eta 0:01:47
epoch [43/50] batch [80/160] time 0.094 (0.087) data 0.000 (0.003) loss 1.3210 (1.3473) teacher_loss 0.0591 (0.1035) loss_zs_kd 0.0863 (0.0740) loss_oracle 0.5902 (0.6025) kd_loss 0.9236 (0.9055) acc 100.0000 (97.1094) gate/entropy 1.0558 (1.0558) gate/usage_max 0.4374 (0.4376) gate/usage_min 0.2077 (0.2078) gate/usage_std 0.0950 (0.0950) teacher/entropy 0.0472 (0.0388) teacher/usage_max 0.6183 (0.5545) teacher/usage_min 0.0208 (0.0270) teacher/usage_std 0.2447 (0.2274) nleep/row_max_mean 1479.3220 (1495.6115) nleep/row_max_std 76.6217 (60.1104) nleep/row_min_mean 1451.7966 (1466.3541) lr 1.5567e-04 eta 0:01:44
epoch [43/50] batch [100/160] time 0.086 (0.087) data 0.000 (0.003) loss 1.2619 (1.3478) teacher_loss 0.0205 (0.1006) loss_zs_kd 0.0708 (0.0726) loss_oracle 0.6008 (0.6053) kd_loss 0.9056 (0.9083) acc 100.0000 (97.2812) gate/entropy 1.0556 (1.0558) gate/usage_max 0.4376 (0.4376) gate/usage_min 0.2074 (0.2077) gate/usage_std 0.0952 (0.0950) teacher/entropy 0.0239 (0.0379) teacher/usage_max 0.5036 (0.5541) teacher/usage_min 0.0003 (0.0271) teacher/usage_std 0.2355 (0.2271) nleep/row_max_mean 1502.9348 (1495.6261) nleep/row_max_std 48.8466 (59.3402) nleep/row_min_mean 1473.2527 (1466.5509) lr 1.5567e-04 eta 0:01:43
epoch [43/50] batch [120/160] time 0.077 (0.086) data 0.000 (0.002) loss 1.2648 (1.3497) teacher_loss 0.0086 (0.1011) loss_zs_kd 0.0577 (0.0732) loss_oracle 0.5706 (0.6051) kd_loss 0.9420 (0.9094) acc 100.0000 (97.1875) gate/entropy 1.0558 (1.0557) gate/usage_max 0.4374 (0.4376) gate/usage_min 0.2077 (0.2077) gate/usage_std 0.0950 (0.0950) teacher/entropy 0.0218 (0.0382) teacher/usage_max 0.5612 (0.5559) teacher/usage_min 0.0281 (0.0278) teacher/usage_std 0.2244 (0.2268) nleep/row_max_mean 1501.7820 (1495.1574) nleep/row_max_std 57.0191 (59.4806) nleep/row_min_mean 1473.4711 (1466.2571) lr 1.5567e-04 eta 0:01:40
epoch [43/50] batch [140/160] time 0.080 (0.086) data 0.000 (0.002) loss 1.3219 (1.3464) teacher_loss 0.0631 (0.0969) loss_zs_kd 0.0564 (0.0726) loss_oracle 0.6117 (0.6075) kd_loss 0.9248 (0.9094) acc 96.8750 (97.2991) gate/entropy 1.0558 (1.0557) gate/usage_max 0.4375 (0.4376) gate/usage_min 0.2079 (0.2077) gate/usage_std 0.0949 (0.0951) teacher/entropy 0.0117 (0.0376) teacher/usage_max 0.5286 (0.5550) teacher/usage_min 0.0001 (0.0270) teacher/usage_std 0.2368 (0.2271) nleep/row_max_mean 1490.9043 (1494.9028) nleep/row_max_std 54.1748 (59.5226) nleep/row_min_mean 1462.0642 (1466.0387) lr 1.5567e-04 eta 0:01:38
epoch [43/50] batch [160/160] time 0.067 (0.085) data 0.000 (0.002) loss 1.3807 (1.3483) teacher_loss 0.0536 (0.0971) loss_zs_kd 0.1021 (0.0733) loss_oracle 0.7171 (0.6073) kd_loss 0.9175 (0.9109) acc 100.0000 (97.3242) gate/entropy 1.0557 (1.0557) gate/usage_max 0.4376 (0.4376) gate/usage_min 0.2076 (0.2077) gate/usage_std 0.0951 (0.0951) teacher/entropy 0.0248 (0.0362) teacher/usage_max 0.5222 (0.5564) teacher/usage_min 0.0307 (0.0266) teacher/usage_std 0.2162 (0.2280) nleep/row_max_mean 1494.0212 (1494.9469) nleep/row_max_std 64.9274 (59.2406) nleep/row_min_mean 1463.5602 (1466.1219) lr 1.2369e-04 eta 0:01:35
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,827
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,920
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 87.9%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [44/50] batch [20/160] time 0.078 (0.097) data 0.000 (0.018) loss 1.3003 (1.3588) teacher_loss 0.0360 (0.0938) loss_zs_kd 0.0799 (0.0747) loss_oracle 0.6356 (0.6166) kd_loss 0.9066 (0.9193) acc 100.0000 (97.5000) gate/entropy 1.0556 (1.0556) gate/usage_max 0.4374 (0.4376) gate/usage_min 0.2074 (0.2074) gate/usage_std 0.0952 (0.0952) teacher/entropy 0.0341 (0.0289) teacher/usage_max 0.5347 (0.5497) teacher/usage_min 0.0045 (0.0290) teacher/usage_std 0.2345 (0.2248) nleep/row_max_mean 1489.3137 (1492.3120) nleep/row_max_std 58.8412 (58.9212) nleep/row_min_mean 1460.6558 (1463.6186) lr 1.2369e-04 eta 0:01:46
epoch [44/50] batch [40/160] time 0.097 (0.087) data 0.000 (0.009) loss 1.4249 (1.3688) teacher_loss 0.1484 (0.1047) loss_zs_kd 0.0875 (0.0756) loss_oracle 0.6484 (0.6156) kd_loss 0.9086 (0.9185) acc 96.8750 (97.1875) gate/entropy 1.0555 (1.0555) gate/usage_max 0.4378 (0.4377) gate/usage_min 0.2074 (0.2074) gate/usage_std 0.0953 (0.0952) teacher/entropy 0.0288 (0.0329) teacher/usage_max 0.5425 (0.5555) teacher/usage_min 0.0307 (0.0271) teacher/usage_std 0.2192 (0.2265) nleep/row_max_mean 1486.9337 (1491.7833) nleep/row_max_std 69.8468 (60.9248) nleep/row_min_mean 1459.6205 (1463.4681) lr 1.2369e-04 eta 0:01:34
epoch [44/50] batch [60/160] time 0.080 (0.085) data 0.001 (0.006) loss 1.4219 (1.3716) teacher_loss 0.1617 (0.1066) loss_zs_kd 0.0692 (0.0738) loss_oracle 0.5941 (0.6219) kd_loss 0.9286 (0.9171) acc 96.8750 (97.1875) gate/entropy 1.0555 (1.0555) gate/usage_max 0.4378 (0.4377) gate/usage_min 0.2074 (0.2074) gate/usage_std 0.0953 (0.0953) teacher/entropy 0.0283 (0.0350) teacher/usage_max 0.4998 (0.5512) teacher/usage_min 0.0359 (0.0295) teacher/usage_std 0.2108 (0.2247) nleep/row_max_mean 1491.3846 (1492.3905) nleep/row_max_std 64.2763 (60.6008) nleep/row_min_mean 1462.6521 (1464.1876) lr 1.2369e-04 eta 0:01:30
epoch [44/50] batch [80/160] time 0.097 (0.087) data 0.000 (0.005) loss 1.2813 (1.3694) teacher_loss 0.0250 (0.1063) loss_zs_kd 0.0729 (0.0739) loss_oracle 0.6288 (0.6192) kd_loss 0.9055 (0.9166) acc 100.0000 (97.2656) gate/entropy 1.0554 (1.0555) gate/usage_max 0.4379 (0.4377) gate/usage_min 0.2072 (0.2074) gate/usage_std 0.0954 (0.0953) teacher/entropy 0.0424 (0.0356) teacher/usage_max 0.5039 (0.5488) teacher/usage_min 0.0236 (0.0297) teacher/usage_std 0.2194 (0.2244) nleep/row_max_mean 1506.6191 (1492.1860) nleep/row_max_std 58.7320 (61.1834) nleep/row_min_mean 1475.7751 (1464.0172) lr 1.2369e-04 eta 0:01:30
epoch [44/50] batch [100/160] time 0.077 (0.090) data 0.000 (0.004) loss 1.2471 (1.3656) teacher_loss 0.0512 (0.1052) loss_zs_kd 0.0530 (0.0737) loss_oracle 0.5187 (0.6142) kd_loss 0.9100 (0.9165) acc 100.0000 (97.2812) gate/entropy 1.0554 (1.0555) gate/usage_max 0.4377 (0.4377) gate/usage_min 0.2071 (0.2073) gate/usage_std 0.0954 (0.0953) teacher/entropy 0.0215 (0.0355) teacher/usage_max 0.4986 (0.5491) teacher/usage_min 0.0028 (0.0306) teacher/usage_std 0.2337 (0.2239) nleep/row_max_mean 1499.7681 (1493.1437) nleep/row_max_std 39.4422 (59.3666) nleep/row_min_mean 1472.3420 (1464.8301) lr 1.2369e-04 eta 0:01:32
epoch [44/50] batch [120/160] time 0.082 (0.088) data 0.000 (0.003) loss 1.2853 (1.3612) teacher_loss 0.0373 (0.1013) loss_zs_kd 0.0718 (0.0727) loss_oracle 0.5756 (0.6144) kd_loss 0.9243 (0.9164) acc 100.0000 (97.4219) gate/entropy 1.0553 (1.0555) gate/usage_max 0.4380 (0.4377) gate/usage_min 0.2070 (0.2073) gate/usage_std 0.0955 (0.0953) teacher/entropy 0.0158 (0.0356) teacher/usage_max 0.5272 (0.5485) teacher/usage_min 0.0314 (0.0301) teacher/usage_std 0.2164 (0.2239) nleep/row_max_mean 1501.5364 (1493.1106) nleep/row_max_std 61.9120 (58.8938) nleep/row_min_mean 1473.1536 (1464.8698) lr 1.2369e-04 eta 0:01:28
epoch [44/50] batch [140/160] time 0.070 (0.087) data 0.000 (0.003) loss 1.3576 (1.3554) teacher_loss 0.0745 (0.0975) loss_zs_kd 0.1068 (0.0731) loss_oracle 0.6483 (0.6104) kd_loss 0.9056 (0.9161) acc 100.0000 (97.5670) gate/entropy 1.0554 (1.0555) gate/usage_max 0.4377 (0.4377) gate/usage_min 0.2071 (0.2073) gate/usage_std 0.0954 (0.0953) teacher/entropy 0.0663 (0.0348) teacher/usage_max 0.5872 (0.5479) teacher/usage_min 0.0319 (0.0284) teacher/usage_std 0.2292 (0.2246) nleep/row_max_mean 1487.7698 (1493.3607) nleep/row_max_std 48.2547 (57.9045) nleep/row_min_mean 1463.1882 (1465.2303) lr 1.2369e-04 eta 0:01:25
epoch [44/50] batch [160/160] time 0.057 (0.086) data 0.000 (0.002) loss 1.6546 (1.3576) teacher_loss 0.3435 (0.0999) loss_zs_kd 0.0827 (0.0733) loss_oracle 0.7311 (0.6123) kd_loss 0.9042 (0.9148) acc 90.6250 (97.4219) gate/entropy 1.0555 (1.0555) gate/usage_max 0.4376 (0.4377) gate/usage_min 0.2073 (0.2073) gate/usage_std 0.0953 (0.0953) teacher/entropy 0.0696 (0.0363) teacher/usage_max 0.5595 (0.5449) teacher/usage_min 0.1060 (0.0299) teacher/usage_std 0.1852 (0.2232) nleep/row_max_mean 1488.5317 (1493.0248) nleep/row_max_std 68.0440 (58.1111) nleep/row_min_mean 1458.5436 (1464.9194) lr 9.5173e-05 eta 0:01:22
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,821
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,918
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 87.9%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [45/50] batch [20/160] time 0.095 (0.099) data 0.000 (0.016) loss 1.3568 (1.3321) teacher_loss 0.1137 (0.0810) loss_zs_kd 0.0691 (0.0714) loss_oracle 0.6392 (0.6123) kd_loss 0.8890 (0.9092) acc 96.8750 (97.8125) gate/entropy 1.0554 (1.0554) gate/usage_max 0.4377 (0.4378) gate/usage_min 0.2071 (0.2071) gate/usage_std 0.0954 (0.0954) teacher/entropy 0.0194 (0.0396) teacher/usage_max 0.6011 (0.5571) teacher/usage_min 0.0000 (0.0326) teacher/usage_std 0.2497 (0.2241) nleep/row_max_mean 1505.8591 (1492.1716) nleep/row_max_std 28.6214 (62.4118) nleep/row_min_mean 1478.3635 (1464.4279) lr 9.5173e-05 eta 0:01:32
epoch [45/50] batch [40/160] time 0.097 (0.095) data 0.000 (0.008) loss 1.4205 (1.3401) teacher_loss 0.1606 (0.0872) loss_zs_kd 0.0610 (0.0729) loss_oracle 0.6597 (0.6111) kd_loss 0.8995 (0.9109) acc 93.7500 (97.7344) gate/entropy 1.0552 (1.0553) gate/usage_max 0.4380 (0.4378) gate/usage_min 0.2069 (0.2071) gate/usage_std 0.0956 (0.0954) teacher/entropy 0.0683 (0.0399) teacher/usage_max 0.5266 (0.5597) teacher/usage_min 0.0444 (0.0325) teacher/usage_std 0.2082 (0.2244) nleep/row_max_mean 1490.3396 (1493.9460) nleep/row_max_std 71.7655 (59.6911) nleep/row_min_mean 1464.1157 (1465.9657) lr 9.5173e-05 eta 0:01:27
epoch [45/50] batch [60/160] time 0.099 (0.092) data 0.001 (0.005) loss 1.2878 (1.3512) teacher_loss 0.0789 (0.0939) loss_zs_kd 0.0654 (0.0748) loss_oracle 0.5549 (0.6139) kd_loss 0.8988 (0.9129) acc 96.8750 (97.6042) gate/entropy 1.0552 (1.0553) gate/usage_max 0.4380 (0.4378) gate/usage_min 0.2069 (0.2071) gate/usage_std 0.0956 (0.0955) teacher/entropy 0.0296 (0.0401) teacher/usage_max 0.5868 (0.5533) teacher/usage_min 0.0324 (0.0342) teacher/usage_std 0.2288 (0.2220) nleep/row_max_mean 1484.0195 (1493.9369) nleep/row_max_std 75.9376 (60.5380) nleep/row_min_mean 1457.3323 (1465.8466) lr 9.5173e-05 eta 0:01:23
epoch [45/50] batch [80/160] time 0.099 (0.093) data 0.000 (0.004) loss 1.3646 (1.3571) teacher_loss 0.0505 (0.0950) loss_zs_kd 0.0778 (0.0746) loss_oracle 0.6203 (0.6198) kd_loss 0.9650 (0.9149) acc 96.8750 (97.5391) gate/entropy 1.0554 (1.0553) gate/usage_max 0.4378 (0.4378) gate/usage_min 0.2071 (0.2070) gate/usage_std 0.0954 (0.0955) teacher/entropy 0.0143 (0.0378) teacher/usage_max 0.5311 (0.5555) teacher/usage_min 0.0577 (0.0344) teacher/usage_std 0.2010 (0.2223) nleep/row_max_mean 1498.9185 (1494.0169) nleep/row_max_std 24.0163 (59.6625) nleep/row_min_mean 1474.6350 (1465.9456) lr 9.5173e-05 eta 0:01:21
epoch [45/50] batch [100/160] time 0.092 (0.093) data 0.000 (0.003) loss 1.4224 (1.3602) teacher_loss 0.1487 (0.0995) loss_zs_kd 0.0728 (0.0745) loss_oracle 0.6075 (0.6195) kd_loss 0.9335 (0.9137) acc 96.8750 (97.3750) gate/entropy 1.0551 (1.0553) gate/usage_max 0.4379 (0.4378) gate/usage_min 0.2067 (0.2070) gate/usage_std 0.0957 (0.0955) teacher/entropy 0.0463 (0.0376) teacher/usage_max 0.5008 (0.5552) teacher/usage_min 0.0676 (0.0328) teacher/usage_std 0.1900 (0.2229) nleep/row_max_mean 1475.4150 (1493.9077) nleep/row_max_std 91.9345 (59.8816) nleep/row_min_mean 1450.2395 (1465.9005) lr 9.5173e-05 eta 0:01:20
epoch [45/50] batch [120/160] time 0.091 (0.093) data 0.000 (0.003) loss 1.3057 (1.3576) teacher_loss 0.0924 (0.0973) loss_zs_kd 0.0789 (0.0745) loss_oracle 0.5658 (0.6160) kd_loss 0.8910 (0.9151) acc 96.8750 (97.3958) gate/entropy 1.0553 (1.0553) gate/usage_max 0.4379 (0.4379) gate/usage_min 0.2070 (0.2070) gate/usage_std 0.0955 (0.0955) teacher/entropy 0.0511 (0.0375) teacher/usage_max 0.5566 (0.5566) teacher/usage_min 0.0462 (0.0329) teacher/usage_std 0.2132 (0.2233) nleep/row_max_mean 1490.6729 (1493.9592) nleep/row_max_std 51.5872 (59.7590) nleep/row_min_mean 1464.9904 (1466.0284) lr 9.5173e-05 eta 0:01:18
epoch [45/50] batch [140/160] time 0.090 (0.093) data 0.000 (0.002) loss 1.3361 (1.3517) teacher_loss 0.0916 (0.0937) loss_zs_kd 0.0594 (0.0734) loss_oracle 0.5683 (0.6143) kd_loss 0.9307 (0.9141) acc 100.0000 (97.5446) gate/entropy 1.0554 (1.0553) gate/usage_max 0.4376 (0.4379) gate/usage_min 0.2071 (0.2070) gate/usage_std 0.0954 (0.0955) teacher/entropy 0.0216 (0.0381) teacher/usage_max 0.5001 (0.5535) teacher/usage_min 0.0300 (0.0327) teacher/usage_std 0.2148 (0.2229) nleep/row_max_mean 1506.4662 (1494.3091) nleep/row_max_std 23.7653 (59.2868) nleep/row_min_mean 1477.6600 (1466.3769) lr 9.5173e-05 eta 0:01:16
epoch [45/50] batch [160/160] time 0.084 (0.093) data 0.000 (0.002) loss 1.4112 (1.3524) teacher_loss 0.1214 (0.0943) loss_zs_kd 0.0764 (0.0731) loss_oracle 0.5820 (0.6120) kd_loss 0.9606 (0.9156) acc 96.8750 (97.5781) gate/entropy 1.0551 (1.0553) gate/usage_max 0.4379 (0.4378) gate/usage_min 0.2067 (0.2070) gate/usage_std 0.0957 (0.0955) teacher/entropy 0.0241 (0.0372) teacher/usage_max 0.4686 (0.5517) teacher/usage_min 0.0826 (0.0325) teacher/usage_std 0.1775 (0.2227) nleep/row_max_mean 1509.3270 (1494.3666) nleep/row_max_std 33.5363 (58.9486) nleep/row_min_mean 1479.5151 (1466.4148) lr 7.0224e-05 eta 0:01:14
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,822
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,920
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 87.9%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [46/50] batch [20/160] time 0.164 (0.129) data 0.001 (0.014) loss 1.6560 (1.3942) teacher_loss 0.4262 (0.1308) loss_zs_kd 0.0706 (0.0746) loss_oracle 0.6068 (0.6184) kd_loss 0.8911 (0.9169) acc 87.5000 (96.4062) gate/entropy 1.0551 (1.0552) gate/usage_max 0.4379 (0.4379) gate/usage_min 0.2067 (0.2069) gate/usage_std 0.0957 (0.0956) teacher/entropy 0.0430 (0.0417) teacher/usage_max 0.5192 (0.5512) teacher/usage_min 0.0161 (0.0387) teacher/usage_std 0.2254 (0.2197) nleep/row_max_mean 1490.4711 (1492.4427) nleep/row_max_std 67.4223 (62.9547) nleep/row_min_mean 1461.1340 (1464.8192) lr 7.0224e-05 eta 0:01:40
epoch [46/50] batch [40/160] time 0.097 (0.111) data 0.000 (0.007) loss 1.2247 (1.3912) teacher_loss 0.0387 (0.1372) loss_zs_kd 0.0761 (0.0737) loss_oracle 0.4438 (0.6041) kd_loss 0.9261 (0.9152) acc 100.0000 (96.3281) gate/entropy 1.0551 (1.0552) gate/usage_max 0.4380 (0.4379) gate/usage_min 0.2067 (0.2068) gate/usage_std 0.0957 (0.0956) teacher/entropy 0.0480 (0.0425) teacher/usage_max 0.5222 (0.5438) teacher/usage_min 0.0538 (0.0368) teacher/usage_std 0.2017 (0.2191) nleep/row_max_mean 1498.4706 (1493.3081) nleep/row_max_std 61.6658 (60.7962) nleep/row_min_mean 1471.8206 (1465.8324) lr 7.0224e-05 eta 0:01:24
epoch [46/50] batch [60/160] time 0.099 (0.106) data 0.001 (0.005) loss 1.2848 (1.3722) teacher_loss 0.0480 (0.1182) loss_zs_kd 0.0682 (0.0722) loss_oracle 0.6171 (0.6071) kd_loss 0.8941 (0.9143) acc 96.8750 (96.7708) gate/entropy 1.0552 (1.0552) gate/usage_max 0.4378 (0.4379) gate/usage_min 0.2069 (0.2068) gate/usage_std 0.0956 (0.0956) teacher/entropy 0.0541 (0.0410) teacher/usage_max 0.4915 (0.5534) teacher/usage_min 0.0323 (0.0345) teacher/usage_std 0.2130 (0.2232) nleep/row_max_mean 1488.2480 (1493.4699) nleep/row_max_std 66.1565 (60.7809) nleep/row_min_mean 1461.3196 (1465.9264) lr 7.0224e-05 eta 0:01:18
epoch [46/50] batch [80/160] time 0.102 (0.104) data 0.000 (0.004) loss 1.3887 (1.3689) teacher_loss 0.0656 (0.1104) loss_zs_kd 0.0652 (0.0722) loss_oracle 0.6776 (0.6140) kd_loss 0.9518 (0.9153) acc 100.0000 (96.9531) gate/entropy 1.0553 (1.0552) gate/usage_max 0.4378 (0.4379) gate/usage_min 0.2070 (0.2068) gate/usage_std 0.0955 (0.0956) teacher/entropy 0.0072 (0.0404) teacher/usage_max 0.5302 (0.5540) teacher/usage_min 0.0317 (0.0349) teacher/usage_std 0.2165 (0.2231) nleep/row_max_mean 1488.7178 (1493.0142) nleep/row_max_std 53.8274 (61.3100) nleep/row_min_mean 1461.9478 (1465.4683) lr 7.0224e-05 eta 0:01:14
epoch [46/50] batch [100/160] time 0.093 (0.102) data 0.000 (0.003) loss 1.3321 (1.3616) teacher_loss 0.0432 (0.1014) loss_zs_kd 0.0661 (0.0715) loss_oracle 0.6492 (0.6127) kd_loss 0.9313 (0.9181) acc 96.8750 (97.1562) gate/entropy 1.0552 (1.0552) gate/usage_max 0.4378 (0.4378) gate/usage_min 0.2068 (0.2068) gate/usage_std 0.0956 (0.0956) teacher/entropy 0.0552 (0.0384) teacher/usage_max 0.6320 (0.5577) teacher/usage_min 0.0400 (0.0340) teacher/usage_std 0.2417 (0.2246) nleep/row_max_mean 1494.8788 (1492.9213) nleep/row_max_std 65.8873 (61.1537) nleep/row_min_mean 1466.1824 (1465.3554) lr 7.0224e-05 eta 0:01:11
epoch [46/50] batch [120/160] time 0.100 (0.101) data 0.000 (0.003) loss 1.5218 (1.3623) teacher_loss 0.2508 (0.1021) loss_zs_kd 0.0889 (0.0733) loss_oracle 0.6124 (0.6112) kd_loss 0.9203 (0.9179) acc 93.7500 (97.1615) gate/entropy 1.0551 (1.0552) gate/usage_max 0.4380 (0.4379) gate/usage_min 0.2066 (0.2068) gate/usage_std 0.0957 (0.0956) teacher/entropy 0.0634 (0.0372) teacher/usage_max 0.5465 (0.5555) teacher/usage_min 0.0601 (0.0332) teacher/usage_std 0.2031 (0.2243) nleep/row_max_mean 1493.0034 (1493.6393) nleep/row_max_std 56.7759 (60.5166) nleep/row_min_mean 1468.2273 (1466.0069) lr 7.0224e-05 eta 0:01:08
epoch [46/50] batch [140/160] time 0.098 (0.100) data 0.000 (0.002) loss 1.3018 (1.3644) teacher_loss 0.0330 (0.1053) loss_zs_kd 0.0502 (0.0729) loss_oracle 0.6289 (0.6116) kd_loss 0.9292 (0.9169) acc 100.0000 (96.9196) gate/entropy 1.0553 (1.0552) gate/usage_max 0.4379 (0.4379) gate/usage_min 0.2070 (0.2068) gate/usage_std 0.0955 (0.0956) teacher/entropy 0.0177 (0.0370) teacher/usage_max 0.5668 (0.5567) teacher/usage_min 0.0585 (0.0337) teacher/usage_std 0.2096 (0.2240) nleep/row_max_mean 1492.0771 (1493.3755) nleep/row_max_std 68.9817 (60.8774) nleep/row_min_mean 1465.0593 (1465.7258) lr 7.0224e-05 eta 0:01:05
epoch [46/50] batch [160/160] time 0.083 (0.098) data 0.000 (0.002) loss 1.2883 (1.3611) teacher_loss 0.0547 (0.1029) loss_zs_kd 0.0788 (0.0727) loss_oracle 0.6739 (0.6118) kd_loss 0.8572 (0.9160) acc 100.0000 (96.9141) gate/entropy 1.0552 (1.0552) gate/usage_max 0.4380 (0.4379) gate/usage_min 0.2068 (0.2068) gate/usage_std 0.0956 (0.0956) teacher/entropy 0.0578 (0.0367) teacher/usage_max 0.6508 (0.5573) teacher/usage_min 0.0319 (0.0333) teacher/usage_std 0.2529 (0.2245) nleep/row_max_mean 1488.9254 (1493.2704) nleep/row_max_std 66.0930 (60.3444) nleep/row_min_mean 1460.1411 (1465.6023) lr 4.8943e-05 eta 0:01:02
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,820
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,912
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.7%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [47/50] batch [20/160] time 0.089 (0.093) data 0.000 (0.018) loss 1.2514 (1.3387) teacher_loss 0.0531 (0.0809) loss_zs_kd 0.0614 (0.0718) loss_oracle 0.5309 (0.6099) kd_loss 0.9021 (0.9169) acc 96.8750 (97.3438) gate/entropy 1.0551 (1.0551) gate/usage_max 0.4380 (0.4379) gate/usage_min 0.2067 (0.2067) gate/usage_std 0.0957 (0.0957) teacher/entropy 0.0151 (0.0414) teacher/usage_max 0.5581 (0.5483) teacher/usage_min 0.0005 (0.0330) teacher/usage_std 0.2401 (0.2224) nleep/row_max_mean 1499.3300 (1489.8505) nleep/row_max_std 44.1945 (62.8385) nleep/row_min_mean 1472.9578 (1462.1977) lr 4.8943e-05 eta 0:00:57
epoch [47/50] batch [40/160] time 0.086 (0.089) data 0.000 (0.009) loss 1.3158 (1.3514) teacher_loss 0.0860 (0.0934) loss_zs_kd 0.0644 (0.0704) loss_oracle 0.5738 (0.6235) kd_loss 0.9107 (0.9111) acc 96.8750 (97.2656) gate/entropy 1.0551 (1.0551) gate/usage_max 0.4378 (0.4379) gate/usage_min 0.2066 (0.2067) gate/usage_std 0.0957 (0.0957) teacher/entropy 0.0362 (0.0428) teacher/usage_max 0.5839 (0.5415) teacher/usage_min 0.0002 (0.0335) teacher/usage_std 0.2454 (0.2205) nleep/row_max_mean 1497.6528 (1489.9111) nleep/row_max_std 48.1859 (62.0472) nleep/row_min_mean 1470.0770 (1462.3722) lr 4.8943e-05 eta 0:00:53
epoch [47/50] batch [60/160] time 0.111 (0.089) data 0.001 (0.006) loss 1.3420 (1.3525) teacher_loss 0.0429 (0.0949) loss_zs_kd 0.0665 (0.0720) loss_oracle 0.6314 (0.6231) kd_loss 0.9502 (0.9100) acc 100.0000 (97.3438) gate/entropy 1.0551 (1.0551) gate/usage_max 0.4381 (0.4379) gate/usage_min 0.2067 (0.2067) gate/usage_std 0.0957 (0.0957) teacher/entropy 0.0117 (0.0428) teacher/usage_max 0.5025 (0.5407) teacher/usage_min 0.0608 (0.0343) teacher/usage_std 0.1946 (0.2200) nleep/row_max_mean 1496.6449 (1490.2363) nleep/row_max_std 56.5560 (61.3967) nleep/row_min_mean 1467.5693 (1462.6879) lr 4.8943e-05 eta 0:00:51
epoch [47/50] batch [80/160] time 0.092 (0.088) data 0.001 (0.005) loss 1.4678 (1.3501) teacher_loss 0.1801 (0.0951) loss_zs_kd 0.0532 (0.0719) loss_oracle 0.6855 (0.6197) kd_loss 0.9184 (0.9092) acc 96.8750 (97.5000) gate/entropy 1.0551 (1.0551) gate/usage_max 0.4378 (0.4379) gate/usage_min 0.2066 (0.2067) gate/usage_std 0.0957 (0.0957) teacher/entropy 0.0614 (0.0426) teacher/usage_max 0.5739 (0.5448) teacher/usage_min 0.0480 (0.0343) teacher/usage_std 0.2170 (0.2207) nleep/row_max_mean 1484.5416 (1491.0592) nleep/row_max_std 77.0158 (58.8377) nleep/row_min_mean 1459.5051 (1463.5347) lr 4.8943e-05 eta 0:00:49
epoch [47/50] batch [100/160] time 0.114 (0.091) data 0.001 (0.004) loss 1.3502 (1.3542) teacher_loss 0.0779 (0.0966) loss_zs_kd 0.0714 (0.0745) loss_oracle 0.6389 (0.6185) kd_loss 0.9172 (0.9111) acc 100.0000 (97.5000) gate/entropy 1.0550 (1.0551) gate/usage_max 0.4381 (0.4379) gate/usage_min 0.2066 (0.2067) gate/usage_std 0.0958 (0.0957) teacher/entropy 0.0336 (0.0413) teacher/usage_max 0.5013 (0.5459) teacher/usage_min 0.0283 (0.0348) teacher/usage_std 0.2161 (0.2205) nleep/row_max_mean 1493.5907 (1490.5105) nleep/row_max_std 64.6735 (59.5062) nleep/row_min_mean 1466.9905 (1463.1457) lr 4.8943e-05 eta 0:00:48
epoch [47/50] batch [120/160] time 0.113 (0.093) data 0.001 (0.003) loss 1.4856 (1.3553) teacher_loss 0.1633 (0.0945) loss_zs_kd 0.0966 (0.0747) loss_oracle 0.6807 (0.6197) kd_loss 0.9337 (0.9136) acc 96.8750 (97.5260) gate/entropy 1.0549 (1.0551) gate/usage_max 0.4381 (0.4379) gate/usage_min 0.2064 (0.2067) gate/usage_std 0.0959 (0.0957) teacher/entropy 0.0012 (0.0400) teacher/usage_max 0.5311 (0.5438) teacher/usage_min 0.0002 (0.0361) teacher/usage_std 0.2369 (0.2192) nleep/row_max_mean 1503.0989 (1490.5566) nleep/row_max_std 42.3865 (59.6252) nleep/row_min_mean 1472.0585 (1463.1757) lr 4.8943e-05 eta 0:00:48
epoch [47/50] batch [140/160] time 0.098 (0.095) data 0.000 (0.003) loss 1.2876 (1.3535) teacher_loss 0.0469 (0.0934) loss_zs_kd 0.0927 (0.0749) loss_oracle 0.5713 (0.6162) kd_loss 0.9087 (0.9146) acc 100.0000 (97.5223) gate/entropy 1.0550 (1.0551) gate/usage_max 0.4381 (0.4379) gate/usage_min 0.2066 (0.2066) gate/usage_std 0.0958 (0.0957) teacher/entropy 0.0533 (0.0396) teacher/usage_max 0.4829 (0.5452) teacher/usage_min 0.0486 (0.0353) teacher/usage_std 0.2014 (0.2202) nleep/row_max_mean 1490.8320 (1491.1697) nleep/row_max_std 64.6577 (59.2518) nleep/row_min_mean 1465.3867 (1463.8314) lr 4.8943e-05 eta 0:00:47
epoch [47/50] batch [160/160] time 0.080 (0.097) data 0.000 (0.003) loss 1.5154 (1.3569) teacher_loss 0.2580 (0.0974) loss_zs_kd 0.0823 (0.0746) loss_oracle 0.5728 (0.6148) kd_loss 0.9299 (0.9147) acc 90.6250 (97.4023) gate/entropy 1.0553 (1.0551) gate/usage_max 0.4376 (0.4379) gate/usage_min 0.2068 (0.2066) gate/usage_std 0.0955 (0.0957) teacher/entropy 0.0483 (0.0403) teacher/usage_max 0.5881 (0.5471) teacher/usage_min 0.0412 (0.0363) teacher/usage_std 0.2248 (0.2205) nleep/row_max_mean 1477.4458 (1491.3058) nleep/row_max_std 73.9310 (59.5574) nleep/row_min_mean 1450.6689 (1463.9334) lr 3.1417e-05 eta 0:00:46
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,824
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,917
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 87.8%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [48/50] batch [20/160] time 0.095 (0.120) data 0.000 (0.023) loss 1.3396 (1.3971) teacher_loss 0.0569 (0.1192) loss_zs_kd 0.0740 (0.0746) loss_oracle 0.5842 (0.6235) kd_loss 0.9536 (0.9289) acc 100.0000 (96.7188) gate/entropy 1.0552 (1.0550) gate/usage_max 0.4379 (0.4380) gate/usage_min 0.2068 (0.2065) gate/usage_std 0.0956 (0.0958) teacher/entropy 0.0230 (0.0350) teacher/usage_max 0.6144 (0.5422) teacher/usage_min 0.0314 (0.0436) teacher/usage_std 0.2385 (0.2149) nleep/row_max_mean 1498.9259 (1490.1774) nleep/row_max_std 42.6492 (65.4123) nleep/row_min_mean 1473.8267 (1462.7568) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [40/160] time 0.098 (0.107) data 0.000 (0.011) loss 1.3186 (1.3725) teacher_loss 0.0459 (0.1030) loss_zs_kd 0.0840 (0.0752) loss_oracle 0.5750 (0.6118) kd_loss 0.9431 (0.9260) acc 100.0000 (97.4219) gate/entropy 1.0550 (1.0550) gate/usage_max 0.4379 (0.4380) gate/usage_min 0.2065 (0.2065) gate/usage_std 0.0958 (0.0958) teacher/entropy 0.0243 (0.0349) teacher/usage_max 0.5637 (0.5523) teacher/usage_min 0.0340 (0.0406) teacher/usage_std 0.2217 (0.2185) nleep/row_max_mean 1497.0129 (1492.7636) nleep/row_max_std 65.9249 (62.6306) nleep/row_min_mean 1466.9043 (1465.0116) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [60/160] time 0.095 (0.104) data 0.001 (0.008) loss 1.3356 (1.3649) teacher_loss 0.1190 (0.1036) loss_zs_kd 0.0988 (0.0739) loss_oracle 0.5688 (0.6059) kd_loss 0.8828 (0.9214) acc 93.7500 (97.1354) gate/entropy 1.0548 (1.0550) gate/usage_max 0.4381 (0.4380) gate/usage_min 0.2061 (0.2065) gate/usage_std 0.0960 (0.0958) teacher/entropy 0.0746 (0.0373) teacher/usage_max 0.4956 (0.5543) teacher/usage_min 0.0514 (0.0382) teacher/usage_std 0.2001 (0.2207) nleep/row_max_mean 1501.5181 (1493.0628) nleep/row_max_std 69.8737 (61.4961) nleep/row_min_mean 1473.7244 (1465.3916) lr 3.1417e-05 eta 0:00:43
epoch [48/50] batch [80/160] time 0.094 (0.102) data 0.000 (0.006) loss 1.2985 (1.3607) teacher_loss 0.0560 (0.1009) loss_zs_kd 0.0804 (0.0727) loss_oracle 0.6028 (0.6084) kd_loss 0.9009 (0.9193) acc 100.0000 (97.1875) gate/entropy 1.0550 (1.0550) gate/usage_max 0.4381 (0.4380) gate/usage_min 0.2065 (0.2065) gate/usage_std 0.0958 (0.0958) teacher/entropy 0.0022 (0.0382) teacher/usage_max 0.6248 (0.5458) teacher/usage_min 0.0001 (0.0396) teacher/usage_std 0.2567 (0.2178) nleep/row_max_mean 1505.9609 (1493.4404) nleep/row_max_std 24.1872 (60.8271) nleep/row_min_mean 1475.5411 (1465.7199) lr 3.1417e-05 eta 0:00:40
epoch [48/50] batch [100/160] time 0.089 (0.100) data 0.000 (0.005) loss 1.3274 (1.3546) teacher_loss 0.1185 (0.0954) loss_zs_kd 0.0760 (0.0726) loss_oracle 0.5127 (0.6101) kd_loss 0.9145 (0.9179) acc 96.8750 (97.4688) gate/entropy 1.0550 (1.0550) gate/usage_max 0.4379 (0.4380) gate/usage_min 0.2065 (0.2065) gate/usage_std 0.0958 (0.0958) teacher/entropy 0.0405 (0.0371) teacher/usage_max 0.5133 (0.5485) teacher/usage_min 0.0316 (0.0372) teacher/usage_std 0.2147 (0.2198) nleep/row_max_mean 1504.5745 (1494.5214) nleep/row_max_std 48.2823 (59.4094) nleep/row_min_mean 1477.1926 (1466.6806) lr 3.1417e-05 eta 0:00:38
epoch [48/50] batch [120/160] time 0.087 (0.099) data 0.000 (0.004) loss 1.2528 (1.3521) teacher_loss 0.0232 (0.0922) loss_zs_kd 0.0673 (0.0724) loss_oracle 0.5639 (0.6131) kd_loss 0.9140 (0.9171) acc 100.0000 (97.5521) gate/entropy 1.0549 (1.0550) gate/usage_max 0.4381 (0.4380) gate/usage_min 0.2063 (0.2065) gate/usage_std 0.0959 (0.0958) teacher/entropy 0.0427 (0.0379) teacher/usage_max 0.5705 (0.5474) teacher/usage_min 0.0183 (0.0369) teacher/usage_std 0.2321 (0.2195) nleep/row_max_mean 1516.6196 (1493.7745) nleep/row_max_std 22.8477 (59.8660) nleep/row_min_mean 1487.0505 (1465.9811) lr 3.1417e-05 eta 0:00:35
epoch [48/50] batch [140/160] time 0.095 (0.098) data 0.000 (0.003) loss 1.4082 (1.3522) teacher_loss 0.1058 (0.0925) loss_zs_kd 0.0827 (0.0724) loss_oracle 0.6414 (0.6129) kd_loss 0.9403 (0.9170) acc 96.8750 (97.5446) gate/entropy 1.0550 (1.0550) gate/usage_max 0.4379 (0.4380) gate/usage_min 0.2065 (0.2065) gate/usage_std 0.0958 (0.0958) teacher/entropy 0.0685 (0.0379) teacher/usage_max 0.4861 (0.5476) teacher/usage_min 0.1106 (0.0363) teacher/usage_std 0.1611 (0.2199) nleep/row_max_mean 1478.7925 (1493.5542) nleep/row_max_std 79.0655 (60.2019) nleep/row_min_mean 1454.8564 (1465.7876) lr 3.1417e-05 eta 0:00:33
epoch [48/50] batch [160/160] time 0.076 (0.097) data 0.000 (0.003) loss 1.3935 (1.3542) teacher_loss 0.1379 (0.0960) loss_zs_kd 0.0765 (0.0725) loss_oracle 0.5664 (0.6116) kd_loss 0.9342 (0.9162) acc 93.7500 (97.4219) gate/entropy 1.0549 (1.0550) gate/usage_max 0.4381 (0.4380) gate/usage_min 0.2064 (0.2065) gate/usage_std 0.0959 (0.0958) teacher/entropy 0.0231 (0.0394) teacher/usage_max 0.5619 (0.5456) teacher/usage_min 0.0208 (0.0380) teacher/usage_std 0.2287 (0.2186) nleep/row_max_mean 1493.4500 (1493.5961) nleep/row_max_std 61.5095 (60.3067) nleep/row_min_mean 1466.3101 (1465.7956) lr 1.7713e-05 eta 0:00:30
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,825
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,916
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 87.8%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [49/50] batch [20/160] time 0.093 (0.107) data 0.000 (0.013) loss 1.4517 (1.3317) teacher_loss 0.1942 (0.0916) loss_zs_kd 0.0862 (0.0692) loss_oracle 0.6021 (0.6051) kd_loss 0.9134 (0.9030) acc 96.8750 (97.9688) gate/entropy 1.0549 (1.0550) gate/usage_max 0.4381 (0.4380) gate/usage_min 0.2063 (0.2065) gate/usage_std 0.0959 (0.0958) teacher/entropy 0.0437 (0.0539) teacher/usage_max 0.5533 (0.5328) teacher/usage_min 0.0225 (0.0355) teacher/usage_std 0.2260 (0.2174) nleep/row_max_mean 1482.8832 (1492.1574) nleep/row_max_std 76.3810 (61.7180) nleep/row_min_mean 1456.4935 (1464.8910) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [40/160] time 0.098 (0.103) data 0.000 (0.007) loss 1.2974 (1.3548) teacher_loss 0.0377 (0.0978) loss_zs_kd 0.0818 (0.0716) loss_oracle 0.6041 (0.6094) kd_loss 0.9167 (0.9165) acc 100.0000 (97.6562) gate/entropy 1.0551 (1.0550) gate/usage_max 0.4379 (0.4380) gate/usage_min 0.2066 (0.2064) gate/usage_std 0.0957 (0.0958) teacher/entropy 0.0312 (0.0460) teacher/usage_max 0.5822 (0.5359) teacher/usage_min 0.0020 (0.0440) teacher/usage_std 0.2439 (0.2135) nleep/row_max_mean 1495.3982 (1492.7382) nleep/row_max_std 49.8247 (62.8006) nleep/row_min_mean 1466.6219 (1465.1317) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [60/160] time 0.116 (0.103) data 0.002 (0.004) loss 1.4945 (1.3503) teacher_loss 0.2547 (0.0939) loss_zs_kd 0.0865 (0.0720) loss_oracle 0.5805 (0.6075) kd_loss 0.9063 (0.9167) acc 93.7500 (97.6562) gate/entropy 1.0549 (1.0550) gate/usage_max 0.4381 (0.4380) gate/usage_min 0.2064 (0.2065) gate/usage_std 0.0959 (0.0958) teacher/entropy 0.0575 (0.0426) teacher/usage_max 0.5346 (0.5500) teacher/usage_min 0.0364 (0.0421) teacher/usage_std 0.2143 (0.2185) nleep/row_max_mean 1480.6476 (1492.9521) nleep/row_max_std 71.0570 (61.4193) nleep/row_min_mean 1455.7520 (1465.1866) lr 1.7713e-05 eta 0:00:26
epoch [49/50] batch [80/160] time 0.096 (0.103) data 0.000 (0.003) loss 1.2469 (1.3450) teacher_loss 0.0656 (0.0950) loss_zs_kd 0.0593 (0.0730) loss_oracle 0.5444 (0.6018) kd_loss 0.8794 (0.9127) acc 96.8750 (97.4219) gate/entropy 1.0549 (1.0550) gate/usage_max 0.4382 (0.4380) gate/usage_min 0.2065 (0.2065) gate/usage_std 0.0959 (0.0958) teacher/entropy 0.0497 (0.0433) teacher/usage_max 0.5118 (0.5542) teacher/usage_min 0.0049 (0.0388) teacher/usage_std 0.2325 (0.2213) nleep/row_max_mean 1508.3784 (1493.3315) nleep/row_max_std 24.9389 (58.1701) nleep/row_min_mean 1481.7021 (1465.5525) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [100/160] time 0.096 (0.101) data 0.000 (0.003) loss 1.3982 (1.3529) teacher_loss 0.1292 (0.1019) loss_zs_kd 0.0879 (0.0727) loss_oracle 0.6833 (0.6042) kd_loss 0.8834 (0.9126) acc 93.7500 (97.1562) gate/entropy 1.0550 (1.0550) gate/usage_max 0.4380 (0.4380) gate/usage_min 0.2064 (0.2065) gate/usage_std 0.0958 (0.0958) teacher/entropy 0.0142 (0.0413) teacher/usage_max 0.6533 (0.5540) teacher/usage_min 0.0010 (0.0378) teacher/usage_std 0.2664 (0.2216) nleep/row_max_mean 1496.0999 (1493.6086) nleep/row_max_std 52.3383 (57.2216) nleep/row_min_mean 1469.0139 (1465.9632) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [120/160] time 0.097 (0.101) data 0.000 (0.002) loss 1.4941 (1.3578) teacher_loss 0.1145 (0.1022) loss_zs_kd 0.0658 (0.0725) loss_oracle 0.8140 (0.6094) kd_loss 0.9396 (0.9146) acc 96.8750 (97.1615) gate/entropy 1.0551 (1.0550) gate/usage_max 0.4378 (0.4380) gate/usage_min 0.2067 (0.2065) gate/usage_std 0.0957 (0.0958) teacher/entropy 0.0479 (0.0399) teacher/usage_max 0.4983 (0.5554) teacher/usage_min 0.0782 (0.0377) teacher/usage_std 0.1830 (0.2217) nleep/row_max_mean 1472.1315 (1493.1310) nleep/row_max_std 89.4134 (57.7583) nleep/row_min_mean 1443.7844 (1465.4953) lr 1.7713e-05 eta 0:00:20
epoch [49/50] batch [140/160] time 0.095 (0.100) data 0.000 (0.002) loss 1.3799 (1.3568) teacher_loss 0.1223 (0.1024) loss_zs_kd 0.0779 (0.0723) loss_oracle 0.6276 (0.6066) kd_loss 0.9048 (0.9149) acc 96.8750 (97.0536) gate/entropy 1.0548 (1.0550) gate/usage_max 0.4381 (0.4380) gate/usage_min 0.2061 (0.2065) gate/usage_std 0.0960 (0.0958) teacher/entropy 0.0434 (0.0402) teacher/usage_max 0.5212 (0.5560) teacher/usage_min 0.0440 (0.0379) teacher/usage_std 0.2076 (0.2218) nleep/row_max_mean 1494.0275 (1493.0883) nleep/row_max_std 64.5012 (57.7187) nleep/row_min_mean 1465.6202 (1465.4703) lr 1.7713e-05 eta 0:00:17
epoch [49/50] batch [160/160] time 0.086 (0.099) data 0.000 (0.002) loss 1.3894 (1.3574) teacher_loss 0.1623 (0.1015) loss_zs_kd 0.0875 (0.0724) loss_oracle 0.5191 (0.6066) kd_loss 0.9237 (0.9165) acc 93.7500 (97.1094) gate/entropy 1.0551 (1.0550) gate/usage_max 0.4378 (0.4380) gate/usage_min 0.2065 (0.2065) gate/usage_std 0.0957 (0.0958) teacher/entropy 0.0589 (0.0391) teacher/usage_max 0.6312 (0.5543) teacher/usage_min 0.0355 (0.0381) teacher/usage_std 0.2432 (0.2213) nleep/row_max_mean 1486.6184 (1493.0912) nleep/row_max_std 57.1374 (57.3501) nleep/row_min_mean 1458.8048 (1465.5066) lr 7.8853e-06 eta 0:00:15
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,826
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,915
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.8%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
epoch [50/50] batch [20/160] time 0.098 (0.107) data 0.001 (0.015) loss 1.4468 (1.3572) teacher_loss 0.2221 (0.1122) loss_zs_kd 0.0602 (0.0722) loss_oracle 0.5905 (0.6119) kd_loss 0.8994 (0.9029) acc 93.7500 (96.2500) gate/entropy 1.0550 (1.0550) gate/usage_max 0.4378 (0.4379) gate/usage_min 0.2064 (0.2065) gate/usage_std 0.0958 (0.0958) teacher/entropy 0.0271 (0.0539) teacher/usage_max 0.5098 (0.5534) teacher/usage_min 0.0002 (0.0357) teacher/usage_std 0.2357 (0.2230) nleep/row_max_mean 1484.1328 (1489.5564) nleep/row_max_std 65.2704 (60.3432) nleep/row_min_mean 1457.5427 (1462.3848) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [40/160] time 0.106 (0.099) data 0.000 (0.008) loss 1.3048 (1.3532) teacher_loss 0.0990 (0.1011) loss_zs_kd 0.0952 (0.0720) loss_oracle 0.5754 (0.6119) kd_loss 0.8705 (0.9102) acc 93.7500 (97.2656) gate/entropy 1.0549 (1.0550) gate/usage_max 0.4380 (0.4379) gate/usage_min 0.2064 (0.2065) gate/usage_std 0.0959 (0.0958) teacher/entropy 0.0417 (0.0440) teacher/usage_max 0.6663 (0.5506) teacher/usage_min 0.0324 (0.0367) teacher/usage_std 0.2598 (0.2218) nleep/row_max_mean 1502.4824 (1491.1444) nleep/row_max_std 31.4521 (58.4684) nleep/row_min_mean 1471.0667 (1463.4288) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [60/160] time 0.087 (0.096) data 0.001 (0.005) loss 1.4933 (1.3507) teacher_loss 0.1960 (0.0948) loss_zs_kd 0.0626 (0.0717) loss_oracle 0.6483 (0.6154) kd_loss 0.9418 (0.9123) acc 93.7500 (97.6042) gate/entropy 1.0548 (1.0550) gate/usage_max 0.4381 (0.4380) gate/usage_min 0.2063 (0.2065) gate/usage_std 0.0960 (0.0958) teacher/entropy 0.0376 (0.0419) teacher/usage_max 0.5327 (0.5460) teacher/usage_min 0.0586 (0.0360) teacher/usage_std 0.2008 (0.2206) nleep/row_max_mean 1472.7871 (1491.1196) nleep/row_max_std 92.4015 (58.8622) nleep/row_min_mean 1445.1964 (1463.5580) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [80/160] time 0.107 (0.095) data 0.000 (0.004) loss 1.2754 (1.3516) teacher_loss 0.0533 (0.0969) loss_zs_kd 0.0743 (0.0723) loss_oracle 0.5628 (0.6142) kd_loss 0.9035 (0.9115) acc 100.0000 (97.4219) gate/entropy 1.0550 (1.0550) gate/usage_max 0.4378 (0.4380) gate/usage_min 0.2065 (0.2065) gate/usage_std 0.0957 (0.0958) teacher/entropy 0.0617 (0.0416) teacher/usage_max 0.5638 (0.5451) teacher/usage_min 0.0301 (0.0350) teacher/usage_std 0.2239 (0.2209) nleep/row_max_mean 1480.9189 (1491.0305) nleep/row_max_std 72.1214 (59.0882) nleep/row_min_mean 1455.2166 (1463.4923) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [100/160] time 0.095 (0.095) data 0.000 (0.003) loss 1.3806 (1.3498) teacher_loss 0.1309 (0.0954) loss_zs_kd 0.0454 (0.0725) loss_oracle 0.6322 (0.6123) kd_loss 0.9108 (0.9120) acc 93.7500 (97.4375) gate/entropy 1.0548 (1.0550) gate/usage_max 0.4380 (0.4380) gate/usage_min 0.2062 (0.2065) gate/usage_std 0.0960 (0.0958) teacher/entropy 0.0465 (0.0411) teacher/usage_max 0.5121 (0.5446) teacher/usage_min 0.0575 (0.0360) teacher/usage_std 0.1979 (0.2200) nleep/row_max_mean 1492.7144 (1491.4180) nleep/row_max_std 71.2338 (59.0734) nleep/row_min_mean 1463.1287 (1463.8729) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [120/160] time 0.094 (0.095) data 0.000 (0.003) loss 1.3503 (1.3478) teacher_loss 0.0353 (0.0949) loss_zs_kd 0.0599 (0.0725) loss_oracle 0.6487 (0.6080) kd_loss 0.9607 (0.9127) acc 100.0000 (97.5260) gate/entropy 1.0552 (1.0550) gate/usage_max 0.4376 (0.4380) gate/usage_min 0.2066 (0.2065) gate/usage_std 0.0956 (0.0958) teacher/entropy 0.0249 (0.0405) teacher/usage_max 0.4701 (0.5454) teacher/usage_min 0.0928 (0.0363) teacher/usage_std 0.1706 (0.2200) nleep/row_max_mean 1476.0748 (1491.7408) nleep/row_max_std 80.7878 (58.9001) nleep/row_min_mean 1448.9182 (1464.1640) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [140/160] time 0.099 (0.095) data 0.000 (0.002) loss 1.2947 (1.3463) teacher_loss 0.0264 (0.0926) loss_zs_kd 0.0702 (0.0727) loss_oracle 0.5272 (0.6075) kd_loss 0.9696 (0.9135) acc 100.0000 (97.5223) gate/entropy 1.0551 (1.0550) gate/usage_max 0.4377 (0.4380) gate/usage_min 0.2066 (0.2064) gate/usage_std 0.0957 (0.0958) teacher/entropy 0.0177 (0.0407) teacher/usage_max 0.7775 (0.5472) teacher/usage_min 0.0010 (0.0361) teacher/usage_std 0.3267 (0.2209) nleep/row_max_mean 1492.7173 (1491.9310) nleep/row_max_std 53.0114 (58.2931) nleep/row_min_mean 1467.2007 (1464.4780) lr 7.8853e-06 eta 0:00:01
epoch [50/50] batch [160/160] time 0.091 (0.095) data 0.000 (0.002) loss 1.3089 (1.3476) teacher_loss 0.0347 (0.0936) loss_zs_kd 0.0823 (0.0723) loss_oracle 0.6667 (0.6106) kd_loss 0.8997 (0.9125) acc 100.0000 (97.4609) gate/entropy 1.0549 (1.0550) gate/usage_max 0.4380 (0.4380) gate/usage_min 0.2063 (0.2064) gate/usage_std 0.0959 (0.0958) teacher/entropy 0.0513 (0.0409) teacher/usage_max 0.5398 (0.5487) teacher/usage_min 0.0561 (0.0358) teacher/usage_std 0.2037 (0.2212) nleep/row_max_mean 1482.4222 (1491.9070) nleep/row_max_std 80.9079 (58.2532) nleep/row_min_mean 1455.0167 (1464.4070) lr 1.9733e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,823
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,916
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 87.9%
******* Domain p best val acc:      83.6%, epoch: 19 *******
******* Domain p best val test acc: 89.0%, epoch: 19 *******
******* Domain p best test acc:     89.3%, epoch: 17 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_1/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:21:57

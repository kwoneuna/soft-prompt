Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------------------------
Dataset    SPG_VLCS
Source     ['labelme', 'pascal', 'sun']
Target     ['caltech']
# classes  5
# train_x  6,519
# val      2,795
# test     1,415
---------  ----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_3/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_3/warmup_1/tensorboard)
epoch [1/50] batch [20/203] time 0.107 (0.144) data 0.001 (0.023) loss 0.9283 (1.3531) teacher_loss 0.4021 (0.6988) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0001 (-0.0000) kd_loss 0.5262 (0.6543) acc 87.5000 (74.0625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3296 (0.3296) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.5737 (0.4435) teacher/usage_max 0.4649 (0.4145) teacher/usage_min 0.1918 (0.2577) teacher/usage_std 0.1117 (0.0674) nleep/row_max_mean 1526.1046 (1529.2627) nleep/row_max_std 46.4920 (52.1768) nleep/row_min_mean 1520.6577 (1520.0555) lr 1.0000e-05 eta 0:24:23
epoch [1/50] batch [40/203] time 0.093 (0.123) data 0.000 (0.012) loss 1.0596 (1.2869) teacher_loss 0.6217 (0.7195) loss_zs_kd 0.0004 (0.0001) loss_oracle 0.0010 (0.0003) kd_loss 0.4373 (0.5672) acc 78.1250 (74.2188) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3297 (0.3296) gate/usage_std 0.0031 (0.0032) teacher/entropy 0.6615 (0.5309) teacher/usage_max 0.4162 (0.4077) teacher/usage_min 0.2044 (0.2618) teacher/usage_std 0.0924 (0.0628) nleep/row_max_mean 1519.0610 (1527.9973) nleep/row_max_std 45.3796 (49.2281) nleep/row_min_mean 1514.7511 (1521.2272) lr 1.0000e-05 eta 0:20:42
epoch [1/50] batch [60/203] time 0.083 (0.113) data 0.000 (0.008) loss 1.0819 (1.2511) teacher_loss 0.7468 (0.7440) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0010 (0.0005) kd_loss 0.3344 (0.5068) acc 71.8750 (74.2708) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3296 (0.3296) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.7658 (0.5916) teacher/usage_max 0.4329 (0.4013) teacher/usage_min 0.2784 (0.2669) teacher/usage_std 0.0706 (0.0578) nleep/row_max_mean 1542.3960 (1529.3081) nleep/row_max_std 37.3386 (46.8327) nleep/row_min_mean 1539.7419 (1523.7383) lr 1.0000e-05 eta 0:19:00
epoch [1/50] batch [80/203] time 0.170 (0.111) data 0.001 (0.006) loss 1.2232 (1.1860) teacher_loss 0.9290 (0.7303) loss_zs_kd 0.0007 (0.0002) loss_oracle 0.0013 (0.0007) kd_loss 0.2933 (0.4552) acc 71.8750 (74.5312) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3295 (0.3296) gate/usage_std 0.0033 (0.0032) teacher/entropy 0.8053 (0.6432) teacher/usage_max 0.3488 (0.3965) teacher/usage_min 0.3043 (0.2722) teacher/usage_std 0.0205 (0.0536) nleep/row_max_mean 1531.8826 (1530.0027) nleep/row_max_std 39.4875 (44.9191) nleep/row_min_mean 1529.7301 (1525.2398) lr 1.0000e-05 eta 0:18:33
epoch [1/50] batch [100/203] time 0.111 (0.109) data 0.001 (0.005) loss 1.2030 (1.1450) teacher_loss 0.9892 (0.7325) loss_zs_kd 0.0008 (0.0003) loss_oracle 0.0023 (0.0008) kd_loss 0.2122 (0.4119) acc 71.8750 (74.5625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3296 (0.3296) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.8878 (0.6865) teacher/usage_max 0.4502 (0.3940) teacher/usage_min 0.2424 (0.2749) teacher/usage_std 0.0868 (0.0511) nleep/row_max_mean 1513.5486 (1529.9276) nleep/row_max_std 54.6747 (44.8753) nleep/row_min_mean 1511.8962 (1525.7423) lr 1.0000e-05 eta 0:18:19
epoch [1/50] batch [120/203] time 0.106 (0.108) data 0.000 (0.004) loss 0.8773 (1.1129) teacher_loss 0.7128 (0.7394) loss_zs_kd 0.0013 (0.0005) loss_oracle 0.0029 (0.0010) kd_loss 0.1624 (0.3728) acc 71.8750 (73.7500) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3295 (0.3296) gate/usage_std 0.0033 (0.0032) teacher/entropy 0.9366 (0.7257) teacher/usage_max 0.3667 (0.3895) teacher/usage_min 0.2922 (0.2785) teacher/usage_std 0.0309 (0.0476) nleep/row_max_mean 1522.3059 (1529.3229) nleep/row_max_std 47.2452 (44.9936) nleep/row_min_mean 1520.9194 (1525.5841) lr 1.0000e-05 eta 0:18:04
epoch [1/50] batch [140/203] time 0.090 (0.107) data 0.000 (0.004) loss 0.7568 (1.0737) teacher_loss 0.6425 (0.7343) loss_zs_kd 0.0006 (0.0005) loss_oracle 0.0026 (0.0013) kd_loss 0.1126 (0.3385) acc 84.3750 (74.0402) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3376 (0.3374) gate/usage_min 0.3294 (0.3296) gate/usage_std 0.0034 (0.0032) teacher/entropy 0.9858 (0.7600) teacher/usage_max 0.3610 (0.3868) teacher/usage_min 0.3004 (0.2816) teacher/usage_std 0.0250 (0.0451) nleep/row_max_mean 1527.6816 (1529.1876) nleep/row_max_std 61.2879 (45.6321) nleep/row_min_mean 1526.5618 (1525.8099) lr 1.0000e-05 eta 0:17:55
epoch [1/50] batch [160/203] time 0.106 (0.106) data 0.000 (0.003) loss 0.8169 (1.0367) teacher_loss 0.7325 (0.7258) loss_zs_kd 0.0019 (0.0006) loss_oracle 0.0034 (0.0015) kd_loss 0.0817 (0.3098) acc 75.0000 (74.2969) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3296 (0.3296) gate/usage_std 0.0032 (0.0032) teacher/entropy 1.0178 (0.7887) teacher/usage_max 0.3675 (0.3844) teacher/usage_min 0.2845 (0.2841) teacher/usage_std 0.0354 (0.0430) nleep/row_max_mean 1511.8472 (1528.2125) nleep/row_max_std 43.0091 (46.6803) nleep/row_min_mean 1511.0398 (1525.1271) lr 1.0000e-05 eta 0:17:37
epoch [1/50] batch [180/203] time 0.074 (0.104) data 0.000 (0.003) loss 0.5740 (1.0110) teacher_loss 0.4781 (0.7244) loss_zs_kd 0.0017 (0.0007) loss_oracle 0.0046 (0.0018) kd_loss 0.0928 (0.2854) acc 90.6250 (74.2882) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3296 (0.3296) gate/usage_std 0.0032 (0.0032) teacher/entropy 1.0054 (0.8132) teacher/usage_max 0.3750 (0.3818) teacher/usage_min 0.2730 (0.2859) teacher/usage_std 0.0437 (0.0411) nleep/row_max_mean 1521.6428 (1527.4927) nleep/row_max_std 56.7852 (48.0373) nleep/row_min_mean 1520.6484 (1524.6476) lr 1.0000e-05 eta 0:17:15
epoch [1/50] batch [200/203] time 0.092 (0.102) data 0.000 (0.003) loss 0.6276 (0.9911) teacher_loss 0.5494 (0.7246) loss_zs_kd 0.0017 (0.0009) loss_oracle 0.0045 (0.0021) kd_loss 0.0751 (0.2650) acc 75.0000 (74.2188) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3373 (0.3374) gate/usage_min 0.3296 (0.3296) gate/usage_std 0.0031 (0.0032) teacher/entropy 1.0239 (0.8336) teacher/usage_max 0.3460 (0.3798) teacher/usage_min 0.3269 (0.2878) teacher/usage_std 0.0089 (0.0394) nleep/row_max_mean 1510.5496 (1527.1339) nleep/row_max_std 68.2505 (48.8262) nleep/row_min_mean 1509.6838 (1524.4850) lr 1.0000e-05 eta 0:16:56
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,196
* accuracy: 78.6%
* error: 21.4%
* macro_f1: 82.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      78.6%, epoch: 1 *******
******* Domain c best val test acc: 100.0%, epoch: 1 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [2/50] batch [20/203] time 0.076 (0.096) data 0.000 (0.014) loss 1.1476 (0.9008) teacher_loss 0.6728 (0.6449) loss_zs_kd 0.0153 (0.0135) loss_oracle 0.2110 (0.1277) kd_loss 0.3616 (0.1853) acc 81.2500 (78.7500) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3373 (0.3373) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0031 (0.0031) teacher/entropy 0.7401 (0.9142) teacher/usage_max 0.4190 (0.4311) teacher/usage_min 0.1665 (0.2521) teacher/usage_std 0.1180 (0.0773) nleep/row_max_mean 1532.2998 (1524.7170) nleep/row_max_std 62.2731 (59.8722) nleep/row_min_mean 1530.2111 (1523.4062) lr 2.0000e-03 eta 0:15:49
epoch [2/50] batch [40/203] time 0.087 (0.089) data 0.000 (0.007) loss 1.2858 (1.0132) teacher_loss 0.3177 (0.5185) loss_zs_kd 0.0486 (0.0242) loss_oracle 0.3716 (0.2152) kd_loss 0.7581 (0.3750) acc 93.7500 (85.0781) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3362 (0.3370) gate/usage_min 0.3302 (0.3299) gate/usage_std 0.0024 (0.0029) teacher/entropy 0.3439 (0.7255) teacher/usage_max 0.4779 (0.4526) teacher/usage_min 0.0827 (0.1886) teacher/usage_std 0.1779 (0.1150) nleep/row_max_mean 1539.0901 (1527.4552) nleep/row_max_std 32.6242 (58.1567) nleep/row_min_mean 1534.6130 (1525.1775) lr 2.0000e-03 eta 0:14:46
epoch [2/50] batch [60/203] time 0.078 (0.088) data 0.000 (0.005) loss 1.5272 (1.1104) teacher_loss 0.4520 (0.4500) loss_zs_kd 0.1004 (0.0348) loss_oracle 0.4637 (0.2809) kd_loss 0.7931 (0.5026) acc 87.5000 (87.5000) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3346 (0.3365) gate/usage_min 0.3319 (0.3303) gate/usage_std 0.0011 (0.0025) teacher/entropy 0.3076 (0.5983) teacher/usage_max 0.6359 (0.4903) teacher/usage_min 0.0538 (0.1523) teacher/usage_std 0.2382 (0.1456) nleep/row_max_mean 1541.3307 (1526.5019) nleep/row_max_std 53.1272 (60.2360) nleep/row_min_mean 1535.1173 (1523.2551) lr 2.0000e-03 eta 0:14:28
epoch [2/50] batch [80/203] time 0.088 (0.090) data 0.000 (0.004) loss 1.4191 (1.1744) teacher_loss 0.4668 (0.4326) loss_zs_kd 0.0386 (0.0385) loss_oracle 0.3317 (0.3190) kd_loss 0.7672 (0.5630) acc 81.2500 (87.8516) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3348 (0.3359) gate/usage_min 0.3320 (0.3308) gate/usage_std 0.0012 (0.0021) teacher/entropy 0.3289 (0.5374) teacher/usage_max 0.7076 (0.5326) teacher/usage_min 0.0862 (0.1384) teacher/usage_std 0.2692 (0.1694) nleep/row_max_mean 1532.4185 (1526.5383) nleep/row_max_std 60.9843 (60.1447) nleep/row_min_mean 1524.8140 (1522.4614) lr 2.0000e-03 eta 0:14:44
epoch [2/50] batch [100/203] time 0.089 (0.089) data 0.000 (0.003) loss 1.2129 (1.2094) teacher_loss 0.1864 (0.4238) loss_zs_kd 0.0768 (0.0418) loss_oracle 0.4455 (0.3264) kd_loss 0.7653 (0.6016) acc 93.7500 (87.9062) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3385 (0.3360) gate/usage_min 0.3300 (0.3308) gate/usage_std 0.0037 (0.0022) teacher/entropy 0.3276 (0.4975) teacher/usage_max 0.5849 (0.5606) teacher/usage_min 0.2068 (0.1331) teacher/usage_std 0.1779 (0.1847) nleep/row_max_mean 1530.6146 (1526.7849) nleep/row_max_std 56.3164 (59.7029) nleep/row_min_mean 1523.1985 (1522.0017) lr 2.0000e-03 eta 0:14:35
epoch [2/50] batch [120/203] time 0.101 (0.088) data 0.000 (0.002) loss 1.6644 (1.2537) teacher_loss 0.4870 (0.4206) loss_zs_kd 0.0722 (0.0455) loss_oracle 0.6142 (0.3565) kd_loss 0.8342 (0.6321) acc 84.3750 (87.7604) gate/entropy 1.0984 (1.0986) gate/usage_max 0.3426 (0.3368) gate/usage_min 0.3274 (0.3305) gate/usage_std 0.0067 (0.0027) teacher/entropy 0.2434 (0.4650) teacher/usage_max 0.8428 (0.5821) teacher/usage_min 0.0608 (0.1330) teacher/usage_std 0.3605 (0.1961) nleep/row_max_mean 1523.5377 (1527.3138) nleep/row_max_std 72.7466 (59.3198) nleep/row_min_mean 1512.8658 (1521.8052) lr 2.0000e-03 eta 0:14:29
epoch [2/50] batch [140/203] time 0.083 (0.088) data 0.000 (0.002) loss 1.6584 (1.3058) teacher_loss 0.5739 (0.4301) loss_zs_kd 0.0649 (0.0471) loss_oracle 0.5443 (0.3902) kd_loss 0.7799 (0.6570) acc 78.1250 (87.3661) gate/entropy 1.0981 (1.0985) gate/usage_max 0.3485 (0.3380) gate/usage_min 0.3239 (0.3298) gate/usage_std 0.0108 (0.0035) teacher/entropy 0.2914 (0.4371) teacher/usage_max 0.7469 (0.6056) teacher/usage_min 0.1263 (0.1280) teacher/usage_std 0.2925 (0.2100) nleep/row_max_mean 1524.5400 (1526.9707) nleep/row_max_std 56.2644 (59.9209) nleep/row_min_mean 1514.0815 (1520.7697) lr 2.0000e-03 eta 0:14:23
epoch [2/50] batch [160/203] time 0.085 (0.088) data 0.000 (0.002) loss 1.4698 (1.3395) teacher_loss 0.2774 (0.4280) loss_zs_kd 0.0790 (0.0469) loss_oracle 0.6678 (0.4135) kd_loss 0.8190 (0.6814) acc 93.7500 (87.4219) gate/entropy 1.0976 (1.0984) gate/usage_max 0.3548 (0.3398) gate/usage_min 0.3206 (0.3288) gate/usage_std 0.0153 (0.0047) teacher/entropy 0.2470 (0.4090) teacher/usage_max 0.6962 (0.6250) teacher/usage_min 0.0760 (0.1239) teacher/usage_std 0.2640 (0.2217) nleep/row_max_mean 1523.7592 (1526.5283) nleep/row_max_std 59.5944 (60.7185) nleep/row_min_mean 1512.4971 (1519.6952) lr 2.0000e-03 eta 0:14:17
epoch [2/50] batch [180/203] time 0.086 (0.089) data 0.000 (0.002) loss 1.5870 (1.3613) teacher_loss 0.5153 (0.4239) loss_zs_kd 0.0602 (0.0477) loss_oracle 0.5088 (0.4282) kd_loss 0.7872 (0.6994) acc 84.3750 (87.6389) gate/entropy 1.0969 (1.0983) gate/usage_max 0.3608 (0.3418) gate/usage_min 0.3180 (0.3278) gate/usage_std 0.0194 (0.0062) teacher/entropy 0.2682 (0.3871) teacher/usage_max 0.7085 (0.6386) teacher/usage_min 0.0936 (0.1206) teacher/usage_std 0.2687 (0.2298) nleep/row_max_mean 1537.5830 (1525.8556) nleep/row_max_std 44.0913 (61.3026) nleep/row_min_mean 1527.1848 (1518.5040) lr 2.0000e-03 eta 0:14:27
epoch [2/50] batch [200/203] time 0.086 (0.089) data 0.000 (0.002) loss 1.5675 (1.3839) teacher_loss 0.3854 (0.4210) loss_zs_kd 0.0686 (0.0490) loss_oracle 0.6583 (0.4453) kd_loss 0.8187 (0.7157) acc 90.6250 (87.5469) gate/entropy 1.0961 (1.0981) gate/usage_max 0.3667 (0.3440) gate/usage_min 0.3159 (0.3267) gate/usage_std 0.0236 (0.0077) teacher/entropy 0.2296 (0.3668) teacher/usage_max 0.6960 (0.6479) teacher/usage_min 0.0407 (0.1155) teacher/usage_std 0.2721 (0.2356) nleep/row_max_mean 1518.8159 (1526.0450) nleep/row_max_std 71.1497 (61.7056) nleep/row_min_mean 1506.0795 (1518.1596) lr 2.0000e-03 eta 0:14:26
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,268
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 84.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      81.1%, epoch: 2 *******
******* Domain c best val test acc: 99.9%, epoch: 2 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [3/50] batch [20/203] time 0.078 (0.105) data 0.000 (0.014) loss 1.5931 (1.5596) teacher_loss 0.3530 (0.3392) loss_zs_kd 0.0587 (0.0550) loss_oracle 0.5835 (0.5674) kd_loss 0.9190 (0.9092) acc 87.5000 (89.2188) gate/entropy 1.0952 (1.0956) gate/usage_max 0.3728 (0.3704) gate/usage_min 0.3130 (0.3144) gate/usage_std 0.0279 (0.0262) teacher/entropy 0.1112 (0.1345) teacher/usage_max 0.7441 (0.6885) teacher/usage_min 0.0101 (0.0277) teacher/usage_std 0.3060 (0.2760) nleep/row_max_mean 1497.8506 (1525.8558) nleep/row_max_std 74.3657 (63.2524) nleep/row_min_mean 1483.8650 (1511.5007) lr 1.9980e-03 eta 0:17:03
epoch [3/50] batch [40/203] time 0.085 (0.097) data 0.000 (0.007) loss 1.5639 (1.5570) teacher_loss 0.1957 (0.3028) loss_zs_kd 0.0747 (0.0579) loss_oracle 0.6980 (0.6013) kd_loss 0.9818 (0.9246) acc 96.8750 (90.7031) gate/entropy 1.0942 (1.0951) gate/usage_max 0.3782 (0.3730) gate/usage_min 0.3087 (0.3125) gate/usage_std 0.0318 (0.0281) teacher/entropy 0.0757 (0.1164) teacher/usage_max 0.5501 (0.6803) teacher/usage_min 0.0338 (0.0227) teacher/usage_std 0.2187 (0.2744) nleep/row_max_mean 1545.3591 (1525.8279) nleep/row_max_std 28.8791 (62.5299) nleep/row_min_mean 1529.3157 (1510.7940) lr 1.9980e-03 eta 0:15:39
epoch [3/50] batch [60/203] time 0.094 (0.095) data 0.001 (0.005) loss 1.6948 (1.5708) teacher_loss 0.3692 (0.3004) loss_zs_kd 0.0638 (0.0564) loss_oracle 0.6125 (0.6115) kd_loss 0.9874 (0.9365) acc 90.6250 (91.3021) gate/entropy 1.0931 (1.0946) gate/usage_max 0.3833 (0.3756) gate/usage_min 0.3044 (0.3105) gate/usage_std 0.0355 (0.0299) teacher/entropy 0.0581 (0.1022) teacher/usage_max 0.5766 (0.6712) teacher/usage_min 0.0016 (0.0182) teacher/usage_std 0.2429 (0.2716) nleep/row_max_mean 1547.5577 (1526.3113) nleep/row_max_std 43.6519 (62.9292) nleep/row_min_mean 1527.5392 (1510.4097) lr 1.9980e-03 eta 0:15:19
epoch [3/50] batch [80/203] time 0.098 (0.095) data 0.000 (0.004) loss 1.6920 (1.5658) teacher_loss 0.4317 (0.2967) loss_zs_kd 0.0522 (0.0550) loss_oracle 0.6151 (0.6105) kd_loss 0.9267 (0.9364) acc 90.6250 (91.4844) gate/entropy 1.0920 (1.0941) gate/usage_max 0.3880 (0.3781) gate/usage_min 0.3006 (0.3085) gate/usage_std 0.0389 (0.0317) teacher/entropy 0.0861 (0.0982) teacher/usage_max 0.6990 (0.6715) teacher/usage_min 0.0006 (0.0154) teacher/usage_std 0.2861 (0.2727) nleep/row_max_mean 1533.9788 (1527.3952) nleep/row_max_std 52.9970 (62.2364) nleep/row_min_mean 1513.3677 (1510.5858) lr 1.9980e-03 eta 0:15:14
epoch [3/50] batch [100/203] time 0.093 (0.095) data 0.000 (0.003) loss 1.5423 (1.5528) teacher_loss 0.2978 (0.2845) loss_zs_kd 0.0353 (0.0549) loss_oracle 0.6167 (0.6028) kd_loss 0.9185 (0.9394) acc 87.5000 (91.8125) gate/entropy 1.0907 (1.0935) gate/usage_max 0.3926 (0.3806) gate/usage_min 0.2966 (0.3065) gate/usage_std 0.0423 (0.0335) teacher/entropy 0.0953 (0.0920) teacher/usage_max 0.6632 (0.6694) teacher/usage_min 0.0140 (0.0132) teacher/usage_std 0.2651 (0.2730) nleep/row_max_mean 1530.1522 (1526.8649) nleep/row_max_std 59.7743 (62.9419) nleep/row_min_mean 1509.7029 (1509.3298) lr 1.9980e-03 eta 0:15:16
epoch [3/50] batch [120/203] time 0.096 (0.095) data 0.000 (0.003) loss 1.4252 (1.5420) teacher_loss 0.1210 (0.2749) loss_zs_kd 0.0738 (0.0546) loss_oracle 0.5629 (0.5952) kd_loss 0.9857 (0.9422) acc 100.0000 (92.2656) gate/entropy 1.0894 (1.0930) gate/usage_max 0.3972 (0.3830) gate/usage_min 0.2929 (0.3045) gate/usage_std 0.0457 (0.0353) teacher/entropy 0.0443 (0.0864) teacher/usage_max 0.5708 (0.6654) teacher/usage_min 0.0023 (0.0118) teacher/usage_std 0.2413 (0.2720) nleep/row_max_mean 1517.9299 (1525.8820) nleep/row_max_std 73.7011 (64.3492) nleep/row_min_mean 1495.1843 (1507.7663) lr 1.9980e-03 eta 0:15:16
epoch [3/50] batch [140/203] time 0.098 (0.095) data 0.000 (0.002) loss 1.6425 (1.5361) teacher_loss 0.3204 (0.2595) loss_zs_kd 0.1006 (0.0579) loss_oracle 0.6542 (0.5983) kd_loss 0.9447 (0.9485) acc 90.6250 (92.6562) gate/entropy 1.0883 (1.0924) gate/usage_max 0.4009 (0.3853) gate/usage_min 0.2892 (0.3026) gate/usage_std 0.0485 (0.0370) teacher/entropy 0.0412 (0.0796) teacher/usage_max 0.7197 (0.6549) teacher/usage_min 0.0003 (0.0110) teacher/usage_std 0.2961 (0.2690) nleep/row_max_mean 1520.5446 (1525.4611) nleep/row_max_std 88.1828 (64.7799) nleep/row_min_mean 1494.8331 (1506.8410) lr 1.9980e-03 eta 0:15:12
epoch [3/50] batch [160/203] time 0.098 (0.095) data 0.000 (0.002) loss 1.5776 (1.5323) teacher_loss 0.3547 (0.2519) loss_zs_kd 0.0536 (0.0590) loss_oracle 0.6087 (0.5960) kd_loss 0.8918 (0.9528) acc 90.6250 (92.9102) gate/entropy 1.0873 (1.0918) gate/usage_max 0.4036 (0.3874) gate/usage_min 0.2859 (0.3007) gate/usage_std 0.0507 (0.0386) teacher/entropy 0.0701 (0.0738) teacher/usage_max 0.7969 (0.6484) teacher/usage_min 0.0157 (0.0103) teacher/usage_std 0.3352 (0.2670) nleep/row_max_mean 1510.7633 (1525.1144) nleep/row_max_std 76.6745 (64.8627) nleep/row_min_mean 1485.0347 (1505.9510) lr 1.9980e-03 eta 0:15:10
epoch [3/50] batch [180/203] time 0.095 (0.096) data 0.000 (0.002) loss 1.5226 (1.5245) teacher_loss 0.1611 (0.2405) loss_zs_kd 0.0791 (0.0609) loss_oracle 0.6439 (0.5928) kd_loss 1.0000 (0.9572) acc 93.7500 (93.2292) gate/entropy 1.0862 (1.0912) gate/usage_max 0.4067 (0.3894) gate/usage_min 0.2827 (0.2988) gate/usage_std 0.0531 (0.0401) teacher/entropy 0.0576 (0.0684) teacher/usage_max 0.5507 (0.6409) teacher/usage_min 0.0262 (0.0098) teacher/usage_std 0.2233 (0.2645) nleep/row_max_mean 1525.2986 (1525.0216) nleep/row_max_std 62.7598 (64.4548) nleep/row_min_mean 1503.2260 (1505.3944) lr 1.9980e-03 eta 0:15:18
epoch [3/50] batch [200/203] time 0.074 (0.096) data 0.000 (0.002) loss 1.4512 (1.5237) teacher_loss 0.2362 (0.2370) loss_zs_kd 0.0563 (0.0622) loss_oracle 0.5286 (0.5938) kd_loss 0.9225 (0.9587) acc 93.7500 (93.3438) gate/entropy 1.0852 (1.0907) gate/usage_max 0.4092 (0.3913) gate/usage_min 0.2795 (0.2971) gate/usage_std 0.0552 (0.0415) teacher/entropy 0.0508 (0.0661) teacher/usage_max 0.7079 (0.6359) teacher/usage_min 0.0015 (0.0092) teacher/usage_std 0.2900 (0.2630) nleep/row_max_mean 1493.2068 (1523.9826) nleep/row_max_std 89.3430 (65.0706) nleep/row_min_mean 1470.9360 (1503.9628) lr 1.9980e-03 eta 0:15:13
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,258
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      81.1%, epoch: 2 *******
******* Domain c best val test acc: 99.9%, epoch: 2 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [4/50] batch [20/203] time 0.092 (0.133) data 0.000 (0.017) loss 1.3905 (1.4588) teacher_loss 0.1204 (0.1673) loss_zs_kd 0.0581 (0.0759) loss_oracle 0.5665 (0.5754) kd_loss 0.9579 (0.9659) acc 93.7500 (95.7812) gate/entropy 1.0841 (1.0845) gate/usage_max 0.4120 (0.4109) gate/usage_min 0.2762 (0.2774) gate/usage_std 0.0575 (0.0566) teacher/entropy 0.0740 (0.0463) teacher/usage_max 0.4884 (0.5740) teacher/usage_min 0.0232 (0.0095) teacher/usage_std 0.2193 (0.2419) nleep/row_max_mean 1502.3828 (1512.3890) nleep/row_max_std 71.1485 (66.4438) nleep/row_min_mean 1479.0437 (1488.7163) lr 1.9921e-03 eta 0:21:06
epoch [4/50] batch [40/203] time 0.098 (0.113) data 0.000 (0.009) loss 1.3683 (1.4402) teacher_loss 0.0510 (0.1466) loss_zs_kd 0.0644 (0.0740) loss_oracle 0.5459 (0.5802) kd_loss 1.0121 (0.9665) acc 100.0000 (96.0938) gate/entropy 1.0828 (1.0840) gate/usage_max 0.4149 (0.4122) gate/usage_min 0.2730 (0.2759) gate/usage_std 0.0598 (0.0577) teacher/entropy 0.0087 (0.0444) teacher/usage_max 0.5002 (0.5675) teacher/usage_min 0.0003 (0.0117) teacher/usage_std 0.2355 (0.2389) nleep/row_max_mean 1525.0209 (1515.9372) nleep/row_max_std 58.9710 (65.5513) nleep/row_min_mean 1501.2456 (1492.2311) lr 1.9921e-03 eta 0:17:51
epoch [4/50] batch [60/203] time 0.098 (0.107) data 0.001 (0.006) loss 1.3934 (1.4400) teacher_loss 0.0489 (0.1425) loss_zs_kd 0.0676 (0.0764) loss_oracle 0.6608 (0.5901) kd_loss 0.9802 (0.9643) acc 100.0000 (96.0938) gate/entropy 1.0816 (1.0834) gate/usage_max 0.4177 (0.4136) gate/usage_min 0.2702 (0.2744) gate/usage_std 0.0621 (0.0588) teacher/entropy 0.0013 (0.0435) teacher/usage_max 0.6248 (0.5693) teacher/usage_min 0.0001 (0.0119) teacher/usage_std 0.2567 (0.2396) nleep/row_max_mean 1532.1448 (1516.6577) nleep/row_max_std 48.5977 (64.8126) nleep/row_min_mean 1505.4513 (1492.6765) lr 1.9921e-03 eta 0:16:52
epoch [4/50] batch [80/203] time 0.099 (0.104) data 0.000 (0.004) loss 1.3922 (1.4453) teacher_loss 0.1015 (0.1481) loss_zs_kd 0.0806 (0.0753) loss_oracle 0.6194 (0.5913) kd_loss 0.9407 (0.9638) acc 96.8750 (96.0156) gate/entropy 1.0805 (1.0828) gate/usage_max 0.4201 (0.4149) gate/usage_min 0.2674 (0.2730) gate/usage_std 0.0641 (0.0599) teacher/entropy 0.0666 (0.0433) teacher/usage_max 0.5603 (0.5685) teacher/usage_min 0.0669 (0.0142) teacher/usage_std 0.2033 (0.2384) nleep/row_max_mean 1511.2332 (1516.2398) nleep/row_max_std 67.4591 (65.2370) nleep/row_min_mean 1487.3153 (1492.3043) lr 1.9921e-03 eta 0:16:21
epoch [4/50] batch [100/203] time 0.099 (0.102) data 0.000 (0.004) loss 1.4169 (1.4473) teacher_loss 0.1519 (0.1497) loss_zs_kd 0.0658 (0.0764) loss_oracle 0.5373 (0.5939) kd_loss 0.9635 (0.9625) acc 93.7500 (95.6875) gate/entropy 1.0794 (1.0822) gate/usage_max 0.4226 (0.4163) gate/usage_min 0.2647 (0.2716) gate/usage_std 0.0661 (0.0610) teacher/entropy 0.0518 (0.0417) teacher/usage_max 0.5025 (0.5721) teacher/usage_min 0.0067 (0.0152) teacher/usage_std 0.2310 (0.2388) nleep/row_max_mean 1513.8091 (1515.9281) nleep/row_max_std 67.9032 (65.3021) nleep/row_min_mean 1491.5771 (1491.7952) lr 1.9921e-03 eta 0:16:07
epoch [4/50] batch [120/203] time 0.087 (0.101) data 0.000 (0.003) loss 1.3731 (1.4370) teacher_loss 0.1074 (0.1441) loss_zs_kd 0.0727 (0.0764) loss_oracle 0.5464 (0.5867) kd_loss 0.9561 (0.9614) acc 96.8750 (95.8854) gate/entropy 1.0780 (1.0816) gate/usage_max 0.4254 (0.4176) gate/usage_min 0.2622 (0.2702) gate/usage_std 0.0683 (0.0620) teacher/entropy 0.0136 (0.0407) teacher/usage_max 0.6264 (0.5752) teacher/usage_min 0.0007 (0.0155) teacher/usage_std 0.2569 (0.2395) nleep/row_max_mean 1530.2852 (1516.8477) nleep/row_max_std 57.6078 (64.9811) nleep/row_min_mean 1504.8152 (1492.5580) lr 1.9921e-03 eta 0:15:51
epoch [4/50] batch [140/203] time 0.094 (0.100) data 0.000 (0.003) loss 1.5048 (1.4347) teacher_loss 0.1132 (0.1454) loss_zs_kd 0.0996 (0.0763) loss_oracle 0.6709 (0.5843) kd_loss 1.0063 (0.9589) acc 100.0000 (95.9821) gate/entropy 1.0769 (1.0810) gate/usage_max 0.4277 (0.4189) gate/usage_min 0.2595 (0.2689) gate/usage_std 0.0702 (0.0630) teacher/entropy 0.0216 (0.0421) teacher/usage_max 0.5496 (0.5738) teacher/usage_min 0.0129 (0.0160) teacher/usage_std 0.2312 (0.2387) nleep/row_max_mean 1535.5188 (1517.5928) nleep/row_max_std 53.7605 (64.2058) nleep/row_min_mean 1505.5204 (1493.2029) lr 1.9921e-03 eta 0:15:41
epoch [4/50] batch [160/203] time 0.094 (0.100) data 0.000 (0.002) loss 1.3109 (1.4313) teacher_loss 0.0137 (0.1411) loss_zs_kd 0.0709 (0.0763) loss_oracle 0.5444 (0.5862) kd_loss 0.9896 (0.9589) acc 100.0000 (96.0938) gate/entropy 1.0758 (1.0804) gate/usage_max 0.4296 (0.4201) gate/usage_min 0.2570 (0.2675) gate/usage_std 0.0719 (0.0640) teacher/entropy 0.0133 (0.0409) teacher/usage_max 0.5018 (0.5726) teacher/usage_min 0.0007 (0.0154) teacher/usage_std 0.2352 (0.2387) nleep/row_max_mean 1526.4454 (1517.9438) nleep/row_max_std 58.2327 (64.3418) nleep/row_min_mean 1501.0061 (1493.2707) lr 1.9921e-03 eta 0:15:37
epoch [4/50] batch [180/203] time 0.095 (0.100) data 0.000 (0.002) loss 1.3607 (1.4337) teacher_loss 0.0647 (0.1445) loss_zs_kd 0.0723 (0.0761) loss_oracle 0.6039 (0.5876) kd_loss 0.9579 (0.9574) acc 100.0000 (96.0590) gate/entropy 1.0746 (1.0798) gate/usage_max 0.4318 (0.4213) gate/usage_min 0.2545 (0.2662) gate/usage_std 0.0737 (0.0650) teacher/entropy 0.0245 (0.0396) teacher/usage_max 0.5621 (0.5752) teacher/usage_min 0.0161 (0.0154) teacher/usage_std 0.2316 (0.2394) nleep/row_max_mean 1533.8843 (1517.8664) nleep/row_max_std 62.9859 (64.8577) nleep/row_min_mean 1502.3513 (1492.9527) lr 1.9921e-03 eta 0:15:32
epoch [4/50] batch [200/203] time 0.091 (0.099) data 0.000 (0.002) loss 1.3266 (1.4311) teacher_loss 0.0936 (0.1448) loss_zs_kd 0.0481 (0.0759) loss_oracle 0.5002 (0.5872) kd_loss 0.9588 (0.9547) acc 96.8750 (96.0781) gate/entropy 1.0736 (1.0793) gate/usage_max 0.4334 (0.4224) gate/usage_min 0.2522 (0.2649) gate/usage_std 0.0752 (0.0660) teacher/entropy 0.0182 (0.0403) teacher/usage_max 0.5591 (0.5760) teacher/usage_min 0.0005 (0.0151) teacher/usage_std 0.2403 (0.2398) nleep/row_max_mean 1520.2148 (1517.3721) nleep/row_max_std 66.5734 (65.7101) nleep/row_min_mean 1490.6300 (1492.2943) lr 1.9921e-03 eta 0:15:23
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,277
* accuracy: 81.5%
* error: 18.5%
* macro_f1: 85.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      81.5%, epoch: 4 *******
******* Domain c best val test acc: 100.0%, epoch: 4 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [5/50] batch [20/203] time 0.088 (0.116) data 0.000 (0.013) loss 1.3517 (1.3965) teacher_loss 0.0248 (0.1382) loss_zs_kd 0.0567 (0.0703) loss_oracle 0.5931 (0.5510) kd_loss 1.0020 (0.9476) acc 100.0000 (96.4062) gate/entropy 1.0727 (1.0729) gate/usage_max 0.4346 (0.4344) gate/usage_min 0.2499 (0.2507) gate/usage_std 0.0764 (0.0761) teacher/entropy 0.0232 (0.0496) teacher/usage_max 0.5871 (0.5681) teacher/usage_min 0.0073 (0.0194) teacher/usage_std 0.2421 (0.2343) nleep/row_max_mean 1526.0577 (1518.1786) nleep/row_max_std 52.7173 (63.6347) nleep/row_min_mean 1496.9751 (1492.1254) lr 1.9823e-03 eta 0:18:00
epoch [5/50] batch [40/203] time 0.091 (0.106) data 0.000 (0.007) loss 1.3485 (1.3949) teacher_loss 0.1277 (0.1387) loss_zs_kd 0.0701 (0.0683) loss_oracle 0.5959 (0.5559) kd_loss 0.8878 (0.9441) acc 96.8750 (96.5625) gate/entropy 1.0716 (1.0725) gate/usage_max 0.4360 (0.4349) gate/usage_min 0.2473 (0.2496) gate/usage_std 0.0779 (0.0767) teacher/entropy 0.0500 (0.0522) teacher/usage_max 0.6802 (0.5671) teacher/usage_min 0.0230 (0.0229) teacher/usage_std 0.2695 (0.2325) nleep/row_max_mean 1539.0942 (1519.0315) nleep/row_max_std 43.0549 (64.0789) nleep/row_min_mean 1514.3008 (1492.6399) lr 1.9823e-03 eta 0:16:24
epoch [5/50] batch [60/203] time 0.089 (0.102) data 0.000 (0.004) loss 1.4345 (1.4044) teacher_loss 0.1984 (0.1504) loss_zs_kd 0.0603 (0.0702) loss_oracle 0.5705 (0.5623) kd_loss 0.9208 (0.9378) acc 96.8750 (96.4062) gate/entropy 1.0709 (1.0721) gate/usage_max 0.4367 (0.4353) gate/usage_min 0.2456 (0.2486) gate/usage_std 0.0788 (0.0772) teacher/entropy 0.1006 (0.0554) teacher/usage_max 0.4687 (0.5632) teacher/usage_min 0.0771 (0.0258) teacher/usage_std 0.1813 (0.2296) nleep/row_max_mean 1484.0410 (1516.7857) nleep/row_max_std 80.9222 (66.2145) nleep/row_min_mean 1459.3738 (1490.8921) lr 1.9823e-03 eta 0:15:48
epoch [5/50] batch [80/203] time 0.093 (0.100) data 0.000 (0.003) loss 1.4253 (1.3993) teacher_loss 0.1716 (0.1469) loss_zs_kd 0.0571 (0.0694) loss_oracle 0.5705 (0.5690) kd_loss 0.9399 (0.9332) acc 93.7500 (96.6016) gate/entropy 1.0700 (1.0717) gate/usage_max 0.4379 (0.4358) gate/usage_min 0.2435 (0.2475) gate/usage_std 0.0801 (0.0778) teacher/entropy 0.0449 (0.0577) teacher/usage_max 0.5531 (0.5585) teacher/usage_min 0.0634 (0.0287) teacher/usage_std 0.2030 (0.2270) nleep/row_max_mean 1507.0931 (1517.0609) nleep/row_max_std 81.3911 (65.5638) nleep/row_min_mean 1479.4189 (1491.1030) lr 1.9823e-03 eta 0:15:26
epoch [5/50] batch [100/203] time 0.081 (0.099) data 0.000 (0.003) loss 1.2699 (1.3971) teacher_loss 0.0989 (0.1480) loss_zs_kd 0.0690 (0.0680) loss_oracle 0.5718 (0.5679) kd_loss 0.8506 (0.9311) acc 96.8750 (96.4062) gate/entropy 1.0690 (1.0713) gate/usage_max 0.4392 (0.4363) gate/usage_min 0.2413 (0.2465) gate/usage_std 0.0814 (0.0783) teacher/entropy 0.1005 (0.0603) teacher/usage_max 0.6059 (0.5590) teacher/usage_min 0.0133 (0.0287) teacher/usage_std 0.2443 (0.2272) nleep/row_max_mean 1514.9670 (1516.3970) nleep/row_max_std 80.0364 (65.9954) nleep/row_min_mean 1491.7534 (1490.6333) lr 1.9823e-03 eta 0:15:14
epoch [5/50] batch [120/203] time 0.092 (0.101) data 0.000 (0.002) loss 1.3931 (1.3974) teacher_loss 0.0519 (0.1461) loss_zs_kd 0.1166 (0.0700) loss_oracle 0.6809 (0.5736) kd_loss 0.9424 (0.9296) acc 100.0000 (96.4844) gate/entropy 1.0682 (1.0708) gate/usage_max 0.4399 (0.4369) gate/usage_min 0.2395 (0.2455) gate/usage_std 0.0823 (0.0789) teacher/entropy 0.0334 (0.0601) teacher/usage_max 0.5209 (0.5589) teacher/usage_min 0.0111 (0.0297) teacher/usage_std 0.2289 (0.2265) nleep/row_max_mean 1524.6135 (1516.8434) nleep/row_max_std 49.6774 (64.9646) nleep/row_min_mean 1500.3696 (1491.1032) lr 1.9823e-03 eta 0:15:29
epoch [5/50] batch [140/203] time 0.094 (0.100) data 0.000 (0.002) loss 1.4585 (1.3988) teacher_loss 0.2933 (0.1494) loss_zs_kd 0.0709 (0.0722) loss_oracle 0.4288 (0.5710) kd_loss 0.9153 (0.9279) acc 93.7500 (96.3839) gate/entropy 1.0673 (1.0704) gate/usage_max 0.4411 (0.4374) gate/usage_min 0.2375 (0.2445) gate/usage_std 0.0836 (0.0795) teacher/entropy 0.0819 (0.0610) teacher/usage_max 0.4985 (0.5590) teacher/usage_min 0.0681 (0.0310) teacher/usage_std 0.1894 (0.2258) nleep/row_max_mean 1514.5525 (1516.1543) nleep/row_max_std 65.5168 (65.0753) nleep/row_min_mean 1491.1240 (1490.4230) lr 1.9823e-03 eta 0:15:19
epoch [5/50] batch [160/203] time 0.099 (0.099) data 0.000 (0.002) loss 1.3071 (1.3936) teacher_loss 0.1537 (0.1491) loss_zs_kd 0.0691 (0.0714) loss_oracle 0.5407 (0.5673) kd_loss 0.8485 (0.9251) acc 96.8750 (96.3672) gate/entropy 1.0665 (1.0699) gate/usage_max 0.4419 (0.4379) gate/usage_min 0.2358 (0.2435) gate/usage_std 0.0845 (0.0801) teacher/entropy 0.1145 (0.0635) teacher/usage_max 0.5919 (0.5572) teacher/usage_min 0.0588 (0.0329) teacher/usage_std 0.2179 (0.2242) nleep/row_max_mean 1496.5413 (1515.5818) nleep/row_max_std 83.5481 (65.0035) nleep/row_min_mean 1473.1571 (1489.9443) lr 1.9823e-03 eta 0:15:12
epoch [5/50] batch [180/203] time 0.096 (0.099) data 0.000 (0.002) loss 1.4731 (1.3893) teacher_loss 0.2339 (0.1491) loss_zs_kd 0.0832 (0.0715) loss_oracle 0.5603 (0.5643) kd_loss 0.9175 (0.9223) acc 93.7500 (96.3542) gate/entropy 1.0659 (1.0695) gate/usage_max 0.4424 (0.4384) gate/usage_min 0.2343 (0.2426) gate/usage_std 0.0852 (0.0806) teacher/entropy 0.0624 (0.0660) teacher/usage_max 0.5137 (0.5552) teacher/usage_min 0.0379 (0.0352) teacher/usage_std 0.2106 (0.2223) nleep/row_max_mean 1517.7205 (1515.2063) nleep/row_max_std 47.2608 (65.1693) nleep/row_min_mean 1488.1355 (1489.6948) lr 1.9823e-03 eta 0:15:04
epoch [5/50] batch [200/203] time 0.076 (0.097) data 0.000 (0.002) loss 1.4333 (1.3911) teacher_loss 0.0762 (0.1513) loss_zs_kd 0.0871 (0.0715) loss_oracle 0.5926 (0.5657) kd_loss 1.0173 (0.9212) acc 96.8750 (96.2969) gate/entropy 1.0650 (1.0691) gate/usage_max 0.4431 (0.4388) gate/usage_min 0.2324 (0.2417) gate/usage_std 0.0862 (0.0811) teacher/entropy 0.0098 (0.0675) teacher/usage_max 0.6250 (0.5542) teacher/usage_min 0.0293 (0.0365) teacher/usage_std 0.2433 (0.2214) nleep/row_max_mean 1541.9741 (1514.7945) nleep/row_max_std 28.3128 (65.3685) nleep/row_min_mean 1512.1902 (1489.2337) lr 1.9823e-03 eta 0:14:49
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,209
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 83.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      81.5%, epoch: 4 *******
******* Domain c best val test acc: 100.0%, epoch: 4 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [6/50] batch [20/203] time 0.086 (0.111) data 0.000 (0.018) loss 1.4705 (1.3947) teacher_loss 0.2018 (0.1586) loss_zs_kd 0.0646 (0.0707) loss_oracle 0.5166 (0.5594) kd_loss 0.9781 (0.9210) acc 93.7500 (96.4062) gate/entropy 1.0644 (1.0647) gate/usage_max 0.4431 (0.4430) gate/usage_min 0.2307 (0.2315) gate/usage_std 0.0869 (0.0865) teacher/entropy 0.0462 (0.0605) teacher/usage_max 0.5614 (0.5404) teacher/usage_min 0.0607 (0.0377) teacher/usage_std 0.2068 (0.2159) nleep/row_max_mean 1511.6968 (1511.9716) nleep/row_max_std 66.1245 (67.6568) nleep/row_min_mean 1486.2347 (1485.3886) lr 1.9686e-03 eta 0:16:53
epoch [6/50] batch [40/203] time 0.087 (0.101) data 0.000 (0.009) loss 1.3010 (1.3806) teacher_loss 0.0716 (0.1421) loss_zs_kd 0.0574 (0.0713) loss_oracle 0.5468 (0.5671) kd_loss 0.9274 (0.9193) acc 100.0000 (96.7188) gate/entropy 1.0638 (1.0644) gate/usage_max 0.4433 (0.4430) gate/usage_min 0.2289 (0.2306) gate/usage_std 0.0876 (0.0868) teacher/entropy 0.0942 (0.0660) teacher/usage_max 0.4455 (0.5404) teacher/usage_min 0.1123 (0.0434) teacher/usage_std 0.1563 (0.2144) nleep/row_max_mean 1514.6741 (1509.2480) nleep/row_max_std 69.5609 (68.3087) nleep/row_min_mean 1491.9810 (1483.3189) lr 1.9686e-03 eta 0:15:14
epoch [6/50] batch [60/203] time 0.093 (0.098) data 0.001 (0.006) loss 1.4072 (1.3774) teacher_loss 0.2378 (0.1566) loss_zs_kd 0.0521 (0.0662) loss_oracle 0.5233 (0.5536) kd_loss 0.8817 (0.9109) acc 87.5000 (95.9375) gate/entropy 1.0630 (1.0641) gate/usage_max 0.4437 (0.4431) gate/usage_min 0.2273 (0.2298) gate/usage_std 0.0884 (0.0872) teacher/entropy 0.1038 (0.0717) teacher/usage_max 0.4945 (0.5405) teacher/usage_min 0.0603 (0.0430) teacher/usage_std 0.1941 (0.2147) nleep/row_max_mean 1513.7279 (1508.9537) nleep/row_max_std 64.3621 (68.7663) nleep/row_min_mean 1487.0408 (1483.1651) lr 1.9686e-03 eta 0:14:45
epoch [6/50] batch [80/203] time 0.084 (0.095) data 0.000 (0.005) loss 1.6872 (1.3796) teacher_loss 0.4483 (0.1615) loss_zs_kd 0.0715 (0.0683) loss_oracle 0.5599 (0.5489) kd_loss 0.9232 (0.9095) acc 87.5000 (95.8203) gate/entropy 1.0625 (1.0638) gate/usage_max 0.4435 (0.4432) gate/usage_min 0.2258 (0.2290) gate/usage_std 0.0889 (0.0875) teacher/entropy 0.0722 (0.0766) teacher/usage_max 0.4666 (0.5394) teacher/usage_min 0.0699 (0.0450) teacher/usage_std 0.1863 (0.2134) nleep/row_max_mean 1512.0775 (1509.4630) nleep/row_max_std 64.7729 (67.6330) nleep/row_min_mean 1484.7670 (1483.8183) lr 1.9686e-03 eta 0:14:20
epoch [6/50] batch [100/203] time 0.069 (0.094) data 0.000 (0.004) loss 1.3689 (1.3739) teacher_loss 0.1476 (0.1569) loss_zs_kd 0.0672 (0.0685) loss_oracle 0.5343 (0.5460) kd_loss 0.9206 (0.9097) acc 96.8750 (95.9062) gate/entropy 1.0620 (1.0635) gate/usage_max 0.4437 (0.4432) gate/usage_min 0.2246 (0.2282) gate/usage_std 0.0894 (0.0879) teacher/entropy 0.1177 (0.0739) teacher/usage_max 0.5435 (0.5423) teacher/usage_min 0.1009 (0.0468) teacher/usage_std 0.1813 (0.2135) nleep/row_max_mean 1529.7319 (1510.8206) nleep/row_max_std 43.3284 (66.6596) nleep/row_min_mean 1504.5791 (1485.0853) lr 1.9686e-03 eta 0:14:07
epoch [6/50] batch [120/203] time 0.082 (0.091) data 0.000 (0.003) loss 1.3322 (1.3723) teacher_loss 0.1732 (0.1544) loss_zs_kd 0.0510 (0.0694) loss_oracle 0.4745 (0.5459) kd_loss 0.8963 (0.9103) acc 96.8750 (96.0156) gate/entropy 1.0616 (1.0632) gate/usage_max 0.4438 (0.4434) gate/usage_min 0.2236 (0.2275) gate/usage_std 0.0899 (0.0882) teacher/entropy 0.0852 (0.0727) teacher/usage_max 0.5067 (0.5422) teacher/usage_min 0.0690 (0.0485) teacher/usage_std 0.1899 (0.2126) nleep/row_max_mean 1502.6011 (1511.6606) nleep/row_max_std 76.7424 (66.2799) nleep/row_min_mean 1483.2151 (1485.7745) lr 1.9686e-03 eta 0:13:36
epoch [6/50] batch [140/203] time 0.064 (0.088) data 0.000 (0.003) loss 1.3177 (1.3663) teacher_loss 0.0559 (0.1501) loss_zs_kd 0.0898 (0.0694) loss_oracle 0.5127 (0.5429) kd_loss 0.9605 (0.9101) acc 100.0000 (96.2946) gate/entropy 1.0611 (1.0629) gate/usage_max 0.4441 (0.4435) gate/usage_min 0.2227 (0.2269) gate/usage_std 0.0904 (0.0885) teacher/entropy 0.0273 (0.0726) teacher/usage_max 0.5231 (0.5435) teacher/usage_min 0.0383 (0.0518) teacher/usage_std 0.2115 (0.2111) nleep/row_max_mean 1508.8560 (1512.1389) nleep/row_max_std 66.0545 (65.6725) nleep/row_min_mean 1482.4312 (1486.1176) lr 1.9686e-03 eta 0:13:07
epoch [6/50] batch [160/203] time 0.092 (0.086) data 0.000 (0.003) loss 1.2453 (1.3624) teacher_loss 0.0208 (0.1458) loss_zs_kd 0.0936 (0.0715) loss_oracle 0.5436 (0.5445) kd_loss 0.9060 (0.9087) acc 100.0000 (96.3086) gate/entropy 1.0603 (1.0626) gate/usage_max 0.4450 (0.4437) gate/usage_min 0.2213 (0.2263) gate/usage_std 0.0913 (0.0888) teacher/entropy 0.0773 (0.0714) teacher/usage_max 0.5506 (0.5477) teacher/usage_min 0.0228 (0.0508) teacher/usage_std 0.2253 (0.2126) nleep/row_max_mean 1514.0902 (1512.5668) nleep/row_max_std 58.3457 (65.2684) nleep/row_min_mean 1487.9003 (1486.3665) lr 1.9686e-03 eta 0:12:52
epoch [6/50] batch [180/203] time 0.064 (0.084) data 0.000 (0.002) loss 1.3306 (1.3638) teacher_loss 0.1174 (0.1439) loss_zs_kd 0.0945 (0.0734) loss_oracle 0.5797 (0.5469) kd_loss 0.8760 (0.9098) acc 93.7500 (96.2326) gate/entropy 1.0597 (1.0623) gate/usage_max 0.4457 (0.4438) gate/usage_min 0.2202 (0.2256) gate/usage_std 0.0921 (0.0891) teacher/entropy 0.0658 (0.0699) teacher/usage_max 0.5845 (0.5475) teacher/usage_min 0.0337 (0.0522) teacher/usage_std 0.2275 (0.2118) nleep/row_max_mean 1518.0254 (1512.8290) nleep/row_max_std 71.1355 (64.8341) nleep/row_min_mean 1489.4690 (1486.4136) lr 1.9686e-03 eta 0:12:33
epoch [6/50] batch [200/203] time 0.077 (0.083) data 0.000 (0.002) loss 1.3384 (1.3630) teacher_loss 0.0979 (0.1429) loss_zs_kd 0.0921 (0.0745) loss_oracle 0.5354 (0.5472) kd_loss 0.9267 (0.9093) acc 96.8750 (96.2188) gate/entropy 1.0589 (1.0620) gate/usage_max 0.4465 (0.4441) gate/usage_min 0.2189 (0.2250) gate/usage_std 0.0929 (0.0895) teacher/entropy 0.0404 (0.0693) teacher/usage_max 0.4868 (0.5474) teacher/usage_min 0.0331 (0.0527) teacher/usage_std 0.2123 (0.2116) nleep/row_max_mean 1528.6133 (1512.8719) nleep/row_max_std 56.1926 (64.9989) nleep/row_min_mean 1499.0387 (1486.4536) lr 1.9686e-03 eta 0:12:25
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,303
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 86.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      82.4%, epoch: 6 *******
******* Domain c best val test acc: 100.0%, epoch: 6 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [7/50] batch [20/203] time 0.084 (0.103) data 0.000 (0.012) loss 1.3913 (1.3416) teacher_loss 0.1097 (0.1088) loss_zs_kd 0.0863 (0.0819) loss_oracle 0.5381 (0.5511) kd_loss 0.9694 (0.9163) acc 93.7500 (97.1875) gate/entropy 1.0581 (1.0585) gate/usage_max 0.4476 (0.4471) gate/usage_min 0.2179 (0.2184) gate/usage_std 0.0938 (0.0934) teacher/entropy 0.0404 (0.0587) teacher/usage_max 0.5739 (0.5413) teacher/usage_min 0.0550 (0.0665) teacher/usage_std 0.2135 (0.2044) nleep/row_max_mean 1507.6436 (1513.9183) nleep/row_max_std 70.2335 (61.4411) nleep/row_min_mean 1478.2734 (1486.1235) lr 1.9511e-03 eta 0:15:17
epoch [7/50] batch [40/203] time 0.097 (0.098) data 0.000 (0.006) loss 1.3370 (1.3568) teacher_loss 0.0712 (0.1269) loss_zs_kd 0.0722 (0.0827) loss_oracle 0.4769 (0.5497) kd_loss 0.9912 (0.9137) acc 100.0000 (96.8750) gate/entropy 1.0576 (1.0582) gate/usage_max 0.4485 (0.4475) gate/usage_min 0.2171 (0.2180) gate/usage_std 0.0944 (0.0937) teacher/entropy 0.0370 (0.0578) teacher/usage_max 0.4735 (0.5412) teacher/usage_min 0.1216 (0.0675) teacher/usage_std 0.1523 (0.2032) nleep/row_max_mean 1521.2061 (1510.4019) nleep/row_max_std 58.2202 (63.0354) nleep/row_min_mean 1498.4037 (1483.3514) lr 1.9511e-03 eta 0:14:29
epoch [7/50] batch [60/203] time 0.094 (0.096) data 0.001 (0.004) loss 1.3176 (1.3487) teacher_loss 0.0326 (0.1163) loss_zs_kd 0.0735 (0.0832) loss_oracle 0.5921 (0.5581) kd_loss 0.9522 (0.9118) acc 100.0000 (97.2396) gate/entropy 1.0569 (1.0579) gate/usage_max 0.4494 (0.4480) gate/usage_min 0.2162 (0.2175) gate/usage_std 0.0952 (0.0941) teacher/entropy 0.0220 (0.0533) teacher/usage_max 0.5007 (0.5457) teacher/usage_min 0.0641 (0.0589) teacher/usage_std 0.1922 (0.2086) nleep/row_max_mean 1512.9102 (1510.2462) nleep/row_max_std 51.2156 (63.2530) nleep/row_min_mean 1486.1318 (1482.9826) lr 1.9511e-03 eta 0:14:13
epoch [7/50] batch [80/203] time 0.087 (0.094) data 0.000 (0.003) loss 1.3299 (1.3546) teacher_loss 0.1734 (0.1244) loss_zs_kd 0.0643 (0.0829) loss_oracle 0.5057 (0.5595) kd_loss 0.8715 (0.9090) acc 96.8750 (96.9531) gate/entropy 1.0559 (1.0575) gate/usage_max 0.4508 (0.4485) gate/usage_min 0.2150 (0.2170) gate/usage_std 0.0963 (0.0945) teacher/entropy 0.0517 (0.0516) teacher/usage_max 0.6511 (0.5515) teacher/usage_min 0.0514 (0.0564) teacher/usage_std 0.2461 (0.2113) nleep/row_max_mean 1523.4532 (1508.9355) nleep/row_max_std 63.6347 (64.6478) nleep/row_min_mean 1493.3884 (1481.6727) lr 1.9511e-03 eta 0:13:53
epoch [7/50] batch [100/203] time 0.108 (0.094) data 0.000 (0.003) loss 1.3741 (1.3512) teacher_loss 0.2120 (0.1263) loss_zs_kd 0.1149 (0.0827) loss_oracle 0.4722 (0.5534) kd_loss 0.8686 (0.9068) acc 90.6250 (96.9062) gate/entropy 1.0554 (1.0571) gate/usage_max 0.4519 (0.4491) gate/usage_min 0.2144 (0.2166) gate/usage_std 0.0969 (0.0949) teacher/entropy 0.0901 (0.0562) teacher/usage_max 0.5003 (0.5515) teacher/usage_min 0.0302 (0.0623) teacher/usage_std 0.2147 (0.2085) nleep/row_max_mean 1507.0129 (1507.8801) nleep/row_max_std 69.6659 (65.4515) nleep/row_min_mean 1479.0630 (1480.7813) lr 1.9511e-03 eta 0:13:48
epoch [7/50] batch [120/203] time 0.097 (0.094) data 0.000 (0.002) loss 1.4793 (1.3514) teacher_loss 0.2549 (0.1309) loss_zs_kd 0.0710 (0.0839) loss_oracle 0.5515 (0.5504) kd_loss 0.9132 (0.9033) acc 90.6250 (96.7448) gate/entropy 1.0550 (1.0568) gate/usage_max 0.4526 (0.4496) gate/usage_min 0.2142 (0.2162) gate/usage_std 0.0973 (0.0953) teacher/entropy 0.0362 (0.0602) teacher/usage_max 0.5921 (0.5573) teacher/usage_min 0.0744 (0.0679) teacher/usage_std 0.2114 (0.2087) nleep/row_max_mean 1521.3077 (1507.2915) nleep/row_max_std 30.2037 (65.4622) nleep/row_min_mean 1492.1033 (1480.3268) lr 1.9511e-03 eta 0:13:50
epoch [7/50] batch [140/203] time 0.090 (0.094) data 0.000 (0.002) loss 1.5350 (1.3516) teacher_loss 0.3293 (0.1336) loss_zs_kd 0.0892 (0.0821) loss_oracle 0.5826 (0.5517) kd_loss 0.8698 (0.9011) acc 90.6250 (96.6741) gate/entropy 1.0541 (1.0565) gate/usage_max 0.4545 (0.4502) gate/usage_min 0.2134 (0.2158) gate/usage_std 0.0985 (0.0957) teacher/entropy 0.0906 (0.0594) teacher/usage_max 0.6241 (0.5634) teacher/usage_min 0.1232 (0.0671) teacher/usage_std 0.2123 (0.2109) nleep/row_max_mean 1485.8140 (1507.0968) nleep/row_max_std 86.4808 (65.8807) nleep/row_min_mean 1460.8706 (1480.1103) lr 1.9511e-03 eta 0:13:49
epoch [7/50] batch [160/203] time 0.094 (0.095) data 0.000 (0.002) loss 1.3705 (1.3506) teacher_loss 0.1640 (0.1333) loss_zs_kd 0.0876 (0.0817) loss_oracle 0.5829 (0.5537) kd_loss 0.8713 (0.8996) acc 93.7500 (96.6211) gate/entropy 1.0530 (1.0561) gate/usage_max 0.4564 (0.4509) gate/usage_min 0.2123 (0.2155) gate/usage_std 0.0997 (0.0961) teacher/entropy 0.0907 (0.0594) teacher/usage_max 0.5617 (0.5659) teacher/usage_min 0.0853 (0.0666) teacher/usage_std 0.1950 (0.2119) nleep/row_max_mean 1517.2107 (1507.2749) nleep/row_max_std 55.0395 (65.7589) nleep/row_min_mean 1490.4646 (1480.2610) lr 1.9511e-03 eta 0:13:51
epoch [7/50] batch [180/203] time 0.092 (0.095) data 0.000 (0.002) loss 1.2259 (1.3491) teacher_loss 0.0203 (0.1339) loss_zs_kd 0.0617 (0.0805) loss_oracle 0.6129 (0.5546) kd_loss 0.8683 (0.8976) acc 100.0000 (96.5278) gate/entropy 1.0520 (1.0557) gate/usage_max 0.4583 (0.4516) gate/usage_min 0.2114 (0.2151) gate/usage_std 0.1008 (0.0966) teacher/entropy 0.0377 (0.0588) teacher/usage_max 0.6918 (0.5699) teacher/usage_min 0.0572 (0.0651) teacher/usage_std 0.2655 (0.2140) nleep/row_max_mean 1514.7218 (1507.5698) nleep/row_max_std 76.4121 (66.0583) nleep/row_min_mean 1484.2865 (1480.5680) lr 1.9511e-03 eta 0:13:51
epoch [7/50] batch [200/203] time 0.087 (0.095) data 0.000 (0.001) loss 1.2581 (1.3501) teacher_loss 0.0958 (0.1361) loss_zs_kd 0.0629 (0.0793) loss_oracle 0.4897 (0.5554) kd_loss 0.8860 (0.8967) acc 96.8750 (96.5156) gate/entropy 1.0513 (1.0553) gate/usage_max 0.4596 (0.4523) gate/usage_min 0.2109 (0.2147) gate/usage_std 0.1016 (0.0970) teacher/entropy 0.0164 (0.0573) teacher/usage_max 0.6562 (0.5723) teacher/usage_min 0.0258 (0.0631) teacher/usage_std 0.2576 (0.2154) nleep/row_max_mean 1510.8728 (1507.3296) nleep/row_max_std 55.3911 (66.3624) nleep/row_min_mean 1481.8938 (1480.2568) lr 1.9511e-03 eta 0:13:46
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,327
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 86.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.3%, epoch: 7 *******
******* Domain c best val test acc: 100.0%, epoch: 7 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [8/50] batch [20/203] time 0.095 (0.107) data 0.000 (0.017) loss 1.4289 (1.3143) teacher_loss 0.3004 (0.1290) loss_zs_kd 0.0841 (0.0754) loss_oracle 0.5099 (0.5421) kd_loss 0.8315 (0.8765) acc 90.6250 (96.5625) gate/entropy 1.0504 (1.0508) gate/usage_max 0.4613 (0.4604) gate/usage_min 0.2100 (0.2104) gate/usage_std 0.1026 (0.1021) teacher/entropy 0.0440 (0.0554) teacher/usage_max 0.7161 (0.5956) teacher/usage_min 0.0130 (0.0436) teacher/usage_std 0.2904 (0.2328) nleep/row_max_mean 1497.0400 (1504.7294) nleep/row_max_std 76.9933 (69.2298) nleep/row_min_mean 1467.7886 (1478.3491) lr 1.9298e-03 eta 0:15:28
epoch [8/50] batch [40/203] time 0.095 (0.101) data 0.000 (0.009) loss 1.1969 (1.3340) teacher_loss 0.0316 (0.1479) loss_zs_kd 0.0795 (0.0738) loss_oracle 0.4707 (0.5498) kd_loss 0.8902 (0.8744) acc 100.0000 (96.4062) gate/entropy 1.0494 (1.0504) gate/usage_max 0.4634 (0.4614) gate/usage_min 0.2095 (0.2101) gate/usage_std 0.1038 (0.1026) teacher/entropy 0.0476 (0.0575) teacher/usage_max 0.5656 (0.6096) teacher/usage_min 0.0401 (0.0527) teacher/usage_std 0.2189 (0.2340) nleep/row_max_mean 1512.8402 (1507.3668) nleep/row_max_std 69.6401 (67.9155) nleep/row_min_mean 1485.9023 (1479.9439) lr 1.9298e-03 eta 0:14:34
epoch [8/50] batch [60/203] time 0.110 (0.104) data 0.001 (0.006) loss 1.2624 (1.3469) teacher_loss 0.1011 (0.1540) loss_zs_kd 0.0769 (0.0758) loss_oracle 0.5753 (0.5565) kd_loss 0.8352 (0.8767) acc 96.8750 (95.8854) gate/entropy 1.0485 (1.0499) gate/usage_max 0.4655 (0.4624) gate/usage_min 0.2091 (0.2099) gate/usage_std 0.1048 (0.1032) teacher/entropy 0.0845 (0.0562) teacher/usage_max 0.6410 (0.6072) teacher/usage_min 0.0614 (0.0562) teacher/usage_std 0.2380 (0.2310) nleep/row_max_mean 1523.0428 (1510.1836) nleep/row_max_std 55.8472 (64.8638) nleep/row_min_mean 1492.2424 (1482.0259) lr 1.9298e-03 eta 0:15:03
epoch [8/50] batch [80/203] time 0.098 (0.103) data 0.000 (0.004) loss 1.2674 (1.3579) teacher_loss 0.0813 (0.1632) loss_zs_kd 0.0770 (0.0759) loss_oracle 0.5198 (0.5546) kd_loss 0.8877 (0.8795) acc 96.8750 (95.5859) gate/entropy 1.0482 (1.0495) gate/usage_max 0.4664 (0.4633) gate/usage_min 0.2092 (0.2097) gate/usage_std 0.1052 (0.1036) teacher/entropy 0.0581 (0.0548) teacher/usage_max 0.5693 (0.6080) teacher/usage_min 0.0637 (0.0606) teacher/usage_std 0.2078 (0.2298) nleep/row_max_mean 1506.3660 (1510.2225) nleep/row_max_std 60.1092 (64.7741) nleep/row_min_mean 1476.9856 (1481.7448) lr 1.9298e-03 eta 0:14:46
epoch [8/50] batch [100/203] time 0.083 (0.101) data 0.000 (0.004) loss 1.2735 (1.3628) teacher_loss 0.0667 (0.1652) loss_zs_kd 0.1110 (0.0782) loss_oracle 0.4645 (0.5494) kd_loss 0.9191 (0.8838) acc 100.0000 (95.6875) gate/entropy 1.0470 (1.0491) gate/usage_max 0.4686 (0.4641) gate/usage_min 0.2082 (0.2095) gate/usage_std 0.1065 (0.1041) teacher/entropy 0.0713 (0.0550) teacher/usage_max 0.4688 (0.5999) teacher/usage_min 0.0804 (0.0648) teacher/usage_std 0.1790 (0.2250) nleep/row_max_mean 1529.1628 (1510.9885) nleep/row_max_std 47.7595 (63.7419) nleep/row_min_mean 1498.9613 (1482.3816) lr 1.9298e-03 eta 0:14:27
epoch [8/50] batch [120/203] time 0.093 (0.099) data 0.000 (0.003) loss 1.3396 (1.3594) teacher_loss 0.1360 (0.1623) loss_zs_kd 0.0766 (0.0794) loss_oracle 0.5737 (0.5461) kd_loss 0.8785 (0.8843) acc 96.8750 (95.7552) gate/entropy 1.0464 (1.0488) gate/usage_max 0.4699 (0.4649) gate/usage_min 0.2080 (0.2093) gate/usage_std 0.1072 (0.1045) teacher/entropy 0.0077 (0.0557) teacher/usage_max 0.6878 (0.5984) teacher/usage_min 0.0316 (0.0675) teacher/usage_std 0.2705 (0.2234) nleep/row_max_mean 1532.6465 (1511.4290) nleep/row_max_std 65.5045 (63.6306) nleep/row_min_mean 1498.8773 (1482.5694) lr 1.9298e-03 eta 0:14:14
epoch [8/50] batch [140/203] time 0.091 (0.098) data 0.000 (0.003) loss 1.3126 (1.3487) teacher_loss 0.1221 (0.1552) loss_zs_kd 0.0932 (0.0784) loss_oracle 0.4820 (0.5444) kd_loss 0.9029 (0.8822) acc 96.8750 (96.0045) gate/entropy 1.0457 (1.0484) gate/usage_max 0.4715 (0.4657) gate/usage_min 0.2079 (0.2092) gate/usage_std 0.1080 (0.1049) teacher/entropy 0.0666 (0.0579) teacher/usage_max 0.5398 (0.5990) teacher/usage_min 0.0919 (0.0691) teacher/usage_std 0.1845 (0.2229) nleep/row_max_mean 1505.8489 (1511.5246) nleep/row_max_std 70.4316 (63.7661) nleep/row_min_mean 1478.0979 (1482.6771) lr 1.9298e-03 eta 0:14:05
epoch [8/50] batch [160/203] time 0.087 (0.098) data 0.000 (0.002) loss 1.2146 (1.3464) teacher_loss 0.0358 (0.1526) loss_zs_kd 0.0776 (0.0789) loss_oracle 0.5258 (0.5438) kd_loss 0.8771 (0.8825) acc 100.0000 (96.0742) gate/entropy 1.0450 (1.0480) gate/usage_max 0.4730 (0.4665) gate/usage_min 0.2075 (0.2090) gate/usage_std 0.1088 (0.1053) teacher/entropy 0.0071 (0.0574) teacher/usage_max 0.6881 (0.5980) teacher/usage_min 0.0316 (0.0686) teacher/usage_std 0.2706 (0.2230) nleep/row_max_mean 1522.5016 (1511.5891) nleep/row_max_std 61.6451 (63.9235) nleep/row_min_mean 1490.7285 (1482.6725) lr 1.9298e-03 eta 0:13:59
epoch [8/50] batch [180/203] time 0.089 (0.097) data 0.000 (0.002) loss 1.3550 (1.3436) teacher_loss 0.1583 (0.1511) loss_zs_kd 0.0814 (0.0790) loss_oracle 0.5227 (0.5434) kd_loss 0.8947 (0.8813) acc 90.6250 (95.9375) gate/entropy 1.0447 (1.0477) gate/usage_max 0.4739 (0.4673) gate/usage_min 0.2076 (0.2088) gate/usage_std 0.1092 (0.1057) teacher/entropy 0.0933 (0.0586) teacher/usage_max 0.5288 (0.5976) teacher/usage_min 0.1262 (0.0692) teacher/usage_std 0.1646 (0.2223) nleep/row_max_mean 1514.9573 (1510.7074) nleep/row_max_std 49.4914 (64.6354) nleep/row_min_mean 1489.0956 (1481.9331) lr 1.9298e-03 eta 0:13:53
epoch [8/50] batch [200/203] time 0.083 (0.097) data 0.000 (0.002) loss 1.4554 (1.3414) teacher_loss 0.2465 (0.1494) loss_zs_kd 0.0968 (0.0796) loss_oracle 0.5526 (0.5445) kd_loss 0.8842 (0.8799) acc 90.6250 (95.9844) gate/entropy 1.0439 (1.0473) gate/usage_max 0.4752 (0.4680) gate/usage_min 0.2071 (0.2087) gate/usage_std 0.1100 (0.1061) teacher/entropy 0.0719 (0.0594) teacher/usage_max 0.5879 (0.5979) teacher/usage_min 0.1113 (0.0694) teacher/usage_std 0.1959 (0.2224) nleep/row_max_mean 1509.6868 (1510.6301) nleep/row_max_std 67.2118 (64.6389) nleep/row_min_mean 1480.6638 (1481.9294) lr 1.9298e-03 eta 0:13:46
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,295
* accuracy: 82.1%
* error: 17.9%
* macro_f1: 86.0%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.3%, epoch: 7 *******
******* Domain c best val test acc: 100.0%, epoch: 7 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [9/50] batch [20/203] time 0.086 (0.099) data 0.000 (0.013) loss 1.4994 (1.2830) teacher_loss 0.3749 (0.1048) loss_zs_kd 0.0853 (0.0827) loss_oracle 0.5059 (0.5227) kd_loss 0.8289 (0.8755) acc 87.5000 (96.8750) gate/entropy 1.0434 (1.0435) gate/usage_max 0.4764 (0.4761) gate/usage_min 0.2069 (0.2069) gate/usage_std 0.1106 (0.1105) teacher/entropy 0.0634 (0.0587) teacher/usage_max 0.6528 (0.5945) teacher/usage_min 0.0221 (0.0641) teacher/usage_std 0.2576 (0.2218) nleep/row_max_mean 1493.2428 (1506.9420) nleep/row_max_std 79.7720 (70.6201) nleep/row_min_mean 1466.8215 (1478.3481) lr 1.9048e-03 eta 0:14:02
epoch [9/50] batch [40/203] time 0.153 (0.097) data 0.000 (0.007) loss 1.5278 (1.3285) teacher_loss 0.3347 (0.1377) loss_zs_kd 0.0677 (0.0774) loss_oracle 0.6066 (0.5356) kd_loss 0.8559 (0.8843) acc 90.6250 (96.0938) gate/entropy 1.0428 (1.0432) gate/usage_max 0.4774 (0.4765) gate/usage_min 0.2065 (0.2067) gate/usage_std 0.1112 (0.1108) teacher/entropy 0.0740 (0.0561) teacher/usage_max 0.6826 (0.5916) teacher/usage_min 0.1419 (0.0756) teacher/usage_std 0.2473 (0.2178) nleep/row_max_mean 1493.6304 (1508.8314) nleep/row_max_std 83.4629 (67.2226) nleep/row_min_mean 1467.0737 (1480.1768) lr 1.9048e-03 eta 0:13:42
epoch [9/50] batch [60/203] time 0.097 (0.098) data 0.001 (0.004) loss 1.5081 (1.3342) teacher_loss 0.4105 (0.1504) loss_zs_kd 0.0733 (0.0739) loss_oracle 0.4881 (0.5364) kd_loss 0.8168 (0.8787) acc 93.7500 (95.8854) gate/entropy 1.0420 (1.0429) gate/usage_max 0.4787 (0.4771) gate/usage_min 0.2060 (0.2065) gate/usage_std 0.1120 (0.1111) teacher/entropy 0.1161 (0.0568) teacher/usage_max 0.5752 (0.5944) teacher/usage_min 0.0457 (0.0676) teacher/usage_std 0.2186 (0.2218) nleep/row_max_mean 1503.7979 (1507.9128) nleep/row_max_std 71.7729 (67.4429) nleep/row_min_mean 1477.6472 (1479.8384) lr 1.9048e-03 eta 0:13:50
epoch [9/50] batch [80/203] time 0.094 (0.097) data 0.000 (0.003) loss 1.3025 (1.3292) teacher_loss 0.1055 (0.1486) loss_zs_kd 0.0778 (0.0754) loss_oracle 0.5178 (0.5331) kd_loss 0.8993 (0.8763) acc 96.8750 (95.8203) gate/entropy 1.0411 (1.0426) gate/usage_max 0.4802 (0.4776) gate/usage_min 0.2053 (0.2064) gate/usage_std 0.1130 (0.1114) teacher/entropy 0.0052 (0.0541) teacher/usage_max 0.6260 (0.5997) teacher/usage_min 0.0303 (0.0619) teacher/usage_std 0.2433 (0.2256) nleep/row_max_mean 1528.9883 (1508.7802) nleep/row_max_std 54.6122 (66.6972) nleep/row_min_mean 1498.8706 (1480.8190) lr 1.9048e-03 eta 0:13:39
epoch [9/50] batch [100/203] time 0.096 (0.097) data 0.001 (0.003) loss 1.4769 (1.3277) teacher_loss 0.2534 (0.1490) loss_zs_kd 0.0736 (0.0740) loss_oracle 0.5734 (0.5329) kd_loss 0.9001 (0.8752) acc 90.6250 (95.7500) gate/entropy 1.0408 (1.0423) gate/usage_max 0.4808 (0.4782) gate/usage_min 0.2051 (0.2062) gate/usage_std 0.1133 (0.1117) teacher/entropy 0.0240 (0.0514) teacher/usage_max 0.5623 (0.6039) teacher/usage_min 0.0148 (0.0574) teacher/usage_std 0.2323 (0.2292) nleep/row_max_mean 1522.2970 (1509.5497) nleep/row_max_std 54.2526 (66.6945) nleep/row_min_mean 1489.5262 (1481.4299) lr 1.9048e-03 eta 0:13:38
epoch [9/50] batch [120/203] time 0.101 (0.098) data 0.000 (0.002) loss 1.2796 (1.3216) teacher_loss 0.0625 (0.1433) loss_zs_kd 0.0798 (0.0740) loss_oracle 0.5484 (0.5309) kd_loss 0.9030 (0.8759) acc 96.8750 (96.0417) gate/entropy 1.0403 (1.0420) gate/usage_max 0.4815 (0.4787) gate/usage_min 0.2048 (0.2060) gate/usage_std 0.1138 (0.1121) teacher/entropy 0.0229 (0.0518) teacher/usage_max 0.5687 (0.6010) teacher/usage_min 0.0264 (0.0571) teacher/usage_std 0.2271 (0.2284) nleep/row_max_mean 1523.9880 (1509.8591) nleep/row_max_std 61.5611 (66.4389) nleep/row_min_mean 1493.6273 (1481.7400) lr 1.9048e-03 eta 0:13:44
epoch [9/50] batch [140/203] time 0.098 (0.098) data 0.000 (0.002) loss 1.2759 (1.3189) teacher_loss 0.1126 (0.1398) loss_zs_kd 0.0797 (0.0746) loss_oracle 0.5123 (0.5311) kd_loss 0.8674 (0.8762) acc 96.8750 (96.1161) gate/entropy 1.0397 (1.0417) gate/usage_max 0.4825 (0.4791) gate/usage_min 0.2043 (0.2058) gate/usage_std 0.1144 (0.1123) teacher/entropy 0.0508 (0.0527) teacher/usage_max 0.6090 (0.5992) teacher/usage_min 0.0494 (0.0589) teacher/usage_std 0.2285 (0.2271) nleep/row_max_mean 1512.7371 (1509.8409) nleep/row_max_std 83.0974 (65.9966) nleep/row_min_mean 1484.6711 (1481.7735) lr 1.9048e-03 eta 0:13:38
epoch [9/50] batch [160/203] time 0.091 (0.100) data 0.000 (0.002) loss 1.2958 (1.3222) teacher_loss 0.0163 (0.1398) loss_zs_kd 0.0731 (0.0755) loss_oracle 0.5052 (0.5329) kd_loss 0.9904 (0.8783) acc 100.0000 (96.1133) gate/entropy 1.0397 (1.0415) gate/usage_max 0.4826 (0.4796) gate/usage_min 0.2043 (0.2056) gate/usage_std 0.1145 (0.1126) teacher/entropy 0.0560 (0.0547) teacher/usage_max 0.4615 (0.5957) teacher/usage_min 0.1386 (0.0623) teacher/usage_std 0.1400 (0.2243) nleep/row_max_mean 1508.5488 (1509.7586) nleep/row_max_std 62.6646 (65.9429) nleep/row_min_mean 1483.1956 (1481.7964) lr 1.9048e-03 eta 0:13:53
epoch [9/50] batch [180/203] time 0.093 (0.099) data 0.000 (0.002) loss 1.3960 (1.3259) teacher_loss 0.1434 (0.1405) loss_zs_kd 0.0930 (0.0758) loss_oracle 0.6074 (0.5371) kd_loss 0.9024 (0.8789) acc 96.8750 (96.1111) gate/entropy 1.0393 (1.0413) gate/usage_max 0.4828 (0.4799) gate/usage_min 0.2038 (0.2054) gate/usage_std 0.1148 (0.1128) teacher/entropy 0.0667 (0.0557) teacher/usage_max 0.5251 (0.5914) teacher/usage_min 0.0848 (0.0630) teacher/usage_std 0.1842 (0.2223) nleep/row_max_mean 1506.5260 (1509.2020) nleep/row_max_std 78.4058 (66.1539) nleep/row_min_mean 1480.0737 (1481.2230) lr 1.9048e-03 eta 0:13:42
epoch [9/50] batch [200/203] time 0.083 (0.097) data 0.000 (0.002) loss 1.2841 (1.3242) teacher_loss 0.0681 (0.1367) loss_zs_kd 0.0752 (0.0770) loss_oracle 0.5261 (0.5402) kd_loss 0.9153 (0.8788) acc 100.0000 (96.2188) gate/entropy 1.0389 (1.0410) gate/usage_max 0.4833 (0.4803) gate/usage_min 0.2033 (0.2052) gate/usage_std 0.1152 (0.1131) teacher/entropy 0.1113 (0.0572) teacher/usage_max 0.4661 (0.5912) teacher/usage_min 0.1595 (0.0648) teacher/usage_std 0.1285 (0.2216) nleep/row_max_mean 1504.0356 (1508.8556) nleep/row_max_std 77.4738 (66.4472) nleep/row_min_mean 1479.3029 (1480.9385) lr 1.9048e-03 eta 0:13:30
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,266
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      83.3%, epoch: 7 *******
******* Domain c best val test acc: 100.0%, epoch: 7 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [10/50] batch [20/203] time 0.100 (0.109) data 0.001 (0.013) loss 1.3719 (1.2959) teacher_loss 0.1728 (0.1044) loss_zs_kd 0.0672 (0.0797) loss_oracle 0.5453 (0.5549) kd_loss 0.8928 (0.8742) acc 93.7500 (97.6562) gate/entropy 1.0388 (1.0388) gate/usage_max 0.4833 (0.4834) gate/usage_min 0.2031 (0.2032) gate/usage_std 0.1152 (0.1153) teacher/entropy 0.1077 (0.0670) teacher/usage_max 0.4942 (0.5861) teacher/usage_min 0.1288 (0.0810) teacher/usage_std 0.1523 (0.2121) nleep/row_max_mean 1509.7223 (1507.3421) nleep/row_max_std 65.6567 (71.1065) nleep/row_min_mean 1479.4642 (1478.9913) lr 1.8763e-03 eta 0:15:02
epoch [10/50] batch [40/203] time 0.089 (0.100) data 0.000 (0.007) loss 1.3648 (1.3270) teacher_loss 0.1577 (0.1178) loss_zs_kd 0.1147 (0.0816) loss_oracle 0.6022 (0.5571) kd_loss 0.8486 (0.8899) acc 93.7500 (96.8750) gate/entropy 1.0385 (1.0387) gate/usage_max 0.4836 (0.4835) gate/usage_min 0.2026 (0.2030) gate/usage_std 0.1156 (0.1154) teacher/entropy 0.0543 (0.0622) teacher/usage_max 0.6782 (0.5722) teacher/usage_min 0.0879 (0.0792) teacher/usage_std 0.2510 (0.2077) nleep/row_max_mean 1501.0383 (1508.1175) nleep/row_max_std 72.9397 (67.5625) nleep/row_min_mean 1473.1116 (1479.1799) lr 1.8763e-03 eta 0:13:45
epoch [10/50] batch [60/203] time 0.100 (0.097) data 0.001 (0.005) loss 1.2282 (1.3238) teacher_loss 0.0763 (0.1268) loss_zs_kd 0.0926 (0.0803) loss_oracle 0.4683 (0.5444) kd_loss 0.8714 (0.8847) acc 100.0000 (96.4583) gate/entropy 1.0381 (1.0386) gate/usage_max 0.4841 (0.4836) gate/usage_min 0.2022 (0.2028) gate/usage_std 0.1159 (0.1155) teacher/entropy 0.0611 (0.0602) teacher/usage_max 0.5568 (0.5808) teacher/usage_min 0.0362 (0.0725) teacher/usage_std 0.2188 (0.2137) nleep/row_max_mean 1527.5107 (1510.3975) nleep/row_max_std 55.3962 (65.8427) nleep/row_min_mean 1499.5165 (1481.4098) lr 1.8763e-03 eta 0:13:21
epoch [10/50] batch [80/203] time 0.095 (0.096) data 0.000 (0.004) loss 1.2320 (1.3122) teacher_loss 0.1192 (0.1206) loss_zs_kd 0.0906 (0.0771) loss_oracle 0.5328 (0.5400) kd_loss 0.8010 (0.8831) acc 96.8750 (96.6797) gate/entropy 1.0378 (1.0384) gate/usage_max 0.4845 (0.4837) gate/usage_min 0.2020 (0.2027) gate/usage_std 0.1162 (0.1156) teacher/entropy 0.0513 (0.0615) teacher/usage_max 0.7184 (0.5796) teacher/usage_min 0.0107 (0.0714) teacher/usage_std 0.2923 (0.2136) nleep/row_max_mean 1512.4424 (1510.1302) nleep/row_max_std 70.8516 (65.0807) nleep/row_min_mean 1485.9403 (1481.3300) lr 1.8763e-03 eta 0:13:15
epoch [10/50] batch [100/203] time 0.097 (0.096) data 0.000 (0.003) loss 1.3303 (1.3201) teacher_loss 0.0220 (0.1251) loss_zs_kd 0.0707 (0.0768) loss_oracle 0.5535 (0.5433) kd_loss 0.9962 (0.8850) acc 100.0000 (96.6250) gate/entropy 1.0376 (1.0383) gate/usage_max 0.4844 (0.4839) gate/usage_min 0.2015 (0.2025) gate/usage_std 0.1163 (0.1157) teacher/entropy 0.0199 (0.0600) teacher/usage_max 0.5936 (0.5748) teacher/usage_min 0.0402 (0.0678) teacher/usage_std 0.2271 (0.2140) nleep/row_max_mean 1525.7422 (1510.4996) nleep/row_max_std 51.6086 (65.0663) nleep/row_min_mean 1493.4071 (1481.7147) lr 1.8763e-03 eta 0:13:12
epoch [10/50] batch [120/203] time 0.087 (0.097) data 0.000 (0.002) loss 1.2042 (1.3257) teacher_loss 0.0655 (0.1269) loss_zs_kd 0.0769 (0.0787) loss_oracle 0.5490 (0.5478) kd_loss 0.8258 (0.8855) acc 100.0000 (96.6146) gate/entropy 1.0376 (1.0382) gate/usage_max 0.4840 (0.4839) gate/usage_min 0.2010 (0.2023) gate/usage_std 0.1163 (0.1158) teacher/entropy 0.0414 (0.0572) teacher/usage_max 0.6736 (0.5766) teacher/usage_min 0.0052 (0.0646) teacher/usage_std 0.2730 (0.2162) nleep/row_max_mean 1509.4973 (1510.4527) nleep/row_max_std 76.5560 (64.9117) nleep/row_min_mean 1480.2292 (1481.5322) lr 1.8763e-03 eta 0:13:13
epoch [10/50] batch [140/203] time 0.089 (0.097) data 0.000 (0.002) loss 1.3230 (1.3271) teacher_loss 0.1017 (0.1296) loss_zs_kd 0.0709 (0.0776) loss_oracle 0.6063 (0.5460) kd_loss 0.8827 (0.8857) acc 96.8750 (96.4509) gate/entropy 1.0372 (1.0381) gate/usage_max 0.4843 (0.4839) gate/usage_min 0.2004 (0.2021) gate/usage_std 0.1166 (0.1159) teacher/entropy 0.0317 (0.0557) teacher/usage_max 0.6210 (0.5774) teacher/usage_min 0.0608 (0.0629) teacher/usage_std 0.2290 (0.2172) nleep/row_max_mean 1509.2826 (1509.9425) nleep/row_max_std 74.2223 (65.1692) nleep/row_min_mean 1479.5721 (1480.9261) lr 1.8763e-03 eta 0:13:16
epoch [10/50] batch [160/203] time 0.091 (0.097) data 0.000 (0.002) loss 1.2354 (1.3283) teacher_loss 0.0547 (0.1309) loss_zs_kd 0.0863 (0.0780) loss_oracle 0.5409 (0.5461) kd_loss 0.8671 (0.8854) acc 100.0000 (96.3477) gate/entropy 1.0368 (1.0380) gate/usage_max 0.4848 (0.4840) gate/usage_min 0.2000 (0.2019) gate/usage_std 0.1170 (0.1160) teacher/entropy 0.0573 (0.0561) teacher/usage_max 0.5698 (0.5771) teacher/usage_min 0.0340 (0.0636) teacher/usage_std 0.2232 (0.2170) nleep/row_max_mean 1513.5598 (1510.1703) nleep/row_max_std 61.8367 (64.8071) nleep/row_min_mean 1486.6892 (1481.0292) lr 1.8763e-03 eta 0:13:11
epoch [10/50] batch [180/203] time 0.091 (0.097) data 0.000 (0.002) loss 1.7138 (1.3286) teacher_loss 0.5052 (0.1325) loss_zs_kd 0.0645 (0.0787) loss_oracle 0.5369 (0.5448) kd_loss 0.9079 (0.8843) acc 87.5000 (96.3021) gate/entropy 1.0368 (1.0379) gate/usage_max 0.4847 (0.4840) gate/usage_min 0.1998 (0.2017) gate/usage_std 0.1170 (0.1161) teacher/entropy 0.0761 (0.0574) teacher/usage_max 0.5551 (0.5761) teacher/usage_min 0.1519 (0.0649) teacher/usage_std 0.1671 (0.2161) nleep/row_max_mean 1494.0757 (1509.7824) nleep/row_max_std 74.6290 (65.3028) nleep/row_min_mean 1465.0350 (1480.5803) lr 1.8763e-03 eta 0:13:09
epoch [10/50] batch [200/203] time 0.090 (0.096) data 0.000 (0.002) loss 1.5200 (1.3309) teacher_loss 0.3244 (0.1356) loss_zs_kd 0.0642 (0.0789) loss_oracle 0.5353 (0.5444) kd_loss 0.8959 (0.8837) acc 90.6250 (96.2656) gate/entropy 1.0366 (1.0378) gate/usage_max 0.4850 (0.4841) gate/usage_min 0.1997 (0.2015) gate/usage_std 0.1172 (0.1161) teacher/entropy 0.0698 (0.0576) teacher/usage_max 0.5848 (0.5752) teacher/usage_min 0.1422 (0.0644) teacher/usage_std 0.1857 (0.2157) nleep/row_max_mean 1519.4135 (1509.6708) nleep/row_max_std 56.6309 (65.4532) nleep/row_min_mean 1488.8103 (1480.3816) lr 1.8763e-03 eta 0:13:03
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,289
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 85.9%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.3%, epoch: 7 *******
******* Domain c best val test acc: 100.0%, epoch: 7 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [11/50] batch [20/203] time 0.099 (0.110) data 0.000 (0.015) loss 1.5093 (1.3264) teacher_loss 0.2304 (0.1139) loss_zs_kd 0.0766 (0.0808) loss_oracle 0.6164 (0.5388) kd_loss 0.9324 (0.9027) acc 93.7500 (96.7188) gate/entropy 1.0363 (1.0364) gate/usage_max 0.4856 (0.4852) gate/usage_min 0.1996 (0.1996) gate/usage_std 0.1175 (0.1173) teacher/entropy 0.0360 (0.0695) teacher/usage_max 0.5009 (0.5399) teacher/usage_min 0.0665 (0.1103) teacher/usage_std 0.1907 (0.1838) nleep/row_max_mean 1498.6858 (1510.5265) nleep/row_max_std 76.8377 (65.6833) nleep/row_min_mean 1467.6079 (1480.9416) lr 1.8443e-03 eta 0:14:53
epoch [11/50] batch [40/203] time 0.100 (0.104) data 0.000 (0.007) loss 1.5458 (1.3340) teacher_loss 0.2873 (0.1210) loss_zs_kd 0.0992 (0.0820) loss_oracle 0.5326 (0.5369) kd_loss 0.9426 (0.9036) acc 87.5000 (96.4062) gate/entropy 1.0360 (1.0363) gate/usage_max 0.4863 (0.4856) gate/usage_min 0.1996 (0.1996) gate/usage_std 0.1179 (0.1175) teacher/entropy 0.0107 (0.0638) teacher/usage_max 0.5310 (0.5522) teacher/usage_min 0.0623 (0.1116) teacher/usage_std 0.1982 (0.1877) nleep/row_max_mean 1506.7102 (1510.3979) nleep/row_max_std 70.4869 (67.0227) nleep/row_min_mean 1475.8726 (1480.3939) lr 1.8443e-03 eta 0:13:59
epoch [11/50] batch [60/203] time 0.092 (0.101) data 0.001 (0.005) loss 1.1806 (1.3307) teacher_loss 0.0439 (0.1182) loss_zs_kd 0.0572 (0.0822) loss_oracle 0.6162 (0.5407) kd_loss 0.8001 (0.9010) acc 100.0000 (96.5104) gate/entropy 1.0355 (1.0361) gate/usage_max 0.4875 (0.4861) gate/usage_min 0.1999 (0.1996) gate/usage_std 0.1183 (0.1177) teacher/entropy 0.1318 (0.0665) teacher/usage_max 0.6176 (0.5568) teacher/usage_min 0.0995 (0.1140) teacher/usage_std 0.2145 (0.1889) nleep/row_max_mean 1506.5018 (1510.9766) nleep/row_max_std 73.3969 (65.7903) nleep/row_min_mean 1478.4766 (1480.5261) lr 1.8443e-03 eta 0:13:32
epoch [11/50] batch [80/203] time 0.093 (0.099) data 0.000 (0.004) loss 1.3288 (1.3366) teacher_loss 0.0677 (0.1221) loss_zs_kd 0.0844 (0.0835) loss_oracle 0.6303 (0.5469) kd_loss 0.9038 (0.8993) acc 100.0000 (96.6016) gate/entropy 1.0352 (1.0359) gate/usage_max 0.4884 (0.4865) gate/usage_min 0.2001 (0.1997) gate/usage_std 0.1187 (0.1179) teacher/entropy 0.0976 (0.0733) teacher/usage_max 0.5804 (0.5553) teacher/usage_min 0.1987 (0.1247) teacher/usage_std 0.1749 (0.1839) nleep/row_max_mean 1524.6074 (1509.5740) nleep/row_max_std 59.0194 (66.6741) nleep/row_min_mean 1487.3440 (1479.1505) lr 1.8443e-03 eta 0:13:17
epoch [11/50] batch [100/203] time 0.096 (0.098) data 0.000 (0.003) loss 1.4157 (1.3402) teacher_loss 0.2662 (0.1278) loss_zs_kd 0.0875 (0.0833) loss_oracle 0.5914 (0.5486) kd_loss 0.8100 (0.8964) acc 90.6250 (96.3750) gate/entropy 1.0347 (1.0357) gate/usage_max 0.4899 (0.4870) gate/usage_min 0.2002 (0.1998) gate/usage_std 0.1194 (0.1181) teacher/entropy 0.0643 (0.0768) teacher/usage_max 0.6792 (0.5561) teacher/usage_min 0.0315 (0.1276) teacher/usage_std 0.2662 (0.1826) nleep/row_max_mean 1500.1742 (1509.6322) nleep/row_max_std 74.4341 (66.2031) nleep/row_min_mean 1466.8284 (1479.1011) lr 1.8443e-03 eta 0:13:09
epoch [11/50] batch [120/203] time 0.095 (0.098) data 0.000 (0.003) loss 1.4246 (1.3297) teacher_loss 0.2187 (0.1191) loss_zs_kd 0.0890 (0.0836) loss_oracle 0.5757 (0.5477) kd_loss 0.8736 (0.8949) acc 90.6250 (96.7188) gate/entropy 1.0345 (1.0356) gate/usage_max 0.4902 (0.4875) gate/usage_min 0.2003 (0.1999) gate/usage_std 0.1196 (0.1183) teacher/entropy 0.1028 (0.0784) teacher/usage_max 0.5690 (0.5538) teacher/usage_min 0.1507 (0.1260) teacher/usage_std 0.1748 (0.1821) nleep/row_max_mean 1511.5773 (1509.6789) nleep/row_max_std 74.2386 (66.0227) nleep/row_min_mean 1482.6206 (1479.2551) lr 1.8443e-03 eta 0:13:01
epoch [11/50] batch [140/203] time 0.092 (0.097) data 0.000 (0.002) loss 1.2772 (1.3343) teacher_loss 0.0808 (0.1238) loss_zs_kd 0.0747 (0.0831) loss_oracle 0.5160 (0.5491) kd_loss 0.9011 (0.8945) acc 96.8750 (96.5402) gate/entropy 1.0342 (1.0354) gate/usage_max 0.4908 (0.4880) gate/usage_min 0.2001 (0.2000) gate/usage_std 0.1199 (0.1185) teacher/entropy 0.1014 (0.0759) teacher/usage_max 0.4721 (0.5564) teacher/usage_min 0.1104 (0.1216) teacher/usage_std 0.1592 (0.1848) nleep/row_max_mean 1501.9463 (1509.8144) nleep/row_max_std 84.5028 (66.2631) nleep/row_min_mean 1472.7898 (1479.3792) lr 1.8443e-03 eta 0:12:54
epoch [11/50] batch [160/203] time 0.091 (0.097) data 0.000 (0.002) loss 1.4498 (1.3346) teacher_loss 0.1859 (0.1258) loss_zs_kd 0.0901 (0.0831) loss_oracle 0.5643 (0.5494) kd_loss 0.9367 (0.8926) acc 96.8750 (96.4453) gate/entropy 1.0342 (1.0352) gate/usage_max 0.4906 (0.4883) gate/usage_min 0.2000 (0.2000) gate/usage_std 0.1198 (0.1187) teacher/entropy 0.1285 (0.0765) teacher/usage_max 0.4208 (0.5575) teacher/usage_min 0.1787 (0.1183) teacher/usage_std 0.1097 (0.1862) nleep/row_max_mean 1506.6434 (1508.9750) nleep/row_max_std 74.0750 (67.1272) nleep/row_min_mean 1477.3787 (1478.7684) lr 1.8443e-03 eta 0:12:49
epoch [11/50] batch [180/203] time 0.096 (0.097) data 0.000 (0.002) loss 1.2818 (1.3325) teacher_loss 0.0650 (0.1276) loss_zs_kd 0.0725 (0.0820) loss_oracle 0.5070 (0.5461) kd_loss 0.9270 (0.8909) acc 100.0000 (96.4757) gate/entropy 1.0339 (1.0351) gate/usage_max 0.4911 (0.4886) gate/usage_min 0.1999 (0.2000) gate/usage_std 0.1201 (0.1189) teacher/entropy 0.1193 (0.0758) teacher/usage_max 0.4245 (0.5592) teacher/usage_min 0.1598 (0.1133) teacher/usage_std 0.1227 (0.1887) nleep/row_max_mean 1502.9288 (1508.7795) nleep/row_max_std 74.0728 (67.3808) nleep/row_min_mean 1476.1387 (1478.7808) lr 1.8443e-03 eta 0:12:48
epoch [11/50] batch [200/203] time 0.088 (0.096) data 0.000 (0.002) loss 1.3381 (1.3354) teacher_loss 0.1025 (0.1290) loss_zs_kd 0.0932 (0.0819) loss_oracle 0.5546 (0.5483) kd_loss 0.9116 (0.8913) acc 96.8750 (96.4688) gate/entropy 1.0338 (1.0350) gate/usage_max 0.4910 (0.4888) gate/usage_min 0.1995 (0.2000) gate/usage_std 0.1202 (0.1190) teacher/entropy 0.0539 (0.0724) teacher/usage_max 0.5241 (0.5619) teacher/usage_min 0.0146 (0.1067) teacher/usage_std 0.2268 (0.1928) nleep/row_max_mean 1511.1163 (1508.4067) nleep/row_max_std 54.9388 (67.4141) nleep/row_min_mean 1482.9395 (1478.5597) lr 1.8443e-03 eta 0:12:42
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,270
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.3%, epoch: 7 *******
******* Domain c best val test acc: 100.0%, epoch: 7 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [12/50] batch [20/203] time 0.113 (0.111) data 0.000 (0.017) loss 1.3341 (1.2913) teacher_loss 0.0768 (0.1059) loss_zs_kd 0.0768 (0.0836) loss_oracle 0.5602 (0.5656) kd_loss 0.9388 (0.8608) acc 96.8750 (97.0312) gate/entropy 1.0334 (1.0338) gate/usage_max 0.4913 (0.4908) gate/usage_min 0.1988 (0.1992) gate/usage_std 0.1205 (0.1202) teacher/entropy 0.0257 (0.0361) teacher/usage_max 0.4901 (0.6256) teacher/usage_min 0.0318 (0.0282) teacher/usage_std 0.2133 (0.2507) nleep/row_max_mean 1519.0679 (1507.4323) nleep/row_max_std 65.4600 (70.7232) nleep/row_min_mean 1490.2441 (1478.6196) lr 1.8090e-03 eta 0:14:33
epoch [12/50] batch [40/203] time 0.115 (0.105) data 0.001 (0.009) loss 1.5322 (1.3224) teacher_loss 0.2443 (0.1221) loss_zs_kd 0.0833 (0.0772) loss_oracle 0.6170 (0.5715) kd_loss 0.9377 (0.8760) acc 90.6250 (96.7188) gate/entropy 1.0336 (1.0337) gate/usage_max 0.4904 (0.4908) gate/usage_min 0.1985 (0.1990) gate/usage_std 0.1202 (0.1202) teacher/entropy 0.0268 (0.0371) teacher/usage_max 0.4940 (0.6022) teacher/usage_min 0.0302 (0.0338) teacher/usage_std 0.2145 (0.2396) nleep/row_max_mean 1506.0292 (1507.5340) nleep/row_max_std 65.4838 (69.4054) nleep/row_min_mean 1478.4396 (1478.3422) lr 1.8090e-03 eta 0:13:50
epoch [12/50] batch [60/203] time 0.104 (0.105) data 0.002 (0.006) loss 1.2149 (1.3183) teacher_loss 0.0546 (0.1140) loss_zs_kd 0.0662 (0.0763) loss_oracle 0.4929 (0.5667) kd_loss 0.8808 (0.8829) acc 100.0000 (96.9792) gate/entropy 1.0339 (1.0337) gate/usage_max 0.4894 (0.4905) gate/usage_min 0.1980 (0.1987) gate/usage_std 0.1199 (0.1202) teacher/entropy 0.0556 (0.0355) teacher/usage_max 0.5410 (0.5997) teacher/usage_min 0.0362 (0.0303) teacher/usage_std 0.2156 (0.2399) nleep/row_max_mean 1493.1886 (1509.1608) nleep/row_max_std 80.2255 (67.7642) nleep/row_min_mean 1463.7988 (1479.2244) lr 1.8090e-03 eta 0:13:43
epoch [12/50] batch [80/203] time 0.106 (0.104) data 0.000 (0.004) loss 1.2685 (1.3320) teacher_loss 0.0499 (0.1214) loss_zs_kd 0.0454 (0.0767) loss_oracle 0.5395 (0.5637) kd_loss 0.9262 (0.8904) acc 96.8750 (96.6016) gate/entropy 1.0341 (1.0338) gate/usage_max 0.4880 (0.4900) gate/usage_min 0.1972 (0.1984) gate/usage_std 0.1194 (0.1200) teacher/entropy 0.0599 (0.0358) teacher/usage_max 0.4731 (0.5855) teacher/usage_min 0.0688 (0.0302) teacher/usage_std 0.1872 (0.2355) nleep/row_max_mean 1483.0906 (1509.4415) nleep/row_max_std 90.8255 (66.9637) nleep/row_min_mean 1454.7054 (1479.2791) lr 1.8090e-03 eta 0:13:34
epoch [12/50] batch [100/203] time 0.106 (0.101) data 0.000 (0.004) loss 1.2438 (1.3326) teacher_loss 0.0586 (0.1226) loss_zs_kd 0.0835 (0.0761) loss_oracle 0.5745 (0.5609) kd_loss 0.8562 (0.8915) acc 100.0000 (96.4375) gate/entropy 1.0341 (1.0338) gate/usage_max 0.4869 (0.4895) gate/usage_min 0.1961 (0.1981) gate/usage_std 0.1193 (0.1199) teacher/entropy 0.0632 (0.0372) teacher/usage_max 0.5632 (0.5781) teacher/usage_min 0.0263 (0.0289) teacher/usage_std 0.2259 (0.2335) nleep/row_max_mean 1490.4674 (1510.0190) nleep/row_max_std 90.2880 (66.3949) nleep/row_min_mean 1461.5179 (1479.6179) lr 1.8090e-03 eta 0:13:08
epoch [12/50] batch [120/203] time 0.093 (0.099) data 0.000 (0.003) loss 1.3782 (1.3387) teacher_loss 0.1190 (0.1298) loss_zs_kd 0.0399 (0.0767) loss_oracle 0.5594 (0.5593) kd_loss 0.9596 (0.8909) acc 93.7500 (96.1979) gate/entropy 1.0342 (1.0339) gate/usage_max 0.4858 (0.4890) gate/usage_min 0.1955 (0.1977) gate/usage_std 0.1190 (0.1198) teacher/entropy 0.0300 (0.0380) teacher/usage_max 0.4962 (0.5761) teacher/usage_min 0.0657 (0.0294) teacher/usage_std 0.1907 (0.2327) nleep/row_max_mean 1491.3546 (1509.7050) nleep/row_max_std 92.1316 (66.9182) nleep/row_min_mean 1464.0715 (1479.3509) lr 1.8090e-03 eta 0:12:54
epoch [12/50] batch [140/203] time 0.091 (0.100) data 0.000 (0.003) loss 1.2353 (1.3320) teacher_loss 0.0542 (0.1272) loss_zs_kd 0.0797 (0.0757) loss_oracle 0.5761 (0.5549) kd_loss 0.8532 (0.8895) acc 96.8750 (96.2723) gate/entropy 1.0345 (1.0340) gate/usage_max 0.4845 (0.4884) gate/usage_min 0.1949 (0.1973) gate/usage_std 0.1186 (0.1196) teacher/entropy 0.0414 (0.0408) teacher/usage_max 0.6098 (0.5734) teacher/usage_min 0.0187 (0.0301) teacher/usage_std 0.2428 (0.2313) nleep/row_max_mean 1517.8906 (1509.1842) nleep/row_max_std 48.3176 (66.8290) nleep/row_min_mean 1486.3926 (1478.9210) lr 1.8090e-03 eta 0:12:56
epoch [12/50] batch [160/203] time 0.105 (0.099) data 0.000 (0.002) loss 1.2180 (1.3280) teacher_loss 0.1054 (0.1233) loss_zs_kd 0.0521 (0.0759) loss_oracle 0.4826 (0.5525) kd_loss 0.8453 (0.8905) acc 96.8750 (96.4258) gate/entropy 1.0347 (1.0340) gate/usage_max 0.4833 (0.4878) gate/usage_min 0.1943 (0.1970) gate/usage_std 0.1182 (0.1195) teacher/entropy 0.0622 (0.0414) teacher/usage_max 0.5621 (0.5706) teacher/usage_min 0.0073 (0.0312) teacher/usage_std 0.2367 (0.2298) nleep/row_max_mean 1493.7441 (1509.2394) nleep/row_max_std 78.3137 (66.8236) nleep/row_min_mean 1466.7207 (1478.9690) lr 1.8090e-03 eta 0:12:51
epoch [12/50] batch [180/203] time 0.093 (0.099) data 0.000 (0.002) loss 1.4079 (1.3328) teacher_loss 0.2161 (0.1286) loss_zs_kd 0.0642 (0.0758) loss_oracle 0.5250 (0.5503) kd_loss 0.8973 (0.8911) acc 96.8750 (96.3715) gate/entropy 1.0346 (1.0341) gate/usage_max 0.4826 (0.4873) gate/usage_min 0.1936 (0.1966) gate/usage_std 0.1182 (0.1193) teacher/entropy 0.0393 (0.0416) teacher/usage_max 0.5556 (0.5688) teacher/usage_min 0.0615 (0.0318) teacher/usage_std 0.2047 (0.2290) nleep/row_max_mean 1503.2649 (1509.4057) nleep/row_max_std 72.9718 (66.4877) nleep/row_min_mean 1475.0732 (1479.1279) lr 1.8090e-03 eta 0:12:46
epoch [12/50] batch [200/203] time 0.086 (0.099) data 0.000 (0.002) loss 1.3234 (1.3323) teacher_loss 0.0932 (0.1281) loss_zs_kd 0.0660 (0.0750) loss_oracle 0.5927 (0.5493) kd_loss 0.9008 (0.8920) acc 96.8750 (96.3906) gate/entropy 1.0348 (1.0341) gate/usage_max 0.4812 (0.4868) gate/usage_min 0.1929 (0.1963) gate/usage_std 0.1178 (0.1192) teacher/entropy 0.0363 (0.0419) teacher/usage_max 0.5033 (0.5652) teacher/usage_min 0.0118 (0.0319) teacher/usage_std 0.2275 (0.2280) nleep/row_max_mean 1514.1002 (1509.7182) nleep/row_max_std 60.7256 (66.3195) nleep/row_min_mean 1480.5568 (1479.4435) lr 1.8090e-03 eta 0:12:40
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,291
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 85.8%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.3%, epoch: 7 *******
******* Domain c best val test acc: 100.0%, epoch: 7 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [13/50] batch [20/203] time 0.089 (0.119) data 0.000 (0.017) loss 1.3894 (1.3325) teacher_loss 0.1972 (0.1246) loss_zs_kd 0.0759 (0.0742) loss_oracle 0.5725 (0.5665) kd_loss 0.8680 (0.8875) acc 90.6250 (95.9375) gate/entropy 1.0348 (1.0348) gate/usage_max 0.4797 (0.4803) gate/usage_min 0.1918 (0.1923) gate/usage_std 0.1176 (0.1177) teacher/entropy 0.0545 (0.0532) teacher/usage_max 0.5205 (0.5235) teacher/usage_min 0.0128 (0.0373) teacher/usage_std 0.2277 (0.2141) nleep/row_max_mean 1512.6259 (1509.2902) nleep/row_max_std 73.1122 (66.3184) nleep/row_min_mean 1482.9546 (1478.9080) lr 1.7705e-03 eta 0:15:16
epoch [13/50] batch [40/203] time 0.097 (0.107) data 0.000 (0.009) loss 1.2348 (1.3305) teacher_loss 0.1167 (0.1242) loss_zs_kd 0.0489 (0.0722) loss_oracle 0.4675 (0.5654) kd_loss 0.8599 (0.8875) acc 93.7500 (96.3281) gate/entropy 1.0352 (1.0349) gate/usage_max 0.4779 (0.4796) gate/usage_min 0.1913 (0.1918) gate/usage_std 0.1170 (0.1175) teacher/entropy 0.1014 (0.0544) teacher/usage_max 0.5002 (0.5308) teacher/usage_min 0.0725 (0.0375) teacher/usage_std 0.1868 (0.2151) nleep/row_max_mean 1484.0332 (1510.3750) nleep/row_max_std 82.1241 (65.0010) nleep/row_min_mean 1461.5360 (1479.9952) lr 1.7705e-03 eta 0:13:42
epoch [13/50] batch [60/203] time 0.094 (0.105) data 0.001 (0.006) loss 1.2698 (1.3172) teacher_loss 0.0454 (0.1228) loss_zs_kd 0.0831 (0.0700) loss_oracle 0.5650 (0.5547) kd_loss 0.9004 (0.8821) acc 100.0000 (96.5104) gate/entropy 1.0350 (1.0349) gate/usage_max 0.4774 (0.4790) gate/usage_min 0.1905 (0.1915) gate/usage_std 0.1171 (0.1174) teacher/entropy 0.0382 (0.0588) teacher/usage_max 0.4976 (0.5360) teacher/usage_min 0.0305 (0.0420) teacher/usage_std 0.2144 (0.2147) nleep/row_max_mean 1516.8457 (1509.8517) nleep/row_max_std 61.8716 (65.7786) nleep/row_min_mean 1485.3716 (1479.8614) lr 1.7705e-03 eta 0:13:25
epoch [13/50] batch [80/203] time 0.098 (0.104) data 0.000 (0.005) loss 1.3323 (1.3309) teacher_loss 0.1597 (0.1305) loss_zs_kd 0.0699 (0.0742) loss_oracle 0.5400 (0.5589) kd_loss 0.8676 (0.8839) acc 96.8750 (96.5234) gate/entropy 1.0347 (1.0349) gate/usage_max 0.4766 (0.4785) gate/usage_min 0.1896 (0.1911) gate/usage_std 0.1172 (0.1173) teacher/entropy 0.0522 (0.0563) teacher/usage_max 0.5211 (0.5436) teacher/usage_min 0.0154 (0.0402) teacher/usage_std 0.2260 (0.2176) nleep/row_max_mean 1527.5510 (1510.1702) nleep/row_max_std 59.2487 (65.5854) nleep/row_min_mean 1496.6663 (1479.8848) lr 1.7705e-03 eta 0:13:12
epoch [13/50] batch [100/203] time 0.094 (0.102) data 0.000 (0.004) loss 1.2282 (1.3270) teacher_loss 0.1117 (0.1304) loss_zs_kd 0.0511 (0.0731) loss_oracle 0.5202 (0.5555) kd_loss 0.8309 (0.8823) acc 96.8750 (96.5938) gate/entropy 1.0350 (1.0349) gate/usage_max 0.4753 (0.4779) gate/usage_min 0.1892 (0.1908) gate/usage_std 0.1168 (0.1172) teacher/entropy 0.0796 (0.0573) teacher/usage_max 0.5461 (0.5452) teacher/usage_min 0.0161 (0.0391) teacher/usage_std 0.2286 (0.2183) nleep/row_max_mean 1515.2927 (1510.0190) nleep/row_max_std 68.9747 (66.0366) nleep/row_min_mean 1486.4486 (1479.6637) lr 1.7705e-03 eta 0:12:59
epoch [13/50] batch [120/203] time 0.088 (0.101) data 0.000 (0.003) loss 1.2753 (1.3268) teacher_loss 0.0687 (0.1307) loss_zs_kd 0.0735 (0.0718) loss_oracle 0.4689 (0.5513) kd_loss 0.9354 (0.8846) acc 100.0000 (96.6406) gate/entropy 1.0347 (1.0349) gate/usage_max 0.4751 (0.4774) gate/usage_min 0.1886 (0.1905) gate/usage_std 0.1170 (0.1172) teacher/entropy 0.0181 (0.0551) teacher/usage_max 0.4978 (0.5452) teacher/usage_min 0.0630 (0.0411) teacher/usage_std 0.1927 (0.2170) nleep/row_max_mean 1527.7395 (1510.2885) nleep/row_max_std 47.8518 (65.9699) nleep/row_min_mean 1496.9346 (1480.0656) lr 1.7705e-03 eta 0:12:49
epoch [13/50] batch [140/203] time 0.097 (0.100) data 0.000 (0.003) loss 1.1898 (1.3230) teacher_loss 0.0287 (0.1288) loss_zs_kd 0.0584 (0.0720) loss_oracle 0.5330 (0.5501) kd_loss 0.8654 (0.8832) acc 100.0000 (96.6295) gate/entropy 1.0349 (1.0349) gate/usage_max 0.4742 (0.4770) gate/usage_min 0.1886 (0.1902) gate/usage_std 0.1167 (0.1171) teacher/entropy 0.0404 (0.0538) teacher/usage_max 0.5799 (0.5478) teacher/usage_min 0.0294 (0.0399) teacher/usage_std 0.2284 (0.2181) nleep/row_max_mean 1502.0745 (1510.2679) nleep/row_max_std 70.4814 (66.4033) nleep/row_min_mean 1474.6562 (1480.1805) lr 1.7705e-03 eta 0:12:38
epoch [13/50] batch [160/203] time 0.183 (0.100) data 0.001 (0.002) loss 1.4289 (1.3282) teacher_loss 0.1994 (0.1310) loss_zs_kd 0.0628 (0.0730) loss_oracle 0.5457 (0.5530) kd_loss 0.9253 (0.8842) acc 93.7500 (96.5430) gate/entropy 1.0350 (1.0349) gate/usage_max 0.4735 (0.4766) gate/usage_min 0.1881 (0.1899) gate/usage_std 0.1165 (0.1171) teacher/entropy 0.0687 (0.0530) teacher/usage_max 0.5257 (0.5482) teacher/usage_min 0.1510 (0.0412) teacher/usage_std 0.1531 (0.2176) nleep/row_max_mean 1469.6345 (1509.8972) nleep/row_max_std 95.5665 (66.7201) nleep/row_min_mean 1445.0344 (1479.9230) lr 1.7705e-03 eta 0:12:34
epoch [13/50] batch [180/203] time 0.088 (0.099) data 0.000 (0.002) loss 1.2444 (1.3299) teacher_loss 0.1272 (0.1339) loss_zs_kd 0.0530 (0.0724) loss_oracle 0.5320 (0.5547) kd_loss 0.8247 (0.8825) acc 100.0000 (96.4583) gate/entropy 1.0348 (1.0349) gate/usage_max 0.4728 (0.4762) gate/usage_min 0.1874 (0.1897) gate/usage_std 0.1166 (0.1170) teacher/entropy 0.0902 (0.0536) teacher/usage_max 0.6240 (0.5498) teacher/usage_min 0.0717 (0.0401) teacher/usage_std 0.2264 (0.2187) nleep/row_max_mean 1504.4597 (1509.7080) nleep/row_max_std 68.9440 (66.9982) nleep/row_min_mean 1481.0850 (1479.6828) lr 1.7705e-03 eta 0:12:29
epoch [13/50] batch [200/203] time 0.087 (0.098) data 0.000 (0.002) loss 1.5795 (1.3294) teacher_loss 0.2937 (0.1325) loss_zs_kd 0.0904 (0.0726) loss_oracle 0.6271 (0.5574) kd_loss 0.9271 (0.8820) acc 93.7500 (96.5469) gate/entropy 1.0346 (1.0348) gate/usage_max 0.4713 (0.4758) gate/usage_min 0.1864 (0.1894) gate/usage_std 0.1165 (0.1170) teacher/entropy 0.0152 (0.0530) teacher/usage_max 0.5018 (0.5493) teacher/usage_min 0.0326 (0.0386) teacher/usage_std 0.2131 (0.2193) nleep/row_max_mean 1505.1354 (1509.7746) nleep/row_max_std 80.3817 (67.0768) nleep/row_min_mean 1474.2715 (1479.6123) lr 1.7705e-03 eta 0:12:17
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,299
* accuracy: 82.3%
* error: 17.7%
* macro_f1: 85.8%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.3%, epoch: 7 *******
******* Domain c best val test acc: 100.0%, epoch: 7 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [14/50] batch [20/203] time 0.093 (0.105) data 0.000 (0.014) loss 1.4222 (1.3403) teacher_loss 0.2361 (0.1420) loss_zs_kd 0.0800 (0.0707) loss_oracle 0.5414 (0.5722) kd_loss 0.8754 (0.8768) acc 90.6250 (95.9375) gate/entropy 1.0348 (1.0347) gate/usage_max 0.4697 (0.4705) gate/usage_min 0.1859 (0.1860) gate/usage_std 0.1161 (0.1163) teacher/entropy 0.0492 (0.0464) teacher/usage_max 0.4958 (0.5469) teacher/usage_min 0.0160 (0.0230) teacher/usage_std 0.2244 (0.2292) nleep/row_max_mean 1494.9451 (1509.4957) nleep/row_max_std 77.3729 (68.2677) nleep/row_min_mean 1464.7762 (1478.2910) lr 1.7290e-03 eta 0:13:09
epoch [14/50] batch [40/203] time 0.113 (0.098) data 0.000 (0.007) loss 1.2753 (1.3213) teacher_loss 0.0513 (0.1354) loss_zs_kd 0.0692 (0.0696) loss_oracle 0.6012 (0.5670) kd_loss 0.8888 (0.8676) acc 96.8750 (96.1719) gate/entropy 1.0346 (1.0346) gate/usage_max 0.4686 (0.4698) gate/usage_min 0.1850 (0.1857) gate/usage_std 0.1162 (0.1163) teacher/entropy 0.0876 (0.0592) teacher/usage_max 0.4788 (0.5522) teacher/usage_min 0.0988 (0.0319) teacher/usage_std 0.1674 (0.2251) nleep/row_max_mean 1513.6450 (1507.5538) nleep/row_max_std 64.5364 (69.6626) nleep/row_min_mean 1482.7300 (1477.2862) lr 1.7290e-03 eta 0:12:13
epoch [14/50] batch [60/203] time 0.092 (0.097) data 0.001 (0.005) loss 1.2027 (1.3199) teacher_loss 0.0639 (0.1385) loss_zs_kd 0.0549 (0.0680) loss_oracle 0.5884 (0.5666) kd_loss 0.8172 (0.8640) acc 100.0000 (96.3021) gate/entropy 1.0344 (1.0346) gate/usage_max 0.4678 (0.4693) gate/usage_min 0.1844 (0.1853) gate/usage_std 0.1162 (0.1162) teacher/entropy 0.0658 (0.0580) teacher/usage_max 0.6567 (0.5480) teacher/usage_min 0.0344 (0.0286) teacher/usage_std 0.2547 (0.2261) nleep/row_max_mean 1527.7993 (1509.2711) nleep/row_max_std 44.4193 (68.7304) nleep/row_min_mean 1495.2058 (1478.9630) lr 1.7290e-03 eta 0:12:03
epoch [14/50] batch [80/203] time 0.083 (0.097) data 0.000 (0.004) loss 1.3833 (1.3210) teacher_loss 0.1340 (0.1375) loss_zs_kd 0.0771 (0.0681) loss_oracle 0.5995 (0.5647) kd_loss 0.9110 (0.8671) acc 96.8750 (96.4453) gate/entropy 1.0344 (1.0346) gate/usage_max 0.4668 (0.4687) gate/usage_min 0.1838 (0.1850) gate/usage_std 0.1161 (0.1162) teacher/entropy 0.0909 (0.0580) teacher/usage_max 0.4745 (0.5501) teacher/usage_min 0.1112 (0.0313) teacher/usage_std 0.1590 (0.2248) nleep/row_max_mean 1518.2655 (1508.7222) nleep/row_max_std 57.7826 (69.0519) nleep/row_min_mean 1485.8152 (1478.6758) lr 1.7290e-03 eta 0:12:00
epoch [14/50] batch [100/203] time 0.101 (0.097) data 0.000 (0.003) loss 1.3610 (1.3229) teacher_loss 0.1328 (0.1378) loss_zs_kd 0.0709 (0.0689) loss_oracle 0.5944 (0.5612) kd_loss 0.8956 (0.8701) acc 96.8750 (96.4375) gate/entropy 1.0343 (1.0345) gate/usage_max 0.4653 (0.4682) gate/usage_min 0.1831 (0.1847) gate/usage_std 0.1159 (0.1161) teacher/entropy 0.0268 (0.0568) teacher/usage_max 0.5325 (0.5454) teacher/usage_min 0.0092 (0.0315) teacher/usage_std 0.2312 (0.2234) nleep/row_max_mean 1528.5977 (1509.6795) nleep/row_max_std 27.2603 (67.4423) nleep/row_min_mean 1495.2180 (1479.4601) lr 1.7290e-03 eta 0:11:58
epoch [14/50] batch [120/203] time 0.100 (0.096) data 0.000 (0.003) loss 1.3232 (1.3208) teacher_loss 0.1462 (0.1383) loss_zs_kd 0.0542 (0.0693) loss_oracle 0.5613 (0.5572) kd_loss 0.8693 (0.8692) acc 96.8750 (96.3021) gate/entropy 1.0342 (1.0345) gate/usage_max 0.4643 (0.4676) gate/usage_min 0.1825 (0.1844) gate/usage_std 0.1159 (0.1161) teacher/entropy 0.0537 (0.0591) teacher/usage_max 0.5381 (0.5417) teacher/usage_min 0.0097 (0.0337) teacher/usage_std 0.2315 (0.2209) nleep/row_max_mean 1519.0546 (1510.2225) nleep/row_max_std 71.6571 (66.6511) nleep/row_min_mean 1484.6224 (1480.1493) lr 1.7290e-03 eta 0:11:52
epoch [14/50] batch [140/203] time 0.072 (0.097) data 0.000 (0.002) loss 1.1969 (1.3230) teacher_loss 0.0455 (0.1428) loss_zs_kd 0.0506 (0.0698) loss_oracle 0.5006 (0.5521) kd_loss 0.8757 (0.8693) acc 100.0000 (96.1607) gate/entropy 1.0342 (1.0345) gate/usage_max 0.4637 (0.4671) gate/usage_min 0.1821 (0.1841) gate/usage_std 0.1159 (0.1161) teacher/entropy 0.0647 (0.0591) teacher/usage_max 0.5221 (0.5424) teacher/usage_min 0.0655 (0.0359) teacher/usage_std 0.1946 (0.2197) nleep/row_max_mean 1491.0209 (1509.4842) nleep/row_max_std 87.7928 (67.6067) nleep/row_min_mean 1464.7621 (1479.6773) lr 1.7290e-03 eta 0:11:56
epoch [14/50] batch [160/203] time 0.103 (0.097) data 0.000 (0.002) loss 1.2097 (1.3170) teacher_loss 0.0379 (0.1367) loss_zs_kd 0.0757 (0.0701) loss_oracle 0.5999 (0.5527) kd_loss 0.8340 (0.8689) acc 100.0000 (96.2305) gate/entropy 1.0341 (1.0344) gate/usage_max 0.4630 (0.4666) gate/usage_min 0.1817 (0.1838) gate/usage_std 0.1159 (0.1160) teacher/entropy 0.0332 (0.0590) teacher/usage_max 0.6945 (0.5449) teacher/usage_min 0.0243 (0.0360) teacher/usage_std 0.2761 (0.2201) nleep/row_max_mean 1506.5654 (1509.7075) nleep/row_max_std 60.7220 (66.7360) nleep/row_min_mean 1478.5415 (1479.9137) lr 1.7290e-03 eta 0:11:53
epoch [14/50] batch [180/203] time 0.093 (0.097) data 0.000 (0.002) loss 1.5383 (1.3201) teacher_loss 0.4227 (0.1377) loss_zs_kd 0.0579 (0.0708) loss_oracle 0.5712 (0.5555) kd_loss 0.8010 (0.8693) acc 87.5000 (96.2326) gate/entropy 1.0341 (1.0344) gate/usage_max 0.4624 (0.4662) gate/usage_min 0.1815 (0.1836) gate/usage_std 0.1158 (0.1160) teacher/entropy 0.1140 (0.0586) teacher/usage_max 0.5425 (0.5443) teacher/usage_min 0.0364 (0.0367) teacher/usage_std 0.2157 (0.2196) nleep/row_max_mean 1492.6508 (1509.8795) nleep/row_max_std 85.5847 (66.5425) nleep/row_min_mean 1467.0206 (1480.1589) lr 1.7290e-03 eta 0:11:49
epoch [14/50] batch [200/203] time 0.084 (0.096) data 0.000 (0.002) loss 1.3356 (1.3194) teacher_loss 0.0987 (0.1373) loss_zs_kd 0.0800 (0.0709) loss_oracle 0.6069 (0.5534) kd_loss 0.8935 (0.8700) acc 96.8750 (96.2656) gate/entropy 1.0340 (1.0343) gate/usage_max 0.4611 (0.4657) gate/usage_min 0.1808 (0.1833) gate/usage_std 0.1157 (0.1160) teacher/entropy 0.0053 (0.0593) teacher/usage_max 0.5928 (0.5443) teacher/usage_min 0.0321 (0.0375) teacher/usage_std 0.2308 (0.2191) nleep/row_max_mean 1504.9382 (1509.4892) nleep/row_max_std 74.1897 (66.9053) nleep/row_min_mean 1475.3149 (1479.8525) lr 1.7290e-03 eta 0:11:43
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,285
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 85.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.3%, epoch: 7 *******
******* Domain c best val test acc: 100.0%, epoch: 7 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [15/50] batch [20/203] time 0.091 (0.123) data 0.000 (0.014) loss 1.2222 (1.3208) teacher_loss 0.0399 (0.1320) loss_zs_kd 0.0840 (0.0761) loss_oracle 0.5334 (0.5636) kd_loss 0.8735 (0.8690) acc 100.0000 (96.7188) gate/entropy 1.0338 (1.0338) gate/usage_max 0.4600 (0.4605) gate/usage_min 0.1802 (0.1803) gate/usage_std 0.1158 (0.1158) teacher/entropy 0.0767 (0.0489) teacher/usage_max 0.6326 (0.5611) teacher/usage_min 0.0200 (0.0397) teacher/usage_std 0.2503 (0.2228) nleep/row_max_mean 1503.3235 (1507.6354) nleep/row_max_std 74.7275 (68.7338) nleep/row_min_mean 1471.9504 (1479.3421) lr 1.6845e-03 eta 0:14:55
epoch [15/50] batch [40/203] time 0.086 (0.110) data 0.000 (0.007) loss 1.2945 (1.3127) teacher_loss 0.0968 (0.1219) loss_zs_kd 0.0739 (0.0780) loss_oracle 0.5217 (0.5724) kd_loss 0.8999 (0.8656) acc 100.0000 (96.6406) gate/entropy 1.0336 (1.0337) gate/usage_max 0.4596 (0.4602) gate/usage_min 0.1797 (0.1801) gate/usage_std 0.1159 (0.1158) teacher/entropy 0.0295 (0.0496) teacher/usage_max 0.6183 (0.5658) teacher/usage_min 0.0024 (0.0356) teacher/usage_std 0.2535 (0.2253) nleep/row_max_mean 1501.4905 (1506.4116) nleep/row_max_std 84.5650 (69.9685) nleep/row_min_mean 1470.0170 (1477.9158) lr 1.6845e-03 eta 0:13:21
epoch [15/50] batch [60/203] time 0.101 (0.105) data 0.001 (0.005) loss 1.3445 (1.3132) teacher_loss 0.1154 (0.1267) loss_zs_kd 0.0906 (0.0743) loss_oracle 0.6250 (0.5626) kd_loss 0.8713 (0.8681) acc 93.7500 (96.3542) gate/entropy 1.0335 (1.0336) gate/usage_max 0.4591 (0.4599) gate/usage_min 0.1795 (0.1799) gate/usage_std 0.1159 (0.1159) teacher/entropy 0.0199 (0.0453) teacher/usage_max 0.6225 (0.5691) teacher/usage_min 0.0318 (0.0325) teacher/usage_std 0.2413 (0.2279) nleep/row_max_mean 1507.3604 (1509.0677) nleep/row_max_std 67.8549 (66.7809) nleep/row_min_mean 1475.4896 (1479.8927) lr 1.6845e-03 eta 0:12:42
epoch [15/50] batch [80/203] time 0.098 (0.103) data 0.000 (0.004) loss 1.3137 (1.3102) teacher_loss 0.1013 (0.1237) loss_zs_kd 0.0709 (0.0740) loss_oracle 0.5173 (0.5580) kd_loss 0.9182 (0.8705) acc 96.8750 (96.4453) gate/entropy 1.0334 (1.0336) gate/usage_max 0.4582 (0.4596) gate/usage_min 0.1791 (0.1798) gate/usage_std 0.1159 (0.1159) teacher/entropy 0.0736 (0.0487) teacher/usage_max 0.6319 (0.5652) teacher/usage_min 0.0688 (0.0352) teacher/usage_std 0.2312 (0.2255) nleep/row_max_mean 1508.8386 (1509.7802) nleep/row_max_std 63.9360 (65.5028) nleep/row_min_mean 1479.8035 (1480.6592) lr 1.6845e-03 eta 0:12:21
epoch [15/50] batch [100/203] time 0.087 (0.101) data 0.000 (0.003) loss 1.3330 (1.3073) teacher_loss 0.0603 (0.1210) loss_zs_kd 0.0794 (0.0734) loss_oracle 0.6240 (0.5577) kd_loss 0.9210 (0.8708) acc 100.0000 (96.5000) gate/entropy 1.0333 (1.0335) gate/usage_max 0.4574 (0.4593) gate/usage_min 0.1786 (0.1796) gate/usage_std 0.1159 (0.1159) teacher/entropy 0.0565 (0.0510) teacher/usage_max 0.5752 (0.5622) teacher/usage_min 0.0684 (0.0372) teacher/usage_std 0.2075 (0.2235) nleep/row_max_mean 1512.3135 (1509.3684) nleep/row_max_std 58.2243 (66.1543) nleep/row_min_mean 1482.3749 (1480.4700) lr 1.6845e-03 eta 0:12:06
epoch [15/50] batch [120/203] time 0.101 (0.100) data 0.000 (0.003) loss 1.2691 (1.3036) teacher_loss 0.0825 (0.1181) loss_zs_kd 0.0778 (0.0728) loss_oracle 0.5032 (0.5542) kd_loss 0.8961 (0.8720) acc 100.0000 (96.5885) gate/entropy 1.0331 (1.0335) gate/usage_max 0.4568 (0.4589) gate/usage_min 0.1781 (0.1793) gate/usage_std 0.1160 (0.1159) teacher/entropy 0.0479 (0.0529) teacher/usage_max 0.4859 (0.5554) teacher/usage_min 0.0636 (0.0400) teacher/usage_std 0.1913 (0.2202) nleep/row_max_mean 1505.5081 (1510.1976) nleep/row_max_std 71.0793 (65.8134) nleep/row_min_mean 1479.1902 (1481.3136) lr 1.6845e-03 eta 0:12:01
epoch [15/50] batch [140/203] time 0.087 (0.100) data 0.000 (0.002) loss 1.1882 (1.3035) teacher_loss 0.0329 (0.1197) loss_zs_kd 0.0679 (0.0721) loss_oracle 0.5654 (0.5561) kd_loss 0.8386 (0.8697) acc 100.0000 (96.5625) gate/entropy 1.0329 (1.0334) gate/usage_max 0.4560 (0.4586) gate/usage_min 0.1777 (0.1791) gate/usage_std 0.1160 (0.1159) teacher/entropy 0.0817 (0.0542) teacher/usage_max 0.5310 (0.5550) teacher/usage_min 0.0197 (0.0388) teacher/usage_std 0.2243 (0.2207) nleep/row_max_mean 1494.3158 (1509.9439) nleep/row_max_std 76.1624 (65.8758) nleep/row_min_mean 1468.8663 (1481.1467) lr 1.6845e-03 eta 0:11:54
epoch [15/50] batch [160/203] time 0.096 (0.099) data 0.000 (0.002) loss 1.1845 (1.3066) teacher_loss 0.0767 (0.1233) loss_zs_kd 0.0650 (0.0730) loss_oracle 0.5231 (0.5586) kd_loss 0.8138 (0.8675) acc 96.8750 (96.4453) gate/entropy 1.0327 (1.0333) gate/usage_max 0.4556 (0.4582) gate/usage_min 0.1773 (0.1789) gate/usage_std 0.1161 (0.1159) teacher/entropy 0.1521 (0.0566) teacher/usage_max 0.4800 (0.5519) teacher/usage_min 0.0932 (0.0401) teacher/usage_std 0.1712 (0.2192) nleep/row_max_mean 1506.0796 (1509.6241) nleep/row_max_std 80.4482 (66.2470) nleep/row_min_mean 1480.0840 (1480.9291) lr 1.6845e-03 eta 0:11:48
epoch [15/50] batch [180/203] time 0.089 (0.098) data 0.000 (0.002) loss 1.2487 (1.3111) teacher_loss 0.0495 (0.1297) loss_zs_kd 0.0726 (0.0733) loss_oracle 0.5637 (0.5555) kd_loss 0.8811 (0.8671) acc 100.0000 (96.3194) gate/entropy 1.0329 (1.0333) gate/usage_max 0.4552 (0.4579) gate/usage_min 0.1774 (0.1787) gate/usage_std 0.1160 (0.1159) teacher/entropy 0.1023 (0.0572) teacher/usage_max 0.5514 (0.5509) teacher/usage_min 0.0831 (0.0405) teacher/usage_std 0.1925 (0.2187) nleep/row_max_mean 1507.9302 (1509.5671) nleep/row_max_std 71.4385 (66.6267) nleep/row_min_mean 1481.8386 (1481.0096) lr 1.6845e-03 eta 0:11:40
epoch [15/50] batch [200/203] time 0.081 (0.097) data 0.000 (0.002) loss 1.3953 (1.3154) teacher_loss 0.2586 (0.1330) loss_zs_kd 0.0780 (0.0731) loss_oracle 0.6198 (0.5572) kd_loss 0.7877 (0.8672) acc 90.6250 (96.2812) gate/entropy 1.0325 (1.0332) gate/usage_max 0.4545 (0.4576) gate/usage_min 0.1766 (0.1786) gate/usage_std 0.1162 (0.1160) teacher/entropy 0.1022 (0.0573) teacher/usage_max 0.5560 (0.5513) teacher/usage_min 0.0122 (0.0409) teacher/usage_std 0.2327 (0.2189) nleep/row_max_mean 1487.5812 (1509.4611) nleep/row_max_std 96.1010 (66.5915) nleep/row_min_mean 1459.8821 (1480.9637) lr 1.6845e-03 eta 0:11:30
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,315
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 86.2%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      83.3%, epoch: 7 *******
******* Domain c best val test acc: 100.0%, epoch: 7 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [16/50] batch [20/203] time 0.098 (0.113) data 0.000 (0.017) loss 1.1921 (1.2880) teacher_loss 0.0638 (0.1093) loss_zs_kd 0.0650 (0.0756) loss_oracle 0.4764 (0.5482) kd_loss 0.8576 (0.8669) acc 100.0000 (97.5000) gate/entropy 1.0326 (1.0325) gate/usage_max 0.4539 (0.4541) gate/usage_min 0.1767 (0.1765) gate/usage_std 0.1160 (0.1162) teacher/entropy 0.0526 (0.0604) teacher/usage_max 0.5118 (0.5342) teacher/usage_min 0.0159 (0.0455) teacher/usage_std 0.2251 (0.2117) nleep/row_max_mean 1503.2820 (1508.9656) nleep/row_max_std 66.0504 (67.5553) nleep/row_min_mean 1473.9736 (1481.2842) lr 1.6374e-03 eta 0:13:17
epoch [16/50] batch [40/203] time 0.093 (0.104) data 0.000 (0.008) loss 1.3417 (1.3104) teacher_loss 0.1377 (0.1428) loss_zs_kd 0.0691 (0.0764) loss_oracle 0.5654 (0.5439) kd_loss 0.8867 (0.8575) acc 96.8750 (95.7031) gate/entropy 1.0324 (1.0325) gate/usage_max 0.4534 (0.4539) gate/usage_min 0.1762 (0.1764) gate/usage_std 0.1162 (0.1162) teacher/entropy 0.0240 (0.0723) teacher/usage_max 0.5562 (0.5395) teacher/usage_min 0.0078 (0.0496) teacher/usage_std 0.2354 (0.2105) nleep/row_max_mean 1503.5549 (1506.6780) nleep/row_max_std 64.9408 (69.0507) nleep/row_min_mean 1474.5039 (1479.9492) lr 1.6374e-03 eta 0:12:16
epoch [16/50] batch [60/203] time 0.094 (0.101) data 0.001 (0.006) loss 1.2728 (1.3130) teacher_loss 0.1613 (0.1389) loss_zs_kd 0.0779 (0.0747) loss_oracle 0.5721 (0.5449) kd_loss 0.7866 (0.8643) acc 96.8750 (96.1458) gate/entropy 1.0320 (1.0324) gate/usage_max 0.4529 (0.4536) gate/usage_min 0.1756 (0.1762) gate/usage_std 0.1164 (0.1162) teacher/entropy 0.1142 (0.0686) teacher/usage_max 0.6736 (0.5349) teacher/usage_min 0.0595 (0.0529) teacher/usage_std 0.2551 (0.2080) nleep/row_max_mean 1510.0139 (1509.2845) nleep/row_max_std 70.5995 (66.0031) nleep/row_min_mean 1485.0424 (1482.1592) lr 1.6374e-03 eta 0:11:50
epoch [16/50] batch [80/203] time 0.078 (0.099) data 0.000 (0.004) loss 1.2849 (1.3127) teacher_loss 0.0305 (0.1365) loss_zs_kd 0.0616 (0.0745) loss_oracle 0.5604 (0.5450) kd_loss 0.9434 (0.8665) acc 100.0000 (96.2891) gate/entropy 1.0321 (1.0323) gate/usage_max 0.4527 (0.4534) gate/usage_min 0.1756 (0.1761) gate/usage_std 0.1163 (0.1162) teacher/entropy 0.0627 (0.0719) teacher/usage_max 0.5422 (0.5313) teacher/usage_min 0.1128 (0.0593) teacher/usage_std 0.1755 (0.2037) nleep/row_max_mean 1521.6599 (1509.2815) nleep/row_max_std 55.4149 (66.1084) nleep/row_min_mean 1495.0234 (1482.1663) lr 1.6374e-03 eta 0:11:38
epoch [16/50] batch [100/203] time 0.146 (0.100) data 0.000 (0.004) loss 1.3999 (1.3218) teacher_loss 0.2327 (0.1462) loss_zs_kd 0.0559 (0.0750) loss_oracle 0.5488 (0.5438) kd_loss 0.8648 (0.8662) acc 96.8750 (95.9062) gate/entropy 1.0322 (1.0323) gate/usage_max 0.4528 (0.4533) gate/usage_min 0.1758 (0.1760) gate/usage_std 0.1162 (0.1162) teacher/entropy 0.0984 (0.0750) teacher/usage_max 0.5083 (0.5298) teacher/usage_min 0.0745 (0.0640) teacher/usage_std 0.1867 (0.2008) nleep/row_max_mean 1504.1074 (1509.0443) nleep/row_max_std 67.0594 (66.1535) nleep/row_min_mean 1476.9463 (1482.0460) lr 1.6374e-03 eta 0:11:43
epoch [16/50] batch [120/203] time 0.100 (0.099) data 0.000 (0.003) loss 1.3730 (1.3222) teacher_loss 0.2735 (0.1474) loss_zs_kd 0.0573 (0.0730) loss_oracle 0.5453 (0.5442) kd_loss 0.7982 (0.8662) acc 90.6250 (95.8854) gate/entropy 1.0322 (1.0323) gate/usage_max 0.4530 (0.4532) gate/usage_min 0.1758 (0.1760) gate/usage_std 0.1163 (0.1162) teacher/entropy 0.1163 (0.0789) teacher/usage_max 0.5338 (0.5281) teacher/usage_min 0.0399 (0.0685) teacher/usage_std 0.2121 (0.1977) nleep/row_max_mean 1478.4050 (1508.2273) nleep/row_max_std 83.3538 (66.6272) nleep/row_min_mean 1455.0847 (1481.4447) lr 1.6374e-03 eta 0:11:34
epoch [16/50] batch [140/203] time 0.094 (0.099) data 0.000 (0.003) loss 1.2829 (1.3233) teacher_loss 0.0740 (0.1482) loss_zs_kd 0.0789 (0.0729) loss_oracle 0.5111 (0.5429) kd_loss 0.9139 (0.8672) acc 96.8750 (95.8705) gate/entropy 1.0321 (1.0323) gate/usage_max 0.4530 (0.4532) gate/usage_min 0.1757 (0.1759) gate/usage_std 0.1164 (0.1163) teacher/entropy 0.0688 (0.0793) teacher/usage_max 0.4784 (0.5299) teacher/usage_min 0.1021 (0.0693) teacher/usage_std 0.1653 (0.1977) nleep/row_max_mean 1516.1576 (1508.3109) nleep/row_max_std 64.5303 (67.0679) nleep/row_min_mean 1491.0662 (1481.4815) lr 1.6374e-03 eta 0:11:29
epoch [16/50] batch [160/203] time 0.102 (0.098) data 0.000 (0.002) loss 1.2966 (1.3184) teacher_loss 0.1717 (0.1430) loss_zs_kd 0.0630 (0.0727) loss_oracle 0.4356 (0.5407) kd_loss 0.8755 (0.8687) acc 96.8750 (95.9766) gate/entropy 1.0319 (1.0322) gate/usage_max 0.4527 (0.4531) gate/usage_min 0.1754 (0.1759) gate/usage_std 0.1164 (0.1163) teacher/entropy 0.0624 (0.0804) teacher/usage_max 0.4871 (0.5276) teacher/usage_min 0.0595 (0.0715) teacher/usage_std 0.1941 (0.1959) nleep/row_max_mean 1525.7814 (1508.2165) nleep/row_max_std 52.4967 (67.1600) nleep/row_min_mean 1500.5635 (1481.4436) lr 1.6374e-03 eta 0:11:23
epoch [16/50] batch [180/203] time 0.095 (0.098) data 0.000 (0.002) loss 1.2327 (1.3205) teacher_loss 0.0943 (0.1446) loss_zs_kd 0.0695 (0.0736) loss_oracle 0.5107 (0.5410) kd_loss 0.8483 (0.8686) acc 93.7500 (95.9201) gate/entropy 1.0320 (1.0322) gate/usage_max 0.4525 (0.4531) gate/usage_min 0.1754 (0.1758) gate/usage_std 0.1164 (0.1163) teacher/entropy 0.0515 (0.0806) teacher/usage_max 0.6189 (0.5263) teacher/usage_min 0.0425 (0.0719) teacher/usage_std 0.2353 (0.1952) nleep/row_max_mean 1497.0605 (1507.9304) nleep/row_max_std 81.8177 (67.7379) nleep/row_min_mean 1473.1687 (1481.1586) lr 1.6374e-03 eta 0:11:20
epoch [16/50] batch [200/203] time 0.087 (0.097) data 0.000 (0.002) loss 1.3315 (1.3194) teacher_loss 0.1611 (0.1445) loss_zs_kd 0.0693 (0.0734) loss_oracle 0.5086 (0.5390) kd_loss 0.8814 (0.8687) acc 93.7500 (95.8906) gate/entropy 1.0319 (1.0322) gate/usage_max 0.4528 (0.4530) gate/usage_min 0.1753 (0.1758) gate/usage_std 0.1165 (0.1163) teacher/entropy 0.1329 (0.0810) teacher/usage_max 0.4493 (0.5258) teacher/usage_min 0.1517 (0.0730) teacher/usage_std 0.1301 (0.1947) nleep/row_max_mean 1523.1819 (1508.0759) nleep/row_max_std 59.1416 (67.9067) nleep/row_min_mean 1496.6534 (1481.1901) lr 1.6374e-03 eta 0:11:13
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,324
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.3%, epoch: 7 *******
******* Domain c best val test acc: 100.0%, epoch: 7 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [17/50] batch [20/203] time 0.108 (0.114) data 0.000 (0.017) loss 1.2960 (1.3307) teacher_loss 0.1335 (0.1675) loss_zs_kd 0.0571 (0.0691) loss_oracle 0.5300 (0.5347) kd_loss 0.8689 (0.8613) acc 96.8750 (95.4688) gate/entropy 1.0319 (1.0320) gate/usage_max 0.4525 (0.4525) gate/usage_min 0.1753 (0.1754) gate/usage_std 0.1164 (0.1164) teacher/entropy 0.0449 (0.0891) teacher/usage_max 0.6203 (0.5400) teacher/usage_min 0.0621 (0.0726) teacher/usage_std 0.2282 (0.1993) nleep/row_max_mean 1511.3513 (1507.7207) nleep/row_max_std 56.7783 (68.4940) nleep/row_min_mean 1485.4932 (1480.3156) lr 1.5878e-03 eta 0:13:03
epoch [17/50] batch [40/203] time 0.093 (0.105) data 0.000 (0.009) loss 1.5138 (1.3368) teacher_loss 0.2083 (0.1634) loss_zs_kd 0.0777 (0.0718) loss_oracle 0.6623 (0.5532) kd_loss 0.9354 (0.8609) acc 90.6250 (95.5469) gate/entropy 1.0317 (1.0319) gate/usage_max 0.4520 (0.4524) gate/usage_min 0.1749 (0.1753) gate/usage_std 0.1165 (0.1164) teacher/entropy 0.0495 (0.0797) teacher/usage_max 0.5090 (0.5354) teacher/usage_min 0.0983 (0.0621) teacher/usage_std 0.1728 (0.2027) nleep/row_max_mean 1514.5056 (1507.5855) nleep/row_max_std 59.9275 (68.9386) nleep/row_min_mean 1485.3608 (1479.4918) lr 1.5878e-03 eta 0:12:02
epoch [17/50] batch [60/203] time 0.125 (0.102) data 0.001 (0.006) loss 1.2889 (1.3283) teacher_loss 0.0687 (0.1480) loss_zs_kd 0.0737 (0.0730) loss_oracle 0.5428 (0.5517) kd_loss 0.9120 (0.8679) acc 96.8750 (95.7812) gate/entropy 1.0319 (1.0319) gate/usage_max 0.4515 (0.4521) gate/usage_min 0.1750 (0.1751) gate/usage_std 0.1164 (0.1165) teacher/entropy 0.1110 (0.0762) teacher/usage_max 0.6046 (0.5346) teacher/usage_min 0.1200 (0.0637) teacher/usage_std 0.2020 (0.2017) nleep/row_max_mean 1501.9868 (1510.1043) nleep/row_max_std 56.3657 (65.9385) nleep/row_min_mean 1475.9731 (1481.7417) lr 1.5878e-03 eta 0:11:36
epoch [17/50] batch [80/203] time 0.101 (0.101) data 0.000 (0.005) loss 1.3747 (1.3261) teacher_loss 0.2071 (0.1489) loss_zs_kd 0.0617 (0.0718) loss_oracle 0.5296 (0.5498) kd_loss 0.8720 (0.8665) acc 93.7500 (95.8594) gate/entropy 1.0316 (1.0318) gate/usage_max 0.4512 (0.4519) gate/usage_min 0.1746 (0.1750) gate/usage_std 0.1166 (0.1165) teacher/entropy 0.0940 (0.0764) teacher/usage_max 0.4660 (0.5363) teacher/usage_min 0.0917 (0.0648) teacher/usage_std 0.1711 (0.2016) nleep/row_max_mean 1509.9680 (1509.5635) nleep/row_max_std 70.0706 (66.9667) nleep/row_min_mean 1480.2397 (1481.1819) lr 1.5878e-03 eta 0:11:32
epoch [17/50] batch [100/203] time 0.101 (0.100) data 0.000 (0.004) loss 1.1855 (1.3270) teacher_loss 0.0612 (0.1485) loss_zs_kd 0.0767 (0.0712) loss_oracle 0.5276 (0.5514) kd_loss 0.8222 (0.8672) acc 100.0000 (96.1250) gate/entropy 1.0316 (1.0318) gate/usage_max 0.4511 (0.4517) gate/usage_min 0.1745 (0.1749) gate/usage_std 0.1166 (0.1165) teacher/entropy 0.0796 (0.0809) teacher/usage_max 0.6320 (0.5312) teacher/usage_min 0.0490 (0.0702) teacher/usage_std 0.2382 (0.1975) nleep/row_max_mean 1510.0411 (1509.3984) nleep/row_max_std 66.4339 (66.5817) nleep/row_min_mean 1479.9547 (1481.2303) lr 1.5878e-03 eta 0:11:21
epoch [17/50] batch [120/203] time 0.102 (0.100) data 0.000 (0.003) loss 1.3219 (1.3302) teacher_loss 0.0473 (0.1503) loss_zs_kd 0.0728 (0.0704) loss_oracle 0.5276 (0.5483) kd_loss 0.9744 (0.8706) acc 100.0000 (96.0938) gate/entropy 1.0315 (1.0317) gate/usage_max 0.4510 (0.4516) gate/usage_min 0.1744 (0.1748) gate/usage_std 0.1166 (0.1165) teacher/entropy 0.0298 (0.0809) teacher/usage_max 0.5047 (0.5297) teacher/usage_min 0.1209 (0.0751) teacher/usage_std 0.1593 (0.1949) nleep/row_max_mean 1510.5623 (1509.7898) nleep/row_max_std 71.0780 (65.9283) nleep/row_min_mean 1484.4174 (1481.7643) lr 1.5878e-03 eta 0:11:16
epoch [17/50] batch [140/203] time 0.114 (0.100) data 0.000 (0.003) loss 1.2793 (1.3254) teacher_loss 0.1242 (0.1444) loss_zs_kd 0.1001 (0.0709) loss_oracle 0.5854 (0.5489) kd_loss 0.8123 (0.8711) acc 93.7500 (96.2723) gate/entropy 1.0314 (1.0317) gate/usage_max 0.4510 (0.4515) gate/usage_min 0.1743 (0.1748) gate/usage_std 0.1167 (0.1165) teacher/entropy 0.1007 (0.0824) teacher/usage_max 0.5992 (0.5296) teacher/usage_min 0.0560 (0.0783) teacher/usage_std 0.2219 (0.1930) nleep/row_max_mean 1505.9441 (1508.9343) nleep/row_max_std 68.1769 (65.8650) nleep/row_min_mean 1477.5984 (1481.0728) lr 1.5878e-03 eta 0:11:14
epoch [17/50] batch [160/203] time 0.092 (0.100) data 0.000 (0.002) loss 1.2376 (1.3267) teacher_loss 0.0256 (0.1410) loss_zs_kd 0.0877 (0.0716) loss_oracle 0.6040 (0.5488) kd_loss 0.8661 (0.8756) acc 100.0000 (96.3477) gate/entropy 1.0315 (1.0317) gate/usage_max 0.4512 (0.4515) gate/usage_min 0.1744 (0.1747) gate/usage_std 0.1166 (0.1165) teacher/entropy 0.0465 (0.0817) teacher/usage_max 0.5924 (0.5288) teacher/usage_min 0.0532 (0.0825) teacher/usage_std 0.2206 (0.1909) nleep/row_max_mean 1503.1346 (1508.6949) nleep/row_max_std 76.2674 (65.3663) nleep/row_min_mean 1474.7358 (1480.9978) lr 1.5878e-03 eta 0:11:11
epoch [17/50] batch [180/203] time 0.152 (0.101) data 0.000 (0.002) loss 1.2713 (1.3256) teacher_loss 0.0457 (0.1402) loss_zs_kd 0.1048 (0.0729) loss_oracle 0.5924 (0.5481) kd_loss 0.8770 (0.8748) acc 100.0000 (96.3715) gate/entropy 1.0314 (1.0317) gate/usage_max 0.4512 (0.4515) gate/usage_min 0.1743 (0.1747) gate/usage_std 0.1167 (0.1166) teacher/entropy 0.0730 (0.0839) teacher/usage_max 0.4891 (0.5267) teacher/usage_min 0.0775 (0.0845) teacher/usage_std 0.1823 (0.1892) nleep/row_max_mean 1522.5051 (1508.2266) nleep/row_max_std 48.4365 (65.6622) nleep/row_min_mean 1491.8103 (1480.6519) lr 1.5878e-03 eta 0:11:18
epoch [17/50] batch [200/203] time 0.088 (0.100) data 0.000 (0.002) loss 1.3081 (1.3338) teacher_loss 0.0870 (0.1435) loss_zs_kd 0.0696 (0.0734) loss_oracle 0.6004 (0.5542) kd_loss 0.8861 (0.8765) acc 93.7500 (96.2969) gate/entropy 1.0317 (1.0317) gate/usage_max 0.4515 (0.4515) gate/usage_min 0.1747 (0.1747) gate/usage_std 0.1166 (0.1166) teacher/entropy 0.0912 (0.0855) teacher/usage_max 0.4698 (0.5240) teacher/usage_min 0.0995 (0.0885) teacher/usage_std 0.1661 (0.1864) nleep/row_max_mean 1511.4449 (1508.0040) nleep/row_max_std 56.2562 (65.5044) nleep/row_min_mean 1481.2681 (1480.5571) lr 1.5878e-03 eta 0:11:08
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,331
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 86.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      83.4%, epoch: 17 *******
******* Domain c best val test acc: 99.9%, epoch: 17 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [18/50] batch [20/203] time 0.090 (0.111) data 0.000 (0.015) loss 1.2493 (1.3361) teacher_loss 0.0610 (0.1359) loss_zs_kd 0.0640 (0.0702) loss_oracle 0.6088 (0.5579) kd_loss 0.8519 (0.8861) acc 100.0000 (97.0312) gate/entropy 1.0316 (1.0316) gate/usage_max 0.4521 (0.4518) gate/usage_min 0.1747 (0.1747) gate/usage_std 0.1167 (0.1166) teacher/entropy 0.1671 (0.0955) teacher/usage_max 0.5831 (0.5092) teacher/usage_min 0.1920 (0.1180) teacher/usage_std 0.1771 (0.1666) nleep/row_max_mean 1504.5249 (1504.6706) nleep/row_max_std 75.9280 (67.2523) nleep/row_min_mean 1479.4255 (1478.4512) lr 1.5358e-03 eta 0:12:19
epoch [18/50] batch [40/203] time 0.086 (0.101) data 0.000 (0.008) loss 1.2709 (1.3456) teacher_loss 0.0174 (0.1367) loss_zs_kd 0.0621 (0.0688) loss_oracle 0.6703 (0.5778) kd_loss 0.8874 (0.8856) acc 100.0000 (96.6406) gate/entropy 1.0316 (1.0316) gate/usage_max 0.4526 (0.4521) gate/usage_min 0.1749 (0.1748) gate/usage_std 0.1167 (0.1167) teacher/entropy 0.0844 (0.0915) teacher/usage_max 0.4712 (0.5268) teacher/usage_min 0.1010 (0.1138) teacher/usage_std 0.1653 (0.1747) nleep/row_max_mean 1525.5017 (1507.7733) nleep/row_max_std 43.3638 (65.4151) nleep/row_min_mean 1497.7334 (1481.7540) lr 1.5358e-03 eta 0:11:15
epoch [18/50] batch [60/203] time 0.091 (0.098) data 0.001 (0.005) loss 1.3596 (1.3630) teacher_loss 0.1963 (0.1349) loss_zs_kd 0.0719 (0.0721) loss_oracle 0.4544 (0.5917) kd_loss 0.9002 (0.8961) acc 93.7500 (96.3021) gate/entropy 1.0316 (1.0316) gate/usage_max 0.4533 (0.4524) gate/usage_min 0.1751 (0.1749) gate/usage_std 0.1167 (0.1167) teacher/entropy 0.0622 (0.0913) teacher/usage_max 0.5006 (0.5119) teacher/usage_min 0.0964 (0.1243) teacher/usage_std 0.1722 (0.1647) nleep/row_max_mean 1527.2280 (1508.6012) nleep/row_max_std 43.7060 (62.7737) nleep/row_min_mean 1500.3535 (1482.5538) lr 1.5358e-03 eta 0:10:51
epoch [18/50] batch [80/203] time 0.087 (0.097) data 0.000 (0.004) loss 1.4418 (1.3682) teacher_loss 0.2694 (0.1494) loss_zs_kd 0.0645 (0.0726) loss_oracle 0.5388 (0.5856) kd_loss 0.8707 (0.8898) acc 93.7500 (96.0156) gate/entropy 1.0318 (1.0317) gate/usage_max 0.4541 (0.4528) gate/usage_min 0.1755 (0.1751) gate/usage_std 0.1167 (0.1167) teacher/entropy 0.0874 (0.0989) teacher/usage_max 0.5158 (0.5150) teacher/usage_min 0.0942 (0.1270) teacher/usage_std 0.1767 (0.1647) nleep/row_max_mean 1509.1426 (1507.3762) nleep/row_max_std 60.1044 (63.1353) nleep/row_min_mean 1482.4297 (1481.3128) lr 1.5358e-03 eta 0:10:44
epoch [18/50] batch [100/203] time 0.088 (0.097) data 0.000 (0.003) loss 1.4259 (1.3756) teacher_loss 0.1368 (0.1540) loss_zs_kd 0.0928 (0.0760) loss_oracle 0.5167 (0.5819) kd_loss 0.9843 (0.8927) acc 96.8750 (95.8438) gate/entropy 1.0317 (1.0317) gate/usage_max 0.4542 (0.4530) gate/usage_min 0.1755 (0.1752) gate/usage_std 0.1168 (0.1167) teacher/entropy 0.0974 (0.0926) teacher/usage_max 0.5080 (0.5174) teacher/usage_min 0.1996 (0.1229) teacher/usage_std 0.1292 (0.1673) nleep/row_max_mean 1514.5808 (1508.2109) nleep/row_max_std 56.1158 (61.8741) nleep/row_min_mean 1491.8132 (1481.9758) lr 1.5358e-03 eta 0:10:37
epoch [18/50] batch [120/203] time 0.091 (0.096) data 0.000 (0.003) loss 1.2225 (1.3644) teacher_loss 0.0659 (0.1479) loss_zs_kd 0.0614 (0.0760) loss_oracle 0.4678 (0.5750) kd_loss 0.8920 (0.8910) acc 100.0000 (96.1719) gate/entropy 1.0318 (1.0317) gate/usage_max 0.4543 (0.4532) gate/usage_min 0.1756 (0.1752) gate/usage_std 0.1167 (0.1167) teacher/entropy 0.1136 (0.0927) teacher/usage_max 0.5273 (0.5154) teacher/usage_min 0.1154 (0.1202) teacher/usage_std 0.1690 (0.1679) nleep/row_max_mean 1507.2338 (1508.0625) nleep/row_max_std 62.9011 (62.0817) nleep/row_min_mean 1483.8392 (1481.8491) lr 1.5358e-03 eta 0:10:28
epoch [18/50] batch [140/203] time 0.089 (0.095) data 0.000 (0.002) loss 1.2065 (1.3585) teacher_loss 0.0397 (0.1445) loss_zs_kd 0.0735 (0.0763) loss_oracle 0.4860 (0.5703) kd_loss 0.8870 (0.8907) acc 100.0000 (96.3393) gate/entropy 1.0316 (1.0317) gate/usage_max 0.4540 (0.4534) gate/usage_min 0.1752 (0.1753) gate/usage_std 0.1168 (0.1167) teacher/entropy 0.0113 (0.0931) teacher/usage_max 0.5292 (0.5125) teacher/usage_min 0.0022 (0.1190) teacher/usage_std 0.2354 (0.1674) nleep/row_max_mean 1521.6155 (1507.9300) nleep/row_max_std 57.7743 (62.3820) nleep/row_min_mean 1492.8005 (1481.8171) lr 1.5358e-03 eta 0:10:23
epoch [18/50] batch [160/203] time 0.098 (0.096) data 0.000 (0.002) loss 1.3046 (1.3553) teacher_loss 0.0356 (0.1412) loss_zs_kd 0.0747 (0.0753) loss_oracle 0.5544 (0.5666) kd_loss 0.9545 (0.8932) acc 100.0000 (96.3281) gate/entropy 1.0317 (1.0317) gate/usage_max 0.4539 (0.4534) gate/usage_min 0.1754 (0.1753) gate/usage_std 0.1167 (0.1167) teacher/entropy 0.0837 (0.0941) teacher/usage_max 0.4382 (0.5095) teacher/usage_min 0.1808 (0.1225) teacher/usage_std 0.1103 (0.1645) nleep/row_max_mean 1518.9762 (1507.9631) nleep/row_max_std 58.1653 (62.0074) nleep/row_min_mean 1490.4871 (1481.9517) lr 1.5358e-03 eta 0:10:26
epoch [18/50] batch [180/203] time 0.095 (0.095) data 0.000 (0.002) loss 1.2822 (1.3566) teacher_loss 0.0827 (0.1426) loss_zs_kd 0.0605 (0.0745) loss_oracle 0.5130 (0.5649) kd_loss 0.9127 (0.8943) acc 96.8750 (96.2500) gate/entropy 1.0318 (1.0317) gate/usage_max 0.4540 (0.4535) gate/usage_min 0.1756 (0.1753) gate/usage_std 0.1167 (0.1167) teacher/entropy 0.0708 (0.0945) teacher/usage_max 0.5090 (0.5068) teacher/usage_min 0.1277 (0.1236) teacher/usage_std 0.1571 (0.1630) nleep/row_max_mean 1498.5942 (1507.5995) nleep/row_max_std 70.2170 (62.5699) nleep/row_min_mean 1474.0103 (1481.6115) lr 1.5358e-03 eta 0:10:20
epoch [18/50] batch [200/203] time 0.087 (0.094) data 0.000 (0.002) loss 1.3970 (1.3579) teacher_loss 0.1594 (0.1456) loss_zs_kd 0.0539 (0.0739) loss_oracle 0.5981 (0.5623) kd_loss 0.9116 (0.8943) acc 93.7500 (96.1250) gate/entropy 1.0315 (1.0317) gate/usage_max 0.4537 (0.4535) gate/usage_min 0.1750 (0.1753) gate/usage_std 0.1169 (0.1167) teacher/entropy 0.0377 (0.0931) teacher/usage_max 0.5572 (0.5077) teacher/usage_min 0.0941 (0.1220) teacher/usage_std 0.1894 (0.1643) nleep/row_max_mean 1531.9102 (1507.5135) nleep/row_max_std 42.3934 (62.7064) nleep/row_min_mean 1503.9360 (1481.4856) lr 1.5358e-03 eta 0:10:13
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,279
* accuracy: 81.5%
* error: 18.5%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.8%
******* Domain c best val acc:      83.4%, epoch: 17 *******
******* Domain c best val test acc: 99.9%, epoch: 17 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [19/50] batch [20/203] time 0.095 (0.130) data 0.000 (0.018) loss 1.6574 (1.3351) teacher_loss 0.4100 (0.1170) loss_zs_kd 0.0610 (0.0781) loss_oracle 0.6439 (0.5745) kd_loss 0.8950 (0.8918) acc 87.5000 (97.3438) gate/entropy 1.0316 (1.0316) gate/usage_max 0.4532 (0.4533) gate/usage_min 0.1751 (0.1751) gate/usage_std 0.1167 (0.1167) teacher/entropy 0.1159 (0.0850) teacher/usage_max 0.4997 (0.5149) teacher/usage_min 0.1609 (0.0995) teacher/usage_std 0.1384 (0.1783) nleep/row_max_mean 1506.4768 (1505.3920) nleep/row_max_std 56.2139 (63.6744) nleep/row_min_mean 1482.1970 (1479.0552) lr 1.4818e-03 eta 0:13:59
epoch [19/50] batch [40/203] time 0.092 (0.112) data 0.000 (0.009) loss 1.3186 (1.3326) teacher_loss 0.0689 (0.1238) loss_zs_kd 0.0651 (0.0735) loss_oracle 0.5610 (0.5715) kd_loss 0.9366 (0.8864) acc 100.0000 (97.0312) gate/entropy 1.0316 (1.0316) gate/usage_max 0.4529 (0.4532) gate/usage_min 0.1751 (0.1750) gate/usage_std 0.1167 (0.1168) teacher/entropy 0.0988 (0.0931) teacher/usage_max 0.6681 (0.5077) teacher/usage_min 0.1176 (0.1009) teacher/usage_std 0.2400 (0.1757) nleep/row_max_mean 1507.0052 (1504.4882) nleep/row_max_std 53.0084 (66.1087) nleep/row_min_mean 1479.6335 (1478.1165) lr 1.4818e-03 eta 0:12:03
epoch [19/50] batch [60/203] time 0.096 (0.108) data 0.001 (0.006) loss 1.2177 (1.3402) teacher_loss 0.0508 (0.1310) loss_zs_kd 0.0824 (0.0723) loss_oracle 0.4785 (0.5702) kd_loss 0.8864 (0.8880) acc 100.0000 (96.7708) gate/entropy 1.0316 (1.0316) gate/usage_max 0.4526 (0.4530) gate/usage_min 0.1749 (0.1750) gate/usage_std 0.1167 (0.1168) teacher/entropy 0.0411 (0.0937) teacher/usage_max 0.4975 (0.5088) teacher/usage_min 0.0405 (0.1036) teacher/usage_std 0.2075 (0.1742) nleep/row_max_mean 1500.0986 (1504.3514) nleep/row_max_std 66.2046 (66.4074) nleep/row_min_mean 1471.4025 (1477.8488) lr 1.4818e-03 eta 0:11:33
epoch [19/50] batch [80/203] time 0.100 (0.104) data 0.000 (0.005) loss 1.3554 (1.3552) teacher_loss 0.1306 (0.1407) loss_zs_kd 0.0724 (0.0729) loss_oracle 0.5375 (0.5754) kd_loss 0.9198 (0.8905) acc 96.8750 (96.4062) gate/entropy 1.0314 (1.0315) gate/usage_max 0.4522 (0.4529) gate/usage_min 0.1746 (0.1749) gate/usage_std 0.1168 (0.1168) teacher/entropy 0.1485 (0.0958) teacher/usage_max 0.4047 (0.5102) teacher/usage_min 0.2073 (0.1085) teacher/usage_std 0.0894 (0.1721) nleep/row_max_mean 1497.9192 (1503.9003) nleep/row_max_std 72.1901 (67.2955) nleep/row_min_mean 1474.8605 (1477.5528) lr 1.4818e-03 eta 0:11:07
epoch [19/50] batch [100/203] time 0.089 (0.102) data 0.000 (0.004) loss 1.4983 (1.3662) teacher_loss 0.2722 (0.1466) loss_zs_kd 0.0789 (0.0743) loss_oracle 0.5486 (0.5754) kd_loss 0.9124 (0.8948) acc 93.7500 (96.2812) gate/entropy 1.0313 (1.0315) gate/usage_max 0.4516 (0.4527) gate/usage_min 0.1743 (0.1748) gate/usage_std 0.1168 (0.1168) teacher/entropy 0.0572 (0.0937) teacher/usage_max 0.5104 (0.5111) teacher/usage_min 0.0826 (0.1102) teacher/usage_std 0.1823 (0.1713) nleep/row_max_mean 1533.4370 (1505.3230) nleep/row_max_std 48.5473 (65.6785) nleep/row_min_mean 1503.9797 (1478.6366) lr 1.4818e-03 eta 0:10:54
epoch [19/50] batch [120/203] time 0.098 (0.101) data 0.000 (0.003) loss 1.2214 (1.3611) teacher_loss 0.0552 (0.1454) loss_zs_kd 0.0698 (0.0728) loss_oracle 0.5355 (0.5688) kd_loss 0.8635 (0.8949) acc 100.0000 (96.2760) gate/entropy 1.0312 (1.0315) gate/usage_max 0.4510 (0.4525) gate/usage_min 0.1740 (0.1747) gate/usage_std 0.1168 (0.1168) teacher/entropy 0.0681 (0.0935) teacher/usage_max 0.5310 (0.5152) teacher/usage_min 0.0394 (0.1101) teacher/usage_std 0.2119 (0.1729) nleep/row_max_mean 1519.2765 (1505.2793) nleep/row_max_std 43.3337 (65.7901) nleep/row_min_mean 1490.5945 (1478.5813) lr 1.4818e-03 eta 0:10:44
epoch [19/50] batch [140/203] time 0.094 (0.100) data 0.000 (0.003) loss 1.2905 (1.3553) teacher_loss 0.1791 (0.1463) loss_zs_kd 0.0583 (0.0708) loss_oracle 0.4154 (0.5595) kd_loss 0.8745 (0.8938) acc 93.7500 (96.2277) gate/entropy 1.0313 (1.0315) gate/usage_max 0.4502 (0.4522) gate/usage_min 0.1739 (0.1746) gate/usage_std 0.1167 (0.1168) teacher/entropy 0.0954 (0.0949) teacher/usage_max 0.5946 (0.5174) teacher/usage_min 0.0682 (0.1088) teacher/usage_std 0.2149 (0.1744) nleep/row_max_mean 1501.3865 (1504.8920) nleep/row_max_std 62.8118 (65.6255) nleep/row_min_mean 1474.8074 (1478.1461) lr 1.4818e-03 eta 0:10:36
epoch [19/50] batch [160/203] time 0.098 (0.100) data 0.000 (0.002) loss 1.4904 (1.3584) teacher_loss 0.3374 (0.1504) loss_zs_kd 0.0689 (0.0699) loss_oracle 0.5513 (0.5558) kd_loss 0.8429 (0.8951) acc 93.7500 (96.1523) gate/entropy 1.0311 (1.0314) gate/usage_max 0.4493 (0.4519) gate/usage_min 0.1734 (0.1745) gate/usage_std 0.1168 (0.1168) teacher/entropy 0.1581 (0.0964) teacher/usage_max 0.4548 (0.5186) teacher/usage_min 0.1278 (0.1109) teacher/usage_std 0.1462 (0.1741) nleep/row_max_mean 1494.7831 (1505.1206) nleep/row_max_std 71.0231 (65.2181) nleep/row_min_mean 1470.7993 (1478.4337) lr 1.4818e-03 eta 0:10:32
epoch [19/50] batch [180/203] time 0.097 (0.100) data 0.000 (0.002) loss 1.4238 (1.3617) teacher_loss 0.2518 (0.1525) loss_zs_kd 0.0898 (0.0699) loss_oracle 0.5677 (0.5565) kd_loss 0.8432 (0.8960) acc 93.7500 (96.1458) gate/entropy 1.0308 (1.0314) gate/usage_max 0.4484 (0.4516) gate/usage_min 0.1729 (0.1744) gate/usage_std 0.1169 (0.1168) teacher/entropy 0.0615 (0.0948) teacher/usage_max 0.5064 (0.5218) teacher/usage_min 0.0184 (0.1096) teacher/usage_std 0.2231 (0.1761) nleep/row_max_mean 1514.1343 (1505.7558) nleep/row_max_std 58.9443 (64.4190) nleep/row_min_mean 1486.1359 (1478.9727) lr 1.4818e-03 eta 0:10:28
epoch [19/50] batch [200/203] time 0.092 (0.099) data 0.000 (0.002) loss 1.5699 (1.3656) teacher_loss 0.4046 (0.1561) loss_zs_kd 0.0598 (0.0696) loss_oracle 0.5324 (0.5585) kd_loss 0.8692 (0.8955) acc 84.3750 (96.0156) gate/entropy 1.0308 (1.0313) gate/usage_max 0.4475 (0.4512) gate/usage_min 0.1727 (0.1742) gate/usage_std 0.1169 (0.1168) teacher/entropy 0.0587 (0.0940) teacher/usage_max 0.5318 (0.5241) teacher/usage_min 0.0386 (0.1076) teacher/usage_std 0.2126 (0.1775) nleep/row_max_mean 1511.6848 (1505.7927) nleep/row_max_std 61.1892 (64.2265) nleep/row_min_mean 1478.8640 (1478.9261) lr 1.4818e-03 eta 0:10:21
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,247
* accuracy: 80.4%
* error: 19.6%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,413
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.6%
******* Domain c best val acc:      83.4%, epoch: 17 *******
******* Domain c best val test acc: 99.9%, epoch: 17 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [20/50] batch [20/203] time 0.094 (0.097) data 0.000 (0.012) loss 1.4012 (1.3928) teacher_loss 0.0725 (0.1796) loss_zs_kd 0.0650 (0.0762) loss_oracle 0.5587 (0.5716) kd_loss 1.0168 (0.8893) acc 100.0000 (94.6875) gate/entropy 1.0307 (1.0306) gate/usage_max 0.4466 (0.4469) gate/usage_min 0.1724 (0.1723) gate/usage_std 0.1169 (0.1170) teacher/entropy 0.0346 (0.0933) teacher/usage_max 0.4397 (0.5247) teacher/usage_min 0.1848 (0.0993) teacher/usage_std 0.1082 (0.1813) nleep/row_max_mean 1513.6943 (1508.2293) nleep/row_max_std 44.5029 (64.6026) nleep/row_min_mean 1487.6462 (1481.2458) lr 1.4258e-03 eta 0:10:05
epoch [20/50] batch [40/203] time 0.074 (0.089) data 0.000 (0.006) loss 1.4082 (1.3488) teacher_loss 0.3731 (0.1657) loss_zs_kd 0.0487 (0.0651) loss_oracle 0.5031 (0.5414) kd_loss 0.7592 (0.8798) acc 90.6250 (95.5469) gate/entropy 1.0304 (1.0306) gate/usage_max 0.4456 (0.4465) gate/usage_min 0.1719 (0.1722) gate/usage_std 0.1170 (0.1170) teacher/entropy 0.1714 (0.0993) teacher/usage_max 0.5256 (0.5382) teacher/usage_min 0.0625 (0.0945) teacher/usage_std 0.1971 (0.1886) nleep/row_max_mean 1479.2527 (1506.0852) nleep/row_max_std 92.2010 (66.9225) nleep/row_min_mean 1454.9200 (1479.7216) lr 1.4258e-03 eta 0:09:17
epoch [20/50] batch [60/203] time 0.097 (0.089) data 0.001 (0.004) loss 1.3037 (1.3504) teacher_loss 0.1664 (0.1696) loss_zs_kd 0.0546 (0.0642) loss_oracle 0.5586 (0.5405) kd_loss 0.8307 (0.8784) acc 96.8750 (95.3125) gate/entropy 1.0303 (1.0305) gate/usage_max 0.4447 (0.4460) gate/usage_min 0.1715 (0.1720) gate/usage_std 0.1171 (0.1170) teacher/entropy 0.0814 (0.0940) teacher/usage_max 0.6550 (0.5459) teacher/usage_min 0.0052 (0.0865) teacher/usage_std 0.2653 (0.1940) nleep/row_max_mean 1492.9336 (1505.4547) nleep/row_max_std 72.8400 (66.0980) nleep/row_min_mean 1466.1272 (1478.9575) lr 1.4258e-03 eta 0:09:13
epoch [20/50] batch [80/203] time 0.096 (0.088) data 0.000 (0.003) loss 1.4819 (1.3569) teacher_loss 0.2173 (0.1722) loss_zs_kd 0.0826 (0.0650) loss_oracle 0.5974 (0.5425) kd_loss 0.9246 (0.8809) acc 96.8750 (95.3906) gate/entropy 1.0298 (1.0304) gate/usage_max 0.4435 (0.4455) gate/usage_min 0.1707 (0.1718) gate/usage_std 0.1174 (0.1171) teacher/entropy 0.0456 (0.0908) teacher/usage_max 0.5956 (0.5502) teacher/usage_min 0.0777 (0.0855) teacher/usage_std 0.2115 (0.1963) nleep/row_max_mean 1527.3705 (1505.9086) nleep/row_max_std 49.8610 (65.9102) nleep/row_min_mean 1500.3062 (1479.3952) lr 1.4258e-03 eta 0:09:08
epoch [20/50] batch [100/203] time 0.090 (0.090) data 0.000 (0.003) loss 1.3851 (1.3592) teacher_loss 0.2242 (0.1793) loss_zs_kd 0.0631 (0.0636) loss_oracle 0.5698 (0.5424) kd_loss 0.8444 (0.8770) acc 93.7500 (95.0938) gate/entropy 1.0298 (1.0303) gate/usage_max 0.4427 (0.4451) gate/usage_min 0.1705 (0.1716) gate/usage_std 0.1174 (0.1171) teacher/entropy 0.0931 (0.0881) teacher/usage_max 0.5176 (0.5584) teacher/usage_min 0.0553 (0.0776) teacher/usage_std 0.2001 (0.2025) nleep/row_max_mean 1503.8964 (1504.7559) nleep/row_max_std 68.3024 (67.2270) nleep/row_min_mean 1479.9307 (1478.1955) lr 1.4258e-03 eta 0:09:16
epoch [20/50] batch [120/203] time 0.095 (0.093) data 0.000 (0.002) loss 1.3844 (1.3562) teacher_loss 0.2094 (0.1812) loss_zs_kd 0.0576 (0.0629) loss_oracle 0.5322 (0.5384) kd_loss 0.8801 (0.8744) acc 96.8750 (95.0000) gate/entropy 1.0297 (1.0302) gate/usage_max 0.4419 (0.4446) gate/usage_min 0.1703 (0.1714) gate/usage_std 0.1174 (0.1172) teacher/entropy 0.0868 (0.0896) teacher/usage_max 0.6122 (0.5665) teacher/usage_min 0.0738 (0.0755) teacher/usage_std 0.2202 (0.2062) nleep/row_max_mean 1512.4703 (1505.0591) nleep/row_max_std 62.6365 (66.6929) nleep/row_min_mean 1485.2119 (1478.4821) lr 1.4258e-03 eta 0:09:31
epoch [20/50] batch [140/203] time 0.098 (0.093) data 0.000 (0.002) loss 1.1945 (1.3573) teacher_loss 0.1286 (0.1843) loss_zs_kd 0.0419 (0.0614) loss_oracle 0.4692 (0.5374) kd_loss 0.8104 (0.8735) acc 93.7500 (94.7545) gate/entropy 1.0292 (1.0301) gate/usage_max 0.4408 (0.4441) gate/usage_min 0.1696 (0.1712) gate/usage_std 0.1177 (0.1172) teacher/entropy 0.0829 (0.0878) teacher/usage_max 0.5510 (0.5739) teacher/usage_min 0.0067 (0.0721) teacher/usage_std 0.2352 (0.2104) nleep/row_max_mean 1508.6593 (1504.5674) nleep/row_max_std 66.3968 (67.1202) nleep/row_min_mean 1479.7817 (1477.7754) lr 1.4258e-03 eta 0:09:32
epoch [20/50] batch [160/203] time 0.103 (0.093) data 0.000 (0.002) loss 1.3586 (1.3590) teacher_loss 0.2993 (0.1926) loss_zs_kd 0.0275 (0.0601) loss_oracle 0.3987 (0.5306) kd_loss 0.8462 (0.8711) acc 93.7500 (94.6094) gate/entropy 1.0291 (1.0300) gate/usage_max 0.4399 (0.4437) gate/usage_min 0.1693 (0.1710) gate/usage_std 0.1177 (0.1173) teacher/entropy 0.0675 (0.0886) teacher/usage_max 0.7086 (0.5799) teacher/usage_min 0.0082 (0.0700) teacher/usage_std 0.2881 (0.2137) nleep/row_max_mean 1499.1619 (1504.5639) nleep/row_max_std 79.2372 (66.5000) nleep/row_min_mean 1471.4014 (1477.7321) lr 1.4258e-03 eta 0:09:30
epoch [20/50] batch [180/203] time 0.092 (0.093) data 0.000 (0.002) loss 1.4084 (1.3704) teacher_loss 0.1976 (0.2038) loss_zs_kd 0.0651 (0.0599) loss_oracle 0.5350 (0.5295) kd_loss 0.9108 (0.8720) acc 90.6250 (94.2361) gate/entropy 1.0289 (1.0299) gate/usage_max 0.4389 (0.4432) gate/usage_min 0.1689 (0.1708) gate/usage_std 0.1178 (0.1173) teacher/entropy 0.1018 (0.0898) teacher/usage_max 0.5918 (0.5830) teacher/usage_min 0.1285 (0.0723) teacher/usage_std 0.1929 (0.2141) nleep/row_max_mean 1518.9552 (1504.3395) nleep/row_max_std 46.7327 (66.5642) nleep/row_min_mean 1493.9634 (1477.5464) lr 1.4258e-03 eta 0:09:30
epoch [20/50] batch [200/203] time 0.084 (0.093) data 0.000 (0.001) loss 1.4129 (1.3750) teacher_loss 0.2147 (0.2060) loss_zs_kd 0.0621 (0.0596) loss_oracle 0.5680 (0.5304) kd_loss 0.8831 (0.8739) acc 96.8750 (94.0938) gate/entropy 1.0288 (1.0298) gate/usage_max 0.4382 (0.4427) gate/usage_min 0.1686 (0.1705) gate/usage_std 0.1179 (0.1174) teacher/entropy 0.0974 (0.0898) teacher/usage_max 0.5130 (0.5872) teacher/usage_min 0.1050 (0.0743) teacher/usage_std 0.1701 (0.2152) nleep/row_max_mean 1482.4099 (1504.2213) nleep/row_max_std 82.2692 (66.6976) nleep/row_min_mean 1456.8307 (1477.5189) lr 1.4258e-03 eta 0:09:26
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,290
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 86.1%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.4%, epoch: 17 *******
******* Domain c best val test acc: 99.9%, epoch: 17 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [21/50] batch [20/203] time 0.093 (0.111) data 0.000 (0.018) loss 1.3798 (1.3951) teacher_loss 0.2825 (0.2526) loss_zs_kd 0.0411 (0.0520) loss_oracle 0.4150 (0.4948) kd_loss 0.8692 (0.8691) acc 84.3750 (92.3438) gate/entropy 1.0285 (1.0285) gate/usage_max 0.4371 (0.4375) gate/usage_min 0.1682 (0.1683) gate/usage_std 0.1181 (0.1180) teacher/entropy 0.1497 (0.0970) teacher/usage_max 0.7683 (0.6817) teacher/usage_min 0.1128 (0.0699) teacher/usage_std 0.3076 (0.2621) nleep/row_max_mean 1479.0752 (1494.1791) nleep/row_max_std 84.3231 (72.7868) nleep/row_min_mean 1458.6501 (1469.6630) lr 1.3681e-03 eta 0:11:10
epoch [21/50] batch [40/203] time 0.101 (0.102) data 0.000 (0.009) loss 1.2154 (1.3905) teacher_loss 0.0682 (0.2501) loss_zs_kd 0.0593 (0.0526) loss_oracle 0.4902 (0.4853) kd_loss 0.8724 (0.8715) acc 100.0000 (92.3438) gate/entropy 1.0283 (1.0284) gate/usage_max 0.4362 (0.4370) gate/usage_min 0.1678 (0.1681) gate/usage_std 0.1182 (0.1181) teacher/entropy 0.0774 (0.0954) teacher/usage_max 0.7113 (0.6638) teacher/usage_min 0.0534 (0.0744) teacher/usage_std 0.2774 (0.2502) nleep/row_max_mean 1511.4624 (1499.3897) nleep/row_max_std 57.3768 (67.3112) nleep/row_min_mean 1486.4515 (1474.6540) lr 1.3681e-03 eta 0:10:19
epoch [21/50] batch [60/203] time 0.096 (0.100) data 0.001 (0.006) loss 1.5098 (1.4088) teacher_loss 0.2062 (0.2570) loss_zs_kd 0.0500 (0.0522) loss_oracle 0.5424 (0.4898) kd_loss 1.0073 (0.8808) acc 90.6250 (92.0833) gate/entropy 1.0279 (1.0283) gate/usage_max 0.4354 (0.4366) gate/usage_min 0.1673 (0.1679) gate/usage_std 0.1184 (0.1182) teacher/entropy 0.0866 (0.0924) teacher/usage_max 0.5761 (0.6525) teacher/usage_min 0.2047 (0.0813) teacher/usage_std 0.1718 (0.2424) nleep/row_max_mean 1488.8171 (1499.2467) nleep/row_max_std 80.7348 (67.2714) nleep/row_min_mean 1466.1145 (1474.4540) lr 1.3681e-03 eta 0:10:00
epoch [21/50] batch [80/203] time 0.079 (0.100) data 0.000 (0.005) loss 1.5124 (1.4227) teacher_loss 0.2876 (0.2614) loss_zs_kd 0.0621 (0.0535) loss_oracle 0.5202 (0.4995) kd_loss 0.9337 (0.8847) acc 90.6250 (91.9531) gate/entropy 1.0277 (1.0282) gate/usage_max 0.4348 (0.4362) gate/usage_min 0.1670 (0.1677) gate/usage_std 0.1185 (0.1183) teacher/entropy 0.0605 (0.0903) teacher/usage_max 0.7653 (0.6485) teacher/usage_min 0.0988 (0.0836) teacher/usage_std 0.3058 (0.2403) nleep/row_max_mean 1503.7068 (1500.1551) nleep/row_max_std 65.4126 (65.3541) nleep/row_min_mean 1477.3273 (1475.3859) lr 1.3681e-03 eta 0:09:58
epoch [21/50] batch [100/203] time 0.093 (0.098) data 0.000 (0.004) loss 1.6730 (1.4256) teacher_loss 0.4640 (0.2605) loss_zs_kd 0.0607 (0.0545) loss_oracle 0.4668 (0.5028) kd_loss 0.9452 (0.8865) acc 93.7500 (92.0625) gate/entropy 1.0276 (1.0281) gate/usage_max 0.4341 (0.4359) gate/usage_min 0.1669 (0.1676) gate/usage_std 0.1186 (0.1183) teacher/entropy 0.1021 (0.0901) teacher/usage_max 0.5960 (0.6448) teacher/usage_min 0.1701 (0.0868) teacher/usage_std 0.1876 (0.2373) nleep/row_max_mean 1502.9402 (1500.2954) nleep/row_max_std 61.7190 (65.1331) nleep/row_min_mean 1479.7795 (1475.4905) lr 1.3681e-03 eta 0:09:48
epoch [21/50] batch [120/203] time 0.095 (0.098) data 0.000 (0.003) loss 1.2778 (1.4237) teacher_loss 0.1445 (0.2549) loss_zs_kd 0.0572 (0.0543) loss_oracle 0.4695 (0.5033) kd_loss 0.8700 (0.8900) acc 96.8750 (92.2135) gate/entropy 1.0273 (1.0280) gate/usage_max 0.4336 (0.4356) gate/usage_min 0.1665 (0.1674) gate/usage_std 0.1188 (0.1184) teacher/entropy 0.0716 (0.0907) teacher/usage_max 0.7376 (0.6329) teacher/usage_min 0.0482 (0.0931) teacher/usage_std 0.2938 (0.2294) nleep/row_max_mean 1522.1482 (1500.7970) nleep/row_max_std 58.7322 (64.7670) nleep/row_min_mean 1494.0542 (1475.9464) lr 1.3681e-03 eta 0:09:43
epoch [21/50] batch [140/203] time 0.103 (0.098) data 0.002 (0.003) loss 1.2405 (1.4163) teacher_loss 0.0949 (0.2461) loss_zs_kd 0.0696 (0.0553) loss_oracle 0.4992 (0.5028) kd_loss 0.8612 (0.8912) acc 96.8750 (92.4554) gate/entropy 1.0273 (1.0279) gate/usage_max 0.4331 (0.4352) gate/usage_min 0.1664 (0.1673) gate/usage_std 0.1188 (0.1184) teacher/entropy 0.0533 (0.0895) teacher/usage_max 0.5752 (0.6325) teacher/usage_min 0.0344 (0.0937) teacher/usage_std 0.2244 (0.2287) nleep/row_max_mean 1501.7410 (1502.0348) nleep/row_max_std 68.1476 (63.7017) nleep/row_min_mean 1475.6318 (1477.1038) lr 1.3681e-03 eta 0:09:42
epoch [21/50] batch [160/203] time 0.116 (0.098) data 0.001 (0.003) loss 1.5417 (1.4160) teacher_loss 0.4439 (0.2476) loss_zs_kd 0.0423 (0.0551) loss_oracle 0.4492 (0.5039) kd_loss 0.8520 (0.8889) acc 84.3750 (92.2461) gate/entropy 1.0273 (1.0278) gate/usage_max 0.4328 (0.4350) gate/usage_min 0.1664 (0.1672) gate/usage_std 0.1188 (0.1185) teacher/entropy 0.1039 (0.0885) teacher/usage_max 0.5170 (0.6272) teacher/usage_min 0.0822 (0.0914) teacher/usage_std 0.1838 (0.2273) nleep/row_max_mean 1490.3853 (1501.9448) nleep/row_max_std 70.4909 (64.0647) nleep/row_min_mean 1466.3506 (1477.0016) lr 1.3681e-03 eta 0:09:41
epoch [21/50] batch [180/203] time 0.089 (0.098) data 0.000 (0.002) loss 1.3907 (1.4140) teacher_loss 0.2086 (0.2480) loss_zs_kd 0.0607 (0.0553) loss_oracle 0.5802 (0.5048) kd_loss 0.8616 (0.8859) acc 93.7500 (92.2743) gate/entropy 1.0268 (1.0277) gate/usage_max 0.4322 (0.4347) gate/usage_min 0.1658 (0.1671) gate/usage_std 0.1191 (0.1185) teacher/entropy 0.0767 (0.0900) teacher/usage_max 0.7182 (0.6222) teacher/usage_min 0.0498 (0.0909) teacher/usage_std 0.2821 (0.2251) nleep/row_max_mean 1529.8624 (1501.9848) nleep/row_max_std 29.6256 (63.9273) nleep/row_min_mean 1502.2926 (1477.1164) lr 1.3681e-03 eta 0:09:39
epoch [21/50] batch [200/203] time 0.084 (0.097) data 0.000 (0.002) loss 1.3499 (1.4068) teacher_loss 0.2577 (0.2436) loss_zs_kd 0.0605 (0.0558) loss_oracle 0.4587 (0.5054) kd_loss 0.8326 (0.8826) acc 90.6250 (92.4219) gate/entropy 1.0269 (1.0276) gate/usage_max 0.4319 (0.4344) gate/usage_min 0.1658 (0.1669) gate/usage_std 0.1191 (0.1186) teacher/entropy 0.0909 (0.0894) teacher/usage_max 0.6191 (0.6200) teacher/usage_min 0.0420 (0.0875) teacher/usage_std 0.2356 (0.2254) nleep/row_max_mean 1483.4172 (1502.6879) nleep/row_max_std 81.1921 (63.5181) nleep/row_min_mean 1461.7111 (1477.7746) lr 1.3681e-03 eta 0:09:33
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,286
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 85.8%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      83.4%, epoch: 17 *******
******* Domain c best val test acc: 99.9%, epoch: 17 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [22/50] batch [20/203] time 0.090 (0.108) data 0.000 (0.015) loss 1.2688 (1.3398) teacher_loss 0.1591 (0.1785) loss_zs_kd 0.0730 (0.0620) loss_oracle 0.5047 (0.5294) kd_loss 0.8209 (0.8656) acc 96.8750 (94.0625) gate/entropy 1.0266 (1.0268) gate/usage_max 0.4315 (0.4317) gate/usage_min 0.1655 (0.1657) gate/usage_std 0.1192 (0.1191) teacher/entropy 0.1155 (0.0809) teacher/usage_max 0.4976 (0.5440) teacher/usage_min 0.0647 (0.0724) teacher/usage_std 0.1915 (0.1998) nleep/row_max_mean 1526.4192 (1504.7411) nleep/row_max_std 49.2662 (64.3367) nleep/row_min_mean 1501.2856 (1479.1919) lr 1.3090e-03 eta 0:10:32
epoch [22/50] batch [40/203] time 0.093 (0.100) data 0.000 (0.007) loss 1.2123 (1.3350) teacher_loss 0.1590 (0.1837) loss_zs_kd 0.0403 (0.0579) loss_oracle 0.4692 (0.5207) kd_loss 0.7986 (0.8620) acc 93.7500 (94.6875) gate/entropy 1.0267 (1.0267) gate/usage_max 0.4312 (0.4315) gate/usage_min 0.1655 (0.1656) gate/usage_std 0.1192 (0.1192) teacher/entropy 0.1036 (0.0818) teacher/usage_max 0.7096 (0.5840) teacher/usage_min 0.0140 (0.0669) teacher/usage_std 0.2868 (0.2182) nleep/row_max_mean 1493.6691 (1503.8811) nleep/row_max_std 69.8668 (64.0948) nleep/row_min_mean 1470.9143 (1478.7959) lr 1.3090e-03 eta 0:09:46
epoch [22/50] batch [60/203] time 0.082 (0.098) data 0.001 (0.005) loss 1.3106 (1.3465) teacher_loss 0.1058 (0.1911) loss_zs_kd 0.0406 (0.0568) loss_oracle 0.5021 (0.5155) kd_loss 0.9335 (0.8693) acc 96.8750 (94.5833) gate/entropy 1.0267 (1.0267) gate/usage_max 0.4310 (0.4314) gate/usage_min 0.1655 (0.1656) gate/usage_std 0.1192 (0.1192) teacher/entropy 0.0730 (0.0869) teacher/usage_max 0.5500 (0.5747) teacher/usage_min 0.1341 (0.0805) teacher/usage_std 0.1702 (0.2084) nleep/row_max_mean 1515.9225 (1503.2469) nleep/row_max_std 32.7431 (63.0222) nleep/row_min_mean 1491.4365 (1478.4622) lr 1.3090e-03 eta 0:09:30
epoch [22/50] batch [80/203] time 0.094 (0.097) data 0.000 (0.004) loss 1.2658 (1.3527) teacher_loss 0.1683 (0.1981) loss_zs_kd 0.0606 (0.0571) loss_oracle 0.4603 (0.5114) kd_loss 0.8371 (0.8704) acc 96.8750 (94.4141) gate/entropy 1.0264 (1.0266) gate/usage_max 0.4306 (0.4312) gate/usage_min 0.1652 (0.1655) gate/usage_std 0.1194 (0.1192) teacher/entropy 0.1174 (0.0868) teacher/usage_max 0.5977 (0.5672) teacher/usage_min 0.0779 (0.0823) teacher/usage_std 0.2123 (0.2045) nleep/row_max_mean 1526.8823 (1504.4139) nleep/row_max_std 32.9839 (61.2505) nleep/row_min_mean 1500.0417 (1479.4839) lr 1.3090e-03 eta 0:09:23
epoch [22/50] batch [100/203] time 0.093 (0.096) data 0.000 (0.003) loss 1.5154 (1.3585) teacher_loss 0.2185 (0.1947) loss_zs_kd 0.0600 (0.0591) loss_oracle 0.5935 (0.5182) kd_loss 0.9702 (0.8752) acc 93.7500 (94.5938) gate/entropy 1.0266 (1.0266) gate/usage_max 0.4307 (0.4311) gate/usage_min 0.1655 (0.1654) gate/usage_std 0.1192 (0.1193) teacher/entropy 0.0553 (0.0870) teacher/usage_max 0.5236 (0.5616) teacher/usage_min 0.1570 (0.0881) teacher/usage_std 0.1500 (0.1998) nleep/row_max_mean 1496.4658 (1504.4349) nleep/row_max_std 60.2247 (61.0918) nleep/row_min_mean 1471.4518 (1479.4135) lr 1.3090e-03 eta 0:09:16
epoch [22/50] batch [120/203] time 0.094 (0.096) data 0.000 (0.003) loss 1.4384 (1.3549) teacher_loss 0.2489 (0.1883) loss_zs_kd 0.0629 (0.0594) loss_oracle 0.5268 (0.5180) kd_loss 0.8946 (0.8778) acc 93.7500 (94.7396) gate/entropy 1.0263 (1.0265) gate/usage_max 0.4303 (0.4310) gate/usage_min 0.1650 (0.1654) gate/usage_std 0.1195 (0.1193) teacher/entropy 0.1130 (0.0882) teacher/usage_max 0.4664 (0.5581) teacher/usage_min 0.1425 (0.0923) teacher/usage_std 0.1384 (0.1968) nleep/row_max_mean 1492.9510 (1504.3154) nleep/row_max_std 80.0118 (61.3170) nleep/row_min_mean 1472.9734 (1479.4354) lr 1.3090e-03 eta 0:09:12
epoch [22/50] batch [140/203] time 0.097 (0.096) data 0.000 (0.002) loss 1.4228 (1.3592) teacher_loss 0.2046 (0.1895) loss_zs_kd 0.0365 (0.0585) loss_oracle 0.5076 (0.5155) kd_loss 0.9461 (0.8827) acc 90.6250 (94.7098) gate/entropy 1.0263 (1.0265) gate/usage_max 0.4301 (0.4309) gate/usage_min 0.1650 (0.1653) gate/usage_std 0.1195 (0.1193) teacher/entropy 0.1008 (0.0894) teacher/usage_max 0.5541 (0.5565) teacher/usage_min 0.1767 (0.0981) teacher/usage_std 0.1606 (0.1938) nleep/row_max_mean 1498.0918 (1503.4484) nleep/row_max_std 59.7311 (61.8827) nleep/row_min_mean 1477.8629 (1478.7716) lr 1.3090e-03 eta 0:09:10
epoch [22/50] batch [160/203] time 0.083 (0.096) data 0.000 (0.002) loss 1.4852 (1.3664) teacher_loss 0.3338 (0.1929) loss_zs_kd 0.0582 (0.0591) loss_oracle 0.4689 (0.5165) kd_loss 0.8878 (0.8857) acc 93.7500 (94.6484) gate/entropy 1.0261 (1.0265) gate/usage_max 0.4299 (0.4308) gate/usage_min 0.1648 (0.1653) gate/usage_std 0.1196 (0.1193) teacher/entropy 0.0688 (0.0899) teacher/usage_max 0.6073 (0.5509) teacher/usage_min 0.0800 (0.1024) teacher/usage_std 0.2158 (0.1899) nleep/row_max_mean 1508.8374 (1503.7966) nleep/row_max_std 58.4641 (61.2767) nleep/row_min_mean 1481.1980 (1479.2052) lr 1.3090e-03 eta 0:09:08
epoch [22/50] batch [180/203] time 0.094 (0.096) data 0.000 (0.002) loss 1.2721 (1.3613) teacher_loss 0.1383 (0.1878) loss_zs_kd 0.0468 (0.0598) loss_oracle 0.4337 (0.5146) kd_loss 0.8935 (0.8863) acc 96.8750 (94.8090) gate/entropy 1.0261 (1.0264) gate/usage_max 0.4299 (0.4307) gate/usage_min 0.1648 (0.1652) gate/usage_std 0.1196 (0.1194) teacher/entropy 0.0856 (0.0916) teacher/usage_max 0.4839 (0.5483) teacher/usage_min 0.1112 (0.1051) teacher/usage_std 0.1603 (0.1874) nleep/row_max_mean 1501.3838 (1503.6088) nleep/row_max_std 71.4941 (61.1173) nleep/row_min_mean 1478.1133 (1479.1077) lr 1.3090e-03 eta 0:09:07
epoch [22/50] batch [200/203] time 0.089 (0.095) data 0.000 (0.002) loss 1.3254 (1.3620) teacher_loss 0.2343 (0.1875) loss_zs_kd 0.0877 (0.0601) loss_oracle 0.4398 (0.5129) kd_loss 0.8273 (0.8880) acc 93.7500 (94.7969) gate/entropy 1.0261 (1.0264) gate/usage_max 0.4298 (0.4306) gate/usage_min 0.1649 (0.1652) gate/usage_std 0.1196 (0.1194) teacher/entropy 0.1551 (0.0914) teacher/usage_max 0.5989 (0.5445) teacher/usage_min 0.1079 (0.1065) teacher/usage_std 0.2025 (0.1854) nleep/row_max_mean 1499.6398 (1503.3721) nleep/row_max_std 72.3758 (61.3535) nleep/row_min_mean 1476.9690 (1478.8915) lr 1.3090e-03 eta 0:09:02
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,325
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.4%, epoch: 17 *******
******* Domain c best val test acc: 99.9%, epoch: 17 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [23/50] batch [20/203] time 0.085 (0.125) data 0.000 (0.018) loss 1.5055 (1.3153) teacher_loss 0.3362 (0.1390) loss_zs_kd 0.0611 (0.0684) loss_oracle 0.5300 (0.5247) kd_loss 0.8738 (0.8797) acc 87.5000 (95.6250) gate/entropy 1.0261 (1.0261) gate/usage_max 0.4297 (0.4298) gate/usage_min 0.1648 (0.1648) gate/usage_std 0.1196 (0.1196) teacher/entropy 0.0479 (0.0973) teacher/usage_max 0.5150 (0.5122) teacher/usage_min 0.0494 (0.1095) teacher/usage_std 0.2034 (0.1716) nleep/row_max_mean 1490.3005 (1502.0580) nleep/row_max_std 71.4443 (61.7112) nleep/row_min_mean 1462.8124 (1476.8105) lr 1.2487e-03 eta 0:11:47
epoch [23/50] batch [40/203] time 0.096 (0.110) data 0.000 (0.009) loss 1.2457 (1.3418) teacher_loss 0.1314 (0.1549) loss_zs_kd 0.0540 (0.0697) loss_oracle 0.4675 (0.5247) kd_loss 0.8536 (0.8897) acc 96.8750 (95.5469) gate/entropy 1.0264 (1.0261) gate/usage_max 0.4298 (0.4297) gate/usage_min 0.1651 (0.1648) gate/usage_std 0.1194 (0.1196) teacher/entropy 0.0892 (0.0931) teacher/usage_max 0.6256 (0.5120) teacher/usage_min 0.0640 (0.1160) teacher/usage_std 0.2299 (0.1675) nleep/row_max_mean 1496.8185 (1502.6476) nleep/row_max_std 55.7383 (60.2467) nleep/row_min_mean 1468.4594 (1477.6227) lr 1.2487e-03 eta 0:10:18
epoch [23/50] batch [60/203] time 0.105 (0.109) data 0.000 (0.006) loss 1.4247 (1.3537) teacher_loss 0.1970 (0.1604) loss_zs_kd 0.1123 (0.0726) loss_oracle 0.5520 (0.5413) kd_loss 0.8956 (0.8864) acc 90.6250 (95.2604) gate/entropy 1.0260 (1.0261) gate/usage_max 0.4296 (0.4297) gate/usage_min 0.1647 (0.1648) gate/usage_std 0.1196 (0.1196) teacher/entropy 0.0562 (0.0933) teacher/usage_max 0.5079 (0.5151) teacher/usage_min 0.0816 (0.1128) teacher/usage_std 0.1824 (0.1704) nleep/row_max_mean 1517.6533 (1503.1127) nleep/row_max_std 29.1650 (61.5687) nleep/row_min_mean 1491.3625 (1477.6785) lr 1.2487e-03 eta 0:10:12
epoch [23/50] batch [80/203] time 0.091 (0.105) data 0.000 (0.005) loss 1.3538 (1.3629) teacher_loss 0.0666 (0.1641) loss_zs_kd 0.0639 (0.0733) loss_oracle 0.6473 (0.5489) kd_loss 0.9316 (0.8876) acc 100.0000 (95.2734) gate/entropy 1.0259 (1.0261) gate/usage_max 0.4295 (0.4297) gate/usage_min 0.1646 (0.1647) gate/usage_std 0.1197 (0.1196) teacher/entropy 0.1126 (0.0915) teacher/usage_max 0.4105 (0.5132) teacher/usage_min 0.1834 (0.1120) teacher/usage_std 0.1061 (0.1701) nleep/row_max_mean 1511.3448 (1502.7125) nleep/row_max_std 64.1519 (63.0780) nleep/row_min_mean 1487.0555 (1477.3353) lr 1.2487e-03 eta 0:09:45
epoch [23/50] batch [100/203] time 0.093 (0.101) data 0.000 (0.004) loss 1.5154 (1.3522) teacher_loss 0.3336 (0.1565) loss_zs_kd 0.0594 (0.0726) loss_oracle 0.5681 (0.5468) kd_loss 0.8681 (0.8860) acc 87.5000 (95.5625) gate/entropy 1.0261 (1.0261) gate/usage_max 0.4295 (0.4296) gate/usage_min 0.1648 (0.1647) gate/usage_std 0.1196 (0.1196) teacher/entropy 0.1265 (0.0894) teacher/usage_max 0.5056 (0.5170) teacher/usage_min 0.1354 (0.1078) teacher/usage_std 0.1522 (0.1733) nleep/row_max_mean 1503.3167 (1502.2777) nleep/row_max_std 66.8597 (63.2240) nleep/row_min_mean 1478.9468 (1476.8072) lr 1.2487e-03 eta 0:09:26
epoch [23/50] batch [120/203] time 0.094 (0.100) data 0.000 (0.003) loss 1.3409 (1.3466) teacher_loss 0.1491 (0.1537) loss_zs_kd 0.0674 (0.0730) loss_oracle 0.6372 (0.5476) kd_loss 0.8395 (0.8826) acc 93.7500 (95.7812) gate/entropy 1.0259 (1.0260) gate/usage_max 0.4294 (0.4296) gate/usage_min 0.1645 (0.1647) gate/usage_std 0.1197 (0.1196) teacher/entropy 0.0924 (0.0876) teacher/usage_max 0.4777 (0.5148) teacher/usage_min 0.0635 (0.1025) teacher/usage_std 0.1909 (0.1756) nleep/row_max_mean 1500.5177 (1502.6250) nleep/row_max_std 78.5133 (63.2558) nleep/row_min_mean 1473.2888 (1477.0108) lr 1.2487e-03 eta 0:09:17
epoch [23/50] batch [140/203] time 0.096 (0.099) data 0.000 (0.003) loss 1.4580 (1.3450) teacher_loss 0.2894 (0.1576) loss_zs_kd 0.0765 (0.0730) loss_oracle 0.5081 (0.5445) kd_loss 0.8763 (0.8786) acc 93.7500 (95.8259) gate/entropy 1.0261 (1.0260) gate/usage_max 0.4295 (0.4296) gate/usage_min 0.1647 (0.1647) gate/usage_std 0.1196 (0.1196) teacher/entropy 0.0708 (0.0883) teacher/usage_max 0.4906 (0.5148) teacher/usage_min 0.0776 (0.0992) teacher/usage_std 0.1824 (0.1775) nleep/row_max_mean 1485.7637 (1502.6884) nleep/row_max_std 75.1755 (63.3230) nleep/row_min_mean 1457.0298 (1476.8294) lr 1.2487e-03 eta 0:09:11
epoch [23/50] batch [160/203] time 0.094 (0.099) data 0.001 (0.002) loss 1.3346 (1.3396) teacher_loss 0.0530 (0.1534) loss_zs_kd 0.0642 (0.0732) loss_oracle 0.5479 (0.5418) kd_loss 0.9755 (0.8787) acc 96.8750 (95.8789) gate/entropy 1.0260 (1.0260) gate/usage_max 0.4294 (0.4296) gate/usage_min 0.1647 (0.1647) gate/usage_std 0.1197 (0.1196) teacher/entropy 0.0224 (0.0855) teacher/usage_max 0.4961 (0.5166) teacher/usage_min 0.1300 (0.0964) teacher/usage_std 0.1522 (0.1795) nleep/row_max_mean 1507.2910 (1502.7669) nleep/row_max_std 52.0594 (63.6506) nleep/row_min_mean 1484.0212 (1476.9138) lr 1.2487e-03 eta 0:09:05
epoch [23/50] batch [180/203] time 0.093 (0.098) data 0.000 (0.002) loss 1.3596 (1.3373) teacher_loss 0.1956 (0.1506) loss_zs_kd 0.0632 (0.0736) loss_oracle 0.6050 (0.5442) kd_loss 0.8298 (0.8778) acc 96.8750 (96.0069) gate/entropy 1.0257 (1.0260) gate/usage_max 0.4292 (0.4295) gate/usage_min 0.1643 (0.1647) gate/usage_std 0.1199 (0.1197) teacher/entropy 0.0673 (0.0835) teacher/usage_max 0.5068 (0.5170) teacher/usage_min 0.0247 (0.0935) teacher/usage_std 0.2188 (0.1812) nleep/row_max_mean 1502.6774 (1503.2964) nleep/row_max_std 73.0447 (63.0685) nleep/row_min_mean 1476.7524 (1477.3177) lr 1.2487e-03 eta 0:09:01
epoch [23/50] batch [200/203] time 0.074 (0.098) data 0.000 (0.002) loss 1.1657 (1.3322) teacher_loss 0.0990 (0.1493) loss_zs_kd 0.0689 (0.0731) loss_oracle 0.5162 (0.5425) kd_loss 0.7741 (0.8751) acc 96.8750 (96.0781) gate/entropy 1.0258 (1.0260) gate/usage_max 0.4292 (0.4295) gate/usage_min 0.1644 (0.1646) gate/usage_std 0.1198 (0.1197) teacher/entropy 0.1052 (0.0839) teacher/usage_max 0.5356 (0.5184) teacher/usage_min 0.0045 (0.0909) teacher/usage_std 0.2346 (0.1829) nleep/row_max_mean 1493.1401 (1503.1254) nleep/row_max_std 82.3877 (63.4149) nleep/row_min_mean 1470.9604 (1477.1119) lr 1.2487e-03 eta 0:08:55
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,340
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 87.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [24/50] batch [20/203] time 0.085 (0.111) data 0.000 (0.023) loss 1.3797 (1.3254) teacher_loss 0.2418 (0.1471) loss_zs_kd 0.0544 (0.0685) loss_oracle 0.4795 (0.5391) kd_loss 0.8709 (0.8745) acc 90.6250 (95.9375) gate/entropy 1.0257 (1.0258) gate/usage_max 0.4291 (0.4292) gate/usage_min 0.1644 (0.1644) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0937 (0.0791) teacher/usage_max 0.4579 (0.5405) teacher/usage_min 0.0988 (0.0844) teacher/usage_std 0.1660 (0.1924) nleep/row_max_mean 1508.4163 (1499.3383) nleep/row_max_std 70.0136 (69.3734) nleep/row_min_mean 1484.8278 (1473.1662) lr 1.1874e-03 eta 0:10:06
epoch [24/50] batch [40/203] time 0.071 (0.093) data 0.000 (0.012) loss 1.1901 (1.3082) teacher_loss 0.1593 (0.1426) loss_zs_kd 0.0638 (0.0692) loss_oracle 0.3792 (0.5304) kd_loss 0.8093 (0.8658) acc 93.7500 (96.2500) gate/entropy 1.0256 (1.0257) gate/usage_max 0.4290 (0.4291) gate/usage_min 0.1642 (0.1644) gate/usage_std 0.1199 (0.1198) teacher/entropy 0.1427 (0.0902) teacher/usage_max 0.4624 (0.5320) teacher/usage_min 0.0846 (0.0865) teacher/usage_std 0.1759 (0.1895) nleep/row_max_mean 1493.2275 (1501.0161) nleep/row_max_std 82.0980 (66.1211) nleep/row_min_mean 1470.7273 (1474.9331) lr 1.1874e-03 eta 0:08:27
epoch [24/50] batch [60/203] time 0.084 (0.088) data 0.000 (0.008) loss 1.2752 (1.3001) teacher_loss 0.1841 (0.1372) loss_zs_kd 0.0681 (0.0685) loss_oracle 0.4997 (0.5253) kd_loss 0.8072 (0.8660) acc 90.6250 (96.5104) gate/entropy 1.0255 (1.0257) gate/usage_max 0.4288 (0.4290) gate/usage_min 0.1641 (0.1643) gate/usage_std 0.1200 (0.1199) teacher/entropy 0.1048 (0.0885) teacher/usage_max 0.5558 (0.5361) teacher/usage_min 0.0463 (0.0848) teacher/usage_std 0.2129 (0.1911) nleep/row_max_mean 1515.3616 (1502.9502) nleep/row_max_std 44.8092 (64.3185) nleep/row_min_mean 1491.0488 (1476.6946) lr 1.1874e-03 eta 0:07:58
epoch [24/50] batch [80/203] time 0.068 (0.085) data 0.000 (0.006) loss 1.3306 (1.3183) teacher_loss 0.0766 (0.1421) loss_zs_kd 0.0640 (0.0697) loss_oracle 0.6397 (0.5339) kd_loss 0.9022 (0.8744) acc 100.0000 (96.3672) gate/entropy 1.0256 (1.0257) gate/usage_max 0.4288 (0.4290) gate/usage_min 0.1642 (0.1643) gate/usage_std 0.1199 (0.1199) teacher/entropy 0.0449 (0.0850) teacher/usage_max 0.5924 (0.5274) teacher/usage_min 0.0873 (0.0904) teacher/usage_std 0.2064 (0.1858) nleep/row_max_mean 1500.8066 (1502.7808) nleep/row_max_std 63.3536 (63.1868) nleep/row_min_mean 1474.5100 (1476.6485) lr 1.1874e-03 eta 0:07:41
epoch [24/50] batch [100/203] time 0.078 (0.083) data 0.000 (0.005) loss 1.1827 (1.3203) teacher_loss 0.0290 (0.1379) loss_zs_kd 0.0717 (0.0711) loss_oracle 0.5101 (0.5364) kd_loss 0.8627 (0.8786) acc 100.0000 (96.5000) gate/entropy 1.0257 (1.0257) gate/usage_max 0.4287 (0.4289) gate/usage_min 0.1643 (0.1643) gate/usage_std 0.1199 (0.1199) teacher/entropy 0.0724 (0.0844) teacher/usage_max 0.5065 (0.5303) teacher/usage_min 0.0643 (0.0940) teacher/usage_std 0.1928 (0.1857) nleep/row_max_mean 1492.0371 (1502.1969) nleep/row_max_std 61.8129 (63.8059) nleep/row_min_mean 1464.9803 (1476.0193) lr 1.1874e-03 eta 0:07:26
epoch [24/50] batch [120/203] time 0.072 (0.080) data 0.000 (0.004) loss 1.2662 (1.3199) teacher_loss 0.1255 (0.1376) loss_zs_kd 0.0644 (0.0722) loss_oracle 0.5196 (0.5388) kd_loss 0.8486 (0.8768) acc 96.8750 (96.5885) gate/entropy 1.0255 (1.0256) gate/usage_max 0.4285 (0.4289) gate/usage_min 0.1640 (0.1642) gate/usage_std 0.1200 (0.1199) teacher/entropy 0.0447 (0.0830) teacher/usage_max 0.5606 (0.5328) teacher/usage_min 0.0184 (0.0906) teacher/usage_std 0.2298 (0.1880) nleep/row_max_mean 1506.9226 (1501.6092) nleep/row_max_std 64.0310 (64.0210) nleep/row_min_mean 1477.3055 (1475.4324) lr 1.1874e-03 eta 0:07:10
epoch [24/50] batch [140/203] time 0.093 (0.080) data 0.000 (0.003) loss 1.2634 (1.3191) teacher_loss 0.0533 (0.1371) loss_zs_kd 0.0518 (0.0710) loss_oracle 0.5282 (0.5368) kd_loss 0.9201 (0.8780) acc 100.0000 (96.6518) gate/entropy 1.0255 (1.0256) gate/usage_max 0.4284 (0.4288) gate/usage_min 0.1641 (0.1642) gate/usage_std 0.1200 (0.1199) teacher/entropy 0.0161 (0.0812) teacher/usage_max 0.5317 (0.5330) teacher/usage_min 0.0644 (0.0899) teacher/usage_std 0.1972 (0.1886) nleep/row_max_mean 1506.1226 (1501.8373) nleep/row_max_std 67.3793 (63.8049) nleep/row_min_mean 1479.8152 (1475.5811) lr 1.1874e-03 eta 0:07:09
epoch [24/50] batch [160/203] time 0.098 (0.084) data 0.000 (0.003) loss 1.4270 (1.3212) teacher_loss 0.2706 (0.1402) loss_zs_kd 0.0760 (0.0709) loss_oracle 0.5397 (0.5382) kd_loss 0.8486 (0.8765) acc 93.7500 (96.5625) gate/entropy 1.0254 (1.0256) gate/usage_max 0.4283 (0.4288) gate/usage_min 0.1640 (0.1642) gate/usage_std 0.1201 (0.1199) teacher/entropy 0.0605 (0.0786) teacher/usage_max 0.5391 (0.5323) teacher/usage_min 0.0362 (0.0857) teacher/usage_std 0.2152 (0.1905) nleep/row_max_mean 1502.0219 (1501.8075) nleep/row_max_std 58.5947 (63.9174) nleep/row_min_mean 1473.3376 (1475.4728) lr 1.1874e-03 eta 0:07:25
epoch [24/50] batch [180/203] time 0.093 (0.085) data 0.000 (0.003) loss 1.2203 (1.3219) teacher_loss 0.0344 (0.1397) loss_zs_kd 0.0864 (0.0713) loss_oracle 0.5521 (0.5423) kd_loss 0.8667 (0.8755) acc 100.0000 (96.5972) gate/entropy 1.0253 (1.0256) gate/usage_max 0.4282 (0.4287) gate/usage_min 0.1638 (0.1641) gate/usage_std 0.1202 (0.1200) teacher/entropy 0.0097 (0.0758) teacher/usage_max 0.5609 (0.5357) teacher/usage_min 0.0007 (0.0816) teacher/usage_std 0.2405 (0.1936) nleep/row_max_mean 1513.4838 (1501.9376) nleep/row_max_std 54.6391 (63.9127) nleep/row_min_mean 1483.2983 (1475.4265) lr 1.1874e-03 eta 0:07:29
epoch [24/50] batch [200/203] time 0.084 (0.086) data 0.000 (0.003) loss 1.2041 (1.3233) teacher_loss 0.0944 (0.1420) loss_zs_kd 0.0620 (0.0717) loss_oracle 0.4490 (0.5435) kd_loss 0.8542 (0.8738) acc 96.8750 (96.5469) gate/entropy 1.0253 (1.0255) gate/usage_max 0.4282 (0.4287) gate/usage_min 0.1639 (0.1641) gate/usage_std 0.1201 (0.1200) teacher/entropy 0.0300 (0.0740) teacher/usage_max 0.5917 (0.5362) teacher/usage_min 0.0070 (0.0779) teacher/usage_std 0.2435 (0.1956) nleep/row_max_mean 1501.8999 (1502.2494) nleep/row_max_std 52.7923 (63.5133) nleep/row_min_mean 1474.2388 (1475.6340) lr 1.1874e-03 eta 0:07:32
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,326
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [25/50] batch [20/203] time 0.084 (0.103) data 0.000 (0.015) loss 1.3594 (1.3167) teacher_loss 0.1958 (0.1327) loss_zs_kd 0.0731 (0.0727) loss_oracle 0.5357 (0.5571) kd_loss 0.8592 (0.8692) acc 96.8750 (95.9375) gate/entropy 1.0251 (1.0252) gate/usage_max 0.4280 (0.4280) gate/usage_min 0.1636 (0.1637) gate/usage_std 0.1203 (0.1202) teacher/entropy 0.0505 (0.0519) teacher/usage_max 0.6560 (0.5615) teacher/usage_min 0.0318 (0.0501) teacher/usage_std 0.2553 (0.2168) nleep/row_max_mean 1490.0192 (1502.9558) nleep/row_max_std 81.2945 (61.5011) nleep/row_min_mean 1465.3247 (1474.9591) lr 1.1253e-03 eta 0:09:01
epoch [25/50] batch [40/203] time 0.091 (0.091) data 0.000 (0.008) loss 1.2435 (1.2978) teacher_loss 0.0749 (0.1221) loss_zs_kd 0.0836 (0.0750) loss_oracle 0.5285 (0.5540) kd_loss 0.8626 (0.8613) acc 100.0000 (96.7969) gate/entropy 1.0251 (1.0252) gate/usage_max 0.4279 (0.4280) gate/usage_min 0.1636 (0.1637) gate/usage_std 0.1203 (0.1202) teacher/entropy 0.0290 (0.0489) teacher/usage_max 0.5412 (0.5663) teacher/usage_min 0.0185 (0.0389) teacher/usage_std 0.2264 (0.2240) nleep/row_max_mean 1507.5447 (1503.1215) nleep/row_max_std 55.8988 (62.3987) nleep/row_min_mean 1477.8228 (1475.0983) lr 1.1253e-03 eta 0:07:55
epoch [25/50] batch [60/203] time 0.100 (0.093) data 0.001 (0.005) loss 1.2263 (1.3057) teacher_loss 0.0562 (0.1388) loss_zs_kd 0.0862 (0.0725) loss_oracle 0.5453 (0.5508) kd_loss 0.8542 (0.8552) acc 100.0000 (96.4583) gate/entropy 1.0250 (1.0251) gate/usage_max 0.4278 (0.4280) gate/usage_min 0.1635 (0.1636) gate/usage_std 0.1203 (0.1203) teacher/entropy 0.0292 (0.0519) teacher/usage_max 0.4979 (0.5563) teacher/usage_min 0.0124 (0.0362) teacher/usage_std 0.2270 (0.2228) nleep/row_max_mean 1516.8645 (1500.7061) nleep/row_max_std 45.0946 (64.4059) nleep/row_min_mean 1487.8347 (1472.9318) lr 1.1253e-03 eta 0:08:04
epoch [25/50] batch [80/203] time 0.100 (0.094) data 0.000 (0.004) loss 1.3821 (1.2992) teacher_loss 0.2633 (0.1330) loss_zs_kd 0.0573 (0.0714) loss_oracle 0.5458 (0.5501) kd_loss 0.8172 (0.8555) acc 90.6250 (96.6016) gate/entropy 1.0249 (1.0251) gate/usage_max 0.4277 (0.4279) gate/usage_min 0.1634 (0.1636) gate/usage_std 0.1204 (0.1203) teacher/entropy 0.0546 (0.0531) teacher/usage_max 0.5404 (0.5559) teacher/usage_min 0.0021 (0.0377) teacher/usage_std 0.2367 (0.2219) nleep/row_max_mean 1497.9417 (1500.5199) nleep/row_max_std 74.8633 (64.5307) nleep/row_min_mean 1470.1952 (1472.7327) lr 1.1253e-03 eta 0:08:10
epoch [25/50] batch [100/203] time 0.081 (0.093) data 0.000 (0.003) loss 1.2151 (1.3006) teacher_loss 0.0518 (0.1353) loss_zs_kd 0.0389 (0.0694) loss_oracle 0.5502 (0.5502) kd_loss 0.8687 (0.8555) acc 100.0000 (96.5000) gate/entropy 1.0248 (1.0251) gate/usage_max 0.4277 (0.4279) gate/usage_min 0.1633 (0.1636) gate/usage_std 0.1205 (0.1203) teacher/entropy 0.0593 (0.0527) teacher/usage_max 0.6044 (0.5540) teacher/usage_min 0.0665 (0.0374) teacher/usage_std 0.2196 (0.2215) nleep/row_max_mean 1502.5884 (1500.2596) nleep/row_max_std 75.8397 (65.5073) nleep/row_min_mean 1477.0000 (1472.6178) lr 1.1253e-03 eta 0:08:03
epoch [25/50] batch [120/203] time 0.093 (0.095) data 0.001 (0.003) loss 1.1540 (1.3038) teacher_loss 0.0477 (0.1401) loss_zs_kd 0.0745 (0.0699) loss_oracle 0.5012 (0.5466) kd_loss 0.8185 (0.8554) acc 100.0000 (96.4323) gate/entropy 1.0249 (1.0251) gate/usage_max 0.4277 (0.4278) gate/usage_min 0.1634 (0.1635) gate/usage_std 0.1204 (0.1203) teacher/entropy 0.0634 (0.0519) teacher/usage_max 0.5613 (0.5548) teacher/usage_min 0.0076 (0.0363) teacher/usage_std 0.2364 (0.2223) nleep/row_max_mean 1513.3350 (1500.0483) nleep/row_max_std 54.3074 (65.5476) nleep/row_min_mean 1487.5681 (1472.5572) lr 1.1253e-03 eta 0:08:09
epoch [25/50] batch [140/203] time 0.088 (0.095) data 0.000 (0.002) loss 1.3806 (1.3061) teacher_loss 0.1972 (0.1451) loss_zs_kd 0.0727 (0.0692) loss_oracle 0.5837 (0.5426) kd_loss 0.8552 (0.8551) acc 93.7500 (96.3393) gate/entropy 1.0249 (1.0250) gate/usage_max 0.4276 (0.4278) gate/usage_min 0.1634 (0.1635) gate/usage_std 0.1204 (0.1203) teacher/entropy 0.0469 (0.0525) teacher/usage_max 0.4965 (0.5570) teacher/usage_min 0.0320 (0.0363) teacher/usage_std 0.2133 (0.2232) nleep/row_max_mean 1473.2651 (1499.2415) nleep/row_max_std 84.4775 (65.6051) nleep/row_min_mean 1448.0852 (1472.0032) lr 1.1253e-03 eta 0:08:10
epoch [25/50] batch [160/203] time 0.095 (0.095) data 0.001 (0.002) loss 1.3820 (1.3082) teacher_loss 0.1780 (0.1478) loss_zs_kd 0.0681 (0.0687) loss_oracle 0.5825 (0.5429) kd_loss 0.8787 (0.8545) acc 96.8750 (96.3086) gate/entropy 1.0249 (1.0250) gate/usage_max 0.4275 (0.4277) gate/usage_min 0.1634 (0.1635) gate/usage_std 0.1204 (0.1204) teacher/entropy 0.0253 (0.0513) teacher/usage_max 0.5458 (0.5594) teacher/usage_min 0.0317 (0.0346) teacher/usage_std 0.2192 (0.2245) nleep/row_max_mean 1504.5063 (1499.7216) nleep/row_max_std 46.8329 (65.2140) nleep/row_min_mean 1475.7896 (1472.3876) lr 1.1253e-03 eta 0:08:07
epoch [25/50] batch [180/203] time 0.097 (0.095) data 0.001 (0.002) loss 1.2706 (1.3062) teacher_loss 0.2510 (0.1469) loss_zs_kd 0.0562 (0.0684) loss_oracle 0.4465 (0.5419) kd_loss 0.7683 (0.8542) acc 93.7500 (96.3194) gate/entropy 1.0249 (1.0250) gate/usage_max 0.4274 (0.4277) gate/usage_min 0.1634 (0.1634) gate/usage_std 0.1204 (0.1204) teacher/entropy 0.1063 (0.0507) teacher/usage_max 0.5425 (0.5592) teacher/usage_min 0.0053 (0.0337) teacher/usage_std 0.2349 (0.2250) nleep/row_max_mean 1491.1206 (1499.7977) nleep/row_max_std 67.1138 (65.0492) nleep/row_min_mean 1468.4080 (1472.4136) lr 1.1253e-03 eta 0:08:05
epoch [25/50] batch [200/203] time 0.086 (0.095) data 0.000 (0.002) loss 1.2675 (1.3053) teacher_loss 0.1915 (0.1481) loss_zs_kd 0.0836 (0.0684) loss_oracle 0.4875 (0.5399) kd_loss 0.7904 (0.8530) acc 93.7500 (96.2812) gate/entropy 1.0247 (1.0249) gate/usage_max 0.4272 (0.4277) gate/usage_min 0.1631 (0.1634) gate/usage_std 0.1206 (0.1204) teacher/entropy 0.0900 (0.0513) teacher/usage_max 0.5033 (0.5593) teacher/usage_min 0.0090 (0.0330) teacher/usage_std 0.2294 (0.2253) nleep/row_max_mean 1494.0433 (1499.8535) nleep/row_max_std 71.3197 (64.7824) nleep/row_min_mean 1468.2954 (1472.4235) lr 1.1253e-03 eta 0:08:01
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,320
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [26/50] batch [20/203] time 0.083 (0.106) data 0.000 (0.015) loss 1.1928 (1.2798) teacher_loss 0.0489 (0.1427) loss_zs_kd 0.0606 (0.0602) loss_oracle 0.5435 (0.5212) kd_loss 0.8418 (0.8463) acc 100.0000 (96.4062) gate/entropy 1.0247 (1.0246) gate/usage_max 0.4272 (0.4272) gate/usage_min 0.1631 (0.1630) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0286 (0.0445) teacher/usage_max 0.5540 (0.5504) teacher/usage_min 0.0016 (0.0209) teacher/usage_std 0.2388 (0.2301) nleep/row_max_mean 1510.7415 (1500.5347) nleep/row_max_std 58.2094 (63.2092) nleep/row_min_mean 1476.3099 (1472.6926) lr 1.0628e-03 eta 0:08:56
epoch [26/50] batch [40/203] time 0.086 (0.099) data 0.000 (0.008) loss 1.3958 (1.2949) teacher_loss 0.1962 (0.1521) loss_zs_kd 0.0545 (0.0630) loss_oracle 0.5438 (0.5339) kd_loss 0.9004 (0.8443) acc 96.8750 (96.4844) gate/entropy 1.0246 (1.0246) gate/usage_max 0.4271 (0.4271) gate/usage_min 0.1630 (0.1630) gate/usage_std 0.1207 (0.1207) teacher/entropy 0.0247 (0.0452) teacher/usage_max 0.5551 (0.5518) teacher/usage_min 0.0611 (0.0192) teacher/usage_std 0.2048 (0.2312) nleep/row_max_mean 1504.9365 (1498.1778) nleep/row_max_std 58.0960 (65.8079) nleep/row_min_mean 1474.8040 (1470.5088) lr 1.0628e-03 eta 0:08:16
epoch [26/50] batch [60/203] time 0.092 (0.096) data 0.001 (0.005) loss 1.3598 (1.3024) teacher_loss 0.1297 (0.1551) loss_zs_kd 0.0640 (0.0624) loss_oracle 0.6377 (0.5326) kd_loss 0.8792 (0.8497) acc 96.8750 (96.3542) gate/entropy 1.0243 (1.0245) gate/usage_max 0.4269 (0.4271) gate/usage_min 0.1627 (0.1629) gate/usage_std 0.1209 (0.1207) teacher/entropy 0.0485 (0.0441) teacher/usage_max 0.5488 (0.5606) teacher/usage_min 0.0572 (0.0228) teacher/usage_std 0.2052 (0.2320) nleep/row_max_mean 1512.0125 (1498.6396) nleep/row_max_std 45.4849 (64.6733) nleep/row_min_mean 1484.7860 (1471.4146) lr 1.0628e-03 eta 0:08:03
epoch [26/50] batch [80/203] time 0.093 (0.095) data 0.000 (0.004) loss 1.2134 (1.2996) teacher_loss 0.1256 (0.1545) loss_zs_kd 0.0692 (0.0625) loss_oracle 0.4589 (0.5308) kd_loss 0.8237 (0.8485) acc 93.7500 (96.3672) gate/entropy 1.0243 (1.0245) gate/usage_max 0.4268 (0.4271) gate/usage_min 0.1626 (0.1629) gate/usage_std 0.1209 (0.1207) teacher/entropy 0.0572 (0.0468) teacher/usage_max 0.6019 (0.5651) teacher/usage_min 0.0062 (0.0242) teacher/usage_std 0.2467 (0.2319) nleep/row_max_mean 1518.5126 (1498.5859) nleep/row_max_std 42.1412 (64.3905) nleep/row_min_mean 1489.5156 (1471.5201) lr 1.0628e-03 eta 0:07:56
epoch [26/50] batch [100/203] time 0.095 (0.095) data 0.000 (0.003) loss 1.2270 (1.2985) teacher_loss 0.1240 (0.1528) loss_zs_kd 0.0542 (0.0639) loss_oracle 0.5138 (0.5328) kd_loss 0.8190 (0.8475) acc 93.7500 (96.3125) gate/entropy 1.0244 (1.0245) gate/usage_max 0.4268 (0.4270) gate/usage_min 0.1628 (0.1629) gate/usage_std 0.1208 (0.1207) teacher/entropy 0.0710 (0.0474) teacher/usage_max 0.5407 (0.5627) teacher/usage_min 0.0221 (0.0237) teacher/usage_std 0.2241 (0.2316) nleep/row_max_mean 1493.8464 (1498.8560) nleep/row_max_std 68.9941 (64.5779) nleep/row_min_mean 1464.8267 (1471.7734) lr 1.0628e-03 eta 0:07:54
epoch [26/50] batch [120/203] time 0.095 (0.095) data 0.000 (0.003) loss 1.2773 (1.2977) teacher_loss 0.0779 (0.1517) loss_zs_kd 0.0905 (0.0666) loss_oracle 0.5917 (0.5316) kd_loss 0.8584 (0.8469) acc 96.8750 (96.4844) gate/entropy 1.0243 (1.0245) gate/usage_max 0.4267 (0.4270) gate/usage_min 0.1627 (0.1629) gate/usage_std 0.1209 (0.1207) teacher/entropy 0.0400 (0.0488) teacher/usage_max 0.5284 (0.5651) teacher/usage_min 0.0277 (0.0247) teacher/usage_std 0.2188 (0.2316) nleep/row_max_mean 1500.2522 (1498.9197) nleep/row_max_std 58.4806 (64.6911) nleep/row_min_mean 1469.0217 (1471.8139) lr 1.0628e-03 eta 0:07:51
epoch [26/50] batch [140/203] time 0.089 (0.095) data 0.000 (0.002) loss 1.2350 (1.2961) teacher_loss 0.0590 (0.1477) loss_zs_kd 0.0811 (0.0674) loss_oracle 0.5759 (0.5309) kd_loss 0.8475 (0.8492) acc 100.0000 (96.5402) gate/entropy 1.0242 (1.0244) gate/usage_max 0.4266 (0.4269) gate/usage_min 0.1626 (0.1628) gate/usage_std 0.1209 (0.1208) teacher/entropy 0.0295 (0.0474) teacher/usage_max 0.6139 (0.5627) teacher/usage_min 0.0020 (0.0256) teacher/usage_std 0.2524 (0.2304) nleep/row_max_mean 1491.8221 (1498.7462) nleep/row_max_std 80.4092 (64.6506) nleep/row_min_mean 1462.8350 (1471.4959) lr 1.0628e-03 eta 0:07:49
epoch [26/50] batch [160/203] time 0.099 (0.095) data 0.000 (0.002) loss 1.1342 (1.2982) teacher_loss 0.0164 (0.1473) loss_zs_kd 0.0541 (0.0680) loss_oracle 0.4572 (0.5315) kd_loss 0.8622 (0.8512) acc 100.0000 (96.4062) gate/entropy 1.0243 (1.0244) gate/usage_max 0.4266 (0.4269) gate/usage_min 0.1626 (0.1628) gate/usage_std 0.1209 (0.1208) teacher/entropy 0.0412 (0.0469) teacher/usage_max 0.5981 (0.5603) teacher/usage_min 0.0303 (0.0272) teacher/usage_std 0.2334 (0.2290) nleep/row_max_mean 1493.2412 (1498.8915) nleep/row_max_std 74.9215 (64.8186) nleep/row_min_mean 1467.1604 (1471.6168) lr 1.0628e-03 eta 0:07:47
epoch [26/50] batch [180/203] time 0.095 (0.095) data 0.000 (0.002) loss 1.3625 (1.2980) teacher_loss 0.1991 (0.1478) loss_zs_kd 0.0638 (0.0676) loss_oracle 0.5827 (0.5299) kd_loss 0.8401 (0.8515) acc 96.8750 (96.3715) gate/entropy 1.0240 (1.0244) gate/usage_max 0.4265 (0.4269) gate/usage_min 0.1624 (0.1628) gate/usage_std 0.1211 (0.1208) teacher/entropy 0.0263 (0.0472) teacher/usage_max 0.6434 (0.5621) teacher/usage_min 0.0009 (0.0277) teacher/usage_std 0.2628 (0.2293) nleep/row_max_mean 1515.2419 (1499.0320) nleep/row_max_std 59.9174 (64.9501) nleep/row_min_mean 1481.4315 (1471.7328) lr 1.0628e-03 eta 0:07:46
epoch [26/50] batch [200/203] time 0.086 (0.095) data 0.000 (0.002) loss 1.2810 (1.2980) teacher_loss 0.1592 (0.1479) loss_zs_kd 0.0684 (0.0671) loss_oracle 0.5165 (0.5301) kd_loss 0.8293 (0.8514) acc 93.7500 (96.3281) gate/entropy 1.0241 (1.0244) gate/usage_max 0.4265 (0.4268) gate/usage_min 0.1624 (0.1627) gate/usage_std 0.1210 (0.1208) teacher/entropy 0.0590 (0.0473) teacher/usage_max 0.5274 (0.5626) teacher/usage_min 0.0173 (0.0278) teacher/usage_std 0.2254 (0.2294) nleep/row_max_mean 1510.5730 (1499.2811) nleep/row_max_std 59.5736 (64.7923) nleep/row_min_mean 1485.6987 (1471.8156) lr 1.0628e-03 eta 0:07:41
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,330
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [27/50] batch [20/203] time 0.094 (0.114) data 0.000 (0.019) loss 1.3452 (1.3019) teacher_loss 0.1207 (0.1359) loss_zs_kd 0.0822 (0.0722) loss_oracle 0.5368 (0.5362) kd_loss 0.9151 (0.8618) acc 96.8750 (96.7188) gate/entropy 1.0243 (1.0241) gate/usage_max 0.4264 (0.4264) gate/usage_min 0.1626 (0.1624) gate/usage_std 0.1209 (0.1210) teacher/entropy 0.0445 (0.0504) teacher/usage_max 0.4873 (0.5312) teacher/usage_min 0.0927 (0.0435) teacher/usage_std 0.1724 (0.2118) nleep/row_max_mean 1491.3818 (1501.5632) nleep/row_max_std 67.0948 (63.1715) nleep/row_min_mean 1462.8835 (1474.9123) lr 1.0000e-03 eta 0:09:12
epoch [27/50] batch [40/203] time 0.090 (0.103) data 0.000 (0.009) loss 1.4159 (1.2948) teacher_loss 0.2823 (0.1379) loss_zs_kd 0.0655 (0.0685) loss_oracle 0.4784 (0.5333) kd_loss 0.8617 (0.8560) acc 87.5000 (96.4844) gate/entropy 1.0241 (1.0241) gate/usage_max 0.4264 (0.4264) gate/usage_min 0.1624 (0.1624) gate/usage_std 0.1210 (0.1210) teacher/entropy 0.1045 (0.0550) teacher/usage_max 0.5446 (0.5430) teacher/usage_min 0.1042 (0.0423) teacher/usage_std 0.1802 (0.2158) nleep/row_max_mean 1494.2848 (1502.0302) nleep/row_max_std 68.8438 (63.4103) nleep/row_min_mean 1468.5989 (1475.0498) lr 1.0000e-03 eta 0:08:17
epoch [27/50] batch [60/203] time 0.101 (0.101) data 0.001 (0.006) loss 1.3443 (1.2985) teacher_loss 0.1777 (0.1453) loss_zs_kd 0.0570 (0.0679) loss_oracle 0.5805 (0.5292) kd_loss 0.8479 (0.8546) acc 96.8750 (96.3542) gate/entropy 1.0239 (1.0240) gate/usage_max 0.4262 (0.4263) gate/usage_min 0.1622 (0.1624) gate/usage_std 0.1212 (0.1211) teacher/entropy 0.0786 (0.0552) teacher/usage_max 0.4829 (0.5581) teacher/usage_min 0.0599 (0.0402) teacher/usage_std 0.1936 (0.2212) nleep/row_max_mean 1503.2195 (1502.8274) nleep/row_max_std 65.2476 (63.8849) nleep/row_min_mean 1478.0199 (1476.0426) lr 1.0000e-03 eta 0:08:03
epoch [27/50] batch [80/203] time 0.093 (0.099) data 0.000 (0.005) loss 1.2003 (1.2974) teacher_loss 0.0420 (0.1397) loss_zs_kd 0.0932 (0.0672) loss_oracle 0.5224 (0.5282) kd_loss 0.8506 (0.8600) acc 100.0000 (96.5625) gate/entropy 1.0239 (1.0240) gate/usage_max 0.4261 (0.4263) gate/usage_min 0.1622 (0.1623) gate/usage_std 0.1212 (0.1211) teacher/entropy 0.0959 (0.0521) teacher/usage_max 0.5794 (0.5545) teacher/usage_min 0.0764 (0.0426) teacher/usage_std 0.2055 (0.2188) nleep/row_max_mean 1508.3657 (1502.9427) nleep/row_max_std 57.1149 (64.0751) nleep/row_min_mean 1480.9958 (1475.9992) lr 1.0000e-03 eta 0:07:54
epoch [27/50] batch [100/203] time 0.095 (0.101) data 0.000 (0.004) loss 1.4178 (1.2980) teacher_loss 0.1942 (0.1397) loss_zs_kd 0.0677 (0.0665) loss_oracle 0.5366 (0.5258) kd_loss 0.9215 (0.8621) acc 96.8750 (96.5000) gate/entropy 1.0240 (1.0240) gate/usage_max 0.4261 (0.4263) gate/usage_min 0.1623 (0.1623) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.1007 (0.0543) teacher/usage_max 0.4231 (0.5498) teacher/usage_min 0.1603 (0.0472) teacher/usage_std 0.1224 (0.2150) nleep/row_max_mean 1499.9374 (1502.3218) nleep/row_max_std 58.4155 (64.8857) nleep/row_min_mean 1477.3191 (1475.4983) lr 1.0000e-03 eta 0:08:02
epoch [27/50] batch [120/203] time 0.102 (0.100) data 0.000 (0.003) loss 1.4158 (1.3046) teacher_loss 0.2497 (0.1446) loss_zs_kd 0.0621 (0.0661) loss_oracle 0.5387 (0.5277) kd_loss 0.8657 (0.8631) acc 93.7500 (96.2760) gate/entropy 1.0239 (1.0240) gate/usage_max 0.4260 (0.4262) gate/usage_min 0.1622 (0.1623) gate/usage_std 0.1212 (0.1211) teacher/entropy 0.0683 (0.0537) teacher/usage_max 0.6409 (0.5496) teacher/usage_min 0.0611 (0.0476) teacher/usage_std 0.2380 (0.2149) nleep/row_max_mean 1482.1050 (1501.7014) nleep/row_max_std 79.0591 (65.4974) nleep/row_min_mean 1457.5331 (1474.9523) lr 1.0000e-03 eta 0:07:57
epoch [27/50] batch [140/203] time 0.101 (0.100) data 0.000 (0.003) loss 1.1601 (1.3087) teacher_loss 0.0379 (0.1471) loss_zs_kd 0.0660 (0.0663) loss_oracle 0.5141 (0.5311) kd_loss 0.8322 (0.8629) acc 100.0000 (96.2277) gate/entropy 1.0239 (1.0240) gate/usage_max 0.4261 (0.4262) gate/usage_min 0.1622 (0.1623) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.0949 (0.0563) teacher/usage_max 0.5825 (0.5523) teacher/usage_min 0.0560 (0.0498) teacher/usage_std 0.2159 (0.2145) nleep/row_max_mean 1501.1958 (1501.3991) nleep/row_max_std 68.7746 (65.4146) nleep/row_min_mean 1475.8391 (1474.6356) lr 1.0000e-03 eta 0:07:51
epoch [27/50] batch [160/203] time 0.098 (0.099) data 0.000 (0.003) loss 1.3875 (1.3078) teacher_loss 0.1804 (0.1431) loss_zs_kd 0.0800 (0.0673) loss_oracle 0.5785 (0.5336) kd_loss 0.8779 (0.8642) acc 93.7500 (96.3086) gate/entropy 1.0238 (1.0239) gate/usage_max 0.4259 (0.4262) gate/usage_min 0.1621 (0.1623) gate/usage_std 0.1212 (0.1211) teacher/entropy 0.0634 (0.0559) teacher/usage_max 0.5370 (0.5519) teacher/usage_min 0.0724 (0.0511) teacher/usage_std 0.1939 (0.2138) nleep/row_max_mean 1492.5005 (1501.9741) nleep/row_max_std 76.4389 (65.3029) nleep/row_min_mean 1467.4856 (1475.1974) lr 1.0000e-03 eta 0:07:46
epoch [27/50] batch [180/203] time 0.097 (0.099) data 0.000 (0.002) loss 1.3676 (1.3129) teacher_loss 0.1016 (0.1455) loss_zs_kd 0.0797 (0.0680) loss_oracle 0.6523 (0.5360) kd_loss 0.9000 (0.8654) acc 93.7500 (96.2326) gate/entropy 1.0238 (1.0239) gate/usage_max 0.4259 (0.4262) gate/usage_min 0.1621 (0.1622) gate/usage_std 0.1212 (0.1211) teacher/entropy 0.0358 (0.0569) teacher/usage_max 0.5514 (0.5495) teacher/usage_min 0.0722 (0.0536) teacher/usage_std 0.1980 (0.2117) nleep/row_max_mean 1492.6758 (1501.7540) nleep/row_max_std 76.0512 (65.7984) nleep/row_min_mean 1466.3671 (1475.0294) lr 1.0000e-03 eta 0:07:42
epoch [27/50] batch [200/203] time 0.089 (0.098) data 0.000 (0.002) loss 1.1787 (1.3160) teacher_loss 0.0953 (0.1456) loss_zs_kd 0.0761 (0.0687) loss_oracle 0.4930 (0.5359) kd_loss 0.7988 (0.8681) acc 96.8750 (96.1875) gate/entropy 1.0237 (1.0239) gate/usage_max 0.4259 (0.4261) gate/usage_min 0.1620 (0.1622) gate/usage_std 0.1213 (0.1211) teacher/entropy 0.1161 (0.0576) teacher/usage_max 0.4910 (0.5487) teacher/usage_min 0.0479 (0.0573) teacher/usage_std 0.2022 (0.2097) nleep/row_max_mean 1495.6627 (1502.1406) nleep/row_max_std 84.1866 (65.7765) nleep/row_min_mean 1471.1753 (1475.4252) lr 1.0000e-03 eta 0:07:38
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,328
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [28/50] batch [20/203] time 0.081 (0.106) data 0.000 (0.016) loss 1.2931 (1.3329) teacher_loss 0.1409 (0.1357) loss_zs_kd 0.0821 (0.0860) loss_oracle 0.5635 (0.5674) kd_loss 0.8295 (0.8705) acc 93.7500 (96.5625) gate/entropy 1.0238 (1.0237) gate/usage_max 0.4259 (0.4259) gate/usage_min 0.1621 (0.1620) gate/usage_std 0.1212 (0.1213) teacher/entropy 0.0699 (0.0580) teacher/usage_max 0.4963 (0.5281) teacher/usage_min 0.0317 (0.0612) teacher/usage_std 0.2135 (0.2003) nleep/row_max_mean 1508.0977 (1501.4162) nleep/row_max_std 64.6596 (70.1735) nleep/row_min_mean 1479.8763 (1474.4105) lr 9.3721e-04 eta 0:08:10
epoch [28/50] batch [40/203] time 0.097 (0.098) data 0.000 (0.008) loss 1.2651 (1.3185) teacher_loss 0.0691 (0.1266) loss_zs_kd 0.0470 (0.0791) loss_oracle 0.5432 (0.5567) kd_loss 0.9008 (0.8740) acc 100.0000 (97.0312) gate/entropy 1.0237 (1.0237) gate/usage_max 0.4258 (0.4259) gate/usage_min 0.1620 (0.1620) gate/usage_std 0.1213 (0.1213) teacher/entropy 0.0639 (0.0573) teacher/usage_max 0.5074 (0.5262) teacher/usage_min 0.0981 (0.0642) teacher/usage_std 0.1726 (0.1990) nleep/row_max_mean 1490.7400 (1504.0147) nleep/row_max_std 80.0892 (65.6645) nleep/row_min_mean 1465.6138 (1476.8434) lr 9.3721e-04 eta 0:07:32
epoch [28/50] batch [60/203] time 0.096 (0.096) data 0.001 (0.006) loss 1.3729 (1.3120) teacher_loss 0.1836 (0.1334) loss_zs_kd 0.0461 (0.0743) loss_oracle 0.5073 (0.5431) kd_loss 0.9127 (0.8699) acc 96.8750 (96.7188) gate/entropy 1.0236 (1.0237) gate/usage_max 0.4258 (0.4259) gate/usage_min 0.1619 (0.1620) gate/usage_std 0.1214 (0.1213) teacher/entropy 0.0162 (0.0571) teacher/usage_max 0.4985 (0.5378) teacher/usage_min 0.0615 (0.0597) teacher/usage_std 0.1937 (0.2048) nleep/row_max_mean 1517.3757 (1505.3297) nleep/row_max_std 59.7211 (62.3989) nleep/row_min_mean 1490.2463 (1478.3060) lr 9.3721e-04 eta 0:07:21
epoch [28/50] batch [80/203] time 0.082 (0.094) data 0.000 (0.004) loss 1.2207 (1.3095) teacher_loss 0.1397 (0.1409) loss_zs_kd 0.0493 (0.0708) loss_oracle 0.4826 (0.5330) kd_loss 0.8150 (0.8668) acc 90.6250 (96.4453) gate/entropy 1.0239 (1.0237) gate/usage_max 0.4259 (0.4259) gate/usage_min 0.1622 (0.1620) gate/usage_std 0.1212 (0.1213) teacher/entropy 0.1061 (0.0576) teacher/usage_max 0.5687 (0.5394) teacher/usage_min 0.0571 (0.0568) teacher/usage_std 0.2108 (0.2066) nleep/row_max_mean 1485.8762 (1504.1109) nleep/row_max_std 65.2732 (62.3430) nleep/row_min_mean 1460.4122 (1477.3778) lr 9.3721e-04 eta 0:07:09
epoch [28/50] batch [100/203] time 0.088 (0.093) data 0.000 (0.003) loss 1.3697 (1.3038) teacher_loss 0.1975 (0.1381) loss_zs_kd 0.0762 (0.0696) loss_oracle 0.5729 (0.5330) kd_loss 0.8477 (0.8644) acc 93.7500 (96.4688) gate/entropy 1.0237 (1.0237) gate/usage_max 0.4259 (0.4259) gate/usage_min 0.1620 (0.1620) gate/usage_std 0.1213 (0.1213) teacher/entropy 0.0518 (0.0578) teacher/usage_max 0.4958 (0.5390) teacher/usage_min 0.0315 (0.0546) teacher/usage_std 0.2136 (0.2076) nleep/row_max_mean 1495.4625 (1504.7956) nleep/row_max_std 67.4411 (61.8090) nleep/row_min_mean 1469.1731 (1478.1442) lr 9.3721e-04 eta 0:07:06
epoch [28/50] batch [120/203] time 0.095 (0.093) data 0.000 (0.003) loss 1.2423 (1.2973) teacher_loss 0.0510 (0.1335) loss_zs_kd 0.0697 (0.0692) loss_oracle 0.5163 (0.5319) kd_loss 0.8983 (0.8632) acc 100.0000 (96.5625) gate/entropy 1.0237 (1.0237) gate/usage_max 0.4258 (0.4259) gate/usage_min 0.1620 (0.1620) gate/usage_std 0.1213 (0.1213) teacher/entropy 0.0543 (0.0564) teacher/usage_max 0.4609 (0.5413) teacher/usage_min 0.0871 (0.0517) teacher/usage_std 0.1741 (0.2101) nleep/row_max_mean 1506.3823 (1504.5032) nleep/row_max_std 56.6436 (61.9846) nleep/row_min_mean 1481.2759 (1477.8886) lr 9.3721e-04 eta 0:07:04
epoch [28/50] batch [140/203] time 0.086 (0.094) data 0.000 (0.003) loss 1.3869 (1.2963) teacher_loss 0.0996 (0.1308) loss_zs_kd 0.0755 (0.0690) loss_oracle 0.5865 (0.5334) kd_loss 0.9564 (0.8643) acc 96.8750 (96.7857) gate/entropy 1.0236 (1.0237) gate/usage_max 0.4257 (0.4258) gate/usage_min 0.1619 (0.1620) gate/usage_std 0.1214 (0.1213) teacher/entropy 0.0304 (0.0551) teacher/usage_max 0.4403 (0.5422) teacher/usage_min 0.1229 (0.0513) teacher/usage_std 0.1488 (0.2106) nleep/row_max_mean 1501.4764 (1504.5777) nleep/row_max_std 61.2743 (61.7698) nleep/row_min_mean 1474.3242 (1477.9462) lr 9.3721e-04 eta 0:07:04
epoch [28/50] batch [160/203] time 0.096 (0.094) data 0.000 (0.002) loss 1.2294 (1.2993) teacher_loss 0.0703 (0.1337) loss_zs_kd 0.0510 (0.0686) loss_oracle 0.4780 (0.5341) kd_loss 0.8946 (0.8643) acc 96.8750 (96.6992) gate/entropy 1.0235 (1.0237) gate/usage_max 0.4257 (0.4258) gate/usage_min 0.1618 (0.1619) gate/usage_std 0.1214 (0.1213) teacher/entropy 0.0820 (0.0556) teacher/usage_max 0.4781 (0.5436) teacher/usage_min 0.1137 (0.0518) teacher/usage_std 0.1579 (0.2107) nleep/row_max_mean 1522.6240 (1504.5417) nleep/row_max_std 48.0709 (61.8546) nleep/row_min_mean 1495.1404 (1477.9779) lr 9.3721e-04 eta 0:07:02
epoch [28/50] batch [180/203] time 0.148 (0.095) data 0.001 (0.002) loss 1.2981 (1.3040) teacher_loss 0.2687 (0.1404) loss_zs_kd 0.0420 (0.0682) loss_oracle 0.4474 (0.5335) kd_loss 0.7847 (0.8628) acc 90.6250 (96.5104) gate/entropy 1.0236 (1.0237) gate/usage_max 0.4257 (0.4258) gate/usage_min 0.1619 (0.1619) gate/usage_std 0.1214 (0.1213) teacher/entropy 0.1393 (0.0563) teacher/usage_max 0.5747 (0.5445) teacher/usage_min 0.0533 (0.0509) teacher/usage_std 0.2146 (0.2114) nleep/row_max_mean 1487.1482 (1503.9833) nleep/row_max_std 78.1076 (62.4910) nleep/row_min_mean 1462.7163 (1477.4444) lr 9.3721e-04 eta 0:07:08
epoch [28/50] batch [200/203] time 0.090 (0.095) data 0.000 (0.002) loss 1.3829 (1.3051) teacher_loss 0.1798 (0.1410) loss_zs_kd 0.0783 (0.0674) loss_oracle 0.5028 (0.5335) kd_loss 0.9126 (0.8636) acc 96.8750 (96.5000) gate/entropy 1.0234 (1.0236) gate/usage_max 0.4255 (0.4258) gate/usage_min 0.1617 (0.1619) gate/usage_std 0.1215 (0.1213) teacher/entropy 0.0659 (0.0563) teacher/usage_max 0.4930 (0.5434) teacher/usage_min 0.1156 (0.0518) teacher/usage_std 0.1594 (0.2107) nleep/row_max_mean 1517.2548 (1503.9069) nleep/row_max_std 37.3653 (62.2798) nleep/row_min_mean 1492.6533 (1477.3685) lr 9.3721e-04 eta 0:07:04
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,326
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [29/50] batch [20/203] time 0.091 (0.113) data 0.000 (0.015) loss 1.5129 (1.3717) teacher_loss 0.3497 (0.1950) loss_zs_kd 0.0861 (0.0713) loss_oracle 0.4840 (0.5327) kd_loss 0.8780 (0.8747) acc 93.7500 (94.6875) gate/entropy 1.0234 (1.0235) gate/usage_max 0.4256 (0.4256) gate/usage_min 0.1617 (0.1618) gate/usage_std 0.1215 (0.1214) teacher/entropy 0.0822 (0.0763) teacher/usage_max 0.4808 (0.5179) teacher/usage_min 0.0942 (0.0848) teacher/usage_std 0.1706 (0.1853) nleep/row_max_mean 1504.3630 (1499.4214) nleep/row_max_std 52.5147 (62.6282) nleep/row_min_mean 1481.9296 (1473.8713) lr 8.7467e-04 eta 0:08:23
epoch [29/50] batch [40/203] time 0.102 (0.102) data 0.000 (0.008) loss 1.3417 (1.3496) teacher_loss 0.1525 (0.1657) loss_zs_kd 0.0889 (0.0713) loss_oracle 0.5329 (0.5497) kd_loss 0.8783 (0.8734) acc 96.8750 (95.4688) gate/entropy 1.0236 (1.0235) gate/usage_max 0.4256 (0.4256) gate/usage_min 0.1619 (0.1617) gate/usage_std 0.1214 (0.1215) teacher/entropy 0.0250 (0.0633) teacher/usage_max 0.6058 (0.5192) teacher/usage_min 0.0313 (0.0697) teacher/usage_std 0.2355 (0.1941) nleep/row_max_mean 1496.0073 (1501.6414) nleep/row_max_std 61.4068 (62.8892) nleep/row_min_mean 1470.1748 (1475.3776) lr 8.7467e-04 eta 0:07:33
epoch [29/50] batch [60/203] time 0.091 (0.100) data 0.001 (0.005) loss 1.6628 (1.3709) teacher_loss 0.4915 (0.1811) loss_zs_kd 0.0567 (0.0726) loss_oracle 0.5620 (0.5573) kd_loss 0.8620 (0.8749) acc 84.3750 (94.8438) gate/entropy 1.0235 (1.0235) gate/usage_max 0.4256 (0.4256) gate/usage_min 0.1617 (0.1617) gate/usage_std 0.1215 (0.1215) teacher/entropy 0.0470 (0.0603) teacher/usage_max 0.6099 (0.5282) teacher/usage_min 0.0376 (0.0680) teacher/usage_std 0.2340 (0.1973) nleep/row_max_mean 1487.3701 (1501.6882) nleep/row_max_std 77.3850 (63.3203) nleep/row_min_mean 1458.5933 (1475.2358) lr 8.7467e-04 eta 0:07:18
epoch [29/50] batch [80/203] time 0.096 (0.099) data 0.000 (0.004) loss 1.2759 (1.3642) teacher_loss 0.0869 (0.1765) loss_zs_kd 0.0587 (0.0717) loss_oracle 0.5265 (0.5530) kd_loss 0.8964 (0.8754) acc 100.0000 (95.0781) gate/entropy 1.0233 (1.0234) gate/usage_max 0.4254 (0.4255) gate/usage_min 0.1615 (0.1617) gate/usage_std 0.1216 (0.1215) teacher/entropy 0.0412 (0.0612) teacher/usage_max 0.7326 (0.5342) teacher/usage_min 0.0634 (0.0692) teacher/usage_std 0.2881 (0.1991) nleep/row_max_mean 1501.9490 (1501.9963) nleep/row_max_std 64.3583 (63.2881) nleep/row_min_mean 1475.6685 (1475.4540) lr 8.7467e-04 eta 0:07:13
epoch [29/50] batch [100/203] time 0.094 (0.099) data 0.000 (0.003) loss 1.3312 (1.3524) teacher_loss 0.1584 (0.1698) loss_zs_kd 0.0785 (0.0714) loss_oracle 0.4753 (0.5448) kd_loss 0.8959 (0.8745) acc 96.8750 (95.2500) gate/entropy 1.0233 (1.0234) gate/usage_max 0.4253 (0.4255) gate/usage_min 0.1615 (0.1617) gate/usage_std 0.1216 (0.1215) teacher/entropy 0.0501 (0.0618) teacher/usage_max 0.6751 (0.5378) teacher/usage_min 0.0739 (0.0686) teacher/usage_std 0.2522 (0.2008) nleep/row_max_mean 1521.6680 (1502.0688) nleep/row_max_std 29.2197 (62.6624) nleep/row_min_mean 1495.1738 (1475.5273) lr 8.7467e-04 eta 0:07:10
epoch [29/50] batch [120/203] time 0.096 (0.098) data 0.000 (0.003) loss 1.4871 (1.3512) teacher_loss 0.2233 (0.1680) loss_zs_kd 0.0575 (0.0705) loss_oracle 0.5771 (0.5436) kd_loss 0.9465 (0.8762) acc 96.8750 (95.3385) gate/entropy 1.0234 (1.0234) gate/usage_max 0.4254 (0.4255) gate/usage_min 0.1616 (0.1617) gate/usage_std 0.1215 (0.1215) teacher/entropy 0.0120 (0.0619) teacher/usage_max 0.4996 (0.5402) teacher/usage_min 0.0956 (0.0705) teacher/usage_std 0.1725 (0.2010) nleep/row_max_mean 1513.3015 (1502.5153) nleep/row_max_std 43.6088 (62.1267) nleep/row_min_mean 1484.1594 (1475.8524) lr 8.7467e-04 eta 0:07:06
epoch [29/50] batch [140/203] time 0.100 (0.099) data 0.000 (0.002) loss 1.2517 (1.3468) teacher_loss 0.1094 (0.1672) loss_zs_kd 0.0726 (0.0693) loss_oracle 0.5371 (0.5390) kd_loss 0.8374 (0.8755) acc 96.8750 (95.2902) gate/entropy 1.0233 (1.0234) gate/usage_max 0.4253 (0.4255) gate/usage_min 0.1615 (0.1617) gate/usage_std 0.1216 (0.1215) teacher/entropy 0.0662 (0.0639) teacher/usage_max 0.5126 (0.5394) teacher/usage_min 0.0353 (0.0718) teacher/usage_std 0.2122 (0.2003) nleep/row_max_mean 1498.8690 (1502.3128) nleep/row_max_std 69.3619 (62.2021) nleep/row_min_mean 1469.6526 (1475.7233) lr 8.7467e-04 eta 0:07:06
epoch [29/50] batch [160/203] time 0.095 (0.098) data 0.000 (0.002) loss 1.3099 (1.3456) teacher_loss 0.1387 (0.1676) loss_zs_kd 0.0495 (0.0686) loss_oracle 0.5149 (0.5374) kd_loss 0.8889 (0.8750) acc 93.7500 (95.2344) gate/entropy 1.0233 (1.0234) gate/usage_max 0.4253 (0.4255) gate/usage_min 0.1615 (0.1616) gate/usage_std 0.1216 (0.1215) teacher/entropy 0.0942 (0.0646) teacher/usage_max 0.4841 (0.5431) teacher/usage_min 0.1177 (0.0719) teacher/usage_std 0.1564 (0.2013) nleep/row_max_mean 1500.7705 (1502.6509) nleep/row_max_std 68.1601 (62.1741) nleep/row_min_mean 1476.2000 (1476.0831) lr 8.7467e-04 eta 0:07:02
epoch [29/50] batch [180/203] time 0.091 (0.098) data 0.000 (0.002) loss 1.1960 (1.3415) teacher_loss 0.0787 (0.1640) loss_zs_kd 0.0651 (0.0695) loss_oracle 0.4805 (0.5341) kd_loss 0.8445 (0.8757) acc 96.8750 (95.2951) gate/entropy 1.0233 (1.0234) gate/usage_max 0.4252 (0.4254) gate/usage_min 0.1615 (0.1616) gate/usage_std 0.1216 (0.1215) teacher/entropy 0.0718 (0.0635) teacher/usage_max 0.5376 (0.5433) teacher/usage_min 0.0509 (0.0714) teacher/usage_std 0.2062 (0.2015) nleep/row_max_mean 1514.8491 (1502.7434) nleep/row_max_std 47.3126 (61.8590) nleep/row_min_mean 1490.2710 (1476.1205) lr 8.7467e-04 eta 0:06:59
epoch [29/50] batch [200/203] time 0.090 (0.097) data 0.000 (0.002) loss 1.4951 (1.3352) teacher_loss 0.4140 (0.1576) loss_zs_kd 0.0617 (0.0696) loss_oracle 0.4324 (0.5339) kd_loss 0.8341 (0.8759) acc 90.6250 (95.5625) gate/entropy 1.0231 (1.0234) gate/usage_max 0.4252 (0.4254) gate/usage_min 0.1614 (0.1616) gate/usage_std 0.1217 (0.1215) teacher/entropy 0.0890 (0.0639) teacher/usage_max 0.5009 (0.5400) teacher/usage_min 0.0552 (0.0722) teacher/usage_std 0.1980 (0.1999) nleep/row_max_mean 1489.3240 (1502.5943) nleep/row_max_std 81.7261 (62.2210) nleep/row_min_mean 1465.7687 (1476.1115) lr 8.7467e-04 eta 0:06:55
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,335
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [30/50] batch [20/203] time 0.172 (0.128) data 0.001 (0.019) loss 1.3440 (1.3363) teacher_loss 0.1375 (0.1392) loss_zs_kd 0.0747 (0.0761) loss_oracle 0.5354 (0.5338) kd_loss 0.9014 (0.8922) acc 96.8750 (96.2500) gate/entropy 1.0233 (1.0232) gate/usage_max 0.4252 (0.4252) gate/usage_min 0.1615 (0.1614) gate/usage_std 0.1216 (0.1217) teacher/entropy 0.0232 (0.0623) teacher/usage_max 0.5020 (0.5282) teacher/usage_min 0.0588 (0.0852) teacher/usage_std 0.1958 (0.1887) nleep/row_max_mean 1507.9836 (1501.9465) nleep/row_max_std 54.8256 (62.9680) nleep/row_min_mean 1478.7783 (1475.6333) lr 8.1262e-04 eta 0:09:01
epoch [30/50] batch [40/203] time 0.092 (0.115) data 0.000 (0.009) loss 1.3821 (1.3386) teacher_loss 0.2164 (0.1413) loss_zs_kd 0.0765 (0.0750) loss_oracle 0.4921 (0.5371) kd_loss 0.8813 (0.8912) acc 93.7500 (96.4062) gate/entropy 1.0234 (1.0232) gate/usage_max 0.4252 (0.4252) gate/usage_min 0.1616 (0.1614) gate/usage_std 0.1215 (0.1216) teacher/entropy 0.0822 (0.0619) teacher/usage_max 0.5475 (0.5343) teacher/usage_min 0.0959 (0.0852) teacher/usage_std 0.1851 (0.1899) nleep/row_max_mean 1484.2839 (1503.2597) nleep/row_max_std 68.6623 (60.8424) nleep/row_min_mean 1458.3464 (1476.3412) lr 8.1262e-04 eta 0:08:05
epoch [30/50] batch [60/203] time 0.098 (0.109) data 0.001 (0.006) loss 1.2670 (1.3405) teacher_loss 0.0991 (0.1390) loss_zs_kd 0.0682 (0.0730) loss_oracle 0.5223 (0.5364) kd_loss 0.8728 (0.8968) acc 96.8750 (96.5104) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4251 (0.4252) gate/usage_min 0.1614 (0.1614) gate/usage_std 0.1217 (0.1216) teacher/entropy 0.1139 (0.0677) teacher/usage_max 0.5241 (0.5314) teacher/usage_min 0.1254 (0.0976) teacher/usage_std 0.1632 (0.1833) nleep/row_max_mean 1489.8047 (1502.5217) nleep/row_max_std 74.5722 (60.6164) nleep/row_min_mean 1463.4648 (1475.8587) lr 8.1262e-04 eta 0:07:39
epoch [30/50] batch [80/203] time 0.094 (0.105) data 0.000 (0.005) loss 1.3861 (1.3509) teacher_loss 0.1974 (0.1324) loss_zs_kd 0.0679 (0.0737) loss_oracle 0.5340 (0.5421) kd_loss 0.8878 (0.9105) acc 96.8750 (96.7969) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4251 (0.4252) gate/usage_min 0.1614 (0.1614) gate/usage_std 0.1217 (0.1216) teacher/entropy 0.0675 (0.0686) teacher/usage_max 0.5453 (0.5188) teacher/usage_min 0.0873 (0.1135) teacher/usage_std 0.1885 (0.1718) nleep/row_max_mean 1500.8982 (1502.5417) nleep/row_max_std 61.9707 (59.9067) nleep/row_min_mean 1477.0707 (1475.9469) lr 8.1262e-04 eta 0:07:21
epoch [30/50] batch [100/203] time 0.098 (0.103) data 0.000 (0.004) loss 1.3993 (1.3655) teacher_loss 0.1196 (0.1395) loss_zs_kd 0.0641 (0.0731) loss_oracle 0.5329 (0.5433) kd_loss 0.9812 (0.9178) acc 96.8750 (96.5312) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4252 (0.4252) gate/usage_min 0.1614 (0.1614) gate/usage_std 0.1217 (0.1216) teacher/entropy 0.1532 (0.0718) teacher/usage_max 0.4265 (0.5138) teacher/usage_min 0.2758 (0.1246) teacher/usage_std 0.0665 (0.1650) nleep/row_max_mean 1505.5217 (1501.6708) nleep/row_max_std 62.3186 (60.6803) nleep/row_min_mean 1483.6133 (1475.3048) lr 8.1262e-04 eta 0:07:08
epoch [30/50] batch [120/203] time 0.105 (0.102) data 0.000 (0.003) loss 1.2005 (1.3757) teacher_loss 0.0630 (0.1479) loss_zs_kd 0.0578 (0.0720) loss_oracle 0.4683 (0.5414) kd_loss 0.8745 (0.9210) acc 100.0000 (96.3021) gate/entropy 1.0233 (1.0232) gate/usage_max 0.4251 (0.4252) gate/usage_min 0.1615 (0.1614) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.1484 (0.0739) teacher/usage_max 0.5020 (0.5073) teacher/usage_min 0.1584 (0.1302) teacher/usage_std 0.1403 (0.1600) nleep/row_max_mean 1485.6074 (1501.1972) nleep/row_max_std 71.2683 (61.3550) nleep/row_min_mean 1463.4810 (1474.9858) lr 8.1262e-04 eta 0:07:02
epoch [30/50] batch [140/203] time 0.100 (0.101) data 0.000 (0.003) loss 1.3885 (1.3866) teacher_loss 0.0696 (0.1511) loss_zs_kd 0.0774 (0.0723) loss_oracle 0.5849 (0.5430) kd_loss 0.9877 (0.9278) acc 100.0000 (96.2054) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4252 (0.4252) gate/usage_min 0.1615 (0.1614) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.0417 (0.0756) teacher/usage_max 0.4243 (0.5011) teacher/usage_min 0.1686 (0.1378) teacher/usage_std 0.1167 (0.1544) nleep/row_max_mean 1499.5260 (1500.8939) nleep/row_max_std 64.3256 (61.4815) nleep/row_min_mean 1468.6021 (1474.7239) lr 8.1262e-04 eta 0:06:58
epoch [30/50] batch [160/203] time 0.092 (0.101) data 0.000 (0.003) loss 1.4138 (1.3902) teacher_loss 0.0337 (0.1495) loss_zs_kd 0.0667 (0.0720) loss_oracle 0.5563 (0.5410) kd_loss 1.0686 (0.9342) acc 100.0000 (96.2500) gate/entropy 1.0233 (1.0232) gate/usage_max 0.4251 (0.4251) gate/usage_min 0.1616 (0.1614) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.0806 (0.0785) teacher/usage_max 0.4274 (0.4957) teacher/usage_min 0.2810 (0.1462) teacher/usage_std 0.0667 (0.1487) nleep/row_max_mean 1495.9805 (1500.8026) nleep/row_max_std 63.9202 (61.5181) nleep/row_min_mean 1471.9401 (1474.6022) lr 8.1262e-04 eta 0:06:52
epoch [30/50] batch [180/203] time 0.101 (0.100) data 0.000 (0.002) loss 1.3741 (1.3954) teacher_loss 0.0628 (0.1500) loss_zs_kd 0.0660 (0.0715) loss_oracle 0.4978 (0.5398) kd_loss 1.0295 (0.9398) acc 100.0000 (96.2674) gate/entropy 1.0233 (1.0232) gate/usage_max 0.4252 (0.4251) gate/usage_min 0.1615 (0.1614) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.1235 (0.0790) teacher/usage_max 0.3867 (0.4928) teacher/usage_min 0.2964 (0.1511) teacher/usage_std 0.0387 (0.1453) nleep/row_max_mean 1489.3219 (1500.4780) nleep/row_max_std 66.5092 (61.5790) nleep/row_min_mean 1469.5854 (1474.3395) lr 8.1262e-04 eta 0:06:49
epoch [30/50] batch [200/203] time 0.087 (0.100) data 0.000 (0.002) loss 1.3437 (1.3950) teacher_loss 0.2073 (0.1500) loss_zs_kd 0.0624 (0.0717) loss_oracle 0.5199 (0.5408) kd_loss 0.8452 (0.9388) acc 93.7500 (96.2500) gate/entropy 1.0231 (1.0232) gate/usage_max 0.4251 (0.4251) gate/usage_min 0.1613 (0.1614) gate/usage_std 0.1217 (0.1216) teacher/entropy 0.1126 (0.0802) teacher/usage_max 0.6987 (0.4930) teacher/usage_min 0.0999 (0.1515) teacher/usage_std 0.2617 (0.1452) nleep/row_max_mean 1484.7200 (1500.2643) nleep/row_max_std 91.2139 (61.9740) nleep/row_min_mean 1459.5095 (1474.2004) lr 8.1262e-04 eta 0:06:45
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,329
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [31/50] batch [20/203] time 0.101 (0.118) data 0.001 (0.020) loss 1.2830 (1.3806) teacher_loss 0.0629 (0.1150) loss_zs_kd 0.0635 (0.0804) loss_oracle 0.5455 (0.5545) kd_loss 0.9156 (0.9481) acc 100.0000 (97.1875) gate/entropy 1.0233 (1.0233) gate/usage_max 0.4252 (0.4251) gate/usage_min 0.1616 (0.1615) gate/usage_std 0.1215 (0.1216) teacher/entropy 0.0396 (0.0751) teacher/usage_max 0.5571 (0.5005) teacher/usage_min 0.0930 (0.1599) teacher/usage_std 0.1899 (0.1446) nleep/row_max_mean 1486.8412 (1496.2458) nleep/row_max_std 77.3681 (64.1654) nleep/row_min_mean 1463.1096 (1470.1170) lr 7.5131e-04 eta 0:07:56
epoch [31/50] batch [40/203] time 0.080 (0.103) data 0.000 (0.010) loss 1.2905 (1.3949) teacher_loss 0.1570 (0.1447) loss_zs_kd 0.0685 (0.0747) loss_oracle 0.4965 (0.5412) kd_loss 0.8510 (0.9422) acc 96.8750 (96.3281) gate/entropy 1.0233 (1.0233) gate/usage_max 0.4252 (0.4251) gate/usage_min 0.1616 (0.1615) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.0995 (0.0708) teacher/usage_max 0.5305 (0.5015) teacher/usage_min 0.0832 (0.1495) teacher/usage_std 0.1864 (0.1493) nleep/row_max_mean 1478.9277 (1496.3662) nleep/row_max_std 83.2172 (63.6262) nleep/row_min_mean 1453.7456 (1470.0277) lr 7.5131e-04 eta 0:06:53
epoch [31/50] batch [60/203] time 0.093 (0.098) data 0.001 (0.007) loss 1.4138 (1.3760) teacher_loss 0.1984 (0.1378) loss_zs_kd 0.0683 (0.0730) loss_oracle 0.5089 (0.5332) kd_loss 0.9268 (0.9351) acc 93.7500 (96.5104) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4251 (0.4251) gate/usage_min 0.1614 (0.1615) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.0718 (0.0691) teacher/usage_max 0.5295 (0.4993) teacher/usage_min 0.1328 (0.1404) teacher/usage_std 0.1620 (0.1525) nleep/row_max_mean 1503.8138 (1497.0894) nleep/row_max_std 61.1338 (63.2735) nleep/row_min_mean 1474.4746 (1470.7927) lr 7.5131e-04 eta 0:06:32
epoch [31/50] batch [80/203] time 0.074 (0.095) data 0.000 (0.005) loss 1.5588 (1.3825) teacher_loss 0.2150 (0.1416) loss_zs_kd 0.0661 (0.0727) loss_oracle 0.7189 (0.5402) kd_loss 0.9513 (0.9344) acc 93.7500 (96.4062) gate/entropy 1.0233 (1.0232) gate/usage_max 0.4251 (0.4251) gate/usage_min 0.1615 (0.1615) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.0905 (0.0670) teacher/usage_max 0.4267 (0.4990) teacher/usage_min 0.1817 (0.1375) teacher/usage_std 0.1081 (0.1538) nleep/row_max_mean 1492.7725 (1497.4411) nleep/row_max_std 61.7847 (63.4741) nleep/row_min_mean 1468.6740 (1471.1813) lr 7.5131e-04 eta 0:06:19
epoch [31/50] batch [100/203] time 0.083 (0.092) data 0.000 (0.004) loss 1.3964 (1.3892) teacher_loss 0.1452 (0.1467) loss_zs_kd 0.0735 (0.0717) loss_oracle 0.4979 (0.5413) kd_loss 0.9655 (0.9360) acc 93.7500 (96.1250) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4251 (0.4251) gate/usage_min 0.1614 (0.1615) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.0592 (0.0670) teacher/usage_max 0.4834 (0.5000) teacher/usage_min 0.1611 (0.1392) teacher/usage_std 0.1325 (0.1537) nleep/row_max_mean 1517.0674 (1497.2389) nleep/row_max_std 45.3495 (64.0800) nleep/row_min_mean 1488.0338 (1471.1343) lr 7.5131e-04 eta 0:06:05
epoch [31/50] batch [120/203] time 0.082 (0.092) data 0.000 (0.004) loss 1.5153 (1.3990) teacher_loss 0.2687 (0.1579) loss_zs_kd 0.0701 (0.0710) loss_oracle 0.5135 (0.5388) kd_loss 0.9548 (0.9362) acc 96.8750 (95.8594) gate/entropy 1.0231 (1.0232) gate/usage_max 0.4251 (0.4251) gate/usage_min 0.1613 (0.1615) gate/usage_std 0.1217 (0.1216) teacher/entropy 0.0389 (0.0707) teacher/usage_max 0.4637 (0.4967) teacher/usage_min 0.1309 (0.1433) teacher/usage_std 0.1451 (0.1509) nleep/row_max_mean 1480.2178 (1497.5605) nleep/row_max_std 84.0285 (64.3491) nleep/row_min_mean 1458.2484 (1471.6498) lr 7.5131e-04 eta 0:06:04
epoch [31/50] batch [140/203] time 0.086 (0.091) data 0.000 (0.003) loss 1.2931 (1.3902) teacher_loss 0.1157 (0.1504) loss_zs_kd 0.0770 (0.0696) loss_oracle 0.5143 (0.5376) kd_loss 0.8818 (0.9362) acc 96.8750 (96.1607) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4251 (0.4251) gate/usage_min 0.1615 (0.1615) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.0866 (0.0712) teacher/usage_max 0.5148 (0.4972) teacher/usage_min 0.1056 (0.1438) teacher/usage_std 0.1703 (0.1506) nleep/row_max_mean 1487.5400 (1497.7407) nleep/row_max_std 74.8453 (64.3327) nleep/row_min_mean 1462.6152 (1471.9938) lr 7.5131e-04 eta 0:05:58
epoch [31/50] batch [160/203] time 0.074 (0.090) data 0.000 (0.003) loss 1.2984 (1.3879) teacher_loss 0.1564 (0.1487) loss_zs_kd 0.0801 (0.0703) loss_oracle 0.4384 (0.5382) kd_loss 0.8828 (0.9349) acc 93.7500 (96.1914) gate/entropy 1.0234 (1.0232) gate/usage_max 0.4251 (0.4251) gate/usage_min 0.1616 (0.1615) gate/usage_std 0.1215 (0.1216) teacher/entropy 0.0930 (0.0732) teacher/usage_max 0.5428 (0.4973) teacher/usage_min 0.1088 (0.1444) teacher/usage_std 0.1775 (0.1503) nleep/row_max_mean 1508.8502 (1498.3486) nleep/row_max_std 47.1424 (64.2163) nleep/row_min_mean 1480.8782 (1472.6946) lr 7.5131e-04 eta 0:05:52
epoch [31/50] batch [180/203] time 0.098 (0.090) data 0.000 (0.002) loss 1.3555 (1.3922) teacher_loss 0.1597 (0.1502) loss_zs_kd 0.0536 (0.0702) loss_oracle 0.4428 (0.5409) kd_loss 0.9476 (0.9365) acc 93.7500 (96.0764) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4250 (0.4251) gate/usage_min 0.1614 (0.1615) gate/usage_std 0.1217 (0.1216) teacher/entropy 0.0471 (0.0724) teacher/usage_max 0.5275 (0.4994) teacher/usage_min 0.1288 (0.1445) teacher/usage_std 0.1629 (0.1512) nleep/row_max_mean 1514.0646 (1498.6155) nleep/row_max_std 56.9654 (64.1789) nleep/row_min_mean 1485.3247 (1472.9708) lr 7.5131e-04 eta 0:05:48
epoch [31/50] batch [200/203] time 0.087 (0.089) data 0.000 (0.002) loss 1.3783 (1.3896) teacher_loss 0.2123 (0.1489) loss_zs_kd 0.0812 (0.0702) loss_oracle 0.5330 (0.5418) kd_loss 0.8589 (0.9347) acc 93.7500 (96.0938) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4250 (0.4251) gate/usage_min 0.1614 (0.1615) gate/usage_std 0.1217 (0.1216) teacher/entropy 0.0748 (0.0727) teacher/usage_max 0.4827 (0.5005) teacher/usage_min 0.0670 (0.1431) teacher/usage_std 0.1888 (0.1523) nleep/row_max_mean 1476.5718 (1498.6916) nleep/row_max_std 89.1616 (64.4162) nleep/row_min_mean 1454.5616 (1473.0698) lr 7.5131e-04 eta 0:05:43
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,327
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [32/50] batch [20/203] time 0.098 (0.110) data 0.000 (0.017) loss 1.4260 (1.3852) teacher_loss 0.1705 (0.1444) loss_zs_kd 0.0757 (0.0720) loss_oracle 0.5553 (0.5683) kd_loss 0.9400 (0.9206) acc 96.8750 (96.4062) gate/entropy 1.0233 (1.0232) gate/usage_max 0.4251 (0.4250) gate/usage_min 0.1615 (0.1614) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.0995 (0.0739) teacher/usage_max 0.5395 (0.5135) teacher/usage_min 0.1749 (0.1273) teacher/usage_std 0.1526 (0.1653) nleep/row_max_mean 1490.5710 (1501.9431) nleep/row_max_std 71.5843 (63.7192) nleep/row_min_mean 1466.4686 (1475.3848) lr 6.9098e-04 eta 0:07:01
epoch [32/50] batch [40/203] time 0.095 (0.102) data 0.000 (0.009) loss 1.4470 (1.3816) teacher_loss 0.1005 (0.1398) loss_zs_kd 0.0718 (0.0740) loss_oracle 0.6075 (0.5673) kd_loss 1.0069 (0.9212) acc 96.8750 (96.4844) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4250 (0.4250) gate/usage_min 0.1614 (0.1614) gate/usage_std 0.1217 (0.1217) teacher/entropy 0.1180 (0.0754) teacher/usage_max 0.4247 (0.5083) teacher/usage_min 0.2700 (0.1310) teacher/usage_std 0.0662 (0.1618) nleep/row_max_mean 1488.4147 (1501.3849) nleep/row_max_std 81.1485 (63.7452) nleep/row_min_mean 1469.4440 (1475.1373) lr 6.9098e-04 eta 0:06:29
epoch [32/50] batch [60/203] time 0.099 (0.099) data 0.001 (0.006) loss 1.2614 (1.3839) teacher_loss 0.1215 (0.1408) loss_zs_kd 0.0929 (0.0745) loss_oracle 0.5005 (0.5705) kd_loss 0.8433 (0.9205) acc 96.8750 (96.3542) gate/entropy 1.0231 (1.0232) gate/usage_max 0.4250 (0.4250) gate/usage_min 0.1614 (0.1614) gate/usage_std 0.1217 (0.1217) teacher/entropy 0.1169 (0.0731) teacher/usage_max 0.5736 (0.5076) teacher/usage_min 0.0924 (0.1284) teacher/usage_std 0.1964 (0.1624) nleep/row_max_mean 1514.1195 (1500.2464) nleep/row_max_std 51.4667 (64.9504) nleep/row_min_mean 1489.3582 (1473.9169) lr 6.9098e-04 eta 0:06:17
epoch [32/50] batch [80/203] time 0.096 (0.100) data 0.000 (0.005) loss 1.3893 (1.3838) teacher_loss 0.0509 (0.1391) loss_zs_kd 0.0668 (0.0763) loss_oracle 0.6453 (0.5699) kd_loss 0.9823 (0.9216) acc 100.0000 (96.3672) gate/entropy 1.0233 (1.0232) gate/usage_max 0.4251 (0.4250) gate/usage_min 0.1615 (0.1614) gate/usage_std 0.1216 (0.1217) teacher/entropy 0.0501 (0.0738) teacher/usage_max 0.5433 (0.5062) teacher/usage_min 0.1752 (0.1308) teacher/usage_std 0.1547 (0.1605) nleep/row_max_mean 1509.2351 (1500.6211) nleep/row_max_std 46.6290 (63.7404) nleep/row_min_mean 1480.1976 (1474.2478) lr 6.9098e-04 eta 0:06:18
epoch [32/50] batch [100/203] time 0.102 (0.099) data 0.000 (0.004) loss 1.3155 (1.3765) teacher_loss 0.1589 (0.1388) loss_zs_kd 0.0665 (0.0762) loss_oracle 0.5834 (0.5656) kd_loss 0.8317 (0.9168) acc 93.7500 (96.4375) gate/entropy 1.0231 (1.0232) gate/usage_max 0.4250 (0.4250) gate/usage_min 0.1613 (0.1614) gate/usage_std 0.1217 (0.1217) teacher/entropy 0.1248 (0.0750) teacher/usage_max 0.4723 (0.5044) teacher/usage_min 0.0919 (0.1272) teacher/usage_std 0.1713 (0.1614) nleep/row_max_mean 1499.7657 (1500.3728) nleep/row_max_std 67.0058 (64.1631) nleep/row_min_mean 1474.7379 (1473.9006) lr 6.9098e-04 eta 0:06:13
epoch [32/50] batch [120/203] time 0.101 (0.099) data 0.000 (0.003) loss 1.3547 (1.3733) teacher_loss 0.0283 (0.1367) loss_zs_kd 0.0615 (0.0747) loss_oracle 0.5965 (0.5653) kd_loss 0.9974 (0.9167) acc 100.0000 (96.4323) gate/entropy 1.0233 (1.0232) gate/usage_max 0.4250 (0.4250) gate/usage_min 0.1615 (0.1614) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.0574 (0.0728) teacher/usage_max 0.4258 (0.5055) teacher/usage_min 0.1941 (0.1250) teacher/usage_std 0.1002 (0.1626) nleep/row_max_mean 1506.8121 (1500.8825) nleep/row_max_std 47.3777 (63.6713) nleep/row_min_mean 1478.7854 (1474.3671) lr 6.9098e-04 eta 0:06:08
epoch [32/50] batch [140/203] time 0.104 (0.098) data 0.000 (0.003) loss 1.2249 (1.3716) teacher_loss 0.0375 (0.1382) loss_zs_kd 0.0775 (0.0739) loss_oracle 0.5443 (0.5640) kd_loss 0.8765 (0.9145) acc 100.0000 (96.4062) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4250 (0.4250) gate/usage_min 0.1614 (0.1614) gate/usage_std 0.1217 (0.1217) teacher/entropy 0.0294 (0.0713) teacher/usage_max 0.5604 (0.5072) teacher/usage_min 0.0364 (0.1212) teacher/usage_std 0.2195 (0.1648) nleep/row_max_mean 1490.0771 (1500.8809) nleep/row_max_std 74.3176 (64.0643) nleep/row_min_mean 1466.0687 (1474.3697) lr 6.9098e-04 eta 0:06:05
epoch [32/50] batch [160/203] time 0.101 (0.098) data 0.001 (0.002) loss 1.3253 (1.3676) teacher_loss 0.1465 (0.1378) loss_zs_kd 0.0625 (0.0738) loss_oracle 0.4684 (0.5626) kd_loss 0.9134 (0.9115) acc 96.8750 (96.3672) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4250 (0.4250) gate/usage_min 0.1614 (0.1614) gate/usage_std 0.1216 (0.1217) teacher/entropy 0.0809 (0.0683) teacher/usage_max 0.5925 (0.5082) teacher/usage_min 0.1266 (0.1151) teacher/usage_std 0.1938 (0.1684) nleep/row_max_mean 1473.9293 (1500.7963) nleep/row_max_std 89.3999 (64.3825) nleep/row_min_mean 1449.3551 (1474.0918) lr 6.9098e-04 eta 0:06:02
epoch [32/50] batch [180/203] time 0.092 (0.097) data 0.000 (0.002) loss 1.3546 (1.3650) teacher_loss 0.0653 (0.1372) loss_zs_kd 0.0991 (0.0750) loss_oracle 0.6077 (0.5610) kd_loss 0.9359 (0.9097) acc 96.8750 (96.3368) gate/entropy 1.0233 (1.0232) gate/usage_max 0.4250 (0.4250) gate/usage_min 0.1615 (0.1614) gate/usage_std 0.1216 (0.1217) teacher/entropy 0.0348 (0.0672) teacher/usage_max 0.5292 (0.5108) teacher/usage_min 0.1047 (0.1121) teacher/usage_std 0.1748 (0.1705) nleep/row_max_mean 1515.6583 (1501.0823) nleep/row_max_std 30.9605 (64.0316) nleep/row_min_mean 1487.3054 (1474.2614) lr 6.9098e-04 eta 0:05:58
epoch [32/50] batch [200/203] time 0.078 (0.097) data 0.000 (0.002) loss 1.4447 (1.3631) teacher_loss 0.2376 (0.1367) loss_zs_kd 0.0875 (0.0753) loss_oracle 0.5835 (0.5600) kd_loss 0.8716 (0.9088) acc 90.6250 (96.3281) gate/entropy 1.0232 (1.0232) gate/usage_max 0.4250 (0.4250) gate/usage_min 0.1614 (0.1614) gate/usage_std 0.1216 (0.1217) teacher/entropy 0.0774 (0.0656) teacher/usage_max 0.5792 (0.5122) teacher/usage_min 0.0803 (0.1095) teacher/usage_std 0.2037 (0.1721) nleep/row_max_mean 1500.0464 (1500.8809) nleep/row_max_std 54.1988 (64.1433) nleep/row_min_mean 1470.3801 (1473.9813) lr 6.9098e-04 eta 0:05:54
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,334
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [33/50] batch [20/203] time 0.086 (0.108) data 0.000 (0.017) loss 1.3380 (1.3145) teacher_loss 0.1824 (0.1346) loss_zs_kd 0.0627 (0.0696) loss_oracle 0.5876 (0.5430) kd_loss 0.8304 (0.8735) acc 90.6250 (96.4062) gate/entropy 1.0231 (1.0232) gate/usage_max 0.4250 (0.4250) gate/usage_min 0.1614 (0.1614) gate/usage_std 0.1217 (0.1217) teacher/entropy 0.1247 (0.0742) teacher/usage_max 0.4801 (0.5007) teacher/usage_min 0.0904 (0.0827) teacher/usage_std 0.1730 (0.1831) nleep/row_max_mean 1488.2996 (1501.6987) nleep/row_max_std 82.9381 (64.8847) nleep/row_min_mean 1460.7893 (1473.7125) lr 6.3188e-04 eta 0:06:33
epoch [33/50] batch [40/203] time 0.096 (0.099) data 0.000 (0.008) loss 1.4565 (1.3356) teacher_loss 0.1807 (0.1302) loss_zs_kd 0.0912 (0.0717) loss_oracle 0.7018 (0.5627) kd_loss 0.8794 (0.8882) acc 96.8750 (96.8750) gate/entropy 1.0231 (1.0232) gate/usage_max 0.4250 (0.4250) gate/usage_min 0.1613 (0.1614) gate/usage_std 0.1217 (0.1217) teacher/entropy 0.0880 (0.0623) teacher/usage_max 0.5061 (0.5118) teacher/usage_min 0.1041 (0.0855) teacher/usage_std 0.1689 (0.1848) nleep/row_max_mean 1500.4307 (1500.2894) nleep/row_max_std 69.6380 (67.0055) nleep/row_min_mean 1471.2734 (1472.7509) lr 6.3188e-04 eta 0:05:58
epoch [33/50] batch [60/203] time 0.102 (0.098) data 0.001 (0.006) loss 1.3674 (1.3307) teacher_loss 0.1379 (0.1225) loss_zs_kd 0.0779 (0.0742) loss_oracle 0.5435 (0.5642) kd_loss 0.9188 (0.8890) acc 96.8750 (96.9271) gate/entropy 1.0231 (1.0232) gate/usage_max 0.4250 (0.4250) gate/usage_min 0.1613 (0.1614) gate/usage_std 0.1217 (0.1217) teacher/entropy 0.0434 (0.0546) teacher/usage_max 0.4712 (0.5228) teacher/usage_min 0.0964 (0.0780) teacher/usage_std 0.1683 (0.1918) nleep/row_max_mean 1510.4000 (1500.7101) nleep/row_max_std 58.9355 (65.2626) nleep/row_min_mean 1486.2546 (1473.2066) lr 6.3188e-04 eta 0:05:51
epoch [33/50] batch [80/203] time 0.089 (0.097) data 0.000 (0.004) loss 1.2006 (1.3346) teacher_loss 0.0529 (0.1277) loss_zs_kd 0.0937 (0.0752) loss_oracle 0.5274 (0.5656) kd_loss 0.8372 (0.8865) acc 100.0000 (96.8750) gate/entropy 1.0231 (1.0232) gate/usage_max 0.4249 (0.4250) gate/usage_min 0.1613 (0.1614) gate/usage_std 0.1217 (0.1217) teacher/entropy 0.0498 (0.0549) teacher/usage_max 0.5317 (0.5259) teacher/usage_min 0.0197 (0.0753) teacher/usage_std 0.2244 (0.1941) nleep/row_max_mean 1508.3901 (1500.2312) nleep/row_max_std 53.4300 (64.8386) nleep/row_min_mean 1480.8320 (1472.8905) lr 6.3188e-04 eta 0:05:48
epoch [33/50] batch [100/203] time 0.083 (0.096) data 0.000 (0.004) loss 1.2119 (1.3344) teacher_loss 0.0536 (0.1297) loss_zs_kd 0.0821 (0.0752) loss_oracle 0.4875 (0.5645) kd_loss 0.8735 (0.8848) acc 100.0000 (96.8125) gate/entropy 1.0233 (1.0232) gate/usage_max 0.4250 (0.4250) gate/usage_min 0.1615 (0.1614) gate/usage_std 0.1216 (0.1217) teacher/entropy 0.0885 (0.0509) teacher/usage_max 0.4711 (0.5303) teacher/usage_min 0.0980 (0.0692) teacher/usage_std 0.1672 (0.1985) nleep/row_max_mean 1476.6082 (1499.7517) nleep/row_max_std 71.6870 (64.9458) nleep/row_min_mean 1453.8805 (1472.3428) lr 6.3188e-04 eta 0:05:42
epoch [33/50] batch [120/203] time 0.090 (0.095) data 0.000 (0.003) loss 1.1660 (1.3306) teacher_loss 0.0291 (0.1279) loss_zs_kd 0.0812 (0.0755) loss_oracle 0.4690 (0.5633) kd_loss 0.8617 (0.8832) acc 100.0000 (96.7448) gate/entropy 1.0232 (1.0231) gate/usage_max 0.4250 (0.4249) gate/usage_min 0.1614 (0.1614) gate/usage_std 0.1217 (0.1217) teacher/entropy 0.0847 (0.0509) teacher/usage_max 0.5040 (0.5328) teacher/usage_min 0.0796 (0.0677) teacher/usage_std 0.1829 (0.1999) nleep/row_max_mean 1516.1783 (1500.5725) nleep/row_max_std 32.7874 (63.9655) nleep/row_min_mean 1487.7816 (1473.0440) lr 6.3188e-04 eta 0:05:35
epoch [33/50] batch [140/203] time 0.079 (0.095) data 0.000 (0.003) loss 1.2898 (1.3248) teacher_loss 0.0942 (0.1258) loss_zs_kd 0.0877 (0.0747) loss_oracle 0.5406 (0.5606) kd_loss 0.8814 (0.8813) acc 96.8750 (96.7634) gate/entropy 1.0230 (1.0231) gate/usage_max 0.4249 (0.4249) gate/usage_min 0.1612 (0.1613) gate/usage_std 0.1218 (0.1217) teacher/entropy 0.0285 (0.0494) teacher/usage_max 0.5916 (0.5361) teacher/usage_min 0.0396 (0.0643) teacher/usage_std 0.2267 (0.2025) nleep/row_max_mean 1490.1528 (1500.5986) nleep/row_max_std 78.6070 (63.9342) nleep/row_min_mean 1463.9561 (1472.9762) lr 6.3188e-04 eta 0:05:34
epoch [33/50] batch [160/203] time 0.155 (0.097) data 0.001 (0.002) loss 1.2556 (1.3294) teacher_loss 0.0724 (0.1307) loss_zs_kd 0.0713 (0.0739) loss_oracle 0.4994 (0.5609) kd_loss 0.8979 (0.8813) acc 100.0000 (96.6016) gate/entropy 1.0233 (1.0231) gate/usage_max 0.4249 (0.4249) gate/usage_min 0.1616 (0.1613) gate/usage_std 0.1216 (0.1217) teacher/entropy 0.0928 (0.0491) teacher/usage_max 0.6116 (0.5394) teacher/usage_min 0.1222 (0.0640) teacher/usage_std 0.2054 (0.2036) nleep/row_max_mean 1501.8491 (1500.1261) nleep/row_max_std 50.9847 (64.0273) nleep/row_min_mean 1475.0725 (1472.4722) lr 6.3188e-04 eta 0:05:37
epoch [33/50] batch [180/203] time 0.099 (0.096) data 0.000 (0.002) loss 1.2592 (1.3291) teacher_loss 0.0712 (0.1332) loss_zs_kd 0.0764 (0.0737) loss_oracle 0.6278 (0.5603) kd_loss 0.8360 (0.8788) acc 96.8750 (96.4583) gate/entropy 1.0232 (1.0231) gate/usage_max 0.4250 (0.4249) gate/usage_min 0.1614 (0.1613) gate/usage_std 0.1217 (0.1217) teacher/entropy 0.0639 (0.0487) teacher/usage_max 0.5348 (0.5394) teacher/usage_min 0.0306 (0.0610) teacher/usage_std 0.2180 (0.2053) nleep/row_max_mean 1493.6765 (1499.5740) nleep/row_max_std 66.1561 (64.6285) nleep/row_min_mean 1463.6124 (1471.9188) lr 6.3188e-04 eta 0:05:34
epoch [33/50] batch [200/203] time 0.091 (0.096) data 0.000 (0.002) loss 1.2162 (1.3291) teacher_loss 0.0727 (0.1346) loss_zs_kd 0.0622 (0.0736) loss_oracle 0.5455 (0.5596) kd_loss 0.8397 (0.8779) acc 100.0000 (96.4375) gate/entropy 1.0230 (1.0231) gate/usage_max 0.4249 (0.4249) gate/usage_min 0.1612 (0.1613) gate/usage_std 0.1218 (0.1217) teacher/entropy 0.0615 (0.0479) teacher/usage_max 0.4986 (0.5389) teacher/usage_min 0.0342 (0.0592) teacher/usage_std 0.2119 (0.2060) nleep/row_max_mean 1514.4839 (1499.5489) nleep/row_max_std 43.8048 (64.7402) nleep/row_min_mean 1484.8507 (1471.8201) lr 6.3188e-04 eta 0:05:31
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,334
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [34/50] batch [20/203] time 0.099 (0.114) data 0.001 (0.017) loss 1.2660 (1.3065) teacher_loss 0.0392 (0.1368) loss_zs_kd 0.0791 (0.0719) loss_oracle 0.5396 (0.5302) kd_loss 0.9174 (0.8687) acc 100.0000 (96.8750) gate/entropy 1.0230 (1.0231) gate/usage_max 0.4249 (0.4249) gate/usage_min 0.1612 (0.1613) gate/usage_std 0.1218 (0.1217) teacher/entropy 0.0339 (0.0391) teacher/usage_max 0.5634 (0.5432) teacher/usage_min 0.0838 (0.0396) teacher/usage_std 0.1963 (0.2166) nleep/row_max_mean 1518.4661 (1498.3723) nleep/row_max_std 24.6925 (64.5741) nleep/row_min_mean 1487.0334 (1470.0955) lr 5.7422e-04 eta 0:06:30
epoch [34/50] batch [40/203] time 0.085 (0.103) data 0.000 (0.009) loss 1.4326 (1.3201) teacher_loss 0.2651 (0.1431) loss_zs_kd 0.0626 (0.0724) loss_oracle 0.4791 (0.5408) kd_loss 0.8967 (0.8703) acc 93.7500 (96.3281) gate/entropy 1.0230 (1.0230) gate/usage_max 0.4248 (0.4249) gate/usage_min 0.1612 (0.1612) gate/usage_std 0.1218 (0.1218) teacher/entropy 0.0057 (0.0350) teacher/usage_max 0.5933 (0.5446) teacher/usage_min 0.0318 (0.0374) teacher/usage_std 0.2311 (0.2190) nleep/row_max_mean 1499.6569 (1500.3570) nleep/row_max_std 61.4660 (64.9475) nleep/row_min_mean 1474.0593 (1471.8130) lr 5.7422e-04 eta 0:05:52
epoch [34/50] batch [60/203] time 0.095 (0.106) data 0.001 (0.006) loss 1.2348 (1.3107) teacher_loss 0.0532 (0.1392) loss_zs_kd 0.0635 (0.0717) loss_oracle 0.4819 (0.5310) kd_loss 0.9089 (0.8703) acc 100.0000 (96.5625) gate/entropy 1.0229 (1.0230) gate/usage_max 0.4248 (0.4249) gate/usage_min 0.1611 (0.1612) gate/usage_std 0.1218 (0.1218) teacher/entropy 0.0390 (0.0384) teacher/usage_max 0.5156 (0.5452) teacher/usage_min 0.0812 (0.0410) teacher/usage_std 0.1841 (0.2170) nleep/row_max_mean 1509.4655 (1499.9067) nleep/row_max_std 48.8461 (64.8471) nleep/row_min_mean 1487.8652 (1471.8687) lr 5.7422e-04 eta 0:05:58
epoch [34/50] batch [80/203] time 0.098 (0.103) data 0.000 (0.005) loss 1.2463 (1.3108) teacher_loss 0.0444 (0.1387) loss_zs_kd 0.0502 (0.0701) loss_oracle 0.5323 (0.5300) kd_loss 0.9106 (0.8720) acc 100.0000 (96.6016) gate/entropy 1.0231 (1.0230) gate/usage_max 0.4248 (0.4249) gate/usage_min 0.1613 (0.1612) gate/usage_std 0.1217 (0.1218) teacher/entropy 0.0323 (0.0414) teacher/usage_max 0.4695 (0.5427) teacher/usage_min 0.0772 (0.0460) teacher/usage_std 0.1812 (0.2135) nleep/row_max_mean 1479.0535 (1500.1444) nleep/row_max_std 69.1203 (63.5169) nleep/row_min_mean 1451.8271 (1472.3636) lr 5.7422e-04 eta 0:05:48
epoch [34/50] batch [100/203] time 0.095 (0.101) data 0.000 (0.004) loss 1.2474 (1.3045) teacher_loss 0.0863 (0.1339) loss_zs_kd 0.0822 (0.0702) loss_oracle 0.5475 (0.5334) kd_loss 0.8463 (0.8688) acc 100.0000 (96.6250) gate/entropy 1.0230 (1.0230) gate/usage_max 0.4248 (0.4249) gate/usage_min 0.1612 (0.1612) gate/usage_std 0.1218 (0.1218) teacher/entropy 0.0899 (0.0433) teacher/usage_max 0.5483 (0.5425) teacher/usage_min 0.0683 (0.0446) teacher/usage_std 0.1991 (0.2139) nleep/row_max_mean 1511.5452 (1500.3907) nleep/row_max_std 56.3534 (63.3638) nleep/row_min_mean 1486.1475 (1472.6776) lr 5.7422e-04 eta 0:05:38
epoch [34/50] batch [120/203] time 0.107 (0.100) data 0.000 (0.003) loss 1.3372 (1.3077) teacher_loss 0.1547 (0.1368) loss_zs_kd 0.0767 (0.0712) loss_oracle 0.5337 (0.5369) kd_loss 0.8773 (0.8669) acc 93.7500 (96.5104) gate/entropy 1.0229 (1.0230) gate/usage_max 0.4248 (0.4249) gate/usage_min 0.1611 (0.1612) gate/usage_std 0.1218 (0.1218) teacher/entropy 0.0488 (0.0439) teacher/usage_max 0.5313 (0.5439) teacher/usage_min 0.0581 (0.0432) teacher/usage_std 0.2008 (0.2150) nleep/row_max_mean 1508.3228 (1499.9877) nleep/row_max_std 57.9599 (63.8107) nleep/row_min_mean 1483.1812 (1472.4196) lr 5.7422e-04 eta 0:05:33
epoch [34/50] batch [140/203] time 0.101 (0.100) data 0.001 (0.003) loss 1.2074 (1.3037) teacher_loss 0.0271 (0.1322) loss_zs_kd 0.0664 (0.0710) loss_oracle 0.5171 (0.5383) kd_loss 0.8885 (0.8668) acc 100.0000 (96.6964) gate/entropy 1.0231 (1.0230) gate/usage_max 0.4249 (0.4248) gate/usage_min 0.1614 (0.1612) gate/usage_std 0.1217 (0.1218) teacher/entropy 0.0317 (0.0435) teacher/usage_max 0.6836 (0.5483) teacher/usage_min 0.0595 (0.0428) teacher/usage_std 0.2605 (0.2169) nleep/row_max_mean 1488.2417 (1499.5191) nleep/row_max_std 59.3491 (63.9382) nleep/row_min_mean 1461.7120 (1472.0061) lr 5.7422e-04 eta 0:05:30
epoch [34/50] batch [160/203] time 0.098 (0.099) data 0.000 (0.002) loss 1.2994 (1.3066) teacher_loss 0.1396 (0.1309) loss_zs_kd 0.0851 (0.0710) loss_oracle 0.5244 (0.5417) kd_loss 0.8550 (0.8694) acc 96.8750 (96.6602) gate/entropy 1.0228 (1.0230) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1610 (0.1612) gate/usage_std 0.1219 (0.1218) teacher/entropy 0.0122 (0.0420) teacher/usage_max 0.6534 (0.5483) teacher/usage_min 0.0026 (0.0440) teacher/usage_std 0.2658 (0.2163) nleep/row_max_mean 1509.6255 (1500.0549) nleep/row_max_std 57.6984 (63.1551) nleep/row_min_mean 1479.6506 (1472.3801) lr 5.7422e-04 eta 0:05:25
epoch [34/50] batch [180/203] time 0.081 (0.099) data 0.000 (0.002) loss 1.2663 (1.3047) teacher_loss 0.1109 (0.1308) loss_zs_kd 0.0587 (0.0708) loss_oracle 0.5602 (0.5407) kd_loss 0.8460 (0.8681) acc 96.8750 (96.6493) gate/entropy 1.0229 (1.0230) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1611 (0.1612) gate/usage_std 0.1218 (0.1218) teacher/entropy 0.0539 (0.0418) teacher/usage_max 0.5109 (0.5458) teacher/usage_min 0.0332 (0.0425) teacher/usage_std 0.2134 (0.2165) nleep/row_max_mean 1495.8632 (1499.7716) nleep/row_max_std 71.1033 (63.6582) nleep/row_min_mean 1466.5593 (1471.9602) lr 5.7422e-04 eta 0:05:22
epoch [34/50] batch [200/203] time 0.090 (0.098) data 0.000 (0.002) loss 1.2396 (1.3068) teacher_loss 0.0851 (0.1324) loss_zs_kd 0.0726 (0.0708) loss_oracle 0.5762 (0.5410) kd_loss 0.8301 (0.8686) acc 96.8750 (96.5625) gate/entropy 1.0228 (1.0230) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1610 (0.1612) gate/usage_std 0.1219 (0.1218) teacher/entropy 0.0417 (0.0425) teacher/usage_max 0.5057 (0.5467) teacher/usage_min 0.0027 (0.0439) teacher/usage_std 0.2339 (0.2160) nleep/row_max_mean 1481.7827 (1499.5328) nleep/row_max_std 82.1133 (63.6498) nleep/row_min_mean 1455.1976 (1471.7646) lr 5.7422e-04 eta 0:05:17
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,331
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,414
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [35/50] batch [20/203] time 0.095 (0.126) data 0.001 (0.017) loss 1.3141 (1.3232) teacher_loss 0.0682 (0.1423) loss_zs_kd 0.0500 (0.0725) loss_oracle 0.6169 (0.5551) kd_loss 0.9124 (0.8672) acc 100.0000 (96.4062) gate/entropy 1.0229 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1611 (0.1611) gate/usage_std 0.1219 (0.1218) teacher/entropy 0.0724 (0.0435) teacher/usage_max 0.4733 (0.5499) teacher/usage_min 0.1206 (0.0431) teacher/usage_std 0.1529 (0.2155) nleep/row_max_mean 1504.9553 (1500.2164) nleep/row_max_std 62.4468 (64.0915) nleep/row_min_mean 1474.8638 (1471.1679) lr 5.1825e-04 eta 0:06:46
epoch [35/50] batch [40/203] time 0.096 (0.110) data 0.000 (0.009) loss 1.2960 (1.3129) teacher_loss 0.0619 (0.1276) loss_zs_kd 0.0961 (0.0727) loss_oracle 0.5939 (0.5558) kd_loss 0.8891 (0.8711) acc 100.0000 (96.6406) gate/entropy 1.0229 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1611 (0.1611) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0114 (0.0405) teacher/usage_max 0.5306 (0.5494) teacher/usage_min 0.0319 (0.0448) teacher/usage_std 0.2165 (0.2161) nleep/row_max_mean 1512.0985 (1502.7408) nleep/row_max_std 64.4152 (62.3037) nleep/row_min_mean 1478.1118 (1473.3797) lr 5.1825e-04 eta 0:05:51
epoch [35/50] batch [60/203] time 0.091 (0.104) data 0.001 (0.006) loss 1.2998 (1.3250) teacher_loss 0.0721 (0.1378) loss_zs_kd 0.0590 (0.0739) loss_oracle 0.6396 (0.5571) kd_loss 0.8784 (0.8717) acc 100.0000 (96.1458) gate/entropy 1.0229 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1611 (0.1611) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0575 (0.0394) teacher/usage_max 0.5379 (0.5470) teacher/usage_min 0.0721 (0.0444) teacher/usage_std 0.1944 (0.2156) nleep/row_max_mean 1503.9163 (1502.7531) nleep/row_max_std 57.1413 (62.7226) nleep/row_min_mean 1478.4878 (1473.4591) lr 5.1825e-04 eta 0:05:31
epoch [35/50] batch [80/203] time 0.087 (0.101) data 0.000 (0.004) loss 1.3079 (1.3230) teacher_loss 0.1484 (0.1357) loss_zs_kd 0.0741 (0.0750) loss_oracle 0.4848 (0.5559) kd_loss 0.8800 (0.8719) acc 96.8750 (96.2891) gate/entropy 1.0229 (1.0229) gate/usage_max 0.4247 (0.4248) gate/usage_min 0.1610 (0.1611) gate/usage_std 0.1219 (0.1218) teacher/entropy 0.0232 (0.0400) teacher/usage_max 0.6342 (0.5550) teacher/usage_min 0.0318 (0.0451) teacher/usage_std 0.2459 (0.2181) nleep/row_max_mean 1502.8394 (1502.4874) nleep/row_max_std 61.8549 (62.3974) nleep/row_min_mean 1476.8135 (1473.1321) lr 5.1825e-04 eta 0:05:20
epoch [35/50] batch [100/203] time 0.092 (0.100) data 0.000 (0.004) loss 1.3198 (1.3235) teacher_loss 0.1496 (0.1376) loss_zs_kd 0.0858 (0.0751) loss_oracle 0.5244 (0.5549) kd_loss 0.8651 (0.8708) acc 96.8750 (96.1875) gate/entropy 1.0229 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1611 (0.1611) gate/usage_std 0.1218 (0.1218) teacher/entropy 0.0420 (0.0395) teacher/usage_max 0.6934 (0.5562) teacher/usage_min 0.0344 (0.0434) teacher/usage_std 0.2725 (0.2190) nleep/row_max_mean 1499.4812 (1501.0339) nleep/row_max_std 61.9202 (63.1659) nleep/row_min_mean 1473.0310 (1471.9463) lr 5.1825e-04 eta 0:05:13
epoch [35/50] batch [120/203] time 0.102 (0.099) data 0.000 (0.003) loss 1.3992 (1.3197) teacher_loss 0.1899 (0.1348) loss_zs_kd 0.0762 (0.0753) loss_oracle 0.5620 (0.5547) kd_loss 0.8902 (0.8699) acc 93.7500 (96.2760) gate/entropy 1.0230 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1612 (0.1611) gate/usage_std 0.1218 (0.1219) teacher/entropy 0.0435 (0.0382) teacher/usage_max 0.5339 (0.5528) teacher/usage_min 0.0658 (0.0411) teacher/usage_std 0.1969 (0.2196) nleep/row_max_mean 1500.6453 (1500.8360) nleep/row_max_std 52.7998 (62.9621) nleep/row_min_mean 1471.1960 (1471.6885) lr 5.1825e-04 eta 0:05:08
epoch [35/50] batch [140/203] time 0.089 (0.097) data 0.000 (0.003) loss 1.2585 (1.3186) teacher_loss 0.0631 (0.1312) loss_zs_kd 0.0825 (0.0750) loss_oracle 0.5749 (0.5581) kd_loss 0.8667 (0.8709) acc 100.0000 (96.3393) gate/entropy 1.0229 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1611 (0.1611) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0033 (0.0380) teacher/usage_max 0.5311 (0.5508) teacher/usage_min 0.0003 (0.0420) teacher/usage_std 0.2369 (0.2186) nleep/row_max_mean 1507.7280 (1501.2552) nleep/row_max_std 66.9000 (62.6324) nleep/row_min_mean 1474.2126 (1471.8521) lr 5.1825e-04 eta 0:05:02
epoch [35/50] batch [160/203] time 0.089 (0.097) data 0.000 (0.002) loss 1.4040 (1.3137) teacher_loss 0.2018 (0.1262) loss_zs_kd 0.0778 (0.0748) loss_oracle 0.5588 (0.5582) kd_loss 0.8839 (0.8709) acc 90.6250 (96.5039) gate/entropy 1.0229 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1611 (0.1611) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0336 (0.0380) teacher/usage_max 0.5401 (0.5492) teacher/usage_min 0.0528 (0.0421) teacher/usage_std 0.2057 (0.2181) nleep/row_max_mean 1497.8455 (1500.8483) nleep/row_max_std 60.8826 (62.5701) nleep/row_min_mean 1466.6816 (1471.3982) lr 5.1825e-04 eta 0:05:00
epoch [35/50] batch [180/203] time 0.085 (0.096) data 0.000 (0.002) loss 1.1933 (1.3121) teacher_loss 0.0528 (0.1243) loss_zs_kd 0.0651 (0.0748) loss_oracle 0.4434 (0.5564) kd_loss 0.8862 (0.8722) acc 100.0000 (96.5278) gate/entropy 1.0229 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1611 (0.1611) gate/usage_std 0.1218 (0.1219) teacher/entropy 0.0162 (0.0375) teacher/usage_max 0.5956 (0.5508) teacher/usage_min 0.0324 (0.0429) teacher/usage_std 0.2316 (0.2179) nleep/row_max_mean 1490.8396 (1501.0356) nleep/row_max_std 69.7583 (62.1392) nleep/row_min_mean 1463.8890 (1471.5519) lr 5.1825e-04 eta 0:04:54
epoch [35/50] batch [200/203] time 0.082 (0.095) data 0.000 (0.002) loss 1.2098 (1.3135) teacher_loss 0.0578 (0.1255) loss_zs_kd 0.0494 (0.0744) loss_oracle 0.4902 (0.5559) kd_loss 0.8822 (0.8728) acc 96.8750 (96.4844) gate/entropy 1.0228 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1610 (0.1611) gate/usage_std 0.1220 (0.1219) teacher/entropy 0.0517 (0.0376) teacher/usage_max 0.4804 (0.5512) teacher/usage_min 0.0678 (0.0436) teacher/usage_std 0.1881 (0.2176) nleep/row_max_mean 1514.2454 (1500.8444) nleep/row_max_std 49.4338 (62.1556) nleep/row_min_mean 1488.4132 (1471.4457) lr 5.1825e-04 eta 0:04:49
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,327
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [36/50] batch [20/203] time 0.092 (0.108) data 0.000 (0.015) loss 1.3710 (1.3393) teacher_loss 0.1841 (0.1457) loss_zs_kd 0.0706 (0.0755) loss_oracle 0.5794 (0.5562) kd_loss 0.8619 (0.8777) acc 90.6250 (95.9375) gate/entropy 1.0229 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1612 (0.1611) gate/usage_std 0.1218 (0.1219) teacher/entropy 0.0684 (0.0380) teacher/usage_max 0.6198 (0.5360) teacher/usage_min 0.0683 (0.0492) teacher/usage_std 0.2256 (0.2100) nleep/row_max_mean 1485.7461 (1499.1209) nleep/row_max_std 50.8402 (58.2416) nleep/row_min_mean 1457.7578 (1469.9929) lr 4.6417e-04 eta 0:05:25
epoch [36/50] batch [40/203] time 0.097 (0.098) data 0.000 (0.008) loss 1.2619 (1.3231) teacher_loss 0.0645 (0.1457) loss_zs_kd 0.0912 (0.0757) loss_oracle 0.5035 (0.5389) kd_loss 0.9001 (0.8702) acc 96.8750 (95.7031) gate/entropy 1.0231 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1613 (0.1611) gate/usage_std 0.1217 (0.1219) teacher/entropy 0.0006 (0.0379) teacher/usage_max 0.5625 (0.5443) teacher/usage_min 0.0313 (0.0412) teacher/usage_std 0.2229 (0.2177) nleep/row_max_mean 1505.9454 (1496.4866) nleep/row_max_std 28.9393 (60.6811) nleep/row_min_mean 1474.5299 (1468.0115) lr 4.6417e-04 eta 0:04:55
epoch [36/50] batch [60/203] time 0.099 (0.097) data 0.000 (0.005) loss 1.3560 (1.3206) teacher_loss 0.1877 (0.1437) loss_zs_kd 0.1080 (0.0760) loss_oracle 0.5674 (0.5467) kd_loss 0.8306 (0.8655) acc 96.8750 (96.0938) gate/entropy 1.0228 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1610 (0.1611) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0494 (0.0376) teacher/usage_max 0.5562 (0.5468) teacher/usage_min 0.0100 (0.0363) teacher/usage_std 0.2340 (0.2207) nleep/row_max_mean 1496.6558 (1496.4833) nleep/row_max_std 58.2985 (61.7742) nleep/row_min_mean 1467.0970 (1467.7963) lr 4.6417e-04 eta 0:04:48
epoch [36/50] batch [80/203] time 0.088 (0.097) data 0.000 (0.004) loss 1.2770 (1.3101) teacher_loss 0.1083 (0.1318) loss_zs_kd 0.0733 (0.0755) loss_oracle 0.5263 (0.5488) kd_loss 0.8689 (0.8660) acc 96.8750 (96.4453) gate/entropy 1.0228 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1610 (0.1611) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0034 (0.0372) teacher/usage_max 0.6247 (0.5483) teacher/usage_min 0.0003 (0.0363) teacher/usage_std 0.2566 (0.2208) nleep/row_max_mean 1497.4241 (1496.4746) nleep/row_max_std 65.5947 (61.9785) nleep/row_min_mean 1469.5730 (1467.7952) lr 4.6417e-04 eta 0:04:46
epoch [36/50] batch [100/203] time 0.094 (0.097) data 0.000 (0.003) loss 1.2782 (1.3031) teacher_loss 0.0932 (0.1262) loss_zs_kd 0.0981 (0.0755) loss_oracle 0.4999 (0.5480) kd_loss 0.8860 (0.8652) acc 96.8750 (96.6562) gate/entropy 1.0228 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1610 (0.1611) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0156 (0.0375) teacher/usage_max 0.5612 (0.5511) teacher/usage_min 0.0324 (0.0356) teacher/usage_std 0.2220 (0.2216) nleep/row_max_mean 1487.1405 (1496.7536) nleep/row_max_std 70.8817 (61.5624) nleep/row_min_mean 1457.1541 (1467.8959) lr 4.6417e-04 eta 0:04:44
epoch [36/50] batch [120/203] time 0.094 (0.096) data 0.000 (0.003) loss 1.6458 (1.3042) teacher_loss 0.3908 (0.1273) loss_zs_kd 0.0840 (0.0750) loss_oracle 0.6123 (0.5482) kd_loss 0.9068 (0.8653) acc 84.3750 (96.5365) gate/entropy 1.0227 (1.0229) gate/usage_max 0.4247 (0.4248) gate/usage_min 0.1609 (0.1611) gate/usage_std 0.1220 (0.1219) teacher/entropy 0.0233 (0.0369) teacher/usage_max 0.5623 (0.5517) teacher/usage_min 0.0620 (0.0350) teacher/usage_std 0.2064 (0.2217) nleep/row_max_mean 1506.5123 (1496.2052) nleep/row_max_std 57.5814 (62.4461) nleep/row_min_mean 1476.0114 (1467.1980) lr 4.6417e-04 eta 0:04:42
epoch [36/50] batch [140/203] time 0.097 (0.096) data 0.000 (0.002) loss 1.2399 (1.3013) teacher_loss 0.0394 (0.1245) loss_zs_kd 0.0823 (0.0749) loss_oracle 0.6379 (0.5488) kd_loss 0.8404 (0.8650) acc 100.0000 (96.6071) gate/entropy 1.0228 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1610 (0.1610) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0584 (0.0367) teacher/usage_max 0.5251 (0.5531) teacher/usage_min 0.0326 (0.0344) teacher/usage_std 0.2153 (0.2224) nleep/row_max_mean 1493.5103 (1496.2291) nleep/row_max_std 71.7813 (62.7233) nleep/row_min_mean 1467.0002 (1467.2538) lr 4.6417e-04 eta 0:04:38
epoch [36/50] batch [160/203] time 0.102 (0.096) data 0.000 (0.002) loss 1.4082 (1.3016) teacher_loss 0.3242 (0.1260) loss_zs_kd 0.0764 (0.0746) loss_oracle 0.4619 (0.5494) kd_loss 0.8148 (0.8635) acc 93.7500 (96.5820) gate/entropy 1.0229 (1.0229) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1611 (0.1610) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0828 (0.0370) teacher/usage_max 0.5070 (0.5529) teacher/usage_min 0.0309 (0.0334) teacher/usage_std 0.2146 (0.2229) nleep/row_max_mean 1468.3164 (1495.9851) nleep/row_max_std 93.8759 (63.1918) nleep/row_min_mean 1440.0337 (1466.8769) lr 4.6417e-04 eta 0:04:36
epoch [36/50] batch [180/203] time 0.095 (0.096) data 0.000 (0.002) loss 1.2847 (1.3040) teacher_loss 0.1538 (0.1271) loss_zs_kd 0.0578 (0.0748) loss_oracle 0.5081 (0.5495) kd_loss 0.8479 (0.8648) acc 96.8750 (96.5278) gate/entropy 1.0228 (1.0228) gate/usage_max 0.4247 (0.4248) gate/usage_min 0.1610 (0.1610) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0231 (0.0364) teacher/usage_max 0.5892 (0.5521) teacher/usage_min 0.0049 (0.0339) teacher/usage_std 0.2440 (0.2224) nleep/row_max_mean 1496.1825 (1496.5363) nleep/row_max_std 68.5448 (63.1815) nleep/row_min_mean 1467.5762 (1467.3824) lr 4.6417e-04 eta 0:04:34
epoch [36/50] batch [200/203] time 0.084 (0.095) data 0.000 (0.002) loss 1.2268 (1.3052) teacher_loss 0.1021 (0.1299) loss_zs_kd 0.0506 (0.0746) loss_oracle 0.5192 (0.5486) kd_loss 0.8398 (0.8637) acc 96.8750 (96.5156) gate/entropy 1.0229 (1.0228) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1610 (0.1610) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0732 (0.0364) teacher/usage_max 0.5106 (0.5527) teacher/usage_min 0.0468 (0.0328) teacher/usage_std 0.2045 (0.2236) nleep/row_max_mean 1488.0923 (1496.0759) nleep/row_max_std 66.5028 (63.8139) nleep/row_min_mean 1460.1254 (1466.8966) lr 4.6417e-04 eta 0:04:30
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,331
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [37/50] batch [20/203] time 0.096 (0.106) data 0.000 (0.014) loss 1.3106 (1.3156) teacher_loss 0.1124 (0.1245) loss_zs_kd 0.0833 (0.0802) loss_oracle 0.4937 (0.5666) kd_loss 0.9097 (0.8677) acc 96.8750 (95.9375) gate/entropy 1.0227 (1.0228) gate/usage_max 0.4247 (0.4248) gate/usage_min 0.1608 (0.1610) gate/usage_std 0.1220 (0.1220) teacher/entropy 0.0158 (0.0292) teacher/usage_max 0.5886 (0.5694) teacher/usage_min 0.0627 (0.0295) teacher/usage_std 0.2150 (0.2294) nleep/row_max_mean 1511.3964 (1496.8278) nleep/row_max_std 57.2978 (64.3835) nleep/row_min_mean 1482.2968 (1466.4190) lr 4.1221e-04 eta 0:05:00
epoch [37/50] batch [40/203] time 0.101 (0.099) data 0.000 (0.007) loss 1.1932 (1.2978) teacher_loss 0.0851 (0.1157) loss_zs_kd 0.0574 (0.0759) loss_oracle 0.5784 (0.5674) kd_loss 0.7902 (0.8605) acc 100.0000 (96.4062) gate/entropy 1.0229 (1.0228) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1611 (0.1610) gate/usage_std 0.1218 (0.1220) teacher/entropy 0.0810 (0.0335) teacher/usage_max 0.5842 (0.5634) teacher/usage_min 0.0047 (0.0268) teacher/usage_std 0.2429 (0.2289) nleep/row_max_mean 1481.4319 (1499.6096) nleep/row_max_std 77.1827 (63.1040) nleep/row_min_mean 1452.9028 (1469.1348) lr 4.1221e-04 eta 0:04:37
epoch [37/50] batch [60/203] time 0.107 (0.098) data 0.001 (0.005) loss 1.2920 (1.2870) teacher_loss 0.1248 (0.1093) loss_zs_kd 0.0659 (0.0765) loss_oracle 0.5976 (0.5576) kd_loss 0.8354 (0.8607) acc 96.8750 (96.8750) gate/entropy 1.0229 (1.0228) gate/usage_max 0.4248 (0.4248) gate/usage_min 0.1611 (0.1610) gate/usage_std 0.1219 (0.1219) teacher/entropy 0.0354 (0.0338) teacher/usage_max 0.5600 (0.5623) teacher/usage_min 0.0008 (0.0268) teacher/usage_std 0.2403 (0.2285) nleep/row_max_mean 1481.6279 (1498.5913) nleep/row_max_std 77.1911 (63.1649) nleep/row_min_mean 1452.3156 (1468.3802) lr 4.1221e-04 eta 0:04:31
epoch [37/50] batch [80/203] time 0.094 (0.096) data 0.000 (0.004) loss 1.4266 (1.2958) teacher_loss 0.2399 (0.1223) loss_zs_kd 0.0602 (0.0755) loss_oracle 0.5331 (0.5538) kd_loss 0.8901 (0.8589) acc 96.8750 (96.5625) gate/entropy 1.0226 (1.0228) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1610) gate/usage_std 0.1221 (0.1220) teacher/entropy 0.0772 (0.0357) teacher/usage_max 0.5241 (0.5621) teacher/usage_min 0.1049 (0.0269) teacher/usage_std 0.1732 (0.2281) nleep/row_max_mean 1516.8109 (1497.7820) nleep/row_max_std 49.3328 (64.0697) nleep/row_min_mean 1487.8877 (1467.8638) lr 4.1221e-04 eta 0:04:26
epoch [37/50] batch [100/203] time 0.096 (0.096) data 0.000 (0.003) loss 1.1663 (1.2914) teacher_loss 0.0695 (0.1218) loss_zs_kd 0.0654 (0.0737) loss_oracle 0.4509 (0.5497) kd_loss 0.8386 (0.8579) acc 100.0000 (96.5000) gate/entropy 1.0226 (1.0228) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1607 (0.1610) gate/usage_std 0.1221 (0.1220) teacher/entropy 0.0566 (0.0375) teacher/usage_max 0.5464 (0.5589) teacher/usage_min 0.0295 (0.0279) teacher/usage_std 0.2206 (0.2270) nleep/row_max_mean 1496.9723 (1497.7528) nleep/row_max_std 76.5353 (64.4897) nleep/row_min_mean 1470.7892 (1468.0635) lr 4.1221e-04 eta 0:04:23
epoch [37/50] batch [120/203] time 0.094 (0.096) data 0.000 (0.003) loss 1.2850 (1.2904) teacher_loss 0.0859 (0.1234) loss_zs_kd 0.0535 (0.0721) loss_oracle 0.5542 (0.5451) kd_loss 0.8952 (0.8585) acc 96.8750 (96.4844) gate/entropy 1.0229 (1.0228) gate/usage_max 0.4248 (0.4247) gate/usage_min 0.1611 (0.1610) gate/usage_std 0.1219 (0.1220) teacher/entropy 0.0662 (0.0385) teacher/usage_max 0.4977 (0.5564) teacher/usage_min 0.0978 (0.0296) teacher/usage_std 0.1708 (0.2253) nleep/row_max_mean 1490.3110 (1498.1606) nleep/row_max_std 50.4418 (63.4965) nleep/row_min_mean 1463.2864 (1468.5754) lr 4.1221e-04 eta 0:04:20
epoch [37/50] batch [140/203] time 0.093 (0.096) data 0.000 (0.002) loss 1.6178 (1.2970) teacher_loss 0.4539 (0.1280) loss_zs_kd 0.0764 (0.0720) loss_oracle 0.5391 (0.5456) kd_loss 0.8562 (0.8602) acc 90.6250 (96.4286) gate/entropy 1.0228 (1.0228) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1610 (0.1610) gate/usage_std 0.1219 (0.1220) teacher/entropy 0.0586 (0.0384) teacher/usage_max 0.4802 (0.5534) teacher/usage_min 0.0480 (0.0314) teacher/usage_std 0.2018 (0.2237) nleep/row_max_mean 1494.9312 (1498.5949) nleep/row_max_std 61.8819 (63.3313) nleep/row_min_mean 1467.9358 (1468.9477) lr 4.1221e-04 eta 0:04:19
epoch [37/50] batch [160/203] time 0.093 (0.096) data 0.000 (0.002) loss 1.2005 (1.2960) teacher_loss 0.0558 (0.1274) loss_zs_kd 0.0755 (0.0719) loss_oracle 0.5349 (0.5437) kd_loss 0.8395 (0.8607) acc 100.0000 (96.4844) gate/entropy 1.0226 (1.0228) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1610) gate/usage_std 0.1221 (0.1220) teacher/entropy 0.0296 (0.0376) teacher/usage_max 0.5493 (0.5547) teacher/usage_min 0.0021 (0.0311) teacher/usage_std 0.2378 (0.2241) nleep/row_max_mean 1528.8303 (1499.0286) nleep/row_max_std 33.5170 (63.5677) nleep/row_min_mean 1498.3608 (1469.3615) lr 4.1221e-04 eta 0:04:16
epoch [37/50] batch [180/203] time 0.093 (0.096) data 0.000 (0.002) loss 1.2233 (1.2963) teacher_loss 0.0861 (0.1267) loss_zs_kd 0.0724 (0.0730) loss_oracle 0.4830 (0.5423) kd_loss 0.8595 (0.8619) acc 100.0000 (96.5278) gate/entropy 1.0226 (1.0228) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1609) gate/usage_std 0.1221 (0.1220) teacher/entropy 0.0244 (0.0364) teacher/usage_max 0.5309 (0.5542) teacher/usage_min 0.0151 (0.0310) teacher/usage_std 0.2272 (0.2241) nleep/row_max_mean 1496.6460 (1499.5123) nleep/row_max_std 73.0068 (62.8777) nleep/row_min_mean 1466.9434 (1469.6782) lr 4.1221e-04 eta 0:04:15
epoch [37/50] batch [200/203] time 0.090 (0.096) data 0.000 (0.002) loss 1.3261 (1.2968) teacher_loss 0.0848 (0.1258) loss_zs_kd 0.0915 (0.0732) loss_oracle 0.6713 (0.5434) kd_loss 0.8599 (0.8626) acc 96.8750 (96.5312) gate/entropy 1.0226 (1.0228) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1609) gate/usage_std 0.1221 (0.1220) teacher/entropy 0.0062 (0.0357) teacher/usage_max 0.6242 (0.5539) teacher/usage_min 0.0007 (0.0309) teacher/usage_std 0.2562 (0.2239) nleep/row_max_mean 1505.2391 (1499.5022) nleep/row_max_std 75.1897 (63.4459) nleep/row_min_mean 1469.7334 (1469.4687) lr 4.1221e-04 eta 0:04:13
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,323
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [38/50] batch [20/203] time 0.099 (0.109) data 0.000 (0.015) loss 1.2157 (1.2829) teacher_loss 0.0570 (0.1030) loss_zs_kd 0.0595 (0.0770) loss_oracle 0.5606 (0.5554) kd_loss 0.8487 (0.8637) acc 96.8750 (96.4062) gate/entropy 1.0226 (1.0227) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1607 (0.1609) gate/usage_std 0.1221 (0.1220) teacher/entropy 0.0170 (0.0315) teacher/usage_max 0.6558 (0.5460) teacher/usage_min 0.0009 (0.0283) teacher/usage_std 0.2674 (0.2242) nleep/row_max_mean 1508.6770 (1496.1973) nleep/row_max_std 60.6103 (63.5550) nleep/row_min_mean 1478.6744 (1466.8967) lr 3.6258e-04 eta 0:04:44
epoch [38/50] batch [40/203] time 0.094 (0.100) data 0.000 (0.008) loss 1.2442 (1.2814) teacher_loss 0.0616 (0.1020) loss_zs_kd 0.0685 (0.0778) loss_oracle 0.5762 (0.5571) kd_loss 0.8603 (0.8620) acc 96.8750 (96.7969) gate/entropy 1.0227 (1.0227) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1609) gate/usage_std 0.1220 (0.1220) teacher/entropy 0.0137 (0.0328) teacher/usage_max 0.5900 (0.5638) teacher/usage_min 0.0033 (0.0278) teacher/usage_std 0.2451 (0.2304) nleep/row_max_mean 1522.3733 (1498.0237) nleep/row_max_std 31.8647 (61.3618) nleep/row_min_mean 1490.9524 (1468.3090) lr 3.6258e-04 eta 0:04:19
epoch [38/50] batch [60/203] time 0.097 (0.099) data 0.000 (0.005) loss 1.2285 (1.2921) teacher_loss 0.0283 (0.1106) loss_zs_kd 0.0956 (0.0774) loss_oracle 0.5522 (0.5557) kd_loss 0.8763 (0.8650) acc 100.0000 (96.5625) gate/entropy 1.0227 (1.0227) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1609) gate/usage_std 0.1220 (0.1220) teacher/entropy 0.0466 (0.0317) teacher/usage_max 0.4933 (0.5588) teacher/usage_min 0.0563 (0.0293) teacher/usage_std 0.1967 (0.2279) nleep/row_max_mean 1511.4095 (1498.1080) nleep/row_max_std 42.0741 (59.8871) nleep/row_min_mean 1481.5576 (1468.4123) lr 3.6258e-04 eta 0:04:15
epoch [38/50] batch [80/203] time 0.094 (0.098) data 0.000 (0.004) loss 1.2466 (1.3155) teacher_loss 0.0846 (0.1351) loss_zs_kd 0.0741 (0.0757) loss_oracle 0.5645 (0.5530) kd_loss 0.8427 (0.8661) acc 96.8750 (96.1719) gate/entropy 1.0226 (1.0227) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1609) gate/usage_std 0.1221 (0.1220) teacher/entropy 0.0511 (0.0328) teacher/usage_max 0.5544 (0.5547) teacher/usage_min 0.0245 (0.0318) teacher/usage_std 0.2251 (0.2249) nleep/row_max_mean 1508.7532 (1498.7290) nleep/row_max_std 54.0690 (59.4643) nleep/row_min_mean 1477.7769 (1469.1667) lr 3.6258e-04 eta 0:04:11
epoch [38/50] batch [100/203] time 0.097 (0.101) data 0.000 (0.003) loss 1.1849 (1.3101) teacher_loss 0.0696 (0.1318) loss_zs_kd 0.0636 (0.0746) loss_oracle 0.4794 (0.5511) kd_loss 0.8438 (0.8655) acc 100.0000 (96.2188) gate/entropy 1.0227 (1.0227) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1609 (0.1609) gate/usage_std 0.1220 (0.1220) teacher/entropy 0.0507 (0.0334) teacher/usage_max 0.5155 (0.5516) teacher/usage_min 0.0262 (0.0317) teacher/usage_std 0.2185 (0.2241) nleep/row_max_mean 1495.4102 (1498.4426) nleep/row_max_std 74.3580 (60.0281) nleep/row_min_mean 1465.6831 (1468.7782) lr 3.6258e-04 eta 0:04:16
epoch [38/50] batch [120/203] time 0.092 (0.100) data 0.000 (0.003) loss 1.2693 (1.3086) teacher_loss 0.0447 (0.1325) loss_zs_kd 0.0784 (0.0734) loss_oracle 0.5658 (0.5484) kd_loss 0.9025 (0.8652) acc 100.0000 (96.1458) gate/entropy 1.0228 (1.0227) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1610 (0.1609) gate/usage_std 0.1220 (0.1220) teacher/entropy 0.0322 (0.0339) teacher/usage_max 0.4954 (0.5558) teacher/usage_min 0.0682 (0.0320) teacher/usage_std 0.1890 (0.2250) nleep/row_max_mean 1490.6246 (1498.0505) nleep/row_max_std 70.0166 (60.8007) nleep/row_min_mean 1460.3317 (1468.6306) lr 3.6258e-04 eta 0:04:12
epoch [38/50] batch [140/203] time 0.101 (0.100) data 0.000 (0.002) loss 1.1995 (1.3065) teacher_loss 0.0553 (0.1316) loss_zs_kd 0.0904 (0.0736) loss_oracle 0.5157 (0.5481) kd_loss 0.8411 (0.8640) acc 100.0000 (96.2946) gate/entropy 1.0225 (1.0227) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1607 (0.1609) gate/usage_std 0.1222 (0.1220) teacher/entropy 0.0356 (0.0343) teacher/usage_max 0.5610 (0.5572) teacher/usage_min 0.0074 (0.0310) teacher/usage_std 0.2365 (0.2260) nleep/row_max_mean 1511.0160 (1498.2748) nleep/row_max_std 59.7180 (61.1218) nleep/row_min_mean 1480.0425 (1468.8623) lr 3.6258e-04 eta 0:04:10
epoch [38/50] batch [160/203] time 0.093 (0.099) data 0.000 (0.002) loss 1.2698 (1.3061) teacher_loss 0.1595 (0.1326) loss_zs_kd 0.0805 (0.0732) loss_oracle 0.4277 (0.5467) kd_loss 0.8562 (0.8635) acc 96.8750 (96.2695) gate/entropy 1.0226 (1.0227) gate/usage_max 0.4246 (0.4247) gate/usage_min 0.1608 (0.1609) gate/usage_std 0.1221 (0.1220) teacher/entropy 0.0142 (0.0342) teacher/usage_max 0.5336 (0.5555) teacher/usage_min 0.0011 (0.0304) teacher/usage_std 0.2366 (0.2258) nleep/row_max_mean 1499.1112 (1498.3823) nleep/row_max_std 60.0981 (61.5890) nleep/row_min_mean 1469.0521 (1468.9115) lr 3.6258e-04 eta 0:04:06
epoch [38/50] batch [180/203] time 0.094 (0.099) data 0.000 (0.002) loss 1.0986 (1.3024) teacher_loss 0.0232 (0.1283) loss_zs_kd 0.0588 (0.0733) loss_oracle 0.4539 (0.5460) kd_loss 0.8190 (0.8644) acc 100.0000 (96.3715) gate/entropy 1.0227 (1.0227) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1609 (0.1609) gate/usage_std 0.1220 (0.1220) teacher/entropy 0.0782 (0.0343) teacher/usage_max 0.6062 (0.5545) teacher/usage_min 0.0267 (0.0315) teacher/usage_std 0.2378 (0.2249) nleep/row_max_mean 1484.9797 (1498.5701) nleep/row_max_std 77.6423 (61.3165) nleep/row_min_mean 1459.9485 (1469.0652) lr 3.6258e-04 eta 0:04:02
epoch [38/50] batch [200/203] time 0.088 (0.098) data 0.000 (0.002) loss 1.1438 (1.3013) teacher_loss 0.0742 (0.1255) loss_zs_kd 0.0505 (0.0730) loss_oracle 0.4638 (0.5472) kd_loss 0.8124 (0.8657) acc 96.8750 (96.4844) gate/entropy 1.0226 (1.0227) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1609) gate/usage_std 0.1221 (0.1220) teacher/entropy 0.1054 (0.0357) teacher/usage_max 0.5747 (0.5544) teacher/usage_min 0.0541 (0.0343) teacher/usage_std 0.2142 (0.2232) nleep/row_max_mean 1484.5840 (1498.6652) nleep/row_max_std 82.4017 (61.4233) nleep/row_min_mean 1460.5945 (1469.3094) lr 3.6258e-04 eta 0:03:58
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,327
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [39/50] batch [20/203] time 0.121 (0.111) data 0.000 (0.018) loss 1.5148 (1.3287) teacher_loss 0.2295 (0.1178) loss_zs_kd 0.0489 (0.0705) loss_oracle 0.6922 (0.5777) kd_loss 0.9148 (0.8868) acc 93.7500 (95.9375) gate/entropy 1.0227 (1.0226) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1609 (0.1608) gate/usage_std 0.1220 (0.1221) teacher/entropy 0.0628 (0.0415) teacher/usage_max 0.5242 (0.5432) teacher/usage_min 0.1115 (0.0621) teacher/usage_std 0.1699 (0.2050) nleep/row_max_mean 1487.4872 (1497.4353) nleep/row_max_std 77.3080 (63.9460) nleep/row_min_mean 1457.9995 (1468.8454) lr 3.1545e-04 eta 0:04:28
epoch [39/50] batch [40/203] time 0.095 (0.100) data 0.000 (0.009) loss 1.2475 (1.3221) teacher_loss 0.1146 (0.1192) loss_zs_kd 0.0569 (0.0716) loss_oracle 0.4476 (0.5645) kd_loss 0.8806 (0.8848) acc 93.7500 (96.3281) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1220 (0.1221) teacher/entropy 0.0193 (0.0539) teacher/usage_max 0.5025 (0.5255) teacher/usage_min 0.0320 (0.0731) teacher/usage_std 0.2136 (0.1943) nleep/row_max_mean 1506.4131 (1499.2463) nleep/row_max_std 42.7314 (62.7859) nleep/row_min_mean 1474.7837 (1470.8066) lr 3.1545e-04 eta 0:04:00
epoch [39/50] batch [60/203] time 0.099 (0.097) data 0.001 (0.006) loss 1.3860 (1.3301) teacher_loss 0.2496 (0.1236) loss_zs_kd 0.0490 (0.0716) loss_oracle 0.4947 (0.5612) kd_loss 0.8645 (0.8901) acc 93.7500 (96.4062) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1220 (0.1221) teacher/entropy 0.1002 (0.0632) teacher/usage_max 0.5806 (0.5195) teacher/usage_min 0.0971 (0.0881) teacher/usage_std 0.1975 (0.1852) nleep/row_max_mean 1501.9924 (1497.9883) nleep/row_max_std 63.5849 (64.7609) nleep/row_min_mean 1472.8826 (1469.8420) lr 3.1545e-04 eta 0:03:51
epoch [39/50] batch [80/203] time 0.083 (0.094) data 0.000 (0.005) loss 1.5669 (1.3371) teacher_loss 0.1564 (0.1220) loss_zs_kd 0.0899 (0.0716) loss_oracle 0.6509 (0.5604) kd_loss 1.0401 (0.8991) acc 93.7500 (96.6016) gate/entropy 1.0227 (1.0226) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1609 (0.1608) gate/usage_std 0.1220 (0.1221) teacher/entropy 0.0530 (0.0654) teacher/usage_max 0.3886 (0.5172) teacher/usage_min 0.2343 (0.0996) teacher/usage_std 0.0702 (0.1795) nleep/row_max_mean 1497.0460 (1498.2045) nleep/row_max_std 62.8181 (63.9996) nleep/row_min_mean 1470.8000 (1470.0519) lr 3.1545e-04 eta 0:03:42
epoch [39/50] batch [100/203] time 0.091 (0.092) data 0.000 (0.004) loss 1.7236 (1.3446) teacher_loss 0.4561 (0.1288) loss_zs_kd 0.0870 (0.0730) loss_oracle 0.5777 (0.5574) kd_loss 0.9351 (0.9006) acc 87.5000 (96.3438) gate/entropy 1.0225 (1.0226) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1607 (0.1608) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.1012 (0.0681) teacher/usage_max 0.4434 (0.5163) teacher/usage_min 0.1745 (0.1039) teacher/usage_std 0.1151 (0.1769) nleep/row_max_mean 1515.8364 (1498.5922) nleep/row_max_std 48.7858 (63.9196) nleep/row_min_mean 1486.9279 (1470.4723) lr 3.1545e-04 eta 0:03:34
epoch [39/50] batch [120/203] time 0.087 (0.091) data 0.000 (0.003) loss 1.4299 (1.3470) teacher_loss 0.1902 (0.1318) loss_zs_kd 0.0567 (0.0723) loss_oracle 0.5576 (0.5567) kd_loss 0.9325 (0.9008) acc 96.8750 (96.2240) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0441 (0.0684) teacher/usage_max 0.5362 (0.5156) teacher/usage_min 0.1102 (0.1043) teacher/usage_std 0.1745 (0.1764) nleep/row_max_mean 1476.2567 (1498.6026) nleep/row_max_std 86.0231 (64.3981) nleep/row_min_mean 1450.8909 (1470.3970) lr 3.1545e-04 eta 0:03:31
epoch [39/50] batch [140/203] time 0.081 (0.091) data 0.000 (0.003) loss 1.3627 (1.3472) teacher_loss 0.0935 (0.1323) loss_zs_kd 0.0816 (0.0725) loss_oracle 0.6354 (0.5557) kd_loss 0.9107 (0.9007) acc 100.0000 (96.2500) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4246 (0.4247) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0385 (0.0687) teacher/usage_max 0.6093 (0.5138) teacher/usage_min 0.0804 (0.1047) teacher/usage_std 0.2165 (0.1754) nleep/row_max_mean 1483.2712 (1498.5089) nleep/row_max_std 77.9346 (64.0958) nleep/row_min_mean 1455.0618 (1470.3288) lr 3.1545e-04 eta 0:03:28
epoch [39/50] batch [160/203] time 0.091 (0.091) data 0.000 (0.002) loss 1.4661 (1.3495) teacher_loss 0.1402 (0.1316) loss_zs_kd 0.0812 (0.0722) loss_oracle 0.6124 (0.5548) kd_loss 0.9791 (0.9044) acc 96.8750 (96.2305) gate/entropy 1.0227 (1.0226) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1220 (0.1221) teacher/entropy 0.0793 (0.0693) teacher/usage_max 0.4411 (0.5138) teacher/usage_min 0.1990 (0.1092) teacher/usage_std 0.1006 (0.1731) nleep/row_max_mean 1489.6602 (1498.2616) nleep/row_max_std 71.7604 (64.5330) nleep/row_min_mean 1462.4653 (1470.1930) lr 3.1545e-04 eta 0:03:26
epoch [39/50] batch [180/203] time 0.099 (0.091) data 0.000 (0.002) loss 1.3336 (1.3476) teacher_loss 0.1152 (0.1319) loss_zs_kd 0.0645 (0.0726) loss_oracle 0.5326 (0.5532) kd_loss 0.9199 (0.9028) acc 93.7500 (96.2153) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0789 (0.0683) teacher/usage_max 0.5154 (0.5145) teacher/usage_min 0.1382 (0.1064) teacher/usage_std 0.1543 (0.1745) nleep/row_max_mean 1506.4309 (1498.4379) nleep/row_max_std 60.1117 (64.3398) nleep/row_min_mean 1481.7885 (1470.2958) lr 3.1545e-04 eta 0:03:25
epoch [39/50] batch [200/203] time 0.084 (0.092) data 0.000 (0.002) loss 1.2285 (1.3406) teacher_loss 0.0809 (0.1267) loss_zs_kd 0.0833 (0.0724) loss_oracle 0.4985 (0.5534) kd_loss 0.8566 (0.9010) acc 100.0000 (96.3906) gate/entropy 1.0225 (1.0226) gate/usage_max 0.4246 (0.4247) gate/usage_min 0.1607 (0.1608) gate/usage_std 0.1222 (0.1221) teacher/entropy 0.0597 (0.0674) teacher/usage_max 0.4905 (0.5137) teacher/usage_min 0.0503 (0.1036) teacher/usage_std 0.2005 (0.1756) nleep/row_max_mean 1488.1821 (1498.2884) nleep/row_max_std 76.1822 (64.4731) nleep/row_min_mean 1463.2739 (1470.1747) lr 3.1545e-04 eta 0:03:25
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,320
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [40/50] batch [20/203] time 0.091 (0.108) data 0.000 (0.018) loss 1.3689 (1.2983) teacher_loss 0.0950 (0.1005) loss_zs_kd 0.1017 (0.0808) loss_oracle 0.6282 (0.5615) kd_loss 0.9090 (0.8766) acc 96.8750 (96.8750) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4247 (0.4247) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0510 (0.0586) teacher/usage_max 0.5504 (0.5452) teacher/usage_min 0.0982 (0.0689) teacher/usage_std 0.1850 (0.2026) nleep/row_max_mean 1492.8586 (1493.2287) nleep/row_max_std 70.3884 (69.0024) nleep/row_min_mean 1464.1904 (1464.9719) lr 2.7103e-04 eta 0:03:59
epoch [40/50] batch [40/203] time 0.098 (0.100) data 0.000 (0.009) loss 1.3049 (1.3162) teacher_loss 0.0560 (0.1070) loss_zs_kd 0.0716 (0.0740) loss_oracle 0.6081 (0.5641) kd_loss 0.9091 (0.8902) acc 100.0000 (97.2656) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4246 (0.4247) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0389 (0.0587) teacher/usage_max 0.4709 (0.5345) teacher/usage_min 0.0834 (0.0831) teacher/usage_std 0.1770 (0.1931) nleep/row_max_mean 1501.8606 (1495.0268) nleep/row_max_std 60.8449 (66.2057) nleep/row_min_mean 1474.4415 (1466.8954) lr 2.7103e-04 eta 0:03:39
epoch [40/50] batch [60/203] time 0.090 (0.099) data 0.001 (0.006) loss 1.3838 (1.3132) teacher_loss 0.2241 (0.1119) loss_zs_kd 0.0619 (0.0743) loss_oracle 0.5618 (0.5561) kd_loss 0.8478 (0.8861) acc 96.8750 (97.0312) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4247 (0.4246) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0674 (0.0609) teacher/usage_max 0.4806 (0.5234) teacher/usage_min 0.0491 (0.0815) teacher/usage_std 0.2010 (0.1910) nleep/row_max_mean 1502.4230 (1495.5753) nleep/row_max_std 60.8554 (66.5479) nleep/row_min_mean 1472.4307 (1467.3268) lr 2.7103e-04 eta 0:03:35
epoch [40/50] batch [80/203] time 0.095 (0.098) data 0.000 (0.005) loss 1.1362 (1.3163) teacher_loss 0.0203 (0.1125) loss_zs_kd 0.0872 (0.0756) loss_oracle 0.4796 (0.5581) kd_loss 0.8325 (0.8869) acc 100.0000 (97.0703) gate/entropy 1.0227 (1.0226) gate/usage_max 0.4247 (0.4246) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1220 (0.1221) teacher/entropy 0.0722 (0.0623) teacher/usage_max 0.5247 (0.5171) teacher/usage_min 0.0372 (0.0838) teacher/usage_std 0.2123 (0.1877) nleep/row_max_mean 1480.4816 (1495.5893) nleep/row_max_std 71.0321 (66.5373) nleep/row_min_mean 1453.8293 (1467.4841) lr 2.7103e-04 eta 0:03:30
epoch [40/50] batch [100/203] time 0.093 (0.097) data 0.000 (0.004) loss 1.3222 (1.3163) teacher_loss 0.1994 (0.1155) loss_zs_kd 0.0909 (0.0749) loss_oracle 0.4830 (0.5564) kd_loss 0.8358 (0.8852) acc 90.6250 (96.9688) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0727 (0.0628) teacher/usage_max 0.6554 (0.5200) teacher/usage_min 0.0375 (0.0826) teacher/usage_std 0.2529 (0.1889) nleep/row_max_mean 1505.1567 (1495.9316) nleep/row_max_std 57.3572 (66.4550) nleep/row_min_mean 1476.3354 (1467.8410) lr 2.7103e-04 eta 0:03:25
epoch [40/50] batch [120/203] time 0.146 (0.097) data 0.000 (0.003) loss 1.4058 (1.3153) teacher_loss 0.2730 (0.1152) loss_zs_kd 0.0552 (0.0748) loss_oracle 0.4766 (0.5566) kd_loss 0.8668 (0.8844) acc 87.5000 (96.9531) gate/entropy 1.0227 (1.0226) gate/usage_max 0.4247 (0.4246) gate/usage_min 0.1609 (0.1608) gate/usage_std 0.1220 (0.1221) teacher/entropy 0.0711 (0.0597) teacher/usage_max 0.5656 (0.5244) teacher/usage_min 0.0748 (0.0786) teacher/usage_std 0.2012 (0.1921) nleep/row_max_mean 1469.2549 (1495.8496) nleep/row_max_std 82.8782 (66.7557) nleep/row_min_mean 1446.8899 (1467.5478) lr 2.7103e-04 eta 0:03:24
epoch [40/50] batch [140/203] time 0.087 (0.096) data 0.000 (0.003) loss 1.2848 (1.3190) teacher_loss 0.0910 (0.1188) loss_zs_kd 0.0665 (0.0747) loss_oracle 0.5375 (0.5591) kd_loss 0.8919 (0.8832) acc 100.0000 (96.7634) gate/entropy 1.0228 (1.0226) gate/usage_max 0.4247 (0.4246) gate/usage_min 0.1610 (0.1608) gate/usage_std 0.1220 (0.1221) teacher/entropy 0.0398 (0.0590) teacher/usage_max 0.5393 (0.5262) teacher/usage_min 0.0643 (0.0766) teacher/usage_std 0.1990 (0.1937) nleep/row_max_mean 1479.0688 (1495.8163) nleep/row_max_std 72.9543 (66.3297) nleep/row_min_mean 1452.0250 (1467.4016) lr 2.7103e-04 eta 0:03:21
epoch [40/50] batch [160/203] time 0.085 (0.095) data 0.000 (0.002) loss 1.3966 (1.3180) teacher_loss 0.2016 (0.1201) loss_zs_kd 0.0640 (0.0746) loss_oracle 0.5409 (0.5577) kd_loss 0.8925 (0.8818) acc 96.8750 (96.7383) gate/entropy 1.0227 (1.0226) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1609 (0.1608) gate/usage_std 0.1220 (0.1221) teacher/entropy 0.0589 (0.0582) teacher/usage_max 0.5957 (0.5294) teacher/usage_min 0.0835 (0.0743) teacher/usage_std 0.2093 (0.1955) nleep/row_max_mean 1475.8911 (1495.8132) nleep/row_max_std 79.0096 (66.7596) nleep/row_min_mean 1451.2936 (1467.4208) lr 2.7103e-04 eta 0:03:16
epoch [40/50] batch [180/203] time 0.094 (0.094) data 0.000 (0.002) loss 1.2231 (1.3185) teacher_loss 0.0767 (0.1228) loss_zs_kd 0.0571 (0.0750) loss_oracle 0.5360 (0.5568) kd_loss 0.8498 (0.8798) acc 100.0000 (96.6840) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0315 (0.0564) teacher/usage_max 0.5636 (0.5301) teacher/usage_min 0.0117 (0.0703) teacher/usage_std 0.2344 (0.1976) nleep/row_max_mean 1501.0006 (1495.8258) nleep/row_max_std 56.9830 (66.5436) nleep/row_min_mean 1472.6119 (1467.2954) lr 2.7103e-04 eta 0:03:13
epoch [40/50] batch [200/203] time 0.084 (0.094) data 0.000 (0.002) loss 1.3060 (1.3186) teacher_loss 0.1337 (0.1254) loss_zs_kd 0.0758 (0.0748) loss_oracle 0.5403 (0.5549) kd_loss 0.8643 (0.8784) acc 96.8750 (96.6250) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4247 (0.4246) gate/usage_min 0.1608 (0.1608) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0344 (0.0552) teacher/usage_max 0.5163 (0.5311) teacher/usage_min 0.0309 (0.0676) teacher/usage_std 0.2154 (0.1994) nleep/row_max_mean 1511.0242 (1495.5371) nleep/row_max_std 44.9265 (66.6488) nleep/row_min_mean 1481.4597 (1466.9338) lr 2.7103e-04 eta 0:03:11
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,327
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [41/50] batch [20/203] time 0.089 (0.118) data 0.000 (0.019) loss 1.3518 (1.2889) teacher_loss 0.1198 (0.1152) loss_zs_kd 0.0699 (0.0698) loss_oracle 0.5997 (0.5421) kd_loss 0.8973 (0.8678) acc 96.8750 (96.8750) gate/entropy 1.0225 (1.0226) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1607 (0.1607) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0425 (0.0438) teacher/usage_max 0.5682 (0.5349) teacher/usage_min 0.0718 (0.0444) teacher/usage_std 0.2035 (0.2123) nleep/row_max_mean 1510.5979 (1500.6320) nleep/row_max_std 48.9200 (60.7773) nleep/row_min_mean 1481.0424 (1470.7173) lr 2.2949e-04 eta 0:03:56
epoch [41/50] batch [40/203] time 0.097 (0.114) data 0.000 (0.009) loss 1.2640 (1.3045) teacher_loss 0.0390 (0.1178) loss_zs_kd 0.0569 (0.0682) loss_oracle 0.5898 (0.5512) kd_loss 0.9017 (0.8770) acc 100.0000 (96.8750) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1608 (0.1607) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0370 (0.0447) teacher/usage_max 0.5899 (0.5375) teacher/usage_min 0.0703 (0.0549) teacher/usage_std 0.2122 (0.2071) nleep/row_max_mean 1483.4749 (1499.3525) nleep/row_max_std 78.6274 (64.1708) nleep/row_min_mean 1457.3486 (1469.5359) lr 2.2949e-04 eta 0:03:47
epoch [41/50] batch [60/203] time 0.077 (0.104) data 0.001 (0.006) loss 1.2342 (1.3078) teacher_loss 0.0751 (0.1188) loss_zs_kd 0.0647 (0.0692) loss_oracle 0.5607 (0.5542) kd_loss 0.8464 (0.8772) acc 100.0000 (96.8229) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1608 (0.1607) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0464 (0.0445) teacher/usage_max 0.5341 (0.5343) teacher/usage_min 0.0243 (0.0553) teacher/usage_std 0.2217 (0.2066) nleep/row_max_mean 1509.9797 (1499.4925) nleep/row_max_std 58.8624 (63.8293) nleep/row_min_mean 1475.8875 (1469.6758) lr 2.2949e-04 eta 0:03:24
epoch [41/50] batch [80/203] time 0.086 (0.099) data 0.000 (0.005) loss 1.2223 (1.3011) teacher_loss 0.0496 (0.1162) loss_zs_kd 0.0595 (0.0691) loss_oracle 0.5400 (0.5467) kd_loss 0.8730 (0.8769) acc 100.0000 (96.8750) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1608 (0.1607) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0377 (0.0442) teacher/usage_max 0.6950 (0.5420) teacher/usage_min 0.0392 (0.0548) teacher/usage_std 0.2720 (0.2092) nleep/row_max_mean 1489.6036 (1497.8697) nleep/row_max_std 65.9809 (64.7833) nleep/row_min_mean 1457.9258 (1468.2915) lr 2.2949e-04 eta 0:03:13
epoch [41/50] batch [100/203] time 0.102 (0.097) data 0.000 (0.004) loss 1.3143 (1.3009) teacher_loss 0.1403 (0.1171) loss_zs_kd 0.0666 (0.0706) loss_oracle 0.6083 (0.5480) kd_loss 0.8366 (0.8745) acc 93.7500 (96.8438) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1608 (0.1607) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0847 (0.0428) teacher/usage_max 0.5746 (0.5442) teacher/usage_min 0.0582 (0.0510) teacher/usage_std 0.2122 (0.2116) nleep/row_max_mean 1494.5311 (1497.6022) nleep/row_max_std 69.1681 (64.9735) nleep/row_min_mean 1462.3447 (1467.9993) lr 2.2949e-04 eta 0:03:06
epoch [41/50] batch [120/203] time 0.099 (0.096) data 0.000 (0.003) loss 1.3683 (1.3066) teacher_loss 0.1451 (0.1217) loss_zs_kd 0.0839 (0.0718) loss_oracle 0.5903 (0.5517) kd_loss 0.8861 (0.8732) acc 93.7500 (96.6406) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1608 (0.1607) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0162 (0.0422) teacher/usage_max 0.5310 (0.5449) teacher/usage_min 0.0341 (0.0488) teacher/usage_std 0.2152 (0.2130) nleep/row_max_mean 1492.5627 (1496.7419) nleep/row_max_std 68.5883 (65.2291) nleep/row_min_mean 1461.7083 (1467.0777) lr 2.2949e-04 eta 0:03:03
epoch [41/50] batch [140/203] time 0.090 (0.096) data 0.000 (0.003) loss 1.3180 (1.3070) teacher_loss 0.1364 (0.1200) loss_zs_kd 0.0807 (0.0723) loss_oracle 0.5528 (0.5553) kd_loss 0.8649 (0.8733) acc 96.8750 (96.7857) gate/entropy 1.0224 (1.0226) gate/usage_max 0.4245 (0.4246) gate/usage_min 0.1605 (0.1607) gate/usage_std 0.1222 (0.1221) teacher/entropy 0.0470 (0.0435) teacher/usage_max 0.4911 (0.5457) teacher/usage_min 0.0454 (0.0503) teacher/usage_std 0.2039 (0.2127) nleep/row_max_mean 1507.6025 (1497.0506) nleep/row_max_std 64.8450 (64.8290) nleep/row_min_mean 1477.6963 (1467.3162) lr 2.2949e-04 eta 0:03:00
epoch [41/50] batch [160/203] time 0.086 (0.095) data 0.000 (0.003) loss 1.2547 (1.3105) teacher_loss 0.0510 (0.1243) loss_zs_kd 0.0949 (0.0728) loss_oracle 0.6047 (0.5544) kd_loss 0.8539 (0.8726) acc 100.0000 (96.6016) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1607 (0.1607) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0229 (0.0431) teacher/usage_max 0.4995 (0.5460) teacher/usage_min 0.0086 (0.0491) teacher/usage_std 0.2296 (0.2136) nleep/row_max_mean 1505.5952 (1497.0691) nleep/row_max_std 54.2317 (64.9724) nleep/row_min_mean 1475.2732 (1467.2921) lr 2.2949e-04 eta 0:02:58
epoch [41/50] batch [180/203] time 0.083 (0.095) data 0.000 (0.002) loss 1.1711 (1.3127) teacher_loss 0.0854 (0.1268) loss_zs_kd 0.0847 (0.0734) loss_oracle 0.4623 (0.5539) kd_loss 0.8122 (0.8722) acc 96.8750 (96.5625) gate/entropy 1.0226 (1.0226) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1607 (0.1607) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0665 (0.0436) teacher/usage_max 0.5004 (0.5477) teacher/usage_min 0.0108 (0.0491) teacher/usage_std 0.2281 (0.2140) nleep/row_max_mean 1501.1803 (1497.4316) nleep/row_max_std 68.7542 (64.4721) nleep/row_min_mean 1470.4906 (1467.5785) lr 2.2949e-04 eta 0:02:56
epoch [41/50] batch [200/203] time 0.084 (0.095) data 0.000 (0.002) loss 1.3813 (1.3090) teacher_loss 0.1571 (0.1241) loss_zs_kd 0.1221 (0.0736) loss_oracle 0.6021 (0.5534) kd_loss 0.8621 (0.8715) acc 96.8750 (96.6562) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4245 (0.4246) gate/usage_min 0.1607 (0.1607) gate/usage_std 0.1222 (0.1221) teacher/entropy 0.0120 (0.0435) teacher/usage_max 0.7464 (0.5489) teacher/usage_min 0.0001 (0.0483) teacher/usage_std 0.3099 (0.2146) nleep/row_max_mean 1495.4236 (1497.8187) nleep/row_max_std 67.1168 (64.1438) nleep/row_min_mean 1462.7451 (1467.9435) lr 2.2949e-04 eta 0:02:52
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,332
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [42/50] batch [20/203] time 0.081 (0.090) data 0.000 (0.015) loss 1.2589 (1.2914) teacher_loss 0.0439 (0.1247) loss_zs_kd 0.0716 (0.0710) loss_oracle 0.5491 (0.5434) kd_loss 0.9047 (0.8596) acc 100.0000 (96.4062) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.0240 (0.0504) teacher/usage_max 0.4715 (0.5238) teacher/usage_min 0.0629 (0.0438) teacher/usage_std 0.1913 (0.2097) nleep/row_max_mean 1518.3739 (1500.0579) nleep/row_max_std 29.4739 (63.6304) nleep/row_min_mean 1484.6290 (1468.9541) lr 1.9098e-04 eta 0:02:42
epoch [42/50] batch [40/203] time 0.062 (0.080) data 0.000 (0.007) loss 1.3717 (1.2911) teacher_loss 0.0992 (0.1155) loss_zs_kd 0.0618 (0.0719) loss_oracle 0.6102 (0.5445) kd_loss 0.9365 (0.8674) acc 96.8750 (96.9531) gate/entropy 1.0226 (1.0225) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1607 (0.1607) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.0299 (0.0495) teacher/usage_max 0.5540 (0.5278) teacher/usage_min 0.1002 (0.0504) teacher/usage_std 0.1854 (0.2064) nleep/row_max_mean 1502.9862 (1499.6614) nleep/row_max_std 53.4776 (61.9623) nleep/row_min_mean 1472.8796 (1469.2636) lr 1.9098e-04 eta 0:02:23
epoch [42/50] batch [60/203] time 0.092 (0.078) data 0.000 (0.005) loss 1.2944 (1.2996) teacher_loss 0.1268 (0.1199) loss_zs_kd 0.0936 (0.0723) loss_oracle 0.5228 (0.5476) kd_loss 0.8594 (0.8697) acc 96.8750 (96.6667) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4245 (0.4246) gate/usage_min 0.1606 (0.1607) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0428 (0.0501) teacher/usage_max 0.6388 (0.5335) teacher/usage_min 0.0318 (0.0535) teacher/usage_std 0.2478 (0.2070) nleep/row_max_mean 1501.7035 (1498.5057) nleep/row_max_std 65.4847 (64.0141) nleep/row_min_mean 1469.2583 (1468.3701) lr 1.9098e-04 eta 0:02:17
epoch [42/50] batch [80/203] time 0.065 (0.077) data 0.000 (0.004) loss 1.5023 (1.3074) teacher_loss 0.2420 (0.1235) loss_zs_kd 0.0695 (0.0724) loss_oracle 0.5836 (0.5460) kd_loss 0.9337 (0.8746) acc 93.7500 (96.5625) gate/entropy 1.0224 (1.0225) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1606 (0.1607) gate/usage_std 0.1222 (0.1221) teacher/entropy 0.0685 (0.0494) teacher/usage_max 0.5266 (0.5372) teacher/usage_min 0.1375 (0.0576) teacher/usage_std 0.1588 (0.2065) nleep/row_max_mean 1505.4460 (1497.9546) nleep/row_max_std 53.7124 (63.4922) nleep/row_min_mean 1478.5892 (1468.1443) lr 1.9098e-04 eta 0:02:14
epoch [42/50] batch [100/203] time 0.095 (0.077) data 0.000 (0.003) loss 1.4938 (1.3154) teacher_loss 0.2349 (0.1314) loss_zs_kd 0.0833 (0.0721) loss_oracle 0.5255 (0.5484) kd_loss 0.9545 (0.8738) acc 93.7500 (96.4375) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1607 (0.1607) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0748 (0.0502) teacher/usage_max 0.4729 (0.5386) teacher/usage_min 0.1665 (0.0576) teacher/usage_std 0.1266 (0.2067) nleep/row_max_mean 1506.3091 (1498.0630) nleep/row_max_std 52.5757 (63.2012) nleep/row_min_mean 1476.3229 (1468.3467) lr 1.9098e-04 eta 0:02:12
epoch [42/50] batch [120/203] time 0.094 (0.080) data 0.000 (0.003) loss 1.2812 (1.3185) teacher_loss 0.0866 (0.1357) loss_zs_kd 0.0755 (0.0724) loss_oracle 0.5256 (0.5512) kd_loss 0.8941 (0.8710) acc 100.0000 (96.4062) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1607 (0.1607) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0770 (0.0507) teacher/usage_max 0.5082 (0.5399) teacher/usage_min 0.1057 (0.0552) teacher/usage_std 0.1685 (0.2080) nleep/row_max_mean 1490.5984 (1497.2511) nleep/row_max_std 69.1102 (63.8257) nleep/row_min_mean 1463.0394 (1467.6415) lr 1.9098e-04 eta 0:02:16
epoch [42/50] batch [140/203] time 0.101 (0.082) data 0.001 (0.002) loss 1.3073 (1.3180) teacher_loss 0.1850 (0.1357) loss_zs_kd 0.0547 (0.0722) loss_oracle 0.5502 (0.5529) kd_loss 0.8199 (0.8697) acc 93.7500 (96.4062) gate/entropy 1.0226 (1.0225) gate/usage_max 0.4245 (0.4246) gate/usage_min 0.1608 (0.1607) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0679 (0.0507) teacher/usage_max 0.5853 (0.5427) teacher/usage_min 0.0181 (0.0538) teacher/usage_std 0.2358 (0.2094) nleep/row_max_mean 1476.1467 (1497.0647) nleep/row_max_std 77.3694 (63.6260) nleep/row_min_mean 1449.3162 (1467.4573) lr 1.9098e-04 eta 0:02:18
epoch [42/50] batch [160/203] time 0.098 (0.085) data 0.000 (0.002) loss 1.4095 (1.3158) teacher_loss 0.2010 (0.1340) loss_zs_kd 0.0863 (0.0719) loss_oracle 0.6043 (0.5528) kd_loss 0.8632 (0.8695) acc 93.7500 (96.4648) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4246 (0.4246) gate/usage_min 0.1607 (0.1607) gate/usage_std 0.1222 (0.1221) teacher/entropy 0.0074 (0.0494) teacher/usage_max 0.5309 (0.5419) teacher/usage_min 0.0015 (0.0522) teacher/usage_std 0.2360 (0.2101) nleep/row_max_mean 1490.1052 (1496.8300) nleep/row_max_std 72.2567 (63.8897) nleep/row_min_mean 1455.0447 (1467.1520) lr 1.9098e-04 eta 0:02:21
epoch [42/50] batch [180/203] time 0.082 (0.085) data 0.000 (0.002) loss 1.3859 (1.3131) teacher_loss 0.2525 (0.1348) loss_zs_kd 0.0765 (0.0721) loss_oracle 0.5118 (0.5510) kd_loss 0.8392 (0.8668) acc 90.6250 (96.4062) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4245 (0.4246) gate/usage_min 0.1607 (0.1607) gate/usage_std 0.1221 (0.1221) teacher/entropy 0.0721 (0.0499) teacher/usage_max 0.4841 (0.5425) teacher/usage_min 0.0445 (0.0499) teacher/usage_std 0.2043 (0.2115) nleep/row_max_mean 1471.0129 (1496.5852) nleep/row_max_std 91.8902 (64.4965) nleep/row_min_mean 1442.1335 (1466.8775) lr 1.9098e-04 eta 0:02:20
epoch [42/50] batch [200/203] time 0.083 (0.085) data 0.000 (0.002) loss 1.2005 (1.3096) teacher_loss 0.0522 (0.1314) loss_zs_kd 0.0548 (0.0719) loss_oracle 0.5177 (0.5506) kd_loss 0.8620 (0.8669) acc 100.0000 (96.5312) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1607) gate/usage_std 0.1222 (0.1221) teacher/entropy 0.0411 (0.0498) teacher/usage_max 0.4856 (0.5424) teacher/usage_min 0.0363 (0.0500) teacher/usage_std 0.2101 (0.2116) nleep/row_max_mean 1498.9429 (1496.3815) nleep/row_max_std 61.4455 (64.4698) nleep/row_min_mean 1467.8068 (1466.6835) lr 1.9098e-04 eta 0:02:17
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,326
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [43/50] batch [20/203] time 0.095 (0.107) data 0.000 (0.014) loss 1.3178 (1.3155) teacher_loss 0.1385 (0.1200) loss_zs_kd 0.0804 (0.0706) loss_oracle 0.5459 (0.5647) kd_loss 0.8661 (0.8779) acc 93.7500 (96.0938) gate/entropy 1.0226 (1.0225) gate/usage_max 0.4246 (0.4245) gate/usage_min 0.1608 (0.1607) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.0635 (0.0448) teacher/usage_max 0.5479 (0.5537) teacher/usage_min 0.0617 (0.0563) teacher/usage_std 0.2025 (0.2116) nleep/row_max_mean 1493.7401 (1494.5964) nleep/row_max_std 56.7488 (65.8362) nleep/row_min_mean 1467.7084 (1464.6475) lr 1.5567e-04 eta 0:02:51
epoch [43/50] batch [40/203] time 0.097 (0.102) data 0.000 (0.007) loss 1.2670 (1.3178) teacher_loss 0.1092 (0.1283) loss_zs_kd 0.0568 (0.0691) loss_oracle 0.5078 (0.5594) kd_loss 0.8755 (0.8753) acc 93.7500 (95.9375) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4246 (0.4245) gate/usage_min 0.1606 (0.1607) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0327 (0.0458) teacher/usage_max 0.5806 (0.5486) teacher/usage_min 0.0445 (0.0547) teacher/usage_std 0.2209 (0.2108) nleep/row_max_mean 1509.1824 (1493.8558) nleep/row_max_std 54.2714 (64.8157) nleep/row_min_mean 1480.4575 (1464.0888) lr 1.5567e-04 eta 0:02:41
epoch [43/50] batch [60/203] time 0.098 (0.099) data 0.000 (0.005) loss 1.2213 (1.3091) teacher_loss 0.0972 (0.1253) loss_zs_kd 0.0835 (0.0697) loss_oracle 0.4943 (0.5597) kd_loss 0.8351 (0.8690) acc 96.8750 (96.2500) gate/entropy 1.0224 (1.0225) gate/usage_max 0.4244 (0.4245) gate/usage_min 0.1605 (0.1607) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0416 (0.0489) teacher/usage_max 0.5392 (0.5498) teacher/usage_min 0.0079 (0.0514) teacher/usage_std 0.2328 (0.2131) nleep/row_max_mean 1489.0797 (1491.9970) nleep/row_max_std 65.9888 (66.0327) nleep/row_min_mean 1459.0726 (1462.4494) lr 1.5567e-04 eta 0:02:35
epoch [43/50] batch [80/203] time 0.100 (0.098) data 0.000 (0.004) loss 1.2816 (1.3058) teacher_loss 0.0627 (0.1258) loss_zs_kd 0.0635 (0.0702) loss_oracle 0.5779 (0.5590) kd_loss 0.8981 (0.8654) acc 96.8750 (96.4844) gate/entropy 1.0224 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1607) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0906 (0.0499) teacher/usage_max 0.4680 (0.5451) teacher/usage_min 0.1251 (0.0488) teacher/usage_std 0.1493 (0.2132) nleep/row_max_mean 1479.0045 (1492.8671) nleep/row_max_std 93.9002 (65.5871) nleep/row_min_mean 1451.7791 (1463.4563) lr 1.5567e-04 eta 0:02:31
epoch [43/50] batch [100/203] time 0.091 (0.099) data 0.000 (0.003) loss 1.3384 (1.3063) teacher_loss 0.0837 (0.1231) loss_zs_kd 0.0714 (0.0723) loss_oracle 0.6259 (0.5590) kd_loss 0.9060 (0.8676) acc 96.8750 (96.6875) gate/entropy 1.0224 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0370 (0.0485) teacher/usage_max 0.4988 (0.5446) teacher/usage_min 0.0771 (0.0497) teacher/usage_std 0.1837 (0.2123) nleep/row_max_mean 1502.4270 (1494.6453) nleep/row_max_std 61.7896 (64.1091) nleep/row_min_mean 1471.6990 (1465.0685) lr 1.5567e-04 eta 0:02:30
epoch [43/50] batch [120/203] time 0.095 (0.098) data 0.000 (0.003) loss 1.3083 (1.3064) teacher_loss 0.1187 (0.1243) loss_zs_kd 0.0777 (0.0735) loss_oracle 0.5323 (0.5595) kd_loss 0.8846 (0.8656) acc 96.8750 (96.6146) gate/entropy 1.0226 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1608 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.0374 (0.0489) teacher/usage_max 0.5688 (0.5447) teacher/usage_min 0.0534 (0.0480) teacher/usage_std 0.2128 (0.2132) nleep/row_max_mean 1497.3711 (1494.8975) nleep/row_max_std 58.8551 (64.1049) nleep/row_min_mean 1466.6233 (1465.3121) lr 1.5567e-04 eta 0:02:28
epoch [43/50] batch [140/203] time 0.089 (0.098) data 0.000 (0.002) loss 1.3191 (1.3058) teacher_loss 0.0732 (0.1222) loss_zs_kd 0.0694 (0.0732) loss_oracle 0.6425 (0.5611) kd_loss 0.8900 (0.8664) acc 96.8750 (96.6518) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0596 (0.0489) teacher/usage_max 0.5286 (0.5450) teacher/usage_min 0.0827 (0.0487) teacher/usage_std 0.1862 (0.2129) nleep/row_max_mean 1479.7594 (1494.5582) nleep/row_max_std 77.1654 (64.0037) nleep/row_min_mean 1452.8429 (1465.0693) lr 1.5567e-04 eta 0:02:25
epoch [43/50] batch [160/203] time 0.093 (0.097) data 0.000 (0.002) loss 1.2668 (1.3077) teacher_loss 0.1237 (0.1247) loss_zs_kd 0.0697 (0.0734) loss_oracle 0.5153 (0.5573) kd_loss 0.8506 (0.8676) acc 100.0000 (96.6406) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0614 (0.0484) teacher/usage_max 0.6276 (0.5466) teacher/usage_min 0.0418 (0.0494) teacher/usage_std 0.2391 (0.2130) nleep/row_max_mean 1481.4399 (1494.2435) nleep/row_max_std 79.8411 (64.1540) nleep/row_min_mean 1449.2598 (1464.7472) lr 1.5567e-04 eta 0:02:22
epoch [43/50] batch [180/203] time 0.095 (0.097) data 0.000 (0.002) loss 1.2199 (1.3052) teacher_loss 0.0568 (0.1242) loss_zs_kd 0.0659 (0.0736) loss_oracle 0.5181 (0.5564) kd_loss 0.8711 (0.8660) acc 96.8750 (96.6319) gate/entropy 1.0226 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.0562 (0.0481) teacher/usage_max 0.4779 (0.5457) teacher/usage_min 0.0612 (0.0475) teacher/usage_std 0.1926 (0.2137) nleep/row_max_mean 1466.4059 (1493.8225) nleep/row_max_std 82.2404 (64.1964) nleep/row_min_mean 1440.9547 (1464.4162) lr 1.5567e-04 eta 0:02:20
epoch [43/50] batch [200/203] time 0.078 (0.097) data 0.000 (0.002) loss 1.1814 (1.3021) teacher_loss 0.0548 (0.1236) loss_zs_kd 0.0791 (0.0734) loss_oracle 0.5391 (0.5534) kd_loss 0.8175 (0.8651) acc 100.0000 (96.6562) gate/entropy 1.0224 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0530 (0.0486) teacher/usage_max 0.5094 (0.5459) teacher/usage_min 0.0025 (0.0470) teacher/usage_std 0.2341 (0.2139) nleep/row_max_mean 1484.6907 (1493.4798) nleep/row_max_std 77.3929 (64.5707) nleep/row_min_mean 1455.6960 (1464.1240) lr 1.5567e-04 eta 0:02:17
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,325
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [44/50] batch [20/203] time 0.114 (0.117) data 0.000 (0.016) loss 1.3601 (1.3289) teacher_loss 0.2141 (0.1374) loss_zs_kd 0.0635 (0.0790) loss_oracle 0.4357 (0.5468) kd_loss 0.8964 (0.8786) acc 93.7500 (96.5625) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.0367 (0.0407) teacher/usage_max 0.6405 (0.5448) teacher/usage_min 0.0636 (0.0524) teacher/usage_std 0.2370 (0.2109) nleep/row_max_mean 1486.9976 (1494.8054) nleep/row_max_std 70.7511 (60.3108) nleep/row_min_mean 1459.1969 (1464.5557) lr 1.2369e-04 eta 0:02:44
epoch [44/50] batch [40/203] time 0.088 (0.108) data 0.000 (0.008) loss 1.2350 (1.3139) teacher_loss 0.0737 (0.1247) loss_zs_kd 0.0598 (0.0759) loss_oracle 0.5637 (0.5567) kd_loss 0.8496 (0.8729) acc 96.8750 (96.8750) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.0477 (0.0476) teacher/usage_max 0.5076 (0.5467) teacher/usage_min 0.0293 (0.0537) teacher/usage_std 0.2158 (0.2105) nleep/row_max_mean 1485.3850 (1491.6219) nleep/row_max_std 70.9583 (64.5241) nleep/row_min_mean 1454.4858 (1462.0644) lr 1.2369e-04 eta 0:02:28
epoch [44/50] batch [60/203] time 0.109 (0.105) data 0.001 (0.005) loss 1.0984 (1.3176) teacher_loss 0.0304 (0.1259) loss_zs_kd 0.0418 (0.0761) loss_oracle 0.4888 (0.5601) kd_loss 0.8027 (0.8735) acc 100.0000 (96.7188) gate/entropy 1.0224 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0870 (0.0483) teacher/usage_max 0.5476 (0.5428) teacher/usage_min 0.0237 (0.0552) teacher/usage_std 0.2243 (0.2089) nleep/row_max_mean 1494.8641 (1492.1996) nleep/row_max_std 73.0297 (64.7607) nleep/row_min_mean 1465.8909 (1462.6192) lr 1.2369e-04 eta 0:02:22
epoch [44/50] batch [80/203] time 0.096 (0.103) data 0.000 (0.004) loss 1.3536 (1.3131) teacher_loss 0.1709 (0.1239) loss_zs_kd 0.0689 (0.0756) loss_oracle 0.5673 (0.5621) kd_loss 0.8646 (0.8704) acc 93.7500 (96.6406) gate/entropy 1.0224 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0368 (0.0481) teacher/usage_max 0.5669 (0.5469) teacher/usage_min 0.0365 (0.0518) teacher/usage_std 0.2211 (0.2121) nleep/row_max_mean 1484.6052 (1493.1585) nleep/row_max_std 73.4498 (64.6987) nleep/row_min_mean 1456.8506 (1463.2343) lr 1.2369e-04 eta 0:02:17
epoch [44/50] batch [100/203] time 0.096 (0.101) data 0.000 (0.003) loss 1.3492 (1.3093) teacher_loss 0.2188 (0.1212) loss_zs_kd 0.0765 (0.0755) loss_oracle 0.5876 (0.5621) kd_loss 0.7984 (0.8693) acc 93.7500 (96.8125) gate/entropy 1.0224 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0795 (0.0496) teacher/usage_max 0.5114 (0.5448) teacher/usage_min 0.0101 (0.0522) teacher/usage_std 0.2290 (0.2111) nleep/row_max_mean 1478.6622 (1493.9956) nleep/row_max_std 82.2144 (65.0142) nleep/row_min_mean 1449.9064 (1464.0596) lr 1.2369e-04 eta 0:02:13
epoch [44/50] batch [120/203] time 0.099 (0.100) data 0.000 (0.003) loss 1.2353 (1.3026) teacher_loss 0.0767 (0.1173) loss_zs_kd 0.0659 (0.0751) loss_oracle 0.5687 (0.5570) kd_loss 0.8414 (0.8692) acc 96.8750 (96.9010) gate/entropy 1.0224 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0587 (0.0495) teacher/usage_max 0.5277 (0.5467) teacher/usage_min 0.0342 (0.0521) teacher/usage_std 0.2147 (0.2119) nleep/row_max_mean 1494.6249 (1494.2428) nleep/row_max_std 61.8976 (65.0576) nleep/row_min_mean 1466.0448 (1464.4080) lr 1.2369e-04 eta 0:02:10
epoch [44/50] batch [140/203] time 0.101 (0.100) data 0.000 (0.002) loss 1.1503 (1.3016) teacher_loss 0.0213 (0.1170) loss_zs_kd 0.0575 (0.0749) loss_oracle 0.4638 (0.5556) kd_loss 0.8684 (0.8693) acc 100.0000 (97.0089) gate/entropy 1.0226 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.0464 (0.0487) teacher/usage_max 0.5673 (0.5481) teacher/usage_min 0.0461 (0.0514) teacher/usage_std 0.2161 (0.2126) nleep/row_max_mean 1478.8752 (1494.1623) nleep/row_max_std 61.7469 (64.5946) nleep/row_min_mean 1451.6724 (1464.3247) lr 1.2369e-04 eta 0:02:07
epoch [44/50] batch [160/203] time 0.092 (0.099) data 0.000 (0.002) loss 1.2709 (1.2978) teacher_loss 0.0431 (0.1143) loss_zs_kd 0.0656 (0.0742) loss_oracle 0.5830 (0.5534) kd_loss 0.9035 (0.8697) acc 100.0000 (97.1289) gate/entropy 1.0226 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.0499 (0.0491) teacher/usage_max 0.5863 (0.5467) teacher/usage_min 0.0919 (0.0523) teacher/usage_std 0.2020 (0.2115) nleep/row_max_mean 1491.9480 (1493.8344) nleep/row_max_std 52.0652 (65.0707) nleep/row_min_mean 1464.3271 (1464.0301) lr 1.2369e-04 eta 0:02:04
epoch [44/50] batch [180/203] time 0.093 (0.099) data 0.000 (0.002) loss 1.3311 (1.2990) teacher_loss 0.1466 (0.1142) loss_zs_kd 0.0626 (0.0744) loss_oracle 0.5592 (0.5552) kd_loss 0.8736 (0.8700) acc 96.8750 (97.0833) gate/entropy 1.0225 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.0258 (0.0484) teacher/usage_max 0.5580 (0.5459) teacher/usage_min 0.0342 (0.0520) teacher/usage_std 0.2202 (0.2116) nleep/row_max_mean 1498.2837 (1494.0369) nleep/row_max_std 56.7212 (64.4678) nleep/row_min_mean 1467.7869 (1464.1516) lr 1.2369e-04 eta 0:02:02
epoch [44/50] batch [200/203] time 0.088 (0.098) data 0.000 (0.002) loss 1.4038 (1.3014) teacher_loss 0.1611 (0.1165) loss_zs_kd 0.0645 (0.0747) loss_oracle 0.5806 (0.5546) kd_loss 0.9202 (0.8702) acc 96.8750 (97.0625) gate/entropy 1.0224 (1.0225) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0070 (0.0480) teacher/usage_max 0.5304 (0.5454) teacher/usage_min 0.0632 (0.0518) teacher/usage_std 0.1976 (0.2115) nleep/row_max_mean 1497.1748 (1494.3219) nleep/row_max_std 66.1563 (64.0963) nleep/row_min_mean 1466.6458 (1464.3886) lr 1.2369e-04 eta 0:01:59
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,333
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [45/50] batch [20/203] time 0.094 (0.114) data 0.000 (0.016) loss 1.1343 (1.3390) teacher_loss 0.0445 (0.1450) loss_zs_kd 0.0589 (0.0792) loss_oracle 0.4705 (0.5680) kd_loss 0.8251 (0.8704) acc 100.0000 (96.4062) gate/entropy 1.0225 (1.0224) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.1187 (0.0552) teacher/usage_max 0.4959 (0.5239) teacher/usage_min 0.0778 (0.0599) teacher/usage_std 0.1829 (0.2010) nleep/row_max_mean 1494.1084 (1494.8447) nleep/row_max_std 63.5833 (65.4361) nleep/row_min_mean 1463.9724 (1464.5124) lr 9.5173e-05 eta 0:02:16
epoch [45/50] batch [40/203] time 0.091 (0.104) data 0.000 (0.008) loss 1.3325 (1.3254) teacher_loss 0.1555 (0.1404) loss_zs_kd 0.0629 (0.0784) loss_oracle 0.5579 (0.5573) kd_loss 0.8666 (0.8671) acc 93.7500 (96.4844) gate/entropy 1.0226 (1.0224) gate/usage_max 0.4246 (0.4245) gate/usage_min 0.1608 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.1019 (0.0581) teacher/usage_max 0.5479 (0.5254) teacher/usage_min 0.1068 (0.0594) teacher/usage_std 0.1803 (0.2022) nleep/row_max_mean 1481.4773 (1493.5900) nleep/row_max_std 71.9060 (65.0647) nleep/row_min_mean 1452.9443 (1463.7269) lr 9.5173e-05 eta 0:02:02
epoch [45/50] batch [60/203] time 0.092 (0.102) data 0.001 (0.006) loss 1.4010 (1.3201) teacher_loss 0.2191 (0.1378) loss_zs_kd 0.0886 (0.0761) loss_oracle 0.5775 (0.5514) kd_loss 0.8488 (0.8685) acc 93.7500 (96.4583) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0226 (0.0544) teacher/usage_max 0.6189 (0.5278) teacher/usage_min 0.0063 (0.0571) teacher/usage_std 0.2518 (0.2037) nleep/row_max_mean 1507.7183 (1494.0723) nleep/row_max_std 41.5386 (63.6009) nleep/row_min_mean 1477.6666 (1464.2973) lr 9.5173e-05 eta 0:01:57
epoch [45/50] batch [80/203] time 0.091 (0.103) data 0.000 (0.004) loss 1.2244 (1.3126) teacher_loss 0.0967 (0.1316) loss_zs_kd 0.0655 (0.0741) loss_oracle 0.5061 (0.5477) kd_loss 0.8420 (0.8701) acc 93.7500 (96.7188) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0703 (0.0533) teacher/usage_max 0.5845 (0.5352) teacher/usage_min 0.0483 (0.0573) teacher/usage_std 0.2202 (0.2054) nleep/row_max_mean 1490.0972 (1494.0139) nleep/row_max_std 70.4116 (62.7106) nleep/row_min_mean 1462.8221 (1464.4177) lr 9.5173e-05 eta 0:01:57
epoch [45/50] batch [100/203] time 0.096 (0.101) data 0.000 (0.004) loss 1.2652 (1.3182) teacher_loss 0.0708 (0.1372) loss_zs_kd 0.0650 (0.0734) loss_oracle 0.5637 (0.5491) kd_loss 0.8801 (0.8698) acc 96.8750 (96.5312) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0688 (0.0535) teacher/usage_max 0.5064 (0.5369) teacher/usage_min 0.0853 (0.0571) teacher/usage_std 0.1799 (0.2060) nleep/row_max_mean 1486.7893 (1493.5106) nleep/row_max_std 71.6048 (63.0830) nleep/row_min_mean 1462.0182 (1463.9783) lr 9.5173e-05 eta 0:01:53
epoch [45/50] batch [120/203] time 0.091 (0.100) data 0.000 (0.003) loss 1.3462 (1.3214) teacher_loss 0.0786 (0.1385) loss_zs_kd 0.0585 (0.0739) loss_oracle 0.6009 (0.5524) kd_loss 0.9378 (0.8697) acc 96.8750 (96.4062) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0564 (0.0535) teacher/usage_max 0.5119 (0.5352) teacher/usage_min 0.1330 (0.0571) teacher/usage_std 0.1555 (0.2056) nleep/row_max_mean 1500.2271 (1493.8892) nleep/row_max_std 58.4263 (62.8315) nleep/row_min_mean 1473.2357 (1464.3510) lr 9.5173e-05 eta 0:01:49
epoch [45/50] batch [140/203] time 0.094 (0.099) data 0.000 (0.003) loss 1.4225 (1.3262) teacher_loss 0.1973 (0.1398) loss_zs_kd 0.0907 (0.0739) loss_oracle 0.5723 (0.5554) kd_loss 0.8937 (0.8718) acc 93.7500 (96.3616) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0985 (0.0542) teacher/usage_max 0.4738 (0.5335) teacher/usage_min 0.1288 (0.0598) teacher/usage_std 0.1480 (0.2034) nleep/row_max_mean 1493.2268 (1493.9481) nleep/row_max_std 60.0470 (62.4775) nleep/row_min_mean 1465.4293 (1464.4013) lr 9.5173e-05 eta 0:01:47
epoch [45/50] batch [160/203] time 0.092 (0.099) data 0.000 (0.002) loss 1.2155 (1.3217) teacher_loss 0.1012 (0.1367) loss_zs_kd 0.0939 (0.0743) loss_oracle 0.5280 (0.5561) kd_loss 0.8033 (0.8697) acc 96.8750 (96.3867) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4245) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0805 (0.0554) teacher/usage_max 0.5422 (0.5343) teacher/usage_min 0.0176 (0.0589) teacher/usage_std 0.2271 (0.2042) nleep/row_max_mean 1499.3037 (1494.1498) nleep/row_max_std 67.6695 (62.5062) nleep/row_min_mean 1469.9088 (1464.5380) lr 9.5173e-05 eta 0:01:44
epoch [45/50] batch [180/203] time 0.089 (0.098) data 0.000 (0.002) loss 1.1884 (1.3197) teacher_loss 0.0724 (0.1348) loss_zs_kd 0.0627 (0.0743) loss_oracle 0.5140 (0.5555) kd_loss 0.8276 (0.8700) acc 96.8750 (96.4583) gate/entropy 1.0225 (1.0224) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0931 (0.0554) teacher/usage_max 0.5955 (0.5352) teacher/usage_min 0.0574 (0.0593) teacher/usage_std 0.2199 (0.2041) nleep/row_max_mean 1496.1787 (1494.5810) nleep/row_max_std 47.6021 (62.0147) nleep/row_min_mean 1470.8948 (1464.9607) lr 9.5173e-05 eta 0:01:42
epoch [45/50] batch [200/203] time 0.088 (0.098) data 0.000 (0.002) loss 1.1847 (1.3141) teacher_loss 0.0227 (0.1314) loss_zs_kd 0.0752 (0.0740) loss_oracle 0.5483 (0.5526) kd_loss 0.8503 (0.8694) acc 100.0000 (96.5312) gate/entropy 1.0225 (1.0224) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0539 (0.0564) teacher/usage_max 0.4928 (0.5349) teacher/usage_min 0.0371 (0.0597) teacher/usage_std 0.2097 (0.2039) nleep/row_max_mean 1487.6182 (1494.6983) nleep/row_max_std 73.6964 (62.2627) nleep/row_min_mean 1456.8450 (1465.1096) lr 9.5173e-05 eta 0:01:39
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,325
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [46/50] batch [20/203] time 0.088 (0.112) data 0.000 (0.014) loss 1.2947 (1.2844) teacher_loss 0.0891 (0.1080) loss_zs_kd 0.0784 (0.0741) loss_oracle 0.5622 (0.5585) kd_loss 0.8853 (0.8600) acc 96.8750 (96.8750) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4245) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0674 (0.0705) teacher/usage_max 0.5475 (0.5472) teacher/usage_min 0.0900 (0.0646) teacher/usage_std 0.1879 (0.2043) nleep/row_max_mean 1498.3818 (1493.5480) nleep/row_max_std 65.7210 (64.6886) nleep/row_min_mean 1468.7073 (1464.3019) lr 7.0224e-05 eta 0:01:51
epoch [46/50] batch [40/203] time 0.088 (0.103) data 0.000 (0.007) loss 1.2030 (1.2885) teacher_loss 0.0747 (0.1013) loss_zs_kd 0.0681 (0.0754) loss_oracle 0.4876 (0.5596) kd_loss 0.8504 (0.8697) acc 96.8750 (97.3438) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4245) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0580 (0.0609) teacher/usage_max 0.5240 (0.5424) teacher/usage_min 0.0428 (0.0649) teacher/usage_std 0.2088 (0.2024) nleep/row_max_mean 1494.9023 (1496.1216) nleep/row_max_std 74.4801 (62.2929) nleep/row_min_mean 1466.5530 (1466.4019) lr 7.0224e-05 eta 0:01:39
epoch [46/50] batch [60/203] time 0.099 (0.099) data 0.000 (0.005) loss 1.5713 (1.3001) teacher_loss 0.4202 (0.1181) loss_zs_kd 0.0766 (0.0750) loss_oracle 0.5344 (0.5583) kd_loss 0.8457 (0.8653) acc 84.3750 (96.8750) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4245) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0691 (0.0625) teacher/usage_max 0.7091 (0.5380) teacher/usage_min 0.0432 (0.0620) teacher/usage_std 0.2785 (0.2033) nleep/row_max_mean 1493.6284 (1494.8910) nleep/row_max_std 77.1141 (64.2328) nleep/row_min_mean 1465.0703 (1465.3421) lr 7.0224e-05 eta 0:01:34
epoch [46/50] batch [80/203] time 0.088 (0.097) data 0.000 (0.004) loss 1.3230 (1.2989) teacher_loss 0.0871 (0.1175) loss_zs_kd 0.0820 (0.0741) loss_oracle 0.5976 (0.5538) kd_loss 0.8961 (0.8675) acc 96.8750 (96.8750) gate/entropy 1.0225 (1.0224) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0350 (0.0609) teacher/usage_max 0.5354 (0.5370) teacher/usage_min 0.0640 (0.0625) teacher/usage_std 0.1982 (0.2026) nleep/row_max_mean 1501.7977 (1496.2473) nleep/row_max_std 56.7312 (63.1536) nleep/row_min_mean 1472.6746 (1466.5648) lr 7.0224e-05 eta 0:01:31
epoch [46/50] batch [100/203] time 0.107 (0.097) data 0.000 (0.003) loss 1.2866 (1.3143) teacher_loss 0.1686 (0.1258) loss_zs_kd 0.0861 (0.0749) loss_oracle 0.5123 (0.5577) kd_loss 0.8188 (0.8723) acc 96.8750 (96.7188) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0614 (0.0603) teacher/usage_max 0.5640 (0.5332) teacher/usage_min 0.0105 (0.0666) teacher/usage_std 0.2352 (0.1994) nleep/row_max_mean 1495.0104 (1495.6380) nleep/row_max_std 67.7576 (63.7101) nleep/row_min_mean 1464.0054 (1465.9674) lr 7.0224e-05 eta 0:01:29
epoch [46/50] batch [120/203] time 0.090 (0.097) data 0.000 (0.003) loss 1.2814 (1.3149) teacher_loss 0.1110 (0.1258) loss_zs_kd 0.0537 (0.0742) loss_oracle 0.5521 (0.5568) kd_loss 0.8676 (0.8736) acc 96.8750 (96.5625) gate/entropy 1.0225 (1.0224) gate/usage_max 0.4245 (0.4245) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.0648 (0.0611) teacher/usage_max 0.5353 (0.5318) teacher/usage_min 0.0651 (0.0688) teacher/usage_std 0.1976 (0.1981) nleep/row_max_mean 1476.4985 (1494.5124) nleep/row_max_std 77.5194 (65.0334) nleep/row_min_mean 1447.4681 (1464.9517) lr 7.0224e-05 eta 0:01:26
epoch [46/50] batch [140/203] time 0.094 (0.097) data 0.000 (0.002) loss 1.3451 (1.3141) teacher_loss 0.1357 (0.1246) loss_zs_kd 0.0873 (0.0739) loss_oracle 0.6224 (0.5547) kd_loss 0.8545 (0.8753) acc 96.8750 (96.6295) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0202 (0.0586) teacher/usage_max 0.4998 (0.5313) teacher/usage_min 0.0068 (0.0679) teacher/usage_std 0.2309 (0.1984) nleep/row_max_mean 1493.5708 (1494.9030) nleep/row_max_std 68.0656 (64.7424) nleep/row_min_mean 1462.8927 (1465.2885) lr 7.0224e-05 eta 0:01:24
epoch [46/50] batch [160/203] time 0.089 (0.097) data 0.000 (0.002) loss 1.2452 (1.3126) teacher_loss 0.0655 (0.1245) loss_zs_kd 0.0691 (0.0740) loss_oracle 0.5329 (0.5536) kd_loss 0.8787 (0.8743) acc 100.0000 (96.6406) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4245) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0624 (0.0588) teacher/usage_max 0.4846 (0.5320) teacher/usage_min 0.0755 (0.0671) teacher/usage_std 0.1832 (0.1991) nleep/row_max_mean 1495.9523 (1495.1647) nleep/row_max_std 70.9860 (64.3450) nleep/row_min_mean 1469.0447 (1465.4714) lr 7.0224e-05 eta 0:01:23
epoch [46/50] batch [180/203] time 0.100 (0.099) data 0.000 (0.002) loss 1.4483 (1.3107) teacher_loss 0.2042 (0.1227) loss_zs_kd 0.0923 (0.0743) loss_oracle 0.5195 (0.5523) kd_loss 0.9382 (0.8747) acc 90.6250 (96.7014) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0304 (0.0578) teacher/usage_max 0.4886 (0.5314) teacher/usage_min 0.1033 (0.0666) teacher/usage_std 0.1659 (0.1991) nleep/row_max_mean 1490.9540 (1495.0295) nleep/row_max_std 68.5429 (64.4942) nleep/row_min_mean 1459.2417 (1465.2719) lr 7.0224e-05 eta 0:01:22
epoch [46/50] batch [200/203] time 0.084 (0.098) data 0.000 (0.002) loss 1.2461 (1.3113) teacher_loss 0.0770 (0.1236) loss_zs_kd 0.0858 (0.0744) loss_oracle 0.5609 (0.5524) kd_loss 0.8458 (0.8743) acc 96.8750 (96.6719) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4245) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0335 (0.0584) teacher/usage_max 0.6257 (0.5320) teacher/usage_min 0.0083 (0.0668) teacher/usage_std 0.2531 (0.1991) nleep/row_max_mean 1487.0295 (1494.7204) nleep/row_max_std 75.5235 (64.6577) nleep/row_min_mean 1459.1101 (1464.9891) lr 7.0224e-05 eta 0:01:20
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,328
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [47/50] batch [20/203] time 0.081 (0.100) data 0.000 (0.016) loss 1.3660 (1.3199) teacher_loss 0.1245 (0.1332) loss_zs_kd 0.0819 (0.0732) loss_oracle 0.6054 (0.5577) kd_loss 0.8978 (0.8712) acc 93.7500 (96.8750) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1606 (0.1605) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0315 (0.0518) teacher/usage_max 0.5239 (0.5282) teacher/usage_min 0.0653 (0.0566) teacher/usage_std 0.1951 (0.2037) nleep/row_max_mean 1502.6655 (1494.8935) nleep/row_max_std 55.6589 (65.9155) nleep/row_min_mean 1473.0969 (1464.7464) lr 4.8943e-05 eta 0:01:19
epoch [47/50] batch [40/203] time 0.078 (0.096) data 0.001 (0.008) loss 1.3792 (1.3032) teacher_loss 0.1822 (0.1188) loss_zs_kd 0.0593 (0.0725) loss_oracle 0.5567 (0.5614) kd_loss 0.8890 (0.8675) acc 96.8750 (97.1094) gate/entropy 1.0225 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0522 (0.0583) teacher/usage_max 0.4675 (0.5322) teacher/usage_min 0.0759 (0.0599) teacher/usage_std 0.1821 (0.2028) nleep/row_max_mean 1484.6077 (1494.5503) nleep/row_max_std 73.5629 (64.7780) nleep/row_min_mean 1457.0398 (1464.6093) lr 4.8943e-05 eta 0:01:14
epoch [47/50] batch [60/203] time 0.092 (0.092) data 0.001 (0.005) loss 1.3111 (1.2931) teacher_loss 0.0904 (0.1071) loss_zs_kd 0.0747 (0.0722) loss_oracle 0.5604 (0.5587) kd_loss 0.9031 (0.8706) acc 100.0000 (97.3958) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0561 (0.0585) teacher/usage_max 0.5773 (0.5307) teacher/usage_min 0.0975 (0.0634) teacher/usage_std 0.1960 (0.2008) nleep/row_max_mean 1481.4387 (1494.4538) nleep/row_max_std 78.0755 (65.5786) nleep/row_min_mean 1450.7604 (1464.5140) lr 4.8943e-05 eta 0:01:09
epoch [47/50] batch [80/203] time 0.076 (0.092) data 0.000 (0.004) loss 1.2812 (1.2948) teacher_loss 0.1173 (0.1090) loss_zs_kd 0.0566 (0.0733) loss_oracle 0.5412 (0.5546) kd_loss 0.8650 (0.8719) acc 96.8750 (97.3047) gate/entropy 1.0225 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.1009 (0.0592) teacher/usage_max 0.4659 (0.5323) teacher/usage_min 0.1021 (0.0655) teacher/usage_std 0.1641 (0.2002) nleep/row_max_mean 1482.9988 (1494.8676) nleep/row_max_std 76.5387 (65.0106) nleep/row_min_mean 1454.6654 (1465.2365) lr 4.8943e-05 eta 0:01:07
epoch [47/50] batch [100/203] time 0.085 (0.091) data 0.000 (0.003) loss 1.5148 (1.3099) teacher_loss 0.2930 (0.1231) loss_zs_kd 0.0621 (0.0738) loss_oracle 0.6041 (0.5564) kd_loss 0.8887 (0.8717) acc 87.5000 (96.8750) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0995 (0.0598) teacher/usage_max 0.4413 (0.5337) teacher/usage_min 0.1252 (0.0658) teacher/usage_std 0.1472 (0.2005) nleep/row_max_mean 1494.5414 (1494.5380) nleep/row_max_std 58.5149 (64.3529) nleep/row_min_mean 1466.0171 (1464.9287) lr 4.8943e-05 eta 0:01:04
epoch [47/50] batch [120/203] time 0.078 (0.091) data 0.000 (0.003) loss 1.2363 (1.3028) teacher_loss 0.1001 (0.1203) loss_zs_kd 0.0867 (0.0737) loss_oracle 0.5111 (0.5521) kd_loss 0.8374 (0.8696) acc 96.8750 (96.9010) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0333 (0.0604) teacher/usage_max 0.5536 (0.5388) teacher/usage_min 0.0037 (0.0641) teacher/usage_std 0.2374 (0.2028) nleep/row_max_mean 1501.9987 (1494.3363) nleep/row_max_std 58.0878 (64.3531) nleep/row_min_mean 1472.5094 (1464.7722) lr 4.8943e-05 eta 0:01:03
epoch [47/50] batch [140/203] time 0.087 (0.091) data 0.000 (0.002) loss 1.2859 (1.3023) teacher_loss 0.0603 (0.1198) loss_zs_kd 0.0562 (0.0728) loss_oracle 0.6048 (0.5517) kd_loss 0.8952 (0.8703) acc 100.0000 (96.8973) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0394 (0.0603) teacher/usage_max 0.5150 (0.5397) teacher/usage_min 0.0680 (0.0646) teacher/usage_std 0.1918 (0.2027) nleep/row_max_mean 1499.4089 (1494.5892) nleep/row_max_std 62.1950 (64.2800) nleep/row_min_mean 1468.2446 (1465.0267) lr 4.8943e-05 eta 0:01:01
epoch [47/50] batch [160/203] time 0.098 (0.090) data 0.000 (0.002) loss 1.3852 (1.3045) teacher_loss 0.1612 (0.1211) loss_zs_kd 0.0756 (0.0731) loss_oracle 0.5153 (0.5511) kd_loss 0.9285 (0.8712) acc 96.8750 (96.8945) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1604 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0017 (0.0589) teacher/usage_max 0.5624 (0.5393) teacher/usage_min 0.0626 (0.0641) teacher/usage_std 0.2062 (0.2029) nleep/row_max_mean 1516.4851 (1495.0610) nleep/row_max_std 42.1840 (63.9605) nleep/row_min_mean 1482.9570 (1465.4184) lr 4.8943e-05 eta 0:00:58
epoch [47/50] batch [180/203] time 0.095 (0.090) data 0.000 (0.002) loss 1.2676 (1.3081) teacher_loss 0.0813 (0.1231) loss_zs_kd 0.0757 (0.0729) loss_oracle 0.5279 (0.5525) kd_loss 0.8845 (0.8723) acc 100.0000 (96.8056) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0429 (0.0598) teacher/usage_max 0.5077 (0.5379) teacher/usage_min 0.0607 (0.0662) teacher/usage_std 0.1952 (0.2015) nleep/row_max_mean 1509.9570 (1494.6645) nleep/row_max_std 58.4880 (64.3709) nleep/row_min_mean 1475.5154 (1465.0152) lr 4.8943e-05 eta 0:00:57
epoch [47/50] batch [200/203] time 0.088 (0.091) data 0.000 (0.002) loss 1.3133 (1.3118) teacher_loss 0.2023 (0.1264) loss_zs_kd 0.0807 (0.0730) loss_oracle 0.5625 (0.5532) kd_loss 0.7895 (0.8724) acc 90.6250 (96.6719) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.1161 (0.0594) teacher/usage_max 0.4822 (0.5382) teacher/usage_min 0.0390 (0.0658) teacher/usage_std 0.2081 (0.2017) nleep/row_max_mean 1480.4771 (1494.5338) nleep/row_max_std 76.9308 (64.4899) nleep/row_min_mean 1453.2057 (1464.8167) lr 4.8943e-05 eta 0:00:55
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,329
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [48/50] batch [20/203] time 0.085 (0.116) data 0.000 (0.015) loss 1.2641 (1.3407) teacher_loss 0.0790 (0.1425) loss_zs_kd 0.0970 (0.0737) loss_oracle 0.5680 (0.5722) kd_loss 0.8525 (0.8752) acc 96.8750 (95.9375) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0397 (0.0560) teacher/usage_max 0.5182 (0.5193) teacher/usage_min 0.0258 (0.0650) teacher/usage_std 0.2189 (0.1965) nleep/row_max_mean 1499.2974 (1493.5189) nleep/row_max_std 57.3884 (65.1037) nleep/row_min_mean 1468.1842 (1463.7672) lr 3.1417e-05 eta 0:01:08
epoch [48/50] batch [40/203] time 0.098 (0.106) data 0.000 (0.007) loss 1.2135 (1.3180) teacher_loss 0.0723 (0.1275) loss_zs_kd 0.0660 (0.0731) loss_oracle 0.5201 (0.5608) kd_loss 0.8481 (0.8735) acc 100.0000 (96.4844) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0723 (0.0620) teacher/usage_max 0.6088 (0.5291) teacher/usage_min 0.0514 (0.0694) teacher/usage_std 0.2276 (0.1973) nleep/row_max_mean 1482.2185 (1493.0260) nleep/row_max_std 82.9693 (64.9958) nleep/row_min_mean 1453.8596 (1463.7780) lr 3.1417e-05 eta 0:01:00
epoch [48/50] batch [60/203] time 0.089 (0.104) data 0.000 (0.005) loss 1.2727 (1.3092) teacher_loss 0.0896 (0.1270) loss_zs_kd 0.0840 (0.0742) loss_oracle 0.5311 (0.5513) kd_loss 0.8756 (0.8694) acc 96.8750 (96.4583) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0283 (0.0607) teacher/usage_max 0.6464 (0.5356) teacher/usage_min 0.0411 (0.0640) teacher/usage_std 0.2475 (0.2018) nleep/row_max_mean 1509.1409 (1494.2065) nleep/row_max_std 56.0916 (65.0140) nleep/row_min_mean 1474.5125 (1464.8115) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [80/203] time 0.098 (0.101) data 0.000 (0.004) loss 1.4658 (1.3147) teacher_loss 0.2950 (0.1329) loss_zs_kd 0.0769 (0.0733) loss_oracle 0.5614 (0.5501) kd_loss 0.8517 (0.8701) acc 90.6250 (96.3281) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0394 (0.0620) teacher/usage_max 0.5628 (0.5340) teacher/usage_min 0.0257 (0.0660) teacher/usage_std 0.2261 (0.2001) nleep/row_max_mean 1488.2065 (1494.5783) nleep/row_max_std 76.2832 (65.3469) nleep/row_min_mean 1456.2686 (1464.9990) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [100/203] time 0.098 (0.099) data 0.000 (0.003) loss 1.2065 (1.3115) teacher_loss 0.0945 (0.1294) loss_zs_kd 0.0863 (0.0736) loss_oracle 0.5540 (0.5534) kd_loss 0.7918 (0.8686) acc 96.8750 (96.4062) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0960 (0.0620) teacher/usage_max 0.6101 (0.5353) teacher/usage_min 0.0233 (0.0644) teacher/usage_std 0.2407 (0.2018) nleep/row_max_mean 1482.0428 (1495.6990) nleep/row_max_std 76.3889 (64.0520) nleep/row_min_mean 1451.8109 (1465.7894) lr 3.1417e-05 eta 0:00:50
epoch [48/50] batch [120/203] time 0.092 (0.097) data 0.000 (0.003) loss 1.1981 (1.3097) teacher_loss 0.0285 (0.1253) loss_zs_kd 0.0839 (0.0739) loss_oracle 0.5586 (0.5561) kd_loss 0.8483 (0.8694) acc 100.0000 (96.5885) gate/entropy 1.0226 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1221 (0.1222) teacher/entropy 0.0604 (0.0618) teacher/usage_max 0.5975 (0.5328) teacher/usage_min 0.0396 (0.0650) teacher/usage_std 0.2287 (0.2008) nleep/row_max_mean 1495.3386 (1495.4377) nleep/row_max_std 53.9842 (64.0905) nleep/row_min_mean 1462.6072 (1465.4560) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [140/203] time 0.097 (0.097) data 0.000 (0.002) loss 1.2933 (1.3090) teacher_loss 0.0502 (0.1235) loss_zs_kd 0.0757 (0.0734) loss_oracle 0.5768 (0.5551) kd_loss 0.9169 (0.8713) acc 96.8750 (96.6295) gate/entropy 1.0225 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1607 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0139 (0.0601) teacher/usage_max 0.5014 (0.5326) teacher/usage_min 0.0642 (0.0652) teacher/usage_std 0.1923 (0.2006) nleep/row_max_mean 1497.8130 (1495.6358) nleep/row_max_std 60.9179 (63.9497) nleep/row_min_mean 1462.9421 (1465.5866) lr 3.1417e-05 eta 0:00:45
epoch [48/50] batch [160/203] time 0.099 (0.097) data 0.000 (0.002) loss 1.3869 (1.3086) teacher_loss 0.2135 (0.1236) loss_zs_kd 0.0852 (0.0734) loss_oracle 0.5350 (0.5552) kd_loss 0.8633 (0.8707) acc 96.8750 (96.6406) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1604 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0805 (0.0611) teacher/usage_max 0.4841 (0.5310) teacher/usage_min 0.0787 (0.0657) teacher/usage_std 0.1811 (0.1999) nleep/row_max_mean 1503.9768 (1495.9630) nleep/row_max_std 72.0478 (63.7924) nleep/row_min_mean 1473.9418 (1465.9720) lr 3.1417e-05 eta 0:00:43
epoch [48/50] batch [180/203] time 0.088 (0.097) data 0.000 (0.002) loss 1.3981 (1.3082) teacher_loss 0.2303 (0.1226) loss_zs_kd 0.0782 (0.0735) loss_oracle 0.5196 (0.5558) kd_loss 0.8688 (0.8710) acc 93.7500 (96.7188) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1604 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0861 (0.0610) teacher/usage_max 0.5940 (0.5334) teacher/usage_min 0.0871 (0.0658) teacher/usage_std 0.2072 (0.2007) nleep/row_max_mean 1481.7402 (1496.0119) nleep/row_max_std 81.6942 (63.8711) nleep/row_min_mean 1453.6354 (1466.0823) lr 3.1417e-05 eta 0:00:41
epoch [48/50] batch [200/203] time 0.134 (0.097) data 0.001 (0.002) loss 1.3974 (1.3059) teacher_loss 0.1818 (0.1214) loss_zs_kd 0.0679 (0.0733) loss_oracle 0.5939 (0.5547) kd_loss 0.8847 (0.8705) acc 96.8750 (96.8281) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0448 (0.0609) teacher/usage_max 0.5500 (0.5349) teacher/usage_min 0.0621 (0.0653) teacher/usage_std 0.2029 (0.2013) nleep/row_max_mean 1493.4410 (1496.0893) nleep/row_max_std 67.2041 (63.6473) nleep/row_min_mean 1463.0781 (1466.1498) lr 3.1417e-05 eta 0:00:39
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,325
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [49/50] batch [20/203] time 0.074 (0.093) data 0.000 (0.013) loss 1.2876 (1.3402) teacher_loss 0.1437 (0.1493) loss_zs_kd 0.0677 (0.0754) loss_oracle 0.5834 (0.5697) kd_loss 0.8183 (0.8683) acc 93.7500 (95.3125) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0636 (0.0574) teacher/usage_max 0.6353 (0.5439) teacher/usage_min 0.0177 (0.0597) teacher/usage_std 0.2523 (0.2063) nleep/row_max_mean 1510.0315 (1494.3291) nleep/row_max_std 47.0034 (65.4684) nleep/row_min_mean 1476.0791 (1464.8702) lr 1.7713e-05 eta 0:00:35
epoch [49/50] batch [40/203] time 0.090 (0.089) data 0.000 (0.007) loss 1.2672 (1.3178) teacher_loss 0.1252 (0.1379) loss_zs_kd 0.0627 (0.0710) loss_oracle 0.5246 (0.5541) kd_loss 0.8483 (0.8673) acc 93.7500 (96.1719) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0357 (0.0548) teacher/usage_max 0.5936 (0.5440) teacher/usage_min 0.0142 (0.0561) teacher/usage_std 0.2402 (0.2090) nleep/row_max_mean 1479.8311 (1492.3377) nleep/row_max_std 76.9639 (67.8698) nleep/row_min_mean 1451.4375 (1463.0002) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [60/203] time 0.078 (0.086) data 0.001 (0.005) loss 1.4847 (1.3067) teacher_loss 0.3024 (0.1310) loss_zs_kd 0.0856 (0.0735) loss_oracle 0.5747 (0.5529) kd_loss 0.8522 (0.8625) acc 90.6250 (96.3021) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0548 (0.0580) teacher/usage_max 0.4840 (0.5512) teacher/usage_min 0.0404 (0.0542) teacher/usage_std 0.2072 (0.2122) nleep/row_max_mean 1484.7656 (1493.7185) nleep/row_max_std 78.3752 (67.0232) nleep/row_min_mean 1454.1830 (1464.2734) lr 1.7713e-05 eta 0:00:29
epoch [49/50] batch [80/203] time 0.087 (0.086) data 0.000 (0.003) loss 1.1931 (1.3082) teacher_loss 0.0396 (0.1319) loss_zs_kd 0.0813 (0.0747) loss_oracle 0.4744 (0.5514) kd_loss 0.8757 (0.8632) acc 100.0000 (96.4062) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1605 (0.1605) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0351 (0.0581) teacher/usage_max 0.5470 (0.5442) teacher/usage_min 0.0458 (0.0551) teacher/usage_std 0.2112 (0.2097) nleep/row_max_mean 1503.9009 (1494.5436) nleep/row_max_std 57.6544 (65.7835) nleep/row_min_mean 1472.4231 (1465.1775) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [100/203] time 0.078 (0.085) data 0.000 (0.003) loss 1.3256 (1.3085) teacher_loss 0.1786 (0.1325) loss_zs_kd 0.0623 (0.0743) loss_oracle 0.5618 (0.5510) kd_loss 0.8350 (0.8634) acc 93.7500 (96.4375) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1605 (0.1605) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0500 (0.0583) teacher/usage_max 0.5912 (0.5438) teacher/usage_min 0.0151 (0.0553) teacher/usage_std 0.2390 (0.2091) nleep/row_max_mean 1498.2490 (1494.6842) nleep/row_max_std 63.7722 (65.6077) nleep/row_min_mean 1464.5365 (1464.9983) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [120/203] time 0.155 (0.087) data 0.001 (0.002) loss 1.1733 (1.3097) teacher_loss 0.0969 (0.1317) loss_zs_kd 0.0455 (0.0739) loss_oracle 0.4450 (0.5508) kd_loss 0.8312 (0.8657) acc 96.8750 (96.5365) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0575 (0.0588) teacher/usage_max 0.5722 (0.5425) teacher/usage_min 0.0193 (0.0582) teacher/usage_std 0.2319 (0.2069) nleep/row_max_mean 1482.4758 (1494.4674) nleep/row_max_std 82.4807 (65.5833) nleep/row_min_mean 1456.3250 (1464.8108) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [140/203] time 0.080 (0.086) data 0.000 (0.002) loss 1.5144 (1.3086) teacher_loss 0.3511 (0.1308) loss_zs_kd 0.0879 (0.0736) loss_oracle 0.5564 (0.5506) kd_loss 0.8412 (0.8656) acc 90.6250 (96.5625) gate/entropy 1.0222 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1604 (0.1606) gate/usage_std 0.1224 (0.1222) teacher/entropy 0.0271 (0.0588) teacher/usage_max 0.5169 (0.5400) teacher/usage_min 0.0011 (0.0582) teacher/usage_std 0.2354 (0.2062) nleep/row_max_mean 1495.2936 (1494.3413) nleep/row_max_std 75.2661 (65.2499) nleep/row_min_mean 1461.7466 (1464.7866) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [160/203] time 0.094 (0.087) data 0.000 (0.002) loss 1.3407 (1.3112) teacher_loss 0.1426 (0.1325) loss_zs_kd 0.0788 (0.0735) loss_oracle 0.5468 (0.5523) kd_loss 0.8853 (0.8659) acc 93.7500 (96.5234) gate/entropy 1.0225 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0639 (0.0592) teacher/usage_max 0.5016 (0.5370) teacher/usage_min 0.0855 (0.0589) teacher/usage_std 0.1789 (0.2050) nleep/row_max_mean 1481.2078 (1493.7918) nleep/row_max_std 74.0191 (65.4946) nleep/row_min_mean 1454.1587 (1464.2041) lr 1.7713e-05 eta 0:00:21
epoch [49/50] batch [180/203] time 0.080 (0.087) data 0.000 (0.002) loss 1.4447 (1.3072) teacher_loss 0.1305 (0.1272) loss_zs_kd 0.0755 (0.0740) loss_oracle 0.6534 (0.5528) kd_loss 0.9498 (0.8666) acc 93.7500 (96.6667) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0303 (0.0596) teacher/usage_max 0.5361 (0.5371) teacher/usage_min 0.1191 (0.0601) teacher/usage_std 0.1704 (0.2044) nleep/row_max_mean 1490.3726 (1493.6128) nleep/row_max_std 72.1042 (65.8032) nleep/row_min_mean 1459.0836 (1464.0863) lr 1.7713e-05 eta 0:00:19
epoch [49/50] batch [200/203] time 0.088 (0.087) data 0.000 (0.002) loss 1.3405 (1.3055) teacher_loss 0.0533 (0.1250) loss_zs_kd 0.0621 (0.0738) loss_oracle 0.6435 (0.5520) kd_loss 0.9344 (0.8677) acc 100.0000 (96.7500) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0677 (0.0584) teacher/usage_max 0.4354 (0.5372) teacher/usage_min 0.1396 (0.0599) teacher/usage_std 0.1371 (0.2045) nleep/row_max_mean 1502.5190 (1493.8514) nleep/row_max_std 58.3751 (65.2347) nleep/row_min_mean 1472.4359 (1464.2257) lr 1.7713e-05 eta 0:00:17
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,327
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
epoch [50/50] batch [20/203] time 0.092 (0.112) data 0.000 (0.017) loss 1.3744 (1.3004) teacher_loss 0.2076 (0.1137) loss_zs_kd 0.0666 (0.0721) loss_oracle 0.5294 (0.5597) kd_loss 0.8688 (0.8707) acc 96.8750 (96.4062) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0321 (0.0646) teacher/usage_max 0.5063 (0.5151) teacher/usage_min 0.0346 (0.0700) teacher/usage_std 0.2121 (0.1942) nleep/row_max_mean 1497.2861 (1496.5682) nleep/row_max_std 57.7875 (62.3508) nleep/row_min_mean 1463.4309 (1466.6558) lr 7.8853e-06 eta 0:00:20
epoch [50/50] batch [40/203] time 0.091 (0.102) data 0.000 (0.009) loss 1.3718 (1.3089) teacher_loss 0.1902 (0.1116) loss_zs_kd 0.0887 (0.0733) loss_oracle 0.5756 (0.5678) kd_loss 0.8494 (0.8768) acc 93.7500 (96.9531) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0259 (0.0549) teacher/usage_max 0.5542 (0.5300) teacher/usage_min 0.0086 (0.0659) teacher/usage_std 0.2345 (0.2003) nleep/row_max_mean 1492.8466 (1495.7171) nleep/row_max_std 63.5099 (62.4927) nleep/row_min_mean 1460.6914 (1466.0059) lr 7.8853e-06 eta 0:00:16
epoch [50/50] batch [60/203] time 0.125 (0.102) data 0.003 (0.006) loss 1.5034 (1.3085) teacher_loss 0.3326 (0.1128) loss_zs_kd 0.0776 (0.0747) loss_oracle 0.5390 (0.5636) kd_loss 0.8625 (0.8765) acc 93.7500 (97.1354) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0452 (0.0550) teacher/usage_max 0.5254 (0.5382) teacher/usage_min 0.0403 (0.0655) teacher/usage_std 0.2105 (0.2027) nleep/row_max_mean 1494.4597 (1495.1358) nleep/row_max_std 74.1476 (62.8940) nleep/row_min_mean 1465.2712 (1465.3825) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [80/203] time 0.095 (0.100) data 0.000 (0.005) loss 1.3741 (1.3134) teacher_loss 0.2448 (0.1234) loss_zs_kd 0.0677 (0.0742) loss_oracle 0.5252 (0.5569) kd_loss 0.8328 (0.8745) acc 96.8750 (96.7578) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0622 (0.0578) teacher/usage_max 0.6633 (0.5355) teacher/usage_min 0.0323 (0.0664) teacher/usage_std 0.2584 (0.2015) nleep/row_max_mean 1494.2354 (1494.4736) nleep/row_max_std 66.7549 (63.8646) nleep/row_min_mean 1462.1519 (1464.9650) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [100/203] time 0.100 (0.099) data 0.000 (0.004) loss 1.3419 (1.3122) teacher_loss 0.2183 (0.1245) loss_zs_kd 0.0779 (0.0736) loss_oracle 0.4719 (0.5559) kd_loss 0.8488 (0.8729) acc 90.6250 (96.5625) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1606 (0.1605) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0410 (0.0589) teacher/usage_max 0.5631 (0.5327) teacher/usage_min 0.0208 (0.0661) teacher/usage_std 0.2290 (0.2009) nleep/row_max_mean 1504.5817 (1494.7904) nleep/row_max_std 54.4754 (63.6824) nleep/row_min_mean 1473.4595 (1465.2436) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [120/203] time 0.094 (0.098) data 0.000 (0.003) loss 1.3684 (1.3112) teacher_loss 0.1221 (0.1220) loss_zs_kd 0.0770 (0.0740) loss_oracle 0.6895 (0.5569) kd_loss 0.8630 (0.8738) acc 96.8750 (96.6406) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0413 (0.0588) teacher/usage_max 0.5024 (0.5343) teacher/usage_min 0.0372 (0.0668) teacher/usage_std 0.2101 (0.2010) nleep/row_max_mean 1480.8914 (1494.0983) nleep/row_max_std 74.6730 (63.6227) nleep/row_min_mean 1448.7087 (1464.5511) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [140/203] time 0.078 (0.098) data 0.000 (0.003) loss 1.5533 (1.3137) teacher_loss 0.3186 (0.1224) loss_zs_kd 0.0725 (0.0745) loss_oracle 0.5332 (0.5563) kd_loss 0.9319 (0.8759) acc 90.6250 (96.6071) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0263 (0.0579) teacher/usage_max 0.5266 (0.5362) teacher/usage_min 0.0920 (0.0679) teacher/usage_std 0.1807 (0.2010) nleep/row_max_mean 1484.0603 (1494.1058) nleep/row_max_std 70.6196 (63.1301) nleep/row_min_mean 1456.7000 (1464.5479) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [160/203] time 0.094 (0.097) data 0.000 (0.002) loss 1.2134 (1.3174) teacher_loss 0.0817 (0.1288) loss_zs_kd 0.0919 (0.0751) loss_oracle 0.4823 (0.5541) kd_loss 0.8446 (0.8740) acc 96.8750 (96.4844) gate/entropy 1.0223 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1223 (0.1222) teacher/entropy 0.0442 (0.0577) teacher/usage_max 0.5414 (0.5372) teacher/usage_min 0.0205 (0.0657) teacher/usage_std 0.2252 (0.2022) nleep/row_max_mean 1497.7213 (1494.0374) nleep/row_max_std 66.0385 (63.3115) nleep/row_min_mean 1469.3555 (1464.4088) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [180/203] time 0.087 (0.097) data 0.000 (0.002) loss 1.4174 (1.3165) teacher_loss 0.1572 (0.1295) loss_zs_kd 0.0627 (0.0747) loss_oracle 0.6236 (0.5516) kd_loss 0.9171 (0.8738) acc 96.8750 (96.4062) gate/entropy 1.0225 (1.0224) gate/usage_max 0.4245 (0.4244) gate/usage_min 0.1606 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0434 (0.0570) teacher/usage_max 0.5269 (0.5375) teacher/usage_min 0.0982 (0.0649) teacher/usage_std 0.1775 (0.2029) nleep/row_max_mean 1513.4432 (1494.1582) nleep/row_max_std 33.8093 (63.3230) nleep/row_min_mean 1479.9163 (1464.5068) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [200/203] time 0.085 (0.096) data 0.000 (0.002) loss 1.3267 (1.3149) teacher_loss 0.1325 (0.1287) loss_zs_kd 0.0747 (0.0739) loss_oracle 0.5230 (0.5504) kd_loss 0.8953 (0.8740) acc 96.8750 (96.4531) gate/entropy 1.0224 (1.0224) gate/usage_max 0.4244 (0.4244) gate/usage_min 0.1605 (0.1606) gate/usage_std 0.1222 (0.1222) teacher/entropy 0.0472 (0.0578) teacher/usage_max 0.4989 (0.5383) teacher/usage_min 0.0767 (0.0658) teacher/usage_std 0.1840 (0.2026) nleep/row_max_mean 1497.6661 (1493.8805) nleep/row_max_std 48.1269 (63.1352) nleep/row_min_mean 1468.1821 (1464.2743) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,795
* correct: 2,327
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 86.7%
Evaluate on the *test* set
=> result
* total: 1,415
* correct: 1,415
* accuracy: 100.0%
* error: 0.0%
* macro_f1: 100.0%
******* Domain c best val acc:      83.7%, epoch: 23 *******
******* Domain c best val test acc: 100.0%, epoch: 23 *******
******* Domain c best test acc:     100.0%, epoch: 1 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:19:58

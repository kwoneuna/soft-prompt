Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'sun']
Target     ['pascal']
# classes  5
# train_x  5,147
# val      2,206
# test     3,376
---------  -----------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_2/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_2/warmup_1/tensorboard)
epoch [1/50] batch [20/160] time 0.095 (0.132) data 0.000 (0.022) loss 1.1521 (1.2183) teacher_loss 0.7695 (0.7417) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0008 (0.0004) kd_loss 0.3822 (0.4765) acc 68.7500 (73.5938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3302 (0.3303) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.7137 (0.6206) teacher/usage_max 0.4604 (0.4331) teacher/usage_min 0.2663 (0.2465) teacher/usage_std 0.0899 (0.0810) nleep/row_max_mean 1516.0049 (1530.5552) nleep/row_max_std 99.8542 (61.3586) nleep/row_min_mean 1513.4805 (1526.6805) lr 1.0000e-05 eta 0:17:37
epoch [1/50] batch [40/160] time 0.108 (0.121) data 0.000 (0.011) loss 0.9206 (1.1164) teacher_loss 0.5664 (0.6881) loss_zs_kd 0.0003 (0.0001) loss_oracle 0.0044 (0.0015) kd_loss 0.3519 (0.4275) acc 81.2500 (75.7812) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0035 (0.0036) teacher/entropy 0.7468 (0.6698) teacher/usage_max 0.3999 (0.4212) teacher/usage_min 0.2527 (0.2507) teacher/usage_std 0.0609 (0.0737) nleep/row_max_mean 1528.1082 (1530.1197) nleep/row_max_std 33.6188 (56.8279) nleep/row_min_mean 1525.5835 (1526.8169) lr 1.0000e-05 eta 0:16:02
epoch [1/50] batch [60/160] time 0.115 (0.115) data 0.001 (0.008) loss 1.2485 (1.0836) teacher_loss 1.0099 (0.6959) loss_zs_kd 0.0005 (0.0002) loss_oracle 0.0068 (0.0029) kd_loss 0.2350 (0.3862) acc 68.7500 (75.0000) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.8613 (0.7113) teacher/usage_max 0.4383 (0.4157) teacher/usage_min 0.2804 (0.2583) teacher/usage_std 0.0742 (0.0679) nleep/row_max_mean 1523.5891 (1528.7900) nleep/row_max_std 72.2821 (56.0792) nleep/row_min_mean 1521.6912 (1525.8578) lr 1.0000e-05 eta 0:15:15
epoch [1/50] batch [80/160] time 0.097 (0.112) data 0.001 (0.006) loss 0.8413 (1.0369) teacher_loss 0.6366 (0.6869) loss_zs_kd 0.0008 (0.0004) loss_oracle 0.0086 (0.0043) kd_loss 0.2000 (0.3477) acc 75.0000 (75.2734) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.8973 (0.7498) teacher/usage_max 0.3957 (0.4114) teacher/usage_min 0.2421 (0.2602) teacher/usage_std 0.0660 (0.0652) nleep/row_max_mean 1542.4268 (1529.5195) nleep/row_max_std 40.3619 (54.6521) nleep/row_min_mean 1540.7905 (1526.8662) lr 1.0000e-05 eta 0:14:44
epoch [1/50] batch [100/160] time 0.113 (0.109) data 0.000 (0.005) loss 0.6744 (1.0078) teacher_loss 0.4985 (0.6883) loss_zs_kd 0.0007 (0.0006) loss_oracle 0.0127 (0.0055) kd_loss 0.1691 (0.3165) acc 75.0000 (75.1875) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.9285 (0.7811) teacher/usage_max 0.3838 (0.4066) teacher/usage_min 0.2842 (0.2643) teacher/usage_std 0.0407 (0.0614) nleep/row_max_mean 1533.7235 (1529.2663) nleep/row_max_std 37.0339 (54.8854) nleep/row_min_mean 1532.1877 (1526.8287) lr 1.0000e-05 eta 0:14:20
epoch [1/50] batch [120/160] time 0.112 (0.107) data 0.001 (0.004) loss 0.8030 (0.9765) teacher_loss 0.6651 (0.6821) loss_zs_kd 0.0035 (0.0007) loss_oracle 0.0151 (0.0068) kd_loss 0.1286 (0.2906) acc 78.1250 (75.5208) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3383 (0.3383) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0035 (0.0036) teacher/entropy 0.9686 (0.8070) teacher/usage_max 0.4030 (0.4023) teacher/usage_min 0.2959 (0.2674) teacher/usage_std 0.0493 (0.0582) nleep/row_max_mean 1538.5332 (1529.0792) nleep/row_max_std 46.3799 (55.0760) nleep/row_min_mean 1537.3306 (1526.8143) lr 1.0000e-05 eta 0:14:04
epoch [1/50] batch [140/160] time 0.087 (0.105) data 0.000 (0.003) loss 0.8216 (0.9439) teacher_loss 0.6476 (0.6717) loss_zs_kd 0.0016 (0.0009) loss_oracle 0.0208 (0.0079) kd_loss 0.1628 (0.2679) acc 71.8750 (76.0714) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3382 (0.3383) gate/usage_min 0.3303 (0.3303) gate/usage_std 0.0035 (0.0036) teacher/entropy 0.9339 (0.8298) teacher/usage_max 0.4230 (0.3985) teacher/usage_min 0.2823 (0.2721) teacher/usage_std 0.0636 (0.0545) nleep/row_max_mean 1532.4985 (1528.2822) nleep/row_max_std 40.5673 (56.0121) nleep/row_min_mean 1531.0779 (1526.1662) lr 1.0000e-05 eta 0:13:47
epoch [1/50] batch [160/160] time 0.089 (0.103) data 0.000 (0.003) loss 0.9320 (0.9292) teacher_loss 0.7978 (0.6742) loss_zs_kd 0.0047 (0.0010) loss_oracle 0.0175 (0.0090) kd_loss 0.1230 (0.2499) acc 75.0000 (75.9180) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3384 (0.3383) gate/usage_min 0.3301 (0.3303) gate/usage_std 0.0036 (0.0036) teacher/entropy 0.9737 (0.8477) teacher/usage_max 0.4165 (0.3965) teacher/usage_min 0.2663 (0.2745) teacher/usage_std 0.0624 (0.0527) nleep/row_max_mean 1515.8579 (1528.1855) nleep/row_max_std 92.0118 (55.8845) nleep/row_min_mean 1514.6586 (1526.1843) lr 2.0000e-03 eta 0:13:29
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,716
* accuracy: 77.8%
* error: 22.2%
* macro_f1: 79.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,929
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 87.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      77.8%, epoch: 1 *******
******* Domain p best val test acc: 86.8%, epoch: 1 *******
******* Domain p best test acc:     86.8%, epoch: 1 *******
epoch [2/50] batch [20/160] time 0.097 (0.119) data 0.000 (0.019) loss 0.9930 (0.8180) teacher_loss 0.6105 (0.5765) loss_zs_kd 0.0257 (0.0130) loss_oracle 0.1909 (0.1308) kd_loss 0.2742 (0.1696) acc 75.0000 (78.9062) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3389 (0.3386) gate/usage_min 0.3302 (0.3302) gate/usage_std 0.0039 (0.0038) teacher/entropy 0.8216 (0.9277) teacher/usage_max 0.4583 (0.4074) teacher/usage_min 0.1960 (0.2381) teacher/usage_std 0.1074 (0.0720) nleep/row_max_mean 1510.6300 (1523.8080) nleep/row_max_std 74.8795 (60.0360) nleep/row_min_mean 1508.7229 (1522.4186) lr 2.0000e-03 eta 0:15:29
epoch [2/50] batch [40/160] time 0.094 (0.108) data 0.000 (0.010) loss 0.9753 (0.8962) teacher_loss 0.4105 (0.4928) loss_zs_kd 0.0177 (0.0170) loss_oracle 0.2600 (0.2314) kd_loss 0.4259 (0.2793) acc 90.6250 (84.0625) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3387 (0.3387) gate/usage_min 0.3295 (0.3301) gate/usage_std 0.0039 (0.0038) teacher/entropy 0.6718 (0.8187) teacher/usage_max 0.5424 (0.4690) teacher/usage_min 0.1396 (0.1918) teacher/usage_std 0.1648 (0.1158) nleep/row_max_mean 1538.3806 (1527.7075) nleep/row_max_std 37.7486 (57.9385) nleep/row_min_mean 1535.8988 (1525.8796) lr 2.0000e-03 eta 0:14:02
epoch [2/50] batch [60/160] time 0.106 (0.111) data 0.001 (0.007) loss 1.1373 (0.9907) teacher_loss 0.2525 (0.4628) loss_zs_kd 0.0247 (0.0182) loss_oracle 0.3265 (0.2467) kd_loss 0.7092 (0.3955) acc 93.7500 (85.4688) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3374 (0.3385) gate/usage_min 0.3279 (0.3297) gate/usage_std 0.0040 (0.0038) teacher/entropy 0.3846 (0.7019) teacher/usage_max 0.7253 (0.5410) teacher/usage_min 0.0523 (0.1518) teacher/usage_std 0.2858 (0.1639) nleep/row_max_mean 1531.2660 (1527.8350) nleep/row_max_std 60.0669 (59.8365) nleep/row_min_mean 1526.9065 (1525.3811) lr 2.0000e-03 eta 0:14:23
epoch [2/50] batch [80/160] time 0.071 (0.106) data 0.000 (0.005) loss 1.2816 (1.0863) teacher_loss 0.3670 (0.4610) loss_zs_kd 0.0316 (0.0202) loss_oracle 0.3263 (0.2728) kd_loss 0.7357 (0.4788) acc 87.5000 (85.1953) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3380 (0.3381) gate/usage_min 0.3262 (0.3290) gate/usage_std 0.0051 (0.0040) teacher/entropy 0.3514 (0.6168) teacher/usage_max 0.7689 (0.5888) teacher/usage_min 0.0405 (0.1242) teacher/usage_std 0.3140 (0.1964) nleep/row_max_mean 1530.0181 (1527.5636) nleep/row_max_std 88.7345 (61.0705) nleep/row_min_mean 1524.6470 (1524.3849) lr 2.0000e-03 eta 0:13:42
epoch [2/50] batch [100/160] time 0.094 (0.103) data 0.000 (0.004) loss 1.4978 (1.1596) teacher_loss 0.4966 (0.4593) loss_zs_kd 0.0383 (0.0224) loss_oracle 0.3521 (0.2810) kd_loss 0.8061 (0.5486) acc 78.1250 (85.3125) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3422 (0.3385) gate/usage_min 0.3238 (0.3282) gate/usage_std 0.0075 (0.0045) teacher/entropy 0.2740 (0.5444) teacher/usage_max 0.7358 (0.6264) teacher/usage_min 0.0445 (0.1042) teacher/usage_std 0.2934 (0.2217) nleep/row_max_mean 1525.5800 (1527.5828) nleep/row_max_std 62.8505 (61.8113) nleep/row_min_mean 1517.6968 (1523.5393) lr 2.0000e-03 eta 0:13:17
epoch [2/50] batch [120/160] time 0.084 (0.101) data 0.000 (0.004) loss 1.5557 (1.2145) teacher_loss 0.4625 (0.4472) loss_zs_kd 0.0290 (0.0241) loss_oracle 0.4936 (0.3086) kd_loss 0.8319 (0.6010) acc 81.2500 (85.4948) gate/entropy 1.0982 (1.0985) gate/usage_max 0.3455 (0.3395) gate/usage_min 0.3211 (0.3272) gate/usage_std 0.0100 (0.0052) teacher/entropy 0.2396 (0.4892) teacher/usage_max 0.7778 (0.6422) teacher/usage_min 0.0218 (0.0905) teacher/usage_std 0.3226 (0.2337) nleep/row_max_mean 1514.0868 (1528.5278) nleep/row_max_std 89.3214 (61.3838) nleep/row_min_mean 1505.6909 (1523.6583) lr 2.0000e-03 eta 0:13:00
epoch [2/50] batch [140/160] time 0.090 (0.100) data 0.000 (0.003) loss 1.3498 (1.2518) teacher_loss 0.2694 (0.4330) loss_zs_kd 0.0168 (0.0256) loss_oracle 0.3669 (0.3291) kd_loss 0.8885 (0.6414) acc 84.3750 (85.8036) gate/entropy 1.0980 (1.0984) gate/usage_max 0.3480 (0.3405) gate/usage_min 0.3187 (0.3262) gate/usage_std 0.0120 (0.0060) teacher/entropy 0.1846 (0.4464) teacher/usage_max 0.6245 (0.6459) teacher/usage_min 0.0367 (0.0817) teacher/usage_std 0.2400 (0.2382) nleep/row_max_mean 1533.2760 (1528.3999) nleep/row_max_std 60.7332 (62.2649) nleep/row_min_mean 1524.0441 (1522.8310) lr 2.0000e-03 eta 0:12:48
epoch [2/50] batch [160/160] time 0.087 (0.098) data 0.000 (0.003) loss 1.3035 (1.2626) teacher_loss 0.2417 (0.4126) loss_zs_kd 0.0294 (0.0264) loss_oracle 0.4609 (0.3420) kd_loss 0.8166 (0.6659) acc 93.7500 (86.6211) gate/entropy 1.0978 (1.0983) gate/usage_max 0.3500 (0.3416) gate/usage_min 0.3166 (0.3251) gate/usage_std 0.0136 (0.0069) teacher/entropy 0.2547 (0.4200) teacher/usage_max 0.6205 (0.6456) teacher/usage_min 0.0627 (0.0815) teacher/usage_std 0.2280 (0.2382) nleep/row_max_mean 1528.4800 (1528.5592) nleep/row_max_std 62.3072 (61.9643) nleep/row_min_mean 1518.9668 (1522.5034) lr 1.9980e-03 eta 0:12:31
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,805
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 83.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,004
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 89.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      81.8%, epoch: 2 *******
******* Domain p best val test acc: 89.0%, epoch: 2 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [3/50] batch [20/160] time 0.088 (0.103) data 0.000 (0.013) loss 1.2262 (1.4090) teacher_loss 0.0830 (0.3335) loss_zs_kd 0.0379 (0.0466) loss_oracle 0.5445 (0.4728) kd_loss 0.8520 (0.8159) acc 96.8750 (88.4375) gate/entropy 1.0975 (1.0977) gate/usage_max 0.3522 (0.3510) gate/usage_min 0.3143 (0.3154) gate/usage_std 0.0155 (0.0146) teacher/entropy 0.2206 (0.2555) teacher/usage_max 0.5790 (0.6340) teacher/usage_min 0.1060 (0.1045) teacher/usage_std 0.1936 (0.2259) nleep/row_max_mean 1527.7926 (1528.6053) nleep/row_max_std 85.5542 (61.3527) nleep/row_min_mean 1516.4470 (1518.5058) lr 1.9980e-03 eta 0:13:05
epoch [3/50] batch [40/160] time 0.099 (0.100) data 0.000 (0.007) loss 1.4251 (1.4241) teacher_loss 0.3581 (0.3317) loss_zs_kd 0.0485 (0.0467) loss_oracle 0.4145 (0.4655) kd_loss 0.8355 (0.8364) acc 84.3750 (88.0469) gate/entropy 1.0971 (1.0975) gate/usage_max 0.3557 (0.3526) gate/usage_min 0.3114 (0.3140) gate/usage_std 0.0181 (0.0157) teacher/entropy 0.2312 (0.2334) teacher/usage_max 0.5822 (0.6292) teacher/usage_min 0.0846 (0.1086) teacher/usage_std 0.2031 (0.2224) nleep/row_max_mean 1543.7854 (1528.4661) nleep/row_max_std 30.8142 (59.8532) nleep/row_min_mean 1529.8887 (1517.2464) lr 1.9980e-03 eta 0:12:41
epoch [3/50] batch [60/160] time 0.088 (0.096) data 0.000 (0.005) loss 1.5668 (1.4513) teacher_loss 0.4036 (0.3381) loss_zs_kd 0.0514 (0.0490) loss_oracle 0.3851 (0.4652) kd_loss 0.9449 (0.8560) acc 84.3750 (87.3958) gate/entropy 1.0967 (1.0973) gate/usage_max 0.3597 (0.3543) gate/usage_min 0.3089 (0.3127) gate/usage_std 0.0208 (0.0170) teacher/entropy 0.1097 (0.2096) teacher/usage_max 0.6680 (0.6504) teacher/usage_min 0.0781 (0.1060) teacher/usage_std 0.2473 (0.2346) nleep/row_max_mean 1538.4285 (1527.6191) nleep/row_max_std 31.0334 (61.8049) nleep/row_min_mean 1523.0298 (1515.2874) lr 1.9980e-03 eta 0:12:13
epoch [3/50] batch [80/160] time 0.070 (0.095) data 0.000 (0.004) loss 1.2811 (1.4565) teacher_loss 0.1244 (0.3356) loss_zs_kd 0.0427 (0.0469) loss_oracle 0.4825 (0.4563) kd_loss 0.8942 (0.8692) acc 96.8750 (87.6562) gate/entropy 1.0961 (1.0971) gate/usage_max 0.3637 (0.3562) gate/usage_min 0.3062 (0.3114) gate/usage_std 0.0236 (0.0183) teacher/entropy 0.1589 (0.1927) teacher/usage_max 0.6705 (0.6642) teacher/usage_min 0.1321 (0.1058) teacher/usage_std 0.2399 (0.2427) nleep/row_max_mean 1510.6138 (1526.1842) nleep/row_max_std 78.5296 (64.6120) nleep/row_min_mean 1495.0438 (1512.9371) lr 1.9980e-03 eta 0:11:58
epoch [3/50] batch [100/160] time 0.095 (0.095) data 0.000 (0.003) loss 1.5813 (1.4603) teacher_loss 0.3925 (0.3288) loss_zs_kd 0.0592 (0.0480) loss_oracle 0.4571 (0.4533) kd_loss 0.9306 (0.8808) acc 87.5000 (87.9062) gate/entropy 1.0955 (1.0968) gate/usage_max 0.3676 (0.3581) gate/usage_min 0.3038 (0.3101) gate/usage_std 0.0263 (0.0197) teacher/entropy 0.0985 (0.1778) teacher/usage_max 0.7965 (0.6707) teacher/usage_min 0.0754 (0.1048) teacher/usage_std 0.3282 (0.2465) nleep/row_max_mean 1539.4297 (1526.8284) nleep/row_max_std 51.1059 (63.5933) nleep/row_min_mean 1521.4792 (1512.6859) lr 1.9980e-03 eta 0:11:59
epoch [3/50] batch [120/160] time 0.088 (0.094) data 0.000 (0.002) loss 1.4937 (1.4677) teacher_loss 0.3407 (0.3262) loss_zs_kd 0.0420 (0.0498) loss_oracle 0.4639 (0.4562) kd_loss 0.9000 (0.8885) acc 84.3750 (88.0208) gate/entropy 1.0947 (1.0965) gate/usage_max 0.3720 (0.3601) gate/usage_min 0.3008 (0.3088) gate/usage_std 0.0294 (0.0210) teacher/entropy 0.1146 (0.1666) teacher/usage_max 0.8493 (0.6782) teacher/usage_min 0.0693 (0.1040) teacher/usage_std 0.3649 (0.2510) nleep/row_max_mean 1522.4420 (1526.0690) nleep/row_max_std 82.2895 (63.7177) nleep/row_min_mean 1504.5571 (1511.2032) lr 1.9980e-03 eta 0:11:53
epoch [3/50] batch [140/160] time 0.074 (0.093) data 0.000 (0.002) loss 1.4107 (1.4657) teacher_loss 0.3138 (0.3222) loss_zs_kd 0.0503 (0.0499) loss_oracle 0.3240 (0.4494) kd_loss 0.9097 (0.8938) acc 84.3750 (88.3036) gate/entropy 1.0939 (1.0962) gate/usage_max 0.3764 (0.3621) gate/usage_min 0.2981 (0.3075) gate/usage_std 0.0325 (0.0224) teacher/entropy 0.1022 (0.1569) teacher/usage_max 0.8232 (0.6884) teacher/usage_min 0.0689 (0.1006) teacher/usage_std 0.3468 (0.2578) nleep/row_max_mean 1498.2043 (1526.1383) nleep/row_max_std 94.9220 (64.2705) nleep/row_min_mean 1480.0126 (1510.5550) lr 1.9980e-03 eta 0:11:44
epoch [3/50] batch [160/160] time 0.081 (0.093) data 0.000 (0.002) loss 1.6350 (1.4632) teacher_loss 0.4885 (0.3201) loss_zs_kd 0.0562 (0.0502) loss_oracle 0.3515 (0.4397) kd_loss 0.9426 (0.8982) acc 84.3750 (88.3594) gate/entropy 1.0929 (1.0959) gate/usage_max 0.3812 (0.3642) gate/usage_min 0.2955 (0.3061) gate/usage_std 0.0357 (0.0239) teacher/entropy 0.0468 (0.1473) teacher/usage_max 0.8504 (0.7016) teacher/usage_min 0.0059 (0.0961) teacher/usage_std 0.3699 (0.2665) nleep/row_max_mean 1527.0297 (1525.5883) nleep/row_max_std 49.1207 (64.6809) nleep/row_min_mean 1505.8455 (1509.3838) lr 1.9921e-03 eta 0:11:35
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,780
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 82.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,981
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 88.4%
******* Domain p best val acc:      81.8%, epoch: 2 *******
******* Domain p best val test acc: 89.0%, epoch: 2 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [4/50] batch [20/160] time 0.099 (0.099) data 0.000 (0.012) loss 1.7922 (1.4680) teacher_loss 0.6483 (0.3184) loss_zs_kd 0.0414 (0.0421) loss_oracle 0.3812 (0.4011) kd_loss 0.9326 (0.9280) acc 75.0000 (89.0625) gate/entropy 1.0920 (1.0925) gate/usage_max 0.3852 (0.3832) gate/usage_min 0.2931 (0.2942) gate/usage_std 0.0385 (0.0371) teacher/entropy 0.0535 (0.0835) teacher/usage_max 0.8383 (0.7388) teacher/usage_min 0.0366 (0.0793) teacher/usage_std 0.3589 (0.2939) nleep/row_max_mean 1530.9210 (1521.7690) nleep/row_max_std 63.3481 (69.5081) nleep/row_min_mean 1506.2361 (1499.8732) lr 1.9921e-03 eta 0:12:19
epoch [4/50] batch [40/160] time 0.101 (0.095) data 0.000 (0.006) loss 1.6467 (1.4687) teacher_loss 0.3518 (0.2996) loss_zs_kd 0.0641 (0.0472) loss_oracle 0.6933 (0.4435) kd_loss 0.9162 (0.9238) acc 90.6250 (88.5938) gate/entropy 1.0912 (1.0920) gate/usage_max 0.3888 (0.3851) gate/usage_min 0.2914 (0.2932) gate/usage_std 0.0409 (0.0384) teacher/entropy 0.0937 (0.0842) teacher/usage_max 0.7009 (0.7412) teacher/usage_min 0.0782 (0.0795) teacher/usage_std 0.2664 (0.2942) nleep/row_max_mean 1496.1455 (1522.7986) nleep/row_max_std 94.8946 (65.8837) nleep/row_min_mean 1470.5681 (1500.0714) lr 1.9921e-03 eta 0:11:50
epoch [4/50] batch [60/160] time 0.092 (0.095) data 0.000 (0.004) loss 1.3869 (1.4756) teacher_loss 0.2394 (0.2942) loss_zs_kd 0.0664 (0.0507) loss_oracle 0.4075 (0.4777) kd_loss 0.9106 (0.9172) acc 90.6250 (89.0625) gate/entropy 1.0906 (1.0916) gate/usage_max 0.3915 (0.3869) gate/usage_min 0.2907 (0.2924) gate/usage_std 0.0426 (0.0396) teacher/entropy 0.0936 (0.0895) teacher/usage_max 0.7238 (0.7380) teacher/usage_min 0.1020 (0.0850) teacher/usage_std 0.2777 (0.2911) nleep/row_max_mean 1514.5891 (1523.2737) nleep/row_max_std 66.0585 (63.7582) nleep/row_min_mean 1492.2606 (1500.0437) lr 1.9921e-03 eta 0:11:47
epoch [4/50] batch [80/160] time 0.081 (0.095) data 0.000 (0.003) loss 1.2749 (1.4656) teacher_loss 0.2244 (0.2938) loss_zs_kd 0.0359 (0.0493) loss_oracle 0.3601 (0.4650) kd_loss 0.8525 (0.9146) acc 90.6250 (89.1797) gate/entropy 1.0897 (1.0913) gate/usage_max 0.3951 (0.3885) gate/usage_min 0.2888 (0.2918) gate/usage_std 0.0450 (0.0406) teacher/entropy 0.1567 (0.0920) teacher/usage_max 0.7068 (0.7318) teacher/usage_min 0.1250 (0.0932) teacher/usage_std 0.2647 (0.2858) nleep/row_max_mean 1528.8303 (1522.3939) nleep/row_max_std 56.0067 (65.4356) nleep/row_min_mean 1504.4952 (1499.0141) lr 1.9921e-03 eta 0:11:43
epoch [4/50] batch [100/160] time 0.108 (0.094) data 0.000 (0.002) loss 1.3288 (1.4760) teacher_loss 0.1716 (0.3019) loss_zs_kd 0.0436 (0.0499) loss_oracle 0.4288 (0.4689) kd_loss 0.9210 (0.9147) acc 93.7500 (88.7812) gate/entropy 1.0887 (1.0908) gate/usage_max 0.3986 (0.3901) gate/usage_min 0.2868 (0.2910) gate/usage_std 0.0475 (0.0418) teacher/entropy 0.0794 (0.0898) teacher/usage_max 0.6973 (0.7313) teacher/usage_min 0.1064 (0.0946) teacher/usage_std 0.2599 (0.2853) nleep/row_max_mean 1537.5066 (1522.5600) nleep/row_max_std 48.5591 (65.1797) nleep/row_min_mean 1513.6030 (1498.7848) lr 1.9921e-03 eta 0:11:37
epoch [4/50] batch [120/160] time 0.097 (0.095) data 0.000 (0.002) loss 1.4444 (1.4779) teacher_loss 0.3249 (0.3040) loss_zs_kd 0.0520 (0.0498) loss_oracle 0.4500 (0.4730) kd_loss 0.8685 (0.9125) acc 81.2500 (88.7500) gate/entropy 1.0873 (1.0904) gate/usage_max 0.4031 (0.3919) gate/usage_min 0.2839 (0.2900) gate/usage_std 0.0508 (0.0430) teacher/entropy 0.0966 (0.0884) teacher/usage_max 0.8121 (0.7357) teacher/usage_min 0.0939 (0.0927) teacher/usage_std 0.3386 (0.2882) nleep/row_max_mean 1531.0710 (1522.7515) nleep/row_max_std 59.3986 (64.3595) nleep/row_min_mean 1501.5723 (1498.4566) lr 1.9921e-03 eta 0:11:41
epoch [4/50] batch [140/160] time 0.097 (0.095) data 0.000 (0.002) loss 1.5517 (1.4740) teacher_loss 0.3263 (0.3017) loss_zs_kd 0.0615 (0.0503) loss_oracle 0.4984 (0.4699) kd_loss 0.9454 (0.9122) acc 90.6250 (88.7500) gate/entropy 1.0860 (1.0898) gate/usage_max 0.4070 (0.3938) gate/usage_min 0.2816 (0.2890) gate/usage_std 0.0535 (0.0443) teacher/entropy 0.0520 (0.0867) teacher/usage_max 0.6575 (0.7336) teacher/usage_min 0.0770 (0.0930) teacher/usage_std 0.2418 (0.2868) nleep/row_max_mean 1501.8422 (1522.9368) nleep/row_max_std 88.2365 (63.7219) nleep/row_min_mean 1476.5928 (1498.2947) lr 1.9921e-03 eta 0:11:42
epoch [4/50] batch [160/160] time 0.090 (0.095) data 0.000 (0.002) loss 1.8284 (1.4696) teacher_loss 0.7457 (0.2993) loss_zs_kd 0.0620 (0.0519) loss_oracle 0.3238 (0.4645) kd_loss 0.8898 (0.9121) acc 78.1250 (88.8477) gate/entropy 1.0850 (1.0893) gate/usage_max 0.4102 (0.3957) gate/usage_min 0.2797 (0.2879) gate/usage_std 0.0558 (0.0456) teacher/entropy 0.0672 (0.0850) teacher/usage_max 0.7930 (0.7303) teacher/usage_min 0.0817 (0.0930) teacher/usage_std 0.3255 (0.2847) nleep/row_max_mean 1505.3833 (1522.4595) nleep/row_max_std 97.2434 (64.0064) nleep/row_min_mean 1477.9705 (1497.4729) lr 1.9823e-03 eta 0:11:39
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,780
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 82.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,962
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.1%
******* Domain p best val acc:      81.8%, epoch: 2 *******
******* Domain p best val test acc: 89.0%, epoch: 2 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [5/50] batch [20/160] time 0.104 (0.117) data 0.000 (0.012) loss 1.3369 (1.4146) teacher_loss 0.2702 (0.3035) loss_zs_kd 0.0458 (0.0542) loss_oracle 0.3522 (0.3823) kd_loss 0.8676 (0.8929) acc 90.6250 (88.9062) gate/entropy 1.0839 (1.0844) gate/usage_max 0.4134 (0.4119) gate/usage_min 0.2779 (0.2788) gate/usage_std 0.0580 (0.0569) teacher/entropy 0.0640 (0.0818) teacher/usage_max 0.8532 (0.7304) teacher/usage_min 0.0520 (0.0963) teacher/usage_std 0.3680 (0.2848) nleep/row_max_mean 1523.5999 (1518.4761) nleep/row_max_std 72.2637 (67.2493) nleep/row_min_mean 1496.9928 (1492.0348) lr 1.9823e-03 eta 0:14:20
epoch [5/50] batch [40/160] time 0.100 (0.110) data 0.000 (0.006) loss 1.4667 (1.4293) teacher_loss 0.2395 (0.3032) loss_zs_kd 0.0591 (0.0565) loss_oracle 0.4600 (0.4075) kd_loss 0.9677 (0.8941) acc 90.6250 (89.1406) gate/entropy 1.0827 (1.0838) gate/usage_max 0.4167 (0.4134) gate/usage_min 0.2762 (0.2779) gate/usage_std 0.0603 (0.0580) teacher/entropy 0.0467 (0.0803) teacher/usage_max 0.5945 (0.7254) teacher/usage_min 0.1545 (0.0978) teacher/usage_std 0.1888 (0.2809) nleep/row_max_mean 1517.3958 (1518.0684) nleep/row_max_std 71.2144 (67.8059) nleep/row_min_mean 1491.5204 (1491.6871) lr 1.9823e-03 eta 0:13:24
epoch [5/50] batch [60/160] time 0.100 (0.106) data 0.001 (0.004) loss 1.2138 (1.4200) teacher_loss 0.1101 (0.2909) loss_zs_kd 0.0691 (0.0545) loss_oracle 0.4951 (0.4155) kd_loss 0.8216 (0.8941) acc 100.0000 (89.7396) gate/entropy 1.0816 (1.0833) gate/usage_max 0.4197 (0.4150) gate/usage_min 0.2748 (0.2771) gate/usage_std 0.0623 (0.0591) teacher/entropy 0.1652 (0.0807) teacher/usage_max 0.6877 (0.7182) teacher/usage_min 0.1251 (0.1005) teacher/usage_std 0.2519 (0.2761) nleep/row_max_mean 1523.0371 (1520.1089) nleep/row_max_std 69.0906 (65.6374) nleep/row_min_mean 1497.5823 (1493.6187) lr 1.9823e-03 eta 0:12:51
epoch [5/50] batch [80/160] time 0.093 (0.108) data 0.001 (0.003) loss 1.5185 (1.4288) teacher_loss 0.4166 (0.2946) loss_zs_kd 0.0519 (0.0553) loss_oracle 0.5121 (0.4256) kd_loss 0.8199 (0.8937) acc 78.1250 (89.6094) gate/entropy 1.0806 (1.0827) gate/usage_max 0.4225 (0.4166) gate/usage_min 0.2738 (0.2764) gate/usage_std 0.0642 (0.0602) teacher/entropy 0.1386 (0.0844) teacher/usage_max 0.7691 (0.7075) teacher/usage_min 0.0315 (0.1029) teacher/usage_std 0.3157 (0.2690) nleep/row_max_mean 1530.5736 (1519.8631) nleep/row_max_std 61.6162 (66.1610) nleep/row_min_mean 1503.3143 (1493.4696) lr 1.9823e-03 eta 0:13:09
epoch [5/50] batch [100/160] time 0.090 (0.104) data 0.000 (0.003) loss 1.3876 (1.4227) teacher_loss 0.1195 (0.2793) loss_zs_kd 0.0455 (0.0553) loss_oracle 0.5144 (0.4382) kd_loss 0.9881 (0.8966) acc 96.8750 (90.1562) gate/entropy 1.0798 (1.0822) gate/usage_max 0.4248 (0.4180) gate/usage_min 0.2735 (0.2759) gate/usage_std 0.0657 (0.0611) teacher/entropy 0.1135 (0.0858) teacher/usage_max 0.3703 (0.6930) teacher/usage_min 0.3125 (0.1118) teacher/usage_std 0.0262 (0.2584) nleep/row_max_mean 1532.7628 (1518.9740) nleep/row_max_std 26.6126 (66.3418) nleep/row_min_mean 1507.8413 (1492.7917) lr 1.9823e-03 eta 0:12:37
epoch [5/50] batch [120/160] time 0.090 (0.103) data 0.000 (0.002) loss 1.6053 (1.4349) teacher_loss 0.3610 (0.2795) loss_zs_kd 0.0317 (0.0562) loss_oracle 0.6305 (0.4571) kd_loss 0.9132 (0.8987) acc 84.3750 (90.0781) gate/entropy 1.0791 (1.0818) gate/usage_max 0.4268 (0.4193) gate/usage_min 0.2735 (0.2755) gate/usage_std 0.0670 (0.0620) teacher/entropy 0.0904 (0.0872) teacher/usage_max 0.6498 (0.6830) teacher/usage_min 0.0315 (0.1135) teacher/usage_std 0.2527 (0.2521) nleep/row_max_mean 1496.7483 (1518.1637) nleep/row_max_std 93.2733 (66.7728) nleep/row_min_mean 1474.0139 (1492.1459) lr 1.9823e-03 eta 0:12:22
epoch [5/50] batch [140/160] time 0.087 (0.102) data 0.000 (0.002) loss 1.5469 (1.4413) teacher_loss 0.2995 (0.2712) loss_zs_kd 0.0990 (0.0573) loss_oracle 0.6086 (0.4783) kd_loss 0.8936 (0.9023) acc 90.6250 (90.5357) gate/entropy 1.0787 (1.0814) gate/usage_max 0.4282 (0.4204) gate/usage_min 0.2741 (0.2752) gate/usage_std 0.0678 (0.0627) teacher/entropy 0.1638 (0.0905) teacher/usage_max 0.4768 (0.6639) teacher/usage_min 0.2422 (0.1210) teacher/usage_std 0.1027 (0.2397) nleep/row_max_mean 1522.2792 (1518.2204) nleep/row_max_std 47.8936 (65.9404) nleep/row_min_mean 1496.7972 (1492.2352) lr 1.9823e-03 eta 0:12:13
epoch [5/50] batch [160/160] time 0.087 (0.100) data 0.000 (0.002) loss 1.5417 (1.4469) teacher_loss 0.1946 (0.2595) loss_zs_kd 0.0646 (0.0572) loss_oracle 0.7114 (0.5005) kd_loss 0.9591 (0.9085) acc 93.7500 (91.0352) gate/entropy 1.0787 (1.0810) gate/usage_max 0.4284 (0.4214) gate/usage_min 0.2756 (0.2752) gate/usage_std 0.0677 (0.0633) teacher/entropy 0.1432 (0.0920) teacher/usage_max 0.4471 (0.6453) teacher/usage_min 0.1563 (0.1256) teacher/usage_std 0.1269 (0.2285) nleep/row_max_mean 1508.9753 (1517.7785) nleep/row_max_std 69.8369 (65.5017) nleep/row_min_mean 1483.1670 (1491.8820) lr 1.9686e-03 eta 0:11:57
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,831
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,964
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.5%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [6/50] batch [20/160] time 0.085 (0.108) data 0.000 (0.017) loss 1.7299 (1.5323) teacher_loss 0.3114 (0.2259) loss_zs_kd 0.0547 (0.0537) loss_oracle 0.7399 (0.6496) kd_loss 1.0213 (0.9547) acc 90.6250 (92.9688) gate/entropy 1.0788 (1.0789) gate/usage_max 0.4285 (0.4281) gate/usage_min 0.2772 (0.2766) gate/usage_std 0.0676 (0.0674) teacher/entropy 0.0648 (0.1085) teacher/usage_max 0.4179 (0.4855) teacher/usage_min 0.2185 (0.1739) teacher/usage_std 0.0842 (0.1316) nleep/row_max_mean 1525.8767 (1512.7163) nleep/row_max_std 48.2185 (69.8895) nleep/row_min_mean 1500.9373 (1487.3237) lr 1.9686e-03 eta 0:12:56
epoch [6/50] batch [40/160] time 0.093 (0.098) data 0.000 (0.009) loss 1.3985 (1.5055) teacher_loss 0.2083 (0.2067) loss_zs_kd 0.0467 (0.0551) loss_oracle 0.4287 (0.6438) kd_loss 0.9526 (0.9493) acc 93.7500 (93.2812) gate/entropy 1.0793 (1.0790) gate/usage_max 0.4274 (0.4279) gate/usage_min 0.2799 (0.2776) gate/usage_std 0.0667 (0.0673) teacher/entropy 0.1319 (0.1176) teacher/usage_max 0.4209 (0.4829) teacher/usage_min 0.2288 (0.1654) teacher/usage_std 0.0793 (0.1349) nleep/row_max_mean 1488.6418 (1513.4780) nleep/row_max_std 90.7080 (67.9218) nleep/row_min_mean 1467.9312 (1487.7957) lr 1.9686e-03 eta 0:11:38
epoch [6/50] batch [60/160] time 0.073 (0.095) data 0.000 (0.006) loss 1.4993 (1.4795) teacher_loss 0.2413 (0.2098) loss_zs_kd 0.0413 (0.0569) loss_oracle 0.4591 (0.5806) kd_loss 1.0078 (0.9510) acc 90.6250 (93.6979) gate/entropy 1.0793 (1.0791) gate/usage_max 0.4275 (0.4279) gate/usage_min 0.2811 (0.2785) gate/usage_std 0.0667 (0.0671) teacher/entropy 0.1531 (0.1191) teacher/usage_max 0.6070 (0.4870) teacher/usage_min 0.1485 (0.1613) teacher/usage_std 0.1974 (0.1387) nleep/row_max_mean 1510.9757 (1513.9906) nleep/row_max_std 92.0491 (68.9528) nleep/row_min_mean 1484.9730 (1487.9785) lr 1.9686e-03 eta 0:11:16
epoch [6/50] batch [80/160] time 0.093 (0.093) data 0.000 (0.004) loss 1.4667 (1.4679) teacher_loss 0.2082 (0.2012) loss_zs_kd 0.0517 (0.0592) loss_oracle 0.4537 (0.5548) kd_loss 1.0058 (0.9596) acc 90.6250 (94.1016) gate/entropy 1.0793 (1.0791) gate/usage_max 0.4277 (0.4278) gate/usage_min 0.2824 (0.2793) gate/usage_std 0.0668 (0.0671) teacher/entropy 0.0780 (0.1164) teacher/usage_max 0.4185 (0.4813) teacher/usage_min 0.2164 (0.1642) teacher/usage_std 0.0855 (0.1351) nleep/row_max_mean 1530.6929 (1515.0557) nleep/row_max_std 50.3301 (68.4125) nleep/row_min_mean 1503.0392 (1488.7976) lr 1.9686e-03 eta 0:11:00
epoch [6/50] batch [100/160] time 0.079 (0.092) data 0.000 (0.004) loss 1.5401 (1.4673) teacher_loss 0.0722 (0.2008) loss_zs_kd 0.0807 (0.0598) loss_oracle 0.6084 (0.5409) kd_loss 1.1234 (0.9662) acc 96.8750 (94.0938) gate/entropy 1.0794 (1.0792) gate/usage_max 0.4276 (0.4278) gate/usage_min 0.2838 (0.2801) gate/usage_std 0.0667 (0.0670) teacher/entropy 0.0420 (0.1126) teacher/usage_max 0.4763 (0.4783) teacher/usage_min 0.2150 (0.1626) teacher/usage_std 0.1081 (0.1348) nleep/row_max_mean 1514.3798 (1515.6901) nleep/row_max_std 58.8861 (67.4592) nleep/row_min_mean 1487.8481 (1489.1621) lr 1.9686e-03 eta 0:10:51
epoch [6/50] batch [120/160] time 0.101 (0.091) data 0.000 (0.003) loss 1.5426 (1.4653) teacher_loss 0.0993 (0.1906) loss_zs_kd 0.0899 (0.0627) loss_oracle 0.7220 (0.5420) kd_loss 1.0373 (0.9722) acc 96.8750 (94.4792) gate/entropy 1.0795 (1.0792) gate/usage_max 0.4273 (0.4278) gate/usage_min 0.2855 (0.2808) gate/usage_std 0.0664 (0.0670) teacher/entropy 0.1118 (0.1085) teacher/usage_max 0.5534 (0.4814) teacher/usage_min 0.1921 (0.1607) teacher/usage_std 0.1577 (0.1371) nleep/row_max_mean 1536.0486 (1516.5404) nleep/row_max_std 31.1326 (66.1102) nleep/row_min_mean 1503.9116 (1489.7060) lr 1.9686e-03 eta 0:10:46
epoch [6/50] batch [140/160] time 0.074 (0.091) data 0.000 (0.003) loss 1.5019 (1.4644) teacher_loss 0.1124 (0.1847) loss_zs_kd 0.0540 (0.0641) loss_oracle 0.5670 (0.5404) kd_loss 1.0790 (0.9775) acc 93.7500 (94.6652) gate/entropy 1.0800 (1.0793) gate/usage_max 0.4262 (0.4277) gate/usage_min 0.2865 (0.2816) gate/usage_std 0.0656 (0.0668) teacher/entropy 0.0896 (0.1048) teacher/usage_max 0.5502 (0.4810) teacher/usage_min 0.1999 (0.1627) teacher/usage_std 0.1547 (0.1362) nleep/row_max_mean 1502.3997 (1516.5663) nleep/row_max_std 77.1152 (65.7416) nleep/row_min_mean 1476.0643 (1489.6192) lr 1.9686e-03 eta 0:10:39
epoch [6/50] batch [160/160] time 0.084 (0.090) data 0.000 (0.002) loss 1.4959 (1.4645) teacher_loss 0.0434 (0.1743) loss_zs_kd 0.1152 (0.0667) loss_oracle 0.6855 (0.5463) kd_loss 1.0521 (0.9836) acc 100.0000 (95.0000) gate/entropy 1.0800 (1.0793) gate/usage_max 0.4260 (0.4275) gate/usage_min 0.2847 (0.2821) gate/usage_std 0.0655 (0.0667) teacher/entropy 0.0357 (0.1006) teacher/usage_max 0.5430 (0.4844) teacher/usage_min 0.0626 (0.1600) teacher/usage_std 0.2008 (0.1387) nleep/row_max_mean 1522.9412 (1516.5876) nleep/row_max_std 61.3120 (65.2113) nleep/row_min_mean 1490.2692 (1489.4387) lr 1.9511e-03 eta 0:10:34
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,822
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,967
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.8%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [7/50] batch [20/160] time 0.111 (0.134) data 0.001 (0.025) loss 1.6766 (1.5037) teacher_loss 0.2321 (0.1248) loss_zs_kd 0.0736 (0.0761) loss_oracle 0.5983 (0.5991) kd_loss 1.1085 (1.0413) acc 96.8750 (97.1875) gate/entropy 1.0804 (1.0802) gate/usage_max 0.4248 (0.4254) gate/usage_min 0.2835 (0.2842) gate/usage_std 0.0648 (0.0651) teacher/entropy 0.0226 (0.0646) teacher/usage_max 0.5994 (0.5077) teacher/usage_min 0.1251 (0.1558) teacher/usage_std 0.1979 (0.1485) nleep/row_max_mean 1523.3512 (1517.4807) nleep/row_max_std 64.7736 (64.6184) nleep/row_min_mean 1494.1052 (1488.3918) lr 1.9511e-03 eta 0:15:39
epoch [7/50] batch [40/160] time 0.098 (0.119) data 0.000 (0.013) loss 1.4235 (1.4726) teacher_loss 0.0599 (0.1005) loss_zs_kd 0.0728 (0.0766) loss_oracle 0.5674 (0.5820) kd_loss 1.0435 (1.0428) acc 100.0000 (97.8906) gate/entropy 1.0807 (1.0804) gate/usage_max 0.4240 (0.4249) gate/usage_min 0.2820 (0.2834) gate/usage_std 0.0643 (0.0649) teacher/entropy 0.0662 (0.0578) teacher/usage_max 0.4569 (0.5043) teacher/usage_min 0.2104 (0.1526) teacher/usage_std 0.1006 (0.1487) nleep/row_max_mean 1510.3826 (1516.0051) nleep/row_max_std 74.1178 (65.4984) nleep/row_min_mean 1483.4481 (1487.0340) lr 1.9511e-03 eta 0:13:54
epoch [7/50] batch [60/160] time 0.100 (0.113) data 0.000 (0.009) loss 1.3266 (1.4803) teacher_loss 0.0295 (0.1034) loss_zs_kd 0.0847 (0.0771) loss_oracle 0.5916 (0.5880) kd_loss 0.9590 (1.0443) acc 100.0000 (97.7083) gate/entropy 1.0809 (1.0805) gate/usage_max 0.4232 (0.4245) gate/usage_min 0.2808 (0.2827) gate/usage_std 0.0638 (0.0646) teacher/entropy 0.1064 (0.0532) teacher/usage_max 0.4405 (0.5040) teacher/usage_min 0.1326 (0.1549) teacher/usage_std 0.1421 (0.1477) nleep/row_max_mean 1496.2178 (1515.2392) nleep/row_max_std 91.6837 (65.6944) nleep/row_min_mean 1467.9231 (1486.2732) lr 1.9511e-03 eta 0:13:10
epoch [7/50] batch [80/160] time 0.095 (0.110) data 0.001 (0.007) loss 1.3847 (1.4757) teacher_loss 0.0304 (0.0947) loss_zs_kd 0.0828 (0.0797) loss_oracle 0.5392 (0.5839) kd_loss 1.0433 (1.0492) acc 100.0000 (97.7344) gate/entropy 1.0810 (1.0806) gate/usage_max 0.4228 (0.4242) gate/usage_min 0.2794 (0.2820) gate/usage_std 0.0637 (0.0644) teacher/entropy 0.0084 (0.0479) teacher/usage_max 0.4697 (0.5050) teacher/usage_min 0.0937 (0.1541) teacher/usage_std 0.1700 (0.1488) nleep/row_max_mean 1534.8796 (1516.6782) nleep/row_max_std 26.7667 (64.3813) nleep/row_min_mean 1503.3601 (1487.4414) lr 1.9511e-03 eta 0:12:42
epoch [7/50] batch [100/160] time 0.088 (0.106) data 0.000 (0.005) loss 1.4385 (1.4762) teacher_loss 0.0427 (0.0959) loss_zs_kd 0.0937 (0.0809) loss_oracle 0.5363 (0.5775) kd_loss 1.0808 (1.0510) acc 100.0000 (97.7188) gate/entropy 1.0811 (1.0807) gate/usage_max 0.4221 (0.4238) gate/usage_min 0.2784 (0.2814) gate/usage_std 0.0634 (0.0642) teacher/entropy 0.0351 (0.0444) teacher/usage_max 0.4764 (0.4937) teacher/usage_min 0.2188 (0.1611) teacher/usage_std 0.1071 (0.1414) nleep/row_max_mean 1520.0652 (1516.5041) nleep/row_max_std 64.2827 (65.3513) nleep/row_min_mean 1490.9026 (1487.2856) lr 1.9511e-03 eta 0:12:17
epoch [7/50] batch [120/160] time 0.094 (0.104) data 0.000 (0.004) loss 1.4404 (1.4764) teacher_loss 0.0841 (0.0967) loss_zs_kd 0.0531 (0.0817) loss_oracle 0.5110 (0.5751) kd_loss 1.0742 (1.0513) acc 96.8750 (97.7344) gate/entropy 1.0810 (1.0808) gate/usage_max 0.4221 (0.4235) gate/usage_min 0.2769 (0.2808) gate/usage_std 0.0635 (0.0641) teacher/entropy 0.0316 (0.0425) teacher/usage_max 0.5280 (0.4933) teacher/usage_min 0.1563 (0.1599) teacher/usage_std 0.1523 (0.1417) nleep/row_max_mean 1530.1772 (1515.5785) nleep/row_max_std 53.1040 (66.2527) nleep/row_min_mean 1500.2076 (1486.4620) lr 1.9511e-03 eta 0:11:58
epoch [7/50] batch [140/160] time 0.097 (0.102) data 0.000 (0.004) loss 1.4828 (1.4743) teacher_loss 0.0317 (0.0944) loss_zs_kd 0.1026 (0.0818) loss_oracle 0.6419 (0.5750) kd_loss 1.0789 (1.0515) acc 100.0000 (97.8795) gate/entropy 1.0811 (1.0808) gate/usage_max 0.4216 (0.4232) gate/usage_min 0.2757 (0.2802) gate/usage_std 0.0634 (0.0640) teacher/entropy 0.0104 (0.0406) teacher/usage_max 0.4038 (0.4930) teacher/usage_min 0.2186 (0.1593) teacher/usage_std 0.0818 (0.1417) nleep/row_max_mean 1512.4299 (1515.3542) nleep/row_max_std 78.6173 (67.2051) nleep/row_min_mean 1482.7350 (1486.2810) lr 1.9511e-03 eta 0:11:46
epoch [7/50] batch [160/160] time 0.083 (0.100) data 0.000 (0.003) loss 1.5302 (1.4747) teacher_loss 0.0842 (0.0915) loss_zs_kd 0.0885 (0.0831) loss_oracle 0.6311 (0.5778) kd_loss 1.0863 (1.0528) acc 93.7500 (97.9688) gate/entropy 1.0815 (1.0809) gate/usage_max 0.4201 (0.4229) gate/usage_min 0.2751 (0.2796) gate/usage_std 0.0625 (0.0638) teacher/entropy 0.0451 (0.0392) teacher/usage_max 0.4223 (0.4923) teacher/usage_min 0.2723 (0.1614) teacher/usage_std 0.0644 (0.1405) nleep/row_max_mean 1503.0574 (1515.5083) nleep/row_max_std 77.2741 (67.0027) nleep/row_min_mean 1476.2415 (1486.4789) lr 1.9298e-03 eta 0:11:31
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,811
* accuracy: 82.1%
* error: 17.9%
* macro_f1: 84.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,948
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 88.3%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [8/50] batch [20/160] time 0.086 (0.106) data 0.000 (0.013) loss 1.4616 (1.4475) teacher_loss 0.0785 (0.0578) loss_zs_kd 0.0906 (0.0826) loss_oracle 0.5772 (0.5782) kd_loss 1.0492 (1.0592) acc 96.8750 (98.7500) gate/entropy 1.0816 (1.0814) gate/usage_max 0.4195 (0.4201) gate/usage_min 0.2736 (0.2741) gate/usage_std 0.0624 (0.0627) teacher/entropy 0.0258 (0.0227) teacher/usage_max 0.4955 (0.5044) teacher/usage_min 0.1222 (0.1398) teacher/usage_std 0.1563 (0.1567) nleep/row_max_mean 1516.8344 (1520.0021) nleep/row_max_std 50.6512 (60.3155) nleep/row_min_mean 1485.9617 (1490.0096) lr 1.9298e-03 eta 0:12:06
epoch [8/50] batch [40/160] time 0.098 (0.099) data 0.000 (0.007) loss 1.5028 (1.4568) teacher_loss 0.0765 (0.0622) loss_zs_kd 0.0908 (0.0834) loss_oracle 0.6515 (0.5941) kd_loss 1.0551 (1.0558) acc 96.8750 (98.6719) gate/entropy 1.0816 (1.0815) gate/usage_max 0.4190 (0.4196) gate/usage_min 0.2726 (0.2737) gate/usage_std 0.0623 (0.0625) teacher/entropy 0.0209 (0.0243) teacher/usage_max 0.4579 (0.4871) teacher/usage_min 0.1563 (0.1511) teacher/usage_std 0.1286 (0.1441) nleep/row_max_mean 1520.5522 (1518.0458) nleep/row_max_std 73.4165 (63.1970) nleep/row_min_mean 1490.5433 (1488.6274) lr 1.9298e-03 eta 0:11:19
epoch [8/50] batch [60/160] time 0.094 (0.097) data 0.000 (0.005) loss 1.4818 (1.4713) teacher_loss 0.0111 (0.0709) loss_zs_kd 0.1034 (0.0866) loss_oracle 0.6503 (0.5960) kd_loss 1.0939 (1.0591) acc 100.0000 (98.4896) gate/entropy 1.0820 (1.0816) gate/usage_max 0.4175 (0.4192) gate/usage_min 0.2721 (0.2733) gate/usage_std 0.0615 (0.0623) teacher/entropy 0.0208 (0.0223) teacher/usage_max 0.6361 (0.4924) teacher/usage_min 0.1251 (0.1499) teacher/usage_std 0.2190 (0.1467) nleep/row_max_mean 1511.3379 (1517.2947) nleep/row_max_std 73.1706 (64.0041) nleep/row_min_mean 1481.3962 (1488.0586) lr 1.9298e-03 eta 0:11:01
epoch [8/50] batch [80/160] time 0.098 (0.096) data 0.000 (0.004) loss 1.5705 (1.4689) teacher_loss 0.1615 (0.0694) loss_zs_kd 0.0864 (0.0860) loss_oracle 0.6736 (0.5949) kd_loss 1.0290 (1.0591) acc 93.7500 (98.3984) gate/entropy 1.0820 (1.0817) gate/usage_max 0.4167 (0.4187) gate/usage_min 0.2709 (0.2728) gate/usage_std 0.0613 (0.0621) teacher/entropy 0.0184 (0.0230) teacher/usage_max 0.4613 (0.4958) teacher/usage_min 0.1250 (0.1540) teacher/usage_std 0.1486 (0.1461) nleep/row_max_mean 1498.1573 (1515.8412) nleep/row_max_std 93.2967 (65.7911) nleep/row_min_mean 1469.0067 (1486.7457) lr 1.9298e-03 eta 0:10:53
epoch [8/50] batch [100/160] time 0.092 (0.095) data 0.000 (0.003) loss 1.4465 (1.4728) teacher_loss 0.0279 (0.0695) loss_zs_kd 0.1057 (0.0864) loss_oracle 0.6170 (0.6031) kd_loss 1.0572 (1.0586) acc 100.0000 (98.3750) gate/entropy 1.0823 (1.0818) gate/usage_max 0.4155 (0.4182) gate/usage_min 0.2702 (0.2723) gate/usage_std 0.0608 (0.0619) teacher/entropy 0.0224 (0.0243) teacher/usage_max 0.4848 (0.4897) teacher/usage_min 0.1562 (0.1619) teacher/usage_std 0.1354 (0.1398) nleep/row_max_mean 1502.9430 (1517.2407) nleep/row_max_std 89.6306 (64.3137) nleep/row_min_mean 1473.4373 (1488.0172) lr 1.9298e-03 eta 0:10:45
epoch [8/50] batch [120/160] time 0.155 (0.097) data 0.001 (0.002) loss 1.4981 (1.4776) teacher_loss 0.0909 (0.0768) loss_zs_kd 0.0772 (0.0859) loss_oracle 0.6304 (0.6031) kd_loss 1.0534 (1.0564) acc 96.8750 (98.1250) gate/entropy 1.0822 (1.0818) gate/usage_max 0.4152 (0.4178) gate/usage_min 0.2692 (0.2719) gate/usage_std 0.0609 (0.0618) teacher/entropy 0.0048 (0.0255) teacher/usage_max 0.4679 (0.4918) teacher/usage_min 0.2187 (0.1599) teacher/usage_std 0.1027 (0.1418) nleep/row_max_mean 1528.7737 (1516.9994) nleep/row_max_std 66.9279 (64.9447) nleep/row_min_mean 1497.3845 (1487.7819) lr 1.9298e-03 eta 0:10:54
epoch [8/50] batch [140/160] time 0.093 (0.098) data 0.000 (0.002) loss 1.5086 (1.4802) teacher_loss 0.0810 (0.0814) loss_zs_kd 0.0680 (0.0858) loss_oracle 0.6796 (0.6023) kd_loss 1.0539 (1.0548) acc 96.8750 (98.0804) gate/entropy 1.0822 (1.0819) gate/usage_max 0.4146 (0.4173) gate/usage_min 0.2683 (0.2714) gate/usage_std 0.0608 (0.0616) teacher/entropy 0.0212 (0.0257) teacher/usage_max 0.4268 (0.4899) teacher/usage_min 0.1875 (0.1616) teacher/usage_std 0.1045 (0.1402) nleep/row_max_mean 1506.9268 (1516.3942) nleep/row_max_std 61.2162 (65.5205) nleep/row_min_mean 1478.6152 (1487.1441) lr 1.9298e-03 eta 0:11:00
epoch [8/50] batch [160/160] time 0.077 (0.096) data 0.000 (0.002) loss 1.4675 (1.4852) teacher_loss 0.0185 (0.0809) loss_zs_kd 0.1245 (0.0876) loss_oracle 0.6894 (0.6092) kd_loss 1.0421 (1.0559) acc 100.0000 (98.0664) gate/entropy 1.0822 (1.0819) gate/usage_max 0.4140 (0.4169) gate/usage_min 0.2674 (0.2710) gate/usage_std 0.0607 (0.0615) teacher/entropy 0.0002 (0.0245) teacher/usage_max 0.4687 (0.4907) teacher/usage_min 0.1250 (0.1625) teacher/usage_std 0.1495 (0.1403) nleep/row_max_mean 1520.5586 (1516.4787) nleep/row_max_std 62.0676 (65.7478) nleep/row_min_mean 1488.4895 (1487.2579) lr 1.9048e-03 eta 0:10:46
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,821
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,976
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 88.9%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [9/50] batch [20/160] time 0.093 (0.114) data 0.000 (0.018) loss 1.3239 (1.4461) teacher_loss 0.0212 (0.0782) loss_zs_kd 0.0927 (0.0705) loss_oracle 0.5093 (0.5695) kd_loss 1.0017 (1.0479) acc 100.0000 (98.4375) gate/entropy 1.0825 (1.0824) gate/usage_max 0.4127 (0.4133) gate/usage_min 0.2670 (0.2673) gate/usage_std 0.0602 (0.0604) teacher/entropy 0.0407 (0.0216) teacher/usage_max 0.5180 (0.5026) teacher/usage_min 0.0625 (0.1393) teacher/usage_std 0.1957 (0.1538) nleep/row_max_mean 1510.9163 (1521.6694) nleep/row_max_std 87.1402 (58.3314) nleep/row_min_mean 1483.6006 (1493.0326) lr 1.9048e-03 eta 0:12:42
epoch [9/50] batch [40/160] time 0.084 (0.104) data 0.000 (0.009) loss 1.3250 (1.4553) teacher_loss 0.0223 (0.0846) loss_zs_kd 0.0812 (0.0797) loss_oracle 0.5252 (0.5799) kd_loss 0.9996 (1.0409) acc 100.0000 (98.1250) gate/entropy 1.0825 (1.0824) gate/usage_max 0.4121 (0.4128) gate/usage_min 0.2662 (0.2669) gate/usage_std 0.0601 (0.0603) teacher/entropy 0.0193 (0.0247) teacher/usage_max 0.5541 (0.4932) teacher/usage_min 0.1249 (0.1396) teacher/usage_std 0.1755 (0.1509) nleep/row_max_mean 1527.7700 (1516.5452) nleep/row_max_std 30.9916 (64.4541) nleep/row_min_mean 1498.4167 (1488.6984) lr 1.9048e-03 eta 0:11:36
epoch [9/50] batch [60/160] time 0.097 (0.101) data 0.000 (0.006) loss 1.4166 (1.4509) teacher_loss 0.0283 (0.0776) loss_zs_kd 0.0831 (0.0788) loss_oracle 0.5894 (0.5790) kd_loss 1.0520 (1.0443) acc 100.0000 (98.2292) gate/entropy 1.0823 (1.0824) gate/usage_max 0.4118 (0.4125) gate/usage_min 0.2650 (0.2665) gate/usage_std 0.0603 (0.0603) teacher/entropy 0.0289 (0.0251) teacher/usage_max 0.5297 (0.4978) teacher/usage_min 0.1517 (0.1491) teacher/usage_std 0.1547 (0.1487) nleep/row_max_mean 1512.7255 (1516.4414) nleep/row_max_std 73.7836 (64.3385) nleep/row_min_mean 1486.7159 (1488.8596) lr 1.9048e-03 eta 0:11:14
epoch [9/50] batch [80/160] time 0.089 (0.099) data 0.000 (0.005) loss 1.4906 (1.4593) teacher_loss 0.1018 (0.0821) loss_zs_kd 0.0760 (0.0812) loss_oracle 0.7037 (0.5909) kd_loss 0.9989 (1.0412) acc 96.8750 (98.0469) gate/entropy 1.0821 (1.0824) gate/usage_max 0.4116 (0.4123) gate/usage_min 0.2638 (0.2660) gate/usage_std 0.0606 (0.0603) teacher/entropy 0.0597 (0.0239) teacher/usage_max 0.4239 (0.4975) teacher/usage_min 0.1729 (0.1450) teacher/usage_std 0.1138 (0.1505) nleep/row_max_mean 1505.3146 (1515.1080) nleep/row_max_std 71.2744 (65.7673) nleep/row_min_mean 1476.6405 (1487.3291) lr 1.9048e-03 eta 0:10:56
epoch [9/50] batch [100/160] time 0.090 (0.098) data 0.000 (0.004) loss 1.4079 (1.4625) teacher_loss 0.0638 (0.0837) loss_zs_kd 0.0718 (0.0813) loss_oracle 0.5997 (0.5946) kd_loss 1.0084 (1.0408) acc 100.0000 (98.0938) gate/entropy 1.0820 (1.0823) gate/usage_max 0.4113 (0.4121) gate/usage_min 0.2628 (0.2655) gate/usage_std 0.0609 (0.0604) teacher/entropy 0.0396 (0.0236) teacher/usage_max 0.4369 (0.4939) teacher/usage_min 0.1322 (0.1476) teacher/usage_std 0.1423 (0.1476) nleep/row_max_mean 1516.9147 (1514.6531) nleep/row_max_std 74.8431 (65.6918) nleep/row_min_mean 1486.9640 (1486.7409) lr 1.9048e-03 eta 0:10:50
epoch [9/50] batch [120/160] time 0.093 (0.098) data 0.000 (0.003) loss 1.4316 (1.4596) teacher_loss 0.0477 (0.0786) loss_zs_kd 0.0654 (0.0823) loss_oracle 0.5896 (0.5977) kd_loss 1.0564 (1.0410) acc 100.0000 (98.2552) gate/entropy 1.0818 (1.0823) gate/usage_max 0.4109 (0.4119) gate/usage_min 0.2616 (0.2649) gate/usage_std 0.0611 (0.0605) teacher/entropy 0.0155 (0.0241) teacher/usage_max 0.5031 (0.4944) teacher/usage_min 0.1554 (0.1489) teacher/usage_std 0.1421 (0.1472) nleep/row_max_mean 1514.7859 (1514.5573) nleep/row_max_std 73.4226 (65.3257) nleep/row_min_mean 1486.8674 (1486.4975) lr 1.9048e-03 eta 0:10:46
epoch [9/50] batch [140/160] time 0.094 (0.097) data 0.000 (0.003) loss 1.4451 (1.4638) teacher_loss 0.0245 (0.0799) loss_zs_kd 0.0783 (0.0837) loss_oracle 0.6257 (0.5996) kd_loss 1.0686 (1.0423) acc 100.0000 (98.2366) gate/entropy 1.0819 (1.0822) gate/usage_max 0.4099 (0.4117) gate/usage_min 0.2611 (0.2644) gate/usage_std 0.0608 (0.0605) teacher/entropy 0.0298 (0.0252) teacher/usage_max 0.5047 (0.4923) teacher/usage_min 0.2149 (0.1545) teacher/usage_std 0.1241 (0.1436) nleep/row_max_mean 1507.7356 (1513.8104) nleep/row_max_std 82.5589 (65.4556) nleep/row_min_mean 1478.6107 (1485.7515) lr 1.9048e-03 eta 0:10:39
epoch [9/50] batch [160/160] time 0.088 (0.096) data 0.000 (0.003) loss 1.3083 (1.4604) teacher_loss 0.0613 (0.0790) loss_zs_kd 0.0523 (0.0833) loss_oracle 0.4867 (0.5959) kd_loss 0.9774 (1.0418) acc 96.8750 (98.2617) gate/entropy 1.0818 (1.0822) gate/usage_max 0.4094 (0.4115) gate/usage_min 0.2601 (0.2639) gate/usage_std 0.0610 (0.0606) teacher/entropy 0.0675 (0.0258) teacher/usage_max 0.4581 (0.4906) teacher/usage_min 0.1211 (0.1571) teacher/usage_std 0.1508 (0.1419) nleep/row_max_mean 1516.3770 (1513.3758) nleep/row_max_std 73.6981 (65.9414) nleep/row_min_mean 1487.8114 (1485.2561) lr 1.8763e-03 eta 0:10:31
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,817
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,997
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 89.3%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [10/50] batch [20/160] time 0.106 (0.118) data 0.000 (0.018) loss 1.4989 (1.4553) teacher_loss 0.1467 (0.0943) loss_zs_kd 0.0860 (0.0781) loss_oracle 0.5797 (0.5986) kd_loss 1.0194 (1.0226) acc 96.8750 (97.9688) gate/entropy 1.0817 (1.0817) gate/usage_max 0.4088 (0.4091) gate/usage_min 0.2590 (0.2595) gate/usage_std 0.0611 (0.0611) teacher/entropy 0.0206 (0.0373) teacher/usage_max 0.4991 (0.5000) teacher/usage_min 0.0935 (0.1466) teacher/usage_std 0.1737 (0.1499) nleep/row_max_mean 1497.6490 (1512.6020) nleep/row_max_std 94.3842 (67.3615) nleep/row_min_mean 1471.8528 (1483.7606) lr 1.8763e-03 eta 0:12:49
epoch [10/50] batch [40/160] time 0.092 (0.115) data 0.001 (0.009) loss 1.5479 (1.4507) teacher_loss 0.1909 (0.0983) loss_zs_kd 0.0714 (0.0749) loss_oracle 0.5089 (0.5921) kd_loss 1.0668 (1.0189) acc 90.6250 (97.5781) gate/entropy 1.0815 (1.0816) gate/usage_max 0.4084 (0.4089) gate/usage_min 0.2582 (0.2590) gate/usage_std 0.0613 (0.0612) teacher/entropy 0.0446 (0.0403) teacher/usage_max 0.3807 (0.4837) teacher/usage_min 0.3056 (0.1523) teacher/usage_std 0.0337 (0.1419) nleep/row_max_mean 1510.7097 (1514.2121) nleep/row_max_std 69.9321 (64.2508) nleep/row_min_mean 1484.0428 (1485.6245) lr 1.8763e-03 eta 0:12:26
epoch [10/50] batch [60/160] time 0.091 (0.109) data 0.000 (0.006) loss 1.3275 (1.4481) teacher_loss 0.0273 (0.0914) loss_zs_kd 0.0581 (0.0779) loss_oracle 0.5369 (0.5962) kd_loss 1.0027 (1.0196) acc 100.0000 (97.6562) gate/entropy 1.0812 (1.0815) gate/usage_max 0.4083 (0.4087) gate/usage_min 0.2569 (0.2585) gate/usage_std 0.0618 (0.0613) teacher/entropy 0.0537 (0.0389) teacher/usage_max 0.4876 (0.4859) teacher/usage_min 0.1412 (0.1486) teacher/usage_std 0.1439 (0.1441) nleep/row_max_mean 1540.5698 (1514.7108) nleep/row_max_std 29.7882 (64.6360) nleep/row_min_mean 1509.5790 (1486.0843) lr 1.8763e-03 eta 0:11:47
epoch [10/50] batch [80/160] time 0.096 (0.107) data 0.000 (0.005) loss 1.3567 (1.4426) teacher_loss 0.1158 (0.0969) loss_zs_kd 0.0613 (0.0783) loss_oracle 0.5407 (0.5826) kd_loss 0.9399 (1.0152) acc 96.8750 (97.6562) gate/entropy 1.0809 (1.0814) gate/usage_max 0.4079 (0.4085) gate/usage_min 0.2555 (0.2580) gate/usage_std 0.0622 (0.0615) teacher/entropy 0.0865 (0.0404) teacher/usage_max 0.5203 (0.4976) teacher/usage_min 0.0656 (0.1404) teacher/usage_std 0.1942 (0.1522) nleep/row_max_mean 1510.3577 (1516.2773) nleep/row_max_std 82.4450 (63.4528) nleep/row_min_mean 1482.4479 (1487.5320) lr 1.8763e-03 eta 0:11:32
epoch [10/50] batch [100/160] time 0.091 (0.104) data 0.000 (0.004) loss 1.3438 (1.4357) teacher_loss 0.0680 (0.0964) loss_zs_kd 0.0660 (0.0789) loss_oracle 0.5983 (0.5775) kd_loss 0.9436 (1.0111) acc 100.0000 (97.7188) gate/entropy 1.0806 (1.0813) gate/usage_max 0.4078 (0.4084) gate/usage_min 0.2543 (0.2574) gate/usage_std 0.0628 (0.0617) teacher/entropy 0.0590 (0.0412) teacher/usage_max 0.5451 (0.5022) teacher/usage_min 0.0744 (0.1368) teacher/usage_std 0.1950 (0.1552) nleep/row_max_mean 1516.5442 (1516.3822) nleep/row_max_std 67.2103 (63.8847) nleep/row_min_mean 1487.9768 (1487.6443) lr 1.8763e-03 eta 0:11:10
epoch [10/50] batch [120/160] time 0.093 (0.102) data 0.000 (0.003) loss 1.3835 (1.4241) teacher_loss 0.0533 (0.0938) loss_zs_kd 0.0702 (0.0784) loss_oracle 0.5451 (0.5709) kd_loss 1.0225 (1.0057) acc 100.0000 (97.8906) gate/entropy 1.0802 (1.0812) gate/usage_max 0.4080 (0.4083) gate/usage_min 0.2530 (0.2567) gate/usage_std 0.0634 (0.0619) teacher/entropy 0.0101 (0.0427) teacher/usage_max 0.5018 (0.5028) teacher/usage_min 0.0937 (0.1313) teacher/usage_std 0.1741 (0.1580) nleep/row_max_mean 1518.5538 (1517.2984) nleep/row_max_std 67.0276 (62.6360) nleep/row_min_mean 1489.8046 (1488.6661) lr 1.8763e-03 eta 0:10:56
epoch [10/50] batch [140/160] time 0.091 (0.101) data 0.000 (0.003) loss 1.4207 (1.4221) teacher_loss 0.1623 (0.0959) loss_zs_kd 0.0544 (0.0775) loss_oracle 0.5805 (0.5687) kd_loss 0.9409 (1.0031) acc 96.8750 (97.9688) gate/entropy 1.0794 (1.0810) gate/usage_max 0.4091 (0.4083) gate/usage_min 0.2509 (0.2561) gate/usage_std 0.0647 (0.0622) teacher/entropy 0.0402 (0.0431) teacher/usage_max 0.5459 (0.5024) teacher/usage_min 0.0121 (0.1286) teacher/usage_std 0.2311 (0.1592) nleep/row_max_mean 1525.4954 (1517.7426) nleep/row_max_std 69.4319 (62.1668) nleep/row_min_mean 1496.2522 (1489.1896) lr 1.8763e-03 eta 0:10:46
epoch [10/50] batch [160/160] time 0.085 (0.100) data 0.000 (0.003) loss 1.2797 (1.4208) teacher_loss 0.1109 (0.1007) loss_zs_kd 0.0573 (0.0777) loss_oracle 0.4225 (0.5665) kd_loss 0.9289 (0.9980) acc 96.8750 (97.8906) gate/entropy 1.0791 (1.0808) gate/usage_max 0.4087 (0.4083) gate/usage_min 0.2500 (0.2555) gate/usage_std 0.0651 (0.0625) teacher/entropy 0.0936 (0.0456) teacher/usage_max 0.5903 (0.5035) teacher/usage_min 0.0452 (0.1243) teacher/usage_std 0.2236 (0.1615) nleep/row_max_mean 1531.5929 (1517.6314) nleep/row_max_std 49.6769 (62.4162) nleep/row_min_mean 1503.3759 (1489.2746) lr 1.8443e-03 eta 0:10:37
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,744
* accuracy: 79.1%
* error: 20.9%
* macro_f1: 82.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,791
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 85.2%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [11/50] batch [20/160] time 0.096 (0.107) data 0.000 (0.014) loss 1.4542 (1.4239) teacher_loss 0.1541 (0.1479) loss_zs_kd 0.0751 (0.0669) loss_oracle 0.6171 (0.5528) kd_loss 0.9540 (0.9662) acc 96.8750 (96.2500) gate/entropy 1.0788 (1.0791) gate/usage_max 0.4087 (0.4084) gate/usage_min 0.2489 (0.2498) gate/usage_std 0.0655 (0.0650) teacher/entropy 0.0469 (0.0629) teacher/usage_max 0.5605 (0.5300) teacher/usage_min 0.0917 (0.0961) teacher/usage_std 0.1917 (0.1843) nleep/row_max_mean 1516.6592 (1516.3499) nleep/row_max_std 72.0243 (67.1455) nleep/row_min_mean 1488.6016 (1489.3413) lr 1.8443e-03 eta 0:11:20
epoch [11/50] batch [40/160] time 0.104 (0.103) data 0.000 (0.007) loss 1.4261 (1.4272) teacher_loss 0.1443 (0.1441) loss_zs_kd 0.0523 (0.0690) loss_oracle 0.4952 (0.5667) kd_loss 1.0081 (0.9653) acc 93.7500 (96.1719) gate/entropy 1.0788 (1.0790) gate/usage_max 0.4078 (0.4083) gate/usage_min 0.2484 (0.2492) gate/usage_std 0.0655 (0.0653) teacher/entropy 0.0347 (0.0636) teacher/usage_max 0.5644 (0.5253) teacher/usage_min 0.1022 (0.0983) teacher/usage_std 0.1887 (0.1813) nleep/row_max_mean 1523.0278 (1513.4310) nleep/row_max_std 57.9983 (69.0959) nleep/row_min_mean 1496.7388 (1487.3501) lr 1.8443e-03 eta 0:10:53
epoch [11/50] batch [60/160] time 0.093 (0.101) data 0.001 (0.005) loss 1.2828 (1.4237) teacher_loss 0.0863 (0.1381) loss_zs_kd 0.0456 (0.0690) loss_oracle 0.5025 (0.5682) kd_loss 0.9224 (0.9670) acc 100.0000 (96.5104) gate/entropy 1.0784 (1.0789) gate/usage_max 0.4077 (0.4081) gate/usage_min 0.2471 (0.2488) gate/usage_std 0.0661 (0.0654) teacher/entropy 0.1048 (0.0652) teacher/usage_max 0.4538 (0.5249) teacher/usage_min 0.1114 (0.1050) teacher/usage_std 0.1571 (0.1779) nleep/row_max_mean 1535.4103 (1513.9491) nleep/row_max_std 25.6609 (68.0180) nleep/row_min_mean 1511.9020 (1488.2433) lr 1.8443e-03 eta 0:10:39
epoch [11/50] batch [80/160] time 0.090 (0.100) data 0.000 (0.004) loss 1.4295 (1.4116) teacher_loss 0.1763 (0.1285) loss_zs_kd 0.0533 (0.0674) loss_oracle 0.5541 (0.5637) kd_loss 0.9495 (0.9676) acc 93.7500 (96.7188) gate/entropy 1.0782 (1.0787) gate/usage_max 0.4070 (0.4079) gate/usage_min 0.2461 (0.2483) gate/usage_std 0.0664 (0.0656) teacher/entropy 0.0767 (0.0660) teacher/usage_max 0.6032 (0.5316) teacher/usage_min 0.0629 (0.1047) teacher/usage_std 0.2206 (0.1805) nleep/row_max_mean 1514.1888 (1515.2380) nleep/row_max_std 65.8932 (65.9488) nleep/row_min_mean 1489.1643 (1489.7504) lr 1.8443e-03 eta 0:10:30
epoch [11/50] batch [100/160] time 0.099 (0.099) data 0.000 (0.003) loss 1.4938 (1.4173) teacher_loss 0.2138 (0.1430) loss_zs_kd 0.0724 (0.0663) loss_oracle 0.5233 (0.5571) kd_loss 0.9822 (0.9626) acc 90.6250 (96.0000) gate/entropy 1.0781 (1.0786) gate/usage_max 0.4060 (0.4076) gate/usage_min 0.2455 (0.2478) gate/usage_std 0.0664 (0.0657) teacher/entropy 0.0504 (0.0718) teacher/usage_max 0.6556 (0.5360) teacher/usage_min 0.0636 (0.1052) teacher/usage_std 0.2445 (0.1818) nleep/row_max_mean 1502.5540 (1515.5709) nleep/row_max_std 85.6555 (65.4767) nleep/row_min_mean 1479.7400 (1490.3622) lr 1.8443e-03 eta 0:10:24
epoch [11/50] batch [120/160] time 0.103 (0.098) data 0.000 (0.003) loss 1.4300 (1.4276) teacher_loss 0.1398 (0.1474) loss_zs_kd 0.0770 (0.0665) loss_oracle 0.5711 (0.5623) kd_loss 0.9661 (0.9658) acc 96.8750 (95.7812) gate/entropy 1.0779 (1.0785) gate/usage_max 0.4045 (0.4072) gate/usage_min 0.2443 (0.2473) gate/usage_std 0.0666 (0.0659) teacher/entropy 0.0801 (0.0717) teacher/usage_max 0.5328 (0.5447) teacher/usage_min 0.1335 (0.1086) teacher/usage_std 0.1630 (0.1848) nleep/row_max_mean 1515.5867 (1516.0449) nleep/row_max_std 68.1371 (64.6354) nleep/row_min_mean 1489.6270 (1490.9576) lr 1.8443e-03 eta 0:10:17
epoch [11/50] batch [140/160] time 0.099 (0.098) data 0.000 (0.002) loss 1.3921 (1.4323) teacher_loss 0.1018 (0.1514) loss_zs_kd 0.0281 (0.0654) loss_oracle 0.6152 (0.5646) kd_loss 0.9687 (0.9659) acc 96.8750 (95.4911) gate/entropy 1.0777 (1.0784) gate/usage_max 0.4028 (0.4066) gate/usage_min 0.2432 (0.2468) gate/usage_std 0.0668 (0.0659) teacher/entropy 0.0675 (0.0735) teacher/usage_max 0.5012 (0.5462) teacher/usage_min 0.1247 (0.1127) teacher/usage_std 0.1564 (0.1835) nleep/row_max_mean 1523.1802 (1516.0092) nleep/row_max_std 61.5755 (64.1157) nleep/row_min_mean 1499.8926 (1491.1498) lr 1.8443e-03 eta 0:10:16
epoch [11/50] batch [160/160] time 0.072 (0.099) data 0.000 (0.002) loss 1.4330 (1.4395) teacher_loss 0.2039 (0.1562) loss_zs_kd 0.0410 (0.0657) loss_oracle 0.5672 (0.5677) kd_loss 0.9249 (0.9666) acc 93.7500 (95.3320) gate/entropy 1.0777 (1.0784) gate/usage_max 0.4010 (0.4060) gate/usage_min 0.2425 (0.2464) gate/usage_std 0.0668 (0.0660) teacher/entropy 0.0876 (0.0738) teacher/usage_max 0.4799 (0.5543) teacher/usage_min 0.0999 (0.1135) teacher/usage_std 0.1668 (0.1868) nleep/row_max_mean 1526.2588 (1515.7555) nleep/row_max_std 45.0663 (63.3490) nleep/row_min_mean 1503.3953 (1491.0204) lr 1.8090e-03 eta 0:10:20
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,797
* accuracy: 81.5%
* error: 18.5%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,917
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 87.8%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [12/50] batch [20/160] time 0.090 (0.103) data 0.000 (0.015) loss 1.6319 (1.4504) teacher_loss 0.3468 (0.2073) loss_zs_kd 0.0491 (0.0615) loss_oracle 0.5402 (0.5323) kd_loss 0.9905 (0.9462) acc 84.3750 (93.4375) gate/entropy 1.0776 (1.0778) gate/usage_max 0.3992 (0.3998) gate/usage_min 0.2417 (0.2424) gate/usage_std 0.0668 (0.0665) teacher/entropy 0.0609 (0.0962) teacher/usage_max 0.7042 (0.6171) teacher/usage_min 0.1187 (0.1131) teacher/usage_std 0.2634 (0.2153) nleep/row_max_mean 1507.5042 (1509.5912) nleep/row_max_std 64.6886 (67.4088) nleep/row_min_mean 1482.6537 (1486.5814) lr 1.8090e-03 eta 0:10:39
epoch [12/50] batch [40/160] time 0.080 (0.091) data 0.000 (0.008) loss 1.4071 (1.4692) teacher_loss 0.1210 (0.2173) loss_zs_kd 0.0657 (0.0620) loss_oracle 0.5606 (0.5476) kd_loss 0.9729 (0.9471) acc 96.8750 (93.3594) gate/entropy 1.0774 (1.0777) gate/usage_max 0.3974 (0.3989) gate/usage_min 0.2408 (0.2420) gate/usage_std 0.0670 (0.0666) teacher/entropy 0.0825 (0.1006) teacher/usage_max 0.5913 (0.6013) teacher/usage_min 0.1563 (0.1280) teacher/usage_std 0.1866 (0.2029) nleep/row_max_mean 1523.8136 (1510.4403) nleep/row_max_std 64.0497 (65.0159) nleep/row_min_mean 1499.3508 (1487.6550) lr 1.8090e-03 eta 0:09:24
epoch [12/50] batch [60/160] time 0.093 (0.089) data 0.000 (0.005) loss 1.4439 (1.4604) teacher_loss 0.0980 (0.2051) loss_zs_kd 0.0710 (0.0634) loss_oracle 0.5724 (0.5488) kd_loss 1.0242 (0.9493) acc 100.0000 (93.8542) gate/entropy 1.0775 (1.0777) gate/usage_max 0.3955 (0.3980) gate/usage_min 0.2407 (0.2416) gate/usage_std 0.0667 (0.0667) teacher/entropy 0.0433 (0.0968) teacher/usage_max 0.5528 (0.5904) teacher/usage_min 0.1910 (0.1310) teacher/usage_std 0.1574 (0.1966) nleep/row_max_mean 1506.6680 (1511.6270) nleep/row_max_std 50.7435 (62.6478) nleep/row_min_mean 1483.2072 (1488.7703) lr 1.8090e-03 eta 0:09:08
epoch [12/50] batch [80/160] time 0.073 (0.087) data 0.000 (0.004) loss 1.4863 (1.4584) teacher_loss 0.2424 (0.2024) loss_zs_kd 0.0548 (0.0619) loss_oracle 0.4786 (0.5497) kd_loss 0.9772 (0.9502) acc 93.7500 (93.7109) gate/entropy 1.0771 (1.0776) gate/usage_max 0.3948 (0.3973) gate/usage_min 0.2396 (0.2412) gate/usage_std 0.0674 (0.0668) teacher/entropy 0.0651 (0.0939) teacher/usage_max 0.6733 (0.5869) teacher/usage_min 0.1250 (0.1311) teacher/usage_std 0.2424 (0.1943) nleep/row_max_mean 1522.1663 (1511.7129) nleep/row_max_std 20.2383 (61.8917) nleep/row_min_mean 1501.4681 (1488.9457) lr 1.8090e-03 eta 0:08:58
epoch [12/50] batch [100/160] time 0.101 (0.089) data 0.000 (0.003) loss 1.2740 (1.4482) teacher_loss 0.0836 (0.1987) loss_zs_kd 0.0444 (0.0597) loss_oracle 0.5271 (0.5433) kd_loss 0.9047 (0.9480) acc 100.0000 (93.5625) gate/entropy 1.0771 (1.0775) gate/usage_max 0.3938 (0.3966) gate/usage_min 0.2393 (0.2409) gate/usage_std 0.0674 (0.0669) teacher/entropy 0.1242 (0.0957) teacher/usage_max 0.5430 (0.5814) teacher/usage_min 0.1214 (0.1330) teacher/usage_std 0.1722 (0.1909) nleep/row_max_mean 1520.4760 (1511.8083) nleep/row_max_std 48.2476 (62.2792) nleep/row_min_mean 1496.3770 (1489.1959) lr 1.8090e-03 eta 0:09:03
epoch [12/50] batch [120/160] time 0.093 (0.089) data 0.000 (0.003) loss 1.4218 (1.4491) teacher_loss 0.1989 (0.2032) loss_zs_kd 0.0557 (0.0601) loss_oracle 0.4455 (0.5433) kd_loss 0.9723 (0.9442) acc 90.6250 (93.3594) gate/entropy 1.0767 (1.0774) gate/usage_max 0.3930 (0.3961) gate/usage_min 0.2383 (0.2406) gate/usage_std 0.0680 (0.0670) teacher/entropy 0.0492 (0.0979) teacher/usage_max 0.7077 (0.5772) teacher/usage_min 0.0879 (0.1322) teacher/usage_std 0.2689 (0.1895) nleep/row_max_mean 1531.3901 (1511.7578) nleep/row_max_std 23.8076 (61.7509) nleep/row_min_mean 1509.8955 (1489.2582) lr 1.8090e-03 eta 0:09:06
epoch [12/50] batch [140/160] time 0.088 (0.090) data 0.000 (0.002) loss 1.7803 (1.4498) teacher_loss 0.4286 (0.2069) loss_zs_kd 0.0646 (0.0588) loss_oracle 0.5536 (0.5411) kd_loss 1.0426 (0.9430) acc 87.5000 (93.0580) gate/entropy 1.0763 (1.0773) gate/usage_max 0.3922 (0.3955) gate/usage_min 0.2372 (0.2402) gate/usage_std 0.0685 (0.0672) teacher/entropy 0.0830 (0.0984) teacher/usage_max 0.3631 (0.5725) teacher/usage_min 0.2949 (0.1331) teacher/usage_std 0.0285 (0.1869) nleep/row_max_mean 1509.7897 (1511.4565) nleep/row_max_std 76.9384 (62.1811) nleep/row_min_mean 1486.7147 (1489.1597) lr 1.8090e-03 eta 0:09:07
epoch [12/50] batch [160/160] time 0.091 (0.090) data 0.000 (0.002) loss 1.4054 (1.4458) teacher_loss 0.1827 (0.2053) loss_zs_kd 0.0426 (0.0584) loss_oracle 0.5524 (0.5390) kd_loss 0.9252 (0.9418) acc 90.6250 (93.1250) gate/entropy 1.0761 (1.0772) gate/usage_max 0.3906 (0.3950) gate/usage_min 0.2367 (0.2398) gate/usage_std 0.0687 (0.0673) teacher/entropy 0.1150 (0.0998) teacher/usage_max 0.5135 (0.5721) teacher/usage_min 0.1547 (0.1341) teacher/usage_std 0.1465 (0.1864) nleep/row_max_mean 1523.3577 (1511.4112) nleep/row_max_std 43.9476 (61.7144) nleep/row_min_mean 1503.5381 (1489.3574) lr 1.7705e-03 eta 0:09:07
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,800
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 83.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 3,002
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 89.3%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [13/50] batch [20/160] time 0.083 (0.114) data 0.000 (0.018) loss 1.3921 (1.4061) teacher_loss 0.2593 (0.2143) loss_zs_kd 0.0227 (0.0372) loss_oracle 0.5069 (0.5245) kd_loss 0.8680 (0.9109) acc 90.6250 (92.9688) gate/entropy 1.0761 (1.0761) gate/usage_max 0.3895 (0.3900) gate/usage_min 0.2366 (0.2366) gate/usage_std 0.0687 (0.0687) teacher/entropy 0.1814 (0.1278) teacher/usage_max 0.4807 (0.5082) teacher/usage_min 0.1779 (0.1537) teacher/usage_std 0.1238 (0.1502) nleep/row_max_mean 1506.4628 (1509.1111) nleep/row_max_std 75.0399 (65.4181) nleep/row_min_mean 1487.6943 (1489.9090) lr 1.7705e-03 eta 0:11:28
epoch [13/50] batch [40/160] time 0.100 (0.104) data 0.000 (0.009) loss 1.4334 (1.4210) teacher_loss 0.2071 (0.2203) loss_zs_kd 0.0486 (0.0423) loss_oracle 0.5789 (0.5275) kd_loss 0.9126 (0.9158) acc 90.6250 (92.3438) gate/entropy 1.0761 (1.0760) gate/usage_max 0.3889 (0.3897) gate/usage_min 0.2366 (0.2364) gate/usage_std 0.0686 (0.0688) teacher/entropy 0.1265 (0.1278) teacher/usage_max 0.4482 (0.5110) teacher/usage_min 0.1608 (0.1611) teacher/usage_std 0.1242 (0.1479) nleep/row_max_mean 1502.6787 (1510.2437) nleep/row_max_std 77.6813 (63.8208) nleep/row_min_mean 1482.0068 (1491.0606) lr 1.7705e-03 eta 0:10:29
epoch [13/50] batch [60/160] time 0.093 (0.101) data 0.000 (0.006) loss 1.2001 (1.4333) teacher_loss 0.1351 (0.2283) loss_zs_kd 0.0423 (0.0432) loss_oracle 0.5073 (0.5348) kd_loss 0.7902 (0.9161) acc 100.0000 (92.2917) gate/entropy 1.0760 (1.0760) gate/usage_max 0.3883 (0.3894) gate/usage_min 0.2363 (0.2364) gate/usage_std 0.0688 (0.0689) teacher/entropy 0.2091 (0.1296) teacher/usage_max 0.5132 (0.5202) teacher/usage_min 0.0732 (0.1587) teacher/usage_std 0.1884 (0.1534) nleep/row_max_mean 1492.7437 (1509.9518) nleep/row_max_std 89.2644 (63.9619) nleep/row_min_mean 1476.8832 (1491.0238) lr 1.7705e-03 eta 0:10:08
epoch [13/50] batch [80/160] time 0.095 (0.104) data 0.000 (0.005) loss 1.4055 (1.4633) teacher_loss 0.2050 (0.2499) loss_zs_kd 0.0562 (0.0445) loss_oracle 0.5844 (0.5486) kd_loss 0.8801 (0.9168) acc 96.8750 (91.6797) gate/entropy 1.0759 (1.0760) gate/usage_max 0.3873 (0.3890) gate/usage_min 0.2361 (0.2364) gate/usage_std 0.0689 (0.0688) teacher/entropy 0.1529 (0.1313) teacher/usage_max 0.5660 (0.5246) teacher/usage_min 0.1427 (0.1638) teacher/usage_std 0.1754 (0.1533) nleep/row_max_mean 1520.5269 (1509.2783) nleep/row_max_std 46.0725 (63.8952) nleep/row_min_mean 1502.5483 (1490.5917) lr 1.7705e-03 eta 0:10:26
epoch [13/50] batch [100/160] time 0.085 (0.102) data 0.000 (0.004) loss 1.4376 (1.4736) teacher_loss 0.3068 (0.2522) loss_zs_kd 0.0353 (0.0444) loss_oracle 0.5128 (0.5569) kd_loss 0.8568 (0.9208) acc 93.7500 (91.5625) gate/entropy 1.0763 (1.0761) gate/usage_max 0.3854 (0.3884) gate/usage_min 0.2368 (0.2365) gate/usage_std 0.0683 (0.0687) teacher/entropy 0.2020 (0.1318) teacher/usage_max 0.6089 (0.5308) teacher/usage_min 0.1943 (0.1654) teacher/usage_std 0.1949 (0.1558) nleep/row_max_mean 1519.9802 (1509.5979) nleep/row_max_std 52.4592 (62.2463) nleep/row_min_mean 1504.4355 (1491.2465) lr 1.7705e-03 eta 0:10:11
epoch [13/50] batch [120/160] time 0.095 (0.100) data 0.000 (0.003) loss 1.5064 (1.4937) teacher_loss 0.2856 (0.2565) loss_zs_kd 0.0452 (0.0447) loss_oracle 0.6541 (0.5788) kd_loss 0.8711 (0.9254) acc 87.5000 (91.2240) gate/entropy 1.0771 (1.0762) gate/usage_max 0.3829 (0.3877) gate/usage_min 0.2383 (0.2367) gate/usage_std 0.0672 (0.0685) teacher/entropy 0.1818 (0.1327) teacher/usage_max 0.5423 (0.5302) teacher/usage_min 0.1858 (0.1704) teacher/usage_std 0.1519 (0.1539) nleep/row_max_mean 1500.8269 (1509.1433) nleep/row_max_std 84.2291 (62.8527) nleep/row_min_mean 1486.7698 (1491.1402) lr 1.7705e-03 eta 0:09:58
epoch [13/50] batch [140/160] time 0.086 (0.099) data 0.000 (0.003) loss 1.6688 (1.5122) teacher_loss 0.4661 (0.2696) loss_zs_kd 0.0399 (0.0446) loss_oracle 0.4887 (0.5869) kd_loss 0.9384 (0.9269) acc 84.3750 (90.6473) gate/entropy 1.0778 (1.0764) gate/usage_max 0.3810 (0.3869) gate/usage_min 0.2400 (0.2371) gate/usage_std 0.0660 (0.0683) teacher/entropy 0.1430 (0.1352) teacher/usage_max 0.5771 (0.5308) teacher/usage_min 0.1750 (0.1724) teacher/usage_std 0.1749 (0.1533) nleep/row_max_mean 1509.9646 (1509.5452) nleep/row_max_std 44.6735 (61.8041) nleep/row_min_mean 1496.7421 (1491.8961) lr 1.7705e-03 eta 0:09:47
epoch [13/50] batch [160/160] time 0.091 (0.098) data 0.000 (0.002) loss 1.7661 (1.5321) teacher_loss 0.2849 (0.2794) loss_zs_kd 0.0342 (0.0438) loss_oracle 0.8697 (0.6069) kd_loss 1.0293 (0.9274) acc 93.7500 (90.1367) gate/entropy 1.0784 (1.0766) gate/usage_max 0.3807 (0.3860) gate/usage_min 0.2411 (0.2375) gate/usage_std 0.0652 (0.0679) teacher/entropy 0.0873 (0.1378) teacher/usage_max 0.6021 (0.5364) teacher/usage_min 0.0606 (0.1703) teacher/usage_std 0.2211 (0.1570) nleep/row_max_mean 1520.5868 (1509.2937) nleep/row_max_std 53.6392 (61.6052) nleep/row_min_mean 1504.0444 (1491.9247) lr 1.7290e-03 eta 0:09:42
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,770
* accuracy: 80.2%
* error: 19.8%
* macro_f1: 81.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,956
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.4%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [14/50] batch [20/160] time 0.090 (0.108) data 0.000 (0.012) loss 1.7111 (1.6590) teacher_loss 0.3702 (0.3160) loss_zs_kd 0.0263 (0.0408) loss_oracle 0.7531 (0.7540) kd_loss 0.9512 (0.9456) acc 81.2500 (87.8125) gate/entropy 1.0790 (1.0788) gate/usage_max 0.3827 (0.3815) gate/usage_min 0.2425 (0.2421) gate/usage_std 0.0643 (0.0645) teacher/entropy 0.0873 (0.1291) teacher/usage_max 0.7071 (0.6357) teacher/usage_min 0.1243 (0.1144) teacher/usage_std 0.2649 (0.2234) nleep/row_max_mean 1487.0419 (1511.3175) nleep/row_max_std 92.5163 (57.6381) nleep/row_min_mean 1469.8293 (1494.5860) lr 1.7290e-03 eta 0:10:35
epoch [14/50] batch [40/160] time 0.099 (0.101) data 0.000 (0.006) loss 1.6223 (1.6765) teacher_loss 0.2911 (0.3204) loss_zs_kd 0.0573 (0.0420) loss_oracle 0.7255 (0.7767) kd_loss 0.9398 (0.9467) acc 84.3750 (87.8125) gate/entropy 1.0799 (1.0792) gate/usage_max 0.3839 (0.3824) gate/usage_min 0.2448 (0.2430) gate/usage_std 0.0628 (0.0639) teacher/entropy 0.1249 (0.1367) teacher/usage_max 0.5996 (0.6133) teacher/usage_min 0.1715 (0.1169) teacher/usage_std 0.1897 (0.2133) nleep/row_max_mean 1513.8889 (1507.9907) nleep/row_max_std 28.6071 (62.5570) nleep/row_min_mean 1497.2310 (1491.7081) lr 1.7290e-03 eta 0:09:55
epoch [14/50] batch [60/160] time 0.109 (0.099) data 0.001 (0.004) loss 1.7873 (1.6769) teacher_loss 0.4319 (0.3275) loss_zs_kd 0.0287 (0.0393) loss_oracle 0.7443 (0.7662) kd_loss 0.9689 (0.9466) acc 78.1250 (87.5000) gate/entropy 1.0806 (1.0795) gate/usage_max 0.3859 (0.3833) gate/usage_min 0.2467 (0.2440) gate/usage_std 0.0617 (0.0634) teacher/entropy 0.1435 (0.1342) teacher/usage_max 0.5833 (0.6251) teacher/usage_min 0.0614 (0.1084) teacher/usage_std 0.2136 (0.2214) nleep/row_max_mean 1504.8986 (1508.2975) nleep/row_max_std 68.8094 (63.6554) nleep/row_min_mean 1487.2981 (1492.0058) lr 1.7290e-03 eta 0:09:42
epoch [14/50] batch [80/160] time 0.101 (0.098) data 0.000 (0.003) loss 1.5105 (1.6606) teacher_loss 0.2177 (0.3306) loss_zs_kd 0.0162 (0.0392) loss_oracle 0.6941 (0.7377) kd_loss 0.9377 (0.9415) acc 87.5000 (87.4219) gate/entropy 1.0810 (1.0799) gate/usage_max 0.3880 (0.3842) gate/usage_min 0.2479 (0.2449) gate/usage_std 0.0612 (0.0629) teacher/entropy 0.1303 (0.1376) teacher/usage_max 0.6319 (0.6225) teacher/usage_min 0.1115 (0.1105) teacher/usage_std 0.2193 (0.2192) nleep/row_max_mean 1509.8213 (1508.3906) nleep/row_max_std 64.8696 (63.0492) nleep/row_min_mean 1491.8389 (1492.1421) lr 1.7290e-03 eta 0:09:32
epoch [14/50] batch [100/160] time 0.096 (0.098) data 0.000 (0.003) loss 1.5665 (1.6590) teacher_loss 0.2433 (0.3303) loss_zs_kd 0.0635 (0.0408) loss_oracle 0.7140 (0.7307) kd_loss 0.9345 (0.9430) acc 90.6250 (87.3750) gate/entropy 1.0817 (1.0802) gate/usage_max 0.3896 (0.3851) gate/usage_min 0.2501 (0.2457) gate/usage_std 0.0601 (0.0624) teacher/entropy 0.1031 (0.1364) teacher/usage_max 0.7129 (0.6207) teacher/usage_min 0.0825 (0.1069) teacher/usage_std 0.2729 (0.2189) nleep/row_max_mean 1507.6794 (1507.5562) nleep/row_max_std 68.3705 (63.1160) nleep/row_min_mean 1490.8427 (1491.1656) lr 1.7290e-03 eta 0:09:29
epoch [14/50] batch [120/160] time 0.092 (0.097) data 0.000 (0.002) loss 1.6357 (1.6567) teacher_loss 0.3244 (0.3346) loss_zs_kd 0.0319 (0.0409) loss_oracle 0.6420 (0.7164) kd_loss 0.9743 (0.9434) acc 90.6250 (87.3698) gate/entropy 1.0821 (1.0804) gate/usage_max 0.3917 (0.3861) gate/usage_min 0.2519 (0.2466) gate/usage_std 0.0593 (0.0620) teacher/entropy 0.1296 (0.1362) teacher/usage_max 0.5821 (0.6221) teacher/usage_min 0.0455 (0.1003) teacher/usage_std 0.2208 (0.2218) nleep/row_max_mean 1507.7417 (1506.7095) nleep/row_max_std 62.8152 (64.6095) nleep/row_min_mean 1489.6804 (1490.2349) lr 1.7290e-03 eta 0:09:23
epoch [14/50] batch [140/160] time 0.096 (0.097) data 0.000 (0.002) loss 2.0314 (1.6619) teacher_loss 0.6297 (0.3390) loss_zs_kd 0.0344 (0.0406) loss_oracle 0.7836 (0.7102) kd_loss 0.9927 (0.9475) acc 84.3750 (87.0759) gate/entropy 1.0824 (1.0807) gate/usage_max 0.3940 (0.3871) gate/usage_min 0.2534 (0.2474) gate/usage_std 0.0590 (0.0616) teacher/entropy 0.0821 (0.1326) teacher/usage_max 0.6459 (0.6215) teacher/usage_min 0.0357 (0.0936) teacher/usage_std 0.2494 (0.2239) nleep/row_max_mean 1503.1322 (1506.8957) nleep/row_max_std 89.5023 (64.4438) nleep/row_min_mean 1485.0657 (1490.2088) lr 1.7290e-03 eta 0:09:20
epoch [14/50] batch [160/160] time 0.083 (0.096) data 0.000 (0.002) loss 1.6294 (1.6699) teacher_loss 0.3126 (0.3408) loss_zs_kd 0.0396 (0.0393) loss_oracle 0.8053 (0.7232) kd_loss 0.8943 (0.9479) acc 90.6250 (86.9336) gate/entropy 1.0831 (1.0810) gate/usage_max 0.3951 (0.3880) gate/usage_min 0.2560 (0.2483) gate/usage_std 0.0578 (0.0612) teacher/entropy 0.1484 (0.1332) teacher/usage_max 0.7096 (0.6174) teacher/usage_min 0.0368 (0.0906) teacher/usage_std 0.2804 (0.2230) nleep/row_max_mean 1503.3643 (1506.5429) nleep/row_max_std 57.7631 (64.3158) nleep/row_min_mean 1488.7898 (1489.7527) lr 1.6845e-03 eta 0:09:14
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,778
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 82.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,975
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 88.3%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [15/50] batch [20/160] time 0.093 (0.111) data 0.000 (0.017) loss 1.9701 (1.8022) teacher_loss 0.5199 (0.4086) loss_zs_kd 0.0254 (0.0332) loss_oracle 0.7925 (0.8044) kd_loss 1.0412 (0.9748) acc 75.0000 (83.9062) gate/entropy 1.0838 (1.0835) gate/usage_max 0.3960 (0.3956) gate/usage_min 0.2587 (0.2575) gate/usage_std 0.0567 (0.0572) teacher/entropy 0.0901 (0.1218) teacher/usage_max 0.4891 (0.5705) teacher/usage_min 0.0334 (0.0550) teacher/usage_std 0.2121 (0.2167) nleep/row_max_mean 1505.0161 (1501.1287) nleep/row_max_std 71.2359 (64.7661) nleep/row_min_mean 1486.2852 (1483.5431) lr 1.6845e-03 eta 0:10:37
epoch [15/50] batch [40/160] time 0.090 (0.101) data 0.000 (0.008) loss 1.6370 (1.7654) teacher_loss 0.2715 (0.3799) loss_zs_kd 0.0615 (0.0362) loss_oracle 0.8315 (0.8030) kd_loss 0.9190 (0.9659) acc 93.7500 (85.0781) gate/entropy 1.0844 (1.0838) gate/usage_max 0.3972 (0.3961) gate/usage_min 0.2614 (0.2588) gate/usage_std 0.0557 (0.0567) teacher/entropy 0.1407 (0.1267) teacher/usage_max 0.6126 (0.5732) teacher/usage_min 0.0909 (0.0579) teacher/usage_std 0.2146 (0.2164) nleep/row_max_mean 1508.5667 (1503.0791) nleep/row_max_std 58.9993 (62.9532) nleep/row_min_mean 1490.2137 (1485.2646) lr 1.6845e-03 eta 0:09:39
epoch [15/50] batch [60/160] time 0.090 (0.098) data 0.001 (0.006) loss 1.7082 (1.7597) teacher_loss 0.2742 (0.3574) loss_zs_kd 0.0318 (0.0383) loss_oracle 0.9011 (0.8267) kd_loss 0.9676 (0.9698) acc 90.6250 (86.6146) gate/entropy 1.0851 (1.0841) gate/usage_max 0.3978 (0.3965) gate/usage_min 0.2646 (0.2603) gate/usage_std 0.0545 (0.0561) teacher/entropy 0.1274 (0.1257) teacher/usage_max 0.4978 (0.5681) teacher/usage_min 0.1210 (0.0576) teacher/usage_std 0.1575 (0.2143) nleep/row_max_mean 1515.5457 (1504.3715) nleep/row_max_std 43.6615 (61.6683) nleep/row_min_mean 1497.6241 (1486.4357) lr 1.6845e-03 eta 0:09:21
epoch [15/50] batch [80/160] time 0.093 (0.097) data 0.000 (0.004) loss 1.8062 (1.7561) teacher_loss 0.2963 (0.3580) loss_zs_kd 0.0398 (0.0379) loss_oracle 0.9154 (0.8297) kd_loss 1.0323 (0.9643) acc 87.5000 (86.7188) gate/entropy 1.0858 (1.0845) gate/usage_max 0.3980 (0.3968) gate/usage_min 0.2681 (0.2618) gate/usage_std 0.0530 (0.0555) teacher/entropy 0.0899 (0.1310) teacher/usage_max 0.4852 (0.5653) teacher/usage_min 0.0579 (0.0549) teacher/usage_std 0.1951 (0.2149) nleep/row_max_mean 1512.2625 (1503.8021) nleep/row_max_std 30.3575 (62.1780) nleep/row_min_mean 1493.2388 (1485.8358) lr 1.6845e-03 eta 0:09:08
epoch [15/50] batch [100/160] time 0.102 (0.097) data 0.000 (0.004) loss 1.5294 (1.7521) teacher_loss 0.2542 (0.3585) loss_zs_kd 0.0379 (0.0375) loss_oracle 0.7799 (0.8268) kd_loss 0.8663 (0.9615) acc 90.6250 (86.5625) gate/entropy 1.0863 (1.0848) gate/usage_max 0.3986 (0.3971) gate/usage_min 0.2708 (0.2634) gate/usage_std 0.0522 (0.0549) teacher/entropy 0.2070 (0.1355) teacher/usage_max 0.5780 (0.5614) teacher/usage_min 0.0411 (0.0548) teacher/usage_std 0.2218 (0.2138) nleep/row_max_mean 1520.1709 (1503.8959) nleep/row_max_std 43.5034 (62.5967) nleep/row_min_mean 1503.2964 (1485.9463) lr 1.6845e-03 eta 0:09:06
epoch [15/50] batch [120/160] time 0.079 (0.097) data 0.000 (0.003) loss 1.5974 (1.7550) teacher_loss 0.1922 (0.3595) loss_zs_kd 0.0624 (0.0382) loss_oracle 0.7893 (0.8270) kd_loss 0.9794 (0.9629) acc 96.8750 (86.6927) gate/entropy 1.0873 (1.0852) gate/usage_max 0.3976 (0.3972) gate/usage_min 0.2752 (0.2651) gate/usage_std 0.0501 (0.0542) teacher/entropy 0.1728 (0.1370) teacher/usage_max 0.6000 (0.5562) teacher/usage_min 0.0586 (0.0536) teacher/usage_std 0.2211 (0.2129) nleep/row_max_mean 1508.7705 (1503.9365) nleep/row_max_std 72.9861 (62.9860) nleep/row_min_mean 1488.1434 (1485.8642) lr 1.6845e-03 eta 0:09:05
epoch [15/50] batch [140/160] time 0.106 (0.097) data 0.000 (0.003) loss 2.0077 (1.7542) teacher_loss 0.6832 (0.3620) loss_zs_kd 0.0437 (0.0397) loss_oracle 0.7888 (0.8141) kd_loss 0.9083 (0.9652) acc 81.2500 (86.6071) gate/entropy 1.0880 (1.0855) gate/usage_max 0.3973 (0.3972) gate/usage_min 0.2789 (0.2668) gate/usage_std 0.0488 (0.0535) teacher/entropy 0.2053 (0.1380) teacher/usage_max 0.5153 (0.5553) teacher/usage_min 0.0468 (0.0532) teacher/usage_std 0.2050 (0.2128) nleep/row_max_mean 1494.5280 (1503.2673) nleep/row_max_std 86.7407 (63.1892) nleep/row_min_mean 1475.2601 (1485.0956) lr 1.6845e-03 eta 0:09:04
epoch [15/50] batch [160/160] time 0.093 (0.096) data 0.000 (0.002) loss 1.9540 (1.7541) teacher_loss 0.4950 (0.3614) loss_zs_kd 0.0402 (0.0392) loss_oracle 0.8714 (0.8143) kd_loss 1.0032 (0.9659) acc 90.6250 (86.6211) gate/entropy 1.0887 (1.0859) gate/usage_max 0.3967 (0.3972) gate/usage_min 0.2830 (0.2686) gate/usage_std 0.0473 (0.0528) teacher/entropy 0.1089 (0.1379) teacher/usage_max 0.5338 (0.5533) teacher/usage_min 0.0363 (0.0509) teacher/usage_std 0.2143 (0.2135) nleep/row_max_mean 1490.7848 (1503.3339) nleep/row_max_std 94.3670 (62.9904) nleep/row_min_mean 1471.5117 (1485.1223) lr 1.6374e-03 eta 0:08:59
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,745
* accuracy: 79.1%
* error: 20.9%
* macro_f1: 80.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,936
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 86.9%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [16/50] batch [20/160] time 0.104 (0.114) data 0.000 (0.017) loss 1.5976 (1.7944) teacher_loss 0.2617 (0.3896) loss_zs_kd 0.0264 (0.0309) loss_oracle 0.6959 (0.8082) kd_loss 0.9747 (0.9852) acc 90.6250 (85.9375) gate/entropy 1.0895 (1.0891) gate/usage_max 0.3954 (0.3959) gate/usage_min 0.2876 (0.2855) gate/usage_std 0.0455 (0.0463) teacher/entropy 0.1679 (0.1471) teacher/usage_max 0.6710 (0.6131) teacher/usage_min 0.0125 (0.0353) teacher/usage_std 0.2691 (0.2420) nleep/row_max_mean 1509.3157 (1504.6991) nleep/row_max_std 73.4282 (61.3706) nleep/row_min_mean 1491.4143 (1485.6008) lr 1.6374e-03 eta 0:10:36
epoch [16/50] batch [40/160] time 0.093 (0.107) data 0.000 (0.009) loss 1.7209 (1.7923) teacher_loss 0.3419 (0.4019) loss_zs_kd 0.0110 (0.0304) loss_oracle 0.7808 (0.7672) kd_loss 0.9832 (0.9915) acc 78.1250 (84.8438) gate/entropy 1.0903 (1.0895) gate/usage_max 0.3935 (0.3951) gate/usage_min 0.2925 (0.2878) gate/usage_std 0.0435 (0.0453) teacher/entropy 0.1182 (0.1393) teacher/usage_max 0.4983 (0.6171) teacher/usage_min 0.0959 (0.0381) teacher/usage_std 0.1721 (0.2421) nleep/row_max_mean 1513.8239 (1504.5540) nleep/row_max_std 57.4384 (61.1592) nleep/row_min_mean 1493.3420 (1485.0562) lr 1.6374e-03 eta 0:09:55
epoch [16/50] batch [60/160] time 0.087 (0.102) data 0.000 (0.006) loss 1.5906 (1.7899) teacher_loss 0.2981 (0.3975) loss_zs_kd 0.0381 (0.0335) loss_oracle 0.6897 (0.7712) kd_loss 0.9286 (0.9901) acc 87.5000 (84.8958) gate/entropy 1.0908 (1.0899) gate/usage_max 0.3923 (0.3943) gate/usage_min 0.2970 (0.2902) gate/usage_std 0.0420 (0.0444) teacher/entropy 0.1629 (0.1373) teacher/usage_max 0.5336 (0.6172) teacher/usage_min 0.0357 (0.0413) teacher/usage_std 0.2146 (0.2410) nleep/row_max_mean 1483.3242 (1502.6267) nleep/row_max_std 97.2795 (64.2141) nleep/row_min_mean 1468.4056 (1483.0568) lr 1.6374e-03 eta 0:09:27
epoch [16/50] batch [80/160] time 0.093 (0.100) data 0.000 (0.004) loss 1.5685 (1.8035) teacher_loss 0.2840 (0.4048) loss_zs_kd 0.0348 (0.0351) loss_oracle 0.7181 (0.7760) kd_loss 0.9080 (0.9932) acc 90.6250 (84.6875) gate/entropy 1.0916 (1.0903) gate/usage_max 0.3897 (0.3933) gate/usage_min 0.3021 (0.2926) gate/usage_std 0.0399 (0.0434) teacher/entropy 0.1970 (0.1359) teacher/usage_max 0.6322 (0.6365) teacher/usage_min 0.0045 (0.0429) teacher/usage_std 0.2571 (0.2490) nleep/row_max_mean 1507.7507 (1502.8068) nleep/row_max_std 75.5146 (64.2837) nleep/row_min_mean 1489.0835 (1483.1177) lr 1.6374e-03 eta 0:09:13
epoch [16/50] batch [100/160] time 0.095 (0.102) data 0.000 (0.004) loss 1.7919 (1.7857) teacher_loss 0.2845 (0.3994) loss_zs_kd 0.0610 (0.0353) loss_oracle 0.8876 (0.7527) kd_loss 1.0331 (0.9923) acc 81.2500 (84.9375) gate/entropy 1.0926 (1.0906) gate/usage_max 0.3858 (0.3922) gate/usage_min 0.3059 (0.2951) gate/usage_std 0.0371 (0.0425) teacher/entropy 0.1132 (0.1357) teacher/usage_max 0.8309 (0.6444) teacher/usage_min 0.0361 (0.0471) teacher/usage_std 0.3541 (0.2508) nleep/row_max_mean 1490.7761 (1503.2435) nleep/row_max_std 72.5378 (64.1573) nleep/row_min_mean 1466.2446 (1483.4860) lr 1.6374e-03 eta 0:09:19
epoch [16/50] batch [120/160] time 0.098 (0.103) data 0.000 (0.003) loss 1.8099 (1.7751) teacher_loss 0.4577 (0.3948) loss_zs_kd 0.0271 (0.0359) loss_oracle 0.6261 (0.7403) kd_loss 1.0255 (0.9922) acc 87.5000 (85.2604) gate/entropy 1.0929 (1.0910) gate/usage_max 0.3840 (0.3910) gate/usage_min 0.3031 (0.2967) gate/usage_std 0.0361 (0.0415) teacher/entropy 0.0867 (0.1344) teacher/usage_max 0.7186 (0.6539) teacher/usage_min 0.0334 (0.0497) teacher/usage_std 0.2862 (0.2543) nleep/row_max_mean 1505.2482 (1502.6631) nleep/row_max_std 59.7216 (63.8216) nleep/row_min_mean 1487.5264 (1482.9304) lr 1.6374e-03 eta 0:09:24
epoch [16/50] batch [140/160] time 0.087 (0.102) data 0.000 (0.003) loss 1.8525 (1.7620) teacher_loss 0.3979 (0.3843) loss_zs_kd 0.0511 (0.0373) loss_oracle 0.7803 (0.7423) kd_loss 1.0389 (0.9878) acc 84.3750 (85.6027) gate/entropy 1.0934 (1.0913) gate/usage_max 0.3810 (0.3898) gate/usage_min 0.3006 (0.2974) gate/usage_std 0.0345 (0.0406) teacher/entropy 0.0680 (0.1356) teacher/usage_max 0.7560 (0.6566) teacher/usage_min 0.0293 (0.0516) teacher/usage_std 0.3083 (0.2547) nleep/row_max_mean 1482.0881 (1502.9804) nleep/row_max_std 82.9990 (63.3259) nleep/row_min_mean 1462.4784 (1483.1595) lr 1.6374e-03 eta 0:09:15
epoch [16/50] batch [160/160] time 0.090 (0.101) data 0.000 (0.002) loss 1.6185 (1.7646) teacher_loss 0.1781 (0.3850) loss_zs_kd 0.0223 (0.0375) loss_oracle 0.8237 (0.7486) kd_loss 1.0174 (0.9865) acc 93.7500 (85.5078) gate/entropy 1.0936 (1.0916) gate/usage_max 0.3782 (0.3885) gate/usage_min 0.2979 (0.2976) gate/usage_std 0.0334 (0.0398) teacher/entropy 0.0895 (0.1340) teacher/usage_max 0.8344 (0.6643) teacher/usage_min 0.0228 (0.0510) teacher/usage_std 0.3577 (0.2587) nleep/row_max_mean 1515.9905 (1503.4209) nleep/row_max_std 44.5926 (62.6176) nleep/row_min_mean 1495.1482 (1483.5550) lr 1.5878e-03 eta 0:09:08
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,802
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 82.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,966
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 87.9%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [17/50] batch [20/160] time 0.094 (0.106) data 0.000 (0.013) loss 1.7741 (1.7669) teacher_loss 0.3046 (0.3699) loss_zs_kd 0.0338 (0.0387) loss_oracle 0.8627 (0.7887) kd_loss 1.0213 (0.9834) acc 90.6250 (87.3438) gate/entropy 1.0939 (1.0937) gate/usage_max 0.3745 (0.3766) gate/usage_min 0.2953 (0.2965) gate/usage_std 0.0324 (0.0330) teacher/entropy 0.0604 (0.1105) teacher/usage_max 0.7451 (0.7651) teacher/usage_min 0.0312 (0.0395) teacher/usage_std 0.3016 (0.3144) nleep/row_max_mean 1511.8972 (1500.9101) nleep/row_max_std 44.9345 (66.0919) nleep/row_min_mean 1486.2581 (1479.9092) lr 1.5878e-03 eta 0:09:33
epoch [17/50] batch [40/160] time 0.089 (0.101) data 0.000 (0.007) loss 1.9916 (1.7493) teacher_loss 0.6066 (0.3804) loss_zs_kd 0.0367 (0.0392) loss_oracle 0.7584 (0.7491) kd_loss 0.9875 (0.9747) acc 84.3750 (86.1719) gate/entropy 1.0938 (1.0938) gate/usage_max 0.3725 (0.3751) gate/usage_min 0.2925 (0.2951) gate/usage_std 0.0327 (0.0328) teacher/entropy 0.0955 (0.1107) teacher/usage_max 0.7320 (0.7413) teacher/usage_min 0.0733 (0.0403) teacher/usage_std 0.2863 (0.3007) nleep/row_max_mean 1466.2190 (1501.9595) nleep/row_max_std 101.7848 (64.5265) nleep/row_min_mean 1447.3245 (1480.9379) lr 1.5878e-03 eta 0:09:04
epoch [17/50] batch [60/160] time 0.093 (0.099) data 0.001 (0.004) loss 1.7052 (1.7353) teacher_loss 0.3121 (0.3743) loss_zs_kd 0.0225 (0.0372) loss_oracle 0.7488 (0.7458) kd_loss 1.0074 (0.9696) acc 84.3750 (85.8333) gate/entropy 1.0937 (1.0938) gate/usage_max 0.3686 (0.3736) gate/usage_min 0.2899 (0.2937) gate/usage_std 0.0327 (0.0328) teacher/entropy 0.0460 (0.1105) teacher/usage_max 0.7279 (0.7505) teacher/usage_min 0.0007 (0.0366) teacher/usage_std 0.3001 (0.3065) nleep/row_max_mean 1511.2434 (1503.3312) nleep/row_max_std 70.5863 (63.7047) nleep/row_min_mean 1487.1458 (1481.9947) lr 1.5878e-03 eta 0:08:54
epoch [17/50] batch [80/160] time 0.092 (0.098) data 0.000 (0.003) loss 1.6736 (1.7362) teacher_loss 0.4021 (0.3812) loss_zs_kd 0.0469 (0.0373) loss_oracle 0.6631 (0.7354) kd_loss 0.9164 (0.9687) acc 87.5000 (85.5859) gate/entropy 1.0934 (1.0937) gate/usage_max 0.3660 (0.3721) gate/usage_min 0.2870 (0.2924) gate/usage_std 0.0337 (0.0329) teacher/entropy 0.1328 (0.1057) teacher/usage_max 0.7534 (0.7624) teacher/usage_min 0.0152 (0.0319) teacher/usage_std 0.3099 (0.3139) nleep/row_max_mean 1483.0237 (1503.8572) nleep/row_max_std 88.5800 (62.4417) nleep/row_min_mean 1461.9054 (1482.0890) lr 1.5878e-03 eta 0:08:47
epoch [17/50] batch [100/160] time 0.100 (0.098) data 0.000 (0.003) loss 1.6519 (1.7420) teacher_loss 0.4319 (0.3908) loss_zs_kd 0.0249 (0.0369) loss_oracle 0.5872 (0.7319) kd_loss 0.9139 (0.9669) acc 87.5000 (85.5625) gate/entropy 1.0929 (1.0936) gate/usage_max 0.3626 (0.3706) gate/usage_min 0.2841 (0.2910) gate/usage_std 0.0350 (0.0332) teacher/entropy 0.1262 (0.1024) teacher/usage_max 0.7875 (0.7760) teacher/usage_min 0.0245 (0.0307) teacher/usage_std 0.3280 (0.3223) nleep/row_max_mean 1501.5597 (1504.1097) nleep/row_max_std 75.4596 (61.7001) nleep/row_min_mean 1483.0562 (1482.2057) lr 1.5878e-03 eta 0:08:43
epoch [17/50] batch [120/160] time 0.097 (0.098) data 0.000 (0.002) loss 1.7036 (1.7314) teacher_loss 0.4777 (0.3881) loss_zs_kd 0.0207 (0.0366) loss_oracle 0.6233 (0.7243) kd_loss 0.9039 (0.9629) acc 84.3750 (85.7812) gate/entropy 1.0923 (1.0934) gate/usage_max 0.3599 (0.3690) gate/usage_min 0.2812 (0.2896) gate/usage_std 0.0369 (0.0337) teacher/entropy 0.1211 (0.1005) teacher/usage_max 0.6798 (0.7796) teacher/usage_min 0.0078 (0.0288) teacher/usage_std 0.2748 (0.3247) nleep/row_max_mean 1507.7092 (1503.4944) nleep/row_max_std 47.9555 (61.4952) nleep/row_min_mean 1487.0568 (1481.5252) lr 1.5878e-03 eta 0:08:40
epoch [17/50] batch [140/160] time 0.078 (0.097) data 0.000 (0.002) loss 1.5647 (1.7239) teacher_loss 0.2381 (0.3886) loss_zs_kd 0.0269 (0.0357) loss_oracle 0.7364 (0.7152) kd_loss 0.9450 (0.9598) acc 90.6250 (85.6027) gate/entropy 1.0916 (1.0932) gate/usage_max 0.3645 (0.3680) gate/usage_min 0.2785 (0.2882) gate/usage_std 0.0389 (0.0343) teacher/entropy 0.0681 (0.0976) teacher/usage_max 0.8665 (0.7782) teacher/usage_min 0.0066 (0.0269) teacher/usage_std 0.3802 (0.3244) nleep/row_max_mean 1513.9346 (1504.1881) nleep/row_max_std 44.0227 (60.2317) nleep/row_min_mean 1490.5471 (1482.0781) lr 1.5878e-03 eta 0:08:33
epoch [17/50] batch [160/160] time 0.092 (0.096) data 0.000 (0.002) loss 1.7006 (1.7133) teacher_loss 0.4621 (0.3866) loss_zs_kd 0.0347 (0.0346) loss_oracle 0.6258 (0.7069) kd_loss 0.9083 (0.9559) acc 87.5000 (85.7031) gate/entropy 1.0907 (1.0930) gate/usage_max 0.3699 (0.3679) gate/usage_min 0.2758 (0.2868) gate/usage_std 0.0412 (0.0350) teacher/entropy 0.0987 (0.0959) teacher/usage_max 0.7042 (0.7765) teacher/usage_min 0.0007 (0.0258) teacher/usage_std 0.2885 (0.3235) nleep/row_max_mean 1506.3955 (1503.9044) nleep/row_max_std 49.6000 (60.9260) nleep/row_min_mean 1484.2385 (1481.7076) lr 1.5358e-03 eta 0:08:27
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,820
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,992
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 89.1%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [18/50] batch [20/160] time 0.072 (0.130) data 0.000 (0.016) loss 1.5104 (1.6023) teacher_loss 0.2309 (0.3095) loss_zs_kd 0.0312 (0.0356) loss_oracle 0.7141 (0.6969) kd_loss 0.9068 (0.9266) acc 93.7500 (90.4688) gate/entropy 1.0899 (1.0903) gate/usage_max 0.3753 (0.3726) gate/usage_min 0.2735 (0.2744) gate/usage_std 0.0434 (0.0424) teacher/entropy 0.0925 (0.0789) teacher/usage_max 0.7831 (0.7667) teacher/usage_min 0.0236 (0.0244) teacher/usage_std 0.3255 (0.3167) nleep/row_max_mean 1490.9902 (1502.8409) nleep/row_max_std 72.7854 (59.2902) nleep/row_min_mean 1467.4886 (1480.3592) lr 1.5358e-03 eta 0:11:22
epoch [18/50] batch [40/160] time 0.087 (0.109) data 0.000 (0.008) loss 1.6583 (1.6267) teacher_loss 0.3259 (0.3441) loss_zs_kd 0.0396 (0.0307) loss_oracle 0.7709 (0.6939) kd_loss 0.9271 (0.9204) acc 87.5000 (88.6719) gate/entropy 1.0889 (1.0898) gate/usage_max 0.3803 (0.3752) gate/usage_min 0.2710 (0.2731) gate/usage_std 0.0459 (0.0437) teacher/entropy 0.0510 (0.0793) teacher/usage_max 0.8798 (0.7803) teacher/usage_min 0.0056 (0.0223) teacher/usage_std 0.3890 (0.3261) nleep/row_max_mean 1495.6006 (1502.1917) nleep/row_max_std 55.0542 (61.0875) nleep/row_min_mean 1473.8651 (1479.8750) lr 1.5358e-03 eta 0:09:28
epoch [18/50] batch [60/160] time 0.097 (0.103) data 0.000 (0.005) loss 1.8875 (1.6286) teacher_loss 0.6350 (0.3515) loss_zs_kd 0.0155 (0.0293) loss_oracle 0.6606 (0.6884) kd_loss 0.9145 (0.9181) acc 78.1250 (88.1250) gate/entropy 1.0876 (1.0892) gate/usage_max 0.3854 (0.3778) gate/usage_min 0.2682 (0.2719) gate/usage_std 0.0488 (0.0449) teacher/entropy 0.0674 (0.0750) teacher/usage_max 0.8138 (0.7892) teacher/usage_min 0.0357 (0.0180) teacher/usage_std 0.3429 (0.3329) nleep/row_max_mean 1497.0829 (1501.3144) nleep/row_max_std 67.9998 (63.2358) nleep/row_min_mean 1474.6990 (1478.6140) lr 1.5358e-03 eta 0:08:59
epoch [18/50] batch [80/160] time 0.091 (0.101) data 0.000 (0.004) loss 1.6607 (1.6137) teacher_loss 0.4097 (0.3391) loss_zs_kd 0.0472 (0.0314) loss_oracle 0.7263 (0.6887) kd_loss 0.8642 (0.9145) acc 81.2500 (88.3203) gate/entropy 1.0863 (1.0887) gate/usage_max 0.3907 (0.3805) gate/usage_min 0.2654 (0.2706) gate/usage_std 0.0517 (0.0463) teacher/entropy 0.0994 (0.0729) teacher/usage_max 0.8620 (0.7995) teacher/usage_min 0.0229 (0.0179) teacher/usage_std 0.3757 (0.3389) nleep/row_max_mean 1490.4680 (1501.9790) nleep/row_max_std 70.5341 (60.7395) nleep/row_min_mean 1469.1750 (1479.0861) lr 1.5358e-03 eta 0:08:45
epoch [18/50] batch [100/160] time 0.094 (0.100) data 0.000 (0.003) loss 1.5085 (1.6182) teacher_loss 0.2156 (0.3464) loss_zs_kd 0.0560 (0.0327) loss_oracle 0.6709 (0.6855) kd_loss 0.9294 (0.9127) acc 93.7500 (87.6875) gate/entropy 1.0849 (1.0881) gate/usage_max 0.3968 (0.3832) gate/usage_min 0.2633 (0.2694) gate/usage_std 0.0547 (0.0477) teacher/entropy 0.0365 (0.0685) teacher/usage_max 0.8282 (0.8103) teacher/usage_min 0.0593 (0.0177) teacher/usage_std 0.3506 (0.3453) nleep/row_max_mean 1503.7209 (1501.8953) nleep/row_max_std 52.0651 (59.8615) nleep/row_min_mean 1478.5227 (1478.8283) lr 1.5358e-03 eta 0:08:36
epoch [18/50] batch [120/160] time 0.094 (0.099) data 0.000 (0.003) loss 1.4498 (1.6165) teacher_loss 0.1661 (0.3476) loss_zs_kd 0.0114 (0.0327) loss_oracle 0.7207 (0.6849) kd_loss 0.9177 (0.9102) acc 96.8750 (87.8385) gate/entropy 1.0834 (1.0874) gate/usage_max 0.4024 (0.3859) gate/usage_min 0.2610 (0.2682) gate/usage_std 0.0578 (0.0491) teacher/entropy 0.0108 (0.0658) teacher/usage_max 0.9394 (0.8150) teacher/usage_min 0.0290 (0.0184) teacher/usage_std 0.4285 (0.3481) nleep/row_max_mean 1505.3468 (1501.9096) nleep/row_max_std 51.1344 (59.3544) nleep/row_min_mean 1480.4419 (1478.6877) lr 1.5358e-03 eta 0:08:30
epoch [18/50] batch [140/160] time 0.093 (0.098) data 0.000 (0.003) loss 1.6932 (1.6121) teacher_loss 0.4394 (0.3490) loss_zs_kd 0.0354 (0.0324) loss_oracle 0.7311 (0.6827) kd_loss 0.8706 (0.9056) acc 78.1250 (87.8348) gate/entropy 1.0818 (1.0867) gate/usage_max 0.4075 (0.3886) gate/usage_min 0.2586 (0.2670) gate/usage_std 0.0608 (0.0506) teacher/entropy 0.0552 (0.0663) teacher/usage_max 0.8702 (0.8170) teacher/usage_min 0.0094 (0.0212) teacher/usage_std 0.3823 (0.3488) nleep/row_max_mean 1490.6777 (1501.9141) nleep/row_max_std 70.4025 (59.3534) nleep/row_min_mean 1463.6462 (1478.5017) lr 1.5358e-03 eta 0:08:23
epoch [18/50] batch [160/160] time 0.086 (0.097) data 0.000 (0.002) loss 1.3899 (1.6130) teacher_loss 0.1726 (0.3534) loss_zs_kd 0.0262 (0.0336) loss_oracle 0.6939 (0.6804) kd_loss 0.8573 (0.9025) acc 93.7500 (87.5391) gate/entropy 1.0800 (1.0860) gate/usage_max 0.4132 (0.3913) gate/usage_min 0.2562 (0.2658) gate/usage_std 0.0641 (0.0520) teacher/entropy 0.0598 (0.0654) teacher/usage_max 0.8905 (0.8177) teacher/usage_min 0.0343 (0.0239) teacher/usage_std 0.3944 (0.3488) nleep/row_max_mean 1516.2629 (1501.8414) nleep/row_max_std 41.0768 (59.4127) nleep/row_min_mean 1490.0398 (1478.2922) lr 1.4818e-03 eta 0:08:15
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,793
* accuracy: 81.3%
* error: 18.7%
* macro_f1: 84.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,926
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 88.1%
******* Domain p best val acc:      83.0%, epoch: 5 *******
******* Domain p best val test acc: 87.8%, epoch: 5 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [19/50] batch [20/160] time 0.089 (0.104) data 0.000 (0.013) loss 1.5275 (1.5636) teacher_loss 0.3337 (0.3469) loss_zs_kd 0.0516 (0.0410) loss_oracle 0.6275 (0.6573) kd_loss 0.8542 (0.8675) acc 87.5000 (86.4062) gate/entropy 1.0786 (1.0793) gate/usage_max 0.4176 (0.4154) gate/usage_min 0.2548 (0.2556) gate/usage_std 0.0666 (0.0653) teacher/entropy 0.0710 (0.0685) teacher/usage_max 0.8143 (0.8134) teacher/usage_min 0.0277 (0.0555) teacher/usage_std 0.3442 (0.3418) nleep/row_max_mean 1478.0209 (1501.9432) nleep/row_max_std 81.3164 (55.3299) nleep/row_min_mean 1454.0593 (1477.1967) lr 1.4818e-03 eta 0:08:50
epoch [19/50] batch [40/160] time 0.093 (0.098) data 0.000 (0.006) loss 1.4313 (1.5602) teacher_loss 0.2407 (0.3480) loss_zs_kd 0.0271 (0.0382) loss_oracle 0.6040 (0.6573) kd_loss 0.8751 (0.8644) acc 90.6250 (86.7969) gate/entropy 1.0769 (1.0785) gate/usage_max 0.4224 (0.4179) gate/usage_min 0.2528 (0.2546) gate/usage_std 0.0695 (0.0668) teacher/entropy 0.0377 (0.0628) teacher/usage_max 0.8675 (0.8256) teacher/usage_min 0.0622 (0.0488) teacher/usage_std 0.3777 (0.3507) nleep/row_max_mean 1506.7056 (1500.9907) nleep/row_max_std 44.2219 (58.0039) nleep/row_min_mean 1480.8480 (1475.5920) lr 1.4818e-03 eta 0:08:19
epoch [19/50] batch [60/160] time 0.097 (0.097) data 0.001 (0.004) loss 1.3764 (1.5467) teacher_loss 0.2080 (0.3495) loss_zs_kd 0.0359 (0.0352) loss_oracle 0.5618 (0.6404) kd_loss 0.8696 (0.8594) acc 93.7500 (86.8750) gate/entropy 1.0749 (1.0776) gate/usage_max 0.4277 (0.4203) gate/usage_min 0.2505 (0.2536) gate/usage_std 0.0728 (0.0683) teacher/entropy 0.0396 (0.0627) teacher/usage_max 0.8197 (0.8272) teacher/usage_min 0.0343 (0.0449) teacher/usage_std 0.3469 (0.3519) nleep/row_max_mean 1494.3182 (1500.3894) nleep/row_max_std 82.1541 (58.9665) nleep/row_min_mean 1467.3735 (1474.6824) lr 1.4818e-03 eta 0:08:10
epoch [19/50] batch [80/160] time 0.094 (0.096) data 0.000 (0.003) loss 1.6876 (1.5357) teacher_loss 0.5497 (0.3451) loss_zs_kd 0.0488 (0.0354) loss_oracle 0.5541 (0.6370) kd_loss 0.8364 (0.8544) acc 81.2500 (86.9531) gate/entropy 1.0733 (1.0767) gate/usage_max 0.4319 (0.4227) gate/usage_min 0.2491 (0.2527) gate/usage_std 0.0753 (0.0697) teacher/entropy 0.0538 (0.0625) teacher/usage_max 0.8452 (0.8300) teacher/usage_min 0.0174 (0.0434) teacher/usage_std 0.3653 (0.3539) nleep/row_max_mean 1473.2800 (1499.0900) nleep/row_max_std 93.4183 (60.0444) nleep/row_min_mean 1451.9229 (1473.2644) lr 1.4818e-03 eta 0:08:03
epoch [19/50] batch [100/160] time 0.101 (0.095) data 0.000 (0.003) loss 1.4814 (1.5364) teacher_loss 0.2623 (0.3485) loss_zs_kd 0.0294 (0.0345) loss_oracle 0.6764 (0.6397) kd_loss 0.8662 (0.8508) acc 93.7500 (87.1250) gate/entropy 1.0712 (1.0758) gate/usage_max 0.4371 (0.4251) gate/usage_min 0.2470 (0.2518) gate/usage_std 0.0786 (0.0712) teacher/entropy 0.0213 (0.0604) teacher/usage_max 0.8409 (0.8349) teacher/usage_min 0.0331 (0.0418) teacher/usage_std 0.3609 (0.3572) nleep/row_max_mean 1502.9485 (1499.7119) nleep/row_max_std 74.9285 (59.8957) nleep/row_min_mean 1474.3081 (1473.4171) lr 1.4818e-03 eta 0:07:57
epoch [19/50] batch [120/160] time 0.121 (0.095) data 0.000 (0.002) loss 1.6130 (1.5421) teacher_loss 0.4699 (0.3599) loss_zs_kd 0.0307 (0.0340) loss_oracle 0.6263 (0.6388) kd_loss 0.8147 (0.8458) acc 84.3750 (86.5625) gate/entropy 1.0691 (1.0749) gate/usage_max 0.4419 (0.4275) gate/usage_min 0.2454 (0.2508) gate/usage_std 0.0816 (0.0727) teacher/entropy 0.0433 (0.0588) teacher/usage_max 0.8842 (0.8410) teacher/usage_min 0.0066 (0.0388) teacher/usage_std 0.3918 (0.3614) nleep/row_max_mean 1498.6650 (1500.1470) nleep/row_max_std 76.0060 (60.3360) nleep/row_min_mean 1467.8120 (1473.3766) lr 1.4818e-03 eta 0:07:55
epoch [19/50] batch [140/160] time 0.089 (0.096) data 0.000 (0.002) loss 1.3969 (1.5383) teacher_loss 0.2585 (0.3616) loss_zs_kd 0.0278 (0.0344) loss_oracle 0.6468 (0.6389) kd_loss 0.8011 (0.8400) acc 87.5000 (86.4286) gate/entropy 1.0669 (1.0739) gate/usage_max 0.4469 (0.4299) gate/usage_min 0.2435 (0.2499) gate/usage_std 0.0847 (0.0742) teacher/entropy 0.0615 (0.0586) teacher/usage_max 0.8860 (0.8463) teacher/usage_min 0.0519 (0.0379) teacher/usage_std 0.3908 (0.3650) nleep/row_max_mean 1501.5723 (1500.3137) nleep/row_max_std 69.8364 (60.1661) nleep/row_min_mean 1469.9502 (1473.1988) lr 1.4818e-03 eta 0:07:55
epoch [19/50] batch [160/160] time 0.074 (0.096) data 0.000 (0.002) loss 1.5098 (1.5362) teacher_loss 0.3573 (0.3636) loss_zs_kd 0.0381 (0.0343) loss_oracle 0.5947 (0.6385) kd_loss 0.8361 (0.8361) acc 87.5000 (86.2109) gate/entropy 1.0648 (1.0729) gate/usage_max 0.4517 (0.4323) gate/usage_min 0.2422 (0.2490) gate/usage_std 0.0877 (0.0757) teacher/entropy 0.0613 (0.0578) teacher/usage_max 0.7620 (0.8491) teacher/usage_min 0.0410 (0.0386) teacher/usage_std 0.3097 (0.3668) nleep/row_max_mean 1498.2028 (1500.3365) nleep/row_max_std 58.9808 (60.4289) nleep/row_min_mean 1470.9268 (1472.9871) lr 1.4258e-03 eta 0:07:56
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 84.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,941
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 88.3%
******* Domain p best val acc:      83.4%, epoch: 19 *******
******* Domain p best val test acc: 87.1%, epoch: 19 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [20/50] batch [20/160] time 0.085 (0.100) data 0.000 (0.016) loss 1.5611 (1.5032) teacher_loss 0.4199 (0.3837) loss_zs_kd 0.0445 (0.0345) loss_oracle 0.6097 (0.6076) kd_loss 0.8142 (0.7985) acc 81.2500 (85.0000) gate/entropy 1.0626 (1.0636) gate/usage_max 0.4563 (0.4541) gate/usage_min 0.2408 (0.2414) gate/usage_std 0.0906 (0.0892) teacher/entropy 0.0188 (0.0411) teacher/usage_max 0.8816 (0.8943) teacher/usage_min 0.0002 (0.0258) teacher/usage_std 0.3907 (0.3976) nleep/row_max_mean 1487.0469 (1494.8483) nleep/row_max_std 90.1072 (70.5838) nleep/row_min_mean 1457.9937 (1465.8692) lr 1.4258e-03 eta 0:08:15
epoch [20/50] batch [40/160] time 0.077 (0.093) data 0.000 (0.008) loss 1.7961 (1.4860) teacher_loss 0.6996 (0.3809) loss_zs_kd 0.0360 (0.0333) loss_oracle 0.5391 (0.5931) kd_loss 0.8089 (0.7919) acc 75.0000 (85.0000) gate/entropy 1.0605 (1.0626) gate/usage_max 0.4606 (0.4563) gate/usage_min 0.2392 (0.2406) gate/usage_std 0.0934 (0.0906) teacher/entropy 0.0594 (0.0558) teacher/usage_max 0.8118 (0.8691) teacher/usage_min 0.0545 (0.0352) teacher/usage_std 0.3399 (0.3802) nleep/row_max_mean 1508.8671 (1499.1670) nleep/row_max_std 61.1731 (64.2693) nleep/row_min_mean 1479.5303 (1470.2267) lr 1.4258e-03 eta 0:07:39
epoch [20/50] batch [60/160] time 0.093 (0.092) data 0.000 (0.005) loss 1.5523 (1.4780) teacher_loss 0.4119 (0.3759) loss_zs_kd 0.0385 (0.0338) loss_oracle 0.5707 (0.5877) kd_loss 0.8357 (0.7913) acc 84.3750 (85.5208) gate/entropy 1.0586 (1.0615) gate/usage_max 0.4643 (0.4584) gate/usage_min 0.2380 (0.2399) gate/usage_std 0.0958 (0.0920) teacher/entropy 0.0238 (0.0540) teacher/usage_max 0.8068 (0.8647) teacher/usage_min 0.0314 (0.0330) teacher/usage_std 0.3390 (0.3775) nleep/row_max_mean 1491.5685 (1500.6072) nleep/row_max_std 64.6335 (61.6223) nleep/row_min_mean 1463.8667 (1471.9218) lr 1.4258e-03 eta 0:07:28
epoch [20/50] batch [80/160] time 0.104 (0.093) data 0.000 (0.004) loss 1.3604 (1.4648) teacher_loss 0.2483 (0.3671) loss_zs_kd 0.0377 (0.0330) loss_oracle 0.6329 (0.5853) kd_loss 0.7767 (0.7886) acc 93.7500 (85.9375) gate/entropy 1.0566 (1.0605) gate/usage_max 0.4681 (0.4604) gate/usage_min 0.2368 (0.2393) gate/usage_std 0.0983 (0.0933) teacher/entropy 0.0602 (0.0570) teacher/usage_max 0.8460 (0.8578) teacher/usage_min 0.0325 (0.0352) teacher/usage_std 0.3644 (0.3728) nleep/row_max_mean 1494.1356 (1500.8197) nleep/row_max_std 65.3558 (60.5374) nleep/row_min_mean 1464.1592 (1472.4100) lr 1.4258e-03 eta 0:07:33
epoch [20/50] batch [100/160] time 0.098 (0.094) data 0.000 (0.003) loss 1.4366 (1.4709) teacher_loss 0.3592 (0.3768) loss_zs_kd 0.0321 (0.0328) loss_oracle 0.5371 (0.5820) kd_loss 0.7928 (0.7866) acc 90.6250 (85.8750) gate/entropy 1.0541 (1.0595) gate/usage_max 0.4727 (0.4624) gate/usage_min 0.2351 (0.2386) gate/usage_std 0.1012 (0.0946) teacher/entropy 0.0297 (0.0556) teacher/usage_max 0.8492 (0.8574) teacher/usage_min 0.0020 (0.0341) teacher/usage_std 0.3697 (0.3725) nleep/row_max_mean 1510.5483 (1500.6160) nleep/row_max_std 56.7542 (59.8684) nleep/row_min_mean 1483.4852 (1472.4052) lr 1.4258e-03 eta 0:07:37
epoch [20/50] batch [120/160] time 0.094 (0.094) data 0.000 (0.003) loss 1.2896 (1.4687) teacher_loss 0.2030 (0.3779) loss_zs_kd 0.0304 (0.0329) loss_oracle 0.5562 (0.5776) kd_loss 0.7933 (0.7856) acc 96.8750 (85.9635) gate/entropy 1.0529 (1.0585) gate/usage_max 0.4749 (0.4643) gate/usage_min 0.2346 (0.2380) gate/usage_std 0.1027 (0.0958) teacher/entropy 0.0325 (0.0583) teacher/usage_max 0.8356 (0.8484) teacher/usage_min 0.0011 (0.0355) teacher/usage_std 0.3613 (0.3667) nleep/row_max_mean 1498.6807 (1499.8906) nleep/row_max_std 42.5915 (60.2181) nleep/row_min_mean 1471.0129 (1472.1926) lr 1.4258e-03 eta 0:07:36
epoch [20/50] batch [140/160] time 0.091 (0.095) data 0.000 (0.002) loss 1.4937 (1.4581) teacher_loss 0.3443 (0.3652) loss_zs_kd 0.0654 (0.0339) loss_oracle 0.6076 (0.5796) kd_loss 0.8128 (0.7862) acc 90.6250 (86.5625) gate/entropy 1.0505 (1.0575) gate/usage_max 0.4789 (0.4661) gate/usage_min 0.2330 (0.2373) gate/usage_std 0.1054 (0.0970) teacher/entropy 0.0095 (0.0577) teacher/usage_max 0.8438 (0.8435) teacher/usage_min 0.0335 (0.0370) teacher/usage_std 0.3628 (0.3634) nleep/row_max_mean 1509.8447 (1499.8218) nleep/row_max_std 44.3041 (60.2262) nleep/row_min_mean 1477.8815 (1472.2015) lr 1.4258e-03 eta 0:07:38
epoch [20/50] batch [160/160] time 0.081 (0.094) data 0.000 (0.002) loss 1.2799 (1.4516) teacher_loss 0.2700 (0.3608) loss_zs_kd 0.0283 (0.0345) loss_oracle 0.5345 (0.5770) kd_loss 0.7284 (0.7849) acc 90.6250 (86.7188) gate/entropy 1.0492 (1.0565) gate/usage_max 0.4814 (0.4679) gate/usage_min 0.2325 (0.2368) gate/usage_std 0.1069 (0.0982) teacher/entropy 0.0250 (0.0578) teacher/usage_max 0.9688 (0.8411) teacher/usage_min 0.0021 (0.0380) teacher/usage_std 0.4495 (0.3617) nleep/row_max_mean 1478.5131 (1499.0206) nleep/row_max_std 75.7908 (60.9570) nleep/row_min_mean 1450.1854 (1471.5069) lr 1.3681e-03 eta 0:07:32
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,828
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,917
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 87.9%
******* Domain p best val acc:      83.4%, epoch: 19 *******
******* Domain p best val test acc: 87.1%, epoch: 19 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [21/50] batch [20/160] time 0.100 (0.112) data 0.000 (0.016) loss 1.2139 (1.3680) teacher_loss 0.1512 (0.2975) loss_zs_kd 0.0410 (0.0373) loss_oracle 0.5811 (0.5723) kd_loss 0.7516 (0.7657) acc 90.6250 (87.5000) gate/entropy 1.0468 (1.0478) gate/usage_max 0.4854 (0.4836) gate/usage_min 0.2313 (0.2318) gate/usage_std 0.1096 (0.1084) teacher/entropy 0.0257 (0.0522) teacher/usage_max 0.9088 (0.8486) teacher/usage_min 0.0245 (0.0438) teacher/usage_std 0.4073 (0.3657) nleep/row_max_mean 1516.7195 (1500.8614) nleep/row_max_std 46.7422 (58.3450) nleep/row_min_mean 1484.1106 (1472.6799) lr 1.3681e-03 eta 0:08:57
epoch [21/50] batch [40/160] time 0.098 (0.107) data 0.000 (0.008) loss 1.4066 (1.3652) teacher_loss 0.3208 (0.2990) loss_zs_kd 0.0391 (0.0374) loss_oracle 0.5072 (0.5642) kd_loss 0.8127 (0.7654) acc 93.7500 (88.0469) gate/entropy 1.0451 (1.0469) gate/usage_max 0.4883 (0.4852) gate/usage_min 0.2305 (0.2314) gate/usage_std 0.1115 (0.1095) teacher/entropy 0.0430 (0.0548) teacher/usage_max 0.7699 (0.8399) teacher/usage_min 0.0604 (0.0473) teacher/usage_std 0.3119 (0.3597) nleep/row_max_mean 1503.3247 (1500.0301) nleep/row_max_std 64.5295 (59.3096) nleep/row_min_mean 1477.1523 (1472.3013) lr 1.3681e-03 eta 0:08:27
epoch [21/50] batch [60/160] time 0.157 (0.110) data 0.002 (0.006) loss 1.4201 (1.3709) teacher_loss 0.4555 (0.3107) loss_zs_kd 0.0299 (0.0357) loss_oracle 0.4636 (0.5602) kd_loss 0.7179 (0.7623) acc 87.5000 (88.3854) gate/entropy 1.0435 (1.0460) gate/usage_max 0.4908 (0.4867) gate/usage_min 0.2298 (0.2310) gate/usage_std 0.1132 (0.1104) teacher/entropy 0.0707 (0.0583) teacher/usage_max 0.8674 (0.8351) teacher/usage_min 0.0131 (0.0452) teacher/usage_std 0.3802 (0.3567) nleep/row_max_mean 1488.4209 (1499.8917) nleep/row_max_std 64.3499 (59.9100) nleep/row_min_mean 1463.8046 (1472.5833) lr 1.3681e-03 eta 0:08:39
epoch [21/50] batch [80/160] time 0.091 (0.106) data 0.000 (0.004) loss 1.5546 (1.3788) teacher_loss 0.5350 (0.3118) loss_zs_kd 0.0514 (0.0366) loss_oracle 0.4638 (0.5643) kd_loss 0.7619 (0.7665) acc 84.3750 (88.9453) gate/entropy 1.0416 (1.0451) gate/usage_max 0.4938 (0.4881) gate/usage_min 0.2289 (0.2305) gate/usage_std 0.1152 (0.1114) teacher/entropy 0.0523 (0.0583) teacher/usage_max 0.8241 (0.8239) teacher/usage_min 0.0386 (0.0463) teacher/usage_std 0.3493 (0.3494) nleep/row_max_mean 1497.9147 (1499.6766) nleep/row_max_std 68.4343 (60.6381) nleep/row_min_mean 1473.2098 (1472.4282) lr 1.3681e-03 eta 0:08:18
epoch [21/50] batch [100/160] time 0.094 (0.103) data 0.000 (0.004) loss 1.2709 (1.3816) teacher_loss 0.2563 (0.3064) loss_zs_kd 0.0348 (0.0375) loss_oracle 0.5520 (0.5694) kd_loss 0.7212 (0.7717) acc 93.7500 (89.1875) gate/entropy 1.0403 (1.0443) gate/usage_max 0.4957 (0.4894) gate/usage_min 0.2280 (0.2301) gate/usage_std 0.1165 (0.1123) teacher/entropy 0.1171 (0.0605) teacher/usage_max 0.7896 (0.8087) teacher/usage_min 0.0688 (0.0495) teacher/usage_std 0.3240 (0.3393) nleep/row_max_mean 1496.2875 (1499.0495) nleep/row_max_std 63.5046 (61.4670) nleep/row_min_mean 1472.3503 (1472.0966) lr 1.3681e-03 eta 0:08:05
epoch [21/50] batch [120/160] time 0.096 (0.102) data 0.000 (0.003) loss 1.4579 (1.3792) teacher_loss 0.2956 (0.2986) loss_zs_kd 0.0477 (0.0384) loss_oracle 0.5695 (0.5680) kd_loss 0.8537 (0.7774) acc 87.5000 (89.5052) gate/entropy 1.0393 (1.0435) gate/usage_max 0.4973 (0.4906) gate/usage_min 0.2275 (0.2297) gate/usage_std 0.1176 (0.1131) teacher/entropy 0.1073 (0.0597) teacher/usage_max 0.6074 (0.7999) teacher/usage_min 0.1593 (0.0549) teacher/usage_std 0.1962 (0.3330) nleep/row_max_mean 1498.8480 (1499.7177) nleep/row_max_std 40.1087 (60.2642) nleep/row_min_mean 1475.2158 (1472.8643) lr 1.3681e-03 eta 0:07:56
epoch [21/50] batch [140/160] time 0.100 (0.101) data 0.000 (0.003) loss 1.2752 (1.3801) teacher_loss 0.2204 (0.2998) loss_zs_kd 0.0519 (0.0395) loss_oracle 0.5572 (0.5665) kd_loss 0.7503 (0.7773) acc 93.7500 (89.7321) gate/entropy 1.0382 (1.0428) gate/usage_max 0.4990 (0.4918) gate/usage_min 0.2272 (0.2294) gate/usage_std 0.1187 (0.1139) teacher/entropy 0.0943 (0.0641) teacher/usage_max 0.7737 (0.7916) teacher/usage_min 0.0711 (0.0595) teacher/usage_std 0.3133 (0.3271) nleep/row_max_mean 1494.0149 (1499.3932) nleep/row_max_std 58.0883 (60.2609) nleep/row_min_mean 1468.1252 (1472.7760) lr 1.3681e-03 eta 0:07:49
epoch [21/50] batch [160/160] time 0.082 (0.099) data 0.000 (0.002) loss 1.3056 (1.3810) teacher_loss 0.1914 (0.2978) loss_zs_kd 0.0375 (0.0402) loss_oracle 0.6377 (0.5679) kd_loss 0.7766 (0.7791) acc 93.7500 (89.8242) gate/entropy 1.0365 (1.0421) gate/usage_max 0.5016 (0.4929) gate/usage_min 0.2263 (0.2290) gate/usage_std 0.1204 (0.1146) teacher/entropy 0.0212 (0.0648) teacher/usage_max 0.8424 (0.7860) teacher/usage_min 0.0611 (0.0627) teacher/usage_std 0.3603 (0.3231) nleep/row_max_mean 1502.6873 (1499.5090) nleep/row_max_std 68.0550 (59.4831) nleep/row_min_mean 1474.6971 (1472.9154) lr 1.3090e-03 eta 0:07:40
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,845
* accuracy: 83.6%
* error: 16.4%
* macro_f1: 85.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,953
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 88.8%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [22/50] batch [20/160] time 0.084 (0.107) data 0.000 (0.016) loss 1.1803 (1.3325) teacher_loss 0.1224 (0.2413) loss_zs_kd 0.0260 (0.0434) loss_oracle 0.5235 (0.5606) kd_loss 0.7832 (0.7892) acc 100.0000 (91.8750) gate/entropy 1.0354 (1.0360) gate/usage_max 0.5033 (0.5024) gate/usage_min 0.2260 (0.2262) gate/usage_std 0.1215 (0.1210) teacher/entropy 0.0929 (0.0729) teacher/usage_max 0.7268 (0.7514) teacher/usage_min 0.1142 (0.0918) teacher/usage_std 0.2788 (0.2978) nleep/row_max_mean 1508.2258 (1497.9340) nleep/row_max_std 44.0017 (60.6585) nleep/row_min_mean 1481.8654 (1471.4000) lr 1.3090e-03 eta 0:08:15
epoch [22/50] batch [40/160] time 0.078 (0.096) data 0.000 (0.008) loss 1.4020 (1.3551) teacher_loss 0.3530 (0.2590) loss_zs_kd 0.0471 (0.0452) loss_oracle 0.5472 (0.5676) kd_loss 0.7518 (0.7897) acc 84.3750 (91.4844) gate/entropy 1.0341 (1.0353) gate/usage_max 0.5052 (0.5034) gate/usage_min 0.2254 (0.2259) gate/usage_std 0.1228 (0.1217) teacher/entropy 0.1017 (0.0689) teacher/usage_max 0.7633 (0.7507) teacher/usage_min 0.1176 (0.0831) teacher/usage_std 0.3040 (0.2988) nleep/row_max_mean 1493.5503 (1498.8216) nleep/row_max_std 66.6906 (59.8383) nleep/row_min_mean 1467.4480 (1472.0847) lr 1.3090e-03 eta 0:07:21
epoch [22/50] batch [60/160] time 0.094 (0.095) data 0.001 (0.005) loss 1.2622 (1.3530) teacher_loss 0.1855 (0.2524) loss_zs_kd 0.0448 (0.0497) loss_oracle 0.6187 (0.5744) kd_loss 0.7449 (0.7886) acc 93.7500 (91.7708) gate/entropy 1.0330 (1.0347) gate/usage_max 0.5068 (0.5043) gate/usage_min 0.2251 (0.2257) gate/usage_std 0.1239 (0.1222) teacher/entropy 0.1082 (0.0663) teacher/usage_max 0.7484 (0.7548) teacher/usage_min 0.0716 (0.0837) teacher/usage_std 0.2968 (0.3015) nleep/row_max_mean 1483.5806 (1498.3302) nleep/row_max_std 94.6518 (59.4357) nleep/row_min_mean 1453.6416 (1471.2821) lr 1.3090e-03 eta 0:07:16
epoch [22/50] batch [80/160] time 0.098 (0.095) data 0.000 (0.004) loss 1.5310 (1.3594) teacher_loss 0.2616 (0.2497) loss_zs_kd 0.0517 (0.0506) loss_oracle 0.6913 (0.5812) kd_loss 0.8978 (0.7938) acc 90.6250 (91.6406) gate/entropy 1.0322 (1.0341) gate/usage_max 0.5080 (0.5052) gate/usage_min 0.2248 (0.2255) gate/usage_std 0.1247 (0.1228) teacher/entropy 0.1106 (0.0684) teacher/usage_max 0.5345 (0.7448) teacher/usage_min 0.1871 (0.0898) teacher/usage_std 0.1471 (0.2942) nleep/row_max_mean 1472.2913 (1498.6337) nleep/row_max_std 87.9757 (58.5500) nleep/row_min_mean 1448.8977 (1471.5776) lr 1.3090e-03 eta 0:07:13
epoch [22/50] batch [100/160] time 0.086 (0.095) data 0.000 (0.003) loss 1.4116 (1.3593) teacher_loss 0.2430 (0.2495) loss_zs_kd 0.0472 (0.0516) loss_oracle 0.6123 (0.5801) kd_loss 0.8388 (0.7940) acc 90.6250 (91.6250) gate/entropy 1.0307 (1.0336) gate/usage_max 0.5102 (0.5060) gate/usage_min 0.2242 (0.2253) gate/usage_std 0.1262 (0.1234) teacher/entropy 0.0859 (0.0676) teacher/usage_max 0.6653 (0.7452) teacher/usage_min 0.1370 (0.0913) teacher/usage_std 0.2361 (0.2941) nleep/row_max_mean 1495.7412 (1498.8933) nleep/row_max_std 62.8034 (58.0804) nleep/row_min_mean 1470.7668 (1471.5841) lr 1.3090e-03 eta 0:07:09
epoch [22/50] batch [120/160] time 0.087 (0.094) data 0.000 (0.003) loss 1.2478 (1.3603) teacher_loss 0.1428 (0.2486) loss_zs_kd 0.0675 (0.0528) loss_oracle 0.5565 (0.5789) kd_loss 0.7930 (0.7958) acc 96.8750 (91.6667) gate/entropy 1.0299 (1.0330) gate/usage_max 0.5115 (0.5068) gate/usage_min 0.2242 (0.2251) gate/usage_std 0.1270 (0.1239) teacher/entropy 0.0408 (0.0691) teacher/usage_max 0.7813 (0.7404) teacher/usage_min 0.1010 (0.0942) teacher/usage_std 0.3168 (0.2906) nleep/row_max_mean 1500.8459 (1498.3192) nleep/row_max_std 43.4569 (58.6511) nleep/row_min_mean 1469.6769 (1470.8979) lr 1.3090e-03 eta 0:07:06
epoch [22/50] batch [140/160] time 0.097 (0.096) data 0.000 (0.002) loss 1.2885 (1.3533) teacher_loss 0.2089 (0.2421) loss_zs_kd 0.0516 (0.0530) loss_oracle 0.5736 (0.5787) kd_loss 0.7670 (0.7954) acc 93.7500 (91.8304) gate/entropy 1.0280 (1.0324) gate/usage_max 0.5141 (0.5076) gate/usage_min 0.2235 (0.2249) gate/usage_std 0.1288 (0.1245) teacher/entropy 0.0999 (0.0691) teacher/usage_max 0.7297 (0.7398) teacher/usage_min 0.1211 (0.0953) teacher/usage_std 0.2805 (0.2901) nleep/row_max_mean 1522.5728 (1498.3013) nleep/row_max_std 28.8783 (58.8472) nleep/row_min_mean 1492.6948 (1470.7209) lr 1.3090e-03 eta 0:07:10
epoch [22/50] batch [160/160] time 0.087 (0.095) data 0.000 (0.002) loss 1.3532 (1.3570) teacher_loss 0.2176 (0.2420) loss_zs_kd 0.0545 (0.0540) loss_oracle 0.5874 (0.5786) kd_loss 0.8147 (0.7987) acc 90.6250 (91.8555) gate/entropy 1.0276 (1.0319) gate/usage_max 0.5146 (0.5084) gate/usage_min 0.2236 (0.2247) gate/usage_std 0.1291 (0.1250) teacher/entropy 0.0547 (0.0693) teacher/usage_max 0.7192 (0.7342) teacher/usage_min 0.1002 (0.0979) teacher/usage_std 0.2748 (0.2862) nleep/row_max_mean 1493.1250 (1498.1103) nleep/row_max_std 67.0882 (59.2792) nleep/row_min_mean 1463.8831 (1470.4726) lr 1.2487e-03 eta 0:07:03
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,837
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,974
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 89.2%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [23/50] batch [20/160] time 0.086 (0.106) data 0.000 (0.019) loss 1.2282 (1.3863) teacher_loss 0.1019 (0.2766) loss_zs_kd 0.0696 (0.0601) loss_oracle 0.6358 (0.5784) kd_loss 0.7736 (0.7905) acc 96.8750 (90.3125) gate/entropy 1.0263 (1.0270) gate/usage_max 0.5164 (0.5155) gate/usage_min 0.2231 (0.2234) gate/usage_std 0.1304 (0.1297) teacher/entropy 0.0571 (0.0587) teacher/usage_max 0.7650 (0.7527) teacher/usage_min 0.0580 (0.0843) teacher/usage_std 0.3091 (0.2992) nleep/row_max_mean 1501.9994 (1496.7309) nleep/row_max_std 58.6152 (56.4170) nleep/row_min_mean 1473.1794 (1467.4806) lr 1.2487e-03 eta 0:07:53
epoch [23/50] batch [40/160] time 0.090 (0.095) data 0.000 (0.010) loss 1.5186 (1.3685) teacher_loss 0.3105 (0.2411) loss_zs_kd 0.0538 (0.0576) loss_oracle 0.6422 (0.5832) kd_loss 0.8601 (0.8069) acc 90.6250 (92.1094) gate/entropy 1.0255 (1.0265) gate/usage_max 0.5176 (0.5162) gate/usage_min 0.2230 (0.2233) gate/usage_std 0.1311 (0.1302) teacher/entropy 0.0367 (0.0594) teacher/usage_max 0.6761 (0.7304) teacher/usage_min 0.0957 (0.0992) teacher/usage_std 0.2484 (0.2834) nleep/row_max_mean 1489.8374 (1497.2375) nleep/row_max_std 77.1833 (56.4366) nleep/row_min_mean 1460.9089 (1467.8466) lr 1.2487e-03 eta 0:07:01
epoch [23/50] batch [60/160] time 0.079 (0.091) data 0.001 (0.007) loss 1.4795 (1.3671) teacher_loss 0.2404 (0.2361) loss_zs_kd 0.0864 (0.0592) loss_oracle 0.5711 (0.5848) kd_loss 0.9104 (0.8090) acc 96.8750 (92.0312) gate/entropy 1.0245 (1.0261) gate/usage_max 0.5190 (0.5168) gate/usage_min 0.2227 (0.2232) gate/usage_std 0.1321 (0.1306) teacher/entropy 0.0178 (0.0565) teacher/usage_max 0.6563 (0.7321) teacher/usage_min 0.1263 (0.0975) teacher/usage_std 0.2314 (0.2846) nleep/row_max_mean 1493.8319 (1496.8392) nleep/row_max_std 50.0303 (55.5059) nleep/row_min_mean 1466.0952 (1467.4172) lr 1.2487e-03 eta 0:06:44
epoch [23/50] batch [80/160] time 0.087 (0.090) data 0.000 (0.005) loss 1.4675 (1.3723) teacher_loss 0.2973 (0.2316) loss_zs_kd 0.0676 (0.0603) loss_oracle 0.5613 (0.5879) kd_loss 0.8558 (0.8166) acc 84.3750 (92.4219) gate/entropy 1.0235 (1.0256) gate/usage_max 0.5204 (0.5175) gate/usage_min 0.2225 (0.2231) gate/usage_std 0.1330 (0.1310) teacher/entropy 0.0510 (0.0613) teacher/usage_max 0.6868 (0.7163) teacher/usage_min 0.0926 (0.1052) teacher/usage_std 0.2553 (0.2737) nleep/row_max_mean 1501.4551 (1496.7066) nleep/row_max_std 53.9983 (55.8431) nleep/row_min_mean 1474.8307 (1467.5616) lr 1.2487e-03 eta 0:06:35
epoch [23/50] batch [100/160] time 0.081 (0.089) data 0.000 (0.004) loss 1.3013 (1.3694) teacher_loss 0.1725 (0.2280) loss_zs_kd 0.0487 (0.0594) loss_oracle 0.5927 (0.5879) kd_loss 0.8081 (0.8177) acc 96.8750 (92.7500) gate/entropy 1.0229 (1.0252) gate/usage_max 0.5212 (0.5181) gate/usage_min 0.2224 (0.2230) gate/usage_std 0.1336 (0.1315) teacher/entropy 0.0699 (0.0605) teacher/usage_max 0.7072 (0.7146) teacher/usage_min 0.1348 (0.1069) teacher/usage_std 0.2646 (0.2723) nleep/row_max_mean 1490.7007 (1495.5390) nleep/row_max_std 64.7255 (56.9043) nleep/row_min_mean 1461.4257 (1466.4994) lr 1.2487e-03 eta 0:06:30
epoch [23/50] batch [120/160] time 0.099 (0.089) data 0.000 (0.003) loss 1.5434 (1.3688) teacher_loss 0.3220 (0.2278) loss_zs_kd 0.0782 (0.0596) loss_oracle 0.5982 (0.5874) kd_loss 0.8832 (0.8175) acc 90.6250 (92.7604) gate/entropy 1.0223 (1.0248) gate/usage_max 0.5220 (0.5187) gate/usage_min 0.2223 (0.2229) gate/usage_std 0.1341 (0.1318) teacher/entropy 0.1093 (0.0618) teacher/usage_max 0.5625 (0.7122) teacher/usage_min 0.2142 (0.1083) teacher/usage_std 0.1621 (0.2705) nleep/row_max_mean 1504.0580 (1494.7478) nleep/row_max_std 26.1375 (57.3027) nleep/row_min_mean 1473.6421 (1465.7013) lr 1.2487e-03 eta 0:06:26
epoch [23/50] batch [140/160] time 0.093 (0.089) data 0.000 (0.003) loss 1.2563 (1.3628) teacher_loss 0.1630 (0.2235) loss_zs_kd 0.0504 (0.0594) loss_oracle 0.5685 (0.5848) kd_loss 0.7839 (0.8173) acc 96.8750 (92.7679) gate/entropy 1.0216 (1.0244) gate/usage_max 0.5230 (0.5192) gate/usage_min 0.2221 (0.2228) gate/usage_std 0.1348 (0.1322) teacher/entropy 0.1022 (0.0619) teacher/usage_max 0.6983 (0.7116) teacher/usage_min 0.1506 (0.1079) teacher/usage_std 0.2581 (0.2702) nleep/row_max_mean 1460.9308 (1494.7486) nleep/row_max_std 99.4615 (57.2953) nleep/row_min_mean 1437.3512 (1465.7371) lr 1.2487e-03 eta 0:06:24
epoch [23/50] batch [160/160] time 0.084 (0.088) data 0.000 (0.003) loss 1.3173 (1.3646) teacher_loss 0.1355 (0.2212) loss_zs_kd 0.0684 (0.0600) loss_oracle 0.6405 (0.5856) kd_loss 0.8274 (0.8205) acc 96.8750 (92.8906) gate/entropy 1.0208 (1.0239) gate/usage_max 0.5240 (0.5198) gate/usage_min 0.2219 (0.2227) gate/usage_std 0.1355 (0.1326) teacher/entropy 0.0710 (0.0610) teacher/usage_max 0.6858 (0.7083) teacher/usage_min 0.1342 (0.1099) teacher/usage_std 0.2499 (0.2679) nleep/row_max_mean 1503.6914 (1494.0630) nleep/row_max_std 54.2770 (58.3353) nleep/row_min_mean 1472.9928 (1465.0789) lr 1.1874e-03 eta 0:06:21
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,830
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,945
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 88.4%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [24/50] batch [20/160] time 0.096 (0.111) data 0.001 (0.013) loss 1.3090 (1.3677) teacher_loss 0.2402 (0.2440) loss_zs_kd 0.0673 (0.0559) loss_oracle 0.5313 (0.5512) kd_loss 0.7696 (0.8201) acc 93.7500 (92.5000) gate/entropy 1.0201 (1.0204) gate/usage_max 0.5250 (0.5246) gate/usage_min 0.2219 (0.2219) gate/usage_std 0.1361 (0.1359) teacher/entropy 0.0955 (0.0642) teacher/usage_max 0.7198 (0.7021) teacher/usage_min 0.1224 (0.1183) teacher/usage_std 0.2736 (0.2633) nleep/row_max_mean 1499.4575 (1497.9484) nleep/row_max_std 65.1335 (51.6027) nleep/row_min_mean 1467.3743 (1469.2251) lr 1.1874e-03 eta 0:07:58
epoch [24/50] batch [40/160] time 0.097 (0.101) data 0.001 (0.007) loss 1.2835 (1.3435) teacher_loss 0.2269 (0.2056) loss_zs_kd 0.0733 (0.0581) loss_oracle 0.5594 (0.5638) kd_loss 0.7402 (0.8269) acc 87.5000 (93.5156) gate/entropy 1.0194 (1.0200) gate/usage_max 0.5259 (0.5251) gate/usage_min 0.2217 (0.2218) gate/usage_std 0.1367 (0.1362) teacher/entropy 0.0529 (0.0634) teacher/usage_max 0.8131 (0.6910) teacher/usage_min 0.0891 (0.1220) teacher/usage_std 0.3393 (0.2555) nleep/row_max_mean 1503.8954 (1496.9683) nleep/row_max_std 31.1953 (54.1765) nleep/row_min_mean 1473.4943 (1468.6172) lr 1.1874e-03 eta 0:07:10
epoch [24/50] batch [60/160] time 0.099 (0.102) data 0.001 (0.005) loss 1.4720 (1.3485) teacher_loss 0.3259 (0.2158) loss_zs_kd 0.0434 (0.0585) loss_oracle 0.5341 (0.5615) kd_loss 0.8574 (0.8227) acc 87.5000 (92.8125) gate/entropy 1.0187 (1.0197) gate/usage_max 0.5269 (0.5255) gate/usage_min 0.2216 (0.2217) gate/usage_std 0.1374 (0.1365) teacher/entropy 0.0418 (0.0617) teacher/usage_max 0.6888 (0.6976) teacher/usage_min 0.0909 (0.1190) teacher/usage_std 0.2569 (0.2601) nleep/row_max_mean 1481.9148 (1497.2014) nleep/row_max_std 81.3464 (54.5897) nleep/row_min_mean 1455.2876 (1468.8779) lr 1.1874e-03 eta 0:07:15
epoch [24/50] batch [80/160] time 0.103 (0.101) data 0.000 (0.004) loss 1.4760 (1.3570) teacher_loss 0.2476 (0.2221) loss_zs_kd 0.0504 (0.0581) loss_oracle 0.5518 (0.5598) kd_loss 0.9274 (0.8259) acc 87.5000 (92.9688) gate/entropy 1.0182 (1.0194) gate/usage_max 0.5275 (0.5260) gate/usage_min 0.2213 (0.2217) gate/usage_std 0.1378 (0.1368) teacher/entropy 0.0610 (0.0604) teacher/usage_max 0.5608 (0.6946) teacher/usage_min 0.1822 (0.1186) teacher/usage_std 0.1637 (0.2583) nleep/row_max_mean 1500.5502 (1496.0920) nleep/row_max_std 41.6810 (56.4658) nleep/row_min_mean 1474.0310 (1467.9193) lr 1.1874e-03 eta 0:07:07
epoch [24/50] batch [100/160] time 0.157 (0.102) data 0.001 (0.003) loss 1.4534 (1.3529) teacher_loss 0.3524 (0.2208) loss_zs_kd 0.0766 (0.0585) loss_oracle 0.5402 (0.5598) kd_loss 0.7926 (0.8229) acc 87.5000 (92.9688) gate/entropy 1.0172 (1.0190) gate/usage_max 0.5288 (0.5264) gate/usage_min 0.2211 (0.2216) gate/usage_std 0.1387 (0.1371) teacher/entropy 0.0574 (0.0584) teacher/usage_max 0.7226 (0.6989) teacher/usage_min 0.0546 (0.1121) teacher/usage_std 0.2837 (0.2620) nleep/row_max_mean 1508.4716 (1495.5241) nleep/row_max_std 27.3057 (57.3010) nleep/row_min_mean 1480.4919 (1467.4189) lr 1.1874e-03 eta 0:07:10
epoch [24/50] batch [120/160] time 0.092 (0.101) data 0.000 (0.003) loss 1.4329 (1.3585) teacher_loss 0.4023 (0.2207) loss_zs_kd 0.0700 (0.0607) loss_oracle 0.5590 (0.5668) kd_loss 0.7161 (0.8241) acc 90.6250 (93.0208) gate/entropy 1.0168 (1.0187) gate/usage_max 0.5293 (0.5268) gate/usage_min 0.2208 (0.2215) gate/usage_std 0.1391 (0.1374) teacher/entropy 0.0743 (0.0586) teacher/usage_max 0.7953 (0.6949) teacher/usage_min 0.0107 (0.1053) teacher/usage_std 0.3351 (0.2614) nleep/row_max_mean 1504.4161 (1495.3313) nleep/row_max_std 47.0796 (58.8264) nleep/row_min_mean 1477.4502 (1467.2194) lr 1.1874e-03 eta 0:07:05
epoch [24/50] batch [140/160] time 0.091 (0.100) data 0.000 (0.002) loss 1.4114 (1.3617) teacher_loss 0.3342 (0.2253) loss_zs_kd 0.0548 (0.0597) loss_oracle 0.5555 (0.5663) kd_loss 0.7720 (0.8234) acc 93.7500 (92.8571) gate/entropy 1.0165 (1.0184) gate/usage_max 0.5297 (0.5272) gate/usage_min 0.2205 (0.2214) gate/usage_std 0.1393 (0.1377) teacher/entropy 0.0469 (0.0559) teacher/usage_max 0.7619 (0.6970) teacher/usage_min 0.0379 (0.0963) teacher/usage_std 0.3102 (0.2643) nleep/row_max_mean 1500.0879 (1495.7220) nleep/row_max_std 56.9059 (59.0306) nleep/row_min_mean 1473.1490 (1467.5889) lr 1.1874e-03 eta 0:06:59
epoch [24/50] batch [160/160] time 0.082 (0.099) data 0.000 (0.002) loss 1.5631 (1.3663) teacher_loss 0.2481 (0.2218) loss_zs_kd 0.0742 (0.0606) loss_oracle 0.5782 (0.5705) kd_loss 0.9888 (0.8290) acc 90.6250 (93.0078) gate/entropy 1.0163 (1.0181) gate/usage_max 0.5299 (0.5276) gate/usage_min 0.2202 (0.2212) gate/usage_std 0.1395 (0.1379) teacher/entropy 0.0325 (0.0547) teacher/usage_max 0.5026 (0.6901) teacher/usage_min 0.0948 (0.0910) teacher/usage_std 0.1735 (0.2623) nleep/row_max_mean 1489.9065 (1495.7918) nleep/row_max_std 68.4635 (59.2196) nleep/row_min_mean 1464.2612 (1467.6942) lr 1.1253e-03 eta 0:06:51
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,829
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 83.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,905
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 87.3%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [25/50] batch [20/160] time 0.094 (0.104) data 0.000 (0.014) loss 1.4858 (1.3838) teacher_loss 0.2763 (0.1922) loss_zs_kd 0.0569 (0.0603) loss_oracle 0.6757 (0.6112) kd_loss 0.8433 (0.8558) acc 87.5000 (93.4375) gate/entropy 1.0160 (1.0160) gate/usage_max 0.5302 (0.5302) gate/usage_min 0.2198 (0.2200) gate/usage_std 0.1398 (0.1397) teacher/entropy 0.0030 (0.0355) teacher/usage_max 0.7185 (0.6643) teacher/usage_min 0.0002 (0.0361) teacher/usage_std 0.2955 (0.2634) nleep/row_max_mean 1492.8953 (1495.7484) nleep/row_max_std 66.5835 (61.1578) nleep/row_min_mean 1464.1921 (1467.4882) lr 1.1253e-03 eta 0:07:09
epoch [25/50] batch [40/160] time 0.107 (0.099) data 0.001 (0.007) loss 1.2830 (1.3925) teacher_loss 0.0981 (0.2110) loss_zs_kd 0.0470 (0.0604) loss_oracle 0.5555 (0.6010) kd_loss 0.8836 (0.8508) acc 100.0000 (93.0469) gate/entropy 1.0159 (1.0160) gate/usage_max 0.5303 (0.5303) gate/usage_min 0.2195 (0.2198) gate/usage_std 0.1399 (0.1398) teacher/entropy 0.0375 (0.0393) teacher/usage_max 0.6247 (0.6653) teacher/usage_min 0.0470 (0.0330) teacher/usage_std 0.2359 (0.2650) nleep/row_max_mean 1500.7706 (1496.5720) nleep/row_max_std 56.8588 (59.4990) nleep/row_min_mean 1474.6355 (1468.4005) lr 1.1253e-03 eta 0:06:48
epoch [25/50] batch [60/160] time 0.098 (0.098) data 0.001 (0.005) loss 1.4420 (1.3862) teacher_loss 0.2026 (0.2099) loss_zs_kd 0.0757 (0.0600) loss_oracle 0.6166 (0.5992) kd_loss 0.8932 (0.8468) acc 96.8750 (93.3333) gate/entropy 1.0157 (1.0158) gate/usage_max 0.5305 (0.5304) gate/usage_min 0.2192 (0.2197) gate/usage_std 0.1400 (0.1399) teacher/entropy 0.0450 (0.0375) teacher/usage_max 0.6052 (0.6722) teacher/usage_min 0.0575 (0.0301) teacher/usage_std 0.2236 (0.2682) nleep/row_max_mean 1498.2922 (1496.6998) nleep/row_max_std 43.2113 (57.7454) nleep/row_min_mean 1469.8762 (1468.8704) lr 1.1253e-03 eta 0:06:42
epoch [25/50] batch [80/160] time 0.095 (0.097) data 0.000 (0.004) loss 1.5104 (1.3911) teacher_loss 0.2069 (0.2103) loss_zs_kd 0.0698 (0.0603) loss_oracle 0.7093 (0.6068) kd_loss 0.9139 (0.8473) acc 93.7500 (93.2031) gate/entropy 1.0154 (1.0158) gate/usage_max 0.5308 (0.5305) gate/usage_min 0.2188 (0.2195) gate/usage_std 0.1402 (0.1399) teacher/entropy 0.0004 (0.0348) teacher/usage_max 0.6250 (0.6745) teacher/usage_min 0.0000 (0.0276) teacher/usage_std 0.2568 (0.2703) nleep/row_max_mean 1499.5354 (1494.4230) nleep/row_max_std 58.5125 (60.1148) nleep/row_min_mean 1468.0045 (1466.6304) lr 1.1253e-03 eta 0:06:37
epoch [25/50] batch [100/160] time 0.088 (0.097) data 0.000 (0.003) loss 1.3505 (1.4009) teacher_loss 0.1178 (0.2103) loss_zs_kd 0.0519 (0.0603) loss_oracle 0.6902 (0.6148) kd_loss 0.8617 (0.8531) acc 96.8750 (93.3438) gate/entropy 1.0151 (1.0157) gate/usage_max 0.5312 (0.5306) gate/usage_min 0.2184 (0.2193) gate/usage_std 0.1405 (0.1400) teacher/entropy 0.0057 (0.0331) teacher/usage_max 0.6875 (0.6687) teacher/usage_min 0.0012 (0.0245) teacher/usage_std 0.2806 (0.2698) nleep/row_max_mean 1506.4089 (1494.7302) nleep/row_max_std 38.9366 (59.5636) nleep/row_min_mean 1472.9771 (1466.7565) lr 1.1253e-03 eta 0:06:34
epoch [25/50] batch [120/160] time 0.103 (0.097) data 0.001 (0.003) loss 1.4560 (1.4024) teacher_loss 0.2890 (0.2094) loss_zs_kd 0.0414 (0.0595) loss_oracle 0.6070 (0.6177) kd_loss 0.8427 (0.8544) acc 87.5000 (93.4115) gate/entropy 1.0148 (1.0156) gate/usage_max 0.5315 (0.5306) gate/usage_min 0.2181 (0.2191) gate/usage_std 0.1407 (0.1401) teacher/entropy 0.0202 (0.0332) teacher/usage_max 0.6923 (0.6666) teacher/usage_min 0.0002 (0.0224) teacher/usage_std 0.2831 (0.2695) nleep/row_max_mean 1479.5376 (1495.1160) nleep/row_max_std 94.7523 (58.8201) nleep/row_min_mean 1452.8252 (1467.0664) lr 1.1253e-03 eta 0:06:32
epoch [25/50] batch [140/160] time 0.095 (0.097) data 0.000 (0.002) loss 1.5687 (1.4065) teacher_loss 0.1067 (0.2097) loss_zs_kd 0.0787 (0.0593) loss_oracle 0.7768 (0.6173) kd_loss 1.0342 (0.8585) acc 100.0000 (93.5491) gate/entropy 1.0152 (1.0155) gate/usage_max 0.5308 (0.5307) gate/usage_min 0.2178 (0.2190) gate/usage_std 0.1403 (0.1401) teacher/entropy 0.0301 (0.0324) teacher/usage_max 0.5758 (0.6625) teacher/usage_min 0.0015 (0.0204) teacher/usage_std 0.2428 (0.2687) nleep/row_max_mean 1478.2416 (1494.9997) nleep/row_max_std 82.2773 (59.5521) nleep/row_min_mean 1447.6965 (1466.9303) lr 1.1253e-03 eta 0:06:28
epoch [25/50] batch [160/160] time 0.087 (0.096) data 0.000 (0.002) loss 1.3801 (1.4114) teacher_loss 0.0953 (0.2115) loss_zs_kd 0.0456 (0.0591) loss_oracle 0.6685 (0.6200) kd_loss 0.9278 (0.8604) acc 96.8750 (93.3594) gate/entropy 1.0152 (1.0154) gate/usage_max 0.5308 (0.5307) gate/usage_min 0.2173 (0.2188) gate/usage_std 0.1404 (0.1402) teacher/entropy 0.0103 (0.0313) teacher/usage_max 0.5911 (0.6605) teacher/usage_min 0.0000 (0.0187) teacher/usage_std 0.2472 (0.2681) nleep/row_max_mean 1504.5354 (1495.3829) nleep/row_max_std 39.6759 (59.3882) nleep/row_min_mean 1473.5529 (1467.1470) lr 1.0628e-03 eta 0:06:24
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,827
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,890
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 87.0%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [26/50] batch [20/160] time 0.085 (0.127) data 0.000 (0.020) loss 1.5619 (1.4768) teacher_loss 0.1153 (0.2526) loss_zs_kd 0.0557 (0.0567) loss_oracle 0.7915 (0.6294) kd_loss 1.0230 (0.8811) acc 96.8750 (92.0312) gate/entropy 1.0152 (1.0151) gate/usage_max 0.5307 (0.5309) gate/usage_min 0.2170 (0.2171) gate/usage_std 0.1403 (0.1404) teacher/entropy 0.0050 (0.0299) teacher/usage_max 0.5322 (0.6310) teacher/usage_min 0.0000 (0.0062) teacher/usage_std 0.2372 (0.2586) nleep/row_max_mean 1518.2915 (1500.6358) nleep/row_max_std 29.5072 (56.3081) nleep/row_min_mean 1482.3208 (1471.1952) lr 1.0628e-03 eta 0:08:24
epoch [26/50] batch [40/160] time 0.101 (0.111) data 0.000 (0.010) loss 1.4674 (1.4674) teacher_loss 0.3606 (0.2649) loss_zs_kd 0.0373 (0.0488) loss_oracle 0.4977 (0.6187) kd_loss 0.8393 (0.8687) acc 87.5000 (91.0938) gate/entropy 1.0153 (1.0151) gate/usage_max 0.5305 (0.5309) gate/usage_min 0.2167 (0.2169) gate/usage_std 0.1402 (0.1404) teacher/entropy 0.0470 (0.0319) teacher/usage_max 0.6584 (0.6426) teacher/usage_min 0.0000 (0.0041) teacher/usage_std 0.2688 (0.2651) nleep/row_max_mean 1492.9543 (1499.3841) nleep/row_max_std 51.9843 (58.0389) nleep/row_min_mean 1466.7563 (1470.0448) lr 1.0628e-03 eta 0:07:20
epoch [26/50] batch [60/160] time 0.108 (0.107) data 0.001 (0.007) loss 1.4346 (1.4824) teacher_loss 0.1923 (0.2670) loss_zs_kd 0.0523 (0.0490) loss_oracle 0.6118 (0.6293) kd_loss 0.9102 (0.8763) acc 90.6250 (90.9896) gate/entropy 1.0155 (1.0151) gate/usage_max 0.5302 (0.5308) gate/usage_min 0.2162 (0.2167) gate/usage_std 0.1401 (0.1404) teacher/entropy 0.0211 (0.0303) teacher/usage_max 0.5976 (0.6348) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.2488 (0.2639) nleep/row_max_mean 1500.6185 (1497.8928) nleep/row_max_std 52.7561 (59.5567) nleep/row_min_mean 1471.2286 (1468.1356) lr 1.0628e-03 eta 0:07:02
epoch [26/50] batch [80/160] time 0.096 (0.104) data 0.000 (0.005) loss 1.4095 (1.4674) teacher_loss 0.2284 (0.2638) loss_zs_kd 0.0535 (0.0472) loss_oracle 0.5956 (0.6186) kd_loss 0.8566 (0.8708) acc 90.6250 (91.3281) gate/entropy 1.0150 (1.0152) gate/usage_max 0.5307 (0.5307) gate/usage_min 0.2158 (0.2166) gate/usage_std 0.1404 (0.1403) teacher/entropy 0.0487 (0.0329) teacher/usage_max 0.6317 (0.6376) teacher/usage_min 0.0003 (0.0029) teacher/usage_std 0.2589 (0.2660) nleep/row_max_mean 1523.3229 (1498.9176) nleep/row_max_std 26.8547 (57.9650) nleep/row_min_mean 1493.3440 (1469.0597) lr 1.0628e-03 eta 0:06:49
epoch [26/50] batch [100/160] time 0.094 (0.102) data 0.000 (0.004) loss 1.5967 (1.4789) teacher_loss 0.2644 (0.2653) loss_zs_kd 0.0740 (0.0473) loss_oracle 0.7030 (0.6193) kd_loss 0.9438 (0.8803) acc 84.3750 (90.9688) gate/entropy 1.0152 (1.0152) gate/usage_max 0.5304 (0.5306) gate/usage_min 0.2153 (0.2164) gate/usage_std 0.1402 (0.1403) teacher/entropy 0.0722 (0.0364) teacher/usage_max 0.5193 (0.6247) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.2362 (0.2619) nleep/row_max_mean 1511.8854 (1499.7652) nleep/row_max_std 55.7467 (56.5531) nleep/row_min_mean 1478.8337 (1469.6548) lr 1.0628e-03 eta 0:06:39
epoch [26/50] batch [120/160] time 0.098 (0.101) data 0.000 (0.004) loss 1.4853 (1.4986) teacher_loss 0.1980 (0.2709) loss_zs_kd 0.0549 (0.0479) loss_oracle 0.6087 (0.6258) kd_loss 0.9555 (0.8908) acc 93.7500 (90.8333) gate/entropy 1.0163 (1.0153) gate/usage_max 0.5288 (0.5304) gate/usage_min 0.2150 (0.2162) gate/usage_std 0.1392 (0.1402) teacher/entropy 0.0386 (0.0387) teacher/usage_max 0.5076 (0.6121) teacher/usage_min 0.0000 (0.0025) teacher/usage_std 0.2358 (0.2586) nleep/row_max_mean 1504.4580 (1499.8334) nleep/row_max_std 45.7751 (57.1102) nleep/row_min_mean 1473.3834 (1469.3612) lr 1.0628e-03 eta 0:06:33
epoch [26/50] batch [140/160] time 0.098 (0.101) data 0.000 (0.003) loss 1.5228 (1.5223) teacher_loss 0.2016 (0.2852) loss_zs_kd 0.0232 (0.0471) loss_oracle 0.5639 (0.6271) kd_loss 1.0277 (0.9000) acc 93.7500 (90.4018) gate/entropy 1.0168 (1.0155) gate/usage_max 0.5279 (0.5302) gate/usage_min 0.2145 (0.2160) gate/usage_std 0.1387 (0.1400) teacher/entropy 0.0480 (0.0420) teacher/usage_max 0.6105 (0.6082) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.2524 (0.2573) nleep/row_max_mean 1504.6429 (1499.2519) nleep/row_max_std 46.0181 (58.6069) nleep/row_min_mean 1470.9385 (1468.4547) lr 1.0628e-03 eta 0:06:28
epoch [26/50] batch [160/160] time 0.078 (0.099) data 0.000 (0.003) loss 1.6167 (1.5422) teacher_loss 0.2643 (0.2924) loss_zs_kd 0.0540 (0.0468) loss_oracle 0.6019 (0.6263) kd_loss 1.0245 (0.9133) acc 93.7500 (90.0977) gate/entropy 1.0178 (1.0157) gate/usage_max 0.5265 (0.5298) gate/usage_min 0.2139 (0.2157) gate/usage_std 0.1378 (0.1398) teacher/entropy 0.0924 (0.0449) teacher/usage_max 0.6721 (0.6092) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.2744 (0.2574) nleep/row_max_mean 1499.2600 (1499.8938) nleep/row_max_std 75.1652 (58.7551) nleep/row_min_mean 1468.0071 (1468.6394) lr 1.0000e-03 eta 0:06:19
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,756
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 81.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,884
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 86.7%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [27/50] batch [20/160] time 0.091 (0.110) data 0.000 (0.014) loss 1.9226 (1.6612) teacher_loss 0.4730 (0.3485) loss_zs_kd 0.0378 (0.0433) loss_oracle 0.6503 (0.5941) kd_loss 1.1055 (0.9941) acc 84.3750 (88.2812) gate/entropy 1.0186 (1.0180) gate/usage_max 0.5250 (0.5260) gate/usage_min 0.2133 (0.2135) gate/usage_std 0.1370 (0.1376) teacher/entropy 0.0476 (0.0705) teacher/usage_max 0.7323 (0.6130) teacher/usage_min 0.0000 (0.0021) teacher/usage_std 0.3025 (0.2566) nleep/row_max_mean 1519.5885 (1501.1133) nleep/row_max_std 32.6880 (60.3371) nleep/row_min_mean 1478.2739 (1467.3782) lr 1.0000e-03 eta 0:06:59
epoch [27/50] batch [40/160] time 0.091 (0.102) data 0.000 (0.007) loss 1.5614 (1.6580) teacher_loss 0.3098 (0.3458) loss_zs_kd 0.0331 (0.0411) loss_oracle 0.5193 (0.5792) kd_loss 0.9754 (1.0021) acc 90.6250 (87.4219) gate/entropy 1.0194 (1.0184) gate/usage_max 0.5237 (0.5253) gate/usage_min 0.2125 (0.2131) gate/usage_std 0.1363 (0.1372) teacher/entropy 0.0939 (0.0714) teacher/usage_max 0.6164 (0.6227) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.2541 (0.2606) nleep/row_max_mean 1492.7704 (1503.2474) nleep/row_max_std 65.6344 (58.4010) nleep/row_min_mean 1461.0603 (1469.1793) lr 1.0000e-03 eta 0:06:29
epoch [27/50] batch [60/160] time 0.088 (0.099) data 0.000 (0.005) loss 2.0126 (1.6523) teacher_loss 0.5986 (0.3468) loss_zs_kd 0.0596 (0.0395) loss_oracle 0.5688 (0.5741) kd_loss 1.0997 (0.9987) acc 68.7500 (86.9271) gate/entropy 1.0200 (1.0188) gate/usage_max 0.5226 (0.5246) gate/usage_min 0.2118 (0.2128) gate/usage_std 0.1356 (0.1368) teacher/entropy 0.0298 (0.0675) teacher/usage_max 0.7101 (0.6145) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.2915 (0.2580) nleep/row_max_mean 1513.7128 (1503.8001) nleep/row_max_std 45.3128 (58.2268) nleep/row_min_mean 1476.4911 (1469.4741) lr 1.0000e-03 eta 0:06:15
epoch [27/50] batch [80/160] time 0.097 (0.099) data 0.000 (0.004) loss 1.5430 (1.6707) teacher_loss 0.2771 (0.3612) loss_zs_kd 0.0282 (0.0387) loss_oracle 0.6209 (0.5762) kd_loss 0.9414 (1.0020) acc 87.5000 (86.4453) gate/entropy 1.0211 (1.0192) gate/usage_max 0.5208 (0.5239) gate/usage_min 0.2111 (0.2124) gate/usage_std 0.1346 (0.1364) teacher/entropy 0.0331 (0.0690) teacher/usage_max 0.5148 (0.6231) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.2360 (0.2611) nleep/row_max_mean 1475.5674 (1504.2642) nleep/row_max_std 84.7673 (58.3218) nleep/row_min_mean 1442.6689 (1470.1500) lr 1.0000e-03 eta 0:06:13
epoch [27/50] batch [100/160] time 0.096 (0.101) data 0.000 (0.003) loss 1.8271 (1.6859) teacher_loss 0.4826 (0.3672) loss_zs_kd 0.0250 (0.0383) loss_oracle 0.6685 (0.5765) kd_loss 0.9977 (1.0113) acc 87.5000 (86.3438) gate/entropy 1.0223 (1.0197) gate/usage_max 0.5186 (0.5231) gate/usage_min 0.2103 (0.2121) gate/usage_std 0.1333 (0.1359) teacher/entropy 0.0551 (0.0672) teacher/usage_max 0.6110 (0.6369) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.2525 (0.2664) nleep/row_max_mean 1488.9600 (1504.7111) nleep/row_max_std 89.7551 (57.9883) nleep/row_min_mean 1455.8635 (1470.5988) lr 1.0000e-03 eta 0:06:17
epoch [27/50] batch [120/160] time 0.090 (0.100) data 0.000 (0.002) loss 1.6392 (1.6869) teacher_loss 0.2562 (0.3672) loss_zs_kd 0.0325 (0.0373) loss_oracle 0.5820 (0.5751) kd_loss 1.0758 (1.0135) acc 96.8750 (86.4583) gate/entropy 1.0233 (1.0202) gate/usage_max 0.5166 (0.5222) gate/usage_min 0.2093 (0.2117) gate/usage_std 0.1323 (0.1354) teacher/entropy 0.0536 (0.0646) teacher/usage_max 0.7401 (0.6394) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.3066 (0.2673) nleep/row_max_mean 1508.0708 (1503.8642) nleep/row_max_std 67.7859 (59.3802) nleep/row_min_mean 1473.3225 (1469.8636) lr 1.0000e-03 eta 0:06:11
epoch [27/50] batch [140/160] time 0.160 (0.101) data 0.001 (0.002) loss 1.6275 (1.6820) teacher_loss 0.3303 (0.3629) loss_zs_kd 0.0295 (0.0366) loss_oracle 0.5553 (0.5772) kd_loss 1.0048 (1.0122) acc 84.3750 (86.5179) gate/entropy 1.0241 (1.0207) gate/usage_max 0.5150 (0.5212) gate/usage_min 0.2084 (0.2113) gate/usage_std 0.1314 (0.1349) teacher/entropy 0.0565 (0.0625) teacher/usage_max 0.6393 (0.6384) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.2617 (0.2675) nleep/row_max_mean 1494.8899 (1503.7237) nleep/row_max_std 71.5831 (58.9460) nleep/row_min_mean 1462.2833 (1469.7608) lr 1.0000e-03 eta 0:06:13
epoch [27/50] batch [160/160] time 0.075 (0.099) data 0.000 (0.002) loss 1.6109 (1.6742) teacher_loss 0.2710 (0.3541) loss_zs_kd 0.0623 (0.0365) loss_oracle 0.5673 (0.5774) kd_loss 1.0251 (1.0131) acc 87.5000 (86.8750) gate/entropy 1.0252 (1.0212) gate/usage_max 0.5128 (0.5203) gate/usage_min 0.2075 (0.2109) gate/usage_std 0.1303 (0.1344) teacher/entropy 0.0362 (0.0618) teacher/usage_max 0.6496 (0.6424) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.2655 (0.2686) nleep/row_max_mean 1515.8459 (1503.7787) nleep/row_max_std 43.3052 (58.8737) nleep/row_min_mean 1481.4060 (1469.9651) lr 9.3721e-04 eta 0:06:02
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,781
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 82.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,893
* accuracy: 85.7%
* error: 14.3%
* macro_f1: 86.8%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [28/50] batch [20/160] time 0.094 (0.109) data 0.000 (0.015) loss 1.5876 (1.6857) teacher_loss 0.2622 (0.3443) loss_zs_kd 0.0417 (0.0393) loss_oracle 0.5498 (0.5768) kd_loss 1.0297 (1.0334) acc 87.5000 (85.6250) gate/entropy 1.0263 (1.0257) gate/usage_max 0.5105 (0.5116) gate/usage_min 0.2067 (0.2071) gate/usage_std 0.1291 (0.1297) teacher/entropy 0.0619 (0.0432) teacher/usage_max 0.7105 (0.6901) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2917 (0.2898) nleep/row_max_mean 1509.4001 (1501.2491) nleep/row_max_std 35.7335 (57.5158) nleep/row_min_mean 1479.6735 (1467.9840) lr 9.3721e-04 eta 0:06:39
epoch [28/50] batch [40/160] time 0.094 (0.099) data 0.000 (0.007) loss 1.7361 (1.6409) teacher_loss 0.4235 (0.3210) loss_zs_kd 0.0366 (0.0387) loss_oracle 0.6783 (0.5827) kd_loss 0.9552 (1.0092) acc 75.0000 (86.9531) gate/entropy 1.0274 (1.0262) gate/usage_max 0.5082 (0.5106) gate/usage_min 0.2058 (0.2066) gate/usage_std 0.1279 (0.1291) teacher/entropy 0.0366 (0.0454) teacher/usage_max 0.5455 (0.6539) teacher/usage_min 0.0030 (0.0002) teacher/usage_std 0.2367 (0.2742) nleep/row_max_mean 1502.5292 (1502.5283) nleep/row_max_std 46.2117 (56.7337) nleep/row_min_mean 1468.5610 (1469.3380) lr 9.3721e-04 eta 0:06:01
epoch [28/50] batch [60/160] time 0.084 (0.095) data 0.001 (0.005) loss 1.7160 (1.6349) teacher_loss 0.3034 (0.3203) loss_zs_kd 0.0465 (0.0385) loss_oracle 0.5378 (0.5765) kd_loss 1.1205 (1.0071) acc 87.5000 (87.1354) gate/entropy 1.0283 (1.0267) gate/usage_max 0.5060 (0.5095) gate/usage_min 0.2049 (0.2062) gate/usage_std 0.1269 (0.1286) teacher/entropy 0.0140 (0.0468) teacher/usage_max 0.8101 (0.6550) teacher/usage_min 0.0001 (0.0006) teacher/usage_std 0.3459 (0.2736) nleep/row_max_mean 1512.4753 (1504.0297) nleep/row_max_std 43.8217 (54.9182) nleep/row_min_mean 1476.5581 (1470.9779) lr 9.3721e-04 eta 0:05:42
epoch [28/50] batch [80/160] time 0.085 (0.093) data 0.000 (0.004) loss 1.8100 (1.6198) teacher_loss 0.4891 (0.3082) loss_zs_kd 0.0373 (0.0373) loss_oracle 0.5666 (0.5723) kd_loss 1.0190 (1.0068) acc 78.1250 (87.7734) gate/entropy 1.0286 (1.0271) gate/usage_max 0.5046 (0.5085) gate/usage_min 0.2037 (0.2057) gate/usage_std 0.1263 (0.1281) teacher/entropy 0.0503 (0.0447) teacher/usage_max 0.7040 (0.6556) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.2886 (0.2739) nleep/row_max_mean 1492.9783 (1504.0192) nleep/row_max_std 71.5250 (55.8453) nleep/row_min_mean 1464.1565 (1471.1315) lr 9.3721e-04 eta 0:05:34
epoch [28/50] batch [100/160] time 0.076 (0.091) data 0.000 (0.003) loss 1.6313 (1.6209) teacher_loss 0.3290 (0.3134) loss_zs_kd 0.0252 (0.0364) loss_oracle 0.5052 (0.5696) kd_loss 1.0371 (1.0045) acc 93.7500 (87.7188) gate/entropy 1.0297 (1.0275) gate/usage_max 0.5020 (0.5074) gate/usage_min 0.2029 (0.2052) gate/usage_std 0.1251 (0.1276) teacher/entropy 0.0441 (0.0448) teacher/usage_max 0.7397 (0.6556) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.3064 (0.2737) nleep/row_max_mean 1481.4944 (1503.0903) nleep/row_max_std 93.8747 (57.4051) nleep/row_min_mean 1450.5978 (1470.6171) lr 9.3721e-04 eta 0:05:25
epoch [28/50] batch [120/160] time 0.102 (0.090) data 0.000 (0.003) loss 1.7440 (1.6151) teacher_loss 0.3960 (0.3111) loss_zs_kd 0.0281 (0.0368) loss_oracle 0.5331 (0.5705) kd_loss 1.0674 (1.0004) acc 87.5000 (87.9427) gate/entropy 1.0304 (1.0279) gate/usage_max 0.5000 (0.5064) gate/usage_min 0.2019 (0.2048) gate/usage_std 0.1242 (0.1271) teacher/entropy 0.0248 (0.0449) teacher/usage_max 0.7723 (0.6522) teacher/usage_min 0.0002 (0.0009) teacher/usage_std 0.3240 (0.2721) nleep/row_max_mean 1484.0269 (1502.3966) nleep/row_max_std 86.9154 (57.3440) nleep/row_min_mean 1455.7413 (1470.3432) lr 9.3721e-04 eta 0:05:20
epoch [28/50] batch [140/160] time 0.079 (0.089) data 0.000 (0.002) loss 1.7629 (1.6198) teacher_loss 0.3283 (0.3145) loss_zs_kd 0.0509 (0.0370) loss_oracle 0.6034 (0.5683) kd_loss 1.1074 (1.0026) acc 90.6250 (87.7679) gate/entropy 1.0310 (1.0283) gate/usage_max 0.4979 (0.5053) gate/usage_min 0.2008 (0.2043) gate/usage_std 0.1234 (0.1267) teacher/entropy 0.0123 (0.0439) teacher/usage_max 0.8421 (0.6590) teacher/usage_min 0.0000 (0.0012) teacher/usage_std 0.3655 (0.2750) nleep/row_max_mean 1505.0247 (1502.6002) nleep/row_max_std 58.4095 (56.3975) nleep/row_min_mean 1475.2646 (1470.8419) lr 9.3721e-04 eta 0:05:15
epoch [28/50] batch [160/160] time 0.085 (0.089) data 0.000 (0.002) loss 1.4317 (1.6279) teacher_loss 0.1919 (0.3173) loss_zs_kd 0.0448 (0.0376) loss_oracle 0.5050 (0.5744) kd_loss 0.9650 (1.0046) acc 96.8750 (87.5586) gate/entropy 1.0318 (1.0287) gate/usage_max 0.4952 (0.5042) gate/usage_min 0.1993 (0.2038) gate/usage_std 0.1224 (0.1262) teacher/entropy 0.0660 (0.0432) teacher/usage_max 0.6809 (0.6663) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.2782 (0.2776) nleep/row_max_mean 1505.7560 (1502.0659) nleep/row_max_std 59.8711 (56.7635) nleep/row_min_mean 1477.5388 (1470.6022) lr 8.7467e-04 eta 0:05:12
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,813
* accuracy: 82.2%
* error: 17.8%
* macro_f1: 84.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,925
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.7%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [29/50] batch [20/160] time 0.089 (0.116) data 0.000 (0.017) loss 1.6344 (1.5808) teacher_loss 0.3417 (0.2908) loss_zs_kd 0.0392 (0.0362) loss_oracle 0.5392 (0.5576) kd_loss 1.0034 (0.9930) acc 84.3750 (87.5000) gate/entropy 1.0328 (1.0324) gate/usage_max 0.4922 (0.4935) gate/usage_min 0.1985 (0.1990) gate/usage_std 0.1211 (0.1216) teacher/entropy 0.0421 (0.0425) teacher/usage_max 0.6735 (0.6879) teacher/usage_min 0.0281 (0.0054) teacher/usage_std 0.2646 (0.2836) nleep/row_max_mean 1508.5944 (1496.3557) nleep/row_max_std 25.4842 (58.9827) nleep/row_min_mean 1480.4246 (1468.2424) lr 8.7467e-04 eta 0:06:46
epoch [29/50] batch [40/160] time 0.084 (0.100) data 0.000 (0.008) loss 1.7367 (1.5893) teacher_loss 0.4209 (0.2981) loss_zs_kd 0.0411 (0.0357) loss_oracle 0.5638 (0.5432) kd_loss 1.0134 (1.0017) acc 81.2500 (87.5000) gate/entropy 1.0336 (1.0328) gate/usage_max 0.4895 (0.4922) gate/usage_min 0.1975 (0.1984) gate/usage_std 0.1201 (0.1211) teacher/entropy 0.0077 (0.0414) teacher/usage_max 0.6866 (0.7121) teacher/usage_min 0.0010 (0.0054) teacher/usage_std 0.2803 (0.2950) nleep/row_max_mean 1496.1082 (1499.3005) nleep/row_max_std 58.3432 (55.9719) nleep/row_min_mean 1465.0045 (1470.2814) lr 8.7467e-04 eta 0:05:47
epoch [29/50] batch [60/160] time 0.088 (0.096) data 0.001 (0.006) loss 1.5378 (1.6007) teacher_loss 0.2284 (0.3029) loss_zs_kd 0.0323 (0.0375) loss_oracle 0.5117 (0.5480) kd_loss 1.0374 (1.0050) acc 90.6250 (87.2396) gate/entropy 1.0341 (1.0331) gate/usage_max 0.4869 (0.4909) gate/usage_min 0.1962 (0.1978) gate/usage_std 0.1192 (0.1207) teacher/entropy 0.0361 (0.0364) teacher/usage_max 0.7591 (0.7173) teacher/usage_min 0.0317 (0.0048) teacher/usage_std 0.3097 (0.2974) nleep/row_max_mean 1503.5656 (1497.7850) nleep/row_max_std 32.8356 (57.5294) nleep/row_min_mean 1476.2510 (1468.7697) lr 8.7467e-04 eta 0:05:32
epoch [29/50] batch [80/160] time 0.076 (0.098) data 0.000 (0.004) loss 1.6143 (1.5878) teacher_loss 0.2870 (0.2889) loss_zs_kd 0.0368 (0.0373) loss_oracle 0.6414 (0.5520) kd_loss 0.9882 (1.0042) acc 90.6250 (87.8516) gate/entropy 1.0346 (1.0334) gate/usage_max 0.4845 (0.4896) gate/usage_min 0.1950 (0.1973) gate/usage_std 0.1185 (0.1202) teacher/entropy 0.0391 (0.0331) teacher/usage_max 0.6954 (0.7153) teacher/usage_min 0.0181 (0.0050) teacher/usage_std 0.2785 (0.2962) nleep/row_max_mean 1495.0159 (1497.7776) nleep/row_max_std 51.5134 (55.6973) nleep/row_min_mean 1465.7578 (1468.5178) lr 8.7467e-04 eta 0:05:36
epoch [29/50] batch [100/160] time 0.093 (0.095) data 0.000 (0.004) loss 1.4641 (1.5938) teacher_loss 0.1438 (0.2908) loss_zs_kd 0.0337 (0.0378) loss_oracle 0.5895 (0.5595) kd_loss 1.0088 (1.0043) acc 96.8750 (87.9062) gate/entropy 1.0350 (1.0337) gate/usage_max 0.4816 (0.4883) gate/usage_min 0.1936 (0.1967) gate/usage_std 0.1177 (0.1198) teacher/entropy 0.0288 (0.0316) teacher/usage_max 0.7756 (0.7211) teacher/usage_min 0.0029 (0.0048) teacher/usage_std 0.3252 (0.2990) nleep/row_max_mean 1502.5950 (1497.4488) nleep/row_max_std 52.3944 (56.3860) nleep/row_min_mean 1470.6648 (1467.9535) lr 8.7467e-04 eta 0:05:26
epoch [29/50] batch [120/160] time 0.089 (0.094) data 0.000 (0.003) loss 1.7032 (1.6015) teacher_loss 0.4048 (0.2956) loss_zs_kd 0.0470 (0.0381) loss_oracle 0.5856 (0.5645) kd_loss 0.9821 (1.0046) acc 87.5000 (87.6042) gate/entropy 1.0355 (1.0340) gate/usage_max 0.4787 (0.4869) gate/usage_min 0.1924 (0.1961) gate/usage_std 0.1169 (0.1194) teacher/entropy 0.0406 (0.0303) teacher/usage_max 0.7481 (0.7281) teacher/usage_min 0.0066 (0.0047) teacher/usage_std 0.3090 (0.3028) nleep/row_max_mean 1489.8356 (1497.2360) nleep/row_max_std 64.4300 (56.6038) nleep/row_min_mean 1458.4771 (1467.4914) lr 8.7467e-04 eta 0:05:20
epoch [29/50] batch [140/160] time 0.095 (0.093) data 0.000 (0.003) loss 1.8374 (1.6107) teacher_loss 0.5453 (0.3042) loss_zs_kd 0.0356 (0.0385) loss_oracle 0.5994 (0.5661) kd_loss 0.9746 (1.0042) acc 84.3750 (87.5446) gate/entropy 1.0358 (1.0342) gate/usage_max 0.4756 (0.4855) gate/usage_min 0.1909 (0.1954) gate/usage_std 0.1163 (0.1190) teacher/entropy 0.0458 (0.0298) teacher/usage_max 0.7049 (0.7351) teacher/usage_min 0.0313 (0.0048) teacher/usage_std 0.2794 (0.3064) nleep/row_max_mean 1504.8462 (1497.0836) nleep/row_max_std 55.8900 (57.3951) nleep/row_min_mean 1471.8937 (1467.1816) lr 8.7467e-04 eta 0:05:15
epoch [29/50] batch [160/160] time 0.078 (0.092) data 0.000 (0.002) loss 1.5989 (1.6083) teacher_loss 0.2940 (0.3029) loss_zs_kd 0.0376 (0.0390) loss_oracle 0.5716 (0.5680) kd_loss 1.0003 (1.0019) acc 90.6250 (87.5977) gate/entropy 1.0362 (1.0344) gate/usage_max 0.4726 (0.4841) gate/usage_min 0.1898 (0.1948) gate/usage_std 0.1155 (0.1186) teacher/entropy 0.0008 (0.0283) teacher/usage_max 0.7500 (0.7358) teacher/usage_min 0.0001 (0.0045) teacher/usage_std 0.3118 (0.3067) nleep/row_max_mean 1482.5869 (1497.0070) nleep/row_max_std 63.3289 (57.4174) nleep/row_min_mean 1453.2825 (1467.0497) lr 8.1262e-04 eta 0:05:09
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,820
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 84.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,909
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 87.6%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [30/50] batch [20/160] time 0.088 (0.100) data 0.000 (0.014) loss 1.7772 (1.6224) teacher_loss 0.4771 (0.3092) loss_zs_kd 0.0474 (0.0423) loss_oracle 0.5515 (0.5923) kd_loss 1.0006 (0.9959) acc 81.2500 (87.0312) gate/entropy 1.0364 (1.0362) gate/usage_max 0.4699 (0.4713) gate/usage_min 0.1886 (0.1890) gate/usage_std 0.1150 (0.1153) teacher/entropy 0.0174 (0.0174) teacher/usage_max 0.8052 (0.7817) teacher/usage_min 0.0073 (0.0067) teacher/usage_std 0.3417 (0.3295) nleep/row_max_mean 1490.4161 (1496.9195) nleep/row_max_std 70.4389 (57.9090) nleep/row_min_mean 1459.3231 (1466.4528) lr 8.1262e-04 eta 0:05:34
epoch [30/50] batch [40/160] time 0.067 (0.092) data 0.000 (0.007) loss 1.7620 (1.6161) teacher_loss 0.4474 (0.3095) loss_zs_kd 0.0616 (0.0435) loss_oracle 0.5868 (0.5818) kd_loss 0.9904 (0.9939) acc 84.3750 (87.7344) gate/entropy 1.0363 (1.0363) gate/usage_max 0.4672 (0.4699) gate/usage_min 0.1870 (0.1884) gate/usage_std 0.1147 (0.1151) teacher/entropy 0.0283 (0.0180) teacher/usage_max 0.8540 (0.7884) teacher/usage_min 0.0014 (0.0070) teacher/usage_std 0.3728 (0.3338) nleep/row_max_mean 1513.8198 (1496.8577) nleep/row_max_std 28.6497 (57.0168) nleep/row_min_mean 1479.3344 (1465.8864) lr 8.1262e-04 eta 0:05:06
epoch [30/50] batch [60/160] time 0.092 (0.089) data 0.000 (0.005) loss 1.5571 (1.6079) teacher_loss 0.2735 (0.3113) loss_zs_kd 0.0361 (0.0414) loss_oracle 0.6567 (0.5812) kd_loss 0.9372 (0.9853) acc 87.5000 (87.1875) gate/entropy 1.0364 (1.0363) gate/usage_max 0.4650 (0.4686) gate/usage_min 0.1862 (0.1878) gate/usage_std 0.1143 (0.1149) teacher/entropy 0.0074 (0.0183) teacher/usage_max 0.6239 (0.7738) teacher/usage_min 0.0013 (0.0068) teacher/usage_std 0.2559 (0.3262) nleep/row_max_mean 1493.1306 (1498.2036) nleep/row_max_std 70.0769 (55.4202) nleep/row_min_mean 1461.7374 (1466.9779) lr 8.1262e-04 eta 0:04:54
epoch [30/50] batch [80/160] time 0.083 (0.088) data 0.000 (0.004) loss 1.4723 (1.6027) teacher_loss 0.2230 (0.3107) loss_zs_kd 0.0490 (0.0420) loss_oracle 0.6128 (0.5830) kd_loss 0.9183 (0.9794) acc 90.6250 (87.1875) gate/entropy 1.0364 (1.0363) gate/usage_max 0.4626 (0.4673) gate/usage_min 0.1851 (0.1873) gate/usage_std 0.1141 (0.1147) teacher/entropy 0.0459 (0.0196) teacher/usage_max 0.7115 (0.7707) teacher/usage_min 0.0006 (0.0065) teacher/usage_std 0.2920 (0.3246) nleep/row_max_mean 1488.8708 (1497.7034) nleep/row_max_std 73.9545 (56.0588) nleep/row_min_mean 1459.1770 (1466.3525) lr 8.1262e-04 eta 0:04:49
epoch [30/50] batch [100/160] time 0.095 (0.088) data 0.000 (0.003) loss 1.5205 (1.5943) teacher_loss 0.2545 (0.3033) loss_zs_kd 0.0244 (0.0434) loss_oracle 0.5816 (0.5868) kd_loss 0.9630 (0.9759) acc 84.3750 (87.4062) gate/entropy 1.0362 (1.0363) gate/usage_max 0.4601 (0.4661) gate/usage_min 0.1838 (0.1867) gate/usage_std 0.1139 (0.1146) teacher/entropy 0.0132 (0.0189) teacher/usage_max 0.7781 (0.7687) teacher/usage_min 0.0016 (0.0062) teacher/usage_std 0.3269 (0.3238) nleep/row_max_mean 1504.4519 (1497.3964) nleep/row_max_std 53.2419 (57.1554) nleep/row_min_mean 1471.9846 (1466.0873) lr 8.1262e-04 eta 0:04:47
epoch [30/50] batch [120/160] time 0.078 (0.088) data 0.000 (0.003) loss 1.5274 (1.5872) teacher_loss 0.2377 (0.2996) loss_zs_kd 0.0348 (0.0430) loss_oracle 0.5763 (0.5868) kd_loss 0.9841 (0.9727) acc 90.6250 (87.6042) gate/entropy 1.0361 (1.0363) gate/usage_max 0.4580 (0.4649) gate/usage_min 0.1829 (0.1861) gate/usage_std 0.1138 (0.1144) teacher/entropy 0.0193 (0.0187) teacher/usage_max 0.7738 (0.7673) teacher/usage_min 0.0387 (0.0064) teacher/usage_std 0.3173 (0.3232) nleep/row_max_mean 1497.2341 (1496.8168) nleep/row_max_std 68.8220 (58.1054) nleep/row_min_mean 1466.2046 (1465.4713) lr 8.1262e-04 eta 0:04:44
epoch [30/50] batch [140/160] time 0.087 (0.087) data 0.000 (0.002) loss 1.7295 (1.5825) teacher_loss 0.4268 (0.2972) loss_zs_kd 0.0506 (0.0431) loss_oracle 0.5975 (0.5862) kd_loss 0.9787 (0.9707) acc 90.6250 (87.8571) gate/entropy 1.0360 (1.0363) gate/usage_max 0.4558 (0.4638) gate/usage_min 0.1820 (0.1856) gate/usage_std 0.1136 (0.1143) teacher/entropy 0.0076 (0.0178) teacher/usage_max 0.8735 (0.7685) teacher/usage_min 0.0004 (0.0063) teacher/usage_std 0.3854 (0.3237) nleep/row_max_mean 1492.5356 (1497.1455) nleep/row_max_std 80.1102 (57.9609) nleep/row_min_mean 1458.5217 (1465.5704) lr 8.1262e-04 eta 0:04:40
epoch [30/50] batch [160/160] time 0.074 (0.087) data 0.000 (0.002) loss 1.5627 (1.5795) teacher_loss 0.2515 (0.2961) loss_zs_kd 0.0463 (0.0435) loss_oracle 0.6328 (0.5874) kd_loss 0.9718 (0.9679) acc 87.5000 (87.8906) gate/entropy 1.0356 (1.0362) gate/usage_max 0.4537 (0.4626) gate/usage_min 0.1808 (0.1851) gate/usage_std 0.1137 (0.1142) teacher/entropy 0.0007 (0.0170) teacher/usage_max 0.8437 (0.7664) teacher/usage_min 0.0001 (0.0062) teacher/usage_std 0.3665 (0.3225) nleep/row_max_mean 1508.9871 (1497.2647) nleep/row_max_std 52.1035 (58.4607) nleep/row_min_mean 1474.0243 (1465.4176) lr 7.5131e-04 eta 0:04:37
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,829
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 84.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,956
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.6%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [31/50] batch [20/160] time 0.092 (0.117) data 0.000 (0.014) loss 1.5329 (1.5746) teacher_loss 0.2979 (0.3068) loss_zs_kd 0.0513 (0.0442) loss_oracle 0.5695 (0.5996) kd_loss 0.9246 (0.9459) acc 90.6250 (88.9062) gate/entropy 1.0355 (1.0357) gate/usage_max 0.4522 (0.4529) gate/usage_min 0.1801 (0.1806) gate/usage_std 0.1137 (0.1136) teacher/entropy 0.0129 (0.0101) teacher/usage_max 0.6835 (0.7687) teacher/usage_min 0.0041 (0.0022) teacher/usage_std 0.2778 (0.3231) nleep/row_max_mean 1499.3542 (1497.1670) nleep/row_max_std 69.6874 (64.8184) nleep/row_min_mean 1464.6421 (1463.5863) lr 7.5131e-04 eta 0:06:13
epoch [31/50] batch [40/160] time 0.095 (0.105) data 0.000 (0.007) loss 1.5282 (1.5687) teacher_loss 0.2691 (0.3097) loss_zs_kd 0.0636 (0.0413) loss_oracle 0.5617 (0.5768) kd_loss 0.9464 (0.9499) acc 90.6250 (88.1250) gate/entropy 1.0355 (1.0356) gate/usage_max 0.4504 (0.4520) gate/usage_min 0.1796 (0.1802) gate/usage_std 0.1136 (0.1136) teacher/entropy 0.0041 (0.0106) teacher/usage_max 0.7806 (0.7849) teacher/usage_min 0.0004 (0.0060) teacher/usage_std 0.3286 (0.3321) nleep/row_max_mean 1473.1571 (1498.1736) nleep/row_max_std 86.1088 (61.1066) nleep/row_min_mean 1442.0503 (1464.7793) lr 7.5131e-04 eta 0:05:31
epoch [31/50] batch [60/160] time 0.098 (0.101) data 0.001 (0.005) loss 1.5772 (1.5680) teacher_loss 0.3356 (0.3111) loss_zs_kd 0.0580 (0.0417) loss_oracle 0.5938 (0.5783) kd_loss 0.9157 (0.9469) acc 87.5000 (87.8125) gate/entropy 1.0351 (1.0354) gate/usage_max 0.4487 (0.4512) gate/usage_min 0.1786 (0.1798) gate/usage_std 0.1137 (0.1137) teacher/entropy 0.0191 (0.0097) teacher/usage_max 0.6782 (0.7814) teacher/usage_min 0.0093 (0.0049) teacher/usage_std 0.2735 (0.3309) nleep/row_max_mean 1501.9181 (1498.4102) nleep/row_max_std 46.9122 (61.0098) nleep/row_min_mean 1468.4172 (1464.8207) lr 7.5131e-04 eta 0:05:16
epoch [31/50] batch [80/160] time 0.092 (0.099) data 0.000 (0.004) loss 1.4554 (1.5530) teacher_loss 0.2022 (0.2942) loss_zs_kd 0.0553 (0.0444) loss_oracle 0.5962 (0.5866) kd_loss 0.9275 (0.9433) acc 93.7500 (88.4766) gate/entropy 1.0348 (1.0353) gate/usage_max 0.4472 (0.4504) gate/usage_min 0.1778 (0.1794) gate/usage_std 0.1138 (0.1137) teacher/entropy 0.0103 (0.0113) teacher/usage_max 0.7477 (0.7736) teacher/usage_min 0.0020 (0.0066) teacher/usage_std 0.3100 (0.3262) nleep/row_max_mean 1485.5100 (1498.0292) nleep/row_max_std 79.4682 (61.2719) nleep/row_min_mean 1450.5623 (1464.4090) lr 7.5131e-04 eta 0:05:08
epoch [31/50] batch [100/160] time 0.091 (0.098) data 0.000 (0.003) loss 1.4334 (1.5502) teacher_loss 0.2288 (0.2922) loss_zs_kd 0.0381 (0.0442) loss_oracle 0.5387 (0.5904) kd_loss 0.9162 (0.9407) acc 90.6250 (88.4688) gate/entropy 1.0345 (1.0352) gate/usage_max 0.4456 (0.4496) gate/usage_min 0.1772 (0.1790) gate/usage_std 0.1139 (0.1137) teacher/entropy 0.0219 (0.0113) teacher/usage_max 0.7740 (0.7760) teacher/usage_min 0.0016 (0.0057) teacher/usage_std 0.3246 (0.3275) nleep/row_max_mean 1488.0758 (1498.1776) nleep/row_max_std 75.0172 (61.5046) nleep/row_min_mean 1456.7339 (1464.5470) lr 7.5131e-04 eta 0:05:03
epoch [31/50] batch [120/160] time 0.093 (0.097) data 0.000 (0.003) loss 1.4175 (1.5541) teacher_loss 0.1856 (0.2982) loss_zs_kd 0.0209 (0.0438) loss_oracle 0.5839 (0.5911) kd_loss 0.9295 (0.9385) acc 93.7500 (88.0990) gate/entropy 1.0342 (1.0350) gate/usage_max 0.4441 (0.4488) gate/usage_min 0.1764 (0.1786) gate/usage_std 0.1140 (0.1138) teacher/entropy 0.0325 (0.0120) teacher/usage_max 0.7831 (0.7774) teacher/usage_min 0.0294 (0.0059) teacher/usage_std 0.3245 (0.3281) nleep/row_max_mean 1504.1702 (1497.9036) nleep/row_max_std 40.6682 (61.0695) nleep/row_min_mean 1473.9034 (1464.3954) lr 7.5131e-04 eta 0:04:59
epoch [31/50] batch [140/160] time 0.094 (0.097) data 0.000 (0.002) loss 1.5650 (1.5543) teacher_loss 0.3240 (0.2992) loss_zs_kd 0.0529 (0.0438) loss_oracle 0.6253 (0.5944) kd_loss 0.9019 (0.9360) acc 90.6250 (88.1250) gate/entropy 1.0339 (1.0349) gate/usage_max 0.4429 (0.4480) gate/usage_min 0.1757 (0.1783) gate/usage_std 0.1142 (0.1138) teacher/entropy 0.0057 (0.0128) teacher/usage_max 0.6255 (0.7753) teacher/usage_min 0.0004 (0.0065) teacher/usage_std 0.2568 (0.3270) nleep/row_max_mean 1478.9716 (1497.5458) nleep/row_max_std 82.3781 (61.5164) nleep/row_min_mean 1447.4341 (1464.1590) lr 7.5131e-04 eta 0:04:56
epoch [31/50] batch [160/160] time 0.086 (0.096) data 0.000 (0.002) loss 1.5432 (1.5478) teacher_loss 0.3146 (0.2965) loss_zs_kd 0.0569 (0.0439) loss_oracle 0.5669 (0.5922) kd_loss 0.9167 (0.9333) acc 90.6250 (88.1055) gate/entropy 1.0338 (1.0348) gate/usage_max 0.4418 (0.4473) gate/usage_min 0.1754 (0.1779) gate/usage_std 0.1142 (0.1139) teacher/entropy 0.0123 (0.0134) teacher/usage_max 0.7824 (0.7730) teacher/usage_min 0.0007 (0.0066) teacher/usage_std 0.3296 (0.3261) nleep/row_max_mean 1506.3116 (1497.7156) nleep/row_max_std 30.7179 (60.8212) nleep/row_min_mean 1471.2754 (1464.3536) lr 6.9098e-04 eta 0:04:52
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,839
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,960
* accuracy: 87.7%
* error: 12.3%
* macro_f1: 88.7%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [32/50] batch [20/160] time 0.091 (0.111) data 0.000 (0.019) loss 1.5992 (1.5174) teacher_loss 0.3929 (0.2982) loss_zs_kd 0.0368 (0.0431) loss_oracle 0.5822 (0.5627) kd_loss 0.8968 (0.9164) acc 90.6250 (87.3438) gate/entropy 1.0334 (1.0335) gate/usage_max 0.4406 (0.4411) gate/usage_min 0.1747 (0.1749) gate/usage_std 0.1145 (0.1144) teacher/entropy 0.0717 (0.0260) teacher/usage_max 0.7891 (0.8134) teacher/usage_min 0.0459 (0.0126) teacher/usage_std 0.3259 (0.3470) nleep/row_max_mean 1482.5280 (1497.7240) nleep/row_max_std 80.5580 (59.3839) nleep/row_min_mean 1450.9851 (1465.0749) lr 6.9098e-04 eta 0:05:35
epoch [32/50] batch [40/160] time 0.091 (0.099) data 0.000 (0.010) loss 1.4754 (1.5043) teacher_loss 0.2543 (0.2889) loss_zs_kd 0.0482 (0.0437) loss_oracle 0.5099 (0.5634) kd_loss 0.9421 (0.9118) acc 87.5000 (87.5000) gate/entropy 1.0331 (1.0334) gate/usage_max 0.4397 (0.4406) gate/usage_min 0.1742 (0.1747) gate/usage_std 0.1147 (0.1145) teacher/entropy 0.0093 (0.0209) teacher/usage_max 0.7813 (0.7737) teacher/usage_min 0.0313 (0.0095) teacher/usage_std 0.3231 (0.3271) nleep/row_max_mean 1488.0469 (1496.9061) nleep/row_max_std 73.6594 (60.4706) nleep/row_min_mean 1457.7544 (1464.7780) lr 6.9098e-04 eta 0:04:58
epoch [32/50] batch [60/160] time 0.086 (0.097) data 0.001 (0.006) loss 1.4287 (1.5130) teacher_loss 0.1697 (0.2926) loss_zs_kd 0.0567 (0.0460) loss_oracle 0.6279 (0.5699) kd_loss 0.9167 (0.9125) acc 93.7500 (87.6562) gate/entropy 1.0329 (1.0333) gate/usage_max 0.4387 (0.4401) gate/usage_min 0.1738 (0.1744) gate/usage_std 0.1147 (0.1146) teacher/entropy 0.0001 (0.0176) teacher/usage_max 0.7500 (0.7793) teacher/usage_min 0.0000 (0.0071) teacher/usage_std 0.3118 (0.3300) nleep/row_max_mean 1507.0603 (1496.9762) nleep/row_max_std 29.5031 (60.1731) nleep/row_min_mean 1473.2476 (1464.6363) lr 6.9098e-04 eta 0:04:50
epoch [32/50] batch [80/160] time 0.104 (0.098) data 0.000 (0.005) loss 1.4099 (1.5091) teacher_loss 0.1383 (0.2827) loss_zs_kd 0.0409 (0.0466) loss_oracle 0.6697 (0.5840) kd_loss 0.9163 (0.9111) acc 96.8750 (88.1641) gate/entropy 1.0327 (1.0331) gate/usage_max 0.4378 (0.4396) gate/usage_min 0.1734 (0.1742) gate/usage_std 0.1148 (0.1146) teacher/entropy 0.0134 (0.0168) teacher/usage_max 0.8715 (0.7722) teacher/usage_min 0.0008 (0.0070) teacher/usage_std 0.3841 (0.3262) nleep/row_max_mean 1498.6528 (1496.2988) nleep/row_max_std 56.6333 (61.1215) nleep/row_min_mean 1464.2944 (1463.9129) lr 6.9098e-04 eta 0:04:50
epoch [32/50] batch [100/160] time 0.092 (0.098) data 0.000 (0.004) loss 1.5042 (1.5138) teacher_loss 0.2740 (0.2860) loss_zs_kd 0.0324 (0.0457) loss_oracle 0.6187 (0.5873) kd_loss 0.9047 (0.9113) acc 84.3750 (88.1875) gate/entropy 1.0324 (1.0330) gate/usage_max 0.4368 (0.4392) gate/usage_min 0.1728 (0.1740) gate/usage_std 0.1151 (0.1147) teacher/entropy 0.0157 (0.0163) teacher/usage_max 0.7751 (0.7780) teacher/usage_min 0.0061 (0.0073) teacher/usage_std 0.3242 (0.3292) nleep/row_max_mean 1508.3147 (1496.7535) nleep/row_max_std 43.5938 (60.7827) nleep/row_min_mean 1475.2212 (1464.0996) lr 6.9098e-04 eta 0:04:47
epoch [32/50] batch [120/160] time 0.092 (0.097) data 0.000 (0.003) loss 1.6186 (1.5092) teacher_loss 0.3907 (0.2838) loss_zs_kd 0.0497 (0.0452) loss_oracle 0.6250 (0.5846) kd_loss 0.8905 (0.9105) acc 78.1250 (88.4375) gate/entropy 1.0322 (1.0329) gate/usage_max 0.4359 (0.4387) gate/usage_min 0.1725 (0.1738) gate/usage_std 0.1152 (0.1148) teacher/entropy 0.0212 (0.0155) teacher/usage_max 0.7577 (0.7755) teacher/usage_min 0.0006 (0.0071) teacher/usage_std 0.3158 (0.3279) nleep/row_max_mean 1482.3408 (1496.2968) nleep/row_max_std 72.7098 (61.4360) nleep/row_min_mean 1448.7113 (1463.6196) lr 6.9098e-04 eta 0:04:43
epoch [32/50] batch [140/160] time 0.067 (0.099) data 0.000 (0.003) loss 1.8657 (1.5074) teacher_loss 0.6639 (0.2852) loss_zs_kd 0.0232 (0.0445) loss_oracle 0.5873 (0.5823) kd_loss 0.8965 (0.9087) acc 78.1250 (88.4598) gate/entropy 1.0318 (1.0328) gate/usage_max 0.4349 (0.4383) gate/usage_min 0.1719 (0.1735) gate/usage_std 0.1154 (0.1148) teacher/entropy 0.0194 (0.0157) teacher/usage_max 0.8344 (0.7745) teacher/usage_min 0.0000 (0.0066) teacher/usage_std 0.3607 (0.3272) nleep/row_max_mean 1478.0690 (1496.2078) nleep/row_max_std 93.9515 (61.7944) nleep/row_min_mean 1444.7188 (1463.4328) lr 6.9098e-04 eta 0:04:46
epoch [32/50] batch [160/160] time 0.089 (0.097) data 0.000 (0.003) loss 1.4305 (1.5092) teacher_loss 0.2086 (0.2888) loss_zs_kd 0.0427 (0.0448) loss_oracle 0.6285 (0.5826) kd_loss 0.8862 (0.9067) acc 93.7500 (88.2812) gate/entropy 1.0316 (1.0326) gate/usage_max 0.4344 (0.4378) gate/usage_min 0.1715 (0.1733) gate/usage_std 0.1156 (0.1149) teacher/entropy 0.0221 (0.0160) teacher/usage_max 0.7512 (0.7704) teacher/usage_min 0.0019 (0.0064) teacher/usage_std 0.3119 (0.3251) nleep/row_max_mean 1495.9143 (1496.4455) nleep/row_max_std 69.5923 (60.9339) nleep/row_min_mean 1462.2617 (1463.6865) lr 6.3188e-04 eta 0:04:40
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,837
* accuracy: 83.3%
* error: 16.7%
* macro_f1: 84.9%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.7%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [33/50] batch [20/160] time 0.103 (0.114) data 0.000 (0.016) loss 1.3776 (1.4685) teacher_loss 0.1527 (0.2617) loss_zs_kd 0.0299 (0.0400) loss_oracle 0.6250 (0.5833) kd_loss 0.8975 (0.8951) acc 93.7500 (90.0000) gate/entropy 1.0314 (1.0315) gate/usage_max 0.4338 (0.4342) gate/usage_min 0.1712 (0.1715) gate/usage_std 0.1157 (0.1156) teacher/entropy 0.0015 (0.0119) teacher/usage_max 0.6873 (0.7537) teacher/usage_min 0.0000 (0.0011) teacher/usage_std 0.2809 (0.3160) nleep/row_max_mean 1506.0774 (1499.2741) nleep/row_max_std 62.0467 (55.7349) nleep/row_min_mean 1470.6956 (1466.5625) lr 6.3188e-04 eta 0:05:27
epoch [33/50] batch [40/160] time 0.087 (0.105) data 0.000 (0.008) loss 1.4827 (1.4799) teacher_loss 0.2581 (0.2735) loss_zs_kd 0.0540 (0.0388) loss_oracle 0.6011 (0.5813) kd_loss 0.8970 (0.8964) acc 90.6250 (89.6094) gate/entropy 1.0312 (1.0314) gate/usage_max 0.4332 (0.4338) gate/usage_min 0.1709 (0.1713) gate/usage_std 0.1158 (0.1157) teacher/entropy 0.0033 (0.0118) teacher/usage_max 0.7182 (0.7654) teacher/usage_min 0.0003 (0.0018) teacher/usage_std 0.2953 (0.3228) nleep/row_max_mean 1505.7161 (1500.7206) nleep/row_max_std 61.5625 (54.5299) nleep/row_min_mean 1470.6174 (1467.8253) lr 6.3188e-04 eta 0:04:57
epoch [33/50] batch [60/160] time 0.097 (0.101) data 0.001 (0.006) loss 1.4182 (1.4836) teacher_loss 0.2248 (0.2714) loss_zs_kd 0.0565 (0.0427) loss_oracle 0.5025 (0.5875) kd_loss 0.9138 (0.8971) acc 93.7500 (89.6875) gate/entropy 1.0313 (1.0313) gate/usage_max 0.4326 (0.4335) gate/usage_min 0.1710 (0.1712) gate/usage_std 0.1158 (0.1157) teacher/entropy 0.0003 (0.0119) teacher/usage_max 0.8750 (0.7717) teacher/usage_min 0.0000 (0.0029) teacher/usage_std 0.3864 (0.3257) nleep/row_max_mean 1498.2380 (1500.4506) nleep/row_max_std 46.3884 (55.1521) nleep/row_min_mean 1465.3894 (1467.6105) lr 6.3188e-04 eta 0:04:45
epoch [33/50] batch [80/160] time 0.074 (0.099) data 0.000 (0.004) loss 1.4124 (1.4847) teacher_loss 0.2350 (0.2737) loss_zs_kd 0.0254 (0.0422) loss_oracle 0.5624 (0.5867) kd_loss 0.8835 (0.8965) acc 93.7500 (89.5312) gate/entropy 1.0306 (1.0312) gate/usage_max 0.4320 (0.4332) gate/usage_min 0.1702 (0.1710) gate/usage_std 0.1162 (0.1158) teacher/entropy 0.0036 (0.0122) teacher/usage_max 0.5943 (0.7685) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.2479 (0.3242) nleep/row_max_mean 1491.5529 (1499.4571) nleep/row_max_std 73.3812 (57.1617) nleep/row_min_mean 1460.2242 (1466.6862) lr 6.3188e-04 eta 0:04:38
epoch [33/50] batch [100/160] time 0.090 (0.098) data 0.000 (0.003) loss 1.3249 (1.4905) teacher_loss 0.2027 (0.2855) loss_zs_kd 0.0295 (0.0411) loss_oracle 0.4148 (0.5801) kd_loss 0.9002 (0.8944) acc 96.8750 (88.9688) gate/entropy 1.0307 (1.0311) gate/usage_max 0.4315 (0.4329) gate/usage_min 0.1702 (0.1709) gate/usage_std 0.1161 (0.1159) teacher/entropy 0.0111 (0.0141) teacher/usage_max 0.8742 (0.7727) teacher/usage_min 0.0010 (0.0038) teacher/usage_std 0.3857 (0.3264) nleep/row_max_mean 1499.7124 (1498.6039) nleep/row_max_std 58.9961 (57.8490) nleep/row_min_mean 1469.0880 (1466.0160) lr 6.3188e-04 eta 0:04:32
epoch [33/50] batch [120/160] time 0.088 (0.097) data 0.000 (0.003) loss 1.5904 (1.4899) teacher_loss 0.3788 (0.2865) loss_zs_kd 0.0504 (0.0402) loss_oracle 0.5821 (0.5791) kd_loss 0.8953 (0.8937) acc 87.5000 (88.9062) gate/entropy 1.0302 (1.0310) gate/usage_max 0.4307 (0.4326) gate/usage_min 0.1695 (0.1707) gate/usage_std 0.1165 (0.1159) teacher/entropy 0.0101 (0.0142) teacher/usage_max 0.8419 (0.7735) teacher/usage_min 0.0008 (0.0039) teacher/usage_std 0.3653 (0.3267) nleep/row_max_mean 1498.7012 (1498.2841) nleep/row_max_std 71.0101 (58.7444) nleep/row_min_mean 1464.8589 (1465.7493) lr 6.3188e-04 eta 0:04:28
epoch [33/50] batch [140/160] time 0.093 (0.097) data 0.000 (0.003) loss 1.6587 (1.4862) teacher_loss 0.4489 (0.2843) loss_zs_kd 0.0418 (0.0405) loss_oracle 0.6206 (0.5781) kd_loss 0.8786 (0.8926) acc 87.5000 (88.9955) gate/entropy 1.0303 (1.0309) gate/usage_max 0.4304 (0.4323) gate/usage_min 0.1696 (0.1706) gate/usage_std 0.1164 (0.1160) teacher/entropy 0.0239 (0.0142) teacher/usage_max 0.7763 (0.7698) teacher/usage_min 0.0033 (0.0038) teacher/usage_std 0.3255 (0.3248) nleep/row_max_mean 1481.7837 (1498.5172) nleep/row_max_std 85.1082 (57.9867) nleep/row_min_mean 1450.6375 (1465.9743) lr 6.3188e-04 eta 0:04:25
epoch [33/50] batch [160/160] time 0.091 (0.096) data 0.000 (0.002) loss 1.5318 (1.4869) teacher_loss 0.3183 (0.2865) loss_zs_kd 0.0325 (0.0404) loss_oracle 0.6160 (0.5779) kd_loss 0.8892 (0.8912) acc 90.6250 (88.8477) gate/entropy 1.0300 (1.0309) gate/usage_max 0.4299 (0.4320) gate/usage_min 0.1692 (0.1704) gate/usage_std 0.1166 (0.1161) teacher/entropy 0.0058 (0.0147) teacher/usage_max 0.7173 (0.7685) teacher/usage_min 0.0014 (0.0035) teacher/usage_std 0.2946 (0.3244) nleep/row_max_mean 1518.1307 (1498.4875) nleep/row_max_std 29.7446 (58.1423) nleep/row_min_mean 1483.2064 (1465.9673) lr 5.7422e-04 eta 0:04:22
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,840
* accuracy: 83.4%
* error: 16.6%
* macro_f1: 84.8%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,957
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 88.6%
******* Domain p best val acc:      83.6%, epoch: 21 *******
******* Domain p best val test acc: 87.5%, epoch: 21 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [34/50] batch [20/160] time 0.094 (0.110) data 0.000 (0.014) loss 1.4025 (1.5209) teacher_loss 0.2359 (0.3199) loss_zs_kd 0.0454 (0.0421) loss_oracle 0.5030 (0.5825) kd_loss 0.8923 (0.8886) acc 90.6250 (86.5625) gate/entropy 1.0300 (1.0300) gate/usage_max 0.4295 (0.4297) gate/usage_min 0.1692 (0.1692) gate/usage_std 0.1166 (0.1166) teacher/entropy 0.0004 (0.0131) teacher/usage_max 0.7187 (0.7827) teacher/usage_min 0.0000 (0.0040) teacher/usage_std 0.2957 (0.3318) nleep/row_max_mean 1504.2784 (1500.3676) nleep/row_max_std 56.8420 (60.1376) nleep/row_min_mean 1470.8029 (1467.0594) lr 5.7422e-04 eta 0:04:58
epoch [34/50] batch [40/160] time 0.094 (0.103) data 0.000 (0.007) loss 1.5517 (1.4962) teacher_loss 0.3822 (0.2949) loss_zs_kd 0.0390 (0.0439) loss_oracle 0.5169 (0.5811) kd_loss 0.8915 (0.8888) acc 87.5000 (88.2812) gate/entropy 1.0298 (1.0299) gate/usage_max 0.4291 (0.4295) gate/usage_min 0.1689 (0.1691) gate/usage_std 0.1168 (0.1167) teacher/entropy 0.0112 (0.0113) teacher/usage_max 0.8748 (0.7758) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.3863 (0.3278) nleep/row_max_mean 1502.6926 (1501.2560) nleep/row_max_std 52.0750 (55.9562) nleep/row_min_mean 1469.9431 (1467.6152) lr 5.7422e-04 eta 0:04:34
epoch [34/50] batch [60/160] time 0.097 (0.105) data 0.001 (0.005) loss 1.6567 (1.4850) teacher_loss 0.4464 (0.2835) loss_zs_kd 0.0621 (0.0443) loss_oracle 0.5921 (0.5797) kd_loss 0.8832 (0.8895) acc 81.2500 (88.6979) gate/entropy 1.0296 (1.0298) gate/usage_max 0.4287 (0.4293) gate/usage_min 0.1686 (0.1690) gate/usage_std 0.1169 (0.1167) teacher/entropy 0.0208 (0.0104) teacher/usage_max 0.7711 (0.7866) teacher/usage_min 0.0100 (0.0028) teacher/usage_std 0.3211 (0.3340) nleep/row_max_mean 1489.7406 (1502.0882) nleep/row_max_std 83.2659 (56.0793) nleep/row_min_mean 1456.5679 (1467.9853) lr 5.7422e-04 eta 0:04:40
epoch [34/50] batch [80/160] time 0.092 (0.102) data 0.000 (0.004) loss 1.4893 (1.4798) teacher_loss 0.2592 (0.2794) loss_zs_kd 0.0402 (0.0446) loss_oracle 0.6514 (0.5789) kd_loss 0.8844 (0.8887) acc 87.5000 (88.6719) gate/entropy 1.0295 (1.0298) gate/usage_max 0.4282 (0.4290) gate/usage_min 0.1685 (0.1689) gate/usage_std 0.1170 (0.1168) teacher/entropy 0.0090 (0.0100) teacher/usage_max 0.7490 (0.7777) teacher/usage_min 0.0008 (0.0027) teacher/usage_std 0.3110 (0.3294) nleep/row_max_mean 1478.9817 (1501.8088) nleep/row_max_std 79.9534 (57.0110) nleep/row_min_mean 1447.2926 (1467.7451) lr 5.7422e-04 eta 0:04:29
epoch [34/50] batch [100/160] time 0.096 (0.101) data 0.000 (0.003) loss 1.7019 (1.4855) teacher_loss 0.4575 (0.2863) loss_zs_kd 0.0454 (0.0441) loss_oracle 0.6779 (0.5790) kd_loss 0.8827 (0.8876) acc 90.6250 (88.5000) gate/entropy 1.0293 (1.0297) gate/usage_max 0.4279 (0.4288) gate/usage_min 0.1683 (0.1688) gate/usage_std 0.1171 (0.1169) teacher/entropy 0.0068 (0.0103) teacher/usage_max 0.7175 (0.7764) teacher/usage_min 0.0001 (0.0024) teacher/usage_std 0.2951 (0.3288) nleep/row_max_mean 1494.5054 (1501.9311) nleep/row_max_std 67.3481 (57.1941) nleep/row_min_mean 1459.5342 (1467.9393) lr 5.7422e-04 eta 0:04:24
epoch [34/50] batch [120/160] time 0.095 (0.100) data 0.000 (0.003) loss 1.3738 (1.4806) teacher_loss 0.1866 (0.2851) loss_zs_kd 0.0346 (0.0432) loss_oracle 0.5656 (0.5738) kd_loss 0.8871 (0.8871) acc 93.7500 (88.5677) gate/entropy 1.0292 (1.0296) gate/usage_max 0.4275 (0.4287) gate/usage_min 0.1681 (0.1687) gate/usage_std 0.1172 (0.1169) teacher/entropy 0.0082 (0.0103) teacher/usage_max 0.8111 (0.7753) teacher/usage_min 0.0006 (0.0024) teacher/usage_std 0.3464 (0.3280) nleep/row_max_mean 1484.1841 (1501.5044) nleep/row_max_std 88.1802 (58.8110) nleep/row_min_mean 1450.9838 (1467.6193) lr 5.7422e-04 eta 0:04:20
epoch [34/50] batch [140/160] time 0.089 (0.099) data 0.000 (0.002) loss 1.4756 (1.4827) teacher_loss 0.2554 (0.2871) loss_zs_kd 0.0436 (0.0428) loss_oracle 0.6407 (0.5761) kd_loss 0.8780 (0.8862) acc 87.5000 (88.4598) gate/entropy 1.0289 (1.0295) gate/usage_max 0.4272 (0.4285) gate/usage_min 0.1678 (0.1686) gate/usage_std 0.1174 (0.1170) teacher/entropy 0.0153 (0.0108) teacher/usage_max 0.7485 (0.7738) teacher/usage_min 0.0040 (0.0025) teacher/usage_std 0.3099 (0.3271) nleep/row_max_mean 1489.0140 (1500.3754) nleep/row_max_std 81.2451 (60.0857) nleep/row_min_mean 1455.0547 (1466.6661) lr 5.7422e-04 eta 0:04:15
epoch [34/50] batch [160/160] time 0.082 (0.098) data 0.000 (0.002) loss 1.5070 (1.4788) teacher_loss 0.2880 (0.2824) loss_zs_kd 0.0468 (0.0428) loss_oracle 0.6161 (0.5779) kd_loss 0.8875 (0.8861) acc 87.5000 (88.7109) gate/entropy 1.0289 (1.0295) gate/usage_max 0.4267 (0.4283) gate/usage_min 0.1678 (0.1685) gate/usage_std 0.1174 (0.1170) teacher/entropy 0.0043 (0.0103) teacher/usage_max 0.7803 (0.7753) teacher/usage_min 0.0010 (0.0024) teacher/usage_std 0.3283 (0.3279) nleep/row_max_mean 1498.4288 (1500.0156) nleep/row_max_std 53.6248 (60.0812) nleep/row_min_mean 1464.7563 (1466.2465) lr 5.1825e-04 eta 0:04:10
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,849
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,953
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 88.6%
******* Domain p best val acc:      83.8%, epoch: 34 *******
******* Domain p best val test acc: 87.5%, epoch: 34 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [35/50] batch [20/160] time 0.096 (0.121) data 0.000 (0.017) loss 1.4055 (1.4921) teacher_loss 0.2542 (0.3020) loss_zs_kd 0.0425 (0.0418) loss_oracle 0.5089 (0.5684) kd_loss 0.8756 (0.8850) acc 87.5000 (87.5000) gate/entropy 1.0288 (1.0289) gate/usage_max 0.4265 (0.4267) gate/usage_min 0.1676 (0.1677) gate/usage_std 0.1175 (0.1174) teacher/entropy 0.0129 (0.0104) teacher/usage_max 0.7190 (0.7719) teacher/usage_min 0.0015 (0.0056) teacher/usage_std 0.2954 (0.3256) nleep/row_max_mean 1494.5588 (1497.7775) nleep/row_max_std 62.9622 (61.1164) nleep/row_min_mean 1461.1023 (1464.1678) lr 5.1825e-04 eta 0:05:07
epoch [35/50] batch [40/160] time 0.102 (0.109) data 0.000 (0.009) loss 1.3677 (1.4936) teacher_loss 0.1693 (0.3037) loss_zs_kd 0.0426 (0.0414) loss_oracle 0.5896 (0.5736) kd_loss 0.8822 (0.8824) acc 93.7500 (87.9688) gate/entropy 1.0288 (1.0288) gate/usage_max 0.4264 (0.4265) gate/usage_min 0.1676 (0.1676) gate/usage_std 0.1175 (0.1175) teacher/entropy 0.0003 (0.0117) teacher/usage_max 0.6250 (0.7732) teacher/usage_min 0.0000 (0.0045) teacher/usage_std 0.2568 (0.3266) nleep/row_max_mean 1494.2039 (1497.2323) nleep/row_max_std 53.9662 (59.0330) nleep/row_min_mean 1461.3802 (1463.8670) lr 5.1825e-04 eta 0:04:35
epoch [35/50] batch [60/160] time 0.092 (0.105) data 0.001 (0.006) loss 1.2648 (1.4957) teacher_loss 0.1159 (0.3047) loss_zs_kd 0.0341 (0.0422) loss_oracle 0.5676 (0.5767) kd_loss 0.8480 (0.8817) acc 100.0000 (87.6562) gate/entropy 1.0285 (1.0287) gate/usage_max 0.4260 (0.4264) gate/usage_min 0.1673 (0.1676) gate/usage_std 0.1177 (0.1175) teacher/entropy 0.0434 (0.0126) teacher/usage_max 0.6729 (0.7678) teacher/usage_min 0.0075 (0.0052) teacher/usage_std 0.2718 (0.3234) nleep/row_max_mean 1502.2095 (1496.5886) nleep/row_max_std 52.2481 (59.9393) nleep/row_min_mean 1470.9521 (1463.4902) lr 5.1825e-04 eta 0:04:22
epoch [35/50] batch [80/160] time 0.096 (0.103) data 0.000 (0.004) loss 1.4500 (1.4837) teacher_loss 0.2837 (0.2939) loss_zs_kd 0.0306 (0.0424) loss_oracle 0.5400 (0.5751) kd_loss 0.8810 (0.8811) acc 81.2500 (88.0469) gate/entropy 1.0284 (1.0287) gate/usage_max 0.4257 (0.4263) gate/usage_min 0.1672 (0.1675) gate/usage_std 0.1177 (0.1176) teacher/entropy 0.0148 (0.0130) teacher/usage_max 0.9334 (0.7710) teacher/usage_min 0.0004 (0.0051) teacher/usage_std 0.4252 (0.3255) nleep/row_max_mean 1501.2633 (1496.5699) nleep/row_max_std 43.0266 (58.9396) nleep/row_min_mean 1469.8220 (1463.7221) lr 5.1825e-04 eta 0:04:14
epoch [35/50] batch [100/160] time 0.114 (0.104) data 0.000 (0.004) loss 1.4193 (1.4814) teacher_loss 0.2642 (0.2910) loss_zs_kd 0.0290 (0.0419) loss_oracle 0.5684 (0.5774) kd_loss 0.8564 (0.8807) acc 90.6250 (88.1250) gate/entropy 1.0285 (1.0286) gate/usage_max 0.4255 (0.4261) gate/usage_min 0.1672 (0.1674) gate/usage_std 0.1177 (0.1176) teacher/entropy 0.0399 (0.0136) teacher/usage_max 0.7016 (0.7714) teacher/usage_min 0.0121 (0.0057) teacher/usage_std 0.2834 (0.3253) nleep/row_max_mean 1504.3149 (1496.9242) nleep/row_max_std 29.7720 (58.2186) nleep/row_min_mean 1476.0466 (1464.2805) lr 5.1825e-04 eta 0:04:16
epoch [35/50] batch [120/160] time 0.098 (0.104) data 0.000 (0.003) loss 1.3732 (1.4759) teacher_loss 0.1876 (0.2876) loss_zs_kd 0.0303 (0.0412) loss_oracle 0.6159 (0.5752) kd_loss 0.8624 (0.8801) acc 93.7500 (88.2552) gate/entropy 1.0283 (1.0286) gate/usage_max 0.4252 (0.4260) gate/usage_min 0.1670 (0.1673) gate/usage_std 0.1179 (0.1176) teacher/entropy 0.0436 (0.0139) teacher/usage_max 0.7890 (0.7687) teacher/usage_min 0.0195 (0.0059) teacher/usage_std 0.3298 (0.3239) nleep/row_max_mean 1500.8054 (1497.3274) nleep/row_max_std 48.9975 (57.9409) nleep/row_min_mean 1469.3601 (1464.9781) lr 5.1825e-04 eta 0:04:12
epoch [35/50] batch [140/160] time 0.094 (0.103) data 0.000 (0.003) loss 1.8356 (1.4710) teacher_loss 0.6589 (0.2839) loss_zs_kd 0.0483 (0.0412) loss_oracle 0.5828 (0.5750) kd_loss 0.8612 (0.8789) acc 78.1250 (88.4821) gate/entropy 1.0282 (1.0285) gate/usage_max 0.4250 (0.4259) gate/usage_min 0.1669 (0.1673) gate/usage_std 0.1179 (0.1177) teacher/entropy 0.0426 (0.0156) teacher/usage_max 0.6982 (0.7669) teacher/usage_min 0.0225 (0.0069) teacher/usage_std 0.2785 (0.3226) nleep/row_max_mean 1500.9514 (1497.1348) nleep/row_max_std 43.4800 (58.2166) nleep/row_min_mean 1467.0088 (1464.9538) lr 5.1825e-04 eta 0:04:08
epoch [35/50] batch [160/160] time 0.135 (0.102) data 0.001 (0.002) loss 1.4597 (1.4705) teacher_loss 0.1607 (0.2823) loss_zs_kd 0.0520 (0.0414) loss_oracle 0.7282 (0.5770) kd_loss 0.9088 (0.8790) acc 93.7500 (88.5938) gate/entropy 1.0280 (1.0285) gate/usage_max 0.4247 (0.4257) gate/usage_min 0.1667 (0.1672) gate/usage_std 0.1180 (0.1177) teacher/entropy 0.0085 (0.0156) teacher/usage_max 0.8111 (0.7680) teacher/usage_min 0.0325 (0.0072) teacher/usage_std 0.3416 (0.3231) nleep/row_max_mean 1517.4319 (1497.8289) nleep/row_max_std 29.1780 (57.2071) nleep/row_min_mean 1480.4243 (1465.6456) lr 4.6417e-04 eta 0:04:05
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,847
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,963
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.8%
******* Domain p best val acc:      83.8%, epoch: 34 *******
******* Domain p best val test acc: 87.5%, epoch: 34 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [36/50] batch [20/160] time 0.098 (0.114) data 0.000 (0.017) loss 1.7804 (1.4862) teacher_loss 0.5678 (0.2938) loss_zs_kd 0.0737 (0.0448) loss_oracle 0.5819 (0.5918) kd_loss 0.8848 (0.8741) acc 75.0000 (88.4375) gate/entropy 1.0278 (1.0280) gate/usage_max 0.4244 (0.4246) gate/usage_min 0.1664 (0.1666) gate/usage_std 0.1182 (0.1181) teacher/entropy 0.0003 (0.0217) teacher/usage_max 0.7813 (0.7550) teacher/usage_min 0.0000 (0.0118) teacher/usage_std 0.3291 (0.3150) nleep/row_max_mean 1510.3237 (1499.6905) nleep/row_max_std 46.3379 (56.8054) nleep/row_min_mean 1478.2926 (1468.4162) lr 4.6417e-04 eta 0:04:30
epoch [36/50] batch [40/160] time 0.098 (0.104) data 0.000 (0.008) loss 1.4427 (1.4761) teacher_loss 0.2021 (0.2801) loss_zs_kd 0.0449 (0.0445) loss_oracle 0.6319 (0.5944) kd_loss 0.9022 (0.8766) acc 87.5000 (88.2812) gate/entropy 1.0279 (1.0280) gate/usage_max 0.4244 (0.4245) gate/usage_min 0.1665 (0.1666) gate/usage_std 0.1181 (0.1181) teacher/entropy 0.0103 (0.0181) teacher/usage_max 0.7185 (0.7533) teacher/usage_min 0.0322 (0.0109) teacher/usage_std 0.2864 (0.3140) nleep/row_max_mean 1505.7932 (1497.4789) nleep/row_max_std 45.8095 (61.2428) nleep/row_min_mean 1474.5964 (1466.1304) lr 4.6417e-04 eta 0:04:04
epoch [36/50] batch [60/160] time 0.093 (0.100) data 0.001 (0.006) loss 1.7445 (1.4872) teacher_loss 0.5338 (0.2924) loss_zs_kd 0.0439 (0.0435) loss_oracle 0.6235 (0.5912) kd_loss 0.8770 (0.8774) acc 78.1250 (87.9167) gate/entropy 1.0276 (1.0279) gate/usage_max 0.4241 (0.4244) gate/usage_min 0.1662 (0.1666) gate/usage_std 0.1183 (0.1181) teacher/entropy 0.0072 (0.0183) teacher/usage_max 0.7489 (0.7609) teacher/usage_min 0.0011 (0.0118) teacher/usage_std 0.3109 (0.3178) nleep/row_max_mean 1476.1627 (1497.7794) nleep/row_max_std 94.2308 (60.0817) nleep/row_min_mean 1444.8918 (1466.2136) lr 4.6417e-04 eta 0:03:54
epoch [36/50] batch [80/160] time 0.098 (0.099) data 0.000 (0.004) loss 1.5538 (1.4877) teacher_loss 0.3729 (0.2964) loss_zs_kd 0.0587 (0.0432) loss_oracle 0.5557 (0.5873) kd_loss 0.8737 (0.8760) acc 87.5000 (87.9688) gate/entropy 1.0277 (1.0279) gate/usage_max 0.4240 (0.4243) gate/usage_min 0.1662 (0.1665) gate/usage_std 0.1183 (0.1181) teacher/entropy 0.0168 (0.0193) teacher/usage_max 0.8067 (0.7676) teacher/usage_min 0.0057 (0.0114) teacher/usage_std 0.3429 (0.3215) nleep/row_max_mean 1491.5507 (1496.7099) nleep/row_max_std 82.9616 (61.0936) nleep/row_min_mean 1461.5197 (1465.1515) lr 4.6417e-04 eta 0:03:49
epoch [36/50] batch [100/160] time 0.099 (0.098) data 0.000 (0.004) loss 1.3808 (1.4848) teacher_loss 0.2047 (0.2944) loss_zs_kd 0.0465 (0.0431) loss_oracle 0.5811 (0.5864) kd_loss 0.8624 (0.8756) acc 87.5000 (88.1562) gate/entropy 1.0276 (1.0279) gate/usage_max 0.4238 (0.4242) gate/usage_min 0.1662 (0.1665) gate/usage_std 0.1183 (0.1182) teacher/entropy 0.0208 (0.0190) teacher/usage_max 0.7137 (0.7715) teacher/usage_min 0.0022 (0.0109) teacher/usage_std 0.2926 (0.3236) nleep/row_max_mean 1500.0100 (1496.4762) nleep/row_max_std 67.3841 (61.6277) nleep/row_min_mean 1469.0237 (1464.8960) lr 4.6417e-04 eta 0:03:46
epoch [36/50] batch [120/160] time 0.102 (0.098) data 0.000 (0.003) loss 1.4078 (1.4757) teacher_loss 0.2360 (0.2856) loss_zs_kd 0.0386 (0.0435) loss_oracle 0.5980 (0.5875) kd_loss 0.8535 (0.8747) acc 87.5000 (88.4635) gate/entropy 1.0273 (1.0278) gate/usage_max 0.4236 (0.4241) gate/usage_min 0.1658 (0.1664) gate/usage_std 0.1185 (0.1182) teacher/entropy 0.0249 (0.0200) teacher/usage_max 0.6142 (0.7666) teacher/usage_min 0.0006 (0.0112) teacher/usage_std 0.2532 (0.3210) nleep/row_max_mean 1497.6399 (1496.9120) nleep/row_max_std 70.3150 (60.0175) nleep/row_min_mean 1468.9114 (1465.4013) lr 4.6417e-04 eta 0:03:43
epoch [36/50] batch [140/160] time 0.092 (0.097) data 0.000 (0.003) loss 1.4836 (1.4727) teacher_loss 0.3249 (0.2833) loss_zs_kd 0.0384 (0.0430) loss_oracle 0.5537 (0.5876) kd_loss 0.8627 (0.8740) acc 87.5000 (88.5491) gate/entropy 1.0274 (1.0278) gate/usage_max 0.4232 (0.4240) gate/usage_min 0.1659 (0.1663) gate/usage_std 0.1185 (0.1182) teacher/entropy 0.0363 (0.0213) teacher/usage_max 0.8259 (0.7641) teacher/usage_min 0.0162 (0.0122) teacher/usage_std 0.3531 (0.3194) nleep/row_max_mean 1508.6523 (1497.0329) nleep/row_max_std 42.9161 (59.5470) nleep/row_min_mean 1475.8390 (1465.5527) lr 4.6417e-04 eta 0:03:40
epoch [36/50] batch [160/160] time 0.090 (0.097) data 0.000 (0.002) loss 1.3615 (1.4730) teacher_loss 0.2161 (0.2834) loss_zs_kd 0.0413 (0.0425) loss_oracle 0.4972 (0.5868) kd_loss 0.8761 (0.8749) acc 96.8750 (88.4766) gate/entropy 1.0273 (1.0277) gate/usage_max 0.4231 (0.4239) gate/usage_min 0.1658 (0.1663) gate/usage_std 0.1186 (0.1183) teacher/entropy 0.0066 (0.0208) teacher/usage_max 0.7815 (0.7635) teacher/usage_min 0.0005 (0.0129) teacher/usage_std 0.3291 (0.3189) nleep/row_max_mean 1510.5591 (1497.0280) nleep/row_max_std 47.2854 (59.7161) nleep/row_min_mean 1481.5276 (1465.6824) lr 4.1221e-04 eta 0:03:36
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,848
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,964
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.8%
******* Domain p best val acc:      83.8%, epoch: 34 *******
******* Domain p best val test acc: 87.5%, epoch: 34 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [37/50] batch [20/160] time 0.095 (0.108) data 0.000 (0.016) loss 1.3490 (1.4828) teacher_loss 0.1669 (0.2932) loss_zs_kd 0.0358 (0.0389) loss_oracle 0.5952 (0.5932) kd_loss 0.8665 (0.8735) acc 96.8750 (87.9688) gate/entropy 1.0275 (1.0274) gate/usage_max 0.4230 (0.4231) gate/usage_min 0.1660 (0.1659) gate/usage_std 0.1184 (0.1185) teacher/entropy 0.0204 (0.0328) teacher/usage_max 0.7441 (0.7758) teacher/usage_min 0.0062 (0.0258) teacher/usage_std 0.3070 (0.3230) nleep/row_max_mean 1493.4742 (1497.1920) nleep/row_max_std 53.6728 (60.5747) nleep/row_min_mean 1464.4673 (1466.9528) lr 4.1221e-04 eta 0:04:00
epoch [37/50] batch [40/160] time 0.084 (0.101) data 0.000 (0.008) loss 1.4063 (1.4786) teacher_loss 0.2991 (0.2913) loss_zs_kd 0.0292 (0.0415) loss_oracle 0.5078 (0.5898) kd_loss 0.8387 (0.8717) acc 84.3750 (88.8281) gate/entropy 1.0273 (1.0273) gate/usage_max 0.4229 (0.4230) gate/usage_min 0.1657 (0.1658) gate/usage_std 0.1186 (0.1185) teacher/entropy 0.0525 (0.0311) teacher/usage_max 0.7283 (0.7619) teacher/usage_min 0.0116 (0.0227) teacher/usage_std 0.2971 (0.3154) nleep/row_max_mean 1502.0109 (1497.5356) nleep/row_max_std 44.6182 (59.1606) nleep/row_min_mean 1472.7473 (1467.2955) lr 4.1221e-04 eta 0:03:41
epoch [37/50] batch [60/160] time 0.091 (0.098) data 0.001 (0.005) loss 1.3923 (1.4785) teacher_loss 0.2082 (0.2890) loss_zs_kd 0.0471 (0.0418) loss_oracle 0.5992 (0.5911) kd_loss 0.8609 (0.8731) acc 93.7500 (89.3229) gate/entropy 1.0272 (1.0273) gate/usage_max 0.4227 (0.4229) gate/usage_min 0.1657 (0.1658) gate/usage_std 0.1186 (0.1186) teacher/entropy 0.0231 (0.0294) teacher/usage_max 0.8527 (0.7614) teacher/usage_min 0.0006 (0.0226) teacher/usage_std 0.3721 (0.3152) nleep/row_max_mean 1515.3826 (1497.4774) nleep/row_max_std 27.1660 (58.9728) nleep/row_min_mean 1483.2546 (1467.2632) lr 4.1221e-04 eta 0:03:33
epoch [37/50] batch [80/160] time 0.089 (0.100) data 0.000 (0.004) loss 1.3880 (1.4659) teacher_loss 0.1835 (0.2794) loss_zs_kd 0.0388 (0.0409) loss_oracle 0.6439 (0.5887) kd_loss 0.8631 (0.8717) acc 90.6250 (89.6484) gate/entropy 1.0272 (1.0273) gate/usage_max 0.4227 (0.4228) gate/usage_min 0.1657 (0.1658) gate/usage_std 0.1186 (0.1186) teacher/entropy 0.0707 (0.0306) teacher/usage_max 0.6078 (0.7562) teacher/usage_min 0.0615 (0.0226) teacher/usage_std 0.2230 (0.3129) nleep/row_max_mean 1503.4679 (1497.7161) nleep/row_max_std 45.9876 (58.0504) nleep/row_min_mean 1475.2727 (1467.5230) lr 4.1221e-04 eta 0:03:36
epoch [37/50] batch [100/160] time 0.087 (0.099) data 0.000 (0.003) loss 1.6697 (1.4653) teacher_loss 0.4408 (0.2791) loss_zs_kd 0.0460 (0.0415) loss_oracle 0.6364 (0.5865) kd_loss 0.8877 (0.8722) acc 84.3750 (89.6562) gate/entropy 1.0271 (1.0273) gate/usage_max 0.4225 (0.4228) gate/usage_min 0.1656 (0.1657) gate/usage_std 0.1187 (0.1186) teacher/entropy 0.0352 (0.0307) teacher/usage_max 0.5428 (0.7484) teacher/usage_min 0.0510 (0.0237) teacher/usage_std 0.2073 (0.3086) nleep/row_max_mean 1496.7633 (1497.1949) nleep/row_max_std 58.9013 (58.5465) nleep/row_min_mean 1467.3677 (1467.1691) lr 4.1221e-04 eta 0:03:32
epoch [37/50] batch [120/160] time 0.092 (0.098) data 0.000 (0.003) loss 1.3395 (1.4625) teacher_loss 0.1620 (0.2771) loss_zs_kd 0.0454 (0.0420) loss_oracle 0.5731 (0.5849) kd_loss 0.8683 (0.8719) acc 96.8750 (89.5312) gate/entropy 1.0271 (1.0272) gate/usage_max 0.4224 (0.4227) gate/usage_min 0.1655 (0.1657) gate/usage_std 0.1187 (0.1186) teacher/entropy 0.0140 (0.0320) teacher/usage_max 0.7182 (0.7457) teacher/usage_min 0.0035 (0.0250) teacher/usage_std 0.2944 (0.3066) nleep/row_max_mean 1487.9036 (1496.9857) nleep/row_max_std 76.0252 (59.6270) nleep/row_min_mean 1460.8958 (1467.0337) lr 4.1221e-04 eta 0:03:27
epoch [37/50] batch [140/160] time 0.086 (0.096) data 0.000 (0.003) loss 1.4460 (1.4618) teacher_loss 0.2431 (0.2763) loss_zs_kd 0.0543 (0.0423) loss_oracle 0.6042 (0.5851) kd_loss 0.8737 (0.8717) acc 90.6250 (89.5536) gate/entropy 1.0271 (1.0272) gate/usage_max 0.4222 (0.4226) gate/usage_min 0.1655 (0.1657) gate/usage_std 0.1187 (0.1186) teacher/entropy 0.0348 (0.0316) teacher/usage_max 0.6462 (0.7448) teacher/usage_min 0.0343 (0.0246) teacher/usage_std 0.2500 (0.3063) nleep/row_max_mean 1494.5070 (1496.3325) nleep/row_max_std 60.0962 (60.7804) nleep/row_min_mean 1464.7233 (1466.3481) lr 4.1221e-04 eta 0:03:22
epoch [37/50] batch [160/160] time 0.080 (0.095) data 0.000 (0.002) loss 1.3238 (1.4586) teacher_loss 0.1552 (0.2742) loss_zs_kd 0.0384 (0.0418) loss_oracle 0.5646 (0.5841) kd_loss 0.8671 (0.8715) acc 100.0000 (89.6094) gate/entropy 1.0269 (1.0272) gate/usage_max 0.4221 (0.4226) gate/usage_min 0.1654 (0.1656) gate/usage_std 0.1188 (0.1187) teacher/entropy 0.0109 (0.0310) teacher/usage_max 0.6570 (0.7443) teacher/usage_min 0.0009 (0.0238) teacher/usage_std 0.2679 (0.3061) nleep/row_max_mean 1491.9298 (1496.6271) nleep/row_max_std 67.1589 (60.5328) nleep/row_min_mean 1461.5997 (1466.5859) lr 3.6258e-04 eta 0:03:17
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,843
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,969
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.8%
******* Domain p best val acc:      83.8%, epoch: 34 *******
******* Domain p best val test acc: 87.5%, epoch: 34 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [38/50] batch [20/160] time 0.087 (0.106) data 0.000 (0.014) loss 1.5152 (1.4514) teacher_loss 0.3593 (0.2767) loss_zs_kd 0.0210 (0.0405) loss_oracle 0.5755 (0.5719) kd_loss 0.8577 (0.8686) acc 90.6250 (90.6250) gate/entropy 1.0269 (1.0269) gate/usage_max 0.4220 (0.4220) gate/usage_min 0.1654 (0.1654) gate/usage_std 0.1188 (0.1188) teacher/entropy 0.0605 (0.0300) teacher/usage_max 0.6905 (0.7299) teacher/usage_min 0.0432 (0.0213) teacher/usage_std 0.2685 (0.3004) nleep/row_max_mean 1500.9138 (1493.7086) nleep/row_max_std 57.1882 (66.7354) nleep/row_min_mean 1473.0247 (1463.7178) lr 3.6258e-04 eta 0:03:39
epoch [38/50] batch [40/160] time 0.089 (0.100) data 0.000 (0.007) loss 1.5873 (1.4729) teacher_loss 0.3976 (0.2923) loss_zs_kd 0.0489 (0.0431) loss_oracle 0.5996 (0.5815) kd_loss 0.8655 (0.8684) acc 90.6250 (89.4531) gate/entropy 1.0269 (1.0269) gate/usage_max 0.4219 (0.4220) gate/usage_min 0.1653 (0.1653) gate/usage_std 0.1189 (0.1189) teacher/entropy 0.0140 (0.0305) teacher/usage_max 0.6541 (0.7386) teacher/usage_min 0.0031 (0.0215) teacher/usage_std 0.2658 (0.3048) nleep/row_max_mean 1477.2915 (1494.2911) nleep/row_max_std 97.2640 (65.3545) nleep/row_min_mean 1446.5485 (1464.2749) lr 3.6258e-04 eta 0:03:24
epoch [38/50] batch [60/160] time 0.091 (0.099) data 0.001 (0.005) loss 1.4755 (1.4704) teacher_loss 0.3645 (0.2930) loss_zs_kd 0.0453 (0.0420) loss_oracle 0.5120 (0.5819) kd_loss 0.8323 (0.8655) acc 84.3750 (89.0625) gate/entropy 1.0268 (1.0269) gate/usage_max 0.4217 (0.4219) gate/usage_min 0.1652 (0.1653) gate/usage_std 0.1189 (0.1189) teacher/entropy 0.0489 (0.0320) teacher/usage_max 0.8495 (0.7437) teacher/usage_min 0.0004 (0.0199) teacher/usage_std 0.3701 (0.3074) nleep/row_max_mean 1499.3799 (1495.7968) nleep/row_max_std 45.9870 (62.9233) nleep/row_min_mean 1468.2837 (1465.7776) lr 3.6258e-04 eta 0:03:19
epoch [38/50] batch [80/160] time 0.093 (0.098) data 0.000 (0.004) loss 1.4639 (1.4616) teacher_loss 0.3141 (0.2825) loss_zs_kd 0.0247 (0.0426) loss_oracle 0.4940 (0.5789) kd_loss 0.8904 (0.8683) acc 87.5000 (89.1406) gate/entropy 1.0269 (1.0269) gate/usage_max 0.4217 (0.4219) gate/usage_min 0.1653 (0.1653) gate/usage_std 0.1189 (0.1189) teacher/entropy 0.0145 (0.0312) teacher/usage_max 0.6899 (0.7428) teacher/usage_min 0.0294 (0.0223) teacher/usage_std 0.2722 (0.3059) nleep/row_max_mean 1496.6375 (1496.3500) nleep/row_max_std 56.7984 (62.1149) nleep/row_min_mean 1465.7188 (1466.2393) lr 3.6258e-04 eta 0:03:15
epoch [38/50] batch [100/160] time 0.099 (0.097) data 0.000 (0.003) loss 1.5460 (1.4588) teacher_loss 0.3717 (0.2793) loss_zs_kd 0.0361 (0.0427) loss_oracle 0.5699 (0.5784) kd_loss 0.8713 (0.8690) acc 84.3750 (88.8750) gate/entropy 1.0269 (1.0269) gate/usage_max 0.4215 (0.4218) gate/usage_min 0.1653 (0.1653) gate/usage_std 0.1188 (0.1189) teacher/entropy 0.0305 (0.0309) teacher/usage_max 0.7865 (0.7418) teacher/usage_min 0.0239 (0.0228) teacher/usage_std 0.3275 (0.3050) nleep/row_max_mean 1492.4099 (1496.0609) nleep/row_max_std 62.0654 (62.3440) nleep/row_min_mean 1460.9865 (1465.9838) lr 3.6258e-04 eta 0:03:12
epoch [38/50] batch [120/160] time 0.092 (0.097) data 0.000 (0.003) loss 1.3907 (1.4579) teacher_loss 0.2151 (0.2774) loss_zs_kd 0.0236 (0.0427) loss_oracle 0.5854 (0.5796) kd_loss 0.8711 (0.8694) acc 87.5000 (88.8021) gate/entropy 1.0266 (1.0268) gate/usage_max 0.4215 (0.4218) gate/usage_min 0.1650 (0.1652) gate/usage_std 0.1190 (0.1189) teacher/entropy 0.0062 (0.0320) teacher/usage_max 0.7177 (0.7371) teacher/usage_min 0.0004 (0.0246) teacher/usage_std 0.2951 (0.3022) nleep/row_max_mean 1511.0624 (1495.9766) nleep/row_max_std 43.3167 (61.9828) nleep/row_min_mean 1482.5256 (1466.0090) lr 3.6258e-04 eta 0:03:10
epoch [38/50] batch [140/160] time 0.095 (0.098) data 0.000 (0.002) loss 1.2644 (1.4580) teacher_loss 0.1535 (0.2783) loss_zs_kd 0.0351 (0.0421) loss_oracle 0.5447 (0.5797) kd_loss 0.8210 (0.8687) acc 96.8750 (88.9062) gate/entropy 1.0267 (1.0268) gate/usage_max 0.4213 (0.4217) gate/usage_min 0.1651 (0.1652) gate/usage_std 0.1190 (0.1189) teacher/entropy 0.1010 (0.0326) teacher/usage_max 0.8156 (0.7376) teacher/usage_min 0.0457 (0.0246) teacher/usage_std 0.3431 (0.3024) nleep/row_max_mean 1487.7952 (1495.9531) nleep/row_max_std 73.4662 (62.0563) nleep/row_min_mean 1462.5425 (1466.0202) lr 3.6258e-04 eta 0:03:09
epoch [38/50] batch [160/160] time 0.087 (0.096) data 0.000 (0.002) loss 1.4413 (1.4565) teacher_loss 0.2975 (0.2782) loss_zs_kd 0.0455 (0.0423) loss_oracle 0.5478 (0.5781) kd_loss 0.8471 (0.8681) acc 87.5000 (88.8867) gate/entropy 1.0266 (1.0268) gate/usage_max 0.4212 (0.4217) gate/usage_min 0.1650 (0.1652) gate/usage_std 0.1191 (0.1189) teacher/entropy 0.0660 (0.0326) teacher/usage_max 0.8053 (0.7384) teacher/usage_min 0.0369 (0.0241) teacher/usage_std 0.3373 (0.3029) nleep/row_max_mean 1499.6973 (1495.9822) nleep/row_max_std 46.1674 (61.7539) nleep/row_min_mean 1471.4402 (1466.1663) lr 3.1545e-04 eta 0:03:04
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,825
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 84.7%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,976
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 88.9%
******* Domain p best val acc:      83.8%, epoch: 34 *******
******* Domain p best val test acc: 87.5%, epoch: 34 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [39/50] batch [20/160] time 0.070 (0.100) data 0.000 (0.013) loss 1.7054 (1.4384) teacher_loss 0.5829 (0.2596) loss_zs_kd 0.0332 (0.0365) loss_oracle 0.4925 (0.5715) kd_loss 0.8596 (0.8747) acc 71.8750 (91.5625) gate/entropy 1.0264 (1.0266) gate/usage_max 0.4211 (0.4212) gate/usage_min 0.1647 (0.1650) gate/usage_std 0.1192 (0.1191) teacher/entropy 0.0303 (0.0317) teacher/usage_max 0.8294 (0.7023) teacher/usage_min 0.0124 (0.0318) teacher/usage_std 0.3558 (0.2815) nleep/row_max_mean 1511.4088 (1495.7424) nleep/row_max_std 45.6065 (61.5911) nleep/row_min_mean 1480.9855 (1466.0507) lr 3.1545e-04 eta 0:03:10
epoch [39/50] batch [40/160] time 0.100 (0.096) data 0.000 (0.007) loss 1.4435 (1.4588) teacher_loss 0.3076 (0.2928) loss_zs_kd 0.0228 (0.0355) loss_oracle 0.5369 (0.5666) kd_loss 0.8561 (0.8650) acc 87.5000 (89.4531) gate/entropy 1.0264 (1.0266) gate/usage_max 0.4210 (0.4212) gate/usage_min 0.1648 (0.1650) gate/usage_std 0.1192 (0.1191) teacher/entropy 0.0573 (0.0382) teacher/usage_max 0.8024 (0.7162) teacher/usage_min 0.0380 (0.0282) teacher/usage_std 0.3353 (0.2896) nleep/row_max_mean 1491.2175 (1496.3717) nleep/row_max_std 74.9057 (61.8053) nleep/row_min_mean 1464.5293 (1467.3268) lr 3.1545e-04 eta 0:03:01
epoch [39/50] batch [60/160] time 0.084 (0.093) data 0.001 (0.005) loss 1.4386 (1.4619) teacher_loss 0.2184 (0.2943) loss_zs_kd 0.0527 (0.0379) loss_oracle 0.6064 (0.5670) kd_loss 0.8907 (0.8651) acc 90.6250 (89.0625) gate/entropy 1.0264 (1.0266) gate/usage_max 0.4210 (0.4212) gate/usage_min 0.1648 (0.1649) gate/usage_std 0.1192 (0.1191) teacher/entropy 0.0145 (0.0375) teacher/usage_max 0.7506 (0.7230) teacher/usage_min 0.0303 (0.0276) teacher/usage_std 0.3049 (0.2933) nleep/row_max_mean 1503.5076 (1496.6320) nleep/row_max_std 56.3936 (60.8563) nleep/row_min_mean 1474.7072 (1467.6052) lr 3.1545e-04 eta 0:02:53
epoch [39/50] batch [80/160] time 0.082 (0.091) data 0.000 (0.004) loss 1.2658 (1.4532) teacher_loss 0.1773 (0.2893) loss_zs_kd 0.0332 (0.0376) loss_oracle 0.5455 (0.5659) kd_loss 0.7992 (0.8622) acc 93.7500 (89.0625) gate/entropy 1.0266 (1.0265) gate/usage_max 0.4210 (0.4211) gate/usage_min 0.1649 (0.1649) gate/usage_std 0.1191 (0.1191) teacher/entropy 0.0854 (0.0393) teacher/usage_max 0.6805 (0.7225) teacher/usage_min 0.0094 (0.0264) teacher/usage_std 0.2745 (0.2938) nleep/row_max_mean 1491.7839 (1496.8153) nleep/row_max_std 79.8004 (60.4697) nleep/row_min_mean 1461.5850 (1467.8443) lr 3.1545e-04 eta 0:02:47
epoch [39/50] batch [100/160] time 0.090 (0.091) data 0.000 (0.003) loss 1.3872 (1.4560) teacher_loss 0.2308 (0.2902) loss_zs_kd 0.0344 (0.0380) loss_oracle 0.5102 (0.5668) kd_loss 0.8840 (0.8634) acc 87.5000 (88.7812) gate/entropy 1.0264 (1.0265) gate/usage_max 0.4209 (0.4211) gate/usage_min 0.1647 (0.1649) gate/usage_std 0.1193 (0.1191) teacher/entropy 0.0578 (0.0401) teacher/usage_max 0.7746 (0.7207) teacher/usage_min 0.0690 (0.0287) teacher/usage_std 0.3141 (0.2923) nleep/row_max_mean 1501.4934 (1496.0315) nleep/row_max_std 42.1083 (61.5254) nleep/row_min_mean 1474.4365 (1467.3796) lr 3.1545e-04 eta 0:02:44
epoch [39/50] batch [120/160] time 0.094 (0.092) data 0.000 (0.002) loss 1.4433 (1.4556) teacher_loss 0.2668 (0.2893) loss_zs_kd 0.0414 (0.0386) loss_oracle 0.5944 (0.5668) kd_loss 0.8586 (0.8636) acc 87.5000 (88.9583) gate/entropy 1.0263 (1.0265) gate/usage_max 0.4208 (0.4210) gate/usage_min 0.1647 (0.1649) gate/usage_std 0.1193 (0.1191) teacher/entropy 0.0274 (0.0402) teacher/usage_max 0.8026 (0.7237) teacher/usage_min 0.0096 (0.0291) teacher/usage_std 0.3397 (0.2938) nleep/row_max_mean 1504.3083 (1495.7792) nleep/row_max_std 58.9734 (60.9642) nleep/row_min_mean 1474.2290 (1467.2381) lr 3.1545e-04 eta 0:02:44
epoch [39/50] batch [140/160] time 0.076 (0.091) data 0.000 (0.002) loss 1.4300 (1.4531) teacher_loss 0.2465 (0.2843) loss_zs_kd 0.0431 (0.0390) loss_oracle 0.6185 (0.5698) kd_loss 0.8527 (0.8645) acc 96.8750 (89.2188) gate/entropy 1.0264 (1.0265) gate/usage_max 0.4207 (0.4210) gate/usage_min 0.1648 (0.1649) gate/usage_std 0.1192 (0.1192) teacher/entropy 0.0246 (0.0406) teacher/usage_max 0.7397 (0.7205) teacher/usage_min 0.0007 (0.0305) teacher/usage_std 0.3062 (0.2918) nleep/row_max_mean 1488.8828 (1495.0114) nleep/row_max_std 63.9437 (61.7154) nleep/row_min_mean 1457.9498 (1466.4510) lr 3.1545e-04 eta 0:02:42
epoch [39/50] batch [160/160] time 0.088 (0.091) data 0.000 (0.002) loss 1.3725 (1.4523) teacher_loss 0.2045 (0.2845) loss_zs_kd 0.0373 (0.0393) loss_oracle 0.5994 (0.5696) kd_loss 0.8497 (0.8634) acc 90.6250 (89.0820) gate/entropy 1.0264 (1.0265) gate/usage_max 0.4207 (0.4210) gate/usage_min 0.1648 (0.1649) gate/usage_std 0.1192 (0.1192) teacher/entropy 0.0453 (0.0408) teacher/usage_max 0.6974 (0.7233) teacher/usage_min 0.0208 (0.0295) teacher/usage_std 0.2786 (0.2936) nleep/row_max_mean 1490.1105 (1495.2162) nleep/row_max_std 59.1415 (61.2388) nleep/row_min_mean 1462.4463 (1466.4629) lr 2.7103e-04 eta 0:02:40
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,843
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,973
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 88.9%
******* Domain p best val acc:      83.8%, epoch: 34 *******
******* Domain p best val test acc: 87.5%, epoch: 34 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [40/50] batch [20/160] time 0.098 (0.116) data 0.000 (0.016) loss 1.4812 (1.4467) teacher_loss 0.3153 (0.2730) loss_zs_kd 0.0481 (0.0428) loss_oracle 0.6089 (0.5802) kd_loss 0.8374 (0.8622) acc 84.3750 (89.3750) gate/entropy 1.0263 (1.0263) gate/usage_max 0.4206 (0.4206) gate/usage_min 0.1646 (0.1647) gate/usage_std 0.1193 (0.1193) teacher/entropy 0.0581 (0.0318) teacher/usage_max 0.7908 (0.7508) teacher/usage_min 0.0201 (0.0190) teacher/usage_std 0.3308 (0.3168) nleep/row_max_mean 1460.6254 (1495.1280) nleep/row_max_std 96.5898 (57.7279) nleep/row_min_mean 1434.4070 (1465.1383) lr 2.7103e-04 eta 0:03:22
epoch [40/50] batch [40/160] time 0.100 (0.107) data 0.001 (0.008) loss 1.3561 (1.4451) teacher_loss 0.2042 (0.2685) loss_zs_kd 0.0387 (0.0431) loss_oracle 0.5441 (0.5824) kd_loss 0.8605 (0.8638) acc 87.5000 (88.4375) gate/entropy 1.0263 (1.0263) gate/usage_max 0.4205 (0.4206) gate/usage_min 0.1646 (0.1647) gate/usage_std 0.1193 (0.1193) teacher/entropy 0.0220 (0.0340) teacher/usage_max 0.7746 (0.7256) teacher/usage_min 0.0066 (0.0234) teacher/usage_std 0.3238 (0.2990) nleep/row_max_mean 1483.9335 (1492.8547) nleep/row_max_std 74.3993 (60.8969) nleep/row_min_mean 1456.0942 (1463.1549) lr 2.7103e-04 eta 0:03:04
epoch [40/50] batch [60/160] time 0.098 (0.103) data 0.001 (0.005) loss 1.4783 (1.4556) teacher_loss 0.2948 (0.2808) loss_zs_kd 0.0489 (0.0427) loss_oracle 0.6040 (0.5777) kd_loss 0.8570 (0.8647) acc 87.5000 (88.1771) gate/entropy 1.0263 (1.0263) gate/usage_max 0.4205 (0.4206) gate/usage_min 0.1646 (0.1647) gate/usage_std 0.1193 (0.1193) teacher/entropy 0.0743 (0.0328) teacher/usage_max 0.7091 (0.7402) teacher/usage_min 0.0596 (0.0229) teacher/usage_std 0.2748 (0.3058) nleep/row_max_mean 1485.9258 (1492.0272) nleep/row_max_std 67.8213 (60.6569) nleep/row_min_mean 1456.6855 (1462.1281) lr 2.7103e-04 eta 0:02:55
epoch [40/50] batch [80/160] time 0.092 (0.101) data 0.000 (0.004) loss 1.6083 (1.4650) teacher_loss 0.3289 (0.2860) loss_zs_kd 0.0312 (0.0427) loss_oracle 0.6100 (0.5774) kd_loss 0.9587 (0.8690) acc 87.5000 (88.0078) gate/entropy 1.0262 (1.0263) gate/usage_max 0.4204 (0.4205) gate/usage_min 0.1645 (0.1647) gate/usage_std 0.1194 (0.1193) teacher/entropy 0.0263 (0.0321) teacher/usage_max 0.5963 (0.7406) teacher/usage_min 0.1184 (0.0269) teacher/usage_std 0.1980 (0.3042) nleep/row_max_mean 1489.2410 (1491.9370) nleep/row_max_std 65.7120 (60.2252) nleep/row_min_mean 1458.6838 (1461.8751) lr 2.7103e-04 eta 0:02:49
epoch [40/50] batch [100/160] time 0.092 (0.100) data 0.000 (0.003) loss 1.5415 (1.4578) teacher_loss 0.3412 (0.2791) loss_zs_kd 0.0326 (0.0425) loss_oracle 0.5751 (0.5767) kd_loss 0.8965 (0.8691) acc 87.5000 (88.4688) gate/entropy 1.0263 (1.0263) gate/usage_max 0.4203 (0.4205) gate/usage_min 0.1646 (0.1646) gate/usage_std 0.1193 (0.1193) teacher/entropy 0.0124 (0.0325) teacher/usage_max 0.8726 (0.7403) teacher/usage_min 0.0336 (0.0274) teacher/usage_std 0.3821 (0.3037) nleep/row_max_mean 1492.7185 (1491.9504) nleep/row_max_std 69.3105 (59.9908) nleep/row_min_mean 1463.6694 (1461.9073) lr 2.7103e-04 eta 0:02:45
epoch [40/50] batch [120/160] time 0.083 (0.098) data 0.000 (0.003) loss 1.3422 (1.4580) teacher_loss 0.1303 (0.2785) loss_zs_kd 0.0528 (0.0429) loss_oracle 0.5708 (0.5763) kd_loss 0.9001 (0.8699) acc 96.8750 (88.3854) gate/entropy 1.0261 (1.0263) gate/usage_max 0.4204 (0.4205) gate/usage_min 0.1644 (0.1646) gate/usage_std 0.1194 (0.1193) teacher/entropy 0.0051 (0.0322) teacher/usage_max 0.7492 (0.7392) teacher/usage_min 0.0318 (0.0280) teacher/usage_std 0.3038 (0.3025) nleep/row_max_mean 1512.5886 (1492.1834) nleep/row_max_std 21.8383 (60.0118) nleep/row_min_mean 1482.1619 (1462.0310) lr 2.7103e-04 eta 0:02:41
epoch [40/50] batch [140/160] time 0.089 (0.099) data 0.000 (0.003) loss 1.5319 (1.4612) teacher_loss 0.3375 (0.2792) loss_zs_kd 0.0524 (0.0430) loss_oracle 0.6317 (0.5774) kd_loss 0.8522 (0.8717) acc 81.2500 (88.3705) gate/entropy 1.0261 (1.0263) gate/usage_max 0.4202 (0.4205) gate/usage_min 0.1645 (0.1646) gate/usage_std 0.1194 (0.1193) teacher/entropy 0.0309 (0.0315) teacher/usage_max 0.6742 (0.7344) teacher/usage_min 0.0095 (0.0294) teacher/usage_std 0.2716 (0.3000) nleep/row_max_mean 1513.7847 (1492.0969) nleep/row_max_std 29.5701 (60.2607) nleep/row_min_mean 1480.8336 (1461.9662) lr 2.7103e-04 eta 0:02:41
epoch [40/50] batch [160/160] time 0.082 (0.098) data 0.000 (0.002) loss 1.3810 (1.4598) teacher_loss 0.2336 (0.2783) loss_zs_kd 0.0204 (0.0430) loss_oracle 0.6177 (0.5795) kd_loss 0.8283 (0.8703) acc 87.5000 (88.4961) gate/entropy 1.0261 (1.0263) gate/usage_max 0.4202 (0.4204) gate/usage_min 0.1644 (0.1646) gate/usage_std 0.1194 (0.1193) teacher/entropy 0.0533 (0.0326) teacher/usage_max 0.8241 (0.7349) teacher/usage_min 0.0056 (0.0289) teacher/usage_std 0.3535 (0.3005) nleep/row_max_mean 1495.3920 (1492.2284) nleep/row_max_std 56.0342 (59.8441) nleep/row_min_mean 1468.7948 (1462.1687) lr 2.2949e-04 eta 0:02:36
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.3%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,974
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 88.9%
******* Domain p best val acc:      83.8%, epoch: 34 *******
******* Domain p best val test acc: 87.5%, epoch: 34 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [41/50] batch [20/160] time 0.076 (0.112) data 0.000 (0.017) loss 1.8199 (1.4885) teacher_loss 0.6356 (0.2950) loss_zs_kd 0.0472 (0.0455) loss_oracle 0.5996 (0.5770) kd_loss 0.8609 (0.8822) acc 75.0000 (88.5938) gate/entropy 1.0262 (1.0262) gate/usage_max 0.4201 (0.4201) gate/usage_min 0.1645 (0.1645) gate/usage_std 0.1194 (0.1194) teacher/entropy 0.0263 (0.0411) teacher/usage_max 0.7807 (0.7225) teacher/usage_min 0.0123 (0.0516) teacher/usage_std 0.3262 (0.2878) nleep/row_max_mean 1471.9010 (1492.7270) nleep/row_max_std 86.5195 (52.1632) nleep/row_min_mean 1442.5789 (1463.4030) lr 2.2949e-04 eta 0:02:56
epoch [41/50] batch [40/160] time 0.086 (0.100) data 0.000 (0.008) loss 1.6683 (1.4745) teacher_loss 0.4043 (0.2798) loss_zs_kd 0.0554 (0.0454) loss_oracle 0.5640 (0.5812) kd_loss 0.9543 (0.8814) acc 81.2500 (89.2969) gate/entropy 1.0260 (1.0261) gate/usage_max 0.4201 (0.4201) gate/usage_min 0.1643 (0.1645) gate/usage_std 0.1195 (0.1194) teacher/entropy 0.0235 (0.0370) teacher/usage_max 0.7335 (0.7070) teacher/usage_min 0.1102 (0.0466) teacher/usage_std 0.2836 (0.2810) nleep/row_max_mean 1507.3987 (1493.2178) nleep/row_max_std 23.6114 (53.5229) nleep/row_min_mean 1477.5480 (1463.5038) lr 2.2949e-04 eta 0:02:36
epoch [41/50] batch [60/160] time 0.099 (0.098) data 0.001 (0.006) loss 1.4488 (1.4586) teacher_loss 0.2958 (0.2678) loss_zs_kd 0.0561 (0.0449) loss_oracle 0.5182 (0.5810) kd_loss 0.8659 (0.8778) acc 90.6250 (90.2083) gate/entropy 1.0260 (1.0261) gate/usage_max 0.4201 (0.4201) gate/usage_min 0.1643 (0.1645) gate/usage_std 0.1195 (0.1194) teacher/entropy 0.0477 (0.0394) teacher/usage_max 0.6746 (0.7099) teacher/usage_min 0.0418 (0.0453) teacher/usage_std 0.2607 (0.2829) nleep/row_max_mean 1482.0417 (1491.7113) nleep/row_max_std 75.4352 (56.8141) nleep/row_min_mean 1453.4221 (1462.4289) lr 2.2949e-04 eta 0:02:31
epoch [41/50] batch [80/160] time 0.091 (0.098) data 0.000 (0.004) loss 1.3119 (1.4666) teacher_loss 0.1265 (0.2776) loss_zs_kd 0.0248 (0.0444) loss_oracle 0.5351 (0.5819) kd_loss 0.9055 (0.8758) acc 96.8750 (89.4141) gate/entropy 1.0261 (1.0261) gate/usage_max 0.4199 (0.4201) gate/usage_min 0.1644 (0.1644) gate/usage_std 0.1195 (0.1194) teacher/entropy 0.0328 (0.0400) teacher/usage_max 0.7173 (0.7134) teacher/usage_min 0.0680 (0.0438) teacher/usage_std 0.2780 (0.2848) nleep/row_max_mean 1498.3579 (1492.0112) nleep/row_max_std 49.7133 (57.0990) nleep/row_min_mean 1470.6094 (1462.6906) lr 2.2949e-04 eta 0:02:29
epoch [41/50] batch [100/160] time 0.099 (0.098) data 0.000 (0.004) loss 1.6445 (1.4666) teacher_loss 0.4561 (0.2810) loss_zs_kd 0.0512 (0.0447) loss_oracle 0.5674 (0.5807) kd_loss 0.8791 (0.8728) acc 81.2500 (88.9062) gate/entropy 1.0260 (1.0261) gate/usage_max 0.4199 (0.4201) gate/usage_min 0.1643 (0.1644) gate/usage_std 0.1196 (0.1194) teacher/entropy 0.0297 (0.0406) teacher/usage_max 0.8386 (0.7209) teacher/usage_min 0.0352 (0.0412) teacher/usage_std 0.3592 (0.2894) nleep/row_max_mean 1492.3860 (1491.9736) nleep/row_max_std 66.8855 (56.7028) nleep/row_min_mean 1461.2854 (1462.6996) lr 2.2949e-04 eta 0:02:27
epoch [41/50] batch [120/160] time 0.110 (0.098) data 0.001 (0.003) loss 1.3527 (1.4572) teacher_loss 0.2512 (0.2734) loss_zs_kd 0.0400 (0.0448) loss_oracle 0.5154 (0.5789) kd_loss 0.8238 (0.8720) acc 84.3750 (89.1667) gate/entropy 1.0260 (1.0261) gate/usage_max 0.4198 (0.4200) gate/usage_min 0.1643 (0.1644) gate/usage_std 0.1195 (0.1194) teacher/entropy 0.0784 (0.0409) teacher/usage_max 0.7108 (0.7230) teacher/usage_min 0.0298 (0.0407) teacher/usage_std 0.2829 (0.2905) nleep/row_max_mean 1491.2460 (1492.4007) nleep/row_max_std 54.3787 (56.3663) nleep/row_min_mean 1463.1932 (1463.0907) lr 2.2949e-04 eta 0:02:25
epoch [41/50] batch [140/160] time 0.101 (0.099) data 0.000 (0.003) loss 1.2700 (1.4559) teacher_loss 0.1207 (0.2733) loss_zs_kd 0.0333 (0.0446) loss_oracle 0.5383 (0.5776) kd_loss 0.8635 (0.8714) acc 93.7500 (89.0625) gate/entropy 1.0260 (1.0261) gate/usage_max 0.4198 (0.4200) gate/usage_min 0.1644 (0.1644) gate/usage_std 0.1195 (0.1195) teacher/entropy 0.0140 (0.0414) teacher/usage_max 0.7469 (0.7211) teacher/usage_min 0.0027 (0.0407) teacher/usage_std 0.3094 (0.2895) nleep/row_max_mean 1492.2351 (1491.9820) nleep/row_max_std 59.9314 (57.4658) nleep/row_min_mean 1463.7065 (1462.7746) lr 2.2949e-04 eta 0:02:23
epoch [41/50] batch [160/160] time 0.107 (0.098) data 0.000 (0.002) loss 1.3950 (1.4488) teacher_loss 0.1792 (0.2665) loss_zs_kd 0.0431 (0.0442) loss_oracle 0.5260 (0.5753) kd_loss 0.9312 (0.8725) acc 90.6250 (89.3750) gate/entropy 1.0260 (1.0261) gate/usage_max 0.4197 (0.4200) gate/usage_min 0.1643 (0.1644) gate/usage_std 0.1195 (0.1195) teacher/entropy 0.0032 (0.0415) teacher/usage_max 0.8435 (0.7219) teacher/usage_min 0.0627 (0.0421) teacher/usage_std 0.3609 (0.2897) nleep/row_max_mean 1484.8271 (1491.8997) nleep/row_max_std 71.6191 (58.1192) nleep/row_min_mean 1456.5297 (1462.7390) lr 1.9098e-04 eta 0:02:21
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,836
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 85.1%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,966
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.7%
******* Domain p best val acc:      83.8%, epoch: 34 *******
******* Domain p best val test acc: 87.5%, epoch: 34 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [42/50] batch [20/160] time 0.079 (0.104) data 0.000 (0.019) loss 1.4978 (1.4182) teacher_loss 0.2766 (0.2384) loss_zs_kd 0.0242 (0.0450) loss_oracle 0.5959 (0.5711) kd_loss 0.9111 (0.8718) acc 84.3750 (90.3125) gate/entropy 1.0260 (1.0259) gate/usage_max 0.4197 (0.4198) gate/usage_min 0.1643 (0.1642) gate/usage_std 0.1195 (0.1196) teacher/entropy 0.0219 (0.0358) teacher/usage_max 0.7390 (0.7132) teacher/usage_min 0.0626 (0.0358) teacher/usage_std 0.2922 (0.2856) nleep/row_max_mean 1506.5879 (1496.6100) nleep/row_max_std 26.4734 (53.4744) nleep/row_min_mean 1474.1312 (1466.8967) lr 1.9098e-04 eta 0:02:27
epoch [42/50] batch [40/160] time 0.066 (0.102) data 0.000 (0.010) loss 1.4703 (1.4462) teacher_loss 0.3467 (0.2561) loss_zs_kd 0.0163 (0.0469) loss_oracle 0.5110 (0.5820) kd_loss 0.8600 (0.8757) acc 90.6250 (89.6875) gate/entropy 1.0261 (1.0260) gate/usage_max 0.4197 (0.4198) gate/usage_min 0.1644 (0.1643) gate/usage_std 0.1194 (0.1196) teacher/entropy 0.0187 (0.0389) teacher/usage_max 0.7771 (0.7105) teacher/usage_min 0.0039 (0.0432) teacher/usage_std 0.3258 (0.2834) nleep/row_max_mean 1474.7561 (1495.3318) nleep/row_max_std 84.6186 (53.6627) nleep/row_min_mean 1447.2268 (1465.6167) lr 1.9098e-04 eta 0:02:23
epoch [42/50] batch [60/160] time 0.075 (0.094) data 0.001 (0.006) loss 1.4668 (1.4536) teacher_loss 0.3165 (0.2670) loss_zs_kd 0.0398 (0.0469) loss_oracle 0.6279 (0.5766) kd_loss 0.8165 (0.8748) acc 84.3750 (89.3229) gate/entropy 1.0260 (1.0260) gate/usage_max 0.4197 (0.4197) gate/usage_min 0.1644 (0.1643) gate/usage_std 0.1195 (0.1196) teacher/entropy 0.0845 (0.0406) teacher/usage_max 0.6928 (0.7095) teacher/usage_min 0.0287 (0.0441) teacher/usage_std 0.2739 (0.2821) nleep/row_max_mean 1498.0291 (1493.7805) nleep/row_max_std 55.5409 (55.2979) nleep/row_min_mean 1468.6431 (1464.4551) lr 1.9098e-04 eta 0:02:09
epoch [42/50] batch [80/160] time 0.088 (0.091) data 0.000 (0.005) loss 1.4961 (1.4620) teacher_loss 0.3032 (0.2783) loss_zs_kd 0.0487 (0.0461) loss_oracle 0.5823 (0.5746) kd_loss 0.8774 (0.8733) acc 84.3750 (89.2188) gate/entropy 1.0260 (1.0260) gate/usage_max 0.4197 (0.4197) gate/usage_min 0.1643 (0.1643) gate/usage_std 0.1195 (0.1196) teacher/entropy 0.0662 (0.0427) teacher/usage_max 0.6741 (0.7140) teacher/usage_min 0.0742 (0.0448) teacher/usage_std 0.2516 (0.2842) nleep/row_max_mean 1490.0133 (1492.8205) nleep/row_max_std 41.4341 (56.8251) nleep/row_min_mean 1459.2869 (1463.7252) lr 1.9098e-04 eta 0:02:03
epoch [42/50] batch [100/160] time 0.076 (0.089) data 0.000 (0.004) loss 1.4601 (1.4576) teacher_loss 0.2710 (0.2727) loss_zs_kd 0.0412 (0.0449) loss_oracle 0.6205 (0.5749) kd_loss 0.8582 (0.8750) acc 87.5000 (89.4062) gate/entropy 1.0258 (1.0259) gate/usage_max 0.4196 (0.4197) gate/usage_min 0.1641 (0.1643) gate/usage_std 0.1197 (0.1196) teacher/entropy 0.0482 (0.0444) teacher/usage_max 0.7401 (0.7119) teacher/usage_min 0.0347 (0.0484) teacher/usage_std 0.2980 (0.2823) nleep/row_max_mean 1493.2103 (1493.0381) nleep/row_max_std 65.2893 (56.4222) nleep/row_min_mean 1463.8845 (1464.0878) lr 1.9098e-04 eta 0:01:59
epoch [42/50] batch [120/160] time 0.091 (0.089) data 0.000 (0.003) loss 1.4086 (1.4587) teacher_loss 0.2453 (0.2751) loss_zs_kd 0.0368 (0.0447) loss_oracle 0.5555 (0.5723) kd_loss 0.8672 (0.8751) acc 90.6250 (88.9844) gate/entropy 1.0259 (1.0259) gate/usage_max 0.4195 (0.4197) gate/usage_min 0.1642 (0.1643) gate/usage_std 0.1196 (0.1196) teacher/entropy 0.0304 (0.0434) teacher/usage_max 0.6619 (0.7080) teacher/usage_min 0.0256 (0.0475) teacher/usage_std 0.2602 (0.2806) nleep/row_max_mean 1478.3756 (1491.9399) nleep/row_max_std 78.7831 (57.7046) nleep/row_min_mean 1450.6704 (1463.0420) lr 1.9098e-04 eta 0:01:57
epoch [42/50] batch [140/160] time 0.086 (0.088) data 0.000 (0.003) loss 1.4376 (1.4596) teacher_loss 0.1932 (0.2761) loss_zs_kd 0.0457 (0.0448) loss_oracle 0.6404 (0.5728) kd_loss 0.9014 (0.8747) acc 90.6250 (89.1741) gate/entropy 1.0257 (1.0259) gate/usage_max 0.4196 (0.4197) gate/usage_min 0.1640 (0.1642) gate/usage_std 0.1197 (0.1196) teacher/entropy 0.0023 (0.0428) teacher/usage_max 0.7810 (0.7124) teacher/usage_min 0.0314 (0.0465) teacher/usage_std 0.3229 (0.2833) nleep/row_max_mean 1508.1556 (1492.2893) nleep/row_max_std 42.5535 (57.4350) nleep/row_min_mean 1475.6219 (1463.3110) lr 1.9098e-04 eta 0:01:54
epoch [42/50] batch [160/160] time 0.083 (0.087) data 0.000 (0.003) loss 1.4704 (1.4632) teacher_loss 0.3051 (0.2795) loss_zs_kd 0.0442 (0.0449) loss_oracle 0.5604 (0.5727) kd_loss 0.8630 (0.8749) acc 84.3750 (88.9258) gate/entropy 1.0259 (1.0259) gate/usage_max 0.4194 (0.4196) gate/usage_min 0.1643 (0.1642) gate/usage_std 0.1196 (0.1196) teacher/entropy 0.0159 (0.0423) teacher/usage_max 0.8402 (0.7119) teacher/usage_min 0.0042 (0.0462) teacher/usage_std 0.3637 (0.2829) nleep/row_max_mean 1495.0549 (1492.3315) nleep/row_max_std 46.4576 (57.8153) nleep/row_min_mean 1465.5970 (1463.2844) lr 1.5567e-04 eta 0:01:51
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,834
* accuracy: 83.1%
* error: 16.9%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,967
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.7%
******* Domain p best val acc:      83.8%, epoch: 34 *******
******* Domain p best val test acc: 87.5%, epoch: 34 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [43/50] batch [20/160] time 0.099 (0.119) data 0.000 (0.017) loss 1.3684 (1.5066) teacher_loss 0.1701 (0.3256) loss_zs_kd 0.0316 (0.0476) loss_oracle 0.6171 (0.5874) kd_loss 0.8740 (0.8635) acc 93.7500 (85.7812) gate/entropy 1.0258 (1.0259) gate/usage_max 0.4195 (0.4195) gate/usage_min 0.1641 (0.1642) gate/usage_std 0.1197 (0.1196) teacher/entropy 0.0478 (0.0452) teacher/usage_max 0.6961 (0.7266) teacher/usage_min 0.0518 (0.0373) teacher/usage_std 0.2692 (0.2948) nleep/row_max_mean 1502.5139 (1489.7447) nleep/row_max_std 56.3791 (62.3068) nleep/row_min_mean 1471.4113 (1459.9547) lr 1.5567e-04 eta 0:02:30
epoch [43/50] batch [40/160] time 0.086 (0.105) data 0.000 (0.009) loss 1.4923 (1.4798) teacher_loss 0.3034 (0.3015) loss_zs_kd 0.0689 (0.0478) loss_oracle 0.6281 (0.5841) kd_loss 0.8405 (0.8624) acc 87.5000 (88.5156) gate/entropy 1.0258 (1.0259) gate/usage_max 0.4194 (0.4195) gate/usage_min 0.1641 (0.1642) gate/usage_std 0.1197 (0.1196) teacher/entropy 0.0357 (0.0475) teacher/usage_max 0.6637 (0.7225) teacher/usage_min 0.0033 (0.0383) teacher/usage_std 0.2696 (0.2921) nleep/row_max_mean 1502.0173 (1489.3973) nleep/row_max_std 46.9101 (62.3845) nleep/row_min_mean 1469.3484 (1459.8973) lr 1.5567e-04 eta 0:02:09
epoch [43/50] batch [60/160] time 0.080 (0.100) data 0.001 (0.006) loss 1.3922 (1.4598) teacher_loss 0.2077 (0.2821) loss_zs_kd 0.0490 (0.0465) loss_oracle 0.5861 (0.5817) kd_loss 0.8669 (0.8636) acc 93.7500 (89.1667) gate/entropy 1.0259 (1.0259) gate/usage_max 0.4194 (0.4194) gate/usage_min 0.1642 (0.1642) gate/usage_std 0.1196 (0.1196) teacher/entropy 0.0482 (0.0426) teacher/usage_max 0.7373 (0.7245) teacher/usage_min 0.0440 (0.0344) teacher/usage_std 0.2944 (0.2936) nleep/row_max_mean 1485.1184 (1490.1291) nleep/row_max_std 72.8799 (61.7818) nleep/row_min_mean 1455.0610 (1460.7812) lr 1.5567e-04 eta 0:02:01
epoch [43/50] batch [80/160] time 0.079 (0.098) data 0.000 (0.004) loss 1.5235 (1.4559) teacher_loss 0.3513 (0.2804) loss_zs_kd 0.0532 (0.0454) loss_oracle 0.5893 (0.5789) kd_loss 0.8510 (0.8633) acc 81.2500 (88.7109) gate/entropy 1.0257 (1.0258) gate/usage_max 0.4194 (0.4194) gate/usage_min 0.1639 (0.1642) gate/usage_std 0.1198 (0.1196) teacher/entropy 0.0223 (0.0394) teacher/usage_max 0.7035 (0.7199) teacher/usage_min 0.0001 (0.0310) teacher/usage_std 0.2883 (0.2918) nleep/row_max_mean 1503.5609 (1489.7888) nleep/row_max_std 43.4907 (61.5386) nleep/row_min_mean 1473.2434 (1460.2372) lr 1.5567e-04 eta 0:01:57
epoch [43/50] batch [100/160] time 0.098 (0.098) data 0.000 (0.004) loss 1.6503 (1.4517) teacher_loss 0.4972 (0.2754) loss_zs_kd 0.0353 (0.0448) loss_oracle 0.5565 (0.5824) kd_loss 0.8573 (0.8626) acc 81.2500 (89.0938) gate/entropy 1.0258 (1.0258) gate/usage_max 0.4193 (0.4194) gate/usage_min 0.1641 (0.1642) gate/usage_std 0.1197 (0.1196) teacher/entropy 0.0372 (0.0405) teacher/usage_max 0.8812 (0.7188) teacher/usage_min 0.0212 (0.0314) teacher/usage_std 0.3887 (0.2908) nleep/row_max_mean 1498.8258 (1489.9964) nleep/row_max_std 45.9255 (61.4515) nleep/row_min_mean 1471.5601 (1460.3009) lr 1.5567e-04 eta 0:01:55
epoch [43/50] batch [120/160] time 0.094 (0.098) data 0.000 (0.003) loss 1.4187 (1.4490) teacher_loss 0.2513 (0.2750) loss_zs_kd 0.0289 (0.0443) loss_oracle 0.5379 (0.5795) kd_loss 0.8840 (0.8621) acc 84.3750 (89.1667) gate/entropy 1.0257 (1.0258) gate/usage_max 0.4193 (0.4194) gate/usage_min 0.1640 (0.1641) gate/usage_std 0.1197 (0.1196) teacher/entropy 0.0229 (0.0398) teacher/usage_max 0.6506 (0.7259) teacher/usage_min 0.0364 (0.0301) teacher/usage_std 0.2512 (0.2949) nleep/row_max_mean 1483.0138 (1491.2500) nleep/row_max_std 76.0661 (59.8754) nleep/row_min_mean 1454.4536 (1461.4391) lr 1.5567e-04 eta 0:01:53
epoch [43/50] batch [140/160] time 0.089 (0.098) data 0.000 (0.003) loss 1.3849 (1.4487) teacher_loss 0.1818 (0.2742) loss_zs_kd 0.0529 (0.0443) loss_oracle 0.5184 (0.5788) kd_loss 0.9175 (0.8630) acc 93.7500 (89.2634) gate/entropy 1.0257 (1.0258) gate/usage_max 0.4193 (0.4194) gate/usage_min 0.1640 (0.1641) gate/usage_std 0.1197 (0.1196) teacher/entropy 0.0142 (0.0387) teacher/usage_max 0.6564 (0.7257) teacher/usage_min 0.0633 (0.0299) teacher/usage_std 0.2450 (0.2947) nleep/row_max_mean 1494.0151 (1492.0611) nleep/row_max_std 68.0727 (59.1643) nleep/row_min_mean 1466.4215 (1462.0367) lr 1.5567e-04 eta 0:01:51
epoch [43/50] batch [160/160] time 0.087 (0.097) data 0.000 (0.002) loss 1.3649 (1.4479) teacher_loss 0.1478 (0.2739) loss_zs_kd 0.0762 (0.0447) loss_oracle 0.5978 (0.5771) kd_loss 0.8801 (0.8632) acc 96.8750 (89.0430) gate/entropy 1.0257 (1.0258) gate/usage_max 0.4193 (0.4194) gate/usage_min 0.1640 (0.1641) gate/usage_std 0.1197 (0.1197) teacher/entropy 0.0939 (0.0383) teacher/usage_max 0.6729 (0.7296) teacher/usage_min 0.1076 (0.0297) teacher/usage_std 0.2444 (0.2970) nleep/row_max_mean 1506.5522 (1492.4265) nleep/row_max_std 28.0202 (58.2341) nleep/row_min_mean 1477.7583 (1462.4068) lr 1.2369e-04 eta 0:01:48
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,851
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 85.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,966
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.7%
******* Domain p best val acc:      83.9%, epoch: 43 *******
******* Domain p best val test acc: 87.9%, epoch: 43 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [44/50] batch [20/160] time 0.090 (0.087) data 0.000 (0.015) loss 1.4137 (1.4169) teacher_loss 0.2684 (0.2539) loss_zs_kd 0.0313 (0.0467) loss_oracle 0.5339 (0.5728) kd_loss 0.8627 (0.8532) acc 90.6250 (90.1562) gate/entropy 1.0257 (1.0258) gate/usage_max 0.4191 (0.4192) gate/usage_min 0.1640 (0.1641) gate/usage_std 0.1198 (0.1197) teacher/entropy 0.0347 (0.0431) teacher/usage_max 0.7899 (0.7292) teacher/usage_min 0.0256 (0.0246) teacher/usage_std 0.3293 (0.2991) nleep/row_max_mean 1504.5581 (1493.0882) nleep/row_max_std 44.3820 (58.1696) nleep/row_min_mean 1475.5422 (1463.7213) lr 1.2369e-04 eta 0:01:35
epoch [44/50] batch [40/160] time 0.083 (0.087) data 0.000 (0.007) loss 1.4208 (1.4329) teacher_loss 0.2675 (0.2669) loss_zs_kd 0.0394 (0.0441) loss_oracle 0.5202 (0.5757) kd_loss 0.8735 (0.8560) acc 90.6250 (89.3750) gate/entropy 1.0258 (1.0258) gate/usage_max 0.4192 (0.4192) gate/usage_min 0.1641 (0.1641) gate/usage_std 0.1197 (0.1197) teacher/entropy 0.0198 (0.0414) teacher/usage_max 0.7284 (0.7216) teacher/usage_min 0.0216 (0.0249) teacher/usage_std 0.2945 (0.2947) nleep/row_max_mean 1503.6304 (1493.3934) nleep/row_max_std 46.4210 (57.9305) nleep/row_min_mean 1472.6250 (1463.9661) lr 1.2369e-04 eta 0:01:33
epoch [44/50] batch [60/160] time 0.089 (0.087) data 0.001 (0.005) loss 1.5060 (1.4376) teacher_loss 0.3856 (0.2724) loss_zs_kd 0.0302 (0.0438) loss_oracle 0.5183 (0.5691) kd_loss 0.8462 (0.8587) acc 84.3750 (89.0625) gate/entropy 1.0257 (1.0258) gate/usage_max 0.4192 (0.4192) gate/usage_min 0.1640 (0.1641) gate/usage_std 0.1197 (0.1197) teacher/entropy 0.0373 (0.0387) teacher/usage_max 0.7345 (0.7248) teacher/usage_min 0.0109 (0.0252) teacher/usage_std 0.3006 (0.2959) nleep/row_max_mean 1497.9891 (1492.4857) nleep/row_max_std 55.1219 (59.7407) nleep/row_min_mean 1470.0491 (1462.9471) lr 1.2369e-04 eta 0:01:32
epoch [44/50] batch [80/160] time 0.081 (0.087) data 0.000 (0.004) loss 1.2971 (1.4465) teacher_loss 0.1588 (0.2780) loss_zs_kd 0.0194 (0.0443) loss_oracle 0.4975 (0.5713) kd_loss 0.8799 (0.8607) acc 93.7500 (88.8672) gate/entropy 1.0256 (1.0258) gate/usage_max 0.4191 (0.4192) gate/usage_min 0.1639 (0.1640) gate/usage_std 0.1198 (0.1197) teacher/entropy 0.0177 (0.0389) teacher/usage_max 0.7865 (0.7231) teacher/usage_min 0.0259 (0.0277) teacher/usage_std 0.3272 (0.2940) nleep/row_max_mean 1511.4814 (1492.4753) nleep/row_max_std 55.7862 (59.6996) nleep/row_min_mean 1479.6643 (1463.0119) lr 1.2369e-04 eta 0:01:30
epoch [44/50] batch [100/160] time 0.083 (0.088) data 0.000 (0.003) loss 1.4314 (1.4448) teacher_loss 0.2698 (0.2753) loss_zs_kd 0.0488 (0.0440) loss_oracle 0.5558 (0.5722) kd_loss 0.8593 (0.8614) acc 84.3750 (88.9375) gate/entropy 1.0258 (1.0257) gate/usage_max 0.4192 (0.4192) gate/usage_min 0.1641 (0.1640) gate/usage_std 0.1196 (0.1197) teacher/entropy 0.0287 (0.0383) teacher/usage_max 0.7029 (0.7209) teacher/usage_min 0.0157 (0.0279) teacher/usage_std 0.2829 (0.2930) nleep/row_max_mean 1485.2483 (1491.8260) nleep/row_max_std 54.6990 (61.3589) nleep/row_min_mean 1458.6519 (1462.2729) lr 1.2369e-04 eta 0:01:29
epoch [44/50] batch [120/160] time 0.089 (0.089) data 0.000 (0.003) loss 1.5137 (1.4436) teacher_loss 0.3394 (0.2752) loss_zs_kd 0.0534 (0.0439) loss_oracle 0.6191 (0.5705) kd_loss 0.8381 (0.8612) acc 87.5000 (88.8021) gate/entropy 1.0257 (1.0257) gate/usage_max 0.4191 (0.4192) gate/usage_min 0.1640 (0.1640) gate/usage_std 0.1197 (0.1197) teacher/entropy 0.0476 (0.0382) teacher/usage_max 0.6546 (0.7295) teacher/usage_min 0.0138 (0.0276) teacher/usage_std 0.2616 (0.2977) nleep/row_max_mean 1487.0245 (1491.6296) nleep/row_max_std 53.1790 (60.7077) nleep/row_min_mean 1457.9189 (1462.1857) lr 1.2369e-04 eta 0:01:28
epoch [44/50] batch [140/160] time 0.094 (0.089) data 0.000 (0.002) loss 1.3579 (1.4423) teacher_loss 0.1190 (0.2720) loss_zs_kd 0.0377 (0.0434) loss_oracle 0.6214 (0.5705) kd_loss 0.9094 (0.8633) acc 96.8750 (88.9062) gate/entropy 1.0257 (1.0257) gate/usage_max 0.4191 (0.4192) gate/usage_min 0.1640 (0.1640) gate/usage_std 0.1198 (0.1197) teacher/entropy 0.0741 (0.0389) teacher/usage_max 0.6607 (0.7244) teacher/usage_min 0.1183 (0.0307) teacher/usage_std 0.2353 (0.2941) nleep/row_max_mean 1492.8521 (1491.6051) nleep/row_max_std 52.3537 (59.7887) nleep/row_min_mean 1466.4235 (1462.2603) lr 1.2369e-04 eta 0:01:27
epoch [44/50] batch [160/160] time 0.088 (0.089) data 0.000 (0.002) loss 1.4572 (1.4411) teacher_loss 0.2984 (0.2712) loss_zs_kd 0.0367 (0.0438) loss_oracle 0.5166 (0.5689) kd_loss 0.8822 (0.8635) acc 87.5000 (88.9453) gate/entropy 1.0256 (1.0257) gate/usage_max 0.4191 (0.4192) gate/usage_min 0.1639 (0.1640) gate/usage_std 0.1198 (0.1197) teacher/entropy 0.0326 (0.0391) teacher/usage_max 0.7365 (0.7249) teacher/usage_min 0.0446 (0.0311) teacher/usage_std 0.2938 (0.2942) nleep/row_max_mean 1504.6206 (1491.3379) nleep/row_max_std 20.5036 (59.2047) nleep/row_min_mean 1475.4126 (1462.1596) lr 9.5173e-05 eta 0:01:25
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,841
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 85.2%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,966
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.7%
******* Domain p best val acc:      83.9%, epoch: 43 *******
******* Domain p best val test acc: 87.9%, epoch: 43 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [45/50] batch [20/160] time 0.091 (0.103) data 0.000 (0.018) loss 1.4082 (1.4702) teacher_loss 0.2620 (0.2911) loss_zs_kd 0.0480 (0.0405) loss_oracle 0.5839 (0.5745) kd_loss 0.8303 (0.8716) acc 84.3750 (88.9062) gate/entropy 1.0256 (1.0257) gate/usage_max 0.4191 (0.4191) gate/usage_min 0.1639 (0.1640) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0574 (0.0409) teacher/usage_max 0.6427 (0.7052) teacher/usage_min 0.0163 (0.0423) teacher/usage_std 0.2558 (0.2786) nleep/row_max_mean 1496.4247 (1491.6272) nleep/row_max_std 40.8389 (49.8587) nleep/row_min_mean 1468.5493 (1462.9882) lr 9.5173e-05 eta 0:01:36
epoch [45/50] batch [40/160] time 0.075 (0.092) data 0.000 (0.009) loss 1.4123 (1.4646) teacher_loss 0.1665 (0.2863) loss_zs_kd 0.0301 (0.0387) loss_oracle 0.6620 (0.5798) kd_loss 0.8998 (0.8691) acc 90.6250 (88.5156) gate/entropy 1.0256 (1.0257) gate/usage_max 0.4191 (0.4191) gate/usage_min 0.1639 (0.1640) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0307 (0.0418) teacher/usage_max 0.6206 (0.6975) teacher/usage_min 0.0621 (0.0406) teacher/usage_std 0.2283 (0.2763) nleep/row_max_mean 1512.5571 (1491.7590) nleep/row_max_std 20.4427 (51.0985) nleep/row_min_mean 1480.6746 (1462.8116) lr 9.5173e-05 eta 0:01:24
epoch [45/50] batch [60/160] time 0.091 (0.091) data 0.001 (0.006) loss 1.3839 (1.4597) teacher_loss 0.1528 (0.2828) loss_zs_kd 0.0324 (0.0385) loss_oracle 0.6027 (0.5812) kd_loss 0.9136 (0.8671) acc 96.8750 (88.8542) gate/entropy 1.0257 (1.0257) gate/usage_max 0.4190 (0.4190) gate/usage_min 0.1640 (0.1640) gate/usage_std 0.1197 (0.1198) teacher/entropy 0.0153 (0.0439) teacher/usage_max 0.7523 (0.7027) teacher/usage_min 0.0597 (0.0408) teacher/usage_std 0.3008 (0.2788) nleep/row_max_mean 1503.3386 (1491.3356) nleep/row_max_std 48.3236 (54.3226) nleep/row_min_mean 1469.6276 (1462.5389) lr 9.5173e-05 eta 0:01:22
epoch [45/50] batch [80/160] time 0.066 (0.090) data 0.000 (0.005) loss 1.3829 (1.4584) teacher_loss 0.1732 (0.2816) loss_zs_kd 0.0821 (0.0407) loss_oracle 0.6314 (0.5789) kd_loss 0.8530 (0.8670) acc 100.0000 (88.7109) gate/entropy 1.0259 (1.0257) gate/usage_max 0.4191 (0.4190) gate/usage_min 0.1642 (0.1640) gate/usage_std 0.1196 (0.1198) teacher/entropy 0.0670 (0.0444) teacher/usage_max 0.6762 (0.7129) teacher/usage_min 0.0498 (0.0412) teacher/usage_std 0.2592 (0.2845) nleep/row_max_mean 1479.8623 (1492.1456) nleep/row_max_std 75.3790 (53.1399) nleep/row_min_mean 1453.3558 (1463.4222) lr 9.5173e-05 eta 0:01:19
epoch [45/50] batch [100/160] time 0.086 (0.090) data 0.000 (0.004) loss 1.3317 (1.4571) teacher_loss 0.1701 (0.2821) loss_zs_kd 0.0627 (0.0410) loss_oracle 0.5943 (0.5762) kd_loss 0.8331 (0.8664) acc 93.7500 (88.7812) gate/entropy 1.0257 (1.0257) gate/usage_max 0.4190 (0.4190) gate/usage_min 0.1640 (0.1640) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0591 (0.0443) teacher/usage_max 0.6394 (0.7140) teacher/usage_min 0.0211 (0.0404) teacher/usage_std 0.2525 (0.2857) nleep/row_max_mean 1485.9570 (1491.0251) nleep/row_max_std 59.9098 (55.9754) nleep/row_min_mean 1454.4484 (1462.4152) lr 9.5173e-05 eta 0:01:17
epoch [45/50] batch [120/160] time 0.073 (0.091) data 0.000 (0.003) loss 1.3477 (1.4598) teacher_loss 0.2066 (0.2860) loss_zs_kd 0.0416 (0.0411) loss_oracle 0.5416 (0.5736) kd_loss 0.8495 (0.8665) acc 93.7500 (88.6458) gate/entropy 1.0256 (1.0257) gate/usage_max 0.4189 (0.4190) gate/usage_min 0.1638 (0.1640) gate/usage_std 0.1199 (0.1198) teacher/entropy 0.0390 (0.0432) teacher/usage_max 0.8079 (0.7146) teacher/usage_min 0.0164 (0.0393) teacher/usage_std 0.3418 (0.2862) nleep/row_max_mean 1497.2329 (1491.4516) nleep/row_max_std 54.9955 (56.1193) nleep/row_min_mean 1469.3245 (1462.7037) lr 9.5173e-05 eta 0:01:16
epoch [45/50] batch [140/160] time 0.098 (0.090) data 0.000 (0.003) loss 1.4508 (1.4543) teacher_loss 0.3130 (0.2808) loss_zs_kd 0.0262 (0.0414) loss_oracle 0.5533 (0.5734) kd_loss 0.8479 (0.8662) acc 90.6250 (88.9955) gate/entropy 1.0257 (1.0257) gate/usage_max 0.4189 (0.4190) gate/usage_min 0.1640 (0.1640) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0520 (0.0432) teacher/usage_max 0.8190 (0.7139) teacher/usage_min 0.0283 (0.0390) teacher/usage_std 0.3471 (0.2858) nleep/row_max_mean 1479.0001 (1491.3206) nleep/row_max_std 77.3900 (57.1669) nleep/row_min_mean 1449.6533 (1462.5606) lr 9.5173e-05 eta 0:01:14
epoch [45/50] batch [160/160] time 0.081 (0.090) data 0.000 (0.003) loss 1.5924 (1.4549) teacher_loss 0.3901 (0.2812) loss_zs_kd 0.0499 (0.0423) loss_oracle 0.6244 (0.5719) kd_loss 0.8652 (0.8665) acc 87.5000 (89.0430) gate/entropy 1.0256 (1.0257) gate/usage_max 0.4190 (0.4190) gate/usage_min 0.1639 (0.1640) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0088 (0.0426) teacher/usage_max 0.7172 (0.7164) teacher/usage_min 0.0011 (0.0387) teacher/usage_std 0.2946 (0.2872) nleep/row_max_mean 1474.5460 (1491.0761) nleep/row_max_std 83.2882 (57.1767) nleep/row_min_mean 1445.1694 (1462.2982) lr 7.0224e-05 eta 0:01:12
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,836
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 85.0%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,966
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.7%
******* Domain p best val acc:      83.9%, epoch: 43 *******
******* Domain p best val test acc: 87.9%, epoch: 43 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [46/50] batch [20/160] time 0.107 (0.115) data 0.001 (0.015) loss 1.4304 (1.4309) teacher_loss 0.2859 (0.2548) loss_zs_kd 0.0296 (0.0436) loss_oracle 0.5516 (0.5664) kd_loss 0.8539 (0.8711) acc 90.6250 (90.1562) gate/entropy 1.0257 (1.0257) gate/usage_max 0.4190 (0.4189) gate/usage_min 0.1640 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0292 (0.0389) teacher/usage_max 0.7392 (0.7165) teacher/usage_min 0.0108 (0.0398) teacher/usage_std 0.3032 (0.2869) nleep/row_max_mean 1482.8118 (1491.6963) nleep/row_max_std 66.8703 (54.6267) nleep/row_min_mean 1452.9496 (1463.0443) lr 7.0224e-05 eta 0:01:29
epoch [46/50] batch [40/160] time 0.097 (0.106) data 0.000 (0.008) loss 1.2915 (1.4261) teacher_loss 0.1204 (0.2506) loss_zs_kd 0.0599 (0.0432) loss_oracle 0.4967 (0.5734) kd_loss 0.8928 (0.8671) acc 100.0000 (90.3125) gate/entropy 1.0257 (1.0256) gate/usage_max 0.4189 (0.4189) gate/usage_min 0.1640 (0.1639) gate/usage_std 0.1197 (0.1198) teacher/entropy 0.0263 (0.0439) teacher/usage_max 0.7315 (0.7041) teacher/usage_min 0.0496 (0.0410) teacher/usage_std 0.2899 (0.2813) nleep/row_max_mean 1493.1350 (1492.6960) nleep/row_max_std 57.8317 (55.0047) nleep/row_min_mean 1463.5948 (1463.8648) lr 7.0224e-05 eta 0:01:20
epoch [46/50] batch [60/160] time 0.107 (0.104) data 0.001 (0.005) loss 1.3317 (1.4316) teacher_loss 0.2105 (0.2624) loss_zs_kd 0.0497 (0.0428) loss_oracle 0.5502 (0.5688) kd_loss 0.8213 (0.8633) acc 90.6250 (89.6354) gate/entropy 1.0255 (1.0256) gate/usage_max 0.4189 (0.4189) gate/usage_min 0.1637 (0.1639) gate/usage_std 0.1199 (0.1198) teacher/entropy 0.0658 (0.0434) teacher/usage_max 0.7546 (0.7151) teacher/usage_min 0.0155 (0.0363) teacher/usage_std 0.3104 (0.2880) nleep/row_max_mean 1494.3777 (1493.1413) nleep/row_max_std 77.7459 (55.9003) nleep/row_min_mean 1466.2505 (1464.1647) lr 7.0224e-05 eta 0:01:16
epoch [46/50] batch [80/160] time 0.098 (0.102) data 0.001 (0.004) loss 1.5177 (1.4387) teacher_loss 0.3470 (0.2660) loss_zs_kd 0.0505 (0.0427) loss_oracle 0.6326 (0.5700) kd_loss 0.8292 (0.8663) acc 87.5000 (90.1562) gate/entropy 1.0258 (1.0256) gate/usage_max 0.4189 (0.4189) gate/usage_min 0.1640 (0.1639) gate/usage_std 0.1197 (0.1198) teacher/entropy 0.0772 (0.0420) teacher/usage_max 0.6450 (0.7145) teacher/usage_min 0.0361 (0.0381) teacher/usage_std 0.2488 (0.2869) nleep/row_max_mean 1491.7092 (1492.2663) nleep/row_max_std 48.1656 (56.6983) nleep/row_min_mean 1462.6360 (1463.1938) lr 7.0224e-05 eta 0:01:13
epoch [46/50] batch [100/160] time 0.090 (0.100) data 0.000 (0.003) loss 1.3346 (1.4510) teacher_loss 0.1539 (0.2756) loss_zs_kd 0.0599 (0.0429) loss_oracle 0.5807 (0.5735) kd_loss 0.8605 (0.8671) acc 96.8750 (89.8125) gate/entropy 1.0257 (1.0256) gate/usage_max 0.4190 (0.4189) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0813 (0.0425) teacher/usage_max 0.4772 (0.7101) teacher/usage_min 0.0746 (0.0392) teacher/usage_std 0.1833 (0.2848) nleep/row_max_mean 1460.6177 (1492.5507) nleep/row_max_std 91.7953 (56.8611) nleep/row_min_mean 1433.6698 (1463.4342) lr 7.0224e-05 eta 0:01:09
epoch [46/50] batch [120/160] time 0.095 (0.099) data 0.000 (0.003) loss 1.4020 (1.4521) teacher_loss 0.2101 (0.2757) loss_zs_kd 0.0533 (0.0428) loss_oracle 0.5848 (0.5733) kd_loss 0.8728 (0.8683) acc 90.6250 (89.7917) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4189 (0.4189) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0307 (0.0410) teacher/usage_max 0.6448 (0.7133) teacher/usage_min 0.0336 (0.0390) teacher/usage_std 0.2497 (0.2867) nleep/row_max_mean 1487.1819 (1492.7730) nleep/row_max_std 59.5762 (56.9717) nleep/row_min_mean 1456.3290 (1463.7308) lr 7.0224e-05 eta 0:01:07
epoch [46/50] batch [140/160] time 0.105 (0.099) data 0.000 (0.002) loss 1.3938 (1.4561) teacher_loss 0.2831 (0.2784) loss_zs_kd 0.0282 (0.0424) loss_oracle 0.5925 (0.5730) kd_loss 0.8004 (0.8700) acc 87.5000 (89.5536) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4189 (0.4189) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0761 (0.0418) teacher/usage_max 0.6623 (0.7132) teacher/usage_min 0.0046 (0.0416) teacher/usage_std 0.2685 (0.2859) nleep/row_max_mean 1480.1829 (1492.8012) nleep/row_max_std 73.0236 (56.3151) nleep/row_min_mean 1452.0708 (1463.8475) lr 7.0224e-05 eta 0:01:05
epoch [46/50] batch [160/160] time 0.083 (0.098) data 0.000 (0.002) loss 1.4466 (1.4514) teacher_loss 0.2509 (0.2723) loss_zs_kd 0.0522 (0.0427) loss_oracle 0.6114 (0.5737) kd_loss 0.8639 (0.8709) acc 90.6250 (89.7852) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4188 (0.4189) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0114 (0.0419) teacher/usage_max 0.8413 (0.7119) teacher/usage_min 0.0023 (0.0427) teacher/usage_std 0.3647 (0.2848) nleep/row_max_mean 1480.8831 (1492.7953) nleep/row_max_std 74.3733 (55.9038) nleep/row_min_mean 1453.4712 (1463.8831) lr 4.8943e-05 eta 0:01:02
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,847
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,969
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 88.8%
******* Domain p best val acc:      83.9%, epoch: 43 *******
******* Domain p best val test acc: 87.9%, epoch: 43 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [47/50] batch [20/160] time 0.178 (0.127) data 0.001 (0.016) loss 1.3646 (1.4371) teacher_loss 0.1253 (0.2697) loss_zs_kd 0.0559 (0.0443) loss_oracle 0.6411 (0.5588) kd_loss 0.8908 (0.8658) acc 96.8750 (89.6875) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4188 (0.4188) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0611 (0.0445) teacher/usage_max 0.6640 (0.7456) teacher/usage_min 0.0848 (0.0402) teacher/usage_std 0.2435 (0.3024) nleep/row_max_mean 1485.8167 (1495.3694) nleep/row_max_std 70.6224 (52.5712) nleep/row_min_mean 1456.3320 (1466.0254) lr 4.8943e-05 eta 0:01:19
epoch [47/50] batch [40/160] time 0.095 (0.113) data 0.000 (0.008) loss 1.6966 (1.4420) teacher_loss 0.5616 (0.2741) loss_zs_kd 0.0389 (0.0431) loss_oracle 0.5566 (0.5635) kd_loss 0.8372 (0.8647) acc 78.1250 (89.7656) gate/entropy 1.0255 (1.0256) gate/usage_max 0.4188 (0.4188) gate/usage_min 0.1638 (0.1639) gate/usage_std 0.1199 (0.1198) teacher/entropy 0.0587 (0.0508) teacher/usage_max 0.7963 (0.7313) teacher/usage_min 0.0247 (0.0457) teacher/usage_std 0.3334 (0.2944) nleep/row_max_mean 1495.7490 (1494.8715) nleep/row_max_std 69.2299 (52.7427) nleep/row_min_mean 1469.6880 (1466.1078) lr 4.8943e-05 eta 0:01:07
epoch [47/50] batch [60/160] time 0.095 (0.106) data 0.001 (0.006) loss 1.3625 (1.4483) teacher_loss 0.2317 (0.2718) loss_zs_kd 0.0452 (0.0427) loss_oracle 0.4697 (0.5714) kd_loss 0.8733 (0.8694) acc 90.6250 (89.4271) gate/entropy 1.0257 (1.0256) gate/usage_max 0.4187 (0.4188) gate/usage_min 0.1640 (0.1639) gate/usage_std 0.1197 (0.1198) teacher/entropy 0.0410 (0.0470) teacher/usage_max 0.7367 (0.7176) teacher/usage_min 0.0444 (0.0468) teacher/usage_std 0.2940 (0.2864) nleep/row_max_mean 1467.7727 (1492.7586) nleep/row_max_std 74.2612 (54.0202) nleep/row_min_mean 1442.5186 (1464.1151) lr 4.8943e-05 eta 0:01:01
epoch [47/50] batch [80/160] time 0.104 (0.102) data 0.000 (0.004) loss 1.4001 (1.4435) teacher_loss 0.1849 (0.2681) loss_zs_kd 0.0680 (0.0435) loss_oracle 0.6614 (0.5720) kd_loss 0.8505 (0.8676) acc 93.7500 (89.4922) gate/entropy 1.0257 (1.0256) gate/usage_max 0.4189 (0.4188) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0680 (0.0483) teacher/usage_max 0.5602 (0.7123) teacher/usage_min 0.0494 (0.0463) teacher/usage_std 0.2124 (0.2834) nleep/row_max_mean 1476.7021 (1492.4614) nleep/row_max_std 83.9616 (55.1840) nleep/row_min_mean 1448.0721 (1463.8757) lr 4.8943e-05 eta 0:00:57
epoch [47/50] batch [100/160] time 0.097 (0.100) data 0.000 (0.004) loss 1.3419 (1.4542) teacher_loss 0.1866 (0.2805) loss_zs_kd 0.0374 (0.0430) loss_oracle 0.5166 (0.5730) kd_loss 0.8783 (0.8656) acc 90.6250 (88.9688) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4188 (0.4188) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0242 (0.0475) teacher/usage_max 0.7134 (0.7140) teacher/usage_min 0.0322 (0.0434) teacher/usage_std 0.2837 (0.2851) nleep/row_max_mean 1489.9890 (1491.9766) nleep/row_max_std 61.1902 (56.0539) nleep/row_min_mean 1463.0105 (1463.3762) lr 4.8943e-05 eta 0:00:54
epoch [47/50] batch [120/160] time 0.085 (0.099) data 0.000 (0.003) loss 1.3865 (1.4517) teacher_loss 0.1656 (0.2777) loss_zs_kd 0.0594 (0.0439) loss_oracle 0.6599 (0.5742) kd_loss 0.8613 (0.8649) acc 93.7500 (89.1146) gate/entropy 1.0257 (1.0256) gate/usage_max 0.4189 (0.4188) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0113 (0.0483) teacher/usage_max 0.6240 (0.7127) teacher/usage_min 0.0005 (0.0435) teacher/usage_std 0.2563 (0.2842) nleep/row_max_mean 1503.0408 (1491.4056) nleep/row_max_std 41.9783 (56.1168) nleep/row_min_mean 1469.8119 (1462.7373) lr 4.8943e-05 eta 0:00:51
epoch [47/50] batch [140/160] time 0.081 (0.098) data 0.000 (0.003) loss 1.4886 (1.4490) teacher_loss 0.2968 (0.2732) loss_zs_kd 0.0448 (0.0444) loss_oracle 0.5820 (0.5759) kd_loss 0.8783 (0.8656) acc 87.5000 (89.2188) gate/entropy 1.0255 (1.0256) gate/usage_max 0.4188 (0.4188) gate/usage_min 0.1638 (0.1639) gate/usage_std 0.1199 (0.1198) teacher/entropy 0.0242 (0.0472) teacher/usage_max 0.7091 (0.7101) teacher/usage_min 0.0323 (0.0431) teacher/usage_std 0.2813 (0.2828) nleep/row_max_mean 1483.3977 (1491.2191) nleep/row_max_std 79.9794 (56.4595) nleep/row_min_mean 1455.7122 (1462.5744) lr 4.8943e-05 eta 0:00:49
epoch [47/50] batch [160/160] time 0.094 (0.098) data 0.000 (0.002) loss 1.3671 (1.4503) teacher_loss 0.2169 (0.2730) loss_zs_kd 0.0375 (0.0444) loss_oracle 0.5282 (0.5745) kd_loss 0.8673 (0.8679) acc 93.7500 (89.3164) gate/entropy 1.0255 (1.0256) gate/usage_max 0.4187 (0.4188) gate/usage_min 0.1637 (0.1639) gate/usage_std 0.1199 (0.1198) teacher/entropy 0.0521 (0.0469) teacher/usage_max 0.8839 (0.7084) teacher/usage_min 0.0495 (0.0452) teacher/usage_std 0.3894 (0.2815) nleep/row_max_mean 1489.5654 (1491.0869) nleep/row_max_std 63.3245 (56.3682) nleep/row_min_mean 1465.3950 (1462.4126) lr 3.1417e-05 eta 0:00:46
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,846
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,964
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.7%
******* Domain p best val acc:      83.9%, epoch: 43 *******
******* Domain p best val test acc: 87.9%, epoch: 43 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [48/50] batch [20/160] time 0.094 (0.120) data 0.000 (0.016) loss 1.6477 (1.4907) teacher_loss 0.3651 (0.2922) loss_zs_kd 0.0856 (0.0435) loss_oracle 0.6179 (0.5921) kd_loss 0.9308 (0.8807) acc 78.1250 (87.9688) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4188 (0.4188) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0561 (0.0401) teacher/usage_max 0.6808 (0.7065) teacher/usage_min 0.1225 (0.0516) teacher/usage_std 0.2476 (0.2785) nleep/row_max_mean 1494.5420 (1490.7976) nleep/row_max_std 46.8557 (60.0324) nleep/row_min_mean 1465.6492 (1461.6582) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [40/160] time 0.097 (0.111) data 0.000 (0.008) loss 1.4747 (1.4763) teacher_loss 0.2563 (0.2879) loss_zs_kd 0.0689 (0.0425) loss_oracle 0.5700 (0.5792) kd_loss 0.8989 (0.8776) acc 90.6250 (88.3594) gate/entropy 1.0254 (1.0256) gate/usage_max 0.4188 (0.4188) gate/usage_min 0.1637 (0.1639) gate/usage_std 0.1200 (0.1198) teacher/entropy 0.0456 (0.0446) teacher/usage_max 0.6776 (0.7130) teacher/usage_min 0.0773 (0.0521) teacher/usage_std 0.2529 (0.2819) nleep/row_max_mean 1497.1411 (1491.7456) nleep/row_max_std 60.4353 (58.3180) nleep/row_min_mean 1468.2258 (1463.1942) lr 3.1417e-05 eta 0:00:49
epoch [48/50] batch [60/160] time 0.094 (0.106) data 0.001 (0.006) loss 1.4330 (1.4662) teacher_loss 0.2019 (0.2780) loss_zs_kd 0.0591 (0.0447) loss_oracle 0.5625 (0.5806) kd_loss 0.9203 (0.8755) acc 96.8750 (88.8542) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4188 (0.4188) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0347 (0.0444) teacher/usage_max 0.6302 (0.7096) teacher/usage_min 0.0886 (0.0499) teacher/usage_std 0.2242 (0.2806) nleep/row_max_mean 1495.2659 (1490.9446) nleep/row_max_std 46.0269 (59.2552) nleep/row_min_mean 1467.4012 (1462.3429) lr 3.1417e-05 eta 0:00:44
epoch [48/50] batch [80/160] time 0.097 (0.104) data 0.001 (0.004) loss 1.3801 (1.4663) teacher_loss 0.2284 (0.2758) loss_zs_kd 0.0533 (0.0454) loss_oracle 0.5240 (0.5810) kd_loss 0.8630 (0.8774) acc 90.6250 (88.9453) gate/entropy 1.0257 (1.0256) gate/usage_max 0.4188 (0.4188) gate/usage_min 0.1640 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0395 (0.0451) teacher/usage_max 0.7831 (0.7034) teacher/usage_min 0.0314 (0.0529) teacher/usage_std 0.3242 (0.2764) nleep/row_max_mean 1501.3192 (1490.2774) nleep/row_max_std 29.2743 (60.1714) nleep/row_min_mean 1473.7755 (1461.7649) lr 3.1417e-05 eta 0:00:41
epoch [48/50] batch [100/160] time 0.100 (0.103) data 0.000 (0.003) loss 1.4130 (1.4643) teacher_loss 0.2348 (0.2727) loss_zs_kd 0.0313 (0.0450) loss_oracle 0.5853 (0.5780) kd_loss 0.8700 (0.8801) acc 90.6250 (88.9375) gate/entropy 1.0255 (1.0256) gate/usage_max 0.4188 (0.4188) gate/usage_min 0.1637 (0.1638) gate/usage_std 0.1199 (0.1198) teacher/entropy 0.0419 (0.0458) teacher/usage_max 0.7385 (0.6987) teacher/usage_min 0.0425 (0.0566) teacher/usage_std 0.2954 (0.2735) nleep/row_max_mean 1505.7959 (1491.2550) nleep/row_max_std 52.8514 (58.7507) nleep/row_min_mean 1474.9360 (1462.7937) lr 3.1417e-05 eta 0:00:39
epoch [48/50] batch [120/160] time 0.096 (0.102) data 0.000 (0.003) loss 1.3669 (1.4586) teacher_loss 0.1631 (0.2694) loss_zs_kd 0.0443 (0.0448) loss_oracle 0.5335 (0.5768) kd_loss 0.9150 (0.8785) acc 100.0000 (89.0625) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4187 (0.4188) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0320 (0.0457) teacher/usage_max 0.7314 (0.6966) teacher/usage_min 0.0797 (0.0549) teacher/usage_std 0.2850 (0.2728) nleep/row_max_mean 1487.5400 (1491.2012) nleep/row_max_std 62.2513 (58.7061) nleep/row_min_mean 1459.4601 (1462.7145) lr 3.1417e-05 eta 0:00:36
epoch [48/50] batch [140/160] time 0.128 (0.101) data 0.000 (0.003) loss 1.3383 (1.4585) teacher_loss 0.1841 (0.2703) loss_zs_kd 0.0638 (0.0453) loss_oracle 0.5831 (0.5760) kd_loss 0.8308 (0.8775) acc 93.7500 (89.1295) gate/entropy 1.0255 (1.0256) gate/usage_max 0.4188 (0.4188) gate/usage_min 0.1637 (0.1639) gate/usage_std 0.1199 (0.1198) teacher/entropy 0.0513 (0.0473) teacher/usage_max 0.6545 (0.6944) teacher/usage_min 0.0107 (0.0556) teacher/usage_std 0.2628 (0.2715) nleep/row_max_mean 1512.0872 (1491.5894) nleep/row_max_std 24.8761 (57.9230) nleep/row_min_mean 1480.0300 (1462.9885) lr 3.1417e-05 eta 0:00:34
epoch [48/50] batch [160/160] time 0.083 (0.101) data 0.000 (0.002) loss 1.2721 (1.4564) teacher_loss 0.1320 (0.2683) loss_zs_kd 0.0534 (0.0455) loss_oracle 0.5261 (0.5765) kd_loss 0.8503 (0.8771) acc 100.0000 (89.3555) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4187 (0.4188) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0227 (0.0485) teacher/usage_max 0.8219 (0.6951) teacher/usage_min 0.0001 (0.0566) teacher/usage_std 0.3530 (0.2716) nleep/row_max_mean 1508.1858 (1491.6803) nleep/row_max_std 22.3420 (58.0251) nleep/row_min_mean 1477.3649 (1463.0482) lr 1.7713e-05 eta 0:00:32
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,849
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,963
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.7%
******* Domain p best val acc:      83.9%, epoch: 43 *******
******* Domain p best val test acc: 87.9%, epoch: 43 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [49/50] batch [20/160] time 0.116 (0.119) data 0.000 (0.016) loss 1.3283 (1.4471) teacher_loss 0.1348 (0.2823) loss_zs_kd 0.0457 (0.0460) loss_oracle 0.6057 (0.5560) kd_loss 0.8677 (0.8638) acc 93.7500 (90.1562) gate/entropy 1.0257 (1.0256) gate/usage_max 0.4188 (0.4187) gate/usage_min 0.1640 (0.1638) gate/usage_std 0.1197 (0.1198) teacher/entropy 0.0308 (0.0530) teacher/usage_max 0.6668 (0.7027) teacher/usage_min 0.0279 (0.0475) teacher/usage_std 0.2616 (0.2774) nleep/row_max_mean 1495.1201 (1490.2438) nleep/row_max_std 53.5514 (58.9462) nleep/row_min_mean 1463.9375 (1461.7562) lr 1.7713e-05 eta 0:00:35
epoch [49/50] batch [40/160] time 0.104 (0.111) data 0.000 (0.008) loss 1.3354 (1.4607) teacher_loss 0.2241 (0.2863) loss_zs_kd 0.0186 (0.0452) loss_oracle 0.4382 (0.5681) kd_loss 0.8829 (0.8678) acc 93.7500 (90.1562) gate/entropy 1.0258 (1.0256) gate/usage_max 0.4186 (0.4187) gate/usage_min 0.1641 (0.1638) gate/usage_std 0.1197 (0.1199) teacher/entropy 0.0447 (0.0539) teacher/usage_max 0.8441 (0.7082) teacher/usage_min 0.0581 (0.0526) teacher/usage_std 0.3615 (0.2795) nleep/row_max_mean 1484.8306 (1490.8612) nleep/row_max_std 55.2722 (57.9229) nleep/row_min_mean 1459.7981 (1462.5325) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [60/160] time 0.098 (0.106) data 0.001 (0.006) loss 1.4048 (1.4732) teacher_loss 0.2086 (0.2883) loss_zs_kd 0.0384 (0.0452) loss_oracle 0.6356 (0.5744) kd_loss 0.8592 (0.8751) acc 90.6250 (89.6875) gate/entropy 1.0255 (1.0256) gate/usage_max 0.4188 (0.4187) gate/usage_min 0.1638 (0.1638) gate/usage_std 0.1199 (0.1198) teacher/entropy 0.0492 (0.0528) teacher/usage_max 0.5938 (0.7016) teacher/usage_min 0.0392 (0.0592) teacher/usage_std 0.2277 (0.2739) nleep/row_max_mean 1496.9159 (1491.4319) nleep/row_max_std 61.1037 (57.0948) nleep/row_min_mean 1469.1527 (1462.9134) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [80/160] time 0.095 (0.103) data 0.000 (0.004) loss 1.4658 (1.4569) teacher_loss 0.2728 (0.2781) loss_zs_kd 0.0448 (0.0435) loss_oracle 0.5877 (0.5710) kd_loss 0.8767 (0.8715) acc 84.3750 (90.0391) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4187 (0.4187) gate/usage_min 0.1639 (0.1638) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0601 (0.0551) teacher/usage_max 0.6550 (0.7023) teacher/usage_min 0.0691 (0.0579) teacher/usage_std 0.2426 (0.2739) nleep/row_max_mean 1495.3795 (1490.6200) nleep/row_max_std 59.2262 (59.6177) nleep/row_min_mean 1467.8302 (1462.3075) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [100/160] time 0.101 (0.102) data 0.000 (0.003) loss 1.4675 (1.4579) teacher_loss 0.2736 (0.2752) loss_zs_kd 0.0537 (0.0441) loss_oracle 0.5822 (0.5730) kd_loss 0.8759 (0.8741) acc 87.5000 (89.9062) gate/entropy 1.0255 (1.0256) gate/usage_max 0.4187 (0.4187) gate/usage_min 0.1638 (0.1638) gate/usage_std 0.1199 (0.1198) teacher/entropy 0.0474 (0.0557) teacher/usage_max 0.6953 (0.6976) teacher/usage_min 0.0546 (0.0614) teacher/usage_std 0.2681 (0.2704) nleep/row_max_mean 1483.2770 (1490.8562) nleep/row_max_std 77.0109 (59.0642) nleep/row_min_mean 1457.3455 (1462.5556) lr 1.7713e-05 eta 0:00:22
epoch [49/50] batch [120/160] time 0.101 (0.101) data 0.000 (0.003) loss 1.3133 (1.4577) teacher_loss 0.1961 (0.2754) loss_zs_kd 0.0424 (0.0442) loss_oracle 0.5394 (0.5710) kd_loss 0.8262 (0.8747) acc 90.6250 (89.6615) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4187 (0.4187) gate/usage_min 0.1639 (0.1638) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0891 (0.0560) teacher/usage_max 0.7858 (0.6956) teacher/usage_min 0.0456 (0.0623) teacher/usage_std 0.3238 (0.2690) nleep/row_max_mean 1497.8257 (1491.1982) nleep/row_max_std 51.7526 (58.7762) nleep/row_min_mean 1469.1447 (1462.8316) lr 1.7713e-05 eta 0:00:20
epoch [49/50] batch [140/160] time 0.108 (0.100) data 0.000 (0.003) loss 1.5899 (1.4536) teacher_loss 0.4073 (0.2720) loss_zs_kd 0.0325 (0.0441) loss_oracle 0.5810 (0.5709) kd_loss 0.8758 (0.8741) acc 87.5000 (89.5312) gate/entropy 1.0255 (1.0256) gate/usage_max 0.4187 (0.4187) gate/usage_min 0.1638 (0.1638) gate/usage_std 0.1199 (0.1198) teacher/entropy 0.0729 (0.0553) teacher/usage_max 0.6879 (0.6912) teacher/usage_min 0.0812 (0.0610) teacher/usage_std 0.2581 (0.2670) nleep/row_max_mean 1472.1484 (1491.1183) nleep/row_max_std 88.5080 (58.7084) nleep/row_min_mean 1445.6332 (1462.7872) lr 1.7713e-05 eta 0:00:17
epoch [49/50] batch [160/160] time 0.084 (0.099) data 0.000 (0.002) loss 1.3673 (1.4521) teacher_loss 0.1681 (0.2700) loss_zs_kd 0.0483 (0.0441) loss_oracle 0.5632 (0.5713) kd_loss 0.8934 (0.8744) acc 93.7500 (89.7461) gate/entropy 1.0257 (1.0256) gate/usage_max 0.4186 (0.4187) gate/usage_min 0.1639 (0.1638) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0723 (0.0552) teacher/usage_max 0.6189 (0.6889) teacher/usage_min 0.0996 (0.0611) teacher/usage_std 0.2151 (0.2657) nleep/row_max_mean 1486.4163 (1491.0260) nleep/row_max_std 51.8616 (58.8474) nleep/row_min_mean 1460.0510 (1462.6729) lr 7.8853e-06 eta 0:00:15
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,847
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 85.4%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,963
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.6%
******* Domain p best val acc:      83.9%, epoch: 43 *******
******* Domain p best val test acc: 87.9%, epoch: 43 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
epoch [50/50] batch [20/160] time 0.077 (0.109) data 0.000 (0.017) loss 1.4088 (1.4481) teacher_loss 0.2003 (0.2550) loss_zs_kd 0.0525 (0.0393) loss_oracle 0.6031 (0.5772) kd_loss 0.8807 (0.8849) acc 96.8750 (89.8438) gate/entropy 1.0257 (1.0256) gate/usage_max 0.4187 (0.4187) gate/usage_min 0.1639 (0.1639) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0235 (0.0424) teacher/usage_max 0.6820 (0.6918) teacher/usage_min 0.0338 (0.0588) teacher/usage_std 0.2669 (0.2705) nleep/row_max_mean 1499.9637 (1499.7142) nleep/row_max_std 32.4510 (47.9184) nleep/row_min_mean 1469.1414 (1470.2987) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [40/160] time 0.090 (0.098) data 0.000 (0.008) loss 1.3169 (1.4466) teacher_loss 0.1405 (0.2652) loss_zs_kd 0.0237 (0.0423) loss_oracle 0.5753 (0.5738) kd_loss 0.8769 (0.8733) acc 93.7500 (89.8438) gate/entropy 1.0257 (1.0256) gate/usage_max 0.4187 (0.4187) gate/usage_min 0.1640 (0.1639) gate/usage_std 0.1197 (0.1198) teacher/entropy 0.0207 (0.0490) teacher/usage_max 0.6593 (0.7066) teacher/usage_min 0.0269 (0.0533) teacher/usage_std 0.2585 (0.2790) nleep/row_max_mean 1493.1282 (1493.6230) nleep/row_max_std 50.8121 (54.9216) nleep/row_min_mean 1462.4146 (1465.0305) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [60/160] time 0.083 (0.100) data 0.001 (0.006) loss 1.3122 (1.4503) teacher_loss 0.1535 (0.2714) loss_zs_kd 0.0524 (0.0421) loss_oracle 0.4979 (0.5723) kd_loss 0.8835 (0.8717) acc 96.8750 (89.5833) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4187 (0.4187) gate/usage_min 0.1639 (0.1638) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0560 (0.0506) teacher/usage_max 0.7643 (0.7064) teacher/usage_min 0.0710 (0.0534) teacher/usage_std 0.3071 (0.2790) nleep/row_max_mean 1480.4086 (1493.3387) nleep/row_max_std 67.6752 (55.1642) nleep/row_min_mean 1455.2515 (1464.7035) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [80/160] time 0.100 (0.099) data 0.001 (0.004) loss 1.4074 (1.4430) teacher_loss 0.1888 (0.2607) loss_zs_kd 0.0480 (0.0423) loss_oracle 0.5429 (0.5732) kd_loss 0.9231 (0.8745) acc 93.7500 (89.8828) gate/entropy 1.0258 (1.0256) gate/usage_max 0.4187 (0.4187) gate/usage_min 0.1641 (0.1639) gate/usage_std 0.1197 (0.1198) teacher/entropy 0.0093 (0.0527) teacher/usage_max 0.6876 (0.6975) teacher/usage_min 0.0639 (0.0586) teacher/usage_std 0.2616 (0.2729) nleep/row_max_mean 1495.8198 (1493.4061) nleep/row_max_std 56.0866 (54.5475) nleep/row_min_mean 1465.9089 (1464.9536) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [100/160] time 0.091 (0.097) data 0.000 (0.004) loss 1.2752 (1.4477) teacher_loss 0.1686 (0.2643) loss_zs_kd 0.0322 (0.0436) loss_oracle 0.4952 (0.5729) kd_loss 0.8429 (0.8751) acc 93.7500 (89.5625) gate/entropy 1.0253 (1.0256) gate/usage_max 0.4187 (0.4187) gate/usage_min 0.1636 (0.1638) gate/usage_std 0.1200 (0.1198) teacher/entropy 0.0304 (0.0511) teacher/usage_max 0.7424 (0.6977) teacher/usage_min 0.0013 (0.0576) teacher/usage_std 0.3074 (0.2733) nleep/row_max_mean 1496.7922 (1493.1546) nleep/row_max_std 71.8532 (55.7494) nleep/row_min_mean 1469.2402 (1464.6463) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [120/160] time 0.081 (0.097) data 0.000 (0.003) loss 1.4416 (1.4507) teacher_loss 0.1770 (0.2677) loss_zs_kd 0.0597 (0.0438) loss_oracle 0.6640 (0.5747) kd_loss 0.9027 (0.8738) acc 90.6250 (89.5833) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4187 (0.4187) gate/usage_min 0.1639 (0.1638) gate/usage_std 0.1198 (0.1199) teacher/entropy 0.0627 (0.0509) teacher/usage_max 0.5875 (0.6977) teacher/usage_min 0.0997 (0.0559) teacher/usage_std 0.1996 (0.2734) nleep/row_max_mean 1488.1250 (1492.4733) nleep/row_max_std 62.0984 (56.2631) nleep/row_min_mean 1460.0969 (1464.0023) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [140/160] time 0.099 (0.096) data 0.000 (0.003) loss 1.5166 (1.4576) teacher_loss 0.2658 (0.2718) loss_zs_kd 0.0569 (0.0450) loss_oracle 0.6541 (0.5777) kd_loss 0.8953 (0.8745) acc 90.6250 (89.5312) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4187 (0.4187) gate/usage_min 0.1639 (0.1638) gate/usage_std 0.1198 (0.1199) teacher/entropy 0.0272 (0.0509) teacher/usage_max 0.6331 (0.6931) teacher/usage_min 0.0536 (0.0566) teacher/usage_std 0.2370 (0.2706) nleep/row_max_mean 1490.0359 (1492.1953) nleep/row_max_std 51.7435 (56.5570) nleep/row_min_mean 1459.6915 (1463.7284) lr 7.8853e-06 eta 0:00:01
epoch [50/50] batch [160/160] time 0.088 (0.095) data 0.000 (0.002) loss 1.3634 (1.4574) teacher_loss 0.2724 (0.2718) loss_zs_kd 0.0709 (0.0454) loss_oracle 0.5314 (0.5773) kd_loss 0.7898 (0.8743) acc 90.6250 (89.6875) gate/entropy 1.0256 (1.0256) gate/usage_max 0.4187 (0.4187) gate/usage_min 0.1639 (0.1638) gate/usage_std 0.1198 (0.1199) teacher/entropy 0.0980 (0.0519) teacher/usage_max 0.8279 (0.6905) teacher/usage_min 0.0159 (0.0575) teacher/usage_std 0.3544 (0.2691) nleep/row_max_mean 1480.4423 (1492.2039) nleep/row_max_std 68.7630 (56.9227) nleep/row_min_mean 1455.0809 (1463.7847) lr 1.9733e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,206
* correct: 1,848
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 85.5%
Evaluate on the *test* set
=> result
* total: 3,376
* correct: 2,964
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 88.7%
******* Domain p best val acc:      83.9%, epoch: 43 *******
******* Domain p best val test acc: 87.9%, epoch: 43 *******
******* Domain p best test acc:     89.0%, epoch: 2 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/p/seed_2/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:17:21

Loading trainer: TRIP
Loading dataset: SPG_VLCS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------------------------
Dataset    SPG_VLCS
Source     ['caltech', 'labelme', 'pascal']
Target     ['sun']
# classes  5
# train_x  5,213
# val      2,234
# test     3,282
---------  --------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_3/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_3/warmup_1/tensorboard)
epoch [1/50] batch [20/162] time 0.096 (0.134) data 0.000 (0.023) loss 0.9284 (1.1093) teacher_loss 0.5721 (0.6841) loss_zs_kd 0.0001 (0.0000) loss_oracle 0.0005 (0.0001) kd_loss 0.3560 (0.4251) acc 87.5000 (76.2500) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3295 (0.3295) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.7411 (0.6730) teacher/usage_max 0.4256 (0.4323) teacher/usage_min 0.2304 (0.2491) teacher/usage_std 0.0800 (0.0784) nleep/row_max_mean 1495.8486 (1504.3921) nleep/row_max_std 104.8424 (105.9466) nleep/row_min_mean 1493.4348 (1500.3673) lr 1.0000e-05 eta 0:18:06
epoch [1/50] batch [40/162] time 0.104 (0.118) data 0.000 (0.012) loss 0.4476 (0.9653) teacher_loss 0.2176 (0.6173) loss_zs_kd 0.0002 (0.0001) loss_oracle 0.0015 (0.0007) kd_loss 0.2292 (0.3476) acc 93.7500 (78.8281) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3294 (0.3295) gate/usage_std 0.0033 (0.0032) teacher/entropy 0.8692 (0.7505) teacher/usage_max 0.3752 (0.4165) teacher/usage_min 0.2933 (0.2572) teacher/usage_std 0.0335 (0.0680) nleep/row_max_mean 1510.2295 (1506.3473) nleep/row_max_std 94.8221 (101.5448) nleep/row_min_mean 1508.5571 (1503.3019) lr 1.0000e-05 eta 0:15:54
epoch [1/50] batch [60/162] time 0.104 (0.113) data 0.000 (0.008) loss 0.6078 (0.9135) teacher_loss 0.3627 (0.6025) loss_zs_kd 0.0000 (0.0002) loss_oracle 0.0026 (0.0013) kd_loss 0.2438 (0.3103) acc 93.7500 (79.0104) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3373 (0.3374) gate/usage_min 0.3295 (0.3295) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.8546 (0.7880) teacher/usage_max 0.4590 (0.4099) teacher/usage_min 0.2540 (0.2636) teacher/usage_std 0.0899 (0.0623) nleep/row_max_mean 1534.3221 (1506.1459) nleep/row_max_std 64.5605 (99.3085) nleep/row_min_mean 1532.4918 (1503.5190) lr 1.0000e-05 eta 0:15:10
epoch [1/50] batch [80/162] time 0.087 (0.109) data 0.000 (0.006) loss 0.7397 (0.8887) teacher_loss 0.5978 (0.6070) loss_zs_kd 0.0003 (0.0004) loss_oracle 0.0060 (0.0020) kd_loss 0.1388 (0.2805) acc 87.5000 (78.9453) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3295 (0.3295) gate/usage_std 0.0033 (0.0032) teacher/entropy 0.9599 (0.8179) teacher/usage_max 0.3455 (0.4026) teacher/usage_min 0.3263 (0.2689) teacher/usage_std 0.0086 (0.0569) nleep/row_max_mean 1503.5264 (1508.4395) nleep/row_max_std 94.5076 (93.7879) nleep/row_min_mean 1502.4250 (1506.0837) lr 1.0000e-05 eta 0:14:31
epoch [1/50] batch [100/162] time 0.096 (0.106) data 0.000 (0.005) loss 0.8098 (0.8595) teacher_loss 0.7091 (0.6032) loss_zs_kd 0.0004 (0.0005) loss_oracle 0.0069 (0.0029) kd_loss 0.0970 (0.2547) acc 75.0000 (79.1562) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3295 (0.3295) gate/usage_std 0.0033 (0.0032) teacher/entropy 1.0011 (0.8438) teacher/usage_max 0.3775 (0.3977) teacher/usage_min 0.2799 (0.2735) teacher/usage_std 0.0404 (0.0529) nleep/row_max_mean 1530.4829 (1510.0142) nleep/row_max_std 58.4510 (89.5433) nleep/row_min_mean 1529.5002 (1507.8719) lr 1.0000e-05 eta 0:14:07
epoch [1/50] batch [120/162] time 0.099 (0.105) data 0.000 (0.004) loss 0.9627 (0.8343) teacher_loss 0.8434 (0.5998) loss_zs_kd 0.0036 (0.0008) loss_oracle 0.0084 (0.0039) kd_loss 0.1134 (0.2321) acc 78.1250 (79.1146) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3294 (0.3295) gate/usage_std 0.0033 (0.0032) teacher/entropy 0.9851 (0.8665) teacher/usage_max 0.3761 (0.3932) teacher/usage_min 0.3005 (0.2779) teacher/usage_std 0.0317 (0.0491) nleep/row_max_mean 1533.3306 (1510.3767) nleep/row_max_std 45.5700 (86.9626) nleep/row_min_mean 1532.2556 (1508.4123) lr 1.0000e-05 eta 0:13:57
epoch [1/50] batch [140/162] time 0.089 (0.104) data 0.000 (0.003) loss 0.3499 (0.8100) teacher_loss 0.2892 (0.5943) loss_zs_kd 0.0016 (0.0010) loss_oracle 0.0113 (0.0050) kd_loss 0.0542 (0.2127) acc 81.2500 (79.0625) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3372 (0.3374) gate/usage_min 0.3296 (0.3295) gate/usage_std 0.0031 (0.0032) teacher/entropy 1.0445 (0.8860) teacher/usage_max 0.3682 (0.3890) teacher/usage_min 0.3136 (0.2814) teacher/usage_std 0.0247 (0.0458) nleep/row_max_mean 1537.0797 (1511.5924) nleep/row_max_std 56.0001 (84.2744) nleep/row_min_mean 1536.3802 (1509.7740) lr 1.0000e-05 eta 0:13:48
epoch [1/50] batch [160/162] time 0.087 (0.103) data 0.000 (0.003) loss 0.5655 (0.7876) teacher_loss 0.4524 (0.5869) loss_zs_kd 0.0024 (0.0012) loss_oracle 0.0144 (0.0059) kd_loss 0.1047 (0.1971) acc 84.3750 (79.1992) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3372 (0.3374) gate/usage_min 0.3297 (0.3295) gate/usage_std 0.0031 (0.0032) teacher/entropy 0.9948 (0.9016) teacher/usage_max 0.3718 (0.3860) teacher/usage_min 0.2857 (0.2837) teacher/usage_std 0.0358 (0.0435) nleep/row_max_mean 1528.5355 (1511.6083) nleep/row_max_std 47.2855 (82.3088) nleep/row_min_mean 1527.6123 (1509.9118) lr 1.0000e-05 eta 0:13:35
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,905
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 87.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,340
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 67.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      85.3%, epoch: 1 *******
******* Domain s best val test acc: 71.3%, epoch: 1 *******
******* Domain s best test acc:     71.3%, epoch: 1 *******
epoch [2/50] batch [20/162] time 0.094 (0.111) data 0.000 (0.014) loss 0.8020 (0.7667) teacher_loss 0.5122 (0.5348) loss_zs_kd 0.0023 (0.0112) loss_oracle 0.2984 (0.2610) kd_loss 0.1395 (0.0958) acc 78.1250 (80.7812) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3367 (0.3371) gate/usage_min 0.3302 (0.3298) gate/usage_std 0.0027 (0.0030) teacher/entropy 0.9574 (1.0030) teacher/usage_max 0.4130 (0.3603) teacher/usage_min 0.2422 (0.2998) teacher/usage_std 0.0702 (0.0257) nleep/row_max_mean 1505.4150 (1518.5732) nleep/row_max_std 72.3766 (64.4357) nleep/row_min_mean 1504.1414 (1517.6370) lr 2.0000e-03 eta 0:14:41
epoch [2/50] batch [40/162] time 0.149 (0.112) data 0.001 (0.007) loss 1.1356 (0.8730) teacher_loss 0.5180 (0.5164) loss_zs_kd 0.0151 (0.0109) loss_oracle 0.6001 (0.3593) kd_loss 0.3099 (0.1715) acc 81.2500 (82.1875) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3361 (0.3367) gate/usage_min 0.3313 (0.3303) gate/usage_std 0.0020 (0.0026) teacher/entropy 0.7891 (0.9267) teacher/usage_max 0.5002 (0.4043) teacher/usage_min 0.2418 (0.2569) teacher/usage_std 0.1182 (0.0626) nleep/row_max_mean 1517.0374 (1521.4878) nleep/row_max_std 71.5245 (62.4650) nleep/row_min_mean 1514.2170 (1519.9911) lr 2.0000e-03 eta 0:14:44
epoch [2/50] batch [60/162] time 0.097 (0.110) data 0.001 (0.005) loss 1.3170 (1.0084) teacher_loss 0.4376 (0.5031) loss_zs_kd 0.0098 (0.0121) loss_oracle 0.5503 (0.4376) kd_loss 0.5992 (0.2805) acc 81.2500 (82.3438) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3343 (0.3362) gate/usage_min 0.3320 (0.3307) gate/usage_std 0.0010 (0.0022) teacher/entropy 0.4979 (0.8179) teacher/usage_max 0.6791 (0.4883) teacher/usage_min 0.1532 (0.2231) teacher/usage_std 0.2446 (0.1180) nleep/row_max_mean 1509.2522 (1519.9939) nleep/row_max_std 70.8476 (63.0965) nleep/row_min_mean 1504.2139 (1517.7649) lr 2.0000e-03 eta 0:14:27
epoch [2/50] batch [80/162] time 0.105 (0.106) data 0.000 (0.004) loss 1.2686 (1.0923) teacher_loss 0.4089 (0.4839) loss_zs_kd 0.0238 (0.0143) loss_oracle 0.3608 (0.4613) kd_loss 0.6674 (0.3706) acc 84.3750 (82.6953) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3373 (0.3361) gate/usage_min 0.3304 (0.3310) gate/usage_std 0.0029 (0.0021) teacher/entropy 0.4260 (0.7268) teacher/usage_max 0.6323 (0.5438) teacher/usage_min 0.1742 (0.1936) teacher/usage_std 0.2115 (0.1560) nleep/row_max_mean 1529.0862 (1521.0416) nleep/row_max_std 51.3273 (62.4934) nleep/row_min_mean 1522.6897 (1518.0309) lr 2.0000e-03 eta 0:13:56
epoch [2/50] batch [100/162] time 0.099 (0.105) data 0.000 (0.003) loss 1.6047 (1.1545) teacher_loss 0.5202 (0.4757) loss_zs_kd 0.0328 (0.0156) loss_oracle 0.4421 (0.4554) kd_loss 0.8471 (0.4432) acc 71.8750 (82.9688) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3410 (0.3367) gate/usage_min 0.3271 (0.3305) gate/usage_std 0.0058 (0.0026) teacher/entropy 0.2355 (0.6521) teacher/usage_max 0.8114 (0.5899) teacher/usage_min 0.0755 (0.1730) teacher/usage_std 0.3384 (0.1873) nleep/row_max_mean 1539.8890 (1521.1131) nleep/row_max_std 58.4572 (62.7285) nleep/row_min_mean 1531.1246 (1517.2833) lr 2.0000e-03 eta 0:13:45
epoch [2/50] batch [120/162] time 0.087 (0.104) data 0.000 (0.003) loss 1.5727 (1.2356) teacher_loss 0.3610 (0.4803) loss_zs_kd 0.0049 (0.0165) loss_oracle 0.5508 (0.4614) kd_loss 0.9339 (0.5164) acc 90.6250 (82.8646) gate/entropy 1.0982 (1.0985) gate/usage_max 0.3462 (0.3378) gate/usage_min 0.3232 (0.3296) gate/usage_std 0.0096 (0.0034) teacher/entropy 0.1309 (0.5753) teacher/usage_max 0.9237 (0.6384) teacher/usage_min 0.0242 (0.1505) teacher/usage_std 0.4176 (0.2207) nleep/row_max_mean 1537.5560 (1521.0809) nleep/row_max_std 52.4710 (62.1691) nleep/row_min_mean 1526.3164 (1516.2899) lr 2.0000e-03 eta 0:13:31
epoch [2/50] batch [140/162] time 0.096 (0.102) data 0.000 (0.002) loss 1.6967 (1.3057) teacher_loss 0.4366 (0.4817) loss_zs_kd 0.0053 (0.0160) loss_oracle 0.5329 (0.4717) kd_loss 0.9910 (0.5801) acc 78.1250 (82.7679) gate/entropy 1.0977 (1.0985) gate/usage_max 0.3523 (0.3395) gate/usage_min 0.3190 (0.3284) gate/usage_std 0.0140 (0.0046) teacher/entropy 0.0552 (0.5062) teacher/usage_max 0.9676 (0.6845) teacher/usage_min 0.0082 (0.1305) teacher/usage_std 0.4485 (0.2526) nleep/row_max_mean 1534.5476 (1521.5800) nleep/row_max_std 59.7967 (62.1331) nleep/row_min_mean 1521.9033 (1515.7617) lr 2.0000e-03 eta 0:13:17
epoch [2/50] batch [160/162] time 0.088 (0.101) data 0.000 (0.002) loss 1.5672 (1.3568) teacher_loss 0.3225 (0.4806) loss_zs_kd 0.0057 (0.0154) loss_oracle 0.5396 (0.4789) kd_loss 0.9721 (0.6290) acc 84.3750 (82.5977) gate/entropy 1.0971 (1.0983) gate/usage_max 0.3584 (0.3415) gate/usage_min 0.3147 (0.3269) gate/usage_std 0.0184 (0.0061) teacher/entropy 0.0555 (0.4511) teacher/usage_max 0.9864 (0.7194) teacher/usage_min 0.0013 (0.1151) teacher/usage_std 0.4618 (0.2768) nleep/row_max_mean 1526.8828 (1522.1426) nleep/row_max_std 60.8725 (61.5367) nleep/row_min_mean 1513.3823 (1515.4029) lr 2.0000e-03 eta 0:13:04
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,943
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 88.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,453
* accuracy: 74.7%
* error: 25.3%
* macro_f1: 72.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      87.0%, epoch: 2 *******
******* Domain s best val test acc: 74.7%, epoch: 2 *******
******* Domain s best test acc:     74.7%, epoch: 2 *******
epoch [3/50] batch [20/162] time 0.105 (0.122) data 0.000 (0.016) loss 1.4391 (1.6982) teacher_loss 0.2330 (0.4667) loss_zs_kd 0.0121 (0.0094) loss_oracle 0.5672 (0.5587) kd_loss 0.9164 (0.9474) acc 93.7500 (82.9688) gate/entropy 1.0962 (1.0966) gate/usage_max 0.3649 (0.3621) gate/usage_min 0.3097 (0.3118) gate/usage_std 0.0232 (0.0211) teacher/entropy 0.1002 (0.0725) teacher/usage_max 0.9323 (0.9642) teacher/usage_min 0.0140 (0.0043) teacher/usage_std 0.4238 (0.4463) nleep/row_max_mean 1519.5198 (1530.0131) nleep/row_max_std 60.3882 (57.8830) nleep/row_min_mean 1504.9558 (1515.8688) lr 1.9980e-03 eta 0:15:48
epoch [3/50] batch [40/162] time 0.105 (0.113) data 0.000 (0.008) loss 1.7511 (1.6803) teacher_loss 0.5642 (0.4443) loss_zs_kd 0.0183 (0.0093) loss_oracle 0.5729 (0.5732) kd_loss 0.8912 (0.9448) acc 75.0000 (83.1250) gate/entropy 1.0953 (1.0962) gate/usage_max 0.3706 (0.3650) gate/usage_min 0.3053 (0.3096) gate/usage_std 0.0274 (0.0233) teacher/entropy 0.1088 (0.0676) teacher/usage_max 0.9460 (0.9642) teacher/usage_min 0.0003 (0.0024) teacher/usage_std 0.4338 (0.4464) nleep/row_max_mean 1515.6975 (1528.9445) nleep/row_max_std 62.5340 (57.2349) nleep/row_min_mean 1500.9165 (1514.4645) lr 1.9980e-03 eta 0:14:35
epoch [3/50] batch [60/162] time 0.106 (0.110) data 0.001 (0.005) loss 1.3922 (1.6665) teacher_loss 0.3402 (0.4420) loss_zs_kd 0.0081 (0.0088) loss_oracle 0.3338 (0.5844) kd_loss 0.8810 (0.9279) acc 93.7500 (82.8646) gate/entropy 1.0943 (1.0957) gate/usage_max 0.3755 (0.3677) gate/usage_min 0.3010 (0.3074) gate/usage_std 0.0312 (0.0253) teacher/entropy 0.1127 (0.0796) teacher/usage_max 0.9068 (0.9489) teacher/usage_min 0.0007 (0.0022) teacher/usage_std 0.4072 (0.4360) nleep/row_max_mean 1519.3098 (1526.7701) nleep/row_max_std 57.9047 (58.6446) nleep/row_min_mean 1505.8325 (1512.3998) lr 1.9980e-03 eta 0:14:07
epoch [3/50] batch [80/162] time 0.099 (0.106) data 0.000 (0.004) loss 1.5339 (1.6375) teacher_loss 0.5021 (0.4482) loss_zs_kd 0.0136 (0.0092) loss_oracle 0.4613 (0.5426) kd_loss 0.7943 (0.9134) acc 84.3750 (82.4219) gate/entropy 1.0931 (1.0952) gate/usage_max 0.3810 (0.3704) gate/usage_min 0.2971 (0.3053) gate/usage_std 0.0352 (0.0273) teacher/entropy 0.2118 (0.0913) teacher/usage_max 0.7709 (0.9238) teacher/usage_min 0.0282 (0.0023) teacher/usage_std 0.3173 (0.4196) nleep/row_max_mean 1513.2053 (1524.5120) nleep/row_max_std 66.2169 (59.3929) nleep/row_min_mean 1499.7384 (1510.1977) lr 1.9980e-03 eta 0:13:36
epoch [3/50] batch [100/162] time 0.097 (0.105) data 0.000 (0.003) loss 1.5544 (1.6243) teacher_loss 0.4271 (0.4472) loss_zs_kd 0.0034 (0.0091) loss_oracle 0.4222 (0.5262) kd_loss 0.9145 (0.9095) acc 87.5000 (82.5625) gate/entropy 1.0918 (1.0946) gate/usage_max 0.3863 (0.3731) gate/usage_min 0.2929 (0.3032) gate/usage_std 0.0391 (0.0293) teacher/entropy 0.0669 (0.0909) teacher/usage_max 0.8418 (0.9104) teacher/usage_min 0.0039 (0.0021) teacher/usage_std 0.3647 (0.4109) nleep/row_max_mean 1510.8218 (1523.6187) nleep/row_max_std 65.5900 (59.9819) nleep/row_min_mean 1495.9635 (1509.1057) lr 1.9980e-03 eta 0:13:26
epoch [3/50] batch [120/162] time 0.101 (0.104) data 0.000 (0.003) loss 1.3219 (1.6198) teacher_loss 0.1430 (0.4445) loss_zs_kd 0.0088 (0.0095) loss_oracle 0.4778 (0.5248) kd_loss 0.9356 (0.9081) acc 100.0000 (82.6823) gate/entropy 1.0905 (1.0941) gate/usage_max 0.3910 (0.3757) gate/usage_min 0.2891 (0.3011) gate/usage_std 0.0427 (0.0313) teacher/entropy 0.0419 (0.0879) teacher/usage_max 0.8099 (0.9006) teacher/usage_min 0.0002 (0.0018) teacher/usage_std 0.3458 (0.4045) nleep/row_max_mean 1507.1443 (1523.0598) nleep/row_max_std 68.9957 (60.7375) nleep/row_min_mean 1493.0532 (1508.3130) lr 1.9980e-03 eta 0:13:13
epoch [3/50] batch [140/162] time 0.092 (0.104) data 0.000 (0.002) loss 1.8153 (1.6046) teacher_loss 0.6795 (0.4373) loss_zs_kd 0.0135 (0.0103) loss_oracle 0.4197 (0.5082) kd_loss 0.9192 (0.9080) acc 75.0000 (83.2366) gate/entropy 1.0892 (1.0935) gate/usage_max 0.3956 (0.3782) gate/usage_min 0.2852 (0.2991) gate/usage_std 0.0462 (0.0332) teacher/entropy 0.0660 (0.0838) teacher/usage_max 0.7316 (0.8919) teacher/usage_min 0.0001 (0.0016) teacher/usage_std 0.3022 (0.3988) nleep/row_max_mean 1513.1307 (1521.9122) nleep/row_max_std 68.9454 (60.9393) nleep/row_min_mean 1498.4205 (1507.0713) lr 1.9980e-03 eta 0:13:12
epoch [3/50] batch [160/162] time 0.079 (0.106) data 0.000 (0.002) loss 1.3518 (1.5935) teacher_loss 0.2640 (0.4319) loss_zs_kd 0.0143 (0.0105) loss_oracle 0.4217 (0.4985) kd_loss 0.8698 (0.9071) acc 93.7500 (83.3984) gate/entropy 1.0878 (1.0928) gate/usage_max 0.3999 (0.3807) gate/usage_min 0.2818 (0.2972) gate/usage_std 0.0494 (0.0350) teacher/entropy 0.0656 (0.0810) teacher/usage_max 0.9189 (0.8831) teacher/usage_min 0.0002 (0.0016) teacher/usage_std 0.4154 (0.3931) nleep/row_max_mean 1537.0726 (1521.0964) nleep/row_max_std 55.3512 (60.8951) nleep/row_min_mean 1519.1353 (1506.1863) lr 1.9980e-03 eta 0:13:27
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,537
* accuracy: 77.3%
* error: 22.7%
* macro_f1: 74.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      87.0%, epoch: 2 *******
******* Domain s best val test acc: 74.7%, epoch: 2 *******
******* Domain s best test acc:     77.3%, epoch: 3 *******
epoch [4/50] batch [20/162] time 0.098 (0.111) data 0.000 (0.014) loss 1.6447 (1.5567) teacher_loss 0.4885 (0.4382) loss_zs_kd 0.0054 (0.0149) loss_oracle 0.4323 (0.4389) kd_loss 0.9373 (0.8916) acc 84.3750 (82.6562) gate/entropy 1.0861 (1.0868) gate/usage_max 0.4050 (0.4028) gate/usage_min 0.2779 (0.2795) gate/usage_std 0.0531 (0.0516) teacher/entropy 0.0053 (0.0521) teacher/usage_max 0.8437 (0.8561) teacher/usage_min 0.0002 (0.0002) teacher/usage_std 0.3664 (0.3759) nleep/row_max_mean 1523.9934 (1518.7321) nleep/row_max_std 60.6549 (61.2127) nleep/row_min_mean 1504.7759 (1501.5817) lr 1.9921e-03 eta 0:14:02
epoch [4/50] batch [40/162] time 0.099 (0.102) data 0.000 (0.007) loss 1.5934 (1.5475) teacher_loss 0.4955 (0.4259) loss_zs_kd 0.0346 (0.0160) loss_oracle 0.4415 (0.4341) kd_loss 0.8599 (0.8965) acc 81.2500 (83.0469) gate/entropy 1.0844 (1.0860) gate/usage_max 0.4099 (0.4053) gate/usage_min 0.2745 (0.2777) gate/usage_std 0.0567 (0.0533) teacher/entropy 0.0679 (0.0457) teacher/usage_max 0.8640 (0.8428) teacher/usage_min 0.0003 (0.0004) teacher/usage_std 0.3793 (0.3672) nleep/row_max_mean 1502.8052 (1518.0497) nleep/row_max_std 63.3097 (60.3759) nleep/row_min_mean 1485.6533 (1500.9047) lr 1.9921e-03 eta 0:12:53
epoch [4/50] batch [60/162] time 0.087 (0.099) data 0.001 (0.005) loss 1.4251 (1.5320) teacher_loss 0.3823 (0.4169) loss_zs_kd 0.0220 (0.0157) loss_oracle 0.4041 (0.4264) kd_loss 0.8298 (0.8941) acc 87.5000 (83.8542) gate/entropy 1.0827 (1.0852) gate/usage_max 0.4145 (0.4076) gate/usage_min 0.2711 (0.2761) gate/usage_std 0.0601 (0.0550) teacher/entropy 0.0949 (0.0460) teacher/usage_max 0.8426 (0.8340) teacher/usage_min 0.0005 (0.0007) teacher/usage_std 0.3657 (0.3619) nleep/row_max_mean 1521.4504 (1516.7095) nleep/row_max_std 63.6021 (62.7309) nleep/row_min_mean 1504.5598 (1499.6316) lr 1.9921e-03 eta 0:12:24
epoch [4/50] batch [80/162] time 0.088 (0.098) data 0.000 (0.004) loss 1.3027 (1.5238) teacher_loss 0.2388 (0.4067) loss_zs_kd 0.0091 (0.0156) loss_oracle 0.4025 (0.4387) kd_loss 0.8581 (0.8899) acc 87.5000 (84.1797) gate/entropy 1.0811 (1.0843) gate/usage_max 0.4186 (0.4099) gate/usage_min 0.2680 (0.2744) gate/usage_std 0.0631 (0.0567) teacher/entropy 0.0363 (0.0480) teacher/usage_max 0.9189 (0.8263) teacher/usage_min 0.0006 (0.0007) teacher/usage_std 0.4153 (0.3573) nleep/row_max_mean 1544.6826 (1516.3258) nleep/row_max_std 61.8733 (63.3839) nleep/row_min_mean 1526.7437 (1499.1639) lr 1.9921e-03 eta 0:12:16
epoch [4/50] batch [100/162] time 0.094 (0.098) data 0.000 (0.003) loss 1.4868 (1.5235) teacher_loss 0.3734 (0.4143) loss_zs_kd 0.0164 (0.0165) loss_oracle 0.4200 (0.4294) kd_loss 0.8952 (0.8862) acc 84.3750 (83.5625) gate/entropy 1.0794 (1.0835) gate/usage_max 0.4225 (0.4120) gate/usage_min 0.2650 (0.2728) gate/usage_std 0.0660 (0.0583) teacher/entropy 0.0149 (0.0477) teacher/usage_max 0.8403 (0.8262) teacher/usage_min 0.0002 (0.0009) teacher/usage_std 0.3643 (0.3571) nleep/row_max_mean 1525.4370 (1515.5549) nleep/row_max_std 57.0148 (63.1321) nleep/row_min_mean 1505.2046 (1498.2773) lr 1.9921e-03 eta 0:12:15
epoch [4/50] batch [120/162] time 0.111 (0.098) data 0.000 (0.003) loss 1.2547 (1.5081) teacher_loss 0.2315 (0.4071) loss_zs_kd 0.0109 (0.0158) loss_oracle 0.3608 (0.4221) kd_loss 0.8374 (0.8820) acc 87.5000 (83.9062) gate/entropy 1.0775 (1.0827) gate/usage_max 0.4271 (0.4142) gate/usage_min 0.2621 (0.2712) gate/usage_std 0.0692 (0.0599) teacher/entropy 0.0413 (0.0479) teacher/usage_max 0.9206 (0.8264) teacher/usage_min 0.0136 (0.0012) teacher/usage_std 0.4158 (0.3574) nleep/row_max_mean 1537.1116 (1516.5747) nleep/row_max_std 46.2733 (62.2991) nleep/row_min_mean 1517.9824 (1499.1378) lr 1.9921e-03 eta 0:12:17
epoch [4/50] batch [140/162] time 0.082 (0.098) data 0.000 (0.002) loss 1.5244 (1.5057) teacher_loss 0.4791 (0.4036) loss_zs_kd 0.0171 (0.0154) loss_oracle 0.4278 (0.4297) kd_loss 0.8229 (0.8795) acc 78.1250 (84.0179) gate/entropy 1.0760 (1.0818) gate/usage_max 0.4301 (0.4163) gate/usage_min 0.2593 (0.2697) gate/usage_std 0.0716 (0.0614) teacher/entropy 0.0527 (0.0486) teacher/usage_max 0.9032 (0.8203) teacher/usage_min 0.0003 (0.0014) teacher/usage_std 0.4049 (0.3539) nleep/row_max_mean 1536.5981 (1516.3674) nleep/row_max_std 48.6719 (62.3293) nleep/row_min_mean 1519.5070 (1499.0287) lr 1.9921e-03 eta 0:12:10
epoch [4/50] batch [160/162] time 0.086 (0.097) data 0.000 (0.002) loss 1.4984 (1.4997) teacher_loss 0.4280 (0.4022) loss_zs_kd 0.0219 (0.0151) loss_oracle 0.4627 (0.4274) kd_loss 0.8281 (0.8763) acc 81.2500 (83.9453) gate/entropy 1.0746 (1.0810) gate/usage_max 0.4331 (0.4182) gate/usage_min 0.2567 (0.2682) gate/usage_std 0.0738 (0.0628) teacher/entropy 0.0417 (0.0490) teacher/usage_max 0.9016 (0.8185) teacher/usage_min 0.0008 (0.0023) teacher/usage_std 0.4038 (0.3527) nleep/row_max_mean 1528.6323 (1516.1962) nleep/row_max_std 55.1293 (61.9705) nleep/row_min_mean 1510.5220 (1498.9194) lr 1.9921e-03 eta 0:12:01
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,951
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 89.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,521
* accuracy: 76.8%
* error: 23.2%
* macro_f1: 74.1%
******* Domain s best val acc:      87.3%, epoch: 4 *******
******* Domain s best val test acc: 76.8%, epoch: 4 *******
******* Domain s best test acc:     77.3%, epoch: 3 *******
epoch [5/50] batch [20/162] time 0.090 (0.115) data 0.000 (0.018) loss 1.2611 (1.4271) teacher_loss 0.1762 (0.3425) loss_zs_kd 0.0159 (0.0140) loss_oracle 0.4006 (0.4658) kd_loss 0.8767 (0.8447) acc 93.7500 (85.6250) gate/entropy 1.0729 (1.0737) gate/usage_max 0.4363 (0.4349) gate/usage_min 0.2536 (0.2550) gate/usage_std 0.0763 (0.0752) teacher/entropy 0.0393 (0.0542) teacher/usage_max 0.7600 (0.8081) teacher/usage_min 0.0213 (0.0058) teacher/usage_std 0.3123 (0.3456) nleep/row_max_mean 1516.6575 (1516.0628) nleep/row_max_std 61.9392 (57.9780) nleep/row_min_mean 1498.5947 (1498.8991) lr 1.9823e-03 eta 0:14:14
epoch [5/50] batch [40/162] time 0.087 (0.103) data 0.000 (0.009) loss 1.4305 (1.4225) teacher_loss 0.3767 (0.3471) loss_zs_kd 0.0117 (0.0150) loss_oracle 0.4338 (0.4446) kd_loss 0.8310 (0.8456) acc 81.2500 (86.0938) gate/entropy 1.0714 (1.0729) gate/usage_max 0.4393 (0.4364) gate/usage_min 0.2513 (0.2537) gate/usage_std 0.0786 (0.0764) teacher/entropy 0.0280 (0.0525) teacher/usage_max 0.8968 (0.8029) teacher/usage_min 0.0007 (0.0065) teacher/usage_std 0.4006 (0.3420) nleep/row_max_mean 1521.6610 (1513.9952) nleep/row_max_std 54.7923 (59.0044) nleep/row_min_mean 1501.5842 (1496.3208) lr 1.9823e-03 eta 0:12:40
epoch [5/50] batch [60/162] time 0.107 (0.109) data 0.001 (0.006) loss 1.2952 (1.4334) teacher_loss 0.2919 (0.3637) loss_zs_kd 0.0178 (0.0147) loss_oracle 0.4182 (0.4408) kd_loss 0.7852 (0.8419) acc 93.7500 (85.3125) gate/entropy 1.0692 (1.0720) gate/usage_max 0.4438 (0.4382) gate/usage_min 0.2485 (0.2524) gate/usage_std 0.0817 (0.0777) teacher/entropy 0.0730 (0.0495) teacher/usage_max 0.8744 (0.8132) teacher/usage_min 0.0002 (0.0062) teacher/usage_std 0.3860 (0.3485) nleep/row_max_mean 1526.4176 (1515.3440) nleep/row_max_std 62.2814 (58.7630) nleep/row_min_mean 1508.5898 (1497.0858) lr 1.9823e-03 eta 0:13:24
epoch [5/50] batch [80/162] time 0.099 (0.104) data 0.000 (0.005) loss 1.4630 (1.4321) teacher_loss 0.4807 (0.3676) loss_zs_kd 0.0145 (0.0149) loss_oracle 0.3258 (0.4375) kd_loss 0.8123 (0.8384) acc 78.1250 (85.0000) gate/entropy 1.0675 (1.0711) gate/usage_max 0.4469 (0.4400) gate/usage_min 0.2461 (0.2511) gate/usage_std 0.0841 (0.0790) teacher/entropy 0.0800 (0.0542) teacher/usage_max 0.7857 (0.8027) teacher/usage_min 0.0286 (0.0070) teacher/usage_std 0.3263 (0.3425) nleep/row_max_mean 1529.7827 (1514.0736) nleep/row_max_std 61.0434 (59.4397) nleep/row_min_mean 1509.7976 (1495.6295) lr 1.9823e-03 eta 0:12:43
epoch [5/50] batch [100/162] time 0.094 (0.101) data 0.000 (0.004) loss 1.4988 (1.4324) teacher_loss 0.4065 (0.3688) loss_zs_kd 0.0129 (0.0156) loss_oracle 0.5325 (0.4436) kd_loss 0.8196 (0.8341) acc 75.0000 (85.2812) gate/entropy 1.0658 (1.0702) gate/usage_max 0.4500 (0.4416) gate/usage_min 0.2438 (0.2499) gate/usage_std 0.0864 (0.0802) teacher/entropy 0.0446 (0.0552) teacher/usage_max 0.8325 (0.8047) teacher/usage_min 0.0037 (0.0078) teacher/usage_std 0.3590 (0.3434) nleep/row_max_mean 1524.1909 (1515.1380) nleep/row_max_std 62.5265 (59.0741) nleep/row_min_mean 1505.4447 (1496.4529) lr 1.9823e-03 eta 0:12:25
epoch [5/50] batch [120/162] time 0.105 (0.101) data 0.000 (0.003) loss 1.3682 (1.4412) teacher_loss 0.2452 (0.3726) loss_zs_kd 0.0147 (0.0153) loss_oracle 0.4962 (0.4517) kd_loss 0.8676 (0.8351) acc 90.6250 (85.1042) gate/entropy 1.0643 (1.0694) gate/usage_max 0.4525 (0.4432) gate/usage_min 0.2417 (0.2487) gate/usage_std 0.0883 (0.0814) teacher/entropy 0.0552 (0.0528) teacher/usage_max 0.6705 (0.8013) teacher/usage_min 0.0024 (0.0071) teacher/usage_std 0.2728 (0.3418) nleep/row_max_mean 1508.7838 (1515.4661) nleep/row_max_std 70.1526 (59.0238) nleep/row_min_mean 1489.8059 (1496.5982) lr 1.9823e-03 eta 0:12:19
epoch [5/50] batch [140/162] time 0.099 (0.100) data 0.000 (0.003) loss 1.3644 (1.4303) teacher_loss 0.3268 (0.3646) loss_zs_kd 0.0247 (0.0158) loss_oracle 0.4387 (0.4488) kd_loss 0.8058 (0.8334) acc 84.3750 (85.5804) gate/entropy 1.0626 (1.0685) gate/usage_max 0.4554 (0.4447) gate/usage_min 0.2394 (0.2475) gate/usage_std 0.0904 (0.0825) teacher/entropy 0.0725 (0.0527) teacher/usage_max 0.7705 (0.7993) teacher/usage_min 0.0012 (0.0071) teacher/usage_std 0.3227 (0.3406) nleep/row_max_mean 1525.1589 (1516.3103) nleep/row_max_std 59.3283 (58.8770) nleep/row_min_mean 1503.5393 (1497.1760) lr 1.9823e-03 eta 0:12:14
epoch [5/50] batch [160/162] time 0.085 (0.099) data 0.000 (0.002) loss 1.3236 (1.4294) teacher_loss 0.2645 (0.3637) loss_zs_kd 0.0259 (0.0169) loss_oracle 0.3907 (0.4500) kd_loss 0.8508 (0.8323) acc 90.6250 (85.6055) gate/entropy 1.0614 (1.0677) gate/usage_max 0.4573 (0.4462) gate/usage_min 0.2376 (0.2464) gate/usage_std 0.0919 (0.0836) teacher/entropy 0.0072 (0.0527) teacher/usage_max 0.8135 (0.7962) teacher/usage_min 0.0002 (0.0072) teacher/usage_std 0.3479 (0.3388) nleep/row_max_mean 1529.4587 (1516.4729) nleep/row_max_std 58.9268 (58.7171) nleep/row_min_mean 1507.3716 (1497.1119) lr 1.9823e-03 eta 0:12:04
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,612
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 75.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      87.3%, epoch: 4 *******
******* Domain s best val test acc: 76.8%, epoch: 4 *******
******* Domain s best test acc:     79.6%, epoch: 5 *******
epoch [6/50] batch [20/162] time 0.099 (0.113) data 0.000 (0.014) loss 1.2624 (1.4315) teacher_loss 0.1864 (0.3780) loss_zs_kd 0.0177 (0.0230) loss_oracle 0.5487 (0.4586) kd_loss 0.7928 (0.8127) acc 93.7500 (84.0625) gate/entropy 1.0597 (1.0604) gate/usage_max 0.4603 (0.4592) gate/usage_min 0.2356 (0.2364) gate/usage_std 0.0940 (0.0932) teacher/entropy 0.0759 (0.0553) teacher/usage_max 0.7899 (0.7876) teacher/usage_min 0.0202 (0.0091) teacher/usage_std 0.3302 (0.3325) nleep/row_max_mean 1503.8816 (1518.3123) nleep/row_max_std 50.6607 (56.7902) nleep/row_min_mean 1484.4244 (1497.1357) lr 1.9686e-03 eta 0:13:38
epoch [6/50] batch [40/162] time 0.093 (0.107) data 0.000 (0.007) loss 1.3435 (1.4288) teacher_loss 0.2573 (0.3427) loss_zs_kd 0.0110 (0.0217) loss_oracle 0.5259 (0.4989) kd_loss 0.8177 (0.8258) acc 93.7500 (85.6250) gate/entropy 1.0583 (1.0597) gate/usage_max 0.4623 (0.4603) gate/usage_min 0.2335 (0.2354) gate/usage_std 0.0956 (0.0941) teacher/entropy 0.0674 (0.0490) teacher/usage_max 0.7374 (0.7645) teacher/usage_min 0.0123 (0.0054) teacher/usage_std 0.3018 (0.3208) nleep/row_max_mean 1529.4668 (1519.0956) nleep/row_max_std 53.5324 (56.8059) nleep/row_min_mean 1507.9116 (1497.4093) lr 1.9686e-03 eta 0:12:52
epoch [6/50] batch [60/162] time 0.087 (0.102) data 0.001 (0.005) loss 1.5545 (1.4523) teacher_loss 0.3093 (0.3469) loss_zs_kd 0.0323 (0.0225) loss_oracle 0.6668 (0.5168) kd_loss 0.8956 (0.8358) acc 87.5000 (85.2604) gate/entropy 1.0572 (1.0590) gate/usage_max 0.4636 (0.4612) gate/usage_min 0.2314 (0.2344) gate/usage_std 0.0969 (0.0948) teacher/entropy 0.0354 (0.0445) teacher/usage_max 0.6118 (0.7467) teacher/usage_min 0.0000 (0.0037) teacher/usage_std 0.2528 (0.3125) nleep/row_max_mean 1502.2766 (1518.8223) nleep/row_max_std 61.1011 (57.4950) nleep/row_min_mean 1480.1049 (1496.6505) lr 1.9686e-03 eta 0:12:16
epoch [6/50] batch [80/162] time 0.089 (0.099) data 0.000 (0.004) loss 1.5755 (1.4773) teacher_loss 0.2810 (0.3555) loss_zs_kd 0.0188 (0.0215) loss_oracle 0.8328 (0.5454) kd_loss 0.8686 (0.8384) acc 90.6250 (85.4688) gate/entropy 1.0568 (1.0586) gate/usage_max 0.4632 (0.4617) gate/usage_min 0.2294 (0.2335) gate/usage_std 0.0972 (0.0953) teacher/entropy 0.1112 (0.0511) teacher/usage_max 0.5152 (0.7210) teacher/usage_min 0.0000 (0.0028) teacher/usage_std 0.2360 (0.3018) nleep/row_max_mean 1507.9196 (1519.3524) nleep/row_max_std 65.5530 (57.9273) nleep/row_min_mean 1484.3552 (1496.6865) lr 1.9686e-03 eta 0:11:56
epoch [6/50] batch [100/162] time 0.099 (0.098) data 0.000 (0.003) loss 1.6915 (1.5051) teacher_loss 0.4608 (0.3615) loss_zs_kd 0.0271 (0.0207) loss_oracle 0.6809 (0.5774) kd_loss 0.8768 (0.8446) acc 81.2500 (85.3125) gate/entropy 1.0570 (1.0582) gate/usage_max 0.4611 (0.4618) gate/usage_min 0.2271 (0.2324) gate/usage_std 0.0967 (0.0957) teacher/entropy 0.1227 (0.0620) teacher/usage_max 0.5770 (0.6894) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.2439 (0.2901) nleep/row_max_mean 1517.3425 (1519.0110) nleep/row_max_std 66.1660 (58.2159) nleep/row_min_mean 1490.3066 (1495.8999) lr 1.9686e-03 eta 0:11:47
epoch [6/50] batch [120/162] time 0.082 (0.098) data 0.000 (0.003) loss 1.2198 (1.5213) teacher_loss 0.2686 (0.3645) loss_zs_kd 0.0117 (0.0202) loss_oracle 0.4331 (0.5830) kd_loss 0.7288 (0.8552) acc 90.6250 (85.4688) gate/entropy 1.0575 (1.0581) gate/usage_max 0.4575 (0.4614) gate/usage_min 0.2246 (0.2313) gate/usage_std 0.0957 (0.0958) teacher/entropy 0.2162 (0.0703) teacher/usage_max 0.5525 (0.6830) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.2396 (0.2876) nleep/row_max_mean 1544.1250 (1519.0006) nleep/row_max_std 51.0375 (58.3832) nleep/row_min_mean 1516.6147 (1495.2624) lr 1.9686e-03 eta 0:11:44
epoch [6/50] batch [140/162] time 0.090 (0.097) data 0.000 (0.002) loss 1.6539 (1.5457) teacher_loss 0.3925 (0.3802) loss_zs_kd 0.0127 (0.0199) loss_oracle 0.6142 (0.5839) kd_loss 0.9480 (0.8636) acc 87.5000 (84.9777) gate/entropy 1.0582 (1.0581) gate/usage_max 0.4529 (0.4605) gate/usage_min 0.2221 (0.2302) gate/usage_std 0.0944 (0.0956) teacher/entropy 0.1367 (0.0769) teacher/usage_max 0.8825 (0.6858) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.3912 (0.2886) nleep/row_max_mean 1525.9600 (1519.1309) nleep/row_max_std 57.6207 (58.8365) nleep/row_min_mean 1498.3684 (1494.8806) lr 1.9686e-03 eta 0:11:32
epoch [6/50] batch [160/162] time 0.081 (0.095) data 0.000 (0.002) loss 1.4878 (1.5487) teacher_loss 0.3388 (0.3808) loss_zs_kd 0.0233 (0.0199) loss_oracle 0.4898 (0.5785) kd_loss 0.8924 (0.8686) acc 81.2500 (85.0586) gate/entropy 1.0586 (1.0581) gate/usage_max 0.4480 (0.4592) gate/usage_min 0.2193 (0.2290) gate/usage_std 0.0934 (0.0954) teacher/entropy 0.1333 (0.0823) teacher/usage_max 0.7483 (0.6902) teacher/usage_min 0.0000 (0.0014) teacher/usage_std 0.3109 (0.2898) nleep/row_max_mean 1538.0466 (1519.6791) nleep/row_max_std 59.8384 (58.5944) nleep/row_min_mean 1508.5112 (1494.9693) lr 1.9686e-03 eta 0:11:20
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,924
* accuracy: 86.1%
* error: 13.9%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,383
* accuracy: 72.6%
* error: 27.4%
* macro_f1: 71.9%
******* Domain s best val acc:      87.3%, epoch: 4 *******
******* Domain s best val test acc: 76.8%, epoch: 4 *******
******* Domain s best test acc:     79.6%, epoch: 5 *******
epoch [7/50] batch [20/162] time 0.096 (0.106) data 0.000 (0.012) loss 1.4604 (1.5234) teacher_loss 0.3783 (0.3745) loss_zs_kd 0.0192 (0.0167) loss_oracle 0.5082 (0.5183) kd_loss 0.8184 (0.8815) acc 84.3750 (85.6250) gate/entropy 1.0588 (1.0588) gate/usage_max 0.4430 (0.4450) gate/usage_min 0.2164 (0.2178) gate/usage_std 0.0926 (0.0928) teacher/entropy 0.1369 (0.1152) teacher/usage_max 0.5374 (0.6737) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2377 (0.2817) nleep/row_max_mean 1533.6864 (1522.1717) nleep/row_max_std 51.4535 (56.4952) nleep/row_min_mean 1506.7480 (1494.8353) lr 1.9511e-03 eta 0:12:35
epoch [7/50] batch [40/162] time 0.092 (0.101) data 0.000 (0.006) loss 1.5499 (1.5356) teacher_loss 0.3102 (0.3679) loss_zs_kd 0.0378 (0.0180) loss_oracle 0.5896 (0.5382) kd_loss 0.9260 (0.8896) acc 87.5000 (86.3281) gate/entropy 1.0590 (1.0588) gate/usage_max 0.4383 (0.4429) gate/usage_min 0.2145 (0.2166) gate/usage_std 0.0919 (0.0926) teacher/entropy 0.0693 (0.1077) teacher/usage_max 0.7318 (0.6973) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3023 (0.2903) nleep/row_max_mean 1534.0773 (1522.9608) nleep/row_max_std 47.5743 (55.6237) nleep/row_min_mean 1509.4628 (1495.8989) lr 1.9511e-03 eta 0:11:56
epoch [7/50] batch [60/162] time 0.096 (0.098) data 0.001 (0.004) loss 1.6976 (1.5378) teacher_loss 0.4581 (0.3753) loss_zs_kd 0.0082 (0.0171) loss_oracle 0.6113 (0.5324) kd_loss 0.9298 (0.8878) acc 81.2500 (85.8854) gate/entropy 1.0584 (1.0587) gate/usage_max 0.4344 (0.4407) gate/usage_min 0.2115 (0.2153) gate/usage_std 0.0922 (0.0924) teacher/entropy 0.0501 (0.1034) teacher/usage_max 0.7147 (0.6959) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2937 (0.2898) nleep/row_max_mean 1510.4277 (1522.6490) nleep/row_max_std 66.3154 (56.1954) nleep/row_min_mean 1482.8921 (1495.9467) lr 1.9511e-03 eta 0:11:33
epoch [7/50] batch [80/162] time 0.094 (0.097) data 0.000 (0.003) loss 1.5780 (1.5670) teacher_loss 0.3786 (0.3939) loss_zs_kd 0.0277 (0.0194) loss_oracle 0.6322 (0.5567) kd_loss 0.8694 (0.8850) acc 84.3750 (85.4297) gate/entropy 1.0578 (1.0586) gate/usage_max 0.4303 (0.4386) gate/usage_min 0.2090 (0.2140) gate/usage_std 0.0924 (0.0924) teacher/entropy 0.1129 (0.1007) teacher/usage_max 0.7895 (0.6941) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3338 (0.2891) nleep/row_max_mean 1499.7537 (1522.4745) nleep/row_max_std 59.7384 (56.7310) nleep/row_min_mean 1473.4070 (1495.9067) lr 1.9511e-03 eta 0:11:24
epoch [7/50] batch [100/162] time 0.103 (0.097) data 0.000 (0.003) loss 1.3876 (1.5631) teacher_loss 0.2519 (0.3928) loss_zs_kd 0.0146 (0.0193) loss_oracle 0.4750 (0.5561) kd_loss 0.8909 (0.8826) acc 87.5000 (85.5312) gate/entropy 1.0573 (1.0584) gate/usage_max 0.4256 (0.4364) gate/usage_min 0.2067 (0.2128) gate/usage_std 0.0926 (0.0924) teacher/entropy 0.0726 (0.0995) teacher/usage_max 0.7464 (0.7029) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3099 (0.2931) nleep/row_max_mean 1520.3806 (1522.2494) nleep/row_max_std 59.4831 (57.1015) nleep/row_min_mean 1495.7594 (1495.7200) lr 1.9511e-03 eta 0:11:23
epoch [7/50] batch [120/162] time 0.098 (0.097) data 0.001 (0.002) loss 1.5895 (1.5484) teacher_loss 0.4275 (0.3882) loss_zs_kd 0.0249 (0.0199) loss_oracle 0.5661 (0.5470) kd_loss 0.8665 (0.8767) acc 78.1250 (85.9375) gate/entropy 1.0567 (1.0581) gate/usage_max 0.4222 (0.4343) gate/usage_min 0.2049 (0.2116) gate/usage_std 0.0930 (0.0925) teacher/entropy 0.0696 (0.0992) teacher/usage_max 0.5946 (0.6943) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2480 (0.2895) nleep/row_max_mean 1514.6587 (1522.1580) nleep/row_max_std 59.0419 (57.3142) nleep/row_min_mean 1488.0964 (1495.7727) lr 1.9511e-03 eta 0:11:20
epoch [7/50] batch [140/162] time 0.100 (0.097) data 0.000 (0.002) loss 1.5981 (1.5398) teacher_loss 0.4454 (0.3886) loss_zs_kd 0.0314 (0.0200) loss_oracle 0.5171 (0.5403) kd_loss 0.8783 (0.8711) acc 84.3750 (86.0268) gate/entropy 1.0556 (1.0578) gate/usage_max 0.4198 (0.4324) gate/usage_min 0.2026 (0.2104) gate/usage_std 0.0940 (0.0927) teacher/entropy 0.0512 (0.0986) teacher/usage_max 0.5799 (0.6786) teacher/usage_min 0.0002 (0.0001) teacher/usage_std 0.2444 (0.2838) nleep/row_max_mean 1513.3033 (1522.4692) nleep/row_max_std 62.4075 (57.5888) nleep/row_min_mean 1489.0874 (1496.3444) lr 1.9511e-03 eta 0:11:18
epoch [7/50] batch [160/162] time 0.086 (0.097) data 0.000 (0.002) loss 1.3938 (1.5225) teacher_loss 0.3153 (0.3749) loss_zs_kd 0.0384 (0.0208) loss_oracle 0.4281 (0.5371) kd_loss 0.8453 (0.8687) acc 87.5000 (86.5430) gate/entropy 1.0547 (1.0575) gate/usage_max 0.4179 (0.4307) gate/usage_min 0.2010 (0.2093) gate/usage_std 0.0948 (0.0929) teacher/entropy 0.0730 (0.0958) teacher/usage_max 0.5021 (0.6659) teacher/usage_min 0.0001 (0.0005) teacher/usage_std 0.2357 (0.2791) nleep/row_max_mean 1525.2280 (1522.2571) nleep/row_max_std 46.9554 (57.8706) nleep/row_min_mean 1502.7529 (1496.4037) lr 1.9511e-03 eta 0:11:13
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,955
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 89.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,474
* accuracy: 75.4%
* error: 24.6%
* macro_f1: 74.4%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     79.6%, epoch: 5 *******
epoch [8/50] batch [20/162] time 0.079 (0.120) data 0.000 (0.017) loss 1.4765 (1.4022) teacher_loss 0.3066 (0.2618) loss_zs_kd 0.0291 (0.0291) loss_oracle 0.5645 (0.5243) kd_loss 0.8732 (0.8637) acc 93.7500 (90.6250) gate/entropy 1.0536 (1.0540) gate/usage_max 0.4164 (0.4170) gate/usage_min 0.1990 (0.1997) gate/usage_std 0.0959 (0.0955) teacher/entropy 0.0429 (0.0594) teacher/usage_max 0.5023 (0.5669) teacher/usage_min 0.0000 (0.0042) teacher/usage_std 0.2357 (0.2417) nleep/row_max_mean 1542.1250 (1522.9824) nleep/row_max_std 48.8041 (57.2982) nleep/row_min_mean 1516.7599 (1499.1715) lr 1.9298e-03 eta 0:13:53
epoch [8/50] batch [40/162] time 0.094 (0.107) data 0.000 (0.009) loss 1.3645 (1.4217) teacher_loss 0.1847 (0.2743) loss_zs_kd 0.0194 (0.0301) loss_oracle 0.5899 (0.5254) kd_loss 0.8751 (0.8696) acc 93.7500 (90.7031) gate/entropy 1.0527 (1.0536) gate/usage_max 0.4155 (0.4164) gate/usage_min 0.1976 (0.1990) gate/usage_std 0.0967 (0.0959) teacher/entropy 0.0489 (0.0508) teacher/usage_max 0.6390 (0.5793) teacher/usage_min 0.0004 (0.0033) teacher/usage_std 0.2614 (0.2459) nleep/row_max_mean 1508.5261 (1522.6540) nleep/row_max_std 63.5425 (58.2347) nleep/row_min_mean 1485.6382 (1498.8130) lr 1.9298e-03 eta 0:12:23
epoch [8/50] batch [60/162] time 0.103 (0.100) data 0.001 (0.006) loss 1.4071 (1.4197) teacher_loss 0.2560 (0.2643) loss_zs_kd 0.0400 (0.0313) loss_oracle 0.5509 (0.5341) kd_loss 0.8556 (0.8726) acc 93.7500 (91.6146) gate/entropy 1.0516 (1.0531) gate/usage_max 0.4149 (0.4159) gate/usage_min 0.1960 (0.1982) gate/usage_std 0.0977 (0.0963) teacher/entropy 0.0568 (0.0465) teacher/usage_max 0.5120 (0.5753) teacher/usage_min 0.0001 (0.0037) teacher/usage_std 0.2358 (0.2445) nleep/row_max_mean 1515.5649 (1521.9120) nleep/row_max_std 62.4521 (58.6879) nleep/row_min_mean 1492.9562 (1498.1291) lr 1.9298e-03 eta 0:11:33
epoch [8/50] batch [80/162] time 0.147 (0.099) data 0.000 (0.004) loss 1.3085 (1.4051) teacher_loss 0.1670 (0.2442) loss_zs_kd 0.0571 (0.0331) loss_oracle 0.5245 (0.5440) kd_loss 0.8506 (0.8723) acc 93.7500 (92.0312) gate/entropy 1.0509 (1.0527) gate/usage_max 0.4147 (0.4156) gate/usage_min 0.1948 (0.1975) gate/usage_std 0.0984 (0.0968) teacher/entropy 0.0546 (0.0459) teacher/usage_max 0.5786 (0.5726) teacher/usage_min 0.0001 (0.0045) teacher/usage_std 0.2442 (0.2436) nleep/row_max_mean 1532.5748 (1523.1185) nleep/row_max_std 49.5777 (57.8968) nleep/row_min_mean 1507.7905 (1499.1489) lr 1.9298e-03 eta 0:11:22
epoch [8/50] batch [100/162] time 0.089 (0.102) data 0.000 (0.004) loss 1.3024 (1.4022) teacher_loss 0.1661 (0.2407) loss_zs_kd 0.0177 (0.0340) loss_oracle 0.5475 (0.5463) kd_loss 0.8536 (0.8713) acc 93.7500 (92.1562) gate/entropy 1.0501 (1.0522) gate/usage_max 0.4145 (0.4154) gate/usage_min 0.1937 (0.1969) gate/usage_std 0.0992 (0.0972) teacher/entropy 0.0678 (0.0455) teacher/usage_max 0.6639 (0.5745) teacher/usage_min 0.0049 (0.0046) teacher/usage_std 0.2690 (0.2444) nleep/row_max_mean 1498.0776 (1522.6558) nleep/row_max_std 53.4629 (57.9657) nleep/row_min_mean 1477.5061 (1498.6301) lr 1.9298e-03 eta 0:11:42
epoch [8/50] batch [120/162] time 0.090 (0.100) data 0.000 (0.003) loss 1.4756 (1.3971) teacher_loss 0.2664 (0.2354) loss_zs_kd 0.0530 (0.0338) loss_oracle 0.5930 (0.5448) kd_loss 0.8862 (0.8724) acc 90.6250 (92.4479) gate/entropy 1.0491 (1.0518) gate/usage_max 0.4145 (0.4153) gate/usage_min 0.1923 (0.1962) gate/usage_std 0.1001 (0.0976) teacher/entropy 0.0500 (0.0445) teacher/usage_max 0.6055 (0.5755) teacher/usage_min 0.0311 (0.0062) teacher/usage_std 0.2355 (0.2438) nleep/row_max_mean 1516.4033 (1522.1789) nleep/row_max_std 60.7057 (57.7769) nleep/row_min_mean 1491.7686 (1498.0716) lr 1.9298e-03 eta 0:11:21
epoch [8/50] batch [140/162] time 0.092 (0.098) data 0.000 (0.003) loss 1.2978 (1.3889) teacher_loss 0.1298 (0.2275) loss_zs_kd 0.0279 (0.0356) loss_oracle 0.5520 (0.5471) kd_loss 0.8781 (0.8700) acc 96.8750 (92.8571) gate/entropy 1.0484 (1.0514) gate/usage_max 0.4147 (0.4151) gate/usage_min 0.1913 (0.1956) gate/usage_std 0.1008 (0.0980) teacher/entropy 0.0621 (0.0466) teacher/usage_max 0.5106 (0.5751) teacher/usage_min 0.0439 (0.0077) teacher/usage_std 0.2064 (0.2431) nleep/row_max_mean 1520.1553 (1522.1191) nleep/row_max_std 69.2183 (57.7471) nleep/row_min_mean 1496.6042 (1498.0521) lr 1.9298e-03 eta 0:11:10
epoch [8/50] batch [160/162] time 0.086 (0.097) data 0.000 (0.002) loss 1.3153 (1.3907) teacher_loss 0.1430 (0.2288) loss_zs_kd 0.0445 (0.0360) loss_oracle 0.5655 (0.5472) kd_loss 0.8673 (0.8703) acc 93.7500 (92.8125) gate/entropy 1.0479 (1.0510) gate/usage_max 0.4145 (0.4151) gate/usage_min 0.1906 (0.1951) gate/usage_std 0.1012 (0.0983) teacher/entropy 0.0485 (0.0468) teacher/usage_max 0.7560 (0.5757) teacher/usage_min 0.0324 (0.0097) teacher/usage_std 0.3077 (0.2425) nleep/row_max_mean 1532.9004 (1521.6719) nleep/row_max_std 52.0294 (58.1923) nleep/row_min_mean 1504.6654 (1497.5895) lr 1.9298e-03 eta 0:11:02
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,918
* accuracy: 85.9%
* error: 14.1%
* macro_f1: 88.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,692
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 76.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [9/50] batch [20/162] time 0.093 (0.111) data 0.000 (0.021) loss 1.2456 (1.3718) teacher_loss 0.0716 (0.1893) loss_zs_kd 0.0433 (0.0405) loss_oracle 0.5680 (0.5895) kd_loss 0.8683 (0.8674) acc 96.8750 (92.6562) gate/entropy 1.0473 (1.0474) gate/usage_max 0.4149 (0.4148) gate/usage_min 0.1899 (0.1899) gate/usage_std 0.1017 (0.1017) teacher/entropy 0.0271 (0.0511) teacher/usage_max 0.6759 (0.5708) teacher/usage_min 0.0001 (0.0230) teacher/usage_std 0.2760 (0.2336) nleep/row_max_mean 1524.1162 (1515.8032) nleep/row_max_std 55.0402 (60.6611) nleep/row_min_mean 1497.4425 (1491.7503) lr 1.9048e-03 eta 0:12:29
epoch [9/50] batch [40/162] time 0.084 (0.102) data 0.000 (0.011) loss 1.4651 (1.3927) teacher_loss 0.2939 (0.2147) loss_zs_kd 0.0545 (0.0408) loss_oracle 0.5519 (0.5940) kd_loss 0.8680 (0.8606) acc 90.6250 (92.1094) gate/entropy 1.0463 (1.0470) gate/usage_max 0.4152 (0.4150) gate/usage_min 0.1885 (0.1895) gate/usage_std 0.1027 (0.1020) teacher/entropy 0.0874 (0.0624) teacher/usage_max 0.5462 (0.5827) teacher/usage_min 0.0738 (0.0298) teacher/usage_std 0.1957 (0.2337) nleep/row_max_mean 1502.2615 (1515.0326) nleep/row_max_std 60.1314 (61.0256) nleep/row_min_mean 1478.5161 (1490.6518) lr 1.9048e-03 eta 0:11:32
epoch [9/50] batch [60/162] time 0.104 (0.101) data 0.001 (0.007) loss 1.2895 (1.3829) teacher_loss 0.1716 (0.2114) loss_zs_kd 0.0297 (0.0382) loss_oracle 0.5333 (0.5888) kd_loss 0.8364 (0.8579) acc 96.8750 (92.3438) gate/entropy 1.0457 (1.0467) gate/usage_max 0.4156 (0.4151) gate/usage_min 0.1877 (0.1890) gate/usage_std 0.1033 (0.1024) teacher/entropy 0.0877 (0.0629) teacher/usage_max 0.5824 (0.5845) teacher/usage_min 0.0365 (0.0283) teacher/usage_std 0.2254 (0.2349) nleep/row_max_mean 1511.0984 (1516.4153) nleep/row_max_std 64.9711 (60.4060) nleep/row_min_mean 1488.0281 (1491.7354) lr 1.9048e-03 eta 0:11:18
epoch [9/50] batch [80/162] time 0.097 (0.099) data 0.000 (0.005) loss 1.3112 (1.3883) teacher_loss 0.1158 (0.2160) loss_zs_kd 0.0281 (0.0398) loss_oracle 0.6173 (0.5896) kd_loss 0.8727 (0.8576) acc 96.8750 (92.6172) gate/entropy 1.0451 (1.0464) gate/usage_max 0.4162 (0.4153) gate/usage_min 0.1870 (0.1886) gate/usage_std 0.1038 (0.1027) teacher/entropy 0.0202 (0.0608) teacher/usage_max 0.6595 (0.5937) teacher/usage_min 0.0004 (0.0264) teacher/usage_std 0.2691 (0.2384) nleep/row_max_mean 1508.8802 (1515.9452) nleep/row_max_std 59.3222 (59.9422) nleep/row_min_mean 1484.3018 (1490.9078) lr 1.9048e-03 eta 0:11:04
epoch [9/50] batch [100/162] time 0.097 (0.098) data 0.000 (0.004) loss 1.3929 (1.3817) teacher_loss 0.2328 (0.2157) loss_zs_kd 0.0210 (0.0393) loss_oracle 0.5311 (0.5826) kd_loss 0.8840 (0.8551) acc 90.6250 (92.3125) gate/entropy 1.0444 (1.0460) gate/usage_max 0.4169 (0.4156) gate/usage_min 0.1861 (0.1881) gate/usage_std 0.1045 (0.1030) teacher/entropy 0.0701 (0.0611) teacher/usage_max 0.5525 (0.5995) teacher/usage_min 0.0760 (0.0247) teacher/usage_std 0.1964 (0.2411) nleep/row_max_mean 1497.7014 (1516.4501) nleep/row_max_std 65.1127 (60.0901) nleep/row_min_mean 1473.8967 (1491.2525) lr 1.9048e-03 eta 0:10:59
epoch [9/50] batch [120/162] time 0.082 (0.099) data 0.000 (0.004) loss 1.5392 (1.3819) teacher_loss 0.3167 (0.2165) loss_zs_kd 0.0539 (0.0391) loss_oracle 0.6481 (0.5815) kd_loss 0.8715 (0.8551) acc 93.7500 (92.3958) gate/entropy 1.0438 (1.0457) gate/usage_max 0.4177 (0.4159) gate/usage_min 0.1853 (0.1877) gate/usage_std 0.1050 (0.1033) teacher/entropy 0.0307 (0.0596) teacher/usage_max 0.5945 (0.6027) teacher/usage_min 0.0113 (0.0237) teacher/usage_std 0.2420 (0.2429) nleep/row_max_mean 1509.3950 (1515.8865) nleep/row_max_std 64.1904 (60.4270) nleep/row_min_mean 1479.2352 (1490.5255) lr 1.9048e-03 eta 0:10:58
epoch [9/50] batch [140/162] time 0.101 (0.098) data 0.000 (0.003) loss 1.6101 (1.3830) teacher_loss 0.4599 (0.2192) loss_zs_kd 0.0371 (0.0393) loss_oracle 0.5789 (0.5818) kd_loss 0.8422 (0.8532) acc 81.2500 (92.5446) gate/entropy 1.0432 (1.0454) gate/usage_max 0.4185 (0.4162) gate/usage_min 0.1846 (0.1874) gate/usage_std 0.1056 (0.1035) teacher/entropy 0.0493 (0.0599) teacher/usage_max 0.6259 (0.6063) teacher/usage_min 0.0010 (0.0226) teacher/usage_std 0.2567 (0.2446) nleep/row_max_mean 1526.1731 (1515.5754) nleep/row_max_std 58.1397 (60.6396) nleep/row_min_mean 1496.7681 (1490.0097) lr 1.9048e-03 eta 0:10:54
epoch [9/50] batch [160/162] time 0.090 (0.098) data 0.000 (0.003) loss 1.2822 (1.3882) teacher_loss 0.1397 (0.2256) loss_zs_kd 0.0502 (0.0395) loss_oracle 0.4988 (0.5806) kd_loss 0.8680 (0.8525) acc 96.8750 (92.2852) gate/entropy 1.0428 (1.0451) gate/usage_max 0.4192 (0.4165) gate/usage_min 0.1841 (0.1870) gate/usage_std 0.1059 (0.1038) teacher/entropy 0.0103 (0.0602) teacher/usage_max 0.8419 (0.6092) teacher/usage_min 0.0001 (0.0229) teacher/usage_std 0.3653 (0.2457) nleep/row_max_mean 1524.5468 (1515.0251) nleep/row_max_std 61.3916 (61.2157) nleep/row_min_mean 1494.2729 (1489.3466) lr 1.9048e-03 eta 0:10:49
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,925
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 88.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,648
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 75.3%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [10/50] batch [20/162] time 0.172 (0.140) data 0.000 (0.016) loss 1.2619 (1.3972) teacher_loss 0.0661 (0.2387) loss_zs_kd 0.0340 (0.0395) loss_oracle 0.6113 (0.5762) kd_loss 0.8731 (0.8506) acc 100.0000 (92.1875) gate/entropy 1.0421 (1.0423) gate/usage_max 0.4204 (0.4199) gate/usage_min 0.1833 (0.1836) gate/usage_std 0.1065 (0.1063) teacher/entropy 0.0145 (0.0521) teacher/usage_max 0.6577 (0.6754) teacher/usage_min 0.0014 (0.0200) teacher/usage_std 0.2680 (0.2719) nleep/row_max_mean 1522.1067 (1516.1460) nleep/row_max_std 50.8845 (61.8425) nleep/row_min_mean 1492.5632 (1488.0133) lr 1.8763e-03 eta 0:15:25
epoch [10/50] batch [40/162] time 0.214 (0.163) data 0.000 (0.008) loss 1.5138 (1.3948) teacher_loss 0.3438 (0.2397) loss_zs_kd 0.0236 (0.0377) loss_oracle 0.6462 (0.5698) kd_loss 0.8351 (0.8514) acc 81.2500 (91.7969) gate/entropy 1.0414 (1.0421) gate/usage_max 0.4214 (0.4204) gate/usage_min 0.1825 (0.1834) gate/usage_std 0.1072 (0.1065) teacher/entropy 0.0753 (0.0563) teacher/usage_max 0.6425 (0.6608) teacher/usage_min 0.0314 (0.0269) teacher/usage_std 0.2495 (0.2641) nleep/row_max_mean 1524.4454 (1513.7362) nleep/row_max_std 60.0941 (61.7981) nleep/row_min_mean 1496.3344 (1486.2068) lr 1.8763e-03 eta 0:17:58
epoch [10/50] batch [60/162] time 0.196 (0.171) data 0.001 (0.005) loss 1.4190 (1.3903) teacher_loss 0.2862 (0.2388) loss_zs_kd 0.0400 (0.0392) loss_oracle 0.4843 (0.5645) kd_loss 0.8706 (0.8496) acc 87.5000 (91.5104) gate/entropy 1.0410 (1.0419) gate/usage_max 0.4221 (0.4208) gate/usage_min 0.1821 (0.1831) gate/usage_std 0.1075 (0.1067) teacher/entropy 0.0333 (0.0566) teacher/usage_max 0.7245 (0.6616) teacher/usage_min 0.0303 (0.0258) teacher/usage_std 0.2902 (0.2650) nleep/row_max_mean 1514.8608 (1513.6807) nleep/row_max_std 66.7825 (62.1574) nleep/row_min_mean 1486.8833 (1485.9038) lr 1.8763e-03 eta 0:18:48
epoch [10/50] batch [80/162] time 0.172 (0.176) data 0.000 (0.004) loss 1.3363 (1.3813) teacher_loss 0.1542 (0.2361) loss_zs_kd 0.0380 (0.0379) loss_oracle 0.6308 (0.5565) kd_loss 0.8476 (0.8481) acc 96.8750 (91.4062) gate/entropy 1.0406 (1.0416) gate/usage_max 0.4229 (0.4212) gate/usage_min 0.1815 (0.1828) gate/usage_std 0.1079 (0.1070) teacher/entropy 0.0475 (0.0582) teacher/usage_max 0.5426 (0.6622) teacher/usage_min 0.0053 (0.0268) teacher/usage_std 0.2349 (0.2650) nleep/row_max_mean 1500.0057 (1512.9214) nleep/row_max_std 74.1306 (62.1164) nleep/row_min_mean 1472.1816 (1485.3179) lr 1.8763e-03 eta 0:19:12
epoch [10/50] batch [100/162] time 0.187 (0.178) data 0.000 (0.003) loss 1.4318 (1.3758) teacher_loss 0.2980 (0.2353) loss_zs_kd 0.0275 (0.0369) loss_oracle 0.5708 (0.5514) kd_loss 0.8347 (0.8463) acc 90.6250 (91.4688) gate/entropy 1.0403 (1.0414) gate/usage_max 0.4237 (0.4216) gate/usage_min 0.1812 (0.1825) gate/usage_std 0.1082 (0.1072) teacher/entropy 0.0598 (0.0589) teacher/usage_max 0.6630 (0.6660) teacher/usage_min 0.0159 (0.0264) teacher/usage_std 0.2643 (0.2662) nleep/row_max_mean 1510.3689 (1513.3333) nleep/row_max_std 55.3548 (61.7116) nleep/row_min_mean 1484.5712 (1485.8167) lr 1.8763e-03 eta 0:19:22
epoch [10/50] batch [120/162] time 0.195 (0.179) data 0.000 (0.003) loss 1.3766 (1.3868) teacher_loss 0.2457 (0.2454) loss_zs_kd 0.0249 (0.0371) loss_oracle 0.4673 (0.5497) kd_loss 0.8848 (0.8479) acc 87.5000 (90.7812) gate/entropy 1.0400 (1.0412) gate/usage_max 0.4248 (0.4221) gate/usage_min 0.1810 (0.1822) gate/usage_std 0.1085 (0.1074) teacher/entropy 0.0358 (0.0587) teacher/usage_max 0.7226 (0.6710) teacher/usage_min 0.0558 (0.0294) teacher/usage_std 0.2835 (0.2673) nleep/row_max_mean 1512.8733 (1513.3626) nleep/row_max_std 53.8486 (61.3316) nleep/row_min_mean 1485.9180 (1485.7865) lr 1.8763e-03 eta 0:19:27
epoch [10/50] batch [140/162] time 0.189 (0.180) data 0.000 (0.002) loss 1.4931 (1.3902) teacher_loss 0.3053 (0.2503) loss_zs_kd 0.0242 (0.0368) loss_oracle 0.5656 (0.5493) kd_loss 0.8928 (0.8469) acc 87.5000 (90.5804) gate/entropy 1.0394 (1.0410) gate/usage_max 0.4261 (0.4226) gate/usage_min 0.1803 (0.1820) gate/usage_std 0.1090 (0.1076) teacher/entropy 0.0601 (0.0601) teacher/usage_max 0.6616 (0.6760) teacher/usage_min 0.0946 (0.0310) teacher/usage_std 0.2400 (0.2693) nleep/row_max_mean 1509.9495 (1513.3263) nleep/row_max_std 64.2798 (60.8313) nleep/row_min_mean 1481.6045 (1485.7349) lr 1.8763e-03 eta 0:19:32
epoch [10/50] batch [160/162] time 0.193 (0.182) data 0.000 (0.002) loss 1.4602 (1.3889) teacher_loss 0.3372 (0.2491) loss_zs_kd 0.0574 (0.0365) loss_oracle 0.4319 (0.5496) kd_loss 0.8783 (0.8467) acc 81.2500 (90.6055) gate/entropy 1.0391 (1.0408) gate/usage_max 0.4272 (0.4231) gate/usage_min 0.1801 (0.1818) gate/usage_std 0.1093 (0.1078) teacher/entropy 0.0284 (0.0593) teacher/usage_max 0.8153 (0.6806) teacher/usage_min 0.0522 (0.0310) teacher/usage_std 0.3424 (0.2716) nleep/row_max_mean 1514.8040 (1513.0049) nleep/row_max_std 61.1136 (60.4984) nleep/row_min_mean 1486.1127 (1485.2466) lr 1.8763e-03 eta 0:19:37
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,914
* accuracy: 85.7%
* error: 14.3%
* macro_f1: 88.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,658
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 77.2%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [11/50] batch [20/162] time 0.114 (0.109) data 0.000 (0.015) loss 1.3159 (1.3515) teacher_loss 0.1714 (0.2032) loss_zs_kd 0.0286 (0.0362) loss_oracle 0.5254 (0.5434) kd_loss 0.8674 (0.8585) acc 90.6250 (92.3438) gate/entropy 1.0387 (1.0390) gate/usage_max 0.4284 (0.4278) gate/usage_min 0.1797 (0.1800) gate/usage_std 0.1097 (0.1094) teacher/entropy 0.0229 (0.0423) teacher/usage_max 0.7827 (0.7358) teacher/usage_min 0.0301 (0.0365) teacher/usage_std 0.3241 (0.2987) nleep/row_max_mean 1524.7820 (1515.5368) nleep/row_max_std 53.9815 (56.9401) nleep/row_min_mean 1494.0493 (1485.4983) lr 1.8443e-03 eta 0:11:44
epoch [11/50] batch [40/162] time 0.202 (0.145) data 0.000 (0.008) loss 1.4495 (1.3708) teacher_loss 0.2833 (0.2321) loss_zs_kd 0.0261 (0.0361) loss_oracle 0.5946 (0.5234) kd_loss 0.8558 (0.8590) acc 93.7500 (90.8594) gate/entropy 1.0386 (1.0389) gate/usage_max 0.4297 (0.4284) gate/usage_min 0.1797 (0.1799) gate/usage_std 0.1098 (0.1095) teacher/entropy 0.0257 (0.0426) teacher/usage_max 0.6875 (0.7463) teacher/usage_min 0.0095 (0.0396) teacher/usage_std 0.2776 (0.3034) nleep/row_max_mean 1512.1631 (1514.7665) nleep/row_max_std 60.7619 (57.7160) nleep/row_min_mean 1479.9595 (1484.3293) lr 1.8443e-03 eta 0:15:31
epoch [11/50] batch [60/162] time 0.146 (0.161) data 0.001 (0.005) loss 1.3572 (1.3841) teacher_loss 0.2096 (0.2468) loss_zs_kd 0.0380 (0.0369) loss_oracle 0.5744 (0.5212) kd_loss 0.8413 (0.8583) acc 93.7500 (90.3646) gate/entropy 1.0383 (1.0387) gate/usage_max 0.4311 (0.4291) gate/usage_min 0.1795 (0.1798) gate/usage_std 0.1101 (0.1097) teacher/entropy 0.0684 (0.0455) teacher/usage_max 0.6679 (0.7462) teacher/usage_min 0.0448 (0.0434) teacher/usage_std 0.2565 (0.3024) nleep/row_max_mean 1504.9423 (1514.0288) nleep/row_max_std 61.8787 (58.1666) nleep/row_min_mean 1473.9418 (1483.5706) lr 1.8443e-03 eta 0:17:13
epoch [11/50] batch [80/162] time 0.193 (0.157) data 0.000 (0.004) loss 1.5807 (1.3862) teacher_loss 0.4705 (0.2539) loss_zs_kd 0.0421 (0.0352) loss_oracle 0.5310 (0.5185) kd_loss 0.8237 (0.8554) acc 84.3750 (90.1562) gate/entropy 1.0383 (1.0386) gate/usage_max 0.4323 (0.4298) gate/usage_min 0.1796 (0.1797) gate/usage_std 0.1102 (0.1098) teacher/entropy 0.0309 (0.0463) teacher/usage_max 0.8561 (0.7474) teacher/usage_min 0.0007 (0.0421) teacher/usage_std 0.3742 (0.3044) nleep/row_max_mean 1522.1693 (1513.4621) nleep/row_max_std 52.3460 (58.4627) nleep/row_min_mean 1487.4578 (1482.8273) lr 1.8443e-03 eta 0:16:43
epoch [11/50] batch [100/162] time 0.194 (0.156) data 0.000 (0.003) loss 1.4527 (1.3872) teacher_loss 0.3424 (0.2598) loss_zs_kd 0.0302 (0.0349) loss_oracle 0.5181 (0.5156) kd_loss 0.8362 (0.8522) acc 84.3750 (89.7812) gate/entropy 1.0380 (1.0385) gate/usage_max 0.4334 (0.4304) gate/usage_min 0.1795 (0.1797) gate/usage_std 0.1104 (0.1099) teacher/entropy 0.0542 (0.0458) teacher/usage_max 0.7671 (0.7478) teacher/usage_min 0.0367 (0.0384) teacher/usage_std 0.3135 (0.3051) nleep/row_max_mean 1508.0933 (1512.3275) nleep/row_max_std 60.7737 (59.0508) nleep/row_min_mean 1475.6993 (1481.5632) lr 1.8443e-03 eta 0:16:36
epoch [11/50] batch [120/162] time 0.163 (0.158) data 0.000 (0.003) loss 1.3746 (1.3860) teacher_loss 0.2375 (0.2609) loss_zs_kd 0.0439 (0.0348) loss_oracle 0.4997 (0.5141) kd_loss 0.8653 (0.8506) acc 87.5000 (89.5833) gate/entropy 1.0374 (1.0384) gate/usage_max 0.4345 (0.4310) gate/usage_min 0.1789 (0.1796) gate/usage_std 0.1110 (0.1100) teacher/entropy 0.0254 (0.0467) teacher/usage_max 0.7502 (0.7465) teacher/usage_min 0.0369 (0.0386) teacher/usage_std 0.3034 (0.3041) nleep/row_max_mean 1517.5818 (1512.2654) nleep/row_max_std 64.8895 (59.3830) nleep/row_min_mean 1486.4335 (1481.5000) lr 1.8443e-03 eta 0:16:47
epoch [11/50] batch [140/162] time 0.159 (0.162) data 0.001 (0.002) loss 1.3466 (1.3849) teacher_loss 0.2467 (0.2610) loss_zs_kd 0.0331 (0.0355) loss_oracle 0.5402 (0.5138) kd_loss 0.8133 (0.8492) acc 90.6250 (89.5089) gate/entropy 1.0374 (1.0382) gate/usage_max 0.4357 (0.4316) gate/usage_min 0.1790 (0.1795) gate/usage_std 0.1111 (0.1102) teacher/entropy 0.0498 (0.0466) teacher/usage_max 0.8809 (0.7496) teacher/usage_min 0.0227 (0.0381) teacher/usage_std 0.3884 (0.3060) nleep/row_max_mean 1525.5371 (1512.6168) nleep/row_max_std 50.5821 (59.3599) nleep/row_min_mean 1493.2786 (1481.6493) lr 1.8443e-03 eta 0:17:08
epoch [11/50] batch [160/162] time 0.196 (0.166) data 0.000 (0.002) loss 1.4804 (1.3830) teacher_loss 0.4023 (0.2612) loss_zs_kd 0.0484 (0.0355) loss_oracle 0.5725 (0.5155) kd_loss 0.7677 (0.8464) acc 84.3750 (89.6094) gate/entropy 1.0372 (1.0381) gate/usage_max 0.4369 (0.4322) gate/usage_min 0.1789 (0.1794) gate/usage_std 0.1113 (0.1103) teacher/entropy 0.0957 (0.0475) teacher/usage_max 0.7627 (0.7502) teacher/usage_min 0.0065 (0.0365) teacher/usage_std 0.3171 (0.3065) nleep/row_max_mean 1502.8286 (1512.7417) nleep/row_max_std 53.6272 (59.4675) nleep/row_min_mean 1470.9547 (1481.6713) lr 1.8443e-03 eta 0:17:28
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,913
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 88.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,623
* accuracy: 79.9%
* error: 20.1%
* macro_f1: 74.9%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [12/50] batch [20/162] time 0.167 (0.201) data 0.000 (0.012) loss 1.3419 (1.3769) teacher_loss 0.2559 (0.2612) loss_zs_kd 0.0378 (0.0355) loss_oracle 0.5511 (0.5248) kd_loss 0.7915 (0.8355) acc 87.5000 (89.3750) gate/entropy 1.0369 (1.0371) gate/usage_max 0.4382 (0.4377) gate/usage_min 0.1788 (0.1789) gate/usage_std 0.1116 (0.1114) teacher/entropy 0.0638 (0.0337) teacher/usage_max 0.8552 (0.7641) teacher/usage_min 0.0140 (0.0154) teacher/usage_std 0.3721 (0.3181) nleep/row_max_mean 1535.4863 (1516.2756) nleep/row_max_std 44.3428 (56.8283) nleep/row_min_mean 1497.6975 (1482.6575) lr 1.8090e-03 eta 0:21:05
epoch [12/50] batch [40/162] time 0.196 (0.194) data 0.000 (0.006) loss 1.4381 (1.3694) teacher_loss 0.3118 (0.2553) loss_zs_kd 0.0330 (0.0348) loss_oracle 0.5906 (0.5270) kd_loss 0.8146 (0.8332) acc 87.5000 (90.0781) gate/entropy 1.0368 (1.0370) gate/usage_max 0.4392 (0.4382) gate/usage_min 0.1788 (0.1789) gate/usage_std 0.1117 (0.1115) teacher/entropy 0.0655 (0.0325) teacher/usage_max 0.7550 (0.7665) teacher/usage_min 0.0314 (0.0122) teacher/usage_std 0.3073 (0.3197) nleep/row_max_mean 1502.3245 (1516.2494) nleep/row_max_std 53.2067 (57.1096) nleep/row_min_mean 1471.0138 (1482.0846) lr 1.8090e-03 eta 0:20:16
epoch [12/50] batch [60/162] time 0.196 (0.188) data 0.001 (0.004) loss 1.2365 (1.3587) teacher_loss 0.1834 (0.2530) loss_zs_kd 0.0350 (0.0353) loss_oracle 0.4745 (0.5216) kd_loss 0.7984 (0.8273) acc 90.6250 (90.0000) gate/entropy 1.0365 (1.0369) gate/usage_max 0.4404 (0.4387) gate/usage_min 0.1786 (0.1788) gate/usage_std 0.1120 (0.1116) teacher/entropy 0.0442 (0.0360) teacher/usage_max 0.8531 (0.7695) teacher/usage_min 0.0018 (0.0105) teacher/usage_std 0.3721 (0.3230) nleep/row_max_mean 1521.2615 (1515.6768) nleep/row_max_std 54.5934 (56.6417) nleep/row_min_mean 1490.0281 (1481.7391) lr 1.8090e-03 eta 0:19:33
epoch [12/50] batch [80/162] time 0.168 (0.187) data 0.000 (0.003) loss 1.2682 (1.3611) teacher_loss 0.2455 (0.2613) loss_zs_kd 0.0376 (0.0346) loss_oracle 0.4255 (0.5175) kd_loss 0.7912 (0.8237) acc 87.5000 (89.4141) gate/entropy 1.0364 (1.0368) gate/usage_max 0.4415 (0.4393) gate/usage_min 0.1787 (0.1788) gate/usage_std 0.1122 (0.1117) teacher/entropy 0.0629 (0.0395) teacher/usage_max 0.7919 (0.7680) teacher/usage_min 0.0072 (0.0111) teacher/usage_std 0.3338 (0.3216) nleep/row_max_mean 1510.7183 (1514.2490) nleep/row_max_std 54.2904 (57.3504) nleep/row_min_mean 1478.0963 (1480.7119) lr 1.8090e-03 eta 0:19:23
epoch [12/50] batch [100/162] time 0.080 (0.170) data 0.000 (0.003) loss 1.3853 (1.3540) teacher_loss 0.2934 (0.2563) loss_zs_kd 0.0311 (0.0340) loss_oracle 0.4883 (0.5164) kd_loss 0.8322 (0.8225) acc 87.5000 (89.7812) gate/entropy 1.0363 (1.0367) gate/usage_max 0.4426 (0.4399) gate/usage_min 0.1789 (0.1788) gate/usage_std 0.1123 (0.1119) teacher/entropy 0.0076 (0.0383) teacher/usage_max 0.8418 (0.7734) teacher/usage_min 0.0001 (0.0098) teacher/usage_std 0.3653 (0.3250) nleep/row_max_mean 1517.2397 (1514.7172) nleep/row_max_std 60.3317 (57.3049) nleep/row_min_mean 1484.4575 (1481.0952) lr 1.8090e-03 eta 0:17:34
epoch [12/50] batch [120/162] time 0.198 (0.173) data 0.000 (0.002) loss 1.2305 (1.3572) teacher_loss 0.1638 (0.2634) loss_zs_kd 0.0221 (0.0330) loss_oracle 0.5165 (0.5118) kd_loss 0.7974 (0.8214) acc 93.7500 (89.5052) gate/entropy 1.0360 (1.0366) gate/usage_max 0.4440 (0.4404) gate/usage_min 0.1787 (0.1788) gate/usage_std 0.1127 (0.1120) teacher/entropy 0.0668 (0.0384) teacher/usage_max 0.6806 (0.7761) teacher/usage_min 0.0008 (0.0098) teacher/usage_std 0.2777 (0.3265) nleep/row_max_mean 1492.4729 (1514.3945) nleep/row_max_std 65.2632 (57.7151) nleep/row_min_mean 1461.7948 (1480.9905) lr 1.8090e-03 eta 0:17:51
epoch [12/50] batch [140/162] time 0.125 (0.174) data 0.000 (0.002) loss 1.4911 (1.3575) teacher_loss 0.3819 (0.2661) loss_zs_kd 0.0435 (0.0328) loss_oracle 0.5486 (0.5103) kd_loss 0.8131 (0.8199) acc 84.3750 (89.4196) gate/entropy 1.0358 (1.0365) gate/usage_max 0.4452 (0.4410) gate/usage_min 0.1788 (0.1788) gate/usage_std 0.1129 (0.1121) teacher/entropy 0.0494 (0.0388) teacher/usage_max 0.6850 (0.7764) teacher/usage_min 0.0002 (0.0094) teacher/usage_std 0.2799 (0.3269) nleep/row_max_mean 1494.6016 (1513.8016) nleep/row_max_std 62.3438 (58.1386) nleep/row_min_mean 1466.0060 (1480.5790) lr 1.8090e-03 eta 0:17:57
epoch [12/50] batch [160/162] time 0.227 (0.171) data 0.000 (0.002) loss 1.1800 (1.3580) teacher_loss 0.0868 (0.2684) loss_zs_kd 0.0297 (0.0329) loss_oracle 0.5125 (0.5078) kd_loss 0.8221 (0.8192) acc 100.0000 (89.2969) gate/entropy 1.0357 (1.0364) gate/usage_max 0.4462 (0.4416) gate/usage_min 0.1789 (0.1788) gate/usage_std 0.1130 (0.1122) teacher/entropy 0.0443 (0.0384) teacher/usage_max 0.6596 (0.7758) teacher/usage_min 0.0007 (0.0087) teacher/usage_std 0.2690 (0.3270) nleep/row_max_mean 1502.7015 (1513.7289) nleep/row_max_std 65.1260 (58.5318) nleep/row_min_mean 1471.5850 (1480.6201) lr 1.8090e-03 eta 0:17:35
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,922
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 88.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,664
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 74.5%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [13/50] batch [20/162] time 0.199 (0.210) data 0.000 (0.018) loss 1.4392 (1.3323) teacher_loss 0.3529 (0.2605) loss_zs_kd 0.0227 (0.0356) loss_oracle 0.4904 (0.4914) kd_loss 0.8297 (0.8083) acc 81.2500 (89.5312) gate/entropy 1.0358 (1.0357) gate/usage_max 0.4475 (0.4468) gate/usage_min 0.1792 (0.1789) gate/usage_std 0.1131 (0.1131) teacher/entropy 0.0234 (0.0341) teacher/usage_max 0.7284 (0.8023) teacher/usage_min 0.0003 (0.0026) teacher/usage_std 0.3004 (0.3424) nleep/row_max_mean 1495.8712 (1515.8223) nleep/row_max_std 59.3376 (58.2211) nleep/row_min_mean 1464.9878 (1483.8922) lr 1.7705e-03 eta 0:21:26
epoch [13/50] batch [40/162] time 0.188 (0.198) data 0.000 (0.009) loss 1.2035 (1.3425) teacher_loss 0.0826 (0.2570) loss_zs_kd 0.0302 (0.0361) loss_oracle 0.6202 (0.5116) kd_loss 0.7957 (0.8117) acc 100.0000 (90.0000) gate/entropy 1.0356 (1.0356) gate/usage_max 0.4487 (0.4475) gate/usage_min 0.1794 (0.1790) gate/usage_std 0.1133 (0.1132) teacher/entropy 0.0528 (0.0327) teacher/usage_max 0.7471 (0.7949) teacher/usage_min 0.0000 (0.0046) teacher/usage_std 0.3103 (0.3379) nleep/row_max_mean 1506.0970 (1514.4526) nleep/row_max_std 63.6011 (57.5618) nleep/row_min_mean 1476.1476 (1482.6941) lr 1.7705e-03 eta 0:20:10
epoch [13/50] batch [60/162] time 0.173 (0.194) data 0.001 (0.006) loss 1.2334 (1.3453) teacher_loss 0.1072 (0.2596) loss_zs_kd 0.0295 (0.0375) loss_oracle 0.5649 (0.5162) kd_loss 0.8290 (0.8089) acc 93.7500 (89.8438) gate/entropy 1.0354 (1.0356) gate/usage_max 0.4502 (0.4482) gate/usage_min 0.1795 (0.1791) gate/usage_std 0.1136 (0.1133) teacher/entropy 0.0158 (0.0353) teacher/usage_max 0.7762 (0.7961) teacher/usage_min 0.0046 (0.0056) teacher/usage_std 0.3252 (0.3386) nleep/row_max_mean 1513.8964 (1514.5020) nleep/row_max_std 59.7333 (58.0270) nleep/row_min_mean 1481.7666 (1482.9344) lr 1.7705e-03 eta 0:19:43
epoch [13/50] batch [80/162] time 0.196 (0.192) data 0.000 (0.005) loss 1.5124 (1.3541) teacher_loss 0.4176 (0.2651) loss_zs_kd 0.0384 (0.0378) loss_oracle 0.5483 (0.5180) kd_loss 0.8014 (0.8111) acc 81.2500 (89.5312) gate/entropy 1.0351 (1.0355) gate/usage_max 0.4515 (0.4488) gate/usage_min 0.1794 (0.1792) gate/usage_std 0.1140 (0.1134) teacher/entropy 0.0457 (0.0338) teacher/usage_max 0.7430 (0.7929) teacher/usage_min 0.0005 (0.0068) teacher/usage_std 0.3080 (0.3366) nleep/row_max_mean 1510.3662 (1514.1316) nleep/row_max_std 70.4121 (57.9903) nleep/row_min_mean 1479.9880 (1482.5244) lr 1.7705e-03 eta 0:19:27
epoch [13/50] batch [100/162] time 0.197 (0.191) data 0.000 (0.004) loss 1.2749 (1.3548) teacher_loss 0.2397 (0.2671) loss_zs_kd 0.0240 (0.0367) loss_oracle 0.4668 (0.5188) kd_loss 0.7898 (0.8099) acc 93.7500 (89.4375) gate/entropy 1.0351 (1.0354) gate/usage_max 0.4528 (0.4495) gate/usage_min 0.1797 (0.1793) gate/usage_std 0.1141 (0.1135) teacher/entropy 0.0356 (0.0336) teacher/usage_max 0.8417 (0.7933) teacher/usage_min 0.0003 (0.0062) teacher/usage_std 0.3652 (0.3371) nleep/row_max_mean 1528.3971 (1514.3892) nleep/row_max_std 50.7753 (58.3635) nleep/row_min_mean 1496.8534 (1482.7379) lr 1.7705e-03 eta 0:19:18
epoch [13/50] batch [120/162] time 0.156 (0.191) data 0.000 (0.003) loss 1.3965 (1.3482) teacher_loss 0.2873 (0.2621) loss_zs_kd 0.0534 (0.0364) loss_oracle 0.5066 (0.5160) kd_loss 0.8292 (0.8099) acc 84.3750 (89.6354) gate/entropy 1.0349 (1.0353) gate/usage_max 0.4543 (0.4502) gate/usage_min 0.1799 (0.1793) gate/usage_std 0.1143 (0.1137) teacher/entropy 0.0253 (0.0323) teacher/usage_max 0.6975 (0.7953) teacher/usage_min 0.0000 (0.0060) teacher/usage_std 0.2856 (0.3384) nleep/row_max_mean 1494.9801 (1514.4221) nleep/row_max_std 63.2134 (58.9216) nleep/row_min_mean 1465.2255 (1482.7148) lr 1.7705e-03 eta 0:19:12
epoch [13/50] batch [140/162] time 0.197 (0.191) data 0.000 (0.003) loss 1.2813 (1.3470) teacher_loss 0.1657 (0.2649) loss_zs_kd 0.0327 (0.0362) loss_oracle 0.5430 (0.5106) kd_loss 0.8277 (0.8087) acc 90.6250 (89.4866) gate/entropy 1.0349 (1.0353) gate/usage_max 0.4559 (0.4509) gate/usage_min 0.1805 (0.1795) gate/usage_std 0.1145 (0.1138) teacher/entropy 0.0074 (0.0326) teacher/usage_max 0.7793 (0.7966) teacher/usage_min 0.0000 (0.0063) teacher/usage_std 0.3280 (0.3390) nleep/row_max_mean 1508.7017 (1514.1661) nleep/row_max_std 60.1642 (59.4548) nleep/row_min_mean 1473.3918 (1482.4934) lr 1.7705e-03 eta 0:19:08
epoch [13/50] batch [160/162] time 0.073 (0.184) data 0.000 (0.002) loss 1.3441 (1.3451) teacher_loss 0.2449 (0.2660) loss_zs_kd 0.0297 (0.0358) loss_oracle 0.5435 (0.5061) kd_loss 0.8126 (0.8082) acc 90.6250 (89.4336) gate/entropy 1.0348 (1.0352) gate/usage_max 0.4574 (0.4516) gate/usage_min 0.1808 (0.1796) gate/usage_std 0.1147 (0.1139) teacher/entropy 0.0232 (0.0321) teacher/usage_max 0.7760 (0.7984) teacher/usage_min 0.0019 (0.0066) teacher/usage_std 0.3257 (0.3400) nleep/row_max_mean 1506.7817 (1513.7734) nleep/row_max_std 65.0045 (59.5443) nleep/row_min_mean 1475.3416 (1482.0997) lr 1.7705e-03 eta 0:18:25
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,942
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 88.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,554
* accuracy: 77.8%
* error: 22.2%
* macro_f1: 71.9%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [14/50] batch [20/162] time 0.212 (0.165) data 0.000 (0.012) loss 1.2658 (1.3014) teacher_loss 0.1949 (0.2525) loss_zs_kd 0.0166 (0.0287) loss_oracle 0.4740 (0.4576) kd_loss 0.8256 (0.8057) acc 90.6250 (90.7812) gate/entropy 1.0346 (1.0346) gate/usage_max 0.4589 (0.4583) gate/usage_min 0.1809 (0.1808) gate/usage_std 0.1151 (0.1149) teacher/entropy 0.0196 (0.0266) teacher/usage_max 0.7261 (0.7966) teacher/usage_min 0.0004 (0.0052) teacher/usage_std 0.2993 (0.3389) nleep/row_max_mean 1503.3767 (1510.7947) nleep/row_max_std 74.2051 (63.2008) nleep/row_min_mean 1470.5735 (1478.9993) lr 1.7290e-03 eta 0:16:25
epoch [14/50] batch [40/162] time 0.190 (0.167) data 0.000 (0.006) loss 1.3712 (1.3089) teacher_loss 0.2238 (0.2585) loss_zs_kd 0.0382 (0.0326) loss_oracle 0.5835 (0.4638) kd_loss 0.8365 (0.8022) acc 96.8750 (90.0000) gate/entropy 1.0344 (1.0346) gate/usage_max 0.4603 (0.4589) gate/usage_min 0.1812 (0.1809) gate/usage_std 0.1154 (0.1151) teacher/entropy 0.0304 (0.0254) teacher/usage_max 0.6432 (0.8103) teacher/usage_min 0.0034 (0.0041) teacher/usage_std 0.2616 (0.3473) nleep/row_max_mean 1491.3502 (1510.0932) nleep/row_max_std 77.8715 (63.4873) nleep/row_min_mean 1458.6095 (1478.4578) lr 1.7290e-03 eta 0:16:36
epoch [14/50] batch [60/162] time 0.166 (0.176) data 0.001 (0.004) loss 1.1909 (1.3135) teacher_loss 0.1817 (0.2599) loss_zs_kd 0.0330 (0.0336) loss_oracle 0.4186 (0.4703) kd_loss 0.7834 (0.8016) acc 90.6250 (89.5312) gate/entropy 1.0343 (1.0345) gate/usage_max 0.4617 (0.4596) gate/usage_min 0.1816 (0.1811) gate/usage_std 0.1155 (0.1152) teacher/entropy 0.0067 (0.0235) teacher/usage_max 0.9359 (0.8159) teacher/usage_min 0.0014 (0.0038) teacher/usage_std 0.4268 (0.3511) nleep/row_max_mean 1526.7021 (1510.9052) nleep/row_max_std 47.6339 (62.9609) nleep/row_min_mean 1491.5720 (1479.1234) lr 1.7290e-03 eta 0:17:24
epoch [14/50] batch [80/162] time 0.180 (0.178) data 0.000 (0.003) loss 1.4949 (1.3285) teacher_loss 0.4214 (0.2727) loss_zs_kd 0.0365 (0.0340) loss_oracle 0.4949 (0.4730) kd_loss 0.8077 (0.8023) acc 84.3750 (88.9844) gate/entropy 1.0341 (1.0344) gate/usage_max 0.4635 (0.4604) gate/usage_min 0.1819 (0.1813) gate/usage_std 0.1159 (0.1153) teacher/entropy 0.0032 (0.0216) teacher/usage_max 0.8432 (0.8155) teacher/usage_min 0.0000 (0.0031) teacher/usage_std 0.3661 (0.3510) nleep/row_max_mean 1516.7869 (1509.8446) nleep/row_max_std 63.3914 (63.0448) nleep/row_min_mean 1480.7842 (1478.0194) lr 1.7290e-03 eta 0:17:30
epoch [14/50] batch [100/162] time 0.193 (0.179) data 0.000 (0.003) loss 1.6136 (1.3236) teacher_loss 0.4540 (0.2668) loss_zs_kd 0.0353 (0.0342) loss_oracle 0.6099 (0.4740) kd_loss 0.8370 (0.8027) acc 87.5000 (89.3125) gate/entropy 1.0340 (1.0343) gate/usage_max 0.4650 (0.4612) gate/usage_min 0.1824 (0.1814) gate/usage_std 0.1162 (0.1155) teacher/entropy 0.0291 (0.0204) teacher/usage_max 0.6361 (0.8137) teacher/usage_min 0.0002 (0.0026) teacher/usage_std 0.2605 (0.3500) nleep/row_max_mean 1483.3552 (1509.7583) nleep/row_max_std 75.5540 (63.2814) nleep/row_min_mean 1452.5002 (1477.8803) lr 1.7290e-03 eta 0:17:37
epoch [14/50] batch [120/162] time 0.197 (0.180) data 0.000 (0.002) loss 1.1917 (1.3153) teacher_loss 0.2058 (0.2660) loss_zs_kd 0.0415 (0.0327) loss_oracle 0.3765 (0.4656) kd_loss 0.7768 (0.8002) acc 93.7500 (89.2708) gate/entropy 1.0338 (1.0343) gate/usage_max 0.4665 (0.4619) gate/usage_min 0.1827 (0.1816) gate/usage_std 0.1165 (0.1156) teacher/entropy 0.0131 (0.0200) teacher/usage_max 0.9030 (0.8202) teacher/usage_min 0.0002 (0.0022) teacher/usage_std 0.4047 (0.3540) nleep/row_max_mean 1519.4099 (1510.0903) nleep/row_max_std 58.1433 (63.1556) nleep/row_min_mean 1484.1001 (1478.1665) lr 1.7290e-03 eta 0:17:35
epoch [14/50] batch [140/162] time 0.196 (0.181) data 0.000 (0.002) loss 1.3411 (1.3116) teacher_loss 0.3583 (0.2640) loss_zs_kd 0.0303 (0.0332) loss_oracle 0.3995 (0.4606) kd_loss 0.7679 (0.8007) acc 78.1250 (89.1964) gate/entropy 1.0335 (1.0342) gate/usage_max 0.4683 (0.4627) gate/usage_min 0.1831 (0.1818) gate/usage_std 0.1169 (0.1158) teacher/entropy 0.0239 (0.0188) teacher/usage_max 0.8996 (0.8196) teacher/usage_min 0.0053 (0.0024) teacher/usage_std 0.4021 (0.3535) nleep/row_max_mean 1521.5941 (1509.5900) nleep/row_max_std 58.0421 (63.8001) nleep/row_min_mean 1487.3735 (1477.7015) lr 1.7290e-03 eta 0:17:40
epoch [14/50] batch [160/162] time 0.196 (0.183) data 0.000 (0.002) loss 1.2483 (1.3145) teacher_loss 0.2054 (0.2683) loss_zs_kd 0.0388 (0.0334) loss_oracle 0.4901 (0.4590) kd_loss 0.7785 (0.8000) acc 93.7500 (89.0430) gate/entropy 1.0334 (1.0341) gate/usage_max 0.4700 (0.4635) gate/usage_min 0.1838 (0.1820) gate/usage_std 0.1172 (0.1159) teacher/entropy 0.0233 (0.0182) teacher/usage_max 0.8467 (0.8208) teacher/usage_min 0.0001 (0.0023) teacher/usage_std 0.3683 (0.3542) nleep/row_max_mean 1497.4448 (1509.7145) nleep/row_max_std 63.6721 (63.6243) nleep/row_min_mean 1466.9717 (1477.8219) lr 1.7290e-03 eta 0:17:46
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,940
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 88.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,432
* accuracy: 74.1%
* error: 25.9%
* macro_f1: 69.9%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [15/50] batch [20/162] time 0.068 (0.197) data 0.000 (0.012) loss 1.1835 (1.3169) teacher_loss 0.2195 (0.2870) loss_zs_kd 0.0218 (0.0297) loss_oracle 0.3762 (0.4337) kd_loss 0.7650 (0.7983) acc 87.5000 (87.9688) gate/entropy 1.0330 (1.0332) gate/usage_max 0.4717 (0.4710) gate/usage_min 0.1840 (0.1839) gate/usage_std 0.1177 (0.1175) teacher/entropy 0.0177 (0.0187) teacher/usage_max 0.9013 (0.8004) teacher/usage_min 0.0007 (0.0035) teacher/usage_std 0.4036 (0.3414) nleep/row_max_mean 1535.9845 (1510.2291) nleep/row_max_std 45.9364 (61.7158) nleep/row_min_mean 1501.3105 (1479.4879) lr 1.6845e-03 eta 0:19:03
epoch [15/50] batch [40/162] time 0.178 (0.166) data 0.000 (0.006) loss 1.3198 (1.3384) teacher_loss 0.2641 (0.2958) loss_zs_kd 0.0311 (0.0302) loss_oracle 0.4816 (0.4521) kd_loss 0.7994 (0.8015) acc 87.5000 (87.6562) gate/entropy 1.0329 (1.0331) gate/usage_max 0.4729 (0.4716) gate/usage_min 0.1844 (0.1840) gate/usage_std 0.1180 (0.1177) teacher/entropy 0.0184 (0.0178) teacher/usage_max 0.7868 (0.7966) teacher/usage_min 0.0004 (0.0063) teacher/usage_std 0.3322 (0.3389) nleep/row_max_mean 1513.1702 (1510.6345) nleep/row_max_std 56.8972 (61.0898) nleep/row_min_mean 1483.8563 (1479.8183) lr 1.6845e-03 eta 0:15:58
epoch [15/50] batch [60/162] time 0.234 (0.175) data 0.001 (0.004) loss 1.4067 (1.3151) teacher_loss 0.2992 (0.2835) loss_zs_kd 0.0358 (0.0298) loss_oracle 0.4903 (0.4440) kd_loss 0.8444 (0.7947) acc 90.6250 (88.3333) gate/entropy 1.0327 (1.0330) gate/usage_max 0.4749 (0.4724) gate/usage_min 0.1851 (0.1842) gate/usage_std 0.1184 (0.1178) teacher/entropy 0.0053 (0.0169) teacher/usage_max 0.6867 (0.8169) teacher/usage_min 0.0010 (0.0058) teacher/usage_std 0.2803 (0.3514) nleep/row_max_mean 1485.1713 (1513.8770) nleep/row_max_std 65.2308 (59.5907) nleep/row_min_mean 1455.7183 (1482.6120) lr 1.6845e-03 eta 0:16:48
epoch [15/50] batch [80/162] time 0.096 (0.168) data 0.000 (0.003) loss 1.1365 (1.3020) teacher_loss 0.1441 (0.2773) loss_zs_kd 0.0294 (0.0296) loss_oracle 0.3796 (0.4372) kd_loss 0.7879 (0.7913) acc 96.8750 (88.7109) gate/entropy 1.0324 (1.0328) gate/usage_max 0.4769 (0.4733) gate/usage_min 0.1858 (0.1845) gate/usage_std 0.1189 (0.1181) teacher/entropy 0.0080 (0.0161) teacher/usage_max 0.8418 (0.8258) teacher/usage_min 0.0020 (0.0053) teacher/usage_std 0.3650 (0.3567) nleep/row_max_mean 1509.2550 (1513.8046) nleep/row_max_std 66.0404 (59.2601) nleep/row_min_mean 1477.7723 (1482.4589) lr 1.6845e-03 eta 0:16:08
epoch [15/50] batch [100/162] time 0.191 (0.168) data 0.000 (0.003) loss 1.2021 (1.3033) teacher_loss 0.1723 (0.2787) loss_zs_kd 0.0230 (0.0297) loss_oracle 0.4085 (0.4381) kd_loss 0.8141 (0.7907) acc 93.7500 (88.5312) gate/entropy 1.0320 (1.0327) gate/usage_max 0.4788 (0.4742) gate/usage_min 0.1862 (0.1848) gate/usage_std 0.1195 (0.1183) teacher/entropy 0.0004 (0.0167) teacher/usage_max 0.7812 (0.8243) teacher/usage_min 0.0000 (0.0061) teacher/usage_std 0.3290 (0.3555) nleep/row_max_mean 1509.1099 (1513.5116) nleep/row_max_std 59.7491 (59.5250) nleep/row_min_mean 1478.4304 (1482.2470) lr 1.6845e-03 eta 0:16:00
epoch [15/50] batch [120/162] time 0.208 (0.171) data 0.000 (0.002) loss 1.2908 (1.3028) teacher_loss 0.2902 (0.2817) loss_zs_kd 0.0208 (0.0301) loss_oracle 0.4391 (0.4355) kd_loss 0.7706 (0.7883) acc 87.5000 (88.6458) gate/entropy 1.0316 (1.0325) gate/usage_max 0.4804 (0.4751) gate/usage_min 0.1865 (0.1851) gate/usage_std 0.1200 (0.1185) teacher/entropy 0.0437 (0.0180) teacher/usage_max 0.8047 (0.8252) teacher/usage_min 0.0169 (0.0064) teacher/usage_std 0.3398 (0.3558) nleep/row_max_mean 1502.0383 (1513.7128) nleep/row_max_std 58.2615 (59.5449) nleep/row_min_mean 1470.9902 (1482.4210) lr 1.6845e-03 eta 0:16:18
epoch [15/50] batch [140/162] time 0.190 (0.174) data 0.000 (0.002) loss 1.2687 (1.2963) teacher_loss 0.2453 (0.2748) loss_zs_kd 0.0329 (0.0308) loss_oracle 0.4818 (0.4374) kd_loss 0.7660 (0.7874) acc 90.6250 (89.0625) gate/entropy 1.0312 (1.0324) gate/usage_max 0.4820 (0.4760) gate/usage_min 0.1869 (0.1853) gate/usage_std 0.1205 (0.1188) teacher/entropy 0.0126 (0.0216) teacher/usage_max 0.8717 (0.8206) teacher/usage_min 0.0009 (0.0096) teacher/usage_std 0.3842 (0.3525) nleep/row_max_mean 1510.8657 (1513.4892) nleep/row_max_std 49.7736 (59.5653) nleep/row_min_mean 1479.9902 (1482.2786) lr 1.6845e-03 eta 0:16:27
epoch [15/50] batch [160/162] time 0.197 (0.176) data 0.000 (0.002) loss 1.2187 (1.2912) teacher_loss 0.2176 (0.2701) loss_zs_kd 0.0403 (0.0325) loss_oracle 0.4134 (0.4371) kd_loss 0.7742 (0.7862) acc 87.5000 (89.4141) gate/entropy 1.0310 (1.0322) gate/usage_max 0.4835 (0.4769) gate/usage_min 0.1875 (0.1856) gate/usage_std 0.1209 (0.1190) teacher/entropy 0.0403 (0.0223) teacher/usage_max 0.8112 (0.8209) teacher/usage_min 0.0271 (0.0106) teacher/usage_std 0.3423 (0.3525) nleep/row_max_mean 1513.1855 (1513.9872) nleep/row_max_std 60.0408 (59.1760) nleep/row_min_mean 1480.0752 (1482.6406) lr 1.6845e-03 eta 0:16:37
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,915
* accuracy: 85.7%
* error: 14.3%
* macro_f1: 87.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,531
* accuracy: 77.1%
* error: 22.9%
* macro_f1: 73.4%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [16/50] batch [20/162] time 0.195 (0.206) data 0.000 (0.015) loss 1.2236 (1.2862) teacher_loss 0.1889 (0.2639) loss_zs_kd 0.0250 (0.0357) loss_oracle 0.5864 (0.4475) kd_loss 0.7290 (0.7807) acc 93.7500 (90.3125) gate/entropy 1.0305 (1.0307) gate/usage_max 0.4857 (0.4848) gate/usage_min 0.1882 (0.1879) gate/usage_std 0.1216 (0.1213) teacher/entropy 0.0695 (0.0585) teacher/usage_max 0.8504 (0.7931) teacher/usage_min 0.0306 (0.0511) teacher/usage_std 0.3674 (0.3289) nleep/row_max_mean 1521.6432 (1514.2039) nleep/row_max_std 54.1258 (59.2711) nleep/row_min_mean 1490.3418 (1483.2797) lr 1.6374e-03 eta 0:19:26
epoch [16/50] batch [40/162] time 0.198 (0.197) data 0.000 (0.008) loss 1.4561 (1.2775) teacher_loss 0.3068 (0.2459) loss_zs_kd 0.0499 (0.0370) loss_oracle 0.4983 (0.4506) kd_loss 0.8752 (0.7878) acc 84.3750 (90.0000) gate/entropy 1.0303 (1.0305) gate/usage_max 0.4872 (0.4856) gate/usage_min 0.1888 (0.1882) gate/usage_std 0.1220 (0.1215) teacher/entropy 0.0442 (0.0533) teacher/usage_max 0.6921 (0.7911) teacher/usage_min 0.1394 (0.0582) teacher/usage_std 0.2539 (0.3267) nleep/row_max_mean 1512.0631 (1514.8634) nleep/row_max_std 53.3616 (58.4028) nleep/row_min_mean 1478.5417 (1483.5572) lr 1.6374e-03 eta 0:18:27
epoch [16/50] batch [60/162] time 0.195 (0.194) data 0.001 (0.005) loss 1.2300 (1.2902) teacher_loss 0.2545 (0.2560) loss_zs_kd 0.0547 (0.0371) loss_oracle 0.4594 (0.4483) kd_loss 0.7184 (0.7916) acc 93.7500 (90.0521) gate/entropy 1.0297 (1.0303) gate/usage_max 0.4892 (0.4866) gate/usage_min 0.1895 (0.1885) gate/usage_std 0.1227 (0.1219) teacher/entropy 0.1444 (0.0569) teacher/usage_max 0.7917 (0.7849) teacher/usage_min 0.0940 (0.0663) teacher/usage_std 0.3242 (0.3220) nleep/row_max_mean 1519.9304 (1515.3774) nleep/row_max_std 42.5794 (58.0053) nleep/row_min_mean 1491.0145 (1484.3150) lr 1.6374e-03 eta 0:18:06
epoch [16/50] batch [80/162] time 0.195 (0.193) data 0.000 (0.004) loss 1.4422 (1.2941) teacher_loss 0.4093 (0.2531) loss_zs_kd 0.0506 (0.0393) loss_oracle 0.4446 (0.4529) kd_loss 0.7853 (0.7949) acc 84.3750 (90.3516) gate/entropy 1.0290 (1.0300) gate/usage_max 0.4916 (0.4876) gate/usage_min 0.1901 (0.1888) gate/usage_std 0.1236 (0.1222) teacher/entropy 0.0901 (0.0626) teacher/usage_max 0.7581 (0.7785) teacher/usage_min 0.1162 (0.0725) teacher/usage_std 0.3004 (0.3172) nleep/row_max_mean 1513.6472 (1515.8056) nleep/row_max_std 63.1099 (57.9854) nleep/row_min_mean 1482.2952 (1485.0225) lr 1.6374e-03 eta 0:18:00
epoch [16/50] batch [100/162] time 0.100 (0.176) data 0.000 (0.003) loss 1.3979 (1.3128) teacher_loss 0.1930 (0.2463) loss_zs_kd 0.0409 (0.0380) loss_oracle 0.5664 (0.4694) kd_loss 0.9012 (0.8127) acc 90.6250 (90.5938) gate/entropy 1.0284 (1.0298) gate/usage_max 0.4937 (0.4886) gate/usage_min 0.1907 (0.1891) gate/usage_std 0.1243 (0.1225) teacher/entropy 0.1133 (0.0675) teacher/usage_max 0.6019 (0.7545) teacher/usage_min 0.1384 (0.0815) teacher/usage_std 0.1962 (0.3008) nleep/row_max_mean 1525.0470 (1514.5529) nleep/row_max_std 58.4580 (58.7171) nleep/row_min_mean 1497.5562 (1483.9425) lr 1.6374e-03 eta 0:16:21
epoch [16/50] batch [120/162] time 0.225 (0.174) data 0.000 (0.003) loss 1.3413 (1.3295) teacher_loss 0.1586 (0.2423) loss_zs_kd 0.0379 (0.0389) loss_oracle 0.4420 (0.4772) kd_loss 0.9428 (0.8292) acc 93.7500 (90.7292) gate/entropy 1.0283 (1.0296) gate/usage_max 0.4949 (0.4895) gate/usage_min 0.1914 (0.1894) gate/usage_std 0.1246 (0.1229) teacher/entropy 0.0891 (0.0720) teacher/usage_max 0.5732 (0.7321) teacher/usage_min 0.1563 (0.0870) teacher/usage_std 0.1759 (0.2866) nleep/row_max_mean 1511.2373 (1514.1635) nleep/row_max_std 63.3446 (59.0721) nleep/row_min_mean 1477.9968 (1483.6504) lr 1.6374e-03 eta 0:16:05
epoch [16/50] batch [140/162] time 0.235 (0.178) data 0.000 (0.002) loss 1.7143 (1.3527) teacher_loss 0.4355 (0.2479) loss_zs_kd 0.0524 (0.0390) loss_oracle 0.5097 (0.4831) kd_loss 0.9978 (0.8438) acc 87.5000 (90.7143) gate/entropy 1.0277 (1.0293) gate/usage_max 0.4967 (0.4905) gate/usage_min 0.1920 (0.1897) gate/usage_std 0.1254 (0.1232) teacher/entropy 0.1261 (0.0789) teacher/usage_max 0.5214 (0.7120) teacher/usage_min 0.0627 (0.0884) teacher/usage_std 0.1962 (0.2753) nleep/row_max_mean 1505.4224 (1513.9554) nleep/row_max_std 51.6809 (59.0170) nleep/row_min_mean 1480.1055 (1483.7629) lr 1.6374e-03 eta 0:16:21
epoch [16/50] batch [160/162] time 0.229 (0.172) data 0.000 (0.002) loss 1.3951 (1.3673) teacher_loss 0.2590 (0.2467) loss_zs_kd 0.0540 (0.0393) loss_oracle 0.4800 (0.4945) kd_loss 0.8691 (0.8537) acc 93.7500 (90.8984) gate/entropy 1.0272 (1.0291) gate/usage_max 0.4981 (0.4913) gate/usage_min 0.1924 (0.1901) gate/usage_std 0.1260 (0.1235) teacher/entropy 0.1436 (0.0827) teacher/usage_max 0.6515 (0.6973) teacher/usage_min 0.0313 (0.0904) teacher/usage_std 0.2534 (0.2666) nleep/row_max_mean 1532.6904 (1514.1117) nleep/row_max_std 58.5709 (58.8629) nleep/row_min_mean 1504.4612 (1484.0265) lr 1.6374e-03 eta 0:15:50
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,899
* accuracy: 85.0%
* error: 15.0%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,456
* accuracy: 74.8%
* error: 25.2%
* macro_f1: 73.1%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [17/50] batch [20/162] time 0.197 (0.197) data 0.000 (0.014) loss 1.2903 (1.4130) teacher_loss 0.1666 (0.2549) loss_zs_kd 0.0416 (0.0362) loss_oracle 0.5961 (0.5189) kd_loss 0.8049 (0.8806) acc 93.7500 (90.6250) gate/entropy 1.0268 (1.0271) gate/usage_max 0.4994 (0.4987) gate/usage_min 0.1929 (0.1927) gate/usage_std 0.1264 (0.1262) teacher/entropy 0.1762 (0.0974) teacher/usage_max 0.6555 (0.6559) teacher/usage_min 0.0871 (0.0860) teacher/usage_std 0.2382 (0.2428) nleep/row_max_mean 1499.9424 (1513.5362) nleep/row_max_std 70.2807 (57.8548) nleep/row_min_mean 1472.3274 (1486.1135) lr 1.5878e-03 eta 0:18:00
epoch [17/50] batch [40/162] time 0.164 (0.190) data 0.000 (0.007) loss 1.3522 (1.4034) teacher_loss 0.2147 (0.2491) loss_zs_kd 0.0561 (0.0390) loss_oracle 0.4091 (0.5164) kd_loss 0.9049 (0.8766) acc 96.8750 (90.9375) gate/entropy 1.0264 (1.0268) gate/usage_max 0.5010 (0.4995) gate/usage_min 0.1935 (0.1930) gate/usage_std 0.1271 (0.1265) teacher/entropy 0.1160 (0.0977) teacher/usage_max 0.6522 (0.6588) teacher/usage_min 0.0027 (0.0876) teacher/usage_std 0.2653 (0.2437) nleep/row_max_mean 1492.3298 (1511.0963) nleep/row_max_std 64.7629 (59.7958) nleep/row_min_mean 1466.1450 (1483.8005) lr 1.5878e-03 eta 0:17:19
epoch [17/50] batch [60/162] time 0.186 (0.189) data 0.001 (0.005) loss 1.5389 (1.4052) teacher_loss 0.2500 (0.2478) loss_zs_kd 0.0385 (0.0390) loss_oracle 0.5651 (0.5081) kd_loss 0.9871 (0.8838) acc 87.5000 (90.7812) gate/entropy 1.0257 (1.0265) gate/usage_max 0.5028 (0.5004) gate/usage_min 0.1941 (0.1933) gate/usage_std 0.1278 (0.1268) teacher/entropy 0.0551 (0.0931) teacher/usage_max 0.5339 (0.6498) teacher/usage_min 0.1987 (0.1000) teacher/usage_std 0.1445 (0.2359) nleep/row_max_mean 1498.7998 (1511.0471) nleep/row_max_std 71.9143 (61.0199) nleep/row_min_mean 1469.3812 (1483.4112) lr 1.5878e-03 eta 0:17:08
epoch [17/50] batch [80/162] time 0.183 (0.187) data 0.000 (0.004) loss 1.6536 (1.4211) teacher_loss 0.3699 (0.2494) loss_zs_kd 0.0491 (0.0418) loss_oracle 0.5012 (0.5024) kd_loss 1.0086 (0.8996) acc 90.6250 (90.9766) gate/entropy 1.0251 (1.0263) gate/usage_max 0.5046 (0.5012) gate/usage_min 0.1948 (0.1936) gate/usage_std 0.1286 (0.1271) teacher/entropy 0.1248 (0.0955) teacher/usage_max 0.4580 (0.6285) teacher/usage_min 0.1524 (0.1043) teacher/usage_std 0.1310 (0.2242) nleep/row_max_mean 1510.8064 (1510.6829) nleep/row_max_std 66.6179 (61.2520) nleep/row_min_mean 1482.4468 (1482.7542) lr 1.5878e-03 eta 0:16:56
epoch [17/50] batch [100/162] time 0.146 (0.185) data 0.000 (0.003) loss 1.5197 (1.4212) teacher_loss 0.2323 (0.2481) loss_zs_kd 0.0179 (0.0408) loss_oracle 0.4898 (0.4980) kd_loss 1.0336 (0.9037) acc 93.7500 (91.0000) gate/entropy 1.0246 (1.0260) gate/usage_max 0.5063 (0.5021) gate/usage_min 0.1956 (0.1939) gate/usage_std 0.1293 (0.1275) teacher/entropy 0.0972 (0.0969) teacher/usage_max 0.4848 (0.6224) teacher/usage_min 0.0942 (0.1028) teacher/usage_std 0.1711 (0.2213) nleep/row_max_mean 1503.0239 (1512.2508) nleep/row_max_std 57.5480 (60.6693) nleep/row_min_mean 1476.8738 (1484.0993) lr 1.5878e-03 eta 0:16:43
epoch [17/50] batch [120/162] time 0.207 (0.184) data 0.000 (0.002) loss 1.3923 (1.4299) teacher_loss 0.3010 (0.2513) loss_zs_kd 0.0262 (0.0393) loss_oracle 0.4380 (0.4981) kd_loss 0.8591 (0.9099) acc 87.5000 (90.6250) gate/entropy 1.0239 (1.0256) gate/usage_max 0.5079 (0.5030) gate/usage_min 0.1961 (0.1942) gate/usage_std 0.1300 (0.1279) teacher/entropy 0.1522 (0.0995) teacher/usage_max 0.6349 (0.6130) teacher/usage_min 0.0323 (0.1035) teacher/usage_std 0.2460 (0.2168) nleep/row_max_mean 1515.9978 (1513.0032) nleep/row_max_std 65.0544 (60.0506) nleep/row_min_mean 1488.4900 (1484.8886) lr 1.5878e-03 eta 0:16:31
epoch [17/50] batch [140/162] time 0.184 (0.182) data 0.000 (0.002) loss 1.4114 (1.4301) teacher_loss 0.2515 (0.2506) loss_zs_kd 0.0371 (0.0393) loss_oracle 0.4750 (0.4979) kd_loss 0.9038 (0.9108) acc 90.6250 (90.7143) gate/entropy 1.0234 (1.0254) gate/usage_max 0.5091 (0.5038) gate/usage_min 0.1966 (0.1945) gate/usage_std 0.1306 (0.1283) teacher/entropy 0.0953 (0.1017) teacher/usage_max 0.5937 (0.6076) teacher/usage_min 0.1562 (0.1057) teacher/usage_std 0.1881 (0.2134) nleep/row_max_mean 1512.5703 (1512.8732) nleep/row_max_std 58.3703 (59.9768) nleep/row_min_mean 1484.5985 (1484.9243) lr 1.5878e-03 eta 0:16:19
epoch [17/50] batch [160/162] time 0.185 (0.183) data 0.000 (0.002) loss 1.2061 (1.4298) teacher_loss 0.1142 (0.2487) loss_zs_kd 0.0325 (0.0392) loss_oracle 0.4280 (0.4951) kd_loss 0.8616 (0.9140) acc 100.0000 (90.7617) gate/entropy 1.0229 (1.0251) gate/usage_max 0.5105 (0.5045) gate/usage_min 0.1971 (0.1948) gate/usage_std 0.1312 (0.1286) teacher/entropy 0.1343 (0.1027) teacher/usage_max 0.6208 (0.6030) teacher/usage_min 0.0947 (0.1059) teacher/usage_std 0.2176 (0.2110) nleep/row_max_mean 1517.4939 (1512.9274) nleep/row_max_std 55.3697 (59.7065) nleep/row_min_mean 1494.8809 (1485.2679) lr 1.5878e-03 eta 0:16:18
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,941
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 87.7%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,360
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 71.6%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [18/50] batch [20/162] time 0.176 (0.178) data 0.001 (0.014) loss 1.8509 (1.4629) teacher_loss 0.6057 (0.2612) loss_zs_kd 0.0458 (0.0458) loss_oracle 0.5294 (0.4710) kd_loss 0.9576 (0.9433) acc 71.8750 (91.2500) gate/entropy 1.0225 (1.0227) gate/usage_max 0.5116 (0.5111) gate/usage_min 0.1976 (0.1973) gate/usage_std 0.1317 (0.1314) teacher/entropy 0.1116 (0.1086) teacher/usage_max 0.4917 (0.5496) teacher/usage_min 0.2186 (0.1340) teacher/usage_std 0.1157 (0.1768) nleep/row_max_mean 1503.3689 (1510.5190) nleep/row_max_std 62.3689 (60.3629) nleep/row_min_mean 1478.4800 (1484.4921) lr 1.5358e-03 eta 0:15:49
epoch [18/50] batch [40/162] time 0.196 (0.170) data 0.000 (0.007) loss 1.5065 (1.4709) teacher_loss 0.2836 (0.2625) loss_zs_kd 0.0494 (0.0437) loss_oracle 0.4116 (0.4677) kd_loss 0.9924 (0.9527) acc 90.6250 (91.4062) gate/entropy 1.0218 (1.0224) gate/usage_max 0.5131 (0.5117) gate/usage_min 0.1980 (0.1976) gate/usage_std 0.1324 (0.1317) teacher/entropy 0.0648 (0.1080) teacher/usage_max 0.5654 (0.5481) teacher/usage_min 0.0626 (0.1192) teacher/usage_std 0.2071 (0.1820) nleep/row_max_mean 1501.7014 (1509.9944) nleep/row_max_std 68.8065 (61.1045) nleep/row_min_mean 1474.6013 (1484.2846) lr 1.5358e-03 eta 0:15:00
epoch [18/50] batch [60/162] time 0.196 (0.174) data 0.001 (0.005) loss 1.4956 (1.4595) teacher_loss 0.2809 (0.2550) loss_zs_kd 0.0499 (0.0414) loss_oracle 0.5291 (0.4697) kd_loss 0.9253 (0.9489) acc 90.6250 (91.3542) gate/entropy 1.0211 (1.0221) gate/usage_max 0.5146 (0.5124) gate/usage_min 0.1987 (0.1978) gate/usage_std 0.1331 (0.1321) teacher/entropy 0.0941 (0.1039) teacher/usage_max 0.5802 (0.5623) teacher/usage_min 0.1213 (0.1080) teacher/usage_std 0.1890 (0.1923) nleep/row_max_mean 1510.7698 (1510.7755) nleep/row_max_std 66.6565 (61.6226) nleep/row_min_mean 1483.7883 (1484.9140) lr 1.5358e-03 eta 0:15:20
epoch [18/50] batch [80/162] time 0.165 (0.176) data 0.000 (0.004) loss 1.4848 (1.4635) teacher_loss 0.2933 (0.2581) loss_zs_kd 0.0343 (0.0407) loss_oracle 0.4497 (0.4766) kd_loss 0.9495 (0.9467) acc 90.6250 (90.9375) gate/entropy 1.0206 (1.0218) gate/usage_max 0.5157 (0.5131) gate/usage_min 0.1991 (0.1981) gate/usage_std 0.1337 (0.1324) teacher/entropy 0.1055 (0.1024) teacher/usage_max 0.5856 (0.5642) teacher/usage_min 0.0046 (0.1083) teacher/usage_std 0.2433 (0.1937) nleep/row_max_mean 1508.7236 (1510.5648) nleep/row_max_std 74.3423 (62.0194) nleep/row_min_mean 1481.7500 (1484.5294) lr 1.5358e-03 eta 0:15:27
epoch [18/50] batch [100/162] time 0.205 (0.177) data 0.000 (0.003) loss 1.3721 (1.4528) teacher_loss 0.1684 (0.2497) loss_zs_kd 0.0334 (0.0411) loss_oracle 0.4565 (0.4766) kd_loss 0.9587 (0.9443) acc 93.7500 (91.1250) gate/entropy 1.0197 (1.0215) gate/usage_max 0.5175 (0.5138) gate/usage_min 0.1995 (0.1984) gate/usage_std 0.1346 (0.1328) teacher/entropy 0.0878 (0.0986) teacher/usage_max 0.5696 (0.5683) teacher/usage_min 0.0635 (0.1082) teacher/usage_std 0.2080 (0.1953) nleep/row_max_mean 1501.7388 (1510.2808) nleep/row_max_std 75.3169 (62.0988) nleep/row_min_mean 1476.4905 (1484.1421) lr 1.5358e-03 eta 0:15:29
epoch [18/50] batch [120/162] time 0.178 (0.178) data 0.000 (0.002) loss 1.3995 (1.4438) teacher_loss 0.2866 (0.2473) loss_zs_kd 0.0231 (0.0408) loss_oracle 0.5092 (0.4784) kd_loss 0.8467 (0.9369) acc 84.3750 (91.1198) gate/entropy 1.0192 (1.0212) gate/usage_max 0.5187 (0.5145) gate/usage_min 0.2001 (0.1986) gate/usage_std 0.1352 (0.1331) teacher/entropy 0.0629 (0.0951) teacher/usage_max 0.6888 (0.5776) teacher/usage_min 0.1253 (0.1089) teacher/usage_std 0.2526 (0.1990) nleep/row_max_mean 1523.6144 (1511.0587) nleep/row_max_std 53.0773 (61.6307) nleep/row_min_mean 1498.0427 (1484.6672) lr 1.5358e-03 eta 0:15:30
epoch [18/50] batch [140/162] time 0.186 (0.179) data 0.000 (0.002) loss 1.7787 (1.4362) teacher_loss 0.5825 (0.2500) loss_zs_kd 0.0481 (0.0409) loss_oracle 0.4003 (0.4773) kd_loss 0.9720 (0.9271) acc 78.1250 (90.8259) gate/entropy 1.0183 (1.0208) gate/usage_max 0.5203 (0.5152) gate/usage_min 0.2006 (0.1989) gate/usage_std 0.1361 (0.1334) teacher/entropy 0.0270 (0.0910) teacher/usage_max 0.6152 (0.5916) teacher/usage_min 0.0625 (0.1053) teacher/usage_std 0.2258 (0.2070) nleep/row_max_mean 1508.3663 (1511.7308) nleep/row_max_std 65.7984 (61.1261) nleep/row_min_mean 1481.1898 (1485.2174) lr 1.5358e-03 eta 0:15:33
epoch [18/50] batch [160/162] time 0.170 (0.179) data 0.000 (0.002) loss 1.3837 (1.4322) teacher_loss 0.2317 (0.2487) loss_zs_kd 0.0415 (0.0407) loss_oracle 0.5708 (0.4796) kd_loss 0.8459 (0.9233) acc 87.5000 (90.6641) gate/entropy 1.0178 (1.0205) gate/usage_max 0.5214 (0.5159) gate/usage_min 0.2010 (0.1991) gate/usage_std 0.1366 (0.1338) teacher/entropy 0.0973 (0.0874) teacher/usage_max 0.6395 (0.5972) teacher/usage_min 0.1591 (0.1069) teacher/usage_std 0.2172 (0.2092) nleep/row_max_mean 1521.3857 (1511.9970) nleep/row_max_std 47.2755 (60.9859) nleep/row_min_mean 1497.3953 (1485.4351) lr 1.5358e-03 eta 0:15:28
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,934
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,367
* accuracy: 72.1%
* error: 27.9%
* macro_f1: 69.2%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [19/50] batch [20/162] time 0.196 (0.195) data 0.000 (0.014) loss 1.3960 (1.3749) teacher_loss 0.2526 (0.2145) loss_zs_kd 0.0334 (0.0428) loss_oracle 0.4971 (0.5168) kd_loss 0.8782 (0.8806) acc 87.5000 (91.4062) gate/entropy 1.0172 (1.0176) gate/usage_max 0.5225 (0.5218) gate/usage_min 0.2013 (0.2012) gate/usage_std 0.1372 (0.1368) teacher/entropy 0.0095 (0.0484) teacher/usage_max 0.7185 (0.6760) teacher/usage_min 0.0939 (0.0944) teacher/usage_std 0.2750 (0.2508) nleep/row_max_mean 1513.8806 (1510.3801) nleep/row_max_std 56.2099 (55.6888) nleep/row_min_mean 1489.0714 (1484.9716) lr 1.4818e-03 eta 0:16:48
epoch [19/50] batch [40/162] time 0.122 (0.171) data 0.001 (0.007) loss 1.4275 (1.3787) teacher_loss 0.2996 (0.2342) loss_zs_kd 0.0441 (0.0439) loss_oracle 0.5857 (0.5107) kd_loss 0.8130 (0.8672) acc 78.1250 (90.3125) gate/entropy 1.0169 (1.0173) gate/usage_max 0.5232 (0.5223) gate/usage_min 0.2017 (0.2014) gate/usage_std 0.1375 (0.1371) teacher/entropy 0.0312 (0.0473) teacher/usage_max 0.7413 (0.6898) teacher/usage_min 0.0993 (0.0949) teacher/usage_std 0.2895 (0.2591) nleep/row_max_mean 1514.5615 (1512.2995) nleep/row_max_std 47.8611 (55.1450) nleep/row_min_mean 1488.9358 (1486.6272) lr 1.4818e-03 eta 0:14:37
epoch [19/50] batch [60/162] time 0.176 (0.171) data 0.000 (0.005) loss 1.4467 (1.3812) teacher_loss 0.2991 (0.2418) loss_zs_kd 0.0311 (0.0419) loss_oracle 0.5412 (0.5105) kd_loss 0.8615 (0.8633) acc 87.5000 (90.1042) gate/entropy 1.0162 (1.0171) gate/usage_max 0.5242 (0.5228) gate/usage_min 0.2018 (0.2015) gate/usage_std 0.1382 (0.1373) teacher/entropy 0.0987 (0.0453) teacher/usage_max 0.6118 (0.6910) teacher/usage_min 0.1812 (0.1028) teacher/usage_std 0.1972 (0.2584) nleep/row_max_mean 1512.8652 (1512.8364) nleep/row_max_std 70.5884 (55.9034) nleep/row_min_mean 1486.6152 (1487.1798) lr 1.4818e-03 eta 0:14:34
epoch [19/50] batch [80/162] time 0.201 (0.176) data 0.000 (0.004) loss 1.3094 (1.3808) teacher_loss 0.1503 (0.2462) loss_zs_kd 0.0480 (0.0408) loss_oracle 0.4695 (0.5134) kd_loss 0.9003 (0.8576) acc 100.0000 (90.0000) gate/entropy 1.0163 (1.0169) gate/usage_max 0.5243 (0.5231) gate/usage_min 0.2020 (0.2016) gate/usage_std 0.1382 (0.1375) teacher/entropy 0.0468 (0.0453) teacher/usage_max 0.6402 (0.6957) teacher/usage_min 0.1381 (0.1032) teacher/usage_std 0.2197 (0.2611) nleep/row_max_mean 1498.6089 (1513.3613) nleep/row_max_std 66.6378 (56.2938) nleep/row_min_mean 1473.1934 (1487.7356) lr 1.4818e-03 eta 0:14:57
epoch [19/50] batch [100/162] time 0.173 (0.169) data 0.000 (0.003) loss 1.4401 (1.3740) teacher_loss 0.3382 (0.2437) loss_zs_kd 0.0387 (0.0402) loss_oracle 0.5555 (0.5127) kd_loss 0.8048 (0.8539) acc 75.0000 (90.0938) gate/entropy 1.0157 (1.0167) gate/usage_max 0.5253 (0.5235) gate/usage_min 0.2022 (0.2017) gate/usage_std 0.1388 (0.1377) teacher/entropy 0.0390 (0.0439) teacher/usage_max 0.7670 (0.7008) teacher/usage_min 0.0751 (0.1021) teacher/usage_std 0.3085 (0.2644) nleep/row_max_mean 1513.7374 (1513.5069) nleep/row_max_std 59.6577 (56.7293) nleep/row_min_mean 1491.6704 (1487.9512) lr 1.4818e-03 eta 0:14:17
epoch [19/50] batch [120/162] time 0.179 (0.168) data 0.000 (0.003) loss 1.3451 (1.3719) teacher_loss 0.1140 (0.2441) loss_zs_kd 0.0145 (0.0407) loss_oracle 0.4779 (0.5094) kd_loss 0.9849 (0.8527) acc 96.8750 (89.9219) gate/entropy 1.0156 (1.0165) gate/usage_max 0.5255 (0.5238) gate/usage_min 0.2024 (0.2018) gate/usage_std 0.1388 (0.1379) teacher/entropy 0.0281 (0.0442) teacher/usage_max 0.5643 (0.7010) teacher/usage_min 0.1568 (0.1026) teacher/usage_std 0.1708 (0.2643) nleep/row_max_mean 1488.2905 (1512.9343) nleep/row_max_std 67.5927 (57.4319) nleep/row_min_mean 1463.8496 (1487.4775) lr 1.4818e-03 eta 0:14:09
epoch [19/50] batch [140/162] time 0.166 (0.170) data 0.000 (0.002) loss 1.3131 (1.3721) teacher_loss 0.1838 (0.2415) loss_zs_kd 0.0525 (0.0406) loss_oracle 0.6064 (0.5134) kd_loss 0.7999 (0.8536) acc 96.8750 (90.0446) gate/entropy 1.0153 (1.0163) gate/usage_max 0.5261 (0.5242) gate/usage_min 0.2026 (0.2019) gate/usage_std 0.1392 (0.1381) teacher/entropy 0.0587 (0.0444) teacher/usage_max 0.7227 (0.6988) teacher/usage_min 0.1125 (0.1038) teacher/usage_std 0.2761 (0.2628) nleep/row_max_mean 1513.3650 (1512.3561) nleep/row_max_std 54.4478 (57.9096) nleep/row_min_mean 1487.3457 (1486.9515) lr 1.4818e-03 eta 0:14:14
epoch [19/50] batch [160/162] time 0.190 (0.170) data 0.000 (0.002) loss 1.3854 (1.3748) teacher_loss 0.3370 (0.2430) loss_zs_kd 0.0253 (0.0406) loss_oracle 0.5293 (0.5167) kd_loss 0.7710 (0.8531) acc 90.6250 (90.0000) gate/entropy 1.0148 (1.0161) gate/usage_max 0.5269 (0.5245) gate/usage_min 0.2026 (0.2020) gate/usage_std 0.1396 (0.1383) teacher/entropy 0.0989 (0.0453) teacher/usage_max 0.7296 (0.6977) teacher/usage_min 0.1010 (0.1048) teacher/usage_std 0.2816 (0.2621) nleep/row_max_mean 1509.8582 (1511.7115) nleep/row_max_std 54.9970 (58.1534) nleep/row_min_mean 1487.5347 (1486.4997) lr 1.4818e-03 eta 0:14:15
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,935
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,417
* accuracy: 73.6%
* error: 26.4%
* macro_f1: 70.4%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [20/50] batch [20/162] time 0.186 (0.199) data 0.000 (0.012) loss 1.4363 (1.3899) teacher_loss 0.2413 (0.2445) loss_zs_kd 0.0690 (0.0379) loss_oracle 0.6356 (0.5209) kd_loss 0.8427 (0.8659) acc 90.6250 (90.7812) gate/entropy 1.0145 (1.0147) gate/usage_max 0.5274 (0.5270) gate/usage_min 0.2027 (0.2027) gate/usage_std 0.1399 (0.1397) teacher/entropy 0.0141 (0.0649) teacher/usage_max 0.7161 (0.6596) teacher/usage_min 0.0955 (0.1114) teacher/usage_std 0.2733 (0.2382) nleep/row_max_mean 1516.8240 (1507.8900) nleep/row_max_std 61.6638 (60.7029) nleep/row_min_mean 1489.1094 (1483.7851) lr 1.4258e-03 eta 0:16:35
epoch [20/50] batch [40/162] time 0.197 (0.191) data 0.000 (0.006) loss 1.4711 (1.4057) teacher_loss 0.2751 (0.2616) loss_zs_kd 0.0432 (0.0369) loss_oracle 0.5477 (0.5301) kd_loss 0.9005 (0.8605) acc 90.6250 (89.2188) gate/entropy 1.0143 (1.0146) gate/usage_max 0.5276 (0.5271) gate/usage_min 0.2028 (0.2027) gate/usage_std 0.1400 (0.1398) teacher/entropy 0.0686 (0.0629) teacher/usage_max 0.6175 (0.6674) teacher/usage_min 0.1249 (0.1081) teacher/usage_std 0.2081 (0.2431) nleep/row_max_mean 1514.9380 (1509.3620) nleep/row_max_std 61.6738 (59.7970) nleep/row_min_mean 1491.2303 (1485.5296) lr 1.4258e-03 eta 0:15:50
epoch [20/50] batch [60/162] time 0.178 (0.183) data 0.000 (0.004) loss 1.2350 (1.3910) teacher_loss 0.2285 (0.2473) loss_zs_kd 0.0375 (0.0365) loss_oracle 0.4240 (0.5199) kd_loss 0.7757 (0.8655) acc 93.7500 (89.8958) gate/entropy 1.0141 (1.0145) gate/usage_max 0.5280 (0.5273) gate/usage_min 0.2028 (0.2028) gate/usage_std 0.1403 (0.1399) teacher/entropy 0.0697 (0.0621) teacher/usage_max 0.7476 (0.6606) teacher/usage_min 0.1225 (0.1137) teacher/usage_std 0.2929 (0.2381) nleep/row_max_mean 1524.1908 (1509.8927) nleep/row_max_std 54.4708 (59.2629) nleep/row_min_mean 1500.0571 (1485.9346) lr 1.4258e-03 eta 0:15:07
epoch [20/50] batch [80/162] time 0.164 (0.184) data 0.000 (0.003) loss 1.3352 (1.3892) teacher_loss 0.1756 (0.2515) loss_zs_kd 0.0643 (0.0378) loss_oracle 0.4988 (0.5100) kd_loss 0.8780 (0.8638) acc 93.7500 (89.7266) gate/entropy 1.0138 (1.0144) gate/usage_max 0.5285 (0.5275) gate/usage_min 0.2030 (0.2028) gate/usage_std 0.1406 (0.1400) teacher/entropy 0.0697 (0.0618) teacher/usage_max 0.6207 (0.6628) teacher/usage_min 0.1885 (0.1132) teacher/usage_std 0.2032 (0.2395) nleep/row_max_mean 1512.7546 (1510.8609) nleep/row_max_std 59.3923 (59.6800) nleep/row_min_mean 1486.3782 (1486.8917) lr 1.4258e-03 eta 0:15:07
epoch [20/50] batch [100/162] time 0.198 (0.183) data 0.000 (0.003) loss 1.5165 (1.3867) teacher_loss 0.2494 (0.2488) loss_zs_kd 0.0415 (0.0383) loss_oracle 0.5836 (0.5091) kd_loss 0.9546 (0.8642) acc 93.7500 (90.1250) gate/entropy 1.0139 (1.0143) gate/usage_max 0.5284 (0.5277) gate/usage_min 0.2032 (0.2029) gate/usage_std 0.1405 (0.1401) teacher/entropy 0.0574 (0.0622) teacher/usage_max 0.5696 (0.6618) teacher/usage_min 0.1312 (0.1145) teacher/usage_std 0.1806 (0.2388) nleep/row_max_mean 1494.6348 (1510.5637) nleep/row_max_std 67.0889 (59.6949) nleep/row_min_mean 1473.4012 (1486.7619) lr 1.4258e-03 eta 0:15:02
epoch [20/50] batch [120/162] time 0.093 (0.173) data 0.000 (0.002) loss 1.5535 (1.3804) teacher_loss 0.2717 (0.2442) loss_zs_kd 0.0332 (0.0380) loss_oracle 0.5897 (0.5083) kd_loss 0.9704 (0.8630) acc 84.3750 (90.3125) gate/entropy 1.0132 (1.0142) gate/usage_max 0.5294 (0.5279) gate/usage_min 0.2034 (0.2029) gate/usage_std 0.1411 (0.1402) teacher/entropy 0.0722 (0.0651) teacher/usage_max 0.5299 (0.6609) teacher/usage_min 0.1580 (0.1127) teacher/usage_std 0.1526 (0.2385) nleep/row_max_mean 1490.7932 (1510.4723) nleep/row_max_std 73.6249 (59.8666) nleep/row_min_mean 1468.3643 (1486.7222) lr 1.4258e-03 eta 0:14:06
epoch [20/50] batch [140/162] time 0.178 (0.172) data 0.000 (0.002) loss 1.3830 (1.3922) teacher_loss 0.1505 (0.2412) loss_zs_kd 0.0610 (0.0382) loss_oracle 0.6066 (0.5146) kd_loss 0.8986 (0.8746) acc 96.8750 (90.5357) gate/entropy 1.0133 (1.0140) gate/usage_max 0.5294 (0.5281) gate/usage_min 0.2035 (0.2030) gate/usage_std 0.1410 (0.1403) teacher/entropy 0.1169 (0.0678) teacher/usage_max 0.5498 (0.6457) teacher/usage_min 0.1886 (0.1143) teacher/usage_std 0.1559 (0.2303) nleep/row_max_mean 1497.7932 (1509.5205) nleep/row_max_std 60.2505 (60.3472) nleep/row_min_mean 1473.2957 (1485.8504) lr 1.4258e-03 eta 0:14:00
epoch [20/50] batch [160/162] time 0.171 (0.173) data 0.000 (0.002) loss 1.7652 (1.4016) teacher_loss 0.4246 (0.2413) loss_zs_kd 0.0527 (0.0379) loss_oracle 0.6712 (0.5195) kd_loss 0.9787 (0.8816) acc 81.2500 (90.6055) gate/entropy 1.0132 (1.0139) gate/usage_max 0.5296 (0.5283) gate/usage_min 0.2036 (0.2031) gate/usage_std 0.1412 (0.1404) teacher/entropy 0.0893 (0.0693) teacher/usage_max 0.4768 (0.6369) teacher/usage_min 0.2538 (0.1167) teacher/usage_std 0.1016 (0.2252) nleep/row_max_mean 1498.9993 (1508.9876) nleep/row_max_std 65.2940 (60.3777) nleep/row_min_mean 1474.5424 (1485.3063) lr 1.4258e-03 eta 0:14:02
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,938
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 87.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,388
* accuracy: 72.8%
* error: 27.2%
* macro_f1: 72.7%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [21/50] batch [20/162] time 0.195 (0.209) data 0.000 (0.016) loss 1.2527 (1.4087) teacher_loss 0.1154 (0.2209) loss_zs_kd 0.0266 (0.0426) loss_oracle 0.4663 (0.5069) kd_loss 0.8908 (0.9130) acc 96.8750 (93.2812) gate/entropy 1.0129 (1.0131) gate/usage_max 0.5301 (0.5298) gate/usage_min 0.2037 (0.2036) gate/usage_std 0.1414 (0.1413) teacher/entropy 0.0381 (0.0769) teacher/usage_max 0.6716 (0.5921) teacher/usage_min 0.0740 (0.1292) teacher/usage_std 0.2503 (0.1985) nleep/row_max_mean 1511.3434 (1509.9517) nleep/row_max_std 66.4565 (60.2599) nleep/row_min_mean 1486.3185 (1486.6094) lr 1.3681e-03 eta 0:16:53
epoch [21/50] batch [40/162] time 0.196 (0.198) data 0.000 (0.008) loss 1.3286 (1.4032) teacher_loss 0.1896 (0.2200) loss_zs_kd 0.0274 (0.0392) loss_oracle 0.5206 (0.5223) kd_loss 0.8650 (0.9025) acc 90.6250 (92.8125) gate/entropy 1.0125 (1.0129) gate/usage_max 0.5306 (0.5300) gate/usage_min 0.2038 (0.2037) gate/usage_std 0.1418 (0.1414) teacher/entropy 0.0662 (0.0726) teacher/usage_max 0.6564 (0.6078) teacher/usage_min 0.1164 (0.1231) teacher/usage_std 0.2329 (0.2075) nleep/row_max_mean 1515.9365 (1510.9398) nleep/row_max_std 56.0915 (59.7603) nleep/row_min_mean 1491.5754 (1487.4548) lr 1.3681e-03 eta 0:15:56
epoch [21/50] batch [60/162] time 0.196 (0.195) data 0.001 (0.005) loss 1.3494 (1.4033) teacher_loss 0.2205 (0.2210) loss_zs_kd 0.0251 (0.0399) loss_oracle 0.5427 (0.5210) kd_loss 0.8450 (0.9019) acc 90.6250 (92.1354) gate/entropy 1.0127 (1.0129) gate/usage_max 0.5305 (0.5301) gate/usage_min 0.2039 (0.2037) gate/usage_std 0.1416 (0.1415) teacher/entropy 0.0887 (0.0685) teacher/usage_max 0.6496 (0.6122) teacher/usage_min 0.1338 (0.1260) teacher/usage_std 0.2262 (0.2085) nleep/row_max_mean 1519.1458 (1511.9273) nleep/row_max_std 56.5534 (58.4838) nleep/row_min_mean 1495.2620 (1488.1717) lr 1.3681e-03 eta 0:15:34
epoch [21/50] batch [80/162] time 0.183 (0.192) data 0.000 (0.004) loss 1.2029 (1.4133) teacher_loss 0.1173 (0.2286) loss_zs_kd 0.0385 (0.0382) loss_oracle 0.4783 (0.5177) kd_loss 0.8272 (0.9068) acc 96.8750 (91.5234) gate/entropy 1.0125 (1.0128) gate/usage_max 0.5308 (0.5302) gate/usage_min 0.2040 (0.2038) gate/usage_std 0.1419 (0.1415) teacher/entropy 0.0455 (0.0681) teacher/usage_max 0.7187 (0.6088) teacher/usage_min 0.1135 (0.1212) teacher/usage_std 0.2734 (0.2086) nleep/row_max_mean 1525.5352 (1512.1216) nleep/row_max_std 46.9358 (57.9507) nleep/row_min_mean 1502.1921 (1488.3151) lr 1.3681e-03 eta 0:15:18
epoch [21/50] batch [100/162] time 0.194 (0.191) data 0.000 (0.003) loss 1.3910 (1.4211) teacher_loss 0.2439 (0.2340) loss_zs_kd 0.0446 (0.0378) loss_oracle 0.4906 (0.5231) kd_loss 0.8795 (0.9067) acc 90.6250 (91.3438) gate/entropy 1.0122 (1.0127) gate/usage_max 0.5312 (0.5304) gate/usage_min 0.2040 (0.2038) gate/usage_std 0.1421 (0.1416) teacher/entropy 0.0805 (0.0663) teacher/usage_max 0.6411 (0.6101) teacher/usage_min 0.0631 (0.1228) teacher/usage_std 0.2375 (0.2084) nleep/row_max_mean 1517.4343 (1512.3423) nleep/row_max_std 53.6921 (57.6579) nleep/row_min_mean 1492.6487 (1488.4972) lr 1.3681e-03 eta 0:15:09
epoch [21/50] batch [120/162] time 0.180 (0.190) data 0.000 (0.003) loss 1.3846 (1.4159) teacher_loss 0.2353 (0.2332) loss_zs_kd 0.0295 (0.0380) loss_oracle 0.5044 (0.5216) kd_loss 0.8824 (0.9030) acc 87.5000 (91.3021) gate/entropy 1.0122 (1.0127) gate/usage_max 0.5312 (0.5305) gate/usage_min 0.2042 (0.2039) gate/usage_std 0.1421 (0.1417) teacher/entropy 0.0233 (0.0663) teacher/usage_max 0.6901 (0.6145) teacher/usage_min 0.0912 (0.1204) teacher/usage_std 0.2576 (0.2113) nleep/row_max_mean 1520.3303 (1512.0531) nleep/row_max_std 53.2163 (57.2143) nleep/row_min_mean 1495.3362 (1488.1697) lr 1.3681e-03 eta 0:14:59
epoch [21/50] batch [140/162] time 0.174 (0.188) data 0.000 (0.002) loss 1.3452 (1.4042) teacher_loss 0.2360 (0.2326) loss_zs_kd 0.0527 (0.0387) loss_oracle 0.4736 (0.5148) kd_loss 0.8461 (0.8948) acc 87.5000 (91.3616) gate/entropy 1.0117 (1.0125) gate/usage_max 0.5320 (0.5307) gate/usage_min 0.2044 (0.2039) gate/usage_std 0.1426 (0.1418) teacher/entropy 0.0172 (0.0657) teacher/usage_max 0.7240 (0.6238) teacher/usage_min 0.1250 (0.1181) teacher/usage_std 0.2765 (0.2170) nleep/row_max_mean 1506.4547 (1512.2534) nleep/row_max_std 58.7688 (57.2270) nleep/row_min_mean 1480.5447 (1488.2436) lr 1.3681e-03 eta 0:14:47
epoch [21/50] batch [160/162] time 0.166 (0.188) data 0.000 (0.002) loss 1.3311 (1.4034) teacher_loss 0.3537 (0.2362) loss_zs_kd 0.0338 (0.0385) loss_oracle 0.4498 (0.5153) kd_loss 0.7357 (0.8903) acc 90.6250 (91.1133) gate/entropy 1.0115 (1.0124) gate/usage_max 0.5324 (0.5309) gate/usage_min 0.2046 (0.2040) gate/usage_std 0.1428 (0.1419) teacher/entropy 0.0468 (0.0650) teacher/usage_max 0.8238 (0.6296) teacher/usage_min 0.0625 (0.1164) teacher/usage_std 0.3474 (0.2206) nleep/row_max_mean 1519.4197 (1511.9954) nleep/row_max_std 53.5905 (57.4562) nleep/row_min_mean 1492.4574 (1487.9281) lr 1.3681e-03 eta 0:14:42
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,927
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,388
* accuracy: 72.8%
* error: 27.2%
* macro_f1: 71.2%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [22/50] batch [20/162] time 0.204 (0.199) data 0.000 (0.014) loss 1.4572 (1.3644) teacher_loss 0.2566 (0.2063) loss_zs_kd 0.0623 (0.0384) loss_oracle 0.5209 (0.5211) kd_loss 0.9090 (0.8784) acc 84.3750 (91.7188) gate/entropy 1.0108 (1.0112) gate/usage_max 0.5333 (0.5328) gate/usage_min 0.2047 (0.2046) gate/usage_std 0.1434 (0.1430) teacher/entropy 0.0543 (0.0606) teacher/usage_max 0.6259 (0.6471) teacher/usage_min 0.0939 (0.1084) teacher/usage_std 0.2204 (0.2324) nleep/row_max_mean 1497.2405 (1510.9722) nleep/row_max_std 74.5662 (58.0325) nleep/row_min_mean 1474.5596 (1486.6096) lr 1.3090e-03 eta 0:15:30
epoch [22/50] batch [40/162] time 0.076 (0.154) data 0.000 (0.007) loss 1.3839 (1.3687) teacher_loss 0.3099 (0.2239) loss_zs_kd 0.0429 (0.0398) loss_oracle 0.5038 (0.5185) kd_loss 0.8006 (0.8657) acc 84.3750 (90.8594) gate/entropy 1.0107 (1.0111) gate/usage_max 0.5336 (0.5331) gate/usage_min 0.2049 (0.2047) gate/usage_std 0.1435 (0.1432) teacher/entropy 0.0379 (0.0616) teacher/usage_max 0.7480 (0.6590) teacher/usage_min 0.1223 (0.1049) teacher/usage_std 0.2933 (0.2399) nleep/row_max_mean 1521.0227 (1510.3834) nleep/row_max_std 59.6025 (59.3883) nleep/row_min_mean 1497.5342 (1486.0636) lr 1.3090e-03 eta 0:11:57
epoch [22/50] batch [60/162] time 0.182 (0.155) data 0.000 (0.005) loss 1.3584 (1.3852) teacher_loss 0.2434 (0.2380) loss_zs_kd 0.0549 (0.0388) loss_oracle 0.4768 (0.5165) kd_loss 0.8491 (0.8696) acc 90.6250 (90.1562) gate/entropy 1.0102 (1.0109) gate/usage_max 0.5343 (0.5333) gate/usage_min 0.2050 (0.2048) gate/usage_std 0.1439 (0.1433) teacher/entropy 0.0458 (0.0578) teacher/usage_max 0.7092 (0.6587) teacher/usage_min 0.0422 (0.1062) teacher/usage_std 0.2788 (0.2393) nleep/row_max_mean 1524.9115 (1509.2403) nleep/row_max_std 53.1296 (60.2670) nleep/row_min_mean 1501.1146 (1484.8987) lr 1.3090e-03 eta 0:12:00
epoch [22/50] batch [80/162] time 0.197 (0.163) data 0.000 (0.004) loss 1.5911 (1.3863) teacher_loss 0.4333 (0.2380) loss_zs_kd 0.0453 (0.0377) loss_oracle 0.5200 (0.5138) kd_loss 0.8752 (0.8726) acc 81.2500 (90.0781) gate/entropy 1.0102 (1.0107) gate/usage_max 0.5344 (0.5336) gate/usage_min 0.2052 (0.2049) gate/usage_std 0.1439 (0.1435) teacher/entropy 0.0256 (0.0552) teacher/usage_max 0.6818 (0.6562) teacher/usage_min 0.1277 (0.1108) teacher/usage_std 0.2478 (0.2367) nleep/row_max_mean 1518.4387 (1509.5918) nleep/row_max_std 55.2512 (60.4370) nleep/row_min_mean 1493.5157 (1485.0829) lr 1.3090e-03 eta 0:12:31
epoch [22/50] batch [100/162] time 0.197 (0.170) data 0.000 (0.003) loss 1.4706 (1.3899) teacher_loss 0.2571 (0.2414) loss_zs_kd 0.0282 (0.0374) loss_oracle 0.5236 (0.5137) kd_loss 0.9377 (0.8730) acc 90.6250 (90.0625) gate/entropy 1.0099 (1.0106) gate/usage_max 0.5348 (0.5338) gate/usage_min 0.2052 (0.2049) gate/usage_std 0.1442 (0.1436) teacher/entropy 0.0472 (0.0550) teacher/usage_max 0.5938 (0.6553) teacher/usage_min 0.1256 (0.1126) teacher/usage_std 0.1947 (0.2359) nleep/row_max_mean 1508.6774 (1510.7913) nleep/row_max_std 59.3427 (59.8458) nleep/row_min_mean 1483.3815 (1486.1722) lr 1.3090e-03 eta 0:12:59
epoch [22/50] batch [120/162] time 0.192 (0.173) data 0.000 (0.003) loss 1.2588 (1.3862) teacher_loss 0.1802 (0.2367) loss_zs_kd 0.0377 (0.0379) loss_oracle 0.4222 (0.5131) kd_loss 0.8486 (0.8740) acc 87.5000 (90.3125) gate/entropy 1.0101 (1.0105) gate/usage_max 0.5347 (0.5340) gate/usage_min 0.2054 (0.2050) gate/usage_std 0.1441 (0.1437) teacher/entropy 0.0909 (0.0571) teacher/usage_max 0.6514 (0.6522) teacher/usage_min 0.0843 (0.1132) teacher/usage_std 0.2366 (0.2336) nleep/row_max_mean 1513.6133 (1511.8249) nleep/row_max_std 42.1462 (58.4299) nleep/row_min_mean 1489.0098 (1487.0684) lr 1.3090e-03 eta 0:13:09
epoch [22/50] batch [140/162] time 0.181 (0.173) data 0.000 (0.002) loss 1.3301 (1.3878) teacher_loss 0.2287 (0.2385) loss_zs_kd 0.0410 (0.0375) loss_oracle 0.4647 (0.5116) kd_loss 0.8486 (0.8747) acc 96.8750 (90.2455) gate/entropy 1.0097 (1.0104) gate/usage_max 0.5353 (0.5342) gate/usage_min 0.2055 (0.2051) gate/usage_std 0.1445 (0.1438) teacher/entropy 0.0914 (0.0597) teacher/usage_max 0.6592 (0.6489) teacher/usage_min 0.0499 (0.1114) teacher/usage_std 0.2505 (0.2323) nleep/row_max_mean 1515.2837 (1512.2820) nleep/row_max_std 49.8923 (57.7860) nleep/row_min_mean 1490.0566 (1487.5261) lr 1.3090e-03 eta 0:13:09
epoch [22/50] batch [160/162] time 0.195 (0.175) data 0.000 (0.002) loss 1.5155 (1.3876) teacher_loss 0.2805 (0.2401) loss_zs_kd 0.0552 (0.0373) loss_oracle 0.4390 (0.5090) kd_loss 0.9879 (0.8743) acc 90.6250 (90.2930) gate/entropy 1.0090 (1.0102) gate/usage_max 0.5361 (0.5343) gate/usage_min 0.2055 (0.2051) gate/usage_std 0.1450 (0.1439) teacher/entropy 0.0267 (0.0604) teacher/usage_max 0.5550 (0.6488) teacher/usage_min 0.1563 (0.1108) teacher/usage_std 0.1658 (0.2321) nleep/row_max_mean 1511.7212 (1512.8267) nleep/row_max_std 53.9534 (57.4912) nleep/row_min_mean 1486.6067 (1488.0391) lr 1.3090e-03 eta 0:13:13
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,908
* accuracy: 85.4%
* error: 14.6%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,449
* accuracy: 74.6%
* error: 25.4%
* macro_f1: 73.4%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [23/50] batch [20/162] time 0.197 (0.204) data 0.000 (0.015) loss 1.3914 (1.4183) teacher_loss 0.2233 (0.2547) loss_zs_kd 0.0344 (0.0384) loss_oracle 0.5273 (0.5034) kd_loss 0.8872 (0.8926) acc 87.5000 (90.0000) gate/entropy 1.0090 (1.0093) gate/usage_max 0.5363 (0.5359) gate/usage_min 0.2057 (0.2056) gate/usage_std 0.1451 (0.1448) teacher/entropy 0.0401 (0.0581) teacher/usage_max 0.6513 (0.6346) teacher/usage_min 0.1305 (0.1003) teacher/usage_std 0.2277 (0.2282) nleep/row_max_mean 1512.9507 (1514.5328) nleep/row_max_std 60.4071 (53.7764) nleep/row_min_mean 1485.8256 (1489.3253) lr 1.2487e-03 eta 0:15:20
epoch [23/50] batch [40/162] time 0.159 (0.198) data 0.000 (0.008) loss 1.2808 (1.3957) teacher_loss 0.2273 (0.2446) loss_zs_kd 0.0214 (0.0370) loss_oracle 0.5202 (0.5021) kd_loss 0.7827 (0.8815) acc 87.5000 (90.3906) gate/entropy 1.0090 (1.0091) gate/usage_max 0.5363 (0.5362) gate/usage_min 0.2059 (0.2057) gate/usage_std 0.1451 (0.1450) teacher/entropy 0.1338 (0.0577) teacher/usage_max 0.6623 (0.6465) teacher/usage_min 0.1334 (0.0990) teacher/usage_std 0.2344 (0.2353) nleep/row_max_mean 1511.7211 (1514.2721) nleep/row_max_std 53.5887 (55.0644) nleep/row_min_mean 1486.2797 (1488.7634) lr 1.2487e-03 eta 0:14:51
epoch [23/50] batch [60/162] time 0.069 (0.170) data 0.001 (0.005) loss 1.3110 (1.3917) teacher_loss 0.2496 (0.2421) loss_zs_kd 0.0404 (0.0387) loss_oracle 0.4529 (0.5053) kd_loss 0.8147 (0.8776) acc 96.8750 (90.1042) gate/entropy 1.0083 (1.0089) gate/usage_max 0.5373 (0.5364) gate/usage_min 0.2059 (0.2058) gate/usage_std 0.1457 (0.1452) teacher/entropy 0.0550 (0.0558) teacher/usage_max 0.7296 (0.6510) teacher/usage_min 0.0497 (0.1035) teacher/usage_std 0.2888 (0.2370) nleep/row_max_mean 1521.6970 (1514.9272) nleep/row_max_std 53.7606 (55.3586) nleep/row_min_mean 1494.5498 (1489.2132) lr 1.2487e-03 eta 0:12:42
epoch [23/50] batch [80/162] time 0.176 (0.164) data 0.000 (0.004) loss 1.4941 (1.3962) teacher_loss 0.3002 (0.2399) loss_zs_kd 0.0473 (0.0395) loss_oracle 0.5325 (0.5164) kd_loss 0.9040 (0.8783) acc 84.3750 (90.1953) gate/entropy 1.0082 (1.0087) gate/usage_max 0.5375 (0.5366) gate/usage_min 0.2060 (0.2058) gate/usage_std 0.1458 (0.1453) teacher/entropy 0.0204 (0.0503) teacher/usage_max 0.6557 (0.6549) teacher/usage_min 0.1178 (0.1057) teacher/usage_std 0.2322 (0.2388) nleep/row_max_mean 1507.9043 (1514.9051) nleep/row_max_std 63.6158 (55.5367) nleep/row_min_mean 1483.9712 (1488.9688) lr 1.2487e-03 eta 0:12:10
epoch [23/50] batch [100/162] time 0.188 (0.167) data 0.000 (0.003) loss 1.3637 (1.3894) teacher_loss 0.3736 (0.2411) loss_zs_kd 0.0351 (0.0393) loss_oracle 0.4243 (0.5167) kd_loss 0.7604 (0.8702) acc 81.2500 (90.1250) gate/entropy 1.0085 (1.0086) gate/usage_max 0.5370 (0.5368) gate/usage_min 0.2061 (0.2059) gate/usage_std 0.1455 (0.1454) teacher/entropy 0.0445 (0.0484) teacher/usage_max 0.7899 (0.6644) teacher/usage_min 0.0819 (0.1067) teacher/usage_std 0.3234 (0.2437) nleep/row_max_mean 1517.9453 (1515.3079) nleep/row_max_std 52.9694 (55.2197) nleep/row_min_mean 1491.2042 (1489.3105) lr 1.2487e-03 eta 0:12:20
epoch [23/50] batch [120/162] time 0.192 (0.159) data 0.000 (0.003) loss 1.2376 (1.3888) teacher_loss 0.1365 (0.2441) loss_zs_kd 0.0220 (0.0401) loss_oracle 0.5353 (0.5186) kd_loss 0.8224 (0.8653) acc 96.8750 (90.0000) gate/entropy 1.0079 (1.0086) gate/usage_max 0.5379 (0.5369) gate/usage_min 0.2061 (0.2059) gate/usage_std 0.1461 (0.1455) teacher/entropy 0.0169 (0.0461) teacher/usage_max 0.7496 (0.6718) teacher/usage_min 0.0955 (0.1068) teacher/usage_std 0.2953 (0.2479) nleep/row_max_mean 1521.1926 (1515.4292) nleep/row_max_std 57.9282 (55.1323) nleep/row_min_mean 1495.9785 (1489.3759) lr 1.2487e-03 eta 0:11:42
epoch [23/50] batch [140/162] time 0.195 (0.157) data 0.000 (0.002) loss 1.5135 (1.3898) teacher_loss 0.3378 (0.2472) loss_zs_kd 0.0509 (0.0395) loss_oracle 0.6142 (0.5206) kd_loss 0.8432 (0.8626) acc 84.3750 (89.8884) gate/entropy 1.0077 (1.0085) gate/usage_max 0.5382 (0.5371) gate/usage_min 0.2062 (0.2059) gate/usage_std 0.1462 (0.1456) teacher/entropy 0.0250 (0.0457) teacher/usage_max 0.7204 (0.6745) teacher/usage_min 0.0921 (0.1082) teacher/usage_std 0.2764 (0.2490) nleep/row_max_mean 1510.4822 (1515.3237) nleep/row_max_std 63.3845 (54.8669) nleep/row_min_mean 1485.1345 (1489.3002) lr 1.2487e-03 eta 0:11:29
epoch [23/50] batch [160/162] time 0.203 (0.159) data 0.000 (0.002) loss 1.3430 (1.3884) teacher_loss 0.1835 (0.2472) loss_zs_kd 0.0317 (0.0391) loss_oracle 0.4988 (0.5246) kd_loss 0.8942 (0.8594) acc 93.7500 (89.9023) gate/entropy 1.0078 (1.0084) gate/usage_max 0.5380 (0.5372) gate/usage_min 0.2063 (0.2060) gate/usage_std 0.1461 (0.1456) teacher/entropy 0.0199 (0.0461) teacher/usage_max 0.6578 (0.6772) teacher/usage_min 0.1538 (0.1073) teacher/usage_std 0.2299 (0.2507) nleep/row_max_mean 1506.7849 (1515.1651) nleep/row_max_std 67.2218 (55.2012) nleep/row_min_mean 1480.7175 (1489.3094) lr 1.2487e-03 eta 0:11:37
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,927
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,375
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 70.9%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [24/50] batch [20/162] time 0.195 (0.206) data 0.000 (0.015) loss 1.4076 (1.3742) teacher_loss 0.1657 (0.2398) loss_zs_kd 0.0269 (0.0285) loss_oracle 0.5464 (0.5459) kd_loss 0.9552 (0.8472) acc 93.7500 (89.2188) gate/entropy 1.0077 (1.0076) gate/usage_max 0.5382 (0.5383) gate/usage_min 0.2062 (0.2063) gate/usage_std 0.1462 (0.1463) teacher/entropy 0.0398 (0.0497) teacher/usage_max 0.5936 (0.6874) teacher/usage_min 0.0669 (0.0892) teacher/usage_std 0.2151 (0.2592) nleep/row_max_mean 1491.7992 (1512.1025) nleep/row_max_std 72.8063 (57.0165) nleep/row_min_mean 1468.8698 (1486.9887) lr 1.1874e-03 eta 0:14:56
epoch [24/50] batch [40/162] time 0.195 (0.199) data 0.000 (0.007) loss 1.2794 (1.3856) teacher_loss 0.1682 (0.2392) loss_zs_kd 0.0445 (0.0346) loss_oracle 0.6178 (0.5483) kd_loss 0.7800 (0.8549) acc 93.7500 (89.6875) gate/entropy 1.0076 (1.0076) gate/usage_max 0.5384 (0.5384) gate/usage_min 0.2063 (0.2063) gate/usage_std 0.1464 (0.1464) teacher/entropy 0.0626 (0.0496) teacher/usage_max 0.7457 (0.6776) teacher/usage_min 0.0960 (0.0988) teacher/usage_std 0.2927 (0.2512) nleep/row_max_mean 1516.7448 (1512.7493) nleep/row_max_std 52.1170 (57.9256) nleep/row_min_mean 1492.3082 (1487.3736) lr 1.1874e-03 eta 0:14:21
epoch [24/50] batch [60/162] time 0.196 (0.195) data 0.001 (0.005) loss 1.3552 (1.3873) teacher_loss 0.1769 (0.2365) loss_zs_kd 0.0370 (0.0363) loss_oracle 0.5744 (0.5524) kd_loss 0.8725 (0.8565) acc 93.7500 (90.3125) gate/entropy 1.0075 (1.0075) gate/usage_max 0.5385 (0.5385) gate/usage_min 0.2064 (0.2063) gate/usage_std 0.1464 (0.1464) teacher/entropy 0.0589 (0.0489) teacher/usage_max 0.6671 (0.6753) teacher/usage_min 0.0302 (0.1028) teacher/usage_std 0.2609 (0.2496) nleep/row_max_mean 1510.3362 (1512.3790) nleep/row_max_std 62.8836 (58.8593) nleep/row_min_mean 1486.1284 (1487.0219) lr 1.1874e-03 eta 0:14:00
epoch [24/50] batch [80/162] time 0.195 (0.195) data 0.000 (0.004) loss 1.5470 (1.3914) teacher_loss 0.3741 (0.2327) loss_zs_kd 0.0430 (0.0356) loss_oracle 0.5363 (0.5501) kd_loss 0.8832 (0.8658) acc 81.2500 (90.6250) gate/entropy 1.0074 (1.0075) gate/usage_max 0.5386 (0.5385) gate/usage_min 0.2063 (0.2063) gate/usage_std 0.1465 (0.1465) teacher/entropy 0.0357 (0.0488) teacher/usage_max 0.6666 (0.6655) teacher/usage_min 0.0928 (0.1069) teacher/usage_std 0.2432 (0.2431) nleep/row_max_mean 1501.4768 (1511.5503) nleep/row_max_std 71.9742 (59.3011) nleep/row_min_mean 1477.8727 (1486.2312) lr 1.1874e-03 eta 0:13:56
epoch [24/50] batch [100/162] time 0.194 (0.194) data 0.000 (0.003) loss 1.2829 (1.3859) teacher_loss 0.2824 (0.2345) loss_zs_kd 0.0356 (0.0363) loss_oracle 0.4330 (0.5406) kd_loss 0.7662 (0.8630) acc 87.5000 (90.5312) gate/entropy 1.0070 (1.0074) gate/usage_max 0.5391 (0.5386) gate/usage_min 0.2065 (0.2063) gate/usage_std 0.1468 (0.1465) teacher/entropy 0.1438 (0.0527) teacher/usage_max 0.6738 (0.6656) teacher/usage_min 0.1016 (0.1023) teacher/usage_std 0.2459 (0.2438) nleep/row_max_mean 1515.9817 (1511.8032) nleep/row_max_std 52.0481 (59.6524) nleep/row_min_mean 1491.6793 (1486.5681) lr 1.1874e-03 eta 0:13:49
epoch [24/50] batch [120/162] time 0.180 (0.193) data 0.000 (0.003) loss 1.5186 (1.3835) teacher_loss 0.3282 (0.2375) loss_zs_kd 0.0501 (0.0360) loss_oracle 0.4771 (0.5341) kd_loss 0.9268 (0.8609) acc 90.6250 (90.3385) gate/entropy 1.0065 (1.0073) gate/usage_max 0.5399 (0.5387) gate/usage_min 0.2066 (0.2064) gate/usage_std 0.1473 (0.1466) teacher/entropy 0.0488 (0.0533) teacher/usage_max 0.6057 (0.6669) teacher/usage_min 0.0942 (0.1025) teacher/usage_std 0.2101 (0.2446) nleep/row_max_mean 1508.5217 (1511.7911) nleep/row_max_std 67.9168 (59.7923) nleep/row_min_mean 1482.1582 (1486.6482) lr 1.1874e-03 eta 0:13:40
epoch [24/50] batch [140/162] time 0.193 (0.182) data 0.000 (0.002) loss 1.4427 (1.3851) teacher_loss 0.3037 (0.2387) loss_zs_kd 0.0347 (0.0361) loss_oracle 0.4920 (0.5306) kd_loss 0.8756 (0.8631) acc 90.6250 (90.4688) gate/entropy 1.0065 (1.0072) gate/usage_max 0.5398 (0.5389) gate/usage_min 0.2067 (0.2064) gate/usage_std 0.1473 (0.1467) teacher/entropy 0.0268 (0.0529) teacher/usage_max 0.6691 (0.6648) teacher/usage_min 0.1572 (0.1045) teacher/usage_std 0.2375 (0.2430) nleep/row_max_mean 1503.8888 (1510.7794) nleep/row_max_std 62.3907 (59.8929) nleep/row_min_mean 1477.0062 (1485.6510) lr 1.1874e-03 eta 0:12:51
epoch [24/50] batch [160/162] time 0.190 (0.181) data 0.000 (0.002) loss 1.4365 (1.3842) teacher_loss 0.2748 (0.2380) loss_zs_kd 0.0435 (0.0368) loss_oracle 0.6277 (0.5315) kd_loss 0.8261 (0.8622) acc 87.5000 (90.5078) gate/entropy 1.0063 (1.0071) gate/usage_max 0.5401 (0.5390) gate/usage_min 0.2067 (0.2064) gate/usage_std 0.1474 (0.1467) teacher/entropy 0.0506 (0.0523) teacher/usage_max 0.7087 (0.6660) teacher/usage_min 0.0932 (0.1043) teacher/usage_std 0.2689 (0.2441) nleep/row_max_mean 1515.5833 (1510.6466) nleep/row_max_std 52.6661 (59.7651) nleep/row_min_mean 1491.4260 (1485.4768) lr 1.1874e-03 eta 0:12:44
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,923
* accuracy: 86.1%
* error: 13.9%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,369
* accuracy: 72.2%
* error: 27.8%
* macro_f1: 70.3%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [25/50] batch [20/162] time 0.162 (0.168) data 0.000 (0.013) loss 1.2710 (1.4024) teacher_loss 0.1919 (0.2531) loss_zs_kd 0.0264 (0.0406) loss_oracle 0.4902 (0.5386) kd_loss 0.8208 (0.8597) acc 90.6250 (89.6875) gate/entropy 1.0064 (1.0063) gate/usage_max 0.5401 (0.5402) gate/usage_min 0.2069 (0.2068) gate/usage_std 0.1474 (0.1475) teacher/entropy 0.0919 (0.0581) teacher/usage_max 0.6756 (0.6651) teacher/usage_min 0.0718 (0.0956) teacher/usage_std 0.2530 (0.2461) nleep/row_max_mean 1507.6687 (1509.9588) nleep/row_max_std 56.6214 (60.2630) nleep/row_min_mean 1482.2930 (1484.1499) lr 1.1253e-03 eta 0:11:43
epoch [25/50] batch [40/162] time 0.169 (0.174) data 0.000 (0.007) loss 1.6283 (1.3983) teacher_loss 0.4124 (0.2504) loss_zs_kd 0.0353 (0.0417) loss_oracle 0.6350 (0.5396) kd_loss 0.8808 (0.8573) acc 81.2500 (90.0000) gate/entropy 1.0061 (1.0062) gate/usage_max 0.5405 (0.5403) gate/usage_min 0.2069 (0.2068) gate/usage_std 0.1477 (0.1476) teacher/entropy 0.0409 (0.0532) teacher/usage_max 0.6420 (0.6689) teacher/usage_min 0.1664 (0.1048) teacher/usage_std 0.2185 (0.2464) nleep/row_max_mean 1501.2273 (1508.9596) nleep/row_max_std 56.3399 (59.5566) nleep/row_min_mean 1474.7472 (1482.9646) lr 1.1253e-03 eta 0:12:04
epoch [25/50] batch [60/162] time 0.168 (0.175) data 0.000 (0.005) loss 1.3325 (1.3809) teacher_loss 0.2316 (0.2405) loss_zs_kd 0.0640 (0.0441) loss_oracle 0.4663 (0.5293) kd_loss 0.8358 (0.8537) acc 90.6250 (90.1562) gate/entropy 1.0058 (1.0061) gate/usage_max 0.5409 (0.5405) gate/usage_min 0.2070 (0.2069) gate/usage_std 0.1479 (0.1476) teacher/entropy 0.0483 (0.0524) teacher/usage_max 0.6993 (0.6745) teacher/usage_min 0.0938 (0.1004) teacher/usage_std 0.2629 (0.2501) nleep/row_max_mean 1510.8422 (1509.4629) nleep/row_max_std 69.7416 (60.0670) nleep/row_min_mean 1480.1129 (1482.9237) lr 1.1253e-03 eta 0:12:08
epoch [25/50] batch [80/162] time 0.193 (0.176) data 0.000 (0.003) loss 1.3502 (1.3745) teacher_loss 0.3215 (0.2360) loss_zs_kd 0.0396 (0.0427) loss_oracle 0.4443 (0.5233) kd_loss 0.7868 (0.8555) acc 81.2500 (90.1172) gate/entropy 1.0053 (1.0060) gate/usage_max 0.5416 (0.5407) gate/usage_min 0.2072 (0.2069) gate/usage_std 0.1484 (0.1478) teacher/entropy 0.0240 (0.0505) teacher/usage_max 0.7812 (0.6747) teacher/usage_min 0.0625 (0.0998) teacher/usage_std 0.3190 (0.2506) nleep/row_max_mean 1528.1207 (1509.6662) nleep/row_max_std 58.1945 (60.4774) nleep/row_min_mean 1498.5214 (1482.7213) lr 1.1253e-03 eta 0:12:07
epoch [25/50] batch [100/162] time 0.199 (0.176) data 0.000 (0.003) loss 1.3512 (1.3724) teacher_loss 0.3290 (0.2340) loss_zs_kd 0.0373 (0.0427) loss_oracle 0.4912 (0.5240) kd_loss 0.7580 (0.8551) acc 90.6250 (90.4062) gate/entropy 1.0054 (1.0058) gate/usage_max 0.5415 (0.5409) gate/usage_min 0.2073 (0.2070) gate/usage_std 0.1483 (0.1479) teacher/entropy 0.0347 (0.0472) teacher/usage_max 0.8067 (0.6784) teacher/usage_min 0.0315 (0.1000) teacher/usage_std 0.3389 (0.2525) nleep/row_max_mean 1519.7266 (1510.1072) nleep/row_max_std 53.8256 (60.3281) nleep/row_min_mean 1491.1846 (1482.9927) lr 1.1253e-03 eta 0:12:05
epoch [25/50] batch [120/162] time 0.125 (0.175) data 0.000 (0.002) loss 1.4111 (1.3758) teacher_loss 0.2545 (0.2337) loss_zs_kd 0.0366 (0.0422) loss_oracle 0.5518 (0.5299) kd_loss 0.8624 (0.8560) acc 90.6250 (90.2865) gate/entropy 1.0049 (1.0057) gate/usage_max 0.5422 (0.5410) gate/usage_min 0.2073 (0.2070) gate/usage_std 0.1487 (0.1480) teacher/entropy 0.0083 (0.0465) teacher/usage_max 0.7187 (0.6779) teacher/usage_min 0.0645 (0.1001) teacher/usage_std 0.2795 (0.2523) nleep/row_max_mean 1516.6377 (1510.4703) nleep/row_max_std 54.9961 (59.9311) nleep/row_min_mean 1488.2385 (1483.2089) lr 1.1253e-03 eta 0:11:56
epoch [25/50] batch [140/162] time 0.157 (0.174) data 0.000 (0.002) loss 1.2640 (1.3766) teacher_loss 0.2139 (0.2350) loss_zs_kd 0.0299 (0.0422) loss_oracle 0.5091 (0.5286) kd_loss 0.7806 (0.8562) acc 90.6250 (90.2455) gate/entropy 1.0048 (1.0056) gate/usage_max 0.5422 (0.5412) gate/usage_min 0.2074 (0.2071) gate/usage_std 0.1488 (0.1481) teacher/entropy 0.0422 (0.0449) teacher/usage_max 0.7444 (0.6793) teacher/usage_min 0.0737 (0.0994) teacher/usage_std 0.2940 (0.2531) nleep/row_max_mean 1527.0079 (1511.0426) nleep/row_max_std 48.0943 (59.3276) nleep/row_min_mean 1498.6499 (1483.5503) lr 1.1253e-03 eta 0:11:49
epoch [25/50] batch [160/162] time 0.175 (0.175) data 0.000 (0.002) loss 1.7663 (1.3765) teacher_loss 0.4170 (0.2349) loss_zs_kd 0.0297 (0.0410) loss_oracle 0.5771 (0.5287) kd_loss 1.0459 (0.8568) acc 87.5000 (90.2539) gate/entropy 1.0050 (1.0055) gate/usage_max 0.5420 (0.5413) gate/usage_min 0.2074 (0.2071) gate/usage_std 0.1486 (0.1482) teacher/entropy 0.0362 (0.0451) teacher/usage_max 0.4863 (0.6783) teacher/usage_min 0.1263 (0.0999) teacher/usage_std 0.1519 (0.2526) nleep/row_max_mean 1485.1965 (1511.4574) nleep/row_max_std 60.4801 (58.8059) nleep/row_min_mean 1458.9077 (1483.9102) lr 1.1253e-03 eta 0:11:48
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,925
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 87.1%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,419
* accuracy: 73.7%
* error: 26.3%
* macro_f1: 71.7%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [26/50] batch [20/162] time 0.098 (0.143) data 0.000 (0.014) loss 1.3367 (1.3933) teacher_loss 0.2003 (0.2346) loss_zs_kd 0.0323 (0.0360) loss_oracle 0.4585 (0.5390) kd_loss 0.8911 (0.8712) acc 90.6250 (89.8438) gate/entropy 1.0049 (1.0047) gate/usage_max 0.5422 (0.5425) gate/usage_min 0.2076 (0.2075) gate/usage_std 0.1487 (0.1489) teacher/entropy 0.0087 (0.0401) teacher/usage_max 0.6873 (0.6676) teacher/usage_min 0.0625 (0.1025) teacher/usage_std 0.2618 (0.2452) nleep/row_max_mean 1508.7190 (1510.9986) nleep/row_max_std 59.7096 (58.9501) nleep/row_min_mean 1482.3538 (1483.8674) lr 1.0628e-03 eta 0:09:38
epoch [26/50] batch [40/162] time 0.191 (0.163) data 0.000 (0.007) loss 1.5029 (1.3923) teacher_loss 0.3131 (0.2519) loss_zs_kd 0.0458 (0.0388) loss_oracle 0.5429 (0.5306) kd_loss 0.8955 (0.8556) acc 87.5000 (88.9062) gate/entropy 1.0048 (1.0045) gate/usage_max 0.5424 (0.5427) gate/usage_min 0.2076 (0.2075) gate/usage_std 0.1488 (0.1490) teacher/entropy 0.0706 (0.0470) teacher/usage_max 0.5989 (0.6774) teacher/usage_min 0.1700 (0.0956) teacher/usage_std 0.1895 (0.2522) nleep/row_max_mean 1496.3491 (1512.5465) nleep/row_max_std 54.5079 (57.6297) nleep/row_min_mean 1467.9617 (1485.1318) lr 1.0628e-03 eta 0:10:53
epoch [26/50] batch [60/162] time 0.174 (0.170) data 0.001 (0.005) loss 1.3078 (1.3766) teacher_loss 0.3510 (0.2494) loss_zs_kd 0.0189 (0.0387) loss_oracle 0.4432 (0.5220) kd_loss 0.7258 (0.8468) acc 81.2500 (89.1146) gate/entropy 1.0039 (1.0044) gate/usage_max 0.5435 (0.5428) gate/usage_min 0.2077 (0.2076) gate/usage_std 0.1496 (0.1491) teacher/entropy 0.1136 (0.0521) teacher/usage_max 0.7499 (0.6820) teacher/usage_min 0.0577 (0.0900) teacher/usage_std 0.2996 (0.2554) nleep/row_max_mean 1517.7932 (1512.3887) nleep/row_max_std 59.8566 (57.4808) nleep/row_min_mean 1491.7170 (1484.9742) lr 1.0628e-03 eta 0:11:16
epoch [26/50] batch [80/162] time 0.195 (0.161) data 0.000 (0.004) loss 1.4523 (1.3799) teacher_loss 0.3368 (0.2513) loss_zs_kd 0.0281 (0.0372) loss_oracle 0.5814 (0.5266) kd_loss 0.8107 (0.8467) acc 84.3750 (89.4141) gate/entropy 1.0038 (1.0043) gate/usage_max 0.5436 (0.5430) gate/usage_min 0.2078 (0.2076) gate/usage_std 0.1496 (0.1492) teacher/entropy 0.0104 (0.0488) teacher/usage_max 0.7800 (0.6853) teacher/usage_min 0.0000 (0.0884) teacher/usage_std 0.3284 (0.2577) nleep/row_max_mean 1518.3777 (1511.6294) nleep/row_max_std 61.2321 (57.4290) nleep/row_min_mean 1491.2705 (1484.3793) lr 1.0628e-03 eta 0:10:40
epoch [26/50] batch [100/162] time 0.195 (0.163) data 0.000 (0.003) loss 1.5139 (1.3751) teacher_loss 0.3599 (0.2468) loss_zs_kd 0.0316 (0.0367) loss_oracle 0.5388 (0.5280) kd_loss 0.8689 (0.8459) acc 78.1250 (89.3125) gate/entropy 1.0034 (1.0042) gate/usage_max 0.5442 (0.5431) gate/usage_min 0.2078 (0.2077) gate/usage_std 0.1500 (0.1493) teacher/entropy 0.0271 (0.0472) teacher/usage_max 0.6675 (0.6873) teacher/usage_min 0.1547 (0.0899) teacher/usage_std 0.2365 (0.2585) nleep/row_max_mean 1512.7039 (1511.1805) nleep/row_max_std 62.9511 (57.7285) nleep/row_min_mean 1485.9834 (1483.9595) lr 1.0628e-03 eta 0:10:42
epoch [26/50] batch [120/162] time 0.200 (0.167) data 0.000 (0.002) loss 1.2640 (1.3642) teacher_loss 0.1669 (0.2384) loss_zs_kd 0.0416 (0.0371) loss_oracle 0.4900 (0.5256) kd_loss 0.8313 (0.8444) acc 90.6250 (89.7135) gate/entropy 1.0036 (1.0041) gate/usage_max 0.5440 (0.5433) gate/usage_min 0.2079 (0.2077) gate/usage_std 0.1498 (0.1494) teacher/entropy 0.0575 (0.0453) teacher/usage_max 0.6969 (0.6903) teacher/usage_min 0.0642 (0.0916) teacher/usage_std 0.2668 (0.2600) nleep/row_max_mean 1516.5225 (1511.4820) nleep/row_max_std 52.9348 (58.1208) nleep/row_min_mean 1490.2452 (1484.1300) lr 1.0628e-03 eta 0:10:56
epoch [26/50] batch [140/162] time 0.184 (0.169) data 0.000 (0.002) loss 1.5699 (1.3664) teacher_loss 0.3595 (0.2384) loss_zs_kd 0.0320 (0.0371) loss_oracle 0.5354 (0.5280) kd_loss 0.9268 (0.8455) acc 87.5000 (89.7098) gate/entropy 1.0034 (1.0040) gate/usage_max 0.5443 (0.5434) gate/usage_min 0.2080 (0.2077) gate/usage_std 0.1500 (0.1495) teacher/entropy 0.0365 (0.0447) teacher/usage_max 0.5956 (0.6888) teacher/usage_min 0.1905 (0.0946) teacher/usage_std 0.1857 (0.2587) nleep/row_max_mean 1501.0493 (1511.1077) nleep/row_max_std 63.9609 (58.3553) nleep/row_min_mean 1474.0356 (1483.7649) lr 1.0628e-03 eta 0:11:01
epoch [26/50] batch [160/162] time 0.171 (0.170) data 0.000 (0.002) loss 1.4848 (1.3644) teacher_loss 0.3905 (0.2345) loss_zs_kd 0.0482 (0.0375) loss_oracle 0.5357 (0.5286) kd_loss 0.8023 (0.8469) acc 84.3750 (89.9023) gate/entropy 1.0031 (1.0039) gate/usage_max 0.5446 (0.5435) gate/usage_min 0.2080 (0.2078) gate/usage_std 0.1503 (0.1496) teacher/entropy 0.0209 (0.0440) teacher/usage_max 0.7474 (0.6876) teacher/usage_min 0.0953 (0.0960) teacher/usage_std 0.2939 (0.2578) nleep/row_max_mean 1516.6219 (1510.8412) nleep/row_max_std 56.4245 (58.1694) nleep/row_min_mean 1490.5972 (1483.4850) lr 1.0628e-03 eta 0:11:00
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,927
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.2%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,403
* accuracy: 73.2%
* error: 26.8%
* macro_f1: 73.0%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [27/50] batch [20/162] time 0.198 (0.201) data 0.000 (0.013) loss 1.2675 (1.3669) teacher_loss 0.1080 (0.2336) loss_zs_kd 0.0236 (0.0376) loss_oracle 0.4974 (0.5356) kd_loss 0.8990 (0.8466) acc 96.8750 (90.3125) gate/entropy 1.0036 (1.0032) gate/usage_max 0.5441 (0.5445) gate/usage_min 0.2081 (0.2080) gate/usage_std 0.1499 (0.1502) teacher/entropy 0.0288 (0.0391) teacher/usage_max 0.6499 (0.6891) teacher/usage_min 0.0943 (0.1009) teacher/usage_std 0.2333 (0.2576) nleep/row_max_mean 1499.3013 (1510.0750) nleep/row_max_std 62.4234 (59.6926) nleep/row_min_mean 1470.5582 (1482.3243) lr 1.0000e-03 eta 0:12:56
epoch [27/50] batch [40/162] time 0.174 (0.194) data 0.000 (0.007) loss 1.3554 (1.3375) teacher_loss 0.1632 (0.2167) loss_zs_kd 0.0422 (0.0388) loss_oracle 0.4959 (0.5167) kd_loss 0.9231 (0.8430) acc 93.7500 (91.1719) gate/entropy 1.0033 (1.0031) gate/usage_max 0.5444 (0.5446) gate/usage_min 0.2081 (0.2080) gate/usage_std 0.1501 (0.1503) teacher/entropy 0.0276 (0.0409) teacher/usage_max 0.6205 (0.6921) teacher/usage_min 0.1227 (0.1023) teacher/usage_std 0.2103 (0.2594) nleep/row_max_mean 1499.2013 (1511.2892) nleep/row_max_std 63.9510 (59.9891) nleep/row_min_mean 1471.8864 (1483.3129) lr 1.0000e-03 eta 0:12:25
epoch [27/50] batch [60/162] time 0.195 (0.194) data 0.000 (0.004) loss 1.5413 (1.3619) teacher_loss 0.2968 (0.2255) loss_zs_kd 0.0528 (0.0383) loss_oracle 0.6028 (0.5277) kd_loss 0.9167 (0.8535) acc 90.6250 (90.5729) gate/entropy 1.0028 (1.0030) gate/usage_max 0.5451 (0.5447) gate/usage_min 0.2081 (0.2081) gate/usage_std 0.1506 (0.1503) teacher/entropy 0.0114 (0.0386) teacher/usage_max 0.6221 (0.6833) teacher/usage_min 0.1278 (0.1039) teacher/usage_std 0.2102 (0.2542) nleep/row_max_mean 1500.7357 (1511.3409) nleep/row_max_std 52.1868 (58.9065) nleep/row_min_mean 1473.5409 (1483.2868) lr 1.0000e-03 eta 0:12:21
epoch [27/50] batch [80/162] time 0.168 (0.188) data 0.000 (0.003) loss 1.1933 (1.3597) teacher_loss 0.2212 (0.2332) loss_zs_kd 0.0627 (0.0386) loss_oracle 0.4610 (0.5281) kd_loss 0.7103 (0.8432) acc 90.6250 (90.2344) gate/entropy 1.0023 (1.0029) gate/usage_max 0.5456 (0.5448) gate/usage_min 0.2081 (0.2081) gate/usage_std 0.1509 (0.1504) teacher/entropy 0.0121 (0.0420) teacher/usage_max 0.8734 (0.6914) teacher/usage_min 0.0313 (0.0992) teacher/usage_std 0.3828 (0.2596) nleep/row_max_mean 1537.5573 (1512.3512) nleep/row_max_std 49.4641 (58.0957) nleep/row_min_mean 1508.2953 (1484.4502) lr 1.0000e-03 eta 0:11:57
epoch [27/50] batch [100/162] time 0.081 (0.170) data 0.000 (0.003) loss 1.2612 (1.3625) teacher_loss 0.0682 (0.2357) loss_zs_kd 0.0502 (0.0388) loss_oracle 0.5348 (0.5274) kd_loss 0.9005 (0.8437) acc 100.0000 (90.2812) gate/entropy 1.0028 (1.0029) gate/usage_max 0.5450 (0.5449) gate/usage_min 0.2082 (0.2081) gate/usage_std 0.1505 (0.1504) teacher/entropy 0.0060 (0.0412) teacher/usage_max 0.6550 (0.6916) teacher/usage_min 0.1575 (0.1000) teacher/usage_std 0.2278 (0.2594) nleep/row_max_mean 1501.3711 (1512.0165) nleep/row_max_std 72.2903 (58.6541) nleep/row_min_mean 1472.0234 (1484.1523) lr 1.0000e-03 eta 0:10:43
epoch [27/50] batch [120/162] time 0.186 (0.171) data 0.000 (0.002) loss 1.2513 (1.3638) teacher_loss 0.1823 (0.2365) loss_zs_kd 0.0450 (0.0389) loss_oracle 0.5037 (0.5256) kd_loss 0.7947 (0.8450) acc 93.7500 (90.2083) gate/entropy 1.0026 (1.0028) gate/usage_max 0.5453 (0.5450) gate/usage_min 0.2083 (0.2081) gate/usage_std 0.1507 (0.1505) teacher/entropy 0.0919 (0.0429) teacher/usage_max 0.6877 (0.6889) teacher/usage_min 0.1177 (0.0985) teacher/usage_std 0.2525 (0.2586) nleep/row_max_mean 1504.6270 (1511.4279) nleep/row_max_std 66.4415 (59.0896) nleep/row_min_mean 1476.4772 (1483.5910) lr 1.0000e-03 eta 0:10:43
epoch [27/50] batch [140/162] time 0.181 (0.172) data 0.000 (0.002) loss 1.4573 (1.3666) teacher_loss 0.2689 (0.2376) loss_zs_kd 0.0358 (0.0389) loss_oracle 0.5691 (0.5259) kd_loss 0.8860 (0.8465) acc 93.7500 (90.0446) gate/entropy 1.0020 (1.0028) gate/usage_max 0.5461 (0.5451) gate/usage_min 0.2083 (0.2082) gate/usage_std 0.1512 (0.1506) teacher/entropy 0.0261 (0.0427) teacher/usage_max 0.6549 (0.6873) teacher/usage_min 0.1563 (0.1010) teacher/usage_std 0.2278 (0.2572) nleep/row_max_mean 1501.6106 (1510.9091) nleep/row_max_std 68.0291 (59.4182) nleep/row_min_mean 1474.6244 (1483.1145) lr 1.0000e-03 eta 0:10:45
epoch [27/50] batch [160/162] time 0.220 (0.168) data 0.000 (0.002) loss 1.4998 (1.3674) teacher_loss 0.3019 (0.2369) loss_zs_kd 0.0403 (0.0396) loss_oracle 0.4555 (0.5249) kd_loss 0.9500 (0.8482) acc 87.5000 (90.1172) gate/entropy 1.0021 (1.0027) gate/usage_max 0.5459 (0.5452) gate/usage_min 0.2084 (0.2082) gate/usage_std 0.1511 (0.1506) teacher/entropy 0.0011 (0.0442) teacher/usage_max 0.6249 (0.6838) teacher/usage_min 0.0938 (0.1011) teacher/usage_std 0.2199 (0.2554) nleep/row_max_mean 1507.9218 (1510.7466) nleep/row_max_std 54.8550 (59.4730) nleep/row_min_mean 1480.1725 (1482.9965) lr 1.0000e-03 eta 0:10:27
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,926
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,374
* accuracy: 72.3%
* error: 27.7%
* macro_f1: 70.4%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [28/50] batch [20/162] time 0.193 (0.206) data 0.000 (0.018) loss 1.4373 (1.3835) teacher_loss 0.3114 (0.2485) loss_zs_kd 0.0418 (0.0381) loss_oracle 0.4690 (0.5317) kd_loss 0.8705 (0.8500) acc 84.3750 (88.5938) gate/entropy 1.0018 (1.0020) gate/usage_max 0.5463 (0.5460) gate/usage_min 0.2084 (0.2084) gate/usage_std 0.1513 (0.1512) teacher/entropy 0.0780 (0.0404) teacher/usage_max 0.6248 (0.6839) teacher/usage_min 0.1093 (0.1089) teacher/usage_std 0.2158 (0.2526) nleep/row_max_mean 1519.1571 (1513.1226) nleep/row_max_std 59.4111 (58.2609) nleep/row_min_mean 1491.6379 (1485.3777) lr 9.3721e-04 eta 0:12:44
epoch [28/50] batch [40/162] time 0.170 (0.200) data 0.000 (0.009) loss 1.3177 (1.3791) teacher_loss 0.2567 (0.2468) loss_zs_kd 0.0340 (0.0379) loss_oracle 0.5036 (0.5295) kd_loss 0.7922 (0.8487) acc 87.5000 (89.2188) gate/entropy 1.0021 (1.0020) gate/usage_max 0.5460 (0.5461) gate/usage_min 0.2085 (0.2084) gate/usage_std 0.1511 (0.1512) teacher/entropy 0.0934 (0.0443) teacher/usage_max 0.6844 (0.6826) teacher/usage_min 0.1412 (0.1020) teacher/usage_std 0.2486 (0.2535) nleep/row_max_mean 1511.6018 (1510.6779) nleep/row_max_std 64.4990 (59.2791) nleep/row_min_mean 1483.2426 (1483.2560) lr 9.3721e-04 eta 0:12:16
epoch [28/50] batch [60/162] time 0.169 (0.194) data 0.000 (0.006) loss 1.1483 (1.3855) teacher_loss 0.1032 (0.2460) loss_zs_kd 0.0333 (0.0399) loss_oracle 0.4620 (0.5306) kd_loss 0.7975 (0.8543) acc 93.7500 (89.3229) gate/entropy 1.0016 (1.0020) gate/usage_max 0.5465 (0.5461) gate/usage_min 0.2085 (0.2084) gate/usage_std 0.1515 (0.1512) teacher/entropy 0.0883 (0.0459) teacher/usage_max 0.7024 (0.6753) teacher/usage_min 0.0315 (0.1023) teacher/usage_std 0.2780 (0.2492) nleep/row_max_mean 1518.8976 (1509.7239) nleep/row_max_std 58.2251 (59.5207) nleep/row_min_mean 1492.8027 (1482.5401) lr 9.3721e-04 eta 0:11:52
epoch [28/50] batch [80/162] time 0.188 (0.191) data 0.000 (0.005) loss 1.3999 (1.3930) teacher_loss 0.1622 (0.2456) loss_zs_kd 0.0566 (0.0409) loss_oracle 0.5426 (0.5322) kd_loss 0.9381 (0.8609) acc 93.7500 (89.6484) gate/entropy 1.0017 (1.0019) gate/usage_max 0.5464 (0.5462) gate/usage_min 0.2085 (0.2085) gate/usage_std 0.1514 (0.1513) teacher/entropy 0.0144 (0.0448) teacher/usage_max 0.6228 (0.6691) teacher/usage_min 0.0944 (0.1036) teacher/usage_std 0.2186 (0.2459) nleep/row_max_mean 1502.0508 (1509.4717) nleep/row_max_std 63.5435 (59.4765) nleep/row_min_mean 1474.3096 (1482.2676) lr 9.3721e-04 eta 0:11:37
epoch [28/50] batch [100/162] time 0.185 (0.189) data 0.000 (0.004) loss 1.3823 (1.3843) teacher_loss 0.2725 (0.2385) loss_zs_kd 0.0486 (0.0402) loss_oracle 0.4797 (0.5320) kd_loss 0.8456 (0.8597) acc 87.5000 (90.0312) gate/entropy 1.0016 (1.0018) gate/usage_max 0.5466 (0.5463) gate/usage_min 0.2085 (0.2085) gate/usage_std 0.1515 (0.1513) teacher/entropy 0.1327 (0.0468) teacher/usage_max 0.6022 (0.6682) teacher/usage_min 0.0532 (0.1025) teacher/usage_std 0.2243 (0.2458) nleep/row_max_mean 1514.0549 (1509.3058) nleep/row_max_std 60.2043 (58.9923) nleep/row_min_mean 1487.9458 (1482.1532) lr 9.3721e-04 eta 0:11:25
epoch [28/50] batch [120/162] time 0.194 (0.186) data 0.000 (0.003) loss 1.6655 (1.3748) teacher_loss 0.4520 (0.2349) loss_zs_kd 0.0329 (0.0404) loss_oracle 0.5570 (0.5321) kd_loss 0.9185 (0.8537) acc 75.0000 (90.1302) gate/entropy 1.0013 (1.0018) gate/usage_max 0.5470 (0.5463) gate/usage_min 0.2086 (0.2085) gate/usage_std 0.1518 (0.1514) teacher/entropy 0.0065 (0.0460) teacher/usage_max 0.6552 (0.6757) teacher/usage_min 0.0627 (0.1004) teacher/usage_std 0.2446 (0.2505) nleep/row_max_mean 1510.6680 (1510.2050) nleep/row_max_std 55.5307 (58.0002) nleep/row_min_mean 1482.9563 (1482.9621) lr 9.3721e-04 eta 0:11:12
epoch [28/50] batch [140/162] time 0.169 (0.185) data 0.000 (0.003) loss 1.5217 (1.3740) teacher_loss 0.2405 (0.2348) loss_zs_kd 0.0253 (0.0402) loss_oracle 0.6095 (0.5311) kd_loss 0.9638 (0.8536) acc 90.6250 (90.0893) gate/entropy 1.0015 (1.0017) gate/usage_max 0.5468 (0.5464) gate/usage_min 0.2086 (0.2085) gate/usage_std 0.1517 (0.1514) teacher/entropy 0.0059 (0.0440) teacher/usage_max 0.5939 (0.6777) teacher/usage_min 0.1572 (0.1001) teacher/usage_std 0.1880 (0.2516) nleep/row_max_mean 1501.3674 (1510.4783) nleep/row_max_std 57.2957 (57.7062) nleep/row_min_mean 1474.0457 (1483.2296) lr 9.3721e-04 eta 0:11:04
epoch [28/50] batch [160/162] time 0.156 (0.185) data 0.000 (0.002) loss 1.4615 (1.3724) teacher_loss 0.2474 (0.2349) loss_zs_kd 0.0384 (0.0394) loss_oracle 0.5460 (0.5339) kd_loss 0.9219 (0.8508) acc 90.6250 (90.0391) gate/entropy 1.0013 (1.0017) gate/usage_max 0.5471 (0.5465) gate/usage_min 0.2087 (0.2085) gate/usage_std 0.1518 (0.1515) teacher/entropy 0.0027 (0.0440) teacher/usage_max 0.6560 (0.6807) teacher/usage_min 0.0629 (0.0993) teacher/usage_std 0.2449 (0.2537) nleep/row_max_mean 1501.3264 (1510.7271) nleep/row_max_std 58.0069 (57.4972) nleep/row_min_mean 1475.0874 (1483.4585) lr 9.3721e-04 eta 0:10:59
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,937
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 87.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,388
* accuracy: 72.8%
* error: 27.2%
* macro_f1: 72.0%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [29/50] batch [20/162] time 0.152 (0.170) data 0.000 (0.013) loss 1.2334 (1.3831) teacher_loss 0.2602 (0.2226) loss_zs_kd 0.0425 (0.0390) loss_oracle 0.3608 (0.5555) kd_loss 0.7716 (0.8633) acc 84.3750 (90.0000) gate/entropy 1.0014 (1.0012) gate/usage_max 0.5468 (0.5471) gate/usage_min 0.2087 (0.2087) gate/usage_std 0.1517 (0.1518) teacher/entropy 0.0367 (0.0438) teacher/usage_max 0.7873 (0.6648) teacher/usage_min 0.0000 (0.1115) teacher/usage_std 0.3326 (0.2409) nleep/row_max_mean 1510.3628 (1508.6369) nleep/row_max_std 57.9887 (57.6145) nleep/row_min_mean 1484.8774 (1481.5620) lr 8.7467e-04 eta 0:10:02
epoch [29/50] batch [40/162] time 0.195 (0.164) data 0.000 (0.007) loss 1.6470 (1.3801) teacher_loss 0.2916 (0.2265) loss_zs_kd 0.0377 (0.0395) loss_oracle 0.6286 (0.5498) kd_loss 1.0222 (0.8590) acc 87.5000 (90.1562) gate/entropy 1.0007 (1.0012) gate/usage_max 0.5478 (0.5472) gate/usage_min 0.2087 (0.2087) gate/usage_std 0.1523 (0.1519) teacher/entropy 0.0193 (0.0411) teacher/usage_max 0.5041 (0.6722) teacher/usage_min 0.2465 (0.1112) teacher/usage_std 0.1208 (0.2454) nleep/row_max_mean 1506.2439 (1510.9287) nleep/row_max_std 65.1817 (56.5105) nleep/row_min_mean 1477.1185 (1483.8613) lr 8.7467e-04 eta 0:09:38
epoch [29/50] batch [60/162] time 0.166 (0.171) data 0.000 (0.004) loss 1.2407 (1.3980) teacher_loss 0.2051 (0.2342) loss_zs_kd 0.0172 (0.0382) loss_oracle 0.3985 (0.5573) kd_loss 0.8278 (0.8660) acc 90.6250 (89.9479) gate/entropy 1.0015 (1.0011) gate/usage_max 0.5468 (0.5472) gate/usage_min 0.2087 (0.2087) gate/usage_std 0.1516 (0.1519) teacher/entropy 0.0508 (0.0380) teacher/usage_max 0.7104 (0.6678) teacher/usage_min 0.0232 (0.1106) teacher/usage_std 0.2845 (0.2429) nleep/row_max_mean 1506.0928 (1510.1235) nleep/row_max_std 50.9034 (56.4928) nleep/row_min_mean 1479.7856 (1483.2091) lr 8.7467e-04 eta 0:10:00
epoch [29/50] batch [80/162] time 0.182 (0.175) data 0.000 (0.003) loss 1.2733 (1.3938) teacher_loss 0.2344 (0.2343) loss_zs_kd 0.0670 (0.0402) loss_oracle 0.4671 (0.5540) kd_loss 0.7719 (0.8624) acc 93.7500 (90.1172) gate/entropy 1.0010 (1.0011) gate/usage_max 0.5474 (0.5472) gate/usage_min 0.2087 (0.2087) gate/usage_std 0.1521 (0.1519) teacher/entropy 0.0581 (0.0408) teacher/usage_max 0.7486 (0.6693) teacher/usage_min 0.0954 (0.1083) teacher/usage_std 0.2947 (0.2444) nleep/row_max_mean 1512.7493 (1510.4281) nleep/row_max_std 50.1191 (56.1450) nleep/row_min_mean 1485.4672 (1483.6684) lr 8.7467e-04 eta 0:10:09
epoch [29/50] batch [100/162] time 0.196 (0.177) data 0.000 (0.003) loss 1.3765 (1.3795) teacher_loss 0.1843 (0.2281) loss_zs_kd 0.0376 (0.0399) loss_oracle 0.5402 (0.5460) kd_loss 0.9033 (0.8584) acc 93.7500 (90.5000) gate/entropy 1.0007 (1.0011) gate/usage_max 0.5478 (0.5473) gate/usage_min 0.2087 (0.2087) gate/usage_std 0.1523 (0.1520) teacher/entropy 0.0178 (0.0409) teacher/usage_max 0.6536 (0.6737) teacher/usage_min 0.0938 (0.1061) teacher/usage_std 0.2356 (0.2476) nleep/row_max_mean 1511.8181 (1510.9958) nleep/row_max_std 58.7413 (56.0331) nleep/row_min_mean 1484.6377 (1484.2783) lr 8.7467e-04 eta 0:10:14
epoch [29/50] batch [120/162] time 0.192 (0.179) data 0.000 (0.002) loss 1.3262 (1.3739) teacher_loss 0.2168 (0.2266) loss_zs_kd 0.0446 (0.0402) loss_oracle 0.4990 (0.5434) kd_loss 0.8376 (0.8556) acc 96.8750 (90.5469) gate/entropy 1.0009 (1.0010) gate/usage_max 0.5475 (0.5474) gate/usage_min 0.2088 (0.2087) gate/usage_std 0.1521 (0.1520) teacher/entropy 0.0345 (0.0405) teacher/usage_max 0.7096 (0.6769) teacher/usage_min 0.0631 (0.1070) teacher/usage_std 0.2744 (0.2493) nleep/row_max_mean 1514.1599 (1511.4037) nleep/row_max_std 56.1960 (55.8989) nleep/row_min_mean 1489.3235 (1484.7030) lr 8.7467e-04 eta 0:10:16
epoch [29/50] batch [140/162] time 0.188 (0.180) data 0.000 (0.002) loss 1.5288 (1.3722) teacher_loss 0.2301 (0.2271) loss_zs_kd 0.0377 (0.0406) loss_oracle 0.5633 (0.5433) kd_loss 0.9982 (0.8532) acc 90.6250 (90.5357) gate/entropy 1.0009 (1.0010) gate/usage_max 0.5475 (0.5474) gate/usage_min 0.2088 (0.2087) gate/usage_std 0.1521 (0.1521) teacher/entropy 0.0206 (0.0411) teacher/usage_max 0.5371 (0.6786) teacher/usage_min 0.1880 (0.1084) teacher/usage_std 0.1484 (0.2502) nleep/row_max_mean 1498.3374 (1511.2578) nleep/row_max_std 57.7743 (55.7756) nleep/row_min_mean 1473.7404 (1484.5716) lr 8.7467e-04 eta 0:10:16
epoch [29/50] batch [160/162] time 0.181 (0.179) data 0.000 (0.002) loss 1.5207 (1.3687) teacher_loss 0.3658 (0.2322) loss_zs_kd 0.0472 (0.0403) loss_oracle 0.6054 (0.5362) kd_loss 0.8287 (0.8483) acc 87.5000 (90.2930) gate/entropy 1.0005 (1.0009) gate/usage_max 0.5481 (0.5475) gate/usage_min 0.2089 (0.2087) gate/usage_std 0.1525 (0.1521) teacher/entropy 0.0264 (0.0406) teacher/usage_max 0.7118 (0.6846) teacher/usage_min 0.1316 (0.1051) teacher/usage_std 0.2678 (0.2543) nleep/row_max_mean 1505.0806 (1511.6834) nleep/row_max_std 60.8504 (55.8785) nleep/row_min_mean 1477.7788 (1485.0164) lr 8.7467e-04 eta 0:10:08
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,934
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,350
* accuracy: 71.6%
* error: 28.4%
* macro_f1: 70.6%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [30/50] batch [20/162] time 0.196 (0.202) data 0.000 (0.015) loss 1.4691 (1.4198) teacher_loss 0.1556 (0.2649) loss_zs_kd 0.0385 (0.0380) loss_oracle 0.6416 (0.5446) kd_loss 0.9734 (0.8636) acc 96.8750 (88.7500) gate/entropy 1.0005 (1.0004) gate/usage_max 0.5480 (0.5481) gate/usage_min 0.2089 (0.2089) gate/usage_std 0.1524 (0.1525) teacher/entropy 0.0474 (0.0405) teacher/usage_max 0.5331 (0.6646) teacher/usage_min 0.2031 (0.1129) teacher/usage_std 0.1434 (0.2423) nleep/row_max_mean 1486.7767 (1508.4006) nleep/row_max_std 65.0092 (57.0691) nleep/row_min_mean 1460.5686 (1481.1709) lr 8.1262e-04 eta 0:11:24
epoch [30/50] batch [40/162] time 0.080 (0.165) data 0.000 (0.008) loss 1.4659 (1.3901) teacher_loss 0.2502 (0.2396) loss_zs_kd 0.0449 (0.0396) loss_oracle 0.5878 (0.5541) kd_loss 0.8994 (0.8536) acc 90.6250 (90.1562) gate/entropy 1.0006 (1.0004) gate/usage_max 0.5479 (0.5482) gate/usage_min 0.2089 (0.2089) gate/usage_std 0.1524 (0.1525) teacher/entropy 0.0109 (0.0380) teacher/usage_max 0.6547 (0.6797) teacher/usage_min 0.1570 (0.1085) teacher/usage_std 0.2276 (0.2515) nleep/row_max_mean 1500.7562 (1510.0703) nleep/row_max_std 53.8763 (57.0980) nleep/row_min_mean 1474.7383 (1482.9455) lr 8.1262e-04 eta 0:09:14
epoch [30/50] batch [60/162] time 0.175 (0.158) data 0.000 (0.005) loss 1.2843 (1.3685) teacher_loss 0.2872 (0.2321) loss_zs_kd 0.0351 (0.0386) loss_oracle 0.5016 (0.5475) kd_loss 0.7287 (0.8433) acc 87.5000 (90.4688) gate/entropy 1.0004 (1.0004) gate/usage_max 0.5482 (0.5482) gate/usage_min 0.2089 (0.2089) gate/usage_std 0.1525 (0.1526) teacher/entropy 0.0549 (0.0372) teacher/usage_max 0.7976 (0.6918) teacher/usage_min 0.0848 (0.1071) teacher/usage_std 0.3286 (0.2596) nleep/row_max_mean 1515.4458 (1510.8050) nleep/row_max_std 51.4460 (56.2858) nleep/row_min_mean 1485.0590 (1483.5714) lr 8.1262e-04 eta 0:08:46
epoch [30/50] batch [80/162] time 0.162 (0.165) data 0.000 (0.004) loss 1.3102 (1.3577) teacher_loss 0.2441 (0.2251) loss_zs_kd 0.0554 (0.0392) loss_oracle 0.5648 (0.5530) kd_loss 0.7560 (0.8365) acc 87.5000 (91.0547) gate/entropy 1.0000 (1.0004) gate/usage_max 0.5486 (0.5482) gate/usage_min 0.2089 (0.2089) gate/usage_std 0.1528 (0.1526) teacher/entropy 0.0080 (0.0358) teacher/usage_max 0.8106 (0.7002) teacher/usage_min 0.0644 (0.1042) teacher/usage_std 0.3384 (0.2649) nleep/row_max_mean 1523.8839 (1511.4467) nleep/row_max_std 55.8948 (55.9350) nleep/row_min_mean 1494.1423 (1483.9776) lr 8.1262e-04 eta 0:09:07
epoch [30/50] batch [100/162] time 0.178 (0.158) data 0.000 (0.003) loss 1.1372 (1.3535) teacher_loss 0.1407 (0.2321) loss_zs_kd 0.0347 (0.0386) loss_oracle 0.3834 (0.5462) kd_loss 0.7874 (0.8289) acc 93.7500 (90.8750) gate/entropy 1.0001 (1.0003) gate/usage_max 0.5486 (0.5483) gate/usage_min 0.2089 (0.2089) gate/usage_std 0.1528 (0.1526) teacher/entropy 0.0116 (0.0355) teacher/usage_max 0.7800 (0.7086) teacher/usage_min 0.0937 (0.1021) teacher/usage_std 0.3161 (0.2702) nleep/row_max_mean 1516.9401 (1511.6810) nleep/row_max_std 62.3838 (56.4571) nleep/row_min_mean 1488.2881 (1484.1784) lr 8.1262e-04 eta 0:08:42
epoch [30/50] batch [120/162] time 0.205 (0.157) data 0.000 (0.003) loss 1.2833 (1.3485) teacher_loss 0.2442 (0.2281) loss_zs_kd 0.0658 (0.0386) loss_oracle 0.4368 (0.5421) kd_loss 0.7877 (0.8302) acc 90.6250 (91.0156) gate/entropy 1.0004 (1.0003) gate/usage_max 0.5482 (0.5483) gate/usage_min 0.2090 (0.2089) gate/usage_std 0.1525 (0.1526) teacher/entropy 0.0045 (0.0349) teacher/usage_max 0.7820 (0.7082) teacher/usage_min 0.0930 (0.0995) teacher/usage_std 0.3175 (0.2702) nleep/row_max_mean 1504.7607 (1510.6886) nleep/row_max_std 52.9274 (57.4660) nleep/row_min_mean 1475.3547 (1483.2481) lr 8.1262e-04 eta 0:08:36
epoch [30/50] batch [140/162] time 0.195 (0.162) data 0.000 (0.002) loss 1.4113 (1.3470) teacher_loss 0.2728 (0.2251) loss_zs_kd 0.0451 (0.0390) loss_oracle 0.5267 (0.5423) kd_loss 0.8526 (0.8312) acc 81.2500 (90.9821) gate/entropy 1.0001 (1.0002) gate/usage_max 0.5485 (0.5484) gate/usage_min 0.2090 (0.2089) gate/usage_std 0.1528 (0.1527) teacher/entropy 0.0113 (0.0354) teacher/usage_max 0.7174 (0.7064) teacher/usage_min 0.0645 (0.1000) teacher/usage_std 0.2787 (0.2690) nleep/row_max_mean 1505.4985 (1509.8263) nleep/row_max_std 62.8998 (58.4713) nleep/row_min_mean 1476.8585 (1482.3797) lr 8.1262e-04 eta 0:08:49
epoch [30/50] batch [160/162] time 0.196 (0.165) data 0.000 (0.002) loss 1.5791 (1.3470) teacher_loss 0.1641 (0.2219) loss_zs_kd 0.0290 (0.0395) loss_oracle 0.7006 (0.5435) kd_loss 1.0502 (0.8336) acc 96.8750 (91.1133) gate/entropy 1.0003 (1.0002) gate/usage_max 0.5484 (0.5484) gate/usage_min 0.2090 (0.2089) gate/usage_std 0.1527 (0.1527) teacher/entropy 0.0598 (0.0365) teacher/usage_max 0.4390 (0.7027) teacher/usage_min 0.2126 (0.1016) teacher/usage_std 0.0930 (0.2665) nleep/row_max_mean 1478.2703 (1509.3934) nleep/row_max_std 63.3687 (58.9011) nleep/row_min_mean 1452.5115 (1481.9557) lr 8.1262e-04 eta 0:08:56
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,929
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 87.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,408
* accuracy: 73.4%
* error: 26.6%
* macro_f1: 71.8%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [31/50] batch [20/162] time 0.191 (0.189) data 0.000 (0.012) loss 1.3064 (1.4077) teacher_loss 0.1547 (0.2586) loss_zs_kd 0.0388 (0.0400) loss_oracle 0.5542 (0.5546) kd_loss 0.8553 (0.8519) acc 93.7500 (88.9062) gate/entropy 1.0000 (0.9999) gate/usage_max 0.5487 (0.5488) gate/usage_min 0.2090 (0.2090) gate/usage_std 0.1529 (0.1530) teacher/entropy 0.0260 (0.0393) teacher/usage_max 0.6799 (0.6773) teacher/usage_min 0.1326 (0.1148) teacher/usage_std 0.2461 (0.2474) nleep/row_max_mean 1502.6523 (1508.0208) nleep/row_max_std 57.7561 (58.7534) nleep/row_min_mean 1473.1633 (1479.8215) lr 7.5131e-04 eta 0:10:09
epoch [31/50] batch [40/162] time 0.180 (0.189) data 0.000 (0.006) loss 1.2268 (1.3770) teacher_loss 0.1190 (0.2396) loss_zs_kd 0.0289 (0.0384) loss_oracle 0.5420 (0.5431) kd_loss 0.8224 (0.8467) acc 96.8750 (90.2344) gate/entropy 0.9998 (0.9998) gate/usage_max 0.5489 (0.5489) gate/usage_min 0.2090 (0.2090) gate/usage_std 0.1530 (0.1530) teacher/entropy 0.0267 (0.0387) teacher/usage_max 0.7229 (0.6857) teacher/usage_min 0.1263 (0.1087) teacher/usage_std 0.2757 (0.2545) nleep/row_max_mean 1501.9036 (1508.8673) nleep/row_max_std 51.0661 (57.6198) nleep/row_min_mean 1475.0544 (1481.0013) lr 7.5131e-04 eta 0:10:03
epoch [31/50] batch [60/162] time 0.195 (0.188) data 0.000 (0.004) loss 1.2584 (1.3662) teacher_loss 0.3167 (0.2413) loss_zs_kd 0.0452 (0.0406) loss_oracle 0.3966 (0.5372) kd_loss 0.7208 (0.8360) acc 90.6250 (89.9479) gate/entropy 0.9998 (0.9998) gate/usage_max 0.5489 (0.5489) gate/usage_min 0.2091 (0.2090) gate/usage_std 0.1530 (0.1530) teacher/entropy 0.0619 (0.0407) teacher/usage_max 0.8017 (0.6945) teacher/usage_min 0.0555 (0.1050) teacher/usage_std 0.3331 (0.2604) nleep/row_max_mean 1521.5513 (1510.2386) nleep/row_max_std 53.8017 (57.2808) nleep/row_min_mean 1494.6338 (1482.2741) lr 7.5131e-04 eta 0:09:58
epoch [31/50] batch [80/162] time 0.184 (0.189) data 0.000 (0.003) loss 1.2904 (1.3621) teacher_loss 0.2878 (0.2389) loss_zs_kd 0.0419 (0.0412) loss_oracle 0.4163 (0.5336) kd_loss 0.7736 (0.8358) acc 84.3750 (90.0000) gate/entropy 0.9998 (0.9997) gate/usage_max 0.5489 (0.5490) gate/usage_min 0.2091 (0.2090) gate/usage_std 0.1530 (0.1531) teacher/entropy 0.0353 (0.0426) teacher/usage_max 0.7742 (0.6930) teacher/usage_min 0.0609 (0.1044) teacher/usage_std 0.3146 (0.2597) nleep/row_max_mean 1521.4490 (1511.2565) nleep/row_max_std 50.3930 (57.1494) nleep/row_min_mean 1493.4573 (1483.2625) lr 7.5131e-04 eta 0:09:56
epoch [31/50] batch [100/162] time 0.195 (0.190) data 0.000 (0.003) loss 1.2851 (1.3569) teacher_loss 0.2544 (0.2349) loss_zs_kd 0.0382 (0.0410) loss_oracle 0.4611 (0.5308) kd_loss 0.7811 (0.8361) acc 87.5000 (90.4062) gate/entropy 0.9995 (0.9997) gate/usage_max 0.5493 (0.5490) gate/usage_min 0.2091 (0.2090) gate/usage_std 0.1533 (0.1531) teacher/entropy 0.0232 (0.0416) teacher/usage_max 0.7736 (0.6935) teacher/usage_min 0.0940 (0.1039) teacher/usage_std 0.3117 (0.2601) nleep/row_max_mean 1510.5739 (1511.0558) nleep/row_max_std 54.0116 (57.4645) nleep/row_min_mean 1481.6887 (1483.0435) lr 7.5131e-04 eta 0:09:56
epoch [31/50] batch [120/162] time 0.101 (0.179) data 0.001 (0.002) loss 1.4830 (1.3622) teacher_loss 0.4397 (0.2391) loss_zs_kd 0.0478 (0.0398) loss_oracle 0.4726 (0.5313) kd_loss 0.7831 (0.8376) acc 84.3750 (90.3385) gate/entropy 0.9992 (0.9997) gate/usage_max 0.5496 (0.5491) gate/usage_min 0.2091 (0.2091) gate/usage_std 0.1535 (0.1531) teacher/entropy 0.0193 (0.0410) teacher/usage_max 0.7799 (0.6928) teacher/usage_min 0.0627 (0.1039) teacher/usage_std 0.3182 (0.2596) nleep/row_max_mean 1524.9282 (1510.9725) nleep/row_max_std 53.3976 (57.5567) nleep/row_min_mean 1495.0762 (1482.9854) lr 7.5131e-04 eta 0:09:17
epoch [31/50] batch [140/162] time 0.185 (0.179) data 0.000 (0.002) loss 1.5928 (1.3650) teacher_loss 0.2733 (0.2426) loss_zs_kd 0.0624 (0.0395) loss_oracle 0.7290 (0.5323) kd_loss 0.9239 (0.8365) acc 84.3750 (90.1562) gate/entropy 0.9992 (0.9996) gate/usage_max 0.5497 (0.5491) gate/usage_min 0.2092 (0.2091) gate/usage_std 0.1535 (0.1532) teacher/entropy 0.0415 (0.0407) teacher/usage_max 0.6007 (0.6947) teacher/usage_min 0.1279 (0.1011) teacher/usage_std 0.1980 (0.2612) nleep/row_max_mean 1500.8225 (1510.5377) nleep/row_max_std 67.6908 (57.8275) nleep/row_min_mean 1473.9297 (1482.6262) lr 7.5131e-04 eta 0:09:16
epoch [31/50] batch [160/162] time 0.185 (0.180) data 0.000 (0.002) loss 1.2618 (1.3608) teacher_loss 0.2140 (0.2421) loss_zs_kd 0.0413 (0.0400) loss_oracle 0.5353 (0.5290) kd_loss 0.7595 (0.8341) acc 90.6250 (90.1562) gate/entropy 0.9992 (0.9996) gate/usage_max 0.5496 (0.5492) gate/usage_min 0.2092 (0.2091) gate/usage_std 0.1535 (0.1532) teacher/entropy 0.0355 (0.0397) teacher/usage_max 0.7916 (0.6987) teacher/usage_min 0.0323 (0.0994) teacher/usage_std 0.3293 (0.2639) nleep/row_max_mean 1516.8132 (1510.4477) nleep/row_max_std 46.8715 (57.6755) nleep/row_min_mean 1489.1665 (1482.5341) lr 7.5131e-04 eta 0:09:13
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,918
* accuracy: 85.9%
* error: 14.1%
* macro_f1: 86.8%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,378
* accuracy: 72.5%
* error: 27.5%
* macro_f1: 69.5%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [32/50] batch [20/162] time 0.193 (0.202) data 0.000 (0.014) loss 1.3804 (1.3019) teacher_loss 0.2090 (0.1965) loss_zs_kd 0.0463 (0.0370) loss_oracle 0.6200 (0.5059) kd_loss 0.8383 (0.8340) acc 90.6250 (91.5625) gate/entropy 0.9992 (0.9992) gate/usage_max 0.5497 (0.5497) gate/usage_min 0.2092 (0.2092) gate/usage_std 0.1535 (0.1535) teacher/entropy 0.0245 (0.0399) teacher/usage_max 0.6894 (0.7017) teacher/usage_min 0.0625 (0.0767) teacher/usage_std 0.2629 (0.2701) nleep/row_max_mean 1497.0652 (1508.3217) nleep/row_max_std 70.3484 (60.0783) nleep/row_min_mean 1467.9197 (1480.4099) lr 6.9098e-04 eta 0:10:16
epoch [32/50] batch [40/162] time 0.192 (0.194) data 0.000 (0.007) loss 1.2258 (1.3229) teacher_loss 0.2124 (0.2099) loss_zs_kd 0.0446 (0.0377) loss_oracle 0.4325 (0.5323) kd_loss 0.7748 (0.8281) acc 96.8750 (91.4844) gate/entropy 0.9987 (0.9991) gate/usage_max 0.5503 (0.5498) gate/usage_min 0.2092 (0.2092) gate/usage_std 0.1539 (0.1536) teacher/entropy 0.0243 (0.0399) teacher/usage_max 0.7824 (0.7058) teacher/usage_min 0.0628 (0.0891) teacher/usage_std 0.3198 (0.2701) nleep/row_max_mean 1531.9092 (1507.1191) nleep/row_max_std 48.7529 (60.8728) nleep/row_min_mean 1501.6494 (1479.2314) lr 6.9098e-04 eta 0:09:50
epoch [32/50] batch [60/162] time 0.192 (0.193) data 0.000 (0.005) loss 1.3591 (1.3303) teacher_loss 0.1900 (0.2186) loss_zs_kd 0.0243 (0.0368) loss_oracle 0.5660 (0.5356) kd_loss 0.8739 (0.8256) acc 90.6250 (91.1458) gate/entropy 0.9991 (0.9990) gate/usage_max 0.5498 (0.5499) gate/usage_min 0.2093 (0.2092) gate/usage_std 0.1536 (0.1537) teacher/entropy 0.0221 (0.0363) teacher/usage_max 0.6819 (0.7125) teacher/usage_min 0.0623 (0.0848) teacher/usage_std 0.2588 (0.2752) nleep/row_max_mean 1500.8064 (1507.4525) nleep/row_max_std 66.4951 (60.6206) nleep/row_min_mean 1474.5691 (1479.8401) lr 6.9098e-04 eta 0:09:42
epoch [32/50] batch [80/162] time 0.195 (0.193) data 0.000 (0.004) loss 1.4541 (1.3376) teacher_loss 0.1196 (0.2212) loss_zs_kd 0.0226 (0.0358) loss_oracle 0.6991 (0.5388) kd_loss 0.9737 (0.8291) acc 96.8750 (90.8984) gate/entropy 0.9987 (0.9990) gate/usage_max 0.5503 (0.5499) gate/usage_min 0.2093 (0.2092) gate/usage_std 0.1539 (0.1537) teacher/entropy 0.0400 (0.0353) teacher/usage_max 0.5415 (0.7096) teacher/usage_min 0.1876 (0.0882) teacher/usage_std 0.1510 (0.2729) nleep/row_max_mean 1499.5222 (1507.6287) nleep/row_max_std 72.3749 (60.2044) nleep/row_min_mean 1471.9692 (1480.2484) lr 6.9098e-04 eta 0:09:39
epoch [32/50] batch [100/162] time 0.165 (0.192) data 0.000 (0.003) loss 1.3229 (1.3501) teacher_loss 0.1839 (0.2204) loss_zs_kd 0.0569 (0.0383) loss_oracle 0.6121 (0.5457) kd_loss 0.8045 (0.8377) acc 93.7500 (90.9375) gate/entropy 0.9987 (0.9990) gate/usage_max 0.5503 (0.5499) gate/usage_min 0.2093 (0.2093) gate/usage_std 0.1539 (0.1537) teacher/entropy 0.0186 (0.0353) teacher/usage_max 0.7475 (0.6998) teacher/usage_min 0.1254 (0.0919) teacher/usage_std 0.2929 (0.2665) nleep/row_max_mean 1510.9038 (1507.2189) nleep/row_max_std 60.3045 (59.9715) nleep/row_min_mean 1481.0571 (1479.8264) lr 6.9098e-04 eta 0:09:31
epoch [32/50] batch [120/162] time 0.171 (0.190) data 0.000 (0.003) loss 1.4035 (1.3509) teacher_loss 0.2142 (0.2176) loss_zs_kd 0.0508 (0.0382) loss_oracle 0.6476 (0.5504) kd_loss 0.8400 (0.8390) acc 90.6250 (91.0677) gate/entropy 0.9991 (0.9990) gate/usage_max 0.5498 (0.5500) gate/usage_min 0.2093 (0.2093) gate/usage_std 0.1536 (0.1537) teacher/entropy 0.0631 (0.0357) teacher/usage_max 0.6651 (0.6985) teacher/usage_min 0.1256 (0.0927) teacher/usage_std 0.2370 (0.2659) nleep/row_max_mean 1499.4043 (1507.5708) nleep/row_max_std 62.9500 (59.2165) nleep/row_min_mean 1473.1545 (1480.1481) lr 6.9098e-04 eta 0:09:23
epoch [32/50] batch [140/162] time 0.192 (0.189) data 0.000 (0.002) loss 1.3045 (1.3542) teacher_loss 0.2025 (0.2222) loss_zs_kd 0.0380 (0.0384) loss_oracle 0.5811 (0.5533) kd_loss 0.7925 (0.8362) acc 84.3750 (90.8259) gate/entropy 0.9987 (0.9989) gate/usage_max 0.5503 (0.5500) gate/usage_min 0.2093 (0.2093) gate/usage_std 0.1539 (0.1538) teacher/entropy 0.0400 (0.0380) teacher/usage_max 0.7299 (0.6985) teacher/usage_min 0.0856 (0.0933) teacher/usage_std 0.2833 (0.2656) nleep/row_max_mean 1508.9039 (1508.1046) nleep/row_max_std 58.9926 (58.8053) nleep/row_min_mean 1482.0665 (1480.6744) lr 6.9098e-04 eta 0:09:14
epoch [32/50] batch [160/162] time 0.196 (0.188) data 0.000 (0.002) loss 1.1366 (1.3558) teacher_loss 0.0500 (0.2212) loss_zs_kd 0.0366 (0.0388) loss_oracle 0.4858 (0.5535) kd_loss 0.8254 (0.8384) acc 96.8750 (90.8594) gate/entropy 0.9987 (0.9989) gate/usage_max 0.5503 (0.5500) gate/usage_min 0.2093 (0.2093) gate/usage_std 0.1539 (0.1538) teacher/entropy 0.0656 (0.0386) teacher/usage_max 0.6862 (0.6951) teacher/usage_min 0.0668 (0.0961) teacher/usage_std 0.2601 (0.2630) nleep/row_max_mean 1515.8243 (1508.2395) nleep/row_max_std 59.2875 (58.7868) nleep/row_min_mean 1485.9402 (1480.8656) lr 6.9098e-04 eta 0:09:09
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,912
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 86.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,352
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 70.9%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [33/50] batch [20/162] time 0.186 (0.198) data 0.000 (0.013) loss 1.4679 (1.3801) teacher_loss 0.3247 (0.2216) loss_zs_kd 0.0491 (0.0392) loss_oracle 0.4809 (0.5630) kd_loss 0.8782 (0.8573) acc 81.2500 (90.1562) gate/entropy 0.9987 (0.9987) gate/usage_max 0.5504 (0.5503) gate/usage_min 0.2093 (0.2093) gate/usage_std 0.1540 (0.1540) teacher/entropy 0.0341 (0.0490) teacher/usage_max 0.6736 (0.6625) teacher/usage_min 0.0003 (0.1040) teacher/usage_std 0.2749 (0.2412) nleep/row_max_mean 1502.3970 (1508.8021) nleep/row_max_std 58.2571 (58.2743) nleep/row_min_mean 1475.7249 (1481.4968) lr 6.3188e-04 eta 0:09:33
epoch [33/50] batch [40/162] time 0.169 (0.160) data 0.000 (0.007) loss 1.1757 (1.3849) teacher_loss 0.2120 (0.2272) loss_zs_kd 0.0549 (0.0388) loss_oracle 0.4999 (0.5516) kd_loss 0.6863 (0.8625) acc 90.6250 (90.6250) gate/entropy 0.9985 (0.9987) gate/usage_max 0.5506 (0.5504) gate/usage_min 0.2093 (0.2093) gate/usage_std 0.1541 (0.1540) teacher/entropy 0.0638 (0.0456) teacher/usage_max 0.8343 (0.6621) teacher/usage_min 0.0509 (0.1008) teacher/usage_std 0.3552 (0.2417) nleep/row_max_mean 1526.6156 (1507.5787) nleep/row_max_std 47.3325 (59.4155) nleep/row_min_mean 1498.9280 (1480.5037) lr 6.3188e-04 eta 0:07:40
epoch [33/50] batch [60/162] time 0.171 (0.159) data 0.001 (0.004) loss 1.2319 (1.3608) teacher_loss 0.1470 (0.2131) loss_zs_kd 0.0547 (0.0399) loss_oracle 0.4705 (0.5468) kd_loss 0.8222 (0.8543) acc 100.0000 (91.1458) gate/entropy 0.9983 (0.9987) gate/usage_max 0.5508 (0.5504) gate/usage_min 0.2094 (0.2093) gate/usage_std 0.1543 (0.1540) teacher/entropy 0.0353 (0.0458) teacher/usage_max 0.7171 (0.6703) teacher/usage_min 0.0939 (0.1027) teacher/usage_std 0.2741 (0.2461) nleep/row_max_mean 1521.9257 (1508.1889) nleep/row_max_std 59.7319 (59.2930) nleep/row_min_mean 1492.6964 (1480.9367) lr 6.3188e-04 eta 0:07:34
epoch [33/50] batch [80/162] time 0.166 (0.164) data 0.000 (0.003) loss 1.5671 (1.3692) teacher_loss 0.5033 (0.2246) loss_zs_kd 0.0485 (0.0393) loss_oracle 0.6301 (0.5475) kd_loss 0.7245 (0.8512) acc 81.2500 (90.6250) gate/entropy 0.9988 (0.9986) gate/usage_max 0.5502 (0.5504) gate/usage_min 0.2094 (0.2094) gate/usage_std 0.1539 (0.1540) teacher/entropy 0.0683 (0.0489) teacher/usage_max 0.7825 (0.6707) teacher/usage_min 0.1055 (0.1015) teacher/usage_std 0.3176 (0.2469) nleep/row_max_mean 1506.9012 (1507.8866) nleep/row_max_std 54.4389 (59.5800) nleep/row_min_mean 1476.4851 (1480.4183) lr 6.3188e-04 eta 0:07:45
epoch [33/50] batch [100/162] time 0.186 (0.169) data 0.000 (0.003) loss 1.3822 (1.3753) teacher_loss 0.1588 (0.2218) loss_zs_kd 0.0381 (0.0398) loss_oracle 0.5746 (0.5525) kd_loss 0.9170 (0.8573) acc 96.8750 (90.5938) gate/entropy 0.9987 (0.9986) gate/usage_max 0.5503 (0.5505) gate/usage_min 0.2094 (0.2094) gate/usage_std 0.1539 (0.1540) teacher/entropy 0.0103 (0.0456) teacher/usage_max 0.6535 (0.6675) teacher/usage_min 0.0313 (0.1029) teacher/usage_std 0.2544 (0.2448) nleep/row_max_mean 1499.2861 (1507.6147) nleep/row_max_std 68.4300 (59.2935) nleep/row_min_mean 1469.8051 (1479.7269) lr 6.3188e-04 eta 0:07:54
epoch [33/50] batch [120/162] time 0.196 (0.169) data 0.000 (0.002) loss 1.3927 (1.3695) teacher_loss 0.2112 (0.2192) loss_zs_kd 0.0422 (0.0413) loss_oracle 0.5813 (0.5513) kd_loss 0.8697 (0.8540) acc 96.8750 (90.8333) gate/entropy 0.9985 (0.9985) gate/usage_max 0.5506 (0.5505) gate/usage_min 0.2094 (0.2094) gate/usage_std 0.1541 (0.1541) teacher/entropy 0.0577 (0.0439) teacher/usage_max 0.6480 (0.6728) teacher/usage_min 0.0699 (0.1020) teacher/usage_std 0.2388 (0.2480) nleep/row_max_mean 1500.3855 (1508.1952) nleep/row_max_std 56.2892 (58.8563) nleep/row_min_mean 1472.4437 (1480.1294) lr 6.3188e-04 eta 0:07:53
epoch [33/50] batch [140/162] time 0.168 (0.171) data 0.000 (0.002) loss 1.4226 (1.3668) teacher_loss 0.3005 (0.2221) loss_zs_kd 0.0542 (0.0418) loss_oracle 0.6234 (0.5522) kd_loss 0.7834 (0.8478) acc 90.6250 (90.7143) gate/entropy 0.9981 (0.9985) gate/usage_max 0.5510 (0.5506) gate/usage_min 0.2095 (0.2094) gate/usage_std 0.1544 (0.1541) teacher/entropy 0.0267 (0.0433) teacher/usage_max 0.7561 (0.6799) teacher/usage_min 0.0857 (0.1008) teacher/usage_std 0.3004 (0.2525) nleep/row_max_mean 1515.9006 (1508.7152) nleep/row_max_std 57.3744 (58.4973) nleep/row_min_mean 1485.6659 (1480.4493) lr 6.3188e-04 eta 0:07:54
epoch [33/50] batch [160/162] time 0.168 (0.173) data 0.000 (0.002) loss 1.4536 (1.3649) teacher_loss 0.3395 (0.2201) loss_zs_kd 0.0218 (0.0417) loss_oracle 0.5159 (0.5534) kd_loss 0.8453 (0.8472) acc 90.6250 (90.8984) gate/entropy 0.9985 (0.9985) gate/usage_max 0.5505 (0.5506) gate/usage_min 0.2095 (0.2094) gate/usage_std 0.1541 (0.1541) teacher/entropy 0.0558 (0.0428) teacher/usage_max 0.6770 (0.6810) teacher/usage_min 0.0581 (0.1014) teacher/usage_std 0.2573 (0.2530) nleep/row_max_mean 1506.1256 (1508.5952) nleep/row_max_std 57.7570 (58.3878) nleep/row_min_mean 1478.0793 (1480.1920) lr 6.3188e-04 eta 0:07:57
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,922
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,354
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 69.7%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [34/50] batch [20/162] time 0.178 (0.188) data 0.000 (0.012) loss 1.1735 (1.3419) teacher_loss 0.1937 (0.2199) loss_zs_kd 0.0243 (0.0359) loss_oracle 0.4505 (0.5458) kd_loss 0.7425 (0.8312) acc 93.7500 (91.0938) gate/entropy 0.9983 (0.9982) gate/usage_max 0.5508 (0.5510) gate/usage_min 0.2096 (0.2095) gate/usage_std 0.1542 (0.1544) teacher/entropy 0.0215 (0.0320) teacher/usage_max 0.8190 (0.7089) teacher/usage_min 0.0560 (0.1029) teacher/usage_std 0.3446 (0.2690) nleep/row_max_mean 1514.5122 (1509.7966) nleep/row_max_std 53.1217 (58.6229) nleep/row_min_mean 1485.4066 (1480.5687) lr 5.7422e-04 eta 0:08:32
epoch [34/50] batch [40/162] time 0.160 (0.183) data 0.000 (0.006) loss 1.3917 (1.3568) teacher_loss 0.2910 (0.2233) loss_zs_kd 0.0382 (0.0386) loss_oracle 0.5782 (0.5542) kd_loss 0.7925 (0.8372) acc 81.2500 (91.0156) gate/entropy 0.9979 (0.9981) gate/usage_max 0.5513 (0.5510) gate/usage_min 0.2095 (0.2095) gate/usage_std 0.1546 (0.1544) teacher/entropy 0.0579 (0.0347) teacher/usage_max 0.7202 (0.7005) teacher/usage_min 0.1202 (0.1026) teacher/usage_std 0.2740 (0.2654) nleep/row_max_mean 1504.6147 (1507.8165) nleep/row_max_std 56.3174 (60.1538) nleep/row_min_mean 1478.5278 (1479.0055) lr 5.7422e-04 eta 0:08:15
epoch [34/50] batch [60/162] time 0.079 (0.169) data 0.001 (0.004) loss 1.4898 (1.3510) teacher_loss 0.1879 (0.2189) loss_zs_kd 0.0362 (0.0396) loss_oracle 0.6218 (0.5478) kd_loss 0.9730 (0.8383) acc 93.7500 (90.8854) gate/entropy 0.9978 (0.9981) gate/usage_max 0.5515 (0.5510) gate/usage_min 0.2095 (0.2095) gate/usage_std 0.1547 (0.1544) teacher/entropy 0.0232 (0.0331) teacher/usage_max 0.5719 (0.7009) teacher/usage_min 0.0942 (0.0981) teacher/usage_std 0.1950 (0.2663) nleep/row_max_mean 1492.8145 (1508.0144) nleep/row_max_std 75.6516 (59.5535) nleep/row_min_mean 1465.2522 (1479.0986) lr 5.7422e-04 eta 0:07:36
epoch [34/50] batch [80/162] time 0.165 (0.163) data 0.000 (0.003) loss 1.4787 (1.3560) teacher_loss 0.3302 (0.2201) loss_zs_kd 0.0713 (0.0396) loss_oracle 0.5908 (0.5496) kd_loss 0.8175 (0.8413) acc 81.2500 (90.8594) gate/entropy 0.9982 (0.9981) gate/usage_max 0.5509 (0.5511) gate/usage_min 0.2096 (0.2095) gate/usage_std 0.1543 (0.1544) teacher/entropy 0.0522 (0.0329) teacher/usage_max 0.6899 (0.6973) teacher/usage_min 0.1140 (0.0998) teacher/usage_std 0.2543 (0.2635) nleep/row_max_mean 1500.9819 (1507.3223) nleep/row_max_std 58.6964 (59.4314) nleep/row_min_mean 1468.6470 (1478.3477) lr 5.7422e-04 eta 0:07:16
epoch [34/50] batch [100/162] time 0.174 (0.168) data 0.000 (0.002) loss 1.3202 (1.3575) teacher_loss 0.1569 (0.2259) loss_zs_kd 0.0250 (0.0399) loss_oracle 0.6257 (0.5479) kd_loss 0.8380 (0.8378) acc 93.7500 (90.5312) gate/entropy 0.9979 (0.9981) gate/usage_max 0.5513 (0.5511) gate/usage_min 0.2096 (0.2095) gate/usage_std 0.1546 (0.1545) teacher/entropy 0.0111 (0.0338) teacher/usage_max 0.7160 (0.7002) teacher/usage_min 0.1270 (0.0982) teacher/usage_std 0.2709 (0.2654) nleep/row_max_mean 1504.9504 (1507.2941) nleep/row_max_std 63.6366 (59.2752) nleep/row_min_mean 1474.6277 (1478.3475) lr 5.7422e-04 eta 0:07:24
epoch [34/50] batch [120/162] time 0.209 (0.165) data 0.000 (0.002) loss 1.4932 (1.3568) teacher_loss 0.2157 (0.2265) loss_zs_kd 0.0361 (0.0400) loss_oracle 0.6157 (0.5439) kd_loss 0.9517 (0.8384) acc 84.3750 (90.4167) gate/entropy 0.9979 (0.9981) gate/usage_max 0.5513 (0.5511) gate/usage_min 0.2096 (0.2095) gate/usage_std 0.1546 (0.1545) teacher/entropy 0.0180 (0.0336) teacher/usage_max 0.6003 (0.6998) teacher/usage_min 0.0938 (0.0975) teacher/usage_std 0.2077 (0.2652) nleep/row_max_mean 1486.4028 (1507.3382) nleep/row_max_std 57.7985 (59.5518) nleep/row_min_mean 1462.4048 (1478.3300) lr 5.7422e-04 eta 0:07:13
epoch [34/50] batch [140/162] time 0.168 (0.163) data 0.000 (0.002) loss 1.1525 (1.3552) teacher_loss 0.1551 (0.2227) loss_zs_kd 0.0215 (0.0397) loss_oracle 0.3722 (0.5418) kd_loss 0.8006 (0.8418) acc 93.7500 (90.6920) gate/entropy 0.9977 (0.9980) gate/usage_max 0.5516 (0.5512) gate/usage_min 0.2096 (0.2096) gate/usage_std 0.1548 (0.1545) teacher/entropy 0.0017 (0.0329) teacher/usage_max 0.7812 (0.6969) teacher/usage_min 0.0312 (0.0986) teacher/usage_std 0.3231 (0.2635) nleep/row_max_mean 1521.4395 (1507.1641) nleep/row_max_std 49.3988 (59.9111) nleep/row_min_mean 1491.1093 (1478.1097) lr 5.7422e-04 eta 0:07:06
epoch [34/50] batch [160/162] time 0.170 (0.165) data 0.000 (0.002) loss 1.3845 (1.3494) teacher_loss 0.3219 (0.2190) loss_zs_kd 0.0548 (0.0404) loss_oracle 0.4549 (0.5380) kd_loss 0.8077 (0.8411) acc 87.5000 (90.8789) gate/entropy 0.9974 (0.9980) gate/usage_max 0.5520 (0.5512) gate/usage_min 0.2097 (0.2096) gate/usage_std 0.1550 (0.1545) teacher/entropy 0.0164 (0.0314) teacher/usage_max 0.7540 (0.6993) teacher/usage_min 0.0630 (0.0971) teacher/usage_std 0.3014 (0.2651) nleep/row_max_mean 1531.6742 (1507.5685) nleep/row_max_std 53.6930 (59.8140) nleep/row_min_mean 1499.9280 (1478.3577) lr 5.7422e-04 eta 0:07:09
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,920
* accuracy: 85.9%
* error: 14.1%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,406
* accuracy: 73.3%
* error: 26.7%
* macro_f1: 71.5%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [35/50] batch [20/162] time 0.169 (0.202) data 0.000 (0.014) loss 1.5460 (1.3636) teacher_loss 0.3409 (0.2416) loss_zs_kd 0.0366 (0.0399) loss_oracle 0.5867 (0.5329) kd_loss 0.8934 (0.8357) acc 87.5000 (89.5312) gate/entropy 0.9976 (0.9977) gate/usage_max 0.5517 (0.5516) gate/usage_min 0.2097 (0.2097) gate/usage_std 0.1549 (0.1548) teacher/entropy 0.0344 (0.0351) teacher/usage_max 0.6469 (0.7028) teacher/usage_min 0.0659 (0.0878) teacher/usage_std 0.2394 (0.2690) nleep/row_max_mean 1501.7489 (1508.0490) nleep/row_max_std 55.9599 (55.9714) nleep/row_min_mean 1472.7466 (1479.1965) lr 5.1825e-04 eta 0:08:40
epoch [35/50] batch [40/162] time 0.196 (0.194) data 0.000 (0.007) loss 1.2088 (1.3530) teacher_loss 0.1159 (0.2246) loss_zs_kd 0.0585 (0.0405) loss_oracle 0.4738 (0.5563) kd_loss 0.8267 (0.8300) acc 93.7500 (90.7031) gate/entropy 0.9972 (0.9976) gate/usage_max 0.5521 (0.5517) gate/usage_min 0.2097 (0.2097) gate/usage_std 0.1551 (0.1548) teacher/entropy 0.0007 (0.0304) teacher/usage_max 0.7500 (0.7121) teacher/usage_min 0.0625 (0.0891) teacher/usage_std 0.2990 (0.2738) nleep/row_max_mean 1522.2023 (1508.6238) nleep/row_max_std 57.6169 (57.3191) nleep/row_min_mean 1490.5760 (1479.2982) lr 5.1825e-04 eta 0:08:15
epoch [35/50] batch [60/162] time 0.125 (0.189) data 0.000 (0.005) loss 1.3214 (1.3469) teacher_loss 0.1225 (0.2134) loss_zs_kd 0.0445 (0.0403) loss_oracle 0.5863 (0.5600) kd_loss 0.8835 (0.8333) acc 100.0000 (91.1458) gate/entropy 0.9975 (0.9976) gate/usage_max 0.5518 (0.5517) gate/usage_min 0.2097 (0.2097) gate/usage_std 0.1549 (0.1549) teacher/entropy 0.0006 (0.0289) teacher/usage_max 0.6874 (0.7097) teacher/usage_min 0.0938 (0.0941) teacher/usage_std 0.2555 (0.2712) nleep/row_max_mean 1501.9441 (1507.7902) nleep/row_max_std 69.2795 (58.1792) nleep/row_min_mean 1474.2310 (1478.3410) lr 5.1825e-04 eta 0:07:59
epoch [35/50] batch [80/162] time 0.196 (0.188) data 0.000 (0.004) loss 1.5727 (1.3508) teacher_loss 0.2706 (0.2145) loss_zs_kd 0.0345 (0.0405) loss_oracle 0.5994 (0.5685) kd_loss 0.9851 (0.8319) acc 90.6250 (91.0938) gate/entropy 0.9976 (0.9976) gate/usage_max 0.5517 (0.5517) gate/usage_min 0.2097 (0.2097) gate/usage_std 0.1549 (0.1549) teacher/entropy 0.0214 (0.0290) teacher/usage_max 0.5564 (0.7103) teacher/usage_min 0.1264 (0.0956) teacher/usage_std 0.1759 (0.2716) nleep/row_max_mean 1496.5918 (1507.7972) nleep/row_max_std 62.8328 (57.7761) nleep/row_min_mean 1468.7893 (1478.2864) lr 5.1825e-04 eta 0:07:52
epoch [35/50] batch [100/162] time 0.196 (0.188) data 0.000 (0.003) loss 1.5325 (1.3540) teacher_loss 0.3869 (0.2139) loss_zs_kd 0.0415 (0.0415) loss_oracle 0.6177 (0.5736) kd_loss 0.8161 (0.8325) acc 81.2500 (91.1875) gate/entropy 0.9975 (0.9976) gate/usage_max 0.5519 (0.5517) gate/usage_min 0.2097 (0.2097) gate/usage_std 0.1550 (0.1549) teacher/entropy 0.0596 (0.0285) teacher/usage_max 0.6771 (0.7098) teacher/usage_min 0.0852 (0.0964) teacher/usage_std 0.2509 (0.2710) nleep/row_max_mean 1504.3989 (1507.6997) nleep/row_max_std 61.7813 (57.8206) nleep/row_min_mean 1473.9948 (1477.9854) lr 5.1825e-04 eta 0:07:48
epoch [35/50] batch [120/162] time 0.196 (0.188) data 0.000 (0.002) loss 1.2894 (1.3508) teacher_loss 0.1647 (0.2154) loss_zs_kd 0.0313 (0.0415) loss_oracle 0.4917 (0.5664) kd_loss 0.8633 (0.8314) acc 96.8750 (91.3021) gate/entropy 0.9973 (0.9975) gate/usage_max 0.5521 (0.5518) gate/usage_min 0.2097 (0.2097) gate/usage_std 0.1551 (0.1549) teacher/entropy 0.0250 (0.0273) teacher/usage_max 0.6876 (0.7125) teacher/usage_min 0.0662 (0.0944) teacher/usage_std 0.2611 (0.2729) nleep/row_max_mean 1514.6963 (1508.1007) nleep/row_max_std 57.2618 (57.5331) nleep/row_min_mean 1485.5291 (1478.3685) lr 5.1825e-04 eta 0:07:45
epoch [35/50] batch [140/162] time 0.105 (0.179) data 0.000 (0.002) loss 1.2919 (1.3469) teacher_loss 0.1089 (0.2145) loss_zs_kd 0.0545 (0.0415) loss_oracle 0.5795 (0.5643) kd_loss 0.8659 (0.8295) acc 96.8750 (91.2054) gate/entropy 0.9975 (0.9975) gate/usage_max 0.5518 (0.5518) gate/usage_min 0.2097 (0.2097) gate/usage_std 0.1549 (0.1549) teacher/entropy 0.0362 (0.0263) teacher/usage_max 0.6618 (0.7156) teacher/usage_min 0.1463 (0.0940) teacher/usage_std 0.2330 (0.2749) nleep/row_max_mean 1503.5824 (1508.4418) nleep/row_max_std 63.2896 (57.8226) nleep/row_min_mean 1472.6932 (1478.6104) lr 5.1825e-04 eta 0:07:18
epoch [35/50] batch [160/162] time 0.207 (0.180) data 0.000 (0.002) loss 1.3518 (1.3477) teacher_loss 0.2524 (0.2143) loss_zs_kd 0.0393 (0.0414) loss_oracle 0.5181 (0.5645) kd_loss 0.8207 (0.8304) acc 93.7500 (91.4258) gate/entropy 0.9972 (0.9975) gate/usage_max 0.5521 (0.5518) gate/usage_min 0.2098 (0.2097) gate/usage_std 0.1551 (0.1549) teacher/entropy 0.0160 (0.0264) teacher/usage_max 0.7449 (0.7145) teacher/usage_min 0.0316 (0.0933) teacher/usage_std 0.3014 (0.2743) nleep/row_max_mean 1513.5785 (1508.6422) nleep/row_max_std 55.5011 (57.5823) nleep/row_min_mean 1484.3577 (1478.8280) lr 5.1825e-04 eta 0:07:16
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,922
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,369
* accuracy: 72.2%
* error: 27.8%
* macro_f1: 71.8%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [36/50] batch [20/162] time 0.168 (0.204) data 0.000 (0.017) loss 1.4477 (1.3296) teacher_loss 0.2579 (0.1922) loss_zs_kd 0.0364 (0.0374) loss_oracle 0.6354 (0.5573) kd_loss 0.8538 (0.8401) acc 84.3750 (92.9688) gate/entropy 0.9973 (0.9973) gate/usage_max 0.5521 (0.5521) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1551 (0.1551) teacher/entropy 0.0437 (0.0227) teacher/usage_max 0.6739 (0.7066) teacher/usage_min 0.0912 (0.0920) teacher/usage_std 0.2479 (0.2692) nleep/row_max_mean 1512.5632 (1511.7273) nleep/row_max_std 66.1619 (55.9162) nleep/row_min_mean 1481.7765 (1482.0057) lr 4.6417e-04 eta 0:08:11
epoch [36/50] batch [40/162] time 0.182 (0.193) data 0.000 (0.008) loss 1.3986 (1.3630) teacher_loss 0.2256 (0.1992) loss_zs_kd 0.0312 (0.0384) loss_oracle 0.5986 (0.5928) kd_loss 0.8580 (0.8482) acc 90.6250 (92.5781) gate/entropy 0.9972 (0.9973) gate/usage_max 0.5521 (0.5521) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1552 (0.1551) teacher/entropy 0.0275 (0.0225) teacher/usage_max 0.6818 (0.6973) teacher/usage_min 0.1251 (0.1026) teacher/usage_std 0.2479 (0.2620) nleep/row_max_mean 1518.0786 (1509.0794) nleep/row_max_std 52.0589 (56.0861) nleep/row_min_mean 1487.8579 (1479.7150) lr 4.6417e-04 eta 0:07:41
epoch [36/50] batch [60/162] time 0.183 (0.191) data 0.000 (0.006) loss 1.1930 (1.3666) teacher_loss 0.1633 (0.2055) loss_zs_kd 0.0336 (0.0392) loss_oracle 0.4865 (0.5901) kd_loss 0.7697 (0.8464) acc 93.7500 (91.9271) gate/entropy 0.9970 (0.9973) gate/usage_max 0.5524 (0.5521) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1551) teacher/entropy 0.0538 (0.0237) teacher/usage_max 0.7536 (0.6986) teacher/usage_min 0.0665 (0.1025) teacher/usage_std 0.3007 (0.2635) nleep/row_max_mean 1518.6467 (1509.5368) nleep/row_max_std 53.9781 (55.5374) nleep/row_min_mean 1489.6030 (1480.1463) lr 4.6417e-04 eta 0:07:31
epoch [36/50] batch [80/162] time 0.186 (0.189) data 0.001 (0.004) loss 1.2576 (1.3644) teacher_loss 0.1571 (0.2040) loss_zs_kd 0.0317 (0.0398) loss_oracle 0.5124 (0.5889) kd_loss 0.8284 (0.8461) acc 93.7500 (92.0312) gate/entropy 0.9971 (0.9973) gate/usage_max 0.5522 (0.5521) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1552 (0.1551) teacher/entropy 0.0028 (0.0243) teacher/usage_max 0.7501 (0.6981) teacher/usage_min 0.0314 (0.1033) teacher/usage_std 0.3044 (0.2631) nleep/row_max_mean 1521.4442 (1509.8156) nleep/row_max_std 57.3474 (55.2538) nleep/row_min_mean 1493.8540 (1480.5264) lr 4.6417e-04 eta 0:07:24
epoch [36/50] batch [100/162] time 0.197 (0.189) data 0.000 (0.003) loss 1.3373 (1.3645) teacher_loss 0.1660 (0.2118) loss_zs_kd 0.0433 (0.0400) loss_oracle 0.5679 (0.5857) kd_loss 0.8657 (0.8399) acc 93.7500 (91.8125) gate/entropy 0.9974 (0.9973) gate/usage_max 0.5520 (0.5521) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1550 (0.1551) teacher/entropy 0.0255 (0.0263) teacher/usage_max 0.6810 (0.7027) teacher/usage_min 0.0945 (0.1024) teacher/usage_std 0.2515 (0.2659) nleep/row_max_mean 1505.3962 (1509.8860) nleep/row_max_std 54.1935 (55.1210) nleep/row_min_mean 1475.9963 (1480.7158) lr 4.6417e-04 eta 0:07:19
epoch [36/50] batch [120/162] time 0.197 (0.189) data 0.000 (0.003) loss 1.2298 (1.3613) teacher_loss 0.1353 (0.2124) loss_zs_kd 0.0401 (0.0395) loss_oracle 0.5546 (0.5824) kd_loss 0.7971 (0.8380) acc 93.7500 (91.5885) gate/entropy 0.9970 (0.9973) gate/usage_max 0.5524 (0.5521) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1551) teacher/entropy 0.0168 (0.0257) teacher/usage_max 0.7568 (0.7054) teacher/usage_min 0.1182 (0.1033) teacher/usage_std 0.2995 (0.2675) nleep/row_max_mean 1525.1748 (1509.8247) nleep/row_max_std 51.9618 (55.1912) nleep/row_min_mean 1496.3291 (1480.6332) lr 4.6417e-04 eta 0:07:16
epoch [36/50] batch [140/162] time 0.171 (0.188) data 0.000 (0.003) loss 1.4317 (1.3626) teacher_loss 0.3757 (0.2167) loss_zs_kd 0.0730 (0.0393) loss_oracle 0.4795 (0.5781) kd_loss 0.7798 (0.8372) acc 84.3750 (91.4062) gate/entropy 0.9972 (0.9973) gate/usage_max 0.5522 (0.5521) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1552 (0.1551) teacher/entropy 0.0171 (0.0264) teacher/usage_max 0.7815 (0.7059) teacher/usage_min 0.0612 (0.1023) teacher/usage_std 0.3193 (0.2678) nleep/row_max_mean 1518.1741 (1509.7668) nleep/row_max_std 52.4075 (55.4744) nleep/row_min_mean 1489.1591 (1480.6528) lr 4.6417e-04 eta 0:07:11
epoch [36/50] batch [160/162] time 0.182 (0.188) data 0.000 (0.002) loss 1.4682 (1.3625) teacher_loss 0.1926 (0.2159) loss_zs_kd 0.0373 (0.0394) loss_oracle 0.6831 (0.5766) kd_loss 0.9154 (0.8386) acc 87.5000 (91.4258) gate/entropy 0.9974 (0.9973) gate/usage_max 0.5520 (0.5521) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1551 (0.1551) teacher/entropy 0.0312 (0.0262) teacher/usage_max 0.6222 (0.7047) teacher/usage_min 0.1039 (0.1021) teacher/usage_std 0.2157 (0.2671) nleep/row_max_mean 1493.9204 (1509.6147) nleep/row_max_std 52.4910 (55.5472) nleep/row_min_mean 1465.9941 (1480.5823) lr 4.6417e-04 eta 0:07:06
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,918
* accuracy: 85.9%
* error: 14.1%
* macro_f1: 86.4%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,364
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 69.7%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [37/50] batch [20/162] time 0.207 (0.193) data 0.000 (0.018) loss 1.2596 (1.3659) teacher_loss 0.1485 (0.2277) loss_zs_kd 0.0511 (0.0426) loss_oracle 0.5643 (0.5616) kd_loss 0.8033 (0.8360) acc 93.7500 (91.5625) gate/entropy 0.9972 (0.9971) gate/usage_max 0.5522 (0.5523) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1552 (0.1552) teacher/entropy 0.0294 (0.0191) teacher/usage_max 0.7450 (0.7152) teacher/usage_min 0.0626 (0.0993) teacher/usage_std 0.2959 (0.2760) nleep/row_max_mean 1517.5046 (1513.4224) nleep/row_max_std 47.8515 (52.2017) nleep/row_min_mean 1486.3923 (1483.8065) lr 4.1221e-04 eta 0:07:13
epoch [37/50] batch [40/162] time 0.189 (0.191) data 0.000 (0.009) loss 1.4324 (1.3536) teacher_loss 0.3413 (0.2292) loss_zs_kd 0.0321 (0.0387) loss_oracle 0.5442 (0.5613) kd_loss 0.8030 (0.8245) acc 87.5000 (91.4844) gate/entropy 0.9971 (0.9971) gate/usage_max 0.5523 (0.5523) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1552) teacher/entropy 0.0479 (0.0271) teacher/usage_max 0.7191 (0.7192) teacher/usage_min 0.1076 (0.0962) teacher/usage_std 0.2741 (0.2776) nleep/row_max_mean 1513.1071 (1512.9596) nleep/row_max_std 52.9894 (52.8523) nleep/row_min_mean 1481.6912 (1483.3265) lr 4.1221e-04 eta 0:07:04
epoch [37/50] batch [60/162] time 0.158 (0.171) data 0.000 (0.006) loss 1.2924 (1.3391) teacher_loss 0.1924 (0.2101) loss_zs_kd 0.0347 (0.0382) loss_oracle 0.6746 (0.5672) kd_loss 0.7453 (0.8263) acc 90.6250 (92.1354) gate/entropy 0.9971 (0.9971) gate/usage_max 0.5523 (0.5523) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1552) teacher/entropy 0.0440 (0.0289) teacher/usage_max 0.7855 (0.7148) teacher/usage_min 0.0921 (0.1001) teacher/usage_std 0.3200 (0.2743) nleep/row_max_mean 1515.9647 (1512.4485) nleep/row_max_std 46.4255 (53.0975) nleep/row_min_mean 1491.0481 (1483.2106) lr 4.1221e-04 eta 0:06:16
epoch [37/50] batch [80/162] time 0.183 (0.169) data 0.000 (0.005) loss 1.2091 (1.3601) teacher_loss 0.1565 (0.2231) loss_zs_kd 0.0591 (0.0406) loss_oracle 0.5253 (0.5769) kd_loss 0.7605 (0.8283) acc 93.7500 (91.1328) gate/entropy 0.9968 (0.9971) gate/usage_max 0.5526 (0.5523) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1553) teacher/entropy 0.0434 (0.0308) teacher/usage_max 0.7738 (0.7109) teacher/usage_min 0.0646 (0.1014) teacher/usage_std 0.3140 (0.2717) nleep/row_max_mean 1514.5723 (1511.6425) nleep/row_max_std 57.4688 (53.6171) nleep/row_min_mean 1487.1509 (1482.4952) lr 4.1221e-04 eta 0:06:10
epoch [37/50] batch [100/162] time 0.194 (0.172) data 0.000 (0.004) loss 1.4370 (1.3603) teacher_loss 0.2564 (0.2254) loss_zs_kd 0.0334 (0.0411) loss_oracle 0.6452 (0.5813) kd_loss 0.8413 (0.8238) acc 90.6250 (90.8438) gate/entropy 0.9972 (0.9971) gate/usage_max 0.5522 (0.5523) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1552 (0.1553) teacher/entropy 0.0421 (0.0313) teacher/usage_max 0.6774 (0.7154) teacher/usage_min 0.1441 (0.0981) teacher/usage_std 0.2437 (0.2749) nleep/row_max_mean 1502.7867 (1511.8986) nleep/row_max_std 54.7682 (53.6855) nleep/row_min_mean 1475.1033 (1482.8822) lr 4.1221e-04 eta 0:06:13
epoch [37/50] batch [120/162] time 0.195 (0.173) data 0.000 (0.003) loss 1.3800 (1.3596) teacher_loss 0.1657 (0.2176) loss_zs_kd 0.0413 (0.0408) loss_oracle 0.6542 (0.5881) kd_loss 0.8665 (0.8275) acc 93.7500 (91.3021) gate/entropy 0.9969 (0.9971) gate/usage_max 0.5525 (0.5523) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1554 (0.1553) teacher/entropy 0.0047 (0.0304) teacher/usage_max 0.6880 (0.7119) teacher/usage_min 0.1245 (0.0997) teacher/usage_std 0.2521 (0.2723) nleep/row_max_mean 1520.3397 (1511.0034) nleep/row_max_std 48.2582 (54.2403) nleep/row_min_mean 1491.9590 (1481.9459) lr 4.1221e-04 eta 0:06:12
epoch [37/50] batch [140/162] time 0.196 (0.176) data 0.000 (0.003) loss 1.4386 (1.3618) teacher_loss 0.2961 (0.2139) loss_zs_kd 0.0406 (0.0410) loss_oracle 0.6070 (0.5909) kd_loss 0.8188 (0.8319) acc 87.5000 (91.4286) gate/entropy 0.9971 (0.9971) gate/usage_max 0.5523 (0.5523) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1553) teacher/entropy 0.0000 (0.0292) teacher/usage_max 0.7500 (0.7086) teacher/usage_min 0.1250 (0.1000) teacher/usage_std 0.2946 (0.2703) nleep/row_max_mean 1512.8232 (1509.9705) nleep/row_max_std 57.7450 (55.0034) nleep/row_min_mean 1481.5092 (1480.9982) lr 4.1221e-04 eta 0:06:15
epoch [37/50] batch [160/162] time 0.195 (0.178) data 0.000 (0.002) loss 1.5331 (1.3648) teacher_loss 0.2413 (0.2149) loss_zs_kd 0.0591 (0.0414) loss_oracle 0.5869 (0.5892) kd_loss 0.9688 (0.8346) acc 90.6250 (91.2891) gate/entropy 0.9972 (0.9971) gate/usage_max 0.5522 (0.5523) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1552 (0.1553) teacher/entropy 0.0372 (0.0290) teacher/usage_max 0.5496 (0.7058) teacher/usage_min 0.1875 (0.1017) teacher/usage_std 0.1560 (0.2684) nleep/row_max_mean 1489.9247 (1509.5896) nleep/row_max_std 63.5679 (55.2490) nleep/row_min_mean 1460.0903 (1480.5765) lr 4.1221e-04 eta 0:06:14
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,928
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,347
* accuracy: 71.5%
* error: 28.5%
* macro_f1: 69.6%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [38/50] batch [20/162] time 0.195 (0.205) data 0.000 (0.016) loss 1.4672 (1.3512) teacher_loss 0.2926 (0.2275) loss_zs_kd 0.0355 (0.0402) loss_oracle 0.5397 (0.5452) kd_loss 0.8870 (0.8310) acc 90.6250 (90.9375) gate/entropy 0.9966 (0.9970) gate/usage_max 0.5528 (0.5524) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1553) teacher/entropy 0.0230 (0.0289) teacher/usage_max 0.6524 (0.7098) teacher/usage_min 0.1562 (0.1051) teacher/usage_std 0.2261 (0.2696) nleep/row_max_mean 1515.6895 (1511.6471) nleep/row_max_std 60.5775 (55.4790) nleep/row_min_mean 1487.6989 (1482.7434) lr 3.6258e-04 eta 0:07:07
epoch [38/50] batch [40/162] time 0.168 (0.199) data 0.000 (0.008) loss 1.2948 (1.3509) teacher_loss 0.1786 (0.2230) loss_zs_kd 0.0319 (0.0376) loss_oracle 0.4559 (0.5483) kd_loss 0.8723 (0.8350) acc 93.7500 (91.0938) gate/entropy 0.9968 (0.9970) gate/usage_max 0.5527 (0.5524) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1553) teacher/entropy 0.0104 (0.0315) teacher/usage_max 0.6874 (0.7026) teacher/usage_min 0.0966 (0.1076) teacher/usage_std 0.2550 (0.2643) nleep/row_max_mean 1515.3962 (1510.4895) nleep/row_max_std 68.5636 (56.0854) nleep/row_min_mean 1485.4604 (1481.7981) lr 3.6258e-04 eta 0:06:50
epoch [38/50] batch [60/162] time 0.068 (0.191) data 0.001 (0.005) loss 1.3931 (1.3653) teacher_loss 0.2249 (0.2296) loss_zs_kd 0.0395 (0.0380) loss_oracle 0.6801 (0.5602) kd_loss 0.8084 (0.8366) acc 90.6250 (91.0938) gate/entropy 0.9969 (0.9970) gate/usage_max 0.5525 (0.5524) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1554 (0.1553) teacher/entropy 0.0579 (0.0305) teacher/usage_max 0.6956 (0.7016) teacher/usage_min 0.1347 (0.1041) teacher/usage_std 0.2565 (0.2642) nleep/row_max_mean 1510.5580 (1508.1979) nleep/row_max_std 58.0881 (56.8169) nleep/row_min_mean 1482.4092 (1479.4000) lr 3.6258e-04 eta 0:06:30
epoch [38/50] batch [80/162] time 0.094 (0.174) data 0.000 (0.004) loss 1.5357 (1.3681) teacher_loss 0.1256 (0.2257) loss_zs_kd 0.0592 (0.0394) loss_oracle 0.6581 (0.5660) kd_loss 1.0514 (0.8396) acc 100.0000 (91.1328) gate/entropy 0.9969 (0.9970) gate/usage_max 0.5525 (0.5524) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1554 (0.1554) teacher/entropy 0.0087 (0.0303) teacher/usage_max 0.5014 (0.6988) teacher/usage_min 0.1236 (0.1035) teacher/usage_std 0.1570 (0.2630) nleep/row_max_mean 1486.3368 (1508.0975) nleep/row_max_std 62.3984 (57.0353) nleep/row_min_mean 1458.1863 (1479.3826) lr 3.6258e-04 eta 0:05:51
epoch [38/50] batch [100/162] time 0.191 (0.176) data 0.000 (0.003) loss 1.4397 (1.3636) teacher_loss 0.3329 (0.2222) loss_zs_kd 0.0770 (0.0403) loss_oracle 0.5243 (0.5704) kd_loss 0.8062 (0.8361) acc 87.5000 (91.4688) gate/entropy 0.9970 (0.9970) gate/usage_max 0.5524 (0.5524) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1554) teacher/entropy 0.0352 (0.0288) teacher/usage_max 0.7238 (0.7039) teacher/usage_min 0.1263 (0.1030) teacher/usage_std 0.2763 (0.2662) nleep/row_max_mean 1507.5637 (1508.1124) nleep/row_max_std 56.6599 (56.8072) nleep/row_min_mean 1477.1556 (1479.3855) lr 3.6258e-04 eta 0:05:52
epoch [38/50] batch [120/162] time 0.090 (0.172) data 0.001 (0.003) loss 1.5928 (1.3634) teacher_loss 0.2611 (0.2177) loss_zs_kd 0.0280 (0.0401) loss_oracle 0.7495 (0.5753) kd_loss 0.9430 (0.8380) acc 90.6250 (91.4844) gate/entropy 0.9971 (0.9970) gate/usage_max 0.5523 (0.5524) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1552 (0.1553) teacher/entropy 0.0331 (0.0289) teacher/usage_max 0.5830 (0.7020) teacher/usage_min 0.1676 (0.1025) teacher/usage_std 0.1797 (0.2651) nleep/row_max_mean 1492.3833 (1507.4029) nleep/row_max_std 56.9640 (56.7711) nleep/row_min_mean 1464.3452 (1478.7470) lr 3.6258e-04 eta 0:05:42
epoch [38/50] batch [140/162] time 0.087 (0.169) data 0.000 (0.002) loss 1.3893 (1.3637) teacher_loss 0.2252 (0.2158) loss_zs_kd 0.0556 (0.0416) loss_oracle 0.6058 (0.5786) kd_loss 0.8334 (0.8379) acc 90.6250 (91.6295) gate/entropy 0.9968 (0.9970) gate/usage_max 0.5526 (0.5525) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1554) teacher/entropy 0.0164 (0.0276) teacher/usage_max 0.7146 (0.7033) teacher/usage_min 0.1253 (0.1035) teacher/usage_std 0.2699 (0.2657) nleep/row_max_mean 1502.5599 (1507.2522) nleep/row_max_std 55.9199 (56.7714) nleep/row_min_mean 1472.4482 (1478.6042) lr 3.6258e-04 eta 0:05:32
epoch [38/50] batch [160/162] time 0.197 (0.171) data 0.000 (0.002) loss 1.3905 (1.3611) teacher_loss 0.1975 (0.2140) loss_zs_kd 0.0243 (0.0419) loss_oracle 0.5361 (0.5776) kd_loss 0.9128 (0.8373) acc 90.6250 (91.7188) gate/entropy 0.9969 (0.9970) gate/usage_max 0.5525 (0.5525) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1554 (0.1554) teacher/entropy 0.0013 (0.0281) teacher/usage_max 0.6561 (0.7032) teacher/usage_min 0.0938 (0.1040) teacher/usage_std 0.2370 (0.2655) nleep/row_max_mean 1503.9553 (1507.1463) nleep/row_max_std 57.3158 (56.8055) nleep/row_min_mean 1476.8600 (1478.5386) lr 3.6258e-04 eta 0:05:32
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,931
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 86.9%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,367
* accuracy: 72.1%
* error: 27.9%
* macro_f1: 70.8%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [39/50] batch [20/162] time 0.189 (0.201) data 0.000 (0.012) loss 1.3964 (1.3939) teacher_loss 0.1668 (0.2705) loss_zs_kd 0.0301 (0.0414) loss_oracle 0.4842 (0.5517) kd_loss 0.9725 (0.8269) acc 93.7500 (88.4375) gate/entropy 0.9971 (0.9969) gate/usage_max 0.5523 (0.5526) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1554) teacher/entropy 0.0050 (0.0267) teacher/usage_max 0.5948 (0.7178) teacher/usage_min 0.0625 (0.0903) teacher/usage_std 0.2174 (0.2776) nleep/row_max_mean 1482.0886 (1506.3519) nleep/row_max_std 66.9120 (55.1866) nleep/row_min_mean 1453.2119 (1478.1154) lr 3.1545e-04 eta 0:06:26
epoch [39/50] batch [40/162] time 0.196 (0.194) data 0.000 (0.006) loss 1.3929 (1.3741) teacher_loss 0.2684 (0.2297) loss_zs_kd 0.0228 (0.0385) loss_oracle 0.5727 (0.5742) kd_loss 0.8267 (0.8380) acc 93.7500 (90.6250) gate/entropy 0.9966 (0.9969) gate/usage_max 0.5529 (0.5526) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1554) teacher/entropy 0.0181 (0.0279) teacher/usage_max 0.7198 (0.7028) teacher/usage_min 0.1267 (0.1007) teacher/usage_std 0.2735 (0.2664) nleep/row_max_mean 1512.6226 (1504.8299) nleep/row_max_std 51.4888 (56.4092) nleep/row_min_mean 1487.1375 (1476.9402) lr 3.1545e-04 eta 0:06:08
epoch [39/50] batch [60/162] time 0.198 (0.194) data 0.001 (0.004) loss 1.1245 (1.3686) teacher_loss 0.1103 (0.2198) loss_zs_kd 0.0308 (0.0379) loss_oracle 0.4067 (0.5808) kd_loss 0.7954 (0.8394) acc 93.7500 (91.3021) gate/entropy 0.9969 (0.9969) gate/usage_max 0.5525 (0.5526) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1554 (0.1554) teacher/entropy 0.0018 (0.0301) teacher/usage_max 0.7810 (0.6986) teacher/usage_min 0.0625 (0.1071) teacher/usage_std 0.3189 (0.2627) nleep/row_max_mean 1506.4778 (1504.5495) nleep/row_max_std 55.0404 (57.3974) nleep/row_min_mean 1479.6240 (1476.6303) lr 3.1545e-04 eta 0:06:05
epoch [39/50] batch [80/162] time 0.170 (0.193) data 0.000 (0.003) loss 1.3770 (1.3650) teacher_loss 0.2257 (0.2132) loss_zs_kd 0.0251 (0.0387) loss_oracle 0.5587 (0.5885) kd_loss 0.8594 (0.8382) acc 90.6250 (91.4844) gate/entropy 0.9966 (0.9969) gate/usage_max 0.5529 (0.5525) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1554) teacher/entropy 0.0161 (0.0316) teacher/usage_max 0.6882 (0.6984) teacher/usage_min 0.1519 (0.1074) teacher/usage_std 0.2509 (0.2626) nleep/row_max_mean 1505.6941 (1504.5126) nleep/row_max_std 63.1054 (57.6723) nleep/row_min_mean 1478.0732 (1476.5593) lr 3.1545e-04 eta 0:05:59
epoch [39/50] batch [100/162] time 0.204 (0.193) data 0.000 (0.003) loss 1.3328 (1.3668) teacher_loss 0.2453 (0.2104) loss_zs_kd 0.0360 (0.0393) loss_oracle 0.5630 (0.5886) kd_loss 0.7879 (0.8425) acc 90.6250 (91.7812) gate/entropy 0.9967 (0.9969) gate/usage_max 0.5528 (0.5525) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1554) teacher/entropy 0.0440 (0.0310) teacher/usage_max 0.7391 (0.6946) teacher/usage_min 0.1016 (0.1087) teacher/usage_std 0.2879 (0.2602) nleep/row_max_mean 1511.0371 (1503.9360) nleep/row_max_std 57.2876 (57.7293) nleep/row_min_mean 1484.3756 (1476.1153) lr 3.1545e-04 eta 0:05:55
epoch [39/50] batch [120/162] time 0.182 (0.191) data 0.000 (0.002) loss 1.2491 (1.3624) teacher_loss 0.0722 (0.2122) loss_zs_kd 0.0384 (0.0387) loss_oracle 0.5413 (0.5823) kd_loss 0.8871 (0.8397) acc 100.0000 (91.6927) gate/entropy 0.9971 (0.9969) gate/usage_max 0.5523 (0.5526) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1554) teacher/entropy 0.0009 (0.0310) teacher/usage_max 0.6874 (0.6978) teacher/usage_min 0.0626 (0.1068) teacher/usage_std 0.2618 (0.2627) nleep/row_max_mean 1498.7693 (1504.4819) nleep/row_max_std 57.4418 (57.6400) nleep/row_min_mean 1469.5659 (1476.6414) lr 3.1545e-04 eta 0:05:48
epoch [39/50] batch [140/162] time 0.106 (0.185) data 0.002 (0.002) loss 1.3186 (1.3603) teacher_loss 0.2640 (0.2089) loss_zs_kd 0.0467 (0.0392) loss_oracle 0.5518 (0.5848) kd_loss 0.7553 (0.8394) acc 84.3750 (91.8527) gate/entropy 0.9965 (0.9969) gate/usage_max 0.5530 (0.5525) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1554) teacher/entropy 0.0040 (0.0321) teacher/usage_max 0.8117 (0.6965) teacher/usage_min 0.0633 (0.1084) teacher/usage_std 0.3392 (0.2616) nleep/row_max_mean 1518.6011 (1504.8149) nleep/row_max_std 45.5717 (57.5790) nleep/row_min_mean 1487.9628 (1476.9821) lr 3.1545e-04 eta 0:05:33
epoch [39/50] batch [160/162] time 0.153 (0.180) data 0.000 (0.002) loss 1.1840 (1.3554) teacher_loss 0.1805 (0.2102) loss_zs_kd 0.0519 (0.0399) loss_oracle 0.4389 (0.5794) kd_loss 0.7581 (0.8355) acc 93.7500 (91.8945) gate/entropy 0.9972 (0.9969) gate/usage_max 0.5522 (0.5526) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1552 (0.1554) teacher/entropy 0.0228 (0.0318) teacher/usage_max 0.7980 (0.7013) teacher/usage_min 0.0626 (0.1051) teacher/usage_std 0.3301 (0.2649) nleep/row_max_mean 1504.3947 (1505.3439) nleep/row_max_std 53.2961 (57.4012) nleep/row_min_mean 1474.9447 (1477.5173) lr 3.1545e-04 eta 0:05:20
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,932
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 87.0%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,379
* accuracy: 72.5%
* error: 27.5%
* macro_f1: 70.4%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [40/50] batch [20/162] time 0.155 (0.156) data 0.000 (0.013) loss 1.3702 (1.4004) teacher_loss 0.2190 (0.2229) loss_zs_kd 0.0316 (0.0418) loss_oracle 0.5818 (0.6247) kd_loss 0.8444 (0.8442) acc 87.5000 (91.7188) gate/entropy 0.9970 (0.9969) gate/usage_max 0.5524 (0.5526) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1553 (0.1554) teacher/entropy 0.0531 (0.0443) teacher/usage_max 0.6671 (0.6768) teacher/usage_min 0.1429 (0.1251) teacher/usage_std 0.2368 (0.2463) nleep/row_max_mean 1498.3065 (1499.9142) nleep/row_max_std 59.3042 (61.7681) nleep/row_min_mean 1470.0911 (1473.5530) lr 2.7103e-04 eta 0:04:34
epoch [40/50] batch [40/162] time 0.181 (0.164) data 0.000 (0.007) loss 1.2278 (1.3936) teacher_loss 0.1927 (0.2198) loss_zs_kd 0.0469 (0.0415) loss_oracle 0.4636 (0.6154) kd_loss 0.7798 (0.8453) acc 93.7500 (91.5625) gate/entropy 0.9970 (0.9969) gate/usage_max 0.5524 (0.5526) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1553 (0.1554) teacher/entropy 0.0147 (0.0375) teacher/usage_max 0.7759 (0.6821) teacher/usage_min 0.0991 (0.1213) teacher/usage_std 0.3131 (0.2501) nleep/row_max_mean 1509.8790 (1500.3136) nleep/row_max_std 57.9518 (60.6505) nleep/row_min_mean 1481.1687 (1473.5004) lr 2.7103e-04 eta 0:04:46
epoch [40/50] batch [60/162] time 0.169 (0.171) data 0.000 (0.004) loss 1.1505 (1.3623) teacher_loss 0.0948 (0.2147) loss_zs_kd 0.0416 (0.0418) loss_oracle 0.5110 (0.5914) kd_loss 0.7794 (0.8310) acc 100.0000 (91.7188) gate/entropy 0.9967 (0.9968) gate/usage_max 0.5528 (0.5526) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1555) teacher/entropy 0.0665 (0.0356) teacher/usage_max 0.7242 (0.7004) teacher/usage_min 0.1083 (0.1109) teacher/usage_std 0.2775 (0.2633) nleep/row_max_mean 1508.0957 (1502.6869) nleep/row_max_std 60.7933 (60.4218) nleep/row_min_mean 1483.0217 (1475.7683) lr 2.7103e-04 eta 0:04:54
epoch [40/50] batch [80/162] time 0.177 (0.173) data 0.000 (0.003) loss 1.4794 (1.3709) teacher_loss 0.1427 (0.2176) loss_zs_kd 0.0374 (0.0425) loss_oracle 0.6524 (0.5884) kd_loss 0.9919 (0.8378) acc 93.7500 (91.3281) gate/entropy 0.9972 (0.9968) gate/usage_max 0.5522 (0.5526) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1552 (0.1555) teacher/entropy 0.0012 (0.0352) teacher/usage_max 0.5625 (0.6943) teacher/usage_min 0.1875 (0.1091) teacher/usage_std 0.1640 (0.2599) nleep/row_max_mean 1479.8274 (1501.2355) nleep/row_max_std 65.0363 (61.6976) nleep/row_min_mean 1451.6191 (1474.3036) lr 2.7103e-04 eta 0:04:53
epoch [40/50] batch [100/162] time 0.191 (0.174) data 0.000 (0.003) loss 1.3379 (1.3653) teacher_loss 0.0854 (0.2151) loss_zs_kd 0.0347 (0.0424) loss_oracle 0.5864 (0.5836) kd_loss 0.9419 (0.8373) acc 100.0000 (91.6250) gate/entropy 0.9969 (0.9968) gate/usage_max 0.5526 (0.5526) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1554 (0.1555) teacher/entropy 0.0340 (0.0347) teacher/usage_max 0.5863 (0.6960) teacher/usage_min 0.1383 (0.1072) teacher/usage_std 0.1874 (0.2611) nleep/row_max_mean 1486.4073 (1501.1575) nleep/row_max_std 68.1710 (61.5906) nleep/row_min_mean 1458.5681 (1474.0671) lr 2.7103e-04 eta 0:04:52
epoch [40/50] batch [120/162] time 0.196 (0.175) data 0.000 (0.002) loss 1.1768 (1.3612) teacher_loss 0.1570 (0.2105) loss_zs_kd 0.0449 (0.0425) loss_oracle 0.5188 (0.5855) kd_loss 0.7380 (0.8367) acc 96.8750 (91.9010) gate/entropy 0.9972 (0.9968) gate/usage_max 0.5523 (0.5526) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1552 (0.1555) teacher/entropy 0.0401 (0.0333) teacher/usage_max 0.7931 (0.6981) teacher/usage_min 0.0822 (0.1063) teacher/usage_std 0.3256 (0.2624) nleep/row_max_mean 1513.4336 (1502.2072) nleep/row_max_std 47.8575 (61.0997) nleep/row_min_mean 1483.4829 (1475.0143) lr 2.7103e-04 eta 0:04:51
epoch [40/50] batch [140/162] time 0.191 (0.177) data 0.000 (0.002) loss 1.3222 (1.3641) teacher_loss 0.1761 (0.2107) loss_zs_kd 0.0610 (0.0433) loss_oracle 0.5995 (0.5877) kd_loss 0.8159 (0.8379) acc 87.5000 (91.8304) gate/entropy 0.9970 (0.9968) gate/usage_max 0.5524 (0.5526) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1553 (0.1555) teacher/entropy 0.0293 (0.0327) teacher/usage_max 0.7194 (0.6976) teacher/usage_min 0.1219 (0.1044) teacher/usage_std 0.2734 (0.2623) nleep/row_max_mean 1506.5198 (1502.5673) nleep/row_max_std 60.0517 (60.4865) nleep/row_min_mean 1477.3628 (1475.2468) lr 2.7103e-04 eta 0:04:51
epoch [40/50] batch [160/162] time 0.194 (0.177) data 0.000 (0.002) loss 1.2793 (1.3667) teacher_loss 0.2015 (0.2146) loss_zs_kd 0.0365 (0.0437) loss_oracle 0.6390 (0.5875) kd_loss 0.7401 (0.8365) acc 93.7500 (91.5234) gate/entropy 0.9968 (0.9968) gate/usage_max 0.5526 (0.5526) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1555) teacher/entropy 0.0493 (0.0325) teacher/usage_max 0.7810 (0.6992) teacher/usage_min 0.0935 (0.1048) teacher/usage_std 0.3168 (0.2633) nleep/row_max_mean 1506.4690 (1502.7255) nleep/row_max_std 53.7772 (60.2367) nleep/row_min_mean 1476.1910 (1475.3248) lr 2.7103e-04 eta 0:04:47
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,924
* accuracy: 86.1%
* error: 13.9%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,369
* accuracy: 72.2%
* error: 27.8%
* macro_f1: 70.7%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [41/50] batch [20/162] time 0.091 (0.137) data 0.001 (0.013) loss 1.3452 (1.4464) teacher_loss 0.1648 (0.2043) loss_zs_kd 0.0347 (0.0419) loss_oracle 0.6263 (0.6265) kd_loss 0.8499 (0.9078) acc 93.7500 (91.7188) gate/entropy 0.9971 (0.9968) gate/usage_max 0.5523 (0.5526) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1555) teacher/entropy 0.0303 (0.0257) teacher/usage_max 0.6779 (0.6288) teacher/usage_min 0.1309 (0.1406) teacher/usage_std 0.2449 (0.2162) nleep/row_max_mean 1506.8354 (1496.3865) nleep/row_max_std 57.4043 (58.1941) nleep/row_min_mean 1475.5942 (1469.0082) lr 2.2949e-04 eta 0:03:38
epoch [41/50] batch [40/162] time 0.201 (0.153) data 0.000 (0.007) loss 1.3118 (1.3885) teacher_loss 0.3921 (0.2028) loss_zs_kd 0.0382 (0.0402) loss_oracle 0.3767 (0.6117) kd_loss 0.7123 (0.8598) acc 84.3750 (92.3438) gate/entropy 0.9965 (0.9968) gate/usage_max 0.5530 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1555) teacher/entropy 0.0015 (0.0257) teacher/usage_max 0.8749 (0.6802) teacher/usage_min 0.0001 (0.1211) teacher/usage_std 0.3863 (0.2502) nleep/row_max_mean 1516.1001 (1503.5980) nleep/row_max_std 46.8026 (57.0642) nleep/row_min_mean 1488.2792 (1475.8688) lr 2.2949e-04 eta 0:04:02
epoch [41/50] batch [60/162] time 0.201 (0.163) data 0.000 (0.005) loss 1.3067 (1.3862) teacher_loss 0.1296 (0.2071) loss_zs_kd 0.0496 (0.0418) loss_oracle 0.5602 (0.5991) kd_loss 0.8723 (0.8586) acc 96.8750 (92.0312) gate/entropy 0.9970 (0.9968) gate/usage_max 0.5524 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1555) teacher/entropy 0.0046 (0.0267) teacher/usage_max 0.6867 (0.6806) teacher/usage_min 0.1563 (0.1184) teacher/usage_std 0.2499 (0.2504) nleep/row_max_mean 1509.7910 (1503.5944) nleep/row_max_std 55.3070 (57.3021) nleep/row_min_mean 1480.8661 (1475.8255) lr 2.2949e-04 eta 0:04:14
epoch [41/50] batch [80/162] time 0.192 (0.157) data 0.000 (0.004) loss 1.6024 (1.3828) teacher_loss 0.2509 (0.2028) loss_zs_kd 0.0327 (0.0429) loss_oracle 0.6927 (0.6049) kd_loss 0.9888 (0.8561) acc 87.5000 (92.5781) gate/entropy 0.9969 (0.9968) gate/usage_max 0.5526 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1554 (0.1555) teacher/entropy 0.0302 (0.0272) teacher/usage_max 0.5326 (0.6826) teacher/usage_min 0.2044 (0.1172) teacher/usage_std 0.1429 (0.2516) nleep/row_max_mean 1502.2451 (1504.5932) nleep/row_max_std 65.8328 (56.5132) nleep/row_min_mean 1474.8813 (1476.5874) lr 2.2949e-04 eta 0:04:02
epoch [41/50] batch [100/162] time 0.195 (0.156) data 0.000 (0.003) loss 1.1654 (1.3739) teacher_loss 0.1675 (0.2099) loss_zs_kd 0.0262 (0.0429) loss_oracle 0.5183 (0.5964) kd_loss 0.7257 (0.8443) acc 93.7500 (92.0625) gate/entropy 0.9967 (0.9968) gate/usage_max 0.5528 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1555) teacher/entropy 0.0452 (0.0290) teacher/usage_max 0.8065 (0.6938) teacher/usage_min 0.0744 (0.1099) teacher/usage_std 0.3351 (0.2596) nleep/row_max_mean 1523.7729 (1506.0318) nleep/row_max_std 50.8182 (55.7883) nleep/row_min_mean 1495.7727 (1477.9623) lr 2.2949e-04 eta 0:03:56
epoch [41/50] batch [120/162] time 0.172 (0.159) data 0.000 (0.002) loss 1.5113 (1.3658) teacher_loss 0.1145 (0.2077) loss_zs_kd 0.0310 (0.0422) loss_oracle 0.7217 (0.5932) kd_loss 1.0205 (0.8404) acc 90.6250 (91.9010) gate/entropy 0.9970 (0.9968) gate/usage_max 0.5524 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1555) teacher/entropy 0.0072 (0.0285) teacher/usage_max 0.5313 (0.6989) teacher/usage_min 0.1578 (0.1050) teacher/usage_std 0.1533 (0.2634) nleep/row_max_mean 1475.4524 (1505.7966) nleep/row_max_std 60.1117 (56.2757) nleep/row_min_mean 1448.0803 (1477.8300) lr 2.2949e-04 eta 0:03:58
epoch [41/50] batch [140/162] time 0.183 (0.161) data 0.000 (0.002) loss 1.2568 (1.3725) teacher_loss 0.1252 (0.2092) loss_zs_kd 0.0217 (0.0415) loss_oracle 0.4779 (0.5968) kd_loss 0.8817 (0.8442) acc 100.0000 (91.9643) gate/entropy 0.9965 (0.9968) gate/usage_max 0.5530 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1555) teacher/entropy 0.0022 (0.0279) teacher/usage_max 0.6872 (0.6957) teacher/usage_min 0.0940 (0.1059) teacher/usage_std 0.2553 (0.2613) nleep/row_max_mean 1504.6604 (1505.3359) nleep/row_max_std 62.3369 (56.8624) nleep/row_min_mean 1481.0015 (1477.4676) lr 2.2949e-04 eta 0:03:58
epoch [41/50] batch [160/162] time 0.173 (0.163) data 0.000 (0.002) loss 1.2296 (1.3706) teacher_loss 0.2157 (0.2111) loss_zs_kd 0.0507 (0.0415) loss_oracle 0.5742 (0.5945) kd_loss 0.7015 (0.8415) acc 90.6250 (91.8750) gate/entropy 0.9966 (0.9968) gate/usage_max 0.5529 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1555) teacher/entropy 0.0559 (0.0281) teacher/usage_max 0.8196 (0.6983) teacher/usage_min 0.0791 (0.1058) teacher/usage_std 0.3439 (0.2628) nleep/row_max_mean 1525.1597 (1505.5037) nleep/row_max_std 52.2857 (56.9728) nleep/row_min_mean 1497.7726 (1477.6026) lr 2.2949e-04 eta 0:03:58
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,932
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,322
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 69.1%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [42/50] batch [20/162] time 0.166 (0.192) data 0.000 (0.013) loss 1.5501 (1.3601) teacher_loss 0.3787 (0.2177) loss_zs_kd 0.0396 (0.0440) loss_oracle 0.6398 (0.5922) kd_loss 0.8317 (0.8243) acc 90.6250 (92.0312) gate/entropy 0.9967 (0.9967) gate/usage_max 0.5528 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1556) teacher/entropy 0.0439 (0.0292) teacher/usage_max 0.6965 (0.7150) teacher/usage_min 0.0897 (0.0993) teacher/usage_std 0.2617 (0.2732) nleep/row_max_mean 1500.7568 (1505.8700) nleep/row_max_std 61.8550 (59.0171) nleep/row_min_mean 1474.1693 (1478.1746) lr 1.9098e-04 eta 0:04:36
epoch [42/50] batch [40/162] time 0.198 (0.190) data 0.000 (0.006) loss 1.2155 (1.3718) teacher_loss 0.1599 (0.2222) loss_zs_kd 0.0447 (0.0441) loss_oracle 0.5255 (0.5898) kd_loss 0.7705 (0.8327) acc 93.7500 (91.4062) gate/entropy 0.9968 (0.9968) gate/usage_max 0.5526 (0.5527) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1555 (0.1555) teacher/entropy 0.0254 (0.0276) teacher/usage_max 0.7805 (0.7080) teacher/usage_min 0.0750 (0.1060) teacher/usage_std 0.3175 (0.2686) nleep/row_max_mean 1505.0978 (1503.8002) nleep/row_max_std 59.7006 (59.7483) nleep/row_min_mean 1478.3483 (1476.0796) lr 1.9098e-04 eta 0:04:29
epoch [42/50] batch [60/162] time 0.171 (0.188) data 0.000 (0.004) loss 1.4025 (1.3580) teacher_loss 0.2333 (0.2128) loss_zs_kd 0.0423 (0.0436) loss_oracle 0.6273 (0.5893) kd_loss 0.8344 (0.8288) acc 90.6250 (91.7708) gate/entropy 0.9968 (0.9968) gate/usage_max 0.5527 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1555) teacher/entropy 0.0378 (0.0284) teacher/usage_max 0.6858 (0.7113) teacher/usage_min 0.1169 (0.1065) teacher/usage_std 0.2514 (0.2708) nleep/row_max_mean 1506.1990 (1504.4298) nleep/row_max_std 63.1543 (59.8541) nleep/row_min_mean 1476.1023 (1476.4823) lr 1.9098e-04 eta 0:04:22
epoch [42/50] batch [80/162] time 0.196 (0.184) data 0.000 (0.003) loss 1.2815 (1.3544) teacher_loss 0.0991 (0.2125) loss_zs_kd 0.0643 (0.0437) loss_oracle 0.5879 (0.5853) kd_loss 0.8563 (0.8274) acc 100.0000 (91.7969) gate/entropy 0.9966 (0.9968) gate/usage_max 0.5528 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1555) teacher/entropy 0.0320 (0.0301) teacher/usage_max 0.6866 (0.7109) teacher/usage_min 0.0625 (0.1046) teacher/usage_std 0.2614 (0.2705) nleep/row_max_mean 1495.5095 (1504.1833) nleep/row_max_std 64.7329 (59.8325) nleep/row_min_mean 1468.2040 (1476.2739) lr 1.9098e-04 eta 0:04:13
epoch [42/50] batch [100/162] time 0.075 (0.176) data 0.000 (0.003) loss 1.6762 (1.3545) teacher_loss 0.2564 (0.2163) loss_zs_kd 0.0512 (0.0428) loss_oracle 0.6513 (0.5815) kd_loss 1.0685 (0.8261) acc 84.3750 (91.4375) gate/entropy 0.9972 (0.9968) gate/usage_max 0.5522 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1552 (0.1555) teacher/entropy 0.0309 (0.0298) teacher/usage_max 0.4682 (0.7131) teacher/usage_min 0.0672 (0.1032) teacher/usage_std 0.1882 (0.2727) nleep/row_max_mean 1460.9626 (1503.7666) nleep/row_max_std 66.8314 (59.6052) nleep/row_min_mean 1439.3885 (1475.8922) lr 1.9098e-04 eta 0:03:59
epoch [42/50] batch [120/162] time 0.189 (0.171) data 0.000 (0.002) loss 1.3517 (1.3627) teacher_loss 0.2968 (0.2175) loss_zs_kd 0.0271 (0.0424) loss_oracle 0.5570 (0.5869) kd_loss 0.7628 (0.8306) acc 93.7500 (91.2760) gate/entropy 0.9969 (0.9968) gate/usage_max 0.5525 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1554 (0.1555) teacher/entropy 0.0343 (0.0306) teacher/usage_max 0.7766 (0.7070) teacher/usage_min 0.0984 (0.1084) teacher/usage_std 0.3136 (0.2680) nleep/row_max_mean 1507.5333 (1503.1981) nleep/row_max_std 52.7889 (59.7917) nleep/row_min_mean 1478.7424 (1475.3790) lr 1.9098e-04 eta 0:03:48
epoch [42/50] batch [140/162] time 0.161 (0.172) data 0.000 (0.002) loss 1.3650 (1.3660) teacher_loss 0.1594 (0.2165) loss_zs_kd 0.0405 (0.0417) loss_oracle 0.6285 (0.5847) kd_loss 0.8711 (0.8362) acc 93.7500 (91.2723) gate/entropy 0.9967 (0.9968) gate/usage_max 0.5527 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1555) teacher/entropy 0.0394 (0.0303) teacher/usage_max 0.6593 (0.7015) teacher/usage_min 0.0955 (0.1088) teacher/usage_std 0.2385 (0.2646) nleep/row_max_mean 1498.7751 (1502.8385) nleep/row_max_std 66.7452 (59.7801) nleep/row_min_mean 1471.8094 (1475.0227) lr 1.9098e-04 eta 0:03:47
epoch [42/50] batch [160/162] time 0.081 (0.168) data 0.000 (0.002) loss 1.3797 (1.3691) teacher_loss 0.2000 (0.2186) loss_zs_kd 0.0637 (0.0420) loss_oracle 0.5922 (0.5878) kd_loss 0.8517 (0.8356) acc 87.5000 (91.3086) gate/entropy 0.9968 (0.9968) gate/usage_max 0.5527 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1555) teacher/entropy 0.0221 (0.0299) teacher/usage_max 0.6874 (0.7027) teacher/usage_min 0.1438 (0.1080) teacher/usage_std 0.2506 (0.2655) nleep/row_max_mean 1496.9827 (1502.7116) nleep/row_max_std 65.3856 (59.9243) nleep/row_min_mean 1469.3071 (1474.8526) lr 1.9098e-04 eta 0:03:37
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,922
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 86.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,339
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 69.4%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [43/50] batch [20/162] time 0.183 (0.198) data 0.000 (0.013) loss 1.4357 (1.3598) teacher_loss 0.1913 (0.2213) loss_zs_kd 0.0320 (0.0389) loss_oracle 0.6759 (0.5844) kd_loss 0.8905 (0.8269) acc 96.8750 (90.6250) gate/entropy 0.9970 (0.9968) gate/usage_max 0.5524 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1555) teacher/entropy 0.0156 (0.0308) teacher/usage_max 0.6613 (0.7115) teacher/usage_min 0.1199 (0.0992) teacher/usage_std 0.2354 (0.2724) nleep/row_max_mean 1489.4259 (1502.2103) nleep/row_max_std 60.2837 (58.7832) nleep/row_min_mean 1462.4154 (1474.2224) lr 1.5567e-04 eta 0:04:12
epoch [43/50] batch [40/162] time 0.166 (0.186) data 0.000 (0.006) loss 1.2629 (1.3850) teacher_loss 0.1521 (0.2308) loss_zs_kd 0.0310 (0.0385) loss_oracle 0.5127 (0.5871) kd_loss 0.8389 (0.8414) acc 96.8750 (90.8594) gate/entropy 0.9964 (0.9967) gate/usage_max 0.5531 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1558 (0.1556) teacher/entropy 0.0023 (0.0280) teacher/usage_max 0.7187 (0.6971) teacher/usage_min 0.0935 (0.1144) teacher/usage_std 0.2752 (0.2607) nleep/row_max_mean 1517.3298 (1502.4390) nleep/row_max_std 52.1965 (59.7211) nleep/row_min_mean 1487.3215 (1474.4956) lr 1.5567e-04 eta 0:03:53
epoch [43/50] batch [60/162] time 0.182 (0.180) data 0.000 (0.004) loss 1.3916 (1.3619) teacher_loss 0.1847 (0.2198) loss_zs_kd 0.0429 (0.0394) loss_oracle 0.6984 (0.5770) kd_loss 0.8361 (0.8339) acc 90.6250 (90.9896) gate/entropy 0.9970 (0.9967) gate/usage_max 0.5524 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1553 (0.1556) teacher/entropy 0.0072 (0.0256) teacher/usage_max 0.7176 (0.7088) teacher/usage_min 0.0950 (0.1050) teacher/usage_std 0.2743 (0.2690) nleep/row_max_mean 1499.9026 (1503.6154) nleep/row_max_std 59.1213 (58.6655) nleep/row_min_mean 1471.9066 (1475.7012) lr 1.5567e-04 eta 0:03:42
epoch [43/50] batch [80/162] time 0.168 (0.178) data 0.000 (0.003) loss 1.1731 (1.3480) teacher_loss 0.1217 (0.2114) loss_zs_kd 0.0503 (0.0401) loss_oracle 0.5050 (0.5742) kd_loss 0.7737 (0.8294) acc 96.8750 (91.7188) gate/entropy 0.9966 (0.9967) gate/usage_max 0.5529 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1555) teacher/entropy 0.0292 (0.0265) teacher/usage_max 0.7704 (0.7128) teacher/usage_min 0.0960 (0.1051) teacher/usage_std 0.3094 (0.2716) nleep/row_max_mean 1506.8392 (1503.1338) nleep/row_max_std 59.0863 (58.6996) nleep/row_min_mean 1477.4583 (1475.3820) lr 1.5567e-04 eta 0:03:35
epoch [43/50] batch [100/162] time 0.163 (0.176) data 0.000 (0.003) loss 1.4301 (1.3506) teacher_loss 0.1199 (0.2164) loss_zs_kd 0.0474 (0.0411) loss_oracle 0.6407 (0.5733) kd_loss 0.9661 (0.8270) acc 96.8750 (91.2500) gate/entropy 0.9966 (0.9967) gate/usage_max 0.5529 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1556) teacher/entropy 0.0426 (0.0268) teacher/usage_max 0.5366 (0.7151) teacher/usage_min 0.2003 (0.1035) teacher/usage_std 0.1460 (0.2732) nleep/row_max_mean 1488.1724 (1503.0268) nleep/row_max_std 69.6451 (59.1153) nleep/row_min_mean 1462.2004 (1475.3798) lr 1.5567e-04 eta 0:03:30
epoch [43/50] batch [120/162] time 0.193 (0.175) data 0.000 (0.002) loss 1.4479 (1.3562) teacher_loss 0.2041 (0.2134) loss_zs_kd 0.0229 (0.0411) loss_oracle 0.6022 (0.5805) kd_loss 0.9312 (0.8320) acc 90.6250 (91.4583) gate/entropy 0.9971 (0.9967) gate/usage_max 0.5523 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1552 (0.1555) teacher/entropy 0.0223 (0.0284) teacher/usage_max 0.6144 (0.7081) teacher/usage_min 0.1047 (0.1054) teacher/usage_std 0.2114 (0.2686) nleep/row_max_mean 1489.5007 (1502.3000) nleep/row_max_std 56.9410 (59.3857) nleep/row_min_mean 1459.8669 (1474.6545) lr 1.5567e-04 eta 0:03:26
epoch [43/50] batch [140/162] time 0.185 (0.175) data 0.000 (0.002) loss 1.6453 (1.3621) teacher_loss 0.3403 (0.2144) loss_zs_kd 0.0282 (0.0407) loss_oracle 0.6944 (0.5842) kd_loss 0.9438 (0.8352) acc 78.1250 (91.2723) gate/entropy 0.9968 (0.9967) gate/usage_max 0.5527 (0.5527) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1556) teacher/entropy 0.0163 (0.0287) teacher/usage_max 0.5927 (0.7044) teacher/usage_min 0.1872 (0.1064) teacher/usage_std 0.1839 (0.2663) nleep/row_max_mean 1484.5973 (1501.8923) nleep/row_max_std 65.7202 (59.2438) nleep/row_min_mean 1457.4827 (1474.3309) lr 1.5567e-04 eta 0:03:22
epoch [43/50] batch [160/162] time 0.166 (0.175) data 0.000 (0.002) loss 1.4030 (1.3585) teacher_loss 0.2292 (0.2130) loss_zs_kd 0.0515 (0.0412) loss_oracle 0.6756 (0.5826) kd_loss 0.8102 (0.8336) acc 87.5000 (91.4844) gate/entropy 0.9969 (0.9967) gate/usage_max 0.5526 (0.5528) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1554 (0.1556) teacher/entropy 0.0257 (0.0288) teacher/usage_max 0.7354 (0.7061) teacher/usage_min 0.1084 (0.1050) teacher/usage_std 0.2849 (0.2675) nleep/row_max_mean 1496.2051 (1502.0350) nleep/row_max_std 61.9446 (59.1772) nleep/row_min_mean 1468.9316 (1474.5310) lr 1.5567e-04 eta 0:03:18
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,921
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 86.3%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,325
* accuracy: 70.8%
* error: 29.2%
* macro_f1: 69.1%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [44/50] batch [20/162] time 0.162 (0.204) data 0.000 (0.012) loss 1.1290 (1.3842) teacher_loss 0.1297 (0.2192) loss_zs_kd 0.0277 (0.0439) loss_oracle 0.5071 (0.6098) kd_loss 0.7319 (0.8382) acc 96.8750 (91.5625) gate/entropy 0.9966 (0.9967) gate/usage_max 0.5530 (0.5528) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1557 (0.1556) teacher/entropy 0.0233 (0.0338) teacher/usage_max 0.8172 (0.6942) teacher/usage_min 0.0626 (0.1111) teacher/usage_std 0.3430 (0.2590) nleep/row_max_mean 1514.7468 (1501.7861) nleep/row_max_std 53.9829 (58.6160) nleep/row_min_mean 1486.0981 (1474.4158) lr 1.2369e-04 eta 0:03:47
epoch [44/50] batch [40/162] time 0.058 (0.172) data 0.000 (0.006) loss 1.2817 (1.3452) teacher_loss 0.1351 (0.1989) loss_zs_kd 0.0266 (0.0415) loss_oracle 0.5732 (0.5898) kd_loss 0.8467 (0.8306) acc 96.8750 (92.5000) gate/entropy 0.9968 (0.9967) gate/usage_max 0.5527 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1556) teacher/entropy 0.0419 (0.0360) teacher/usage_max 0.6874 (0.7013) teacher/usage_min 0.0527 (0.1070) teacher/usage_std 0.2643 (0.2638) nleep/row_max_mean 1489.6562 (1503.5877) nleep/row_max_std 64.1034 (57.7012) nleep/row_min_mean 1463.4761 (1476.0778) lr 1.2369e-04 eta 0:03:07
epoch [44/50] batch [60/162] time 0.181 (0.165) data 0.000 (0.004) loss 1.6804 (1.3480) teacher_loss 0.5060 (0.2077) loss_zs_kd 0.0288 (0.0414) loss_oracle 0.5939 (0.5865) kd_loss 0.8631 (0.8262) acc 84.3750 (91.9792) gate/entropy 0.9968 (0.9967) gate/usage_max 0.5527 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1556) teacher/entropy 0.0208 (0.0350) teacher/usage_max 0.6830 (0.7072) teacher/usage_min 0.1239 (0.1034) teacher/usage_std 0.2489 (0.2680) nleep/row_max_mean 1502.4541 (1503.4634) nleep/row_max_std 51.5603 (57.6367) nleep/row_min_mean 1475.2344 (1475.7567) lr 1.2369e-04 eta 0:02:57
epoch [44/50] batch [80/162] time 0.166 (0.170) data 0.000 (0.003) loss 1.3279 (1.3394) teacher_loss 0.0938 (0.2068) loss_zs_kd 0.0466 (0.0420) loss_oracle 0.6511 (0.5795) kd_loss 0.8852 (0.8218) acc 100.0000 (92.2266) gate/entropy 0.9968 (0.9967) gate/usage_max 0.5527 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1556) teacher/entropy 0.0398 (0.0338) teacher/usage_max 0.6407 (0.7137) teacher/usage_min 0.1262 (0.0999) teacher/usage_std 0.2217 (0.2726) nleep/row_max_mean 1495.9045 (1503.8132) nleep/row_max_std 52.3951 (57.4651) nleep/row_min_mean 1469.2797 (1476.1122) lr 1.2369e-04 eta 0:02:59
epoch [44/50] batch [100/162] time 0.185 (0.174) data 0.000 (0.003) loss 1.4898 (1.3489) teacher_loss 0.2900 (0.2098) loss_zs_kd 0.0524 (0.0419) loss_oracle 0.6617 (0.5850) kd_loss 0.8428 (0.8256) acc 87.5000 (92.0312) gate/entropy 0.9966 (0.9967) gate/usage_max 0.5530 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1556) teacher/entropy 0.0037 (0.0330) teacher/usage_max 0.7180 (0.7106) teacher/usage_min 0.1258 (0.0992) teacher/usage_std 0.2723 (0.2709) nleep/row_max_mean 1502.5389 (1503.3072) nleep/row_max_std 60.8968 (57.5615) nleep/row_min_mean 1474.3431 (1475.7442) lr 1.2369e-04 eta 0:02:59
epoch [44/50] batch [120/162] time 0.196 (0.176) data 0.000 (0.002) loss 1.4076 (1.3556) teacher_loss 0.1664 (0.2111) loss_zs_kd 0.0437 (0.0418) loss_oracle 0.6673 (0.5881) kd_loss 0.8857 (0.8295) acc 93.7500 (91.8490) gate/entropy 0.9964 (0.9967) gate/usage_max 0.5531 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1558 (0.1556) teacher/entropy 0.0188 (0.0317) teacher/usage_max 0.6497 (0.7077) teacher/usage_min 0.1315 (0.1008) teacher/usage_std 0.2265 (0.2690) nleep/row_max_mean 1499.4567 (1502.8467) nleep/row_max_std 59.1495 (57.8210) nleep/row_min_mean 1472.1711 (1475.3277) lr 1.2369e-04 eta 0:02:58
epoch [44/50] batch [140/162] time 0.166 (0.176) data 0.000 (0.002) loss 1.5678 (1.3647) teacher_loss 0.3780 (0.2149) loss_zs_kd 0.0359 (0.0420) loss_oracle 0.6617 (0.5910) kd_loss 0.8410 (0.8333) acc 84.3750 (91.6295) gate/entropy 0.9964 (0.9967) gate/usage_max 0.5531 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1558 (0.1556) teacher/entropy 0.0045 (0.0318) teacher/usage_max 0.7186 (0.7032) teacher/usage_min 0.1248 (0.1029) teacher/usage_std 0.2727 (0.2658) nleep/row_max_mean 1509.4008 (1502.5551) nleep/row_max_std 54.4182 (57.7971) nleep/row_min_mean 1483.5084 (1475.1099) lr 1.2369e-04 eta 0:02:55
epoch [44/50] batch [160/162] time 0.164 (0.178) data 0.000 (0.002) loss 1.5720 (1.3640) teacher_loss 0.3941 (0.2145) loss_zs_kd 0.0387 (0.0417) loss_oracle 0.6818 (0.5906) kd_loss 0.8176 (0.8333) acc 90.6250 (91.5820) gate/entropy 0.9969 (0.9967) gate/usage_max 0.5526 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1556) teacher/entropy 0.0421 (0.0320) teacher/usage_max 0.7026 (0.7031) teacher/usage_min 0.1252 (0.1036) teacher/usage_std 0.2618 (0.2656) nleep/row_max_mean 1491.2551 (1502.6826) nleep/row_max_std 52.4829 (57.7573) nleep/row_min_mean 1461.9034 (1475.2482) lr 1.2369e-04 eta 0:02:52
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,925
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,330
* accuracy: 71.0%
* error: 29.0%
* macro_f1: 69.3%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [45/50] batch [20/162] time 0.173 (0.180) data 0.000 (0.014) loss 1.5517 (1.3813) teacher_loss 0.2136 (0.2126) loss_zs_kd 0.0350 (0.0455) loss_oracle 0.6897 (0.5854) kd_loss 0.9757 (0.8533) acc 93.7500 (91.5625) gate/entropy 0.9968 (0.9966) gate/usage_max 0.5527 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1557) teacher/entropy 0.0168 (0.0308) teacher/usage_max 0.5634 (0.6839) teacher/usage_min 0.1875 (0.1101) teacher/usage_std 0.1646 (0.2529) nleep/row_max_mean 1489.3013 (1501.0544) nleep/row_max_std 63.5467 (56.8955) nleep/row_min_mean 1462.0459 (1474.3361) lr 9.5173e-05 eta 0:02:51
epoch [45/50] batch [40/162] time 0.171 (0.181) data 0.000 (0.007) loss 0.9923 (1.3419) teacher_loss 0.0386 (0.2079) loss_zs_kd 0.0260 (0.0402) loss_oracle 0.3573 (0.5719) kd_loss 0.7621 (0.8280) acc 100.0000 (92.1094) gate/entropy 0.9971 (0.9966) gate/usage_max 0.5523 (0.5529) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1552 (0.1556) teacher/entropy 0.0050 (0.0299) teacher/usage_max 0.8125 (0.7118) teacher/usage_min 0.0636 (0.0995) teacher/usage_std 0.3397 (0.2718) nleep/row_max_mean 1503.9015 (1504.5180) nleep/row_max_std 52.7002 (57.1163) nleep/row_min_mean 1473.8096 (1477.2678) lr 9.5173e-05 eta 0:02:48
epoch [45/50] batch [60/162] time 0.087 (0.172) data 0.000 (0.005) loss 1.4713 (1.3516) teacher_loss 0.2169 (0.2052) loss_zs_kd 0.0358 (0.0399) loss_oracle 0.6776 (0.5776) kd_loss 0.8977 (0.8377) acc 90.6250 (91.9792) gate/entropy 0.9968 (0.9967) gate/usage_max 0.5527 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1556) teacher/entropy 0.0428 (0.0287) teacher/usage_max 0.6254 (0.7022) teacher/usage_min 0.1251 (0.1031) teacher/usage_std 0.2126 (0.2653) nleep/row_max_mean 1503.1927 (1502.3027) nleep/row_max_std 59.9217 (58.2621) nleep/row_min_mean 1474.7593 (1474.8578) lr 9.5173e-05 eta 0:02:36
epoch [45/50] batch [80/162] time 0.179 (0.159) data 0.000 (0.004) loss 1.3951 (1.3510) teacher_loss 0.2328 (0.1976) loss_zs_kd 0.0327 (0.0404) loss_oracle 0.6454 (0.5805) kd_loss 0.8232 (0.8429) acc 90.6250 (92.1875) gate/entropy 0.9965 (0.9967) gate/usage_max 0.5530 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1556) teacher/entropy 0.0734 (0.0294) teacher/usage_max 0.6776 (0.6961) teacher/usage_min 0.0653 (0.1054) teacher/usage_std 0.2557 (0.2612) nleep/row_max_mean 1497.7910 (1501.9361) nleep/row_max_std 57.7102 (58.3680) nleep/row_min_mean 1473.5637 (1474.4222) lr 9.5173e-05 eta 0:02:22
epoch [45/50] batch [100/162] time 0.140 (0.162) data 0.000 (0.003) loss 1.4059 (1.3479) teacher_loss 0.2280 (0.2029) loss_zs_kd 0.0615 (0.0401) loss_oracle 0.6942 (0.5759) kd_loss 0.8000 (0.8370) acc 90.6250 (91.9062) gate/entropy 0.9963 (0.9967) gate/usage_max 0.5532 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1559 (0.1556) teacher/entropy 0.0663 (0.0295) teacher/usage_max 0.6970 (0.7027) teacher/usage_min 0.1420 (0.1014) teacher/usage_std 0.2573 (0.2660) nleep/row_max_mean 1502.0066 (1503.0879) nleep/row_max_std 54.2549 (57.5558) nleep/row_min_mean 1474.9999 (1475.6101) lr 9.5173e-05 eta 0:02:21
epoch [45/50] batch [120/162] time 0.081 (0.161) data 0.000 (0.002) loss 1.4932 (1.3492) teacher_loss 0.3309 (0.2060) loss_zs_kd 0.0371 (0.0400) loss_oracle 0.5994 (0.5749) kd_loss 0.8440 (0.8357) acc 87.5000 (91.9010) gate/entropy 0.9964 (0.9966) gate/usage_max 0.5531 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1558 (0.1556) teacher/entropy 0.0213 (0.0294) teacher/usage_max 0.6948 (0.7037) teacher/usage_min 0.1245 (0.1024) teacher/usage_std 0.2566 (0.2665) nleep/row_max_mean 1515.7361 (1503.5710) nleep/row_max_std 53.3584 (57.5727) nleep/row_min_mean 1485.7395 (1476.0972) lr 9.5173e-05 eta 0:02:17
epoch [45/50] batch [140/162] time 0.201 (0.157) data 0.000 (0.002) loss 1.3541 (1.3538) teacher_loss 0.1680 (0.2101) loss_zs_kd 0.0194 (0.0401) loss_oracle 0.6243 (0.5762) kd_loss 0.8643 (0.8356) acc 93.7500 (91.6741) gate/entropy 0.9966 (0.9967) gate/usage_max 0.5529 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1556) teacher/entropy 0.0105 (0.0290) teacher/usage_max 0.6843 (0.7041) teacher/usage_min 0.1250 (0.1039) teacher/usage_std 0.2496 (0.2664) nleep/row_max_mean 1513.2485 (1503.5292) nleep/row_max_std 50.0195 (57.1553) nleep/row_min_mean 1483.3064 (1475.9981) lr 9.5173e-05 eta 0:02:10
epoch [45/50] batch [160/162] time 0.154 (0.156) data 0.000 (0.002) loss 1.2693 (1.3571) teacher_loss 0.0794 (0.2120) loss_zs_kd 0.0325 (0.0404) loss_oracle 0.6099 (0.5778) kd_loss 0.8686 (0.8360) acc 100.0000 (91.5039) gate/entropy 0.9965 (0.9966) gate/usage_max 0.5530 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1556) teacher/entropy 0.0178 (0.0288) teacher/usage_max 0.6795 (0.7033) teacher/usage_min 0.1330 (0.1057) teacher/usage_std 0.2458 (0.2656) nleep/row_max_mean 1507.4785 (1504.1646) nleep/row_max_std 53.1489 (56.4774) nleep/row_min_mean 1477.2671 (1476.4587) lr 9.5173e-05 eta 0:02:06
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,929
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,326
* accuracy: 70.9%
* error: 29.1%
* macro_f1: 69.2%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [46/50] batch [20/162] time 0.169 (0.205) data 0.000 (0.015) loss 1.2889 (1.3364) teacher_loss 0.1311 (0.1832) loss_zs_kd 0.0387 (0.0400) loss_oracle 0.6391 (0.5893) kd_loss 0.8189 (0.8385) acc 96.8750 (92.9688) gate/entropy 0.9965 (0.9967) gate/usage_max 0.5530 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1556) teacher/entropy 0.0390 (0.0266) teacher/usage_max 0.7075 (0.7021) teacher/usage_min 0.1375 (0.1090) teacher/usage_std 0.2647 (0.2642) nleep/row_max_mean 1514.4260 (1510.1808) nleep/row_max_std 55.3567 (50.7419) nleep/row_min_mean 1484.2358 (1481.1806) lr 7.0224e-05 eta 0:02:41
epoch [46/50] batch [40/162] time 0.182 (0.194) data 0.000 (0.008) loss 1.3004 (1.3521) teacher_loss 0.3177 (0.1990) loss_zs_kd 0.0588 (0.0394) loss_oracle 0.4431 (0.5900) kd_loss 0.7317 (0.8384) acc 90.6250 (92.2656) gate/entropy 0.9963 (0.9966) gate/usage_max 0.5532 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1559 (0.1556) teacher/entropy 0.0516 (0.0288) teacher/usage_max 0.7961 (0.6996) teacher/usage_min 0.0543 (0.1085) teacher/usage_std 0.3295 (0.2629) nleep/row_max_mean 1522.8887 (1509.6372) nleep/row_max_std 48.1672 (51.9615) nleep/row_min_mean 1495.0793 (1480.9212) lr 7.0224e-05 eta 0:02:29
epoch [46/50] batch [60/162] time 0.200 (0.186) data 0.000 (0.005) loss 1.1613 (1.3545) teacher_loss 0.1686 (0.2158) loss_zs_kd 0.0503 (0.0388) loss_oracle 0.5632 (0.5827) kd_loss 0.6859 (0.8279) acc 90.6250 (91.4062) gate/entropy 0.9970 (0.9966) gate/usage_max 0.5524 (0.5528) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1553 (0.1556) teacher/entropy 0.0444 (0.0286) teacher/usage_max 0.8422 (0.7119) teacher/usage_min 0.0324 (0.1004) teacher/usage_std 0.3618 (0.2719) nleep/row_max_mean 1514.5142 (1509.0230) nleep/row_max_std 45.5740 (52.4755) nleep/row_min_mean 1484.5146 (1480.5133) lr 7.0224e-05 eta 0:02:19
epoch [46/50] batch [80/162] time 0.195 (0.185) data 0.000 (0.004) loss 1.3304 (1.3554) teacher_loss 0.1608 (0.2168) loss_zs_kd 0.0463 (0.0398) loss_oracle 0.5940 (0.5795) kd_loss 0.8495 (0.8290) acc 93.7500 (91.2891) gate/entropy 0.9966 (0.9967) gate/usage_max 0.5529 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1556) teacher/entropy 0.0380 (0.0298) teacher/usage_max 0.6764 (0.7093) teacher/usage_min 0.1492 (0.1013) teacher/usage_std 0.2428 (0.2701) nleep/row_max_mean 1503.3838 (1507.6551) nleep/row_max_std 50.2287 (53.1220) nleep/row_min_mean 1474.6161 (1479.1998) lr 7.0224e-05 eta 0:02:14
epoch [46/50] batch [100/162] time 0.169 (0.184) data 0.000 (0.003) loss 1.1992 (1.3632) teacher_loss 0.1694 (0.2190) loss_zs_kd 0.0404 (0.0402) loss_oracle 0.5888 (0.5807) kd_loss 0.7151 (0.8338) acc 90.6250 (91.0312) gate/entropy 0.9967 (0.9967) gate/usage_max 0.5527 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1556) teacher/entropy 0.0123 (0.0274) teacher/usage_max 0.8408 (0.7066) teacher/usage_min 0.0032 (0.1033) teacher/usage_std 0.3642 (0.2682) nleep/row_max_mean 1510.0696 (1506.3323) nleep/row_max_std 47.6329 (53.8716) nleep/row_min_mean 1480.1443 (1477.9042) lr 7.0224e-05 eta 0:02:10
epoch [46/50] batch [120/162] time 0.165 (0.183) data 0.000 (0.003) loss 1.3240 (1.3681) teacher_loss 0.1318 (0.2226) loss_zs_kd 0.0483 (0.0414) loss_oracle 0.6224 (0.5810) kd_loss 0.8568 (0.8343) acc 96.8750 (90.8073) gate/entropy 0.9967 (0.9967) gate/usage_max 0.5528 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1556) teacher/entropy 0.0447 (0.0278) teacher/usage_max 0.6762 (0.7056) teacher/usage_min 0.0405 (0.1043) teacher/usage_std 0.2619 (0.2675) nleep/row_max_mean 1490.9058 (1505.7269) nleep/row_max_std 68.0460 (54.2981) nleep/row_min_mean 1462.1436 (1477.4178) lr 7.0224e-05 eta 0:02:06
epoch [46/50] batch [140/162] time 0.168 (0.182) data 0.000 (0.002) loss 1.4783 (1.3699) teacher_loss 0.1528 (0.2211) loss_zs_kd 0.0448 (0.0414) loss_oracle 0.6305 (0.5808) kd_loss 0.9878 (0.8377) acc 93.7500 (90.9375) gate/entropy 0.9966 (0.9966) gate/usage_max 0.5529 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1556) teacher/entropy 0.0281 (0.0280) teacher/usage_max 0.5384 (0.7018) teacher/usage_min 0.1874 (0.1041) teacher/usage_std 0.1493 (0.2651) nleep/row_max_mean 1493.6765 (1505.2232) nleep/row_max_std 59.0519 (54.6595) nleep/row_min_mean 1466.8875 (1477.0172) lr 7.0224e-05 eta 0:02:01
epoch [46/50] batch [160/162] time 0.071 (0.172) data 0.000 (0.002) loss 1.2576 (1.3563) teacher_loss 0.1616 (0.2167) loss_zs_kd 0.0388 (0.0413) loss_oracle 0.5982 (0.5748) kd_loss 0.7775 (0.8316) acc 93.7500 (91.1914) gate/entropy 0.9966 (0.9966) gate/usage_max 0.5529 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1556) teacher/entropy 0.0457 (0.0283) teacher/usage_max 0.7473 (0.7082) teacher/usage_min 0.1122 (0.1024) teacher/usage_std 0.2929 (0.2693) nleep/row_max_mean 1511.1331 (1505.9120) nleep/row_max_std 61.3682 (54.8094) nleep/row_min_mean 1483.3115 (1477.7188) lr 7.0224e-05 eta 0:01:51
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,928
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,336
* accuracy: 71.2%
* error: 28.8%
* macro_f1: 69.4%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [47/50] batch [20/162] time 0.132 (0.153) data 0.000 (0.013) loss 1.0902 (1.3584) teacher_loss 0.0487 (0.2015) loss_zs_kd 0.0342 (0.0415) loss_oracle 0.4817 (0.5805) kd_loss 0.7836 (0.8459) acc 100.0000 (92.1875) gate/entropy 0.9970 (0.9966) gate/usage_max 0.5525 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1554 (0.1557) teacher/entropy 0.0110 (0.0218) teacher/usage_max 0.7841 (0.7007) teacher/usage_min 0.0625 (0.1137) teacher/usage_std 0.3209 (0.2625) nleep/row_max_mean 1501.9159 (1503.2531) nleep/row_max_std 50.5181 (58.2226) nleep/row_min_mean 1473.6875 (1475.3691) lr 4.8943e-05 eta 0:01:36
epoch [47/50] batch [40/162] time 0.182 (0.148) data 0.000 (0.007) loss 1.5790 (1.3685) teacher_loss 0.4886 (0.2152) loss_zs_kd 0.0715 (0.0429) loss_oracle 0.4971 (0.5810) kd_loss 0.8061 (0.8414) acc 78.1250 (91.1719) gate/entropy 0.9964 (0.9966) gate/usage_max 0.5531 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1558 (0.1556) teacher/entropy 0.0111 (0.0243) teacher/usage_max 0.7519 (0.7019) teacher/usage_min 0.1226 (0.1127) teacher/usage_std 0.2960 (0.2638) nleep/row_max_mean 1509.7853 (1502.5638) nleep/row_max_std 59.0611 (56.7572) nleep/row_min_mean 1481.6233 (1474.2677) lr 4.8943e-05 eta 0:01:30
epoch [47/50] batch [60/162] time 0.161 (0.159) data 0.000 (0.005) loss 1.6679 (1.3635) teacher_loss 0.3776 (0.2108) loss_zs_kd 0.0476 (0.0416) loss_oracle 0.6413 (0.5826) kd_loss 0.9458 (0.8405) acc 84.3750 (91.5625) gate/entropy 0.9968 (0.9966) gate/usage_max 0.5527 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1556) teacher/entropy 0.0448 (0.0254) teacher/usage_max 0.5651 (0.7019) teacher/usage_min 0.1876 (0.1072) teacher/usage_std 0.1657 (0.2647) nleep/row_max_mean 1489.7312 (1503.3261) nleep/row_max_std 49.5566 (56.8333) nleep/row_min_mean 1463.9196 (1474.9829) lr 4.8943e-05 eta 0:01:33
epoch [47/50] batch [80/162] time 0.172 (0.163) data 0.000 (0.003) loss 1.2640 (1.3590) teacher_loss 0.2592 (0.2085) loss_zs_kd 0.0523 (0.0419) loss_oracle 0.4996 (0.5764) kd_loss 0.7289 (0.8414) acc 90.6250 (91.7188) gate/entropy 0.9968 (0.9966) gate/usage_max 0.5527 (0.5529) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1555 (0.1556) teacher/entropy 0.0094 (0.0244) teacher/usage_max 0.8412 (0.7022) teacher/usage_min 0.0651 (0.1071) teacher/usage_std 0.3593 (0.2650) nleep/row_max_mean 1519.7737 (1503.7312) nleep/row_max_std 43.5658 (56.2041) nleep/row_min_mean 1489.4977 (1475.3863) lr 4.8943e-05 eta 0:01:32
epoch [47/50] batch [100/162] time 0.187 (0.168) data 0.000 (0.003) loss 1.4333 (1.3614) teacher_loss 0.1587 (0.2103) loss_zs_kd 0.0357 (0.0416) loss_oracle 0.6228 (0.5803) kd_loss 0.9453 (0.8401) acc 93.7500 (91.6250) gate/entropy 0.9966 (0.9966) gate/usage_max 0.5529 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1556) teacher/entropy 0.0108 (0.0249) teacher/usage_max 0.5931 (0.7030) teacher/usage_min 0.1570 (0.1055) teacher/usage_std 0.1876 (0.2655) nleep/row_max_mean 1494.1635 (1503.9402) nleep/row_max_std 65.8210 (56.0334) nleep/row_min_mean 1464.7515 (1475.6748) lr 4.8943e-05 eta 0:01:31
epoch [47/50] batch [120/162] time 0.197 (0.170) data 0.000 (0.002) loss 1.3065 (1.3635) teacher_loss 0.2424 (0.2148) loss_zs_kd 0.0262 (0.0414) loss_oracle 0.6149 (0.5807) kd_loss 0.7436 (0.8376) acc 87.5000 (91.4323) gate/entropy 0.9964 (0.9966) gate/usage_max 0.5531 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1558 (0.1556) teacher/entropy 0.0835 (0.0259) teacher/usage_max 0.7449 (0.7046) teacher/usage_min 0.1028 (0.1048) teacher/usage_std 0.2917 (0.2666) nleep/row_max_mean 1519.3060 (1504.3846) nleep/row_max_std 54.8197 (55.6960) nleep/row_min_mean 1491.7139 (1476.0780) lr 4.8943e-05 eta 0:01:29
epoch [47/50] batch [140/162] time 0.158 (0.171) data 0.000 (0.002) loss 1.2344 (1.3521) teacher_loss 0.1878 (0.2126) loss_zs_kd 0.0617 (0.0421) loss_oracle 0.5510 (0.5767) kd_loss 0.7402 (0.8301) acc 93.7500 (91.6071) gate/entropy 0.9966 (0.9966) gate/usage_max 0.5529 (0.5529) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1557 (0.1556) teacher/entropy 0.0346 (0.0262) teacher/usage_max 0.7980 (0.7126) teacher/usage_min 0.0938 (0.1001) teacher/usage_std 0.3286 (0.2721) nleep/row_max_mean 1509.8602 (1504.9771) nleep/row_max_std 52.9243 (55.2694) nleep/row_min_mean 1480.7762 (1476.6654) lr 4.8943e-05 eta 0:01:26
epoch [47/50] batch [160/162] time 0.153 (0.171) data 0.000 (0.002) loss 1.2388 (1.3511) teacher_loss 0.2079 (0.2109) loss_zs_kd 0.0327 (0.0417) loss_oracle 0.5162 (0.5762) kd_loss 0.7564 (0.8313) acc 93.7500 (91.6797) gate/entropy 0.9964 (0.9966) gate/usage_max 0.5532 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1558 (0.1556) teacher/entropy 0.0127 (0.0262) teacher/usage_max 0.8123 (0.7111) teacher/usage_min 0.0348 (0.1009) teacher/usage_std 0.3421 (0.2710) nleep/row_max_mean 1521.7268 (1504.8915) nleep/row_max_std 50.0170 (55.6001) nleep/row_min_mean 1493.9277 (1476.6352) lr 4.8943e-05 eta 0:01:23
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,928
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 86.6%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,341
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 69.5%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [48/50] batch [20/162] time 0.182 (0.194) data 0.000 (0.013) loss 1.3848 (1.3485) teacher_loss 0.2663 (0.1947) loss_zs_kd 0.0424 (0.0386) loss_oracle 0.6186 (0.5961) kd_loss 0.7880 (0.8365) acc 87.5000 (93.1250) gate/entropy 0.9965 (0.9966) gate/usage_max 0.5531 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1558 (0.1557) teacher/entropy 0.0187 (0.0360) teacher/usage_max 0.7516 (0.6941) teacher/usage_min 0.0336 (0.1077) teacher/usage_std 0.3049 (0.2590) nleep/row_max_mean 1508.9921 (1503.0414) nleep/row_max_std 51.4531 (58.9718) nleep/row_min_mean 1481.2188 (1475.9188) lr 3.1417e-05 eta 0:01:30
epoch [48/50] batch [40/162] time 0.087 (0.169) data 0.000 (0.007) loss 1.5699 (1.3544) teacher_loss 0.2214 (0.1997) loss_zs_kd 0.0393 (0.0390) loss_oracle 0.6553 (0.5897) kd_loss 1.0011 (0.8403) acc 87.5000 (92.3438) gate/entropy 0.9970 (0.9966) gate/usage_max 0.5525 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1554 (0.1556) teacher/entropy 0.0237 (0.0310) teacher/usage_max 0.5293 (0.6960) teacher/usage_min 0.1885 (0.1084) teacher/usage_std 0.1437 (0.2602) nleep/row_max_mean 1483.5359 (1502.6310) nleep/row_max_std 58.2339 (58.2109) nleep/row_min_mean 1455.1882 (1475.1511) lr 3.1417e-05 eta 0:01:15
epoch [48/50] batch [60/162] time 0.163 (0.158) data 0.001 (0.004) loss 1.4692 (1.3468) teacher_loss 0.2229 (0.2042) loss_zs_kd 0.0375 (0.0401) loss_oracle 0.6277 (0.5808) kd_loss 0.9137 (0.8322) acc 93.7500 (91.9792) gate/entropy 0.9969 (0.9966) gate/usage_max 0.5526 (0.5528) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1554 (0.1556) teacher/entropy 0.0010 (0.0313) teacher/usage_max 0.6562 (0.7050) teacher/usage_min 0.0938 (0.1005) teacher/usage_std 0.2370 (0.2669) nleep/row_max_mean 1487.0112 (1502.8528) nleep/row_max_std 61.6468 (57.3331) nleep/row_min_mean 1459.5137 (1475.2743) lr 3.1417e-05 eta 0:01:07
epoch [48/50] batch [80/162] time 0.161 (0.162) data 0.000 (0.003) loss 1.1929 (1.3435) teacher_loss 0.2111 (0.2073) loss_zs_kd 0.0213 (0.0398) loss_oracle 0.4156 (0.5844) kd_loss 0.7634 (0.8242) acc 90.6250 (91.6406) gate/entropy 0.9962 (0.9966) gate/usage_max 0.5533 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1559 (0.1556) teacher/entropy 0.0035 (0.0305) teacher/usage_max 0.8121 (0.7139) teacher/usage_min 0.0628 (0.0995) teacher/usage_std 0.3395 (0.2728) nleep/row_max_mean 1511.1603 (1504.2895) nleep/row_max_std 46.6586 (56.5943) nleep/row_min_mean 1481.8757 (1476.4928) lr 3.1417e-05 eta 0:01:05
epoch [48/50] batch [100/162] time 0.072 (0.157) data 0.000 (0.003) loss 1.6223 (1.3535) teacher_loss 0.4336 (0.2125) loss_zs_kd 0.0356 (0.0399) loss_oracle 0.6214 (0.5825) kd_loss 0.8602 (0.8298) acc 87.5000 (91.4688) gate/entropy 0.9966 (0.9966) gate/usage_max 0.5529 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1556) teacher/entropy 0.0246 (0.0287) teacher/usage_max 0.6821 (0.7101) teacher/usage_min 0.1303 (0.1008) teacher/usage_std 0.2478 (0.2703) nleep/row_max_mean 1494.8927 (1503.3535) nleep/row_max_std 64.4580 (57.2324) nleep/row_min_mean 1466.2651 (1475.5756) lr 3.1417e-05 eta 0:01:00
epoch [48/50] batch [120/162] time 0.211 (0.154) data 0.000 (0.002) loss 1.4729 (1.3593) teacher_loss 0.2646 (0.2165) loss_zs_kd 0.0277 (0.0404) loss_oracle 0.6386 (0.5852) kd_loss 0.8752 (0.8299) acc 90.6250 (91.1979) gate/entropy 0.9965 (0.9966) gate/usage_max 0.5530 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1556) teacher/entropy 0.0054 (0.0287) teacher/usage_max 0.6866 (0.7098) teacher/usage_min 0.1251 (0.1033) teacher/usage_std 0.2511 (0.2697) nleep/row_max_mean 1503.9492 (1503.2260) nleep/row_max_std 56.7374 (57.1925) nleep/row_min_mean 1477.2562 (1475.2669) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [140/162] time 0.171 (0.154) data 0.000 (0.002) loss 1.4072 (1.3550) teacher_loss 0.2063 (0.2158) loss_zs_kd 0.0438 (0.0410) loss_oracle 0.5464 (0.5802) kd_loss 0.9058 (0.8286) acc 93.7500 (91.1607) gate/entropy 0.9965 (0.9966) gate/usage_max 0.5531 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1558 (0.1556) teacher/entropy 0.0045 (0.0277) teacher/usage_max 0.6554 (0.7123) teacher/usage_min 0.1259 (0.1020) teacher/usage_std 0.2309 (0.2714) nleep/row_max_mean 1507.0354 (1503.6833) nleep/row_max_std 63.1994 (56.8570) nleep/row_min_mean 1478.6260 (1475.5913) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [160/162] time 0.196 (0.157) data 0.000 (0.002) loss 1.3295 (1.3477) teacher_loss 0.1585 (0.2108) loss_zs_kd 0.0453 (0.0411) loss_oracle 0.6540 (0.5784) kd_loss 0.8215 (0.8272) acc 93.7500 (91.4258) gate/entropy 0.9965 (0.9966) gate/usage_max 0.5531 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1558 (0.1556) teacher/entropy 0.0311 (0.0274) teacher/usage_max 0.7096 (0.7143) teacher/usage_min 0.1304 (0.1017) teacher/usage_std 0.2663 (0.2726) nleep/row_max_mean 1511.5343 (1503.9595) nleep/row_max_std 58.6083 (56.4717) nleep/row_min_mean 1483.3445 (1475.8522) lr 3.1417e-05 eta 0:00:51
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,927
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,336
* accuracy: 71.2%
* error: 28.8%
* macro_f1: 69.4%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [49/50] batch [20/162] time 0.196 (0.195) data 0.000 (0.013) loss 1.1866 (1.3535) teacher_loss 0.1593 (0.2181) loss_zs_kd 0.0429 (0.0375) loss_oracle 0.4893 (0.5811) kd_loss 0.7612 (0.8261) acc 87.5000 (91.5625) gate/entropy 0.9967 (0.9966) gate/usage_max 0.5528 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1557) teacher/entropy 0.0014 (0.0313) teacher/usage_max 0.8126 (0.7115) teacher/usage_min 0.0936 (0.0931) teacher/usage_std 0.3389 (0.2724) nleep/row_max_mean 1515.5265 (1507.3921) nleep/row_max_std 45.2662 (53.7437) nleep/row_min_mean 1487.4556 (1478.7376) lr 1.7713e-05 eta 0:00:59
epoch [49/50] batch [40/162] time 0.181 (0.188) data 0.000 (0.007) loss 1.3518 (1.3531) teacher_loss 0.2610 (0.2225) loss_zs_kd 0.0503 (0.0395) loss_oracle 0.5660 (0.5808) kd_loss 0.7827 (0.8205) acc 84.3750 (91.0938) gate/entropy 0.9967 (0.9966) gate/usage_max 0.5528 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1557) teacher/entropy 0.0152 (0.0295) teacher/usage_max 0.7754 (0.7193) teacher/usage_min 0.0937 (0.0996) teacher/usage_std 0.3130 (0.2763) nleep/row_max_mean 1508.8073 (1507.5414) nleep/row_max_std 47.6912 (53.4507) nleep/row_min_mean 1480.0780 (1478.9628) lr 1.7713e-05 eta 0:00:53
epoch [49/50] batch [60/162] time 0.196 (0.190) data 0.000 (0.005) loss 1.3895 (1.3676) teacher_loss 0.1443 (0.2252) loss_zs_kd 0.0441 (0.0397) loss_oracle 0.5813 (0.5820) kd_loss 0.9325 (0.8316) acc 93.7500 (90.9375) gate/entropy 0.9966 (0.9966) gate/usage_max 0.5530 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1557) teacher/entropy 0.0202 (0.0286) teacher/usage_max 0.6204 (0.7085) teacher/usage_min 0.0638 (0.1036) teacher/usage_std 0.2276 (0.2693) nleep/row_max_mean 1490.8497 (1506.1648) nleep/row_max_std 58.8461 (54.7941) nleep/row_min_mean 1464.8064 (1477.5613) lr 1.7713e-05 eta 0:00:50
epoch [49/50] batch [80/162] time 0.184 (0.190) data 0.000 (0.003) loss 1.2815 (1.3658) teacher_loss 0.2152 (0.2220) loss_zs_kd 0.0487 (0.0405) loss_oracle 0.5081 (0.5805) kd_loss 0.7879 (0.8334) acc 93.7500 (90.8594) gate/entropy 0.9963 (0.9966) gate/usage_max 0.5532 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1559 (0.1557) teacher/entropy 0.0186 (0.0289) teacher/usage_max 0.7555 (0.7058) teacher/usage_min 0.0625 (0.1068) teacher/usage_std 0.3025 (0.2672) nleep/row_max_mean 1520.0111 (1506.3112) nleep/row_max_std 51.6137 (54.5932) nleep/row_min_mean 1489.3210 (1477.7202) lr 1.7713e-05 eta 0:00:46
epoch [49/50] batch [100/162] time 0.177 (0.186) data 0.000 (0.003) loss 1.2470 (1.3617) teacher_loss 0.1086 (0.2251) loss_zs_kd 0.0519 (0.0403) loss_oracle 0.5367 (0.5742) kd_loss 0.8441 (0.8294) acc 96.8750 (90.7500) gate/entropy 0.9969 (0.9966) gate/usage_max 0.5526 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1554 (0.1557) teacher/entropy 0.0092 (0.0274) teacher/usage_max 0.7189 (0.7121) teacher/usage_min 0.0938 (0.1021) teacher/usage_std 0.2753 (0.2720) nleep/row_max_mean 1500.7627 (1506.6061) nleep/row_max_std 57.1962 (54.7904) nleep/row_min_mean 1472.9961 (1478.0679) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [120/162] time 0.140 (0.184) data 0.000 (0.002) loss 1.4192 (1.3562) teacher_loss 0.1987 (0.2200) loss_zs_kd 0.0526 (0.0406) loss_oracle 0.6474 (0.5767) kd_loss 0.8705 (0.8276) acc 90.6250 (90.8854) gate/entropy 0.9968 (0.9966) gate/usage_max 0.5526 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1555 (0.1557) teacher/entropy 0.0354 (0.0268) teacher/usage_max 0.6526 (0.7146) teacher/usage_min 0.1635 (0.1033) teacher/usage_std 0.2259 (0.2733) nleep/row_max_mean 1499.2273 (1506.7237) nleep/row_max_std 58.4011 (54.7682) nleep/row_min_mean 1469.6987 (1478.1403) lr 1.7713e-05 eta 0:00:37
epoch [49/50] batch [140/162] time 0.183 (0.172) data 0.000 (0.002) loss 1.2316 (1.3583) teacher_loss 0.1942 (0.2185) loss_zs_kd 0.0327 (0.0412) loss_oracle 0.5804 (0.5776) kd_loss 0.7308 (0.8304) acc 93.7500 (90.9152) gate/entropy 0.9963 (0.9966) gate/usage_max 0.5533 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1559 (0.1557) teacher/entropy 0.0392 (0.0257) teacher/usage_max 0.7989 (0.7124) teacher/usage_min 0.0701 (0.1032) teacher/usage_std 0.3301 (0.2719) nleep/row_max_mean 1524.3950 (1506.3618) nleep/row_max_std 51.9971 (54.9211) nleep/row_min_mean 1496.8008 (1477.7821) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [160/162] time 0.203 (0.174) data 0.000 (0.002) loss 1.2352 (1.3548) teacher_loss 0.1745 (0.2156) loss_zs_kd 0.0382 (0.0415) loss_oracle 0.4394 (0.5767) kd_loss 0.8219 (0.8301) acc 93.7500 (91.0938) gate/entropy 0.9965 (0.9966) gate/usage_max 0.5530 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1556) teacher/entropy 0.0110 (0.0251) teacher/usage_max 0.7518 (0.7135) teacher/usage_min 0.0009 (0.1019) teacher/usage_std 0.3126 (0.2727) nleep/row_max_mean 1506.9047 (1506.2153) nleep/row_max_std 60.4948 (54.6176) nleep/row_min_mean 1478.0931 (1477.6968) lr 1.7713e-05 eta 0:00:28
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,927
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,337
* accuracy: 71.2%
* error: 28.8%
* macro_f1: 69.4%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
epoch [50/50] batch [20/162] time 0.171 (0.204) data 0.000 (0.017) loss 1.5797 (1.3959) teacher_loss 0.3063 (0.2438) loss_zs_kd 0.0384 (0.0445) loss_oracle 0.6890 (0.5970) kd_loss 0.9097 (0.8313) acc 90.6250 (89.3750) gate/entropy 0.9965 (0.9966) gate/usage_max 0.5530 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1557) teacher/entropy 0.0185 (0.0244) teacher/usage_max 0.6255 (0.7129) teacher/usage_min 0.1582 (0.1039) teacher/usage_std 0.2080 (0.2721) nleep/row_max_mean 1497.6636 (1505.3586) nleep/row_max_std 53.4161 (55.5504) nleep/row_min_mean 1471.3901 (1476.9179) lr 7.8853e-06 eta 0:00:28
epoch [50/50] batch [40/162] time 0.199 (0.193) data 0.000 (0.009) loss 1.5455 (1.3784) teacher_loss 0.3313 (0.2369) loss_zs_kd 0.0461 (0.0418) loss_oracle 0.6608 (0.5895) kd_loss 0.8607 (0.8259) acc 87.5000 (90.6250) gate/entropy 0.9967 (0.9966) gate/usage_max 0.5527 (0.5529) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1556 (0.1556) teacher/entropy 0.0210 (0.0292) teacher/usage_max 0.6899 (0.7140) teacher/usage_min 0.0957 (0.0993) teacher/usage_std 0.2567 (0.2732) nleep/row_max_mean 1498.8711 (1504.5515) nleep/row_max_std 50.7822 (53.7746) nleep/row_min_mean 1471.8566 (1476.2191) lr 7.8853e-06 eta 0:00:23
epoch [50/50] batch [60/162] time 0.177 (0.190) data 0.001 (0.006) loss 1.0564 (1.3691) teacher_loss 0.1472 (0.2282) loss_zs_kd 0.0316 (0.0416) loss_oracle 0.3852 (0.5845) kd_loss 0.7008 (0.8279) acc 90.6250 (90.7812) gate/entropy 0.9965 (0.9966) gate/usage_max 0.5530 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1558 (0.1557) teacher/entropy 0.0083 (0.0266) teacher/usage_max 0.8760 (0.7149) teacher/usage_min 0.0301 (0.0977) teacher/usage_std 0.3846 (0.2746) nleep/row_max_mean 1524.6721 (1505.4379) nleep/row_max_std 44.4909 (54.3242) nleep/row_min_mean 1494.6917 (1477.1808) lr 7.8853e-06 eta 0:00:19
epoch [50/50] batch [80/162] time 0.195 (0.188) data 0.000 (0.004) loss 1.2730 (1.3770) teacher_loss 0.1080 (0.2294) loss_zs_kd 0.0208 (0.0419) loss_oracle 0.6191 (0.5891) kd_loss 0.8451 (0.8321) acc 96.8750 (90.6250) gate/entropy 0.9967 (0.9966) gate/usage_max 0.5528 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1556 (0.1557) teacher/entropy 0.0212 (0.0277) teacher/usage_max 0.6986 (0.7087) teacher/usage_min 0.1451 (0.1028) teacher/usage_std 0.2583 (0.2697) nleep/row_max_mean 1497.5428 (1505.0184) nleep/row_max_std 60.3686 (54.9454) nleep/row_min_mean 1470.5476 (1476.8540) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [100/162] time 0.196 (0.187) data 0.000 (0.004) loss 1.4344 (1.3757) teacher_loss 0.2999 (0.2252) loss_zs_kd 0.0373 (0.0411) loss_oracle 0.6481 (0.5852) kd_loss 0.7918 (0.8374) acc 84.3750 (90.8125) gate/entropy 0.9965 (0.9966) gate/usage_max 0.5530 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1557 (0.1557) teacher/entropy 0.0312 (0.0281) teacher/usage_max 0.7424 (0.7027) teacher/usage_min 0.1036 (0.1058) teacher/usage_std 0.2900 (0.2654) nleep/row_max_mean 1502.8794 (1504.4884) nleep/row_max_std 47.4972 (55.4345) nleep/row_min_mean 1477.2009 (1476.3642) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [120/162] time 0.182 (0.184) data 0.000 (0.003) loss 1.1816 (1.3671) teacher_loss 0.2540 (0.2241) loss_zs_kd 0.0508 (0.0406) loss_oracle 0.3946 (0.5806) kd_loss 0.7048 (0.8325) acc 87.5000 (90.8073) gate/entropy 0.9965 (0.9966) gate/usage_max 0.5530 (0.5529) gate/usage_min 0.2099 (0.2098) gate/usage_std 0.1557 (0.1557) teacher/entropy 0.0112 (0.0277) teacher/usage_max 0.8716 (0.7082) teacher/usage_min 0.0034 (0.1052) teacher/usage_std 0.3838 (0.2689) nleep/row_max_mean 1527.9004 (1505.3052) nleep/row_max_std 46.3659 (55.0466) nleep/row_min_mean 1499.4982 (1477.1605) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [140/162] time 0.198 (0.183) data 0.000 (0.003) loss 1.4462 (1.3668) teacher_loss 0.3055 (0.2231) loss_zs_kd 0.0529 (0.0406) loss_oracle 0.6158 (0.5814) kd_loss 0.8064 (0.8327) acc 96.8750 (90.9152) gate/entropy 0.9963 (0.9966) gate/usage_max 0.5532 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1559 (0.1557) teacher/entropy 0.0237 (0.0276) teacher/usage_max 0.7270 (0.7079) teacher/usage_min 0.0625 (0.1060) teacher/usage_std 0.2849 (0.2686) nleep/row_max_mean 1515.1658 (1505.4922) nleep/row_max_std 52.4821 (55.1903) nleep/row_min_mean 1488.0383 (1477.3054) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [160/162] time 0.169 (0.182) data 0.000 (0.002) loss 1.2554 (1.3622) teacher_loss 0.1709 (0.2197) loss_zs_kd 0.0620 (0.0405) loss_oracle 0.5525 (0.5807) kd_loss 0.7773 (0.8318) acc 96.8750 (91.0742) gate/entropy 0.9964 (0.9966) gate/usage_max 0.5531 (0.5529) gate/usage_min 0.2098 (0.2098) gate/usage_std 0.1558 (0.1557) teacher/entropy 0.0179 (0.0271) teacher/usage_max 0.7792 (0.7093) teacher/usage_min 0.0916 (0.1053) teacher/usage_std 0.3156 (0.2695) nleep/row_max_mean 1506.5227 (1505.4273) nleep/row_max_std 63.1711 (55.4645) nleep/row_min_mean 1480.1641 (1477.2385) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,234
* correct: 1,928
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 86.5%
Evaluate on the *test* set
=> result
* total: 3,282
* correct: 2,335
* accuracy: 71.1%
* error: 28.9%
* macro_f1: 69.4%
******* Domain s best val acc:      87.5%, epoch: 7 *******
******* Domain s best val test acc: 75.4%, epoch: 7 *******
******* Domain s best test acc:     82.0%, epoch: 8 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/vlcs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:28:53

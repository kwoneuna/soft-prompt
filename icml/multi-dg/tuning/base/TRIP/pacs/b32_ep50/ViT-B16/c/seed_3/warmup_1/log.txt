Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -----------------------------------
Dataset    SPG_PACS
Source     ['art_painting', 'photo', 'sketch']
Target     ['cartoon']
# classes  7
# train_x  5,349
# val      2,297
# test     2,344
---------  -----------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_3/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_3/warmup_1/tensorboard)
epoch [1/50] batch [20/167] time 0.118 (0.184) data 0.000 (0.023) loss 1.0585 (1.3693) teacher_loss 0.2835 (0.5348) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0002 (-0.0000) kd_loss 0.7749 (0.8345) acc 90.6250 (80.1562) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3297 (0.3298) gate/usage_std 0.0031 (0.0032) teacher/entropy 0.3266 (0.2648) teacher/usage_max 0.6277 (0.5499) teacher/usage_min 0.0982 (0.1914) teacher/usage_std 0.2202 (0.1569) nleep/row_max_mean 1594.8220 (1591.2485) nleep/row_max_std 58.5896 (81.7366) nleep/row_min_mean 1585.1946 (1577.9941) lr 1.0000e-05 eta 0:25:30
epoch [1/50] batch [40/167] time 0.150 (0.160) data 0.000 (0.011) loss 1.0572 (1.2889) teacher_loss 0.3824 (0.5259) loss_zs_kd 0.0002 (0.0000) loss_oracle 0.0024 (0.0005) kd_loss 0.6735 (0.7627) acc 93.7500 (80.7812) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3297 (0.3298) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.4274 (0.3370) teacher/usage_max 0.4991 (0.5612) teacher/usage_min 0.1778 (0.1846) teacher/usage_std 0.1314 (0.1657) nleep/row_max_mean 1603.3201 (1600.1898) nleep/row_max_std 69.9318 (74.4092) nleep/row_min_mean 1597.9297 (1590.1063) lr 1.0000e-05 eta 0:22:12
epoch [1/50] batch [60/167] time 0.145 (0.156) data 0.000 (0.008) loss 0.9157 (1.2263) teacher_loss 0.2935 (0.5061) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0069 (0.0016) kd_loss 0.6186 (0.7193) acc 87.5000 (81.4583) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0031 (0.0032) teacher/entropy 0.4821 (0.3805) teacher/usage_max 0.6741 (0.5666) teacher/usage_min 0.1077 (0.1801) teacher/usage_std 0.2452 (0.1697) nleep/row_max_mean 1631.8531 (1603.5266) nleep/row_max_std 58.6947 (70.9457) nleep/row_min_mean 1627.6711 (1595.0631) lr 1.0000e-05 eta 0:21:31
epoch [1/50] batch [80/167] time 0.166 (0.155) data 0.000 (0.006) loss 0.6525 (1.1769) teacher_loss 0.1574 (0.4957) loss_zs_kd 0.0001 (0.0001) loss_oracle 0.0096 (0.0034) kd_loss 0.4903 (0.6794) acc 100.0000 (81.8359) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0031 (0.0032) teacher/entropy 0.6096 (0.4203) teacher/usage_max 0.6121 (0.5743) teacher/usage_min 0.1762 (0.1799) teacher/usage_std 0.1976 (0.1743) nleep/row_max_mean 1600.7380 (1605.5753) nleep/row_max_std 62.4595 (68.6431) nleep/row_min_mean 1597.3677 (1598.1614) lr 1.0000e-05 eta 0:21:24
epoch [1/50] batch [100/167] time 0.154 (0.155) data 0.000 (0.005) loss 1.1458 (1.1466) teacher_loss 0.5841 (0.4904) loss_zs_kd 0.0020 (0.0002) loss_oracle 0.0197 (0.0062) kd_loss 0.5508 (0.6529) acc 81.2500 (82.0938) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3297 (0.3298) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.5481 (0.4467) teacher/usage_max 0.6917 (0.5822) teacher/usage_min 0.1306 (0.1786) teacher/usage_std 0.2541 (0.1793) nleep/row_max_mean 1599.3347 (1606.6696) nleep/row_max_std 52.9860 (68.0968) nleep/row_min_mean 1595.8296 (1599.9634) lr 1.0000e-05 eta 0:21:21
epoch [1/50] batch [120/167] time 0.147 (0.154) data 0.000 (0.004) loss 0.6896 (1.1188) teacher_loss 0.1770 (0.4813) loss_zs_kd 0.0005 (0.0004) loss_oracle 0.0260 (0.0098) kd_loss 0.4994 (0.6325) acc 96.8750 (82.4740) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3373 (0.3374) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0031 (0.0032) teacher/entropy 0.6004 (0.4672) teacher/usage_max 0.6011 (0.5910) teacher/usage_min 0.1772 (0.1768) teacher/usage_std 0.1902 (0.1851) nleep/row_max_mean 1597.6665 (1606.2122) nleep/row_max_std 56.6241 (67.5034) nleep/row_min_mean 1593.8444 (1600.0164) lr 1.0000e-05 eta 0:21:06
epoch [1/50] batch [140/167] time 0.139 (0.153) data 0.000 (0.003) loss 0.7788 (1.1073) teacher_loss 0.3132 (0.4821) loss_zs_kd 0.0003 (0.0005) loss_oracle 0.0308 (0.0136) kd_loss 0.4499 (0.6181) acc 90.6250 (82.7009) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3296 (0.3298) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.6492 (0.4816) teacher/usage_max 0.6185 (0.6009) teacher/usage_min 0.1854 (0.1736) teacher/usage_std 0.2017 (0.1917) nleep/row_max_mean 1593.7756 (1605.5042) nleep/row_max_std 75.0101 (66.6164) nleep/row_min_mean 1590.5979 (1599.6898) lr 1.0000e-05 eta 0:20:56
epoch [1/50] batch [160/167] time 0.074 (0.146) data 0.000 (0.003) loss 1.0762 (1.0978) teacher_loss 0.4382 (0.4781) loss_zs_kd 0.0014 (0.0007) loss_oracle 0.0691 (0.0176) kd_loss 0.6027 (0.6104) acc 81.2500 (82.7930) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3373 (0.3374) gate/usage_min 0.3297 (0.3298) gate/usage_std 0.0031 (0.0032) teacher/entropy 0.4962 (0.4891) teacher/usage_max 0.6408 (0.6093) teacher/usage_min 0.1627 (0.1708) teacher/usage_std 0.2179 (0.1974) nleep/row_max_mean 1585.1239 (1604.2821) nleep/row_max_std 70.0493 (66.2784) nleep/row_min_mean 1581.3157 (1598.7262) lr 1.0000e-05 eta 0:19:58
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,170
* accuracy: 94.5%
* error: 5.5%
* macro_f1: 95.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,325
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      94.5%, epoch: 1 *******
******* Domain c best val test acc: 99.2%, epoch: 1 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [2/50] batch [20/167] time 0.094 (0.114) data 0.000 (0.014) loss 1.1241 (1.0642) teacher_loss 0.2662 (0.3765) loss_zs_kd 0.0045 (0.0059) loss_oracle 0.2068 (0.1975) kd_loss 0.7522 (0.5860) acc 87.5000 (85.3125) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3359 (0.3366) gate/usage_min 0.3282 (0.3290) gate/usage_std 0.0036 (0.0033) teacher/entropy 0.3423 (0.5113) teacher/usage_max 0.7136 (0.6618) teacher/usage_min 0.1317 (0.1569) teacher/usage_std 0.2691 (0.2326) nleep/row_max_mean 1618.8584 (1598.6770) nleep/row_max_std 45.5460 (67.0870) nleep/row_min_mean 1613.3966 (1594.4949) lr 2.0000e-03 eta 0:15:27
epoch [2/50] batch [40/167] time 0.068 (0.116) data 0.000 (0.007) loss 1.2782 (1.1209) teacher_loss 0.3856 (0.3937) loss_zs_kd 0.0076 (0.0066) loss_oracle 0.2874 (0.2166) kd_loss 0.7451 (0.6156) acc 84.3750 (84.7656) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3393 (0.3371) gate/usage_min 0.3266 (0.3282) gate/usage_std 0.0052 (0.0038) teacher/entropy 0.3422 (0.4789) teacher/usage_max 0.7683 (0.6729) teacher/usage_min 0.1018 (0.1476) teacher/usage_std 0.3078 (0.2406) nleep/row_max_mean 1595.7466 (1600.1064) nleep/row_max_std 53.6175 (64.5811) nleep/row_min_mean 1588.8798 (1595.3760) lr 2.0000e-03 eta 0:15:42
epoch [2/50] batch [60/167] time 0.077 (0.114) data 0.000 (0.005) loss 1.3084 (1.1479) teacher_loss 0.4633 (0.3905) loss_zs_kd 0.0014 (0.0074) loss_oracle 0.2728 (0.2349) kd_loss 0.7081 (0.6363) acc 84.3750 (85.4167) gate/entropy 1.0984 (1.0985) gate/usage_max 0.3432 (0.3386) gate/usage_min 0.3248 (0.3273) gate/usage_std 0.0076 (0.0047) teacher/entropy 0.3711 (0.4551) teacher/usage_max 0.7780 (0.6838) teacher/usage_min 0.1066 (0.1430) teacher/usage_std 0.3144 (0.2483) nleep/row_max_mean 1613.9928 (1601.8739) nleep/row_max_std 57.4941 (64.0208) nleep/row_min_mean 1605.7538 (1596.5916) lr 2.0000e-03 eta 0:15:29
epoch [2/50] batch [80/167] time 0.074 (0.114) data 0.000 (0.004) loss 1.2371 (1.1640) teacher_loss 0.3751 (0.3822) loss_zs_kd 0.0079 (0.0072) loss_oracle 0.2875 (0.2460) kd_loss 0.7143 (0.6551) acc 87.5000 (85.7812) gate/entropy 1.0981 (1.0984) gate/usage_max 0.3477 (0.3403) gate/usage_min 0.3227 (0.3264) gate/usage_std 0.0105 (0.0058) teacher/entropy 0.3607 (0.4329) teacher/usage_max 0.7088 (0.6905) teacher/usage_min 0.1331 (0.1385) teacher/usage_std 0.2657 (0.2532) nleep/row_max_mean 1599.4685 (1601.4771) nleep/row_max_std 54.7003 (63.1624) nleep/row_min_mean 1591.7937 (1595.6969) lr 2.0000e-03 eta 0:15:21
epoch [2/50] batch [100/167] time 0.095 (0.112) data 0.000 (0.003) loss 1.0546 (1.1681) teacher_loss 0.2959 (0.3716) loss_zs_kd 0.0090 (0.0077) loss_oracle 0.2381 (0.2597) kd_loss 0.6351 (0.6628) acc 90.6250 (86.3438) gate/entropy 1.0978 (1.0983) gate/usage_max 0.3519 (0.3422) gate/usage_min 0.3210 (0.3255) gate/usage_std 0.0134 (0.0071) teacher/entropy 0.4346 (0.4223) teacher/usage_max 0.6879 (0.6884) teacher/usage_min 0.1512 (0.1396) teacher/usage_std 0.2508 (0.2517) nleep/row_max_mean 1590.5559 (1600.5993) nleep/row_max_std 82.4609 (63.1630) nleep/row_min_mean 1583.2258 (1594.3899) lr 2.0000e-03 eta 0:15:02
epoch [2/50] batch [120/167] time 0.097 (0.111) data 0.000 (0.003) loss 1.0692 (1.1790) teacher_loss 0.1487 (0.3674) loss_zs_kd 0.0091 (0.0079) loss_oracle 0.3797 (0.2675) kd_loss 0.7261 (0.6739) acc 96.8750 (86.6406) gate/entropy 1.0975 (1.0982) gate/usage_max 0.3558 (0.3442) gate/usage_min 0.3194 (0.3246) gate/usage_std 0.0160 (0.0084) teacher/entropy 0.3416 (0.4082) teacher/usage_max 0.6508 (0.6884) teacher/usage_min 0.1628 (0.1389) teacher/usage_std 0.2247 (0.2517) nleep/row_max_mean 1580.1777 (1599.4869) nleep/row_max_std 60.4052 (62.7101) nleep/row_min_mean 1570.2471 (1592.8267) lr 2.0000e-03 eta 0:14:55
epoch [2/50] batch [140/167] time 0.065 (0.112) data 0.000 (0.002) loss 1.1554 (1.1980) teacher_loss 0.3487 (0.3737) loss_zs_kd 0.0082 (0.0083) loss_oracle 0.3174 (0.2751) kd_loss 0.6439 (0.6826) acc 93.7500 (86.3393) gate/entropy 1.0971 (1.0981) gate/usage_max 0.3594 (0.3462) gate/usage_min 0.3179 (0.3237) gate/usage_std 0.0185 (0.0097) teacher/entropy 0.4433 (0.3970) teacher/usage_max 0.4436 (0.6830) teacher/usage_min 0.2729 (0.1412) teacher/usage_std 0.0781 (0.2479) nleep/row_max_mean 1574.8978 (1598.1602) nleep/row_max_std 71.6333 (62.5492) nleep/row_min_mean 1567.4742 (1591.1212) lr 2.0000e-03 eta 0:15:04
epoch [2/50] batch [160/167] time 0.070 (0.112) data 0.000 (0.002) loss 1.1828 (1.2101) teacher_loss 0.1870 (0.3647) loss_zs_kd 0.0037 (0.0086) loss_oracle 0.4862 (0.2978) kd_loss 0.7508 (0.6922) acc 93.7500 (86.7578) gate/entropy 1.0965 (1.0979) gate/usage_max 0.3642 (0.3481) gate/usage_min 0.3156 (0.3229) gate/usage_std 0.0219 (0.0110) teacher/entropy 0.3055 (0.3844) teacher/usage_max 0.6546 (0.6840) teacher/usage_min 0.1500 (0.1396) teacher/usage_std 0.2279 (0.2487) nleep/row_max_mean 1586.0498 (1596.2303) nleep/row_max_std 53.1080 (61.5966) nleep/row_min_mean 1575.2949 (1588.7587) lr 2.0000e-03 eta 0:14:58
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,177
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 95.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      94.8%, epoch: 2 *******
******* Domain c best val test acc: 99.1%, epoch: 2 *******
******* Domain c best test acc:     99.2%, epoch: 1 *******
epoch [3/50] batch [20/167] time 0.145 (0.111) data 0.000 (0.015) loss 1.4784 (1.3929) teacher_loss 0.3595 (0.3637) loss_zs_kd 0.0240 (0.0101) loss_oracle 0.5516 (0.4853) kd_loss 0.8311 (0.7814) acc 90.6250 (86.2500) gate/entropy 1.0955 (1.0958) gate/usage_max 0.3709 (0.3685) gate/usage_min 0.3123 (0.3134) gate/usage_std 0.0266 (0.0250) teacher/entropy 0.2072 (0.2625) teacher/usage_max 0.7155 (0.6987) teacher/usage_min 0.1337 (0.1180) teacher/usage_std 0.2703 (0.2607) nleep/row_max_mean 1582.9390 (1587.1601) nleep/row_max_std 61.9753 (55.5073) nleep/row_min_mean 1568.9924 (1575.1197) lr 1.9980e-03 eta 0:14:49
epoch [3/50] batch [40/167] time 0.132 (0.127) data 0.000 (0.008) loss 1.4444 (1.3985) teacher_loss 0.3747 (0.3638) loss_zs_kd 0.0101 (0.0105) loss_oracle 0.5094 (0.5043) kd_loss 0.8099 (0.7773) acc 87.5000 (86.7188) gate/entropy 1.0946 (1.0954) gate/usage_max 0.3760 (0.3710) gate/usage_min 0.3105 (0.3124) gate/usage_std 0.0302 (0.0267) teacher/entropy 0.2188 (0.2633) teacher/usage_max 0.7294 (0.6998) teacher/usage_min 0.0920 (0.1161) teacher/usage_std 0.2823 (0.2616) nleep/row_max_mean 1605.5164 (1582.8414) nleep/row_max_std 39.7489 (56.4307) nleep/row_min_mean 1592.5233 (1570.5708) lr 1.9980e-03 eta 0:16:54
epoch [3/50] batch [60/167] time 0.158 (0.134) data 0.000 (0.005) loss 1.3411 (1.3832) teacher_loss 0.2437 (0.3448) loss_zs_kd 0.0224 (0.0113) loss_oracle 0.4763 (0.4879) kd_loss 0.8481 (0.7889) acc 90.6250 (87.4479) gate/entropy 1.0939 (1.0950) gate/usage_max 0.3798 (0.3733) gate/usage_min 0.3100 (0.3117) gate/usage_std 0.0329 (0.0283) teacher/entropy 0.1977 (0.2525) teacher/usage_max 0.6153 (0.6798) teacher/usage_min 0.1051 (0.1127) teacher/usage_std 0.2117 (0.2505) nleep/row_max_mean 1585.0936 (1580.0958) nleep/row_max_std 54.8901 (57.6008) nleep/row_min_mean 1573.8220 (1567.8958) lr 1.9980e-03 eta 0:17:48
epoch [3/50] batch [80/167] time 0.145 (0.141) data 0.000 (0.004) loss 1.5918 (1.3845) teacher_loss 0.5780 (0.3372) loss_zs_kd 0.0154 (0.0121) loss_oracle 0.3862 (0.4805) kd_loss 0.8130 (0.8010) acc 78.1250 (87.8906) gate/entropy 1.0931 (1.0946) gate/usage_max 0.3834 (0.3754) gate/usage_min 0.3074 (0.3109) gate/usage_std 0.0354 (0.0298) teacher/entropy 0.2400 (0.2402) teacher/usage_max 0.5594 (0.6666) teacher/usage_min 0.1316 (0.1085) teacher/usage_std 0.1755 (0.2441) nleep/row_max_mean 1570.6626 (1580.0213) nleep/row_max_std 56.6330 (58.0864) nleep/row_min_mean 1559.1138 (1567.5982) lr 1.9980e-03 eta 0:18:35
epoch [3/50] batch [100/167] time 0.164 (0.143) data 0.000 (0.003) loss 1.3924 (1.3848) teacher_loss 0.3336 (0.3377) loss_zs_kd 0.0142 (0.0129) loss_oracle 0.3440 (0.4690) kd_loss 0.8796 (0.8063) acc 84.3750 (87.6562) gate/entropy 1.0922 (1.0942) gate/usage_max 0.3873 (0.3774) gate/usage_min 0.3045 (0.3099) gate/usage_std 0.0382 (0.0312) teacher/entropy 0.1383 (0.2351) teacher/usage_max 0.6965 (0.6536) teacher/usage_min 0.0439 (0.1086) teacher/usage_std 0.2715 (0.2369) nleep/row_max_mean 1594.6353 (1579.6688) nleep/row_max_std 44.0808 (57.6010) nleep/row_min_mean 1582.2649 (1567.2360) lr 1.9980e-03 eta 0:18:49
epoch [3/50] batch [120/167] time 0.147 (0.143) data 0.000 (0.003) loss 1.4622 (1.3856) teacher_loss 0.3471 (0.3396) loss_zs_kd 0.0129 (0.0131) loss_oracle 0.5066 (0.4632) kd_loss 0.8554 (0.8078) acc 90.6250 (87.6302) gate/entropy 1.0915 (1.0938) gate/usage_max 0.3903 (0.3793) gate/usage_min 0.3023 (0.3089) gate/usage_std 0.0403 (0.0325) teacher/entropy 0.2021 (0.2321) teacher/usage_max 0.5163 (0.6493) teacher/usage_min 0.1202 (0.1117) teacher/usage_std 0.1631 (0.2338) nleep/row_max_mean 1562.9825 (1578.9473) nleep/row_max_std 40.8693 (57.2271) nleep/row_min_mean 1550.5355 (1566.4243) lr 1.9980e-03 eta 0:18:46
epoch [3/50] batch [140/167] time 0.080 (0.142) data 0.000 (0.002) loss 1.2555 (1.3930) teacher_loss 0.2714 (0.3423) loss_zs_kd 0.0194 (0.0138) loss_oracle 0.4479 (0.4703) kd_loss 0.7505 (0.8088) acc 87.5000 (87.5670) gate/entropy 1.0903 (1.0934) gate/usage_max 0.3949 (0.3813) gate/usage_min 0.2996 (0.3077) gate/usage_std 0.0436 (0.0339) teacher/entropy 0.2886 (0.2277) teacher/usage_max 0.5755 (0.6535) teacher/usage_min 0.1048 (0.1127) teacher/usage_std 0.1924 (0.2358) nleep/row_max_mean 1567.2334 (1578.7037) nleep/row_max_std 49.8043 (56.2542) nleep/row_min_mean 1555.0477 (1565.9042) lr 1.9980e-03 eta 0:18:39
epoch [3/50] batch [160/167] time 0.077 (0.135) data 0.000 (0.002) loss 1.2928 (1.3965) teacher_loss 0.2173 (0.3389) loss_zs_kd 0.0146 (0.0138) loss_oracle 0.4815 (0.4777) kd_loss 0.8275 (0.8119) acc 90.6250 (87.6562) gate/entropy 1.0889 (1.0929) gate/usage_max 0.3998 (0.3833) gate/usage_min 0.2966 (0.3065) gate/usage_std 0.0471 (0.0354) teacher/entropy 0.1582 (0.2208) teacher/usage_max 0.7571 (0.6582) teacher/usage_min 0.1048 (0.1139) teacher/usage_std 0.2999 (0.2383) nleep/row_max_mean 1572.1470 (1578.4173) nleep/row_max_std 47.2740 (55.6759) nleep/row_min_mean 1557.7803 (1565.3663) lr 1.9980e-03 eta 0:17:40
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,177
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 95.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      94.8%, epoch: 2 *******
******* Domain c best val test acc: 99.1%, epoch: 2 *******
******* Domain c best test acc:     99.2%, epoch: 3 *******
epoch [4/50] batch [20/167] time 0.078 (0.114) data 0.000 (0.015) loss 1.3028 (1.3934) teacher_loss 0.2336 (0.2978) loss_zs_kd 0.0194 (0.0190) loss_oracle 0.4060 (0.4941) kd_loss 0.8564 (0.8391) acc 90.6250 (87.8125) gate/entropy 1.0873 (1.0878) gate/usage_max 0.4053 (0.4034) gate/usage_min 0.2933 (0.2943) gate/usage_std 0.0510 (0.0497) teacher/entropy 0.1860 (0.1718) teacher/usage_max 0.5531 (0.6539) teacher/usage_min 0.1437 (0.1406) teacher/usage_std 0.1685 (0.2309) nleep/row_max_mean 1579.2693 (1575.5017) nleep/row_max_std 49.0325 (49.6130) nleep/row_min_mean 1565.9746 (1561.0845) lr 1.9921e-03 eta 0:14:52
epoch [4/50] batch [40/167] time 0.067 (0.115) data 0.000 (0.007) loss 1.5530 (1.3919) teacher_loss 0.4318 (0.2967) loss_zs_kd 0.0066 (0.0177) loss_oracle 0.5400 (0.4851) kd_loss 0.8478 (0.8438) acc 84.3750 (88.1250) gate/entropy 1.0859 (1.0872) gate/usage_max 0.4096 (0.4054) gate/usage_min 0.2912 (0.2933) gate/usage_std 0.0540 (0.0511) teacher/entropy 0.1497 (0.1669) teacher/usage_max 0.6724 (0.6480) teacher/usage_min 0.1117 (0.1381) teacher/usage_std 0.2435 (0.2273) nleep/row_max_mean 1581.9268 (1574.9256) nleep/row_max_std 45.3068 (48.5859) nleep/row_min_mean 1566.4370 (1560.5664) lr 1.9921e-03 eta 0:14:56
epoch [4/50] batch [60/167] time 0.076 (0.112) data 0.001 (0.005) loss 1.4557 (1.4071) teacher_loss 0.3296 (0.2984) loss_zs_kd 0.0266 (0.0184) loss_oracle 0.4957 (0.4949) kd_loss 0.8650 (0.8520) acc 87.5000 (88.3854) gate/entropy 1.0848 (1.0866) gate/usage_max 0.4129 (0.4072) gate/usage_min 0.2894 (0.2923) gate/usage_std 0.0564 (0.0524) teacher/entropy 0.0913 (0.1607) teacher/usage_max 0.7872 (0.6360) teacher/usage_min 0.0997 (0.1440) teacher/usage_std 0.3209 (0.2189) nleep/row_max_mean 1575.3883 (1573.8795) nleep/row_max_std 40.6018 (48.5059) nleep/row_min_mean 1558.0840 (1559.2380) lr 1.9921e-03 eta 0:14:34
epoch [4/50] batch [80/167] time 0.059 (0.110) data 0.000 (0.004) loss 1.3087 (1.4231) teacher_loss 0.1427 (0.3099) loss_zs_kd 0.0163 (0.0178) loss_oracle 0.6318 (0.5089) kd_loss 0.8419 (0.8499) acc 93.7500 (88.1641) gate/entropy 1.0835 (1.0860) gate/usage_max 0.4166 (0.4091) gate/usage_min 0.2876 (0.2914) gate/usage_std 0.0590 (0.0537) teacher/entropy 0.1904 (0.1586) teacher/usage_max 0.5555 (0.6438) teacher/usage_min 0.2157 (0.1392) teacher/usage_std 0.1572 (0.2242) nleep/row_max_mean 1583.0895 (1573.9234) nleep/row_max_std 46.1932 (48.9841) nleep/row_min_mean 1566.8003 (1558.8013) lr 1.9921e-03 eta 0:14:16
epoch [4/50] batch [100/167] time 0.057 (0.108) data 0.000 (0.003) loss 1.3466 (1.4341) teacher_loss 0.1656 (0.3107) loss_zs_kd 0.0173 (0.0175) loss_oracle 0.5590 (0.5250) kd_loss 0.8928 (0.8522) acc 93.7500 (88.3438) gate/entropy 1.0818 (1.0853) gate/usage_max 0.4211 (0.4111) gate/usage_min 0.2851 (0.2904) gate/usage_std 0.0622 (0.0551) teacher/entropy 0.0947 (0.1531) teacher/usage_max 0.6728 (0.6474) teacher/usage_min 0.1261 (0.1371) teacher/usage_std 0.2420 (0.2265) nleep/row_max_mean 1574.0028 (1573.8835) nleep/row_max_std 58.5284 (49.4907) nleep/row_min_mean 1556.0991 (1558.3144) lr 1.9921e-03 eta 0:13:57
epoch [4/50] batch [120/167] time 0.188 (0.111) data 0.000 (0.003) loss 1.5456 (1.4386) teacher_loss 0.3109 (0.3122) loss_zs_kd 0.0199 (0.0176) loss_oracle 0.6366 (0.5371) kd_loss 0.9064 (0.8491) acc 90.6250 (88.2812) gate/entropy 1.0803 (1.0846) gate/usage_max 0.4252 (0.4132) gate/usage_min 0.2827 (0.2892) gate/usage_std 0.0651 (0.0566) teacher/entropy 0.1147 (0.1504) teacher/usage_max 0.5660 (0.6569) teacher/usage_min 0.1454 (0.1347) teacher/usage_std 0.1746 (0.2327) nleep/row_max_mean 1569.7646 (1574.7966) nleep/row_max_std 49.6227 (49.7561) nleep/row_min_mean 1552.7208 (1558.8911) lr 1.9921e-03 eta 0:14:17
epoch [4/50] batch [140/167] time 0.150 (0.112) data 0.000 (0.002) loss 1.5634 (1.4375) teacher_loss 0.4231 (0.3107) loss_zs_kd 0.0151 (0.0175) loss_oracle 0.5316 (0.5423) kd_loss 0.8669 (0.8469) acc 81.2500 (88.3929) gate/entropy 1.0783 (1.0838) gate/usage_max 0.4300 (0.4153) gate/usage_min 0.2797 (0.2881) gate/usage_std 0.0685 (0.0581) teacher/entropy 0.1173 (0.1492) teacher/usage_max 0.6575 (0.6602) teacher/usage_min 0.1440 (0.1323) teacher/usage_std 0.2303 (0.2350) nleep/row_max_mean 1565.6809 (1574.3539) nleep/row_max_std 53.3982 (50.3755) nleep/row_min_mean 1547.3557 (1558.2687) lr 1.9921e-03 eta 0:14:24
epoch [4/50] batch [160/167] time 0.125 (0.116) data 0.000 (0.002) loss 1.3445 (1.4326) teacher_loss 0.3116 (0.3077) loss_zs_kd 0.0191 (0.0170) loss_oracle 0.5620 (0.5435) kd_loss 0.7423 (0.8447) acc 87.5000 (88.4180) gate/entropy 1.0768 (1.0830) gate/usage_max 0.4335 (0.4174) gate/usage_min 0.2773 (0.2868) gate/usage_std 0.0710 (0.0595) teacher/entropy 0.2312 (0.1496) teacher/usage_max 0.6681 (0.6595) teacher/usage_min 0.1207 (0.1306) teacher/usage_std 0.2396 (0.2350) nleep/row_max_mean 1570.3116 (1574.1201) nleep/row_max_std 56.7803 (50.4598) nleep/row_min_mean 1555.0435 (1557.9367) lr 1.9921e-03 eta 0:14:54
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,191
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 95.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      95.4%, epoch: 4 *******
******* Domain c best val test acc: 99.1%, epoch: 4 *******
******* Domain c best test acc:     99.2%, epoch: 3 *******
epoch [5/50] batch [20/167] time 0.149 (0.167) data 0.000 (0.017) loss 1.1664 (1.4035) teacher_loss 0.1674 (0.3182) loss_zs_kd 0.0106 (0.0154) loss_oracle 0.4705 (0.5291) kd_loss 0.7585 (0.8131) acc 93.7500 (89.2188) gate/entropy 1.0749 (1.0755) gate/usage_max 0.4377 (0.4364) gate/usage_min 0.2739 (0.2750) gate/usage_std 0.0740 (0.0731) teacher/entropy 0.2271 (0.1558) teacher/usage_max 0.6324 (0.6711) teacher/usage_min 0.1583 (0.1093) teacher/usage_std 0.2125 (0.2456) nleep/row_max_mean 1559.9703 (1565.8021) nleep/row_max_std 50.7130 (51.3277) nleep/row_min_mean 1546.6172 (1550.0686) lr 1.9823e-03 eta 0:21:20
epoch [5/50] batch [40/167] time 0.128 (0.153) data 0.000 (0.009) loss 1.5244 (1.4180) teacher_loss 0.3952 (0.3186) loss_zs_kd 0.0265 (0.0162) loss_oracle 0.4704 (0.5312) kd_loss 0.8808 (0.8257) acc 84.3750 (88.6719) gate/entropy 1.0729 (1.0746) gate/usage_max 0.4420 (0.4383) gate/usage_min 0.2712 (0.2737) gate/usage_std 0.0771 (0.0745) teacher/entropy 0.1114 (0.1443) teacher/usage_max 0.6077 (0.6632) teacher/usage_min 0.1529 (0.1052) teacher/usage_std 0.1972 (0.2424) nleep/row_max_mean 1565.6526 (1566.5189) nleep/row_max_std 45.6019 (48.4631) nleep/row_min_mean 1549.1816 (1550.1732) lr 1.9823e-03 eta 0:19:26
epoch [5/50] batch [60/167] time 0.099 (0.142) data 0.000 (0.006) loss 1.5864 (1.4149) teacher_loss 0.4025 (0.3092) loss_zs_kd 0.0182 (0.0174) loss_oracle 0.6309 (0.5399) kd_loss 0.8594 (0.8270) acc 81.2500 (88.3333) gate/entropy 1.0714 (1.0738) gate/usage_max 0.4452 (0.4401) gate/usage_min 0.2688 (0.2725) gate/usage_std 0.0794 (0.0757) teacher/entropy 0.0978 (0.1454) teacher/usage_max 0.6761 (0.6548) teacher/usage_min 0.1110 (0.1125) teacher/usage_std 0.2459 (0.2356) nleep/row_max_mean 1561.3137 (1566.4681) nleep/row_max_std 51.0166 (49.6231) nleep/row_min_mean 1541.4841 (1549.9824) lr 1.9823e-03 eta 0:17:59
epoch [5/50] batch [80/167] time 0.081 (0.132) data 0.000 (0.004) loss 1.3940 (1.3966) teacher_loss 0.2315 (0.2895) loss_zs_kd 0.0132 (0.0171) loss_oracle 0.5947 (0.5339) kd_loss 0.8585 (0.8316) acc 90.6250 (89.1797) gate/entropy 1.0701 (1.0731) gate/usage_max 0.4479 (0.4417) gate/usage_min 0.2671 (0.2713) gate/usage_std 0.0813 (0.0769) teacher/entropy 0.1500 (0.1465) teacher/usage_max 0.5733 (0.6409) teacher/usage_min 0.1986 (0.1262) teacher/usage_std 0.1701 (0.2248) nleep/row_max_mean 1572.1121 (1566.6688) nleep/row_max_std 44.4256 (49.7981) nleep/row_min_mean 1553.6189 (1550.3003) lr 1.9823e-03 eta 0:16:44
epoch [5/50] batch [100/167] time 0.098 (0.126) data 0.000 (0.004) loss 1.4319 (1.3984) teacher_loss 0.3732 (0.2852) loss_zs_kd 0.0172 (0.0175) loss_oracle 0.4753 (0.5362) kd_loss 0.8125 (0.8364) acc 87.5000 (89.3125) gate/entropy 1.0692 (1.0724) gate/usage_max 0.4497 (0.4431) gate/usage_min 0.2662 (0.2704) gate/usage_std 0.0826 (0.0779) teacher/entropy 0.2016 (0.1488) teacher/usage_max 0.5695 (0.6249) teacher/usage_min 0.1270 (0.1340) teacher/usage_std 0.1819 (0.2139) nleep/row_max_mean 1546.5186 (1566.9015) nleep/row_max_std 53.0933 (49.5307) nleep/row_min_mean 1531.7565 (1550.4245) lr 1.9823e-03 eta 0:15:57
epoch [5/50] batch [120/167] time 0.176 (0.126) data 0.000 (0.003) loss 1.4208 (1.4132) teacher_loss 0.1675 (0.2870) loss_zs_kd 0.0261 (0.0187) loss_oracle 0.6041 (0.5431) kd_loss 0.9381 (0.8452) acc 93.7500 (89.3490) gate/entropy 1.0685 (1.0717) gate/usage_max 0.4511 (0.4445) gate/usage_min 0.2654 (0.2695) gate/usage_std 0.0836 (0.0789) teacher/entropy 0.1154 (0.1465) teacher/usage_max 0.4726 (0.6109) teacher/usage_min 0.2308 (0.1429) teacher/usage_std 0.1021 (0.2039) nleep/row_max_mean 1554.6211 (1567.2170) nleep/row_max_std 50.1413 (49.0524) nleep/row_min_mean 1535.4874 (1550.4639) lr 1.9823e-03 eta 0:15:49
epoch [5/50] batch [140/167] time 0.097 (0.123) data 0.000 (0.003) loss 1.5259 (1.4193) teacher_loss 0.2545 (0.2903) loss_zs_kd 0.0353 (0.0191) loss_oracle 0.6118 (0.5491) kd_loss 0.9478 (0.8448) acc 90.6250 (89.2188) gate/entropy 1.0668 (1.0711) gate/usage_max 0.4544 (0.4457) gate/usage_min 0.2639 (0.2688) gate/usage_std 0.0859 (0.0798) teacher/entropy 0.1234 (0.1483) teacher/usage_max 0.4418 (0.6068) teacher/usage_min 0.2726 (0.1470) teacher/usage_std 0.0769 (0.2007) nleep/row_max_mean 1570.6737 (1567.3010) nleep/row_max_std 41.2444 (49.4939) nleep/row_min_mean 1552.1365 (1550.3985) lr 1.9823e-03 eta 0:15:26
epoch [5/50] batch [160/167] time 0.073 (0.123) data 0.000 (0.002) loss 1.5301 (1.4266) teacher_loss 0.4106 (0.2898) loss_zs_kd 0.0181 (0.0199) loss_oracle 0.5303 (0.5502) kd_loss 0.8453 (0.8518) acc 87.5000 (89.3945) gate/entropy 1.0656 (1.0705) gate/usage_max 0.4568 (0.4469) gate/usage_min 0.2630 (0.2681) gate/usage_std 0.0876 (0.0806) teacher/entropy 0.1394 (0.1478) teacher/usage_max 0.6219 (0.5940) teacher/usage_min 0.0961 (0.1503) teacher/usage_std 0.2177 (0.1932) nleep/row_max_mean 1570.7347 (1566.5738) nleep/row_max_std 48.2433 (49.6461) nleep/row_min_mean 1553.1223 (1549.5520) lr 1.9823e-03 eta 0:15:26
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,190
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.0%
******* Domain c best val acc:      95.4%, epoch: 4 *******
******* Domain c best val test acc: 99.1%, epoch: 4 *******
******* Domain c best test acc:     99.2%, epoch: 3 *******
epoch [6/50] batch [20/167] time 0.081 (0.129) data 0.000 (0.014) loss 1.5917 (1.5157) teacher_loss 0.3115 (0.2933) loss_zs_kd 0.0133 (0.0230) loss_oracle 0.6382 (0.5657) kd_loss 0.9545 (0.9280) acc 84.3750 (88.7500) gate/entropy 1.0654 (1.0651) gate/usage_max 0.4573 (0.4578) gate/usage_min 0.2637 (0.2630) gate/usage_std 0.0879 (0.0883) teacher/entropy 0.1708 (0.1324) teacher/usage_max 0.4193 (0.4932) teacher/usage_min 0.2323 (0.1543) teacher/usage_std 0.0771 (0.1426) nleep/row_max_mean 1551.5680 (1568.1576) nleep/row_max_std 49.8382 (51.5623) nleep/row_min_mean 1534.0481 (1549.0324) lr 1.9686e-03 eta 0:16:09
epoch [6/50] batch [40/167] time 0.091 (0.124) data 0.000 (0.007) loss 1.4247 (1.5275) teacher_loss 0.1965 (0.3047) loss_zs_kd 0.0238 (0.0245) loss_oracle 0.5331 (0.5729) kd_loss 0.9497 (0.9241) acc 96.8750 (88.2812) gate/entropy 1.0638 (1.0648) gate/usage_max 0.4605 (0.4586) gate/usage_min 0.2630 (0.2631) gate/usage_std 0.0901 (0.0888) teacher/entropy 0.0709 (0.1315) teacher/usage_max 0.5481 (0.4962) teacher/usage_min 0.1255 (0.1394) teacher/usage_std 0.1726 (0.1518) nleep/row_max_mean 1577.1274 (1568.2034) nleep/row_max_std 49.1290 (53.3485) nleep/row_min_mean 1552.5669 (1548.4513) lr 1.9686e-03 eta 0:15:29
epoch [6/50] batch [60/167] time 0.151 (0.130) data 0.001 (0.005) loss 1.5710 (1.5133) teacher_loss 0.3280 (0.3011) loss_zs_kd 0.0167 (0.0230) loss_oracle 0.4709 (0.5634) kd_loss 0.9992 (0.9190) acc 93.7500 (88.8542) gate/entropy 1.0634 (1.0644) gate/usage_max 0.4614 (0.4593) gate/usage_min 0.2635 (0.2632) gate/usage_std 0.0907 (0.0893) teacher/entropy 0.1376 (0.1330) teacher/usage_max 0.5335 (0.5052) teacher/usage_min 0.1300 (0.1402) teacher/usage_std 0.1647 (0.1557) nleep/row_max_mean 1565.8789 (1567.7857) nleep/row_max_std 50.3936 (53.9797) nleep/row_min_mean 1547.4816 (1547.7226) lr 1.9686e-03 eta 0:16:12
epoch [6/50] batch [80/167] time 0.154 (0.133) data 0.000 (0.004) loss 1.6194 (1.4906) teacher_loss 0.4079 (0.2908) loss_zs_kd 0.0227 (0.0228) loss_oracle 0.4962 (0.5659) kd_loss 0.9520 (0.9055) acc 87.5000 (89.3359) gate/entropy 1.0618 (1.0639) gate/usage_max 0.4643 (0.4602) gate/usage_min 0.2629 (0.2632) gate/usage_std 0.0927 (0.0899) teacher/entropy 0.0881 (0.1303) teacher/usage_max 0.5077 (0.5293) teacher/usage_min 0.1165 (0.1356) teacher/usage_std 0.1625 (0.1677) nleep/row_max_mean 1564.4922 (1568.0182) nleep/row_max_std 51.2097 (54.0135) nleep/row_min_mean 1545.0574 (1547.9593) lr 1.9686e-03 eta 0:16:29
epoch [6/50] batch [100/167] time 0.120 (0.132) data 0.000 (0.003) loss 1.4778 (1.4903) teacher_loss 0.2820 (0.2928) loss_zs_kd 0.0206 (0.0220) loss_oracle 0.5874 (0.5684) kd_loss 0.8919 (0.9022) acc 93.7500 (89.3438) gate/entropy 1.0606 (1.0634) gate/usage_max 0.4666 (0.4613) gate/usage_min 0.2623 (0.2631) gate/usage_std 0.0943 (0.0906) teacher/entropy 0.1208 (0.1245) teacher/usage_max 0.5506 (0.5428) teacher/usage_min 0.1687 (0.1343) teacher/usage_std 0.1603 (0.1741) nleep/row_max_mean 1564.3191 (1567.6241) nleep/row_max_std 41.8698 (52.8518) nleep/row_min_mean 1543.7017 (1547.3884) lr 1.9686e-03 eta 0:16:17
epoch [6/50] batch [120/167] time 0.128 (0.132) data 0.000 (0.002) loss 1.3188 (1.4874) teacher_loss 0.2138 (0.2913) loss_zs_kd 0.0163 (0.0220) loss_oracle 0.6075 (0.5704) kd_loss 0.7932 (0.8999) acc 90.6250 (89.2188) gate/entropy 1.0592 (1.0628) gate/usage_max 0.4690 (0.4624) gate/usage_min 0.2618 (0.2629) gate/usage_std 0.0960 (0.0914) teacher/entropy 0.1327 (0.1200) teacher/usage_max 0.7000 (0.5515) teacher/usage_min 0.1129 (0.1354) teacher/usage_std 0.2610 (0.1780) nleep/row_max_mean 1551.2925 (1567.2392) nleep/row_max_std 64.6164 (51.8238) nleep/row_min_mean 1530.0195 (1546.8389) lr 1.9686e-03 eta 0:16:17
epoch [6/50] batch [140/167] time 0.110 (0.133) data 0.000 (0.002) loss 1.6761 (1.4848) teacher_loss 0.4799 (0.2919) loss_zs_kd 0.0325 (0.0220) loss_oracle 0.5691 (0.5725) kd_loss 0.8953 (0.8956) acc 78.1250 (89.2188) gate/entropy 1.0569 (1.0621) gate/usage_max 0.4730 (0.4637) gate/usage_min 0.2601 (0.2626) gate/usage_std 0.0988 (0.0923) teacher/entropy 0.0832 (0.1165) teacher/usage_max 0.6049 (0.5632) teacher/usage_min 0.1069 (0.1337) teacher/usage_std 0.2058 (0.1842) nleep/row_max_mean 1570.0295 (1566.7884) nleep/row_max_std 46.6688 (51.3873) nleep/row_min_mean 1548.3074 (1546.2888) lr 1.9686e-03 eta 0:16:20
epoch [6/50] batch [160/167] time 0.148 (0.134) data 0.000 (0.002) loss 1.3723 (1.4803) teacher_loss 0.1477 (0.2890) loss_zs_kd 0.0331 (0.0222) loss_oracle 0.6054 (0.5743) kd_loss 0.9054 (0.8931) acc 96.8750 (89.4336) gate/entropy 1.0553 (1.0613) gate/usage_max 0.4758 (0.4650) gate/usage_min 0.2591 (0.2622) gate/usage_std 0.1008 (0.0932) teacher/entropy 0.0812 (0.1122) teacher/usage_max 0.5877 (0.5725) teacher/usage_min 0.1277 (0.1330) teacher/usage_std 0.1909 (0.1889) nleep/row_max_mean 1567.1121 (1566.7917) nleep/row_max_std 51.2412 (51.1609) nleep/row_min_mean 1543.1304 (1546.0478) lr 1.9686e-03 eta 0:16:28
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,194
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      95.5%, epoch: 6 *******
******* Domain c best val test acc: 99.1%, epoch: 6 *******
******* Domain c best test acc:     99.2%, epoch: 3 *******
epoch [7/50] batch [20/167] time 0.077 (0.133) data 0.000 (0.016) loss 1.3914 (1.4339) teacher_loss 0.2233 (0.2773) loss_zs_kd 0.0224 (0.0221) loss_oracle 0.5244 (0.5583) kd_loss 0.8946 (0.8663) acc 93.7500 (88.4375) gate/entropy 1.0529 (1.0537) gate/usage_max 0.4797 (0.4785) gate/usage_min 0.2578 (0.2581) gate/usage_std 0.1035 (0.1027) teacher/entropy 0.0832 (0.0963) teacher/usage_max 0.5991 (0.6260) teacher/usage_min 0.1505 (0.1218) teacher/usage_std 0.1923 (0.2186) nleep/row_max_mean 1568.5127 (1565.6346) nleep/row_max_std 54.3093 (53.4184) nleep/row_min_mean 1548.0674 (1544.1353) lr 1.9511e-03 eta 0:16:15
epoch [7/50] batch [40/167] time 0.188 (0.118) data 0.000 (0.008) loss 1.4695 (1.4227) teacher_loss 0.3647 (0.2745) loss_zs_kd 0.0219 (0.0196) loss_oracle 0.6043 (0.5655) kd_loss 0.7918 (0.8557) acc 87.5000 (89.1406) gate/entropy 1.0507 (1.0528) gate/usage_max 0.4833 (0.4798) gate/usage_min 0.2562 (0.2576) gate/usage_std 0.1060 (0.1036) teacher/entropy 0.0666 (0.0856) teacher/usage_max 0.7874 (0.6592) teacher/usage_min 0.0665 (0.1167) teacher/usage_std 0.3227 (0.2382) nleep/row_max_mean 1558.2809 (1562.5871) nleep/row_max_std 57.6224 (55.1887) nleep/row_min_mean 1533.9546 (1540.4007) lr 1.9511e-03 eta 0:14:22
epoch [7/50] batch [60/167] time 0.074 (0.114) data 0.001 (0.005) loss 1.6620 (1.4560) teacher_loss 0.4718 (0.2996) loss_zs_kd 0.0227 (0.0198) loss_oracle 0.6161 (0.5727) kd_loss 0.8708 (0.8601) acc 81.2500 (88.1771) gate/entropy 1.0492 (1.0519) gate/usage_max 0.4857 (0.4814) gate/usage_min 0.2553 (0.2570) gate/usage_std 0.1078 (0.1047) teacher/entropy 0.0617 (0.0868) teacher/usage_max 0.6669 (0.6485) teacher/usage_min 0.1568 (0.1198) teacher/usage_std 0.2360 (0.2322) nleep/row_max_mean 1568.5505 (1561.8863) nleep/row_max_std 56.2361 (53.7453) nleep/row_min_mean 1541.4280 (1539.5266) lr 1.9511e-03 eta 0:13:52
epoch [7/50] batch [80/167] time 0.068 (0.114) data 0.000 (0.004) loss 1.4787 (1.4497) teacher_loss 0.2928 (0.2965) loss_zs_kd 0.0240 (0.0193) loss_oracle 0.5701 (0.5749) kd_loss 0.8888 (0.8560) acc 90.6250 (88.3203) gate/entropy 1.0469 (1.0510) gate/usage_max 0.4893 (0.4829) gate/usage_min 0.2537 (0.2564) gate/usage_std 0.1103 (0.1057) teacher/entropy 0.0961 (0.0821) teacher/usage_max 0.5796 (0.6603) teacher/usage_min 0.1926 (0.1190) teacher/usage_std 0.1748 (0.2396) nleep/row_max_mean 1571.6411 (1562.7652) nleep/row_max_std 52.3374 (52.9619) nleep/row_min_mean 1548.3110 (1540.0600) lr 1.9511e-03 eta 0:13:48
epoch [7/50] batch [100/167] time 0.172 (0.112) data 0.000 (0.003) loss 1.6212 (1.4489) teacher_loss 0.4254 (0.2922) loss_zs_kd 0.0240 (0.0202) loss_oracle 0.6695 (0.5807) kd_loss 0.8491 (0.8562) acc 84.3750 (88.6562) gate/entropy 1.0456 (1.0500) gate/usage_max 0.4913 (0.4843) gate/usage_min 0.2530 (0.2558) gate/usage_std 0.1117 (0.1068) teacher/entropy 0.0861 (0.0807) teacher/usage_max 0.6517 (0.6606) teacher/usage_min 0.1618 (0.1192) teacher/usage_std 0.2253 (0.2391) nleep/row_max_mean 1572.1426 (1562.8923) nleep/row_max_std 60.5153 (53.0389) nleep/row_min_mean 1544.9728 (1539.9771) lr 1.9511e-03 eta 0:13:33
epoch [7/50] batch [120/167] time 0.088 (0.111) data 0.000 (0.003) loss 1.2425 (1.4466) teacher_loss 0.0917 (0.2900) loss_zs_kd 0.0028 (0.0214) loss_oracle 0.5663 (0.5872) kd_loss 0.8662 (0.8524) acc 100.0000 (88.8281) gate/entropy 1.0439 (1.0491) gate/usage_max 0.4938 (0.4858) gate/usage_min 0.2518 (0.2552) gate/usage_std 0.1135 (0.1078) teacher/entropy 0.1391 (0.0787) teacher/usage_max 0.5479 (0.6677) teacher/usage_min 0.1429 (0.1172) teacher/usage_std 0.1662 (0.2435) nleep/row_max_mean 1562.9382 (1563.8883) nleep/row_max_std 45.6180 (53.6281) nleep/row_min_mean 1542.4026 (1540.5287) lr 1.9511e-03 eta 0:13:19
epoch [7/50] batch [140/167] time 0.093 (0.112) data 0.000 (0.002) loss 1.2972 (1.4527) teacher_loss 0.2328 (0.2938) loss_zs_kd 0.0228 (0.0219) loss_oracle 0.5284 (0.5923) kd_loss 0.7888 (0.8518) acc 93.7500 (88.7277) gate/entropy 1.0417 (1.0481) gate/usage_max 0.4970 (0.4873) gate/usage_min 0.2501 (0.2545) gate/usage_std 0.1158 (0.1089) teacher/entropy 0.0521 (0.0763) teacher/usage_max 0.7903 (0.6706) teacher/usage_min 0.0603 (0.1181) teacher/usage_std 0.3252 (0.2449) nleep/row_max_mean 1547.9675 (1563.6852) nleep/row_max_std 61.3115 (53.6670) nleep/row_min_mean 1524.0845 (1540.0977) lr 1.9511e-03 eta 0:13:28
epoch [7/50] batch [160/167] time 0.177 (0.114) data 0.000 (0.002) loss 1.3964 (1.4533) teacher_loss 0.2467 (0.2933) loss_zs_kd 0.0293 (0.0218) loss_oracle 0.5520 (0.5876) kd_loss 0.8591 (0.8553) acc 84.3750 (88.6523) gate/entropy 1.0395 (1.0472) gate/usage_max 0.5002 (0.4887) gate/usage_min 0.2484 (0.2539) gate/usage_std 0.1180 (0.1099) teacher/entropy 0.1009 (0.0753) teacher/usage_max 0.6092 (0.6653) teacher/usage_min 0.1626 (0.1209) teacher/usage_std 0.1969 (0.2409) nleep/row_max_mean 1572.3188 (1563.5885) nleep/row_max_std 41.0685 (53.3451) nleep/row_min_mean 1546.9482 (1539.9818) lr 1.9511e-03 eta 0:13:39
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,209
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.6%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.2%, epoch: 7 *******
******* Domain c best val test acc: 99.1%, epoch: 7 *******
******* Domain c best test acc:     99.2%, epoch: 3 *******
epoch [8/50] batch [20/167] time 0.149 (0.171) data 0.000 (0.014) loss 1.4819 (1.4264) teacher_loss 0.2820 (0.2613) loss_zs_kd 0.0233 (0.0212) loss_oracle 0.5172 (0.5652) kd_loss 0.9297 (0.8720) acc 90.6250 (89.8438) gate/entropy 1.0387 (1.0385) gate/usage_max 0.5015 (0.5017) gate/usage_min 0.2473 (0.2473) gate/usage_std 0.1189 (0.1191) teacher/entropy 0.0608 (0.0713) teacher/usage_max 0.5651 (0.6324) teacher/usage_min 0.2010 (0.1335) teacher/usage_std 0.1644 (0.2187) nleep/row_max_mean 1541.7976 (1561.4334) nleep/row_max_std 63.6866 (55.3105) nleep/row_min_mean 1519.9930 (1537.4714) lr 1.9298e-03 eta 0:20:22
epoch [8/50] batch [40/167] time 0.147 (0.158) data 0.000 (0.007) loss 1.3233 (1.4674) teacher_loss 0.2173 (0.3013) loss_zs_kd 0.0171 (0.0218) loss_oracle 0.5316 (0.5735) kd_loss 0.8316 (0.8685) acc 93.7500 (88.2031) gate/entropy 1.0360 (1.0376) gate/usage_max 0.5052 (0.5030) gate/usage_min 0.2451 (0.2465) gate/usage_std 0.1215 (0.1200) teacher/entropy 0.0464 (0.0618) teacher/usage_max 0.7205 (0.6494) teacher/usage_min 0.0388 (0.1132) teacher/usage_std 0.2859 (0.2330) nleep/row_max_mean 1571.6887 (1563.5728) nleep/row_max_std 59.1426 (55.1377) nleep/row_min_mean 1546.2854 (1539.0153) lr 1.9298e-03 eta 0:18:51
epoch [8/50] batch [60/167] time 0.152 (0.155) data 0.001 (0.005) loss 1.6402 (1.4819) teacher_loss 0.4198 (0.3096) loss_zs_kd 0.0131 (0.0212) loss_oracle 0.6466 (0.5771) kd_loss 0.8906 (0.8732) acc 84.3750 (87.8646) gate/entropy 1.0345 (1.0368) gate/usage_max 0.5073 (0.5041) gate/usage_min 0.2433 (0.2457) gate/usage_std 0.1230 (0.1207) teacher/entropy 0.0337 (0.0604) teacher/usage_max 0.6528 (0.6435) teacher/usage_min 0.0592 (0.1078) teacher/usage_std 0.2445 (0.2322) nleep/row_max_mean 1570.8514 (1563.8257) nleep/row_max_std 48.7392 (54.0247) nleep/row_min_mean 1545.2756 (1539.1913) lr 1.9298e-03 eta 0:18:24
epoch [8/50] batch [80/167] time 0.165 (0.155) data 0.000 (0.004) loss 1.4831 (1.4833) teacher_loss 0.2056 (0.3037) loss_zs_kd 0.0220 (0.0213) loss_oracle 0.6336 (0.5830) kd_loss 0.9496 (0.8774) acc 96.8750 (87.8516) gate/entropy 1.0333 (1.0361) gate/usage_max 0.5089 (0.5050) gate/usage_min 0.2416 (0.2449) gate/usage_std 0.1242 (0.1214) teacher/entropy 0.0552 (0.0554) teacher/usage_max 0.5362 (0.6430) teacher/usage_min 0.0586 (0.0934) teacher/usage_std 0.2015 (0.2364) nleep/row_max_mean 1550.9590 (1563.5116) nleep/row_max_std 50.9074 (53.6747) nleep/row_min_mean 1528.2568 (1538.7191) lr 1.9298e-03 eta 0:18:23
epoch [8/50] batch [100/167] time 0.136 (0.142) data 0.000 (0.003) loss 1.4997 (1.4761) teacher_loss 0.3320 (0.3007) loss_zs_kd 0.0303 (0.0220) loss_oracle 0.5393 (0.5837) kd_loss 0.8829 (0.8726) acc 87.5000 (87.8750) gate/entropy 1.0323 (1.0354) gate/usage_max 0.5102 (0.5060) gate/usage_min 0.2400 (0.2440) gate/usage_std 0.1252 (0.1221) teacher/entropy 0.0668 (0.0521) teacher/usage_max 0.6100 (0.6528) teacher/usage_min 0.0081 (0.0794) teacher/usage_std 0.2481 (0.2457) nleep/row_max_mean 1548.2982 (1562.9193) nleep/row_max_std 58.0119 (53.6907) nleep/row_min_mean 1524.3953 (1537.8831) lr 1.9298e-03 eta 0:16:47
epoch [8/50] batch [120/167] time 0.134 (0.138) data 0.000 (0.003) loss 1.5486 (1.4704) teacher_loss 0.3098 (0.3055) loss_zs_kd 0.0190 (0.0220) loss_oracle 0.5035 (0.5768) kd_loss 0.9775 (0.8655) acc 90.6250 (87.8125) gate/entropy 1.0302 (1.0347) gate/usage_max 0.5130 (0.5070) gate/usage_min 0.2380 (0.2432) gate/usage_std 0.1271 (0.1228) teacher/entropy 0.0857 (0.0511) teacher/usage_max 0.4794 (0.6626) teacher/usage_min 0.0670 (0.0704) teacher/usage_std 0.1886 (0.2528) nleep/row_max_mean 1552.4410 (1561.8289) nleep/row_max_std 46.7861 (53.7264) nleep/row_min_mean 1532.8719 (1536.7652) lr 1.9298e-03 eta 0:16:16
epoch [8/50] batch [140/167] time 0.163 (0.135) data 0.000 (0.002) loss 1.1900 (1.4549) teacher_loss 0.0804 (0.2974) loss_zs_kd 0.0187 (0.0213) loss_oracle 0.5292 (0.5697) kd_loss 0.8356 (0.8621) acc 96.8750 (88.1473) gate/entropy 1.0290 (1.0339) gate/usage_max 0.5146 (0.5080) gate/usage_min 0.2365 (0.2423) gate/usage_std 0.1283 (0.1236) teacher/entropy 0.0769 (0.0505) teacher/usage_max 0.6557 (0.6667) teacher/usage_min 0.0259 (0.0654) teacher/usage_std 0.2573 (0.2558) nleep/row_max_mean 1555.7698 (1561.2855) nleep/row_max_std 54.9771 (53.3952) nleep/row_min_mean 1531.1685 (1536.3659) lr 1.9298e-03 eta 0:15:52
epoch [8/50] batch [160/167] time 0.078 (0.131) data 0.000 (0.002) loss 1.2659 (1.4459) teacher_loss 0.1493 (0.2950) loss_zs_kd 0.0120 (0.0219) loss_oracle 0.5171 (0.5684) kd_loss 0.8520 (0.8557) acc 96.8750 (88.3203) gate/entropy 1.0263 (1.0331) gate/usage_max 0.5181 (0.5091) gate/usage_min 0.2344 (0.2414) gate/usage_std 0.1308 (0.1243) teacher/entropy 0.0562 (0.0495) teacher/usage_max 0.6615 (0.6752) teacher/usage_min 0.0647 (0.0615) teacher/usage_std 0.2472 (0.2611) nleep/row_max_mean 1572.3557 (1561.8821) nleep/row_max_std 40.6835 (53.1886) nleep/row_min_mean 1546.0118 (1536.8426) lr 1.9298e-03 eta 0:15:20
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,198
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.2%, epoch: 7 *******
******* Domain c best val test acc: 99.1%, epoch: 7 *******
******* Domain c best test acc:     99.2%, epoch: 3 *******
epoch [9/50] batch [20/167] time 0.158 (0.134) data 0.000 (0.015) loss 1.1361 (1.3794) teacher_loss 0.1321 (0.2805) loss_zs_kd 0.0186 (0.0242) loss_oracle 0.5146 (0.5301) kd_loss 0.7374 (0.8217) acc 96.8750 (89.6875) gate/entropy 1.0249 (1.0254) gate/usage_max 0.5200 (0.5193) gate/usage_min 0.2330 (0.2335) gate/usage_std 0.1321 (0.1316) teacher/entropy 0.0585 (0.0473) teacher/usage_max 0.8068 (0.7117) teacher/usage_min 0.0165 (0.0467) teacher/usage_std 0.3411 (0.2826) nleep/row_max_mean 1555.8059 (1562.6404) nleep/row_max_std 62.6567 (52.4166) nleep/row_min_mean 1530.4337 (1536.3110) lr 1.9048e-03 eta 0:15:34
epoch [9/50] batch [40/167] time 0.094 (0.119) data 0.000 (0.008) loss 1.2202 (1.3943) teacher_loss 0.1032 (0.2959) loss_zs_kd 0.0149 (0.0247) loss_oracle 0.5661 (0.5319) kd_loss 0.8264 (0.8202) acc 96.8750 (89.3750) gate/entropy 1.0235 (1.0246) gate/usage_max 0.5217 (0.5203) gate/usage_min 0.2319 (0.2329) gate/usage_std 0.1333 (0.1324) teacher/entropy 0.0098 (0.0425) teacher/usage_max 0.7490 (0.7186) teacher/usage_min 0.0016 (0.0387) teacher/usage_std 0.3109 (0.2897) nleep/row_max_mean 1568.7834 (1563.8154) nleep/row_max_std 60.6227 (53.8642) nleep/row_min_mean 1538.5741 (1536.6937) lr 1.9048e-03 eta 0:13:47
epoch [9/50] batch [60/167] time 0.182 (0.120) data 0.001 (0.005) loss 1.4132 (1.3774) teacher_loss 0.2541 (0.2911) loss_zs_kd 0.0167 (0.0229) loss_oracle 0.5601 (0.5325) kd_loss 0.8708 (0.8086) acc 90.6250 (88.8542) gate/entropy 1.0209 (1.0238) gate/usage_max 0.5250 (0.5213) gate/usage_min 0.2301 (0.2322) gate/usage_std 0.1357 (0.1331) teacher/entropy 0.0251 (0.0436) teacher/usage_max 0.6664 (0.7313) teacher/usage_min 0.0005 (0.0360) teacher/usage_std 0.2719 (0.2973) nleep/row_max_mean 1568.8088 (1562.8916) nleep/row_max_std 45.4567 (54.5870) nleep/row_min_mean 1540.8555 (1535.4692) lr 1.9048e-03 eta 0:13:52
epoch [9/50] batch [80/167] time 0.128 (0.120) data 0.000 (0.004) loss 1.3730 (1.3673) teacher_loss 0.3042 (0.2827) loss_zs_kd 0.0076 (0.0209) loss_oracle 0.5149 (0.5357) kd_loss 0.8076 (0.8064) acc 87.5000 (89.1016) gate/entropy 1.0198 (1.0230) gate/usage_max 0.5264 (0.5223) gate/usage_min 0.2293 (0.2317) gate/usage_std 0.1366 (0.1338) teacher/entropy 0.0012 (0.0430) teacher/usage_max 0.7812 (0.7337) teacher/usage_min 0.0002 (0.0336) teacher/usage_std 0.3290 (0.2985) nleep/row_max_mean 1574.0542 (1562.6350) nleep/row_max_std 67.8988 (54.7543) nleep/row_min_mean 1544.2722 (1535.2358) lr 1.9048e-03 eta 0:13:55
epoch [9/50] batch [100/167] time 0.127 (0.125) data 0.000 (0.003) loss 1.4372 (1.3839) teacher_loss 0.3577 (0.2990) loss_zs_kd 0.0236 (0.0207) loss_oracle 0.5614 (0.5393) kd_loss 0.7870 (0.8050) acc 87.5000 (88.3750) gate/entropy 1.0187 (1.0222) gate/usage_max 0.5277 (0.5233) gate/usage_min 0.2283 (0.2311) gate/usage_std 0.1376 (0.1345) teacher/entropy 0.0587 (0.0436) teacher/usage_max 0.7334 (0.7338) teacher/usage_min 0.0456 (0.0352) teacher/usage_std 0.2918 (0.2983) nleep/row_max_mean 1559.0128 (1562.8175) nleep/row_max_std 57.1300 (54.2351) nleep/row_min_mean 1531.1056 (1535.2104) lr 1.9048e-03 eta 0:14:24
epoch [9/50] batch [120/167] time 0.144 (0.126) data 0.000 (0.003) loss 1.2450 (1.3804) teacher_loss 0.1643 (0.2987) loss_zs_kd 0.0145 (0.0201) loss_oracle 0.5441 (0.5379) kd_loss 0.8014 (0.8027) acc 93.7500 (88.5156) gate/entropy 1.0180 (1.0215) gate/usage_max 0.5285 (0.5242) gate/usage_min 0.2277 (0.2305) gate/usage_std 0.1382 (0.1351) teacher/entropy 0.0353 (0.0428) teacher/usage_max 0.7426 (0.7366) teacher/usage_min 0.0282 (0.0326) teacher/usage_std 0.3008 (0.3000) nleep/row_max_mean 1547.6411 (1562.0834) nleep/row_max_std 61.7649 (54.6282) nleep/row_min_mean 1520.2804 (1534.2773) lr 1.9048e-03 eta 0:14:31
epoch [9/50] batch [140/167] time 0.133 (0.129) data 0.000 (0.002) loss 1.1778 (1.3807) teacher_loss 0.0869 (0.2982) loss_zs_kd 0.0016 (0.0198) loss_oracle 0.5141 (0.5378) kd_loss 0.8330 (0.8038) acc 96.8750 (88.6161) gate/entropy 1.0164 (1.0208) gate/usage_max 0.5305 (0.5250) gate/usage_min 0.2265 (0.2300) gate/usage_std 0.1396 (0.1357) teacher/entropy 0.0731 (0.0428) teacher/usage_max 0.6505 (0.7340) teacher/usage_min 0.0270 (0.0313) teacher/usage_std 0.2547 (0.2988) nleep/row_max_mean 1559.9750 (1561.2868) nleep/row_max_std 47.4239 (54.6789) nleep/row_min_mean 1531.1609 (1533.3271) lr 1.9048e-03 eta 0:14:45
epoch [9/50] batch [160/167] time 0.143 (0.129) data 0.000 (0.002) loss 1.2857 (1.3815) teacher_loss 0.1805 (0.2990) loss_zs_kd 0.0125 (0.0198) loss_oracle 0.5417 (0.5330) kd_loss 0.8281 (0.8061) acc 96.8750 (88.5547) gate/entropy 1.0161 (1.0202) gate/usage_max 0.5309 (0.5258) gate/usage_min 0.2260 (0.2295) gate/usage_std 0.1398 (0.1363) teacher/entropy 0.0467 (0.0427) teacher/usage_max 0.6930 (0.7301) teacher/usage_min 0.0668 (0.0313) teacher/usage_std 0.2640 (0.2967) nleep/row_max_mean 1547.5160 (1561.2254) nleep/row_max_std 59.2338 (54.7432) nleep/row_min_mean 1517.5322 (1533.0751) lr 1.9048e-03 eta 0:14:47
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,202
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.2%, epoch: 7 *******
******* Domain c best val test acc: 99.1%, epoch: 7 *******
******* Domain c best test acc:     99.2%, epoch: 3 *******
epoch [10/50] batch [20/167] time 0.084 (0.125) data 0.000 (0.015) loss 1.4974 (1.3784) teacher_loss 0.5191 (0.3235) loss_zs_kd 0.0230 (0.0183) loss_oracle 0.5179 (0.5084) kd_loss 0.7079 (0.7916) acc 78.1250 (87.6562) gate/entropy 1.0134 (1.0143) gate/usage_max 0.5341 (0.5330) gate/usage_min 0.2242 (0.2248) gate/usage_std 0.1422 (0.1414) teacher/entropy 0.0911 (0.0532) teacher/usage_max 0.7816 (0.7270) teacher/usage_min 0.0041 (0.0358) teacher/usage_std 0.3284 (0.2935) nleep/row_max_mean 1560.2550 (1562.0466) nleep/row_max_std 50.6502 (55.2695) nleep/row_min_mean 1529.1396 (1532.2759) lr 1.8763e-03 eta 0:14:16
epoch [10/50] batch [40/167] time 0.180 (0.124) data 0.000 (0.008) loss 1.3882 (1.3679) teacher_loss 0.2471 (0.3022) loss_zs_kd 0.0121 (0.0182) loss_oracle 0.5586 (0.5240) kd_loss 0.8557 (0.7946) acc 87.5000 (88.3594) gate/entropy 1.0131 (1.0137) gate/usage_max 0.5344 (0.5337) gate/usage_min 0.2240 (0.2244) gate/usage_std 0.1424 (0.1419) teacher/entropy 0.0275 (0.0433) teacher/usage_max 0.6793 (0.7342) teacher/usage_min 0.0388 (0.0287) teacher/usage_std 0.2640 (0.2984) nleep/row_max_mean 1553.7136 (1561.9757) nleep/row_max_std 70.8807 (55.6893) nleep/row_min_mean 1523.9823 (1531.3910) lr 1.8763e-03 eta 0:14:01
epoch [10/50] batch [60/167] time 0.088 (0.121) data 0.001 (0.005) loss 1.3844 (1.3833) teacher_loss 0.3005 (0.3156) loss_zs_kd 0.0368 (0.0208) loss_oracle 0.4954 (0.5296) kd_loss 0.8179 (0.7926) acc 87.5000 (87.9167) gate/entropy 1.0112 (1.0132) gate/usage_max 0.5368 (0.5344) gate/usage_min 0.2228 (0.2240) gate/usage_std 0.1440 (0.1423) teacher/entropy 0.0297 (0.0426) teacher/usage_max 0.7170 (0.7370) teacher/usage_min 0.0114 (0.0293) teacher/usage_std 0.2914 (0.3006) nleep/row_max_mean 1573.5870 (1562.4874) nleep/row_max_std 61.3908 (56.5149) nleep/row_min_mean 1538.7104 (1531.4038) lr 1.8763e-03 eta 0:13:43
epoch [10/50] batch [80/167] time 0.087 (0.116) data 0.000 (0.004) loss 1.3572 (1.3636) teacher_loss 0.2137 (0.3062) loss_zs_kd 0.0137 (0.0211) loss_oracle 0.4399 (0.5184) kd_loss 0.9166 (0.7877) acc 93.7500 (88.0859) gate/entropy 1.0107 (1.0126) gate/usage_max 0.5373 (0.5350) gate/usage_min 0.2225 (0.2237) gate/usage_std 0.1444 (0.1428) teacher/entropy 0.0528 (0.0448) teacher/usage_max 0.5644 (0.7396) teacher/usage_min 0.0105 (0.0278) teacher/usage_std 0.2353 (0.3026) nleep/row_max_mean 1559.5005 (1560.9222) nleep/row_max_std 48.4126 (57.3196) nleep/row_min_mean 1531.2560 (1529.7785) lr 1.8763e-03 eta 0:13:03
epoch [10/50] batch [100/167] time 0.143 (0.115) data 0.001 (0.003) loss 1.1874 (1.3531) teacher_loss 0.1724 (0.2982) loss_zs_kd 0.0369 (0.0211) loss_oracle 0.4682 (0.5132) kd_loss 0.7624 (0.7877) acc 96.8750 (88.6250) gate/entropy 1.0092 (1.0121) gate/usage_max 0.5391 (0.5356) gate/usage_min 0.2218 (0.2234) gate/usage_std 0.1456 (0.1432) teacher/entropy 0.0787 (0.0445) teacher/usage_max 0.7270 (0.7395) teacher/usage_min 0.0401 (0.0295) teacher/usage_std 0.2893 (0.3019) nleep/row_max_mean 1573.4895 (1560.5514) nleep/row_max_std 45.9613 (57.3393) nleep/row_min_mean 1542.9092 (1529.1294) lr 1.8763e-03 eta 0:12:56
epoch [10/50] batch [120/167] time 0.156 (0.112) data 0.000 (0.003) loss 1.4608 (1.3487) teacher_loss 0.4828 (0.2991) loss_zs_kd 0.0193 (0.0206) loss_oracle 0.5402 (0.5119) kd_loss 0.6982 (0.7834) acc 75.0000 (88.5938) gate/entropy 1.0086 (1.0116) gate/usage_max 0.5399 (0.5363) gate/usage_min 0.2215 (0.2231) gate/usage_std 0.1462 (0.1437) teacher/entropy 0.0532 (0.0457) teacher/usage_max 0.8333 (0.7428) teacher/usage_min 0.0152 (0.0308) teacher/usage_std 0.3579 (0.3034) nleep/row_max_mean 1551.2080 (1560.0445) nleep/row_max_std 67.2058 (57.9683) nleep/row_min_mean 1516.4540 (1528.2685) lr 1.8763e-03 eta 0:12:33
epoch [10/50] batch [140/167] time 0.094 (0.111) data 0.000 (0.002) loss 1.3209 (1.3476) teacher_loss 0.3637 (0.3003) loss_zs_kd 0.0248 (0.0201) loss_oracle 0.5352 (0.5094) kd_loss 0.6772 (0.7825) acc 81.2500 (88.4598) gate/entropy 1.0076 (1.0110) gate/usage_max 0.5410 (0.5369) gate/usage_min 0.2211 (0.2228) gate/usage_std 0.1470 (0.1441) teacher/entropy 0.0737 (0.0455) teacher/usage_max 0.8350 (0.7436) teacher/usage_min 0.0381 (0.0313) teacher/usage_std 0.3566 (0.3037) nleep/row_max_mean 1545.9757 (1559.5143) nleep/row_max_std 54.3584 (57.9009) nleep/row_min_mean 1513.6049 (1527.6471) lr 1.8763e-03 eta 0:12:21
epoch [10/50] batch [160/167] time 0.076 (0.112) data 0.000 (0.002) loss 1.2151 (1.3484) teacher_loss 0.1404 (0.3003) loss_zs_kd 0.0167 (0.0196) loss_oracle 0.5810 (0.5130) kd_loss 0.7758 (0.7818) acc 96.8750 (88.6133) gate/entropy 1.0066 (1.0105) gate/usage_max 0.5422 (0.5375) gate/usage_min 0.2205 (0.2226) gate/usage_std 0.1478 (0.1446) teacher/entropy 0.0159 (0.0452) teacher/usage_max 0.7813 (0.7444) teacher/usage_min 0.0249 (0.0310) teacher/usage_std 0.3241 (0.3045) nleep/row_max_mean 1548.3821 (1558.3242) nleep/row_max_std 63.7100 (58.1944) nleep/row_min_mean 1517.0776 (1526.4817) lr 1.8763e-03 eta 0:12:25
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,190
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.2%, epoch: 7 *******
******* Domain c best val test acc: 99.1%, epoch: 7 *******
******* Domain c best test acc:     99.2%, epoch: 3 *******
epoch [11/50] batch [20/167] time 0.165 (0.167) data 0.000 (0.016) loss 1.6323 (1.3413) teacher_loss 0.5504 (0.2807) loss_zs_kd 0.0288 (0.0155) loss_oracle 0.5255 (0.5136) kd_loss 0.8047 (0.7961) acc 81.2500 (88.9062) gate/entropy 1.0051 (1.0060) gate/usage_max 0.5440 (0.5429) gate/usage_min 0.2197 (0.2202) gate/usage_std 0.1491 (0.1483) teacher/entropy 0.0112 (0.0386) teacher/usage_max 0.7511 (0.7291) teacher/usage_min 0.0319 (0.0238) teacher/usage_std 0.3049 (0.2970) nleep/row_max_mean 1556.3236 (1549.3629) nleep/row_max_std 59.9815 (58.6393) nleep/row_min_mean 1522.7781 (1517.8254) lr 1.8443e-03 eta 0:18:33
epoch [11/50] batch [40/167] time 0.185 (0.164) data 0.000 (0.008) loss 1.4081 (1.3672) teacher_loss 0.2797 (0.3016) loss_zs_kd 0.0157 (0.0197) loss_oracle 0.4748 (0.5112) kd_loss 0.8831 (0.8001) acc 87.5000 (88.7500) gate/entropy 1.0051 (1.0057) gate/usage_max 0.5440 (0.5432) gate/usage_min 0.2196 (0.2200) gate/usage_std 0.1491 (0.1486) teacher/entropy 0.0861 (0.0386) teacher/usage_max 0.5688 (0.7239) teacher/usage_min 0.0343 (0.0204) teacher/usage_std 0.2228 (0.2963) nleep/row_max_mean 1552.4713 (1548.9026) nleep/row_max_std 52.3177 (57.4654) nleep/row_min_mean 1525.5833 (1517.5736) lr 1.8443e-03 eta 0:18:07
epoch [11/50] batch [60/167] time 0.113 (0.159) data 0.000 (0.006) loss 1.3287 (1.3733) teacher_loss 0.1897 (0.2996) loss_zs_kd 0.0174 (0.0206) loss_oracle 0.5586 (0.5202) kd_loss 0.8510 (0.8033) acc 93.7500 (88.9062) gate/entropy 1.0037 (1.0053) gate/usage_max 0.5456 (0.5437) gate/usage_min 0.2188 (0.2197) gate/usage_std 0.1502 (0.1489) teacher/entropy 0.0149 (0.0338) teacher/usage_max 0.6876 (0.7250) teacher/usage_min 0.0037 (0.0189) teacher/usage_std 0.2798 (0.2976) nleep/row_max_mean 1571.3676 (1550.6317) nleep/row_max_std 39.7137 (56.5086) nleep/row_min_mean 1535.7018 (1519.0306) lr 1.8443e-03 eta 0:17:32
epoch [11/50] batch [80/167] time 0.155 (0.156) data 0.000 (0.004) loss 1.3430 (1.3805) teacher_loss 0.2842 (0.3013) loss_zs_kd 0.0173 (0.0207) loss_oracle 0.5869 (0.5231) kd_loss 0.7566 (0.8073) acc 90.6250 (88.9062) gate/entropy 1.0037 (1.0050) gate/usage_max 0.5455 (0.5441) gate/usage_min 0.2187 (0.2195) gate/usage_std 0.1502 (0.1492) teacher/entropy 0.0058 (0.0311) teacher/usage_max 0.8117 (0.7229) teacher/usage_min 0.0320 (0.0178) teacher/usage_std 0.3420 (0.2976) nleep/row_max_mean 1556.0823 (1550.9679) nleep/row_max_std 54.3455 (55.7579) nleep/row_min_mean 1525.2302 (1519.3251) lr 1.8443e-03 eta 0:17:07
epoch [11/50] batch [100/167] time 0.133 (0.155) data 0.000 (0.003) loss 1.1855 (1.3728) teacher_loss 0.2122 (0.2976) loss_zs_kd 0.0159 (0.0203) loss_oracle 0.4794 (0.5220) kd_loss 0.7257 (0.8040) acc 90.6250 (88.8750) gate/entropy 1.0028 (1.0046) gate/usage_max 0.5465 (0.5444) gate/usage_min 0.2182 (0.2193) gate/usage_std 0.1509 (0.1494) teacher/entropy 0.0224 (0.0296) teacher/usage_max 0.8280 (0.7284) teacher/usage_min 0.0158 (0.0178) teacher/usage_std 0.3544 (0.2999) nleep/row_max_mean 1566.8108 (1552.1192) nleep/row_max_std 54.5680 (55.7554) nleep/row_min_mean 1533.2882 (1520.2743) lr 1.8443e-03 eta 0:17:01
epoch [11/50] batch [120/167] time 0.110 (0.155) data 0.000 (0.003) loss 1.3565 (1.3751) teacher_loss 0.2805 (0.2960) loss_zs_kd 0.0251 (0.0202) loss_oracle 0.5149 (0.5244) kd_loss 0.8061 (0.8068) acc 90.6250 (88.8021) gate/entropy 1.0031 (1.0044) gate/usage_max 0.5462 (0.5447) gate/usage_min 0.2181 (0.2191) gate/usage_std 0.1507 (0.1496) teacher/entropy 0.0103 (0.0280) teacher/usage_max 0.7469 (0.7269) teacher/usage_min 0.0031 (0.0166) teacher/usage_std 0.3093 (0.2996) nleep/row_max_mean 1538.6404 (1552.8910) nleep/row_max_std 65.7972 (55.6831) nleep/row_min_mean 1510.3861 (1521.1458) lr 1.8443e-03 eta 0:16:58
epoch [11/50] batch [140/167] time 0.081 (0.150) data 0.000 (0.002) loss 1.3783 (1.3711) teacher_loss 0.3446 (0.2937) loss_zs_kd 0.0232 (0.0203) loss_oracle 0.5615 (0.5219) kd_loss 0.7413 (0.8063) acc 90.6250 (88.7946) gate/entropy 1.0021 (1.0041) gate/usage_max 0.5473 (0.5451) gate/usage_min 0.2176 (0.2189) gate/usage_std 0.1515 (0.1499) teacher/entropy 0.0326 (0.0268) teacher/usage_max 0.7929 (0.7292) teacher/usage_min 0.0029 (0.0164) teacher/usage_std 0.3352 (0.3008) nleep/row_max_mean 1566.4980 (1554.4738) nleep/row_max_std 53.3806 (55.6443) nleep/row_min_mean 1532.4280 (1522.7140) lr 1.8443e-03 eta 0:16:22
epoch [11/50] batch [160/167] time 0.083 (0.144) data 0.000 (0.002) loss 1.6513 (1.3700) teacher_loss 0.6224 (0.2934) loss_zs_kd 0.0245 (0.0208) loss_oracle 0.4959 (0.5168) kd_loss 0.7687 (0.8078) acc 81.2500 (88.8867) gate/entropy 1.0017 (1.0038) gate/usage_max 0.5478 (0.5453) gate/usage_min 0.2174 (0.2187) gate/usage_std 0.1518 (0.1501) teacher/entropy 0.0168 (0.0260) teacher/usage_max 0.7812 (0.7281) teacher/usage_min 0.0066 (0.0175) teacher/usage_std 0.3276 (0.2998) nleep/row_max_mean 1556.5651 (1554.2631) nleep/row_max_std 64.8616 (55.8232) nleep/row_min_mean 1527.0532 (1522.6815) lr 1.8443e-03 eta 0:15:35
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,203
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.2%, epoch: 7 *******
******* Domain c best val test acc: 99.1%, epoch: 7 *******
******* Domain c best test acc:     99.2%, epoch: 3 *******
epoch [12/50] batch [20/167] time 0.083 (0.126) data 0.000 (0.014) loss 1.3177 (1.3334) teacher_loss 0.2046 (0.2492) loss_zs_kd 0.0345 (0.0270) loss_oracle 0.4452 (0.4871) kd_loss 0.8732 (0.8271) acc 93.7500 (90.9375) gate/entropy 1.0007 (1.0013) gate/usage_max 0.5489 (0.5482) gate/usage_min 0.2169 (0.2171) gate/usage_std 0.1526 (0.1521) teacher/entropy 0.0350 (0.0194) teacher/usage_max 0.6394 (0.7111) teacher/usage_min 0.0406 (0.0390) teacher/usage_std 0.2446 (0.2836) nleep/row_max_mean 1551.9951 (1553.4320) nleep/row_max_std 56.7347 (55.7339) nleep/row_min_mean 1523.2378 (1523.5141) lr 1.8090e-03 eta 0:13:39
epoch [12/50] batch [40/167] time 0.085 (0.120) data 0.000 (0.007) loss 1.2724 (1.3321) teacher_loss 0.2951 (0.2569) loss_zs_kd 0.0082 (0.0230) loss_oracle 0.4899 (0.4740) kd_loss 0.7283 (0.8267) acc 90.6250 (90.8594) gate/entropy 1.0005 (1.0011) gate/usage_max 0.5491 (0.5484) gate/usage_min 0.2168 (0.2170) gate/usage_std 0.1527 (0.1522) teacher/entropy 0.0040 (0.0210) teacher/usage_max 0.8430 (0.7098) teacher/usage_min 0.0000 (0.0394) teacher/usage_std 0.3660 (0.2824) nleep/row_max_mean 1555.7632 (1552.6164) nleep/row_max_std 52.3256 (55.4084) nleep/row_min_mean 1521.5892 (1522.6436) lr 1.8090e-03 eta 0:12:57
epoch [12/50] batch [60/167] time 0.182 (0.115) data 0.001 (0.005) loss 1.1848 (1.3421) teacher_loss 0.1963 (0.2732) loss_zs_kd 0.0201 (0.0231) loss_oracle 0.4115 (0.4703) kd_loss 0.7728 (0.8221) acc 93.7500 (89.6875) gate/entropy 1.0005 (1.0009) gate/usage_max 0.5491 (0.5487) gate/usage_min 0.2168 (0.2169) gate/usage_std 0.1527 (0.1525) teacher/entropy 0.0538 (0.0267) teacher/usage_max 0.7372 (0.7088) teacher/usage_min 0.0615 (0.0454) teacher/usage_std 0.2912 (0.2804) nleep/row_max_mean 1544.5376 (1553.4591) nleep/row_max_std 69.1701 (55.2738) nleep/row_min_mean 1516.0010 (1523.1452) lr 1.8090e-03 eta 0:12:21
epoch [12/50] batch [80/167] time 0.077 (0.114) data 0.000 (0.004) loss 1.2055 (1.3371) teacher_loss 0.2550 (0.2704) loss_zs_kd 0.0362 (0.0235) loss_oracle 0.4713 (0.4730) kd_loss 0.6968 (0.8185) acc 90.6250 (89.8438) gate/entropy 0.9994 (1.0007) gate/usage_max 0.5503 (0.5489) gate/usage_min 0.2163 (0.2168) gate/usage_std 0.1536 (0.1526) teacher/entropy 0.0321 (0.0311) teacher/usage_max 0.8454 (0.7079) teacher/usage_min 0.0087 (0.0461) teacher/usage_std 0.3664 (0.2803) nleep/row_max_mean 1560.0718 (1553.8925) nleep/row_max_std 60.9340 (55.7617) nleep/row_min_mean 1527.3953 (1523.4701) lr 1.8090e-03 eta 0:12:13
epoch [12/50] batch [100/167] time 0.175 (0.113) data 0.000 (0.003) loss 1.3787 (1.3466) teacher_loss 0.3170 (0.2724) loss_zs_kd 0.0141 (0.0245) loss_oracle 0.4689 (0.4824) kd_loss 0.8203 (0.8207) acc 81.2500 (89.6875) gate/entropy 0.9994 (1.0004) gate/usage_max 0.5503 (0.5492) gate/usage_min 0.2163 (0.2167) gate/usage_std 0.1536 (0.1528) teacher/entropy 0.0241 (0.0307) teacher/usage_max 0.7132 (0.7058) teacher/usage_min 0.0370 (0.0484) teacher/usage_std 0.2823 (0.2785) nleep/row_max_mean 1567.3512 (1554.0433) nleep/row_max_std 52.0198 (55.8189) nleep/row_min_mean 1535.6321 (1523.6019) lr 1.8090e-03 eta 0:12:04
epoch [12/50] batch [120/167] time 0.076 (0.114) data 0.000 (0.003) loss 1.4480 (1.3494) teacher_loss 0.2867 (0.2701) loss_zs_kd 0.0265 (0.0240) loss_oracle 0.4757 (0.4833) kd_loss 0.9102 (0.8256) acc 90.6250 (89.8177) gate/entropy 0.9997 (1.0002) gate/usage_max 0.5501 (0.5494) gate/usage_min 0.2163 (0.2167) gate/usage_std 0.1534 (0.1530) teacher/entropy 0.0450 (0.0314) teacher/usage_max 0.5803 (0.6996) teacher/usage_min 0.0203 (0.0529) teacher/usage_std 0.2333 (0.2744) nleep/row_max_mean 1547.6743 (1554.8525) nleep/row_max_std 58.7429 (55.7955) nleep/row_min_mean 1521.2600 (1524.3472) lr 1.8090e-03 eta 0:12:11
epoch [12/50] batch [140/167] time 0.165 (0.117) data 0.000 (0.002) loss 1.3929 (1.3460) teacher_loss 0.3078 (0.2620) loss_zs_kd 0.0270 (0.0243) loss_oracle 0.5086 (0.4844) kd_loss 0.8173 (0.8298) acc 87.5000 (90.1562) gate/entropy 0.9985 (1.0000) gate/usage_max 0.5513 (0.5496) gate/usage_min 0.2159 (0.2166) gate/usage_std 0.1543 (0.1531) teacher/entropy 0.0266 (0.0328) teacher/usage_max 0.7232 (0.6934) teacher/usage_min 0.1164 (0.0575) teacher/usage_std 0.2763 (0.2698) nleep/row_max_mean 1562.5922 (1555.2492) nleep/row_max_std 50.4610 (55.5907) nleep/row_min_mean 1529.9755 (1524.7217) lr 1.8090e-03 eta 0:12:26
epoch [12/50] batch [160/167] time 0.150 (0.121) data 0.000 (0.002) loss 1.2611 (1.3500) teacher_loss 0.1959 (0.2604) loss_zs_kd 0.0199 (0.0254) loss_oracle 0.4638 (0.4855) kd_loss 0.8234 (0.8342) acc 93.7500 (90.1758) gate/entropy 0.9987 (0.9999) gate/usage_max 0.5512 (0.5498) gate/usage_min 0.2159 (0.2165) gate/usage_std 0.1542 (0.1532) teacher/entropy 0.0240 (0.0333) teacher/usage_max 0.7073 (0.6881) teacher/usage_min 0.0427 (0.0621) teacher/usage_std 0.2777 (0.2656) nleep/row_max_mean 1553.4182 (1555.0097) nleep/row_max_std 59.4459 (55.3757) nleep/row_min_mean 1522.6055 (1524.5996) lr 1.8090e-03 eta 0:12:49
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,201
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.2%, epoch: 7 *******
******* Domain c best val test acc: 99.1%, epoch: 7 *******
******* Domain c best test acc:     99.2%, epoch: 3 *******
epoch [13/50] batch [20/167] time 0.139 (0.161) data 0.000 (0.016) loss 1.3864 (1.3774) teacher_loss 0.2747 (0.2422) loss_zs_kd 0.0228 (0.0324) loss_oracle 0.4786 (0.4976) kd_loss 0.8610 (0.8701) acc 87.5000 (91.0938) gate/entropy 0.9984 (0.9984) gate/usage_max 0.5515 (0.5515) gate/usage_min 0.2158 (0.2158) gate/usage_std 0.1544 (0.1544) teacher/entropy 0.0425 (0.0484) teacher/usage_max 0.6543 (0.6356) teacher/usage_min 0.1605 (0.1270) teacher/usage_std 0.2272 (0.2230) nleep/row_max_mean 1538.0874 (1547.3269) nleep/row_max_std 68.5178 (54.8691) nleep/row_min_mean 1512.1973 (1518.4741) lr 1.7705e-03 eta 0:16:58
epoch [13/50] batch [40/167] time 0.187 (0.158) data 0.000 (0.008) loss 1.2010 (1.3885) teacher_loss 0.1368 (0.2299) loss_zs_kd 0.0241 (0.0327) loss_oracle 0.4918 (0.4930) kd_loss 0.8062 (0.8957) acc 96.8750 (91.3281) gate/entropy 0.9977 (0.9983) gate/usage_max 0.5523 (0.5516) gate/usage_min 0.2157 (0.2158) gate/usage_std 0.1550 (0.1545) teacher/entropy 0.0534 (0.0448) teacher/usage_max 0.7089 (0.6124) teacher/usage_min 0.0937 (0.1453) teacher/usage_std 0.2689 (0.2047) nleep/row_max_mean 1559.3958 (1548.5523) nleep/row_max_std 51.3301 (55.1037) nleep/row_min_mean 1530.2230 (1518.8725) lr 1.7705e-03 eta 0:16:38
epoch [13/50] batch [60/167] time 0.155 (0.136) data 0.001 (0.005) loss 1.2735 (1.3893) teacher_loss 0.1121 (0.2255) loss_zs_kd 0.0170 (0.0346) loss_oracle 0.5241 (0.5012) kd_loss 0.8908 (0.8959) acc 93.7500 (91.4062) gate/entropy 0.9974 (0.9981) gate/usage_max 0.5526 (0.5518) gate/usage_min 0.2157 (0.2158) gate/usage_std 0.1552 (0.1547) teacher/entropy 0.0464 (0.0476) teacher/usage_max 0.6236 (0.6100) teacher/usage_min 0.1235 (0.1467) teacher/usage_std 0.2120 (0.2025) nleep/row_max_mean 1560.8696 (1549.9920) nleep/row_max_std 55.2960 (55.9045) nleep/row_min_mean 1531.1499 (1520.1279) lr 1.7705e-03 eta 0:14:14
epoch [13/50] batch [80/167] time 0.185 (0.129) data 0.000 (0.004) loss 1.4913 (1.4057) teacher_loss 0.1788 (0.2190) loss_zs_kd 0.0293 (0.0353) loss_oracle 0.5105 (0.5064) kd_loss 1.0425 (0.9158) acc 90.6250 (91.7188) gate/entropy 0.9979 (0.9979) gate/usage_max 0.5520 (0.5520) gate/usage_min 0.2160 (0.2158) gate/usage_std 0.1548 (0.1548) teacher/entropy 0.1087 (0.0519) teacher/usage_max 0.3803 (0.5867) teacher/usage_min 0.3069 (0.1574) teacher/usage_std 0.0333 (0.1874) nleep/row_max_mean 1535.5488 (1550.1399) nleep/row_max_std 57.5761 (55.8388) nleep/row_min_mean 1508.0815 (1520.3510) lr 1.7705e-03 eta 0:13:28
epoch [13/50] batch [100/167] time 0.084 (0.122) data 0.000 (0.003) loss 1.5583 (1.4225) teacher_loss 0.1500 (0.2141) loss_zs_kd 0.0268 (0.0360) loss_oracle 0.6107 (0.5217) kd_loss 1.0895 (0.9296) acc 93.7500 (91.9062) gate/entropy 0.9977 (0.9978) gate/usage_max 0.5524 (0.5522) gate/usage_min 0.2161 (0.2158) gate/usage_std 0.1550 (0.1549) teacher/entropy 0.0574 (0.0525) teacher/usage_max 0.4458 (0.5729) teacher/usage_min 0.1577 (0.1565) teacher/usage_std 0.1258 (0.1810) nleep/row_max_mean 1538.7900 (1550.2543) nleep/row_max_std 64.1459 (56.6649) nleep/row_min_mean 1507.9690 (1520.2304) lr 1.7705e-03 eta 0:12:39
epoch [13/50] batch [120/167] time 0.070 (0.121) data 0.000 (0.003) loss 1.6167 (1.4373) teacher_loss 0.2751 (0.2148) loss_zs_kd 0.0355 (0.0362) loss_oracle 0.6209 (0.5208) kd_loss 1.0133 (0.9440) acc 87.5000 (91.9271) gate/entropy 0.9963 (0.9977) gate/usage_max 0.5539 (0.5523) gate/usage_min 0.2159 (0.2159) gate/usage_std 0.1561 (0.1550) teacher/entropy 0.0104 (0.0508) teacher/usage_max 0.5321 (0.5628) teacher/usage_min 0.0948 (0.1514) teacher/usage_std 0.1807 (0.1778) nleep/row_max_mean 1564.6556 (1550.8173) nleep/row_max_std 55.7825 (56.8914) nleep/row_min_mean 1530.3101 (1520.5770) lr 1.7705e-03 eta 0:12:32
epoch [13/50] batch [140/167] time 0.106 (0.117) data 0.000 (0.002) loss 1.4820 (1.4510) teacher_loss 0.2021 (0.2174) loss_zs_kd 0.0241 (0.0356) loss_oracle 0.5023 (0.5174) kd_loss 1.0166 (0.9571) acc 96.8750 (91.9420) gate/entropy 0.9969 (0.9975) gate/usage_max 0.5532 (0.5525) gate/usage_min 0.2164 (0.2159) gate/usage_std 0.1556 (0.1551) teacher/entropy 0.0772 (0.0493) teacher/usage_max 0.4543 (0.5561) teacher/usage_min 0.1253 (0.1488) teacher/usage_std 0.1477 (0.1754) nleep/row_max_mean 1536.9932 (1552.0173) nleep/row_max_std 70.5507 (56.7093) nleep/row_min_mean 1509.1661 (1521.6383) lr 1.7705e-03 eta 0:12:05
epoch [13/50] batch [160/167] time 0.083 (0.115) data 0.000 (0.002) loss 1.5839 (1.4552) teacher_loss 0.4639 (0.2145) loss_zs_kd 0.0611 (0.0352) loss_oracle 0.5381 (0.5157) kd_loss 0.8205 (0.9653) acc 84.3750 (92.0117) gate/entropy 0.9963 (0.9974) gate/usage_max 0.5540 (0.5526) gate/usage_min 0.2164 (0.2160) gate/usage_std 0.1561 (0.1552) teacher/entropy 0.0353 (0.0485) teacher/usage_max 0.7106 (0.5506) teacher/usage_min 0.0953 (0.1463) teacher/usage_std 0.2698 (0.1739) nleep/row_max_mean 1566.8916 (1553.4796) nleep/row_max_std 54.1413 (56.1240) nleep/row_min_mean 1534.1819 (1523.0701) lr 1.7705e-03 eta 0:11:54
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,189
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,329
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain c best val acc:      96.2%, epoch: 7 *******
******* Domain c best val test acc: 99.1%, epoch: 7 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [14/50] batch [20/167] time 0.160 (0.141) data 0.000 (0.018) loss 1.4865 (1.5148) teacher_loss 0.0802 (0.2139) loss_zs_kd 0.0122 (0.0332) loss_oracle 0.5132 (0.5238) kd_loss 1.1436 (1.0225) acc 96.8750 (91.8750) gate/entropy 0.9974 (0.9963) gate/usage_max 0.5527 (0.5539) gate/usage_min 0.2172 (0.2166) gate/usage_std 0.1552 (0.1561) teacher/entropy 0.0310 (0.0474) teacher/usage_max 0.3638 (0.4989) teacher/usage_min 0.2815 (0.1417) teacher/usage_std 0.0369 (0.1508) nleep/row_max_mean 1541.0261 (1558.8540) nleep/row_max_std 61.6020 (55.9181) nleep/row_min_mean 1511.1898 (1528.3110) lr 1.7290e-03 eta 0:14:31
epoch [14/50] batch [40/167] time 0.094 (0.131) data 0.000 (0.009) loss 1.4922 (1.5260) teacher_loss 0.1355 (0.2204) loss_zs_kd 0.0480 (0.0343) loss_oracle 0.5829 (0.5236) kd_loss 1.0412 (1.0267) acc 96.8750 (91.4062) gate/entropy 0.9956 (0.9962) gate/usage_max 0.5547 (0.5540) gate/usage_min 0.2167 (0.2167) gate/usage_std 0.1566 (0.1561) teacher/entropy 0.0295 (0.0436) teacher/usage_max 0.4804 (0.4923) teacher/usage_min 0.0940 (0.1503) teacher/usage_std 0.1707 (0.1462) nleep/row_max_mean 1567.8870 (1558.8791) nleep/row_max_std 52.6218 (56.3061) nleep/row_min_mean 1533.7078 (1528.2635) lr 1.7290e-03 eta 0:13:22
epoch [14/50] batch [60/167] time 0.168 (0.131) data 0.000 (0.006) loss 1.4821 (1.5297) teacher_loss 0.1288 (0.2174) loss_zs_kd 0.0311 (0.0389) loss_oracle 0.5439 (0.5459) kd_loss 1.0658 (1.0199) acc 96.8750 (91.4583) gate/entropy 0.9958 (0.9961) gate/usage_max 0.5545 (0.5542) gate/usage_min 0.2170 (0.2168) gate/usage_std 0.1565 (0.1563) teacher/entropy 0.0386 (0.0398) teacher/usage_max 0.4425 (0.4999) teacher/usage_min 0.1254 (0.1435) teacher/usage_std 0.1471 (0.1518) nleep/row_max_mean 1561.1968 (1560.6405) nleep/row_max_std 56.5855 (55.3765) nleep/row_min_mean 1529.6218 (1529.5806) lr 1.7290e-03 eta 0:13:18
epoch [14/50] batch [80/167] time 0.147 (0.133) data 0.000 (0.005) loss 1.4917 (1.5312) teacher_loss 0.2527 (0.2137) loss_zs_kd 0.0320 (0.0403) loss_oracle 0.6076 (0.5478) kd_loss 0.9192 (1.0235) acc 84.3750 (91.6797) gate/entropy 0.9952 (0.9960) gate/usage_max 0.5552 (0.5543) gate/usage_min 0.2170 (0.2168) gate/usage_std 0.1569 (0.1564) teacher/entropy 0.0543 (0.0367) teacher/usage_max 0.5799 (0.5069) teacher/usage_min 0.1499 (0.1347) teacher/usage_std 0.1812 (0.1586) nleep/row_max_mean 1571.0763 (1561.7959) nleep/row_max_std 49.8671 (55.2409) nleep/row_min_mean 1534.6599 (1530.3049) lr 1.7290e-03 eta 0:13:32
epoch [14/50] batch [100/167] time 0.143 (0.137) data 0.000 (0.004) loss 1.6138 (1.5373) teacher_loss 0.2501 (0.2166) loss_zs_kd 0.0338 (0.0400) loss_oracle 0.5871 (0.5510) kd_loss 1.0533 (1.0251) acc 90.6250 (91.5000) gate/entropy 0.9959 (0.9959) gate/usage_max 0.5544 (0.5544) gate/usage_min 0.2175 (0.2169) gate/usage_std 0.1564 (0.1564) teacher/entropy 0.0217 (0.0360) teacher/usage_max 0.4743 (0.5028) teacher/usage_min 0.0945 (0.1363) teacher/usage_std 0.1698 (0.1564) nleep/row_max_mean 1560.3450 (1561.8787) nleep/row_max_std 55.5032 (55.0811) nleep/row_min_mean 1529.1021 (1530.3316) lr 1.7290e-03 eta 0:13:52
epoch [14/50] batch [120/167] time 0.120 (0.139) data 0.000 (0.003) loss 1.6228 (1.5409) teacher_loss 0.2079 (0.2128) loss_zs_kd 0.0782 (0.0397) loss_oracle 0.6721 (0.5580) kd_loss 1.0397 (1.0292) acc 93.7500 (91.4323) gate/entropy 0.9950 (0.9958) gate/usage_max 0.5555 (0.5545) gate/usage_min 0.2174 (0.2170) gate/usage_std 0.1571 (0.1565) teacher/entropy 0.0414 (0.0358) teacher/usage_max 0.4652 (0.5010) teacher/usage_min 0.1249 (0.1364) teacher/usage_std 0.1491 (0.1553) nleep/row_max_mean 1579.0278 (1562.0213) nleep/row_max_std 35.8113 (55.2407) nleep/row_min_mean 1543.4583 (1530.5259) lr 1.7290e-03 eta 0:14:01
epoch [14/50] batch [140/167] time 0.126 (0.138) data 0.000 (0.003) loss 1.5398 (1.5417) teacher_loss 0.2313 (0.2134) loss_zs_kd 0.0282 (0.0396) loss_oracle 0.5326 (0.5604) kd_loss 1.0281 (1.0283) acc 93.7500 (91.4955) gate/entropy 0.9959 (0.9958) gate/usage_max 0.5545 (0.5546) gate/usage_min 0.2180 (0.2171) gate/usage_std 0.1564 (0.1565) teacher/entropy 0.0490 (0.0371) teacher/usage_max 0.4688 (0.5018) teacher/usage_min 0.1396 (0.1346) teacher/usage_std 0.1406 (0.1563) nleep/row_max_mean 1553.0569 (1561.7226) nleep/row_max_std 47.5114 (55.3619) nleep/row_min_mean 1524.6516 (1530.2763) lr 1.7290e-03 eta 0:13:55
epoch [14/50] batch [160/167] time 0.117 (0.138) data 0.000 (0.002) loss 1.5839 (1.5458) teacher_loss 0.1213 (0.2116) loss_zs_kd 0.0509 (0.0389) loss_oracle 0.6878 (0.5669) kd_loss 1.0933 (1.0313) acc 90.6250 (91.5234) gate/entropy 0.9949 (0.9957) gate/usage_max 0.5556 (0.5546) gate/usage_min 0.2179 (0.2172) gate/usage_std 0.1572 (0.1565) teacher/entropy 0.0105 (0.0368) teacher/usage_max 0.4398 (0.4982) teacher/usage_min 0.1562 (0.1374) teacher/usage_std 0.1261 (0.1538) nleep/row_max_mean 1567.4644 (1560.8900) nleep/row_max_std 42.2017 (55.2270) nleep/row_min_mean 1531.2926 (1529.5072) lr 1.7290e-03 eta 0:13:53
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,189
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.2%, epoch: 7 *******
******* Domain c best val test acc: 99.1%, epoch: 7 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [15/50] batch [20/167] time 0.103 (0.122) data 0.000 (0.014) loss 1.4616 (1.5909) teacher_loss 0.2379 (0.2142) loss_zs_kd 0.0458 (0.0390) loss_oracle 0.5584 (0.6321) kd_loss 0.9216 (1.0411) acc 87.5000 (91.4062) gate/entropy 0.9949 (0.9953) gate/usage_max 0.5556 (0.5552) gate/usage_min 0.2182 (0.2182) gate/usage_std 0.1572 (0.1569) teacher/entropy 0.0370 (0.0371) teacher/usage_max 0.5987 (0.4970) teacher/usage_min 0.0625 (0.1415) teacher/usage_std 0.2189 (0.1496) nleep/row_max_mean 1573.8611 (1558.5049) nleep/row_max_std 54.8558 (50.6287) nleep/row_min_mean 1537.6936 (1526.3950) lr 1.6845e-03 eta 0:12:09
epoch [15/50] batch [40/167] time 0.125 (0.122) data 0.000 (0.007) loss 1.7597 (1.5731) teacher_loss 0.2641 (0.2100) loss_zs_kd 0.0354 (0.0406) loss_oracle 0.5223 (0.6147) kd_loss 1.2167 (1.0355) acc 84.3750 (90.8594) gate/entropy 0.9958 (0.9952) gate/usage_max 0.5546 (0.5552) gate/usage_min 0.2188 (0.2183) gate/usage_std 0.1565 (0.1569) teacher/entropy 0.0402 (0.0370) teacher/usage_max 0.5971 (0.5016) teacher/usage_min 0.1269 (0.1305) teacher/usage_std 0.1962 (0.1564) nleep/row_max_mean 1543.9199 (1559.3457) nleep/row_max_std 57.7086 (52.3473) nleep/row_min_mean 1514.9645 (1526.7986) lr 1.6845e-03 eta 0:12:08
epoch [15/50] batch [60/167] time 0.230 (0.116) data 0.001 (0.005) loss 1.4579 (1.5700) teacher_loss 0.0324 (0.2131) loss_zs_kd 0.0141 (0.0385) loss_oracle 0.6243 (0.6069) kd_loss 1.1063 (1.0342) acc 100.0000 (90.6250) gate/entropy 0.9949 (0.9952) gate/usage_max 0.5557 (0.5553) gate/usage_min 0.2186 (0.2184) gate/usage_std 0.1572 (0.1570) teacher/entropy 0.0433 (0.0361) teacher/usage_max 0.4588 (0.5019) teacher/usage_min 0.1513 (0.1284) teacher/usage_std 0.1317 (0.1578) nleep/row_max_mean 1565.4702 (1560.6572) nleep/row_max_std 48.8915 (52.1927) nleep/row_min_mean 1530.0122 (1527.5961) lr 1.6845e-03 eta 0:11:28
epoch [15/50] batch [80/167] time 0.068 (0.119) data 0.000 (0.004) loss 1.3721 (1.5602) teacher_loss 0.1837 (0.2082) loss_zs_kd 0.0394 (0.0373) loss_oracle 0.5191 (0.5974) kd_loss 0.9093 (1.0347) acc 93.7500 (90.7422) gate/entropy 0.9945 (0.9952) gate/usage_max 0.5560 (0.5552) gate/usage_min 0.2187 (0.2186) gate/usage_std 0.1575 (0.1569) teacher/entropy 0.0536 (0.0374) teacher/usage_max 0.5924 (0.5027) teacher/usage_min 0.0709 (0.1286) teacher/usage_std 0.2129 (0.1584) nleep/row_max_mean 1574.1870 (1560.6886) nleep/row_max_std 60.9753 (52.8448) nleep/row_min_mean 1537.5908 (1527.4837) lr 1.6845e-03 eta 0:11:45
epoch [15/50] batch [100/167] time 0.070 (0.118) data 0.000 (0.003) loss 1.5348 (1.5547) teacher_loss 0.0606 (0.2060) loss_zs_kd 0.0302 (0.0373) loss_oracle 0.6599 (0.6024) kd_loss 1.1292 (1.0289) acc 100.0000 (91.1562) gate/entropy 0.9958 (0.9952) gate/usage_max 0.5547 (0.5552) gate/usage_min 0.2195 (0.2187) gate/usage_std 0.1565 (0.1569) teacher/entropy 0.0737 (0.0390) teacher/usage_max 0.5975 (0.5069) teacher/usage_min 0.0684 (0.1268) teacher/usage_std 0.2160 (0.1606) nleep/row_max_mean 1544.6685 (1561.4134) nleep/row_max_std 50.4015 (52.4445) nleep/row_min_mean 1515.1526 (1527.9593) lr 1.6845e-03 eta 0:11:38
epoch [15/50] batch [120/167] time 0.077 (0.118) data 0.000 (0.003) loss 1.5019 (1.5485) teacher_loss 0.3021 (0.2023) loss_zs_kd 0.0387 (0.0384) loss_oracle 0.4539 (0.5999) kd_loss 0.9535 (1.0270) acc 84.3750 (91.3542) gate/entropy 0.9952 (0.9952) gate/usage_max 0.5553 (0.5553) gate/usage_min 0.2195 (0.2188) gate/usage_std 0.1570 (0.1570) teacher/entropy 0.0040 (0.0381) teacher/usage_max 0.5935 (0.5083) teacher/usage_min 0.1873 (0.1244) teacher/usage_std 0.1844 (0.1626) nleep/row_max_mean 1567.4364 (1561.0526) nleep/row_max_std 55.6597 (52.6017) nleep/row_min_mean 1531.7443 (1527.3503) lr 1.6845e-03 eta 0:11:35
epoch [15/50] batch [140/167] time 0.153 (0.115) data 0.000 (0.002) loss 1.5936 (1.5488) teacher_loss 0.2477 (0.2103) loss_zs_kd 0.0516 (0.0389) loss_oracle 0.4763 (0.5870) kd_loss 1.0820 (1.0255) acc 93.7500 (90.8929) gate/entropy 0.9951 (0.9952) gate/usage_max 0.5554 (0.5553) gate/usage_min 0.2197 (0.2189) gate/usage_std 0.1571 (0.1570) teacher/entropy 0.0689 (0.0370) teacher/usage_max 0.5145 (0.5104) teacher/usage_min 0.0966 (0.1215) teacher/usage_std 0.1751 (0.1648) nleep/row_max_mean 1550.8180 (1560.9182) nleep/row_max_std 45.9501 (52.6139) nleep/row_min_mean 1518.0989 (1526.8282) lr 1.6845e-03 eta 0:11:13
epoch [15/50] batch [160/167] time 0.160 (0.114) data 0.000 (0.002) loss 1.5863 (1.5381) teacher_loss 0.2831 (0.2099) loss_zs_kd 0.0391 (0.0394) loss_oracle 0.5320 (0.5751) kd_loss 1.0176 (1.0209) acc 87.5000 (90.9766) gate/entropy 0.9952 (0.9952) gate/usage_max 0.5553 (0.5553) gate/usage_min 0.2199 (0.2190) gate/usage_std 0.1570 (0.1570) teacher/entropy 0.0469 (0.0381) teacher/usage_max 0.4831 (0.5131) teacher/usage_min 0.0609 (0.1213) teacher/usage_std 0.1930 (0.1661) nleep/row_max_mean 1542.0435 (1560.6246) nleep/row_max_std 64.3653 (52.5435) nleep/row_min_mean 1510.1172 (1526.2794) lr 1.6845e-03 eta 0:11:09
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,186
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.7%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,329
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
******* Domain c best val acc:      96.2%, epoch: 7 *******
******* Domain c best val test acc: 99.1%, epoch: 7 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [16/50] batch [20/167] time 0.136 (0.168) data 0.000 (0.014) loss 1.3849 (1.4861) teacher_loss 0.1535 (0.1945) loss_zs_kd 0.0555 (0.0366) loss_oracle 0.4820 (0.5372) kd_loss 0.9627 (1.0047) acc 90.6250 (91.8750) gate/entropy 0.9945 (0.9947) gate/usage_max 0.5561 (0.5558) gate/usage_min 0.2199 (0.2199) gate/usage_std 0.1575 (0.1573) teacher/entropy 0.0803 (0.0351) teacher/usage_max 0.5052 (0.5249) teacher/usage_min 0.0912 (0.1191) teacher/usage_std 0.1762 (0.1717) nleep/row_max_mean 1568.1915 (1566.6311) nleep/row_max_std 52.1891 (55.2043) nleep/row_min_mean 1532.0762 (1528.9857) lr 1.6374e-03 eta 0:16:17
epoch [16/50] batch [40/167] time 0.135 (0.161) data 0.000 (0.007) loss 1.5294 (1.4578) teacher_loss 0.3149 (0.1892) loss_zs_kd 0.0417 (0.0366) loss_oracle 0.6099 (0.5316) kd_loss 0.8887 (0.9845) acc 87.5000 (92.1094) gate/entropy 0.9944 (0.9948) gate/usage_max 0.5562 (0.5557) gate/usage_min 0.2200 (0.2200) gate/usage_std 0.1576 (0.1573) teacher/entropy 0.0272 (0.0420) teacher/usage_max 0.6389 (0.5324) teacher/usage_min 0.1566 (0.1126) teacher/usage_std 0.2170 (0.1784) nleep/row_max_mean 1577.3691 (1563.4535) nleep/row_max_std 69.1573 (55.4014) nleep/row_min_mean 1531.0236 (1525.6985) lr 1.6374e-03 eta 0:15:36
epoch [16/50] batch [60/167] time 0.155 (0.154) data 0.000 (0.005) loss 1.5276 (1.4634) teacher_loss 0.2314 (0.2134) loss_zs_kd 0.0449 (0.0369) loss_oracle 0.5425 (0.5235) kd_loss 1.0024 (0.9697) acc 90.6250 (90.9896) gate/entropy 0.9939 (0.9947) gate/usage_max 0.5567 (0.5559) gate/usage_min 0.2199 (0.2201) gate/usage_std 0.1580 (0.1574) teacher/entropy 0.0316 (0.0421) teacher/usage_max 0.5127 (0.5456) teacher/usage_min 0.1563 (0.1155) teacher/usage_std 0.1455 (0.1827) nleep/row_max_mean 1578.1976 (1563.5732) nleep/row_max_std 40.0298 (56.2730) nleep/row_min_mean 1537.7185 (1525.6843) lr 1.6374e-03 eta 0:14:50
epoch [16/50] batch [80/167] time 0.169 (0.155) data 0.000 (0.004) loss 1.4984 (1.4576) teacher_loss 0.2592 (0.2239) loss_zs_kd 0.0312 (0.0391) loss_oracle 0.5241 (0.5166) kd_loss 0.9616 (0.9559) acc 93.7500 (90.9375) gate/entropy 0.9954 (0.9947) gate/usage_max 0.5551 (0.5559) gate/usage_min 0.2208 (0.2201) gate/usage_std 0.1568 (0.1574) teacher/entropy 0.0899 (0.0415) teacher/usage_max 0.4930 (0.5595) teacher/usage_min 0.1812 (0.1195) teacher/usage_std 0.1274 (0.1874) nleep/row_max_mean 1537.4517 (1562.5640) nleep/row_max_std 51.9224 (56.2901) nleep/row_min_mean 1505.9316 (1524.5635) lr 1.6374e-03 eta 0:14:55
epoch [16/50] batch [100/167] time 0.098 (0.153) data 0.000 (0.003) loss 1.3806 (1.4411) teacher_loss 0.3566 (0.2234) loss_zs_kd 0.0329 (0.0394) loss_oracle 0.3857 (0.5074) kd_loss 0.8148 (0.9443) acc 87.5000 (91.0625) gate/entropy 0.9943 (0.9946) gate/usage_max 0.5563 (0.5560) gate/usage_min 0.2203 (0.2201) gate/usage_std 0.1577 (0.1575) teacher/entropy 0.0461 (0.0421) teacher/usage_max 0.6998 (0.5701) teacher/usage_min 0.1281 (0.1172) teacher/usage_std 0.2597 (0.1928) nleep/row_max_mean 1550.0487 (1560.8375) nleep/row_max_std 56.9768 (55.2462) nleep/row_min_mean 1516.2306 (1522.9017) lr 1.6374e-03 eta 0:14:41
epoch [16/50] batch [120/167] time 0.090 (0.144) data 0.000 (0.003) loss 1.4151 (1.4244) teacher_loss 0.3225 (0.2215) loss_zs_kd 0.0283 (0.0383) loss_oracle 0.5490 (0.4995) kd_loss 0.8040 (0.9340) acc 84.3750 (91.1719) gate/entropy 0.9933 (0.9945) gate/usage_max 0.5575 (0.5561) gate/usage_min 0.2199 (0.2202) gate/usage_std 0.1585 (0.1575) teacher/entropy 0.0195 (0.0423) teacher/usage_max 0.7415 (0.5801) teacher/usage_min 0.0312 (0.1161) teacher/usage_std 0.2995 (0.1977) nleep/row_max_mean 1564.3749 (1559.7311) nleep/row_max_std 59.1533 (55.6834) nleep/row_min_mean 1517.2893 (1521.6925) lr 1.6374e-03 eta 0:13:46
epoch [16/50] batch [140/167] time 0.061 (0.140) data 0.000 (0.002) loss 1.3746 (1.4141) teacher_loss 0.1662 (0.2187) loss_zs_kd 0.0299 (0.0383) loss_oracle 0.5733 (0.4997) kd_loss 0.9067 (0.9264) acc 93.7500 (91.3616) gate/entropy 0.9939 (0.9944) gate/usage_max 0.5568 (0.5562) gate/usage_min 0.2203 (0.2202) gate/usage_std 0.1580 (0.1576) teacher/entropy 0.0439 (0.0432) teacher/usage_max 0.6026 (0.5867) teacher/usage_min 0.1252 (0.1155) teacher/usage_std 0.1996 (0.2011) nleep/row_max_mean 1540.2576 (1558.7087) nleep/row_max_std 71.0727 (55.6943) nleep/row_min_mean 1505.1619 (1520.7962) lr 1.6374e-03 eta 0:13:16
epoch [16/50] batch [160/167] time 0.061 (0.136) data 0.000 (0.002) loss 1.4754 (1.4082) teacher_loss 0.3246 (0.2197) loss_zs_kd 0.0306 (0.0382) loss_oracle 0.5114 (0.4982) kd_loss 0.8798 (0.9203) acc 87.5000 (91.2891) gate/entropy 0.9932 (0.9943) gate/usage_max 0.5575 (0.5563) gate/usage_min 0.2201 (0.2202) gate/usage_std 0.1585 (0.1577) teacher/entropy 0.0161 (0.0433) teacher/usage_max 0.6619 (0.5927) teacher/usage_min 0.1562 (0.1167) teacher/usage_std 0.2326 (0.2038) nleep/row_max_mean 1558.4307 (1557.7055) nleep/row_max_std 58.4535 (56.0223) nleep/row_min_mean 1515.2944 (1519.8333) lr 1.6374e-03 eta 0:12:51
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,199
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,325
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
******* Domain c best val acc:      96.2%, epoch: 7 *******
******* Domain c best val test acc: 99.1%, epoch: 7 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [17/50] batch [20/167] time 0.071 (0.134) data 0.000 (0.018) loss 1.4414 (1.2947) teacher_loss 0.2779 (0.2125) loss_zs_kd 0.0372 (0.0345) loss_oracle 0.5574 (0.5042) kd_loss 0.8661 (0.8129) acc 84.3750 (92.6562) gate/entropy 0.9931 (0.9932) gate/usage_max 0.5576 (0.5575) gate/usage_min 0.2201 (0.2201) gate/usage_std 0.1586 (0.1585) teacher/entropy 0.0598 (0.0632) teacher/usage_max 0.6287 (0.6830) teacher/usage_min 0.1246 (0.1186) teacher/usage_std 0.2147 (0.2509) nleep/row_max_mean 1549.4396 (1554.8830) nleep/row_max_std 53.1513 (54.5542) nleep/row_min_mean 1513.1245 (1516.0767) lr 1.5878e-03 eta 0:12:39
epoch [17/50] batch [40/167] time 0.100 (0.123) data 0.000 (0.009) loss 1.2410 (1.2938) teacher_loss 0.1594 (0.2371) loss_zs_kd 0.0220 (0.0352) loss_oracle 0.4956 (0.5005) kd_loss 0.8228 (0.7889) acc 93.7500 (91.5625) gate/entropy 0.9927 (0.9930) gate/usage_max 0.5580 (0.5577) gate/usage_min 0.2199 (0.2200) gate/usage_std 0.1589 (0.1587) teacher/entropy 0.0441 (0.0592) teacher/usage_max 0.6923 (0.7131) teacher/usage_min 0.1500 (0.1070) teacher/usage_std 0.2539 (0.2716) nleep/row_max_mean 1557.9027 (1556.1846) nleep/row_max_std 56.6084 (54.1211) nleep/row_min_mean 1519.4727 (1516.2772) lr 1.5878e-03 eta 0:11:31
epoch [17/50] batch [60/167] time 0.090 (0.121) data 0.001 (0.006) loss 1.2994 (1.2864) teacher_loss 0.1890 (0.2424) loss_zs_kd 0.0440 (0.0343) loss_oracle 0.4291 (0.4995) kd_loss 0.8738 (0.7771) acc 93.7500 (91.3021) gate/entropy 0.9927 (0.9929) gate/usage_max 0.5581 (0.5578) gate/usage_min 0.2199 (0.2200) gate/usage_std 0.1589 (0.1587) teacher/entropy 0.0802 (0.0581) teacher/usage_max 0.5987 (0.7269) teacher/usage_min 0.1562 (0.1021) teacher/usage_std 0.1911 (0.2808) nleep/row_max_mean 1548.6091 (1555.6405) nleep/row_max_std 54.2534 (54.3767) nleep/row_min_mean 1513.4263 (1515.8990) lr 1.5878e-03 eta 0:11:22
epoch [17/50] batch [80/167] time 0.082 (0.119) data 0.000 (0.005) loss 1.3036 (1.2911) teacher_loss 0.3441 (0.2609) loss_zs_kd 0.0453 (0.0334) loss_oracle 0.4816 (0.4976) kd_loss 0.6961 (0.7647) acc 84.3750 (90.3516) gate/entropy 0.9920 (0.9927) gate/usage_max 0.5589 (0.5580) gate/usage_min 0.2196 (0.2199) gate/usage_std 0.1595 (0.1589) teacher/entropy 0.0877 (0.0555) teacher/usage_max 0.7803 (0.7429) teacher/usage_min 0.1074 (0.0961) teacher/usage_std 0.3160 (0.2918) nleep/row_max_mean 1561.3875 (1557.3072) nleep/row_max_std 55.4071 (54.7301) nleep/row_min_mean 1518.5750 (1516.5795) lr 1.5878e-03 eta 0:11:06
epoch [17/50] batch [100/167] time 0.146 (0.123) data 0.000 (0.004) loss 1.1511 (1.2824) teacher_loss 0.1280 (0.2603) loss_zs_kd 0.0154 (0.0341) loss_oracle 0.4619 (0.4996) kd_loss 0.7845 (0.7552) acc 93.7500 (90.4375) gate/entropy 0.9919 (0.9925) gate/usage_max 0.5589 (0.5583) gate/usage_min 0.2196 (0.2198) gate/usage_std 0.1595 (0.1590) teacher/entropy 0.0490 (0.0514) teacher/usage_max 0.7255 (0.7571) teacher/usage_min 0.0477 (0.0877) teacher/usage_std 0.2868 (0.3020) nleep/row_max_mean 1560.2068 (1558.2021) nleep/row_max_std 57.5877 (55.2082) nleep/row_min_mean 1516.8124 (1516.7618) lr 1.5878e-03 eta 0:11:23
epoch [17/50] batch [120/167] time 0.155 (0.128) data 0.000 (0.003) loss 1.2769 (1.2878) teacher_loss 0.3569 (0.2770) loss_zs_kd 0.0186 (0.0332) loss_oracle 0.5171 (0.5000) kd_loss 0.6522 (0.7441) acc 87.5000 (89.7656) gate/entropy 0.9915 (0.9923) gate/usage_max 0.5594 (0.5585) gate/usage_min 0.2194 (0.2198) gate/usage_std 0.1598 (0.1592) teacher/entropy 0.0329 (0.0484) teacher/usage_max 0.8875 (0.7721) teacher/usage_min 0.0313 (0.0814) teacher/usage_std 0.3924 (0.3124) nleep/row_max_mean 1552.1318 (1557.5917) nleep/row_max_std 51.9530 (55.6065) nleep/row_min_mean 1504.9839 (1515.6700) lr 1.5878e-03 eta 0:11:49
epoch [17/50] batch [140/167] time 0.145 (0.133) data 0.000 (0.003) loss 1.3439 (1.2895) teacher_loss 0.3635 (0.2824) loss_zs_kd 0.0237 (0.0317) loss_oracle 0.4784 (0.5026) kd_loss 0.7294 (0.7400) acc 87.5000 (89.5312) gate/entropy 0.9909 (0.9921) gate/usage_max 0.5600 (0.5587) gate/usage_min 0.2191 (0.2197) gate/usage_std 0.1603 (0.1593) teacher/entropy 0.0634 (0.0457) teacher/usage_max 0.7714 (0.7792) teacher/usage_min 0.1085 (0.0769) teacher/usage_std 0.3098 (0.3175) nleep/row_max_mean 1547.3953 (1557.2663) nleep/row_max_std 53.9977 (55.4400) nleep/row_min_mean 1504.6765 (1515.2197) lr 1.5878e-03 eta 0:12:14
epoch [17/50] batch [160/167] time 0.164 (0.136) data 0.000 (0.002) loss 1.1464 (1.2860) teacher_loss 0.1950 (0.2835) loss_zs_kd 0.0176 (0.0300) loss_oracle 0.5053 (0.5015) kd_loss 0.6899 (0.7368) acc 93.7500 (89.4141) gate/entropy 0.9897 (0.9919) gate/usage_max 0.5613 (0.5589) gate/usage_min 0.2185 (0.2196) gate/usage_std 0.1612 (0.1595) teacher/entropy 0.0046 (0.0420) teacher/usage_max 0.8740 (0.7864) teacher/usage_min 0.0010 (0.0714) teacher/usage_std 0.3857 (0.3227) nleep/row_max_mean 1572.6548 (1557.4977) nleep/row_max_std 41.5229 (55.3710) nleep/row_min_mean 1530.5156 (1515.2601) lr 1.5878e-03 eta 0:12:29
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,201
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.2%, epoch: 7 *******
******* Domain c best val test acc: 99.1%, epoch: 7 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [18/50] batch [20/167] time 0.079 (0.152) data 0.000 (0.017) loss 1.2154 (1.2124) teacher_loss 0.2372 (0.2824) loss_zs_kd 0.0202 (0.0208) loss_oracle 0.4612 (0.4860) kd_loss 0.7375 (0.6767) acc 90.6250 (89.0625) gate/entropy 0.9898 (0.9900) gate/usage_max 0.5612 (0.5610) gate/usage_min 0.2185 (0.2186) gate/usage_std 0.1611 (0.1610) teacher/entropy 0.0127 (0.0166) teacher/usage_max 0.8133 (0.8753) teacher/usage_min 0.0000 (0.0105) teacher/usage_std 0.3479 (0.3866) nleep/row_max_mean 1563.0955 (1563.3542) nleep/row_max_std 53.0880 (57.1282) nleep/row_min_mean 1518.2391 (1516.4070) lr 1.5358e-03 eta 0:13:54
epoch [18/50] batch [40/167] time 0.109 (0.130) data 0.000 (0.009) loss 1.6506 (1.2526) teacher_loss 0.6823 (0.3066) loss_zs_kd 0.0393 (0.0201) loss_oracle 0.5331 (0.4950) kd_loss 0.6821 (0.6884) acc 68.7500 (88.2812) gate/entropy 0.9892 (0.9898) gate/usage_max 0.5618 (0.5612) gate/usage_min 0.2182 (0.2185) gate/usage_std 0.1615 (0.1611) teacher/entropy 0.0224 (0.0193) teacher/usage_max 0.8611 (0.8594) teacher/usage_min 0.0001 (0.0116) teacher/usage_std 0.3775 (0.3760) nleep/row_max_mean 1575.9946 (1564.3561) nleep/row_max_std 72.0990 (60.1666) nleep/row_min_mean 1520.1154 (1516.6904) lr 1.5358e-03 eta 0:11:49
epoch [18/50] batch [60/167] time 0.074 (0.127) data 0.000 (0.006) loss 1.3222 (1.2460) teacher_loss 0.3251 (0.2998) loss_zs_kd 0.0128 (0.0191) loss_oracle 0.5391 (0.4950) kd_loss 0.7212 (0.6891) acc 87.5000 (88.5938) gate/entropy 0.9895 (0.9896) gate/usage_max 0.5615 (0.5614) gate/usage_min 0.2184 (0.2184) gate/usage_std 0.1613 (0.1612) teacher/entropy 0.0000 (0.0181) teacher/usage_max 0.8438 (0.8598) teacher/usage_min 0.0000 (0.0120) teacher/usage_std 0.3665 (0.3762) nleep/row_max_mean 1543.5781 (1563.2220) nleep/row_max_std 73.5196 (61.1157) nleep/row_min_mean 1496.4980 (1515.7179) lr 1.5358e-03 eta 0:11:31
epoch [18/50] batch [80/167] time 0.075 (0.114) data 0.000 (0.004) loss 1.3599 (1.2403) teacher_loss 0.3274 (0.2876) loss_zs_kd 0.0143 (0.0192) loss_oracle 0.4947 (0.4960) kd_loss 0.7780 (0.6951) acc 87.5000 (88.9062) gate/entropy 0.9890 (0.9895) gate/usage_max 0.5620 (0.5615) gate/usage_min 0.2181 (0.2183) gate/usage_std 0.1617 (0.1614) teacher/entropy 0.0021 (0.0155) teacher/usage_max 0.7809 (0.8559) teacher/usage_min 0.0004 (0.0116) teacher/usage_std 0.3288 (0.3739) nleep/row_max_mean 1549.4727 (1562.9214) nleep/row_max_std 70.7990 (61.7379) nleep/row_min_mean 1503.7352 (1515.7064) lr 1.5358e-03 eta 0:10:20
epoch [18/50] batch [100/167] time 0.058 (0.112) data 0.000 (0.004) loss 1.2363 (1.2443) teacher_loss 0.2476 (0.2891) loss_zs_kd 0.0147 (0.0194) loss_oracle 0.5425 (0.4973) kd_loss 0.7100 (0.6968) acc 90.6250 (88.8750) gate/entropy 0.9890 (0.9893) gate/usage_max 0.5620 (0.5617) gate/usage_min 0.2181 (0.2183) gate/usage_std 0.1617 (0.1615) teacher/entropy 0.0089 (0.0139) teacher/usage_max 0.8456 (0.8556) teacher/usage_min 0.0002 (0.0107) teacher/usage_std 0.3676 (0.3740) nleep/row_max_mean 1547.0968 (1562.3995) nleep/row_max_std 66.4311 (62.3417) nleep/row_min_mean 1503.9846 (1515.4792) lr 1.5358e-03 eta 0:10:08
epoch [18/50] batch [120/167] time 0.151 (0.108) data 0.000 (0.003) loss 1.1611 (1.2485) teacher_loss 0.2243 (0.2909) loss_zs_kd 0.0161 (0.0196) loss_oracle 0.5332 (0.4999) kd_loss 0.6621 (0.6979) acc 90.6250 (88.8281) gate/entropy 0.9882 (0.9892) gate/usage_max 0.5628 (0.5619) gate/usage_min 0.2177 (0.2182) gate/usage_std 0.1623 (0.1616) teacher/entropy 0.0001 (0.0125) teacher/usage_max 0.9062 (0.8558) teacher/usage_min 0.0000 (0.0107) teacher/usage_std 0.4069 (0.3741) nleep/row_max_mean 1550.1179 (1561.6705) nleep/row_max_std 79.0248 (62.9961) nleep/row_min_mean 1501.9036 (1514.9967) lr 1.5358e-03 eta 0:09:44
epoch [18/50] batch [140/167] time 0.122 (0.108) data 0.000 (0.003) loss 1.4287 (1.2614) teacher_loss 0.4355 (0.3016) loss_zs_kd 0.0277 (0.0203) loss_oracle 0.5202 (0.5019) kd_loss 0.7192 (0.6987) acc 81.2500 (88.4821) gate/entropy 0.9880 (0.9890) gate/usage_max 0.5630 (0.5620) gate/usage_min 0.2176 (0.2181) gate/usage_std 0.1624 (0.1617) teacher/entropy 0.0000 (0.0116) teacher/usage_max 0.8437 (0.8557) teacher/usage_min 0.0000 (0.0102) teacher/usage_std 0.3665 (0.3741) nleep/row_max_mean 1560.4996 (1560.6947) nleep/row_max_std 47.4711 (63.1432) nleep/row_min_mean 1519.6656 (1514.4452) lr 1.5358e-03 eta 0:09:41
epoch [18/50] batch [160/167] time 0.071 (0.109) data 0.000 (0.002) loss 1.1708 (1.2568) teacher_loss 0.2064 (0.2990) loss_zs_kd 0.0253 (0.0199) loss_oracle 0.5207 (0.5029) kd_loss 0.6914 (0.6965) acc 93.7500 (88.6133) gate/entropy 0.9879 (0.9889) gate/usage_max 0.5632 (0.5622) gate/usage_min 0.2175 (0.2180) gate/usage_std 0.1625 (0.1618) teacher/entropy 0.0001 (0.0116) teacher/usage_max 0.8750 (0.8578) teacher/usage_min 0.0313 (0.0096) teacher/usage_std 0.3839 (0.3755) nleep/row_max_mean 1545.6865 (1560.2979) nleep/row_max_std 70.2923 (62.6692) nleep/row_min_mean 1499.3063 (1514.1706) lr 1.5358e-03 eta 0:09:41
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,199
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.2%, epoch: 7 *******
******* Domain c best val test acc: 99.1%, epoch: 7 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [19/50] batch [20/167] time 0.179 (0.168) data 0.000 (0.014) loss 1.0973 (1.2404) teacher_loss 0.1947 (0.3054) loss_zs_kd 0.0073 (0.0165) loss_oracle 0.5392 (0.4999) kd_loss 0.6293 (0.6768) acc 96.8750 (87.1875) gate/entropy 0.9874 (0.9873) gate/usage_max 0.5637 (0.5638) gate/usage_min 0.2173 (0.2172) gate/usage_std 0.1629 (0.1630) teacher/entropy 0.0021 (0.0144) teacher/usage_max 0.9371 (0.8739) teacher/usage_min 0.0004 (0.0083) teacher/usage_std 0.4277 (0.3855) nleep/row_max_mean 1554.9619 (1562.0075) nleep/row_max_std 72.9834 (60.2498) nleep/row_min_mean 1507.2177 (1514.8461) lr 1.4818e-03 eta 0:14:56
epoch [19/50] batch [40/167] time 0.151 (0.163) data 0.000 (0.007) loss 1.4331 (1.2570) teacher_loss 0.5663 (0.3121) loss_zs_kd 0.0318 (0.0185) loss_oracle 0.5024 (0.5046) kd_loss 0.5996 (0.6834) acc 78.1250 (87.3438) gate/entropy 0.9863 (0.9872) gate/usage_max 0.5649 (0.5639) gate/usage_min 0.2167 (0.2172) gate/usage_std 0.1637 (0.1630) teacher/entropy 0.0005 (0.0125) teacher/usage_max 0.9687 (0.8687) teacher/usage_min 0.0001 (0.0098) teacher/usage_std 0.4494 (0.3822) nleep/row_max_mean 1577.2014 (1560.3771) nleep/row_max_std 58.1951 (62.0934) nleep/row_min_mean 1526.5488 (1513.4782) lr 1.4818e-03 eta 0:14:25
epoch [19/50] batch [60/167] time 0.142 (0.158) data 0.000 (0.005) loss 1.2599 (1.2459) teacher_loss 0.2619 (0.3046) loss_zs_kd 0.0277 (0.0202) loss_oracle 0.4866 (0.5071) kd_loss 0.7408 (0.6777) acc 87.5000 (88.1250) gate/entropy 0.9868 (0.9871) gate/usage_max 0.5643 (0.5641) gate/usage_min 0.2170 (0.2171) gate/usage_std 0.1633 (0.1631) teacher/entropy 0.0058 (0.0123) teacher/usage_max 0.8139 (0.8748) teacher/usage_min 0.0000 (0.0073) teacher/usage_std 0.3482 (0.3864) nleep/row_max_mean 1569.0439 (1562.1356) nleep/row_max_std 54.9176 (60.7091) nleep/row_min_mean 1522.8715 (1514.7920) lr 1.4818e-03 eta 0:13:52
epoch [19/50] batch [80/167] time 0.148 (0.156) data 0.000 (0.004) loss 1.1836 (1.2373) teacher_loss 0.2602 (0.2987) loss_zs_kd 0.0107 (0.0198) loss_oracle 0.4605 (0.5043) kd_loss 0.6877 (0.6765) acc 93.7500 (88.4375) gate/entropy 0.9862 (0.9869) gate/usage_max 0.5650 (0.5642) gate/usage_min 0.2167 (0.2170) gate/usage_std 0.1638 (0.1633) teacher/entropy 0.0007 (0.0113) teacher/usage_max 0.8751 (0.8768) teacher/usage_min 0.0312 (0.0072) teacher/usage_std 0.3839 (0.3880) nleep/row_max_mean 1570.4459 (1563.2725) nleep/row_max_std 57.8394 (60.6198) nleep/row_min_mean 1523.2759 (1515.8667) lr 1.4818e-03 eta 0:13:43
epoch [19/50] batch [100/167] time 0.138 (0.153) data 0.000 (0.003) loss 1.4069 (1.2359) teacher_loss 0.4549 (0.2981) loss_zs_kd 0.0207 (0.0196) loss_oracle 0.4792 (0.5007) kd_loss 0.7020 (0.6777) acc 84.3750 (88.3750) gate/entropy 0.9864 (0.9868) gate/usage_max 0.5647 (0.5644) gate/usage_min 0.2168 (0.2170) gate/usage_std 0.1636 (0.1634) teacher/entropy 0.0122 (0.0115) teacher/usage_max 0.8479 (0.8753) teacher/usage_min 0.0000 (0.0091) teacher/usage_std 0.3691 (0.3869) nleep/row_max_mean 1560.3823 (1562.2782) nleep/row_max_std 57.9991 (61.4312) nleep/row_min_mean 1509.3912 (1515.2211) lr 1.4818e-03 eta 0:13:23
epoch [19/50] batch [120/167] time 0.088 (0.149) data 0.000 (0.002) loss 1.2290 (1.2414) teacher_loss 0.3012 (0.2976) loss_zs_kd 0.0236 (0.0197) loss_oracle 0.4787 (0.5024) kd_loss 0.6766 (0.6827) acc 84.3750 (88.5938) gate/entropy 0.9862 (0.9867) gate/usage_max 0.5650 (0.5644) gate/usage_min 0.2167 (0.2169) gate/usage_std 0.1638 (0.1634) teacher/entropy 0.0095 (0.0114) teacher/usage_max 0.8776 (0.8699) teacher/usage_min 0.0001 (0.0094) teacher/usage_std 0.3881 (0.3833) nleep/row_max_mean 1548.7651 (1560.7279) nleep/row_max_std 71.6815 (61.9607) nleep/row_min_mean 1507.9985 (1514.3148) lr 1.4818e-03 eta 0:13:00
epoch [19/50] batch [140/167] time 0.182 (0.144) data 0.000 (0.002) loss 1.1241 (1.2441) teacher_loss 0.1849 (0.2965) loss_zs_kd 0.0191 (0.0195) loss_oracle 0.5031 (0.5027) kd_loss 0.6781 (0.6865) acc 90.6250 (88.7277) gate/entropy 0.9857 (0.9866) gate/usage_max 0.5655 (0.5645) gate/usage_min 0.2164 (0.2169) gate/usage_std 0.1642 (0.1635) teacher/entropy 0.0162 (0.0113) teacher/usage_max 0.8684 (0.8659) teacher/usage_min 0.0000 (0.0101) teacher/usage_std 0.3821 (0.3807) nleep/row_max_mean 1562.1597 (1559.2490) nleep/row_max_std 62.7745 (62.4756) nleep/row_min_mean 1522.4963 (1513.5261) lr 1.4818e-03 eta 0:12:30
epoch [19/50] batch [160/167] time 0.073 (0.139) data 0.000 (0.002) loss 0.8959 (1.2406) teacher_loss 0.0688 (0.2919) loss_zs_kd 0.0080 (0.0198) loss_oracle 0.4678 (0.5032) kd_loss 0.5892 (0.6872) acc 100.0000 (88.8672) gate/entropy 0.9857 (0.9865) gate/usage_max 0.5655 (0.5646) gate/usage_min 0.2164 (0.2168) gate/usage_std 0.1642 (0.1636) teacher/entropy 0.0154 (0.0114) teacher/usage_max 0.9630 (0.8650) teacher/usage_min 0.0057 (0.0106) teacher/usage_std 0.4454 (0.3800) nleep/row_max_mean 1563.1909 (1558.6452) nleep/row_max_std 62.2177 (62.0399) nleep/row_min_mean 1518.6108 (1513.4775) lr 1.4818e-03 eta 0:11:58
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,212
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.0%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [20/50] batch [20/167] time 0.086 (0.121) data 0.000 (0.014) loss 1.2274 (1.2172) teacher_loss 0.3044 (0.2606) loss_zs_kd 0.0214 (0.0203) loss_oracle 0.4583 (0.5001) kd_loss 0.6832 (0.6964) acc 87.5000 (89.0625) gate/entropy 0.9855 (0.9855) gate/usage_max 0.5657 (0.5657) gate/usage_min 0.2163 (0.2164) gate/usage_std 0.1643 (0.1643) teacher/entropy 0.0227 (0.0206) teacher/usage_max 0.8565 (0.8447) teacher/usage_min 0.0002 (0.0256) teacher/usage_std 0.3745 (0.3652) nleep/row_max_mean 1562.5286 (1555.5573) nleep/row_max_std 56.0474 (59.9978) nleep/row_min_mean 1520.2759 (1514.8851) lr 1.4258e-03 eta 0:10:22
epoch [20/50] batch [40/167] time 0.097 (0.112) data 0.000 (0.007) loss 1.3340 (1.2414) teacher_loss 0.3907 (0.2663) loss_zs_kd 0.0261 (0.0239) loss_oracle 0.4851 (0.5059) kd_loss 0.6877 (0.7102) acc 84.3750 (89.6094) gate/entropy 0.9859 (0.9855) gate/usage_max 0.5653 (0.5657) gate/usage_min 0.2165 (0.2164) gate/usage_std 0.1641 (0.1643) teacher/entropy 0.0011 (0.0190) teacher/usage_max 0.8748 (0.8317) teacher/usage_min 0.0002 (0.0364) teacher/usage_std 0.3863 (0.3561) nleep/row_max_mean 1526.6970 (1553.6269) nleep/row_max_std 74.1873 (61.9165) nleep/row_min_mean 1487.8005 (1512.8938) lr 1.4258e-03 eta 0:09:33
epoch [20/50] batch [60/167] time 0.175 (0.114) data 0.000 (0.005) loss 1.3207 (1.2648) teacher_loss 0.2968 (0.2691) loss_zs_kd 0.0270 (0.0274) loss_oracle 0.4697 (0.5151) kd_loss 0.7756 (0.7245) acc 87.5000 (89.3229) gate/entropy 0.9852 (0.9854) gate/usage_max 0.5660 (0.5658) gate/usage_min 0.2162 (0.2163) gate/usage_std 0.1645 (0.1644) teacher/entropy 0.0027 (0.0216) teacher/usage_max 0.7812 (0.8140) teacher/usage_min 0.0625 (0.0473) teacher/usage_std 0.3190 (0.3434) nleep/row_max_mean 1549.0908 (1554.1731) nleep/row_max_std 53.8017 (61.0345) nleep/row_min_mean 1509.8486 (1513.6714) lr 1.4258e-03 eta 0:09:45
epoch [20/50] batch [80/167] time 0.089 (0.112) data 0.000 (0.004) loss 1.3040 (1.2601) teacher_loss 0.2699 (0.2644) loss_zs_kd 0.0231 (0.0283) loss_oracle 0.4765 (0.5139) kd_loss 0.7843 (0.7246) acc 90.6250 (89.8047) gate/entropy 0.9851 (0.9853) gate/usage_max 0.5661 (0.5659) gate/usage_min 0.2162 (0.2163) gate/usage_std 0.1646 (0.1644) teacher/entropy 0.0204 (0.0233) teacher/usage_max 0.7536 (0.8122) teacher/usage_min 0.0336 (0.0486) teacher/usage_std 0.3061 (0.3419) nleep/row_max_mean 1557.2321 (1554.3047) nleep/row_max_std 71.1606 (61.3907) nleep/row_min_mean 1516.0551 (1513.9597) lr 1.4258e-03 eta 0:09:32
epoch [20/50] batch [100/167] time 0.189 (0.109) data 0.000 (0.003) loss 1.1924 (1.2598) teacher_loss 0.2578 (0.2610) loss_zs_kd 0.0211 (0.0293) loss_oracle 0.4467 (0.5156) kd_loss 0.7008 (0.7263) acc 90.6250 (89.8750) gate/entropy 0.9855 (0.9853) gate/usage_max 0.5657 (0.5659) gate/usage_min 0.2163 (0.2162) gate/usage_std 0.1643 (0.1645) teacher/entropy 0.0161 (0.0246) teacher/usage_max 0.8449 (0.8090) teacher/usage_min 0.0301 (0.0513) teacher/usage_std 0.3638 (0.3394) nleep/row_max_mean 1541.4412 (1553.9640) nleep/row_max_std 69.3870 (61.0519) nleep/row_min_mean 1501.7334 (1513.8748) lr 1.4258e-03 eta 0:09:11
epoch [20/50] batch [120/167] time 0.109 (0.112) data 0.000 (0.002) loss 1.3649 (1.2604) teacher_loss 0.2446 (0.2548) loss_zs_kd 0.0408 (0.0293) loss_oracle 0.5469 (0.5161) kd_loss 0.8264 (0.7329) acc 90.6250 (90.1042) gate/entropy 0.9847 (0.9852) gate/usage_max 0.5665 (0.5660) gate/usage_min 0.2160 (0.2162) gate/usage_std 0.1649 (0.1645) teacher/entropy 0.0545 (0.0265) teacher/usage_max 0.6720 (0.8001) teacher/usage_min 0.0467 (0.0574) teacher/usage_std 0.2579 (0.3330) nleep/row_max_mean 1549.8011 (1554.5723) nleep/row_max_std 59.0921 (60.6315) nleep/row_min_mean 1512.1375 (1514.6552) lr 1.4258e-03 eta 0:09:24
epoch [20/50] batch [140/167] time 0.147 (0.114) data 0.000 (0.002) loss 1.2874 (1.2602) teacher_loss 0.3074 (0.2466) loss_zs_kd 0.0403 (0.0299) loss_oracle 0.5060 (0.5173) kd_loss 0.7069 (0.7400) acc 87.5000 (90.5357) gate/entropy 0.9843 (0.9851) gate/usage_max 0.5670 (0.5661) gate/usage_min 0.2158 (0.2162) gate/usage_std 0.1652 (0.1646) teacher/entropy 0.0212 (0.0268) teacher/usage_max 0.8314 (0.7923) teacher/usage_min 0.0436 (0.0631) teacher/usage_std 0.3537 (0.3273) nleep/row_max_mean 1561.0576 (1554.6256) nleep/row_max_std 66.3143 (59.8573) nleep/row_min_mean 1523.7128 (1515.1240) lr 1.4258e-03 eta 0:09:35
epoch [20/50] batch [160/167] time 0.118 (0.118) data 0.000 (0.002) loss 1.0799 (1.2621) teacher_loss 0.0912 (0.2454) loss_zs_kd 0.0186 (0.0313) loss_oracle 0.4959 (0.5151) kd_loss 0.7315 (0.7435) acc 96.8750 (90.4883) gate/entropy 0.9845 (0.9851) gate/usage_max 0.5667 (0.5662) gate/usage_min 0.2159 (0.2162) gate/usage_std 0.1650 (0.1646) teacher/entropy 0.0250 (0.0277) teacher/usage_max 0.8023 (0.7877) teacher/usage_min 0.0937 (0.0658) teacher/usage_std 0.3316 (0.3241) nleep/row_max_mean 1565.0078 (1554.1052) nleep/row_max_std 52.7503 (59.3306) nleep/row_min_mean 1525.1689 (1515.1038) lr 1.4258e-03 eta 0:09:50
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,208
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 96.6%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,318
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 98.8%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [21/50] batch [20/167] time 0.169 (0.153) data 0.000 (0.015) loss 1.1919 (1.2365) teacher_loss 0.2648 (0.1917) loss_zs_kd 0.0367 (0.0323) loss_oracle 0.4860 (0.4937) kd_loss 0.6657 (0.7819) acc 90.6250 (92.8125) gate/entropy 0.9843 (0.9845) gate/usage_max 0.5670 (0.5668) gate/usage_min 0.2158 (0.2159) gate/usage_std 0.1652 (0.1651) teacher/entropy 0.0925 (0.0440) teacher/usage_max 0.8012 (0.7308) teacher/usage_min 0.0947 (0.0976) teacher/usage_std 0.3309 (0.2834) nleep/row_max_mean 1557.0431 (1553.4133) nleep/row_max_std 62.7297 (53.8636) nleep/row_min_mean 1526.2145 (1519.2068) lr 1.3681e-03 eta 0:12:43
epoch [21/50] batch [40/167] time 0.158 (0.153) data 0.000 (0.008) loss 1.3972 (1.2771) teacher_loss 0.3190 (0.2129) loss_zs_kd 0.0619 (0.0362) loss_oracle 0.4886 (0.5014) kd_loss 0.8029 (0.7954) acc 87.5000 (92.0312) gate/entropy 0.9841 (0.9844) gate/usage_max 0.5671 (0.5669) gate/usage_min 0.2158 (0.2159) gate/usage_std 0.1653 (0.1651) teacher/entropy 0.0317 (0.0395) teacher/usage_max 0.7215 (0.7215) teacher/usage_min 0.1246 (0.0993) teacher/usage_std 0.2747 (0.2777) nleep/row_max_mean 1552.7402 (1554.7118) nleep/row_max_std 51.6528 (53.3397) nleep/row_min_mean 1515.2483 (1520.1089) lr 1.3681e-03 eta 0:12:40
epoch [21/50] batch [60/167] time 0.105 (0.140) data 0.000 (0.005) loss 1.1948 (1.2854) teacher_loss 0.2298 (0.2022) loss_zs_kd 0.0479 (0.0345) loss_oracle 0.4829 (0.5113) kd_loss 0.6996 (0.8104) acc 87.5000 (92.2396) gate/entropy 0.9843 (0.9844) gate/usage_max 0.5670 (0.5669) gate/usage_min 0.2158 (0.2159) gate/usage_std 0.1652 (0.1651) teacher/entropy 0.0244 (0.0344) teacher/usage_max 0.8369 (0.7111) teacher/usage_min 0.0686 (0.1049) teacher/usage_std 0.3562 (0.2703) nleep/row_max_mean 1556.0173 (1553.1236) nleep/row_max_std 44.8557 (55.4735) nleep/row_min_mean 1520.5189 (1518.6088) lr 1.3681e-03 eta 0:11:33
epoch [21/50] batch [80/167] time 0.091 (0.133) data 0.000 (0.004) loss 1.1669 (1.2920) teacher_loss 0.1767 (0.2049) loss_zs_kd 0.0283 (0.0358) loss_oracle 0.4470 (0.5128) kd_loss 0.7526 (0.8127) acc 93.7500 (92.2266) gate/entropy 0.9842 (0.9844) gate/usage_max 0.5670 (0.5669) gate/usage_min 0.2158 (0.2159) gate/usage_std 0.1652 (0.1652) teacher/entropy 0.0255 (0.0335) teacher/usage_max 0.7801 (0.7095) teacher/usage_min 0.1024 (0.1068) teacher/usage_std 0.3160 (0.2689) nleep/row_max_mean 1548.2998 (1552.5670) nleep/row_max_std 71.2622 (56.4768) nleep/row_min_mean 1513.3425 (1518.0218) lr 1.3681e-03 eta 0:10:53
epoch [21/50] batch [100/167] time 0.070 (0.129) data 0.000 (0.003) loss 1.2746 (1.2949) teacher_loss 0.2234 (0.2064) loss_zs_kd 0.0488 (0.0355) loss_oracle 0.5379 (0.5110) kd_loss 0.7579 (0.8153) acc 90.6250 (91.8438) gate/entropy 0.9838 (0.9843) gate/usage_max 0.5675 (0.5669) gate/usage_min 0.2156 (0.2158) gate/usage_std 0.1655 (0.1652) teacher/entropy 0.0348 (0.0336) teacher/usage_max 0.7651 (0.7067) teacher/usage_min 0.0939 (0.1105) teacher/usage_std 0.3059 (0.2667) nleep/row_max_mean 1559.2517 (1552.4127) nleep/row_max_std 49.5874 (56.2827) nleep/row_min_mean 1524.7448 (1517.6621) lr 1.3681e-03 eta 0:10:32
epoch [21/50] batch [120/167] time 0.171 (0.127) data 0.000 (0.003) loss 1.3800 (1.2938) teacher_loss 0.2011 (0.2070) loss_zs_kd 0.0463 (0.0366) loss_oracle 0.4689 (0.5103) kd_loss 0.9212 (0.8134) acc 87.5000 (92.1094) gate/entropy 0.9840 (0.9843) gate/usage_max 0.5673 (0.5670) gate/usage_min 0.2157 (0.2158) gate/usage_std 0.1654 (0.1652) teacher/entropy 0.0064 (0.0328) teacher/usage_max 0.6250 (0.7096) teacher/usage_min 0.1870 (0.1079) teacher/usage_std 0.2062 (0.2690) nleep/row_max_mean 1554.0930 (1553.0997) nleep/row_max_std 53.1452 (56.6050) nleep/row_min_mean 1517.9717 (1518.0386) lr 1.3681e-03 eta 0:10:20
epoch [21/50] batch [140/167] time 0.131 (0.122) data 0.000 (0.002) loss 1.1581 (1.2883) teacher_loss 0.0796 (0.2027) loss_zs_kd 0.0311 (0.0368) loss_oracle 0.4660 (0.5065) kd_loss 0.8300 (0.8139) acc 96.8750 (92.2991) gate/entropy 0.9839 (0.9842) gate/usage_max 0.5674 (0.5671) gate/usage_min 0.2157 (0.2158) gate/usage_std 0.1655 (0.1653) teacher/entropy 0.0312 (0.0317) teacher/usage_max 0.6942 (0.7101) teacher/usage_min 0.1496 (0.1072) teacher/usage_std 0.2552 (0.2694) nleep/row_max_mean 1549.9805 (1553.2719) nleep/row_max_std 69.2706 (57.1197) nleep/row_min_mean 1516.1105 (1518.0501) lr 1.3681e-03 eta 0:09:54
epoch [21/50] batch [160/167] time 0.174 (0.120) data 0.000 (0.002) loss 1.2709 (1.2918) teacher_loss 0.0927 (0.2046) loss_zs_kd 0.0369 (0.0373) loss_oracle 0.5523 (0.5051) kd_loss 0.8836 (0.8160) acc 93.7500 (92.2070) gate/entropy 0.9837 (0.9842) gate/usage_max 0.5676 (0.5671) gate/usage_min 0.2156 (0.2158) gate/usage_std 0.1657 (0.1653) teacher/entropy 0.0151 (0.0318) teacher/usage_max 0.6554 (0.7078) teacher/usage_min 0.0910 (0.1087) teacher/usage_std 0.2372 (0.2678) nleep/row_max_mean 1565.7190 (1554.3481) nleep/row_max_std 42.4908 (57.1540) nleep/row_min_mean 1525.0752 (1518.8711) lr 1.3681e-03 eta 0:09:43
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,201
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [22/50] batch [20/167] time 0.196 (0.144) data 0.000 (0.017) loss 1.6089 (1.2686) teacher_loss 0.3655 (0.1535) loss_zs_kd 0.0599 (0.0338) loss_oracle 0.4988 (0.5113) kd_loss 0.9641 (0.8425) acc 93.7500 (95.4688) gate/entropy 0.9836 (0.9839) gate/usage_max 0.5677 (0.5674) gate/usage_min 0.2156 (0.2157) gate/usage_std 0.1657 (0.1655) teacher/entropy 0.0169 (0.0293) teacher/usage_max 0.5695 (0.6830) teacher/usage_min 0.1875 (0.1221) teacher/usage_std 0.1685 (0.2499) nleep/row_max_mean 1553.7649 (1555.6631) nleep/row_max_std 49.9518 (58.2628) nleep/row_min_mean 1516.9143 (1520.0136) lr 1.3090e-03 eta 0:11:33
epoch [22/50] batch [40/167] time 0.153 (0.129) data 0.000 (0.009) loss 1.2133 (1.3089) teacher_loss 0.2269 (0.1803) loss_zs_kd 0.0296 (0.0366) loss_oracle 0.5604 (0.5223) kd_loss 0.6914 (0.8491) acc 87.5000 (93.3594) gate/entropy 0.9838 (0.9838) gate/usage_max 0.5675 (0.5675) gate/usage_min 0.2156 (0.2156) gate/usage_std 0.1656 (0.1656) teacher/entropy 0.0247 (0.0277) teacher/usage_max 0.8441 (0.6777) teacher/usage_min 0.0315 (0.1262) teacher/usage_std 0.3631 (0.2461) nleep/row_max_mean 1559.2480 (1557.0933) nleep/row_max_std 61.5825 (57.4311) nleep/row_min_mean 1524.7648 (1521.0171) lr 1.3090e-03 eta 0:10:18
epoch [22/50] batch [60/167] time 0.127 (0.137) data 0.000 (0.006) loss 1.4636 (1.3203) teacher_loss 0.2408 (0.1905) loss_zs_kd 0.0311 (0.0354) loss_oracle 0.4724 (0.5285) kd_loss 0.9711 (0.8478) acc 87.5000 (92.6042) gate/entropy 0.9840 (0.9838) gate/usage_max 0.5673 (0.5675) gate/usage_min 0.2158 (0.2157) gate/usage_std 0.1654 (0.1656) teacher/entropy 0.0155 (0.0297) teacher/usage_max 0.5622 (0.6769) teacher/usage_min 0.1525 (0.1231) teacher/usage_std 0.1707 (0.2459) nleep/row_max_mean 1546.1012 (1554.9990) nleep/row_max_std 66.9077 (58.3498) nleep/row_min_mean 1513.0496 (1519.2447) lr 1.3090e-03 eta 0:10:54
epoch [22/50] batch [80/167] time 0.158 (0.139) data 0.000 (0.005) loss 1.5437 (1.3497) teacher_loss 0.4124 (0.2037) loss_zs_kd 0.0522 (0.0369) loss_oracle 0.5406 (0.5447) kd_loss 0.8349 (0.8552) acc 78.1250 (91.8750) gate/entropy 0.9836 (0.9837) gate/usage_max 0.5677 (0.5676) gate/usage_min 0.2156 (0.2156) gate/usage_std 0.1658 (0.1656) teacher/entropy 0.0299 (0.0283) teacher/usage_max 0.6901 (0.6705) teacher/usage_min 0.1339 (0.1201) teacher/usage_std 0.2529 (0.2432) nleep/row_max_mean 1546.1304 (1555.8334) nleep/row_max_std 68.7911 (58.3391) nleep/row_min_mean 1512.5920 (1519.7016) lr 1.3090e-03 eta 0:11:00
epoch [22/50] batch [100/167] time 0.133 (0.140) data 0.000 (0.004) loss 1.4223 (1.3580) teacher_loss 0.1180 (0.2042) loss_zs_kd 0.0327 (0.0363) loss_oracle 0.7031 (0.5593) kd_loss 0.9364 (0.8560) acc 93.7500 (91.9062) gate/entropy 0.9834 (0.9837) gate/usage_max 0.5679 (0.5676) gate/usage_min 0.2155 (0.2156) gate/usage_std 0.1659 (0.1657) teacher/entropy 0.0349 (0.0293) teacher/usage_max 0.5795 (0.6688) teacher/usage_min 0.1342 (0.1170) teacher/usage_std 0.1848 (0.2428) nleep/row_max_mean 1559.9519 (1554.8808) nleep/row_max_std 55.9923 (58.4759) nleep/row_min_mean 1522.7388 (1519.0341) lr 1.3090e-03 eta 0:11:05
epoch [22/50] batch [120/167] time 0.136 (0.141) data 0.000 (0.003) loss 1.4206 (1.3530) teacher_loss 0.2136 (0.1994) loss_zs_kd 0.0469 (0.0362) loss_oracle 0.6216 (0.5625) kd_loss 0.8727 (0.8542) acc 93.7500 (92.2396) gate/entropy 0.9834 (0.9836) gate/usage_max 0.5679 (0.5676) gate/usage_min 0.2156 (0.2156) gate/usage_std 0.1658 (0.1657) teacher/entropy 0.0251 (0.0301) teacher/usage_max 0.6570 (0.6698) teacher/usage_min 0.0627 (0.1148) teacher/usage_std 0.2455 (0.2439) nleep/row_max_mean 1551.7437 (1554.1745) nleep/row_max_std 60.0448 (58.6004) nleep/row_min_mean 1514.7869 (1518.4940) lr 1.3090e-03 eta 0:11:08
epoch [22/50] batch [140/167] time 0.142 (0.142) data 0.000 (0.003) loss 1.1217 (1.3530) teacher_loss 0.1835 (0.2026) loss_zs_kd 0.0372 (0.0364) loss_oracle 0.5157 (0.5626) kd_loss 0.6617 (0.8509) acc 93.7500 (92.0536) gate/entropy 0.9830 (0.9836) gate/usage_max 0.5683 (0.5677) gate/usage_min 0.2154 (0.2156) gate/usage_std 0.1662 (0.1657) teacher/entropy 0.0239 (0.0313) teacher/usage_max 0.8747 (0.6720) teacher/usage_min 0.0492 (0.1107) teacher/usage_std 0.3830 (0.2460) nleep/row_max_mean 1579.8955 (1554.8815) nleep/row_max_std 57.8302 (58.9086) nleep/row_min_mean 1537.7023 (1518.9760) lr 1.3090e-03 eta 0:11:09
epoch [22/50] batch [160/167] time 0.156 (0.143) data 0.000 (0.002) loss 1.2998 (1.3512) teacher_loss 0.1304 (0.2018) loss_zs_kd 0.0296 (0.0366) loss_oracle 0.5270 (0.5620) kd_loss 0.8910 (0.8500) acc 93.7500 (92.1875) gate/entropy 0.9836 (0.9836) gate/usage_max 0.5677 (0.5677) gate/usage_min 0.2157 (0.2156) gate/usage_std 0.1657 (0.1657) teacher/entropy 0.0541 (0.0333) teacher/usage_max 0.6071 (0.6709) teacher/usage_min 0.0637 (0.1105) teacher/usage_std 0.2219 (0.2454) nleep/row_max_mean 1543.7543 (1554.2947) nleep/row_max_std 57.4247 (59.2635) nleep/row_min_mean 1510.7605 (1518.5333) lr 1.3090e-03 eta 0:11:08
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,190
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [23/50] batch [20/167] time 0.087 (0.105) data 0.000 (0.014) loss 1.3452 (1.3240) teacher_loss 0.0369 (0.1736) loss_zs_kd 0.0200 (0.0299) loss_oracle 0.6723 (0.5817) kd_loss 0.9621 (0.8446) acc 100.0000 (93.2812) gate/entropy 0.9835 (0.9834) gate/usage_max 0.5678 (0.5679) gate/usage_min 0.2156 (0.2156) gate/usage_std 0.1658 (0.1659) teacher/entropy 0.0267 (0.0399) teacher/usage_max 0.5625 (0.6696) teacher/usage_min 0.1098 (0.1168) teacher/usage_std 0.1848 (0.2439) nleep/row_max_mean 1542.4346 (1551.9756) nleep/row_max_std 58.8612 (55.3496) nleep/row_min_mean 1509.5178 (1516.9104) lr 1.2487e-03 eta 0:08:10
epoch [23/50] batch [40/167] time 0.069 (0.109) data 0.000 (0.007) loss 1.2245 (1.3426) teacher_loss 0.1588 (0.1831) loss_zs_kd 0.0223 (0.0313) loss_oracle 0.5263 (0.5951) kd_loss 0.7913 (0.8463) acc 93.7500 (92.8906) gate/entropy 0.9833 (0.9833) gate/usage_max 0.5680 (0.5680) gate/usage_min 0.2156 (0.2156) gate/usage_std 0.1660 (0.1659) teacher/entropy 0.0681 (0.0427) teacher/usage_max 0.6956 (0.6650) teacher/usage_min 0.0869 (0.1123) teacher/usage_std 0.2616 (0.2413) nleep/row_max_mean 1555.9381 (1551.6314) nleep/row_max_std 55.5435 (56.2308) nleep/row_min_mean 1520.6654 (1516.4078) lr 1.2487e-03 eta 0:08:23
epoch [23/50] batch [60/167] time 0.087 (0.107) data 0.000 (0.005) loss 1.3379 (1.3470) teacher_loss 0.1985 (0.1842) loss_zs_kd 0.0520 (0.0336) loss_oracle 0.6078 (0.5915) kd_loss 0.8095 (0.8503) acc 93.7500 (92.8125) gate/entropy 0.9835 (0.9833) gate/usage_max 0.5677 (0.5680) gate/usage_min 0.2157 (0.2156) gate/usage_std 0.1658 (0.1659) teacher/entropy 0.0198 (0.0421) teacher/usage_max 0.7271 (0.6616) teacher/usage_min 0.1250 (0.1092) teacher/usage_std 0.2786 (0.2403) nleep/row_max_mean 1534.0588 (1550.1250) nleep/row_max_std 65.7407 (57.2369) nleep/row_min_mean 1501.0713 (1515.0692) lr 1.2487e-03 eta 0:08:12
epoch [23/50] batch [80/167] time 0.081 (0.108) data 0.000 (0.004) loss 1.4443 (1.3607) teacher_loss 0.1120 (0.1967) loss_zs_kd 0.0477 (0.0359) loss_oracle 0.6383 (0.5860) kd_loss 0.9892 (0.8530) acc 96.8750 (92.3828) gate/entropy 0.9835 (0.9833) gate/usage_max 0.5678 (0.5680) gate/usage_min 0.2157 (0.2156) gate/usage_std 0.1658 (0.1659) teacher/entropy 0.0304 (0.0409) teacher/usage_max 0.5299 (0.6600) teacher/usage_min 0.1227 (0.1090) teacher/usage_std 0.1666 (0.2397) nleep/row_max_mean 1541.3458 (1549.8734) nleep/row_max_std 65.0830 (56.6973) nleep/row_min_mean 1510.0682 (1514.6539) lr 1.2487e-03 eta 0:08:17
epoch [23/50] batch [100/167] time 0.095 (0.110) data 0.000 (0.003) loss 1.2891 (1.3541) teacher_loss 0.2885 (0.2043) loss_zs_kd 0.0424 (0.0371) loss_oracle 0.4890 (0.5772) kd_loss 0.7349 (0.8427) acc 81.2500 (91.9688) gate/entropy 0.9830 (0.9833) gate/usage_max 0.5683 (0.5680) gate/usage_min 0.2155 (0.2156) gate/usage_std 0.1661 (0.1660) teacher/entropy 0.0101 (0.0390) teacher/usage_max 0.8144 (0.6726) teacher/usage_min 0.0313 (0.1053) teacher/usage_std 0.3438 (0.2476) nleep/row_max_mean 1553.0154 (1550.3169) nleep/row_max_std 62.1568 (56.6178) nleep/row_min_mean 1514.6746 (1514.8674) lr 1.2487e-03 eta 0:08:22
epoch [23/50] batch [120/167] time 0.084 (0.111) data 0.000 (0.002) loss 1.3621 (1.3569) teacher_loss 0.1808 (0.2075) loss_zs_kd 0.0268 (0.0367) loss_oracle 0.5472 (0.5771) kd_loss 0.8943 (0.8425) acc 93.7500 (91.8490) gate/entropy 0.9833 (0.9833) gate/usage_max 0.5680 (0.5680) gate/usage_min 0.2157 (0.2156) gate/usage_std 0.1659 (0.1660) teacher/entropy 0.0601 (0.0371) teacher/usage_max 0.5976 (0.6748) teacher/usage_min 0.1012 (0.1054) teacher/usage_std 0.2039 (0.2487) nleep/row_max_mean 1540.5333 (1550.2313) nleep/row_max_std 52.4581 (56.3903) nleep/row_min_mean 1513.5369 (1514.9103) lr 1.2487e-03 eta 0:08:27
epoch [23/50] batch [140/167] time 0.086 (0.111) data 0.001 (0.002) loss 1.5576 (1.3554) teacher_loss 0.2657 (0.2023) loss_zs_kd 0.0510 (0.0362) loss_oracle 0.5947 (0.5820) kd_loss 0.9691 (0.8441) acc 93.7500 (92.1429) gate/entropy 0.9829 (0.9832) gate/usage_max 0.5684 (0.5681) gate/usage_min 0.2155 (0.2156) gate/usage_std 0.1662 (0.1660) teacher/entropy 0.0184 (0.0362) teacher/usage_max 0.5625 (0.6740) teacher/usage_min 0.1811 (0.1068) teacher/usage_std 0.1649 (0.2479) nleep/row_max_mean 1562.7144 (1550.5327) nleep/row_max_std 48.4378 (56.1628) nleep/row_min_mean 1524.6980 (1515.2222) lr 1.2487e-03 eta 0:08:23
epoch [23/50] batch [160/167] time 0.151 (0.114) data 0.000 (0.002) loss 1.2468 (1.3576) teacher_loss 0.2078 (0.2055) loss_zs_kd 0.0330 (0.0358) loss_oracle 0.5017 (0.5790) kd_loss 0.7716 (0.8447) acc 90.6250 (92.2461) gate/entropy 0.9834 (0.9832) gate/usage_max 0.5679 (0.5681) gate/usage_min 0.2157 (0.2156) gate/usage_std 0.1658 (0.1660) teacher/entropy 0.0489 (0.0361) teacher/usage_max 0.7354 (0.6735) teacher/usage_min 0.0757 (0.1079) teacher/usage_std 0.2880 (0.2473) nleep/row_max_mean 1547.5479 (1550.2382) nleep/row_max_std 49.9505 (56.4767) nleep/row_min_mean 1515.0249 (1515.0155) lr 1.2487e-03 eta 0:08:35
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,196
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,327
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [24/50] batch [20/167] time 0.150 (0.170) data 0.000 (0.014) loss 1.4877 (1.3414) teacher_loss 0.1034 (0.1940) loss_zs_kd 0.0442 (0.0379) loss_oracle 0.6474 (0.5475) kd_loss 1.0385 (0.8548) acc 93.7500 (93.4375) gate/entropy 0.9831 (0.9831) gate/usage_max 0.5683 (0.5682) gate/usage_min 0.2156 (0.2156) gate/usage_std 0.1661 (0.1661) teacher/entropy 0.0438 (0.0318) teacher/usage_max 0.4657 (0.6673) teacher/usage_min 0.1299 (0.1219) teacher/usage_std 0.1460 (0.2417) nleep/row_max_mean 1549.4803 (1552.5099) nleep/row_max_std 44.7952 (52.3515) nleep/row_min_mean 1516.8528 (1518.2821) lr 1.1874e-03 eta 0:12:42
epoch [24/50] batch [40/167] time 0.149 (0.158) data 0.000 (0.007) loss 1.3479 (1.3485) teacher_loss 0.2881 (0.1992) loss_zs_kd 0.0368 (0.0397) loss_oracle 0.5558 (0.5532) kd_loss 0.7634 (0.8528) acc 87.5000 (92.1875) gate/entropy 0.9833 (0.9831) gate/usage_max 0.5680 (0.5683) gate/usage_min 0.2157 (0.2156) gate/usage_std 0.1659 (0.1661) teacher/entropy 0.0179 (0.0279) teacher/usage_max 0.7763 (0.6734) teacher/usage_min 0.0985 (0.1173) teacher/usage_std 0.3134 (0.2466) nleep/row_max_mean 1544.7368 (1552.9780) nleep/row_max_std 59.5887 (53.1664) nleep/row_min_mean 1509.3440 (1518.9701) lr 1.1874e-03 eta 0:11:45
epoch [24/50] batch [60/167] time 0.160 (0.155) data 0.000 (0.005) loss 1.4921 (1.3526) teacher_loss 0.2627 (0.2009) loss_zs_kd 0.0305 (0.0403) loss_oracle 0.6609 (0.5549) kd_loss 0.8836 (0.8541) acc 84.3750 (91.5625) gate/entropy 0.9827 (0.9830) gate/usage_max 0.5686 (0.5683) gate/usage_min 0.2155 (0.2156) gate/usage_std 0.1664 (0.1661) teacher/entropy 0.0139 (0.0281) teacher/usage_max 0.6563 (0.6720) teacher/usage_min 0.0900 (0.1116) teacher/usage_std 0.2379 (0.2467) nleep/row_max_mean 1557.4690 (1552.3990) nleep/row_max_std 43.2333 (52.2826) nleep/row_min_mean 1519.4836 (1518.3715) lr 1.1874e-03 eta 0:11:28
epoch [24/50] batch [80/167] time 0.096 (0.142) data 0.000 (0.004) loss 1.4916 (1.3594) teacher_loss 0.1972 (0.2004) loss_zs_kd 0.0451 (0.0391) loss_oracle 0.6191 (0.5652) kd_loss 0.9623 (0.8569) acc 90.6250 (91.5234) gate/entropy 0.9831 (0.9830) gate/usage_max 0.5682 (0.5683) gate/usage_min 0.2156 (0.2156) gate/usage_std 0.1661 (0.1661) teacher/entropy 0.0262 (0.0273) teacher/usage_max 0.5614 (0.6698) teacher/usage_min 0.1881 (0.1173) teacher/usage_std 0.1633 (0.2440) nleep/row_max_mean 1548.1426 (1552.4135) nleep/row_max_std 51.2434 (51.1738) nleep/row_min_mean 1513.9497 (1518.3227) lr 1.1874e-03 eta 0:10:27
epoch [24/50] batch [100/167] time 0.080 (0.137) data 0.000 (0.003) loss 1.4702 (1.3593) teacher_loss 0.2288 (0.1983) loss_zs_kd 0.0338 (0.0402) loss_oracle 0.6292 (0.5748) kd_loss 0.9099 (0.8534) acc 90.6250 (91.6875) gate/entropy 0.9826 (0.9830) gate/usage_max 0.5687 (0.5683) gate/usage_min 0.2154 (0.2156) gate/usage_std 0.1664 (0.1662) teacher/entropy 0.0134 (0.0289) teacher/usage_max 0.6285 (0.6716) teacher/usage_min 0.1840 (0.1135) teacher/usage_std 0.2087 (0.2460) nleep/row_max_mean 1568.1699 (1552.9067) nleep/row_max_std 41.0902 (50.5350) nleep/row_min_mean 1533.2440 (1518.7660) lr 1.1874e-03 eta 0:10:03
epoch [24/50] batch [120/167] time 0.096 (0.131) data 0.000 (0.002) loss 1.3940 (1.3663) teacher_loss 0.2146 (0.2009) loss_zs_kd 0.0427 (0.0395) loss_oracle 0.5314 (0.5837) kd_loss 0.8923 (0.8537) acc 93.7500 (91.7188) gate/entropy 0.9827 (0.9830) gate/usage_max 0.5687 (0.5684) gate/usage_min 0.2155 (0.2156) gate/usage_std 0.1664 (0.1662) teacher/entropy 0.0041 (0.0308) teacher/usage_max 0.6566 (0.6693) teacher/usage_min 0.0937 (0.1132) teacher/usage_std 0.2373 (0.2444) nleep/row_max_mean 1562.8030 (1553.1842) nleep/row_max_std 34.9566 (50.3661) nleep/row_min_mean 1528.0903 (1519.0446) lr 1.1874e-03 eta 0:09:36
epoch [24/50] batch [140/167] time 0.128 (0.130) data 0.000 (0.002) loss 1.4405 (1.3680) teacher_loss 0.2419 (0.1999) loss_zs_kd 0.0330 (0.0393) loss_oracle 0.5425 (0.5855) kd_loss 0.9108 (0.8556) acc 90.6250 (91.6071) gate/entropy 0.9829 (0.9829) gate/usage_max 0.5684 (0.5684) gate/usage_min 0.2156 (0.2156) gate/usage_std 0.1662 (0.1662) teacher/entropy 0.0513 (0.0333) teacher/usage_max 0.5893 (0.6648) teacher/usage_min 0.1092 (0.1114) teacher/usage_std 0.1973 (0.2425) nleep/row_max_mean 1544.3420 (1552.5964) nleep/row_max_std 51.8471 (50.1953) nleep/row_min_mean 1509.4548 (1518.6447) lr 1.1874e-03 eta 0:09:29
epoch [24/50] batch [160/167] time 0.094 (0.127) data 0.000 (0.002) loss 1.1912 (1.3610) teacher_loss 0.0851 (0.1994) loss_zs_kd 0.0300 (0.0386) loss_oracle 0.5779 (0.5826) kd_loss 0.8022 (0.8510) acc 100.0000 (91.7383) gate/entropy 0.9825 (0.9829) gate/usage_max 0.5688 (0.5684) gate/usage_min 0.2154 (0.2156) gate/usage_std 0.1665 (0.1662) teacher/entropy 0.0318 (0.0360) teacher/usage_max 0.7215 (0.6668) teacher/usage_min 0.0542 (0.1071) teacher/usage_std 0.2831 (0.2443) nleep/row_max_mean 1556.5710 (1552.3306) nleep/row_max_std 47.1469 (50.6494) nleep/row_min_mean 1524.6841 (1518.3870) lr 1.1874e-03 eta 0:09:12
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,189
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,326
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [25/50] batch [20/167] time 0.080 (0.127) data 0.000 (0.018) loss 1.3413 (1.4096) teacher_loss 0.1182 (0.2294) loss_zs_kd 0.0421 (0.0415) loss_oracle 0.6167 (0.5840) kd_loss 0.8938 (0.8675) acc 96.8750 (90.9375) gate/entropy 0.9825 (0.9828) gate/usage_max 0.5688 (0.5686) gate/usage_min 0.2155 (0.2156) gate/usage_std 0.1665 (0.1663) teacher/entropy 0.0029 (0.0615) teacher/usage_max 0.6562 (0.6233) teacher/usage_min 0.0311 (0.0880) teacher/usage_std 0.2556 (0.2258) nleep/row_max_mean 1561.1941 (1550.1075) nleep/row_max_std 54.4951 (55.3609) nleep/row_min_mean 1521.9681 (1516.7346) lr 1.1253e-03 eta 0:09:07
epoch [25/50] batch [40/167] time 0.171 (0.119) data 0.000 (0.009) loss 1.4324 (1.3777) teacher_loss 0.2703 (0.2052) loss_zs_kd 0.0492 (0.0378) loss_oracle 0.5384 (0.5730) kd_loss 0.8683 (0.8671) acc 87.5000 (92.1094) gate/entropy 0.9822 (0.9827) gate/usage_max 0.5691 (0.5686) gate/usage_min 0.2154 (0.2156) gate/usage_std 0.1667 (0.1664) teacher/entropy 0.0315 (0.0568) teacher/usage_max 0.6537 (0.6284) teacher/usage_min 0.0388 (0.0689) teacher/usage_std 0.2517 (0.2343) nleep/row_max_mean 1563.9661 (1549.3533) nleep/row_max_std 40.7231 (57.7196) nleep/row_min_mean 1527.2887 (1515.8184) lr 1.1253e-03 eta 0:08:30
epoch [25/50] batch [60/167] time 0.176 (0.112) data 0.001 (0.006) loss 1.1788 (1.3741) teacher_loss 0.0904 (0.2049) loss_zs_kd 0.0177 (0.0348) loss_oracle 0.5718 (0.5669) kd_loss 0.7936 (0.8683) acc 96.8750 (92.1354) gate/entropy 0.9828 (0.9827) gate/usage_max 0.5685 (0.5686) gate/usage_min 0.2157 (0.2156) gate/usage_std 0.1663 (0.1664) teacher/entropy 0.0495 (0.0561) teacher/usage_max 0.7125 (0.6295) teacher/usage_min 0.0267 (0.0587) teacher/usage_std 0.2847 (0.2392) nleep/row_max_mean 1540.8049 (1549.5516) nleep/row_max_std 66.5684 (59.0303) nleep/row_min_mean 1507.3885 (1515.3620) lr 1.1253e-03 eta 0:08:00
epoch [25/50] batch [80/167] time 0.159 (0.115) data 0.000 (0.005) loss 1.2118 (1.3687) teacher_loss 0.1245 (0.2064) loss_zs_kd 0.0187 (0.0336) loss_oracle 0.4931 (0.5641) kd_loss 0.8315 (0.8635) acc 93.7500 (91.9141) gate/entropy 0.9829 (0.9827) gate/usage_max 0.5684 (0.5686) gate/usage_min 0.2157 (0.2156) gate/usage_std 0.1662 (0.1664) teacher/entropy 0.1092 (0.0569) teacher/usage_max 0.6107 (0.6333) teacher/usage_min 0.0315 (0.0523) teacher/usage_std 0.2371 (0.2429) nleep/row_max_mean 1545.1909 (1549.9354) nleep/row_max_std 69.7728 (59.8770) nleep/row_min_mean 1509.3298 (1515.1071) lr 1.1253e-03 eta 0:08:10
epoch [25/50] batch [100/167] time 0.147 (0.120) data 0.000 (0.004) loss 1.1953 (1.3702) teacher_loss 0.1308 (0.2086) loss_zs_kd 0.0223 (0.0338) loss_oracle 0.5349 (0.5675) kd_loss 0.7858 (0.8609) acc 96.8750 (91.9062) gate/entropy 0.9824 (0.9827) gate/usage_max 0.5689 (0.5687) gate/usage_min 0.2155 (0.2156) gate/usage_std 0.1666 (0.1664) teacher/entropy 0.0438 (0.0558) teacher/usage_max 0.7260 (0.6367) teacher/usage_min 0.0311 (0.0473) teacher/usage_std 0.2908 (0.2462) nleep/row_max_mean 1565.8362 (1550.4452) nleep/row_max_std 61.0923 (59.3474) nleep/row_min_mean 1523.9637 (1515.2984) lr 1.1253e-03 eta 0:08:30
epoch [25/50] batch [120/167] time 0.122 (0.123) data 0.000 (0.003) loss 1.2777 (1.3722) teacher_loss 0.1294 (0.2087) loss_zs_kd 0.0327 (0.0331) loss_oracle 0.5059 (0.5625) kd_loss 0.8790 (0.8657) acc 96.8750 (91.8750) gate/entropy 0.9828 (0.9827) gate/usage_max 0.5685 (0.5686) gate/usage_min 0.2157 (0.2156) gate/usage_std 0.1663 (0.1664) teacher/entropy 0.0869 (0.0550) teacher/usage_max 0.5844 (0.6358) teacher/usage_min 0.0706 (0.0438) teacher/usage_std 0.2099 (0.2469) nleep/row_max_mean 1539.3997 (1548.9001) nleep/row_max_std 58.5256 (59.6107) nleep/row_min_mean 1505.8046 (1513.9433) lr 1.1253e-03 eta 0:08:38
epoch [25/50] batch [140/167] time 0.143 (0.124) data 0.000 (0.003) loss 1.2756 (1.3688) teacher_loss 0.0359 (0.2106) loss_zs_kd 0.0109 (0.0325) loss_oracle 0.6531 (0.5574) kd_loss 0.9077 (0.8633) acc 100.0000 (91.8750) gate/entropy 0.9828 (0.9827) gate/usage_max 0.5685 (0.5687) gate/usage_min 0.2157 (0.2156) gate/usage_std 0.1663 (0.1664) teacher/entropy 0.0707 (0.0548) teacher/usage_max 0.5725 (0.6379) teacher/usage_min 0.0005 (0.0392) teacher/usage_std 0.2428 (0.2497) nleep/row_max_mean 1531.2700 (1548.1228) nleep/row_max_std 67.9498 (59.7649) nleep/row_min_mean 1500.6157 (1513.2495) lr 1.1253e-03 eta 0:08:42
epoch [25/50] batch [160/167] time 0.145 (0.125) data 0.000 (0.002) loss 1.6823 (1.3678) teacher_loss 0.3925 (0.2088) loss_zs_kd 0.0214 (0.0322) loss_oracle 0.6927 (0.5581) kd_loss 0.9328 (0.8638) acc 87.5000 (92.1094) gate/entropy 0.9829 (0.9827) gate/usage_max 0.5684 (0.5687) gate/usage_min 0.2157 (0.2156) gate/usage_std 0.1662 (0.1664) teacher/entropy 0.0691 (0.0552) teacher/usage_max 0.5467 (0.6365) teacher/usage_min 0.0514 (0.0367) teacher/usage_std 0.2079 (0.2502) nleep/row_max_mean 1542.5017 (1547.6638) nleep/row_max_std 64.7659 (59.9248) nleep/row_min_mean 1506.5547 (1513.0417) lr 1.1253e-03 eta 0:08:42
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,188
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,324
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [26/50] batch [20/167] time 0.072 (0.132) data 0.000 (0.017) loss 1.1310 (1.4001) teacher_loss 0.0206 (0.2066) loss_zs_kd 0.0104 (0.0304) loss_oracle 0.5744 (0.6006) kd_loss 0.8181 (0.8780) acc 100.0000 (91.5625) gate/entropy 0.9824 (0.9827) gate/usage_max 0.5689 (0.5686) gate/usage_min 0.2154 (0.2156) gate/usage_std 0.1666 (0.1664) teacher/entropy 0.0176 (0.0610) teacher/usage_max 0.7196 (0.6161) teacher/usage_min 0.0000 (0.0127) teacher/usage_std 0.2962 (0.2528) nleep/row_max_mean 1549.4230 (1543.3717) nleep/row_max_std 63.8611 (62.1231) nleep/row_min_mean 1512.4211 (1509.9448) lr 1.0628e-03 eta 0:09:09
epoch [26/50] batch [40/167] time 0.074 (0.124) data 0.000 (0.008) loss 1.4830 (1.4109) teacher_loss 0.3294 (0.2209) loss_zs_kd 0.0355 (0.0312) loss_oracle 0.5974 (0.5896) kd_loss 0.8372 (0.8796) acc 87.5000 (91.6406) gate/entropy 0.9823 (0.9826) gate/usage_max 0.5690 (0.5687) gate/usage_min 0.2153 (0.2155) gate/usage_std 0.1666 (0.1665) teacher/entropy 0.0325 (0.0551) teacher/usage_max 0.6836 (0.6263) teacher/usage_min 0.0624 (0.0143) teacher/usage_std 0.2598 (0.2562) nleep/row_max_mean 1559.7910 (1545.3802) nleep/row_max_std 56.1414 (58.3621) nleep/row_min_mean 1523.3967 (1511.9348) lr 1.0628e-03 eta 0:08:32
epoch [26/50] batch [60/167] time 0.104 (0.118) data 0.000 (0.006) loss 1.5666 (1.4111) teacher_loss 0.2338 (0.2217) loss_zs_kd 0.0300 (0.0309) loss_oracle 0.7075 (0.5880) kd_loss 0.9641 (0.8800) acc 90.6250 (91.8750) gate/entropy 0.9827 (0.9826) gate/usage_max 0.5687 (0.5688) gate/usage_min 0.2155 (0.2155) gate/usage_std 0.1664 (0.1665) teacher/entropy 0.0358 (0.0561) teacher/usage_max 0.5486 (0.6221) teacher/usage_min 0.0621 (0.0159) teacher/usage_std 0.2025 (0.2538) nleep/row_max_mean 1546.9380 (1544.9987) nleep/row_max_std 54.5303 (59.1899) nleep/row_min_mean 1515.3391 (1511.7807) lr 1.0628e-03 eta 0:08:05
epoch [26/50] batch [80/167] time 0.112 (0.117) data 0.000 (0.004) loss 1.5443 (1.4031) teacher_loss 0.2320 (0.2158) loss_zs_kd 0.0375 (0.0302) loss_oracle 0.6411 (0.5855) kd_loss 0.9730 (0.8794) acc 93.7500 (91.9922) gate/entropy 0.9825 (0.9826) gate/usage_max 0.5688 (0.5688) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1665 (0.1665) teacher/entropy 0.0443 (0.0574) teacher/usage_max 0.5314 (0.6196) teacher/usage_min 0.0004 (0.0164) teacher/usage_std 0.2369 (0.2525) nleep/row_max_mean 1553.1196 (1545.6432) nleep/row_max_std 49.5016 (59.1171) nleep/row_min_mean 1518.0039 (1512.4589) lr 1.0628e-03 eta 0:08:00
epoch [26/50] batch [100/167] time 0.099 (0.116) data 0.000 (0.004) loss 1.1975 (1.3905) teacher_loss 0.2120 (0.2086) loss_zs_kd 0.0144 (0.0299) loss_oracle 0.5572 (0.5805) kd_loss 0.6997 (0.8766) acc 90.6250 (92.3438) gate/entropy 0.9824 (0.9825) gate/usage_max 0.5689 (0.5688) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1666 (0.1665) teacher/entropy 0.0181 (0.0573) teacher/usage_max 0.8407 (0.6217) teacher/usage_min 0.0006 (0.0160) teacher/usage_std 0.3645 (0.2537) nleep/row_max_mean 1558.2548 (1546.2347) nleep/row_max_std 62.0906 (58.7576) nleep/row_min_mean 1522.0625 (1513.1452) lr 1.0628e-03 eta 0:07:52
epoch [26/50] batch [120/167] time 0.085 (0.119) data 0.000 (0.003) loss 1.4170 (1.4016) teacher_loss 0.2286 (0.2157) loss_zs_kd 0.0291 (0.0302) loss_oracle 0.5388 (0.5816) kd_loss 0.9044 (0.8800) acc 87.5000 (92.1094) gate/entropy 0.9832 (0.9825) gate/usage_max 0.5681 (0.5688) gate/usage_min 0.2157 (0.2154) gate/usage_std 0.1660 (0.1665) teacher/entropy 0.1416 (0.0567) teacher/usage_max 0.5011 (0.6183) teacher/usage_min 0.0284 (0.0157) teacher/usage_std 0.2160 (0.2527) nleep/row_max_mean 1527.6127 (1546.5655) nleep/row_max_std 65.3033 (58.2419) nleep/row_min_mean 1498.3318 (1513.5810) lr 1.0628e-03 eta 0:08:01
epoch [26/50] batch [140/167] time 0.185 (0.119) data 0.000 (0.003) loss 1.3659 (1.4048) teacher_loss 0.2580 (0.2188) loss_zs_kd 0.0260 (0.0307) loss_oracle 0.5376 (0.5806) kd_loss 0.8260 (0.8803) acc 87.5000 (91.8304) gate/entropy 0.9826 (0.9825) gate/usage_max 0.5687 (0.5688) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1664 (0.1665) teacher/entropy 0.0688 (0.0569) teacher/usage_max 0.6568 (0.6179) teacher/usage_min 0.0349 (0.0159) teacher/usage_std 0.2545 (0.2525) nleep/row_max_mean 1528.1613 (1546.6239) nleep/row_max_std 67.3668 (58.4626) nleep/row_min_mean 1497.9546 (1513.5909) lr 1.0628e-03 eta 0:08:00
epoch [26/50] batch [160/167] time 0.147 (0.119) data 0.000 (0.002) loss 1.4338 (1.4067) teacher_loss 0.3284 (0.2202) loss_zs_kd 0.0428 (0.0308) loss_oracle 0.5622 (0.5776) kd_loss 0.8029 (0.8823) acc 81.2500 (91.7383) gate/entropy 0.9818 (0.9825) gate/usage_max 0.5695 (0.5688) gate/usage_min 0.2149 (0.2154) gate/usage_std 0.1670 (0.1665) teacher/entropy 0.0022 (0.0566) teacher/usage_max 0.7502 (0.6160) teacher/usage_min 0.0002 (0.0161) teacher/usage_std 0.3119 (0.2520) nleep/row_max_mean 1570.5703 (1546.4861) nleep/row_max_std 38.8470 (58.0225) nleep/row_min_mean 1534.7745 (1513.5426) lr 1.0628e-03 eta 0:07:57
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,201
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [27/50] batch [20/167] time 0.131 (0.170) data 0.000 (0.016) loss 1.4277 (1.3802) teacher_loss 0.1605 (0.2055) loss_zs_kd 0.0255 (0.0318) loss_oracle 0.6192 (0.5366) kd_loss 0.9448 (0.8904) acc 93.7500 (92.6562) gate/entropy 0.9829 (0.9825) gate/usage_max 0.5684 (0.5688) gate/usage_min 0.2154 (0.2152) gate/usage_std 0.1663 (0.1665) teacher/entropy 0.0759 (0.0449) teacher/usage_max 0.5272 (0.6195) teacher/usage_min 0.0429 (0.0123) teacher/usage_std 0.2092 (0.2582) nleep/row_max_mean 1535.7732 (1544.1457) nleep/row_max_std 63.7643 (56.7474) nleep/row_min_mean 1504.4160 (1512.4296) lr 1.0000e-03 eta 0:11:19
epoch [27/50] batch [40/167] time 0.132 (0.153) data 0.000 (0.008) loss 1.4927 (1.3821) teacher_loss 0.1032 (0.2091) loss_zs_kd 0.0311 (0.0323) loss_oracle 0.5370 (0.5407) kd_loss 1.1055 (0.8865) acc 96.8750 (92.5000) gate/entropy 0.9825 (0.9825) gate/usage_max 0.5688 (0.5688) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1665 (0.1665) teacher/entropy 0.0386 (0.0442) teacher/usage_max 0.5606 (0.6262) teacher/usage_min 0.0385 (0.0162) teacher/usage_std 0.2185 (0.2560) nleep/row_max_mean 1538.5350 (1546.2437) nleep/row_max_std 49.1821 (56.1690) nleep/row_min_mean 1507.5503 (1514.0804) lr 1.0000e-03 eta 0:10:07
epoch [27/50] batch [60/167] time 0.154 (0.153) data 0.001 (0.005) loss 1.2582 (1.3788) teacher_loss 0.0528 (0.2144) loss_zs_kd 0.0160 (0.0320) loss_oracle 0.5747 (0.5400) kd_loss 0.9101 (0.8784) acc 100.0000 (92.5521) gate/entropy 0.9823 (0.9825) gate/usage_max 0.5690 (0.5688) gate/usage_min 0.2150 (0.2152) gate/usage_std 0.1667 (0.1665) teacher/entropy 0.0563 (0.0496) teacher/usage_max 0.5838 (0.6271) teacher/usage_min 0.0576 (0.0178) teacher/usage_std 0.2155 (0.2552) nleep/row_max_mean 1553.6189 (1544.3354) nleep/row_max_std 55.3388 (57.3369) nleep/row_min_mean 1521.0022 (1511.8066) lr 1.0000e-03 eta 0:10:04
epoch [27/50] batch [80/167] time 0.128 (0.151) data 0.000 (0.004) loss 1.3615 (1.3592) teacher_loss 0.2483 (0.2114) loss_zs_kd 0.0518 (0.0322) loss_oracle 0.5041 (0.5305) kd_loss 0.8352 (0.8665) acc 84.3750 (92.3047) gate/entropy 0.9822 (0.9825) gate/usage_max 0.5691 (0.5689) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1667 (0.1665) teacher/entropy 0.0425 (0.0512) teacher/usage_max 0.6759 (0.6368) teacher/usage_min 0.0034 (0.0192) teacher/usage_std 0.2747 (0.2586) nleep/row_max_mean 1551.7954 (1544.4352) nleep/row_max_std 52.1405 (57.8663) nleep/row_min_mean 1516.7401 (1511.5463) lr 1.0000e-03 eta 0:09:54
epoch [27/50] batch [100/167] time 0.163 (0.151) data 0.000 (0.003) loss 1.4572 (1.3602) teacher_loss 0.3898 (0.2196) loss_zs_kd 0.0208 (0.0326) loss_oracle 0.4624 (0.5275) kd_loss 0.8258 (0.8606) acc 84.3750 (91.7188) gate/entropy 0.9823 (0.9825) gate/usage_max 0.5690 (0.5689) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1667 (0.1666) teacher/entropy 0.0943 (0.0520) teacher/usage_max 0.6322 (0.6416) teacher/usage_min 0.0005 (0.0192) teacher/usage_std 0.2590 (0.2599) nleep/row_max_mean 1543.2017 (1544.6000) nleep/row_max_std 48.7263 (57.4634) nleep/row_min_mean 1513.7609 (1511.5752) lr 1.0000e-03 eta 0:09:50
epoch [27/50] batch [120/167] time 0.164 (0.150) data 0.000 (0.003) loss 1.4735 (1.3575) teacher_loss 0.2444 (0.2204) loss_zs_kd 0.0505 (0.0325) loss_oracle 0.5472 (0.5267) kd_loss 0.9303 (0.8575) acc 93.7500 (91.6927) gate/entropy 0.9826 (0.9825) gate/usage_max 0.5688 (0.5689) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1665 (0.1666) teacher/entropy 0.0293 (0.0514) teacher/usage_max 0.5905 (0.6451) teacher/usage_min 0.0054 (0.0215) teacher/usage_std 0.2441 (0.2609) nleep/row_max_mean 1537.7378 (1544.5336) nleep/row_max_std 61.4404 (57.2160) nleep/row_min_mean 1504.4523 (1511.5021) lr 1.0000e-03 eta 0:09:44
epoch [27/50] batch [140/167] time 0.091 (0.140) data 0.001 (0.002) loss 1.4147 (1.3500) teacher_loss 0.4091 (0.2203) loss_zs_kd 0.0362 (0.0325) loss_oracle 0.5443 (0.5258) kd_loss 0.7154 (0.8506) acc 84.3750 (91.6518) gate/entropy 0.9819 (0.9824) gate/usage_max 0.5694 (0.5689) gate/usage_min 0.2147 (0.2151) gate/usage_std 0.1670 (0.1666) teacher/entropy 0.0467 (0.0511) teacher/usage_max 0.7946 (0.6522) teacher/usage_min 0.0637 (0.0229) teacher/usage_std 0.3277 (0.2637) nleep/row_max_mean 1556.3640 (1545.1234) nleep/row_max_std 49.5292 (56.6943) nleep/row_min_mean 1523.1755 (1511.9652) lr 1.0000e-03 eta 0:09:02
epoch [27/50] batch [160/167] time 0.176 (0.137) data 0.000 (0.002) loss 1.0881 (1.3491) teacher_loss 0.1060 (0.2243) loss_zs_kd 0.0256 (0.0321) loss_oracle 0.4788 (0.5241) kd_loss 0.7299 (0.8466) acc 96.8750 (91.5430) gate/entropy 0.9825 (0.9824) gate/usage_max 0.5688 (0.5689) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1665 (0.1666) teacher/entropy 0.1209 (0.0523) teacher/usage_max 0.7030 (0.6548) teacher/usage_min 0.0730 (0.0254) teacher/usage_std 0.2686 (0.2639) nleep/row_max_mean 1546.3536 (1545.4110) nleep/row_max_std 65.3200 (56.9210) nleep/row_min_mean 1512.2798 (1512.3559) lr 1.0000e-03 eta 0:08:46
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,186
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.7%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,327
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [28/50] batch [20/167] time 0.102 (0.137) data 0.000 (0.019) loss 1.2344 (1.3374) teacher_loss 0.1121 (0.2072) loss_zs_kd 0.0244 (0.0323) loss_oracle 0.4629 (0.5581) kd_loss 0.8786 (0.8349) acc 96.8750 (92.5000) gate/entropy 0.9825 (0.9824) gate/usage_max 0.5689 (0.5689) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1665 (0.1666) teacher/entropy 0.0428 (0.0648) teacher/usage_max 0.6312 (0.6527) teacher/usage_min 0.0839 (0.0597) teacher/usage_std 0.2260 (0.2521) nleep/row_max_mean 1542.9924 (1543.8461) nleep/row_max_std 47.1056 (51.5049) nleep/row_min_mean 1515.3752 (1512.9715) lr 9.3721e-04 eta 0:08:44
epoch [28/50] batch [40/167] time 0.156 (0.126) data 0.000 (0.010) loss 1.3908 (1.3279) teacher_loss 0.3269 (0.2097) loss_zs_kd 0.0362 (0.0305) loss_oracle 0.5060 (0.5453) kd_loss 0.7928 (0.8303) acc 84.3750 (91.8750) gate/entropy 0.9820 (0.9823) gate/usage_max 0.5694 (0.5690) gate/usage_min 0.2147 (0.2149) gate/usage_std 0.1669 (0.1667) teacher/entropy 0.0426 (0.0625) teacher/usage_max 0.7194 (0.6598) teacher/usage_min 0.1389 (0.0653) teacher/usage_std 0.2730 (0.2525) nleep/row_max_mean 1552.2567 (1546.8828) nleep/row_max_std 49.8948 (51.1656) nleep/row_min_mean 1520.3997 (1515.4377) lr 9.3721e-04 eta 0:07:59
epoch [28/50] batch [60/167] time 0.080 (0.122) data 0.000 (0.007) loss 1.4802 (1.3351) teacher_loss 0.2040 (0.2083) loss_zs_kd 0.0517 (0.0312) loss_oracle 0.5693 (0.5473) kd_loss 0.9657 (0.8375) acc 93.7500 (92.1354) gate/entropy 0.9820 (0.9823) gate/usage_max 0.5694 (0.5690) gate/usage_min 0.2147 (0.2149) gate/usage_std 0.1669 (0.1667) teacher/entropy 0.0173 (0.0651) teacher/usage_max 0.5673 (0.6497) teacher/usage_min 0.0630 (0.0744) teacher/usage_std 0.2075 (0.2441) nleep/row_max_mean 1549.7190 (1546.4080) nleep/row_max_std 43.2475 (51.1187) nleep/row_min_mean 1517.5630 (1515.1207) lr 9.3721e-04 eta 0:07:42
epoch [28/50] batch [80/167] time 0.088 (0.123) data 0.000 (0.005) loss 1.3762 (1.3328) teacher_loss 0.2704 (0.2111) loss_zs_kd 0.0344 (0.0320) loss_oracle 0.5676 (0.5504) kd_loss 0.8048 (0.8305) acc 84.3750 (92.1094) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2148 (0.2149) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0783 (0.0660) teacher/usage_max 0.6705 (0.6560) teacher/usage_min 0.0837 (0.0789) teacher/usage_std 0.2474 (0.2455) nleep/row_max_mean 1543.7363 (1547.0692) nleep/row_max_std 46.9400 (51.7587) nleep/row_min_mean 1515.4952 (1515.7584) lr 9.3721e-04 eta 0:07:40
epoch [28/50] batch [100/167] time 0.174 (0.124) data 0.000 (0.004) loss 1.4322 (1.3370) teacher_loss 0.4219 (0.2161) loss_zs_kd 0.0374 (0.0327) loss_oracle 0.5340 (0.5484) kd_loss 0.7246 (0.8304) acc 81.2500 (91.9375) gate/entropy 0.9819 (0.9823) gate/usage_max 0.5694 (0.5691) gate/usage_min 0.2147 (0.2149) gate/usage_std 0.1670 (0.1667) teacher/entropy 0.0692 (0.0663) teacher/usage_max 0.7621 (0.6559) teacher/usage_min 0.0910 (0.0843) teacher/usage_std 0.3040 (0.2439) nleep/row_max_mean 1568.6132 (1547.6068) nleep/row_max_std 55.7781 (51.6298) nleep/row_min_mean 1530.6793 (1516.2346) lr 9.3721e-04 eta 0:07:42
epoch [28/50] batch [120/167] time 0.138 (0.122) data 0.000 (0.003) loss 1.2366 (1.3421) teacher_loss 0.1832 (0.2169) loss_zs_kd 0.0240 (0.0326) loss_oracle 0.5332 (0.5524) kd_loss 0.7747 (0.8327) acc 96.8750 (92.0052) gate/entropy 0.9821 (0.9823) gate/usage_max 0.5693 (0.5691) gate/usage_min 0.2147 (0.2149) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0755 (0.0660) teacher/usage_max 0.7041 (0.6538) teacher/usage_min 0.1261 (0.0884) teacher/usage_std 0.2628 (0.2416) nleep/row_max_mean 1561.8409 (1547.9500) nleep/row_max_std 51.9940 (51.3468) nleep/row_min_mean 1531.6414 (1516.4644) lr 9.3721e-04 eta 0:07:34
epoch [28/50] batch [140/167] time 0.158 (0.127) data 0.000 (0.003) loss 1.1800 (1.3456) teacher_loss 0.0745 (0.2163) loss_zs_kd 0.0202 (0.0337) loss_oracle 0.5712 (0.5544) kd_loss 0.8098 (0.8353) acc 96.8750 (92.0536) gate/entropy 0.9819 (0.9823) gate/usage_max 0.5695 (0.5691) gate/usage_min 0.2146 (0.2149) gate/usage_std 0.1670 (0.1667) teacher/entropy 0.0714 (0.0669) teacher/usage_max 0.6714 (0.6512) teacher/usage_min 0.1329 (0.0911) teacher/usage_std 0.2404 (0.2395) nleep/row_max_mean 1569.3062 (1548.3786) nleep/row_max_std 56.8549 (51.6861) nleep/row_min_mean 1533.6923 (1516.8461) lr 9.3721e-04 eta 0:07:48
epoch [28/50] batch [160/167] time 0.149 (0.131) data 0.000 (0.003) loss 1.4348 (1.3516) teacher_loss 0.2641 (0.2161) loss_zs_kd 0.0344 (0.0339) loss_oracle 0.6020 (0.5528) kd_loss 0.8525 (0.8421) acc 87.5000 (92.0117) gate/entropy 0.9824 (0.9823) gate/usage_max 0.5690 (0.5691) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.0983 (0.0664) teacher/usage_max 0.5997 (0.6448) teacher/usage_min 0.1429 (0.0961) teacher/usage_std 0.1941 (0.2349) nleep/row_max_mean 1535.0652 (1547.9578) nleep/row_max_std 52.5694 (52.0243) nleep/row_min_mean 1508.3235 (1516.5702) lr 9.3721e-04 eta 0:08:00
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,193
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 98.9%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [29/50] batch [20/167] time 0.166 (0.161) data 0.000 (0.013) loss 1.4202 (1.3660) teacher_loss 0.3601 (0.2008) loss_zs_kd 0.0569 (0.0355) loss_oracle 0.4871 (0.5417) kd_loss 0.7882 (0.8765) acc 90.6250 (93.1250) gate/entropy 0.9817 (0.9821) gate/usage_max 0.5696 (0.5692) gate/usage_min 0.2145 (0.2147) gate/usage_std 0.1671 (0.1668) teacher/entropy 0.0593 (0.0627) teacher/usage_max 0.7063 (0.6118) teacher/usage_min 0.0686 (0.1370) teacher/usage_std 0.2714 (0.2059) nleep/row_max_mean 1558.4216 (1549.0387) nleep/row_max_std 60.0598 (55.1232) nleep/row_min_mean 1526.5990 (1517.7418) lr 8.7467e-04 eta 0:09:47
epoch [29/50] batch [40/167] time 0.098 (0.135) data 0.000 (0.007) loss 1.3383 (1.3884) teacher_loss 0.0591 (0.2081) loss_zs_kd 0.0489 (0.0391) loss_oracle 0.6343 (0.5606) kd_loss 0.9377 (0.8804) acc 100.0000 (92.7344) gate/entropy 0.9817 (0.9822) gate/usage_max 0.5697 (0.5692) gate/usage_min 0.2145 (0.2147) gate/usage_std 0.1671 (0.1668) teacher/entropy 0.0666 (0.0654) teacher/usage_max 0.5447 (0.6051) teacher/usage_min 0.0518 (0.1368) teacher/usage_std 0.2072 (0.2018) nleep/row_max_mean 1568.2009 (1547.5234) nleep/row_max_std 58.1956 (54.9494) nleep/row_min_mean 1533.6616 (1516.3590) lr 8.7467e-04 eta 0:08:11
epoch [29/50] batch [60/167] time 0.086 (0.124) data 0.000 (0.004) loss 1.3466 (1.3891) teacher_loss 0.2593 (0.2124) loss_zs_kd 0.0311 (0.0387) loss_oracle 0.5524 (0.5634) kd_loss 0.7956 (0.8757) acc 87.5000 (92.1875) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5690 (0.5692) gate/usage_min 0.2148 (0.2147) gate/usage_std 0.1666 (0.1668) teacher/entropy 0.0946 (0.0636) teacher/usage_max 0.6624 (0.6119) teacher/usage_min 0.1624 (0.1368) teacher/usage_std 0.2327 (0.2059) nleep/row_max_mean 1548.5052 (1548.4567) nleep/row_max_std 58.1091 (54.7660) nleep/row_min_mean 1515.4116 (1517.1330) lr 8.7467e-04 eta 0:07:27
epoch [29/50] batch [80/167] time 0.086 (0.123) data 0.001 (0.003) loss 1.4581 (1.3781) teacher_loss 0.1509 (0.2007) loss_zs_kd 0.0338 (0.0374) loss_oracle 0.5978 (0.5599) kd_loss 0.9914 (0.8787) acc 90.6250 (92.5781) gate/entropy 0.9824 (0.9822) gate/usage_max 0.5689 (0.5692) gate/usage_min 0.2148 (0.2147) gate/usage_std 0.1666 (0.1668) teacher/entropy 0.0569 (0.0678) teacher/usage_max 0.4995 (0.6045) teacher/usage_min 0.2110 (0.1404) teacher/usage_std 0.1218 (0.2011) nleep/row_max_mean 1545.2690 (1548.2416) nleep/row_max_std 64.6793 (55.4430) nleep/row_min_mean 1513.7285 (1517.1051) lr 8.7467e-04 eta 0:07:21
epoch [29/50] batch [100/167] time 0.171 (0.124) data 0.000 (0.003) loss 1.4914 (1.3868) teacher_loss 0.2928 (0.2054) loss_zs_kd 0.0434 (0.0372) loss_oracle 0.5834 (0.5636) kd_loss 0.8852 (0.8811) acc 90.6250 (92.1250) gate/entropy 0.9820 (0.9822) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1669 (0.1667) teacher/entropy 0.0538 (0.0702) teacher/usage_max 0.6115 (0.5994) teacher/usage_min 0.0729 (0.1440) teacher/usage_std 0.2202 (0.1973) nleep/row_max_mean 1556.0498 (1548.5685) nleep/row_max_std 46.5475 (55.9302) nleep/row_min_mean 1520.3464 (1517.4184) lr 8.7467e-04 eta 0:07:21
epoch [29/50] batch [120/167] time 0.160 (0.121) data 0.000 (0.002) loss 1.3692 (1.3879) teacher_loss 0.0707 (0.2013) loss_zs_kd 0.0237 (0.0361) loss_oracle 0.6921 (0.5666) kd_loss 0.9406 (0.8853) acc 96.8750 (92.4479) gate/entropy 0.9819 (0.9822) gate/usage_max 0.5694 (0.5692) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1670 (0.1668) teacher/entropy 0.0287 (0.0685) teacher/usage_max 0.5812 (0.5971) teacher/usage_min 0.1980 (0.1447) teacher/usage_std 0.1755 (0.1959) nleep/row_max_mean 1568.3218 (1549.5215) nleep/row_max_std 41.5811 (55.1195) nleep/row_min_mean 1534.7688 (1518.3813) lr 8.7467e-04 eta 0:07:10
epoch [29/50] batch [140/167] time 0.104 (0.120) data 0.000 (0.002) loss 1.3313 (1.3885) teacher_loss 0.0242 (0.2003) loss_zs_kd 0.0145 (0.0352) loss_oracle 0.5814 (0.5704) kd_loss 1.0091 (0.8854) acc 100.0000 (92.5670) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5690 (0.5692) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0869 (0.0686) teacher/usage_max 0.4501 (0.5969) teacher/usage_min 0.1273 (0.1422) teacher/usage_std 0.1461 (0.1966) nleep/row_max_mean 1550.3674 (1550.5612) nleep/row_max_std 61.9119 (55.2473) nleep/row_min_mean 1519.4331 (1519.2618) lr 8.7467e-04 eta 0:07:05
epoch [29/50] batch [160/167] time 0.140 (0.121) data 0.000 (0.002) loss 1.2463 (1.3934) teacher_loss 0.2083 (0.2025) loss_zs_kd 0.0405 (0.0356) loss_oracle 0.5550 (0.5685) kd_loss 0.7402 (0.8888) acc 93.7500 (92.5586) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0790 (0.0691) teacher/usage_max 0.7352 (0.5939) teacher/usage_min 0.1255 (0.1423) teacher/usage_std 0.2842 (0.1952) nleep/row_max_mean 1561.7313 (1550.7606) nleep/row_max_std 62.3700 (55.0053) nleep/row_min_mean 1526.6379 (1519.5167) lr 8.7467e-04 eta 0:07:03
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,187
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,329
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [30/50] batch [20/167] time 0.108 (0.128) data 0.000 (0.014) loss 1.6271 (1.4673) teacher_loss 0.2117 (0.2074) loss_zs_kd 0.0271 (0.0299) loss_oracle 0.7127 (0.5633) kd_loss 1.0454 (0.9633) acc 90.6250 (92.5000) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5693 (0.5691) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0313 (0.0726) teacher/usage_max 0.4693 (0.5164) teacher/usage_min 0.1016 (0.1615) teacher/usage_std 0.1647 (0.1520) nleep/row_max_mean 1562.0376 (1550.4224) nleep/row_max_std 57.5163 (52.6355) nleep/row_min_mean 1525.6736 (1520.1238) lr 8.1262e-04 eta 0:07:26
epoch [30/50] batch [40/167] time 0.149 (0.140) data 0.000 (0.007) loss 1.3561 (1.4662) teacher_loss 0.2532 (0.2216) loss_zs_kd 0.0504 (0.0343) loss_oracle 0.5817 (0.5838) kd_loss 0.7869 (0.9355) acc 87.5000 (91.9531) gate/entropy 0.9822 (0.9822) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0825 (0.0789) teacher/usage_max 0.6833 (0.5364) teacher/usage_min 0.1208 (0.1618) teacher/usage_std 0.2494 (0.1598) nleep/row_max_mean 1557.3439 (1550.2024) nleep/row_max_std 52.9347 (51.5970) nleep/row_min_mean 1524.9949 (1520.2839) lr 8.1262e-04 eta 0:08:06
epoch [30/50] batch [60/167] time 0.158 (0.142) data 0.000 (0.005) loss 1.6005 (1.4569) teacher_loss 0.3386 (0.2054) loss_zs_kd 0.0488 (0.0363) loss_oracle 0.5479 (0.5978) kd_loss 0.9636 (0.9345) acc 87.5000 (92.6042) gate/entropy 0.9824 (0.9822) gate/usage_max 0.5689 (0.5691) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.1069 (0.0794) teacher/usage_max 0.4767 (0.5361) teacher/usage_min 0.2591 (0.1605) teacher/usage_std 0.1014 (0.1611) nleep/row_max_mean 1535.8662 (1550.3346) nleep/row_max_std 61.0455 (51.2053) nleep/row_min_mean 1508.4650 (1520.3265) lr 8.1262e-04 eta 0:08:09
epoch [30/50] batch [80/167] time 0.160 (0.144) data 0.000 (0.004) loss 1.3460 (1.4549) teacher_loss 0.0625 (0.2067) loss_zs_kd 0.0252 (0.0367) loss_oracle 0.6874 (0.6027) kd_loss 0.9272 (0.9285) acc 100.0000 (92.3828) gate/entropy 0.9820 (0.9822) gate/usage_max 0.5694 (0.5691) gate/usage_min 0.2145 (0.2147) gate/usage_std 0.1669 (0.1667) teacher/entropy 0.0746 (0.0788) teacher/usage_max 0.5468 (0.5430) teacher/usage_min 0.1322 (0.1608) teacher/usage_std 0.1695 (0.1641) nleep/row_max_mean 1563.1953 (1552.1834) nleep/row_max_std 50.6874 (50.8076) nleep/row_min_mean 1529.4766 (1522.0677) lr 8.1262e-04 eta 0:08:13
epoch [30/50] batch [100/167] time 0.158 (0.145) data 0.000 (0.003) loss 1.7774 (1.4729) teacher_loss 0.4258 (0.2166) loss_zs_kd 0.0398 (0.0365) loss_oracle 0.6464 (0.6085) kd_loss 1.0085 (0.9338) acc 81.2500 (91.9375) gate/entropy 0.9819 (0.9822) gate/usage_max 0.5694 (0.5691) gate/usage_min 0.2145 (0.2147) gate/usage_std 0.1669 (0.1667) teacher/entropy 0.0711 (0.0764) teacher/usage_max 0.4678 (0.5398) teacher/usage_min 0.2361 (0.1696) teacher/usage_std 0.0982 (0.1596) nleep/row_max_mean 1557.5052 (1553.1175) nleep/row_max_std 42.2874 (50.5993) nleep/row_min_mean 1528.6636 (1522.9588) lr 8.1262e-04 eta 0:08:12
epoch [30/50] batch [120/167] time 0.150 (0.146) data 0.000 (0.003) loss 1.3826 (1.4768) teacher_loss 0.0542 (0.2119) loss_zs_kd 0.0381 (0.0372) loss_oracle 0.5992 (0.6104) kd_loss 1.0097 (0.9411) acc 100.0000 (92.0833) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.1074 (0.0781) teacher/usage_max 0.4290 (0.5323) teacher/usage_min 0.2715 (0.1758) teacher/usage_std 0.0686 (0.1535) nleep/row_max_mean 1554.1654 (1553.2106) nleep/row_max_std 57.4826 (50.6158) nleep/row_min_mean 1527.2222 (1523.2031) lr 8.1262e-04 eta 0:08:12
epoch [30/50] batch [140/167] time 0.138 (0.145) data 0.000 (0.002) loss 1.6617 (1.4793) teacher_loss 0.4004 (0.2100) loss_zs_kd 0.0270 (0.0371) loss_oracle 0.5755 (0.6111) kd_loss 0.9599 (0.9453) acc 78.1250 (92.0982) gate/entropy 0.9822 (0.9822) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0646 (0.0789) teacher/usage_max 0.5246 (0.5288) teacher/usage_min 0.2021 (0.1789) teacher/usage_std 0.1383 (0.1506) nleep/row_max_mean 1552.3687 (1553.1366) nleep/row_max_std 43.6146 (50.8016) nleep/row_min_mean 1522.1846 (1523.2550) lr 8.1262e-04 eta 0:08:08
epoch [30/50] batch [160/167] time 0.085 (0.140) data 0.000 (0.002) loss 1.5160 (1.4963) teacher_loss 0.1008 (0.2111) loss_zs_kd 0.0117 (0.0368) loss_oracle 0.6957 (0.6157) kd_loss 1.0614 (0.9589) acc 96.8750 (91.7969) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5693 (0.5691) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0617 (0.0789) teacher/usage_max 0.4227 (0.5196) teacher/usage_min 0.2881 (0.1845) teacher/usage_std 0.0632 (0.1441) nleep/row_max_mean 1557.2296 (1552.7730) nleep/row_max_std 45.9767 (50.6469) nleep/row_min_mean 1532.2751 (1522.9561) lr 8.1262e-04 eta 0:07:48
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,176
* accuracy: 94.7%
* error: 5.3%
* macro_f1: 95.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,328
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.4%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [31/50] batch [20/167] time 0.191 (0.103) data 0.000 (0.014) loss 1.6038 (1.5784) teacher_loss 0.1310 (0.1863) loss_zs_kd 0.0240 (0.0334) loss_oracle 0.6667 (0.6425) kd_loss 1.1274 (1.0541) acc 93.7500 (93.1250) gate/entropy 0.9828 (0.9823) gate/usage_max 0.5685 (0.5691) gate/usage_min 0.2149 (0.2146) gate/usage_std 0.1663 (0.1667) teacher/entropy 0.0723 (0.0785) teacher/usage_max 0.4796 (0.4490) teacher/usage_min 0.1764 (0.2092) teacher/usage_std 0.1240 (0.1016) nleep/row_max_mean 1543.3430 (1553.9339) nleep/row_max_std 62.5875 (54.5402) nleep/row_min_mean 1514.4149 (1523.7960) lr 7.5131e-04 eta 0:05:42
epoch [31/50] batch [40/167] time 0.082 (0.104) data 0.000 (0.007) loss 1.5930 (1.6130) teacher_loss 0.1888 (0.1761) loss_zs_kd 0.0519 (0.0344) loss_oracle 0.5818 (0.6507) kd_loss 1.0874 (1.0944) acc 90.6250 (93.5938) gate/entropy 0.9821 (0.9823) gate/usage_max 0.5692 (0.5690) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0196 (0.0739) teacher/usage_max 0.4403 (0.4360) teacher/usage_min 0.2196 (0.2283) teacher/usage_std 0.0902 (0.0890) nleep/row_max_mean 1563.0439 (1551.7323) nleep/row_max_std 55.0932 (55.5812) nleep/row_min_mean 1531.6025 (1522.0548) lr 7.5131e-04 eta 0:05:44
epoch [31/50] batch [60/167] time 0.194 (0.110) data 0.001 (0.005) loss 1.6495 (1.6176) teacher_loss 0.2430 (0.1672) loss_zs_kd 0.0396 (0.0347) loss_oracle 0.5862 (0.6472) kd_loss 1.0936 (1.1094) acc 87.5000 (94.0104) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5691 (0.5690) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0762 (0.0732) teacher/usage_max 0.3751 (0.4304) teacher/usage_min 0.2947 (0.2388) teacher/usage_std 0.0329 (0.0821) nleep/row_max_mean 1566.0164 (1553.5032) nleep/row_max_std 53.1640 (54.1264) nleep/row_min_mean 1535.9773 (1523.3415) lr 7.5131e-04 eta 0:06:01
epoch [31/50] batch [80/167] time 0.082 (0.113) data 0.000 (0.004) loss 1.5640 (1.6324) teacher_loss 0.1220 (0.1689) loss_zs_kd 0.0258 (0.0344) loss_oracle 0.5651 (0.6488) kd_loss 1.1465 (1.1219) acc 93.7500 (93.7109) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1666 (0.1666) teacher/entropy 0.0573 (0.0774) teacher/usage_max 0.3544 (0.4257) teacher/usage_min 0.3051 (0.2412) teacher/usage_std 0.0208 (0.0788) nleep/row_max_mean 1541.0000 (1552.9198) nleep/row_max_std 61.0370 (54.1461) nleep/row_min_mean 1510.7739 (1522.8092) lr 7.5131e-04 eta 0:06:08
epoch [31/50] batch [100/167] time 0.079 (0.114) data 0.000 (0.003) loss 1.7641 (1.6544) teacher_loss 0.1867 (0.1744) loss_zs_kd 0.0656 (0.0356) loss_oracle 0.7740 (0.6612) kd_loss 1.1576 (1.1316) acc 90.6250 (93.1562) gate/entropy 0.9824 (0.9824) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1666 (0.1666) teacher/entropy 0.0709 (0.0755) teacher/usage_max 0.5476 (0.4254) teacher/usage_min 0.1399 (0.2421) teacher/usage_std 0.1671 (0.0784) nleep/row_max_mean 1558.3141 (1552.2818) nleep/row_max_std 58.3226 (53.5997) nleep/row_min_mean 1523.9407 (1521.9768) lr 7.5131e-04 eta 0:06:09
epoch [31/50] batch [120/167] time 0.081 (0.115) data 0.000 (0.003) loss 1.9838 (1.6821) teacher_loss 0.1638 (0.1751) loss_zs_kd 0.0530 (0.0373) loss_oracle 0.9467 (0.6831) kd_loss 1.3202 (1.1467) acc 93.7500 (93.0729) gate/entropy 0.9827 (0.9824) gate/usage_max 0.5686 (0.5689) gate/usage_min 0.2148 (0.2147) gate/usage_std 0.1663 (0.1666) teacher/entropy 0.0610 (0.0736) teacher/usage_max 0.4816 (0.4284) teacher/usage_min 0.1562 (0.2392) teacher/usage_std 0.1344 (0.0808) nleep/row_max_mean 1545.4207 (1551.8960) nleep/row_max_std 48.7676 (53.2729) nleep/row_min_mean 1506.2725 (1521.3086) lr 7.5131e-04 eta 0:06:10
epoch [31/50] batch [140/167] time 0.161 (0.116) data 0.000 (0.002) loss 1.8751 (1.6964) teacher_loss 0.1058 (0.1707) loss_zs_kd 0.0266 (0.0366) loss_oracle 0.8622 (0.6937) kd_loss 1.3249 (1.1605) acc 96.8750 (93.2366) gate/entropy 0.9828 (0.9824) gate/usage_max 0.5685 (0.5689) gate/usage_min 0.2148 (0.2147) gate/usage_std 0.1663 (0.1666) teacher/entropy 0.0575 (0.0729) teacher/usage_max 0.4416 (0.4332) teacher/usage_min 0.1551 (0.2356) teacher/usage_std 0.1270 (0.0846) nleep/row_max_mean 1540.6511 (1550.6239) nleep/row_max_std 59.2234 (53.1415) nleep/row_min_mean 1505.3177 (1519.7408) lr 7.5131e-04 eta 0:06:11
epoch [31/50] batch [160/167] time 0.132 (0.121) data 0.000 (0.002) loss 1.6639 (1.7164) teacher_loss 0.0960 (0.1781) loss_zs_kd 0.0235 (0.0365) loss_oracle 0.7370 (0.7043) kd_loss 1.1876 (1.1680) acc 96.8750 (92.8320) gate/entropy 0.9828 (0.9825) gate/usage_max 0.5685 (0.5689) gate/usage_min 0.2148 (0.2147) gate/usage_std 0.1663 (0.1665) teacher/entropy 0.1081 (0.0713) teacher/usage_max 0.4656 (0.4395) teacher/usage_min 0.2438 (0.2333) teacher/usage_std 0.0954 (0.0887) nleep/row_max_mean 1543.2131 (1550.3250) nleep/row_max_std 50.0663 (53.0608) nleep/row_min_mean 1509.7666 (1519.1399) lr 7.5131e-04 eta 0:06:24
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,192
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [32/50] batch [20/167] time 0.149 (0.168) data 0.000 (0.017) loss 1.6658 (1.7805) teacher_loss 0.1972 (0.2026) loss_zs_kd 0.0353 (0.0347) loss_oracle 0.7562 (0.7366) kd_loss 1.0729 (1.1922) acc 90.6250 (92.1875) gate/entropy 0.9830 (0.9828) gate/usage_max 0.5683 (0.5686) gate/usage_min 0.2149 (0.2148) gate/usage_std 0.1661 (0.1663) teacher/entropy 0.0993 (0.0732) teacher/usage_max 0.3795 (0.4953) teacher/usage_min 0.2502 (0.2111) teacher/usage_std 0.0589 (0.1238) nleep/row_max_mean 1548.2589 (1553.1563) nleep/row_max_std 55.5320 (49.9695) nleep/row_min_mean 1512.0857 (1517.8977) lr 6.9098e-04 eta 0:08:50
epoch [32/50] batch [40/167] time 0.155 (0.160) data 0.000 (0.008) loss 1.7515 (1.7952) teacher_loss 0.2987 (0.2019) loss_zs_kd 0.0405 (0.0343) loss_oracle 0.5921 (0.7275) kd_loss 1.1365 (1.2125) acc 90.6250 (92.9688) gate/entropy 0.9828 (0.9828) gate/usage_max 0.5685 (0.5685) gate/usage_min 0.2147 (0.2148) gate/usage_std 0.1663 (0.1663) teacher/entropy 0.0881 (0.0724) teacher/usage_max 0.3502 (0.5220) teacher/usage_min 0.3185 (0.2002) teacher/usage_std 0.0130 (0.1399) nleep/row_max_mean 1554.8560 (1551.8567) nleep/row_max_std 50.0575 (48.6209) nleep/row_min_mean 1519.3737 (1515.8521) lr 6.9098e-04 eta 0:08:22
epoch [32/50] batch [60/167] time 0.100 (0.143) data 0.001 (0.006) loss 1.7554 (1.8010) teacher_loss 0.2285 (0.2030) loss_zs_kd 0.0514 (0.0347) loss_oracle 0.6309 (0.7223) kd_loss 1.1858 (1.2196) acc 93.7500 (92.6042) gate/entropy 0.9826 (0.9828) gate/usage_max 0.5687 (0.5685) gate/usage_min 0.2146 (0.2148) gate/usage_std 0.1664 (0.1663) teacher/entropy 0.0563 (0.0700) teacher/usage_max 0.4846 (0.5382) teacher/usage_min 0.2168 (0.1907) teacher/usage_std 0.1120 (0.1513) nleep/row_max_mean 1564.1376 (1553.2338) nleep/row_max_std 56.1660 (48.6651) nleep/row_min_mean 1526.6995 (1516.6098) lr 6.9098e-04 eta 0:07:24
epoch [32/50] batch [80/167] time 0.153 (0.137) data 0.000 (0.004) loss 1.7843 (1.8126) teacher_loss 0.0956 (0.2056) loss_zs_kd 0.0215 (0.0344) loss_oracle 0.7597 (0.7253) kd_loss 1.2981 (1.2272) acc 96.8750 (92.5000) gate/entropy 0.9827 (0.9829) gate/usage_max 0.5686 (0.5684) gate/usage_min 0.2146 (0.2148) gate/usage_std 0.1664 (0.1662) teacher/entropy 0.0207 (0.0706) teacher/usage_max 0.6331 (0.5492) teacher/usage_min 0.1482 (0.1809) teacher/usage_std 0.2139 (0.1603) nleep/row_max_mean 1566.6062 (1552.8727) nleep/row_max_std 51.6547 (48.7757) nleep/row_min_mean 1528.2136 (1515.7019) lr 6.9098e-04 eta 0:07:02
epoch [32/50] batch [100/167] time 0.107 (0.134) data 0.000 (0.004) loss 1.6290 (1.8158) teacher_loss 0.1778 (0.2092) loss_zs_kd 0.0564 (0.0351) loss_oracle 0.6269 (0.7273) kd_loss 1.1095 (1.2253) acc 90.6250 (92.2500) gate/entropy 0.9829 (0.9829) gate/usage_max 0.5685 (0.5684) gate/usage_min 0.2147 (0.2148) gate/usage_std 0.1663 (0.1662) teacher/entropy 0.0734 (0.0727) teacher/usage_max 0.4920 (0.5468) teacher/usage_min 0.1492 (0.1809) teacher/usage_std 0.1411 (0.1590) nleep/row_max_mean 1560.0023 (1553.1824) nleep/row_max_std 54.3648 (49.4633) nleep/row_min_mean 1523.3635 (1515.6400) lr 6.9098e-04 eta 0:06:52
epoch [32/50] batch [120/167] time 0.073 (0.130) data 0.000 (0.003) loss 1.9330 (1.8295) teacher_loss 0.1260 (0.2119) loss_zs_kd 0.0359 (0.0359) loss_oracle 0.8572 (0.7408) kd_loss 1.3604 (1.2292) acc 100.0000 (92.0573) gate/entropy 0.9833 (0.9830) gate/usage_max 0.5680 (0.5684) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1659 (0.1662) teacher/entropy 0.0482 (0.0715) teacher/usage_max 0.6401 (0.5495) teacher/usage_min 0.1250 (0.1806) teacher/usage_std 0.2215 (0.1605) nleep/row_max_mean 1547.1082 (1552.9081) nleep/row_max_std 48.3044 (49.2272) nleep/row_min_mean 1506.1545 (1515.0386) lr 6.9098e-04 eta 0:06:36
epoch [32/50] batch [140/167] time 0.193 (0.127) data 0.000 (0.003) loss 1.7038 (1.8367) teacher_loss 0.1600 (0.2121) loss_zs_kd 0.0430 (0.0369) loss_oracle 0.7307 (0.7466) kd_loss 1.1569 (1.2328) acc 90.6250 (92.0536) gate/entropy 0.9837 (0.9830) gate/usage_max 0.5676 (0.5683) gate/usage_min 0.2150 (0.2148) gate/usage_std 0.1656 (0.1662) teacher/entropy 0.1344 (0.0732) teacher/usage_max 0.6231 (0.5588) teacher/usage_min 0.1322 (0.1758) teacher/usage_std 0.2100 (0.1669) nleep/row_max_mean 1539.5869 (1552.9561) nleep/row_max_std 54.0467 (49.4226) nleep/row_min_mean 1497.7487 (1514.6846) lr 6.9098e-04 eta 0:06:25
epoch [32/50] batch [160/167] time 0.189 (0.127) data 0.000 (0.002) loss 1.7654 (1.8413) teacher_loss 0.1707 (0.2106) loss_zs_kd 0.0126 (0.0364) loss_oracle 0.6350 (0.7470) kd_loss 1.2709 (1.2390) acc 90.6250 (92.2266) gate/entropy 0.9832 (0.9830) gate/usage_max 0.5681 (0.5683) gate/usage_min 0.2147 (0.2148) gate/usage_std 0.1660 (0.1661) teacher/entropy 0.0950 (0.0727) teacher/usage_max 0.6132 (0.5699) teacher/usage_min 0.1692 (0.1721) teacher/usage_std 0.1989 (0.1742) nleep/row_max_mean 1559.4485 (1553.1214) nleep/row_max_std 47.5016 (49.9802) nleep/row_min_mean 1520.6260 (1514.4878) lr 6.9098e-04 eta 0:06:21
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,198
* accuracy: 95.7%
* error: 4.3%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [33/50] batch [20/167] time 0.069 (0.136) data 0.000 (0.016) loss 1.8915 (1.8929) teacher_loss 0.2501 (0.2174) loss_zs_kd 0.0293 (0.0330) loss_oracle 0.7183 (0.7743) kd_loss 1.2676 (1.2718) acc 93.7500 (92.3438) gate/entropy 0.9832 (0.9834) gate/usage_max 0.5681 (0.5678) gate/usage_min 0.2146 (0.2148) gate/usage_std 0.1660 (0.1658) teacher/entropy 0.0371 (0.0639) teacher/usage_max 0.7339 (0.6600) teacher/usage_min 0.0358 (0.1249) teacher/usage_std 0.2942 (0.2363) nleep/row_max_mean 1565.1849 (1555.2879) nleep/row_max_std 47.3197 (54.4622) nleep/row_min_mean 1526.2517 (1514.5574) lr 6.3188e-04 eta 0:06:47
epoch [33/50] batch [40/167] time 0.150 (0.135) data 0.000 (0.008) loss 1.8717 (1.9030) teacher_loss 0.2142 (0.2231) loss_zs_kd 0.0505 (0.0348) loss_oracle 0.6197 (0.7431) kd_loss 1.3223 (1.2909) acc 90.6250 (91.7969) gate/entropy 0.9836 (0.9835) gate/usage_max 0.5677 (0.5678) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1657 (0.1658) teacher/entropy 0.0815 (0.0628) teacher/usage_max 0.7223 (0.6893) teacher/usage_min 0.1281 (0.1141) teacher/usage_std 0.2752 (0.2560) nleep/row_max_mean 1560.9797 (1555.0243) nleep/row_max_std 60.6992 (55.0756) nleep/row_min_mean 1519.6206 (1514.0923) lr 6.3188e-04 eta 0:06:41
epoch [33/50] batch [60/167] time 0.168 (0.142) data 0.001 (0.005) loss 1.7378 (1.8847) teacher_loss 0.1081 (0.2140) loss_zs_kd 0.0260 (0.0346) loss_oracle 0.6373 (0.7231) kd_loss 1.2981 (1.2919) acc 100.0000 (92.5000) gate/entropy 0.9846 (0.9836) gate/usage_max 0.5666 (0.5677) gate/usage_min 0.2151 (0.2148) gate/usage_std 0.1650 (0.1657) teacher/entropy 0.1372 (0.0649) teacher/usage_max 0.6764 (0.7001) teacher/usage_min 0.0938 (0.1082) teacher/usage_std 0.2489 (0.2633) nleep/row_max_mean 1531.8148 (1556.8120) nleep/row_max_std 65.1073 (55.5292) nleep/row_min_mean 1492.6848 (1515.6561) lr 6.3188e-04 eta 0:06:59
epoch [33/50] batch [80/167] time 0.141 (0.144) data 0.000 (0.004) loss 1.9371 (1.8998) teacher_loss 0.1120 (0.2115) loss_zs_kd 0.0349 (0.0342) loss_oracle 0.7153 (0.7332) kd_loss 1.4500 (1.3046) acc 100.0000 (92.7344) gate/entropy 0.9838 (0.9836) gate/usage_max 0.5674 (0.5677) gate/usage_min 0.2147 (0.2148) gate/usage_std 0.1655 (0.1657) teacher/entropy 0.0434 (0.0620) teacher/usage_max 0.8942 (0.7121) teacher/usage_min 0.0330 (0.1023) teacher/usage_std 0.3969 (0.2716) nleep/row_max_mean 1554.5442 (1557.2431) nleep/row_max_std 57.5582 (55.3007) nleep/row_min_mean 1513.8002 (1515.8392) lr 6.3188e-04 eta 0:06:59
epoch [33/50] batch [100/167] time 0.144 (0.144) data 0.000 (0.003) loss 2.3502 (1.9306) teacher_loss 0.4434 (0.2291) loss_zs_kd 0.0247 (0.0354) loss_oracle 0.8943 (0.7448) kd_loss 1.4473 (1.3114) acc 87.5000 (92.0312) gate/entropy 0.9838 (0.9837) gate/usage_max 0.5675 (0.5676) gate/usage_min 0.2146 (0.2148) gate/usage_std 0.1656 (0.1657) teacher/entropy 0.0171 (0.0585) teacher/usage_max 0.9045 (0.7228) teacher/usage_min 0.0330 (0.0973) teacher/usage_std 0.4040 (0.2790) nleep/row_max_mean 1560.2850 (1556.6109) nleep/row_max_std 64.7990 (55.1718) nleep/row_min_mean 1518.3276 (1515.0594) lr 6.3188e-04 eta 0:06:59
epoch [33/50] batch [120/167] time 0.169 (0.146) data 0.000 (0.003) loss 1.8872 (1.9531) teacher_loss 0.1602 (0.2323) loss_zs_kd 0.0217 (0.0353) loss_oracle 0.7920 (0.7686) kd_loss 1.3201 (1.3189) acc 93.7500 (91.8229) gate/entropy 0.9840 (0.9837) gate/usage_max 0.5672 (0.5675) gate/usage_min 0.2147 (0.2148) gate/usage_std 0.1654 (0.1656) teacher/entropy 0.0544 (0.0575) teacher/usage_max 0.7587 (0.7361) teacher/usage_min 0.0853 (0.0927) teacher/usage_std 0.3022 (0.2880) nleep/row_max_mean 1563.5098 (1556.1673) nleep/row_max_std 40.9953 (54.7725) nleep/row_min_mean 1521.3013 (1514.3816) lr 6.3188e-04 eta 0:07:00
epoch [33/50] batch [140/167] time 0.163 (0.147) data 0.000 (0.002) loss 2.0250 (1.9574) teacher_loss 0.1821 (0.2261) loss_zs_kd 0.0166 (0.0345) loss_oracle 0.8756 (0.7844) kd_loss 1.3969 (1.3219) acc 90.6250 (92.0759) gate/entropy 0.9847 (0.9838) gate/usage_max 0.5665 (0.5674) gate/usage_min 0.2149 (0.2148) gate/usage_std 0.1649 (0.1655) teacher/entropy 0.0348 (0.0563) teacher/usage_max 0.8625 (0.7443) teacher/usage_min 0.0438 (0.0869) teacher/usage_std 0.3747 (0.2939) nleep/row_max_mean 1547.5885 (1555.1678) nleep/row_max_std 54.4732 (54.3910) nleep/row_min_mean 1505.3668 (1513.2235) lr 6.3188e-04 eta 0:07:02
epoch [33/50] batch [160/167] time 0.082 (0.141) data 0.000 (0.002) loss 2.1798 (1.9750) teacher_loss 0.2844 (0.2318) loss_zs_kd 0.0353 (0.0353) loss_oracle 0.9650 (0.8018) kd_loss 1.3952 (1.3247) acc 93.7500 (91.7969) gate/entropy 0.9843 (0.9839) gate/usage_max 0.5670 (0.5674) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1652 (0.1655) teacher/entropy 0.0264 (0.0542) teacher/usage_max 0.8656 (0.7514) teacher/usage_min 0.0298 (0.0823) teacher/usage_std 0.3776 (0.2990) nleep/row_max_mean 1565.6798 (1555.8436) nleep/row_max_std 53.4070 (53.7110) nleep/row_min_mean 1521.6801 (1513.6162) lr 6.3188e-04 eta 0:06:41
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,186
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.7%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,319
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 99.0%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [34/50] batch [20/167] time 0.067 (0.106) data 0.000 (0.016) loss 2.0712 (2.0709) teacher_loss 0.0895 (0.2209) loss_zs_kd 0.0243 (0.0369) loss_oracle 1.0917 (0.9241) kd_loss 1.4237 (1.3695) acc 100.0000 (92.0312) gate/entropy 0.9847 (0.9845) gate/usage_max 0.5666 (0.5668) gate/usage_min 0.2147 (0.2146) gate/usage_std 0.1649 (0.1651) teacher/entropy 0.0071 (0.0306) teacher/usage_max 0.8731 (0.8096) teacher/usage_min 0.0331 (0.0617) teacher/usage_std 0.3825 (0.3389) nleep/row_max_mean 1544.3612 (1555.1871) nleep/row_max_std 57.9264 (52.6762) nleep/row_min_mean 1495.6559 (1510.2224) lr 5.7422e-04 eta 0:04:57
epoch [34/50] batch [40/167] time 0.067 (0.108) data 0.000 (0.008) loss 2.0476 (2.0881) teacher_loss 0.1615 (0.2120) loss_zs_kd 0.0529 (0.0408) loss_oracle 0.8619 (0.9596) kd_loss 1.4287 (1.3760) acc 96.8750 (91.7969) gate/entropy 0.9847 (0.9846) gate/usage_max 0.5665 (0.5666) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1649 (0.1650) teacher/entropy 0.0036 (0.0282) teacher/usage_max 0.7814 (0.8067) teacher/usage_min 0.0939 (0.0646) teacher/usage_std 0.3171 (0.3367) nleep/row_max_mean 1560.9575 (1555.3682) nleep/row_max_std 47.5158 (53.1397) nleep/row_min_mean 1517.5635 (1510.3918) lr 5.7422e-04 eta 0:05:02
epoch [34/50] batch [60/167] time 0.085 (0.111) data 0.001 (0.006) loss 2.1369 (2.0885) teacher_loss 0.1989 (0.2080) loss_zs_kd 0.0355 (0.0422) loss_oracle 1.0558 (0.9708) kd_loss 1.3923 (1.3739) acc 90.6250 (91.9271) gate/entropy 0.9850 (0.9847) gate/usage_max 0.5662 (0.5666) gate/usage_min 0.2147 (0.2146) gate/usage_std 0.1647 (0.1649) teacher/entropy 0.0085 (0.0262) teacher/usage_max 0.8109 (0.7955) teacher/usage_min 0.0643 (0.0686) teacher/usage_std 0.3386 (0.3291) nleep/row_max_mean 1558.3879 (1556.5890) nleep/row_max_std 39.5259 (52.8659) nleep/row_min_mean 1513.8676 (1511.5165) lr 5.7422e-04 eta 0:05:07
epoch [34/50] batch [80/167] time 0.092 (0.112) data 0.000 (0.004) loss 2.0146 (2.0834) teacher_loss 0.0397 (0.2037) loss_zs_kd 0.0306 (0.0412) loss_oracle 1.0677 (0.9755) kd_loss 1.4258 (1.3714) acc 100.0000 (92.2656) gate/entropy 0.9855 (0.9848) gate/usage_max 0.5656 (0.5664) gate/usage_min 0.2148 (0.2147) gate/usage_std 0.1643 (0.1648) teacher/entropy 0.0037 (0.0256) teacher/usage_max 0.7818 (0.7847) teacher/usage_min 0.0938 (0.0754) teacher/usage_std 0.3174 (0.3212) nleep/row_max_mean 1535.6624 (1554.5200) nleep/row_max_std 55.4259 (53.6700) nleep/row_min_mean 1489.3857 (1509.5865) lr 5.7422e-04 eta 0:05:07
epoch [34/50] batch [100/167] time 0.169 (0.113) data 0.000 (0.003) loss 2.1534 (2.0945) teacher_loss 0.1471 (0.2064) loss_zs_kd 0.0255 (0.0410) loss_oracle 1.0846 (0.9846) kd_loss 1.4512 (1.3752) acc 90.6250 (92.2812) gate/entropy 0.9853 (0.9849) gate/usage_max 0.5659 (0.5664) gate/usage_min 0.2146 (0.2146) gate/usage_std 0.1645 (0.1648) teacher/entropy 0.0087 (0.0252) teacher/usage_max 0.8126 (0.7858) teacher/usage_min 0.0625 (0.0723) teacher/usage_std 0.3398 (0.3223) nleep/row_max_mean 1559.8276 (1554.3337) nleep/row_max_std 50.1795 (53.0080) nleep/row_min_mean 1514.7556 (1509.5581) lr 5.7422e-04 eta 0:05:10
epoch [34/50] batch [120/167] time 0.106 (0.116) data 0.000 (0.003) loss 2.2171 (2.1009) teacher_loss 0.2239 (0.2115) loss_zs_kd 0.0342 (0.0414) loss_oracle 1.1111 (0.9880) kd_loss 1.4205 (1.3747) acc 93.7500 (92.1615) gate/entropy 0.9862 (0.9850) gate/usage_max 0.5650 (0.5663) gate/usage_min 0.2149 (0.2146) gate/usage_std 0.1638 (0.1647) teacher/entropy 0.0078 (0.0249) teacher/usage_max 0.7493 (0.7823) teacher/usage_min 0.0938 (0.0737) teacher/usage_std 0.2953 (0.3198) nleep/row_max_mean 1534.6423 (1554.0789) nleep/row_max_std 69.7204 (53.0414) nleep/row_min_mean 1489.9426 (1509.2759) lr 5.7422e-04 eta 0:05:15
epoch [34/50] batch [140/167] time 0.163 (0.117) data 0.000 (0.003) loss 2.1345 (2.1035) teacher_loss 0.2636 (0.2098) loss_zs_kd 0.0249 (0.0406) loss_oracle 0.9416 (0.9914) kd_loss 1.3876 (1.3777) acc 96.8750 (92.3438) gate/entropy 0.9857 (0.9850) gate/usage_max 0.5655 (0.5662) gate/usage_min 0.2146 (0.2146) gate/usage_std 0.1642 (0.1646) teacher/entropy 0.0100 (0.0249) teacher/usage_max 0.8109 (0.7844) teacher/usage_min 0.0643 (0.0738) teacher/usage_std 0.3386 (0.3212) nleep/row_max_mean 1547.9850 (1553.4216) nleep/row_max_std 49.9490 (53.4149) nleep/row_min_mean 1504.4025 (1508.7035) lr 5.7422e-04 eta 0:05:15
epoch [34/50] batch [160/167] time 0.140 (0.121) data 0.000 (0.002) loss 2.0772 (2.1034) teacher_loss 0.2267 (0.2127) loss_zs_kd 0.0480 (0.0403) loss_oracle 0.9853 (0.9879) kd_loss 1.3339 (1.3766) acc 90.6250 (92.1094) gate/entropy 0.9857 (0.9851) gate/usage_max 0.5655 (0.5661) gate/usage_min 0.2145 (0.2146) gate/usage_std 0.1642 (0.1646) teacher/entropy 0.0428 (0.0255) teacher/usage_max 0.8089 (0.7846) teacher/usage_min 0.0450 (0.0730) teacher/usage_std 0.3388 (0.3213) nleep/row_max_mean 1554.2441 (1553.2688) nleep/row_max_std 55.2913 (53.2988) nleep/row_min_mean 1506.6969 (1508.6103) lr 5.7422e-04 eta 0:05:24
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,189
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,319
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 99.0%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [35/50] batch [20/167] time 0.160 (0.167) data 0.000 (0.016) loss 1.8070 (2.0655) teacher_loss 0.0360 (0.1977) loss_zs_kd 0.0276 (0.0379) loss_oracle 0.8660 (0.9528) kd_loss 1.3242 (1.3724) acc 100.0000 (93.5938) gate/entropy 0.9860 (0.9861) gate/usage_max 0.5651 (0.5651) gate/usage_min 0.2145 (0.2145) gate/usage_std 0.1639 (0.1639) teacher/entropy 0.0103 (0.0269) teacher/usage_max 0.7477 (0.7854) teacher/usage_min 0.0624 (0.0785) teacher/usage_std 0.2976 (0.3211) nleep/row_max_mean 1557.9641 (1550.1530) nleep/row_max_std 44.8669 (51.2819) nleep/row_min_mean 1513.4739 (1505.5747) lr 5.1825e-04 eta 0:07:23
epoch [35/50] batch [40/167] time 0.169 (0.159) data 0.000 (0.008) loss 1.9874 (2.1019) teacher_loss 0.2187 (0.2234) loss_zs_kd 0.0522 (0.0402) loss_oracle 0.7835 (0.9603) kd_loss 1.3508 (1.3783) acc 90.6250 (92.4219) gate/entropy 0.9862 (0.9862) gate/usage_max 0.5649 (0.5650) gate/usage_min 0.2144 (0.2145) gate/usage_std 0.1638 (0.1638) teacher/entropy 0.0238 (0.0260) teacher/usage_max 0.7594 (0.7900) teacher/usage_min 0.0938 (0.0742) teacher/usage_std 0.3020 (0.3245) nleep/row_max_mean 1543.4340 (1548.6321) nleep/row_max_std 51.8335 (49.9257) nleep/row_min_mean 1501.3464 (1504.4079) lr 5.1825e-04 eta 0:06:58
epoch [35/50] batch [60/167] time 0.106 (0.140) data 0.001 (0.005) loss 2.0916 (2.0933) teacher_loss 0.2143 (0.2109) loss_zs_kd 0.0640 (0.0399) loss_oracle 1.0223 (0.9706) kd_loss 1.3342 (1.3771) acc 87.5000 (92.5521) gate/entropy 0.9866 (0.9863) gate/usage_max 0.5645 (0.5649) gate/usage_min 0.2145 (0.2145) gate/usage_std 0.1635 (0.1637) teacher/entropy 0.0009 (0.0263) teacher/usage_max 0.7501 (0.7816) teacher/usage_min 0.0625 (0.0741) teacher/usage_std 0.2991 (0.3192) nleep/row_max_mean 1538.9481 (1547.3537) nleep/row_max_std 53.0735 (49.8301) nleep/row_min_mean 1495.1324 (1503.1890) lr 5.1825e-04 eta 0:06:05
epoch [35/50] batch [80/167] time 0.128 (0.135) data 0.000 (0.004) loss 1.9232 (2.0974) teacher_loss 0.1293 (0.2121) loss_zs_kd 0.0222 (0.0400) loss_oracle 0.8746 (0.9735) kd_loss 1.3454 (1.3786) acc 93.7500 (92.3047) gate/entropy 0.9873 (0.9864) gate/usage_max 0.5638 (0.5648) gate/usage_min 0.2146 (0.2145) gate/usage_std 0.1630 (0.1637) teacher/entropy 0.0774 (0.0286) teacher/usage_max 0.7807 (0.7816) teacher/usage_min 0.0941 (0.0763) teacher/usage_std 0.3166 (0.3189) nleep/row_max_mean 1533.4443 (1546.6995) nleep/row_max_std 53.6686 (49.4810) nleep/row_min_mean 1492.3042 (1502.6372) lr 5.1825e-04 eta 0:05:49
epoch [35/50] batch [100/167] time 0.084 (0.131) data 0.000 (0.003) loss 2.0967 (2.1036) teacher_loss 0.1948 (0.2156) loss_zs_kd 0.0718 (0.0408) loss_oracle 1.0367 (0.9759) kd_loss 1.3476 (1.3797) acc 90.6250 (92.2188) gate/entropy 0.9873 (0.9864) gate/usage_max 0.5637 (0.5647) gate/usage_min 0.2145 (0.2145) gate/usage_std 0.1629 (0.1636) teacher/entropy 0.0400 (0.0272) teacher/usage_max 0.7441 (0.7848) teacher/usage_min 0.1251 (0.0750) teacher/usage_std 0.2905 (0.3210) nleep/row_max_mean 1532.8970 (1546.0052) nleep/row_max_std 51.5167 (48.9986) nleep/row_min_mean 1490.3364 (1502.1170) lr 5.1825e-04 eta 0:05:36
epoch [35/50] batch [120/167] time 0.098 (0.129) data 0.000 (0.003) loss 1.9783 (2.0936) teacher_loss 0.0860 (0.2085) loss_zs_kd 0.0546 (0.0407) loss_oracle 0.9198 (0.9700) kd_loss 1.4050 (1.3798) acc 96.8750 (92.2656) gate/entropy 0.9878 (0.9866) gate/usage_max 0.5632 (0.5645) gate/usage_min 0.2146 (0.2145) gate/usage_std 0.1626 (0.1635) teacher/entropy 0.0142 (0.0273) teacher/usage_max 0.8177 (0.7837) teacher/usage_min 0.0885 (0.0772) teacher/usage_std 0.3425 (0.3202) nleep/row_max_mean 1518.8441 (1545.0898) nleep/row_max_std 54.2439 (48.8935) nleep/row_min_mean 1479.2379 (1501.3854) lr 5.1825e-04 eta 0:05:28
epoch [35/50] batch [140/167] time 0.068 (0.125) data 0.000 (0.002) loss 2.1484 (2.0953) teacher_loss 0.2021 (0.2085) loss_zs_kd 0.0391 (0.0411) loss_oracle 0.9976 (0.9721) kd_loss 1.4279 (1.3802) acc 90.6250 (92.2545) gate/entropy 0.9874 (0.9867) gate/usage_max 0.5636 (0.5644) gate/usage_min 0.2143 (0.2144) gate/usage_std 0.1629 (0.1634) teacher/entropy 0.0216 (0.0259) teacher/usage_max 0.8557 (0.7866) teacher/usage_min 0.0625 (0.0750) teacher/usage_std 0.3694 (0.3223) nleep/row_max_mean 1547.0411 (1545.2055) nleep/row_max_std 44.0421 (48.9563) nleep/row_min_mean 1504.8853 (1501.7281) lr 5.1825e-04 eta 0:05:15
epoch [35/50] batch [160/167] time 0.163 (0.122) data 0.000 (0.002) loss 2.2403 (2.0929) teacher_loss 0.3953 (0.2068) loss_zs_kd 0.0410 (0.0409) loss_oracle 0.9898 (0.9739) kd_loss 1.3296 (1.3787) acc 93.7500 (92.4219) gate/entropy 0.9872 (0.9868) gate/usage_max 0.5639 (0.5643) gate/usage_min 0.2141 (0.2144) gate/usage_std 0.1630 (0.1634) teacher/entropy 0.0019 (0.0254) teacher/usage_max 0.7500 (0.7867) teacher/usage_min 0.0625 (0.0742) teacher/usage_std 0.2990 (0.3224) nleep/row_max_mean 1555.2207 (1545.3196) nleep/row_max_std 48.4092 (49.2774) nleep/row_min_mean 1512.0206 (1502.0447) lr 5.1825e-04 eta 0:05:06
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,191
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [36/50] batch [20/167] time 0.165 (0.148) data 0.000 (0.020) loss 2.2647 (2.0587) teacher_loss 0.4563 (0.2100) loss_zs_kd 0.0301 (0.0381) loss_oracle 0.9370 (0.9590) kd_loss 1.3249 (1.3502) acc 87.5000 (91.5625) gate/entropy 0.9881 (0.9879) gate/usage_max 0.5629 (0.5632) gate/usage_min 0.2143 (0.2142) gate/usage_std 0.1624 (0.1625) teacher/entropy 0.0479 (0.0243) teacher/usage_max 0.7350 (0.7577) teacher/usage_min 0.1218 (0.0830) teacher/usage_std 0.2842 (0.3024) nleep/row_max_mean 1541.9683 (1547.2331) nleep/row_max_std 50.6286 (48.2057) nleep/row_min_mean 1501.7841 (1505.8512) lr 4.6417e-04 eta 0:06:08
epoch [36/50] batch [40/167] time 0.085 (0.129) data 0.000 (0.010) loss 2.0449 (2.0774) teacher_loss 0.2018 (0.1904) loss_zs_kd 0.0358 (0.0379) loss_oracle 1.0100 (1.0019) kd_loss 1.3201 (1.3671) acc 90.6250 (92.7344) gate/entropy 0.9878 (0.9880) gate/usage_max 0.5632 (0.5630) gate/usage_min 0.2140 (0.2142) gate/usage_std 0.1626 (0.1624) teacher/entropy 0.0160 (0.0242) teacher/usage_max 0.7564 (0.7746) teacher/usage_min 0.0625 (0.0721) teacher/usage_std 0.3030 (0.3144) nleep/row_max_mean 1549.5972 (1543.8650) nleep/row_max_std 48.5037 (48.1283) nleep/row_min_mean 1507.0950 (1502.7257) lr 4.6417e-04 eta 0:05:17
epoch [36/50] batch [60/167] time 0.165 (0.132) data 0.000 (0.007) loss 1.9548 (2.0722) teacher_loss 0.1327 (0.1889) loss_zs_kd 0.0342 (0.0399) loss_oracle 0.9375 (1.0058) kd_loss 1.3362 (1.3604) acc 93.7500 (92.9688) gate/entropy 0.9886 (0.9882) gate/usage_max 0.5624 (0.5628) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1620 (0.1623) teacher/entropy 0.0518 (0.0257) teacher/usage_max 0.8516 (0.7798) teacher/usage_min 0.0284 (0.0696) teacher/usage_std 0.3684 (0.3181) nleep/row_max_mean 1550.4062 (1543.6294) nleep/row_max_std 49.0319 (48.4968) nleep/row_min_mean 1509.5342 (1502.6075) lr 4.6417e-04 eta 0:05:22
epoch [36/50] batch [80/167] time 0.173 (0.139) data 0.000 (0.005) loss 1.9373 (2.0730) teacher_loss 0.1416 (0.1887) loss_zs_kd 0.0384 (0.0402) loss_oracle 0.9552 (1.0036) kd_loss 1.2988 (1.3624) acc 93.7500 (93.1250) gate/entropy 0.9887 (0.9883) gate/usage_max 0.5622 (0.5627) gate/usage_min 0.2141 (0.2142) gate/usage_std 0.1619 (0.1622) teacher/entropy 0.0293 (0.0250) teacher/usage_max 0.6850 (0.7757) teacher/usage_min 0.1266 (0.0751) teacher/usage_std 0.2499 (0.3149) nleep/row_max_mean 1552.9247 (1544.2022) nleep/row_max_std 55.0642 (49.6909) nleep/row_min_mean 1513.9224 (1503.4261) lr 4.6417e-04 eta 0:05:37
epoch [36/50] batch [100/167] time 0.161 (0.142) data 0.000 (0.004) loss 2.1701 (2.0679) teacher_loss 0.1735 (0.1869) loss_zs_kd 0.0316 (0.0393) loss_oracle 1.0854 (0.9975) kd_loss 1.4381 (1.3625) acc 93.7500 (93.1562) gate/entropy 0.9887 (0.9884) gate/usage_max 0.5622 (0.5626) gate/usage_min 0.2139 (0.2142) gate/usage_std 0.1619 (0.1621) teacher/entropy 0.0037 (0.0237) teacher/usage_max 0.8745 (0.7720) teacher/usage_min 0.0625 (0.0768) teacher/usage_std 0.3827 (0.3123) nleep/row_max_mean 1556.1709 (1545.0520) nleep/row_max_std 42.8646 (50.4987) nleep/row_min_mean 1518.6127 (1504.4871) lr 4.6417e-04 eta 0:05:41
epoch [36/50] batch [120/167] time 0.133 (0.143) data 0.000 (0.003) loss 2.1235 (2.0604) teacher_loss 0.1681 (0.1861) loss_zs_kd 0.0484 (0.0388) loss_oracle 0.9998 (0.9882) kd_loss 1.4313 (1.3608) acc 90.6250 (93.1510) gate/entropy 0.9901 (0.9886) gate/usage_max 0.5607 (0.5624) gate/usage_min 0.2143 (0.2141) gate/usage_std 0.1608 (0.1620) teacher/entropy 0.0140 (0.0237) teacher/usage_max 0.7225 (0.7657) teacher/usage_min 0.0625 (0.0809) teacher/usage_std 0.2821 (0.3079) nleep/row_max_mean 1530.3090 (1544.3899) nleep/row_max_std 59.7471 (51.9526) nleep/row_min_mean 1492.7711 (1504.2926) lr 4.6417e-04 eta 0:05:41
epoch [36/50] batch [140/167] time 0.160 (0.142) data 0.000 (0.003) loss 1.9266 (2.0621) teacher_loss 0.1513 (0.1870) loss_zs_kd 0.0371 (0.0385) loss_oracle 0.9685 (0.9898) kd_loss 1.2725 (1.3608) acc 93.7500 (93.1250) gate/entropy 0.9890 (0.9887) gate/usage_max 0.5619 (0.5622) gate/usage_min 0.2137 (0.2141) gate/usage_std 0.1616 (0.1619) teacher/entropy 0.0245 (0.0235) teacher/usage_max 0.7003 (0.7668) teacher/usage_min 0.0810 (0.0802) teacher/usage_std 0.2655 (0.3086) nleep/row_max_mean 1554.5735 (1543.9182) nleep/row_max_std 59.8408 (52.9228) nleep/row_min_mean 1515.4319 (1504.0816) lr 4.6417e-04 eta 0:05:35
epoch [36/50] batch [160/167] time 0.161 (0.142) data 0.000 (0.003) loss 2.1885 (2.0608) teacher_loss 0.2592 (0.1877) loss_zs_kd 0.0247 (0.0386) loss_oracle 1.0394 (0.9915) kd_loss 1.3973 (1.3581) acc 90.6250 (92.9688) gate/entropy 0.9897 (0.9888) gate/usage_max 0.5612 (0.5621) gate/usage_min 0.2138 (0.2141) gate/usage_std 0.1612 (0.1618) teacher/entropy 0.0096 (0.0239) teacher/usage_max 0.8741 (0.7655) teacher/usage_min 0.0322 (0.0810) teacher/usage_std 0.3832 (0.3078) nleep/row_max_mean 1558.9780 (1544.2938) nleep/row_max_std 58.7489 (53.1774) nleep/row_min_mean 1520.1755 (1504.7029) lr 4.6417e-04 eta 0:05:33
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,190
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,319
* accuracy: 98.9%
* error: 1.1%
* macro_f1: 99.0%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [37/50] batch [20/167] time 0.087 (0.129) data 0.000 (0.018) loss 2.0111 (2.0536) teacher_loss 0.1061 (0.1759) loss_zs_kd 0.0285 (0.0397) loss_oracle 1.0246 (1.0161) kd_loss 1.3784 (1.3499) acc 96.8750 (93.5938) gate/entropy 0.9906 (0.9902) gate/usage_max 0.5601 (0.5606) gate/usage_min 0.2139 (0.2138) gate/usage_std 0.1604 (0.1607) teacher/entropy 0.0043 (0.0256) teacher/usage_max 0.7195 (0.7563) teacher/usage_min 0.1243 (0.0872) teacher/usage_std 0.2734 (0.3010) nleep/row_max_mean 1548.0479 (1546.1469) nleep/row_max_std 59.1655 (57.6141) nleep/row_min_mean 1510.5349 (1508.8138) lr 4.1221e-04 eta 0:04:59
epoch [37/50] batch [40/167] time 0.236 (0.119) data 0.000 (0.009) loss 2.0510 (2.0850) teacher_loss 0.1242 (0.2037) loss_zs_kd 0.0263 (0.0396) loss_oracle 1.1012 (1.0217) kd_loss 1.3630 (1.3507) acc 96.8750 (92.3438) gate/entropy 0.9907 (0.9904) gate/usage_max 0.5600 (0.5604) gate/usage_min 0.2138 (0.2138) gate/usage_std 0.1603 (0.1606) teacher/entropy 0.0175 (0.0237) teacher/usage_max 0.7863 (0.7666) teacher/usage_min 0.0916 (0.0782) teacher/usage_std 0.3205 (0.3089) nleep/row_max_mean 1555.4695 (1545.4918) nleep/row_max_std 46.2733 (58.1998) nleep/row_min_mean 1514.5641 (1508.1242) lr 4.1221e-04 eta 0:04:33
epoch [37/50] batch [60/167] time 0.139 (0.117) data 0.000 (0.006) loss 2.3068 (2.0621) teacher_loss 0.2168 (0.1905) loss_zs_kd 0.0457 (0.0384) loss_oracle 1.1888 (1.0197) kd_loss 1.4728 (1.3426) acc 90.6250 (92.6042) gate/entropy 0.9903 (0.9905) gate/usage_max 0.5605 (0.5602) gate/usage_min 0.2134 (0.2138) gate/usage_std 0.1607 (0.1605) teacher/entropy 0.0180 (0.0247) teacher/usage_max 0.9052 (0.7649) teacher/usage_min 0.0019 (0.0776) teacher/usage_std 0.4061 (0.3078) nleep/row_max_mean 1560.7490 (1545.2246) nleep/row_max_std 54.5225 (58.2585) nleep/row_min_mean 1523.1271 (1507.7294) lr 4.1221e-04 eta 0:04:25
epoch [37/50] batch [80/167] time 0.186 (0.117) data 0.000 (0.005) loss 2.1906 (2.0602) teacher_loss 0.2628 (0.1868) loss_zs_kd 0.0612 (0.0390) loss_oracle 1.0634 (1.0238) kd_loss 1.3655 (1.3420) acc 90.6250 (92.6953) gate/entropy 0.9916 (0.9907) gate/usage_max 0.5590 (0.5600) gate/usage_min 0.2137 (0.2137) gate/usage_std 0.1597 (0.1604) teacher/entropy 0.0192 (0.0256) teacher/usage_max 0.6928 (0.7612) teacher/usage_min 0.1199 (0.0831) teacher/usage_std 0.2557 (0.3048) nleep/row_max_mean 1521.1125 (1543.5747) nleep/row_max_std 52.5751 (57.7016) nleep/row_min_mean 1484.0374 (1506.1285) lr 4.1221e-04 eta 0:04:24
epoch [37/50] batch [100/167] time 0.092 (0.117) data 0.000 (0.004) loss 2.1204 (2.0618) teacher_loss 0.2621 (0.1955) loss_zs_kd 0.0348 (0.0401) loss_oracle 1.0218 (1.0160) kd_loss 1.3300 (1.3382) acc 84.3750 (92.4375) gate/entropy 0.9916 (0.9908) gate/usage_max 0.5591 (0.5599) gate/usage_min 0.2135 (0.2137) gate/usage_std 0.1597 (0.1603) teacher/entropy 0.0296 (0.0263) teacher/usage_max 0.7977 (0.7584) teacher/usage_min 0.0630 (0.0824) teacher/usage_std 0.3298 (0.3031) nleep/row_max_mean 1552.0676 (1543.8211) nleep/row_max_std 63.4027 (57.0862) nleep/row_min_mean 1509.7871 (1506.3290) lr 4.1221e-04 eta 0:04:22
epoch [37/50] batch [120/167] time 0.100 (0.118) data 0.000 (0.003) loss 2.0993 (2.0597) teacher_loss 0.1704 (0.1955) loss_zs_kd 0.0334 (0.0408) loss_oracle 1.0762 (1.0175) kd_loss 1.3741 (1.3351) acc 93.7500 (92.3177) gate/entropy 0.9922 (0.9910) gate/usage_max 0.5583 (0.5597) gate/usage_min 0.2135 (0.2136) gate/usage_std 0.1592 (0.1602) teacher/entropy 0.0000 (0.0255) teacher/usage_max 0.7500 (0.7602) teacher/usage_min 0.1250 (0.0798) teacher/usage_std 0.2946 (0.3047) nleep/row_max_mean 1542.6494 (1544.3069) nleep/row_max_std 58.9377 (57.1251) nleep/row_min_mean 1500.0372 (1506.4571) lr 4.1221e-04 eta 0:04:21
epoch [37/50] batch [140/167] time 0.165 (0.119) data 0.000 (0.003) loss 1.8408 (2.0558) teacher_loss 0.1067 (0.1945) loss_zs_kd 0.0460 (0.0409) loss_oracle 0.8863 (1.0139) kd_loss 1.2679 (1.3339) acc 93.7500 (92.2991) gate/entropy 0.9920 (0.9911) gate/usage_max 0.5586 (0.5595) gate/usage_min 0.2132 (0.2136) gate/usage_std 0.1594 (0.1600) teacher/entropy 0.0124 (0.0248) teacher/usage_max 0.7471 (0.7587) teacher/usage_min 0.0317 (0.0804) teacher/usage_std 0.3027 (0.3037) nleep/row_max_mean 1554.3745 (1543.9264) nleep/row_max_std 42.0031 (56.3086) nleep/row_min_mean 1515.7975 (1505.9843) lr 4.1221e-04 eta 0:04:21
epoch [37/50] batch [160/167] time 0.138 (0.117) data 0.000 (0.002) loss 2.1723 (2.0544) teacher_loss 0.2402 (0.1956) loss_zs_kd 0.0561 (0.0414) loss_oracle 1.0279 (1.0110) kd_loss 1.3901 (1.3327) acc 90.6250 (92.4023) gate/entropy 0.9926 (0.9913) gate/usage_max 0.5578 (0.5593) gate/usage_min 0.2132 (0.2136) gate/usage_std 0.1589 (0.1599) teacher/entropy 0.0069 (0.0247) teacher/usage_max 0.8131 (0.7600) teacher/usage_min 0.0932 (0.0801) teacher/usage_std 0.3392 (0.3047) nleep/row_max_mean 1550.9949 (1543.9087) nleep/row_max_std 43.7920 (55.6212) nleep/row_min_mean 1509.2725 (1505.6558) lr 4.1221e-04 eta 0:04:15
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,196
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.1%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,317
* accuracy: 98.8%
* error: 1.2%
* macro_f1: 99.0%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [38/50] batch [20/167] time 0.128 (0.167) data 0.000 (0.018) loss 1.8451 (2.0465) teacher_loss 0.1180 (0.2127) loss_zs_kd 0.0484 (0.0443) loss_oracle 0.9028 (0.9591) kd_loss 1.2515 (1.3320) acc 100.0000 (91.4062) gate/entropy 0.9929 (0.9929) gate/usage_max 0.5575 (0.5575) gate/usage_min 0.2130 (0.2131) gate/usage_std 0.1587 (0.1587) teacher/entropy 0.0026 (0.0302) teacher/usage_max 0.6879 (0.7972) teacher/usage_min 0.0624 (0.0619) teacher/usage_std 0.2621 (0.3304) nleep/row_max_mean 1549.2561 (1545.2980) nleep/row_max_std 41.8540 (51.3899) nleep/row_min_mean 1511.4979 (1505.8888) lr 3.6258e-04 eta 0:05:59
epoch [38/50] batch [40/167] time 0.163 (0.161) data 0.000 (0.009) loss 2.0938 (2.0307) teacher_loss 0.2376 (0.2054) loss_zs_kd 0.0347 (0.0424) loss_oracle 1.0176 (0.9558) kd_loss 1.3301 (1.3262) acc 93.7500 (91.8750) gate/entropy 0.9932 (0.9931) gate/usage_max 0.5571 (0.5573) gate/usage_min 0.2129 (0.2131) gate/usage_std 0.1584 (0.1585) teacher/entropy 0.0080 (0.0257) teacher/usage_max 0.7520 (0.7859) teacher/usage_min 0.0919 (0.0626) teacher/usage_std 0.2972 (0.3231) nleep/row_max_mean 1544.8965 (1543.1442) nleep/row_max_std 57.0357 (51.4129) nleep/row_min_mean 1504.8000 (1504.0203) lr 3.6258e-04 eta 0:05:44
epoch [38/50] batch [60/167] time 0.156 (0.158) data 0.001 (0.006) loss 2.2050 (2.0223) teacher_loss 0.2147 (0.1898) loss_zs_kd 0.0316 (0.0400) loss_oracle 1.0958 (0.9710) kd_loss 1.4266 (1.3270) acc 93.7500 (92.1875) gate/entropy 0.9939 (0.9933) gate/usage_max 0.5563 (0.5570) gate/usage_min 0.2129 (0.2130) gate/usage_std 0.1578 (0.1583) teacher/entropy 0.0246 (0.0253) teacher/usage_max 0.8189 (0.7812) teacher/usage_min 0.0313 (0.0676) teacher/usage_std 0.3468 (0.3195) nleep/row_max_mean 1547.1426 (1542.2452) nleep/row_max_std 47.3649 (52.2121) nleep/row_min_mean 1508.4387 (1503.0750) lr 3.6258e-04 eta 0:05:34
epoch [38/50] batch [80/167] time 0.092 (0.148) data 0.000 (0.005) loss 1.8126 (2.0119) teacher_loss 0.1936 (0.1846) loss_zs_kd 0.0455 (0.0407) loss_oracle 0.8545 (0.9703) kd_loss 1.1690 (1.3218) acc 93.7500 (92.5391) gate/entropy 0.9941 (0.9935) gate/usage_max 0.5561 (0.5568) gate/usage_min 0.2127 (0.2130) gate/usage_std 0.1577 (0.1582) teacher/entropy 0.0538 (0.0257) teacher/usage_max 0.6741 (0.7791) teacher/usage_min 0.0469 (0.0668) teacher/usage_std 0.2589 (0.3184) nleep/row_max_mean 1545.1796 (1541.5666) nleep/row_max_std 52.7758 (52.9512) nleep/row_min_mean 1505.6396 (1502.5179) lr 3.6258e-04 eta 0:05:09
epoch [38/50] batch [100/167] time 0.088 (0.140) data 0.000 (0.004) loss 1.9650 (2.0124) teacher_loss 0.1896 (0.1857) loss_zs_kd 0.0543 (0.0412) loss_oracle 0.9982 (0.9703) kd_loss 1.2492 (1.3210) acc 90.6250 (92.6875) gate/entropy 0.9948 (0.9937) gate/usage_max 0.5554 (0.5566) gate/usage_min 0.2127 (0.2129) gate/usage_std 0.1572 (0.1580) teacher/entropy 0.0257 (0.0259) teacher/usage_max 0.7028 (0.7797) teacher/usage_min 0.0784 (0.0671) teacher/usage_std 0.2675 (0.3187) nleep/row_max_mean 1536.5994 (1541.3727) nleep/row_max_std 49.8466 (53.1598) nleep/row_min_mean 1497.9558 (1502.3957) lr 3.6258e-04 eta 0:04:49
epoch [38/50] batch [120/167] time 0.093 (0.135) data 0.000 (0.003) loss 2.0301 (2.0217) teacher_loss 0.1368 (0.1918) loss_zs_kd 0.0274 (0.0411) loss_oracle 1.0211 (0.9734) kd_loss 1.3691 (1.3226) acc 93.7500 (92.4740) gate/entropy 0.9959 (0.9939) gate/usage_max 0.5540 (0.5564) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1563 (0.1579) teacher/entropy 0.0504 (0.0255) teacher/usage_max 0.7878 (0.7793) teacher/usage_min 0.0586 (0.0674) teacher/usage_std 0.3237 (0.3183) nleep/row_max_mean 1528.7124 (1542.1779) nleep/row_max_std 56.3953 (53.0320) nleep/row_min_mean 1490.5466 (1503.0878) lr 3.6258e-04 eta 0:04:37
epoch [38/50] batch [140/167] time 0.072 (0.131) data 0.000 (0.003) loss 1.9644 (2.0215) teacher_loss 0.1525 (0.1938) loss_zs_kd 0.0419 (0.0408) loss_oracle 0.9525 (0.9723) kd_loss 1.3148 (1.3212) acc 93.7500 (92.5446) gate/entropy 0.9961 (0.9941) gate/usage_max 0.5538 (0.5561) gate/usage_min 0.2126 (0.2128) gate/usage_std 0.1561 (0.1577) teacher/entropy 0.0648 (0.0252) teacher/usage_max 0.8547 (0.7836) teacher/usage_min 0.0531 (0.0634) teacher/usage_std 0.3690 (0.3216) nleep/row_max_mean 1537.9329 (1543.1513) nleep/row_max_std 55.7967 (53.0240) nleep/row_min_mean 1498.9258 (1503.9248) lr 3.6258e-04 eta 0:04:26
epoch [38/50] batch [160/167] time 0.085 (0.125) data 0.000 (0.002) loss 1.9914 (2.0151) teacher_loss 0.1624 (0.1894) loss_zs_kd 0.0295 (0.0404) loss_oracle 0.9713 (0.9729) kd_loss 1.3287 (1.3191) acc 96.8750 (92.7539) gate/entropy 0.9963 (0.9943) gate/usage_max 0.5536 (0.5559) gate/usage_min 0.2124 (0.2128) gate/usage_std 0.1560 (0.1576) teacher/entropy 0.0262 (0.0253) teacher/usage_max 0.7658 (0.7848) teacher/usage_min 0.1096 (0.0627) teacher/usage_std 0.3059 (0.3224) nleep/row_max_mean 1533.6608 (1542.9054) nleep/row_max_std 62.2291 (53.8388) nleep/row_min_mean 1495.7687 (1503.6204) lr 3.6258e-04 eta 0:04:11
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,192
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [39/50] batch [20/167] time 0.162 (0.143) data 0.000 (0.016) loss 1.9874 (1.9975) teacher_loss 0.1038 (0.1908) loss_zs_kd 0.0335 (0.0332) loss_oracle 1.1191 (0.9800) kd_loss 1.3074 (1.3000) acc 96.8750 (92.6562) gate/entropy 0.9964 (0.9964) gate/usage_max 0.5534 (0.5535) gate/usage_min 0.2120 (0.2121) gate/usage_std 0.1559 (0.1559) teacher/entropy 0.0503 (0.0302) teacher/usage_max 0.7208 (0.7826) teacher/usage_min 0.1250 (0.0609) teacher/usage_std 0.2742 (0.3213) nleep/row_max_mean 1545.8821 (1542.1656) nleep/row_max_std 55.9675 (60.1126) nleep/row_min_mean 1510.4595 (1504.1157) lr 3.1545e-04 eta 0:04:43
epoch [39/50] batch [40/167] time 0.150 (0.125) data 0.000 (0.008) loss 1.9330 (2.0026) teacher_loss 0.1534 (0.1988) loss_zs_kd 0.0229 (0.0343) loss_oracle 0.8814 (0.9706) kd_loss 1.3275 (1.3014) acc 93.7500 (92.6562) gate/entropy 0.9969 (0.9966) gate/usage_max 0.5528 (0.5532) gate/usage_min 0.2119 (0.2121) gate/usage_std 0.1555 (0.1557) teacher/entropy 0.0457 (0.0299) teacher/usage_max 0.8357 (0.7847) teacher/usage_min 0.0705 (0.0655) teacher/usage_std 0.3554 (0.3221) nleep/row_max_mean 1530.5535 (1539.5329) nleep/row_max_std 54.9211 (59.2377) nleep/row_min_mean 1495.2174 (1501.2315) lr 3.1545e-04 eta 0:04:04
epoch [39/50] batch [60/167] time 0.171 (0.123) data 0.000 (0.005) loss 1.9746 (1.9780) teacher_loss 0.1163 (0.1872) loss_zs_kd 0.0182 (0.0359) loss_oracle 0.9420 (0.9524) kd_loss 1.3781 (1.2966) acc 93.7500 (92.9688) gate/entropy 0.9978 (0.9968) gate/usage_max 0.5517 (0.5529) gate/usage_min 0.2119 (0.2120) gate/usage_std 0.1548 (0.1555) teacher/entropy 0.0140 (0.0284) teacher/usage_max 0.9088 (0.7850) teacher/usage_min 0.0287 (0.0609) teacher/usage_std 0.4072 (0.3229) nleep/row_max_mean 1542.2045 (1539.0537) nleep/row_max_std 60.9357 (59.3849) nleep/row_min_mean 1503.2638 (1501.1056) lr 3.1545e-04 eta 0:03:59
epoch [39/50] batch [80/167] time 0.124 (0.117) data 0.000 (0.004) loss 2.0217 (1.9857) teacher_loss 0.2714 (0.1932) loss_zs_kd 0.0423 (0.0361) loss_oracle 0.9166 (0.9542) kd_loss 1.2708 (1.2974) acc 87.5000 (92.7344) gate/entropy 0.9970 (0.9970) gate/usage_max 0.5526 (0.5527) gate/usage_min 0.2113 (0.2119) gate/usage_std 0.1554 (0.1554) teacher/entropy 0.0458 (0.0280) teacher/usage_max 0.7057 (0.7857) teacher/usage_min 0.1287 (0.0614) teacher/usage_std 0.2637 (0.3233) nleep/row_max_mean 1559.6763 (1539.1911) nleep/row_max_std 51.6747 (59.4121) nleep/row_min_mean 1526.8124 (1501.5746) lr 3.1545e-04 eta 0:03:45
epoch [39/50] batch [100/167] time 0.147 (0.123) data 0.000 (0.003) loss 1.7978 (1.9857) teacher_loss 0.1664 (0.1960) loss_zs_kd 0.0435 (0.0360) loss_oracle 0.8462 (0.9557) kd_loss 1.1865 (1.2938) acc 90.6250 (92.4688) gate/entropy 0.9984 (0.9973) gate/usage_max 0.5510 (0.5524) gate/usage_min 0.2115 (0.2119) gate/usage_std 0.1543 (0.1552) teacher/entropy 0.0424 (0.0289) teacher/usage_max 0.6946 (0.7845) teacher/usage_min 0.0523 (0.0610) teacher/usage_std 0.2683 (0.3225) nleep/row_max_mean 1553.1096 (1539.6944) nleep/row_max_std 52.7829 (58.7686) nleep/row_min_mean 1519.7607 (1502.1307) lr 3.1545e-04 eta 0:03:53
epoch [39/50] batch [120/167] time 0.168 (0.129) data 0.000 (0.003) loss 1.8178 (1.9804) teacher_loss 0.1060 (0.1910) loss_zs_kd 0.0330 (0.0363) loss_oracle 0.9138 (0.9567) kd_loss 1.2385 (1.2929) acc 96.8750 (92.6302) gate/entropy 0.9992 (0.9975) gate/usage_max 0.5500 (0.5521) gate/usage_min 0.2114 (0.2118) gate/usage_std 0.1536 (0.1550) teacher/entropy 0.0391 (0.0294) teacher/usage_max 0.7904 (0.7849) teacher/usage_min 0.0221 (0.0600) teacher/usage_std 0.3302 (0.3229) nleep/row_max_mean 1533.9429 (1540.4788) nleep/row_max_std 73.0281 (58.0274) nleep/row_min_mean 1495.3682 (1503.0070) lr 3.1545e-04 eta 0:04:03
epoch [39/50] batch [140/167] time 0.153 (0.133) data 0.000 (0.002) loss 1.9588 (1.9712) teacher_loss 0.2798 (0.1877) loss_zs_kd 0.0341 (0.0361) loss_oracle 0.8255 (0.9497) kd_loss 1.2492 (1.2906) acc 90.6250 (92.8125) gate/entropy 0.9990 (0.9977) gate/usage_max 0.5502 (0.5518) gate/usage_min 0.2110 (0.2117) gate/usage_std 0.1537 (0.1548) teacher/entropy 0.0414 (0.0294) teacher/usage_max 0.8026 (0.7835) teacher/usage_min 0.0253 (0.0601) teacher/usage_std 0.3372 (0.3221) nleep/row_max_mean 1548.5093 (1540.8637) nleep/row_max_std 52.8275 (57.9372) nleep/row_min_mean 1513.9802 (1503.5102) lr 3.1545e-04 eta 0:04:07
epoch [39/50] batch [160/167] time 0.134 (0.135) data 0.000 (0.002) loss 2.1166 (1.9713) teacher_loss 0.2033 (0.1900) loss_zs_kd 0.0260 (0.0361) loss_oracle 0.9590 (0.9451) kd_loss 1.4207 (1.2907) acc 93.7500 (92.7344) gate/entropy 0.9993 (0.9979) gate/usage_max 0.5498 (0.5515) gate/usage_min 0.2107 (0.2116) gate/usage_std 0.1535 (0.1546) teacher/entropy 0.0088 (0.0297) teacher/usage_max 0.9977 (0.7868) teacher/usage_min 0.0000 (0.0585) teacher/usage_std 0.4698 (0.3244) nleep/row_max_mean 1562.3972 (1541.3526) nleep/row_max_std 55.1718 (58.3106) nleep/row_min_mean 1525.2766 (1504.1024) lr 3.1545e-04 eta 0:04:09
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,190
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.8%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [40/50] batch [20/167] time 0.114 (0.137) data 0.000 (0.016) loss 1.9664 (1.9556) teacher_loss 0.1663 (0.1990) loss_zs_kd 0.0462 (0.0393) loss_oracle 1.0123 (0.9404) kd_loss 1.2708 (1.2668) acc 96.8750 (92.6562) gate/entropy 1.0007 (1.0004) gate/usage_max 0.5480 (0.5485) gate/usage_min 0.2107 (0.2108) gate/usage_std 0.1523 (0.1526) teacher/entropy 0.0358 (0.0372) teacher/usage_max 0.7396 (0.7972) teacher/usage_min 0.1041 (0.0459) teacher/usage_std 0.2881 (0.3325) nleep/row_max_mean 1536.9873 (1542.4815) nleep/row_max_std 59.9816 (55.7580) nleep/row_min_mean 1499.9047 (1505.7228) lr 2.7103e-04 eta 0:04:09
epoch [40/50] batch [40/167] time 0.097 (0.127) data 0.000 (0.008) loss 1.8285 (1.9347) teacher_loss 0.1136 (0.1818) loss_zs_kd 0.0544 (0.0379) loss_oracle 0.9138 (0.9317) kd_loss 1.2308 (1.2680) acc 96.8750 (93.3594) gate/entropy 1.0011 (1.0006) gate/usage_max 0.5475 (0.5482) gate/usage_min 0.2105 (0.2107) gate/usage_std 0.1520 (0.1524) teacher/entropy 0.0395 (0.0335) teacher/usage_max 0.7727 (0.8005) teacher/usage_min 0.0398 (0.0438) teacher/usage_std 0.3165 (0.3345) nleep/row_max_mean 1548.0524 (1543.5345) nleep/row_max_std 51.4692 (56.6413) nleep/row_min_mean 1511.9200 (1506.9218) lr 2.7103e-04 eta 0:03:48
epoch [40/50] batch [60/167] time 0.090 (0.121) data 0.001 (0.006) loss 1.8321 (1.9290) teacher_loss 0.0866 (0.1767) loss_zs_kd 0.0375 (0.0376) loss_oracle 0.9097 (0.9249) kd_loss 1.2720 (1.2711) acc 96.8750 (93.3854) gate/entropy 1.0014 (1.0008) gate/usage_max 0.5472 (0.5479) gate/usage_min 0.2102 (0.2106) gate/usage_std 0.1518 (0.1523) teacher/entropy 0.0459 (0.0325) teacher/usage_max 0.8662 (0.8048) teacher/usage_min 0.0116 (0.0435) teacher/usage_std 0.3795 (0.3380) nleep/row_max_mean 1548.1165 (1544.4970) nleep/row_max_std 60.8572 (56.7242) nleep/row_min_mean 1511.5417 (1507.9006) lr 2.7103e-04 eta 0:03:35
epoch [40/50] batch [80/167] time 0.155 (0.119) data 0.000 (0.004) loss 1.8547 (1.9328) teacher_loss 0.1353 (0.1851) loss_zs_kd 0.0270 (0.0382) loss_oracle 0.9272 (0.9200) kd_loss 1.2423 (1.2686) acc 93.7500 (93.0859) gate/entropy 1.0024 (1.0011) gate/usage_max 0.5459 (0.5476) gate/usage_min 0.2102 (0.2105) gate/usage_std 0.1509 (0.1521) teacher/entropy 0.0507 (0.0311) teacher/usage_max 0.8549 (0.8062) teacher/usage_min 0.0000 (0.0387) teacher/usage_std 0.3735 (0.3394) nleep/row_max_mean 1543.8997 (1544.9382) nleep/row_max_std 61.1372 (56.8506) nleep/row_min_mean 1505.2963 (1508.2976) lr 2.7103e-04 eta 0:03:29
epoch [40/50] batch [100/167] time 0.072 (0.119) data 0.000 (0.003) loss 2.0347 (1.9312) teacher_loss 0.2201 (0.1910) loss_zs_kd 0.0319 (0.0373) loss_oracle 0.9875 (0.9168) kd_loss 1.3050 (1.2632) acc 90.6250 (92.5625) gate/entropy 1.0034 (1.0013) gate/usage_max 0.5447 (0.5473) gate/usage_min 0.2102 (0.2104) gate/usage_std 0.1502 (0.1518) teacher/entropy 0.0307 (0.0309) teacher/usage_max 0.8822 (0.8003) teacher/usage_min 0.0254 (0.0396) teacher/usage_std 0.3891 (0.3358) nleep/row_max_mean 1528.8074 (1545.4852) nleep/row_max_std 54.4963 (56.1834) nleep/row_min_mean 1493.5562 (1508.9364) lr 2.7103e-04 eta 0:03:26
epoch [40/50] batch [120/167] time 0.075 (0.118) data 0.001 (0.003) loss 1.8682 (1.9332) teacher_loss 0.0920 (0.1951) loss_zs_kd 0.0200 (0.0374) loss_oracle 0.9848 (0.9150) kd_loss 1.2738 (1.2619) acc 96.8750 (92.5260) gate/entropy 1.0032 (1.0015) gate/usage_max 0.5448 (0.5470) gate/usage_min 0.2097 (0.2102) gate/usage_std 0.1502 (0.1517) teacher/entropy 0.0139 (0.0300) teacher/usage_max 0.7855 (0.8004) teacher/usage_min 0.0583 (0.0388) teacher/usage_std 0.3222 (0.3359) nleep/row_max_mean 1552.3118 (1546.2558) nleep/row_max_std 44.7689 (55.1312) nleep/row_min_mean 1515.4800 (1509.8238) lr 2.7103e-04 eta 0:03:23
epoch [40/50] batch [140/167] time 0.079 (0.117) data 0.000 (0.003) loss 1.8316 (1.9334) teacher_loss 0.1483 (0.1943) loss_zs_kd 0.0309 (0.0361) loss_oracle 0.8712 (0.9154) kd_loss 1.2323 (1.2634) acc 100.0000 (92.6339) gate/entropy 1.0035 (1.0018) gate/usage_max 0.5444 (0.5466) gate/usage_min 0.2093 (0.2101) gate/usage_std 0.1500 (0.1514) teacher/entropy 0.0222 (0.0282) teacher/usage_max 0.7900 (0.8056) teacher/usage_min 0.0225 (0.0357) teacher/usage_std 0.3299 (0.3395) nleep/row_max_mean 1547.9482 (1545.5715) nleep/row_max_std 56.5998 (56.1715) nleep/row_min_mean 1516.4026 (1509.2626) lr 2.7103e-04 eta 0:03:18
epoch [40/50] batch [160/167] time 0.070 (0.116) data 0.000 (0.002) loss 1.8873 (1.9313) teacher_loss 0.1856 (0.1969) loss_zs_kd 0.0250 (0.0359) loss_oracle 0.8468 (0.9099) kd_loss 1.2657 (1.2615) acc 93.7500 (92.6367) gate/entropy 1.0040 (1.0021) gate/usage_max 0.5437 (0.5463) gate/usage_min 0.2090 (0.2100) gate/usage_std 0.1496 (0.1512) teacher/entropy 0.0087 (0.0273) teacher/usage_max 0.8449 (0.8074) teacher/usage_min 0.0003 (0.0330) teacher/usage_std 0.3672 (0.3409) nleep/row_max_mean 1557.9883 (1544.9886) nleep/row_max_std 38.6480 (56.3144) nleep/row_min_mean 1525.0718 (1508.8410) lr 2.7103e-04 eta 0:03:14
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,193
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 95.9%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [41/50] batch [20/167] time 0.112 (0.158) data 0.000 (0.014) loss 1.9613 (1.9068) teacher_loss 0.2340 (0.1950) loss_zs_kd 0.0334 (0.0321) loss_oracle 0.8383 (0.8841) kd_loss 1.2915 (1.2537) acc 90.6250 (92.5000) gate/entropy 1.0048 (1.0046) gate/usage_max 0.5426 (0.5428) gate/usage_min 0.2087 (0.2089) gate/usage_std 0.1488 (0.1490) teacher/entropy 0.0012 (0.0128) teacher/usage_max 0.8748 (0.8301) teacher/usage_min 0.0002 (0.0074) teacher/usage_std 0.3863 (0.3591) nleep/row_max_mean 1550.6488 (1543.8247) nleep/row_max_std 50.6155 (55.8801) nleep/row_min_mean 1515.8226 (1508.4290) lr 2.2949e-04 eta 0:04:21
epoch [41/50] batch [40/167] time 0.148 (0.147) data 0.000 (0.007) loss 1.9566 (1.9138) teacher_loss 0.3068 (0.2015) loss_zs_kd 0.0250 (0.0336) loss_oracle 0.7981 (0.8833) kd_loss 1.2383 (1.2539) acc 90.6250 (92.3438) gate/entropy 1.0053 (1.0050) gate/usage_max 0.5419 (0.5424) gate/usage_min 0.2084 (0.2088) gate/usage_std 0.1485 (0.1487) teacher/entropy 0.0030 (0.0106) teacher/usage_max 0.8120 (0.8317) teacher/usage_min 0.0005 (0.0058) teacher/usage_std 0.3470 (0.3599) nleep/row_max_mean 1543.4886 (1542.0266) nleep/row_max_std 65.3720 (55.5159) nleep/row_min_mean 1506.6091 (1506.1919) lr 2.2949e-04 eta 0:04:00
epoch [41/50] batch [60/167] time 0.133 (0.144) data 0.000 (0.005) loss 1.8337 (1.9050) teacher_loss 0.0691 (0.1924) loss_zs_kd 0.0252 (0.0336) loss_oracle 0.8875 (0.8725) kd_loss 1.3082 (1.2597) acc 96.8750 (93.0208) gate/entropy 1.0060 (1.0052) gate/usage_max 0.5409 (0.5420) gate/usage_min 0.2083 (0.2086) gate/usage_std 0.1478 (0.1485) teacher/entropy 0.0020 (0.0083) teacher/usage_max 0.9059 (0.8396) teacher/usage_min 0.0000 (0.0047) teacher/usage_std 0.4067 (0.3649) nleep/row_max_mean 1540.3671 (1541.6090) nleep/row_max_std 40.5543 (54.4519) nleep/row_min_mean 1508.9098 (1506.1427) lr 2.2949e-04 eta 0:03:51
epoch [41/50] batch [80/167] time 0.134 (0.143) data 0.000 (0.004) loss 1.7588 (1.8897) teacher_loss 0.0799 (0.1922) loss_zs_kd 0.0248 (0.0330) loss_oracle 0.9101 (0.8601) kd_loss 1.2114 (1.2510) acc 96.8750 (92.9297) gate/entropy 1.0062 (1.0055) gate/usage_max 0.5406 (0.5417) gate/usage_min 0.2078 (0.2085) gate/usage_std 0.1476 (0.1483) teacher/entropy 0.0005 (0.0096) teacher/usage_max 0.7812 (0.8320) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.3290 (0.3600) nleep/row_max_mean 1550.0427 (1541.0019) nleep/row_max_std 52.9636 (54.8248) nleep/row_min_mean 1514.3208 (1505.4882) lr 2.2949e-04 eta 0:03:46
epoch [41/50] batch [100/167] time 0.120 (0.140) data 0.000 (0.003) loss 1.8161 (1.8943) teacher_loss 0.1662 (0.1948) loss_zs_kd 0.0311 (0.0332) loss_oracle 0.9293 (0.8613) kd_loss 1.1696 (1.2523) acc 90.6250 (92.7812) gate/entropy 1.0072 (1.0057) gate/usage_max 0.5392 (0.5413) gate/usage_min 0.2077 (0.2084) gate/usage_std 0.1468 (0.1480) teacher/entropy 0.0246 (0.0096) teacher/usage_max 0.7643 (0.8357) teacher/usage_min 0.0000 (0.0049) teacher/usage_std 0.3196 (0.3623) nleep/row_max_mean 1544.1449 (1541.1754) nleep/row_max_std 49.9919 (54.0391) nleep/row_min_mean 1508.8385 (1505.7782) lr 2.2949e-04 eta 0:03:39
epoch [41/50] batch [120/167] time 0.076 (0.139) data 0.000 (0.003) loss 1.5450 (1.8882) teacher_loss 0.0687 (0.1914) loss_zs_kd 0.0284 (0.0332) loss_oracle 0.7507 (0.8632) kd_loss 1.0868 (1.2486) acc 96.8750 (92.9948) gate/entropy 1.0072 (1.0060) gate/usage_max 0.5391 (0.5409) gate/usage_min 0.2072 (0.2082) gate/usage_std 0.1467 (0.1478) teacher/entropy 0.0515 (0.0102) teacher/usage_max 0.6913 (0.8343) teacher/usage_min 0.0000 (0.0045) teacher/usage_std 0.2828 (0.3615) nleep/row_max_mean 1561.4685 (1541.0669) nleep/row_max_std 42.7634 (53.3397) nleep/row_min_mean 1523.3585 (1505.6941) lr 2.2949e-04 eta 0:03:35
epoch [41/50] batch [140/167] time 0.191 (0.134) data 0.000 (0.002) loss 1.8167 (1.8848) teacher_loss 0.1431 (0.1898) loss_zs_kd 0.0422 (0.0336) loss_oracle 0.8111 (0.8640) kd_loss 1.2470 (1.2462) acc 96.8750 (93.0357) gate/entropy 1.0084 (1.0063) gate/usage_max 0.5374 (0.5404) gate/usage_min 0.2072 (0.2081) gate/usage_std 0.1457 (0.1475) teacher/entropy 0.0008 (0.0104) teacher/usage_max 0.8436 (0.8338) teacher/usage_min 0.0001 (0.0043) teacher/usage_std 0.3664 (0.3612) nleep/row_max_mean 1540.7827 (1541.1971) nleep/row_max_std 52.3792 (52.8788) nleep/row_min_mean 1502.6736 (1505.7690) lr 2.2949e-04 eta 0:03:24
epoch [41/50] batch [160/167] time 0.172 (0.131) data 0.000 (0.002) loss 1.9544 (1.8926) teacher_loss 0.2178 (0.1993) loss_zs_kd 0.0274 (0.0342) loss_oracle 0.9145 (0.8637) kd_loss 1.2657 (1.2444) acc 90.6250 (92.7539) gate/entropy 1.0090 (1.0066) gate/usage_max 0.5366 (0.5400) gate/usage_min 0.2069 (0.2080) gate/usage_std 0.1451 (0.1473) teacher/entropy 0.0014 (0.0101) teacher/usage_max 0.8748 (0.8328) teacher/usage_min 0.0002 (0.0046) teacher/usage_std 0.3862 (0.3606) nleep/row_max_mean 1525.5398 (1540.9747) nleep/row_max_std 61.5293 (52.5466) nleep/row_min_mean 1492.3500 (1505.4920) lr 2.2949e-04 eta 0:03:18
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,195
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.0%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [42/50] batch [20/167] time 0.187 (0.140) data 0.000 (0.018) loss 2.0646 (1.8732) teacher_loss 0.2979 (0.1875) loss_zs_kd 0.0340 (0.0339) loss_oracle 0.9306 (0.8787) kd_loss 1.2844 (1.2294) acc 84.3750 (92.6562) gate/entropy 1.0096 (1.0093) gate/usage_max 0.5356 (0.5360) gate/usage_min 0.2065 (0.2065) gate/usage_std 0.1446 (0.1448) teacher/entropy 0.0012 (0.0077) teacher/usage_max 0.9061 (0.8352) teacher/usage_min 0.0002 (0.0020) teacher/usage_std 0.4068 (0.3623) nleep/row_max_mean 1535.5834 (1544.0448) nleep/row_max_std 60.8978 (52.5290) nleep/row_min_mean 1500.2051 (1507.5793) lr 1.9098e-04 eta 0:03:28
epoch [42/50] batch [40/167] time 0.178 (0.128) data 0.000 (0.009) loss 1.9067 (1.8873) teacher_loss 0.2869 (0.2021) loss_zs_kd 0.0260 (0.0318) loss_oracle 0.7411 (0.8690) kd_loss 1.2364 (1.2348) acc 93.7500 (92.6562) gate/entropy 1.0103 (1.0096) gate/usage_max 0.5346 (0.5356) gate/usage_min 0.2062 (0.2064) gate/usage_std 0.1440 (0.1446) teacher/entropy 0.0004 (0.0076) teacher/usage_max 0.8437 (0.8452) teacher/usage_min 0.0001 (0.0016) teacher/usage_std 0.3665 (0.3683) nleep/row_max_mean 1536.8514 (1542.8146) nleep/row_max_std 44.1995 (51.2330) nleep/row_min_mean 1502.7498 (1506.4310) lr 1.9098e-04 eta 0:03:07
epoch [42/50] batch [60/167] time 0.110 (0.127) data 0.000 (0.006) loss 1.8224 (1.8919) teacher_loss 0.1254 (0.2175) loss_zs_kd 0.0190 (0.0330) loss_oracle 0.8782 (0.8587) kd_loss 1.2484 (1.2286) acc 93.7500 (91.7188) gate/entropy 1.0111 (1.0099) gate/usage_max 0.5335 (0.5352) gate/usage_min 0.2060 (0.2063) gate/usage_std 0.1433 (0.1443) teacher/entropy 0.0059 (0.0083) teacher/usage_max 0.8738 (0.8395) teacher/usage_min 0.0000 (0.0019) teacher/usage_std 0.3856 (0.3649) nleep/row_max_mean 1532.4945 (1541.2661) nleep/row_max_std 45.4902 (50.9240) nleep/row_min_mean 1495.5579 (1504.8597) lr 1.9098e-04 eta 0:03:03
epoch [42/50] batch [80/167] time 0.071 (0.125) data 0.000 (0.005) loss 2.0640 (1.8866) teacher_loss 0.2613 (0.2089) loss_zs_kd 0.0634 (0.0338) loss_oracle 0.9717 (0.8633) kd_loss 1.2851 (1.2291) acc 90.6250 (92.2656) gate/entropy 1.0116 (1.0102) gate/usage_max 0.5326 (0.5347) gate/usage_min 0.2057 (0.2061) gate/usage_std 0.1427 (0.1440) teacher/entropy 0.0149 (0.0088) teacher/usage_max 0.9429 (0.8415) teacher/usage_min 0.0000 (0.0033) teacher/usage_std 0.4316 (0.3658) nleep/row_max_mean 1528.3730 (1540.6670) nleep/row_max_std 47.1345 (50.3169) nleep/row_min_mean 1496.4430 (1504.2967) lr 1.9098e-04 eta 0:02:57
epoch [42/50] batch [100/167] time 0.092 (0.123) data 0.000 (0.004) loss 1.6290 (1.8788) teacher_loss 0.0755 (0.2100) loss_zs_kd 0.0326 (0.0341) loss_oracle 0.8202 (0.8580) kd_loss 1.1271 (1.2228) acc 96.8750 (92.1562) gate/entropy 1.0115 (1.0104) gate/usage_max 0.5326 (0.5343) gate/usage_min 0.2051 (0.2060) gate/usage_std 0.1428 (0.1438) teacher/entropy 0.0447 (0.0099) teacher/usage_max 0.7625 (0.8356) teacher/usage_min 0.0024 (0.0039) teacher/usage_std 0.3180 (0.3623) nleep/row_max_mean 1549.2015 (1541.5549) nleep/row_max_std 43.7078 (49.6660) nleep/row_min_mean 1514.1599 (1505.1897) lr 1.9098e-04 eta 0:02:52
epoch [42/50] batch [120/167] time 0.168 (0.124) data 0.000 (0.003) loss 1.9132 (1.8738) teacher_loss 0.2300 (0.2085) loss_zs_kd 0.0421 (0.0341) loss_oracle 0.9250 (0.8586) kd_loss 1.1996 (1.2190) acc 93.7500 (92.2656) gate/entropy 1.0125 (1.0107) gate/usage_max 0.5311 (0.5339) gate/usage_min 0.2050 (0.2058) gate/usage_std 0.1419 (0.1436) teacher/entropy 0.0004 (0.0100) teacher/usage_max 0.8125 (0.8319) teacher/usage_min 0.0000 (0.0044) teacher/usage_std 0.3474 (0.3600) nleep/row_max_mean 1548.2025 (1541.5142) nleep/row_max_std 49.8908 (50.1381) nleep/row_min_mean 1508.5862 (1505.2126) lr 1.9098e-04 eta 0:02:51
epoch [42/50] batch [140/167] time 0.145 (0.129) data 0.000 (0.003) loss 1.5429 (1.8705) teacher_loss 0.0313 (0.2084) loss_zs_kd 0.0275 (0.0339) loss_oracle 0.7450 (0.8574) kd_loss 1.1254 (1.2164) acc 100.0000 (92.3438) gate/entropy 1.0138 (1.0110) gate/usage_max 0.5293 (0.5335) gate/usage_min 0.2051 (0.2057) gate/usage_std 0.1408 (0.1433) teacher/entropy 0.0055 (0.0094) teacher/usage_max 0.7196 (0.8301) teacher/usage_min 0.0001 (0.0042) teacher/usage_std 0.2961 (0.3590) nleep/row_max_mean 1524.9338 (1541.7664) nleep/row_max_std 57.8614 (50.2905) nleep/row_min_mean 1490.3053 (1505.3143) lr 1.9098e-04 eta 0:02:55
epoch [42/50] batch [160/167] time 0.117 (0.129) data 0.000 (0.002) loss 1.8591 (1.8697) teacher_loss 0.2362 (0.2105) loss_zs_kd 0.0414 (0.0337) loss_oracle 0.8442 (0.8578) kd_loss 1.1800 (1.2134) acc 90.6250 (92.3633) gate/entropy 1.0132 (1.0113) gate/usage_max 0.5298 (0.5330) gate/usage_min 0.2042 (0.2055) gate/usage_std 0.1412 (0.1431) teacher/entropy 0.0124 (0.0093) teacher/usage_max 0.8092 (0.8281) teacher/usage_min 0.0004 (0.0043) teacher/usage_std 0.3453 (0.3576) nleep/row_max_mean 1552.9420 (1541.9220) nleep/row_max_std 42.2287 (50.2183) nleep/row_min_mean 1516.2649 (1505.4302) lr 1.9098e-04 eta 0:02:53
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,203
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [43/50] batch [20/167] time 0.145 (0.161) data 0.000 (0.017) loss 1.7453 (1.8367) teacher_loss 0.1254 (0.1948) loss_zs_kd 0.0325 (0.0328) loss_oracle 0.8756 (0.8555) kd_loss 1.1659 (1.1978) acc 93.7500 (93.7500) gate/entropy 1.0140 (1.0138) gate/usage_max 0.5284 (0.5288) gate/usage_min 0.2038 (0.2040) gate/usage_std 0.1404 (0.1406) teacher/entropy 0.0026 (0.0102) teacher/usage_max 0.7815 (0.8320) teacher/usage_min 0.0000 (0.0039) teacher/usage_std 0.3292 (0.3602) nleep/row_max_mean 1543.9032 (1545.2559) nleep/row_max_std 56.2778 (51.3260) nleep/row_min_mean 1505.0793 (1507.5442) lr 1.5567e-04 eta 0:03:31
epoch [43/50] batch [40/167] time 0.092 (0.142) data 0.000 (0.009) loss 1.8977 (1.8466) teacher_loss 0.3281 (0.2106) loss_zs_kd 0.0530 (0.0363) loss_oracle 0.8399 (0.8588) kd_loss 1.1231 (1.1884) acc 84.3750 (92.6562) gate/entropy 1.0140 (1.0140) gate/usage_max 0.5283 (0.5284) gate/usage_min 0.2032 (0.2038) gate/usage_std 0.1404 (0.1404) teacher/entropy 0.0008 (0.0111) teacher/usage_max 0.7189 (0.8203) teacher/usage_min 0.0000 (0.0049) teacher/usage_std 0.2958 (0.3535) nleep/row_max_mean 1548.7695 (1544.9317) nleep/row_max_std 64.4435 (55.4398) nleep/row_min_mean 1506.7085 (1506.7481) lr 1.5567e-04 eta 0:03:04
epoch [43/50] batch [60/167] time 0.080 (0.133) data 0.001 (0.006) loss 1.8401 (1.8403) teacher_loss 0.2702 (0.2026) loss_zs_kd 0.0562 (0.0363) loss_oracle 0.7646 (0.8636) kd_loss 1.1595 (1.1878) acc 84.3750 (92.6042) gate/entropy 1.0146 (1.0143) gate/usage_max 0.5273 (0.5280) gate/usage_min 0.2030 (0.2037) gate/usage_std 0.1398 (0.1402) teacher/entropy 0.0038 (0.0107) teacher/usage_max 0.7805 (0.8209) teacher/usage_min 0.0008 (0.0051) teacher/usage_std 0.3285 (0.3535) nleep/row_max_mean 1552.6996 (1544.1864) nleep/row_max_std 53.4990 (55.6277) nleep/row_min_mean 1514.3441 (1506.0283) lr 1.5567e-04 eta 0:02:49
epoch [43/50] batch [80/167] time 0.187 (0.131) data 0.000 (0.005) loss 1.8610 (1.8540) teacher_loss 0.2920 (0.2170) loss_zs_kd 0.0279 (0.0363) loss_oracle 0.8317 (0.8687) kd_loss 1.1392 (1.1845) acc 87.5000 (92.1094) gate/entropy 1.0151 (1.0145) gate/usage_max 0.5264 (0.5276) gate/usage_min 0.2027 (0.2035) gate/usage_std 0.1393 (0.1400) teacher/entropy 0.0248 (0.0120) teacher/usage_max 0.7687 (0.8190) teacher/usage_min 0.0128 (0.0058) teacher/usage_std 0.3191 (0.3523) nleep/row_max_mean 1546.1263 (1543.8091) nleep/row_max_std 47.0718 (54.6049) nleep/row_min_mean 1508.3538 (1505.6763) lr 1.5567e-04 eta 0:02:43
epoch [43/50] batch [100/167] time 0.101 (0.127) data 0.000 (0.004) loss 1.7750 (1.8603) teacher_loss 0.2348 (0.2223) loss_zs_kd 0.0387 (0.0363) loss_oracle 0.7814 (0.8698) kd_loss 1.1302 (1.1849) acc 90.6250 (91.8750) gate/entropy 1.0153 (1.0147) gate/usage_max 0.5259 (0.5272) gate/usage_min 0.2022 (0.2034) gate/usage_std 0.1391 (0.1397) teacher/entropy 0.0081 (0.0115) teacher/usage_max 0.7516 (0.8213) teacher/usage_min 0.0002 (0.0057) teacher/usage_std 0.3126 (0.3536) nleep/row_max_mean 1563.0320 (1542.4463) nleep/row_max_std 47.9052 (54.0486) nleep/row_min_mean 1522.9642 (1504.4470) lr 1.5567e-04 eta 0:02:36
epoch [43/50] batch [120/167] time 0.084 (0.123) data 0.000 (0.003) loss 1.7591 (1.8564) teacher_loss 0.0547 (0.2190) loss_zs_kd 0.0193 (0.0362) loss_oracle 0.9786 (0.8739) kd_loss 1.2054 (1.1824) acc 100.0000 (91.7969) gate/entropy 1.0171 (1.0150) gate/usage_max 0.5234 (0.5268) gate/usage_min 0.2028 (0.2032) gate/usage_std 0.1375 (0.1395) teacher/entropy 0.0163 (0.0116) teacher/usage_max 0.8503 (0.8205) teacher/usage_min 0.0247 (0.0054) teacher/usage_std 0.3679 (0.3534) nleep/row_max_mean 1519.2812 (1542.1289) nleep/row_max_std 61.5563 (53.4157) nleep/row_min_mean 1479.5706 (1503.9866) lr 1.5567e-04 eta 0:02:29
epoch [43/50] batch [140/167] time 0.088 (0.121) data 0.000 (0.003) loss 1.8649 (1.8539) teacher_loss 0.1945 (0.2130) loss_zs_kd 0.0294 (0.0368) loss_oracle 0.8692 (0.8781) kd_loss 1.2211 (1.1835) acc 90.6250 (92.0089) gate/entropy 1.0167 (1.0152) gate/usage_max 0.5236 (0.5264) gate/usage_min 0.2019 (0.2031) gate/usage_std 0.1377 (0.1393) teacher/entropy 0.0090 (0.0114) teacher/usage_max 0.9037 (0.8253) teacher/usage_min 0.0000 (0.0048) teacher/usage_std 0.4052 (0.3563) nleep/row_max_mean 1541.3666 (1541.5310) nleep/row_max_std 49.8773 (52.9739) nleep/row_min_mean 1503.1641 (1503.2678) lr 1.5567e-04 eta 0:02:25
epoch [43/50] batch [160/167] time 0.063 (0.120) data 0.000 (0.002) loss 1.9353 (1.8526) teacher_loss 0.2081 (0.2106) loss_zs_kd 0.0193 (0.0366) loss_oracle 0.9756 (0.8803) kd_loss 1.2298 (1.1835) acc 90.6250 (92.1484) gate/entropy 1.0174 (1.0154) gate/usage_max 0.5223 (0.5259) gate/usage_min 0.2017 (0.2029) gate/usage_std 0.1370 (0.1390) teacher/entropy 0.0066 (0.0115) teacher/usage_max 0.8767 (0.8281) teacher/usage_min 0.0296 (0.0047) teacher/usage_std 0.3851 (0.3580) nleep/row_max_mean 1538.2666 (1540.2941) nleep/row_max_std 49.4679 (52.6803) nleep/row_min_mean 1496.9585 (1501.9781) lr 1.5567e-04 eta 0:02:20
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,205
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [44/50] batch [20/167] time 0.132 (0.133) data 0.000 (0.015) loss 1.9258 (1.8215) teacher_loss 0.3294 (0.2003) loss_zs_kd 0.0381 (0.0407) loss_oracle 0.8271 (0.8674) kd_loss 1.1638 (1.1672) acc 87.5000 (92.5000) gate/entropy 1.0174 (1.0176) gate/usage_max 0.5219 (0.5218) gate/usage_min 0.2009 (0.2013) gate/usage_std 0.1369 (0.1368) teacher/entropy 0.0001 (0.0118) teacher/usage_max 0.8125 (0.8224) teacher/usage_min 0.0000 (0.0084) teacher/usage_std 0.3474 (0.3540) nleep/row_max_mean 1560.8804 (1538.6501) nleep/row_max_std 49.8502 (46.6713) nleep/row_min_mean 1516.6780 (1498.9311) lr 1.2369e-04 eta 0:02:32
epoch [44/50] batch [40/167] time 0.159 (0.143) data 0.000 (0.007) loss 1.9558 (1.8588) teacher_loss 0.3177 (0.2337) loss_zs_kd 0.0224 (0.0382) loss_oracle 0.9246 (0.8720) kd_loss 1.1646 (1.1700) acc 90.6250 (91.3281) gate/entropy 1.0183 (1.0178) gate/usage_max 0.5206 (0.5214) gate/usage_min 0.2010 (0.2012) gate/usage_std 0.1361 (0.1366) teacher/entropy 0.0153 (0.0100) teacher/usage_max 0.8413 (0.8288) teacher/usage_min 0.0011 (0.0066) teacher/usage_std 0.3648 (0.3580) nleep/row_max_mean 1529.8115 (1537.5489) nleep/row_max_std 55.4405 (48.2715) nleep/row_min_mean 1493.4255 (1498.0090) lr 1.2369e-04 eta 0:02:41
epoch [44/50] batch [60/167] time 0.129 (0.144) data 0.000 (0.005) loss 1.7479 (1.8501) teacher_loss 0.1379 (0.2193) loss_zs_kd 0.0288 (0.0369) loss_oracle 0.8454 (0.8783) kd_loss 1.1729 (1.1732) acc 96.8750 (91.8229) gate/entropy 1.0186 (1.0181) gate/usage_max 0.5199 (0.5210) gate/usage_min 0.2006 (0.2011) gate/usage_std 0.1358 (0.1364) teacher/entropy 0.0042 (0.0098) teacher/usage_max 0.8429 (0.8356) teacher/usage_min 0.0000 (0.0067) teacher/usage_std 0.3660 (0.3620) nleep/row_max_mean 1549.3009 (1538.2312) nleep/row_max_std 45.5319 (49.1125) nleep/row_min_mean 1508.3531 (1498.7191) lr 1.2369e-04 eta 0:02:39
epoch [44/50] batch [80/167] time 0.170 (0.145) data 0.000 (0.004) loss 1.7272 (1.8452) teacher_loss 0.1372 (0.2144) loss_zs_kd 0.0364 (0.0368) loss_oracle 0.8439 (0.8813) kd_loss 1.1499 (1.1717) acc 93.7500 (92.0312) gate/entropy 1.0186 (1.0182) gate/usage_max 0.5196 (0.5206) gate/usage_min 0.2000 (0.2009) gate/usage_std 0.1357 (0.1362) teacher/entropy 0.0059 (0.0101) teacher/usage_max 0.8121 (0.8356) teacher/usage_min 0.0007 (0.0069) teacher/usage_std 0.3470 (0.3620) nleep/row_max_mean 1551.6759 (1538.6554) nleep/row_max_std 48.0288 (49.3252) nleep/row_min_mean 1511.3792 (1499.0024) lr 1.2369e-04 eta 0:02:37
epoch [44/50] batch [100/167] time 0.167 (0.146) data 0.000 (0.003) loss 1.8076 (1.8329) teacher_loss 0.2315 (0.2108) loss_zs_kd 0.0514 (0.0377) loss_oracle 0.7959 (0.8770) kd_loss 1.1524 (1.1648) acc 90.6250 (92.1875) gate/entropy 1.0193 (1.0184) gate/usage_max 0.5185 (0.5203) gate/usage_min 0.1999 (0.2008) gate/usage_std 0.1351 (0.1360) teacher/entropy 0.0001 (0.0119) teacher/usage_max 0.8125 (0.8302) teacher/usage_min 0.0000 (0.0065) teacher/usage_std 0.3474 (0.3587) nleep/row_max_mean 1542.3147 (1538.8708) nleep/row_max_std 43.8942 (49.7090) nleep/row_min_mean 1497.9290 (1499.1476) lr 1.2369e-04 eta 0:02:36
epoch [44/50] batch [120/167] time 0.159 (0.147) data 0.000 (0.003) loss 1.7051 (1.8219) teacher_loss 0.1610 (0.2065) loss_zs_kd 0.0561 (0.0372) loss_oracle 0.8245 (0.8723) kd_loss 1.1038 (1.1606) acc 93.7500 (92.5781) gate/entropy 1.0200 (1.0186) gate/usage_max 0.5173 (0.5199) gate/usage_min 0.2000 (0.2006) gate/usage_std 0.1344 (0.1358) teacher/entropy 0.0872 (0.0133) teacher/usage_max 0.8186 (0.8259) teacher/usage_min 0.0397 (0.0079) teacher/usage_std 0.3457 (0.3559) nleep/row_max_mean 1529.4255 (1538.4230) nleep/row_max_std 64.0880 (50.9094) nleep/row_min_mean 1493.2748 (1498.6397) lr 1.2369e-04 eta 0:02:33
epoch [44/50] batch [140/167] time 0.072 (0.144) data 0.000 (0.002) loss 1.9309 (1.8181) teacher_loss 0.2492 (0.2081) loss_zs_kd 0.0352 (0.0372) loss_oracle 0.8675 (0.8656) kd_loss 1.2303 (1.1586) acc 90.6250 (92.4777) gate/entropy 1.0202 (1.0188) gate/usage_max 0.5168 (0.5195) gate/usage_min 0.1996 (0.2005) gate/usage_std 0.1342 (0.1356) teacher/entropy 0.0192 (0.0139) teacher/usage_max 0.9375 (0.8259) teacher/usage_min 0.0284 (0.0080) teacher/usage_std 0.4272 (0.3560) nleep/row_max_mean 1531.1882 (1538.3055) nleep/row_max_std 48.2628 (51.3435) nleep/row_min_mean 1493.2996 (1498.4939) lr 1.2369e-04 eta 0:02:27
epoch [44/50] batch [160/167] time 0.150 (0.136) data 0.000 (0.002) loss 1.5658 (1.8103) teacher_loss 0.0316 (0.2066) loss_zs_kd 0.0249 (0.0368) loss_oracle 0.7932 (0.8588) kd_loss 1.1251 (1.1559) acc 100.0000 (92.5781) gate/entropy 1.0209 (1.0190) gate/usage_max 0.5156 (0.5191) gate/usage_min 0.1997 (0.2003) gate/usage_std 0.1334 (0.1354) teacher/entropy 0.0008 (0.0144) teacher/usage_max 0.7814 (0.8253) teacher/usage_min 0.0000 (0.0074) teacher/usage_std 0.3291 (0.3558) nleep/row_max_mean 1524.3931 (1538.4563) nleep/row_max_std 48.4862 (51.2096) nleep/row_min_mean 1481.8478 (1498.5997) lr 1.2369e-04 eta 0:02:17
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,202
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,323
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.2%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [45/50] batch [20/167] time 0.087 (0.146) data 0.000 (0.018) loss 1.6686 (1.7276) teacher_loss 0.0455 (0.1602) loss_zs_kd 0.0375 (0.0336) loss_oracle 0.9272 (0.8121) kd_loss 1.1408 (1.1445) acc 100.0000 (93.7500) gate/entropy 1.0210 (1.0207) gate/usage_max 0.5151 (0.5155) gate/usage_min 0.1990 (0.1989) gate/usage_std 0.1333 (0.1336) teacher/entropy 0.0228 (0.0201) teacher/usage_max 0.8338 (0.8325) teacher/usage_min 0.0101 (0.0112) teacher/usage_std 0.3588 (0.3596) nleep/row_max_mean 1529.6594 (1537.3940) nleep/row_max_std 55.9180 (55.7964) nleep/row_min_mean 1489.1702 (1498.6573) lr 9.5173e-05 eta 0:02:23
epoch [45/50] batch [40/167] time 0.091 (0.127) data 0.000 (0.009) loss 1.6973 (1.7474) teacher_loss 0.1184 (0.1755) loss_zs_kd 0.0339 (0.0363) loss_oracle 0.7746 (0.8205) kd_loss 1.1746 (1.1435) acc 93.7500 (93.5156) gate/entropy 1.0213 (1.0209) gate/usage_max 0.5144 (0.5152) gate/usage_min 0.1988 (0.1988) gate/usage_std 0.1330 (0.1334) teacher/entropy 0.0369 (0.0154) teacher/usage_max 0.8588 (0.8230) teacher/usage_min 0.0473 (0.0122) teacher/usage_std 0.3721 (0.3543) nleep/row_max_mean 1535.0515 (1537.7608) nleep/row_max_std 50.2238 (54.5878) nleep/row_min_mean 1499.5032 (1497.7706) lr 9.5173e-05 eta 0:02:02
epoch [45/50] batch [60/167] time 0.166 (0.126) data 0.001 (0.006) loss 1.9345 (1.7658) teacher_loss 0.3788 (0.1955) loss_zs_kd 0.0494 (0.0368) loss_oracle 0.8621 (0.8254) kd_loss 1.0999 (1.1392) acc 87.5000 (92.9688) gate/entropy 1.0217 (1.0210) gate/usage_max 0.5136 (0.5149) gate/usage_min 0.1987 (0.1987) gate/usage_std 0.1325 (0.1333) teacher/entropy 0.0277 (0.0169) teacher/usage_max 0.7968 (0.8236) teacher/usage_min 0.0000 (0.0099) teacher/usage_std 0.3381 (0.3546) nleep/row_max_mean 1536.5212 (1540.0432) nleep/row_max_std 52.3914 (53.9186) nleep/row_min_mean 1494.9373 (1499.8737) lr 9.5173e-05 eta 0:01:58
epoch [45/50] batch [80/167] time 0.176 (0.126) data 0.000 (0.005) loss 1.7709 (1.7519) teacher_loss 0.1685 (0.1837) loss_zs_kd 0.0262 (0.0359) loss_oracle 0.8748 (0.8281) kd_loss 1.1519 (1.1362) acc 93.7500 (93.4375) gate/entropy 1.0216 (1.0211) gate/usage_max 0.5134 (0.5146) gate/usage_min 0.1981 (0.1986) gate/usage_std 0.1325 (0.1331) teacher/entropy 0.0221 (0.0174) teacher/usage_max 0.8655 (0.8222) teacher/usage_min 0.0090 (0.0095) teacher/usage_std 0.3793 (0.3536) nleep/row_max_mean 1544.6151 (1541.5189) nleep/row_max_std 47.6207 (53.0665) nleep/row_min_mean 1507.9910 (1501.4073) lr 9.5173e-05 eta 0:01:56
epoch [45/50] batch [100/167] time 0.163 (0.125) data 0.000 (0.004) loss 1.8348 (1.7617) teacher_loss 0.3216 (0.1934) loss_zs_kd 0.0494 (0.0357) loss_oracle 0.7423 (0.8266) kd_loss 1.1173 (1.1371) acc 90.6250 (93.0938) gate/entropy 1.0220 (1.0213) gate/usage_max 0.5127 (0.5142) gate/usage_min 0.1980 (0.1985) gate/usage_std 0.1322 (0.1330) teacher/entropy 0.0183 (0.0170) teacher/usage_max 0.7263 (0.8255) teacher/usage_min 0.0550 (0.0091) teacher/usage_std 0.2858 (0.3556) nleep/row_max_mean 1544.3074 (1541.4707) nleep/row_max_std 61.1639 (53.3571) nleep/row_min_mean 1501.6532 (1501.2555) lr 9.5173e-05 eta 0:01:52
epoch [45/50] batch [120/167] time 0.082 (0.123) data 0.000 (0.003) loss 1.6069 (1.7577) teacher_loss 0.1584 (0.1954) loss_zs_kd 0.0467 (0.0356) loss_oracle 0.7256 (0.8232) kd_loss 1.0624 (1.1328) acc 90.6250 (93.0469) gate/entropy 1.0220 (1.0214) gate/usage_max 0.5123 (0.5139) gate/usage_min 0.1974 (0.1983) gate/usage_std 0.1321 (0.1328) teacher/entropy 0.0126 (0.0187) teacher/usage_max 0.7156 (0.8226) teacher/usage_min 0.0000 (0.0094) teacher/usage_std 0.2942 (0.3538) nleep/row_max_mean 1551.7195 (1542.8312) nleep/row_max_std 58.8261 (53.5860) nleep/row_min_mean 1511.1252 (1502.5110) lr 9.5173e-05 eta 0:01:48
epoch [45/50] batch [140/167] time 0.123 (0.123) data 0.001 (0.003) loss 1.7217 (1.7531) teacher_loss 0.1612 (0.1952) loss_zs_kd 0.0431 (0.0357) loss_oracle 0.7942 (0.8211) kd_loss 1.1419 (1.1295) acc 93.7500 (92.8795) gate/entropy 1.0224 (1.0215) gate/usage_max 0.5116 (0.5136) gate/usage_min 0.1973 (0.1982) gate/usage_std 0.1317 (0.1327) teacher/entropy 0.0043 (0.0187) teacher/usage_max 0.8434 (0.8182) teacher/usage_min 0.0005 (0.0096) teacher/usage_std 0.3662 (0.3510) nleep/row_max_mean 1547.1855 (1543.5229) nleep/row_max_std 53.9994 (53.9252) nleep/row_min_mean 1506.9567 (1503.1592) lr 9.5173e-05 eta 0:01:46
epoch [45/50] batch [160/167] time 0.122 (0.125) data 0.000 (0.002) loss 1.7665 (1.7542) teacher_loss 0.2807 (0.1985) loss_zs_kd 0.0674 (0.0361) loss_oracle 0.7438 (0.8208) kd_loss 1.0802 (1.1272) acc 87.5000 (92.7344) gate/entropy 1.0221 (1.0217) gate/usage_max 0.5115 (0.5133) gate/usage_min 0.1964 (0.1981) gate/usage_std 0.1319 (0.1325) teacher/entropy 0.0505 (0.0189) teacher/usage_max 0.7915 (0.8168) teacher/usage_min 0.0177 (0.0094) teacher/usage_std 0.3316 (0.3502) nleep/row_max_mean 1554.9089 (1543.8725) nleep/row_max_std 60.1049 (53.7801) nleep/row_min_mean 1514.4487 (1503.3453) lr 9.5173e-05 eta 0:01:45
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,202
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.3%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,322
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [46/50] batch [20/167] time 0.162 (0.170) data 0.000 (0.017) loss 1.7282 (1.7609) teacher_loss 0.2226 (0.2073) loss_zs_kd 0.0381 (0.0318) loss_oracle 0.7630 (0.8371) kd_loss 1.1050 (1.1192) acc 90.6250 (92.3438) gate/entropy 1.0227 (1.0229) gate/usage_max 0.5104 (0.5104) gate/usage_min 0.1966 (0.1970) gate/usage_std 0.1313 (0.1311) teacher/entropy 0.0469 (0.0203) teacher/usage_max 0.7320 (0.8189) teacher/usage_min 0.0765 (0.0121) teacher/usage_std 0.2858 (0.3508) nleep/row_max_mean 1547.4093 (1541.7425) nleep/row_max_std 57.1342 (56.6612) nleep/row_min_mean 1509.0095 (1500.8797) lr 7.0224e-05 eta 0:02:18
epoch [46/50] batch [40/167] time 0.150 (0.160) data 0.000 (0.009) loss 1.7750 (1.7595) teacher_loss 0.2134 (0.2157) loss_zs_kd 0.0360 (0.0344) loss_oracle 0.7968 (0.8285) kd_loss 1.1453 (1.1123) acc 93.7500 (92.3438) gate/entropy 1.0230 (1.0230) gate/usage_max 0.5099 (0.5101) gate/usage_min 0.1964 (0.1969) gate/usage_std 0.1310 (0.1310) teacher/entropy 0.0096 (0.0231) teacher/usage_max 0.8724 (0.8117) teacher/usage_min 0.0002 (0.0130) teacher/usage_std 0.3847 (0.3461) nleep/row_max_mean 1543.6360 (1543.2187) nleep/row_max_std 64.9324 (56.8138) nleep/row_min_mean 1499.5092 (1502.3566) lr 7.0224e-05 eta 0:02:07
epoch [46/50] batch [60/167] time 0.090 (0.142) data 0.001 (0.006) loss 1.7744 (1.7563) teacher_loss 0.2338 (0.2133) loss_zs_kd 0.0257 (0.0349) loss_oracle 0.8363 (0.8271) kd_loss 1.1095 (1.1120) acc 90.6250 (92.7604) gate/entropy 1.0238 (1.0231) gate/usage_max 0.5089 (0.5099) gate/usage_min 0.1970 (0.1968) gate/usage_std 0.1303 (0.1309) teacher/entropy 0.0214 (0.0206) teacher/usage_max 0.8309 (0.8123) teacher/usage_min 0.0000 (0.0105) teacher/usage_std 0.3585 (0.3474) nleep/row_max_mean 1523.4425 (1542.6817) nleep/row_max_std 62.9410 (56.8157) nleep/row_min_mean 1487.2002 (1501.9851) lr 7.0224e-05 eta 0:01:50
epoch [46/50] batch [80/167] time 0.067 (0.135) data 0.000 (0.004) loss 1.6667 (1.7433) teacher_loss 0.1231 (0.2025) loss_zs_kd 0.0288 (0.0343) loss_oracle 0.8890 (0.8263) kd_loss 1.0847 (1.1105) acc 96.8750 (93.2031) gate/entropy 1.0235 (1.0232) gate/usage_max 0.5088 (0.5097) gate/usage_min 0.1962 (0.1967) gate/usage_std 0.1305 (0.1308) teacher/entropy 0.0218 (0.0194) teacher/usage_max 0.7898 (0.8077) teacher/usage_min 0.0003 (0.0112) teacher/usage_std 0.3339 (0.3443) nleep/row_max_mean 1551.5054 (1543.1185) nleep/row_max_std 49.0526 (56.2845) nleep/row_min_mean 1508.1212 (1502.2601) lr 7.0224e-05 eta 0:01:41
epoch [46/50] batch [100/167] time 0.133 (0.131) data 0.000 (0.004) loss 1.8120 (1.7425) teacher_loss 0.1780 (0.2043) loss_zs_kd 0.0186 (0.0353) loss_oracle 0.8930 (0.8226) kd_loss 1.1782 (1.1093) acc 93.7500 (93.0000) gate/entropy 1.0239 (1.0233) gate/usage_max 0.5081 (0.5094) gate/usage_min 0.1964 (0.1966) gate/usage_std 0.1300 (0.1307) teacher/entropy 0.0072 (0.0191) teacher/usage_max 0.9361 (0.8077) teacher/usage_min 0.0011 (0.0104) teacher/usage_std 0.4270 (0.3446) nleep/row_max_mean 1525.8958 (1541.0643) nleep/row_max_std 54.8006 (56.9010) nleep/row_min_mean 1486.5188 (1500.5449) lr 7.0224e-05 eta 0:01:35
epoch [46/50] batch [120/167] time 0.076 (0.127) data 0.000 (0.003) loss 1.6035 (1.7432) teacher_loss 0.1543 (0.2061) loss_zs_kd 0.0367 (0.0351) loss_oracle 0.6567 (0.8212) kd_loss 1.1025 (1.1088) acc 96.8750 (92.9688) gate/entropy 1.0239 (1.0234) gate/usage_max 0.5078 (0.5092) gate/usage_min 0.1960 (0.1965) gate/usage_std 0.1300 (0.1306) teacher/entropy 0.0098 (0.0196) teacher/usage_max 0.7509 (0.8080) teacher/usage_min 0.0316 (0.0112) teacher/usage_std 0.3048 (0.3446) nleep/row_max_mean 1535.8254 (1539.7967) nleep/row_max_std 47.8206 (56.5810) nleep/row_min_mean 1499.4202 (1499.5957) lr 7.0224e-05 eta 0:01:30
epoch [46/50] batch [140/167] time 0.104 (0.122) data 0.000 (0.003) loss 1.6142 (1.7414) teacher_loss 0.0326 (0.2044) loss_zs_kd 0.0352 (0.0359) loss_oracle 0.9116 (0.8223) kd_loss 1.1082 (1.1079) acc 100.0000 (92.9464) gate/entropy 1.0244 (1.0234) gate/usage_max 0.5071 (0.5090) gate/usage_min 0.1962 (0.1964) gate/usage_std 0.1295 (0.1305) teacher/entropy 0.0061 (0.0196) teacher/usage_max 0.8115 (0.8070) teacher/usage_min 0.0002 (0.0115) teacher/usage_std 0.3467 (0.3439) nleep/row_max_mean 1527.8539 (1539.1240) nleep/row_max_std 54.3027 (56.1243) nleep/row_min_mean 1482.5352 (1499.0164) lr 7.0224e-05 eta 0:01:24
epoch [46/50] batch [160/167] time 0.073 (0.121) data 0.000 (0.002) loss 1.7609 (1.7406) teacher_loss 0.1617 (0.2020) loss_zs_kd 0.0388 (0.0359) loss_oracle 0.8427 (0.8247) kd_loss 1.1584 (1.1083) acc 93.7500 (92.9102) gate/entropy 1.0242 (1.0235) gate/usage_max 0.5068 (0.5087) gate/usage_min 0.1955 (0.1963) gate/usage_std 0.1296 (0.1304) teacher/entropy 0.0032 (0.0202) teacher/usage_max 0.9056 (0.8099) teacher/usage_min 0.0000 (0.0118) teacher/usage_std 0.4065 (0.3457) nleep/row_max_mean 1538.8281 (1537.3339) nleep/row_max_std 60.9576 (55.8977) nleep/row_min_mean 1495.9729 (1497.4692) lr 7.0224e-05 eta 0:01:21
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,204
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.0%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [47/50] batch [20/167] time 0.088 (0.138) data 0.001 (0.017) loss 1.6305 (1.7037) teacher_loss 0.0425 (0.1835) loss_zs_kd 0.0063 (0.0331) loss_oracle 0.9098 (0.8149) kd_loss 1.1299 (1.0962) acc 100.0000 (93.2812) gate/entropy 1.0247 (1.0244) gate/usage_max 0.5061 (0.5065) gate/usage_min 0.1957 (0.1954) gate/usage_std 0.1291 (0.1294) teacher/entropy 0.0209 (0.0216) teacher/usage_max 0.7874 (0.7921) teacher/usage_min 0.0564 (0.0187) teacher/usage_std 0.3237 (0.3336) nleep/row_max_mean 1533.8184 (1530.8604) nleep/row_max_std 60.1224 (54.5142) nleep/row_min_mean 1493.6982 (1492.0996) lr 4.8943e-05 eta 0:01:29
epoch [47/50] batch [40/167] time 0.137 (0.125) data 0.000 (0.008) loss 1.8023 (1.7181) teacher_loss 0.3090 (0.1982) loss_zs_kd 0.0726 (0.0346) loss_oracle 0.8017 (0.8149) kd_loss 1.0562 (1.0951) acc 87.5000 (92.8125) gate/entropy 1.0244 (1.0244) gate/usage_max 0.5061 (0.5063) gate/usage_min 0.1951 (0.1953) gate/usage_std 0.1293 (0.1294) teacher/entropy 0.0432 (0.0229) teacher/usage_max 0.7528 (0.7896) teacher/usage_min 0.0227 (0.0208) teacher/usage_std 0.3078 (0.3316) nleep/row_max_mean 1527.9047 (1532.8151) nleep/row_max_std 64.5180 (54.0117) nleep/row_min_mean 1491.1433 (1493.9078) lr 4.8943e-05 eta 0:01:18
epoch [47/50] batch [60/167] time 0.149 (0.134) data 0.000 (0.006) loss 1.6931 (1.7168) teacher_loss 0.2564 (0.2010) loss_zs_kd 0.0236 (0.0352) loss_oracle 0.8063 (0.8144) kd_loss 1.0217 (1.0910) acc 90.6250 (92.5000) gate/entropy 1.0244 (1.0245) gate/usage_max 0.5059 (0.5062) gate/usage_min 0.1948 (0.1953) gate/usage_std 0.1293 (0.1293) teacher/entropy 0.0183 (0.0218) teacher/usage_max 0.6834 (0.7863) teacher/usage_min 0.0000 (0.0177) teacher/usage_std 0.2792 (0.3304) nleep/row_max_mean 1543.4600 (1533.7009) nleep/row_max_std 52.6233 (54.3229) nleep/row_min_mean 1500.6509 (1494.4909) lr 4.8943e-05 eta 0:01:21
epoch [47/50] batch [80/167] time 0.139 (0.136) data 0.000 (0.004) loss 1.7966 (1.7248) teacher_loss 0.1632 (0.2081) loss_zs_kd 0.0264 (0.0370) loss_oracle 0.9352 (0.8182) kd_loss 1.1526 (1.0891) acc 90.6250 (92.2656) gate/entropy 1.0250 (1.0245) gate/usage_max 0.5052 (0.5060) gate/usage_min 0.1953 (0.1952) gate/usage_std 0.1287 (0.1292) teacher/entropy 0.0155 (0.0241) teacher/usage_max 0.8802 (0.7851) teacher/usage_min 0.0265 (0.0193) teacher/usage_std 0.3876 (0.3294) nleep/row_max_mean 1527.8491 (1533.1091) nleep/row_max_std 52.2855 (53.6575) nleep/row_min_mean 1489.7512 (1493.9807) lr 4.8943e-05 eta 0:01:19
epoch [47/50] batch [100/167] time 0.110 (0.136) data 0.000 (0.003) loss 1.6188 (1.7232) teacher_loss 0.1018 (0.2024) loss_zs_kd 0.0398 (0.0377) loss_oracle 0.8193 (0.8234) kd_loss 1.0875 (1.0902) acc 93.7500 (92.5625) gate/entropy 1.0249 (1.0246) gate/usage_max 0.5051 (0.5058) gate/usage_min 0.1948 (0.1952) gate/usage_std 0.1288 (0.1291) teacher/entropy 0.0209 (0.0235) teacher/usage_max 0.7813 (0.7862) teacher/usage_min 0.0196 (0.0197) teacher/usage_std 0.3251 (0.3300) nleep/row_max_mean 1540.7654 (1532.9795) nleep/row_max_std 46.4058 (53.3696) nleep/row_min_mean 1502.1000 (1493.5803) lr 4.8943e-05 eta 0:01:17
epoch [47/50] batch [120/167] time 0.162 (0.138) data 0.000 (0.003) loss 1.6169 (1.7229) teacher_loss 0.1766 (0.2013) loss_zs_kd 0.0386 (0.0370) loss_oracle 0.7963 (0.8252) kd_loss 1.0229 (1.0905) acc 93.7500 (92.5781) gate/entropy 1.0249 (1.0247) gate/usage_max 0.5048 (0.5057) gate/usage_min 0.1945 (0.1951) gate/usage_std 0.1288 (0.1291) teacher/entropy 0.0570 (0.0237) teacher/usage_max 0.6566 (0.7884) teacher/usage_min 0.0584 (0.0196) teacher/usage_std 0.2466 (0.3314) nleep/row_max_mean 1545.3878 (1533.4511) nleep/row_max_std 57.7743 (53.6439) nleep/row_min_mean 1504.1425 (1493.8418) lr 4.8943e-05 eta 0:01:15
epoch [47/50] batch [140/167] time 0.167 (0.141) data 0.000 (0.003) loss 1.6072 (1.7292) teacher_loss 0.1242 (0.2059) loss_zs_kd 0.0383 (0.0379) loss_oracle 0.8098 (0.8249) kd_loss 1.0590 (1.0919) acc 93.7500 (92.4330) gate/entropy 1.0255 (1.0247) gate/usage_max 0.5041 (0.5055) gate/usage_min 0.1951 (0.1950) gate/usage_std 0.1283 (0.1290) teacher/entropy 0.0245 (0.0245) teacher/usage_max 0.7717 (0.7898) teacher/usage_min 0.0000 (0.0216) teacher/usage_std 0.3237 (0.3319) nleep/row_max_mean 1525.5287 (1534.4699) nleep/row_max_std 58.8624 (53.1358) nleep/row_min_mean 1483.1069 (1494.8151) lr 4.8943e-05 eta 0:01:14
epoch [47/50] batch [160/167] time 0.166 (0.143) data 0.000 (0.002) loss 1.7509 (1.7258) teacher_loss 0.1690 (0.2005) loss_zs_kd 0.0329 (0.0382) loss_oracle 0.9147 (0.8283) kd_loss 1.1081 (1.0921) acc 96.8750 (92.7539) gate/entropy 1.0251 (1.0248) gate/usage_max 0.5041 (0.5053) gate/usage_min 0.1942 (0.1950) gate/usage_std 0.1285 (0.1289) teacher/entropy 0.0108 (0.0250) teacher/usage_max 0.8423 (0.7913) teacher/usage_min 0.0013 (0.0220) teacher/usage_std 0.3654 (0.3327) nleep/row_max_mean 1551.7938 (1535.1587) nleep/row_max_std 46.5543 (52.6557) nleep/row_min_mean 1505.6300 (1495.4073) lr 4.8943e-05 eta 0:01:12
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,206
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,320
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.0%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [48/50] batch [20/167] time 0.089 (0.112) data 0.000 (0.014) loss 1.5986 (1.6899) teacher_loss 0.0929 (0.1684) loss_zs_kd 0.0224 (0.0432) loss_oracle 0.8312 (0.8391) kd_loss 1.0789 (1.0804) acc 100.0000 (94.6875) gate/entropy 1.0254 (1.0253) gate/usage_max 0.5037 (0.5038) gate/usage_min 0.1944 (0.1943) gate/usage_std 0.1282 (0.1283) teacher/entropy 0.0430 (0.0247) teacher/usage_max 0.7812 (0.7669) teacher/usage_min 0.0376 (0.0279) teacher/usage_std 0.3221 (0.3167) nleep/row_max_mean 1545.6823 (1541.1933) nleep/row_max_std 51.2711 (52.8692) nleep/row_min_mean 1506.1160 (1499.3041) lr 3.1417e-05 eta 0:00:53
epoch [48/50] batch [40/167] time 0.101 (0.107) data 0.000 (0.007) loss 1.6324 (1.6870) teacher_loss 0.1545 (0.1720) loss_zs_kd 0.0342 (0.0406) loss_oracle 0.8161 (0.8338) kd_loss 1.0528 (1.0778) acc 93.7500 (94.1406) gate/entropy 1.0255 (1.0254) gate/usage_max 0.5034 (0.5037) gate/usage_min 0.1943 (0.1943) gate/usage_std 0.1281 (0.1282) teacher/entropy 0.0216 (0.0249) teacher/usage_max 0.7378 (0.7755) teacher/usage_min 0.0122 (0.0210) teacher/usage_std 0.3020 (0.3229) nleep/row_max_mean 1550.3215 (1540.6391) nleep/row_max_std 62.0799 (52.8423) nleep/row_min_mean 1501.5774 (1498.7707) lr 3.1417e-05 eta 0:00:49
epoch [48/50] batch [60/167] time 0.142 (0.109) data 0.001 (0.005) loss 1.9913 (1.7015) teacher_loss 0.4418 (0.1812) loss_zs_kd 0.0483 (0.0407) loss_oracle 0.8672 (0.8359) kd_loss 1.0918 (1.0821) acc 84.3750 (93.6458) gate/entropy 1.0252 (1.0254) gate/usage_max 0.5034 (0.5036) gate/usage_min 0.1937 (0.1943) gate/usage_std 0.1283 (0.1282) teacher/entropy 0.0266 (0.0247) teacher/usage_max 0.8492 (0.7863) teacher/usage_min 0.0007 (0.0199) teacher/usage_std 0.3698 (0.3300) nleep/row_max_mean 1556.1086 (1540.5795) nleep/row_max_std 41.1366 (53.2395) nleep/row_min_mean 1516.5945 (1498.8447) lr 3.1417e-05 eta 0:00:48
epoch [48/50] batch [80/167] time 0.179 (0.115) data 0.000 (0.004) loss 1.8279 (1.7088) teacher_loss 0.4004 (0.1908) loss_zs_kd 0.0539 (0.0405) loss_oracle 0.7724 (0.8366) kd_loss 1.0143 (1.0796) acc 84.3750 (93.2812) gate/entropy 1.0255 (1.0254) gate/usage_max 0.5031 (0.5034) gate/usage_min 0.1939 (0.1942) gate/usage_std 0.1281 (0.1281) teacher/entropy 0.0661 (0.0270) teacher/usage_max 0.6736 (0.7827) teacher/usage_min 0.0542 (0.0220) teacher/usage_std 0.2565 (0.3279) nleep/row_max_mean 1547.9659 (1539.7120) nleep/row_max_std 35.0080 (52.9553) nleep/row_min_mean 1512.4978 (1498.2548) lr 3.1417e-05 eta 0:00:48
epoch [48/50] batch [100/167] time 0.082 (0.116) data 0.000 (0.003) loss 1.7688 (1.7161) teacher_loss 0.2592 (0.1989) loss_zs_kd 0.0704 (0.0409) loss_oracle 0.8443 (0.8361) kd_loss 1.0523 (1.0787) acc 90.6250 (93.1250) gate/entropy 1.0254 (1.0255) gate/usage_max 0.5030 (0.5033) gate/usage_min 0.1936 (0.1942) gate/usage_std 0.1280 (0.1281) teacher/entropy 0.0335 (0.0280) teacher/usage_max 0.7743 (0.7819) teacher/usage_min 0.0072 (0.0230) teacher/usage_std 0.3235 (0.3275) nleep/row_max_mean 1550.7563 (1539.9320) nleep/row_max_std 49.6871 (53.0907) nleep/row_min_mean 1509.0305 (1498.5278) lr 3.1417e-05 eta 0:00:46
epoch [48/50] batch [120/167] time 0.061 (0.115) data 0.000 (0.002) loss 1.6667 (1.7161) teacher_loss 0.1822 (0.1977) loss_zs_kd 0.0426 (0.0406) loss_oracle 0.7849 (0.8368) kd_loss 1.0709 (1.0796) acc 93.7500 (93.0990) gate/entropy 1.0257 (1.0255) gate/usage_max 0.5026 (0.5032) gate/usage_min 0.1939 (0.1941) gate/usage_std 0.1278 (0.1280) teacher/entropy 0.0116 (0.0272) teacher/usage_max 0.7803 (0.7797) teacher/usage_min 0.0010 (0.0246) teacher/usage_std 0.3283 (0.3257) nleep/row_max_mean 1546.9246 (1540.3294) nleep/row_max_std 54.1173 (53.3454) nleep/row_min_mean 1500.9915 (1498.7036) lr 3.1417e-05 eta 0:00:43
epoch [48/50] batch [140/167] time 0.164 (0.115) data 0.000 (0.002) loss 1.7252 (1.7137) teacher_loss 0.2559 (0.1963) loss_zs_kd 0.0406 (0.0405) loss_oracle 0.8051 (0.8358) kd_loss 1.0465 (1.0793) acc 90.6250 (93.1250) gate/entropy 1.0257 (1.0255) gate/usage_max 0.5024 (0.5031) gate/usage_min 0.1936 (0.1941) gate/usage_std 0.1278 (0.1280) teacher/entropy 0.0432 (0.0275) teacher/usage_max 0.7979 (0.7826) teacher/usage_min 0.0001 (0.0233) teacher/usage_std 0.3387 (0.3275) nleep/row_max_mean 1533.0549 (1540.4026) nleep/row_max_std 57.0714 (53.4528) nleep/row_min_mean 1494.0610 (1498.7523) lr 3.1417e-05 eta 0:00:41
epoch [48/50] batch [160/167] time 0.137 (0.115) data 0.000 (0.002) loss 1.5423 (1.7098) teacher_loss 0.1088 (0.1953) loss_zs_kd 0.0280 (0.0402) loss_oracle 0.8027 (0.8334) kd_loss 1.0181 (1.0777) acc 100.0000 (93.2031) gate/entropy 1.0259 (1.0256) gate/usage_max 0.5022 (0.5030) gate/usage_min 0.1937 (0.1941) gate/usage_std 0.1276 (0.1280) teacher/entropy 0.0437 (0.0294) teacher/usage_max 0.7435 (0.7808) teacher/usage_min 0.0000 (0.0250) teacher/usage_std 0.3084 (0.3260) nleep/row_max_mean 1538.6965 (1540.3181) nleep/row_max_std 46.1774 (53.0658) nleep/row_min_mean 1495.3987 (1498.7595) lr 3.1417e-05 eta 0:00:39
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,206
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [49/50] batch [20/167] time 0.154 (0.163) data 0.000 (0.017) loss 1.6158 (1.6575) teacher_loss 0.0764 (0.1546) loss_zs_kd 0.0390 (0.0397) loss_oracle 0.8464 (0.8251) kd_loss 1.0966 (1.0705) acc 96.8750 (95.1562) gate/entropy 1.0259 (1.0259) gate/usage_max 0.5020 (0.5020) gate/usage_min 0.1937 (0.1937) gate/usage_std 0.1275 (0.1275) teacher/entropy 0.0263 (0.0281) teacher/usage_max 0.8065 (0.7674) teacher/usage_min 0.0313 (0.0263) teacher/usage_std 0.3388 (0.3181) nleep/row_max_mean 1540.4878 (1541.5936) nleep/row_max_std 42.9128 (48.2887) nleep/row_min_mean 1501.1470 (1498.4031) lr 1.7713e-05 eta 0:00:51
epoch [49/50] batch [40/167] time 0.150 (0.156) data 0.000 (0.009) loss 1.9097 (1.6930) teacher_loss 0.3408 (0.1749) loss_zs_kd 0.0657 (0.0409) loss_oracle 0.7969 (0.8364) kd_loss 1.1377 (1.0794) acc 81.2500 (94.0625) gate/entropy 1.0259 (1.0259) gate/usage_max 0.5019 (0.5020) gate/usage_min 0.1935 (0.1937) gate/usage_std 0.1275 (0.1275) teacher/entropy 0.0049 (0.0254) teacher/usage_max 0.9064 (0.7811) teacher/usage_min 0.0006 (0.0259) teacher/usage_std 0.4069 (0.3261) nleep/row_max_mean 1536.9657 (1543.0912) nleep/row_max_std 45.0412 (46.3094) nleep/row_min_mean 1497.4144 (1499.7793) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [60/167] time 0.163 (0.153) data 0.000 (0.006) loss 1.5224 (1.6895) teacher_loss 0.0964 (0.1783) loss_zs_kd 0.0145 (0.0408) loss_oracle 0.7979 (0.8331) kd_loss 1.0198 (1.0742) acc 93.7500 (94.0104) gate/entropy 1.0259 (1.0259) gate/usage_max 0.5018 (0.5019) gate/usage_min 0.1934 (0.1936) gate/usage_std 0.1275 (0.1275) teacher/entropy 0.0308 (0.0300) teacher/usage_max 0.7186 (0.7761) teacher/usage_min 0.0027 (0.0279) teacher/usage_std 0.2948 (0.3232) nleep/row_max_mean 1541.5817 (1542.5722) nleep/row_max_std 38.5263 (45.7159) nleep/row_min_mean 1498.6033 (1500.0817) lr 1.7713e-05 eta 0:00:41
epoch [49/50] batch [80/167] time 0.090 (0.143) data 0.000 (0.004) loss 1.7064 (1.7049) teacher_loss 0.2506 (0.1935) loss_zs_kd 0.0426 (0.0418) loss_oracle 0.8018 (0.8333) kd_loss 1.0336 (1.0739) acc 87.5000 (93.4766) gate/entropy 1.0262 (1.0260) gate/usage_max 0.5015 (0.5018) gate/usage_min 0.1938 (0.1936) gate/usage_std 0.1272 (0.1275) teacher/entropy 0.0214 (0.0303) teacher/usage_max 0.7319 (0.7744) teacher/usage_min 0.0000 (0.0290) teacher/usage_std 0.3023 (0.3218) nleep/row_max_mean 1531.7974 (1542.0014) nleep/row_max_std 50.1418 (45.9123) nleep/row_min_mean 1488.9940 (1499.8074) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [100/167] time 0.095 (0.136) data 0.000 (0.004) loss 1.5267 (1.7054) teacher_loss 0.0437 (0.1967) loss_zs_kd 0.0253 (0.0413) loss_oracle 0.8453 (0.8329) kd_loss 1.0476 (1.0716) acc 100.0000 (93.3125) gate/entropy 1.0261 (1.0260) gate/usage_max 0.5015 (0.5018) gate/usage_min 0.1935 (0.1936) gate/usage_std 0.1273 (0.1275) teacher/entropy 0.0000 (0.0317) teacher/usage_max 0.7187 (0.7714) teacher/usage_min 0.0000 (0.0298) teacher/usage_std 0.2957 (0.3199) nleep/row_max_mean 1549.4028 (1541.2974) nleep/row_max_std 42.9643 (46.0515) nleep/row_min_mean 1501.9192 (1499.1675) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [120/167] time 0.173 (0.133) data 0.000 (0.003) loss 1.8135 (1.7028) teacher_loss 0.3039 (0.1929) loss_zs_kd 0.0480 (0.0404) loss_oracle 0.8148 (0.8348) kd_loss 1.0781 (1.0723) acc 84.3750 (93.3854) gate/entropy 1.0261 (1.0260) gate/usage_max 0.5014 (0.5017) gate/usage_min 0.1933 (0.1935) gate/usage_std 0.1273 (0.1274) teacher/entropy 0.0193 (0.0316) teacher/usage_max 0.8196 (0.7768) teacher/usage_min 0.0004 (0.0279) teacher/usage_std 0.3516 (0.3237) nleep/row_max_mean 1537.9900 (1541.0367) nleep/row_max_std 48.0500 (46.1023) nleep/row_min_mean 1497.9041 (1498.9239) lr 1.7713e-05 eta 0:00:28
epoch [49/50] batch [140/167] time 0.074 (0.129) data 0.000 (0.003) loss 1.6731 (1.7014) teacher_loss 0.2537 (0.1943) loss_zs_kd 0.0390 (0.0403) loss_oracle 0.7325 (0.8316) kd_loss 1.0337 (1.0711) acc 87.5000 (93.2812) gate/entropy 1.0261 (1.0260) gate/usage_max 0.5012 (0.5017) gate/usage_min 0.1932 (0.1935) gate/usage_std 0.1273 (0.1274) teacher/entropy 0.0357 (0.0313) teacher/usage_max 0.7040 (0.7747) teacher/usage_min 0.0315 (0.0276) teacher/usage_std 0.2789 (0.3225) nleep/row_max_mean 1530.2167 (1540.1944) nleep/row_max_std 46.9107 (46.0950) nleep/row_min_mean 1490.6235 (1498.1623) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [160/167] time 0.070 (0.126) data 0.000 (0.002) loss 1.8153 (1.6991) teacher_loss 0.3423 (0.1938) loss_zs_kd 0.0377 (0.0399) loss_oracle 0.8012 (0.8300) kd_loss 1.0535 (1.0704) acc 87.5000 (93.2227) gate/entropy 1.0262 (1.0260) gate/usage_max 0.5011 (0.5016) gate/usage_min 0.1933 (0.1935) gate/usage_std 0.1272 (0.1274) teacher/entropy 0.0296 (0.0319) teacher/usage_max 0.7869 (0.7748) teacher/usage_min 0.0028 (0.0276) teacher/usage_std 0.3317 (0.3225) nleep/row_max_mean 1532.9803 (1539.6566) nleep/row_max_std 53.0687 (46.5115) nleep/row_min_mean 1491.5447 (1497.6394) lr 1.7713e-05 eta 0:00:21
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,206
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
epoch [50/50] batch [20/167] time 0.086 (0.136) data 0.000 (0.016) loss 1.5024 (1.7228) teacher_loss 0.1319 (0.2253) loss_zs_kd 0.0311 (0.0436) loss_oracle 0.7200 (0.8191) kd_loss 0.9949 (1.0662) acc 96.8750 (92.0312) gate/entropy 1.0260 (1.0262) gate/usage_max 0.5012 (0.5011) gate/usage_min 0.1930 (0.1932) gate/usage_std 0.1273 (0.1272) teacher/entropy 0.0476 (0.0283) teacher/usage_max 0.6380 (0.7511) teacher/usage_min 0.0381 (0.0336) teacher/usage_std 0.2450 (0.3070) nleep/row_max_mean 1542.3513 (1536.6605) nleep/row_max_std 38.0191 (48.8422) nleep/row_min_mean 1502.2949 (1494.7916) lr 7.8853e-06 eta 0:00:19
epoch [50/50] batch [40/167] time 0.075 (0.125) data 0.000 (0.008) loss 1.6438 (1.7120) teacher_loss 0.1537 (0.2002) loss_zs_kd 0.0358 (0.0401) loss_oracle 0.8838 (0.8354) kd_loss 1.0303 (1.0741) acc 96.8750 (92.5000) gate/entropy 1.0263 (1.0262) gate/usage_max 0.5010 (0.5010) gate/usage_min 0.1933 (0.1933) gate/usage_std 0.1271 (0.1272) teacher/entropy 0.0187 (0.0302) teacher/usage_max 0.7226 (0.7759) teacher/usage_min 0.0009 (0.0311) teacher/usage_std 0.2974 (0.3223) nleep/row_max_mean 1536.6941 (1533.6555) nleep/row_max_std 52.9482 (49.2725) nleep/row_min_mean 1490.7161 (1492.2594) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [60/167] time 0.095 (0.122) data 0.001 (0.006) loss 1.6546 (1.7019) teacher_loss 0.0975 (0.1926) loss_zs_kd 0.0361 (0.0407) loss_oracle 0.8529 (0.8281) kd_loss 1.1126 (1.0749) acc 96.8750 (93.1771) gate/entropy 1.0265 (1.0262) gate/usage_max 0.5008 (0.5010) gate/usage_min 0.1937 (0.1932) gate/usage_std 0.1269 (0.1272) teacher/entropy 0.0235 (0.0310) teacher/usage_max 0.8987 (0.7792) teacher/usage_min 0.0003 (0.0312) teacher/usage_std 0.4019 (0.3240) nleep/row_max_mean 1532.0549 (1534.9682) nleep/row_max_std 42.4418 (49.1799) nleep/row_min_mean 1490.6176 (1493.5186) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [80/167] time 0.179 (0.129) data 0.000 (0.004) loss 1.7621 (1.7128) teacher_loss 0.2819 (0.2043) loss_zs_kd 0.0344 (0.0407) loss_oracle 0.7811 (0.8255) kd_loss 1.0725 (1.0754) acc 90.6250 (93.0078) gate/entropy 1.0266 (1.0262) gate/usage_max 0.5006 (0.5010) gate/usage_min 0.1937 (0.1932) gate/usage_std 0.1268 (0.1271) teacher/entropy 0.0212 (0.0312) teacher/usage_max 0.7449 (0.7777) teacher/usage_min 0.0357 (0.0328) teacher/usage_std 0.3005 (0.3227) nleep/row_max_mean 1527.7732 (1535.2632) nleep/row_max_std 57.4832 (48.9364) nleep/row_min_mean 1486.2264 (1493.7152) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [100/167] time 0.148 (0.136) data 0.000 (0.003) loss 1.5831 (1.7115) teacher_loss 0.0882 (0.2057) loss_zs_kd 0.0256 (0.0406) loss_oracle 0.8218 (0.8239) kd_loss 1.0712 (1.0735) acc 100.0000 (93.0000) gate/entropy 1.0262 (1.0262) gate/usage_max 0.5009 (0.5009) gate/usage_min 0.1930 (0.1932) gate/usage_std 0.1272 (0.1271) teacher/entropy 0.0189 (0.0320) teacher/usage_max 0.7540 (0.7779) teacher/usage_min 0.0285 (0.0316) teacher/usage_std 0.3073 (0.3228) nleep/row_max_mean 1528.4814 (1535.9167) nleep/row_max_std 56.4107 (48.7440) nleep/row_min_mean 1490.5205 (1494.1234) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [120/167] time 0.152 (0.139) data 0.000 (0.003) loss 1.7303 (1.7123) teacher_loss 0.1338 (0.2047) loss_zs_kd 0.0357 (0.0401) loss_oracle 0.9234 (0.8242) kd_loss 1.1169 (1.0754) acc 96.8750 (92.9167) gate/entropy 1.0266 (1.0263) gate/usage_max 0.5006 (0.5009) gate/usage_min 0.1937 (0.1932) gate/usage_std 0.1268 (0.1271) teacher/entropy 0.0375 (0.0318) teacher/usage_max 0.8728 (0.7821) teacher/usage_min 0.0334 (0.0309) teacher/usage_std 0.3823 (0.3255) nleep/row_max_mean 1518.6531 (1535.2399) nleep/row_max_std 66.2778 (49.3990) nleep/row_min_mean 1475.5000 (1493.4396) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [140/167] time 0.166 (0.141) data 0.000 (0.003) loss 1.6510 (1.7089) teacher_loss 0.1385 (0.2002) loss_zs_kd 0.0298 (0.0398) loss_oracle 0.8737 (0.8265) kd_loss 1.0608 (1.0755) acc 93.7500 (93.0357) gate/entropy 1.0264 (1.0263) gate/usage_max 0.5006 (0.5009) gate/usage_min 0.1933 (0.1932) gate/usage_std 0.1269 (0.1271) teacher/entropy 0.0219 (0.0314) teacher/usage_max 0.7935 (0.7834) teacher/usage_min 0.0002 (0.0301) teacher/usage_std 0.3361 (0.3265) nleep/row_max_mean 1531.4393 (1534.7296) nleep/row_max_std 54.3842 (49.3736) nleep/row_min_mean 1486.0962 (1493.1285) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [160/167] time 0.151 (0.143) data 0.000 (0.002) loss 1.7910 (1.6985) teacher_loss 0.2393 (0.1954) loss_zs_kd 0.0543 (0.0402) loss_oracle 0.8370 (0.8233) kd_loss 1.1060 (1.0713) acc 90.6250 (93.3008) gate/entropy 1.0265 (1.0263) gate/usage_max 0.5006 (0.5009) gate/usage_min 0.1934 (0.1932) gate/usage_std 0.1269 (0.1271) teacher/entropy 0.0194 (0.0318) teacher/usage_max 0.8702 (0.7784) teacher/usage_min 0.0053 (0.0289) teacher/usage_std 0.3827 (0.3238) nleep/row_max_mean 1519.8550 (1534.6056) nleep/row_max_std 58.2624 (49.3719) nleep/row_min_mean 1477.7129 (1492.9252) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,297
* correct: 2,206
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 2,344
* correct: 2,321
* accuracy: 99.0%
* error: 1.0%
* macro_f1: 99.1%
******* Domain c best val acc:      96.3%, epoch: 19 *******
******* Domain c best val test acc: 99.0%, epoch: 19 *******
******* Domain c best test acc:     99.4%, epoch: 13 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/c/seed_3/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:23:13

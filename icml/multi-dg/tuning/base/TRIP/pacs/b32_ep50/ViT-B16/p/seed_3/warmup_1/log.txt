Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------------------------
Dataset    SPG_PACS
Source     ['art_painting', 'cartoon', 'sketch']
Target     ['photo']
# classes  7
# train_x  5,823
# val      2,497
# test     1,670
---------  -------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/tensorboard)
epoch [1/50] batch [20/181] time 0.076 (0.152) data 0.000 (0.023) loss 1.0215 (1.1252) teacher_loss 0.4200 (0.5112) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0000 (-0.0000) kd_loss 0.6015 (0.6140) acc 78.1250 (82.1875) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3375) gate/usage_min 0.3299 (0.3299) gate/usage_std 0.0031 (0.0032) teacher/entropy 0.4971 (0.4855) teacher/usage_max 0.3979 (0.3940) teacher/usage_min 0.2949 (0.2732) teacher/usage_std 0.0459 (0.0511) nleep/row_max_mean 1589.9712 (1574.8882) nleep/row_max_std 122.0341 (148.1017) nleep/row_min_mean 1584.1174 (1568.5285) lr 1.0000e-05 eta 0:22:54
epoch [1/50] batch [40/181] time 0.098 (0.139) data 0.000 (0.011) loss 1.0345 (1.0527) teacher_loss 0.6109 (0.4910) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0008 (0.0001) kd_loss 0.4232 (0.5617) acc 78.1250 (82.5781) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3375) gate/usage_min 0.3300 (0.3299) gate/usage_std 0.0031 (0.0032) teacher/entropy 0.6750 (0.5377) teacher/usage_max 0.3651 (0.3939) teacher/usage_min 0.2888 (0.2735) teacher/usage_std 0.0324 (0.0510) nleep/row_max_mean 1536.3638 (1570.0323) nleep/row_max_std 150.3728 (141.0354) nleep/row_min_mean 1532.7537 (1564.6269) lr 1.0000e-05 eta 0:20:52
epoch [1/50] batch [60/181] time 0.082 (0.130) data 0.000 (0.008) loss 1.9679 (1.0371) teacher_loss 1.3483 (0.5111) loss_zs_kd 0.0000 (0.0001) loss_oracle 0.0014 (0.0004) kd_loss 0.6189 (0.5258) acc 56.2500 (82.0312) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3375) gate/usage_min 0.3298 (0.3299) gate/usage_std 0.0032 (0.0032) teacher/entropy 0.4803 (0.5735) teacher/usage_max 0.4392 (0.3968) teacher/usage_min 0.2106 (0.2730) teacher/usage_std 0.0941 (0.0525) nleep/row_max_mean 1602.2687 (1572.4915) nleep/row_max_std 97.4501 (135.8268) nleep/row_min_mean 1597.9019 (1567.7163) lr 1.0000e-05 eta 0:19:31
epoch [1/50] batch [80/181] time 0.086 (0.129) data 0.000 (0.006) loss 0.7835 (0.9897) teacher_loss 0.4253 (0.4954) loss_zs_kd 0.0007 (0.0001) loss_oracle 0.0028 (0.0008) kd_loss 0.3564 (0.4939) acc 84.3750 (82.6172) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3375) gate/usage_min 0.3298 (0.3299) gate/usage_std 0.0032 (0.0031) teacher/entropy 0.7409 (0.6053) teacher/usage_max 0.3744 (0.3950) teacher/usage_min 0.2594 (0.2746) teacher/usage_std 0.0524 (0.0512) nleep/row_max_mean 1567.9390 (1571.9595) nleep/row_max_std 110.0282 (132.0675) nleep/row_min_mean 1565.2959 (1567.6208) lr 1.0000e-05 eta 0:19:13
epoch [1/50] batch [100/181] time 0.084 (0.125) data 0.000 (0.005) loss 0.5128 (0.9480) teacher_loss 0.2843 (0.4931) loss_zs_kd 0.0005 (0.0002) loss_oracle 0.0051 (0.0013) kd_loss 0.2257 (0.4542) acc 90.6250 (82.6250) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3375) gate/usage_min 0.3299 (0.3299) gate/usage_std 0.0031 (0.0031) teacher/entropy 0.8725 (0.6449) teacher/usage_max 0.3557 (0.3915) teacher/usage_min 0.3127 (0.2775) teacher/usage_std 0.0176 (0.0485) nleep/row_max_mean 1575.3389 (1572.4788) nleep/row_max_std 105.0309 (126.5174) nleep/row_min_mean 1573.5673 (1568.5772) lr 1.0000e-05 eta 0:18:40
epoch [1/50] batch [120/181] time 0.138 (0.128) data 0.000 (0.004) loss 0.4362 (0.9249) teacher_loss 0.2114 (0.4995) loss_zs_kd 0.0007 (0.0003) loss_oracle 0.0101 (0.0023) kd_loss 0.2194 (0.4240) acc 90.6250 (82.2656) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3375) gate/usage_min 0.3299 (0.3299) gate/usage_std 0.0031 (0.0031) teacher/entropy 0.8783 (0.6747) teacher/usage_max 0.3790 (0.3951) teacher/usage_min 0.2999 (0.2755) teacher/usage_std 0.0335 (0.0512) nleep/row_max_mean 1577.7104 (1574.6691) nleep/row_max_std 104.0260 (120.8714) nleep/row_min_mean 1576.0935 (1571.0812) lr 1.0000e-05 eta 0:19:04
epoch [1/50] batch [140/181] time 0.143 (0.131) data 0.000 (0.003) loss 0.6581 (0.8980) teacher_loss 0.3995 (0.4932) loss_zs_kd 0.0013 (0.0004) loss_oracle 0.0168 (0.0041) kd_loss 0.2495 (0.4026) acc 87.5000 (82.5223) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3375) gate/usage_min 0.3300 (0.3299) gate/usage_std 0.0031 (0.0031) teacher/entropy 0.8454 (0.6957) teacher/usage_max 0.5156 (0.4086) teacher/usage_min 0.1903 (0.2680) teacher/usage_std 0.1356 (0.0602) nleep/row_max_mean 1547.5366 (1574.2914) nleep/row_max_std 103.3312 (116.8820) nleep/row_min_mean 1545.8267 (1570.9452) lr 1.0000e-05 eta 0:19:23
epoch [1/50] batch [160/181] time 0.146 (0.132) data 0.000 (0.003) loss 0.7511 (0.8800) teacher_loss 0.4210 (0.4866) loss_zs_kd 0.0006 (0.0006) loss_oracle 0.0359 (0.0064) kd_loss 0.3119 (0.3899) acc 84.3750 (82.8711) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3375) gate/usage_min 0.3298 (0.3299) gate/usage_std 0.0031 (0.0031) teacher/entropy 0.7827 (0.7079) teacher/usage_max 0.5348 (0.4247) teacher/usage_min 0.1856 (0.2604) teacher/usage_std 0.1475 (0.0710) nleep/row_max_mean 1579.6692 (1574.6626) nleep/row_max_std 96.0937 (112.6145) nleep/row_min_mean 1577.5449 (1571.4887) lr 1.0000e-05 eta 0:19:37
epoch [1/50] batch [180/181] time 0.126 (0.132) data 0.000 (0.003) loss 0.8696 (0.8769) teacher_loss 0.4325 (0.4815) loss_zs_kd 0.0028 (0.0007) loss_oracle 0.0345 (0.0089) kd_loss 0.4185 (0.3906) acc 87.5000 (83.0035) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3375) gate/usage_min 0.3299 (0.3299) gate/usage_std 0.0031 (0.0031) teacher/entropy 0.6749 (0.7067) teacher/usage_max 0.6093 (0.4457) teacher/usage_min 0.1618 (0.2501) teacher/usage_std 0.1970 (0.0853) nleep/row_max_mean 1597.2417 (1574.8777) nleep/row_max_std 73.5515 (108.9387) nleep/row_min_mean 1594.5293 (1571.7804) lr 1.0000e-05 eta 0:19:30
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,367
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 95.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain p best val acc:      94.8%, epoch: 1 *******
******* Domain p best val test acc: 99.9%, epoch: 1 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [2/50] batch [20/181] time 0.098 (0.107) data 0.000 (0.012) loss 1.0829 (1.0296) teacher_loss 0.4126 (0.4155) loss_zs_kd 0.0050 (0.0061) loss_oracle 0.3658 (0.2677) kd_loss 0.4848 (0.4771) acc 84.3750 (85.7812) gate/entropy 1.0985 (1.0985) gate/usage_max 0.3406 (0.3389) gate/usage_min 0.3280 (0.3290) gate/usage_std 0.0053 (0.0041) teacher/entropy 0.6026 (0.6132) teacher/usage_max 0.6727 (0.6593) teacher/usage_min 0.1346 (0.1477) teacher/usage_std 0.2411 (0.2315) nleep/row_max_mean 1579.7415 (1585.0045) nleep/row_max_std 72.9676 (76.2469) nleep/row_min_mean 1575.3755 (1581.5181) lr 2.0000e-03 eta 0:15:45
epoch [2/50] batch [40/181] time 0.116 (0.115) data 0.000 (0.006) loss 1.5595 (1.1585) teacher_loss 0.6662 (0.4203) loss_zs_kd 0.0166 (0.0080) loss_oracle 0.4563 (0.3612) kd_loss 0.6568 (0.5535) acc 65.6250 (84.9219) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3457 (0.3410) gate/usage_min 0.3251 (0.3278) gate/usage_std 0.0089 (0.0056) teacher/entropy 0.4170 (0.5318) teacher/usage_max 0.7824 (0.7026) teacher/usage_min 0.0852 (0.1251) teacher/usage_std 0.3182 (0.2621) nleep/row_max_mean 1582.9827 (1582.4501) nleep/row_max_std 70.1066 (75.1981) nleep/row_min_mean 1577.3837 (1577.6375) lr 2.0000e-03 eta 0:16:51
epoch [2/50] batch [60/181] time 0.184 (0.114) data 0.001 (0.004) loss 1.5468 (1.2138) teacher_loss 0.4174 (0.4065) loss_zs_kd 0.0054 (0.0090) loss_oracle 0.5862 (0.4051) kd_loss 0.8336 (0.6003) acc 90.6250 (85.9896) gate/entropy 1.0979 (1.0983) gate/usage_max 0.3509 (0.3435) gate/usage_min 0.3220 (0.3264) gate/usage_std 0.0126 (0.0074) teacher/entropy 0.2301 (0.4810) teacher/usage_max 0.7808 (0.7050) teacher/usage_min 0.0625 (0.1163) teacher/usage_std 0.3188 (0.2647) nleep/row_max_mean 1584.8245 (1582.2278) nleep/row_max_std 69.7986 (73.9263) nleep/row_min_mean 1572.9631 (1576.2590) lr 2.0000e-03 eta 0:16:43
epoch [2/50] batch [80/181] time 0.087 (0.114) data 0.000 (0.003) loss 1.6681 (1.2684) teacher_loss 0.4943 (0.4039) loss_zs_kd 0.0106 (0.0094) loss_oracle 0.6497 (0.4465) kd_loss 0.8436 (0.6366) acc 75.0000 (85.9375) gate/entropy 1.0974 (1.0982) gate/usage_max 0.3563 (0.3461) gate/usage_min 0.3182 (0.3248) gate/usage_std 0.0165 (0.0092) teacher/entropy 0.2142 (0.4404) teacher/usage_max 0.7283 (0.7065) teacher/usage_min 0.0707 (0.1074) teacher/usage_std 0.2843 (0.2669) nleep/row_max_mean 1597.0735 (1582.4002) nleep/row_max_std 72.8284 (73.3323) nleep/row_min_mean 1585.0083 (1575.3566) lr 2.0000e-03 eta 0:16:40
epoch [2/50] batch [100/181] time 0.197 (0.113) data 0.000 (0.003) loss 1.4024 (1.3056) teacher_loss 0.3009 (0.3905) loss_zs_kd 0.0085 (0.0097) loss_oracle 0.6510 (0.4824) kd_loss 0.7717 (0.6691) acc 87.5000 (86.6250) gate/entropy 1.0968 (1.0979) gate/usage_max 0.3612 (0.3486) gate/usage_min 0.3147 (0.3231) gate/usage_std 0.0201 (0.0110) teacher/entropy 0.3120 (0.4050) teacher/usage_max 0.4810 (0.6940) teacher/usage_min 0.0992 (0.0991) teacher/usage_std 0.1674 (0.2625) nleep/row_max_mean 1553.5725 (1582.2190) nleep/row_max_std 88.5580 (72.9449) nleep/row_min_mean 1541.7917 (1574.1771) lr 2.0000e-03 eta 0:16:29
epoch [2/50] batch [120/181] time 0.080 (0.111) data 0.000 (0.002) loss 1.5088 (1.3433) teacher_loss 0.2395 (0.3836) loss_zs_kd 0.0159 (0.0107) loss_oracle 0.7340 (0.5109) kd_loss 0.8944 (0.6990) acc 87.5000 (86.7448) gate/entropy 1.0962 (1.0977) gate/usage_max 0.3652 (0.3511) gate/usage_min 0.3105 (0.3213) gate/usage_std 0.0232 (0.0128) teacher/entropy 0.1485 (0.3740) teacher/usage_max 0.7084 (0.6712) teacher/usage_min 0.0252 (0.0905) teacher/usage_std 0.2829 (0.2552) nleep/row_max_mean 1580.1392 (1581.1672) nleep/row_max_std 65.5459 (73.3890) nleep/row_min_mean 1565.2367 (1572.3128) lr 2.0000e-03 eta 0:16:13
epoch [2/50] batch [140/181] time 0.058 (0.111) data 0.000 (0.002) loss 1.5880 (1.3662) teacher_loss 0.3015 (0.3721) loss_zs_kd 0.0070 (0.0112) loss_oracle 0.6848 (0.5314) kd_loss 0.9406 (0.7228) acc 87.5000 (87.0982) gate/entropy 1.0955 (1.0974) gate/usage_max 0.3694 (0.3534) gate/usage_min 0.3066 (0.3195) gate/usage_std 0.0265 (0.0145) teacher/entropy 0.1119 (0.3477) teacher/usage_max 0.5787 (0.6592) teacher/usage_min 0.0336 (0.0832) teacher/usage_std 0.2258 (0.2518) nleep/row_max_mean 1577.0590 (1580.3844) nleep/row_max_std 67.0328 (72.8353) nleep/row_min_mean 1560.3665 (1570.7124) lr 2.0000e-03 eta 0:16:12
epoch [2/50] batch [160/181] time 0.087 (0.111) data 0.000 (0.002) loss 1.5742 (1.3921) teacher_loss 0.3715 (0.3695) loss_zs_kd 0.0225 (0.0125) loss_oracle 0.5995 (0.5395) kd_loss 0.8917 (0.7466) acc 90.6250 (87.3242) gate/entropy 1.0947 (1.0971) gate/usage_max 0.3733 (0.3557) gate/usage_min 0.3025 (0.3176) gate/usage_std 0.0296 (0.0162) teacher/entropy 0.1709 (0.3215) teacher/usage_max 0.5282 (0.6491) teacher/usage_min 0.0139 (0.0751) teacher/usage_std 0.2277 (0.2503) nleep/row_max_mean 1582.4301 (1580.5736) nleep/row_max_std 66.5455 (71.8309) nleep/row_min_mean 1565.3765 (1570.0715) lr 2.0000e-03 eta 0:16:07
epoch [2/50] batch [180/181] time 0.063 (0.111) data 0.000 (0.002) loss 1.8347 (1.4164) teacher_loss 0.4904 (0.3672) loss_zs_kd 0.0392 (0.0137) loss_oracle 0.6691 (0.5471) kd_loss 0.9901 (0.7688) acc 78.1250 (87.3785) gate/entropy 1.0941 (1.0968) gate/usage_max 0.3758 (0.3578) gate/usage_min 0.2986 (0.3157) gate/usage_std 0.0320 (0.0179) teacher/entropy 0.0619 (0.2982) teacher/usage_max 0.5046 (0.6385) teacher/usage_min 0.0241 (0.0683) teacher/usage_std 0.2191 (0.2484) nleep/row_max_mean 1592.1719 (1580.2580) nleep/row_max_std 56.6064 (70.9285) nleep/row_min_mean 1573.5033 (1568.9290) lr 2.0000e-03 eta 0:16:02
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,377
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.2%, epoch: 2 *******
******* Domain p best val test acc: 99.9%, epoch: 2 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [3/50] batch [20/181] time 0.143 (0.149) data 0.000 (0.012) loss 1.4550 (1.5216) teacher_loss 0.2574 (0.2621) loss_zs_kd 0.0188 (0.0170) loss_oracle 0.5727 (0.6115) kd_loss 0.9019 (0.9452) acc 90.6250 (90.1562) gate/entropy 1.0933 (1.0936) gate/usage_max 0.3785 (0.3773) gate/usage_min 0.2948 (0.2965) gate/usage_std 0.0345 (0.0334) teacher/entropy 0.1523 (0.1128) teacher/usage_max 0.5249 (0.5602) teacher/usage_min 0.0227 (0.0251) teacher/usage_std 0.2217 (0.2295) nleep/row_max_mean 1577.2947 (1577.0142) nleep/row_max_std 51.6369 (63.0706) nleep/row_min_mean 1559.1290 (1559.3394) lr 1.9980e-03 eta 0:21:34
epoch [3/50] batch [40/181] time 0.141 (0.146) data 0.000 (0.006) loss 1.5215 (1.5516) teacher_loss 0.3278 (0.2855) loss_zs_kd 0.0348 (0.0205) loss_oracle 0.5675 (0.6122) kd_loss 0.8925 (0.9498) acc 93.7500 (89.8438) gate/entropy 1.0925 (1.0933) gate/usage_max 0.3810 (0.3786) gate/usage_min 0.2908 (0.2946) gate/usage_std 0.0370 (0.0346) teacher/entropy 0.1568 (0.1061) teacher/usage_max 0.5077 (0.5658) teacher/usage_min 0.0323 (0.0204) teacher/usage_std 0.2137 (0.2334) nleep/row_max_mean 1592.9254 (1578.6288) nleep/row_max_std 59.3600 (60.9154) nleep/row_min_mean 1573.1306 (1559.9573) lr 1.9980e-03 eta 0:21:04
epoch [3/50] batch [60/181] time 0.139 (0.146) data 0.000 (0.004) loss 1.6333 (1.5536) teacher_loss 0.3362 (0.2856) loss_zs_kd 0.0237 (0.0214) loss_oracle 0.6020 (0.6137) kd_loss 0.9842 (0.9504) acc 84.3750 (89.4792) gate/entropy 1.0917 (1.0929) gate/usage_max 0.3832 (0.3797) gate/usage_min 0.2875 (0.2928) gate/usage_std 0.0392 (0.0358) teacher/entropy 0.0776 (0.1024) teacher/usage_max 0.6028 (0.5642) teacher/usage_min 0.0407 (0.0226) teacher/usage_std 0.2301 (0.2319) nleep/row_max_mean 1572.7225 (1579.8654) nleep/row_max_std 64.0582 (61.4433) nleep/row_min_mean 1553.2803 (1560.7046) lr 1.9980e-03 eta 0:20:57
epoch [3/50] batch [80/181] time 0.145 (0.146) data 0.000 (0.003) loss 1.3382 (1.5281) teacher_loss 0.1729 (0.2782) loss_zs_kd 0.0174 (0.0221) loss_oracle 0.5324 (0.5936) kd_loss 0.8904 (0.9420) acc 93.7500 (90.0000) gate/entropy 1.0910 (1.0925) gate/usage_max 0.3848 (0.3808) gate/usage_min 0.2843 (0.2910) gate/usage_std 0.0411 (0.0369) teacher/entropy 0.1775 (0.1105) teacher/usage_max 0.6074 (0.5594) teacher/usage_min 0.0718 (0.0297) teacher/usage_std 0.2188 (0.2267) nleep/row_max_mean 1566.0771 (1578.6320) nleep/row_max_std 66.6274 (61.6241) nleep/row_min_mean 1547.9919 (1559.6157) lr 1.9980e-03 eta 0:21:00
epoch [3/50] batch [100/181] time 0.132 (0.146) data 0.000 (0.003) loss 1.3101 (1.5264) teacher_loss 0.1398 (0.2835) loss_zs_kd 0.0149 (0.0225) loss_oracle 0.5801 (0.5892) kd_loss 0.8728 (0.9370) acc 93.7500 (89.6875) gate/entropy 1.0903 (1.0921) gate/usage_max 0.3862 (0.3818) gate/usage_min 0.2810 (0.2893) gate/usage_std 0.0430 (0.0379) teacher/entropy 0.1538 (0.1152) teacher/usage_max 0.5537 (0.5550) teacher/usage_min 0.0552 (0.0358) teacher/usage_std 0.2075 (0.2226) nleep/row_max_mean 1577.8239 (1578.3665) nleep/row_max_std 59.7441 (61.9705) nleep/row_min_mean 1561.6160 (1559.3933) lr 1.9980e-03 eta 0:20:51
epoch [3/50] batch [120/181] time 0.168 (0.147) data 0.000 (0.002) loss 1.3875 (1.5295) teacher_loss 0.1894 (0.2918) loss_zs_kd 0.0286 (0.0232) loss_oracle 0.4918 (0.5820) kd_loss 0.9379 (0.9351) acc 93.7500 (89.3229) gate/entropy 1.0895 (1.0917) gate/usage_max 0.3876 (0.3827) gate/usage_min 0.2779 (0.2876) gate/usage_std 0.0448 (0.0389) teacher/entropy 0.1234 (0.1165) teacher/usage_max 0.7156 (0.5544) teacher/usage_min 0.0259 (0.0410) teacher/usage_std 0.2865 (0.2195) nleep/row_max_mean 1579.4365 (1577.3253) nleep/row_max_std 59.5655 (61.7719) nleep/row_min_mean 1561.9471 (1558.2161) lr 1.9980e-03 eta 0:21:01
epoch [3/50] batch [140/181] time 0.085 (0.139) data 0.000 (0.002) loss 1.7475 (1.5181) teacher_loss 0.5472 (0.2860) loss_zs_kd 0.0456 (0.0232) loss_oracle 0.5522 (0.5747) kd_loss 0.9014 (0.9331) acc 87.5000 (89.6429) gate/entropy 1.0889 (1.0914) gate/usage_max 0.3885 (0.3834) gate/usage_min 0.2752 (0.2861) gate/usage_std 0.0463 (0.0399) teacher/entropy 0.1339 (0.1185) teacher/usage_max 0.5763 (0.5596) teacher/usage_min 0.0197 (0.0443) teacher/usage_std 0.2326 (0.2201) nleep/row_max_mean 1562.6909 (1576.5292) nleep/row_max_std 42.0936 (61.2049) nleep/row_min_mean 1544.3867 (1557.3803) lr 1.9980e-03 eta 0:19:49
epoch [3/50] batch [160/181] time 0.086 (0.137) data 0.000 (0.002) loss 1.3715 (1.5049) teacher_loss 0.2229 (0.2796) loss_zs_kd 0.0290 (0.0231) loss_oracle 0.5157 (0.5681) kd_loss 0.8763 (0.9297) acc 93.7500 (89.9414) gate/entropy 1.0882 (1.0910) gate/usage_max 0.3891 (0.3841) gate/usage_min 0.2726 (0.2845) gate/usage_std 0.0477 (0.0408) teacher/entropy 0.1928 (0.1223) teacher/usage_max 0.6365 (0.5606) teacher/usage_min 0.1038 (0.0498) teacher/usage_std 0.2237 (0.2178) nleep/row_max_mean 1559.8149 (1575.5424) nleep/row_max_std 64.3319 (60.9215) nleep/row_min_mean 1540.9073 (1556.4709) lr 1.9980e-03 eta 0:19:26
epoch [3/50] batch [180/181] time 0.071 (0.134) data 0.000 (0.002) loss 1.5132 (1.5000) teacher_loss 0.2973 (0.2795) loss_zs_kd 0.0218 (0.0237) loss_oracle 0.5019 (0.5650) kd_loss 0.9540 (0.9262) acc 87.5000 (89.8958) gate/entropy 1.0877 (1.0907) gate/usage_max 0.3891 (0.3847) gate/usage_min 0.2702 (0.2830) gate/usage_std 0.0488 (0.0416) teacher/entropy 0.1201 (0.1266) teacher/usage_max 0.5911 (0.5645) teacher/usage_min 0.1449 (0.0550) teacher/usage_std 0.1887 (0.2169) nleep/row_max_mean 1576.2144 (1574.8584) nleep/row_max_std 69.3636 (60.5480) nleep/row_min_mean 1554.4785 (1555.7325) lr 1.9980e-03 eta 0:18:59
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,394
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      95.9%, epoch: 3 *******
******* Domain p best val test acc: 99.9%, epoch: 3 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [4/50] batch [20/181] time 0.092 (0.130) data 0.000 (0.014) loss 1.6694 (1.4829) teacher_loss 0.4408 (0.2496) loss_zs_kd 0.0423 (0.0336) loss_oracle 0.4687 (0.5490) kd_loss 0.9730 (0.9420) acc 87.5000 (90.0000) gate/entropy 1.0871 (1.0874) gate/usage_max 0.3896 (0.3894) gate/usage_min 0.2681 (0.2689) gate/usage_std 0.0500 (0.0495) teacher/entropy 0.1086 (0.1375) teacher/usage_max 0.6007 (0.5612) teacher/usage_min 0.1660 (0.1623) teacher/usage_std 0.1910 (0.1707) nleep/row_max_mean 1584.6560 (1572.8286) nleep/row_max_std 50.7217 (53.9896) nleep/row_min_mean 1563.1169 (1552.0215) lr 1.9921e-03 eta 0:18:22
epoch [4/50] batch [40/181] time 0.165 (0.121) data 0.000 (0.007) loss 1.5471 (1.5093) teacher_loss 0.2068 (0.2590) loss_zs_kd 0.0485 (0.0350) loss_oracle 0.6209 (0.5493) kd_loss 1.0056 (0.9581) acc 93.7500 (89.9219) gate/entropy 1.0870 (1.0872) gate/usage_max 0.3888 (0.3893) gate/usage_min 0.2672 (0.2683) gate/usage_std 0.0502 (0.0498) teacher/entropy 0.0806 (0.1262) teacher/usage_max 0.6035 (0.5419) teacher/usage_min 0.1820 (0.1727) teacher/usage_std 0.1915 (0.1586) nleep/row_max_mean 1577.3873 (1573.2836) nleep/row_max_std 59.5912 (54.5774) nleep/row_min_mean 1550.5187 (1551.9619) lr 1.9921e-03 eta 0:17:03
epoch [4/50] batch [60/181] time 0.109 (0.118) data 0.001 (0.005) loss 1.5942 (1.5288) teacher_loss 0.2480 (0.2596) loss_zs_kd 0.0323 (0.0336) loss_oracle 0.6008 (0.5538) kd_loss 1.0296 (0.9755) acc 90.6250 (90.1562) gate/entropy 1.0868 (1.0871) gate/usage_max 0.3880 (0.3889) gate/usage_min 0.2660 (0.2678) gate/usage_std 0.0506 (0.0500) teacher/entropy 0.0541 (0.1149) teacher/usage_max 0.5650 (0.5486) teacher/usage_min 0.1924 (0.1760) teacher/usage_std 0.1651 (0.1613) nleep/row_max_mean 1577.3491 (1573.4217) nleep/row_max_std 55.5013 (55.1755) nleep/row_min_mean 1556.4646 (1551.3504) lr 1.9921e-03 eta 0:16:33
epoch [4/50] batch [80/181] time 0.095 (0.119) data 0.000 (0.004) loss 1.4888 (1.5295) teacher_loss 0.1261 (0.2495) loss_zs_kd 0.0198 (0.0318) loss_oracle 0.6385 (0.5581) kd_loss 1.0336 (0.9851) acc 96.8750 (90.7812) gate/entropy 1.0867 (1.0871) gate/usage_max 0.3869 (0.3885) gate/usage_min 0.2653 (0.2673) gate/usage_std 0.0507 (0.0501) teacher/entropy 0.0990 (0.1091) teacher/usage_max 0.5106 (0.5546) teacher/usage_min 0.1462 (0.1724) teacher/usage_std 0.1489 (0.1655) nleep/row_max_mean 1572.5612 (1572.2093) nleep/row_max_std 51.4877 (54.3651) nleep/row_min_mean 1551.0524 (1549.8926) lr 1.9921e-03 eta 0:16:44
epoch [4/50] batch [100/181] time 0.095 (0.118) data 0.000 (0.003) loss 1.4306 (1.5384) teacher_loss 0.1141 (0.2472) loss_zs_kd 0.0255 (0.0322) loss_oracle 0.5294 (0.5678) kd_loss 1.0391 (0.9912) acc 100.0000 (90.9062) gate/entropy 1.0865 (1.0870) gate/usage_max 0.3861 (0.3882) gate/usage_min 0.2643 (0.2667) gate/usage_std 0.0511 (0.0503) teacher/entropy 0.0940 (0.1038) teacher/usage_max 0.6036 (0.5575) teacher/usage_min 0.0718 (0.1705) teacher/usage_std 0.2172 (0.1672) nleep/row_max_mean 1564.3140 (1571.8664) nleep/row_max_std 58.4114 (54.7740) nleep/row_min_mean 1543.0706 (1549.4898) lr 1.9921e-03 eta 0:16:36
epoch [4/50] batch [120/181] time 0.144 (0.124) data 0.000 (0.003) loss 1.7654 (1.5434) teacher_loss 0.4674 (0.2493) loss_zs_kd 0.0321 (0.0326) loss_oracle 0.5700 (0.5694) kd_loss 0.9968 (0.9932) acc 81.2500 (90.7031) gate/entropy 1.0863 (1.0869) gate/usage_max 0.3850 (0.3877) gate/usage_min 0.2630 (0.2662) gate/usage_std 0.0515 (0.0505) teacher/entropy 0.0866 (0.1025) teacher/usage_max 0.5891 (0.5628) teacher/usage_min 0.2018 (0.1690) teacher/usage_std 0.1809 (0.1707) nleep/row_max_mean 1574.5194 (1570.2628) nleep/row_max_std 45.6579 (55.3137) nleep/row_min_mean 1550.1658 (1547.8438) lr 1.9921e-03 eta 0:17:18
epoch [4/50] batch [140/181] time 0.152 (0.127) data 0.000 (0.002) loss 1.7796 (1.5499) teacher_loss 0.4581 (0.2544) loss_zs_kd 0.0371 (0.0325) loss_oracle 0.5345 (0.5672) kd_loss 1.0358 (0.9957) acc 81.2500 (90.4464) gate/entropy 1.0863 (1.0868) gate/usage_max 0.3833 (0.3872) gate/usage_min 0.2624 (0.2657) gate/usage_std 0.0515 (0.0506) teacher/entropy 0.0300 (0.1011) teacher/usage_max 0.7472 (0.5661) teacher/usage_min 0.1245 (0.1662) teacher/usage_std 0.2927 (0.1736) nleep/row_max_mean 1582.0166 (1569.5794) nleep/row_max_std 57.8180 (55.2509) nleep/row_min_mean 1556.4301 (1546.9704) lr 1.9921e-03 eta 0:17:46
epoch [4/50] batch [160/181] time 0.156 (0.130) data 0.000 (0.002) loss 1.5872 (1.5530) teacher_loss 0.2434 (0.2554) loss_zs_kd 0.0350 (0.0325) loss_oracle 0.5712 (0.5639) kd_loss 1.0408 (0.9994) acc 90.6250 (90.3125) gate/entropy 1.0862 (1.0867) gate/usage_max 0.3808 (0.3865) gate/usage_min 0.2616 (0.2653) gate/usage_std 0.0516 (0.0507) teacher/entropy 0.0675 (0.0974) teacher/usage_max 0.6599 (0.5780) teacher/usage_min 0.0682 (0.1580) teacher/usage_std 0.2454 (0.1822) nleep/row_max_mean 1541.6741 (1568.8694) nleep/row_max_std 63.2811 (55.7998) nleep/row_min_mean 1519.6147 (1546.0515) lr 1.9921e-03 eta 0:18:05
epoch [4/50] batch [180/181] time 0.149 (0.132) data 0.000 (0.002) loss 1.4590 (1.5609) teacher_loss 0.2003 (0.2650) loss_zs_kd 0.0188 (0.0322) loss_oracle 0.4606 (0.5581) kd_loss 1.0190 (1.0007) acc 93.7500 (89.9479) gate/entropy 1.0858 (1.0866) gate/usage_max 0.3788 (0.3858) gate/usage_min 0.2602 (0.2648) gate/usage_std 0.0522 (0.0508) teacher/entropy 0.0661 (0.0958) teacher/usage_max 0.7230 (0.5872) teacher/usage_min 0.0630 (0.1510) teacher/usage_std 0.2824 (0.1891) nleep/row_max_mean 1569.9282 (1568.1924) nleep/row_max_std 58.0846 (56.2244) nleep/row_min_mean 1544.6727 (1545.2781) lr 1.9921e-03 eta 0:18:18
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,405
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.3%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [5/50] batch [20/181] time 0.086 (0.102) data 0.000 (0.014) loss 1.6924 (1.5717) teacher_loss 0.4324 (0.2951) loss_zs_kd 0.0157 (0.0258) loss_oracle 0.4600 (0.5085) kd_loss 1.0222 (1.0095) acc 84.3750 (88.7500) gate/entropy 1.0858 (1.0858) gate/usage_max 0.3756 (0.3771) gate/usage_min 0.2596 (0.2599) gate/usage_std 0.0523 (0.0523) teacher/entropy 0.0565 (0.0783) teacher/usage_max 0.7743 (0.6738) teacher/usage_min 0.0146 (0.0859) teacher/usage_std 0.3220 (0.2520) nleep/row_max_mean 1570.3164 (1566.8318) nleep/row_max_std 58.2912 (57.9931) nleep/row_min_mean 1542.6091 (1542.8683) lr 1.9823e-03 eta 0:14:05
epoch [5/50] batch [40/181] time 0.070 (0.105) data 0.001 (0.007) loss 1.6811 (1.5836) teacher_loss 0.3627 (0.3049) loss_zs_kd 0.0582 (0.0260) loss_oracle 0.5872 (0.5185) kd_loss 0.9957 (1.0065) acc 90.6250 (89.0625) gate/entropy 1.0856 (1.0857) gate/usage_max 0.3727 (0.3756) gate/usage_min 0.2590 (0.2595) gate/usage_std 0.0526 (0.0524) teacher/entropy 0.0757 (0.0800) teacher/usage_max 0.6394 (0.6730) teacher/usage_min 0.1457 (0.0845) teacher/usage_std 0.2183 (0.2518) nleep/row_max_mean 1562.8867 (1564.4877) nleep/row_max_std 55.4433 (59.9047) nleep/row_min_mean 1540.6312 (1540.6452) lr 1.9823e-03 eta 0:14:29
epoch [5/50] batch [60/181] time 0.097 (0.107) data 0.001 (0.005) loss 1.6712 (1.5847) teacher_loss 0.4123 (0.3124) loss_zs_kd 0.0348 (0.0274) loss_oracle 0.4698 (0.5142) kd_loss 1.0066 (1.0014) acc 90.6250 (88.6458) gate/entropy 1.0853 (1.0856) gate/usage_max 0.3722 (0.3743) gate/usage_min 0.2581 (0.2592) gate/usage_std 0.0532 (0.0526) teacher/entropy 0.0736 (0.0792) teacher/usage_max 0.5929 (0.6816) teacher/usage_min 0.1556 (0.0834) teacher/usage_std 0.1877 (0.2574) nleep/row_max_mean 1551.3677 (1565.0755) nleep/row_max_std 58.2953 (59.6672) nleep/row_min_mean 1524.2709 (1541.0235) lr 1.9823e-03 eta 0:14:46
epoch [5/50] batch [80/181] time 0.094 (0.108) data 0.000 (0.004) loss 1.5564 (1.5836) teacher_loss 0.3111 (0.3057) loss_zs_kd 0.0209 (0.0295) loss_oracle 0.5305 (0.5237) kd_loss 0.9696 (1.0012) acc 84.3750 (88.9844) gate/entropy 1.0847 (1.0855) gate/usage_max 0.3762 (0.3743) gate/usage_min 0.2566 (0.2587) gate/usage_std 0.0544 (0.0529) teacher/entropy 0.0425 (0.0732) teacher/usage_max 0.8509 (0.6910) teacher/usage_min 0.0607 (0.0816) teacher/usage_std 0.3662 (0.2632) nleep/row_max_mean 1580.4836 (1565.2838) nleep/row_max_std 53.6593 (58.7360) nleep/row_min_mean 1554.1188 (1541.1226) lr 1.9823e-03 eta 0:14:53
epoch [5/50] batch [100/181] time 0.225 (0.112) data 0.000 (0.003) loss 1.6131 (1.5791) teacher_loss 0.3115 (0.3076) loss_zs_kd 0.0310 (0.0283) loss_oracle 0.6058 (0.5211) kd_loss 0.9833 (0.9968) acc 90.6250 (88.7500) gate/entropy 1.0842 (1.0853) gate/usage_max 0.3802 (0.3751) gate/usage_min 0.2556 (0.2582) gate/usage_std 0.0553 (0.0533) teacher/entropy 0.1132 (0.0741) teacher/usage_max 0.5812 (0.6980) teacher/usage_min 0.0997 (0.0775) teacher/usage_std 0.1968 (0.2681) nleep/row_max_mean 1545.5549 (1563.1110) nleep/row_max_std 66.1631 (59.4386) nleep/row_min_mean 1523.8152 (1539.2107) lr 1.9823e-03 eta 0:15:20
epoch [5/50] batch [120/181] time 0.086 (0.113) data 0.000 (0.003) loss 1.5239 (1.5764) teacher_loss 0.3368 (0.3037) loss_zs_kd 0.0310 (0.0283) loss_oracle 0.4667 (0.5271) kd_loss 0.9382 (0.9949) acc 84.3750 (88.7760) gate/entropy 1.0838 (1.0851) gate/usage_max 0.3838 (0.3762) gate/usage_min 0.2550 (0.2577) gate/usage_std 0.0561 (0.0537) teacher/entropy 0.0683 (0.0719) teacher/usage_max 0.7744 (0.7025) teacher/usage_min 0.1038 (0.0760) teacher/usage_std 0.3119 (0.2712) nleep/row_max_mean 1555.2114 (1562.1919) nleep/row_max_std 68.9173 (59.5107) nleep/row_min_mean 1530.8245 (1538.3524) lr 1.9823e-03 eta 0:15:29
epoch [5/50] batch [140/181] time 0.175 (0.114) data 0.000 (0.002) loss 1.8396 (1.5815) teacher_loss 0.6204 (0.3145) loss_zs_kd 0.0513 (0.0281) loss_oracle 0.5308 (0.5253) kd_loss 0.9281 (0.9904) acc 78.1250 (88.4598) gate/entropy 1.0826 (1.0848) gate/usage_max 0.3892 (0.3777) gate/usage_min 0.2528 (0.2572) gate/usage_std 0.0584 (0.0542) teacher/entropy 0.0848 (0.0701) teacher/usage_max 0.7577 (0.7124) teacher/usage_min 0.1007 (0.0743) teacher/usage_std 0.3005 (0.2772) nleep/row_max_mean 1563.2712 (1561.7204) nleep/row_max_std 56.8064 (59.4937) nleep/row_min_mean 1539.4050 (1537.7898) lr 1.9823e-03 eta 0:15:34
epoch [5/50] batch [160/181] time 0.180 (0.116) data 0.000 (0.002) loss 1.4343 (1.5742) teacher_loss 0.3182 (0.3157) loss_zs_kd 0.0385 (0.0283) loss_oracle 0.4715 (0.5236) kd_loss 0.8611 (0.9826) acc 87.5000 (88.3594) gate/entropy 1.0819 (1.0845) gate/usage_max 0.3936 (0.3794) gate/usage_min 0.2517 (0.2566) gate/usage_std 0.0599 (0.0548) teacher/entropy 0.1311 (0.0725) teacher/usage_max 0.7965 (0.7190) teacher/usage_min 0.0886 (0.0731) teacher/usage_std 0.3277 (0.2814) nleep/row_max_mean 1550.6245 (1561.0652) nleep/row_max_std 73.9962 (59.8230) nleep/row_min_mean 1527.6069 (1537.2595) lr 1.9823e-03 eta 0:15:43
epoch [5/50] batch [180/181] time 0.143 (0.114) data 0.000 (0.002) loss 1.4165 (1.5719) teacher_loss 0.2836 (0.3216) loss_zs_kd 0.0256 (0.0285) loss_oracle 0.4113 (0.5182) kd_loss 0.9144 (0.9769) acc 87.5000 (88.1076) gate/entropy 1.0804 (1.0841) gate/usage_max 0.3992 (0.3813) gate/usage_min 0.2494 (0.2559) gate/usage_std 0.0625 (0.0555) teacher/entropy 0.0710 (0.0717) teacher/usage_max 0.7929 (0.7278) teacher/usage_min 0.0876 (0.0708) teacher/usage_std 0.3252 (0.2872) nleep/row_max_mean 1570.5168 (1560.7470) nleep/row_max_std 53.4585 (59.9924) nleep/row_min_mean 1547.2672 (1536.8899) lr 1.9823e-03 eta 0:15:30
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,393
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.3%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [6/50] batch [20/181] time 0.157 (0.170) data 0.000 (0.016) loss 1.4165 (1.5380) teacher_loss 0.2926 (0.3717) loss_zs_kd 0.0136 (0.0215) loss_oracle 0.4312 (0.4785) kd_loss 0.9016 (0.9163) acc 90.6250 (86.7188) gate/entropy 1.0792 (1.0798) gate/usage_max 0.4045 (0.4020) gate/usage_min 0.2480 (0.2487) gate/usage_std 0.0647 (0.0636) teacher/entropy 0.0657 (0.0670) teacher/usage_max 0.8584 (0.8106) teacher/usage_min 0.0195 (0.0503) teacher/usage_std 0.3737 (0.3401) nleep/row_max_mean 1557.1366 (1557.2162) nleep/row_max_std 58.1459 (60.0655) nleep/row_min_mean 1533.1033 (1532.9176) lr 1.9686e-03 eta 0:23:00
epoch [6/50] batch [40/181] time 0.154 (0.164) data 0.000 (0.008) loss 1.5290 (1.5267) teacher_loss 0.3144 (0.3703) loss_zs_kd 0.0145 (0.0204) loss_oracle 0.5120 (0.4739) kd_loss 0.9513 (0.9092) acc 90.6250 (86.0156) gate/entropy 1.0777 (1.0791) gate/usage_max 0.4105 (0.4048) gate/usage_min 0.2464 (0.2479) gate/usage_std 0.0673 (0.0648) teacher/entropy 0.0072 (0.0668) teacher/usage_max 0.8447 (0.8253) teacher/usage_min 0.0311 (0.0375) teacher/usage_std 0.3636 (0.3509) nleep/row_max_mean 1555.4493 (1554.1488) nleep/row_max_std 59.7601 (61.5535) nleep/row_min_mean 1530.1630 (1530.2666) lr 1.9686e-03 eta 0:22:06
epoch [6/50] batch [60/181] time 0.170 (0.160) data 0.000 (0.006) loss 1.6630 (1.5231) teacher_loss 0.4976 (0.3665) loss_zs_kd 0.0122 (0.0195) loss_oracle 0.4641 (0.4801) kd_loss 0.9273 (0.9068) acc 81.2500 (86.1458) gate/entropy 1.0760 (1.0783) gate/usage_max 0.4165 (0.4078) gate/usage_min 0.2449 (0.2471) gate/usage_std 0.0702 (0.0662) teacher/entropy 0.0447 (0.0644) teacher/usage_max 0.8012 (0.8283) teacher/usage_min 0.0269 (0.0314) teacher/usage_std 0.3361 (0.3540) nleep/row_max_mean 1552.0767 (1553.2389) nleep/row_max_std 57.1160 (60.6357) nleep/row_min_mean 1531.1760 (1529.5604) lr 1.9686e-03 eta 0:21:35
epoch [6/50] batch [80/181] time 0.155 (0.158) data 0.000 (0.004) loss 1.5222 (1.5077) teacher_loss 0.4436 (0.3515) loss_zs_kd 0.0271 (0.0189) loss_oracle 0.4629 (0.4876) kd_loss 0.8336 (0.9029) acc 84.3750 (86.8359) gate/entropy 1.0744 (1.0776) gate/usage_max 0.4222 (0.4107) gate/usage_min 0.2437 (0.2464) gate/usage_std 0.0729 (0.0675) teacher/entropy 0.1033 (0.0630) teacher/usage_max 0.8520 (0.8295) teacher/usage_min 0.0187 (0.0299) teacher/usage_std 0.3695 (0.3548) nleep/row_max_mean 1550.6488 (1553.1982) nleep/row_max_std 49.2871 (60.5879) nleep/row_min_mean 1526.5194 (1529.7144) lr 1.9686e-03 eta 0:21:16
epoch [6/50] batch [100/181] time 0.152 (0.158) data 0.000 (0.003) loss 1.2998 (1.5033) teacher_loss 0.2636 (0.3488) loss_zs_kd 0.0117 (0.0189) loss_oracle 0.4492 (0.4935) kd_loss 0.8057 (0.8984) acc 87.5000 (87.0312) gate/entropy 1.0729 (1.0767) gate/usage_max 0.4271 (0.4136) gate/usage_min 0.2427 (0.2457) gate/usage_std 0.0753 (0.0689) teacher/entropy 0.1154 (0.0660) teacher/usage_max 0.8437 (0.8224) teacher/usage_min 0.0579 (0.0316) teacher/usage_std 0.3613 (0.3501) nleep/row_max_mean 1542.6138 (1552.7533) nleep/row_max_std 66.0649 (59.7737) nleep/row_min_mean 1522.4913 (1529.6330) lr 1.9686e-03 eta 0:21:08
epoch [6/50] batch [120/181] time 0.133 (0.146) data 0.001 (0.003) loss 1.6063 (1.4983) teacher_loss 0.5190 (0.3470) loss_zs_kd 0.0221 (0.0183) loss_oracle 0.4483 (0.4937) kd_loss 0.8521 (0.8953) acc 84.3750 (87.1354) gate/entropy 1.0713 (1.0760) gate/usage_max 0.4322 (0.4163) gate/usage_min 0.2420 (0.2452) gate/usage_std 0.0778 (0.0702) teacher/entropy 0.1226 (0.0715) teacher/usage_max 0.7635 (0.8093) teacher/usage_min 0.0006 (0.0322) teacher/usage_std 0.3190 (0.3421) nleep/row_max_mean 1546.7319 (1551.4542) nleep/row_max_std 63.7398 (59.6040) nleep/row_min_mean 1524.7546 (1528.6440) lr 1.9686e-03 eta 0:19:34
epoch [6/50] batch [140/181] time 0.134 (0.147) data 0.000 (0.003) loss 1.5173 (1.4956) teacher_loss 0.3689 (0.3445) loss_zs_kd 0.0270 (0.0185) loss_oracle 0.4848 (0.4978) kd_loss 0.8924 (0.8930) acc 90.6250 (87.2991) gate/entropy 1.0697 (1.0752) gate/usage_max 0.4373 (0.4189) gate/usage_min 0.2415 (0.2447) gate/usage_std 0.0804 (0.0714) teacher/entropy 0.0529 (0.0732) teacher/usage_max 0.7801 (0.8023) teacher/usage_min 0.0400 (0.0325) teacher/usage_std 0.3210 (0.3378) nleep/row_max_mean 1550.8906 (1551.3329) nleep/row_max_std 64.4961 (59.2695) nleep/row_min_mean 1528.7908 (1528.5298) lr 1.9686e-03 eta 0:19:34
epoch [6/50] batch [160/181] time 0.171 (0.143) data 0.000 (0.002) loss 1.4563 (1.4924) teacher_loss 0.2374 (0.3426) loss_zs_kd 0.0094 (0.0182) loss_oracle 0.5565 (0.4986) kd_loss 0.9360 (0.8914) acc 90.6250 (87.4219) gate/entropy 1.0684 (1.0744) gate/usage_max 0.4414 (0.4215) gate/usage_min 0.2418 (0.2443) gate/usage_std 0.0823 (0.0727) teacher/entropy 0.0771 (0.0760) teacher/usage_max 0.6698 (0.7926) teacher/usage_min 0.0046 (0.0325) teacher/usage_std 0.2716 (0.3324) nleep/row_max_mean 1535.0028 (1550.2072) nleep/row_max_std 61.1465 (59.2075) nleep/row_min_mean 1513.3435 (1527.5134) lr 1.9686e-03 eta 0:19:01
epoch [6/50] batch [180/181] time 0.080 (0.137) data 0.000 (0.002) loss 1.5240 (1.4884) teacher_loss 0.3303 (0.3370) loss_zs_kd 0.0110 (0.0179) loss_oracle 0.5494 (0.5031) kd_loss 0.9135 (0.8909) acc 84.3750 (87.7604) gate/entropy 1.0662 (1.0736) gate/usage_max 0.4471 (0.4240) gate/usage_min 0.2411 (0.2440) gate/usage_std 0.0855 (0.0739) teacher/entropy 0.0607 (0.0775) teacher/usage_max 0.7232 (0.7845) teacher/usage_min 0.0002 (0.0306) teacher/usage_std 0.2978 (0.3283) nleep/row_max_mean 1553.6459 (1549.1636) nleep/row_max_std 52.2460 (59.5662) nleep/row_min_mean 1528.7285 (1526.4735) lr 1.9686e-03 eta 0:18:10
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,395
* accuracy: 95.9%
* error: 4.1%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.3%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [7/50] batch [20/181] time 0.150 (0.131) data 0.000 (0.014) loss 1.2578 (1.4661) teacher_loss 0.2113 (0.3409) loss_zs_kd 0.0269 (0.0180) loss_oracle 0.4995 (0.5224) kd_loss 0.7833 (0.8550) acc 93.7500 (87.5000) gate/entropy 1.0645 (1.0654) gate/usage_max 0.4520 (0.4497) gate/usage_min 0.2416 (0.2414) gate/usage_std 0.0880 (0.0868) teacher/entropy 0.1344 (0.0779) teacher/usage_max 0.8003 (0.7811) teacher/usage_min 0.0032 (0.0043) teacher/usage_std 0.3395 (0.3309) nleep/row_max_mean 1529.9053 (1544.2847) nleep/row_max_std 70.7439 (57.9594) nleep/row_min_mean 1507.1917 (1518.1174) lr 1.9511e-03 eta 0:17:19
epoch [7/50] batch [40/181] time 0.171 (0.118) data 0.000 (0.007) loss 1.3966 (1.4485) teacher_loss 0.2060 (0.3171) loss_zs_kd 0.0216 (0.0180) loss_oracle 0.5400 (0.5428) kd_loss 0.9098 (0.8510) acc 93.7500 (88.3594) gate/entropy 1.0619 (1.0642) gate/usage_max 0.4583 (0.4526) gate/usage_min 0.2410 (0.2413) gate/usage_std 0.0917 (0.0884) teacher/entropy 0.1450 (0.0739) teacher/usage_max 0.5715 (0.7861) teacher/usage_min 0.0008 (0.0053) teacher/usage_std 0.2424 (0.3343) nleep/row_max_mean 1531.7158 (1543.8423) nleep/row_max_std 51.6811 (57.7207) nleep/row_min_mean 1505.6628 (1517.1693) lr 1.9511e-03 eta 0:15:37
epoch [7/50] batch [60/181] time 0.071 (0.121) data 0.001 (0.005) loss 1.5664 (1.4770) teacher_loss 0.2839 (0.3393) loss_zs_kd 0.0165 (0.0174) loss_oracle 0.6440 (0.5571) kd_loss 0.9523 (0.8505) acc 90.6250 (87.3438) gate/entropy 1.0593 (1.0629) gate/usage_max 0.4640 (0.4556) gate/usage_min 0.2407 (0.2411) gate/usage_std 0.0951 (0.0902) teacher/entropy 0.0418 (0.0677) teacher/usage_max 0.6540 (0.7890) teacher/usage_min 0.0000 (0.0047) teacher/usage_std 0.2671 (0.3356) nleep/row_max_mean 1525.9077 (1543.5231) nleep/row_max_std 57.6100 (57.6962) nleep/row_min_mean 1497.6382 (1516.0360) lr 1.9511e-03 eta 0:15:59
epoch [7/50] batch [80/181] time 0.162 (0.118) data 0.000 (0.004) loss 1.6910 (1.4626) teacher_loss 0.4581 (0.3381) loss_zs_kd 0.0186 (0.0171) loss_oracle 0.6205 (0.5458) kd_loss 0.9133 (0.8430) acc 78.1250 (87.3438) gate/entropy 1.0565 (1.0616) gate/usage_max 0.4698 (0.4586) gate/usage_min 0.2402 (0.2409) gate/usage_std 0.0986 (0.0919) teacher/entropy 0.0314 (0.0616) teacher/usage_max 0.7137 (0.8025) teacher/usage_min 0.0000 (0.0035) teacher/usage_std 0.2933 (0.3437) nleep/row_max_mean 1535.5222 (1544.0175) nleep/row_max_std 52.0609 (58.1953) nleep/row_min_mean 1504.3191 (1515.4412) lr 1.9511e-03 eta 0:15:31
epoch [7/50] batch [100/181] time 0.145 (0.125) data 0.000 (0.003) loss 1.3110 (1.4621) teacher_loss 0.3035 (0.3409) loss_zs_kd 0.0187 (0.0167) loss_oracle 0.4588 (0.5434) kd_loss 0.7688 (0.8411) acc 93.7500 (87.2500) gate/entropy 1.0539 (1.0602) gate/usage_max 0.4750 (0.4615) gate/usage_min 0.2401 (0.2407) gate/usage_std 0.1018 (0.0937) teacher/entropy 0.0555 (0.0567) teacher/usage_max 0.8827 (0.8057) teacher/usage_min 0.0000 (0.0032) teacher/usage_std 0.3914 (0.3455) nleep/row_max_mean 1532.6650 (1544.4800) nleep/row_max_std 63.7518 (58.5179) nleep/row_min_mean 1498.5001 (1514.9788) lr 1.9511e-03 eta 0:16:22
epoch [7/50] batch [120/181] time 0.144 (0.128) data 0.000 (0.002) loss 1.4514 (1.4615) teacher_loss 0.2763 (0.3387) loss_zs_kd 0.0176 (0.0166) loss_oracle 0.5682 (0.5444) kd_loss 0.8822 (0.8423) acc 90.6250 (87.4479) gate/entropy 1.0513 (1.0589) gate/usage_max 0.4798 (0.4642) gate/usage_min 0.2400 (0.2405) gate/usage_std 0.1049 (0.0953) teacher/entropy 0.0202 (0.0534) teacher/usage_max 0.7551 (0.8024) teacher/usage_min 0.0000 (0.0027) teacher/usage_std 0.3145 (0.3435) nleep/row_max_mean 1541.9277 (1543.8986) nleep/row_max_std 53.5450 (58.6365) nleep/row_min_mean 1508.4734 (1514.0005) lr 1.9511e-03 eta 0:16:45
epoch [7/50] batch [140/181] time 0.145 (0.131) data 0.000 (0.002) loss 1.3794 (1.4544) teacher_loss 0.2858 (0.3373) loss_zs_kd 0.0195 (0.0161) loss_oracle 0.5184 (0.5415) kd_loss 0.8246 (0.8383) acc 90.6250 (87.6116) gate/entropy 1.0484 (1.0576) gate/usage_max 0.4851 (0.4668) gate/usage_min 0.2396 (0.2404) gate/usage_std 0.1083 (0.0969) teacher/entropy 0.0611 (0.0516) teacher/usage_max 0.7694 (0.8045) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.3224 (0.3446) nleep/row_max_mean 1552.8668 (1543.9855) nleep/row_max_std 49.9485 (58.6867) nleep/row_min_mean 1520.1212 (1513.5862) lr 1.9511e-03 eta 0:17:05
epoch [7/50] batch [160/181] time 0.150 (0.132) data 0.001 (0.002) loss 1.3139 (1.4480) teacher_loss 0.3522 (0.3336) loss_zs_kd 0.0241 (0.0158) loss_oracle 0.4401 (0.5395) kd_loss 0.7296 (0.8368) acc 90.6250 (87.7930) gate/entropy 1.0460 (1.0563) gate/usage_max 0.4892 (0.4694) gate/usage_min 0.2398 (0.2403) gate/usage_std 0.1109 (0.0985) teacher/entropy 0.0080 (0.0493) teacher/usage_max 0.9672 (0.8041) teacher/usage_min 0.0000 (0.0024) teacher/usage_std 0.4484 (0.3443) nleep/row_max_mean 1545.7911 (1544.6778) nleep/row_max_std 60.0598 (58.5700) nleep/row_min_mean 1510.6423 (1513.8048) lr 1.9511e-03 eta 0:17:11
epoch [7/50] batch [180/181] time 0.143 (0.133) data 0.000 (0.002) loss 1.6717 (1.4417) teacher_loss 0.5272 (0.3306) loss_zs_kd 0.0197 (0.0157) loss_oracle 0.6135 (0.5394) kd_loss 0.8279 (0.8336) acc 78.1250 (88.0208) gate/entropy 1.0429 (1.0550) gate/usage_max 0.4943 (0.4719) gate/usage_min 0.2393 (0.2403) gate/usage_std 0.1143 (0.1001) teacher/entropy 0.0282 (0.0476) teacher/usage_max 0.7897 (0.8050) teacher/usage_min 0.0000 (0.0023) teacher/usage_std 0.3339 (0.3448) nleep/row_max_mean 1546.5520 (1545.2543) nleep/row_max_std 55.8328 (58.3456) nleep/row_min_mean 1512.5029 (1513.9680) lr 1.9511e-03 eta 0:17:15
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,387
* accuracy: 95.6%
* error: 4.4%
* macro_f1: 96.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.3%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [8/50] batch [20/181] time 0.089 (0.143) data 0.000 (0.017) loss 1.6409 (1.5042) teacher_loss 0.5329 (0.3786) loss_zs_kd 0.0091 (0.0144) loss_oracle 0.5062 (0.5583) kd_loss 0.8504 (0.8393) acc 78.1250 (85.3125) gate/entropy 1.0404 (1.0417) gate/usage_max 0.4982 (0.4962) gate/usage_min 0.2395 (0.2396) gate/usage_std 0.1170 (0.1156) teacher/entropy 0.0226 (0.0283) teacher/usage_max 0.7566 (0.7689) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3153 (0.3242) nleep/row_max_mean 1564.7240 (1556.5477) nleep/row_max_std 46.0968 (52.0593) nleep/row_min_mean 1531.6521 (1521.5036) lr 1.9298e-03 eta 0:18:29
epoch [8/50] batch [40/181] time 0.185 (0.136) data 0.000 (0.009) loss 1.3173 (1.4745) teacher_loss 0.2306 (0.3475) loss_zs_kd 0.0104 (0.0152) loss_oracle 0.6613 (0.5736) kd_loss 0.7508 (0.8325) acc 87.5000 (87.0312) gate/entropy 1.0386 (1.0405) gate/usage_max 0.5010 (0.4981) gate/usage_min 0.2401 (0.2396) gate/usage_std 0.1188 (0.1169) teacher/entropy 0.0656 (0.0330) teacher/usage_max 0.8280 (0.7677) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3568 (0.3231) nleep/row_max_mean 1552.4015 (1557.6700) nleep/row_max_std 57.7858 (51.4122) nleep/row_min_mean 1511.9691 (1521.6137) lr 1.9298e-03 eta 0:17:32
epoch [8/50] batch [60/181] time 0.089 (0.125) data 0.001 (0.006) loss 1.8156 (1.4428) teacher_loss 0.8187 (0.3378) loss_zs_kd 0.0194 (0.0156) loss_oracle 0.5438 (0.5707) kd_loss 0.7152 (0.8118) acc 68.7500 (87.1354) gate/entropy 1.0354 (1.0393) gate/usage_max 0.5058 (0.5000) gate/usage_min 0.2394 (0.2396) gate/usage_std 0.1221 (0.1182) teacher/entropy 0.0380 (0.0357) teacher/usage_max 0.9032 (0.7882) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.4049 (0.3353) nleep/row_max_mean 1555.1036 (1558.1777) nleep/row_max_std 55.1303 (52.0500) nleep/row_min_mean 1518.7692 (1520.8817) lr 1.9298e-03 eta 0:16:05
epoch [8/50] batch [80/181] time 0.161 (0.124) data 0.000 (0.005) loss 1.4394 (1.4396) teacher_loss 0.3915 (0.3461) loss_zs_kd 0.0180 (0.0155) loss_oracle 0.5132 (0.5639) kd_loss 0.7823 (0.8039) acc 81.2500 (86.9141) gate/entropy 1.0325 (1.0379) gate/usage_max 0.5099 (0.5020) gate/usage_min 0.2387 (0.2395) gate/usage_std 0.1249 (0.1195) teacher/entropy 0.0103 (0.0338) teacher/usage_max 0.8427 (0.7974) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.3658 (0.3406) nleep/row_max_mean 1554.5168 (1558.6212) nleep/row_max_std 58.1268 (52.9147) nleep/row_min_mean 1515.3745 (1520.5093) lr 1.9298e-03 eta 0:15:57
epoch [8/50] batch [100/181] time 0.078 (0.123) data 0.000 (0.004) loss 1.3490 (1.4332) teacher_loss 0.4109 (0.3509) loss_zs_kd 0.0146 (0.0151) loss_oracle 0.4842 (0.5567) kd_loss 0.6887 (0.7964) acc 78.1250 (86.8750) gate/entropy 1.0296 (1.0364) gate/usage_max 0.5139 (0.5041) gate/usage_min 0.2379 (0.2392) gate/usage_std 0.1278 (0.1210) teacher/entropy 0.0370 (0.0311) teacher/usage_max 0.9220 (0.8069) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.4175 (0.3463) nleep/row_max_mean 1547.9708 (1559.2741) nleep/row_max_std 60.5898 (53.5032) nleep/row_min_mean 1503.8145 (1520.3476) lr 1.9298e-03 eta 0:15:47
epoch [8/50] batch [120/181] time 0.108 (0.123) data 0.000 (0.003) loss 1.2971 (1.4175) teacher_loss 0.2691 (0.3441) loss_zs_kd 0.0119 (0.0148) loss_oracle 0.4770 (0.5519) kd_loss 0.7835 (0.7901) acc 87.5000 (87.1354) gate/entropy 1.0270 (1.0350) gate/usage_max 0.5174 (0.5061) gate/usage_min 0.2373 (0.2389) gate/usage_std 0.1302 (0.1224) teacher/entropy 0.0194 (0.0310) teacher/usage_max 0.8134 (0.8115) teacher/usage_min 0.0000 (0.0002) teacher/usage_std 0.3479 (0.3489) nleep/row_max_mean 1553.9707 (1558.6771) nleep/row_max_std 52.4773 (53.9730) nleep/row_min_mean 1513.0200 (1519.4811) lr 1.9298e-03 eta 0:15:44
epoch [8/50] batch [140/181] time 0.164 (0.123) data 0.000 (0.003) loss 1.6013 (1.4044) teacher_loss 0.5705 (0.3381) loss_zs_kd 0.0184 (0.0144) loss_oracle 0.5239 (0.5468) kd_loss 0.7597 (0.7857) acc 68.7500 (87.2991) gate/entropy 1.0240 (1.0336) gate/usage_max 0.5213 (0.5080) gate/usage_min 0.2365 (0.2386) gate/usage_std 0.1330 (0.1237) teacher/entropy 0.0137 (0.0308) teacher/usage_max 0.8443 (0.8139) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.3669 (0.3503) nleep/row_max_mean 1567.7949 (1558.6530) nleep/row_max_std 52.9960 (54.1636) nleep/row_min_mean 1527.0057 (1519.1585) lr 1.9298e-03 eta 0:15:41
epoch [8/50] batch [160/181] time 0.133 (0.124) data 0.000 (0.002) loss 1.1385 (1.3941) teacher_loss 0.2111 (0.3342) loss_zs_kd 0.0094 (0.0149) loss_oracle 0.5020 (0.5437) kd_loss 0.6718 (0.7806) acc 87.5000 (87.5000) gate/entropy 1.0220 (1.0323) gate/usage_max 0.5239 (0.5098) gate/usage_min 0.2361 (0.2383) gate/usage_std 0.1348 (0.1249) teacher/entropy 0.0374 (0.0313) teacher/usage_max 0.9207 (0.8164) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.4166 (0.3518) nleep/row_max_mean 1570.5238 (1558.3833) nleep/row_max_std 54.0880 (54.3546) nleep/row_min_mean 1527.3723 (1518.8079) lr 1.9298e-03 eta 0:15:46
epoch [8/50] batch [180/181] time 0.159 (0.123) data 0.000 (0.002) loss 1.3239 (1.3899) teacher_loss 0.2549 (0.3303) loss_zs_kd 0.0038 (0.0148) loss_oracle 0.5322 (0.5431) kd_loss 0.8010 (0.7806) acc 90.6250 (87.6042) gate/entropy 1.0204 (1.0310) gate/usage_max 0.5259 (0.5115) gate/usage_min 0.2359 (0.2380) gate/usage_std 0.1362 (0.1262) teacher/entropy 0.0498 (0.0322) teacher/usage_max 0.7389 (0.8122) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.3059 (0.3494) nleep/row_max_mean 1542.8546 (1558.4602) nleep/row_max_std 52.5991 (54.0194) nleep/row_min_mean 1503.6091 (1518.9329) lr 1.9298e-03 eta 0:15:32
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,392
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,669
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.3%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [9/50] batch [20/181] time 0.165 (0.184) data 0.000 (0.016) loss 1.3036 (1.3937) teacher_loss 0.1562 (0.3319) loss_zs_kd 0.0044 (0.0136) loss_oracle 0.5400 (0.5395) kd_loss 0.8753 (0.7853) acc 93.7500 (87.0312) gate/entropy 1.0178 (1.0187) gate/usage_max 0.5291 (0.5280) gate/usage_min 0.2352 (0.2353) gate/usage_std 0.1385 (0.1377) teacher/entropy 0.0713 (0.0417) teacher/usage_max 0.6154 (0.7654) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2538 (0.3246) nleep/row_max_mean 1566.4724 (1557.2823) nleep/row_max_std 56.8777 (54.4812) nleep/row_min_mean 1525.4469 (1519.4243) lr 1.9048e-03 eta 0:23:11
epoch [9/50] batch [40/181] time 0.165 (0.181) data 0.000 (0.008) loss 1.3620 (1.4130) teacher_loss 0.2057 (0.3321) loss_zs_kd 0.0077 (0.0141) loss_oracle 0.5778 (0.5375) kd_loss 0.8635 (0.8051) acc 90.6250 (87.1875) gate/entropy 1.0164 (1.0179) gate/usage_max 0.5309 (0.5290) gate/usage_min 0.2339 (0.2350) gate/usage_std 0.1397 (0.1384) teacher/entropy 0.0361 (0.0444) teacher/usage_max 0.6701 (0.7373) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.2736 (0.3098) nleep/row_max_mean 1562.5369 (1555.5161) nleep/row_max_std 55.7887 (53.9726) nleep/row_min_mean 1524.6326 (1518.0574) lr 1.9048e-03 eta 0:22:47
epoch [9/50] batch [60/181] time 0.180 (0.180) data 0.001 (0.005) loss 1.2087 (1.4069) teacher_loss 0.1173 (0.3304) loss_zs_kd 0.0077 (0.0136) loss_oracle 0.5579 (0.5309) kd_loss 0.8087 (0.8042) acc 96.8750 (87.7604) gate/entropy 1.0147 (1.0172) gate/usage_max 0.5330 (0.5299) gate/usage_min 0.2321 (0.2344) gate/usage_std 0.1412 (0.1390) teacher/entropy 0.0612 (0.0459) teacher/usage_max 0.7053 (0.7345) teacher/usage_min 0.0000 (0.0010) teacher/usage_std 0.2892 (0.3074) nleep/row_max_mean 1569.8683 (1555.2227) nleep/row_max_std 48.6645 (54.9197) nleep/row_min_mean 1529.9498 (1517.3098) lr 1.9048e-03 eta 0:22:39
epoch [9/50] batch [80/181] time 0.089 (0.162) data 0.000 (0.004) loss 1.4521 (1.4081) teacher_loss 0.3581 (0.3355) loss_zs_kd 0.0218 (0.0146) loss_oracle 0.5857 (0.5334) kd_loss 0.7903 (0.7986) acc 90.6250 (87.7734) gate/entropy 1.0131 (1.0165) gate/usage_max 0.5348 (0.5307) gate/usage_min 0.2304 (0.2337) gate/usage_std 0.1425 (0.1396) teacher/entropy 0.0582 (0.0468) teacher/usage_max 0.7292 (0.7386) teacher/usage_min 0.0000 (0.0008) teacher/usage_std 0.3010 (0.3092) nleep/row_max_mean 1564.9020 (1555.1660) nleep/row_max_std 46.0162 (55.4863) nleep/row_min_mean 1526.7124 (1516.5634) lr 1.9048e-03 eta 0:20:15
epoch [9/50] batch [100/181] time 0.086 (0.153) data 0.000 (0.003) loss 1.6262 (1.4285) teacher_loss 0.4665 (0.3460) loss_zs_kd 0.0187 (0.0157) loss_oracle 0.6024 (0.5444) kd_loss 0.8491 (0.8024) acc 84.3750 (87.2188) gate/entropy 1.0122 (1.0159) gate/usage_max 0.5359 (0.5315) gate/usage_min 0.2291 (0.2330) gate/usage_std 0.1433 (0.1401) teacher/entropy 0.0297 (0.0486) teacher/usage_max 0.6894 (0.7304) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.2819 (0.3054) nleep/row_max_mean 1576.2886 (1554.8381) nleep/row_max_std 41.4622 (56.0696) nleep/row_min_mean 1536.3883 (1515.9927) lr 1.9048e-03 eta 0:19:05
epoch [9/50] batch [120/181] time 0.094 (0.147) data 0.000 (0.003) loss 1.3387 (1.4285) teacher_loss 0.1793 (0.3367) loss_zs_kd 0.0158 (0.0157) loss_oracle 0.6286 (0.5516) kd_loss 0.8373 (0.8081) acc 93.7500 (87.5521) gate/entropy 1.0126 (1.0154) gate/usage_max 0.5354 (0.5321) gate/usage_min 0.2285 (0.2324) gate/usage_std 0.1429 (0.1406) teacher/entropy 0.0779 (0.0526) teacher/usage_max 0.6425 (0.7173) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.2628 (0.2999) nleep/row_max_mean 1559.4365 (1554.2785) nleep/row_max_std 57.4813 (57.1083) nleep/row_min_mean 1518.3512 (1515.1173) lr 1.9048e-03 eta 0:18:18
epoch [9/50] batch [140/181] time 0.091 (0.142) data 0.000 (0.002) loss 1.7441 (1.4336) teacher_loss 0.5171 (0.3330) loss_zs_kd 0.0189 (0.0162) loss_oracle 0.5903 (0.5542) kd_loss 0.9224 (0.8154) acc 84.3750 (87.5670) gate/entropy 1.0115 (1.0149) gate/usage_max 0.5366 (0.5327) gate/usage_min 0.2270 (0.2317) gate/usage_std 0.1438 (0.1410) teacher/entropy 0.0692 (0.0538) teacher/usage_max 0.5477 (0.7071) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.2389 (0.2958) nleep/row_max_mean 1566.8132 (1554.7696) nleep/row_max_std 58.0774 (56.9496) nleep/row_min_mean 1525.4854 (1515.3800) lr 1.9048e-03 eta 0:17:37
epoch [9/50] batch [160/181] time 0.105 (0.137) data 0.000 (0.002) loss 1.2980 (1.4296) teacher_loss 0.3242 (0.3272) loss_zs_kd 0.0186 (0.0164) loss_oracle 0.4997 (0.5473) kd_loss 0.7146 (0.8205) acc 87.5000 (87.8711) gate/entropy 1.0113 (1.0145) gate/usage_max 0.5368 (0.5331) gate/usage_min 0.2261 (0.2311) gate/usage_std 0.1440 (0.1413) teacher/entropy 0.0759 (0.0559) teacher/usage_max 0.7926 (0.6990) teacher/usage_min 0.0000 (0.0004) teacher/usage_std 0.3356 (0.2925) nleep/row_max_mean 1558.4902 (1554.8460) nleep/row_max_std 48.6603 (57.1818) nleep/row_min_mean 1518.8306 (1515.4329) lr 1.9048e-03 eta 0:17:01
epoch [9/50] batch [180/181] time 0.183 (0.134) data 0.000 (0.002) loss 1.4344 (1.4277) teacher_loss 0.4367 (0.3258) loss_zs_kd 0.0282 (0.0166) loss_oracle 0.4268 (0.5399) kd_loss 0.7702 (0.8236) acc 84.3750 (87.6910) gate/entropy 1.0110 (1.0141) gate/usage_max 0.5372 (0.5335) gate/usage_min 0.2252 (0.2305) gate/usage_std 0.1442 (0.1416) teacher/entropy 0.1304 (0.0574) teacher/usage_max 0.6567 (0.6920) teacher/usage_min 0.0000 (0.0003) teacher/usage_std 0.2682 (0.2896) nleep/row_max_mean 1546.6833 (1554.8543) nleep/row_max_std 41.9782 (56.7058) nleep/row_min_mean 1511.4753 (1515.4913) lr 1.9048e-03 eta 0:16:34
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,397
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.5%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.3%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [10/50] batch [20/181] time 0.200 (0.149) data 0.000 (0.017) loss 1.3054 (1.4087) teacher_loss 0.0698 (0.2817) loss_zs_kd 0.0153 (0.0183) loss_oracle 0.6368 (0.5122) kd_loss 0.9095 (0.8617) acc 100.0000 (89.8438) gate/entropy 1.0113 (1.0109) gate/usage_max 0.5368 (0.5373) gate/usage_min 0.2247 (0.2248) gate/usage_std 0.1440 (0.1443) teacher/entropy 0.0615 (0.0644) teacher/usage_max 0.5684 (0.6290) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2422 (0.2644) nleep/row_max_mean 1540.4194 (1551.5644) nleep/row_max_std 42.5746 (52.0337) nleep/row_min_mean 1501.5283 (1513.3878) lr 1.8763e-03 eta 0:18:22
epoch [10/50] batch [40/181] time 0.105 (0.130) data 0.000 (0.009) loss 1.3836 (1.3807) teacher_loss 0.2057 (0.2702) loss_zs_kd 0.0245 (0.0197) loss_oracle 0.5110 (0.5041) kd_loss 0.9101 (0.8487) acc 96.8750 (90.4688) gate/entropy 1.0101 (1.0106) gate/usage_max 0.5381 (0.5376) gate/usage_min 0.2233 (0.2243) gate/usage_std 0.1450 (0.1445) teacher/entropy 0.0425 (0.0642) teacher/usage_max 0.5879 (0.6422) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.2464 (0.2690) nleep/row_max_mean 1566.3936 (1553.4393) nleep/row_max_std 43.8674 (52.3758) nleep/row_min_mean 1524.7379 (1515.5729) lr 1.8763e-03 eta 0:15:58
epoch [10/50] batch [60/181] time 0.166 (0.138) data 0.001 (0.006) loss 1.3645 (1.3850) teacher_loss 0.2097 (0.2867) loss_zs_kd 0.0126 (0.0197) loss_oracle 0.6004 (0.5081) kd_loss 0.8483 (0.8344) acc 93.7500 (89.4792) gate/entropy 1.0098 (1.0104) gate/usage_max 0.5385 (0.5378) gate/usage_min 0.2225 (0.2238) gate/usage_std 0.1452 (0.1447) teacher/entropy 0.0213 (0.0633) teacher/usage_max 0.6891 (0.6593) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.2818 (0.2756) nleep/row_max_mean 1552.7463 (1553.9026) nleep/row_max_std 60.4592 (53.5249) nleep/row_min_mean 1514.3997 (1515.8591) lr 1.8763e-03 eta 0:16:52
epoch [10/50] batch [80/181] time 0.139 (0.141) data 0.000 (0.004) loss 1.3741 (1.3899) teacher_loss 0.1502 (0.2835) loss_zs_kd 0.0247 (0.0198) loss_oracle 0.6458 (0.5207) kd_loss 0.8887 (0.8361) acc 96.8750 (89.7656) gate/entropy 1.0095 (1.0102) gate/usage_max 0.5388 (0.5380) gate/usage_min 0.2218 (0.2234) gate/usage_std 0.1455 (0.1449) teacher/entropy 0.0626 (0.0626) teacher/usage_max 0.5880 (0.6583) teacher/usage_min 0.0000 (0.0000) teacher/usage_std 0.2464 (0.2756) nleep/row_max_mean 1559.8361 (1553.5622) nleep/row_max_std 51.6288 (54.5640) nleep/row_min_mean 1521.9087 (1515.6775) lr 1.8763e-03 eta 0:17:12
epoch [10/50] batch [100/181] time 0.132 (0.142) data 0.000 (0.004) loss 1.5872 (1.3995) teacher_loss 0.3927 (0.2890) loss_zs_kd 0.0276 (0.0210) loss_oracle 0.5556 (0.5231) kd_loss 0.9028 (0.8385) acc 90.6250 (89.5625) gate/entropy 1.0095 (1.0101) gate/usage_max 0.5387 (0.5382) gate/usage_min 0.2210 (0.2230) gate/usage_std 0.1454 (0.1450) teacher/entropy 0.0524 (0.0629) teacher/usage_max 0.5817 (0.6544) teacher/usage_min 0.0003 (0.0002) teacher/usage_std 0.2448 (0.2735) nleep/row_max_mean 1551.3735 (1553.1399) nleep/row_max_std 39.1860 (53.8951) nleep/row_min_mean 1515.6849 (1515.5020) lr 1.8763e-03 eta 0:17:19
epoch [10/50] batch [120/181] time 0.149 (0.144) data 0.000 (0.003) loss 1.2843 (1.4090) teacher_loss 0.2626 (0.2911) loss_zs_kd 0.0221 (0.0215) loss_oracle 0.4002 (0.5289) kd_loss 0.8105 (0.8426) acc 93.7500 (89.6875) gate/entropy 1.0088 (1.0100) gate/usage_max 0.5394 (0.5383) gate/usage_min 0.2200 (0.2226) gate/usage_std 0.1460 (0.1451) teacher/entropy 0.0997 (0.0611) teacher/usage_max 0.6361 (0.6506) teacher/usage_min 0.0000 (0.0007) teacher/usage_std 0.2606 (0.2720) nleep/row_max_mean 1566.3608 (1552.4054) nleep/row_max_std 44.1093 (54.4107) nleep/row_min_mean 1531.2217 (1515.2419) lr 1.8763e-03 eta 0:17:32
epoch [10/50] batch [140/181] time 0.158 (0.146) data 0.000 (0.003) loss 1.4226 (1.4130) teacher_loss 0.2834 (0.2926) loss_zs_kd 0.0421 (0.0218) loss_oracle 0.5413 (0.5308) kd_loss 0.8475 (0.8442) acc 93.7500 (89.7545) gate/entropy 1.0092 (1.0098) gate/usage_max 0.5388 (0.5384) gate/usage_min 0.2195 (0.2222) gate/usage_std 0.1456 (0.1451) teacher/entropy 0.0509 (0.0602) teacher/usage_max 0.6498 (0.6487) teacher/usage_min 0.0008 (0.0006) teacher/usage_std 0.2652 (0.2711) nleep/row_max_mean 1553.4736 (1552.7044) nleep/row_max_std 64.3816 (55.1871) nleep/row_min_mean 1516.6072 (1515.9340) lr 1.8763e-03 eta 0:17:40
epoch [10/50] batch [160/181] time 0.158 (0.146) data 0.001 (0.002) loss 1.3848 (1.4149) teacher_loss 0.1084 (0.2854) loss_zs_kd 0.0137 (0.0215) loss_oracle 0.5499 (0.5339) kd_loss 0.9946 (0.8518) acc 96.8750 (90.0586) gate/entropy 1.0100 (1.0098) gate/usage_max 0.5378 (0.5384) gate/usage_min 0.2190 (0.2218) gate/usage_std 0.1449 (0.1452) teacher/entropy 0.0190 (0.0599) teacher/usage_max 0.5029 (0.6419) teacher/usage_min 0.0000 (0.0006) teacher/usage_std 0.2357 (0.2690) nleep/row_max_mean 1555.7791 (1552.6655) nleep/row_max_std 56.2995 (55.8918) nleep/row_min_mean 1517.1647 (1516.0807) lr 1.8763e-03 eta 0:17:42
epoch [10/50] batch [180/181] time 0.071 (0.139) data 0.000 (0.002) loss 1.6405 (1.4188) teacher_loss 0.3971 (0.2786) loss_zs_kd 0.0259 (0.0213) loss_oracle 0.5060 (0.5376) kd_loss 0.9775 (0.8607) acc 81.2500 (90.2604) gate/entropy 1.0105 (1.0098) gate/usage_max 0.5371 (0.5383) gate/usage_min 0.2181 (0.2215) gate/usage_std 0.1445 (0.1451) teacher/entropy 0.0319 (0.0589) teacher/usage_max 0.5068 (0.6340) teacher/usage_min 0.0021 (0.0005) teacher/usage_std 0.2343 (0.2665) nleep/row_max_mean 1535.1827 (1552.6408) nleep/row_max_std 58.6284 (56.3727) nleep/row_min_mean 1506.3888 (1516.2054) lr 1.8763e-03 eta 0:16:47
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,404
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.3%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [11/50] batch [20/181] time 0.075 (0.114) data 0.000 (0.016) loss 1.4852 (1.4230) teacher_loss 0.2945 (0.2429) loss_zs_kd 0.0158 (0.0257) loss_oracle 0.5039 (0.5067) kd_loss 0.9309 (0.9140) acc 90.6250 (91.4062) gate/entropy 1.0111 (1.0107) gate/usage_max 0.5362 (0.5367) gate/usage_min 0.2173 (0.2175) gate/usage_std 0.1439 (0.1443) teacher/entropy 0.0711 (0.0459) teacher/usage_max 0.5124 (0.5782) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.2359 (0.2496) nleep/row_max_mean 1546.1096 (1551.2174) nleep/row_max_std 57.7855 (57.3518) nleep/row_min_mean 1508.9872 (1516.9504) lr 1.8443e-03 eta 0:13:40
epoch [11/50] batch [40/181] time 0.075 (0.115) data 0.000 (0.008) loss 1.4867 (1.4026) teacher_loss 0.3374 (0.2330) loss_zs_kd 0.0395 (0.0244) loss_oracle 0.5067 (0.5044) kd_loss 0.8762 (0.9052) acc 84.3750 (91.6406) gate/entropy 1.0115 (1.0109) gate/usage_max 0.5355 (0.5364) gate/usage_min 0.2167 (0.2172) gate/usage_std 0.1435 (0.1441) teacher/entropy 0.0489 (0.0494) teacher/usage_max 0.6104 (0.5833) teacher/usage_min 0.0002 (0.0008) teacher/usage_std 0.2523 (0.2502) nleep/row_max_mean 1545.2430 (1550.9726) nleep/row_max_std 59.5305 (55.0401) nleep/row_min_mean 1511.4541 (1517.0062) lr 1.8443e-03 eta 0:13:49
epoch [11/50] batch [60/181] time 0.165 (0.115) data 0.001 (0.006) loss 1.3326 (1.4153) teacher_loss 0.2390 (0.2594) loss_zs_kd 0.0181 (0.0254) loss_oracle 0.5337 (0.5076) kd_loss 0.8177 (0.8894) acc 87.5000 (90.8854) gate/entropy 1.0115 (1.0111) gate/usage_max 0.5355 (0.5361) gate/usage_min 0.2159 (0.2169) gate/usage_std 0.1435 (0.1439) teacher/entropy 0.0690 (0.0521) teacher/usage_max 0.6582 (0.5958) teacher/usage_min 0.0035 (0.0015) teacher/usage_std 0.2673 (0.2539) nleep/row_max_mean 1557.8804 (1551.3833) nleep/row_max_std 55.6262 (54.9076) nleep/row_min_mean 1521.5623 (1517.3575) lr 1.8443e-03 eta 0:13:44
epoch [11/50] batch [80/181] time 0.087 (0.112) data 0.000 (0.004) loss 1.3745 (1.4108) teacher_loss 0.0594 (0.2508) loss_zs_kd 0.0076 (0.0241) loss_oracle 0.6597 (0.5162) kd_loss 0.9814 (0.8898) acc 100.0000 (91.2891) gate/entropy 1.0125 (1.0112) gate/usage_max 0.5340 (0.5359) gate/usage_min 0.2156 (0.2165) gate/usage_std 0.1426 (0.1438) teacher/entropy 0.0209 (0.0502) teacher/usage_max 0.5051 (0.5992) teacher/usage_min 0.0001 (0.0015) teacher/usage_std 0.2357 (0.2546) nleep/row_max_mean 1524.7328 (1552.4320) nleep/row_max_std 55.6342 (54.9891) nleep/row_min_mean 1495.0005 (1518.8361) lr 1.8443e-03 eta 0:13:24
epoch [11/50] batch [100/181] time 0.102 (0.113) data 0.000 (0.003) loss 1.2390 (1.4017) teacher_loss 0.1199 (0.2484) loss_zs_kd 0.0117 (0.0242) loss_oracle 0.5444 (0.5145) kd_loss 0.8410 (0.8840) acc 93.7500 (91.0625) gate/entropy 1.0120 (1.0114) gate/usage_max 0.5344 (0.5356) gate/usage_min 0.2143 (0.2162) gate/usage_std 0.1430 (0.1436) teacher/entropy 0.0360 (0.0483) teacher/usage_max 0.6680 (0.6070) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.2727 (0.2570) nleep/row_max_mean 1563.9811 (1552.6856) nleep/row_max_std 55.2937 (54.7301) nleep/row_min_mean 1530.3015 (1519.5866) lr 1.8443e-03 eta 0:13:28
epoch [11/50] batch [120/181] time 0.138 (0.113) data 0.000 (0.003) loss 1.4169 (1.4039) teacher_loss 0.2232 (0.2481) loss_zs_kd 0.0277 (0.0247) loss_oracle 0.5613 (0.5169) kd_loss 0.8993 (0.8850) acc 90.6250 (91.0938) gate/entropy 1.0128 (1.0116) gate/usage_max 0.5333 (0.5353) gate/usage_min 0.2138 (0.2158) gate/usage_std 0.1423 (0.1434) teacher/entropy 0.0405 (0.0468) teacher/usage_max 0.5833 (0.6107) teacher/usage_min 0.0000 (0.0018) teacher/usage_std 0.2453 (0.2578) nleep/row_max_mean 1538.7313 (1552.0707) nleep/row_max_std 69.1885 (55.0986) nleep/row_min_mean 1508.6379 (1519.1117) lr 1.8443e-03 eta 0:13:27
epoch [11/50] batch [140/181] time 0.161 (0.113) data 0.000 (0.003) loss 1.5591 (1.4088) teacher_loss 0.3738 (0.2584) loss_zs_kd 0.0295 (0.0255) loss_oracle 0.5961 (0.5145) kd_loss 0.8724 (0.8804) acc 87.5000 (90.8482) gate/entropy 1.0131 (1.0118) gate/usage_max 0.5327 (0.5350) gate/usage_min 0.2132 (0.2155) gate/usage_std 0.1419 (0.1433) teacher/entropy 0.0503 (0.0474) teacher/usage_max 0.6024 (0.6147) teacher/usage_min 0.0008 (0.0019) teacher/usage_std 0.2497 (0.2586) nleep/row_max_mean 1539.7209 (1551.1608) nleep/row_max_std 57.9894 (54.8395) nleep/row_min_mean 1509.1327 (1518.4173) lr 1.8443e-03 eta 0:13:25
epoch [11/50] batch [160/181] time 0.092 (0.113) data 0.000 (0.002) loss 1.4286 (1.4076) teacher_loss 0.2454 (0.2560) loss_zs_kd 0.0242 (0.0255) loss_oracle 0.4813 (0.5142) kd_loss 0.9305 (0.8817) acc 90.6250 (90.8398) gate/entropy 1.0132 (1.0119) gate/usage_max 0.5324 (0.5347) gate/usage_min 0.2124 (0.2152) gate/usage_std 0.1418 (0.1431) teacher/entropy 0.0619 (0.0474) teacher/usage_max 0.5072 (0.6119) teacher/usage_min 0.0000 (0.0017) teacher/usage_std 0.2358 (0.2577) nleep/row_max_mean 1545.6879 (1550.5254) nleep/row_max_std 59.4566 (54.6837) nleep/row_min_mean 1518.2333 (1517.8289) lr 1.8443e-03 eta 0:13:19
epoch [11/50] batch [180/181] time 0.144 (0.116) data 0.000 (0.002) loss 1.2464 (1.4064) teacher_loss 0.1536 (0.2526) loss_zs_kd 0.0232 (0.0258) loss_oracle 0.5508 (0.5158) kd_loss 0.8058 (0.8831) acc 93.7500 (91.0069) gate/entropy 1.0136 (1.0121) gate/usage_max 0.5316 (0.5343) gate/usage_min 0.2114 (0.2148) gate/usage_std 0.1414 (0.1429) teacher/entropy 0.0421 (0.0470) teacher/usage_max 0.7021 (0.6102) teacher/usage_min 0.0000 (0.0018) teacher/usage_std 0.2877 (0.2571) nleep/row_max_mean 1561.1819 (1550.0675) nleep/row_max_std 52.3673 (54.5702) nleep/row_min_mean 1528.0065 (1517.4607) lr 1.8443e-03 eta 0:13:37
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,405
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.8%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.3%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [12/50] batch [20/181] time 0.140 (0.158) data 0.000 (0.012) loss 1.4797 (1.3867) teacher_loss 0.3444 (0.2372) loss_zs_kd 0.0391 (0.0265) loss_oracle 0.5325 (0.5012) kd_loss 0.8495 (0.8857) acc 90.6250 (91.8750) gate/entropy 1.0149 (1.0145) gate/usage_max 0.5298 (0.5304) gate/usage_min 0.2111 (0.2114) gate/usage_std 0.1403 (0.1406) teacher/entropy 0.0769 (0.0517) teacher/usage_max 0.5934 (0.5993) teacher/usage_min 0.0001 (0.0050) teacher/usage_std 0.2477 (0.2511) nleep/row_max_mean 1530.4680 (1538.4592) nleep/row_max_std 50.4182 (52.7466) nleep/row_min_mean 1503.9740 (1508.5391) lr 1.8090e-03 eta 0:18:34
epoch [12/50] batch [40/181] time 0.152 (0.153) data 0.000 (0.006) loss 1.2017 (1.3623) teacher_loss 0.1777 (0.2386) loss_zs_kd 0.0290 (0.0260) loss_oracle 0.4128 (0.4927) kd_loss 0.8031 (0.8644) acc 93.7500 (91.3281) gate/entropy 1.0144 (1.0146) gate/usage_max 0.5302 (0.5301) gate/usage_min 0.2103 (0.2110) gate/usage_std 0.1406 (0.1405) teacher/entropy 0.0849 (0.0522) teacher/usage_max 0.6435 (0.6186) teacher/usage_min 0.0000 (0.0061) teacher/usage_std 0.2632 (0.2591) nleep/row_max_mean 1549.7838 (1540.1332) nleep/row_max_std 41.1971 (50.2619) nleep/row_min_mean 1526.1831 (1510.6519) lr 1.8090e-03 eta 0:17:53
epoch [12/50] batch [60/181] time 0.152 (0.152) data 0.001 (0.004) loss 1.2388 (1.3407) teacher_loss 0.2116 (0.2302) loss_zs_kd 0.0316 (0.0264) loss_oracle 0.4973 (0.4930) kd_loss 0.7627 (0.8508) acc 93.7500 (91.9792) gate/entropy 1.0145 (1.0146) gate/usage_max 0.5299 (0.5300) gate/usage_min 0.2099 (0.2108) gate/usage_std 0.1405 (0.1404) teacher/entropy 0.0688 (0.0552) teacher/usage_max 0.7240 (0.6298) teacher/usage_min 0.0000 (0.0086) teacher/usage_std 0.2983 (0.2616) nleep/row_max_mean 1544.3063 (1540.7730) nleep/row_max_std 45.0388 (48.1863) nleep/row_min_mean 1510.8600 (1511.4618) lr 1.8090e-03 eta 0:17:46
epoch [12/50] batch [80/181] time 0.103 (0.146) data 0.000 (0.003) loss 1.2784 (1.3342) teacher_loss 0.1698 (0.2305) loss_zs_kd 0.0157 (0.0249) loss_oracle 0.5428 (0.4875) kd_loss 0.8293 (0.8475) acc 96.8750 (92.0703) gate/entropy 1.0146 (1.0147) gate/usage_max 0.5297 (0.5299) gate/usage_min 0.2097 (0.2105) gate/usage_std 0.1404 (0.1404) teacher/entropy 0.0751 (0.0565) teacher/usage_max 0.6233 (0.6306) teacher/usage_min 0.0138 (0.0100) teacher/usage_std 0.2497 (0.2605) nleep/row_max_mean 1545.8516 (1539.9861) nleep/row_max_std 48.5203 (48.1603) nleep/row_min_mean 1519.7422 (1511.0376) lr 1.8090e-03 eta 0:17:00
epoch [12/50] batch [100/181] time 0.189 (0.139) data 0.000 (0.003) loss 1.3642 (1.3353) teacher_loss 0.2254 (0.2354) loss_zs_kd 0.0276 (0.0252) loss_oracle 0.5032 (0.4890) kd_loss 0.8734 (0.8428) acc 90.6250 (91.8750) gate/entropy 1.0145 (1.0146) gate/usage_max 0.5298 (0.5298) gate/usage_min 0.2094 (0.2103) gate/usage_std 0.1405 (0.1404) teacher/entropy 0.1031 (0.0601) teacher/usage_max 0.5226 (0.6316) teacher/usage_min 0.0138 (0.0123) teacher/usage_std 0.2272 (0.2598) nleep/row_max_mean 1534.2156 (1539.9979) nleep/row_max_std 51.2843 (48.7919) nleep/row_min_mean 1507.1344 (1511.6101) lr 1.8090e-03 eta 0:16:09
epoch [12/50] batch [120/181] time 0.109 (0.135) data 0.000 (0.002) loss 1.1903 (1.3252) teacher_loss 0.1716 (0.2346) loss_zs_kd 0.0176 (0.0248) loss_oracle 0.4639 (0.4869) kd_loss 0.7779 (0.8347) acc 93.7500 (91.7708) gate/entropy 1.0143 (1.0146) gate/usage_max 0.5300 (0.5299) gate/usage_min 0.2094 (0.2102) gate/usage_std 0.1406 (0.1404) teacher/entropy 0.0396 (0.0618) teacher/usage_max 0.7424 (0.6402) teacher/usage_min 0.0044 (0.0151) teacher/usage_std 0.3066 (0.2618) nleep/row_max_mean 1531.1978 (1538.9826) nleep/row_max_std 60.9953 (49.7073) nleep/row_min_mean 1504.9905 (1511.1519) lr 1.8090e-03 eta 0:15:37
epoch [12/50] batch [140/181] time 0.083 (0.131) data 0.000 (0.002) loss 1.4295 (1.3269) teacher_loss 0.2831 (0.2396) loss_zs_kd 0.0203 (0.0253) loss_oracle 0.5157 (0.4925) kd_loss 0.8783 (0.8284) acc 87.5000 (91.4732) gate/entropy 1.0136 (1.0145) gate/usage_max 0.5309 (0.5300) gate/usage_min 0.2094 (0.2101) gate/usage_std 0.1412 (0.1405) teacher/entropy 0.0785 (0.0656) teacher/usage_max 0.5716 (0.6451) teacher/usage_min 0.0869 (0.0221) teacher/usage_std 0.1980 (0.2615) nleep/row_max_mean 1537.8547 (1538.2948) nleep/row_max_std 57.3880 (50.9174) nleep/row_min_mean 1511.0411 (1510.7434) lr 1.8090e-03 eta 0:15:06
epoch [12/50] batch [160/181] time 0.081 (0.128) data 0.000 (0.002) loss 1.1137 (1.3388) teacher_loss 0.0896 (0.2513) loss_zs_kd 0.0238 (0.0268) loss_oracle 0.5199 (0.4984) kd_loss 0.7523 (0.8250) acc 100.0000 (90.9766) gate/entropy 1.0132 (1.0143) gate/usage_max 0.5316 (0.5302) gate/usage_min 0.2097 (0.2100) gate/usage_std 0.1416 (0.1407) teacher/entropy 0.0508 (0.0730) teacher/usage_max 0.7697 (0.6432) teacher/usage_min 0.0308 (0.0349) teacher/usage_std 0.3162 (0.2564) nleep/row_max_mean 1530.4609 (1537.7931) nleep/row_max_std 75.2510 (51.7844) nleep/row_min_mean 1503.7014 (1510.6144) lr 1.8090e-03 eta 0:14:40
epoch [12/50] batch [180/181] time 0.074 (0.124) data 0.000 (0.002) loss 1.2204 (1.3389) teacher_loss 0.1890 (0.2537) loss_zs_kd 0.0337 (0.0273) loss_oracle 0.4279 (0.4985) kd_loss 0.8007 (0.8223) acc 93.7500 (90.8160) gate/entropy 1.0116 (1.0141) gate/usage_max 0.5338 (0.5304) gate/usage_min 0.2097 (0.2099) gate/usage_std 0.1431 (0.1408) teacher/entropy 0.0971 (0.0773) teacher/usage_max 0.6698 (0.6442) teacher/usage_min 0.1469 (0.0461) teacher/usage_std 0.2384 (0.2535) nleep/row_max_mean 1563.3906 (1538.1867) nleep/row_max_std 47.1744 (52.3698) nleep/row_min_mean 1534.1973 (1511.0365) lr 1.8090e-03 eta 0:14:14
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,392
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 96.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.3%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [13/50] batch [20/181] time 0.078 (0.125) data 0.000 (0.017) loss 1.2370 (1.3304) teacher_loss 0.2158 (0.3097) loss_zs_kd 0.0143 (0.0278) loss_oracle 0.4868 (0.4752) kd_loss 0.7706 (0.7693) acc 93.7500 (89.2188) gate/entropy 1.0112 (1.0114) gate/usage_max 0.5346 (0.5343) gate/usage_min 0.2104 (0.2101) gate/usage_std 0.1435 (0.1433) teacher/entropy 0.1210 (0.1040) teacher/usage_max 0.6803 (0.7008) teacher/usage_min 0.1526 (0.1142) teacher/usage_std 0.2454 (0.2624) nleep/row_max_mean 1530.1439 (1542.9157) nleep/row_max_std 64.7725 (61.9774) nleep/row_min_mean 1500.9197 (1514.7593) lr 1.7705e-03 eta 0:14:14
epoch [13/50] batch [40/181] time 0.084 (0.117) data 0.000 (0.009) loss 1.2682 (1.3199) teacher_loss 0.2791 (0.2927) loss_zs_kd 0.0319 (0.0295) loss_oracle 0.5204 (0.4937) kd_loss 0.7130 (0.7655) acc 93.7500 (89.5312) gate/entropy 1.0098 (1.0108) gate/usage_max 0.5365 (0.5351) gate/usage_min 0.2107 (0.2103) gate/usage_std 0.1447 (0.1438) teacher/entropy 0.0684 (0.1012) teacher/usage_max 0.8198 (0.7086) teacher/usage_min 0.0527 (0.1043) teacher/usage_std 0.3453 (0.2689) nleep/row_max_mean 1549.7660 (1543.9368) nleep/row_max_std 65.2208 (61.9938) nleep/row_min_mean 1512.2816 (1514.7282) lr 1.7705e-03 eta 0:13:23
epoch [13/50] batch [60/181] time 0.156 (0.118) data 0.001 (0.006) loss 1.2947 (1.3230) teacher_loss 0.3189 (0.3043) loss_zs_kd 0.0145 (0.0283) loss_oracle 0.4707 (0.4895) kd_loss 0.7333 (0.7598) acc 90.6250 (89.1667) gate/entropy 1.0087 (1.0102) gate/usage_max 0.5381 (0.5359) gate/usage_min 0.2111 (0.2105) gate/usage_std 0.1457 (0.1443) teacher/entropy 0.1300 (0.1061) teacher/usage_max 0.7217 (0.7108) teacher/usage_min 0.0965 (0.1040) teacher/usage_std 0.2768 (0.2704) nleep/row_max_mean 1532.2610 (1544.9442) nleep/row_max_std 77.1219 (61.3164) nleep/row_min_mean 1503.3066 (1514.9244) lr 1.7705e-03 eta 0:13:27
epoch [13/50] batch [80/181] time 0.155 (0.126) data 0.000 (0.004) loss 1.2003 (1.3161) teacher_loss 0.2792 (0.3009) loss_zs_kd 0.0311 (0.0283) loss_oracle 0.4695 (0.4858) kd_loss 0.6708 (0.7581) acc 93.7500 (89.4922) gate/entropy 1.0071 (1.0096) gate/usage_max 0.5402 (0.5367) gate/usage_min 0.2113 (0.2106) gate/usage_std 0.1471 (0.1448) teacher/entropy 0.1233 (0.1059) teacher/usage_max 0.8025 (0.7142) teacher/usage_min 0.0426 (0.1009) teacher/usage_std 0.3349 (0.2733) nleep/row_max_mean 1543.7791 (1545.3170) nleep/row_max_std 68.9210 (61.7208) nleep/row_min_mean 1517.0372 (1514.7514) lr 1.7705e-03 eta 0:14:16
epoch [13/50] batch [100/181] time 0.136 (0.130) data 0.000 (0.004) loss 1.1153 (1.3106) teacher_loss 0.3169 (0.3058) loss_zs_kd 0.0156 (0.0283) loss_oracle 0.4186 (0.4788) kd_loss 0.5813 (0.7513) acc 93.7500 (89.2188) gate/entropy 1.0063 (1.0091) gate/usage_max 0.5414 (0.5375) gate/usage_min 0.2117 (0.2108) gate/usage_std 0.1478 (0.1454) teacher/entropy 0.1778 (0.1066) teacher/usage_max 0.8364 (0.7209) teacher/usage_min 0.0510 (0.1009) teacher/usage_std 0.3566 (0.2774) nleep/row_max_mean 1548.5833 (1545.5876) nleep/row_max_std 62.9365 (61.6392) nleep/row_min_mean 1515.7188 (1514.8229) lr 1.7705e-03 eta 0:14:40
epoch [13/50] batch [120/181] time 0.153 (0.132) data 0.000 (0.003) loss 1.4676 (1.3101) teacher_loss 0.3483 (0.3081) loss_zs_kd 0.0432 (0.0287) loss_oracle 0.5184 (0.4815) kd_loss 0.8385 (0.7469) acc 87.5000 (89.1406) gate/entropy 1.0050 (1.0085) gate/usage_max 0.5430 (0.5383) gate/usage_min 0.2120 (0.2110) gate/usage_std 0.1488 (0.1459) teacher/entropy 0.0813 (0.1054) teacher/usage_max 0.6483 (0.7274) teacher/usage_min 0.1456 (0.0958) teacher/usage_std 0.2241 (0.2822) nleep/row_max_mean 1547.1543 (1546.4236) nleep/row_max_std 45.9104 (62.4745) nleep/row_min_mean 1515.0166 (1515.2894) lr 1.7705e-03 eta 0:14:52
epoch [13/50] batch [140/181] time 0.133 (0.134) data 0.000 (0.003) loss 1.2242 (1.3075) teacher_loss 0.2414 (0.3127) loss_zs_kd 0.0123 (0.0275) loss_oracle 0.5138 (0.4785) kd_loss 0.7197 (0.7418) acc 90.6250 (89.1295) gate/entropy 1.0039 (1.0079) gate/usage_max 0.5445 (0.5391) gate/usage_min 0.2124 (0.2112) gate/usage_std 0.1498 (0.1464) teacher/entropy 0.0306 (0.1033) teacher/usage_max 0.8402 (0.7353) teacher/usage_min 0.0618 (0.0927) teacher/usage_std 0.3587 (0.2875) nleep/row_max_mean 1554.4792 (1547.2412) nleep/row_max_std 58.2595 (62.3842) nleep/row_min_mean 1523.1887 (1515.8939) lr 1.7705e-03 eta 0:15:03
epoch [13/50] batch [160/181] time 0.162 (0.135) data 0.000 (0.002) loss 1.2870 (1.3045) teacher_loss 0.1847 (0.3086) loss_zs_kd 0.0300 (0.0274) loss_oracle 0.6980 (0.4891) kd_loss 0.7383 (0.7377) acc 90.6250 (89.1797) gate/entropy 1.0027 (1.0073) gate/usage_max 0.5460 (0.5399) gate/usage_min 0.2127 (0.2113) gate/usage_std 0.1508 (0.1469) teacher/entropy 0.0920 (0.1016) teacher/usage_max 0.7497 (0.7421) teacher/usage_min 0.0845 (0.0877) teacher/usage_std 0.2963 (0.2924) nleep/row_max_mean 1552.7086 (1547.8737) nleep/row_max_std 54.0307 (61.8978) nleep/row_min_mean 1515.6221 (1516.3266) lr 1.7705e-03 eta 0:15:08
epoch [13/50] batch [180/181] time 0.162 (0.135) data 0.000 (0.002) loss 1.2058 (1.3047) teacher_loss 0.1929 (0.3055) loss_zs_kd 0.0307 (0.0265) loss_oracle 0.4769 (0.4927) kd_loss 0.7591 (0.7395) acc 93.7500 (89.3750) gate/entropy 1.0012 (1.0067) gate/usage_max 0.5478 (0.5407) gate/usage_min 0.2130 (0.2115) gate/usage_std 0.1521 (0.1474) teacher/entropy 0.0926 (0.1008) teacher/usage_max 0.7363 (0.7414) teacher/usage_min 0.0001 (0.0815) teacher/usage_std 0.3046 (0.2932) nleep/row_max_mean 1561.0537 (1547.9764) nleep/row_max_std 60.1699 (61.8846) nleep/row_min_mean 1527.2803 (1516.1573) lr 1.7705e-03 eta 0:15:06
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,402
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.7%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,668
* accuracy: 99.9%
* error: 0.1%
* macro_f1: 99.9%
******* Domain p best val acc:      96.3%, epoch: 4 *******
******* Domain p best val test acc: 99.9%, epoch: 4 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [14/50] batch [20/181] time 0.102 (0.128) data 0.000 (0.015) loss 1.1702 (1.2899) teacher_loss 0.1503 (0.2749) loss_zs_kd 0.0272 (0.0226) loss_oracle 0.5473 (0.4990) kd_loss 0.7327 (0.7542) acc 93.7500 (89.5312) gate/entropy 1.0006 (1.0009) gate/usage_max 0.5487 (0.5483) gate/usage_min 0.2136 (0.2133) gate/usage_std 0.1526 (0.1523) teacher/entropy 0.0638 (0.0892) teacher/usage_max 0.7878 (0.7413) teacher/usage_min 0.0413 (0.0215) teacher/usage_std 0.3257 (0.3049) nleep/row_max_mean 1551.1782 (1549.4443) nleep/row_max_std 65.7296 (56.4688) nleep/row_min_mean 1509.6613 (1515.6095) lr 1.7290e-03 eta 0:14:14
epoch [14/50] batch [40/181] time 0.068 (0.115) data 0.000 (0.008) loss 1.5373 (1.3162) teacher_loss 0.3944 (0.2681) loss_zs_kd 0.0290 (0.0215) loss_oracle 0.6447 (0.5388) kd_loss 0.8062 (0.7679) acc 87.5000 (90.0781) gate/entropy 0.9997 (1.0004) gate/usage_max 0.5498 (0.5489) gate/usage_min 0.2139 (0.2135) gate/usage_std 0.1533 (0.1527) teacher/entropy 0.1179 (0.0836) teacher/usage_max 0.6560 (0.7320) teacher/usage_min 0.0011 (0.0203) teacher/usage_std 0.2674 (0.2992) nleep/row_max_mean 1547.7700 (1548.9930) nleep/row_max_std 58.6989 (56.6673) nleep/row_min_mean 1509.3362 (1514.6109) lr 1.7290e-03 eta 0:12:47
epoch [14/50] batch [60/181] time 0.174 (0.112) data 0.001 (0.005) loss 1.3745 (1.3542) teacher_loss 0.2395 (0.2723) loss_zs_kd 0.0239 (0.0238) loss_oracle 0.6075 (0.5643) kd_loss 0.8193 (0.7879) acc 87.5000 (90.2083) gate/entropy 0.9984 (0.9999) gate/usage_max 0.5513 (0.5495) gate/usage_min 0.2141 (0.2137) gate/usage_std 0.1543 (0.1531) teacher/entropy 0.0699 (0.0849) teacher/usage_max 0.6904 (0.7088) teacher/usage_min 0.0029 (0.0193) teacher/usage_std 0.2813 (0.2895) nleep/row_max_mean 1556.0376 (1548.8457) nleep/row_max_std 40.7824 (55.7312) nleep/row_min_mean 1521.4347 (1514.9065) lr 1.7290e-03 eta 0:12:26
epoch [14/50] batch [80/181] time 0.178 (0.115) data 0.000 (0.004) loss 1.3458 (1.3832) teacher_loss 0.2415 (0.2658) loss_zs_kd 0.0271 (0.0254) loss_oracle 0.6390 (0.5997) kd_loss 0.7713 (0.8048) acc 87.5000 (90.6641) gate/entropy 0.9981 (0.9995) gate/usage_max 0.5518 (0.5500) gate/usage_min 0.2146 (0.2138) gate/usage_std 0.1546 (0.1535) teacher/entropy 0.0474 (0.0824) teacher/usage_max 0.7637 (0.6943) teacher/usage_min 0.0004 (0.0184) teacher/usage_std 0.3192 (0.2830) nleep/row_max_mean 1539.2620 (1548.3906) nleep/row_max_std 59.3106 (56.1338) nleep/row_min_mean 1506.0161 (1514.9431) lr 1.7290e-03 eta 0:12:40
epoch [14/50] batch [100/181] time 0.079 (0.116) data 0.000 (0.003) loss 1.6308 (1.4280) teacher_loss 0.2608 (0.2640) loss_zs_kd 0.0288 (0.0268) loss_oracle 0.7106 (0.6333) kd_loss 1.0003 (0.8339) acc 90.6250 (90.6250) gate/entropy 0.9976 (0.9991) gate/usage_max 0.5523 (0.5505) gate/usage_min 0.2150 (0.2140) gate/usage_std 0.1550 (0.1538) teacher/entropy 0.0332 (0.0772) teacher/usage_max 0.5356 (0.6727) teacher/usage_min 0.0058 (0.0180) teacher/usage_std 0.2338 (0.2747) nleep/row_max_mean 1536.3240 (1548.8405) nleep/row_max_std 63.5287 (56.6393) nleep/row_min_mean 1506.2679 (1515.6097) lr 1.7290e-03 eta 0:12:44
epoch [14/50] batch [120/181] time 0.076 (0.116) data 0.000 (0.003) loss 1.6056 (1.4464) teacher_loss 0.2230 (0.2574) loss_zs_kd 0.0261 (0.0292) loss_oracle 0.6927 (0.6333) kd_loss 1.0232 (0.8578) acc 93.7500 (90.8333) gate/entropy 0.9966 (0.9987) gate/usage_max 0.5535 (0.5509) gate/usage_min 0.2151 (0.2142) gate/usage_std 0.1558 (0.1541) teacher/entropy 0.0266 (0.0742) teacher/usage_max 0.5156 (0.6525) teacher/usage_min 0.0000 (0.0181) teacher/usage_std 0.2360 (0.2675) nleep/row_max_mean 1559.3665 (1548.9879) nleep/row_max_std 54.9972 (56.6178) nleep/row_min_mean 1523.7570 (1516.0602) lr 1.7290e-03 eta 0:12:41
epoch [14/50] batch [140/181] time 0.083 (0.116) data 0.000 (0.002) loss 1.5117 (1.4508) teacher_loss 0.2204 (0.2514) loss_zs_kd 0.0376 (0.0296) loss_oracle 0.6673 (0.6357) kd_loss 0.9388 (0.8668) acc 90.6250 (91.1384) gate/entropy 0.9965 (0.9984) gate/usage_max 0.5536 (0.5513) gate/usage_min 0.2156 (0.2144) gate/usage_std 0.1559 (0.1543) teacher/entropy 0.0448 (0.0729) teacher/usage_max 0.5833 (0.6429) teacher/usage_min 0.0288 (0.0183) teacher/usage_std 0.2296 (0.2634) nleep/row_max_mean 1545.3147 (1548.1023) nleep/row_max_std 61.5060 (56.7131) nleep/row_min_mean 1515.0914 (1515.6605) lr 1.7290e-03 eta 0:12:41
epoch [14/50] batch [160/181] time 0.120 (0.116) data 0.000 (0.002) loss 1.4898 (1.4690) teacher_loss 0.1675 (0.2519) loss_zs_kd 0.0336 (0.0309) loss_oracle 0.6708 (0.6434) kd_loss 0.9700 (0.8800) acc 96.8750 (90.9180) gate/entropy 0.9958 (0.9981) gate/usage_max 0.5544 (0.5516) gate/usage_min 0.2158 (0.2145) gate/usage_std 0.1564 (0.1546) teacher/entropy 0.0504 (0.0720) teacher/usage_max 0.5398 (0.6301) teacher/usage_min 0.0759 (0.0194) teacher/usage_std 0.1928 (0.2584) nleep/row_max_mean 1538.6506 (1547.3576) nleep/row_max_std 47.8546 (56.3585) nleep/row_min_mean 1511.3018 (1515.2852) lr 1.7290e-03 eta 0:12:41
epoch [14/50] batch [180/181] time 0.162 (0.118) data 0.000 (0.002) loss 1.3150 (1.4718) teacher_loss 0.2776 (0.2539) loss_zs_kd 0.0168 (0.0313) loss_oracle 0.4650 (0.6355) kd_loss 0.7966 (0.8845) acc 87.5000 (90.9375) gate/entropy 0.9957 (0.9979) gate/usage_max 0.5546 (0.5520) gate/usage_min 0.2161 (0.2147) gate/usage_std 0.1566 (0.1548) teacher/entropy 0.0912 (0.0714) teacher/usage_max 0.6838 (0.6253) teacher/usage_min 0.0190 (0.0202) teacher/usage_std 0.2726 (0.2561) nleep/row_max_mean 1530.3641 (1546.4250) nleep/row_max_std 54.6959 (56.0028) nleep/row_min_mean 1505.4304 (1514.6825) lr 1.7290e-03 eta 0:12:47
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,408
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.4%, epoch: 14 *******
******* Domain p best val test acc: 99.8%, epoch: 14 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [15/50] batch [20/181] time 0.151 (0.166) data 0.000 (0.014) loss 1.6193 (1.3965) teacher_loss 0.3704 (0.2216) loss_zs_kd 0.0339 (0.0333) loss_oracle 0.5572 (0.5422) kd_loss 0.9533 (0.8872) acc 81.2500 (91.4062) gate/entropy 0.9950 (0.9954) gate/usage_max 0.5554 (0.5550) gate/usage_min 0.2163 (0.2162) gate/usage_std 0.1571 (0.1568) teacher/entropy 0.0965 (0.0663) teacher/usage_max 0.5111 (0.6186) teacher/usage_min 0.0121 (0.0286) teacher/usage_std 0.2276 (0.2481) nleep/row_max_mean 1544.7539 (1539.9810) nleep/row_max_std 48.8857 (50.0980) nleep/row_min_mean 1518.7249 (1511.0254) lr 1.6845e-03 eta 0:17:56
epoch [15/50] batch [40/181] time 0.148 (0.159) data 0.000 (0.007) loss 1.3941 (1.4205) teacher_loss 0.1105 (0.2224) loss_zs_kd 0.0146 (0.0347) loss_oracle 0.6676 (0.5759) kd_loss 0.9425 (0.8927) acc 96.8750 (91.3281) gate/entropy 0.9949 (0.9951) gate/usage_max 0.5555 (0.5553) gate/usage_min 0.2166 (0.2163) gate/usage_std 0.1572 (0.1570) teacher/entropy 0.0891 (0.0508) teacher/usage_max 0.5270 (0.6275) teacher/usage_min 0.0530 (0.0238) teacher/usage_std 0.2030 (0.2553) nleep/row_max_mean 1527.9427 (1540.9001) nleep/row_max_std 64.2105 (52.0991) nleep/row_min_mean 1499.7235 (1510.4133) lr 1.6845e-03 eta 0:17:06
epoch [15/50] batch [60/181] time 0.161 (0.157) data 0.000 (0.005) loss 1.5848 (1.4320) teacher_loss 0.2072 (0.2221) loss_zs_kd 0.0629 (0.0352) loss_oracle 0.6798 (0.5884) kd_loss 1.0063 (0.8982) acc 93.7500 (91.4583) gate/entropy 0.9943 (0.9949) gate/usage_max 0.5562 (0.5555) gate/usage_min 0.2167 (0.2164) gate/usage_std 0.1577 (0.1572) teacher/entropy 0.0862 (0.0476) teacher/usage_max 0.4984 (0.6266) teacher/usage_min 0.0387 (0.0214) teacher/usage_std 0.2089 (0.2549) nleep/row_max_mean 1537.3895 (1540.8011) nleep/row_max_std 53.3041 (52.1795) nleep/row_min_mean 1509.2854 (1509.9209) lr 1.6845e-03 eta 0:16:50
epoch [15/50] batch [80/181] time 0.103 (0.145) data 0.000 (0.004) loss 1.5663 (1.4290) teacher_loss 0.3063 (0.2221) loss_zs_kd 0.0369 (0.0332) loss_oracle 0.6979 (0.5975) kd_loss 0.8927 (0.8916) acc 81.2500 (91.2500) gate/entropy 0.9937 (0.9947) gate/usage_max 0.5569 (0.5558) gate/usage_min 0.2168 (0.2165) gate/usage_std 0.1582 (0.1574) teacher/entropy 0.0242 (0.0455) teacher/usage_max 0.6496 (0.6352) teacher/usage_min 0.0023 (0.0178) teacher/usage_std 0.2645 (0.2595) nleep/row_max_mean 1546.6812 (1540.2669) nleep/row_max_std 53.9064 (52.6309) nleep/row_min_mean 1512.5884 (1509.0957) lr 1.6845e-03 eta 0:15:32
epoch [15/50] batch [100/181] time 0.190 (0.140) data 0.000 (0.003) loss 1.5278 (1.4363) teacher_loss 0.2352 (0.2255) loss_zs_kd 0.0596 (0.0335) loss_oracle 0.6919 (0.6038) kd_loss 0.9169 (0.8921) acc 84.3750 (90.9375) gate/entropy 0.9934 (0.9945) gate/usage_max 0.5572 (0.5560) gate/usage_min 0.2170 (0.2166) gate/usage_std 0.1584 (0.1575) teacher/entropy 0.0532 (0.0452) teacher/usage_max 0.5918 (0.6356) teacher/usage_min 0.0219 (0.0172) teacher/usage_std 0.2357 (0.2595) nleep/row_max_mean 1544.8706 (1540.6129) nleep/row_max_std 43.7923 (51.9118) nleep/row_min_mean 1511.6230 (1509.3135) lr 1.6845e-03 eta 0:15:00
epoch [15/50] batch [120/181] time 0.140 (0.137) data 0.000 (0.003) loss 1.3112 (1.4517) teacher_loss 0.2932 (0.2303) loss_zs_kd 0.0331 (0.0339) loss_oracle 0.5564 (0.6129) kd_loss 0.7232 (0.8980) acc 90.6250 (90.7812) gate/entropy 0.9934 (0.9943) gate/usage_max 0.5572 (0.5563) gate/usage_min 0.2173 (0.2167) gate/usage_std 0.1584 (0.1577) teacher/entropy 0.0519 (0.0452) teacher/usage_max 0.7959 (0.6296) teacher/usage_min 0.0563 (0.0188) teacher/usage_std 0.3292 (0.2568) nleep/row_max_mean 1527.9800 (1540.8951) nleep/row_max_std 61.2869 (51.4725) nleep/row_min_mean 1492.1853 (1509.5605) lr 1.6845e-03 eta 0:14:38
epoch [15/50] batch [140/181] time 0.090 (0.132) data 0.000 (0.002) loss 1.5406 (1.4615) teacher_loss 0.2955 (0.2342) loss_zs_kd 0.0230 (0.0344) loss_oracle 0.6583 (0.6213) kd_loss 0.9044 (0.8994) acc 84.3750 (90.7143) gate/entropy 0.9926 (0.9941) gate/usage_max 0.5581 (0.5565) gate/usage_min 0.2172 (0.2168) gate/usage_std 0.1590 (0.1578) teacher/entropy 0.0043 (0.0455) teacher/usage_max 0.6556 (0.6274) teacher/usage_min 0.0005 (0.0194) teacher/usage_std 0.2675 (0.2555) nleep/row_max_mean 1539.5757 (1540.6850) nleep/row_max_std 58.3063 (51.4111) nleep/row_min_mean 1510.2765 (1509.4557) lr 1.6845e-03 eta 0:14:04
epoch [15/50] batch [160/181] time 0.066 (0.129) data 0.000 (0.002) loss 1.5697 (1.4650) teacher_loss 0.2949 (0.2340) loss_zs_kd 0.0343 (0.0341) loss_oracle 0.7292 (0.6296) kd_loss 0.8930 (0.8992) acc 84.3750 (90.6641) gate/entropy 0.9928 (0.9939) gate/usage_max 0.5579 (0.5566) gate/usage_min 0.2176 (0.2168) gate/usage_std 0.1588 (0.1580) teacher/entropy 0.0301 (0.0447) teacher/usage_max 0.6400 (0.6273) teacher/usage_min 0.0327 (0.0194) teacher/usage_std 0.2480 (0.2552) nleep/row_max_mean 1525.2909 (1540.2952) nleep/row_max_std 50.0941 (51.7713) nleep/row_min_mean 1496.0620 (1509.0038) lr 1.6845e-03 eta 0:13:37
epoch [15/50] batch [180/181] time 0.110 (0.127) data 0.000 (0.002) loss 1.4116 (1.4740) teacher_loss 0.2223 (0.2388) loss_zs_kd 0.0261 (0.0338) loss_oracle 0.6093 (0.6308) kd_loss 0.8716 (0.9029) acc 93.7500 (90.6250) gate/entropy 0.9923 (0.9938) gate/usage_max 0.5584 (0.5568) gate/usage_min 0.2177 (0.2169) gate/usage_std 0.1592 (0.1581) teacher/entropy 0.0386 (0.0443) teacher/usage_max 0.6520 (0.6241) teacher/usage_min 0.0335 (0.0202) teacher/usage_std 0.2529 (0.2540) nleep/row_max_mean 1533.8472 (1540.1423) nleep/row_max_std 45.9604 (51.7785) nleep/row_min_mean 1505.3308 (1508.8755) lr 1.6845e-03 eta 0:13:24
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,409
* accuracy: 96.5%
* error: 3.5%
* macro_f1: 96.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.5%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [16/50] batch [20/181] time 0.068 (0.139) data 0.000 (0.017) loss 1.7708 (1.5600) teacher_loss 0.2091 (0.2496) loss_zs_kd 0.0463 (0.0346) loss_oracle 0.8004 (0.6635) kd_loss 1.1384 (0.9614) acc 90.6250 (89.6875) gate/entropy 0.9917 (0.9923) gate/usage_max 0.5591 (0.5585) gate/usage_min 0.2176 (0.2178) gate/usage_std 0.1597 (0.1592) teacher/entropy 0.0630 (0.0356) teacher/usage_max 0.6260 (0.5959) teacher/usage_min 0.0313 (0.0235) teacher/usage_std 0.2429 (0.2417) nleep/row_max_mean 1562.2573 (1539.7938) nleep/row_max_std 37.2907 (54.5291) nleep/row_min_mean 1528.0405 (1507.8535) lr 1.6374e-03 eta 0:14:38
epoch [16/50] batch [40/181] time 0.163 (0.132) data 0.000 (0.009) loss 1.3521 (1.5331) teacher_loss 0.1287 (0.2364) loss_zs_kd 0.0293 (0.0370) loss_oracle 0.6419 (0.6654) kd_loss 0.8878 (0.9455) acc 96.8750 (90.9375) gate/entropy 0.9923 (0.9923) gate/usage_max 0.5585 (0.5585) gate/usage_min 0.2182 (0.2179) gate/usage_std 0.1592 (0.1592) teacher/entropy 0.0266 (0.0307) teacher/usage_max 0.6487 (0.6019) teacher/usage_min 0.0000 (0.0188) teacher/usage_std 0.2651 (0.2457) nleep/row_max_mean 1532.3228 (1538.2885) nleep/row_max_std 76.2431 (57.4941) nleep/row_min_mean 1497.3391 (1505.9195) lr 1.6374e-03 eta 0:13:53
epoch [16/50] batch [60/181] time 0.165 (0.140) data 0.000 (0.006) loss 1.4896 (1.5161) teacher_loss 0.2141 (0.2320) loss_zs_kd 0.0303 (0.0376) loss_oracle 0.6613 (0.6495) kd_loss 0.9297 (0.9406) acc 93.7500 (91.1979) gate/entropy 0.9918 (0.9922) gate/usage_max 0.5590 (0.5586) gate/usage_min 0.2182 (0.2180) gate/usage_std 0.1596 (0.1593) teacher/entropy 0.0267 (0.0313) teacher/usage_max 0.6028 (0.6003) teacher/usage_min 0.0000 (0.0193) teacher/usage_std 0.2502 (0.2452) nleep/row_max_mean 1544.8174 (1538.8040) nleep/row_max_std 63.1309 (57.1308) nleep/row_min_mean 1509.9993 (1506.2050) lr 1.6374e-03 eta 0:14:37
epoch [16/50] batch [80/181] time 0.156 (0.144) data 0.000 (0.004) loss 1.6868 (1.5007) teacher_loss 0.2026 (0.2231) loss_zs_kd 0.0287 (0.0367) loss_oracle 0.7840 (0.6435) kd_loss 1.0779 (0.9374) acc 93.7500 (91.5625) gate/entropy 0.9917 (0.9921) gate/usage_max 0.5591 (0.5586) gate/usage_min 0.2184 (0.2181) gate/usage_std 0.1596 (0.1593) teacher/entropy 0.0032 (0.0332) teacher/usage_max 0.5001 (0.5993) teacher/usage_min 0.0309 (0.0206) teacher/usage_std 0.2143 (0.2442) nleep/row_max_mean 1542.4264 (1539.1042) nleep/row_max_std 57.5194 (57.1765) nleep/row_min_mean 1508.5664 (1506.5031) lr 1.6374e-03 eta 0:14:58
epoch [16/50] batch [100/181] time 0.133 (0.145) data 0.000 (0.004) loss 1.5976 (1.5161) teacher_loss 0.1764 (0.2218) loss_zs_kd 0.0599 (0.0391) loss_oracle 0.7206 (0.6648) kd_loss 1.0310 (0.9423) acc 93.7500 (91.6562) gate/entropy 0.9915 (0.9921) gate/usage_max 0.5594 (0.5587) gate/usage_min 0.2185 (0.2182) gate/usage_std 0.1598 (0.1594) teacher/entropy 0.0608 (0.0326) teacher/usage_max 0.5247 (0.5990) teacher/usage_min 0.0177 (0.0216) teacher/usage_std 0.2249 (0.2439) nleep/row_max_mean 1549.4952 (1539.4863) nleep/row_max_std 48.2844 (56.3740) nleep/row_min_mean 1517.0789 (1506.9625) lr 1.6374e-03 eta 0:15:02
epoch [16/50] batch [120/181] time 0.157 (0.147) data 0.000 (0.003) loss 1.5446 (1.5174) teacher_loss 0.2049 (0.2260) loss_zs_kd 0.0481 (0.0387) loss_oracle 0.6662 (0.6572) kd_loss 0.9826 (0.9434) acc 93.7500 (91.5365) gate/entropy 0.9914 (0.9920) gate/usage_max 0.5594 (0.5588) gate/usage_min 0.2187 (0.2182) gate/usage_std 0.1599 (0.1594) teacher/entropy 0.0138 (0.0319) teacher/usage_max 0.5590 (0.6001) teacher/usage_min 0.0000 (0.0200) teacher/usage_std 0.2406 (0.2452) nleep/row_max_mean 1550.4012 (1539.7233) nleep/row_max_std 62.0055 (56.2858) nleep/row_min_mean 1515.9043 (1507.2470) lr 1.6374e-03 eta 0:15:11
epoch [16/50] batch [140/181] time 0.168 (0.148) data 0.000 (0.003) loss 1.5440 (1.5115) teacher_loss 0.2980 (0.2206) loss_zs_kd 0.0494 (0.0387) loss_oracle 0.6417 (0.6582) kd_loss 0.9004 (0.9425) acc 81.2500 (91.7857) gate/entropy 0.9915 (0.9919) gate/usage_max 0.5593 (0.5589) gate/usage_min 0.2190 (0.2183) gate/usage_std 0.1598 (0.1595) teacher/entropy 0.0040 (0.0315) teacher/usage_max 0.6559 (0.5991) teacher/usage_min 0.0312 (0.0195) teacher/usage_std 0.2554 (0.2450) nleep/row_max_mean 1541.9221 (1540.7056) nleep/row_max_std 57.3507 (56.5513) nleep/row_min_mean 1508.0339 (1507.9556) lr 1.6374e-03 eta 0:15:16
epoch [16/50] batch [160/181] time 0.089 (0.144) data 0.000 (0.002) loss 1.6950 (1.5155) teacher_loss 0.3014 (0.2196) loss_zs_kd 0.0605 (0.0395) loss_oracle 0.7929 (0.6668) kd_loss 0.9670 (0.9427) acc 87.5000 (91.8945) gate/entropy 0.9913 (0.9919) gate/usage_max 0.5596 (0.5589) gate/usage_min 0.2191 (0.2184) gate/usage_std 0.1600 (0.1595) teacher/entropy 0.0423 (0.0308) teacher/usage_max 0.5450 (0.5998) teacher/usage_min 0.0000 (0.0184) teacher/usage_std 0.2385 (0.2456) nleep/row_max_mean 1553.0896 (1540.7090) nleep/row_max_std 58.2225 (56.9424) nleep/row_min_mean 1516.3029 (1507.9360) lr 1.6374e-03 eta 0:14:49
epoch [16/50] batch [180/181] time 0.101 (0.141) data 0.000 (0.002) loss 1.6107 (1.5168) teacher_loss 0.3313 (0.2241) loss_zs_kd 0.0277 (0.0396) loss_oracle 0.5636 (0.6619) kd_loss 0.9837 (0.9419) acc 87.5000 (91.6493) gate/entropy 0.9913 (0.9918) gate/usage_max 0.5596 (0.5590) gate/usage_min 0.2193 (0.2185) gate/usage_std 0.1600 (0.1596) teacher/entropy 0.0351 (0.0303) teacher/usage_max 0.5340 (0.5999) teacher/usage_min 0.0002 (0.0189) teacher/usage_std 0.2372 (0.2455) nleep/row_max_mean 1536.5397 (1541.4182) nleep/row_max_std 46.1918 (56.8048) nleep/row_min_mean 1508.5964 (1508.6295) lr 1.6374e-03 eta 0:14:28
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,407
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.9%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.5%, epoch: 15 *******
******* Domain p best val test acc: 99.8%, epoch: 15 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [17/50] batch [20/181] time 0.072 (0.133) data 0.000 (0.019) loss 1.8960 (1.4673) teacher_loss 0.4720 (0.2311) loss_zs_kd 0.0764 (0.0399) loss_oracle 0.6197 (0.5788) kd_loss 1.0760 (0.9269) acc 84.3750 (92.3438) gate/entropy 0.9910 (0.9912) gate/usage_max 0.5599 (0.5597) gate/usage_min 0.2194 (0.2194) gate/usage_std 0.1602 (0.1600) teacher/entropy 0.0214 (0.0379) teacher/usage_max 0.5201 (0.5963) teacher/usage_min 0.0313 (0.0280) teacher/usage_std 0.2156 (0.2389) nleep/row_max_mean 1541.2297 (1544.0885) nleep/row_max_std 58.6159 (56.4945) nleep/row_min_mean 1511.4791 (1511.9499) lr 1.5878e-03 eta 0:13:37
epoch [17/50] batch [40/181] time 0.065 (0.122) data 0.000 (0.009) loss 1.5161 (1.4841) teacher_loss 0.3241 (0.2410) loss_zs_kd 0.0429 (0.0389) loss_oracle 0.5832 (0.5882) kd_loss 0.8789 (0.9296) acc 90.6250 (91.3281) gate/entropy 0.9912 (0.9912) gate/usage_max 0.5597 (0.5597) gate/usage_min 0.2196 (0.2194) gate/usage_std 0.1601 (0.1601) teacher/entropy 0.0374 (0.0347) teacher/usage_max 0.6421 (0.6012) teacher/usage_min 0.0427 (0.0275) teacher/usage_std 0.2450 (0.2413) nleep/row_max_mean 1536.0271 (1545.8893) nleep/row_max_std 60.8367 (56.9728) nleep/row_min_mean 1503.4802 (1513.2409) lr 1.5878e-03 eta 0:12:24
epoch [17/50] batch [60/181] time 0.093 (0.119) data 0.001 (0.006) loss 1.3911 (1.4624) teacher_loss 0.3137 (0.2298) loss_zs_kd 0.0339 (0.0380) loss_oracle 0.5457 (0.5925) kd_loss 0.7875 (0.9174) acc 84.3750 (91.3021) gate/entropy 0.9909 (0.9911) gate/usage_max 0.5600 (0.5598) gate/usage_min 0.2196 (0.2195) gate/usage_std 0.1603 (0.1601) teacher/entropy 0.0645 (0.0354) teacher/usage_max 0.7100 (0.6107) teacher/usage_min 0.0296 (0.0292) teacher/usage_std 0.2825 (0.2445) nleep/row_max_mean 1540.9177 (1545.5165) nleep/row_max_std 63.3961 (57.9088) nleep/row_min_mean 1510.2924 (1512.6784) lr 1.5878e-03 eta 0:12:07
epoch [17/50] batch [80/181] time 0.083 (0.118) data 0.000 (0.005) loss 1.6673 (1.4558) teacher_loss 0.2857 (0.2318) loss_zs_kd 0.0417 (0.0387) loss_oracle 0.7464 (0.5968) kd_loss 0.9876 (0.9062) acc 90.6250 (91.5234) gate/entropy 0.9906 (0.9911) gate/usage_max 0.5604 (0.5598) gate/usage_min 0.2196 (0.2196) gate/usage_std 0.1605 (0.1602) teacher/entropy 0.0491 (0.0377) teacher/usage_max 0.5126 (0.6187) teacher/usage_min 0.0290 (0.0295) teacher/usage_std 0.2163 (0.2473) nleep/row_max_mean 1547.7312 (1545.0747) nleep/row_max_std 55.1740 (58.4118) nleep/row_min_mean 1512.8138 (1511.9074) lr 1.5878e-03 eta 0:11:58
epoch [17/50] batch [100/181] time 0.117 (0.117) data 0.000 (0.004) loss 1.2156 (1.4358) teacher_loss 0.1338 (0.2256) loss_zs_kd 0.0250 (0.0373) loss_oracle 0.5625 (0.5963) kd_loss 0.7880 (0.8934) acc 96.8750 (91.9688) gate/entropy 0.9910 (0.9910) gate/usage_max 0.5599 (0.5599) gate/usage_min 0.2200 (0.2196) gate/usage_std 0.1602 (0.1602) teacher/entropy 0.0414 (0.0405) teacher/usage_max 0.7340 (0.6282) teacher/usage_min 0.0309 (0.0287) teacher/usage_std 0.2953 (0.2508) nleep/row_max_mean 1539.0594 (1543.7677) nleep/row_max_std 59.6223 (57.8701) nleep/row_min_mean 1506.6694 (1510.8725) lr 1.5878e-03 eta 0:11:46
epoch [17/50] batch [120/181] time 0.093 (0.117) data 0.000 (0.003) loss 1.2864 (1.4245) teacher_loss 0.2322 (0.2284) loss_zs_kd 0.0267 (0.0367) loss_oracle 0.5126 (0.5887) kd_loss 0.7845 (0.8834) acc 87.5000 (91.6927) gate/entropy 0.9912 (0.9910) gate/usage_max 0.5597 (0.5599) gate/usage_min 0.2200 (0.2197) gate/usage_std 0.1601 (0.1602) teacher/entropy 0.0708 (0.0420) teacher/usage_max 0.7065 (0.6364) teacher/usage_min 0.0011 (0.0271) teacher/usage_std 0.2894 (0.2546) nleep/row_max_mean 1516.4998 (1543.1124) nleep/row_max_std 52.3641 (57.2677) nleep/row_min_mean 1487.4570 (1510.2824) lr 1.5878e-03 eta 0:11:46
epoch [17/50] batch [140/181] time 0.163 (0.122) data 0.000 (0.003) loss 1.4590 (1.4048) teacher_loss 0.3663 (0.2305) loss_zs_kd 0.0560 (0.0365) loss_oracle 0.4721 (0.5734) kd_loss 0.8287 (0.8695) acc 84.3750 (91.7411) gate/entropy 0.9900 (0.9909) gate/usage_max 0.5610 (0.5600) gate/usage_min 0.2193 (0.2196) gate/usage_std 0.1610 (0.1603) teacher/entropy 0.0714 (0.0467) teacher/usage_max 0.6568 (0.6462) teacher/usage_min 0.0312 (0.0270) teacher/usage_std 0.2558 (0.2592) nleep/row_max_mean 1559.6586 (1543.0859) nleep/row_max_std 53.2272 (57.0625) nleep/row_min_mean 1524.3022 (1510.2859) lr 1.5878e-03 eta 0:12:14
epoch [17/50] batch [160/181] time 0.160 (0.126) data 0.000 (0.003) loss 1.1909 (1.3882) teacher_loss 0.2608 (0.2362) loss_zs_kd 0.0316 (0.0360) loss_oracle 0.4924 (0.5594) kd_loss 0.6681 (0.8543) acc 87.5000 (91.5234) gate/entropy 0.9897 (0.9908) gate/usage_max 0.5613 (0.5601) gate/usage_min 0.2190 (0.2196) gate/usage_std 0.1612 (0.1604) teacher/entropy 0.0242 (0.0463) teacher/usage_max 0.8778 (0.6621) teacher/usage_min 0.0000 (0.0273) teacher/usage_std 0.3882 (0.2669) nleep/row_max_mean 1561.0956 (1542.9397) nleep/row_max_std 63.7251 (57.3685) nleep/row_min_mean 1522.8866 (1510.0292) lr 1.5878e-03 eta 0:12:37
epoch [17/50] batch [180/181] time 0.125 (0.128) data 0.000 (0.002) loss 1.1458 (1.3688) teacher_loss 0.1910 (0.2399) loss_zs_kd 0.0271 (0.0357) loss_oracle 0.4939 (0.5483) kd_loss 0.6944 (0.8370) acc 93.7500 (91.3021) gate/entropy 0.9899 (0.9907) gate/usage_max 0.5610 (0.5602) gate/usage_min 0.2191 (0.2196) gate/usage_std 0.1610 (0.1604) teacher/entropy 0.0290 (0.0443) teacher/usage_max 0.8453 (0.6821) teacher/usage_min 0.0305 (0.0271) teacher/usage_std 0.3640 (0.2777) nleep/row_max_mean 1544.3206 (1543.0891) nleep/row_max_std 68.4496 (57.8348) nleep/row_min_mean 1505.7385 (1509.8471) lr 1.5878e-03 eta 0:12:46
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,411
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.6%, epoch: 17 *******
******* Domain p best val test acc: 99.8%, epoch: 17 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [18/50] batch [20/181] time 0.150 (0.151) data 0.000 (0.012) loss 1.2746 (1.1886) teacher_loss 0.2232 (0.2133) loss_zs_kd 0.0379 (0.0380) loss_oracle 0.5555 (0.4910) kd_loss 0.7546 (0.7107) acc 90.6250 (92.6562) gate/entropy 0.9896 (0.9897) gate/usage_max 0.5614 (0.5613) gate/usage_min 0.2189 (0.2190) gate/usage_std 0.1613 (0.1612) teacher/entropy 0.0200 (0.0261) teacher/usage_max 0.7903 (0.8308) teacher/usage_min 0.0623 (0.0340) teacher/usage_std 0.3250 (0.3553) nleep/row_max_mean 1549.3469 (1544.2161) nleep/row_max_std 56.9606 (58.4696) nleep/row_min_mean 1508.0073 (1508.2913) lr 1.5358e-03 eta 0:14:59
epoch [18/50] batch [40/181] time 0.172 (0.133) data 0.000 (0.006) loss 1.1353 (1.2241) teacher_loss 0.1198 (0.2377) loss_zs_kd 0.0250 (0.0379) loss_oracle 0.5279 (0.4964) kd_loss 0.7391 (0.7193) acc 93.7500 (91.4062) gate/entropy 0.9891 (0.9895) gate/usage_max 0.5619 (0.5615) gate/usage_min 0.2186 (0.2189) gate/usage_std 0.1616 (0.1613) teacher/entropy 0.0287 (0.0264) teacher/usage_max 0.7973 (0.8210) teacher/usage_min 0.0479 (0.0318) teacher/usage_std 0.3309 (0.3498) nleep/row_max_mean 1547.2451 (1544.8427) nleep/row_max_std 62.2011 (60.3629) nleep/row_min_mean 1511.5127 (1508.9882) lr 1.5358e-03 eta 0:13:06
epoch [18/50] batch [60/181] time 0.165 (0.130) data 0.001 (0.004) loss 1.3468 (1.2182) teacher_loss 0.3245 (0.2373) loss_zs_kd 0.0404 (0.0353) loss_oracle 0.4998 (0.4929) kd_loss 0.7522 (0.7168) acc 84.3750 (90.9375) gate/entropy 0.9887 (0.9893) gate/usage_max 0.5624 (0.5617) gate/usage_min 0.2183 (0.2188) gate/usage_std 0.1620 (0.1615) teacher/entropy 0.0698 (0.0269) teacher/usage_max 0.7386 (0.8229) teacher/usage_min 0.0584 (0.0295) teacher/usage_std 0.2925 (0.3511) nleep/row_max_mean 1548.1384 (1546.6350) nleep/row_max_std 65.5686 (61.0400) nleep/row_min_mean 1514.4304 (1510.4920) lr 1.5358e-03 eta 0:12:48
epoch [18/50] batch [80/181] time 0.074 (0.127) data 0.000 (0.003) loss 1.2301 (1.2254) teacher_loss 0.2731 (0.2396) loss_zs_kd 0.0366 (0.0350) loss_oracle 0.4985 (0.4990) kd_loss 0.6895 (0.7188) acc 84.3750 (90.7422) gate/entropy 0.9885 (0.9892) gate/usage_max 0.5625 (0.5618) gate/usage_min 0.2182 (0.2187) gate/usage_std 0.1621 (0.1616) teacher/entropy 0.0049 (0.0258) teacher/usage_max 0.8741 (0.8218) teacher/usage_min 0.0005 (0.0273) teacher/usage_std 0.3858 (0.3505) nleep/row_max_mean 1545.1484 (1547.0788) nleep/row_max_std 58.7135 (61.6133) nleep/row_min_mean 1511.0215 (1511.1577) lr 1.5358e-03 eta 0:12:28
epoch [18/50] batch [100/181] time 0.096 (0.122) data 0.000 (0.003) loss 1.2403 (1.2325) teacher_loss 0.3239 (0.2471) loss_zs_kd 0.0298 (0.0342) loss_oracle 0.5118 (0.5006) kd_loss 0.6456 (0.7180) acc 90.6250 (90.6875) gate/entropy 0.9882 (0.9890) gate/usage_max 0.5629 (0.5620) gate/usage_min 0.2180 (0.2186) gate/usage_std 0.1624 (0.1617) teacher/entropy 0.0312 (0.0252) teacher/usage_max 0.8918 (0.8231) teacher/usage_min 0.0090 (0.0258) teacher/usage_std 0.3966 (0.3514) nleep/row_max_mean 1558.2278 (1547.6617) nleep/row_max_std 54.0107 (61.0624) nleep/row_min_mean 1518.9258 (1511.7600) lr 1.5358e-03 eta 0:11:55
epoch [18/50] batch [120/181] time 0.106 (0.119) data 0.000 (0.002) loss 1.1127 (1.2285) teacher_loss 0.1114 (0.2475) loss_zs_kd 0.0312 (0.0342) loss_oracle 0.5386 (0.4999) kd_loss 0.7164 (0.7140) acc 96.8750 (90.6771) gate/entropy 0.9882 (0.9889) gate/usage_max 0.5629 (0.5621) gate/usage_min 0.2180 (0.2185) gate/usage_std 0.1623 (0.1618) teacher/entropy 0.0217 (0.0245) teacher/usage_max 0.8275 (0.8278) teacher/usage_min 0.0162 (0.0255) teacher/usage_std 0.3541 (0.3545) nleep/row_max_mean 1542.7200 (1546.4831) nleep/row_max_std 61.6368 (61.2823) nleep/row_min_mean 1506.4199 (1510.8046) lr 1.5358e-03 eta 0:11:38
epoch [18/50] batch [140/181] time 0.158 (0.119) data 0.000 (0.002) loss 1.1030 (1.2260) teacher_loss 0.2464 (0.2485) loss_zs_kd 0.0344 (0.0340) loss_oracle 0.4624 (0.4968) kd_loss 0.6082 (0.7121) acc 93.7500 (90.5357) gate/entropy 0.9881 (0.9888) gate/usage_max 0.5630 (0.5623) gate/usage_min 0.2179 (0.2184) gate/usage_std 0.1624 (0.1619) teacher/entropy 0.0206 (0.0250) teacher/usage_max 0.9427 (0.8292) teacher/usage_min 0.0005 (0.0247) teacher/usage_std 0.4315 (0.3555) nleep/row_max_mean 1539.4016 (1546.1023) nleep/row_max_std 57.2930 (60.5477) nleep/row_min_mean 1501.1254 (1510.5324) lr 1.5358e-03 eta 0:11:35
epoch [18/50] batch [160/181] time 0.086 (0.121) data 0.000 (0.002) loss 1.4542 (1.2264) teacher_loss 0.3670 (0.2469) loss_zs_kd 0.0307 (0.0337) loss_oracle 0.5543 (0.4995) kd_loss 0.7947 (0.7129) acc 84.3750 (90.6445) gate/entropy 0.9876 (0.9886) gate/usage_max 0.5636 (0.5624) gate/usage_min 0.2176 (0.2183) gate/usage_std 0.1628 (0.1620) teacher/entropy 0.0130 (0.0247) teacher/usage_max 0.7532 (0.8284) teacher/usage_min 0.0001 (0.0244) teacher/usage_std 0.3135 (0.3552) nleep/row_max_mean 1537.4027 (1545.0951) nleep/row_max_std 61.9465 (60.1963) nleep/row_min_mean 1503.6526 (1509.6562) lr 1.5358e-03 eta 0:11:42
epoch [18/50] batch [180/181] time 0.079 (0.120) data 0.000 (0.002) loss 1.1547 (1.2294) teacher_loss 0.2478 (0.2458) loss_zs_kd 0.0437 (0.0341) loss_oracle 0.5121 (0.5037) kd_loss 0.6289 (0.7147) acc 93.7500 (90.7118) gate/entropy 0.9875 (0.9885) gate/usage_max 0.5636 (0.5626) gate/usage_min 0.2176 (0.2182) gate/usage_std 0.1628 (0.1621) teacher/entropy 0.0633 (0.0241) teacher/usage_max 0.8748 (0.8270) teacher/usage_min 0.0625 (0.0241) teacher/usage_std 0.3829 (0.3544) nleep/row_max_mean 1532.9944 (1545.3930) nleep/row_max_std 59.5622 (59.6979) nleep/row_min_mean 1492.9578 (1509.8424) lr 1.5358e-03 eta 0:11:36
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,416
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 97.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.8%, epoch: 18 *******
******* Domain p best val test acc: 99.8%, epoch: 18 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [19/50] batch [20/181] time 0.164 (0.150) data 0.000 (0.014) loss 1.1649 (1.1790) teacher_loss 0.1343 (0.2184) loss_zs_kd 0.0441 (0.0363) loss_oracle 0.5269 (0.4978) kd_loss 0.7451 (0.6935) acc 96.8750 (91.8750) gate/entropy 0.9872 (0.9872) gate/usage_max 0.5640 (0.5639) gate/usage_min 0.2174 (0.2174) gate/usage_std 0.1631 (0.1631) teacher/entropy 0.0054 (0.0218) teacher/usage_max 0.8130 (0.8502) teacher/usage_min 0.0003 (0.0195) teacher/usage_std 0.3476 (0.3689) nleep/row_max_mean 1533.2186 (1543.9345) nleep/row_max_std 55.6608 (55.9657) nleep/row_min_mean 1499.6866 (1508.1715) lr 1.4818e-03 eta 0:14:28
epoch [19/50] batch [40/181] time 0.150 (0.149) data 0.000 (0.007) loss 1.0335 (1.1882) teacher_loss 0.1480 (0.2268) loss_zs_kd 0.0264 (0.0377) loss_oracle 0.4564 (0.4991) kd_loss 0.6441 (0.6930) acc 96.8750 (91.5625) gate/entropy 0.9871 (0.9871) gate/usage_max 0.5641 (0.5641) gate/usage_min 0.2173 (0.2173) gate/usage_std 0.1632 (0.1631) teacher/entropy 0.0667 (0.0281) teacher/usage_max 0.8546 (0.8438) teacher/usage_min 0.0370 (0.0214) teacher/usage_std 0.3697 (0.3649) nleep/row_max_mean 1522.3116 (1541.1698) nleep/row_max_std 50.7262 (54.6777) nleep/row_min_mean 1492.2375 (1506.4229) lr 1.4818e-03 eta 0:14:19
epoch [19/50] batch [60/181] time 0.125 (0.146) data 0.000 (0.005) loss 1.4273 (1.2050) teacher_loss 0.3389 (0.2328) loss_zs_kd 0.0499 (0.0362) loss_oracle 0.5233 (0.4974) kd_loss 0.8018 (0.7055) acc 84.3750 (91.3021) gate/entropy 0.9863 (0.9870) gate/usage_max 0.5648 (0.5642) gate/usage_min 0.2169 (0.2173) gate/usage_std 0.1637 (0.1632) teacher/entropy 0.0226 (0.0289) teacher/usage_max 0.7341 (0.8296) teacher/usage_min 0.0001 (0.0272) teacher/usage_std 0.3035 (0.3554) nleep/row_max_mean 1552.8550 (1541.0488) nleep/row_max_std 55.3344 (53.9460) nleep/row_min_mean 1521.1340 (1507.0772) lr 1.4818e-03 eta 0:13:54
epoch [19/50] batch [80/181] time 0.137 (0.145) data 0.000 (0.004) loss 1.2046 (1.2057) teacher_loss 0.1887 (0.2342) loss_zs_kd 0.0376 (0.0351) loss_oracle 0.5014 (0.4926) kd_loss 0.7464 (0.7077) acc 90.6250 (91.1719) gate/entropy 0.9865 (0.9868) gate/usage_max 0.5647 (0.5643) gate/usage_min 0.2170 (0.2172) gate/usage_std 0.1636 (0.1633) teacher/entropy 0.0042 (0.0277) teacher/usage_max 0.8118 (0.8284) teacher/usage_min 0.0319 (0.0265) teacher/usage_std 0.3421 (0.3546) nleep/row_max_mean 1538.6788 (1541.8166) nleep/row_max_std 52.2863 (53.3767) nleep/row_min_mean 1506.5710 (1508.1018) lr 1.4818e-03 eta 0:13:48
epoch [19/50] batch [100/181] time 0.138 (0.144) data 0.000 (0.003) loss 1.5305 (1.2152) teacher_loss 0.4525 (0.2371) loss_zs_kd 0.0552 (0.0347) loss_oracle 0.5469 (0.4959) kd_loss 0.7770 (0.7127) acc 84.3750 (91.2188) gate/entropy 0.9863 (0.9868) gate/usage_max 0.5649 (0.5644) gate/usage_min 0.2169 (0.2171) gate/usage_std 0.1637 (0.1634) teacher/entropy 0.0485 (0.0291) teacher/usage_max 0.7335 (0.8215) teacher/usage_min 0.0724 (0.0312) teacher/usage_std 0.2873 (0.3499) nleep/row_max_mean 1540.3900 (1541.8272) nleep/row_max_std 48.3608 (53.5704) nleep/row_min_mean 1503.8406 (1508.1957) lr 1.4818e-03 eta 0:13:39
epoch [19/50] batch [120/181] time 0.134 (0.143) data 0.000 (0.002) loss 1.2279 (1.2205) teacher_loss 0.2690 (0.2351) loss_zs_kd 0.0290 (0.0354) loss_oracle 0.5228 (0.5012) kd_loss 0.6830 (0.7171) acc 87.5000 (91.2240) gate/entropy 0.9862 (0.9866) gate/usage_max 0.5650 (0.5645) gate/usage_min 0.2168 (0.2171) gate/usage_std 0.1638 (0.1635) teacher/entropy 0.0351 (0.0286) teacher/usage_max 0.8456 (0.8173) teacher/usage_min 0.0659 (0.0317) teacher/usage_std 0.3624 (0.3473) nleep/row_max_mean 1541.2161 (1542.9450) nleep/row_max_std 62.3048 (53.7738) nleep/row_min_mean 1504.7939 (1509.3081) lr 1.4818e-03 eta 0:13:32
epoch [19/50] batch [140/181] time 0.096 (0.140) data 0.000 (0.002) loss 1.1548 (1.2236) teacher_loss 0.2718 (0.2347) loss_zs_kd 0.0445 (0.0350) loss_oracle 0.4342 (0.5024) kd_loss 0.6436 (0.7202) acc 84.3750 (91.1830) gate/entropy 0.9859 (0.9865) gate/usage_max 0.5653 (0.5646) gate/usage_min 0.2166 (0.2170) gate/usage_std 0.1641 (0.1635) teacher/entropy 0.0353 (0.0296) teacher/usage_max 0.8860 (0.8129) teacher/usage_min 0.0044 (0.0326) teacher/usage_std 0.3931 (0.3444) nleep/row_max_mean 1551.4611 (1543.3872) nleep/row_max_std 50.5368 (53.8913) nleep/row_min_mean 1518.6819 (1509.8679) lr 1.4818e-03 eta 0:13:09
epoch [19/50] batch [160/181] time 0.185 (0.136) data 0.000 (0.002) loss 1.0538 (1.2221) teacher_loss 0.1677 (0.2324) loss_zs_kd 0.0280 (0.0348) loss_oracle 0.4853 (0.5011) kd_loss 0.6294 (0.7217) acc 93.7500 (91.2891) gate/entropy 0.9857 (0.9865) gate/usage_max 0.5656 (0.5647) gate/usage_min 0.2165 (0.2170) gate/usage_std 0.1642 (0.1636) teacher/entropy 0.0339 (0.0316) teacher/usage_max 0.9023 (0.8092) teacher/usage_min 0.0084 (0.0363) teacher/usage_std 0.4037 (0.3415) nleep/row_max_mean 1556.7852 (1543.4144) nleep/row_max_std 58.4129 (54.9509) nleep/row_min_mean 1521.1245 (1510.0428) lr 1.4818e-03 eta 0:12:48
epoch [19/50] batch [180/181] time 0.173 (0.135) data 0.000 (0.002) loss 1.4241 (1.2256) teacher_loss 0.5172 (0.2320) loss_zs_kd 0.0458 (0.0345) loss_oracle 0.3942 (0.5009) kd_loss 0.6869 (0.7259) acc 81.2500 (91.3542) gate/entropy 0.9855 (0.9864) gate/usage_max 0.5657 (0.5648) gate/usage_min 0.2164 (0.2169) gate/usage_std 0.1643 (0.1637) teacher/entropy 0.0021 (0.0319) teacher/usage_max 0.8748 (0.8043) teacher/usage_min 0.0002 (0.0386) teacher/usage_std 0.3862 (0.3381) nleep/row_max_mean 1544.8643 (1543.4924) nleep/row_max_std 40.4301 (55.3158) nleep/row_min_mean 1513.2289 (1510.4662) lr 1.4818e-03 eta 0:12:36
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,414
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.8%, epoch: 18 *******
******* Domain p best val test acc: 99.8%, epoch: 18 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [20/50] batch [20/181] time 0.083 (0.131) data 0.000 (0.016) loss 1.1919 (1.1860) teacher_loss 0.1964 (0.2180) loss_zs_kd 0.0340 (0.0321) loss_oracle 0.5108 (0.4806) kd_loss 0.7231 (0.7116) acc 90.6250 (92.8125) gate/entropy 0.9854 (0.9855) gate/usage_max 0.5659 (0.5657) gate/usage_min 0.2163 (0.2164) gate/usage_std 0.1644 (0.1643) teacher/entropy 0.0466 (0.0456) teacher/usage_max 0.7902 (0.8039) teacher/usage_min 0.0302 (0.0580) teacher/usage_std 0.3288 (0.3350) nleep/row_max_mean 1549.0554 (1545.7976) nleep/row_max_std 71.9782 (54.2909) nleep/row_min_mean 1517.3787 (1514.7072) lr 1.4258e-03 eta 0:12:13
epoch [20/50] batch [40/181] time 0.071 (0.126) data 0.000 (0.008) loss 1.3052 (1.2333) teacher_loss 0.2101 (0.2139) loss_zs_kd 0.0395 (0.0333) loss_oracle 0.5027 (0.5023) kd_loss 0.8240 (0.7516) acc 93.7500 (92.3438) gate/entropy 0.9855 (0.9855) gate/usage_max 0.5657 (0.5658) gate/usage_min 0.2164 (0.2164) gate/usage_std 0.1643 (0.1643) teacher/entropy 0.0351 (0.0421) teacher/usage_max 0.6982 (0.7657) teacher/usage_min 0.1139 (0.0639) teacher/usage_std 0.2597 (0.3106) nleep/row_max_mean 1528.9158 (1545.5585) nleep/row_max_std 69.9779 (56.2277) nleep/row_min_mean 1501.6978 (1514.6170) lr 1.4258e-03 eta 0:11:39
epoch [20/50] batch [60/181] time 0.097 (0.123) data 0.001 (0.006) loss 1.3854 (1.2362) teacher_loss 0.3429 (0.2062) loss_zs_kd 0.0432 (0.0337) loss_oracle 0.4894 (0.5096) kd_loss 0.7762 (0.7583) acc 81.2500 (92.4479) gate/entropy 0.9852 (0.9854) gate/usage_max 0.5660 (0.5658) gate/usage_min 0.2163 (0.2164) gate/usage_std 0.1645 (0.1644) teacher/entropy 0.0386 (0.0414) teacher/usage_max 0.7443 (0.7594) teacher/usage_min 0.0708 (0.0718) teacher/usage_std 0.2943 (0.3054) nleep/row_max_mean 1541.9010 (1545.9057) nleep/row_max_std 58.0078 (56.9709) nleep/row_min_mean 1511.5138 (1514.9901) lr 1.4258e-03 eta 0:11:24
epoch [20/50] batch [80/181] time 0.097 (0.123) data 0.000 (0.004) loss 1.1315 (1.2472) teacher_loss 0.2788 (0.2152) loss_zs_kd 0.0355 (0.0345) loss_oracle 0.4208 (0.5128) kd_loss 0.6246 (0.7583) acc 87.5000 (92.1875) gate/entropy 0.9849 (0.9854) gate/usage_max 0.5663 (0.5659) gate/usage_min 0.2161 (0.2163) gate/usage_std 0.1648 (0.1644) teacher/entropy 0.0457 (0.0428) teacher/usage_max 0.8943 (0.7579) teacher/usage_min 0.0313 (0.0749) teacher/usage_std 0.3971 (0.3043) nleep/row_max_mean 1540.0333 (1545.1267) nleep/row_max_std 48.8002 (56.9479) nleep/row_min_mean 1509.5991 (1514.0886) lr 1.4258e-03 eta 0:11:19
epoch [20/50] batch [100/181] time 0.164 (0.125) data 0.000 (0.003) loss 1.3270 (1.2478) teacher_loss 0.1928 (0.2158) loss_zs_kd 0.0318 (0.0342) loss_oracle 0.5307 (0.5140) kd_loss 0.8530 (0.7579) acc 93.7500 (92.3125) gate/entropy 0.9847 (0.9853) gate/usage_max 0.5665 (0.5660) gate/usage_min 0.2160 (0.2163) gate/usage_std 0.1649 (0.1645) teacher/entropy 0.0179 (0.0410) teacher/usage_max 0.6849 (0.7602) teacher/usage_min 0.1273 (0.0769) teacher/usage_std 0.2498 (0.3054) nleep/row_max_mean 1552.7809 (1544.4926) nleep/row_max_std 58.5658 (57.2135) nleep/row_min_mean 1520.7008 (1513.4676) lr 1.4258e-03 eta 0:11:30
epoch [20/50] batch [120/181] time 0.168 (0.125) data 0.000 (0.003) loss 1.4067 (1.2517) teacher_loss 0.2868 (0.2149) loss_zs_kd 0.0541 (0.0332) loss_oracle 0.5794 (0.5189) kd_loss 0.8031 (0.7608) acc 90.6250 (92.2396) gate/entropy 0.9847 (0.9852) gate/usage_max 0.5665 (0.5660) gate/usage_min 0.2160 (0.2162) gate/usage_std 0.1649 (0.1645) teacher/entropy 0.0053 (0.0404) teacher/usage_max 0.7500 (0.7577) teacher/usage_min 0.0934 (0.0783) teacher/usage_std 0.2958 (0.3035) nleep/row_max_mean 1541.4136 (1544.7487) nleep/row_max_std 61.0414 (56.5298) nleep/row_min_mean 1509.9056 (1513.7477) lr 1.4258e-03 eta 0:11:29
epoch [20/50] batch [140/181] time 0.152 (0.130) data 0.000 (0.002) loss 1.3595 (1.2569) teacher_loss 0.1128 (0.2114) loss_zs_kd 0.0513 (0.0337) loss_oracle 0.5492 (0.5229) kd_loss 0.9464 (0.7672) acc 93.7500 (92.2991) gate/entropy 0.9846 (0.9852) gate/usage_max 0.5667 (0.5661) gate/usage_min 0.2159 (0.2162) gate/usage_std 0.1650 (0.1646) teacher/entropy 0.0341 (0.0402) teacher/usage_max 0.5704 (0.7511) teacher/usage_min 0.1476 (0.0824) teacher/usage_std 0.1764 (0.2987) nleep/row_max_mean 1553.5154 (1544.6240) nleep/row_max_std 41.8408 (56.4354) nleep/row_min_mean 1524.5201 (1513.6911) lr 1.4258e-03 eta 0:11:51
epoch [20/50] batch [160/181] time 0.154 (0.134) data 0.000 (0.002) loss 1.3462 (1.2663) teacher_loss 0.2263 (0.2125) loss_zs_kd 0.0475 (0.0355) loss_oracle 0.5530 (0.5271) kd_loss 0.8196 (0.7725) acc 93.7500 (92.3438) gate/entropy 0.9846 (0.9851) gate/usage_max 0.5666 (0.5661) gate/usage_min 0.2159 (0.2162) gate/usage_std 0.1650 (0.1646) teacher/entropy 0.0386 (0.0396) teacher/usage_max 0.6980 (0.7462) teacher/usage_min 0.1398 (0.0832) teacher/usage_std 0.2580 (0.2957) nleep/row_max_mean 1546.5023 (1545.4500) nleep/row_max_std 46.0798 (55.9244) nleep/row_min_mean 1515.2971 (1514.3596) lr 1.4258e-03 eta 0:12:08
epoch [20/50] batch [180/181] time 0.136 (0.135) data 0.000 (0.002) loss 1.0545 (1.2715) teacher_loss 0.1040 (0.2129) loss_zs_kd 0.0275 (0.0360) loss_oracle 0.3921 (0.5259) kd_loss 0.7406 (0.7776) acc 100.0000 (92.3090) gate/entropy 0.9845 (0.9850) gate/usage_max 0.5667 (0.5662) gate/usage_min 0.2159 (0.2162) gate/usage_std 0.1650 (0.1647) teacher/entropy 0.0451 (0.0386) teacher/usage_max 0.7733 (0.7419) teacher/usage_min 0.1010 (0.0855) teacher/usage_std 0.3112 (0.2927) nleep/row_max_mean 1544.8662 (1546.1443) nleep/row_max_std 53.2174 (55.4408) nleep/row_min_mean 1518.5822 (1514.9347) lr 1.4258e-03 eta 0:12:15
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,415
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.8%, epoch: 18 *******
******* Domain p best val test acc: 99.8%, epoch: 18 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [21/50] batch [20/181] time 0.102 (0.135) data 0.000 (0.014) loss 1.5498 (1.3109) teacher_loss 0.3025 (0.1930) loss_zs_kd 0.0746 (0.0395) loss_oracle 0.5886 (0.5298) kd_loss 0.9157 (0.8332) acc 81.2500 (92.8125) gate/entropy 0.9844 (0.9845) gate/usage_max 0.5668 (0.5668) gate/usage_min 0.2158 (0.2159) gate/usage_std 0.1651 (0.1651) teacher/entropy 0.0210 (0.0236) teacher/usage_max 0.6156 (0.6992) teacher/usage_min 0.0937 (0.0981) teacher/usage_std 0.2152 (0.2635) nleep/row_max_mean 1555.0847 (1556.2285) nleep/row_max_std 46.1275 (53.9290) nleep/row_min_mean 1518.1594 (1522.2475) lr 1.3681e-03 eta 0:12:08
epoch [21/50] batch [40/181] time 0.082 (0.129) data 0.000 (0.007) loss 1.2870 (1.2950) teacher_loss 0.1641 (0.1857) loss_zs_kd 0.0486 (0.0403) loss_oracle 0.4913 (0.5346) kd_loss 0.8529 (0.8219) acc 93.7500 (93.1250) gate/entropy 0.9841 (0.9844) gate/usage_max 0.5671 (0.5668) gate/usage_min 0.2157 (0.2158) gate/usage_std 0.1653 (0.1651) teacher/entropy 0.0194 (0.0315) teacher/usage_max 0.6832 (0.7027) teacher/usage_min 0.1566 (0.1037) teacher/usage_std 0.2474 (0.2652) nleep/row_max_mean 1561.4824 (1556.4970) nleep/row_max_std 42.8229 (54.6393) nleep/row_min_mean 1525.8960 (1522.9214) lr 1.3681e-03 eta 0:11:33
epoch [21/50] batch [60/181] time 0.073 (0.125) data 0.000 (0.005) loss 1.2914 (1.2864) teacher_loss 0.1252 (0.1867) loss_zs_kd 0.0142 (0.0389) loss_oracle 0.5367 (0.5259) kd_loss 0.8908 (0.8173) acc 93.7500 (93.0208) gate/entropy 0.9845 (0.9844) gate/usage_max 0.5667 (0.5669) gate/usage_min 0.2159 (0.2158) gate/usage_std 0.1650 (0.1651) teacher/entropy 0.0096 (0.0325) teacher/usage_max 0.6545 (0.7064) teacher/usage_min 0.1265 (0.1028) teacher/usage_std 0.2302 (0.2679) nleep/row_max_mean 1540.0886 (1556.6181) nleep/row_max_std 67.7353 (55.8309) nleep/row_min_mean 1508.0659 (1522.7305) lr 1.3681e-03 eta 0:11:13
epoch [21/50] batch [80/181] time 0.093 (0.122) data 0.000 (0.004) loss 1.1578 (1.2925) teacher_loss 0.1267 (0.1958) loss_zs_kd 0.0436 (0.0396) loss_oracle 0.4402 (0.5228) kd_loss 0.7892 (0.8155) acc 96.8750 (92.9688) gate/entropy 0.9841 (0.9844) gate/usage_max 0.5671 (0.5669) gate/usage_min 0.2157 (0.2158) gate/usage_std 0.1653 (0.1652) teacher/entropy 0.0236 (0.0301) teacher/usage_max 0.7448 (0.7108) teacher/usage_min 0.0625 (0.1017) teacher/usage_std 0.2957 (0.2709) nleep/row_max_mean 1553.1500 (1556.4522) nleep/row_max_std 65.2752 (56.2225) nleep/row_min_mean 1518.4673 (1522.5975) lr 1.3681e-03 eta 0:10:54
epoch [21/50] batch [100/181] time 0.077 (0.120) data 0.000 (0.003) loss 1.3361 (1.2971) teacher_loss 0.2965 (0.1979) loss_zs_kd 0.0495 (0.0395) loss_oracle 0.4733 (0.5242) kd_loss 0.7782 (0.8173) acc 84.3750 (92.8750) gate/entropy 0.9841 (0.9843) gate/usage_max 0.5672 (0.5669) gate/usage_min 0.2157 (0.2158) gate/usage_std 0.1654 (0.1652) teacher/entropy 0.0209 (0.0297) teacher/usage_max 0.7588 (0.7093) teacher/usage_min 0.0534 (0.1014) teacher/usage_std 0.3058 (0.2700) nleep/row_max_mean 1561.7041 (1555.8217) nleep/row_max_std 65.4113 (56.4831) nleep/row_min_mean 1524.6685 (1521.8244) lr 1.3681e-03 eta 0:10:39
epoch [21/50] batch [120/181] time 0.087 (0.120) data 0.000 (0.003) loss 1.2445 (1.2916) teacher_loss 0.1505 (0.1932) loss_zs_kd 0.0331 (0.0395) loss_oracle 0.5423 (0.5247) kd_loss 0.8063 (0.8162) acc 96.8750 (93.0469) gate/entropy 0.9840 (0.9843) gate/usage_max 0.5673 (0.5670) gate/usage_min 0.2156 (0.2158) gate/usage_std 0.1654 (0.1652) teacher/entropy 0.0013 (0.0275) teacher/usage_max 0.7501 (0.7127) teacher/usage_min 0.0938 (0.0999) teacher/usage_std 0.2958 (0.2722) nleep/row_max_mean 1553.0061 (1554.8524) nleep/row_max_std 59.8146 (56.7518) nleep/row_min_mean 1517.5511 (1520.8558) lr 1.3681e-03 eta 0:10:35
epoch [21/50] batch [140/181] time 0.177 (0.120) data 0.000 (0.002) loss 1.2828 (1.2977) teacher_loss 0.0727 (0.1947) loss_zs_kd 0.0483 (0.0405) loss_oracle 0.6192 (0.5282) kd_loss 0.8763 (0.8187) acc 96.8750 (93.0134) gate/entropy 0.9839 (0.9842) gate/usage_max 0.5674 (0.5670) gate/usage_min 0.2156 (0.2157) gate/usage_std 0.1655 (0.1652) teacher/entropy 0.0275 (0.0266) teacher/usage_max 0.6504 (0.7111) teacher/usage_min 0.1621 (0.1006) teacher/usage_std 0.2244 (0.2710) nleep/row_max_mean 1550.5225 (1554.1464) nleep/row_max_std 66.0193 (57.0688) nleep/row_min_mean 1515.5193 (1520.2960) lr 1.3681e-03 eta 0:10:35
epoch [21/50] batch [160/181] time 0.165 (0.122) data 0.000 (0.002) loss 1.2664 (1.3030) teacher_loss 0.1507 (0.1989) loss_zs_kd 0.0485 (0.0411) loss_oracle 0.5786 (0.5313) kd_loss 0.8021 (0.8179) acc 96.8750 (92.9492) gate/entropy 0.9837 (0.9842) gate/usage_max 0.5676 (0.5671) gate/usage_min 0.2155 (0.2157) gate/usage_std 0.1656 (0.1653) teacher/entropy 0.0065 (0.0260) teacher/usage_max 0.7485 (0.7125) teacher/usage_min 0.1250 (0.1017) teacher/usage_std 0.2936 (0.2717) nleep/row_max_mean 1563.0959 (1553.8661) nleep/row_max_std 52.5681 (56.7742) nleep/row_min_mean 1526.2073 (1520.1278) lr 1.3681e-03 eta 0:10:42
epoch [21/50] batch [180/181] time 0.167 (0.120) data 0.000 (0.002) loss 1.7288 (1.3101) teacher_loss 0.4553 (0.2044) loss_zs_kd 0.0553 (0.0418) loss_oracle 0.6159 (0.5338) kd_loss 0.9379 (0.8179) acc 87.5000 (92.7778) gate/entropy 0.9838 (0.9842) gate/usage_max 0.5675 (0.5671) gate/usage_min 0.2155 (0.2157) gate/usage_std 0.1656 (0.1653) teacher/entropy 0.0301 (0.0255) teacher/usage_max 0.5836 (0.7130) teacher/usage_min 0.1662 (0.1019) teacher/usage_std 0.1802 (0.2720) nleep/row_max_mean 1553.1368 (1553.0777) nleep/row_max_std 60.8172 (56.9341) nleep/row_min_mean 1517.6610 (1519.4544) lr 1.3681e-03 eta 0:10:31
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,420
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      96.9%, epoch: 21 *******
******* Domain p best val test acc: 99.8%, epoch: 21 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [22/50] batch [20/181] time 0.143 (0.153) data 0.000 (0.013) loss 1.4641 (1.2824) teacher_loss 0.3767 (0.1869) loss_zs_kd 0.0627 (0.0413) loss_oracle 0.5269 (0.5260) kd_loss 0.7927 (0.8118) acc 81.2500 (93.2812) gate/entropy 0.9836 (0.9838) gate/usage_max 0.5677 (0.5675) gate/usage_min 0.2154 (0.2155) gate/usage_std 0.1658 (0.1656) teacher/entropy 0.0401 (0.0288) teacher/usage_max 0.7234 (0.7157) teacher/usage_min 0.1210 (0.0911) teacher/usage_std 0.2762 (0.2742) nleep/row_max_mean 1551.6870 (1547.0115) nleep/row_max_std 46.3098 (57.6021) nleep/row_min_mean 1518.6310 (1514.4727) lr 1.3090e-03 eta 0:13:19
epoch [22/50] batch [40/181] time 0.144 (0.151) data 0.000 (0.007) loss 1.3783 (1.3074) teacher_loss 0.2775 (0.1909) loss_zs_kd 0.0313 (0.0402) loss_oracle 0.5317 (0.5317) kd_loss 0.8193 (0.8306) acc 93.7500 (93.2031) gate/entropy 0.9836 (0.9838) gate/usage_max 0.5677 (0.5675) gate/usage_min 0.2155 (0.2155) gate/usage_std 0.1657 (0.1656) teacher/entropy 0.0170 (0.0283) teacher/usage_max 0.7202 (0.6967) teacher/usage_min 0.1265 (0.1077) teacher/usage_std 0.2737 (0.2604) nleep/row_max_mean 1551.3966 (1545.0121) nleep/row_max_std 56.8607 (57.8964) nleep/row_min_mean 1518.9198 (1512.9710) lr 1.3090e-03 eta 0:13:04
epoch [22/50] batch [60/181] time 0.151 (0.150) data 0.000 (0.004) loss 1.1466 (1.3158) teacher_loss 0.1106 (0.1876) loss_zs_kd 0.0230 (0.0405) loss_oracle 0.5478 (0.5445) kd_loss 0.7506 (0.8356) acc 93.7500 (93.3333) gate/entropy 0.9836 (0.9837) gate/usage_max 0.5677 (0.5676) gate/usage_min 0.2155 (0.2155) gate/usage_std 0.1657 (0.1656) teacher/entropy 0.0411 (0.0281) teacher/usage_max 0.7663 (0.6915) teacher/usage_min 0.0370 (0.1082) teacher/usage_std 0.3130 (0.2571) nleep/row_max_mean 1544.3191 (1545.4072) nleep/row_max_std 66.8087 (58.4278) nleep/row_min_mean 1513.6770 (1513.4468) lr 1.3090e-03 eta 0:12:59
epoch [22/50] batch [80/181] time 0.156 (0.152) data 0.000 (0.003) loss 1.4159 (1.3146) teacher_loss 0.2172 (0.1819) loss_zs_kd 0.0254 (0.0408) loss_oracle 0.5345 (0.5463) kd_loss 0.9187 (0.8392) acc 90.6250 (93.3984) gate/entropy 0.9837 (0.9837) gate/usage_max 0.5675 (0.5676) gate/usage_min 0.2155 (0.2155) gate/usage_std 0.1656 (0.1656) teacher/entropy 0.0084 (0.0272) teacher/usage_max 0.6265 (0.6889) teacher/usage_min 0.1250 (0.1100) teacher/usage_std 0.2133 (0.2556) nleep/row_max_mean 1539.2107 (1546.2032) nleep/row_max_std 65.6606 (58.0931) nleep/row_min_mean 1504.8389 (1513.9660) lr 1.3090e-03 eta 0:13:07
epoch [22/50] batch [100/181] time 0.142 (0.153) data 0.000 (0.003) loss 1.0278 (1.3105) teacher_loss 0.0739 (0.1817) loss_zs_kd 0.0186 (0.0409) loss_oracle 0.4734 (0.5455) kd_loss 0.7078 (0.8355) acc 96.8750 (93.4062) gate/entropy 0.9836 (0.9837) gate/usage_max 0.5676 (0.5676) gate/usage_min 0.2155 (0.2155) gate/usage_std 0.1657 (0.1657) teacher/entropy 0.0493 (0.0288) teacher/usage_max 0.8021 (0.6910) teacher/usage_min 0.0467 (0.1102) teacher/usage_std 0.3342 (0.2568) nleep/row_max_mean 1536.7834 (1545.7626) nleep/row_max_std 73.9346 (58.2042) nleep/row_min_mean 1501.1377 (1513.5614) lr 1.3090e-03 eta 0:13:07
epoch [22/50] batch [120/181] time 0.089 (0.146) data 0.000 (0.002) loss 1.3545 (1.3174) teacher_loss 0.2523 (0.1906) loss_zs_kd 0.0367 (0.0410) loss_oracle 0.5343 (0.5438) kd_loss 0.8168 (0.8344) acc 87.5000 (93.0469) gate/entropy 0.9837 (0.9836) gate/usage_max 0.5676 (0.5677) gate/usage_min 0.2155 (0.2155) gate/usage_std 0.1657 (0.1657) teacher/entropy 0.0511 (0.0312) teacher/usage_max 0.6878 (0.6896) teacher/usage_min 0.1518 (0.1118) teacher/usage_std 0.2507 (0.2558) nleep/row_max_mean 1531.6602 (1545.5834) nleep/row_max_std 59.2363 (58.0755) nleep/row_min_mean 1499.0826 (1513.2953) lr 1.3090e-03 eta 0:12:28
epoch [22/50] batch [140/181] time 0.172 (0.141) data 0.000 (0.002) loss 1.2078 (1.3153) teacher_loss 0.1581 (0.1884) loss_zs_kd 0.0673 (0.0414) loss_oracle 0.5038 (0.5447) kd_loss 0.7642 (0.8338) acc 93.7500 (93.1920) gate/entropy 0.9834 (0.9836) gate/usage_max 0.5679 (0.5677) gate/usage_min 0.2153 (0.2155) gate/usage_std 0.1659 (0.1657) teacher/entropy 0.0546 (0.0317) teacher/usage_max 0.7381 (0.6897) teacher/usage_min 0.1290 (0.1115) teacher/usage_std 0.2863 (0.2561) nleep/row_max_mean 1543.4150 (1545.3720) nleep/row_max_std 55.0042 (57.9772) nleep/row_min_mean 1514.8119 (1513.0509) lr 1.3090e-03 eta 0:12:00
epoch [22/50] batch [160/181] time 0.099 (0.138) data 0.000 (0.002) loss 1.5074 (1.3217) teacher_loss 0.2190 (0.1905) loss_zs_kd 0.0768 (0.0429) loss_oracle 0.6678 (0.5487) kd_loss 0.9161 (0.8354) acc 90.6250 (93.0273) gate/entropy 0.9832 (0.9836) gate/usage_max 0.5681 (0.5677) gate/usage_min 0.2153 (0.2155) gate/usage_std 0.1660 (0.1657) teacher/entropy 0.0160 (0.0303) teacher/usage_max 0.6211 (0.6895) teacher/usage_min 0.1252 (0.1108) teacher/usage_std 0.2101 (0.2561) nleep/row_max_mean 1544.1019 (1545.5027) nleep/row_max_std 57.1245 (57.8493) nleep/row_min_mean 1512.2878 (1513.1237) lr 1.3090e-03 eta 0:11:44
epoch [22/50] batch [180/181] time 0.076 (0.136) data 0.000 (0.002) loss 1.2430 (1.3236) teacher_loss 0.1087 (0.1873) loss_zs_kd 0.0588 (0.0429) loss_oracle 0.5466 (0.5520) kd_loss 0.8316 (0.8388) acc 96.8750 (93.2118) gate/entropy 0.9833 (0.9836) gate/usage_max 0.5680 (0.5677) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1659 (0.1658) teacher/entropy 0.0068 (0.0298) teacher/usage_max 0.7176 (0.6865) teacher/usage_min 0.1250 (0.1136) teacher/usage_std 0.2721 (0.2537) nleep/row_max_mean 1539.8740 (1545.5497) nleep/row_max_std 72.4208 (58.2274) nleep/row_min_mean 1506.3959 (1513.0709) lr 1.3090e-03 eta 0:11:27
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,421
* accuracy: 97.0%
* error: 3.0%
* macro_f1: 97.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.0%, epoch: 22 *******
******* Domain p best val test acc: 99.7%, epoch: 22 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [23/50] batch [20/181] time 0.153 (0.129) data 0.000 (0.017) loss 1.1213 (1.2970) teacher_loss 0.2035 (0.1967) loss_zs_kd 0.0442 (0.0401) loss_oracle 0.4565 (0.5278) kd_loss 0.6675 (0.8163) acc 90.6250 (92.6562) gate/entropy 0.9832 (0.9832) gate/usage_max 0.5681 (0.5681) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1660 (0.1660) teacher/entropy 0.0413 (0.0289) teacher/usage_max 0.8519 (0.7105) teacher/usage_min 0.0670 (0.1135) teacher/usage_std 0.3667 (0.2684) nleep/row_max_mean 1540.0208 (1549.1259) nleep/row_max_std 51.5433 (59.6203) nleep/row_min_mean 1508.2317 (1514.0917) lr 1.2487e-03 eta 0:10:49
epoch [23/50] batch [40/181] time 0.190 (0.116) data 0.000 (0.009) loss 1.2555 (1.3034) teacher_loss 0.1185 (0.1914) loss_zs_kd 0.0232 (0.0419) loss_oracle 0.5810 (0.5464) kd_loss 0.8349 (0.8178) acc 93.7500 (92.5781) gate/entropy 0.9831 (0.9832) gate/usage_max 0.5682 (0.5681) gate/usage_min 0.2152 (0.2153) gate/usage_std 0.1661 (0.1660) teacher/entropy 0.0023 (0.0234) teacher/usage_max 0.7190 (0.7146) teacher/usage_min 0.1250 (0.1071) teacher/usage_std 0.2730 (0.2719) nleep/row_max_mean 1545.5039 (1547.1054) nleep/row_max_std 57.2362 (60.1095) nleep/row_min_mean 1512.1744 (1512.5826) lr 1.2487e-03 eta 0:09:45
epoch [23/50] batch [60/181] time 0.170 (0.109) data 0.001 (0.006) loss 1.2249 (1.3085) teacher_loss 0.2174 (0.1939) loss_zs_kd 0.0355 (0.0428) loss_oracle 0.5007 (0.5476) kd_loss 0.7394 (0.8193) acc 93.7500 (92.7083) gate/entropy 0.9829 (0.9832) gate/usage_max 0.5684 (0.5681) gate/usage_min 0.2151 (0.2153) gate/usage_std 0.1662 (0.1660) teacher/entropy 0.0096 (0.0260) teacher/usage_max 0.8101 (0.7104) teacher/usage_min 0.0938 (0.1101) teacher/usage_std 0.3372 (0.2690) nleep/row_max_mean 1558.4979 (1543.9660) nleep/row_max_std 58.2763 (60.3280) nleep/row_min_mean 1521.1238 (1510.0493) lr 1.2487e-03 eta 0:09:08
epoch [23/50] batch [80/181] time 0.085 (0.108) data 0.000 (0.004) loss 1.1877 (1.3077) teacher_loss 0.2618 (0.1947) loss_zs_kd 0.0344 (0.0426) loss_oracle 0.4693 (0.5478) kd_loss 0.6741 (0.8178) acc 87.5000 (92.6953) gate/entropy 0.9831 (0.9832) gate/usage_max 0.5682 (0.5681) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1661 (0.1660) teacher/entropy 0.0427 (0.0270) teacher/usage_max 0.8430 (0.7109) teacher/usage_min 0.0635 (0.1095) teacher/usage_std 0.3606 (0.2696) nleep/row_max_mean 1556.5210 (1543.8843) nleep/row_max_std 60.9547 (59.4563) nleep/row_min_mean 1519.4753 (1510.0034) lr 1.2487e-03 eta 0:08:56
epoch [23/50] batch [100/181] time 0.186 (0.105) data 0.000 (0.004) loss 1.2187 (1.3089) teacher_loss 0.1230 (0.1927) loss_zs_kd 0.0282 (0.0423) loss_oracle 0.6023 (0.5556) kd_loss 0.7804 (0.8172) acc 96.8750 (92.8438) gate/entropy 0.9831 (0.9831) gate/usage_max 0.5682 (0.5682) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1661 (0.1661) teacher/entropy 0.0331 (0.0269) teacher/usage_max 0.7432 (0.7117) teacher/usage_min 0.0910 (0.1089) teacher/usage_std 0.2914 (0.2701) nleep/row_max_mean 1545.4519 (1544.7058) nleep/row_max_std 55.4986 (59.0096) nleep/row_min_mean 1508.8149 (1510.5205) lr 1.2487e-03 eta 0:08:43
epoch [23/50] batch [120/181] time 0.141 (0.108) data 0.000 (0.003) loss 1.2736 (1.3081) teacher_loss 0.3527 (0.1970) loss_zs_kd 0.0504 (0.0418) loss_oracle 0.4746 (0.5547) kd_loss 0.6585 (0.8128) acc 87.5000 (92.6562) gate/entropy 0.9827 (0.9831) gate/usage_max 0.5686 (0.5682) gate/usage_min 0.2150 (0.2152) gate/usage_std 0.1664 (0.1661) teacher/entropy 0.0462 (0.0276) teacher/usage_max 0.8556 (0.7155) teacher/usage_min 0.0316 (0.1078) teacher/usage_std 0.3708 (0.2727) nleep/row_max_mean 1551.8535 (1545.0246) nleep/row_max_std 52.2003 (58.1015) nleep/row_min_mean 1518.4194 (1510.9073) lr 1.2487e-03 eta 0:08:54
epoch [23/50] batch [140/181] time 0.152 (0.116) data 0.000 (0.003) loss 1.0430 (1.3019) teacher_loss 0.0550 (0.1939) loss_zs_kd 0.0256 (0.0414) loss_oracle 0.5116 (0.5522) kd_loss 0.7194 (0.8111) acc 96.8750 (92.8125) gate/entropy 0.9828 (0.9831) gate/usage_max 0.5685 (0.5682) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1663 (0.1661) teacher/entropy 0.0428 (0.0285) teacher/usage_max 0.7964 (0.7163) teacher/usage_min 0.0679 (0.1063) teacher/usage_std 0.3286 (0.2735) nleep/row_max_mean 1541.6523 (1545.1222) nleep/row_max_std 50.2958 (56.8740) nleep/row_min_mean 1512.4204 (1511.1770) lr 1.2487e-03 eta 0:09:32
epoch [23/50] batch [160/181] time 0.142 (0.120) data 0.000 (0.002) loss 1.3274 (1.3031) teacher_loss 0.2908 (0.1932) loss_zs_kd 0.0255 (0.0414) loss_oracle 0.4955 (0.5526) kd_loss 0.7761 (0.8129) acc 90.6250 (92.7930) gate/entropy 0.9830 (0.9831) gate/usage_max 0.5684 (0.5683) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1662 (0.1661) teacher/entropy 0.0624 (0.0294) teacher/usage_max 0.7176 (0.7135) teacher/usage_min 0.0903 (0.1062) teacher/usage_std 0.2749 (0.2718) nleep/row_max_mean 1523.4863 (1544.9227) nleep/row_max_std 64.9368 (56.3544) nleep/row_min_mean 1496.0867 (1511.1755) lr 1.2487e-03 eta 0:09:48
epoch [23/50] batch [180/181] time 0.123 (0.122) data 0.000 (0.002) loss 1.3883 (1.3031) teacher_loss 0.1540 (0.1925) loss_zs_kd 0.0393 (0.0412) loss_oracle 0.6127 (0.5540) kd_loss 0.9083 (0.8130) acc 96.8750 (92.8646) gate/entropy 0.9826 (0.9830) gate/usage_max 0.5687 (0.5683) gate/usage_min 0.2150 (0.2152) gate/usage_std 0.1664 (0.1661) teacher/entropy 0.0149 (0.0294) teacher/usage_max 0.6299 (0.7134) teacher/usage_min 0.1201 (0.1055) teacher/usage_std 0.2163 (0.2719) nleep/row_max_mean 1553.4855 (1544.2603) nleep/row_max_std 50.2441 (55.6900) nleep/row_min_mean 1520.7853 (1510.8453) lr 1.2487e-03 eta 0:09:55
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,419
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.0%, epoch: 22 *******
******* Domain p best val test acc: 99.7%, epoch: 22 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [24/50] batch [20/181] time 0.082 (0.128) data 0.000 (0.014) loss 1.1251 (1.3085) teacher_loss 0.0536 (0.1899) loss_zs_kd 0.0178 (0.0424) loss_oracle 0.4724 (0.5485) kd_loss 0.8263 (0.8232) acc 100.0000 (93.2812) gate/entropy 0.9830 (0.9828) gate/usage_max 0.5684 (0.5685) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1662 (0.1663) teacher/entropy 0.0395 (0.0368) teacher/usage_max 0.6893 (0.6952) teacher/usage_min 0.1228 (0.1115) teacher/usage_std 0.2531 (0.2593) nleep/row_max_mean 1540.2261 (1540.4033) nleep/row_max_std 51.8652 (51.5196) nleep/row_min_mean 1508.0703 (1509.5274) lr 1.1874e-03 eta 0:10:24
epoch [24/50] batch [40/181] time 0.082 (0.116) data 0.000 (0.007) loss 1.0110 (1.2952) teacher_loss 0.0882 (0.1940) loss_zs_kd 0.0323 (0.0411) loss_oracle 0.4311 (0.5396) kd_loss 0.6912 (0.8109) acc 96.8750 (92.9688) gate/entropy 0.9826 (0.9828) gate/usage_max 0.5687 (0.5686) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1664 (0.1663) teacher/entropy 0.0193 (0.0326) teacher/usage_max 0.8490 (0.7121) teacher/usage_min 0.0313 (0.0986) teacher/usage_std 0.3664 (0.2716) nleep/row_max_mean 1551.3300 (1541.9922) nleep/row_max_std 37.7189 (50.2840) nleep/row_min_mean 1521.5310 (1510.4511) lr 1.1874e-03 eta 0:09:23
epoch [24/50] batch [60/181] time 0.093 (0.117) data 0.001 (0.005) loss 1.1410 (1.2883) teacher_loss 0.1604 (0.1845) loss_zs_kd 0.0209 (0.0409) loss_oracle 0.4728 (0.5460) kd_loss 0.7337 (0.8103) acc 93.7500 (93.4896) gate/entropy 0.9826 (0.9827) gate/usage_max 0.5687 (0.5686) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1664 (0.1664) teacher/entropy 0.0228 (0.0323) teacher/usage_max 0.8015 (0.7129) teacher/usage_min 0.0421 (0.0960) teacher/usage_std 0.3343 (0.2725) nleep/row_max_mean 1538.7246 (1541.9260) nleep/row_max_std 60.2395 (51.4561) nleep/row_min_mean 1506.4038 (1510.1482) lr 1.1874e-03 eta 0:09:24
epoch [24/50] batch [80/181] time 0.154 (0.119) data 0.000 (0.004) loss 1.3134 (1.2806) teacher_loss 0.2306 (0.1926) loss_zs_kd 0.0289 (0.0404) loss_oracle 0.5573 (0.5372) kd_loss 0.7897 (0.7993) acc 87.5000 (93.1641) gate/entropy 0.9827 (0.9827) gate/usage_max 0.5687 (0.5686) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1664 (0.1664) teacher/entropy 0.0166 (0.0340) teacher/usage_max 0.7513 (0.7226) teacher/usage_min 0.0938 (0.0942) teacher/usage_std 0.2966 (0.2789) nleep/row_max_mean 1535.2263 (1540.7986) nleep/row_max_std 64.9928 (53.2807) nleep/row_min_mean 1499.7949 (1508.7568) lr 1.1874e-03 eta 0:09:32
epoch [24/50] batch [100/181] time 0.110 (0.114) data 0.000 (0.003) loss 1.5663 (1.2884) teacher_loss 0.3296 (0.1937) loss_zs_kd 0.0424 (0.0414) loss_oracle 0.6606 (0.5425) kd_loss 0.8851 (0.8028) acc 87.5000 (92.8438) gate/entropy 0.9828 (0.9827) gate/usage_max 0.5685 (0.5687) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1663 (0.1664) teacher/entropy 0.0243 (0.0317) teacher/usage_max 0.6440 (0.7213) teacher/usage_min 0.0945 (0.0939) teacher/usage_std 0.2300 (0.2782) nleep/row_max_mean 1527.3108 (1541.4163) nleep/row_max_std 62.3512 (54.5053) nleep/row_min_mean 1495.0142 (1508.9579) lr 1.1874e-03 eta 0:09:05
epoch [24/50] batch [120/181] time 0.080 (0.114) data 0.000 (0.003) loss 1.4151 (1.2894) teacher_loss 0.3104 (0.1921) loss_zs_kd 0.0509 (0.0415) loss_oracle 0.4684 (0.5418) kd_loss 0.8451 (0.8056) acc 90.6250 (92.9427) gate/entropy 0.9827 (0.9826) gate/usage_max 0.5686 (0.5687) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1664 (0.1664) teacher/entropy 0.0570 (0.0320) teacher/usage_max 0.6515 (0.7181) teacher/usage_min 0.1530 (0.0963) teacher/usage_std 0.2256 (0.2758) nleep/row_max_mean 1520.6312 (1542.2245) nleep/row_max_std 61.5414 (55.4877) nleep/row_min_mean 1492.3605 (1509.4764) lr 1.1874e-03 eta 0:09:03
epoch [24/50] batch [140/181] time 0.181 (0.116) data 0.000 (0.002) loss 1.3773 (1.2839) teacher_loss 0.3261 (0.1907) loss_zs_kd 0.0408 (0.0408) loss_oracle 0.5214 (0.5371) kd_loss 0.7701 (0.8043) acc 87.5000 (92.9464) gate/entropy 0.9823 (0.9826) gate/usage_max 0.5690 (0.5687) gate/usage_min 0.2148 (0.2150) gate/usage_std 0.1667 (0.1664) teacher/entropy 0.0069 (0.0326) teacher/usage_max 0.7804 (0.7189) teacher/usage_min 0.0628 (0.0985) teacher/usage_std 0.3184 (0.2761) nleep/row_max_mean 1555.5905 (1542.6507) nleep/row_max_std 59.7011 (56.4395) nleep/row_min_mean 1522.9038 (1509.8377) lr 1.1874e-03 eta 0:09:11
epoch [24/50] batch [160/181] time 0.099 (0.115) data 0.000 (0.002) loss 1.1060 (1.2854) teacher_loss 0.0735 (0.1923) loss_zs_kd 0.0220 (0.0407) loss_oracle 0.4923 (0.5357) kd_loss 0.7753 (0.8049) acc 96.8750 (92.7930) gate/entropy 0.9824 (0.9826) gate/usage_max 0.5689 (0.5687) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1666 (0.1665) teacher/entropy 0.0384 (0.0314) teacher/usage_max 0.7427 (0.7194) teacher/usage_min 0.0914 (0.0980) teacher/usage_std 0.2910 (0.2765) nleep/row_max_mean 1538.6093 (1543.0199) nleep/row_max_std 70.8410 (57.4687) nleep/row_min_mean 1510.1704 (1510.1154) lr 1.1874e-03 eta 0:09:05
epoch [24/50] batch [180/181] time 0.072 (0.115) data 0.000 (0.002) loss 1.2312 (1.2887) teacher_loss 0.1612 (0.1927) loss_zs_kd 0.0412 (0.0412) loss_oracle 0.5263 (0.5385) kd_loss 0.7863 (0.8062) acc 96.8750 (92.8646) gate/entropy 0.9824 (0.9826) gate/usage_max 0.5690 (0.5688) gate/usage_min 0.2148 (0.2149) gate/usage_std 0.1666 (0.1665) teacher/entropy 0.0216 (0.0314) teacher/usage_max 0.7485 (0.7181) teacher/usage_min 0.1242 (0.0985) teacher/usage_std 0.2935 (0.2756) nleep/row_max_mean 1539.1552 (1542.6812) nleep/row_max_std 68.3778 (58.0745) nleep/row_min_mean 1508.5747 (1509.9086) lr 1.1874e-03 eta 0:09:00
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,418
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,664
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.6%
******* Domain p best val acc:      97.0%, epoch: 22 *******
******* Domain p best val test acc: 99.7%, epoch: 22 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [25/50] batch [20/181] time 0.135 (0.165) data 0.000 (0.016) loss 1.2425 (1.2945) teacher_loss 0.0919 (0.1861) loss_zs_kd 0.0137 (0.0380) loss_oracle 0.5677 (0.5518) kd_loss 0.8600 (0.8135) acc 96.8750 (92.8125) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5691 (0.5690) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0797 (0.0430) teacher/usage_max 0.6131 (0.6985) teacher/usage_min 0.1516 (0.1070) teacher/usage_std 0.2007 (0.2617) nleep/row_max_mean 1545.2614 (1542.1630) nleep/row_max_std 62.2602 (59.7753) nleep/row_min_mean 1515.2751 (1511.6876) lr 1.1253e-03 eta 0:12:51
epoch [25/50] batch [40/181] time 0.128 (0.159) data 0.000 (0.008) loss 1.1587 (1.2826) teacher_loss 0.1293 (0.1730) loss_zs_kd 0.0661 (0.0401) loss_oracle 0.5146 (0.5378) kd_loss 0.7391 (0.8206) acc 96.8750 (93.5156) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0080 (0.0368) teacher/usage_max 0.8109 (0.6974) teacher/usage_min 0.0634 (0.1050) teacher/usage_std 0.3387 (0.2616) nleep/row_max_mean 1533.7544 (1543.6739) nleep/row_max_std 62.2159 (59.7296) nleep/row_min_mean 1506.8274 (1512.8876) lr 1.1253e-03 eta 0:12:20
epoch [25/50] batch [60/181] time 0.148 (0.155) data 0.000 (0.006) loss 1.3884 (1.2833) teacher_loss 0.2001 (0.1710) loss_zs_kd 0.0432 (0.0408) loss_oracle 0.6224 (0.5408) kd_loss 0.8554 (0.8215) acc 93.7500 (93.5417) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5691) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.0644 (0.0373) teacher/usage_max 0.6335 (0.6960) teacher/usage_min 0.1416 (0.1047) teacher/usage_std 0.2149 (0.2610) nleep/row_max_mean 1536.9347 (1544.4068) nleep/row_max_std 53.1474 (59.2951) nleep/row_min_mean 1508.5540 (1513.6081) lr 1.1253e-03 eta 0:11:58
epoch [25/50] batch [80/181] time 0.165 (0.152) data 0.000 (0.004) loss 1.3506 (1.2982) teacher_loss 0.1237 (0.1778) loss_zs_kd 0.0399 (0.0409) loss_oracle 0.5782 (0.5407) kd_loss 0.9179 (0.8297) acc 96.8750 (93.3203) gate/entropy 0.9821 (0.9823) gate/usage_max 0.5693 (0.5691) gate/usage_min 0.2147 (0.2148) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0280 (0.0397) teacher/usage_max 0.6057 (0.6851) teacher/usage_min 0.0802 (0.1104) teacher/usage_std 0.2150 (0.2534) nleep/row_max_mean 1557.5996 (1543.8925) nleep/row_max_std 55.2133 (58.9225) nleep/row_min_mean 1523.3311 (1513.2412) lr 1.1253e-03 eta 0:11:43
epoch [25/50] batch [100/181] time 0.152 (0.152) data 0.000 (0.003) loss 1.3705 (1.3092) teacher_loss 0.1352 (0.1829) loss_zs_kd 0.0534 (0.0421) loss_oracle 0.5960 (0.5453) kd_loss 0.9106 (0.8326) acc 96.8750 (93.0000) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0409 (0.0401) teacher/usage_max 0.6004 (0.6816) teacher/usage_min 0.1893 (0.1120) teacher/usage_std 0.1890 (0.2511) nleep/row_max_mean 1529.8182 (1542.8290) nleep/row_max_std 53.1975 (59.5029) nleep/row_min_mean 1502.1825 (1512.3330) lr 1.1253e-03 eta 0:11:38
epoch [25/50] batch [120/181] time 0.088 (0.149) data 0.000 (0.003) loss 1.4560 (1.3213) teacher_loss 0.1300 (0.1882) loss_zs_kd 0.0576 (0.0424) loss_oracle 0.5847 (0.5478) kd_loss 1.0048 (0.8381) acc 96.8750 (92.7083) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5690 (0.5691) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0532 (0.0418) teacher/usage_max 0.4919 (0.6743) teacher/usage_min 0.2457 (0.1164) teacher/usage_std 0.1124 (0.2459) nleep/row_max_mean 1518.6338 (1542.0317) nleep/row_max_std 67.3350 (59.7819) nleep/row_min_mean 1496.0751 (1511.8180) lr 1.1253e-03 eta 0:11:21
epoch [25/50] batch [140/181] time 0.160 (0.143) data 0.000 (0.002) loss 1.3056 (1.3337) teacher_loss 0.0617 (0.1879) loss_zs_kd 0.0243 (0.0428) loss_oracle 0.6416 (0.5533) kd_loss 0.9110 (0.8477) acc 100.0000 (92.8348) gate/entropy 0.9822 (0.9822) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2147 (0.2148) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0518 (0.0422) teacher/usage_max 0.5887 (0.6640) teacher/usage_min 0.1528 (0.1208) teacher/usage_std 0.1857 (0.2390) nleep/row_max_mean 1546.2533 (1542.6589) nleep/row_max_std 58.5291 (59.2196) nleep/row_min_mean 1514.7535 (1512.4510) lr 1.1253e-03 eta 0:10:51
epoch [25/50] batch [160/181] time 0.073 (0.140) data 0.000 (0.002) loss 1.6030 (1.3385) teacher_loss 0.3160 (0.1893) loss_zs_kd 0.0443 (0.0429) loss_oracle 0.6212 (0.5531) kd_loss 0.9542 (0.8512) acc 84.3750 (92.8125) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2147 (0.2148) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0543 (0.0454) teacher/usage_max 0.5418 (0.6572) teacher/usage_min 0.2201 (0.1250) teacher/usage_std 0.1476 (0.2341) nleep/row_max_mean 1536.9735 (1542.9936) nleep/row_max_std 53.2833 (58.9314) nleep/row_min_mean 1505.6858 (1512.9013) lr 1.1253e-03 eta 0:10:37
epoch [25/50] batch [180/181] time 0.073 (0.136) data 0.000 (0.002) loss 1.2041 (1.3382) teacher_loss 0.0932 (0.1876) loss_zs_kd 0.0172 (0.0429) loss_oracle 0.5700 (0.5518) kd_loss 0.8174 (0.8533) acc 100.0000 (92.9514) gate/entropy 0.9824 (0.9822) gate/usage_max 0.5689 (0.5691) gate/usage_min 0.2148 (0.2147) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.1705 (0.0478) teacher/usage_max 0.5634 (0.6526) teacher/usage_min 0.1930 (0.1282) teacher/usage_std 0.1640 (0.2307) nleep/row_max_mean 1530.3885 (1543.4892) nleep/row_max_std 71.0323 (59.0754) nleep/row_min_mean 1502.6888 (1513.5288) lr 1.1253e-03 eta 0:10:14
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,419
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.0%, epoch: 22 *******
******* Domain p best val test acc: 99.7%, epoch: 22 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [26/50] batch [20/181] time 0.072 (0.129) data 0.000 (0.015) loss 1.2541 (1.3855) teacher_loss 0.1572 (0.1908) loss_zs_kd 0.0333 (0.0447) loss_oracle 0.5400 (0.5548) kd_loss 0.8103 (0.8949) acc 93.7500 (92.8125) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5692 (0.5692) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.1260 (0.0583) teacher/usage_max 0.6163 (0.5988) teacher/usage_min 0.1738 (0.1534) teacher/usage_std 0.2006 (0.1935) nleep/row_max_mean 1542.0386 (1541.8657) nleep/row_max_std 50.0697 (59.9246) nleep/row_min_mean 1515.0464 (1513.6232) lr 1.0628e-03 eta 0:09:43
epoch [26/50] batch [40/181] time 0.094 (0.121) data 0.000 (0.008) loss 1.1674 (1.3857) teacher_loss 0.0922 (0.1967) loss_zs_kd 0.0528 (0.0449) loss_oracle 0.5731 (0.5504) kd_loss 0.7623 (0.8913) acc 96.8750 (92.9688) gate/entropy 0.9822 (0.9821) gate/usage_max 0.5691 (0.5693) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0490 (0.0649) teacher/usage_max 0.7453 (0.5957) teacher/usage_min 0.0615 (0.1550) teacher/usage_std 0.2962 (0.1914) nleep/row_max_mean 1528.7191 (1542.9789) nleep/row_max_std 54.2620 (54.7131) nleep/row_min_mean 1500.9541 (1514.9134) lr 1.0628e-03 eta 0:09:03
epoch [26/50] batch [60/181] time 0.104 (0.120) data 0.001 (0.005) loss 1.2393 (1.3751) teacher_loss 0.2297 (0.1893) loss_zs_kd 0.0610 (0.0449) loss_oracle 0.5224 (0.5556) kd_loss 0.7180 (0.8856) acc 93.7500 (93.2292) gate/entropy 0.9819 (0.9821) gate/usage_max 0.5695 (0.5692) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1670 (0.1668) teacher/entropy 0.0761 (0.0612) teacher/usage_max 0.7625 (0.6055) teacher/usage_min 0.1179 (0.1483) teacher/usage_std 0.3035 (0.1987) nleep/row_max_mean 1539.3157 (1541.3163) nleep/row_max_std 54.1199 (54.7902) nleep/row_min_mean 1514.8757 (1513.5916) lr 1.0628e-03 eta 0:08:56
epoch [26/50] batch [80/181] time 0.183 (0.124) data 0.000 (0.004) loss 1.3213 (1.3857) teacher_loss 0.1183 (0.1846) loss_zs_kd 0.0343 (0.0439) loss_oracle 0.6396 (0.5671) kd_loss 0.8661 (0.8956) acc 93.7500 (93.1641) gate/entropy 0.9821 (0.9821) gate/usage_max 0.5692 (0.5692) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0585 (0.0616) teacher/usage_max 0.6289 (0.5949) teacher/usage_min 0.1035 (0.1565) teacher/usage_std 0.2195 (0.1910) nleep/row_max_mean 1521.4374 (1539.5338) nleep/row_max_std 58.9310 (54.8034) nleep/row_min_mean 1496.0281 (1511.9966) lr 1.0628e-03 eta 0:09:11
epoch [26/50] batch [100/181] time 0.100 (0.121) data 0.000 (0.003) loss 1.3672 (1.3966) teacher_loss 0.1255 (0.1806) loss_zs_kd 0.0553 (0.0442) loss_oracle 0.5261 (0.5713) kd_loss 0.9511 (0.9082) acc 96.8750 (93.4062) gate/entropy 0.9820 (0.9821) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.0642 (0.0610) teacher/usage_max 0.5357 (0.5826) teacher/usage_min 0.1519 (0.1640) teacher/usage_std 0.1574 (0.1824) nleep/row_max_mean 1533.5616 (1538.0600) nleep/row_max_std 47.2501 (55.0962) nleep/row_min_mean 1510.2433 (1510.6183) lr 1.0628e-03 eta 0:08:56
epoch [26/50] batch [120/181] time 0.155 (0.124) data 0.000 (0.003) loss 1.4677 (1.3963) teacher_loss 0.1368 (0.1785) loss_zs_kd 0.0521 (0.0441) loss_oracle 0.6185 (0.5699) kd_loss 0.9956 (0.9108) acc 93.7500 (93.4896) gate/entropy 0.9819 (0.9821) gate/usage_max 0.5695 (0.5692) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1670 (0.1668) teacher/entropy 0.0487 (0.0630) teacher/usage_max 0.5055 (0.5778) teacher/usage_min 0.1910 (0.1650) teacher/usage_std 0.1301 (0.1795) nleep/row_max_mean 1555.9058 (1538.2078) nleep/row_max_std 53.4705 (54.9262) nleep/row_min_mean 1525.2231 (1510.7392) lr 1.0628e-03 eta 0:09:04
epoch [26/50] batch [140/181] time 0.148 (0.128) data 0.000 (0.002) loss 1.3667 (1.4143) teacher_loss 0.1320 (0.1799) loss_zs_kd 0.0657 (0.0446) loss_oracle 0.5586 (0.5738) kd_loss 0.9225 (0.9252) acc 96.8750 (93.4152) gate/entropy 0.9818 (0.9821) gate/usage_max 0.5696 (0.5692) gate/usage_min 0.2146 (0.2147) gate/usage_std 0.1670 (0.1668) teacher/entropy 0.1366 (0.0641) teacher/usage_max 0.4907 (0.5640) teacher/usage_min 0.1738 (0.1670) teacher/usage_std 0.1294 (0.1724) nleep/row_max_mean 1545.4734 (1539.0509) nleep/row_max_std 45.6739 (54.3387) nleep/row_min_mean 1518.1892 (1511.4408) lr 1.0628e-03 eta 0:09:21
epoch [26/50] batch [160/181] time 0.150 (0.132) data 0.000 (0.002) loss 1.4704 (1.4220) teacher_loss 0.1407 (0.1787) loss_zs_kd 0.0423 (0.0446) loss_oracle 0.5207 (0.5721) kd_loss 1.0481 (0.9350) acc 96.8750 (93.4766) gate/entropy 0.9820 (0.9821) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.0494 (0.0643) teacher/usage_max 0.4512 (0.5562) teacher/usage_min 0.1288 (0.1667) teacher/usage_std 0.1452 (0.1691) nleep/row_max_mean 1541.5364 (1538.5727) nleep/row_max_std 54.0658 (54.9030) nleep/row_min_mean 1513.3341 (1510.9349) lr 1.0628e-03 eta 0:09:35
epoch [26/50] batch [180/181] time 0.133 (0.134) data 0.000 (0.002) loss 1.7267 (1.4296) teacher_loss 0.2969 (0.1766) loss_zs_kd 0.0770 (0.0446) loss_oracle 0.5444 (0.5680) kd_loss 1.1191 (0.9467) acc 90.6250 (93.5590) gate/entropy 0.9821 (0.9821) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0595 (0.0637) teacher/usage_max 0.5333 (0.5466) teacher/usage_min 0.0985 (0.1669) teacher/usage_std 0.1792 (0.1647) nleep/row_max_mean 1537.0472 (1538.5818) nleep/row_max_std 58.4394 (55.6636) nleep/row_min_mean 1507.3989 (1510.8379) lr 1.0628e-03 eta 0:09:42
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,420
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.0%, epoch: 22 *******
******* Domain p best val test acc: 99.7%, epoch: 22 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [27/50] batch [20/181] time 0.090 (0.109) data 0.000 (0.013) loss 1.3650 (1.5020) teacher_loss 0.0570 (0.1595) loss_zs_kd 0.0240 (0.0467) loss_oracle 0.5547 (0.5323) kd_loss 1.0186 (1.0530) acc 96.8750 (94.6875) gate/entropy 0.9822 (0.9821) gate/usage_max 0.5691 (0.5693) gate/usage_min 0.2148 (0.2147) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0397 (0.0416) teacher/usage_max 0.4905 (0.4840) teacher/usage_min 0.2307 (0.1703) teacher/usage_std 0.1129 (0.1348) nleep/row_max_mean 1543.9038 (1540.3985) nleep/row_max_std 55.7783 (58.7054) nleep/row_min_mean 1512.7035 (1510.4302) lr 1.0000e-03 eta 0:07:50
epoch [27/50] batch [40/181] time 0.067 (0.110) data 0.000 (0.007) loss 1.4920 (1.5324) teacher_loss 0.2384 (0.1700) loss_zs_kd 0.0571 (0.0465) loss_oracle 0.5570 (0.5318) kd_loss 0.9465 (1.0732) acc 90.6250 (94.0625) gate/entropy 0.9821 (0.9821) gate/usage_max 0.5692 (0.5693) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0395 (0.0443) teacher/usage_max 0.5661 (0.4827) teacher/usage_min 0.0938 (0.1746) teacher/usage_std 0.1929 (0.1319) nleep/row_max_mean 1535.0656 (1540.7629) nleep/row_max_std 66.8499 (57.6803) nleep/row_min_mean 1503.5073 (1510.4808) lr 1.0000e-03 eta 0:07:54
epoch [27/50] batch [60/181] time 0.063 (0.108) data 0.001 (0.005) loss 1.3650 (1.5374) teacher_loss 0.0282 (0.1731) loss_zs_kd 0.0228 (0.0494) loss_oracle 0.5640 (0.5439) kd_loss 1.0434 (1.0677) acc 100.0000 (93.8542) gate/entropy 0.9822 (0.9821) gate/usage_max 0.5691 (0.5693) gate/usage_min 0.2148 (0.2147) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0430 (0.0436) teacher/usage_max 0.4625 (0.4817) teacher/usage_min 0.1998 (0.1703) teacher/usage_std 0.1073 (0.1333) nleep/row_max_mean 1536.3221 (1540.1762) nleep/row_max_std 67.7044 (59.0146) nleep/row_min_mean 1505.1763 (1509.4648) lr 1.0000e-03 eta 0:07:42
epoch [27/50] batch [80/181] time 0.064 (0.105) data 0.000 (0.003) loss 1.5255 (1.5527) teacher_loss 0.1687 (0.1729) loss_zs_kd 0.0645 (0.0500) loss_oracle 0.5604 (0.5513) kd_loss 1.0443 (1.0792) acc 96.8750 (93.6719) gate/entropy 0.9820 (0.9821) gate/usage_max 0.5694 (0.5692) gate/usage_min 0.2147 (0.2147) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.0529 (0.0432) teacher/usage_max 0.4510 (0.4759) teacher/usage_min 0.1924 (0.1714) teacher/usage_std 0.1069 (0.1304) nleep/row_max_mean 1549.5220 (1539.1074) nleep/row_max_std 55.6963 (59.5051) nleep/row_min_mean 1517.4148 (1508.1519) lr 1.0000e-03 eta 0:07:25
epoch [27/50] batch [100/181] time 0.088 (0.100) data 0.000 (0.003) loss 1.4823 (1.5453) teacher_loss 0.0608 (0.1728) loss_zs_kd 0.0313 (0.0509) loss_oracle 0.4586 (0.5485) kd_loss 1.1765 (1.0728) acc 96.8750 (93.5938) gate/entropy 0.9821 (0.9821) gate/usage_max 0.5692 (0.5693) gate/usage_min 0.2148 (0.2147) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0254 (0.0414) teacher/usage_max 0.5930 (0.4812) teacher/usage_min 0.0625 (0.1633) teacher/usage_std 0.2167 (0.1358) nleep/row_max_mean 1539.4951 (1539.4844) nleep/row_max_std 54.8576 (59.8749) nleep/row_min_mean 1509.9933 (1508.3061) lr 1.0000e-03 eta 0:07:05
epoch [27/50] batch [120/181] time 0.100 (0.105) data 0.001 (0.002) loss 1.5465 (1.5450) teacher_loss 0.1044 (0.1688) loss_zs_kd 0.0365 (0.0496) loss_oracle 0.5720 (0.5501) kd_loss 1.1379 (1.0765) acc 96.8750 (93.7760) gate/entropy 0.9823 (0.9821) gate/usage_max 0.5690 (0.5692) gate/usage_min 0.2149 (0.2148) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0032 (0.0390) teacher/usage_max 0.4058 (0.4848) teacher/usage_min 0.2187 (0.1603) teacher/usage_std 0.0820 (0.1385) nleep/row_max_mean 1546.6807 (1539.4534) nleep/row_max_std 61.3643 (60.0526) nleep/row_min_mean 1511.7446 (1508.1556) lr 1.0000e-03 eta 0:07:24
epoch [27/50] batch [140/181] time 0.167 (0.108) data 0.000 (0.002) loss 1.8276 (1.5473) teacher_loss 0.3132 (0.1689) loss_zs_kd 0.0416 (0.0493) loss_oracle 0.4798 (0.5515) kd_loss 1.2537 (1.0780) acc 93.7500 (93.7946) gate/entropy 0.9822 (0.9821) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2149 (0.2148) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0435 (0.0385) teacher/usage_max 0.6375 (0.4862) teacher/usage_min 0.1164 (0.1584) teacher/usage_std 0.2215 (0.1399) nleep/row_max_mean 1529.6990 (1539.6180) nleep/row_max_std 53.4563 (60.2727) nleep/row_min_mean 1499.2744 (1508.2457) lr 1.0000e-03 eta 0:07:35
epoch [27/50] batch [160/181] time 0.062 (0.110) data 0.000 (0.002) loss 1.6027 (1.5449) teacher_loss 0.2146 (0.1687) loss_zs_kd 0.0606 (0.0487) loss_oracle 0.5794 (0.5486) kd_loss 1.0681 (1.0776) acc 93.7500 (93.7695) gate/entropy 0.9819 (0.9821) gate/usage_max 0.5694 (0.5692) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.0215 (0.0381) teacher/usage_max 0.4595 (0.4886) teacher/usage_min 0.1562 (0.1552) teacher/usage_std 0.1290 (0.1422) nleep/row_max_mean 1557.2394 (1539.8320) nleep/row_max_std 61.1603 (60.2726) nleep/row_min_mean 1523.6133 (1508.4060) lr 1.0000e-03 eta 0:07:41
epoch [27/50] batch [180/181] time 0.167 (0.110) data 0.000 (0.002) loss 1.6351 (1.5513) teacher_loss 0.2939 (0.1747) loss_zs_kd 0.0468 (0.0493) loss_oracle 0.4477 (0.5477) kd_loss 1.0940 (1.0781) acc 87.5000 (93.5243) gate/entropy 0.9821 (0.9821) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2148 (0.2148) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0139 (0.0366) teacher/usage_max 0.4408 (0.4912) teacher/usage_min 0.1250 (0.1525) teacher/usage_std 0.1473 (0.1445) nleep/row_max_mean 1529.8585 (1539.9833) nleep/row_max_std 63.4782 (60.1362) nleep/row_min_mean 1501.4900 (1508.4523) lr 1.0000e-03 eta 0:07:38
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,412
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.0%, epoch: 22 *******
******* Domain p best val test acc: 99.7%, epoch: 22 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [28/50] batch [20/181] time 0.154 (0.173) data 0.000 (0.018) loss 1.5339 (1.5215) teacher_loss 0.2312 (0.1694) loss_zs_kd 0.0488 (0.0425) loss_oracle 0.5570 (0.5034) kd_loss 0.9998 (1.0792) acc 93.7500 (93.5938) gate/entropy 0.9820 (0.9822) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2148 (0.2149) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.0214 (0.0270) teacher/usage_max 0.5291 (0.4873) teacher/usage_min 0.1566 (0.1522) teacher/usage_std 0.1527 (0.1429) nleep/row_max_mean 1551.9092 (1540.7917) nleep/row_max_std 61.7440 (58.6626) nleep/row_min_mean 1517.1116 (1509.0916) lr 9.3721e-04 eta 0:11:55
epoch [28/50] batch [40/181] time 0.169 (0.164) data 0.000 (0.009) loss 1.3749 (1.5131) teacher_loss 0.1528 (0.1490) loss_zs_kd 0.0433 (0.0406) loss_oracle 0.4735 (0.5128) kd_loss 0.9637 (1.0874) acc 93.7500 (94.3750) gate/entropy 0.9822 (0.9822) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0364 (0.0281) teacher/usage_max 0.5512 (0.4913) teacher/usage_min 0.0939 (0.1480) teacher/usage_std 0.1873 (0.1465) nleep/row_max_mean 1539.0040 (1538.5785) nleep/row_max_std 58.8940 (57.6295) nleep/row_min_mean 1509.9966 (1507.0016) lr 9.3721e-04 eta 0:11:16
epoch [28/50] batch [60/181] time 0.160 (0.157) data 0.000 (0.006) loss 1.7118 (1.5327) teacher_loss 0.2943 (0.1579) loss_zs_kd 0.0434 (0.0426) loss_oracle 0.5837 (0.5325) kd_loss 1.1040 (1.0873) acc 90.6250 (94.0625) gate/entropy 0.9822 (0.9822) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0458 (0.0260) teacher/usage_max 0.3974 (0.4897) teacher/usage_min 0.2305 (0.1533) teacher/usage_std 0.0735 (0.1428) nleep/row_max_mean 1533.1526 (1538.3581) nleep/row_max_std 64.6874 (57.5452) nleep/row_min_mean 1504.1138 (1506.8261) lr 9.3721e-04 eta 0:10:45
epoch [28/50] batch [80/181] time 0.142 (0.152) data 0.000 (0.005) loss 1.4945 (1.5361) teacher_loss 0.1461 (0.1629) loss_zs_kd 0.0571 (0.0453) loss_oracle 0.6177 (0.5337) kd_loss 1.0110 (1.0837) acc 96.8750 (93.7891) gate/entropy 0.9822 (0.9822) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2150 (0.2149) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0090 (0.0247) teacher/usage_max 0.5307 (0.4966) teacher/usage_min 0.0953 (0.1465) teacher/usage_std 0.1801 (0.1482) nleep/row_max_mean 1542.9431 (1537.9206) nleep/row_max_std 58.2259 (56.8510) nleep/row_min_mean 1507.4731 (1506.3428) lr 9.3721e-04 eta 0:10:22
epoch [28/50] batch [100/181] time 0.166 (0.151) data 0.000 (0.004) loss 1.6954 (1.5372) teacher_loss 0.2772 (0.1608) loss_zs_kd 0.0669 (0.0470) loss_oracle 0.5084 (0.5426) kd_loss 1.1306 (1.0816) acc 84.3750 (93.8125) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2150 (0.2149) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0120 (0.0237) teacher/usage_max 0.4057 (0.4955) teacher/usage_min 0.1895 (0.1503) teacher/usage_std 0.1017 (0.1461) nleep/row_max_mean 1526.4900 (1537.7886) nleep/row_max_std 57.2560 (57.1975) nleep/row_min_mean 1499.5529 (1506.2641) lr 9.3721e-04 eta 0:10:12
epoch [28/50] batch [120/181] time 0.100 (0.149) data 0.000 (0.003) loss 1.3789 (1.5396) teacher_loss 0.0557 (0.1565) loss_zs_kd 0.0387 (0.0465) loss_oracle 0.5995 (0.5536) kd_loss 1.0041 (1.0830) acc 96.8750 (93.9844) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5690 (0.5691) gate/usage_min 0.2151 (0.2150) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.0152 (0.0239) teacher/usage_max 0.5313 (0.4902) teacher/usage_min 0.1306 (0.1544) teacher/usage_std 0.1636 (0.1421) nleep/row_max_mean 1537.3348 (1537.5585) nleep/row_max_std 64.1398 (57.1568) nleep/row_min_mean 1503.5182 (1506.1123) lr 9.3721e-04 eta 0:10:02
epoch [28/50] batch [140/181] time 0.135 (0.145) data 0.000 (0.003) loss 1.6821 (1.5352) teacher_loss 0.2217 (0.1547) loss_zs_kd 0.0417 (0.0471) loss_oracle 0.6256 (0.5523) kd_loss 1.1267 (1.0807) acc 96.8750 (93.9732) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5690 (0.5691) gate/usage_min 0.2151 (0.2150) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.0650 (0.0249) teacher/usage_max 0.3734 (0.4910) teacher/usage_min 0.2729 (0.1554) teacher/usage_std 0.0435 (0.1421) nleep/row_max_mean 1537.0249 (1537.3001) nleep/row_max_std 52.8255 (56.9892) nleep/row_min_mean 1505.5916 (1505.9053) lr 9.3721e-04 eta 0:09:44
epoch [28/50] batch [160/181] time 0.199 (0.143) data 0.000 (0.002) loss 1.4341 (1.5329) teacher_loss 0.1207 (0.1573) loss_zs_kd 0.0585 (0.0473) loss_oracle 0.4843 (0.5511) kd_loss 1.0420 (1.0765) acc 96.8750 (93.9258) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0070 (0.0249) teacher/usage_max 0.5005 (0.4917) teacher/usage_min 0.1563 (0.1537) teacher/usage_std 0.1407 (0.1432) nleep/row_max_mean 1552.4312 (1537.6591) nleep/row_max_std 56.5494 (56.7264) nleep/row_min_mean 1519.3943 (1506.2280) lr 9.3721e-04 eta 0:09:33
epoch [28/50] batch [180/181] time 0.074 (0.140) data 0.000 (0.002) loss 1.5495 (1.5357) teacher_loss 0.1665 (0.1602) loss_zs_kd 0.0562 (0.0480) loss_oracle 0.6451 (0.5559) kd_loss 1.0322 (1.0736) acc 93.7500 (93.9062) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2151 (0.2150) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0176 (0.0245) teacher/usage_max 0.5001 (0.4913) teacher/usage_min 0.1183 (0.1539) teacher/usage_std 0.1595 (0.1430) nleep/row_max_mean 1537.1887 (1538.4319) nleep/row_max_std 68.3408 (56.4712) nleep/row_min_mean 1504.7656 (1506.9049) lr 9.3721e-04 eta 0:09:17
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,413
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.0%, epoch: 22 *******
******* Domain p best val test acc: 99.7%, epoch: 22 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [29/50] batch [20/181] time 0.175 (0.137) data 0.000 (0.014) loss 1.3763 (1.4987) teacher_loss 0.0573 (0.1531) loss_zs_kd 0.0213 (0.0473) loss_oracle 0.5634 (0.5550) kd_loss 1.0266 (1.0444) acc 96.8750 (94.5312) gate/entropy 0.9821 (0.9823) gate/usage_max 0.5692 (0.5690) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0212 (0.0276) teacher/usage_max 0.5019 (0.5014) teacher/usage_min 0.1612 (0.1470) teacher/usage_std 0.1391 (0.1503) nleep/row_max_mean 1556.8540 (1534.5841) nleep/row_max_std 52.2456 (62.7498) nleep/row_min_mean 1524.8232 (1504.1754) lr 8.7467e-04 eta 0:09:03
epoch [29/50] batch [40/181] time 0.167 (0.126) data 0.000 (0.007) loss 1.4390 (1.5316) teacher_loss 0.0645 (0.1447) loss_zs_kd 0.0591 (0.0521) loss_oracle 0.4725 (0.5605) kd_loss 1.1087 (1.0807) acc 96.8750 (95.0000) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0020 (0.0239) teacher/usage_max 0.4686 (0.4849) teacher/usage_min 0.0938 (0.1591) teacher/usage_std 0.1698 (0.1386) nleep/row_max_mean 1537.7599 (1536.5922) nleep/row_max_std 59.6361 (62.5613) nleep/row_min_mean 1508.6970 (1505.9950) lr 8.7467e-04 eta 0:08:16
epoch [29/50] batch [60/181] time 0.155 (0.124) data 0.000 (0.005) loss 1.7092 (1.5295) teacher_loss 0.2172 (0.1463) loss_zs_kd 0.0465 (0.0526) loss_oracle 0.6489 (0.5753) kd_loss 1.1443 (1.0693) acc 87.5000 (94.6875) gate/entropy 0.9825 (0.9823) gate/usage_max 0.5689 (0.5691) gate/usage_min 0.2152 (0.2151) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.0257 (0.0219) teacher/usage_max 0.4645 (0.4913) teacher/usage_min 0.1596 (0.1590) teacher/usage_std 0.1280 (0.1416) nleep/row_max_mean 1529.8269 (1538.2243) nleep/row_max_std 60.1709 (61.5408) nleep/row_min_mean 1501.0013 (1507.4781) lr 8.7467e-04 eta 0:08:05
epoch [29/50] batch [80/181] time 0.066 (0.117) data 0.000 (0.004) loss 1.4706 (1.5282) teacher_loss 0.0718 (0.1471) loss_zs_kd 0.0501 (0.0532) loss_oracle 0.6456 (0.5730) kd_loss 1.0510 (1.0680) acc 96.8750 (94.7266) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5691) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0196 (0.0223) teacher/usage_max 0.4781 (0.4884) teacher/usage_min 0.2188 (0.1628) teacher/usage_std 0.1080 (0.1384) nleep/row_max_mean 1555.3804 (1539.1312) nleep/row_max_std 61.7558 (61.4759) nleep/row_min_mean 1519.5796 (1508.3981) lr 8.7467e-04 eta 0:07:38
epoch [29/50] batch [100/181] time 0.078 (0.115) data 0.000 (0.003) loss 1.7183 (1.5265) teacher_loss 0.1624 (0.1450) loss_zs_kd 0.0416 (0.0533) loss_oracle 0.6165 (0.5674) kd_loss 1.2268 (1.0711) acc 90.6250 (94.7500) gate/entropy 0.9825 (0.9823) gate/usage_max 0.5688 (0.5690) gate/usage_min 0.2152 (0.2151) gate/usage_std 0.1665 (0.1667) teacher/entropy 0.0253 (0.0218) teacher/usage_max 0.5213 (0.4899) teacher/usage_min 0.1875 (0.1653) teacher/usage_std 0.1395 (0.1378) nleep/row_max_mean 1535.9026 (1539.2167) nleep/row_max_std 50.3157 (61.9596) nleep/row_min_mean 1504.2610 (1508.3756) lr 8.7467e-04 eta 0:07:28
epoch [29/50] batch [120/181] time 0.089 (0.116) data 0.000 (0.003) loss 1.3678 (1.5271) teacher_loss 0.0893 (0.1488) loss_zs_kd 0.0741 (0.0524) loss_oracle 0.5480 (0.5597) kd_loss 0.9675 (1.0722) acc 96.8750 (94.6094) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5691 (0.5690) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0186 (0.0223) teacher/usage_max 0.5650 (0.4887) teacher/usage_min 0.2162 (0.1663) teacher/usage_std 0.1638 (0.1370) nleep/row_max_mean 1548.7017 (1539.7404) nleep/row_max_std 55.8333 (61.7964) nleep/row_min_mean 1513.0719 (1508.8655) lr 8.7467e-04 eta 0:07:27
epoch [29/50] batch [140/181] time 0.084 (0.116) data 0.000 (0.002) loss 1.4122 (1.5145) teacher_loss 0.0697 (0.1453) loss_zs_kd 0.0654 (0.0517) loss_oracle 0.4952 (0.5499) kd_loss 1.0623 (1.0684) acc 100.0000 (94.7991) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5692 (0.5690) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0406 (0.0237) teacher/usage_max 0.4450 (0.4874) teacher/usage_min 0.1920 (0.1676) teacher/usage_std 0.1054 (0.1359) nleep/row_max_mean 1557.6689 (1540.3200) nleep/row_max_std 64.5270 (61.6325) nleep/row_min_mean 1524.6633 (1509.3836) lr 8.7467e-04 eta 0:07:26
epoch [29/50] batch [160/181] time 0.171 (0.117) data 0.000 (0.002) loss 1.5058 (1.5114) teacher_loss 0.1892 (0.1485) loss_zs_kd 0.0580 (0.0516) loss_oracle 0.5285 (0.5447) kd_loss 1.0234 (1.0647) acc 90.6250 (94.5312) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2152 (0.2151) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.0265 (0.0253) teacher/usage_max 0.4999 (0.4877) teacher/usage_min 0.1334 (0.1675) teacher/usage_std 0.1515 (0.1358) nleep/row_max_mean 1542.1335 (1539.7217) nleep/row_max_std 57.8991 (62.0674) nleep/row_min_mean 1513.4517 (1508.9275) lr 8.7467e-04 eta 0:07:28
epoch [29/50] batch [180/181] time 0.170 (0.117) data 0.000 (0.002) loss 1.4252 (1.5077) teacher_loss 0.2533 (0.1523) loss_zs_kd 0.0856 (0.0528) loss_oracle 0.4131 (0.5416) kd_loss 0.9226 (1.0581) acc 87.5000 (94.3229) gate/entropy 0.9825 (0.9823) gate/usage_max 0.5688 (0.5690) gate/usage_min 0.2153 (0.2151) gate/usage_std 0.1665 (0.1667) teacher/entropy 0.0677 (0.0272) teacher/usage_max 0.5606 (0.4908) teacher/usage_min 0.0861 (0.1680) teacher/usage_std 0.1942 (0.1371) nleep/row_max_mean 1536.6713 (1539.2730) nleep/row_max_std 59.5165 (61.7525) nleep/row_min_mean 1504.6399 (1508.5706) lr 8.7467e-04 eta 0:07:23
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,419
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.0%, epoch: 22 *******
******* Domain p best val test acc: 99.7%, epoch: 22 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [30/50] batch [20/181] time 0.108 (0.106) data 0.000 (0.016) loss 1.5992 (1.5213) teacher_loss 0.1983 (0.2162) loss_zs_kd 0.0549 (0.0581) loss_oracle 0.5984 (0.5304) kd_loss 1.0743 (1.0108) acc 90.6250 (91.4062) gate/entropy 0.9821 (0.9823) gate/usage_max 0.5693 (0.5690) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0553 (0.0509) teacher/usage_max 0.4171 (0.4982) teacher/usage_min 0.2376 (0.1727) teacher/usage_std 0.0738 (0.1360) nleep/row_max_mean 1559.0200 (1539.4097) nleep/row_max_std 48.8555 (57.0103) nleep/row_min_mean 1523.9578 (1508.9262) lr 8.1262e-04 eta 0:06:42
epoch [30/50] batch [40/181] time 0.081 (0.097) data 0.000 (0.008) loss 1.2347 (1.4617) teacher_loss 0.0206 (0.1832) loss_zs_kd 0.0262 (0.0531) loss_oracle 0.5138 (0.5266) kd_loss 0.9441 (0.9886) acc 100.0000 (92.8125) gate/entropy 0.9824 (0.9824) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1666 (0.1666) teacher/entropy 0.1266 (0.0585) teacher/usage_max 0.4781 (0.5087) teacher/usage_min 0.1893 (0.1752) teacher/usage_std 0.1179 (0.1399) nleep/row_max_mean 1548.6492 (1539.7459) nleep/row_max_std 63.8440 (57.4002) nleep/row_min_mean 1519.5461 (1508.8950) lr 8.1262e-04 eta 0:06:03
epoch [30/50] batch [60/181] time 0.143 (0.105) data 0.000 (0.005) loss 1.4924 (1.4562) teacher_loss 0.2085 (0.1777) loss_zs_kd 0.0589 (0.0519) loss_oracle 0.5579 (0.5308) kd_loss 0.9755 (0.9872) acc 93.7500 (93.0208) gate/entropy 0.9823 (0.9824) gate/usage_max 0.5691 (0.5690) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1667 (0.1666) teacher/entropy 0.0738 (0.0601) teacher/usage_max 0.5004 (0.5086) teacher/usage_min 0.2091 (0.1782) teacher/usage_std 0.1227 (0.1391) nleep/row_max_mean 1540.2810 (1540.5984) nleep/row_max_std 64.9104 (56.1824) nleep/row_min_mean 1512.1030 (1509.9071) lr 8.1262e-04 eta 0:06:33
epoch [30/50] batch [80/181] time 0.138 (0.117) data 0.000 (0.004) loss 1.2809 (1.4414) teacher_loss 0.1683 (0.1752) loss_zs_kd 0.0515 (0.0523) loss_oracle 0.5126 (0.5354) kd_loss 0.8305 (0.9724) acc 93.7500 (93.0469) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5691 (0.5690) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1667 (0.1666) teacher/entropy 0.0487 (0.0611) teacher/usage_max 0.6750 (0.5212) teacher/usage_min 0.1524 (0.1767) teacher/usage_std 0.2418 (0.1462) nleep/row_max_mean 1547.9476 (1541.3658) nleep/row_max_std 63.5095 (56.0006) nleep/row_min_mean 1514.2468 (1510.4750) lr 8.1262e-04 eta 0:07:14
epoch [30/50] batch [100/181] time 0.155 (0.123) data 0.000 (0.003) loss 1.3208 (1.4420) teacher_loss 0.1189 (0.1814) loss_zs_kd 0.0727 (0.0530) loss_oracle 0.4828 (0.5455) kd_loss 0.9242 (0.9614) acc 93.7500 (92.7500) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5691 (0.5690) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1667 (0.1666) teacher/entropy 0.0777 (0.0630) teacher/usage_max 0.5495 (0.5296) teacher/usage_min 0.0941 (0.1746) teacher/usage_std 0.1866 (0.1513) nleep/row_max_mean 1539.4098 (1541.9461) nleep/row_max_std 57.6881 (55.9808) nleep/row_min_mean 1511.7688 (1510.7988) lr 8.1262e-04 eta 0:07:37
epoch [30/50] batch [120/181] time 0.136 (0.128) data 0.000 (0.003) loss 1.5095 (1.4290) teacher_loss 0.0460 (0.1752) loss_zs_kd 0.0171 (0.0522) loss_oracle 0.7128 (0.5529) kd_loss 1.0985 (0.9513) acc 100.0000 (93.0208) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1666 (0.1666) teacher/entropy 0.0417 (0.0627) teacher/usage_max 0.4063 (0.5397) teacher/usage_min 0.2796 (0.1726) teacher/usage_std 0.0535 (0.1573) nleep/row_max_mean 1546.3188 (1542.1894) nleep/row_max_std 59.9780 (55.5900) nleep/row_min_mean 1510.7186 (1510.9347) lr 8.1262e-04 eta 0:07:52
epoch [30/50] batch [140/181] time 0.146 (0.132) data 0.000 (0.002) loss 1.4373 (1.4223) teacher_loss 0.2233 (0.1740) loss_zs_kd 0.0499 (0.0514) loss_oracle 0.5782 (0.5594) kd_loss 0.8999 (0.9429) acc 90.6250 (93.1473) gate/entropy 0.9825 (0.9823) gate/usage_max 0.5688 (0.5690) gate/usage_min 0.2153 (0.2152) gate/usage_std 0.1665 (0.1666) teacher/entropy 0.1558 (0.0664) teacher/usage_max 0.4930 (0.5441) teacher/usage_min 0.2258 (0.1720) teacher/usage_std 0.1151 (0.1598) nleep/row_max_mean 1520.7244 (1541.6325) nleep/row_max_std 58.6648 (55.5820) nleep/row_min_mean 1495.0312 (1510.4867) lr 8.1262e-04 eta 0:08:01
epoch [30/50] batch [160/181] time 0.166 (0.134) data 0.000 (0.002) loss 1.3616 (1.4115) teacher_loss 0.2316 (0.1749) loss_zs_kd 0.0434 (0.0509) loss_oracle 0.5389 (0.5598) kd_loss 0.8389 (0.9312) acc 87.5000 (93.2422) gate/entropy 0.9825 (0.9823) gate/usage_max 0.5689 (0.5690) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1666 (0.1666) teacher/entropy 0.0944 (0.0690) teacher/usage_max 0.6196 (0.5530) teacher/usage_min 0.1709 (0.1697) teacher/usage_std 0.2030 (0.1654) nleep/row_max_mean 1534.8052 (1540.9070) nleep/row_max_std 54.0860 (55.9793) nleep/row_min_mean 1502.8250 (1509.8912) lr 8.1262e-04 eta 0:08:07
epoch [30/50] batch [180/181] time 0.156 (0.135) data 0.000 (0.002) loss 1.1449 (1.4031) teacher_loss 0.0800 (0.1755) loss_zs_kd 0.0560 (0.0504) loss_oracle 0.5157 (0.5596) kd_loss 0.7790 (0.9227) acc 96.8750 (93.1597) gate/entropy 0.9824 (0.9823) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1666 (0.1666) teacher/entropy 0.0354 (0.0689) teacher/usage_max 0.7416 (0.5617) teacher/usage_min 0.1006 (0.1658) teacher/usage_std 0.2896 (0.1710) nleep/row_max_mean 1539.8062 (1540.4636) nleep/row_max_std 64.0941 (56.1647) nleep/row_min_mean 1507.6143 (1509.4582) lr 8.1262e-04 eta 0:08:09
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,424
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [31/50] batch [20/181] time 0.076 (0.116) data 0.000 (0.015) loss 1.4827 (1.3712) teacher_loss 0.2578 (0.1657) loss_zs_kd 0.0481 (0.0442) loss_oracle 0.6076 (0.6051) kd_loss 0.8970 (0.8808) acc 90.6250 (93.7500) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.1071 (0.0693) teacher/usage_max 0.5463 (0.6030) teacher/usage_min 0.1833 (0.1495) teacher/usage_std 0.1547 (0.1976) nleep/row_max_mean 1541.2334 (1542.3351) nleep/row_max_std 45.6751 (54.9798) nleep/row_min_mean 1511.3055 (1510.5476) lr 7.5131e-04 eta 0:06:57
epoch [31/50] batch [40/181] time 0.119 (0.119) data 0.000 (0.008) loss 1.4410 (1.3620) teacher_loss 0.2091 (0.1627) loss_zs_kd 0.0400 (0.0449) loss_oracle 0.6404 (0.5929) kd_loss 0.8917 (0.8804) acc 93.7500 (94.3750) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5691 (0.5690) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0676 (0.0702) teacher/usage_max 0.5929 (0.6021) teacher/usage_min 0.1610 (0.1583) teacher/usage_std 0.1868 (0.1952) nleep/row_max_mean 1556.4205 (1543.9553) nleep/row_max_std 47.0985 (53.7554) nleep/row_min_mean 1520.4335 (1512.0988) lr 7.5131e-04 eta 0:07:05
epoch [31/50] batch [60/181] time 0.080 (0.117) data 0.000 (0.005) loss 1.2299 (1.3604) teacher_loss 0.2625 (0.1708) loss_zs_kd 0.0609 (0.0462) loss_oracle 0.4899 (0.5957) kd_loss 0.6920 (0.8686) acc 90.6250 (94.2188) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5692 (0.5690) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0647 (0.0741) teacher/usage_max 0.8012 (0.6101) teacher/usage_min 0.0728 (0.1477) teacher/usage_std 0.3316 (0.2029) nleep/row_max_mean 1552.4734 (1543.3590) nleep/row_max_std 50.0829 (55.1754) nleep/row_min_mean 1520.8364 (1511.2333) lr 7.5131e-04 eta 0:06:56
epoch [31/50] batch [80/181] time 0.098 (0.118) data 0.000 (0.004) loss 1.2422 (1.3736) teacher_loss 0.1099 (0.1809) loss_zs_kd 0.0391 (0.0468) loss_oracle 0.5373 (0.5936) kd_loss 0.8441 (0.8725) acc 96.8750 (93.9062) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.1453 (0.0766) teacher/usage_max 0.5616 (0.6034) teacher/usage_min 0.1667 (0.1458) teacher/usage_std 0.1670 (0.1994) nleep/row_max_mean 1536.0139 (1543.3547) nleep/row_max_std 68.8128 (55.8684) nleep/row_min_mean 1505.5496 (1511.4289) lr 7.5131e-04 eta 0:06:58
epoch [31/50] batch [100/181] time 0.094 (0.114) data 0.000 (0.003) loss 1.3224 (1.3720) teacher_loss 0.2289 (0.1849) loss_zs_kd 0.0262 (0.0468) loss_oracle 0.4716 (0.5925) kd_loss 0.8446 (0.8674) acc 87.5000 (93.7188) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.1837 (0.0792) teacher/usage_max 0.5221 (0.6059) teacher/usage_min 0.1404 (0.1420) teacher/usage_std 0.1559 (0.2017) nleep/row_max_mean 1538.5977 (1542.2620) nleep/row_max_std 54.3105 (56.7187) nleep/row_min_mean 1514.8982 (1510.3618) lr 7.5131e-04 eta 0:06:42
epoch [31/50] batch [120/181] time 0.079 (0.115) data 0.000 (0.003) loss 1.3339 (1.3709) teacher_loss 0.1563 (0.1903) loss_zs_kd 0.0725 (0.0463) loss_oracle 0.4893 (0.5876) kd_loss 0.8966 (0.8637) acc 93.7500 (93.4896) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.1101 (0.0838) teacher/usage_max 0.5441 (0.6051) teacher/usage_min 0.2006 (0.1416) teacher/usage_std 0.1507 (0.2012) nleep/row_max_mean 1520.1387 (1540.7956) nleep/row_max_std 63.2733 (56.7678) nleep/row_min_mean 1496.6694 (1509.4908) lr 7.5131e-04 eta 0:06:42
epoch [31/50] batch [140/181] time 0.078 (0.115) data 0.000 (0.002) loss 1.4212 (1.3751) teacher_loss 0.1005 (0.1893) loss_zs_kd 0.0315 (0.0457) loss_oracle 0.7510 (0.5888) kd_loss 0.9294 (0.8685) acc 96.8750 (93.5268) gate/entropy 0.9824 (0.9823) gate/usage_max 0.5689 (0.5691) gate/usage_min 0.2152 (0.2151) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.1026 (0.0862) teacher/usage_max 0.5177 (0.5975) teacher/usage_min 0.1565 (0.1447) teacher/usage_std 0.1476 (0.1965) nleep/row_max_mean 1541.4438 (1540.2603) nleep/row_max_std 66.4622 (56.7440) nleep/row_min_mean 1505.6605 (1509.2283) lr 7.5131e-04 eta 0:06:40
epoch [31/50] batch [160/181] time 0.153 (0.116) data 0.000 (0.002) loss 1.3502 (1.3784) teacher_loss 0.1170 (0.1884) loss_zs_kd 0.0231 (0.0450) loss_oracle 0.5171 (0.5864) kd_loss 0.9630 (0.8744) acc 90.6250 (93.4766) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5691) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0742 (0.0878) teacher/usage_max 0.5129 (0.5905) teacher/usage_min 0.2339 (0.1493) teacher/usage_std 0.1272 (0.1916) nleep/row_max_mean 1531.7047 (1539.5818) nleep/row_max_std 68.5653 (57.2017) nleep/row_min_mean 1503.1239 (1508.8629) lr 7.5131e-04 eta 0:06:41
epoch [31/50] batch [180/181] time 0.147 (0.119) data 0.000 (0.002) loss 1.3296 (1.3774) teacher_loss 0.1137 (0.1858) loss_zs_kd 0.0549 (0.0444) loss_oracle 0.5294 (0.5789) kd_loss 0.9238 (0.8800) acc 100.0000 (93.5764) gate/entropy 0.9824 (0.9823) gate/usage_max 0.5689 (0.5691) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.0888 (0.0903) teacher/usage_max 0.5382 (0.5829) teacher/usage_min 0.2276 (0.1550) teacher/usage_std 0.1449 (0.1860) nleep/row_max_mean 1530.8794 (1538.9868) nleep/row_max_std 54.3969 (57.3614) nleep/row_min_mean 1502.5773 (1508.6896) lr 7.5131e-04 eta 0:06:49
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,422
* accuracy: 97.0%
* error: 3.0%
* macro_f1: 97.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,664
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.6%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [32/50] batch [20/181] time 0.138 (0.164) data 0.000 (0.017) loss 1.5503 (1.3987) teacher_loss 0.1405 (0.1410) loss_zs_kd 0.0544 (0.0415) loss_oracle 0.5584 (0.5522) kd_loss 1.1034 (0.9608) acc 93.7500 (94.2188) gate/entropy 0.9824 (0.9823) gate/usage_max 0.5689 (0.5691) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.1171 (0.0959) teacher/usage_max 0.4672 (0.5033) teacher/usage_min 0.2094 (0.2024) teacher/usage_std 0.1055 (0.1284) nleep/row_max_mean 1531.9070 (1532.1511) nleep/row_max_std 54.0460 (57.0435) nleep/row_min_mean 1503.6077 (1504.1646) lr 6.9098e-04 eta 0:09:19
epoch [32/50] batch [40/181] time 0.150 (0.156) data 0.000 (0.009) loss 1.4019 (1.4259) teacher_loss 0.1884 (0.1599) loss_zs_kd 0.0610 (0.0464) loss_oracle 0.5391 (0.5640) kd_loss 0.9135 (0.9609) acc 90.6250 (94.1406) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0837 (0.0853) teacher/usage_max 0.5539 (0.5102) teacher/usage_min 0.1467 (0.2049) teacher/usage_std 0.1679 (0.1323) nleep/row_max_mean 1543.4622 (1535.0070) nleep/row_max_std 54.8308 (57.0903) nleep/row_min_mean 1514.4528 (1506.6522) lr 6.9098e-04 eta 0:08:50
epoch [32/50] batch [60/181] time 0.163 (0.153) data 0.000 (0.006) loss 1.5427 (1.4235) teacher_loss 0.2471 (0.1690) loss_zs_kd 0.0522 (0.0493) loss_oracle 0.6519 (0.5735) kd_loss 0.9435 (0.9431) acc 93.7500 (93.9583) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0814 (0.0848) teacher/usage_max 0.5248 (0.5267) teacher/usage_min 0.1276 (0.1932) teacher/usage_std 0.1625 (0.1439) nleep/row_max_mean 1545.1353 (1536.1238) nleep/row_max_std 55.2016 (58.6981) nleep/row_min_mean 1511.2911 (1507.0122) lr 6.9098e-04 eta 0:08:35
epoch [32/50] batch [80/181] time 0.156 (0.151) data 0.000 (0.004) loss 1.4578 (1.4213) teacher_loss 0.1785 (0.1659) loss_zs_kd 0.0334 (0.0493) loss_oracle 0.6886 (0.5750) kd_loss 0.9183 (0.9433) acc 93.7500 (94.0234) gate/entropy 0.9824 (0.9823) gate/usage_max 0.5690 (0.5691) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.0755 (0.0793) teacher/usage_max 0.5572 (0.5311) teacher/usage_min 0.1828 (0.1870) teacher/usage_std 0.1614 (0.1481) nleep/row_max_mean 1537.3818 (1537.6051) nleep/row_max_std 70.1874 (59.4845) nleep/row_min_mean 1501.8801 (1508.0412) lr 6.9098e-04 eta 0:08:27
epoch [32/50] batch [100/181] time 0.151 (0.150) data 0.000 (0.004) loss 1.4561 (1.4149) teacher_loss 0.1904 (0.1659) loss_zs_kd 0.0523 (0.0488) loss_oracle 0.5530 (0.5724) kd_loss 0.9632 (0.9383) acc 93.7500 (94.0312) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.1080 (0.0778) teacher/usage_max 0.4773 (0.5371) teacher/usage_min 0.1735 (0.1854) teacher/usage_std 0.1245 (0.1516) nleep/row_max_mean 1552.3203 (1538.7610) nleep/row_max_std 52.0294 (59.4750) nleep/row_min_mean 1518.9641 (1508.9448) lr 6.9098e-04 eta 0:08:19
epoch [32/50] batch [120/181] time 0.094 (0.142) data 0.000 (0.003) loss 1.3327 (1.4127) teacher_loss 0.1438 (0.1683) loss_zs_kd 0.0328 (0.0491) loss_oracle 0.5727 (0.5728) kd_loss 0.8862 (0.9334) acc 93.7500 (93.9844) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.1240 (0.0759) teacher/usage_max 0.5405 (0.5436) teacher/usage_min 0.2223 (0.1832) teacher/usage_std 0.1466 (0.1559) nleep/row_max_mean 1541.8901 (1539.5722) nleep/row_max_std 62.5809 (59.7546) nleep/row_min_mean 1513.3435 (1509.4464) lr 6.9098e-04 eta 0:07:52
epoch [32/50] batch [140/181] time 0.080 (0.137) data 0.000 (0.003) loss 1.2161 (1.4109) teacher_loss 0.1694 (0.1694) loss_zs_kd 0.0348 (0.0483) loss_oracle 0.4950 (0.5707) kd_loss 0.7818 (0.9320) acc 90.6250 (93.9062) gate/entropy 0.9822 (0.9823) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0610 (0.0738) teacher/usage_max 0.7127 (0.5469) teacher/usage_min 0.1162 (0.1830) teacher/usage_std 0.2692 (0.1578) nleep/row_max_mean 1546.4189 (1539.6190) nleep/row_max_std 60.4827 (59.9093) nleep/row_min_mean 1514.8428 (1509.3151) lr 6.9098e-04 eta 0:07:30
epoch [32/50] batch [160/181] time 0.087 (0.133) data 0.000 (0.002) loss 1.4317 (1.4038) teacher_loss 0.1272 (0.1654) loss_zs_kd 0.0669 (0.0476) loss_oracle 0.5920 (0.5694) kd_loss 0.9751 (0.9299) acc 93.7500 (94.0625) gate/entropy 0.9821 (0.9823) gate/usage_max 0.5693 (0.5691) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0542 (0.0724) teacher/usage_max 0.5202 (0.5503) teacher/usage_min 0.1606 (0.1804) teacher/usage_std 0.1472 (0.1604) nleep/row_max_mean 1560.4583 (1539.4322) nleep/row_max_std 52.7483 (60.5122) nleep/row_min_mean 1526.3446 (1508.9223) lr 6.9098e-04 eta 0:07:17
epoch [32/50] batch [180/181] time 0.073 (0.131) data 0.000 (0.002) loss 1.5093 (1.4014) teacher_loss 0.2863 (0.1684) loss_zs_kd 0.0420 (0.0479) loss_oracle 0.5452 (0.5698) kd_loss 0.9294 (0.9241) acc 87.5000 (93.8889) gate/entropy 0.9824 (0.9823) gate/usage_max 0.5690 (0.5691) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.1004 (0.0707) teacher/usage_max 0.5204 (0.5577) teacher/usage_min 0.2192 (0.1773) teacher/usage_std 0.1333 (0.1654) nleep/row_max_mean 1535.5684 (1538.9810) nleep/row_max_std 52.1124 (60.9144) nleep/row_min_mean 1506.1494 (1508.3519) lr 6.9098e-04 eta 0:07:06
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,421
* accuracy: 97.0%
* error: 3.0%
* macro_f1: 97.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [33/50] batch [20/181] time 0.064 (0.125) data 0.000 (0.015) loss 1.4810 (1.4231) teacher_loss 0.1380 (0.1648) loss_zs_kd 0.0474 (0.0488) loss_oracle 0.5261 (0.5901) kd_loss 1.0563 (0.9389) acc 96.8750 (93.5938) gate/entropy 0.9822 (0.9822) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0381 (0.0616) teacher/usage_max 0.4538 (0.5503) teacher/usage_min 0.1594 (0.1746) teacher/usage_std 0.1260 (0.1624) nleep/row_max_mean 1539.0874 (1539.0279) nleep/row_max_std 64.0934 (64.0029) nleep/row_min_mean 1508.5768 (1506.6721) lr 6.3188e-04 eta 0:06:44
epoch [33/50] batch [40/181] time 0.060 (0.116) data 0.000 (0.007) loss 1.2952 (1.3995) teacher_loss 0.1049 (0.1604) loss_zs_kd 0.0325 (0.0462) loss_oracle 0.6090 (0.5761) kd_loss 0.8695 (0.9279) acc 93.7500 (93.9062) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0416 (0.0631) teacher/usage_max 0.6424 (0.5620) teacher/usage_min 0.1200 (0.1681) teacher/usage_std 0.2237 (0.1708) nleep/row_max_mean 1533.5698 (1537.9346) nleep/row_max_std 59.6408 (61.7767) nleep/row_min_mean 1500.7566 (1506.4529) lr 6.3188e-04 eta 0:06:13
epoch [33/50] batch [60/181] time 0.162 (0.117) data 0.001 (0.005) loss 1.2723 (1.3991) teacher_loss 0.1899 (0.1615) loss_zs_kd 0.0356 (0.0457) loss_oracle 0.5280 (0.5828) kd_loss 0.8006 (0.9233) acc 90.6250 (93.6979) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5690 (0.5691) gate/usage_min 0.2151 (0.2150) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.1443 (0.0623) teacher/usage_max 0.6077 (0.5669) teacher/usage_min 0.1608 (0.1651) teacher/usage_std 0.1961 (0.1740) nleep/row_max_mean 1520.8022 (1535.1011) nleep/row_max_std 53.0289 (61.3997) nleep/row_min_mean 1495.5513 (1503.7950) lr 6.3188e-04 eta 0:06:13
epoch [33/50] batch [80/181] time 0.134 (0.125) data 0.000 (0.004) loss 1.3700 (1.3957) teacher_loss 0.1201 (0.1563) loss_zs_kd 0.0569 (0.0467) loss_oracle 0.4879 (0.5795) kd_loss 0.9775 (0.9263) acc 96.8750 (93.9844) gate/entropy 0.9820 (0.9822) gate/usage_max 0.5693 (0.5691) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1669 (0.1667) teacher/entropy 0.0832 (0.0610) teacher/usage_max 0.4887 (0.5649) teacher/usage_min 0.2123 (0.1678) teacher/usage_std 0.1154 (0.1723) nleep/row_max_mean 1537.5653 (1534.0983) nleep/row_max_std 51.7534 (60.0312) nleep/row_min_mean 1510.6594 (1503.0181) lr 6.3188e-04 eta 0:06:38
epoch [33/50] batch [100/181] time 0.148 (0.128) data 0.000 (0.003) loss 1.2733 (1.3938) teacher_loss 0.1238 (0.1548) loss_zs_kd 0.0252 (0.0464) loss_oracle 0.5707 (0.5785) kd_loss 0.8515 (0.9265) acc 96.8750 (94.1250) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0476 (0.0619) teacher/usage_max 0.6545 (0.5635) teacher/usage_min 0.1550 (0.1709) teacher/usage_std 0.2276 (0.1707) nleep/row_max_mean 1537.3409 (1533.1652) nleep/row_max_std 55.4594 (59.3316) nleep/row_min_mean 1504.4229 (1502.0559) lr 6.3188e-04 eta 0:06:43
epoch [33/50] batch [120/181] time 0.131 (0.129) data 0.000 (0.003) loss 1.3174 (1.3971) teacher_loss 0.1222 (0.1592) loss_zs_kd 0.0636 (0.0474) loss_oracle 0.5941 (0.5778) kd_loss 0.8663 (0.9254) acc 96.8750 (94.0104) gate/entropy 0.9824 (0.9822) gate/usage_max 0.5690 (0.5691) gate/usage_min 0.2151 (0.2150) gate/usage_std 0.1666 (0.1667) teacher/entropy 0.0603 (0.0616) teacher/usage_max 0.6269 (0.5649) teacher/usage_min 0.0961 (0.1701) teacher/usage_std 0.2203 (0.1717) nleep/row_max_mean 1518.4973 (1532.5629) nleep/row_max_std 62.3055 (58.3721) nleep/row_min_mean 1485.5078 (1501.5703) lr 6.3188e-04 eta 0:06:45
epoch [33/50] batch [140/181] time 0.153 (0.132) data 0.000 (0.002) loss 1.2629 (1.4040) teacher_loss 0.1403 (0.1612) loss_zs_kd 0.0426 (0.0480) loss_oracle 0.4970 (0.5793) kd_loss 0.8529 (0.9292) acc 93.7500 (93.9509) gate/entropy 0.9820 (0.9822) gate/usage_max 0.5694 (0.5692) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1669 (0.1667) teacher/entropy 0.1439 (0.0616) teacher/usage_max 0.5545 (0.5616) teacher/usage_min 0.2173 (0.1729) teacher/usage_std 0.1565 (0.1693) nleep/row_max_mean 1529.9666 (1532.3958) nleep/row_max_std 67.0522 (58.2542) nleep/row_min_mean 1500.4767 (1501.3524) lr 6.3188e-04 eta 0:06:50
epoch [33/50] batch [160/181] time 0.133 (0.133) data 0.000 (0.002) loss 1.5695 (1.4034) teacher_loss 0.2572 (0.1647) loss_zs_kd 0.0497 (0.0477) loss_oracle 0.5876 (0.5781) kd_loss 0.9936 (0.9258) acc 87.5000 (93.8672) gate/entropy 0.9820 (0.9822) gate/usage_max 0.5693 (0.5691) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1669 (0.1667) teacher/entropy 0.0384 (0.0601) teacher/usage_max 0.5178 (0.5665) teacher/usage_min 0.2207 (0.1714) teacher/usage_std 0.1315 (0.1722) nleep/row_max_mean 1554.2975 (1531.7689) nleep/row_max_std 45.7314 (58.6050) nleep/row_min_mean 1520.0601 (1500.7384) lr 6.3188e-04 eta 0:06:52
epoch [33/50] batch [180/181] time 0.121 (0.134) data 0.000 (0.002) loss 1.4691 (1.4059) teacher_loss 0.1931 (0.1646) loss_zs_kd 0.0430 (0.0482) loss_oracle 0.5778 (0.5794) kd_loss 0.9656 (0.9275) acc 96.8750 (93.9236) gate/entropy 0.9822 (0.9822) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0617 (0.0592) teacher/usage_max 0.5227 (0.5655) teacher/usage_min 0.1888 (0.1711) teacher/usage_std 0.1400 (0.1718) nleep/row_max_mean 1539.0149 (1532.4116) nleep/row_max_std 66.0616 (58.7431) nleep/row_min_mean 1506.3314 (1501.1145) lr 6.3188e-04 eta 0:06:51
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,421
* accuracy: 97.0%
* error: 3.0%
* macro_f1: 97.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.7%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [34/50] batch [20/181] time 0.085 (0.127) data 0.000 (0.017) loss 1.3151 (1.3789) teacher_loss 0.0499 (0.1633) loss_zs_kd 0.0385 (0.0483) loss_oracle 0.6090 (0.5640) kd_loss 0.9415 (0.9094) acc 100.0000 (94.0625) gate/entropy 0.9819 (0.9821) gate/usage_max 0.5695 (0.5692) gate/usage_min 0.2148 (0.2150) gate/usage_std 0.1670 (0.1668) teacher/entropy 0.0725 (0.0517) teacher/usage_max 0.5360 (0.5907) teacher/usage_min 0.1381 (0.1584) teacher/usage_std 0.1625 (0.1889) nleep/row_max_mean 1557.7319 (1534.0687) nleep/row_max_std 46.0151 (56.0808) nleep/row_min_mean 1521.7053 (1502.8829) lr 5.7422e-04 eta 0:06:27
epoch [34/50] batch [40/181] time 0.176 (0.119) data 0.000 (0.008) loss 1.4354 (1.3875) teacher_loss 0.1975 (0.1636) loss_zs_kd 0.0660 (0.0473) loss_oracle 0.5619 (0.5663) kd_loss 0.9240 (0.9170) acc 93.7500 (94.3750) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5692 (0.5692) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0310 (0.0561) teacher/usage_max 0.5974 (0.5784) teacher/usage_min 0.1269 (0.1708) teacher/usage_std 0.1964 (0.1788) nleep/row_max_mean 1524.1499 (1530.8102) nleep/row_max_std 49.3690 (57.2088) nleep/row_min_mean 1498.5588 (1500.2157) lr 5.7422e-04 eta 0:06:00
epoch [34/50] batch [60/181] time 0.082 (0.115) data 0.001 (0.006) loss 1.3292 (1.3880) teacher_loss 0.0479 (0.1564) loss_zs_kd 0.0307 (0.0478) loss_oracle 0.6539 (0.5752) kd_loss 0.9390 (0.9201) acc 100.0000 (94.5833) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0693 (0.0532) teacher/usage_max 0.5420 (0.5783) teacher/usage_min 0.1330 (0.1620) teacher/usage_std 0.1671 (0.1817) nleep/row_max_mean 1526.9220 (1531.6215) nleep/row_max_std 62.6492 (57.6879) nleep/row_min_mean 1495.7623 (1500.3621) lr 5.7422e-04 eta 0:05:47
epoch [34/50] batch [80/181] time 0.066 (0.115) data 0.000 (0.004) loss 1.2860 (1.3826) teacher_loss 0.0660 (0.1565) loss_zs_kd 0.0373 (0.0478) loss_oracle 0.6566 (0.5759) kd_loss 0.8731 (0.9142) acc 96.8750 (94.6875) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5692 (0.5692) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0216 (0.0556) teacher/usage_max 0.6590 (0.5819) teacher/usage_min 0.0644 (0.1609) teacher/usage_std 0.2460 (0.1836) nleep/row_max_mean 1542.8013 (1532.9114) nleep/row_max_std 57.4867 (57.6913) nleep/row_min_mean 1507.3326 (1501.3113) lr 5.7422e-04 eta 0:05:43
epoch [34/50] batch [100/181] time 0.090 (0.115) data 0.000 (0.003) loss 1.4059 (1.3832) teacher_loss 0.1618 (0.1570) loss_zs_kd 0.0602 (0.0482) loss_oracle 0.5949 (0.5790) kd_loss 0.9166 (0.9125) acc 96.8750 (94.5312) gate/entropy 0.9820 (0.9822) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.0694 (0.0563) teacher/usage_max 0.5653 (0.5829) teacher/usage_min 0.0700 (0.1548) teacher/usage_std 0.2034 (0.1861) nleep/row_max_mean 1536.7771 (1532.4975) nleep/row_max_std 60.5281 (57.8755) nleep/row_min_mean 1505.2961 (1500.9513) lr 5.7422e-04 eta 0:05:41
epoch [34/50] batch [120/181] time 0.088 (0.113) data 0.000 (0.003) loss 1.4020 (1.3876) teacher_loss 0.2130 (0.1597) loss_zs_kd 0.0467 (0.0484) loss_oracle 0.5790 (0.5808) kd_loss 0.8761 (0.9133) acc 90.6250 (94.4271) gate/entropy 0.9822 (0.9822) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0363 (0.0575) teacher/usage_max 0.6411 (0.5808) teacher/usage_min 0.1434 (0.1553) teacher/usage_std 0.2196 (0.1847) nleep/row_max_mean 1533.9321 (1532.2363) nleep/row_max_std 68.4383 (58.1306) nleep/row_min_mean 1497.8174 (1500.7213) lr 5.7422e-04 eta 0:05:35
epoch [34/50] batch [140/181] time 0.077 (0.113) data 0.000 (0.003) loss 1.2256 (1.3802) teacher_loss 0.1065 (0.1562) loss_zs_kd 0.0180 (0.0476) loss_oracle 0.5193 (0.5767) kd_loss 0.8505 (0.9119) acc 96.8750 (94.6205) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0449 (0.0586) teacher/usage_max 0.6581 (0.5811) teacher/usage_min 0.1541 (0.1569) teacher/usage_std 0.2301 (0.1843) nleep/row_max_mean 1544.4634 (1532.6209) nleep/row_max_std 50.2960 (58.0107) nleep/row_min_mean 1509.5244 (1501.1832) lr 5.7422e-04 eta 0:05:31
epoch [34/50] batch [160/181] time 0.102 (0.113) data 0.000 (0.002) loss 1.2703 (1.3805) teacher_loss 0.0585 (0.1586) loss_zs_kd 0.0385 (0.0473) loss_oracle 0.6154 (0.5763) kd_loss 0.8848 (0.9101) acc 100.0000 (94.4336) gate/entropy 0.9820 (0.9822) gate/usage_max 0.5694 (0.5692) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.0950 (0.0577) teacher/usage_max 0.5712 (0.5839) teacher/usage_min 0.1745 (0.1571) teacher/usage_std 0.1713 (0.1858) nleep/row_max_mean 1553.0952 (1532.5754) nleep/row_max_std 53.7687 (58.0097) nleep/row_min_mean 1518.0095 (1501.0667) lr 5.7422e-04 eta 0:05:28
epoch [34/50] batch [180/181] time 0.155 (0.112) data 0.000 (0.002) loss 1.1553 (1.3820) teacher_loss 0.1416 (0.1588) loss_zs_kd 0.0537 (0.0475) loss_oracle 0.4784 (0.5758) kd_loss 0.7476 (0.9115) acc 96.8750 (94.5833) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5692 (0.5692) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1668 (0.1668) teacher/entropy 0.0800 (0.0579) teacher/usage_max 0.7283 (0.5822) teacher/usage_min 0.1027 (0.1590) teacher/usage_std 0.2806 (0.1843) nleep/row_max_mean 1536.2660 (1532.6953) nleep/row_max_std 54.6490 (57.8011) nleep/row_min_mean 1506.8843 (1501.2038) lr 5.7422e-04 eta 0:05:24
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,414
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,663
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.6%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [35/50] batch [20/181] time 0.155 (0.162) data 0.000 (0.015) loss 1.2495 (1.4423) teacher_loss 0.1609 (0.1916) loss_zs_kd 0.0399 (0.0520) loss_oracle 0.4774 (0.5861) kd_loss 0.8299 (0.9317) acc 93.7500 (92.8125) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2150 (0.2149) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0487 (0.0586) teacher/usage_max 0.6760 (0.5606) teacher/usage_min 0.1568 (0.1621) teacher/usage_std 0.2423 (0.1704) nleep/row_max_mean 1520.4243 (1533.4807) nleep/row_max_std 62.5143 (59.5522) nleep/row_min_mean 1492.2134 (1501.6397) lr 5.1825e-04 eta 0:07:45
epoch [35/50] batch [40/181] time 0.188 (0.159) data 0.000 (0.008) loss 1.3131 (1.4330) teacher_loss 0.1631 (0.2020) loss_zs_kd 0.0359 (0.0522) loss_oracle 0.6123 (0.5822) kd_loss 0.8258 (0.9137) acc 93.7500 (92.1875) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2150 (0.2149) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0965 (0.0618) teacher/usage_max 0.6307 (0.5759) teacher/usage_min 0.1246 (0.1614) teacher/usage_std 0.2159 (0.1802) nleep/row_max_mean 1525.5176 (1534.3479) nleep/row_max_std 51.5512 (59.4142) nleep/row_min_mean 1501.5515 (1502.5628) lr 5.1825e-04 eta 0:07:34
epoch [35/50] batch [60/181] time 0.170 (0.161) data 0.000 (0.005) loss 1.2715 (1.4226) teacher_loss 0.1065 (0.1798) loss_zs_kd 0.0498 (0.0493) loss_oracle 0.5946 (0.5903) kd_loss 0.8428 (0.9230) acc 100.0000 (93.4375) gate/entropy 0.9825 (0.9821) gate/usage_max 0.5689 (0.5692) gate/usage_min 0.2151 (0.2149) gate/usage_std 0.1666 (0.1668) teacher/entropy 0.0631 (0.0616) teacher/usage_max 0.6479 (0.5666) teacher/usage_min 0.1261 (0.1650) teacher/usage_std 0.2262 (0.1741) nleep/row_max_mean 1524.1439 (1537.2115) nleep/row_max_std 59.0421 (58.1726) nleep/row_min_mean 1495.9836 (1505.0663) lr 5.1825e-04 eta 0:07:36
epoch [35/50] batch [80/181] time 0.188 (0.162) data 0.000 (0.004) loss 1.4383 (1.4466) teacher_loss 0.2088 (0.1898) loss_zs_kd 0.0586 (0.0505) loss_oracle 0.5785 (0.5935) kd_loss 0.9110 (0.9348) acc 90.6250 (93.4375) gate/entropy 0.9823 (0.9821) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2150 (0.2149) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0487 (0.0604) teacher/usage_max 0.5917 (0.5558) teacher/usage_min 0.0645 (0.1664) teacher/usage_std 0.2154 (0.1683) nleep/row_max_mean 1524.4537 (1538.5762) nleep/row_max_std 66.9691 (58.0636) nleep/row_min_mean 1495.4270 (1506.1524) lr 5.1825e-04 eta 0:07:34
epoch [35/50] batch [100/181] time 0.156 (0.162) data 0.000 (0.003) loss 1.4945 (1.4320) teacher_loss 0.1170 (0.1851) loss_zs_kd 0.0455 (0.0504) loss_oracle 0.6241 (0.5815) kd_loss 1.0427 (0.9310) acc 93.7500 (93.5625) gate/entropy 0.9823 (0.9821) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2150 (0.2149) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0378 (0.0627) teacher/usage_max 0.4676 (0.5574) teacher/usage_min 0.2305 (0.1677) teacher/usage_std 0.0993 (0.1689) nleep/row_max_mean 1537.1978 (1538.1315) nleep/row_max_std 53.9699 (57.5395) nleep/row_min_mean 1504.2971 (1506.1618) lr 5.1825e-04 eta 0:07:31
epoch [35/50] batch [120/181] time 0.112 (0.159) data 0.000 (0.003) loss 1.6944 (1.4430) teacher_loss 0.2695 (0.1856) loss_zs_kd 0.0726 (0.0514) loss_oracle 0.6758 (0.5848) kd_loss 1.0508 (0.9394) acc 90.6250 (93.5417) gate/entropy 0.9820 (0.9821) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2148 (0.2149) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.1290 (0.0642) teacher/usage_max 0.4652 (0.5490) teacher/usage_min 0.1694 (0.1685) teacher/usage_std 0.1229 (0.1646) nleep/row_max_mean 1540.9294 (1538.1419) nleep/row_max_std 53.4602 (57.5771) nleep/row_min_mean 1511.8452 (1506.1945) lr 5.1825e-04 eta 0:07:21
epoch [35/50] batch [140/181] time 0.157 (0.152) data 0.000 (0.002) loss 1.4431 (1.4584) teacher_loss 0.2212 (0.1883) loss_zs_kd 0.0757 (0.0522) loss_oracle 0.4937 (0.5856) kd_loss 0.9371 (0.9512) acc 96.8750 (93.5491) gate/entropy 0.9823 (0.9821) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2150 (0.2149) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.1431 (0.0656) teacher/usage_max 0.4677 (0.5392) teacher/usage_min 0.1229 (0.1732) teacher/usage_std 0.1507 (0.1585) nleep/row_max_mean 1517.2821 (1537.3204) nleep/row_max_std 66.7186 (57.3687) nleep/row_min_mean 1491.3884 (1505.6049) lr 5.1825e-04 eta 0:06:58
epoch [35/50] batch [160/181] time 0.148 (0.146) data 0.000 (0.002) loss 1.3704 (1.4687) teacher_loss 0.2097 (0.1893) loss_zs_kd 0.0427 (0.0515) loss_oracle 0.4429 (0.5838) kd_loss 0.9179 (0.9618) acc 90.6250 (93.3008) gate/entropy 0.9823 (0.9821) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0704 (0.0655) teacher/usage_max 0.5629 (0.5293) teacher/usage_min 0.2027 (0.1760) teacher/usage_std 0.1628 (0.1528) nleep/row_max_mean 1516.5372 (1536.9818) nleep/row_max_std 63.4283 (57.7375) nleep/row_min_mean 1491.3022 (1505.3903) lr 5.1825e-04 eta 0:06:39
epoch [35/50] batch [180/181] time 0.065 (0.142) data 0.000 (0.002) loss 1.4593 (1.4802) teacher_loss 0.1018 (0.1905) loss_zs_kd 0.0509 (0.0514) loss_oracle 0.6828 (0.5847) kd_loss 0.9907 (0.9716) acc 96.8750 (93.2812) gate/entropy 0.9820 (0.9821) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2148 (0.2149) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.0530 (0.0655) teacher/usage_max 0.5054 (0.5223) teacher/usage_min 0.1417 (0.1787) teacher/usage_std 0.1491 (0.1485) nleep/row_max_mean 1549.6687 (1537.0682) nleep/row_max_std 58.4734 (57.8007) nleep/row_min_mean 1511.3643 (1505.3242) lr 5.1825e-04 eta 0:06:26
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,423
* accuracy: 97.0%
* error: 3.0%
* macro_f1: 97.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [36/50] batch [20/181] time 0.075 (0.137) data 0.000 (0.019) loss 1.4840 (1.5198) teacher_loss 0.0890 (0.1689) loss_zs_kd 0.0488 (0.0487) loss_oracle 0.5414 (0.5760) kd_loss 1.1000 (1.0386) acc 96.8750 (94.0625) gate/entropy 0.9823 (0.9821) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0778 (0.0540) teacher/usage_max 0.3680 (0.4711) teacher/usage_min 0.2794 (0.1901) teacher/usage_std 0.0387 (0.1207) nleep/row_max_mean 1532.7834 (1539.6137) nleep/row_max_std 63.6744 (58.1230) nleep/row_min_mean 1499.0912 (1506.9639) lr 4.6417e-04 eta 0:06:10
epoch [36/50] batch [40/181] time 0.070 (0.123) data 0.000 (0.010) loss 1.4560 (1.5269) teacher_loss 0.0848 (0.1707) loss_zs_kd 0.0467 (0.0511) loss_oracle 0.5722 (0.5863) kd_loss 1.0618 (1.0375) acc 100.0000 (94.2188) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.1539 (0.0554) teacher/usage_max 0.3533 (0.4761) teacher/usage_min 0.3177 (0.1881) teacher/usage_std 0.0148 (0.1240) nleep/row_max_mean 1528.2600 (1538.6065) nleep/row_max_std 49.9691 (61.1147) nleep/row_min_mean 1499.8010 (1505.3819) lr 4.6417e-04 eta 0:05:29
epoch [36/50] batch [60/181] time 0.158 (0.124) data 0.000 (0.007) loss 1.6624 (1.5345) teacher_loss 0.1230 (0.1691) loss_zs_kd 0.0356 (0.0518) loss_oracle 0.6120 (0.5908) kd_loss 1.2157 (1.0441) acc 96.8750 (94.4792) gate/entropy 0.9820 (0.9822) gate/usage_max 0.5693 (0.5692) gate/usage_min 0.2148 (0.2149) gate/usage_std 0.1669 (0.1668) teacher/entropy 0.0162 (0.0524) teacher/usage_max 0.4649 (0.4760) teacher/usage_min 0.2233 (0.1967) teacher/usage_std 0.0998 (0.1206) nleep/row_max_mean 1556.4733 (1537.3623) nleep/row_max_std 51.5129 (61.6849) nleep/row_min_mean 1516.2275 (1504.2723) lr 4.6417e-04 eta 0:05:30
epoch [36/50] batch [80/181] time 0.128 (0.129) data 0.000 (0.005) loss 1.5510 (1.5456) teacher_loss 0.3039 (0.1735) loss_zs_kd 0.0641 (0.0529) loss_oracle 0.5146 (0.5906) kd_loss 0.9577 (1.0503) acc 90.6250 (94.2969) gate/entropy 0.9822 (0.9822) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1667 (0.1668) teacher/entropy 0.0480 (0.0540) teacher/usage_max 0.5450 (0.4683) teacher/usage_min 0.1564 (0.2022) teacher/usage_std 0.1605 (0.1144) nleep/row_max_mean 1539.0532 (1535.7238) nleep/row_max_std 64.3323 (62.1158) nleep/row_min_mean 1507.7579 (1502.8681) lr 4.6417e-04 eta 0:05:40
epoch [36/50] batch [100/181] time 0.154 (0.132) data 0.000 (0.004) loss 1.7327 (1.5541) teacher_loss 0.2603 (0.1685) loss_zs_kd 0.0684 (0.0522) loss_oracle 0.5904 (0.5913) kd_loss 1.1430 (1.0639) acc 90.6250 (94.2812) gate/entropy 0.9823 (0.9822) gate/usage_max 0.5691 (0.5692) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0907 (0.0547) teacher/usage_max 0.4037 (0.4603) teacher/usage_min 0.2852 (0.2103) teacher/usage_std 0.0509 (0.1072) nleep/row_max_mean 1527.5208 (1535.8185) nleep/row_max_std 58.7751 (61.5131) nleep/row_min_mean 1498.5264 (1503.0450) lr 4.6417e-04 eta 0:05:45
epoch [36/50] batch [120/181] time 0.151 (0.136) data 0.000 (0.003) loss 1.6330 (1.5489) teacher_loss 0.1622 (0.1602) loss_zs_kd 0.0437 (0.0514) loss_oracle 0.7165 (0.5915) kd_loss 1.0907 (1.0672) acc 93.7500 (94.5052) gate/entropy 0.9821 (0.9822) gate/usage_max 0.5692 (0.5691) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1668 (0.1667) teacher/entropy 0.0642 (0.0517) teacher/usage_max 0.3912 (0.4589) teacher/usage_min 0.2289 (0.2096) teacher/usage_std 0.0740 (0.1066) nleep/row_max_mean 1538.4417 (1536.6632) nleep/row_max_std 63.6689 (61.3177) nleep/row_min_mean 1505.0757 (1503.7798) lr 4.6417e-04 eta 0:05:51
epoch [36/50] batch [140/181] time 0.147 (0.138) data 0.000 (0.003) loss 1.5340 (1.5549) teacher_loss 0.1741 (0.1585) loss_zs_kd 0.0672 (0.0516) loss_oracle 0.6203 (0.5982) kd_loss 1.0162 (1.0715) acc 96.8750 (94.7098) gate/entropy 0.9822 (0.9822) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0618 (0.0528) teacher/usage_max 0.4700 (0.4605) teacher/usage_min 0.1131 (0.2092) teacher/usage_std 0.1572 (0.1074) nleep/row_max_mean 1539.1992 (1537.9608) nleep/row_max_std 61.5032 (60.7928) nleep/row_min_mean 1503.3662 (1504.8001) lr 4.6417e-04 eta 0:05:54
epoch [36/50] batch [160/181] time 0.157 (0.140) data 0.000 (0.003) loss 1.5431 (1.5606) teacher_loss 0.1341 (0.1588) loss_zs_kd 0.0632 (0.0518) loss_oracle 0.6497 (0.6024) kd_loss 1.0525 (1.0746) acc 100.0000 (94.6875) gate/entropy 0.9825 (0.9822) gate/usage_max 0.5688 (0.5691) gate/usage_min 0.2150 (0.2149) gate/usage_std 0.1665 (0.1667) teacher/entropy 0.0742 (0.0537) teacher/usage_max 0.4201 (0.4602) teacher/usage_min 0.2897 (0.2112) teacher/usage_std 0.0614 (0.1066) nleep/row_max_mean 1524.7783 (1538.2811) nleep/row_max_std 67.0363 (60.8946) nleep/row_min_mean 1495.5239 (1505.0276) lr 4.6417e-04 eta 0:05:56
epoch [36/50] batch [180/181] time 0.164 (0.140) data 0.000 (0.002) loss 1.6880 (1.5720) teacher_loss 0.1105 (0.1595) loss_zs_kd 0.0295 (0.0523) loss_oracle 0.6898 (0.6100) kd_loss 1.2178 (1.0814) acc 96.8750 (94.7049) gate/entropy 0.9822 (0.9822) gate/usage_max 0.5691 (0.5691) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.1116 (0.0555) teacher/usage_max 0.4429 (0.4576) teacher/usage_min 0.2116 (0.2136) teacher/usage_std 0.0948 (0.1046) nleep/row_max_mean 1546.9456 (1538.8297) nleep/row_max_std 61.1272 (60.8017) nleep/row_min_mean 1517.4718 (1505.4476) lr 4.6417e-04 eta 0:05:55
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,419
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.3%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,664
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.6%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [37/50] batch [20/181] time 0.119 (0.116) data 0.000 (0.016) loss 1.6313 (1.6489) teacher_loss 0.1648 (0.1433) loss_zs_kd 0.0538 (0.0580) loss_oracle 0.5900 (0.6951) kd_loss 1.1447 (1.1291) acc 93.7500 (95.3125) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.1379 (0.0896) teacher/usage_max 0.4622 (0.4571) teacher/usage_min 0.2600 (0.2300) teacher/usage_std 0.0914 (0.0970) nleep/row_max_mean 1521.2827 (1538.8302) nleep/row_max_std 76.1703 (64.7742) nleep/row_min_mean 1492.2966 (1505.1383) lr 4.1221e-04 eta 0:04:50
epoch [37/50] batch [40/181] time 0.184 (0.122) data 0.000 (0.008) loss 1.5923 (1.6891) teacher_loss 0.1288 (0.1557) loss_zs_kd 0.0439 (0.0596) loss_oracle 0.6748 (0.7009) kd_loss 1.1041 (1.1531) acc 93.7500 (94.6094) gate/entropy 0.9826 (0.9823) gate/usage_max 0.5688 (0.5690) gate/usage_min 0.2150 (0.2149) gate/usage_std 0.1665 (0.1667) teacher/entropy 0.1012 (0.0881) teacher/usage_max 0.3790 (0.4558) teacher/usage_min 0.2827 (0.2277) teacher/usage_std 0.0395 (0.0969) nleep/row_max_mean 1528.7681 (1536.0460) nleep/row_max_std 62.6238 (63.0008) nleep/row_min_mean 1494.8588 (1502.1556) lr 4.1221e-04 eta 0:05:03
epoch [37/50] batch [60/181] time 0.080 (0.121) data 0.000 (0.005) loss 1.7624 (1.6881) teacher_loss 0.1988 (0.1492) loss_zs_kd 0.0727 (0.0566) loss_oracle 0.7470 (0.6876) kd_loss 1.1537 (1.1668) acc 93.7500 (94.7396) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1667 (0.1667) teacher/entropy 0.0545 (0.0824) teacher/usage_max 0.3478 (0.4426) teacher/usage_min 0.3159 (0.2311) teacher/usage_std 0.0132 (0.0898) nleep/row_max_mean 1554.3792 (1539.0733) nleep/row_max_std 50.3717 (60.7684) nleep/row_min_mean 1514.4312 (1504.7580) lr 4.1221e-04 eta 0:04:58
epoch [37/50] batch [80/181] time 0.082 (0.120) data 0.000 (0.004) loss 1.8490 (1.7039) teacher_loss 0.2058 (0.1463) loss_zs_kd 0.0800 (0.0549) loss_oracle 0.6215 (0.6824) kd_loss 1.2925 (1.1890) acc 90.6250 (94.9219) gate/entropy 0.9823 (0.9823) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1666 (0.1666) teacher/entropy 0.0318 (0.0789) teacher/usage_max 0.4065 (0.4465) teacher/usage_min 0.2167 (0.2253) teacher/usage_std 0.0834 (0.0940) nleep/row_max_mean 1532.3007 (1538.4815) nleep/row_max_std 54.2204 (60.4260) nleep/row_min_mean 1502.7063 (1504.7574) lr 4.1221e-04 eta 0:04:55
epoch [37/50] batch [100/181] time 0.092 (0.116) data 0.000 (0.003) loss 1.7353 (1.7174) teacher_loss 0.1459 (0.1501) loss_zs_kd 0.0732 (0.0559) loss_oracle 0.6816 (0.6822) kd_loss 1.2120 (1.1982) acc 96.8750 (94.7812) gate/entropy 0.9821 (0.9823) gate/usage_max 0.5692 (0.5690) gate/usage_min 0.2148 (0.2149) gate/usage_std 0.1668 (0.1666) teacher/entropy 0.0255 (0.0722) teacher/usage_max 0.4671 (0.4462) teacher/usage_min 0.2272 (0.2280) teacher/usage_std 0.0999 (0.0929) nleep/row_max_mean 1560.7920 (1539.5109) nleep/row_max_std 48.0175 (59.5787) nleep/row_min_mean 1523.9524 (1505.5747) lr 4.1221e-04 eta 0:04:43
epoch [37/50] batch [120/181] time 0.131 (0.118) data 0.000 (0.003) loss 1.7785 (1.7275) teacher_loss 0.1057 (0.1561) loss_zs_kd 0.0572 (0.0554) loss_oracle 0.6777 (0.6727) kd_loss 1.3054 (1.2073) acc 93.7500 (94.4792) gate/entropy 0.9823 (0.9824) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1666 (0.1666) teacher/entropy 0.0448 (0.0699) teacher/usage_max 0.5806 (0.4486) teacher/usage_min 0.1893 (0.2255) teacher/usage_std 0.1757 (0.0954) nleep/row_max_mean 1547.8683 (1538.7919) nleep/row_max_std 52.5846 (59.5322) nleep/row_min_mean 1512.8236 (1505.1214) lr 4.1221e-04 eta 0:04:45
epoch [37/50] batch [140/181] time 0.134 (0.118) data 0.000 (0.002) loss 1.8631 (1.7322) teacher_loss 0.1495 (0.1542) loss_zs_kd 0.0656 (0.0549) loss_oracle 0.6669 (0.6705) kd_loss 1.3474 (1.2153) acc 93.7500 (94.5312) gate/entropy 0.9824 (0.9824) gate/usage_max 0.5690 (0.5690) gate/usage_min 0.2149 (0.2149) gate/usage_std 0.1666 (0.1666) teacher/entropy 0.0051 (0.0676) teacher/usage_max 0.4677 (0.4478) teacher/usage_min 0.1875 (0.2236) teacher/usage_std 0.1147 (0.0959) nleep/row_max_mean 1551.1151 (1539.5988) nleep/row_max_std 35.8478 (59.1100) nleep/row_min_mean 1516.9711 (1505.8908) lr 4.1221e-04 eta 0:04:42
epoch [37/50] batch [160/181] time 0.156 (0.119) data 0.000 (0.002) loss 1.7035 (1.7423) teacher_loss 0.1170 (0.1582) loss_zs_kd 0.0296 (0.0542) loss_oracle 0.6211 (0.6696) kd_loss 1.2612 (1.2222) acc 93.7500 (94.3750) gate/entropy 0.9828 (0.9824) gate/usage_max 0.5686 (0.5690) gate/usage_min 0.2151 (0.2149) gate/usage_std 0.1663 (0.1666) teacher/entropy 0.0392 (0.0655) teacher/usage_max 0.4738 (0.4480) teacher/usage_min 0.2410 (0.2223) teacher/usage_std 0.1010 (0.0965) nleep/row_max_mean 1529.5132 (1539.4148) nleep/row_max_std 62.0212 (59.1644) nleep/row_min_mean 1496.8882 (1505.6900) lr 4.1221e-04 eta 0:04:41
epoch [37/50] batch [180/181] time 0.119 (0.120) data 0.000 (0.002) loss 1.8220 (1.7544) teacher_loss 0.1095 (0.1608) loss_zs_kd 0.0315 (0.0545) loss_oracle 0.5099 (0.6710) kd_loss 1.4418 (1.2307) acc 96.8750 (94.3056) gate/entropy 0.9825 (0.9824) gate/usage_max 0.5688 (0.5689) gate/usage_min 0.2150 (0.2149) gate/usage_std 0.1665 (0.1666) teacher/entropy 0.0314 (0.0645) teacher/usage_max 0.5092 (0.4524) teacher/usage_min 0.0628 (0.2175) teacher/usage_std 0.1942 (0.1004) nleep/row_max_mean 1531.3579 (1539.2263) nleep/row_max_std 67.7624 (59.2626) nleep/row_min_mean 1504.3612 (1505.4768) lr 4.1221e-04 eta 0:04:43
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,420
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 97.4%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,667
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [38/50] batch [20/181] time 0.143 (0.152) data 0.000 (0.014) loss 1.8997 (1.7840) teacher_loss 0.2014 (0.1455) loss_zs_kd 0.0576 (0.0529) loss_oracle 0.5872 (0.6724) kd_loss 1.3759 (1.2759) acc 90.6250 (95.1562) gate/entropy 0.9828 (0.9825) gate/usage_max 0.5685 (0.5688) gate/usage_min 0.2151 (0.2150) gate/usage_std 0.1663 (0.1665) teacher/entropy 0.0652 (0.0450) teacher/usage_max 0.5257 (0.4672) teacher/usage_min 0.0951 (0.1999) teacher/usage_std 0.1787 (0.1136) nleep/row_max_mean 1525.9106 (1543.9207) nleep/row_max_std 66.1249 (60.4647) nleep/row_min_mean 1493.8748 (1509.0429) lr 3.6258e-04 eta 0:05:54
epoch [38/50] batch [40/181] time 0.147 (0.148) data 0.000 (0.007) loss 1.8026 (1.8058) teacher_loss 0.2138 (0.1681) loss_zs_kd 0.0952 (0.0550) loss_oracle 0.5305 (0.6660) kd_loss 1.2759 (1.2772) acc 93.7500 (94.1406) gate/entropy 0.9826 (0.9825) gate/usage_max 0.5687 (0.5688) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1664 (0.1665) teacher/entropy 0.0436 (0.0516) teacher/usage_max 0.4040 (0.4653) teacher/usage_min 0.2213 (0.1960) teacher/usage_std 0.0801 (0.1151) nleep/row_max_mean 1531.5435 (1541.7407) nleep/row_max_std 52.4909 (60.6967) nleep/row_min_mean 1499.3955 (1507.8340) lr 3.6258e-04 eta 0:05:41
epoch [38/50] batch [60/181] time 0.167 (0.148) data 0.000 (0.005) loss 1.6964 (1.8043) teacher_loss 0.1630 (0.1586) loss_zs_kd 0.0474 (0.0526) loss_oracle 0.6293 (0.6720) kd_loss 1.1951 (1.2834) acc 90.6250 (94.5833) gate/entropy 0.9825 (0.9826) gate/usage_max 0.5689 (0.5688) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1665 (0.1665) teacher/entropy 0.0790 (0.0527) teacher/usage_max 0.4195 (0.4747) teacher/usage_min 0.2685 (0.1935) teacher/usage_std 0.0635 (0.1196) nleep/row_max_mean 1544.2487 (1541.0401) nleep/row_max_std 58.7624 (60.1657) nleep/row_min_mean 1507.6548 (1507.1575) lr 3.6258e-04 eta 0:05:39
epoch [38/50] batch [80/181] time 0.165 (0.150) data 0.000 (0.004) loss 1.7624 (1.8070) teacher_loss 0.1261 (0.1609) loss_zs_kd 0.0531 (0.0531) loss_oracle 0.5922 (0.6746) kd_loss 1.3137 (1.2823) acc 93.7500 (94.4922) gate/entropy 0.9826 (0.9826) gate/usage_max 0.5687 (0.5687) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1664 (0.1665) teacher/entropy 0.0250 (0.0512) teacher/usage_max 0.4680 (0.4700) teacher/usage_min 0.2009 (0.1946) teacher/usage_std 0.1090 (0.1173) nleep/row_max_mean 1553.6941 (1541.7887) nleep/row_max_std 48.3126 (59.2752) nleep/row_min_mean 1516.1064 (1507.6278) lr 3.6258e-04 eta 0:05:41
epoch [38/50] batch [100/181] time 0.139 (0.150) data 0.000 (0.003) loss 1.7010 (1.7989) teacher_loss 0.0799 (0.1604) loss_zs_kd 0.0268 (0.0518) loss_oracle 0.5853 (0.6647) kd_loss 1.3151 (1.2803) acc 93.7500 (94.4062) gate/entropy 0.9829 (0.9826) gate/usage_max 0.5685 (0.5687) gate/usage_min 0.2151 (0.2150) gate/usage_std 0.1663 (0.1664) teacher/entropy 0.0381 (0.0501) teacher/usage_max 0.4919 (0.4651) teacher/usage_min 0.1869 (0.1970) teacher/usage_std 0.1248 (0.1142) nleep/row_max_mean 1531.2104 (1541.3255) nleep/row_max_std 52.2869 (59.4685) nleep/row_min_mean 1497.4561 (1507.0203) lr 3.6258e-04 eta 0:05:38
epoch [38/50] batch [120/181] time 0.099 (0.143) data 0.000 (0.003) loss 1.9075 (1.8033) teacher_loss 0.2648 (0.1623) loss_zs_kd 0.0455 (0.0521) loss_oracle 0.6568 (0.6704) kd_loss 1.2915 (1.2797) acc 93.7500 (94.2969) gate/entropy 0.9828 (0.9826) gate/usage_max 0.5685 (0.5687) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1663 (0.1664) teacher/entropy 0.0609 (0.0493) teacher/usage_max 0.5727 (0.4677) teacher/usage_min 0.1878 (0.1977) teacher/usage_std 0.1705 (0.1150) nleep/row_max_mean 1534.1099 (1541.4500) nleep/row_max_std 60.7879 (58.9971) nleep/row_min_mean 1500.8955 (1507.0207) lr 3.6258e-04 eta 0:05:19
epoch [38/50] batch [140/181] time 0.096 (0.138) data 0.000 (0.002) loss 1.8345 (1.8000) teacher_loss 0.0924 (0.1602) loss_zs_kd 0.0747 (0.0530) loss_oracle 0.8138 (0.6702) kd_loss 1.2979 (1.2781) acc 96.8750 (94.3304) gate/entropy 0.9826 (0.9826) gate/usage_max 0.5687 (0.5687) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1665 (0.1664) teacher/entropy 0.0532 (0.0507) teacher/usage_max 0.5609 (0.4676) teacher/usage_min 0.1875 (0.1975) teacher/usage_std 0.1630 (0.1151) nleep/row_max_mean 1552.1943 (1541.4752) nleep/row_max_std 70.6329 (59.1981) nleep/row_min_mean 1516.9730 (1507.1739) lr 3.6258e-04 eta 0:05:06
epoch [38/50] batch [160/181] time 0.075 (0.134) data 0.000 (0.002) loss 1.6535 (1.7966) teacher_loss 0.0418 (0.1577) loss_zs_kd 0.0343 (0.0536) loss_oracle 0.7143 (0.6690) kd_loss 1.2375 (1.2776) acc 100.0000 (94.3750) gate/entropy 0.9827 (0.9827) gate/usage_max 0.5686 (0.5687) gate/usage_min 0.2150 (0.2150) gate/usage_std 0.1664 (0.1664) teacher/entropy 0.0500 (0.0502) teacher/usage_max 0.4952 (0.4639) teacher/usage_min 0.2519 (0.1997) teacher/usage_std 0.1145 (0.1127) nleep/row_max_mean 1545.8545 (1541.5435) nleep/row_max_std 69.2050 (59.2839) nleep/row_min_mean 1510.1804 (1507.2129) lr 3.6258e-04 eta 0:04:54
epoch [38/50] batch [180/181] time 0.073 (0.130) data 0.000 (0.002) loss 1.5573 (1.7932) teacher_loss 0.0771 (0.1579) loss_zs_kd 0.0486 (0.0532) loss_oracle 0.6114 (0.6672) kd_loss 1.1503 (1.2750) acc 96.8750 (94.4097) gate/entropy 0.9828 (0.9827) gate/usage_max 0.5685 (0.5687) gate/usage_min 0.2151 (0.2150) gate/usage_std 0.1663 (0.1664) teacher/entropy 0.0628 (0.0521) teacher/usage_max 0.3806 (0.4618) teacher/usage_min 0.2893 (0.2004) teacher/usage_std 0.0374 (0.1115) nleep/row_max_mean 1549.5608 (1541.4159) nleep/row_max_std 61.6081 (59.9713) nleep/row_min_mean 1516.8774 (1507.1765) lr 3.6258e-04 eta 0:04:43
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,416
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [39/50] batch [20/181] time 0.173 (0.137) data 0.000 (0.017) loss 1.6790 (1.8134) teacher_loss 0.1304 (0.1624) loss_zs_kd 0.0753 (0.0595) loss_oracle 0.5679 (0.6772) kd_loss 1.2270 (1.2826) acc 90.6250 (93.9062) gate/entropy 0.9829 (0.9828) gate/usage_max 0.5685 (0.5685) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1663 (0.1663) teacher/entropy 0.0504 (0.0506) teacher/usage_max 0.3839 (0.4518) teacher/usage_min 0.2643 (0.2065) teacher/usage_std 0.0506 (0.1068) nleep/row_max_mean 1536.8979 (1542.0613) nleep/row_max_std 41.0103 (57.8572) nleep/row_min_mean 1503.2466 (1507.4369) lr 3.1545e-04 eta 0:04:55
epoch [39/50] batch [40/181] time 0.123 (0.124) data 0.000 (0.009) loss 1.7124 (1.8053) teacher_loss 0.1109 (0.1682) loss_zs_kd 0.0381 (0.0561) loss_oracle 0.5998 (0.6752) kd_loss 1.2825 (1.2714) acc 96.8750 (94.0625) gate/entropy 0.9829 (0.9828) gate/usage_max 0.5684 (0.5685) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1662 (0.1663) teacher/entropy 0.0695 (0.0530) teacher/usage_max 0.4790 (0.4491) teacher/usage_min 0.1876 (0.2110) teacher/usage_std 0.1190 (0.1022) nleep/row_max_mean 1533.1365 (1542.2198) nleep/row_max_std 62.2325 (58.7323) nleep/row_min_mean 1500.1975 (1507.8949) lr 3.1545e-04 eta 0:04:23
epoch [39/50] batch [60/181] time 0.171 (0.116) data 0.001 (0.006) loss 1.8003 (1.7938) teacher_loss 0.1213 (0.1595) loss_zs_kd 0.0407 (0.0531) loss_oracle 0.7780 (0.6859) kd_loss 1.2696 (1.2648) acc 96.8750 (94.2188) gate/entropy 0.9828 (0.9829) gate/usage_max 0.5686 (0.5685) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1663 (0.1663) teacher/entropy 0.0170 (0.0532) teacher/usage_max 0.5009 (0.4454) teacher/usage_min 0.2452 (0.2107) teacher/usage_std 0.1186 (0.1006) nleep/row_max_mean 1557.6310 (1544.4392) nleep/row_max_std 60.5704 (58.5520) nleep/row_min_mean 1517.8610 (1509.5589) lr 3.1545e-04 eta 0:04:05
epoch [39/50] batch [80/181] time 0.150 (0.126) data 0.000 (0.005) loss 1.6503 (1.7917) teacher_loss 0.0220 (0.1576) loss_zs_kd 0.0270 (0.0513) loss_oracle 0.5944 (0.6825) kd_loss 1.3176 (1.2672) acc 100.0000 (94.3359) gate/entropy 0.9831 (0.9829) gate/usage_max 0.5682 (0.5684) gate/usage_min 0.2152 (0.2151) gate/usage_std 0.1661 (0.1662) teacher/entropy 0.0577 (0.0545) teacher/usage_max 0.6068 (0.4479) teacher/usage_min 0.1638 (0.2069) teacher/usage_std 0.1952 (0.1036) nleep/row_max_mean 1531.5602 (1544.7837) nleep/row_max_std 64.0307 (58.5539) nleep/row_min_mean 1500.5928 (1509.9955) lr 3.1545e-04 eta 0:04:22
epoch [39/50] batch [100/181] time 0.141 (0.131) data 0.000 (0.004) loss 1.7724 (1.7995) teacher_loss 0.0929 (0.1609) loss_zs_kd 0.0604 (0.0530) loss_oracle 0.6924 (0.6864) kd_loss 1.3031 (1.2689) acc 96.8750 (94.2188) gate/entropy 0.9829 (0.9829) gate/usage_max 0.5685 (0.5684) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1663 (0.1662) teacher/entropy 0.0414 (0.0533) teacher/usage_max 0.4444 (0.4534) teacher/usage_min 0.1947 (0.2030) teacher/usage_std 0.1038 (0.1073) nleep/row_max_mean 1550.9548 (1544.9668) nleep/row_max_std 51.7311 (57.7519) nleep/row_min_mean 1516.0122 (1510.1768) lr 3.1545e-04 eta 0:04:31
epoch [39/50] batch [120/181] time 0.138 (0.133) data 0.000 (0.003) loss 1.7396 (1.8007) teacher_loss 0.1401 (0.1633) loss_zs_kd 0.0440 (0.0542) loss_oracle 0.7362 (0.6821) kd_loss 1.2094 (1.2693) acc 93.7500 (94.1406) gate/entropy 0.9828 (0.9829) gate/usage_max 0.5685 (0.5684) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1663 (0.1662) teacher/entropy 0.0209 (0.0526) teacher/usage_max 0.3984 (0.4509) teacher/usage_min 0.2891 (0.2043) teacher/usage_std 0.0470 (0.1057) nleep/row_max_mean 1561.2283 (1544.6019) nleep/row_max_std 50.9801 (57.2463) nleep/row_min_mean 1519.8057 (1509.8378) lr 3.1545e-04 eta 0:04:33
epoch [39/50] batch [140/181] time 0.161 (0.135) data 0.000 (0.003) loss 2.0792 (1.7988) teacher_loss 0.2781 (0.1647) loss_zs_kd 0.0644 (0.0540) loss_oracle 0.8398 (0.6821) kd_loss 1.3491 (1.2660) acc 93.7500 (94.1518) gate/entropy 0.9828 (0.9829) gate/usage_max 0.5685 (0.5684) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1663 (0.1662) teacher/entropy 0.0622 (0.0535) teacher/usage_max 0.5928 (0.4508) teacher/usage_min 0.1250 (0.2068) teacher/usage_std 0.1943 (0.1045) nleep/row_max_mean 1549.5374 (1544.9204) nleep/row_max_std 66.0728 (57.0791) nleep/row_min_mean 1513.4880 (1510.0265) lr 3.1545e-04 eta 0:04:34
epoch [39/50] batch [160/181] time 0.124 (0.136) data 0.000 (0.002) loss 1.9428 (1.7991) teacher_loss 0.0479 (0.1637) loss_zs_kd 0.0298 (0.0541) loss_oracle 0.9064 (0.6829) kd_loss 1.4268 (1.2669) acc 100.0000 (94.1797) gate/entropy 0.9833 (0.9829) gate/usage_max 0.5680 (0.5684) gate/usage_min 0.2152 (0.2151) gate/usage_std 0.1659 (0.1662) teacher/entropy 0.0375 (0.0552) teacher/usage_max 0.5569 (0.4512) teacher/usage_min 0.0698 (0.2054) teacher/usage_std 0.2008 (0.1052) nleep/row_max_mean 1548.4292 (1545.4409) nleep/row_max_std 68.4070 (57.2159) nleep/row_min_mean 1509.5630 (1510.4172) lr 3.1545e-04 eta 0:04:33
epoch [39/50] batch [180/181] time 0.148 (0.136) data 0.000 (0.002) loss 1.7971 (1.7985) teacher_loss 0.1527 (0.1671) loss_zs_kd 0.0371 (0.0539) loss_oracle 0.7395 (0.6795) kd_loss 1.2561 (1.2647) acc 93.7500 (93.9931) gate/entropy 0.9831 (0.9829) gate/usage_max 0.5682 (0.5684) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1661 (0.1662) teacher/entropy 0.0343 (0.0556) teacher/usage_max 0.4437 (0.4505) teacher/usage_min 0.2497 (0.2065) teacher/usage_std 0.0814 (0.1046) nleep/row_max_mean 1551.9514 (1545.3324) nleep/row_max_std 54.0104 (57.6538) nleep/row_min_mean 1511.1060 (1510.3118) lr 3.1545e-04 eta 0:04:31
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,411
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.0%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [40/50] batch [20/181] time 0.147 (0.158) data 0.001 (0.018) loss 1.7217 (1.8414) teacher_loss 0.2164 (0.2007) loss_zs_kd 0.0446 (0.0483) loss_oracle 0.5682 (0.6836) kd_loss 1.1989 (1.2747) acc 90.6250 (92.9688) gate/entropy 0.9830 (0.9831) gate/usage_max 0.5683 (0.5683) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1662 (0.1661) teacher/entropy 0.0745 (0.0513) teacher/usage_max 0.4556 (0.4624) teacher/usage_min 0.2688 (0.2064) teacher/usage_std 0.0865 (0.1095) nleep/row_max_mean 1541.5034 (1547.9058) nleep/row_max_std 52.7034 (60.6271) nleep/row_min_mean 1511.0081 (1512.4194) lr 2.7103e-04 eta 0:05:11
epoch [40/50] batch [40/181] time 0.074 (0.142) data 0.000 (0.009) loss 1.7684 (1.8121) teacher_loss 0.0815 (0.1897) loss_zs_kd 0.0402 (0.0497) loss_oracle 0.6905 (0.6673) kd_loss 1.3216 (1.2639) acc 100.0000 (93.5938) gate/entropy 0.9829 (0.9831) gate/usage_max 0.5684 (0.5682) gate/usage_min 0.2150 (0.2151) gate/usage_std 0.1662 (0.1661) teacher/entropy 0.0575 (0.0597) teacher/usage_max 0.4682 (0.4617) teacher/usage_min 0.1592 (0.2036) teacher/usage_std 0.1292 (0.1098) nleep/row_max_mean 1550.1416 (1546.2577) nleep/row_max_std 57.8732 (60.8971) nleep/row_min_mean 1517.2997 (1511.1018) lr 2.7103e-04 eta 0:04:36
epoch [40/50] batch [60/181] time 0.081 (0.134) data 0.001 (0.006) loss 1.8643 (1.8067) teacher_loss 0.0788 (0.1865) loss_zs_kd 0.0267 (0.0507) loss_oracle 0.7772 (0.6749) kd_loss 1.3835 (1.2574) acc 100.0000 (93.4896) gate/entropy 0.9832 (0.9831) gate/usage_max 0.5681 (0.5682) gate/usage_min 0.2152 (0.2151) gate/usage_std 0.1660 (0.1661) teacher/entropy 0.0837 (0.0625) teacher/usage_max 0.4939 (0.4555) teacher/usage_min 0.0674 (0.2062) teacher/usage_std 0.1894 (0.1062) nleep/row_max_mean 1534.1318 (1544.1976) nleep/row_max_std 63.9624 (59.9386) nleep/row_min_mean 1501.5420 (1509.4522) lr 2.7103e-04 eta 0:04:19
epoch [40/50] batch [80/181] time 0.099 (0.127) data 0.000 (0.005) loss 1.7163 (1.7937) teacher_loss 0.1131 (0.1793) loss_zs_kd 0.0486 (0.0513) loss_oracle 0.7174 (0.6758) kd_loss 1.2202 (1.2508) acc 96.8750 (93.6719) gate/entropy 0.9830 (0.9831) gate/usage_max 0.5683 (0.5682) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1661 (0.1661) teacher/entropy 0.0685 (0.0623) teacher/usage_max 0.4959 (0.4543) teacher/usage_min 0.2512 (0.2087) teacher/usage_std 0.1149 (0.1047) nleep/row_max_mean 1541.6475 (1542.2294) nleep/row_max_std 58.2727 (59.4552) nleep/row_min_mean 1508.1178 (1507.6555) lr 2.7103e-04 eta 0:04:02
epoch [40/50] batch [100/181] time 0.182 (0.127) data 0.000 (0.004) loss 1.8379 (1.7986) teacher_loss 0.0647 (0.1746) loss_zs_kd 0.0403 (0.0508) loss_oracle 0.7958 (0.6806) kd_loss 1.3552 (1.2583) acc 100.0000 (93.8750) gate/entropy 0.9835 (0.9831) gate/usage_max 0.5678 (0.5682) gate/usage_min 0.2153 (0.2151) gate/usage_std 0.1658 (0.1661) teacher/entropy 0.0344 (0.0599) teacher/usage_max 0.4399 (0.4545) teacher/usage_min 0.1470 (0.2055) teacher/usage_std 0.1322 (0.1061) nleep/row_max_mean 1525.0792 (1541.1131) nleep/row_max_std 69.1947 (59.4574) nleep/row_min_mean 1491.3677 (1506.5006) lr 2.7103e-04 eta 0:03:59
epoch [40/50] batch [120/181] time 0.078 (0.121) data 0.000 (0.003) loss 1.9692 (1.7974) teacher_loss 0.2437 (0.1743) loss_zs_kd 0.0444 (0.0516) loss_oracle 0.7720 (0.6755) kd_loss 1.3173 (1.2595) acc 90.6250 (93.8281) gate/entropy 0.9833 (0.9832) gate/usage_max 0.5680 (0.5682) gate/usage_min 0.2152 (0.2151) gate/usage_std 0.1659 (0.1660) teacher/entropy 0.0574 (0.0604) teacher/usage_max 0.5081 (0.4545) teacher/usage_min 0.1625 (0.2048) teacher/usage_std 0.1411 (0.1062) nleep/row_max_mean 1534.3842 (1539.8812) nleep/row_max_std 54.8265 (59.2775) nleep/row_min_mean 1501.2667 (1505.4159) lr 2.7103e-04 eta 0:03:46
epoch [40/50] batch [140/181] time 0.067 (0.120) data 0.000 (0.003) loss 1.5721 (1.7856) teacher_loss 0.1091 (0.1687) loss_zs_kd 0.0531 (0.0514) loss_oracle 0.5815 (0.6721) kd_loss 1.1457 (1.2551) acc 96.8750 (94.0848) gate/entropy 0.9832 (0.9832) gate/usage_max 0.5681 (0.5682) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1660 (0.1660) teacher/entropy 0.0568 (0.0620) teacher/usage_max 0.3411 (0.4528) teacher/usage_min 0.3266 (0.2067) teacher/usage_std 0.0060 (0.1048) nleep/row_max_mean 1555.4578 (1539.8238) nleep/row_max_std 64.7949 (59.4613) nleep/row_min_mean 1517.6970 (1505.3566) lr 2.7103e-04 eta 0:03:42
epoch [40/50] batch [160/181] time 0.076 (0.117) data 0.000 (0.002) loss 1.7766 (1.7819) teacher_loss 0.0913 (0.1655) loss_zs_kd 0.0476 (0.0518) loss_oracle 0.6761 (0.6729) kd_loss 1.3234 (1.2541) acc 93.7500 (94.1797) gate/entropy 0.9833 (0.9832) gate/usage_max 0.5680 (0.5681) gate/usage_min 0.2152 (0.2151) gate/usage_std 0.1659 (0.1660) teacher/entropy 0.0563 (0.0621) teacher/usage_max 0.5114 (0.4509) teacher/usage_min 0.1573 (0.2080) teacher/usage_std 0.1445 (0.1035) nleep/row_max_mean 1548.5719 (1539.8431) nleep/row_max_std 50.9191 (59.4119) nleep/row_min_mean 1516.0598 (1505.3165) lr 2.7103e-04 eta 0:03:34
epoch [40/50] batch [180/181] time 0.068 (0.116) data 0.000 (0.002) loss 1.4666 (1.7739) teacher_loss 0.1338 (0.1635) loss_zs_kd 0.0358 (0.0518) loss_oracle 0.5426 (0.6673) kd_loss 1.0437 (1.2508) acc 96.8750 (94.2361) gate/entropy 0.9832 (0.9832) gate/usage_max 0.5681 (0.5681) gate/usage_min 0.2151 (0.2151) gate/usage_std 0.1660 (0.1660) teacher/entropy 0.0806 (0.0631) teacher/usage_max 0.4217 (0.4510) teacher/usage_min 0.2791 (0.2098) teacher/usage_std 0.0630 (0.1028) nleep/row_max_mean 1535.9287 (1539.4122) nleep/row_max_std 62.6466 (59.5903) nleep/row_min_mean 1503.8020 (1505.0907) lr 2.7103e-04 eta 0:03:30
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,413
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [41/50] batch [20/181] time 0.174 (0.189) data 0.000 (0.013) loss 1.9413 (1.7707) teacher_loss 0.3295 (0.1690) loss_zs_kd 0.0698 (0.0529) loss_oracle 0.6720 (0.6694) kd_loss 1.2409 (1.2406) acc 90.6250 (93.9062) gate/entropy 0.9835 (0.9833) gate/usage_max 0.5678 (0.5680) gate/usage_min 0.2153 (0.2152) gate/usage_std 0.1658 (0.1659) teacher/entropy 0.0433 (0.0711) teacher/usage_max 0.4074 (0.4529) teacher/usage_min 0.2564 (0.2177) teacher/usage_std 0.0617 (0.1008) nleep/row_max_mean 1531.5078 (1532.1290) nleep/row_max_std 57.3341 (59.0331) nleep/row_min_mean 1498.1118 (1499.7463) lr 2.2949e-04 eta 0:05:37
epoch [41/50] batch [40/181] time 0.164 (0.182) data 0.000 (0.007) loss 1.9274 (1.7724) teacher_loss 0.2364 (0.1719) loss_zs_kd 0.0676 (0.0551) loss_oracle 0.6356 (0.6633) kd_loss 1.3395 (1.2412) acc 90.6250 (94.4531) gate/entropy 0.9832 (0.9833) gate/usage_max 0.5681 (0.5680) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1660 (0.1659) teacher/entropy 0.0512 (0.0710) teacher/usage_max 0.5506 (0.4551) teacher/usage_min 0.1458 (0.2181) teacher/usage_std 0.1666 (0.1015) nleep/row_max_mean 1538.5107 (1531.6311) nleep/row_max_std 61.9426 (59.9072) nleep/row_min_mean 1508.0966 (1499.3310) lr 2.2949e-04 eta 0:05:22
epoch [41/50] batch [60/181] time 0.116 (0.171) data 0.001 (0.005) loss 1.5155 (1.7508) teacher_loss 0.0545 (0.1642) loss_zs_kd 0.0140 (0.0521) loss_oracle 0.6319 (0.6522) kd_loss 1.1380 (1.2345) acc 96.8750 (94.3229) gate/entropy 0.9837 (0.9833) gate/usage_max 0.5675 (0.5680) gate/usage_min 0.2154 (0.2152) gate/usage_std 0.1656 (0.1659) teacher/entropy 0.1343 (0.0708) teacher/usage_max 0.3931 (0.4561) teacher/usage_min 0.2685 (0.2186) teacher/usage_std 0.0510 (0.1018) nleep/row_max_mean 1505.2767 (1531.9426) nleep/row_max_std 69.9799 (60.0151) nleep/row_min_mean 1475.4180 (1499.5983) lr 2.2949e-04 eta 0:04:59
epoch [41/50] batch [80/181] time 0.163 (0.167) data 0.000 (0.003) loss 1.7931 (1.7494) teacher_loss 0.1886 (0.1553) loss_zs_kd 0.0796 (0.0524) loss_oracle 0.6481 (0.6573) kd_loss 1.2407 (1.2394) acc 93.7500 (94.7266) gate/entropy 0.9833 (0.9833) gate/usage_max 0.5680 (0.5680) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1659 (0.1659) teacher/entropy 0.0609 (0.0651) teacher/usage_max 0.4470 (0.4530) teacher/usage_min 0.2381 (0.2199) teacher/usage_std 0.0863 (0.1000) nleep/row_max_mean 1538.0627 (1533.1270) nleep/row_max_std 55.5511 (59.6323) nleep/row_min_mean 1508.4932 (1500.6663) lr 2.2949e-04 eta 0:04:49
epoch [41/50] batch [100/181] time 0.154 (0.165) data 0.000 (0.003) loss 1.7795 (1.7542) teacher_loss 0.1884 (0.1585) loss_zs_kd 0.0447 (0.0522) loss_oracle 0.5534 (0.6566) kd_loss 1.2921 (1.2412) acc 93.7500 (94.5312) gate/entropy 0.9836 (0.9834) gate/usage_max 0.5677 (0.5680) gate/usage_min 0.2153 (0.2152) gate/usage_std 0.1657 (0.1659) teacher/entropy 0.0740 (0.0633) teacher/usage_max 0.4985 (0.4522) teacher/usage_min 0.1724 (0.2181) teacher/usage_std 0.1332 (0.1006) nleep/row_max_mean 1519.7241 (1532.4332) nleep/row_max_std 67.8023 (60.0963) nleep/row_min_mean 1490.0967 (1500.1137) lr 2.2949e-04 eta 0:04:42
epoch [41/50] batch [120/181] time 0.166 (0.163) data 0.000 (0.002) loss 1.7272 (1.7598) teacher_loss 0.0850 (0.1596) loss_zs_kd 0.0227 (0.0512) loss_oracle 0.7113 (0.6600) kd_loss 1.2751 (1.2446) acc 100.0000 (94.4792) gate/entropy 0.9837 (0.9834) gate/usage_max 0.5676 (0.5679) gate/usage_min 0.2153 (0.2152) gate/usage_std 0.1657 (0.1659) teacher/entropy 0.0719 (0.0625) teacher/usage_max 0.4556 (0.4499) teacher/usage_min 0.1906 (0.2165) teacher/usage_std 0.1091 (0.1005) nleep/row_max_mean 1517.9226 (1532.0492) nleep/row_max_std 72.7741 (60.6884) nleep/row_min_mean 1487.5363 (1499.7586) lr 2.2949e-04 eta 0:04:35
epoch [41/50] batch [140/181] time 0.094 (0.156) data 0.000 (0.002) loss 1.9025 (1.7553) teacher_loss 0.1290 (0.1588) loss_zs_kd 0.0594 (0.0514) loss_oracle 0.6558 (0.6577) kd_loss 1.4159 (1.2419) acc 93.7500 (94.5089) gate/entropy 0.9833 (0.9834) gate/usage_max 0.5680 (0.5679) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1659 (0.1659) teacher/entropy 0.0224 (0.0632) teacher/usage_max 0.5024 (0.4499) teacher/usage_min 0.0969 (0.2173) teacher/usage_std 0.1722 (0.1000) nleep/row_max_mean 1538.5549 (1532.2944) nleep/row_max_std 62.2637 (60.9485) nleep/row_min_mean 1506.9927 (1500.1405) lr 2.2949e-04 eta 0:04:21
epoch [41/50] batch [160/181] time 0.090 (0.152) data 0.000 (0.002) loss 1.4107 (1.7548) teacher_loss 0.0380 (0.1632) loss_zs_kd 0.0291 (0.0511) loss_oracle 0.5547 (0.6562) kd_loss 1.0807 (1.2379) acc 100.0000 (94.2969) gate/entropy 0.9836 (0.9834) gate/usage_max 0.5676 (0.5679) gate/usage_min 0.2153 (0.2152) gate/usage_std 0.1657 (0.1659) teacher/entropy 0.1137 (0.0637) teacher/usage_max 0.4549 (0.4495) teacher/usage_min 0.1954 (0.2180) teacher/usage_std 0.1066 (0.0992) nleep/row_max_mean 1514.3835 (1532.3282) nleep/row_max_std 63.8030 (61.5383) nleep/row_min_mean 1484.5507 (1500.0903) lr 2.2949e-04 eta 0:04:10
epoch [41/50] batch [180/181] time 0.069 (0.148) data 0.000 (0.002) loss 1.4741 (1.7522) teacher_loss 0.0505 (0.1629) loss_zs_kd 0.0372 (0.0511) loss_oracle 0.6026 (0.6531) kd_loss 1.1037 (1.2372) acc 100.0000 (94.3229) gate/entropy 0.9835 (0.9834) gate/usage_max 0.5678 (0.5679) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1658 (0.1659) teacher/entropy 0.0988 (0.0648) teacher/usage_max 0.3584 (0.4505) teacher/usage_min 0.3009 (0.2173) teacher/usage_std 0.0241 (0.0998) nleep/row_max_mean 1532.1958 (1532.1476) nleep/row_max_std 72.3648 (61.5844) nleep/row_min_mean 1502.1331 (1500.1059) lr 2.2949e-04 eta 0:04:00
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,413
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [42/50] batch [20/181] time 0.079 (0.142) data 0.000 (0.019) loss 1.9024 (1.7376) teacher_loss 0.2611 (0.1606) loss_zs_kd 0.0628 (0.0510) loss_oracle 0.7339 (0.6602) kd_loss 1.2429 (1.2214) acc 90.6250 (94.3750) gate/entropy 0.9834 (0.9835) gate/usage_max 0.5679 (0.5678) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1659 (0.1658) teacher/entropy 0.0525 (0.0675) teacher/usage_max 0.4999 (0.4494) teacher/usage_min 0.2435 (0.2364) teacher/usage_std 0.1179 (0.0935) nleep/row_max_mean 1538.3000 (1529.9735) nleep/row_max_std 62.7718 (66.4238) nleep/row_min_mean 1505.6459 (1498.4652) lr 1.9098e-04 eta 0:03:48
epoch [42/50] batch [40/181] time 0.071 (0.131) data 0.000 (0.010) loss 1.6566 (1.7329) teacher_loss 0.2588 (0.1629) loss_zs_kd 0.0597 (0.0520) loss_oracle 0.4703 (0.6484) kd_loss 1.1328 (1.2198) acc 87.5000 (94.2188) gate/entropy 0.9834 (0.9835) gate/usage_max 0.5679 (0.5678) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1659 (0.1658) teacher/entropy 0.0562 (0.0753) teacher/usage_max 0.3548 (0.4509) teacher/usage_min 0.3142 (0.2245) teacher/usage_std 0.0167 (0.0991) nleep/row_max_mean 1526.5818 (1527.1507) nleep/row_max_std 62.3832 (63.9757) nleep/row_min_mean 1493.1543 (1496.5242) lr 1.9098e-04 eta 0:03:28
epoch [42/50] batch [60/181] time 0.122 (0.119) data 0.001 (0.006) loss 1.8554 (1.7423) teacher_loss 0.2234 (0.1674) loss_zs_kd 0.0652 (0.0518) loss_oracle 0.7000 (0.6530) kd_loss 1.2495 (1.2224) acc 90.6250 (94.1667) gate/entropy 0.9833 (0.9835) gate/usage_max 0.5680 (0.5678) gate/usage_min 0.2151 (0.2152) gate/usage_std 0.1659 (0.1658) teacher/entropy 0.0881 (0.0713) teacher/usage_max 0.5649 (0.4570) teacher/usage_min 0.2001 (0.2228) teacher/usage_std 0.1643 (0.1014) nleep/row_max_mean 1535.5607 (1527.8542) nleep/row_max_std 53.6527 (62.9042) nleep/row_min_mean 1504.6521 (1497.1175) lr 1.9098e-04 eta 0:03:06
epoch [42/50] batch [80/181] time 0.159 (0.127) data 0.000 (0.005) loss 1.7921 (1.7358) teacher_loss 0.1604 (0.1654) loss_zs_kd 0.0481 (0.0531) loss_oracle 0.7822 (0.6514) kd_loss 1.2165 (1.2181) acc 96.8750 (94.0234) gate/entropy 0.9836 (0.9835) gate/usage_max 0.5677 (0.5678) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1658 (0.1658) teacher/entropy 0.0447 (0.0674) teacher/usage_max 0.4831 (0.4539) teacher/usage_min 0.2377 (0.2254) teacher/usage_std 0.1072 (0.0982) nleep/row_max_mean 1540.7328 (1527.8838) nleep/row_max_std 49.2162 (62.1347) nleep/row_min_mean 1505.5649 (1496.9346) lr 1.9098e-04 eta 0:03:17
epoch [42/50] batch [100/181] time 0.126 (0.131) data 0.000 (0.004) loss 1.6720 (1.7297) teacher_loss 0.1876 (0.1605) loss_zs_kd 0.0549 (0.0529) loss_oracle 0.6275 (0.6502) kd_loss 1.1432 (1.2176) acc 90.6250 (94.0312) gate/entropy 0.9836 (0.9835) gate/usage_max 0.5677 (0.5678) gate/usage_min 0.2152 (0.2152) gate/usage_std 0.1658 (0.1658) teacher/entropy 0.1074 (0.0661) teacher/usage_max 0.4104 (0.4529) teacher/usage_min 0.2903 (0.2275) teacher/usage_std 0.0546 (0.0968) nleep/row_max_mean 1533.5503 (1529.0420) nleep/row_max_std 62.7487 (61.2955) nleep/row_min_mean 1503.9312 (1498.0747) lr 1.9098e-04 eta 0:03:20
epoch [42/50] batch [120/181] time 0.155 (0.135) data 0.000 (0.003) loss 1.5772 (1.7330) teacher_loss 0.0815 (0.1574) loss_zs_kd 0.0537 (0.0526) loss_oracle 0.5936 (0.6512) kd_loss 1.1721 (1.2237) acc 100.0000 (94.2708) gate/entropy 0.9839 (0.9835) gate/usage_max 0.5674 (0.5677) gate/usage_min 0.2154 (0.2152) gate/usage_std 0.1655 (0.1658) teacher/entropy 0.0610 (0.0648) teacher/usage_max 0.3475 (0.4532) teacher/usage_min 0.3088 (0.2260) teacher/usage_std 0.0174 (0.0975) nleep/row_max_mean 1523.1750 (1529.6294) nleep/row_max_std 70.2493 (60.5916) nleep/row_min_mean 1494.4198 (1498.8353) lr 1.9098e-04 eta 0:03:22
epoch [42/50] batch [140/181] time 0.133 (0.137) data 0.000 (0.003) loss 1.9647 (1.7338) teacher_loss 0.1396 (0.1596) loss_zs_kd 0.0542 (0.0525) loss_oracle 0.6988 (0.6527) kd_loss 1.4486 (1.2216) acc 93.7500 (94.2188) gate/entropy 0.9837 (0.9836) gate/usage_max 0.5676 (0.5677) gate/usage_min 0.2153 (0.2152) gate/usage_std 0.1657 (0.1658) teacher/entropy 0.0476 (0.0647) teacher/usage_max 0.5808 (0.4530) teacher/usage_min 0.0360 (0.2261) teacher/usage_std 0.2252 (0.0973) nleep/row_max_mean 1539.3904 (1531.4098) nleep/row_max_std 36.7779 (60.0748) nleep/row_min_mean 1511.7871 (1500.3644) lr 1.9098e-04 eta 0:03:23
epoch [42/50] batch [160/181] time 0.152 (0.138) data 0.000 (0.003) loss 1.6379 (1.7405) teacher_loss 0.1328 (0.1660) loss_zs_kd 0.0553 (0.0521) loss_oracle 0.6199 (0.6549) kd_loss 1.1675 (1.2211) acc 93.7500 (93.8281) gate/entropy 0.9837 (0.9836) gate/usage_max 0.5676 (0.5677) gate/usage_min 0.2153 (0.2152) gate/usage_std 0.1657 (0.1657) teacher/entropy 0.0917 (0.0647) teacher/usage_max 0.3987 (0.4530) teacher/usage_min 0.2824 (0.2276) teacher/usage_std 0.0486 (0.0968) nleep/row_max_mean 1516.3267 (1531.9166) nleep/row_max_std 71.2290 (60.0681) nleep/row_min_mean 1487.3638 (1500.8772) lr 1.9098e-04 eta 0:03:22
epoch [42/50] batch [180/181] time 0.135 (0.139) data 0.000 (0.002) loss 1.8226 (1.7416) teacher_loss 0.0974 (0.1660) loss_zs_kd 0.0460 (0.0523) loss_oracle 0.7589 (0.6573) kd_loss 1.3227 (1.2208) acc 96.8750 (93.8715) gate/entropy 0.9838 (0.9836) gate/usage_max 0.5675 (0.5677) gate/usage_min 0.2153 (0.2152) gate/usage_std 0.1656 (0.1657) teacher/entropy 0.0265 (0.0640) teacher/usage_max 0.5186 (0.4530) teacher/usage_min 0.1877 (0.2269) teacher/usage_std 0.1380 (0.0970) nleep/row_max_mean 1526.2307 (1531.9884) nleep/row_max_std 57.6325 (60.3095) nleep/row_min_mean 1493.8296 (1500.9238) lr 1.9098e-04 eta 0:03:20
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,414
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [43/50] batch [20/181] time 0.086 (0.133) data 0.000 (0.015) loss 1.7713 (1.7973) teacher_loss 0.2084 (0.1811) loss_zs_kd 0.0356 (0.0512) loss_oracle 0.5745 (0.6961) kd_loss 1.2578 (1.2425) acc 93.7500 (93.1250) gate/entropy 0.9835 (0.9836) gate/usage_max 0.5678 (0.5677) gate/usage_min 0.2152 (0.2153) gate/usage_std 0.1658 (0.1657) teacher/entropy 0.0850 (0.0701) teacher/usage_max 0.5584 (0.4940) teacher/usage_min 0.1943 (0.2086) teacher/usage_std 0.1606 (0.1236) nleep/row_max_mean 1531.2974 (1531.3658) nleep/row_max_std 60.2597 (59.5017) nleep/row_min_mean 1504.6033 (1501.0326) lr 1.5567e-04 eta 0:03:09
epoch [43/50] batch [40/181] time 0.140 (0.120) data 0.000 (0.008) loss 1.8918 (1.7655) teacher_loss 0.1971 (0.1835) loss_zs_kd 0.0361 (0.0524) loss_oracle 0.8460 (0.6753) kd_loss 1.2536 (1.2182) acc 90.6250 (93.2812) gate/entropy 0.9838 (0.9837) gate/usage_max 0.5675 (0.5676) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1656 (0.1657) teacher/entropy 0.0472 (0.0680) teacher/usage_max 0.4460 (0.4669) teacher/usage_min 0.2384 (0.2244) teacher/usage_std 0.0857 (0.1051) nleep/row_max_mean 1530.1216 (1528.2360) nleep/row_max_std 61.5079 (59.3714) nleep/row_min_mean 1494.9141 (1497.8454) lr 1.5567e-04 eta 0:02:49
epoch [43/50] batch [60/181] time 0.127 (0.121) data 0.001 (0.005) loss 1.7828 (1.7592) teacher_loss 0.2279 (0.1828) loss_zs_kd 0.0476 (0.0536) loss_oracle 0.6369 (0.6630) kd_loss 1.2126 (1.2181) acc 87.5000 (93.2812) gate/entropy 0.9838 (0.9837) gate/usage_max 0.5674 (0.5676) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1655 (0.1657) teacher/entropy 0.0742 (0.0705) teacher/usage_max 0.4120 (0.4607) teacher/usage_min 0.2537 (0.2235) teacher/usage_std 0.0647 (0.1021) nleep/row_max_mean 1520.2014 (1526.0431) nleep/row_max_std 63.0056 (60.0801) nleep/row_min_mean 1487.8484 (1495.9537) lr 1.5567e-04 eta 0:02:47
epoch [43/50] batch [80/181] time 0.097 (0.121) data 0.001 (0.004) loss 1.7377 (1.7369) teacher_loss 0.2150 (0.1732) loss_zs_kd 0.0527 (0.0527) loss_oracle 0.6281 (0.6541) kd_loss 1.1823 (1.2104) acc 90.6250 (93.7500) gate/entropy 0.9837 (0.9837) gate/usage_max 0.5676 (0.5676) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1656 (0.1656) teacher/entropy 0.0474 (0.0689) teacher/usage_max 0.3712 (0.4531) teacher/usage_min 0.3126 (0.2300) teacher/usage_std 0.0268 (0.0961) nleep/row_max_mean 1524.2589 (1526.8888) nleep/row_max_std 54.5578 (59.0561) nleep/row_min_mean 1494.9270 (1496.5502) lr 1.5567e-04 eta 0:02:44
epoch [43/50] batch [100/181] time 0.173 (0.120) data 0.001 (0.003) loss 1.7769 (1.7385) teacher_loss 0.2125 (0.1757) loss_zs_kd 0.0646 (0.0524) loss_oracle 0.7200 (0.6554) kd_loss 1.1720 (1.2089) acc 93.7500 (93.7188) gate/entropy 0.9835 (0.9837) gate/usage_max 0.5678 (0.5676) gate/usage_min 0.2152 (0.2153) gate/usage_std 0.1658 (0.1656) teacher/entropy 0.0627 (0.0677) teacher/usage_max 0.4452 (0.4481) teacher/usage_min 0.2481 (0.2334) teacher/usage_std 0.0826 (0.0925) nleep/row_max_mean 1542.6934 (1527.5079) nleep/row_max_std 43.7368 (58.0868) nleep/row_min_mean 1511.1021 (1497.1918) lr 1.5567e-04 eta 0:02:41
epoch [43/50] batch [120/181] time 0.103 (0.117) data 0.000 (0.003) loss 1.9453 (1.7428) teacher_loss 0.1763 (0.1758) loss_zs_kd 0.0349 (0.0530) loss_oracle 0.6627 (0.6577) kd_loss 1.4202 (1.2117) acc 90.6250 (93.6198) gate/entropy 0.9842 (0.9837) gate/usage_max 0.5670 (0.5676) gate/usage_min 0.2155 (0.2153) gate/usage_std 0.1652 (0.1656) teacher/entropy 0.0387 (0.0652) teacher/usage_max 0.4643 (0.4480) teacher/usage_min 0.0740 (0.2335) teacher/usage_std 0.1834 (0.0924) nleep/row_max_mean 1508.6001 (1528.1614) nleep/row_max_std 66.0785 (58.1159) nleep/row_min_mean 1483.7319 (1497.7144) lr 1.5567e-04 eta 0:02:35
epoch [43/50] batch [140/181] time 0.093 (0.118) data 0.000 (0.002) loss 1.5346 (1.7498) teacher_loss 0.0893 (0.1783) loss_zs_kd 0.0549 (0.0530) loss_oracle 0.6134 (0.6633) kd_loss 1.1111 (1.2134) acc 96.8750 (93.6384) gate/entropy 0.9837 (0.9837) gate/usage_max 0.5676 (0.5676) gate/usage_min 0.2152 (0.2153) gate/usage_std 0.1656 (0.1656) teacher/entropy 0.0296 (0.0635) teacher/usage_max 0.4037 (0.4487) teacher/usage_min 0.2478 (0.2316) teacher/usage_std 0.0645 (0.0933) nleep/row_max_mean 1532.5682 (1528.0994) nleep/row_max_std 65.8843 (58.2649) nleep/row_min_mean 1500.1665 (1497.6270) lr 1.5567e-04 eta 0:02:34
epoch [43/50] batch [160/181] time 0.097 (0.117) data 0.000 (0.002) loss 1.7344 (1.7537) teacher_loss 0.0577 (0.1751) loss_zs_kd 0.0412 (0.0528) loss_oracle 0.7969 (0.6681) kd_loss 1.2576 (1.2181) acc 100.0000 (93.7305) gate/entropy 0.9837 (0.9837) gate/usage_max 0.5676 (0.5676) gate/usage_min 0.2152 (0.2153) gate/usage_std 0.1657 (0.1656) teacher/entropy 0.0216 (0.0619) teacher/usage_max 0.4264 (0.4486) teacher/usage_min 0.2611 (0.2311) teacher/usage_std 0.0691 (0.0932) nleep/row_max_mean 1550.2163 (1528.2972) nleep/row_max_std 47.2253 (58.4675) nleep/row_min_mean 1514.1587 (1497.8124) lr 1.5567e-04 eta 0:02:30
epoch [43/50] batch [180/181] time 0.074 (0.116) data 0.000 (0.002) loss 1.6882 (1.7523) teacher_loss 0.2684 (0.1734) loss_zs_kd 0.0394 (0.0526) loss_oracle 0.5951 (0.6706) kd_loss 1.1025 (1.2173) acc 90.6250 (93.8542) gate/entropy 0.9840 (0.9837) gate/usage_max 0.5673 (0.5676) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1654 (0.1656) teacher/entropy 0.1481 (0.0627) teacher/usage_max 0.3866 (0.4488) teacher/usage_min 0.2898 (0.2303) teacher/usage_std 0.0401 (0.0935) nleep/row_max_mean 1519.2441 (1528.7497) nleep/row_max_std 65.8207 (58.7870) nleep/row_min_mean 1490.0767 (1498.2612) lr 1.5567e-04 eta 0:02:27
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,415
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [44/50] batch [20/181] time 0.164 (0.171) data 0.000 (0.015) loss 1.5656 (1.7528) teacher_loss 0.1363 (0.1582) loss_zs_kd 0.0681 (0.0534) loss_oracle 0.6108 (0.6733) kd_loss 1.0898 (1.2312) acc 96.8750 (95.1562) gate/entropy 0.9837 (0.9838) gate/usage_max 0.5676 (0.5675) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1656 (0.1656) teacher/entropy 0.1027 (0.0618) teacher/usage_max 0.3604 (0.4440) teacher/usage_min 0.2890 (0.2193) teacher/usage_std 0.0316 (0.0948) nleep/row_max_mean 1533.9041 (1533.9406) nleep/row_max_std 55.9171 (59.6425) nleep/row_min_mean 1502.1411 (1503.2389) lr 1.2369e-04 eta 0:03:33
epoch [44/50] batch [40/181] time 0.191 (0.168) data 0.000 (0.008) loss 1.6072 (1.7847) teacher_loss 0.1016 (0.1795) loss_zs_kd 0.0418 (0.0502) loss_oracle 0.6195 (0.6745) kd_loss 1.1749 (1.2428) acc 93.7500 (93.3594) gate/entropy 0.9838 (0.9838) gate/usage_max 0.5675 (0.5675) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1656 (0.1656) teacher/entropy 0.0557 (0.0601) teacher/usage_max 0.4274 (0.4538) teacher/usage_min 0.2621 (0.2155) teacher/usage_std 0.0694 (0.1008) nleep/row_max_mean 1535.9259 (1534.7540) nleep/row_max_std 51.1120 (58.5740) nleep/row_min_mean 1505.4857 (1504.1044) lr 1.2369e-04 eta 0:03:26
epoch [44/50] batch [60/181] time 0.156 (0.170) data 0.001 (0.005) loss 1.8768 (1.7953) teacher_loss 0.1612 (0.1764) loss_zs_kd 0.0350 (0.0515) loss_oracle 0.8537 (0.6888) kd_loss 1.2712 (1.2488) acc 93.7500 (93.6979) gate/entropy 0.9840 (0.9838) gate/usage_max 0.5673 (0.5675) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1654 (0.1656) teacher/entropy 0.0316 (0.0529) teacher/usage_max 0.5334 (0.4501) teacher/usage_min 0.2317 (0.2204) teacher/usage_std 0.1415 (0.0975) nleep/row_max_mean 1527.1677 (1533.7579) nleep/row_max_std 54.2295 (56.5153) nleep/row_min_mean 1495.8425 (1503.0100) lr 1.2369e-04 eta 0:03:24
epoch [44/50] batch [80/181] time 0.155 (0.167) data 0.000 (0.004) loss 1.7907 (1.7820) teacher_loss 0.2436 (0.1729) loss_zs_kd 0.0337 (0.0508) loss_oracle 0.6866 (0.6893) kd_loss 1.1870 (1.2390) acc 84.3750 (93.8672) gate/entropy 0.9840 (0.9838) gate/usage_max 0.5673 (0.5675) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1655 (0.1656) teacher/entropy 0.1477 (0.0537) teacher/usage_max 0.5166 (0.4423) teacher/usage_min 0.2025 (0.2257) teacher/usage_std 0.1335 (0.0921) nleep/row_max_mean 1516.9385 (1534.1212) nleep/row_max_std 57.6752 (56.1357) nleep/row_min_mean 1489.7487 (1503.3789) lr 1.2369e-04 eta 0:03:18
epoch [44/50] batch [100/181] time 0.176 (0.166) data 0.000 (0.003) loss 1.6708 (1.7691) teacher_loss 0.0918 (0.1689) loss_zs_kd 0.0448 (0.0509) loss_oracle 0.6099 (0.6867) kd_loss 1.2517 (1.2314) acc 100.0000 (94.2188) gate/entropy 0.9839 (0.9838) gate/usage_max 0.5674 (0.5675) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1655 (0.1656) teacher/entropy 0.0695 (0.0522) teacher/usage_max 0.4733 (0.4423) teacher/usage_min 0.2181 (0.2263) teacher/usage_std 0.1056 (0.0919) nleep/row_max_mean 1529.4683 (1535.1078) nleep/row_max_std 58.0941 (55.7344) nleep/row_min_mean 1503.2081 (1504.1149) lr 1.2369e-04 eta 0:03:13
epoch [44/50] batch [120/181] time 0.079 (0.165) data 0.000 (0.003) loss 1.7510 (1.7713) teacher_loss 0.1170 (0.1707) loss_zs_kd 0.0465 (0.0506) loss_oracle 0.7237 (0.6884) kd_loss 1.2489 (1.2311) acc 93.7500 (94.3229) gate/entropy 0.9840 (0.9838) gate/usage_max 0.5673 (0.5675) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1654 (0.1656) teacher/entropy 0.0495 (0.0516) teacher/usage_max 0.4346 (0.4437) teacher/usage_min 0.2404 (0.2275) teacher/usage_std 0.0795 (0.0923) nleep/row_max_mean 1534.1565 (1536.1186) nleep/row_max_std 60.5812 (55.8385) nleep/row_min_mean 1504.3081 (1505.1054) lr 1.2369e-04 eta 0:03:08
epoch [44/50] batch [140/181] time 0.084 (0.160) data 0.000 (0.002) loss 1.6004 (1.7751) teacher_loss 0.1014 (0.1699) loss_zs_kd 0.0313 (0.0501) loss_oracle 0.6778 (0.6910) kd_loss 1.1445 (1.2347) acc 100.0000 (94.2188) gate/entropy 0.9838 (0.9838) gate/usage_max 0.5674 (0.5675) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1655 (0.1656) teacher/entropy 0.0234 (0.0499) teacher/usage_max 0.3964 (0.4443) teacher/usage_min 0.2280 (0.2269) teacher/usage_std 0.0750 (0.0929) nleep/row_max_mean 1550.2523 (1536.9635) nleep/row_max_std 55.1231 (56.1805) nleep/row_min_mean 1513.9302 (1505.7708) lr 1.2369e-04 eta 0:03:00
epoch [44/50] batch [160/181] time 0.099 (0.153) data 0.000 (0.002) loss 1.3479 (1.7741) teacher_loss 0.0592 (0.1711) loss_zs_kd 0.0241 (0.0500) loss_oracle 0.5388 (0.6918) kd_loss 1.0072 (1.2322) acc 100.0000 (94.1797) gate/entropy 0.9839 (0.9838) gate/usage_max 0.5674 (0.5674) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1655 (0.1655) teacher/entropy 0.1021 (0.0500) teacher/usage_max 0.4364 (0.4429) teacher/usage_min 0.2164 (0.2277) teacher/usage_std 0.0903 (0.0918) nleep/row_max_mean 1534.2642 (1536.9204) nleep/row_max_std 60.8638 (56.7201) nleep/row_min_mean 1507.2992 (1505.6729) lr 1.2369e-04 eta 0:02:49
epoch [44/50] batch [180/181] time 0.071 (0.148) data 0.000 (0.002) loss 1.9069 (1.7727) teacher_loss 0.1961 (0.1685) loss_zs_kd 0.0520 (0.0502) loss_oracle 0.7952 (0.6951) kd_loss 1.2872 (1.2315) acc 93.7500 (94.2361) gate/entropy 0.9839 (0.9838) gate/usage_max 0.5674 (0.5674) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1655 (0.1655) teacher/entropy 0.0017 (0.0494) teacher/usage_max 0.4685 (0.4437) teacher/usage_min 0.2500 (0.2291) teacher/usage_std 0.0964 (0.0917) nleep/row_max_mean 1543.4589 (1537.3330) nleep/row_max_std 56.4939 (56.9968) nleep/row_min_mean 1506.5402 (1505.8996) lr 1.2369e-04 eta 0:02:41
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,414
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,665
* accuracy: 99.7%
* error: 0.3%
* macro_f1: 99.7%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [45/50] batch [20/181] time 0.144 (0.130) data 0.000 (0.016) loss 1.7125 (1.7769) teacher_loss 0.1267 (0.1530) loss_zs_kd 0.0219 (0.0478) loss_oracle 0.6657 (0.7117) kd_loss 1.2420 (1.2441) acc 93.7500 (93.9062) gate/entropy 0.9842 (0.9839) gate/usage_max 0.5671 (0.5673) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1653 (0.1655) teacher/entropy 0.0346 (0.0386) teacher/usage_max 0.3766 (0.4537) teacher/usage_min 0.2630 (0.2264) teacher/usage_std 0.0502 (0.0971) nleep/row_max_mean 1530.7483 (1534.9106) nleep/row_max_std 76.8849 (59.4587) nleep/row_min_mean 1499.6288 (1503.1268) lr 9.5173e-05 eta 0:02:18
epoch [45/50] batch [40/181] time 0.099 (0.120) data 0.000 (0.008) loss 1.8047 (1.7601) teacher_loss 0.2215 (0.1556) loss_zs_kd 0.0547 (0.0487) loss_oracle 0.7249 (0.7111) kd_loss 1.1934 (1.2246) acc 87.5000 (93.9844) gate/entropy 0.9839 (0.9839) gate/usage_max 0.5673 (0.5674) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1655 (0.1655) teacher/entropy 0.0785 (0.0434) teacher/usage_max 0.4381 (0.4400) teacher/usage_min 0.2677 (0.2388) teacher/usage_std 0.0749 (0.0863) nleep/row_max_mean 1529.6760 (1536.6848) nleep/row_max_std 70.8253 (60.9551) nleep/row_min_mean 1498.4641 (1504.9497) lr 9.5173e-05 eta 0:02:05
epoch [45/50] batch [60/181] time 0.164 (0.122) data 0.001 (0.005) loss 1.8813 (1.7742) teacher_loss 0.1220 (0.1697) loss_zs_kd 0.0419 (0.0484) loss_oracle 0.7923 (0.7053) kd_loss 1.3421 (1.2276) acc 96.8750 (93.4375) gate/entropy 0.9840 (0.9839) gate/usage_max 0.5673 (0.5674) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1654 (0.1655) teacher/entropy 0.0066 (0.0470) teacher/usage_max 0.5304 (0.4419) teacher/usage_min 0.1875 (0.2349) teacher/usage_std 0.1446 (0.0887) nleep/row_max_mean 1545.8208 (1536.4261) nleep/row_max_std 54.7031 (61.0679) nleep/row_min_mean 1514.2356 (1504.8436) lr 9.5173e-05 eta 0:02:04
epoch [45/50] batch [80/181] time 0.161 (0.130) data 0.000 (0.004) loss 1.7781 (1.7799) teacher_loss 0.1214 (0.1634) loss_zs_kd 0.0530 (0.0488) loss_oracle 0.7217 (0.7144) kd_loss 1.2693 (1.2349) acc 100.0000 (93.7500) gate/entropy 0.9840 (0.9839) gate/usage_max 0.5673 (0.5674) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1654 (0.1655) teacher/entropy 0.0199 (0.0450) teacher/usage_max 0.3839 (0.4479) teacher/usage_min 0.2501 (0.2279) teacher/usage_std 0.0593 (0.0940) nleep/row_max_mean 1537.9592 (1537.7925) nleep/row_max_std 49.7726 (60.3960) nleep/row_min_mean 1504.9165 (1505.7745) lr 9.5173e-05 eta 0:02:10
epoch [45/50] batch [100/181] time 0.146 (0.133) data 0.000 (0.003) loss 1.8780 (1.7879) teacher_loss 0.2231 (0.1644) loss_zs_kd 0.0657 (0.0498) loss_oracle 0.7414 (0.7195) kd_loss 1.2513 (1.2388) acc 90.6250 (93.8438) gate/entropy 0.9840 (0.9839) gate/usage_max 0.5673 (0.5674) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1654 (0.1655) teacher/entropy 0.0733 (0.0432) teacher/usage_max 0.4849 (0.4449) teacher/usage_min 0.2132 (0.2278) teacher/usage_std 0.1131 (0.0925) nleep/row_max_mean 1536.3009 (1537.3597) nleep/row_max_std 50.4887 (59.9556) nleep/row_min_mean 1502.1061 (1505.3327) lr 9.5173e-05 eta 0:02:10
epoch [45/50] batch [120/181] time 0.151 (0.134) data 0.000 (0.003) loss 1.6408 (1.8010) teacher_loss 0.1346 (0.1685) loss_zs_kd 0.0576 (0.0516) loss_oracle 0.6802 (0.7269) kd_loss 1.1373 (1.2433) acc 93.7500 (93.8802) gate/entropy 0.9838 (0.9839) gate/usage_max 0.5674 (0.5674) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1655 (0.1655) teacher/entropy 0.0744 (0.0431) teacher/usage_max 0.3468 (0.4500) teacher/usage_min 0.3223 (0.2243) teacher/usage_std 0.0102 (0.0962) nleep/row_max_mean 1532.7268 (1537.4393) nleep/row_max_std 52.8783 (59.9518) nleep/row_min_mean 1503.7449 (1505.3901) lr 9.5173e-05 eta 0:02:09
epoch [45/50] batch [140/181] time 0.124 (0.135) data 0.000 (0.002) loss 1.6838 (1.7931) teacher_loss 0.1652 (0.1624) loss_zs_kd 0.0351 (0.0506) loss_oracle 0.6735 (0.7264) kd_loss 1.1643 (1.2421) acc 93.7500 (94.0179) gate/entropy 0.9838 (0.9839) gate/usage_max 0.5675 (0.5674) gate/usage_min 0.2152 (0.2153) gate/usage_std 0.1656 (0.1655) teacher/entropy 0.0274 (0.0427) teacher/usage_max 0.4633 (0.4482) teacher/usage_min 0.1862 (0.2254) teacher/usage_std 0.1137 (0.0952) nleep/row_max_mean 1554.0636 (1537.6259) nleep/row_max_std 52.3439 (60.2566) nleep/row_min_mean 1519.4650 (1505.4649) lr 9.5173e-05 eta 0:02:07
epoch [45/50] batch [160/181] time 0.126 (0.135) data 0.000 (0.002) loss 1.9048 (1.8019) teacher_loss 0.1595 (0.1691) loss_zs_kd 0.0645 (0.0510) loss_oracle 0.9104 (0.7272) kd_loss 1.2579 (1.2437) acc 93.7500 (93.7109) gate/entropy 0.9838 (0.9839) gate/usage_max 0.5675 (0.5674) gate/usage_min 0.2152 (0.2153) gate/usage_std 0.1656 (0.1655) teacher/entropy 0.0008 (0.0416) teacher/usage_max 0.4688 (0.4504) teacher/usage_min 0.2499 (0.2264) teacher/usage_std 0.0966 (0.0960) nleep/row_max_mean 1556.7001 (1537.3903) nleep/row_max_std 59.0651 (60.6518) nleep/row_min_mean 1517.4153 (1505.1745) lr 9.5173e-05 eta 0:02:05
epoch [45/50] batch [180/181] time 0.119 (0.135) data 0.000 (0.002) loss 1.7538 (1.7963) teacher_loss 0.0868 (0.1648) loss_zs_kd 0.0479 (0.0509) loss_oracle 0.7241 (0.7242) kd_loss 1.2810 (1.2440) acc 96.8750 (93.8542) gate/entropy 0.9838 (0.9839) gate/usage_max 0.5675 (0.5673) gate/usage_min 0.2152 (0.2153) gate/usage_std 0.1656 (0.1655) teacher/entropy 0.0218 (0.0413) teacher/usage_max 0.5000 (0.4481) teacher/usage_min 0.2357 (0.2275) teacher/usage_std 0.1184 (0.0944) nleep/row_max_mean 1546.7076 (1536.7306) nleep/row_max_std 54.9357 (60.8066) nleep/row_min_mean 1513.1104 (1504.5121) lr 9.5173e-05 eta 0:02:02
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,416
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [46/50] batch [20/181] time 0.088 (0.154) data 0.000 (0.017) loss 1.6595 (1.7211) teacher_loss 0.2180 (0.1389) loss_zs_kd 0.0415 (0.0408) loss_oracle 0.5465 (0.6946) kd_loss 1.1474 (1.2144) acc 87.5000 (95.0000) gate/entropy 0.9841 (0.9841) gate/usage_max 0.5672 (0.5672) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1654 (0.1654) teacher/entropy 0.0608 (0.0517) teacher/usage_max 0.3363 (0.4215) teacher/usage_min 0.3294 (0.2506) teacher/usage_std 0.0029 (0.0735) nleep/row_max_mean 1535.6545 (1534.5782) nleep/row_max_std 57.9241 (58.1550) nleep/row_min_mean 1503.2900 (1502.5521) lr 7.0224e-05 eta 0:02:16
epoch [46/50] batch [40/181] time 0.158 (0.129) data 0.000 (0.008) loss 1.9874 (1.7668) teacher_loss 0.3059 (0.1557) loss_zs_kd 0.0679 (0.0456) loss_oracle 0.6420 (0.7040) kd_loss 1.3266 (1.2363) acc 90.6250 (94.5312) gate/entropy 0.9838 (0.9840) gate/usage_max 0.5675 (0.5673) gate/usage_min 0.2152 (0.2153) gate/usage_std 0.1656 (0.1654) teacher/entropy 0.0585 (0.0456) teacher/usage_max 0.4559 (0.4332) teacher/usage_min 0.1511 (0.2293) teacher/usage_std 0.1314 (0.0873) nleep/row_max_mean 1530.6926 (1536.3479) nleep/row_max_std 72.0133 (58.5045) nleep/row_min_mean 1502.6826 (1504.2892) lr 7.0224e-05 eta 0:01:51
epoch [46/50] batch [60/181] time 0.182 (0.125) data 0.000 (0.006) loss 1.8616 (1.7713) teacher_loss 0.3035 (0.1588) loss_zs_kd 0.0390 (0.0486) loss_oracle 0.6478 (0.6935) kd_loss 1.2146 (1.2415) acc 84.3750 (94.0625) gate/entropy 0.9843 (0.9840) gate/usage_max 0.5670 (0.5673) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1652 (0.1654) teacher/entropy 0.0540 (0.0410) teacher/usage_max 0.4203 (0.4373) teacher/usage_min 0.2710 (0.2326) teacher/usage_std 0.0634 (0.0876) nleep/row_max_mean 1534.0522 (1538.8563) nleep/row_max_std 50.5555 (57.4690) nleep/row_min_mean 1502.4586 (1506.6860) lr 7.0224e-05 eta 0:01:45
epoch [46/50] batch [80/181] time 0.061 (0.121) data 0.000 (0.004) loss 1.7678 (1.7756) teacher_loss 0.1956 (0.1577) loss_zs_kd 0.0439 (0.0476) loss_oracle 0.7091 (0.7017) kd_loss 1.1958 (1.2432) acc 93.7500 (94.2188) gate/entropy 0.9840 (0.9840) gate/usage_max 0.5673 (0.5673) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1655 (0.1654) teacher/entropy 0.0019 (0.0399) teacher/usage_max 0.4997 (0.4399) teacher/usage_min 0.1566 (0.2310) teacher/usage_std 0.1403 (0.0897) nleep/row_max_mean 1554.9131 (1539.4968) nleep/row_max_std 59.6880 (57.8359) nleep/row_min_mean 1515.8759 (1507.1618) lr 7.0224e-05 eta 0:01:40
epoch [46/50] batch [100/181] time 0.170 (0.121) data 0.000 (0.003) loss 1.7401 (1.7737) teacher_loss 0.1199 (0.1605) loss_zs_kd 0.0642 (0.0492) loss_oracle 0.7807 (0.7062) kd_loss 1.1978 (1.2355) acc 96.8750 (94.2500) gate/entropy 0.9841 (0.9840) gate/usage_max 0.5672 (0.5673) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1654 (0.1654) teacher/entropy 0.0629 (0.0419) teacher/usage_max 0.3877 (0.4434) teacher/usage_min 0.2801 (0.2276) teacher/usage_std 0.0439 (0.0927) nleep/row_max_mean 1532.9749 (1539.8421) nleep/row_max_std 55.1916 (57.4047) nleep/row_min_mean 1498.1846 (1507.3381) lr 7.0224e-05 eta 0:01:37
epoch [46/50] batch [120/181] time 0.099 (0.116) data 0.000 (0.003) loss 1.9371 (1.7695) teacher_loss 0.2301 (0.1606) loss_zs_kd 0.0589 (0.0498) loss_oracle 0.6806 (0.7001) kd_loss 1.3373 (1.2339) acc 90.6250 (94.3229) gate/entropy 0.9841 (0.9840) gate/usage_max 0.5671 (0.5673) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1653 (0.1654) teacher/entropy 0.0406 (0.0428) teacher/usage_max 0.4275 (0.4438) teacher/usage_min 0.1583 (0.2305) teacher/usage_std 0.1239 (0.0918) nleep/row_max_mean 1531.2378 (1538.4003) nleep/row_max_std 62.4144 (57.9277) nleep/row_min_mean 1500.6636 (1506.1003) lr 7.0224e-05 eta 0:01:30
epoch [46/50] batch [140/181] time 0.176 (0.117) data 0.000 (0.003) loss 1.7917 (1.7767) teacher_loss 0.1361 (0.1614) loss_zs_kd 0.0360 (0.0497) loss_oracle 0.7210 (0.7052) kd_loss 1.2770 (1.2378) acc 93.7500 (94.1741) gate/entropy 0.9839 (0.9840) gate/usage_max 0.5674 (0.5673) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1655 (0.1654) teacher/entropy 0.0126 (0.0417) teacher/usage_max 0.4359 (0.4442) teacher/usage_min 0.2498 (0.2275) teacher/usage_std 0.0771 (0.0931) nleep/row_max_mean 1539.2881 (1538.0350) nleep/row_max_std 51.1171 (57.8024) nleep/row_min_mean 1509.4099 (1505.7281) lr 7.0224e-05 eta 0:01:29
epoch [46/50] batch [160/181] time 0.168 (0.116) data 0.000 (0.002) loss 1.9183 (1.7820) teacher_loss 0.1462 (0.1609) loss_zs_kd 0.0532 (0.0493) loss_oracle 0.8437 (0.7083) kd_loss 1.3237 (1.2423) acc 93.7500 (93.9844) gate/entropy 0.9839 (0.9840) gate/usage_max 0.5674 (0.5672) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1655 (0.1654) teacher/entropy 0.0510 (0.0412) teacher/usage_max 0.6296 (0.4449) teacher/usage_min 0.1600 (0.2261) teacher/usage_std 0.2105 (0.0941) nleep/row_max_mean 1544.2509 (1537.4672) nleep/row_max_std 49.6425 (57.8099) nleep/row_min_mean 1512.2734 (1505.3297) lr 7.0224e-05 eta 0:01:26
epoch [46/50] batch [180/181] time 0.134 (0.115) data 0.000 (0.002) loss 2.0199 (1.7864) teacher_loss 0.1492 (0.1642) loss_zs_kd 0.0298 (0.0488) loss_oracle 0.8742 (0.7099) kd_loss 1.4187 (1.2429) acc 96.8750 (93.9062) gate/entropy 0.9841 (0.9840) gate/usage_max 0.5671 (0.5672) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1653 (0.1654) teacher/entropy 0.0661 (0.0416) teacher/usage_max 0.6015 (0.4443) teacher/usage_min 0.0463 (0.2254) teacher/usage_std 0.2270 (0.0940) nleep/row_max_mean 1535.7993 (1537.0927) nleep/row_max_std 58.4918 (57.6684) nleep/row_min_mean 1507.8539 (1505.0288) lr 7.0224e-05 eta 0:01:23
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,414
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [47/50] batch [20/181] time 0.153 (0.168) data 0.000 (0.018) loss 1.9161 (1.7633) teacher_loss 0.2224 (0.1424) loss_zs_kd 0.0461 (0.0478) loss_oracle 0.8014 (0.7169) kd_loss 1.2700 (1.2386) acc 93.7500 (94.8438) gate/entropy 0.9841 (0.9841) gate/usage_max 0.5672 (0.5671) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1654 (0.1653) teacher/entropy 0.0470 (0.0370) teacher/usage_max 0.5497 (0.4445) teacher/usage_min 0.2200 (0.2412) teacher/usage_std 0.1531 (0.0879) nleep/row_max_mean 1534.8057 (1532.7316) nleep/row_max_std 58.5484 (58.3668) nleep/row_min_mean 1502.6451 (1500.6862) lr 4.8943e-05 eta 0:01:58
epoch [47/50] batch [40/181] time 0.123 (0.155) data 0.000 (0.009) loss 2.1245 (1.7732) teacher_loss 0.4060 (0.1478) loss_zs_kd 0.0504 (0.0471) loss_oracle 0.7313 (0.7233) kd_loss 1.3277 (1.2402) acc 84.3750 (94.2188) gate/entropy 0.9841 (0.9841) gate/usage_max 0.5671 (0.5672) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1653 (0.1654) teacher/entropy 0.0650 (0.0399) teacher/usage_max 0.5603 (0.4391) teacher/usage_min 0.1421 (0.2412) teacher/usage_std 0.1726 (0.0844) nleep/row_max_mean 1529.4515 (1535.9428) nleep/row_max_std 56.7736 (58.8585) nleep/row_min_mean 1499.9435 (1503.8741) lr 4.8943e-05 eta 0:01:46
epoch [47/50] batch [60/181] time 0.135 (0.152) data 0.001 (0.006) loss 1.7615 (1.7745) teacher_loss 0.1343 (0.1602) loss_zs_kd 0.0429 (0.0475) loss_oracle 0.7292 (0.7074) kd_loss 1.2411 (1.2369) acc 96.8750 (93.8542) gate/entropy 0.9841 (0.9841) gate/usage_max 0.5671 (0.5672) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1653 (0.1654) teacher/entropy 0.0162 (0.0420) teacher/usage_max 0.3718 (0.4363) teacher/usage_min 0.2833 (0.2432) teacher/usage_std 0.0371 (0.0821) nleep/row_max_mean 1533.0903 (1535.3887) nleep/row_max_std 63.1327 (57.6114) nleep/row_min_mean 1499.6731 (1503.6898) lr 4.8943e-05 eta 0:01:40
epoch [47/50] batch [80/181] time 0.136 (0.150) data 0.000 (0.005) loss 1.8463 (1.7913) teacher_loss 0.3015 (0.1700) loss_zs_kd 0.0482 (0.0493) loss_oracle 0.6598 (0.7138) kd_loss 1.1908 (1.2397) acc 90.6250 (93.7500) gate/entropy 0.9841 (0.9841) gate/usage_max 0.5672 (0.5672) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1653 (0.1654) teacher/entropy 0.0571 (0.0411) teacher/usage_max 0.3573 (0.4367) teacher/usage_min 0.2931 (0.2380) teacher/usage_std 0.0287 (0.0846) nleep/row_max_mean 1527.2690 (1534.6259) nleep/row_max_std 53.6749 (57.0314) nleep/row_min_mean 1496.7937 (1502.9552) lr 4.8943e-05 eta 0:01:36
epoch [47/50] batch [100/181] time 0.145 (0.148) data 0.000 (0.004) loss 1.7072 (1.7952) teacher_loss 0.1260 (0.1706) loss_zs_kd 0.0394 (0.0495) loss_oracle 0.6948 (0.7141) kd_loss 1.2141 (1.2429) acc 96.8750 (93.7188) gate/entropy 0.9840 (0.9841) gate/usage_max 0.5672 (0.5672) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1654 (0.1654) teacher/entropy 0.0544 (0.0416) teacher/usage_max 0.3650 (0.4391) teacher/usage_min 0.2720 (0.2328) teacher/usage_std 0.0434 (0.0880) nleep/row_max_mean 1526.5361 (1534.9490) nleep/row_max_std 54.7365 (55.7907) nleep/row_min_mean 1494.8408 (1503.4802) lr 4.8943e-05 eta 0:01:32
epoch [47/50] batch [120/181] time 0.164 (0.148) data 0.000 (0.003) loss 1.7781 (1.7929) teacher_loss 0.2497 (0.1690) loss_zs_kd 0.0484 (0.0492) loss_oracle 0.6613 (0.7134) kd_loss 1.1735 (1.2426) acc 87.5000 (93.9062) gate/entropy 0.9842 (0.9841) gate/usage_max 0.5671 (0.5672) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1653 (0.1654) teacher/entropy 0.0618 (0.0419) teacher/usage_max 0.4231 (0.4398) teacher/usage_min 0.2702 (0.2320) teacher/usage_std 0.0652 (0.0887) nleep/row_max_mean 1530.3419 (1534.8157) nleep/row_max_std 63.7794 (55.6016) nleep/row_min_mean 1497.6997 (1503.4002) lr 4.8943e-05 eta 0:01:29
epoch [47/50] batch [140/181] time 0.100 (0.147) data 0.000 (0.003) loss 1.7714 (1.7940) teacher_loss 0.1749 (0.1702) loss_zs_kd 0.0519 (0.0504) loss_oracle 0.7107 (0.7104) kd_loss 1.2152 (1.2433) acc 93.7500 (94.0179) gate/entropy 0.9842 (0.9841) gate/usage_max 0.5671 (0.5672) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1653 (0.1654) teacher/entropy 0.0363 (0.0412) teacher/usage_max 0.3692 (0.4400) teacher/usage_min 0.2889 (0.2318) teacher/usage_std 0.0333 (0.0887) nleep/row_max_mean 1521.1482 (1534.1911) nleep/row_max_std 61.5103 (55.2842) nleep/row_min_mean 1488.3079 (1502.7759) lr 4.8943e-05 eta 0:01:25
epoch [47/50] batch [160/181] time 0.174 (0.142) data 0.000 (0.002) loss 1.9478 (1.7971) teacher_loss 0.3598 (0.1721) loss_zs_kd 0.0522 (0.0503) loss_oracle 0.5931 (0.7126) kd_loss 1.2653 (1.2435) acc 90.6250 (93.8867) gate/entropy 0.9842 (0.9841) gate/usage_max 0.5671 (0.5672) gate/usage_min 0.2154 (0.2153) gate/usage_std 0.1653 (0.1654) teacher/entropy 0.0782 (0.0417) teacher/usage_max 0.4247 (0.4396) teacher/usage_min 0.1942 (0.2315) teacher/usage_std 0.1000 (0.0886) nleep/row_max_mean 1528.8889 (1533.9876) nleep/row_max_std 48.6259 (55.4402) nleep/row_min_mean 1501.1865 (1502.6780) lr 4.8943e-05 eta 0:01:20
epoch [47/50] batch [180/181] time 0.076 (0.137) data 0.000 (0.002) loss 1.7518 (1.7947) teacher_loss 0.2192 (0.1690) loss_zs_kd 0.0411 (0.0497) loss_oracle 0.6721 (0.7135) kd_loss 1.1760 (1.2442) acc 90.6250 (94.0451) gate/entropy 0.9841 (0.9841) gate/usage_max 0.5672 (0.5672) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1654 (0.1654) teacher/entropy 0.0254 (0.0406) teacher/usage_max 0.3851 (0.4402) teacher/usage_min 0.2731 (0.2319) teacher/usage_std 0.0461 (0.0888) nleep/row_max_mean 1541.1101 (1534.2713) nleep/row_max_std 51.1348 (55.6877) nleep/row_min_mean 1506.8313 (1502.9307) lr 4.8943e-05 eta 0:01:14
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,416
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [48/50] batch [20/181] time 0.155 (0.143) data 0.000 (0.017) loss 1.5263 (1.7779) teacher_loss 0.0996 (0.1502) loss_zs_kd 0.0223 (0.0501) loss_oracle 0.6316 (0.7073) kd_loss 1.0997 (1.2490) acc 93.7500 (93.9062) gate/entropy 0.9840 (0.9841) gate/usage_max 0.5673 (0.5672) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1654 (0.1654) teacher/entropy 0.0088 (0.0308) teacher/usage_max 0.4372 (0.4477) teacher/usage_min 0.2188 (0.2264) teacher/usage_std 0.0895 (0.0943) nleep/row_max_mean 1547.0190 (1535.7000) nleep/row_max_std 58.2574 (54.7195) nleep/row_min_mean 1514.1519 (1504.0254) lr 3.1417e-05 eta 0:01:14
epoch [48/50] batch [40/181] time 0.059 (0.122) data 0.000 (0.009) loss 1.8168 (1.7793) teacher_loss 0.1852 (0.1530) loss_zs_kd 0.0637 (0.0498) loss_oracle 0.6955 (0.7143) kd_loss 1.2520 (1.2442) acc 93.7500 (94.5312) gate/entropy 0.9840 (0.9841) gate/usage_max 0.5673 (0.5672) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1654 (0.1654) teacher/entropy 0.0076 (0.0367) teacher/usage_max 0.3737 (0.4433) teacher/usage_min 0.2813 (0.2320) teacher/usage_std 0.0386 (0.0900) nleep/row_max_mean 1535.6831 (1535.6229) nleep/row_max_std 39.7945 (55.0054) nleep/row_min_mean 1503.5228 (1504.0222) lr 3.1417e-05 eta 0:01:01
epoch [48/50] batch [60/181] time 0.078 (0.116) data 0.001 (0.006) loss 1.8244 (1.7867) teacher_loss 0.1842 (0.1662) loss_zs_kd 0.0568 (0.0526) loss_oracle 0.6829 (0.7087) kd_loss 1.2704 (1.2398) acc 93.7500 (94.0104) gate/entropy 0.9842 (0.9841) gate/usage_max 0.5671 (0.5672) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1653 (0.1653) teacher/entropy 0.0477 (0.0413) teacher/usage_max 0.3998 (0.4426) teacher/usage_min 0.2199 (0.2330) teacher/usage_std 0.0806 (0.0895) nleep/row_max_mean 1538.9241 (1535.2608) nleep/row_max_std 46.5305 (54.9755) nleep/row_min_mean 1507.8456 (1503.8818) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [80/181] time 0.147 (0.114) data 0.000 (0.004) loss 1.9506 (1.7929) teacher_loss 0.1806 (0.1643) loss_zs_kd 0.0859 (0.0524) loss_oracle 0.8570 (0.7184) kd_loss 1.2986 (1.2431) acc 96.8750 (94.1016) gate/entropy 0.9841 (0.9841) gate/usage_max 0.5672 (0.5672) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1653 (0.1653) teacher/entropy 0.0659 (0.0416) teacher/usage_max 0.6235 (0.4481) teacher/usage_min 0.1700 (0.2285) teacher/usage_std 0.2057 (0.0942) nleep/row_max_mean 1531.2537 (1535.9850) nleep/row_max_std 51.7707 (55.8172) nleep/row_min_mean 1500.3677 (1504.4503) lr 3.1417e-05 eta 0:00:52
epoch [48/50] batch [100/181] time 0.189 (0.126) data 0.000 (0.004) loss 1.6698 (1.7944) teacher_loss 0.1433 (0.1676) loss_zs_kd 0.0377 (0.0523) loss_oracle 0.5988 (0.7145) kd_loss 1.2083 (1.2434) acc 90.6250 (93.8438) gate/entropy 0.9844 (0.9841) gate/usage_max 0.5669 (0.5672) gate/usage_min 0.2155 (0.2154) gate/usage_std 0.1652 (0.1653) teacher/entropy 0.0509 (0.0425) teacher/usage_max 0.3854 (0.4512) teacher/usage_min 0.2807 (0.2279) teacher/usage_std 0.0427 (0.0956) nleep/row_max_mean 1517.2893 (1535.6957) nleep/row_max_std 70.2021 (56.3756) nleep/row_min_mean 1488.0115 (1504.2235) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [120/181] time 0.191 (0.134) data 0.000 (0.003) loss 1.6846 (1.8054) teacher_loss 0.0730 (0.1716) loss_zs_kd 0.0336 (0.0516) loss_oracle 0.7264 (0.7170) kd_loss 1.2317 (1.2495) acc 96.8750 (93.6458) gate/entropy 0.9840 (0.9841) gate/usage_max 0.5673 (0.5672) gate/usage_min 0.2153 (0.2153) gate/usage_std 0.1654 (0.1653) teacher/entropy 0.0266 (0.0424) teacher/usage_max 0.4046 (0.4598) teacher/usage_min 0.2822 (0.2238) teacher/usage_std 0.0520 (0.1011) nleep/row_max_mean 1544.1108 (1536.2414) nleep/row_max_std 46.4713 (56.0052) nleep/row_min_mean 1511.9561 (1504.8131) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [140/181] time 0.189 (0.140) data 0.000 (0.003) loss 1.7166 (1.8047) teacher_loss 0.0733 (0.1689) loss_zs_kd 0.0386 (0.0511) loss_oracle 0.6783 (0.7169) kd_loss 1.2849 (1.2517) acc 100.0000 (93.7054) gate/entropy 0.9844 (0.9841) gate/usage_max 0.5669 (0.5672) gate/usage_min 0.2155 (0.2154) gate/usage_std 0.1652 (0.1653) teacher/entropy 0.0041 (0.0411) teacher/usage_max 0.4055 (0.4581) teacher/usage_min 0.2500 (0.2224) teacher/usage_std 0.0640 (0.1011) nleep/row_max_mean 1523.6776 (1536.1375) nleep/row_max_std 65.8713 (56.1400) nleep/row_min_mean 1491.3999 (1504.7318) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [160/181] time 0.190 (0.145) data 0.000 (0.002) loss 1.8164 (1.7953) teacher_loss 0.1687 (0.1637) loss_zs_kd 0.0557 (0.0505) loss_oracle 0.8018 (0.7136) kd_loss 1.2189 (1.2496) acc 96.8750 (94.0039) gate/entropy 0.9841 (0.9841) gate/usage_max 0.5672 (0.5671) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1654 (0.1653) teacher/entropy 0.0151 (0.0403) teacher/usage_max 0.3487 (0.4555) teacher/usage_min 0.3074 (0.2243) teacher/usage_std 0.0184 (0.0991) nleep/row_max_mean 1541.2405 (1535.5266) nleep/row_max_std 41.7720 (55.6187) nleep/row_min_mean 1507.6683 (1504.1318) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [180/181] time 0.187 (0.148) data 0.000 (0.002) loss 2.0141 (1.7959) teacher_loss 0.2301 (0.1642) loss_zs_kd 0.0760 (0.0507) loss_oracle 0.7899 (0.7152) kd_loss 1.3511 (1.2487) acc 84.3750 (93.8889) gate/entropy 0.9839 (0.9841) gate/usage_max 0.5674 (0.5671) gate/usage_min 0.2152 (0.2154) gate/usage_std 0.1655 (0.1653) teacher/entropy 0.0275 (0.0399) teacher/usage_max 0.6082 (0.4563) teacher/usage_min 0.1563 (0.2250) teacher/usage_std 0.1970 (0.0991) nleep/row_max_mean 1541.3762 (1535.7485) nleep/row_max_std 57.2667 (55.1175) nleep/row_min_mean 1511.2262 (1504.3038) lr 3.1417e-05 eta 0:00:53
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,414
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [49/50] batch [20/181] time 0.184 (0.154) data 0.000 (0.015) loss 2.0199 (1.7672) teacher_loss 0.2851 (0.1338) loss_zs_kd 0.0671 (0.0461) loss_oracle 0.7115 (0.7088) kd_loss 1.3454 (1.2560) acc 90.6250 (95.3125) gate/entropy 0.9840 (0.9842) gate/usage_max 0.5673 (0.5671) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1654 (0.1653) teacher/entropy 0.0593 (0.0332) teacher/usage_max 0.5225 (0.4485) teacher/usage_min 0.1298 (0.2320) teacher/usage_std 0.1606 (0.0913) nleep/row_max_mean 1539.0120 (1536.4992) nleep/row_max_std 52.5220 (53.6144) nleep/row_min_mean 1510.6599 (1505.4256) lr 1.7713e-05 eta 0:00:52
epoch [49/50] batch [40/181] time 0.185 (0.134) data 0.000 (0.007) loss 1.7837 (1.7962) teacher_loss 0.1494 (0.1636) loss_zs_kd 0.0845 (0.0497) loss_oracle 0.8258 (0.7240) kd_loss 1.1791 (1.2457) acc 93.7500 (94.3750) gate/entropy 0.9842 (0.9842) gate/usage_max 0.5671 (0.5671) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1653 (0.1653) teacher/entropy 0.0608 (0.0433) teacher/usage_max 0.3622 (0.4470) teacher/usage_min 0.3013 (0.2248) teacher/usage_std 0.0250 (0.0938) nleep/row_max_mean 1540.6335 (1533.8261) nleep/row_max_std 52.4716 (56.0477) nleep/row_min_mean 1507.7776 (1502.9128) lr 1.7713e-05 eta 0:00:43
epoch [49/50] batch [60/181] time 0.071 (0.130) data 0.001 (0.005) loss 1.7379 (1.7915) teacher_loss 0.0760 (0.1632) loss_zs_kd 0.0475 (0.0496) loss_oracle 0.8326 (0.7210) kd_loss 1.2218 (1.2431) acc 96.8750 (93.9062) gate/entropy 0.9842 (0.9842) gate/usage_max 0.5670 (0.5671) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1653 (0.1653) teacher/entropy 0.0389 (0.0432) teacher/usage_max 0.3712 (0.4476) teacher/usage_min 0.2798 (0.2277) teacher/usage_std 0.0390 (0.0939) nleep/row_max_mean 1532.1493 (1532.6936) nleep/row_max_std 60.4381 (57.7128) nleep/row_min_mean 1496.5494 (1501.7772) lr 1.7713e-05 eta 0:00:39
epoch [49/50] batch [80/181] time 0.072 (0.125) data 0.000 (0.004) loss 1.8080 (1.7916) teacher_loss 0.2397 (0.1683) loss_zs_kd 0.0743 (0.0501) loss_oracle 0.6681 (0.7141) kd_loss 1.1972 (1.2412) acc 87.5000 (93.6328) gate/entropy 0.9843 (0.9842) gate/usage_max 0.5670 (0.5671) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1652 (0.1653) teacher/entropy 0.0338 (0.0423) teacher/usage_max 0.3703 (0.4474) teacher/usage_min 0.3106 (0.2299) teacher/usage_std 0.0264 (0.0929) nleep/row_max_mean 1524.1494 (1532.0684) nleep/row_max_std 64.1231 (58.1844) nleep/row_min_mean 1492.1492 (1500.9507) lr 1.7713e-05 eta 0:00:35
epoch [49/50] batch [100/181] time 0.096 (0.120) data 0.000 (0.003) loss 1.8460 (1.7931) teacher_loss 0.1199 (0.1721) loss_zs_kd 0.0269 (0.0507) loss_oracle 0.8811 (0.7141) kd_loss 1.2721 (1.2387) acc 93.7500 (93.7188) gate/entropy 0.9839 (0.9842) gate/usage_max 0.5673 (0.5671) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1655 (0.1653) teacher/entropy 0.0380 (0.0431) teacher/usage_max 0.5672 (0.4538) teacher/usage_min 0.2053 (0.2264) teacher/usage_std 0.1656 (0.0972) nleep/row_max_mean 1552.9836 (1533.0346) nleep/row_max_std 55.9210 (58.6538) nleep/row_min_mean 1517.0684 (1501.8169) lr 1.7713e-05 eta 0:00:31
epoch [49/50] batch [120/181] time 0.067 (0.115) data 0.000 (0.003) loss 1.8102 (1.7920) teacher_loss 0.0735 (0.1718) loss_zs_kd 0.0494 (0.0507) loss_oracle 0.7994 (0.7120) kd_loss 1.3123 (1.2388) acc 100.0000 (93.6979) gate/entropy 0.9840 (0.9842) gate/usage_max 0.5673 (0.5671) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1654 (0.1653) teacher/entropy 0.0064 (0.0433) teacher/usage_max 0.4058 (0.4522) teacher/usage_min 0.2196 (0.2271) teacher/usage_std 0.0814 (0.0965) nleep/row_max_mean 1547.5208 (1532.9582) nleep/row_max_std 58.0264 (59.1299) nleep/row_min_mean 1511.5938 (1501.7715) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [140/181] time 0.072 (0.112) data 0.000 (0.002) loss 1.7068 (1.7872) teacher_loss 0.1698 (0.1680) loss_zs_kd 0.0586 (0.0505) loss_oracle 0.6727 (0.7104) kd_loss 1.1713 (1.2388) acc 93.7500 (93.9062) gate/entropy 0.9840 (0.9842) gate/usage_max 0.5673 (0.5671) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1654 (0.1653) teacher/entropy 0.0224 (0.0443) teacher/usage_max 0.3494 (0.4484) teacher/usage_min 0.3054 (0.2285) teacher/usage_std 0.0198 (0.0943) nleep/row_max_mean 1547.3818 (1532.4162) nleep/row_max_std 65.1398 (59.7702) nleep/row_min_mean 1511.8696 (1501.2813) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [160/181] time 0.060 (0.108) data 0.000 (0.002) loss 2.0515 (1.7889) teacher_loss 0.1781 (0.1687) loss_zs_kd 0.0576 (0.0503) loss_oracle 0.8378 (0.7122) kd_loss 1.4257 (1.2389) acc 93.7500 (93.9453) gate/entropy 0.9839 (0.9842) gate/usage_max 0.5674 (0.5671) gate/usage_min 0.2152 (0.2154) gate/usage_std 0.1655 (0.1653) teacher/entropy 0.0132 (0.0457) teacher/usage_max 0.5601 (0.4487) teacher/usage_min 0.0945 (0.2268) teacher/usage_std 0.1903 (0.0950) nleep/row_max_mean 1549.2478 (1532.3652) nleep/row_max_std 49.1728 (59.8537) nleep/row_min_mean 1517.9598 (1501.2512) lr 1.7713e-05 eta 0:00:21
epoch [49/50] batch [180/181] time 0.076 (0.108) data 0.000 (0.002) loss 1.5911 (1.7895) teacher_loss 0.0830 (0.1705) loss_zs_kd 0.0276 (0.0497) loss_oracle 0.6647 (0.7113) kd_loss 1.1620 (1.2385) acc 96.8750 (93.9236) gate/entropy 0.9839 (0.9842) gate/usage_max 0.5674 (0.5671) gate/usage_min 0.2152 (0.2154) gate/usage_std 0.1655 (0.1653) teacher/entropy 0.0762 (0.0474) teacher/usage_max 0.4283 (0.4473) teacher/usage_min 0.2692 (0.2269) teacher/usage_std 0.0685 (0.0945) nleep/row_max_mean 1547.4308 (1532.1342) nleep/row_max_std 67.0540 (59.8216) nleep/row_min_mean 1516.4331 (1501.1217) lr 1.7713e-05 eta 0:00:19
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,415
* accuracy: 96.7%
* error: 3.3%
* macro_f1: 97.2%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
epoch [50/50] batch [20/181] time 0.160 (0.173) data 0.000 (0.017) loss 1.8874 (1.8320) teacher_loss 0.2428 (0.1885) loss_zs_kd 0.0738 (0.0532) loss_oracle 0.7781 (0.7327) kd_loss 1.2187 (1.2505) acc 87.5000 (92.8125) gate/entropy 0.9841 (0.9841) gate/usage_max 0.5672 (0.5671) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1653 (0.1653) teacher/entropy 0.0365 (0.0424) teacher/usage_max 0.4021 (0.4598) teacher/usage_min 0.2850 (0.2146) teacher/usage_std 0.0499 (0.1044) nleep/row_max_mean 1542.6989 (1536.0611) nleep/row_max_std 50.5943 (57.7675) nleep/row_min_mean 1510.1719 (1504.4412) lr 7.8853e-06 eta 0:00:27
epoch [50/50] batch [40/181] time 0.129 (0.161) data 0.000 (0.009) loss 1.7760 (1.7821) teacher_loss 0.1536 (0.1766) loss_zs_kd 0.0495 (0.0514) loss_oracle 0.7083 (0.7090) kd_loss 1.2435 (1.2252) acc 93.7500 (93.2031) gate/entropy 0.9842 (0.9842) gate/usage_max 0.5670 (0.5671) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1652 (0.1653) teacher/entropy 0.0443 (0.0507) teacher/usage_max 0.4903 (0.4524) teacher/usage_min 0.2503 (0.2270) teacher/usage_std 0.1110 (0.0963) nleep/row_max_mean 1536.3796 (1535.5592) nleep/row_max_std 68.4358 (59.8390) nleep/row_min_mean 1503.3411 (1504.2330) lr 7.8853e-06 eta 0:00:22
epoch [50/50] batch [60/181] time 0.156 (0.155) data 0.001 (0.006) loss 1.6212 (1.7914) teacher_loss 0.0606 (0.1750) loss_zs_kd 0.0632 (0.0501) loss_oracle 0.6557 (0.7116) kd_loss 1.2012 (1.2356) acc 100.0000 (93.6458) gate/entropy 0.9842 (0.9842) gate/usage_max 0.5671 (0.5671) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1653 (0.1653) teacher/entropy 0.0505 (0.0484) teacher/usage_max 0.3705 (0.4576) teacher/usage_min 0.2892 (0.2212) teacher/usage_std 0.0336 (0.1009) nleep/row_max_mean 1531.2195 (1535.9756) nleep/row_max_std 63.7197 (59.2417) nleep/row_min_mean 1500.4951 (1504.8489) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [80/181] time 0.119 (0.154) data 0.000 (0.004) loss 1.6958 (1.7895) teacher_loss 0.0962 (0.1705) loss_zs_kd 0.0562 (0.0515) loss_oracle 0.7712 (0.7124) kd_loss 1.1860 (1.2371) acc 100.0000 (93.9844) gate/entropy 0.9840 (0.9841) gate/usage_max 0.5673 (0.5671) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1654 (0.1653) teacher/entropy 0.0313 (0.0479) teacher/usage_max 0.4085 (0.4571) teacher/usage_min 0.2672 (0.2200) teacher/usage_std 0.0580 (0.1016) nleep/row_max_mean 1548.4749 (1536.0642) nleep/row_max_std 49.5783 (58.2371) nleep/row_min_mean 1513.4341 (1504.8842) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [100/181] time 0.141 (0.152) data 0.000 (0.004) loss 1.6862 (1.7862) teacher_loss 0.0750 (0.1684) loss_zs_kd 0.0681 (0.0518) loss_oracle 0.8018 (0.7145) kd_loss 1.1762 (1.2346) acc 100.0000 (94.0312) gate/entropy 0.9841 (0.9842) gate/usage_max 0.5672 (0.5671) gate/usage_min 0.2153 (0.2154) gate/usage_std 0.1654 (0.1653) teacher/entropy 0.0219 (0.0485) teacher/usage_max 0.3932 (0.4555) teacher/usage_min 0.2631 (0.2197) teacher/usage_std 0.0536 (0.1007) nleep/row_max_mean 1543.6160 (1535.3833) nleep/row_max_std 55.5811 (58.0595) nleep/row_min_mean 1507.9803 (1504.2268) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [120/181] time 0.131 (0.152) data 0.000 (0.003) loss 1.6986 (1.7819) teacher_loss 0.0939 (0.1651) loss_zs_kd 0.0385 (0.0511) loss_oracle 0.5767 (0.7116) kd_loss 1.2971 (1.2355) acc 100.0000 (94.1667) gate/entropy 0.9843 (0.9842) gate/usage_max 0.5670 (0.5671) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1652 (0.1653) teacher/entropy 0.0645 (0.0464) teacher/usage_max 0.4340 (0.4521) teacher/usage_min 0.1748 (0.2211) teacher/usage_std 0.1135 (0.0986) nleep/row_max_mean 1524.6962 (1535.1528) nleep/row_max_std 58.4069 (59.0873) nleep/row_min_mean 1495.7207 (1503.8125) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [140/181] time 0.089 (0.149) data 0.000 (0.003) loss 1.7595 (1.7822) teacher_loss 0.1934 (0.1616) loss_zs_kd 0.0615 (0.0509) loss_oracle 0.6482 (0.7099) kd_loss 1.2112 (1.2401) acc 90.6250 (94.3527) gate/entropy 0.9843 (0.9842) gate/usage_max 0.5670 (0.5671) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1652 (0.1653) teacher/entropy 0.0149 (0.0441) teacher/usage_max 0.4372 (0.4521) teacher/usage_min 0.2480 (0.2208) teacher/usage_std 0.0784 (0.0985) nleep/row_max_mean 1527.9636 (1534.7941) nleep/row_max_std 53.0289 (59.0047) nleep/row_min_mean 1493.5762 (1503.4888) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [160/181] time 0.156 (0.144) data 0.000 (0.002) loss 2.0202 (1.7800) teacher_loss 0.2654 (0.1603) loss_zs_kd 0.0778 (0.0500) loss_oracle 0.7985 (0.7111) kd_loss 1.3166 (1.2392) acc 84.3750 (94.3750) gate/entropy 0.9842 (0.9842) gate/usage_max 0.5671 (0.5671) gate/usage_min 0.2154 (0.2154) gate/usage_std 0.1653 (0.1653) teacher/entropy 0.0017 (0.0438) teacher/usage_max 0.4997 (0.4523) teacher/usage_min 0.2188 (0.2229) teacher/usage_std 0.1204 (0.0977) nleep/row_max_mean 1540.6912 (1534.7006) nleep/row_max_std 54.8732 (58.4188) nleep/row_min_mean 1505.5874 (1503.2882) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [180/181] time 0.078 (0.139) data 0.000 (0.002) loss 1.5865 (1.7787) teacher_loss 0.0868 (0.1591) loss_zs_kd 0.0392 (0.0498) loss_oracle 0.5912 (0.7109) kd_loss 1.1844 (1.2393) acc 96.8750 (94.4618) gate/entropy 0.9845 (0.9842) gate/usage_max 0.5667 (0.5671) gate/usage_min 0.2155 (0.2154) gate/usage_std 0.1650 (0.1653) teacher/entropy 0.0461 (0.0444) teacher/usage_max 0.4462 (0.4495) teacher/usage_min 0.2426 (0.2232) teacher/usage_std 0.0846 (0.0965) nleep/row_max_mean 1523.1335 (1534.4402) nleep/row_max_std 65.3889 (58.0301) nleep/row_min_mean 1490.4131 (1503.0849) lr 7.8853e-06 eta 0:00:00
Evaluate on the *val* set
=> result
* total: 2,497
* correct: 2,413
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 97.1%
Evaluate on the *test* set
=> result
* total: 1,670
* correct: 1,666
* accuracy: 99.8%
* error: 0.2%
* macro_f1: 99.8%
******* Domain p best val acc:      97.1%, epoch: 30 *******
******* Domain p best val test acc: 99.7%, epoch: 30 *******
******* Domain p best test acc:     99.9%, epoch: 1 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/p/seed_3/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:24:47

Loading trainer: TRIP
Loading dataset: SPG_PACS
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------------------------------
Dataset    SPG_PACS
Source     ['art_painting', 'cartoon', 'photo']
Target     ['sketch']
# classes  7
# train_x  4,241
# val      1,821
# test     3,928
---------  ------------------------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
=== Trainable Parameters by Module ===
prompt_learner.0.ctx                               2,048
prompt_learner.1.ctx                               2,048
prompt_learner.2.ctx                               2,048
gate.mlp.0.weight                                  65,536
gate.mlp.0.bias                                    128
gate.mlp.2.weight                                  384
gate.mlp.2.bias                                    3
Total trainable params: 72,195
[Info] Hyperparameters saved to: icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/hyperparameters.json
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/tensorboard)
epoch [1/50] batch [20/132] time 0.119 (0.149) data 0.000 (0.023) loss 0.7492 (0.7953) teacher_loss 0.2732 (0.2682) loss_zs_kd 0.0000 (0.0000) loss_oracle -0.0000 (-0.0001) kd_loss 0.4760 (0.5272) acc 90.6250 (90.9375) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3375 (0.3374) gate/usage_min 0.3297 (0.3298) gate/usage_std 0.0032 (0.0031) teacher/entropy 0.6236 (0.5725) teacher/usage_max 0.3996 (0.4142) teacher/usage_min 0.2620 (0.2423) teacher/usage_std 0.0563 (0.0735) nleep/row_max_mean 1546.1920 (1526.9594) nleep/row_max_std 122.4652 (146.9229) nleep/row_min_mean 1542.8757 (1522.1291) lr 1.0000e-05 eta 0:16:23
epoch [1/50] batch [40/132] time 0.133 (0.145) data 0.000 (0.012) loss 0.4830 (0.7239) teacher_loss 0.1365 (0.2638) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0002 (0.0000) kd_loss 0.3465 (0.4601) acc 96.8750 (91.6406) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3296 (0.3298) gate/usage_std 0.0032 (0.0031) teacher/entropy 0.7539 (0.6395) teacher/usage_max 0.4998 (0.4052) teacher/usage_min 0.1960 (0.2561) teacher/usage_std 0.1257 (0.0641) nleep/row_max_mean 1537.9835 (1530.9814) nleep/row_max_std 130.1073 (137.8128) nleep/row_min_mean 1535.7252 (1527.1567) lr 1.0000e-05 eta 0:15:53
epoch [1/50] batch [60/132] time 0.151 (0.144) data 0.001 (0.008) loss 0.7645 (0.6656) teacher_loss 0.4943 (0.2552) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0005 (0.0001) kd_loss 0.2699 (0.4103) acc 87.5000 (92.0833) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3373 (0.3374) gate/usage_min 0.3299 (0.3298) gate/usage_std 0.0031 (0.0031) teacher/entropy 0.8286 (0.6893) teacher/usage_max 0.3882 (0.4069) teacher/usage_min 0.2854 (0.2582) teacher/usage_std 0.0422 (0.0635) nleep/row_max_mean 1522.0234 (1531.4710) nleep/row_max_std 108.0102 (132.0312) nleep/row_min_mean 1520.1345 (1528.2132) lr 1.0000e-05 eta 0:15:44
epoch [1/50] batch [80/132] time 0.156 (0.144) data 0.000 (0.006) loss 0.5172 (0.6193) teacher_loss 0.3228 (0.2504) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0009 (0.0002) kd_loss 0.1940 (0.3687) acc 90.6250 (92.2656) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3374 (0.3374) gate/usage_min 0.3297 (0.3298) gate/usage_std 0.0031 (0.0031) teacher/entropy 0.9062 (0.7310) teacher/usage_max 0.4123 (0.4051) teacher/usage_min 0.2371 (0.2571) teacher/usage_std 0.0726 (0.0630) nleep/row_max_mean 1532.6863 (1531.7713) nleep/row_max_std 95.5407 (126.1415) nleep/row_min_mean 1531.2291 (1528.9092) lr 1.0000e-05 eta 0:15:39
epoch [1/50] batch [100/132] time 0.140 (0.146) data 0.000 (0.005) loss 0.3003 (0.5826) teacher_loss 0.1605 (0.2518) loss_zs_kd 0.0000 (0.0000) loss_oracle 0.0009 (0.0004) kd_loss 0.1393 (0.3307) acc 93.7500 (92.2188) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3373 (0.3374) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0031 (0.0031) teacher/entropy 0.9606 (0.7691) teacher/usage_max 0.4076 (0.4058) teacher/usage_min 0.2449 (0.2582) teacher/usage_std 0.0672 (0.0628) nleep/row_max_mean 1514.0208 (1532.5317) nleep/row_max_std 100.1403 (119.6708) nleep/row_min_mean 1512.9706 (1529.9778) lr 1.0000e-05 eta 0:15:49
epoch [1/50] batch [120/132] time 0.142 (0.147) data 0.000 (0.004) loss 0.2519 (0.5475) teacher_loss 0.1590 (0.2493) loss_zs_kd 0.0004 (0.0000) loss_oracle 0.0006 (0.0006) kd_loss 0.0924 (0.2979) acc 93.7500 (92.1354) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3373 (0.3374) gate/usage_min 0.3298 (0.3298) gate/usage_std 0.0031 (0.0031) teacher/entropy 1.0072 (0.8018) teacher/usage_max 0.3935 (0.4077) teacher/usage_min 0.2611 (0.2589) teacher/usage_std 0.0547 (0.0634) nleep/row_max_mean 1513.5138 (1532.9860) nleep/row_max_std 83.0508 (113.2199) nleep/row_min_mean 1512.6472 (1530.6731) lr 1.0000e-05 eta 0:15:50
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,800
* accuracy: 98.8%
* error: 1.2%
* macro_f1: 98.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,474
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 90.7%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      98.8%, epoch: 1 *******
******* Domain s best val test acc: 88.4%, epoch: 1 *******
******* Domain s best test acc:     88.4%, epoch: 1 *******
epoch [2/50] batch [20/132] time 0.104 (0.110) data 0.000 (0.015) loss 0.5677 (0.4299) teacher_loss 0.3322 (0.2124) loss_zs_kd 0.0017 (0.0016) loss_oracle 0.0265 (0.0289) kd_loss 0.2214 (0.2023) acc 87.5000 (93.4375) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3364 (0.3369) gate/usage_min 0.3296 (0.3297) gate/usage_std 0.0028 (0.0030) teacher/entropy 0.8768 (0.8969) teacher/usage_max 0.5697 (0.5108) teacher/usage_min 0.2049 (0.2146) teacher/usage_std 0.1673 (0.1294) nleep/row_max_mean 1523.9797 (1545.3822) nleep/row_max_std 69.6985 (67.8800) nleep/row_min_mean 1522.4661 (1543.9880) lr 2.0000e-03 eta 0:11:47
epoch [2/50] batch [40/132] time 0.091 (0.114) data 0.000 (0.007) loss 0.8093 (0.5434) teacher_loss 0.1401 (0.2198) loss_zs_kd 0.0123 (0.0023) loss_oracle 0.1733 (0.0711) kd_loss 0.5764 (0.2869) acc 96.8750 (92.8906) gate/entropy 1.0986 (1.0986) gate/usage_max 0.3366 (0.3365) gate/usage_min 0.3285 (0.3294) gate/usage_std 0.0035 (0.0030) teacher/entropy 0.5158 (0.8109) teacher/usage_max 0.7670 (0.5766) teacher/usage_min 0.1162 (0.1835) teacher/usage_std 0.3067 (0.1748) nleep/row_max_mean 1556.5718 (1549.7791) nleep/row_max_std 58.4079 (64.3852) nleep/row_min_mean 1553.1936 (1547.9852) lr 2.0000e-03 eta 0:12:13
epoch [2/50] batch [60/132] time 0.099 (0.119) data 0.000 (0.005) loss 0.9324 (0.6327) teacher_loss 0.2708 (0.2042) loss_zs_kd 0.0031 (0.0026) loss_oracle 0.1983 (0.1085) kd_loss 0.5608 (0.3729) acc 90.6250 (93.3333) gate/entropy 1.0985 (1.0986) gate/usage_max 0.3399 (0.3370) gate/usage_min 0.3270 (0.3289) gate/usage_std 0.0052 (0.0034) teacher/entropy 0.5281 (0.7226) teacher/usage_max 0.6998 (0.6227) teacher/usage_min 0.1105 (0.1615) teacher/usage_std 0.2611 (0.2069) nleep/row_max_mean 1547.8096 (1551.3623) nleep/row_max_std 53.5560 (61.7232) nleep/row_min_mean 1543.7462 (1549.0198) lr 2.0000e-03 eta 0:12:43
epoch [2/50] batch [80/132] time 0.177 (0.119) data 0.000 (0.004) loss 1.0886 (0.7338) teacher_loss 0.1474 (0.2027) loss_zs_kd 0.0061 (0.0029) loss_oracle 0.2535 (0.1470) kd_loss 0.8114 (0.4562) acc 96.8750 (93.2422) gate/entropy 1.0983 (1.0985) gate/usage_max 0.3448 (0.3383) gate/usage_min 0.3248 (0.3282) gate/usage_std 0.0084 (0.0043) teacher/entropy 0.2596 (0.6355) teacher/usage_max 0.8849 (0.6711) teacher/usage_min 0.0332 (0.1377) teacher/usage_std 0.3905 (0.2408) nleep/row_max_mean 1578.8639 (1554.0298) nleep/row_max_std 49.3525 (58.6806) nleep/row_min_mean 1572.2361 (1550.9536) lr 2.0000e-03 eta 0:12:41
epoch [2/50] batch [100/132] time 0.097 (0.117) data 0.000 (0.003) loss 1.1714 (0.8046) teacher_loss 0.2449 (0.2043) loss_zs_kd 0.0003 (0.0031) loss_oracle 0.2251 (0.1672) kd_loss 0.8138 (0.5151) acc 93.7500 (93.1250) gate/entropy 1.0979 (1.0984) gate/usage_max 0.3503 (0.3402) gate/usage_min 0.3224 (0.3272) gate/usage_std 0.0122 (0.0055) teacher/entropy 0.2510 (0.5718) teacher/usage_max 0.7895 (0.7007) teacher/usage_min 0.1051 (0.1231) teacher/usage_std 0.3226 (0.2615) nleep/row_max_mean 1546.6948 (1555.1154) nleep/row_max_std 39.7673 (55.8088) nleep/row_min_mean 1538.9934 (1551.3663) lr 2.0000e-03 eta 0:12:27
epoch [2/50] batch [120/132] time 0.073 (0.115) data 0.000 (0.003) loss 1.1823 (0.8553) teacher_loss 0.2408 (0.2031) loss_zs_kd 0.0066 (0.0033) loss_oracle 0.2464 (0.1917) kd_loss 0.8150 (0.5547) acc 87.5000 (93.1250) gate/entropy 1.0975 (1.0983) gate/usage_max 0.3560 (0.3425) gate/usage_min 0.3198 (0.3262) gate/usage_std 0.0161 (0.0070) teacher/entropy 0.2323 (0.5274) teacher/usage_max 0.8605 (0.7172) teacher/usage_min 0.0287 (0.1149) teacher/usage_std 0.3743 (0.2730) nleep/row_max_mean 1560.1279 (1556.3630) nleep/row_max_std 45.6102 (54.1593) nleep/row_min_mean 1552.6023 (1551.9911) lr 2.0000e-03 eta 0:12:10
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,519
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 92.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.2%, epoch: 2 *******
******* Domain s best val test acc: 89.6%, epoch: 2 *******
******* Domain s best test acc:     89.6%, epoch: 2 *******
epoch [3/50] batch [20/132] time 0.147 (0.168) data 0.000 (0.013) loss 1.3387 (1.1103) teacher_loss 0.3200 (0.1840) loss_zs_kd 0.0113 (0.0054) loss_oracle 0.4916 (0.4142) kd_loss 0.7672 (0.7165) acc 87.5000 (93.7500) gate/entropy 1.0966 (1.0969) gate/usage_max 0.3634 (0.3613) gate/usage_min 0.3169 (0.3177) gate/usage_std 0.0213 (0.0198) teacher/entropy 0.2797 (0.3433) teacher/usage_max 0.7392 (0.6661) teacher/usage_min 0.0681 (0.0977) teacher/usage_std 0.2914 (0.2438) nleep/row_max_mean 1547.3733 (1561.8357) nleep/row_max_std 41.1656 (43.5014) nleep/row_min_mean 1539.2083 (1554.3942) lr 1.9980e-03 eta 0:17:42
epoch [3/50] batch [40/132] time 0.158 (0.158) data 0.000 (0.007) loss 1.1549 (1.1374) teacher_loss 0.1348 (0.1843) loss_zs_kd 0.0019 (0.0059) loss_oracle 0.3957 (0.4296) kd_loss 0.8213 (0.7354) acc 93.7500 (93.3594) gate/entropy 1.0959 (1.0966) gate/usage_max 0.3685 (0.3636) gate/usage_min 0.3149 (0.3168) gate/usage_std 0.0249 (0.0215) teacher/entropy 0.2249 (0.3210) teacher/usage_max 0.6895 (0.6676) teacher/usage_min 0.0875 (0.0980) teacher/usage_std 0.2579 (0.2454) nleep/row_max_mean 1564.3218 (1559.4411) nleep/row_max_std 26.0027 (41.6938) nleep/row_min_mean 1556.0535 (1551.4217) lr 1.9980e-03 eta 0:16:36
epoch [3/50] batch [60/132] time 0.141 (0.155) data 0.000 (0.004) loss 1.0528 (1.1475) teacher_loss 0.0734 (0.1851) loss_zs_kd 0.0039 (0.0065) loss_oracle 0.3565 (0.4269) kd_loss 0.7992 (0.7457) acc 96.8750 (93.1771) gate/entropy 1.0952 (1.0962) gate/usage_max 0.3724 (0.3659) gate/usage_min 0.3136 (0.3160) gate/usage_std 0.0276 (0.0231) teacher/entropy 0.2591 (0.3080) teacher/usage_max 0.5831 (0.6652) teacher/usage_min 0.1552 (0.1031) teacher/usage_std 0.1819 (0.2429) nleep/row_max_mean 1560.0715 (1558.4762) nleep/row_max_std 42.7783 (40.9509) nleep/row_min_mean 1551.6907 (1550.0190) lr 1.9980e-03 eta 0:16:10
epoch [3/50] batch [80/132] time 0.146 (0.153) data 0.000 (0.003) loss 1.2577 (1.1540) teacher_loss 0.2513 (0.1826) loss_zs_kd 0.0114 (0.0069) loss_oracle 0.4719 (0.4268) kd_loss 0.7647 (0.7545) acc 90.6250 (93.5938) gate/entropy 1.0945 (1.0959) gate/usage_max 0.3764 (0.3681) gate/usage_min 0.3117 (0.3151) gate/usage_std 0.0305 (0.0246) teacher/entropy 0.2818 (0.2973) teacher/usage_max 0.6288 (0.6599) teacher/usage_min 0.1404 (0.1148) teacher/usage_std 0.2121 (0.2376) nleep/row_max_mean 1563.6179 (1558.4700) nleep/row_max_std 35.4416 (40.7403) nleep/row_min_mean 1552.3250 (1549.6593) lr 1.9980e-03 eta 0:15:56
epoch [3/50] batch [100/132] time 0.154 (0.149) data 0.000 (0.003) loss 1.1803 (1.1642) teacher_loss 0.1415 (0.1809) loss_zs_kd 0.0040 (0.0067) loss_oracle 0.6148 (0.4502) kd_loss 0.7293 (0.7549) acc 93.7500 (93.7812) gate/entropy 1.0937 (1.0955) gate/usage_max 0.3804 (0.3702) gate/usage_min 0.3096 (0.3142) gate/usage_std 0.0333 (0.0261) teacher/entropy 0.3095 (0.2956) teacher/usage_max 0.6445 (0.6530) teacher/usage_min 0.1577 (0.1223) teacher/usage_std 0.2206 (0.2321) nleep/row_max_mean 1553.7295 (1557.3902) nleep/row_max_std 42.6480 (41.1513) nleep/row_min_mean 1544.1958 (1548.3246) lr 1.9980e-03 eta 0:15:32
epoch [3/50] batch [120/132] time 0.140 (0.150) data 0.000 (0.002) loss 1.1939 (1.1852) teacher_loss 0.0896 (0.1812) loss_zs_kd 0.0056 (0.0069) loss_oracle 0.5427 (0.4692) kd_loss 0.8302 (0.7659) acc 96.8750 (93.8021) gate/entropy 1.0927 (1.0951) gate/usage_max 0.3854 (0.3723) gate/usage_min 0.3073 (0.3133) gate/usage_std 0.0368 (0.0276) teacher/entropy 0.2246 (0.2829) teacher/usage_max 0.5486 (0.6483) teacher/usage_min 0.1528 (0.1272) teacher/usage_std 0.1635 (0.2283) nleep/row_max_mean 1550.3708 (1557.3082) nleep/row_max_std 59.6131 (41.7919) nleep/row_min_mean 1540.1917 (1547.7636) lr 1.9980e-03 eta 0:15:32
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,805
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,525
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 92.0%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.2%, epoch: 2 *******
******* Domain s best val test acc: 89.6%, epoch: 2 *******
******* Domain s best test acc:     89.7%, epoch: 3 *******
epoch [4/50] batch [20/132] time 0.181 (0.128) data 0.000 (0.017) loss 1.2596 (1.2404) teacher_loss 0.1250 (0.1320) loss_zs_kd 0.0041 (0.0076) loss_oracle 0.5459 (0.5703) kd_loss 0.8596 (0.8194) acc 93.7500 (95.4688) gate/entropy 1.0907 (1.0913) gate/usage_max 0.3936 (0.3910) gate/usage_min 0.3026 (0.3041) gate/usage_std 0.0426 (0.0408) teacher/entropy 0.1418 (0.2105) teacher/usage_max 0.7318 (0.6342) teacher/usage_min 0.0645 (0.1345) teacher/usage_std 0.2875 (0.2184) nleep/row_max_mean 1562.9724 (1556.0497) nleep/row_max_std 48.2855 (48.3461) nleep/row_min_mean 1547.8806 (1542.8108) lr 1.9921e-03 eta 0:13:12
epoch [4/50] batch [40/132] time 0.073 (0.124) data 0.000 (0.009) loss 1.1775 (1.2640) teacher_loss 0.0761 (0.1534) loss_zs_kd 0.0084 (0.0081) loss_oracle 0.4545 (0.5392) kd_loss 0.8700 (0.8370) acc 96.8750 (94.6875) gate/entropy 1.0896 (1.0907) gate/usage_max 0.3975 (0.3933) gate/usage_min 0.2998 (0.3026) gate/usage_std 0.0454 (0.0424) teacher/entropy 0.1721 (0.1934) teacher/usage_max 0.5633 (0.6234) teacher/usage_min 0.1287 (0.1210) teacher/usage_std 0.1783 (0.2182) nleep/row_max_mean 1562.5215 (1552.1872) nleep/row_max_std 31.6683 (49.2109) nleep/row_min_mean 1549.5648 (1538.6594) lr 1.9921e-03 eta 0:12:43
epoch [4/50] batch [60/132] time 0.218 (0.120) data 0.001 (0.006) loss 1.3760 (1.2886) teacher_loss 0.1576 (0.1604) loss_zs_kd 0.0062 (0.0099) loss_oracle 0.6879 (0.5353) kd_loss 0.8714 (0.8555) acc 93.7500 (94.8438) gate/entropy 1.0888 (1.0902) gate/usage_max 0.4004 (0.3952) gate/usage_min 0.2975 (0.3013) gate/usage_std 0.0475 (0.0438) teacher/entropy 0.1798 (0.1798) teacher/usage_max 0.5204 (0.6003) teacher/usage_min 0.0629 (0.1198) teacher/usage_std 0.1959 (0.2066) nleep/row_max_mean 1537.2566 (1550.8702) nleep/row_max_std 58.8754 (48.8334) nleep/row_min_mean 1524.0103 (1536.9504) lr 1.9921e-03 eta 0:12:16
epoch [4/50] batch [80/132] time 0.176 (0.119) data 0.000 (0.004) loss 1.2836 (1.3153) teacher_loss 0.1313 (0.1541) loss_zs_kd 0.0000 (0.0098) loss_oracle 0.4657 (0.5615) kd_loss 0.9195 (0.8755) acc 96.8750 (94.8828) gate/entropy 1.0879 (1.0897) gate/usage_max 0.4031 (0.3969) gate/usage_min 0.2942 (0.2999) gate/usage_std 0.0494 (0.0450) teacher/entropy 0.1159 (0.1605) teacher/usage_max 0.5545 (0.5900) teacher/usage_min 0.0077 (0.0969) teacher/usage_std 0.2351 (0.2123) nleep/row_max_mean 1555.7766 (1550.8827) nleep/row_max_std 45.8773 (47.8414) nleep/row_min_mean 1537.1956 (1536.0510) lr 1.9921e-03 eta 0:12:10
epoch [4/50] batch [100/132] time 0.095 (0.121) data 0.000 (0.004) loss 1.3721 (1.3203) teacher_loss 0.2224 (0.1555) loss_zs_kd 0.0004 (0.0095) loss_oracle 0.5366 (0.5600) kd_loss 0.8812 (0.8801) acc 96.8750 (94.9375) gate/entropy 1.0868 (1.0893) gate/usage_max 0.4064 (0.3985) gate/usage_min 0.2907 (0.2984) gate/usage_std 0.0519 (0.0461) teacher/entropy 0.1322 (0.1519) teacher/usage_max 0.6182 (0.5951) teacher/usage_min 0.0386 (0.0812) teacher/usage_std 0.2367 (0.2197) nleep/row_max_mean 1544.6084 (1550.1862) nleep/row_max_std 62.3260 (48.2013) nleep/row_min_mean 1527.6611 (1534.7428) lr 1.9921e-03 eta 0:12:16
epoch [4/50] batch [120/132] time 0.156 (0.122) data 0.000 (0.003) loss 1.5234 (1.3235) teacher_loss 0.2805 (0.1574) loss_zs_kd 0.0120 (0.0091) loss_oracle 0.6188 (0.5626) kd_loss 0.9274 (0.8803) acc 90.6250 (94.7656) gate/entropy 1.0857 (1.0887) gate/usage_max 0.4097 (0.4001) gate/usage_min 0.2871 (0.2968) gate/usage_std 0.0544 (0.0473) teacher/entropy 0.0365 (0.1498) teacher/usage_max 0.7593 (0.5944) teacher/usage_min 0.0008 (0.0774) teacher/usage_std 0.3166 (0.2207) nleep/row_max_mean 1557.8367 (1549.2531) nleep/row_max_std 44.5127 (48.2077) nleep/row_min_mean 1537.2407 (1533.6130) lr 1.9921e-03 eta 0:12:21
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,805
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,523
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 91.5%
******* Domain s best val acc:      99.2%, epoch: 2 *******
******* Domain s best val test acc: 89.6%, epoch: 2 *******
******* Domain s best test acc:     89.7%, epoch: 3 *******
epoch [5/50] batch [20/132] time 0.182 (0.165) data 0.000 (0.014) loss 1.3922 (1.3941) teacher_loss 0.1063 (0.2013) loss_zs_kd 0.0133 (0.0081) loss_oracle 0.6450 (0.5794) kd_loss 0.9567 (0.8991) acc 96.8750 (93.5938) gate/entropy 1.0843 (1.0848) gate/usage_max 0.4131 (0.4120) gate/usage_min 0.2822 (0.2837) gate/usage_std 0.0572 (0.0563) teacher/entropy 0.0596 (0.1219) teacher/usage_max 0.5635 (0.5737) teacher/usage_min 0.0068 (0.0424) teacher/usage_std 0.2373 (0.2250) nleep/row_max_mean 1553.3306 (1547.2365) nleep/row_max_std 35.2838 (46.0947) nleep/row_min_mean 1533.2336 (1528.9054) lr 1.9823e-03 eta 0:16:38
epoch [5/50] batch [40/132] time 0.163 (0.162) data 0.000 (0.007) loss 1.3871 (1.3846) teacher_loss 0.2523 (0.1857) loss_zs_kd 0.0110 (0.0092) loss_oracle 0.5831 (0.5998) kd_loss 0.8378 (0.8944) acc 93.7500 (93.9844) gate/entropy 1.0833 (1.0843) gate/usage_max 0.4157 (0.4131) gate/usage_min 0.2789 (0.2821) gate/usage_std 0.0592 (0.0572) teacher/entropy 0.1563 (0.1172) teacher/usage_max 0.6376 (0.5968) teacher/usage_min 0.0620 (0.0381) teacher/usage_std 0.2361 (0.2344) nleep/row_max_mean 1556.1975 (1550.2031) nleep/row_max_std 40.0814 (43.5160) nleep/row_min_mean 1536.2048 (1531.1083) lr 1.9823e-03 eta 0:16:19
epoch [5/50] batch [60/132] time 0.139 (0.165) data 0.000 (0.005) loss 1.4903 (1.3858) teacher_loss 0.2367 (0.1821) loss_zs_kd 0.0077 (0.0081) loss_oracle 0.7175 (0.6174) kd_loss 0.8910 (0.8909) acc 90.6250 (93.9583) gate/entropy 1.0820 (1.0838) gate/usage_max 0.4187 (0.4145) gate/usage_min 0.2758 (0.2805) gate/usage_std 0.0615 (0.0583) teacher/entropy 0.0985 (0.1170) teacher/usage_max 0.6220 (0.6056) teacher/usage_min 0.0029 (0.0419) teacher/usage_std 0.2545 (0.2361) nleep/row_max_mean 1547.9451 (1550.5276) nleep/row_max_std 37.8862 (43.0934) nleep/row_min_mean 1526.9194 (1531.1349) lr 1.9823e-03 eta 0:16:31
epoch [5/50] batch [80/132] time 0.195 (0.166) data 0.000 (0.004) loss 1.2315 (1.3656) teacher_loss 0.1470 (0.1753) loss_zs_kd 0.0069 (0.0076) loss_oracle 0.5614 (0.6109) kd_loss 0.8003 (0.8811) acc 93.7500 (94.2188) gate/entropy 1.0808 (1.0832) gate/usage_max 0.4216 (0.4159) gate/usage_min 0.2729 (0.2789) gate/usage_std 0.0638 (0.0594) teacher/entropy 0.2222 (0.1234) teacher/usage_max 0.5138 (0.6083) teacher/usage_min 0.0315 (0.0452) teacher/usage_std 0.2148 (0.2360) nleep/row_max_mean 1547.0172 (1550.4375) nleep/row_max_std 54.4686 (44.3453) nleep/row_min_mean 1530.1570 (1531.0235) lr 1.9823e-03 eta 0:16:33
epoch [5/50] batch [100/132] time 0.115 (0.158) data 0.001 (0.003) loss 1.1524 (1.3460) teacher_loss 0.0799 (0.1665) loss_zs_kd 0.0035 (0.0072) loss_oracle 0.5626 (0.6014) kd_loss 0.7895 (0.8751) acc 100.0000 (94.4688) gate/entropy 1.0792 (1.0825) gate/usage_max 0.4253 (0.4174) gate/usage_min 0.2694 (0.2774) gate/usage_std 0.0667 (0.0606) teacher/entropy 0.1187 (0.1222) teacher/usage_max 0.8385 (0.6221) teacher/usage_min 0.0019 (0.0444) teacher/usage_std 0.3630 (0.2422) nleep/row_max_mean 1564.5569 (1551.5257) nleep/row_max_std 42.6449 (44.3882) nleep/row_min_mean 1541.5591 (1531.7839) lr 1.9823e-03 eta 0:15:44
epoch [5/50] batch [120/132] time 0.065 (0.152) data 0.000 (0.003) loss 1.2099 (1.3380) teacher_loss 0.0811 (0.1633) loss_zs_kd 0.0185 (0.0073) loss_oracle 0.5746 (0.5983) kd_loss 0.8322 (0.8718) acc 100.0000 (94.6354) gate/entropy 1.0777 (1.0819) gate/usage_max 0.4285 (0.4190) gate/usage_min 0.2664 (0.2758) gate/usage_std 0.0691 (0.0618) teacher/entropy 0.1152 (0.1206) teacher/usage_max 0.7029 (0.6282) teacher/usage_min 0.0005 (0.0413) teacher/usage_std 0.2879 (0.2458) nleep/row_max_mean 1553.2021 (1552.2094) nleep/row_max_std 48.9927 (44.6524) nleep/row_min_mean 1530.2604 (1531.9545) lr 1.9823e-03 eta 0:15:02
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,553
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 92.1%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.2%, epoch: 2 *******
******* Domain s best val test acc: 89.6%, epoch: 2 *******
******* Domain s best test acc:     90.5%, epoch: 5 *******
epoch [6/50] batch [20/132] time 0.161 (0.121) data 0.000 (0.013) loss 1.3184 (1.2933) teacher_loss 0.0924 (0.1330) loss_zs_kd 0.0149 (0.0059) loss_oracle 0.6114 (0.5934) kd_loss 0.9129 (0.8607) acc 96.8750 (95.3125) gate/entropy 1.0755 (1.0761) gate/usage_max 0.4329 (0.4317) gate/usage_min 0.2614 (0.2630) gate/usage_std 0.0727 (0.0717) teacher/entropy 0.0724 (0.1166) teacher/usage_max 0.5719 (0.6093) teacher/usage_min 0.0001 (0.0183) teacher/usage_std 0.2428 (0.2482) nleep/row_max_mean 1570.0022 (1557.2636) nleep/row_max_std 35.4913 (45.8753) nleep/row_min_mean 1541.3231 (1533.8370) lr 1.9686e-03 eta 0:11:57
epoch [6/50] batch [40/132] time 0.140 (0.120) data 0.000 (0.006) loss 1.4056 (1.3159) teacher_loss 0.2296 (0.1541) loss_zs_kd 0.0159 (0.0065) loss_oracle 0.5718 (0.5882) kd_loss 0.8821 (0.8645) acc 90.6250 (94.5312) gate/entropy 1.0741 (1.0755) gate/usage_max 0.4354 (0.4329) gate/usage_min 0.2583 (0.2615) gate/usage_std 0.0748 (0.0727) teacher/entropy 0.0667 (0.1071) teacher/usage_max 0.6765 (0.6217) teacher/usage_min 0.0313 (0.0125) teacher/usage_std 0.2650 (0.2545) nleep/row_max_mean 1572.0061 (1556.7018) nleep/row_max_std 36.0096 (44.8482) nleep/row_min_mean 1544.2983 (1532.2182) lr 1.9686e-03 eta 0:11:46
epoch [6/50] batch [60/132] time 0.148 (0.117) data 0.000 (0.004) loss 1.3874 (1.3135) teacher_loss 0.2416 (0.1463) loss_zs_kd 0.0020 (0.0066) loss_oracle 0.5505 (0.5905) kd_loss 0.8695 (0.8685) acc 90.6250 (94.6354) gate/entropy 1.0730 (1.0748) gate/usage_max 0.4370 (0.4340) gate/usage_min 0.2555 (0.2600) gate/usage_std 0.0763 (0.0737) teacher/entropy 0.1096 (0.1051) teacher/usage_max 0.5668 (0.6129) teacher/usage_min 0.0000 (0.0096) teacher/usage_std 0.2419 (0.2531) nleep/row_max_mean 1535.8281 (1554.2775) nleep/row_max_std 55.7809 (44.8802) nleep/row_min_mean 1511.9854 (1529.2102) lr 1.9686e-03 eta 0:11:29
epoch [6/50] batch [80/132] time 0.122 (0.123) data 0.000 (0.003) loss 1.1605 (1.3210) teacher_loss 0.1049 (0.1555) loss_zs_kd 0.0015 (0.0070) loss_oracle 0.5259 (0.5899) kd_loss 0.7919 (0.8671) acc 93.7500 (94.4922) gate/entropy 1.0717 (1.0742) gate/usage_max 0.4391 (0.4351) gate/usage_min 0.2524 (0.2584) gate/usage_std 0.0782 (0.0746) teacher/entropy 0.1715 (0.1063) teacher/usage_max 0.6128 (0.6050) teacher/usage_min 0.0190 (0.0075) teacher/usage_std 0.2437 (0.2517) nleep/row_max_mean 1551.6580 (1552.6112) nleep/row_max_std 45.2026 (44.5428) nleep/row_min_mean 1525.0723 (1527.0694) lr 1.9686e-03 eta 0:12:01
epoch [6/50] batch [100/132] time 0.163 (0.128) data 0.000 (0.003) loss 1.2764 (1.3157) teacher_loss 0.0612 (0.1471) loss_zs_kd 0.0052 (0.0067) loss_oracle 0.5978 (0.5925) kd_loss 0.9136 (0.8691) acc 96.8750 (94.8438) gate/entropy 1.0709 (1.0736) gate/usage_max 0.4400 (0.4360) gate/usage_min 0.2499 (0.2570) gate/usage_std 0.0793 (0.0754) teacher/entropy 0.0436 (0.1036) teacher/usage_max 0.6093 (0.6017) teacher/usage_min 0.0000 (0.0061) teacher/usage_std 0.2520 (0.2512) nleep/row_max_mean 1547.5776 (1551.6496) nleep/row_max_std 36.9503 (43.6764) nleep/row_min_mean 1519.6879 (1525.7162) lr 1.9686e-03 eta 0:12:28
epoch [6/50] batch [120/132] time 0.151 (0.134) data 0.000 (0.002) loss 1.5575 (1.3144) teacher_loss 0.3479 (0.1493) loss_zs_kd 0.0023 (0.0067) loss_oracle 0.5511 (0.5842) kd_loss 0.9329 (0.8697) acc 90.6250 (94.7135) gate/entropy 1.0698 (1.0730) gate/usage_max 0.4412 (0.4368) gate/usage_min 0.2471 (0.2555) gate/usage_std 0.0807 (0.0762) teacher/entropy 0.0551 (0.1009) teacher/usage_max 0.5123 (0.6007) teacher/usage_min 0.0082 (0.0052) teacher/usage_std 0.2303 (0.2514) nleep/row_max_mean 1539.8566 (1551.1754) nleep/row_max_std 42.6207 (43.0819) nleep/row_min_mean 1513.1357 (1524.7466) lr 1.9686e-03 eta 0:12:57
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,804
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.0%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,531
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 91.7%
******* Domain s best val acc:      99.2%, epoch: 2 *******
******* Domain s best val test acc: 89.6%, epoch: 2 *******
******* Domain s best test acc:     90.5%, epoch: 5 *******
epoch [7/50] batch [20/132] time 0.136 (0.152) data 0.000 (0.013) loss 1.2523 (1.2803) teacher_loss 0.1300 (0.1299) loss_zs_kd 0.0086 (0.0079) loss_oracle 0.5050 (0.5112) kd_loss 0.8655 (0.8909) acc 93.7500 (94.6875) gate/entropy 1.0681 (1.0686) gate/usage_max 0.4430 (0.4426) gate/usage_min 0.2429 (0.2441) gate/usage_std 0.0828 (0.0823) teacher/entropy 0.1263 (0.1015) teacher/usage_max 0.5197 (0.5556) teacher/usage_min 0.0000 (0.0001) teacher/usage_std 0.2362 (0.2420) nleep/row_max_mean 1555.0227 (1548.0746) nleep/row_max_std 35.6183 (39.8799) nleep/row_min_mean 1527.6307 (1520.9522) lr 1.9511e-03 eta 0:14:39
epoch [7/50] batch [40/132] time 0.145 (0.147) data 0.000 (0.006) loss 1.2389 (1.3015) teacher_loss 0.0420 (0.1285) loss_zs_kd 0.0049 (0.0069) loss_oracle 0.5375 (0.5380) kd_loss 0.9257 (0.9006) acc 100.0000 (95.0781) gate/entropy 1.0674 (1.0682) gate/usage_max 0.4434 (0.4430) gate/usage_min 0.2406 (0.2429) gate/usage_std 0.0837 (0.0828) teacher/entropy 0.0858 (0.0905) teacher/usage_max 0.5866 (0.5680) teacher/usage_min 0.0003 (0.0000) teacher/usage_std 0.2459 (0.2451) nleep/row_max_mean 1546.9144 (1548.0188) nleep/row_max_std 41.3334 (40.0545) nleep/row_min_mean 1521.1663 (1520.2955) lr 1.9511e-03 eta 0:14:05
epoch [7/50] batch [60/132] time 0.089 (0.135) data 0.000 (0.004) loss 1.3079 (1.3371) teacher_loss 0.1060 (0.1600) loss_zs_kd 0.0068 (0.0069) loss_oracle 0.5410 (0.5428) kd_loss 0.9281 (0.9022) acc 96.8750 (94.3750) gate/entropy 1.0667 (1.0678) gate/usage_max 0.4434 (0.4432) gate/usage_min 0.2382 (0.2417) gate/usage_std 0.0844 (0.0833) teacher/entropy 0.0556 (0.0900) teacher/usage_max 0.5184 (0.5763) teacher/usage_min 0.0000 (0.0005) teacher/usage_std 0.2362 (0.2471) nleep/row_max_mean 1550.7278 (1548.9183) nleep/row_max_std 34.6130 (40.6420) nleep/row_min_mean 1524.1707 (1521.1387) lr 1.9511e-03 eta 0:12:53
epoch [7/50] batch [80/132] time 0.086 (0.127) data 0.000 (0.003) loss 1.4398 (1.3365) teacher_loss 0.2780 (0.1657) loss_zs_kd 0.0180 (0.0069) loss_oracle 0.5079 (0.5452) kd_loss 0.8988 (0.8947) acc 87.5000 (94.1797) gate/entropy 1.0660 (1.0674) gate/usage_max 0.4436 (0.4433) gate/usage_min 0.2360 (0.2405) gate/usage_std 0.0852 (0.0837) teacher/entropy 0.0982 (0.0941) teacher/usage_max 0.5513 (0.5760) teacher/usage_min 0.0085 (0.0009) teacher/usage_std 0.2341 (0.2466) nleep/row_max_mean 1535.5981 (1549.3905) nleep/row_max_std 45.3630 (41.2415) nleep/row_min_mean 1511.7837 (1521.9232) lr 1.9511e-03 eta 0:12:09
epoch [7/50] batch [100/132] time 0.089 (0.123) data 0.000 (0.003) loss 1.3359 (1.3417) teacher_loss 0.2014 (0.1737) loss_zs_kd 0.0002 (0.0065) loss_oracle 0.5443 (0.5469) kd_loss 0.8623 (0.8913) acc 90.6250 (94.0000) gate/entropy 1.0649 (1.0670) gate/usage_max 0.4446 (0.4435) gate/usage_min 0.2334 (0.2393) gate/usage_std 0.0866 (0.0842) teacher/entropy 0.0910 (0.0931) teacher/usage_max 0.5544 (0.5713) teacher/usage_min 0.0000 (0.0016) teacher/usage_std 0.2398 (0.2451) nleep/row_max_mean 1558.7891 (1549.5319) nleep/row_max_std 34.1156 (41.5578) nleep/row_min_mean 1528.8544 (1522.1005) lr 1.9511e-03 eta 0:11:39
epoch [7/50] batch [120/132] time 0.159 (0.124) data 0.000 (0.002) loss 1.3517 (1.3286) teacher_loss 0.3289 (0.1704) loss_zs_kd 0.0076 (0.0066) loss_oracle 0.4887 (0.5456) kd_loss 0.7746 (0.8822) acc 90.6250 (94.1146) gate/entropy 1.0641 (1.0665) gate/usage_max 0.4451 (0.4437) gate/usage_min 0.2316 (0.2381) gate/usage_std 0.0874 (0.0847) teacher/entropy 0.1322 (0.0971) teacher/usage_max 0.6941 (0.5739) teacher/usage_min 0.0008 (0.0021) teacher/usage_std 0.2838 (0.2455) nleep/row_max_mean 1543.5315 (1549.4050) nleep/row_max_std 43.2363 (41.8712) nleep/row_min_mean 1519.2820 (1522.1180) lr 1.9511e-03 eta 0:11:46
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,551
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.7%
******* Domain s best val acc:      99.2%, epoch: 7 *******
******* Domain s best val test acc: 90.4%, epoch: 7 *******
******* Domain s best test acc:     90.5%, epoch: 5 *******
epoch [8/50] batch [20/132] time 0.099 (0.121) data 0.000 (0.013) loss 1.1075 (1.2538) teacher_loss 0.0701 (0.1372) loss_zs_kd 0.0057 (0.0072) loss_oracle 0.5066 (0.5388) kd_loss 0.7812 (0.8436) acc 96.8750 (95.6250) gate/entropy 1.0622 (1.0628) gate/usage_max 0.4475 (0.4468) gate/usage_min 0.2284 (0.2292) gate/usage_std 0.0897 (0.0891) teacher/entropy 0.1815 (0.0991) teacher/usage_max 0.5356 (0.5925) teacher/usage_min 0.0267 (0.0131) teacher/usage_std 0.2205 (0.2453) nleep/row_max_mean 1550.7771 (1549.7318) nleep/row_max_std 39.4757 (42.9906) nleep/row_min_mean 1526.6685 (1524.6909) lr 1.9298e-03 eta 0:11:27
epoch [8/50] batch [40/132] time 0.164 (0.128) data 0.000 (0.007) loss 1.4198 (1.2923) teacher_loss 0.3420 (0.1856) loss_zs_kd 0.0055 (0.0065) loss_oracle 0.4863 (0.5452) kd_loss 0.8318 (0.8308) acc 93.7500 (94.2188) gate/entropy 1.0612 (1.0622) gate/usage_max 0.4492 (0.4476) gate/usage_min 0.2270 (0.2284) gate/usage_std 0.0910 (0.0897) teacher/entropy 0.0979 (0.1063) teacher/usage_max 0.6033 (0.6068) teacher/usage_min 0.0021 (0.0167) teacher/usage_std 0.2492 (0.2485) nleep/row_max_mean 1548.1501 (1548.1949) nleep/row_max_std 42.0872 (42.4367) nleep/row_min_mean 1525.2627 (1524.1941) lr 1.9298e-03 eta 0:11:59
epoch [8/50] batch [60/132] time 0.160 (0.135) data 0.000 (0.004) loss 1.1609 (1.2847) teacher_loss 0.0624 (0.1807) loss_zs_kd 0.0088 (0.0069) loss_oracle 0.5584 (0.5446) kd_loss 0.8149 (0.8282) acc 100.0000 (94.6875) gate/entropy 1.0602 (1.0617) gate/usage_max 0.4509 (0.4485) gate/usage_min 0.2256 (0.2276) gate/usage_std 0.0922 (0.0904) teacher/entropy 0.1428 (0.1059) teacher/usage_max 0.5664 (0.6176) teacher/usage_min 0.0521 (0.0182) teacher/usage_std 0.2127 (0.2516) nleep/row_max_mean 1555.6543 (1548.2035) nleep/row_max_std 29.4449 (40.9004) nleep/row_min_mean 1534.0701 (1524.4349) lr 1.9298e-03 eta 0:12:39
epoch [8/50] batch [80/132] time 0.135 (0.142) data 0.000 (0.003) loss 1.3284 (1.2698) teacher_loss 0.1517 (0.1687) loss_zs_kd 0.0093 (0.0066) loss_oracle 0.6464 (0.5475) kd_loss 0.8489 (0.8240) acc 96.8750 (94.8438) gate/entropy 1.0587 (1.0611) gate/usage_max 0.4535 (0.4494) gate/usage_min 0.2240 (0.2269) gate/usage_std 0.0940 (0.0911) teacher/entropy 0.0394 (0.1017) teacher/usage_max 0.7404 (0.6386) teacher/usage_min 0.0283 (0.0191) teacher/usage_std 0.2996 (0.2595) nleep/row_max_mean 1546.9797 (1547.6841) nleep/row_max_std 38.0663 (40.5966) nleep/row_min_mean 1520.0059 (1523.9703) lr 1.9298e-03 eta 0:13:13
epoch [8/50] batch [100/132] time 0.140 (0.146) data 0.000 (0.003) loss 1.4702 (1.2643) teacher_loss 0.3869 (0.1663) loss_zs_kd 0.0063 (0.0065) loss_oracle 0.5487 (0.5505) kd_loss 0.8058 (0.8195) acc 84.3750 (94.8438) gate/entropy 1.0570 (1.0604) gate/usage_max 0.4568 (0.4506) gate/usage_min 0.2226 (0.2262) gate/usage_std 0.0960 (0.0919) teacher/entropy 0.0423 (0.0962) teacher/usage_max 0.8279 (0.6635) teacher/usage_min 0.0120 (0.0191) teacher/usage_std 0.3549 (0.2710) nleep/row_max_mean 1547.0321 (1547.2205) nleep/row_max_std 45.5823 (40.9641) nleep/row_min_mean 1523.9354 (1523.4097) lr 1.9298e-03 eta 0:13:36
epoch [8/50] batch [120/132] time 0.149 (0.148) data 0.000 (0.002) loss 1.3239 (1.2603) teacher_loss 0.2664 (0.1676) loss_zs_kd 0.0044 (0.0063) loss_oracle 0.5755 (0.5521) kd_loss 0.7676 (0.8135) acc 90.6250 (94.7656) gate/entropy 1.0551 (1.0597) gate/usage_max 0.4608 (0.4519) gate/usage_min 0.2213 (0.2255) gate/usage_std 0.0984 (0.0928) teacher/entropy 0.0852 (0.0930) teacher/usage_max 0.7889 (0.6847) teacher/usage_min 0.0008 (0.0186) teacher/usage_std 0.3333 (0.2814) nleep/row_max_mean 1558.5144 (1547.1523) nleep/row_max_std 42.4462 (40.9722) nleep/row_min_mean 1534.7413 (1523.1588) lr 1.9298e-03 eta 0:13:41
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,550
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.1%
******* Domain s best val acc:      99.2%, epoch: 7 *******
******* Domain s best val test acc: 90.4%, epoch: 7 *******
******* Domain s best test acc:     90.5%, epoch: 5 *******
epoch [9/50] batch [20/132] time 0.088 (0.148) data 0.000 (0.015) loss 1.1083 (1.2529) teacher_loss 0.0152 (0.1763) loss_zs_kd 0.0000 (0.0066) loss_oracle 0.5934 (0.5820) kd_loss 0.7964 (0.7822) acc 100.0000 (93.7500) gate/entropy 1.0522 (1.0531) gate/usage_max 0.4672 (0.4653) gate/usage_min 0.2201 (0.2204) gate/usage_std 0.1019 (0.1009) teacher/entropy 0.0633 (0.0636) teacher/usage_max 0.8026 (0.8106) teacher/usage_min 0.0571 (0.0210) teacher/usage_std 0.3335 (0.3439) nleep/row_max_mean 1539.9414 (1550.0431) nleep/row_max_std 58.9354 (44.0358) nleep/row_min_mean 1516.0558 (1523.3085) lr 1.9048e-03 eta 0:13:38
epoch [9/50] batch [40/132] time 0.087 (0.131) data 0.000 (0.007) loss 1.2426 (1.2414) teacher_loss 0.2321 (0.1710) loss_zs_kd 0.0075 (0.0065) loss_oracle 0.5315 (0.5783) kd_loss 0.7410 (0.7780) acc 90.6250 (94.2188) gate/entropy 1.0501 (1.0521) gate/usage_max 0.4715 (0.4674) gate/usage_min 0.2191 (0.2200) gate/usage_std 0.1044 (0.1021) teacher/entropy 0.0434 (0.0631) teacher/usage_max 0.9234 (0.8118) teacher/usage_min 0.0010 (0.0160) teacher/usage_std 0.4183 (0.3457) nleep/row_max_mean 1548.4077 (1549.4346) nleep/row_max_std 43.1388 (46.3559) nleep/row_min_mean 1520.5997 (1522.4820) lr 1.9048e-03 eta 0:11:59
epoch [9/50] batch [60/132] time 0.186 (0.126) data 0.000 (0.005) loss 1.1805 (1.2418) teacher_loss 0.0824 (0.1657) loss_zs_kd 0.0058 (0.0063) loss_oracle 0.5868 (0.5830) kd_loss 0.8018 (0.7815) acc 96.8750 (94.5833) gate/entropy 1.0485 (1.0511) gate/usage_max 0.4747 (0.4694) gate/usage_min 0.2186 (0.2196) gate/usage_std 0.1062 (0.1032) teacher/entropy 0.0260 (0.0588) teacher/usage_max 0.8102 (0.8070) teacher/usage_min 0.0019 (0.0152) teacher/usage_std 0.3457 (0.3433) nleep/row_max_mean 1556.9257 (1550.2791) nleep/row_max_std 48.0568 (46.7944) nleep/row_min_mean 1527.4800 (1522.8098) lr 1.9048e-03 eta 0:11:28
epoch [9/50] batch [80/132] time 0.080 (0.127) data 0.000 (0.004) loss 1.2433 (1.2394) teacher_loss 0.1630 (0.1671) loss_zs_kd 0.0098 (0.0059) loss_oracle 0.6334 (0.5824) kd_loss 0.7587 (0.7781) acc 96.8750 (94.7266) gate/entropy 1.0459 (1.0501) gate/usage_max 0.4797 (0.4714) gate/usage_min 0.2174 (0.2192) gate/usage_std 0.1092 (0.1044) teacher/entropy 0.0313 (0.0570) teacher/usage_max 0.8990 (0.8138) teacher/usage_min 0.0311 (0.0167) teacher/usage_std 0.4003 (0.3474) nleep/row_max_mean 1561.0029 (1551.1829) nleep/row_max_std 54.2074 (47.7903) nleep/row_min_mean 1530.0054 (1523.4087) lr 1.9048e-03 eta 0:11:35
epoch [9/50] batch [100/132] time 0.088 (0.126) data 0.000 (0.003) loss 1.1994 (1.2372) teacher_loss 0.2052 (0.1687) loss_zs_kd 0.0011 (0.0060) loss_oracle 0.5694 (0.5859) kd_loss 0.7090 (0.7726) acc 90.6250 (94.5625) gate/entropy 1.0439 (1.0491) gate/usage_max 0.4836 (0.4734) gate/usage_min 0.2169 (0.2188) gate/usage_std 0.1115 (0.1055) teacher/entropy 0.0920 (0.0537) teacher/usage_max 0.8653 (0.8259) teacher/usage_min 0.0347 (0.0144) teacher/usage_std 0.3771 (0.3551) nleep/row_max_mean 1549.2410 (1550.6844) nleep/row_max_std 49.4150 (47.3263) nleep/row_min_mean 1522.0507 (1522.4873) lr 1.9048e-03 eta 0:11:24
epoch [9/50] batch [120/132] time 0.085 (0.120) data 0.000 (0.003) loss 1.0714 (1.2389) teacher_loss 0.0210 (0.1766) loss_zs_kd 0.0000 (0.0060) loss_oracle 0.6293 (0.5871) kd_loss 0.7357 (0.7657) acc 100.0000 (94.2448) gate/entropy 1.0421 (1.0481) gate/usage_max 0.4873 (0.4754) gate/usage_min 0.2169 (0.2185) gate/usage_std 0.1135 (0.1067) teacher/entropy 0.0241 (0.0520) teacher/usage_max 0.9169 (0.8381) teacher/usage_min 0.0001 (0.0133) teacher/usage_std 0.4140 (0.3630) nleep/row_max_mean 1539.3721 (1549.4115) nleep/row_max_std 46.0641 (47.3048) nleep/row_min_mean 1508.2402 (1520.9591) lr 1.9048e-03 eta 0:10:52
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,540
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.4%
******* Domain s best val acc:      99.2%, epoch: 7 *******
******* Domain s best val test acc: 90.4%, epoch: 7 *******
******* Domain s best test acc:     90.5%, epoch: 5 *******
epoch [10/50] batch [20/132] time 0.140 (0.180) data 0.000 (0.014) loss 1.1460 (1.1849) teacher_loss 0.1694 (0.1688) loss_zs_kd 0.0027 (0.0062) loss_oracle 0.5318 (0.5818) kd_loss 0.7094 (0.7220) acc 93.7500 (94.3750) gate/entropy 1.0383 (1.0393) gate/usage_max 0.4942 (0.4924) gate/usage_min 0.2162 (0.2163) gate/usage_std 0.1176 (0.1166) teacher/entropy 0.0451 (0.0338) teacher/usage_max 0.9066 (0.9129) teacher/usage_min 0.0004 (0.0076) teacher/usage_std 0.4071 (0.4111) nleep/row_max_mean 1549.1106 (1543.5788) nleep/row_max_std 48.7426 (46.9557) nleep/row_min_mean 1518.8192 (1513.7935) lr 1.8763e-03 eta 0:16:09
epoch [10/50] batch [40/132] time 0.150 (0.168) data 0.000 (0.007) loss 0.9916 (1.1706) teacher_loss 0.0242 (0.1569) loss_zs_kd 0.0006 (0.0061) loss_oracle 0.5117 (0.5753) kd_loss 0.7112 (0.7230) acc 100.0000 (94.6094) gate/entropy 1.0359 (1.0381) gate/usage_max 0.4985 (0.4946) gate/usage_min 0.2160 (0.2161) gate/usage_std 0.1202 (0.1179) teacher/entropy 0.0208 (0.0307) teacher/usage_max 0.9341 (0.9095) teacher/usage_min 0.0002 (0.0061) teacher/usage_std 0.4256 (0.4091) nleep/row_max_mean 1546.0688 (1545.1786) nleep/row_max_std 51.7761 (46.6323) nleep/row_min_mean 1517.2074 (1514.5479) lr 1.8763e-03 eta 0:15:01
epoch [10/50] batch [60/132] time 0.161 (0.164) data 0.001 (0.005) loss 1.2567 (1.1752) teacher_loss 0.2772 (0.1722) loss_zs_kd 0.0128 (0.0062) loss_oracle 0.5715 (0.5652) kd_loss 0.6873 (0.7173) acc 90.6250 (94.0625) gate/entropy 1.0332 (1.0369) gate/usage_max 0.5031 (0.4967) gate/usage_min 0.2156 (0.2160) gate/usage_std 0.1230 (0.1191) teacher/entropy 0.0246 (0.0305) teacher/usage_max 0.9566 (0.9136) teacher/usage_min 0.0008 (0.0048) teacher/usage_std 0.4410 (0.4120) nleep/row_max_mean 1559.3979 (1545.4433) nleep/row_max_std 47.9445 (46.5880) nleep/row_min_mean 1526.0121 (1514.3610) lr 1.8763e-03 eta 0:14:36
epoch [10/50] batch [80/132] time 0.143 (0.161) data 0.000 (0.004) loss 1.2674 (1.1743) teacher_loss 0.2362 (0.1752) loss_zs_kd 0.0045 (0.0060) loss_oracle 0.6111 (0.5644) kd_loss 0.7234 (0.7140) acc 90.6250 (93.9453) gate/entropy 1.0310 (1.0357) gate/usage_max 0.5068 (0.4987) gate/usage_min 0.2155 (0.2159) gate/usage_std 0.1253 (0.1204) teacher/entropy 0.0253 (0.0315) teacher/usage_max 0.8837 (0.9118) teacher/usage_min 0.0000 (0.0041) teacher/usage_std 0.3920 (0.4108) nleep/row_max_mean 1546.1858 (1545.6303) nleep/row_max_std 38.0653 (45.9907) nleep/row_min_mean 1514.3793 (1514.3100) lr 1.8763e-03 eta 0:14:19
epoch [10/50] batch [100/132] time 0.161 (0.159) data 0.000 (0.003) loss 1.1008 (1.1667) teacher_loss 0.1384 (0.1703) loss_zs_kd 0.0066 (0.0061) loss_oracle 0.5171 (0.5624) kd_loss 0.7006 (0.7121) acc 93.7500 (94.0312) gate/entropy 1.0286 (1.0345) gate/usage_max 0.5106 (0.5007) gate/usage_min 0.2154 (0.2158) gate/usage_std 0.1276 (0.1216) teacher/entropy 0.0187 (0.0292) teacher/usage_max 0.9364 (0.9136) teacher/usage_min 0.0315 (0.0044) teacher/usage_std 0.4264 (0.4121) nleep/row_max_mean 1541.8721 (1545.7101) nleep/row_max_std 39.0699 (45.4052) nleep/row_min_mean 1510.0117 (1514.2591) lr 1.8763e-03 eta 0:14:02
epoch [10/50] batch [120/132] time 0.138 (0.158) data 0.000 (0.002) loss 1.1258 (1.1697) teacher_loss 0.1637 (0.1752) loss_zs_kd 0.0017 (0.0061) loss_oracle 0.5295 (0.5635) kd_loss 0.6965 (0.7097) acc 93.7500 (93.9323) gate/entropy 1.0271 (1.0334) gate/usage_max 0.5131 (0.5027) gate/usage_min 0.2156 (0.2157) gate/usage_std 0.1291 (0.1228) teacher/entropy 0.0117 (0.0300) teacher/usage_max 0.9350 (0.9115) teacher/usage_min 0.0011 (0.0044) teacher/usage_std 0.4262 (0.4106) nleep/row_max_mean 1535.7268 (1546.5182) nleep/row_max_std 51.1535 (44.8122) nleep/row_min_mean 1505.2198 (1514.9759) lr 1.8763e-03 eta 0:13:57
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,553
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 92.5%
******* Domain s best val acc:      99.2%, epoch: 7 *******
******* Domain s best val test acc: 90.4%, epoch: 7 *******
******* Domain s best test acc:     90.5%, epoch: 5 *******
epoch [11/50] batch [20/132] time 0.151 (0.119) data 0.000 (0.017) loss 1.2852 (1.1767) teacher_loss 0.2025 (0.1941) loss_zs_kd 0.0080 (0.0051) loss_oracle 0.6575 (0.5792) kd_loss 0.7500 (0.6904) acc 90.6250 (93.2812) gate/entropy 1.0229 (1.0242) gate/usage_max 0.5193 (0.5175) gate/usage_min 0.2150 (0.2152) gate/usage_std 0.1331 (0.1319) teacher/entropy 0.0200 (0.0331) teacher/usage_max 0.8353 (0.9038) teacher/usage_min 0.0312 (0.0080) teacher/usage_std 0.3574 (0.4051) nleep/row_max_mean 1550.0479 (1549.0628) nleep/row_max_std 38.1352 (39.8999) nleep/row_min_mean 1516.5684 (1517.4016) lr 1.8443e-03 eta 0:10:28
epoch [11/50] batch [40/132] time 0.089 (0.118) data 0.000 (0.009) loss 1.1809 (1.1662) teacher_loss 0.2754 (0.1840) loss_zs_kd 0.0028 (0.0054) loss_oracle 0.5243 (0.5779) kd_loss 0.6419 (0.6905) acc 96.8750 (93.5938) gate/entropy 1.0211 (1.0231) gate/usage_max 0.5220 (0.5190) gate/usage_min 0.2149 (0.2151) gate/usage_std 0.1348 (0.1329) teacher/entropy 0.0417 (0.0382) teacher/usage_max 0.9512 (0.8915) teacher/usage_min 0.0005 (0.0047) teacher/usage_std 0.4374 (0.3976) nleep/row_max_mean 1534.3750 (1546.5276) nleep/row_max_std 42.2110 (39.5120) nleep/row_min_mean 1505.1218 (1515.4146) lr 1.8443e-03 eta 0:10:16
epoch [11/50] batch [60/132] time 0.082 (0.114) data 0.000 (0.006) loss 1.0641 (1.1557) teacher_loss 0.0675 (0.1746) loss_zs_kd 0.0086 (0.0056) loss_oracle 0.5887 (0.5719) kd_loss 0.6980 (0.6923) acc 100.0000 (93.7500) gate/entropy 1.0194 (1.0223) gate/usage_max 0.5244 (0.5203) gate/usage_min 0.2147 (0.2151) gate/usage_std 0.1364 (0.1337) teacher/entropy 0.0550 (0.0401) teacher/usage_max 0.8443 (0.8835) teacher/usage_min 0.0002 (0.0047) teacher/usage_std 0.3669 (0.3924) nleep/row_max_mean 1555.1534 (1544.4664) nleep/row_max_std 39.3092 (39.2710) nleep/row_min_mean 1522.7533 (1513.9373) lr 1.8443e-03 eta 0:09:54
epoch [11/50] batch [80/132] time 0.108 (0.113) data 0.000 (0.004) loss 1.1903 (1.1503) teacher_loss 0.1214 (0.1697) loss_zs_kd 0.0095 (0.0060) loss_oracle 0.5426 (0.5704) kd_loss 0.7928 (0.6924) acc 93.7500 (93.9844) gate/entropy 1.0187 (1.0214) gate/usage_max 0.5254 (0.5215) gate/usage_min 0.2149 (0.2150) gate/usage_std 0.1370 (0.1345) teacher/entropy 0.0330 (0.0389) teacher/usage_max 0.7401 (0.8825) teacher/usage_min 0.0035 (0.0037) teacher/usage_std 0.3056 (0.3918) nleep/row_max_mean 1536.6714 (1544.3988) nleep/row_max_std 26.8607 (38.5103) nleep/row_min_mean 1509.7666 (1513.9692) lr 1.8443e-03 eta 0:09:47
epoch [11/50] batch [100/132] time 0.093 (0.114) data 0.000 (0.004) loss 1.0390 (1.1442) teacher_loss 0.0762 (0.1622) loss_zs_kd 0.0119 (0.0059) loss_oracle 0.5513 (0.5662) kd_loss 0.6812 (0.6960) acc 96.8750 (94.1875) gate/entropy 1.0171 (1.0207) gate/usage_max 0.5276 (0.5225) gate/usage_min 0.2146 (0.2149) gate/usage_std 0.1385 (0.1352) teacher/entropy 0.0553 (0.0408) teacher/usage_max 0.8629 (0.8727) teacher/usage_min 0.0000 (0.0038) teacher/usage_std 0.3786 (0.3856) nleep/row_max_mean 1537.8179 (1544.0965) nleep/row_max_std 38.3721 (38.8524) nleep/row_min_mean 1510.0166 (1514.0494) lr 1.8443e-03 eta 0:09:52
epoch [11/50] batch [120/132] time 0.192 (0.118) data 0.000 (0.003) loss 1.1875 (1.1464) teacher_loss 0.1503 (0.1645) loss_zs_kd 0.0035 (0.0058) loss_oracle 0.6221 (0.5630) kd_loss 0.7244 (0.6975) acc 93.7500 (94.1406) gate/entropy 1.0156 (1.0199) gate/usage_max 0.5296 (0.5236) gate/usage_min 0.2143 (0.2149) gate/usage_std 0.1398 (0.1359) teacher/entropy 0.0458 (0.0421) teacher/usage_max 0.8142 (0.8670) teacher/usage_min 0.0000 (0.0036) teacher/usage_std 0.3484 (0.3820) nleep/row_max_mean 1544.2620 (1544.5890) nleep/row_max_std 42.7935 (38.9577) nleep/row_min_mean 1514.0793 (1514.5795) lr 1.8443e-03 eta 0:10:07
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,540
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 91.9%
******* Domain s best val acc:      99.2%, epoch: 7 *******
******* Domain s best val test acc: 90.4%, epoch: 7 *******
******* Domain s best test acc:     90.5%, epoch: 5 *******
epoch [12/50] batch [20/132] time 0.166 (0.169) data 0.000 (0.015) loss 1.2160 (1.1567) teacher_loss 0.2703 (0.1864) loss_zs_kd 0.0042 (0.0056) loss_oracle 0.5242 (0.5369) kd_loss 0.6815 (0.6990) acc 87.5000 (93.2812) gate/entropy 1.0144 (1.0145) gate/usage_max 0.5313 (0.5310) gate/usage_min 0.2142 (0.2142) gate/usage_std 0.1409 (0.1408) teacher/entropy 0.1422 (0.0619) teacher/usage_max 0.7514 (0.8251) teacher/usage_min 0.0563 (0.0048) teacher/usage_std 0.3008 (0.3553) nleep/row_max_mean 1534.3928 (1541.6780) nleep/row_max_std 36.0851 (36.8940) nleep/row_min_mean 1506.8533 (1512.9468) lr 1.8090e-03 eta 0:14:27
epoch [12/50] batch [40/132] time 0.149 (0.163) data 0.000 (0.008) loss 1.1796 (1.1462) teacher_loss 0.1763 (0.1556) loss_zs_kd 0.0041 (0.0052) loss_oracle 0.5303 (0.5416) kd_loss 0.7362 (0.7172) acc 93.7500 (94.6875) gate/entropy 1.0132 (1.0140) gate/usage_max 0.5328 (0.5317) gate/usage_min 0.2139 (0.2141) gate/usage_std 0.1420 (0.1412) teacher/entropy 0.0358 (0.0575) teacher/usage_max 0.8068 (0.8057) teacher/usage_min 0.0002 (0.0047) teacher/usage_std 0.3440 (0.3440) nleep/row_max_mean 1538.2031 (1541.5542) nleep/row_max_std 43.9989 (37.6187) nleep/row_min_mean 1509.5005 (1512.9519) lr 1.8090e-03 eta 0:13:53
epoch [12/50] batch [60/132] time 0.126 (0.156) data 0.001 (0.005) loss 1.1543 (1.1380) teacher_loss 0.1848 (0.1463) loss_zs_kd 0.0070 (0.0054) loss_oracle 0.5778 (0.5451) kd_loss 0.6771 (0.7164) acc 90.6250 (95.1042) gate/entropy 1.0120 (1.0136) gate/usage_max 0.5342 (0.5322) gate/usage_min 0.2134 (0.2140) gate/usage_std 0.1429 (0.1415) teacher/entropy 0.0861 (0.0627) teacher/usage_max 0.8159 (0.7992) teacher/usage_min 0.0000 (0.0055) teacher/usage_std 0.3494 (0.3402) nleep/row_max_mean 1540.9799 (1541.8853) nleep/row_max_std 41.3152 (39.0485) nleep/row_min_mean 1510.7693 (1513.6809) lr 1.8090e-03 eta 0:13:11
epoch [12/50] batch [80/132] time 0.132 (0.153) data 0.000 (0.004) loss 1.1470 (1.1400) teacher_loss 0.1135 (0.1490) loss_zs_kd 0.0145 (0.0059) loss_oracle 0.5846 (0.5437) kd_loss 0.7339 (0.7162) acc 96.8750 (95.1562) gate/entropy 1.0119 (1.0133) gate/usage_max 0.5344 (0.5326) gate/usage_min 0.2134 (0.2138) gate/usage_std 0.1431 (0.1418) teacher/entropy 0.0745 (0.0646) teacher/usage_max 0.7563 (0.7962) teacher/usage_min 0.0027 (0.0053) teacher/usage_std 0.3145 (0.3382) nleep/row_max_mean 1541.1158 (1541.1883) nleep/row_max_std 40.8860 (40.8197) nleep/row_min_mean 1514.9564 (1513.4834) lr 1.8090e-03 eta 0:12:55
epoch [12/50] batch [100/132] time 0.154 (0.152) data 0.000 (0.003) loss 1.2078 (1.1435) teacher_loss 0.1093 (0.1487) loss_zs_kd 0.0008 (0.0057) loss_oracle 0.5713 (0.5449) kd_loss 0.8125 (0.7196) acc 93.7500 (95.0625) gate/entropy 1.0114 (1.0129) gate/usage_max 0.5351 (0.5331) gate/usage_min 0.2133 (0.2137) gate/usage_std 0.1435 (0.1422) teacher/entropy 0.0441 (0.0659) teacher/usage_max 0.6958 (0.7898) teacher/usage_min 0.0172 (0.0071) teacher/usage_std 0.2789 (0.3342) nleep/row_max_mean 1532.2842 (1540.8818) nleep/row_max_std 54.7811 (42.0222) nleep/row_min_mean 1508.9878 (1513.6033) lr 1.8090e-03 eta 0:12:47
epoch [12/50] batch [120/132] time 0.125 (0.151) data 0.000 (0.003) loss 1.1989 (1.1418) teacher_loss 0.1677 (0.1458) loss_zs_kd 0.0029 (0.0057) loss_oracle 0.5509 (0.5464) kd_loss 0.7543 (0.7200) acc 96.8750 (95.1562) gate/entropy 1.0109 (1.0126) gate/usage_max 0.5356 (0.5335) gate/usage_min 0.2131 (0.2136) gate/usage_std 0.1439 (0.1424) teacher/entropy 0.0807 (0.0697) teacher/usage_max 0.7184 (0.7840) teacher/usage_min 0.0006 (0.0081) teacher/usage_std 0.2954 (0.3307) nleep/row_max_mean 1539.7509 (1540.9129) nleep/row_max_std 33.7900 (42.2801) nleep/row_min_mean 1516.8999 (1513.9653) lr 1.8090e-03 eta 0:12:36
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,509
* accuracy: 89.3%
* error: 10.7%
* macro_f1: 91.6%
******* Domain s best val acc:      99.3%, epoch: 12 *******
******* Domain s best val test acc: 89.3%, epoch: 12 *******
******* Domain s best test acc:     90.5%, epoch: 5 *******
epoch [13/50] batch [20/132] time 0.079 (0.126) data 0.000 (0.016) loss 0.9642 (1.1622) teacher_loss 0.0668 (0.1604) loss_zs_kd 0.0074 (0.0078) loss_oracle 0.4912 (0.5474) kd_loss 0.6481 (0.7243) acc 96.8750 (94.8438) gate/entropy 1.0095 (1.0099) gate/usage_max 0.5373 (0.5369) gate/usage_min 0.2128 (0.2129) gate/usage_std 0.1451 (0.1447) teacher/entropy 0.0648 (0.0726) teacher/usage_max 0.8800 (0.7744) teacher/usage_min 0.0002 (0.0254) teacher/usage_std 0.3896 (0.3236) nleep/row_max_mean 1544.2283 (1536.0246) nleep/row_max_std 47.1357 (48.2598) nleep/row_min_mean 1519.0161 (1511.3936) lr 1.7705e-03 eta 0:10:27
epoch [13/50] batch [40/132] time 0.226 (0.117) data 0.000 (0.008) loss 1.0400 (1.1460) teacher_loss 0.0027 (0.1448) loss_zs_kd 0.0000 (0.0069) loss_oracle 0.5184 (0.5409) kd_loss 0.7781 (0.7273) acc 100.0000 (95.2344) gate/entropy 1.0090 (1.0097) gate/usage_max 0.5380 (0.5372) gate/usage_min 0.2126 (0.2128) gate/usage_std 0.1455 (0.1449) teacher/entropy 0.0975 (0.0798) teacher/usage_max 0.6648 (0.7602) teacher/usage_min 0.0001 (0.0230) teacher/usage_std 0.2714 (0.3160) nleep/row_max_mean 1547.7380 (1534.7548) nleep/row_max_std 41.5271 (47.4783) nleep/row_min_mean 1521.8789 (1510.9275) lr 1.7705e-03 eta 0:09:43
epoch [13/50] batch [60/132] time 0.083 (0.113) data 0.000 (0.006) loss 1.1639 (1.1485) teacher_loss 0.2189 (0.1445) loss_zs_kd 0.0000 (0.0065) loss_oracle 0.4962 (0.5371) kd_loss 0.6968 (0.7323) acc 90.6250 (95.0521) gate/entropy 1.0086 (1.0094) gate/usage_max 0.5385 (0.5375) gate/usage_min 0.2125 (0.2127) gate/usage_std 0.1458 (0.1451) teacher/entropy 0.0680 (0.0794) teacher/usage_max 0.8233 (0.7544) teacher/usage_min 0.0621 (0.0252) teacher/usage_std 0.3471 (0.3120) nleep/row_max_mean 1543.5110 (1535.4318) nleep/row_max_std 44.5238 (46.2641) nleep/row_min_mean 1517.8259 (1511.8292) lr 1.7705e-03 eta 0:09:18
epoch [13/50] batch [80/132] time 0.165 (0.115) data 0.000 (0.004) loss 1.1534 (1.1533) teacher_loss 0.1933 (0.1522) loss_zs_kd 0.0152 (0.0064) loss_oracle 0.5903 (0.5349) kd_loss 0.6574 (0.7305) acc 93.7500 (94.6875) gate/entropy 1.0081 (1.0092) gate/usage_max 0.5392 (0.5377) gate/usage_min 0.2124 (0.2127) gate/usage_std 0.1463 (0.1453) teacher/entropy 0.0988 (0.0791) teacher/usage_max 0.8283 (0.7575) teacher/usage_min 0.0436 (0.0286) teacher/usage_std 0.3517 (0.3131) nleep/row_max_mean 1533.4041 (1534.6904) nleep/row_max_std 38.1602 (45.5341) nleep/row_min_mean 1510.3547 (1511.4017) lr 1.7705e-03 eta 0:09:27
epoch [13/50] batch [100/132] time 0.137 (0.119) data 0.000 (0.003) loss 1.0367 (1.1636) teacher_loss 0.0977 (0.1575) loss_zs_kd 0.0056 (0.0067) loss_oracle 0.5360 (0.5410) kd_loss 0.6681 (0.7322) acc 93.7500 (94.4062) gate/entropy 1.0078 (1.0090) gate/usage_max 0.5396 (0.5381) gate/usage_min 0.2124 (0.2126) gate/usage_std 0.1466 (0.1456) teacher/entropy 0.0957 (0.0754) teacher/usage_max 0.8104 (0.7596) teacher/usage_min 0.0056 (0.0278) teacher/usage_std 0.3451 (0.3141) nleep/row_max_mean 1532.7053 (1534.8699) nleep/row_max_std 45.1621 (45.1466) nleep/row_min_mean 1510.3003 (1511.5044) lr 1.7705e-03 eta 0:09:44
epoch [13/50] batch [120/132] time 0.142 (0.124) data 0.000 (0.003) loss 1.4802 (1.1734) teacher_loss 0.2139 (0.1613) loss_zs_kd 0.0033 (0.0067) loss_oracle 0.6328 (0.5440) kd_loss 0.9482 (0.7367) acc 90.6250 (94.2188) gate/entropy 1.0072 (1.0087) gate/usage_max 0.5403 (0.5384) gate/usage_min 0.2121 (0.2126) gate/usage_std 0.1471 (0.1458) teacher/entropy 0.0509 (0.0774) teacher/usage_max 0.5269 (0.7517) teacher/usage_min 0.1020 (0.0314) teacher/usage_std 0.1755 (0.3089) nleep/row_max_mean 1537.9846 (1534.8665) nleep/row_max_std 43.7025 (44.6132) nleep/row_min_mean 1516.2002 (1511.8241) lr 1.7705e-03 eta 0:10:08
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,549
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.3%
******* Domain s best val acc:      99.3%, epoch: 12 *******
******* Domain s best val test acc: 89.3%, epoch: 12 *******
******* Domain s best test acc:     90.5%, epoch: 5 *******
epoch [14/50] batch [20/132] time 0.136 (0.165) data 0.000 (0.013) loss 1.0974 (1.2161) teacher_loss 0.0606 (0.1357) loss_zs_kd 0.0034 (0.0062) loss_oracle 0.6156 (0.5494) kd_loss 0.7274 (0.8027) acc 96.8750 (95.9375) gate/entropy 1.0078 (1.0075) gate/usage_max 0.5395 (0.5398) gate/usage_min 0.2118 (0.2119) gate/usage_std 0.1465 (0.1467) teacher/entropy 0.1027 (0.1029) teacher/usage_max 0.7469 (0.6428) teacher/usage_min 0.1140 (0.0836) teacher/usage_std 0.2926 (0.2401) nleep/row_max_mean 1533.5139 (1531.3514) nleep/row_max_std 42.3715 (42.9861) nleep/row_min_mean 1512.2076 (1510.9592) lr 1.7290e-03 eta 0:13:22
epoch [14/50] batch [40/132] time 0.137 (0.151) data 0.000 (0.007) loss 1.0672 (1.2228) teacher_loss 0.0531 (0.1506) loss_zs_kd 0.0106 (0.0080) loss_oracle 0.5218 (0.5427) kd_loss 0.7479 (0.7969) acc 96.8750 (94.8438) gate/entropy 1.0071 (1.0075) gate/usage_max 0.5402 (0.5398) gate/usage_min 0.2116 (0.2118) gate/usage_std 0.1471 (0.1468) teacher/entropy 0.1248 (0.1010) teacher/usage_max 0.6828 (0.6532) teacher/usage_min 0.0701 (0.0873) teacher/usage_std 0.2575 (0.2418) nleep/row_max_mean 1528.3220 (1530.2295) nleep/row_max_std 45.5136 (44.3426) nleep/row_min_mean 1508.1855 (1510.1213) lr 1.7290e-03 eta 0:12:10
epoch [14/50] batch [60/132] time 0.149 (0.146) data 0.000 (0.004) loss 1.0406 (1.2284) teacher_loss 0.1391 (0.1596) loss_zs_kd 0.0088 (0.0077) loss_oracle 0.5002 (0.5451) kd_loss 0.6470 (0.7923) acc 93.7500 (94.5312) gate/entropy 1.0067 (1.0074) gate/usage_max 0.5408 (0.5399) gate/usage_min 0.2116 (0.2118) gate/usage_std 0.1475 (0.1468) teacher/entropy 0.1579 (0.1035) teacher/usage_max 0.7645 (0.6588) teacher/usage_min 0.0450 (0.0980) teacher/usage_std 0.3106 (0.2424) nleep/row_max_mean 1534.4656 (1531.0971) nleep/row_max_std 38.2485 (45.2577) nleep/row_min_mean 1512.6338 (1510.6481) lr 1.7290e-03 eta 0:11:44
epoch [14/50] batch [80/132] time 0.188 (0.145) data 0.001 (0.003) loss 1.3216 (1.2246) teacher_loss 0.2446 (0.1618) loss_zs_kd 0.0146 (0.0090) loss_oracle 0.5247 (0.5415) kd_loss 0.8074 (0.7874) acc 90.6250 (94.3750) gate/entropy 1.0068 (1.0073) gate/usage_max 0.5407 (0.5401) gate/usage_min 0.2117 (0.2117) gate/usage_std 0.1474 (0.1469) teacher/entropy 0.1464 (0.1071) teacher/usage_max 0.5966 (0.6623) teacher/usage_min 0.1626 (0.1033) teacher/usage_std 0.1889 (0.2428) nleep/row_max_mean 1538.3534 (1531.6872) nleep/row_max_std 48.9972 (45.4801) nleep/row_min_mean 1516.6495 (1511.0108) lr 1.7290e-03 eta 0:11:34
epoch [14/50] batch [100/132] time 0.068 (0.134) data 0.000 (0.003) loss 1.2349 (1.2157) teacher_loss 0.1237 (0.1520) loss_zs_kd 0.0048 (0.0090) loss_oracle 0.5391 (0.5359) kd_loss 0.8393 (0.7912) acc 93.7500 (94.6562) gate/entropy 1.0069 (1.0071) gate/usage_max 0.5405 (0.5403) gate/usage_min 0.2118 (0.2117) gate/usage_std 0.1472 (0.1471) teacher/entropy 0.1189 (0.1084) teacher/usage_max 0.5846 (0.6573) teacher/usage_min 0.1388 (0.1082) teacher/usage_std 0.1863 (0.2383) nleep/row_max_mean 1532.7291 (1532.0421) nleep/row_max_std 55.0323 (46.6547) nleep/row_min_mean 1512.1646 (1511.1005) lr 1.7290e-03 eta 0:10:42
epoch [14/50] batch [120/132] time 0.071 (0.127) data 0.000 (0.002) loss 1.1798 (1.2125) teacher_loss 0.1421 (0.1481) loss_zs_kd 0.0236 (0.0093) loss_oracle 0.5164 (0.5318) kd_loss 0.7677 (0.7938) acc 93.7500 (94.8177) gate/entropy 1.0061 (1.0070) gate/usage_max 0.5415 (0.5404) gate/usage_min 0.2116 (0.2117) gate/usage_std 0.1479 (0.1472) teacher/entropy 0.1090 (0.1082) teacher/usage_max 0.6791 (0.6540) teacher/usage_min 0.0800 (0.1095) teacher/usage_std 0.2531 (0.2364) nleep/row_max_mean 1537.0308 (1531.9107) nleep/row_max_std 36.4641 (47.1623) nleep/row_min_mean 1513.2089 (1510.9060) lr 1.7290e-03 eta 0:10:04
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,529
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.2%
******* Domain s best val acc:      99.3%, epoch: 14 *******
******* Domain s best val test acc: 89.8%, epoch: 14 *******
******* Domain s best test acc:     90.5%, epoch: 5 *******
epoch [15/50] batch [20/132] time 0.102 (0.122) data 0.000 (0.015) loss 1.3035 (1.2996) teacher_loss 0.0841 (0.1342) loss_zs_kd 0.0068 (0.0115) loss_oracle 0.5545 (0.5737) kd_loss 0.9387 (0.8728) acc 96.8750 (96.0938) gate/entropy 1.0063 (1.0064) gate/usage_max 0.5412 (0.5411) gate/usage_min 0.2112 (0.2114) gate/usage_std 0.1477 (0.1477) teacher/entropy 0.0423 (0.1071) teacher/usage_max 0.5601 (0.5588) teacher/usage_min 0.1570 (0.1406) teacher/usage_std 0.1684 (0.1786) nleep/row_max_mean 1558.4038 (1539.5853) nleep/row_max_std 43.1322 (45.0867) nleep/row_min_mean 1530.7683 (1516.5023) lr 1.6845e-03 eta 0:09:36
epoch [15/50] batch [40/132] time 0.191 (0.125) data 0.000 (0.008) loss 1.3475 (1.2825) teacher_loss 0.1446 (0.1410) loss_zs_kd 0.0053 (0.0119) loss_oracle 0.5291 (0.5539) kd_loss 0.9357 (0.8586) acc 96.8750 (95.4688) gate/entropy 1.0071 (1.0065) gate/usage_max 0.5402 (0.5409) gate/usage_min 0.2112 (0.2113) gate/usage_std 0.1471 (0.1476) teacher/entropy 0.1398 (0.1162) teacher/usage_max 0.4570 (0.5657) teacher/usage_min 0.2458 (0.1308) teacher/usage_std 0.0899 (0.1842) nleep/row_max_mean 1535.9825 (1538.8109) nleep/row_max_std 45.4833 (46.0665) nleep/row_min_mean 1512.3569 (1515.8663) lr 1.6845e-03 eta 0:09:47
epoch [15/50] batch [60/132] time 0.133 (0.123) data 0.000 (0.005) loss 1.2451 (1.2704) teacher_loss 0.0971 (0.1454) loss_zs_kd 0.0100 (0.0112) loss_oracle 0.6106 (0.5495) kd_loss 0.8377 (0.8445) acc 96.8750 (95.3125) gate/entropy 1.0071 (1.0066) gate/usage_max 0.5401 (0.5408) gate/usage_min 0.2109 (0.2112) gate/usage_std 0.1471 (0.1475) teacher/entropy 0.1237 (0.1223) teacher/usage_max 0.5630 (0.5731) teacher/usage_min 0.0571 (0.1188) teacher/usage_std 0.2091 (0.1920) nleep/row_max_mean 1526.0774 (1536.9803) nleep/row_max_std 47.4404 (46.7091) nleep/row_min_mean 1501.9279 (1513.9847) lr 1.6845e-03 eta 0:09:35
epoch [15/50] batch [80/132] time 0.131 (0.131) data 0.000 (0.004) loss 1.1392 (1.2572) teacher_loss 0.0269 (0.1308) loss_zs_kd 0.0121 (0.0112) loss_oracle 0.5526 (0.5495) kd_loss 0.8300 (0.8460) acc 100.0000 (95.8594) gate/entropy 1.0075 (1.0068) gate/usage_max 0.5396 (0.5406) gate/usage_min 0.2106 (0.2111) gate/usage_std 0.1467 (0.1473) teacher/entropy 0.1393 (0.1165) teacher/usage_max 0.5562 (0.5763) teacher/usage_min 0.0730 (0.1110) teacher/usage_std 0.1990 (0.1962) nleep/row_max_mean 1542.7249 (1537.3566) nleep/row_max_std 41.2518 (46.6162) nleep/row_min_mean 1520.2484 (1514.0356) lr 1.6845e-03 eta 0:10:12
epoch [15/50] batch [100/132] time 0.140 (0.134) data 0.000 (0.003) loss 1.1471 (1.2635) teacher_loss 0.0980 (0.1353) loss_zs_kd 0.0038 (0.0110) loss_oracle 0.6045 (0.5537) kd_loss 0.7450 (0.8459) acc 96.8750 (95.5625) gate/entropy 1.0075 (1.0069) gate/usage_max 0.5394 (0.5403) gate/usage_min 0.2102 (0.2109) gate/usage_std 0.1466 (0.1472) teacher/entropy 0.0887 (0.1155) teacher/usage_max 0.7289 (0.5772) teacher/usage_min 0.0586 (0.1078) teacher/usage_std 0.2867 (0.1986) nleep/row_max_mean 1534.0896 (1536.5839) nleep/row_max_std 43.2988 (46.4457) nleep/row_min_mean 1507.2002 (1513.0410) lr 1.6845e-03 eta 0:10:24
epoch [15/50] batch [120/132] time 0.134 (0.135) data 0.000 (0.003) loss 1.2345 (1.2605) teacher_loss 0.1670 (0.1341) loss_zs_kd 0.0154 (0.0108) loss_oracle 0.5149 (0.5553) kd_loss 0.8023 (0.8433) acc 90.6250 (95.5208) gate/entropy 1.0083 (1.0071) gate/usage_max 0.5384 (0.5401) gate/usage_min 0.2101 (0.2108) gate/usage_std 0.1460 (0.1470) teacher/entropy 0.1496 (0.1135) teacher/usage_max 0.5947 (0.5833) teacher/usage_min 0.1479 (0.1062) teacher/usage_std 0.1901 (0.2015) nleep/row_max_mean 1531.0010 (1536.1289) nleep/row_max_std 44.9389 (45.7904) nleep/row_min_mean 1506.8669 (1512.3507) lr 1.6845e-03 eta 0:10:27
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,510
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.9%
******* Domain s best val acc:      99.3%, epoch: 14 *******
******* Domain s best val test acc: 89.8%, epoch: 14 *******
******* Domain s best test acc:     90.5%, epoch: 5 *******
epoch [16/50] batch [20/132] time 0.121 (0.156) data 0.000 (0.013) loss 1.3978 (1.2783) teacher_loss 0.1888 (0.1265) loss_zs_kd 0.0143 (0.0121) loss_oracle 0.7130 (0.6039) kd_loss 0.8453 (0.8438) acc 90.6250 (95.9375) gate/entropy 1.0084 (1.0083) gate/usage_max 0.5381 (0.5382) gate/usage_min 0.2095 (0.2097) gate/usage_std 0.1458 (0.1459) teacher/entropy 0.0884 (0.0871) teacher/usage_max 0.5973 (0.6085) teacher/usage_min 0.0604 (0.0903) teacher/usage_std 0.2193 (0.2146) nleep/row_max_mean 1550.1581 (1533.7210) nleep/row_max_std 30.6570 (38.1130) nleep/row_min_mean 1522.2297 (1508.9530) lr 1.6374e-03 eta 0:11:57
epoch [16/50] batch [40/132] time 0.132 (0.151) data 0.000 (0.007) loss 1.1054 (1.2841) teacher_loss 0.0817 (0.1233) loss_zs_kd 0.0102 (0.0118) loss_oracle 0.5499 (0.5971) kd_loss 0.7437 (0.8564) acc 96.8750 (95.8594) gate/entropy 1.0086 (1.0085) gate/usage_max 0.5378 (0.5379) gate/usage_min 0.2091 (0.2096) gate/usage_std 0.1457 (0.1457) teacher/entropy 0.0807 (0.0850) teacher/usage_max 0.7423 (0.5958) teacher/usage_min 0.0608 (0.0844) teacher/usage_std 0.2945 (0.2142) nleep/row_max_mean 1535.3696 (1532.7982) nleep/row_max_std 46.1425 (39.0554) nleep/row_min_mean 1507.8901 (1507.2288) lr 1.6374e-03 eta 0:11:29
epoch [16/50] batch [60/132] time 0.086 (0.140) data 0.000 (0.005) loss 1.0486 (1.2802) teacher_loss 0.0119 (0.1229) loss_zs_kd 0.0054 (0.0111) loss_oracle 0.5240 (0.5846) kd_loss 0.7720 (0.8595) acc 100.0000 (95.8854) gate/entropy 1.0093 (1.0088) gate/usage_max 0.5368 (0.5375) gate/usage_min 0.2088 (0.2094) gate/usage_std 0.1451 (0.1455) teacher/entropy 0.1176 (0.0809) teacher/usage_max 0.6701 (0.5976) teacher/usage_min 0.1146 (0.0908) teacher/usage_std 0.2416 (0.2130) nleep/row_max_mean 1535.4426 (1533.1542) nleep/row_max_std 35.3934 (38.6102) nleep/row_min_mean 1507.7139 (1507.3161) lr 1.6374e-03 eta 0:10:39
epoch [16/50] batch [80/132] time 0.109 (0.130) data 0.000 (0.003) loss 1.2917 (1.2784) teacher_loss 0.2235 (0.1255) loss_zs_kd 0.0169 (0.0108) loss_oracle 0.5357 (0.5809) kd_loss 0.7919 (0.8570) acc 90.6250 (95.7031) gate/entropy 1.0100 (1.0090) gate/usage_max 0.5358 (0.5372) gate/usage_min 0.2087 (0.2092) gate/usage_std 0.1444 (0.1453) teacher/entropy 0.1413 (0.0820) teacher/usage_max 0.6292 (0.5989) teacher/usage_min 0.1766 (0.0906) teacher/usage_std 0.2093 (0.2140) nleep/row_max_mean 1526.2393 (1533.1121) nleep/row_max_std 35.9859 (38.0779) nleep/row_min_mean 1503.6233 (1507.2469) lr 1.6374e-03 eta 0:09:51
epoch [16/50] batch [100/132] time 0.103 (0.128) data 0.000 (0.003) loss 1.1845 (1.2681) teacher_loss 0.0341 (0.1189) loss_zs_kd 0.0053 (0.0101) loss_oracle 0.5200 (0.5829) kd_loss 0.8877 (0.8527) acc 100.0000 (95.7812) gate/entropy 1.0099 (1.0092) gate/usage_max 0.5358 (0.5369) gate/usage_min 0.2084 (0.2091) gate/usage_std 0.1445 (0.1451) teacher/entropy 0.0614 (0.0815) teacher/usage_max 0.5853 (0.6054) teacher/usage_min 0.0940 (0.0926) teacher/usage_std 0.2008 (0.2167) nleep/row_max_mean 1528.4434 (1532.7861) nleep/row_max_std 31.3607 (37.4830) nleep/row_min_mean 1504.6177 (1506.8430) lr 1.6374e-03 eta 0:09:36
epoch [16/50] batch [120/132] time 0.140 (0.127) data 0.000 (0.002) loss 1.1882 (1.2743) teacher_loss 0.1080 (0.1217) loss_zs_kd 0.0211 (0.0099) loss_oracle 0.5521 (0.5861) kd_loss 0.7936 (0.8546) acc 96.8750 (95.7031) gate/entropy 1.0104 (1.0094) gate/usage_max 0.5350 (0.5366) gate/usage_min 0.2080 (0.2090) gate/usage_std 0.1440 (0.1449) teacher/entropy 0.1205 (0.0804) teacher/usage_max 0.6263 (0.6051) teacher/usage_min 0.0774 (0.0967) teacher/usage_std 0.2256 (0.2151) nleep/row_max_mean 1535.1367 (1532.7814) nleep/row_max_std 30.5340 (36.7617) nleep/row_min_mean 1509.7070 (1506.9334) lr 1.6374e-03 eta 0:09:31
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,538
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.3%
******* Domain s best val acc:      99.5%, epoch: 16 *******
******* Domain s best val test acc: 90.1%, epoch: 16 *******
******* Domain s best test acc:     90.5%, epoch: 5 *******
epoch [17/50] batch [20/132] time 0.179 (0.133) data 0.000 (0.016) loss 1.2713 (1.3145) teacher_loss 0.0702 (0.1200) loss_zs_kd 0.0036 (0.0080) loss_oracle 0.5835 (0.5989) kd_loss 0.9075 (0.8910) acc 100.0000 (96.0938) gate/entropy 1.0114 (1.0110) gate/usage_max 0.5336 (0.5342) gate/usage_min 0.2076 (0.2078) gate/usage_std 0.1431 (0.1435) teacher/entropy 0.1562 (0.0817) teacher/usage_max 0.4606 (0.5581) teacher/usage_min 0.2088 (0.1189) teacher/usage_std 0.1028 (0.1829) nleep/row_max_mean 1533.2188 (1532.3965) nleep/row_max_std 40.3870 (38.0901) nleep/row_min_mean 1512.0901 (1506.9465) lr 1.5878e-03 eta 0:09:52
epoch [17/50] batch [40/132] time 0.157 (0.142) data 0.000 (0.008) loss 1.3684 (1.3194) teacher_loss 0.1307 (0.1391) loss_zs_kd 0.0051 (0.0095) loss_oracle 0.6928 (0.6035) kd_loss 0.8888 (0.8739) acc 93.7500 (95.5469) gate/entropy 1.0116 (1.0112) gate/usage_max 0.5331 (0.5338) gate/usage_min 0.2074 (0.2076) gate/usage_std 0.1429 (0.1433) teacher/entropy 0.1069 (0.0810) teacher/usage_max 0.5213 (0.5829) teacher/usage_min 0.1051 (0.1197) teacher/usage_std 0.1723 (0.1959) nleep/row_max_mean 1531.8629 (1530.8766) nleep/row_max_std 39.5541 (38.2482) nleep/row_min_mean 1506.4015 (1505.1788) lr 1.5878e-03 eta 0:10:30
epoch [17/50] batch [60/132] time 0.123 (0.142) data 0.000 (0.006) loss 1.2197 (1.3284) teacher_loss 0.1014 (0.1448) loss_zs_kd 0.0030 (0.0102) loss_oracle 0.5656 (0.6144) kd_loss 0.8340 (0.8713) acc 96.8750 (95.4688) gate/entropy 1.0116 (1.0113) gate/usage_max 0.5330 (0.5336) gate/usage_min 0.2071 (0.2075) gate/usage_std 0.1429 (0.1431) teacher/entropy 0.0709 (0.0803) teacher/usage_max 0.6417 (0.5865) teacher/usage_min 0.0902 (0.1168) teacher/usage_std 0.2298 (0.1984) nleep/row_max_mean 1535.6219 (1530.4038) nleep/row_max_std 34.4185 (38.3697) nleep/row_min_mean 1508.2197 (1504.5059) lr 1.5878e-03 eta 0:10:28
epoch [17/50] batch [80/132] time 0.133 (0.142) data 0.000 (0.004) loss 1.3150 (1.3319) teacher_loss 0.0773 (0.1436) loss_zs_kd 0.0048 (0.0108) loss_oracle 0.5006 (0.6159) kd_loss 0.9850 (0.8750) acc 96.8750 (95.4297) gate/entropy 1.0123 (1.0115) gate/usage_max 0.5321 (0.5333) gate/usage_min 0.2068 (0.2074) gate/usage_std 0.1423 (0.1430) teacher/entropy 0.0551 (0.0796) teacher/usage_max 0.5111 (0.5830) teacher/usage_min 0.2203 (0.1188) teacher/usage_std 0.1273 (0.1964) nleep/row_max_mean 1530.0291 (1529.7217) nleep/row_max_std 39.8793 (38.4919) nleep/row_min_mean 1507.1738 (1503.7917) lr 1.5878e-03 eta 0:10:23
epoch [17/50] batch [100/132] time 0.143 (0.141) data 0.000 (0.003) loss 1.1006 (1.3135) teacher_loss 0.0231 (0.1312) loss_zs_kd 0.0072 (0.0101) loss_oracle 0.5373 (0.6130) kd_loss 0.8053 (0.8707) acc 100.0000 (95.9688) gate/entropy 1.0125 (1.0117) gate/usage_max 0.5317 (0.5330) gate/usage_min 0.2065 (0.2072) gate/usage_std 0.1420 (0.1428) teacher/entropy 0.0707 (0.0786) teacher/usage_max 0.6741 (0.5887) teacher/usage_min 0.0640 (0.1146) teacher/usage_std 0.2542 (0.2000) nleep/row_max_mean 1535.7029 (1530.3742) nleep/row_max_std 39.8784 (38.0011) nleep/row_min_mean 1507.4808 (1504.2177) lr 1.5878e-03 eta 0:10:17
epoch [17/50] batch [120/132] time 0.154 (0.141) data 0.000 (0.003) loss 1.3687 (1.3061) teacher_loss 0.1772 (0.1303) loss_zs_kd 0.0177 (0.0098) loss_oracle 0.5888 (0.6063) kd_loss 0.8882 (0.8678) acc 93.7500 (96.0156) gate/entropy 1.0131 (1.0119) gate/usage_max 0.5307 (0.5327) gate/usage_min 0.2064 (0.2071) gate/usage_std 0.1414 (0.1426) teacher/entropy 0.0772 (0.0785) teacher/usage_max 0.5783 (0.5932) teacher/usage_min 0.1551 (0.1155) teacher/usage_std 0.1791 (0.2022) nleep/row_max_mean 1525.1564 (1530.9390) nleep/row_max_std 35.0920 (37.4156) nleep/row_min_mean 1497.3713 (1504.6039) lr 1.5878e-03 eta 0:10:14
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,812
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,560
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 92.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.5%, epoch: 17 *******
******* Domain s best val test acc: 90.6%, epoch: 17 *******
******* Domain s best test acc:     90.6%, epoch: 17 *******
epoch [18/50] batch [20/132] time 0.096 (0.150) data 0.000 (0.020) loss 1.1671 (1.2339) teacher_loss 0.0481 (0.1142) loss_zs_kd 0.0035 (0.0116) loss_oracle 0.5948 (0.5626) kd_loss 0.8198 (0.8326) acc 100.0000 (95.6250) gate/entropy 1.0123 (1.0129) gate/usage_max 0.5317 (0.5310) gate/usage_min 0.2060 (0.2061) gate/usage_std 0.1422 (0.1417) teacher/entropy 0.0082 (0.0775) teacher/usage_max 0.7517 (0.6473) teacher/usage_min 0.0938 (0.1251) teacher/usage_std 0.2969 (0.2285) nleep/row_max_mean 1535.7024 (1530.0897) nleep/row_max_std 42.1791 (43.6278) nleep/row_min_mean 1502.0159 (1502.4680) lr 1.5358e-03 eta 0:10:48
epoch [18/50] batch [40/132] time 0.078 (0.133) data 0.000 (0.010) loss 1.2030 (1.2425) teacher_loss 0.1477 (0.1272) loss_zs_kd 0.0103 (0.0103) loss_oracle 0.5476 (0.5698) kd_loss 0.7763 (0.8252) acc 93.7500 (95.3906) gate/entropy 1.0123 (1.0128) gate/usage_max 0.5318 (0.5311) gate/usage_min 0.2060 (0.2061) gate/usage_std 0.1422 (0.1417) teacher/entropy 0.0959 (0.0811) teacher/usage_max 0.6848 (0.6477) teacher/usage_min 0.0810 (0.1124) teacher/usage_std 0.2563 (0.2328) nleep/row_max_mean 1536.5853 (1531.8262) nleep/row_max_std 26.2553 (41.1955) nleep/row_min_mean 1507.6394 (1504.1628) lr 1.5358e-03 eta 0:09:34
epoch [18/50] batch [60/132] time 0.133 (0.124) data 0.000 (0.007) loss 1.4426 (1.2513) teacher_loss 0.2409 (0.1313) loss_zs_kd 0.0169 (0.0095) loss_oracle 0.5892 (0.5655) kd_loss 0.8987 (0.8325) acc 90.6250 (95.4167) gate/entropy 1.0128 (1.0127) gate/usage_max 0.5311 (0.5312) gate/usage_min 0.2061 (0.2061) gate/usage_std 0.1418 (0.1418) teacher/entropy 0.0647 (0.0766) teacher/usage_max 0.5666 (0.6439) teacher/usage_min 0.1161 (0.1107) teacher/usage_std 0.1842 (0.2312) nleep/row_max_mean 1534.3457 (1533.2275) nleep/row_max_std 42.4934 (40.4537) nleep/row_min_mean 1507.0974 (1505.2203) lr 1.5358e-03 eta 0:08:52
epoch [18/50] batch [80/132] time 0.089 (0.124) data 0.000 (0.005) loss 1.0709 (1.2486) teacher_loss 0.0080 (0.1336) loss_zs_kd 0.0000 (0.0097) loss_oracle 0.5960 (0.5681) kd_loss 0.7649 (0.8261) acc 100.0000 (95.3125) gate/entropy 1.0124 (1.0127) gate/usage_max 0.5316 (0.5313) gate/usage_min 0.2061 (0.2061) gate/usage_std 0.1421 (0.1418) teacher/entropy 0.0507 (0.0782) teacher/usage_max 0.7372 (0.6488) teacher/usage_min 0.0080 (0.1052) teacher/usage_std 0.3029 (0.2350) nleep/row_max_mean 1550.4656 (1533.8312) nleep/row_max_std 26.8507 (39.9451) nleep/row_min_mean 1519.8895 (1505.6284) lr 1.5358e-03 eta 0:08:48
epoch [18/50] batch [100/132] time 0.091 (0.122) data 0.000 (0.004) loss 1.3247 (1.2493) teacher_loss 0.1402 (0.1332) loss_zs_kd 0.0126 (0.0096) loss_oracle 0.5453 (0.5729) kd_loss 0.9057 (0.8248) acc 96.8750 (95.4062) gate/entropy 1.0122 (1.0126) gate/usage_max 0.5319 (0.5314) gate/usage_min 0.2059 (0.2061) gate/usage_std 0.1423 (0.1419) teacher/entropy 0.0880 (0.0814) teacher/usage_max 0.5333 (0.6447) teacher/usage_min 0.1431 (0.1023) teacher/usage_std 0.1595 (0.2333) nleep/row_max_mean 1531.8020 (1533.7179) nleep/row_max_std 40.1776 (39.9282) nleep/row_min_mean 1505.0555 (1505.3465) lr 1.5358e-03 eta 0:08:41
epoch [18/50] batch [120/132] time 0.128 (0.119) data 0.000 (0.003) loss 1.3279 (1.2550) teacher_loss 0.0417 (0.1359) loss_zs_kd 0.0080 (0.0097) loss_oracle 0.5851 (0.5763) kd_loss 0.9896 (0.8262) acc 100.0000 (95.3906) gate/entropy 1.0127 (1.0125) gate/usage_max 0.5312 (0.5314) gate/usage_min 0.2058 (0.2060) gate/usage_std 0.1418 (0.1420) teacher/entropy 0.1096 (0.0818) teacher/usage_max 0.5739 (0.6427) teacher/usage_min 0.0681 (0.0989) teacher/usage_std 0.2072 (0.2330) nleep/row_max_mean 1524.8467 (1533.7418) nleep/row_max_std 42.8334 (39.6640) nleep/row_min_mean 1498.6987 (1505.2041) lr 1.5358e-03 eta 0:08:23
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,520
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 92.1%
******* Domain s best val acc:      99.5%, epoch: 17 *******
******* Domain s best val test acc: 90.6%, epoch: 17 *******
******* Domain s best test acc:     90.6%, epoch: 17 *******
epoch [19/50] batch [20/132] time 0.156 (0.161) data 0.000 (0.014) loss 1.2557 (1.2664) teacher_loss 0.1022 (0.1125) loss_zs_kd 0.0108 (0.0105) loss_oracle 0.5831 (0.6124) kd_loss 0.8565 (0.8425) acc 96.8750 (96.4062) gate/entropy 1.0128 (1.0127) gate/usage_max 0.5308 (0.5309) gate/usage_min 0.2052 (0.2055) gate/usage_std 0.1417 (0.1417) teacher/entropy 0.0511 (0.0893) teacher/usage_max 0.6302 (0.5979) teacher/usage_min 0.0657 (0.0773) teacher/usage_std 0.2314 (0.2156) nleep/row_max_mean 1543.7004 (1535.3075) nleep/row_max_std 35.8358 (38.6668) nleep/row_min_mean 1512.7463 (1505.5266) lr 1.4818e-03 eta 0:11:17
epoch [19/50] batch [40/132] time 0.159 (0.159) data 0.000 (0.007) loss 1.3312 (1.2758) teacher_loss 0.1767 (0.1084) loss_zs_kd 0.0154 (0.0108) loss_oracle 0.6638 (0.6236) kd_loss 0.8148 (0.8502) acc 96.8750 (96.5625) gate/entropy 1.0138 (1.0131) gate/usage_max 0.5292 (0.5304) gate/usage_min 0.2047 (0.2052) gate/usage_std 0.1407 (0.1414) teacher/entropy 0.1211 (0.0962) teacher/usage_max 0.5957 (0.5841) teacher/usage_min 0.0907 (0.0730) teacher/usage_std 0.2067 (0.2135) nleep/row_max_mean 1529.8213 (1532.5103) nleep/row_max_std 35.0368 (38.3132) nleep/row_min_mean 1500.5953 (1503.2084) lr 1.4818e-03 eta 0:11:05
epoch [19/50] batch [60/132] time 0.170 (0.160) data 0.001 (0.005) loss 1.5020 (1.2907) teacher_loss 0.2754 (0.1177) loss_zs_kd 0.0167 (0.0105) loss_oracle 0.6751 (0.6230) kd_loss 0.8806 (0.8563) acc 87.5000 (96.1979) gate/entropy 1.0148 (1.0134) gate/usage_max 0.5274 (0.5298) gate/usage_min 0.2043 (0.2050) gate/usage_std 0.1397 (0.1411) teacher/entropy 0.0923 (0.0999) teacher/usage_max 0.5330 (0.5738) teacher/usage_min 0.0766 (0.0769) teacher/usage_std 0.1906 (0.2076) nleep/row_max_mean 1512.9290 (1531.3156) nleep/row_max_std 33.9832 (37.8509) nleep/row_min_mean 1483.3103 (1502.2579) lr 1.4818e-03 eta 0:11:05
epoch [19/50] batch [80/132] time 0.138 (0.159) data 0.000 (0.004) loss 1.2786 (1.2997) teacher_loss 0.1125 (0.1207) loss_zs_kd 0.0160 (0.0107) loss_oracle 0.5637 (0.6192) kd_loss 0.8763 (0.8642) acc 93.7500 (95.9375) gate/entropy 1.0154 (1.0138) gate/usage_max 0.5263 (0.5291) gate/usage_min 0.2036 (0.2047) gate/usage_std 0.1391 (0.1407) teacher/entropy 0.0850 (0.0972) teacher/usage_max 0.5439 (0.5665) teacher/usage_min 0.0625 (0.0784) teacher/usage_std 0.2011 (0.2045) nleep/row_max_mean 1524.3405 (1531.1833) nleep/row_max_std 44.5845 (36.9977) nleep/row_min_mean 1494.7363 (1502.3053) lr 1.4818e-03 eta 0:10:56
epoch [19/50] batch [100/132] time 0.151 (0.153) data 0.000 (0.003) loss 1.4896 (1.3071) teacher_loss 0.1796 (0.1216) loss_zs_kd 0.0023 (0.0108) loss_oracle 0.6535 (0.6170) kd_loss 0.9821 (0.8716) acc 93.7500 (95.7812) gate/entropy 1.0165 (1.0142) gate/usage_max 0.5244 (0.5284) gate/usage_min 0.2032 (0.2044) gate/usage_std 0.1380 (0.1403) teacher/entropy 0.0506 (0.0946) teacher/usage_max 0.4629 (0.5609) teacher/usage_min 0.1325 (0.0845) teacher/usage_std 0.1440 (0.1996) nleep/row_max_mean 1535.5465 (1531.1305) nleep/row_max_std 36.8619 (37.4973) nleep/row_min_mean 1508.2119 (1502.3364) lr 1.4818e-03 eta 0:10:32
epoch [19/50] batch [120/132] time 0.141 (0.154) data 0.000 (0.002) loss 1.2175 (1.3063) teacher_loss 0.0023 (0.1207) loss_zs_kd 0.0142 (0.0106) loss_oracle 0.6084 (0.6158) kd_loss 0.9039 (0.8724) acc 100.0000 (95.8333) gate/entropy 1.0170 (1.0146) gate/usage_max 0.5235 (0.5277) gate/usage_min 0.2028 (0.2042) gate/usage_std 0.1375 (0.1399) teacher/entropy 0.1097 (0.0934) teacher/usage_max 0.5038 (0.5600) teacher/usage_min 0.1568 (0.0869) teacher/usage_std 0.1417 (0.1984) nleep/row_max_mean 1533.7053 (1530.9119) nleep/row_max_std 29.2900 (37.4714) nleep/row_min_mean 1505.1233 (1502.2243) lr 1.4818e-03 eta 0:10:32
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,535
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 92.3%
******* Domain s best val acc:      99.5%, epoch: 17 *******
******* Domain s best val test acc: 90.6%, epoch: 17 *******
******* Domain s best test acc:     90.6%, epoch: 17 *******
epoch [20/50] batch [20/132] time 0.131 (0.116) data 0.000 (0.014) loss 1.2146 (1.2923) teacher_loss 0.1237 (0.1408) loss_zs_kd 0.0222 (0.0143) loss_oracle 0.6011 (0.5923) kd_loss 0.7793 (0.8482) acc 96.8750 (95.4688) gate/entropy 1.0167 (1.0168) gate/usage_max 0.5238 (0.5237) gate/usage_min 0.2023 (0.2024) gate/usage_std 0.1378 (0.1377) teacher/entropy 0.1057 (0.0790) teacher/usage_max 0.6445 (0.6111) teacher/usage_min 0.0313 (0.0996) teacher/usage_std 0.2504 (0.2188) nleep/row_max_mean 1537.3931 (1529.5010) nleep/row_max_std 37.8199 (38.6196) nleep/row_min_mean 1504.3063 (1499.9213) lr 1.4258e-03 eta 0:07:50
epoch [20/50] batch [40/132] time 0.142 (0.104) data 0.000 (0.007) loss 1.2661 (1.2936) teacher_loss 0.0369 (0.1309) loss_zs_kd 0.0087 (0.0139) loss_oracle 0.5863 (0.5930) kd_loss 0.9317 (0.8593) acc 96.8750 (95.5469) gate/entropy 1.0170 (1.0168) gate/usage_max 0.5232 (0.5236) gate/usage_min 0.2021 (0.2023) gate/usage_std 0.1375 (0.1377) teacher/entropy 0.0877 (0.0774) teacher/usage_max 0.5168 (0.5959) teacher/usage_min 0.2055 (0.0983) teacher/usage_std 0.1330 (0.2115) nleep/row_max_mean 1541.3068 (1530.1503) nleep/row_max_std 33.5267 (39.2205) nleep/row_min_mean 1509.7893 (1500.2691) lr 1.4258e-03 eta 0:07:00
epoch [20/50] batch [60/132] time 0.068 (0.100) data 0.000 (0.005) loss 1.2664 (1.2859) teacher_loss 0.0943 (0.1220) loss_zs_kd 0.0182 (0.0140) loss_oracle 0.5958 (0.5888) kd_loss 0.8651 (0.8624) acc 96.8750 (95.7812) gate/entropy 1.0174 (1.0170) gate/usage_max 0.5224 (0.5232) gate/usage_min 0.2017 (0.2022) gate/usage_std 0.1371 (0.1375) teacher/entropy 0.0771 (0.0824) teacher/usage_max 0.6132 (0.5850) teacher/usage_min 0.1534 (0.0941) teacher/usage_std 0.2006 (0.2083) nleep/row_max_mean 1529.2307 (1529.8543) nleep/row_max_std 44.0129 (40.4998) nleep/row_min_mean 1498.0452 (1499.9231) lr 1.4258e-03 eta 0:06:42
epoch [20/50] batch [80/132] time 0.095 (0.101) data 0.000 (0.004) loss 1.4133 (1.2915) teacher_loss 0.2414 (0.1253) loss_zs_kd 0.0251 (0.0134) loss_oracle 0.6178 (0.5836) kd_loss 0.8505 (0.8677) acc 90.6250 (95.5859) gate/entropy 1.0173 (1.0172) gate/usage_max 0.5222 (0.5229) gate/usage_min 0.2011 (0.2020) gate/usage_std 0.1371 (0.1373) teacher/entropy 0.0354 (0.0796) teacher/usage_max 0.6417 (0.5816) teacher/usage_min 0.0313 (0.0929) teacher/usage_std 0.2492 (0.2065) nleep/row_max_mean 1530.3973 (1530.1264) nleep/row_max_std 49.9206 (41.5767) nleep/row_min_mean 1495.9558 (1499.9037) lr 1.4258e-03 eta 0:06:46
epoch [20/50] batch [100/132] time 0.076 (0.101) data 0.000 (0.003) loss 1.4727 (1.2864) teacher_loss 0.1747 (0.1233) loss_zs_kd 0.0155 (0.0129) loss_oracle 0.6838 (0.5800) kd_loss 0.9484 (0.8666) acc 93.7500 (95.5938) gate/entropy 1.0184 (1.0174) gate/usage_max 0.5205 (0.5225) gate/usage_min 0.2011 (0.2019) gate/usage_std 0.1360 (0.1371) teacher/entropy 0.1122 (0.0832) teacher/usage_max 0.5392 (0.5796) teacher/usage_min 0.0764 (0.0932) teacher/usage_std 0.1924 (0.2052) nleep/row_max_mean 1521.8771 (1529.9682) nleep/row_max_std 54.6539 (42.4435) nleep/row_min_mean 1493.1053 (1499.7152) lr 1.4258e-03 eta 0:06:44
epoch [20/50] batch [120/132] time 0.192 (0.103) data 0.000 (0.002) loss 1.4758 (1.2886) teacher_loss 0.3992 (0.1251) loss_zs_kd 0.0152 (0.0128) loss_oracle 0.5594 (0.5836) kd_loss 0.7893 (0.8652) acc 84.3750 (95.5990) gate/entropy 1.0185 (1.0176) gate/usage_max 0.5202 (0.5221) gate/usage_min 0.2006 (0.2017) gate/usage_std 0.1360 (0.1369) teacher/entropy 0.0657 (0.0831) teacher/usage_max 0.7105 (0.5799) teacher/usage_min 0.0684 (0.0923) teacher/usage_std 0.2738 (0.2058) nleep/row_max_mean 1516.4863 (1529.3773) nleep/row_max_std 46.0126 (43.4743) nleep/row_min_mean 1484.5725 (1499.0747) lr 1.4258e-03 eta 0:06:50
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,547
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.6%
******* Domain s best val acc:      99.5%, epoch: 17 *******
******* Domain s best val test acc: 90.6%, epoch: 17 *******
******* Domain s best test acc:     90.6%, epoch: 17 *******
epoch [21/50] batch [20/132] time 0.170 (0.183) data 0.000 (0.016) loss 1.2613 (1.2859) teacher_loss 0.0322 (0.1244) loss_zs_kd 0.0058 (0.0116) loss_oracle 0.6228 (0.6034) kd_loss 0.9147 (0.8541) acc 100.0000 (96.4062) gate/entropy 1.0198 (1.0193) gate/usage_max 0.5176 (0.5186) gate/usage_min 0.2000 (0.2001) gate/usage_std 0.1346 (0.1351) teacher/entropy 0.0974 (0.1030) teacher/usage_max 0.4742 (0.5720) teacher/usage_min 0.1096 (0.0851) teacher/usage_std 0.1600 (0.2054) nleep/row_max_mean 1530.3022 (1532.1717) nleep/row_max_std 40.9906 (43.4112) nleep/row_min_mean 1503.1584 (1501.2075) lr 1.3681e-03 eta 0:12:01
epoch [21/50] batch [40/132] time 0.158 (0.173) data 0.000 (0.008) loss 1.2733 (1.2944) teacher_loss 0.1769 (0.1232) loss_zs_kd 0.0229 (0.0136) loss_oracle 0.5910 (0.6059) kd_loss 0.7894 (0.8614) acc 90.6250 (96.0938) gate/entropy 1.0201 (1.0195) gate/usage_max 0.5167 (0.5180) gate/usage_min 0.1993 (0.1999) gate/usage_std 0.1342 (0.1348) teacher/entropy 0.1121 (0.0960) teacher/usage_max 0.6220 (0.5654) teacher/usage_min 0.0463 (0.0918) teacher/usage_std 0.2350 (0.2012) nleep/row_max_mean 1530.3362 (1532.4650) nleep/row_max_std 52.5402 (43.6431) nleep/row_min_mean 1500.6382 (1501.8256) lr 1.3681e-03 eta 0:11:17
epoch [21/50] batch [60/132] time 0.140 (0.166) data 0.000 (0.005) loss 1.2429 (1.2940) teacher_loss 0.0684 (0.1261) loss_zs_kd 0.0107 (0.0134) loss_oracle 0.5481 (0.6014) kd_loss 0.8951 (0.8605) acc 96.8750 (95.9375) gate/entropy 1.0203 (1.0198) gate/usage_max 0.5162 (0.5174) gate/usage_min 0.1990 (0.1996) gate/usage_std 0.1339 (0.1345) teacher/entropy 0.0778 (0.0901) teacher/usage_max 0.5708 (0.5743) teacher/usage_min 0.1627 (0.0938) teacher/usage_std 0.1732 (0.2034) nleep/row_max_mean 1537.0037 (1530.5618) nleep/row_max_std 43.5204 (44.5444) nleep/row_min_mean 1506.7148 (1500.1853) lr 1.3681e-03 eta 0:10:46
epoch [21/50] batch [80/132] time 0.136 (0.162) data 0.000 (0.004) loss 1.1263 (1.2843) teacher_loss 0.1218 (0.1245) loss_zs_kd 0.0096 (0.0137) loss_oracle 0.5066 (0.5960) kd_loss 0.7464 (0.8550) acc 93.7500 (95.7812) gate/entropy 1.0203 (1.0200) gate/usage_max 0.5161 (0.5170) gate/usage_min 0.1988 (0.1995) gate/usage_std 0.1339 (0.1343) teacher/entropy 0.1057 (0.0910) teacher/usage_max 0.7201 (0.5827) teacher/usage_min 0.0715 (0.0958) teacher/usage_std 0.2791 (0.2065) nleep/row_max_mean 1525.0413 (1530.7735) nleep/row_max_std 52.0284 (44.2031) nleep/row_min_mean 1496.2627 (1500.6118) lr 1.3681e-03 eta 0:10:27
epoch [21/50] batch [100/132] time 0.148 (0.158) data 0.000 (0.003) loss 1.3622 (1.2821) teacher_loss 0.1991 (0.1227) loss_zs_kd 0.0131 (0.0138) loss_oracle 0.5555 (0.5944) kd_loss 0.8788 (0.8553) acc 93.7500 (95.9375) gate/entropy 1.0210 (1.0201) gate/usage_max 0.5150 (0.5167) gate/usage_min 0.1988 (0.1993) gate/usage_std 0.1333 (0.1342) teacher/entropy 0.0749 (0.0883) teacher/usage_max 0.6020 (0.5874) teacher/usage_min 0.1604 (0.0980) teacher/usage_std 0.1926 (0.2072) nleep/row_max_mean 1526.0875 (1530.5478) nleep/row_max_std 45.3380 (43.9396) nleep/row_min_mean 1498.4539 (1500.5179) lr 1.3681e-03 eta 0:10:10
epoch [21/50] batch [120/132] time 0.122 (0.157) data 0.000 (0.003) loss 1.1720 (1.2732) teacher_loss 0.0619 (0.1150) loss_zs_kd 0.0148 (0.0136) loss_oracle 0.6131 (0.5914) kd_loss 0.7962 (0.8557) acc 93.7500 (96.1458) gate/entropy 1.0211 (1.0202) gate/usage_max 0.5146 (0.5165) gate/usage_min 0.1986 (0.1992) gate/usage_std 0.1332 (0.1341) teacher/entropy 0.0996 (0.0866) teacher/usage_max 0.6601 (0.5893) teacher/usage_min 0.0955 (0.0993) teacher/usage_std 0.2389 (0.2071) nleep/row_max_mean 1528.8677 (1530.7998) nleep/row_max_std 29.8308 (42.6843) nleep/row_min_mean 1499.0631 (1500.8120) lr 1.3681e-03 eta 0:10:02
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,530
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 92.2%
******* Domain s best val acc:      99.5%, epoch: 17 *******
******* Domain s best val test acc: 90.6%, epoch: 17 *******
******* Domain s best test acc:     90.6%, epoch: 17 *******
epoch [22/50] batch [20/132] time 0.065 (0.128) data 0.000 (0.015) loss 1.4414 (1.2970) teacher_loss 0.1800 (0.0925) loss_zs_kd 0.0131 (0.0128) loss_oracle 0.6228 (0.6074) kd_loss 0.9435 (0.8944) acc 93.7500 (96.8750) gate/entropy 1.0212 (1.0211) gate/usage_max 0.5140 (0.5144) gate/usage_min 0.1979 (0.1981) gate/usage_std 0.1330 (0.1331) teacher/entropy 0.1011 (0.0671) teacher/usage_max 0.4348 (0.5559) teacher/usage_min 0.1355 (0.1057) teacher/usage_std 0.1399 (0.1931) nleep/row_max_mean 1541.4227 (1534.1231) nleep/row_max_std 35.0822 (35.9368) nleep/row_min_mean 1513.3860 (1505.5080) lr 1.3090e-03 eta 0:08:05
epoch [22/50] batch [40/132] time 0.117 (0.113) data 0.001 (0.008) loss 1.2277 (1.2945) teacher_loss 0.0918 (0.0971) loss_zs_kd 0.0042 (0.0116) loss_oracle 0.5807 (0.6111) kd_loss 0.8434 (0.8860) acc 96.8750 (96.5625) gate/entropy 1.0217 (1.0213) gate/usage_max 0.5128 (0.5138) gate/usage_min 0.1974 (0.1979) gate/usage_std 0.1324 (0.1329) teacher/entropy 0.0892 (0.0816) teacher/usage_max 0.6099 (0.5464) teacher/usage_min 0.1148 (0.1022) teacher/usage_std 0.2062 (0.1899) nleep/row_max_mean 1528.6731 (1529.5367) nleep/row_max_std 31.1740 (39.0404) nleep/row_min_mean 1500.9503 (1501.5336) lr 1.3090e-03 eta 0:07:08
epoch [22/50] batch [60/132] time 0.159 (0.118) data 0.000 (0.005) loss 1.4283 (1.3331) teacher_loss 0.0755 (0.1105) loss_zs_kd 0.0110 (0.0114) loss_oracle 0.6318 (0.6172) kd_loss 1.0314 (0.9083) acc 96.8750 (95.8333) gate/entropy 1.0227 (1.0216) gate/usage_max 0.5107 (0.5132) gate/usage_min 0.1969 (0.1977) gate/usage_std 0.1313 (0.1325) teacher/entropy 0.0549 (0.0794) teacher/usage_max 0.4789 (0.5301) teacher/usage_min 0.1560 (0.1095) teacher/usage_std 0.1337 (0.1794) nleep/row_max_mean 1538.6847 (1528.6410) nleep/row_max_std 35.2121 (38.4652) nleep/row_min_mean 1509.5115 (1501.1135) lr 1.3090e-03 eta 0:07:25
epoch [22/50] batch [80/132] time 0.071 (0.116) data 0.000 (0.004) loss 1.2970 (1.3417) teacher_loss 0.0511 (0.1140) loss_zs_kd 0.0183 (0.0128) loss_oracle 0.5795 (0.6205) kd_loss 0.9470 (0.9110) acc 100.0000 (95.8203) gate/entropy 1.0233 (1.0220) gate/usage_max 0.5088 (0.5123) gate/usage_min 0.1958 (0.1973) gate/usage_std 0.1306 (0.1321) teacher/entropy 0.0667 (0.0816) teacher/usage_max 0.4538 (0.5249) teacher/usage_min 0.1029 (0.1075) teacher/usage_std 0.1630 (0.1782) nleep/row_max_mean 1532.1079 (1527.9851) nleep/row_max_std 25.9581 (38.5720) nleep/row_min_mean 1504.4902 (1500.6267) lr 1.3090e-03 eta 0:07:14
epoch [22/50] batch [100/132] time 0.063 (0.115) data 0.000 (0.003) loss 1.3648 (1.3447) teacher_loss 0.0673 (0.1110) loss_zs_kd 0.0057 (0.0125) loss_oracle 0.6698 (0.6151) kd_loss 0.9598 (0.9199) acc 96.8750 (96.0625) gate/entropy 1.0246 (1.0224) gate/usage_max 0.5057 (0.5113) gate/usage_min 0.1951 (0.1970) gate/usage_std 0.1291 (0.1317) teacher/entropy 0.0823 (0.0798) teacher/usage_max 0.4693 (0.5202) teacher/usage_min 0.1224 (0.1095) teacher/usage_std 0.1512 (0.1755) nleep/row_max_mean 1528.9397 (1527.4582) nleep/row_max_std 31.8821 (38.4560) nleep/row_min_mean 1501.0566 (1500.3298) lr 1.3090e-03 eta 0:07:06
epoch [22/50] batch [120/132] time 0.149 (0.116) data 0.000 (0.003) loss 1.3504 (1.3418) teacher_loss 0.0779 (0.1103) loss_zs_kd 0.0063 (0.0125) loss_oracle 0.5673 (0.6084) kd_loss 0.9856 (0.9209) acc 96.8750 (96.0938) gate/entropy 1.0250 (1.0228) gate/usage_max 0.5042 (0.5102) gate/usage_min 0.1942 (0.1966) gate/usage_std 0.1285 (0.1312) teacher/entropy 0.0407 (0.0805) teacher/usage_max 0.4429 (0.5154) teacher/usage_min 0.1211 (0.1108) teacher/usage_std 0.1501 (0.1729) nleep/row_max_mean 1529.6675 (1527.0901) nleep/row_max_std 37.9842 (38.6352) nleep/row_min_mean 1504.6470 (1500.1413) lr 1.3090e-03 eta 0:07:11
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,524
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 92.2%
******* Domain s best val acc:      99.5%, epoch: 17 *******
******* Domain s best val test acc: 90.6%, epoch: 17 *******
******* Domain s best test acc:     90.6%, epoch: 17 *******
epoch [23/50] batch [20/132] time 0.169 (0.174) data 0.000 (0.013) loss 1.3240 (1.3726) teacher_loss 0.1164 (0.1263) loss_zs_kd 0.0139 (0.0136) loss_oracle 0.5806 (0.5974) kd_loss 0.9103 (0.9408) acc 96.8750 (95.0000) gate/entropy 1.0262 (1.0258) gate/usage_max 0.5007 (0.5018) gate/usage_min 0.1929 (0.1933) gate/usage_std 0.1271 (0.1276) teacher/entropy 0.1479 (0.0792) teacher/usage_max 0.5293 (0.5192) teacher/usage_min 0.1127 (0.1121) teacher/usage_std 0.1710 (0.1722) nleep/row_max_mean 1527.7598 (1530.3844) nleep/row_max_std 39.7733 (35.9803) nleep/row_min_mean 1503.5305 (1503.6631) lr 1.2487e-03 eta 0:10:39
epoch [23/50] batch [40/132] time 0.142 (0.165) data 0.000 (0.007) loss 1.3087 (1.3719) teacher_loss 0.0488 (0.1246) loss_zs_kd 0.0093 (0.0128) loss_oracle 0.6210 (0.5994) kd_loss 0.9447 (0.9412) acc 100.0000 (95.5469) gate/entropy 1.0268 (1.0262) gate/usage_max 0.4988 (0.5008) gate/usage_min 0.1922 (0.1929) gate/usage_std 0.1264 (0.1272) teacher/entropy 0.0776 (0.0717) teacher/usage_max 0.4911 (0.5144) teacher/usage_min 0.1792 (0.1167) teacher/usage_std 0.1273 (0.1679) nleep/row_max_mean 1529.2852 (1531.3788) nleep/row_max_std 38.2822 (37.7993) nleep/row_min_mean 1500.3260 (1504.2501) lr 1.2487e-03 eta 0:10:03
epoch [23/50] batch [60/132] time 0.161 (0.163) data 0.000 (0.005) loss 1.3870 (1.3627) teacher_loss 0.1316 (0.1242) loss_zs_kd 0.0132 (0.0132) loss_oracle 0.6700 (0.6033) kd_loss 0.9138 (0.9303) acc 96.8750 (95.7812) gate/entropy 1.0267 (1.0264) gate/usage_max 0.4982 (0.5000) gate/usage_min 0.1915 (0.1925) gate/usage_std 0.1263 (0.1269) teacher/entropy 0.0049 (0.0720) teacher/usage_max 0.6553 (0.5205) teacher/usage_min 0.1250 (0.1148) teacher/usage_std 0.2309 (0.1717) nleep/row_max_mean 1543.6986 (1531.4925) nleep/row_max_std 30.5521 (38.0467) nleep/row_min_mean 1511.5366 (1504.2387) lr 1.2487e-03 eta 0:09:52
epoch [23/50] batch [80/132] time 0.131 (0.160) data 0.000 (0.004) loss 1.3766 (1.3569) teacher_loss 0.0803 (0.1188) loss_zs_kd 0.0022 (0.0131) loss_oracle 0.5480 (0.6005) kd_loss 1.0212 (0.9312) acc 96.8750 (95.9375) gate/entropy 1.0273 (1.0266) gate/usage_max 0.4967 (0.4993) gate/usage_min 0.1911 (0.1922) gate/usage_std 0.1257 (0.1266) teacher/entropy 0.0410 (0.0721) teacher/usage_max 0.4745 (0.5138) teacher/usage_min 0.2440 (0.1164) teacher/usage_std 0.1010 (0.1691) nleep/row_max_mean 1535.0508 (1531.8061) nleep/row_max_std 42.6651 (37.6655) nleep/row_min_mean 1510.2058 (1504.7000) lr 1.2487e-03 eta 0:09:37
epoch [23/50] batch [100/132] time 0.094 (0.154) data 0.000 (0.003) loss 1.2080 (1.3635) teacher_loss 0.0181 (0.1175) loss_zs_kd 0.0067 (0.0126) loss_oracle 0.6573 (0.6072) kd_loss 0.8580 (0.9361) acc 100.0000 (95.9062) gate/entropy 1.0277 (1.0268) gate/usage_max 0.4950 (0.4985) gate/usage_min 0.1904 (0.1920) gate/usage_std 0.1250 (0.1263) teacher/entropy 0.0729 (0.0702) teacher/usage_max 0.5625 (0.5114) teacher/usage_min 0.0615 (0.1213) teacher/usage_std 0.2068 (0.1663) nleep/row_max_mean 1531.4905 (1531.7288) nleep/row_max_std 38.2980 (37.5232) nleep/row_min_mean 1505.9319 (1504.7707) lr 1.2487e-03 eta 0:09:12
epoch [23/50] batch [120/132] time 0.129 (0.146) data 0.000 (0.002) loss 1.4496 (1.3653) teacher_loss 0.1262 (0.1215) loss_zs_kd 0.0172 (0.0127) loss_oracle 0.6206 (0.6080) kd_loss 1.0045 (0.9335) acc 93.7500 (95.7031) gate/entropy 1.0280 (1.0270) gate/usage_max 0.4938 (0.4978) gate/usage_min 0.1900 (0.1917) gate/usage_std 0.1246 (0.1261) teacher/entropy 0.0556 (0.0715) teacher/usage_max 0.4664 (0.5109) teacher/usage_min 0.1549 (0.1217) teacher/usage_std 0.1312 (0.1661) nleep/row_max_mean 1522.7081 (1531.3544) nleep/row_max_std 40.0355 (37.6692) nleep/row_min_mean 1500.8259 (1504.5358) lr 1.2487e-03 eta 0:08:42
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,540
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.5%
******* Domain s best val acc:      99.5%, epoch: 17 *******
******* Domain s best val test acc: 90.6%, epoch: 17 *******
******* Domain s best test acc:     90.6%, epoch: 17 *******
epoch [24/50] batch [20/132] time 0.182 (0.134) data 0.000 (0.015) loss 1.2813 (1.3700) teacher_loss 0.0197 (0.1286) loss_zs_kd 0.0077 (0.0150) loss_oracle 0.6792 (0.6257) kd_loss 0.9181 (0.9211) acc 100.0000 (95.4688) gate/entropy 1.0287 (1.0285) gate/usage_max 0.4914 (0.4921) gate/usage_min 0.1893 (0.1894) gate/usage_std 0.1237 (0.1240) teacher/entropy 0.0644 (0.0712) teacher/usage_max 0.6093 (0.5126) teacher/usage_min 0.0110 (0.1188) teacher/usage_std 0.2464 (0.1684) nleep/row_max_mean 1519.4207 (1525.9704) nleep/row_max_std 39.6491 (39.4386) nleep/row_min_mean 1494.1050 (1500.1110) lr 1.1874e-03 eta 0:07:53
epoch [24/50] batch [40/132] time 0.097 (0.122) data 0.000 (0.008) loss 1.3825 (1.3825) teacher_loss 0.0952 (0.1343) loss_zs_kd 0.0105 (0.0143) loss_oracle 0.5494 (0.6248) kd_loss 1.0073 (0.9286) acc 96.8750 (95.0781) gate/entropy 1.0289 (1.0286) gate/usage_max 0.4903 (0.4916) gate/usage_min 0.1887 (0.1892) gate/usage_std 0.1234 (0.1239) teacher/entropy 0.0317 (0.0719) teacher/usage_max 0.5618 (0.5108) teacher/usage_min 0.0935 (0.1174) teacher/usage_std 0.1914 (0.1670) nleep/row_max_mean 1516.5391 (1524.8172) nleep/row_max_std 45.4444 (38.0943) nleep/row_min_mean 1490.8684 (1498.7142) lr 1.1874e-03 eta 0:07:11
epoch [24/50] batch [60/132] time 0.072 (0.121) data 0.000 (0.005) loss 1.2432 (1.3653) teacher_loss 0.0545 (0.1241) loss_zs_kd 0.0096 (0.0142) loss_oracle 0.6085 (0.6214) kd_loss 0.8797 (0.9234) acc 96.8750 (95.6771) gate/entropy 1.0289 (1.0287) gate/usage_max 0.4895 (0.4911) gate/usage_min 0.1881 (0.1889) gate/usage_std 0.1233 (0.1237) teacher/entropy 0.0489 (0.0712) teacher/usage_max 0.5642 (0.5143) teacher/usage_min 0.0621 (0.1129) teacher/usage_std 0.2070 (0.1702) nleep/row_max_mean 1529.6564 (1525.5280) nleep/row_max_std 34.2389 (37.8767) nleep/row_min_mean 1503.2891 (1499.1788) lr 1.1874e-03 eta 0:07:04
epoch [24/50] batch [80/132] time 0.137 (0.126) data 0.000 (0.004) loss 1.3292 (1.3583) teacher_loss 0.0773 (0.1130) loss_zs_kd 0.0026 (0.0131) loss_oracle 0.6055 (0.6194) kd_loss 0.9479 (0.9290) acc 96.8750 (96.0938) gate/entropy 1.0296 (1.0288) gate/usage_max 0.4878 (0.4905) gate/usage_min 0.1881 (0.1887) gate/usage_std 0.1225 (0.1235) teacher/entropy 0.1441 (0.0728) teacher/usage_max 0.4960 (0.5109) teacher/usage_min 0.1812 (0.1190) teacher/usage_std 0.1287 (0.1663) nleep/row_max_mean 1522.9580 (1525.5419) nleep/row_max_std 38.9587 (37.7088) nleep/row_min_mean 1497.0708 (1498.9330) lr 1.1874e-03 eta 0:07:17
epoch [24/50] batch [100/132] time 0.148 (0.127) data 0.000 (0.003) loss 1.2442 (1.3533) teacher_loss 0.0605 (0.1115) loss_zs_kd 0.0104 (0.0131) loss_oracle 0.5838 (0.6137) kd_loss 0.8867 (0.9285) acc 100.0000 (96.1562) gate/entropy 1.0295 (1.0289) gate/usage_max 0.4863 (0.4898) gate/usage_min 0.1868 (0.1884) gate/usage_std 0.1224 (0.1233) teacher/entropy 0.0650 (0.0734) teacher/usage_max 0.5137 (0.5100) teacher/usage_min 0.0687 (0.1158) teacher/usage_std 0.1912 (0.1678) nleep/row_max_mean 1528.0934 (1525.1126) nleep/row_max_std 45.4752 (38.3045) nleep/row_min_mean 1499.4758 (1498.3330) lr 1.1874e-03 eta 0:07:20
epoch [24/50] batch [120/132] time 0.145 (0.128) data 0.000 (0.003) loss 1.5384 (1.3546) teacher_loss 0.3886 (0.1163) loss_zs_kd 0.0107 (0.0135) loss_oracle 0.5852 (0.6118) kd_loss 0.8518 (0.9256) acc 93.7500 (96.1458) gate/entropy 1.0298 (1.0291) gate/usage_max 0.4851 (0.4891) gate/usage_min 0.1864 (0.1882) gate/usage_std 0.1220 (0.1231) teacher/entropy 0.0970 (0.0743) teacher/usage_max 0.4883 (0.5089) teacher/usage_min 0.0375 (0.1137) teacher/usage_std 0.2092 (0.1688) nleep/row_max_mean 1525.3392 (1524.9422) nleep/row_max_std 45.3137 (38.8075) nleep/row_min_mean 1497.1760 (1498.0008) lr 1.1874e-03 eta 0:07:21
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,551
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.7%
******* Domain s best val acc:      99.5%, epoch: 17 *******
******* Domain s best val test acc: 90.6%, epoch: 17 *******
******* Domain s best test acc:     90.6%, epoch: 17 *******
epoch [25/50] batch [20/132] time 0.157 (0.169) data 0.000 (0.014) loss 1.2735 (1.3350) teacher_loss 0.0775 (0.1330) loss_zs_kd 0.0107 (0.0135) loss_oracle 0.6454 (0.5951) kd_loss 0.8679 (0.8977) acc 96.8750 (95.0000) gate/entropy 1.0303 (1.0300) gate/usage_max 0.4829 (0.4837) gate/usage_min 0.1858 (0.1859) gate/usage_std 0.1213 (0.1216) teacher/entropy 0.1311 (0.0883) teacher/usage_max 0.6266 (0.5182) teacher/usage_min 0.0373 (0.0951) teacher/usage_std 0.2406 (0.1801) nleep/row_max_mean 1532.2748 (1526.2589) nleep/row_max_std 32.7631 (42.3643) nleep/row_min_mean 1502.7794 (1498.6727) lr 1.1253e-03 eta 0:09:34
epoch [25/50] batch [40/132] time 0.171 (0.167) data 0.000 (0.007) loss 1.4124 (1.3172) teacher_loss 0.2409 (0.1075) loss_zs_kd 0.0154 (0.0115) loss_oracle 0.5937 (0.6067) kd_loss 0.8670 (0.9006) acc 87.5000 (96.0156) gate/entropy 1.0304 (1.0301) gate/usage_max 0.4818 (0.4830) gate/usage_min 0.1853 (0.1857) gate/usage_std 0.1210 (0.1214) teacher/entropy 0.0596 (0.0829) teacher/usage_max 0.5255 (0.5133) teacher/usage_min 0.0372 (0.1002) teacher/usage_std 0.2125 (0.1768) nleep/row_max_mean 1518.6975 (1526.1995) nleep/row_max_std 41.2806 (40.4776) nleep/row_min_mean 1492.1580 (1498.7695) lr 1.1253e-03 eta 0:09:27
epoch [25/50] batch [60/132] time 0.097 (0.158) data 0.001 (0.005) loss 1.3789 (1.3184) teacher_loss 0.1408 (0.1137) loss_zs_kd 0.0145 (0.0122) loss_oracle 0.6235 (0.6076) kd_loss 0.9190 (0.8948) acc 96.8750 (95.8854) gate/entropy 1.0304 (1.0302) gate/usage_max 0.4808 (0.4824) gate/usage_min 0.1847 (0.1854) gate/usage_std 0.1209 (0.1213) teacher/entropy 0.1043 (0.0832) teacher/usage_max 0.4951 (0.5208) teacher/usage_min 0.1836 (0.0966) teacher/usage_std 0.1274 (0.1809) nleep/row_max_mean 1527.8782 (1527.4814) nleep/row_max_std 36.3805 (39.4024) nleep/row_min_mean 1504.0460 (1499.9484) lr 1.1253e-03 eta 0:08:51
epoch [25/50] batch [80/132] time 0.092 (0.144) data 0.001 (0.004) loss 1.2031 (1.3171) teacher_loss 0.0361 (0.1162) loss_zs_kd 0.0038 (0.0124) loss_oracle 0.6275 (0.6051) kd_loss 0.8514 (0.8922) acc 100.0000 (95.7812) gate/entropy 1.0306 (1.0303) gate/usage_max 0.4795 (0.4819) gate/usage_min 0.1842 (0.1852) gate/usage_std 0.1206 (0.1211) teacher/entropy 0.0993 (0.0837) teacher/usage_max 0.4875 (0.5263) teacher/usage_min 0.0577 (0.0925) teacher/usage_std 0.1953 (0.1844) nleep/row_max_mean 1541.2926 (1527.7162) nleep/row_max_std 37.3598 (39.3903) nleep/row_min_mean 1509.4766 (1499.9760) lr 1.1253e-03 eta 0:08:04
epoch [25/50] batch [100/132] time 0.092 (0.138) data 0.000 (0.003) loss 1.2106 (1.3262) teacher_loss 0.0390 (0.1189) loss_zs_kd 0.0127 (0.0127) loss_oracle 0.5788 (0.6049) kd_loss 0.8758 (0.8986) acc 100.0000 (95.6250) gate/entropy 1.0306 (1.0303) gate/usage_max 0.4783 (0.4813) gate/usage_min 0.1836 (0.1849) gate/usage_std 0.1203 (0.1210) teacher/entropy 0.0588 (0.0796) teacher/usage_max 0.5399 (0.5273) teacher/usage_min 0.0623 (0.0935) teacher/usage_std 0.2002 (0.1845) nleep/row_max_mean 1536.5237 (1527.4383) nleep/row_max_std 38.8882 (39.4819) nleep/row_min_mean 1507.0204 (1499.8316) lr 1.1253e-03 eta 0:07:40
epoch [25/50] batch [120/132] time 0.127 (0.135) data 0.000 (0.003) loss 1.3903 (1.3272) teacher_loss 0.2218 (0.1222) loss_zs_kd 0.0254 (0.0134) loss_oracle 0.5313 (0.6001) kd_loss 0.8901 (0.8982) acc 93.7500 (95.5990) gate/entropy 1.0309 (1.0304) gate/usage_max 0.4768 (0.4807) gate/usage_min 0.1832 (0.1847) gate/usage_std 0.1199 (0.1209) teacher/entropy 0.1872 (0.0810) teacher/usage_max 0.6637 (0.5265) teacher/usage_min 0.1179 (0.0921) teacher/usage_std 0.2372 (0.1849) nleep/row_max_mean 1515.5020 (1526.9677) nleep/row_max_std 44.0828 (39.1967) nleep/row_min_mean 1494.1346 (1499.3816) lr 1.1253e-03 eta 0:07:27
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,813
* accuracy: 99.6%
* error: 0.4%
* macro_f1: 99.5%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best.pth.tar
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,526
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.2%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.6%, epoch: 17 *******
epoch [26/50] batch [20/132] time 0.173 (0.133) data 0.000 (0.016) loss 1.3233 (1.2866) teacher_loss 0.1478 (0.1176) loss_zs_kd 0.0098 (0.0117) loss_oracle 0.6283 (0.5608) kd_loss 0.8565 (0.8827) acc 90.6250 (95.4688) gate/entropy 1.0311 (1.0310) gate/usage_max 0.4740 (0.4748) gate/usage_min 0.1821 (0.1823) gate/usage_std 0.1194 (0.1196) teacher/entropy 0.0736 (0.0851) teacher/usage_max 0.5662 (0.5534) teacher/usage_min 0.0723 (0.0594) teacher/usage_std 0.2026 (0.2104) nleep/row_max_mean 1519.9822 (1524.0323) nleep/row_max_std 36.3405 (40.3809) nleep/row_min_mean 1493.9635 (1496.3094) lr 1.0628e-03 eta 0:07:17
epoch [26/50] batch [40/132] time 0.161 (0.143) data 0.000 (0.008) loss 1.2756 (1.2774) teacher_loss 0.1378 (0.1099) loss_zs_kd 0.0006 (0.0105) loss_oracle 0.6029 (0.5597) kd_loss 0.8361 (0.8825) acc 93.7500 (96.4062) gate/entropy 1.0310 (1.0310) gate/usage_max 0.4722 (0.4739) gate/usage_min 0.1811 (0.1819) gate/usage_std 0.1192 (0.1194) teacher/entropy 0.0606 (0.0861) teacher/usage_max 0.5926 (0.5553) teacher/usage_min 0.0330 (0.0592) teacher/usage_std 0.2303 (0.2119) nleep/row_max_mean 1521.4005 (1523.6663) nleep/row_max_std 46.3299 (41.7295) nleep/row_min_mean 1492.1448 (1495.7603) lr 1.0628e-03 eta 0:07:47
epoch [26/50] batch [60/132] time 0.159 (0.147) data 0.000 (0.006) loss 1.3429 (1.2716) teacher_loss 0.1465 (0.1054) loss_zs_kd 0.0081 (0.0103) loss_oracle 0.5793 (0.5601) kd_loss 0.9027 (0.8810) acc 96.8750 (96.5625) gate/entropy 1.0312 (1.0310) gate/usage_max 0.4701 (0.4730) gate/usage_min 0.1805 (0.1815) gate/usage_std 0.1188 (0.1193) teacher/entropy 0.0726 (0.0882) teacher/usage_max 0.6028 (0.5525) teacher/usage_min 0.0442 (0.0592) teacher/usage_std 0.2285 (0.2107) nleep/row_max_mean 1525.9761 (1525.4443) nleep/row_max_std 39.5479 (41.0088) nleep/row_min_mean 1496.5298 (1497.2858) lr 1.0628e-03 eta 0:07:57
epoch [26/50] batch [80/132] time 0.155 (0.151) data 0.000 (0.004) loss 1.2388 (1.2709) teacher_loss 0.0782 (0.1034) loss_zs_kd 0.0270 (0.0106) loss_oracle 0.4876 (0.5577) kd_loss 0.9033 (0.8833) acc 96.8750 (96.5625) gate/entropy 1.0312 (1.0311) gate/usage_max 0.4681 (0.4720) gate/usage_min 0.1795 (0.1811) gate/usage_std 0.1186 (0.1191) teacher/entropy 0.0870 (0.0875) teacher/usage_max 0.4998 (0.5560) teacher/usage_min 0.0938 (0.0596) teacher/usage_std 0.1736 (0.2113) nleep/row_max_mean 1532.4486 (1526.8204) nleep/row_max_std 37.2014 (40.5872) nleep/row_min_mean 1506.7576 (1498.6379) lr 1.0628e-03 eta 0:08:05
epoch [26/50] batch [100/132] time 0.155 (0.151) data 0.000 (0.003) loss 1.1783 (1.2689) teacher_loss 0.0908 (0.1027) loss_zs_kd 0.0036 (0.0110) loss_oracle 0.5045 (0.5537) kd_loss 0.8334 (0.8839) acc 93.7500 (96.5625) gate/entropy 1.0312 (1.0311) gate/usage_max 0.4665 (0.4710) gate/usage_min 0.1789 (0.1807) gate/usage_std 0.1183 (0.1190) teacher/entropy 0.1276 (0.0864) teacher/usage_max 0.4938 (0.5503) teacher/usage_min 0.0883 (0.0625) teacher/usage_std 0.1760 (0.2080) nleep/row_max_mean 1539.3245 (1528.0826) nleep/row_max_std 22.9883 (39.9270) nleep/row_min_mean 1511.9939 (1499.9537) lr 1.0628e-03 eta 0:08:02
epoch [26/50] batch [120/132] time 0.124 (0.149) data 0.000 (0.003) loss 1.1705 (1.2697) teacher_loss 0.0398 (0.1059) loss_zs_kd 0.0047 (0.0110) loss_oracle 0.5383 (0.5490) kd_loss 0.8592 (0.8838) acc 100.0000 (96.4583) gate/entropy 1.0311 (1.0311) gate/usage_max 0.4655 (0.4702) gate/usage_min 0.1784 (0.1804) gate/usage_std 0.1183 (0.1189) teacher/entropy 0.0645 (0.0844) teacher/usage_max 0.6680 (0.5461) teacher/usage_min 0.1024 (0.0652) teacher/usage_std 0.2423 (0.2057) nleep/row_max_mean 1538.3323 (1528.8320) nleep/row_max_std 34.2245 (39.8838) nleep/row_min_mean 1507.9159 (1500.7588) lr 1.0628e-03 eta 0:07:54
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,534
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 92.4%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.6%, epoch: 17 *******
epoch [27/50] batch [20/132] time 0.088 (0.109) data 0.000 (0.013) loss 1.3031 (1.2893) teacher_loss 0.1861 (0.1297) loss_zs_kd 0.0030 (0.0156) loss_oracle 0.4805 (0.5498) kd_loss 0.8753 (0.8768) acc 93.7500 (95.9375) gate/entropy 1.0312 (1.0311) gate/usage_max 0.4650 (0.4651) gate/usage_min 0.1784 (0.1782) gate/usage_std 0.1182 (0.1183) teacher/entropy 0.0786 (0.0767) teacher/usage_max 0.5549 (0.5351) teacher/usage_min 0.1019 (0.0809) teacher/usage_std 0.1851 (0.1929) nleep/row_max_mean 1526.2092 (1529.1572) nleep/row_max_std 46.4860 (41.9697) nleep/row_min_mean 1502.1702 (1502.4397) lr 1.0000e-03 eta 0:05:41
epoch [27/50] batch [40/132] time 0.184 (0.111) data 0.001 (0.007) loss 1.3082 (1.2828) teacher_loss 0.0943 (0.1270) loss_zs_kd 0.0135 (0.0140) loss_oracle 0.6144 (0.5459) kd_loss 0.9000 (0.8758) acc 96.8750 (95.5469) gate/entropy 1.0311 (1.0311) gate/usage_max 0.4647 (0.4649) gate/usage_min 0.1780 (0.1781) gate/usage_std 0.1183 (0.1183) teacher/entropy 0.0766 (0.0793) teacher/usage_max 0.4801 (0.5311) teacher/usage_min 0.1069 (0.0858) teacher/usage_std 0.1624 (0.1899) nleep/row_max_mean 1530.1801 (1529.4551) nleep/row_max_std 42.5508 (39.8824) nleep/row_min_mean 1506.1505 (1503.4240) lr 1.0000e-03 eta 0:05:48
epoch [27/50] batch [60/132] time 0.080 (0.108) data 0.000 (0.005) loss 1.2087 (1.2832) teacher_loss 0.0060 (0.1224) loss_zs_kd 0.0000 (0.0129) loss_oracle 0.5919 (0.5418) kd_loss 0.9067 (0.8835) acc 100.0000 (95.5729) gate/entropy 1.0312 (1.0311) gate/usage_max 0.4644 (0.4647) gate/usage_min 0.1780 (0.1780) gate/usage_std 0.1182 (0.1183) teacher/entropy 0.1022 (0.0791) teacher/usage_max 0.5411 (0.5271) teacher/usage_min 0.1753 (0.0960) teacher/usage_std 0.1534 (0.1841) nleep/row_max_mean 1527.4634 (1530.1645) nleep/row_max_std 45.3334 (39.5295) nleep/row_min_mean 1502.7646 (1504.2517) lr 1.0000e-03 eta 0:05:37
epoch [27/50] batch [80/132] time 0.211 (0.114) data 0.000 (0.004) loss 1.3036 (1.2967) teacher_loss 0.0347 (0.1261) loss_zs_kd 0.0097 (0.0133) loss_oracle 0.5816 (0.5494) kd_loss 0.9733 (0.8893) acc 100.0000 (95.5078) gate/entropy 1.0310 (1.0311) gate/usage_max 0.4643 (0.4646) gate/usage_min 0.1778 (0.1780) gate/usage_std 0.1183 (0.1182) teacher/entropy 0.0556 (0.0801) teacher/usage_max 0.4325 (0.5230) teacher/usage_min 0.1565 (0.1055) teacher/usage_std 0.1254 (0.1780) nleep/row_max_mean 1522.8616 (1529.7936) nleep/row_max_std 44.3541 (40.6716) nleep/row_min_mean 1500.5657 (1504.2570) lr 1.0000e-03 eta 0:05:51
epoch [27/50] batch [100/132] time 0.088 (0.117) data 0.000 (0.003) loss 1.2914 (1.3001) teacher_loss 0.0812 (0.1275) loss_zs_kd 0.0095 (0.0129) loss_oracle 0.5584 (0.5516) kd_loss 0.9262 (0.8903) acc 96.8750 (95.5000) gate/entropy 1.0312 (1.0311) gate/usage_max 0.4641 (0.4645) gate/usage_min 0.1779 (0.1779) gate/usage_std 0.1181 (0.1182) teacher/entropy 0.0389 (0.0818) teacher/usage_max 0.4956 (0.5231) teacher/usage_min 0.0956 (0.1101) teacher/usage_std 0.1718 (0.1766) nleep/row_max_mean 1527.1642 (1529.1632) nleep/row_max_std 35.3462 (40.6941) nleep/row_min_mean 1502.2988 (1503.9418) lr 1.0000e-03 eta 0:05:57
epoch [27/50] batch [120/132] time 0.167 (0.115) data 0.000 (0.002) loss 1.3234 (1.3027) teacher_loss 0.0746 (0.1242) loss_zs_kd 0.0117 (0.0124) loss_oracle 0.5914 (0.5572) kd_loss 0.9473 (0.8937) acc 96.8750 (95.4688) gate/entropy 1.0310 (1.0311) gate/usage_max 0.4642 (0.4644) gate/usage_min 0.1778 (0.1779) gate/usage_std 0.1182 (0.1182) teacher/entropy 0.1386 (0.0811) teacher/usage_max 0.4107 (0.5255) teacher/usage_min 0.2383 (0.1141) teacher/usage_std 0.0715 (0.1754) nleep/row_max_mean 1522.9385 (1528.8707) nleep/row_max_std 33.5367 (40.2299) nleep/row_min_mean 1501.0436 (1503.8593) lr 1.0000e-03 eta 0:05:50
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,805
* accuracy: 99.1%
* error: 0.9%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,559
* accuracy: 90.6%
* error: 9.4%
* macro_f1: 92.8%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.6%, epoch: 17 *******
epoch [28/50] batch [20/132] time 0.160 (0.175) data 0.000 (0.018) loss 1.5016 (1.3679) teacher_loss 0.2009 (0.1413) loss_zs_kd 0.0093 (0.0175) loss_oracle 0.5395 (0.5790) kd_loss 1.0263 (0.9283) acc 90.6250 (95.4688) gate/entropy 1.0311 (1.0310) gate/usage_max 0.4643 (0.4641) gate/usage_min 0.1779 (0.1777) gate/usage_std 0.1182 (0.1182) teacher/entropy 0.1257 (0.0937) teacher/usage_max 0.3537 (0.4994) teacher/usage_min 0.3119 (0.1677) teacher/usage_std 0.0171 (0.1419) nleep/row_max_mean 1523.3627 (1524.5102) nleep/row_max_std 50.1796 (40.4923) nleep/row_min_mean 1501.9235 (1501.5927) lr 9.3721e-04 eta 0:08:47
epoch [28/50] batch [40/132] time 0.133 (0.161) data 0.000 (0.009) loss 1.5217 (1.3609) teacher_loss 0.2430 (0.1370) loss_zs_kd 0.0038 (0.0145) loss_oracle 0.6121 (0.5748) kd_loss 0.9708 (0.9292) acc 90.6250 (95.6250) gate/entropy 1.0310 (1.0310) gate/usage_max 0.4644 (0.4642) gate/usage_min 0.1778 (0.1777) gate/usage_std 0.1183 (0.1182) teacher/entropy 0.0529 (0.0869) teacher/usage_max 0.5615 (0.5260) teacher/usage_min 0.2053 (0.1697) teacher/usage_std 0.1617 (0.1530) nleep/row_max_mean 1545.0037 (1526.5381) nleep/row_max_std 33.2952 (40.4375) nleep/row_min_mean 1516.9514 (1503.1387) lr 9.3721e-04 eta 0:08:03
epoch [28/50] batch [60/132] time 0.152 (0.157) data 0.000 (0.006) loss 1.2826 (1.3450) teacher_loss 0.1299 (0.1307) loss_zs_kd 0.0099 (0.0140) loss_oracle 0.5011 (0.5691) kd_loss 0.8971 (0.9227) acc 93.7500 (95.5208) gate/entropy 1.0309 (1.0310) gate/usage_max 0.4655 (0.4645) gate/usage_min 0.1780 (0.1778) gate/usage_std 0.1185 (0.1183) teacher/entropy 0.0641 (0.0883) teacher/usage_max 0.6740 (0.5481) teacher/usage_min 0.1589 (0.1676) teacher/usage_std 0.2409 (0.1649) nleep/row_max_mean 1515.2871 (1526.2870) nleep/row_max_std 49.2044 (40.6545) nleep/row_min_mean 1492.8240 (1502.7885) lr 9.3721e-04 eta 0:07:48
epoch [28/50] batch [80/132] time 0.165 (0.155) data 0.000 (0.005) loss 1.3097 (1.3579) teacher_loss 0.0189 (0.1305) loss_zs_kd 0.0052 (0.0139) loss_oracle 0.5910 (0.5708) kd_loss 0.9926 (0.9351) acc 100.0000 (95.4688) gate/entropy 1.0311 (1.0310) gate/usage_max 0.4664 (0.4649) gate/usage_min 0.1788 (0.1780) gate/usage_std 0.1184 (0.1183) teacher/entropy 0.0983 (0.0854) teacher/usage_max 0.4168 (0.5449) teacher/usage_min 0.2469 (0.1733) teacher/usage_std 0.0694 (0.1615) nleep/row_max_mean 1533.3263 (1526.9007) nleep/row_max_std 35.4806 (40.5017) nleep/row_min_mean 1508.2791 (1503.3691) lr 9.3721e-04 eta 0:07:38
epoch [28/50] batch [100/132] time 0.162 (0.155) data 0.000 (0.004) loss 1.4946 (1.3681) teacher_loss 0.2370 (0.1310) loss_zs_kd 0.0342 (0.0131) loss_oracle 0.6032 (0.5720) kd_loss 0.9389 (0.9446) acc 90.6250 (95.4062) gate/entropy 1.0310 (1.0310) gate/usage_max 0.4677 (0.4653) gate/usage_min 0.1791 (0.1782) gate/usage_std 0.1187 (0.1184) teacher/entropy 0.0565 (0.0830) teacher/usage_max 0.6087 (0.5489) teacher/usage_min 0.1876 (0.1726) teacher/usage_std 0.1948 (0.1638) nleep/row_max_mean 1514.4412 (1527.3052) nleep/row_max_std 38.0830 (40.2549) nleep/row_min_mean 1489.2598 (1503.6380) lr 9.3721e-04 eta 0:07:35
epoch [28/50] batch [120/132] time 0.142 (0.155) data 0.000 (0.003) loss 1.4405 (1.3675) teacher_loss 0.0613 (0.1272) loss_zs_kd 0.0072 (0.0136) loss_oracle 0.6557 (0.5739) kd_loss 1.0478 (0.9466) acc 96.8750 (95.4948) gate/entropy 1.0312 (1.0310) gate/usage_max 0.4687 (0.4658) gate/usage_min 0.1798 (0.1784) gate/usage_std 0.1186 (0.1184) teacher/entropy 0.0792 (0.0832) teacher/usage_max 0.5084 (0.5509) teacher/usage_min 0.1484 (0.1703) teacher/usage_std 0.1471 (0.1654) nleep/row_max_mean 1534.0804 (1527.7104) nleep/row_max_std 35.5650 (40.2008) nleep/row_min_mean 1509.3740 (1503.9643) lr 9.3721e-04 eta 0:07:32
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,806
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.1%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,562
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 92.9%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 28 *******
epoch [29/50] batch [20/132] time 0.084 (0.129) data 0.000 (0.015) loss 1.3287 (1.3561) teacher_loss 0.0358 (0.1174) loss_zs_kd 0.0172 (0.0135) loss_oracle 0.5205 (0.5697) kd_loss 1.0240 (0.9471) acc 100.0000 (95.9375) gate/entropy 1.0310 (1.0310) gate/usage_max 0.4705 (0.4699) gate/usage_min 0.1803 (0.1800) gate/usage_std 0.1190 (0.1190) teacher/entropy 0.0587 (0.0859) teacher/usage_max 0.4642 (0.5693) teacher/usage_min 0.2574 (0.1738) teacher/usage_std 0.0929 (0.1729) nleep/row_max_mean 1522.0128 (1528.3375) nleep/row_max_std 48.4212 (44.6478) nleep/row_min_mean 1500.9521 (1503.7758) lr 8.7467e-04 eta 0:06:10
epoch [29/50] batch [40/132] time 0.081 (0.124) data 0.000 (0.007) loss 1.3052 (1.3602) teacher_loss 0.0353 (0.1125) loss_zs_kd 0.0190 (0.0140) loss_oracle 0.5372 (0.5575) kd_loss 0.9918 (0.9620) acc 100.0000 (95.8594) gate/entropy 1.0310 (1.0310) gate/usage_max 0.4714 (0.4704) gate/usage_min 0.1807 (0.1802) gate/usage_std 0.1191 (0.1190) teacher/entropy 0.1159 (0.0880) teacher/usage_max 0.4739 (0.5540) teacher/usage_min 0.2257 (0.1812) teacher/usage_std 0.1040 (0.1619) nleep/row_max_mean 1524.0750 (1527.1557) nleep/row_max_std 43.3055 (42.8413) nleep/row_min_mean 1503.1913 (1503.1190) lr 8.7467e-04 eta 0:05:53
epoch [29/50] batch [60/132] time 0.180 (0.121) data 0.000 (0.005) loss 1.3689 (1.3767) teacher_loss 0.1386 (0.1090) loss_zs_kd 0.0220 (0.0152) loss_oracle 0.5642 (0.5625) kd_loss 0.9371 (0.9789) acc 93.7500 (96.0417) gate/entropy 1.0308 (1.0309) gate/usage_max 0.4726 (0.4710) gate/usage_min 0.1810 (0.1804) gate/usage_std 0.1194 (0.1191) teacher/entropy 0.0518 (0.0798) teacher/usage_max 0.6760 (0.5497) teacher/usage_min 0.1077 (0.1783) teacher/usage_std 0.2463 (0.1607) nleep/row_max_mean 1537.8815 (1527.6338) nleep/row_max_std 44.6786 (42.2469) nleep/row_min_mean 1510.8223 (1503.3678) lr 8.7467e-04 eta 0:05:45
epoch [29/50] batch [80/132] time 0.085 (0.119) data 0.000 (0.004) loss 1.4202 (1.3827) teacher_loss 0.2615 (0.1154) loss_zs_kd 0.0077 (0.0148) loss_oracle 0.5406 (0.5685) kd_loss 0.8845 (0.9756) acc 87.5000 (95.6641) gate/entropy 1.0309 (1.0309) gate/usage_max 0.4736 (0.4715) gate/usage_min 0.1816 (0.1806) gate/usage_std 0.1195 (0.1192) teacher/entropy 0.1371 (0.0799) teacher/usage_max 0.5846 (0.5465) teacher/usage_min 0.1917 (0.1813) teacher/usage_std 0.1781 (0.1582) nleep/row_max_mean 1520.4642 (1528.4690) nleep/row_max_std 48.4607 (42.0185) nleep/row_min_mean 1498.6960 (1504.2363) lr 8.7467e-04 eta 0:05:35
epoch [29/50] batch [100/132] time 0.161 (0.114) data 0.000 (0.003) loss 1.5228 (1.3842) teacher_loss 0.1712 (0.1170) loss_zs_kd 0.0152 (0.0151) loss_oracle 0.6121 (0.5724) kd_loss 1.0379 (0.9734) acc 90.6250 (95.7188) gate/entropy 1.0307 (1.0309) gate/usage_max 0.4741 (0.4720) gate/usage_min 0.1815 (0.1808) gate/usage_std 0.1197 (0.1193) teacher/entropy 0.0184 (0.0804) teacher/usage_max 0.5327 (0.5420) teacher/usage_min 0.2150 (0.1838) teacher/usage_std 0.1418 (0.1552) nleep/row_max_mean 1542.9058 (1527.6770) nleep/row_max_std 39.8814 (42.1003) nleep/row_min_mean 1514.6628 (1503.5780) lr 8.7467e-04 eta 0:05:21
epoch [29/50] batch [120/132] time 0.185 (0.115) data 0.000 (0.003) loss 1.4144 (1.3811) teacher_loss 0.0562 (0.1131) loss_zs_kd 0.0165 (0.0150) loss_oracle 0.5199 (0.5727) kd_loss 1.0900 (0.9742) acc 96.8750 (95.8594) gate/entropy 1.0307 (1.0309) gate/usage_max 0.4747 (0.4724) gate/usage_min 0.1819 (0.1810) gate/usage_std 0.1197 (0.1193) teacher/entropy 0.0184 (0.0799) teacher/usage_max 0.4377 (0.5369) teacher/usage_min 0.2753 (0.1865) teacher/usage_std 0.0740 (0.1519) nleep/row_max_mean 1533.5162 (1527.8927) nleep/row_max_std 42.1399 (41.8505) nleep/row_min_mean 1509.5208 (1503.9644) lr 8.7467e-04 eta 0:05:20
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,548
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.6%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 28 *******
epoch [30/50] batch [20/132] time 0.154 (0.165) data 0.000 (0.013) loss 1.4178 (1.3766) teacher_loss 0.0984 (0.1011) loss_zs_kd 0.0347 (0.0137) loss_oracle 0.5828 (0.5811) kd_loss 1.0107 (0.9781) acc 96.8750 (96.8750) gate/entropy 1.0306 (1.0307) gate/usage_max 0.4759 (0.4756) gate/usage_min 0.1824 (0.1822) gate/usage_std 0.1200 (0.1199) teacher/entropy 0.0315 (0.0961) teacher/usage_max 0.5644 (0.5113) teacher/usage_min 0.1858 (0.1949) teacher/usage_std 0.1655 (0.1371) nleep/row_max_mean 1529.8572 (1530.5308) nleep/row_max_std 46.0112 (44.9355) nleep/row_min_mean 1507.4219 (1508.0877) lr 8.1262e-04 eta 0:07:33
epoch [30/50] batch [40/132] time 0.158 (0.156) data 0.000 (0.007) loss 1.1841 (1.3634) teacher_loss 0.0413 (0.0882) loss_zs_kd 0.0142 (0.0146) loss_oracle 0.5419 (0.5808) kd_loss 0.8648 (0.9775) acc 100.0000 (97.1875) gate/entropy 1.0305 (1.0307) gate/usage_max 0.4766 (0.4759) gate/usage_min 0.1825 (0.1824) gate/usage_std 0.1202 (0.1200) teacher/entropy 0.1283 (0.0894) teacher/usage_max 0.6079 (0.5089) teacher/usage_min 0.1943 (0.1993) teacher/usage_std 0.1941 (0.1345) nleep/row_max_mean 1530.6230 (1529.2667) nleep/row_max_std 42.1185 (43.7118) nleep/row_min_mean 1508.5151 (1507.0041) lr 8.1262e-04 eta 0:07:06
epoch [30/50] batch [60/132] time 0.124 (0.153) data 0.000 (0.004) loss 1.3554 (1.3820) teacher_loss 0.0889 (0.0981) loss_zs_kd 0.0165 (0.0147) loss_oracle 0.5985 (0.5893) kd_loss 0.9590 (0.9820) acc 96.8750 (96.8750) gate/entropy 1.0305 (1.0306) gate/usage_max 0.4770 (0.4762) gate/usage_min 0.1828 (0.1825) gate/usage_std 0.1202 (0.1200) teacher/entropy 0.0572 (0.0858) teacher/usage_max 0.5287 (0.5076) teacher/usage_min 0.1919 (0.1957) teacher/usage_std 0.1427 (0.1342) nleep/row_max_mean 1532.4470 (1528.7345) nleep/row_max_std 40.0980 (43.1887) nleep/row_min_mean 1509.8528 (1506.3754) lr 8.1262e-04 eta 0:06:54
epoch [30/50] batch [80/132] time 0.155 (0.153) data 0.000 (0.003) loss 1.5149 (1.3886) teacher_loss 0.1105 (0.0991) loss_zs_kd 0.0173 (0.0153) loss_oracle 0.6498 (0.5987) kd_loss 1.0710 (0.9824) acc 93.7500 (96.6797) gate/entropy 1.0305 (1.0306) gate/usage_max 0.4778 (0.4765) gate/usage_min 0.1832 (0.1826) gate/usage_std 0.1203 (0.1201) teacher/entropy 0.0848 (0.0835) teacher/usage_max 0.4234 (0.5072) teacher/usage_min 0.2171 (0.1981) teacher/usage_std 0.0862 (0.1330) nleep/row_max_mean 1534.9791 (1528.4270) nleep/row_max_std 38.5970 (42.6583) nleep/row_min_mean 1511.6145 (1505.9978) lr 8.1262e-04 eta 0:06:50
epoch [30/50] batch [100/132] time 0.133 (0.153) data 0.000 (0.003) loss 1.4906 (1.3866) teacher_loss 0.2083 (0.1042) loss_zs_kd 0.0280 (0.0144) loss_oracle 0.5866 (0.5953) kd_loss 0.9751 (0.9776) acc 93.7500 (96.6562) gate/entropy 1.0303 (1.0306) gate/usage_max 0.4782 (0.4768) gate/usage_min 0.1832 (0.1827) gate/usage_std 0.1205 (0.1202) teacher/entropy 0.0634 (0.0840) teacher/usage_max 0.4726 (0.5036) teacher/usage_min 0.1954 (0.1995) teacher/usage_std 0.1132 (0.1309) nleep/row_max_mean 1532.5383 (1528.0007) nleep/row_max_std 33.4821 (42.3799) nleep/row_min_mean 1509.7064 (1505.6142) lr 8.1262e-04 eta 0:06:47
epoch [30/50] batch [120/132] time 0.147 (0.152) data 0.000 (0.002) loss 1.2566 (1.3794) teacher_loss 0.0536 (0.1041) loss_zs_kd 0.0216 (0.0142) loss_oracle 0.6243 (0.5928) kd_loss 0.8801 (0.9718) acc 96.8750 (96.6406) gate/entropy 1.0304 (1.0306) gate/usage_max 0.4786 (0.4771) gate/usage_min 0.1834 (0.1829) gate/usage_std 0.1205 (0.1202) teacher/entropy 0.0938 (0.0856) teacher/usage_max 0.5838 (0.5044) teacher/usage_min 0.1532 (0.1988) teacher/usage_std 0.1827 (0.1311) nleep/row_max_mean 1524.0266 (1526.9026) nleep/row_max_std 36.6338 (42.3497) nleep/row_min_mean 1501.2913 (1504.6105) lr 8.1262e-04 eta 0:06:42
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,807
* accuracy: 99.2%
* error: 0.8%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,544
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.5%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 28 *******
epoch [31/50] batch [20/132] time 0.105 (0.118) data 0.000 (0.015) loss 1.1897 (1.3644) teacher_loss 0.0037 (0.1142) loss_zs_kd 0.0021 (0.0127) loss_oracle 0.4837 (0.5699) kd_loss 0.9431 (0.9588) acc 100.0000 (95.4688) gate/entropy 1.0303 (1.0304) gate/usage_max 0.4791 (0.4789) gate/usage_min 0.1836 (0.1836) gate/usage_std 0.1207 (0.1206) teacher/entropy 0.0946 (0.0770) teacher/usage_max 0.5529 (0.5060) teacher/usage_min 0.2058 (0.1942) teacher/usage_std 0.1560 (0.1341) nleep/row_max_mean 1534.7242 (1522.8969) nleep/row_max_std 35.7714 (42.4896) nleep/row_min_mean 1510.4958 (1500.1115) lr 7.5131e-04 eta 0:05:09
epoch [31/50] batch [40/132] time 0.201 (0.111) data 0.000 (0.008) loss 1.4399 (1.3605) teacher_loss 0.1589 (0.1084) loss_zs_kd 0.0069 (0.0123) loss_oracle 0.6053 (0.5651) kd_loss 0.9750 (0.9635) acc 90.6250 (95.5469) gate/entropy 1.0303 (1.0304) gate/usage_max 0.4796 (0.4791) gate/usage_min 0.1838 (0.1837) gate/usage_std 0.1208 (0.1206) teacher/entropy 0.0713 (0.0796) teacher/usage_max 0.4378 (0.4949) teacher/usage_min 0.1892 (0.1970) teacher/usage_std 0.1053 (0.1272) nleep/row_max_mean 1521.0499 (1523.8480) nleep/row_max_std 47.4572 (43.7245) nleep/row_min_mean 1496.1250 (1501.0087) lr 7.5131e-04 eta 0:04:49
epoch [31/50] batch [60/132] time 0.189 (0.117) data 0.000 (0.005) loss 1.3659 (1.3518) teacher_loss 0.0716 (0.1142) loss_zs_kd 0.0164 (0.0120) loss_oracle 0.5680 (0.5606) kd_loss 1.0021 (0.9512) acc 100.0000 (95.8854) gate/entropy 1.0303 (1.0304) gate/usage_max 0.4798 (0.4792) gate/usage_min 0.1840 (0.1838) gate/usage_std 0.1208 (0.1207) teacher/entropy 0.0706 (0.0770) teacher/usage_max 0.4683 (0.5154) teacher/usage_min 0.2505 (0.1879) teacher/usage_std 0.0962 (0.1407) nleep/row_max_mean 1533.4377 (1526.2073) nleep/row_max_std 53.2996 (43.9264) nleep/row_min_mean 1507.2748 (1502.8435) lr 7.5131e-04 eta 0:05:01
epoch [31/50] batch [80/132] time 0.078 (0.118) data 0.000 (0.004) loss 1.3566 (1.3549) teacher_loss 0.0570 (0.1220) loss_zs_kd 0.0050 (0.0121) loss_oracle 0.5822 (0.5564) kd_loss 1.0060 (0.9487) acc 96.8750 (95.5078) gate/entropy 1.0302 (1.0303) gate/usage_max 0.4805 (0.4795) gate/usage_min 0.1842 (0.1838) gate/usage_std 0.1210 (0.1207) teacher/entropy 0.0482 (0.0761) teacher/usage_max 0.5707 (0.5247) teacher/usage_min 0.1488 (0.1829) teacher/usage_std 0.1762 (0.1466) nleep/row_max_mean 1531.3418 (1525.9456) nleep/row_max_std 46.5795 (45.5359) nleep/row_min_mean 1507.7646 (1502.3231) lr 7.5131e-04 eta 0:05:01
epoch [31/50] batch [100/132] time 0.194 (0.120) data 0.000 (0.003) loss 1.2588 (1.3471) teacher_loss 0.0487 (0.1191) loss_zs_kd 0.0008 (0.0118) loss_oracle 0.4953 (0.5557) kd_loss 0.9620 (0.9443) acc 100.0000 (95.7188) gate/entropy 1.0302 (1.0303) gate/usage_max 0.4811 (0.4797) gate/usage_min 0.1846 (0.1839) gate/usage_std 0.1210 (0.1208) teacher/entropy 0.0445 (0.0777) teacher/usage_max 0.5477 (0.5276) teacher/usage_min 0.1875 (0.1826) teacher/usage_std 0.1548 (0.1482) nleep/row_max_mean 1528.3300 (1526.8714) nleep/row_max_std 40.3090 (45.1514) nleep/row_min_mean 1504.7310 (1503.1515) lr 7.5131e-04 eta 0:05:06
epoch [31/50] batch [120/132] time 0.156 (0.123) data 0.000 (0.003) loss 1.3206 (1.3502) teacher_loss 0.0499 (0.1241) loss_zs_kd 0.0048 (0.0122) loss_oracle 0.5125 (0.5556) kd_loss 1.0121 (0.9422) acc 100.0000 (95.6510) gate/entropy 1.0300 (1.0303) gate/usage_max 0.4813 (0.4800) gate/usage_min 0.1844 (0.1840) gate/usage_std 0.1212 (0.1208) teacher/entropy 0.0805 (0.0785) teacher/usage_max 0.4214 (0.5290) teacher/usage_min 0.2549 (0.1821) teacher/usage_std 0.0683 (0.1495) nleep/row_max_mean 1524.0667 (1527.8985) nleep/row_max_std 48.9850 (45.0452) nleep/row_min_mean 1502.5957 (1504.0865) lr 7.5131e-04 eta 0:05:10
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,548
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.6%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 28 *******
epoch [32/50] batch [20/132] time 0.189 (0.180) data 0.000 (0.016) loss 1.3327 (1.3236) teacher_loss 0.0107 (0.0914) loss_zs_kd 0.0124 (0.0124) loss_oracle 0.6082 (0.5885) kd_loss 1.0117 (0.9317) acc 100.0000 (97.0312) gate/entropy 1.0300 (1.0300) gate/usage_max 0.4821 (0.4819) gate/usage_min 0.1848 (0.1848) gate/usage_std 0.1214 (0.1213) teacher/entropy 0.1002 (0.0734) teacher/usage_max 0.3748 (0.5384) teacher/usage_min 0.2584 (0.1788) teacher/usage_std 0.0531 (0.1552) nleep/row_max_mean 1536.9672 (1533.9830) nleep/row_max_std 44.3830 (41.4554) nleep/row_min_mean 1513.9248 (1509.6712) lr 6.9098e-04 eta 0:07:26
epoch [32/50] batch [40/132] time 0.167 (0.170) data 0.000 (0.008) loss 1.4952 (1.3619) teacher_loss 0.2603 (0.1094) loss_zs_kd 0.0561 (0.0147) loss_oracle 0.5830 (0.5935) kd_loss 0.9154 (0.9484) acc 87.5000 (96.0938) gate/entropy 1.0298 (1.0300) gate/usage_max 0.4823 (0.4820) gate/usage_min 0.1847 (0.1848) gate/usage_std 0.1215 (0.1213) teacher/entropy 0.0724 (0.0755) teacher/usage_max 0.5608 (0.5096) teacher/usage_min 0.1651 (0.1844) teacher/usage_std 0.1669 (0.1390) nleep/row_max_mean 1511.0284 (1531.3331) nleep/row_max_std 37.9622 (41.5859) nleep/row_min_mean 1489.7428 (1507.5671) lr 6.9098e-04 eta 0:06:58
epoch [32/50] batch [60/132] time 0.168 (0.166) data 0.000 (0.005) loss 1.3715 (1.3709) teacher_loss 0.0318 (0.1156) loss_zs_kd 0.0112 (0.0141) loss_oracle 0.6494 (0.6012) kd_loss 1.0094 (0.9476) acc 100.0000 (96.2500) gate/entropy 1.0299 (1.0300) gate/usage_max 0.4819 (0.4820) gate/usage_min 0.1847 (0.1848) gate/usage_std 0.1214 (0.1213) teacher/entropy 0.0784 (0.0755) teacher/usage_max 0.3967 (0.5054) teacher/usage_min 0.2328 (0.1749) teacher/usage_std 0.0719 (0.1413) nleep/row_max_mean 1523.6821 (1530.6046) nleep/row_max_std 43.6280 (42.0394) nleep/row_min_mean 1500.8875 (1506.6897) lr 6.9098e-04 eta 0:06:47
epoch [32/50] batch [80/132] time 0.176 (0.167) data 0.000 (0.004) loss 1.1579 (1.3644) teacher_loss 0.0051 (0.1149) loss_zs_kd 0.0001 (0.0130) loss_oracle 0.5765 (0.6006) kd_loss 0.8645 (0.9426) acc 100.0000 (96.1719) gate/entropy 1.0301 (1.0300) gate/usage_max 0.4814 (0.4819) gate/usage_min 0.1845 (0.1848) gate/usage_std 0.1212 (0.1213) teacher/entropy 0.1076 (0.0801) teacher/usage_max 0.5378 (0.4994) teacher/usage_min 0.1237 (0.1702) teacher/usage_std 0.1691 (0.1405) nleep/row_max_mean 1529.1614 (1529.3818) nleep/row_max_std 55.1714 (42.2525) nleep/row_min_mean 1504.7239 (1505.5000) lr 6.9098e-04 eta 0:06:45
epoch [32/50] batch [100/132] time 0.139 (0.156) data 0.000 (0.003) loss 1.4171 (1.3728) teacher_loss 0.1105 (0.1169) loss_zs_kd 0.0246 (0.0133) loss_oracle 0.5621 (0.6060) kd_loss 1.0132 (0.9462) acc 96.8750 (96.0000) gate/entropy 1.0302 (1.0300) gate/usage_max 0.4807 (0.4817) gate/usage_min 0.1843 (0.1847) gate/usage_std 0.1210 (0.1213) teacher/entropy 0.0606 (0.0810) teacher/usage_max 0.4131 (0.4945) teacher/usage_min 0.2192 (0.1699) teacher/usage_std 0.0828 (0.1383) nleep/row_max_mean 1529.3378 (1528.2767) nleep/row_max_std 40.4065 (42.3584) nleep/row_min_mean 1502.1416 (1504.4363) lr 6.9098e-04 eta 0:06:14
epoch [32/50] batch [120/132] time 0.163 (0.148) data 0.000 (0.003) loss 1.2999 (1.3718) teacher_loss 0.1311 (0.1120) loss_zs_kd 0.0119 (0.0132) loss_oracle 0.6163 (0.6085) kd_loss 0.8546 (0.9489) acc 93.7500 (96.1198) gate/entropy 1.0301 (1.0301) gate/usage_max 0.4803 (0.4815) gate/usage_min 0.1839 (0.1846) gate/usage_std 0.1210 (0.1212) teacher/entropy 0.0875 (0.0817) teacher/usage_max 0.5788 (0.4899) teacher/usage_min 0.0997 (0.1716) teacher/usage_std 0.1958 (0.1360) nleep/row_max_mean 1517.3698 (1527.6191) nleep/row_max_std 57.5799 (42.9108) nleep/row_min_mean 1493.4430 (1503.7751) lr 6.9098e-04 eta 0:05:54
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,533
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 92.3%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 28 *******
epoch [33/50] batch [20/132] time 0.091 (0.127) data 0.000 (0.018) loss 1.5509 (1.3874) teacher_loss 0.2281 (0.1206) loss_zs_kd 0.0066 (0.0130) loss_oracle 0.5624 (0.5844) kd_loss 1.0383 (0.9681) acc 90.6250 (95.6250) gate/entropy 1.0305 (1.0304) gate/usage_max 0.4792 (0.4794) gate/usage_min 0.1839 (0.1839) gate/usage_std 0.1206 (0.1207) teacher/entropy 0.1127 (0.0938) teacher/usage_max 0.3644 (0.4552) teacher/usage_min 0.3161 (0.1893) teacher/usage_std 0.0220 (0.1146) nleep/row_max_mean 1522.8835 (1524.0023) nleep/row_max_std 42.5879 (43.3686) nleep/row_min_mean 1498.6882 (1499.9916) lr 6.3188e-04 eta 0:04:59
epoch [33/50] batch [40/132] time 0.212 (0.125) data 0.001 (0.009) loss 1.4413 (1.3888) teacher_loss 0.1292 (0.1288) loss_zs_kd 0.0083 (0.0129) loss_oracle 0.6796 (0.5933) kd_loss 0.9682 (0.9569) acc 93.7500 (95.3125) gate/entropy 1.0303 (1.0304) gate/usage_max 0.4787 (0.4792) gate/usage_min 0.1833 (0.1837) gate/usage_std 0.1206 (0.1206) teacher/entropy 0.0477 (0.0834) teacher/usage_max 0.6201 (0.4835) teacher/usage_min 0.0675 (0.1737) teacher/usage_std 0.2261 (0.1318) nleep/row_max_mean 1532.9004 (1525.0330) nleep/row_max_std 43.6378 (42.9264) nleep/row_min_mean 1506.4371 (1500.5596) lr 6.3188e-04 eta 0:04:51
epoch [33/50] batch [60/132] time 0.156 (0.126) data 0.000 (0.006) loss 1.3855 (1.3996) teacher_loss 0.1302 (0.1283) loss_zs_kd 0.0191 (0.0131) loss_oracle 0.5850 (0.5989) kd_loss 0.9532 (0.9653) acc 93.7500 (95.3125) gate/entropy 1.0306 (1.0304) gate/usage_max 0.4783 (0.4789) gate/usage_min 0.1836 (0.1836) gate/usage_std 0.1204 (0.1206) teacher/entropy 0.1074 (0.0834) teacher/usage_max 0.4971 (0.4748) teacher/usage_min 0.2456 (0.1834) teacher/usage_std 0.1159 (0.1237) nleep/row_max_mean 1510.5099 (1524.3935) nleep/row_max_std 50.7256 (43.8799) nleep/row_min_mean 1485.7153 (1499.6104) lr 6.3188e-04 eta 0:04:51
epoch [33/50] batch [80/132] time 0.155 (0.133) data 0.000 (0.005) loss 1.6673 (1.3910) teacher_loss 0.3567 (0.1193) loss_zs_kd 0.0121 (0.0132) loss_oracle 0.6162 (0.5978) kd_loss 0.9964 (0.9661) acc 93.7500 (95.7812) gate/entropy 1.0305 (1.0304) gate/usage_max 0.4777 (0.4787) gate/usage_min 0.1831 (0.1835) gate/usage_std 0.1204 (0.1205) teacher/entropy 0.0727 (0.0834) teacher/usage_max 0.4801 (0.4778) teacher/usage_min 0.1746 (0.1808) teacher/usage_std 0.1250 (0.1258) nleep/row_max_mean 1527.1312 (1524.7239) nleep/row_max_std 48.9470 (43.4634) nleep/row_min_mean 1503.2573 (1499.9300) lr 6.3188e-04 eta 0:05:05
epoch [33/50] batch [100/132] time 0.168 (0.141) data 0.000 (0.004) loss 1.3649 (1.3866) teacher_loss 0.0722 (0.1139) loss_zs_kd 0.0055 (0.0131) loss_oracle 0.4995 (0.5959) kd_loss 1.0403 (0.9682) acc 93.7500 (95.8750) gate/entropy 1.0307 (1.0304) gate/usage_max 0.4770 (0.4784) gate/usage_min 0.1831 (0.1834) gate/usage_std 0.1201 (0.1205) teacher/entropy 0.1454 (0.0848) teacher/usage_max 0.3639 (0.4713) teacher/usage_min 0.2983 (0.1856) teacher/usage_std 0.0270 (0.1212) nleep/row_max_mean 1501.4641 (1524.4639) nleep/row_max_std 54.3157 (43.9382) nleep/row_min_mean 1479.3186 (1499.6293) lr 6.3188e-04 eta 0:05:20
epoch [33/50] batch [120/132] time 0.161 (0.145) data 0.000 (0.003) loss 1.3451 (1.3922) teacher_loss 0.0593 (0.1158) loss_zs_kd 0.0083 (0.0135) loss_oracle 0.6368 (0.5978) kd_loss 0.9632 (0.9707) acc 96.8750 (95.7812) gate/entropy 1.0306 (1.0305) gate/usage_max 0.4766 (0.4781) gate/usage_min 0.1826 (0.1833) gate/usage_std 0.1201 (0.1204) teacher/entropy 0.1180 (0.0836) teacher/usage_max 0.4279 (0.4710) teacher/usage_min 0.2400 (0.1886) teacher/usage_std 0.0767 (0.1200) nleep/row_max_mean 1523.5406 (1523.9642) nleep/row_max_std 48.3293 (44.0330) nleep/row_min_mean 1500.2576 (1499.2605) lr 6.3188e-04 eta 0:05:26
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,527
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.2%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 28 *******
epoch [34/50] batch [20/132] time 0.137 (0.182) data 0.000 (0.018) loss 1.3089 (1.4016) teacher_loss 0.0312 (0.0865) loss_zs_kd 0.0121 (0.0153) loss_oracle 0.6186 (0.6518) kd_loss 0.9624 (0.9816) acc 100.0000 (96.2500) gate/entropy 1.0308 (1.0307) gate/usage_max 0.4755 (0.4760) gate/usage_min 0.1824 (0.1825) gate/usage_std 0.1198 (0.1200) teacher/entropy 0.0747 (0.1002) teacher/usage_max 0.5702 (0.4831) teacher/usage_min 0.1111 (0.1967) teacher/usage_std 0.1877 (0.1206) nleep/row_max_mean 1508.9795 (1520.2396) nleep/row_max_std 59.4994 (46.1529) nleep/row_min_mean 1486.2197 (1495.9961) lr 5.7422e-04 eta 0:06:45
epoch [34/50] batch [40/132] time 0.095 (0.148) data 0.000 (0.009) loss 1.4035 (1.4182) teacher_loss 0.1820 (0.1012) loss_zs_kd 0.0097 (0.0152) loss_oracle 0.5406 (0.6378) kd_loss 0.9464 (0.9905) acc 90.6250 (96.3281) gate/entropy 1.0307 (1.0307) gate/usage_max 0.4753 (0.4757) gate/usage_min 0.1821 (0.1824) gate/usage_std 0.1199 (0.1199) teacher/entropy 0.1001 (0.0914) teacher/usage_max 0.4365 (0.4664) teacher/usage_min 0.1892 (0.2058) teacher/usage_std 0.1050 (0.1106) nleep/row_max_mean 1518.0952 (1522.2944) nleep/row_max_std 50.5761 (46.7047) nleep/row_min_mean 1496.8076 (1497.5074) lr 5.7422e-04 eta 0:05:27
epoch [34/50] batch [60/132] time 0.133 (0.139) data 0.000 (0.006) loss 1.2467 (1.4147) teacher_loss 0.0041 (0.1047) loss_zs_kd 0.0010 (0.0161) loss_oracle 0.6179 (0.6217) kd_loss 0.9331 (0.9911) acc 100.0000 (96.1979) gate/entropy 1.0308 (1.0307) gate/usage_max 0.4748 (0.4755) gate/usage_min 0.1821 (0.1823) gate/usage_std 0.1197 (0.1199) teacher/entropy 0.1366 (0.0857) teacher/usage_max 0.4195 (0.4666) teacher/usage_min 0.2175 (0.2043) teacher/usage_std 0.0851 (0.1119) nleep/row_max_mean 1524.0581 (1522.8412) nleep/row_max_std 48.6588 (46.1862) nleep/row_min_mean 1501.1476 (1497.9353) lr 5.7422e-04 eta 0:05:03
epoch [34/50] batch [80/132] time 0.113 (0.134) data 0.000 (0.005) loss 1.4440 (1.4175) teacher_loss 0.0087 (0.1042) loss_zs_kd 0.0030 (0.0162) loss_oracle 0.7379 (0.6209) kd_loss 1.0649 (0.9947) acc 100.0000 (96.0938) gate/entropy 1.0311 (1.0308) gate/usage_max 0.4744 (0.4753) gate/usage_min 0.1823 (0.1822) gate/usage_std 0.1195 (0.1198) teacher/entropy 0.1005 (0.0825) teacher/usage_max 0.3496 (0.4642) teacher/usage_min 0.3166 (0.2083) teacher/usage_std 0.0135 (0.1092) nleep/row_max_mean 1528.7422 (1523.3591) nleep/row_max_std 55.4642 (45.8194) nleep/row_min_mean 1499.7354 (1498.1745) lr 5.7422e-04 eta 0:04:50
epoch [34/50] batch [100/132] time 0.081 (0.131) data 0.000 (0.004) loss 1.3763 (1.4210) teacher_loss 0.0917 (0.1106) loss_zs_kd 0.0188 (0.0164) loss_oracle 0.6478 (0.6205) kd_loss 0.9513 (0.9919) acc 96.8750 (95.9375) gate/entropy 1.0307 (1.0308) gate/usage_max 0.4745 (0.4751) gate/usage_min 0.1817 (0.1822) gate/usage_std 0.1197 (0.1198) teacher/entropy 0.1018 (0.0844) teacher/usage_max 0.4983 (0.4663) teacher/usage_min 0.2322 (0.2084) teacher/usage_std 0.1176 (0.1100) nleep/row_max_mean 1538.8315 (1523.4787) nleep/row_max_std 37.6844 (45.0664) nleep/row_min_mean 1512.1101 (1498.3296) lr 5.7422e-04 eta 0:04:40
epoch [34/50] batch [120/132] time 0.082 (0.127) data 0.000 (0.003) loss 1.4109 (1.4223) teacher_loss 0.0920 (0.1112) loss_zs_kd 0.0067 (0.0169) loss_oracle 0.6122 (0.6183) kd_loss 1.0094 (0.9935) acc 96.8750 (95.8594) gate/entropy 1.0307 (1.0308) gate/usage_max 0.4745 (0.4750) gate/usage_min 0.1818 (0.1821) gate/usage_std 0.1197 (0.1198) teacher/entropy 0.0737 (0.0823) teacher/usage_max 0.5292 (0.4712) teacher/usage_min 0.1765 (0.2092) teacher/usage_std 0.1466 (0.1121) nleep/row_max_mean 1537.1526 (1523.6861) nleep/row_max_std 49.0588 (45.1471) nleep/row_min_mean 1509.8179 (1498.5353) lr 5.7422e-04 eta 0:04:29
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,525
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 92.1%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 28 *******
epoch [35/50] batch [20/132] time 0.133 (0.159) data 0.000 (0.015) loss 1.3775 (1.4515) teacher_loss 0.1201 (0.1266) loss_zs_kd 0.0081 (0.0116) loss_oracle 0.6695 (0.5944) kd_loss 0.9185 (1.0219) acc 93.7500 (95.1562) gate/entropy 1.0308 (1.0308) gate/usage_max 0.4747 (0.4747) gate/usage_min 0.1820 (0.1820) gate/usage_std 0.1197 (0.1197) teacher/entropy 0.0677 (0.0726) teacher/usage_max 0.5612 (0.4758) teacher/usage_min 0.1572 (0.2174) teacher/usage_std 0.1689 (0.1086) nleep/row_max_mean 1536.6416 (1522.8944) nleep/row_max_std 42.5689 (45.0393) nleep/row_min_mean 1508.5061 (1497.2734) lr 5.1825e-04 eta 0:05:33
epoch [35/50] batch [40/132] time 0.120 (0.149) data 0.000 (0.008) loss 1.5473 (1.4529) teacher_loss 0.0562 (0.1100) loss_zs_kd 0.0035 (0.0130) loss_oracle 0.6520 (0.6074) kd_loss 1.1633 (1.0327) acc 96.8750 (96.2500) gate/entropy 1.0308 (1.0308) gate/usage_max 0.4750 (0.4748) gate/usage_min 0.1822 (0.1820) gate/usage_std 0.1197 (0.1197) teacher/entropy 0.0280 (0.0660) teacher/usage_max 0.3751 (0.4593) teacher/usage_min 0.2731 (0.2223) teacher/usage_std 0.0437 (0.1007) nleep/row_max_mean 1526.9883 (1523.5147) nleep/row_max_std 41.1590 (44.0134) nleep/row_min_mean 1498.2344 (1497.8156) lr 5.1825e-04 eta 0:05:09
epoch [35/50] batch [60/132] time 0.141 (0.149) data 0.000 (0.005) loss 1.5098 (1.4533) teacher_loss 0.2405 (0.1116) loss_zs_kd 0.0184 (0.0146) loss_oracle 0.6630 (0.6171) kd_loss 0.9286 (1.0258) acc 90.6250 (96.0417) gate/entropy 1.0306 (1.0308) gate/usage_max 0.4753 (0.4749) gate/usage_min 0.1821 (0.1821) gate/usage_std 0.1199 (0.1197) teacher/entropy 0.0461 (0.0609) teacher/usage_max 0.5686 (0.4727) teacher/usage_min 0.1444 (0.2140) teacher/usage_std 0.1762 (0.1106) nleep/row_max_mean 1532.9231 (1522.6702) nleep/row_max_std 34.1032 (41.6050) nleep/row_min_mean 1505.9020 (1496.9768) lr 5.1825e-04 eta 0:05:05
epoch [35/50] batch [80/132] time 0.164 (0.149) data 0.000 (0.004) loss 1.3034 (1.4402) teacher_loss 0.0155 (0.0998) loss_zs_kd 0.0019 (0.0141) loss_oracle 0.6073 (0.6152) kd_loss 0.9833 (1.0257) acc 100.0000 (96.4453) gate/entropy 1.0308 (1.0308) gate/usage_max 0.4755 (0.4750) gate/usage_min 0.1824 (0.1821) gate/usage_std 0.1198 (0.1197) teacher/entropy 0.0914 (0.0645) teacher/usage_max 0.4291 (0.4696) teacher/usage_min 0.2301 (0.2180) teacher/usage_std 0.0814 (0.1079) nleep/row_max_mean 1519.7305 (1521.3131) nleep/row_max_std 35.0410 (41.6519) nleep/row_min_mean 1497.0686 (1496.0655) lr 5.1825e-04 eta 0:05:03
epoch [35/50] batch [100/132] time 0.153 (0.149) data 0.000 (0.003) loss 1.6559 (1.4398) teacher_loss 0.2271 (0.0979) loss_zs_kd 0.0191 (0.0147) loss_oracle 0.6155 (0.6107) kd_loss 1.1115 (1.0293) acc 93.7500 (96.5312) gate/entropy 1.0309 (1.0308) gate/usage_max 0.4756 (0.4751) gate/usage_min 0.1826 (0.1822) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0453 (0.0648) teacher/usage_max 0.3933 (0.4659) teacher/usage_min 0.2637 (0.2183) teacher/usage_std 0.0534 (0.1060) nleep/row_max_mean 1510.1016 (1520.6606) nleep/row_max_std 48.2154 (41.3886) nleep/row_min_mean 1487.4539 (1495.7442) lr 5.1825e-04 eta 0:05:00
epoch [35/50] batch [120/132] time 0.167 (0.151) data 0.000 (0.003) loss 1.5363 (1.4420) teacher_loss 0.1011 (0.0940) loss_zs_kd 0.0209 (0.0144) loss_oracle 0.6720 (0.6105) kd_loss 1.0887 (1.0354) acc 93.7500 (96.5365) gate/entropy 1.0309 (1.0308) gate/usage_max 0.4759 (0.4752) gate/usage_min 0.1828 (0.1822) gate/usage_std 0.1198 (0.1198) teacher/entropy 0.0834 (0.0666) teacher/usage_max 0.4035 (0.4614) teacher/usage_min 0.2220 (0.2208) teacher/usage_std 0.0796 (0.1032) nleep/row_max_mean 1507.9968 (1519.8202) nleep/row_max_std 46.9807 (41.6022) nleep/row_min_mean 1483.0298 (1495.0709) lr 5.1825e-04 eta 0:05:00
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,538
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.4%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 28 *******
epoch [36/50] batch [20/132] time 0.169 (0.137) data 0.000 (0.015) loss 1.5813 (1.4883) teacher_loss 0.2036 (0.1107) loss_zs_kd 0.0234 (0.0194) loss_oracle 0.5878 (0.6232) kd_loss 1.0722 (1.0563) acc 90.6250 (95.6250) gate/entropy 1.0307 (1.0307) gate/usage_max 0.4761 (0.4761) gate/usage_min 0.1826 (0.1826) gate/usage_std 0.1200 (0.1200) teacher/entropy 0.0672 (0.0613) teacher/usage_max 0.4027 (0.4465) teacher/usage_min 0.2763 (0.2364) teacher/usage_std 0.0523 (0.0892) nleep/row_max_mean 1518.4490 (1521.3065) nleep/row_max_std 50.7033 (43.2988) nleep/row_min_mean 1493.9609 (1496.5439) lr 4.6417e-04 eta 0:04:27
epoch [36/50] batch [40/132] time 0.099 (0.132) data 0.000 (0.008) loss 1.4894 (1.4760) teacher_loss 0.0622 (0.1003) loss_zs_kd 0.0190 (0.0198) loss_oracle 0.6479 (0.6170) kd_loss 1.0937 (1.0573) acc 100.0000 (96.3281) gate/entropy 1.0308 (1.0307) gate/usage_max 0.4765 (0.4763) gate/usage_min 0.1830 (0.1827) gate/usage_std 0.1199 (0.1200) teacher/entropy 0.0541 (0.0668) teacher/usage_max 0.3635 (0.4393) teacher/usage_min 0.3133 (0.2360) teacher/usage_std 0.0217 (0.0867) nleep/row_max_mean 1530.0823 (1521.9115) nleep/row_max_std 45.1426 (43.7782) nleep/row_min_mean 1501.6802 (1496.9403) lr 4.6417e-04 eta 0:04:16
epoch [36/50] batch [60/132] time 0.192 (0.130) data 0.000 (0.005) loss 1.5595 (1.4797) teacher_loss 0.1352 (0.0944) loss_zs_kd 0.0099 (0.0193) loss_oracle 0.6160 (0.6231) kd_loss 1.1113 (1.0641) acc 93.7500 (96.5625) gate/entropy 1.0306 (1.0307) gate/usage_max 0.4766 (0.4763) gate/usage_min 0.1827 (0.1828) gate/usage_std 0.1201 (0.1200) teacher/entropy 0.0203 (0.0664) teacher/usage_max 0.4042 (0.4319) teacher/usage_min 0.2862 (0.2418) teacher/usage_std 0.0510 (0.0812) nleep/row_max_mean 1530.8044 (1524.0358) nleep/row_max_std 36.9110 (43.3734) nleep/row_min_mean 1503.8542 (1498.6831) lr 4.6417e-04 eta 0:04:08
epoch [36/50] batch [80/132] time 0.105 (0.123) data 0.000 (0.004) loss 1.3891 (1.4779) teacher_loss 0.1529 (0.0953) loss_zs_kd 0.0255 (0.0184) loss_oracle 0.5948 (0.6178) kd_loss 0.9261 (1.0645) acc 90.6250 (96.5234) gate/entropy 1.0306 (1.0307) gate/usage_max 0.4766 (0.4764) gate/usage_min 0.1827 (0.1828) gate/usage_std 0.1201 (0.1200) teacher/entropy 0.0605 (0.0691) teacher/usage_max 0.6062 (0.4289) teacher/usage_min 0.1834 (0.2448) teacher/usage_std 0.1933 (0.0787) nleep/row_max_mean 1533.8425 (1524.8338) nleep/row_max_std 36.2424 (43.0153) nleep/row_min_mean 1507.6019 (1499.4279) lr 4.6417e-04 eta 0:03:54
epoch [36/50] batch [100/132] time 0.206 (0.123) data 0.000 (0.003) loss 1.6100 (1.4749) teacher_loss 0.0939 (0.0948) loss_zs_kd 0.0078 (0.0176) loss_oracle 0.6617 (0.6161) kd_loss 1.1813 (1.0632) acc 96.8750 (96.4375) gate/entropy 1.0308 (1.0308) gate/usage_max 0.4766 (0.4764) gate/usage_min 0.1830 (0.1828) gate/usage_std 0.1200 (0.1200) teacher/entropy 0.0829 (0.0722) teacher/usage_max 0.4704 (0.4275) teacher/usage_min 0.2211 (0.2460) teacher/usage_std 0.1033 (0.0774) nleep/row_max_mean 1532.9513 (1525.0495) nleep/row_max_std 45.7705 (43.1132) nleep/row_min_mean 1505.6249 (1499.5177) lr 4.6417e-04 eta 0:03:51
epoch [36/50] batch [120/132] time 0.120 (0.125) data 0.000 (0.003) loss 1.6044 (1.4748) teacher_loss 0.1298 (0.0946) loss_zs_kd 0.0525 (0.0177) loss_oracle 0.6415 (0.6149) kd_loss 1.1275 (1.0639) acc 96.8750 (96.4062) gate/entropy 1.0306 (1.0308) gate/usage_max 0.4767 (0.4764) gate/usage_min 0.1828 (0.1828) gate/usage_std 0.1201 (0.1200) teacher/entropy 0.0054 (0.0708) teacher/usage_max 0.4058 (0.4293) teacher/usage_min 0.2817 (0.2425) teacher/usage_std 0.0527 (0.0795) nleep/row_max_mean 1528.3524 (1524.8790) nleep/row_max_std 36.8534 (42.7561) nleep/row_min_mean 1502.6442 (1499.3986) lr 4.6417e-04 eta 0:03:52
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,537
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 92.4%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 28 *******
epoch [37/50] batch [20/132] time 0.149 (0.170) data 0.000 (0.017) loss 1.6000 (1.4967) teacher_loss 0.2134 (0.0949) loss_zs_kd 0.0116 (0.0196) loss_oracle 0.6001 (0.6255) kd_loss 1.0808 (1.0792) acc 93.7500 (96.8750) gate/entropy 1.0307 (1.0307) gate/usage_max 0.4769 (0.4769) gate/usage_min 0.1831 (0.1830) gate/usage_std 0.1201 (0.1200) teacher/entropy 0.0713 (0.0702) teacher/usage_max 0.4779 (0.4250) teacher/usage_min 0.2597 (0.2489) teacher/usage_std 0.1022 (0.0762) nleep/row_max_mean 1524.6604 (1522.9379) nleep/row_max_std 38.4831 (42.5065) nleep/row_min_mean 1499.2642 (1497.7558) lr 4.1221e-04 eta 0:05:11
epoch [37/50] batch [40/132] time 0.150 (0.163) data 0.000 (0.008) loss 1.3983 (1.4795) teacher_loss 0.0282 (0.0997) loss_zs_kd 0.0126 (0.0202) loss_oracle 0.5778 (0.6099) kd_loss 1.0749 (1.0648) acc 96.8750 (96.1719) gate/entropy 1.0307 (1.0307) gate/usage_max 0.4770 (0.4769) gate/usage_min 0.1830 (0.1831) gate/usage_std 0.1201 (0.1201) teacher/entropy 0.0179 (0.0672) teacher/usage_max 0.4668 (0.4285) teacher/usage_min 0.2530 (0.2448) teacher/usage_std 0.0951 (0.0790) nleep/row_max_mean 1524.4270 (1521.8806) nleep/row_max_std 47.1943 (42.5042) nleep/row_min_mean 1500.2251 (1497.1616) lr 4.1221e-04 eta 0:04:55
epoch [37/50] batch [60/132] time 0.151 (0.160) data 0.000 (0.006) loss 1.6854 (1.4731) teacher_loss 0.1730 (0.0879) loss_zs_kd 0.0280 (0.0178) loss_oracle 0.6399 (0.6145) kd_loss 1.1784 (1.0690) acc 93.7500 (96.6667) gate/entropy 1.0308 (1.0308) gate/usage_max 0.4772 (0.4770) gate/usage_min 0.1833 (0.1831) gate/usage_std 0.1201 (0.1201) teacher/entropy 0.0545 (0.0671) teacher/usage_max 0.4523 (0.4324) teacher/usage_min 0.1800 (0.2365) teacher/usage_std 0.1138 (0.0843) nleep/row_max_mean 1512.7538 (1522.1154) nleep/row_max_std 60.9361 (43.3273) nleep/row_min_mean 1485.5907 (1497.1668) lr 4.1221e-04 eta 0:04:45
epoch [37/50] batch [80/132] time 0.179 (0.158) data 0.000 (0.004) loss 1.4580 (1.4792) teacher_loss 0.0828 (0.0890) loss_zs_kd 0.0319 (0.0172) loss_oracle 0.6010 (0.6192) kd_loss 1.0587 (1.0719) acc 93.7500 (96.6016) gate/entropy 1.0306 (1.0307) gate/usage_max 0.4773 (0.4770) gate/usage_min 0.1831 (0.1831) gate/usage_std 0.1202 (0.1201) teacher/entropy 0.0632 (0.0669) teacher/usage_max 0.4190 (0.4333) teacher/usage_min 0.2801 (0.2359) teacher/usage_std 0.0611 (0.0847) nleep/row_max_mean 1509.5062 (1522.3111) nleep/row_max_std 46.8179 (42.9141) nleep/row_min_mean 1486.2861 (1497.2987) lr 4.1221e-04 eta 0:04:38
epoch [37/50] batch [100/132] time 0.137 (0.157) data 0.000 (0.003) loss 1.4634 (1.4887) teacher_loss 0.0190 (0.0920) loss_zs_kd 0.0105 (0.0179) loss_oracle 0.6133 (0.6208) kd_loss 1.1325 (1.0773) acc 100.0000 (96.5312) gate/entropy 1.0306 (1.0307) gate/usage_max 0.4776 (0.4771) gate/usage_min 0.1832 (0.1832) gate/usage_std 0.1203 (0.1201) teacher/entropy 0.0441 (0.0670) teacher/usage_max 0.4370 (0.4376) teacher/usage_min 0.1630 (0.2327) teacher/usage_std 0.1214 (0.0881) nleep/row_max_mean 1531.8109 (1521.1495) nleep/row_max_std 38.4510 (42.6876) nleep/row_min_mean 1505.9824 (1496.2195) lr 4.1221e-04 eta 0:04:33
epoch [37/50] batch [120/132] time 0.069 (0.154) data 0.000 (0.003) loss 1.6727 (1.4866) teacher_loss 0.2731 (0.0917) loss_zs_kd 0.0261 (0.0178) loss_oracle 0.6415 (0.6193) kd_loss 1.0659 (1.0763) acc 93.7500 (96.4844) gate/entropy 1.0306 (1.0307) gate/usage_max 0.4782 (0.4772) gate/usage_min 0.1835 (0.1832) gate/usage_std 0.1203 (0.1201) teacher/entropy 0.0755 (0.0665) teacher/usage_max 0.4084 (0.4408) teacher/usage_min 0.2623 (0.2306) teacher/usage_std 0.0597 (0.0906) nleep/row_max_mean 1535.4624 (1521.5274) nleep/row_max_std 34.1252 (42.1807) nleep/row_min_mean 1510.9961 (1496.4586) lr 4.1221e-04 eta 0:04:25
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,808
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.2%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,563
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 92.8%
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model-best-test.pth.tar
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [38/50] batch [20/132] time 0.096 (0.120) data 0.000 (0.014) loss 1.5807 (1.5352) teacher_loss 0.0256 (0.0827) loss_zs_kd 0.0192 (0.0176) loss_oracle 0.7207 (0.6251) kd_loss 1.1852 (1.1311) acc 100.0000 (97.0312) gate/entropy 1.0307 (1.0307) gate/usage_max 0.4787 (0.4785) gate/usage_min 0.1839 (0.1839) gate/usage_std 0.1204 (0.1203) teacher/entropy 0.0223 (0.0578) teacher/usage_max 0.4142 (0.4789) teacher/usage_min 0.2190 (0.1755) teacher/usage_std 0.0831 (0.1296) nleep/row_max_mean 1526.5142 (1521.0638) nleep/row_max_std 40.7587 (41.1297) nleep/row_min_mean 1498.8481 (1495.0009) lr 3.6258e-04 eta 0:03:23
epoch [38/50] batch [40/132] time 0.121 (0.116) data 0.000 (0.007) loss 1.4181 (1.5344) teacher_loss 0.0519 (0.0895) loss_zs_kd 0.0299 (0.0200) loss_oracle 0.6565 (0.6274) kd_loss 1.0230 (1.1212) acc 100.0000 (96.8750) gate/entropy 1.0305 (1.0306) gate/usage_max 0.4792 (0.4787) gate/usage_min 0.1839 (0.1839) gate/usage_std 0.1206 (0.1204) teacher/entropy 0.0880 (0.0556) teacher/usage_max 0.4797 (0.4690) teacher/usage_min 0.2010 (0.1804) teacher/usage_std 0.1142 (0.1231) nleep/row_max_mean 1523.7288 (1520.8879) nleep/row_max_std 36.2525 (41.3314) nleep/row_min_mean 1498.7776 (1494.9752) lr 3.6258e-04 eta 0:03:15
epoch [38/50] batch [60/132] time 0.090 (0.118) data 0.000 (0.005) loss 1.6760 (1.5345) teacher_loss 0.1550 (0.0924) loss_zs_kd 0.0314 (0.0197) loss_oracle 0.6038 (0.6205) kd_loss 1.2034 (1.1220) acc 96.8750 (96.5104) gate/entropy 1.0307 (1.0306) gate/usage_max 0.4794 (0.4789) gate/usage_min 0.1844 (0.1840) gate/usage_std 0.1204 (0.1204) teacher/entropy 0.0547 (0.0510) teacher/usage_max 0.4689 (0.4668) teacher/usage_min 0.2167 (0.1783) teacher/usage_std 0.1038 (0.1227) nleep/row_max_mean 1514.2864 (1521.8055) nleep/row_max_std 45.3798 (41.8337) nleep/row_min_mean 1489.2545 (1495.7790) lr 3.6258e-04 eta 0:03:16
epoch [38/50] batch [80/132] time 0.200 (0.123) data 0.000 (0.004) loss 1.6616 (1.5344) teacher_loss 0.1477 (0.0893) loss_zs_kd 0.0262 (0.0190) loss_oracle 0.6339 (0.6179) kd_loss 1.1838 (1.1267) acc 93.7500 (96.6016) gate/entropy 1.0304 (1.0306) gate/usage_max 0.4803 (0.4792) gate/usage_min 0.1844 (0.1841) gate/usage_std 0.1208 (0.1205) teacher/entropy 0.0454 (0.0481) teacher/usage_max 0.4392 (0.4704) teacher/usage_min 0.2166 (0.1756) teacher/usage_std 0.0912 (0.1254) nleep/row_max_mean 1516.7173 (1522.0602) nleep/row_max_std 48.4192 (42.0457) nleep/row_min_mean 1488.9521 (1495.9238) lr 3.6258e-04 eta 0:03:21
epoch [38/50] batch [100/132] time 0.169 (0.126) data 0.000 (0.003) loss 1.3518 (1.5235) teacher_loss 0.0261 (0.0844) loss_zs_kd 0.0101 (0.0181) loss_oracle 0.5265 (0.6096) kd_loss 1.0574 (1.1253) acc 100.0000 (96.8750) gate/entropy 1.0304 (1.0306) gate/usage_max 0.4805 (0.4794) gate/usage_min 0.1846 (0.1842) gate/usage_std 0.1208 (0.1205) teacher/entropy 0.1060 (0.0505) teacher/usage_max 0.4046 (0.4694) teacher/usage_min 0.2311 (0.1753) teacher/usage_std 0.0741 (0.1252) nleep/row_max_mean 1506.6189 (1521.1328) nleep/row_max_std 42.6199 (42.3110) nleep/row_min_mean 1485.2594 (1495.0790) lr 3.6258e-04 eta 0:03:23
epoch [38/50] batch [120/132] time 0.155 (0.131) data 0.000 (0.002) loss 1.3954 (1.5243) teacher_loss 0.0679 (0.0879) loss_zs_kd 0.0157 (0.0180) loss_oracle 0.5517 (0.6034) kd_loss 1.0438 (1.1257) acc 96.8750 (96.7448) gate/entropy 1.0302 (1.0305) gate/usage_max 0.4812 (0.4796) gate/usage_min 0.1846 (0.1843) gate/usage_std 0.1211 (0.1206) teacher/entropy 0.0588 (0.0495) teacher/usage_max 0.5191 (0.4711) teacher/usage_min 0.1500 (0.1739) teacher/usage_std 0.1507 (0.1265) nleep/row_max_mean 1521.8875 (1520.7398) nleep/row_max_std 36.0636 (42.1807) nleep/row_min_mean 1498.3186 (1494.7158) lr 3.6258e-04 eta 0:03:28
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,550
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 92.6%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [39/50] batch [20/132] time 0.126 (0.171) data 0.000 (0.014) loss 1.4369 (1.5276) teacher_loss 0.0168 (0.1034) loss_zs_kd 0.0150 (0.0183) loss_oracle 0.5793 (0.6028) kd_loss 1.1229 (1.1136) acc 100.0000 (95.9375) gate/entropy 1.0304 (1.0303) gate/usage_max 0.4816 (0.4814) gate/usage_min 0.1852 (0.1850) gate/usage_std 0.1210 (0.1210) teacher/entropy 0.0375 (0.0473) teacher/usage_max 0.4710 (0.4755) teacher/usage_min 0.1263 (0.1530) teacher/usage_std 0.1490 (0.1394) nleep/row_max_mean 1528.5735 (1515.1594) nleep/row_max_std 26.4463 (38.6737) nleep/row_min_mean 1501.4675 (1489.6949) lr 3.1545e-04 eta 0:04:27
epoch [39/50] batch [40/132] time 0.161 (0.160) data 0.000 (0.007) loss 1.5406 (1.5323) teacher_loss 0.0728 (0.0951) loss_zs_kd 0.0224 (0.0190) loss_oracle 0.6305 (0.5958) kd_loss 1.1414 (1.1298) acc 96.8750 (96.3281) gate/entropy 1.0302 (1.0303) gate/usage_max 0.4821 (0.4816) gate/usage_min 0.1852 (0.1851) gate/usage_std 0.1212 (0.1211) teacher/entropy 0.0415 (0.0469) teacher/usage_max 0.4376 (0.4805) teacher/usage_min 0.1414 (0.1641) teacher/usage_std 0.1359 (0.1350) nleep/row_max_mean 1521.4318 (1515.3402) nleep/row_max_std 45.1039 (40.2940) nleep/row_min_mean 1495.4001 (1490.1678) lr 3.1545e-04 eta 0:04:06
epoch [39/50] batch [60/132] time 0.155 (0.160) data 0.001 (0.005) loss 1.3984 (1.5326) teacher_loss 0.0242 (0.0952) loss_zs_kd 0.0054 (0.0180) loss_oracle 0.6378 (0.6004) kd_loss 1.0526 (1.1283) acc 100.0000 (96.4062) gate/entropy 1.0303 (1.0303) gate/usage_max 0.4821 (0.4818) gate/usage_min 0.1854 (0.1852) gate/usage_std 0.1211 (0.1211) teacher/entropy 0.0613 (0.0500) teacher/usage_max 0.4108 (0.4749) teacher/usage_min 0.2870 (0.1703) teacher/usage_std 0.0551 (0.1302) nleep/row_max_mean 1521.9576 (1516.1829) nleep/row_max_std 40.8273 (41.0631) nleep/row_min_mean 1498.8728 (1491.2216) lr 3.1545e-04 eta 0:04:03
epoch [39/50] batch [80/132] time 0.099 (0.155) data 0.000 (0.004) loss 1.5208 (1.5384) teacher_loss 0.1764 (0.0993) loss_zs_kd 0.0088 (0.0177) loss_oracle 0.4921 (0.5974) kd_loss 1.0940 (1.1316) acc 96.8750 (96.3672) gate/entropy 1.0302 (1.0303) gate/usage_max 0.4824 (0.4819) gate/usage_min 0.1854 (0.1853) gate/usage_std 0.1213 (0.1211) teacher/entropy 0.0516 (0.0489) teacher/usage_max 0.4893 (0.4714) teacher/usage_min 0.1200 (0.1750) teacher/usage_std 0.1561 (0.1264) nleep/row_max_mean 1517.4830 (1516.1818) nleep/row_max_std 36.7219 (41.0564) nleep/row_min_mean 1493.0706 (1491.3050) lr 3.1545e-04 eta 0:03:53
epoch [39/50] batch [100/132] time 0.085 (0.146) data 0.000 (0.003) loss 1.3454 (1.5388) teacher_loss 0.0223 (0.1034) loss_zs_kd 0.0001 (0.0186) loss_oracle 0.6240 (0.5952) kd_loss 1.0111 (1.1285) acc 100.0000 (96.1250) gate/entropy 1.0301 (1.0303) gate/usage_max 0.4828 (0.4821) gate/usage_min 0.1855 (0.1853) gate/usage_std 0.1214 (0.1212) teacher/entropy 0.1173 (0.0503) teacher/usage_max 0.4047 (0.4734) teacher/usage_min 0.2888 (0.1735) teacher/usage_std 0.0510 (0.1274) nleep/row_max_mean 1523.6720 (1517.0473) nleep/row_max_std 47.4347 (40.6730) nleep/row_min_mean 1499.6321 (1492.0454) lr 3.1545e-04 eta 0:03:36
epoch [39/50] batch [120/132] time 0.074 (0.142) data 0.000 (0.003) loss 1.4961 (1.5371) teacher_loss 0.0709 (0.1038) loss_zs_kd 0.0140 (0.0190) loss_oracle 0.6173 (0.5972) kd_loss 1.1095 (1.1252) acc 96.8750 (96.0417) gate/entropy 1.0302 (1.0302) gate/usage_max 0.4832 (0.4822) gate/usage_min 0.1859 (0.1854) gate/usage_std 0.1214 (0.1212) teacher/entropy 0.0100 (0.0508) teacher/usage_max 0.4354 (0.4728) teacher/usage_min 0.2522 (0.1731) teacher/usage_std 0.0762 (0.1273) nleep/row_max_mean 1504.1226 (1517.4387) nleep/row_max_std 37.6197 (40.3853) nleep/row_min_mean 1480.7828 (1492.4014) lr 3.1545e-04 eta 0:03:28
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,547
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 92.6%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [40/50] batch [20/132] time 0.082 (0.135) data 0.000 (0.017) loss 1.5131 (1.4948) teacher_loss 0.0736 (0.0830) loss_zs_kd 0.0209 (0.0193) loss_oracle 0.6242 (0.5989) kd_loss 1.1170 (1.1026) acc 96.8750 (97.0312) gate/entropy 1.0302 (1.0301) gate/usage_max 0.4836 (0.4835) gate/usage_min 0.1863 (0.1860) gate/usage_std 0.1214 (0.1215) teacher/entropy 0.0355 (0.0598) teacher/usage_max 0.4729 (0.4820) teacher/usage_min 0.1309 (0.1664) teacher/usage_std 0.1465 (0.1357) nleep/row_max_mean 1521.6436 (1521.1049) nleep/row_max_std 44.2178 (41.2605) nleep/row_min_mean 1493.3535 (1495.3979) lr 2.7103e-04 eta 0:03:13
epoch [40/50] batch [40/132] time 0.059 (0.124) data 0.000 (0.008) loss 1.6037 (1.5012) teacher_loss 0.0385 (0.0809) loss_zs_kd 0.0083 (0.0172) loss_oracle 0.5901 (0.6028) kd_loss 1.2659 (1.1103) acc 96.8750 (97.1875) gate/entropy 1.0303 (1.0301) gate/usage_max 0.4837 (0.4836) gate/usage_min 0.1864 (0.1860) gate/usage_std 0.1214 (0.1215) teacher/entropy 0.0447 (0.0560) teacher/usage_max 0.5285 (0.4788) teacher/usage_min 0.2174 (0.1711) teacher/usage_std 0.1388 (0.1329) nleep/row_max_mean 1521.0035 (1518.6035) nleep/row_max_std 45.3191 (41.3225) nleep/row_min_mean 1493.8123 (1493.0411) lr 2.7103e-04 eta 0:02:55
epoch [40/50] batch [60/132] time 0.159 (0.129) data 0.000 (0.006) loss 1.3226 (1.5008) teacher_loss 0.0383 (0.0915) loss_zs_kd 0.0067 (0.0182) loss_oracle 0.6198 (0.6017) kd_loss 0.9710 (1.0993) acc 100.0000 (97.1875) gate/entropy 1.0300 (1.0301) gate/usage_max 0.4841 (0.4838) gate/usage_min 0.1861 (0.1861) gate/usage_std 0.1217 (0.1216) teacher/entropy 0.1472 (0.0576) teacher/usage_max 0.4494 (0.4767) teacher/usage_min 0.2300 (0.1774) teacher/usage_std 0.0900 (0.1279) nleep/row_max_mean 1512.7726 (1518.2185) nleep/row_max_std 45.0906 (40.8843) nleep/row_min_mean 1488.7450 (1492.7826) lr 2.7103e-04 eta 0:02:59
epoch [40/50] batch [80/132] time 0.162 (0.137) data 0.000 (0.004) loss 1.4490 (1.5011) teacher_loss 0.0606 (0.0914) loss_zs_kd 0.0118 (0.0188) loss_oracle 0.7283 (0.6057) kd_loss 1.0184 (1.0975) acc 96.8750 (97.0312) gate/entropy 1.0301 (1.0300) gate/usage_max 0.4844 (0.4839) gate/usage_min 0.1866 (0.1861) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.0960 (0.0596) teacher/usage_max 0.4435 (0.4728) teacher/usage_min 0.2453 (0.1851) teacher/usage_std 0.0824 (0.1226) nleep/row_max_mean 1500.1782 (1517.7493) nleep/row_max_std 37.3382 (40.7432) nleep/row_min_mean 1476.0861 (1492.5442) lr 2.7103e-04 eta 0:03:08
epoch [40/50] batch [100/132] time 0.168 (0.143) data 0.000 (0.003) loss 1.4788 (1.4988) teacher_loss 0.0599 (0.0909) loss_zs_kd 0.0108 (0.0187) loss_oracle 0.5671 (0.6026) kd_loss 1.1300 (1.0973) acc 96.8750 (97.0625) gate/entropy 1.0301 (1.0300) gate/usage_max 0.4846 (0.4840) gate/usage_min 0.1867 (0.1862) gate/usage_std 0.1216 (0.1216) teacher/entropy 0.0794 (0.0595) teacher/usage_max 0.4321 (0.4675) teacher/usage_min 0.1938 (0.1882) teacher/usage_std 0.1015 (0.1190) nleep/row_max_mean 1505.3896 (1517.3610) nleep/row_max_std 34.3462 (40.1663) nleep/row_min_mean 1482.5505 (1492.3319) lr 2.7103e-04 eta 0:03:13
epoch [40/50] batch [120/132] time 0.154 (0.146) data 0.000 (0.003) loss 1.3726 (1.5004) teacher_loss 0.0091 (0.0937) loss_zs_kd 0.0070 (0.0185) loss_oracle 0.5957 (0.6027) kd_loss 1.0621 (1.0960) acc 100.0000 (96.8490) gate/entropy 1.0300 (1.0300) gate/usage_max 0.4847 (0.4841) gate/usage_min 0.1865 (0.1862) gate/usage_std 0.1218 (0.1216) teacher/entropy 0.1319 (0.0615) teacher/usage_max 0.3766 (0.4662) teacher/usage_min 0.2868 (0.1902) teacher/usage_std 0.0367 (0.1174) nleep/row_max_mean 1506.8838 (1516.3148) nleep/row_max_std 39.9682 (40.1842) nleep/row_min_mean 1483.9110 (1491.4299) lr 2.7103e-04 eta 0:03:13
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,809
* accuracy: 99.3%
* error: 0.7%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,544
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 92.5%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [41/50] batch [20/132] time 0.167 (0.189) data 0.000 (0.017) loss 1.5658 (1.5147) teacher_loss 0.1160 (0.0870) loss_zs_kd 0.0235 (0.0202) loss_oracle 0.5219 (0.5843) kd_loss 1.1772 (1.1254) acc 93.7500 (96.7188) gate/entropy 1.0300 (1.0299) gate/usage_max 0.4849 (0.4850) gate/usage_min 0.1866 (0.1866) gate/usage_std 0.1218 (0.1219) teacher/entropy 0.0136 (0.0501) teacher/usage_max 0.4393 (0.4776) teacher/usage_min 0.1248 (0.1782) teacher/usage_std 0.1475 (0.1279) nleep/row_max_mean 1510.3336 (1512.1848) nleep/row_max_std 47.9203 (42.0378) nleep/row_min_mean 1485.7429 (1487.3281) lr 2.2949e-04 eta 0:04:05
epoch [41/50] batch [40/132] time 0.164 (0.154) data 0.000 (0.009) loss 1.3490 (1.5174) teacher_loss 0.0573 (0.0919) loss_zs_kd 0.0271 (0.0228) loss_oracle 0.5809 (0.5891) kd_loss 0.9877 (1.1195) acc 96.8750 (96.2500) gate/entropy 1.0297 (1.0299) gate/usage_max 0.4855 (0.4851) gate/usage_min 0.1867 (0.1867) gate/usage_std 0.1221 (0.1219) teacher/entropy 0.0607 (0.0525) teacher/usage_max 0.5410 (0.4866) teacher/usage_min 0.1965 (0.1655) teacher/usage_std 0.1493 (0.1371) nleep/row_max_mean 1513.2217 (1511.2146) nleep/row_max_std 38.0372 (40.3909) nleep/row_min_mean 1489.0793 (1486.3528) lr 2.2949e-04 eta 0:03:16
epoch [41/50] batch [60/132] time 0.093 (0.142) data 0.001 (0.006) loss 1.4293 (1.5080) teacher_loss 0.0076 (0.0926) loss_zs_kd 0.0011 (0.0229) loss_oracle 0.5617 (0.5914) kd_loss 1.1403 (1.1083) acc 100.0000 (96.4062) gate/entropy 1.0298 (1.0299) gate/usage_max 0.4858 (0.4853) gate/usage_min 0.1870 (0.1867) gate/usage_std 0.1221 (0.1219) teacher/entropy 0.0253 (0.0538) teacher/usage_max 0.4422 (0.4837) teacher/usage_min 0.1547 (0.1631) teacher/usage_std 0.1273 (0.1368) nleep/row_max_mean 1513.2648 (1511.2265) nleep/row_max_std 34.9944 (39.2213) nleep/row_min_mean 1488.0605 (1486.4796) lr 2.2949e-04 eta 0:02:59
epoch [41/50] batch [80/132] time 0.083 (0.137) data 0.000 (0.004) loss 1.3627 (1.5100) teacher_loss 0.0602 (0.0963) loss_zs_kd 0.0225 (0.0215) loss_oracle 0.5949 (0.5894) kd_loss 0.9939 (1.1082) acc 100.0000 (96.4453) gate/entropy 1.0296 (1.0298) gate/usage_max 0.4861 (0.4854) gate/usage_min 0.1868 (0.1868) gate/usage_std 0.1223 (0.1220) teacher/entropy 0.0849 (0.0550) teacher/usage_max 0.5479 (0.4829) teacher/usage_min 0.1300 (0.1643) teacher/usage_std 0.1708 (0.1355) nleep/row_max_mean 1525.0674 (1513.4946) nleep/row_max_std 41.2511 (39.0862) nleep/row_min_mean 1499.6367 (1488.6270) lr 2.2949e-04 eta 0:02:49
epoch [41/50] batch [100/132] time 0.166 (0.135) data 0.000 (0.004) loss 1.5279 (1.5117) teacher_loss 0.1305 (0.0992) loss_zs_kd 0.0074 (0.0221) loss_oracle 0.5453 (0.5915) kd_loss 1.1210 (1.1057) acc 93.7500 (96.2500) gate/entropy 1.0298 (1.0298) gate/usage_max 0.4861 (0.4856) gate/usage_min 0.1873 (0.1869) gate/usage_std 0.1221 (0.1220) teacher/entropy 0.0622 (0.0541) teacher/usage_max 0.4429 (0.4821) teacher/usage_min 0.1224 (0.1648) teacher/usage_std 0.1492 (0.1350) nleep/row_max_mean 1517.1909 (1514.3784) nleep/row_max_std 47.2920 (39.1305) nleep/row_min_mean 1492.0051 (1489.3029) lr 2.2949e-04 eta 0:02:44
epoch [41/50] batch [120/132] time 0.082 (0.129) data 0.000 (0.003) loss 1.3651 (1.5198) teacher_loss 0.0017 (0.0974) loss_zs_kd 0.0014 (0.0211) loss_oracle 0.5819 (0.5940) kd_loss 1.0717 (1.1149) acc 100.0000 (96.3542) gate/entropy 1.0297 (1.0298) gate/usage_max 0.4863 (0.4857) gate/usage_min 0.1871 (0.1869) gate/usage_std 0.1222 (0.1220) teacher/entropy 0.0586 (0.0532) teacher/usage_max 0.4493 (0.4837) teacher/usage_min 0.2062 (0.1678) teacher/usage_std 0.0995 (0.1346) nleep/row_max_mean 1527.1650 (1514.5286) nleep/row_max_std 25.0238 (38.6114) nleep/row_min_mean 1501.5432 (1489.4690) lr 2.2949e-04 eta 0:02:35
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,539
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 92.4%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [42/50] batch [20/132] time 0.162 (0.170) data 0.000 (0.015) loss 1.4147 (1.4968) teacher_loss 0.0404 (0.0847) loss_zs_kd 0.0288 (0.0188) loss_oracle 0.6436 (0.5791) kd_loss 1.0382 (1.1131) acc 100.0000 (96.8750) gate/entropy 1.0298 (1.0296) gate/usage_max 0.4866 (0.4866) gate/usage_min 0.1875 (0.1873) gate/usage_std 0.1222 (0.1223) teacher/entropy 0.0753 (0.0505) teacher/usage_max 0.5143 (0.4994) teacher/usage_min 0.1246 (0.1377) teacher/usage_std 0.1603 (0.1535) nleep/row_max_mean 1510.9326 (1515.3376) nleep/row_max_std 36.3579 (33.6928) nleep/row_min_mean 1487.1367 (1490.8007) lr 1.9098e-04 eta 0:03:18
epoch [42/50] batch [40/132] time 0.163 (0.168) data 0.000 (0.008) loss 1.4886 (1.5130) teacher_loss 0.1147 (0.0891) loss_zs_kd 0.0223 (0.0210) loss_oracle 0.5340 (0.5824) kd_loss 1.0958 (1.1222) acc 96.8750 (96.6406) gate/entropy 1.0295 (1.0296) gate/usage_max 0.4870 (0.4867) gate/usage_min 0.1873 (0.1874) gate/usage_std 0.1225 (0.1223) teacher/entropy 0.0880 (0.0495) teacher/usage_max 0.4383 (0.4876) teacher/usage_min 0.1273 (0.1513) teacher/usage_std 0.1457 (0.1430) nleep/row_max_mean 1528.6357 (1515.9594) nleep/row_max_std 31.0605 (33.9654) nleep/row_min_mean 1503.7300 (1491.4686) lr 1.9098e-04 eta 0:03:12
epoch [42/50] batch [60/132] time 0.169 (0.166) data 0.000 (0.005) loss 1.5387 (1.5302) teacher_loss 0.1081 (0.0868) loss_zs_kd 0.0226 (0.0199) loss_oracle 0.6259 (0.5935) kd_loss 1.1063 (1.1367) acc 93.7500 (96.7188) gate/entropy 1.0295 (1.0296) gate/usage_max 0.4872 (0.4868) gate/usage_min 0.1875 (0.1874) gate/usage_std 0.1225 (0.1223) teacher/entropy 0.0410 (0.0474) teacher/usage_max 0.4225 (0.4875) teacher/usage_min 0.2206 (0.1520) teacher/usage_std 0.0841 (0.1426) nleep/row_max_mean 1506.7665 (1515.6603) nleep/row_max_std 32.3803 (34.5707) nleep/row_min_mean 1482.4781 (1491.0250) lr 1.9098e-04 eta 0:03:06
epoch [42/50] batch [80/132] time 0.146 (0.163) data 0.000 (0.004) loss 1.5026 (1.5347) teacher_loss 0.0740 (0.0868) loss_zs_kd 0.0336 (0.0204) loss_oracle 0.6322 (0.6033) kd_loss 1.0957 (1.1361) acc 96.8750 (96.7188) gate/entropy 1.0294 (1.0296) gate/usage_max 0.4875 (0.4869) gate/usage_min 0.1874 (0.1874) gate/usage_std 0.1226 (0.1224) teacher/entropy 0.0526 (0.0481) teacher/usage_max 0.3731 (0.4762) teacher/usage_min 0.3048 (0.1667) teacher/usage_std 0.0290 (0.1317) nleep/row_max_mean 1508.6235 (1515.3214) nleep/row_max_std 29.5715 (35.6709) nleep/row_min_mean 1485.8500 (1490.8968) lr 1.9098e-04 eta 0:03:00
epoch [42/50] batch [100/132] time 0.148 (0.162) data 0.000 (0.003) loss 1.3929 (1.5341) teacher_loss 0.0898 (0.0873) loss_zs_kd 0.0165 (0.0193) loss_oracle 0.5847 (0.6059) kd_loss 1.0026 (1.1343) acc 96.8750 (96.6875) gate/entropy 1.0295 (1.0296) gate/usage_max 0.4876 (0.4870) gate/usage_min 0.1877 (0.1875) gate/usage_std 0.1226 (0.1224) teacher/entropy 0.0449 (0.0472) teacher/usage_max 0.5330 (0.4732) teacher/usage_min 0.2110 (0.1727) teacher/usage_std 0.1424 (0.1279) nleep/row_max_mean 1518.5978 (1515.9105) nleep/row_max_std 50.8696 (35.9317) nleep/row_min_mean 1496.0247 (1491.4364) lr 1.9098e-04 eta 0:02:56
epoch [42/50] batch [120/132] time 0.146 (0.161) data 0.000 (0.003) loss 1.4978 (1.5301) teacher_loss 0.1440 (0.0867) loss_zs_kd 0.0317 (0.0196) loss_oracle 0.5693 (0.6051) kd_loss 1.0533 (1.1311) acc 90.6250 (96.7708) gate/entropy 1.0293 (1.0296) gate/usage_max 0.4877 (0.4870) gate/usage_min 0.1876 (0.1875) gate/usage_std 0.1227 (0.1224) teacher/entropy 0.0263 (0.0470) teacher/usage_max 0.5313 (0.4741) teacher/usage_min 0.1554 (0.1722) teacher/usage_std 0.1541 (0.1282) nleep/row_max_mean 1522.0657 (1516.2706) nleep/row_max_std 42.4243 (36.5494) nleep/row_min_mean 1496.0824 (1491.6557) lr 1.9098e-04 eta 0:02:52
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,528
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 92.3%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [43/50] batch [20/132] time 0.090 (0.131) data 0.000 (0.015) loss 1.3749 (1.5101) teacher_loss 0.0482 (0.0814) loss_zs_kd 0.0140 (0.0162) loss_oracle 0.5793 (0.6100) kd_loss 1.0300 (1.1156) acc 96.8750 (97.3438) gate/entropy 1.0293 (1.0295) gate/usage_max 0.4879 (0.4876) gate/usage_min 0.1877 (0.1878) gate/usage_std 0.1227 (0.1226) teacher/entropy 0.0431 (0.0550) teacher/usage_max 0.5034 (0.4752) teacher/usage_min 0.2148 (0.1706) teacher/usage_std 0.1233 (0.1283) nleep/row_max_mean 1516.4905 (1520.6856) nleep/row_max_std 46.3286 (38.1621) nleep/row_min_mean 1492.9958 (1495.6679) lr 1.5567e-04 eta 0:02:15
epoch [43/50] batch [40/132] time 0.195 (0.126) data 0.000 (0.008) loss 1.5015 (1.5151) teacher_loss 0.0441 (0.0805) loss_zs_kd 0.0072 (0.0182) loss_oracle 0.5878 (0.6124) kd_loss 1.1599 (1.1194) acc 96.8750 (97.3438) gate/entropy 1.0294 (1.0295) gate/usage_max 0.4879 (0.4877) gate/usage_min 0.1878 (0.1878) gate/usage_std 0.1227 (0.1226) teacher/entropy 0.0626 (0.0575) teacher/usage_max 0.4593 (0.4696) teacher/usage_min 0.1666 (0.1614) teacher/usage_std 0.1229 (0.1316) nleep/row_max_mean 1512.2969 (1520.1533) nleep/row_max_std 41.3342 (39.6926) nleep/row_min_mean 1488.0966 (1495.0106) lr 1.5567e-04 eta 0:02:08
epoch [43/50] batch [60/132] time 0.094 (0.124) data 0.000 (0.005) loss 1.4615 (1.5341) teacher_loss 0.1469 (0.0854) loss_zs_kd 0.0368 (0.0199) loss_oracle 0.5602 (0.6127) kd_loss 1.0160 (1.1324) acc 93.7500 (96.9271) gate/entropy 1.0293 (1.0295) gate/usage_max 0.4882 (0.4878) gate/usage_min 0.1878 (0.1879) gate/usage_std 0.1228 (0.1226) teacher/entropy 0.0872 (0.0546) teacher/usage_max 0.4879 (0.4750) teacher/usage_min 0.1847 (0.1642) teacher/usage_std 0.1238 (0.1323) nleep/row_max_mean 1515.7563 (1519.5221) nleep/row_max_std 36.2860 (40.3124) nleep/row_min_mean 1491.7225 (1494.3180) lr 1.5567e-04 eta 0:02:03
epoch [43/50] batch [80/132] time 0.078 (0.120) data 0.000 (0.004) loss 1.5171 (1.5363) teacher_loss 0.1158 (0.0856) loss_zs_kd 0.0163 (0.0197) loss_oracle 0.6514 (0.6133) kd_loss 1.0675 (1.1343) acc 93.7500 (96.7969) gate/entropy 1.0295 (1.0295) gate/usage_max 0.4880 (0.4878) gate/usage_min 0.1880 (0.1879) gate/usage_std 0.1226 (0.1226) teacher/entropy 0.0802 (0.0521) teacher/usage_max 0.4535 (0.4733) teacher/usage_min 0.1639 (0.1724) teacher/usage_std 0.1233 (0.1279) nleep/row_max_mean 1520.6094 (1520.0872) nleep/row_max_std 40.9409 (39.9881) nleep/row_min_mean 1495.2313 (1494.7084) lr 1.5567e-04 eta 0:01:56
epoch [43/50] batch [100/132] time 0.188 (0.119) data 0.000 (0.003) loss 1.4666 (1.5347) teacher_loss 0.0817 (0.0893) loss_zs_kd 0.0363 (0.0210) loss_oracle 0.6321 (0.6127) kd_loss 1.0507 (1.1285) acc 96.8750 (96.5625) gate/entropy 1.0293 (1.0295) gate/usage_max 0.4884 (0.4879) gate/usage_min 0.1879 (0.1879) gate/usage_std 0.1228 (0.1226) teacher/entropy 0.0557 (0.0517) teacher/usage_max 0.4839 (0.4754) teacher/usage_min 0.1864 (0.1743) teacher/usage_std 0.1215 (0.1280) nleep/row_max_mean 1523.4994 (1519.8770) nleep/row_max_std 34.7816 (39.7995) nleep/row_min_mean 1494.0820 (1494.5444) lr 1.5567e-04 eta 0:01:54
epoch [43/50] batch [120/132] time 0.077 (0.118) data 0.000 (0.003) loss 1.4933 (1.5379) teacher_loss 0.1311 (0.0901) loss_zs_kd 0.0129 (0.0206) loss_oracle 0.6196 (0.6145) kd_loss 1.0460 (1.1303) acc 93.7500 (96.5104) gate/entropy 1.0294 (1.0294) gate/usage_max 0.4883 (0.4880) gate/usage_min 0.1880 (0.1879) gate/usage_std 0.1228 (0.1227) teacher/entropy 0.0344 (0.0507) teacher/usage_max 0.4842 (0.4745) teacher/usage_min 0.2344 (0.1765) teacher/usage_std 0.1084 (0.1262) nleep/row_max_mean 1521.2695 (1520.3663) nleep/row_max_std 40.9072 (39.5503) nleep/row_min_mean 1496.2749 (1494.9103) lr 1.5567e-04 eta 0:01:50
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,521
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 92.1%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [44/50] batch [20/132] time 0.169 (0.184) data 0.000 (0.017) loss 1.5493 (1.5601) teacher_loss 0.0089 (0.0938) loss_zs_kd 0.0046 (0.0208) loss_oracle 0.6885 (0.6457) kd_loss 1.1938 (1.1331) acc 100.0000 (96.5625) gate/entropy 1.0294 (1.0294) gate/usage_max 0.4883 (0.4884) gate/usage_min 0.1882 (0.1882) gate/usage_std 0.1227 (0.1228) teacher/entropy 0.1046 (0.0545) teacher/usage_max 0.5028 (0.4498) teacher/usage_min 0.2439 (0.2090) teacher/usage_std 0.1199 (0.1036) nleep/row_max_mean 1524.5234 (1520.7135) nleep/row_max_std 32.2442 (36.8636) nleep/row_min_mean 1499.9462 (1494.1631) lr 1.2369e-04 eta 0:02:46
epoch [44/50] batch [40/132] time 0.168 (0.166) data 0.000 (0.009) loss 1.5054 (1.5681) teacher_loss 0.0797 (0.1097) loss_zs_kd 0.0186 (0.0223) loss_oracle 0.5328 (0.6338) kd_loss 1.1500 (1.1303) acc 96.8750 (95.7031) gate/entropy 1.0294 (1.0294) gate/usage_max 0.4887 (0.4885) gate/usage_min 0.1884 (0.1882) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0678 (0.0534) teacher/usage_max 0.4521 (0.4583) teacher/usage_min 0.1751 (0.2006) teacher/usage_std 0.1165 (0.1093) nleep/row_max_mean 1522.8306 (1520.4771) nleep/row_max_std 41.3281 (38.2083) nleep/row_min_mean 1495.7063 (1494.4772) lr 1.2369e-04 eta 0:02:27
epoch [44/50] batch [60/132] time 0.148 (0.163) data 0.001 (0.006) loss 1.4763 (1.5489) teacher_loss 0.0833 (0.0999) loss_zs_kd 0.0358 (0.0221) loss_oracle 0.7297 (0.6370) kd_loss 1.0102 (1.1194) acc 100.0000 (96.4062) gate/entropy 1.0294 (1.0294) gate/usage_max 0.4885 (0.4885) gate/usage_min 0.1883 (0.1882) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0804 (0.0552) teacher/usage_max 0.4719 (0.4514) teacher/usage_min 0.2359 (0.2046) teacher/usage_std 0.1006 (0.1053) nleep/row_max_mean 1512.2900 (1520.2890) nleep/row_max_std 37.4083 (38.6242) nleep/row_min_mean 1487.7651 (1494.4519) lr 1.2369e-04 eta 0:02:20
epoch [44/50] batch [80/132] time 0.125 (0.160) data 0.000 (0.004) loss 1.6697 (1.5373) teacher_loss 0.0912 (0.0952) loss_zs_kd 0.0123 (0.0209) loss_oracle 0.6210 (0.6325) kd_loss 1.2618 (1.1154) acc 93.7500 (96.6016) gate/entropy 1.0292 (1.0294) gate/usage_max 0.4888 (0.4885) gate/usage_min 0.1881 (0.1882) gate/usage_std 0.1230 (0.1228) teacher/entropy 0.0137 (0.0557) teacher/usage_max 0.4392 (0.4565) teacher/usage_min 0.2178 (0.2050) teacher/usage_std 0.0907 (0.1072) nleep/row_max_mean 1535.4099 (1521.7921) nleep/row_max_std 34.5600 (38.6032) nleep/row_min_mean 1506.6604 (1495.9178) lr 1.2369e-04 eta 0:02:15
epoch [44/50] batch [100/132] time 0.148 (0.159) data 0.000 (0.004) loss 1.6869 (1.5532) teacher_loss 0.1118 (0.1028) loss_zs_kd 0.0205 (0.0213) loss_oracle 0.6330 (0.6364) kd_loss 1.2484 (1.1216) acc 93.7500 (96.3125) gate/entropy 1.0296 (1.0294) gate/usage_max 0.4882 (0.4885) gate/usage_min 0.1885 (0.1882) gate/usage_std 0.1226 (0.1228) teacher/entropy 0.0923 (0.0581) teacher/usage_max 0.6061 (0.4582) teacher/usage_min 0.1173 (0.2053) teacher/usage_std 0.2036 (0.1078) nleep/row_max_mean 1512.5139 (1521.0274) nleep/row_max_std 37.6945 (38.5465) nleep/row_min_mean 1487.3330 (1495.1253) lr 1.2369e-04 eta 0:02:10
epoch [44/50] batch [120/132] time 0.078 (0.157) data 0.000 (0.003) loss 1.4974 (1.5510) teacher_loss 0.1094 (0.0973) loss_zs_kd 0.0161 (0.0209) loss_oracle 0.6242 (0.6371) kd_loss 1.0679 (1.1247) acc 93.7500 (96.5104) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4886 (0.4885) gate/usage_min 0.1881 (0.1882) gate/usage_std 0.1229 (0.1228) teacher/entropy 0.0515 (0.0556) teacher/usage_max 0.4707 (0.4598) teacher/usage_min 0.1846 (0.2031) teacher/usage_std 0.1171 (0.1091) nleep/row_max_mean 1529.6891 (1520.7697) nleep/row_max_std 35.0100 (38.1998) nleep/row_min_mean 1503.1823 (1494.8634) lr 1.2369e-04 eta 0:02:06
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,510
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.9%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [45/50] batch [20/132] time 0.121 (0.137) data 0.000 (0.015) loss 1.4621 (1.5060) teacher_loss 0.0565 (0.0676) loss_zs_kd 0.0278 (0.0183) loss_oracle 0.6513 (0.6403) kd_loss 1.0659 (1.1091) acc 100.0000 (97.6562) gate/entropy 1.0294 (1.0294) gate/usage_max 0.4887 (0.4887) gate/usage_min 0.1883 (0.1883) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0867 (0.0653) teacher/usage_max 0.3963 (0.4609) teacher/usage_min 0.2539 (0.1922) teacher/usage_std 0.0593 (0.1155) nleep/row_max_mean 1518.6630 (1522.3290) nleep/row_max_std 43.8817 (38.5488) nleep/row_min_mean 1494.4932 (1496.9927) lr 9.5173e-05 eta 0:01:45
epoch [45/50] batch [40/132] time 0.102 (0.116) data 0.000 (0.008) loss 1.5863 (1.5338) teacher_loss 0.0462 (0.0710) loss_zs_kd 0.0083 (0.0192) loss_oracle 0.7121 (0.6426) kd_loss 1.1800 (1.1318) acc 96.8750 (97.6562) gate/entropy 1.0294 (1.0294) gate/usage_max 0.4884 (0.4886) gate/usage_min 0.1882 (0.1883) gate/usage_std 0.1228 (0.1228) teacher/entropy 0.0643 (0.0605) teacher/usage_max 0.4406 (0.4567) teacher/usage_min 0.2661 (0.1947) teacher/usage_std 0.0766 (0.1130) nleep/row_max_mean 1528.2551 (1524.3108) nleep/row_max_std 37.6307 (38.3037) nleep/row_min_mean 1502.7822 (1498.0819) lr 9.5173e-05 eta 0:01:26
epoch [45/50] batch [60/132] time 0.157 (0.116) data 0.000 (0.005) loss 1.3936 (1.5388) teacher_loss 0.0663 (0.0805) loss_zs_kd 0.0031 (0.0191) loss_oracle 0.6317 (0.6440) kd_loss 1.0099 (1.1267) acc 96.8750 (97.1875) gate/entropy 1.0293 (1.0293) gate/usage_max 0.4888 (0.4887) gate/usage_min 0.1882 (0.1883) gate/usage_std 0.1229 (0.1228) teacher/entropy 0.0491 (0.0596) teacher/usage_max 0.5444 (0.4571) teacher/usage_min 0.1672 (0.1968) teacher/usage_std 0.1572 (0.1120) nleep/row_max_mean 1523.7073 (1524.7619) nleep/row_max_std 40.0414 (38.9925) nleep/row_min_mean 1497.7529 (1498.3743) lr 9.5173e-05 eta 0:01:24
epoch [45/50] batch [80/132] time 0.167 (0.119) data 0.000 (0.004) loss 1.4779 (1.5362) teacher_loss 0.0290 (0.0770) loss_zs_kd 0.0108 (0.0183) loss_oracle 0.6038 (0.6432) kd_loss 1.1416 (1.1284) acc 100.0000 (97.4609) gate/entropy 1.0294 (1.0294) gate/usage_max 0.4888 (0.4887) gate/usage_min 0.1884 (0.1883) gate/usage_std 0.1229 (0.1228) teacher/entropy 0.0944 (0.0589) teacher/usage_max 0.4470 (0.4567) teacher/usage_min 0.2317 (0.1977) teacher/usage_std 0.0883 (0.1108) nleep/row_max_mean 1521.9227 (1525.5218) nleep/row_max_std 37.5180 (38.7680) nleep/row_min_mean 1495.1698 (1498.9625) lr 9.5173e-05 eta 0:01:24
epoch [45/50] batch [100/132] time 0.167 (0.118) data 0.000 (0.003) loss 1.5653 (1.5429) teacher_loss 0.1280 (0.0792) loss_zs_kd 0.0198 (0.0187) loss_oracle 0.6032 (0.6441) kd_loss 1.1259 (1.1322) acc 90.6250 (97.2812) gate/entropy 1.0291 (1.0294) gate/usage_max 0.4891 (0.4887) gate/usage_min 0.1882 (0.1883) gate/usage_std 0.1231 (0.1228) teacher/entropy 0.0698 (0.0592) teacher/usage_max 0.4226 (0.4581) teacher/usage_min 0.1885 (0.1997) teacher/usage_std 0.1033 (0.1103) nleep/row_max_mean 1518.9469 (1524.9422) nleep/row_max_std 41.6409 (39.1717) nleep/row_min_mean 1493.1678 (1498.4596) lr 9.5173e-05 eta 0:01:21
epoch [45/50] batch [120/132] time 0.119 (0.124) data 0.000 (0.003) loss 1.5712 (1.5438) teacher_loss 0.1500 (0.0855) loss_zs_kd 0.0084 (0.0191) loss_oracle 0.6231 (0.6373) kd_loss 1.1055 (1.1301) acc 96.8750 (97.0312) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4889 (0.4887) gate/usage_min 0.1884 (0.1883) gate/usage_std 0.1229 (0.1228) teacher/entropy 0.0856 (0.0596) teacher/usage_max 0.4433 (0.4581) teacher/usage_min 0.1311 (0.1962) teacher/usage_std 0.1432 (0.1120) nleep/row_max_mean 1518.5688 (1524.5026) nleep/row_max_std 52.5315 (39.7454) nleep/row_min_mean 1492.3917 (1498.0807) lr 9.5173e-05 eta 0:01:23
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,810
* accuracy: 99.4%
* error: 0.6%
* macro_f1: 99.3%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,513
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [46/50] batch [20/132] time 0.149 (0.184) data 0.000 (0.013) loss 1.6298 (1.5578) teacher_loss 0.2262 (0.0860) loss_zs_kd 0.0232 (0.0178) loss_oracle 0.6327 (0.6393) kd_loss 1.0757 (1.1432) acc 93.7500 (97.3438) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4889 (0.4888) gate/usage_min 0.1883 (0.1884) gate/usage_std 0.1229 (0.1228) teacher/entropy 0.0297 (0.0503) teacher/usage_max 0.4683 (0.4354) teacher/usage_min 0.2153 (0.2205) teacher/usage_std 0.1040 (0.0903) nleep/row_max_mean 1531.7097 (1523.5037) nleep/row_max_std 36.8554 (44.9954) nleep/row_min_mean 1505.6523 (1497.0978) lr 7.0224e-05 eta 0:01:57
epoch [46/50] batch [40/132] time 0.163 (0.173) data 0.000 (0.007) loss 1.7826 (1.5349) teacher_loss 0.2081 (0.0826) loss_zs_kd 0.0260 (0.0185) loss_oracle 0.6623 (0.6419) kd_loss 1.2304 (1.1221) acc 90.6250 (97.2656) gate/entropy 1.0293 (1.0293) gate/usage_max 0.4888 (0.4888) gate/usage_min 0.1883 (0.1884) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0440 (0.0549) teacher/usage_max 0.4884 (0.4511) teacher/usage_min 0.2270 (0.2135) teacher/usage_std 0.1122 (0.1008) nleep/row_max_mean 1522.2644 (1523.8516) nleep/row_max_std 44.9028 (45.9450) nleep/row_min_mean 1494.3533 (1497.2229) lr 7.0224e-05 eta 0:01:47
epoch [46/50] batch [60/132] time 0.147 (0.167) data 0.000 (0.005) loss 1.6094 (1.5527) teacher_loss 0.0035 (0.0866) loss_zs_kd 0.0008 (0.0191) loss_oracle 0.6640 (0.6433) kd_loss 1.2735 (1.1349) acc 100.0000 (97.0312) gate/entropy 1.0294 (1.0294) gate/usage_max 0.4889 (0.4888) gate/usage_min 0.1885 (0.1884) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0365 (0.0558) teacher/usage_max 0.5543 (0.4598) teacher/usage_min 0.1640 (0.2086) teacher/usage_std 0.1635 (0.1065) nleep/row_max_mean 1519.4764 (1522.7601) nleep/row_max_std 49.4713 (46.1510) nleep/row_min_mean 1492.0858 (1496.2996) lr 7.0224e-05 eta 0:01:40
epoch [46/50] batch [80/132] time 0.149 (0.167) data 0.000 (0.003) loss 1.6576 (1.5635) teacher_loss 0.1849 (0.0916) loss_zs_kd 0.0304 (0.0193) loss_oracle 0.6616 (0.6398) kd_loss 1.1266 (1.1423) acc 93.7500 (96.7188) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4890 (0.4888) gate/usage_min 0.1884 (0.1884) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0399 (0.0540) teacher/usage_max 0.4317 (0.4592) teacher/usage_min 0.1661 (0.2071) teacher/usage_std 0.1189 (0.1069) nleep/row_max_mean 1527.0244 (1522.6174) nleep/row_max_std 43.0860 (45.9637) nleep/row_min_mean 1500.7028 (1496.0025) lr 7.0224e-05 eta 0:01:36
epoch [46/50] batch [100/132] time 0.075 (0.156) data 0.000 (0.003) loss 1.6582 (1.5626) teacher_loss 0.0839 (0.0899) loss_zs_kd 0.0096 (0.0194) loss_oracle 0.6596 (0.6399) kd_loss 1.2397 (1.1430) acc 96.8750 (96.7500) gate/entropy 1.0295 (1.0294) gate/usage_max 0.4886 (0.4888) gate/usage_min 0.1885 (0.1884) gate/usage_std 0.1228 (0.1229) teacher/entropy 0.0377 (0.0537) teacher/usage_max 0.5327 (0.4571) teacher/usage_min 0.1330 (0.2053) teacher/usage_std 0.1632 (0.1071) nleep/row_max_mean 1534.0798 (1522.8348) nleep/row_max_std 36.7024 (45.4758) nleep/row_min_mean 1505.2549 (1496.2206) lr 7.0224e-05 eta 0:01:27
epoch [46/50] batch [120/132] time 0.169 (0.148) data 0.000 (0.002) loss 1.5826 (1.5561) teacher_loss 0.0895 (0.0878) loss_zs_kd 0.0321 (0.0199) loss_oracle 0.6341 (0.6379) kd_loss 1.1599 (1.1393) acc 96.8750 (96.7969) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4889 (0.4888) gate/usage_min 0.1884 (0.1884) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0055 (0.0529) teacher/usage_max 0.4374 (0.4582) teacher/usage_min 0.1574 (0.2018) teacher/usage_std 0.1251 (0.1090) nleep/row_max_mean 1520.7618 (1521.9110) nleep/row_max_std 40.3138 (44.8268) nleep/row_min_mean 1495.4521 (1495.5226) lr 7.0224e-05 eta 0:01:19
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,513
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [47/50] batch [20/132] time 0.176 (0.122) data 0.000 (0.014) loss 1.3892 (1.5385) teacher_loss 0.0623 (0.0769) loss_zs_kd 0.0068 (0.0209) loss_oracle 0.6264 (0.6259) kd_loss 1.0103 (1.1382) acc 96.8750 (97.0312) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4891 (0.4889) gate/usage_min 0.1885 (0.1885) gate/usage_std 0.1230 (0.1229) teacher/entropy 0.1101 (0.0535) teacher/usage_max 0.4807 (0.4686) teacher/usage_min 0.1649 (0.1946) teacher/usage_std 0.1298 (0.1164) nleep/row_max_mean 1513.7776 (1516.7719) nleep/row_max_std 58.4950 (46.0403) nleep/row_min_mean 1488.3872 (1490.8221) lr 4.8943e-05 eta 0:01:01
epoch [47/50] batch [40/132] time 0.106 (0.119) data 0.000 (0.007) loss 1.5140 (1.5569) teacher_loss 0.0842 (0.0875) loss_zs_kd 0.0378 (0.0220) loss_oracle 0.5704 (0.6283) kd_loss 1.1257 (1.1443) acc 100.0000 (96.7188) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4890 (0.4889) gate/usage_min 0.1885 (0.1885) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0199 (0.0524) teacher/usage_max 0.4082 (0.4557) teacher/usage_min 0.2453 (0.2058) teacher/usage_std 0.0672 (0.1054) nleep/row_max_mean 1510.2842 (1516.4270) nleep/row_max_std 47.0722 (45.0589) nleep/row_min_mean 1483.3933 (1490.7681) lr 4.8943e-05 eta 0:00:57
epoch [47/50] batch [60/132] time 0.084 (0.118) data 0.000 (0.005) loss 1.4729 (1.5562) teacher_loss 0.0884 (0.0875) loss_zs_kd 0.0325 (0.0214) loss_oracle 0.6830 (0.6372) kd_loss 1.0268 (1.1394) acc 100.0000 (96.8229) gate/entropy 1.0292 (1.0294) gate/usage_max 0.4889 (0.4888) gate/usage_min 0.1882 (0.1885) gate/usage_std 0.1230 (0.1229) teacher/entropy 0.0362 (0.0533) teacher/usage_max 0.4871 (0.4594) teacher/usage_min 0.2535 (0.2057) teacher/usage_std 0.1088 (0.1075) nleep/row_max_mean 1526.6561 (1516.6417) nleep/row_max_std 41.2376 (44.9882) nleep/row_min_mean 1500.5645 (1491.0309) lr 4.8943e-05 eta 0:00:55
epoch [47/50] batch [80/132] time 0.152 (0.122) data 0.000 (0.004) loss 1.4265 (1.5526) teacher_loss 0.0040 (0.0885) loss_zs_kd 0.0164 (0.0222) loss_oracle 0.6311 (0.6411) kd_loss 1.0988 (1.1324) acc 100.0000 (96.8750) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4888 (0.4889) gate/usage_min 0.1884 (0.1885) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0773 (0.0543) teacher/usage_max 0.3592 (0.4547) teacher/usage_min 0.2875 (0.2112) teacher/usage_std 0.0325 (0.1040) nleep/row_max_mean 1525.2323 (1516.7221) nleep/row_max_std 38.1873 (45.0390) nleep/row_min_mean 1502.1124 (1491.1856) lr 4.8943e-05 eta 0:00:54
epoch [47/50] batch [100/132] time 0.135 (0.128) data 0.000 (0.003) loss 1.5416 (1.5591) teacher_loss 0.0439 (0.0925) loss_zs_kd 0.0144 (0.0214) loss_oracle 0.6857 (0.6389) kd_loss 1.1476 (1.1364) acc 96.8750 (96.7500) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4888 (0.4888) gate/usage_min 0.1883 (0.1885) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0556 (0.0555) teacher/usage_max 0.4288 (0.4557) teacher/usage_min 0.1944 (0.2096) teacher/usage_std 0.1005 (0.1049) nleep/row_max_mean 1527.4944 (1517.2276) nleep/row_max_std 41.5217 (44.8660) nleep/row_min_mean 1500.0331 (1491.7457) lr 4.8943e-05 eta 0:00:54
epoch [47/50] batch [120/132] time 0.153 (0.134) data 0.000 (0.002) loss 1.4182 (1.5582) teacher_loss 0.0556 (0.0926) loss_zs_kd 0.0208 (0.0210) loss_oracle 0.6456 (0.6405) kd_loss 1.0294 (1.1347) acc 100.0000 (96.7708) gate/entropy 1.0294 (1.0294) gate/usage_max 0.4890 (0.4888) gate/usage_min 0.1886 (0.1885) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0927 (0.0561) teacher/usage_max 0.5022 (0.4548) teacher/usage_min 0.1231 (0.2083) teacher/usage_std 0.1575 (0.1051) nleep/row_max_mean 1514.9829 (1517.4813) nleep/row_max_std 43.0946 (44.0193) nleep/row_min_mean 1490.1113 (1492.0123) lr 4.8943e-05 eta 0:00:54
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,512
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.9%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [48/50] batch [20/132] time 0.150 (0.172) data 0.000 (0.016) loss 1.4959 (1.5905) teacher_loss 0.0442 (0.1006) loss_zs_kd 0.0174 (0.0219) loss_oracle 0.6721 (0.6416) kd_loss 1.1069 (1.1581) acc 100.0000 (96.7188) gate/entropy 1.0294 (1.0294) gate/usage_max 0.4886 (0.4888) gate/usage_min 0.1884 (0.1884) gate/usage_std 0.1228 (0.1229) teacher/entropy 0.0552 (0.0450) teacher/usage_max 0.4059 (0.4437) teacher/usage_min 0.2191 (0.2118) teacher/usage_std 0.0817 (0.0988) nleep/row_max_mean 1526.0913 (1520.9348) nleep/row_max_std 29.9122 (40.5858) nleep/row_min_mean 1499.6031 (1495.3554) lr 3.1417e-05 eta 0:01:04
epoch [48/50] batch [40/132] time 0.162 (0.163) data 0.000 (0.008) loss 1.6106 (1.5701) teacher_loss 0.1270 (0.0880) loss_zs_kd 0.0065 (0.0193) loss_oracle 0.6707 (0.6451) kd_loss 1.1450 (1.1499) acc 93.7500 (96.7188) gate/entropy 1.0295 (1.0294) gate/usage_max 0.4887 (0.4888) gate/usage_min 0.1886 (0.1885) gate/usage_std 0.1228 (0.1229) teacher/entropy 0.0482 (0.0479) teacher/usage_max 0.3795 (0.4568) teacher/usage_min 0.2832 (0.2032) teacher/usage_std 0.0394 (0.1086) nleep/row_max_mean 1515.7734 (1520.8163) nleep/row_max_std 40.7544 (39.6663) nleep/row_min_mean 1489.2238 (1495.1710) lr 3.1417e-05 eta 0:00:58
epoch [48/50] batch [60/132] time 0.095 (0.153) data 0.000 (0.005) loss 1.3974 (1.5695) teacher_loss 0.0314 (0.0928) loss_zs_kd 0.0140 (0.0197) loss_oracle 0.6550 (0.6497) kd_loss 1.0315 (1.1420) acc 100.0000 (96.6667) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4889 (0.4888) gate/usage_min 0.1884 (0.1885) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0907 (0.0489) teacher/usage_max 0.4206 (0.4530) teacher/usage_min 0.2680 (0.2085) teacher/usage_std 0.0642 (0.1045) nleep/row_max_mean 1523.8157 (1521.1602) nleep/row_max_std 39.1461 (38.9830) nleep/row_min_mean 1499.0093 (1495.4638) lr 3.1417e-05 eta 0:00:51
epoch [48/50] batch [80/132] time 0.078 (0.141) data 0.000 (0.004) loss 1.5865 (1.5554) teacher_loss 0.1466 (0.0926) loss_zs_kd 0.0151 (0.0197) loss_oracle 0.6082 (0.6411) kd_loss 1.1282 (1.1324) acc 96.8750 (96.6016) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4889 (0.4889) gate/usage_min 0.1883 (0.1885) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0538 (0.0515) teacher/usage_max 0.3909 (0.4552) teacher/usage_min 0.2288 (0.2045) teacher/usage_std 0.0740 (0.1074) nleep/row_max_mean 1528.8401 (1520.9075) nleep/row_max_std 34.5281 (38.5722) nleep/row_min_mean 1502.9128 (1495.3503) lr 3.1417e-05 eta 0:00:44
epoch [48/50] batch [100/132] time 0.106 (0.137) data 0.001 (0.003) loss 1.5248 (1.5685) teacher_loss 0.2283 (0.1010) loss_zs_kd 0.0225 (0.0209) loss_oracle 0.5990 (0.6430) kd_loss 0.9858 (1.1356) acc 90.6250 (96.1250) gate/entropy 1.0291 (1.0294) gate/usage_max 0.4892 (0.4889) gate/usage_min 0.1882 (0.1885) gate/usage_std 0.1231 (0.1229) teacher/entropy 0.0451 (0.0507) teacher/usage_max 0.5643 (0.4543) teacher/usage_min 0.1846 (0.2060) teacher/usage_std 0.1655 (0.1069) nleep/row_max_mean 1532.3214 (1520.3114) nleep/row_max_std 39.6811 (38.5416) nleep/row_min_mean 1509.2747 (1494.7203) lr 3.1417e-05 eta 0:00:40
epoch [48/50] batch [120/132] time 0.103 (0.134) data 0.000 (0.003) loss 1.3591 (1.5604) teacher_loss 0.0053 (0.0935) loss_zs_kd 0.0040 (0.0203) loss_oracle 0.6039 (0.6430) kd_loss 1.0499 (1.1353) acc 100.0000 (96.4844) gate/entropy 1.0294 (1.0294) gate/usage_max 0.4888 (0.4889) gate/usage_min 0.1886 (0.1885) gate/usage_std 0.1228 (0.1229) teacher/entropy 0.0948 (0.0510) teacher/usage_max 0.4182 (0.4575) teacher/usage_min 0.2307 (0.2027) teacher/usage_std 0.0776 (0.1095) nleep/row_max_mean 1514.1387 (1520.7204) nleep/row_max_std 34.1421 (38.3011) nleep/row_min_mean 1491.0447 (1495.0086) lr 3.1417e-05 eta 0:00:37
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,512
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.9%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [49/50] batch [20/132] time 0.163 (0.134) data 0.000 (0.017) loss 1.5433 (1.5317) teacher_loss 0.1986 (0.0892) loss_zs_kd 0.0156 (0.0197) loss_oracle 0.6757 (0.6430) kd_loss 0.9990 (1.1112) acc 90.6250 (96.5625) gate/entropy 1.0292 (1.0293) gate/usage_max 0.4890 (0.4889) gate/usage_min 0.1883 (0.1885) gate/usage_std 0.1230 (0.1229) teacher/entropy 0.0747 (0.0458) teacher/usage_max 0.5281 (0.4565) teacher/usage_min 0.1670 (0.2133) teacher/usage_std 0.1488 (0.1033) nleep/row_max_mean 1524.2953 (1521.4739) nleep/row_max_std 35.7834 (37.6151) nleep/row_min_mean 1499.4792 (1495.7712) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [40/132] time 0.163 (0.143) data 0.000 (0.009) loss 1.5234 (1.5489) teacher_loss 0.0608 (0.1028) loss_zs_kd 0.0373 (0.0209) loss_oracle 0.6044 (0.6354) kd_loss 1.1417 (1.1178) acc 100.0000 (96.0156) gate/entropy 1.0294 (1.0293) gate/usage_max 0.4891 (0.4889) gate/usage_min 0.1886 (0.1885) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0531 (0.0480) teacher/usage_max 0.3921 (0.4632) teacher/usage_min 0.2597 (0.2094) teacher/usage_std 0.0551 (0.1078) nleep/row_max_mean 1510.8890 (1520.5775) nleep/row_max_std 32.5085 (38.0752) nleep/row_min_mean 1485.4491 (1495.0908) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [60/132] time 0.162 (0.149) data 0.001 (0.006) loss 1.5867 (1.5611) teacher_loss 0.1634 (0.1014) loss_zs_kd 0.0312 (0.0220) loss_oracle 0.5878 (0.6336) kd_loss 1.1139 (1.1319) acc 93.7500 (95.9896) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4890 (0.4889) gate/usage_min 0.1884 (0.1885) gate/usage_std 0.1229 (0.1229) teacher/entropy 0.0358 (0.0485) teacher/usage_max 0.4641 (0.4598) teacher/usage_min 0.1401 (0.2056) teacher/usage_std 0.1395 (0.1080) nleep/row_max_mean 1528.6318 (1519.4940) nleep/row_max_std 41.1809 (38.2796) nleep/row_min_mean 1502.6165 (1493.8784) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [80/132] time 0.185 (0.150) data 0.000 (0.005) loss 1.6355 (1.5575) teacher_loss 0.2501 (0.0941) loss_zs_kd 0.0376 (0.0221) loss_oracle 0.6607 (0.6389) kd_loss 1.0363 (1.1329) acc 90.6250 (96.3672) gate/entropy 1.0295 (1.0294) gate/usage_max 0.4887 (0.4889) gate/usage_min 0.1885 (0.1885) gate/usage_std 0.1228 (0.1229) teacher/entropy 0.0633 (0.0517) teacher/usage_max 0.4912 (0.4599) teacher/usage_min 0.1862 (0.2057) teacher/usage_std 0.1247 (0.1081) nleep/row_max_mean 1512.0149 (1520.1575) nleep/row_max_std 40.1621 (37.6122) nleep/row_min_mean 1487.3064 (1494.3884) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [100/132] time 0.160 (0.151) data 0.000 (0.004) loss 1.5715 (1.5570) teacher_loss 0.0452 (0.0930) loss_zs_kd 0.0230 (0.0223) loss_oracle 0.6913 (0.6431) kd_loss 1.1691 (1.1313) acc 96.8750 (96.4375) gate/entropy 1.0297 (1.0294) gate/usage_max 0.4885 (0.4889) gate/usage_min 0.1888 (0.1885) gate/usage_std 0.1226 (0.1229) teacher/entropy 0.0658 (0.0535) teacher/usage_max 0.4725 (0.4574) teacher/usage_min 0.1730 (0.2091) teacher/usage_std 0.1232 (0.1058) nleep/row_max_mean 1514.4984 (1520.5061) nleep/row_max_std 40.2112 (37.4847) nleep/row_min_mean 1487.5845 (1494.6129) lr 1.7713e-05 eta 0:00:24
epoch [49/50] batch [120/132] time 0.135 (0.150) data 0.000 (0.003) loss 1.7639 (1.5633) teacher_loss 0.2995 (0.0981) loss_zs_kd 0.0280 (0.0220) loss_oracle 0.6302 (0.6448) kd_loss 1.1353 (1.1318) acc 87.5000 (96.5365) gate/entropy 1.0294 (1.0294) gate/usage_max 0.4887 (0.4889) gate/usage_min 0.1883 (0.1885) gate/usage_std 0.1228 (0.1229) teacher/entropy 0.0918 (0.0528) teacher/usage_max 0.4369 (0.4558) teacher/usage_min 0.2318 (0.2110) teacher/usage_std 0.0838 (0.1047) nleep/row_max_mean 1514.1682 (1520.9339) nleep/row_max_std 47.4619 (38.1077) nleep/row_min_mean 1488.7300 (1494.9190) lr 1.7713e-05 eta 0:00:21
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,512
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 91.9%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
epoch [50/50] batch [20/132] time 0.104 (0.133) data 0.000 (0.013) loss 1.5644 (1.5745) teacher_loss 0.0200 (0.0722) loss_zs_kd 0.0262 (0.0229) loss_oracle 0.6688 (0.6578) kd_loss 1.1970 (1.1620) acc 100.0000 (97.1875) gate/entropy 1.0296 (1.0294) gate/usage_max 0.4886 (0.4888) gate/usage_min 0.1886 (0.1885) gate/usage_std 0.1227 (0.1228) teacher/entropy 0.0558 (0.0539) teacher/usage_max 0.4878 (0.4668) teacher/usage_min 0.1786 (0.2041) teacher/usage_std 0.1262 (0.1115) nleep/row_max_mean 1520.1974 (1518.8905) nleep/row_max_std 41.1736 (39.7406) nleep/row_min_mean 1495.2169 (1492.8651) lr 7.8853e-06 eta 0:00:14
epoch [50/50] batch [40/132] time 0.088 (0.120) data 0.000 (0.007) loss 1.3949 (1.5663) teacher_loss 0.0445 (0.0840) loss_zs_kd 0.0045 (0.0208) loss_oracle 0.6358 (0.6467) kd_loss 1.0303 (1.1485) acc 96.8750 (96.8750) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4889 (0.4889) gate/usage_min 0.1884 (0.1885) gate/usage_std 0.1229 (0.1228) teacher/entropy 0.0248 (0.0522) teacher/usage_max 0.4666 (0.4538) teacher/usage_min 0.2226 (0.2074) teacher/usage_std 0.1009 (0.1054) nleep/row_max_mean 1522.2180 (1518.6990) nleep/row_max_std 32.0394 (39.4985) nleep/row_min_mean 1498.2275 (1492.7896) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [60/132] time 0.176 (0.120) data 0.000 (0.004) loss 1.5812 (1.5724) teacher_loss 0.0986 (0.0863) loss_zs_kd 0.0293 (0.0198) loss_oracle 0.6092 (0.6492) kd_loss 1.1634 (1.1516) acc 93.7500 (96.8229) gate/entropy 1.0295 (1.0294) gate/usage_max 0.4887 (0.4889) gate/usage_min 0.1887 (0.1885) gate/usage_std 0.1227 (0.1229) teacher/entropy 0.1035 (0.0517) teacher/usage_max 0.5077 (0.4552) teacher/usage_min 0.1668 (0.2053) teacher/usage_std 0.1393 (0.1064) nleep/row_max_mean 1519.7495 (1518.1076) nleep/row_max_std 38.8477 (40.7103) nleep/row_min_mean 1492.9705 (1492.1718) lr 7.8853e-06 eta 0:00:08
epoch [50/50] batch [80/132] time 0.081 (0.120) data 0.000 (0.003) loss 1.5528 (1.5701) teacher_loss 0.0756 (0.0938) loss_zs_kd 0.0250 (0.0201) loss_oracle 0.5705 (0.6441) kd_loss 1.1794 (1.1441) acc 96.8750 (96.5625) gate/entropy 1.0293 (1.0294) gate/usage_max 0.4890 (0.4889) gate/usage_min 0.1884 (0.1885) gate/usage_std 0.1230 (0.1229) teacher/entropy 0.0492 (0.0549) teacher/usage_max 0.4534 (0.4546) teacher/usage_min 0.1994 (0.2017) teacher/usage_std 0.1042 (0.1078) nleep/row_max_mean 1519.7634 (1517.7645) nleep/row_max_std 40.2484 (41.1477) nleep/row_min_mean 1494.8884 (1491.8781) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [100/132] time 0.088 (0.121) data 0.000 (0.003) loss 1.5476 (1.5596) teacher_loss 0.1518 (0.0934) loss_zs_kd 0.0397 (0.0201) loss_oracle 0.6474 (0.6422) kd_loss 1.0522 (1.1350) acc 90.6250 (96.5312) gate/entropy 1.0292 (1.0294) gate/usage_max 0.4891 (0.4889) gate/usage_min 0.1884 (0.1885) gate/usage_std 0.1230 (0.1229) teacher/entropy 0.0448 (0.0550) teacher/usage_max 0.4887 (0.4535) teacher/usage_min 0.1943 (0.2013) teacher/usage_std 0.1207 (0.1074) nleep/row_max_mean 1524.9036 (1517.3958) nleep/row_max_std 43.3025 (41.1443) nleep/row_min_mean 1497.6614 (1491.7400) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [120/132] time 0.076 (0.118) data 0.000 (0.002) loss 1.7196 (1.5583) teacher_loss 0.0802 (0.0940) loss_zs_kd 0.0065 (0.0194) loss_oracle 0.8038 (0.6430) kd_loss 1.2343 (1.1332) acc 96.8750 (96.5104) gate/entropy 1.0295 (1.0294) gate/usage_max 0.4886 (0.4889) gate/usage_min 0.1886 (0.1885) gate/usage_std 0.1227 (0.1229) teacher/entropy 0.0786 (0.0557) teacher/usage_max 0.5307 (0.4524) teacher/usage_min 0.2261 (0.2034) teacher/usage_std 0.1397 (0.1062) nleep/row_max_mean 1523.1901 (1517.4690) nleep/row_max_std 50.8614 (41.1672) nleep/row_min_mean 1494.1897 (1491.8164) lr 7.8853e-06 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 1,821
* correct: 1,811
* accuracy: 99.5%
* error: 0.5%
* macro_f1: 99.4%
Evaluate on the *test* set
=> result
* total: 3,928
* correct: 3,513
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 92.0%
******* Domain s best val acc:      99.6%, epoch: 25 *******
******* Domain s best val test acc: 89.8%, epoch: 25 *******
******* Domain s best test acc:     90.7%, epoch: 37 *******
Checkpoint saved to icml/multi-dg/tuning/base/TRIP/pacs/b32_ep50/ViT-B16/s/seed_3/warmup_1/prompt_learner/model.pth.tar-50
Finish the whole training
Elapsed: 0:21:32
